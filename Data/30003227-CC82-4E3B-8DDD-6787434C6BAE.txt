 2
虛擬研發知識活動支援平台與實現技術研發－子計畫三： 
經驗知識誘導、探勘與分享技術研發 
 
               計畫編號：NSC97-2221-E-327-038 
               執行期限：97 年 08 月 01 日至 98 年 07 月 31 日 
               主持人：陳育仁 國立高雄第一科技大學 會計資訊學系 
               共同主持人：陳裕民 國立成功大學 製造資訊與系統研究所 
                           曾新穆 國立成功大學 資訊工程學系(所) 
                           陳宗義 南華大學 電子商務管理學系 
               計劃參與人員：吳孟昇、趙中岳 國立成功大學 製造資訊與系統研究所 
                             鄭雅如、黃鳳玲 國立高雄第一科技大學 會計資訊學系 
 
Abstract 
In the knowledge economy era of the 21st 
century [14][17], the competitive advantage of 
enterprises has shifted from visible equipment, 
capital and labor in the past to invisible knowledge 
nowadays. Knowledge can be distinguished into 
tacit knowledge and explicit knowledge. Meanwhile, 
tacit knowledge largely encompasses empirical 
knowledge difficult to be documented and generally 
hidden inside of personal mental models. The 
inability to transfer tacit knowledge to 
organizational knowledge would cause it to 
disappear after knowledge workers leaving their post, 
ultimately losing important intellectual assets for 
enterprises. Therefore, enterprises attempting to 
create higher knowledge value are highly concerned 
with how to transfer personal empirical knowledge 
inside of an enterprise into an organizational explicit 
knowledge by using a systematic method to manage 
and share such valuable empirical knowledge 
effectively.  
This study develops a method of 
ontology-based empirical knowledge representation 
and reasoning, which adopts OWL (Web Ontology 
Language) to represent empirical knowledge in a 
structural way in order to help knowledge requesters 
clearly understand empirical knowledge. An 
ontology reasoning method is subsequently adopted 
to deduce empirical knowledge in order to share and 
reuse relevant empirical knowledge effectively. 
Specifically, this study involves the following tasks: 
(i) analyze characteristics for empirical knowledge, 
(ii) design an ontology-based multi-layer empirical 
knowledge representation model, (iii) design an 
ontology-based empirical knowledge concept 
schema, (iv) establish an OWL-based empirical 
knowledge ontology, (v) design reasoning rules for 
ontology-based empirical knowledge, (vi) develop a 
reasoning algorithm for ontology-based empirical 
knowledge, and (vii) implement an ontology-based 
empirical knowledge reasoning mechanism.  
    Results of this study facilitate the tacit 
knowledge storage, management and sharing to 
provide knowledge requesters with accurate and 
comprehensive empirical knowledge for problem 
solving and decision support.  
Keywords: Empirical knowledge, ontology, OWL, 
knowledge representation, knowledge 
reasoning  
 
1. Introduction 
The global economy has shifted recently from a 
manufacturing-based value system to a 
knowledge-based one. Knowledge is essential for 
entrepreneurial success in the knowledge economy 
era. Capable of deciding the life or death of an 
enterprise, knowledge application has become 
pivotal for enhancing entrepreneurial 
competitiveness. Consequently, an effective means 
of improving the competitive advantage of an 
 4
research.  
 
2. Design of Ontology-based Empirical 
Knowledge Representation Model  
    This section analyzes the characteristics of 
empirical knowledge and then describes the design 
of an empirical knowledge representation model as 
well as empirical knowledge concept schema by 
using ontology techniques.  
 
2.1 Empirical Knowledge Characterization  
Based on reviewing and integrating relevant 
empirical knowledge literature [1][3][16][18][22] 
[23][25][26][27][28][29][31][33][36][39], empirical 
knowledge is used here to mean: difficult and costly 
to transfer, making it considerably less mobile than 
more explicit forms. Firms can possess unique 
capabilities that are hard to replicate and often are 
invisible to outside observers. For a notable example 
is particular knowledge such as empirical rule or 
know-how.  
This study analyzes and explains empirical 
knowledge in terms of composition element, trait, 
characteristic, and feature, as shown in Table 1.  
 
2.2 Ontology-based Empirical Knowledge 
Representation Model Design  
This section first divides empirical knowledge 
into four different layers of “know-what”, 
“know-why”, “know-how”, and “know-with” based 
on the empirical knowledge characterization in 2.1 
Section. The conceptual model of ontology-based 
multi-layer empirical knowledge representation is 
then designed by using ontology techniques, as 
shown in Fig. 1.  
 
In Fig.1, descriptive empirical knowledge is 
defined as a know-what layer that identifies class, 
hierarchy, layer, and composition of empirical 
knowledge; in addition, the relationships include the 
taxonomy relationship “Is_a” and the partonomy 
relationship “Part_of”. Casual empirical knowledge 
is treated as a know-why layer that explains the 
causality and is a consequence of empirical 
knowledge. Therefore, the relationships are defined 
as “Cause” and “Caused_by”, respectively. 
Moreover, procedural empirical knowledge is 
defined to a know-how layer that describes the 
operational activity and procedure of an event; the 
relationships are “Follow” and “Is_followed_by”. 
Finally, the know-with layer mainly presents the 
relational empirical knowledge that records the 
relationships among operational activities of an 
event. The relationship is therefore defined as 
“Cooperate_with” to represent the collaboration 
among empirical knowledge concepts.  
 
2.3 Ontology-based Empirical Knowledge 
Concept Schema Design  
For the empirical knowledge concept in the 
conceptual model of ontology-based empirical 
knowledge representation designed in Section 2.2, 
this section adopts the object-oriented method [20][38] 
to design an concept schema of empirical knowledge, 
as shown in Fig. 2. The schema is used to construct 
empirical knowledge ontology, so as to design 
reasoning rules and reason empirical knowledge. The 
empirical knowledge concept schema consists of 
three elements of concept, property, and relationship. 
Each element is described as follows:  
‧ Concept: Concept refers to the name of the basic 
unit that can constitute an empirical knowledge 
ontology to express a visible or invisible object.  
‧ Property: Empirical knowledge properties include 
“Concept_ID”, “Definition”, “Synonym”, 
“Appearance Reason”, “Status”, and “Action”. 
Meanwhile, “Concept_ID” refers to the number of 
empirical knowledge concepts, while the property 
“Definition” describes a certain concept of 
empirical knowledge, making it easy to 
understand and specify. Furthermore, the property 
“Synonym” describes the same semantic using 
 6
had been inherited.  
(iv) owl:SymmetricProperty: the relationship 
symmetry between two concepts.  
(v) owl:inverseOf: the reversibility between 
concept relationships.  
(vi) owl:DatatypeProperty: the data property of a 
concept.  
(vii) owl:minCardinality: constraint on the 
minimum of a property value.  
(viii) owl:maxCardinality: constraint on the 
maximum of a property value.  
 
By using the above OWL constructs, the 
empirical knowledge concept, relationship and 
property of OWL-based empirical knowledge 
ontology are established, as shown in Figs. 3 and 4, 
respectively.  
    Figure 3 shows the empirical knowledge 
concept and relationship of OWL-based empirical 
knowledge ontology. First, the empirical knowledge 
ontology uses the OWL construct rdf:subClassof to 
represent a situation in which the taxonomy 
relationship “Is_a＂exists between the empirical 
knowledge concepts A and B, implying that the 
empirical knowledge concept A is the subclass of 
empirical knowledge concept B. The partonomy 
relationship “Part_of” exists between empirical 
knowledge concepts D and E, indicating that 
empirical knowledge concept D belongs to empirical 
knowledge concept E. Additionally, the partonomy 
relationship “Part_of” can become the transitive 
relationship through the OWL construct 
owl:TransitiveProperty. Moreover, a causal 
relationship “Cause” exists between empirical 
knowledge concepts H and I. Therefore, the 
relationship “Caused_by” is the inversive 
relationship of the relationship “Cause” by using the 
OWL construct owl:inverseOf. A cooperative 
relationship “Cooperate_with” exists between the 
empirical knowledge concepts N and O, implying 
that empirical knowledge concept N cooperates with 
empirical knowledge concept O. Through the OWL 
construct owl:SymmetricProperty, the cooperative 
relationship “Cooperate_with” can be the symmetric 
relationship.  
 
Figure 4 illustrates the property of OWL-based 
empirical knowledge ontology. The empirical 
knowledge concept possesses properties 
“Appearance Reason” and “Status”; they are both 
defined as the OWL construct owl:DatatypeProperty. 
For the rationality of logical reasoning, the 
minimum value of property “Appearance Reason” is 
limited to be 1 (by owl:minCardinality), suggesting 
that filling in one or more property values to 
describe appearance reason is necessary. 
Additionally, the maximum value of property 
“Status” is identified as 1 (by owl:maxCardinality) 
to fill in the value “Normal” or “Abnormal”.  
 
3.2 Ontology-based Reasoning Rules Design for 
Single-Layer Empirical Knowledge  
According to Ronald et al. (2000) [31], the 
knowledge representation method and the logical 
rules used for reasoning must be considered in 
designing reasoning rules. Meanwhile, description 
logics can be applied to related reasoning methods 
and can effectively support the ontology language 
OWL DL as well as identify implied knowledge 
through ontology reasoning methods to facilitate the 
sharing of tacit knowledge [8][19][24][35]. 
Therefore, this section describes the ontology-based 
reasoning rules for single-layer empirical knowledge 
based on the OWL-based empirical knowledge 
ontology and related methods of knowledge 
reasoning, description logics, OWL DL basic axiom 
and constraint [6][15][21] established from Section 
3.1, as shown in Table 3. The empirical knowledge 
reasoning rules in Table 3 comprise four different 
types of know-what, know-why, know-how, and 
know-with. Their descriptions are detailed as 
follows with Figs. 5, 6, 7 and 8 showing the 
 8
of the empirical knowledge concept K after the 
empirical knowledge concept L is “Is_followed_by” 
is derived.  
 
Empirical knowledge reasoning model in the 
know-with layer  
    In this conceptual model of empirical 
knowledge in the know-with layer, a cooperative 
relationship “Cooperate_with” between the 
empirical knowledge concepts M and N and a 
cooperative relationship “Cooperate_with” between 
the empirical knowledge concepts N and O are 
existent. Via the reasoning rule of transitive property 
(Rule (11) in Table 3), the cooperative relationship 
“Cooperate_with” between empirical knowledge 
concepts M and O is therefore deduced. Additionally, 
a cooperative relationship “Cooperate_with” exists 
between empirical knowledge concepts N and O. 
Therefore, the fact that empirical knowledge concept 
O has a cooperative relationship with the empirical 
knowledge concept N is deduced based on the 
reasoning rule of synonymous relationship (Rule (12) 
in Table 3), as shown in Fig. 8.  
 
3.3 Ontology-based Reasoning Rules Design for 
Cross-Layer Empirical Knowledge  
According to the OWL-based empirical 
knowledge ontology and the related methods of 
knowledge reasoning, description logics, and OWL 
DL basic axiom and constraint [14][34] established 
in Section 3.1, this section analyzes how the 
relationships among empirical knowledge in 
different layers are related based on the 
ontology-based multi-layer empirical knowledge 
representation model. Additionally, as well as the 
ontology-based reasoning rules for cross-layer 
empirical knowledge are designed by using ontology 
language OWL DL. According to Table 4, the 
ontology-based reasoning rules for cross-layer 
empirical knowledge involve three categories. They 
are, i.e. “know-what layer vs. know-why layer”, 
“know-what layer vs. know-how layer”, and 
“know-what layer vs. know-with layer”, respectively. 
Each category is described as follows.  
 
Empirical knowledge reasoning model between the 
know-what layer and know-why layer  
    Figure 9 presents the conceptual model of 
empirical knowledge reasoning between the 
know-what layer and know-why layer. In the model, 
a causal relationship “Cause” exists between the 
empirical knowledge concepts X and Y and the 
partonomy relationship “Part_of” exists between 
empirical knowledge concepts Y and Z. Hence, the 
fact that a causal relationship “Cause” exists 
between the empirical knowledge concepts X and Z 
is derived through the reasoning rule (1) from Table 
4.  
 
Empirical knowledge reasoning model between the 
know-what layer and know-how layer  
    In the empirical knowledge reasoning between 
the know-what layer and know-how layer, a 
procedural relationship “Follow” between empirical 
knowledge concepts U and V and a partonomy 
relationship “Part_of” between empirical knowledge 
concepts V and W are existent. Consequently, the 
procedural relationship “Follow” between the 
empirical knowledge concepts U and W is found 
based on the reasoning rule (2) from Table 4, as 
shown in Fig. 10.  
 
Empirical knowledge reasoning model between the 
know-what layer and know-with layer  
    Figure 11 shows the conceptual model of 
empirical knowledge reasoning between the 
know-what layer and know-with layer. A 
cooperative relationship “Cooperate_with” exists 
between the empirical knowledge concepts R and S  
and a partonomy relationship “Part_of” exists 
between empirical knowledge concepts S and T, 
indicating that the cooperative relationship 
 10
cross-layer empirical knowledge, as shown in Fig. 
14. This algorithm involves the following steps:  
Step 1. Input the cross-layer empirical knowledge 
ontology and perform the reasoning of 
cross-layer empirical knowledge.  
Step 2. Determine whether the input empirical 
knowledge covers “know-what” and 
“know-why” and whether the relationships 
are “Part_of” and “Cause”. If yes, then go to 
Step 3; otherwise, go to Step 4.  
Step 3. Execute the reasoning rules for cross-layer 
empirical knowledge “know-what layer vs. 
know-why layer”.  
Step 4. Determine whether the input empirical 
knowledge covers “know-what” and 
“know-how” and whether the relationships 
are “Part_of” and “Follow”. If yes, then go to 
Step 5; otherwise, go to Step 6.  
Step 5. Execute the reasoning rules for cross-layer 
empirical knowledge “know-what layer vs. 
know-how layer”.  
Step 6. Determine whether the input empirical 
knowledge covers “know-what” and 
“know-with”, and whether the relationships 
are “Part_of” and “Cooperate_with”. If yes, 
then go to Step 7; otherwise end the 
algorithm process.  
Step 7. Execute the reasoning rules for cross-layer 
empirical knowledge “know-what layer vs. 
know-with layer”.  
 
The reasoning process for cross-layer empirical 
knowledge shown in Fig. 14 can be represented as 
an algorithm written in Pseudo Code (Fig. 15).  
 
4. Illustrative Example of an Enterprise’s 
Financial Diagnosis  
    Based on the proposed method of 
ontology-based empirical knowledge representation 
and reasoning, the applicability and feasibility of the 
proposed method are demonstrated using an 
illustrative example of enterprise’s financial 
diagnosis.  
 
4.1 Ontology-based Multi-Layer Financial 
Diagnosis Empirical Knowledge  
This section describes a practical example of an 
enterprise’s financial diagnosis to establish the 
ontology-based multi-layer financial diagnosis 
empirical knowledge, as shown in Fig. 16. The 
knowledge representation content for each layer is 
discussed as below:  
(1) Know-what layer: A taxonomy relationship 
“Is_a” exists between the empirical knowledge 
concepts Diet_Enterprise and 
Enterprise_a/Enterprise_b, implying that the 
empirical knowledge concepts Enterprise_a and 
Enterprise_b are the subclasses of the empirical 
knowledge concept Diet_Enterprise. Moreover, 
a taxonomy relationship “Is_a” exists between 
the empirical knowledge concepts Company_a 
and Enterprise_b, indicating that empirical 
knowledge concept Company_a is the subclass 
of the empirical knowledge concept 
Enterprise_b. Additionally, a partonomy 
relationship “Part_of” exists between the 
empirical knowledge concepts Enterprise_a and 
Sub-conglomerate_1/Sub-conglomerate_2. This 
finding suggests that both empirical knowledge 
concepts Sub-conglomerate_1 and 
Sub-conglomerate_2 are parts of the empirical 
knowledge concept Enterprise_a. Meanwhile, a 
partonomy relationship “Part_of” exists between 
the empirical knowledge concepts 
Sub-conglomerate_2 and 
Subsidiary_2/Subsidiary_3/Subsidiary_4/ 
Subsidiary_5, implying that the empirical 
knowledge concepts Subsidiary_2, Subsidiary_3, 
Subsidiary_4, and Subsidiary_5 are all parts of 
the empirical knowledge concept 
Sub-conglomerate_2.  
(2) Know-why layer: A causal relationship “Cause” 
 12
Meanwhile, Fig. 17 shows the part of the empirical 
knowledge concept and relationship of OWL-based 
financial diagnosis empirical knowledge ontology, 
while Fig. 18 depicts the part of property of 
OWL-based financial diagnosis empirical 
knowledge ontology.  
 
4.3 Ontology-based Single-Layer Financial 
Diagnosis Empirical Knowledge Reasoning  
    This section illustrates the ontology-based 
single-layer financial diagnosis empirical knowledge 
reasoning by using the empirical knowledge 
ontology “know-why” as an example. For this 
example, the empirical knowledge ontology 
“know-why” is first represented by using OWL DL. 
Subsequently, reasoning in the know-why layer of 
financial diagnosis empirical knowledge is 
performed through the defined ontology-based 
reasoning rules for single-layer empirical 
knowledge.  
Table 5 lists the partial contents of the 
reasoning in the know-why layer of financial 
diagnosis empirical knowledge before and after the 
executing reasoning process. Meanwhile, a causal 
relationship “Cause” exists between the empirical 
knowledge concepts Subsidiary_3 and Subsidiary_4, 
as well as between the empirical knowledge 
concepts Subsidiary_4 and Subsidiary_5 (Fig. 19). 
Thus, the causal relationship “Cause” exists between 
the empirical knowledge concepts Subsidiary_3 and 
Subsidiary_5 is deduced by using the reasoning rule 
of transitive property (Rule (1) in Table 5). 
Moreover, the relationship “Cause” is the inversive 
relationship of the relationship “Caused_by” (Rule 
(2) in Table 5). Therefore, the relationship 
“Caused_by” between the empirical knowledge 
concepts Subsidiary_5 and Subsidiary_4, between 
the empirical knowledge concepts Subsidiary_4 and 
Subsidiary_3, and between the empirical knowledge 
concepts Subsidiary_5 and Subsidiary_3 are 
deduced by applying the reasoning rule of inversive 
property (Rule (3) in Table 5).  
 
4.4 Ontology-based Cross-Layer Financial 
Diagnosis Empirical Knowledge Reasoning  
This section demonstrates the feasibility of the 
proposed cross-layer empirical knowledge reasoning 
method by selecting the cross-layer empirical 
knowledge ontology “know-what layer vs. 
know-why layer” as an illustrative example. In this 
example, the ontology language OWL DL is initially 
adopted to represent the cross-layer financial 
diagnosis empirical knowledge “know-what layer vs. 
know-why layer”. Next, the defined ontology-based 
reasoning rules for cross-layer empirical knowledge 
in Section 3.3 are applied to the reasoning between 
the know-what layer and know-why layer of 
financial diagnosis empirical knowledge.  
    Table 6 lists the partial contents of the 
reasoning between the know-what layer and 
know-why layer of financial diagnosis empirical 
knowledge before and after the executing reasoning 
process. Meanwhile, a partonomy relationship 
“Part_of” exists between the empirical knowledge 
concepts Financial_Abnormal_of_Subsidiary_2 and 
Financial_Abnormal_of_Sub-conglomerate_2, while 
a causal relationship “Cause” (Fig. 20) exists 
between the empirical knowledge concepts 
Financial_Abnormal_of_Subsidiary_3 and 
Financial_Abnormal_of_Subsidiary_2. Therefore, a 
causal relationship “Cause” exists between empirical 
knowledge concepts 
Financial_Abnormal_of_Subsidiary_3 and 
Financial_Abnormal_of_Sub-conglomerate_2 is 
deduced by the reasoning rule for cross-layer 
empirical knowledge, as shown in Table 6.  
 
5. Ontology-based Empirical Knowledge 
Reasoning Mechanism Implementation 
    Based on the above developed method of 
ontology-based empirical knowledge representation 
and reasoning, this section uses the software Protégé 
 14
studies should as well develop a method for 
distributed empirical knowledge reasoning.  
‧ Situated empirical knowledge representation and 
reasoning: Empirical knowledge is associated 
with situation property. Situated empirical 
knowledge can comprise basic elements such as 
spatial relation and temporal relation. Therefore, 
future studies should consider the situation 
property of empirical knowledge to develop a 
method of situated empirical knowledge 
representation and reasoning in order to deduce a 
more suitable empirical knowledge that would 
satisfy the requirements from a knowledge 
requester under certain circumstances.  
 
Acknowledgements 
The author would like to thank the National 
Science Council of the Republic of China, Taiwan, 
for partially supporting this research under Contract 
No. NSC98-2221-E-327-039.  
 
References 
[1] Alavi, M. and Leidner, D. E., Review: 
Knowledge management and knowledge 
management systems: Conceptual foundations 
and research issues, MIS Quarterly, Vol. 25, No. 
1, pp. 107-136, 2001.  
[2] Andrade, J., Ares, J., García, R., Pazos, J., 
Rodríguez, S., Rodríguez-Patón, A. and Silva, 
A., Towards a lessons learned system for 
critical software, Reliability Engineering and 
System Safety, Vol. 92, No. 7, pp. 902-913, 
2007.  
[3] Bradley, J. H., Paul, R. and Seeman, E., 
Analyzing the structure of expert knowledge, 
Information & Management, Vol. 43, No. 1, pp. 
77-91, 2006.  
[4] Bolloju, N., Khalifa, M. and Turban, E., 
Integrating knowledge management into 
enterprise environments for the next generation 
decision support, Decision Support Systems, 
Vol. 33, No. 2, pp. 163-176, 2002.  
[5] Chandrasekaran, B., Josephson, J. R. and 
Benjamins V. R., What are ontologies, and why 
do we need them?, IEEE Intelligent Systems, 
Vol. 14, No.1, pp. 20-26, 1999.  
[6] Das, S. K., A logical reasoning with preference, 
Decision Support Systems, Vol. 15, No. 1, pp. 
19-25, 1995.  
[7] Dixon, B. E., McGowan, J. J. and Cravens, G. 
D., Knowledge sharing using codification and 
collaboration technologies to improve health 
care: lessons from the public sector, Knowledge 
Management Research & Practice, Vol. 7, pp. 
249-259, 2009.  
[8] Ejigu, D., Scuturici, M. and Brunie, L., An 
ontology-based approach to context modeling 
and reasoning in pervasive computing, in 
Pervasive Computing and Communications 
Workshops, PerCom Workshops '07, Fifth 
Annual IEEE International Conference on, pp. 
14-19, 2007.  
[9] Grant, R. M., Prospering in 
dynamically-competitive environments: 
Organizational capability as knowledge 
integration, Organization Science, Vol. 7, No. 4, 
pp. 375-388, 1996.  
[10] Gruber, T. R., A translation approach to 
portable ontologies, Knowledge Acquisition, 
Vol. 5, No. 2, pp. 199-220, 1993.  
[11] Guarino, N., Understanding, building and using 
ontologies, International Journal of 
Human-Computer Studies, Vol. 46, No. 2-3, pp. 
293-310, 1997.  
[12] Guo, T., Schwartz, D. G., Burstein, F. and 
Linger, H., Codifying collaborative knowledge: 
using Wikipedia as a basis for automated 
ontology learning, Knowledge Management 
Research & Practice, Vol. 7, pp. 206-217, 2009.  
[13] Hansen, M. T., Nohria, N. and Tierney, T., 
What's your strategy for managing knowledge?, 
Harvard Business Review, Vol. 77, No. 2, pp. 
106-116, 1999.  
 16
K., Ontology based context modeling and 
reasoning using OWL, in Pervasive Computing 
and Communications Workshops, Proceedings 
of the Second IEEE Annual Conference on, pp. 
18-22, 2004.  
[36] Weber, R., Aha, D. W. and Becerra-Fernandez, 
I., Intelligent lessons learned systems, Expert 
Systems with Applications, Vol. 20, No, 1, pp. 
17-34, 2001.  
[37] Weber, R. O. and Aha, D. W., Intelligent 
delivery of military lessons learned, Decision 
Support Systems, Vol. 34, No. 3, pp. 287-304, 
2003.  
[38] Xu, W. L., Kuhnert, L., Foster, K., Bronlund, J., 
Potgieter, J. and Diegel, O., Object-oriented 
knowledge representation and discovery of 
human chewing behaviors, Engineering 
Applications of Artificial Intelligence, Vol. 20, 
No. 7, pp. 1000-1012, 2007.  
[39] Zack, M., Managing codified knowledge, Sloan 
Management Review, pp. 45-48, 1999.  
 
 
Table 1. Empirical Knowledge Characterization  
 Empirical Knowledge Description 
Composition 
Element Problem/Cause/Solution 
As either a problem solving method or a modified action, 
empirical knowledge can be described by three elements of 
problem, cause, and solution.  
Feature Tacit 
Characterized as generally having a particular context and 
personalization, empirical knowledge is not easily 
understood, learned, imitated, communicated, transferred, 
and shared.  
Hierarchical Empirical knowledge can be distinguished into different layers based on the use purpose.  
Descriptive “Descriptive” refers to the concept, class, and structure of empirical knowledge.  
Causal “Causal” refers to the causality and consequence of empirical knowledge.  
Procedural “Procedural” refers to the operational activity and procedure of an event.  
Characteristic 
Relational “Relational” refers to how operational activities of an event are related.  
Action-oriented Empirical knowledge can be viewed as action-oriented knowledge, which is represented by conditional action.  
Trait 
Skillful 
Skill indicates the objective-oriented expressional behavior, 
which is difficult to be represented by language. While 
empirical knowledge can be treated as action-oriented 
knowledge, an action can represent knowledge through its 
skill.  
 
 
 18
Table 2. Relevant Symbols for Establishment of OWL-based Empirical Knowledge 
Ontology 
OWL Construct DL Syntax Relationship of  Empirical Knowledge Ontology 
rdf:subClassof ⊆ Is_a 
owl:ObjectProperty P ⊆ Pi 
owl:TransitiveProperty P+ ⊆ P Part_of, Cause, Follow, Cooperate_with 
owl:SymmetricProperty P1 ≡ P1－ Cooperate_with 
owl:inverseOf P ≡ P－ Has_part, Caused_by, Is_followed_by, …etc. 
OWL Construct DL Syntax Property of  Empirical Knowledge Ontology 
owl:DatatypeProperty U ⊆ Ui Appearance Reason, Status, Action 
owl:minCardinality ≥ n P Appearance Reason 
owl:maxCardinality ≤ n P Status, Action 
 
 
  <owl:Class rdf:ID="Empirical_Knowledge_Concept_A"> 
    <rdfs:subClassOf> 
      <owl:Class rdf:ID="Empirical_Knowledge_Concept_B"/> 
    </rdfs:subClassOf> 
  </owl:Class> 
  <owl:TransitiveProperty rdf:ID="Part_of"> 
    <rdfs:domain rdf:resource="#Empirical_Knowledge_Concept_D"/> 
    <rdf:type rdf:resource="http://www.w3.org/2002/07/owl#ObjectProperty"/> 
    <rdfs:range rdf:resource="#Empirical_Knowledge_Concept_E"/> 
  </owl:TransitiveProperty> 
  <owl:TransitiveProperty rdf:about="#Cause"> 
    <rdfs:domain rdf:resource="#Empirical_Knowledge_Concept_H"/> 
    <rdf:type rdf:resource="http://www.w3.org/2002/07/owl#ObjectProperty"/> 
    <owl:inverseOf rdf:resource="#Caused_by"/> 
    <rdfs:range rdf:resource="#Empirical_Knowledge_Concept_I"/> 
  </owl:TransitiveProperty> 
  <owl:SymmetricProperty rdf:ID="Cooperate_with"> 
    <rdfs:domain rdf:resource="#Empirical_Knowledge_Concept_N"/> 
    <rdfs:range rdf:resource="#Empirical_Knowledge_Concept_O"/>     
    <rdf:type rdf:resource="http://www.w3.org/2002/07/owl#ObjectProperty"/> 
  </owl:SymmetricProperty> 
Figure 3. Part of OWL-based Empirical Knowledge Ontology  
(Empirical Knowledge Concept and Relationship)  
 
 
 
 20
Table 3. Ontology-based Reasoning Rules for Single-Layer Empirical Knowledge  
Single-Layer Empirical 
Knowledge Type Relationship Reasoning Rule  
Is_a (1) (?A rdfs:subClassOf ?B)∧(?B rdfs:subClassOf ?C) ⇒ (?A rdfs:subClassOf ?C) 
Know-What Layer Part_of 
Has_part 
(2) ∀D,E,F : Part-of(D,E)∧Part-of(E,F) ⇒ Part-of(D,F) 
(3) Has- part ≡ Part-of -1 (inverse) 
(4) ∀D,E : Part-of(D,E) ⇔ Has- part(E,D) 
Know-Why Layer Cause Caused_by 
(5) (?Cause rdf:type owl:TransitiveProperty)∧(?G ? Cause ?H)∧(?H ? Cause ?I) ⇒ (?G ? Cause ?I) 
(6) Cause ≡ Caused_by -1 (inverse) 
(7) (?Cause owl:inverseOf ? Caused_by)∧(?H ? Cause ?I) ⇒ (?I ? Caused_by ?H) 
Know-How Layer Follow Is_followed_by 
(8) (?Follow rdf:type owl:TransitiveProperty)∧(?J ? Follow ?K)∧(?K ? Follow ?L) ⇒ (?J ? Follow ?L) 
(9) Follow ≡ Is_followed_by -1 (inverse) 
(10) (?Follow owl:inverseOf ? Is_followed_by)∧(?K ? Follow ?L) ⇒ (?L ? Is_followed_by ?K) 
Know-With Layer Cooperate_with 
(11) (?Cooperate_with rdf:type owl:TransitiveProperty) ∧ (?M ? Cooperate_with ?N) ∧ (?N ? 
Cooperate_with ?O)  
⇒ (?M ? Cooperate_with ?O) 
(12) (?Cooperate_with rdf:type owl:SymmetricProperty) ∧ (?N ? Cooperate_with ?O) ⇒ (?O ? 
Cooperate_with ?N) 
NOTE: (1) Parameters A、B、C… denote the concept names of empirical knowledge.  
     (2) Symbol “^” represents the logical operator AND.  
     (3) Symbol “⇒”means reasoning.  
 22
 
Figure 8. Conceptual Model of Empirical Knowledge Reasoning in the Know-With Layer  
 
Table 4. Ontology-based Reasoning Rules for Cross-Layer Empirical Knowledge  
Cross-Empirical 
Knowledge Type Relationship Reasoning Rule 
Know-What Layer 
vs.  
Know-Why Layer 
Part_of 
Cause 
(1) X ⊆ ∃ Cause.Y∧Y ⊆  ∃  Part-of . Z ⇒ X ⊆ ∃ Cause. 
Z 
Know-What Layer 
vs.  
Know-How Layer 
Part_of 
Follow 
(2) U ⊆ ∃ Follow.V∧V ⊆  ∃  Part-of . W ⇒ U 
⊆ ∃ Follow. W 
Know-What Layer 
vs.  
Know-With Layer 
Part_of 
Cooperate_with
(3) R ⊆ ∃ Cooperate_with.S∧S ⊆  ∃  Part-of . T ⇒ R 
⊆ ∃ Cooperate_with. T 
NOTE: (1) Parameters X、Y、Z…denote the concept names of empirical knowledge.  
     (2) Symbol “^” represents the logical operator AND.  
     (3) Symbol “⇒” implies reasoning.  
     (4) Symbol “⊆” implies a subset.  
     (5) Symbol “∃” implies an existential quantifier.  
 
 
Figure 9. Conceptual Model of Empirical Knowledge Reasoning between the Know-What Layer and 
Know-Why Layer  
 
 24
 
Figure 12. Reasoning Process for Single-Layer Empirical Knowledge  
 
 
Single-Layer Empirical Knowledge Reasoning Process  
BEGIN 
Input Empirical Knowledge Ontology (Single-Layer); 
K. Layer: Knowledge Layer; 
IF K. Layer is Know-What AND Relationship is Is_a OR Part_of OR Has_part 
  SWITCH (Relationship) 
    Case 1: Is_a 
      Reasoning by Relationship Is_a; 
      Break; 
    Case 2: Part_of 
      Reasoning by Relationship Part_of; 
      Break; 
    Case 3: Has_part 
      Reasoning by Relationship Has_part; 
 26
 
Figure 14. Reasoning Process for Cross-Layer Empirical Knowledge  
 
 
Cross-Layer Empirical Knowledge Reasoning Process 
BEGIN 
Input Empirical Knowledge Ontology (Cross-Layer); 
K. Layer: Knowledge Layer; 
IF K. Layers are Know-What and Know-Why AND Relationships are Part_of and Cause 
   Cross-Layer Reasoning between Know-What and Know-Why 
Else IF K. Layers are Know-What and Know-How AND Relationships are Part_of and Follow 
   Cross-Layer Reasoning between Know-What and Know-How 
Else IF K. Layer are Know-What and Know-How AND Relationship are Part_of and Cooperate_with 
   Cross-Layer Reasoning between Know-What and Know-With 
END 
Figure 15. Reasoning Algorithm for Cross-Layer Empirical Knowledge (Pseudo Code)  
 
 
 28
  <owl:Class rdf:ID="Empirical_Knowledge_Concept_A"> 
    <rdfs:subClassOf> 
      <owl:Class rdf:ID="Empirical_Knowledge_Concept_B"/> 
    </rdfs:subClassOf> 
  </owl:Class> 
  <Empirical_Knowledge_Concept_A rdf:ID=" Company_a"/> 
  <Empirical_Knowledge_Concept_B rdf:ID=" Enterprise_a "/> 
  <Empirical_Knowledge_Concept_D rdf:ID="Subsidiary_1"> 
    <Part_of> 
      <Empirical_Knowledge_Concept_E rdf:ID="Sub-conglomerate_1"/> 
    </Part_of> 
  </Empirical_Knowledge_Concept_D> 
  <Empirical_Knowledge_Concept_I rdf:ID="Subsidiary_5"> 
    <Caused_by> 
      <Empirical_Knowledge_Concept_H rdf:ID="Subsidiary_4"> 
        <Cause rdf:resource="#Subsidiary_5"/> 
      </Empirical_Knowledge_Concept_H> 
    </Caused_by> 
  </Empirical_Knowledge_Concept_I> 
  <Empirical_Knowledge_Concept_N rdf:ID=" Stability"> 
    <Cooperate_with> 
      <Empirical_Knowledge_Concept_O rdf:ID="Profitability"> 
        <Cooperate_with rdf:resource="# Stability "/> 
      </Empirical_Knowledge_Concept_O> 
    </Cooperate_with> 
  </Empirical_Knowledge_Concept_N> 
Figure 17. Portion of OWL-based Financial Diagnosis Empirical Knowledge Ontology (Empirical Knowledge 
Concept and Relationship)  
 
  <owl:Class rdf:ID="Empirical_Knowledge_Concept"> 
    <rdfs:subClassOf> 
      <owl:Restriction> 
        <owl:onProperty> 
          <owl:DatatypeProperty rdf:ID="AppeareanceReason"/> 
        </owl:onProperty> 
 <owl:minCardinality rdf:datatype="http://www.w3.org/2001/XMLSchema#int" 
        >1</owl:minCardinality> 
      </owl:Restriction> 
    </rdfs:subClassOf> 
    <rdfs:subClassOf> 
      <owl:Restriction> 
 30
Table 5. OWL-based Financial Diagnosis Empirical Knowledge Reasoning Contents 
(Know-Why Layer)  
Financial D
iagnosis Em
pirical K
now
ledge  
before R
easoning 
  <owl:TransitiveProperty rdf:about="#Cause"> 
    <rdfs:domain rdf:resource="#G"/> 
    <rdf:type rdf:resource="http://www.w3.org/2002/07/ 
     owl#ObjectProperty"/> 
    <rdfs:range rdf:resource="#H"/> 
  </owl:TransitiveProperty> 
  <owl:TransitiveProperty rdf:about="#Cause"> 
    <rdfs:domain rdf:resource="#H"/> 
    <rdf:type rdf:resource="http://www.w3.org/2002/07/ 
     owl#ObjectProperty"/> 
    <owl:inverseOf rdf:resource="#Caused_by"/> 
    <rdfs:range rdf:resource="#I"/> 
  </owl:TransitiveProperty> 
  <G rdf:ID="Subsidiary_3"> 
    <Cause rdf:resource="#Subsidiary_4"/> 
  </G> 
  <H rdf:ID="Subsidiary_4"> 
    <Cause rdf:resource="#Subsidiary_5"/> 
  </H> 
R
easoning 
R
ules U
sed 
(1) (?Cause rdf:type owl:TransitiveProperty)∧(?G ? Cause ?H)∧
(?H ? Cause ?I) ⇒ (?G ? Cause ?I) 
(2) Cause ≡ Caused_by -1 (inverse) 
(3) (?Cause owl:inverseOf ? Caused_by)∧(?H ? Cause ?I)  
    ⇒ (?I ? Caused_by ?H) 
Financial D
iagnosis Em
pirical K
now
ledge 
after R
easoning 
  <G rdf:ID="Subsidiary_3"> 
    <Cause rdf:resource="#Subsidiary_5"/> 
  </G> 
  <I rdf:ID="Subsidiary_5"> 
    <Caused_by> 
      <H rdf:ID="Subsidiary_4"> 
    </Caused_by> 
  </I> 
<H rdf:ID="Subsidiary_4"> 
    <Caused_by> 
     <G rdf:ID="Subsidiary_3"> 
</Caused_by> 
  </H> 
  <I rdf:ID="Subsidiary_5"> 
    <Caused_by> 
  <G rdf:ID="Subsidiary_3"> 
  </Caused_by> 
</I> 
 
 32
Table 6. OWL-based Financial Diagnosis Empirical Knowledge Reasoning Contents between the Know-What 
Layer and Know-Why Layer  
Financial D
iagnosis Em
pirical K
now
ledge before R
easoning 
  <owl:Class rdf:ID="X"> 
    <rdfs:subClassOf> 
      <owl:Class rdf:ID="Y"/> 
    </rdfs:subClassOf> 
  </owl:Class> 
  <owl:Class rdf:about="#Y"> 
    <rdfs:subClassOf> 
      <owl:Class rdf:ID="Z"/> 
    </rdfs:subClassOf> 
  </owl:Class> 
  <owl:TransitiveProperty rdf:ID="Cause"> 
    <rdfs:range rdf:resource="#Y"/> 
    <rdf:type rdf:resource="owl#ObjectProperty"/> 
    <rdfs:domain rdf:resource="#X"/> 
  </owl:TransitiveProperty> 
  <owl:TransitiveProperty rdf:ID="Part_of"> 
    <rdf:type rdf:resource="owl#ObjectProperty"/> 
    <rdfs:range rdf:resource="#Z"/> 
    <rdfs:domain rdf:resource="#Y"/> 
  </owl:TransitiveProperty> 
  <Z rdf:ID=" Financial_Abnormal_of_ Sub-conglomerate_2"> 
<Y rdf:ID=" Financial_Abnormal_of_Subsidiary_2"/> 
  <X rdf:ID=" Financial_Abnormal_of_Subsidiary_3"/> 
R
easoning 
R
ules U
sed 
   X ⊆ ∃ Cause.Y∧Y ⊆  ∃  part-of . Z ⇒ X ⊆ ∃ Cause. Z 
Financial D
iagnosis Em
pirical 
K
now
ledge after R
easoning 
  <owl:Class rdf:ID="X"> 
    <rdfs:subClassOf> 
      <owl:Class rdf:ID="Z"/> 
    </rdfs:subClassOf> 
  </owl:Class> 
  <Z rdf:ID=" Financial_Abnormal_of_ Sub-conglomerate_2"/> 
<X rdf:ID=" Financial_Abnormal_of_Subsidiary_3"/> 
< Cause rdf:resource="# Financial_Abnormal_of_ 
Sub-conglomerate_2"/> 
  </X> 
 
 
 
 34
 
Figure 24. Financial Diagnosis Empirical Knowledge after Reasoning (Know-What Layer) 
 
 
 2
三、攜回資料 
‧IEEE ICCSIT 2010 Conference Digest 一本 
‧IEEE ICCSIT 2010 Proceeding CD 一片 
 
 
國科會補助專題研究計畫成果報告自評表 
請就研究內容與原計畫相符程度、達成預期目標情況、研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）、是否適
合在學術期刊發表或申請專利、主要發現或其他有關價值等，作一綜合評估。
1. 請就研究內容與原計畫相符程度、達成預期目標情況作一綜合評估 
■達成目標 
□未達成目標（請說明，以 100字為限） 
□實驗失敗 
□因故實驗中斷 
□其他原因 
說明： 
2. 研究成果在學術期刊發表或申請專利等情形： 
論文：■已發表 □未發表之文稿 □撰寫中 □無 
專利：□已獲得 □申請中 ■無 
技轉：□已技轉 □洽談中 ■無 
其他：（以 100字為限） 
3. 請依學術成就、技術創新、社會影響等方面，評估研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）（以
500字為限） 
本研究之目地為發展一「本體論為基之經驗知識表達與推理方法」，針對經驗知識予以結
構化的表達模式，有效地表達經驗知識，以協助知識需求者明確地了解經驗知識，並使其
能夠有效的再利用及分享，進而幫助未來問題解決及決策制定。本研究之具體成果包含：
(1)本體論為基之多層次經驗知識表達模式，(2)本體論為基之經驗知識概念基模，(3)OWL
為基之經驗知識本體，(3)本體論為基之單層次經驗知識推理規則以及(4)本體論為基之跨
層次經驗知識推理規則。 
本研究透過上述之研究成果，藉由經驗知識表達與推論的方法，使經驗知識能夠有效地分
類及塑模，並有效地分享與再利用，以利於經驗知識的儲存與管理，進而提供知識需求者
正確且完整的知識分享與決策支援，增加經驗知識管理的效率，以期創造更高的知識價值。
 
