 2
壹、 計畫緣由與目的 
 
Semantic Web 是一個近幾年來常被討論的互聯網架構。它的底層是 XML 的文件。XML
在可見的未來應是大家可以接受的一個標準。在這個 syntactic layer 的上層則用 RDF 來表示
文件間的關聯，並在其上用 ontology 的概念建立一個 domain 中整體知識的結構。再往上的抽
象層次的邏輯及 verification 則尚未有全面性的規劃。 
本研究目的亦是希望探討互聯網中內容使用的問題，但我們用一個不同的切入方式。
Semantic Web 是用由下往上的方式一層一層往上建構，我們則思考可否用一個邏輯程式語言
（logic programming language）直接貫穿整個結構，換句話說，直接在 XML 上用一個可以用
來做 specification 也可以做 reasoning 的語言來得到 Semantic Web 想要捕捉的效果。 
為了這個目的我們設計了一個基於 Horn logic 的程式語言叫 Path Inference Language 
(PIL)。我們沒有直接用邏輯程式語言如 Prolog，因為我們需要一個更便利的方法來直接管理
XML 語法中的樹狀結構。如同其他的邏輯程式語言一樣，PIL 的程式易寫易懂，使用者可以
用 PIL 的程式擷取 XML 中的資料，也可以用來 specify ontology。因為 PIL 和 Prolog 一樣，
本身就是用 unification 與 resolution 做為基本的運算 engine，所以當然可以用來做 verification。
既然是基於 Horn logic，所以亦有 question-answering 的功能。我們覺得 PIL 大體上可以做到
Semantic Web 所想達到的效果，當然如要做到一個完整、可用、且有效率的系統尚需相當的
工作。 
在第二章我們會對 PIL 做一較清楚的介紹。在本計畫中我們考慮的另外一個主要的問題
是搜尋時候的模糊性。我們覺得在網路上搜尋的 fuzziness 是內在且無法避免的。譬如說”類
似” (Similarity) 就是一個不可能不模糊的觀念。但是我們覺得一般來說網路上所做的模糊搜
尋的研究並沒有考慮到一些問題，譬如：相似度在 transitivity 下的遞減性。我們覺得一個比
較少被提及的邏輯：Goguen fuzzy logic 反而較適合被使用在網路上的模糊搜尋引擎（fuzzy 
search engine）上。事實上，Goguen logic 的一個 subset：Goguen style fuzzy Horn logic，就夠
用了。而且這個邏輯也可以很自然的與 PIL 結合。所以在第三章中，我們報告一些這方面的
結果。  
 
貳、A Reasoning Framework for Heterogeneous XML 
 
XML is designed to structure data for exchange. It is also a new trend to use XML to encode 
knowledge on the Web. An important project for this purpose is the Semantic Web of W3C. They 
proposed several specifications, including RDF/RDFS and OWL, for knowledge representation. In 
the architecture of SW, they proposed XML for the syntax layer, RDF/RDFS for the semantics 
layer, and OWL for the ontology layer. However, languages for the logic layer and proof layer are 
not yet defined.  
We propose a different approach for knowledge representation and reasoning in this paper. We 
define a logic-based framework to transform XML documents into logical facts, and to reason about 
data, but have different names. 
2. Different locations: In <private> the ID number is recorded as an attribute of <private>, but in 
<person> the ID number is recorded in a sub-tag. 
3. Different languages: Yuh-Pyng Shieh and  are the names of the same person (the first 
author), but is in English and the other in Chinese. 
4. Different structures: The tags <name> in <private> and <name> in <person> have different 
structure. The latter splits a name to first and last. 
5. Different semantics: The meaning of <father> in <private> and <father> in <person> are very 
different. The former is the name of the person’s father, while the latter is the father’s ID 
number. 
The last problem mentioned above the most serious.  A simple minded solution is to require that 
all tags have the same meaning. A more reasonable one is to design a mechanism to transform 
documents of one type into other types. 
Several projects were initiated to unify XML tags using ontology. The most well known is the 
Semantic Web project [1,2] of W3C. The SW working group of W3C proposed a series of 
languages including XML, XPATH, XSLT, RDF, RDFS and OWL. XML is used to encode data on 
the Web in a standard markup format. XPATH is to locate nodes in XML documents. XSL is for 
showing the same XML document in different presentational styles. RDF is used to encode XML 
documents in standard object-oriented format for machine to read and write. RDFS is used to 
encode the meaning of XML tags. And OWL is for representing ontology in XML format. More 
specifically, RDF contains a set of standard tags used to describe data as objects, and RDFS 
contains a set of tags to describe the meanings of user-defined tags. OWL is a language evolved 
from OIL and DAML, and contains a set of tags such as "subClassOf" and "onProperty" to define 
the simple set-theoretic semantics of the ontology. Those who want to understand the relationship 
among these languages can read the tutorial paper of Decker et al [3]. 
 
Figure 2. The specification stack of SW [7] 
 
Figure 2 shows the specification stack of the Semantic Web project. In SW, XML is a language 
for the syntax layer; RDF/RDFS are languages for the semantic layer; and DAML, OIL and OWL 
 4
XML filesXML files
XML files
Type A
XML filesXML files
XML files
Type B
Reasoning Engine
Semantic
Facts
Common
Ontology
Semantic
Facts
Query Answer
Semantics
Extractor for
Type B
Semantics
Extractor for
Type A
Path Inference Langugae
 
Figure 4. The architecture of our logic-based framework 
 
Figure 4 shows the architecture of our proposed framework. The framework contains the 
following parts, a set of XML documents of several different types, a set of semantic extractors in 
PIL, a common ontology in PIL, and a reasoning engine. In the architecture of Figure 4, logical 
facts are extracted from XML documents via a semantic extractor, and then a reasoning process 
based on the extracted logical facts and the common ontology is used to answer questions by 
reasoning. 
In order to illustrate our approach, the following XML document about the customer "Peter" is 
used as an example. 
 
<customer name="Peter"> 
<tel>886-2-23445267</tel> 
</customer> 
 
A semantic extractor contains a set of extraction rules. An extraction rule is a rule in the 
following form. 
 
Matching Part => Transformation Part 
 
The matching part and transformation part here are both logical expressions with the extension of 
operator ".". The operator "." is an object-oriented extension to the logical expression to access the 
members of the object. The following example shows an extraction rule to extract the value of tag 
<telephone> in the block enclosed by the "customer" tag, and then to transform it into logical facts 
 6
semantic extractors for each type of XML documents.  
 
customer(P).tel(T#V) => person(P).telephone(#V)
<customer name=“Peter”>
<tel>886-2-23445267</tel>
</customer>
person($387).telephone(#”886-2-23445267”)
$387
person($387).nation(#”Taiwan”)
person(P).nation(#”Taiwan”) :- person(P).telephone(#V) & fetch(#V, “886[0-9|-]*”)
Semantic 
Extractor
Ontology
Reasoning
Extraction
  
Figure 5. An example of dataflow for reasoning on XML 
 
In Figure 5, we use one ontology and one type of XML documents to show the dataflow of our 
framework. The same condition holds on different types of XML documents. An XML document 
about a customer of Citibank named "Peter" is used as the input source. The node with "customer" 
tag in XML documents is assigned with a unique address "$387". A rule "customer(P).tel(T#V) => 
person(P).telephone(#V)" is used to locate the related nodes in the document and to transform a 
found one into the logical fact person($387).telephone(#"886-2-23445267"). This fact can be used 
in the reasoning process. The rule person(P).nation(#"Taiwan"):-person(P).telephone(#V) & 
fetch(#V, "886[0-9|-]*") in the common ontology is used to reason with the logical fact. The 
function "fetch" is an embedded function to match string, where "886[0-9|-]*" is a regular 
expression. In the reasoning process, the variable "P" is bound to "$387" and the variable "V" is 
bound to "886-2-23445267". Finally, the conclusion person($387).nation(#"Taiwan") is reached 
from the reasoning. 
3.THE PATH INFERENCE LANGUAGE 
In this chapter, we talk about the Path Inference Language (PIL). The syntax, denotational 
semantics and operational semantics will be discussed in detail. PIL is not only used to be a 
language to write extraction rules, but also a language to write ontologies. 
 8
universe of a model M where N={na0,na1,…,na23}, E={(na0,na3), (na0,na6), (na0,na7), 
(na0,na21),…}, L={person, name, first_name, last_name, telephone, nation_code, area_code, 
number, extension, security, university}, and D={“A128825252”, “Jieh Hsiang”, “Jieh”, 
“Hsiang”,…}. 
 
first_name
"Jieh"
na9
name
"Jieh Hsiang"
 10
person
na1
"L112481632"
name
"Yuh-Pyng Shieh"
na4
first_name
"Yuh-Pyng"
na11
last_name
"Shieh"
na12
telephone
"886-2-23625336-303"
na7
nation_code
"886"
na15
area_code
"2"
na16
number
"23625336"
na17
extension
"303"
na18
telephone
"886-968-229549"
na5
area_code
"968"
na13
number
"229549"
na14
person
"N123939889"
na2
name
"Chung-Chen Chen"
na8
first_name
"Chung-Chen"
na19
last_name
"Chen"
na20
university
"NTU"
na6
person
"A128825252"
na0
na3security
"A128825252"
last_name
"Hsiang"
na21 na10
security
"L112481632"
na22
security
"N123939889"
na23
 
Figure 7. A graph model of some PIL program 
 
In Figure 7, each node has a unique identifier called node address. For example, na0, na1, … and 
na23 are node addresses. Each node is associated with a label and a datum of some basic data type. 
For example, the node na6 is labeled by “university” and associated with a datum “NTU”.  Each 
label “s” represents two sets. One is the set of nodes labeled by s. The other is the set of data 
associated with the nodes labeled by s. For example, the label “last_name” represents a set of nodes 
{na10, na12, na19} and a set of data {“Hsiang”, “Shieh”, “Chen”}. Since a label can represent two 
sets, each label can also be taken as two predicates. One is a node predicate with a node argument, 
and the other is a datum predicate with a datum argument. For example, last_name(na10) and 
last_name(“Hsiang”) will be evaluated to be true and last_name(na0) or last_name(“Liu”) will be 
evaluated to be false. In order to distinguish between these two predicates, we put a “#” symbol 
 12
na1.name(na4).first_name(#”Yuh-Pyng”). 
                               
na4.last_name(#”Shieh”). 
              na1.telephone(na5).na15. 
                                       
na5.areacode(#”968”). 
                                       
na5.number(#”229549”). 
              na1.na7. 
person(na2).security(#”N123939889”). 
              na2.na6. 
              na2.na7. 
              
na2.name(na8).first_name(#”Chung-Chen”). 
                               
na8.last_name(#“Chen”). 
X#(Concatenation(Y,Z)) :- 
name(X).first_name(#Y), X.last_name(#Z). 
X#(Concatenation(Y,”-“,Z,”-“,N,”-“,E)) :- 
telephone(X), X.nation_code(#Y), 
X.area_code(#Z), X.number(#N), 
X.extension(#E). 
X#(Concatenation(Y,”-“,Z,”-“,N)) :- 
telephone(X), X.nation_code(#Y), 
X.area_code(#Z), X.number(#N). 
X#Y :- person(X), X.security(#Y). 
Figure 8. A PIL program 
 
For the formal definition of semantics, see the following definitions. 
 
Denotational Semantics of PIL. Remark that the syntax of a program is constructed by a tuple 
(VN,VD,L,P,F,C). The universe of a model M is a tuple G of (N, E, L, D) where N is a set of nodes, 
E is a binary relation to represent the directed links between nodes, and D is a universe of data. 
Each node in N is labeled by a label in L, and associated by at most one datum in D. A model M 
also has to interpret each symbol, label, predicate or function in VN, VD, L P, F, and C. 
 
1. x∈T, if x∈VD. 
p is k. 
M maps p to be a set pM⊆Dk. And 
M p(t1,t2,t3,…,tk) if (t1M,t2M,t3M,…,tkM) is an 
element of pM. 
9. a. ∈S, if a∈A. 
M a.  if M a. 
10. a0:-a1,a2,a3,…,ak. ∈S, if ai ∈A. 
M a0:-a1,a2,a3,…,ak.  if M a0, or M does not 
satisfy ai for some i. 
11. s1 s2 s3 … sk is a program if si∈S. 
M s1 s2 s3 … sk, if M si for each i. 
Figure  9. The denotational semantics of PIL language 
 
C. Operational Semantics 
We use Prolog as the operational semantics by transforming a PIL program into a Prolog 
program. 
 
1. If x∈VD, then x itself is in Prolog. 
2. If f(t1,t2,t3,…,tk)∈T, then it is already in Prolog 
as long as the function fM is an embedded 
function in Prolog. 
3. For each node symbol n in C or VN, it is 
already a Prolog statement. 
4. If r(n#t), r(n), r(#t), r, n#t, n, #t∈B, we do the 
following. For each r in L, we construct 
predicates r_nt(n,t), r_n(n), r_t(t), r to encode 
r(n#t), r(n), r(#t), and r. Also, we construct 
predicates _nt(n,t), _t(t) to encode n#t and #t. 
we have to encode the relations between these 
predicates in the followings.  
r_nt(n,t):-r_n(n),_nt(n,t). 
r_n(n):-r_nt(n,t). 
_nt(n,t):-r_nt(n,t). 
r_t(t):-r_nt(n,t). 
r:-r(n). 
_t(t):-_nt(n,t). 
_t(t):-r_t(t). 
 14
 16
4.LOGIC BASED ONTOLOGY 
Ontology in our sense is just background knowledge. Seeing Figure 4, a logic-based ontology is 
just a program of PIL encoding background knowledge. An ontology together with logical facts 
extracted from heterogeneous documents can be used to do some reasoning. For example, 
example.pil in last section can be divided into two parts. One part is directly extracted from XML 
documents. The other part can be seen as background knowledge. We put them there as an ontology 
person.pil. We emphasize, however, that an ontology can also include facts. 
 
person.pil
X#(Concatenation(Y,Z)) :- 
name(X).first_name(#Y), 
X.last_name(#Z). 
X#(Concatenation(Y,”-“,Z,”-“,N,”-“,E)) :- 
telephone(X), 
X.nation_code(#Y), X.area_code(#Z), 
X.number(#N), X.extension(#E). 
X#(Concatenation(Y,”-“,Z,”-“,N)) :- 
telephone(X), X.nation_code(#Y), 
X.area_code(#Z), X.number(#N). 
X#Y :- person(X), X.security(#Y). 
WorkingTogether(X,Y) :- 
person(X).telephone(Z), 
person(Y).telephone(Z). 
Figure 11. A logic based ontology 
 
5.SEMANTIC EXTRACTOR FOR XML 
When we want to do reasoning on heterogeneous XML documents, we should first choose a 
suitable ontology about the concerned domain. We then design suitable semantic extractors for each 
type of XML documents. 
Here we take one ontology and one type of XML documents to demonstrate how the semantic 
extractor works. The same condition holds on heterogeneous XML documents. We use the ontology 
person.pil in the Section 4, and the following XML files with a private.dtd to illustrate our point.  
private.dtd 
<?xml version=”1.0”?> 
<!DOCTYPE private[ 
<!ELEMENT private (name,father?,brother?,advisor?,tel+) 
> 
 18
@sex
hsiang_na2
"male"
tel
"02-23625336-303"
hsiang_na4
name
"Jieh Hsiang"
hsiang_na3
@security
"A128825252"
hsiang_na1
@security
"N123939889"
chen_na1
@sex
"male"
chen_na2private
hsiang_na0
name
"Chung-Chen Chen"
chen_na3
tel
"02-23625336-303"
chen_na6
father
"A112358132"
chen_na4
advisor
"Jieh Hsiang"
chen_na5
private
chen_na0
 
Figure 12. The tree structure of XML documents 
 
These rooted trees can also be thought together as a directed graph. So we can use our PIL 
language to ask which atom is true under our directed graph model. For example, 
private(chen_na0).@security(#"N123939889") is true.  
A semantic extractor (".sem" file) indicates that when the extractor matches some property of an 
XML file, the extractor will output some instruction into the ontology. The syntax of a .sem file is a 
set of rules. Each rule is of the form "AS => SS.", where AS is a set of atoms and SS is a set of 
sentences. On the left hand side of =>, the atoms describe the world of XML files, and on the right 
hand side, the sentence describes the world of ontology. On the left hand side, the atoms have its 
own syntax different from the right hand side. See the following sem file as an example. 
 
private.sem
private(X).@security(#Y) => person(X).security(#Y). 
private(X).@sex(#”male”) => male(X).  
private(X).name(Z#Y), fetch(Y,”[[a-zA-Z]*/F] 
[[a-zA-Z]/A][[ ]*]”) =>person(X).name(Z).last_name(#A), 
Z.first_name(#F). 
 
private(X).tel(Z#Y), fetch(Y,”0[[0-9]/A]-[[0-9]*/N]-[[0-9]*/E]”) 
=>person(X).telephone(Z#Y).nation_code(#”886”),  
Z.area_code(#A), Z.number(#N), Z.extension(#E). 
 
private(X).advisor(#Y)=>advisor_of(X,Z):-person(Z).name(#Y).
private(X).father(#Y)=>father_of(X,Z):-person(Z).sercurity(#Y).
Figure 13. A semantic extractor 
 
6.SUMMARY AND DISCUSSION 
In this paper we proposed a logic-based framework for reasoning about XML documents. This 
includes a logic programming language, PIL, for describing ontologies and elements in XML 
documents as logic programs. We also presented a method to write semantic extractors in PIL 
extracting logical facts (also PIL programs) from XML documents, and a method for reasoning 
about these facts using ontologies. We think this framework can be used for integrating 
heterogeneous XML documents into uniform semantic rules, and for reasoning about them.  
Our approach simplifies the specification stack of Semantic Web into just two layers, data and 
knowledge.  XML describes the data. The knowledge part, including the specification of relations, 
ontologies, logic, and proof, can all be handled by PIL. A semantic extractor is the bridge to 
connect data and knowledge. Figure 15 shows the relationship between XML documents, semantic 
extractor and ontology.  
 
XML 
documents Ontology
OntologyXML documents
Semantic
Extractor
Data Knowledge
 
Figure 15. The relationship between data and knowledge 
 
The separation of data and knowledge results in a flexible model. Data creators write XML 
documents as they like without having to follow standard. Knowledge workers may focus on the 
problem of knowledge construction for specific domains. Programmers may build applications by 
write program in PIL to extract logical facts from XML documents into ontology. Different 
programmers may have different ways to extract logical facts from data and put them into different 
ontologies for reasoning. This flexibility provides a good solution for knowledge engineering to 
scale up. 
We now give a brief comparison between our approach and Semantic Web. The SW project was 
built in a bottom-up fashion.  The languages for different layers were proposed incrementally 
(with those for the logic and reasoning layers still in the waiting.)   Because the languages were 
built incrementally, there are heavy in notion and quite restricted. For instance, only binary relations 
can be expressed in RDF, and even OWL can only deal with simple set-theoretic relations. 
In the model of SW, data builders must write documents based on the RDF specifications. Those 
 20
 22
efficient reasoning framework. This research is partially supported by grants 
NSC92-2213-E002-005 and NSC92-2213-E002-084 of the Republic of China. 
 
1 Introduction 
Research in knowledge retrieval has made tremendous stride in recent years, among the most 
notable is the rapid development in ontology, which tries to provide a common understanding of 
concepts in a particular domain and relations between concepts. With the ontologies, the computer 
may try to answer the auser’s questions by reasoning. Ontobroker [4] and TRIPLE [5] are examples 
of such inference engines. 
However, most ontologies are based on the traditional binary logic, with truth values of either 0 
or 1, and lack the ability to represent different degrees of truth. Two of the possible problems are: 
 
1. The intrinsic fuzziness of relations 
Suppose in an ontology Astronomy is relevant to Physics and Astronomy is also relevant to 
Astrology. There is no easy way to indicate that Astronomy is more relevant to Physics than 
it is to Astrology in binary logic. 
2. The degradation of truth degree 
The degree of relatedness of a transitive relation may degrade with the number of transitive 
steps applied. Using the above example to demonstrate, Physics is obviously less relvant to 
Astrology than to Astronomy, even if relevance is transitive. 
It is therefor important to introduce the notion of fuzziness and degradation into ontologies. To 
tackle these problems, we propose a framework based on the Goguen Style Fuzzy Horn Logic [1]. 
Let truth(x) represents the truth degree of a logical statement x, we have 
• truth(α) ∈ [0, 1], 
• truth(α ∧ β) = min{truth(α), truth(β)}, 
• truth(α =⇒ β) = min{1, truth(β)/truth(α)}. 
While the defintion of ∧ is typical in fuzzy logic, there are a number of ways to define 
implication. (See [6] for details.) However, among the ones we have surveyed, only Gugen’s fuzzy 
implication seems to capture the degradation of truth degrees. We remark that Goguen’s paper [1] 
did not provide a way to apply his logic system to knowledge retrieval. Neither is his full logic 
necessary. In this paper, we select a Horn subclass of Goguen’s logic as the underlying logic for 
knowledge retrieval, and shall present its syntax, semantics, as well as two inference methods for 
applying them. Soundness and completeness results will also be outlined. 
2 A Framework for Knowledge Retrieval 
A knowledge retrieval system should at least be able to (1) retrieve and show documents relevant 
to a query, (2) show descriptions (such as definitions, illustration or characteristics) of concepts and 
relations between concepts, (3) answer questions.  
To accomplish these tasks, a knowledge retrieval system should have at least the following 
components: 
• Ontology: The ontology contains experts’ knowledge of the intended domain and is built by 
 24
may be a relation such as parent-child or similar-to. 
• Metadata We regard metadata as a partial function meta : A×D → Data where A ⊆ C is the 
set of attribute names, and Data is the set of all possible metadata values. For example, 
meta(author,KRF) = “Bee − Chung__ means that the author (an attribute) of KRF is 
“Bee-Chung” (a value). 
• Built-in Measures 
An n-ary built-in measurem : Dn → [0, 1] is a machine-computable (partial) function to  
measure a relation among n elements of D. To incorporate the measures into the rest of the 
formalism more naturally, we define a one-to-one function f that maps each built-in m ∈ MB 
to a relation symbol f(m) ∈ R. The set of all f(m), where m ∈ MB is called the set of 
built-in relation symbols and is denoted by RB. The rest of the relation symbols are denoted 
by RL.  
A built-in measure m ∈ MB defines the meaning of a built-in relation f(m) ∈ RB, i.e. the 
truth degree of f(m)(d1, d2, · · · , dn) = a if and only if m(d1, d2, · · · , dn) = a The meaning of 
a relation r ∈ RL is defined by logical sentences in the ontology or the knowledge base. Its 
evaluation also uses the fuzzy truth assingment μ. 
• Fuzzy Truth Assignment The fuzzy truth assignment μ is a function RL × (∪n≥1Dn) → [0, 
1]. We say that the tuple (d1, d2, · · · , dn) ∈ D has the relation r ∈ RL, written as r(d1, 
d2, · · · , dn), with truth degreea ∈ [0, 1]) if and only if μ(r, d1, d2, · · · , dn) = a. 
3.2 The (Informal) Query Model 
In our model, a user can ask the following types of questions: (1)Which elements of D have what 
metadata values. (2)Which elements of D have what relationship. (3) A conjunction of queries of 
the above types. 
The answers to a given query will be listed according to their degrees of truth, from highest to 
lowest. 
4 Goguen Style Fuzzy Horn Logic 
We now formally define the Goguen Style fuzzy Horn logic, the language used to describe 
knowledge in the proposed model. 
4.1 Syntax 
Let Σ, called the vocabulary, be a countable set of symbols over which the ontology language is 
defined. There is also a predefined function symbol, metadata, which is not in Σ. A subset Π of Σ, 
called the set of relation symbols (or predicates), represents the relations between objects. The set 
of variables is denoted by V, where V ∩ Σ = ∅. We use Data to denote the set of all possible 
metadata values. 
A rule has two parts: the premise and the consequence. The set of premises, P(Σ,Π,V) is defined 
as follows.  
• r(c1, · · · , cn) ∈ P(Σ,Π,V) where r ∈ Π  ∪ V and 
ci ∈ Σ  ∪ V for all i. 
• “metadata(v, d) = s” ∈ P(Σ,Π,V), where v, d ∈ Σ  ∪ V and s ∈ Data. 
• If α, β ∈ P(Σ,Π,V), then α ∧ β ∈ P(Σ,Π,V). 
 26
maximal degree of truth of ϕ with respect to Φ (written Maxdeg(Φ, ϕ)) as 
Maxdeg(Φ, ϕ) = max{kjΦ |= [ϕ, k]}, 
where max φ = 0. 
Note that Φ |= [ϕ, k] iff Maxdeg(Φ, ϕ) ≥ k. If ϕ ∈ F(Σ, Π), [ϕ, k] is called a fact assertion. If 
ϕ ∈ A(Σ, Π, V), then [ϕ, k] is called a rule assertion. 
4.3 Properties 
We now list some properties of the proposed fuzzy Horn logic. In the following, α, β, and δ are 
facts, and γ is a unit fact. 
Property 1. Φ  {∪ [α, k]} |= [α, k]. 
Property 2. Φ |= [α, k] iff k ≤min{αI|I satisfies Φ}. 
According to the above property, given a fact α, Maxdeg(Φ, α) is the lower bound of αI, where I 
satisfies Φ. 
Property 3. Φ |= [α ∧ β, k] iff Φ |= [α, k] and Φ |= [β, k]. 
Property 4. Φ {∪ [α∧β, k] |= [δ, k] iff Φ {∪ [α, k], [β, k]} |= [δ, k]. 
Property 5. {α =⇒ γ,m], [α, n]} |= [γ, k] iff {[γ,m × n], [α, n]} |= [γ, k]. 
We say that a set Φ entails a set Ψ of fuzzy assertions (written as Φ |= Ψiff Φ entails at least one 
member of Ψ. 
Property 6. Φ  {∪ [α =⇒ γ,m]} |= [γ, k] iff Φ |= {[γ, k], [α, k/m]}. 
4.4 Reasoning Methods 
Given a finite set Φ of assertions and a ground fact α, one can always generate a finite set of 
ground assertions Φg such that Φg |= [α, k] iff Φ |= [α, k] This can be done imply by taking all the 
ground instances of Φ. Thus in this section we assume that Φ is ground. 
We give two reasoning methods in this section, forward and backward reasoning. Forward 
reasoning generates facts from known ones, and backward reasoning works on the query. Obviously, 
forward reasoning can/should be done prior to the issuing of queries by the user, while backward 
reasoning can is mainly performed during run time (unless some mechanism for predicting queries 
is available). 
Backward Reasoning. Given a finite set Φ of ground assertions and a fact β, Φ |= [β, k] if and 
only if 
• β is β1β2, Φ |= [β1, k] and Φ |= [β2, k], or 
• there exists an [α,m] ∈ Φ such that β is a part of α 
and m ≥ k, or 
• there exists an [α =⇒ β,m] ∈ Φ such that Φ − 
{[α =⇒ β,m]} |= {[β, k], [α, k/m]}. 
Note that to decide whether Φ entails [β, k] is equivalent to applying steps (1) – (3) recursively. It 
is easy to see that this process must terminate. Optimization of this process will be left for the 
 28
Fuzzy Horn Logic. It is composed of a set of acquired facts, which are knowledge acquired by the 
knowledge acquisition agents, and a set of user’s rules, which are a user’s personal rules for 
personalization purposes. 
Inference Engine. The job of the inference engine is to answer users’ queries based on facts and 
rules in the ontology and the knowledge base. The inference mechanism is as follows. 
1. Generate an initial KB (KBinit), which contains: 
• knowledge provided by the built-in measures MB. That is, for any m ∈ MB, if m(d1 , 
d2 ,..., dn) = k, then [f (m)(d1 , d2 ,..., dn), k] ∈ KBinit, where d1 , d2 ,..., dn ∈ D, and f 
is the function that maps each built-in measure m to a relation symbol, and 
• knowledge provided by the metadata meta. That is, if meta(v, d) = s, then [metadata(v, d) 
= s, 1] ∈ KBinit, where v ∈ C, d ∈ D, and s ∈ Data of all possible metadata, and 
• all ontological facts (in the ontology), and 
• all forward rules (in the ontology), and 
• all acquired facts (in the knowledge base). 
2. Generate the forward-closure KB (KBfc) by applying the forward reasoning method to the 
initial KB, i.e. KBfc = (KBinit)∗. 
3. Form the online KB, which is composed of the forward-closure KB, the backward rules (in 
the ontology), and the user’s rules (in the knowledge base). 
i.e. KBonline = (KBinit)∗  ∪ (the set of backward 
rules)  ∪ (the set of user’s rules) 
4. When the inference engine receives a query, it applies the backward reasoning method to the 
online KB (KBonline). 
Note that, steps 1, 2, and 3 are done prior to all users’ queries. When receiving user’s query, the 
inference engine applies backward reasoning only. 
6 Conclusion 
In this paper we introduced a formal model of knowledge retrieval which seems applicable to 
most retrieval needs. In order to solve the inherent fuzziness that occurs in many domains, we 
proposed a fuzzy Horn logic based on Goguen’s implication logic. We also presented a reasoning 
framework, which incorporated both forward and backward reasoning. We are in the process of 
implementing a retrieval system based on the proposed framework. 
References 
[1] J. A. Goguen. The Logic of Inexact Concepts. Synthese, Vol. 19, 1969. 
[2] Tim Berners-Lee. Semantic Web Roadmap. World Wide Web Consortium (W3C), 1998. 
(http://www.w3c.org/DesignIssues/Semantic.html) 
[3] Stefan Decker, Sergey Melnik, Frank Van Harmelen, Dieter Fensel, Michel Klein, Jeen 
Broekstra, Michael Erdmann, Ian Horrocks. The Semantic Web: The Roles of XML and RDF. 
IEEE Internet Computing, 2000. 
[4] Dieter Fensel, J¨urgen Angele, Stefan Decker, Michael Erdmann, Hans-Peter Schnurr, Steffen 
Staab, Rudi Studer. On2broker: Semantic-based access to information sources at the WWW. 
World Conference on the WWW and Internet (WebNet 99). 1999. 
行政院國家科學委員會補助國內專家學者出席國際學術會議報告 
                                                           95  年 11  月 20  日 
報告人姓名 
 
項潔 
 
服務機構
及職稱 
 
國立台灣大學資訊工程學系教授 
 
     時間 
會議 
     地點 
(12)13-17 November 
2006 
 
Phnom Penh,Cambodia 
本會核定
補助文號
NSC 94-2213-E-002-011 
會議 
名稱 
 (中文) 
 (英文)13th International Conference on  
Logic for Programming,  
Artificial Intelligence ,and Reasoning. 
發表 
論文 
題目 
 (中文) 
 (英文)Boolean Rings for Intersection-Based Satisfiability. 
 
LPAR 2006 
13th International Conference on Logic for Programming, Artificial Intelligence , and Reasoning. 
http://www.lix.polytechnique.fr/~hermann/LPAR2006/
 
 
1 
1 
壹、 前言 
 
本報告敘述參加 2006 年 LPAR（Logic for Programming, Artificial Intelligence and 
Reasoning）會議的經過。 
LPAR 是一個每年一次的會議，一開始（1990-1994）主要是 Logic Programming 方面的研
討會，後來漸漸轉型成現在包括數理、邏輯、自動推論、人工智慧邏輯、程式語言邏輯等領
域的研討會。因為這些領域的研究者以歐洲為主，所以每年會議幾乎由歐洲的學者規劃，參
與的也以歐洲人為多。邏輯方面的會議上多強調自己的獨立性，不與各種學會合辦，LPAR
也不例外。而會議論文集則由 Springer 的 Lecture Notes in Computer Science 出版。 
本年會議在東普寨首都金邊市舉行，時間是 2006 年 11 月 12 日至 11 月 17 日，包括 2 個
工作坊、48 篇論文及兩個 invited talks。參加人數 100 多人，大多來自歐美（歐洲大部份國家
均有學者參加），亞洲除台灣外，亦有來自印度、日本、越南的學者。大陸則無人來參加。 
以下說明會議的歷史，本次會議的流程，及 present 的論文。 
 
貳、 參加會議經過 
 
日期 起訖地點 工作記要 
95/11/12 台北-金邊 抵達金邊/參加 Workshops 
95/11/13-16 金邊 參加 LPAR 會議 
95/11/17 金邊-台北 參加 LPAR 會議/返程 
 
參、LPAR（Logic for Programming, Artificial Intelligence and Reasoning）及其
會議簡介 
 
一、 What’s LPAR 
 
There are several definitions of LPAR: 
LPAR is an acronym for Logic for Programming, Artificial intelligence and Reasoning.  
LPAR is the string "(" representing the left parenthesis in some dialects of LISP.  
LPAR is a series of conferences intended to bring Computer Science Logic to all parts of 
this large world.  
3 
LPAR 2003: 10th International Conference on Logic for Programming, Artificial 
Intelligence, and Reasoning, Almaty, Kazakhstan.  
LPAR 2004: 11th International Conference on Logic for Programming, Artificial 
Intelligence, and Reasoning Montevideo, Uruguay  
LPAR 2005: 12th International Conference on Logic for Programming, Artificial 
Intelligence, and Reasoning Montego Bay, Jamaica 
 
三、 LPAR 2006 
 
LPAR 2006 was held in Phnom Penh, Cambodia,(12)13-17 November 2006. 
Topics of interest include: 
• automated reasoning  
• interactive theorem proving  
• software verification  
• software testing  
• proof assistants  
• proof planning  
• proof checking  
• rewriting and unification  
• logic programming  
• modal and temporal logics  
• systems specification and synthesis  
• model checking  
• proof-carrying code  
• logic and databases  
• reasoning for the semantic web  
• propositional reasoning  
• description logics  
• hardware verification  
• logic and ontologies  
• network and protocol verification  
• nonmonotonic reasoning  
• constructive logic and type theory  
• lambda and combinatory calculi  
• knowledge representation and reasoning  
• constraint programming  
• logical foundations of programming  
• computational interpretations of logic  
• logic and computational complexity  
• logic in artificial intelligence  
• reasoning about actions  
     
四、 Next LPAR(s) 
 
      LPAR 2007 will be held in Tashkent, Uzbekistan, 2007. 
 
肆、會議議程 
 
   13th International Conference on Logic for Programming, Artificial Intelligence ,and Reasoning.
於 2006 年 11 月 12 日至 17 日在金邊舉辦。會議內容包含二個工作坊、二個 Invited Lectures、
三十七篇長篇 papers、11 篇短篇 papers。 
    11 月 12 日至 11 月 17 日為期六天的詳細議程如下： 
5 
    Frédéric Blanqui and Colin Riba 
  17 : 00  -  18 : 00 Presentation of short papers 
 
 
Tuesday, 14 November  
 
  9 : 00  -  10 : 00 Invited Lecture: Disjunctive Logic Programming for Knowledge Representation and Reasoning
    Nicola Leone 
  10 : 00  -  10 : 30 On a Local-Step Cut-Elimination Procedure for the Intuitionistic Sequent Calculus 
    Kentaro Kikuchi 
  10 : 30  -  11 : 00 Coffee Break 
  11 : 00  -  11 : 30 Modular Cut-Elimination: Finding Proofs or Counterexamples 
    Agata Ciabattoni and Kazushige Terui 
  11 : 30  -  12 : 00 A Semantic Completeness Proof for Tableaux Modulo 
    Richard Bonichon and Olivier Hermant 
  12 : 00  -  12 : 30 Saturation up to Redundancy for Tableau and Sequent Calculi 
    Martin Giese 
  12 : 30  -  14 : 00 Lunch 
  14 : 00  -  14 : 30 Branching Time Temporal Logic Extended with Presburger Constraints 
    Régis Gascon and Laura Bozzelli 
  14 : 30  -  15 : 00 Combining Supervaluation and Degree Based Reasoning under Vagueness 
    Christian Fermüller and Robert Kosik 
  15 : 00  -  15 : 30 A Comparison of Techniques for Querying Large Description Logic ABoxes 
    Boris Motik and Ulrike Sattler 
  15 : 30  -  16 : 00 A Local System for Intuitionistic Logic 
    Alwen Tiu 
  16 : 00  -  16 : 30 Coffee Break 
  16 : 30  -  17 : 00 Reducing Nondeterminism in the Calculus of Structures 
    Ozan Kahramanogullari 
  17 : 00  -  17 : 30 A Relaxed Approach to Integrity and Inconsistency in Databases 
    Hendrik Decker and Davide Martinenghi 
  17 : 30  -  18 : 00 Automata for Positive Core XPath Queries on Compressed Documents 
    Barbara Fila and Siva Anantharaman 
