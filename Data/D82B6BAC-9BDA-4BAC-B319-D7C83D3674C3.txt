 2 
可供推廣之研發成果資料表 
■ 可申請專利  ■ 可技術移轉                                      日期： 年 月 日 
國科會補助計畫 
計畫名稱：利用擴散理論、語義網絡與時序分析為基礎之機器學習
法建立人類活動與環境變遷間之分析模擬模型 (2/3) 
計畫主持人：蔣以仁 
計畫編號：NSC 98－2221－E－038－006 學門領域：資訊二 
技術/創作名稱 即時動態文件資訊分群 
發明人/創作人 蔣以仁 
技術說明 
中文：我們的研究成果中，關鍵特徵的擷取能更正確且具獨特性，是建立因語
義而結合，探討動態性隨時而變之 Ontology規律最重要的起始歨驟，利用機器
學習結合諸如辭典之專家知識以建立屬特殊領域數位內容為目標之關鍵資訊萃
取方法，我們以統計機率演算法，並藉助專業詞庫（ Dictionary或 Lexicon）及
字詞特性，發展 Conditional Random Field模式，成為 Knowledge-Based 
Probabilistic Extracting法則，以形成各特殊領域從專業文件中萃取重要之詞彙；
為求能確實掌握其中文義涵意，以作為後續同質分類分群，建立推論 Ontology。 
英文：This research has taken scientific dataset and related articles as subject, 
especially the ecology domain, implementing “automatic feature extraction” and 
“scoring” model for automatically constructing the taxonomical and decision 
supporting ontology.  The conditional random fields (CRFs) have taken to extract 
the significant features, i.e., named entities, in a document.  Afterwards, invited 
experts will evaluate the efficiency of the system with personal diagnosis and 
feedback the results to the system. With the computer learning technology, the 
process of constructing the ontology, especially for decision making, will be 
modified. 
可利用之產業 
及 
可開發之產品 
1. 圖書及檔案資訊：進行知識地圖建構，以協助檔案管理機構、
及圖資系統公司，作相似議題與內容的分類歸納。 
2. 科技性或其他各類文獻：已提供建立國衛院實證醫學網站
(ebpg.nhri.gov.tw)實證資料檢索，協助醫護人員正確找到所
需的資料。 
技術特點 
1. 機器學習法進行詞彙選取，可使適應於各專業領域，並隨資料
累積，而使系統之準確性更加提升。 
2. 能結合特定領域專家知識，進行加權，萃取符合這領域之關鍵
詞彙。 
3. 協助能達到語義上之詞彙歸納與分群分類。 
4. 可不斷增加新詞彙的累積。 
推廣及運用的價值 
改善一般資料檢索方式，使能更準確掌握語意上的意義與實質內容
特性。可運用於資料檢索、群聚分析等服務。可與資訊檢索作有效
整合。 
※ 1.每項研發成果請填寫一式二份，一份隨成果報告送繳本會，一份送 貴單
位研發成果推廣單位（如技術移轉中心）。 
※ 2.本項研發成果若尚未申請專利，請勿揭露可申請專利之主要內容。 
※ 3.本表若不敷使用，請自行影印使用。 
 4 
Entity Extractions, Graph Theory 
 
二、Introduction and Background 
 
Nowadays, as the rapid growth of huge 
repositories including data, texts, medias, and 
so forth, on the World Wide Wed (WWW) 
have become available to public, search 
engines are almost the only tool attempted to 
aid users in gathering relevant contents from 
the Web based on users' requests from the 
human-machine interaction.  The amount of 
scientific information continues to increase 
as the number of electronic journals on the 
internet [1].  To benefit scientists from 
accessing all the large and growing 
disseminate scientific literatures or other 
information sources within seconds relys on 
Web search engines [2].  Web search 
engines extend the information retrieval and 
literature search techniques originally 
dominated by librarians and other search 
specialists to all kinds of scientists that 
eliminate the barrier of techniques for web 
users.  Novices are easy to perform searches 
on the Web to access heterogenous 
information without needing any preliminary 
skills. 
Lawrence et al. [2] and Henzinger [3] 
surveyed and compared some search engines, 
such as AltaVista, Excite, HotBot, Infoseek, 
Lycos, Northern Light, and Google. Both of 
them exhibited the weakness of web search 
engines and proposed some soultion on it.  
Ignoring the problems of the design of the 
infrastructure needed to support large-scale 
search engines [4,5], the limitation of the 
coverage of information on the World Wide 
Wed (WWW) is widely accessible to search 
engines [6], and the prohibition of a large 
fraction of the so called ``deep Web'' 
database accessible to search engines [7], this 
article concentrates on the information 
retrieval aspects of searching to describe this 
challenge on determining the most relevant 
search results and solutions on the search 
results. It is crucial for the 
comprehensiveness of a search engine if the 
search engine evolves a sophisticated 
mechanism able to recognize the latent 
semantics in the returned search results.  
Along with the comprehensiveness of the 
search engines, the ranking of the returned 
search results that Henzinger [3] mentioned 
can also be solved. 
Search engine often returns inconsistent, 
uninteresting and disorganized results.  On 
the Web, the Web pages are heterogeneous 
and of varying quality that affects.  
Polysemy, synonyms, homonyms, phrases, 
term dependency, and spam bring the 
limitations of search technology that strongly 
decline the comprehensiveness of search 
engines.  In order to understand the terms in 
search queries from users, the critical 
approach is to analyze keyword relations to 
understand their meaning at conceptual level 
- not about what words appear on the page 
but more concern ‘what is this about?’.  
Search engines should be enhanced to 
understand the terms in search queries and 
the contextual meaning of those terms as they 
appear in the returned results to look for 
relevance and quality, rather than just terms 
or links going in or out of the pages, which is 
known as Google PageRank.  It is hard and 
almost impossible to predict the relevance of 
search results to fit user intent.  More 
feasible searched results by categories, 
subjects, and contents are major requisites for 
the design of search engines to allow users to 
choose what documents are relevant to their 
intent. 
In order to more naturally fruitful to 
facilitate and enhance relevant information 
access to analyze huge amount of 
environmental information, a sophisticated 
fundamental models to deal with ambiguity, 
elusiveness, or impreciseness of user requests 
to discover latent semantics in returned 
documents and then to classify those 
documents into some homogeneous semantic 
clusters is essential.  Each semantic cluster 
is considered to be an individual topic that 
indicates an abstract from a subset of 
returned search documents.  According to 
the clusters users are able to identify which 
topics some documents demonstrate are 
relevant to their intent, that is, we wish such 
that a query term “jaguar'” can be classified 
into the “Animal” topic and the 
“Automobile” topic in accord with the 
semantics of the returned documents and 
users are able to further going into their 
 6 
document or documents should follow de 
Finetti (1990) theorem of exchangeability 
that is the order of terms in a documents and 
the specific ordering of the documents in a 
corpus can be neglected.  But if we consider 
the semantics generated from somewhat 
co-occurrence relationships on a limited 
number of terms, the criterion of `”the order 
of terms in a document can be neglected” 
should be modified to be “the order of terms 
in a relationship in a document and the 
specific ordering of relationships in a 
documents can be neglected.” In probability 
theory, the random variables t1, t2, …, tN, i.e., 
terms, are said to exchangeable if the joint 
distribution F(t1, t2, …, tN) is invariant under 
permutation of its arguments, so that F(z1, 
z2, …, zN) = F(t1, t2, …, tN) whenever z1, 
z2, …, zN is a permutation of t1, t2, …, tN. 
  
三、Methods and Results 
  The document space X and the topic 
space C are both formed from two open sets 
X and C that any set in them are close 
through the operations of countable union, 
countable intersection, and complement 
individually.  Both the document space X 
and the topic space C are Borel sets.  
Consider the following algebra properties 
[18]: 
Definition: An algebra on the set X is a 
collection A of subsets of X such that: 
1. X in A; 
2. Whenever A belongs to A so does Ac = X 
- A; i.e., A is closer under 
complementation; and 
3. A is closed under finite unions.  
 
An algebra closed under countable unions 
is called a σ-algebra or sigma-algebra. The 
σ-algebra generated by a topology is called 
the Borel σ-algebra [20] of the topology. 
Obviously the topologies of the document 
space X = (X, τ) and the topic space C 
satisfies the algebra property and both are 
able to equip with distinguished σ-algebras, 
so called Borel spaces. Following 
Kuratowski theorem on Borel spaces, a 
morphism f: X  C is a Borel measurable 
mapping defined on two Borel spaces. This 
property of σ-algebra also defines an axiom 
of choice to generate the bases in B. 
  On the other hand, the document space 
and topic space can produce a product 
topology such that Π = X × C, which is 
countable and finite.  The product topology 
Π is the Cartesian product of X and C, that is 
defined to be the coarsest topology, i.e., the 
topology with the fewest topics.  These two 
topological spaces can be extracted 
individually by a projection.  A discrete 
metric d defined on the product topology Π is 
given as 
1. d(x, y) = 1 if x = y, 
2. d(x, y) = 0 if x≠y; 
for any x, y in Π. For each x in Π, x=(w0, 
w1, …, wN-1, zk) where wi , 0 ≤ i ≤ N - 1 is a 
feature in F(X) and zk denotes a topic in C, 
and a discrete metric d is a metric defined on 
N+1-dimensional space Π.  In order to 
define a discrete metric d for a topological 
space Π, it is essential to use the base set B = 
{b1, b2, b3, … } of X at least because a base 
element bi = {wi1, wi2, …} in B, |bi| ≤ N in B 
is enough to identify a semantic topic zk  in 
C. No bases in any two distinguishable topics 
are the same, otherwise, one topic is said to 
be finer than the others or indistinguishable. 
The product topology Π equipped with a 
discrete metric is called completely 
metrizable that makes the product topology 
Π organize a separable, completely 
metrizable topological space, i.e., a Polish 
space.  Let Γ = Ub in B b in F(X) which is the 
largest set containing all the features of base 
elements in B satisfy the property of 
σ-algebra.  The order-pair (Π, Γ × C) 
therefore organizes a measurable space also 
called σ-field. The latent semantics is 
illustrated in the entangling structure of (Π, Γ
× C).  Accordingly, a Borel measure 
mapping between two Borel spaces is 
defined in this paper for modeling semantics 
in text corpora. The Borel σ -algebra Γ×C of 
the metrizable space Π equals the smallest 
family Borel set of subsets of X ×C that 
contains all categorized open set and that is 
closed under countable intersections and 
countable unions. Figure. 1 illustrates such 
phenomenon. The base B is enough to infer 
 8 
PB(Π|X) = P(B) P(C|X,B,Θ,Λ) P(B) P(W|X, 
B, Σ, β) / P(B) 
   = P(C|X,B,Θ,Λ)P(B)P(W|X,B, Σ, β) 
= P(C|X,B,Θ,Λ)P(W)P(B|X,W,Σ,β). 
Based on B, the conditional probability PB(Π
|X) could be decomposed into two parts: 
P(C|X,B,Θ,Λ) and P(W)P(B|X,W,Σ,β). Each 
topic in C is probabilistically determined by a 
base in B.  This paper ignores to consider 
the probability of dependence among bases, 
i.e., topics, the former part is simplified as: 
P(C|X,B,Θ,Λ) ≈ ∏i=1M P(zi |bi, βi) = ∏i=1M λi 
θi 
Where θi is in Θ is the topic distribution for 
each topic, λi is in Λ denotes the probability 
of a base mapping to a topic and the lower 
case characters with the subscripts represent 
the elements belonging to C and B 
respectively.  The later part P(W) P(B |X, W, 
Σ,β) is obviously derived from all possible 
combinations of the features in W, where the 
parameter Σ denotes the joint probability of 
the occurrence of correlated features. 
 
In order to find the optimal Borel σ-algebra 
for arbitrary set of documents, it is essential 
to maximize the probabilistic measure 
function PB(Π|X).  The log-likelihood of 
PB(Π|X) is as follows. 
l(Θ,β)=ln(P(C|X,B,Θ,Λ)P(W) P(B|X,W,Σ,β))= 
ln(∏i=1M P(zi|bi,θi))+ln(P(W)P(B|X,W, Σ,β)). 
The high dimensional data can form a 
latent semantic model based on the features 
and the internal structures discovered from 
the data. The semantic topics are hidden in 
the model. In order to discover latent 
semantics within a data, the sophisticated 
algorithm is required that can be divided into 
three ad hoc parts: first, to extract the 
features and to construct an undirected and 
connected factor graph based on Markov 
models, i.e., a Markov-based simplicial 
complex, from a document set X; second, to 
decompose the skeleton from the 
Markov-based simplicial complex using 
graph decomposition method with a 
simplex-size to generate topologically 
distinguishable simplexes bound with a 
simplex-size; third, to cluster 
CRFs have a different nature by 
comparing with HMMs. CRFs are 
discriminative model, while at the training 
stage, to maximize the conditional 
probability of observation and state 
sequences. This leads to a great diminution 
of a number of possible combinations 
between the features and their labels. It 
makes possible to represent much additional 
knowledge in CRFs, which can be much 
more expressive than HMM-like models 
because CRFs allow arbitrary dependencies 
on the sequence. In contrast to the HMMs, 
CRFs may not only depend on the feature 
itself but on any feature, which is 
incorporated into the model. In addition, all 
the states or observations are not needed to 
completely specified, that is the model can be 
estimated from less training data. This paper 
selects CRFs to extract the features and build 
a Markov-based simplicial complex. 
Whatever the method is HMMs or CRFs, 
the generated graphical model is represented 
as a factor graph. Graph decomposition 
algorithm has involved to separate the result 
from HMMs or CRFs into several semantic 
simplexes. In order to efficiently identify the 
maximum-likelihood parameters, dynamic 
programming with Viterbi search algorithm 
has been used. The detail calculation has 
been mentioned in [21,22]. Given a training 
dataset, the forward procedure and the 
backward procedure of Viterbi algorithm 
search for the optimal model from a landing 
state. Newton methods are therefore to derive 
an optimal numerical solution for extracting 
features. 
After features and the associated 
relationships have been identi_ed, the next 
step is to decompose the Markov model into 
topological distinguishable simplexes. Each 
simplex is no doubt a complete subgraph, i.e., 
a clique. Therefore, it is no doubt that to find 
all simplexes in the graph is an NP problem. 
It is not necessary to exhaustive search all 
simplexes to illustrate latent semantics, given 
an upper bound n, only need to derive all 
possible maximal simplexes whose 
dimensions are below n. 
 
四、Discussion and Conclusion 
 
Besides the effectiveness, the 
performance of efficiency of three methods, 
LT, LST, and CCF with a number of features 
 10 
Landauer, and R. Harshman. Indexing by latent 
semantic analysis. Journal of the American 
Society for Information Science, 41(6):391-407, 
1990. 
13. G. Karypis and E. H. S. Han, Concept indexing: 
A fast dimensionality reduction algorithm with 
applications to document retrieval and 
categorization. The Weaknesses of Full-Text 
Searching. IN CIKM’00, 2000 
14. T. P. Minka and J. Lafferty. 
Expectation-propagation for the generative aspect 
model. In Proceedings of the 18th Conference on 
Uncertainty in Artificial Intelligence, 352{359, 
2002. 
15. D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent 
dirichlet allocation. Journal of Machine Learning 
Research, 3:993{1022, 2003 D. M. Blei, A. Y. Ng, 
and M. I. Jordan. Latent dirichlet allocation. 
Journal of Machine Learning Research, 
3:993-1022, 2003. 
16. I. J. Chiang. Discover the semantic topology in 
high-dimensional data. Expert Systems with 
Applications, 33(1):256-262, 2007. 
17. J. Garcia-Flores, L. Gillard, O. Ferret, and G. de 
Chalendar. Bag of senses versus bag of words: 
Comparing semantic and lexical approaches on 
sentence extraction. In Proceedings of Text 
Analysis Conference 2008, pages 256-262, 2008. 
18. A. S. Kechris. Classical Descriptive Set Theory. 
Springer-Verlag, New York, NY, 1946. 
19. S. M. Srivastava. A Course on Borel Sets. 
Springer-Verlag New York Inc., 1998. 
20. J. Lafferty, A. McCallum, F. Pereira: Conditional 
Random Fields: Probabilistic Models for 
Segmenting and Labeling Sequence Data. In 
Proceesings of 18th International Conference on 
Machine Learning (ICML 2001) 2001:282-289. 
21. T. H. Tsai, W. C. Chou, S. H. Wu, T. Y. Sung, J. 
Hsiang, and W. L. Hsu. Integrating linguistic 
knowledge into a conditional random field 
framework to identify biomedical named entities. 
Expert Systems with Applications, 30:117-128, 
2005. 
22. H. M. Wallach. Conditional random fields: An 
introduction. Technical Report MS-CIS-04-21, 
Department of Computer and Information Science, 
University of Pennsylvania, 2004. 
出差經過報告表  
填表日：      年     月     日 
出 差 人 蔣以仁 
單
位 
醫學資訊研究所 
職
稱 
副教授 
出差事由 
參加 APAMI 2009 學術研討會 
 
出差地點 日本廣島 
起止日期      98   年     11   月       22   日起至    98   年    11   月     26    日止 
工作紀要 
1. APAMI 2009 學術發表論文. 
2. 參與 APAMI 事務性工作. 
 
 
 
具體成果
及建議 
1. 發表兩篇論文. 
2. 獲推薦擔任 APAMI 秘書長. 
3. 與日本，韓國，香港，馬來西亞等國達成學術交流與合作。 
 
 
 
 
 
 
 
 
 
 
國科會補助計畫衍生研發成果推廣資料表
日期:2010/12/16
國科會補助計畫
計畫名稱: 利用擴散理論、語義網絡與時序分析為基礎之機器學習法建立人類活動與環境
變遷間之分析模擬模型 (2/3)
計畫主持人: 蔣以仁
計畫編號: 98-2221-E-038-012- 學門領域: 人工智慧 
研發成果名稱
(中文) 利用擴散利利、語義網絡與時序分析為基礎之機器學習法建利人利活動與環境變
遷間之分析模擬模型 (2/3)
(英文)
成果歸屬機構
臺北醫學大學 發明人
(創作人)
蔣以仁
技術說明
(中文) 我們的研究成果中，關鍵特徵的擷取能更正確且具獨特性，是建立因語義而結合，
探討動態性隨時而變之Ontology規律最重要的起始利驟，利用機器學習結合諸如
辭典之專家知識以建立屬特殊領域數位內容為目標之關鍵資訊萃取方法，我們以
統計機率演算法，並藉助專業詞庫（ Dictionary或Lexicon）及字詞特性，發展
Conditional Random Field模式，成為Knowledge-Based Probabilistic 
Extracting法則，以形成各特殊領域從專業文件中萃取重要之詞彙；為求能確實
掌握其中文義涵意，以作為後續同質分類分群，建立推論 Ontology。
(英文) ：This research has taken scientific dataset and related articles as subject, especially the 
ecology domain, implementing “automatic feature extraction” and “scoring” model for 
automatically constructing the taxonomical and decision supporting ontology. The 
conditional random fields (CRFs) have taken to extract the significant features, i.e., 
named entities, in a document. Afterwards, invited experts will evaluate the efficiency of 
the system with personal diagnosis and feedback the results to the system. With the 
computer learning technology, the process of constructing the ontology, especially for 
decision making, will be modified.
產業別 研究發展服務業
技術/產品應用範圍
1. 圖書及檔案資訊：進行知識地圖建構，以協助檔案管理機構、及圖資系統公司，作相
似議題與內容的分類歸納。 
2. 科技性或其他各類文獻：已提供建立國衛院實證醫學網站(ebpg.nhri.gov.tw)實證資
料檢索，協助醫護人員正確找到所需的資料。
技術移轉可行性及
預期效益
改善一般資料檢索方式，使能更準確掌握語意上的意義與實質內容特性。可運用於資料
檢索、群聚分析等服務。可與資訊檢索作有效整合。
註：本項研發成果若尚未申請專利，請勿揭露可申請專利之主要內容。
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
