Robust Framework of Cloud Services for Supporting 
Multi-dimensional and Dynamic Data Analysis (RoSA for 
short). RoSA is massively scalable, efficient and 
robust to provide important multi-dimensional and 
location-based functionalities for supporting crisis 
management. We will design search algorithms to 
improve the performance of queries over highly 
dimensional and dynamic data sets. To facilitate the 
high-performanced search algorithms, effective index 
structures that will make significant improvement in 
organizing data sets for retrieval operations and 
handling frequent data updates will be proposed. 
Furthermore, this research work will develop cache 
management and pre-computational techniques to reduce 
the query evaluation cost in order to achieve fast 
response time. These proposed techniques will be 
widely utilized in multi-criteria decision making 
applications. On the system level, to manage the 
time-varying computational resources that are 
dynamically inserted into or removed from the entire 
infrastructure, we will design a flexible control 
mechanism to achieve better scalability and 
robustness. 
英文關鍵詞： Multi-Dimensional Databases, Spatial-temporal 
Databases, Location-based Services, Moving Object 
Processing, Scalable Continuous Query Processing, 
Spatial Data Indexing, Cloud Computing 
 
propose to design and implement a Robust Framework of Cloud Services for 
Supporting Multi-dimensional and Dynamic Data Analysis (RoSA for short). 
RoSA is massively scalable, efficient and robust to provide important multi -
dimensional and location-based functionalities for supporting crisis 
management. We will design search algorithms to improve the performance of 
queries over highly dimensional and dynamic data sets. To facilitate the high-
performanced search algorithms, effective index structures that will make 
significant improvement in organizing data sets for retrieval operations and 
handling frequent data updates will be proposed. Furthermore, this research 
work will develop cache management and pre-computational techniques to 
reduce the query evaluation cost in order to achieve fast response time. These 
proposed techniques will be widely utilized in multi -criteria decision making 
applications. On the system level, to manage the time-varying computational 
resources that are dynamically inserted into or removed from the entire 
infrastructure, we will design a flexible control mechanism to achieve better 
scalability and robustness.  
 
Keywords: Multi-Dimensional Databases, Spatial-temporal Databases, 
Location-based Services, Moving Object Processing, Scalable Continuous 
Query Processing, Spatial Data Indexing, Cloud Computing 
 
INTRODUCTION 
Many recent studies show that decision makers have to be capable of 
analyzing massive high-dimensional data collections to dynamically and 
judiciously make critical decisions under complex situations such as 2011 
Japan Tohoku earthquake and 2009 Taiwan flood 88. Importantly, the need of 
effective and real-time support for disaster management or resource dispatching 
exists in a wide variety of disciplines. In addition, the impressive advancement 
of mobile communication technologies together with ever more capable  
handheld devices with GPS sensors has sparked intense interest in location-
aware services, where each mobile unit is considered as a spatial-temporal data 
object that is capsulated with high-dimensional data attributes. In the past, 
researchers have made substantial progress on querying spatial-temporal 
databases and multi-dimensional data searches. Some of the prior work 
assumed that data are static. Other approaches assumed that query 
computations involve only a partial of dynamic dimensions. Furthermore, the 
query computations are very computationally complex in higher dimensions. 
The cost of the query evaluation process increases as the number of data 
dimensionality and data mobility increase. Therefore, existing systems are 
often unable to provide up-to-date search results with quick response time 
when considering a highly dimensional and dynamic data set. It is very difficult 
to design real-time and robust search techniques under critical conditions where 
many challenging issues (e.g., communication delay, limited power supply,  
be part of the skyline. In case (3), if there is not enough memory in the list, p is 
inserted into a temporary disk file. After scanning the whole data set, only points in 
the candidate list will be guaranteed and returned as the skyline result. Then BNL will 
be executed again with the temporary disk file as input. The whole procedure 
continues until all skyline points have been checked. The main problem of this 
algorithm is its restriction by the memory size. If the memory size of the candidate list 
is too small, many iterations will be incurred. As a result, this approach is inadequate 
for dynamic processing. 
Referencing the 2-dimensional example in Figure 2, the divide-and-conquer (DC) 
approach works as follows: (1) compute the median mx of the data set on some 
dimension x and divide the whole data set into two partitions s1 and s2. s1 contains 
points whose values in dimension x are smaller than mx; s2 contains all others. (2) 
Calculate skylines of s1 and s2, respectively. This is done by recursively applying the 
dividing step until there are one or very few points in one partition, making the 
computation of the skyline trivial. (3) Merge results of s1 and s2 as the overall skyline. 
In this step, first the algorithm computes the median my of the data set on dimension y 
and divides s1 and s2 further into s11, s21, s12, and s22. Because points in s21 always 
have a smaller y dimensional values than points in s12, s12 and s21 are incomparable. 
As a result, we only need to merge results in s11 and s21, results in s12 and s22 (named 
as R2), and results in s11 and R2. The DC algorithm cannot merge and return the 
overall skyline result until the partitioning phase completes. This phase needs 
continuous position updates for all moving objects. 
The nearest neighbor (NN) method [8] indexes the input data set with an R-tree. It 
then utilizes the nearest neighbor query of the R-tree to find the result skyline. Taking 
the data set of Figure 3(a) as a 2-dimensional example, NN invokes the nearest 
neighbor query and returns point g, which is one point of the result skyline. 
Coordinates of g divide data space into four areas: 1, 2, 3, and 4 (as shown in Figure 
3(b)). All other points located in area 4 need no further consideration because they are 
dominated by g. Then NN inserts the remaining areas (1 and 3; 1 and 2) into a to-do 
list. This method continues to pop areas from the to-do list and repeats the above 
query-and-divide procedure. NN terminates when the to-do list is empty. The NN 
method can be generalized into higher dimensional data cases. Kossmann et al. [8] 
proposed hybrid approaches for duplicate elimination of overlapping partitions. 
However, construction of an R-tree for continuous moving objects may incur much 
communication cost for position updates. 
             (a)   (b)  
Figure 2. Divide and conquer.                Figure 3. Nearest neighbor approach.  
 
SKYLINE POINT SEARCH ALGORITHM for RoSA 
The formal definition of skyline points in d-dimensional space is a set of distinct 
objects, where any two tuples of objects a and b, ta = ida, cor1a, ..., corna, tb = idb, 
cor1b, ..., cornb in the set satisfy the condition that if any k, corka < corkb, there exists 
at least one m that satisﬁes corma > cormb. Each coordinate represents a spatial or non-
spatial value, for example, the distance between a moving object and a query object, 
the maximum speed, and the current direction, etc. The number of features for a 
moving object is more than one and the features are dynamically changing over time. 
The general setup of the problem consists of a dynamic query object q and a set of 
dynamic data objects with a dimension d. A regular grid G consisting of n × n ... × n = 
n
d
 cells is used to index the moving objects and the origin O represents the query 
object q. At any time instance t, each cell ci,j consists of indices of a list of moving 
objects (denoted Mi,j) and a list of skyline points (denoted Si,j) residing within it. 
Constructing the index requires scanning through the objects and inserting each object 
into a corresponding cell. The grid-cell index structure is shown in Figure 4. Moving 
objects in grid G can freely move from cell to cell. 
An update from each object is issued to a centralized server periodically and its 
tuple id, cor1aold, cor2aold, ..., cornaold is changed to id, cor1anew, cor2anew, ..., cornanew. 
Thus, in case that a moving object moves out of its current cell ci,j into ci+1,j, the index 
of this object will be removed from the Mi,j and inserted into Mi+1,j. 
C-Sky processes a cell in G by utilizing the block-nested-loops method (BNL) [2], 
and a set of local skyline points is returned. The algorithm then combines these local 
skyline points with the skyline points from some other cells in order to obtain an 
overall set of skyline points. The C-Sky algorithm uses a grid of cells that provides a 
partitioning approach [9,10,11], such that skyline computations consider the minimal 
set of cells in order to retrieve the skyline points eﬃciently. The sequence of 
computing skyline points is important to avoid unnecessary cell visits. It can be easily 
observed that a natural processing order of skyline computations starts from the cell 
ci,j with minimum mindist to the query point (or the origin), since it prunes a 
maximum number of cells, the moving points of which are guaranteed to be 
dominated by any skyline points in cell ci,j. Given a dynamic query object and a cell, 
mindist is deﬁned as a possible minimum distance between the query point and a cell 
rectangle boundary. Eﬃcient methods for the computation of mindist have been 
discussed in previous work [6,7]. 
           
Figure 4. Data structure of grid-based index.      Figure 5. Grid G and corresponding                           
binary search tree. 
“delete.” The merge operation also skips those cells in area B since the moving points 
in any cell of area B and cell c2,2 can never dominate each other. 
Lemma 3: An extension of Lemma 2. During a merge process, a point h of the 
local skyline points in cell ci,j = G[i,j] is pruned if and only if any skyline point in C = 
{G[0...i−1,j], G[i,0...j−1]} cells dominate it. 
Proof: A naïve approach is to consider all moving objects in C cells for merging. 
Assume a cell cy,z in C, a set of non-skyline points NSy,z , and a set of skyline points 
Sy,z. If a local skyline point h in cell ci,j is dominated by a non-skyline point in NSy,z, h 
must also be dominated by a skyline point in Sy,z, since each non-skyline point in NSy,z 
is dominated by a skyline skyline point in Sy,z. Therefore, it is not necessary to 
examine all moving objects in C to obtain a ﬁnal list of skyline points for ci,j. ■ 
As Figure 6(b) shows, Slocal = {a,b,c} for cell c2,2, and C-Sky compares these points 
with S0,2 = {h,e} and S2,0 = {d,f} and S2,1 = {g} to output a ﬁnal list of skyline points 
of cell c2,2. As a result, a, b, c are dominated, so S2,2 = {φ}. 
Algorithm 1 presents the pseudo-code for C-Sky. In line 2, each data object is 
periodically updated before the skyline computations. An entry of the search order is 
retrieved in line 3 and line 5 computes a set of local skyline points for a cell with 
respect to the entry. A pruning operation and merge operation are performed in line 9 
and lines 11-15, respectively. Line 16 stores the overall skyline points. 
 
 
 
(a) 
 
 
(b) 
 
 
 
Figure 6. Example of (a) pruning and (b) 
merge operations. 
Algorithm 1. C-Sky Algorithm – Periodic Updates. 
EXPERIMENTAL EVALUATION 
We evaluated the performance of C-Sky algorithm by comparing it with BBS 
[2]. For verifying the eﬀectiveness and eﬃciency of the lazy update approach, 
we implemented two versions of C-Sky: C-Sky with periodic updates (C-Sky-
PD) and C-Sky with lazy updates (C-Sky-LZ). In accordance with a prior study 
[12], our data sets are generated based on the random walk theory. Each output 
data object moves with a constant velocity until its expiration time. The velocity 
is then replaced by a new velocity with an expiration time. Figure 8 shows an 
example of a moving object moving based on the random walk approach. At the 
initial position p0, the moving object p moves with a constant velocity. After 
reaching its expiration time, p arrives at the position p1. The length of movement 
path l is calculated by p.velocity × p.expTime. A new velocity and a new 
expiration time are assigned to p and it keeps moving accordingly with its new 
velocity. 
We generated 100K to 1M uniform and correlated distributed data with a 
dimension in the range of 2 to 5. Experiments were conducted on a system with 
an Itanium 1 GHz CPU and 8 GB of memory. The result sets of the skyline 
points are evaluated at every time instance. Our experiments are using several 
factors to examine the performance of C-Sky. In particular, in Section 4.1, we 
evaluate the effect of grid sizes ranging from 2 to 30 for each axis; in Section 4.2, 
we study the effect of cardinality and dimensionality by comparing C-Sky with 
the BBS algorithm; in Section 4.3, the effect of the lazy update approach is 
analyzed. In the BBS algorithm, R*-trees are used for indexing the moving 
objects. We use the R*-trees library implemented in Java by [15]. A page size of 
4KB is deployed, resulting in node capacities between 94 (d=5) and 204 (d=2). 
4.1 Grid Size 
In this section we measure the overall CPU time of C-Sky by varying the grid 
size, which is one of the important parameters for the C-Sky performance. If the 
grid size is too small (e.g., less than 5 per dimension), it incurs a higher CPU 
cost. Because each cell (with larger cell size) may contain a large data set and a 
BNL computation works efficiently only with a small set of data, it suffers many 
iterations and the performance deteriorates. Furthermore, when a merge 
operation is performed on cells containing large data sets, it results in many 
unnecessary computations. If the grid size is too large, each cell is under-utilized 
for containing only a few data points. Particularly in the lazy update approach, as 
an activity circle of a moving object grows, it is likely to cover more cells such 
that it results in expensive index update costs. 
Figure 9 illustrates the result for grid sizes ranging from 2 × 2 × 2 to 30 × 30 × 
30 for uniform and correlated data sets. The performance is improved when 
applying a grid size of 10, but it is degraded when a larger grid size is used. 
Figure 9 suggests that the optimal grid size is 10, so this size is chosen for the 
rest of our experiments. 
4.3 Lazy Updates 
Lazy updates have been defined earlier in this paper as a mechanism where the 
location of a moving object is updated only when its activity circle intersects 
with the currently processed cell, in contrast to a periodic update approach where 
the entire set of moving objects are updated periodically. However, with the lazy 
update approach, if the activity circle of a moving object is not updated, the 
boundary of its movement is increasing such that it may cover many cells. As a 
result, it incurs many index updates and costs more CPU time. Therefore, we set 
up a threshold for the lazy update approach. When an activity circle of a moving 
object covers more than a certain percentage of the entire number of cells (e.g., 
10%), the system updates the moving object, even though its activity c ircle does 
not intersect with the currently processed cell. Figures 12(a) and 12(b) compare 
the number of updates and CPU time versus the update rates from 0% to 20% for 
the uniform and correlated data sets. It can be observed that the choice of update 
rate is a trade-off between the number of updates and the CPU time. A high lazy 
update rate results in a lower number of updates but incurs a higher CPU time. In 
the following experiments we use the mean of these rates, namely 10%, as our 
lazy update rate. 
Figures 13(a) and 13(b) measure the effect of the two update approaches for 
the uniform and correlated distributed data sets. The number of updates is greatly 
reduced by utilizing the lazy update approach. Figures 14(a) and 14(b) present 
the overall CPU time. C-Sky-LZ costs more CPU time than C-Sky-PD. The CPU 
time is increased because C-Sky-LZ handles more index updates. Since we 
assume C-Sky adopts by client-server architecture, the overall update cost has 
two parts: the communication cost between moving objects and the server, and 
the local update cost including data updates and index updates on the server. 
Therefore, if the number of updates issued by moving objects is decreased, the 
communication cost is reduced as well. In our future work, we plan to fur ther 
investigate the measurements of the communication cost, and a fair comparison 
of C-Sky-PD and C-Sky-LZ with respect to their overall update cost. 
   
(a) Number of updates (uniform and correlated). (b) CPU time (uniform and correlated). 
Figure 12. Lazy update rate. 
[9] Mouratidis, K., Hadjieleftheriou, M., and Papadias, D., “Conceptual Partitioning: an 
Efficient Method for Continuous Nearest Neighbor Monitoring,” In Proc. Int'l Conf. on 
Management of Data, ACM SIGMOD, 2005. 
[10] Yu, X., Pu, Q., Koudas, N., “Monitoring k-Nearest Neighbor Queries over Moving 
Objects,” In Proc. Int’l Conf. on Data Engineering, ICDE, 2005. 
[11] Xiong, X., and Mokbel, M. F., “SEACNN: Scalable Processing of Continuous K -Nearest 
Neighbor Queries in Spatio-temporal Databases,” In Proc. Int’l Conf. on Data 
Engineering, ICDE, 2005. 
[12] McDonald, A. B., and Znati, T., “A Mobility Based Framework for Adaptive Clustering in 
Wireless Ad-Hoc Networks,” IEEE Journal on Selected Areas in Communications, Vol. 17, 
No. 8, pp. 1466-1487, August 1999. 
[13] Zhang, Z., Guo, X., Lu, H., Tung, A. K. H., and Wang, N., “Discovery Strong Skyline 
Points in High Dimensional Spaces,” In Proc. Int’l Conf. on Information and Knowledge 
Management, CIKM, 2005. 
[14] Yuang, Y., Lin, X., Liu, Q., Wang, W., Yu, J. X., and Zhang, Q., “Efficient Computation of 
the Skyline Cube,” In Proc. Int’l Conf. on Very Large Data Bases, VLDB, 2005. 
[15] Hadjieleftheriou, M., “Spatial Index Library version, 0.44.2b (Java),” 
http://www.cs.ucr.edu/ marioh/spatialindex/. 
 
 
ACHIEVEMENTS 
本計畫所作的相關研究已經寫成數篇會議論文，我們也將計畫的研究成果發表
於一些相關的比賽，如以下所示： 
 
會議論文 
1. Yuling Hsueh, Roger Zimmermann, and Wei-Shinn Ku, “Caching Support 
for Skyline Query Processing with Partially-Ordered Domains”, In 
Proceedings of the 20th ACM SIGSPATIAL International Conference on 
Advances in Geographic Information Systems (ACM SIGSPATIAL GIS), 
Redondo Beach, CA, USA, 2012. 
 
2. Ren-Hung Hwang, Yu-Ling Hsueh, and Hao-Wei Chung, “A Novel Time-
Obfuscated Algorithm for Trajectory Privacy”, In Proceedings of the 
International Symposium on Pervasive Systems, Algorithms, and Networks 
(ISPAN), San Marcos, Texas, USA, 2012. 
 
3. 張邑豪,林欣漢,薛幼苓,“基於快取機制之路徑規劃方法  (An Efficient 
Cache-based Route Planning Approach in Road Networks)”, In 
Proceedings of the 17th Conference on Technologies and Applications of 
Artificial Intelligence (TAAI), Tainai, Taiwan, 2012.  
 
4. Yu-Ling Hsueh, and Roger Zimmermann, “Continuous Skyline Queries for 
Multi-Dimensional Moving Objects,” International Conference on 
Emerging Databases (EDB), Incheon, Korea, August 2011 
 
比賽 
1. 2012 ACM SIGSPATIAL Cup, 全球排名 12 名 (主題: Map Matching，指
導學生：賴韋利、張邑豪 
2. 軟體創作達人暑期成長營入圍決賽 (主題:雲端網際服務，指導學生: 李
嘉泓、蘇嘉浚、陸志良) 
 1 
國科會補助專題研究計畫出席國際學術會議心得報告 
                                  日期： 2012  年 04 月 20日 
 
一、 參加會議經過 
我參加的 International Conference on Emerging Databases (EDB 2011)是資料庫管理領域重要的國際
研討會之一。EDB’11 研討會提供學術研究者與業界人士一個討論資料庫科技與發表最新成果的平
台，並冀望藉由此交流活動，能帶領這領域的研究發展與茁狀、更希望能讓這領域的學者能在開
放的討論環境中，激發新的研究創意與想法。EDB’11 於 8 月 25 日在韓國仁川舉行，三天的研討
會包含了 poster session、二場 tutorial、keynote speech、industrial workshop 與一般議程。EDB’11
會議包含了 Data Mining、Geo-spatial, XML and Text、Social Network、Service, Manufacturing, RFID 
applications、Biomedical, Health Applications 等不同主題。在此次的 EDB’11 會議中，我在 Geo-spatial, 
XML and Text session 中發表了本計劃所規劃一項重要核心技術，論文題目為 “Continuous Skyline 
Queries for Multi-Dimensional Moving Objects”，我報告的時間為 20 分鐘包含論文內報告與Ｑ＆Ａ
時間，會場約有 40 多人蒞臨聆聽。在 Q＆Ａ時間時，有一、二位韓國教授提出了問題與看法。在
會後我與 Dr. Yoo-Sung Kim、Dr. Sangdon Lee、Dr. Kyoji Kawagoe、Dr. Young-Kuk Kim 等多位學者
們有更進一步的交流。另外，我也參與其它研究議程，收穫良多。 
二、與會心得 
大會的議題包含了資料庫管理技術相關的研究主題，我參加了大部分的研究議程，包含 data mining 
的資訊分析方法、Geo-spatial, XML and Text 對巨量資料的管理與應用、Social  Network Service 所
計畫編號 NSC 100－2218－E－194－004－ 
計畫名稱 支援多維度動態資料分析之雲端服務的可靠性框架 
出國人員
姓名 
薛幼苓 
服務機構
及職稱 
國立中正大學資訊工程學系 
助理教授 
會議時間 
2011 年 08 月 25 日至
2011 年 07 月 31 日 
會議地點 韓國 
會議名稱 
(中文) 
(英文) International Conference on Emerging Databases 
發表題目 
(中文) 
(英文) Continuous Skyline Queries for Multi-Dimensional Moving Objects 
 3 
A continuous skyline query retrieves a set of d-dimensional moving object points, which are not 
dominated by any other points in space. Each dimension represents a unique criterion and the skyline 
query result reflects all possible trade-offs among the best candidate points. Skyline queries are of crucial 
importance with the recent proliferation of location-based and e-commerce mobile services. To support 
these applications we assume that both query and data objects are dynamic, in contrast to much of the 
prior work. In this paper we propose C-Sky, a grid-based, progressive algorithm to efficiently compute 
continuous skyline queries in multi-dimensional and dynamic environments. Objects are indexed with a 
regular grid consisting of n
d
 cells. A search order imposed on the grid cells is introduced to reduce 
unnecessary cell visits. Moving from one cell to the next in search order, C-Sky performs three 
consecutive operations for each cell that it processes: (1) a block-nested-loop algorithm to locally 
compute the skyline points, (2) a pruning operation to remove unpromising cells from the search space, 
and (3) a merge operation to combine the latest skyline points with results from previous cell visits. A set 
of overall skyline points is obtained after the algorithm terminates. Because of its pruning abilities, C-Sky 
significantly reduces the required processing. We also propose a lazy update approach that updates an 
object only when its activity circle, a boundary on its movement, intersects with the currently processed 
cell. This approach further decreases the IO overhead. We evaluate C-Sky through rigorous simulations 
and compare it with an existing technique. Experimental results are presented that show the performance  
and utility of our novel approach.       
 
四、建議 
EDB’11會議為資料庫管理領域中最重要的會議之一，參加此會議能獲知最新的資料探勘、資料庫
索引與查詢、巨量資料處理等技術，擴展研究視野，並能與其他學者交流研究心得與建立研究合
作，對於研究的深度與廣度均有莫大的幫助。因此，吾人懇切建議國科會能繼續支持補助出席國
際學術會議。 
 
五、攜回資料名稱及內容 
研討會論文集 (光碟)與 keynote演講講義 
 
六、其他 
無 
 Recommending Representative Tags for Social Media Users: An LSA-based Method
Xian Chen, Hyoseop Shin (Konkuk University, Korea)
 Locating the Social Network Suspects by Using Subsequence Matching and Graph Clustering
Soo-Hyun Eom, Wookey Lee, Chul-Ghi Lee (Inha University, Korea)
 Tag Association Based Graphical Password using Image Search Web Services
Shinichi Sakaguchi, Hung-Hsuan Huang, Kyoji Kawagoe (Ritsumeikan University, Japan)
Session 4 : Service, Manufacturing, RFID Applications (Saturday, August 27th, 09:40~11:20)
[Lily A, 2nd, fl.]
Session Chair: Wonik Choi
 Design of Pedigree Checking System for Verification of Pedigree Information
Seungwoo Jeon, Jia Fengjuan, Bonghee Hong, Joonho Kwon (Pusan National University, Korea)
 A Method for the Fast and Extendable EPC Information Service
TaiHyun Ahn, Gihong Kim, Juneup Park, Bonghee Hong, Joonho Kwon (Pusan National University, Korea)
 A Technique for verification of Query Processing of RFID Middleware by using Tag Event Log
Jiwan Lee, Wooseok Ryu, Bonghee Hong, Joonho Kwon (Pusan National University, Korea),
ByeongSam Kim (Distribution Research Group Korea Food Research Institute, Korea)
 Access Key based Distributed Secure Access Control for EPCglobal Networking
Wenyan Yu, Yongxu Piao, Joonho Kwon, Bonghee Hong (Pusan National University, Korea)
 CUBRID Reference Architecture for Social Networking Service
Kieun Park (NHN Business Platform Corp., Korea)
Session 5 : Biomedical, Health Applications (Saturday, August 27th, 09:40~11:20) 
[Lily C, 2nd, fl.]
Session Chair: Yang-Sae Moon
 An Efficient Approach for Mining Significant Contiguous Frequent Patterns in Biological Sequences
Md. Mamunur Rashid, Md. Rezaul Karim, Md. Azam Hossain, Byeong-Soo Jeong (Kyung Hee University, Korea)
 An Anonymization Technique in Preserving Uniform Distribution of Sensitive Values
Hangyoung Go, Kangsoo Jung, Seog Park (Sogang University, Korea)
 A Fast Frequent Contiguous Sequential DNA Pattern Mining Technique
Syeda Farzana Zerin, Byeong-Soo Jeong (Kyung Hee University, Korea)
 Application of Database Technology to a RFID-based Exercise and Nutritional Management System
Sue Kyung Lee, Younghee Ro (Daeyang eT&C., Co., Ltd., Korea)
 Toward Efficient Information Gathering from Document Archives: a Study of Iterative Document Filtering
Strategies in the Biomedical Domain
Manbu Torii, Dongkyu Kim, Noele Nelson, David Hartley (Georgetown University Medical Center, USA)
Hongfang Liu (Mayo Clinic College of Medicine, USA)
Tutorial (B) (Saturday, August 27th, 11:35~12:35) [Lily A, 2nd, fl.]
Session Chair: Wook-Shin Han
 Support Vector Machines for Classification and Ranking
Prof. Hwanjo Yu (POSTECH, Korea)
Industrial Workshop (Friday, August 26th, 09:40~11:20) [Rose, 2nd fl.]
 Database Monitoring and Tuning
Prof. Jonghoon Chun (Myongji University, Korea), Yonghoi Choi (Quest Software, Korea)
國科會補助計畫衍生研發成果推廣資料表
日期:2012/10/26
國科會補助計畫
計畫名稱: 支援多維度動態資料分析之雲端服務的可靠性框架
計畫主持人: 薛幼苓
計畫編號: 100-2218-E-194-004- 學門領域: 資料庫系統及資料工程
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
#學術活動 
‧ Program Committee Co-Chair for Symposium on Cloud and Services 
Computing (SCC 2013), Tainan, 2013.  
‧Web Master on 2013 CACS International Automatic Control Conference 
(CACS 2013), Nantou, Taiwan, 2013. 
‧ Technical Program Committee Member, Workshop on Algorithms, 
Database,Data Mining, and Information Retrieval, the International 
Computer Symposium (ICS 2012), Hualien, Taiwan, 12–14 December 2012
‧Program Committee, Workshop on Databases, Data Mining, and Information 
Retrieval, the National Computer Symposium (NCS 2011), ChiaYi, Taiwan, 
2–3 December 2011 
‧Reviewer, ACM Transactions on Multimedia Computing Communications and 
Applications, 2012 
‧ Reviewer, Workshop on Databases, Data Mining, and Information 
Retrieval, the National Computer Symposium (NCS 2011), ChiaYi, Taiwan, 
2–3 December 2011 
#所指導之學生曾獲之獎項及特出之表現: 
‧2012 ACM SIGSPATIAL Cup, 全球排名 12 名 (主題: Map Matching，指導學
生：賴韋利、張邑豪 
‧2012 軟體創作達人暑期成長營入圍決賽 (主題:雲端網際服務，指導學生: 李
嘉泓、蘇嘉浚、陸志良) 
‧2011 i-Star 國家創新發明大賽入圍決賽 (作品名稱: 雲端適地性團購服務: 
MobileGroupBuy，指導學生：彭守均、黃宏閔、陳智群) 
 
 
 
 
 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
