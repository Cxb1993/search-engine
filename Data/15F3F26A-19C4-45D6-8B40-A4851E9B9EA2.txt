 1
行政院國家科學委員會專題研究計畫成果報告 
 
 
三段式不特定語句大量語者辨識系統之設計與實作 
 
 
計畫編號：NSC 98-2221-E-110-059 
執行期限：98 年 08 月 01 日至 99 年 07 月 31 日 
 
主持人：陳志堅 
 
國立中山大學  電機工程學系 
 
中文摘要 
 
我們以卡式轉換、高斯混合模型與局部
線性內嵌為基礎，設計了三段式的不特定語
句語者辨識系統。計劃中我們錄製了 1500 位
國語語者之資料庫來測試系統的正確率。結
果證實，僅使用 32 個卡式特徵，配合巴式距
離量度，以第一階段選取前 4% 之 60 位最相
近之候選語者，並配合第二段之 32 個分量的
高斯混合模型的辨識策略，選取前 10 位最相
近之候選語者，與第三段之局部線性內嵌辨
識器，來作不特定語句之語者辨識，可獲得
比高斯混合模型，高出約 4% 之正確辨識率，
同時計算速度更可加快將近 25 倍。 
 
關鍵字:  卡式轉換、巴式距離、高斯混合 
         模型、局部線性內嵌 
 
Abstract: 
 
A classification scheme that 
incorporates KLT, GMM and LLE for three-
stage text independent speaker identification 
has been designed in this project.  Our 
results show that the combination is 
beneficial to both classification accuracy and 
computational cost. For a database with 1500 
Mandarin speakers, the first 32 KLT features 
combined with the Bhattacharyya distance 
measure are applied to initially select 4% (60 
candidates) of the all speakers in the first 
stage, and then the GMM classifier is used to 
choose the most resembling 10 semi-finals in 
the second stage, and finally the LLE is used 
to confirm the final speaker in the last stage. 
It is demonstrated in the experiment that the 
accuracy improvement of up to 4% and the 
computational cost saving of 25 times 
compared to those of the conventional GMM 
model can be achieved. 
 
Keywords:  Karhunen-Loeve transform,  
 Bhattacharyya distance, 
Gaussian mixture model, 
Locally linear embedding 
 
Introduction:  
 
Karhunen-Loeve transform (KLT) has 
been applied to extract spectral pattern for 
text independent speaker identification [1]. 
Theoretically, it is the optimal transform in 
minimum mean square error and maximal 
energy packing sense. The transformed data 
is totally uncorrelated and contains most of 
the classification information in the first few 
coordinates.  But, as the number of speakers 
increases, performance eventually decreases 
due to speaker distribution overlap. 
 3
Bhattacharyya distance:  
 
Bhattacharyya distance is closely tied to 
the probability of error as an upper bound on 
the Bayes error for normally distributed 
classes [3].  For normal pdf’s, the 
Bhattacharyya distance between class i and j 
is 
)()
2
()(
8
1
2
ln
2
1
1
2
2
1
2
1
ji
jiT
ji
ji
ji
BD
μμμμ −Σ+Σ−+
ΣΣ
Σ+Σ
=
−
  (5) 
 
The first term of eqn. 5 gives the class 
separability due to the difference between 
class covariance matrices, while the second 
term gives the class separability due to the 
difference between class means. Furthermore, 
the optimal Bayes classification error 
between the two classes is bounded by the 
following expression: 
 
)exp( 221 BDPP −≤ε        (6) 
 
We will refer to the upper bound of the 
error probability evaluated from the 
inequality (6) with 5.021 == PP , as the 
Bhattacharyya error, 
 
)exp(5.0 2BB D−=ε         (7) 
 
The Bhattacharyya distance directly 
compares the estimated mean vector and the 
covariance matrix of the test speaker with 
those of the training speakers. If inclusion of 
the test covariance in the metric is useful, 
Bhattacharyya distance will outperform 
others distances [3]. 
 
Gaussian mixture speaker model: 
 
Gaussian mixture model uses multi-
modal Gaussian distribution to represent 
speaker’s voice and vocal tract 
configurations. For a feature vector denoted 
as C, the mixture density for speaker s is 
defined as ∑
=
=
M
i
s
i
s
is CbpCp
1
)()|( λ . The 
density is a weighted linear combination of 
M component uni-modal Gaussian 
densities )(Cbsi , each parameterized by a 
mean vector siμ  and a covariance matrix siΣ . 
Collectively, the parameters of a speaker’s 
density model are denoted 
as },,{ si
s
i
s
is p Σ= μλ , i = 1,2,...,M.  In this 
Report, 32 component mixtures with 
diagonal covariance matrices are used. 
maximum likelihood estimates of the model 
parameters are obtained using the expecta-
tion-maximization (EM) algorithm [2]. 
 
Locally linear embedding: 
 
Locally linear embedding (LLE) is a 
globally nonlinear technique that can be used 
to preserve the distances in high-dimensional 
feature space.  Let iX
r
 be a D-dimensional 
sample vector in the database with N samples, 
and K be the number of nearest neighbors 
jX
r
on its linearly surrounding patch.  The 
total square error ( )Wε  between all iXr and 
its K neighbors is : 
 
( ) ∑ ∑−=
i
jj iji
XWXW 2||
rrε     (8) 
 
where the weight ijW = 0 for the jX
r
 outside 
the K’th nearest range, and 
 
∑ =j ijW 1           (9) 
 
The optimal weight can be found by the 
constrained least square algorithm. 
 
∑
∑
−
−
=
lm lm
k jk
j C
C
w 1
1
         (10) 
 
where jkC  is the local covariance matrix. 
 5
Classification of speech data:  
 
In the first stage of the initial candidate 
selection process, 200 frames of test data  
(~4.6 s) are transformed by the first 32 KLT 
features. The mean vector and covariance 
matrix of this test speaker are then estimated.  
The Bhattacharyya distances in eqn. 5 are 
calculated and ranked in increasing order for 
candidate selection.  In the second stage of 
the semi-final speaker recognition process, 
the maximal likelihood decision rule shown 
in eqn. 14, 
 
∑
=≤≤
=
NF
t
ktNCk
CPs
11
))|(log(maxargˆ λ    (14) 
 
is applied to the 200 frames ( NF=200 ) of 
test data with 24 MFCC features over all NC 
selected candidates’ GMM models to make 
the semi-final decision.  In the last LLE 
stage, these 200 test frames are first reformed 
into 25 frames with 2048 sampling points, 
and then transformed into three-dimensional 
embedding space. Maximal likelihood classi-
fier in eqn. 14 is used to confirm the ultimate 
speaker. 
 
Experimental results:  
 
Table 1 shows the performance of the 
three-stage speaker identification system 
based on KLT/GMM/LLE for the 1500-
speaker database. The results for both 
KLT/GMM and GMM are also included for 
comparison. 
 
Table 1. Performance using KLT/GMM/LLE  
Method KLT/GMM/LLE KLT/GMM GMM
Pr(correct) 0.921 0.902 0.881
Time (sec) 1.32 1.30  32.46 
 
For this three-stage classification system 
60 speakers, that is 4% of the population size, 
are chosen in the initial KLT candidate 
selection process for further decision in the 
second stage.  Then in the second stage the 
24 MFCCs’ based GMM classifier selects the 
10 most resembling speakers for further 
processing in the third LLE stage to find the 
ultimate speaker. 
 
The results indicate that the three stage 
KLT/GMM/LLE model has an improvement 
of 4% over the conventional GMM approach. 
Furthermore, for the conventional GMM, the 
algorithm requires 32.46 s of CPU time on a 
Pentium-4 2.4Ghz machine to perform the 
search in the entire 1500-speaker database. 
But, for the KLT/GMM/LLE, the algorithm 
requires only 1.32 seconds of CPU time to 
find the correct speaker. 
 
Conclusions: 
 
A KLT/GMM/LLE approach based on 
three-stage classifiers has been introduced to 
text independent speaker identification.  
Both linear and non-linear speaker features 
are applied in this system.  In the first stage, 
the linear KLT features are used as the initial 
candidate selection tool to discard those 
speakers with larger separability.  Then in 
the second stage, the GMM is utilized as the 
semi-final speaker recognition means to 
make the second level decision. Finally the 
LLE classifier based on non-linear speaker 
features is designed to make the ultimate 
decision.  
 
For a database with 1500 Mandarin 
speakers, it is demonstrated in the 
experiment that the accuracy improvement of 
up to 4% and the computational cost saving 
of 25 times compared to those of the 
conventional GMM model can be achieved. 
 
References 
 
[1] Chih-Chien Thomas Chen, Chin-Ta 
Chen, and Chih-Ming Tsai, “Hard-
limited Karhunen- Loeve transform for 
text independent speaker recognition”, 
Electronics Letters, Vol. 33, pp. 2014-
2016, 1997 
 7
 
國科會補助專題研究計畫成果報告自評表 
請就研究內容與原計畫相符程度、達成預期目標情況、研究成果之學術或應用
價值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）、是
否適合在學術期刊發表或申請專利、主要發現或其他有關價值等，作一綜合評
估。 
1. 請就研究內容與原計畫相符程度、達成預期目標情況作一綜合評估 
█達成目標 
□ 未達成目標（請說明，以 100 字為限） 
□ 實驗失敗 
□ 因故實驗中斷 
□ 其他原因 
說明： 
 
 
2. 研究成果在學術期刊發表或申請專利等情形： 
論文：□已發表 □未發表之文稿 █撰寫中 □無 
專利：□已獲得 □申請中 █無 
技轉：□已技轉 □洽談中 █無 
其他：（以 100 字為限） 
 
 
3. 請依學術成就、技術創新、社會影響等方面，評估研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）（以
500 字為限） 
 
使用三段式語者辨識系統架構，能有效運用語者語音資料中同時隱含之線性
與非線性訊息。卡式轉換以線性特徵之優點，快速地篩選出第一段的少量候
選語者；再由高斯混合模型，挑出其中更吻合之第二段候選人，這樣的策略
可大量減少高斯混合模型所需的辨識時間；最後經由非線性之局部線性內嵌
特徵，來精密地確定第三段之最終語者。實驗結果顯示，系統不但具有一定
程度之技術創新，同時亦有相當之實際運用價值。 
 
 
 
附件二 
國科會補助計畫衍生研發成果推廣資料表
日期 2010年10月31日
國科會補助計畫
研發成果名稱
發明人
(創作人)
技術說明
技術移轉可行性及
預期效益
技術/產品應用範圍
產業別
計畫名稱:
計畫主持人:
計畫編號: 學門領域:
(中文)
(英文)
成果歸屬機構
(中文)
(英文)
三段式不特定語句大量語者辨識系統之設計與實作
陳志堅
98 -2221-E -110 -059 - 自然語言處理與語音處理
大廈門禁控管機制
Access Control Mechanism for Premises
國立中山大學 陳志堅
本技術透過三段式辨識機制，建立使用者之聲紋特徵資料庫，來作大廈門禁或
資訊安全系統之授權，以確定合法使用者身份。使用聲紋認證，將不需記憶密
碼，或隨身攜帶鑰匙、刷卡片；同時可避免密碼、鑰匙、卡片遭盜用與冒用之
風險。系統由於建立之三段式辨識機制，具有大量降低辨識時間與提升辨識率
之特性，因此能相當快速與正確地辨識使用者之身分。同時在系統之建置與使
用上，亦相當簡易，只需合法使用者讀入約三十秒之一般語料，即可完成訓練
過程；辨識授權時，使用人亦只需讀入約五秒之語料，即可判定身分。
This premises access control system is built by users’ voice
features.  It can greatly eliminate the need to memorize password, or
carry key/card to the system.
顧問服務業
大廈門禁系統，宿舍門禁系統，電腦登入系統
加入使用人之聲紋特徵資訊於電腦系統登入或門禁系統控管機制中，來執行確認與授
權之動作，將可大量降低記憶密碼，攜帶鑰匙或刷卡門卡片之不便及減少密碼和卡片
遭盜用與冒用之風險。
註：本項研發成果若尚未申請專利，請勿揭露可申請專利之主要內容。
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
科 
教 
處 
計 
畫 
加 
填 
項 
目 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
計畫成果推廣之參與（閱聽）人數 0  
 
