行政院國家科學委員會專題研究計畫成果報告 
多攝影機視訊監控與人物外貌辨識 
Human Appearance Identification Based on a Robust Multi-camera 
Surveillance System 
計畫編號：NSC － 99 － 2218 － E － 468 － 005 
執行期限：99 年 2 月 1 日至 99 年 11 月 15 日 
主持人：林智揚   
執行機構及單位名稱: 亞洲大學資訊工程學系 
 
[註]:本計畫內容已發表於國際會議: Chih-Yang Lin, Chao-Chin Chang, Wei-Wen Chang, Meng-Hui 
Chen, and Li-Wei Kang, "Real-Time Robust Background Modeling Based on Joint Color and 
Texture Descriptions," Proceedings of The Fourth International Conference on Genetic and 
Evolutionary Computing (ICGEC 2010), Shenzhen, China, December 13-15, pp. 622-625, 2010. 
 
 
 Abstract 
Background construction is the base of object detection and 
tracking for the machine vision system. Traditional 
background modeling methods often require complicated 
computations and are sensitive to illumination changes and 
shadow interference. In this paper, we propose a block-based 
background modeling method, which fully utilizes the color 
and texture characteristics of each incoming frame. The 
proposed method is quite efficient and is capable of resisting 
illumination changes and shadow disturbance. Experimental 
results show that our method is suitable for real-word scenes 
and real-time applications. 
Keywords-component; Background modeling; motion detection; 
Gaussian mixture modeling 
 
 中文摘要 
背景建立法是機器視覺系統中遺物動偵測與追蹤的基礎。傳統
背景建立法模型通常需要很複雜的計算量，並且容易受到光線
變化、雜訊、與陰影的干擾。在本篇論文中，我們提出一個以
區塊為基礎之背景模型建立法，對每一張攝像進來的影像，同
時擷取顏色與紋裡的資訊。我們所提的方法十分的有效率，並
且可以抵抗光線變化、雜訊、與陰影的干擾。實驗結果顯示我
們的方法非常適合應用於真實的監控環境。 
關鍵字：背景模型; 移動物偵測; 高斯混合模型 
 
計畫緣由及目的 
Object detection is a very important task in video 
surveillance. In general, background modeling is utilized for 
distinguishing between foreground and background. With a 
robust background model, the objects can then be 
successfully extracted from the background. 
In literature, a number of methods for detecting moving 
objects have been proposed, where many different features 
are employed for background modeling. The most 
frequently used features are based on color information. For 
example, a color statistical approach [13] accomplished 
background subtraction without being affected by shadow; 
furthermore, the algorithm is also implemented by a DM270 
iMX and DSP subsystem [9] for DV applications. In 
addition to the running statistics (e.g. average) of 
neighboring frames, a one-Gaussian adaptive modeling 
method is also a popular approach that can be found in [14].  
However, one-Gaussian modeling cannot cope with 
dynamic background changes. Therefore, the Gaussian 
mixture modeling (GMM) approach [11-12, 15] was 
developed by means of using more than one Gaussian model 
for each pixel. Pixel values that do not fit the model would 
be recognized as foreground areas. One of the examples 
using GMM was developed (three Gaussian) for traffic 
monitoring [4]. Other discussions on implementation using 
GMM can be found in [2] and [10], which provide details of 
Stauffer and Grimson’s algorithm [12]. 
Motion-based and edge-based methods are other 
approaches for background modeling. The motion-based 
method [13] utilizes optical flow to detect salient motion 
over frames. This approach usually suffers from 
complicated computations. The edge-based method [8] 
considers only edge information in frames and constructs 
edge histograms as a feature description for background 
modeling. The histogram-matching process determines the 
performance of this method. 
compared with the K bitmaps by the following similarity 
equation, where m is in the range of [1, K]: 
1 1
( , ) (
n n
new m
new m ij ij
i j
Sim BM BM b b
= =
= ∩∑∑ )
)
. (4) 
 
If is greater than a predefined 
threshold THD, the block BMnew matches BMm in the 
background model, and the update process will be invoked; 
otherwise, BMnew is regarded as a foreground block, and the 
unmatched process will be launched. The complexity of the 
above distance calculation is quite low since it requires only 
bit operations. 
max ( , )new mm Sim BM BM
The update and unmatched processes are derived from 
Stauffer and Grimson’s method [12]. When an incoming 
block is considered as a background block, the weights of 
the background model are updated by: 
 
' (1K K Kw M wα α= + − , (5) 
where α is the learning rate and Mk is 1 for the best-matched 
bitmap and 0 for the others.  
The learning rate determines the speed of adaptation. 
That is, larger learning rates result in faster adaptations. As 
to each bit of the best-matched bitmap BMm, the update 
rules are given in Eqs. (6) and (7). In Eq. (6), when t is 
greater than a predefined threshold T, t should be set to T to 
meet the self-adaptation requirement. 
m
ijb
' 1 1(1 )m mij ij ijp pt t
= − + newb
B
, where t represents the tth 
frame and =0 in the initial stage. mijp
(6) 
'
' 0,  if 0.5,
1,  otherwise.
m
ijm
ij
p
b
⎧ ≤⎪= ⎨⎪⎩
 (7) 
 
If the incoming block is a foreground block, the 
unmatched process replaces the bitmap that has the lowest 
weight in the background model with the incoming block. 
Then, the weight of the new block is set to a low initial 
weight of 0.01 in our experiments. Finally, the weights of 
the background model are renormalized in order to have a 
sum of one. 
In the above description, the incoming block may 
match the bitmap with a low weight and is regarded as a 
background block. However, the low weight means that the 
corresponding bitmap has a low probability of being a 
background block. To solve this problem, the weights of the 
background model are sorted in decreasing order, and only 
the first B bitmaps are selected as the background model, 
such that: 
 
1
B
i
i
w TH
=
>∑ , where THB is a predefined threshold. (8) 
C. Motion Detection Based on Joint Color and Texture 
Background Models 
The proposed method is to detect moving objects in the 
captured frames based on the constructed background 
models. In Section 3.2, we have proposed a texture-based 
background modeling method for moving object detection. 
However, a false negative may occur when the texture 
description of the moving object is similar to that of the 
background. Such a case can be greatly alleviated with the 
help of a color background model. The construction of a 
color background model for each block is done by using the 
Stauffer and Grimson’s algorithm [12], where the input for a 
block is the mean vector containing R, G, and B channel 
mean values calculated by Eq. (1), respectively. 
After the color background model is constructed, the moving 
objects can also be detected. The final result of motion 
detection is the intersection of CM and TM, where CM and 
TM represent the detection results using the color and texture 
models, respectively. 
 
4. 結果 
The performance of the proposed method is compared 
with two state-of-the-art approaches [5, 12] using several 
video sequences. The video sequences were acquired from 
real indoor and outdoor environments. The simulated 
environment for the experiments is equipped with a 1.8 GHz 
Core 2 Intel processor and 2 GB of memory. The image 
resolution was set to 320×240 pixels. All algorithms were 
implemented in C++. 
For the sake of labeling and segmenting the foreground 
pixels, the connected components algorithm [1, 7] is applied 
to each background modeling method. The parameters used 
in the experiments are listed as in Table 1, where α is the 
learning rate, THB is used in Eq. (10), K denotes the number 
of Gaussians, X represents the fact that the parameter is not 
required in this method, BS means the block size, and 
LBPP,R is only used in Heikkilä and Pietikäinen’s method 
[5-6] and represents using radius R to find P neighbors such 
as the example shown in Fig. 1(a).  
The performance comparisons of these three methods 
are presented in Table 2, where the last row denotes the 
connected components labeling (CCL) method that is also 
involved in the background construction. From this table we 
can observe that the proposed method is much faster than 
other methods because the proposed block-based approach 
requires only bit operations. Heikkilä and Pietikäinen’s 
method is slowest since they divide each frame into 
overlapping blocks, and the size of the LBP histogram 
significantly affects the performance. 
Figs. 3 and 4 show the indoor scenes with some 
illumination changes, where people were walking towards 
the camera. The detection results can be observed that 
Stauffer and Grimson’s method [12] is very sensitive to 
illumination changes, and Heikkilä and Pietikäinen’s method 
[5-6] also suffers from noise interference. On the contrary, 
 
Methods Stauffer and Grimson’s method 
Heikkilä and Pietikäinen’s 
method Proposed method 
Frame rate 20.94 3.54 57.55 
Frame rate with CCL 20.01 3.38 45.32 
 
    
(a) (b) (c) (d) (a) (b) (c) (d) 
Fig. 3. Detection results of the first sequence: (a) original image, (b) 
Stauffer and Grimson’s method, (c) Heikkilä and Pietikäinen’s method, and 
(d) proposed method. 
Fig. 4. Detection results of the second sequence: (a) original image, (b) 
Stauffer and Grimson’s method, (c) Heikkilä and Pietikäinen’s method, and 
(d) proposed method. 
 
   
(a) (b) (c) (a) (b) (c) (d) 
Fig. 5. Detection results of the third sequence: (a) original 
image, (b) Stauffer and Grimson’s method, and (c) proposed 
method. 
Fig. 6. Detection results of the fourth sequence: (a) original image, (b) Stauffer and 
Grimson’s method, (c) proposed method, and (d) proposed method with morphology.
 
出席 2010 年第 5 屆 International Conference 
on Broadband and Wireless Computing, 
Communication and Applications 報告 
 
報告人：林智揚 
亞洲大學資訊工程學系 助理教授 
TEL：(04)23323456 轉 20102 
FAX：(4)23320718 
E-mail：andrewlin@asia.edu.tw 
 
一、緣由 
 
BWCCA 2010(International Conference on Broadband and Wireless Computing, 
Communication and Applications)已舉辦五年之久，今年在日本福岡的福岡工業大
學舉辦。 
此 Conference 從 182 篇投稿論文中接受了 53 篇論文，主軸主要針對網路應
用等議題進行討論，包括網路安全、多媒體安全，無線網路、異質性網路等議題。
由於網路的普及，目前電腦的使用大部分已跟網路世界密不可分，探討網路上相
關的研究與議題，有其必要性。BWCCA 會議每年舉行一次，其目的就是讓電腦
專家們共同參與討論他們的研究成果。今年是五屆，很幸運地，今年我們的論文
被接受並應邀參加，除了發表最近的研究成果外，也聽取了相關領域教授們所提
出的研究報告 
 
二、參加會議經過 
今年的第5屆 International Conference on Broadband and Wireless Computing, 
Communication and Applications (BWCCA 2010)是由日本福岡的福岡工業大學主
辦。本次會議，在日本福岡的福岡工業大學舉行。此次會議投稿的論文篇數共有
182篇文章，最後錄取的文章篇數53篇，錄取率低於30%。為了確保論文的品質，
每篇文章均經由3位以上的議程委員仔細評審過，整個審查制度可以說是相當地
嚴謹。我們的論文被安排在此會議下之 International Workshop on Cloud, Wireless and 
E-Commerce (CWECS 2010)中。 
本會議可以說是一個非常盛大的國際學術研討會，會議日程從 2010 年 11 月
4 日至 11 月 6 日。參加會議的人數很多，他們來自各個不同的機構，有學術機
構、研究機構、產業機構、政府機構。從第一天開幕起就十分熱鬧，到最後一天
仍有不少人參與會議的研討，可以說是相當成功的一次國際學術會議。會議的論
國科會補助計畫衍生研發成果推廣資料表
日期:2011/01/09
國科會補助計畫
計畫名稱: 多攝影機視訊監控與人物外貌辨識
計畫主持人: 林智揚
計畫編號: 99-2218-E-468-005- 學門領域: 圖形辨識
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
擔任 The Fourth International Conference on Genetic and Evolutionary 
Computing (ICGEC 2010)國際會議之 Session Chair 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
