2 
 
HDRI 豐富亮麗的影像畫面以 LDRI 的格式表現，再利用色調再現的技術做後處
理，一方面提高影像的對比度，二來節省頻寬，創造出利用低位元的顯示器就能
播放如同高位元對比的影像。如此一來，在現有傳統的顯示器上便能夠輸出逼真
的 LDRI；未來當 HDR 顯示器普及後，一樣能夠利用相同技術，重建出高動態
比的 HDRI，這是我們本計畫的主要目的。圖 1 為本計畫基本概念架構圖，我們
將琢磨於四個黃色的區塊做深入的研究。 
 科技的發展十分迅速，從早期的幻燈片發展到黑白電視，再演進到彩色電
視，人類對影像品質的需求愈來愈高，因此高動態影像所帶來更逼真的影像世界
必然是未來的趨勢！ 
 
 
圖 1. 本計畫基本概念架構圖 
三、文獻探討 
在真實世界中，人眼所能捕捉的亮度範圍 (Luminance Range)，從極亮到極
暗 ( 68 10~10 − 燭光/每平方公尺， 2/ mcd ) 的動態範圍變化甚大，即使在一瞬間
人眼也能感受到 510 的動態範圍。其中，動態範圍的定義為可見光之最大值除上
可見光之最小值。以傳統 CRT 螢幕而言，我們只能看見 1:100  甚至更低 1:50  
的對比度。由於傳統顯示器的限制，使得一般影像的資訊只能以 RGB 或者 
YCbCr 規格三個通道各 8 位元 (色階 0～255，共 256 階) 的數位影像儲存。真
實世界的影像涵蓋了高動態範圍的色彩資訊，但經過相機拍攝並轉換成影像檔案
後，我們在螢幕上只能看見 0～255 的色彩資訊，如圖二所示。與可見光的動態
範圍相較之下，我們稱 0～255 的資訊為低動態範圍影像 (Low Dynamic Range 
Image, LDRI)。 
z 色調對映 
 現今的顯示器還無法普遍支援 HDRI 的影像格式，因此如何將高動態範圍的
影像以低動態範圍的影像顯示並且保留高動態影像獨特之特徵是一重要的課
題。因此便有了色調再生 (Tone Reproduction)以及色調對映的技術  (Tone 
Mapping)，色調對映技術可概分為以下三類， 
    1.全域色調對映(Global Tone Mapping) 
高動態影像序列 
色調對映 
可調性編碼 
傳
輸 
可調性解碼 
色調再現 
高動態影像序列 
低動態影像序列 
低動態影像 
低動態影像 
4 
 
議題。接下來介紹幾種反色調對映的方法[1]： 
1. 線性轉換（linear scaling）：其中 x 為輸入的低位元資料，直接乘上原本
高、低位元間的差異即可得到反色調對映轉換後的值 y，例如高位元 M
為 10，低位元 N 為 8，輸入的 x 直接乘以 4 倍即可得到 y，但必需注意
y 的值域不得超過 1210 − 。 
                          ( )12,2min −= − MNM xy                    （1） 
2. 線性內插（linear interpolation）：給定範圍 ),( nn yx 與 ),( 11 ++ nn yx 之後，根
據公式 2.2 進行內插的動作，因此給定的範圍關係著 x 透過內插後的值，
範圍大則內插後的數值較粗略，範圍小則內插後數值精密，不過仍需注
意 y 的值域。 
                   
⎟⎟⎠
⎞
⎜⎜⎝
⎛ −−−
−+=
≤≤
+
+
+++
12),(min
)()(
1
1
11,1,
M
nn
nn
n
n
nnnnnn
yy
xx
xxyy
xxxyxyxgiven
           （2） 
3. 對照表格（look-up table mapping）：這是最為普遍的反色調對映方法，
在編碼端執行色調對映技術時便同時把對映前、後的像素值紀錄下來，
而且同時加入編碼程序成為之後接收端可以參考的資訊（ side 
information）。 
 
z 色調再現 
    色調再現是將低動態範圍的影像，經由後處理，得到對比度強烈、色彩鮮艷，
更逼近我們的高動態影像表現的技術。由於高動態影像得來不易，因此眾多學者
也紛紛研究這塊領域，希望由低動態影像就能呈現如高動態影像的表現，本計畫
也希望利用此技術，將我們色調對映且經過編解碼後的影像，利用此技術來加強
色彩的對比度。 
 
四、研究方法 
    圖 1 為本計畫基本概念架構圖，有三個研究重點，分別為:色調對映、色調
再現與位元深度可調性編碼技術。 
    於色調對映技術方面，首先我們先將高動態影像等比例分成三個區段 A、B、
C，再計算三個區段的像素值出現的機率，如 A 機率最大，則表示此影像偏暗，
如 B 機率最大，則表示此影像亮度適中，如 C 機率最大，則表示此影像偏亮。
針對不同的影像特性給予不同的色調對映方程式。當區域 A 最大時，先將高動
態影像的像素值正規化成 [0,1]，再等份分成三個區段，每個區段大小為
1 1 2 2( 0 ~ , ~ , ~ 1)
3 3 3 3
A B C= = = ，且給 A、C 兩段不同的參數α ，其色調對映方
6 
 
圖 4.  色調對應之 S 型曲線 
 區域 C 最大時，先將高動態影像的像素值正規化成[0,1]，再等份分成三個區
段，每個區段大小為 1 1 2 2( 0 ~ , ~ , ~ 1)
3 3 3 3
A B C= = = ，且給 A、C 兩段不同的參
數 β ，其色調對映方程式為公式(4.3)。 
                       1.1, 1.4L H
β β= =                 (5) 
其中 L 為低動態影像像素值，H 為高動態影像像素值，A 區域給予的 β 為 1.1、
C 區域給予的 β 為 1.4、而 B 區域則是 1.11( )
3
到 1.42( )
3
這兩點的線性方程式最後再
乘上 255 即為我們的低動態影像，圖 5 為公式(5)的對照圖。 
 
圖 5. 公式(5)色調對映之曲線 
    當影像的像素值偏亮時，則給予像素值大的區段較多的資源，隨著像素值越
小，給予的資源則越少。 
 以上我們的色調對映都只考慮到空間上的問題，沒有考量到時間的連續性，
當一序列的高動態影像做色調對映時，會因為輸入影像的像素值不同而給予不同
的方程式，因此色調對映為非線性的關係，輸出的影像就可能會發生不連續性，
為了避免這個問題，我們將時間上的關聯性納入考量。參考文獻[2]的做法如圖 6。 
 
圖 6. 色調對映參考時間關係之示意圖 
 ( , , 1)x yH x v y v t− − − 與 ( , , )H x y t 是不同時間的高動態範圍影像區塊，
1.1α =
1.4α =
8 
 
影像層的序列先經過 SVC 的 I-frame 編碼，得到的冗餘資料在經過 DCT 轉換、
量化後，經過編碼後輸入到多工器，而 Reconstruction 則儲存反量化、反 DCT
之後的重建 I-frame。高動態影像層除了原先畫面內 (Intra)預測 4*4 的 9 種預測
模式，與 16*16 的 4 種預測模式，還多了一個從低動態影像層重建的影像經過反
色調對映的參考源，我們稱為 IPLB (Intra Prediction from Low Bit-depth)，以增加
高動態影像層的編碼效率，反色調對映的演算法則基於最小均方誤差的方法，最
後高低動態影像的位元流都進入多工器之後傳輸。  
 
圖 8. 位元深度可調性之 I-frame 編碼流程 
 圖 9 說明我們的畫面間 (Inter)預測的演算法，與 I-frame 架構圖相同，左邊
是低動態影像層，右邊是高動態影像層。高動態範圍影像先經過色調對映後成為
低動態範圍影像，在經過 SVC 的 P-frame 編碼，得到的冗餘資料在經過 DCT 轉
換、量化後，經過編碼後輸入到多工器，而 Reconstruction 則儲存反量化、反 DCT
之後的重建 P-frame。而高位元層除了原先 4 個區塊大小為 16*16 和 16 個區塊大
小為 4*4 的 intra prediction mode，和 16*16、16*8、8*16、8*8、8*4、4*8、4*4，
七種區塊大小的 inter prediction mode 外，還多了兩個預測源，第一個是低位元
層重建的 P-frame 經過反色調對映成為高位元層的一參考源，我們稱為 IPLB 
(Intra Prediction from Low Bit-depth)，另一個參考源是低位元層做完 inter 
prediction 後的冗餘值，經過反量化，反 DCT 轉換在經過反色調對應，和高位元
層的原始圖做相減，相減完的影像再進入 inter prediction 做預測，之後從四種預
測源選擇RD cost最小的進行編碼，最後高低位元層的位元流都進入多工器傳輸。 
 Residual prediction 除了我們提出的先將輸入的高動態影像與低動態影像編
Tone 
mapping 
Transformation 
and 
quantization 
Entropy 
Encoding 
Reconstruction
Intra  
Prediction 
Transformation 
and 
quantization 
Entropy 
Encoding 
Inverse 
Tone 
Mapping 
IPLB Intra  
Prediction 
Reconstruction
Intra frame 
High bit depth layer Low bit depth layer 
MUX
Scalable Bit-stream 
10 
 
基礎層的冗餘值依照層間大小比例放大，將原始的加強層影像與其相減後做移動
搜尋，而我們將放大地方改變反色調對映，給予高位元層做相減。 
五、結果與討論 
1. 色調對映之結果 
    做色調對映首先要先取得高動態的影像，我們利用軟體 Photomatix Pro[4]幫
助我們取得高動態的影像，將多張不同曝光時間的 LDRI 輸入，便能產生出一張
高動態影像。圖 10 是參考論文[5]直方圖等化 (Histogram Equalization)為基礎的
色調對映結果，可看出效果較優於前述兩種方法，但左圖右下角較暗部分區域其
細節已喪失，窗外的部分則是過亮，右圖則是室內影像可分辨出來，但窗外的影
像則過亮。 
 
圖 10. 論文[6]色調對映之結果 
 圖 11 為我們所提出色調對映的結果，由於考慮影像的像素值分布，則給與
相對的色調對映方程式，可看出效果較優於其他種方法，左圖窗外部份的景像清
晰可見，椅子的色彩也凸顯出來，右圖中窗外的景象也比較自然，椅子也不會過
度曝光。 
  
圖 11.  提出之色調對映之結果 
2. 色調再現之結果 
12 
 
single layer，當量化參數越小，影像品質則越佳，但是其位元率越大，simulcast
表示高低位元層沒有互相參考，獨立自己編碼，因此編碼效率最差，single layer
則是只有高位元層的資料，因此 bitrate 最少。 
 
(a) sunrise  
 
 (b) library 
圖 13. I frame 之編碼效益比較 
z I+P frame 實驗結果 
   接下來我們要討論提出架構加入 P frame 之後的跨層級預測結果，實驗如圖
14，GOP 分別為 4、8、16。 
14 
 
 
 (c) sunrise (GOP=8) 
 
  (d) library (GOP=8) 
16 
 
Residual QP 24 QP 28 QP 32 QP 36 QP 40 
Sunrise 39.10% 36.71% 30.70% 28.86% 25.30% 
Library 39.90% 36.76% 32.99% 28.93% 26.16% 
 由表 3 可得知，在編碼過程中，依據不同的量化參數，會有不同的結果，會
參考我們所提出的 IPLB 預測模式約 1.14%~12.31%，利用 RPME 預測模式約有
6.24%~9.37%，而利用 Residual 預測模式約有 26.16%~39.90%，總共約 31%~49%
會參考我們所提出的預測源。其他的 51%~69%是採用原先 JSVM P frame 的參考
模式。由圖 14 可看出其資料量都比不參考低位元層資訊的 simulcast 少。由 RPME
與 Residual 兩者被參考的機率可看出，將高動態影像層的殘餘值再減去反色調轉
換後的低動態影像層的殘餘值，比高動態影像層的原始影像先減去反色調轉換後
的低動態影像層的殘餘值再做移動估測被參考的機率來的大。 
 
圖 15.不同 QP 下，高低動態影像(Library)之位元數比率(GOP=4) 
 圖 15 為不同 QP 下，12 bit 的高態影像與 8 bit 的低動態影像之位元數比率，
就未壓縮的影像而言，高動態影像的資料量約為低動態影像的 16 倍。QP 24 的
高低動態層的位元數比約為 4:1，QP40 的位元數比為 16:1，由於高動態影像的資
料量相當大，當高位元層在低 QP 時，壓縮率比低位元層來的佳；在高 QP 時，
兩者資料量的壓縮率則差不多。 
 
六、結論 
    在本計劃中，我們提出了色調對映，色調再現與位元深度可調之視訊編碼。
以往的色調對映鮮少有根據影像像素值分布給予適當的方法，而我們是根據影像
的特性給予不同的色調對映方程式，如影像偏暗或偏亮，依據其影像的像素值分
布給予適當的色調對映法。 
國科會補助專題研究計畫項下出席國際學術會議心得報告 
                                     日期： 100 年 01 月 10 日 
                                                             
 
一、 參加會議經過 
ISCAS 是電路與系統領域最大的國際會議，而這是本人第一次參加此國際研討會。此會議今年的
論文的接受率約為 44%，其中 regular paper 的投稿量 共有 2058 篇，而接受發表的有 905 篇。此會議
的規模頗大，總共包含 16 個 track。此外，大會另外安排 9 場的 tutorial 與 3 場 keynote lecture，整個
會議的內容十分豐富。 
    大會的第一天 5/30 包含開幕式和 9 場的 tutorial。而本人論文的發表時間被安排在第二天 5/31 上
午 9:30-11:00 的 Video Coding: SVC/MVC/DVC (lecture) 此時段，並由本人大學部專題生周起如同學
(共同作者之一)負責發表。剛好此 session 的議題便是本人平時的研究領域，所以對於所有此 session
的論文發表極感興趣。此 session 的 chair man 為成功大學黃悅民教授，此為本人與他的第一次會面，
雙方交換名片後不久，會議即開始。此 session 共安排四篇論文發表，我們的論文是第四篇，同屬這
時段的論文發表還包含台大陳良基教授與交大杭學鳴教授的論文，這兩篇論文也分別由他們所指導的
博士班學生負責發表。台大陳良基教授的論文探討如何加強合成影像的品質，屬於 MVC 的領域；而
杭學鳴教授的論文則是探討如何加速時間可調性視訊編碼的速度，屬於 SVC 的領域。而我們的論文
則是提出以區塊為單位的分散式視訊編碼架構，並討論如何做有效的區塊模式選擇，屬於 DVC 的領
域。當周起如同學報告完畢時，杭學鳴教授以及當場一位與會者分別有問題提問，此時就由本人負責
回答。整體而言，論文發表的過程很順利，也達到訓練學生英文發表論文的目的。 
    之後，本人便隨即參加 11:20-12:50 的 Encoder Optimization 此 session，其中的論文大多與如何達
到編碼的優化有關。其中第三篇為台大陳宏銘教授的論文，探討以視覺感受為主的模式選擇，由其博
士班學生負責發表。中午休息後，下午我所參與的 session 包含“Multimedia Coding I＂與“Advanced 
Video Coding I＂。 
    接下來的兩天，我所參與的 session 包含“Multimedia Coding I＂、“Multimedia Technologies＂ 
“Special Session: New Video Technologies＂、“Special Session: Directional Transform for Image 
Coding＂ 、“Video Coding & Communication＂以及“Advanced Video Coding II＂。大體而言，本次
會議的參與讓本人除了對許多已經在做的研究有更深一層的了解之外，最大的收穫是得到一些以前沒
有的新觀念。 
計畫編號 NSC 98－2221－E－194－040－ 
計畫名稱 結合空間可調性與位元深度可調性的視訊編碼技術之研究 
出國人員
姓名 江瑞秋 
服務機構
及職稱 
國立中正大學電機系助理教授 
會議時間 99 年 5 月 30 日至 99 年 6 月 2 日 會議地點 
法國  巴黎 
會議名稱 The IEEE International Symposium on Circuits and Systems (ISCAS) 
發表論文
題目 Block-based Distributed Video Coding with Variable Block Modes 
國科會補助計畫衍生研發成果推廣資料表
日期:2011/01/10
國科會補助計畫
計畫名稱: 結合空間可調性與位元深度可調性的視訊編碼技術之研究
計畫主持人: 江瑞秋
計畫編號: 98-2221-E-194-040- 學門領域: 訊號處理
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
