可供推廣之研發成果資料表 
V 可申請專利  V 可技術移轉                                      日期：99年 10 月 4日 
國科會補助計畫 
計畫名稱：多目標車牌即時辨識系統 
計畫主持人：郭景明         
計畫編號：NSC 98－2622－E－011－009－CC3 
學門領域：圖形辨識 
技術/創作名稱 多車牌辨識系統 
發明人/創作人 郭景明、劉雲夫 
技術說明 
中文：車牌辨識是智能交通系統的一個重要組成部分。在本計畫
中，提出了一種針對高解析影像的基於小波轉換的多車牌辨識系
統。擬議的系統包括四個主要階段。首先，基於對稱遮罩的離散
小波轉換被提出來進一步提高處理效率，且階層式的 AdaBoost 車
牌偵測方法也被提出來解決多車牌的檢測問題。對於字元分割部
分，其以投影為基礎且同時參考到字元之間的相關性。最後字元
辨識部分，13 種不同特徵配合貝式分類器來進行處理。實驗結果
表現出良好的車牌定位、字元分割、字元辨識之性能，其各自成
功率為 92.5％，95.2％和 98.23％。此外，針對大小為 4288x 2848
的影像處理速度是 5 fps。 
 
關鍵詞: 車牌辨識、字元辨識、圖像辨識、Adaboost、小波轉換 
英文：License plate recognition is a key component of intelligent 
transportation systems. In this paper, a wavelet-based method for 
multiple license plates recognition system is proposed for high 
resolution applications. The proposed system consists of four major 
stages. First, the Symmetric Mask-based Discrete Wavelet Transform 
(SMDWT) method is proposed for further improving the processing 
efficiency. Then, a Hierarchical AdaBoost (HA) is also proposed for 
multiple license plates detection, which leads less training time than 
that of the traditional AdaBoost. For the character segmentation, a 
projection-based method is used, which takes the relationships among 
characters into consideration. Finally, a Bayesian-based method with 
13 different features is adopted for character recognition. The 
experimental results demonstrated good performance in terms of 
license plate localization, character segmentation, and character 
recognition rates of 92.5%, 95.2% and 98.23%, respectively. 
Moreover, the processing speed is five fps for frames of size 
4288x2848. The performance ensures that the proposed method can be 
applied to vehicle technology operations multiple toll station in a 
freeway and transportation management applications. 
 
Keywords: License plate recognition, character recognition, pattern 
recognition, AdaBoost, wavelet transforms. 
附件二 
摘要 
車牌辨識是智能交通系統的一個重要組成部分。在本計
畫中，提出了一種針對高解析影像的基於小波轉換的多
車牌辨識系統。擬議的系統包括四個主要階段。首先，
基於對稱遮罩的離散小波轉換被提出來進一步提高處理
效率，且階層式的 AdaBoost 車牌偵測方法也被提出來解
決多車牌的檢測問題。對於字元分割部分，其以投影為
基礎且同時參考到字元之間的相關性。最後字元辨識部
分，13 種不同特徵配合貝式分類器來進行處理。實驗結
果表現出良好的車牌定位、字元分割、字元辨識之性能，
其各自成功率為 92.5％，95.2％和 98.23％。此外，針對
大小為 4288x 2848 的影像處理速度是 5 fps。 
 
關鍵詞: 車牌辨識、字元辨識、圖像辨識、Adaboost、
小波轉換 
 
ABSTRACT 
License plate recognition is a key component of intelligent 
transportation systems. In this paper, a wavelet-based 
method for multiple license plates recognition system is 
proposed for high resolution applications. The proposed 
system consists of four major stages. First, the Symmetric 
Mask-based Discrete Wavelet Transform (SMDWT) method 
is proposed for further improving the processing efficiency. 
Then, a Hierarchical AdaBoost (HA) is also proposed for 
multiple license plates detection, which leads less training 
time than that of the traditional AdaBoost. For the character 
segmentation, a projection-based method is used, which 
takes the relationships among characters into consideration. 
Finally, a Bayesian-based method with 13 different features 
is adopted for character recognition. The experimental 
results demonstrated good performance in terms of license 
plate localization, character segmentation, and character 
recognition rates of 92.5%, 95.2% and 98.23%, respectively. 
Moreover, the processing speed is five fps for frames of size 
4288x2848. The performance ensures that the proposed 
method can be applied to vehicle technology operations 
multiple toll station in a freeway and transportation 
management applications. 
 
Keywords: License plate recognition, character recognition, 
pattern recognition, AdaBoost, wavelet transforms.  
 
INTRODUCTION 
License Plates Recognition (LPR) normally integrates 
various technologies to automatically deal with the license 
plates. This system can be mainly separated into three parts: 
1) detecting the location of the License Plate (LP), namely 
License Plate Localization (LPL); 2) segmenting the 
characters inside the LP, namely Character Segmentation 
(CS), and 3) recognizing the meaning of the characters, 
namely Character Recognition (CR). Many state-of-the-art 
methods [1]-[16] have been addressed in the progress of the 
LPR systems, and some of them have also been marketed. 
Regarding the LPL, in general, the literatures can be 
separated into two parts: 1) based on the textures of the LP 
and 2) based on the colors of the LP. The two types of 
methods are discussed below.  
The methods based on the textures mainly exploited the 
aspect ratio [1]-[3], the contrast variations [4], the uniform 
distribution of the characters [5], the ratio between 
background area and character area [6]-[7]. Among these, 
the approaches in [1] and [3] are applied to the LPR in Saudi 
Arabia. The main idea is to process the image with the 
grayscale image, and employ the Sobel edge detection, 
projection, and seed-filling algorithms [8] to remove the 
regions unrelated to the LP. The result is then filtered by 
aspect ratio and object connections. However, the method is 
not capable of dealing with the complex environment and 
rotation. Nonetheless, the rotation problem can be eased by 
considering the rotation extent [2]. Wu et al. [7] adopted the 
morphological and projection to localize a LP. The method 
exploited the ratio between background area and character 
area, and used the opening operation to blur the image. The 
processed image is compared to the original image. The 
discrepancy part is then processed with the projection 
method to locate the LP. The advantage of this method is its 
high efficiency, while the disadvantage is easily undergone 
the interference of the lighting effect. The methods based on 
the colors are discussed as follows: Jia et al. [6] adopted 
mean shift to blur the image, and then localized the LP via 
applying Mahalanobis distance linear classifier to classify 
the candidate regions according to the rectangularity, aspect 
ratio, and edge density. Syed et al. [9] adopted the vector 
angle measure [10] to retrieve the color edge, and then 
enhanced the edge. The object connection is applied to the 
classified regions separated by the edges and further locates 
the LP. Chang et al. [11] converted the RGB color space to 
HSI model and then performed the blurring processing to 
reduce the interference of the noise. The clustered-edge 
property of the LP is exploited to cooperate with the HSI 
color spaces to locate the LP. The advantage of this method 
is capable of withstanding the interference of the 
environment. A learning-based framework has been 
proposed in [16] to zoom in the digits in a license plate. 
Yang et al., [12] simultaneously adopted textures and colors 
to locate the LP, in which the color collocation of the plate‟s 
background, characters, and the plate‟s structure are 
exploited. The plate‟s region is then binarized, segmented 
and recognized. The advantage is its high efficiency and 
good localization result. The disadvantage is vulnerable in 
dealing with low contrast or poor color. In Rastegar et al. 
[14], concept of enhancing the low resolution image was 
involved to increase processing speed for better extraction of 
characters.  
According to the above discussions, most schemes are 
dedicated on some specific conditions, such as single vehicle 
license plate, low resolution image size, various lighting 
condition, unstable environment, and low recognition time. 
In this study, high-resolution sources are considered for 
multiple license plates recognition application. This type of 
source is required since the low-resolution sources employed 
in former works [5], [15] cannot provide sufficient 
information for some applications, such as shown in Fig. 1. 
This figure demonstrates that when multiple license plates 
are shown in a single frame, the size of a LP is relatively too 
small compared to the size of a frame. Adopting high-
resolution sources becomes a trend on this application, yet 
which also accompanies the shortcoming of long processing 
time. To cope with this, the Symmetric Mask-based Discrete 
Wavelet Transform (SMDWT) is proposed to reduce the 
frame size without losing two much high-frequency energy. 
In addition, the Hierarchical AdaBoost (HA) is proposed to 
detect LPs on various situations. This method requires much 
object (compact energy) and reduce resolution. The 
proposed LL band-mask method is introduced step by step 
in follows. 
According to the 2-D 5/3 LDWT [18], the LL-band 
coefficients of the SMDWT can be expressed as follows: 
LL(i,j)=(9/16)x(2i,2j)+(1/64)∑1u=0∑
1
v=0x(2i-2+4u,2j-
2+4v)+(1/16)∑1u=0∑
1
v=0x(2i-1+2u,2j-1+2v)+(-
1/32)∑1u=0∑
1
v=0x(2i-1+2u,2j-2+4v)+(-
1/32)∑1u=0∑
1
v=0x(2i-2+4u,2j-
1+2v)+(3/16)∑1u=0[x(2i-1+2u,2j)+P(2i,2j-1+2u)]+(-
3/32)∑1u=0[x(2i-2+4u,2j)+x(2i,2j-2+4u)].   (10) 
The mask as shown in Fig. 4 can be obtained via (10), 
where α = -1/32, β = 1/64, γ = 1/16, δ = -3/32, ε = 3/16, and 
δ = 9/16. The complexity of the SMDWT is further reduced 
by employing the symmetric feature of the mask. First, the 
initial horizontal scan LL(0,0). The next coefficient can be 
calculated as LL(0,1). where the variable XMH+1 denotes the 
repeated part after the first horizontal coefficient. The 
general form of the first horizontal step can be expressed as: 
LL(i,1)=β×x(i,j+2)+δ×x(i,j+4)+α×x(i,j+5)+β×x(i,j+6)+α×x(i
+1,j+2)+ε×x(i+1,j+4)+γ×x(i+1,j+5)+α×x(i+1,j+6)+
δ×x(i+2,j+2)+δ×x(i+2,j+4)+ε×x(i+2,j+5)+δ×x(i+2,j
+6)+α×x(i+3,j+2)+ε×x(i+3,j+4)+γ×x(i+3,j+5)+α×x
(i+3,j+6)+β×x(i+4,j+2)+δ×x(i+4,j+4)+α×x(i+4,j+5)
+β×x(i+4,j+6)+XMH+1,                       (11) 
where i = 0~N-1, and  
XMH+1=α×x(i,3)+γ×x(i+1,3)+ε×x(i+2,3)+ 
γ×x(i+3,3)+α×x(i+4,3).                   (12) 
The next coefficient can be calculated as LL(0,2). where the 
variable XMH+n denotes the repeated part after the second 
horizontal coefficient. From LL(0,2), the general form can 
be expressed as: 
LL(i,j+2)=δ×x(i,2j+6)+α×x(i,2j+7)+β×x(i,2j+8)+ε×x(i+1,2j
+6)+γ×x(i+1,2j+7)+α×x(i+1,2j+8)+δ×x(i+2,2j+6
)+ε×x(i+2,2j+7)+δ×x(i+2,2j+8)+ε×x(i+3,2j+6)+γ
×x(i+3,2j+7)+α×x(i+3,2j+8)+δ×x(i+4,2j+6)+α×x
(i+4,2j+7)+β×x(i+4,2j+8)+XMH+n,          (13) 
where i = 0~N-1, j = 0~N-2, and 
XMH+n=×x(i,2j+4)+α×x(i,2j+5)+α×x(i+1,2j+4)+γ×x(i+1,2j+
5)+δ×x(i+2,2j+4)+ε×x(i+2,2j+5)+α×x(i+3,2j+4)+γ×x(i+3,2j
+5)+β×x(i+4,2j+4)+α×x(i+4,2j+5).                 (14) 
The vertical scan can be done in the same way, where 
LL(0,0) is the same as that horizontal in LL(0,0). The next 
coefficient can be calculated as LL(1,0). Next, the initial 
vertical scan is calculated by the method similar to that of 
LH SMDWT, where the variable XMV+1 denotes the 
repeated part after the vertical first coefficient. The general 
form of the first vertical step can be expressed as: 
LL(1,j)=β×x(2i,j)+α×x(2i,j+1)+δ×x(2i,j+2)+α×x(2i,j+3)+β×
x(2i,j+4)+δ×x(2i+4,j)+ε×x(2i+4,j+1)+δ×x(2i+4,j+2
)+ε×x(2i+4,j+3)+δ×x(2i+4,j+4)+α×x(2i+5,j)+γ×x(2
i+5,j+1)+ε×x(2i+5,j+2)+γ×x(2i+5,j+3)+α×x(2i+5,j
+4)+β×x(2i+6,j)+α×x(2i+6,j+1)+δ×x(2i+6,j+2)+α×
x(2i+6,j+3)+β×x(2i+6,j+4)+XMV+1,              (15) 
where i = 0, j = 0~N-1, and 
XMV+1=α×x(3,j)+γ×x(3,j+1)+ε×x(3,j+2)+γ×x(3,j+3)+α×x(3,
j+4).                                         (16) 
Next, the second vertical scan is calculated by the method 
similar to that of LH SMDWT. 
LL(i+2,j)=δ×x(2i+6,j)+ε×x(2i+6,j+1)+δ×x(2i+6,j+2)+ε×x(2i
+6,j+3)+δ×x(2i+6,j+4)+ε×x(2i+7,j+2)+γ×x(2i+7,
j+1)+ε×x(i,2j+7)+γ×x(2i+7,j+3)+α×x(2i+7,j+4)+
β×x(i,2j+8)+α×x(2i+8,j+1)+δ×x(2i+8,j+2)+α×x(
2i+8,j+3)+β×x(2i+8,j+4)+XMV+n,          (17) 
where i = 0~N-1, j = 0~N-2, and 
XMV+n=β×x(2i+4,j)+α×x(2i+4,j+1)+δ×x(2i+4,j+2)+α×x(2i+
4,j+3)+β×x(2i+4,j+4)+β×x(2i+5,j)+γ×x(2i+5,j+1)+
ε×x(2i+5,j+2)+γ×x(2i+5,j+3)+α×x(2i+5,j+4).  (18) 
Finally, the diagonal oriented scan can be derived as: 
LL(1,1)=β×x(2,2)+α×x(2,5)+β×x(2,6)+δ×x(4,4)+ε×x(4,5)+α
×x(5,2)+ε×x(5,4)+γ×x(5,5)+α×x(5,6)+β×x(6,2)+δ×
x(6,4)+α×x(6,5)+β×x(6,6)+XMD+1,          (19) 
where the variable XMD+1 denotes the repeated part after the 
first diagonal scan. 
Next the HL(2,2) is calculated as: 
LL(2,2)=ε×x(6,5)+δ×x(6,6)+ε×x(6,7)+γ×x(7,5)+ε×x(7,6)+γ
×x(7,7)+α×x(7,8)+α×x(8,5)+δ×x(8,6)+α×x(8,7)+β×
x(8,8)+XMD+n,                          (20) 
where the variable XMD+2 denotes the repeated part after the 
first diagonal scan. The variable XMD+1 denote the repeated 
part after the first diagonal scan. The general form of XMD+n 
can be expressed as: 
XMD+n=β×x(2i+6,2i+6)+α×x(2i+6,2i+7)+δ×x(2i+6,2i+8)+α
×x(2i+6,2i+9)+β×x(2i+6,2i+10)+α×x(2i+7,2i+6)+
γ×x(2i+7,2i+7)+ε×x(2i+7,2i+8)+γ×x(2i+7,2i+9)+
α×x(2i+7,2i+10)+δ×x(2i+8,2i+6)+ε×x(2i+8,2i+7)
+δ×x(2i+8,2i+10)+α×x(2i+9,2i+6)+γ×x(2i+9,2i+7
)+β×x(2i+10,2i+6)+α×x(2i+10,2i+7).       (21) 
The general form of the rest part can be expressed as: 
LL(i+1,j+1)=δ×x(2i+8,2i+8)+ε×x(2i+8,2i+9)+ε×x(2i+9,2i+8
)+γ×x(2i+9,2i+9)+α×x(2i+9,2i+10)+δ×x(2i+1
0,2i+8)+α×x(2i+10,2i+9)+β×x(2i+10,2i+10)+
XMD+n,                                           (22) 
where i = 1~N-1, j = 1~N-1. 
The performance of the proposed 2-D 5/3 SMDWT is 
evaluated in terms of its complexity and practical execution 
time. The discussion above shows that the complexity of the 
proposed SMDWT can be significantly reduced by 
exploiting the symmetric feature of the masks, and the four-
matrix frameworks, HH, HL, LH, and LL can be 
individually employed for any specific applications. Table I 
shows the analysis results of the complexity between the 
conventional 2-D Lifting DWT [19] and the conventional 2-
D Daubechies DWT [20] (the length of the filter is 4) and 
the 2-D SMDWT scheme for obtaining the LL-band images. 
Suppose an image is of size N×N, the ratio between LDWT 
[19] and SMDWT at all levels are equivalent to 4.2%; the 
ratio between D4DWT [20] and SMDWT at all levels are 
1.6%; the ratio between fast LDWT [21] and SMDWT at all 
levels are 7.1%. The conventional 2-D Daubechies DWT 
scheme [20] requires to conduct a 1-D horizontal DWT to 
obtain low- and high-frequency subband images, and then 
gone through another 1-D vertical DWT for generating four-
subband images. In [20], an image is transformed into four-
subband images with the Daubechies coefficients DWT. The 
overall computational Complexity (C) can be evaluated as 
below: 
2C 16 (1 4 ) /3LN J     
     
             (23) 
where J and L denote the length of the filter, and the number 
of level decompositions, respectively. 
In [19], it transforms an image into four-subband 
images with the lifting coefficients DWT. The overall 
computational complexity can be evaluated as below: 
eliminated from the process before the detection process is 
conducted and the detection efficiency is improved as a 
result. 
 
4. PROJECTION-BASED CHARACTER SEGMENTATION 
4.1. Binarization 
In outdoor environment, the lighting condition is not 
controllable. In addition, the dirt on a LP is also an issue in 
LPRS. In a regular segmentation procedure, the CS has to 
utilize the information of a classified LP represented by only 
two colors as black for characters and white for the 
background in general. The usually employed method to 
achieve this is thresholding which normally uses a threshold 
to distinguish different meaningful regions of LPs for 
further processing. However, which shows a drawback of 
not being able to deal with the various lighting conditions 
and dirty LPs. To cope with these, this work divides the 
extracted LP of size PxQ into non-overlapped blocks of 
MxN for block-based thresholding, where M=P/4 and 
N=Q/4, respectively. The processing of each block is as 
below, 
    
    
   
 
   
 
   ,                             (28) 
      
        if       
     otherwise
 ,                           (29) 
where      denotes the original grayscale value of the 
original LP;        denotes the binary results as shown in 
Fig. 9(e) with various conditions. Although some specific 
characters do not binarized perfectly as Fig. 9(b)‟s „F‟, this 
results are enough for the extraction of top and bottom 
boundaries of characters as discussed following subsection.  
 
4.2. Character segmentation 
Figure 10 illustrates an aspect definition of LP, where the 
variables are frequently used in this subsection. First, the top 
and bottom boundaries of the characters have to be verified. 
The horizontal projection is adopted for deriving the 
information, and which is represented as below.  
             
  
   ,                              (30) 
where the variable    denotes the width of the extracted LP, 
and         denotes the horizontal projection performing on 
Fig. 9(a)‟s  . According to the observation, the gray circles 
in Fig. 11(a) indicate the most possible top (the right circle) 
and bottom (the left circle) boundaries of the LP. Yet, there 
are some other minimal projection points which may 
interfere the detection precision. To solve this, the searching 
strategy is given below.  
                             ,                 (31) 
  argmin
     
                        ,       (32) 
where     and   denote the imaginary height of LP and 
vertical coordinate of LP, respectively; variable   denotes 
the set of combination of         that has the minimal 
         . Nonetheless, the   still has a lot of combinations 
of        . For this, some constrains have to be established. 
The first is the bottom boundaries of LPs should locate 
within the vertical region [1, 
  
 
], where    denotes the 
height of LP; the top boundaries of LPs should locate within 
the vertical region [
  
 
  ,   ]. The second constrain is 
formulated as below,  
               min                ,          (33) 
where    denotes the subset of   which meets the first 
constrain. Subsequently, the bottom and top boundaries can 
be easily derived by            and                   , 
respectively.  
The left and right boundaries of each character are 
derived with the same manner as above. Note that, the 
utilized binarized result for following vertical projection of 
LP is recalculated with the manner of subsection 4.1, where 
the binarization vertical range are limited within 
{     ,      }. The corresponding results are shown in Fig. 
9(f) and the horizontal projection of LP is calculated as  
             
            
   
           
    .          (34) 
Notably, the possible calculating range of vertical projection 
is limited within the characters region from a general entire 
vehicle plate because of the affects from other non-character 
parts. The practical projection result is exhibited in Fig. 
11(b), where the gray circles indicate the true left and right 
boundaries of characters. It is noteworthy that there are two 
possible arrangements of the LPs in Taiwan, for example 
TR-5894 and 6675-WU, named type 1 (t1) and type 2 (t2), 
respectively, in this paper. The notation “-” is used to 
enhance the positions in separating the two groups, numbers 
and characters. Thus, the CS algorithm has to be modified 
by considering this characteristic. As shown in Fig. 11(b), 
eight points with gray circles have the minimum magnitude 
of projections, and thus the calculation can be arranged as 
below.  
                
              
 
                          
 
   ,    (35) 
                
              
 
                          
 
   ,    (36) 
                            argmin
        
                
 argmin
        
                ,                  (37) 
where     and     denote the imaginary width of character 
and the imaginary width of the “-” notation in Taiwan‟s LPs, 
respectively, and     is set at      ;   denotes the horizontal 
coordination of LP. According to these calculation, the 
boundaries of characters (        
  and         
 ) can be 
segmented by                        as below,  
      
   
 
                              if        
                            Otherwise
 ,       (38) 
       
   
 
                            if        
                        Otherwise
 ,           (39) 
     
   if the used                           
   if the used                          
 ,     (40) 
where   denotes the kth character in LP;     is a variable to 
denote different types of LP. Finally, the boundaries of each 
character can be determined by the above horizontal and 
vertical projections. According to these extracted boundaries, 
each character are cropped from the original grayscale 
source and normalized to 10x20. These cropped grayscale 
sources will be binarized again with its mean, and the results 
are exhibited in Fig. 9(g). The binarized results with a 
connecting component processing that remains only one 
object with the maximum area size will be used for further 
processing.  
 
  
    if                   
    Otherwise                     
 .                    (50) 
The probability of this feature is also calculated by Eq. 41, 
where   is empirically set at 10. 
 
7) Three different corner area size coding 
Figure 18 shows some character pairs which are hardly 
distinguished by computer vision, and the three different 
corner area size coding is designed for solving this problem. 
Figure 19 shows a conceptual diagram, where    ,    ,    , 
and     denote the area size of a character in its top-left, 
top-middle, top-right, and bottom-left regions, respectively. 
Based on the information, the three features are determined 
as below,  
           ,                                (51) 
           ,                                (52) 
       .                                     (53) 
The probabilities of these features are calculated by Eq. 41, 
where   is empirically set at        . 
 
5.2. Character recognition 
The Bayesian theorem is a fundamental probabilistic 
approach to the problem of classification, which can obtain a 
linear optimum decision based on all known probabilistic 
features. Based on these features, the probability of the 
various character classes can be determined. The conditional 
probability is described as follows:  
                  
                
             
,             (54) 
where variable    denotes the nth feature and    denotes 
the kth character. Focusing on the numerator, the above 
equation can be rewritten as follows: 
                  
                     
             
,          (55) 
where       is called the priori probability; 
                  is called the likelihood of    with 
respect to these features            , and 
               is called the evidence. To simplify the 
implementation, the above equation is rewritten as follows 
to let all features be independent. The independent 
assumption is from the Naïve Bayes classifier, which has 
been proven that it still can maintain excellent performance 
from Zhang‟s research [23]. 
                  
                    
             
.           (56) 
The evidence could be re-described by the Bayesian theorem 
as follows, 
                  
                    
                     
  
   
.      (57) 
The probabilities of all the    can be pre-calculated. Finally, 
the classified result can be obtained by the following 
equation,  
        argmax     
              ,            (58) 
According this method, the character can be recognized. 
 
6. EXPERIMENTAL RESULTS 
The performance of the proposed Hierarchical AdaBoost 
(HA) is tested in twofold, computation complexity and 
training time, which are organized in Table II and III, 
respectively. The analysis on the computation of both Haar-
like features and the proposed HFs is arranged in Table II. 
From the observation of the results, the Haar-like features 
requires the additional computation on integral images, and 
thus the complexity is more than about three times than that 
of the HFs. Based on this premise, the training time of the 
two features are shown in Table III. The experiment is 
conducted with the platform: CPU: Intel 2.13 GHz, RAM: 2 
GB, and OS: Microsoft 32-bit Win7. Notably, the parallel 
processing is not enabled in this work. 
The performance of the proposed MLPRS is discussed 
as below. In this study, in total 335 LPs in 168 test images of 
size 4288x2848 with different environments as indoor or 
outdoor are taken into account. Table IV(a) shows the 
correct rates of proposed system, where the correct 
localization rate and correct character segmentation rate are 
92.5% and 95.2%, respectively. Figure 2 shows a practical 
detection result, where the rectangular with different colors 
denote different located LPs. Table IV(b) organizes the 
correct recognition rates with the proposed CR system, the 
average correct character recognition rate is 98.23%. Finally, 
the processing speed can achieve around 5 fps (frame per 
second) with these high-resolution images, where the three-
level SMDWT is employed. 
 
7. CONCLUSIONS 
License plate recognition is a computer vision used to 
identify vehicles license plates. Detecting the accurate 
location of license plates from many vehicles image is 
considered to be the most important stage of Multiple 
License Plates Recognition System (MLPRS), which greatly 
influences the overall recognition accuracy ratio and 
computation time of the whole system. In this paper, we 
propose a system to recognize multiple license plates of 
moving vehicles. This kind of system for multiple targets 
that especially for the license plates requires high-resolution 
images be the sources for process. For instance, the multiple 
toll stations in a freeway and transportation management 
such applications, where the vehicles are lined up with a line, 
this makes the width of the used source have to provide 
enough information for recognition. Based on this 
environment constrains, the proposed system gearing with 
the proposed Symmetric Mask-based Discrete Wavelet 
Transform (SMDWT) for increase processing efficiency, the 
proposed Hierarchical AdaBoost (HA) with a faster training 
time, projection-based characters segmentation with an good 
accuracy, the reliable Bayesian-based character recognition 
algorithm, provides a superior performance for practical 
applications. According to the experiment results, the 
proposed system can correctly locate the license plates, 
segment and recognize characters with highly correct rate. 
Moreover, the processing speed achieve to 5 fps (frame per 
second) for frame of size 4288x2848 in three-level SMDWT 
condition. These demonstrated performance display that the 
proposed system sufficiently qualified for practical usages.  
 
ACKNOWLEDGEMENT 
This research work was partially supported by the National 
Science Council of Taiwan, under grant number NSC-99-
2221-E-032-028. 
 
REFERENCES 
[1] M. Sarfraz, M. J. Ahmed, and S. A. Ghazi, “Saudi Arabian license 
plate recognition system,” IEEE International Conference on 
Geometric Modeling and Graphics, pp. 36-41, July 2003. 
[2] M. Yu and Y. D. Kim, “An approach to Korean license plate 
recognition based on vertical edge matching,” IEEE International 
Conference on Systems, Man, and, Cybernetics, vol. 4, pp. 2975-
(b) 
Fig. 3. The system block diagram of the proposed 2-D 
SMDWT: (a) 2-D 5/3 SMDWT, (b) De-relation matrix. 
 
 
β δ
γ
α
α
α
β
δ
γ
α
α
α
δ
ε
β
γα
α β
γ
α
α
δ
ε
δ
 
Fig. 4. LL-band mask coefficients. 
 
 
Fig. 5. Five types of rectangular features employed in Haar-
like features [22]. 
 
  
P1 P2
P3 P4
P5 P6
 
Fig. 6. Examples of the use of rectangular features on a face. 
 
 
Fig. 7. Adopted positive training samples of size 30x14. 
 
Weak classifier 1
(Number of feature point = 4)
Weak classifier T



4
1
1 )),(),,((
k
i kyxOwhereyxXsumF






6
5
1
6
1
2
)),(),,((
)),(),,((
k
i
k
i
kyxOwhereyxXF
kyxOwhereyxXsumF
Weak classifier 2
(Number of feature point = 6)
Weak classifier 3
(Number of feature point = 9)
…
…
…
…
…
…






9
7
2
9
1
3
)),(),,((
)),(),,((
k
i
k
i
kyxOwhereyxXF
kyxOwhereyxXsumF
spoblacknewofsumationFF TT int1  
…
…
…
…
…
…
 
Fig. 8. Strong classifier equivalent concept using 
Hierarchical Features (HFs). 
 
 
 
 
 
Binarized 
Various      results 
conditions 
Original grayscale 
source (d) 
  (e)    (f)     (g) 
Normal condition 
(a) 
  
 
 
 
Dirty condition 
(b) 
  
 
 
 
Lighting condition 
(c) 
  
 
 
 
Fig. 9. Examples of license plate binarization with various situations. 
 
Fig. 17. Example of ratio of projection coding. (a) Target 
characters to be enhanced. (b) Conceptual projection scopes.  
 
 
(a) 
  
(b) 
 
(c) 
Fig. 18. Some different easily confused character pairs. 
 
3
3
20
10
Rtl Rtm Rtr
Rbl
 
Fig. 19. Conceptual diagram of the four regions of a character 
for area size calculation. 
 
 
Fig. 20. Example of practical detection result. 
 
TABLE I COMPLEXITY COMPARISONS AMONG VARIOUS 2-D DWT APPROACHES. 
Level(s) 
①
LL of 
LDWT [19] 
②
LL of 
D4DWT [20] 
③
LL of 
Fast DWT [21] 
◎
LL of 
SMDWT 
Ratio 
(◎/①) 
×100% 
Ratio 
(◎/②) 
×100% 
Ratio 
(◎/③) 
×100% 
level1 6×N
2
 16×N
2
 7/2×N
2
 1/4×N
2
 4.2% 1.6% 7.1% 
level1+level2 15/2×N
2
 20×N
2
 35/8×N
2
 5/16×N
2
 4.2% 1.6% 7.1% 
level1+level2+level3 63/8×N
2
 21×N
2
 147/32×N
2
 21/64×N
2
 4.2% 1.6% 7.1% 
 
TABLE II COMPUTATION COMPLEXITY COMPARISON BETWEEN HAAR-LIKE FEATURES AND THE PROPOSED HFS (SUPPOSE SAMPLE OF 
SIZE MXN). 
Feature 
Operation                  type 
number 
Haar-like features HFs 
Addition/ Subtraction 
Integral Image (MxN-1)+(M-1)(N-1) 
Less than 2xMxN K weak classifiers 
(suppose all are 2-rectangle feature) 
7xK 
Addition/ Subtraction 
(Suppose sub-window of size 30x14) 
Case1: 2196  
(suppose 200 features are 2-rectangle features) 
Case2: >2196  
(suppose 3-rectangle or 4-rectagle features are used) 
Less than 840 
 
TABLE III TRAINING TIME COMPARISON BETWEEN HAAR-LIKE FEATURES AND THE PROPOSED HFS. 
 Possible features for training Training time 
Haar-like features More than 100,000 More than 10 days 
PBH features Less than 576 Around 10 minutes 
 
TABLE IV THE DETECTION ACCURACY OF THE PROPOSED SYSTEM. 
 # Test data # Correct Correct rate 
License plate localization 335 310 92.5% 
Character segmentation 310 295 95.2% 
(a) 
Digits Correct rate Characters Correct rate Characters Correct rate 
0 100% A 100% N 88.4% 
1 100% B 90.1% O 100% 
2 96.4% C 99.4% P 98.8% 
計畫成果自評部份: 
 
單一車牌的智慧型辨識系統已趨於成熟，但其可應用之場合同時受限於僅能辨識單一車牌的功能，
例如其無法針對多車道僅利用單一裝置進行處理，或在交通繁雜之路口進行多車牌的辨識。考慮
到多車牌之應用，由於每一個車牌皆需要具備足夠的解析度才可進行辨識，這直接導致所需求的
影像大小將較過往如 320x240 或 640x480 等來之大，且同時，過高的影像解析度直接導致智慧型
系統偵測的速度下降，導致無法進行即時處理。在本研究中，針對高解析度且多車牌之辨識應用
提出一解決辦法，產生之結果同時具備高速處理速度及多車牌辨識之能力，這幾種優秀特性導致
本提出之技術除可涵蓋過往的應用範圍如停車場自動收費系統，單一車道的車牌辨識等，延伸至
前所述之多車道及交通繁雜環境。此外亦由於高速的處理速度，本系統甚至可安裝至行駛中的車
輛上，進行即時的多車牌辨識處理。以上種種有別於傳統裝置的優異特性，使得本研究提出之成
果足以具備更優良可靠的優異評價。 
 
本技術已投稿國際 SCI 期刊 IEEE Transactions on Image Processing，並且申請中華民國
及美國專利。 
98年度專題研究計畫研究成果彙整表 
計畫主持人：郭景明 計畫編號：98-2622-E-011-009-CC3 
計畫名稱：多目標車牌即時辨識系統 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 1 1 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 1 1 100%  專利 已獲得件數 0 0 100% 件  
件數 3 3 100% 件  
技術移轉 
權利金 90 90 100% 千元  
碩士生 0 0 100%  
博士生 1 1 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 1 1 100%  
研究報告/技術報告 0 0 100%  
研討會論文 1 1 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 1 1 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
 
