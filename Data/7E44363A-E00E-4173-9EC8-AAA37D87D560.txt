 
 
 
 
1
中文摘要—許多影像相關應用非常依賴景物內
容顏色不隨時間與空間變動太大之特性，但其
內建演算法卻往往忽略光源可以對景物顏色造
成劇烈變動之事實。例如根據顏色辨識物體之
系統可能運作失常，原因在於其仰賴建立大量
物體在正常光源下反射之顏色資料庫，卻運作
於偏離正常光源之環境。對於這類應用，色彩
恆常為重要之影像前置處理，其相關研究仍是
一個蓬勃發展之領域，從熟知之影像擷取裝置 
(數位相機與攝影機)、工業界使用之機器視
覺、學術界研究之電腦視覺、日漸興盛之機器
人甚至醫學界之遠端看診，都可找到其應用場
合，新的應用預期也會日漸增加。隨著相關產
品與應用變得熱門，相關硬體也跟著蓬勃發
展，預估產品之效能也將愈受重視。而提升影
像品質除了透過發展與使用更好之硬體外，另
一個可以降低成本之方向便是從演算法著手，
但目前演算法之發展尚有很大空間，仍有許多
重要研究題目值得探討。因此我們規劃了為期
一年之系列研究子題，除了針對現有之白平衡
與色彩恆常演算法引入模糊系統與類神經網路
發展智慧型演算法外，也將發展其他演算法。
所發展之演算法將搭配數位相機進行實驗。研
究成果將能升級工業界設計生產相關產品之軟
體技術，也能提升國內學術界相關研究之水平。 
關鍵詞：色彩恆常、白平衡、數位相機、模糊
系統、類神經網路 
 
Abstract—Functionality and performance of various image 
applications rely on the fact that the colors of the scene do not vary 
with time or location. For those applications, however, the built-in 
software algorithms often ignore that the ambient light could 
significantly changes the (reflected) colors of a scene. For example, 
an algorithm designed to recognized objects of specific color 
depends on a database comprising the colors of various types of 
objects under a standard illuminant (e.g., D65). The algorithm will 
not function properly under a different illuminant. For such 
application where accurate color of a scene is important, color 
constancy is an indispensable imaging pipeline. Color constancy is 
still a field with high R&D activity. It has found application in area 
such as digital still and CCD cameras, machine vision in 
manufacturing industry, computer vision, robotics, remote medical 
diagnosis, etc. The new application is expected to grow. With 
related products and applications becoming popular, supported 
hardware technology will quickly advance. At the same time, the 
performance, mainly the image quality, of a product will receive 
more emphasis. Besides incorporating better hardware technology 
into a product to improve the image quality, another option is 
implementing software with high-performance algorithm. For the 
field of color constancy, there are still many open topics worth 
exploration. Hence, this project will invest one-year duration to 
investigate a series of research topics. We will upgrade the 
‘intelligence’ of existing white balance algorithms by introducing 
fuzzy systems and neural networks into the algorithm develop 
process. We will also examine and exploit new classes of color 
constancy methods. An experimental system based on digital still 
camera will be established and used to develop and justify the 
feasibility and performance of the developed algorithms. 
Keywords: Color constancy, white balance, digital still camera, 
fuzzy system, neural network 
I. INTRODUCTION 
Digital image capturing devices have evolved into a class 
of consumer electronics indispensable for modern family. 
For most image capturing or recording devices, image 
signals from sensors (CCD or CMOS) must be converted 
into physical quantities compatible with storage devices or 
monitors. The conversion should take into account the fact 
that dynamic response of the sensor is different from that of 
the human visual system. That is, the images viewed by 
sensors are different from that by the human eyes. In 
addition, the images captured are actually lights reflected 
from the surface of the objects. Hence, the conversion 
should also consider the effect of the light source. Color 
balance is a class of image processing algorithms developed 
to compensate for the effects of light sources on captured 
images. Images which are not color balanced will appear to 
have been shifted towards one color or another, i.e., have 
color cast. A color balance algorithm adjusts the image 
through red, green, and blue values of the three basic color 
layers so that the hues of a variety of colors are returned to 
normal. Since human eyes are particularly sensitive to the 
neutral (gray or white) colors within an image, compensating 
for such colors has become the main objective of most color 
balance algorithms. Color balance algorithms aiming at 
compensating the white color within captured images are 
also known as white balance algorithms. Most image related 
applications require taking measurement of the colors from 
surrounding objects or scenes, but often neglect the fact that 
the colors of an object or scene may subject to change with 
factors such as ambient light and illuminants. When 
invariance of color measurement to such factors is important 
for an application, white balance algorithm may be 
incorporated into the corresponding image processing 
pipeline to ensure equitable measurement of colors. 
A generic white balance algorithm usually consists of two 
essential steps: (1) estimating the color temperature of the 
light source for a captured image; (2) adjusting the image 
contents to remove the effect of the light source. Many 
high-end digital cameras and camcorders have built-in 
sensors which can measure lighting conditions in real-time 
and make corresponding correction to the captured images. 
On the other hand, the market of consumer electronics relies 
 
 
3 
 
 
11 11 11 21 21 21
1 1 1
12 12 12 22 22 22
2 2 2
1 1 1 2 2
IF ( , , ) AND ( , , ) AND ... 
AND ( , , ) THEN Light source #1
IF ( , , ) AND ( , , ) AND ... 
AND ( , , ) THEN Light source #2
        
IF ( , , ) AND ( ,
M M M
M M M
N N N N N
R G B R G B
R G B
R G B R G B
R G B
R G B R G

2, ) AND ... 
AND ( , , ) THEN Light source #N
N
MN MN MN
B
R G B
 
In practical circumstance, it is not possible to know 
precisely the color or spectral properties of an object or 
illuminant. First of all, a monochromatic object with a 
surface of uniform spectral properties (e.g., transmittance 
and reflectance) hardly exits in real world. Therefore, slight 
variation is expected when taking measurement of the colors 
from different surface area of a monochromatic object. Other 
factors will also contribute to perturbation of ijR , ijG , and 
ijB  values, such as fluctuation in spectral power distribution 
of an illuminant, measurement inaccuracy of the equipment, 
and inference from the environment. Alternatively, ijR , ijG , 
and ijB  may be specified as fuzzy sets which are defined 
over intervals in accordance with their variation ranges. The 
color temperature of the illuminant may also be specified as 
a fuzzy set defined over an interval. Let 1x , 2x , and 3x  
represent one measurement of R , G , and B  components, 
respectively, from an  image subject to an illuminant with 
color temperature y . The following NM  fuzzy inference 
rules may be constructed:  
Rule 1~Rule M: If 1 2 3( , , )x x x  is 11 21 31
i i iA A A  , then y  is 
1B , 1,...,i M . 
Rule M+1~Rule 2M: If 1 2 3( , , )x x x  is 12 22 32
i i iA A A  , then 
y  is 2B , 1,...,i M . 
  
Rule (N-1)M+1~Rule NM: If 1 2 3( , , )x x x  is 
1 2 3
i i i
N N NA A A  , then y  is NB , 1,...,i M . 
where   denotes taking ‘AND’ operation of the fuzzy sets, 
e.g., 1 2 3 1 2 3 1 1 2 2 3 3[ ]( , , ) ( ) ( ) ( )A A A x x x A x A x A x   . Besides, 
1
i
jA , 2
i
jA , and 3
i
jA  represent the fuzzy sets of ijR , ijG , 
and ijB , respectively, corresponding to the ith reference 
object subject to the jth reference illuminant. The outputs of 
the NM  rules may be further combined by a 
defuzzification algorithm. Here the centroid method or 
center average defuzzifier is utilized, i.e., 
 
1 2 3 1 2 3
1 1
1 2 3 1 2 3
1 1
( , , )
( , , )
N M
i i i
j j j cj
j i
N M
i i i
j j j
j i
A A A x x x y
y
A A A x x x
 
 
             
 
 
 (1) 
where cjy  denotes the centroid of the fuzzy set jB . The 
formulated fuzzy logic system is such that it accepts the 
values of R , G , and B  components from a captured 
image under an unknown illuminant and is capable of 
making deduction of the color temperature of the illuminant. 
B. Configuration and Training of the Fuzzy Neural 
Network 
To enhance the performance and improve the robustness 
of the fuzzy logic system developed previously. The fuzzy 
logic system may be topologically depicted as a neural 
network as shown in Figure 2. Let  ku  and  ka  be the 
input and the output of the kth layer of the network. The 
functions of the four layers and the corresponding nodes and 
links may be described as follows: 
Layer 1: No computation is done in this layer. Here 1x , 2x , 
and 3x  are the inputs to layer 1 of the neural network, 
which has 3 nodes and transmits the input values directly to 
the next layer, i.e., 
 (1) (1)i ia u x   (2) 
Layer 2: This layer has 3NM  nodes and performs the 
fuzzification operation. Each node in this layer consists of 
the fuzzy set, 1
i
jA , 2
i
jA , or 3
i
jA , and each fuzzy set is 
specified as a Gaussian membership function, i.e., 
  
  22
2 exp i i
i
u m
a 
          
 (3) 
where im  and i  are, respectively, the center (or mean) 
and the width (or variance) of the Gaussian membership 
function of the ith input variable iu . The link weights 
between layer 1 and 2 are set to unity. 
Layer 3: This layer has NM  nodes with each node 
performing the ‘AND’ operation, i.e., 
     
3
3 3
1
i
i
a u

  (4) 
The output of this layer represents the firing strength of the 
corresponding fuzzy rule. The link weights between layer 2 
and 3 are also set to unity. 
Layer 4: This layer consists of a single node which acts as a 
defuzzifier by integrating all the signals from layer 3 using 
the centroid method, i.e., 
 
(4)
(4) 1
(4)
1
NM
i i
i
NM
i
i
u w
a
u





 (5) 
where iw  is the centroid of the output membership function 
and can be regarding as the link weights between layer 3 and 
4. 
Training of the FNN involves adjusting the center/width, 
im  and i , of each Gaussian membership function in layer 
2 and the link weights, iw , between layer 3 and 4 such that 
the output generated by the network for a given input pair is 
as close to the reference or desired color temperature as 
 
 
5 
 
may also be estimated according to the estimated color 
temperature from the previous section. To finalize white 
balance, pixel-wise operation in the red, green, and blue 
color separates of the test image is performed according to 
 
65
65
65
,
,
,
awb D c
awb D c
awb D c
R R R R
G G G G
B B B B
 
 
 
 (15) 
where awbR , awbG , and awbB  denote the red, green and 
blue components for the white balanced image. In addition, 
R , G , and B  are the red, green and blue components 
from the test image. 65DR , 65DG , and 65DB  are the 
components of the white object under D65 illuminant, 
whereas cR , cG , and cB  are  the components of the 
white object under the unknown illuminant. 
It is observed that the red or blue color separate of an 
image subject to high or low color temperature tends to have 
lots of image pixels with zero intensity. Those pixels will not 
be affected by (15) and will therefore degrade the white 
balanced image. To solve this issue, (15) may be modified as 
follows: 
 
   
  
   
  
65
65
65
max 1, . . 6500 100
         max 1, . . 6500 100
max 1, 6500 . . 100
         max 1, 6500 . . 100
awb D c
awb D c
awb D c
R R E T R R
E T
G G G G
B B E T B B
E T
   
 
 
   
 
 (16) 
where . .E T  is the estimated color temperature of the 
unknown illuminant. The idea behind the proposed 
modification is to shift the intensity of the red or blue color 
separate (add a positive constant) when subject to 
illuminants of high or low color temperature, adjust the pixel 
values, and then shift the intensity of the color separate back 
(add a negative constant). 
III. EXPERIMENTAL PROCEDURES AND RESULTS 
Figure 3 illustrates the experimental setup and procedure. 
A color checker containing patches/segments may serve as 
reference objects with different surface colors. A high-end 
digital camera with a native resolution of 3888 2592  
pixels is utilized to acquire raw image data. Note that the 
raw image is not affected by the camera’s built-in color 
balance functions. The raw data is then converted to TIF 
format which preserves the original lighting condition of the 
image. A light booth provides various illuminants with 
known color temperature (A: incandescent of 2856K, U30: 
warm white fluorescent of 3000K, CWF: cool white 
fluorescent of 4150K, and D65: daylight of 6500K) inside 
which the color checker can be placed with desired 
orientation. Among them, D65 is the desired or reference 
illuminant, and the image captured under D65 can be 
regarded as the reference image (with desired white balance). 
Other images captured under A, U30 and CWF are treated as 
test images (to be white balanced). The reference image is 
shown in Figure 4(a), and the test images subject to other 
illuminants are given in Figure 4(b), Figure 4(c), and Figure 
4(d). 
We propose the following method, which takes into 
account statistical variation (both static and dynamic) among 
image pixels, to select a set of reference objects which 
provide samples and initial conditions for training the FNN. 
First, the color checker is positioned properly inside the light 
booth. For each known illuminant, raw image of the color 
checker is collected six times using the high-resolution 
digital camera, with each taken 20 seconds apart. Pixels of a 
specified area ( 370 370  pixels) from each color patch on 
the raw image become candidates of training samples. Hence, 
there are a set of 370 370 6   candidate pixels 
corresponding to each color patch, which account for time 
and spatial variation of that specific color. For each color 
patch, histograms are generated for the R/G/B components of 
the candidate pixels. Figure 5 demonstrates the histograms 
for two of the color patches subject to D65 illuminant. 
Twenty candidate pixels lying within the interval of one 
standard deviation from the mean are then randomly selected 
as the training samples with respect to an illuminant of 
known color temperature. The means and standard 
deviations of the R/G/B histograms also provide sensible 
initial values of the center and width of the membership 
functions in layer 2 of the FNN. The centroid of the output 
membership function is set to 0. The desired output is set to 
the normalized color temperatures of the known illuminants, 
i.e., [2856,3000,4150,6500] 6500 . For each training cycle 
of the FNN, a training sample and a desired normalized 
color temperature are presented to the network. At the end of 
each training cycle, the square root of (6) or the root mean 
square error (RMSE) is recorded. Note that the learning rate 
  is set to 0.005, and the number of training cycles is set to 
1000. The RMSE versus training cycle is shown in Figure 6. 
The RMSE is 0.151036 at the end of the first training cycle 
and is reduced to 0.005041 after 1000 training cycles. 
After training of the FNN is complete, test images (see 
Figure 4(b), Figure 4(c), and Figure 4(d)) are then utilized to 
demonstrate the proposed white balance approach. Using the 
method described previously with a threshold of 0.5, the 
estimated color temperatures are 4151K, 2993K, and 2850K, 
which are very close to the actual color temperatures of the 
illuminants. Using the white color patch as the reference 
white object, of which the R, G, and B components under 
various illuminants are listed in TABLE I, the data from 
TABLE I can be curve fitted using polynomials of degree 
two as shown in Figure 7. As a final step, (16) is applied and 
the white balanced images are provided in Figure 8. All the 
white balanced images, i.e., Figure 8(e), Figure 8(f), and 
Figure 8(g), can be concluded to be visually closer to the 
reference image, Figure 8(a), than the original images, i.e., 
Figure 8(b), Figure 8(c), and Figure 8(d). 
A study is made which compares the proposed white 
 
 
7 
 
cG , and cB  may be retrieved instantly using a lookup table. 
When further parametric adjustment of the algorithm is 
requested, e.g., training of the FNN, the user may switch the 
device into special operation mode to carry out the 
corresponding calibration, which will demand longer 
execution time. 
REFERENCES 
[1] G. Buchsbaum, “A spatial processor model for object color 
perception,” Journal of the Franklin Institute, vol. 310, pp. 1-26, 1980. 
[2] R. Gershon, A. D. Jepson, and J. K. Tsotsos, “From [R,G,B] to surface 
reflectance: computing color constant descriptors in images,” 
Perception, pp. 755-758, 1988. 
[3] John J. McCann, Suzanne P. McKee, and Thomas H. Taylor, 
“Quantitative studies in Retinex theory,” Vision Research, vol. 16, pp. 
445-458, 1976. 
[4] E. H. Land, “Recent advances in Retinex theory,” Vision Research, 
vol. 26, pp. 7-21, 1986. 
[5] A. Blake, “Boundary conditions for lightness computation in 
Mondrian world,” Computer Vision, Graphics, and Image Processing, 
vol. 32, pp. 314-327, 1985. 
[6] A. Hurlbert, “Formal connections between lightness algorithms,” 
Journal of the Optical Society of America A, vol. 3, pp. 1684-1692, 
1986. 
[7] D. A. Brainard and B. A. Wandell, “Analysis of the Retinex theory of 
Color Vision,” Journal of the Optical Society of America A, vol. 3, pp. 
1651-1661, 1986. 
[8] D. Forsyth, “A novel algorithm for color constancy,” Int. J. Comput. 
Vis., vol. 5, pp. 5–36, 1990. 
[9] G. D. Finlayson, “Color in perspective,” IEEE Trans. Pattern Anal. 
Machine Intell., vol. 18, pp. 1034–1038, 1996. 
[10] G. D. Finlayson and S. Hordley, “Improving Gamut mapping color 
constancy,” IEEE Trans. Image Processing,” vol. 9, no. 10, pp. 
1774-1783, 2000. 
[11] S. Tominaga and B. A. Wandell, “Standard surface-reflectance model 
and illuminant estimation,” Journal of the Optical Society of America 
A, vol. 6, pp. 576-584, 1989. 
[12] H.-C. Lee, “Method for computing the scene-illuminant chromaticity 
from specular highlights,” Journal of the Optical Society of America A, 
vol. 3, pp. 1964-1699, 1986. 
[13] M. D’Zmura and P. Lennie, “Mechanisms of color constancy,” Journal 
of the Optical Society of America A, vol. 3, pp. 1662-1672, 1986. 
[14] S. Tominaga and B. A. Wandell, “Component estimation of surface 
spectral reflectance,” Journal of the Optical Society of America A, vol. 
7, pp. 312-317, 1990. 
[15] Z. Wang and A.C. Bovik, Modern Image Quality Assessment, Morgan 
& Claypool Publishers, 2006. 
[16] H.-K. Lam, O. C. Au, and C.-W. Wong, “Automatic white balancing 
using luminance component and standard deviation of RGB 
components,” IEEE International Conference on Acoustics, Speech, 
and Signal Processing, Montreal, Canada, pp.493-496, 2004. 
[17] Chikane, and C.-S. Fuh, “Automatic white balance for digital still 
cameras,” Journal of Information Science and Engineering, vol.22, 
no.3, pp.497-509, 2006. 
[18] J.-Y. Huo, Y.-L. Chang, J. Wang and X.-X. Wei, “Robust automatic 
white balance algorithm using gray color points in images,” IEEE 
Transactions on Consumer Electronics, vol.52, no.2, pp.541-546, 
2006. 
[19] P.-M. Wang and C.-S. Fuh, “Automatic white balance with color 
temperature estimation,” IEEE International Conference on Consumer 
Electronics, pp. 1-2, 2007. 
[20] C.-L. Chen and S.-H. Lin, “Formulating and solving a class of 
optimization problems for high-performance gray world automatic 
white balance,” Applied Soft Computing, vol.11, no.1, pp.523-533, 
2011. 
 
 
 
 
TABLE I  
THE R, G, B COMPONENTS OF THE REFERENCE WHITE OBJECT. 
 2856K 3000K 4150K 6500K
Red 255 244 237 212 
Green 179 182 196 208 
Blue 88 106 138 207 
 
 
 
 
TABLE II 
 THE MSE BETWEEN TEST AND REFERENCE IMAGES (IN RGB COLOR SPACE). 
Color temperature Illuminants for the test 
images 4150K 3000K 2856K 
Before being white 
balanced 855.79 1849.67 2836.34
SRM 449.08 1249.71 2076.18
GWM 463.75 995.06 1686.37
Lam’s method 390.37 806.87 1252.19
Chikane's method 319.6 496.46 1513.39
Huo's method 537.4 2023.04 2690.84
Chen’s method 242.44 509.47 835.64 
Wang’s method 214.83 1453.42 2446.12
A
fter being w
hite balanced 
The proposed  
method 134.48 236.55 375.05 
 
 
 
 
TABLE III  
THE MSE BETWEEN TEST AND REFERENCE IMAGES (IN YCBCR COLOR 
SPACE). 
Color temperature Illuminants for the test 
images 4150K 3000K 2856K
Before being white 
balanced 283.9 599.94 943.68
SRM 203.25 503.21 705.31
GWM 170.1 360 612.66
Lam’s method 137.4 260.98 403.55
Chikane's method 97.21 136.39 422.15
Huo's method 159.46 528.45 825.72
Chen’s method 98.49 173.01 274.62
Wang’s method 75.78 459.8 797.9 
A
fter being w
hite balanced The proposed  
method 50.42 84.62 154.29
 
 
 
 
 
9 
 
(a) (b)
(c) (d)
 
Figure 4: A color checker subject to different illuminants (a) 
D65 - 6500K (b) CWF -  4150K (c) U30 – 3000K (d) A – 
2856K. 
 
 
 
Figure 5: Histograms for the R/G/B components of the 
candidate pixels from two of the color patches subject to 
D65 illuminant. 
 
 
0 100 200 300 400 500 600 700 800 900 1000
0
0.02
0.04
0.06
0.08
0.1
0.12
0.14
0.16
0.18
0.2
training cycle
R
M
SE
X: 1000
Y: 0.0002486
R
M
SE
 
Figure 6: Root mean square error versus training cycle. 
2500 3000 3500 4000 4500 5000 5500 6000 6500
80
100
120
140
160
180
200
220
240
260
color temperature (K)
co
lo
r c
om
po
ne
nt
 v
al
ue
s
Red
Green
Blue
co
lo
r c
om
po
ne
nt
 v
al
ue
s
 
Figure 7: Curve fitting the data of the R/G/B components of 
the reference white object under various illuminants. 
(a)
(d)(c)
(g)(f)(e)
(b)
 
Figure 8: Before being white balanced: (a) reference image - 
6500K, (b) test image - 4150K, (c) test image - 3000K, (d) 
test image - 2856K. After being white balanced: (e) test 
image - 4150K, (f) test image - 3000K, (g) test image - 
2856K. 
(i)                         (j)
(a)                         (b) 
(c)                         (d)                       (e)
(f)                         (g)                       (h)
 
Figure 9: (a) Reference image. (b) Test image - 4150K. 
After being white balanced using (c) SRM, (d) GWM, (e) 
Lam’s method, (f) Chikane's method, (g) Huo's method, (h) 
Chen’s method 3, (i) Wang’s method, and (j) the proposed 
method. 
 
 
11 
 
國科會補助專題研究計畫成果報告自評表 
請就研究內容與原計畫相符程度、達成預期目標情況、研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）、是否適
合在學術期刊發表或申請專利、主要發現或其他有關價值等，作一綜合評估。
1. 請就研究內容與原計畫相符程度、達成預期目標情況作一綜合評估 
█  達成目標 (補充說明如下) 
□ 未達成目標 
□ 實驗失敗 
□ 因故實驗中斷 
□ 其他原因 
說明：本計畫已完成所規劃之工作大項與相關實驗驗證。 
 
2. 研究成果在學術期刊發表或申請專利等情形： 
論文：█已發表█未發表之文稿█撰寫中 □無 (補充說明如下) 
專利：□已獲得 □申請中 □無 
技轉：□已技轉 □洽談中 □無 
說明：研究成果除了陸續在國際研討會 [1]-[3] 進行口頭報告外，已經發表兩
篇 SCI 期刊論文 [4][5]，另有數篇論文尚在準備中。 
 
[1] C.-L. Chen and S.-H. Lin, “Intelligent color temperature estimation using fuzzy neural 
network with application to automatic white balance,” 2010 IEEE International Conference on 
Systems, Man and Cybernetics, Istanbul, Turkey, pp.796-803, January 2010. (EI) 
[2] S.-H. Lin, C.-L. Chen, and B.-S. You, “A fuzzy neural network with optimal parameters 
for compensating the effect of ambient light on digitally captured images,” 第十七屆模糊理
論及其應用研討會, 台灣高雄, December 2009. 
[3] C.-L. Chen and S.-H. Lin, “Automatic white balance based on estimation of light source 
using fuzzy neural network,” 4th IEEE Conference on Industrial Electronics and Applications, 
Xi’an, China, pp.1905-1910, May 2009. (EI) 
[4] C.-L. Chen and S.-H. Lin, “Formulating and solving a class of optimization problems for 
high-performance gray world automatic white balance,” Applied Soft Computing, vol.11, 
no.1, pp.523-533, January 2011. (SCI) 
[5] C.-L. Chen and S.-H. Lin, “Intelligent color temperature estimation using fuzzy neural 
network with application to automatic white balance,” Expert Systems with Applications, 
vol.38, no.6, pp.7718-7728, June 2011. (SCI) 
 
 
國科會補助專題研究計畫項下出席國際學術會議心得報告 
                                                          日期：100 年 10 月 20 日 
 
一、參加會議經過： 
IEEE SMC Conference 為每年舉辦一次之國際學術研討會，舉辦地點遍及世界各地。2010 年之會
議選擇在土耳其伊斯坦堡舉行，會議時程計 10/10-10/13 共四天。由於該研討會之主題涵蓋許多智慧
型演算法相關研究，適合吾人該年度研究成果之發表，且鑒於研討會發表之論文有品質認證，諸多動
機讓吾人當初便計畫投稿該研討會。所投稿之論文被安排於10/11下午進行口頭報告。吾人於10/9
自桃園機場出發，於隔日 10/10 上午抵達伊斯坦堡國際機場，再搭乘巴士抵達住宿飯店入住。
10/11 日上午前往會場聆聽了 Dr. Paul J. Werbos 與 Kevin Warwick 之 keynote speech，講題分別
為 Neural Networks: From Toys to Cars to Mind 與 The Cyborg Experiments。下午則前往會場口
頭報告發表之論文。10/12 中午再聆聽 Dr. Edgar Koerner 之 keynote speech，講題為 Learning to 
Behave in a Natural Environment。晚上則參加研討會在船上舉辦之夜宴。10/14 下午搭乘班機
回台灣。 
二、與會心得與建議： 
本次會議舉辦地點為位於伊斯坦堡市區之軍事博物館，硬體設施齊全，週邊生活機能也
不錯，唯會場之入口開放時間標示不清讓許多人繞了大圈才得以進入。但進入會議現場標示
還算清楚，各會場均配備不錯之電腦與投影設備，也有派人員輔助 session chair 主持各場報
告。可能因主辦地點之軍事敏感性，進出要 X 光檢查，主辦單位便沒有力邀廠商參展，造成
會場略顯冷清。建議主辦單位無論如何還是應邀請與大會主題相關之廠商設攤，除可讓與會
人士了解應用層面之技術亦提供直接與廠商洽談合作或購買商品之機會。會議之參與者來自
世界各國，投稿論文總計 959 篇，被接受並完成註冊之論文篇有 672 篇，其中 538 篇是口頭
計畫編號 NSC 99-2221-E-005-104 
計畫名稱 智慧型色彩恆常演算法與其在數位相機之應用 
出國人員
姓名 陳正倫 
服務機構
及職稱 
國立中興大學電機工程學系
(所)/副教授 
會議時間  99年 10月 10日至  99 年 10 月 13 日 會議地點 伊斯坦堡/土耳其 
會議名稱 The 2011 IEEE International Conference on Systems, Man, and Cybernetics 
發表論文
題目 
Intelligent Color Temperature Estimation Using Fuzzy Neural Network with 
Application to Automatic White Balance 
                                      
Intelligent Color Temperature Estimation Using 
Fuzzy Neural Network with Application to Automatic 
White Balance 
 
Cheng-Lun Chen and Shao-Hua Lin 
Department of Electrical Engineering 
National Chung Hsing University 
Taichung 40227, Taiwan 
chenc@dragon.nchu.edu.tw 
 
 
Abstract—In this paper, a novel white balance method is 
proposed, which consists of two fundamental steps, i.e., color 
temperature estimation of the illuminant and adjustment of the 
components of the color separates. A fuzzy logic system is 
constructed to infer the color temperature of an illuminant 
which a digitally acquired image subjected to. The fuzzy logic 
system is further optimized by representing the system as a fuzzy 
neural network and a training scheme of the FNN parameters is 
proposed. The estimated color temperature is then employed to 
determine the required amount of adjustment for each color 
separate of the image. Experimental procedures are outlined and 
performed, which validates the feasibility and performance of 
the proposed method. A comparative study is also made based on 
two quantitative indices. The study shows that the proposed 
approach is preferable to most methods in the literatures in 
terms of performance and robustness to varieties of illuminants 
and scenes. 
Keywords-Color temperature estimation, fuzzy neural network, 
white balance 
I.  INTRODUCTION  
Digital image capturing devices have evolved into a class 
of consumer electronics indispensable for modern family. For 
most image capturing or recording devices, image signals from 
sensors (CCD or CMOS) must be converted into physical 
quantities compatible with storage devices or monitors. The 
conversion should take into account the fact that dynamic 
response of the sensor is different from that of the human 
visual system. That is, the images viewed by sensors are 
different from that by the human eyes. In addition, the images 
captured are actually lights reflected from the surface of the 
objects. Hence, the conversion should also consider the effect 
of the light source. Color balance is a class of image 
processing algorithms developed to compensate for the effects 
of light sources on captured images. Images which are not 
color balanced will appear to have been shifted towards one 
color or another, i.e., have color cast. A color balance 
algorithm adjusts the image through red, green, and blue 
values of the three basic color layers so that the hues of a 
variety of colors are returned to normal. Since human eyes are 
particularly sensitive to the neutral (gray or white) colors 
within an image, compensating for such colors has become the 
main objective of most color balance algorithms. Color 
balance algorithms aiming at compensating the white color 
within captured images are also known as white balance 
algorithms. Most image related applications require taking 
measurement of the colors from surrounding objects or scenes, 
but often neglect the fact that the colors of an object or scene 
may subject to change with factors such as ambient light and 
illuminants. When invariance of color measurement to such 
factors is important for an application, white balance algorithm 
may be incorporated into the corresponding image processing 
pipeline to ensure equitable measurement of colors. 
A generic white balance algorithm usually consists of two 
essential steps: (1) estimating the color temperature of the 
light source for a captured image; (2) adjusting the image 
contents to remove the effect of the light source. Many high-
end digital cameras and camcorders have built-in sensors 
which can measure lighting conditions in real-time and make 
corresponding correction to the captured images. On the other 
hand, the market of consumer electronics relies largely on the 
sale of low-end cameras, which must estimate the lighting 
conditions based on the contents of the captured images using 
software algorithm. Existing white balance algorithms fall 
into the following four categories: gray world method [1][2], 
Retinex method [3]-[7], gamut mapping method [8]-[10], and 
specular reflection method [11]-[14]. Gray world method is 
based on gray world assumption: Suppose that an image has 
abundant colors under standard light source (e.g., D65), the 
average value of its red (R), green (G), and blue (B) separates 
would be gray, i.e., R=G=B. Therefore, adjustment may be 
applied to each color separate to ensure that the modified 
image satisfies the assumption. Retinex method assumes that 
a normal scene contains various objects which reflect full 
intensity of the red, green, and blue components of the light 
source. Hence, the maximum red, green, and blue component 
values from a captured image may be utilized to estimate the 
color of the light source. Gamut mapping method establishes a 
database of the R/G/B components of the light reflected from 
all possible object surfaces under known standard light source, 
which forms a convex hull sH . As next step, various R/G/B 
,(((
796
                                      
set defined over an interval. Let 1x , 2x , and 3x  represent one 
measurement of R , G , and B  components, respectively, 
from an  image subject to an illuminant with color 
temperature y . The following NM  fuzzy inference rules 
may be constructed:  
Rule 1~Rule M: If 1 2 3( , , )x x x  is 11 21 31
i i iA A A  , then y  is 1B , 
1,...,i M . 
Rule M+1~Rule 2M: If 1 2 3( , , )x x x  is 12 22 32
i i iA A A  , then y  
is 2B , 1,...,i M . 
  
Rule (N-1)M+1~Rule NM: If 1 2 3( , , )x x x  is 1 2 3
i i i
N N NA A A  , 
then y  is NB , 1,...,i M . 
where   denotes taking ‘AND’ operation of the fuzzy sets, 
e.g., 1 2 3 1 2 3 1 1 2 2 3 3[ ]( , , ) ( ) ( ) ( )A A A x x x A x A x A x   . Besides, 
1
i
jA , 2
i
jA , and 3
i
jA  represent the fuzzy sets of ijR , ijG , and 
ijB , respectively, corresponding to the ith reference object 
subject to the jth reference illuminant. The outputs of the 
NM  rules may be further combined by a defuzzification 
algorithm. Here the centroid method or center average 
defuzzifier is utilized, i.e., 
 
1 2 3 1 2 3
1 1
1 2 3 1 2 3
1 1
( , , )
( , , )
N M
i i i
j j j cj
j i
N M
i i i
j j j
j i
A A A x x x y
y
A A A x x x
 
 
             
 
 
 (1) 
where cjy  denotes the centroid of the fuzzy set jB . The 
formulated fuzzy logic system is such that it accepts the 
values of R , G , and B  components from a captured image 
under an unknown illuminant and is capable of making 
deduction of the color temperature of the illuminant. 
B. Configuration and Training of the Fuzzy Neural Network 
To enhance the performance and improve the robustness 
of the fuzzy logic system developed previously. The fuzzy 
logic system may be topologically depicted as a neural 
network. Let  ka  be the input and the output of the kth layer 
of the network. The functions of the four layers and the 
corresponding nodes and links may be described as follows: 
Layer 1: No computation is done in this layer. Here 1x , 2x , 
and 3x  are the inputs to layer 1 of the neural network, which 
has 3 nodes and transmits the input values directly to the next 
layer, i.e., 
 (1) (1)i ia u x   (2) 
Layer 2: This layer has 3NM  nodes and performs the 
fuzzification operation. Each node in this layer consists of the 
fuzzy set, 1
i
jA , 2
i
jA , or 3
i
jA , and each fuzzy set is specified as 
a Gaussian membership function, i.e., 
  
  22
2 exp i i
i
u m
a 
          
 (3) 
where im  and i  are, respectively, the center (or mean) and 
the width (or variance) of the Gaussian membership function 
of the ith input variable iu . The link weights between layer 1 
and 2 are set to unity. 
Layer 3: This layer has NM  nodes with each node 
performing the ‘AND’ operation, i.e., 
     
3
3 3
1
i
i
a u

  (4) 
The output of this layer represents the firing strength of the 
corresponding fuzzy rule. The link weights between layer 2 
and 3 are also set to unity. 
Layer 4: This layer consists of a single node which acts as a 
defuzzifier by integrating all the signals from layer 3 using the 
centroid method, i.e., 
 
(4)
(4) 1
(4)
1
NM
i i
i
NM
i
i
u w
a
u





 (5) 
where iw  is the centroid of the output membership function 
and can be regarding as the link weights between layer 3 and 
4. 
Training of the FNN involves adjusting the center/width, 
im  and i , of each Gaussian membership function in layer 2 
and the link weights, iw , between layer 3 and 4 such that the 
output generated by the network for a given input pair is as 
close to the reference or desired color temperature as possible. 
Mathematically, the objective is to minimize the error 
function 
      
 
 
 
2
4
2 1
4
1
1 1
2 2
NM
i i
d di
NM
i
i
u w
E t y t y t y t
u


            


 (6) 
where  dy t  is the desired output and  y t  is the actual 
output. For each training sample, starting at the input nodes, a 
forward pass is used to compute the activity levels of all the 
nodes in the network to obtain the current output  y t  
according to (2)-(5). 
A back-propagation type algorithm is employed to adjust or 
update the three aforementioned set of parameters. With the 
error function defined in (6), the update rules for the free 
parameters in the FNN are summarized as follows: 
(1) Update rule of kw  (the link weight between layer 3 and 
4): The update rule of kw  is 
798
                                      
lots of image pixels with zero intensity. Those pixels will not 
be affected by (15) and will therefore degrade the white 
balanced image. To solve this issue, (15) may be modified as 
follows: 
 
   
  
   
  
65
65
65
max 1, . . 6500 100
         max 1, . . 6500 100
max 1, 6500 . . 100
         max 1, 6500 . . 100
awb D c
awb D c
awb D c
R R E T R R
E T
G G G G
B B E T B B
E T
   
 
 
   
 
 (16) 
where . .E T  is the estimated color temperature of the unknown 
illuminant. The idea behind the proposed modification is to 
shift the intensity of the red or blue color separate (add a 
positive constant) when subject to illuminants of high or low 
color temperature, adjust the pixel values, and then shift the 
intensity of the color separate back (add a negative constant). 
III. EXPERIMENTAL PROCEDURES AND RESULTS 
A color checker containing patches/segments may serve as 
reference objects with different surface colors. A high-end 
digital camera with a native resolution of 3888 2592  pixels 
is utilized to acquire raw image data. Note that the raw image 
is not affected by the camera’s built-in color balance functions. 
The raw data is then converted to TIF format which preserves 
the original lighting condition of the image. A light booth 
provides various illuminants with known color temperature (A: 
incandescent of 2856K, U30: warm white fluorescent of 
3000K, CWF: cool white fluorescent of 4150K, and D65: 
daylight of 6500K) inside which the color checker can be 
placed with desired orientation. Among them, D65 is the 
desired or reference illuminant, and the image captured under 
D65 can be regarded as the reference image (with desired 
white balance). Other images captured under A, U30 and 
CWF are treated as test images (to be white balanced). The 
reference image is shown in Figure 3(a), and the test images 
subject to other illuminants are given in  Figure 3(b), Figure 3 
(c), and  Figure 3(d). 
We propose the following method, which takes into 
account statistical variation (both static and dynamic) among 
image pixels, to select a set of reference objects which 
provide samples and initial conditions for training the FNN. 
First, the color checker is positioned properly inside the light 
booth. For each known illuminant, raw image of the color 
checker is collected six times using the high-resolution digital 
camera, with each taken 20 seconds apart. Pixels of a 
specified area ( 370 370  pixels) from each color patch on the 
raw image become candidates of training samples. Hence, 
there are a set of 370 370 6   candidate pixels corresponding 
to each color patch, which account for time and spatial 
variation of that specific color. For each color patch, 
histograms are generated for the R/G/B components of the 
candidate pixels. Twenty candidate pixels lying within the 
interval of one standard deviation from the mean are then 
randomly selected as the training samples with respect to an 
illuminant of known color temperature. The means and 
standard deviations of the R/G/B histograms also provide 
sensible initial values of the center and width of the 
membership functions in layer 2 of the FNN. The centroid of 
the output membership function is set to 0. The desired output 
is set to the normalized color temperatures of the known 
illuminants, i.e., [2856,3000, 4150,6500] 6500 . For each 
training cycle of the FNN, a training sample and a desired 
normalized color temperature are presented to the network. At 
the end of each training cycle, the square root of (6) or the 
root mean square error (RMSE) is recorded. Note that the 
learning rate   is set to 0.005, and the number of training 
cycles is set to 1000. The RMSE versus training cycle is 
shown in Figure 2. The RMSE is 0.151036 at the end of the 
first training cycle and is reduced to 0.005041 after 1000 
training cycles. 
After training of the FNN is complete, test images (see 
Figure 3(b), Figure 3(c), and Figure 3(d)) are then utilized to 
demonstrate the proposed white balance approach. Using the 
method described previously with a threshold of 0.5, the 
estimated color temperatures are 4151K, 2993K, and 2850K, 
which are very close to the actual color temperatures of the 
illuminants. Using the white color patch as the reference white 
object, of which the R, G, and B components under various 
illuminants are listed in TABLE I, The data from TABLE I 
can be curve fitted using polynomials of degree two. As a 
final step, (16) is applied and the white balanced images are 
provided in Figure 3. All the white balanced images, i.e., 
Figure 3(e), Figure 3(f), and Figure 3(g), can be concluded to 
be visually closer to the reference image, Figure 3(a), than the 
original images, i.e., Figure 3(b), Figure 3(c), and Figure 3(d). 
A study is made which compares the proposed white 
balance method with other methods in existing literature, i.e., 
gray world method (GWM) [1][2], specular reflection method 
(SRM) [11]-[14], Lam’s method [16], Chikane's method [17], 
Huo's method [18], Wang's method [19], and Chen’s method 
[20]. The study employs the same set of reference image and 
test images as given in Figure 3. Each test image is processed 
by each individual algorithm and produces a white balanced 
image. To compare the results quantitatively, two 
performance indices are introduced. The average chromaticity 
(AC), commonly used in the literatures (e.g., [17]-[19]), for a 
white balanced image is given by 
    2 2AC Cb Cr   (17) 
where Cb  and Cr  are mean values of the corresponding Cb 
and Cr color separates. Since calculation of the AC value does 
not involve a reference image (with desired balanced color), it 
is arguable to state that a method producing a white balanced 
image with low value of AC performs better than the others. 
Therefore, another performance index for comparative study 
will be utilized. When a reference/desired image is available, 
it is common practice to use mean square error (MSE) for 
quantitative evaluation of how well an image processing 
algorithm performs [15]. In this study, we have a reference 
image, which is the image digitally captured under desired 
800
                                      
[12] H.-C. Lee, “Method for computing the scene-illuminant chromaticity 
from specular highlights,” Journal of the Optical Society of America A, 
vol. 3, pp. 1964-1699, 1986. 
[13] M. D’Zmura and P. Lennie, “Mechanisms of color constancy,” Journal 
of the Optical Society of America A, vol. 3, pp. 1662-1672, 1986. 
[14] S. Tominaga and B. A. Wandell, “Component estimation of surface 
spectral reflectance,” Journal of the Optical Society of America A, vol. 
7, pp. 312-317, 1990. 
[15] Z. Wang and A.C. Bovik, Modern Image Quality Assessment, Morgan 
& Claypool Publishers, 2006. 
[16] H.-K. Lam, O. C. Au, and C.-W. Wong, “Automatic white balancing 
using luminance component and standard deviation of RGB 
components,” IEEE International Conference on Acoustics, Speech, and 
Signal Processing, Montreal, Canada, pp.493-496, 2004. 
[17] Chikane, and C.-S. Fuh, “Automatic white balance for digital still 
cameras,” Journal of Information Science and Engineering, vol.22, no.3, 
pp.497-509, 2006. 
[18] J.-Y. Huo, Y.-L. Chang, J. Wang and X.-X. Wei, “Robust automatic 
white balance algorithm using gray color points in images,” IEEE 
Transactions on Consumer Electronics, vol.52, no.2, pp.541-546, 2006. 
[19] P.-M. Wang and C.-S. Fuh, “Automatic white balance with color 
temperature estimation,” IEEE International Conference on Consumer 
Electronics, pp. 1-2, 2007. 
[20] C.-L. Chen and S.-H. Lin, “Formulating and solving a class of 
optimization problems for high-performance gray world automatic 
white balance,” Applied Soft Computing (revision submitted). 
 
 
 
TABLE I. The R, G, B components of the reference white object. 
 2856K 3000K 4150K 6500K 
Red 255 244 237 212 
Green 179 182 196 208 
Blue 88 106 138 207 
 
 
 
TABLE II. The MSE between test and reference images (in YCbCr color 
space). 
Color temperature Illuminants for the test images 4150K 3000K 2856K 
Before being white balanced 283.9 599.94 943.68 
SRM 203.25 503.21 705.31 
GWM 170.1 360 612.66 
Lam’s method 137.4 260.98 403.55 
Chikane's method 97.21 136.39 422.15 
Huo's method 159.46 528.45 825.72 
Chen’s method 98.49 173.01 274.62 
Wang’s method 75.78 459.8 797.9 
A
fter being w
hite 
balanced 
The proposed  method 50.42 84.62 154.29 
 
 
 
TABLE III. The average chromaticity values of the test images. 
Color temperature Illuminants for the test images 
4150K 3000K 2856K 
Before being white balanced 32.81 43.9 52.38 
SRM 20.91 42.23 48.1 
GWM 0.03 0.06 0.4 
Lam’s method 5.25 8.23 9.34 
Chikane's method 9.34 16.05 17.3 
Huo's method 22.23 34.5 45.37 
Chen’s method 2.15 4.79 5.35 
Wang’s method 14.89 38.61 47.68 
A
fter being w
hite 
balanced 
The proposed  method 11.26 10.41 18.09 
 
 
 
TABLE IV. Ranking of various methods. 
Performance Method Time (sec.) Complexity 
MSE Chromaticity 
SRM 6.8156 (2) Low 8 8 
GWM 3.3031 (1) Low 5 1 
Lam’s method 71.1281 (5) Middle 4 3 
Chikane's method 19.0438 (4) High 3 5 
Huo's method 106.7594 (6) Middle 7 7 
Chen’s method 14 (3) High 2 2 
Wang’s method 774.1407 (8) Middle 6 6 
The proposed 
method 268.1813 (7) High 1 4 
 
R G
B
object A
object B
object C
object D
light source #1
light source #2  
Figure 1: The colors reflected from four monochromatic objects (labeled as A, 
B, C, and D) follow different trajectories in RGB color space when subject to 
different illuminants. 
 
 
0 100 200 300 400 500 600 700 800 900 1000
0
0.02
0.04
0.06
0.08
0.1
0.12
0.14
0.16
0.18
0.2
training cycle
R
M
S
E
X: 1000
Y: 0.0002486
R
M
S
E
 
Figure 2: Root mean square error versus training cycle. 
 
(a)
(d)(c)
(g)(f)(e)
(b)
 
Figure 3: Before being white balanced: (a) reference image - 6500K, (b) test 
image - 4150K, (c) test image - 3000K, (d) test image - 2856K. After being 
white balanced: (e) test image - 4150K, (f) test image - 3000K, (g) test image 
- 2856K. 
802
國科會補助計畫衍生研發成果推廣資料表
日期:2011/10/20
國科會補助計畫
計畫名稱: 智慧型色彩恆常演算法與其在數位相機之應用
計畫主持人: 陳正倫
計畫編號: 99-2221-E-005-104- 學門領域: 智慧型控制
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
