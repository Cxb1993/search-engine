studied and formalized in Zadrozny’s paper in [7]. In this
paper, we consider our case as feature bias and apply the
cost-proportionate rejection sampling method in [7] to cor-
rect our biased training examples which contains only “sold
items”. We use starting price and sellers’ feedback score as
the sample selection probability. We show in experiments
that the predicted end-price is closer to the actual end-price.
On the other hand, end-price alone is not enough for auc-
tion sellers to predict their net revenue. As described above,
end-price prediction and sold probability are two things that
could not be maximized at the same time. Thus, we argue
in this paper that sold probability should also be considered
in sellers’ decision process and a decision based on both sold
probability and end-price should give higher profit than con-
sidering them alone. To this end, an accurate probability
for each class membership is necessary. Although most su-
pervised classifiers output ranking scores for examples, they
need to be calibrated into probability. In this paper, we
use Platt’s parametric approach to map SVM scores into
well-calibrated sold probability [4]. We show in experiments
that we can get higher profit gain with the support from
calibrated probability than probability without calibration.
Finally, although some researches suggest the use of pre-
dicted end-price for selling strategy, their papers did not
address the problem of how to apply predicted end-price
in decision making but only focus on precision of end-price
prediction. For this problem, we proposed the use of cost-
sensitive decision making to resolve whether to list a com-
modity or not. We compare three different decision criteria
respectively: one depends on sold probability), another de-
pends on end-price, and the other depends on both of them.
We use profit gain over average profit of similar items sold
by similar sellers as our measure and show that CS (cost-
sensitive) approach provides highest profit gain than the first
two approaches.
The rest of the paper is organized as follows: In Section
2, we describe the data and features used by our learning
algorithms. Section 3 discusses the criteria to support the
decision whether to use current auction setting. Section 4
and 5 details the procedure for sample bias correction and
sold probability calibration, respectively. We report our ex-
perimental evaluations to prove our argument in Section 6.
Finally, in Section 7, we summarize the contribution of this
paper and suggest the directions for future work.
2. DATA
We write a crawler to collect auction data from eBays in
the category of digital cameras over a period of two months
in March-April 2006. We select five models (A530, SD600,
SD550, S2, A620) of digital camera with maximum transac-
tions. There are a total of 4,852 records extracted for our
research. Table 1 shows the statistical information of the
data set. Note that we exclude old commodities from our
data set because they are highly affected by their descrip-
tions and pictures which is hard to predict by our collected
data.
We preprocess the collected data to extract for each auction
item 72 features which are classified into 3 classes as used in
[1]:
Table 1: Statistics of the collected data set
Model No. of Sale Average Standard
Items Ratio end-price Deviation
A530 881 0.63 177 34
SD600 831 0.64 296 38
SD550 807 0.44 321 44
S2 1021 0.73 361 62
A620 1312 0.61 269 47
Table 2: Comparison of auction listing and BuyIt-
Now listing
Auction Listing BuyItNow Listing
Model No. Sale End- No. Sale End-
Items Ratio Price Items Ratio Price
A530 427 0.92 172.12 454 0.35 189.46
SD600 394 0.96 292.75 437 0.34 304.06
SD550 322 0.76 313.31 485 0.22 338.07
S2 538 0.96 339.98 483 0.46 409.95
A620 626 0.94 258.30 686 0.30 301.06
• Seller Features: feedback score, negative feedback,
positive feedback, IsPowerSeller, HasAboutMePage,
HasEBayStore, ActivePeriod, number of products listed
by the seller, etc.
• Item Features: memory size, warranty, bundled kits
(bag, battery, memory, tripod, lens, memory, reader,
etc.).
• Auction Features: auction listing or BuyItNow list-
ing, starting price, BuyItNow price, shipping cost, start
date, end date, auction duration, pictures, presence of
reserve price, payment method, listing upgrade fea-
tures (bold, subtitle, etc.) some predefined words in
title or subtitle (no reserve, fast ship, etc.).
Generally speaking, sellers have two ways to sell items on
eBay - Auction listing and BuyItNow listing. For auction
listing, sellers give a starting price and then the buyers bid
for the item until the auction duration is over. For Buy-
ItNow listing, sellers give a direct price (BuyItNow price).
Once any buyer is willing to pay the price, the bid is over. As
shown in Table 2, except the SD550, almost all items were
sold out (Sale Ratio: 0.92∼0.96) for auction listing. For
BuyItNow listing, the sale ratio is much lower (0.22∼0.35)
and the average end-price is higher since most sellers are
professional sellers and the sale is usually associated with
more kits as we will see later.
Table 3 shows the average starting price and listing cost for
sold and unsold items, respectively. Listing cost refers to
money paid to eBay, which depends on the auction setting.
As we can see, unsold items have higher starting price and
listing cost than those of sold items. This can be explained as
auction sellers set higher starting bids in order to get higher
end-price, but the auction fails due to the same reason. In
this situation, auction sellers also incur additional lost due to
higher starting price. As for BuyItNow listing, items with
higher BuyItNow price seem to scare many buyers away.
Thus, sellers need to spend more listing cost to promote their
commodities (e.g. via advertisement), showing the intense
outcome of the four cases has different profit gain. For this
kind of problem, cost-sensitive decision making is a good
approach that could changes decision boundary to help us
choose the class with maximum profit gain. Suppose we
can estimate the probability for each class j, P (c = j|x),
Bayes’ risk theory suggests that we choose class i with the
maximum expected profit gain as follows.
argmax
i
ΣjP (c = j|x)Mx(i, j) (2)
The idea is similar to Zadrozny and Elkan’s work on KDD-
Cup98 data set [8], where they apply direct cost-sensitive
decision making to send mail only when the expected dona-
tion is greater than mailing cost. In this case, we suggest
the use of current auction setting only when the expected
profit gain is greater than listing cost plus ultra cost.
In summary, we have three approaches of decision criteria:
• Sold Probability Based Approach: When the pre-
dicted sold probability is greater than 50%, i.e. P (c =
1|x) > P (c = −1|x), we suggest the seller list the
auction. Thus, this approach depends only sold prob-
ability alone.
• End-price Based Approach: When the predicted
end-price is higher than the average end-price of sim-
ilar items, i.e. y(x) > Avgy(x), we suggest the seller
list the auction. Thus, this approach depends only sold
probability alone.
• Expected Profit Based Approach: When the ex-
pected profit gain for suggesting sell is greater than
zero, i.e.
P (c = 1|x)[Profit(x)−AvgP (x)] >
P (c = −1|x)[lc(x) + uc] (3)
we suggest the seller use the current auction setting.
Thus, this approach combines both sold probability
and end-price.
4. END-PRICE PREDICTION
There are two types of auction end-price predication: static
and dynamic. The former uses machine learning algorithms
and is more useful for auction bidders while the later applies
functional data analysis and is important to auction sellers.
To support auction sellers in commodity listing, we only
need static end-price predication as auction setting must be
determined before the auction begins.
4.1 Multiple Binary Classification
In this paper, we use multiple binary classifiers to predict
the end-price for auction listing items [1]. The idea is to sort
auction items by their prices and divide data into two classes
at various prices. For each price $Yi, we train a binary
classifier which judges whether the end-price is greater than
$Yi or not. The output for a test example x upon this binary
classifier is then a three-tuple (”>$Yi”, true/false,θ) showing
that x is greater than $Yi (true; or false otherwise) with
confidence θ. Finally, the end-price is determined by the
largest $Yi (and its larger neighbor $Yi+1) which predicts x
as true. For example, if the outputs of three binary classifiers
50,45, and 40are(” >50”, -1, 0.8), (”>45”, 1, 0.85), (” >40”,
1, 0.9), we determine the end-price locates between segment
50 and 45 and take the mean value 47.5 as the predicted
end-price. As discussed in [1], each binary classifier can use
the full data set as training data, which is important for
data sets with few transaction items.
4.2 Sample Selection Bias Correction
As described above, since we can only use sold items as the
training data for end-price prediction, the selection of exam-
ples for training is biased. We can interpret this situation
as many high end-price items are not selected from training
set due to their lower sold probability. In other words, the
negative correlation between sold probability and end-price
will cause the prediction price lower than its real value.
Sample selection bias problem has been studied in economet-
rics and statistics. Heckman [2] proposed a two-step proce-
dure to solve the problem in 1979. However, the method
is limited to linear regression model. In recent years, there
are some researches from machine learning field [5, 7] which
focus on discrete predication, i.e. classification problem.
There are four kinds of sample selection bias [7]:
• Complete Independent: Selection variable s is in-
dependent of attribute x and label y, that is, P (s =
1|x, y) = P (s = 1), then the selection is not biased.
• Feature Bias: Selection variable s is dependent of
attribute x and independent of label y with attribute
x, that is, P (s = 1|x, y) = P (s = 1|x).
• Class Bias: Selection variable s is dependent of label
y and is independent of attribute x with label y, that
is, P (s = 1|x, y) = P (s = 1|y).
• Complete Bias: Selection variable s is dependent of
both attribute x and label y, that is, P (y|s = 1) 6=
P (y) and P (x|y, s = 1) 6= P (x|y).
In our work, whether an item is sold can be taken as a selec-
tion variable s, label y is the discretized end-price segment,
and property x means the features (including seller features,
item features, and auction features). Since the data used for
end-price prediction are all sold items (s=1), we only have
data sets for (x, y, s=1) and (x, s=0) but not (x, y, s=0),
which is the most complicated complete bias case (s is de-
pendent of both x and y). In theory, we cannot predict
under complete bias. Thus, we need further assumption to
solve the complete bias problem.
We assume that items with the same features have the same
end-price, and therefore the same label, no matter it is sold
or not, that is, P (y|x) = P (y|x, s = 1). With this assump-
tion, the problem can be simplified to feature bias problem
as shown in equation (4).
P (s = 1|x, y) = P (x,y|s=1)P (s=1)
P (x,y)
= P (x|s = 1)P (y|x, s = 1)× P (s=1)
P (x,y)
= P (x|s = 1)P (y|x)× P (s=1)
P (x,y)
= P (s=1|x)P (x)
P (s=1)
× P (x,y)
P (x)
× P (s=1)
P (x,y)
= P (s = 1|x)
(4)
Table 5: Classification accuracies for SoldOrNot pre-
diction
MODEL AUCTION LISTING BUYITNOW
A530 91.9 71.5
SD600 96.1 76.8
SD550 92.9 84.8
S2 94.5 71.4
A620 92.1 76.5
AVERAGE 93.5 76.2
Figure 3: Starting price difference, feedback score
and kits amount in each sold probability interval in
auction listing
sellers have multiple items to sell but the market need is
lower, thus, some are sold while others are not.
Recall from Table 3 that sold items have lower starting price.
Thus, we expect to see that items with higher starting price
should have lower probability. To do this, we extract data
with starting price greater than average end-price (of its
similar items) from the auction listing and show the aver-
age starting price of items in each sold probability range in
Figure 3. The blue bars represent the average difference of
starting price with similar items. As we can see, items with
low sold probability have higher price difference, while items
with high sold probability have lower price difference.
Figure 3 also presents the average feedback score (red bars)
of sellers in each probability range. Generally speaking,
items with higher sold probability also belong to sellers with
higher rating, which is consistent with general expectation.
The next information is the average amount of kits (yel-
low bars) associated with items. Since the items analyzed
in this figure have high starting price than average, the Kit-
sAmount in average is not low and has a positive correlation
with sold probability. To simplify the figure, we did not show
the number of examples and accuracy of prediction in each
probability range. Since most items (even for higher starting
price) in auction listing are sold, the estimated probabilities
tend to locate on the right end. Thus, items with higher
sold probability dominate larger percentage (70%∼90%) of
the high starting price items, except for SD550 where half
the items are not sold. Note that all the values, including
price difference, feedback score and kits amount are normal-
ized into a number between 0∼1 to fit into the figure.
As for BuyItNow listing, we gather data within the same sold
probability range and calculate the difference of BuyItNow
price and the average BuyItNow price of similar items. Fig-
ure 4 shows an even stronger negative correlation between
the price difference and sold probability than auction listing.
If the BuyItNow price is greater than the average price of
similar items, the items would have very low sold probabil-
ity. However, sellers’ feedback score and items’ kits amount
do not present such strong correlation with estimated prob-
ability as shown in Figure 5. Thus, sellers should focus on
the BuyItNow price in the domain of BuyItNow listing.
From the analysis above, we confirm our argument that
starting price could strongly affect sold probability. Thus,
when sellers use high starting price or BuyItNow price ap-
proach to ensure higher end-price, they should also consider
sold probability as well. Note that, probability calibration
is necessary; otherwise the probability will be either 0 or
1 and cannot indicate the relationship between probability
and listing setting.
6.2 End-price Prediction
To use multiple binary classifiers for end-price prediction, we
need to decide the reference value $Y for each binary classi-
fier. We exclude the highest and lowest end-prices, and use
10% window of the average end-price as the interval size,
i.e. $Y is increased by 10% of the average end-price for each
binary classifier. The number of intervals for each model is
shown in the second column (denoted by “No. of Int”) in
Table 6. Again, SVM is used as the base classifier to predict
whether the end-price is greater than the reference value $Y.
For the collected digital camera data, the major factors af-
fecting end-price are the kits amount and the memory size.
Since there are a variety of kits can be associated, the price
varies greatly even for the same digital camera item, which
causes the difficulty for prediction. Table 6 shows the result
of multiple binary classifiers for sold items. Though the ac-
curacy is not high (51%) for the target interval, the accuracy
approximates 90% within ±1 interval range.
As described above, due to sample selection bias problem,
the predicted model (based on training data with only sold
items) will underestimate the end-price of items with low
sold probability. With the assumption that items with the
same features will also have the same end-price, we apply
the modified costing algorithm to correct the feature bias
problem. Hence, we also need to ensure that p(x, s = 1)>0,
that is, the selected data contains all feature spaces of the
data and with enough examples in each feature space. As
starting price and feedback score are the main factors affect-
ing the sold probability, we use these two features to predict
p(s = 1|x) for each example. For each of the five training
sets (of each digital camera model), we calculate the weight
(i.e. p(s = 1)/p(s = 1|x)) for every example and use re-
jection sampling to generate 10 sample sets (t=10). Each
sample set has about 250 examples. We then apply SVM to
train classification models for each $Y, and use the vote of
the 10 predictions as the final result for each binary classifier
with judgment whether the end-price is greater than $Y.
To see how the correction of feature bias calibrates the pre-
diction of unsold items, we extract unsold items with start-
ing price greater than average end-price of similar items and
compare the predicted end-price before and after calibra-
tion in Table 7. The result shows that the predicted end-
price based on sold items without costing correction is lower
than the average starting price of these items (i.e. under-
estimate), while the predicted end-price after calibration is
closer to the average starting price. Similarly, we compare
the predicted price before and after costing calibration for
linear regression. Contract to the result for multiple binary
classifiers, only SD550 presents visible change by the correc-
tion. We suspect it’s because SD550 has more unsold items,
thus has more impact for linear regression approach based
on mean square errors. As shown in Table 6, the accuracy
before and after calibration is about the same. Thus, the
calibration for sample selection bias does not only maintain
the accuracy for sold items but also has better prediction
for unsold items.
6.3 Profit Gain Comparison
In order to validate our argument that end-price alone does
not guarantee high profit due to low sold probability, we use
profit gain over other sellers to compare the three approaches
described in Section 3. Figure 6 and Figure 7 show the
average profit gain of the three approaches for BuyItNow
listing and auction listing, respectively. We also use “Sell
All” approach as the baseline for comparison, which suggest
selling all the time.
For BuyItNow listing set, the end-price based approach uses
the BuyItNow price as end-price and suggests sale if the
BuyItNow price is greater than average BuyItNow price
Figure 6: Average profit gain for BuyItNow listing.
of similar items sold by similar sellers; while profit based
approach uses sold probability either with or without sold
probability calibration. Figure 5 show that the baseline ap-
proach (“Sell All”) makes a loss of $2.882 than average even
at uc=$0 since the sale ratio is only 22%∼46%. With the
help of sold probability prediction, we can obtain an average
profit gain of $0.967 at uc=$0. As uc increases, probability
based approach gains even more profit than average since we
have ultra cost if the commodities are not sold. On the other
hand, end-price based approach although makes a high gain
of $4.578 than average at uc=$0, the profit gain decreases to
$3.769 as uc increases to $6 due to the decrease in sold prob-
ability. Finally, approaches based on expected profit (either
with or without probability calibration) obtain the highest
profit gain. Even when extra cost uc increases, the average
profit gain increases as well, which means expected profit
based approaches avoid the loss of unsold items by balanc-
ing the expected profit. As seen from Figure 6, probability
calibration improves profit gain by making more accurate
estimation in sold probability.
Figure 7 shows a similar result in auction listing, though
the change with ultra cost is not as obvious: the base line
approach has a profit gain of $0.025 at uc=$0, while proba-
bility based approach even makes a loss of $0.081 at uc=$0.
Thus, if most items could be sold, sellers could simply use
“sell all” approach. However, sale amount based approach
does not deteriorate like the base line approach as ultra cost
increases.
Similar to BuyItNow listing, end-price based approaches (ei-
ther with or without correction by costing) show a negative
correlation with ultra cost, while only profit based approach
maintains an increasing profit as ultra cost increases for auc-
tion listing. Figure 7 also shows that end-price based ap-
proach with feature bias correction performs better than
without correction, though the difference is not obvious.
The reason why the profit gain by costing is not obvious
can be attributed to high sale ratio for auction listing data
set. Thus, we can observe more profit gain in SD550 (i.e.
the lowest sale ratio model), showing that sample selection
bias correction is more important in categories with a lot of
unsold items
7. CONCLUSIONS AND FUTURE WORK
