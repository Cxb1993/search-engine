II 
 
 
智慧型接待服務機器人之研製 
 
主持人： 謝銘原  
執行機構：南台科技大學電機工程系暨研究所 
執行期間： 民國96年8月1日至99年7月31日  
國科會計畫編號：NSC 96-2221-E-218 -039-MY3  
 
摘   要  
本計畫係設計一智慧型接待服務機器人，建立完整之互動溝通系統，以視覺
化、具親和力之人機介面，結合視覺表情辨識、語音語意辨識技術，進行令人滿
意的人機溝通，期提供互動的接待服務。本計畫分三年進行。其中，第一年完成
聽覺及語音辨識功能之開發、人臉辨識及表情辨識系統、及人機互動介面之設計
與實現與遠端監控與操作的應用等研究，同時配合各部功能，設計符合要求之機
器人機構、驅動系統、視覺系統、聽覺及語音系統、人機互動介面及導引追隨之
運動控制系統等。第二年主要發展即時方位辨識系統與自我保護系統及表情及語
意學習系統。其中利用視覺伺服系統配合感知系統可即時擷取現場環境資訊，建
立即時影像地圖於機器人資料系統中，並判斷所在區域。同時結合感測（雷射、
超音波、紅外線等）系統、即時方位辨識系統與自我充電裝置，可保護機器人避
免碰撞人或物、規劃最佳目標路線、指引帶領迷路的人、或自走運動至充電區進
行充電或調整。第三年著重身份辨識系統之開發，使機器人可以智慧判斷使用者
可能產生之行為，並予以學習應對。此外，加入多模式互動學習系統，來整合機
器人系統溝通介面，使機器人各部分機制透過傳輸協定與 I/O 可互相溝通協調，
便於建立自我學習模式，並透過整合之溝通介面來表達機器人與人之良善的互動
行為，實現一人性化的智慧型服務機器人。 
關鍵詞：智慧型接待服務機器人、即時方位辨識系統、表情及語意學習系統、多
模式互動學習系統、身份辨識系統 
1 
 
一、前言 
近年來由於科技日新月異，機器人領域各相關技術之發展相當蓬勃，舉凡機
構設計、運動規劃與控制、驅動伺服控制、影像視覺技術、環境辨識感知技術、
互動學習系統、嵌入式系統晶片開發、語音及語意分析辨識系統、整合各系統設
計研製等各方面，都有許多學者提出有效的方法。由於機器人的各項功能及動作
都互有關聯，各項技術之整合設計將是機器人研究最重要的一環。 
最早開發，也是目前發展最多的領域是工業用的機器人，如工廠所需之焊
接、切削、裝配、運輸、以及各種加工等重覆性或危險性高的粗重工作，皆可以
機器人代勞。許多機器人大多是針對特定工作協助的目的而設計，例如，
Maruyama 等人於 1993 年起陸續研發 “Phase I～III” 形機器人，應用於高壓電
力線的維修檢測工作，成果十分可觀 [1-3]，Matsumoto 等人於 2000 年，提出一
網路架構之工業形機器人之研究 [4]。此外，被定位於從事維護、保養、修理、
運輸、清洗、保安、救援、監護等工作之服務形機器人，則強調舒適化、自動化、
服務輔助的能力，多為自走式機器人（Mobile Robots），具有視覺等感知環境的
能力。 
然而，從過去機器人的研究來看，很多並不像人，有的甚至沒有一點人的模
樣，這也讓很多機器人愛好者大失所望。其實，研發出外觀和功能都與人相同的
機器人一直都是科學家門夢寐以求的願望，也是他們努力不懈追求的目標。人形
機器人就是以建造與人類相同軀體架構為目標，希望製造像人類一樣雙足直立行
走，這也是十分困難的一環。同時，具有思考、表情、動作甚至於情感的機器人，
更是各方研究人員努力的目標。雖然，目前這方面的研究還沒有顯著具體功能的
例子，但以生物體的特徵及優點為設計出發點，實現單一功能為主的研究卻透露
出許多契機。例如史丹佛大學開發的多足機器人可學習蟑螂的爬行能力 [5]，
Aspinall 以螃蟹的靈感設計用來執行水陸掃雷任務的機器蟹 [6]，都是很有創意
的研究。 
3 
 
求助及自我充電，是一個功能相當完備的服務型機器人。而德國 Gross 等人於
2001-2004 年發展於超級市場與人溝通互動的協助機器人[15-18]，具有問候、交
談、導引及解說等功能，為相當人性化的研究。 
國內過去幾年對機器人產業及研究上，大多集中在學術界，一直到 2005 年
日本愛知縣博覽會引發的機器人熱，才使我國政府開始重視機器人產業及研究之
發展。同時，國內廠商如微星、鴻海…等，也才宣示並著手機器人產品之開發。
政府主導之智慧型機器人產業發展主軸，第一階段即著重應用層面之機器人，以
創造市場及擴展優勢產業為推動目標，以導覽服務、休閒娛樂、家庭服務、生產
製造為重點方向。其中，於高雄國立科學工藝博物館服務之導覽機器人『鐵克納』
和『賽恩絲』（來自義大利），是已經服務十年以上（民國 86 年迄今）的導覽服
務機器人。2005 年 3 月由第二代「少年台客鐵克納」及「美少女賽恩絲」接
替『鐵克納』與『賽恩絲』的工作，該機器人係由台灣桃園縣傑凌公司製造，主
要是與參觀民眾互動、導覽及諮詢，是具有「思考記憶體」的機器人。其中，
「少年台客鐵克納」的興趣是科學，特別的才藝是時下流行的 RAP，而「美
少女賽恩絲」的興趣是思考腦筋急轉彎的問題，會的才藝是 POP 
Music[19]。唯該機器人雖可即時與人互動，但並不是自主式，而是由工作
人員透過遠端介面發話對談而得，這也顯現出機器人與人自主式互動對談
之困難。  
由於機器人產業的發展迅速，人工智慧在機器人應用上已逐漸擴展，加上人
類的生活水平及要求相對提高下，功能化、自動化、資訊電子化、及便利化成為
人們生活環境上的主要考量，具備人工智慧的機器人逐漸與生活產生密不可分的
關係。然而，這些機器人往往只具備機械式工作能力，卻無法與人產生良好的互
動，而且只能用在固定的場合。因此如何設計符合需求的智慧型接待服務機器
人，便成為近年來各專家學者研究發展的重點。 
智慧型接待服務機器人之主要任務在於與人互動、溝通及協助，因此其功能
應包括與人問候、寒暄、場館地圖說明、所在位置及目標位置之詢答、以及各項
資訊說明等。此外，機器人應具有自走導引之功能，可帶領人們到達目的位置，
或協助場館內需要幫助的人，如行動不便者、迷路者、孩童等。同時，機器人並
5 
 
二、研究目的 
當今社會絕大部分的家庭都是雙薪家庭，父母都必須長時間外出工作，小朋
友回到家中總是面對一個空蕩蕩的環境，外出在外工作的父母親心裡也無時無刻
懸掛於家中的寶貝小孩，害怕小朋友會有任何意外的發生，因而無法專心工作導
致工作進度落後必須加班等惡性循環。為了可以解決此問題，本研究設計一智慧
型接待服務機器人，除可在展場或公共場所執行接待任務外，也可讓機器人搖身
一變成為家中的一員，替代外出工作的父母親陪伴家中的寶貝，我們相信這將會
是未來潮流與趨勢，因為可以減少人力的負擔，也能使生活更加便捷。 
由機器人代替服務人員陪同、協助、服務或接待人們已是未來科技發展之趨
勢，而機器人功能及外觀之設計將會是讓人們接受機器人服務之關鍵點。因此，
如何提升人們與機器人互動的意願將會是本計畫機器人設計之重點。由於，影像
與聲音一直都可以引起使用者興趣之要素，因此本計畫之機器人將著重影音互動
之功能設計，讓使用者可更親近這新的服務人員，願意與之互動，也藉由影音互
動的功能提高人們的服務滿意度。 
智慧型接待服務機器人的主要功能，係具有與人溝通互動之能力。由
於人們互動溝通的主要方式之一為語音交談，因此，讓機器人可以辨識說
話者，聽懂說話者在說什麼，並可與之應對，便成為過去定義機器人是否
具有『智慧』的判斷依據。然而，欲聽懂語音及辨識詞句除需建立大量的
語音資料外，語音辨識學習及語意辨識學習系統均扮演相當重要的角色，
語音辨識是利用聲音辨識方法判別語者之音調，輔以判斷對象之概略身份。同
時，對相關人員及特定人士進行身份辨識學習及紀錄，建立知識庫，使機器人可
尋得不同身份之互動模式。 
為了可以讓使用者可以用最簡單直接的方式與機器人進行互動，利用壓力、
觸碰等感測器當做功能選擇鍵，當使用者碰觸不同的感測器機器人將會做出不同
的回應（如開心、難過等表情顯示）；此外，在操作介面的設計上，吾等也利用
活潑可愛的圖片來去取代呆板的文字按鈕，增加介面的活潑性，提高使用者的互
7 
 
三、文獻探討 
智慧型接待服務機器人，其功能應包含：（1）互動介面：機器人應具有近、
遠端互動介面，可讓使用者透過介面與之溝通。（2）表情應對及動作回應：除經
由互動介面輸入文字、點選畫面選項（近、遠端）外，機器人應可由語音（近、
遠端）及表情（近端）來產生適當之應對，如聲音（語音、音樂或特定形式之聲
音）、燈號、動作（例如打招呼、問候、高興時轉個圈等）。（3）語音互動詢答：
機器人應可與人產生互動式詢答（如以語音回應動作、問題回答、回應問候等）、
主動交談（主動問候、導覽介紹、資料解說等）、或互動式交談（直接對談）。（4）
導引及陪伴：機器人具自走功能，可導引人們到指定位置、或類似一導遊、私人
助理、或朋友之角色，可陪伴人們進行導覽說明、資訊解說或互動聊天陪伴等。 
由於聲音可說是人類及自然界中最早使用的訊號，也是最直接的通訊
方式。人與人之間之互動大多透過聲音，與影像最大的不同是，聲音無須
面對面，所謂隔牆有耳正是說明聲音傳播的效力。因此早在兩百多年前
（1780），Wolfgang von Kemplen 就設計一個可發音的機器。然而過了半個
世紀（1835），Sir Charles Wheatstone 才根據 von Kemplen 的觀念，做了一
個說話機器。但是真正可以說一句完整話的機器，是 Home Dudley 於 1939
年舊金山與紐約的世界博覽會發表的 Voder。  
1970 年代在語音比對上也發展出兩個重要的工具，一是動態時間校正
(DTW)，可用來進行兩段語音訊號的比對；另一則是隱藏式馬可夫模型
(HMM)，用來描述語音產生的過程，很適合用在連續語音辨認的演算[20]。
在語音溝通發展下，有許多的學者朝向發展語意辨識分析，不但使電腦有
語音辨識能力外，更增加了使電腦聽懂自然語言的含意，並能執行動作。
其中，2004 年 Pulasinghe 等人提出以自然語音命令應用於 Fuzzy-Neuro 的
方式操控輪型機器人的行走避障[21]，2005 年他們將此自然語音的命令模
式，應用於執行七軸機械手臂的移動與動作之控制[22]。  
有關聽覺的研究  [23-24] 包括音頻辨識、方位判別及語音辨識等。這
9 
 
際的應用裡，要進行語音辨識，必須先認出說話的人是誰，或對一個宣稱他是
誰的人，從他說話的聲音來確認是否真的就是這個人。其過程為先對聲源進行
方位判別，確定說話者之主音源後進行音頻識別，進而才是語句辨識。因此，
欲使智慧型機器人熟知環境並與人們互動溝通，單從聽覺功能開發互動模式是
有困難的，其效果也往往不甚理想。如同人類具有多種感官一般，機器人也需
從視覺、聽覺及語音等訊號，整合或選擇一最適方式，進行較佳之溝通方式。
或許人類的感官精密度，是目前各感測裝置無法達到的境界，然而透過去蕪擇
優的設計，機器人仍應可具備『耳聰目明』的感知能力。 
此外，機器人的視覺功能，往往也是互動溝通的重要媒介之ㄧ。機器人的接
收的即時影像（Real-time Image）處理技術可進行影像感知、視覺伺服控制
及物件追蹤等研究，視覺系統將先執行物件追蹤控制，鎖定人臉後進行人臉
辨識，藉由人臉特徵區別對象身份（男女、老幼、特定身份、需要協助者）。近
年來，隨著 CPU 計算能力的持續增進，影像處理技術之發展已漸趨成
熟，特別在監控或檢測等應用上，有廣泛之應用實例：例如在工業上經
由非接觸式的影像比對檢測，可以判定 IC 電路板製造的良劣。而應用視
覺技術來進行互動溝通設計者，多為行為姿態辨識及表情辨識。大部分
有關表情辨識的研究，多應用在判斷人的情緒變化。其中，研究發現且
證明了不同語言在相同語意時，其情緒變化具有相同的特徵。不過大多
數有關人的表情分析研究，多利用表情及語音之關聯性，進行情緒分析
及判別；或進一步加入人臉辨識與語音分析，進行綜合判斷，瞭解受測
對象於不同狀態呈現何種意涵；也有一些學者單純只針對人臉辨識，來
進行情緒的判斷；甚至 Gunes 等人及 Camurri 等人在研究中，利用肢體語
言的判斷，也可分辨出情緒及動作之涵義。另外，有些研究則著重探討
如何利用表情判斷人類的情緒，使機器人與人類能夠進行更有效的溝
通。  
在進行表情辨識時，視覺系統需具備物件追蹤及追隨的功能。物件追
蹤的研究通常可被分為兩方面來探討，一是如何利用有效的特徵來表達物
件；二是如何對物件作有效的偵測與追蹤。欲獲得穩定的物件追蹤，一個
很重要的課題是找到一個好的特徵。近年來，一直有學者提出不同的特徵
11 
 
音之辨識，則為機器人主動溝通判別的模式，兩者溝通的方向性不同，但實現
的效果均可提供人機互動之溝通媒介。 
 
因此在互動溝通介面上，人機介面的設計可補充表情及語音辨識的不足。但
值得注意的是，由於介面使用者間，存在許多個人差異（Individual Differences），
每一個使用者大都會希望以自己能瞭解的方式操作介面，因此在設計人機介面
時，需設計在各種操作方式下，都可使操作者達成相同的目的。這也說明，人機
介面設計也不是想像中的容易。綜合人機介面的研究分析 [30-34]，其設計原則
大致包含下列幾項：(1) 一致性 (2) 使用者擁有主控權 (3) 清晰與簡單 (4) 減
輕記憶負擔 (5) 所見即所得 (6) 個別差異 (7) 易學易用 (8) 整體的美感 (9) 
適當的回饋 (10) 容易復原(11) 輔助操作的擴充性。利用這些原則，應可設計較
符合使用者需求的人機介面。 
雖然有不同的困難點存在各種人機互動溝通方式上，但若以機率的觀點來
看，如同打靶問題一般，多射擊打中靶的成功率亦會隨著次數快速提高。因
此，多個互動介面同時提供各項互動資訊，進行整合學習後，將可以提高整體
之辨識準確度，且可免除單一介面發展的極限與障礙，截長補短，進而達到互
動溝通之目的。 
 
 
13 
 
特定句子段落，將產生不同的聲紋檔案，並記錄在語音辨識的資料庫，透過特徵
值的擷取及建立，可作為參考之樣本以供後續之模型比對。一般常用的語音特徵
值包括下列幾項： 
(1)  能量（Energy）特徵參數： 
依照語音輸入訊號之振幅和頻率來作為語音辨識的特徵，此特徵稱為能量特
徵參數，通常用於語音辨識之端點偵測（End Point Detection）。能量判定方
式除了運用在語音辨識之端點測試以外，搭配上麥克風陣列所構成的環境聽
覺系統，針對環境的關係劃分區域，再運用模糊聲音定位辨識系統(Fuzzy 
Speech Localization Recognition)，即可尋找出音源發出之方位。 
(2)  頻域（Frequency Domain）特徵參數： 
頻域特徵參數係一般決定語音辨識時，辨識成功率高低重要參數之一。而在
頻域的研究方法上，以交越能量相位分析 (Cross-power Spectrum Phase 
analysis, CSP)這個方法最為常見，結合DOA (Different-Of-Arrival)的觀念，是
近幾年來最常運用於聽聲辨位與聲音辨識的方法。不過，由於頻域之特徵參
數之，往往需要複雜之數學計算（如快速傅利葉轉換 FFT），用於小型單晶
片上實現不易。一般設計方法為先採用帶通濾波器（Band-Pass Filter）之硬
體電路求出頻域參數後，再以微控制器來進行處理。 
(3) 時域（Time Domain）特徵參數： 
語音輸入訊號的時間長度及時域上之特徵參數，如零交率(Zero-Crossing 
Rate)、短時距能量（Short-time energy）、線性預測編碼（Linear prediction coding, 
LPC）… 等，皆可作為語音辨識的特徵。由於人在說話的過程中有效音的
部份會有較大的能量，因此利用這個特性就能在一段話中，找到好幾個突
波，就表示為有聲音段的部份，而這些突波與中斷的部份是相鄰接的，所以
說只要判定出無效音中斷的部份，就也能找到有效音的部份，只要針對這些
部分加以去判定，就能找到正確的語者方向，也能減少運算量，並且把雜訊
部份與有效音的部份做一個區隔。有時，設計者也可能同時採用時域與頻域
的特徵參數，在某一時段內取出特定頻率的混合式特徵參數作為語音辨識之
有效參數。 
15 
 
有效之噪音防治係增加聲音辨識的成功率原因之一，故噪音診斷之研究也是
語音辨識重要之部分。許多學者對聲場空間轉換（Spatial Transformation of Sound 
Field, STSF）分析技術，提出探討及研究 [35-38]。此方法係一種經由二維表面
非接觸式的聲壓量測，推算整個三維空間聲源的表面聲場資料，如近場聲壓、聲
強、遠場聲壓、聲場等。利用不同噪音源（可視為特定聲音）進行 STSF 方法的
驗證與實驗，可以單一音源及多重音源方式進行分析，取得音源可能之分佈特
性，進而辨識音源的位置、強度。並利用不同發聲距離分析近場與遠場模型之不
同，以及聲強與距離之衰減關係。 
由於近場中感測器陣列接收到的訊號波前為球面波（spherical wave），需考
慮球面擴張因子（spherical spreading factor），此點相對於遠場訊號，分析上較為
複雜。同時機器人與音源之相對運動往往非固定，且聲音於環境中會遭受反射、
繞射之影響，因此近場與遠場聲音之辨識上，需透過學習法則，以不同數目及配
置的取音感測器，分別進行取音實驗。以不同方位、強度、音頻等聲音，進行測
試與分析，藉由比對及訓練，找尋最大關聯值，建立近場與遠場之聲音模型，進
而提供音源方位之辨識。 
 
圖 1 麥克風陣列語者定位系統架構圖 
本計畫之聽覺系統架構，如圖 1 所示，大致可分成音訊接收系統、資料擷取
系統及音源方位判定系統。在音訊接收系統部分，主要是用來接收聲波訊號，本
計畫的外部麥克風陣列是由數個電容式麥克風排列構成，由於電容式麥克風接受
到聲音訊號轉換成電壓的變化量非常小，所以必須經過放大處理後才能得到較為
17 
 
 
圖 2（a）輸入（Input, V1, V2）之歸屬函數 
 
圖 2（b）輸出（Output,  ）之歸屬函數 
當系統於實際環境應用時，必須考量環境條件的影響，尤其是未知的音訊反
射的問題。為了克服這方面的問題，本子計畫設計一模糊架構之語者定位系統，
使其模擬人耳功能，能適應環境條件的影響來進行聲音前後遠近的判定。由實驗
結果可看出系統初步驗證之成效，以及所提架構之可行性。這部分之研究部分成
果，亦已於國際會議發表 [39-41]。 
4.2 視覺及人臉辨識功能之設計與實現 
本機器人之視覺系統主要用以環境偵測、辨物追蹤及規避障礙物外，還包含
一人臉辨識系統，可利用 webcam 攝影機擷取即時影像，同時偵測出人臉，進行
身份辨識。 
系統會先判斷環境燈光的條件進行亮度調整，若有人進入到影像範圍內，則
經由膚色分割及影像處理決定膚色區域，再由橢圓遮罩鎖定人臉及偵測眼睛與嘴
唇來判定是否為人臉。由一系列的演算法整合而成，完成整個人臉偵測流程。系
統流程圖如圖 3 所示。 
一、膚色分割 
從複雜背景中將人臉分割出來的方法中，最快速且簡單的方法是擷取影像中
之膚色區域，但此法如在 RGB 色彩空間中進行，因該模型對亮度變化相當敏感，
需轉換至對亮度較不敏感的色彩空間，如 HSV、YIQ、NCC、YCbCr 等後，才
能執行後續處理。因此，本系統採用 YCbCr 色彩空間，其中 Y(luminance)代表
VN N C F VF 
0 90 22. 5 45 67. 5 
VS S M B VB 
0 3 0.75 1.5 2. 25 
19 
 
 
圖 5   人臉區域之定位結果 
1maskA
2Amask
FA FAEA
1maskB
2 Bmask
  
(a) A 為眼睛遮罩，B 為嘴唇遮罩  
  
(b) 眼與嘴之範圍偵測結果 
圖 6  臉部特徵擷取之情形 
二、人臉區域定位 
本系統利用連接元區域標定（Connected component labeling）之程序，找出
影像中屬於同一物件的相連像素，即可得知物件範圍、高度和寬度的資訊，以便
標定出各個物件。其後，再利用人臉區域的高度會大於寬度之簡單比例與範圍大
小關係，訂出寬度與高度的比值為 1:1.2，依此特性就可把非人臉區域（特別是
脖子區域）去除，亦即可篩選出較正確之臉部區域，如圖 5 黃框所示區域。 
由於人臉輪廓接近於橢圓形，因此可先以影像的邊緣偵測方法，增強影像物
件之輪廓。本系統在此採用 Sobel 法來進行邊緣化運算。之後，再利用橢圓形遮
罩來搜尋影像中最像橢圓形的物件。由於此遮罩是以其長短軸來決定範圍大小，
當攝影機擷取到人臉影像大小會隨相對取像距離不同而改變，所以透過調整橢圓
遮罩大小來符合影像中人臉的變化，由於人臉之長短軸比例約 1.2:1，可根據此
21 
 
 
圖 8  近端互動介面之系統架構圖 
 近端互動介面 
近端互動介面架構可如圖 8 所示，控制命令可由使用者輸入，或者由機器
人判別使用者的聲音或影像來決定。其中，互動介面之媒介可包括下列三項： 
1. 語音感測裝置： 
語音互動是最自然的溝通方式，人們的語言模式於不同語意情境，有不同的
對談方式。機器人的語言對話能力將以情境對話的方式來呈現，提升機器人
互動溝通的適應性。例如，於問候情境下，機器人只需依照時間、地點、交
談對象、及特定語句來進行回應。於應對式交談情境下，例如以語音回應動
作、問題回答、回應問候等，機器人只需將目前語句與應答情境之對答語句
資料庫進行比對，找尋最適合的應答語句即可。此外，於主動交談時（如主
動問候、導覽介紹、資料解說、提供協助等），機器人只需提出問題之語音，
等待對象之回應，再判斷回話之語意（往往是可以與否等之答案），即可產生
下一適切之動作。 
2. 觸控面板操作感測裝置： 
互動系統中，人機介面除硬體輸入（鍵盤、滑鼠、或遠端網路外），並增加設
計了一個觸控式介面，使用者由此可觸碰互動畫面之按鍵，該觸控命令即可
由面板與控制器，透過 USB 協定來傳遞，可說是近端互動最直接且正確的操
作方式之一。使用者經由互動介面輸入文字或觸控感知畫面選則選項後，機
23 
 
此外，因語音功能仍是人機介面最主要的溝通方式之一。因此，除了機器
人需具備語音辨識能力外，於語音發聲部分，也應設計在人機介面中。這部分
亦可實現於服務場合之各項操作、導覽、或資訊解說等功能。此外，我們亦擬
於互動介面中，設計與使用者互動語音答詢之功能，吾等只需在系統中安排一
些問答情境，由機器人提供定型化問題與使用者進行交談，透過判斷使用者是
否回答關鍵詞，即可以一連串適切的問題與之交談，讓此互動介面具有人性化
對談之效果。相類似的功能，也可以設計在導覽、資訊解說等功能上。 
 近端互動介面 
遠端的互動介面，通常透過網路環境建構而成：當系統於伺服控制端（近
端）從網路上得到客戶端（遠端）控制命令後，近端除接收即將執行的命令外，
同時分辨遠端（客戶端）的需求取向，進而詢問客戶端幾個進階分類的問題（如
同語音掛號系統先問基本選項問題般），來精準且快速地鎖定客戶端的需求目
標，並透過學習將分類過程朝人性化方向進行簡化設計。 
這裡值得注意的是，命令可能同時來自近端與遠端，介面系統必須加以判
斷，決定主從關係。這也就是遠端與近端合作協調的研究課題。網際網路的無
遠弗屆，使得遠端系統的設計在越來越多的裝置上，已成為不可或缺的功能之
一，例如許多印表機、伺服機、及辦公資訊產品均設計具備網路功能。在本研
究裡，也設計遠端控制之互動介面。 
 近、遠端監控系統 
(1)  近端系統： 
在近端系統中，以 PC-Based 為架構主體，透過 Visual Basic 來設計近端友善
之人機介面，以圖形化來操作近端智慧型機器人系統，當遠端與近端連線成
功後，透過 API 函式庫，將由遠端系統使用者所下之命令，經過網際網路
的傳輸至近端系統中，來達成遠端控制之功能，並以連線的過程中，將近端
智慧型機器人系統之監視影像，傳回遠端系統之顯示畫面。 
(2) 遠端系統：（如圖 9） 
目前市場上常見的無線網路產品，多為依照 802.11 規格所製作，802.11g 的
25 
 
 
      
圖 10  可旋轉控制之攝影機旋轉機構 
客戶遠端控制
Internet
伺服控制近端
任務分配
及任務排序
否
任務執行
發生未知警訊
鄰近機器人是
否需協助
完成任務並
回報伺服端
否
任務無法執行
否
是
自主式視覺感
測伺服模式
是
是否處於
安全狀態
是 否
是
 
圖 11  機器人與人、機器人間、或與環境之互動流程 
4.4 即時方位辨識系統 
在定位部份主要包含影像前處理、影像辨識、環境地圖建立、定位系統的應
用。定位系統運用了超音波距離感測器、攝影機之感測器資訊，將這些感測器資
訊結合，建立環境地圖資料庫與標的物特徵影像，於後來的機器人自主航行模式
下除了使用避障控制法則航行，透過辨識標的物影像的特徵與相對位置比較，藉
此結合影像達到位置與方向估測。其工作流程如圖 12。 
27 
 
 
圖 14 影像辨視區域成像面 
在本研究中，幾何形狀偵測的主要目的是提高地圖定位的準確度，在此我們
使用幾何形狀偵測的影像處理流程，如圖 15。在此以圖 16 中的影像為例，首先，
輸入影像為經過色彩分割後的二值化影像，而該影像在此經過二值化與建立標的
物的程序後，我們可計算影像中每一物體所包含之像素數量以及輪廓線上的像素
數，也就分別是該物體之面積以及周長。其中計算周長時，在斜方向上會產生數
位化圖形特有的誤差，如圖 17 所示，故應以其 2 倍的數量補正。 
 
圖 15 幾何形狀偵測流程圖 
 
圖 16 形態學處理原影像 
  
圖 17 顏色分割和幾何形狀偵測之結果 
29 
 
          
0 0
0 0
0 0
C
l C
l C
C
C
C
f
zx x
f
y y
z
f z
f
z
 
 
    
        
       
 
  
     
（5） 
 
 , ,C C Cx y z
f
Cx
Cy
Cz
lX
lY
A
A
 , ,l lx y f
 
圖 19 攝影機成像原理 
藉由上述 4.4.2 節提到的影像標的物辨識已知標的物在攝影機成像上
( , )l lA x y 的位置與像素而建立的資料庫，而 Cz 為建立標的物時攝影機到標的物
A 的距離吾人可透過超音波距離感測器得知，F 為本文使用羅技快看隨身版攝影
機焦距 296.71mm，當所有條件皆已知，由(5)式推算出物體實際寬與高 ,C Cx y ，
即可完整建立標的物影像資料庫。 
4.5 機器人自我保護系統 
自我保護之系統架構如圖 20 所示，在架構中的中央處理控制單元是採用
ALTERA Cylone 系列，可支援 20,060 個 Logic Elements 與 294,912 個 RAM bits，
配合各電路模組之間訊號協定。此系統包含了三種不同特性感測器：超音波感測
組、近接感測組及紅外線感測器；以及電量檢測電路、馬達驅動電路及 FPGA 控
31 
 
4.5.1 電量檢測系統 
一般自走式機器人由於移動平台頗為龐大，且可能涵蓋了電腦主機、各種感
測系統及馬達伺服系統等，因而電力使用消耗極為快速。因此，大多數的自走式
機器人的設計均應包含自動充電警示系統的設計。本文針對智慧型接待服務機器
人所提之自我保護機制，亦是希望隨時提供電量檢測，當機器人於任務執行過程
中發生電力不足時，可迅速回到充電區，完成電力補充來進行自我保護。 
接待服務機器人之電源由兩組 12V、26AH 的密閉式鉛酸電池來提供，需供
應各子系統之電力，當使用不當的放電將會造成電池循環壽命的減少。因此，勢
必需偵測電池剩餘殘量，來即時停止於電力不足時的供電，避免電池因過度放電
而損壞老化。值得注意的是，相對地，若系統常進行不必要的充電，亦將造成電
池的損壞，故準確的電池殘量估測將可使機器人的電量使用效能達最佳化。 
一般常用的鉛酸電池殘電量估測法有二，其一是採用內電阻測定方式來粹取
電池初始電容量。此法係先根據電池開路電壓及負載閉路電壓的量測而得到電池
內電阻，其中，電池開路電壓是以高輸入阻抗之電壓計測得開路電壓，而負載電
壓是用電流計測得。然後以重複步驟量測取樣 N 次數據，正確測得電池內電阻
及電池電容量的放電關係，再依序讀取電池開路電壓值與負載電壓值後，藉由電
池電容量放電關係可計算出目前殘電容量。然而，此法的缺點為欲量測電池殘電
容量，必須當電池為開路狀態才能測得，這將不可能於機器人執行任務中隨時進
行電力估測，而只能在充飽電欲離開執行任務時，來估測機器人的電量當作初始
電容量。 
第二種方法則延續方法一，由方法一可知，得到目前初始殘電容量，採用安
培小時法來做定時電量檢測，其中，電流檢測元件採用 LEM 公司的 LA 55-P 霍
爾元件，輸出腳以流過電阻的電壓經過一儀表差動放大器取代，最後以類比訊號
進行 A/D 轉換傳送至 FPGA 晶片作為電量偵測資訊。此法經多次實驗結果可發
現，確可於機器人執行任務下，判斷出電池電容量不足情況，並發出電量不足警
示及停止目前工作，並自動回至充電自我充電。 
33 
 
 
圖 23 自動充電機構示意圖 
4.5.3 自動充電機制 
執行自動充電之機制，相對地，機器人本身除了具有自動導航至充電站之功
能外，另應具有回到定點的定位功能，其中為沿壁尋標之細部調整功能設計。這
方面，於機構邊緣右側各增加 2 顆超音波感測器，用來實現沿壁運動的功能，藉
由近接感測器感應金屬線直到定點位置，並設計紅外線感測裝置進行細部對準，
使其校正機器人充電機構左右移動定位產生精確位置。 
我們把自動充電機制設計在機器人的前側，整個機制的動作意示圖如圖 23
所示。當機器人前側對準停至充電設定點後，驅動馬達帶動伸縮傳動軸以便進行
充電。這裡，充電插頭及插座之設計，將採用伸縮式吸附型插座組，如此可讓充
電機座可以安全地吸附至充電電源上，且插座組是採用磁鐵式吸附，當充電過量
時即磁鐵部分會產生過熱則自動脫落，以確保自動安全斷電，相對地，因細部調
整定位後也有少許定位誤差值，此吸附式插座組周邊設計一個漏斗型狀，以讓充
電機座平滑順於吸附充電插座上，可減少吸附動作誤差，完成了自我充電功能，
最後，當機器人欲離開執行任務時，則反方向將傳動軸收回即可。 
4.6 語音聲源判斷 
4.6.1 聲源定位 
    本研究係延伸 4.1 之機器人聲源定位系統至 3D，付予機器人立體聽覺的感
知，讓機器人擁有垂直方向之聽聲辨位的功能。此系統之硬體架構，如圖 24 將
12 顆電容式麥克風分上下兩層裝置於一直徑 19 公分的半球面上；其中，上層圓
周以間隔 90°排列 4 顆麥克風，下層圓周則以間隔 45°排列 8 顆麥克風。此硬體
35 
 
 
圖 25 為聲源定位系統架構  
 其做法為取下層最大的三顆麥克風能量值然後加以平均，然後再與所對應的
上層麥克風能量加以比較，如果上層麥克風能量值較大表示聲源位於麥克風陣列
的上方，反之若下層能量值較大表示聲源位於麥克風陣列的下方。以圖來說假設
a8、a1、a2的能量為下層最大的三個，便取這三顆麥克風的能量並且加以平均，
其平均的值再與所對應的上層麥克風也就是b1的能量值加以比較。假設a7、a8、
a1的能量為下層最大的三個，便取這三顆麥克風的能量並且加以平均，其平均的
值再與所對應的上層麥克風也就是b1與b4的能量平均值加以比較。圖26為聲源高
低比較示圖。 
37 
 
4.7.1  小波轉換 
    一般而言，小波轉換能過把一個訊號經過高通及低通濾波器分解成頻和低頻
兩個部份，在繼續把這兩個部份各自分解成高頻及低頻。也就是把訊號用多層解
析(multiresolution analysis, MRA)的階層式架構表示，如圖28所示。如圖28所示的
結果是先對水平做 low-pass 和 high-pass filtering 影像會分為二部份，再對垂直
方向做依次 low-pass 和 high-pass filtering，所以此時影像會分成 LL、LH、HL、
HH 四部份。由於低頻部份(LL)能保留肉眼容易察覺的資訊，所以一般把它當作
是影像中最重要的部分，所以做完小波轉換後只採用 LL 部分來當作輸入。 
目前小波轉換的方法有很多種類，例如連續小波轉換、離散小波轉換，但應
用在人臉辨識的特徵擷取上主要是用一種較簡單的 Harr 小波轉換，主要是將影
像的像素值視為各自獨立的數值，然後再將各個數值做相加或相減的運算，以求
得頻域中的小波係數，相加的部分其值會越來越大，代表包含著重要的資訊，那
就是我們的低頻部分。相反地，相減部分代表著像素間的差值，若是在影像邊緣
部分，其差值會變大，而在影像平滑的部分，其差值會很小，所以在小波轉換之
後這會明顯的強調高頻地方的部分。 
 
圖28   小波轉換架構圖 
4.7.2 主成份分析法 
主成份分析法（PCA）主要應用於資料間彼此可能存在的相關變項，如何透
過主成分分析將許多變項予以減少，並使其改變為較少數幾個互相獨立的線性組
39 
 
 i i iCu u  
2 1,2, ,i N               (9) 
由於 A 是一個維度大小為 2N M 的矩陣，所以矩陣 C 為一個 2 2N N 的矩
陣，對於這樣如此龐大矩陣 TA A，將矩陣維度降至M M 再求其特徵向量 iv 如
(10)。 
 
T
i i iAA Av Av                      (10)  
利用(10)式求出特徵向量 iv 再換算成特徵向量 iu ，求出的 iu 即為特徵臉
(egienface)，如(11)式所示。 
 
T
i j iu v     1, 2, ,i M    (11)  
在將每個人臉樣本向量 1 2, , , M   ，依照計算得到的特徵值由大到小做排序，
將所對應的特徵向量組合而成特徵空間，求其在特徵空間的權重向量 W，如(12)
式所示。 
 
 
 1  2  
( )  
[ , , , ]
T T
i i i
M
u u
W
      

    
  1,2, ,i M   (12) 
最後將每個人臉訓練樣本 i ，分別帶入(12)式中的，求出人臉在特徵空間
裡的權重向量 iW ，  1,2, ,i M  ，即為訓練完成的人臉影像資料庫。 
4.7.3  線性鑑別分析 
鑑別分析是 1930 年代中期由費雪(Fisher)提出一種劃分群體的技術，根據預
測變數的某些特性將研究對象區分為兩個以上的群體，其目的是找出預測變數的
線性組合，並建立一套判別模式，使此線性區別模式具有區別群體的最佳效果。
換言之，即是在所有資料點歸屬群組已知的情況下，求取最能將各群組資料點區
別清楚的鑑別函數(discriminant function)，並以此函數對新的資料點做歸類或預
判其最可能之結果， 
LDA 這個方式最主要的是能將不同類別間的中心點拉開，並將屬於同一類
別間的影像分散程度縮小，並且 LDA 能找到一個由資料庫中所有影像一起訓練
出來的投影空間，使得這兩個類別的影像各自對特徵向量空間做投影，即把兩個
41 
 
確認，達到使用者身份辨識與確認的能力。 
身份辨識流程可歸納如下： 
步驟一、 進行聲音特徵比對：由語音感知系統將參與辨識之對象的聲音紀錄起
來，經由語音辨識系統，將其語音特徵找尋出來，透過模糊類神經網路與語音資
料庫內的特徵值進行模糊比對，找出辨識人的身份。 
步驟二、 人臉影像特徵比對：根據對象臉部影像進行特徵值萃取，用這些特徵
值進行比對。 
步驟三、 如果聲音特徵比對與影像特徵比對都找不出來相同的特徵，那系統將
不給予身份辨識的確認，可能不允許進入系統，或是無權使用某些方面的功能，
或視為一般對象來應對。 
4.9 整合式溝通介面 
整個機器人之互動介面系統，可以圖30之系統結構來說明。其中可將介面端
分為伺服控制端與客戶控制端：伺服控制端為機器人，其架構結構包含主控電腦
（或命令處理接收端）、取音模組、取像裝置（攝影機）及驅動控制系統及相關
模組；在客戶控制端方面，則包括遠端網路、近端觸控介面、即時影像輸入（人
臉影像，表情）、及語音輸入（聲音、指令或語句輸入）。介面之協調機制為系
統控制中樞，將進行智慧型判斷客戶端訊號之主從關係、包括身份關係、情緒關
係、時間關係、狀況分析等。這裡，將由模糊類神經網路來加以實現，其推論結
果將交由機器人之運動控制中樞，執行任務所需之各種動作。 
本研究所提多模式互動系統中，語音互動是最自然的溝通方式，但因為容易
受環境吵雜聲音干擾，且字彙及語意的資料庫往往相當龐大，語意的辨識與語法
往往不易周全，所以欲直接由語音進行溝通是需要很多軟硬體方面的條件支援。
我們考慮下列幾個方向： 
1. 以指向性高且高性能之收音裝置，來克服環境聲音之雜訊。這樣做法的
優點是省去許多雜訊濾波的計算困難度，但缺點是成本可能過高，而且
不一定可以有大幅改善的成效。 
43 
 
應高於工作人員，會員應高於一般訪客，先使用者應高於後使用者，友善者
高於非友善者，老者及殘障人士優先，婦女優於男性。另外，某些情境下，
一般人高於學齡前之小孩。 
4. 系統將依各種輸入，轉換應對之情境。同一情境之應對相對較易達成滿意的
互動模式。 
4.10 整合式人機互動與協助 
智慧型接待服務機器人之人機互動介面，可如圖31所示之架構，來進行設
計。互動系統中需內建該展覽場館之環境地圖，並擁有自我定位與動態更替環境
狀態之能力，同時也應具備即時防碰撞系統，避免造成人員、環境及機器人之損
傷。機器人應於特定路線及時刻執行所需之任務，由於任務規劃（Mission 
Planning）時多半不考慮路徑之參觀群眾是否壅塞，因此往往於實際執行任務的
過程中，應隨時揚聲告知前方群眾讓出可通行之通道，如果於欲進行定點導覽之
區域有阻礙之群眾時，如揚聲告知亦無改善時，則應自動更改定點導覽之位置，
或主動尋求館內維護人員之協助。此外，當機器人在每個展覽點進行介紹及特定
物品說明時，如有需要，亦可實際導引群眾到某些特定點。 
 
圖31 人機介面的設計架構圖 
此外，智慧型接待服務機器人應該提供協助給下列對象，包括行動不便人
士、迷路人士、殘疾人士、幼童及老人等。當有語言障礙人士需要幫忙時，可以
利用智慧型接待服務機器人的觸控互動畫面來與之互動，並且能在觸控面板上顯
45 
 
五、結果與討論 
5.1 音源判別之實驗結果 
針對本文所提出以正方形麥克風陣列之架構，計算四個線性陣列上各
Channel 分別得到的電壓值加總與平均後，分析四大組的能量與方位的關係。圖
32 說明本研究以 MFC 為平台，建立擷取音訊能量大小的畫面，除了擷取類比電
壓大小，也自動轉換成容易比較的數位訊號。 
圖 33 為語者與機器人相對方位不同下，系統取得之音訊辨別波形圖。其中，
CH0~CH3 分別表示 A、B、C、D 四大組所得到的平均能量大小。此實驗之環境
條件為 11*8.1*3.4 m 的教室，前方有一面大白板，左右兩側有八面玻璃窗，背
景噪音為一台冷氣機大約 -8dB。將語音裝置放置於房間中央面向前方，而語者
是站在房間的右上方距離機器人大約 1.5m 並且面向機器人。從結果可以看到能
量最大的是 CH0(藍色線表示)其次是 CH1(黃色線表示)，因此判定語者的方位是
在 A 區偏移至 B 區之間，與實際的語者位置相符合。 
5.2 語意理解及對話系統之實驗 
此部分係以 MATLAB 建構語意分析之 ANFIS 系統，來進行語意推論模擬。
我們依照不同語句結構，分別輸入其人(People)、行為(Active)、時間(Time)、地
點(Space)、與疑問詞(Ask)等屬性參數，來進行模擬。圖 34 為人(People)、行為
(Active)、時間(Time)、地點(Space)、與疑問詞(Ask) 於 MATLAB 內 ANFIS 模擬
推論之結果圖，各顏色表示語句之期望輸出值（目標值），紅色線表示模糊數之
模擬推論結果。 
 
圖 32  音訊能量擷取介面之畫面 
47 
 
  
(a) “你需要協助嗎” 之語意分析結果 
 
圖 35 (b)   “你需要幫忙嗎” 之語意分析結果    . 
5.3 人臉辨識之實驗 
本系統使用 USB webcam 攝影機做為人臉影像之擷取裝置，每次擷取之畫面
為 200×160 24Bit 的 BMP 影像。人臉偵測系統分為複雜度低與複雜度高之環境
於不同人臉做測試，複雜度低為偵測背景環境較為單純之情況，而複雜度高為偵
測背景環境較複雜，有許多干擾因素存在，其中有光源變化、人臉遠近之情形及
背景有接近膚色的地方。圖 36(a)(b)兩圖為不同人臉辨識之結果。其中，圖 36(a)
為單純背景環境之辨識結果，圖 36(b) 則展示在複雜背景中有很多不同的顏色、
形狀，且有與膚色相近的顏色，干擾因素較高的情況下，還是可以成功偵測人臉
之結果。 
49 
 
此外，本研究計畫共有 3 篇碩士論文及 3 篇會議論文[39-41]完成發表，並已
同時已將成果發表於 2007 ISND、2007IECON、2007CACS 等國際研討會 
[44-46]，並延伸為往後研究之基礎。整理投往國際期刊，相關研究亦將持續進行。 
5.4 即時方位辨識系統之實驗結果 
圖 37 所示為機器人面朝地圖上方，由消失點與走廊邊線可以得之朝向角 0
度、機器人橫向位置於 X 軸為 159，對應至 1 公尺寬走廊地圖為靠近中央 49.68
公分處，而從標的物的畫素寬×高等於 14×15，可以得知機器人與標的物滅火器
的縱向距離約 289 公分，對應到滅火器座標(100,500)，即可推算出機器人所在位
置（50.32,211）與朝向角 0 度。 
 
圖 37 機器人於模擬走廊環境下之定位 
5.5 語意理解及對話系統之實驗 
圖 38 為利用 ANFIS 與 FLC1 控制器組合系統對有限空間充電區進行路徑姿
態導引，其讓購物機器人能自我處理回到目的地與避障功能。 
 
圖 38 自動導航避障控制之模擬結果 
51 
 
5.7 人臉辨識之實驗 
本系統使用 USB webcam 攝影機做為人臉影像之擷取裝置，每次擷取之畫面
為 200×160 24Bit 的 BMP 影像。人臉偵測系統分為複雜度低與複雜度高之環境
於不同人臉做測試，複雜度低為偵測背景環境較為單純之情況，而複雜度高為偵
測背景環境較複雜，有許多干擾因素存在，其中有光源變化、人臉遠近之情形及
背景有接近膚色的地方。圖 41 為人臉辨識結果。 
.  
圖 41 人臉辨識實驗之結果 
5.4-5.7 節說明本計畫第二年之研究成果，本年度已對靜態及動態的人臉影
像，進行視覺系統的設計與實現，唯其研究僅將影像資訊進行建立及大小、形狀
或顏色之影像辨識。然而，如同聲紋辨識之情形，欲使機器人能夠具有智慧（能
判斷目前的情境並知悉該如何執行），影像分類比對技術將成為智慧化設計之關
鍵。這裡我們使用類神經網路學習架構來進行影像分類及建模。在物理意義上，
每個多層認知器的中間層神經元（Hidden Neuron）都可視為一個特徵偵測器或
抽取器，它所抽取的特徵就是由該神經元與其輸入神經元間的連接鍵加權值
（Connection Weights），以及神經元本身的活化函數（Activation Function）決定。
當連接鍵加權值經由倒傳遞（BP）學習演算法的適應學習後，會自動收斂至適
當的數值，使類神經網路的輸出與理像的輸出值間的誤差低於設定門檻值，此時
即表示類神經網路的中間層神經元已經學習到可讓機器人辨識或分類影像的理
想特徵。 
53 
 
5.9 適當的應對方式 
因為接待服務機器人可應用的場合很多，像展覽館、賣場等地方，經由本子
題的研究，除可辨識出人臉、表情、語音及語意情緒外，更可以經由本接待機器
人達到親子互動的功能例如在展覽館中，每參觀完一個主題之後，系統會有相關
的問題詢問，當答對問題接待機器人便可經由發聲系統告訴你答對或答錯，再配
合影像系統展現出答對與答錯不同的影像，達到真正的人機互動。 
智慧型接待服務機器人首要具備禮貌問候之功能，當機器人於與人互動的過
程中，應於適當時間主動問候操控者，例如於開始溝通之初，或在各特定時間、
地點來回行走時，於不同時段、地點進行不特定人物之問候。此外，智慧型溝通
服務機器人也可以提供貼心的即時訊息及資訊（例如即時重大新聞、室外氣象、
特展…等）之廣播，或提供時刻及節目之查詢。 
由於理想境界的智慧型接待服務機器人需要記憶相當多的語句，才能提供完
整且適切的應對模式。以日本愛知博覽會的接待服務機器人來說，她具備四國語
言能力，可提供約四萬句日常生活對話，但實際狀況仍有相當多的情況是雞同鴨
講。因此，在本研究之實現過程中，將以能提供有限議題之簡單會話為目標，呈
現基本功能效果為本研究之目標。 
舉例而言，當觀眾進入展覽館時，智慧型接待服務機器人會有禮貌的說：「你
好，歡迎光臨！」與人們互動時，如果有小朋友對機器人做出危險或惡作劇動作，
機器人會出現警告及小心危險的聲音、燈號及畫面來警告小朋友及身邊的大人
們，避免危險發生。當參觀者問候機器人特定語句，例如「早安」、「午安」、
「晚安」和「謝謝」…等問候語時，機器人會以目前時間及地點來回應適當的問
候語，避免產生讓使用者愚弄的窘境。 
此外，智慧型接待服務機器人必須提供使用者進行詢答之功能，例如能對迷
路的人們提供場館之指引；或展覽場館或展示物之說明；或其他服務資訊之詢
答。詢答方式可以透過觸控畫面以圖表文字之形式回應或介紹，或以語音回答，
或詢問使用者是否需要帶領他至其所要到達之地點。 
當使用者接近或詢問機器人時，機器人會先以聽聲辨位機制將頭部轉向詢問
55 
 
5.10 未來發展及新一代之設計概念 
圖 43 說明本計畫之智慧型接待服務機器人之機構及外觀設計、功能及配置
規劃、設計及實作成品。未來第二代之智慧型接待服務機器人，將依照實際動作
及運作模式功能之變動而改進及進化，做適切設計。其工作項目，包括： 
（1）設計及研製具完整外觀及處理平台、伺服驅動、馬達、輪及相關結構之智
慧互動機器人，預計設計之第二代比第一代矮（原先 138cm 高），新的智慧
型服務機器人名為 FAIRY 之身高約 90cm，寬跟深則設計於 45~50cm 範圍
內。（如圖 1） 
（2）FAIRY 前後面各安置 2-3 個超音波感測器，用來量測 FAIRY 四周之環境物
件距離。同時，機器人底層四周設計防撞條，下緣則安置 6-8 個紅外線感
測器，用以進行防墜落偵測。 
（3）FAIRY 前腹部安置一觸碰螢幕，供訊息交換及顯示用，增加互動與資訊呈
現。腹部下方有一小型攝影機，用以進行環境辨識之影像處理之用。 
（4）FAIRY 脖子區域及頭部，配置一組含 12 個麥克風之陣列，用來執行音源
方位判別。 
（5）FAIRY 眼睛部分的 webcamera，用來進行人臉辨識、視訊擷取及傳輸用。 
（6）FAIRY 胸前部分，分別有四個按鈕，當按下後，隨即執行特定功能之程式，
避免執行過多程式後，造成機器人運算誤差與負擔。而胸前上方，可放置
智慧型手機，供遠距監控互動之用。 
5.10.1 系統架構 
    FAIRY 之功能規劃如圖 45 所示，其進行避障控制之環境參考資訊包括紅外
線、超音波、影像、語音（麥克風陣列）及焦電型紅外線感測器等，感測器配置
圖如圖 46 所示。根據過去相關研究者之經驗可知，以影像為基礎之避障控制，
可僅以俯角方式取得機器人前方地面之影像資訊，將每一個感測影像均減去原始
無障礙物體之地面影像即可進行簡單的無障礙區域判斷。唯此法之限制為，當機
器人運動環境之地板並非同一材質，且許多因光線不同造成的影像顏色不一致
57 
 
 
圖 46  FAIRY 之環境感知配置規劃圖 
 
圖 47 以感測方式進行安全避障之流程圖 
59 
 
人臉辨識的工作流程主要包含三個部分：前置處理、特徵抽取及分類。前置
處理係對取得之影像進行人臉偵測、定位及前處理；再經由不同特徵判別進行抽
取，最後對特徵抽取後的樣本進行分類比對，找出資料庫中最接近之人臉。這些
過程中，由於人臉偵測或人工切割所得的人臉影像，其大小規格不儘相同，如欲
進行分類比對，人臉影像物件的正規化是必要的步驟。常用的影像（大小）正規
化是利用內插法，包括常用的最鄰近內插法（Nearest Neighbor Interpolation）與
雙線性內插法（Bilinear Interpolation）流程圖如圖48 所示。經過統計，臉部影
像物件之長寬比接近1.2：1，因此吾等可將所有得到的臉部影像正規化成120*100
像素的解析度，再進行後續影像比對及分類等工作。 
 
圖48  追隨功能之影像伺服控制流程 
5.10.2 設計原理 
    在 FAIRY 之設計，吾等將分為 4 個部分進行： 
(1) 運動控制及本能行為之開發(包括自主運動控制、避障感知及控制、導引、巡
邏及防墜落設計等基本功能)： 
FAIRY 仍採兩輪驅動之運動控制方式，為考慮安全及美觀，其外殼包覆雙
輪之設計（如圖 49）可讓其運動時，不致於壓傷或使小孩的手滾入輪縫。而機
器機器人具有即時安全防護之功能，我們於機器人頭部、肩部、背部、手部及底
部，配置了數個壓力感測器、靜電感測器、及紅外線近接感測器。其中，由於機
器人具備自主之運動功能，因此我們設計了其安全防護及自我保護（避障）之機
制，除觸碰感測可提供接觸式安全機制外；在此機器人上，我們也設計 6-8 個此
種光感測器於機器人底部，當感測器偵測到無反射區域時（輸出為 0V），表示此
感測器下方可能為低陷或落空之區域，機器人將執行反向運動之動作，以避免機
器人運動時從桌緣、樓梯或高處摔落。 
61 
 
圖50  機器人功能鍵之設計：記錄、人臉辨識、跟隨、互動 
(4) 視覺、人臉辨識及表情理解之功能開發： 
服務環境之突發狀況，如無法即時處理，往往造成憾事。而接待服務機器人
如僅定位在娛樂或巡邏，就可能會顯得不足。此跟隨功能之視覺處理，僅是將視
訊影像處理簡化成物件色塊辨識之問題，亦即做一個簡單假設，當欲被追隨之人
及物，放置在FAIRY前方固定位置取像，建立樣版（pattern）於資料庫中，FAIRY
僅需學習將所有物件之顏色、大小及輪廓特徵分類建檔，之後僅需去除動態影像
之背景，即可進行待追物所在相對位置。而視覺伺服控制僅需控制機器人運動使
以目標物影像物件維持在影像中央，即可達成追隨控制。   
 
圖51  機器人之頭部外觀設計圖 
5.10.3 規格及配置設計： 
（1） FAIRY 脖子區域及頭部，配置一組含 12 個麥克風之陣列，用來執行音
源方位判別。 
（2） FAIRY 眼睛部分的 webcamera，用來進行人臉辨識、視訊擷取及傳輸
用。 
（3） FAIRY 胸口部分，分別有四個按鈕，當按下後，隨即執行特定功能之
程式，避免執行過多程式後，造成機器人運算誤差與負擔。 
（4） FAIRY 前後面各安置 2-3 個超音波感測器，用來量測 FAIRY 四周之環
境物件距離。同時，機器人底層四周設計防撞條，下緣則安置 6-8 個紅
63 
 
事件提醒，或簡短留言。當使用者在胸口留下事件提醒或留言，等候一段
時間後，螢幕將會自動關閉，減低電力消耗，僅剩記錄功能按鈕會有呼吸
燈的閃爍提醒。透過此一功能，家中冰箱、牆面，將可不必再看到一張一
張黃色的 MEMO 貼紙，讓家裡更為整潔。 
 B. 人臉辨識： 
人臉辨識的設計，除了簡易的保全功能外，仍是增加親子互動的功能。
FARIY 的定位在於居家陪伴型機器人，所以在人臉辨識的部分，僅設定
在較為簡易的人臉辨識，因此辨識率自然並不如高階電腦般細膩。 
C. 跟隨： 
星際大戰中可愛的 R2D2，總是緊跟隨著主人到處亂跑，可愛的模樣令人
愛不釋手。現在有了 FAIRY，你將有機會一嘗擁有 R2D2 的追隨感。跟隨
的功能一經啟動後，機器人將會透過攝影機持續的追蹤你的腳步，就像個
小小的跟屁蟲一樣，不斷的跟著你走到哪，跟到哪。 
D. 互動： 
冷冰冰的機器，只能默默的執行著我們的指令，這一點都不是我們想要的
居家陪伴型機器人。當你有這樣的期待時，請按下互動按鈕，機器人將會
依照你的對話內容，從記憶體內部隨機的挑選可能符合當下情境的對話內
容。透過隨機的挑選，你永遠可以保持跟機器人互動的新鮮感，因為你不
知道他將會告訴你什麼樣的有趣對白。 
 
 
65 
 
'03. IEEE International Conference on Robotics and Automation, Vol.2, Sept. 
2003, p.1633 – 1639. 
[11] 經濟部工業局，新聞稿：『啟動我國智慧型機器人產業創造新興產業發展契
機』，中華民國經濟部網頁： 
http://w2kdmz1.moea.gov.tw/user/news/detail-1.asp?kind=1&id=10433, 15 Dec. 
2005. 
[12] 大紀元，新聞稿：『愛知世界博覽會機器人少女迎賓』，
http://www.epochtimes.com/b5/5/3/10/n843366.htm, 10 March 2005. 
[13] Caprari, G.; Siegwart, R.; “Mobile Micro-Robots Ready to Use: Alice.” 
Proceedings of 2005 IEEE/RSJ International Conference on Intelligent Robots 
and Systems, IROS 2005, p.3845-3850, 02-06 Aug. 2005. 
[14] Radhakrishnan, D., Nourbakhsh, I.R., “Topological robot localization by 
training a vision-based transition detector,”. Proceedings. of the 1999 IEEE/RSJ 
International Conference on Intelligent Robots and Systems (IROS '99), Vol.1 , 
1999, p.468 -473. 
[15] Gross, H.-M.; Boehme, H.-J., “PERSES-a vision-based interactive mobile 
shopping assistant,” Proceedings of 2000 IEEE International Conference on 
Systems, Man, and Cybernetics, Vol.1, 2000, p.80-85. 
[16] Gross, H.-M., Boehme, H.-J., Wilhelm, T., “Contribution to vision-based 
localization, tracking and navigation methods for an interactive mobile 
service-robot,” Proceedings of 2001 IEEE International Conference on Systems, 
Man, and Cybernetics, Vol.2, 2001, p.672-677. 
[17] Gross, H.-M., Koenig, A., Boehme, H.-J., Schroeter, Ch., “Vision-based Monte 
Carlo self-localization for a mobile service robot acting as shopping assistant in 
a home store,” Proceedings of 2002 IEEE/RSJ International Conference on 
Intelligent Robots and System, Vol.1, 2002, p.256-262. 
[18] Gross, H.-M., Koenig, A., Schroeter, C., Bochme, H.-J., “Omnivision-based 
probabilistic self-localization for a mobile shopping assistant continued,” 
Proceedings of 2003 IEEE/RSJ International Conference on Intelligent Robots 
and System, Vol.2, 2003, p.1505-1511. 
[19] 大紀元新聞稿，2005.03.19. 
http://www.epochtimes.com/b5/5/3/20/n858148.htm 
[20] Pulasinghe, K.; Watanabe, K.; Izumi, K.; Kiguchi, K.; “Modular fuzzy-neuro 
controller driven by spoken language commands.” IEEE Transactions on 
Systems, Man and Cybernetics, Part B, Volume 34, Issue 1, 2004, p. 293 – 302. 
[21] Chatterjee, A.; Pulasinghe, K.; Watanabe, K.; Izumi, K.; “A 
particle-swarm-optimized fuzzy-neural network for voice-controlled robot 
systems.” IEEE Transactions on Industrial Electronics, Volume 52, Issue 
6, 2005, p. 1478 – 1489. 
[22] Valin, J.-M.; Michaud, F.; Rouat, J.; Letourneau, D., “Robust sound source 
67 
 
[35] Hald J. and Ginn K. B., “Spatial Transformation of Sound Fields: principle, 
instrumentation and applications,” Acoustic Intensity Symposium, Tokyo, 1987. 
[36] Grembergen F. V., “Acoustic Holography – Mercedes c220 & Mercedes 
SL280,” pp. 8-19, 1996. 
[37] Trazegnies, de C.; Urdiales, C.; Sandoval, F.; “Curvature based image 
recognition using hidden Markov models”, Electronics Letters, Volume 40, 
Issue 20, p.1258-1259. 30 Sept. 2004.  
[38] Sabisch, T.; Ferguson, A.; Bolouri, H.; “Identification of complex shapes using 
a self organizing neural system”, IEEE Transactions on Neural Networks, 
Volume 11, Issue 4, p.921-934, July 2000. 
[39] 謝銘原、黃紀仁，麥克風陣列式模糊語者定位辨識系統之設計，2006 中華
民國第十四屆模糊理論及其應用研討會，高雄, 義守大學，2006 年 12 月。 
[40] 謝銘原、莊鎮陽：應用類神經模糊網路推論自然對話的語言含意，2006 中
華民國第十四屆模糊理論及其應用研討會，高雄, 義守大學，2006 年 12 月。 
[41] Shieh, M.-Y.; Huang, C.-J. “Design of Microphone Array Based Fuzzy Speaker 
Localization Recognition System for Humanoid Robots,” Accepted by 2007 
International Automatic Control Conference, 2007 CACS, Taichung, Taiwan, 
Nov. 2007. 
[42] Garcia C.; Tziritas G. (1999), “Face Detection Using Quantized Skin Color 
Regions Merging and Wavelet Packet Analysis,” IEEE Tran. on Multimedia, Vol. 
1, No. 3, pp. 264-277. 
[43] 黃一庭 (2002)，規則導向之多人人臉即時偵測，國立東華大學資訊工程系
碩士論文，中華民國九十一年。 
[44] Shieh, M.-Y.; Chang, K.-H.; “Development and Implementation of an Artificial 
Neural Network based Controller for Gait Balance of a Biped Robot,” Accepted 
by 2007 International Conference ISND, Shanghai, China, Oct. 2007. 
[45] Ming-Yuan Shieh, Ke-Hao Chang, Chen-Yang Chuang, Yu-Sheng Lia, 
Development and Implementation of an Artificial Neural Network based 
Controller for Gait Balance of a Biped Robot, Proc. of IEEE IECON 2007, 
Taipei, Taiwan, Nov. 2007. 
[46] Ming-Yuan Shieh, Chi-Jen Huang, Yu-Sheng Lia, Design of Microphone Array 
Based Fuzzy Speaker Localization Recognition System for Humanoid Robots, 
Proc. of 2007 CACS International Automatic Control Conference, Taichung, 
Taiwan, Nov. 2007. 
[47] Tsai, M.-H.; Shieh, M.-Y.; Lu C.-M.; “Design and Implementation of an 
Intelligent Interactive Home Robot,” Proceedings of 2008 CACS, Nov. 2008. 
[48] Chen, Y.-S.; Shieh, M.-Y.; Chen G.-H.; “Design and Implementation of A 
Real-Time Face Recognition System for mobile robot,” Proceedings of 2008 
CACS, Nov. 2008. 
69 
 
七、國科會補助專題研究計畫成果報告自評表 
請就研究內容與原計畫相符程度、達成預期目標情況、研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）、是否適
合在學術期刊發表或申請專利、主要發現或其他有關價值等，作一綜合評估。 
1. 請就研究內容與原計畫相符程度、達成預期目標情況作一綜合評估 
■   達成目標 
□ 未達成目標（請說明，以 100 字為限） 
□ 實驗失敗 
□ 因故實驗中斷 
□ 其他原因 
說明：  
2. 研究成果在學術期刊發表或申請專利等情形： 
論文：■已發表 □未發表之文稿 □撰寫中 □無 
專利：■已獲得 □申請中 □無 
技轉：□已技轉 □洽談中 ■無 
其他：（以 100 字為限）本研究共發表兩篇國際期刊論文、八篇國際會議論文、
七篇碩士論文、並獲得三項中華民國專利及十三項國內外實作競賽獎項。 
3. 請依學術成就、技術創新、社會影響等方面，評估研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）（以
500 字為限） 
本研究完成所提計畫之預期目標及預定內容，包括完成機器人環境辨識及互
動感知控制、聽覺、視覺、語音理解及辨識、人臉辨識、自我保護系統、表
情及語意學習系統、多模式互動學習系統、身份辨識系統等九個子題項目，
並延伸完成新一代智慧型接待服務機器人 FAIRY 之設計。其中，本研究創新
開發半球形架構之音源方位辨識系統，可進行三度空間之音源方位辨識，達
成立體音源之聽聲辨位功能，可提供機器人聽覺、遠距會議及機器聽覺系統
之輔助。同時，本研究亦完成簡單且有效之人臉辨識系統，對提供互動服務
之機器人系統而言，可達成有效之身份辨識及情緒分析。因整個計畫係以整
合多種技術，並予以實現於一機器人主體上，對開發完整機器人系統架構有
實質助益。未來亦將持續開發更適切應用之接待服務機器人，增加應用智慧
及互動學習能力，使之具有與人合作、服務、協助、互動之智慧化服務功能。 
 
 
71 
 
九、國科會補助專題研究計畫項下出席國際學術會議心得報告 
                                   日期： 98 年 8 月 25 日 
一、參加會議經過 
本人與多位國內學者共同參與此國際會議，此國際會議為日本控制學會主辦之年度會議，2009 年
於日本九州福岡市福岡國際會議中心舉行。共舉行四天超過 200 場次之論文發表。本人發表之論
文安排於 2009/8/20 上午，經過約 12 分鐘之簡報，及約 6 分鐘之問答，吾等獲得許多收穫並可對
此研究進行改進。其中，Session Chair, Dr. Kenbu Teramoto, 建議我們可以將本系統結果延伸至動
態學習演算法，並取得更多實際資料及經驗；而日本學者 Ikoma 則建議將半球形麥克風陣列架構
換成多層切換之動態陣列系統，以期獲得更適切之適應性量測及辨識。 
二、與會心得 
此論文為本計畫之部分成果，為接待服務機器人聽覺系統之設計概念及理論基礎。會議結束後，也
與多位日本學者進行經驗分享及技術交流，發現目前所遭遇之問題相似，解決經驗也經過討論後，
獲得新的見解。由於本研究係為本人團隊之新嘗試領域，經過此會議之研討增加了不少歷練及經驗，
相信對後續研究已產生重要幫助。 
三、考察參觀活動(無是項活動者略)：無 
四、建議 
本研究之未來方向將朝多層巢狀架構設計，並以較高精度之陶瓷麥克風為取音元件，以提高辨識率
及音源內容之正確性。 
五、攜回資料名稱及內容 
論文摘要集一本、論文光碟一份、日本產經資訊資料數份、機器人相關產業雜誌數份。 
六、其他 
 
計畫編號 NSC 96-2221-E-218 -039-MY3 
計畫名稱 智慧型接待服務機器人之研製 
出國人員
姓名 謝銘原 
服務機構
及職稱 
南台科技大學電機工程系 
助理教授 
會議時間 
98年 8月 18日至 
98 年 8 月 21 日 會議地點 
日 本 九 州 福 岡 市 （ Fukuoka 
International Congress Center, 
Fukuoka, JAPAN） 
會議名稱 
(中文)2009 年儀器、控制及資訊技術國際會議 
(英文) SICE 2009（International Conference on Instrumentation, Control 
and Information Technology） 
發表論文
題目 
(中文)半球形麥克風陣列之音源定位系統之設計 
(英文) Design of A Semi-spherical Microphone Array Based Sound 
Localization System 
國科會補助計畫衍生研發成果推廣資料表
日期 2010年10月26日
國科會補助計畫
研發成果名稱
發明人
(創作人)
技術說明
技術移轉可行性及
預期效益
技術/產品應用範圍
產業別
計畫名稱:
計畫主持人:
計畫編號: 學門領域:
(中文)
(英文)
成果歸屬機構
(中文)
(英文)
智慧型接待服務機器人之研製
謝銘原
96 -2221-E -218 -039 -MY3 系統整合與工業應用
智慧型接待服務機器人之研製
南臺科技大學 謝銘原,陳建源
本發明提出的結合主成分分析法及線性鑑別技術之即時人臉辨識系統，包括硬
體架構、系統及分析辨識程式，可有效且快速進行人臉特徵辨識，具有超過
90％之靜態人臉辨識之成功率，且可進行動態人臉辨識。
因為本方法主要應用於機器人系統，故需克服動態人臉偵測及影像辨識，透過
主成分分析法，可有效達成人臉偵測及特徵辨識；同時結合線性鑑別分析技術
，可使辨識率提高，並可進行慢速度之動態人臉影像分析。本研究亦持續結合
類神經網路等學習架構，以及加入支援向量機（SVM）之最佳化架構，使提高有
效辨識率及辨識速度。
PCA and LDA Based Fuzzy Face Recognition System
保全業；資訊服務業；其他專業、科學及技術服務業
手持裝置之人臉辨識、遠距通訊之身分辨識、視訊及物件分析
可提供解決人臉辨識及身份特徵辨識之有效演算法。
註：本項研發成果若尚未申請專利，請勿揭露可申請專利之主要內容。
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
獲得國內外專題實作競賽之獎項 13 件。 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
