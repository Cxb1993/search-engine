中文摘要 
 
由於電腦硬體及網路技術的快速發展，使用者對存取影像資料的需求量大增，使得影
像資料庫儲存的影像數量大幅成長。同時，影像的內容也愈來愈多元而且複雜，因此更需
要能符合這些變化的影像搜尋方法。過去除了內容導向式影像讀取(Content-Based Image 
Retrieval, CBIR)，也有另外一部分學者研究以影像內物件的空間關係(spatial relationship)為
主的影像讀取，這和傳統以內容為主的影像是有很大的差別，過去有很多關於物件空間關
係描述的研究，例如使用二維字串，但卻沒有人將此描述方式與相關回饋做結合。因此本
研究針對以二維字串描述的空間關係，發展出一套全新的圖像相關回饋技術，使得系統可
以根據回饋資訊推論出真正符合使用者需要的空間關係的查詢結果。而且本研究不但可以
針對圖像標示出”相關”與”不相關”外，還可以針對影像內部的物件來標示，這樣更能快速
並精確的找出相關的圖像。 
關鍵字：相關回饋、二維字串、最長共同子序列、最短共同超序列 
 
Abstract 
 
Due to the popularity of Internet and the growing demand of image access, the volume of 
image databases is exploding. Hence, we need a more efficient and effective image searching 
technology. Researchers in content-based image retrieval (CBIR) have been using different visual 
features, including color, shape, texture, and spatial relationships, to describe image content. 
Relevance feedback techniques, which are popularly used with CBIR, however, have never been 
used with spatial relationship-based image retrieval. Hence, we propose a new relevance 
feedback technique to deal with spatial relationships represented by a specific 2D string data 
structure. Our system not only handles “relevant” and “irrelevant” images, but also deals with 
“relevant” and “irrelevant” objects, such that the efficacy and effectiveness of our retrieval 
system are improved. 
 
Keywords: relevance feedback, 2D String, longest common subsequence, shortest common 
supersequence. 
 
第一節  前言 
由於電腦硬體及網路技術的快速發展，使用者對存取影像資料的需求量大增，例如數
位典藏、網路藝廊、遙測影像、醫療影像、以及商標影像等，使得影像資料庫儲存的影像
數量大幅成長，包含的影像內容也愈來愈多元而且複雜，造成傳統資料庫的索引及比對技
術效能降低。因此，如何改進影像資料庫的索引及比對技術成為近年來學者非常關心的議
題。 
    傳統以影像檔名或關鍵字來查詢影像資料庫的方法並不實際，因為影像檔名或關鍵字
無法完整描述影像的內容，不同的人也可能會對同一張影像做不同的註解，而且秏費極大
的人工。比較務實的做法是利用輸入範例影像來查詢與其相關影像的方法，稱之為內容導
向式影像讀取(Content-Based Image Retrieval，CBIR) [1-4]。系統計算範例影像的各種低階
特徵，例如：顏色、條紋、形狀等，來做為查詢相關影像的依據，從資料庫影像中找出跟
此張範例影像在低階特徵空間中距離最接近的圖(例如根據歐幾里德距離)，並回覆給使用
者。但是，這樣的系統所查詢的結果仍然無法滿足一般使用者的需求。主要的原因有以下
兩點： (1)由於影像的低階特徵(low-level features)無法充分代表人類的高階語意概念
(high-level semantics)，查詢的結果往往與使用者的預期有一些落差。(2)使用者無法事先了
解影像資料庫中有那些影像內容，因此不容易選擇適當的範例影像來進行查詢，以致於影
響到查詢結果的準確性。 
要解決上述的問題可以利用相關回饋(Relevance Feedback，RF)的技術來克服，將查詢
期間(query session)當作是一連串的查詢嘗試，在每一次系統回覆的查詢結果中，由使用者
γ 代表系統控制舊查詢範例影像向量以及相關與不相關影像的相對權重，當α 越大時表示
舊查詢向量 )( jiX 所佔的權重越高，當 β 越大時表示使用者所回饋標示為相關的影像所佔的權
重越高，而當γ 越大時表示使用者所回饋標示為不相關的影像所佔的權重越高。 
 
3.2  Feature Relevance Estimation (FRE) 
FRE 假設在計算影像相似度比對時，根據使用者的相關性認知，可能某些低階特徵的
重要性比其它低階特徵的重要性高，必須付予較高的權重。決定特徵權重的方法，可以利
用以下程序：(1)利用歐幾里德距離計算出離範例影像最相似的前 t 張影像回覆給使用者。
(2)使用者在 t 張影像中標示相關與不相關的回饋資訊。(3)分別根據每一個單獨的特徵維度
i，計算在此維度上離範例影像最近的前 t 張影像，再檢查此 t 張影像中含有標示為相關影
像的個數( iR )以及標示為不相關影像的個數( iN )。最後，特徵維度 i 的權重 iw 可設定為
( ) tNRWw iii −= ，其中 ( )ii NRW − 為與 ii NR − 成正向比例的權重函數，可以是線性、二次
多項式或指數型函數。為了正規化，系統會控制 1
1
=∑
=
t
i
iw 。(4)利用更新後的特徵權重，以
加權式歐幾里德距離 ∑
=
−=
d
i
iii yxwYXDist
1
2)() ,( 計算出離範例影像最相似的前 t 張影像回覆給
使用者。(5)反覆執行步驟(2)-(4)，直到使用者滿意或查詢結果無法再改善為止。 
 
3.3  Bayesian Inference (BI) 
貝氏推論(BI)是利用事前觀察資訊(a priori information)推論事後機率(a posteriori probability)
的原理，來估計資料庫影像與範例影像之間有相關的機率。假設 R 表示已被標示為相關的
影像集合， N 表示已被標示為不相關的影像集合； ( )RP 表示任何一張資料庫影像被標示為
相關影像的機率， ( )NP 表示任何一張資料庫影像被標示為不相關影像的機率； )( RYP 與
)( NYP 表示已被使用者標示為相關或者不相關，而影像特徵向量為 Y 的條件機率。貝式推
論利用以上觀察資訊估計資料庫影像為 Y，而與範例影像比較之後可能被使用者標示為相
關或者不相關的事後機率 ( ) ( ) ( )( )YP
RPRYPR|YP |  = ， ( ) ( ) ( )( )YP
NPNYPN|YP |  = 。然後可以再利用
兩者的比值來判斷影像 Y 是相關影像的可能性， ( ) ( )( )
( ) ( )
( ) ( )NPNYP
RPRYP
YNP
YRPYJ
|
|
|
|
==θ 。 若
( )YJθ >1 表示 Y 影像與範例影像相關的機率比不相關的機率大，若 ( )YJθ <1 表示 Y 影像與
範例影像相關的機率比不相關的機率小，所以 ( )YJθ 越大表示 Y 影像越有可能是相關影像，
而 ( )YJθ 越小則表示 Y 影像越不可能是相關影像。因此，貝式推論依照每張影像的 ( )YJθ 值，
選擇比值最高的前 t 張影像回覆給使用者。 
 
3.4  2D String Family  
    Chang et al. [13]最早提出 2D string 的表示法，可以有效的描述符號圖(symbolic picture)
中物件彼此的空間關係。之後又有許多學者針對更複雜的空間情況提出了許多 2D string 的
變型，包括 2D+-string[14]、2D C-string [15]、2D C+-string [16]、2D C-tree [17]、2D B-string 
[18]、2D Be-string[19]、2D H-string [20]、Adaptive 2D H-string[21]、2D R-string[22]、2D 
RS-string[23]、2D Z-string [24]等。表 1 列出不同版本 2D string 變型之間的差異。 
 
第四節  研究方法 
由於傳統的相關回饋技術是以描述影像的物件內容(如顏色、條紋、形狀等)為主，並沒
有探討物件之間的空間關係要如何與相關回饋的技術做結合。但是使用者在進行影像查詢
時，除了關心影像內容特徵之外，也可能對影像中各個物件彼此間的空間關係有興趣，例
如應用在都市計畫、旅遊規劃、室內設計、或展場規劃等。 
因為傳統的相關回饋技術無法直接應用在物件的空間關係描述上，因此，本研究針對
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
圖 1 本研究之系統架構圖 
 
4.1  2D Be-String 的相似比對 
2D String 的比對大致分為兩大類，其中”絕對比對”並沒有分數的概念，較不符合一般
人對於相似程度的判斷，因此，本研究採用另一種方式，計算 Longest Common Subsequence 
(LCS)以提供不同程度的相似度估算值，而 LCS 可以利用動態規劃(Dynamic Programming) 
[36]求出。接著，我們將範例圖的 2D Be-string 與資料庫中每張圖像的 2D Be-string 做 LCS
比對。 
4.2  相關回饋 
    由於傳統的相關回饋技術(如QVM、FRE、BI、及SVM等)無法直接應用在以 2D Be-string
表示的空間關係描述上，我們必須發展出一套全新的圖像相關回饋技術，使得系統可以根
據回饋資訊推論出真正符合使用者需要的空間關係的查詢結果。針對使用者標示為相關的
圖樣部份，本系統將計算其最短共同超序列，當作新的符號範例圖的 2D Be-string，以推演
其代表的空間關係；而針對被標示為不相關的圖樣部份，本系統將記錄其個別的 2D 
Be-string，避免再找到含有同樣空間關係的圖樣；至於被標示為無關緊要的圖樣部份，則不
做任何處理。以下就針對相關及不相關的圖樣部份做進一步闡述。 
 
4.2.1  相關資訊的處理 
為了將所有相關的空間關係融合在查詢範例圖像當中，我們採用不斷修正範例圖像的
2D Be-string 的方式，進行推論使用者的查詢概念。而 common supersequence 具有同時包含
數個序列的特性，很適合做為融合空間關係的運算。common supersequence 的定義如下：
給定一個以上的 sequences，其 common supersequence 必須滿足同時包含所有 sequences 內
的所有符號，且符號出現順序相同但可以不連續。例如：給定兩序列 S = “ABDE”，T = 
“CDES”，則它們的 common supersequence 可以是”ABCDES”，”ACBDES”，“ACDBDES”，
“ABDE CDES”，…等。所以 supersequence 並不唯一，而其中長度最短的 supersequence 稱
之為最短共同超序列(Shortest Common Supersequence，SCS)，經常是最有用途的資訊。 
然而，計算數個序列的 SCS 為 NP-hard 的問題[31]，無法有效率地找出最佳解。而過
去的學者多數是利用數學規劃法或經驗法則(heuristics)來找尋 SCS。利用數學規劃法來找尋
SCS 的方法包括動態規劃(Dynamic programming)、分支界定法(branch-and-bound)等方法，
但是這些演算法對於有龐大的序列數時則顯得沒有效率。而過往使用經驗法則來找尋 SCS
的方法最常使用的有兩種：第一種因為尋找兩個序列的 SCS 比較容易求出，因此將尋找 L
個序列的 SCS 問題轉為 L-1 次尋找兩個序列的 SCS 問題。第二種則是 Foulser et al. [38]提
出同時掃瞄 L 個序列並逐步建立 SCS。首先比對每一個序列最前面的符號，選擇出現頻率
最高的符號，將此符號加入目前的 SCS 序列，再將此符號從出現的原序列最前端刪除。重
(4) 
(1) Query Q
(2) Image Database 
LCS Similarity matching 
(3) Retrievals 
Relevance feedback
(4) Q³SCS(R) 
Relevant set R 
Non-relevant 
2D strings(N) 
Non-relevant set N 
等。如此一來，可以將圖 2 表達成使用者理想中的圖像為”一座露營地的右下方有遊樂區，
而遊樂區的右下方有烤肉區”，這樣的方式，可讓使用者更容易想像每張圖像所代表真實的
意義。也代表本系統未來可以朝著有關旅遊、地圖等真實應用上去發展。 
 
 
圖 3 第一次圖像搜尋的結果及使用者輸入之回饋資訊 
 
使用者在剛開始設定查詢範例時，可能並不知道資料庫中有那些他所需要的物件，則
以最簡單的方式呈現查詢範例，就像此範例中只使用了”A”物件、”G”物件和”L”物件做為
第一次查詢範例的物件。圖 3 為系統依據查詢範例所搜尋資料庫之結果。在第一次搜尋結
果中發現，資料庫中並沒有完全符合這個條件的圖像，因此使用者從這些圖像中挑選出心
目中相關、不相關及無關緊要的圖像及物件，進行下一次的回饋機制，系統會依據這些條
件的結合，找出更符合使用者想找尋的圖像。從圖 3 中可發現系統在搜尋後會出現一些使
用者原本並沒有設定在查詢範例中的物件(例 C、K、J、H 物件等)，而使用者可能在看到這
些物件後才發現如果所要找尋的圖像中有包含這些物件也不錯，或是發現他們非常不希望
有某些物件的出現。例如圖 3 中第二張圖像，他和查詢範例相比多了”J”物件(湖泊)，而使
用者在看到這些圖像時，可能會覺得如果在露營區及遊樂區附近有個湖泊是個不錯的選
擇，或是像第三張和第七張圖像，多了”K”(廁所)物件，而讓使用者覺得附近有廁所是很方
便的事情，又或是像第九張圖像讓使用者覺得露營區旁邊多個餐廳(C 物件)也是很好的選
擇，因此使用者會將這些圖像設為相關圖像。但也有一些圖像是使用者並不喜歡的，例如
第五張圖像，露營區旁邊有一座垃圾場(I 物件)，另外一邊還有射箭場(E 物件)，因此使用
者會將此圖像設為不相關圖像。 
圖 4 為系統回饋之結果，圖中上方顯示了系統依使用者前次下達回饋機制的條件所結
合出新的 supersequence 資訊，此資訊結合了使用者選擇為相關圖像中的物件關係，而發展
出新的物件空間關係，系統再利用新的 supersequence 找尋到符合使用者期望的圖像。我們
可從回饋結果出證實了空間遞移的關係。例如圖 4 第一張圖像(編號 323)中的關係是由圖 3
第三(編號 101)及第九張圖像(編號 154)所結合之空間關係，圖 3 第三張圖像的物件關係為
GÆLÆK(L 物件在 G 物件右下方；而 K 物件又在 L 物件右下方)；而圖 3 第九張圖像的物
件關係為 CÆAÆL(A 物件在 C 物件右下方；而 L 物件又在 A 物件的右下方)；這兩張圖像
關係的結合為：GÆCÆAÆLÆK，而圖 4 第一張圖像的關係為 CÆAÆLÆK，就包含了結
表 2 進行回饋 20 次，顯示前 20 名圖像並執行 5 次取平均值之實驗數據 
群
別 
第一次 
搜尋 
回饋
1 
回饋 
2 
回饋
3 
回饋
4 
回饋
5 
回饋
6 
回饋
7 
回饋 
8 
回饋 
9 
回饋
10 
1 0.3620  0.4506 0.5067  0.5486 0.5692 0.5887 0.5975 0.6131 0.6259  0.6384  0.6443 
2 0.3538  0.4689 0.5407  0.5857 0.6196 0.6433 0.6724 0.6853 0.7033  0.7143  0.7255 
3 0.3685  0.4575 0.5259  0.5831 0.6152 0.6491 0.6645 0.6832 0.7125  0.7196  0.7345 
4 0.3031  0.4316 0.4977  0.5564 0.5866 0.6280 0.6591 0.6867 0.7076  0.7213  0.7360 
5 0.3202  0.5137 0.5682  0.5882 0.6040 0.6104 0.6144 0.6193 0.6309  0.6387  0.6371 
平
均 0.3415  0.4645 0.5279  0.5724 0.5989 0.6239 0.6416 0.6575 0.6760  0.6865  0.6955 
 
表 2[續] 進行回饋 20 次，顯示前 20 名圖像並執行 5 次取平均值之實驗數據 
群
別 
回饋 
11 
回饋 
12 
回饋 
13 
回饋 
14 
回饋 
15 
回饋 
16 
回饋 
17 
回饋 
18 
回饋 
19 
回饋 
20 
1 0.6539  0.6630 0.6740  0.6816 0.6866 0.6973 0.7016 0.7104  0.7203  0.7241 
2 0.7462  0.7546 0.7627  0.7739 0.7782 0.7816 0.7858 0.7943  0.7960  0.8001 
3 0.7442  0.7597 0.7710  0.7837 0.7865 0.7949 0.7998 0.8080  0.8097  0.8136 
4 0.7436  0.7550 0.7608  0.7712 0.7753 0.7889 0.7958 0.8001  0.8063  0.8140 
5 0.6449  0.6518 0.6522  0.6555 0.6572 0.6588 0.6626 0.6652  0.6662  0.6721 
平
均 0.7066  0.7168 0.7241  0.7332 0.7368 0.7443 0.7491 0.7556  0.7597  0.7648 
 
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21
The numbers of Retrieval
Pr
eci
sio
n
 
圖 5 每次顯示 20 張的 5 個分群值分均之圖表分析 
     
5.3  結論與建議 
    過去關於圖像回饋的研究，都大致專注在內容導向式圖像讀取(Content-Based Image 
Retrieval，CBIR)上，並沒有關於 2D string 用在圖像回饋方面的研究，但本研究針對這方面
做研究，並發現在 2D string 上做圖像回饋是有需要的。因為使用者事先並不了解資料庫的
內容，所以使用者心目中的圖像並不一定會在資料庫中找到，這時就需透過回饋的機制找
到其它符合使用者心目中相關的圖像。 
    本研究也不像一般內容導向式影像讀取利用歐幾里德距離來計算影像間的相似度，而
是利用找尋兩個圖像字串的最長共同子序列(LCS)的觀念來計算相似度，再針對相關的圖樣
集合，系統將計算其最短共同超序列(SCS)當作新的符號範例圖的 2D Be-string，以推演其
代表的空間關係；而針對不相關的圖樣集合，系統將記錄其個別的 2D Be-string，避免再找
到含有同樣空間關係的圖樣。 
    本研究不只可以指定圖像為”相關圖像”、”不相關圖像”或”無關緊要圖像”外，還可以針
對每張圖像中的各物件關係標示出”相關”或”不相關”，這樣可以更精確的表達使用者的想
法，增加系統的效能，更能快速的找尋到使用者心目中理想的圖像。 
 
image databases,” Pattern Recognition Letters 24, pp.3015-3026, 2003. 
[25]D. E. Goldberg, “Genetic Algorithms in Search, Optimization, and Machine Learning,” 
Addison Wesley, Reading, Massachusetts, 1997. 
[26]S. Kirkpatrick, C. Gelatt Jr. and M. Vecchi, “Optimization by simulated annealing,” Science 
220, pp. 671-680, 1983. 
[27]F. Glover, Tabu search – Part I, ORSA J. Computing 1, pp. 190-206, 1989. 
[28]M. Dorigo and L. Gambardella, “Ant colony system: a cooperative learning approach to the 
traveling salesman problem,” IEEE Trans. on Evolutionary Computation 1, pp. 53-66, 1997. 
[29]M. Dorigo, “Optimization, learning, and natural algorithms,” Ph.D. Thesis, Dip. Elettronica e 
Informazione, Politecnico di Milano, Italy 1992. 
[30]J. Kennedy and R. C. Eberhart, “Particle swarm optimization,” Proceedings IEEE Int’l. Conf. 
on Neural Networks, IV, pp. 1942-1948, 1995. 
[31]J. Branke, M. Middendorf, and F. Schneider, “Improved heuristics and a genetic algorithm 
for finding short supersequences,” OR-Spektrum, pp. 39-46, 1998. 
[32]S. Y. Lee, M. K. Shan and W. P. Yang, “Similarity Retrieval of Iconic Image Database,” 
Pattern Recognition 22(6), pp.675-682, 1989. 
[33]S. Y. Lee and F. J. Hsu, “Spatial Reasoning and Similarity Retrieval of Images Using 2D 
C-String Knowledge Representation,” Pattern Recognition 25(3), pp.305-318, 1992. 
[34]F. J. Hsu and S. Y. Lee, “Similarity Retrieval by 2D C-Trees Matching in Image Databases,” 
Journal of Visual Communication and Image Representation 9(1), pp.87-100, 1998. 
[35]L. Bergroth, H. Hakonen and T. Raita, “A Survey of Longest Common Subsequence 
Algorithms,” String Processing and Information Retrieval, 2000. 
[36]D. E. Fraser, “Subsequences and supersequences of strings”, PhD. Thesis, Department of 
Computer Science, University of Glasgow, 1995. 
[37]S. Gautama, R. Bellens, Guy De Tré and W. Philips, ”Relevance Criteria for Spatial 
Information Retrieval Using Error-Tolerant Graph Matching,” IEEE Transactions on 
Geoscience and Remote Sensing 45(4), pp.810-817, 2007. 
[38]R. Michel and M. Middendorf, “An ACO Algorithm for the Shortest Common 
Supersequence Problem,” in New Ideas in Optimization, GcGraw-Hill, pp.51-62, 1999. 
 
計畫成果自評 
    本研究內容與原計畫相符，達成之預期目標包括：(1)使用者透過本系統提供的物件空
間關係描述界面，輸入想找尋的物件空間關係的符號範例圖(symbolic sample picture)，系統
將產生對應的 2D Be-string。(2)系統根據最長共同子序列(Longest Common Subsequence，
LCS)，找尋最相似的圖。(3)針對相關的圖樣，系統將計算其最短共同超序列(Shortest 
Common Supersequence，SCS)當作新的符號範例圖的 2D Be-string，以推演其代表的空間關
係。(4)針對不相關的圖樣部份，系統將記錄其個別的 2D Be-string，避免再找到含有同樣空
間關係的圖樣。 
本研究內容之成果同時具有學術及應用價值，目前正著手撰寫論文以進行投稿學術期
刊發表，成果報告將送本校研發處尋找適合技轉之廠商。 
 
推廣及運用的價值
目前市場上並無同型之產品 
※ 1.每項研發成果請填寫一式二份，一份隨成果報告送繳本會，一份送 貴單位
研發成果推廣單位（如技術移轉中心）。 
※ 2.本項研發成果若尚未申請專利，請勿揭露可申請專利之主要內容。 
※ 3.本表若不敷使用，請自行影印使用。 
表 Y04 
 
二、與會心得 
近年來在演化式計算 (Evolutionary Computation) 及次經驗演算法
(Metaheuristics)的論文產量激增，然而受到 No Free Lunch Theory 的影響，
大部份的論文都是著重在某一小主題的應用及效能改良，顯少廣泛的探討這些
演算法及不同應用領域之間的對應關係。但是如果我們觀察主要的國際會議及
學術期刊的論文不難發現一個現象，一些重量級學者開始尋找各個演算單元（含
問題編碼、自然天擇、交換及變異資訊等）的最佳實作方法與各種問題性質的
關聯性，並分別從理論及實證的層面去探討，我國雖然有優秀的研究人才，但
是或許是受到短期升等壓力的影響，都將精力花在特定主題上，而未關注整體
領域的趨勢，這或許是各大學推動 tenure-track 升等制度所應考量到的可能副
作用。 
 
三、建議 
近年來國科會鼓勵學人申請多年期及整合型計劃，對修正研究人員的研究規
劃應有很大的引導作用，讓彼此的研究有連結成面的機會，也更有登上國際一
流期刊的可能。同時，多年期及整合型計劃所編列的出國經費，也對學人長期
經營與國際研究社群的關係大有幫助，如果能在參加國際研討會的場合，積極
尋找與國際學者合作的機會並發展跨國計畫，或爭取在學會或下次主辦會議的
擔任角色，則對我國的研究水準及能見度會更有幫助。 
 
四、攜回資料名稱及內容 
 
會議論文光碟片一張 
 
 
 
 
 
International Conference on Artificial Intelligence and Pattern Recognition (AIPR’07), Orlando 
表 Y04 
since in practice it is hard to say which image is more 
“irrelevant” if the image does not contain the information 
that the user is seeking for. To this end, we must modify 
the formulae of traditional RF approaches to 
accommodate this new feature. 
 Let the feature vectors of a query image and a 
database image be represented by ),...,,( 21 dxxxX =  
and ),...,,( 21 dyyyY = , respectively, where d is the 
number of selected features and ix  and iy  are the 
values of the ith feature. The first display of retrievals can 
be returned by calculating the top t database images that 
are the nearest neighbors of the query according to a 
given similarity metric, say the normalized Euclidean 
metric, dyxYXDist
d
i
ii∑
=
−=
1
2)() ,( . Then the user is 
invited to enter a soft RF process if he/she is not satisfied 
with the retrieved result. 
 
2.1. Soft QVM 
 
Let the submitted query be the ith database image and 
have experienced j RF iterations, and let )( jiX  denote the 
current query formulation. The system returns t images as 
current retrievals and requests for soft relevance feedback. 
The user identifies relevance degree of each retrieved 
image using our 4-level feedback interface. Let R be the 
set of excellent and fair retrievals and N be the set of bad 
retrievals. The soft QVM derives the reformulated query 
vector by 
∑ ∑∑ ∑ ∈
∈
∈
∈
+ ++=
NY
NY
Y
kY
RY
RY
Y
kYj
i
j
i
k
k
k
k
k
k
k
k
r
Yr
r
Yr
XX γβα )()1( , 
whereα, β, and γ are the parameters controlling the 
relative importance of each type of relevance information, 
kY
r  is the discounting weight of image kY  according to 
the relevance feedback. Empirically, we find those values 
of 0.5, 0.1, 0, and –0.1 for the discounting weights of 
“excellent”, “fair”, “don’t care”, and “bad” work better 
for our experiments.  
 
2.2. Soft FRE 
 
With the user’s feedback, the soft FRE examines the 
retrieval ability of each feature by projecting all the 
database images onto the corresponding feature axis, and 
the new t closest images to the query are retrieved. In 
particular, the relevance weight of feature i is evaluated 
by 




= ∑
Ω∈
0 ,max
ij
ji trw , where iΩ  is the set of 
retrieved images using feature i alone. Hence, the feature 
is more relevant if many of the retrieved images in iΩ  
have been marked as excellent or fair by the user. Finally, 
the new t retrievals after this RF iteration are determined 
by the weighted Euclidean dissimilarity metric 
∑∑
==
−=
d
i
i
d
i
iii wyxwYXDist
11
2)() ,( . It is worth noting 
that our Soft FRE technique also serves as a dymanic 
feature selection method as an irrelevant feature may be 
eliminated from our feature set if its corresponding weight 
is changed to zero after user’s feedback. 
 
2.3. Soft CB 
 
Here, we illustrate our idea by taking Bayesian 
classifier as an example. Let ( )Rp  and ( )Yp  be the a 
priori probabilities that a database image being relevant 
or irrelevant to the query, and )( RYp  and )( NYp  be 
the conditional probabilities that an image is Y given that 
it is relevant or irrelevant to the query. We estimate 
)( RYp  and )( NYp  using the observed samples in R 
and N, respectively. Assume the relevant images form a 
Gaussian density, then )( RYp  ≡ ) ,( RRN σµ  with 








∈∀= ∑
∈
RYrYrR k
RY
YkY
R
k
kk
  µµ  and 








∈∀= ∑
∈
RYrYrR k
RY
YkY
R
k
kk
   σσ  where )(⋅µ  and 
)(⋅σ  denote the vectors of mean and standard deviation 
of the observed samples. Hence, the image relevance 
weight 
KY
r  determines the proportion of the relevance 
probability contribution made by the relevant image kY . 
Similarly, we use a Gaussian density to model irrelevant 
images and let )( NYp  ≡ ) ,( NNN σµ  with 








∈∀= ∑
∈
NYrYrN k
NY
YkY
N
k
kk
  µµ  and 






 ∈∀= ∑
∈
NYrYrN k
kNY
YkY
N
k
kk
  σσ . The most relevant 
images are determined using the Bayesian classifier. 
Bayesian classifier provides a framework to compute the 
a posteriori probabilities )()()()( YpRpRYpYRp =  
and )()()()( YpNpNYpYNp = . The system then 
returns the top t images with the highest values of 
)()()( YNpYRpYJ =θ  = ( ) ( ))()()()( NpNYpRpRYp . 
 
3. Association rule mining 
 
Association rule mining has been successfully applied 
to many business and industrial domains [7]. It finds 
International Conference on Artificial Intelligence and Pattern Recognition (AIPR’07), Orlando 
表 Y04 
extremely large which may cause expensive searching 
time, it is desired to reduce this number with minimum 
precision sacrifice. We propose two types of rule set 
reduction techniques based on confidence quantization 
and redundancy detection and they are described as 
follows.  
Type-1 rule set reduction: Because our aim is to 
retrieve most relevant images using the strong association 
rules, the rules with similar confidence can be merged if 
they have the same antecedent since all the images in the 
consequences of the merging rules have similar relevance 
weight to the antecedent image. To facilitate this, we first 
quantize the confidence value into fixed-length intervals 
and merge all the rules that have the same antecedent and 
whose confidence values fall in the same interval. 
Formally, assume there are k rules with the same 
antecedent A and similar confidence values, enumerated 
as A ⇒ Bi, i = 1, …, k. We merge these rules into one as A 
⇒ Z, U
ki
iBZ
,...,1=
=
 and ( ) ( )∑
=
⇒=⇒
ki
iBAConfk
ZAConf
,...,1
1 . 
For example, let Figure 2(a) correspond to all the rules 
that have the same antecedent {a} and we take the fixed 
interval of length 0.01. The second and the forth rules fall 
in the same interval [0.19, 0.20] and can be merged into 
one rule (see the second rule in Figure 2(b)) and the 
confidence of the resulting rule is the average of the 
original confidence values. Analogously, the third and the 
fifth rules in Figure 2(a) are merged into the third rule in 
Figure 2(b). The interval length should be small enough to 
minimize the degradation in retrieval precision. 
 
Type-2 rule set reduction: Another useful reduction 
technique is to detect redundancy in the rules. Let two 
rules have the same antecedent A and be enumerated as A 
⇒ B and A ⇒ C. Rule redundancy exists if the two rules 
satisfy at least one of the following conditions. 
z If CB ⊂  and ( ) ( )CAConfBAConf ⇒<⇒ , then rule 
A ⇒ B is redundant and can be removed from the rule 
set. 
z If  CBD ∩=  and ( ) ( )CAConfBAConf ⇒<⇒ , 
then rule A ⇒ B can be shorten as A ⇒ B\D where 
B\D denotes the difference set between B and D. 
For example, the first and the second rules in Figure 2(c) 
satisfy the first redundancy condition and the latter rule 
with lower confidence can be removed. Also, the first and 
the third rules satisfy the second redundancy condition 
and the latter rule {a}⇒{c, d, e, f} can be shorten as 
{a}⇒{e, f} (see Figure 2(d)). The type-2 reduction 
technique will not cause any loss in retrieval precision 
since the removed items are redundant. 
 
3.3. Relevance inference 
 
With the prior relevance knowledge represented as 
association rules, the potentially relevant images to a 
particular query can be found using relevance inference. 
Given a query image q, we consider the following 
relevance inference rules.  
z The first-order inference rule seeks for all the rules 
A ⇒ B with A = {q}. It infers the relevance of 
image b ∈ B to query q as ( ) ( )BAConfbq ⇒=Φ . 
z The second-order inference rule seeks for the rules 
A ⇒ B and C ⇒ D where A = {q} and BC ⊂ . It 
infers the relevance of image d ∈ D to query q as 
( ) ( ) ( )DCConfBAConfdq ⇒×⇒=Φ . 
The relevant images are sorted in the decreasing order of 
image relevance derived by the inference rules. The top t 
most relevant images are returned to the user. If the 
number of relevant images in the sorted list is less than 
the user-specified number of retrievals, the lack is filled 
by the most similar images according to Euclidean metric. 
Apparently, in additional to the above inference rules, we 
can use other higher order inference rules to find more 
relevant images. However, we avoid this for two reasons. 
(1) The image relevance derived from the third-order or 
higher order inference is usually low due to the 
multiplication of multiple confidence values. The image 
with low inferred relevance should be discredited since 
the prior experience is contributed by few individuals and 
their feedbacks could be outliers to the subjective of mass 
users. This is analogous to the use of minimum 
confidence for eliminating insignificant rules. (2) Using 
higher order inference rules would definitely entail 
expensive computation time and contribute little in 
retrieval improvement. We thus consider only the first two 
orders of relevance inference for saving computations. 
 
Rule ID Association rules Confidence 
1 {a}⇒{b} 0.651 
2 {a}⇒{c, d, e} 0.253 
3 {a}⇒{f, g} 0.185 
4 {b}⇒{h, i, j} 0.426 
5 {b}⇒{k, l, m, n} 0.323 
: : : 
: : : 
 
Figure 3. Image relevance inference. 
 
3.4. Binary search and best-first search 
 
To expedite the computation for relevance inference, 
we propose some practical implementations using binary 
search and best-first search. The process is proceeded as 
follows. All of the image relevance association rules are 
sorted according to the rule antecedent, and in each 
antecedent category, rules are sorted in the decreasing 
order of rule confidence. An example is shown in Figure 3. 
Thus, for a given query, the association rules satisfying 
International Conference on Artificial Intelligence and Pattern Recognition (AIPR’07), Orlando 
表 Y04 
 
Figure 4. The average RS values obtained using 
ASQVM and ESQVM, respectively. 
 
at different numbers of relevance feedback iterations. The 
RS curve of ASQVM starts with a very high score (3.87) 
due to the contribution of association rule mining, and the 
RS value increases gradually by the soft QVM process as 
the number of iterations increases. While the RS curve of 
ESQVM starts from 1.85 since the traditional Euclidean 
matching is applied, in which case the retrieval 
performance can still be improved by the proposed soft 
QVM mechanism and the RS increases rapidly at the first 
three iterations, then the improvement ratio becomes 
slower for the rest of the iterations. Hence, the ASQVM 
method can greatly improve the performance of retrieval 
systems with relevance feedback, and even the user sticks 
to Euclidean matching the proposed soft QVM scheme 
can help improve the retrievals significantly.  
 Figures 5(a) and 5(b) show a typical example of the 
first retrievals using ASQVM and the improved retrievals 
after applying one soft QVM iteration. It is seen that in 
the first retrievals there are six images marked as 
“excellent”, three as “fair”, and one as “bad”, obtaining an 
RS value of 3.2. In the retrievals after applying one soft 
 
 
(a) 
 
(b) 
 
 
(c) 
 
 
(d) 
Figure 5. ASQVM vs. ESQVM on category search. 
