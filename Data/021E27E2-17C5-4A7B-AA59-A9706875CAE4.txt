一般型研究計畫(個別型)95-2221-E-324-022 
 2
新進入使用者所帶來的傷害值，選擇較低者來決定服務的對象。 
2. Research Methodology 
本方法利用無線網路應用伺服器（Wireless Application Server；WAS）收集
服務歷程記錄，透過前置處理及過濾機制，以獲得探勘所需的資料。本研究設計
一套具循環性的序列型樣探勘技術，以找出使用者在某一個區域中循環性要求服
務的行為。根據循環性序列型樣，預先傳送到使用者端的快取記憶體中，以減少
使用者的延遲等待時間。此外，再發展多階層關聯規則的探勘，分析使用者在不
同區域間移動所需要的服務項目，結合我們所提出的傷害函數計算策略，以決定
當有新使用者進入後，是否進行服務插播，選擇傷害程度較低的策略來服務新或
舊之使用者。 
2.1 Data Collecting and Preprocessing 
在無線環境中，WAS 中收集了各個 BS 的日誌檔（Log Files），而檔案中記
載了許多使用者相關的資料。透過前處理的動作，如：擷取（Select）、整合
（Integrate）及轉換（Transfer）等動作，將資料依據時間的先後順序，轉換成後
續所需要的資料，我們稱這些使用者的日誌檔為服務歷程（Service History）。 
2.2 RFM Filtering Strategies 
RFM[11] 是眾多市場區隔方法的其中之一，藉由最近購買時間（Recency）、
某個時間的購買頻率（Frequency）、交易的平均金額或總金額（Monetary）三個
因素，為了衡量顧客對企業的貢獻程度及忠誠度而設計的單一區隔方法，透過此
分析可以瞭解顧客再次購買的機率與忠誠度的關係。利用這三個因素來分別過濾
出最近常被要求的服務、經常被要求的服務及服務價值較高的服務，輸入下一階
段進行探勘的動作。 
2.3 Location-Based Cyclic Sequence Mining (LBCS) 
在無線網路環境中，使用者（Client）帶著無線網路的連接設備，如：PDA
或是具有無線功能的筆記型電腦，就可以透過 BS 連上無線網路，以進行資料或
服務的要求。透過 BS 向後端的無線網路應用伺服器（WAS）來進行使用者服務
要求，這些要求服務的行為，將會被一一記錄在 WAS 中。本文稱這些服務要求
的檔案記錄為服務歷程(Services History)。在服務歷程中每筆記錄都會包括：使
用者名稱、要求服務、服務時間及服務地點等相關資料。令 s(L)為以區域為基礎
的服務項目，表示在區域 L 中使用者所要求的服務項目 s。I 為所有服務項目的
一般型研究計畫(個別型)95-2221-E-324-022 
 4
（L2, S2）］，其表示使用者在區域 L1 中要求了服務 S1，當使用者移動進入區域
L2 時，可能會有服務項目 S2 的需求，因此該型樣前項稱之為“因型樣”（Cause 
Pattern；CP），後項稱為“果型樣”（Decision Pattern；DP）。當區域感知服務型樣
的信賴度滿足所訂定的門檻值時，該型樣成為區域感知服務關聯規則
（Location-Aware Service Rule；LASR），如［（L1, S1）Î（L2, S2）］，這些規則
將可以提供下一步驟進行資料預存取的決策依據。 
2.5 傳送行動定位服務 
在無線環境中，WAS 與使用者透過基地台（Base Station；BS）來互相進行
資料的交換，因此 BS 具有偵測使用者在區域內進出或移動的能力。有一群使用
者，由 L1 移動進入 L2 時，我們稱他們為新使用者（Foreigner），而原本在 L2的
使用者則稱為舊使用者（Native）。當 BS 偵測到有一群新使用者進入該區域，BS
將會透過 WAS 來啟動預測機制（Predicting），此機制乃依據之前探勘出來的
LASR，再加上本論文所制定的傷害函數計算（Penalty Calculation）策略，作為
決定是否要依據預測機制所推薦的服務來傳送給這群新使用者，傷害函數計算的
策略，將在下個段落中進行詳細的說明。 
預測機制啟動時，WAS 會先從 LASR 資料庫 R 中取出符合該地區的規則，
並將其儲存在 BS 的資料庫 'R
i
中，因此 'R
i
為 R 的子集合，再依據 'R
i
的信賴度由
高至低來排序。接著再逐一將 'R
i
規則中 Decision Pattern 所預測的服務項目，由
WAS 中取出存放至ωi中，ωi為前 Top N 個 Decision Pattern 預測之服務項目的
集合，預先將ωi 儲存在 BS 的 Buffer 中，乃因為這些項目都有可能是新使用者
進入該區域後的需求，但是並非ωi 中所有的服務項目都會進行傳送的動作，因
為在傳送之前，我們還必須透過傷害函數的計算，以決定服務的對象是新使用者
還是舊使用者。而將服務項目預先儲存在 BS 中的原因，乃既使當我們決定不服
務新使用者時，而新使用者又有這些服務項目的需求時，即可直接在 BS 的 Buffer
中直接進行存取，可以大大地減少 BS 再向後端 WAS 要求服務的傳輸及等待時
間。 
因此，當有新使用者移動進入區域中時，並非直接傳送事先儲存在 BS 中的
服務項目，因為提供服務給新使用者時，會對舊使用者產生傷害（Penalty），也
就是接收服務的延遲時間。因此本研究提出傷害函數計算的策略，透過傷害函數
的計算，以決定是否針對新使用者來提供服務，或是維持原本的廣播服務策略。 
一般型研究計畫(個別型)95-2221-E-324-022 
 6
現今行動商務中，少有企業針對使用者過去的服務要求行為及移動區域的習
慣來提供個人化及適地性的行動服務，雖然企業中具有使用者過去的要求服務記
錄，卻因為該資料具有商業價值，且基於隱私權的問題，大多不願意提供所擁有
的使用者記錄，導致在這方面的研究往往缺乏的就是真實的使用者資料來進行實
驗。為了解決資料來源的問題，本研究自行開發 Web-based 的網站
（http://163.17.9.88/wisp/index.html），請擁有手機或行動設備的使用者，透過網
頁呈現的方式，設計四個不同的區域空間（North、Central、North 及 East），讓
使用者預先選擇即將前往的兩個區域，再分別依序選擇在不同區域中預計要向
WISP 要求的行動服務項目，並將原本 23 個服務項目，概念化提昇成 9 個服務
項目，以供使用者可以在網頁中在每個區域選擇 3~6 個服務。共收集 1200 筆資
料，經由資料的前處理階段後，尚有 1127 筆服務歷程記錄，再利用 80/20 法則
將原始資料區分成探勘資料（Training Data）及測試資料（Testing Data），亦即
取 80%的原始資料來進行探勘，另外 20%的資料來進行資料驗證的動作，探勘
資料共 902 筆，測試資料共 225 筆。以下實驗將利用所收集的資料來進行 LBCS
的探勘，以及利用測試資料來驗證在不同 Cache Size 下，LBCS 的命中率及平均
延遲時間的變化，最後驗證採用 LBCS 是否能降低使用者平均等待服務延遲時
間。 
3.1 不同支持度下，LBCS 的探勘結果 
首先，我們利用不同的支持度門檻來探勘 LBCS 的數量。支持度愈低，所能
得到的數量愈多，反之則愈少。 
3.2 Cache Size 對 LBCS 服務命中率的影響 
在研究中，我們依據 LBCS 所組成的廣播磁碟，逐一將服務傳送到使用者行
動設備的 Cache 裡。假設 Cache Size 為 2 的情況下，一次只能提供兩個服務項目
給使用者，再去驗證這兩個服務項目能滿足多少比率的使用者，即為我們所呈現
的命中率。因此，我們驗證了在較大的 Cache Size 下，LBCS 所提供的服務，較
能滿足使用者的需求，提高服務命中率。 
3.3 Cache Size 對平均延遲時間的影響 
除了在上述實驗中，探討 Cache Size 的對命中率的影響之外，我們也利用
LBCS 與 Cache Size 的變化，以驗證使用者等待服務的延遲時間，在較大的 Cache 
Size 下能得到改善。 
一般型研究計畫(個別型)95-2221-E-324-022 
 8
between Sets of Items in Large Databases,” Proceedings of the ACM SIGMOD 
Conference on Management of Data, pp. 207-216. 
[6] S. M. Chen, S. J. Park, and S. P. Yu (1998), “Efficient Data Mining for Path 
Traversal Patterns,” IEEE Transactions on Knowledge and Data 
Engineering, , Vol. 10, Issue 2, pp. 209-221.  
[7] J. W. Lee, O. H. Paek, and K. H. Ryu (2004), “Temporal Moving Pattern Mining 
for Location-Based Service,” The Journal of the Systems and Software, Vol. 3, 
No. 3, pp. 481-490. 
[8] G. H. Li, K. Y. Lam, T. W. Kuo, and S. W. Lo (2004), “Location Management in 
Cellar Mobile Computing Systems with Dynamic Hierarchical Location 
Database,” The Journal of Systems and Software, Vol. 69, No. 1-2, pp. 159-171. 
[9] B. Rao, and L. Minakakis (2003), “Evolution of Mobile Location-Based 
Services,” Communications of the ACM, Vol. 46, No. 12, pp. 61-65. 
[10] Y. Saygin, and O. Ulusoy (2002), “Exploiting Data Mining Techniques for 
Broadcasting Data in Mobile Computing Environment,” IEEE Transactions on 
Knowledge and Data Engineering, Vol. 14, No.6, pp. 1387-1399. 
[11] J. B. Schafer, J. Konstan, and J. Riedi (1999), “Recommender Systems in 
E-commerce,” Proceedings of the 1st ACM Conference on Electronic Commerce, 
pp. 158-166. 
[12] S. M. Tseng, and C. F. Tsui (2004), “Mining Multilevel and Location-Aware 
Service Patterns in Mobile Web Environments Systems,” Man and Cybernetics, 
Part B, IEEE Transactions, Vol. 34, Issue 6, pp. 2480 – 2485. 
5. 計畫成果自評 
研究內容與原計畫相符、提供更具個人化及適地性的行動服務，減少使用者的延
遲等待時間及提高行動服務的命中率。因此，本研究計畫的部份相關已發表於兩
個國際會議上，其相關之論文發表資料呈列於下。 
[1] Lee, Chin-Feng and Lan, Ying-Chang, (2006): “Exploiting Data Mining 
Techniques to Generate Prefetching Mechanism and Broadcasting 
Strategies in Mobile Computing Environment,” International Conference on 
Business and Information (BAI 2006(ISSN ： 1729-9322)), Pan Pacific 
Hotel, Singapore, July 12-14, 2006, 
[2] Lee, Chin-Feng and Lan, Ying-Chang, (2005): “Using Hyper-connectivity 
Method for Mining Location-Service in Mobile Computing Environments,” 
The 3rd International Workshop on Supply Chain Management and 
Information Systems (SCMIS 2005), (ISBN 9060-87869-0-8), at the Electra 
Palace Hotel, Thessaloniki, Greece July 6th - 8th, 2005. 
 
 2
行 政 院 國 家 科 學 委 員 會 補 助 國 內 專 家 學 者 出 席
國 際 學 術 會 議 報 告  
 
報告人：資管系李金鳳 2007 年 7 月 20 日 
※ 一、參加會議經過 
 
2007 International Conference on Business and Information (BAI2007) 國際研
討會於2007年 7 月11 日至 7 月 13 日，在日本東京的InterContinental Hotel Tokyo 
Bay隆重舉行。BAI2007所舉行的學術性會議，向來都以包羅廣泛吸引國際尤其是亞洲
以及歐美地區產學界的矚目。此次承蒙國科會及朝陽科技大學補助，使本人有機會得
以參加如此知名的國際性學術研究會。BAI2007的論文科技委員會會員包括有 
。BAI2007 研究領域總共含括數十種研究議題如下 
•  Accounting 
•  Business Administration 
•  Business Policy and Strategy 
•  Economics 
•  Electronic Commerce 
•  Entrepreneurship 
•  Financial and Banking 
•  Health Care Administration 
•  Human Resource 
•  Information Systems and Technology 
•  International Business  
•  Management 
•  Management Education and Development 
•  Management Information System 
•  Marketing 
•  Operations Management 
•  Organizational Behavior 
•  Research Methods 
•  Social Issues in Management 
•  Technology and Innovation 
•  Web Technology and Management 
•  Other Relevant Topics 
 
此次接受的論文共830篇，並有Australia, Austria, Banglandesh, Bosina and 
Herzegovina, Canada, China, Egypt, Finland, Germany, Hong Kong, India, Indonesia, Iran, 
 4
A RECOMMENDATION METHOD FOR DISTRIBUTING 
ELEMEMNTARY STUDENTS BY DATA MIMING AND NEURAL 
NETWORKING  
 
*Chin-Feng Lee and Kuan-Hua Chen 
Department of Information Management, Chaoyang University of Technology, 
No.168, Jifong E. Rd., Wufong Township, Taichung County 41349, Taiwan (R.O.C.) 
Email: {lcf, s9354607}@cyut.edu.tw 
 
ABSTRACT 
Nowadays, most of the elementary student transfer operations in Taiwan are not based on 
adaptive transfer information. However, adaptive studying environment and partners are 
key points to help pupils to get used to a new environment. The purpose of this paper is to 
provide decision supports for educators to cope with the transfer operation of pupils. The 
process to do so are: first, use Binning technology to discrete students’ grade data. Second, 
use Adaptive Resonance Theory to classify students into clusters. Third, use Class 
Inheritance Tree (CIT) of data mining to exploit the characteristic between each cluster. 
The discovered rules corresponding to each cluster are called associative classification 
rules. Fourth, use the set of k associative classification rules to encode a set of data related 
to pupils as a set of training data and the encoded data is a binary vector with length of k. 
Then use these training vectors as the inputs into a Back-Propagation Network to build a 
classification model. We can the classification model to predict a appropriate class for 
every elementary transfer student. The K-Nearest Neighbor Algorithm is used to find out 
the most proper Top–K classes so that we can use these data as decision support for student 
transfer operations. 
The experiment divides elementary pupils into the training group and the test group by the 
principle of 80-20 rule. The training data is used to build a classification model by which 
we can obtain the recognition degree by means of the test data. By the experimental results, 
the recognition degree can be up to 88% in average. The contribution of this system is to 
help Taiwan elementary transfer students can rapidly adapt into a new school environment 
such that it is possible to reduce the unnecessary adapting or experimental periods for these 
students. 
 
Keywords：Decision Support System, Distributing Elementary Transfer Students, Adaptive 
Resonance Theory, Back Propagation Network, K-Nearest Neighbor 
Algorithm 
 6
3. School: Elementary students are affected by personal recognition and evaluations 
from their parents and teachers. Teachers, the most important evaluation factor in 
school, affect students learning status and performance evaluation (Spinath and 
Sponath, 2005). 
 
2.2 Decision support system 
Decision support system (DSS) uses interactive dialogs to assist decision makers to use 
data and model and solve unstructured problems (Liang, 1994). The primary purpose of 
DSS is to use the raise of decision making performance to help decision makers, but not 
just the improvement of efficiency. There are two different types of decision problems, 
which are structured and unstructured (Simon,1960; Wu and Hsieh,1998). During the 
process of making decisions, decision makers are responsible for unstructured problems, 
such as the capability of judgment, intuition, and analysis; computers are tools for dealing 
with structured problems. The components of DSS are Data Management, Model 
Management, and Management (FIGURE 1) for an interface between users and the system
（Liang, 1994; Wu and Hsieh, 1998). 
 
FIGURE 1：COMPONENTS of DSS 
 
2.3 Collaborative Filtering Recommendation 
Collaborative filtering recommendation uses historical data to find out neighboring cluster 
which have relation behavior and preferences. Through analyzing these neighboring 
clusters, we can obtain new or acceptable information upon specific users and provide 
suggestions to them. However, there exists two problems of sparse and limitation of 
extension. 
 
2.4 Data mining and associative classification rules  
When we use the traditional methods for mining association rules, the process spends 
enormous space and time. However, the approach based on class inheritance tree (also 
called CIT) (Lu, Chang, and Changchien, 2002) can solve this problem. The technology of 
class inheritance tree is that it scans the database first and then inserts data items into a CIT 
Database Model
Data Management Model Management
Management for an interface
User
 8
includes user interface, database and model. The number of the data is 439. The reasons to 
choose the sixth grade students are: (1) the area score data of high grade is larger than low 
grade. (2) the transfer student data of high grade is larger than low grade, and thus the 
number of sample is enough to objectively analyze. 
 
 
 
FIGURE 2：STRUCTURE of DSS 
 
3.1.1 Data pre-process 
Before doing data mining, we have to pre-process the data which we need. These processes 
include data cleaning, data integration, data transformation, and data reduction.(Agrawal 
and Srikant ,1994) 
 
3.1.2 Data cleaning 
In reality, we often have incomplete data or data inconsistency. Thus, we have to purify 
data. Normally, we can ignore the incomplete data or fill in an appropriate number which 
can be calculated by average or statistical values. Data noise use method of data 
discretization,and clustering to process. The data inconsistency can be reduced by using 
external query proof. After cleaning data, 394 raw data are used for data mining because we 
eliminate inappropriate ones. 
 
3.1.3 Data combining 
The integration of data is that combine many data sources as a data file. In this paper, we 
have four data sources: student scores, student basic data, student family data, and teacher 
 10
1. The number of groups should be appropriate. If the number of groups is few, we can not 
obtain the features of each group. If the number of groups is huge, it is difficult to 
analyze for us. 
2. Utilize the Hip Point to get cluster number by vigilance parameter, is regarded as better 
result of hiving off (Kuo et al., 2005).  
 
3.2 Establishing the module of class transfers 
We use ART to classify students and use the result as DECs. The following are the steps of 
using CIT to create a set of associative classification rules. 
1. Student learning area scores S={LA, HP, MA, SA, SS, AH, IA}, Socioeconomic status 
present FL, Teacher's age and service seniority TY are attribute of CECs, DECs are 
cluster of student. DECs attribute value use the cluster of student by ART, set to{1, 
2, …, r}, where r =9 in this paper. 
2. Setting up a group of associative classification rules to each cluster of student, this 
regular form is CF][S,BA → . Among them, A part is Ii=vi several preconditions of 
application, the },,,,,,,,{ TYFLIAAHSSSAMAHPLAIi ∈ , where vi belongs to CECs. B 
part is cluster v’ of DECs, among them “Cluster” is DECs, and v’ is cluster value. S is a 
support value of association rule; CF means confidence degree. 
After using CIT to classifying the nine groups, we can get the result shown as Table 3. 
For example, all LA of all classification rules are one in group number one. Thus, we can 
know the LA scores for the students of that group are between the  62 and 71. Using CIT 
to get associative classification rules, we can understand the features of each cluster and 
why students distributed into different clusters by specific features. 
 
 
TABLE 3：THE RESULTS OF ASSOCIATIVE CLASSIFICATION RULES 
NO Part A Part B  (Cluster) CF 
1 LA=1,TY=3,SA=1,SS=1 1 100%
2 LA=1,TY=3,SA=1,HP=1 1 100%
3 LA=1,TY=3,SA=1,MA=1 1 100%
4 LA=1,SA=1,SS=1,AH=1 1 1100%
… …… … … 
83 MA=3,SS=4,LA=3 9 100%
84 MA=3,SS=4,AH=2 9 100%
 
3.2.3 Network training by Back-Propagation Network (BPN) 
The paper divides elementary pupils into the training group (316 records) and the test group 
(78 records) by the principle of 80-20 rule. Each training data is first transformed into a 
vector with the length of 84. We use BPN to establish a classification model by using the 
training data set as model input.  
 12
tend to be classified to the third cluster. 
 
3.3 K-Nearest neighbor 
The last step for recommending elementary transfer students is to utilize K-Nearest 
Neighbor algorithm to find out K most similar examples. For given an example a=(a1, 
a2, …, a9), and assumed the transfer student a is classified into cluster Ca by the BPN 
classification model. For deal with the sparse problem, we apply KNN to each ai for finding 
the most K target students whose ith parameter is most similar to ai of student a. The class 
numbers for these K target students are class[j] for j = 1, 2, …, K. Therefore, class number 
h is recommended to student a because h= mode (class[j]).  That is, we use a single 
parameter to get the appropriate class and use the class which appears most of the times to 
do class recommendation decision for the student. 
The result of recommendation is in table six. Originally, there are two students distributed 
by BPN classification model into cluster 3, and they are recommended into class 603. 
 
TABLE 6：The class recommends the result 
Name LA HP MA SA SS AH IA FL TY Recommend
S1 606 604 606 605 606 606 606 606 606 606 
S2 606 604 605 609 609 606 606 606 606 606 
S3 604 603 603 603 604 603 603 608 604 603 
S4 607 607 607 607 607 607 614 607 607 607 
S5 609 604 606 609 609 606 606 609 609 609 
S6 604 608 603 603 603 603 603 603 604 603 
However, in cluster 2, though S5 is assigned to cluster 2, the scores of that student in math, 
society, and science are different from the scores of the other two students S1 and S2. Thus, 
that student is firstly recommend to class 609, and then 606.  
 
5. CONCLUSIONS AND FUTURE RESEARCH 
In this research, we use some technologies to achieve that recommend the most appropriate 
class for transfer student, and that establish a recommend decision system. Examining the 
classes and classes’ information of decision support, we know that the ratio of correct of the 
result outputted by recommend decision support is fairly high, and that the credibility of this 
class recommendation method is solid.  
In the future, we can use student data across different schools but in the same grade, and 
extend the scope from single school to the same school district. 
 
REFERENCES 
1. Agrawal, R.,and Srikant, R. (1994),  “Fast Algorithms for Mining Association Rules 
 14
COLOR IMAGE RECONSTRUCITON OF MISSING BLOCKS BASED 
ON ROBUST ASSOCIATION RULES 
 
*Chin-Feng Lee and Wan-Ting Chang, 
Department of Information Management, Chaoyang University of Technology, 
No.168, Jifong E. Rd., Wufong Township, Taichung County 41349, 
Email: {lcf, s9414034}@cyut.edu.tw 
 
ABSTRACT 
When a block-coded color image data are transmitted via the internet, block lost will often 
occur to damage the image. This paper deals with the problem for color image 
reconstruction of missing blocks. We propose a novel method for missing block 
reconstruction by using a data mining technique called Robust Association Rule (RAR). A 
set of association rules will be exploited from a between the color R, G and B information.  
The experimental results show the quality of image reconstruction developed by our 
method performs better than that of VQ with Error Self-Embedding (VQESE).  
 
1. INTRODUCTION 
Images can be binary, halftone, intensity (grayscale), or RGB. In this paper, we will 
propose an approach to reconstruct an RGB image with missing blocks.  
An RGB image also known as a truecolor image in which each pixel is specified by three 
values — one each for the red, blue, and green components of the pixel's color. An RGB 
image can be represented by an array, where the first plane represents the red pixel 
intensities, the second plane represents the green pixel intensities, and the third plane 
represents the blue pixel intensities. Blocks that perform color operations expect three input 
matrices, one for each color component. 
Block-coded transmission of color image over a bad internet will result in block damages 
that may cause pixel degradation. When a Sender transmits a color image to the Receiver 
via internet, a bad network qualification due to corruption, noisy disturbance, artificial 
operation and so on, results in block lose or erratic. Therefore, the block-coded color image 
will be damaged. If the Receiver discards the damaged image and makes a request for 
retransmission, there are costs associated with the transmission.  
Therefore, it is important to develop an image reconstruction method for block-code color 
images such that the image can be completed without retransmission. This way, It not 
 16
2. PREVIOUS RELATED WORK 
In the following, we will present a review of previous works related to image 
self-embedding and robust association rule mining methods.  
 
2.1 VQ with error self-embedding (VQESE) 
Lee et al. proposed a scheme for self-embedding an image into itself as a means for 
detecting and locating tamper, and self-recovering. Firstly, the image is divided into 8×8 
blocks and each block corresponds to a codeword. This codeword is associated with an 
index of a codebook.  For given a block (say b1), the next step is to find a target block (say 
bt) which has the smallest difference from b1. Then, the difference will be transformed into 
a DCT coefficient. Both the index of b1 and the DCT coefficient will be further embedded 
into the corresponding masking block of b1.  
For avoiding the lost of image block and its corresponding masking block at the same time, 
Lee et al. used the method proposed by Kang and Leou  to determine a better masking 
block. However, when the loop references between a missing image block and its masking 
block, the block reconstruction will be fail. At this moment, Lee et al. also have to 
reference a pertained codebook by using SMVQ technology to reconstruct a missing block.  
 
2.2 Association rule 
Agrawal in 1993 proposed the method of association rule mining. The method defines a set 
of product items as I = { i1, i2, …, in}on the set of transactions D. Let T (Transaction) 
represent a transaction record of D, and IT ⊆ . 
The association rule between two itemsets X and Y is the form of X→Y, ,X Y I⊂ , 
X Y∩ = . The Minimal Support and Minimal Confidence are two predefined threshold 
values to determine if the association rule X→Y is effective or not. Their corresponding 
definition are listed as Formula (1). 
 
Minimal Support =
||
||
D
YX ∪ *100% 
Minimal Confidence =
||
||
X
YX ∪ *100%                                   (1) 
 
2.3 Robust association rule 
RAR method is employed for the information of relational databases. RAR brought in a 
concept of “valid database” to exploit the more precise information associated items in a 
database containing missing values.  
Let DB be a database with missing values. Assume that there are m distinct attribute values 
for attribute A. Let Attr(A) ={
1 2
, ,..., mv v v } without missing value contained in. Let iVA  
 18
TABLE 1. THE DB1 INCLUDE MISSING VALUE OF ASSOCIATION 
INFORMATION 
 
 
The procedure to discover all frequent itemsets using RAR method is shown in the flowing 
FIGURE 1. 
 
 
 
 
 
 
 
 20
corresponding to a color image is discovered, where each rule is related to one block. 
Accordingly, we can use the association rule to predicate the color intensities of missing 
block. 
 
3.1 Calculate the RGB of the color image 
 
Given an RGB image I, let M*M be the image size and the block size P*P. Accordingly, 
the number of blocks for I is 
PP
MM
*
* . For each block b, let R(i, j), G(i,,j),and  B(i, j) 
represent the pixel value at position (i, j), and )()()( ,, bbb BGR  represent the means for the 
color components R, G, and B, respectively. 
 
PP
jiR
R
p
i
P
j
b *
),(
1 1
)(
∑∑
= ==  , b=1,2,…,
PP
MM
*
*    
PP
jiG
G
p
i
P
j
b *
),(
1 1
)(
∑∑
= == , b=1,2,…,
PP
MM
*
*  
PP
jiB
B
p
i
P
j
b *
),(
1 1
)(
∑∑
= ==  , b=1,2,…,
PP
MM
*
*                                   (2)      
 
 
In FIGURE 2, we choose the block at the bottom-right corner of the Lena image (say, 
block b) as an example to show the intensities of color component R. The size of block b is 
8*8. By Equation (2), R(b) = 224. 
 
 
 
 22
( )
( )
( )
( )
1
' ( 1)
( 1)
b
b
b
b
B
B
B B
B
δ
δ δδ δ
⎧ < ⎫⎪⎡ ⎤⎪ ⎪= ≤ < Ω−⎨ ⎬⎢ ⎥⎢ ⎥⎪ ⎪Ω− ≤ ⎭⎪ Ω⎩
                          (3 ) 
 
For example, a given image could have an image size of 64 by 64 pixels.  Assume 
that Ω =8, and δ = 32
8
256 = . The mean quantization for the 18th block is ' 190 6
32
R ⎡ ⎤= =⎢ ⎥⎢ ⎥  
by Eq. (3), where )18(R =190 and (18) ( 1)Rδ δ≤ < Ω− . 
 
 
  
FIGURE 3. THE BLOCK MEANS      FIGURE 4. MEAN QUANTIZATION. 
FOR R COMPONENT.      
 
3.2 Proposed robust association rule scheme 
In the following, we will present our proposed method based on the concept of RAR 
scheme.  Let Attr( 'R ) = 1 2{ , ,..., }mv v v , Attr( 'G ) = 1 2{ , ,..., }nv v v , and  Attr( 'B ) 
= 1 2{ , ,..., }pv v v  denote as the m distinct R, n distinct G and p distinct B components. These 
R, G, and B values are quantized by Eq (3) and not missing values. Let 
'
ivR  stand for the 
attribute value iv  of 'R  for block b. Let iv  stand for the conut of tuples for the 
attribute value iv , 
'( )Vdb R
 the number of valid tuples for attribute 'R  that contains no 
missing values, Dis( 'B ) the set of invalid tuples for attribute 'B  containing one or more 
missing values. The minimal support, minimal confidence and the representation value can 
be redefined as follows: 
'
( ' )
( ')
i
i
R v
Sup R v
Vdb R
=  
 24
 
 
 
FIGURE 5. BLOCK MEAN QUANTIZATION. 
 
Step2：To data mining the association rules use the RAR. 
 
 26
4. EXPERIMENTAL RESULTS 
We conducted a series of experiments to evaluate the performance of the proposed color 
image reconstruction scheme. We use four 256*256 color images from Lena, Baboon, F16 
and Pepper, respectively, as shown in FIGURE 5(a)-5(d). 
 
    
(a) Lena                        (b)Baboon 
     
(c)F16                          (D)Papper 
 
FIGURE 5. FOUR ORIGINAL IMAGES FOR THE 
EXPERIMENT. 
 
 
In the experiment, Lena image was firstly divided into 8*8 blocks with a block size of 
32*32 (as seen in FIGURE 6 (a)). There are two experiments for reconstructing Lena 
image.  The first one is to set 8Ω = , and 256
8
δ = =32.  The second one is to set  
 28
 
FIGURE 6. THE EXPERIMENT RESULTS FROM LENA IMAGE WITH SIZE OF 
256*256 (a) THE ORIGINAL IMAGE (b) THE MISSING-BLOCK IMAGE (c-d) 
THE RECONSTRUCTION IMAGE WITHΩ = 8 AND Ω =16, RESPECTIVELY. 
 
In the following experiments, we will divide the Lena image into a block with the size of 
32*32, 16*16 and 8*8, respectively. We also introduce 10% missing blocks for each 
experiment. From the experimental results as shown in TABLE 6, we can find that the 
performance of reconstruction is the best (i.e. the PSNR values is the largest) when image 
block is in the size of 8*8. From FIGURE 7, the effectiveness can be observed from that 
FIGURE 7 (d) is better than FIGURE 7 (c). 
 
TABLE 6. THE PSNR VALUES AFTER IMAGE RECONSTRUCTION 
 
The pixel array of one block 32*32 16*16 8*8 
PSNR  after block  reconstruction 26.18db 31.24 db 33.21db 
 
 
 
 
 
 
 
 
 
  
  
 
 
 
    
 
 
 
 
 
                                
(a) Block size is 32*32, randomly 
introducing 10% missing blocks  
(b) Block size is 8*8, randomly 
introducing 10% missing blocks 
 30
F16 42.9
2 
41.7
2 
36.3
5 
35.41 33.65 30.56 28.64 
Pepper 44.1
2 
42.9
7 
38.2 34.37 31.81 30.43 28.94 
The average of PSNR 41.7
8 
39.2
9 
35.2
2 
32.97 31.03 29.30 27.78 
 
TABLE 8. THE PSNR VALUES BY OUR PROPOSED METHOD WITH 
DIFFERENT MISSING BLOCK RATE INTRODUCED 
PSNR 
 
Missing block rate 
3% 5% 10% 15% 20% 25% 30% 
Lena 44.6
2 
38.4
5 
35.4
4 
32.9
6 
30.56 28.6
6 
27.32 
Baboon 37.4
0 
35.2
2 
31.4
1 
29.2
3 
27.12 25.1
4 
24.86 
F16 43.1
2 
42.3
3 
37.3
7 
36.1
1 
34.07 30.9
5 
28.60 
Pepper 45.1
2 
43.0
2 
39.1
3 
35.1
0 
31.96 30.8
8 
29.14 
The average of PSNR 42.5
7 
39.7
6 
35.8
4 
33.3
5 
30.93 
28.9
1 
27.48 
 
5. CONCLUSIONS AND FUTURE DIRECTIONS 
Image reconstruction is very important because it doesn’t need the retransmission of 
missing blocks or images. Therefore, the reconstruction quality determines the 
effectiveness of a reconstruction method. 
This paper has proposed a novel method based on RAR technique for reconstructing the 
missing blocks of transmitted RGB images. The experimental results show our method 
performs better than that of VQ with Error Self-Embedding (VQESE). The image quality 
can achieve 30db when randomly introducing 20% missing blocks. The reconstructed of 
missing blocks can result less blocking-effect. The smooth of missing blocks reconstructed 
better than the edge of missing blocks. 
In the future, we will improve our method for more effectively reconstructing the missing 
blocks where edges exist.  
 
