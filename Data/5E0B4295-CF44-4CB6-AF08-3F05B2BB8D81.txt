1 
 
 
整合 Nelder-Mead 搜尋法與粒子群體最佳化處理限制式最佳化
問題之研究 
 
摘要 
 
   非線性規劃的問題通常存在於科學及工程分析的相關領域中。受限制的非線性模型，由單
一的目標函數及限制式的條件所組成，目標函數及限制式條件為非線性的情形。粒子群體最佳
化演算法如何處理有限制式最佳化問題為首要關鍵問題。本研究主要提出限制式處理方式，並
以整合的 Nelder-Mead 單體法及粒子群體最佳化演算法，稱為 NM-PSO 演算法，處理受限制非
線性規劃的問題。NM-PSO 是一種簡單的工具，並不需要透過複雜的斜率計算，已被成功的運
用在處理無限制條件的最佳化、資料分群及影像處理等相關研究。本研究由文獻中擷取 13 個
標準的非線性規劃測試問題，以整合 NM-PSO 演算法進行實驗模擬，依據求解的準確性及收
斂比率做比較，希望結果明顯優於其他演算法且能有效的處理受限制最佳化的問題並且相當有
效率。 
 
關鍵詞：非線性規劃、Ｎelder-Mead 單體法、粒子群體最佳化演算法 
 
3 
 
I. Introduction 
   Constrained optimization is a mathematical programming technique which attempts to solve 
nonlinear objective functions, or deals with constraints that have a nonlinear relationship, or handles 
both at the same time. It has become an important branch of operations research and has a wide 
variety of applications in such areas as the military, economics, engineering optimization, and 
management science (Nash and Sofer 1996). Constrained optimization problems (COP) with n 
variables and m constraints may be written in the following canonical form: 
 Minimize   )(xf                                         (1) 
subject to   
niuxl
mqjh
qjg
iii
j
j
,,1,
,,1,0)(
,,1,0)(






x
x
 
where ),,,( 21 nxxx x is an one dimensional vector of n decision variables, )(xf is an objective 
function, 0)( xjg  are q inequality constraints, and 0)( xjh  are m-q equality constraints. The 
values iu  and il  are the upper and the lower bounds of ix , respectively. 
Traditionally, most of the methods found in the literature search for approximate solutions to 
constraint optimization problems and assume that the goal and constraints are differentiable (Fung et 
al. 2002). In case that the goal and constraints are not differentiable, heuristic methods are employed. 
Optimization methods using heuristics, which have helped researchers formulate such new stochastic 
algorithms as genetic algorithm (Tang et al. 1998), evolutionary algorithm (Runarsson and Yao 2005), 
and particle swarm optimization (Dong et al. 2005), are of little practical use in solving constraint 
optimization problems due to slow convergence rates. Fan and Zahara (2007) have demonstrated the 
hybrid Nelder-Mead simplex method and particle swarm optimization method (NM-PSO) to be a 
promising and viable tool for solving unconstrained nonlinear optimization problems. This paper 
demonstrates that this algorithm can also be adopted to solve constrained nonlinear optimization 
problems. Until recently, the most commonly used constraint-handling technique for stochastic 
optimization is the penalty method (Coello Coello 2002). The penalty method converts a constrained 
5 
 
problem. 
2. Compute Vx , where Vx  are the derivatives of these constraints with respect to the solution 
vector (n decision variables) and e  is a small scalar for perturbation. 
nmii
ii
nm niexx
niexx
e 








 

,2,1),()|(
,2,1),()|(1
xhxh
xgxg
h
g
V
x
x
x          (3) 
  Therefore, the relationship between changes of constraint violation V and solution vector x is 
expressed by 
VVxxVV xx  1                  (4) 
3. Compute the Moore-Pensore inverse or pseudoinverse   Vx which is the approximate inverse of 
Vx  is to be used instead in Equation (4). 
4. Update the solution vector by VVxVVxxxx xx   tttt 11 . 
5. Loop through steps 1 to 4 at most five times. 
 
2.2 Constraint Fitness Priority­Based Ranking Method 
   This method has been proposed by Dong et al. (2005) and it solves the difficulty of selecting an 
appropriate penalty value that appears in the penalty method. The method introduces a constraint 
fitness function )(xCf  for constraints, and it is computed from both inequality and equality 
constraints as follows: 
For inequality constraints 0)( xjg , 





 0)(,
)(
)(
1
0)(,1
)(
max
x
x
x
x
x
j
j
j
j gIf
g
g
gIf
C                     (5) 
where  qjgg j ,2,1),(max)(max  xx  and )(xjC  is the fitness level of point x for constrained 
condition (j). 
 
7 
 
the simplex can successively improve itself and zero in on the optimum.  
The steps of NM, which is modified to handle a minimization COP, are described below: 
1. Initialization. An initial N+1 vertex points are randomly generated in their respective search  
range or space. Evaluate fitness of the objective function and the constraint fitness at each vertex 
point of the simplex. For the maximization case, it is convenient to transform the problem into the 
minimization case by pre-multiplying the objective function by –1. 
2. Reflection. Determine Xhigh and Xlow, vertices with the highest and the lowest function values, 
respectively. Let lowhigh ff , and lowhigh CfCf , represent the corresponding objective function values 
and constraint function values, respectively. Find centx , the center of the simplex without highx  in 
the minimization case. Generate a new vertex reflx  by reflecting the worst point according to the 
following equation   
)0()1(   highcentrefl xxx                  (8) 
Nelder and Mead suggested that =1. If lowreflrefl CfCfandCf 1  or lowreflrefl ffandCf 1  
then proceed with expansion; otherwise proceed with contraction. 
3. Expansion. After reflection, two possible expansion cases need to be considered, as described 
below: 
3.1 If lowreflrefl CfCfandCf 1 , the simplex is expanded in order to extend the search space in 
the same direction and the expansion point is calculated by Equation (9): 
)1()1(exp   centrefl xxx                    (9) 
    Nelder and Mead suggested = 2. If 1expexp  CforCfCf low , the expansion is accepted by 
replacing highx with expx ; otherwise, reflx replaces highx .  
 3.2 If lowreflrefl ffCf  &1 , the expansion point is calculated by Equation (9). 
9 
 
3.2 Particle Swarm Optimization (PSO) 
Particle swarm optimization (PSO) is one of the latest evolutionary optimization techniques 
developed by Kennedy and Eberhart (1995). PSO concept is based on a metaphor of social 
interaction such as bird flocking and fish schooling. Similar to genetic algorithms, PSO is also 
population-based and evolutionary in nature, with one major difference from genetic algorithms that 
it does not implement filtering, i.e., all members in the population survive through the entire search 
process. PSO simulates a commonly observed social behavior, where members of a group tend to 
follow the leader of the best among the group. The procedure of PSO is reviewed below. 
1. Initialization. Randomly generate a swarm of potential solutions called “particles” and assign a 
random velocity to each.  
2. Velocity Update. The particles are then “flown” through hyperspace by updating their own 
velocity. The velocity update of a particle is dynamically adjusted, subject to its own past flight 
and those of its companions. The particle’s velocity and position are updated by the following 
equations: 
           
))()(()(
))()(()()()1(
2
10
txtprandc
txtprandctVctV
old
idgd
old
idid
old
id
New
id


         (12) 
           )1()()1(  tVtxtx NewidoldidNewid                             (13) 
    where 1c  and 2c  are two positive constants; 0c  is an inertia weight and rand( ) is a random 
value inside (0, 1). Eberhart and Shi (2001) and Hu and Eberhart (2001) suggested 221  cc  
and )]0.2/)((5.0[0 randc  . Equation (12) illustrates the calculation of a new velocity for 
each individual. The velocity of each particle is updated according to its previous velocity ( idV ), 
the particle’s previous best location ( idp ) and the global best location ( gdp ). Particle’s velocities 
on each dimension are clamped to a maximum velocity maxV , which is a fraction in the search 
space on each dimension. Equation (13) shows how each particle’s position is updated in the 
search space.  
11 
 
IV. Experimental Results 
   In this study, we applied the proposed NM-PSO to solve 13 benchmark problems studied by 
Becerra and Coello (2006). This test suite is a set of difficult nonlinear functions for constrained 
optimization and includes four maximization problems G02, G03, G08 and G12. The characteristics 
of these problems includes the number of decision variables (n), the type of objective function, the 
size of feasible region (k), the number of linear inequalities (LI), nonlinear equalities (NE) and 
nonlinear inequalities (NI), and the number of active constraints at the optimum are summarized in 
Table 1. The size of feasible region, empirically determined by simulation (Koziel and Michaelwicz 
1999), indicates the degree of difficulty of randomly generating a feasible solution, the greater the 
size, the higher the degree of difficulty. The forms of the functions are described completely in the 
appendix. The algorithm is coded in Matlab 7.0 and the simulations are run on a Pentium IV 2.4GHz 
with 512 MB memory capacity. 
During the simulation, it has been found that the population size has significant effects on the 
performance of NM-PSO. Table 2 shows the performance of NM-PSO with different population sizes 
for test problems G01, G04, G05 and G08 and it is clearly seen that for the population sizes 21N+1 
and 31N+1, the same performance is achieved and have better solutions than for 11N+1. Therefore, a 
population size of 21N+1 was employed in NM-PSO algorithm instead of 31N+1 to decrease the 
number of function evaluations. 
   The task of optimizing each of the test functions was executed 20 times by NM-PSO, and the 
search process was iterated 5000 times until the reference or a better solution was found. Table 3 
contains a summary of the execution results of NM-PSO, and includes the worst and the best 
solutions obtained, the means, the medians and the standard deviations of the solutions, the average 
number of function evaluations, the average number of iterations and the average number of 
computation times. For the sake of comparison, the table also gives the reference optimal values. In 
every problem, the best solutions are almost equal to the reference optimal solutions. 
13 
 
Table 2. The effect of population size 
Population NM-PSO 
Size 11N+1 21N+1 31N+1 
G01 
(min) 
Best -15.000 -15.000 -15.000 
Mean -14.998 -15.000 -15.000 
Worst -14.997 -15.000 -15.000 
Std. 0.00107 0.00000 0.00000 
G04 
(min) 
Best -30665.5386 -30665.5386 -30665.5386 
Mean -30665.2025 -30665.5386 -30665.5386 
Worst -30663.8583 -30665.5386 -30665.5386 
Std. 0.751451 1.35e-005 1.52e-006 
G05 
(min) 
Best 5126.359 5126.359 5126.359 
Mean 5126.372 5126.359 5126.359 
Worst 5126.397 5126.359 5126.359 
Std. 0.013854 2.70e-004 1.34e-004 
G08 
(max) 
Best 0.095825 0.095825 0.095825 
Mean 0.068486 0.095825 0.095825 
Worst 0.025812 0.095825 0.095825 
Std. 0.037453 3.45e-008 1.12e-008 
 
   For problems G05 and G10, the optimal solutions are better than the reference. For problems G01, 
G03, G04, G05, G06, G08, G09, G11 and G12, the optimal solutions are found consistently in all 20 
runs. For problems G02 and G13, the optimal solutions were not consistently found. Finally, for 
problems G07 and G10, we found quite satisfactory global optima. In term of the efficiency of 
NM-PSO, Table 3 shows that more than half of test problems converged in less than 300 iterations, or 
equivalently less than 50 sec, and problems G09 and G13 converged in less than 2800 iterations, or 
equivalently less than 240 sec. However, test problems G02, G07, and G10 never completely 
converged; they all stopped at the preset maximum number of iterations, which is 5000, with a high 
standard deviation, signifying that the solutions found thus far are still quite far apart.  
 
15 
 
Table 4. Comparison results of test problems with CDE, FSA, GA and ES 
No Type Algorithm Best 
objective 
value 
Mean 
objective 
value 
Worst 
objective 
value 
Standard 
deviation
Average of 
func_evaluations
G01 Min CDE -15.000000 -14.999996 -14.999993 0.000002 100,100 
FSA -14.999105 -14.993316 -14.979977 0.004813 205,748 
GA -15.000000 -15.000000 -15.000000 0.000000 95,512 
EA -15.000000 -15.000000 -15.000000 0.000000 122,000 
NM-PSO -15.000000 -15.000000 -15.000000 0.000000 41,959 
G02 Max CDE 0.803619 0.724886 0.590908 0.070125 100,100 
FSA 0.754912 0.371708 0.271311 0.098023 227,832 
GA 0.801119 0.785746 0.745329 0.013700 331,972 
EA 0.803619 0.753209 0.609330 0.037000 349,600 
NM-PSO 0.803619 0.796431 0.796422 0.002522 2,229,858 
G03 Max CDE 0.995413 0.788635 0.639920 0.115214 100,100 
FSA 1.000001 0.9991874 0.9915186 0.001653 314,938 
GA 0.999980 0.999920 0.999790 0.000060 399,804 
EA 1.000000 1.000000 1.000000 0.000000 339,600 
NM-PSO 1.000000 1.000000 1.000000 0.000000 64,108 
G04 Min CDE -30665.5387 -30665.5387 -30665.5387 0.000000 100,100 
FSA -30665.5380 -30665.4665 -30664.6880 0.173218 86,154 
GA -30665.5386 -30665.5386 -30665.5386 0.000000 26,981 
EA -30665.5386 -30665.5386 -30665.5386 0.000000 66,400 
NM-PSO -30665.5386 -30665.5386 -30665.5386 0.000000 19,658 
G05 Min CDE 5126.5709 5207.4107 5327.3905 69.225796 100,100 
FSA 5126.4981 5126.4981 5126.4981 0.000000 47,661 
GA 5126.4981 5126.4981 5126.4981 0.000000 39,459 
EA 5126.4970 5126.4970 5126.4970 0.000000 62,000 
NM-PSO 5126.3590 5126.3590 5126.3590 0.000000 25,253 
G06 Min CDE -6961.8139 -6961.8139 -6961.8139 0.000000 100,100 
FSA -6961.8139 -6961.8139 -6961.8139 0.000000 44,538 
GA -6961.8139 -6961.8139 -6961.8139 0.000000 13,577 
EA -6961.8139 -6961.8139 -6961.8139 0.000000 56,000 
NM-PSO -6961.8240 -6961.8240 -6961.8240 0.000000 9,856 
 
 
 
17 
 
 
 
These 13 benchmark problems have been solved by NM-PSO and the solutions are now 
compared with those obtained by applying the cultural differential evolution (CDE) algorithm 
(Becerra and Coello 2006), the filter simulated annealing (FSA) method (Hedar and Fukushima 
2006), the genetic algorithm (GA) (Chootinan and Chen 2006) and the evolutionary algorithm 
(EA) (Runarsson and Yao 2005). Table 4 lists the results of solving these problems by the various 
methods using 20 runs in terms of the best, the mean, and the worst solutions, the standard 
deviation, and the average of function evaluations of each method. Solutions to Problems G12 
and G13 by GA are not readily available and therefore are not included in the table. Better values 
in each category are highlighted in boldface. Upon examining the results in Table 4, it is seen that 
NM-PSO consistently found the global optimal solutions in 10 test problems out the 13, while the 
other methods found the optimum for at most 8 test problems. In terms of computational costs, 
NM-PSO outperformed the other four methods in 8 test problems out the 13. Considering both 
the solution quality and the computational efforts, NM-PSO is superior to the CDE method in 10 
test problems out of 13 and surpassed the other three methods in all 13 problems, making 
NM-PSO a clear winner. The superiority of NM-PSO over the other methods can be attributed to 
two factors. One, NM-PSO can effectively reach a global optimum because of the mechanism of 
the gradient repair method, which ensures that no infeasible intermediate solution will ever enter 
consideration and corrupt the solution quality. The gradient repair mechanism also helps 
transform a constrained problem into an unconstrained one once all the constraints have been 
satisfied. Two, the hybrid NM and PSO algorithm is a proven technique (Fan and Zahara 2007) 
for efficiently solving unconstrained optimization problems. Additionally, NM-PSO is easy to use 
because NM-PSO does not call for the selection of an appropriate penalty value for every test 
problem. We therefore conclude that NM-PSO is a robust and suitable tool for solving constraint 
optimization problems. 
 
19 
 
 
 
(a) 
 
 
(b) 
Figure 3. (a) Relation between iteration and constraint fitness function for G06 and (b) Relation between iteration and objective fitness function 
for G06 
 
21 
 
References 
Nash, S. G and Sofer, A., 1996. Linear and nonlinear programming. New York: McGraw-Hill. 
Fung, R. Y. K., Tang, J. F. and Wang, D., 2002. Extension of a hybrid genetic algorithm for 
nonlinear programming problems with equality and inequality constraints. Computers and 
Operations Research, 29, 261-274. 
Tang, J. F., Wang, D. W., Ip, A. and Fung, R. Y. K., 1998. A hybrid genetic algorithm for a type of 
non-linear programming problems. Computers and Mathematics with Applications, 36, 11-21. 
Runarsson, T. P. and Yao, X., 2005. Search biases in constrained evolutionary optimization. IEEE 
Transaction on Systems, Man and Cybernetic, 35, 233-243. 
Dong, Y., Tang, J. F., Xu, B. D. and Wang, D., 2005. An application of swarm optimization to 
nonlinear programming. Computers and Mathematics with Applications, 49, 1655-1668. 
Fan, S. K. and Zahara, E., 2007. A hybrid simplex search and particle swarm optimization for 
unconstrained optimization. European Journal of Operational Research, 181, 527-548. 
Coello Coello, C. A., 2002. Theoretical and numerical constraint-handling techniques used with 
evolutionary algorithms; a survey of the state of art. Computer Methods in Applied Mechanics and 
Engineering, 191, 1245-1287. 
Farmani, R. and Wright, J. A., 2003. Self-adaptive fitness formulation for constrained 
optimization. IEEE Transaction on Evolutionary Computation, 7, 445-455. 
Chootinan, P. and Chen, A., 2006. Constraint handling in genetic algorithms using a 
gradient-based repair method. Computers and Operations Research, 33, 2263-2281. 
Nelder, J. A. and Mead, R., 1965. A simplex method for function minimization. Computer 
Journal, 7, 308-313. 
Eberhart, R. C. and Kennedy, J., 1995. A new optimizer using particle swarm theory. Proc. of the 
Sixth International Symposium on Micro Machine and Human Science, Nagoya, Japan, pp. 39-43.
Eberhart, R. C. and Shi, Y., 2001. Tracking and optimizing dynamic systems with particle swarms. 
Proc. Congress on Evolutionary Computation, Seoul, Korea, pp. 94-97. 
Hu, X. and Eberhart, R. C., 2001. Tracking dynamic systems with PSO: where’s the cheese? Proc. 
of The Workshop on Particle Swarm Optimization, Indianapolis, IN, USA. 
Becerra, R. L. and Coello, C. A., 2006. Cultured differential evolution for constrained 
optimization. Computer Methods in Applied Mechanics and Engineering, 195, 4303-4322. 
Koziel, S. and Michaelwicz, Z., 1999. Evolutionary algorithms, homomorphous mappings, and 
constrained parameter optimization. Evolutionary Computation, 7, 19-44. 
Hedar, A. D. and Fukushima, M., 2006. Derivative-free filter simulated annealing method for 
constrained continuous global optimization. Journal of Global Optimization, 35, 521-549. 
Lee, T. S., Ting, T. O., Lin, Y. J. and Htay, T., 2007. A particle swarm approach for grinding 
process optimization analysis. International Journal of Advanced Manufacturing Technology, 
online available, 2007. 
Gopal, A. V. and Rao, P. V., 2003. The optimization of the grinding of silicon carbide with 
diamond wheels using genetic algorithms. International Journal of Advanced Manufacturing 
Technology, 22, 475-480. 
 
23 
 
















nix
n
xxh
ts
xnxf
Maximize
G
i
n
i
i
n
i
i
n
,...,1,10
10
01)(
..
)()(
03
1
2
1
1

 
 























5,4,3,4527
4533
10278
0200019085.00012547.00047026.0300961.9)(
0250019085.00012547.00047026.0300961.9)(
0900021813.0002995.00071317.051249.80)(
01100021813.00029955.00071317.051249.80)(
00022053.00006262.00056858.0334407.85)(
0920056858.0334407.85)(
..
141.40792293239.378356891.03578547.5)(
04
2
1
4331536
4331535
2
321524
2
321523
5341522
521
151
2
3
ix
x
x
xxxxxxxg
xxxxxxxg
xxxxxxg
xxxxxxg
xxxxxxxg
xxxg
ts
xxxxxf
Minimize
G
i
 
 






















,4,3,55.055.0
12000
12000
08.1294)25.0sin(1000)25.0sin(1000)(
08.894)25.0sin(1000)25.0sin(1000)(
08.894)25.0sin(1000)25.0sin(1000)(
055.0)(
055.0)(
..
)3/000002.0(2000001.03)(
05
2
1
3445
14334
1433
432
341
3
22
3
11
ix
x
x
xxxxh
xxxxxh
xxxxh
xxxg
xxxg
ts
xxxxxf
Minimize
G
i
 
25 
 















7,...,1,1010
0115234)(
08623196)(
01037282)(
05432127)(
..
8104710)11(3)12(5)10()(
09
76
2
321
2
2
2
14
7
2
6
2
213
54
2
3212
5
2
43
4
2
2
11
7676
4
7
2
6
6
5
2
4
4
3
2
2
2
1
ix
xxxxxxxxg
xxxxxg
xxxxxxg
xxxxxxg
ts
xxxxxxxxxxxxf
Minimize
G
i
 
 























,8,...,4,100010
,3,2,100001000
10000100
025001250000)(
012501250)(
0333.8333310033252.833)(
0)(01.01)(
0)(0025.01)(
0)(0025.01)(
..
)(
10
1
553836
4425725
14614
583
4762
641
321
ix
ix
x
xxxxxxg
xxxxxxxg
xxxxxg
xxxg
xxxxg
xxxg
ts
xxxxf
Minimize
G
i
i
 
 










,2,1,11
0)(
..
)1()(
11
2
12
22
1
ix
xxxh
ts
xxxf
Minimize
G
i
 










,5,5,5,100
00625.0)()()()(
..
100/))5()5()5(100()(
12
2
3
2
2
2
2
3
2
2
2
1
ix
rxqxpxxg
ts
xxxxf
Maximize
G
i
i
 






