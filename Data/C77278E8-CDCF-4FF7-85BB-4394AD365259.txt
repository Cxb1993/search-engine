 二、報告內容與參考文獻 
本次的專題結果已投稿並獲接受於 IEEE 於台北圓山飯店 10 月舉行的 SMC 2006: 
   2006 IEEE International Conference on Systems, Man, and Cybernetics 
Oct. 8 - Oct. 11, 2006 - The Grand Hotel, Taipei, Taiwan 
所發表的文章（6 頁）附錄於本頁之後。 
 
 
三、計畫成果自評 
 
本計畫執行成果所提之利用 Adaboost 與 reference feedback 來進行繪畫主題的搜尋，能有
效且正確的找尋出與 query 相符的主題，效果非常令人滿意，執行成果顯示與當初所提之原計
畫內容大致相符，也達到預期目標。本計畫的執行不僅得以發表一篇於 IEEE conference paper， 
還有一位碩士班學生以此為主題作為其畢業論文。希望後續能以這次研究的成效與經驗，推廣
至更多各式各樣的繪畫搜尋。 
 
 
 
 
 
 
 
 
 II. SYSTEM FRAMEWORK 
Usually, a user may wish to search “portraits” (high-level 
concept) instead of the paintings with skin color (low-level 
feature). Our proposed system is designed to bridge the gap 
such that it classifies painting images according to their 
“contents” that people are really interested in. In order to 
extract and combine the features for different queries and be 
efficient enough for on-line learning, AdaBoost learning 
algorithm is adopted for training the classifier. In the following, 
AdaBoost Algorithm [9] and its modified version will be 
discussed. Since images from the initial query only provide a 
small amount of positive and negative training data, a device 
of relevance feedback (RF) is necessary to make more samples 
available for the system learning and thus improve the 
retrieval performance. We will also discuss the mechanism of 
the RF in the proposed system.  
A. Original Adaboost Algorithm [9] 
The AdaBoost Algorithm is used to boost the performance 
of a single weak classifier by combining a few weak classifiers 
to a strong classifier. T weak classifiers with the least error are 
selected to constitute a final strong classifier. The AdaBoost 
Algorithm is briefly described as blow. 
______________________________________________ 
Given: training images ( )ii yx , , ni ,,1K= , and 1,0=iy  for 
negative/positive training images respectively. 
z Initialize the weights 
lmi 2
1 or 
2
1
,1 =ω  for 1,0=iy  
respectively, where m, l are the number of negative and 
positive training images. 
z For t = 1, …, T: 
 For each feature j, a weak classifier hj is trained. Next, 
calculate ( ) iiji itj yxh −=∑ ,ωε . 
 Choose k such that ., kjjk ≠∀< εε  Let 
( )  =⋅kh ( )⋅th  and .kt εε =  
 Update ietitit −+ = 1,,1 βωω where ei = 0, 1 for training 
image xi being correctly or incorrectly classified by ht(⋅), 
and 
t
t
t ε
εβ −= 1
. 
 Normalize 1+tω  so that it is a distribution. 
z The final strong classifier is 
( ) ( )
⎪⎩
⎪⎨
⎧ ≥= ∑ ∑= =
otherwise
xhxH
T
t
T
t ttt
                     0
2
1 1
1 1
αα           (1) 
 where 
t
t βα
1log= . 
______________________________________________ 
When the strong classifier, as in (1), has been trained, it 
evaluates the score ∑ =Tt tt xh1 )(α  for every image x in the 
database. If H(x) = 1 then x is classified as a positive and a 
negative otherwise. The score indicates that how similar the 
image x is matched with the query.  
To implement the AdaBoost Algorithm, each weak classifier 
hj needs to be trained ahead of time. Because our system is for 
on-line learning, both accuracy and efficiency should be 
considered. A simple definition for weak classifier is as 
followed [10]: 
( ) ( )
⎩⎨
⎧ <=
otherwise
 if     
0
1 jjjj
j
pxfp
xh
θ                  (2) 
where x is an image from database, fj(x) is the value of feature 
j for x, pj is a parity sign, θj is the threshold determined as in (3) 
with Cn and Cp the negative and positive training set. γ = 0.5 is 
used for simplicity. Cai [10] suggests that pj = 1 if the average 
feature values of positive training set is smaller than that of the 
negative training set and pj = -1 otherwise. 
( ) ( )
( ) ( ) ( )
   
otherwise 
1 if 
111
11 =
⎪⎪
⎪
⎩
⎪⎪
⎪
⎨
⎧
⎟⎟⎠
⎞
⎜⎜⎝
⎛
+
⎟⎟⎠
⎞
⎜⎜⎝
⎛
+
=
∑∑
∑∑
∈∈
∈∈
j
Cx
j
pCx
j
n
Cx
j
pCx
j
n
j
p
xf
C
xf
C
-
xf
C
xf
C
θ
pn
pn
γ
γ    (3) 
B.  Modified AdaBoost 
To make the AdaBoost Algorithm more prominent for 
CBPIR, three modifications are made. 
(1). Outliers Removing:  
For each feature j, as mentioned, the range of fj(xi) usually 
is large for different images xi. Thus, in determining the 
thresholdθj in (3), those extreme values of fj(xi) should be 
removed to reduce the effect of outliers. The task is 
achieved by following steps. 
______________________________________________ 
z For each feature j, sort feature values fj(xi), xi is a training 
image, i = 1, 2, …, n, with increasing order. 
z Let Smin = Sm – 2⋅( SM - Sm) and Smax = SM + 2⋅( SM - Sm) 
where ms  and Ms  are the values of the top 4n  and 
43n  feature values respectively.  
z The feature value which is not in the range [Smin, Smax] will 
be removed. 
__________________________________________________ 
(2). Preserving Previous Classifier: 
Through the feedback procedure, as discussed in the 
following, the user would select some false positive 
images or false negative images from the retrieved images 
to refine the query. In addition to retraining a new 
classifier using added samples from RF [7], we preserve 
the previous training result and multiply it by a weight ρ, 
0 ≤ ρ ≤ 1. The modified final strong classifier is in (4), h′ 
and α ′ are the previous weak classifiers and 
corresponding weights. 
( ) ( ) { }
⎪⎩
⎪⎨
⎧ +′≥+′′= ∑ ∑∑∑ = =
otherwise                                                               0
2
1          1)( 1 1
T
t
T
t ttt
xhxhxH ααρααρ  (4) 
In this way, any insignificant features that had been 
selected previously will become less influential in 
succeeding  feedback rounds due to multiplication by ρ. 
evaluated. The average and SD values are calculated by 
considering all edge pixels with angles between θi-1 and 
θi+1 since the amount of bin θi  is accumulated from 
those edge pixels. The average and SD of angles to each 
bin θi are calculated in the same way. Together with the 
value of θi in the histogram, there are 7 feature values per 
angle θi. Hence there are 4x7=28 features for each block, 
and 28x23=644 features for one image. 
______________________________________________ 
B. Local Edge Pattern (LEP) [13]: 
Extended from LBP [14], LEP represents the local texture 
of edge image effectively. First, get the texture of each pixel 
by taking the binary edge image obtained as in SAD to 
convolute with a mask shown in Fig. 1. Next, construct the 
LEP histogram hlep for a region R such that the mth bin hlep(m) 
is evaluated by (5), 
511,,0,)( K== m
N
nmh mlep                    (5) 
where nm is the number of pixels with LEP value m, and N is 
the number of total pixels in R. In here, the region R will be 
the whole image. 
 
C. Orientational Correlogram (OC): 
One of well known disadvantages of histogram analysis is 
that it does not contain any spatial information. Qiu [15] 
proposed an orientational color correlogram (OCC). OCC 
extends from the traditional gray-level co-occurrence matrix 
[16] [17] which is widely used for texture description.  
In here, only gray-level is considered so called OC 
(Orientational Correlogram) feature. Gray-levels in image I 
are quantized into Lcc ,,1 K  levels. Let Ic denote the set of 
pixels with its gray-level being c. Define the distance between 
two pixels p1 and p2 in the directional angle θ to be 
θδ 12 pp −= . OC is defined as in (6). 
 ( ) ( )δθδ θ =−∈∈= 1221 ,,Pr,,, ppIpIpjiocc ji cc    (6) 
In our research, gray-levels are quantized into 8 levels, and 
two orientations, horizontal and vertical, are considered. 
Distance is treated as the percentage of width (or height) of 
image when considering horizontal (or vertical) direction. 
Here we choose 25 distances including 1%, 3%, 5%, ..., 49% 
of width (or height). Hence, the dimension of OC 
is ( ) 32008225 2 =×× . 
IV. EXPERIMENT 
In order to implement our system, 1047 paintings are 
downloaded from various web sites and 192 images are 
manually labeled “portrait” among them. Since paintings are 
in different sizes, images are rescaled proportionally so that 
they all have a height of 128. As the purpose of the system is 
to classify the semantic contents of paintings, the over all 
layouts are more important than detailed strokes of paintings. 
Thus a preprocessing of histogram equalization followed by a 
7x7 median filter is applied to images to eliminate the 
influence of illumination and fine details. The detailed 
implementations of the system are described as below. 
1).  The system first randomly provides sample images, 12 
images per page, for user to select his target as shown in Fig. 2. 
User selects about 5 images each that he does or does not want 
for positive and negative training images. 
2).  The classified result is presented on the Retrieval Pages. 
Every image x with H(x) = 1 in Eq. (4) will be displayed 
according to the descending order of the score 
∑ ∑ =+′′ Tt tt xhxh 1 )()( ααρ . As in Fig. 3, the first page, i.e. 12 
images with the highest scores, of the retrieval result is 
displayed after the initial query. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 3). Relevance Feedback (RF) is next activated. After the 
Retrieval Pages are displayed, user should make a positive and 
a negative feedback to retrain the classifier. User is suggested 
to select about 3 to 5 irrelevant images starting from the first 
page of the Retrieval Pages, i.e. best matching irrelevant 
images. As indicated in Fig. 3, three images are selected as a 
1 2 4 
8 256 16 
32 64 128 
  Figure 1 The mask used for calculating the LEP 
Figure 2 The page randomly providing sample images to initiate 
a query.
Figure 3 The Retrieval Page. Three images are labeled as 
