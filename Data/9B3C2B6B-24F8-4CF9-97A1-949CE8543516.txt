部份以少量的位元傳送訊號特徵參數就可以
了，如此就能達到提高壓縮率的目的。 
    近年來，不少研究學者提出許多方法來
提升 VAD 的效能，例如：利用統計模型對外
加雜訊做統計估計[4-5]；結合模糊理論及類
神網路來作語音活動檢測的決策機制
[6-7] ；利用知覺小波封包轉換的方式，將有
效的波段保留，删除能量較低的波段以達到
VAD 的目的[8]；在頻域中，透過分頻階層統
計濾波器估計語音訊號和背景雜訊能量，計
算出信號雜訊比，以此當作 VAD 判斷依據
[9-10]。 
    然而在上述的方法中，除了參考文獻[6-7]
的方法外，大多在頻域中操作且需額外假設
一統計模型做雜訊的統計分析，因此在轉換
的過程中將造成系統的計算負擔。另一方
面，文獻[6-7]的方法亦需在資料訓練上付出
相當的計算量。有鑒於此，本研究計畫將透
過 GM(1,1)模型提出一個灰色語音活動檢測
方法，期待本方法能有效提高 VAD 的效能並
降低計算的複雜度，最後並與 G.729[11]與
GSM AMR[12]做比較。 
    本研究報告的架構如下：第二節將詳細
說明如何透過GM(1,1)模做信號 /雜訊的估
計，第三節則完整介紹本研究計畫所提出的
灰色語音活動檢測方法，第四節將透過模擬
結果驗證本研究所提方法的可行性並與G.729
和GSM AMR做比較，最後第五節對本研究計
畫做一結論。 
 
三、基於GM(1,1)模型之信號/雜訊估計方法 
 
    在外加信號模型(additive signal model)的
假設下，灰色信號/雜訊估計(grey signal/noise 
estimation, GSNE )方法主要是基於下列觀察
與想法：第一、在無外加雜訊的情況下，
GM(1,1) 模型對於近似常數信號 (constant 
signal)與隨機指數信號 (random exponential 
signal)的估計誤差分別是零和近似於零。而在
有外加雜訊的情況下，對於近似常數與隨機
指數兩種信號，GM(1,1)模型的估計誤差都不
為零。第二、 
乾淨的語音信號(clean speech)一般可分為二
個部分：非語音部分與語音部分。若我們將
非語音部分視為近似常數信號而語音部分視
為隨機信號，那麼利用GM(1,1)模型來估計乾
淨的語音信號的估計誤差應為零或近似零。
而 對 於 有 外 加 雜 訊 的 語 音 信 號 (noisy 
speech)，GM(1,1)模型的估計誤差應不為零。 
    以下我們將以二個小節對此方法進行說
明：3.1 節將簡要的回顧 GM(1,1)模型；在 3.2
節中，將描述以 GM(1,1)模型為基礎的信號/
雜訊估計(GSNE)方法。最後在透過六個範例
驗證 GSNE 可以準確對信號/雜訊進行估計。 
 
3.1 GM(1,1)模型回顧 
 
    假定原始資料為一非負序列，記為
}1for ),(,),2(),1({ KkKxxx ≤≤= "x ，經過一
次 累 加 生 成 運 算 (first-order accumulated 
generating operation, 1-AGO)後如下： 
∑
=
=
k
n
nxkx
1
)1( )()(            (1) 
利用 )(kx 和 )()1( kx 建構灰差分方程如下： 
          bkazkx =+ )()( )1(            (2) 
Kk ≤≤2for 。參數 a 和 b 分別是發展係數
(developing coefficient)、灰輸入(grey input)。
背景值(background value) )()1( kz 其定義如下： 
)]1()([5.0)( )1()1()1( −+= kxkxkz   (3) 
    令 








=
)(
)3(
)2(
Kx
x
x
#y
，










−
−
−
=
1     Kz
                
1     z
1     z
)(
)3(
)2(
)1(
)1(
)1(
##B
    (4) 
則聯立差分方程組式(4)可寫成 
                


=
b
a
By               (5) 
利 用 最 小 平 方 法 (least squares method, 
LSM)，解出 a與b 兩值為 
for 42 ≤≤ k ，其中參數 A 與 τ 具有均勻機率
分佈，其變化範圍分別是 )20 ,10( 與。在式(10)
中， )(kn 被設為 0。依據式(10)產生下列四點
資 料 }1.9916 ,2.1303 ,2.2786 ,4372.2{ 。 由
GM(1,1) 模 型 所 得 的 估 計 誤 差 是
)}4(ˆ ),3(ˆ ),2(ˆ { nnn =
}106.252 ,10228.7 ,10309.8{ 444 −−− ××× ，其中
調整因子 0.1=α 。這個例子說明了在沒有外
加雜訊的情況下，GM(1,1)模型可以準確的估
計隨機指數信號。 
 
(iii) 有外加雜訊時的近似常數信號估計 
 
為了說明外加雜訊會導致 GM(1,1)模型
的估計誤差，我們使範例一中的外加雜訊
)(kn 具有高斯機率分佈，其平均值 0=µ 、標
準差 5.0=σ 。在這個例子中，外加雜訊信號
模型 )(5)()()( knknkskx +=+= 。這個例子總
共產生了 1,000 組資料，每組資料各有 20 點
資料。根據 2.2 小節的信號/雜訊估計方法，
在 0.1=α 的情況下，外加雜訊的平均值 µ 與
標 準 差 σ 分 別 估 計 為 0021.0ˆ =µ 和
2941.0ˆ =σ 。明顯的，對平均值µ的估計是適
當的，而標準差σ 則被低估了。為了使標準
差σ 的估計更加準確，我們設定調整因子
75.1=α 。然後重複上一個實驗十次，其 µˆ與
σˆ 的平均值分別為 0.00376 與 0.50562。這個
實驗說明了外加雜訊 )(kn 的統計值 µ 與σ ，
在 75.1=α 的情況下，可以被準確的估計出
來，因為 µµ ≈ˆ 、 σσ ≈ˆ 。 
 
(iv) 有外加雜訊時的隨機指數信號估計 
 
這個例子所使用的隨機指數信號仍然是
由式(10)所產生，其中參數 A 與 τ 的設定與範
例二相同，而 )(kn 則是具有高斯機率分佈，
其平均值 0=µ 、標準差 1.0=σ 。在 0.1=α 的
情況下，µ與σ 的估計值分別是 4104.7ˆ −×=µ
與 0583.0ˆ =σ 。明顯的，平均值µ的估計是適
當的，而標準差σ 則被低估了。如前例，為
了更準確的估計σ ，調整因子α 設為 1.75。
然後重複實驗十次，其 µˆ 與 σˆ 的平均值分別
為 0.0013 與 0.10138。如例三， µµ ≈ˆ 、 σσ ≈ˆ 。
這個實驗再次說明了 GM(1,1)模型可以準確
的估計外加雜訊 )(kn 的統計值µ與σ 。 
 
(v) 乾淨語音信號的估計 
 
    為了印證在第三小節所描述的第二個想
法，在沒有外加雜訊的情況下，我們以一範
例驗證 GM(1,1)模型能適當的估計出語音信
號。在這裡我們以參考文獻[13]中的語音信號
b.wav(男性讀的英文字母“b”)為例。由於
b.wav 的值域範圍介於 1) ,1(− 之間，因此不能
滿足 GM(1,1)建模條件。所以我們將 b.wav 的
準位加 5 後，再送到 GM(1,1)模型進行估計，
接著將估計信號的準位减 5 以得到最後輸出
結果。原始語音信號 b.wav 顯示在圖(4) (a)；
由 GM(1,1)模型估計的 b.wav 顯示在圖(4) 
(b)。明顯的，從圖 (4)的結果中可以看出
GM(1,1)能夠適當的估計語音信號 b.wav。 
 
(vi) 摻雜語音信號的外加雜訊估計 
 
    相同地，為了驗證 GM(1,1)模型估計誤差
確實能適當地用來估計外加雜訊，我們以上
例中的語音訊號為例，不同的是，我們分別
加 入 了 平 穩 (stationary) 與 非 平 穩
(non-stationary)二種不同的外加白高斯雜訊
(additive white Gaussian noise, AWGN)，其
SNR 分別為 5 dB 與 3.73 dB。摻雜的語音訊
號 b.wav 顯示在圖(5)和圖(6) (a)；外加雜訊(標
準差分別為 0.091 與 0.106)顯示在圖(5-6) 
(b)；經由 GSNE 估計出來的外加雜訊(分別為
0.092 與 0.110)顯示在圖(5)和圖(6)，其中
7.1=α ，音段長度為 240。從結果來看，透過
GSNE 來估計外加雜訊是可行的。 
    從範例 (iii)到範例 (vi)中清楚說明了以
GM(1,1)模型為基礎的信號/雜訊估計方法可
以準確的估計出外加雜訊 )(kn 的標準差σ 。
(i) 平穩外加白高斯雜訊 
 
    摻雜的語音信號分別顯示在圖(8)到圖
(11) (b)；實際的外加雜訊與透過 GSNE 所估
計出來的雜訊分別顯示在圖 (8)到圖 (11) 
(c)(d)；本論文中的適應性門檻值分別顯示在
圖(8)到圖(11) (e)；灰色語音活動檢測方法的
輸出顯示在圖(8)到圖(11) (f)，最後 G.729、
GSM AMR 的輸出分別顯示在圖(8)到圖(11) 
(g)(h)。在例子中，GVAD 比 G.729、GSM AMR
中的 VAD 有較好的檢測結果。 
 
(ii) 非平穩外加白高斯雜訊 
 
    摻雜的語音信號分別顯示在圖(12)到(15) 
(b)；實際的外加雜訊與透過 GSNE 所估計出
來的雜訊分別顯示在圖(12)到(15) (c)(d)；本
論文中的適應性門檻值分別顯示在圖(12)到
(15) (e)；最後 G.729、GSM AMR 的輸出分別
顯示在圖(12)到(15) (g)(h)。從模擬結果中可
以看出 GVAD 比其他二種語音檢測方法有較
好的輸出結果。 
 
六、結論 
 
    本研究擴展了 GM(1,1)模型的應用，將其
用來做信號/雜訊的估計，我們稱為灰色信號/
雜訊估計(GSNE)方法。基於 GSNE 與一適應
性門檻值，我們提出一個簡單且有效的灰色
語音活動檢測方法，稱為 GVAD。在 GVAD
的方法中不需要額外統計模型的假設且完全
在時域中操作，因此具有較低的計算複雜
度。透過模擬結果的驗證，本研究之方法不
僅在平穩與非平穩二種不同類型的外加白高
斯雜訊下，能適當地判斷出語音與非語音的
部份，而且也優於 G.729 與 GSM AMR 二種
語音編碼系統中的 VAD 模組。因此，GVAD
可說是一個簡單且有效的語音檢測方法。 
 
七、參考文獻 
 
[1] L. Karray and A. Martin, “Toward 
Improving Speech Detection Robustness for 
Speech Recognition in Adverse 
Environments,” Speech Communications., 
no. 3, pp. 261-276, 2003. 
[2] Jane-Hwa Huang, Szu-Lin Su, Jiann-Horng 
Chen, “Design and Performance Analysis 
for Data Transmission in GSM/GPRS 
System With Voice Activity Detection,” 
IEEE Transactions on Vehicular Technology, 
Vol. 51, no. 4, Jul 2002. 
[3] R. Venkatesha Prasad, Abhijeet Sangwan, 
HS Jamadagni, Chiranth, M.C,  Rahul Sah, 
Vishal Gaurav, “Comparison of Voice 
Activity Detection Algorithms for VoIP,” 
International Symposium Computers and 
Communications , pp. 530-535, Jul 2002 . 
[4] J. Sohn, N. S. Kim, and W. Sung, “A 
Statistical Model-Based Voice Activity 
Detection,” IEEE Signal Processing Letters, 
Vol. 6, No. 1, pp. 1-3, Jan 1999. 
[5] J.-H. Chang and N. S. Kim, “Voice Activity 
Detection Based on Complex Laplacian 
Model,” Electronics Letters, Vol. 39, No. 7, 
pp. 632-634, 2003. 
[6] Gin-Der Wu and Chin-Teng Lin,“A 
Recurrent Neural Fuzzy Network for Word 
Boundary Detection in Variable Noise-Level 
Environments,”IEEE Transactions on 
System, Man, and Cybernetics, Vol. 31, No. 
1, Feb 2001.  
[7] K.-I. Kim and S.-K. Park, “Voice Activity 
Detection Algorithm Using Radial Basis 
Function Network,” Electronic Letters, Vol. 
40, No. 22, pp. 1454-1455, Oct. 2004. 
[8] Yasser Ghanbari, Mohannand Reza 
Karami-Mollaei,“A New Approach for 
Speech Enhancement Based on The 
Adaptive Thresholding of Wavelet 
 
圖(4) (a)原始的語音信號 b.wav  (b)經 GSNE 所估計的 b.wav 
 
 
圖(5) (a)摻雜的語音訊號 b.wav (b)stationary AWGN (c)估計的外加雜訊 
 
 
圖(6) (a)摻雜的語音訊號 b.wav (b) non-stationary AWGN (c)估計的外加雜訊  
 
 
 
圖(9)語音信號 f0126s.wav 在 SNR= 5 dB GVAD、G.729、GSM AMR 的輸出結果 
 
 
 
圖(10)語音信號 f0127s.wav 在 SNR= 5 dB GVAD、G.729、GSM AMR 的輸出結果 
 
 
圖(13)語音信號 f0126s.wav 在 SNR= 1.2 dB GVAD、G.729、GSM AMR 的輸出結果 
 
 
圖(14)語音信號 f0127s.wav 在 SNR= 1.1 dB GVAD、G.729、GSM AMR 的輸出結果 
? Y04 
???????????????????????????? 
                                                            96 ?7 ? 15?
 
????? 
 
 
??? ????
??? 
???????????? 
???  
?? 
???? 
July 11-13 2007 
Melbourne, Australia 
????
????
 
 
???? 
 
 
IEEE/ACIS International Conference on Computer and Information Science 
???? 
?? 
(1) One-Dimensional Grey Polynomial Interpolators for Image Enlargement 
(2) Voice Activity Detection Based on GM(1,1) Model 
???? 
????IEEE/ACIS International Conference on Systems Computer and Information
Science???????????? Central Michigan?Deakin?Monash???????
??????????????????????????? 28 ?????????
392 ????????????????????????????????????
?????? 187??????????????????????????????
??????????????????????????????????????
??????????????????????????????????????
??????????????????????????????????????
??????????????????????????? 
?????????? 
    ?? IEEE/ACIS International Conference on Systems Computer and Information 
Science ?????????????????? Melbourne ????????
Computer Science and Information Science?Image Processing and Pattern Recognition?
Image, Acoustic, Speech, and Signal Processing?Visual and Multimedia Computing?
Speech Processing and Healthcare Engineering ?24?????????????Deakin 
University ?  Kate Smith-Miles ?????????????Meta-learning: From 
Classification to Forecasting, to Optimization, and Beyond??????? meta-learning?
?????????????????????????????????????
????????????????????????????????? 
?
?
?
 
