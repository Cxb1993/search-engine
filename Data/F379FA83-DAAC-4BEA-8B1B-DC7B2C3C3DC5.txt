行政院國家科學委員會補助專題研究計畫 ▓ 成 果 報 告   
□ 期中進度報告 
 
總計畫：夜視型自主式群組校園巡邏機器人之研究 
 
計畫類別：□個別型計畫  ▓整合型計畫 
計畫編號：NSC 99-2221-E-003-022 
執行期間： 99年 8 月 1日至 100 年 7 月 31 日 
 
計畫主持人：王偉彥 
共同主持人：簡忠漢 
計畫參與人員：簡宜興、蔡政沛、戴嘉言、陳銘滄 
 
成果報告類型(依經費核定清單規定繳交)：▓精簡報告  □完整報告 
 
本成果報告包括以下應繳交之附件： 
□赴國外出差或研習心得報告一份 
□赴大陸地區出差或研習心得報告一份 
□出席國際學術會議心得報告及發表之論文各二份 
□國際合作研究計畫國外研究報告書一份 
 
處理方式：除產學合作研究計畫、提升產業技術及人才培育研究計畫、列管
計畫及下列情形者外，得立即公開查詢 
          ▓涉及專利或其他智慧財產權，□一年▓二年後可公開查詢 
          
中   華   民   國 100年 10月 20日 
 網路原本沒有時間定義，為了效能計算的要求而產生時間派屈網路(TPN, Timed Petri nets) 
[4]。眾多時間派屈網路中最被注目的為隨機派屈網路(SPN, Stochastic Petri nets)，並擴展成為
廣義隨機派屈網路(GSPN, Generalized Stochastic Petri nets) [5]。又為了加強系統塑模能力，顏
色派屈網路(CPN, Colour Petri Net)被提出[7, 8]。更有模糊派屈網路將模糊理論與派屈網路理
論結為模糊派屈網路[3, 9]。許多的工具也被發展用來為派屈網路塑模，如 TimeNET 、TINA、
CPN-TOOLS 等。 
    而為了達到有效監控與管理的目的，機器人在巡邏與搜索當中，可透過無線網路與主控電
腦做溝通，使主控電腦可以取得機器人的資訊，如所在位置、殘存電量、電池健康度等。這些
資訊將會顯示在使用者介面系統。當機器人搜索一個複雜的環境，為了使控制端可以得到機器
人的座標，機器人所配置 GPS 將會將所在的地球座標傳送到控制端，並透過 Google map 所提
供之 API[10]將其即時座標顯示在使用者介面。 
    近幾年，投入熱影像人臉辨識的研究人員越來越多，主要的原因是因為藉由熱影像圖所擷
取出來的人臉生理資訊具有獨特性、不容易受到外在因素的影響而改變。例如：光源的變化、
臉部表情的改變或使用者年齡的增長，都可能會造成辨識效能的降低[11, 12]。由於熱紅外線
頻譜圖相較於視覺頻譜在辨識效能上並不會特別出色，但熱紅外線頻譜圖所擷取出來的生理資
訊具有獨特性。有些研究者將視覺頻譜與紅外光譜結合運用，用來增加人臉辨識的效能[13-15]。 
    而在行人區域偵測方面，[16-18]利用特徵(包含膚色、身體輪廓、形狀)來偵測行人。而[19, 
20]提出三角分割法，依造人的行為動作進而判斷是行人，而[21, 22]則以 HoG 特徵來偵測行人。
除了特徵點的判斷，在[20, 23]中使用AdaBoost分類法，以及使用SVM (Support Vector Machines) 
[24]，藉由 Adaboost 或 SVM 訓練與學習的機制，從影像中偵測出行人的位置。在本研究總計
畫中則是以 AdaBoost 的學習機制，配合 HoG 特徵來做行人偵測。 
2. 計劃目的 
    本整合型計畫的總體目的是讓群組機器人能夠自主的在日間(一般 CCD 辨識技術)、夜間或
是光線不佳(整合紅外線熱像儀影像辨識技術)的環境下，進行環境巡邏的工作。當中得進行人、
動物、車輛及障礙物的辨識，尤其是夜間和光線不佳的環境，並有效的判定屋內運轉中設備，
如冷氣機、燈光等，是否無人使用，無人使用則進行無線遙控關閉之動作，達到節能減碳的理
念。細部的總計畫目的，如下所敘述：目前群組機器人的相關研究，缺乏系統方面整合與訊息
分析並下達最終決策命令的研究，因此本整合研究計畫首先(子計畫二)將以 Petri nets 理論研究
巡邏機器人之系統，並以 Fuzzy Petri nets 直接分派監控夜間群組巡邏機器人之單機行動，以期
能夠透過網路通訊實現決策機制功能與分散式網路分派監控之概念。另外，總計畫中(子計畫一)
也將應用 cMsg 技術建立專屬於夜間巡邏群組機械人的訊息整合系統與建立資料庫系統，能有
效率管理資料庫，並結合 Clutter 技術建立夜間巡邏群組機械人的 3D 使用者介面，此介面將顯
示各機器人的所在位置，亦開發模糊類神經網路與實數基因演算法去預測機械人所剩的電池電
量及使用的電池健康度。在執行巡邏工作時，資料庫裡必須具有即時或事先建立之環境地圖、
地標供路徑規畫之用，因此總計畫中(子計畫二、五)也將著重於發展結構化未知環境與未結構
化未知環境之探索技術，讓機器人能透過各類感測器自主探索環境，進而建立執行任務所需之
環境地圖與標示參考地標，完成各機器人巡邏任務之路徑規畫。機器人巡邏中，將會碰上各式
各樣的不明物體，若不將這些不明物體詳細辨識，則會忽略了入侵的可疑份子或是阻礙機器人
  
圖 2、使用 ZigBee 架構(星狀拓樸) 
3.2 自走車移動軌跡紀錄與路徑追蹤 (子計畫二) 
    自走車的移動軌跡之紀錄係利用驅動輪上所配備的編碼器，自走車在做地圖建構時，當下
位置座標的紀錄是以自走車啟動時的座標設為(0,0)，起始角度令自走車正前方定為0D 。經由
左右輪的移動來計算出自走車移動的距離以得到當下自走車在環境中的座標，與自走車當下方
向的角度。故於自走車行走時的每一步，將自走車在行進過程中所在的座標點紀錄下來，並且
連續的描繪出來，便可從中觀察自走車行走的移動軌跡。以此方法，自走車行走時所量測到與
障礙物的距離，不僅可以做為避障的依據，自走車行進周遭的地圖輪廓也可以藉此方法建構起
來。 
    因為很多系統可以被表示成數學模型的形式，所以在模糊控制器的發展上，使用 T-S 模糊
類神經模型是非常適當的。模糊規則的前件部是輸入變數，而後件部是輸入變數的線性組合
[25]。T-S 模糊類神經模型規則定義如下: 
( )
1 1
1 1 2 2 ( )
: If   is  and  is  and  is  
        Then 
i i i i
n n n m n m
i i i
l l l l n m n m
R z F z F z F
y p z p z p z
+ +
+ += + + +
… "
…                 (1) 
其中 T1 2[z ,z , , ]n mz +=z " 為語意變數輸入向量， ly 是派屈模糊類神經網路層的輸出變數， ijF 是模
糊集合， ilkp 是可調整參數亦稱為權重因子。圖3為派屈模糊類神經網路的架構圖。 
 0,
1,
T
T
εβ ε
⎧ ΩΩ >⎪= ⎨ ΩΩ ≤⎪⎩
                              (4) 
其中，ε 是一個小的正數。 
定理一: 考慮某一類的輪型行動機器人近似系統(2)，假若控制器設計為(3)，其更新法則為 
1
1
ˆ ( ) , 1,2, ,i i T T Tw i hξη −= =F H HH ex "                      (5) 
1
2
ˆ ( ) , 1,2, ,i i T T Tw i hξη −= =G H HH eu "                      (6) 
其中 1η 與 2η 是正的常數，則閉迴路系統是強健穩定的且 lim ( ) 0t t→∞ =e 。 
3.3 行人偵測系統 (子計畫四、五) 
    行人偵測之架構之圖 4所示，整個架構分為三個部份，黃色部份是訓練機制，藉由 Adaboost
的訓練機制從眾多的弱分類器(Weak classifier)中挑選出適合偵測行人的分類器，組成強分類器
(Strong classifier)。而綠色部份則為即時特徵擷取，當熱感影像輸入後，先做二值化的處理，取
得我們所要的前景影像，從這些前景影像中，找出我們有興趣的區域(RoI)，再擷取每一個 RoI
的特徵資料。最後在藍色區塊中，以原先訓練出來的強分類器，與即時影像所取得的 RoI 特徵
資料做比對，以找出影像中行人所在的位置。 
 
 
 
 
 
 
 
 
 
Thermal  
Image Sequence
Image 
Segmentation 
RoIs 
Generation
Feature 
Extraction 
AdaBoost 
Detector
Pedestrians 
Location 
AdaBoost 
Training 
Training 
Samples 
Feature 
Extraction
 
圖 4、行人偵測之系統架構圖 
    由於人在行走時會擺動雙手及移動雙腳，因此身體與腳的部分的變化通常較為頻繁且明
顯，而相對於頭的部分，頭部的變化就相對降低許多。因此，我們將頭、身體、及腳三者之間，
依據多數人的高度比例分配其不同的權重值於相似度的計算當中。最後依 Bhattacharyya distance
的公式所求得的值若越大，則表示兩張 RoI 影像重疊部分的比例就越大，也就意味著其相似度
越高。反之，值越小，則表示其相似度越低。 
3.4 身分辨識系統 (子計畫四) 
    身分辨識系統架構如圖5所示。系統的架構主要有受測者身分特徵資料攝取、綜合評判等相
 4.1 人機介面的訊息整合平台 (子計畫一、二) 
    我們設定 5台客戶端機械人每間隔 1秒詢問伺服器進行訊息溝通，一共執行 20 秒，即資料
量為 100 筆資料(每台客戶端機械人 20 筆資料)。當客戶端機器人電量變動時，及位置變動時，
會將變動後之結果透過 ZigBee 及 URAT 介面傳輸資料給 Server 端，Server 端將接收到之資料，
分析資料後，將資料存放至資料庫，再由前端平台讀取資料，將目前各機器人之狀態，顯示在
畫面上。我們模擬 Server 端接收資料，並將資料處理後，存至資料庫(如圖 7 所示)中。圖 8
為將機械人顯示在 google map 的示意圖。 
 
 
圖 7、資料存至資料庫 
 
圖 8、機械人在 google map 上的示意圖 
4.2 自走車移動軌跡與路徑追蹤模擬 (子計畫二) 
    移動軌跡與建構地圖的實驗是在台灣師範大學實驗室外的公共空間進行。自走車向前移
動，一面紀錄自走車本身的移動軌跡(移動軌跡以藍色線做紀錄)，一面經由超音波紀錄下自走
車經過的地圖(紀錄地圖以紅色線做紀錄)，將自走車的移動軌跡與所建構的地圖以 Visual Studio 
OPEN GL 建構出來。圖 9 為測試不同封閉環境之下的實驗結果。圖 9(a)、圖 9 (c)為實驗環境圖。
 我們使用所提出的控制法則(3)去控制系統的橫軸方位追蹤參考訊號 1 sin( )r t= ，縱軸方位追蹤
參考訊號 2 co s( )r t= 。圖 11(a)和圖 11(b)分別顯示出橫軸與縱軸的方位軌跡圖。圖 11(c)為橫
軸與縱軸的路徑追蹤模擬圖。圖 11 的藍色線為軌跡模擬圖，紅色線為期望路徑。 
0    2 4 6 8 10
-2
-1.5
-1
-0.5
0
0.5
1
1.5
2
Time (sec)
U
 (m
)
0    2 4 6 8 10
-2
-1.5
-1
-0.5
0
0.5
1
1.5
2
Time (sec)
V
 (m
)
 
                         (a)                             (b) 
-2 -1.5 -1 -0.5 0 0.5 1 1.5 2
-1.5
-1
-0.5
0
0.5
1
1.5
U (m)
V
 (m
)
 
(c) 
圖11、橫軸與縱軸的路徑追蹤模擬圖 
 
4.3 熱感影像之行人偵測 (子計畫四、五) 
    本實驗經由先使用Otsu's 做二值化影像，經由 Closing 運算做雜訊去除，Opening 運算做破
碎區域填滿，再使用 ROI 濾除非行人區域，所得影像結果如圖12(a)。圖12(a)顯示之框架是經
由 HOG feature 演算法所得。在圖12(a)(c)(e)(f)中，我們可看出所框選的區域，主要在身體
與腳的部分，由於人在行走時會擺動雙手及移動雙腳，因此身體與腳的部分的變化通常較為頻
繁且明顯；接著再以 Bhattacharyya distance 將頭、身體、及腳三者之間，依據多數人的高度比
例分配其不同的權重值於相似度的計算來顯示完整的框架，如圖12(b)(d)(f)(h)所顯示。我們
依照行人間不同的距離做偵測，較遠顯示結果為圖12(c)(d)，兩位行人距離較近如圖12(e)(f)
所示，兩位行人相同距離顯示結果如圖12(g)(h)所示。由實驗結果可知，本偵測系統所使用的
HOG feature 可成功偵測行人位置。 
 將無法警告機器人與監控人員，學生或是學校的安全將暴露在一個危險的環境中。但是熱像儀
的影像卻可以在一片漆黑的環境中凸顯人體的位置，幫助機器人與監控人員做偵測與後續處理。 
 
A 
B
B 
A 
 
 
B AA B
 
(a)                                     (b) 
圖 13、遠端監控校園其日間與傍晚的情形 
 
4.4 身分辨識系統 (子計畫四) 
    結合身份宣告進行切割鼻孔以下部分再切半圓的比對，則比對的結果將進一步獲得提升，
詳如表1。表1中屬於N的結果全部去除。由N的錯誤轉為U的錯誤的數量減為4個，總辨識率提升
為92%。表2是將表1的比對結果，藉由系列的放寬門檻值，觀察比對結果的預期改善情形。當門
檻放寬10%後，編號1-2、5-4、9-1、10-3所有的四個比對結果都獲得通過，因此辨識率提升到
100%，然而這是在理想與穩定的實驗室環境所達成的性能。 
 
表1、結合身份宣告進行切割鼻孔以下部分再切半圓的比對結果 
編號 數值 改善後 原本 改善後
1-2 1.04 1.04 U U 
5-2 0.10 0.27 N P 
5-4 1.07 1.07 U U 
9-1 0.56 1.08 N U 
10-3 1.03 1.09 N U 
 
表2、將表1經門檻值放寬的比對結果 
編號 10% 20% 30% 40% 50% 
1-2 P P P P P 
5-4 P P P P P 
9-1 P P P P P 
10-3 P P P P P 
 
 [6] R. Zurawski and M. C. Zhou, “Petri Nets and Industrial Applications: A Tutorial,” IEEE 
Transactions on Industrial Electronics, Vol. 4, No. 6, pp. 567-583, 1994. 
[7] http://wiki.daimi.au.dk/cpntools/cpntools.wiki, Computer Tool for Coloured Petri Nets 
[8] 張進榮，應用模糊理論及彩色派翠網路於配電系統負載預測之研究，國立高雄應用科技大
學電能與控制工程研究所碩士論文，民國 94 年。 
[9] R. Zhu, C. Shi, and X. Yang, “A New Petri Net Model and Stability Analysis of Fuzzy Control 
System,” IEEE International Conference on Networking, Sensing and Control, March 26-29, 
2009. 
[10] http://googlemapsapi.blogspot.com/ 
[11] M. Akhloufi and A. Bendada, “Thermal Faceprint: A new thermal face signature extraction for 
infrared face recognition”, IEEE Canadian Conference on Computer and Robot Vision, pp. 
269-272, 2008. 
[12] S.-Y. Cho, L. Wang, and W. J. Ong, “Thermal Imprint Feature Analysis for Face Recognition,” 
IEEE International Symposium on Industrial Electronics, pp. 1875-1880, July 2009. 
[13] J. H., S. G. Kong, B. R. Abidi and M. A. Abidi, “Fusion of Visual and Thermal Signatures with 
Eyeglass Removal for Robust Face Recognition,” IEEE Computer Society Conference on 
Computer Vision and Pattern Recognition Workshops, pp. 122-122, 2004. 
[14] D. A. Socolinsky and A. Selinger, “Thermal Face Recognition in an Operational Scenario,” IEEE 
Computer Society Conference on Computer Vision and Pattern Recognition, Vol. 2, pp. II-1012 - 
II-1019, 2004. 
[15] J.-G. Wang, E. Sung and R. Venkateswarlu, “Registration of Infra-red and Visible-spectrum 
Imagery for Face Recognition,” IEEE International Conference on Automatic Face and Gesture 
Recognition, pp. 638-644, 2004. 
[16] S. Munder, C. Schnörr, and D. M. Gavrila, “Pedestrian detection and tracking using a mixture of 
view-based shape–texture models,” IEEE Transactions on Intelligent Transportation Systes, Vol. 
9, No. 2, pp. 333-343, Jun. 2008. 
[17] F. H Seitner, and B. C Lovell, “Pedestrian tracking based on colour and spatial information,” in 
Proc.Digital Image Computing Techniques and Applications, Dec. 06-08, 2005. 
[18] J. Park, Y. Luo, H. Wang, and Y. L. Murphey, “Pedestrian detection by modeling local convex 
shape features,” in Proc. International Conference on  Pattern Recognition,  pp. 1-4, Dec. 8-11, 
2008. 
[19] Y. T. Hsu, J.W. Hsieh, H. F. Kao, and H.Y. Mark Liao, “Human behavior analysis using 
deformable triangulations,” in Proc. IEEE Workshop on Multimedia Signal Processing, pp. 1-4,  
Oct. 30-Nov. 2, 2005. 
[20] J. Hsieh, S. Y. Chen, C. H. Chuang, Y. S. Chen, Z. Y. Guo, and K. C. Fan, “Pedestrian 
segmentation using deformable triangulation and kernel density estimation,” in Proc. 
International Conference on  Machine Learning and Cybernetic, Vol. 6, pp.3270-3274, July 
12-15, 2009. 
國科會補助計畫衍生研發成果推廣資料表
日期:2011/12/06
國科會補助計畫
計畫名稱: 總計畫：夜視型自主式群組校園巡邏機器人之研究
計畫主持人: 王偉彥
計畫編號: 99-2221-E-003-022- 學門領域: 智慧型控制
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
第一年有初步成果尚未發表 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
