 1
 
行政院國家科學委員會補助專題研究計畫 □期中進度報告 ■期末報告 
 
視障者資訊輔具計畫—應用場景符號與文字辨識技術 
提供視障者獨自行進之指引 
 
計畫類別：■個別型計畫   □整合型計畫 
計畫編號：NSC 100 – 2221 – E – 212 – 002 – 
執行期間：100 年 08 月 01 日 至 101 年 07 月 31 日 
 
執行機構及系所：大葉大學 資訊管理學系 
 
計畫主持人：曾逸鴻 
共同主持人：林清同 
計畫參與人員：石乃碩、謝明遠、陳政廷、宋光凱、洪杰宏、洪源鍵、陳柏翰 
 
 
 
 
本計畫除繳交成果報告外，另須繳交以下出國報告： 
□赴國外移地研究心得報告 
□赴大陸地區移地研究心得報告 
□出席國際學術會議心得報告及發表之論文 
□國際合作研究計畫國外研究報告 
 
 
處理方式：除列管計畫及下列情形者外，得立即公開查詢 
            ■涉及專利或其他智慧財產權，■一年□二年後可公開查詢 
 
中   華   民   國    100    年    10    月    26    日 
 1
二、 報告內容 
甲、 前言 
人類的種種感官都在提供訊息，但所有接收到的感官訊息都仰賴「視覺」來確認；因
此，當人們喪失視覺的時候，往往對其他感官所提供的訊息容易產生懷疑，並進而造成個
人自信心的喪失。視障朋友們(尤其是兩眼全盲者)長期處於黑暗的世界中，無法以視覺來體
認世界，必須依靠聽覺、觸覺、嗅覺等剩餘感官，來感受他們所生存的空間。由於缺乏影
像的資訊，使他們一旦面臨外在環境以及障礙空間的挑戰，其危險性比一般正常人高出數
百倍；此外，因為長久處於不確定的環境，使得視障者通常缺乏安全威，導致日常生活適
應能力較為不足。因此，視障者對安全性的需求特別強烈，特別是生活行動上的安全，任
何輔助器材的設計都必須以安全為第一考量；同時，對於其他感官與行動能力正常的視障
者而言，往往有強烈的獨力行進之欲望，希望可透過簡易之輔助器材，在陌生的環境中自
由行進至特定地點，這也是產學研各界針對視障者關懷所注重並強化研發的重點。 
乙、 研究目的 
採用白手杖或雙手探索，通常是視障者獨自行進時，為求避免碰撞或跌落危險的輔助
方式；然而，白手杖或探索方式並無法對所欲前往的地點，提供任何明確的指引功能。至
於使用導盲犬，雖可提供特定地點的指引，但往往限於事先學習過的熟悉環境，指引方式
也僅能透過視障者自行感觸控制繩的牽引或鬆緊程度。對於較陌生之環境，或者尚未學習
過的地點，即使透過導盲犬的協助，視障者仍無法隨心所欲的獨自移動至特定地點。 
對於有強烈獨力行進欲望之全盲視障者而言，他們渴望可以實現獨力行進之地點，通
常是在危險程度較低的建築物室內環境，或者像校園、公園、社區等人車分道的室外環境。
對於陌生的建築物室內環境，視障者也希望可以像明眼人一樣，「看到」相關路標符號或標
示文字，獲得必要的指引資訊，以協助他們建立此環境的心理地圖，並依據指引配合輔助
工具(白手杖或導盲犬)，自行獨力地行進至特定地點。 
電腦視覺(computer vision)是一門如何使機器像明眼人一樣，可「看」到景物，進而瞭
解「眼前」環境特性的研究領域。首先，利用影像或視訊擷取設備(如相機、攝影機)代替眼
睛的功能，拍攝並擷取畫面影像後，透過影像分析(image analysis)與圖形識別(pattern 
recognition)技術，進行特定物體或特定事件的判定，以提供決策者所需的各種資訊。由於
可利用電腦視覺技術提供的資訊進行判斷，決策者並不必非得「眼見為憑」；此時的決策者
就如同視障者一般，雖無法親眼所見，但可連同其他各式資訊以及經驗，做出正確的決策。
本研究的目的，就是透過開發電腦視覺領域中的場景標示符號與文字辨識(scene sign/text 
recognition)技術，進而應用於視障資訊輔具，以協助視障者欲在陌生的建築物室內環境中
 3
方式，使視障者可透過理解環境標示指引資訊，以主動找尋路徑方式，安全且獨力行進至
特定地點。至於如何指引視障者前進方面，經常採用的方式是「點鐘方位」資訊；點鐘方
位是以視障者的所處方位為基準(當作是鐘面的中心點)，將周圍環境事物利用鐘點方位的原
則(正前方是12點鐘，而背側即是6點鐘位置，以此類推，將環境區分成12個區域)，讓視障
者做環境認識的動作。 
視訊監控(video surveillance)技術之開發與應用，近年來受到不少研究單位的關注，並
在相關領域期刊發表了一些視訊監控研究的概括論述文章(survey paper) [1-4]。概略來說，
視訊監控技術可分成幾個主題：移動物體偵測(moving object detection)、追蹤(tracking)、物
件分類(object classification)、人類動作分析(human motion analysis)與行為理解(behavior 
understanding)等。這些主題牽涉到不同的專長領域，包括電腦視覺(computer vision)、樣型
分析(pattern analysis)、與人工智慧(artificial intelligence)等。綜合視訊監控對移動物體處理
相關技術的研究領域，可大概分成三大類：偵測與追蹤、動作分析、以及行為理解。其中，
移動物體的偵測與追蹤是視訊監控系統的基礎，因此有不少的研究著重在如何從視訊畫面
中偵測出前景物體並進行追蹤。前景物體的偵測技術，可約略分成三種方法：背景相減法
(background subtraction)、時間差異法(temporal differencing)、以及光流分析法(optical flow 
analysis)。背景相減法[5]會將目前畫面與事先訓練的背景模型做影像相減，利用各位置之
像素色彩差異值，來判定哪些為前景像素點，再組合成前景物體。由於此種方式需要建構
背景模型，較適合用在背景變動不大的穩定環境中。而時間差異法[6]則將兩張連續畫面之
間的相異點，視為可能的前景像素點，過濾掉鬼影像素(ghost pixels)後，即可利用剩餘之前
景像素組成物體。此種方法並不需事先訓練，適合使用在背景變動頻繁的環境中。所謂的
光流(optical flow)，即是當一張畫面平順地轉變成另一張畫面時，各像素點在兩張畫面產生
的速度場(velocity field)。利用光流分析法[7]來偵測前景物體，就是將兩連續畫面中移動不
一致的像素視為前景點，再組合成前景物體。此種方法的計算較複雜、速度較慢，較適合
用在追蹤單一移動物體上。本研究即是參考應用於機器人或自動車之導引系統以及部分運
用在視障者行動指引之相關技術[8]，推動後續之相關技術開發。 
針對視訊畫面中的場景符號(scene sign)判定部分，絕大多數的研究均著重在道路標示
符號(road traffic sign)之偵測與辨識。常見的方法是利用符號圖形與背景標示板的顏色或亮
度差異明顯的特性，先找出各色彩區間的邊緣點，再透過符號圖形的外型特性，做標示符
號的判定[9-12]；欲分辨不同形狀標示牌中的不同符號圖形，Support Vector Machines(SVMs)
則是常被使用的方法[13, 14]。除了考量色彩變異與邊緣特性，同時也考慮人類辨識物體的
處理方式，建立一套計算模式，分成感官的(sensory)、知覺的(perceptual)和概念的(conceptual)
三大分析步驟，也可應用於道路標示之辨識[15, 16]。有的研究特別針對偏向視角拍攝之畫
 5
理(位置判定、擷取、特徵抽取與辨識)、標示符號辨識結果之指引資訊轉換為語音呈現等。
此外，本研究也以文件影像之光學文字辨識(OCR)技術為基礎，擴大應用範圍至視訊畫面
中特定標示文字之搜尋、辨識與理解，處理常見之標示板上同時具有地點圖形符號與指引
文字的情形，可提供更完整、更準確的指引資訊給欲獨力前往該地點之視障人士。 
 
 
本計畫模擬全盲視障者在大型館舍建築物內部自行獨力行走，透過配戴於腰間、具視
圖 2. 視障者配戴資訊輔具之模擬情境 
圖 3. 本研究之主要系統流程 
語音訊息與聲響頻率提示 
偏角標示牌之定位
標示符號 
特徵資料庫
視訊畫面擷取
實際應用 
偏角符號影像之
特徵訓練學習
標示文字 
特徵資料庫 
語音片段與 
聲響資料庫 
偏角文字影像之 
特徵訓練學習 
畫面影像對比強化
標示符號與文字之指引資訊整合
偏角符號 
影像資料庫 
偏角文字 
影像資料庫 
特定標示文字之辨識 
特定標示符號之偵測 
標示符號之指引訊息理解 標示文字之指引資訊轉換
特定標示符號之判定 
標示文字之擷取 
 7
之後，即可設定左上、右上與左下的座標位置，利用此三點做為變形後平行四邊形的端點，
將原影像進行變形的處理。如此一來，可透過此工具程式，模擬各種可能的拍攝角度造成
的影像傾斜變形(如圖 7 所示)；只要收集夠多、不同傾斜角度的變形影像，即可用以訓練並
學習不同角度偏斜影像之外形特徵。 
 
 
本研究開發之主系統畫面如圖 8 所示，左上方看到的是目前所拍攝到移動方向前方之
畫面影像，右上方則是開放給使用者選定之目標圖樣，右下方則是開放給使用者設定的目
標字串，左下方則是系統欲提供給使用者之訊息，並同時以語音或聲響方式呈現。本研究
開發系統的應用場景，乃是視障者可請明眼人(親人或朋友)事先透過本系統(如圖 9 所
示)，協助其設定特定地點的標示圖形群組(如廁所、電梯、飲水機等)，或者是設定該特定
地點的標示文字群組(如圖 10 所示)。當視障者在陌生建築物行走時，若需前往特定地點
時，即可透過腰間配戴的資訊輔具，選取該地點群組，系統即可自動帶入事先設定該地點
群組的所有標示圖形當作目標圖樣，並自動帶入該群組的所有標示文字當作目標字串，針
對輸入之視訊畫面，本系統即可自動判定是否存在目標圖樣或目標字串，並依據標的位置
與指引資訊，轉化為語音或聲響資訊提供給視障使用者，協助其獨力前往該地點。 
圖 6. 本研究開發之影像變形工具 
圖 7. 利用影像變形技術，模擬不同偏角之圖形與文字 
 9
戊、 結果與討論 
本研究主要開發與實驗時所使用的電腦設備為 Intel Core i7-3610QM CPU 2.3GHZ、8G 
RAM、Windows 7 64-bits OS，而開發軟體為 Microsoft Visual Studio 2010，使用的程式語言
為 C#，攝影設備為 Sony DCR-DVD803 DVD 攝影機，331 萬像素鏡頭，實驗環境為大型建
築物(大學校園館舍)之走廊空間。實驗影片模擬視障者欲行進前往四個特定地點(廁所、電
梯、飲水機、公共電話)，以模擬情境的方式分別在四棟不同館舍拍攝並錄製視訊檔案，模
擬者以眼罩遮避雙眼行走，再以攝影機掛置腰間，拍攝模擬畫面如圖 11。 
 
欲測試本系統之指引效果，本研究另邀請四位視覺正常、已認識多數中文字之國小四
年級學生，分別觀看對其仍屬陌生環境之大學館舍所拍之視訊檔案，並記錄其何時(第幾張
畫面時)注意到標示符號圖形或文字，並了解該標示之指引含義，用以與本系統之指引資訊
做比對。測試之項目包括指引資訊之正確與否，指引反應之即時性。此外，再邀請兩位全
盲視障同學傾聽本系統提供之指引語音訊息，請其描繪出心理地圖，再與實際欲前往該目
的地之路徑做比對，以評估其誤差程度。配合實驗需求，本研究總共拍攝 16 段影片，每段
影片的長度約為 3~5 分鐘；拍攝者因以眼罩遮蔽雙眼以模擬視障者行進，移動速度約在 5~10 
km/hr 之間，拍攝過程並以明眼人從旁指導方式，引導視障模擬者前進至目標地點。本系統
以每秒鐘擷取三張畫面之速度進行標示圖形與文字識別，並分成兩階段進行測試；第一階
段分別記錄畫面中特定標示圖形或標示文字的識別效果，第二階段則測試引導訊息對視障
者的指引成效。 
在第一階段測試中，針對各實驗場景之視訊檔案，先透過工具程式每秒鐘擷取出三張
畫面，並以人工方面在每張畫面標示出夠大且夠清楚的目標圖樣或目標字串出現之位置，
建立真實正確資料(ground truth)，做為比較基準；然後，本系統設定特定地點之目標圖樣與
目標字串，並向參與實驗的小四同學說明每個圖樣與字串之代表涵義後，即分別記錄系統
從連續畫面中判定出目標圖樣與目標字串之畫面編號，對照組之四位小四學生亦透過目視
連續畫面，再點選辨認出目標圖樣或字串之畫面，分別記錄畫面編號之差異度，實驗結果
圖 11. 本研究之實驗模擬方式 
 11
己、 結論 
本研究模擬視障者透過配戴於腰間之輔具設備，以向上 45 度之角度持續拍攝畫面，針
對釘貼於牆壁或垂掛於天花板、原本用於提醒並引導明眼人之標示符號圖形或標示文字，
進行偵測、判定、辨識與理解之相關技術開發，並將理解所得的之指引資訊，以語音或聲
響方式告知視障者欲行進至特定地點之移動方向，協助其建立心理地圖。 
本研究開發之系統，在訓練與學習階段，先對各種常見地點的各角度標示符號影像收
集、分類與特徵訓練、對相同地點之不同圖形符號之自訂管理功能、標示圖形符號意義之
整理與歸納、相關語音呈現之事先錄製等；而在測試使用階段，則進行視訊畫面的前處理、
畫面影像中特定標示符號之處理(位置判定、擷取、特徵抽取與辨識)、標示符號辨識結果之
指引資訊轉換為語音呈現等。此外，本研究也以文件影像之光學文字辨識(OCR)技術為基
礎，擴大應用範圍至視訊畫面中特定標示文字之搜尋、辨識與理解，處理常見之標示板上
同時具有地點圖形符號與指引文字的情形，可提供更完整、更準確的指引資訊給欲獨力前
往該地點之視障人士。 
三、 參考文獻 
1. L. Wang, W. Hu, and T. Tan, “Recent developments in human motion analysis,” Pattern 
Recognition, 36, 585-601, 2003. 
2. W. Hu, T. Tan, L. Wang, and S. Maybank, “A survey on visual surveillance of object motion 
and behaviors,” IEEE Transactions on Systems, Man, and Cybernetics-Part C: Applications 
and Reviews, 34, 334-352, 2004. 
3. S. D. Roy, S. Chaudhury, and S. Banerjee, “Active recognition through next view planning: A 
survey,” Pattern Recognition, 37, 429-446, 2004. 
4. T. B. Moeslund, A. Hilton, and V. Kruger, “A survey of advances in vision-based human 
motion capture and analysis,” Computer Vision and Image Understanding, 104, 90-126, 2006. 
5. L. Li, W. Huang, I. Y. H. Gu, and Q. Tian, “Statistical modeling of complex backgrounds for 
foreground object detection,” IEEE Transactions on Image Processing, 13, 1459-1472, 2004. 
6. F. H. Cheng and Y. L. Chen, “Real time multiple objects tracking and identification based on 
discrete wavelet transform,” Pattern Recognition, 39, 1126-1139, 2006. 
7. M. Tagliasacchi, “A genetic algorithm for optical flow estimation,” Image and Vision 
Computing, 25, 141-147, 2007. 
8. I. Ulrich and J. Borenstein, “The GuideCane - Applying mobile robot technologies to assist the 
visually impaired,” IEEE Transactions on Systems, Man, and Cybernetics-Part A: Systems and 
Humans, 31(2), 131-136, 2001. 
9. R. Marmo and L. Lombardi, “Road bridge sign detection and classification,” In: Proceedings 
of Intelligent Transportation Systems Conference, 823-826, 2006. 
10. L. W. Tsai, J. W. Hsieh, C. H. Chuang, Y. J. Tseng, K. C. Fan, and C. C. Lee, “Road sign 
detection using eigen colour,” IET Computer Vision, 2, 164-177, 2008. 
11. I. Landesa-Vázquez, F. Parada-Loira, and J. L. Alba-Castro, “Fast real-time multiclass traffic 
 13
27. Q. Ye, J. Jiao, J. Huang, and H. Yu, “Text detection and restoration in natural scene images,” 
Journal of Visual Communication & Image Representation, 18, 504-513, 2007. 
四、 計畫成果自評 
本研究計畫原本希望執行兩年之持續研究，經審查後僅核可一年；還是利用有限的時
間與經費，由主持人與數位參與之研究生合作開發相關技術。茲將原計畫書之兩年研究規
劃的主要成果預估與實際達成狀況，表列於表 2；本研究計畫相關之成果發表，條列於表 3。 
表 2. 計畫執行情形表 
計畫書中預計
完成工作項目 實際執行內容 達成率 學術或應用價值 
畫面影像對
比強化 
 利用整張畫面之亮度分布統
計 ， 進 行 分 布 圖 均 等 化
(histogram equalization)，強化整
張畫面之對比。 
 針對已偵測出的可能標示牌，在
進行後續標示圖案辨識之前，再
針對畫面中標示牌區域，進行第
二次亮度分布圖均等化，再次強
化影像之對比。 
100%
 透過兩階段之亮度分
布圖均等化，可做到畫
面影像之層次式對比
強化效果。 
偏角標示牌
之定位 
 利用標示牌之矩形外觀，即使是
偏角拍攝，亦是四邊形之外觀特
性。 
 先利用邊緣點偵測，再透過霍夫
轉換找到可能的線段，並分析各
線段之交點特性，用以定位出符
合條件的標示牌。 
100%
 利用邊緣點連結成線
段，並用以組成四邊
形，判定出標示牌位
置，可提升偏角拍攝下
的標示牌定位效果。 
偏角符號影
像之特徵訓
練學習 
 開發利用變動邊界位置之影像
變形工具，可自動模擬各種偏角
的影像，快速地建立完整偏角符
號影像資料庫。 
 不同標示圖形之顏色與外型特
性不同，在訓練學習階段，顏色
特性可利用人工設定，而外型特
性則可利用以模擬出的各種偏
角符號影像，進行外型統計特徵
的自動訓練。 
100%
 搭配影像變形工具，可
快速地符號各種偏角
的符號影像，並進行外
觀統計特徵，可讓偏角
符號影像之特徵訓練
學習更加方便。 
特定標示符
號之偵測與
判定 
 依據以建立之各種標示符號之
顏色特性與外型特徵向量，可快
速地以顏色特性進行特定標示
符號之過濾，並利用該標示符號
100%
 利用兩階段式比對，並
將偵測與判定過程合
一，可提高特定標示符
號判定之效果。 
國科會補助計畫衍生研發成果推廣資料表
日期:2012/10/26
國科會補助計畫
計畫名稱: 視障者資訊輔具計畫:應用場景符號與文字辨識技術提供視障者獨自行進之指
引
計畫主持人: 曾逸鴻
計畫編號: 100-2221-E-212-002- 學門領域: 殘障輔具研究
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
