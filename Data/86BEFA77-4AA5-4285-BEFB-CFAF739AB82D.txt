???????????????????????????????????
???????????????????????????? 
Privacy protection has become one of the most important issues in the information era. 
Consequently, many protocols have been developed to achieve the goal of 
accomplishing a computational task cooperatively without revealing the participants' 
private data. Practical protocols, however, do not guarantee perfect privacy protection, 
as some degree of privacy leakage is allowed so that resources can be used efficiently, 
e.g., the number of random bits required and the computation time. A metric for 
measuring the degree of information leakage based on an information theoretical 
framework was proposed in \cite{cwlh}. Based on that formal framework, we present 
a lower bound of the scalar product problem in this paper, and show that to solve the 
problem without the help of a third party, approximately half the private information 
must be revealed. To better capture our intuition about the secrecy of various 
protocols, we propose two more measurements: evenness and spread. The first 
measures how evenly the information leakage is distributed among the participants' 
private inputs. The second measures the size of the smallest set an adversary could 
use to obtain the same ratio of leaked information that could be derived in the worst 
case scenario. 
???????????? evenness ?? pread?????????????
?????? evenness?????????????????????????
?????????????? spread??????????????????
?????????????????????????????? parties??
???????????????????????????????????
???????????????????????????????????
????? 
1 Introduction
Privacy protection is one of the most pressing issues in the information era.
The massive databases spread over the Internet are gold mines for some
and, at the same time, one of the greatest threats to privacy for others.
How to accomplish a computational task cooperatively without revealing
the participants’ private inputs has therefore gained a great deal of attention
in recent years and the development of efficient solutions is now an active
research area. In theory [11, 7], it is possible to securely compute almost
any function without revealing anything, except the output. Unfortunately,
the theoretical results are not readily applicable to real applications due to
their high computational complexity.
Most theoretical approaches adopt a computationally indistinguishable
view of secrecy and try to find provable secure solutions, but such a definition
leaves little room to quantify secrecy. Meanwhile, in application-oriented
studies, researchers usually take an intuitive approach to the definition of
secrecy and try to argue for the secrecy of protocols by refuting possible
attacks. There is a gap between these two approaches in terms of prov-
able secrecy. Although, privacy is a basic human right, it is not the only
one. When multi-party private computation is applied in the public sector,
sometimes privacy must be compromised in order to accommodate other
important social values. The computation can also be applied in the private
sector, such as in a business setting. For example, two (or more) companies
might want to compute a function cooperatively; however, neither of them
wants to share their private information. In both public and private sector
applications, it would be beneficial to be able to quantify secrecy so that
a tradeoff could be made, for example, between secrecy and computational
efficiency. In [5], similar arguments are presented about ideal secrecy and ac-
ceptable secrecy. Meanwhile in [2], an information theoretical framework is
proposed and two quantitative definitions of secrecy for multi-party private
computation are defined, namely, relative secrecy and absolute secrecy. In
this paper, we prove a lower bound for the relative secrecy of protocols that
solve scalar product problems. We also propose two refined measurements,
evenness and spread, for quantifying information leakage by multiparty pri-
vate computation protocols.
The remainder of this paper is organized as follows. We give a short
review of related works in Section 2. In Section 3, we present the formal
framework proposed in [2]. In Section 4, we present our lower bound proof.
In Section 5, we present our extension of the formal framework, and use
three examples to explain our new measurements. Finally, in Section 6, we
2
3 Framework
As our lower bound proof is based on the formal framework in [2], we in-
clude a brief introduction to the framework here. In multi-party private
computation, n players cooperate to compute a function. Each player holds
some private input that is part of the parameters for computing the func-
tion. The goal is to compute the function and maintain the secrecy of each
party’s private input. Given a protocol, P , we use XPi to denote the pri-
vate input of party i, and msgPi to denote the message received by party
i. We use information theory to model the amount of information revealed
after running P . Note that before running P , none of the parties has any
information about the other parties’ private inputs. However, after run-
ning P , each party may know something about some of the other parties’
private inputs because of new information gathered during the execution
of P . Let HPi = H(X
P
i ) denote the entropy of the random variable X
P
i ,
and HPij = H(X
P
i |msgPj ) denote the entropy of the random variable XPi
given msgPj . The conditional entropy corresponds to the intuitive idea of
the amount of information (uncertainty) of XPi from party j’s perspective
after receiving msgPj .
Two measurements, relative secrecy and absolute secrecy, of the secrecy
of protocol P are defined as mini,j(HPij/H
P
i ) and mini,j(H
P
ij ) respectively.
4 Lower Bound
In this section we show that for any two party scalar product protocol, the
relative secrecy can not be better than 12 . Without loss of generality, let
us assume that the protocol proceeds in rounds, where Alice and Bob send
messages to each other alternately, with Alice sending the first message.
We can record the communication between Alice and Bob as a sequence
of messages, msg = (msgA1 ,msg
B
2 , . . .). Given a message sequence msg,
we say that an input sequence X of Alice(Bob) is compatible with msg if
it is a possible record of the communication when the input sequence of
Alice(Bob) is X. We use IA(msg)(IB(msg)) to denote the set of input
sequences, that are compatible with msg, for Alice(Bob). Note that msg is
a possible record of the communication when Alice’s input is in IA(msg) and
Bob’s in IB(msg). We use IA,B(msg) to denote {(X,Y )|X ∈ IA(msg), Y ∈
IB(msg)}. The set IA(msg)(IB(nsg)) can be further partitioned into two
subsets according to the output value u(v). We use IA,u(msg)(IB,v(msg))
to denote the set of input sequences compatible with msg and the final
4
1A contains every vector in I ′ and 1A, we derive that there are at least
|I ′| + |1A| ≥ 2k1 − 1 vectors in this space. Therefore, dim(1A) ≥ k1.
Hence, by dim(1A) + dim(1B) ≤ n and dim(1A) + dim(0B) ≤ n + 1, we
get dim(1B) ≤ n − k1 and dim(0B) ≤ n − k1 + 1. There are at most
2n−k1+1 vectors in the vector space spanned by 0B. However, half the
vectors in this space are not in 0B, so we get |0B| ≤ 2n−k1 ; therefore,
|IB(msg)| = |0B| + |1B| ≤ 2n−k1+1. If H(XB|msg) ≥ k2, then by Fact 1,
|IB(msg)| ≥ 2k2 . Now we have 2k2 ≤ |IB(msg)| ≤ 2n−k1+1. Thus, we get
k1 + k2 ≤ n+ 1 and the following lemma and theorem.
Lemma 1 For any two-party scalar product protocol P , if H(XA|msg) ≥ k1
and H(XB|msg) ≥ k2, then k1 + k2 ≤ n+ 1.
SinceH(XA) = H(XB) = n, we getH(XA|msg)/H(HA)+H(XB|nsg)/H(XB) ≤
1 + 1/n. The relative secrecy of the protocol is
min(
H(XA|msg)
H(XA)
,
H(XB|msg)
H(XB)
) ≤ 1
2
+
1
n
.
Theorem 1 For any two-party scalar product protocol, the relative secrecy
is at most 12 +Ω(
1
n).
5 Extension of the formal framework and exam-
ples
Although the two metrics, relative secrecy and absolute secrecy, capture the
amount of information revealed by a protocol, they fail to distinguish intu-
itively apparent differences between various protocols. For example, many
two-party scalar product protocols have a relative secrecy of 12 , but, it is ob-
vious that a protocol that allows Alice and Bob to send half of their respec-
tive inputs to each other is not acceptable. We try to capture the intuition
by extending the definition of the secrecy metrics. First we introduce the
concept of evenness to overcome the drawback of the above-mentioned mea-
surements, which only capture a global view of information leakage. Now
consider two protocols, each with relative secrecy 12 . In the first protocol, the
amount of information leakage only reaches 12 when all the input elements
are considered. In the other protocol, however, the information leakage
reaches 12 when only a single input element is considered. Clearly, the first
protocol is better than the second. We introduce the concept of spread to
capture the intuition that the first protocol is better. Before we formally
6
the evenness of this protocol is 12 . Thus one party has full information of
half the private input elements. In addition, the fact that the spread is equal
to one makes the situation even worse.
For the second protocol, we use the Chinese Remainder theorem to en-
code each element of the input vectors with the same base. Specifically, we
pick two consecutive integers, p1, p2, such that p1p2 > p and encode each
number x as (x mod p1, x mod p2). Thus,XA = ((x11, x12), . . . , (xn1, xn2))
and XB = ((y11, y12), . . . , (yn1, yn2)). Alice then sends the first coordinate
of her private input, (x11, x21, . . . , xn1), to Bob and Bob sends the second
coordinate of his private input, (y12, y22, . . . , yn2), to Alice. Alice com-
putes a =
∑n
i=1 xi2yi2 mod p2, and set u = p1p
−1
1 a; and Bob computes
b =
∑n
i=1 xi1yi1 mod p1, and set v = p1p
−1
1 b, where p1p
−1
1 = 1 mod p2 and
p2p
−1
2 = 1 mod p1. It is easy to see that the relative secrecy of the protocol
is again 12 , but this time the evenness is 0, since half of the information
of each private input element is revealed to the other party. However, the
spread of the protocol is 1; for example, once Bob gets x11 the information
about x1 is reduced to about 12 .
The third protocol [5] operates as follows. First Alice and Bob agree to
an n ∗n invertible matrix M and a positive integer k that is not larger than
n. The rest of the protocol comprises the following steps:
Alice Bob
1. Compute X ′A = XA ∗M . Compute X ′B = (M−1 ∗XTB)T .
Let X ′A = [xA1 , . . . , xAn ], Let X
′
B = [xB1 , . . . , xBn ],
X¯A = [xA1 , . . . , xAk ], X¯B = [xB1 , . . . , xBk ],
X
¯A
=[xAk+1 , . . . , xAn ] X¯B
= [xBk+1 , . . . , xBn ]
2. Alice
X¯A−→ Bob
Alice
X
¯B←− Bob
3. u = X
¯A
∗X
¯
T
B v = X¯A ∗ X¯TB
In this protocol, M is an n by n invertible matrix. Without loss of
generality, let S = {xA1 , xA2 , ..., xAr} and T = {xAr+1 , ..., xAn}. H(S) =
r ∗ log p. Let msg = {msg1,msg2, ...,msgn}. We have the following linear
system of equations from Bob’s perspective:
a11 ∗ xA1 + a12 ∗ xA2 + · · ·+ a1r ∗ xAr + · · ·+ a1n ∗ xAn = msg1
a21 ∗ xA1 + a22 ∗ xA2 + · · ·+ a2r ∗ xAr + · · ·+ a2n ∗ xAn = msg2
...............
ak1 ∗ xA1 + ak2 ∗ xA2 + · · ·+ akr ∗ xAr + · · ·+ akn ∗ xAn = msgk
H(S, T |msg) = (n − k) log p. Moreover, H(S, T |msg) = H(S|msg) +
H(T |S,msg) = H(S|msg) + maxS{(n − r − k), 0} ∗ log p. If r ≤ n − k,
8
[3] W. Du and M. J. Atallah. Privacy-preserving cooperative statistical
analysis. In Proceedings of the 17th Annual Computer Security Ap-
plications Conference, pages 102–110, New Orleans, Louisiana, USA,
December 2001.
[4] W. Du and M. J. Atallah. Secure multi-party computation problems
and their applications: A review and open problems. In New Secu-
rity Paradigms Workshop, pages 11–20, Cloudcroft, New Mexico, USA,
September 2001.
[5] W. Du and Z. Zhan. A practical approach to solve secure multi-
party computation problems. In Proceedings of New Security Paradigms
Workshop, Virginia Beach, Virginia, USA, September 2002.
[6] O. Goldreich. Foundations of Cryptography Volume II Basic Aplica-
tions. Cambridge, 2004.
[7] O. Goldreich, S. Micali, and A. Wigderson. How to play any mental
game, or: A completeness theorem for protocols with honest majority.
In Proc. 19th ACM Symposium on Theory of Computing, pages 218–
229, 1987.
[8] M. Kantarcoglu and C. Clifton. Privacy-preserving distributed mining
of association rules on horizontally partitioned data. IEEE Transactions
on Knowledge and Data Engineering, 16(9):1026–1037, 2004.
[9] Dahlia Malkhi, Noam Nisan, Benny Pinkas, and Yaron Sella. Fairplay
— a secure two-party computation system. In Proceedings of the 13th
Symposium on Security, Usenix, pages 287–302, 2004.
[10] J. Vaidya and C. Clifton. Privacy preserving association rule mining in
vertically partitioned data. In The Eighth ACM SIGKDD International
Conference on Knowledge Discovery and Data Mining, pages 639–644,
July 2002.
[11] A. C. Yao. How to generate and exchange secrets. In Proceedings of the
27rd Annual IEEE Symposium on Foundations of Computer Science,
pages 162–167, November 1986.
10
????????????????????????????? 
 
???????????????????????????????????
???????????????????????????????????
???????????????????????? 
 
???????????????????????????????????
???????????????????????????????????
???????????????????????????????? 
 
 
2 D.W. Wang and C.J. Liau and Y.T. Chiang and T.-s. Hsu
1 Introduction
Privacy protection is one of the most pressing issues in the information era. The
massive databases spread over the Internet are gold mines for some and, at the
same time, one of the greatest threats to privacy for others. How to accomplish
a computational task cooperatively without revealing the participants’ private
inputs has therefore gained a great deal of attention in recent years and the
development of efficient solutions is now an active research area. In theory [11,
7], it is possible to securely compute almost any function without revealing
anything, except the output. Unfortunately, the theoretical results are not readily
applicable to real applications due to their high computational complexity.
Most theoretical approaches adopt a computationally indistinguishable view
of secrecy and try to find provable secure solutions, but such a definition leaves
little room to quantify secrecy. Meanwhile, in application-oriented studies, re-
searchers usually take an intuitive approach to the definition of secrecy and try
to argue for the secrecy of protocols by refuting possible attacks. There is a gap
between these two approaches in terms of provable secrecy. Although, privacy is
a basic human right, it is not the only one. When multi-party private compu-
tation is applied in the public sector, sometimes privacy must be compromised
in order to accommodate other important social values. The computation can
also be applied in the private sector, such as in a business setting. For example,
two (or more) companies might want to compute a function cooperatively; how-
ever, neither of them wants to share their private information. In both public
and private sector applications, it would be beneficial to be able to quantify
secrecy so that a tradeoff could be made, for example, between secrecy and com-
putational efficiency. In [5], similar arguments are presented about ideal secrecy
and acceptable secrecy. Meanwhile in [2], an information theoretical framework
is proposed and two quantitative definitions of secrecy for multi-party private
computation are defined, namely, relative secrecy and absolute secrecy. In this
paper, we prove a lower bound for the relative secrecy of protocols that solve
scalar product problems. We also propose two refined measurements, evenness
and spread, for quantifying information leakage by multiparty private computa-
tion protocols.
The remainder of this paper is organized as follows. We give a short review
of related works in Section 2. In Section 3, we present the formal framework
proposed in [2]. In Section 4, we present our lower bound proof. In Section 5,
we present our extension of the formal framework, and use three examples to
explain our new measurements. Finally, in Section 6, we present our conclusions
and a short discussion about possible extensions of our model. We also indicate
the direction of future work.
2 Related Work
Secure two-party computation was first studied by Yao [11] and extended to the
multi-party case by Goldreich et al [7]. Through a sequence of efforts, a satis-
factory definitional treatment was found and precise proofs for the security of
4 D.W. Wang and C.J. Liau and Y.T. Chiang and T.-s. Hsu
Two measurements, relative secrecy and absolute secrecy, of the secrecy of
protocol P are defined as mini,j(HPij/H
P
i ) and mini,j(H
P
ij ) respectively.
4 Lower Bound
In this section we show that for any two party scalar product protocol, the
relative secrecy can not be better than 12 . Without loss of generality, let us
assume that the protocol proceeds in rounds, where Alice and Bob send mes-
sages to each other alternately, with Alice sending the first message. We can
record the communication between Alice and Bob as a sequence of messages,
msg = (msgA1 ,msg
B
2 , . . .). Given a message sequence msg, we say that an in-
put sequence X of Alice(Bob) is compatible with msg if it is a possible record
of the communication when the input sequence of Alice(Bob) is X. We use
IA(msg)(IB(msg)) to denote the set of input sequences, that are compatible
with msg, for Alice(Bob). Note that msg is a possible record of the communica-
tion when Alice’s input is in IA(msg) and Bob’s in IB(msg). We use IA,B(msg)
to denote {(X,Y )|X ∈ IA(msg), Y ∈ IB(msg)}. The set IA(msg)(IB(msg)) can
be further partitioned into two subsets according to the output value u(v). We
use IA,u(msg)(IB,v(msg)) to denote the set of input sequences compatible with
msg and the final outcome. Note that, for allX ∈ IA,u(msg) and Y ∈ IB,v(msg),
XY = u+ v. Here, we consider the case where each number is from GF (2) and
the input vector is n dimensional. A general lower bound can be derived by the
same approach. Below, we present a high-level sketch of the lower bound proof.
If after the execution of the protocol, the information content of the input se-
quence of Alice(Bob) is still high, it means that many input sequences should
be compatible with the recorded conversation. However, a larger IA(msg) would
imply a smaller IB(msg), since each sequence in IB(msg) paired with each se-
quence in IA(msg) has to satisfy the condition that their scalar product is equal
to the sum of their outputs. We therefore derive a lower bound. To formalize
the above sketch, we state some basic facts from information theory and linear
algebra.
Fact 1
Let X be a random source with n possible outcomes, H(X) ≤ log n. In other
words, for a random source to have entropy n, we need at least 2n possible out-
comes.
Fact 2 Let I1, I2 be two sets of n-dimensional binary vectors. We use dim(I1)
to denote the dimension of the subspace spanned by I1.
– If |I1| ≥ 2k, then dim(I1) ≥ k; and if dim(I) ≤ k, then |I| ≤ 2k.
– If I1 and I2 are orthogonal, i.e., the scalar product between every vector in
I1 and I2 is zero, then dim(I1) + dim(I2) ≤ n.
Given a message sequence msg, let 0A = IA,0(msg), 0B = IB,0(msg), 1A =
IA,1(msg), and 1B = IB,1(msg). By Fact 2, we get dim(0A) + dim(0B) ≤ n
6 D.W. Wang and C.J. Liau and Y.T. Chiang and T.-s. Hsu
however, the information leakage reaches 12 when only a single input element is
considered. Clearly, the first protocol is better than the second. We introduce
the concept of spread to capture the intuition that the first protocol is better.
Before we formally define evenness and spread, we introduce some notations.
We present only the two-party case here, and defer the multi-party case to a
full paper. Let us first generalize the definition of HPi and H
P
ij to any subset of
input elements. Let A and B denote the two parties. For player A(the definition
for party B is similar), let XPA = (x1, x2, . . . , xn), and S = {xk1 , xk2 , . . . , xkr} ⊆
{x1, x2, . . . , xn}. We use H(S) to denote H(xk1 , xk2 , . . . , xkr ) and H(S|msg)
to denote H(xk1 , xk2 , . . . , xkr |msg). Define HPA (S) = H(S) and HPAB(S) =
H(S|msgPB). Let rA = r = minS{H(S|msg
P
B)
H(S) }, rgA = H(X
P
A |msgPB)
H(XPA )
, and ηA =
rgA − rA. In the above definitions, rA is the minimum ratio between the infor-
mation of any subset of the secret input before and after the execution of the
protocol, rgA is the ratio for the whole input. It is reasonable to replace rgA
by rA; however, we feel it is more informative to define evenness to be ηA, and
interpret it as the measurement of the evenness of information leakage about
player A. When ηA equals zero, it means that player A’s input is leaked evenly.
We define the spread for player A as min{|S| : {H(S|msgPB)H(S) } = rA}; that is, the
minimum number of input elements required to reach the maximum information
leakage level. An ideal protocol should have relative secrecy as close to one as
possible, evenness of every player as close to zero as possible, and spread of every
player as large as possible. We use three two-party scalar product protocols to
demonstrate the concept of evenness and spread. In the two-party scalar product
problem, the two parties, Alice and Bob, have private input XA and XB(two n
dimensional vectors), respectively. A solution to this problem is a protocol that,
after running, enables Alice and Bob to correctly compute the numbers u and v
respectively, such that u+ v is the inner product of XA and XB , i.e., XA ·XB .
Let ∗ be the matrix product operator, and XTB be the transpose of XB . Then,
u + v = XA · XB = XA ∗ XTB . Hereafter, we assume that XA, XB ∈ GF (p)n,
where GF (p) is a Galois field of order p, and p is a prime number. We also
assume that XA and XB are uniformly distributed and that both parties are
semi-honest, i.e., they both follow the protocol and do not deliberately deviate
from it to get more information. Instead, they only deduce information from the
messages they receive.
Examples
Our first example is a naive protocol whereby Alice sends the first half of her
vector to Bob, and Bob sends the second half of his vector to Alice. It is obvious
that relative secrecy rg = 12 , which matches the best protocol. However, it is
also obvious that this is not a very appealing solution, because the evenness of
this protocol is 12 . Thus one party has full information of half the private input
elements. In addition, the fact that the spread is equal to one makes the situation
even worse.
8 D.W. Wang and C.J. Liau and Y.T. Chiang and T.-s. Hsu
product problem by only allowing the two parties to communicate with each
other. Although this seems intuitively straightforward, proving the claim with-
out the help of an information theoretical formalism is non-trivial. Our lower
bound proof not only confirms our intuition, but also demonstrates the advan-
tage of the information theoretical framework. To better capture our intuition,
we also propose refinements and extensions of the measurements of information
leakage for two-party secure computation. We hope that analyzing protocols for-
mally will not only provide solid certification of the secrecy of existing protocols,
but also facilitate the design of better protocols. Using the Chinese Remainder
theorem to design protocols is an interesting approach worthy of further investi-
gation. In this paper, we assume that inputs are uniformly distributed. We feel
it would be a very interesting and challenging task to develop a method that
incorporates players’ a priori information about others players’ private inputs
into the formalism. Finally, and obviously, extending the model to multi-party
situations and analyzing some interesting problems is logically the next step.
7 Acknowledgement
This work was supported in part by the National Science Council under the
Grants NSC94-2213-E-001-004, NSC-94-2422-H-001-0001, and NSC-94-2752-E-
002-005-PAE, and by the Taiwan Information Security Center (TWISC) under
the Grants NSC 94-3114-P-011-001, NSC 94-3114-P-001-001-Y, NSC94-3114-P-
001-002-Y and NSC94-3114-P-001-003-Y.
References
1. M. J. Atallah and W. Du. Secure multi-party computational geometry. Lecture
Notes in Computer Science, 2125:165–179, 2000.
2. Yi-Ting Chiang, Da-Wei Wang, Churn-Jung Liau, and Tsan-sheng Hsu. Secrecy
of two-party secure computation. In Proc. 19th Annual IFIP WG 11.3 Working
Conference on Data and Applications Security,Lecture Notes in Computer Science,
Vol. 3654, Jajodia, Sushil; Wijesekera, Duminda (Eds.), pages 114–123, 2005.
3. W. Du and M. J. Atallah. Privacy-preserving cooperative statistical analysis. In
Proceedings of the 17th Annual Computer Security Applications Conference, pages
102–110, New Orleans, Louisiana, USA, December 2001.
4. W. Du and M. J. Atallah. Secure multi-party computation problems and their
applications: A review and open problems. In New Security Paradigms Workshop,
pages 11–20, Cloudcroft, New Mexico, USA, September 2001.
5. W. Du and Z. Zhan. A practical approach to solve secure multi-party computation
problems. In Proceedings of New Security Paradigms Workshop, Virginia Beach,
Virginia, USA, September 2002.
6. O. Goldreich. Foundations of Cryptography Volume II Basic Aplications. Cam-
bridge, 2004.
7. O. Goldreich, S. Micali, and A. Wigderson. How to play any mental game, or:
A completeness theorem for protocols with honest majority. In Proc. 19th ACM
Symposium on Theory of Computing, pages 218–229, 1987.
