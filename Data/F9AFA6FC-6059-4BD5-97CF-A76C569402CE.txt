 1
行政院國家科學委員會補助專題研究計畫成果報告 
※※※※※※※※※※※※※※※※※※※※※※※※※※ 
※                         ※ 
※       以核心函數為基之支持向量分類器及其應用（1/3）      ※ 
※                         ※ 
※※※※※※※※※※※※※※※※※※※※※※※※※※ 
 
計畫類別：個別型計畫   
計畫編號：NSC-95-2221-E-007-181-MY3 
執行期間：95 年 8 月 1 日至 96 年 7 月 31 日 
 
計畫主持人：蘇朝墩 
 
 
 
 
 
 
 
 
 
 
本成果報告包括以下應繳交之附件： 
□赴國外出差或研習心得報告一份 
□赴大陸地區出差或研習心得報告一份 
□出席國際學術會議心得報告及發表之論文各一份 
□國際合作研究計畫國外研究報告書一份 
 
 
 
執行單位：國立清華大學工業工程與工程管理學系 
 
 
中 華 民 國 九 十 六 年 五 月 二 十 日 
 3
which depends on the VC dimension, which 
characterizes the complexity of the 
approximating function class (Vapnik, 1998; 
Pardo and Sberveglieri, 2005). 
However, not all of the cases are linear 
and separable for classification. In fact data 
that is both vague and overlapping is 
common in many cases. Thus, many 
interactions occur, particularly at the input 
spaces. Based on available studies (Oyang et 
al., 2005; Scholkopf et al., 1995), it seems 
that the original SVM did not perform well 
for these cases. In order to solve this problem, 
mathematicians provided related kernel 
functions to deal with nonlinear classification 
problems on the basis of the above 
limitations (Muller et al., 2001). There are 
several types of kernels being used for all 
kinds of problems. Each kernel may be 
suitable for some of the problems. For 
instance, some well-known special problems, 
such as text classification (Joachims, 2000) 
and DNA problems (Yeang et al., 2001) are 
reported to be classified more correctly using 
the linear kernel. 
Although the approach of the SVM with 
kernel function is useful for classification, its 
performance must be improved, especially 
for complex data. This is particularly 
important for people who want to obtain a 
high level of accuracy in advanced areas 
such as precision engineering and medical 
diagnosis. Therefore, this first-year study 
proposed a simple approach using combined 
kernels for data classification. We attempted 
to increase the classification performance 
using our proposed combined kernels. 
 
三、結果與討論 
 
Implementation 
Two kernels including polynomial and 
RBF kernels are employed in this study to 
develop new kernels. In order to simplify the 
tasks of the classification process, some 
parameters are ignored. These two equations, 
polynomial ( pk ) and RBF ( Gk ) kernels, are 
rewritten as follows: 
d
iiPk )(),( xxxx ⋅=  
)
2
1(),( 2xxexpxx −γ−= iiGk  
Consequently, the kernel function GPk +  
is defined as, 
⎟⎟⎠
⎞
⎜⎜⎝
⎛ −γ−+⋅=+ )2
1()(),( 2xxexpxxxx i
d
iiGPk  
and kernel function GPk ⋅  is defined as. 
⎟⎟⎠
⎞
⎜⎜⎝
⎛ −γ−⋅=⋅ )2
1(.)(),( 2xxexpxxxx i
d
iiGPk  
As a result, the SVM decision functions 
using the new kernels, GPk +  and GPk ⋅ , can 
be rewritten as: 
( ) ⎟⎟⎠
⎞
⎜⎜⎝
⎛ +α= ∑
=
+
sM
i
iGPii bkysignf
1
),( xxx  
( ) ⎟⎟⎠
⎞
⎜⎜⎝
⎛ +α= ∑
=
⋅
sM
i
iGPii bkysignf
1
),( xxx  
We can prove that the combined kernels 
are symmetric and satisfied with the 
characterization of Mercer’s Theorem.  
 
Comparisons 
In order to validate the effectiveness of 
our proposed method, four approaches 
including two popular kernels (polynomial 
and RBF), and two proposed kernels 
(polynomial plus RBF and polynomial 
multiplies RBF) were implemented for the 
classification tasks. We use the 
one-against-all procedure to calculate the 
accuracy of classification in the multi-class 
SVM model, else the general procedure is 
employed to acquire that.  
A total of 12 datasets are selected and 
showed in Table 1. The items 1 to 3 are from 
a memorial hospital; the others are from UCI 
data set (Blake and Merz, 1998) 
        Table 1. The data 
No Data set # of 
samples 
# of 
features 
# of 
classes
1 Hyperlipidemia 6000 33 2 
2 Liver disease 6000 33 2 
3 Renal disease 6000 33 2 
4 Census income 32561 14 2 
5 Shuttle* 14500 9 7 
6 Mushroom 8124 22 2 
7 Letter 15000 16 26 
8 Sonar 208 60 2 
9 Ionosphere 351 34 2 
10 Vehicle 
silhouettes 
846 18 4 
11 Spambase 4601 57 2 
12 Vowel 990 13 11 
 
Table 2 compares the accuracy of the 
classification with the larger and smaller data 
 5
including original and combined ones with 
SVM. A total of nine datasets from UCI and 
three diseases datasets from a hospital are 
employed to illustrate these classifiers. From 
this investigation, we found the performance 
of the combined kernel GPk ⋅  has the better 
performance. The combined kernels have 
shown that they are feasible for classification. 
In addition, this study also provides a 
guideline on parameters setting. The 
guideline is useful for classification on SVM 
modeling. However, the parameters setting 
approach are still based on an exhaustive 
procedure. Hence, the determination of the 
parameters setting and problem solving with 
real case on SVM modeling are worth 
investigating in future study. 
Parts of above research results have 
been accepted for publication in Expert 
Systems with Applications (SCI). 
 
五、參考文獻 
 
[1] Cortes, C. and Vapnik, V., 
Support-vector networks, Machine 
learning, 20(3), 273-297, 1995. 
[2] Blake C. L. and Merz, C. J., UCI 
repository of machine learning databases, 
Dept. Infor. Comput. Sci., Univ. 
California, Irvine, CA, 1998. 
[3] Joachims, T., The Maximum-Margin 
Approach to Learning Text Classifiers: 
Methods, Theory, and Algorithms. PhD 
thesis, Universitaet Dortmund, 2000. 
[4] LeCun, Y., Jackel, L. D., Bottou, L., 
Brunot, A., Cortes, C., Denker, J. S., 
Drucker, H., Guyon, I., Muller, U. A., 
Sackinger, E., Simard, P. and Vapnik, V., 
Comparison of learning algorithms for 
handwritten digit recognition, 
International Conference on Artificial 
Neural Networks, Fogelman, F. and 
Gallinari, P. (Ed.), 53-60, 1995. 
[5] Muller, K. R., Mika, S., Ratsch, G., 
Tsuda, K. and Scholkopf, B., An 
introduction to kernel-based learning 
algorithms, IEEE Transactions on Neural 
Networks, 12(2), 181-201, 2001. 
[6] Osuna E., Freund, R. and Girosi, F., 
Training support vector machines: an 
application to face detection, Proc. 
Computer Vision and Pattern 
Recognition ’97, 130-136, 1997. 
[7] Oyang, Y. J., Hwang, S. C., Ou, Y. Y., 
Chen, C. Y. and Chen, Z. W., Data 
classification with radial basis function 
networks based on a novel kernel density 
estimation algorithm, IEEE Transactions 
on Neural Networks, 16(1), 225-236, 
2005. 
[8] Pardo, M. and Sberveglieri G.., 
Classification of electronic nose data 
with support vector machines, Sensors 
and Actuators B, 107, 730-737, 2005. 
[9] Schmidt, M., Identifying Speakers with 
Support Vector Networks, in Interface ’96 
Proceedings, Sydney, 1996. 
[10] Scholkopf, B., Burges, C. J. C. and 
Smola, A. J., Extracting support data for 
a given task. In U.M. Fayyad and R. 
Uthursamy, editors, Proceedings, First 
International Conference on Knowledge 
Discovery and Data mining, Menlo Park, 
1995. AAAI Press. 
[11] Scholkopf, B., Support Vector Learning, 
PhD Theiss, R. Oldenbourg Verlag, 
Munich, 1997. 
[12] Vapnik, V., The Nature of Statistical 
Learning Theory, Springer-Verlag, New 
York, 1995. 
[13] Yeang, C. H., Ramaswamy, S., Tamayo, 
P., Mukherjee, S., Rifkin, R.M., Angelo, 
M., Reich, M., Lander, E., Mesirov, J. 
and Golub, T., Molecular classification of 
multiple tumor types, Bioinformatics: 
Discovery Note, 1(1), 1-7, 2001. 
 
 
 
 2
行政院國家科學委員會專題研究計畫成果報告 
以核心函數為基之支持向量分類器及其應用（2/3） 
Kernel-Based SVM: Theory and Application 
計畫編號：NSC-95-2221-E-007-181-MY3 
執行期限：96 年 8 月 1 日至 97 年 7 月 31 日 
主持人：蘇朝墩    國立清華大學工業工程與工程管理學系 
計畫參與人員：陳昆皇、林鴻鈞、林依祈、方振宇、張原瑞、王芳芳 
              國立清華大學工業工程與工程管理學系 
 
一、中文摘要 
 
支持向量分類器除了可以用在兩種類
別的分類作業之外，亦可用以進行特徵選
取。支持向量分類器的特徵選取方法不外
乎是以 Wrappers 或是以 Filters 為基礎的程
序，而這些方法常受限於不易使用、計算
時間長、複雜度高等缺點。因此，本計畫(第
二年)將以第一年所發展的支持向量分類
器與Hermes和Buhmman(2000)所提的特徵
選取方法作結合，建構一特徵選取程序。
研究結果顯示，透過此一程序的特徵選取
作業有利於分類績效的改善。 
 
關鍵詞：支持向量分類器、核心函數、特
徵選取、Wrappers、Filters。 
 
Abstract 
In addition to classification, the support 
vector machine (SVM) has the strong 
function for feature selection. The feature 
selection method for SVM is always based 
on the procedures of Wrappers or Filters. 
However, the procedures often limited to 
some disadvantages, such as more 
computation, high complexity and difficult to 
used. In this second-year project, we hope to 
investigate the feature selection problem of 
our proposed method developed in the first 
year. We will apply Hermes and Buhmann’s 
(2000) idea to our method. The result showed 
that the proposed method has a better 
performance for feature selection. 
 
Keywords: Support vector machine; Kernel 
function; Feature selection; 
Wrappers; Filters. 
 
二、緣由與目的 
 
Features are called attributes, properties, 
variables, or characteristics. Feature selection 
is a process by which a sample in the 
measurement space is described by a finite 
and usually smaller set of numbers classed 
features, say nxxx ,......,, 21 . The features 
become components of the pattern space. The 
feature selection is regarded as a procedure 
to determine that which variables (attributes) 
are to be measured first or last. Liu and 
Montoda (1998) defined that feature 
selection is a process that chooses an optimal 
subset of features according to certain 
criterion. In other words, feature selection 
may be multistage process to enhance the 
accuracy or performance of classification. 
The universal algorithms of feature 
selection are often divided along three lines: 
wrappers, filters and embedded (Kohavi and 
John, 1997; Guyon and Elisseeff, 2003). 
Both wrappers and filters do this work by 
select subsets of variables. Wrappers 
approach is one of the subset selection 
methods. It assesses subsets of variables 
according to their usefulness to a given 
predictor. The filters approach is a 
preprocessing step, independent of the choice 
of the predictor. Still, under certain 
dependence or orthogonality assumptions, it 
may be optimal with respect to a give 
predictor. Obviously, an exhaustive search 
can conceivably be performed, if the number 
of variables is not too large. But, the problem 
is known to be NP-hard (Amaldi and Kann, 
1998) and the search becomes quickly 
computationally intractable. They may suffer 
 4
Implementation 
Four kernels, including polynomial, and 
RBF polynomial plus RBF( GPk + ) and 
polynomial multiplies RBF( GPk ⋅ ) were 
implemented for the classification tasks. A 
total of 12 datasets are selected and as 
showed in the following table. The items 1 to 
3 are from a memorial hospital; the others are 
from UCI data set (Blake and Merz, 1998) 
 
           The data 
No Data set # of 
samples 
# of 
features 
# of 
classes
1 Hyperlipidemia 6000 33 2 
2 Liver disease 6000 33 2 
3 Renal disease 6000 33 2 
4 Census income 32561 14 2 
5 Shuttle* 14500 9 7 
6 Mushroom 8124 22 2 
7 Letter 15000 16 26 
8 Sonar 208 60 2 
9 Ionosphere 351 34 2 
10 Vehicle 
silhouettes 
846 18 4 
11 Spambase 4601 57 2 
12 Vowel 990 13 11 
 
The implementation results of feature 
selection are showed in Tables 1 and 2. In 
this procedure, the kernels were applied to 
L-J method for feature selection. The optimal 
parameter settings were employed in SVM 
model for L-J feature selection. The average 
accuracies of the classification for the seven 
larger data sets and five smaller data sets are 
shown in Tables 1 and 2. Their standard 
deviations are listed in the brackets.  
These two tables indicated that the 
combined kernel GPk ⋅  has better 
performance than the other approaches. After 
feature selection (from 75% to 25%), the 
kernel GPk ⋅  also showed a better 
performance both in larger and smaller data. 
In the larger data, the combined kernel GPk +  
showed a better performance than the 
polynomial and RBF kernel. The result in the 
smaller data was the same as that in the 
larger one. Furthermore, the kernel GPk ⋅  
almost had the lowest standard deviation 
among the four approaches in the larger data. 
In the smaller data set, the kernel GPk ⋅  
performed well. 
 
 
 
 
 6
Academic, 1998. 
[10] Torkkola, K., Feature extraction by 
non-parametric mutual information 
maximization, Journal of Machine 
Learning Research, 3, 1415-1438, 2003. 
[11] Weston, J., Elisseff, A., Schoelkopf, B. 
and Tipping, M., Use of the zero norm 
with linear models and kernel methods, 
Journal of Machine Learning Research, 3, 
1439-1461, 2003. 
 
 
 
 
 2
行政院國家科學委員會專題研究計畫成果報告 
以核心函數為基之支持向量分類器及其應用（3/3） 
Kernel-Based SVM: Theory and Application 
計畫編號：NSC-95-2221-E-007-181-MY3 
執行期限：97 年 8 月 1 日至 98 年 7 月 31 日 
主持人：蘇朝墩    國立清華大學工業工程與工程管理學系 
計畫參與人員：蕭宇翔、陳昆煌、 陳衍成、林鴻鈞 
              國立清華大學工業工程與工程管理學系 
 
一、中文摘要 
 
 
高血壓是一種慢性病，也是人類主要
死因。在臨床上，有許多環境與生理的流
行病學因子會影響或導致高血壓，然而，
過多的因子除了不易解釋之外，在收集資
料上也相當耗時及昂貴。近年來，許多研
究開始討論新陳代謝症候群與體型之間的
關係，事實上，該議題仍面臨於特徵項目
過多而不易解釋的限制。在先前的計畫
中，我們發現，以核心函數為基礎的支持
向量分類器，和支持向量分類器與 Hermes
和 Buhmman(2000)所提的特徵選取方法作
結合，有不錯的分類績效及特徵選取結
果。因此，本計畫(第三年)將使用先前所發
展的方法進行高血壓檢測的特徵選取，並
與數個資料探勘工具（包含倒傳遞類神經
網路、決策樹、羅吉斯迴歸、粗略集合）
的特徵選取結果加以比較，並利用流行病
學因子加以評估，結果顯示本計畫提出之
方法較其他方法為佳。 
 
關鍵詞：支持向量分類器、核心函數、特
徵選取、高血壓、檢測。 
 
Abstract 
Hypertension is one of the major 
diseases leading to death all over the world. 
In clinical practice, many epidemiological 
variables including environmental and 
physical factors could affect the disease. 
However, too many variables are not easy to 
collect, i.e. it is a time-consuming and 
expensive work. Recently, the relationship 
between anthropometric factors and 
metabolic syndrome is investigated more and 
more exact in the biomedicine studies. In fact, 
the issue still faces too many features to 
explain the relationships. In the previous 
projects, we obtain the better performance by 
applying Hermes and Buhmann’s (2000) idea 
to the support vector machine with combined 
kernels. Hence, in this third-year project, we 
implement a feature selection procedure to 
explore the significant anthropometric factors 
that will affect the hypertension. The relevant 
approaches including Back Propagation 
Neural Network, Rough Sets, and Decision 
Tree are executed for the comparison 
purpose based on some epidemiological 
indices. The result shows that the 
performance of our proposed feature 
selection procedure is better than the other 
approaches. 
 
Keywords: Support vector machine; Kernel 
function; Feature selection; 
Hypertension; Detection. 
 
二、緣由與目的 
 
Hypertension is a major disease and is a 
significant cause of death all over the world. 
The relevant researches show that the 
cardiovascular disease is an important risk 
causing hypertension (Mykkanen et al., 1997; 
Jeppesen et al., 2000). As defined by the 
National High Blood Pressure Education 
Program (NHPEP), hypertension can be 
summarized as shown in Table 1. 
 
 4
waist circumference, right thigh 
circumference, left thigh circumference, right 
leg circumference, left leg circumference, 
breast width, hip width, volume of trunk, 
surface area of trunk, volume of left arm, 
volume of right arm and volume of right leg. 
All of the feature selection approaches 
are assessed by the epidemiology based 
indices, namely, sensitivity and specificity. 
In addition, accuracy was employed to 
evaluate their performance. There are 13 and 
14 features selected by the implemented 
approaches. As shown in table 2, we found 
that the neural network based model is the 
worst in terms of the three indices among the 
various approaches. We also found that the 
sensitivity was decreased and the specificity 
was increased in SVM based approaches. 
Furthermore, the accuracy of SVM based 
model is better than those of the neural 
network based, decision tree and rough sets 
approaches. In addition, although the results 
showed that the decision tree and rough sets 
is better on sensitivity, the SVM based 
methods have the fewer decreased range after 
feature selection. Hence, we consider that the 
SVM based method has the advantage of 
optimization computation and prevails over 
all other methods. 
 
 
 
 
四、計劃成果自評 
 
The aim of this study is to investigate 
the relationship between anthropometrical 
factors and hypertension. In addition, some 
significant anthropometrical factors are 
selected by our approaches. After the feature 
selection, the common anthropometric 
factors including waist circumference, right 
thigh circumference, left thigh circumference, 
volume of trunk, surface area of trunk and 
volume of right arm were collected by these 
methods. 
As similar to other studies previously 
conducted, our study considered waist 
circumference as a predictor of hypertension 
(Lin et al., 2002; Wang, 2003). Moreover, as 
for thigh circumference, the accumulation of 
fat, especially viscera fat was noted to result 
in a wider thigh circumference. For adults, 
the fat usually disperses uniformly to viscera 
and subcutaneous tissue. Erwin et al. (2000) 
consider that the subcutaneous adipose tissue 
in people with syndrome X, especially in the 
lower trunk is greater than healthy people. 
Furthermore, they indicate that the visceral 
fat is a risk factor for syndrome X and infer 
to hypertension. However, we obtained a 
crude index when we based on indices BMI 
and WHR. It is relatively easy to do, even 
though advanced medical techniques such as 
computer topography (CT) and magnetic 
resonance imaging (MRI) are available to 
evaluate visceral fat. These techniques 
however are much too expensive for 
screening all patients, and it could reduce the 
wish to be examined for hypertension for 
some patients. Thus, hypertension detection 
via a simple and accurate approach is worthy 
of performing. Summary of this study, 3D 
whole body scanner is useful for 
anthropometrics collection; our proposed 
combined kernel is good at the performance 
of hypertension detection. 
Parts of above research results have 
been accepted for publication in the 37th 
International Conference on Computers and 
Industrial Engineering. 
  
行政院國家科學委員會 
補助國內專家學者出席國際學術會議報告 
 
 
 
 
計畫名稱：以核心函數為基之支持向量分類器及其應用 
計畫編號：95-2221-E-007-181-MY3 
執行期限：2006.08.01. ~ 2009.07.31. 
核定之出席國際會議費用：90,000 元 
 
 
 
 
蘇朝墩 
清華大學工業工程與工程管理系 
Pressure Ulcers Prediction Using Support Vector 
Machines
Yan-Cheng Chen 
National Tsing Hua University Department of Industry 
Engineering and Engineering Management 
Hsinchu, Taiwan 
d9534818@oz.nthu.edu.tw 
Pa-Chun Wang, MD, MSc 
Department of Otolaryngology, Cathay General 
Hospital, Fu Jen Catholic University School of 
Medicine 
Taipei, Taiwan 
drtony@tpts4.seed.net.tw 
Chao-Ton Su 
National Tsing Hua University Department of Industry  
Engineering and Engineering Management 
Hsinchu, Taiwan 
ctsu@mx.nthu.edu.tw 
Abstract—Surgical patients are usually at high risk of developing 
pressure ulcers after their operation. Usually, the pressure ulcers 
data sets are imbalanced. Therefore, this study aims to examine 
the real medical case of pressure ulcers with the use of Support 
Vector Machines (SVMs). SVMs are used for forecasting and are 
a type of classification techniques. We utilize the measurement of 
sensitivity and specificity to compare the performances of SVMs 
with several classification techniques. The results indicated that 
SVMs performed better than the other classifiers for pressure 
ulcers prediction. In addition, the classifier of SVMs is a robust 
and powerful approach when facing the different ratios of 
training data sets. 
Keywords- Support vector machines, imbalanced data, 
classification, Data mining. 
I. INTRODUCTION
Support vector machines (SVMs) were proposed by 
Vapnik and co-workers [1] and were a set of related machine 
learning methods used for classification problem. SVMs had 
shown significant classification results successfully in many 
practical applications, from microarray gene profiling [2], 
handwriting digit recognition, to text classification. SVMs also 
work very well with high-dimensional data sets and avoid the 
dimensionality problem [3]. The aim of SVMs is to minimize 
classification error through maximizing the margin between 
the separating hyperplane and the data sets. Therefore, unlike 
the studies made extensively on the classification problem in 
data mining, a special property of SVMs is that they 
simultaneously minimize the empirical classification error and 
maximize the geometric margin. A comparison of SVMs to 
other classifiers has been made by Meyer [16], and the results 
indicated that SVMs showed mostly good performances both 
on classification and regression tasks, but other methods 
proved to be very competitive. However, it was found that 
application areas have many skewed data sets with the rarest 
number of positive instances, especially in disease diagnosis, 
credit rating, and so on. The influence of imbalance data sets 
on a predictive model or classifier will cause bias in the 
classification accuracy ratio. Furthermore, imbalanced 
problems always occur to high predictive values over a 
majority class, but poor values over a minority class. 
Recent studies have suggested that two main directions 
coped with the problems of imbalanced data sets [9]. 
Preprocessing the data via under-sampling majority class or 
oversampling minority class is treated as the first approach. 
The oversampling and under-sampling techniques for skewed 
or imbalanced data sets had been studied by several 
researchers [4], [5], [6]. The goal of the second approach is to 
make the learned hyperplane be placed further away from the 
positive class. To avoid the hyperplane from being closer to 
positive instances, Gang [7] proposed to adjust the class 
boundary by modifying the kernel matrix according to 
imbalanced data distribution. The bias will be produced 
between the original kernel matrix and conformal 
transformation kernel matrix. Veropoulos [8] suggested 
controlling the trade-off between false positives and false 
negatives with SVMs. 
We choose SVMs to attack the problem of imbalanced data 
set in the medical field because they have strong theoretical 
foundations [1], and empirical results show that they perform 
well with moderately imbalanced data even without any 
modifications [9]. The study aims to use SVMs to predict the 
classification accuracy rates of pressure ulcers. A pressure 
ulcer is an area of localized damage to the skin and underlying 
tissue caused by pressure, shear, friction, and/or a combination 
of these. Finally, a real case about the incidence of pressure 
ulcers after surgical operation was studied. 
978-1-4244-2108-4/08/$25.00  © 2008 IEEE

ܟ
ԡܟԡଶ
ʹ
൅ ܥሺ෍ߦ௜
ே
௜ୀଵ
ሻ 
ݕ௜ሺܟ ȉ Ȱሺܠ࢏ሻ ൅ ܾሻ ൒ ͳ െ ߦ௜ǡ ͳ ൑  ൑ ܰ 
 
 
(10.) 
where C refers to user-specified parameters representing the 
penalty of misclassified training sample and can be chosen 
based on the model’s performance on the validation set. When 
the optimal parameters of w and b are found, we classify 
according to the sign ofሺܟ ȉ Ȱሺܠ࢏ሻ ൅ ܾሻ.
III. CASE STUDY
A. Case Description 
The case studied here comes from a hospital in Taiwan. In 
healthcare, pressure ulcers are a serious problem. Therefore, 
most hospitals have developed a strategy for pressure ulcers 
prevention and management. Doctors want to understand the 
reasons for patients’ pressure ulcers after surgical operation as 
well as reduce the incidence of pressure ulcers. Surgical 
patients are at high risk of developing pressure ulcers because 
of their fixed position during surgical procedures and low 
resistances. However, pressure ulcer has now been established 
as a quality indicator on the hospital level and results to 
pressure ulcer prevalence and prevention. Hence, it is 
important to construct a predictive model for pressure ulcers. 
The data set of pressure ulcers includes 14 attributes after 
data preprocessing and are labeled as gender, age, weight, 
course, anesthesia, prone position, skin point, beg temp, temp 
range, end temp, time, air, knife, and skin status. For example, 
the prone position refers to the patient’s body position on the 
surgical table during the operation, which may be lying, left, 
right, and other positions. 
In this case study, the data were sampled randomly and 
split into training and testing data sets. The data set of pressure 
ulcers was collected from 168 patients consisting of 8 positive 
examples and 160 negative examples.  
B. Performance Metric 
In order to measure the performance of the medical data 
set, the concepts sensitivity and specificity are often used by 
several researchers [2], [8] for the evaluation of binary 
classifier. Sensitivity is defined as the proportion of true 
positives of all positive instances in the data set, whereas 
specificity is the proportion of true negatives of all negative 
instances. The formulations of sensitivity and specificity are as 
follows: Sensitivity = (true positives)/(true positives +false 
negatives); Specificity =(true negatives)/(true negatives +false 
negatives). High sensitivity is required when early diagnosis 
and treatment are advantageous, and when the disease is 
infectious, whereas high specificity is important when the 
treatment or diagnosis is harmful to the patient mentally. 
Kubat and Matwin [13] suggested the g-means metric that is 
applied as the evaluating classifier on the imbalanced data sets 
by some researchers [7], [9], [14]. The g-means metric is 
defined as 
 ൌ ඥ ȉ ϐ (11.) 
The overall accuracy is the ratio between the number of 
correctly identified examples and the size of testing data sets z.
In this study, four indexes of sensitivity, specificity, overall 
accuracy, and g-means are used to measure the performance of 
classification techniques. 
C. Pressure Ulcers Prediction 
Four techniques, SVMs, logistic regression, decision tree 
(C4.5), and Naïve Bayes (NB), were employed to predict 
pressure ulcers. The performance comparisons of these four 
classifiers were based on the three-fold cross validation 
approach. Radial basis kernel function of the form ሺܠǡ ܠᇱሻ ൌ
ିԡܠି୷ԡమ ଶ஢మΤ is used for SVMs. The number of support vectors 
is 20 and b is 3.2627. Then, the classifier can be written as 
follows: 
ࢌሺܢሻ ൌ ݏ݅݃݊ሺܟ ȉ Ȱሺܢሻ ൅ ܾሻ.
Ifࢌሺܢሻ ൌ ͳ, the test example is classified as positive class; 
otherwise, it is classified as negative class. The results of the 
comparisons among the four classifiers are given in Table 2.  
TABLE I. COMPARISON OF TEST RESULTS ON THE PRESSURE ULCERS 
DATA SET (FOLD=3) 
Index SVMs Logistic C4.5 NB 
Sensitivity 0.5 0.25 0.375 0.5 
Specificity 1 0.981 0.981 0.969 
g-means 0.707 0.495 0.6065 0.6960 
Overall  0.97619 0.94643 0.95238 0.9464 
Table I shows the test results on the pressure ulcers data set. 
The results indicated that SVMs performed better than the 
other methods. The four classifiers had good performance on 
the specificity metric, but were worse on sensitivity. SVMs 
still have better value of g-means and overall accuracy than 
the other classifiers even with the imbalanced data sets with 
the rarest number of positive instances. 
D. Evaluation 
In this section, we want to evaluate the performance of the 
four classifiers when facing different ratios of training and 
testing data sets, especially in the rarest positive example with 
low ratio of training data sets. We split training and testing 
data sets randomly into three different ratios, which are 1 to 1, 
3 to 1, and 1 to 3 (that is, experiments 1, 2, 3). Three different 
degrees of training and testing data sets are designed for 
evaluating the performance of classifiers. Each classifier of 
experiments was repeated 10 times, and the values of the 
indexes were averaged. The results are provided in Table II. 
Experimental results show that SVMs performed better on 
g-means and overall accuracy than the other methods. It is 
obviously indicated that SVMs had better performance under 
the different ratios of training and testing data sets. In the ratio 
3:1 or 1:3, C4.5, and NB were influenced by the different 
ratios of training data sets more easily than SVMs and logistic 
regression because they had poor values of g-means and were 
978-1-4244-2108-4/08/$25.00  © 2008 IEEE
 1
Combining Neural Networks and Genetic Algorithms 
for Optimizing the Parameter Design of Inter-Metal 
Dielectric Layer 
 
Chia-Jen Chou 
Department of Industry Engineering and Engineering 
Management, National Tsing Hua University 
Hsinchu, Taiwan 
Johnson.iem89g@nctu.edu.tw 
Fong-Jung Yu 
Department of Industrial Engineering and Technology 
Management, Da Yeh University 
Changhua, Taiwan 
fischer@mail.dyu.edu.tw
Chao-Ton Su 
Department of Industry Engineering and Engineering 
Management, National Tsing Hua University 
Hsinchu, Taiwan 
ctsu@mx.nthu.edu.tw 
 
 
Abstract—Integrated circuits generally involve many layers of 
metallization as semiconductor devices require different 
functions; otherwise, the devices’ density increases. The inter-
metal dielectric (IMD) is deposited between metal layers to 
provide isolated capability to the device and separate the 
different metal layers, which are not necessary in conducting 
electricity. A good isolated capability will help the devices become 
more reliable and stable. The key problem in IMD layer is the 
occurrence of voids, which lead to electric leakage and cause 
wafer scrape. To overcome the void problem in the IMD process 
is difficult due to its complicated input-response relationship. In 
this study, the authors combined neural networks, genetic 
algorithms (GAs), and desirability function to optimize the IMD 
process. First, a backpropagation (BP) neural network is 
developed to map the complex non-linear relationship between 
process parameters and corresponding responses. Next, 
desirability function and genetic algorithm are employed to 
obtain the optimum operation parameters with respect to each 
response. The implementation of the proposed approach was 
carried out in a semiconductor manufacturing company in 
Taiwan, and the results illustrated the practicability of the said 
approach.   
Keywords- inter-metal dielectric (IMD), neural networks, 
genetic algorithms, desirability function 
I.  INTRODUCTION 
Integrated circuits are extremely restricted by their ability 
to reliably deposit an interlayer. In order to satisfy varied 
functions of customer requirement, wafer manufacturing need 
more additional metal levels. The multiple levels of metal 
layers make the manufacturing process more difficult and 
result in more defects in the wafer. Therefore, the scaling down 
of devices is directly affecting the performance of the inter-
metal dielectric (IMD) process, which is located between the 
different metal layers in the device. There occur some things 
that are caused by the inadequate capacity of IMD 
manufacturing process. Firstly, voids are generated during 
deposition of high aspect ratio gaps. After chemical mechanical 
polishing (CMP) manufacturing process, some keyhole voids 
become trenches. These trenches result in an open circuit after 
metal deposition and lead to electric leakage. Secondly, the 
incomplete insulating film results in an increase in line 
resistance (R) for signals and produces more parasitic 
capacitance (C). It would incur an increase in the R/C signal 
delay time and make the chips become slower in speed and 
lower in performance. Thirdly, the chemical or gas etches the 
metal layer and scrapes the wafer as the Via shifts to the 
keyhole voids. 
Due to the inadequate knowledge on how to effectively 
analyze the source of variation and resolve the complicated 
input-response relationship, practitioners have difficulty in 
achieving the optimum conditions for the IMD process. 
Therefore, this multivariate operation requires an effective 
intelligent approach to evaluate the process and determine the 
optimum adjustment. The neural networks and genetic 
algorithms (GAs) are two of the most promising soft 
computing intelligence techniques and are widely applied in 
many engineering optimization problems. In recent years, 
neural networks have become a very powerful and practical 
method to model extremely complex non-linear problems 
(Chow et al., 2002; Cook et al. 2000). GAs are also powerful 
parameter optimization methods in various research fields 
(Chakraborti et al., 2006). Many researches indicate that the 
combined neural networks and genetic algorithms perform well 
in obtaining the effective result for resolving the optimization 
problem (Su and Chiang, 2002; Alonso et. al., 2007). Therefore, 
the authors recommend an integrated approach, using neural 
networks and genetic algorithms, to optimize and provide a 
National Science Council 
 3
according to the probability of mutation. Mutation probability 
is usually set fairly low. If it is set too high, the search will 
turn into a primitive random search. 
Khan et al. (1997) had indicated the robustness and 
effective capabilities of GAs search. Hung et al. (2005) and 
Hsu and Su (1998) have demonstrated the ability of GAs to 
address the optimization problem. Some other industrial 
application of GAs can be found in Karr and Freeman (1999). 
More related information could be found in Man and Tang 
(1999). 
C. Desirability function 
The desirability function approach is designed to transform 
a multiple responses problem into a single response one by 
mathematical transformation (Derringer and Suich, 1980). 
This approach uses the desirability functions to transform each 
response iyˆ  into an individual desirability function )ˆ( ii yd , 
that varies over the range 1≤)ˆ(≤0 ii yd . The value of 
)ˆ( ii yd =1 demonstrating a completely desirable or optimum 
end result of )ˆ( ii yd =0 representing an absolute unacceptable. 
Due to a particular response, iyˆ  is to be minimized, 
maximized, or assigned a target value, and a different 
desirability function should be used. The il  and iu  are 
assumed as the lower and upper bounds and it  be the target 
value of the response iyˆ , with iii utl << . The desirability 
function of the “target is best” is computed as follows: 
                   






















ii
iii
t
ii
ii
iii
ii
ii
ii
ii
uy
uy t
ut
uy
ty l
lt
ly
ly  
yd
ˆ                   ,0
   ,ˆ    ,
ˆ
,ˆ     ,
ˆ
,ˆ                 ,0
)ˆ(
s
                 (4) 
where the exponents s and t determine how strictly target 
value is desired and how the user must specify their values. 
Equation (5) denotes the response that is wanted to be 
maximized. 
                   












ii
iii
ii
ii
ii
ii
ty
ty l
lt
ly
ly  
yd
ˆ                   ,1
,ˆ     ,
ˆ
,ˆ                 ,0
)ˆ(
s
                 (5) 
with it  explaining a large enough value for the response. 
Finally, as the response is desired to be minimized, the 
desirability function is shown in Equation (6).  
               












ii
iii
ii
ii
ii
ii
uy
uy t
ut
uy
ty  
yd
ˆ                    ,1
,ˆ     ,
ˆ
,ˆ                   ,0
)ˆ(
s
              (6) 
with it  denoting the small enough value for the response. 
The design variables are chosen to maximize the overall 
desirability value D, which are calculated by the geometric 
mean of the individual response desirability, 
                        mmdddD
1
21 )×××(=                       (7) 
where there are m responses. The maximum of overall 
desirability value D means the individual desirability functions 
are in their best result. 
III. PROPOSED METHODS 
This study proposes to integrate neural networks, genetic 
algorithms and desirability function to optimize the parameter 
settings in IMD manufacturing process. The proposed 
approach consists of three stages. The first stage is defining 
the parameters/responses of IMD process, and designing the 
experiment. The experimental data are collected by the 
experimental design. The second stage involves employing the 
BP network to construct the relationship model between 
parameters and responses. Through the trained network, the 
corresponding response can be obtained by tuning the input 
parameter. Moreover, the desirability function is employed to 
transform the multiple responses into a single response, i.e., 
equations (4)-(7) are used. The objective of the third stage is 
to apply GAs to obtain the optimum degree of satisfaction (λ). 
The fitness function of GAs can be expressed by equation (7). 
The chromosome represents the possible solution, and each 
gene in the chromosome is the value of the input parameter. 
The operators including reproduction, crossover, and mutation 
are conducted to obtain the optimal response. Figure 1 
displays the proposed optimization procedure. The detailed 
steps are summarized as follows: 
Step1: Determine the parameters / responses of IMD process. 
Step2: Collect the required data by using an experimental 
design. 
Step3: Construct the relationship between the responses and 
the parameters through developing the BP neural 
network.  
Step 4: Use the desirability function to transform the multiple 
responses problem into a single one. The trained 
network with a modified single response is regarded as 
a fitness function. 
Step 5: Define the process parameters as a chromosome and 
employ GAs to search the optimal parameter settings. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 5
TABLE I.  RESPONSES AND TARGETS OF THE IMD PROCESS  
Responses Desired target 
Die Defect ( 1y ) 0 (%) 
VRDB ( 2y ) 7.5   ≥ V 
Fluorine contained ( 3y )  5.0±7 (%) 
TABLE II.  PROCESS PARAMETERS AND THEIR LEVELS 
Parameters Levels 1 2 
SRO linear 
Thickness ( 1x ) 650 850 
R/I ( 2x ) 1.65 1.85 
FSG1 
Thickness ( 3x ) 1000 3000 
O2 ( 4x ) 80 90 
SiH4 ( 5x ) 28 38 
SiF4 ( 6x ) 20 30 
Argon ( 7x ) 25 35 
Temperature ( 8x ) 390 450 
C. Neural networks modeling 
BP network is used to construct the nonlinear relationship 
between parameters and responses. It was implemented by 
using Professional II Plus software packages. The thirty-six 
samples (approximately 70%) are used to train the neural 
network and the other eighteen samples (approximately 30%) 
are used for testing the accuracy of the trained network. Table 
III lists several options for the neural network architecture. 
The criteria used to judge the performance of the network was 
based on: (1) minimal RMSE from testing samples, (2) 
minimal RMSE from training samples, and (3) minimal 
discrepancy between RMSEs from training and testing 
samples. Therefore, the structure 8-8-3 is selected to obtain a 
better performance. 
TABLE III.  THE RESULT OF NEURAL NETWORKS 
 RMSE 
Architecture Training  Testing 
8-3-3 0.0875 0.1155 
8-4-3 0.092 0.1144 
8-5-3 0.086 0.1221 
8-6-3 0.0921 0.1114 
8-7-3 0.0914 0.1122 
8-8-3 0.0904 0.1098 
D. Fitness function construction 
By inputting the process parameters into the trained 
network 8-8-3, the values of three responses can be obtained. 
In this case, these three responses have different objectives. 
The response 1y  is desired to be minimized, 2y  is expected to 
be maximized and 3y  has the corresponding target value. 
Herein, the desirability function is used to transform these 
three responses into a single response. The fitness function is 
1/3)××(= 321 dddmax  
where 321=  ,,i,di  is calculated from (4), (5) and (6). Due 
to the responses 3,2,1=  ,ˆ iyi  has the linear relation with 
desirability function; therefore; the values of s and t were set 
equal one. The function λ is set as the fitness function of the 
GAs and the further explored is summarized in the next 
section.  
E. GAs implementation 
When GAs are applied for finding the optimal parameter 
settings of the IMD manufacturing process, the essential 
operators, including reproduction, crossover and mutation 
should be determined in advance. Herein, a roulette wheel 
method is used to select the settings of operators. The 
crossover rate and mutation rate are set as 0.5 and 0.02, 
respectively. Each gene in the chromosome represents the 
values of the eight process parameters. Forty chromosomes are 
randomly generated to establish the initial population. The 
optimum search using GAs converges in 200 generations. The 
GA is executed twenty runs and Table IV illustrated the 
implementation results. The higher value of λ indicated a 
better degree of satisfaction. The largest λ is 0.8994 and the 
optimum chromosome is (691.7, 1.71, 1434, 81.3, 28.56, 20.4, 
31.05, 432.5). These settings are the optimal condition for the 
eight process parameters. 
TABLE IV.  THE RESULT OF GENETIC ALGORITHMS 
Item Fitness value 
The maximum λ value within 20 runs 0.8994 
The minimum λ value within 20 runs 0.7845 
Average λ value 0.8495 
Standard deviation 0.0286 
F. A comparison 
In the past, the process engineers employed the RSM to 
handle a multiresponses problem. They determine the optimal 
parameter settings by overlaying of contour plots along with a 
separate response surface analysis. The optimal parameter 
settings can be obtained as (838.2, 1.84, 2100, 88.5, 28.5, 29.5, 
34, 426.3). 
In order to make a comparison between the proposed 
approach and the RSM, one more lot (24 pieces of wafers) 
was conducted. Table V illustrated the confirmation result. We 
can see that the proposed approach reveals a better 
performance on the three responses. In addition, we employed 
the t tests of the mean values to compare the proposed 
approach with RSM. The statistic of die defect is 1.96 with a 
P-value of 0.028 and the statistic of VRDB is 1.85 with a P-
value of 0.036. These results indicated that the mean values 
for die defect and VRDB by the proposed approach are strong 
significant better than the means value by the RSM approach. 
Based on the proposed approach’s solution, the product yield 
of the C3010 product increased from the average of around 
96% to 97.25% and raise about 1.25%. The annual cost saving 
is expected to exceed about US$ 1.20 million. 
 
 
行政院國家科學委員會補助國內專家學者出席國際學術會議報告 
報告人姓名：蘇朝墩 
服務機構及職稱：清華大學工業工程與工程管理系 教授 
會議時間/地點：2008/10/28 ~ 2008/10/31，泰國(曼谷) 
會議名稱：(中文) 第六屆亞洲品質年會暨研討會 
                    (英文) 2008 ANQ Congress 
發表論文題目：1. Applying Artificial Immune Recognition System to Enhance the Quality of 
Diabetes Diagnosing 
                            2. Applying Neural Network to Improve the Quality of OSA Diagnosis 
3. Saxophone Timbre Quality Inspection Using Proposed Automatic Multi-class 
Timbre Classification System 
本會核定補助文號：95-2221-E-007-181-MY3 
 
一、參加會議經過 
此行本人與本人所指導的博士生三人，以及台灣他校教授數人等，前往參加該研討會 (6th 
ANQ Congress)。研討會之內容涵蓋 People Leadership、Customer-driven excellence、Quality 
People-valuing and development、Innovation-future driven、Social Responsibility、Quality 
Management、Process Excellence 等七個議題；會議的第一天有五場 Keynote Speech，第二天有
一場 Keynote Speech，分別為“Quality People, Key to Excellence”、“Achievement to Workforce 
Excellence”、“Review and Prospect of Statistical Quality Methods”、“Meditation on “Quality” 
Being Fascinated by its Profound Concept”、“Environmental Changes and Development Strategies 
of Quality Management”、”Let’s Revisit What PDCA Cycle Means in Today’s IT Age!”。 
除了個人與學生的論文發表之外，本人亦選擇與研究興趣關聯性較高之場次進行聆聽。整
體而言，透過此次研討會，與國內外學者有良好交流，瞭解了一些國際學者在品質及其相關領
域之研究方向，頗有收穫。 
 
二、與會心得 
本次與會，透過其他各國研究者的報告，以及與幾位世界品質大師的互動，感覺在品
質觀念與方法上又有更上一層的體會。本研討會非常適合年輕學者或博士生參加。 
 
三、考察參觀活動 
無。 
 
四、攜回資料名稱及內容 
1. 研討會論文光碟集 
2. Program and Abstract Book  
3. ANQ 簡介小冊 
 
2 
 
 The dataset used in this study is obtained from the medical cases of pregnant women in a particular medical center, and was 
grouped into three groups. The set of data used is a so-called imbalanced data wherein the majority part of the dataset comes from one or 
two classes and the rest from the other classes. The first group has non-diabetic women and is labelled Normal. The second is Pre-DM 
which indicates that the women are in pre-diabetes state. The third is DM which indicates that the women have diabetes. The dataset has 
12 attributes and they are as follows: age, screen, ap_ac, pc100g_1, pc100g_2, pc100g_3, BMIprep, weight_before, increased_weight, 
NB_weight, DM_history, and birth_order. There are 152 instances. Ten of these instances are DM, 32 are Pre-DM, and 110 instances 
are Normal. The missing values in the dataset are replaced with the average value of the known values for the attribute in this study. 
 
Previous research 
 There have been many researches in the field of classification. Kaieda and Abe (2004) used kernel principal component 
analysis (KPCA) to develop a fuzzy classifier with ellipsoidal region to the datasets in UCI databank or other researchers used such as 
the dataset of blood cell. In Cao et al. (2006), rough set was used in the prediction of protein structural classes. Electromyography (EMG) 
signals were classified with autoregressive model, artificial neural network (ANN), and higher-order statistical (HOS) model in Reaz, 
Hussain, and Mohd-Yasin (2006). In Boriboonhirunsarn and Sunsaneevithayakul (2008), logistic regression was used to determine the 
independent risk factors related to the normality or abnormality for four sub-groups of diabetes dataset. According to the previous 
related works, the utilization of different methods of classification is more popular in medical science. 
 
Natural and artificial immune systems 
 The natural immune system is a distributed pattern detection system. It consists of several functional elements throughout the 
body. The immune system is handling the defense mechanism of the body by innate and adaptive immune response. Adaptive immune 
response is especially important for us because it has abilities like memory acquisition, diversity, recognition, etc. The adaptive 
immunity then become as the main line of defense in the body and has three key properties. It responds only if an invader is present. It 
remembers a previous contact with an invader, therefore responding faster after initial recognition. Third, it can differentiate between the 
self and the non-self. The immune system is composed of lymphocytes which are classified into two types such as B and T cells. T-cells 
mature in the thymus, while B-cells mature in the bone marrow. Both of these lymphocytes produce antibodies that bind to invading 
antigens. Antigens can be thought of as viruses that trigger immune response. The antigens and the antibodies have one-to-one 
correspondence. When the foreign antigens invade the body, B-cells will produce corresponding antibodies binding to the antigens. The 
Artificial Immune System (AIS) imitates this mechanism. When data enter the system like an antigen, the model will generate the 
corresponding datum as the antibody and store this in the memory cells to immediately respond when the same situation happens. The 
AIS can produce similar antibodies through mutation to respond to the similar data faster. 
 
METHOD 
Artificial Immune Recognition System (AIRS) classification algorithm 
 AIRS is a resource limited and a type of supervised learning algorithm. This algorithm used immune mechanisms are 
resources competition, clone selection, maturation, mutation and memory cells generation. The training and test data items are viewed as 
antigens in the system. These antigens induce the B-cells in the system to produce artificial recognition balls (ARBs). These ARBs 
compete with each other for the given resource number. The ARBs with higher resources will get more chances to produce the mutated 
offspring to improve the system. The memory cells generated after all training antigens have been introduced are used to classify the test 
data items. The algorithm is composed of five stages. These stages are initialization, memory cell identification and ARB generation, 
competition for resources and development of a candidate memory cell, memory cell introduction, and classification. The figure 1 shows 
the flowchart of AIRS algorithm. 
 
Initialization 
 The first stage of the algorithm is data pre-processing stage. In this stage, all items in the dataset are normalized to comply 
with the Euclidean distance which says that the distance between any two data is in the range of [0, 1]. The calculation of the Euclidean 
distance is showed in (1) 
 


m
i
ii yxdistanceEuclidean
1
2_  1  
where x and y represent feature vectors and m is the number of attributes in data. 
After normalization, the affinity threshold is calculated as (2) 
 
 
2
1
 ,
_ 1 1 
 
 
nn
agagaffinity
thresholdaffinity
n
i
n
ij
ji  2  
where n is the number of training data items, iag  and jag  are the thi  and thj  training antigen in the training vector, and  ji agagaffinity  ,  represents the Euclidean distance between the two antigens’ feature vector. 
 
4 
 
Memory cell identification and ARB generation 
 In this stage, the first step is to find out the memory cell, matchmc , given a specific training antigen. The matchmc  is defined 
as  mcagnstimulatioMCmc  ,maxarg  , where  yxnstimulatio  ,  is defined as (3). 
   yxdistanceEuclideanyxnstimulatio  ,_1 ,   3  
Given this definition, it can be assumed that the antibody, matchmc , is the most stimulated memory cell by the given antigen in the set 
of memory cells of the same category. When matchmc  is identified, this cell is used to create new ARBs to be introduced to the 
population of pre-existing ARBs. The number of new ARBs depends on the stimulation value between the memory cell and the antigen. 
 
Competition for resources and development of a candidate memory cell 
 In this stage, all ARBs presently existing in the system are awarded the resource numbers according to their affinity values. 
The ARBs with higher affinity values will get more resources than those with lower affinity values. If the sum of the number of 
resources of all ARBs exceeds the allowed number, the system will remove the ARBs and their awarded resources beginning with the 
lowest number of resources until the sum of the number of resources of all ARBs is lower than the allowed number in the system. After 
this process, the stimulation values of all remaining ARBs are calculated and maximal and minimal stimulation values are determined as 
maxStim and minStim , respectively. The stimulation level of each ARB is recalculated as (4). 








otherwise         ,.1
 of class of class if              ,.
.
minStimmaxStim
minStimstimarb
antigenarb
minStimmaxStim
minStimstimarb
stimarb  4  
Then, we use (5) to calculate the average value of these levels for each class and verify if any of these average values is lower than a 
given stimulation threshold or not. If any of the average values is lower, the ARBs belonging to that class are mutated and the generated 
clones are added to ARB pool. This process is continuously done until the average stimulation levels of all classes are larger than the 
stimulation threshold. 
ij
i
ARB
j
j
i ARBarbARB
stimarb
s
i


         ,
.
1  5  
where nci  ,...,2 ,1 ,  ncssss  ,..., , 21 , iARB  is the number of ARBs belonging to thi  class and stimabj .  is the 
stimulation level of thj  ARB of thi  class. 
 
Memory cell introduction 
 After achieving the criterion described above, the ARB with the highest stimulation value in the same class with the presented 
training antigen is taken as a candidate memory cell, candidatemc . If the stimulation value of the candidatemc  motivated by the training 
antigen is higher than the stimulation value of the matchmc , the candidate memory cell is added to the set of memory cells. If this test is 
passed, a calculation of the affinity between candidatemc  and matchmc  must be obtained. If the affinity between this two memory cells 
is lower than the product of the affinity threshold and the affinity threshold scalar, candidatemc  is replaced with matchmc  in the set of 
memory cells. 
 
Classification 
 After repeating step 2 to step 4 to each training antigen, the developed memory cells are ready for exploitation and for 
classification. The classification is executed in a k-nearest neighbor approach. The classification of a datum in the system is determined 
by the ballot of the results of the k most stimulated memory cells. 
 
Used parameters 
 One advantage of AIRS is that it is not necessary to try all combinations of all parameters to find the best one. AIRS is self-
adjusting to the feature of its architecture. According to the experience of Goodman, Boggess & Watkins (2002), the setting of AIRS’s 
parameters had a classifier with only a few percentages of accuracy less than the optimal combination of the parameters of the system. 
Therefore, we set the parameters as in table 1. 
 
 
 
 
6 
 
REFERENCES 
A. Watkins, AIRS: A resource limited artificial immune classifier. Master thesis, Mississippi State University, 2001. 
D. Boriboonhirunsarn and P. Sunsaneevithayakul, “Abnormal results on a second testing and risk of gestational diabetes in women with normal baseline 
glucose levels,” International Journal of Gynecology and Obstetrics, 2008, vol. 100, issue 2, pp. 147-153. 
Department of Health, Executive Yuan, R.O.C. (Taiwan). URL: 
http://www.doh.gov.tw/CHT2006/DM/SEARCH_MAIN.aspx?keyword=%u7cd6%u5c3f%u75c5 
Formosan Diabetes Care Foundation. URL: http://www.dmcare.org.tw/ 
H.H. Ho, P.C. Hsieh, C.Y. Li, H.F. Su, “A relational study of gestational diabetes and type 2 diabetes,” Taiwan Journal of Public Health, 2006, vol. 25, 
no. 2, pp. 143-151. 
K. Kaieda and S. Abe, “KPCA-based training of a kernel fuzzy classifier with ellipsoidal regions,” International Journal of Approximate Reasoning, 2004, 
vol. 37, pp. 189-217. 
M. B. I. Reaz, M. S. Hussain, and F. Mohd-Yasin, “Techniques of EMG signal analysis: detection, processing, classification and applications,” 
Biological Procedures Online, 2006, vol. 8, pp. 11-35. 
Taipei Veterans General Hospital Endocrinology & Metabolism. URL: http://homepage.vghtpe.gov.tw/~meta/dm.htm#DM_basic 
Y. Cao, S. Liu, L. Zhang, J. Qin, J. Wang, and K. Tang, “Prediction of protein structural class with Rough Sets,” BMC Bioinformatics, 2006, vol. 7, 
Article Number 20. 
 
 
 
 
8 
 
There are two available methods in the detection of OSA, namely, the one-stage and two-stage methods. The one-stage method 
includes a questionnaire, O2 pulse oximeter and body mass index (BMI). The two-stage method utilizes BMI＋O2 pulse oximeter and 
questionnaire＋O2 pulse oximeter.. 
 
NEURAL NETWORK 
The neural network is an information-processing system based on how the human brain processes information. The neural network 
is composed of processing elements and their connections. Each processing element has a single output signal that fans out along the 
connections to other processing elements. The output signals of the processing element are delivered to the processing element in the 
next layer. The neural network depends on the neural interconnection architecture, and on the activation function that transforms input 
and output signals in the neural network. The most common type of neural networks consists of input layer, hidden layer and output 
layer. 
Learning is a major process of the neural network, where the learning process can modify the connecting weights. Two types of 
learning are commonly used: supervised learning and unsupervised learning. The frequently used supervised neural networks, include 
back-propagation neural network (BPNN), counter propagation network (CPN) and learning vector quantization (LVQ).  
In this study, we apply BPNN to construct the functional relationship between OSA factors and RDI. A BPNN consists of three or 
more layers, including an input, one or more hidden layers and an output layer. The training of a BPNN includes three stages: (1) feed-
forwarding of the input training pattern, (2) associated error calculation and back-propagation, and (3) weight and bias adjustments. 
Once trained, a neural network can be evaluated and the relationships between input and output patterns are determined. Thereafter, the 
weights are used to recognise new input patterns. Learning rate and momentum are the two parameters that have the greatest effect on 
the training performance on BPNN. Learning rate controls the weight change during training, while momentum provides significant 
improvements in terms of fast calculations to avoid the local minima oscillations. For more background reviews of the BPNN, readers 
may refer to Rimelhard and MeClelland (1989). 
 
CASE STUDY 
Problem description 
 The OSA’s common factors include the following: Sex, Age, BW, Height, BMI, ASO, MNO, DI, SOST, ESST. These factors 
can be classified into two basic types. The first type includes human characteristics, namely; Sex, Age, BW, Height, BMI, ASO, MNO, 
DI. The second type involves the measure value in the OSA questionnaire, including SOST and ESST. After a consulation with a 
medical doctor with expertise in OSA, we selected three factors. These are Sex, SOST, and ESST. These factors present a conspicuous 
relation with OSA. In this study, 154 samples were collected,148 of these samples had the disease and 6 samples did not show any trace 
of the disease. We employed fold=4 to construct the train data and test data in the NN model. 
 
Applying BPNN to OSA diagnosis 
 The NeuralWorks Professional II/plus software was employed to construct BPNN. The network architecture is a very 
important factor that can dramatically alter the results of the analysis. The learning rate and momentum were set at 0.25 and 0.8, 
respectively. Table 1 shows the candidate neural models. The 3-2-1 neural network model with minimal training and testing RMSEs was 
selected for OSA diagnosis. The implementation results are shown in Table 2. We can see that the BPNN have a good effect to detect 
OSA。 
 
Table1-The candidate BP neural models 
Structure Cross-Volidation(K=4) 
K=1 K=2 K=3 K=4 Avg. 
3-1-1 Train RMS 0.14012 0.14207 0.13535 0.13906 0.13915 Test RMS 0.14245 0.12999 0.15456 0.13855 0.141388 
3-2-1 Train RMS 0.13794 0.14009 0.13385 0.13625 0.137033 Test RMS 0.14234 0.12988 0.1544 0.1387 0.14133 
3-3-1 Train RMS 0.13896 0.14284 0.13448 0.14177 0.139513 Test RMS 0.14228 0.12999 0.15442 0.13877 0.141365 
3-4-1 Train RMS 0.13761 0.14103 0.13373 0.1401 0.138118 Test RMS 0.14238 0.12995 0.15441 0.13884 0.141395 
3-5-1 Train RMS 0.13827 0.14173 0.13346 0.14001 0.138368 Test RMS 0.14238 0.12999 0.15459 0.13863 0.141398 
3-6-1 Train RMS 0.13743 0.14297 0.13398 0.14113 0.138878 Test RMS 0.14231 0.12998 0.15446 0.13876 0.141378 
 
Table2-The Confusion Matrix of NN. 
 Disease Non-Disease 
Positive 146 5 
Negative 0 1 
 
 
 
10 
 
Saxophone Timbre Quality Inspection Using Proposed Automatic Multi-class Timbre 
Classification System 
 
Yu-Hsiang Hsiao and Chao-Ton Su 
 
Department of Industrial Engineering and Engineering Management, National Tsing Hua University, Hsinchu 300, Taiwan 
e-mail: Adrian.iem88@nctu.edu.tw 
 
 
 
 
ABSTRACT 
So far, the timbre quality inspection of saxophone still relies on the musicians’ hearing judgment.  However, the sensitivity and the 
stability of human perception can be influenced by many factors in psychology and in physiology.  To improve the reliability of 
saxophone timbre quality inspection, an automatic multi-class timbre classification system (AMTCS) is developed to assist in the 
inspection work.  The AMTCS composes of our proposed waveform shape-based feature extraction method (WFEM) in sound signal 
parameterization phase and multi-class Mahalanobis-Taguchi system (MMTS) in timbre quality classification phase.  By AMTCS, a 
perfect identification rate on the saxophones with different timbre quality levels is achieved, and the significant tones having impact on 
saxophone timbre quality is also identified.  This can not only increase the robustness of timbre quality judgment but also provides the 
direction for the follow-up saxophone adjustment and the critical points for improving the timbre quality of saxophones. 
 
Keywords: Saxophone, timbre, Mahalanobis-Taguchi system, Classification, Feature extraction, Feature selection. 
 
 
INTRODUCTION 
Saxophone, a woodwind instrument with a single reed, was invented by Antoine-Joseph Sax in 1840.  Among various kinds of 
saxophones, the alto saxophone is the most representative and popular one because of its rich sound, clear tone, and powerful and 
beautiful timbre.  Under the highly developed automation today, the manufacture of saxophone is still a non-automatic process and 
much relies on highly skilled technicians.  Producing a saxophone involves multifarious mechanically processing routes and a final 
assembly of more than 300 components, which takes more than one month.  According to the pattern and specification designed using 
computer simulations, all main components of saxophone are processed separately, and assembled in the end of manufacturing 
procedure.  Although every saxophone is yielded according to the precise specifications given by computer simulations, it is possible 
that some unobvious imprecision that has impact on the sound quality may be caused during handmade manufacture.  For example, the 
diversity of the drilled tone holes can lead to different sharpness of instrument sound.  Thus, sound quality is tested in the final 
inspection by professional musicians to insure that the timbre quality and other sound elements are within acceptable specifications, and 
further to differentiate among different quality levels of saxophones.  It is worthy to notice that the pitch can be easily checked using an 
apparatus while the timbre quality mainly depends on the musicians’ hearing judgment.  However, the sensitivity and the stability of 
human perception can be influenced by many factors, such as emotions (psychological) and tiredness (physiological) [1], which may 
lead to decrease the reliability of timbre quality inspection.  Actually, the saxophone timbre quality judgment task implemented by the 
professional musicians in the final inspection stage can be regarded as a musical instrument timbre classification problem. 
12 
 
the signal behavior in time or frequency domain, which has been done in most research work.  MMTS inherits the robustness of 
classification from Mahalanobis-Taguchi system [28] and can simultaneously efficiently accomplish the multi-class classification and 
feature selection tasks.  The results indicated that by using the AMTCS, a perfect classification rate of different timbre quality levels of 
saxophones was achieved.  Also, through the feature selection function of MMTS, the significant tones having impact on saxophone 
timbre quality were identified. 
 
MULTI-CLASS MAHALANOBIS-TAGUCHI SYSTEM 
The multi-class Mahalanobis-Taguchi system (MMTS) [26] was developed according to the framework of Mahalanobis-Tagichi system, 
and is composed of four main implementing stages: 1) construction of a full model measurement scale with Mahalanobis space of each 
class as the reference; 2) validation of the full model measurement scale; 3) feature selection; and 4) future prediction with important 
features.  In this study, the MMTS was employed as the main algorithm in the classification phase of musical instrument timbre 
classification task.  The four stages of implementing MMTS are detailed as follows. 
 
Stage 1: Construction of A Full Model Measurement Scale with the Mahalanobis Space of each Class as the Reference 
In this stage, the problem and all related features are defined, and the representative examples are collected to construct the individual 
Mahalanobis space for each class and establish the full model measurement scale.  In order to enhance the accuracy of constructing the 
measurement scale, Gram-Schmidt orthogonalization process [27] is applied to eliminate the multicollinearity among features that 
makes the covariance matrix almost singular and the inverse matrix invalid. 
Assume that there are k  classes in a d  dimensional space. For each of classes iC  ),,2,1( ki  , we define the examples sampled 
from its population as “normal” while the examples coming from the other 1k  classes are defined as “abnormal.”  The Mahalanobis 
space iMS  is formed by the in  normal examples sampled from iC .  )()(2
)(
1 )()()(
,,, pd
pp
iii AAA   denote the standardized feature vectors of 
iMS  standardized by the feature means and standard deviations of pMS .  The Gram-Schmidt feature vectors of iMS  orthogonalized on 
the basis of pMS , i.e. 
)(
)(
p
l iU , are sequentially constructed from 1l  to dl   by the following Gram-Schmidt setting: 



1
1
)()()(
)()()()(
l
q
p
qlq
p
l
p
l ipii UtAU
                                          (1) 
where )(
)(
p
l iA  is the 
thl  feature vector of iMS  standardized by pMS ; 
   )(
)(
p
q iU  is the Gram-Schmidt vector of the 
thq  feature of iMS  orthogonalized on the basis of pMS ; 
)( plqt  is the Gram-Schmidt coefficient of pMS . 
)( plqt  is set as follows for dl ,,2,1  , 1,,2,1  lq  : 
)()(
)()(
)()(
)()(
)(
p
q
Tp
q
p
q
Tp
l
lq
pp
pp
p
UU
UA
t                                                (2) 
where )(
)(
p
l pA  is the 
thl  standardized feature vector of pMS ; 
   )(
)(
p
q pU  is the Gram-Schmidt vector of the 
thq  feature of pMS . 
The Mahalanobis distance from any example r  to iC  can be calculated using the Gram-Schmidt orthogonalization process as 
follows.  First, the features in example r  should be standardized by using the feature means and standard deviations of iMS .  Next, the 
Gram-Schmidt coefficients of iMS  are employed to perform the Gram-Schmidt orthogonalization process on the standardized features 
14 
 
where in  is the umber of examples in the Mahalanobis space iMS ; 
)(
)(
ip
j iMD
  is the Mahalanobis distance from the thj  example in iMS  to class pC , and ip  ; 
)(
)(
ip
j iMD
  is the Mahalanobis distance from the thj  example in iMS  to class pC , and ip  . 
For the thl  feature, 

lSN  is used to represent the average signal-to-noise ratio of all runs including the feature, while 

lSN  
represents the average signal-to-noise ratio of all runs excluding the feature.  Because of the usage of orthogonal arrays, it is allowable 
to independently evaluate the effect of each main factor.  Thus, the “effect gain” of each feature can be directly calculated using the 
following equation: 
                                         lll SNSNGain                                           (5) 
If the effect gain corresponding to a feature is positive, the variable may be important and be considered as worth keeping.  However, a 
variable with negative effect gain should be removed. 
 
Stage 4: Future Prediction with the Important Features 
In this final stage, a reduced model measurement scale is constructed using the important features, and is then validated.  A “weighted 
Mahalanobis distance” is employed to be the distance metric for classification.  By simply classifying examples into the class with the 
minimum weighted Mahalanobis distance, the classification can be achieved. 
The measurement scale is reconstructed using the feature subset R  composed of   important features identified in the third stage.  
This scale is called the “reduced model measurement scale.”  Similarly, for iMS , ki ,,2,1  , the validations of the scale should be 
applied using the corresponding abnormal examples to ensure that this reduced model has a good ability to discriminate among different 
classes.  The weighted Mahalanobis distance weighing the different features in the Mahalanobis distance according to the corresponding 
effect gains obtained in the third stage is used for classification after the reduced model measurement scale is validated.  The weighted 
Mahalanobis distance from any example r  to iC  is computed through the following equation: 



Rl
l
i
rl
l
i
r
i
uwWMD 2
2)(
)(
)(
1

                                      (6) 
where   is the number of features in reduced model; 
lw  is the weight of the 
thl  feature in reduced model;  
)(i
rlu  is the Gram-Schmidt vector of the 
thl  feature of example r  processed by iMS  in reduced model; 
)( il  is the standard deviations of )( )(pl iU  in reduced model for ip  . 
The weight of the thl  feature, i.e. lw , in reduced model can be acquired by normalizing the corresponding effect gain obtained in the 
third stage as (7).   



Rl
l
l
l
Gain
Gainw
                                            (7) 
where lGain  is the effect gain of 
thl  feature in reduced model. 
Based on this reduced model, a classification can be achieved by simply classifying examples into the class with minimum weighted 
Mahalanobis distance, and thus the classification accuracy can be acquired.  Importantly, a test experiment should be implemented using 
the unknown examples to confirm the classification ability of the reduced model. 
 
 
16 
 
 
Step 4: Derive the Variation Property on Each Amplitude Level 
Variation property on an amplitude level is recorded by calculating the “level-crossing amount.”  The level-crossing amount is the 
number of intersections of signal waveform and the amplitude level.  The level-crossing amount on LA , i.e. LCA , can be calculated as 
follows: 



1
1
)(
E
e
LL eCA                                            (12) 
where  




0)]]1[()][[(if,0
0)]]1[()][[(if,1
)(
LL
LL
L AeyAey
AeyAey
e                            (13) 
Obviously, a signal with higher fundamental frequency will have larger level-crossing amount in a frame.  In order to eliminate the 
effect of this phenomenon, the proportion of the level-crossing amount on each amplitude level to that on zero amplitude level is 
calculated as the variation property.  The equation of the variation property on LA , i.e. LVA , is shown as (14).  The 0VA  is ignored for 
being permanently equal to 1. 
0CA
CAVA LL                                              (14) 
 
Step 5: Derive the Existence Property on Each Amplitude Level 
Existence property on an amplitude level is recorded by calculating the “level-integral value” of waveform over the range from the first 
sample to the final sample in a frame on the basis of each amplitude level.  Because the sound is digitally recorded, the waveform is 
formed by linearly connecting the adjacent samples.  Thus, the integral of waveform can be perfectly approximated by Trapezoid Rule 
[30] which is a method to approximately calculate the integral of a function over a definite range.  The Trapezoid Rule approximates the 
integral of a function by fitting several trapezoids to the region under the function, and the overall area of the trapezoids is calculated to 
be the approximate integral value.  Let )(yWL  be the LA -centered waveform function.  By the Trapezoid Rule with the width of each 
trapezoid equal to 1, the level-integral value of the )(yWL  over whole frame range, i.e. LIN , can be computed using (15). 
                                    


1
1
1 2
)]1[()][()(
E
e
LLE
LL
AeyAeydyyWIN                            (15) 
Similarly, homogeneous signals with different fundamental frequency will result in different integral values even if on the same 
amplitude level.  Thus, in order to eliminate the effect of different fundamental frequency, the proportion of the level-integral value on 
each amplitude level to that on the lower bound is calculated as the existence property. The equation of the existence property on LA , i.e. 
LEX , is shown as (16). 
maxy
L
L IN
INEX

                                          (16) 
where  




1
1
maxmax
2
)](]1[[)](][[
max
E
e
y
yeyyeyIN                              (17) 
 
Step 6: Obtain the Waveform Shape-based Feature Set 
The average of the variation and existence property on each amplitude level over all frames is taken to be the feature for a musical 
instrument tone.  That is, for a musical instrument tone, a set of totally 34   features composing of 22   features for describing the 
18 
 
A metric called multiple Mahalanobis distance [27] was used when implementing MMTS of AMTCS in this case study.  Multiple 
Mahalanobis distance method is very useful in the situations where the large number of variables can be divided into several meaningful 
subsets containing local variables.  In the multiple Mahalanobis distance method, the Mahalanobis distance is calculated using local 
variables for each subset, and the Mahalanobis distances of all subsets belonging to an example form a new variable vector.  MMTS is 
then implementing on the dataset with the new variable vectors.  In this way, not only the complexity of problems is reduced but the 
important variables selected by MMTS can have more practical meaning.  In the saxophone case, multiple Mahalanobis distance method 
was used because the 255 features of a saxophone example can be divided in to 15 feature groups according to the tones where the 
features come from.  Moreover, it is more valuable to get the knowledge about which tone causes the different quality levels of 
saxophones than to review the individual importance of each of the 255 features.   Therefore, for a saxophone example, the Mahalanobis 
distance of each tone was first calculated using the corresponding 17 features, and this resulted in a new feature vector composing 15 
Mahalanobis distances.  The MMTS is then implemented on the dataset containing 150 saxophone examples and each example has 15 
feature values representing the 15 tones. 
The 5-fold stratified cross-validation strategy was applied for the classification of three saxophone quality levels.  The classification 
and feature selection results yield by our proposed AMTCS are shown in Table 1.  The results indicated that AMTCS achieved perfect 
identification accuracy.  Also, information about the importance of each tone for discriminating the different quality levels of 
saxophones was revealed.  Tones 1c , 1d , 1e , 1f , 1g , 2c , 2e , 2f  were identified in more than three of the five folds, and were thus 
considered important for discriminating the saxophone quality levels. 
Through employing our proposed AMTCS, strong assistance was provided to implement the final timbre inspection of alto 
saxophone.  This not only can increase the reliability of timbre quality judgment but also can reduce the required effort for 
discriminating different quality levels by professional musicians’ hearing.  Besides, through the feature selection function, the 
significant tones having impact on saxophone timbre quality can be easily identified.  This not only provides the direction for the 
follow-up saxophone adjustment but informs the manufacturer about the critical points for improving the timbre quality of alto 
saxophone.  
 
Table 1– The Classification and Feature Selection Results of AMTCS on Saxophone Case 
Classification 
Accuracy (%) 
Need Adjustment Qualified Quality High Quality Overall 
100.00 100.00 100.00 100.00 
Feature Selection 
 Tone 
Fold 
c1 d1 e1 f1 g1 a1 b1 c2 d2 e2 f2 g2 a2 b2 c3 
1 ♪ ♪ ♪ ♪ ♪ ♪ ♪     
2 ♪ ♪ ♪  ♪ ♪ ♪ ♪ ♪     
3 ♪  ♪ ♪ ♪  ♪ ♪ ♪     
4  ♪ ♪ ♪ ♪ ♪  ♪ ♪   ♪  
5  ♪ ♪ ♪ ♪ ♪ ♪     
Overall ♪ ♪ ♪ ♪ ♪ ♪ ♪ ♪     
 
In order to verify the effectiveness of our proposal method, the classification algorithms including k nearest neighborhood classifier 
(kNN), support vector machine (SVM), back-propagation neural network (BPN), learning vector quantization (LVQ), stepwise 
discriminant analysis (SDA), decision tree (C4.5), and rough set theory (RST), and the feature scheme of Mel-frequency cepstral 
coefficients (MFCC) were also employed for the comparison.  The WFEM and MMTS were developed using MATLAB 
(http://www.mathworks.com).  The 5-fold stratified cross-validation strategy was applied for these algorithms, and all the 255 waveform 
shape-based features belonging to 15 tones were used.  For the classification algorithms with feature selection function including MMTS, 
stepwise discriminant analysis, decision tree, and rough set theory, a tone is considered important if any feature belonging to the tone is 
selected.  With regard to k nearest neighborhood classifier, support vector machines, back-propagation neural network, and learning 
20 
 
The symmetrical uncertainty [31] was also adopted to assess and confirm the quality of the proposed waveform-based features used 
for classification.  There were totally 195 Mel-frequency cepstral coefficients (MFCC, 13 features for each of the 15 tones) and 255 
waveform-based features (17 features for each of the 15 tones) considered in this assessment.  Table 4 lists the ranking of first 30 
important features and their symmetrical uncertainty (SU) values.  The result indicates that 22 out of the fist 30 important features are 
occupied by our proposed waveform-based features, and this provides the evidence that our proposed WFEM is comparable. 
 
Table 4 – Feature Ranking for Saxophone Classification 
Rank Feature SU Value Rank Feature SU Value Rank Feature SU Value 
1 WFEM 186 0.6138 11 WFEM 82 0.5113 21 WFEM 168 0.4134 
2 WFEM 83 0.6115 12 WFEM 84 0.5078 22 WFEM 47 0.4116 
3 WFEM 185 0.5917 13 MFCC 107 0.5069 23 MFCC 146 0.3963 
4 WFEM 178 0.5897 14 WFEM 167 0.4857 24 WFEM 177 0.3894 
5 WFEM 187 0.5897 15 WFEM 183 0.4586 25 WFEM 66 0.3813 
6 MFCC 157 0.5554 16 WFEM 81 0.4512 26 WFEM 90 0.381 
7 MFCC 105 0.5437 17 MFCC 68 0.4502 27 MFCC 120 0.3798 
8 MFCC 159 0.5351 18 WFEM 23 0.4285 28 MFCC 1 0.3786 
9 WFEM 166 0.5269 19 WFEM 151 0.4259 29 WFEM 64 0.375 
10 WFEM 184 0.5207 20 WFEM 150 0.4165 30 WFEM 73 0.3681 
 
CONCLUSION 
Under the highly developed automation today, the manufacture of saxophone is still a non-automatic process and much relies on highly 
skilled technicians.  In order to insure that the timbre quality and other sound elements are within acceptable specifications, the sound of 
finished saxophone must be tested in the final inspection stage by professional musicians.  Unlike the pitch which can be easily checked 
using an apparatus, the evaluation of timbre quality mainly depends on the musicians’ hearing judgment.  However, the sensitivity of 
human perception can be influenced by many factors such as the emotions and the tiredness, and this may lead to a low reliability of 
timbre quality inspection.  In this study, an AMTCS was developed in order to improve the accuracy and reliability of timbre quality 
inspection of alto saxophone.  The AMTCS composes of our proposed WFEM in parameterization phase and MMTS in classification 
phase.  The WFEM attempts to directly catch some simple shape characteristics of waveform to depict the sound or signal behavior, 
while the MMTS can identify the important features and accomplish the sound classification.  Through employing the AMTCS, strong 
assistance was provided to the inspection of saxophone timbre quality, and a perfect identification rate on high quality saxophones, 
qualified quality saxophones, and the saxophones needed to be further adjusted was achieved.  The proposed system not only can help 
increase the reliability of saxophone timbre quality judgment but also can reduce the required effort for discriminating different quality 
levels by professional musicians’ hearing.  Besides, through the feature selection function of MMTS, the significant tones having impact 
on saxophone timbre quality were also identified, and this provides valuable information for the follow-up quality improvement of 
saxophone.  
 
REFERENCES 
[1] M. S. Sanders and E. J. McCormick (1993), Human Factors in Engineering and Design, 7th Edition, McGraw-Hill, New York. 
[2] American National Standards Institute (1973), American national psychoacoustical terminology, S3.20, New York: American Standards 
Association. 
[3] S. Ando and K. Yamaguchi (1993), “Statistical Study of Spectral Parameters in Musical Instrument Tones,” Journal of the Acoustical Society of 
America, vol. 94(1), pp. 37-45. 
[4] J. G. Proakis and D. G. Manolakis (2006), Digital Signal Processing: Principles, Algorithms, and Applications, Prentice Hall. 
[5] J. C. Brown (1991), “Calculation of A Constant Q Spectral Transform,” Journal of the Acoustical Society of America, vol. 89(1), pp. 425-434. 
[6] A. Wieczorkowska (2001), “Musical Sound Classification based on Wavelet Analysis,” Fundamenta Informaticae, vol. 47(1-2), pp. 175-188. 
[7] W. J. Pielemeier (1996), G. H. Wakefield, and M. H. Simoni, “Time-frequency analysis of musical signals,” Proceedings of the IEEE, vol. 84(9), 
  
行政院國家科學委員會補助國內專家學者出席國際學術會議報告 
報告人姓名：蘇朝墩 
服務機構及職稱：清華大學工業工程與工程管理系 教授 
會議時間/地點：2009/5/18 ~ 2009/5/23，美國(Minneapolis) 
會議名稱：(中文) 2009 ASQ  世界品質研討會；國際品質學術院大會 
                    (英文) 2009 World Conference on Quality & Improvement (ASQ) 
                                IAQ (International Academy for Quality) General Meeting 
發表論文題目：New Academician Presentation—Chao-Ton Su 
                             
本會核定補助文號：95-2221-E-007-181-MY3 
 
一、參加會議經過 
本人於 2008 年 10 月獲遴選為國際品質學術院院士(An Academician of the International 
Academy for Quality, IAQ)。IAQ 成立於 1971 年，IAQ 的院士主要來自三大地區：(1)美洲，(2)
歐洲，(3)泛亞；IAQ 院士人數上限為 100 名，該院至今擁有 84 名院士(含現役、榮譽、退休和
通訊院士)。本人此行最大之目的為參加 IAQ General Meeting 進行自我介紹報告，並闡述品質
管理相關心得。 
由於 IAQ 乃是 ASQ、EOQ 及 JUSE 此三個區域性品質專業組織所催生出來的全球性
品質專業組織，因此當 IAQ 舉行 General Meeting 時，也希望各院士亦能同時參與 ASQ、
EOQ 及 JUSE 的研討會。所以，此次赴美，本人同時參加了二個會議。 
此行由本人獨自前往，首先於台灣時間 2009.5.18.搭機至洛杉磯，再轉機至
Minneapolis (此時為當地時間 2009.5.19.早上 06:00)，本人隨即參加 ASQ 的研討會，選擇
參加二場 Keynote Speech 與三個 Concurrent presentation。本人於 2009.5.20.參加 IAQ 
General Meeting，參與討論；本人被安排於 2009.5.21.進行 30 分鐘的報告。隨後，馬上赴
機場轉洛杉磯，於 2009.5.23.早上返回台灣。 
二、與會心得 
ASQ 所舉辦的 World Conference on Quality & Improvement 相當多元，內容也豐富，值
得推薦參加。可多鼓勵國內的品質管理專家與學者多多參加 ASQ 所舉辦的活動。 
由於本人被推薦至 IAQ，依規定每三年至少要參加二次 General Meeting，無形中也增
添了不少負擔。 
此行也碰到世界級品質大師—費跟堡博士(TQC 的最原始倡導者)，進行短暫之互動；
除此之外，也遇到上海質量管理學研究院的唐曉芬院長，了解到中國大陸遠赴世界各國學
習品質管理的做法，藉以提升與改善大陸的產品與服務品質，其強烈企圖心是大家都可感
受的；我個人覺得中國大陸已經愈來愈不需要台灣品管專家的協助了。 
三、考察參觀活動 
無。 
四、攜回資料名稱及內容 
大會手冊一本。 
 
