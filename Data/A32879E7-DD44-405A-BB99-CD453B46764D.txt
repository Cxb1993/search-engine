系統驗證之可重用性研究(I) 
Closing the Gap between Design and Verification Reuse 
計畫編號：NSC 95-2221-E-002 -432 - 
執行期間：95 年 8 月 1 日至 96 年 7 月 31 日 
計畫主持人：江介宏助理教授 台灣大學電機系暨電子所  
 
摘要 
藉由「設計再利用」(design reuse)，模組化之積
體電路設計方式為極具前景的有效方法，用以克服愈
趨複雜的超大型積體電路系統設計，並能大幅提升電
路設計者的產能。函數相依性(functional dependency)
為設計與驗證再利用的重要工具。我們將函數相依性
的 計 算 改 寫 為 布 林 條 件 式 的 滿 足 問 題
(satisfiability)。利用 Craig 內插定理，我們克服相依
函數的計算問題，進而將函數相依性的計算能力大幅
提升。 
Abstract 
Functional dependency plays an important role in 
many aspects of electronics design automation, ranging 
from logic synthesis to formal verification. Prior 
approaches to the exploration of functional dependency 
are based on binary decision diagrams (BDDs), which 
may not be easily scalable to large designs. This paper 
proposes a novel reformulation that extensively exploits 
the capability of modern satisfiability (SAT) solvers. 
Thereby, functional dependency is detected effectively 
through incremental SAT solving and the dependency 
function, if exists, is obtained through Craig 
interpolation. The main strengths of the proposed 
approach include: (1) fast detection of functional 
dependency with small memory consumption and thus 
scalable to large designs, (2) a full capacity to handle a 
large set of base functions and thus discovering 
dependency whenever exists, and (3) potential 
application to large-scale logic optimization with 
different design constraints. Experimental results show 
the proposed method is far superior to prior work and 
scales well in dealing with the largest ISCAS89 and 
ITC99 benchmark circuits with up to 200K gates. 
1. Introduction 
Component-based IC design methodology is one of 
the most promising approaches to combat the 
ever-increasing design complexity and to improve circuit 
designers’ productivity through design reuse. 
Verification cost occupies a great portion of total 
development cost in modern electronic system design. It 
becomes much apparent under the design reuse 
methodology, where design time is greatly reduced while 
verification time stays mostly intact. Although design 
reuse is a promising approach to greatly shorten design 
time, the total development cycle may not be improved 
comparably unless its verification portion can be reused 
as well. As current design and synthesis tools do not 
support reverification, it strongly motivates the 
investigation of how verification can be reused in the 
context of design reuse and resynthesis. 
2. Main Results 
We propose the use of functional dependency for 
design reuse and verification reduction. In particular, we 
show that the capacity of logic resubstitution can be 
much extended by SAT-based formulation. 
Functional dependency [1] is concerned with 
rewriting a Boolean function f as a function h over a set 
of base functions {g1, …, gn}, i.e. f = h(g1, …, gn). It 
plays an important role in many aspects of electronics 
design automation (EDA), ranging from logic synthesis 
1 is plotted as a spot in Fig. 2. The first tendency can be seen 
from the two regression lines indicating highly (positive) 
correlated data set. The second tendency can be seen from the 
fact that the line for the retimed circuits is well below that for 
the original circuits. As evident in Columns 4 and 7 of Table 1, 
more functional dependency exists for the retimed circuits. 
Effectively, more unsatisfiable SAT instances are there. It 
reflects the fact that in our experiments a satisfiable instance 
usually takes longer time to solve than an unsatisfiable one. It 
seems contradicting with common sense. However, the 
tendency can be explained as follows. Because the support 
sizes of interpolants are mostly very small (to be shown in Fig. 
3), it suggests that conflicts can be found locally. Also, 
incremental SAT solving increases implicativity [18] and thus 
enhances early conflict detection. Thus, decisions over only a 
few variables might be enough to draw an unsatisfiable 
conclusion. In contrast, in a satisfiable case to obtain a 
satisfying assignment, decisions must be made over all 
variables. 
We characterize the derived dependency functions in terms 
of their support sizes in Fig. 3, where a single dependency 
function, if exists, is derived for each transition function of a 
given circuit. The x-axis and y-axis indicate the numbers of 
supports and of dependency functions, respectively. The y-axis 
is log-scaled. As can be seen, most of the functions have less 
than 10 supports. It demonstrates the fact that the derived 
interpolants are mostly small. On the other hand, complex 
functional dependency can also be detected easily by the 
SAT-based approach. For instance, in the retimed b18 circuit, a 
dependency function of support size around 300 is obtained, 
which is not possible using BDD-based methods. 
In another set of experiments not shown due to space 
limitation, we enumerate different dependency functions for a 
target function. The amount of dependency varies greatly from 
function to function. In addition, a great amount of trivial 
dependency exists due to the transitivity of dependency. It 
results in vast redundant search. How to effectively avoid the 
unnecessary search remains to be done. Nevertheless, if the 
candidate base functions are specified (e.g. for circuit rewiring), 
finding a dependency function can be done very efficiently. 
0.001
0.01
0.1
1
10
100
1 50 99
Iteration
Ti
m
e 
(lo
g)
b19 (200k nodes) b18 (100k nodes)
b17 (30k nodes) b15 (10k nodes)
 
0.0001
0.001
0.01
0.1
1
10
100 1000 10000 100000 1000000
Number of nodes (log)
A
ve
ra
ge
 ti
m
e 
(lo
g)
Original
Retimed
 
 
1
10
100
1000
10000
0 10 20 30
Number of support variables
Nu
m
be
r o
f f
un
ct
io
ns
 (l
og
)
s5378
s9234.1
s13207.1
s15850.1
s35932
s38417
s38584
 
 
Figure 3. Frequency distribution of different support sizes.
Figure 1. Runtime of the first 100 SAT iterations. 
Figure 2. Average runtime for SAT iterations.
出席國際學術會議心得報告 
        
計畫編號 95-2221-E-002-432- 
計畫名稱 系統驗證之可重用性研究(I) 
出國人員姓名 
服務機關及職稱 
江介宏助理教授 台灣大學電機系暨電子所 
會議時間地點 San Diego, USA, 5/30-6/1, 2007 
會議名稱 International Workshop on Logic and Synthesis 
發表論文題目 
1. Scalable Exploration of Functional Dependency by Interpolation and 
Incremental SAT Solving 
2. SAT-based Logic Optimization and Resynthesis 
 
一、參加會議經過 
The International Workshop on Logic and Synthesis provides a research forum for the exchange of ideas 
pertaining to all aspects of synthesis, optimization, and verification of integrated circuits and systems. 
The emphasis is on novelty and intellectual rigor. Topics of interest include (but are not limited to): 
synthesis and optimization; power and timing analysis; testing and verification; architectures and 
compilation; design experiences. Research on modeling, analysis and synthesis for emerging technologies 
and platforms is particularly encouraged. The workshop is supported in part by IEEE Computer Society, 
ACM SIGDA as well as industrial sponsors, Altera, Cadence Design Systems, Fujitsu IBM Research, 
Intel, Magma Design Automation, and Synopsys.  
 
二、與會心得 
In the workshop, we presented the two papers entitled “Scalable Exploration of Functional 
Dependency by Interpolation and Incremental SAT Solving,” and “SAT-based Logic Optimization 
and Resynthesis.” For the first paper, functional dependency is concerned with rewriting a Boolean 
function f as a function h over a set of base functions {g1, …, gn}, i.e. f = h(g1, …, gn). It plays an 
important role in many aspects of electronics design automation (EDA), ranging from logic 
synthesis to formal verification. Prior approaches to the exploration of functional dependency are 
based on binary decision diagrams (BDDs), which may not be easily scalable to large designs. This 
Scalable Exploration of Functional Dependency by 
Interpolation and Incremental SAT Solving 
 
Chih-Chun Lee, Jie-Hong R. Jiang, Chung-Yang Huang 
EE Dept./Graduate Inst. of Electronics Engineering 
National Taiwan University 
 
Alan Mishchenko 
Dept. of EECS 
University of California, Berkeley 
ABSTRACT 
Functional dependency is concerned with rewriting a Boolean 
function f as a function h over a set of base functions {g1, …, gn}, 
i.e. f = h(g1, …, gn). It plays an important role in many aspects of 
electronics design automation (EDA), ranging from logic 
synthesis to formal verification. Prior approaches to the 
exploration of functional dependency are based on binary 
decision diagrams (BDDs), which may not be easily scalable to 
large designs. This paper proposes a novel reformulation that 
extensively exploits the capability of modern satisfiability (SAT) 
solvers. Thereby, functional dependency is detected effectively 
through incremental SAT solving and the dependency function h, 
if exists, is obtained through Craig interpolation. The main 
strengths of the proposed approach include: (1) fast detection of 
functional dependency with small memory consumption and thus 
scalable to large designs, (2) a full capacity to handle a large set 
of base functions and thus discovering dependency whenever 
exists, and (3) potential application to large-scale logic 
optimization with different design constraints. Experimental 
results show the proposed method is far superior to prior work and 
scales well in dealing with the largest ISCAS89 and ITC99 
benchmark circuits with up to 200K gates. 
Categories and Subject Descriptors 
B.6.3 [Logic Design]: Design Aids -- Automatic Synthesis, 
Optimization, Verification; J.6 [Computer-Aided Engineering]: 
Computer-aided design (CAD). 
General Terms 
Algorithms, Optimization, Synthesis, Verification 
Keywords 
BDD, Boolean Satisfiability, Craig Interpolation, Functional 
Dependency, Refutation Proof 
1. INTRODUCTION 
Functional dependency [1] appears commonly among a set of 
Boolean functions {f1, ..., fn} in VLSI circuit design as a function 
fi (called the target function) can often be reexpressed as some 
function h (called the dependency function) over a subset of the 
functions (called the base functions). The exploration of 
functional dependency plays an important role in many aspects of 
EDA, ranging from logic synthesis to formal verification. For 
instance, it leads to the identification of redundant registers in 
RTL synthesis [2][3], resubstitution and simplification of Boolean 
functions in both technology-independent and technology-
dependent logic synthesis [4], BDD minimization [5] and state 
space reduction [1][6][7] in formal verification, search space 
reduction in SAT solving [8], etc. Advances on the exploration of 
functional dependency may benefit a wide range of applications. 
Given a set of Boolean functions {f1, …, fn}, we would like 
to know if any fi can be written as h(f1, …, fi–1, fi+1, …, fn). 
Conventional approaches [1] to the exploration of functional 
dependency rely mostly on BDDs [9]. Unfortunately computation 
using BDDs suffers from the memory explosion problem and thus 
is not scalable to manipulate large designs. In contrast, SAT 
solving consumes little memory (linear in the input size) at the 
cost of time resources and thus is more robust at least in 
representing large designs. Recent advances, see e.g. [10][11], in 
SAT solving have made it a very efficient Boolean reasoning 
engine and a viable alternative to BDD. More and more logic 
synthesis and verification algorithms shift their computation 
paradigm from BDD to SAT, e.g. [12][13]. However, formulating 
the computation of functional dependency as pure SAT solving is 
not straightforward due to the difficulty in deriving the 
dependency function h, whose derivation in BDD-based 
computation is in contrast immediate. 
This paper demonstrates, for the first time, that the 
exploration of functional dependency (including efficient 
derivation of dependency function) can be achieved with pure 
SAT solving. In particular, a dependency function, if exists, can 
be obtained through the construction of interpolants from a 
refutation proof of a SAT solver. Essentially, Craig interpolation 
theorem [14] lays the foundation. Moreover, to detect functional 
dependency for different target functions and to obtain different 
dependency functions for a target function, incremental SAT 
solving is adopted to reuse learned clauses.  Experimental results 
show encouraging improvements over BDD-based approaches.  
The main results of the paper include (1) a new SAT-based 
derivation of dependency function using Craig interpolation, 
which enables a pure SAT solution to the exploration of 
functional dependency, and (2) an incremental SAT-based 
enumeration of target and base functions, which effectively 
reduces the search space for solving similar SAT instances. 
Practical experience shows that a pure SAT formulation of 
functional dependency avoids the BDD memory explosion 
problem and is scalable to large designs. It is powerful in 
detecting functional dependency even among a large set of base 
functions. 
The paper is organized as follows. After preliminaries are 
introduced in Section 2, our SAT formulation of functional 
dependency is detailed in Section 3. The proposed approach is 
evaluated with experimental results in Section 4. Section 5 
concludes this paper and outlines some future research directions. 
unsatisfiable), then there exists a Boolean formula A# referring 
only to the common input variables of A and B such that A ⇒ A# 
and A# ⇒ ¬B. 
The Boolean formula A# is referred to as the interpolant of A and 
B. Detailed exposition on how to construct an interpolant from a 
refutation proof in linear time can be found in [16][17][18]. Note 
that the so-derived interpolant is in a circuit structure, which can 
then be converted into CNF as discussed below. 
2.2.2 Circuit to CNF Conversion 
Given a circuit netlist, it can be converted to a CNF in such a way 
that the satisfiability is preserved. The conversion is achievable in 
linear time by introducing some intermediate variables [19][20]. 
3. SAT-BASED EXPLORATION OF 
FUNCTIONAL DEPENDENCY 
 
 
3.1 The Primary Construct 
To formulate the exploration of functional dependency as SAT 
solving, we introduce the dependency function network (DFN) 
as shown in Fig. 1. For a given circuit netlist consisting of n + 1 
Boolean functions {f0, …, fn}, suppose function f0 and the others 
are identified to be the target function and base functions, 
respectively. Then, in the notation of Section 2, f0 corresponds to f 
and fi corresponds to gi for i = 1, …, n. The circuit netlist is 
instantiated into two copies, identified as DFNon and DFNoff, in 
the DFN. For every variable v in DFNon, there is starred 
counterpart v* in DFNoff. Let yi and yi* be the output variables of fi 
and fi*, respectively. The circuits DFNon and DFNoff can be 
converted to CNFs Con and Coff, respectively, in linear time. In 
addition, the output of the target function f in DFNon is asserted to 
true, i.e., y0 = 1; that of f* in DFNoff is asserted to false, i.e., y0* = 
0. Furthermore, equality constraints (yi ≡ yi*) are imposed for i = 
1, …, n. Thereby the entire CNF CDFN is  
Con ∧ Coff ∧ y0 ∧ ¬y0* ∧ (y1 ≡ y1*) ∧ ⋅⋅⋅ ∧ (yn ≡ yn*),  (1.1) 
where (yi ≡ yi*) is the shorthand for (yi ∨ ¬yi*) ∧ (¬yi ∨ yi*). 
The intuition behind this construct is that formula Con ∧ y0 
(respectively Coff ∧ ¬y0*) imposes the constraint that the 
valuations over input variables (x1, …, xm) (respectively (x1*, …, 
xm*)) must be the on-set of f (respectively off-set of f*). By 
Proposition 1, we can thus test if h0 and h1 are disjoint. Precisely 
speaking, we conclude the following. 
Theorem 3. Given a target function f and a set of base functions 
gi for i=1, …, n, a dependency function h exists if and only if the 
CNF CDFN of the corresponding DFN is unsatisfiable.  
Proof: (⇒) By Definition 1, f can be expressed as h(g1(X), …, 
gn(X)). Proposition 1 asserts that the onset h1 and offset h0 of h 
must be disjoint. Observe that h0 and h1 are essentially the sets of 
satisfying assignments of variables yi of DFNon and yi* of DFNoff, 
respectively. Hence CNF CDFN, which is the conjunction of Con 
and Coff, is unsatisfiable. 
(⇐) For CDFN is unsatisfiable, there are two cases. For the first 
case, Con or Coff is unsatisfiable. It happens only when f is a 
constant function. Con (Coff) is unsatisfiable if and only if f is 
constant zero (one). In this case, we may express f as a function 
over any base functions. For the second case, Con and Coff are both 
satisfiable. Then unsatisfiable CDFN implies its clauses of the 
equality constraints (yi ≡ yi*) are violated. That is, the sets of 
images of the onset and offset of f under the base functions are 
disjoint. By Proposition 1, we know that h must exist. ■ 
In the sequel we shall assume a target function is non-constant. 
Remark 1. Note that, although DFN is similar to the miter 
structure used in combinational equivalence checking, the 
underlying principle is completely different. The DFN construct 
differs from the miter structure in that: Firstly, the sets of input 
variables of DFNon and DFNoff are disjoint. Secondly, the output 
variables of the target functions of DFNon and DFNoff are asserted 
to true and false, respectively. Thirdly, the equality constraints are 
imposed only on the corresponding pairs of base functions. 
We show how the dependency function can be derived using 
interpolation provided that the clause set CDFN is unsatisfiable. To 
apply Theorem 2, consider partitioning the clause set CDFN into 
two subsets A and B. We claim the following. 
Corollary 1. For unsatisfiable CDFN = A ∧ B with A = Con ∧ y0  
and B = Coff ∧ ¬y0* ∧ (y1 ≡ y1*) ∧ ⋅⋅⋅ ∧ (yn ≡ yn*), the resultant 
interpolant A# derived from a refutation proof yields a desired 
dependency function h.  
Proof: Observe that the common variables of A and B are Y = 
(y1, …, yn), which is desirable for the dependency function. Since 
A ∧ B is unsatisfiable, by Theorem 2 there exists an interpolant A# 
which refers only to Y. In addition, conditions A ⇒ A# and A# ⇒ 
¬B suggest that the set of valuations over variables Y satisfying 
A# must be an over-approximation of h1(Y) and must be disjoint 
from h0(Y). Hence, A#(Y) is a valid implementation of the 
dependency function h(Y) with respect to the underlying target 
and base functions. ■ 
Therefore, as long as a SAT solver can produce an interpolant 
from a refutation proof, it can be exploited to generate the 
dependency function. The overall algorithm of the exploration of 
functional dependency is sketched in Fig. 2. 
Figure 1. Dependency Function Network. 
= 
 
= = 
… 
… 
 
… … 
1 0 
DFNofDFNon 
0y
*
0y
*y2
*
ny… … 1y 2y ny
1x 2x mx
*
mx*x1
*x2
Constraint Part 
Circuit Part 
*y1
Table 1. SAT- vs. BDD-based Exploration of Functional Dependency.  
  Original Retimed SAT (original) BDD (original) SAT (retimed) BDD (retimed)
Circuit #Nodes #FF. #Dep-S #Dep-B #FF. #Dep-S #Dep-B Time Mem Time Mem Time Mem Time Mem
s5378 2794 179 52 25 398 283 173 1.2s 18m 1.6s 20m 0.6s 18m 7s 51m
s9234.1 5597 211 46 x 459 301 201 4.1s 19m x x 1.7s 19m 194.6s 149m
s13207.1 8022 638 190 136 1930 802 x 15.6s 22m 31.4s 78m 15.3s 22m x x 
s15850.1 9785 534 18 9 907 402 x 23.3s 22m 82.6s 94m 7.9s 22m x x 
s35932 16065 1728 0 -- 2026 1170 -- 176.7s 27m 1117s 164m 78.1 27m -- -- 
s38417 22397 1636 95 -- 5016 243 -- 270.3s 30m -- -- 123.1 32m -- -- 
s38584 19407 1452 24 -- 4350 2569 -- 166.5s 21m -- -- 99.4s 30m 1117s 164m
b12 946 121 4 2 170 66 33 0.15s 17m 12.8s 38m 0.13s 17m 2.5s 42m
b14 9847 245 2 -- 245 2 -- 3.3s 22m -- -- 5.2s 22m -- -- 
b15 8367 449 0 -- 1134 793 -- 5.8s 22m -- -- 5.8s 22m -- -- 
b17 30777 1415 0 -- 3967 2350 -- 119.1s 28m -- -- 161.7s 42m -- -- 
b18 111241 3320 5 -- 9254 5723 -- 1414.9s 100m -- -- 2842.6s 100m -- -- 
b19 224624 6642 0 -- * * * 8184.8s 217m -- -- * * * * 
b20 19682 490 4 -- 1604 1167 -- 25.7s 28m -- -- 36 30m -- -- 
b21 20027 490 4 -- 1950 1434 -- 24.6s 29m -- -- 36.3 31m -- -- 
b22 29162 735 6 -- 3013 2217 -- 73.4s 36m -- -- 90.6 37m -- -- 
 (“--”: memory usage exceeds 1Gb.  “x”: runtime exceeds 10000 seconds.  “*”: circuit cannot be retimed using ABC [23].) 
 
Large circuits from the ISCAS89 and ITC99 benchmark suits 
are chosen. To have fair comparison with [1], functional 
dependency among the transition functions of a circuit is explored. 
Among the transition functions of a given circuit, each of them is 
specified in turn as the target function and all others as base 
functions. We then explore the corresponding functional 
dependency and compute dependency functions if exist. 
Table 1 compares our approach with the prior work [1]. Columns 
1 and 2 respectively list the name and the number of nodes of 
each circuit. The numbers of flip-flops, denoted #FF, of a circuit 
and its retimed version are listed in Columns 3 and 6, respectively. 
Among the flip-flops of an original circuit (respectively a retimed 
circuit), those whose transition functions possess functional 
dependency are counted in Columns 4 and 5 (respectively 
Columns 7 and 8), denoted as #Dep. In particular, #Dep-S and 
#Dep-B are obtained by the SAT- and BDD-based methods, 
respectively. In fact, #Dep-S data are exact and complete except 
for retimed b19 circuit, which is unavailable from ABC. In 
comparison, the BDD-based method only succeeded in a few 
circuits and detected only a subset of the dependency over a few 
support variables.) The runtime (in seconds) and memory (in 
Megabytes) usage are shown in the following columns. Note that 
the reported memory usage includes the underlying system 
memory whereas the prior work was built on VIS [24] and ours 
on ABC. Despite the uneven comparison, the scalability of our 
approach is evident and outperforms the prior work. 
The strength of incremental SAT solving is shown in Fig. 3. 
The x-axis and y-axis, respectively, represent the iteration number 
and the runtime of solving a SAT instance at that particular 
iteration. The y-axis is log-scaled. Five sample circuits of 
different sizes from Table 1 are plotted for the first 100 iterations. 
As can be seen in all of the plots, the runtimes of the first 
iterations are the maximum of among their first 100 iterations. In 
fact, all the circuits of Table 1 exhibit the same behavior. After 
the first iteration, the runtimes for SAT solving decrease rapidly 
and become relatively short and stable within about 10 iterations. 
It demonstrates the effectiveness for incremental SAT solving. 
The experiments tend to suggest that (1) the average runtime 
for a circuit is linear in the number of its nodes and (2) the solving 
time for an unsatisfiable SAT instance is often much shorter than 
that for a satisfiable one. The statistics are plotted in Fig. 4. The 
x-axis and y-axis, respectively, represent the number of nodes of 
each circuit and the average runtime of SAT iterations. Both axes 
are log-scaled. Every circuit in Table 1 is plotted as a spot in Fig. 
4. The first tendency can be seen from the two regression lines 
indicating highly (positive) correlated data set. The second 
tendency can be seen from the fact that the line for the retimed 
circuits is well below that for the original circuits. As evident in 
Columns 4 and 7 of Table 1, more functional dependency exists 
for the retimed circuits. Effectively, more unsatisfiable SAT 
instances are there. It reflects the fact that in our experiments a 
satisfiable instance usually takes longer time to solve than an 
unsatisfiable one. It seems contradicting with common sense. 
However, the tendency can be explained as follows. Because the 
input sizes of interpolants are mostly very small (to be shown in 
Fig. 5), it suggests that conflicts can be found locally. Also, 
incremental SAT solving increases implicativity [25] and thus 
enhances early conflict detection. Thus, decisions over only a few 
variables might be enough to draw an unsatisfiable conclusion. In 
contrast, in a satisfiable case to obtain a satisfying assignment, 
decisions must be made over all variables. 
We characterize the derived dependency functions in terms 
of their input sizes in Fig. 5, where a single dependency function, 
if exists, is derived for each transition function of a given circuit. 
The x-axis and y-axis indicate the numbers of support variables 
and of dependency functions, respectively. The y-axis is log-
scaled. As can be seen, most of the functions have less than 10 
support variables. It demonstrates the fact that the derived 
interpolants are mostly small. On the other hand, complex 
functional dependency can also be detected easily by the SAT-
based approach. For instance, in the retimed b18 circuit, a 
