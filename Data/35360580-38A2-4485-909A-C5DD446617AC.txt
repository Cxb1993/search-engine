 1
 
行政院國家科學委員會補助專題研究計畫 ■成果報告   □期中進度報告 
 
次波長光柵於顯示器背光系統分光之設計、製造與應用 
 
 
計畫類別：■個別型計畫   □整合型計畫 
計畫編號：NSC  100-2221-E-007-021- 
執行期間： 100 年 8 月 1 日至 101 年 10 月 31 日 
 
執行機構及系所：清華大學動力機械工程學系 
 
計畫主持人：林士傑 
共同主持人：李企桓 
計畫參與人員：劉俊葳   楊子君   吳宗哲 
 
 
 
成果報告類型(依經費核定清單規定繳交)：■精簡報告  □完整報告 
 
 
 
 
 
 
中   華   民   國 101 年 10 月 31 日 
 
 
 
 
 
 3
12  90                      (2) 
21  inc                    (3) 
其中1 為最佳導光棒傾斜角度; nL為導光板折射率; 2 為準直光經導光棒之折射角;  inc為導光棒上
方之入射角度。1 決定整體出光強度和均勻性，若導光棒傾斜角度設計大於1，每次全反射間會有暗
帶發生; 若導光棒傾斜角度設計小於1，全反射光線會在傾斜面產生不同之入射角度，造成後續設計之
色飽和度降低，而這兩者狀況皆會導致導光棒之不均勻性發生。導光棒材質我們選用 PMMA 基材，其
折射率nL 為 1.5，代入式(1)-(3)可得1 為 26.73°; 2 為 26.73°;光柵入射角度inc為 63.27°，唯有符合此入
射角度才能在導光棒內達成均勻之全反射傳遞過程。 
 
 
圖 2 導光棒內部角度之關係圖 
 
2.2 次微米光柵 
從光柵公式可知繞射角度受板材折射率、波長、光柵週期與入射角度等因素所影響，其關係式如
下所示: 
mλ = Λ(n0 sin θdif – nL sin θinc)           (4) 
 
其中 m 為繞射階數，在此取 m=-1；n0 為出光介質折射率，在此為 1.0 (空氣)；nL為光入射所在之介質
折射率，在此我們取 1.5；θinc為光入射角在 63.27°。本次設計希望在入射紅光 R(621nm) 時，能達成垂
直出射(θdif=0°)之目的，即光柵繞射角為 0°。將全部參數帶入後，可得到其光柵週期應為 464nm。 在
此光柵週期下，在入射綠光 G(523nm)，及入射藍光 B(448nm)時，其繞射角分別為 12.2°及 21.85°。R、
G、B 繞射光線分布皆在法線之一側， 若在導光棒末端再加入一反射鏡即可達成對稱出光之 B-G-R-G-B
之繞射角度。  
 
繞射效率取決於光柵結構之深寬比，此對稱數列除了 B-G-R-G-B 外，還有 R-G-B-G-R [6-8]。 R. 
Caputo 等人利用干涉微影蝕刻方式製作週期 320nm，高度 210nm 方形次波長級光柵結構實現
R-G-B-G，其 R(615nm)、G(545nm)、B(450nm)之繞射角度為 31.4°、17.6°與 0.3°。圖 3 為 V 形槽與方
形槽結構之繞射效率比較圖，由圖中可知 V 形槽之整體繞射效率比方形槽高; B-G-R-G (Period=464nm)
出光利用率較 R-G-B-G (Period=320nm)高，故利用 V 形槽來實現 B-G-R-G 分光能有最佳表現。在此曲
線分佈可知此時繞射效率在紅光部分減少甚多，但因紅光區為垂直出光設計，加上反射鏡設計而疊加
其繞射效率，可增加整體系統之均勻性。 
 
 
圖 3 B-G-R-G-B 與 R-G-B-G-R 之光柵結構繞射效率關係 
 5
 
圖 7 色彩分光膜滾壓成形製程示意圖 
 
圖 8(a)和圖 8(b)為次微米光柵之 SEM 剖面圖和上視圖。 當刀具刻劃過久時，由圖 8(c)可以
發現光柵結構有銳角鈍化、結構變形且底端面相當的粗糙。在製作光柵時因週期較小，在長時間
的模仁刻劃下尖刀表面之磨損因素必須加以考慮，因此在需求的刻劃長度範圍內，磨損所造成的
光柵輪廓變化會使光柵效率變低，故在刻劃時必須先評估刻劃路徑總長度。此外在設計階段亦需
將模仁上之結構尖角(成型後光柵底部)的變化列入考慮，因為造成結構變形和底面粗糙的原因很
多，環境潮濕造成結構吸水膨脹、材料硬度不均勻、超精密加工機台和滾壓設備振動和熱效應與
刀腹受力過大造成崩損等都有可能影響光柵的繞射效率。 
 
 
圖 8 次微米光柵之 (a)剖面圖與(b)週期大小，(c)刀具磨損而造成次波長光柵結構缺陷 
 
光柵週期影響繞射角度分佈，我們經由 SEM 量測光柵形貌與週期數據可知超精密加工模仁
和滾壓製程的膜片分布範圍在 391nm~478 nm。我們利用紅光(650nm)、綠光(532nm)與藍光(473nm)
雷射利用-1T 之繞射效率位置帶入式(4)來反推其等效週期，其實驗架構如圖 9 所示。 表 1 為測定
之繞射位置，可以得到繞射角度 θdif，在已知之入射角度與材質折射率即可得到在不同波長下各個
週期對應值為 468.82nm、455.87nm 和 460.91nm，與設定值之週期 464nm 之精度誤差為 2%左右。 
 
 
圖 9 利用雷射測定等效週期之實驗架構圖 
 
 7
 
圖 12 彩色分光背光模組色域量測結果 
 
 
圖 13 B-G-R-G 色彩分光強度分佈之量測 
 
4. 結論 
為了降低製造成本並提高光效能，本研究之目的在開發利用滾筒壓印技術製作出色彩分光之
背光模組系統。此一背光模組系統透過光學模擬設計、微奈米製程到光學檢測驗證等步驟方能完
成。 經由實驗檢測可知此準直光源架構下可實現 NTSC 100%之色彩飽和度， 利用 SEM 與雷射
檢測可知次微米光柵週期誤差小於 2%。 此方式不同於傳統彩色顯示效果方式，不僅在能量節約
上有較高的光能使用率與較廣的色域外，利用超精密加工與 UV 滾壓製作使製程更加簡易和可量
產性，能讓光學膜片更節省製作成本。 
 
5. 致謝 
本文作者感謝國科會在計劃經費(NSC100-2221-E- 007-021-)的支持及工研院在設備及操作技術上
的諮詢及協助。 
 
6. 參考文獻 
[1] T. V. Gunn and W. Haistead, “Diffractive color separation fabrication,” Proc. SPIE 3363, 1998, pp 
198-208 . 
[2] H. Dammann, “Color separation gratings,” Appl. Opt. 17(15), 1978, pp 2273-2279. 
[3] Y. Taira, H. Numata, D. Nakano, K. Sueoka, F. Yamada, M. Suzuki, M. Noguchi, R. Singh, and E. G. 
Colgan, “Color Filterless Liquid Crystal Display Illuminated with LEDs,” SID 03 Digest 34, 2003, pp 
1250–1253. 
[4] Y. Taira, D. Nakano, H. Numata, A. Nishikai, S. Ono, and F. Yamada, M. Suzuki, and M. Noguchi, R. 
Singh, and E. G. Colgan,“Low-power LCD using a novel optical system,” SID 02 Digest 50,1313-1315 
(2002). 
2012 ISPEMI 會議報告 
By 林士傑 
2012 8th International Symposium on Precision Engineering Measurements and 
Instrumentation (ISPEMI) 是由 International Committee on Measurements and 
Instrumentation (ICMI)所主辦。此次會議於成都家園國際酒店舉行。此次會議有
96 篇口頭論文及 138 篇論文發表。當然七場 plenary speech 是最受會議所重視
的。  
 
 
 首先上場的是川大中國工程學院院士 Jie Gao，他近期的研究在降低電流對電
壓在平坦區的斜率以驗證量子現象。藉由微結構形成電場及狹小通路；藉由控制
測試環境於低溫下，平坦區的斜率不斷下降；這些結果呈現在國際重要期刊上。
但量測值仍有許多不確定性。 
 第二場是由瑞士 Federal office of metrology (METAS) 的 Rudolf Thalmann 對
瑞士量測機構發展接觸式三次元量測的發展進行報告。由於接觸式三次元量測的
精度受探頭大小的影響極深;因此探頭朝微小化進行。但微小化後對於撞針問題的
處理更顯重要，因此如何避免撞針受損，在設計上須有特殊考量，而類似 AFM 
修正空氣因溫度濕度造成空氣折射率的變化。他們採用 pulse to pulse 
intereferometer 且設計了 walvelength-stabilized optical frequency comb 來完成精
確量測。由於我們也曾試過採用兩種雷射作量測實驗;此一結果對未來相關研究結
果具啟發性。 
  
 
  
applications, the reduction in the number of projections also means the reduction of 
processing time.  However, it was shown that artifact will appear when limited 
projections were used in reconstruction [2, 3].  The iterative reconstruction methods 
can do much better than the filtered back projection approach with limited projections.  
However, the computing time for the iterative reconstruction methods is much higher 
than that for the filtered back projection approaches [1, 3].   
In this study, it is of interest to find a way to improve the results of the 
reconstruction when the filtered back projection approach was adopted.  Artificial 
network could be one feasible way to improve the reconstructed results.  Suzuki et al. 
used artificial neural network as a tool to detect lung nodules in low-dose computed 
tomography [4].  Morisue adopted Hopfield type neural networks to reconstruct 
image [5].  Instead of training the neural networks, the connection weights of the 
neural networks were determined based on algebraic reconstruction technique (ART).  
It was shown that from the simulation results that the Hopfield type neural network is 
a feasible approach for reconstruction of the image in CT.   However, this study is 
only limited to sample with a small size of 32×32pixels and with very limited grey 
levels of 8.  Ma et al. [6] and Ali et al. [7] used back propagation type neural network 
to reconstruct image.  Small amount of projection data are used to train the network.  
And the trained network can used to reconstruct the image of the training sample.  
However, the trained network is not tested by other test samples. 
In this study, it is of interest to study the feasibility of using artificial neural 
network to reconstruct image from limited images.  The information estimated using 
the filtered back projection technique is adopted as the input to the network.  In the 
following section we will briefly review the network adopted in this study. Three 
networks are then trained and test for 16, 32 and 64 projections.  Conclusions are 
not well organized, it is still very difficult to train a successful network. 
In this study, fan beam projection is used as an example.  Assuming a line image 
detector of 121 pixels is used.  For 32 projections, it means more than three thousand 
pixel information is taken and should be taken into account for reconstruct 2-D image.  
It is inefficient and almost impossible to train the network with such large amount of 
information.  It is necessary to reorganize this loose information to more compact 
information to serve as the inputs of the network. 
Filtered back projection is now one of the most two popular approaches used for 
computed tomography.  Filtered back projection has the advantage of faster 
processing speed over the iteration approach.  The following steps for computer 
implementation are clearly stated in [2].  Assuming that each projection R(s) is 
sampled with a sampling interval of a, the known projection data then are Ri(na); i 
are the angles for which fan projections are known.  For each fan projection Ri(na), 
the corresponding modified projection R’i(na) is given by 
ܴఉ೔ᇱ ሺ݊ܽሻ ൌ ܴఉ೔ሺ݊ܽሻ ·
ܦ
ඥܦଶ ൅ ሺ݊ܽሻଶ                                ሺ1ሻ 
The corresponding filtered projection can be generated by convolving each 
modified projection R’i(na) with g(na)  
ܳఉ೔ሺ݊ܽሻ ൌ ܴఉ೔ᇱ ሺ݊ܽሻ כ ݃ሺ݊ܽሻ                                ሺ2ሻ 
 
    
3. Network Training 
The popular Shepp-Logan Phantom is used as the training sample for this study.  
The size of the training sample used is 41×41pixels.  For each test data set, the output 
of the network is the grey level of training sample at a certain position.  For each 
projection, ଵ௎మሺ௫,௬,ఉ೔ሻ ܳఉ೔ሺݏԢሻ is calculates for a certain position (x, y).  Therefore, 
there are N inputs if N projections are taken to reconstruct the image. The N inputs 
and the grey level of (x, y) is now one data set of the artificial network.  In this study, 
there are 1681 data sets are used for training. 
  The network is trained on a personal computer with an AMD Athlon 64 CPU.  The 
simulated projections and all other calculations are conducted under the environment 
of MATLAB.   The simulated system is shown in Fig. 3.  The distance of the X-ray 
source to center of the examined object is 80mm while the distance of the X-ray 
source to the detector is 160mm. The size of the detector is 121pixel.   
In previous study [3], it was found that the image reconstructed using the 
Simultaneous Algebraic Reconstruction Technique (SART) can reach a relatively 
acceptable results when 32 projections are used for image reconstruction.  Therefore, 
we would like to know the feasibility of adopting artificial network to reconstruct 
images with limited projection around 32.  There are two networks NN32x40x1, and 
NN64x70x1 are trained to reconstruct image for 32 and 64 projections, respectively.  
The learning rate adopted for training these networks is 0.1.   
For comparison, three image indexes were adopted here.  One is the Peak 
Signal-to-Noise Ratio (PSNR) [12].  The PSNR values are determined by the 
following equation. 
 4. Network Testing 
Three test samples are made to verify the trained networks.  Figs. 5-7 show the 
comparison of the reconstructed images.  As shown in Fig. 5, all image measures 
indicate that the image reconstructed using the trained neural networks is more 
similar to the original image than the image reconstructed filtered back projection 
method for sample one.  Certainly, the more the projection is, the better the 
reconstructed result.  Although the improvement in image measures is not as good 
as what observed in the training sample, improvement is clearly observed for various 
projections.       
    Sample 2 and 3 are samples with relatively complex geometries.  Sample one 
and the training sample are more circular type of image.  Therefore, we design these 
two samples that look quite different from the training sample.  Fig. 6 shows the 
images reconstructed for sample two.  When 32 projections were used for image 
reconstruction, the image is improved by the trained network.  However, the image 
quality is not good enough.  When 64 projections were used for image reconstruction, 
the improvement of the trained network over the filtered back projection is clearly 
visible.  
Fig. 7 shows the test results for sample three.  When 32 or 64 projections were 
used for image reconstruction, the image is improved by the trained network.  And, 
the reconstructed image is much closer to the original sample image than the image 
reconstructed using the filtered back projection approach.  
 
5. Discussions and Conclusions 
It had been a major concern about multi-slice X-ray CT for its high radiation dose 
delivered to a patient.  In order to reduce the radiation dose, one can either limit the 
[4] K. Suzuki, S. G. Armato, F. Li, S. Sone, and K. Doi, “Massive training artificial 
neural network (MTANN) for reduction of false positives in computerized 
detection of lung nodules in low-dose computed tomography,” Medical Physics, 
vol. 30, no. 7, pp.1602-1617, 2003. 
[5] M. Morisue, K. Sakai, H. Koinuma, “Neural networks for Computed 
Tomography,” Proc. IEEE International Symposium on Circuits and Systems, 
vol. 6, pp. 2893–2896, 1992. 
[6] X.F. Ma, M. Fukuhara, T. Takeda, “Neural Network CT image reconstruction 
method for small amount of projection data,” Nuclear Instruments and Methods 
in Physics Research A, vol. 449, pp. 366–377, 2000. 
[7] F. Ali, Z. Nakao, Y.-W. Chen, “Two new neural network approaches to two- 
dimensional CT image reconstruction,” Fuzzy Sets and Systems, vol. 103, pp. 
295–302, 1999. 
[8] B. Chen, J. F. Wang, and S. B. Chen, “Prediction of pulsed GTAW penetration 
status based on BP neural network and D-S evidence theory information fusion,” 
International Journal of Advanced Manufacturing Technology, Vol. 48, No. 1-4 
pp. 83-94, 2010. 
[9] M. M. Mahapatra and L. Li, “Prediction of pulsed-laser powder deposits' shape 
profiles using a back-propagation artificial neural network,” Proceedings of the 
Institution of Mechanical Engineers Part B-Journal of Engineering manufacture, 
Vol. 222, No. 12, pp. 1567-1576, 2008. 
[10] W. C. Chen, P. H. Tai, M. W. Wang, et al.,” A neural network-based approach 
for dynamic quality prediction in a plastic injection molding process,” Expert 
Systems with applications, Vol. 35, No.3, pp. 843-849, 2008. 
[11] L. Fausett, Fundamentals of Neural Networks: Architectures, Algorithms, and 
Applications, Prentice-Hall, Inc, 1994 
[12] E. D. Castro, C. Morandi, “Registration of translated and rotated images using 
finite Fourier transform,” IEEE Transactions on Pattern Analysis and Machine 
Intelligence, vol. 9 ,1987, pp. 700–703. 
 
 
 
 
 
 
 
 
 
Input 
Layer 
Hidden Layer Output 
Layer 
Interconnections
Processing 
Element 
 
Training sample Filtered back projection Artificial neural network 
32 projections 64 projections 32 projections 64 projections 
  
CC=0.7320 
MSE=0.0275  
PSNR=15.6025 
CC=0.9009 
MSE=0.0118  
PSNR=19.2989 
 
CC= 0.9554 
MSE=0.0048  
PSNR=23.2196 
CC= 0.9740 
MSE= 0.0026  
PSNR=25.7692 
Fig. 4 Comparison of reconstructed images for training sample 
 
 
 
Test sample 1 Filtered back projection Artificial neural network 
32 projections 64 projections 32 projections 64 projections 
  
CC=0.9043 
MSE=0.0553  
PSNR=12.5735 
CC=0.9450 
MSE=0.0391 
PSNR=14.0786 
 
CC=0.9389 
MSE=0.0252  
PSNR=15.9791 
CC=0.9404 
MSE=0.0246  
PSNR=16.0844 
Fig. 5 Comparison of reconstructed images for Test sample 1 
 
 
Test sample 2 Filtered back projection Artificial neural network 
32 projections 64 projections 32 projections 64 projections 
  
CC=0.8964 
MSE=0.0659  
PSNR=11.8092 
CC=0.9597 
MSE=0.0322  
PSNR=14.9164 
 
CC=0.8951  
MSE=0.0456  
PSNR=13.4070 
CC=0.9670  
MSE=0.0149  
PSNR=18.2686 
Fig. 6 Comparison of reconstructed images for Test sample 2 
 
國科會補助計畫衍生研發成果推廣資料表
日期:2012/12/19
國科會補助計畫
計畫名稱: 次波長光柵於顯示器背光系統分光之設計、製造與應用
計畫主持人: 林士傑
計畫編號: 100-2221-E-007-021- 學門領域: 自動化檢測技術
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
2012 與逢甲大學李企桓教授、馬仕信教授，指導清華大學動機系學生劉俊葳、
吳忠哲、科管所徐偉哲(動機系１１級畢)、生科系學生曾郁容，台灣大學學生
劉伊容，逢甲大學學生戴銨慶、黃宗賢以「綠色面板之心-高效能彩色分光背光
系統」榮獲 2012 第 7 屆「龍騰微笑創業競賽」第三名。 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
