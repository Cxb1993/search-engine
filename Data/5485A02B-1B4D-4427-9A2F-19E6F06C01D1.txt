3.3.4 Practical Construction IIext . . . . . . . . . . . . . . . . . . . 48
3.4 System Performance Over the Precoded Partial Response Channel and
Optical Recording Channel . . . . . . . . . . . . . . . . . . . . . . . . 51
3.4.1 ECC-RLL System . . . . . . . . . . . . . . . . . . . . . . . . . 54
3.4.2 RLL-ECC System . . . . . . . . . . . . . . . . . . . . . . . . . 55
3.5 Concluding Remarks . . . . . . . . . . . . . . . . . . . . . . . . . . . 61
4 On Soft Iterative Decoding for Ternary Recording Systems with RLL
Constraints 63
4.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 63
4.2 Basic LDPC Coded Recording Systems . . . . . . . . . . . . . . . . . 64
4.2.1 PLM Precoded Partial Response Channels . . . . . . . . . . . 64
4.2.2 Ternary (0,3) Code Construction . . . . . . . . . . . . . . . . 65
4.3 Soft Decoding for an ECC-RLL Scheme . . . . . . . . . . . . . . . . . 67
4.3.1 Codeword-Branch Trellis . . . . . . . . . . . . . . . . . . . . . 67
4.3.2 Symbol-Branch Trellis . . . . . . . . . . . . . . . . . . . . . . 70
4.4 Specific Constructions and Simulation Results . . . . . . . . . . . . . 72
4.5 Concluding Remarks . . . . . . . . . . . . . . . . . . . . . . . . . . . 74
5 Concluding Remarks 75
Bibliography 76
ii
3.2 Simulation results of a coded 4-Level RLL (0, k) constraints over PR(1, 2, 2, 1)
partial response channel. . . . . . . . . . . . . . . . . . . . . . . . . . 56
3.3 Simulation results of a coded 4-Level RLL (0, k) constraints over PR(1, 2, 2, 2, 1)
partial response channel. . . . . . . . . . . . . . . . . . . . . . . . . . 57
3.4 An RLL-ECC multilevel optical recording system. . . . . . . . . . . . 58
3.5 Simulation results of a coded 4-Level RLL (0, k) constraints over PR(1, 2, 2, 1)
partial response channel. (A) 4-level (0,4) RLL Code; (B) 4-level (0,7)
RLL Code; (C) 4-level (0,10) RLL Code; (D) RS Code + 4-level (0,4)
RLL Code; (E) RS Code + 4-level (0,7) RLL Code; (F) RS Code +
4-level (0,10) RLL Code; (G) 4-level (0,6) RLL Code + LDPC Code
with hard decoding, (0,7) constraint; (H) 4-level (0,6) RLL Code +
LDPC Code with soft decoding, (0,7) constraint, 10 iterations; (I)
4-level (0,3) RLL Code + LDPC Code with hard decoding, (0,4) con-
straint; (J) 4-level (0,3) RLL Code + LDPC Code with soft decoding,
(0,4) constraint, 10 iterations. . . . . . . . . . . . . . . . . . . . . . . 59
3.6 Simulation results of an optical recording system with AGWN noise
only (i.e., β = 0). (A) RS Code + 4-level (0,4) RLL Code; (B) RS Code
+ 4-level (0,7) RLL Code; (C) 4-level (0,3) RLL Code + LDPC Code
with hard decoding, (0,4) constraint; (D) 4-level (0,6) RLL Code +
LDPC Code with hard decoding, (0,7) constraint; (E) 4-level (0,3) RLL
Code + LDPC Code with soft decoding, (0,4) constraint, 10 iterations;
(F) 4-level (0,6) RLL Code + LDPC Code with soft decoding, (0,7)
constraint, 10 iterations. . . . . . . . . . . . . . . . . . . . . . . . . . 60
3.7 Simulation results of an optical recording system with both AGWN
and jitter noise (β = 0.15). (A) RS Code + 4-level (0,4) RLL Code;
(B) RS Code + 4-level (0,7) RLL Code; (C) 4-level (0,3) RLL Code +
LDPC Code with hard decoding, (0,4) constraint; (D) 4-level (0,6) RLL
Code + LDPC Code with hard decoding, (0,7) constraint; (E) 4-level
(0,3) RLL Code + LDPC Code with soft decoding, (0,4) constraint,
10 iterations; (F) 4-level (0,6) RLL Code + LDPC Code with soft
decoding, (0,7) constraint, 10 iterations. . . . . . . . . . . . . . . . . 61
4.1 Equivalent form of the concatenation of the pulse length modulation
precoder, the signal mapper and the partial response channel. . . . . 66
4.2 Schematic diagram of a ternary RLL recording systems over the pre-
coded partial response channel with iterative decoding. . . . . . . . . 66
4.3 Codeword-PSPR trellis. . . . . . . . . . . . . . . . . . . . . . . . . . 69
4.4 Symbol-PSPR trellis. . . . . . . . . . . . . . . . . . . . . . . . . . . . 71
iv
List of Tables
1.1 Some practical applications of RLL and ECC codes for the storage
recording systems. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1
3.1 The 6-bit input/4-symbol output look-up table for Example 3.4. . . . 44
3.2 (M,d, k) = (4, 0, k) RLL codes obtained by Practical Construction II. 51
3.3 (M,d, k) = (4, 0, k) RLL codes obtained by Practical Construction IIext. 51
4.1 A ternary (0, 3) RLL code with rate of 4/3 bits/symbol. . . . . . . . 67
vi
the RLL (0, k) constrained coding are presented.
Constructing RLL codes with error-correcting (EC) capabilities, i.e, RLL-EC cod-
ing scheme, is an interesting topic [4], [5]. A straightforward method to construct RLL
code with EC capability can be divided into three stages. For the first stage, we con-
vert a message sequence into a data sequence satisfying RLL constraint. For the
second stage, a systematic EC encoder adds parity bits which may not satisfy the
RLL constraint to the data sequence. For the third stage, the parity bits which may
not satisfy the RLL constraint are converted into a parity sequence satisfying RLL
constraint. However, the EC capability of the resultant RLL-EC coding scheme may
be changed. In case that the RLL constraint is the (0, k) constraint, there is a very
simple method for which the EC capability of the resultant RLL-EC coding scheme
will not be changed. We first encode a message sequence into a codeword of length n
using the ECC (EC code) encoder and then we insert 1’s into this codeword every k
bits. The resultant code will satisfy the (0, k) constraint and will have a code length
of n + dn
k
e, where dxe stands for the smallest integer no less than x. In [69]-[73],
novel methods have been proposed to insert parity bits of the ECC into the message
sequence which meets the (0, k′) constraint so that the resultant sequence will not
violate the (0, k) constraint, where k′ ≤ k. The overall information rate will be the
product of the RLL coding rate and the ECC coding rate. Hence, such a procedure of
constructing RLL code with EC capability is not efficient in the overall information
rate.
In [9]-[12], the channel for data storage and detection is considered as a partial
response (PR) channel. Since a combined ECC with PR channel can be considered
as a concatenated coding system, we can combine the soft-in-soft-out (SISO) equal-
izer for the PR channel and the SISO ECC decoder to achieve high reliability. Since
the affect of inter-symbol interference can be effectively removed in this concatenated
structure, we can set d = 0 for the (d, k) sequence constraint. In particular, using
a turbo code [13] or an LDPC code [14]-[16] as ECC which is combined with PR
channel can achieve very high error-correcting capability [9]-[12]. The precoder is not
considered in this scheme. In [74], the unconstrained LDPC codeword is deliberately
bit flipped to satisfy the RLL constraint before being sent to the channel, while the
deliberately flipped bits are expected to be removed by the powerful LDPC decoder.
This scheme is novel in using the capability of ECC to eliminate the need of redun-
dancy in RLL coding. This scheme can be applied to (0, k) sequences with loose
constraint, i.e., large k. In case of moderate or small k, the number of deliberately
flipped bits will be so great that only a low rate LDPC code is powerful enough to
correct them. To reduce the number of deliberately flipped bits, Li and Vijaya Ku-
mar [11] proposed to try a number of test sequences which are respectively added
(modulo 2) to the unconstrained LDPC codeword to find a resultant sequence which
is likely to have acceptable number of flipped bits. The scheme proposed in [11] can
2
where λ is the largest real root of the characteristic equation
Zk+2 − Zk+1 − (M − 1)Zk−d+1 +M − 1 = 0. (1.2)
The code efficiency of an M -level RLL (M,d, k) code is expressed as η = R/C(M,d,k).
By now, some M -level RLL (M,d, k) codes using finite-state machine encoders
have been designed in [29]-[31]. Instead of the sequential design as in [29]-[31], we
focus on (M, 0, k) block coding in this report, where M ≥ 4. We look for efficient
(M, 0, k, kl, kr) codes of finite length which can be easily encoded and decoded, where
an (M, 0, k, kl, kr) sequence is an M -level (0, k)-constrained RLL sequence which has
at most kl leading zeros and at most kr trailing zeros. The condition of kl + kr ≤ k
is required such that concatenating any two (M, 0, k, kl, kr) sequences can still meet
the (M, 0, k) constraint.
For the multilevel RLL constrained recording systems, we begin our study by
searching for capacity-approaching primitive code constructions. These primitive
code constructions are formed by collecting (M, 0, k, kl, kr) sequences according to
some simple rules. We are intended to construct as many (M, 0, k, kl, kr) sequences
as we can based on the simple rules. The simple construction rules may not enable
the primitive code constructions to have the merit of low complexity of encoding and
decoding. However, practical code constructions with low complexity of encoding
and decoding can be obtained by the concatenation of subsets of these primitive
code constructions. The capacity-approaching coding rates of the primitive code
constructions can be used as the target for the rates of our practical code construction.
In this report, we propose two practical codes and their extended design constructions
for the (M, 0, k, kl, kr) codes, for which the code rates are very close to those of the
primitive code constructions and hence are also close to the capacity.
We propose two practical code constructions. Using Construction I, we can obtain
(M, 0, k, kl, kr) RLL codes of length n = kl + kr + 2k, for which the number of code
sequences is Mn−1(M − 1). The encoding is implemented by first mapping a message
P into a sequence u¯ = (u0, . . . , un−1), where P = 0, 1, · · · ,Mn−1(M − 1) − 1, ui
∈ {0, 1, · · · ,M − 1}, i = 0, 1, · · · , n − 2 and un−1 ∈ {1, 2, · · · ,M − 1}, and then
u¯ is encoded into a code sequence v¯ = (v0, . . . , vn−1), where vi ∈ {0, 1, · · · ,M −
1}. For binary (0, k) RLL codes of length n, some classes of rate (n − 1)/n code
constructions have been reported [69]. In the sense of coding rate, the code obtained
from Construction I may be regarded as an analogue of the rate (n − 1)/n binary
(0, k) RLL codes of length n. In Construction II, the condition of un−1 6= 0 is relaxed
so that the code size can be greater than Mn−1(M − 1), where n = kl + kr + 2k − 2.
Employing either Construction I or Construction II, the constructed code has a code
rate close to the capacity given in (1.1). In case that the message P is in the form
of a binary sequence and log2M is an integer, then we propose an extended design of
4
Chapter 2
Low-Density Parity-Check Coded
Recording Systems With
Run-Length-Limited Constraints
2.1 Introduction
In data storage systems, run-length-limited (RLL) coding [63]-[65] are usually needed
to avoid the adverse effect of inter-symbol interference (ISI) and to facilitate the
operation of synchronization. A runlength-limited sequence is a binary sequence, for
which the run length of consecutive 0’s is under a given constraint. For example, in
a (d, k) sequence, the number of consecutive 0’s is at least d and at most k. An RLL
code is a collection of RLL sequences, which may not have error-correcting capability.
Constructing RLL codes with error-correcting (EC) capabilities, i.e, RLL-EC cod-
ing scheme, is an interesting topic [4], [5]. A straightforward method to construct RLL
code with EC capability can be divided into three stages. For the first stage, we con-
vert a message sequence into a data sequence satisfying RLL constraint. For the
second stage, a systematic EC encoder adds parity bits which may not satisfy the
RLL constraint to the data sequence. For the third stage, the parity bits which may
not satisfy the RLL constraint are converted into a parity sequence satisfying RLL
constraint. However, the EC capability of the resultant RLL-EC coding scheme may
be changed. In case that the RLL constraint is the (0, k) constraint, there is a very
simple method for which the EC capability of the resultant RLL-EC coding scheme
will not be changed. We first encode a message sequence into a codeword of length n
using the ECC (EC code) encoder and then we insert 1’s into this codeword every k
bits. The resultant code will satisfy the (0, k) constraint. In [69]-[73], novel methods
have been proposed to insert parity bits of the ECC into the message sequence which
meets the (0, k′) constraint so that the resultant sequence will not violate the (0, k)
6
encoder of an LDPC code, Cldpc, to obtain the n-bit output v¯ = (v0, v1, · · · , vn−1) .
The purpose of LDPC coding is twofold. The first is to enhance the reliability of the
retrieved data. The second is to remove flipped bits. The sequence v¯ may not meet
the RLL constraint. Let Q be a set of L maximum length sequences (m sequences)
of length n. For each sequence q¯ = (q0, q1, · · · , qn−1) ∈ Q, we have
v¯ ⊕ q¯ = (v0 ⊕ q0, v1 ⊕ q1, · · · , vn−1 ⊕ qn−1). (2.1)
We flip some bits of v¯ ⊕ q¯ to result in a sequence vˆ(q¯) that meets the RLL con-
straint. Let y¯ = (y0, y1, · · · , yn−1) be the vˆ(q¯) such that, the number of flipped bits,
i.e., the weight of vˆ(q¯) ⊕ v¯ ⊕ q¯, is the smallest among all the q¯ ∈ Q. Each compo-
nent yj, j = 0, 1, · · · , n − 1, in y¯ is either 0 or 1. Replacing each component that
is equal to 0 by a component -1, we converts the sequence y¯ into a corresponding
sequence y¯′ = (y′0, y
′
1, · · · , y′n−1). The sequence y¯′ will be the input of a PR channel
with impulse response h¯ = (h0, h1, · · · , hm). At the reading side, we can use soft-
in-soft-out (SISO) equalizer to exploit the effect of ISI caused by the PR channel.
Since L candidates are used to reduce the number of flipped bits which are needed
to meet the RLL constraint, we may call this multiple-candidate method a selective
flipping (SLF) technique. This SLF technique for the LDPC coded PR equalized
system with RLL constraint was proposed in [11]. Multiple-candidate method was
also used in the technique of guided scrambling to design constrained codes with
high efficiency in [70], [71].The technique of selective flipping is similar to the selec-
tive mapping technique used for PAPR (peak-to-average-power ratio) reduction for
orthogonal frequency-division multiplexing (OFDM) systems [55]. For the selective
mapping technique, increasing the number of candidates can increase the capability of
PAPR reduction. Similarly, for the selective flipping scheme, increasing the number
of candidates, i.e., L, can increase the capability of reducing the flipped bits. As to
selective mapping technique for PAPR reduction, the problem is that increasing the
number of candidates will usually significantly increase the complexity, since a large
number of inverse Fast Fourier Transform operations are needed. In contrast, increas-
ing the number of candidates for the selective flipping technique will not increase the
complexity too much, since checking the run-length constraint and bit flipping are
simple operations.
2.2.1 Systems Using Side Information
In [11], side information s¯ is used to indicate the selected maximum length sequence
q¯. Note that s¯ needs to be coded into c¯s to acquire error protection and satisfy the
RLL constraint. For example, we may use a (25,8) block code shortened from a (26,9)
binary linear code [56] with minimum distance 9 to protect the 8-bit side information
for indicating the candidate (maximum length sequence) selected from Q containing
8
as output.
Step 3) Let LD(yi) = LD(vi)·(−1)qi . The extrinsic value for the bit yi from the
decoder is obtained by LD(yi) - Le(yi) which is used as the a priori LLR, i.e.,
La(yi), in the MAP detector. The resultant sequence is (La(y0), La(y1), · · · ,
La(yn−1)) which will be used in the next iteration.
Step 4) Increase Uo by 1. If the index of iteration Uo = I, then the hard decision
of LD(vi), i = 0, 1, · · · , n − 1, is used as the final estimate of v¯. Otherwise, go
back to Step 1.
Example 2.1: Consider the PR channel which is the EPR4 channel with impulse
response h¯ = (1, 1,−1,−1). Let the RLL constraint be the (d, k) = (0,7) constraint.
Fig. 2.2 shows the BER (bit error rate) curve obtained by deliberate flipping as pro-
posed in [74]. We can use the SLF technique in [11] to improve the error performance.
Let the number of candidates, L, be 256. The side information is protected by a (29,8)
block code Cs which is converted from a (25,8) code with distance 9 by adding bits to
satisfy the (0, 7) constraint. The number of message bits is lm = 888. An (999,888)
LDPC code with column weight and row weight (t, s) = (3, 27) [15] is used. From
Fig. 2.2, the BER obtained by using Algorithm SI and L = 256 is very close to the
ideal case, i.e., the LDPC coded PR channel without any RLL constraint, where Ui
= 1 and Uo = 15, Eb stands for the consumed energy per message bit and N0 is the
one-sided power spectral density of the additive white Gaussian noise. However, the
SLF technique using side information has a rate loss of 100%×29/(999+29) ≈ 2.82%
as compared to this ideal case. To reduce the rate loss, we may use only 16 candidates
instead of the original 256 candidates. To protect the 4-bit side information, we may
use a (21,4) binary linear code with minimum distance 9 that is shortened from a
(26,9) code [56]. To satisfy the (0,7) constraint, the code length needs to be extended
to 24. Thus, the code rate loss will be 100%×24/(999+24) ≈ 2.35%. However, as
shown in Fig. 2.2, the BER obtained by using Algorithm SI and L = 16 is quite
inferior to that obtained by using Algorithm SI and L = 256. ¤
We may compare Example 2.1 with Example 2.2 which is constructed by using
the powerful RLL-LDPC concatenation scheme proposed in [69].
Example 2.2: According to Table I of [69], we can design a (18,17) RLL code,
denoted C1, meeting the (0,7) constraint, for which 10 of the 18 bit positions in each
codeword can be used as unconstrained bits, where each unconstrained bit means that
we can arbitrarily assign 0 or 1 to this bit position without violating the constraint.
In addition, we can design a (9,8) RLL code, denoted C ′1, meeting the (0,7) constraint.
Moreover, the concatenation of C1 and C
′
1 will still meet the (0,7) constraint. We
can concatenate 55 C1 and 1 C
′
1 codeword to form a (999,943) RLL code C2 meeting
the (0,7) constraint, for which 550 bit positions in each codeword can be used as
10
error-protected side information. Hence, the information rate will be exactly the same
as the ideal case. For this side-information free technique, z¯s is no longer available.
We now only have z¯ = y¯′∗h¯ + w¯ for detection. Due to the lack of side information, we
have no idea of which candidate q¯ is selected. Thus, we have to test every candidate.
As shown in Fig. 2.3, we have a set of L component detectors, each for a candidate
q¯l, 1 ≤ l ≤ L. The detection and decoding algorithm for the side-information free
system is shown as follows. Let I ′ be a positive integer which is smaller than I.
ALGORITHM NSI:
Step 1) For the l-th component detector, 1 ≤ l ≤ L, the iteration (Steps 1 ∼ 4) for
Uo ∈ {1, 2, · · · , I ′} is the same as that in Algorithm SI except that q¯ should be
replaced by q¯l = (ql,0, ql,1, · · · , ql,n−1).
Step 2) At the end of the I ′-th iteration, we compute the sum of LLR values
LLRSUM =
n−1∑
i=0
|LD(vi)|, (2.2)
for each component detector. Decide the component detector with the largest
LLRSUM .
Step 3) Let the l′-th component detector be the one with the largest LLRSUM . We
complete the (I ′ + 1)-th to the I-th iteration for the l′-th component detector.
Step 4) If the index of iteration Uo = I, then the hard decision of LD(vi), i =
0, 1, · · · , n− 1, for the l′-th component code is used as the final estimate of v¯.
This side-information free selective flipping technique is designed based on an
assumption that the cosets, q¯i ⊕ Cldpc and q¯j ⊕ Cldpc, are widely separated, where
i 6= j and q¯i ⊕ Cldpc = {q¯i ⊕ v¯|v¯ ∈ Cldpc}. If the assumption is correct, the bit error
rate (BER) of the side-information free selective flipping technique will be similar to
the technique using correct side information. Although we are unable to prove this
fact analytically, in our simulation, we randomly pick some LDPC codes from [15]
and the simulation results show that this technique works as expected.
The computational complexity of Algorithms SI and NSI is dominated by MAP
equalization (detection) and LDPC decoding. The computational complexity of Al-
gorithm NSI is about (LI ′+(I−I ′))/I times of that of Algorithm SI. Usually, using I ′
equal to 1 or 2 will be enough for the detector to identify the correct candidate. Hence,
the increase of computational complexity will not be too great. For Algorithms SI
and NSI implemented in hardware, the hardware complexity is highly dependent on
the architectures used and the throughput and latency requirements. As compared
12
2.3 Estimation of the Flipped Bits
We now propose a scheme which alleviates the interference of flipped bits by estimat-
ing the positions of these flipped bits in the detection process. We utilize the correla-
tion introduced by the RLL constraint to estimate the positions of these flipped bits
in the detection process. Then, we apply a selected flipping operation with a small
L to this estimation scheme so that the number of flipped bits is not too great to
estimate. Since a small L is used, the number of bits for side information is reduced
as compared to [11]. Assuming that the side information s¯ is correctly recovered, we
can find the selected candidate q¯ from s¯.
2.3.1 Flipped Bits Estimation for Side-Information Free Tech-
niques
Remember that in Section 4.2.2, for the side-information free technique, I ′ iterations
are implemented for each of the L component detectors and in case that the l′-th
component detector has the largest LLRSUM at the I ′-th iteration then the rest of
the I−I ′ iterations are implemented for only the l′-th component detector, where each
iteration is implemented for the exchange of information between the MAP (channel)
detector (equalizer) and the LDPC decoder as indicated in Section 4.2.1. Note that
the LDPC decoder is used to remove both the additive noise and the flipped bits
which are used to meet the RLL constraint. In case that the number of flipped bits is
great, the LDPC decoder alone can not correct these flipped bits. We need to employ
the correlation property within the RLL sequences to enhance the error-correcting
capability of the LDPC code.
After we decide the single component detector which employs the candidate q¯l′
and will be chosen for the j-th iteration, I ′ < j ≤ I, we will execute the decoding
and estimation operations as shown in Fig. 2.4. In each iteration, we have the soft
output of the LDPC decoder, i.e., the a posteriori LLR value for the bit vi, denoted
LD(vi), 0 ≤ i ≤ n−1. For each component of q¯l′ equal to 1, we reverse the polarity of
corresponding component of the LD(vi) to remove the effect of selective flipping and
obtain LD(yi). Make hard decision on LD(yi). Then, we have v¯
∗ ⊕ q¯l′ which imitates
the procedure of selective flipping, where v¯∗ = (v∗0, v
∗
1, · · · , v∗n−1) is an estimation of
v¯ obtained by making hard decision on LD(vi). Moreover, we modify v¯
∗ ⊕ q¯l′ into
y¯∗ which satisfies the RLL constraint by flipping some bits of v¯∗ ⊕ q¯l′ . The nonzero
bits in v¯∗⊕ q¯l′ ⊕ y¯∗ represent the estimation of the flipped bits for satisfying the RLL
constraint. The nonzero bits in v¯∗ ⊕ q¯l′ ⊕ y¯∗ will be used to change the polarity of
La(yi) and Le(yi) in Algorithm SI. The algorithm for detection and decoding along
with the estimation of flipped bits is summarized as follows.
ALGORITHM NSIEST:
14
Example 2.4: We modify Example 2.3 by using Algorithm NSIEST for detection
and decoding instead of using Algorithm NSI. Now we use the (999,888) LDPC code
with column weight and row weight (t, s) = (3, 27) from [15]. Other parameters
are (d, k) = (0,7), L = 16, I = 15 and I ′ = 1. The computational complexity of
using Algorithm NSIEST is only (16×1 + (15 − 1))/15 = 2 times of that of using
Algorithm SI. From Fig. 2.5, we see that the simulation results indicate that the
BER performance of using Algorithm NSIEST is very close to the ideal case. ¤
5 5.5 6 6.5 7
10−6
10−5
10−4
10−3
10−2
10−1
Eb/No (dB)
BE
R
Deliberate flipping only
Ideal
NSIEST, L=16
SIEST, L=16
SI, L=16
RLL−LDPC scheme
Figure 2.5: Additional simulation results of (999,888) LDPC coded EPR4 channel
with (0,7) constraint (Ui = 1, Uo = 15).
2.3.2 Flipped Bits Estimation Along With Side Information
Either Algorithm NSI or Algorithm NSIEST is designed based on the idea of waiving
the need of side information so that there is no rate loss resulting from using side
information. The price is the increased computational complexity. The concept of
estimation can be applied to the selective flipping technique with side information to
reduce the number of candidates needed for selective flipping, i.e., L, and hence the
number of bits for side information. In this way, there will be almost no penalty for
16
5 5.5 6 6.5 7 7.5 8
10−6
10−5
10−4
10−3
10−2
10−1
Eb/No (dB)
BE
R
Deliberate flipping only, Uo=15
Ideal,  Uo=15
SIEST, L=16, Uo=15
SIEST, L=16, Uo=12
SIEST, L=16, Uo=6
RLL−LDPC scheme, Uo=15
Figure 2.6: Simulation results of (4608,4096) LDPC coded EPR4 channel with (0,7)
constraint (Ui = 1).
18
parameter conditionally Gaussian random variable whose variance is twice the mag-
nitude of the mean, i.e.
fΛ(λ|X = x) = exp(−(λ− (σ
2
Λ/2) · x)2/2σ2Λ)√
2piσΛ
. (2.7)
Thus (2.5) becomes :
IΛ(σΛ) = 1− 1√
2piσΛ
∫ ∞
−∞
exp(−(λ− (σ2Λ/2))2/2σ2Λ) · log2[1 + e−λ]dλ. (2.8)
For abbreviation we define :
J(σ) := Iin(σin = σ), (2.9)
with
lim
σ→0
J(σ) = 0, lim
σ→∞
J(σ) = 1, σ > 0. (2.10)
The capacity of the binary input/continuous output AWGN channel is therefore given
by :
CG = J(σ = 2/σn). (2.11)
The capacity CG cannot be expressed in closed form. It is monotonically increasing
in σ = 2/σn and thus reversible:
σin = J
−1(Iin). (2.12)
The range [0, 1] of J compactly describes the quality of the output LLRs of a receiver
component and is more convenient then [0,∞] for the approaches based onmor the
SNR. To obtain , (2.5) is used as well, whereas the conditional PDFs are empirically
determined through Monte-Carlo simulations: the input apriori LLRs are randomly
generated with a normal distribution and feed to the SISO component of interest; a
certain value of Iin is got by appropriately choosing the parameter according to (2.12).
Then the corresponding output LLRs are computed by histogram measurements for
their PDFs. Fig. 2.7 and Fig. 2.8 illustrates the procedures for plotting the EXIT
curves of detector and decoder, respectively. Note that the EXIT curves for the outer
decoder in SCCC system are the same for all channel SNR values since no channel
information feed to it directly.
The crucial observation in [57] analysis is that the output sequence Λout can also
be reasonable well approximated by a single parameter Gaussian distribution of type
(2.7). A MAP equalizer and a MAP decoder are assumed to match this assumption,
which was shown to be accurate in [58] for sum product decoding algorithms in
20
2.4.2 Convergence Analysis for Algorithms NSIEST and SIEST
EXIT (extrinsic information transfer) chart is a powerful tool to explain the dynamics
of iterative decoding [57]. EXIT chart was used to explain the dynamics of turbo de-
coder and turbo equalizer in [59] and [60], respectively. In [59], [60], a soft-in-soft-out
(SISO) component such as decoder or equalizer is regarded as a device transforming
soft information Lin associated with a random variable X into another soft infor-
mation Lout with the same random variable X. More precisely, the component is
characterized as performing a mapping T of the input mutual information I(Lin, X)
to the output mutual information I(Lout, X). The mapping T is called the EXIT
characteristic of that component.
In this section, we use the technique of EXIT (extrinsic information transfer) chart
[57] to examine the the convergence behavior of Algorithms NSIEST and SIEST. We
assume that the detector is chosen correctly in either NSIEST and SIEST. We consider
information exchange between the LDPC decoder and the MAP equalizer (detector)
including the flipped bits estimator.
For the MAP equalizer including the flipped bits estimator, we investigate the
EXIT characteristic TE of the input mutual information IE,in = IE(LD(vi), vi) and
the output mutual information IE,out = IE(L(vi), vi). Since the channel output is also
an input to the MAP equalizer, we calculate TE based on a channel with a certain
level of additive noise and a certain level of flipping errors which are dependent on
Eb/N0, k and L, i.e., the number of candidates in the SLF technique. Hence, TE is a
function of Eb/N0, k and L, and we write IE,out = TE(IE,in, Eb/N0, k, L).
For the LDPC decoder, we investigate the EXIT characteristic TD of the input
mutual information ID,in = ID(L(vi), vi) and the output mutual information ID,out =
ID(LD(vi), vi) = TD(ID,in). Note that TD is not a function of Eb/N0 or k or L.
Fig. 2.9 shows TD and TE under various conditions. From Fig. 2.9, we find that the
LDPC coded system using Algorithm NSIEST (or SIEST) with L = 16 can converge
to a low BER at Eb/N0 = 6.5 dB under (0, 7) constraint since TD and TE intersect at
a value of mutual information equal to 1. In addition, we find that the LDPC coded
system using Algorithm NSIEST (or SIEST) with L = 256 can not converge to a low
BER at Eb/N0 = 6.5 dB under (0, 3) constraint since TD and TE intersect at a low
value of mutual information.
Although EXIT chart analysis is most effective for long codes, the EXIT chart
for our examples using LDPC codes of lengths 999 and 4608 respectively still reveals
valuable information. For example, we can investigate the speed of convergence by
observing the trajectory in Fig. 2.10. We find that the LDPC coded system using
Algorithm NSIEST (or SIEST) can converge to a value of mutual information equal to
1 at the 12th iteration. This observation of convergence speed is verified by the BER
results shown in Fig. 2.6. Both the (4608,4096) PEG LDPC code and the (999,888)
LDPC code used in this report have the same rate of 0.888. The longer (4608,4096)
22
0 0.2 0.4 0.6 0.8 1
0.8
0.82
0.84
0.86
0.88
0.9
0.92
0.94
0.96
0.98
1
IE,in ID,out
I
E
,o
u
t
I
D
,i
n
Detector, Eb/N0= 6.2 dB, (0,7) constraint
(4608,4096) LDPC Decoder
Figure 2.10: Trajectories of iterative processes for MAP detector including flipped
bits estimator and LDPC decoder (SIEST with L = 16 and Ui = 1).
24
5 5.5 6 6.510
−6
10−5
10−4
10−3
10−2
10−1
Eb/No (dB)
BE
R
Deliberate flipping only
Ideal
SI, L=512
NSIEST, L=32
Figure 2.11: Simulation results of (999,888) LDPC coded EPR4 channel with (0,6)
constraint (Ui = 1, Uo = 15).
26
passing between LDPC decoder and the MAP detector can be used for decoding.
To examine the performance of NSIEST algorithm, we modify the detection of the
partially ideal case by checking the 968 constrained bits of C7 which are encoded to
satisfy the (0,4) constraint to see whether they meet the (0,4) constraint or not, i.e.,
NSIEST algorithm. Fig. 2.12 shows that the associated BER performances will be
very close to those obtained by C7 with NSIEST and L = 2. ¤
BER performances of the ideal case, for which LDPC coded PR channel without
RLL constraint is considered, have been shown in Fig. 2.2. For the ideal case, the BER
is 10−6 at Eb/N0 of 6.3 dB, where Eb stands for the consumed energy per message
bit and N0 is the one-sided power spectral density of the additive white Gaussian
noise. From Fig. 2.12, we see that C7 with NSIEST and L = 2, the BER is 10
−6 at
Eb/N0 of 6.73 dB. The loss of Eb/N0 for C7 with NSIEST and L = 2 as compared
to the ideal case at BER = 10−6 is 0.43 dB, which is resultant from the rate loss.
Since the information rate of C7 is 0.801 and the information rate of the ideal case
is 0.889, the asymptotic rate loss at very high Eb/N0 will approach 0.45 dB. In this
sense, NSIEST with a sufficiently small L is very efficient for RLL-ECC concatenation
recording systems with strict RLL constraint by properly using the technique of [69].
5 5.5 6 6.5 7 7.5 810
−6
10−5
10−4
10−3
10−2
10−1
Eb/No (dB)
BE
R
C , deliberate
flipping only
C , NSIEST, L=1
C , partially ideal case
 with RLL check
C , NSIEST, L=2
7
7
7
7
Figure 2.12: Simulation results of (999,888) LDPC coded EPR4 channel with (0,4)
constraint (Ui = 1, Uo = 15).
28
together with additional 6 message bits are encoded into a codeword of the (999,
888) systematic LDPC codeword, where 98 out of the 111 parity bits will replace 98
zero bits in the unconstrained bit positions. The resultant code, denoted C12, has an
overall information rate of 790/999 ≈ 0.790. In C12, each codeword is still an LDPC
codeword of length 999 bits for which 980 bits meets the (0,3) constraint and the
other 19 bits may not. We can deliberately flip some bits of these 19 bits to meet the
(0,3) constraint. At the reading side, we can apply the conventional message passing
between LDPC code and the MAP detector, which is equivalent to Algorithm SI with
L = 1. The associated BER performances as indicated by ”C12, deliberate flipping
only” are shown in Fig. 2.13. We can also apply NSIEST to C12 with deliberate
flipping. From Fig. 2.13, we can see that the BER performances represented by ”C12,
NSIEST and L = 1”, i.e., pure estimation without using SLF technique, are clearly
superior to those represented by ”C12, deliberate flipping only”. In Fig. 2.13, we also
observe that C12 with NSIEST and L = 2 provides further improvement in the BER
performances. ¤
As a comparison, we may consider a partially ideal case for which in the storage
side, C12 without flipping any bit is used, and in the reading side, conventional mes-
sage passing between LDPC code and the MAP detector, equivalently Algorithm SI
with L = 1, is used. Although no bit flipping is needed in this partially ideal case,
we see from Fig. 2.13 that the associated BER performances are inferior to those
obtained by C12 with NSIEST and L = 2. A major reason for this phenomenon is
that in C12 with NSIEST and L = 2, the correlation property imposed by the (0,3)
constraint is efficiently exploited to remove errors caused by additive noise and de-
liberate flipping. To examine this argument, we modify the detection of the partially
ideal case by checking the 980 bit positions which are encoded to satisfy the (0,3)
constraint to see whether they meet the (0,3) constraint or not. Fig. 2.13 shows that
the associated BER performances will be very close to those obtained by C12 with
NSIEST and L = 2.
BER performances of the ideal case, for which LDPC coded PR channel without
RLL constraint is considered, have been shown in Fig. 2.2 and Fig. 2.5. For the ideal
case, the BER is 10−6 at Eb/N0 of 6.3 dB. From Fig. 2.13, we see that C12 with
NSIEST and L = 2, the BER is 10−6 at Eb/N0 of 6.75 dB. The loss of Eb/N0 for C12
with NSIEST and L = 2 as compared to the ideal case at BER = 10−6 is 0.45 dB,
which is resultant from the rate loss. Since the information rate of C12 is 0.790 and
the information rate of the ideal case is 0.889, the asymptotic rate loss at very high
Eb/N0 will approach 0.51 dB. In this sense, NSIEST with a sufficiently large L is very
efficient for ECC with strict RLL constraint by properly using the technique of [69].
30
2.6 Concluding Remarks
In this chapter, we propose two techniques for the LDPC coded partial response
channel with RLL constraint. The first is a modification of the selective flipping
technique so that side information is not needed. The advantage of this modification
is the increased information rate and the disadvantage is the increased computational
complexity as compared to the selective flipping technique using side information. The
second is based on the estimation of flipped bits for the selective flipping technique.
This technique can increase the information rate or reduce the BER without the
penalty of increasing computational complexity as compared to the selective flipping
technique either using side information or not using side information. In case of very
strict RLL constraint, the proposed techniques can be incorporated into a technique
in [69] to increase the information rate without performance degradation.
32
M -level RLL (M,d, k) code [81], denoted by C(M,d,k), is given by
C(M,d,k) = log2 λ, (3.1)
where λ is the largest real root of the characteristic equation
Zk+2 − Zk+1 − (M − 1)Zk−d+1 +M − 1 = 0. (3.2)
The code efficiency of an M -level RLL (M,d, k) code is expressed as η = R/C(M,d,k).
By now, some M -level RLL (M,d, k) codes using finite-state machine encoders
have been designed in [29]-[31]. Instead of the sequential design as in [29]-[31], we
focus on (M, 0, k) block coding in this report, where M ≥ 4. We look for efficient
(M, 0, k, kl, kr) codes of finite length which can be easily encoded and decoded, where
an (M, 0, k, kl, kr) sequence is an M -level (0, k)-constrained RLL sequence which has
at most kl leading zeros and at most kr trailing zeros. The condition of kl + kr ≤ k
is required such that concatenating any two (M, 0, k, kl, kr) sequences can still meet
the (M, 0, k) constraint.
We begin our study by searching for capacity-approaching primitive code construc-
tions. These primitive code constructions are formed by collecting (M, 0, k, kl, kr)
sequences according to some simple rules. We are intended to construct as many
(M, 0, k, kl, kr) sequences as we can based on the simple rules. The simple construc-
tion rules may not enable the primitive code constructions to have the merit of low
complexity of encoding and decoding. However, practical code constructions with
low complexity of encoding and decoding can be obtained by the concatenation of
subsets of these primitive code constructions. The capacity-approaching coding rates
of the primitive code constructions can be used as the target for the rates of our
practical code construction. In this report, we propose two practical code and their
extended design constructions for the (M, 0, k, kl, kr) codes, for which the code rates
are very close to those of the primitive code constructions and hence are also close to
the capacity.
We propose two practical code constructions. Using Construction I, we can obtain
(M, 0, k, kl, kr) RLL codes of length n = kl + kr + 2k, for which the number of code
sequences is Mn−1(M − 1). The encoding is implemented by first mapping a message
P into a sequence u¯ = (u0, . . . , un−1), where P = 0, 1, · · · ,Mn−1(M − 1) − 1, ui
∈ {0, 1, · · · ,M − 1}, i = 0, 1, · · · , n − 2 and un−1 ∈ {1, 2, · · · ,M − 1}, and then
u¯ is encoded into a code sequence v¯ = (v0, . . . , vn−1), where vi ∈ {0, 1, · · · ,M −
1}. For binary (0, k) RLL codes of length n, some classes of rate (n − 1)/n code
constructions have been reported [69]. In the sense of coding rate, the code obtained
from Construction I may be regarded as an analogue of the rate (n − 1)/n binary
(0, k) RLL codes of length n. In Construction II, the condition of un−1 6= 0 is relaxed
so that the code size can be greater than Mn−1(M − 1), where n = kl + kr + 2k − 2.
34
3.2.1 Primitive Construction I
Theorem 3.1 : For M ≥ 4, there exists an (M, 0, k, kl, kr) code of length n =
2(k + 1) + 1 such that its rate in bits/symbol is
R = log2{M2(k+1)(M−1)[1−(1+M−2)(M−kl−1+M−kr−1)+M−kl−kr−2+M−2(3−M−1)]}/n,
(3.3)
where kl = dk/2e and kr = k − kl.
Proof : We consider (M, 0, k, kl, kr) sequences length n = 2(k+1)+1, which are
categorized into four disjoint groups, denoted G1, G2, G3, and G4 respectively. The
categorization of the four groups are based on the 2(k+1)-tuple u¯ = (u0, u1, . . . , un−2),
where each ui is an M -level symbol. Each (M, 0, k, kl, kr) sequence can be expressed
as v¯ = (v0, v1, . . . , vn−1). For G1, the symbol vk+1 is an arbitrary nonzero M -level
symbol £. For G2, the symbol vk+1 is 0 and the symbol vk+2 is 1. For G3, the symbol
vk+1 is 0 and the symbol vk+2 is 2. For G4, the symbol vk+1 is 0 and the symbol vk+2
is 3. Based on these characteristics, we see that these four groups are disjoint. The
details of the four groups are given as follows.
G1 : The condition that (u0, u1,. . ., ukl) 6= (0, · · · , 0) and (un−2−kr , un−1−kr , . . . , un−2)
6= (0, · · · , 0) is required. Each sequence in this group is v¯, where (v0, v1, . . ., vk)
= (u0, u1, . . ., uk), vk+1 = £, and (vk+2, vk+3, . . ., v2(k+1)) = (uk+1, uk+2, . . .,
u2(k+1)−1).
G2 : The condition that (u0, u1, . . ., ukl) = (0, · · · , 0), and (un−2−kr , un−1−kr , . . .,
un−2) 6= (0, · · · , 0) is required. Each sequence in this group is v¯, where vi = ×
for 0 ≤ i ≤ kl − 2, vkl−1 = ukl+1, vkl = £, vi = ui+1, for i = kl + 1, kl + 2, · · · ,
k, vk+1 = 0, vk+2 = 1, and vi = ui−1, for i = k + 3, k + 4, · · · , 2(k + 1).
G3 : The condition that (u0, u1, . . ., ukl) 6= (0, · · · , 0) and (un−2−kr , un−1−kr , . . .,
un−2) = (0, · · · , 0) is required. Each sequence in this group is v¯, where vi = ui,
for i = 0, 1, · · · , k, vk+1 = 0, vk+2 = 2, and vi = ui−2, for i = k + 3, k + 4, · · · ,
2(k + 1) − kr − 1, v2(k+1)−kr = £, v2(k+1)−kr+1 = u2(k+1)−kr−2, and vi = × for
2(k + 1)− kr + 2 ≤ i ≤ 2(k + 1).
G4 : The condition that (u0, u1, . . ., ukl) = (0, · · · , 0) and (un−2−kr , un−1−kr , . . .,
un−2) = (0, · · · , 0) is required. Each sequence in this group is v¯, where vi =
ui+kl+1, for i = 0, 1, · · · , kl − 1, vkl = £, vi = × for kl + 1 ≤ i ≤ k, vk+1 = 0,
vk+2 = 3, vi = × for k + 3 ≤ i ≤ 2(k + 1) − kr − 1, v2(k+1)−kr = £, and vi =
ui−kr−2, for 2(k + 1)− kr + 1 ≤ i ≤ 2(k + 1).
It can be easily checked that v¯ in any group satisfies the (M, 0, k, kl, kr) constraint.
There areM2(k+1)(M−1) v¯ sequences with nonzero vk+1. There areM2(k+1)−kl−1(M−
1) sequences with zero (v0, v1,. . ., vkl) andM
2(k+1)−kr−1(M−1) v¯ sequences with zero
36
3.2.2 Primitive Construction II
Theorem 3.2 : For M ≥ 4, there exists an (M, 0, k, kl, kr) code of length n =
kl + kr + 2k such that its rate in bits/symbol is
R = log2{Mkl+kr+2k−4(M − 1)(M3 +M −M−1 − 1)}/n, (3.4)
where kl = dk/2e and kr = k − kl.
Proof : We will construct all the distinct (M, 0, k, kl, kr) sequences of length
n = kl + kr + 2k, which are divided into four disjoint groups, denoted G1, G2, G3,
and G4 respectively, based on the (n − 1)-tuple u¯ = (u0, u1, . . . , un−2), where each
ui is an M -level symbol. Each (M, 0, k, kl, kr) sequence can be expressed as v¯ =
(v0, v1, . . . , vn−1). For G1, the symbol vkl+k−1 is an arbitrary nonzero M -level symbol
£. For G2, the symbol vkl+k−1 is 0 and the symbol vkl+k is 1. For G3, the symbol
vkl+k−1 is 0 and the symbol vkl+k is 2. For G4, the symbol vkl+k−1 is 0 and the symbol
vkl+k is 3. Based on these characteristics, we see that these four groups are disjoint.
The details of the four groups are given as follows.
G1 : The condition that (ukl−1, ukl) 6= (0,0) and (ukl+2k−2, ukl+2k−1) 6= (0,0) is re-
quired. For v¯, we set vi = ui for 0 ≤ i ≤ kl + k− 2, vkl+k−1 = £, and vi = ui−1
for kl + k ≤ i ≤ kl + kr + 2k − 1 = n− 1.
G2 : The condition that (ukl−1, ukl) = (0,0) and (ukl+2k−2, ukl+2k−1) 6= (0,0) is re-
quired. For v¯, we set vi = ui for 0 ≤ i ≤ kl − 2, vkl−1 = ukl+1, vkl = £,
vi = ui+1 for kl + 1 ≤ i ≤ kl + k − 2, vkl+k−1 = 0, vkl+k = 1, vi = ui−1 for
kl + k + 1 ≤ i ≤ kl + kr + 2k − 1.
G3 : The condition that (ukl−1, ukl) 6= (0,0) and (ukl+2k−2, ukl+2k−1) = (0,0) is re-
quired. For v¯, we set vi = ui for 0 ≤ i ≤ kl + k − 2, vkl+k−1 = 0, vkl+k =
2, vi = ui−2 for kl + k + 1 ≤ i ≤ kl + 2k − 1, vkl+2k = £, vi = ui−1 for
kl + 2k + 1 ≤ i ≤ kl + 2k + kr − 1.
G4 : The condition that (ukl−1, ukl) = (0,0) and (ukl+2k−2, ukl+2k−1) = (0,0) is re-
quired. For v¯, we set vi = ui for 0 ≤ i ≤ kl − 2, vkl−1 = ukl+1, vkl = £,
vi = ui+1 for kl + 1 ≤ i ≤ kl + k − 2, vkl+k−1 = 0, vkl+k = 3, vi = ui−1
for kl + k + 1 ≤ i ≤ kl + 2k − 2, vkl+2k−1 = ×, vkl+2k = £, vi = ui−1 for
kl + 2k + 1 ≤ i ≤ kl + 2k + kr − 1.
It can be easily checked that v¯ in any group satisfies the (M, 0, k, kl, kr) constraint.
There are
Mkl+kr+2k−1 · (M − 1)[1− 2M−2 +M−4]
38
3.3 Practical Code Constructions
In this section, we propose code constructions for (M, 0, k, kl, kr) RLL codes of length
n, for which each code sequence v¯ = (v0, v1, . . . , vn−1) is chosen based on the sequence
u¯ = (u0, u1, . . . , un−1), where vi, ui ∈ {0, 1, · · · ,M − 1} for i = 0, 1, · · · , n − 1. A
nonzero un−1 is frequently used. In such a case, we denote un−1 by un−1.
3.3.1 Practical Construction I
Let M ≥ 4 and k ≥ 2. We can construct an RLL code V consisting of (M, 0, k, kl, kr)
sequences of length n = kl + kr + 2k, which are divided into four disjoint groups,
denoted G1, G2, G3, and G4 respectively, based on u¯.
The details of the four groups are given as follows.
G1 : In case of (ukl−1, ukl) 6= (0,0) and (ukl+2k−2, ukl+2k−1) 6= (0,0), we set vi = ui for
0 ≤ i ≤ kl+k−2, vkl+k−1 = un−1, and vi = ui−1 for kl+k ≤ i ≤ kl+kr+2k−1 =
n− 1.
G2 : In case of (ukl−1, ukl) = (0,0) and (ukl+2k−2, ukl+2k−1) 6= (0,0), we set vi = ui for
0 ≤ i ≤ kl − 2 and kl ≥ 2, vkl−1 = ukl+1, vkl = un−1, vi = ui+1 for kl + 1 ≤ i ≤
kl+ k− 2, vkl+k−1 = 0, vkl+k = 1, vi = ui−1 for kl+ k+1 ≤ i ≤ kl+ kr+2k− 1.
G3 : In case of (ukl−1, ukl) 6= (0,0) and (ukl+2k−2, ukl+2k−1) = (0,0), we set vi = ui for
0 ≤ i ≤ kl+k−2, vkl+k−1 = 0, vkl+k = 2, vi = ui−2 for kl+k+1 ≤ i ≤ kl+2k−1,
vkl+2k = un−1, vi = ui−1 for kl + 2k + 1 ≤ i ≤ kl + 2k + kr − 1.
G4 : In case of (ukl−1, ukl) = (0,0) and (ukl+2k−2, ukl+2k−1) = (0,0), we set vi = ui for
0 ≤ i ≤ kl − 2 and kl ≥ 2, vkl−1 = ukl+1, vkl = un−1, vi = ui+1 for kl + 1 ≤ i ≤
kl + k − 2, vkl+k−1 = 0, vkl+k = 3, vi = ui−1 for kl + k + 1 ≤ i ≤ kl + 2k − 2,
vkl+2k−1 = 1, vkl+2k = 1, vi = ui−1 for kl + 2k + 1 ≤ i ≤ kl + 2k + kr − 1.
Theorem 3.3 : The code V consists ofMn−1(M−1) code sequences which satisfy
the (M, 0, k, kl, kr) constraint. The coding rate in bits/symbol is
R =
log2[M
n−1(M − 1)]
n
. (3.5)
Proof : For G1, we have vkl+k−1 = un−1 6= 0. For G2, we have vkl+k−1 = 0 and
vkl+k = 1. For G3, we have vkl+k−1 = 0 and vkl+k = 2. For G4, we have vkl+k−1 =
0 and vkl+k = 3. Based on these characteristics, we see that these four groups are
disjoint. In the following, we will show that the sequences in each group satisfy the
(M, 0, k, kl, kr) constraint and will compute the number of sequences in each group.
40
v¯ = (u0u1u2u5u20u6u7u8u9u1003u11u12u13u14u1511u18u19).
There are 420 · 3− 2·418 · 3 + 416 · 3 distinct sequences in G1, 418 · 3− 416 · 3 distinct
sequences in G2, 4
18 · 3− 416 · 3 distinct sequences in G3, and 416 · 3 distinct sequences
in G4. The total number of sequences in this RLL code is 4
20 ·3. Hence, the code rate
R = log2(4
20 · 3)/21 ≈ 1.980236 bits/symbol. The efficiency is 1.980236/1.999983 ≈
99.01264 %. ¤
Encoding and Decoding : Let P be a message to be encoded, where P =
0, 1, · · · ,Mn−1(M − 1) − 1. The encoding of V is implemented by the following
procedure.
1) Let P ′ = P + Mn−1. Then, P ′ ∈ {Mn−1,Mn−1 + 1, · · · ,Mn − 1}.
2) Find the representation of P ′ in the base of M , i.e.,
P ′ = u0 + u1·M + u2·M2 + · · ·+ un−1·Mn−1. (3.6)
Note that un−1 is nonzero and can be denoted by un−1.
3) Map u¯ into v¯ according to the conditions of G1, G2, G3 and G4 for Construction
I.
The decoding of v¯ into the message P is implemented by the following procedure.
1) If vkl+k−1 6= 0, then v¯ is in G1. If vkl+k−1 = 0 and vkl+k = i, then v¯ is in Gi+1, i
= 1, 2, and 3.
2) According to rule of Gi, find the associated u¯ from v¯.
3) Obtain P ′ by (3.6). The message is P = P ′ - Mn−1.
3.3.2 Practical Construction Iext
For Construction I, the message P is an integer in the range of {0, 1, · · · ,Mn−1(M −
1) − 1}. In case that the message is in the form of a binary sequence, then the
mapping from the message to u¯ can not be implemented. Hence, we need to modify
Construction I to Construction Iext.
Let V be a code of length n designed according to Construction I. Let V L be the
code of length Ln, in which each code sequence is in the form of (v¯0, ..., v¯`, · · · , v¯L−1),
where v¯` ∈ V . There are [Mn−1(M − 1)]L code sequences in V L. For encoding from
binary message sequences, we consider a subset of V L, denoted V ext, which consists
of 2Q sequences, where Q = blog2[Mn−1(M − 1)]Lc. The coding rate will be reduced
to
R =
blog2[Mn−1(M − 1)]Lc
Ln
. (3.7)
42
Table 3.1: The 6-bit input/4-symbol output look-up table for Example 3.4.
Binary Quaternary
b0,40 b0,41 b1,40 b1,41 b2,40 b3,40 u0,20 u1,20 u2,20 u3,20
0 0 0 0 0 0 1 1 1 1
0 0 0 0 0 1 1 1 1 2
0 0 0 0 1 0 1 1 1 3
0 0 0 0 1 1 1 1 2 1
0 0 0 1 0 0 1 1 2 2
0 0 0 1 0 1 1 1 2 3
o o
1 1 1 0 1 0 3 3 2 1
1 1 1 0 1 1 3 3 2 2
1 1 1 1 0 0 3 3 2 3
1 1 1 1 0 1 3 3 3 1
1 1 1 1 1 0 3 3 3 2
1 1 1 1 1 1 3 3 3 3
M allows more room for RLL code construction. In the following, we will show an
(M, 0, k, kl, kr) RLL code construction forM ≥ 4, which can achieve better efficiency.
3.3.3 Practical Construction II
Let M ≥ 4, kl ≤ 4, kr ≤ 3 and k ≥ 3. We can construct an RLL code V consisting
of (M, 0, k, kl, kr) sequences of length n = kl + kr + 2k − 2, which are divided into
nine disjoint groups, denoted GA1, GA2, GA3, GB1, GB2, GB3, GC1, GC2, and GC3
respectively, based on u¯. The details of the nine groups are given as follows.
GA1 : In case of un−1 = un−1, (u1, · · · , ukl) 6= (0, · · · , 0) and (un−2−kr , · · · , un−3) 6=
(0, · · · , 0), set vi = ui for 0 ≤ i ≤ kl + k − 3, vkl+k−2 = un−1, and vi = ui−1 for
kl + k − 1 ≤ i ≤ kl + kr + 2k − 3 = n− 1.
GA2 : In case of un−1 = un−1, u1 = · · · = ukl = 0, set v0 = u0 for kl ≥ 1, vi = ui+kl
for 1 ≤ i ≤ kl − 1 and kl ≥ 1, vkl = 1, vi = ui+kl−1 for kl + 1 ≤ i ≤ kl + k − 3,
vkl+k−2 = 0, vkl+k−1 = 0, vkl+k = un−1, vi = ui for kl + k + 1 ≤ i ≤ kl + 2k − 4,
vkl+2k−3 = 1, and vi = ui−1 for kl + 2k − 2 ≤ i ≤ kl + kr + 2k − 3 = n− 1.
GA3 : In case of un−1 = un−1, (u1, · · · , ukl) 6= (0, · · · , 0) and un−2−kr = · · · = un−3
= 0, set vi = ui for 0 ≤ i ≤ kl − 1 and kl ≥ 1, vkl = 1, vi = ui−1 for kl + 1 ≤
i ≤ kl + k − 3, vkl+k−2 = 0, vkl+k−1 = 1, vi = ui−3 for kl + k ≤ i ≤ kl + 2k − 4,
44
GB1, we have vkl+k−2 = 0 and vkl+k−1 = 2. For GB2, we have vkl = 2, vkl+k−2 = 0,
and vkl+k−1 = 0. For GB3, we have vkl = 2, vkl+k−2 = 0, and vkl+k−1 = 1. For GC1,
we have vkl+k−2 = 0 and vkl+k−1 = 3. For GC2, we have vkl = 3, vkl+k−2 = 0 and
vkl+k−1 = 0. For GC3, we have vkl = 3, vkl+k−2 = 0 and vkl+k−1 = 1. Based on these
characteristics, we see that these nine groups are disjoint. In the following, we will
show that the sequences in each group satisfy the (M, 0, k, kl, kr) constraint and will
compute the number of sequences in each group.
GA1 : (i) For k ≥ 3, we have vi = ui for 0 ≤ i ≤ kl + k− 3 ≤ kl. Hence, we have (v1,
· · · , vkl) = (u1, · · · , ukl) 6= (0, · · · , 0). Hence, there are at most kl zeros from
v0 to vkl . Since vkl+k−2 = un−1, there are at most k zeros from v1 to vkl+k−2 for
kl ≤ 4. (ii) For k ≥ 2, we have kl + k − 2 ≤ n − 2 − kr and hence (vn−1−kr ,
· · · , vn−2) = (un−2−kr , · · · , un−3) 6= (0, · · · , 0). There will be at most k zeros
from vkl+k−2 to vn−2 (for kr ≤ 3) and at most kr zeros from vn−1−kr to vn−1.
(iii) In GA1, we encode u¯ into v¯, where un−1 6= 0, (u1, · · · , ukl) 6= (0, · · · , 0)
and (un−2−kr , · · · , un−3) 6= (0, · · · , 0). Hence, the number of sequences in GA1
is Mn−1(M − 1) - Mn−1−kl(M − 1) - Mn−1−kr(M − 1) + Mn−1−kl−kr(M − 1).
GA2 : (i) Since vkl = 1 and vkl+k = un−1, there will be at most kl zeros from v0 to vkl
and at most k − 1 zeros from vkl to vkl+k. (ii) Since vkl+2k−3 = 1, there will be
at most k − 4 zeros from vkl+k to vkl+2k−3 and at most kr zeros from vkl+2k−3
to vn−1. (iii) In GA2, we encode u¯ into v¯, where un−1 6= 0, (u1, · · · , ukl) =
(0, · · · , 0). Hence, the number of sequences in GA2 is Mn−1−kl(M − 1).
GA3 : (i) Since vkl = 1 and vkl+k−1 = 1, there will be at most kl zeros from v0 to vkl
and at most k − 2 zeros from vkl to vkl+k−1. (ii) Since vkl+2k−3 = un−1, there
will be at most k − 3 zeros from vkl+k−1 to vkl+2k−3 and at most kr zeros from
vkl+2k−3 to vn−1. (iii) In GA3, we encode u¯ into v¯, where un−1 6= 0, (u1, · · · ,
ukl) 6= (0, · · · , 0) and (un−2−kr , · · · , un−3) = (0, · · · , 0). Hence, the number of
sequences in GA3 is M
n−1−kr(M − 1) - Mn−1−kl−kr(M − 1).
GB1 : (i) Since (v2, · · · , vkl) = (u2, · · · , ukl) 6= (0, · · · , 0) and vkl+k−1 = 2, there will
be at most kl zeros from v0 to vkl and at most k zeros from v2 to vkl+k−1 for
kl ≤ 4. (ii) Since (vn−1−kr , · · · , vn−3) = (un−3−kr , · · · , un−5) 6= (0, · · · , 0), there
will be at most k zeros from vkl+k−1 to vn−3 (for kr ≤ 5) and no more than kr
zeros from vn−1−kr to vn−1. (iii) In GB1, we encode u¯ into v¯, where un−2 = un−1
= 0, (u2, · · · , ukl) 6= (0, · · · , 0) and (un−3−kr , · · · , un−5) 6= (0, · · · , 0). Hence,
the number of sequences in GB1 is M
n−2 - Mn−1−kl - Mn−1−kr + Mn−kl−kr .
GB2 : (i) Since vkl = 2 and vkl+k = 2, there will be at most kl zeros from v0 to vkl
and at most k − 1 zeros from vkl to vkl+k. (ii) Since vkl+2k−3 = 2, there will be
at most k− 4 zeros from vkl+k to vkl+2k−3 and at most kr zeros from vkl+2k−3 to
46
The decoding of v¯ into the message P is implemented by the following procedure.
1) According to vkl , vkl+k−2, and vkl+k−1, classify whether v¯ is in GA1 ∪GA2 ∪GA3 or
in GB1 ∪GB2 ∪GB3 or in GC1 ∪GC2 ∪GC3.
2) Now that we find the union of groups Gi1∪Gi2∪Gi3, i = A,B,C for v¯. According
to rule of Gi1 ∪Gi2 ∪Gi3, we can find the associated u¯ and the associated P .
Example 3.5 : We can design a 4-level RLL code V consisting of (M, 0, k, kl, kr)
= (4, 0, 7, 4, 3) of length n = 19 using in Construction II. Let
u¯ = (u0u1u2u3u4u5u6u7u8u9u10u11u12u13u14u15u16u17u18). The nine groups are as fol-
lows.
GA1 : For (u1u2u3u4) 6= (0, 0, 0, 0) and (u14u15u16) 6= (0, 0, 0), u18 = u18 6= 0, set
v¯ = (u0u1u2u3u4u5u6u7u8u18u9u10u11u12u13u14u15u16u17).
GA2 : For (u1u2u3u4) = (0, 0, 0, 0), u18 = u18 6= 0, set
v¯ = (u0u5u6u71u8u9u10u1100 u18u12u13u141u15u16u17).
GA3 : For (u1u2u3u4) 6= (0, 0, 0, 0) and (u14u15u16) = (0, 0, 0), u18 = u18 6= 0, set
v¯ = (u0u1u2u31u4u5u6u701u8 u9u10u11 u18u12u13u17).
GB1 : For (u2u3u4) 6= (0, 0, 0) and (u13u14) 6= (0, 0), u17 = u18 = 0, set
v¯ = (u0u1u2u3u4u5u6u7u802u9u10u11u12u13u14u15u16).
GB2 : For (u2u3u4) = (0, 0, 0), u17 = u18 = 0, set
v¯ = (u0u1u5u62u7u8u9u10002u11u12u132u14u15u16).
GB3 : For (u2u3u4) 6= (0, 0, 0) and (u13u14) = (0, 0), u17 = u18 = 0, set
v¯ = (u0u1u2u32u4u5u6 u701 u8u9u10u112u12u15u16).
GC1 : For (u2u3u4) 6= (0, 0, 0) and u13u14 6= (0, 0), u17 = 1, u18 = 0, set
v¯ = (u0u1u2u3u4 u5u6u7u803 u9u10u11u12u13u14u15u16).
GC2 : For (u2u3u4) = (0, 0, 0), u17 = 1, u18 = 0, set
v¯ = (u0u1u5u63u7u8u9u10003u11u12u133u14u15u16).
GC3 : For (u2u3u4) 6= (0, 0, 0) and (u13u14) = (0, 0), u17 = 1, u18 = 0, set
v¯ = (u0u1u2u33u4u5u6 u701u8u9u10u113u12u15u16).
There are 418 · 3 sequences in GA1 ∪ GA2 ∪ GA3; 417 sequences in GB1 ∪ GB2 ∪ GB3;
417 sequences in GC1 ∪GC2 ∪GC3. In total, there are 417 · 14 sequences of length 19.
The rate is R = log2(4
17 · 14)/19 ≈ 1.989861. The efficiency is 1.989861/1.999983 ≈
99.49389 % ¤
3.3.4 Practical Construction IIext
In case that the message is in the form of a binary sequence, we need to modify
Construction II to Construction IIext.
Let V be a code of length n designed according to Construction II. Let V L be the
code of length Ln, in which each code sequence is in the form of (v¯0, ..., v¯`, · · · , v¯L−1),
48
(c) Suppose that W` = M(M − 1) + 1. Set u`,n−2 = 1, u`,n−1 = 0. Then, we encode
u¯` into v¯` according to the rule of GC1 ∪GC2 ∪GC3.
Then, we have v¯ext = (v¯0, v¯1, . . ., v¯`, . . ., v¯L−1) as the RLL sequence encoded from
(b0, b1, · · · , bL(n−2)p+q−1).
The decoding is a simple reverse operation of the encoding. Let v¯ext be the RLL
sequence for decoding. By checking vkl , vkl+k−2, and vkl+k−1, we can tell the group
(one of the nine groups, i.e., GA1, GA2, GA3, GB1, GB2, GB3, GC1, GC2, GC3) to which
v¯` belongs.
i) If v¯` is in GC1 ∪GC2 ∪GC3, then W` = M(M − 1) + 1.
ii) If v¯` is in GB1 ∪GB2 ∪GB3, then W` = M(M − 1).
iii) If v¯` is in GA1∪GA2∪GA3, then we can retrieve (u`,n−2, u`,n−1) from v¯`. We then
have W ′` = u`,n−1M + u`,n−2 and W` = W
′
` - M .
With W`, 0 ≤ ` ≤ L − 1, we can compute IBR according to (3.15). Then, we
can recover (bL(n−2)p, · · · , bL(n−2)p+q−1), the binary representation of IBR. With the
knowledge of the group to which v¯` belongs, we can also recover (u`,0, u`,1, · · · , u`,n−3)
for 0 ≤ ` ≤ L − 1. Then, we can find (b0, b1, · · · , bL(n−2)p−1). Note that no look-up
table is needed in the encoding and decoding.
Example 3.6 : Suppose that we employ Example 3.3 and use L = 4 blocks for
encoding. Remember that n = 19. In addition, log2M = p = 2, and blog2{M(M −
1) + 2}Lc = q = 15. For the integer IBR, we have 0 ≤ IBR ≤ 215 − 1. According
to equation (3.15), the integer IBR = W3 · 143 + W2 · 142 + W1 · 14 + W0, where
0 ≤ W` ≤ 13, for ` = 0, 1, 2 and 0 ≤ W3 ≤ 11. The code rate is (34 · 4 + 15)/(19 · 4)
≈ 1.986842 (bits/symbol), the efficiency is 1.986842/1.999983 ≈ 99.34294 %. We
see that this practical realization of (4, 0, 7, 4, 3) code with low encoding/decoding
complexity has coding rate approaching the capacity and the efficiency is very close
to 1. ¤
The coding rates of some (M, 0, k, kl, kr) codes obtained from Construction II and
Construction IIext respectively, with M = 4 and n = 2k + kl + kr − 2 for various k
are listed in Tables 3.2 and 3.3 respectively. We can see that the proposed (M, 0, k)
code designs are efficient for a wide range of k. Note that for binary (0, k) code, its
capacity can not exceed 1 bit/symbol. Hence, advantage of the proposed (M, 0, k)
block code over the binary (0, k) block code is obvious.
50
length n listed in Table 3.3, we see that increasing k will result in an increased n and
hence an increased αBURST .
We need to use an efficient error-correcting code (ECC) to combat the combination
of random errors and bursts. In this section, we consider the joint effect of ECC
and the proposed M -level RLL code over a precoded partial response channel and
a precoded optical recording channel. We consider two systems. The first is the
classical ECC-RLL system, for which the the ECC encoding is followed by the RLL
coding. The second is the RLL-ECC system [61], [69], [7], [73], for which the RLL
encoding is followed by the ECC encoding. For each system, the RLL code obtained
from Construction IIext with L = 4, n = 2k+ kl+ kr − 2 is used. We use an M -level
PLM precoder, which uses {vi} as input and {zi} as output, where i is the time index,
the relation between {vi} and {zi} is given by
zi = vi + zi−1 (mod M). (3.16)
In each system, there is a signal mapper which maps the M -level (M -ary) symbol zi
into an M -level pulse amplitude modulation (PAM) signal z˜i. Assuming that M is
an even integer, we have z˜i ∈ {−(M − 1)A, −(M − 3)A, · · · , (M − 3)A, (M − 1)A},
where A is a constant.
For the classes of partial response channels, the general family of PR polynomials
are given by the equation
P (D) = (1−D)(1 +D)m, (3.17)
where m = 1, 2, 3, . . ., is chosen according to the desired channel response, data
rate (density) and noise characteristics. We consider the PR channel represented by
1 + 2D + 2D2 + D3 and 1 + 2D + 2D2 + 2D3 + D4, denoted as PR(1, 2, 2, 1) and
PR(1, 2, 2, 2, 1), respectively. For simplicity, we assume that the output of the PR
channels will be corrupted by additive white Gaussian noise (AWGN), although in
the optical recording channel, the noise model should be more complicated.
We also consider the optical recording channel as presented in [35], for which the
impulse response is
f(t) =
2
ST
√
pi
exp{−( 2t
ST
)2}, (3.18)
and the transition response g(t) is the convolution of
∏
(t) and f(t), where
∏
(t)
equals 1 for 0 ≤ t ≤ T and equals 0 otherwise. The output signal of the optical
recording channel is
y(t) =
∞∑
i=−∞
z˜ig(t− (i+∆i)T ) + n(t), (3.19)
52
state of the channel represented by g(iT ). Furthermore, we write M0 = βN0. In the
simulation, we consider β = 0 and 0.15 respectively. Note that for β = 0, there is no
jitter noise.
3.4.1 ECC-RLL System
The system under consideration is shown in Fig. 3.1. A sequence of information bits
is first encoded by the Reed-Solomon (RS) encoder. Then, its output is sequentially
processed by an M -level RLL encoder, an M -level pulse length modulation (PLM)
precoder, an M -level signal mapper to result in M -level signals which will be used
as input to the partial response channel or optical recording channel. The output of
the channel is processed by anM -level MAP (maximum a posteriori) detector for the
precoded partial response channel or precoded optical recording channel, an M -level
RLL decoder, and finally an RS decoder to retrieve the information bits.
ECC
Encoder
M-level
RLL
Encoder
M-level
PLM
Precoder
Partial
Response/
Optical
Recording
Channel
M-level MAP
 Precoded
Channel
Detector
M-level
RLL
Decoder
ECC
Decoder
User
bits
Decoded
bits
M-level
Signal
Mapping
Figure 3.1: An ECC-RLL multilevel optical recording system.
For the RLL code, we consider (M,d, k)=(4, 0, 4) code with n = 10 and rate R
≈ 1.9750 bits/symbol, (M,d, k)=(4, 0, 7) code with n = 19 and rate R ≈ 1.9868
bits/symbol, (M,d, k)=(4, 0, 10) code with n = 28 and rate R ≈ 1.9910 bits/symbol
respectively, which are given in Tables 3.3. The largest lengths of the associated
αBURST ’s are 12 bits, 30 bits and 48 bits respectively, while the largest lengths of
the associated βBURST ’s are all equal to q = 15.
To provide the error-correcting capability to tackle the error burst in the M -
level RLL code of length Ln log2M -bit symbols, we consider the (511, 455) Reed-
Solomon code based on GF (29), which is equivalently a (4599,4095) binary code
54
16 17 18 19 20 21 22
10−6
10−5
10−4
10−3
10−2
10−1
Eb/No (dB)
BE
R
R=1.9750  4−ary (0,4) RLL Code
R=1.9868  4−ary (0,7) RLL Code
R=1.9910  4−ary (0,10) RLL Code
RS Code + R=1.9750 4−ary (0,4) RLL Code
RS Code + R=1.9868 4−ary (0,7) RLL Code
RS Code + R=1.9910 4−ary (0,10) RLL Code
Figure 3.2: Simulation results of a coded 4-Level RLL (0, k) constraints over
PR(1, 2, 2, 1) partial response channel.
56
M -level signals which will be used as input to the partial response channel or optical
recording channel. The output of the channel is processed by an MAP detector for the
precoded partial response channel or precoded optical recording channel, a uniform
deinterleaver, a non-binary LDPC decoder, and an M -level RLL decoder to retrieve
the recorded information bits. The RLL-ECC system is expected to significantly
reduce the error propagation from the RLL decoder to the ECC decoder. However,
the error propagation from the input of the RLL decoder to its output still exists.
M-level
RLL
Encoder
GF(M)
LDPC
Encoder
M-level
PLM
Precoder
Partial
Response/
Optical
Recording
Channel
M-level MAP 
 Precoded
Channel
Detector
GF(M)
LDPC
Decoder
M-level
RLL
Decoder
User
bits
Decoded
bits
M-level
Signal
Mapping
Uniform
Interleaver
For M-level 
RLL
Uniform
Deinterleaver
For M-level 
RLL
Figure 3.4: An RLL-ECC multilevel optical recording system.
From Tables 3.3, we have (4, 0, 3) code with n= 7 and rateR≈ 1.9642 bits/symbol,
(4, 0, 6) code with n = 16 and rate R ≈ 1.9843 bits/symbol. With M = 4, k
= 4, h = 1 and k − h = 3, each (4, 0, 3) sequence will be converted into a se-
quence satisfying the (4, 0, 4) constraint after passing through the systematic ECC
and the uniform interleaver. With M = 4, k = 7, h = 1 and k − h = 6, each
(4, 0, 6) sequence will be converted into a sequence satisfying the (4, 0, 7) constraint
after passing through the systematic ECC and the uniform interleaver [73]. Fol-
lowing the progressive edge-growth LDPC code construction [82] and non-binary
LDPC [62] code construction, a PEG non-binary LDPC code is obtained for this
system. Specifically, we have the column weight and row weight (t, s) = (3, 27)
(2297, 2048) LDPC code over GF (4). The overall system rate of (4, 0, 4) and (4, 0, 7)
are 1.9642*(2048/2297) ≈ 1.7512 and 1.9843*(2048/2297) ≈ 1.7691. Note that for
the ECC-RLL which uses the (511, 455) Reed-Solomon code over GF (29) concate-
nated with the (M,d, k)=(4, 0, 4) and (M,d, k)=(4, 0, 7) RLL codes have rate of
1.9750*(455/511) ≈ 1.7585 and 1.9868*(455/511) ≈ 1.7690, respectively. We con-
sider hard decoding and soft decoding respectively for the non-binary LDPC code.
From the simulation results given in Fig. 3.5, we see that using the the second
system which is the RLL-ECC system over partial response channel can have better
BER as compared to using the first system which is the ECC-RLL system. This
58
5 5.5 6 6.5 7 7.5 8 8.5 9
10−6
10−5
10−4
10−3
10−2
10−1
Eb/No (dB)
BE
R
(A)
(B)
(C)
(D)
(E)
(F)
Figure 3.6: Simulation results of an optical recording system with AGWN noise only
(i.e., β = 0). (A) RS Code + 4-level (0,4) RLL Code; (B) RS Code + 4-level (0,7) RLL
Code; (C) 4-level (0,3) RLL Code + LDPC Code with hard decoding, (0,4) constraint;
(D) 4-level (0,6) RLL Code + LDPC Code with hard decoding, (0,7) constraint; (E) 4-
level (0,3) RLL Code + LDPC Code with soft decoding, (0,4) constraint, 10 iterations;
(F) 4-level (0,6) RLL Code + LDPC Code with soft decoding, (0,7) constraint, 10
iterations.
of eliminating the error propagation from RLL to ECC which may occurs in the
ECC-RLL system.
Note that using the non-binary LDPC code with soft decoding in the RLL-ECC
system over optical recording channel can provide very excellent error performance
for either β = 0 or β = 0.15, where the soft output of the MAP precoded channel
detector is required and 10 iterations are used for the decoding. This result shows the
powerful error-correcting capability of the non-binary LDPC code with soft decoding
even if the noise is not restricted to the AWGN noise.
For this RLL-ECC system over optical recording channel, the BER curves for the
(M, 0, k) = (4, 0, 4) constraint are better than the curves for the (4, 0, 7) constraint.
Note that, in the RLL encoding/decoding for this system, (M, 0, k) = (4, 0, 3) code
will be used for the (4, 0, 4) constraint and (4, 0, 6) code will be used for the (4, 0, 7)
60
of encoding and decoding with low complexity, code constructions with low com-
plexity of encoding and decoding can be obtained by modifying these primitive code
constructions. We then propose two practical code constructions for (M, 0, k, kl, kr)
run-length-limited codes of finite length. The code obtained from any of the proposed
constructions has coding rate very close to the capacity. In addition, we propose varia-
tions of the proposed constructions to achieve the merit of low complexity of encoding
and decoding.
When an error-corrupted RLL sequence is applied to the input of an RLL decoder,
errors at some positions may cause serious error propagation. We analyze the possible
error propagation of the (M, 0, k) codes proposed in Construction IIext. In particular,
the numerical values of error propagation of the (M, 0, k) = (4, 0, 3), (4, 0, 4), (4, 0, 6),
(4, 0, 7) and the (4, 0, 10) RLL codes are provided. The error propagation of the
(M, 0, k) RLL code is more serious than that of the (M, 0, k′) RLL code for k > k′.
We consider the application of the constructed RLL codes to the partial response
channel corrupted with AWGN noise and optical recording channel corrupted by the
jitter noise and the AWGN noise. Simulation results show that, in the ECC-RLL
system, using the (4, 0, 4) code can achieve better BER as compared to using the
(4, 0, 7) code. Simulation results also show that, in the RLL-ECC system, using the
(4, 0, 3) RLL code for the (4, 0, 4) constraint can achieve better BER as compared to
using the (4, 0, 6) RLL code for the (4, 0, 7) constraint.
For applications to the partial response channel corrupted with AWGN noise and
optical recording channel corrupted by the jitter noise and the AWGN noise, the
channel errors may cause significant error propagation within the (M, 0, k) code se-
quence. Our study shows that applying a Reed-Solomon encoder followed by the
RLL encoder to the system can somewhat alleviate the problem of the channel errors
and error propagation. However, by arranging the RLL encoder followed by a non-
binary LDPC encoder and a uniform interleaver, the effect of channel errors and the
associated error propagation can be greatly reduced, especially when soft decoding is
used.
62
by a more strict RLL coding for the message part of the ECC and the parity part of
the ECC is uniformly inserted back to the message part to result in the RLL sequence
with less strict constraint. Using ECC followed by the RLL coding, referred as the
ECC-RLL concatenation, will usually affect either the error-correcting capability of
the ECC or complicate the decoding operation. In [74], a modified ECC-RLL version
is proposed by flipping the bits in ECC codeword to satisfy the RLL constraint and
the flipped bits are removed by the error-correcting capability of the ECC code. In
[75], a multiple-candidate technique is used to reduce the number of flipped bits.
In this chapter, we consider the ECC-RLL concatenation and employ the iterative
passing of the soft information between the ECC decoder and the RLL detector.
The soft iterative decoding for the binary case has been discussed in [79]. It will
be interesting to investigate the performance for the ternary recording system using
the soft iterative decoding. In this chapter, we propose two soft iterative decoding
algorithms for the ECC-RLL concatenation recording systems. The difference of the
two proposed algorithms lies in the trellis representations of the concatenation of the
RLL encoder, PLM (pulse length modulation) precoder, the partial response channel.
We will compare the decoding performance of the proposed decoding algorithms for
the ECC-RLL systems to an efficient RLL-ECC algorithm using the techniquein [73].
The rest of this chapter is organized as follows. In section 4.2, we describe the
basic LDPC coded recording systems. The proposed soft decoding algorithms are
given in section 4.3. Simulation results and comparison are shown in section 4.4.
Conclusions are provided in section 4.5.
4.2 Basic LDPC Coded Recording Systems
4.2.1 PLM Precoded Partial Response Channels
In the recording, a PLM precoder [80] followed a signal mapper is used. An M -ary
PLM precoder takes an M -ary symbol sequence {xi} as input and an M -ary symbol
sequence {yi} as output, where the relation between {xi} and {yi} the mapping is
given by
yi = xi ⊕ yi−1 (mod M). (4.1)
The signal mapper maps the M -ary symbol into an M -level pulse amplitude modu-
lation (PAM) signal so that the ternary symbol in {0, 1, 2} is mapped to a symbol
in {−1, 0, 1}. The channel between the PLM precoder and the reading output of the
recording system can be represented by a partial response (PR) channel. In this pa-
per, We use the PR channel represented by 1+D+D2+D3, denoted as PR(1,1,1,1),
for demonstration. For simplicity, we assume that the output of the PR channel will
be corrupted by additive white Gaussian noise (AWGN) only, although in the optical
64
Mod
(M)
Signal
Mapping
Signal
De-Mapping
D D DΞΞ
¦
h0 h1 hnΞΞΞ
AWGN
Channel
output
M-ary
Symbols
Figure 4.1: Equivalent form of the concatenation of the pulse length modulation
precoder, the signal mapper and the partial response channel.
LDPC
Encoder
Interleaver
Ternary
RLL Encoder
PLM
Precoded
PR
Channel
+
AWGN
De-
Interleaver
Symbol-bit
Soft
Mapping
Interleaver
MAP
(BCJR)
Precoded
Channel
Detector
LDPC
Decoder
Bit-symbol
Soft
Mapping
u v zb
)(vL
e
i
)(bLe i )(bL id )(xL jd
)(xL ja)(bL ia)(vL i)(vL iD
u c
r
a
Figure 4.2: Schematic diagram of a ternary RLL recording systems over the precoded
partial response channel with iterative decoding.
66
the present state and s be the next state. The branch connecting state s
′
and state
s is represented by a q-symbol RLL codeword (corresponding to the p-bit input [b0,
b1, · · · , bp−1]), denoted as X`, ` = 0, 1, · · · , L − 1 and the associated output of the
PR channel, denoted as z`. The RLL-PSPR trellis for M = 3 and D = 3 is shown in
Fig. 4.3. Based on r¯` = (r`,0, · · · , r`,q−1), which is the error-corrupted version of z`,
the operation of iterative passing of soft information between the LDPC decoder and
the trellis MAP detector is described as following.
ALGORITHM Using the Codeword-PSPR Trellis:
Set the index of outer iteration Uo = 1 and the a priori LLR (log-likelihood ratio)
value of the RLL codeword X`, La(X`) to ln(
1
L
).
Step 1 The MAP detector for the RLL-PSPR trellis takes r¯` and La(X`), as input to
calculate the metric of the q-symbol RLL codeword X` representing the branch
from state s
′
to state s, γt,`(s
′
, s). The γt,`(s
′
, s) is calculated by
γt,`(s
′
, s) = La(X`) +
q−1∑
i=0
ln(e
−Eb
N0
|r`,i−z`,i|2) (4.4)
where t ∈ {0, 1, · · · , B} is the index of time and Eb is the average bit energy and
N0 is the one-sided power spectral density of the AWGN. Note that an n-bit
binary LDPC codeword is encoded into a sequence of B M -ary RLL codewords.
Let max∗(y, z) = max(y, z) + ln(1 + e−|y−z|). We calculate αt in the forward
recursion and βt in the backward recursion, where
αt(s) =

0, if t = 0, s
′
= 0;
−∞, if t = 0, s′ 6= 0;
max∗[γt,`(s
′
, s)
+αt−1(s
′
)], if 1 ≤ t ≤ B.
(4.5)
and
βt(s
′
) =

ln 1
ρ
, if t = B;
max∗[γj′ ,t(s, s
′
)
+βj′+1(s)], if 0 ≤ t ≤ B − 1.
(4.6)
The a posteriori LLR of X` from s
′
to s is Ld(X`) = max
∗
X`
[γt,`(s
′
, s) + αt−1(s)
+ βt+1(s
′
)]. The a posteriori LLR of bi is Ld(bi) = max
∗
X`∈(bi=1)Ld(X`) -
max∗
Xt∈(bi=0)Ld(X`), i = 0, 1, · · · , p − 1. In each iteration, the extrinsic LLR
of bi is obtained by Le(bi) = Ld(bi) - La(bi).
68
4.3.2 Symbol-Branch Trellis
Now we consider the trellis with symbol branches, which represents the concatenation
of the PLM decoder, the signal mapper and the partial response channel. Note that
the RLL encoder is not included. Such a trellis can be referred as the symbol-PSPR
trellis. There are ρ =MD states, M outgoing branches and M incoming branches for
each state. Let s
′
be the present state and s be the next state. The branch connecting
state s
′
and state s is represented by a an M -ary symbol (corresponding to M -ary
input), denoted as X, X = 0, 1, · · · , M − 1 and the associated output of the PR
channel, denoted as z. The PSPR trellis for M = 3 and D = 3 is shown in Fig. 4.4.
Based on r, the error-corrupted version of X, the operation of iterative passing of soft
information between the LDPC decoder and the MAP detector for the RLL-PSPR
concatenation is described as following.
ALGORITHM Using the Symbol-PSPR Trellis :
Set the index of outer iteration Uo = 1 and the a priori LLR value of the RLL
symbol xj, La(xj) to ln(
1
M
).
Step 1 The MAP detector for the PSPR trellis takes rj and La(xj), as input to
calculate the symbol branch metrics, γj(s
′
, s),
γj(s
′
, s) = La(xj) + ln(e
−Eb
N0
|rj−zj |2), (4.7)
where j ∈ {0, 1, . . . , H) is the time index. Note that an n-bit binary LDPC
codeword is encoded into a sequence of H M -ary symbols. The La(xj) is the a
prior symbol LLR. For the forward recursion,
αj(s) =

0, if j = 0, s
′
= 0;
−∞, if j = 0, s′ 6= 0;
max∗[γj(s
′
, s)
+αj−1(s
′
)], if 1 ≤ j ≤ H.
(4.8)
For backward recursions,
βj(s
′
) =

ln 1
ρ
, if j = H;
max∗[γj(s, s
′
)
+βj+1(s)], if 0 ≤ j ≤ H − 1.
(4.9)
The a posteriori value of xj is, Ld(xj, g) = max
∗
xj∈g[γj(s
′
, s)+αj−1(s)+βj+1(s
′
)],
j ∈ (0, 1, . . . , H − 1), g ∈ {0, 1, . . . ,M − 1}.
Step 2 The soft-value of the symbol, Ld(xj, g), need to be converted into bit Log-
Likehood Ratio (LLR). According to the p-bit to q-symbol RLL encoding
70
table, the bit LLR for each bi is, Ld(bi) = Ld(bi = 1) − Ld(bi = 0), i =
0, 1, . . . , p − 1, where Ld(bi = 1)=max∗X`∈(bi=1)[
∑(j′+1)q−1
m=j
′
q
Ld(xm, g)], Ld(bi =
0)=max∗
X`∈(bi=0)[
∑(j′+1)q−1
m=j′q Ld(xm, g)], j
′ ∈ (0, 1, . . . , B − 1), g ∈ {0, 1, . . . ,M-
1}.
Step 3 After the de-interleaver processing, we have La(vi) =
∏−1(Le(bi)). Then, use
(La(v0), La(v1), · · · , La(vn−1)) as input to the decoder of the LDPC code Cldpc.
After Ui iterations within the LDPC decoder, the LDPC decoder generates the
a posteriori LLR for vi, denoted LD(vi) as output. The extrinsic value for the
bit vi from the LDPC decoder is obtained by Le(vi)=LD(vi)-La(vi). After the
interleaver processing, we have La(bi) =
∏
(La(vi)). The resultant sequence is
(La(b0), La(b1), · · · , La(bn−1)), which will be used in the next iteration.
Step 4 The bit-to-symbol soft mapper convertes the bit LLR to a prior bit proba-
bility, by Pr(bi = 0)=
1
1+eLa(bi)
and Pr(bi = 1)=
eLa(bi)
1+eLa(bi)
. The binary p-bit code-
word probability of X¯` is, Pr(X`) = Pr(b`,0) ·Pr(b`,1) · . . . ·Pr(b`,p−1), where ` ∈
{0, 1, . . . , L−1}. The symbol probability of xj is, Pr(xj,i)=
∑
X`∈(xj=g){Pr(X`)},
where ` ∈ {0, 1, .., L − 1}, g = {0, 1, · · · , M − 1}. Then, the a prior symbol
soft value is La(xj) = ln(Pr(xj)).
Step 5 Increase Uo by 1. If the index of iteration Uo = I, then the hard decision
of LD(vi), i = 0, 1, · · · , n − 1, is used as the final estimate of v¯. Otherwise, go
back to Step 1.
4.4 Specific Constructions and Simulation Results
In this section, we show specific LDPC coded ternary RLL recording systems de-
coded based on the codeword-PSPR trellis and symbol-PSPR trellis respectively to-
gether with the simulation results for bit error rates (BER). Here, we consider the
PR (1,1,1,1) channel. The RLL constraint is the (d, k) = (0, 3) constraint. The RLL
encoder is obtained based on Tables 4.1. Thus, the coding rate o the RLL code is
Rrll = p/q = 4/3 bits/symbol. We follow the Progressive edge-growth (PEG) LDPC
construction method [82] to find a (4608,4096) binary LDPC code with coding rate of
Recc = 0.8889. Hence, the overall coding rate is R = ReccRrll = (4/3)·0.8889 = 1.1852
bits/symbol. One inner iteration within the LDPC decoder and 20 iterations between
the MAP detector and the LDPC decoder are employed. Thus, Ui = 1 and Uo = 20.
From Fig. 4.5, we see that using the symbol-PSPR trellis will outperform using the
codeword-PSPR trellis. This phenomenon probably implies that extracting the LLR
bit information from the RLL structure alone is more accurate than extracting the
72
LLR bit information from the trellis which integrates the RLL coding and the PSPR
concatenation.
For comparison, we also show the BER performance of the LDPC coded ternary
system over the concatenation of the PLM precoder, signal mapper and the PR re-
sponse channel of the same parameters without RLL constraint. We use a rate of
11/7 bits/symbol signal mapper to convert the binary sequence into the ternary se-
quence. Although there is no RLL constraint in the signal mapper, the rate of 11/7
≈ 1.5714 is still a bit lower than the capacity of the ternary (0,3) coding which is
1.5726. In order that the overall system rate to be close to 1.1852 bits/symbol, a
(3456,2608) ternary PEG LDPC code is used. From Fig. 4.5, we note that compared
to the ternary system without RLL constraint, the proposed ternary ECC-RLL con-
catenation using the PSPR trellis can achieve BER performance which is better for
the low to medium signal-to-noise ratio (SNR) regime and is worse for the high SNR
regime.
4.5 Concluding Remarks
We have investigated the LDPC coded ternary recording systems with (0,3) constraint
through a ECC-RLL concatenation structure. Two decoding methods for the iterative
passing of soft information between the LDPC decoder and the MAP detector for
the concatenation of the combination of the RLL encoder, PLM precoder and the
partial response channel are proposed. The first is based on the trellis with codeword
branches representing the the combination of the RLL encoder, PLM precoder and
the partial response channel. The second is based on the trellis with symbol branches
representing the combination of PLM precoder and the partial response channel.
Simulation results shows that the second provides better performance. Comparison
with the system without considering the RLL constraint is also provided.
74
Bibliography
[1] B. H. Marcus, P. H. Siegel, and J. K. Wolf, ”Finite-state modulation codes for
data storage,” IEEE J. Sel. Areas Commun., vol. 10, no. 1, pp. 5-37, Jan. 1992.
[2] K. A. S. Immink, Coding Techniques for Digital Recorders. Prentice Hall, Engle-
wood Cliffs, New Jersey, 1991.
[3] K. A. S. Immink, Codes for Mass Data Storage Systems. Shannon Foundation
Publishers, 2004.
[4] P. Lee and J.K. Wolf, ”A general error-correcting code construction for run-
length limited binary channels,” IEEE Trans. Inform. Theory, vol. 35, no. 6,
pp.1330-1335, November 1989.
[5] H.H. Tang and M.C. Lin, ”A class of multilevel run-length limited trellis codes,”
Electronics Letters, vol.35, no.25, pp. 2192-2193 9th December 1999.
[6] A. J. van Wijngaarden and K. A. S. Immink, ”Maximum runlength limited codes
with error control capabilities,” IEEE J. Sel. Areas Commun., vol. 19, no. 4, pp.
602-611, Apr. 2001.
[7] Y. Han, and W.E. Ryan, ”Concatenating a structured LDPC code and a con-
strained code to preserve soft-decoding, structure, and burst correction,” IEEE
Trans. Magn., vol. 42, no. 10, pp. 2558-2560, Oct. 2006.
[8] J. Lu, and K.G. Boyer, ”Novel RLL-ECC concatenation scheme for high-density
magnetic recording,” IEEE Trans. Magn., vol. 43, no. 6, pp. 2271-2273, Jun.
2007.
[9] B. M Kurkoski, P. H. Siegel, and J. K. Wolf, ”Joint message-passing decoding of
LDPC codes and partial-response channels,” IEEE Trans. Inf. Theory, vol. 48,
no. 6, pp. 1410-1422, Jun. 2002.
[10] J. L. Fan and J. M. Cioffi, ”Constrained coding techniques for soft iterative
decoders,” in Proc. IEEE GLOBECOM, Rio De Janeiro, Brazil,1999, pp. 723-
727.
76
[24] G. Jacoby, ”Ternary 3PM magnetic recording code and system,” IEEE Trans.
Magn., MAG-17, No. 6, pp. 3326-8 1981.
[25] T. Kasami, T. Takata, T. Fujiwara, and S. Lin, ”On multilevel block codes,”
IEEE Trans. Info. Th., 37, No. 4, pp. 965-75 1991.
[26] A. Earman, ”Optical data storage with electron trapping materials using M-ary
data channel coding,” Optical Data Storage 92; Proc. SPIE, ed. D. Carlin and
D. Kay, 1663, pp. 92-103 1992.
[27] F. H. Lo, J. W. Kuo, N. H. Tseng, J. J. Ju, and D. Howe, ”Recording of multi-
level run-length-limited modulation signals on compact disc/digital versatile disc
rewritable discs,” Jpn. J. Appl. Phys., vol. 43, no. 7B, pp. 4852-4855, Jul. 2004.
[28] CA. French, G.S. Dixon, and J. Wolf, ”Results involving (d,k)- constrained M-ary
codes,” IEEE Trans. Magn., vol. 23, no. 5, pp. 3678-3680, Sept. 1987.
[29] S.W. McLaughlin, ”Five runlength-limited codes for M-ary recording channels,”
IEEE Trans. Magn., vol. 33, no. 3, pp. 2442-2450, May 1997.
[30] S. W. McLaughlin, J. Luo and Q. Xie, ”On the capacity of M-ary runlength-
limited codes,” IEEE Trans. Inform. Theory, vol. 41, pp. 1508-1511, Sept. 1995.
[31] S. W. McLaughlin, ”The construction of M-ary (d,∞) codes that achieve capacity
and have the fewest number of encoder states,” IEEE Trans. Inform. Theory,
vol. 43, pp. 699-703, Mar. 1997.
[32] H. Hu, L. F. Pan, G. S. Qi, H. Hu and D. Y. Xu, ”Study of multi-level run-length
limited photo-chromic storage,” Acta Physica Sinica, vol. 55, pp. 1759-1763,
April 2006.
[33] John L. Fan, Constrained Coding and Soft Iterative Decoding. ISBN 079237455X,
9780792374558, Springer, 2001.
[34] Sadik C. Esener ”INTRODUCTION-OPTICAL STORAGE” Published: June
1999; WTEC Hyper-Librarian.
[35] Bergmans, J.W.M., Digital Baseband Transmission and Recording. Kluwer Aca-
demic Publishers, Dovdvecht, Hingham, MA, 1996.
[36] Dennis, ”Rll modulation for multi-level recording,” Optical Data Storage Center,
University of Arizona, 1999.
78
[49] http://www.inference.phy.cam.ac.uk/mackay/codes/data.html.
[50] R. M. Tanner, ”A recursive approach to low complexity codes”, IEEE Tans.
Inform. Theory, pp. 533-547, Sept. 1981.
[51] X. Hu, E. Eleftheriou, and D. Arnold, ”Progressive edge-growth Tanner graphs,”
Global Telecommunications Conference, 2001. GLOBECOM ’01. IEEE , Volume:
2, pp. 995-1001, 25-29 Nov. 2001.
[52] X. Hu, E. Eleftheriou, and D. Arnold, ”Regular and irregular progressive edge-
growth Tanner graphs,” IEEE Trans. Inf. Theory, vol. 51, no. 1, pp. 386V398,
Jan. 2005.
[53] Sklar, B., Digital Communications: Fundamentals and Applications. Second Edi-
tion (Upper Saddle River, NJ: Prentice-Hall, 2001).
[54] Odenwalder, J. P., Error Control Coding Handbook. Linkabit Corporation, San
Diego, CA, July 15, 1976.
[55] R. W. Bauml, R.F.H. Fisher, and J. B. Huber, ”Reducing the peak-to-average
power ratio of multicarrier modulation be selective mapping,” Electronics Letters,
vol.32, no.22, pp. 2056-2057, Oct. 1996.
[56] F.J. MacWilliams and N.J.A. Sloane, The theory of error-correcting codes. Ap-
pendix A, North-Holland, Amsterdam 1983.
[57] S.ten Brink,”Convergence behavior of iteratively decoded parallel concatenated
codes,” IEEE Trans. Commun., vol.40, pp. 1727-1737, Oct. 2001.
[58] T. J. Richardson and R. Urbamke, ”The capacity of low-density parity check
codes under message-passing decoding”, IEEE Trans. Inform. Theory, vol. 47,
pp. 599-618, Feb. 2001.
[59] S. Olcer, M. Keskinoz, ”Performance of MMSE turbo equalization using outer
LDPC coding for magnetic recording channel,” IEEE International Conf. On
Commun., vol. 9, pp. 645-650, Jun. 2004.
[60] C. Douillard et al.,”Iterative correction of intersymbol interference:Turbo equal-
ization,” Eur. Trans. Telecommun., vol.6,pp.507-511,Sept.-Oct. 1995.
[61] J. L. Fan and A. R. Calderbank, ”A modified concatenated coding scheme, with
applications to magnetic storage,” IEEE Trans. Inf. Theory, vol. 44, no. 4, pp.
1565-1574, Jul. 1998.
80
[75] Z. Li and B. V. K. V. Kumar, ”Low-density parity-check codes with run length
limited (RLL) constraints,” IEEE Trans. Magn., vol. 42, no. 2, pp. 344-349, Feb.
2006.
[76] Hsin-Yi Chen, Mao-Chao Lin, and Yeong-Luh Ueng, ”Low-Density Parity-Check
Coded Recording Systems With Run-Length-Limited Constraints,” IEEE Trans.
Magn., vol. 44, no. 9, pp. 2235-2242, Sept. 2008.
[77] F. H. Lo, J. W. Kuo, N. H. Tseng, J. J. Ju, and D. Howe, ”Recording of multi-
level run-length-limited modulation signals on compact disc/digital versatile disc
rewritable discs,” Jpn. J. Appl. Phys., vol. 43, no. 7B, pp. 4852-4855, Jul. 2004.
[78] H. Hu, L. F. Pan, G. S. Qi, H. Hu and D. Y. Xu, ”Study of multi-level run-length
limited photo-chromic storage,” Acta Physica Sinica, vol. 55, pp. 1759-1763,
April 2006.
[79] John L. Fan, Constrained Coding and Soft Iterative Decoding. ISBN 079237455X,
9780792374558, Springer, 2001.
[80] Dennis, ”Rll modulation for multi-level recording,” Optical Data Storage Cen-
ter,University of Arizona, 1999.
[81] CA. French, G.S. Dixon, and J. Wolf, ”Results involving (d,k)- constrained M-ary
codes,” IEEE Trans. Magn., vol. 23, no. 5, pp. 3678-3680, Sept. 1987.
[82] X. Hu, E. Eleftheriou, and D. Arnold, ”Progressive edge-growth Tanner graphs,”
Global Telecommunications Conference, 2001. GLOBECOM ’01. IEEE , Volume:
2 ,pp. 995-1001, 25-29 Nov. 2001.
82
而飛回台北。我搭的兩點三十五分飛機準時起飛，起飛之後飛機非常顛簸有如
搭雲霄飛車，空服人員也只能綁在坐椅上以避免受傷。抵達花蓮機場時非常幸
運地雨勢稍歇，飛機得以降落。過沒一會飛機再度起飛前往石垣島。有一陣子
見到了陽光，以為飛航將漸入佳境，那知道其後又是一連串的亂流，填寫入境
表格都很困難。好不容易挨到了石垣島機場，飛機在大雨中順利降落。來到旅
館後開始雷聲隆隆，有些由琉球那霸飛來石垣島參與 AEW6的人員因為大雷雨
而導致飛機延誤。後來得知蘇花公路因梅姬颱風加上東北季風影響降下超大豪
雨造成嚴重傷亡，才聯想起這一趟台北花蓮石垣島之行還真的有些冒險呢。 
 
這一次參與 AEW6的教授有許多是參加了在台中舉行的 ISITA2010/ISSSTA2010
之後再飛來石垣島的。Prof. Kingo Kobayashi 為 ISITA2010/ISSSTA2010邀請的
keynote speaker之一。Prof. Han Vinck 及 Prof. Te Sun Han 皆為消息理論界之重
量級學者，Prof. Han Vinck是早期 AEW之推手而 Prof. Te Sun Han是 recipient of 
the 2010 Information Theory Society Claude E. Shannon award。Prof. Ulrich Spiedel
則為 ISITA2008之 General Chair。Prof. Hiroyoshi Morita則是以這次 AEW6之主
要負責人。除了 Prof. Kingo Kobayashi先飛回東京再去石垣島。其他人多是由
桃園機場先飛到那霸機場然後再轉飛石垣島。原先我也打算以這樣路線前往石
垣島，可以搭較大型的飛機成行。後來發現如此搭機，其機票價格是搭復興包
機票價三倍以上，只好改搭復興航空的小飛機了。原先我們曾經邀請 Prof. 
Richard E. Blahut來 ISITA2010/ ISSSTA2010給一個特別演講。Prof. Blahut是兼
具消息理論，編碼理論及信號處理領域之大師，我們對於是他所擬定的多使用
者消息理論講題期望很深。而 Prof. Blahut原也打算搭復興包機去石垣島參加
AEW6，可惜 Prof. Blahut後來因為家中有緊急事務而取消了 ISITA2010/ 
ISSSTA2010之行及也取消了 AEW6之行。Prof. Ning Cai是 network coding方
面之專家，曾經與 Robert Li, Raymond Yeung共同發表得到 2005 Information 
Theory Society Award的論文”Linear Network Coding” 。Prof. Ning Cai 沒有去台
中參加 ISITA2010/ ISSSTA2010，但是卻來了 AEW6，給了一個題目為”Adaptive 
randomized convolutional network coding”之演講。Prof. Ning Cai 曾經與我共同
擔任 CinaCom 2009中 Information Theory and Coding Symposium 的 Symposium 
Co-Chairs，在電郵中有許多溝通來往，但是一直沒有機會碰面，沒想到卻會在
這個小型研討會見到面。AEW6的各個演講中，我最感興趣的是 Prof. Hajime 
Matsui講的”On Polynomial Generator Matrices of Generalized Quasi-Cyclic 
Codes” 。Quasi-Cyclic Codes已經是 Low-Density Parity Check (LDPC) Block 
Codes 或 LDPC Convolutional Codes系列中很受重視的一種設計基礎，而這個
演講內容所提到的以 polynomial型式的研究有助於尋找具有更優越編解碼性能
的 LDPC Codes。 
 
我所給的演講題目是”The Separation Capability of Cosets of Random-Like 
http://morita.appnet.is.uec.ac.jp/myHome/homu/entori/2009
/11/10_CFP_of_AEW2010_files/CFP-AEW6_latest.pdf 
 
I am looking forward to seeing you at Ishigaki.  
 
Best regads, 
 
Hiro 
 
 
國科會補助計畫衍生研發成果推廣資料表
日期:2011/10/07
國科會補助計畫
計畫名稱: 用於記錄系統之先進編碼研究
計畫主持人: 林茂昭
計畫編號: 97-2221-E-002-145-MY3 學門領域: 通訊
無研發成果推廣資料
No. 1, pp. 95-104, 
January 2010. 
研究報告/技術報告 0 0 100%  
研討會論文 1 0 100% 
Shih-kai Lee, 
Hsin-Yi Chen, 
Mao-Chao Lin, 
Tien-Hui Chen, 
Hong-Fu Chou, 
Yu-Hsien Ku, ’On 
Soft Iterative 
Decoding For Ternary 
Recording Systems 
With RLL 
Constraints,’ 
ISITA2010, 
Taichung, Oct. 
17-20, 2010 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
其他成果 
(無法以量化表達之
成果如辦理學術活
動、獲得獎項、重要
國際合作、研究成果
國際影響力及其他協
助產業技術發展之具
體效益事項等，請以
文字敘述填列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
科 
教 
處 
計 
畫 
加 
填 
項 電子報、網站 0  
