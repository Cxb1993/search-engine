proposed text mining techniques. The developed scheme 
as well as techniques integrate the entire 
intelligence management functionality and establish 
the collection and processing stages of OSINT 
management. The techniques for the analysis, 
production, and dissemination of the OSINT were also 
developed which emphasizes on the intelligence mining 
techniques. The major contribution of this project is 
that we developed high-order mining techniques for 
OSINT, which will benefit domains like national 
security, company＇s growth, and personal knowledge 
management. The result of this research has been 
presented in IEEE International Symposium on IT in 
Medicine and Education. 
 
英文關鍵詞： Open Source Intelligence, Text Mining, Self-
Organizing Map 
 
 2 
 
中文摘要 
 
情報蒐集與分析對一國家的安全與企業成長皆是重要的因素之一。傳統之情報管理流程，自蒐集
開始至發佈為止，大多是隱密且需要大量的人力介入。其缺陷為情報來源較少且具危險性。因此近年
來公開來源情報(Open Source Intelligence, OSINT)漸漸成為蒐集與分析之重要管道。與傳統情報不同之
處為其之情報來源為公開的，因此具有大量性與公開性。然亦具有情報內容難以驗證與不相容性之問
題。目前的公開來源情報之相關處理主要仍以人力進行為主，需仰賴大量的專業人力並耗費大量之時
間。自動化公開來源情報處理便成為未來之趨勢。目前雖已存在公開來源情報之輔助處理系統，然而
其功能性與自動化程度皆未臻成熟。 
本計畫以文本探勘技術為核心建立一自動化公開來源情報處理流程與相關技術。本研究完成公開
來源情報之規劃、蒐集與處理程序，並發展相關之情報探勘技術。本計畫之完成，在學術上之主要貢
獻為發展高階之情報探勘技術。此等技術發展與平台建立，將對國家安全、企業發展、乃至個人知識
管理產生助益。本研究之成果已整理於國際會議中發表。 
 4 
1. 前言 
情報(intelligence)之蒐集與分析一直以來被認為在軍事與商業戰爭中具有關鍵的角色。歷史上多有
獲得關鍵情報而獲得軍事或商戰勝利的案例。情報之用途，主要是能「料敵機先」，收「知己知彼，百
戰百勝」之效。故情報之蒐集，應具有可靠性與廣泛性，求來源之充足與正確，以利分析。情報之分
析，則應具有預測性，求關鍵事件之預知，而能防患未然。若能持續的、廣泛的、且可靠的獲得情報，
再加以進行準確分析，則不論在戰爭行為或商業利益上，皆可獲得鉅大的進展。故自古以來，情報的
蒐集與分析一直備受（政治或企業）當權者重視。 
在情報蒐集上，傳統以來，不論在軍事或商業上，情報大都藉由秘密、隱蔽的管道獲得。主要的
原因是具有價值的情報通常具有機密性與敏感性而不對外公開。機密情報的取得因而時常經由不合法
的方式取得，造成情報蒐集過程具有極大風險。另一方面，秘密情報蒐集因管道之特殊與稀少性，加
上反情報(counter-intelligence)蒐集之可能，使得情報之可靠性亦時無保障。由於這些因素，使情報蒐集
之過程一直以來皆蒙上一層隱晦的面紗，情報蒐集者（情報員）之故事亦在坊間多所流傳。由傳統管
道所蒐集之情報，則具有資料量稀少、資料需驗證、通訊管道難以建立等缺點。 
傳統之情報分析通常為專業人員進行。情報分析師依據其執行準則與流程[1]對情報進行分析。其
間需運用大量之分析技巧與個人經驗與智慧。此類技巧之運用與經驗之累積需耗費極大的時間與心
力，故無法大量為之。因此各國政府或企業莫不把具備高度分析能力之情報分析師視為重要資產。誠
然，一具有高度情報分析能力之人員可為機構帶來巨大利益，然終就人力有限且訓練曠日費時，要依
賴此方式進行情報分析僅國家及大型企業具有能力進行。 
各種情報蒐集方法各有其應用領域與限制及其優劣點。一般而言，上述各種情報蒐集方法皆需運
用專業技術且需花費大量財力與人力，非一般個人或企業所能負荷，因此多由國家級專門機構進行。
然而其中之公開來源情報卻具有成本低、資訊即時、資訊量充足等優勢，對情報蒐集而言成為一新興
且具吸引力之管道。 
公開來源情報係指自公開來源，如新聞、政府公報、企業財報、機關網頁等，所能獲取之情報。
「公開」代表大眾可以付費方式或免費方式自由取得，乃相對於隱匿或機密而言。公開來源情報大約
來自下列各來源： 
1. 媒體：報紙、雜誌、廣播、電視、網路媒介等。 
2. 網路社群：社交網站、視訊分享網站、維基百科、部落格、社會性書籤網站等。 
3. 公開資料：政府公報、官方文件如財務報告、戶政資料、公聽會、國會質詢、記者會、演講、
環境影響評估等。 
4. 觀察報告：業餘無線電監聽者、飛機觀測者、公開之衛星圖與地圖等。 
5. 學術專業：學術會議、學術組織、學術論文、專家等。 
美國國家情報總監(Director of National Intelligence)與國防部於美國 2006 年會計年度之國防授權
法案[2]中定義公開來源情報為「為特定聽眾之特定情報需求，由公開資訊中進行即時的蒐集、利用、
與發佈」。由此定義可知公開來源情報需包含下列特性： 
1. 其情報來源為公開資料。 
2. 其目的為提供特定情報需求。 
3. 其運用過程包含蒐集、利用、與發佈。 
公開來源情報並非一新的情報蒐集管道，早在 1941 年二次世界大戰時美國中央情報局的外國廣
播資訊服務(Foreign Broadcast Information Service, FBIS)便依巴黎之柳橙價格（為一公開資訊）來判斷
鐵路橋樑是否已被炸斷。近代的公開來源情報開始於 1988 年美國葛雷將軍(Alfred M. Gray Jr.)提議將大
部份的情報蒐集放在公開來源上[3]。美國隨後於 2005 年在國家情報總監下設置公開來源中心(Open 
Source Center)來蒐集來自「網際網路、資料庫、媒體、廣播、電視、視訊、地理空間資料、攝影、與
 6 
Symposium on Open Source Intelligence and Web Mining (OSINT-WM)。此會議第一屆是於 2008 年於英
國倫敦舉行，其後 2009 年於西班牙巴塞隆納舉行，今年(2010)年則於丹麥歐恩塞(Odense, Denmark)舉
行。這個會議主要便是希望藉由資料探勘方法，尤其是網路探勘(Web mining)技術與社交網路分析，進
行公開來源情報之分析，可以說是目前世界上少數聚集這方面研究之重要會議。除了此會議之外，另
有一些論文散見於不同的國際會議中。整理後得知，此方面之研究大多以歐洲國家為主。以下則擇其
重要之論文進行探討。 
義大利的 SYNTHEMA 公司之 Baldini 等人於 2007 年開始發表了數篇論文描述其所發展的公開來
源情報處理平台 SPYWatch[8-10]。他們提出一架構來進行公開來源情報之蒐集、處理、分析、產出、
與發佈。此系統的核心技術在使用 K-means 演算法將文件分群後再進行分類。特點是本系統可處理來
自不同語文文件之情報。 
奧地利的 Sail Technology 之 Pfeiffer 等學者[11]則發表了基於 MPEG-7 之處理平台 Media Mining 
System。此系統之輸入可以為不同型式之公開來源資料，如衛星影像、電視影像、網頁與 RSS 輸入等。
這些原始輸入隨後被處理以萃取其內容。產出的內容則可在該公司之 Media Mining Server 中被檢索、
分析與檢視。Media Mining System 可用於早期預警、資訊分享、與風險評估上。 
英國 Innovation Works 公司之 Vincen 等人[12]則提出一集中式架構以融合來自不同來源的資訊以
提供緊急服務所用。他們的技術主要的核心是使用機率加強知識本體(probabilistic enhanced ontology)
並配合多功能的服務介面與使用語意特徵。本系統於發表時尚未成熟，其主要目標是要能夠達成情境
認知(situation awareness)與影響評估(impact assessment)。 
Badia 等學者[13]分析文字文件中的語句以獲得文件之時空資訊以提供公開來源情報使用。他們先
將語句轉換成主詞－動作－受詞的型式，再依據剖析程式所提供之提示資訊與特定的語法樣式來找出
語句中的時、空資訊。 
美國德州的 Austin Info System 之 Palmer 早於 2005 年發表論文[14]則提出了一語意比較量度以進
行事件分析(event analysis)。他使用 Lavalette 分布取代了較早所使用的語料庫分析[15]。他的系統主要
的特點是可以偵測事件間之關聯。 
歐盟執委會(European Commission)的聯合研究中心(Joint Research Centre, JRC)建立了一個二階段
的事件淬取系統[16]。在第一階段中，他們建立了一稱為歐洲媒體監測器(Europe Media Monitor, EMM)
的新聞報導蒐集平台。這些新聞報導會被分類與分群以供第二階段使用。在第二階段中，他們使用了
兩個方法，其一是 JRC 所發展的 NEXUS 系統[17,18]。此系統以分群為中心，採取簡淺語言學方法來
自某一主題群組中萃取資訊。其二是芬蘭赫爾辛基大學所發展了 PULS 系統[19,20]。此系統則較為深
入的分析新聞之內容，因而允許使用者自未明之新聞中發掘事件。 
前述之 OSINT-WM 會議之最近一屆於今年(2010 年)和 ASONAM 2010 會議合併舉行。其中有關
公開來源情報之相關論文概述如下。Wiil 等人[21, 22]以圖論的方法來來分析恐怖份子網路(Terrorist 
Network)。本文之特殊性在於其分析著重於連結(link)而非傳統該類網路所著重之節點(node)。Bartik[23]
的研究試圖將文本資料進行分類。他除了使用傳統的 tf-idf 加權法來描述文件內容外，也採用視覺特
徵，即文字所出現的位置作為分類的依據。Dawoud 等人[24]則結合數個社交網路分析常用的量度成為
一全域性量度，以度量恐怖組織之組織強度。Liu 與 Sandfort[25]則針對公開源碼，分析其與公眾參與
對社會創新的影響。雖然她們的研究亦與 Open Source 相關，但與此處之公開來源情報較無關聯。Neri
等人[26]則以義大利總理之性醜聞為例，探討如何分析、標示、分群新聞文件並發掘其隱含之關聯與情
感方向。 
 
3. 研究方法 
本研究之架構圖如圖 1 與圖 2 所示。圖 1 為資料蒐集與處理過程，圖 2 則為情報分析過程。 
 8 
 
圖 2 情報探勘流程 
以下針對研究架構中之重要步驟作一說明。 
1. 前置處理：經由代理人所蒐集之文件，具有不同的格式，亦包含許多無效的文件。本步驟將
文件進行正規化並篩選有效文件。各子步驟概述如下： 
A. 文件正規化：首先我們必須將不同來源之文件轉換成相同型式，由於我們將只針對文字
部份進行處理，因此本研究會將文件內各種型式之網頁標記(tag)、多媒體物件、無效字
元去除，淬取其中之文字部份，構成文本文件。在此無效字元包含控制字元與非英文字
元。 
B. 無效文件篩選：無效文件即對訓練無助益之文件，其存在將會增加訓練時間，同時可能
會降低訓練品質。因此為了提升訓練品質，本研究會將這些無效文件篩除。本研究所定
義之無效文件即正規化後文件容量過小之文件。 
2. 特徵淬取：為了將所蒐集之文本資料轉換為適合後續分群與分類訓練使用，我們必須加以處
理以轉換為向量型式。首先進行斷詞(segmentation)，將本文轉換為字詞之集合。標準的字詞
處理程序，如停用字去除(stopword elimination)、字根還原(stemming)、關鍵字選取(keyword 
selection)等也被運用以降低關鍵字之數量，即字彙集(vocabulary)之大小。最後我們再利用向
量空間模型(vector space model)將網頁 Pi轉換為一向量 Pi。在向量化的過程中，字詞之權重
設定亦是考量的因素。本研究採取二元化權重，即根據字詞出現於文件與否，決定其所對應
的向量成份值為 0 或 1。 
 
 
情報探勘 
使用者需求側寫檔 
情報可信度評估 
分析結果 
事件偵測 
文件向量 
關鍵事物偵測 事物關聯探勘 
來源側寫檔 文件側寫檔 
分析結果產出 
分析結果發佈 
使用者介面 
事件記錄檔 
 10 
C. 新奇事件偵測：在此新奇事件之定義為未能歸屬於任一文件群組之事件，其代表著此事
件不曾出現過或之前未被注意到。偵測方法為當新進文件 dI 出現時，它的文件向量會與
自我組織圖中之所有神經元比較，即計算文件向量 dI 與每一神經元之突觸權重向量 wj
之歐氏距離(Euclidean distance)。若 dI與所有神經元之突觸權重向量 wj之距離皆超過一門
檻值，則我們便認為 dI 為一新奇事件，因其與任一文件群組皆不相似。 
 
4. 結果與討論 
本研究所使用之實驗資料集為 Reuters-21578，其內容為路透社自 1987 年 2 月至 1987 年 10 月中
所收集之新聞，由 David D. Lewis[27]與路透社人員所整理而成，總共為 21578 篇新聞文件。此資料集
將文件區分為 135 個類別，然而其中部分類別並不包含任何文件。我們使用其中的 Modified Apte Split
方法將其區分為訓練資料與測試資料，其中各包含了 9603 與 3299 份文件。為了達到更好的效果，我
們捨棄了包含少於 20 份文件的類別，我也們捨棄了字數過少(少於 20 個字)與字數過多的文件(多於 300
個字)，經上述處理後訓練資料與測試資料各包含 5815 與 2355 份文件。我們再將這些文件依第三章所
述方法轉為轉換為向量，在建立字彙集時會捨棄只出現一次的關鍵字與不是名詞的字，再根據這些向
量進行自我組織圖訓練來進行分群與標記文件以建立文件分群圖，最後透過所得到的文件關聯來進行
本研究所提之三種偵測，並進行評估。 
本研究前置處理步驟包含文件正規化與無效文件篩選，此步驟之目的是為了將無效字元去除以得
到文本文件，並剔除無效文件以提升訓練之品質。正規化過程包含去除各種型式之網頁標記(tag)、多
媒體物件、無效字元，淬取其中之文字部份所構成文本文件，其中無效字元指控制字元與非英文字元。
之後再將字數少於 20 或大於 300 的文件捨棄，以降低分群效果不佳之可能性。 
在特徵淬取時，我們進行斷詞、詞性標記、字根還原、停用字去除與關鍵字選取等步驟。本研究
採用 Stanford Natural Language Processing Group 所開發之 Part-Of-Speech Tagger[28]來進行斷詞與詞性
標記。在完成特徵淬取後，接著進行文件向量化，首先我們從文件集中進行特徵選取以形成一字彙集，
再利用 Salton[29]等人提出之向量空間模型將文件轉換成文件向量，此一文件表示法可與自我組織圖結
合，作為自我組織圖之輸入參數，而權重部分則是採用二元布林值作為向量值，即文件中有出現該關
鍵字則設值為 1 反之為 0。 
本研究使用 SOM 分群演算法對文件向量進行訓練，在完成訓練之後，將進行一標記過程，把文
件標記於自我組織圖中之優勝神經元上，如此便可得到一文件分群圖，圖中每一神經元帶代表一個分
群，由於文件是依據跟神經元距離之遠近作為標記之準則，將文件標記在離最近之神經元上，從另一
方面來說，被標記在相同神經元上之文件，其相似度很高，故我們便可以得到文件之分群結果，從而
了解文件間的關聯。本研究的分群訓練其輸入為 Modified Apte Split 分割中屬於訓練集合之文件，再根
據前述所提之條件過濾，所得共 5815 份文件；從文件在文件分群圖上的映射位置，亦可大約的表示出
其文件間之關係，文件所屬的神經元距離越近，代表著他們的關係越緊密。這是因為一般而言，擁有
相似主題之文件，其使用之文字亦會有相似的語言特徵，即有很大機會採用相同的詞彙，故他們會擁
有相似的特徵向量，在映射至分群圖時會被映射至相同或鄰近的神經元上面。表 1 為自我組織圖之統
計資料。本研究嘗試不同的參數範圍，自我組織圖神經元數量由 100 至 225，學習速率由 0.2 至 1，最
大訓練週期由 200 至 1000。此表所顯示的為獲得最佳結果之自我組織圖。 
表 1 自我組織圖統計資料 
參數 值 
 12 
門檻值2 
成功偵測數量 
準確率 
最佳單一類別準確率 
最差單一類別準確率 
0.3 
593 
25.18% 
59.56% 
0% 
0.4 
1034 
43.91% 
81.78% 
0% 
0.5 
1497 
63.57% 
100% 
0% 
0.6 
1890 
80.25% 
100% 
0% 
0.7 
2135 
90.66% 
100% 
0% 
  
門檻值=0.3 
 正確 錯誤 
正確   
錯誤   
 
門檻值=0.5 
 正確 錯誤 
正確   
錯誤   
 
 
 
 
 
 
測試的文件數量一共有 2355 份文件分別來自 57 個類別，我們從一個類別中抽出一份文件 dI
來計算他與所有文件分群的距離，當這份文件與文件分群的距離小於一定範圍時，才認定此
文件屬於該文件分群 CI。其範圍之訂定為 DCM 中，所有文件與該文件分群之距離的一定比
例下，如下所示： 
)min(*)]min()[max( 2 iiiiiiII CdCdCdCd  
 
其中2為門檻值，Ci為文件分群 Ci之突觸權重向量，di為該分群中的文件。從表 2 中我們可
以發現，當門檻值從 0.3 逐步調整到 0.7 時，其最差之準確率仍然為 0%，檢視測試資料集後
我們發現，造成此結果的原因是因為，某些類別其文件數量過少，如 retail 與 stg 這兩個類別，
其在測試資料集中皆各只有一份文件存在，故其準確率非 0%即 100%，致使最差準確率始終
相當的低。 
C. 新奇事件偵測 
要評估新奇事件偵測之效能較為困難，主要是因為我們必須另於訓練文件外準備一組新奇文
件。之前所使用的測試文件集並不能滿足新奇性的要求。一個簡單的策略為假設屬於不同類
門檻值=0.4 
 正確 錯誤 
正確   
錯誤   
門檻值=0.6 
 正確 錯誤 
正確   
錯誤   
門檻值=0.7 
 正確 錯誤 
正確   
錯誤   
實際 
預測 
實際 
預測 
實際 
預測 
實際 
預測 
實際 
預測 
 14 
門檻值3 
成功偵測數量 
準確率 
最佳單一類別準確率 
最差單一類別準確率 
0.3 
1265 
97.68% 
100% 
91.48% 
0.4 
1071 
82.70% 
97.01% 
59.57% 
0.5 
703 
54.28% 
80.59% 
14.28% 
 
0.00%
20.00%
40.00%
60.00%
80.00%
100.00%
120.00%
新奇事件偵測
門檻值 0.3
門檻值 0.4
門檻值 0.5
 
圖 3 新奇事件偵測準確度 
由表 6 可知當門檻值較低時，代表測試文件只要與某一類別之文件有些許不同，亦即頗為相
似時，仍會被認為是新奇文件。反之，若門檻值較高，代表測試文件與某類別的文件間要有
較大的差異性才會被認為是新奇文件。由於本研究採取只要不屬於同一類別的文件即為新奇
文件的作法，但實際上不同類別的文件間仍有可能具有相關性，故當門檻值較高時，要被偵
測為新奇文件之可能性便較低，造成準確率降低。由於本研究並未對不同類別文件間之相似
度進行分析，故門檻值及其準確度並無法提供確切之參考價值。為改善此一缺憾，一可能作
法為計算測試文件與各訓練類別間之平均相似度，再以此相似度作為門檻值。若準確率超過
50%則可認為本方法可以成功的偵測新奇事件。 
0.00%
10.00%
20.00%
30.00%
40.00%
50.00%
60.00%
70.00%
80.00%
90.00%
 
圖 4 採用新門檻值之新奇事件偵測準確度 
 
 圖 4 為考量測試文件與各訓練類別之相似度後，再次進行的新奇事件偵測之準確度，圖
中準確率高的代表對此類別之新奇事件之偵測能力較高，所以在 14 個類別當中，對 wpi、cpi
 16 
Intelligence Agency, http://www.au.af.mil/au/awc/awcgate/psych-intel/art5.html, retrieved 2010-12-9 
[2] House of Representatives Report 109-89, National Defense Authorization Act for Fiscal Year 2006 
(109th Congress 1st Session, May 20, 2005) 
[3] Gray, A. M. (Winter 1989-1990) “Global Intelligence Challenges in the 1990's”, American Intelligence 
Journal, pp. 37-41. 
[4]  NATO (2001). NATO Open Source Intelligence Handbook, Supreme Allied Commander Atlantic, 
Norfolk, VA. 
[5]  NATO (2002). NATO Open Source Intelligence Reader, Supreme Allied Commander Atlantic, Norfolk, 
VA. 
[6]  NATO (2002). Intelligence Exploitation of the Internet, Supreme Allied Commander Atlantic, Norfolk, 
VA. 
[7]  http://www.dniopensource.org/ 
[8] Baldini, N., Neri, F. and Pettoni, M. (2007) “A Multilanguage Platform for Open Source Intelligence,” 
WIT Transactions on Information and Communication Technologies, Vol 38, pp. 325-334. 
[9] Neri, F. and Priamo, A. (2008) “SPYWatch, Overcoming Linguistic Barriers in Information 
Management,” LNCS, Vol. 5376, Intelligence and Security Informatics, pp. 51-60. 
[10] Neri, F. and Geraci, P. (2009) “Mining Textual Data to Boost Information Access in OSINT,” 
Proceedings of the 13th International Conference on Information Visualization, Vol. IV, pp. 427-432. 
[11] Pfeiffer, M., Avila, M., Backfried, G., Pfannerer, N., and Riedler, J. (2008) “Next Generation Data 
Fusion Open Source Intelligence (OSINT) System Based on MPEG-7,” Proceedings of the International 
Conference on Technologies on Homeland Security, Waltham, MA, pp. 41-46. 
[12] Vincen, D., Stampouli, D., and Powell, G. (2009) “Foundations for System Implementation for a 
Centralised. Intelligence Fusion Framework for Emergency Services,” Proceedings of the 12th 
International Conference on Information Fusion, Seattle, WA, pp. 1401-1408. 
[13] Badia, A., Ravishankar, J., and Muezzinoglu, T. (2007) “Text Extraction of Spatial and Temporal 
Information,” Proceedings of the 2007 International Conference on Intelligence and Security 
Informatics, pp. 381. 
[14] Palmer, J. (2005) “Textually Retrieved Event Analysis Toolset,” Military Communications Conference, 
Vol. 3, pp.1679-1685. 
[15] Jiang, J. and Conrath, D. W. (1997) “Semantic Similarity Based on Corpus Statistics and Lexical 
Taxonomy,” Proceedings of International Conference on Research in Computational Linguistics 
(ROCLING X), Taiwan. 
[16] Atkinson, M., Belayeva, J., Zavarella, V., Piskorski, J.,  Huttunen, S.,  Vihavainen, A., and Yangarber, 
R. (2010) “News Mining for Border Security Intelligence,” Proceedings of IEEE International 
Conference on Intelligence and Security Informatics, Vancouver, Canada, pp. 173. 
[17] Tanev, H., Piskorski, J., and Atkinson, M. (2008) “Real-Time News Event Extraction for Global Crisis 
Monitoring,” Proceedings of the 13th International Conference on Applications of Natural Language to 
Information Systems (NLDB 2008), Lecture Notes in Computer Science Vol. 5039, pp. 207-218. 
[18] Piskorski, J., Tanev, H., Atkinson, M., and Van der Goot, E. (2009) “Cluster-Centric Approach to News 
Event Extraction,” Proceedings of the International Conference on Multimedia & Network Information 
Systems, Wroclaw, Poland, IOS Press. 
[19] Grishman,R., Huttunen, S., and Yangarber, R. (2003) “Information Extraction for Enhanced Access to 
 1 
 
國科會補助專題研究計畫出席國際學術會議心得報告 
                                     日期：102年 1月 28日 
                                 
一、參加會議經過 
本次會議由日本未來大學(Future University)、早稻田大學(Waseda University)、山東師範大學、
與厦門大學舉辦，廣州大學、蘭州大學、河南工業大學、武漢理工大學、華東師範大學、英國
Birmingham City University，與澳洲南昆士蘭大學(University of Southern Queensland)協辦，是同系
列會議的第四屆舉辦。未來大學為本校之姐妹校，本會議之大會主席姜曉鴻教授 (Prof. 
Xiaohong Jiang)受邀來本校訪問時建立交誼。故本人除受邀擔任本次會議的議程委員外，更受邀為
keynote speaker。本人在會議中除發表論文外，亦擔任兩個議程(session)之主持人。 
本人原訂於 101/8/2 至 101/8/5 間參與會議，但因颱風來襲，故延後一天於 101/8/3 出發抵達
日本北海道札幌市。隨後到達會議舉辦地點 Prince Hotels & Resorts 飯店，巧遇姜曉鴻教授，並受
其邀請於當日共進晚餐。晚餐中與本會議的其他重要成員相聚，包含另外兩位 keynote speaker，Norio 
Shiratori 教授與 Yoshiyori Urano 教授。其間交換了有關台、中、日學術環境之現況與意見，以及洽
談未來合作可能。 
隔日 (101/8/4) 本人發表 keynote speech ，題目為 ”Discovering Secrets from Texts: A 
Self-Organizing Map Perspective”，午餐後展開二議程，皆由本人主持。每一議程均包含十篇論文進
行口頭報告。論文作者主要來自中國大陸、台灣與日本，符合地緣與主辦者因素。另有來自澳洲、
東南亞與歐洲國家之作者參與，但數量不多。議程結束後進行晚餐，再與姜教授等人聚談。 
101/8/5 因行程關係本日用完早餐便整裝返回台灣，結束本次會議行程。 
計畫編號 NSC 100－2221－E－390－031－ 
計畫名稱 基於文本探勘技術之公開來源情報管理平台 OSINText 之建置與研究 
出國人員
姓名 
楊新章 
服務機構
及職稱 
國立高雄大學資訊管理學系教授 
會議時間 
101 年 8 月 3 日至 
101 年 8 月 5 日 
會議地點 日本札幌 
會議名稱 
(中文) 
(英文)2012 International Symposium on Information Technology in 
Medicine and Education 
發表題目 
(中文) 
(英文) Mining Open Source Text Documents for Intelligence Gathering 
 3 
 
與會人合影（前排左一為本人） 
 
100年度專題研究計畫研究成果彙整表 
計畫主持人：楊新章 計畫編號：100-2221-E-390-031- 
計畫名稱：基於文本探勘技術之公開來源情報管理平台 OSINText 之建置與研究 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 1 1 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 2 2 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 1 1 100% 
發表論文為與前
年計畫共同研究
成果。 
研究報告/技術報告 0 0 100%  
研討會論文 2 1 200% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
