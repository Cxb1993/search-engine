temporal and spatial references among frames. Our
algorithm consists of three main steps: a) defect detection;
b) defect filter (to recover miss-detected areas), and c)
spatial/temporal inpainting. The procedure is illustrated in
Figure 1. Each run requires a number of frames to be
calculated together in order to obtain the best detection and 
inpainting results. We explain each building block of our 
strategy in different sections below.
Figure 1. The Video Inpainting
Procedure
2.1 Defect Detection
Our detection algorithm takes two steps using
intensity and motion estimation. The first step decides 
candidate pixels in a frame. The second step takes motion 
estimation into consideration.
(1) Searching for Best Matching Area
For each frame, we compare the intensity between a
pixel fij and its neighboring pixels within a watching
windows, W, where the watching window is set to 10×10
pixels  by default. If the differences of pixel intensities 
between fij and its nearby pixels are greater then a noise
threshold, then we assume that the pixel is corrupted by 
noise. The assumption is rough but useful as the initial step
of detection. Thus, the preliminary noise detection can de
calculated by Eq. (1)
,
( , )
1, | | ,  is a noise pixel
0, otherwise,  is not a noise
ij i n j m I ij
i j W ij
if f f f
TNoise
f
θ± ±
∈
− >⎧⎪
= ⎨⎪⎩∑
, (1)
where θI is a intensity threshold. The threshold is 
decided by users for each practical case. Thus, TNoise is 
the total number of noise pixels in a watching window, W. If
TNoise is greater than a user defined threshold, the
watching windows is a best matching area (BMA). The
decision for noise threshold θI is the major concern. In fact, 
each video has a different feature. To achieve better
performance, the threshold can be dynamically adjusted 
dependent on the image content. In a typical practical 
example, θI is set to 9 (in a scale of 256). And, TNoise is 20 
(with the default 10×10 watching window). However, the 
size of W and the two thresholds can be adjusted by using 
our tool. A human observer is recommended.
(2) Target Area Mask
We compare the average intensity of each BMA in the
current frame, Framen, and its corresponding frames,
Framen+i (1 ≤ i ≤ 3). A simple method, SAD (Sum of Absolute
Differences) is  used to reduce the complexity of calculation. 
Our experiments proof that SAD achieves a similar result as 
if MAD or SSD is used. The core concepts of the algorithm 
are as follows. Firstly, to decompose each frame into some
2×2-pixel blocks. Then, we select 7×7 blocks as the
targeting searching area (the current block is the center).
The operation for the block-based detection can be
formulated as the following:
,( , ) , ( , )
( , )
min | |j n x y n i x y
x y block j
SAD Frame Frame +
∈
= −∑ (2)
1
,
1, if min  (x,y) block
0, otherwise
j SAD
x y
SAD j
TAM
θ≥ ⊕ ∈
=
⎧⎨⎩
(3)
where minSADj is the minimumSAD of the jth block in
the current frame and its best matching blocks in the 
corresponding 3 frames. θSAD1 is a threshold used to decide 
if the content of a block is a noise and TAM is the target
area mask. A target area mask is used to indicate the 
changing parts of image frames. TAM=0 means an ordinary
motion and the algorithm should store the motion vectors, 
(dx, dy) (to be used in temporal inpainting). And, TAM=1
means there is no match of any motion block. As such, we
need to enlarge the search area to 15×15 blocks. Repeating
Eq. (2) and (3) on Framen and Framen+i (1 ≤ i ≤ 3), additional
noise pixels could be marked due to a larger range of search.
in Eq. (2), the symbol У is a conjunction. It is possible that 
TAM is enlarged (in most cases). However, our noise filter 
can relax this problem. θSAD1 is set to 10 as default. But, the
observer can make a change.
2.2 Defect filter
In defect detection, ordinary video pixels  may be 
recognized as defects. Additional considerations will be 
used to recover misdetections. Our adaptive defect filter is 
split into two parts: block-based filter to cope with
misdetection due to fast motion, and pixel-based filter to 
relax the restriction of defects as blocks.
(1) Block-based filter
We decompose video clips into frames and study how 
defects are distributed among frames. In most cases, spike 
and dirt occur in one or two frames. This characteristic was
found in more than 95% (subjective observation) of the 15
video sequences  that we have collected. Since our defect 
Pixel
Filter
Best Matching TAM Block
Filter
Temporal InpaintingSpatial Inpainting
Framen
Source
Framen+i
Framen
Framen+1
Framen
Framen-1Framen
Framen-1
Framen-2
Framen
Result Frames
Figure 3. The spatial inpainting algorithm, Damaged Image
Block (DIB), Image Block (IB) and Pixel Block (PB)
There are three thresholds in the above algorithm,α, β1
and β2. We use α = 80, β1 = 85, and β2 = 95. The experiments
are discussed in [4].
3. Experiments and Analysis
It is hard to find aged motion pictures with suitable 
defects, especially for color videos. We collected about 15
video clips with different categories (B/W or color movies,
western and Chinese movies, historical movies, science
movies, etc). In Figures 4, 5, and 6, we illustrate the original 
frames (i.e., picture (a)’s) where defects occur. These
defects include white spikes, dark spikes, and large dirt 
areas. In Figure (b)’s, the detected defects (after applying 
defect filters) are shown in red. Figure (c)’s illustrate the 
recovered frames. In Figure (d)’s, green pixels indicate
temporal inpainting from previous frame and yellow color
indicate the use of next frame. Spatial inpainting areas are 
left intact. On important argument is that how to decide the 
thresholds. As we have explained, thresholds are decided 
by users. The recommended thresholds discussed above 
are due to real experimental results and a very careful
analysis.
(a) Original frame (b) Detected spikes
(c) Restored frame (d) Use of inpainting methods 
Figure 4. Video inpainting on spikes
(a) Original frame (b) Detected spikes
(c) Restored frame (d) Use of inpainting methods
Figure 5. Video inpainting on spikes: black & white films
(a) Original frame (b) The detected dirt
(c) Restored frame (d) Use of inpainting methods 
Figure 6. Video inpainting on dirt
We found that there is no proper solution for a
quantitative evaluation of video inpainting since the
original video (no defect) can not be obtained. Thus, human 
evaluation is our strategy. Among the video clips that we 
have inpainted, our evaluators (20 undergraduate
volunteers) all agree that the inpainted video sequences  are 
better then their originals . However, there are miss-
detection and improper inpainting. Again, the evaluation is 
subjective. In the video clip we shown in Figure 4, there are 
about 15% (number of spikes) of defects not detected. Most 
of these defects are very small spikes. About 10% cases of
improper inpainting occur due to fast motion. In such cases 
our multi-resolution image inpainting strategy can not
precisely recover large continuous defect areas which cover 
a complicated object structure.
