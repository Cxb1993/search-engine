1 
行政院國家科學委員會專題研究計畫成果報告 
類人型機器人之動態感測與控制及系統整合 
Dynamic sensing and control and system integration of humanoid robot. 
計 畫 編 號：NSC  96-2221-E-002-318 
執 行 期 限：97 年 08 月 01 日 至 98 年 07 月 31 日 
主 持 人：羅仁權 教授 台灣大學電機系 
計畫參與人員：吳士強 台灣大學機械研究所 
一、中文摘要 
此子計畫之目標是建立類人形機器人之
完善感測系統，使雙足機器人有良好感測能
力與環境互動。本子計畫分別對機械手臂、
機械視覺與機器人自動尋找充電站並賦歸充
電站這三部分進行研究。機器手臂部分，利
用 CCD Camera 與雷射測距儀(LRF, Laser 
Range Finder)進行感測融合，使機器手臂能
自動尋找抓取物，並找到適合之抓取點進行
抓取。而在機器視覺方面，我們使用 Adaboost
演算法，使用大量正片與負片樣本進行訓
練。經過一系列的訓練，可以攝影機擷取之
畫面上自動鎖定人臉與人體目標，得以實現
機器人對人臉或人體追蹤。最後，利用 LRF
與 Camera 這兩個感測器，並使用變異數交互
關係法(CI, Cross Intersection)感測融合方
法，降低機器人尋找充電站的不確定性，機
器人進行同時定位與建地圖之功能(SLAM, 
simultaneous localization and mapping)找出自
身所在位置，並往充電站方向移動，進行充
電之功能。 
關鍵詞：感測融合、SLAM 同時定位與建地
圖、Adaboost 演算法、變異數交互
關係法(CI, Cross Intersection) 
Abstract 
In order to make humanoid robot have 
better ability to detect the environment, this 
project aims to develop multi sensor fusion 
system. By using CCD camera and LRF, we 
have image and distance information. After 
fusing them, it’s easy for the arm to detect the 
potential target and find a suitable point to 
grasp. About machine vision, we take camera 
with employing the adaboost algorithm and 
taking a series of training to detect the face and 
human body. Once it detects targets, it does 
tracking. Last but not least, we reduce the 
uncertainty of detecting the charging station by 
taking advantage of LRF and Camera with CI 
(Cross Intersection) approach. Robot does 
SLAM to find the location where it is. Then it 
docks to do charging. 
Keywords: Sensor Fusion, SLAM, Adaboost 
algorithm, Cross Intersection (CI) 
二、緣由與目的 
    近年來國內自動化技術逐漸發展成熟，
全球各項科技也都有許多創新突破，國內許
多產業界、學術界、研究單位開始思考繼電
子資訊產品之下一波具有廣大應用價值的市
場。也因此機器人產業被列為下一世代具有
強大發展潛力革命性產品之一。 
    然而國內機器人研究主要集中在輪型機
器人功能的開發與改善，由居家保全、到娛
樂等領域的應用都主要以輪型機器人發展為
主。而輪型機器人在環境中克服障礙物之能
力卻有其限制。近幾年，許多專家學者將其
注意力轉移至雙足步行機器人之研究上。 
一個具備多個感測器的智慧型移動機器
3 
    圖 5 是人臉跟踪的實驗結果，使用紅色
框框將辨識到的目標框出來，分別有人體偵
測，與人臉偵測。圖 6 是人體追踪的實驗結
果，經過訓練後，可以得到較好的追蹤效果。 
 
圖 5 單一人臉追蹤實驗結果 
 
圖 6 雙人人體追蹤 
3.2 Eye in Hand 抓取物體之多重感測回饋 
我們結合多個傳感器馬達編碼器、CCD
和雷射測距儀。利用 CCD 鏡頭設計機器人手
臂路徑規劃：得到的資訊，提供鑑於機器人
的環境作為一個輸入一個Adaboost的學習過
程，構建了串列分類器(Cascade Classifier)。
但相機影像的品質強烈受到環境的影響。為
了減少相機受到環境的影響，我們的系統是
整合從雷射測距儀提供的距離資料，在處理
過程中，比對影像與距離資訊便可完成物件
辨識與分類。 
3.2.1 機械手臂系統架構  
為了探討仿人形機器人可行性，我們建
立了一個裝有傳感器構造機器人手臂進行初
步研究。機器手臂構造使用鋁合金。系統主
控制器的規格如下：PC (Personal Computer) 
with a Intel(R) Core™ 2 Duo CPU 2.26GHz 
與 4GB RAM，8 個馬達驅動器 1 夾爪和配備
了兩個不同的傳感器：CCD 相機和雷測測距
儀。我們利用 PC 的高速運算能力控制機器
人，可編程和更靈活的控制，甚至它提供的
整合開發環境，具有豐富的軟體和硬體支
援。使用 MOXA UPort 的 1650-8 USB 到串列
轉換器提供高穩定性的機器人實時控制。最
後，我們開發了六自由度手臂配合視覺伺服
系統和雷射測距儀在手。機器人臂的硬體系
統架構如圖 7。 
 
圖 7 手臂物體抓取之系統架構 
機器人手臂的設計與六自由度能達到
的工作範圍在三維空間中。為瞭解機器手臂
動態的運動情形，首先每一個關節空間的影
響必須建立從底座到手臂末端的關係。圖 8(a)
為使用 Denavit – Hartenberg 法則建立每一個
環節之間的關係座標系統的六自由度手臂。 
 
圖 8 (a)手臂與夾爪之設計圖 (b)手臂上之座標系統 
機器人手臂控制程序結合微軟 C＃、
WPF(Windows Presentation Foundation)和在
Microsoft.Net frame 下的 MATLAB。該程式
使用 C＃，提供友好的人機界面的顯示圖，
5 
便往水壺的位置靠近。圖 12 顯示了機器手臂
抓取水壺一連串的過程。在前兩張圖片中，
CCD 影像中被偵測到較短的線特徵，很明顯
地被視為手把，然後控制機械手臂接近該線
特徵，再由 CCD 影像作回授確認，再進行抓
取。 
 
圖 11 利用視覺伺服回授進行水壺夾取點之偵測與選
取 
 
圖 12 機械手臂自主抓取水壺連續鏡頭 
3.3 自主移動機器人之賦歸與充電 
在本節中，我們開發了多傳感器融合方
法。使用 Covariance Intersection 方法進行強
度和範圍數據融合，以達到使機器人賦歸並
進行充電之功能。利用一個人工的 landmark
做為充電站影像上線索，通過逆透視投影以
便確認該位置。同時，獲得的數據的範圍由
雷射測距儀的建模為多線段，假設是在環境
中的牆壁。然後，通過使用變異數交互關係
法的方法能更加精確地估計機器人與充電站
之間的幾何關係。透過實驗結果，我們成功
證明該演算法的可行性。 
3.3.1 影像模型  
圖 13 說明了相機和測距儀的幾何關
係，彩色相機安裝在雷射測距儀上方。一個
額外的伺服控制裝置是執行測距儀的傾斜功
能。範圍資料平面的數據是由擺動 LRF 所產
生。彩色圖像則由相機所捕捉到。各種數據
和圖像數據的收集和計算主要由安裝在機器
人上的個人電腦進行處理。 
 
圖 13 機器人上 ICS 與 RCS 座標系統之幾何關係 
我們使用 4 × 4 同質矩陣 將 RCS 轉
換成 ICS 座標系。轉換矩陣 的定義為： 
                  (10)          
然後， 
           (11) 
3.3.2 相機模型  
    我們定義相機模型為： 
I=AX,                              (12) 
I 是行向量 ，代表在影像平面的
齊次坐標。 X 是行向量 代表在世
界坐標系統下的齊次座標（即為 ICS）。A是
4 × 3 矩陣，將三維世界座標系的點座標映射
7 
圖 16 IEPF 疊代分割 
3.3.3.2 IEPF 之權重 
圖 17（a）顯示利用 IEPF 在附近的一個
角落裡進行雷射掃描之結果。由於頂點的角
落，是超越距離的測量（3 米），IEPF 將導
致了三個線段。顯然，在最短的線段是 不是
真正的目標。在這個實驗中，我們修改 IEPF
加入加權總和。當第一點線段的是，比前一
個閾值(threshold value)（例如閾值為 5），線
段從 IEPF 所得到的結果是有效的。否則，該
線段就不是我們所想要的。圖 17（b）顯示
IEPF 的加權總和的門檻。 
3.3.3.3 霍夫轉換之不確定性估測 
Hough轉換是一種在 IEPF線特徵提取方
面，十分流行的方法。然而，在這一節中，
我們利用 Hough 轉換將這些已聚集成組的加
權 IEPF 共線點重新取樣。 
 
圖 17 (a) 不具權重 IEPF 之結果(b) 具權重 IEPF 之
結果 
 
圖 18 霍夫轉換 
圖 18 顯示了 Hough 變換的結果。最大
投 票 值 表 示 最 有 可 能 線 功 能 在
。 不 過 ， 周 邊 地 區 的
也顯示了不 確定性。為此，我
們可以重新採樣霍夫領域內的黑暗橢圓估計
均值，方差和協方差線的功能。圖 19（a）
顯示了兩個線段的比重 IEPF 和圖 19（b）顯
示行在兩個偏差值間線特徵的不確定性。 
 
圖 19 線特徵不確定性之估測 
3.3.4 利用 Covariance Intersection 方法作
感測融合 
一般來說，為了提取充電站之特徵，我
們可以從視覺系統得到可靠的方向資訊
(orientation)，但深度資訊則會比較粗糙。另
一方面，LRF 模型的處理上，不同於視覺資
訊的處理，LRF 模型具有較容易獲得距離方
面精確的資訊，而在空間特徵的擷取上，則
較為薄弱，不易辨識環境中的特徵。在這個
方法中我們結合相機所或的之影像資訊，與
LRF 所得到之所得到之距離模型來降低偵測
或辨識充電站的特徵上的不確定性。感測融
合利用不同的感測器針對相同的目標物，進
行感測互相彌補彼此不足之資訊，改善量測
各項資訊的性能。 
兩部分信息， 和 ，要融合在一起，
得出一個輸出 ，其中 和 的估計，從視
覺和雷射測距系統模型，和 ， 和 是
他們的變異數。變異數交互相關(Covariance 
Intersection, CI）方法是用於這些融合。交集
的特色是交互組合變異數。變異數交互相關
演算法如下： 
                    
     
其中ω א [1, 0]，和ω修改相對權重分配給
和 。不同的選擇的 ω可以對於不同的性
能要求，用來最佳化變異數的估計，如最小
化 的 determinant 值。事實上，此資料更
新對每個 ω相對較為保守，可以透過下面這
個矩陣證明： 
9 
我們開發使用充電站和機器人賦歸之機
構，提出的數據融合與變異數交互關係法中
實現服務機器人自動賦歸充電站進行充電之
功能。一個具有人工 Landmark 作為視覺線索
的充電站，通過逆透視投影以便確認該位
置。同時，由雷射測距儀獲得的範圍數據的
建模為多線段，其假設該線段是在環境中的
牆壁。然後，機器人與充電戰之間的幾何關
係可經由變異數交互相關法更加精確地被估
計。透過使用變異數交互關係的方法。我們
提出的方法在減少不確定性方面，比單獨使
用雷射測距儀或相機所擷取到的資訊進行自
動賦歸充電功能擁有更佳的表現。 
五、結論 
本子計畫已實現利用 Camera 與透過
Adaboost 演算法進行人臉與人體追蹤，並且
獲得良好之效果。同時也建立六軸機器手臂
之感測融合系統與機械手臂控制之人機介
面。藉由機械手臂前端之雷射測距儀感測到
之物體位置與相機鏡頭得到之影像資訊比
對，可判斷出欲抓取目標與選取適當抓取點
進行抓取。實驗結果顯示，透過本實驗之感
測系統架設，確實有助於提升機械手臂抓取
物體之準確度。友善之人機界面之建立也令
使用者更易進行機械手臂之操作。關於機器
人自動返回充電站進行充電部分，利用 LRF
透過 Hough Transform 去估測機器人周遭環
境之資訊，降低不確定性。在利用機器人頭
上之 Camera 所得到之影像之資料，將其與
LRF 之距離資訊透過 Covariance Intersection
進行資料感測，令機器人找出確切充電站之
位子進行充電。 
六、成果統計 
名稱 次數 說 明
國際研
討會 
1 Ren C. Luo, C.T Liao, Y.J. Chen, 
“Robot - human face tracking and 
recognition using relative affine 
structure” IEEE International 
Conference on Advanced Robotics and 
its Social Impacts Taipei, Taiwan, Aug. 
23-25, 2008 
國際研
討會 
1 R. C. Luo, Cheng-Tse Chen, ” Internet 
Based Remote Supervisory System for 
Tele-medicine Robotics Application” 
IEEE Workshop on Advanced Robotics 
and its Social Impacts (ARSO 2009), 
Tokyo, Japan, November 23-25, 2009 
國際研
討會 
1 Ren C. Luo, Chung T. Liao, and Shih 
C. Lin, “Multi-Sensor Fusion for 
Reduced Uncertainty in Autonomous 
Mobile Robot Docking and 
Recharging,” Preprint submitted to The 
2009 IEEE/RSJ International 
Conference on Intelligent Robots and 
Systems. Received June 10, 2009 
國際研
討會 
1 Ren C. Luo, Nai W. Chang, Shih C. Lin 
and Shih C. Wu, “Human Tracking and 
Following Using Sensor Fusion 
Approach for Mobile Assistive 
Companion Robot,” Preprint submitted 
to The 35th Annual Conference of the 
IEEE Industrial Electronics Society. 
Received July 17, 2009 
國際研
討會 
1 Ren. C. Luo, M. H. Li, H. L. Jhu, J.W. 
Chen, “Multi-Sensors Feedback for 
Grasping Objects With Laser Ranger in 
Hand” Preprint submitted to The 35th 
Annual Conference of the IEEE 
Industrial Electronics Society 
國際研 1 Ren C. Luo, Ogst Chen,"Indoor Human 
Dynamic Localization and Tracking 
11 
"Contour-Based Object Tracking with 
Occlusion Handling in Video Acquired Using 
Mobile Cameras," IEEE Transactions on 
Pattern Analysis and Machine Intelligence, pp. 
1531-1536, 2004. 
[12] H. Bang, D. Yu, S. Lee, I. H. Suh, " An 
object recognition system based on color 
co-occurrence histogram and geometric 
relations of pyramidal image patches," 
Intelligent Robots and Systems, 2008.(IROS 
2008). Proceedings. 2008 IEEE/RSJ 
International Conference on,, September 22-26, 
2008 Page(s):3591 – 3596. 
[13] P. Viola and M. Jones, "Rapid object 
detection using a boosted cascade of simple 
features," Proc. CVPR, vol. 1, pp. 511–518, 
2001.  
[14] Terawaki, “Measuring Distance Type 
Obstacle Detection Sensor PBS-03JN 
Instruction Manual”, Hokuyo Automatic Co., 
LTD., April 2004, pp. 1-19. 
[15] [Hokuyo Automation, 2005] Hokuyo 
Automation. Scanning laser range finder for 
robotics. 
http://www.hokuyo-aut.jp/products/urg/urg.htm, 
2005. 
  
generation, distributed power generation, integrated renewable systems, hybrid electric 
vehicles, fuel cells, advanced batteries. 
 Electrical Machines & Drives: AC motor drives, observers and sensorless methods, drive 
control and applications, electrical machine design and modelling, thermal, noise and vibration 
issues in electrical machines, testing and diagnostics, fault finding in machines and drives, 
motion control, special machines and actuators. 
 Factory Automation & Industrial Informatics: Building automation, factory 
communications, factory automation, flexible manufacturing system, process automation, 
industrial agents, integrated systems and processes, distributed collaborative 
systems, human-machine interfaces, security & safety applications, infrastructures for 
industrial informatics portable electronics. 
 Mechatronics & Robotics: Mechatronics systems, robotics, autonomous mobile robots, 
telerobotics and teleoperation, humanoid robots, multi-robot systems, intelligent transportation, 
distributed collaborative systems, security & safety applications, human-robot interface, 
vision-based robots. 
 Sensors, Actuators and Systems Integration: Intelligent sensors/actuators and multisensor 
fusion - Micro-sensors and micro-actuators - Micro-nano technology - Electronic 
instrumentation - Micro-electro-mechanical systems (MEMS) - Systems on Chip (SoC) - RF 
systems integration - Integrated optics and related technologies. 
 Signal and Image Processing & Computational Intelligence: computer vision, virtual 
reality systems, industrial vision, virtual instrumentation, image & sound processing, digital 
signal processing, remote sensing, multimedia applications, neural networks, fuzzy logic, 
genetic algorithms, industrial applications of intelligent controllers. 
 
In this meaningful International Conference, we presented a paper entitled“Indoor 
Autonomous Mobile Robot Localization Using Natural Landmark” In this paper we presented a 
method which can solve simultaneous localization and mapping (SLAM) problem using natural 
landmarks when mobile robot is in a long corridor or a roomy space. Generally, for an EKF-SLAM 
procedure, it is difficult to estimate the robot position before getting a complete landmark 
measurement. In this paper, the method we have proposed not only can reduce the complicated 
merging identical landmark process, but also can utilize pieces information of observed landmark to 
improve the localization performance in the EKF-SLAM. We have demonstrated our estimation 
method to SLAM process, it can make the overall framework effectively to adapt more natural 
landmarks for a common indoor environment. 
2. Experience: 
It is very much appreciated for the strong supports from the National Science Council to make 
my attendance to this meaningful International Conference possible. It is very beneficial for having 
