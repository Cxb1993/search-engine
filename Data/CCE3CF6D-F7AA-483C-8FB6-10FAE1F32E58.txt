the recognition is also alleviated. Second, some 
familiar behaviors are modeled. Hence, it is possible 
to compare the extracted behavior features with those 
stored in the database. In fact, this part of the 
work is divided into two categories: simple behavior 
recognition and complex behavior recognition. The 
last step is the behavior understanding process, 
which means the final step is classifying the 
analyzed behaviors into the normal and the abnormal 
behaviors, and sending alarm if the abnormal 
behaviors are detected. 
英文關鍵詞： Intelligent video surveillance, Human motion 
detection and tracing, Video classification, Behavior 
analysis and understanding, Low light level images 
 
 2
中文摘要 
智慧型監控系統中包含兩個相當具有重要性的研究領域：以人為移動目標之行為辨識與行為模式
分析。使用前述兩項技術便能對視訊資料進行即時分析，若發現被監控目標行為異常，則可立刻發出
警示資訊。  
本計畫除進行人體行為的辨識與解析外，此舉也是本計畫之重點與創新之處。分析場景資訊之目
的是為行為分析與辨識提供基礎資訊以降低辨識難度;進行行為建模以利行為辨識時提供行為特徵進
行資料比對；行為分析即對於偵測到的行為進行分類以判別其行為類型，並決定是否發出警示資訊。 
後將實際校園內部進行實機架設與測試，此外更建立兩種低照度產生之雜訊影像過濾模組與本系統搭
配，從而完成完整的智慧型視訊監控系統。 
關鍵詞：智慧型視訊監控、移動人體偵測與追蹤、視訊分類、行為辨識與理解、低照度影像 
 
Abstract 
With the rapid development of the digital video processing and network techniques, the video 
surveillance system becomes more and more powerful in the aspects of intelligent and network processing. 
One of the most important research topics is the human behavior recognition and understanding. 
In this project, the human detection and tracking techniques in video surveillance systems are investigated. 
They are the foundation of the human behavior recognition and understanding. Meanwhile, according to the 
feature such as number of targets, velocities, trajectories, etc. and different strategies, the videos are classified 
into two categories for processing: the single human behavior and the several humans ’behaviors. Besides, we 
focus on studying several familiar behaviors carefully selected based on the constructed behavior descriptions. 
This project aims to recognize and understand the human behaviors based on the former obtained results. This 
is also the key point and innovation of this project. The designed structure in this project can be described in 
two phases: First, the surveillance scene is analyzed for the purpose of providing some transcendental 
knowledge for the behavior understanding. At the same time, the difficulty of the recognition is also alleviated. 
Second, some familiar behaviors are modeled. Hence, it is possible to compare the extracted behavior features 
with those stored in the database. In fact, this part of the work is divided into two categories: simple behavior 
recognition and complex behavior recognition. The last step is the behavior understanding process, which 
means the final step is classifying the analyzed behaviors into the normal and the abnormal behaviors, and 
sending alarm if the abnormal behaviors are detected. 
Keywords: Intelligent video surveillance, Human motion detection and tracing, Video classification, Behavior 
analysis and understanding, Low light level images 
 
前言 
人的行為分析與理解是實現智慧型視訊監控的一項關鍵技術。傳統的視訊監控都使用閉路電視系
統，其主要功能只是消極的錄影存證，並不能主動即時地對影像進行分析，並自發性的指示系統做出
各種回應。然而隨著數位化影音技術的進步及大量資料儲存設備和光學攝影器材成本的降低，使得視
訊數位化處理更為普及化，加上監控操作人員的人事成本支出逐年提高和人工智慧技術日趨成熟，使
智慧型視訊監控系統(intelligent video surveillance system)更為大眾所矚目。智慧型視訊監控系統適用於
對地鐵站、廣場、辦公室、監獄、銀行、商店以及一些門禁考勤系統等以人為主要活動物件且有安全
考慮的場所進行即時監控。 
 4
望能看到各種角度的畫面，避免有死角的區域無法偵測到。Black 等人則發展多個相機系統用來監控
和追蹤多目標物[11]，使用背景相減法偵測移動目標物，加上 Kalman 濾波器追蹤線性移動目標物，並
利用多相機取得各部分環境影像，建立起 3D 地理環境結合多重視點產生一個可變景深，而在可變景深
中加上多個攝影機配合，可以使用較易處理的線性卡門濾波器，代替難處理的延伸 Kalman 濾波器，在
3D 監控環境上追蹤多目標的非線性移動。而 Zhou 等人則對監控環境中的目標物加以分類[12]，使用
主軸成分分析抽取顏色特徵降低戶外環境影響，然後利用目標物移動軌跡方向、大小、形狀等資訊，
分辨出一個人、一群人和車輛等。Kleinsmith 等人[29]研究發現，影響人體行為辨識與理解的因素還包
括文化背景，因此他們透過建立一系列文化模型來輔助人體姿態辨識。從目前的進展來看，國內外在
智慧型監控系統領域的研究主要有兩個重點： 
(1) 大部分的研究重點在於研究單一人體的行為動作或其附屬資訊[21-23]，如頭部、手勢、腿部、軀
幹等肢體局部動作，以及跑、跳、走路等以一人為單元完成的行為。然而，對於大規模人群的行
為分析與辨識研究尚處於起步階段。 
(2) 對於人體行為的理解或語義分析還不完善，這也是智慧型監控系統中最重要也是最具有難度的研
究內容。有鑒於此，本計畫主要從兩方面切入：其一是研究人體行為的分類，本計畫不僅研究單
人的行為，同時還進行多人的行為分析；其二則是探討人體行為(包括單人和多人)的理解或語義分
析，努力推動實現真正意義上的智慧型監控系統。 
 
研究方法 
在原始的計畫書中提到使用貝氏網路來進行本計畫，但因實際上處理太過複雜因此使用類神經網路的
方式進行辨識，人體行為之辨識演算法之系統整合了數位影像處理、視訊認知的技術才可以完成以及
取像控制，此章節將要介紹本系統的方法以及整個系統之流程與架構，整個系統概略可以分為三個部
分移動物的偵測、特徵擷取、行為辨識與分析，其架構如圖 1 所式。 
 
 
圖 1 人體行為辨識系統流程圖 
 
由圖 1 可了解整個人體行為辨識演算法系統之架構，下面我們針對圖中區塊進行說明： 
 連續影像：本計畫使用 CCD 做為取像之工具，而影像之建立基礎以一個靜態背景為本文取樣
 6
不管在人臉識別、人體識別、目標物追蹤都需要使用此項技術，因此本計畫針對本系統之需求提出一
個完整的移動物流程，流程之細節如圖 3 所示。 
 
圖 3 移動物偵測流程圖 
 
在經由 CCD 產生之影片經過擷取後須進行背景相減，以判別為移動物或是背景。如果將視訊資料
中產生的任一個影格與背景影像相減後會獲得差異強度影像，此差異強度之影像代表畫面中影格與背
景之差異程度，這也表示變化少差異強度較弱，而有移動物的地方差異性強。對其差異性強度影像取
門檻值可得到二值化之差異影像，即可用此判定是否有移動物體。 
 
  
圖 4 原始影像(左)建立背景(右) 
 8
圖 6 兩種 3×3 的平均濾波器 
 
本計畫使用了圖 6 中之左圖之遮罩為本計畫使用之遮罩，因此經由平滑化背景相減法之影像可由
下圖 7 所示。 
 
  
圖 7 原始圖像(左)平滑後(右) 
 
當我們在戶外或是陰暗的室內時，對於移動物的偵測上會照成影響。因光線屬於直線前進的，因
此只要有光線存在的地方一定多少都會產生陰影，本計畫是採用視訊為基礎的偵測方式，所以偵測目
標物的同時，在場景所造成的陰影會偵測之結果造成誤判。輕微光線照成之陰影可能對前景偵測沒有
帶大的問題，但如果光線變化大造成之陰影一定會產生強烈的干擾，最後獲得目標物會產生分裂不夠
完整的狀況。 
首先針對色彩影像進行影像處理時，希望能夠只使用單一量值即可表示色調獲式亮度之間的關聯
性，越低越好而陰影就有此種特性。HSV 色彩空間為色調(Hue)、飽和度(Saturation)、亮度(Value)，依
照圖 8(右)標準色盤 0 ~ 360 之數值；飽和度(S)是指色彩的純度，越高表示色彩越純，越低則慢慢趨向
灰色，其範圍落在 0 ~ 100% 的數值；亮度(V)也可表示為「明度」，其範圍 0 ~ 100% 的數值。此色彩
系統與 RGB 相比系統更為接近人類所體驗和描繪的色彩感受。HSV 色彩空間主要是沿著 RGB 色彩
立體中的灰階軸其實就是該軸連接黑色與白色頂點來觀察此立方體，所制定的調色盤可由圖 8(右) 所
示。 
 
  
圖 8 HSV 色彩空間圖(資料來源：Google 圖片) 
 
 10
其實再經由去除陰影後，目標物容易因門檻值設定變得有些破損或是產生一些白點雜訊，因此我
們必須克服上述之情況產生，於是本計畫加入了形態學運算(Morphology)。影像處理的方法裡形態學運
算有好幾種方法例如膨脹(Dilation)、侵蝕(Erosion)、斷開(Closing)、閉合(Opening)等方法。而斷開與閉
合是由膨脹和侵蝕延伸出來之方法，因此本計畫針對膨脹和侵蝕做介紹。 
侵蝕主要使二值化影像中物件有「收縮」或是「變薄」。收縮的方式和程度是由結構的元素所控制。
經由數學定義來說明，A 被 B 侵蝕表示成  A⊖B 因此最後我們可定義為： 
 
G⊝  = JK|	L ⊆ GN (6) 
 
公式(6)中指出 A 被 B 的侵蝕而 B 位移被 z 後依然包含在 A 中所有的 z 點集合。本計畫使用圖說
明之。在本計畫探討時假設在一個平面上有 A 和 B 兩個影像，如圖 9 所示，則 A 和 B 的侵蝕運算定
義為：將影像 B 假設為一遮罩，開始時首先由影像 B 沿著影像 A 由左上到右下進行掃描時，假使遮罩
鄰近區域範圍之內產生任何像素點其二值化的像素值為 0 時，則將影像 A 的遮罩內中心點全部設定為
0 否則為將之設定為 1。因此 A 將根據 B 之形狀，縮減和遮罩的鄰近區域範圍，因 A 和 B 皆為正方形，
假設 B 邊長為 d/4 單位，則經過侵蝕運算的 A 則會改變使的每邊減少 2 個 d/8 單位之長度，也就是總
長減少了 2*(d/8)個單位長度如圖 10 所示： 
 
 
 
 
 
 
 
圖 10 侵蝕運算示意圖 
 
實際使用於人體行為的圖像上，可以發現雜訊點已經被去除了雖然人容易變的不完整，但還是可
以經由後續動作之調整使的目標物更為完整，如圖 11 所示。 
 
  
 12
  
圖 13 膨脹前(左) 膨脹後(右) 
 
區域連通法之目的將完整人體輪廓偵測出來，再利用標記法將連通法確定之完整輪廓擷取出來，
區域連通法又稱物件連通標示法(Connected Component Labeling)[2]，主要目的在於過濾掉目標物以外
的背景物件或雜訊，在處理上原則上將人體定義為物件之條件下進行區域連通法，經由此方法後可知
面積涵蓋範圍最大必為去雜訊後之背景，次大區域及為目標物內的空洞部分，將空洞部分做空洞填
(Hole Filling)滿後，經過此動作後所擷取之目標物具有封閉性。此處理可以使本演算法更精準的擷取人
體物件。 
 
以下為區域連通法之步驟： 
Step1：從灰階值判定為背景或物件之數字 1 開始標示，搜尋過程中標示值不斷累加，而非背
景或物件的像素不加以標示。 
Step2：由左上至右下 Top-Down 方式作方向搜尋，假使已標示像素，則開始搜尋八連通範圍
內像素之最小標示值，所謂的八連通如圖 12 所示方搜索，並取代自己標示值。 
Step3：由左上至右下 Bottom-Up 方式作方向搜尋，假使已標示像素，則開始搜尋八連通範圍
內像素之最小標示值，並取代自己標示值。 
Step4：並且開始重複 Step2 、Step3 結束條件為所有像素之標示值不在改變，此條件產生即
中止本連通區域法，如圖 14 為八連通標記法示意圖。 
 
 14
圖 16 原圖(左)標記後(右) 
 
本計畫是由一連串之連續動態影像所組成之目標物，如何從中找出可提供辨識之特徵為本章節之
目的。因此本計畫提出了一種以全域人體外觀模型為主之方法，原理在於不同行為動作例如走路、跑
步、跳躍等都是需要一段時間才可以了解其行為動作，另外在影片上說法就是要經過許多的影格才能
表示一個動作的變化，因此本計畫利用行為的此項特徵相一段時間之行為序列壓縮成一張圖像，然後
此圖像當作每個行為的模型，本計畫稱此種圖像模型為序列壓縮圖像(Sequence Compressed Images, 
SCIs)，每個 SCI 中都還含有時間與外觀的資訊，使用此種方式可以很容易在不同的行為之間做識別與
分析。 
在 SCI 的建立上首先必須要了解目標物之長、寬資訊以及其座標位置，因此必須求取目標物之最
小邊界矩陣來表示目標物之範圍，如圖 17。 
 
 
圖 17 目標物之最小邊界矩形 
 
經過上圖我們求得之目標物最小邊界矩形，也知道其整張圖像長為 himg 與寬為 wimg 之後，接下
來進行圖像中心化，此程序是為了再不同行為時，每個行為並不會在畫格中心的位置上而是隨行為而
在每個畫格中的不同位置，而我們必做中心化的動作讓每個目標物能夠在畫格的中心，這最後續的處
理佔有很重要的地位；獲得長寬高後也就可以知道其座標位置，也可計算出最小矩形之寬 ws 和長 hs
之大小後，在求其目標物之中心像素之座標，獲得中心點座標後再算出整張圖之像素中心點後，並另
兩個像素中心點座標相等，即可獲得如圖 18。 
 
 
圖 18 影像中心化後 
 
經過影像中心化後， 接下來進行行為的序列壓縮，本計畫是以每個行為以 16 個畫面壓縮成一個
w
img
 
h
img
 h
s
 
w
s
 
w
img
 
h
img
 
h
s
 
w
s
 
 16
由上述之方法後，本計畫利用實驗資料 KTH 做為方法說明之實例，所使用之行為資料庫範例將經
過序列壓縮之列壓縮圖像表示於下圖 21 中，(a)為資料庫原始圖像其行為拳擊、拍手、揮手、快跑、慢
跑、走路而(b)為經 XOR 壓縮後之圖像，由圖(b)可明顯的了解本實驗之行為特徵所在，其特徵值輪廓
軌跡的變化為基礎的圖像為特徵值來進行辨識。 
 
   
拳擊 拍手 舉手 
   
慢跑 快跑 走路 
(a)原始行為圖 
   
拳擊 拍手 舉手 
   
慢跑 快跑 走路 
(b) 序列壓縮圖像 
圖 21 人體行為分類 
 
本計畫使用圖像大小為 320×240，但是本計畫希望在演算法的計算上加快其辨識速度，所以經為過
行為序列壓縮後之圖像我們必須從 320×240 縮小至 80×60 之圖像大小以加快演算法之運算速度。最後
在放置行為辨識之演算法時，須進行圖像轉向量的程序如圖 22 為轉換示意圖，此程序是為了針對類神
經之讀檔方式，另外有一個優點就將二維的圖像轉為一維的向量時整體的辨識效率也可提升。 
 
 18
∑
 
圖 23 資料傳播示意圖 
 
圖 24 類神經網路架構 
 
經過前面敘述後，針對整個辨識之架構有了初步的了解，因此在本章節因此從較細微的部分切入，
主要針對訓練演算法之結構進行演算法步驟說明。本計畫使用部分傳統之倒傳遞學習但在反向運算時
使用了與傳統較不相同之方法，在傳統倒傳遞演算法中其架構屬於前向式架構。此架構包含兩種的運
算方式，前向運算(Forward Computation)及反向運算(Backward Computation)如圖 23。前向運算是利用
連結各層的權重值並計算每個神經元之輸出值及誤差函數；而反向運算則是利用前向運算所獲得之誤
差函數，再經由輸出層反向至隱藏層再返回輸入層，透過來回一層一層的動作，來更新各層之間之權
重值，其學習終止之條件為誤差小於一定之門檻值則停止學習，倒傳遞之學習流程如下： 
Step1：網路初始化，學習循環 k=0，設定學習率	η，使用隨機亂數將權重值設定於-1~1 之間的實數。 
Step2：輸入序列壓縮圖像之 4800×1 特徵向量。 
Step3：計算輸入向量隱藏層中之神經元輸出，如公式(9)、 (10) 
 
 20
 
ec = −hcja	chcjkc + lc|hc|1 (17) 
 
公式(17) 中	kc 則可表示為公式(18)： 
 
kc = a′	c + mchc − a	cmc 	 , 0 < mc ≤ 1 (18) 
 
由公式(17)中可了解	c 之學習率大小，其可以使誤差函數值之二階微分值最小。而(18)式中之 kc 
則以不同之方法趨近於	a"	chc。在(17)式中	lc表示為比例參數，並且以二階誤差來趨近於真實誤差，
其中	lc在每次疊代(Epoch)中做調整。最後權重值得更新方式以公式(19)表示： 
 
dc = ec	hc (19) 
 
經過上述之方式調整前一章節之參數，可明顯增加其收斂數度，當網路訓練完畢後，便可以使用
訓練完之網路資料庫來做辨識的工作。在辨識的階段中只有利用前向運算的階段，不會再用到反向運
算階段，最後只要輸入特徵向量，便可以透過網路所產生之回想過程得到一個推論向量，此推論所產
生之向量就是網路的行為辨識結果。經過前述的修正說明，以下為 SCG 演算法其步驟的說明以及推論： 
 
Step1：選擇及初始化之權重向量w，設定p = r = −E′	w, k = 1, σ > 0, λ > 0 and λu > 0，
success = true. 
Step2：計算二階資訊 
 
mc = m|hc| (20) 
c = a′	c + mchc − a′	cmc  (21) ;c = hcjc (22) 
 
Step3：掃描步長	sw： 
 
	c = 	c + 	lc − lcuuuhc (23) ;c = ;c + 	lc − lcuuu|hc|1 (24) 
 
Step4：假使;c ≤ 0使 Hessian 矩陣為正定： 
 
	c = 	c + 	lc − 2 ;c|xc|1hc (25) 
lcuuu = 2	lc − 2 ;c|hc|1 (26) ;c = −;c + lc|hc|1，lc = lcuuu (27) 
 22
 
圖 26 倒傳遞學習結合 SCG 演算流程圖 
 
最後本計畫必須說明，當類神經網路經由的樣本訓練完成後，雖然神經網路的輸出值已經和我們
所要求的目標值相當接近，但這只算是對訓練組的樣本進行最佳化，其時在訓練的過程中本計畫加入
了驗證樣本其加入目的為測試其推廣性，看看是均方根誤差是否會太高。推廣性也是類神經網路中的
其中一項優點之一，當類神經網路訓練全部完成後，對於與訓練樣本相近之輸入，類神經網路通常能
夠給予一個合理之輸出，但是如果最後測試樣本與訓練樣本的差異過大，類神經網路仍就是無法給予
正確的數值。因此當驗證樣本驗證之結果，其均方根誤差低於某一特定範圍。則整個學習之過程即可
算完成。若驗證樣本的驗證效果沒有達到要求，則可稱之為學習的結果推廣度低，則必須重新學習如
圖 25 所示。 
 
 24
 
其中，|G_| 表示第 t 時刻估計出的大小；|_| 表示第 t 時刻目標物實際的大小；|G_ ∩ _| 表示兩
交集的面積；_	數值介於 0到 1之間	，_越小代表追蹤結果越準確。非重疊區域比可以分為以下四種
狀況： 
 
 
 
(a)0 < _ < 1 (b)	_ = 0 
 
 
(c)	_ = 1 (d)	0 < _ < 1 
圖 27 非重疊區域比的四種情況。 
 
本實驗使用了兩部我們自己所拍攝的影片進行模擬，畫面解析度為 320×240，畫面速率(frame rate)
為 30fps。其中影片(一)特點是背景在教室中，由於黑板與牆磚造成背景強烈的對比，一般的背景相減
法經過相減二值化後，容易造成目標物分割錯誤的情況。影片(二)背景較為複雜，許多的椅子會產生雜
訊，時間的變化也會使燈的光度產生些微的變化。其本系統輸出的結果如圖 28、29。 
 
(a) (b) 
 26
表 1 本計畫在兩部影片執行追蹤的結果 
影片序列 平均重疊誤差比/% 平均時間 ms 總畫面張數 
影片(一) 0.134±0.076 33.359±3.63 388 
影片(二) 0.159±0.093 34.293±4.77 1087 
 
表 1 本計畫在兩部影片執行追蹤的結果顯示，平均重疊誤差比皆有不錯的效果，而計算每張畫面
的平均時間維持 33-34ms 左右，符合現實系統所需求的每秒三十張畫素。 
執行追蹤後，本實驗使用 1.3 小節所提到之特徵擷取之方法，最後在應用倒傳遞神經網路結合比
例共軛梯度法來進行行為辨識，在資料庫部分使用四部我們拍攝的影片做為訓練樣本，其中資料庫的
人體行為包含了站立(Standing)、向左走、向右走(Walking)、蹲下(Squat)、舉手(Hand-Waving)、臥倒(Lie 
down)六種動作，如圖 30，其中 S1、S2、S3、S4 表示在不同情境下所拍攝的影片。 
  
站立 向左走 向右走 
S1 
   
S2 
   
S3 
   
S4 
   
 
舉手 蹲下 臥倒 
S1 
   
S2 
   
 28
 
圖 31 正切雙彎曲轉移函數 
 
@ = @Ab	A (36) 
 
經過表 2 之參數設定過後，本實驗中由 4 部短片進行行為序列特徵擷取後，每段影片都有多個行
為樣本做為訓練樣本(包含驗證樣本)。最後利用倒傳遞神經網路學習並使用比例共軛梯度演算法尋找最
佳值，此實驗以比例共軛梯度演算法訓練，因模擬環境屬於隨機抽取樣本數理面之訓練樣本與測試樣
本屬於隨機決定，所以本計畫中每部影片必須進行 20 次的實驗在經過平均才可獲得較為準確之值。 
 
表 3 影片(一)人體行為辨識率(總畫面張數：388) 
     輸出 
輸入 站立 向左走 向右走 舉手 蹲下 臥倒 
站立 94.88 2.825 2.68 3.12 0 1.33 
向左走 2.63 94.41 3.29 0 0 0 
向右走 2.49 2.765 94.03 0 0 0 
舉手 0 0 0 95.67 1.92 0 
蹲下 0 0 0 1.21 96.47 1.82 
臥倒 0 0 0 0 1.61 96.85 
平均辨識率 95.385 
 
表 4 影片(二)人體行為辨識率(總畫面張數：1087) 
     輸出 
輸入 站立 向左走 向右走 舉手 蹲下 臥倒 
站立 94.52 3.35 3.28 3.54 2.13 1.01 
向左走 2.37 93.23 3.66 0 0 0 
向右走 3.11 3.42 93.06 0 0 0 
 30
of the Human Body”, IEEE Transactions on Pattern Analysis and Machine Intelligence, 19(7), pp. 
780-785, 1997  
[7] J. Batista, P. Peixoto, P. Araujo, “Real-Time Vergence and Binocular Gaze Control,” IRSO907-IEEE/RS 
Int. Conf. OnIntelligent Robots and Systems, 1997  
[8] L. Zhao, C. E. Thorpe, “Stereo- and Neural Network-Based Pedestrian Detection,” IEEE Transactions on 
Intelligent Transportation Systems, 1(3), pp. 148-154, 2000  
[9] M. Oren, C. Papageorgiou, P. Sinha, E. Osuna, T. Poggio, “Pedestrian Detection Using Wavelet 
Templates,” CVPR, pp. 193-199, 1997  
[10] C. Anderson, P. Burt, G. V. D. Wal,“Change detection and tracking using pyramid transformation 
techniques”, Proc. of SPIE-Intelligent Robics and Computer Vision, 579, pp. 72-78, 1985  
[11] J. Black, T. Ellis, “Multi Camera Image Tracking,” Image and Vision Computing, 24(11), pp. 1256-1267, 
2006  
[12] Q. Zhou, J. K. Aggarwal, “Tracking and Classifying Moving Objects from Video,” Proceedings 2nd 
IEEE Int. Workshop on PETS, 2001  
[13] Erik Sundnes Løvlie, Automatic recognition of unwanted behavior, Master’s Thesis, Norwegian 
University of Science and Technology, 2006  
[14] A. Mokhber, C. Achard, M. Milgram, “Recognition of human behavior by space-time silhouette 
characterization,” Pattern Recognition Letters 29, pp. 81-89, 2008  
[15] T. Nakata, “Temporal Segmentation and Recognition of Body Motion Data Based on Inter-Limb 
Correlation Analysis,” IEEE/RSJ International Conference on Intelligent Robots and Systems, pp. 
1383-1388, 2007  
[16] J. J. Wong, S. Y. Cho, “A local experts organization model with application to face emotion recognition,” 
Expert Systems with Applications, doi:10.1016/j.eswa.2007.10.030, 2008  
[17] T. B. Moeslund, A. Hilton, V. Kruger, “Asurvey of advances in vision-based human motion capture and 
analysis,” Computer Vision and Image Understanding, 104, pp. 90-126, 2006  
[18] M. Ozeki, Y. Nakamura, and Y. Ohta, “Human Behavior Recognition for an Intelligent Video Production 
System,” LNCS 2532, pp. 1153-1160, 2002  
[19] A. Galata, N. Johnson, and D. Hogg, “Learning Variable-Length Markov Models of Behavior,” 
Computer Vision and Image Understanding, 81, pp. 398-413, 2001  
[20] S. Gong, J. Ng, J. Sherrah, “On the semantics of visual behaviour, structured events and trajectories of 
human action,” Image and Vision Computing, 20, pp. 873-888, 2002  
[21] 劉成祥，利用視訊資料作人體走勢分析，國立中央大學資訊工程研究所碩士論文，2002  
[22] 黃少鵬，以主動式外觀模型為基礎之人體行為分析，國立中央大學資訊工程研究所碩士論文，2008  
[23] 陳怡君，利用軌跡特徵分析行人異常行為，國立中央大學資訊工程研究所碩士論文，2006  
[24] CASIA Action Database, http://www.sinobiometrics.com 
[25] L. Wang, W. Hu, T. Tan, “Recent developments in human motion analysis,” Pattern Recognition, 36, pp. 
585-601, 2003  
[26] M. K. Hu, “Visual Pattern Recognition by Moment Invariants,” IEEE Transactions on Information 
Theory, 8, pp. 179-187, 1962  
[27] L. M. Fuentes and S. A. Velastin, “People tracking in surveillance applications,” In 2nd IEEE 
International Workshop on Performance Evaluation of Tracking and Surveillance (PETS 2001), Hawaii, 
2001  
國科會補助專題研究計畫出席國際學術會議心得報告 
                                     日期：101 年 7月 21 日 
一、參加會議經過 
此次前往希臘-雅典參加 IIHMSP-2012 國際研討會。於會前先至雅典大學內與當
地教授商討合作事項，並互相交換相關研究領域之研究心得與取得之研究資料，隨
後出席第八屆智能資訊隱藏與多媒體訊號處理會議。本人於此次會議與相關領域內，
頗具學術權威之先進前輩討論相關研究領域未來之發展方向與可能的研究潛能，對
於解決本計畫中所遇到之困難有莫大之幫助。會議結束後，與主辦會議幾位核心人
士及相關領域之先進前輩討論，相關研究領域未來之發展方向。隨後於會議結束隔
天返台。 
 
二、與會心得 
此次出席 IIHMSP-2012 國際會議除了與雅典大學師生建立良好友誼關係之外，
亦於本次參與之研討會中獲得許多研究相關領域知識與新的靈感。本次會議與會人
計畫編號 NSC 98－2211－E－151－036－MY3 
計畫名稱 智慧型視訊監控系統之人體行為辨識與分析（第 3 年） 
出國人員
姓名 潘正祥 
服務機構
及職稱 國立高雄應用科技大學   教授 
會議時間 101 年 7 月 18 日至 101 年 7 月 20 日 會議地點 希臘 雅典 
會議名稱 
(中文)第八屆智能資訊隱藏與多媒體訊號處理會議(IIHMSP-2012) 
(英文) The Eighth International Conference on Intelligent Information 
Hiding and Multimedia Signal Processing 
發表題目 A New Statistical Based Algorithm for ECG Identification 
國科會補助計畫衍生研發成果推廣資料表
日期:2012/10/26
國科會補助計畫
計畫名稱: 智慧型視訊監控系統之人體行為辨識與分析
計畫主持人: 潘正祥
計畫編號: 98-2221-E-151-036-MY3 學門領域: 影像處理
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
建立一人體行為資料庫及分析系統。 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
