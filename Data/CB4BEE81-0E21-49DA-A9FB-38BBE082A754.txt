2一、前言
1.1 計畫緣由
在地小人稠的台灣，研製智慧型運輸系統(ITS)以解決民眾塞車的不便，是有
其迫切性的。相對於現行的交通廣播電台的路況報導，ITS 系統可以提供更多樣、
更聰明的的服務，不只是收集、報導路況，更可以作行車路徑的規劃而讓用路人
避免塞車之苦。很明顯的，一個 ITS 系統必須要能夠同時應付許多人的路況資訊
查詢、及路程規劃之請求，再者這些描述路況及路徑規劃的文字敘述必須由電腦
軟體來自動產生(因為人工太慢、且人工費用很高)。當一個駕駛人打電話給 ITS
系統來要求服務，ITS 系統要如何把產生出的文字敘述傳達給駕駛人，很明顯地
我們必須顧慮駕駛人的安全與舒適，不能叫他一邊開車一邊看簡訊文字，所以必
須先作文字翻語音(text-to-speech, TTS)的處理，再將含有路況路徑資訊的語音播
放給駕駛人聽。由於敘述路況、路徑的文字都是以動態方式、且依駕駛人的需求
來產生的，所以不可能事先請播音員來錄製文字敘述所對應的語音訊號。因此本
計畫和另一計畫 智慧型運輸系統之信息整合與處理 的”content planning”組件互
動，由該組件來產生路況資訊的文字描述，然後由本計畫來作文字翻語音的處理。也
就是說，我們期望能提供如目前已在使用的 1968 的路況報導專線，但是我們希
望能夠自動產生，並能即時擷取資訊及結合資料庫的使用。
1.2 整合式 語音合成 的研究動機
國內外一直有不少人在從事文字翻語音(TTS)相關問題的研究，目標是要讓
電腦接收到任意的文句時，都能輸出像人講的一樣自然、流暢的語音，因此研究
者多以自然度、流暢度、清晰度來評估一個文字翻語音系統的效能，自然度是要
評斷是否像人講的一樣自然而無機器腔(味)，流暢度是要評斷整句話、整篇話是
否流暢而無斷續、或不連續的感覺，清晰度是要評斷信號是否清晰而無雜訊、迴
音(reverberation)。一般來說，一個文字翻語音系統可看成是由(a)文句分析(text
analysis)，(b)韻律參數產生(prosodic parameter generation)，(c)信號波形合成(signal
waveform synthesis)等三個組件所構成，其中韻律參數(pitch contour, duration,
amplitude)數值的決定，對於自然度具有關鍵性的影響，而所使用的信號波形合
成方法，是信號清晰度的一個主要決定因素。
4文句，要如何判斷它是屬於那一個語言的呢？不過，在 ITS 的應用裡，我們可假
設輸入的文句的詞語邊界訊息，可由 ITS 系統中產生文字敘述的模組提供，且欲
合成的語言種類，也是由文字敘述產生模組來指示，則要把簡化過的文句分析功
能作跨語言的整合，就變成是可行的。
以往的文句翻語音系統，若要作多種語言的語音合成，則必需為每一種語言
建立各自的韻律參數(基週軌跡)模型，這樣的作法有兩個缺點，第一個是訓練語
料錄製上的困難性；第二個是，每加入一個新的語言，就要耗費很大的人力、時
間成本，以建立該語言的模型。在訓練語料錄製上，需要一位精通各種語言、且
口齒清晰的人，以錄製各種語言的訓練語料，而要找一位精通各種語言且口齒清
晰者，則是很因難的。此外，當要加入新的一種語言，就必需耗費人力、時間來
錄製該語言的訓練語料，以便建立對應的韻律參數模型，這是資源的浪費。因此
本計畫研究了一種能夠整合、支援三種語言之韻律參數模型的作法，以節省研究
的資源與時間花費；此外，使用同一個軟體模組來作三種語言的語音信號合成，
即整合式的信號合成，其好處是，信號合成方面的任何改進(如流暢度或清晰度
的改進)，三種語言都可同時受益，而不需花費三倍的時間、氣力，去對個別語
言的軟體模組作更改。
1.4 語言辨識 的研究動機
在許多需和人應答的自動化服務中，語言辨識亦為重要的前置處理。由於能
瞭解各種方言的人並不是相當常見，透過語言辨識，就可將撥入電話自動轉接至
熟悉該方言的人。自動化的語言辨識處理，也可以省略掉互動系統中擾人的「國
語請按 1、台語請按 2......」之類的開場說明，如此就可以節省時間，而用以服務
更多的人。
本計畫研究以整合的方式來提供國、閩南、客三種語言的 TTS 功能，那麼
相對的一個問題是，如何知道打電語給 ITS 系統的駕駛人，他正在使用那一種語
言發音？所以一個 ITS 系統也需要具備語言辨認的能力，以便依照使用者的語
言，來回應所查詢的問題。因此在本計劃裡，我們也對語言辨識的問題進行了研
究，並作了實驗測試。
6體執行後的一個視窗畫面如圖 2-1 所示，此軟體除了提供輸入、查詢的功能之外，
還提供了音標符號轉換的功能，可將”台語羅馬字”符號轉換成”通用拼音”符號。
圖 2-1 語詞對照輸入之輔助軟體
使用如圖 2-1 所示之輔助輸入軟體，本計畫參考吳秀麗小姐的「實用漢字台語讀音」
教材[2]，已經輸入了 11,362 個閩南、國語的對照語詞，其中 6,190 個是雙字詞。在客
家語方面，我們參考了何石松、劉醇鑫先生的「現代客語詞彙彙編」[3]，目前輸
入了 13,576 個客語、國語的對照語詞，其中 8,426 個是雙字詞。
2.2 基本音節錄音 和 基週標記軟體
由於國語、閩南語、客語都是以音節為語音單位，所以我們的整合式 TTS
系統選擇以音節作為信號合成處理的單位。雖然過去我們已成功地使用 TIPW
(time-proportioned interpolation of pitch waveform)法[4]來作國語音節信號的合成
處理，但是我們知道，閩南語和客家語都有的入聲韻音節（以 p ,t ,k ,h 結尾），
是國語中所沒有的，並且在閩南語和客語裡，入聲韻音節具有高、低兩種聲調，
而其它的音節則會以 5 種聲調之一來唸。關於入聲韻音節的信號波形合成，在以
前研究客家語語音信號合成時，我們已經修正了 TIPW 法，以考慮入聲韻音節結
尾的切音波形[5]，所以入聲韻音節的信號合成，我們已有經驗。
8三、整合式語音合成之 系統建造
在計畫的第二個年度裡，我們完成了如下的工作項目: (a)文句分析，定義一
些標記符號，以讓產生路況報導文字的另一子計畫可以傳遞必要的資訊；剖析這
些標記符號的程式已完成。(b)韻律參數產生，我們採取 ANN 與 SPC-HMM 的混
合模型，來建立基週軌跡(pitch contour)模型，然後研究、比較閩南語模型調適後
產生出的國語基週軌跡，和原生國語模型產生出的軌跡，發現調適模型雖可產生
出聽得懂的軌跡，但是自然度會比原生模型的差一些。(c)對於 TIPW 信號波形合
成法[4]，一個音節內各音素的時間分配的比例，研究使用片段線性之時間扭曲
(warping)函數，來取代原先的線性扭曲方式，結果發現可讓流暢度獲得明顯的提
升。(d)整合各部分的軟體模組，製做成一個三種語言的文句翻語音系統，也就是
可在句子之間插入標記符號，來作動態的語言切換，而整體系統的主要處理流程
就如圖 3-1 所示。
三種語言整合的語音合成系統，已初步完成，可供作線上測試。但是仍有不
少細節的問題需要再考慮，如閩南語裡的變調問題、破音字問題。
圖 3-1 整合式語音合成系統之主要處理流程
text input
text-analysis A
text-analysis B
pronunciation
dictionary
syllable pitch-contour
generation (ann, hmm)
amp. & dur. value generation
(rule-based)
ANN & HMM
model parameter
time-warping mapping
(phone boundary mark)
signal waveform
synthesis (TIPW)
speech signal
speech-units:
waveform, pitch peaks,
boundary location.
10
即只建造出閩南語的基週軌跡模型，再經由聲調調號的對映(mapping)，就可用
以為三種語言產生出基週軌跡的參數值。另外在音長、音量方面，我們也是只建
立了一套規則，而不是分別對各語言去訂定規則。
關於基週軌跡模型的建造，由於閩南語的聲調數量為 7，比國語的 5 個多，
且比客語(7 個聲調)容易找到人錄音，因此我們決定以閩南語作為工作語言，也
就是只需錄製閩南語發音的訓練語句，共錄了 643 句 3,696 字。然後使用這些語
句來分別訓練出 ANN (artificial neural network)和 SPC-HMM (syllable pitch
contour hidden Markov model)的基週軌跡模型，之後當要產生基週軌跡參數時，
就讓 ANN 和 SPC-HMM 模型先各自產生出參數向量 Ca 和 Ch，再將 Ca 和 Ch 作混合
(即加權和)，如此用以兼顧基週軌跡的穩定性(SPC-HMM 較穩定)和活潑性(ANN 較
活潑)[6]。
如果要合成的是客語(海陸腔)語音，如:”shit-8 bau-2 le-1”，首先可將聲
調 8 對映至閩南語的聲調 4，聲調 2 對映至聲調 5，聲調 1 對映至聲調 2，然後
將”shit-4 bau-5 le-2”當作是閩南語語句，帶入前述的基週軌跡模型，去求得
基週軌跡參數。同理，如果要合成的是國語語音，也可先作聲調的對映，再帶入
基週軌跡模型，去求得基週軌跡參數。國語和客語的較詳細的聲調對映關係，如
表 3-2 和 3-3 所示。
表 3-2 客語聲調對映
客語(海陸)調號 1 2 3 4 5 7 8
閩南語調號 2 5 3 8 1 7 4
表 3-3 國語聲調對映
國語調號 1 2 3 4 5
閩南語調號 1 5 3 2 4
由於以前我們曾錄製過國語的訓練語句，用以研究、建造國語的基週軌跡模
型。因此在本計畫裡，我們便想探討調適過的和原生的國語基週軌跡模型(也是
ANN 和 SPC-HMM 混合)，在所產生的基週軌跡參數上(其它因素控制為一致)，是
否會造成合成語音在自然度上的明顯差異? 我們首先用調適的和原生的模型分
別合成出一段短文的語音信號，然後進行聽測，結果發現使用原生模型的合成語
音，其自然度確實是會比使用調適模型的好。所以，調適的基週軌跡模型，雖可
12
Ra = Rs –Rm –Rn
圖 3-2 片段線性時間扭曲函數
在使用公式(3-1)來作時間長度的分配之前，必需要先對原始音節作音素邊界
的標記處理，目前我們是以人工方式來作。對合成出的語音作聽測後，我們發現
即使只使用如公式(3-1)的簡單規則，已經可以使合成語句的流暢度獲得明顯的改
進。未來，我們將再研究比較系統化的方法，來建立原始音和合成音之間的時間
扭曲函數，期望能獲得更多的流暢度提升。
3.4 線上測試 與 論文發表
對於本計畫所製作的國、閩南、客語的整合式語音合成系統有興趣者，可瀏
覽網頁 http://guhy.csie.ntust.edu.tw/hmtts/，去試聽預先合成的語音檔案。如果要
作線上的測試，則可連至 http://guhy.csie.ntust.edu.tw/hmtts/speak.html，從網頁輸
入想要合成的文句。
目前我們已經把整合式語音合成的研究成果，寫成會議論文和期刊論文，會
議論文發表於 2006 International Symposium on Chinese Spoken Language Processing
(Singapore)；期刊論文已被接受，將刊登於中華民國計算語言學會的期刊 :
International Journal of Computational Linguistics and Chinese Language Processing，期刊
論文的標題是“A System Framework for Integrated Synthesis of Mandarin, Min-nan, and
Hakka Speech”，而全文則如附錄 A 所示。
synthetic-syllable time axis
tRm Ra Rn
Dm
Da
Dn
t’
14
4.2 系統的處理流程
我們研究的語言辨識系統，可分割成兩階段來看，亦即訓練階段和辨識階
段，而整體的流程如圖 4-1 所示。在訓練階段，訓練語料經過特徵萃取後，進行
模型訓練，得到 3 種語言各自的 4 組模型參數(共 12 組)、然後以檔案儲存。在辨
識階段，一樣先對輸入的待測語音進行特徵萃取之處理，接著讀取 12 組參數來
計算各語言的分數，最後輸出辨識的結果。
圖 4-1 語言辨識系統之主流程
我們採用高斯混合模型(GMM)來模式化各語言的聲學特性，並且以 PPM 模
型來模式化各語言之語音發音的時序關係。一開始先作語料的蒐集，然後使用各
語言分別蒐集到的訓練語料來訓練該語言的模型，模型參數可分為四個種類：聲
道 GMM 參數、聲道 PPM 參數、聲調 GMM 參數、聲調 PPM 參數。訓練階段的
處理流程如圖 4-2 所示，原始 wav 檔語料先經過特徵萃取函數轉換成 MFCC 向
量及音高軌跡向量，接著作 K-Mean 分群後建立初步的 GMM 模型，再以 MLE
或高斯機率 K-Mean 方法加以訓練，而得到較為精確的 GMM 模型。完成後再用
GMM 對各音框進行表徵化(tokenize)處理，來轉換成一序列的表徵(token)代碼，
再使用此表徵序列去訓練出一個 PPM 模型。
如圖 4-3 所示，在辨識階段裡，測試的語音信號由檔案或即時由麥克風輸入，再經
過聲道與音調各自的 GMM 和 PPM 模型作機率量測，而得到各語言的分數，分數最高
參數萃取
模型訓練
計算分數參數萃取
訓練語料
MFCC GMM 3
MFCC GMM 2
MFCC GMM 1
Pitch GMM 3
Pitch GMM 2
Pitch GMM 1
MFCC PPM 1
Pitch PPM 1
辨識結果待測語音
16
4.3 特徵擷取
由於原始語音波形的資料量太大且無穩定的特徵，故我們必須抽出對辨識有
用且易於處理的特徵參數。本研究使用了兩類的特徵參數，分別是聲學(acoustics)
特徵和音調(pitch)特徵。
聲學特徵: 一個音框的分析，最常用的方法是離散傅立葉轉換(Descrete
Fourier Transform, DFT)，經由傅立葉轉換，可以把本來在時域上的信號 x[n]轉換
成頻域上的信號 S[k]。轉換到頻域後，可更進一步處理頻域信號，以萃取最能代
表語音內容的特徵。倒頻譜(cepstrum)描述了人講話時的聲道形狀，它的算法如
下：將離散的頻域訊號 S[k]取絕對值後再取對數而得到 L[k]，再對 L[k]作離散傅
立葉反轉換，就可得到倒頻譜係數 C[n]。這種 C[n]序列有個特性，就是激發信號
引起的係數會在較後方，所以抽取 C[n]序列的前段係數就可以將聲道響應獨立出
來作為特徵參數使用。
在此我們採用 20ms 的音框(frame)，每個音框之間重疊 10ms，並且從各音框
去求取 12 維度的梅爾倒頻譜係數 (Mel-Frequency Cepstrum Coefficient,
MFCC)，係數求取實際上是使用 HTK (HMM TooKit)，也就是我們的程式內含必
要的 HTK 原始碼，並且直接呼叫 HTK 提供的外部函數。此外，由於要考慮音框
之間的關聯性，我們再取三個音框的距離來計算另外 12 維度的差分係數，即
3k k kC C C  
  
，k 為音框編號。
音調特徵: 由於國、閩南、客語都是有聲調的語言，所以音高軌跡具有重要
的語言意義，我們於是把音高軌跡當作特徵參數來使用。語音的音高(pitch)代表
人在發聲時聲帶震動的頻率，也就是語音訊號的基頻(F0)。語音訊號可分成兩種，
一種是聲帶有週期性振動的有聲(voiced)語音，另一種是無週期性振動的無聲
(unvoiced)語音。所有的母音都是有聲，子音則分成有聲和無聲。由於無聲語音
不具有週期性而不能估計出基頻，因此我們只能球取出有聲部分的音高軌跡。
計算出所有有聲音框的音高後，再採用中值平滑法和動態規劃法來修正估計
音高時可能出現的倍頻或半頻的錯誤[17]。為了去除語者間的音高位準之差異，
我們對每個語音檔案作了 Zero Mean 處理，將各個音框的音高減去所有有聲音框
18
2
,
1
0
1
( | ( ) )
1
(( ) | ( ) ), if
0, if
j n n
nj
n n nm n
njj
j
j K
k
k
x g x j
N
x g x j m n
NC
m n
N
w
N




 
   
 




(4-4)
為了減少計算量，我們假設特徵向量各維間互相無關，所以共變異矩陣是一
個對角矩陣。得到初始值後，就可計算訓練語料對現在模型的 Log Likelihood，
Lg(λ)：
1 1
00
( ) log ( | ) log ( | )
N N
g i i
ii
L P x P x  
 

  (4-5)
要求極大值，可對 L(λ)分別以μj、Cj 和 wj 微分，分別令微分值為 0 後，就可得
到以下公式[14, 15]：
)(
)(
)(
i
ijj
ij xP
xDw
x  (4-6)







 1
0
1
0
)(
)(
ˆ
N
i
ij
N
i
iij
j
x
xx


 (4-7)
T
jjN
i
ij
N
i
T
iiij
j
xD
xxx
C 


ˆˆ
)(
)(
ˆ
1
0
1
0 







 (4-8)
N
x
w
N
i
ij
j



1
0
)(
ˆ

(4-9)
MLE 利用上述公式迭代修正λ，找出讓 Lg(λ)最大的參數集合。每迭代一次，就
去計算現在的 log likelihood 值，若該值落在一定範圍以內則結束訓練。
4.5 語言辨識之模型--PPM
高斯混合模型可用來模式化聲學特性單獨的出現機率，可是無法模式化它們
之間的時間次序關係。因此我們採取 PPM 來實作 n-gram 模型，以期達到聲學特
20
表 4-1 語料來源及時數
語言 來源電台 語者數 時數
國語 台視、中視、華視、民視、公視 15 (6/4) 0.51hr
閩南語 民視、公視、大愛 19 (6/4) 0.63hr
客語 客家電視台、哈客廣播網 13 (5/5) 0.46hr
在測試時，我們從訓練語料中隨機抽出一定長度的語音作為 Inside 測試的測
試語料，並另外找三個語者，一樣隨機抽出一定長度的語音作為 Outside 測試的
測試語料。測試語料分為 3 秒、10 秒、45 秒，系統整體測試時，3 秒和 10 秒各
語言分別有 199 個測試檔案，45 秒則有 99 個測試檔案。
實驗系統主要以 Borland C++ Builder 6 開發，電腦平台為 Pentium4
2.40GHz、WinXP、以及 1.5GB 的記憶體。
4.7 線外測試實驗
待測語料在抽取特徵向量後，分別由四個子系統來計算機率分數，四個子系
統分別是: (1)MFCC GMM，(2)MFCC PPM，(3)Pitch GMM，(4)Pitch PPM，其畫
分範圍如圖 4-4 所示，四個子系統算出的分數再作加權總和，即為該語言的分數。
圖 4-4 子系統範圍畫分
待測語音特徵向量
GMM 機率計算音框表徵化 GMM 機率計算
PPM 機率計算
音框表徵化
PPM 機率計算
MFCC
MFCC
MFCC GMM
MFCC
MFCC
MFCC PPM
PitchGMM
PitchGMM
Pitch GMM 兼
PitchGMM
PitchGMM
Pitch PPM
語言分數
MFCC
MFCC
MFCC 表徵器
βGMM(0)
βPPM(0)
βGMM(1)
βPPM(1)
子系統(2) 子系統(1) 子系統(3) 子系統(4)
22
語言的辨識錯誤也大部分是被誤判成國語。另外，和只使用子系統(1)和(2)的結
果比起來，加入音調特性對辨識率似乎沒有改進的效果，例如在外部測試裡，整
體系統對於 3 及 45 秒語料的辨識率 (78.0%和 79.1%) 都比子系統(1)和(2)的辨識
率(83.7%和 82.8%)降低了 3.5%以上，而對於 10 秒語料的辨識率也只上升 3.1%
(80.6%-79.6%)。
4.8 線上測試實驗
我們實作了一個可以自動接聽電話然後辨識發話者所用語言的線上辨識系
統，系統內安裝了亦誠科技公司的 VL4P-05O 電話卡來讓軟體可自動接聽電話並
作錄音，其實我們的 C++程式是經由呼叫電話卡提供的函式庫，來控制電話的接
聽和掛斷，作錄音及播音的處理。使用者撥號後，系統會自動接聽並播放提示音
檔，接著進入錄音模式。在錄音模式中，只要使用者停止說話 4 秒，系統就會停
止錄音並進行音檔轉換，然後辨識使用者所用的語言。
由於這張電話卡錄製的語音固定是 8-bit mu-law 8000Hz，所以我們必須另外
撰寫 mu-law 轉成 PCM 的程式。此外，由於電話卡擷取的電話語音和電視、廣播
節目錄製的訓練語料，在取樣率、通道、內容及說話方式等方面皆有差異，故在
此我們對訓練語料作增加的處理動作：(a)由於頻寬差異，先呼叫 Downsampling
模組 libsamplerate，將訓練語料的取樣率降成 8000Hz；(b)作 Cepstrum Mean
Substraction，對每一個檔案求取所有音框的 MFCC 係數的平均向量，然後把該
檔案每一個 MFCC 向量減去平均向量，以除去聲音通道的影響；(c) 重新訓練模
型，得到模型參數值。
這裡準備的測試語料共 30 筆，三種語言各 10 筆，國語語料是由 6 名男性錄
音，閩南語語料是由 5 位錄音，客語語料則由 3 位錄音，每筆語料長度為 5 到
10 秒，內容則模仿電視台播報的短句。由於線外實驗結果顯示音調特徵對辨識
率無甚幫助，故為了節省運算時間，在此只使用圖 4-4 中的子系統(1)和(2)來進行
辨識。MFCC 特徵使用 12 維，差分間距設為 3。
在 MFCC GMM 的混合數方面，當訓練和測試語料特性差異太大時，過多的
混合數會導致輸出分數的偏袒，故需要重新進行混合數的實驗。不過 MFCC PPM
模型的 GMM 表徵器的混合數則只固定為 32，PPM 的階數設為 3 且使用 ppmc
24
參考文獻
[1] 余伯泉、徐兆泉、吳長能，台灣語通用拼音，南天書局，台北，1999.
[2] 吳秀麗, 實用漢字台語讀音, 學生書局, 1997.
[3] 何石松、劉醇鑫, 現代客語詞彙彙編, 臺北市民政局, 2002.
[4] Gu, H. Y. and Shiu W. L., “A Mandarin-syllable Signal Synthesis Method with
Increases Flexibility in Duration, Tone and Timbre Control”, Proc. Natl. Sci.
Counc. ROC(A), Vol. 22, No.3, pp. 385-395, 1998.
[5] 李雪真, 客家語語音合成之初步研究, 碩士論文, 台灣科技大學資訊工程研
究所, 2002.
[6] 黃維，以混合模型產生閩南語音節基週軌跡之研究, 碩士論文, 台灣科技大
學資訊工程研究所, 2005.
[7] Chou, F. C., Corpus-based Technologies for Chinese Text-to-Speech, Doctoral
dissertation, National Taiwan University, Department of Electrical Engineering,
1999.
[8] 張唐瑜，以大量詞彙作為合成單元的中文文轉音系統，碩士論文，國立中興
大學資訊科學研究所，2005。
[9] 蔡仲明，基於 GMM 及 PPM 模型的國、閩南、客語之語言辨識，碩士論文，
國立台灣科技大學資訊工程研究所，2007。
[10] Li, K. and T. Edwards,“Statistical models for automatic language identification”,
Proc. International Conference on Acoustics, Speech, Signal Processing, 1980.
[11] Zissman, M. A., “Comparison of four approaches to automatic language 
identification”, IEEE Trans. Speech and Audio Processing, vol. 4, pp. 31-44, Jan.
1996.
[12] P. A. Torres-Carrasquillo, D. A. Reynolds, and J. R. Deller Jr., “Language
identification using Gaussian mixture model tokenization”, IEEE International
Conference on Acoustics, Speech, Signal Processing, May 2002.
[13] Tsai, W. H. and W. W. Chang, “Discriminative training of Gaussian mixture bigram
models with application to Chinese dialect identification”, Speech Communication, Vol.
36, pp. 317-326, Mar. 2002.
[14] 林俊青，多國語言辨識系統之特徵設計研究，碩士論文，國立中山大學電機
工程研究所，2002。
[15] 張智傑，以高斯混合模型表徵器與語言模型為基礎之語言辨認研究，碩士論
26
附錄 A (期刊論文)
A System Framework for Integrated Synthesis of
Mandarin, Min-nan, and Hakka Speech
28
independently developed speech synthesis systems for different languages. Therefore, a better
approach is to construct a more generalized system that can synthesize not only Mandarin but
also Min-nan and Hakka speech. Such an approach, if successfully realized, can not only save
resources but also obtain much higher consistency among the synthesized speech for different
languages. Another advantage is that an improvement, when made to a system component, can
immediately benefit all the languages supported.
Mandarin, Min-nan, and Hakka are all syllable prominent languages, and are all tonal
languages. Hakka has many accents found in users in Taiwan, of which “four-country”and
“sea-land”are the primary ones. If not specified, the sea-land accent is the default accent
representing Hakka in this paper. This is because it has more lexical tone and more unique
syllables than the four-country accent has, and the authors believe the speech signal of the
sea-land accent is more difficult to synthesize. As to the number of different syllables (not
distinguishing lexical tones), Mandarin has 405, Min-nan has 833, and Hakka has 783 [Yu
1999]. The languages also vary in the numbers of different lexical tones, being 5, 7, and 7,
respectively, for Mandarin, Min-nan, and Hakka. Since the numbers, 405, 833, and 783, are
not large, syllable is commonly chosen as the speech unit for synthesis processing. Actually,
in this system, each syllable (tone not distinguished) of a language has only one recorded
utterance. That is, no extra units are available to do unit selection, and each syllable’s
waveform must be manipulated to synthesize speech signals with different required prosodic
characteristics.
Note that the focus of this study is in the system framework of an integrated speech
synthesis system for the three languages. To show the feasibility of the proposed framework, a
workable integrated synthesis system is built. This system is just in its initial phase. Therefore,
there will be many unsolved problems in the details. Most of these problems belong to text
analysis since signal synthesis is the major concern in this research while text analysis is just a
minor concern. In general, a speech synthesis system can be divided into three subsystems, i.e.,
(a) text analysis, (b) prosodic parameter generation, and (c) speech waveform synthesis [Shih
et al. 1996; Wang 1998]. The framework for the integrated synthesis system is also divided
into such subsystems. The main processing flow of this framework is shown in Figure 1. The
first two processing blocks are for text analysis, the middle two blocks are for prosodic
parameter generation, and the last two blocks are for signal waveform synthesis. The synthesis
system built is an integrated system, not a bundle of three independent systems for the three
languages. This is because the program modules in the three subsystems are all shared in
synthesizing the three languages’speech. For example, the model for pitch-contour parameter
generation is shared (or adapted) between Mandarin and Hakka, although it is originally
trained with Min-nan sentences. The explanations for why the program modules can be shared
are given in the following sections.
A System Framework for Integrated Synthesis of
Mandarin, Min-nan, and Hakka Speech
30
2. Text Analysis
In Min-nan and Hakka, there are still many spoken words whose corresponding ideographic
words are not known. Therefore, the authors made a decision that, in the input text, Chinese
characters may be interleaved with syllables spelled in alphanumeric symbols. For example,
“cit-4 tou-5 人”is a Min-nan word whose first two syllables are spelled in alphanumeric
symbols. This decision implies that the input text must first be parsed into a sequence of
Chinese-character and alphanumeric-syllable tokens. For example, “今天 mai-3 ki-3”is
parsed into “今天”, “mai-3”, and “ki-3”. The number at the end of a syllable indicates the
lexical tone of the syllable. This parsing processing is executed in the first block of Figure 1.
In addition, the authors have defined several kinds of tags to help carry some necessary
controlling information. For example, the tag, “@>2”, may be placed between two sentences
to command that the sentences behind the tag will be synthesized to Hakka speech until
another language-selection tag is encountered. Such a language-selection tag is needed
because it is intended that the sentences of an article may be alternatively synthesized to
different languages’speech. Another kind of tag is “@>dxxx”. This tag may also be placed
between two sentences to change the speaking rate of the sentences behind it. The part, “xxx”,
in the tag represents three decimal digits to specify how many milliseconds on average a
syllable will be synthesized to. In addition to the two tags explained, several other kinds of
tags are also defined. The details are listed in Table 1. The parsing of such tags is also
executed in the first block of Figure 1.
Table 1. Tags and their meanings.
Tag symbol Explanation
@>x language selection, x may be 0, 1, or 2.
0: Mandarin, 1: Min-nan, 2: Hakka
@>dxxx speaking rate, syllable average duration in xxx milliseconds.
@>txxx average tone height, in xxx Hz.
@>vxxx vocal track extended (or shrunken) to xxx percents of
original length.
<, > word-constructing tag, e.g., <cit-4 tou-5>
* breath-break tag
After an input sentence is parsed into a sequence of tokens, the pronunciation syllables
for each Chinese character token are determined in the second block of Figure 1. According to
the language-selection tag, the corresponding pronunciation dictionaries are consulted to
check if the prefix part of a token can be found in the dictionaries. A dictionary consisting of
longer words is tried before a dictionary consisting of shorter words. Currently, the authors
have collected 55,000, 12,000, and 19,000 multi-syllabic words, respectively, for Mandarin,
A System Framework for Integrated Synthesis of
Mandarin, Min-nan, and Hakka Speech
32
amplitude values, 0dB, -4dB, -3dB, -2dB, or -1dB. In the word layer, the first syllable of a
word is emphasized 0.5 dB in amplitude. Finally, in the breath-group layer, the first two
syllables of a group are emphasized 1dB and 0.5dB respectively. In addition, the last two
syllables of the last breath-group of a sentence are deemphasized 0.5dB and 1dB respectively.
By interaction of these rules in the three layers, the generated amplitude and duration values
appear to have some randomness, and can present a certain level of naturalness.
3.1 Syllable Pitch Contour HMM
A syllable at the beginning of a sentence is usually uttered with higher pitch than one at the
end, i.e., the phenomenon of declining. With respect to this phenomenon, the authors imagine
that there are three prosodic states corresponding to sentence-initial, sentence-middle, and
sentence-final. However, how to assign a sentence’s syllables to these states is not explicitly
known. Therefore, the authors imagine these prosodic states are hidden and will simulate them
by the hidden states of a left-to-right hidden Markov model [Rabiner et al. 1993]. Besides the
influence of prosodic states, the lexical tones of a syllable and its adjacent syllables also have
strong influences. Therefore, the authors take into account the lexical-tones of a syllable and
its adjacent syllables, and call such an HMM as syllable pitch-contour HMM (SPC-HMM).
The height and shape of a syllable’s pitch-contour are mainly influenced by the lexical
tones of the syllable and its immediately adjacent syllables. Therefore, the authors decide to
combine the t-th syllable’s lexical tone and pitch-contour VQ (vector quantization) code with
its left and right adjacent syllables’lexical tones to define the t-th observation symbol, Ot, as
1 1392 56 8 ,
0 6, 0 7.
t t t t t
t t
O X X X V
X V
      
   
(1)
where Xt is the lexical-tone number of the t-th syllable, and Vt is the pitch-contour VQ code of
the t-th syllable in a training sentence. Actually, the number, Xt, is indirectly obtained, i.e.
lexical-tone number eight is mapped to six beforehand, and then the lexical-tone number is
decreased by one. In Equation (1), the number, eight, is multiplied because there are eight
codewords in each tone’s pitch-contour VQ codebook. The numbers, 56 and 392, may be
viewed as 78 and 778, respectively, and 7 is the number of different lexical tones in
Min-nan and 8 is the number of code-words in a VQ codebook. When t=1, i.e. staying at the
first syllable of a training sentence, Xt-1 is undefined. In this case, the definition of Ot is
modified to 7778 + 56 Xt + 8 Xt+1 + Vt. Similarly, the definition of Ot for the last syllable
of a sentence must also be modified [Gu et al. 2000].
Before VQ encoding, the pitch-contour of each syllable from a training sentences is first
time normalized and then pitch-height normalized [Gu et al. 2000]. Time normalization means
A System Framework for Integrated Synthesis of
Mandarin, Min-nan, and Hakka Speech
34
dimensional frequency vector is output in the output layer. This frequency vector can be
interpreted as a sequence of 16 frequency values along a pitch-contour.
8 con tex tu a l p ara m eters
16 d im . p itch -con tou r
Figure 2. The architecture of the ANN studied here.
Here, the contextual parameters, i.e. the inputs to the ANN, are appropriately selected to
provide essential contextual information and to lower the quantity of required training
sentences. In detail, the contextual parameters are as listed in Table 2. As there are seven
lexical tones in Min-nan, 3 bits are enough to represent them. The numbers of different
syllable initials and finals are 18 and 61, respectively. Hence, 5 and 6 bits, respectively, are
used to represent current syllable’s initial and final types. As to the parameter of the previous
syllable’s final, the authors first group the 61 possible finals into 12 classes, and use only 4
bits to represent the 12 final classes. Similarly, the authors first group the 18 possible initials
into 6 classes, and use only 3 bits to represent the 6 initial classes for the next syllable’s initial.
Grouping is made here because the quantity of recorded training sentences is not large enough
to let the ANN learn the influences of the detailed combinations of current syllable and
previous (or next) syllable. Syllable initial and final classes grouped here are detailed in Table
3 and 4, respectively. The last item in Table 2, the time-progress index, is intended to carry
timing information. If the current syllable is the k-th syllable of a sentence of N syllables in
length, then the value of time-progress index is set to the floating-point number k/N.
Table 2. Contextual parameters.
Items Tone of
previous
syllable
Final
class of
previous
syllable
Tone of
current
syllable
Initial of
current
syllable
Final of
current
syllable
Tone of
next
syllable
Initial
class of
next
syllable
Time
progress
index
Bits 3 4 3 5 6 3 3 void
A System Framework for Integrated Synthesis of
Mandarin, Min-nan, and Hakka Speech
36
Note that some syllable initials and finals of Mandarin (e.g., /yu/) and Hakka (e.g., /oi,
eu/) are not found in Min-nan. With respect to this, it may make one suspect if the adaptation
method can indeed work. However, in SPC-HMM, the definition of observation symbol in
equation (1) does not include syllable initials and finals. This indicates that pitch-contour is
only insignificantly influenced by syllable initials and finals according to previous studies [Gu
et al. 2000; Gu et al. 2005b]. Although the information of syllable initial and final is used in
the pitch-contour ANN, the authors still think that the factors of syllable initial and final are
insignificant according to previous experiments for evaluating classification methods of
Min-nan initials and finals [Gu et al. 2005b]. Anyway, to solve the problem of mismatched
initials and finals between the two languages, the authors let the program automatically select
a similar one (more same letters in spelling) to replace a finial or initial not found in Min-nan.
For example, /yu/ is replaced with /u/, and /oi, eu/ are replaced with /ai, au/ respectively. The
authors think such replacements are acceptable.
The mappings from Hakka tones to Min-nan tones are listed in Table 5. The mapping
from sea-land Hakka to Min-nan, Table 5(a), can be said to be a nice one-to-one mapping
because both have the same number of lexical tones, and for each lexical tone of Hakka one
can find a lexical tone in Min-nan that has almost same pitch-contour shape. The mapping
from four-country Hakka to Min-nan, Table 5(b), is also straightforward. If tone number 7 is
removed from Min-nan, then this mapping is still a nice one-to-one mapping.
Table 5. Tone mapping from Hakka to Min-nan.
(a) sea-land Hakka to Min-nan
Hakka tone number 1 2 3 4 5 7 8
Mapped Min-nan tone
number 2 5 3 8 1 7 4
Example Chinese
characters
衫 短 褲 寬 人 鼻 直
(b) four-country Hakka to Min-nan
Hakka tone number 1 2 3 4 5 8
Mapped Min-nan tone
number 5 2 1 4 3 8
Example Chinese
characters
夫 虎 富 福 湖 復
The mapping from Mandarin tones to Min-nan tones is listed in Table 6. Three of the
Mandarin lexical tones, i.e. high-level, rising, and falling, also exist as Min-nan lexical tones.
Besides these three tones, the low-level tone of Min-nan and the low-dipping tone of
Mandarin are perceived to be almost identical. Therefore, the low-dipping tone of Mandarin
A System Framework for Integrated Synthesis of
Mandarin, Min-nan, and Hakka Speech
38
4. Signal Waveform Synthesis
In this system, each syllable of a language has only one utterance recorded in a level tone
(high or medium level). Therefore, the original syllable waveform must be manipulated to
obtain synthesized waveforms with different prosodic characteristics. The synthesis method
used here is TIPW [Gu et al. 1998]. TIPW is an improved variant of PSOLA, i.e. the effects of
chorus and reverberation are largely reduced. Besides, TIPW is capable of adjusting vocal
track length through re-sampling [Gu 2001].
Originally, TIPW was developed for synthesizing Mandarin speech. Thus, it does not
support the synthesis of signal waveform with suddenly changed amplitude that is often found
at the ending portion of an abrupt-tone syllable, e.g. /zit8/. Nevertheless, abrupt-tone syllables
are very frequently used in Min-nan and Hakka. One method to overcome this difficulty is to
treat the end portion of an abrupt-tone syllable as a stop consonant. Then, the same method
used in synthesizing a stop consonant at the syllable initial portion can also be adopted to
solve this problem.
4.1 A Fluency-Improving Method
In addition, the authors have made another improvement to TIPW. This improvement
significantly increases the fluency of the synthesized speech. In an ordinary speech synthesis
system, the subsystem of prosodic-parameter generating only determines the duration value,
Es, of a syllable to be synthesized. The detailed dividing of syllable duration, Es, to its
comprising phonemes is, however, not controlled by the prosody subsystem. Furthermore, the
subsystem of signal waveform synthesis usually extends (or shrinks) the original speech
waveform to an intended time length in a linear manner. According to this study, linear
extending (or shrinking) of time length is a major cause of a decrease in much of the fluency
of synthesized speech.
Consider an example syllable, /man/. Suppose that, in its original recorded waveform, the
three phonemes, /m/, /a/, and /n/, occupy Dm, Da, and Dn milliseconds, respectively, and Ds =
Dm + Da + Dn. A phenomenon that can be observed is that the ratio, (Dm+Dn)/Ds, will
become smaller when /man/ is uttered within a sentence instead of being uttered in isolation.
Currently, the authors are studying a simple method to simulate this phenomenon. In further
research, the authors will study it with a more systematic method. The method used here is as
depicted in Figure 4. That is, a piece-wise linear function is used to map the time-axis of a
synthetic syllable waveform to the time-axis of its original waveform. In Figure 4, the
symbols,
A System Framework for Integrated Synthesis of
Mandarin, Min-nan, and Hakka Speech
40
4.2 Example Waveforms
4.2.1 TIPW Synthesis Method
Since the synthesis method, TIPW, is not as popular as PSOLA, the authors will illustrate its
processing steps with signal waveforms. To obtain a complete view of TIPW, including a
detailed explanation of the method, see [Gu et al. 1998]. Here, let the two adjacent pitch
periods in Figure 5(a) be around the mapped (using the piece-wise linear mapping function)
time point, m, in a recorded syllable. The first step of TIPW is to determine the weights, w1
and w2, for the left and right pitch periods. The value of w2 is computed as (m -1) / (2 -1)
where 1 and 2 are time points of the left and right pitch periods’centers respectively. The
value of w1 is simply 1 - w2. By weighting the two pitch periods with w1 and w2 respectively,
one can obtain the two waveforms shown in Figure 5(b). Here, weighting a signal waveform
with a weight, w, means that the value of each signal sample in the waveform is multiplied by
the weight, w.
The second step is to window the pitch waveforms with two Hanning (or cosine) window
halves. Here, windowing a signal waveform x(n) with a window function f(n) means that the
result sample value at time n is x(n)f(n), i.e. one-to-one multiplying. The two waveforms in
Figure 6(a) are obtained by windowing the left pitch period in Figure 5(b) with two symmetric
half Hanning windows. Here, the window length, L, is set to the smaller of L1 and Lm where
L1 is the left pitch period’s length and Lm is the length of the period to be synthesized. The
detailed formula for the two window functions used in the left and right sides, respectively, of
Figure 6(a) are:
 ( ) 0.5 0.5cos , 0, 1, 2, ..., 1,nleft Lf n n L     (3)
 ( ) 0.5 0.5cos , 0, 1, 2, ..., 1.nright Lf n n L     (4)
After windowing, the signal samples’values will be depressed in proportion to the window
function’s curve height. This can be seen from Figure 6(a). Similarly, the two waveforms in
Figure 6(b) are obtained by windowing the right pitch period in Figure 5(b) with two
symmetric half Hanning windows. However, the window length is now set to the smaller of L2
and Lm. Note that the window length determination rules are important because they can
prevent the effects of reverberation and dual-tones.
Then, as the last step, the four waveforms in Figure 6(a) and Figure 6(b) are overlapped
and added to obtain a synthesized pitch period whose waveform is shown in Figure 7. Here,
“overlapped”means that the four waveforms’locations on the time axis are left or right
shifted in order that they have same starting or ending times. In detail, the two waveforms on
A System Framework for Integrated Synthesis of
Mandarin, Min-nan, and Hakka Speech
42
4.2.2 Piece-wise Linear Mapping
To demonstrate the effect of the piece-wise linear mapping function, take the Mandarin word,
“農田”(farmland) as an example and show its signal waveforms obtained from the original
recording and the synthesis processing. The waveform in Figure 8 is a direct concatenation of
the recorded waveforms of /nong-1/ and /tien-1/ while the waveform in Figure 9 is synthesized
by this system. From Figure 8, it can be observed that the /ng/ part in /nong/ and the /n/ part in
/tien/ both occupy a large portion of the syllable duration. However, through the remedying of
the piece-wise linear mapping function, this phenomenon is largely reduced, and the fluency
of the synthesized speech is improved greatly. It can be seen from Figure 9 that the duration
ratios of /ng/ to /nong/ and /n/ to /tien/ now apparently become smaller.
ngn nt
/nong-1/ /tien-1/
Figure 8. Direct concatenation of the recorded syllables, /nong-1/ and /tien-1/.
ngn nt
農/nong-2/ 田/tien-2/
Figure 9. A synthetic waveform for /nong-2 tien-2/.
5. Experiments and Results
After the integrated system is implemented and ready to run, perception tests are conducted.
The first issue of concern is the naturalness levels of Mandarin and Hakka pitch-contours
generated by the Min-nan trained pitch contour models. Therefore, three short articles written
in Mandarin, Hakka and Min-nan, respectively, are fed as inputs into the system. Then, the
output speeches are played to each of the persons participating in the tests. Here, ten persons
studying in university were invited to evaluate the synthetic speeches. For each person, two
pairs of speech files were played, (Sn, Sm) and (Sn, Sh). Sn, Sm, and Sh represent synthetic
Min-nan, Mandarin, and Hakka speeches, respectively. Then, the person was requested to give
a score of -2, -1, 0, 1, or 2 for each pair. Here, 2 and -2 mean“better”, 1 and -1 mean“slightly
better”, and 0 means “almostidentical”. As to the sign, positive sign means the latter is more
A System Framework for Integrated Synthesis of
Mandarin, Min-nan, and Hakka Speech
44
Chiou, H. B., H. C. Wang, and Y. C. Chang,“Synthesis of Mandarin Speech Based on Hybrid
Concatenation,”Computer Processing of Chinese and Oriental Languages, 5(1), 1991,
pp. 217-231.
Chou, F. C., Corpus-based Technologies for Chinese Text-to-Speech Synthesis, PhD thesis,
National Taiwan University, Taipei, Taiwan, 1999.
Chu, M., H. Peng, Y. Zhao, Z. Niu, and E. Chang, “Microsoft Mulan - a Bilingual TTS
System,”In Proceedings of IEEE International Conference on Acoustics, Speech, and
Signal Processing, 2003, Hong Kong, China, vol. 1, pp. 264-267.
Gu, H. Y., and W. L. Shiu, “A Mandarin-Syllable Signal Synthesis Method with Increased
Flexibility in Duration, Tone and Timbre Control,”Proceedings of the National Science
Council ROC(A), 22(3), 1998, pp. 385-395.
Gu, H. Y., and C. C. Yang, “A Sentence-Pitch-Contour Generation Method Using VQ/HMM
for Mandarin Text-to-speech,”In Proceedings of International Symposium on Chinese
Spoken Language Processing, 2000, Beijing, China, pp. 125-128.
Gu, H. Y., “Signal Resampling in Speech Synthesis,”In Proceedings of the 5th World
Multi-conference on Systemics, Cybernetics and Informatics, 2001, Orlando, USA, vol.
vi, pp. 521-525.
Gu, H. Y., and H. C. Tsai, “A Pitch-Contour Model Adaptation Method for Integrated
Synthesis of Mandarin, Min-Nan, and Hakka Speech,”In Proceedings of the 9th IEEE
International Workshop on Cellular Neutral Networks and their Applications, 2005,
Hsin-Chu, Taiwan, pp. 190-193.
Gu, H. Y., and W. Huang, “Min-Nan Sentence Pitch-contour Generation: Mixing and
Comparison of Two Kinds of Models,”In Proceedings of Conference on Computational
Linguistics and Speech Processing (ROCLING), 2005, Tai-Nan, Taiwan, pp. 213-225.
(in Chinese)
Lee, L. S., C. Y. Tseng, and C. J. Hsieh, “Improved Tone Concatenation Rules in a
Formant-Based Chinese Text-to-Speech System,”IEEE Trans. Speech and Audio
Processing, 1(3), 1993, pp. 287-294.
Lee, S. J., K. C. Kim, H. Y. Jung, and W. Cho, “Application of Fully Recurrent Neural
Networks for Speech Recognition,”In Proceedings of International Conference on
Acoustics, Speech, and Signal Processing, 1991, Toronto, Canada, pp. 77-80.
Modulines, E., and F. Charpentier, “Pitch-synchronous Waveform Processing Techniques for
Text-to-Speech Synthesis Using Diphones,” Speech Communication, 9(5), 1990, pp.
453-467.
Rabiner, L., and B. H. Juang, Fundamentals of Speech Recognition, Prentice Hall, New Jersey,
1993.
Shih, C., and R. Sproat, “Issues in Text-to-Speech Conversion for Mandarin,”International
Journal of Computational Linguistics and Chinese Language Processing, 1(1), 1996, pp.
37-86.
出席國際學術會議心得報告
計畫編號 NSC 95-2218-E-011-006
計畫名稱
智慧型運輸系統之道路信息整合應用與交通控制--子計畫一：用於路況
報導之國語、閩南語、客語的整合式文句翻語音及語言辨識(3/3)
出國人員姓名
服務機關及職稱
古鴻炎
台灣科技大學資訊工程系副教授
會議時間地點 2006/12/13 ~ 2006/12/16, 新加坡
會議名稱 The 5th International Symposium on Chinese Spoken Language Processing
發表論文題目 An Initial System for Integrated Synthesis of Mandarin, Min-nan, and HakkaSpeech
一、參加會議經過
由於大會第一天安排的是 tutorial sessions，並且顧慮到自己所教授的課程，因此決
定第二天一大早搭機前往新加坡。當抵達新加坡時，時間是中午 12:25 左右，離 13:30
(也就是我的論文被安排發表的時段)，已是十分靠近，因此趕緊搭車前往新加坡大學，
到達大學後，又花費了一些時間搭校車及尋找會議舉辦的大樓，所以到達會議地點時，
已是 14:00，雖是遲到但總算是趕上。就是因為以前曾經來過，所以才會大意了一點，
不過主辦單位不把開會地點安排於平地上的大樓，而安排於山坡上難找的建築，也是不
恰當的。
這次的會議，第五屆中文口語語言處理國際會議，是第二次在新加坡舉辦，聚集了
許多研究華語語音處理的專家、學者，所以遇到了多位國內作語音處理的前輩和朋友，
並且也遇到了多位國際上知名的人士。此次會議共有 183 篇來自 18 個國家和地區的投
稿，被接受的有 149篇。我的論文排於 P1 session (Speech Analysis, Enhancement, Coding
and Synthesis)，除此之外，還參加了數個 sessions，例如: P2 session (Topics in Spoken
Language Processing)，L5 session (Speech Synthesis), SPE3 session (Multi-Lingual Corpus
Development)。
二、與會心得
目前我的研究重心是在語音合成方面，因此在此次會議裡，也大多是參加語音合成
相關的 session，其中令我印象最深刻的是，K. Tokuda 所提出的以 HMM 模型來作彈性
化的語音合成的方向，而且已經有中國微軟的研究人員依據此方向在作華語的語音合成
了。語音合成的研究裡，已有不少韻律模型的研究成果被提出，可用以提升合成語音的
自然度，不過流暢度方面，相關的研究卻很少，而基於 HMM 模型的語音合成方式，我
覺得可用以同時考慮自然度和流暢度的問題。
華人或華裔人口所使用的語言，除了華語(Mandarin)之外，其實閩南語(Holo)、客語
(Hakka)和其它的漢語，在台灣和中國也有很多的使用人口，可是相對地作閩南語、客語
的語音處理的論文卻很少，這表示華語之外的其它漢語，並未得到其人口比率相當的重
視。這次我發表的論文，就是思考、研究作多種語言(華語、閩南語、客語)的整合式語
音合成的初步成果。
Mandarin, Min-nan, and Hakka are all syllable prominent languages, and are all
tone languages. The number of different syllables (not distinguishing lexical tones) is
405 for Mandarin, 833 for Min-nan, and 783 for Hakka [3]. The numbers of different
lexical tones are 5, 7, and 7, respectively, for Mandarin, Min-nan, and Hakka. Since
the numbers, 405, 833, and 783, are not large, syllable is commonly chosen as the
speech unit for synthesis processing. Actually, in our system, each syllable (tone not
distinguished) of a language has only one recorded utterance. That is, no extra units
are available to do unit selection, and each syllable’s waveform must be manipulated
to synthesize speech signals owning different required prosodic characteristics.
In general, a speech synthesis system can be divided into three subsystems, i.e.,
(a) text analysis, (b) prosodic parameter generation, and (c) speech waveform
synthesis [4], [5]. Our integrated system is also divided into such subsystems. The
main processing flow of our system is shown in Fig. 1. The first two processing
blocks are for text analysis, the middle two blocks are for prosodic parameter
generation, and the last two blocks are for signal waveform synthesis. Our system is
an integrated system but not a bundle of three independent systems for the three
languages. This is because the program modules in the three subsystems are all shared
in synthesizing the three languages’speeches. For example, the model for pitch-
contour parameter generation is shared (or adapted) to Mandarin and Hakka, although
it is originally trained with Min-nan training sentences. The explanations for why the
program modules can be shared are given in the following sections.
In the subsystem of text analysis, the first block in Fig. 1, ”Text Analysis A”,
parse the inputted text to recognize tags and slice the text string into a sequence of
Chinese-character or alphanumeric-syllable tokens. Then, each Chinese-character
token is tried, in the second block (”Text Analysis B”), to check if it can be looked up
in a pronunciation dictionary in order to determine the comprising character’s
pronunciation syllable. For the subsystem of prosodic parameter generation, the pitch-
contour parameters of a syllable are determined by a mixed model of ANN [6], [7]
and SPC-HMM [8] in the third block of Fig. 1. As to the parameters, amplitude and
duration, for a syllable, they are determined with a rule-based method [9], [10] in the
forth block of Fig. 1. For the subsystem of signal waveform synthesis, a piece-wise
linear time-warping function is first constructed in the fifth block of Fig. 1. Then, the
method of TIPW (time-proportioned interpolation of pitch waveform, an improved
variant of PSOLA) [11] is used in the sixth block of Fig. 1 to synthesize speech signal
waveforms. To show that the integrated system has noticeable performance in
naturalness and signal clarity, we have set up a web page to provide example
synthetic speeches for the three languages (http://guhy.csie.ntust.edu.tw/hmtts/).
2 Text Analysis
In Min-nan and Hakka, there are still many spoken words whose corresponding
ideographic words are not known. Therefore, we make a decision that in the inputted
text, Chinese characters may be interleaved with syllables spelled in alphanumeric
symbols. For example,“cit4 tou5 ”is a Min-nan word whose first two syllables are
spelled in alphanumeric symbols. This decision implies that the inputted text must
Table 1. Defined tags and their meanings.
Tag symbol Explanation
@>x language selection, x may be 0, 1, or 2.
0: Min-nan, 1: Mandarin, 2: Hakka
@>dxxx speaking rate, syllable average duration in xxx mini-seconds.
@>txxx average tone height, in xxx Hz.
@>vxxx vocal track extended (or shrunken) to xxx percents of
original length.
<, > word-constructing tag, e.g., <cit4 tou5>
* breath-break tag
consisted of shorter words. Currently, we have collected 55,000, 12,000, and 19,000
multi-syllabic words, respectively, for Mandarin, Min-nan, and Hakka. Note that
inputted text is usually composed in Mandarin written words. Therefore, dictionary
looking-up plays a role of word translation. For example, “ ”(today) in Mandarin
is translate to “ ”, in Min-nan, which is pronounced as, “gin1a2 rit8”. Another
example,“ ”(chopstick) in Mandarin is translated to “”which is pronounced as,
“di7”. These examples also show that the words obtained after translation may have
longer or shorter lengths.
After a word is found in a dictionary or a segment of syllables bounded with the
tags,“<”and“>”, is parsed out, we know the boundaries of a word and its comprising
syllables. Then, tone-sandhi rules for the currently selected language can be applied to
the comprising syllables of the word. This is executed in the second block of Fig. 1.
Note that different languages have very different tone-sandhi rules. For example, in
Mandarin, if two adjacent syllables are both of the third tone, then the former one
must have its tone changed to the second tone. As another example, consider the tone-
sandhi rule in Min-nan that every syllable of a word except the word-final one must
have its tone changed to its inflected tone.
3 Prosodic Parameter Generation
The prosodic parameters of a syllable include pitch-contour, duration, amplitude, and
leading pause. The generating of prosodic parameter values plays a very important
role because it determines the naturalness level of a synthesized speech. Therefore,
many efforts had been devoted to investigate models (or methods) for generating of
prosodic parameter values [7], [8], [12], [13], [14].
Among these prosodic parameters, pitch-contour is the most important one for
higher naturalness level. Therefore, we have spent many efforts in investigating
different kinds of models, HMM [8], ANN, and a mixed model of both [15]. In the
third block of Fig. 1, a mixed model of HMM and ANN is used to generate pitch-
contours. Here, model mixing means taking a weighted sum of two pitch-contours
generated by HMM and ANN, respectively. Note that in this study, pitch-contour
models, HHM and ANN, are both trained with Min-nan spoken sentences. Then,
through tone mapping, we adapt the Min-nan trained and mixed model to generate
three-dimensional DP algorithm and used to search the most probable path [8].
According to the path found, pitch-contour VQ codes of the syllables can then be
decoded.
3.2 Syllable Pitch Contour ANN
The architecture of the artificial neural network used here is as shown in Fig. 2. It is
designed to be a recurrent type ANN in order to have prosodic state kept internally.
The input layer of the ANN has 8 ports (28 bits) to receive contextual parameters. For
the hidden and recurrent hidden layers, the numbers of nodes are both set to be 30
according to experiment results. After a syllable’s contextual parameters are inputted
and processed, a pitch contour represented as a 16 dimensional frequency vector is
outputted at the output layer.
8 con tex tu a l p ara m eters
16 d im . p itch -con tou r
Fig. 2. The architecture of the ANN studied here.
Here, the contextual parameters, i.e. the inputs to the ANN, are appropriately
selected to provide essential contextual information and to lower the quantity of
required training sentences. In details, the contextual parameters are as listed Table 2.
Because there are totally seven lexical tones in Min-Nan, 3 bits are enough to
represent them. The numbers of different syllable initials and finals are respectively
18 and 61. Hence, 5 and 6 bits are used respectively to represent current syllable’s
initial and final types. As to the parameter of the previous syllable’s final, we first
group the 61 possible finals into 12 classes, and use only 4 bits to represent the 12
final classes. Similarly, we first group the 18 possible initials into 6 classes, and use
only 3 bits to represent the 6 initial classes for the next syllable’s initial. Grouping is
made here because the quantity of recorded training sentences is not large enough to
let the ANN learn the influences of the detailed combinations of current syllable and
previous (or next) syllable. Syllable initial and final classes grouped here are detailed
in Table 3 and 4, respectively. The last item in Table 2, i.e. time-progress index, is
intended to carry timing information. If the current syllable is the k’th syllable of a
sentence of N syllables in length, then time-progress index is defined as k/N.
shape in a target language with a shape class trained in the working language that is of
similar shape trend in the central part. Note that each lexical tone of the working
language is usually trained to have several representative shape classes, e.g. 8 code-
words in each tone’s VQ codebook. Hence, for a pitch-contour shape in a target
language, we can select from the shape classes trained for the mapped lexical tone to
pick out the one that is most similar. Then, the possible decrease in naturalness due to
differences in frequency-height and boundary-part shape can be minimized.
The mapping from Hakka tones to Min-Nan tones is listed in Table 5. This
mapping can be said to be a nice one-to-one mapping because both have the same
number of lexical tones, and for each lexical tone of Hakka we can find a lexical tone
in Min-Nan that has almost same pitch-contour shape.
Table 5. Tone mapping from Hakka to Min-nan.
Hakka tone number 1 2 3 4 5 7 8
Mapped Min-Nan
tone number 2 5 3 8 1 7 4
The mapping from Mandarin tones to Min-Nan tones is listed in Table 6. Three
of the Mandarin lexical tones, i.e. high-level, rising, and falling, are also existent as
Min-Nan lexical tones. Besides these three tones, the low-level tone of Min-nan and
the low-dipping tone of Mandarin are perceived as the same tone. Therefore, the low-
dipping tone of Mandarin can be mapped to the low-level tone. As to neutral tone of
Mandarin, it has shorter duration than the other tones. This contrast also exists in
Min-nan, i.e. both abrupt tones have shorter durations. In addition, the low-abrupt
tone of Min-nan has low pitch-height as the neutral tone has. Hence, the neutral tone
of Mandarin can be mapped to low-abrupt tone of Min-nan.
Table 6. Tone mapping from Mandarin to Min-nan.
Mandarin tone number 1 2 3 4 5
Mapped Min-Nan tone number 1 5 3 2 4
4 Signal Waveform Synthesis
In our system, each syllable of a language has only one utterance recorded in level
tone. Therefore, an original syllable waveform must be manipulated to synthesize
target syllable waveforms of different prosodic characteristics. The synthesis method
used here is TIPW [11]. TIPW is an improved variant of PSOLA, i.e. the effects of
chorus and reverberation are largely reduced. Besides, TIPW is capable of adjusting
vocal track length through re-sampling [17].
Originally, TIPW is developed for synthesizing Mandarin speech. Thus, it does
not support the synthesis of abruptly changing signal waveform that is found at the
r = 0.7;
do {
Em = (Dm/Ds) * r * Es;
En = (Dn/Ds) * r * Es;
Ea = Es – Em – En;
if(Ea > Es*0.4) break;
r = r – 0.05;
} while(r>=0.2);
If the structure of a syllable is the same as /san/ or /an/, i.e. without voiced initial
consonant, then the values of Dm and Em can be set directly to zero. Similarly, if the
structure of a syllable is the same as /ma/, i.e. without voiced ending consonant, then
the values of Dn and En can be set directly to zero. Apparently, to apply the
procedure given above, the boundary point between two adjacent phonemes must be
labeled beforehand in order to compute the values of Dm, Da, and Dn, and to
construct the mapping function.
5 Experiments and Results
After the integrated system is implemented and ready to run, we then start to do
perception tests. The first issue we are concerned is the naturalness levels of
Mandarin and Hakka pitch-contours generated by the Min-nan trained pitch contour
model. Therefore, short articles written in Mandarin and Hakka are fed as inputs to
our system. The outputted speech signals are then played to each of the ten persons
who participates the tests. Initial results show that the lexical tones in the synthetic
Mandarin and Hakka speeches can be correctly recognized. As to naturalness level,
the synthetic Hakka speech is perceived to be slightly more natural than the synthetic
Mandarin speech. This is because the pitch-contours generated for Mandarin is
perceived to have slightly strange accent.
Another issue we are concerned is the fluency of the synthetic speech. Therefore,
two synthesis conditions are set to synthesize a short article into two Mandarin
speeches. In the first condition, the mapping function (used in waveform synthesis)
between synthetic and original time axes is forced to be linear while in the second
condition, the mapping function adopted is as showed in Fig. 3. The two synthetic
speeches are then played to each of the participating persons to evaluate their fluency.
Initial results show that the fluency of the synthetic speech under the second condition
is significantly better than the one under the first condition.
Acknowledgments. This study is supported by National Science Council under the
contract number, NSC 94-2218-E-011-007.
