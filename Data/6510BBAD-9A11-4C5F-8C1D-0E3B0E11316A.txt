Report on ”On-line Fault Tolerant Learning Algorithms III: Node
fault injection-based BPA for MLP”
John Sum
Abstract— Improving fault tolerance of a neural network is
an important issue that has been studied for more than two
decades. Various training algorithms have been proposed in
sequel. The on-line node fault injection-based algorithm is one
of these algorithms. In this algorithm, hidden nodes randomly
output zeros during the training. While the idea is simple,
theoretical analyses on this algorithm are far from complete.
In this paper, we present the objective functions and the
convergence proofs of this algorithm. We consider three cases
for multilayer perceptrons (MLPs). They are, (i) MLPs with
single linear output node, (ii) MLPs with multiple linear output
nodes, and (iii) MLPs with single sigmoid output node. For the
convergence proof, we show that the algorithm converges with
probability one. For the objective function, we show that the
corresponding objective functions of Cases (i) and (ii) are of the
same form. They both consist of a mean square errors term,
a regularizer term, and a weight decay term. For Case (iii),
the objective function is slight different from that of Cases (i)
and (ii). With the objective functions derived, we can compare
the similarities and differences amongst various algorithms and
various cases.
I. INTRODUCTION
There are various training algorithms aiming at attaining a
neural network that is able to tolerate fault and noise. Some
of these algorithms include injecting random node/weight
fault (stuck-at-zero fault for instance) during training [6],
[36], [42], applying weight decay learning [7], [10], [26],
injecting weight noise during training [12], [31], [32], in-
troducing network replication [30], [34], formulating the
training algorithm as a nonlinear constraint optimization
problem [11], [33], hard-bounding weight magnitude during
training [8], [16], [24], regularization [2], [3], [4], [19], [25],
[26], [27], [28], [38], [44], and others [9], [35], [37], [43].
In those algorithms, injecting fault or noise during training
is a simple and effective on-line technique. Sequin & Clay
[36] and Bolt [6] are the first two research groups proposing
injecting random node fault during training. Based on simu-
lations, they showed that the resultant multilayer perceptron
(MLP) is able to tolerate random node fault. Instead of
injecting node fault, Judd & Munro [23] proposed to train a
MLP with random output hidden nodes. Murray & Edward
[31], [32] proposed the injecting weight noise algorithm. By
simulations, they showed that the resultant MLP is able to
tolerate weight fault and weight noise. Besides, the conver-
gence of this training algorithm is better than that of the
The work supported by this research grant has been published in the
following paper: John Sum, Chi-sing Leung, Kevin Ho, Convergence
analysis of on-line node fault injection-based training algorithms for MLP
networks, IEEE Transactions on Neural Networks and Learning Systems,
Vol.23(2), 211-222, Feb 2012. Here, only the key results are summarized.
The proofs of the theorems are omitted.
standard back-propagation. Jim et al [22] applied the same
idea to real-time-recurrent-learning (RTRL). Similarly, they
showed that the convergence of this modified RTRL is better
than the standard RTRL. Moreover, the resultant RNN has
better generalization. Apart from injecting fault/noise during
training, injecting input noise during training is another
simple method [5], [29], [21]. Its idea is similar. Random
noise is injected to the input of a network during training.
Although many on-line fault/noise injection-based training
algorithms have been developed in the last two decades,
not many theoretical works have been done regarding node
fault injection-based and weight noise injection-based train-
ing algorithms. Most of the analyses focused on the effect
of fault/noise on the output or the prediction error of a
trained neural network which is injected by fault/noise [1],
[14], [15], [22], [32]. Analyses on the objective functions
and the convergence of these on-line fault/noise injection
learning algorithms are scarce. In fact, only the injecting
input noise algorithm has an objective function which is
equivalent to the objective function of adding Tikhonov
regularizer. For other fault/noise injection-based algorithms,
not much theoretical analysis has been done. In this regard,
we have recently investigated in depth the convergence and
the objective functions of some on-line fault/noise injection
training algorithms [17], [18], [20], [39], [40], [41].
By applying Gladyshev Theorem [13], we have showed in
[17] that for RBF networks, the convergence of the injecting
weight noise algorithm is with probability one1. However,
this training algorithm is not able to improve generalization,
nor fault tolerance. By applying the same theorem, we
have further showed in [39] that for RBF networks the
convergence of the injecting node fault algorithm is with
probability one. Moreover, we have found that the objective
function of this node fault injection algorithm is identical to
the objective function of the open fault approach [25].
While we have accomplished the analyses on the conver-
gence and objective functions of those on-line fault/noise
injection training algorithms for RBF networks, the conver-
gence and the objective functions of these algorithms for
multilayer perceptrons (MLPs) are still unknown. One reason
is that the Gladyshev Theorem is not applicable to MLPs.
Therefore, in this paper, we continue our study for MLPs.
Instead of applying Gladyshev Theorem, we apply a theorem
from H. White [45] and follow the approach in [46] to prove
the convergence of the on-line node fault injection training
1Let {훽푡}푡≥0 be a sequence of random variables. The convergence of
훽푡 is with probability one meaning that there exists a real number 훽∗ such
that 푃 (lim푡→∞ 훽푡 = 훽∗) = 1.
w푖 (for 푖 = 1, 2, ⋅ ⋅ ⋅ ,푚) can then be written as follows2 :
w푖(푡+ 1)−w푖(푡)
= 휇(푡) {(푦푡 − 푓(x푡,w(푡)))g푖(x푡,w(푡))
− 훼w푖(푡)} , (8)
where
g푖(x푡,w(푡)) =
∂
∂w푖
푓(x푡,w)
∣∣∣∣
w=w(푡)
(9)
=
⎡⎣ 푧푖(푡)푑푖(푡)푧푖(푡)(1− 푧푖(푡))x푡
푑푖(푡)푧푖(푡)(1− 푧푖(푡))
⎤⎦ , (10)
휇(푡) > 0 is the step size at the 푡푡ℎ iteration, and 훼 > 0
is the decay constant controlling the amount of decay of the
weight vector w푖(푡) in each update iteration. Conventionally,
the initial weight vector w(0) is set to a small random vector
with elements around zero.
Similar to the notation w in (5), we can define a vec-
tor function g which augments all the vector functions
g1,g2, ⋅ ⋅ ⋅ ,g푚, i.e.
g = (g푇1 ,g
푇
2 , ⋅ ⋅ ⋅ ,g푇푚)푇 . (11)
From (8),
w(푡+ 1)−w(푡)
= 휇(푡) {(푦푡 − 푓(x푡,w(푡)))g(x푡,w(푡))
− 훼w(푡)} , (12)
Conventionally, the initial weight vector w(0) is set to a
small random vector with elements around zero.
By using notation 훿푘(푡), one should note that an alternative
form for (8) is given by
w푖(푡+ 1)−w푖(푡)
= 휇(푡)
푁∑
푘=1
훿푘(푡)(푦푘 − 푓(x푘,w(푡)))g푖(x푘,w(푡))
−훼w푖(푡). (13)
It has been proved in [46] that the objective function being
minimized by weight decay training algorithm (8) is
1
푁
푁∑
푘=1
(푦푘 − 푓(x푘,w))2 + 훼∥w∥22. (14)
Besides, its convergence is with probability one [46].
III. ON-LINE NODE FAULT INJECTION TRAINING
The node fault injection-based algorithm was pro-
posed [36], [6] a heuristic modification of the weight
decay training algorithm by randomly setting zero values
to the outputs of hidden nodes. However, the analyses on
the objective functions and the convergence of the on-line
node fault injection algorithms are still scarce. In this section,
we will model its update equation as a stochastic update
equation.
2The factor −훼w푖(푡) is usually called the weight decay term.
To model the behavior of random node fault injection, we
introduce a binary random vector b(푡) ∈ {0, 1}푚 at the 푡푡ℎ
update iteration. The probability mass function of b(푡) is
given by
푃 (푏푖(푡)) =
{
1− 푝 if 푏푖(푡) = 1
푝 if 푏푖(푡) = 0,
(15)
where the value 0 < 푝 < 1. For all 푖, 푗 (푖 ∕= 푗), 푡, 푡′ (푡 ∕= 푡′),
the random variables 푏푖(푡), 푏푖(푡′), 푏푗(푡) are all independent
and identically distributed.
With 푏푖(푡), the output 푧˜푖 of the 푖푡ℎ hidden node during
training is given by
푧˜푖(푡, ) = 푏푖(푡)푧푖(푡). (16)
Note that to save the space, in (16) we denote
푧˜푖(x푡,a푖(푡), 푐푖(푡)) by 푧˜푖(푡). The output 푓˜ of a linear output
MLP with node fault injection is expressed as
푓˜(x푡,w(푡)) =
푚∑
푖=1
푑푖(푡)푏푖(푡)푧푖(푡). (17)
On the other hand, we let g˜푖(x푡,w(푡)) be the perturbed
counterpart of g푖(x푡,w(푡)). By replacing 푧푖 by 푧˜푖 in (10),
g˜푖(x푡,w(푡)) =
⎡⎣ 푧˜푖(푡)푑푖(푡)푧˜푖(푡)(1− 푧˜푖(푡))x푡
푑푖(푡)푧˜푖(푡)(1− 푧˜푖(푡))
⎤⎦ . (18)
Based on (8), (17) and (18), the update equation for w푖
for all 푖 = 1, ⋅ ⋅ ⋅ ,푚 is defined as follows :
w푖(푡+ 1)−w푖(푡)
= 휇(푡)
{
(푦푡 − 푓˜(x푡,w(푡)))g˜푖(x푡,w(푡))
− 훼w푖(푡)} , (19)
where 휇(푡) > 0 is the step size at the 푡푡ℎ iteration and 훼 > 0
is called the decay constant. Similar to (12), (19) can be
rewritten as follows :
w(푡+ 1)−w(푡)
= 휇(푡)
{
(푦푡 − 푓˜(x푡,w(푡)))g˜(x푡,w(푡))
− 훼w(푡)} , (20)
where g˜ is a vector function augmenting g˜1, g˜2, ⋅ ⋅ ⋅ , g˜푚, i.e.
g˜ = (g˜푇1 , g˜
푇
2 , ⋅ ⋅ ⋅ , g˜푇푚)푇 . (21)
By using notation 훿푘(푡), an alternative form for (19) is
given by
w푖(푡+ 1)−w푖(푡)
= 휇(푡)
{
푁∑
푘=1
훿푘(푡)(푦푘 − 푓˜(x푘,w(푡)))g˜푖(x푘,w(푡))
−훼w푖(푡)} . (22)
Equation (22) is the update equation for the on-line node fault
injection algorithm. Its stochastic behavior is modelled by
훿푘(푡)’s and 푏푖(푡)’s. This form of update equation is particular
useful for the derivations of the mean update equation and
the objective function.
follows :
퐸[w푖(푡+ 1)∣w(푡)]
= w푖(푡) +
휇′(푡)
푁
푁∑
푘=1
(푦푘 − 푓(x푘,w(푡)))g푖(x푘,w(푡))
+
휇′(푡)푝
푁
푁∑
푘=1
(푓(x푡,w(푡))− 푑푖(푡)푧푖(푡))g푖(x푘,w(푡))
− 휇′(푡)훼′w푖(푡), (34)
for all 푖, where 휇′(푡) = (1 − 푝)휇(푡) and 훼′ = 훼/(1 − 푝).
(34) is the mean update equation of the on-line node fault
injection algorithm for MLPs with single linear output node.
B. Deriving the objective function
The mean update equation of (34) can be written as
follows :
퐸[w푖(푡+ 1)∣w(푡)] = w푖(푡)− 휇′(푡) ∂
∂w푖
푉 (w)
∣∣∣∣
w=w(푡)
,
(35)
for all 푖, where 푉 (w) is a scalar function. In the following,
we will identify the scalar function 푉 (w) in the mean update
equation of the on-line node fault injection algorithm. With
the proof of the convergence of (19) in the next section, we
can conclude that the on-line node fault injection algorithm,
equation (19), is a stochastic gradient descent algorithm and
푉 (w) is the objective function.
Let ∂∂w푉 (w) denotes the vector augmenting
∂
∂w1
푉 (w)
∂
∂w2
푉 (w), ⋅ ⋅ ⋅ , ∂∂w푚푉 (w), i.e.
∂
∂w
푉 (w) =
(
∂
∂w1
푉 (w)푇 , ⋅ ⋅ ⋅ , ∂
∂w푚
푉 (w)푇
)푇
. (36)
Equation (35) can be written as follows :
퐸[w(푡+ 1)∣w(푡)] = w(푡)− 휇′(푡) ∂
∂w
푉 (w)
∣∣∣∣
w=w(푡)
. (37)
In Theorem 1, we will identify the scalar function 푉 (w)
based on (34) and (35).
Theorem 1: The scalar function in (35) is given by
푉 (w) =
1
2푁
푁∑
푘=1
(푦푘 − 푓(x푘,w))2
+
푝
2푁
푁∑
푘=1
d푇 (G(x푘,w)−H(x푘,w))d
+
훼
2(1− 푝)∥w∥
2
2. (38)
The matrices G(x푘,w) and H(x푘,w) in (38) are given by
G(x푘,w) = diag{푧21(x푘,w), ⋅ ⋅ ⋅ , 푧2푚(x푘,w)}, (39)
H(x푘,w) = z(x푘,w)z(x푘,w)
푇 , (40)
and ∥w∥22 = w푇w.
The implication of Theorem 1 is that the mean update
equation (34) of (19) can be rewritten as (35). With the
proof of the convergence of (19) in the next section, we
can conclude that the on-line node fault injection algorithm,
equation (34), is a stochastic gradient descent algorithm and
푉 (w) is the objective function. One should also note that
the term “ 푝푁
∑푁
푘=1 d
푇 (G(x푘,w)−H(x푘,w))d” in (38)
is similar to the fault tolerant regularizer derived in [25].
V. CONVERGENCE ANALYSIS
To accomplish the proof of convergence, we first definite
some notations. The absolute value of a number 훾 is denoted
as ∣훾∣. The 푙∞ norm and 푙2 norm of vector q are denoted
as ∥q∥∞ and ∥q∥2, where ∥q∥∞ = max{∣푞1∣, ⋅ ⋅ ⋅ , ∣푞푣∣},
and ∥q∥2 =
[∑푣
푖=1 푞
2
푖
]1/2. By the definitions of 푙∞ and 푙2
norms, it is clear that
∥q∥2 ≤
√
푣 ∥q∥∞. (41)
The convergence proof will be presented in the rest of
this section. We first show that ∥w(푡)∥2 is bounded for
all 푡. Then, we apply a theorem in [45] to show that the
convergence of (19). In the proof, b(0), a푖(0) and w(0) are
the initial weight vectors. By default, they are all bounded.
A. Boundedness of ∥w(푡)∥2
The boundedness of ∥w(푡)∥2 will be explained one by
one from boundedness of ∥d(푡)∥2, ∥a푖(푡)∥2 and ∣푐푖(푡)∣ for
all 푖 = 1, ⋅ ⋅ ⋅ ,푚.
By (4), (18) and (19), the update of 푑푖(푡) can be expressed
as follows :
푑푖(푡+ 1)− 푑푖(푡)
= 휇(푡)
{
(푦푡 − d푇 (푡)z˜(푡))푧˜푖(푡)− 훼푑푖(푡)
}
. (42)
In vector-matrix form,
d(푡+ 1)− d(푡)
= 휇(푡)
{
(푦푡 − d푇 (푡)z˜(푡))z˜(푡)− 훼d(푡)
}
. (43)
Let
B(푡) = (1− 휇(푡)훼)I푚×푚 − 휇(푡)z˜(푡)z˜푇 (푡).
d(푡+ 1) = B(푡)d(푡) + 휇(푡)푦푡z˜(푡). (44)
It can be showed that the eigenvalues of z˜(푡)z˜푇 (푡) are either
0 or
∑푚
푖=1 푧˜푖(푡)
2, with 푚 − 1 eigenvalues equal to 0 (see
Lemma 6.3 in [46]). Thus, the eigenvalues of the matrix B(푡)
in (44) are either 1−휇(푡)훼 or 1−휇(푡)훼−휇(푡)∑푚푖=1 푧˜푖(푡)2.
As 0 < 푧˜푖(푡) < 1, one can set the step size small enough
to ensure that the eigenvalues of B(푡) is positive and less
than one. For instance,
0 < 휇(푡) <
1
훼+푚
. (45)
In such case (1 − 휇(푡)훼) will be the largest eigenvalue of
B(푡).
By the definition of 푙∞ norm, and the facts that ∣푦푡∣ <∞
and 0 < 푧˜푖(푡) < 1,
∥d(푡+ 1)∥∞ ≤ (1− 휇(푡)훼)∥d(푡)∥∞ + 휇(푡)휅1, (46)
VI. EXTENDED RESULTS
In the above analyses, we have assumed that the MLP is
of single linear output node (1). The results regarding to the
objective function and the convergence proof can be extended
to Case ii, where there are multiple linear output nodes, and
Case iii, where there is a single sigmoid output node.
A. MLP with multiple linear output nodes
For a MLP with 푛 input nodes, 푚 hidden nodes, and
푟 linear output node, the output of the MLP is defined as
follows :
f(x푘,D,A, c) = Dz(A
푇x푘 + c), (59)
where f = (푓1, 푓2, ⋅ ⋅ ⋅ , 푓푟) ∈ 푅푟 is a vector function and
D ∈ 푅푟×푚 is the hidden to output weight matrix,
D =
⎡⎢⎢⎢⎣
푑11 푑12 ⋅ ⋅ ⋅ 푑1푚
푑21 푑22 ⋅ ⋅ ⋅ 푑2푚
...
...
. . .
...
푑푟1 푑푟2 ⋅ ⋅ ⋅ 푑푟푚
⎤⎥⎥⎥⎦ .
Again, we can extend the definition w푖 in (4) as follows :
w푖 = (푑1푖, 푑2푖, ⋅ ⋅ ⋅ , 푑푟푖,a푇푖 , 푐푖)푇 . (60)
The definition of f˜ will be given by the following equation.
푓˜푗(x푡,w(푡)) =
푚∑
푖=1
푑푗푖(푡)푏푖(푡)푧푖(푡) (61)
for all 푗 = 1, 2, ⋅ ⋅ ⋅ , 푟. Denote g푗푖(x푡,w푖(푡)) as the gradient
vector of 푓푗(x푡,w(푡)) with respect to w푖,
g˜푗푖(x푡,w(푡)) =
⎡⎣ 푧˜푖(푡)e푟푑푗푖(푡)푧˜푖(푡)(1− 푧˜푖(푡))x푡
푑푗푖(푡)푧˜푖(푡)(1− 푧˜푖(푡))
⎤⎦ , (62)
where
e푟 = (1, 1, ⋅ ⋅ ⋅ , 1︸ ︷︷ ︸
푟
)푇 .
Using (61), (62), the update equation for w푖 will be given
by
w푖(푡+ 1)−w푖(푡)
= 휇(푡)
푟∑
푗=1
(푦푡푗 − 푓˜푗(x푡,w(푡)))g˜푗푖(x푡,w(푡))
−휇(푡)훼w푖(푡), (63)
where 휇(푡) > 0 is the step size at the 푡푡ℎ iteration and 훼 > 0
is called the decay constant.
Following the similar steps in Section IV, the mean update
equation for w푖 for all 푖 = 1, ⋅ ⋅ ⋅ ,푚 is given as follows :
퐸[w푖(푡+ 1)∣w(푡)]−w푖(푡)
=
휇′(푡)
푁푟
푁∑
푘=1
푟∑
푗=1
(푦푘푗 − 푓푗(x푘,w(푡)))g푗푖(x푘,w(푡))
− 휇
′(푡)푝
푁푟
푁∑
푘=1
푟∑
푗=1
⎡⎣∑
푖′ ∕=푖
푑푗푖′(푡)푧푖′(푡)
⎤⎦g푗푖(x푘,w(푡))
− 휇′(푡)훼′w푖(푡), (64)
where 휇′(푡) = (1 − 푝)휇(푡) and 훼′ = 훼/(1 − 푝) and
푦푘1, 푦푘2, ⋅ ⋅ ⋅ , 푦푘푟 are the target outputs of the 푘푡ℎ sample.
We can thus show that the mean update equation (64) can
be rewritten as
퐸[w푖(푡+ 1)∣w(푡)] = w푖(푡)− 휇′(푡) ∂
∂w푖
푉 ∗(w)
∣∣∣∣
w=w(푡)
.
(65)
where the scalar function 푉 ∗(w) is given by Theorem 4.
With the proof of the convergence of (63) given by Theo-
rem 6, 푉 ∗(w) is the objective function of (63).
Theorem 4: The scalar function in (65) is given by
푉 ∗(w) =
1
푁푟
푁∑
푘=1
푟∑
푗=1
(푦푘푗 − 푓푗(x푘,w))2
+
푝
푁푟
푁∑
푘=1
푟∑
푗=1
d푇푗 (G(x푘,w)−H(x푘,w))d푗
+
훼
(1− 푝)∥w∥
2
2, (66)
where d푗 = (푑푗1, 푑푗2, ⋅ ⋅ ⋅ , 푑푗푚)푇 . The matrices G(x푘,w)
and H(x푘,w) in (66) are given by (39) and (40).
Similar to the case of multilayer perceptron
with single linear output node, the term
“ 푝푁푟
∑푁
푘=1
∑푟
푗=1 d
푇
푗 (G(x푘,w)−H(x푘,w))d푗” in
(66) is similar to the fault tolerant regularizer derived
in [25].
For the boundedness proof, one can follow the same
approach as in Section V-A to show that w푖(푡) obtained
by algorithm (63) is bounded for all 푡 ≥ 0. Thus, the
convergence proof of (63) can be readily showed by Lemma
4. We state without proof the following theorem.
Theorem 5: Suppose 0 < 휇(푡)훼 < 1 for all 푡 ≥ 0. For
w(푡) obtained by algorithm (63), ∥w(푡)∥2 ≤ 휅8 for all 푡 ≥ 0,
where 휅8 is a positive constant depended on the initial values
of the weights and the decay constant 훼.
Theorem 6: Let Z(푡) = (x푇푡 ,y
푇
푡 ,b(푡)
푇 )푇 , y푡 =
(푦푡1, 푦푡2, ⋅ ⋅ ⋅ , 푦푡푟)푇 and M = (M푇1 ,M푇2 , ⋅ ⋅ ⋅ ,M푇푚)푇 ,
where
M푖(Z(푡),w(푡)) =
푟∑
푗=1
(푦푡푗 − 푓˜푗(x푡,w(푡)))g˜푗푖(x푡,w(푡))
−훼w푖(푡). (67)
Suppose 0 < 휇(푡)훼 < 1 and the step size 휇(푡) fulfils the
conditions that∑
푡
휇(푡) =∞,
∑
푡
휇2(푡) <∞.
For arbitrarily given w(0), w(푡) defined by (63) converges
to {w∣ ( ∂∂w푉 ∗(w))푇 M¯(w) = 0} with probability 1, where
푉 ∗(w) is given by (66).
From Theorems 4–6, the on-line fault fault injection algo-
rithm for MLPs with multiple linear output nodes converges
with probability one. It is a stochastic gradient descent
algorithm. Its objective function is given by Theorem 4.
Using (74), the mean update equation for w푖 will then be
given by
퐸[w푖(푡+ 1)∣w(푡)]−w푖(푡)
= 훽1
휇(푡)
푁
푁∑
푘=1
휉(x푘,w(푡))g푖(x푘,w(푡))
+ 훽2
휇(푡)
푁
푁∑
푘=1
푚∑
푖푓=1,푖푓 ∕=푖
휉−푖푓 (x푡,w(푡))g
−푖푓
푖 (x푡,w(푡))
− 휇(푡)훼w푖(푡). (84)
where 훽1 = (1 −푚푝) and 훽2 = 푝(1 −푚푝 + 푝). In (84), it
is clear that
− 1
2
∂
∂w푖
(푦푡 − ℎ(푡))2
∣∣∣∣
w=w(푡)
= (푦푡 − ℎ(푡))ℎ(푡)(1− ℎ(푡))g푖(x푡,w(푡))
= 휉(x푡,w(푡))g푖(x푡,w(푡)).
For 푖푓 ∕= 푖 and we let
− 1
2
∂
∂w푖
(푦푡 − ℎ−푖푓 (푡))2
∣∣∣∣
w=w(푡)
= (푦푡 − ℎ−푖푓 (푡))ℎ−푖푓 (푡)(1− ℎ−푖푓 (푡))g−푖푓푖 (x푡,w(푡))
= 휉−푖푓 (x푡,w(푡))g
−푖푓
푖 (x푡,w(푡))
and
w푖(푡) =
1
2
∂
∂w푖
∥w∥22
∣∣∣∣
w=w(푡)
.
Therefore, the mean update equation (84) can be rewritten
as follows :
퐸[w푖(푡+ 1)∣w(푡)] = w푖(푡)− 휇(푡) ∂
∂w푖
푉 ∗∗(w)
∣∣∣∣
w=w(푡)
.
(85)
where the scalar function 푉 ∗∗(w) is given by Theorem 7.
Theorem 7: If 푝≪ 1, the scalar function in (85) is given
by
푉 ∗∗(w) =
훽1
2푁
푁∑
푘=1
(푦푘 − ℎ(x푘,w))2
+
훽2
2푁
푚∑
푖푓=1
푁∑
푘=1
(푦푘 − ℎ−푖푓 (x푘,w−푖푓 ))2
+
훼
2
∥w∥22, (86)
where 훽1 = (1−푚푝) and 훽2 = 푝(1−푚푝+ 푝).
Considering (70) for the update of 푑푖 and by definition
that the first element in g˜푖 is ∂푓˜∂푑푖 , which is given by
∂
∂푑푖
푓˜ = 푏푖(푡)푧푖(푡),
the update of 푑푖 is given by
푑푖(푡+ 1) = (1− 휇(푡)훼)푑푖(푡)
+휇(푡)(푦푡 − ℎ˜(푡))ℎ˜(푡)(1− ℎ˜(푡))푏푖(푡)푧푖(푡).
Based upon the facts that 0 ≤ ℎ˜ ≤ 1 and ∣푦푘∣ are bounded,
∣(푦푡 − ℎ˜(푡))ℎ˜(푡)(1− ℎ˜(푡))∣
in (70) is bounded. Then, we can have the inequality for the
absolute values of 푑푖(푡+ 1) and 푑푖(푡) as follows :
∣푑푖(푡+ 1)∣ ≤ (1− 휇(푡)훼)∣푑푖(푡)∣+ 휇(푡)휅9, (87)
where
휅9 = max
{∣∣∣(푦푡 − ℎ˜(푡))ℎ˜(푡)(1− ℎ˜(푡))∣∣∣} .
Applying the same technique as the boundedness proof in
Lemma 1, we can show that ∣푑푖(푡)∣ is bounded for all 푖 =
1, ⋅ ⋅ ⋅ ,푚 and 푡 ≥ 0.
Moreover, one can clearly establish the inequalities for
∥a푖(푡)∥∞ and ∣푐푖(푡)∣ by similar argument.
∥a푖(푡+ 1)∥∞ ≤ (1− 휇(푡)훼)∥a푖(푡)∥∞ + 휇(푡)휅10,(88)
∣푐푖(푡+ 1)∣ ≤ (1− 휇(푡)훼)∣푐푖(푡)∣+ 휇(푡)휅11, (89)
where 휅10 is positive constant depended on ∥a푖(0)∥∞, 훼 and
max푘{∥x푘∥∞}. Whereas, 휅11 is positive constant depended
on ∣푐푖(0)∣ and 훼. Therefore, we state without proof regarding
the boundedness of w(푡) obtained by (70) in the following
theorem.
Theorem 8: Suppose 0 < 휇(푡)훼 < 1. For w(푡) obtained
by algorithm (70), ∥w(푡)∥2 ≤ 휅12 for all 푡 ≥ 0, where 휅12
is a positive constant depended on the initial values of the
weights, max푘 ∣푦푘∣, max푘{∥x푘∥∞} and the decay constant
훼.
Applying the boundedness condition stated in Theorem 8,
the definition of step size in (55), and Lemma 4, we can
show the convergence of the algorithm (70).
Theorem 9: Let Z(푡) = (x푇푡 , 푦푡,b(푡)
푇 )푇 , and
M(Z(푡),w(푡)) = (푦푡 − ℎ˜(푡))ℎ˜(푡)(1− ℎ˜(푡))g˜푖(x푡,w(푡))
−훼w푖(푡), (90)
where ℎ˜(푡) = ℎ˜(x푡,w(푡)). Suppose 0 < 휇(푡)훼 < 1 and the
step size 휇(푡) fulfils the conditions that∑
푡
휇(푡) =∞,
∑
푡
휇2(푡) <∞.
For arbitrarily given w(0), w(푡) defined by (78) converges
to {w∣ ( ∂∂w푉 ∗∗(w))푇 M¯(w) = 0} with probability 1, where
푉 ∗∗(w) is given by (86).
With Theorem 7 and 9 , the on-line node fault injection
algorithm (70) is a stochastic gradient descent algorithm. It
converges with probability one. Its objective function is given
by Theorem 7.
[40] Sum J. and K. Ho, SNIWD: Simultaneous weight noise injection with
weight decay for MLP training, in Proceedings of ICONIP 2009,
Springer LNCS 5863, 2009.
[41] Sum J., K. Ho, C.S. Leung, S.C. Lau, Convergence Analysis of
Multiplicative Weight Noise Injection During Training, Proc. TAAI
2010, 2010.
[42] Takanami I., M. Sato and Y. P. Yang, A fault-value injection approach
for multiple-weight-fault tolerance of MNNs, Proc. of the IEEE-INNS-
ENNS International Joint Conference on Neural Networks, vol. III, pp.
515-520, 2000.
[43] Tchernev E.B., R.G. Mulvaney, and D.S. Phatak, Investigating the
Fault Tolerance of Neural Networks, Neural Computation, Vol.17,
1646-1664, 2005.
[44] Wang H.J., C.S. Leung, P.F. Sum and G. Wei, Kernel Width Optimiza-
tion for Faulty RBF Neural Networks with Multi-node Open Fault,
Neural Processing Letters, Vol.32(1), 97-107, August 2010.
[45] White H., Some asymptotic results for learning in single hidden-
layer feedforward network models, Journal of American Statistical
Associtation, Vol.84, No.408, p.1003-1013, December, 1989.
[46] Zhang, Huisheng, Wei Wu, Fei Liu, and Mingchen Yao, Bounded-
ness and convergence of online gradient method with penalty for
feedforward neural networks IEEE Transactions on Neural Networks,
Vol.20(6), 1050-1054, June 2009.
國科會補助計畫衍生研發成果推廣資料表
日期:2012/12/08
國科會補助計畫
計畫名稱: 利用Weight Decay結合隨機fault或加注雜訊的在線容錯訓練之特性研究(3)
計畫主持人: 沈培輝
計畫編號: 100-2221-E-005-083- 學門領域: 人工智慧與仿生計算
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
Nil 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
