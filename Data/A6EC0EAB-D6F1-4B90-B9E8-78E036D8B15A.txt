iii 
 
 
英文摘要 
Keywords: Design-for-Yield, Process Variation, Analog Behavioral Model, Design Centering, 
Yield Optimization 
With nanometer semiconductor technology, the device size is continuously shrinking. 
Currently, the device parameter variations have more and more impacts on the chip performance 
and yield. In order to solve this issue, design-for-yield (DFY) techniques are getting popular, 
which try to consider the process variation effects in early design stages. The DFY techniques for 
digital circuits have been studied for several years. However, for more sensitive analog circuits, 
no systematic DFY techniques are available now. Therefore, in this project, we will try to use our 
previous experience on mixed-signal behavioral modeling to develop DFY techniques for analog 
circuits. Based on analog behavioral models, a nominal point moving algorithm is proposed to 
reduce the impacts of process variation on analog circuits at early design stage. 
Design centering is one of the popular yield optimization techniques. Its aim is to find a 
nominal design that makes most simulation samples under process variation fall into the 
acceptable design region. Conventional design centering techniques often use a geometric 
approach to locate the feasible design region first. However, complicated formulas and numerous 
design constrains are often required to describe the boundaries of feasible design regions. For 
complicated analog circuits, finding the feasible region or its partial boundaries within the circuit 
space is extremely complicated even for a given circuit topology. 
Therefore, a novel implicit approach is proposed in this project to improve the user-given 
analog circuits toward better yield. The key idea is reusing the yield analysis data and applying 
the mechanical work-energy theorem to determine the new nominal point based on the Pass/Fail 
distributions. Since exploring the feasible region is not necessary in this boundary-less approach, 
the computation time of the yield enhancement flow can be significantly reduced, which enables 
this approach to deal with complicated analog circuits. A hierarchical sizing approach is also 
proposed to synthesize the new nominal design from performance level to behavior level. With 
the corresponding behavioral parameters, any existing approach can be applied to determinate 
the device sizes of the new nominal point, which helps designers improve their designs more 
easily. In this year, a complicated phase-locked-loop circuit will be used as a case study to 
develop the required algorithms in the proposed yield enhancement flow. The feasibility and 
improvements will also be verified using this large case.
2 
 
 
圖二：製程變異對於加法器延遲時間的影響比較 [1] 
 
圖三：生產良率與製程技術節點關係圖 [2] 
為了提升電路設計的生產良率，首要工作是要有效率地分析良率。傳統上，類比電路
的分析主要都是透過HSPICE模擬器，經過數百次或數千次的電晶體階層(transistor level)
模擬，以不同的製程變異參數為變因，萃取出受到影響而偏移的電路效能；並且結合蒙地
卡羅(Monte-Carlo, MC)[3]分析的技術，將結果統整在效能空間(performance space)上，
藉以觀察製程變異對於整體晶片效能的影響及預測良率的好壞。然而，在較複雜的電路設
4 
 
運作原理的了解，根據電路規格(specification)定義出必要的設計限制(design constrain)，並
且經由複雜的數學運算公式以及演算法，找到所有在元件階層中相對應的公式，以定義出
可行性參數區間(feasible region)的邊界。經過上述的步驟之後，可在參數空間中利用外凸
多邊形設計法(Convex Programming Approach)[23]，或最大內接橢圓(Maximum Volume 
Ellipsoid, MVE)演算法[24]等，使用線性近似的技術來逼近這些邊界；當用來描述可行性區
間的複雜方程式被簡化的數學模型取代後，就可以在快速的模擬時間之內，去移動設計標
稱點到較好的位置，讓電路的良率獲得改善。 
由於分析良率時，常以常態分佈 (Normal distribution, 亦稱高斯分佈 Gaussian 
distribution)的製程變異模型為主要模擬樣本，而兩個變數的常態分佈，投影在二維平面上
即為橢圓的型態；因此，目前相關研究上，以橢圓模型的方式較受歡迎。圖五為例，即應
用了 MVE 演算法來實現設計中心化。將初始標稱點 P(0)，經過多邊形做為可行性區間的近
似邊界，爾後再以最大內接橢圓的方式去移動標稱點，逐次移動至 P(2)的位置，達到良率
最佳化的目的。這樣的設計中心化方法，提供了一個很快速的模擬環境；然而，因為使用
了近似的可行性區間邊界，未把實際製程變動的影響反應在其中，所以難免在良率估測上，
有些許精確度的損失。此外，在演算法的使用上，需要預先設定電路的設計限制，以及具
備足夠的數學方程式或演算法連結電路規格與元件參數之關係，才能進行公式簡化的步
驟，所以比較適合架構簡單的類比電路，或是可忽略非理想效應的數位電路之應用。 
p1
p2
P(1)
P(2)
p1
p2
P(0)
P(1)
 
圖五:利用 MVE 演算法實現 Design centering 
6 
 
 
p1
p2
P(0)
WCD = 1.5σ
p1
p2
P(1)
WCD = 3.1σ
 
圖七:利用 WCD 分析演算法實現 Design centering 
整體而言，以模擬為基礎的良率改善方式，透過大量的電晶體階層模擬，得到完整的
效能輸出波形，不僅可精確地估測設計良率，對於電路的種種效應也擁有極佳的可觀察性；
然而，龐大的模擬樣本卻也使其付出了時間的代價，針對規模較為複雜的類比電路，電晶
體階層模擬所帶來時間消耗更為可觀。有鑑於此，藉由階層式的行為模型來輔助良率分析
[4-10]，以加速模擬時間，近年來也有不少相關研究。主要的概念，希望能建立一個準確度
還不錯的行為模型，而將繁瑣的效能模擬向上提升到行為階層來實行，不但可有效地縮減
執行時間，也保留對於電路波形的可觀察性。 
然而，不論是利用simulation-based的方式，或是equation-base的方法來改善電路良率，
都需要預先設定電路的設計限制，並建立繁複的數學方程式來連結電路規格與所有的元件
參數之關係，以定義出可行性參數區間的邊界，這對較為複雜的類比電路而言，例如：時
脈與資料回復電路( Clock and Data Recovery, CDR )、類比數位轉換器 (Analog Digital 
Convertor, ADC)，或是鎖相迴路(Phase-locked Loop, PLL)等電路，因為其電晶體個數繁多，
再加上不同的製程變異參數造成的影響不一，使得需要考量的元件參數變異可能有數百個
之多，要完全地描述這些設計限制與建立適合的方程式，定義出一個合理的可行性參數區
間之邊界，將會是設計者的一大挑戰。如同先前的研究文件中所記錄，建立可行性參數區
間通常都是最花時間的步驟，表示這個步驟已經成為整個良率優化流程之中的最大的瓶頸。 
因此，本計畫希望研發一個不同的良率優化設計方式，無須定義複雜的可行性參數區
間之邊界，而是透過既有的良率模擬結果，再利用統計分析的方法與力學模型的輔助，找
到設計標稱點應該移動的位置來改善良率，即一種無邊界式(boundary-less)的良率優化方
8 
 
 
Performance space
Pass/Fail centroid
Calculate next 
nominal point
Pass/Fail samples 
grouping
Nominal 
point moving
 
圖八：標稱點移動法之設計流程 
PCA
Behavioral-level 
sizing
Device-level sizing
RSM
Hierarchical 
parameter sizing
 
圖九：階層式參數調整之設計流程 
10 
 
 
圖十：(1)良率較差之效能空間參數分布圖；(2)良率較佳之效能空間參數分布圖
%100(%)  failpass
pass
NN
N
yield                             (1) 
從上述兩個例子可以發現，若是能改變 nominal design 的位置，使得多數受到偏移後
的樣本，仍然能落在規格之中，則可以有效改善設計良率。在傳統的作法上，需要使用大
量的設計限制，及繁複的數學方程式，以定義出可行性參數區間的邊界，才能計算出
nominal design 應該移動的位置；然而，這對較為複雜的類比電路而言，因為其電晶體個
數及所考慮的製程變異參數為數眾多，要定義出一個合理的可行性參數區間之邊界實屬不
易。因此，希望提出一無邊界式的良率優化方法，透過既有的效能模擬結果，再利用統計
分析的方法與力學模型的輔助，找到設計標稱點應該移動的位置來改善良率。 
首先，觀察效能空間上參數分布情形可以發現，當設計良率不佳時，nominal point
的位置會比較靠近 fail 樣本數較多的地方，相反地，若設計良率較高時，nominal point
的位置反而會接近 pass 樣本群聚之處。換言之，倘若能夠讓所設計的 nominal point 遠離
fail 的樣本群，而接近 pass 的樣本群，如圖十一(1)(2)所示，預期將會有效提升電路之
設計良率。 
p1
p2
p1
p2
 
(1)                   (2) 
圖十一：(1)標稱設計靠近 pass 樣本群聚示意圖；(2)標稱設計遠離 fail 樣本群聚示意圖 
12 
 
根據設計者所定義出來的效能規格，可以由式(2)定義出 pass 群組；其中每一筆效能
參數值共有 m項效能規格需滿足，pij表示第 j筆效能參數值的第 i項效能規格，si_upper為第
i 項效能規格之上限，si_lower為第 i 項效能規格之下限，而 Ppass則為滿足所有規格之樣本集
合，如圖十二中的白點所示。以此類推，式(3)則定義出 fail 群組，其中 Pfail表至少有一
效能未滿足規格之樣本集合。 
   1 ,...,mi,sp|s p  P i_upperiji_lowerijpass               ( 2 ) 
   1 ,...,mi,pss|p p  P iji_loweri_upperijijfail               ( 3 ) 
2.2.2  力學定理應用 
如同前面章節所提，當設計的電路良率不如預期時，若能將標稱點作些微的修正，讓
標稱點往 pass 的區域移動；讓標稱點遠離 fail 的區域，則可以達到提升電路設計良率的
目標。接著，我們將何在效能空間上，使用力學定理來移動標稱點。 
有鑑於力學的定理，提供目標施力方向、大小，可使目標產生位移的概念，在此，我
們將此定理應用於移動標稱的方法中。首先，假設 pass samples 對於標稱點具有與距離成
正比的吸引力，因此可定義出其吸引力如式(4)到(7)所示；而 fail samples 對於標稱點具
有與距離成反比的排斥力，因此可定義出其吸引力如式(8)到(11)所示，在此，Wi,k為 kth
效能的 ith個樣本的權重，Nk為 kth效能標稱點的位置，Rk是作為標準化之用途，在此定義出
兩種力的大小以及方向的特性，作為之後決定新標稱點的依據。 
 )( ,kipass XdF                                                   (4) 
  kikiki DWXd ,,, )(                                              (5) 
kkikki RXND /)( ,,                                                 (6) 
kpasskk XNR ,min                                                 (7) 
14 
 
 
(1) 
  
(2) 
 
(3) 
圖十四：找尋平衡點流程示意圖 
16 
 
  
2.2.5 主成分分析 
主成分分析(PCA)[33]由卡爾‧皮爾森(K. Pearson)於西元 1901 提出，其概念主要如
圖十六所示。假設有變數 x1、x2 及 x3，其樣本點 Xi(x1i, x2i, x3i)散布在三維空間中；
倘若可以在此系統中找到兩條彼此正交(orthogonal)的線性方程式 pc1 與 pc2 如式(12)，
來近似原有的樣本點集合，便可將三個變數的系統簡化成用二個變數就能表示。式中 amn
代表第 n項變數在第 m個的主成分中之係數，反映了該變數權重的特性；而空間中的樣本
點分別投影至 pc1 與 pc2 上所得數值，即為主成分分數(principal component score)，此
分數可作為一組新的變數來取代原有的變數空間，以上即為主成分分析的基本概念。 
x1
x2
x3
pc2
pc1
xi
 
圖十六：以主成分分析化簡多變數之示意圖 
203232221212
103132121111
+ax+ax+ax = apc
+ ax+ax+ax = apc
                                   (12) 
主成分分析利用線性近似的方式，能夠有效地降低變數的維度；另一方面，其線性方
程式間彼此正交，因而去除了變數間的相關性；有鑑於上述特性，主成分分析常被應用於
多變量統計分析(multi-valuable analysis)的議題。雖然利用線性模型去近似多變數的時
候，會損失些許資訊量；但在複雜的多變量空間中，若變數間的相關性越高，主成分分析
的方法，越能凸顯其變數化簡的優勢。 
18 
 
                                               
0
1 11
axxaxaY
k
i
k
j
jiij
k
i
ii  
 
                                      (14) 
透過反應曲面法的方式，能夠建立效能階層與 PCA 階層參數間之關係，如式(15)所述；
式中 y1，y2，…，yn 表 n 個效能參數， pc1，pc2，…，pcm 表示較重要之 m個主成分參
數，經過 RSM 建構的線性模型則為 f1，f2，…，fn。 
)...(
                   
)...(
)...(
21
2122
2111
mnn
m
m
,pc,,pcpc = fy
,pc,,pcpc = fy
,pc,,pcpc = fy

                                       (15) 
在行為階層參數調整的部分，希望透過所建立之方程式，以效能參數的資訊，計算出
行為階層之參數值。然而，若是主成分的個數 m>效能參數個數 n時，同一筆效能參數值所
對應出的主成分參數並非唯一解；因此，便將表示一單位主成分能構成多少效能的關係式，
轉化成定義一單位效能參數能轉換成多少主成分參數的方程式。相同地，可利用反應曲面
法，如式(16)般重新建構二參數階層間之關係。此外，在 PCA 階層與行為階層間，也可依
照相同模式定義其關係式，如式(17)所述。如此一來，便可將行為參數與效能參數間建立
如圖十七之關係。 
)...,(
              
)...,(
)...,(
21
2122
2111
nmm
n
n
y,,yy = gpc
y,,yy = gpc
y,,yy = gpc

                                          (16) 
),...,,(
                     
),...,,(
),...,,(
21
2122
2111
mkk
m
m
pcpcpcQx
pcpcpcQx
pcpcpcQx




                                      (17) 
20 
 
 
圖十八：以反應曲面法與主成分分析建立 FBMCS 流程 
所提出之 FBMCS，是利用既有的統計分析資料建立層與層間關係，直接推估新的標稱
點所具有的效能變化，而不需耗時模擬額外的訓練樣本。在這般前提之下，可以有效提升
良率估計的效率，於高階層完成從良率分析、標稱點移動、參數調整到良率改善等流程，
降低未來低階設計之良率提升不足時而重複設計(iteration)的次數。這樣的分析方式簡單
又快速，可協助我們及早評估 nominal design 移動對於良率改善的成效，而在最後分析整
體電路良率時，我們仍會以較準確的 BMCS 模擬方式來估計良率。因此，透過所提出之無邊
界式良率優化方法，結合 FBMCS 快速分析，將可大幅提升良率的設計效率。 
2.2.8  元件階層參數調整 
藉由效能空間的標稱點移動與雙階層參數調整，計算出具關鍵性的行為階層參數之
後，設計者可以根據這些特徵參數，去調整元件的尺寸以改良設計。在元件階層參數調整
的部份，因為類比電路的參數調整，已有許多相關論文[30-31]被發表可供使用，在此，是
採用 MunEDA 公司所開法的 WiCkeD[32]來作為調整電晶體尺寸的工具。有了特徵參數的資
訊，不論是實現前人所提出之演算法，或者使用參數調整工具，皆有助於加快設計改良的
時間。 
22 
 
 
 實驗結果 
此設計中依照效能規格需求，定義了三項效能參數需要滿足；分別是鎖定電壓(lock 
voltage, Vlock)、鎖定時間(lock time, Tlock)，以及峰對峰抖動(p-p jitter)。其設計規格
如表一所示，在鎖相迴路正常操作達相位鎖定時，其鎖定電壓需為 1 V ± 0.2V，而鎖定時
間需小於 2.5us，另外輸出訊號之等峰對峰抖動不可超過 34ps,功率消耗需低於 0.85mW。 
表一:鎖相迴路規格 
效能 規格 
Lock voltage 1 V ± 0.2 V 
Lock time < 2.5 us 
P-P jitter < 34 ps 
Power < 0.85 mW 
初始 nominal design 之良率分析結果如圖二十所示；x軸表示鎖定時間，y軸表示輸
出抖動；其中原始的 nominal point 以實線箭頭所指之菱形點◇表示，效能參數部分，以
圓點ｏ表示 pass 樣本，而 x則表示 fail 樣本；此外，pass centroid 與 fail centroid
分別以粗體字 x與粗體字 o標記之。由數據中觀察，一開始良率僅有 50.7%，然而在進行
完改善良率的流程後，可以將良率提升至 93.0%，原始設計與改善良率後，各項參數與效
能的數據，則詳列於表二之中。 
 
圖二十: 標稱點移動的過程及 FBMCS 分析的結果 
24 
 
 
圖二十一: 元件尺寸調整後的良率分析結果 
最後是執行時間的部分，我們參考[35]的研究成果，在這篇論文中利用效能空間探索
(performance space exploration, PSE)的方式，同樣針對充電幫浦架構的 PLL 電路，找
出部分可行性區間之邊界，約略需要 4到 5個小時的執行時間，另外在行為階層參數調整
部分，大概需要 1至 2個小時找出特徵參數值。而我們所提出之無邊界良率優化流程，因
為省去了定義複雜的可行性設計區間的時間，藉由標稱設計移動法以及快速的行為參數調
整方式，整體而言，只需要大略數秒鐘即可得到大幅提升良率的 nominal design，由此可
知本方法在良率優化上擁有還不錯的效能，這樣不但能達到提升良率的效果，還能減少重
新設計或重新下線(Re-spin)的時間，大幅降低 IC 設計成本。 
三、 結論與計畫自評 
在這個年度裡，我們研發出了一套完全不同的良率優化設計流程，無須定義複雜的可
行性參數區間之邊界，而是重複使用既有的良率模擬結果，再利用統計分析的方法與力學
模型的輔助，找到設計標稱點應該移動的位置來改善良率。這一種隱含式(implicit)的良
率優化方法，在不需要描繪可行性參數區間之邊界的前提下，大大地節省了整個良率優化
流程所需的時間，即使是較為複雜的類比電路，也能夠有效率地去修正設計標稱點，達到
良率優化的目的。為了將計算出來的較佳標稱點實現出來，本計劃也研發了階層式之參數
調整技術，將此標稱點所對應的行為階層參數值(behavioral-level parameter)計算出
來，再利用現成的一些參數調整工具，就可以快速地找出此標稱點所對應的元件尺寸修改
方案，協助電路設計者能更有效率的改良設計，進而提升電路之設計良率。相關結果已經
被這個領域最頂尖的 DAC 研討會(Design Automation Conference)所接受刊登[29]，表示
26 
 
[8] Xin Li, Jiayong Le, L.T. Pileggi, A. Strojwas, “Projection-based Performance Modeling 
for Inter/Intra-die Variations,” IEEE/ACM International Conference on 
Computer-Aided Design, pp. 721-727, Nov. 2005. 
[9] Guo Yu, Peng Li, “Lookup Table Based Simulation and Statistical Modeling of 
Sigma-delta ADCs,” IEEE/ACM Design Automation Conference, pp. 1035-1040, Jul. 
2006. 
[10] Chin-Cheng Kuo, Meng-Jung Lee, Chien-Nan Jimmy Liu, and Ching-Ji Huang, "Fast 
Statistical Analysis of Process Variation Effects Using Accurate PLL Behavioral 
Models", accepted to appear in IEEE Transactions on Circuits and Systems I. 
[11] H. L. Abdel-Malek, A. S. O. Hassan, E. A. Soliman, and S. A. Dakroury, “The Ellipsoidal 
Technique for Design Centering of Microwave Circuits Exploiting Space-Mapping 
Interpolating Surrogates”, IEEE Trans. on Microwave Theory and Techniques, vol. 54, 
no. 10, pp. 3731-3738, Oct. 2006. 
[12] H. E. Graeb, Analog Design Centering and Sizing, Springer, 2007. 
[13] G. Stehr, M. Pronath, F. Schenkel, H. Graeb, K. Antreich, “Initial Sizing of Analog 
Integrated Circuits by Centering within Topology-given Implicit Specifications”, in 
Proc. Int’l Conf. on Computer-Aided Design, pp.241-246, 2003. 
[14] X. Li, J. Wang, L. T. Pileggi, T.-S. Chen and W. Chiang, “Performance-Centering 
Optimization for System-Level Analog Design Exploration”, in Proc. Int’l Conf. on 
Computer-Aided Design, pp 422-429, 2005. 
[15] U. Sobe, K.-H. Rooch, A. Ripp, M. Pronath, “Robust Analog Design for Automotive 
Applications by Design Centering with Safe Operating Areas”, in Proc. Int’l Symp. on 
Quality Electronic Design, pp. 848-854, 2008. 
[16] M. Hershenson, “Efficient description of the design space of analog circuits,” 
IEEE/ACM Design Automation Conference, pp. 970-973, 2003. 
[17] S.S. Sapatnekar, P.M. Vaidya, S.M. Kang, ”Convexity-based Algorithms for Design 
Centering,” IEEE/ACM International Conference on Computer-Aided Design, pp. 
206-209, 1993. 
[18] Guido Stehr, Michael Pronath, Frank Schenkel, Helmut Graeb, Kurt Antreich, “Initial 
Sizing of Analog Integrated Circuits by Centering Within Topology-given Implicit 
Specifications,” IEEE/ACM International Conference on Computer-Aided Design, 
pp.241-246, 2003. 
[19] B. Smedt and G. Gielen, “WATSON: design space boundary exploration and model 
generation for analog and RF IC design,” IEEE Transactions on Computer-Aided 
Design of Integrated Circuits and Systems, vol. 22, no. 2, pp. 213-224, Feb. 2003. 
[20] G. Stehr, H. Graeb and K. Antreich, “Performance trade-off analysis of analog circuits 
by normal-boundary intersection,” IEEE/ACM Design Automation Conference, pp. 
958-963, 2003. 
28 
 
刊 pp. 119-130, 2005 
[35] Jun Zou, Daniel Mueller, Helmut Graeb, Ulf Schlichtmann “A CPPLL Hierarchical 
Optimization Methodology Considering Jitter, Power and Locking Time,” 
IEEE/ACM Design Automation Conference, pp. 19-24, 2006. 
Behavior-Level Yield Enhancement Approach 
for Large-Scaled Analog Circuits 
 
Chin-Cheng Kuo Yen-Lung Chen I-Ching Tsai Li-Yu Chan Chien-Nan Jimmy Liu 
Department of EE, National Central University, Jung-Li City, 320, Taiwan, ROC 
casey@ee.ncu.edu.tw; {985201018, 95521029, 985201027}@cc.ncu.edu.tw; jimmy@ee.ncu.edu.tw 
 
ABSTRACT 
In traditional yield enhancement approaches, a lot of computation 
efforts have to be paid first to find the feasible regions and the 
Pareto fronts, which will become a heavy cost for large analog 
circuits. In order to reduce the computation efforts, this work tries 
to finish all iteration steps of the yield enhancement flow at 
behavior level. First, a novel force-directed nominal point moving 
(NPM) algorithm is proposed to find a better nominal point 
without building the feasible regions. Then, an equation-based 
behavior-level sizing approach is proposed to map the NPM 
results at performance level to behavior-level parameters. A fast 
behavior-level Monte Carlo simulation is also proposed to shorten 
the iterative yield enhancement flow. Finally, using the obtained 
behavioral parameters as the sizing targets of each sub-block, the 
device sizing time is significantly reduced instead of sizing from 
the system-level specifications directly. As demonstrated on a 
complex CPPLL design, this behavior-level approach could be 
another efficient methodology to help designers improve their 
analog circuits toward better yield. 
Categories and Subject Descriptors 
B.7.2 [Integrated Circuits]: Design Aids 
General Terms 
Algorithm, Design, Reliability 
Keywords 
Process Variation, Yield Enhancement, Analog Circuits 
 
1. INTRODUCTION 
With shrinking device size in deep submicron process, 
parametric yield loss due to process variations has become a 
critical issue, especially for sensitive analog circuits. Therefore, 
design-for-manufacturability (DFM) and design-for-yield (DFY) 
techniques have recently become popular research topics for 
considering process variation effects before manufacturing. They 
can help designers improve design yield at early stages and 
reduce re-design cycles and re-spin cost. 
Design centering is one of the popular techniques for yield 
enhancement at design stages. The aim is to find the nominal 
design that leads to the maximum yield. Conventional design 
centering techniques often use a geometric approach to locate the 
feasible region first, which is the region in device parameter space 
that satisfies all design constraints and target specifications. For a 
given circuit topology, the ellipsoidal technique [1] can be applied 
to approximate the feasible region using a hyper-ellipsoid. The 
center of this hyper-ellipsoid is regarded as the nominal point that 
allows maximum device parameter variations because it has 
largest distance to all boundaries. However, if the feasible region 
has a strange shape, using a hyper-ellipsoid to approximate the 
realistic feasible region may not be the best solution. 
In most cases, the entire design space is often irregular in 
analog circuits. Traditional design centering approaches often 
require complicated formulas and numerous design constrains to 
describe the boundaries of feasible design regions. For 
complicated analog circuits, the number of required design 
constraints could be huge. For example, a charge pump PLL 
(CPPLL) contains 40K optimization variables and 150K 
constraints [2]. Therefore, finding the feasible region or its partial 
boundaries within the design space is extremely complicated even 
for a given circuit topology, as demonstrated by the PLL case in 
[3] and the OPA results in [4]. 
When properly accomplished, automated synthesis techniques 
[10] for analog circuits can avoid time-consuming transistor-level 
simulations and significantly improve the efficiency of circuit 
optimization. In order to reduce the exploration efforts, the Pareto 
front [4-9] is identified to find an optimal tradeoff curve between 
competing performance specifications. Because the process 
variation effects are not considered, those optimization algorithms 
typically push the system performance to some corners that are 
vulnerable to parametric variation [11]. Therefore, yield-aware 
Pareto front models are proposed [11, 12] to provide different 
tradeoff curves under different yield targets. According to the 
given yield value, the optimal point can be found in the 
corresponding Pareto front curve. However, it is known that 
building the Pareto front of a design requires a lot of simulation 
resources. Building multiple Pareto front curves even worsens this 
overhead, especially for large circuits. Although this is only a 
one-time cost for synthesis tools to enable fast generation of new 
circuits in the future, it may become a long waiting time for the 
designers who just want to improve the yield of their existing 
circuits. 
 
Permission to make digital or hard copies of all or part of this work for 
personal or classroom use is granted without fee provided that copies are 
not made or distributed for profit or commercial advantage and that 
copies bear this notice and the full citation on the first page. To copy 
otherwise, or republish, to post on servers or to redistribute to lists, 
requires prior specific permission and/or a fee. 
DAC’10, June 13-18, 2010, Anaheim, California, USA 
Copyright 2010 ACM 978-1-4503-0002-5 /10/06…$10.00. 
number of concerned performances, which is the same number as 
the performance space dimensions. The weight of each Pass 
sample (Wi,k) is the same in this case. Di,k represents the distance 
of ith sample at kth axis. Because the magnitude has different unit 
in different dimension, the distance of each dimension (Dk) is 
normalized by the distance of the closest pass point (Rk) to the 
next nominal point (Nk), as shown in (2) and (3). 
ki
i k
kiPass DWF ,, *
                                                     (1) 
kkikk RXND /)( ,

                                                      (2) 
|)min(| ,kpasskk XNR                                                  (3) 
2.2 Step 2 –Fail Force Computation 
The Fail samples close to Pass samples are more important 
because those Fail samples that leave the specifications too much 
are not likely to be the next nominal point. Therefore, each Fail 
sample (Xi,k) is modeled as a force that is inversely proportional 
to its distance between the next nominal design point (Nk), as 
shown in (4). Please be noted that the distance of each dimension 
(Dk) is also normalized by the distance of the closest fail point (Rk) 
to the next nominal point (Nk), as shown in (5) and (6). 
ki
i k
kiFail DWF ,, /
                                                            (4) 
)/( ,kikkk XNRD 

                                                            (5) 
|)min(| ,kfailkk XNR                                                        (6) 
2.3 Step 3 –Next Nominal Point Calculation 
In typical force-directed approaches, the point that reaches 
force equilibrium is the best solution. However, it is hard to find a 
point with exact zero force in some situations. Therefore, the 
optimization goal in this work is relaxed a little bit, which tries to 
find the point with minimal Ftotal instead of the zero-force point, 
as shown in (7). Because the number of Pass samples is often 
more than the number of Fail samples, the force equilibrium point 
Cp with Fpass only is calculated first to simplify the calculation, as 
shown in Fig. 5(a). Then, Ffail is added to push Cp toward the 
equilibrium point (Cp’), as shown in Fig. 5(b). Because Cp’ is 
often close to Cp, searching for the final solution can be limited to 
a small region around Cp thus reducing the computation time 
significantly. 
Minimize         FailPassTotal FFF                                    (7) 
3. BEHAVIOR-LEVEL SIZING & FBMCS 
After NPM step, the new nominal point at performance level 
can be obtained. Then, the performance values are mapped to 
device sizes to verify the new yield with device variation models. 
If the new yield is not satisfied, the NPM step repeats until users’ 
requests are fulfilled. However, for large analog circuits, 
iteratively doing top-down sizing is a significant cost. Even using 
hierarchical analysis, overall sizing cost is still expensive, as 
shown in a CPPLL case [3]. 
In order to reduce the sizing cost, this paper proposes efficient 
behavior-level sizing and fast behavior-level MC simulation 
(FBMCS) to shorten the yield enhancement process. Reusing the 
Pass samples from initial yield analysis, some simple regression 
equations between behavior level and performance level are built 
for sizing and MC analysis at behavior level. This approach can 
complete each yield enhancement iteration in seconds and allows 
more iterations. After the yield value is improved to an acceptable 
number, a precise MC analysis is performed to verify the yield 
value and avoid possible errors of the rough estimation during 
iterations. If the final yield is passed, any sizing tool can be used 
afterward to implement the new nominal design into real device 
sizes. The details of the proposed behavior-level sizing and 
FBMCS are introduced in the following sections. 
3.1 Behavior-Level Sizing 
Since system performance is the overall response from the 
behavior of each sub-circuit, the relationship between behavior 
level and performance level is still complicated. Therefore, high-
order response surface methodology (RSM) is often used in 
pervious works to model such relationships [14, 18-21]. Using 
RSM techniques, each circuit performance is expressed as a 
Figure 4. K-dimensional performance space 
Figure 3. Pass/Fail samples in the performance space 
(a)                                                   (b) 
Figure 5. Illustrations of nominal point calculation (a) the 
force equilibrium point Cp of Fpass (b) the final solution Cp’ 
Reusing these yield analysis results, the equations between 
performance level and behavior level can be built for behavior-
level sizing and FBMCS. As to the relationship between device 
level and behavior level, the sensitivity analysis (SA) and quasi-
SA models in [17] are adopted in the experiments. TABLE I 
shows the specifications of this CPPLL and the critical behavioral 
parameters of its analog sub-blocks. Starting from the initial 
nominal design, the performance-level NPM results and the 
corresponding behavior-level sizing results are shown in the 
column “After yield enhancement”. 
Table 1. Yield enhancement results of the CPPLL 
Using power as a rough cost constraint, Fig. 8 shows the 
overall NPM results and the last FBMCS results by using the 
proposed yield enhancement approach. The yield of this CPPLL 
is improved from 50.7% to 93.0% in 3 iterations. The run-time 
including the entire NPM steps, behavior-level sizing, and 
FBMCS is totally 4.43 seconds.  Referring to the previous work 
[3], the whole optimization procedure for a CPPLL requires 
several hours because numerous circuit simulations are required 
for building the Pareto fronts and regression equations. Although 
the modeling results are very accurate in [3], the run-time of 
performance space exploration and optimal behavior-level sizing 
is a significant cost. Using some heuristic methodologies, this 
work starts from a user-given initial design and reuses its yield 
analysis results to avoid identifying the hard-to-predict feasible 
region. Therefore, the required regression efforts and iteration 
cost can be greatly reduced while improving the design yield. 
Finally, users can use any sizing tool, such as NeoCircuitTM [23] 
and WiCkeDTM [24], or their own design experience to map the 
behavior-level results to the circuit-level device sizes. In order to 
verify that the obtained nominal design is a feasible solution, we 
use WiCkeD to compute the device sizes for this nominal point. 
Using the obtained behavioral parameters as the sizing targets of 
each sub-block, optimization is performed block-by-block to get 
the device sizes. The performance of the whole circuit is shown in 
the column “Block-level sizing” of TABLE II, which 
demonstrates that the proposed approach does improve the yield 
of the original design but still matches all specifications. The MC 
analysis results after sizing are also shown in Fig. 9 for readers’ 
reference. 
Table 2. Device-level sizing results of the CPPLL 
Blocks Parameters Spec. Behavioral results 
Whole 
PLL sizing
Block-
level 
sizing
CPPLL
(nominal)
Vlock (V) 1 ± 0.2 1.08 1.11 1.09
Tlock (μs) < 5 1.50 1.39 1.33
jitter (ps) < 34 28.77 25.59 26.9
power (mW) <0.9 0.85 0. 86 0.86
Yield (%) 93.0 91.5 92.3
Area (um2) -- 416.45 417.30
Optimization Time (min.) 0.07 300 6 
Giving the target system-level specifications, WiCkeD can also 
perform device-level sizing directly. The performance of the 
resultant circuit by this approach is also shown in the column 
“Whole PLL sizing” of TABLE II. Comparing the last two 
columns of TABLE II, using the obtained behavioral parameters 
as the sizing targets of each sub-block can significantly reduce the 
optimization time with similar solution quality. It shows that the 
proposed approach is a practical solution to guide the sizing tools 
toward better yield with much less computation time on nominal 
point moving and device-level sizing. 
5. CONCLUSION 
This paper proposes a novel force-directed yield enhancement 
approach for large analog circuits. Instead of finding the hard-to-
predict feasible regions, this work starts from a given design and 
reuses its yield analysis distributions to determine the next 
nominal design toward better yield. In this way, the heavy 
simulation efforts for building the feasible regions can be 
significantly reduced. Then, an equation-based behavior-level 
sizing approach is proposed to map the NPM results at 
performance level to behavior-level parameters. A fast behavior-
level MC simulation (FBMCS) is also proposed to shorten the 
Blocks Parameters Spec. Initial design 
After yield 
enhancement
CPPLL 
(nominal) 
Vlock (V) 1 ± 0.2 0.99 1.08
Tlock (μs) < 5 1.17 1.50
pk-pk jitter (ps) < 34 32.72 28.77
power (mW) <0.9 0.88 0. 85 
CP 
Current ratio Iratio 
－ 
1.00 1.00
Switch time Tsw (ns) 4.64 5.01
VCO 
KVCO (GHz/V) 1.14 1.00
fmin (MHz) 317.3 275.5
fmax (MHz) 1036.1 904.1
Yield (%) 50.7 93.0 
Figure 8. NPM results and rough yield values by FBMCS
Figure 9. Final BMCS results after device-level sizing 
表 Y04 
行政院國家科學委員會補助國內專家學者出席國際學術會議報告 
                                                        99 年 6 月 10 日 
報告人姓名 
 
李 牧 勳 
 
服務機構
及職稱 中央大學電機所博士班 
     時間 
會議 
     地點 
2010/05/30~2010/06/02 
法國巴黎 
本會核定
補助文號
 
 
會議 
名稱 
 (中文) 2010 年國際電路及系統研討會議 
 (英文) International Symposium on Circuits and Systems 2010 
發表 
論文 
題目 
 (中文) 使用標準函式庫資訊之閘層級動態電壓降估測 
 (英文) Dynamic IR Drop Estimation at Gate Level with Standard Library 
Information 
報告內容應包括下列各項： 
一、 參加會議經過 
此次之國際電路以及系統研討會選在法國巴黎的Hotel NewYork之國際會議
中心舉行，五月三十日大會開設數個短期課程，如類比數位轉換器的設計應
用，功率元件的設計實際考量。正式會議則是於五月三十一日正式展開。開
幕式共有約五、六百人參與，隨後並邀請 Giovanni De Micheli 教授做 keynote 
speech，與我們談論電路與系統進入奈米系統的進展，此次大會還邀請了另
外兩位專家於會議的其他兩天早上作 keynote speech，讓我了解了許多現今
大家最重視的問題，學術論文的部分則分成數個 parallel section 分散在三天
當中做口頭報告以及海報展示。本人的論文被安排在第二天下午以海報展示
的方式大會中的專家一起討論並且交換研究心得，讓我獲益不少。此外亦於
晚宴及空檔時間和各地學者交換經驗，並認識了許多研究上的先進，相信對
我日後的研究工作有很大的幫助。 
 
二、 與會心得 
這次與會，可以了解到進入奈米時代電路與系統這個領域進步的快速，對於
目前最新的發展，以及自己正在研究的題目方向，也都有了更清楚的認知，
看過別人的作品之後，對自己的優點以及缺點也更加的熟悉，當然也更加激
勵我自己必需更努力，來改善研究上的缺失，使研究能夠更得上現今一流大
學的程度。也特別感謝國科會的支持，在研究領域上給予極大的幫助，日後
我們將會繼續努力，爭取更好的表現。 
三、 攜回資料名稱及內容 
會議論文集與論文光碟片。 
 
 
 
The delay time, rise/fall time, and energy consumption 
of each cell will be changed when the IR-drop effect is 
considered. If those data in the LIB files are modified to 
include IR-drop effects, the estimated current waveforms 
based on new data will include IR-drop effects, too. 
Therefore, an analytical method is proposed in this paper to 
modify the data stored in activity file (.vcd). With those 
modified data, using the method proposed in [2] can also 
obtain accurate supply current waveforms and IR-drop values 
with non-ideal supply lines. The proposed method can reduce 
the characterization efforts of different libraries with different 
non-ideal supply lines. 
The rest of this paper is organized as follow. In Section 
II, the standard library format, liberty format (LIB), and the 
previous current estimation flow are briefly introduced. The 
proposed method is presented in Section III. The 
experimental results on benchmark circuits are shown in 
Section IV. Finally, a conclusion is drawn in Section V. 
II. BACKGROUND 
The most popular standard library format, liberty format 
(LIB) [5], is briefly introduced in Section II.A. Then, the 
quick gate-level supply current waveform estimation flow 
proposed in [2] is briefly introduced in Section II.B. 
A. Liberty Format (LIB)[5] 
Liberty format is the popular standard library format at 
gate level to store timing information and internal energy of 
each cell. Look-up-tables are used to store these data. The 
definitions of the variables used to calculate supply current 
waveforms are listed as follows. 
Transition time: It is defined as the duration time of a 
signal from 10% to 90% supply voltage (VDD) in the rising 
case and from 90% to 10% VDD in the falling case.  
Propagation delay time: It is defined as the duration 
from input stimulus crossing 50% VDD to the output 
response crossing 50%VDD.  
Input capacitance: It is the capacitance of each input 
pin in a cell.  
Internal energy: It is the internal energy consumption 
of a cell without its energy consumption of its output load.  
B. Gate-Level Supply Current Waveform Estimation Flow[2] 
The estimation flow of the supply current in [2] is shown 
in Fig.2. The input data are the gate-level netlist of the design 
(.v), the design constraints of the primary input transition 
time and primary output load (.sdc), standard library 
information (.lib) and the activity file (.vcd) obtained in gate-
level simulation [8], which are the same with conventional 
gate-level power analysis tools.   
After reading those input files, the switching events can 
be obtained by the activity file (.vcd). The active gates are 
decided by each event and their supply current waveforms are 
calculated by the proposed formulas in [2]. Finally, all supply 
current waveforms of active gates are summarized in time 
and the total supply current waveform of the design is plotted. 
No additional characterization efforts are required at all 
because only the same data for the conventional power 
estimation flow are used. 
 
Figure 2 The quick gate-level supply current waveform estimation flow 
III. PROPOSED IR-DROP ESTIMATION METHOD 
Using the previous approach in [2], a supply current 
waveform can be obtained by the information of standard 
library and activity files. In this work, an analytical method is 
proposed to estimate the IR-drop effect with the same 
information as in [2]. No extra characterization efforts for 
different supply resistances are required. The proposed 
approach is composed of two parts, modification of standard 
libraries and modification of activity files, which are 
explained in the following sections. 
A. Modification of Standard Libraries Information 
Although there are a lot of cells in a cell library, most of 
them can be classified into three categories, simple logic cells, 
composite logic cells and flip flops. The transition time, the 
propagation time and the internal energy are the most 
important information stored in standard libraries. Then, the 
detailed modification methods are presented as follows. 
1) Simple Logic Cells 
Fig.3(a) illustrates the equivalent model with non-ideal 
supply lines in the output rising case. TR(Y)(OLD) represents 
the rise time stored in standard libraries and TR(Y)(NEW) 
represents the modified rise time. The first-order RC model is 
used to equivalent the charging behavior of the cell. REQ(TR) is 
a charging resistor. Following the definition of rise transition 
time, TR(Y)(NEW) can be implied by TR(Y)(OLD) and Rwire. The 
detailed corollary is listed as follows. 
 )()9ln()( )()( YLoadRYTR TREQOLD   
)()9ln()(
)()()9ln()(
)(
)()(
YLoadRYTR
YLoadRRYTR
wireOLD
wireTREQNEW

  
Fig.3(b) illustrates the equivalent model with non-ideal 
supply lines for measuring the propagation delay time. 
TDR(XY)(OLD) represents the delay time stored in standard 
libraries and TDR(XY)(NEW) represents the modified delay 
time. In this case, the equivalent resistor is derived from 
TDR(XY)(OLD) to keep the same operation condition. 
According to the definition of propagation delay time, 
TDR(XY)(NEW) can be implied by TDR(XY)(OLD) and 
Rwire. The detailed corollary is listed as follows. 
)()5.0ln()( )()( YLoadRYXTDR TDREQOLD   
be obtained by the modification method of the signal cell. 
Then, TDfix_G1 can be implied by TD_G1(NEW)-TD_G1 and 
be propagated to next event T(B). T(B)(NEW) is derived by the 
summation of T(B) and TDfix_G1. The other events can be 
modified in the similar way. 
 
Figure 6 Illustration of VCD events with (a) ideal (b) non-ideal supply lines 
IV. EXPERMENTAL RESULTS 
According to the formulas proposed in previous sections, 
we have implemented an IR-drop estimation tool in C++ 
language. All the input files of this tool follow standard 
formats, which are netlist file (.v), activity files (.vcd) of the 
design under given input vectors, design constraint files (.sdc) 
of the primary input transition time and output loads and the 
LIB file (.lib) of standard libraries. Those input files are 
compatible with current EDA tools. It allows the proposed 
solution to be plugged into current EDA flow smoothly.  
 
Figure 7 The supply current waveforms of c7552 with Rwire=10ohm  
In order to demonstrate the accuracy of the proposed 
approach, ISCAS’85 and ISCAS’89 benchmark circuits, 
which are implemented with TSMC 0.13um process, are used  
to perform some experiments. For each benchmark circuit, 
200 random pattern pairs are generated to trigger the circuit. 
The average results of all circuits are shown in column 
“Proposed Method” in TABLE I and TABLE II. Using 
HSPICE results as the golden values, the eVpeak is defined 
as the average error of the 200 results of the maximum IR-
drop. The eTpeak is defined as the average error of the 200 
results of the time when the maximum IR-drop occurs. The 
CORR is the average correlation of IR-drop waveforms. 
As shown in TABLE I and TABLE II, the average peak 
error is around 5% only, which is accurate enough for gate-
level application. Fig.7 shows the estimated supply current 
waveforms of c7552 circuit as example, which also confirm 
the accuracy of the proposed approach. In order to show the 
difference with IR-drop effect, the previous approach [2] is 
rebuilt in our environment and tested using the same input 
pattern. The results show that previous estimation suffers 
large errors when the resistance on supply lines is getting 
larger. The proposed approach can consider the Rwire effects 
and have a significant improvement on accuracy. 
TABLE I.  EXPERIMEMENTAL RESULTS OF ISCAS85 CIRCUITS 
RWIRE 
(ohm) 
GCM[2] Proposed Method 
eVpeak eTpeak CORR eVpeak eTpeak CORR 
2.5 2.98% 3.53% 0.98 0.29% 4.04% 0.98 
5 5.40% 4.02% 0.96 0.78% 4.85% 0.96 
10 9.29% 6.04% 0.90 1.90% 5.68% 0.95 
TABLE II.  EXPERIMEMENTAL RESULTS OF ISCAS89 CIRCUITS 
RWIRE 
(ohm) 
GCM[2] Proposed Method 
eVpeak eTpeak CORR eVpeak eTpeak CORR
2.5 0.51% 15.37% 0.90 0.72% 14.59% 0.91 
5 3.60% 15.72% 0.87 2.70% 13.28% 0.89 
10 8.53% 16.25% 0.78 4.48% 15.99% 0.82 
V. CONCLUSION 
In this paper, an analytical approach is proposed to 
modify the data in standard libraries and the events in activity 
files. With those modified data, using the method proposed in 
[2] can also obtain accurate supply current waveforms and 
IR-drop values with non-ideal supply lines. Extra 
characterization efforts and regression cost are still not 
required to obtain accurate IR-drop estimation. As shown in 
the experimental results, such an efficient modification 
method can improve the accuracy in the IR-drop estimation 
with limited information. The estimation errors of our 
approach are about 5% compared with HSPICE results.  
REFERENCES 
[1] M. Popovich, M. Sotman, A. Kolodny, and E. Friedman, “Effective 
radii of on-chip decoupling capacitors”, IEEE Transactions on Vary 
Large Scale Integration System, vol. 16, no. 7, pp. 894-907, July 2008.  
[2] M.-S. Lee, C.-H. Lin, C.-N. Liu, and S.-C. Lin, “Quick supply current 
waveform estimation at gate level using existed cell library 
information”, ACM/IEEE Great Lakes Symopsium on VLSI, pp. 135-
138, May 2008. 
[3] G. Blakiewicz and M. Chrzanowska-Jeske, “Estimation of supply 
current spectrum for early noise evaluation”, IEEE International. 
Symposium on Circuit and System, pp. 21-24, March 2006. 
[4] K. Shimazaki, H. Tsujikawa, S. Kojima, and S. Hirano, “Lemings : 
Lsi’s emi-noise analysis with gate level simulator”, IEEE International 
Symposium on Quality Electronic Design, pp.129-136, March 2000. 
[5] Library Compiler User Guide : Modeling Timing and Power 
Technology Libraries, Synopsys, March 2003 
[6] Open Source ECSM Format Specification Version 2.1, Cadence, 
December 2006. 
[7] CCS Timing Library Characterization Guidelines Version 3.2, 
Synopsys, December 2008 
[8] PrimeTime PX User Guide Version C-2009.06, Synopsys, June 2009 
 
98年度專題研究計畫研究成果彙整表 
計畫主持人：劉建男 計畫編號：98-2221-E-008-090- 
計畫名稱：適用於類比電路之隱含式良率改善技術之研究 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 1 1 100%  
研討會論文 2 2 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 2 3 100%  
博士生 3 1 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 2 1 100%  
研究報告/技術報告 0 0 100%  
研討會論文 3 2 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
 
