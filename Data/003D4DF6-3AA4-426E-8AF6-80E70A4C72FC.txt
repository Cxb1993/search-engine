 2
consistency, test collection for 
categorization, subject analysis, duplicate 
detection 
 
二、報告內容 
請參考附件中發表之論文。 
 
三、計畫成果自評 
 
本計畫已將相關的研究結果發表在
ACM SIGIR國際會議與「大學圖書館期」
刊上[1-2]，供國內外研究者參考。ACM 
SIGIR 是國際間資訊檢索領域最大型、最
重要國際學術會議。本論文發表期間，發
展 Reuters-21578分類測試集（國際上進行
自動分類研究使用最廣的測試集）的
David Lewis以及發展 OSHMED分類測試
集的 William Hersh等人（TREC filtering 
track歷屆主辦人），都對本研究自動偵測
分類測試集不一致的結果感到非常的興
趣。本計畫結果驗證了過去所有相關研究
的有效性，其學術意義重大，執行成果良
好。 
 
四、參考文獻 
 
[1] 曾元顯, "分類不一致對文件自動分類
效果的影響", 「大學圖書館」, 第 9 卷
第 1 期, 2005 年 3 月, 頁 2-19. 
[2] Yuen-Hsien Tseng and William John 
Teahan, "Verifying a Chinese Collection 
for Text Categorization," Proceedings of 
the 27th International ACM SIGIR 
Conference on Research and 
Development in Information Retrieval - 
SIGIR '04, July 25 - 29 Sheffield, U.K., 
2004, pp.556-557. 
 
 
is an approximation of cosine normalization, similarity scores 
sometimes were larger than 1. In such cases, they were set to 1.  
Results of the retrieval-based approach are shown in Table 1. 
Compared to the R-measure in [1], which reported 177 duplicates 
in Reuters-21578, this approach (S-measure for simplicity) 
detected 269 duplicates. An additional fuzzy string matching 
technique based on dynamic programming (D-measure) was 
applied to double-check the 269 documents. All were confirmed 
to be real duplicates. The most dissimilar pair was 2782 and 2880 
(with R=0.17, D=0.83, and S=1.0, all are the larger one between 
the pair) as shown in Table 2. As can be seen, these two 
documents are similar in fragments, a case that R-measure 
overlooks. At low S level, similar documents can still be found. 
Examples are document 519 and 7204 which have S=0.53. 
Document 519 contains only the title: “FED SETS 1.5 BILLION 
DLR CUSTOMER REPURCHASE, FED SAYS”, and 7204 is also a 
title: “FED SAYS IT SETS 1.5 BILLION DLRS OF CUSTOMER 
REPURCHASE AGREEMENTS”. In contrast, the R- and D-measure 
for these two documents are 0.15 and 0.37, respectively. 
For the Chinese collection, 113 documents were found with 
R=1.0 and 1965 documents were found with S=1.0. The same 
fuzzy string matching detects 22 documents among the 1965 with 
fuzzy similarity lower than 0.5. A number of human inspections 
revealed that even among these dissimilar documents, most are 
plagiaries of the others in parts or in whole. The Chinese 
collection not only has a high percentage of similar documents, 
but also has an extreme distribution of label inconsistency among 
these similar documents, compared to the English corpus.  
3. Effectiveness Experiments 
The label inconsistency between similar documents may confuse 
any machine learning classifiers such that effectiveness becomes 
unpredictable and unreliable. To have an idea of what this effect 
may have on these collections under the inconsistency level we 
found, we removed these similar documents from the collections 
to see how the effectiveness changes.  
We used KNN classifiers for both collections. Since KNN’s 
performance highly depends on the similarity measure, we used a 
bytesize normalized vector-space model (VSM) [3] and a 
probabilistic model called BM11 [4] for comparison. The K in the 
KNN method was set to 20 in all our experiments. Each document 
in the Chinese collection was assigned exactly one category from 
those that have the maximum category score of the classifier. 
Each document in the English collection was assigned at most two 
categories, one with the largest category score, the other with the 
second largest. The second ranked category was not assigned to 
the document if its score is less than the half of the largest. 
Feature selection was based on averaged chi-square values. Terms 
whose document frequency is less than 2 were not used for both 
collections. Both microF and macroF were reported as the 
effectiveness measures. 
Results are shown in Table 3. The BM11 retrieval model 
performs better than the VSM in all cases. In the Chinese corpus, 
although inconsistent similar documents are far more than the 
consistent ones, the effectiveness was not getting obviously better 
as more confusing documents were removed. In the English 
corpus, the effectiveness was not getting obviously worse as more 
consistent similar documents were removed. This suggests that 
given these levels of duplication and given these levels of 
consistency imbalance, the classifiers were not affected. 
4. Conclusions 
Our experiments showed: (1) Better classifiers perform better 
independent of duplicates and label inconsistency. (2) The high 
percentage of the confusing documents in the Chinese corpus 
does not prevent it from being a test collection candidate for TC. 
Actually, the 17 years of the collection time span provides 
another facet of TC that may be worthy of further exploration. 
Table 1: Percentage of similar documents and label 
inconsistency at different S levels, where S is similarity score. 
S>=1.0 S>=0.8 S>=0.6 Collections label 
# Doc % # Doc % # Doc % 
Incon. 1922 6.86 7894 28.18 9618 34.34 
Con. 43 0.15 351 1.25 2438 8.70 FJU CTC 
Total 1965 7.02 8245 29.43 12056 43.04 
Incon. 62 0.57 121 1.12 246 2.28 
Con. 207 1.92 628 5.82 1165 10.80 Reuters-21578 
Total 269 2.49 749 6.94 1411 13.08 
Table 2: The most dissimilar pair with S=1.0. Only the first 
paragraph is shown. The 2nd paragraph of both is the same. 
2782: TECHNIGEN PLATINUM CORP> IN METALS FIND. Technigen 
Platinum corp said it initial results of a 13-hole drilling program on its 
R.M. Nicel platinum property in Rouyn-Noranda, Quebec, indicate 
"extensive" near-surface zones "highly" enriched in gold, platinum and 
palladium were found in rocks on the periphery of a sulphide deposit.  
2880: TECHNIGEN PLATINUM CORP IN METALS FIND. Technigen 
Platinum corp said initial results of a 13-hole drilling program on its R.M. 
Nicel platinum property in Rouyn-Noranda, Quebec, indicate extensive 
near-surface zones highly enriched in gold, platinum and palladium. The 
metals were found in rocks on the periphery of a sulphide deposit.  
Table 3: MicroF (upper half) and MacroF (lower half). 
Collection Model All docs. S<1.0 S<0.8 S<0.6 
VSM 0.4383 0.4412 0.4494 0.4504 FJU CTC 
BM11 0.4605 0.4679 0.4787 0.4788 
VSM 0.8192 0.8170 0.8161 0.8156 Reuters-
21578 BM11 0.8240 0.8253 0.8247 0.8232 
VSM 0.2881 0.2916 0.2844 0.2844 FJU CTC 
BM11 0.3177 0.3236 0.3182 0.3080 
VSM 0.3681 0.3676 0.3603 0.3428 Reuters-
21578 BM11 0.4211 0.4206 0.4072 0.3823 
5. Acknowledgments 
This work is partly supported by NSC 92-2213-E-030-017-. 
6. References 
[1] Dmitry V. Khmelev and William J. Teahan,  “A Repetition 
Based Measure for Verification of Text Collections and for 
Text Categorization,” ACM SIGIR, 2003, pp.104-110. 
[2] WebGenie 3.23, http://www.webgenie.com.tw 
[3] Amit Singhal, Gerard Salton and Chris Buckley, “Length 
Normalization in Degraded Text Collections” Symp. on 
Document Analysis and Info. Retr., 1996, pp. 149-162. 
[4] S. E. Robertson and S. Walker, “Some Simple Effective 
Approximations to the 2-Poisson Model for Probabilistic 
Weighted Retrieval,” Proc. of ACM SIGIR, 1992, pp.42-49. 
557
表 Y04 
管是研究論文或是報告最新結果的壁報論文，每一篇幾乎都是結構完整嚴密的作品，從
現象的觀察、理論或方法的推演、實驗的設計、到結果的分析與解釋等都相當完整。此
現象也反應了一種訊息：對於這個領域的新進研究者，必須要有更大的耐心，對所從事
的研究作廣泛、深入的探討，僅提出新的技術並不足夠，還要將解決方案作徹底的驗證、
並與先前的相關研究做比較，分析得失原因，才有較好的機會在此種會議中發表。 
過去 30多年來，資訊檢索在計算機科學領域中極不受重視，研究人員相當稀少，
研究資源也極端匱乏。一直到近十年來，數位環境的改變，政府、業界才有較多的人力、
資源投入。較明顯的現象是美國的 NIST官方單位支助了十一、二年的大型資訊檢索評
比（TREC：Text REtrieval Conference），日本 NII也支助了類似 TREC的 NTCIR資訊檢
索評比。產業界則因全球資訊網的興起，而出現了較多、較大規模的資訊檢索廠商與服
務。這些轉變，終於吸引了計算機科學界有較多的人逐漸投入相關的研究。然而資訊檢
索領域在過去遭受忽視的慘澹時期並沒有氣餒潰散，反而發展出以實驗驗證、成效評
估、使用者互動參與為主軸的研究風格，為資訊檢索立下了一個堅實的學術研究平台。
以往計算機科學著重在技術創新，解決有明確解答的問題，如資料的精確儲存與取用。
但現今電腦要解的問題，大多沒有精確的解答，如「相關」資料的取得。電腦再也無法
精確得知或得出人們想要的「相關」資料。在這種情形下，資訊檢索領域立下的研究要
求，便非常適合學術的有效進展，也就是說，創新的技術，如果沒有經歷嚴謹的驗證評
估與比較，根本不被接受。 
以評估驗證來導引創新技術的發展，而非以創新技術來導引研究發展的方向，可以
免除學術上各說各話的紛擾，節約研究資源的無謂浪費。但此策略也有抑制創意研究的
遺珠之憾。例如 google的發明人其最初的論文，創意雖佳，但成效評估做得很粗糟，看
起來就不會被 ACM SIGIR會議接受，然而目前 google是最佳的網頁檢索引擎之一，使
用者的比例最高。因此，有人問資訊檢索大師 Croft教授，何不擴大 ACM SIGIR會議接
受的廣度等相關問題，但 Croft教授則堅持嚴謹原則，希望 ACM SIGIR維持其一貫的聲
譽。這應該會讓一些不錯的研究，往WWW、CKIM、ICML等其他相關的會議流走。
不過，誠如前面報告的數據，今年 ACM SIGIR 會議的投稿篇數，創歷年新高，似乎 SIGIR
的堅持，並沒有影響多數人的投稿意願。 
  
三、建議 
ACM SIGIR的研究論文審查嚴格，接受率低，即便是很好的論文，可能由於相同
主題的優秀論文超過一個場次的容量而有遺珠之憾，因此很難入選，但不去參加這樣的
盛會，無法現場觀摩並與頂尖的研究人員對話，殊為可惜。對校內的研究人員而言，一
個簡易的策略是參加其壁報論文的投稿，只要品質優秀，被接受的機率自然增高。多接
觸這樣的場合，深入瞭解其特性後，將有助於爾後研究論文的投稿與通過。筆者 1998
年即投稿一篇研究論文，被評審認為重要性夠高，但寫法、表達還不夠成熟而直接改接
納為一篇較精簡的壁報論文，有此經驗後 1999年的投稿才順利通過另一篇完整的研究
論文。 
不管是研究或精簡的論文，持續投稿這個會議相當重要，一方面保持參與國際盛會
的機會，一方面繼續接受嚴格的評審，使自己做得論文獲得客觀指正的機會，從而不斷
提升個人的研究能力與視野。 
其實近幾年來國內的重要學者都體會到，在重要的國際會議上發表論文，跟在重要
的國際期刊上發表論文，同樣重要，因為能在頂尖的學者前發表演說，或現場接受提問、
指正，對個人而言收穫極大，對本校論文的宣傳以及將來的引用上也同樣有其效果。因
此目前國科會以及本校較注重期刊論文而輕視會議論文的情形應當要有所改善。（當然
這中間的原因可能來自於 ISI做出的論文引用統計 SCI及 SSCI資料，只根據期刊論文
而沒有包含會議論文所致） 
