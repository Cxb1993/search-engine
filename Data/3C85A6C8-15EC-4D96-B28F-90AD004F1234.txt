   
  
應用於監控系統之特徵擷取與辨識演算法之開發 
Development of Features Extraction and Recognition 
 Algorithm on Security System 
 
計畫編號：NSC94-2221-E-606-031 
執行期限：95 年 08 月 01 日至 96 年 07 月 31 日 
計畫主持人: 郝樹聲 副教授 
計畫參與人員：胡榮富、許志彬、許世賢 
計畫執行單位: 國防大學理工學院電機電子工程學系 
桃園大溪鎮 335 員樹林三元一街 190 號 
電話：03-3800301 分機 371，傳真：03-3801407 
 
E-mail: haoshu@ccit.edu.tw
摘要—本計畫執行迄今完畢後，以一年的時間發展可運用於安全監控系統的特徵擷取與
辨識之演算法，本計畫執行完畢後所完成的項目如下，包括軟硬體設備的獲得與安裝，雛
型系統的建立及其他相關軟體的開發，以及相關辨識與擷取演算法理論的發展，本年度所
完成的重要工作項目為，建立紅外線、熱影像與可見光影像等相關之臉部資料庫、現有辨
識與擷取理論之改進、各種分類器之設計、發展並改善系統模擬控制視窗軟體、最後並完
成以紅外線/可見光IP攝影機為基礎之影像擷取與入侵偵測雛型系統的整合測試。本系統完
成後將具備以下的功能：入侵偵測與預警顯示、臉部特徵擷取、辨識與比對、可見光、熱
影像與紅外線特徵資料庫之建立，資料庫搜尋與特徵比對法則，相關視窗模擬與控制軟體
等，本計畫執行期間，其中的部份成果並且發表於 2007 年於日本四國德島所舉辦的第 15
屆IEEE非線性動態電子系統國際研討會(15th IEEE International Workshop on Nonlinear 
Dynamics of Electronic Systems 2007 , NDES 2007)的論文集中。除了上述的成果以外，並且
指導兩位碩士學生完成畢業論文，對於訓練國內產學界相關人才與相關產業技術的發展有
其顯著的成果。 
 
Abstract—The main tasks that we have finished during this project year include feature 
extraction and recognition algorithms, software and hardware development and construction, 
infrared, thermal and visible facial database construction, windows application interface(API) 
software development and face extraction and intrusion alarm system construction. The main 
algorithms about feature extraction and classification are keep modifying and developing while 
executing this project. The proposed project items have been achieved by the end of this project. 
Part of the results have been submitted to and published in the conference NDES2007 held in 
Japan, July 23-26, 2007. Two master theses related to this project have been finished after this 
project.  
 
 
關鍵詞：特徵擷取、特徵辨識、特徵描述、臉部資料庫、安全監控系統、統計分析 
 
 
Keywords: Feature Extraction, Feature Recognition, Feature Description, Facial Database, 
Security System, Statistical Analysis 
   
可見光：
初始畫面
位移偵測
產生之畫面
儲存畫面
test
 
熱影像資料庫
ing set
 
 
 
 
 
 
 
 
 
 
 
 
 
圖四、攝影機擷取影像的功能畫面 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
圖五、入侵偵測之畫面 
 
 
 
 
 
 
 
 
 
 
 
 
 
圖六、入侵偵測目標(可見光) 
 
(b)我們所採用的資料庫可分自建與國外
學術單位現有的資料庫，資料庫本身有可分
可見光、紅外線與熱影像三種類型。 
可見光與紅外線人臉資料庫
 
 
 
 
 
 
 
 
 
 
 
 
 
圖七、可見光、紅外線影像 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
圖八、熱影像 
可見光、紅外線如圖七所示而熱影像如
圖八所示： 
 
(c)大部份的模擬影像都需要加以從事前
處理的部份，我們的前處理步驟有包含形態
學(Morphology)的二值化(Binarizing)、區域
填補(Filling)、連通成分抽取、浸蝕(Erosion)
及膨脹(Dilation)等方法，這些基本的影像處
理方法我們將整合至視窗模擬軟體中以方
便實驗及應用。 
(d)視窗模擬軟體已初步建構完成，功能
包含各種基本的影像格式轉換、影像前處
理、模糊理論(FCM)與主值轉換(PCT)軟體
等。圖九所示為 PCT 視窗模擬的方塊圖。
圖十所示為 FCM 視窗模擬的方塊圖。 
 
 
 
 
 
 
 
 
 
圖九、PCT 視窗模擬軟體的方塊圖 
 
 
 
 
 
 
 
圖十、FCM 視窗模擬軟體的方塊圖 
,, ,( )(
i j i
T
i i j i i j
∈
= − −∑
x X
S x x x )ix  (13) 
   
其中
,
,
1
i j i
i i
iN ∈
= ∑
x X
x x j  (14) 
群內散佈矩陣 W 是所有的共變異矩陣的總和， iS 是第 個群組共變異的矩陣，其中
S
i
C為總群組數。 iX 是代表第 i 個群組，而
i 為第 i 群組的第 j 張影像， X i 是同一群組所有影像的平均值， iN 為第 i 個類別的影像數目。類別間的散度矩陣 (Between-Class 
Scatter Matrix) B ：是藉由不同類別的平均值影像減去全部影像的平均值後，再計算共
變異矩陣的總和，S 表示為 
x
S
B
1
( )( )
C
T
B i i i
i=
= − −∑S N x x x x  (15) 
,
1 1
1 iNC
i j
i jTN = =
= ∑∑x x  (16) 
其中 i 是群組影像的數量， T 是所有影像的數量，
N N
i 是第 i 個群組裡影像的平均值如
(16)式，而
x
i 是所有影像的平均值， 為總群組數。二維線性鑑別分析法主要的概念是
找出轉換前後類別內及類別間散度矩陣和
轉換矩陣 1 2 d 的關係，來縮小轉換後同一類別內特徵參數與該群組中心點
的距離，並拉大不同類別間的差距，藉由第
j 張原始影像
x
,..., ]=X x x x
C
[ ,
jA 和投影向量 運算，就可把原始影像投影到新的子空間
X
jY 。投射效果的好壞可藉由F 值來判斷，也就是要讓轉換
後群組內散佈矩陣的行列式值縮小，並同時
拉大群組間散佈矩陣的行列式值，F 值越大
代表投射效果越好，方能有較好的識別能
力。也就是計算S SW B 矩陣，這個矩陣經特徵分解後所求得之特徵向量組成之矩陣，將
每個影像交由基底向量投影到新的空間，如
此則可獲得對應的最佳分類特徵。 
1− 
(S ) (X S X)(X)
(X S X)(S )
T
B
T
WW
tr trF
trtr
= = B  (17) 
X 為最佳的投射軸，也就是有最大的 值。 F
 
(6) 二維主值分析法： 
二維主值分析法(2DPCA)中，就是要求
得 最 佳 全 域 散 佈 矩 陣 (Total Scatter 
Matrix)Aopt，定義G= E[(X-EX)T(X-EX)]為影
像共變異矩陣(image covariance matrix )，其
維度為nxn。假設有M張訓練用影像資料，
每 一 張 影 像 維 度 為 mxn 的 Xk 
(k=1,2,…,M) ，其平均影像為 
 
1X k
kM
= ∑X  (18) 
影像變異矩陣 G 可表示為 
T
1
1 (X X) (X X)
M
k k
kM =
= −∑G −  (19) 
表達最佳全域散佈矩陣(Total Scatter 
Matrix)Aopt 是 一 組 正 交 歸 一 特 徵 向 量
(A1,A2,...,Ad)所組成，即Aopt =[A1,A2,...,Ad]，
其做法如圖十一所示 
 
 
 
 
 
 
 
 
 
 
圖十一、2DPCA 模擬示意圖 
 
(7) 特徵比對：我們利用各種比對指標
來判斷特徵的相似性。這些比對指標有， 
city block:  
∑
=
−= N iiL
1i
1 )( BABA,  (20) 
Euclidean distance: 
∑ −
=
= N iiL
1i
2
2 )()( BABA,  (21) 
Covariance 
B
B
A
ABA, •=)(cov  (22) 
Mahalanobis distance 
∑
=
−= N iiiMah
1i
)( CBABA,  (23) 
λ ii
1=C    i=1,…,N (24) 
Correlation 
∑
=
−−= N iiC
1i BA
BA ))(()orr( σσ
μμ BABA,  (25) 
利用上述的幾種比對指標我們可以針對各
種辨識演算法加以評估其錯誤率。 
 
 
四、    結果與討論 
 
 綜合本計畫的研究成果除了建構一套
可見光/紅外線取像與入侵偵測控制攝影系
統之外，也發了一套視窗模擬系統，未來本
實驗室發展的各項模擬與控制軟體將可以
模組化的方式整合至此一視窗環境當中，至
於核心的模擬架構，就如上節所舉的幾項演
算法為例，經由各項測試改進之後均已經獲
致不錯的模擬結果，例如以 ORL 資料庫(如
圖十二所示)所從事的模擬為例，利用 PCA
及 2DPCA 作法分別計算出投影特徵向量，
整個計算所發的時間如表一所示，PCA 所得
到投影特徵向量維度為 200x200，所花費時
間為 5.72 秒，而 2DPCA 所得到投影特徵向
量維度為 92x200，所花費時間為 7.25 秒，
發現 PCA 及 2DPCA 所花費時間相差不到 2
秒，其值可視為相差無幾。所求得的
EigenFace 如圖十三所示， 
 
 
參考文獻 
[1] A. K. Jain, A. Ross and S. Prabhaker, ”An 
Introduction to Biometric Recognition” 
IEEE Trans. on Circuits and Systems for 
Video Technology, vol. 14, no. 1, pp. 4-20, 
January 2004. 
[2] Phillips, P.J.; Martin, A.; Wilson, C.L.; 
Przybocki, M.; ＂ An Introduction 
Evaluating Biometric Systems ＂
Computer , vol. 33, Issue 2, pp. 56 – 
63,Feb. 2000 
[3] J. Yang, D. Zhang, A.F. Frangi, and J.Y. 
Yang, “Two-dimensional PCA: A New 
Approach to Appearance-based Face 
Representation and Recognition.”. IEEE 
Trans. on Pattern Analysis and Machine 
Intelligence, vol. 26, no.1, pp. 131– 137, 
2004. 
[4] A.M. Martinez and A.C. Kak,”PCA versus 
LDA”, IEEE Trans. on Pattern Analysis 
and Machine Intelligence, vol. 23, No. 2, 
pp. 228-233, 2001 
[5] Kith, K.; Zahzah, E” Discrete Wavelet 
Descriptor for 2D Shape” . Third 
International Conference on Image and 
Graphics, pp. 76 – 79, 18-20 Dec. 2004 
[6] Qing Chen; Emil Petriu; Xiaoli Yang, ”A 
comparative study of Fourier descriptors 
and Hu's seven moment invariants for 
image recognition”; , 2004. Canadian 
Conference on Electrical and Computer 
Engineering , vol.1,pp. 103 – 106, 2-5 
May 2004 
[7] M. K. Hu, ”Visual Pattern Recognition by 
Moment Invariants,” IRE Transactions on 
Information Theory, pp.179-187,1962 
[8] M. Turk, A. “Pentland, Eigenfaces for 
Recognition,” Journal of Cognitive 
Neurosicenc , vol. 3, no. 1, pp. 71-86,1991 
[9]許世賢,＂ 影像特徵擷取與搜索比對法
之研究,＂國防大學中正理工學院電子
工程研究所碩士論文，2007 年 6 月 
[10]許志彬” 船艦辨識法之研究,” 國防大
學中正理工學院電子工程研究所碩士論
文，2007 年 6 月 
[12] Shu-Sheng Hao, Chih-Bin Hsu and 
Rong-Fuh Hwu,” Objects Extraction by 
Nonlinear Methods”, 15th IEEE 
International Workshop on Nonlinear 
Dynamics of Electronic Systems 2007 
(NDES 2007), July 23-26, 2007, 
Tokushima, Japan 
 
附件: 
一. 出席 15th IEEE International Workshop 
on Nonlinear Dynamics of Electronic 
Systems 2007 (NDES 2007)心得報告 
二. 第 15 屆IEEE非線性動態電子系統國際
研討會 15th IEEE International Workshop 
on Nonlinear Dynamics of Electronic 
Systems 2007 (NDES 2007)張貼投影片 
三. NDES2007 發表論文 
   
15th IEEE International Workshop on Nonlinear Dynamics of 
Electronic Systems 2007 (NDES 2007) 
心  得 報 告 
報告人: 郝樹聲 
服務機關名稱及名稱: 國防大學理工學院電機電子系副教授 
計畫類別:個別型計畫 
計畫執行期限: 95 年 8 月 1 日至 96 年 7 月 31 日 
計畫題目: 應用於監控系統之特徵擷取與辨識演算法之開發 
計畫編號: 國科會專題研究計畫 95-2221-E-606-031 
         ﹝本校更名前舊編號 NSC 95-2221-E-014-015﹞ 
投稿題目: 
     中文: 利用非線性法擷取物件 
     英文: Objects Extraction by Nonlinear Methods 
會議時間:July 23 – July 26，2007 
會議地點:日本四國德島 Shikoku University Community Plaza, Tokushima, Japan 
會議名稱:  
中文:第 15 屆 IEEE 非線性動態電子系統國際研討會 
英文:15th IEEE International Workshop on Nonlinear Dynamics of Electronic 
Systems 2007 (NDES 2007) 
會議活動照片: 
     
 2
報告內容 
一、會議主題: 
 第 15 屆 IEEE 非線性動態電子系統國際研討會(NDES2007)於 2007 年 7 月
23 日至 7 月 26 日於日本四國德島舉行，會議地點位於德島市中心的四國大學社
區廣場(Shikoku University Community Plaza)大樓舉行。這個研討會的目的乃是為
了集合世界各地的專家學者針對非線性動態系統與其應用廣泛的交換意見。因為
非線性系統本身廣泛的出現在各種領域之中，例如 Physics, Biology, Economics, 
Ecology, Electronics 與 Computer Science。本次會議將針對這些領域的嶄新發展
從事意見的交流，除此之外也針對傳統的 Nonlinear Circuits, Data Analysis 與認知
科學上的應用等主題互相交換意見。本研討會邀請了來自俄羅斯、瑞士、法國與
日本等國的專家學者與會並且發表重要的論文。共有 37 篇口頭報告論文與 39
篇海報張貼論文。 
 
大會的主要議程列舉如下: 
Date,Time 7 月 23
日（一） 
7 月 24 日（二） 7 月 25 日
（三） 
7 月 26 日（四） 
Simulation Neural 
Oscillators 
Synchronization 
Coupled Oscillators Nonlinear 
Circuits 
Bio/medicals 上午 
 
Guest Talk Guest Talk Guest Talk 
Poster  Poster 
Commun- 
ications 
Nonlinear
Dynamics
Excursion Neural 
Networks 
Data 
Analysis
下午 
Plenary  
Talks 
   
 
二、心得: 
 本人出席此一國際會議發表了一篇利用非線性方法（模糊分類法）來擷取影
像中的物件，並且將此一方法與主值轉換法所模擬出來的結果互相比較，在資料
的呈現與模擬過程中我們結合視窗軟體來加以撰寫模擬程式，大大的簡化了模擬
的過程並且增加了結果的易讀。希望此一方法可以有效的應用在相關的影像視訊
產品中，參加會議過程中與其他專家學者廣泛的交換意見並且觀摩他人發表的文
章與研究方法。整理參加此一會議所得到的幾項較重要的心得如下： 
 1.會議期間與其他各國的專家學者廣泛的交換新知，從事意見的交流，從中
獲取了不少的經驗，這是參加國際研討會最顯著的效益。 
 2.有幾位世界著名的學者被大會安排做專題演講，聆聽這些大師的演講有讓
人如沐春風耳目一新的感覺，並且了解大師級人物從事研究的態度與風範。 
 4
OUTLINE
I. Simulation Function Block Diagram
II. Texture Analysis
III.Morphology Operations
IV. Fuzzy C-Means (FCM)
V. Comparison with Other Method
VI. Windows Application Program Interface (API)
VII.Conclusions
 
I. Simulation Function Block Diagram
Block
Variance 
Ship
Color 
Image Gray
Level
Image
Binary 
Image 
Nonlinear
Filters
Object
Mask
1st Stage
Object
FCM/PCT/
Weighting FCM
Desired
Object
Logical
Operations
R,G,B color planes
Mouse 
Click
Texture Analysis
Human
Color
Image
Complex Background Elimination Loop
 
 6
IV. Fuzzy C-Means
( ) ( )∑ ∑
= =
⋅= N
q
c
j
jq
m
jqm distuJ
1 1
2 ,;, vxXVU
Objective Function
( ) ( ) 12
1
,
k
q j q jdist dist x vα α
α=
⎡ ⎤= = −⎢ ⎥⎣ ⎦∑x v
{ }NxxxX ,,, 21 …=Unlabeled Data
{ }cvvvV ,,, 21 …=Unknown Prototype
Belonging Matrix { }mjqu=U 10 ≤≤ mjqu
In order to minimize the cost of following objective function.
 
IV. Fuzzy C-Means
( ) ( )∑ ∑
= =
⋅= N
q
c
j
jq
m
jqm distuJ
1 1
2 ,;, vxXVU
Objective Function
( ) ( ) 12
1
,
k
q j q jdist dist x vα α
α=
⎡ ⎤= = −⎢ ⎥⎣ ⎦∑x v
{ }NxxxX ,,, 21 …=Unlabeled Data
{ }cvvvV ,,, 21 …=Unknown Prototype
Belonging Matrix { }mjqu=U 10 ≤≤ mjqu
In order to minimize the cost of following objective function.
 
 8
After Weighting Method 1 FCM 
 
Morphology Operations After Weighting Method 1 FCM
 
 10
PCT Results
 
Original Images
Signal Plane                      Noise Plane 1                 Noise Plane 2
R1
R2
R1R2
 
 12
VII. Conclusions
I. FCM can be used to segment the desired objects 
from the RGB color image
II.   Weighting FCM can improve the extraction results
III. The FCM/wFCM algorithms have more global extraction
effect compared to  the PCT algorithm. 
IV.  The Morphology Operations are helpful to obtain a 
clear mask. It is useful in  pre-processing procedures.
V. The window application  program interface(API) is
user-friendly and efficient to simulate.
VI.  How to extract the desired objects from a complex
background image is a challenge.
 
附錄二：會議論文 
 14
( )
1
2
2
1 1
1
i j
m n
mn = =⎣ ⎦
1 1
1 m n
n ij n
n ij
i j
x m
m x
mn
μ
= =
⎡ ⎤= −⎢ ⎥
=
∑∑
∑∑
+
=
( )
0
,   1,2,3,k= ⊕ ∩ =B A …1
z,    initial setting
k k
X
X X
l( ){ }|
z
z φ⊕ = ∩ ≠B A
( ) ( )2
1 1
, ; ,
N c
m
m jq q j
q j
dist
= =
= ⋅∑∑U V X x v
A B
J u
 
 
( )
1
2
2
1 1
1 1
1
1
m n
n ij n
i j
m n
n ij
i j
x m
mn
m x
mn
μ
= =
= =
⎡ ⎤= −⎢ ⎥⎣ ⎦
=
∑∑
∑∑
12.81512.50412.0426.096356.73616.3724.44824.916Variance
161514131211109Region
46.66611.3046.98814.5724.20474.74173.30263.2616Variance
87654321Region
Block 8
Block 12
 
 
 
 
 
 
 
 
(a) (b)
(c) (d)
 
 
 
 
Fig.2 Texture Analysis of the battleship  
 
 
 
                                       (1) 
 
 
where nμ  and is the variance and mean of the 
n
nm
th block. The block size is m by n. The threshold 
setting is according to the variances. After scanning 
whole image, we keep the larger variance blocks. 
The white areas shown in Fig. 3(a) are the blocks 
with larger variance.  
 
 
 
 
 
 
          (a)               (b) 
Fig.3  (a) the larger variance region after masking (b) 
after binarized and region connected 
IV. MORPHOLOGY OPERATIONS 
The image after threshold is binarized and 
processed by the morphological filters. We use 
region connected method to fill the holes of the 
image. Assume that the image is A and the 
structure element is B, we want to connect the 
sub-image P in A. Assuming z is a point in P, the 
process can be computed as Eq. (2): 
 
 
                                   (2) 
 
where ⊕ is the dilation operation and ∩ is the 
intersection of  two sets. Iterating the procedures, 
it stops at 1k k−=X X . The binarized and connected 
result of Fig. 3(a) is shown in Fig. 3(b). 
We can also use the erosion and dilation to trim 
the object. The operations can be described as in 
Eq.(3) and (4): 
A\ B ( ){ }| zz= ⊆B A                     (3) 
 
              (4)                        
  
where is the reflection of B. The simulation 
procedures can be shown as in Fig. 4. After 
maximum connection operation the noise in Fig. 
4(a) is disappeared as shown in Fig. 4(b). The 
erosion and dilation operation results are shown in 
Fig. 4(b) and (c). Applying the mask, we can 
extract the ship body as shown in Fig 4(d). 
Bˆ
 
 
 
 
 
 
 
 
 
 
 
 
Fig. 4. Object extracted by morphology operators (a) 
maximum connected (b) erosion (c) dilation (d) ship 
body after masked 
V. FUZZY C-MEANS (FCM) 
Regardless of the image is a human or a 
battleship, we can use the fuzzy C-means (FCM) to 
extract the desired objects. The algorithm of FCM 
basically is a nonlinear classification method. We 
take the R, G and B elements in three color planes 
as our classification features described as in Eq. (5) 
 ( ), ,r g bx x x=X
                                     (6) 
                       (5) 
Iterative computing the belongings of each feature, 
we can finally assign each feature to its class. The 
goal of FCM is to minimize the cost of the 
objective function described in Eq.(6) 
 
 
  
 
where N is the sample number, c is the class 
 
 
Original
FCM                           Method 1 WFCM                 Method 2 WFCM
 
 
 
 
 
 
 
 
 
 
Fig. 8. the morphology results of Fig. 8. 
 
 
 
 
 
 
 
 
 
 
 
 
 
Fig. 9. Results of wFCM1 and wFCM2  
 
For comparison, we also extract the objects with 
PCT algorithm [9]. The algorithm transfers the 
original image to eigenspace constructed by the 
covariance matrix according the image data. The 
algorithm can be described as follows: 
T=y A x                             (14) 
where A is the matrix formed by the eigenvectors 
and x is the original data. Fig. 10 shows the PCT 
results of AR database. 
 
 
 
 
 
 
 
 
 
 
 
 
 
FIG. 10. PCT results of AR database. 
The windows application program interface (API) 
is also devised and shown in Fig. 11. 
 
 
 
 
 
 
 
 
 
 
FIG. 11. Window API 
VI. CONCLUSIONS 
The proposed wFCM combined with nonlinear 
spatial filters can give us an effective way to 
segment the desired color objects. Extracting the 
ship body is more difficult because there are 
complex backgrounds, and the colors of battleships 
are very similar to the color of sky and sea. With 
wFCM, we can easily extract the desired objects 
from the head-and-shoulder images with simple 
background in uneven illumination and occlusions. 
After inspecting PCT results, we found that the 
segmentation using wFCM is has more robust 
segmentation capability than using PCT. The 
window API is also created to perform the 
simulation more user friendly.  
REFERENCES 
[1] B. S. Manjunath, et. al.,”Color and texture descriptors,” 
IEEE trans. on circuits and systems for video technology, 
vol.11, no. 6, June 2001, pp. 703-715 
[2] J. Bormans, et. al.,”MPEG21-The 21st century multimedia 
framework,” IEEE Signal Processing Magazine, march 
2003, pp. 53-62 
[3] L. Chiariglione,” Impacts of MPEG standards on 
multimedia industry,” Proceedings of the IEEE, vol. 86, no. 
6, June 1998, pp. 1222-1227 
[4] J.F. Yang S.S. Hao and P.C. Chung,” Color object 
segmentation using fuzzy C-means with eigen-subspace 
projections”, vol. 82 Signal Processing, 2002, pp.461-472 
[5] F. Höppner,et, al., “ Fuzzy Cluster Analysis,” John Wiley & 
Sons Ltd., 1999 
[6] R. Johnson and P. Kuby, “Elementary Statistics, 8th ed.,” 
Duxbury, 2000 
[7] R. C. Gonzalez and R. E. Woods, Digital Image Processing, 
pp.655-659, 2nd Ed. Prentice-Hall, Inc. 2002 
[8] P. Salembier, et. al., “Morphological operators for image 
and video compression,” IEEE trans. on image processing, 
vol. 6, no. 6, June 1996, pp. 881-898 
[9] H. Moon and  P. J. Phillips, ”Computational and 
Performance Aspects of PCA-based Face Recognition 
Algorithms”, Perception, vol. 30, pp. 303-321, 2001 
15th IEEE International Workshop on Nonlinear Dynamics of 
Electronic Systems 2007 (NDES 2007) 
心  得 報 告 
報告人: 郝樹聲 
服務機關名稱及名稱: 國防大學理工學院電機電子系副教授 
計畫類別:個別型計畫 
計畫執行期限: 95 年 8 月 1 日至 96 年 7 月 31 日 
計畫題目: 應用於監控系統之特徵擷取與辨識演算法之開發 
計畫編號: 國科會專題研究計畫 95-2221-E-606-031 
         ﹝本校更名前舊編號 NSC 95-2221-E-014-015﹞ 
投稿題目: 
     中文: 利用非線性法擷取物件 
     英文: Objects Extraction by Nonlinear Methods 
會議時間:July 23 – July 26，2007 
會議地點:日本四國德島 Shikoku University Community Plaza, Tokushima, Japan 
會議名稱:  
中文:第 15 屆 IEEE 非線性動態電子系統國際研討會 
英文:15th IEEE International Workshop on Nonlinear Dynamics of Electronic 
Systems 2007 (NDES 2007) 
會議活動照片: 
     
 2
報告內容 
一、會議主題: 
 第 15 屆 IEEE 非線性動態電子系統國際研討會(NDES2007)於 2007 年 7 月
23 日至 7 月 26 日於日本四國德島舉行，會議地點位於德島市中心的四國大學社
區廣場(Shikoku University Community Plaza)大樓舉行。這個研討會的目的乃是為
了集合世界各地的專家學者針對非線性動態系統與其應用廣泛的交換意見。因為
非線性系統本身廣泛的出現在各種領域之中，例如 Physics, Biology, Economics, 
Ecology, Electronics 與 Computer Science。本次會議將針對這些領域的嶄新發展
從事意見的交流，除此之外也針對傳統的 Nonlinear Circuits, Data Analysis 與認知
科學上的應用等主題互相交換意見。本研討會邀請了來自俄羅斯、瑞士、法國與
日本等國的專家學者與會並且發表重要的論文。共有 37 篇口頭報告論文與 39
篇海報張貼論文。 
 
大會的主要議程列舉如下: 
Date,Time 7 月 23
日（一） 
7 月 24 日（二） 7 月 25 日
（三） 
7 月 26 日（四） 
Simulation Neural 
Oscillators 
Synchronization 
Coupled Oscillators Nonlinear 
Circuits 
Bio/medicals 上午 
 
Guest Talk Guest Talk Guest Talk 
Poster  Poster 
Commun- 
ications 
Nonlinear
Dynamics
Excursion Neural 
Networks 
Data 
Analysis
下午 
Plenary  
Talks 
   
 
二、心得: 
 本人出席此一國際會議發表了一篇利用非線性方法（模糊分類法）來擷取影
像中的物件，並且將此一方法與主值轉換法所模擬出來的結果互相比較，在資料
的呈現與模擬過程中我們結合視窗軟體來加以撰寫模擬程式，大大的簡化了模擬
的過程並且增加了結果的易讀。希望此一方法可以有效的應用在相關的影像視訊
產品中，參加會議過程中與其他專家學者廣泛的交換意見並且觀摩他人發表的文
章與研究方法。整理參加此一會議所得到的幾項較重要的心得如下： 
 1.會議期間與其他各國的專家學者廣泛的交換新知，從事意見的交流，從中
獲取了不少的經驗，這是參加國際研討會最顯著的效益。 
 2.有幾位世界著名的學者被大會安排做專題演講，聆聽這些大師的演講有讓
人如沐春風耳目一新的感覺，並且了解大師級人物從事研究的態度與風範。 
 4
OUTLINE
I. Simulation Function Block Diagram
II. Texture Analysis
III.Morphology Operations
IV. Fuzzy C-Means (FCM)
V. Comparison with Other Method
VI. Windows Application Program Interface (API)
VII.Conclusions
 
I. Simulation Function Block Diagram
Block
Variance 
Ship
Color 
Image Gray
Level
Image
Binary 
Image 
Nonlinear
Filters
Object
Mask
1st Stage
Object
FCM/PCT/
Weighting FCM
Desired
Object
Logical
Operations
R,G,B color planes
Mouse 
Click
Texture Analysis
Human
Color
Image
Complex Background Elimination Loop
 
 6
IV. Fuzzy C-Means
( ) ( )∑ ∑
= =
⋅= N
q
c
j
jq
m
jqm distuJ
1 1
2 ,;, vxXVU
Objective Function
( ) ( ) 12
1
,
k
q j q jdist dist x vα α
α=
⎡ ⎤= = −⎢ ⎥⎣ ⎦∑x v
{ }NxxxX ,,, 21 …=Unlabeled Data
{ }cvvvV ,,, 21 …=Unknown Prototype
Belonging Matrix { }mjqu=U 10 ≤≤ mjqu
In order to minimize the cost of following objective function.
 
IV. Fuzzy C-Means
( ) ( )∑ ∑
= =
⋅= N
q
c
j
jq
m
jqm distuJ
1 1
2 ,;, vxXVU
Objective Function
( ) ( ) 12
1
,
k
q j q jdist dist x vα α
α=
⎡ ⎤= = −⎢ ⎥⎣ ⎦∑x v
{ }NxxxX ,,, 21 …=Unlabeled Data
{ }cvvvV ,,, 21 …=Unknown Prototype
Belonging Matrix { }mjqu=U 10 ≤≤ mjqu
In order to minimize the cost of following objective function.
 
 8
After Weighting Method 1 FCM 
 
Morphology Operations After Weighting Method 1 FCM
 
 10
PCT Results
 
Original Images
Signal Plane                      Noise Plane 1                 Noise Plane 2
R1
R2
R1R2
 
 12
VII. Conclusions
I. FCM can be used to segment the desired objects 
from the RGB color image
II.   Weighting FCM can improve the extraction results
III. The FCM/wFCM algorithms have more global extraction
effect compared to  the PCT algorithm. 
IV.  The Morphology Operations are helpful to obtain a 
clear mask. It is useful in  pre-processing procedures.
V. The window application  program interface(API) is
user-friendly and efficient to simulate.
VI.  How to extract the desired objects from a complex
background image is a challenge.
 
附錄二：會議論文 
 14
( )
1
2
2
1 1
1
i j
m n
mn = =⎣ ⎦
1 1
1 m n
n ij n
n ij
i j
x m
m x
mn
μ
= =
⎡ ⎤= −⎢ ⎥
=
∑∑
∑∑
+
=
( )
0
,   1,2,3,k= ⊕ ∩ =B A …1
z,    initial setting
k k
X
X X
l( ){ }|
z
z φ⊕ = ∩ ≠B A
( ) ( )2
1 1
, ; ,
N c
m
m jq q j
q j
dist
= =
= ⋅∑∑U V X x v
A B
J u
 
 
( )
1
2
2
1 1
1 1
1
1
m n
n ij n
i j
m n
n ij
i j
x m
mn
m x
mn
μ
= =
= =
⎡ ⎤= −⎢ ⎥⎣ ⎦
=
∑∑
∑∑
12.81512.50412.0426.096356.73616.3724.44824.916Variance
161514131211109Region
46.66611.3046.98814.5724.20474.74173.30263.2616Variance
87654321Region
Block 8
Block 12
 
 
 
 
 
 
 
 
(a) (b)
(c) (d)
 
 
 
 
Fig.2 Texture Analysis of the battleship  
 
 
 
                                       (1) 
 
 
where nμ  and is the variance and mean of the 
n
nm
th block. The block size is m by n. The threshold 
setting is according to the variances. After scanning 
whole image, we keep the larger variance blocks. 
The white areas shown in Fig. 3(a) are the blocks 
with larger variance.  
 
 
 
 
 
 
          (a)               (b) 
Fig.3  (a) the larger variance region after masking (b) 
after binarized and region connected 
IV. MORPHOLOGY OPERATIONS 
The image after threshold is binarized and 
processed by the morphological filters. We use 
region connected method to fill the holes of the 
image. Assume that the image is A and the 
structure element is B, we want to connect the 
sub-image P in A. Assuming z is a point in P, the 
process can be computed as Eq. (2): 
 
 
                                   (2) 
 
where ⊕ is the dilation operation and ∩ is the 
intersection of  two sets. Iterating the procedures, 
it stops at 1k k−=X X . The binarized and connected 
result of Fig. 3(a) is shown in Fig. 3(b). 
We can also use the erosion and dilation to trim 
the object. The operations can be described as in 
Eq.(3) and (4): 
A\ B ( ){ }| zz= ⊆B A                     (3) 
 
              (4)                        
  
where is the reflection of B. The simulation 
procedures can be shown as in Fig. 4. After 
maximum connection operation the noise in Fig. 
4(a) is disappeared as shown in Fig. 4(b). The 
erosion and dilation operation results are shown in 
Fig. 4(b) and (c). Applying the mask, we can 
extract the ship body as shown in Fig 4(d). 
Bˆ
 
 
 
 
 
 
 
 
 
 
 
 
Fig. 4. Object extracted by morphology operators (a) 
maximum connected (b) erosion (c) dilation (d) ship 
body after masked 
V. FUZZY C-MEANS (FCM) 
Regardless of the image is a human or a 
battleship, we can use the fuzzy C-means (FCM) to 
extract the desired objects. The algorithm of FCM 
basically is a nonlinear classification method. We 
take the R, G and B elements in three color planes 
as our classification features described as in Eq. (5) 
 ( ), ,r g bx x x=X
                                     (6) 
                       (5) 
Iterative computing the belongings of each feature, 
we can finally assign each feature to its class. The 
goal of FCM is to minimize the cost of the 
objective function described in Eq.(6) 
 
 
  
 
where N is the sample number, c is the class 
