 1 
 
行政院國家科學委員會補助專題研究計畫 
□v 成果報告   
□期中進度報告 
 
計算蛋白質體學：蛋白質細胞定位預測及其 
在蛋白質功能分類之應用 
 
計畫類別：□v 個別型計畫   □整合型計畫 
計畫編號：NSC 99-2218-E-038-002- 
執行期間：  99 年 3 月 1 日至 100 年 10 月 31 日 
 
執行機構及系所：台北醫學大學 醫學資訊研究所 
 
計畫主持人：蘇家玉 助理教授 
共同主持人： 
計畫參與人員：張志昇、張至潔和林宜衡 
 
 
 
成果報告類型(依經費核定清單規定繳交)：□v 精簡報告  □完整報告 
 
本計畫除繳交成果報告外，另須繳交以下出國心得報告： 
□赴國外出差或研習心得報告 
□赴大陸地區出差或研習心得報告 
□v 出席國際學術會議心得報告 
□國際合作研究計畫國外研究報告 
 
 
處理方式：除列管計畫及下列情形者外，得立即公開查詢 
            □v 涉及專利或其他智慧財產權，□一年□v 二年後可公開查詢 
 
中   華   民   國 101 年 1 月 30 日 
2 
 
NucPred [1], and NUCLEO [4]. In this project, we propose a method to improve nuclear localization 
prediction based on potential NLSs and NESs generated from our gapped dipeptide analysis.  
3. Challenges 
The prediction of refined PSL presents several challenges. First, the performance of amino acid 
composition-based and sequence homology-based methods might be significantly degraded if homologous 
sequences are not detected. Second, the results of these methods are generally difficult to interpret; therefore, 
it is difficult to determine which biological features should be used to identify specific PSL and why they 
work well for prediction. If the features were biologically interpretable, the resultant knowledge could help in 
designing artificial proteins with the desired properties. Meanwhile, methods that integrate various features 
could suffer from the problem of low coverage in high-throughput proteomic analyses due to the lack of 
information to characterize unknown proteins. Finally, many PSL methods are implemented on redundant 
training sets, which might lead to overestimation of the predictive performance. Thus, the performance would 
be significantly lower if redundant sequences were meticulously removed. 
4. Goals 
In this project, we formulate the refined PSL prediction as a document classification problem based on 
PSLDoc (Protein Subcellular Localization prediction based on Document classification) [5]. The document 
classification problem is to assign an electronic document to one or more categories based on its contents. A 
protein sequence can be considered as the content of a document, and localization sites are considered as 
categories. To predict the localization site(s) of a protein is equivalent to predicting the category (e.g., sports, 
politics, etc.) of a document (e.g., a piece of news). Given a large number of documents, document 
classification is usually tackled by the following three steps. First, documents have to be transformed into 
feature vectors in which each distinct term corresponds to a feature. The value of a feature in a vector 
represents the weight of a term in a document. Another set of documents with known categories is used as a 
training set. Second, because of high-dimensional feature spaces, feature reduction is necessary before 
applying machine learning methods, to improve generalization accuracy and to avoid overfitting [5]. The first 
two steps could be considered as feature representation and feature reduction, respectively. Finally, these 
reduced feature vectors are used to perform the category assignment automatically.  
II. Methods 
To solve nuclear localization prediction problem, we propose a method in which proteins are represented by 
gapped dipeptides weighted by evolutionary information and then probabilistic latent semantic analysis is 
applied for feature reduction. Next, the feature representation, feature weighting, feature reduction, system 
architecture, and evaluation measures are shown in the following sections.  
4 
 
residues [11]. In a standard PSSM profile, the log-likelihood at each position is calculated based on an 
assumption that each position is independent from the others. Inspired by the consideration of adjacent pixels 
used in the spatial domain method from the research field of image processing, a new encoding scheme was 
proposed to consider the dependency among surrounding neighbors. We use a sliding window of size w to 
incorporate the evolutionary information from upstream and downstream residues. In the construction of a 
smoothed PSSM, each row vector of a residue αi is represented and smoothed by the summation of ws 
surrounding row vectors (Vsmoothed_i = Vi-(ws-1)/2 + … + Vi + … + Vi+(ws-1)/2 ). For the N-terminal and 
C-terminal of a protein, (w-1)/2 ZERO vectors, are appended to the hand or tail of a smoothed PSSM profile. 
Using the smoothed PSSM encoding scheme, the feature vector of a residue αi is represented by 
(Vsmoothed_i-(w-1)/2, …, Vsmoothed_i, …, Vsmoothed_i+(w-1)/2). Here, we apply different smoothing window sizes from 
3 to 11 with a step as 2 (i.e., ws = 3, 5, …, 11).  
3) TFPSSM weighting scheme 
We design a term weighting scheme based on smoothed PSSM, denoted by TFPSSM as follows. Given a 
protein sequence S of length n, any gapped dipeptide XdZ of S has smoothed PSSM entries corresponding to 
gapped dipeptide S(i)dS(i+d+1) for 1 ≦ i ≦ n-(d+1), where S(i) denotes the ith amino acid of S. Take the 
sequence MPLDLYNTLT as an example. From the sequence information, M2D only occurs once. However, 
in view of smoothed PSSM, M2D may occur in the corresponding gapped dipeptides obtained from the 
sequence, i.e., M2D, P2L, L2Y, D2N, L2T, Y2L, N2T. We define the weight of XdZ in S as 



)1(1
),1(),(),(
dni
ZdifXifSXdZW                      (2) 
where f(i,Y) denotes the normalized value of the smoothed PSSM entry at the ith row and the column 
corresponding to amino acid Y. In the above example, the weight of M2D based on smoothed PSSM is given 
by f(1,M) × f(4,D) + f(2,M) × f(5,D)+…+f(7,M) × f(10,D) = 0.99995 × 0.04743 + 0.11920 × 0.00247 +…+ 
0.00669 × 0.26894. 
As mentioned before, each protein is represented by a vector, and each entry of the vector is given by 
TFPSSM of the corresponding gapped dipeptide. Note that the values in each feature vector are normalized 
between (0~1] by dividing the maximum value in the vector.  
3. Feature reduction - probabilistic latent semantic analysis 
1) Probabilistic latent semantic analysis 
Hofmann proposed probabilistic latent semantic analysis (PLSA) based on an aspect model to deal with those 
above disadvantages [12]. The aspect model is a latent variable model for co-occurrence data (i.e., documents 
6 
 
 

 



'
'
),|'(),(
),|(),(
)|(
),'|(),'(
),|(),(
)|(
z w
w
w d
d
dwzPdwW
dwzPdwW
dzP
dwzPdwW
dwzPdwW
zwP
                      (8) 
where parameters P(w|z) and P(z|d) are re-estimated to maximize L. 
3) PLSA model testing 
After training, the estimated P(w|z) parameters are used to estimate P(z|q) for new (test) documents q through 
a folding-in process [12]. In the folding-in process, EM procedure runs in a similar manner to the training 
stage. The E-step is identical but the M-step keeps all the P(w|z) constant and only re-calculates P(z|q). 
Usually, a very small number of iterations of the EM algorithm are sufficient for folding-in process. 
4) Feature reduction by PLSA 
We apply PLSA not only for feature reduction but also for gapped-dipeptides semantic relation extraction. 
Vectors are mapped from the gapped-dipeptides space to the latent semantic space. This will lead to 
improvement in learning performance and efficiency. Though it is not easy to determine an appropriate 
reduced feature size of PLSA, it can be approximated by the reduced feature size of LSA. To determine the 
reduced feature size of LSA, we calculate singular values of LSA and sort them in a decreasing order. Then, 
the reduced feature size of LSA equals to n if the n-th largest singular value is close to zero. 
4. System architecture 
Prediction of nuclear localization proteins can be treated as a multiclass classification problem. For 
multiclass classification, one-versus-rest (1-v-r) SVM model has demonstrated a good classification 
performance [13]. For each class i, we construct a 1-v-r (Ci versus non-Ci) binary classifier. Our prediction 
method consists of several 1-v-r SVM classifiers corresponding to different classes of proteins. The LIBSVM 
[14] package is used in our system, and it can generate probability estimates that are used to determine the 
confidence levels of classifications [15]. For all classifiers, we use Radial Basis Function kernel, and tune the 
cost (c) and gamma (γ) parameters optimized by five-fold cross-validation on the training data set.  
 Here we present a method, PSLNuc, to predict protein nuclear localization based on smoothed 
evolutionary information and PLSA. PSLNuc extracts biological features from gapped-dipeptides of various 
distances, where smoothed evolutionary information from the PSSM is utilized to determine the weighting of 
each gapped-dipeptide. Then, the features are further reduced by PLSA and incorporated as input vectors for 
support vector machine classifiers. The standard PSSM assumes independency between different residues, 
however, this simplifying assumption does not hold. It has been showed that smoothed PSSM encoding 
8 
 
both under- and over-predictions, and takes range from –1 to 1, where MCC = 1 indicates a perfect prediction; 
MCC = 0 indicates a completely random assignment; and MCC = -1 indicates a perfectly reverse correlation.  
III. Experiment Results  
Experiment results shows that our method could improve prediction performance by incorporating smoothed 
PSSM and gapped dipeptide analysis. In addition, our method is able to propose candidate localization 
signals. In this project, we try to further improve the performance using only the localization signals. 
Table 1: Numbers of nuclear and non-nuclear proteins for training and testing. 
  
 Nuclear Non-nuclear 
   
Training 2,842 2,606 
Testing 564 398 
   
Total 3,406 3,004 
  
1. Prediction performance 
1) Data set 
To evaluate the performance of PSLNuc, we utilize a benchmark data set of proteins from Swiss-Prot that 
have been used in previous work [1, 3, 4]. It consists of proteins with experimentally determined 
localizations. In addition, both the nuclear and non-nuclear proteins were redundancy-reduced using 
BlastClust with a 10% identity threshold, so that the remaining sequences have no more than 10% identical 
residues in the aligned regions covering at least 90% of the sequences. Table 1 lists the number of nuclear 
and non-nuclear protein in the data set. 
 Experiment results as illustrated in Table 2 show that PSLNuc significantly enhances the prediction 
performance. Using five-fold cross-validation on a non-redundant (<10% sequence identity) benchmark data 
set, PSLNuc achieves 0.800 and 0.595 in overall accuracy and MCC, respectively, compared favorably to the 
state-of-the-art results of 0.749 and 0.497. Evaluated by an independent test set, our method also performs 
better than other approaches by 0.039~0.199 and 0.077~0.207 in terms of overall accuracy and MCC, 
respectively. Our results lend support to the assumption that smoothed PSSM encoding can better resolve the 
ambiguity of discriminating between nuclear and non-nuclear proteins by considering the dependency from 
surrounding residues. Moreover, the proposed biological features and gapped-dipeptide signatures are 
interpretable and can be applied to experimental studies of targeting signals, including NLSs and NESs.  
Table 2. Performance comparison of different nuclear localization prediction approaches. 
                    Training Set (by five-fold cross-validation) 
Method tp tn fp fn Sens Spec Acc MCC 
PSLNuc 2317 2030 576 525 0.815  0.779  0.800  0.595  
10 
 
results of proteins can be used collectively to assist biologists in both inferring the function and annotating 
the proteins. Therefore, our work will contribute to scientific discoveries on a high-throughput basis. 
References 
1. Brameier, M., A. Krings, and R.M. MacCallum, NucPred--predicting nuclear localization of proteins. 
Bioinformatics, 2007. 23(9): p. 1159-60. 
2. Macara, I.G., Transport into and out of the nucleus. Microbiol Mol Biol Rev, 2001. 65(4): p. 570-94, table of 
contents. 
3. Cokol, M., R. Nair, and B. Rost, Finding nuclear localization signals. EMBO Rep, 2000. 1(5): p. 411-5. 
4. Hawkins, J., L. Davis, and M. Boden, Predicting nuclear localization. J Proteome Res, 2007. 6(4): p. 1402-9. 
5. Chang, J.M., et al., PSLDoc: Protein subcellular localization prediction based on gapped-dipeptides and 
probabilistic latent semantic analysis. Proteins, 2008. 
6. Hua, S. and Z. Sun, Support vector machine approach for protein subcellular localization prediction. 
Bioinformatics, 2001. 17(8): p. 721-8. 
7. Yu, C.S., C.J. Lin, and J.K. Hwang, Predicting subcellular localization of proteins for Gram-negative bacteria 
by support vector machines based on n-peptide compositions. Protein Sci, 2004. 13(5): p. 1402-6. 
8. Liang, H.K., et al., Amino acid coupling patterns in thermophilic proteins. Proteins-Structure Function and 
Bioinformatics, 2005. 59(1): p. 58-63. 
9. Altschul, S.F., et al., Gapped BLAST and PSI-BLAST: a new generation of protein database search programs. 
Nucleic Acids Research, 1997. 25(17): p. 3389-3402. 
10. Jones, D.T., Protein secondary structure prediction based on position-specific scoring matrices. Journal of 
Molecular Biology, 1999. 292(2): p. 195-202. 
11. Cheng, C.W., et al., Predicting RNA-binding sites of proteins using support vector machines and evolutionary 
information. BMC Bioinformatics, 2008. 9 Suppl 12: p. S6. 
12. Hofmann, T., Unsupervised learning by probabilistic latent semantic analysis. Machine Learning, 2001. 
42(1-2): p. 177-196. 
13. Garg, A., M. Bhasin, and G.P.S. Raghava, Support vector machine-based method for subcellular localization of 
human proteins using amino acid compositions, their order, and similarity search. Journal of Biological 
Chemistry, 2005. 280(15): p. 14427-14432. 
14. Chang, C.-C. and C.-J. Lin, LIBSVM: a library for support vector machines. 2001. 
15. Wu, T.F., C.J. Lin, and R.C. Weng, Probability estimates for multi-class classification by pairwise coupling. 
Journal of Machine Learning Research, 2004. 5: p. 975-1005. 
 
 
 2 
99/06/24 啟程經舊金山轉機前往波士頓 
99/07/09~07/13 在波士頓出席國際研討會 
99/07/14 在舊金山轉機 
99/07/15 抵達台北 
二、與會心得 
1. 參與會議並瞭解生物醫學資訊學界目前重要的研究課題 
2. 與國內外與會學者進行學術交流與討論 
3. 由國際研討會中之學術交流活動尋求研究合作機會 
4. 報告論文並藉由討論機會聽取其他學者之建議 
5. 造訪麻省理工學院 (Massachusetts Institute of Technology, MIT) 的電機資訊系並與
師生進行學術交流 
三、攜回資料名稱及內容 
    本次會議之論文集和壁報集均收錄在會議光碟中。 
 
 
ISMB 國際會議接受函 
會議網站：http://www.iscb.org/ismb2010  
會議日期：2010/July/9~13 
會議名稱： 18th Annual International Conference On Intelligent Systems for Molecular 
Biology(ISMB)第十八屆分子生物之智慧型系統國際會議 
From: admin@iscb.org  
To: emilysu@tmu.edu.tw  
Sent: Saturday, May 15, 2010 7:48 AM 
Subject: ISMB 2010 Poster Submission Notification 
 
Dear Emily Chia-Yu Su, 
 
We are pleased to confirm that your submission, entitled 'Prediction of Nuclear Proteins Based on 
Evolutionary Information and Probabilistic Latent Semantic Indexing', has been accepted for poster 
presentation at ISMB 2010 in Boston, USA, July 11-13. 
 
Confirming your Acceptance - MUST BE COMPLETED BY MAY 28, 2010: 
 
When you confirm your acceptance (below) agreeing to present your poster at ISMB you will also be 
asked to confirm your interest in two new ISMB 2010 activities: PLoS Postcards and the ISMB Killer 
App Award. These programs are: 
 
PLoS Postcards-ISCB is partnering with PLoS Computational Biology to have all presentations at ISMB 
2010 potentially reported on by conference student and jr. scientist attendees and published in PLoS 
Computational Biology as part of an article summarizing the conference. This program is referred to as 
PLoS Postcards. Your permission is not a guarantee that the material will be published in PLoS 
Computational Biology. For full details on PLoS Postcards please see 
http://www.iscb.org/ismb2010-program/plos-postcards  
 
ISMB Killer App Award - We invite you to submit your poster for consideration in the first ever ISMB 
'Killer App Award', which will be given for the tool or system judged to be of most practical benefit to 
experimental biologists. A panel of judges will select three finalists whom will each give a short talk as 
part of a Technology Track session. The winner will receive a year-long subscription to ScienceDirect 
and Scopus, and will be featured on the ScienceDirect Knowledge Discovery Platform. 
 
 
Please follow the link below to: 
國科會補助計畫衍生研發成果推廣資料表
日期:2012/01/31
國科會補助計畫
計畫名稱: 計算蛋白質體學：蛋白質細胞定位預測及其在蛋白質功能分類之應用
計畫主持人: 蘇家玉
計畫編號: 99-2218-E-038-002- 學門領域: 生物資訊
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
在此計畫中，我們致力於發展根據蛋白質序列分析的自動化預測系統，我們分
別發展了 PSL101、PSLDoc 和 RNAProB 三個系統，並發表論文在不錯的學術期
刊上。國內外數個生物實驗室也使用我們發展的軟體進行不同蛋白質體學研
究，並發表論文。 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
