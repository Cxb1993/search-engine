Further, for the asymmetric stereoscopic video 
coding, we present an efficient up-sampling method to 
scale up the right-view frame such that the resized 
right-view frame and the left-view frame are both the 
same. Experimental results on a set of stereoscopic 
sequences demonstrate the superiority of the proposed 
up-sampling method in terms of quality when compared 
to state-of-the-art up-sampling methods. Besides the 
up-sampling process, the proposed method be used to 
recover the erroneous macroblocks in video frames for 
realizing the error concealment ins 3D video 
sequences. 
英文關鍵詞： Video compression, error concealment, erroneous 
macroblock, H.264/AVC. 
 
has better quality performance. The pro-
posed deinterlacing method can also be 
used to recover the erroneous macrob-
locks in video frames by referring the 
neighboring pixels. Further, for the 
asymmetric stereoscopic video coding, we 
present an efficient up-sampling method 
to scale up the right-view frame such that 
the resized right-view frame and the 
left-view frame are both the same. Expe-
rimental results on a set of stereoscopic 
sequences demonstrate the superiority of 
the proposed up-sampling method in 
terms of quality when compared to 
state-of-the-art up-sampling methods. Be-
sides the up-sampling process, the pro-
posed method be used to recover the er-
roneous macroblocks in video frames for 
realizing the error concealment ins 3D 
video sequences.  
 
計畫緣由、結果與討論 
 
視 訊 壓 縮 ， 例 如 ： MPEG-1 、
MPEG-2、MPEG-4、H.261、H.263、
H.26L、與 H.264/AVC，主要的目的是
運用資料壓縮技術來降低視訊影片中的
空間與時間的冗餘資訊，減少儲存視訊
縮需的記憶空間以及傳輸視訊所需的頻
寬。在目前常被使用到的壓縮標準中，
視 訊 影 像 會 透 過 離 散 餘 弦 轉 換
(DiscreteCosine Transform, DCT)將空間
域的像素值轉換為頻率域的係數，接下
來會執行量化的程序將大量的高頻DCT 
係數量化為 0，並以 Zigzag 掃描方式配
合 Run Length 編碼法來記錄 DCT 係
數。針對這些 DCT 係數，我們利用可變
長度編碼法 (Variable Length Coding, 
VLC) 來進一步採取移除統計上的冗餘
性。在網際網路的應用上，壓縮過的視
訊需要以串流的形式經過封包網路來進
行傳輸，在傳輸的過程中若因為干擾或
是網路擁塞發生封包損失的情況，解碼
端可能會因此無法解碼出完整的視訊。
在限制網路頻寬或即時應用的環境，接
收端無法要求傳送端重新傳送傳輸遺失
的封包，這種情況將導致影片的觀賞品
質大幅度的降低。為了增加視頻碼技術
的強健性，我們必須透過錯誤恢復(Error 
Resilience) 以及錯誤隱藏 (Error Con-
cealment)的機制來降低傳輸錯誤對影片
品質造成的影響。 
 
錯誤恢復技術主要應用在編碼端方
面，利用加入額外資訊的方式，來偵測
視訊串流的錯誤，並控制錯誤範圍不致
擴大。一般常用到的錯誤恢復技術有再
同步標記、標頭延伸碼、資料分割、可
逆式變長度編碼法等技術。由於需要記
錄額外的資訊，錯誤恢復技術雖然能夠
提昇視訊壓縮技術的強健性，也會造成
壓縮率的降低。錯誤隱藏技術主要應用
在解碼端，在解碼的過程中，若發生區
塊資料因封包遺失造成損毀的情況，錯
誤隱藏技術可被執行來回復損毀區塊的
內容。由於視訊本身所具備的空間與時
間的冗餘資訊，我們可以從周邊區塊，
或是利用前一張已解碼的視訊畫面來重
建損毀區塊。與錯誤恢復技術相較之
下，錯誤隱藏技術對於壓縮率的影響較
小，但重建損毀區塊必須要花費額外的
運算量。本計劃針對錯誤隱藏技術的部
份進行相關的研究探討，提出以下三個
成果。 
 
(1) 植基於 H.264/AVC 的高容量資料隱
藏技術及其在錯誤隱藏的應用[1]： 
 
最近，Ma 等人[2]提出了一個有效的
方法，在不造成錯誤傳的的前提
下，來將資料藏入 H.264/AVC 編碼
視訊中量化後的離散餘弦轉換係
數。然而，該方法只能使用視訊畫
面中 46%的 4×4 區塊來進行資料隱
像素，或是透過左/右畫面的交互參
考，就能夠針對毀損的區域進行回
復，達到錯誤隱藏的效果(本研究成
果已被 IPPR Conf. on Computer Vi-
sion, Graphics, and Image Processing
研討會接受)。 
計畫自評 
 
本計畫的成果與報告內容和原計畫
的申請項目大致相同，計畫之分項子題
成的狀況亦很理想。三項成果已被 SCI
期刊 Journal of Systems and Software 及
研討會 IEEE International Conference on 
Signal Processing, Communications and 
Computing 與 IPPR Conf. on Computer 
Vision, Graphics, and Image Processing接
受。本計畫所提及之各項成果對於視訊
錯誤隱藏技術的研究領域及實作方面上
皆有相當貢獻。除了在學術理論上將有
顯著的成果外，在實際應用上，提供了
較以往更理想的影像品質。透過本計畫
的研究與實作，能夠讓參與的人員對於
視訊錯誤隱藏技術的相關技術有深入的
瞭解，並將理論與實際應用結合，可提
升參與之工作人員今後之研發能力進而
提昇國家競爭力。 
 
參考文獻 
 
[1] T. J. Lin, K. L. Chung, P. C. Chang, Y. 
H. Huang, H. Y. M. Liao, and C. Y. Fang, 
"An improved DCT-based perturbation 
scheme for high capacity data hiding in 
H.264/AVC intra frames," J. Systems and 
Software, acceptance for publication, 
2012 
 
[2] X. J. Ma, Z. T. Li, H. Tu, and B. Zhang, 
“A data hiding algorithm for H.264/AVC 
video streams without intra-frame distor-
tion drift,” IEEE Trans. Circuits and Sys-
tems for Video Technology, vol. 20, no. 10, 
pp. 1320-1330, Oct. 2010. 
 
[3] W. Huo, Y. Zhu, and H. Chen, “A con-
trollable error-drift elimination scheme for 
watermarking algorithm in H.264/AVC 
stream,” IEEE Signal Processing Letters, 
vol. 18, no. 9, pp. 535-538, Sept. 2011. 
 
[4] W. J. Yang, K.. L. Chung , Y. H. Huang, 
and L. C. Lin, "Quality-efficient 
de-interlacing for h.264-coded video," in 
Proc. IEEE Signal Processing, Communi-
cations and Computing, Aug. 12-15, 2012, 
Hong Kong, China. 
 
[5] J. Dong and K. N. Ngan, "Real-time 
de-interlacing for H. 264-coded hd vid-
eos," IEEE Trans. Circuits and Systems 
for Video Technology, vol. 20, no. 8, pp. 
1144--1149, 2010. 
 
[6] K. L. Chung, Y. H. Huang, Y. H. Shen, 
"Quality-Efficient Up-Sampling Method 
for Asymmetric Stereoscopic Video Cod-
ing Using Inter-View Motion Compensa-
tion and Error Compensation Schemes," 
in Proc. IPPR Conf. on Computer Vision, 
Graphics, and Image Processing, Aug. 
2012, Nantou, Taiwan. 
 
[7] X. Li and M. T. Orchard, "New 
edge-directed interpolation," IEEE Trans-
actions on Image Processing, vol. 10, no. 
10, pp. 1521-1527, Oct. 2001. 
 
[8] Y. Zhang, D. Zhao, J. Zhang, R. Xiong, 
and W. Gao, "Interpolation Dependent 
Image Downsampling," IEEE Transac-
tions on Image Processing, vol. 20, no. 11, 
pp. 3291-3296, Nov. 2011. 
 
 
An Improved DCT-based Perturbation Scheme for High
Capacity Data Hiding in H.264/AVC Intra Frames
Tseng-Jung Lina, Kuo-Liang Chunga,1, Po-Chun Changa, Yong-Huai
Huangb,2, Hong-Yuan Mark Liaoc, Chiung-Yao Fangd
aDepartment of Computer Science and Information Engineering
National Taiwan University of Science and Technology
No. 43, Section 4, Keelung Road, Taipei, Taiwan 10672, R. O. C.
bInstitute of Computer and Communication Engineering and
Department of Electronic Engineering
Jinwen University of Science and Technology,
No. 99, An-Chung Road, Hsin-Tien Dist., New Taipei City, Taiwan 23154, R.O.C.
cInstitute of Information Science, Academia Sinica,
No. 128, Academia Road, Section 2, Taipei, Taiwan 115, R.O.C.
dDepartment of Computer Science and Information Engineering,
National Taiwan Normal University,
No. 162, Heping East Road Section 1, Taipei, Taiwan 106, R.O.C.
Abstract
Recently, Ma et al. proposed an efficient error propagation-free discrete
cosine transform-based (DCT-based) data hiding algorithm that embeds data
in H.264/AVC intra frames. In their algorithm, only 46% of the 4 × 4 luma
blocks can be used to embed hidden bits. In this paper, we propose an improved
error propagation-free DCT-based perturbation scheme that fully exploits the
remaining 54% of luma blocks and thereby doubles the data hiding capacity
of Ma et al.’s algorithm. Further, in order to preserve the visual quality and
increase the embedding capacity of the embedded video sequences, a new set of
1Email: E-mail: klchung01@gmail.com, supported by National Council of Science of
R.O.C. under contract NSC98-2221-E-011-084-MY3.
2Corresponding author. Email: yonghuai@ms28.hinet.net, supported by the National Sci-
ence Council of R.O.C. under the contract NSC100-2221-E-228-007.
Preprint submitted to Journal of Systems and Software September 20, 2012
*Manuscript
Click here to view linked References
fully utilizes all luma blocks in order to improve the embedding capacity.
Instead of perturbing three QDCT coefficient-pairs to embed three bits into
each luma block [6], this paper allows one more coefficient-pair to embed four
bits into each luma block. Contrasty to Ma et al.’s approach, we fully utilize the
remaining 54% of all luma blocks. To further preserve the visual quality of the
embedded video sequences, a new set of sifted 4× 4 luma blocks, which can be
used to embed hidden bits by perturbing the related QDCT coefficients, is con-
sidered in the proposed DCT-based perturbation scheme. Based on twenty-six
test video sequences, experimental results confirm the embedding capacity supe-
riority while keeping the similar human visual effect in terms of SSIM (structural
similarity) index when compared with Ma et al.’s algorithm. The remainder of
this paper is organized as follows. In the next section, we highlight the capacity
limitation in Ma et al.’s algorithm. In Section III, the proposed algorithm is
presented and a related theoretical analysis is given. In Section IV, we report
the results of experiments. Section V contains some concluding remarks.
2. The Capacity Limitation Problem inMa et al.’s Data Hiding Scheme
In this section, we briefly explain intra prediction under H.264/AVC, and
describe how an existing approach defines five categories for all 4 × 4 luma
blocks. It is well known that intra prediction plays an important role in reducing
spatial redundancy among H.264/AVC intra frames. In H.264/AVC, each 16×
16 macroblock (MB) can be encoded by 16 × 16 intra mode or 4 × 4 intra
mode. Here we only consider embedding data into MBs encoded by 4× 4 intra
mode since MBs encoded by 16× 16 intra mode are homogeneous and thus the
3
a b c d
e f g h
i j k l
m n o p
A B C D
I
J
K
L
E F G HM
1, 1
r
i jB   1,
r
i jB  1, 1
r
i jB  !
, 1
r
i jB  
,i jB
Figure 1: The predicted pixels in a 4 × 4 luma block and the related reference pixels in the
four encoded neighboring blocks.
example, assume that the selected prediction mode for Bi,j+1 is 1, as shown in
Fig. 2, and that d, h, l, and p are used to predict Bi,j+1. The error propagation
problem will occur if the luma values of d, h, l, and p are changed by perturbing
some coefficients of RQDCTi,j .
To solve the error propagation problem, Ma et al. [6] first classify the re-
lations between the above-mentioned seven boundary pixels and the selected
prediction modes of four adjacent blocks into three cases. For simplicity, let
Mi,j+1,Mi+1,j−1,Mi+1,j, andMi+1,j+1 denote the four sets of prediction modes
selected for Bi,j+1, Bi+1,j−1, Bi+1,j , and Bi+1,j+1, respectively. The value of
each mode is in the range 0 to 8. The three cases, Case1, Case2, and Case3, are
defined as follows. Case1 occurs when the value of Mi,j+1 is in {1, 2, 4, 5, 6, 8},
which indicates that d, h, l, and p are the reference pixels for predicting Bi,j+1.
Case2 occurs when the value ofMi+1,j falls in {0, 2, 3, 4, 5, 6, 7} and the value of
Mi+1,j−1 is in {3, 7}. This indicates that m, n, o, and p are the reference pixels
for predicting Bi,j+1 and Bi+1,j . Case3 occurs when the value of Mi+1,j+1 falls
in {4, 5, 6}, which indicates that p is the reference pixel for predicting Bi+1,j+1.
5
1, 1i jB !  1,i jB !
, 1i jB !
1, 1i jB ! !
,
r
i jB
a
k
b c d
e f g h
i j l
m n o p
Figure 3: An encoded 4 × 4 luma block and the four adjacent luma blocks affected by the
encoding process.
Table 1: Five categories of optimally selected modes of adjacent 4 × 4 luma blocks and the
related reference pixels.
Case1 Case2 Case3 Reference pixels
Cat1 TRUE FALSE X d, h, l, p
Cat2 FALSE TRUE X m, n, o, p
Cat3 FALSE FALSE FALSE NIL
Cat4 FALSE FALSE TRUE p
Cat5 TRUE TRUE X ALL
X: Don’t care. NIL: No reference pixel. ALL: All seven related pixels.
embedding scheme can be implemented by perturbing the three corresponding
coefficient-pairs. Since there are no reference pixels in Cat3, Ma et al.’s scheme
utilizes each QDCT coefficient in the corresponding 4×4 luma block; thus, each
block contributes 16 bits of capacity. Interestingly, Ma et al. did not present
an error propagation-free data hiding scheme for Cat5. Based on six different
quantization parameters (QPs), 18, 23, 28, 33, 38, and 43, we ran their algo-
rithm on twenty-six sequences. Table 2 shows the percentage distribution of
luma blocks corresponding to each category. In average, we observe that only
46% of the 4 × 4 luma blocks are error propagation-free because Ma et al.’s
scheme does not consider Cat5. As a result, 54% of the luma blocks are not er-
ror propagation-free. This observation motivates us to design a new embedding
7
as follows:
RQDCTi,j = (CfR
p
i,jC
T
f )⊗ (Ef/Q)
=


Y00 Y01 Y02 Y03
Y10 Y11 Y12 Y13
Y20 Y21 Y22 Y23
Y30 Y31 Y32 Y33

 (1)
where Cf =


1 1 1 1
2 1 −1 −2
1 −1 −1 1
1 −2 2 −1

, Ef =


a2 ab
2
a2 ab
2
ab
2
b2
4
ab
2
b2
4
a2 ab
2
a2 ab
2
ab
2
b2
4
ab
2
b2
4

, a = 12 , b =
√
2
5
; the
operator “⊗” denotes an element-by-element product of two matrices; and Q is
the step size of a quantizer determined by a quantization parameter (QP). In
the decoding stage, the dequantization operation and the 4 × 4 integer inverse
DCT are applied to RQDCTi,j to obtain a residual block R
r
i,j as follows:
Rri,j = C
T
r (R
QDCT
i,j ×Q⊗ Er)Cr (2)
where Cr =


1 1 1 1
1 1
2
− 1
2
−1
1 −1 −1 1
1
2
−1 1 − 1
2

 and Er =


a2 ab a2 ab
ab b2 ab b2
a2 ab a2 ab
ab b2 ab b2

. FromRri,j , we derive
the decoded luma block Bri,j (= B
p
i,j + R
r
i,j). Next, we describe the proposed
improved data hiding algorithm.
For the categoryCat1, we define the set of vertical coefficient-pairs in R
QDCT
i,j
to be SV = {(Y10, Y12),(Y20, Y22), (Y30, Y32), (Y00,Y02)}. The first three pairs are
used in Ma et al.’s algorithm. We propose the fourth pair (Y00,Y02) to increase
the embedding capacity.
Next, we demonstrate the correctness of error propagation-free assurance.
Each coefficient-pair in SV can embed one hidden bit by perturbing the two
corresponding QDCT coefficients. Hence, our scheme has a four-bit embedding
capacity for each 4×4 luma block belonging to Cat1, compared to the three-bit
9
hidden bits in each 4×4 block. Cat4 can be handled in the same way as Cat1 or
Cat2. In our implementation, every block belonging to Cat4 can be perturbed
by the same way as the blocks in Cat1, that is, one more bit can be embedded.
For Cat5, we present a new perturbation technique to embed one hidden
bit without error propagation. For each 4 × 4 luma block, the four suggested
coefficients in RQDCTi,j are denoted as the set SQuad = {(Y00,Y02,Y20, Y22)}. The
perturbation of SQuad is realized by perturbing (Y00,Y02,Y20,Y22) to (Y00 + 1,
Y02 − 1,Y20 − 1, Y22 + 1). The error propagation-free property of the perturba-
tion technique used in the fifth category is proved by the following theorem.
Theorem 1. For Cat5, we can embed one hidden bit in each 4× 4 luma block
by perturbing (Y00,Y02,Y20,Y22) to (Y00 + 1, Y02 − 1,Y20 − 1,Y22 + 1).
Proof. After perturbing (Y00,Y02,Y20,Y22) in R
QDCT
i,j to (Y00 + 1, Y02 − 1,Y20 − 1,Y22 + 1)
in RQDCT
′
i,j , the difference between R
QDCT ′
i,j and R
QDCT
i,j is given by
∆RQDCTi,j = R
QDCT ′
i,j −R
QDCT
i,j =


1 0 −1 0
0 0 0 0
−1 0 1 0
0 0 0 0

 . (5)
Then, the difference between the decoded residual block Rri,j and the per-
turbed residual block Rr
′
i,j is calculated by
∆Rri,j = R
r′
i,j −R
r
i,j = C
T
r (∆R
QDCT
i,j ×Q⊗ Er)Cr
= Q×


0 0 0 0
0 4a2 4a2 0
0 4a2 4a2 0
0 0 0 0

 . (6)
Because Br
′
i,j = B
p
i,j + R
r′
i,j + ∆R
r
i,j and the rightmost column vector and the
bottom row vector in ∆Rri,j are zero vectors, the corresponding vectors in the
11
RQDCT
′
i,j and R
QDCT
i,j can be calculated as follows:
∆RQDCTi,j = R
QDCT ′
i,j − R
QDCT
i,j =


0 0 0 0
1 0 −1 0
0 0 0 0
0 0 0 0

 (9)
Through further derivation, we have
∆Rri,j = R
r′
i,j −R
r
i,j = C
T
r (∆R
QDCT
i,j ×Q⊗ Er)Cr
= Q×


0 2ab 2ab 0
0 ab ab 0
0 −ab −ab 0
0 −2ab −2ab 0

 , (10)
where b =
√
2
5
. The distortion caused by perturbing (Y10, Y12) is calculated as
follows:
D(Y10, Y12) =
3∑
m=0
3∑
n=0
∆Rr2mn
= 4× (2ab)2 + 4× (ab)2 ×Q2
= 20× (ab)2 ×Q2
= 2Q2. (11)
By the same arguments, we have D(Y20, Y22) = D(Y30, Y32) = 2Q
2. Overall, the
upper bound of the total distortion with respect to the first category is 8Q2 (=
D(Y00, Y02) +D(Y10, Y12) +D(Y20, Y22) +D(Y30, Y32)). According to the above
distortion analysis, the upper bound of the total distortion with respect to the
second and fourth categories is 8Q2. It is known that at most sixteen hidden bits
can be embedded into the luma block in the third category, so the total distortion
is bounded by 16Q2. For the fifth category, perturbing (Y00,Y02,Y20,Y22) to
(Y00 + 1,Y02 − 1,Y20 − 1,Y22 + 1) yields the following distortion:
13
algorithm for hiding data in H.264/AVC intra frames is bounded by
DMa = [6Q
2 × (PCat1 + PCat2 + PCat4) + 16Q
2 × PCat3 + 0× PCat5 ]
= 6Q2 × 0.42 + 16Q2 × 0.04 + 0× 0.54
= 3.16Q2. (14)
3.3. The proposed data hiding algorithm
Although the proposed DCT-based perturbation scheme significantly im-
proves the embedding capacity of Ma et al.s algorithm, the above distortion
analysis reveals that the proposed scheme suffers from the quality degradation
problem. Besdies preserving the high embedding capacity benefit, we still hope
to preserve the visual quality in terms of SSIM, the proposed data hiding al-
gorithm is performed in a new set of sifted 4 × 4 luma blocks and results in
less visual quality degradation. Human visual system is much more sensitive to
smooth regions than to textural regions, if a MB is encoded by 16 ? 16 intra
mode, we do not embed any hidden bits since the MB contains a smooth region;
otherwise, the magnitudes of the sixteen QDCT coefficients of each 4× 4 luma
block are used to sift the textural luma blocks from smooth blocks by
1
16
3∑
m=0
3∑
n=0
|Y ′m,n| ≥ T (15)
where |Y ′m,n| denotes the absolute vale of Y
′
m,n and T is the threshold of average
QDCT coefficient magnitude. When a 4 × 4 block violates the condition of
Eq. (15), the proposed data hiding algorithm discards the block; otherwise, the
15
is calculated by
(Y ′00, Y
′
02, Y
′
20, Y
′
22) =

(Y00 + 1, Y02 − 1, Y20 − 1, Y22 + 1),
if (Y00 is even, h=1, Y00 ≥ 0, and Y22 ≥ 0)
or (Y00 is odd, h=0, Y00 ≥ 0, and Y22 ≥ 0)
(Y00 − 1, Y02 + 1, Y20 + 1, Y22 − 1),
if (Y00 is even, h=1, Y00 < 0, and Y22 < 0)
or (Y00 is odd, h=0, Y00 < 0, and Y22 < 0)
(Y00, Y02, Y20, Y22), otherwise.
(18)
According to the value derived by Eq. (18), one extra bit can be embedded
into the luma block. Based on the above embedding process, after embedding
hidden bits into suitable luma blocks, the embedded luma blocks still make the
condition of Eq. (15) held.
The hidden data extraction process is performed in the H.264/AVC decoding
stage. For each decoded 4 × 4 intra mode, if the condition of Eq. (15) is
held, it indicates that some hidden bits have been embedded in the luma block
successfully. If the current decode luma block belongs to Cat1 or Cat2, we check
each perturbed pair (Y ′mn, Y
′
pq) in SV or SH . If it is a non-zero coefficient-pair,
the hidden bit can be extracted by
h =
{
1, if Y ′mn is odd
0, otherwise.
(19)
The above extraction process is also applicable to Cat3. If a decoded marked
luma block belongs to Cat4, we check each non-zero coefficient Y
′
m,n in that
block and the hidden bit can be extracted by Eq. (19). In Cat5, if SQuad is a
non-zero quad-coefficient, the hidden bit can be extracted by
h =
{
1, if Y ′00 is odd
0, otherwise.
(20)
17
Table 3: Comparison of the embedding capacity of Ma et al.’s algorithm and the proposed
algorithm in terms of the number of bits per 4× 4 luma block.
QP Ma et al. Proposed Improvement Ratio
18 0.97 1.32 36%
23 0.69 0.94 36%
28 0.45 0.60 33%
33 0.24 0.31 29%
38 0.10 0.13 30%
43 0.03 0.04 33%
Average 0.41 0.56 33%
for different QPs. The average bitrate increment rates of Ma et al.’s algorithm
and the proposed algorithm were 1.44% and 1.68%, respectively, and it indicates
that the bitrate degradation is rather small. For saving space of the context,
we omit the bitrate increment ratios of both algorithms for each test sequence.
The quality comparison for both algorithms is illustrated in Table 6. Besides
using PSNR to measure the quality of the embedded video frames, the well-
known SSIM index is adopted to measure the visual quality. In our experiments,
the SSIM index [16] between the original and embedded frames IX and IY is
calculated by
SSIM(IX , IY ) =
1
NB − 1
NB−1∑
i=0
(2µBXiµBYi + c1)× (2σBXiBYi + c2)
(µ2BXi
+ µ2BYi
+ c1)(σ2BXi
+ σ2BYi
+ c2)
(21)
where BXi and BYi denote i-th 4x4 luma block in IX and IY , respectively, and
both two frames can be partitioned into NB 4×4 luma blocks; µBXi (µBYi ) and
σB2
Xi
(σ2BYi
) denotes the mean and variance of BX (BY ), respectively; σBXiBYi
is the covariance of BX and BY ; c1 and c2 are defined by
c1 = (k1 × L)
2
c2 = (k2 × L)
2
19
Table 6: PSNR and SSIM comparison between Ma et al.’s algorithm and the proposed algo-
rithm.
QP
Ma et al. Proposed
PSNR SSIM PSNR SSIM
18 42.66 0.994 42.21 0.993
23 39.22 0.987 38.74 0.986
28 36.05 0.976 35.62 0.974
33 32.94 0.956 32.65 0.955
38 30.07 0.924 29.91 0.923
43 27.53 0.878 27.49 0.878
Average 34.75 0.953 34.44 0.952
where L = 255, k1 = 0.01, and k2 = 0.03.
When compared to Ma et al.’s algorithm, although the PSNR degradation
of the proposed algorithm is 0.31 dBs (= 34.75− 34.44 dBs), the SSIM index is
similar to that of Ma et al.’s algorithm and the proposed algorithm can improve
xx% embedding capacity. The similar SSIM indexes of two concerned algorithms
imply that the proposed algorithm improve the embedding capacity of Ma et
al.’s algorithm without visual quality degradation. For QP= 28, when compared
to Ma et al.’s algorithm, Table 7 demonstrates that PSNR degradation of the
proposed algorithm is ranged from 0.06 dBs to 0.68 dBs, but the SSIM index is
almost the same each other.
Figs. 4–9 are six image sets namely, Bridge-Close, Coastguard, Container,
Crew, City, and Soccer sequences, which are used to evaluate the visual quality
performance. In the first image set shown in Fig. 4, we compare the visual effect
between Fig. 4(a) and each of Figs. 4(b)–(c), and observe that both concerned
algorithms slightly degrade the visual quality when compared to H.264. The
remaining five image sets shown in Figs. 5–9 also reveal the same visual quality
observation. The decoding time performance of the concerned two algorithms is
21
(a) (b)
(c)
Figure 4: Visual effect of the resultant intra frames in Bridge-Close sequence by (a)
H.264/AVC. (b) Ma et al.’s algorithm. (c) The proposed algorithm.
shown in Table 8 and it indicates that in average, each algorithm requires about
18.8 milliseconds to decode each frame from the compressed video sequence.
Table 8 also demonstrates that the decoding time performance of each algorithm
satisfies real-time requirement. For example, in the popular NTSC and PAL
standards, 30 and 40 milliseconds are required for encoding each image frame.
Besides Ma et al.’s algorithm, we also implement Huo et al.’s algorithm [3],
which mainly improves the quality of Ma et al.’s algorithm. Table 9 shows
the concerned four performances of Huo et al.’s algorithm. When compared to
23
(a) (b)
(c)
Figure 6: Visual effect of the resultant intra frames in Container sequence by (a) H.264/AVC.
(b) Ma et al.’s algorithm. (c) The proposed algorithm.
25
(a) (b)
(c)
Figure 8: Visual effect of the resultant intra frames in City sequence by (a) H.264/AVC. (b)
Ma et al.’s algorithm. (c) The proposed algorithm.
27
Table 9: Performance of Huo et al.’s algorithm.
QP
Embedding Bitrate Increment
PSNR SSIM
Decoding
Capacity Rate Time
18 0.61 0.51% 42.84 0.994 28.256
23 0.54 0.98% 39.44 0.988 21.956
28 0.30 1.69% 36.13 0.979 18.745
33 0.14 2.18% 33.01 0.960 16.461
38 0.11 2.08% 30.26 0.925 15.478
43 0.04 1.29% 27.60 0.878 14.723
Average 0.29 1.45% 34.88 0.954 19.270
Tables 3, 5, 6, and 8, Table 9 indicates that Huo et al.’s algorithm has smaller bi-
trate overhead, higher PSNR, and similar SSIM index when compared to Ma et
al.’s algorithm and our proposed algorithm, but the embedding capacity degra-
dation is 41% and 93% of Ma et al.’s algorithm and the proposed algorithm,
respectively. In summary,Ma et al.’s algorithm and Huo et al.’s algorithm are
suitable for embedding applications with low and medium embedding capacity.
However, the proposed algorithm allows the applications with higher embed-
ding capacity; for example, embed more encoding information to assist error
concealment process in H.264 video sequences and hope to keep the similar
visual quality as in H.264.
5. Conclusion
We have presented a new data hiding algorithm to resolve the capacity limi-
tation problem in Ma et al.’s data hiding algorithm for H.264/AVC intra frames.
The contribution of this work is threefold. First, unlike Ma et al.’s algorithm,
the proposed scheme exploits the fifth block category, which accounts for 54%
of all luma blocks. Further, for preserving the visual quality and increasing
29
[6] X. J. Ma, Z. T. Li, H. Tu, and B. Zhang, “A data hiding algorithm
for H.264/AVC video streams without intra-frame distortion drift,” IEEE
Trans. Circuits and Systems for Video Technology, vol. 20, no. 10, pp.
1320-1330, Oct. 2010.
[7] C. V. Nguyen, D. Tay, and G. Deng, “A fast watermarking system for
H.264/AVC video,” in Proc. IEEE Asia Pacific Conf. Circuits and Systems,
Singapore, pp. 81-84, Dec. 2006.
[8] M. Noorkami and R. Mersereau, “Compressed-domain video watermarking
for H.264,” in Proc. IEEE Int. Conf. Image Processing (ICIP 2005), Los
Alamitos, vol. 2, pp. 11-14, Sep. 2005.
[9] M. Noorkami and R. M. Mersereau, “A framework for robust watermarking
of H.264-encoded video with controllable detection performance,” IEEE
Trans. Information Forensics and Security, vol. 2, pp. 14-23, Feb. 2007.
[10] A. Papoulis, The Fourier Integral and Its Applications.,New York:
McGraw-Hill, 1962, ch. 2.
[11] G. Qiu, P. Marziliano, A. T. Ho, D. He, and Q. Sun, “A Hybrid Water-
marking Scheme for H.264/AVC Video,”in Proc. IEEE ICPR, vol. 4, Aug.
2004, pp. 865-868.
[12] I. E. G. Richardson, H.264 and MPEG–4 Video Compression, John Willy
& Sons Ltd, 2003.
[13] K. Wong, K. Tanaka, and X. Qi, “Multiple Messages Embedding Using
31
國科會補助計畫衍生研發成果推廣資料表
日期:2012/10/10
國科會補助計畫
計畫名稱: 視訊壓縮的錯誤隱藏技術之研究
計畫主持人: 黃詠淮
計畫編號: 100-2221-E-228-007- 學門領域: 影像處理
無研發成果推廣資料
 
(2) 論文標題： 
Distortion 
reduction for 
histogram 
modification-based 
reversible data 
hiding 
期刊名稱： 
Applied 
Mathematics and 
Computation 
 
(3) 論文標題： 
Efficient sampling 
strategy and 
refinement 
strategy for 
randomized 
circle-detection 
期刊名稱： 
Pattern 
Recognition 
研究報告/技術報告 0 0 100%  
研討會論文 1 1 100% 
論文標題： 
Quality-efficient 
de-interlacing for 
h.264-coded video
研討會名稱： 
IEEE Signal 
Processing, 
Communications and 
Computing 
 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
