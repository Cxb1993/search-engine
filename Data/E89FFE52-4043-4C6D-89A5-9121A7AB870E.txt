行政院國家科學委員會補助專題研究計畫 ■ 成 果 報 告   
□期中進度報告 
 
 
輪式機器人智慧型視覺導引控制技術研究 
 
 
計畫類別：■ 個別型計畫  □ 整合型計畫 
計畫編號：NSC 99－2221－E－011－023－ 
執行期間： 99 年 8 月 1 日至 100 年 7 月 31 日 
 
計畫主持人：黃緒哲教授 
計畫參與人員：林于崴, 吳俊錫, 張巍瀚 
 
成果報告類型(依經費核定清單規定繳交)：□精簡報告  ■完整報告 
 
本成果報告包括以下應繳交之附件： 
□赴國外出差或研習心得報告一份 
□赴大陸地區出差或研習心得報告一份 
□出席國際學術會議心得報告及發表之論文各一份 
□國際合作研究計畫國外研究報告書一份 
 
處理方式：除產學合作研究計畫、提升產業技術及人才培育研究計畫、
列管計畫及下列情形者外，得立即公開查詢 
      □涉及專利或其他智慧財產權，□一年□二年後可公開查詢 
          
執行單位：國立台灣科技大學 機械系(所) 
 
中   華   民   國  100 年  8 月   1 日
 類雙眼的架構，人類之所以可以分辨出
遠近，是因為兩隻眼睛所得到的畫面視
差，透過大腦轉換成深度資訊，因此，
立體視覺影像系統多使用兩台或以上的
攝影機來模仿雙眼構成立體視覺系統，
文獻【1】【2】【3】，皆是利用兩台攝影
機同時取得影像，然後利用演算法來重
現大腦計算視差的過程；透過計算出左
右兩張畫面的平方誤差和（Sum of 
Squared Differences, SSD），即可以轉換
出影像中物件的深度資訊 
 
三、研究目的 
本研究將探討的是雙眼立體視覺的 
演算，包含立體對應以及影像深度估計
的演算法，並且利用實驗來進行影像感
測對校正，以及各項參數的量測，最後
估算出物體三維立體座標。首先針對雙
眼視覺的左右影像之目標物體做＂立體
對應＂（Stereo Matching），所謂立體
對應就是在左右兩張影像中，對同一個
目標點做出定位，立體對應分為主動式
以及被動式，主動式的立體對應是在目
標物上偵測特定的特徵影像，像是利用
雷射光點打在目標物上，立體對應時只
要在兩張畫面中搜尋雷射光點的位置即
可達到立體對應。而被動式立體對應的
方法，是直接利用左右影像的特徵點做
比對，像是直接對應法、區塊灰階比較
法，邊界法，投影法，重心法等，其中，
本研究將採用邊界法以及直接對應法。
當移動目標物被找到，並且完成立體對
應之後，作估測目標物體的景深，與三
維座標之計算。 
本研究所發展之立體影像系統將與
第一年之研發成果輪式仿人型雙臂機器
人進行所有訊號與控制器溝通整合，以
達成可利用影像資訊來導引仿人型機器
人之運動控制功能。以開發出雙臂機器
人之雙臂可互助合作、亦可利用視覺回
饋與運動位置回饋的訊號來達成互動式
運動控制之智慧型機器人控制技術。 
 
 
四、文獻探討 
在視覺結合仿人型機器人做辨識或
互動方面，文獻【4】【5】利用色彩為基
礎的對物件做即時辨識並應用於人形機
器人上，並對人招手有互動反應，然而
物體顏色必須事先設定，否則無法辨
識，【6】則是將立體視覺應用於移動式
機器上對障礙物進行避障動作，然而其
並未與人型機器人做結合，並且在標定
障礙物方式是先採用邊緣偵測，將物體
圖面區塊框選出後再進行立體對應求出
其座標，然而邊緣偵測對複雜環境有很
大的敏感度，在複雜環境下標定物體有
很大的困難，【7】則是移動式機器人上
架設一小型低自由度機械手臂，並利用
立體視覺取出特定物體之距離並抓取
之。文獻【8】成功將立體視覺結合仿人
型雙足機器人上，建立視差圖利用霍夫
轉換（Hough transform）找出地板平面
並取得其表面曲面，避障功能則是利用
避開曲面高處來達成，然而從文獻中可
得知該演算法並無法知道障礙物之資
訊，【9】則是建立一完整系統利用 DSP
做為運算台台之接球機器人，【10】將立
體視覺與移動式輪型機器人做結合，並
建立一套視覺伺服控制系統，利用視覺
做回授來控制機械手臂，並使用 PD 控
制器來控制機械手臂達成移動物追蹤功
能，然而文中並未提到當移動式機器人
移動的同時系統適用與否。 
 
 
 
五、立體視覺系統 
本研究之視覺系統運作流程，如圖
5.1 所示，參考本實驗室既有研究成果，
採用 TMS320C6416T DSK（以下簡稱
DSP）配合 2 個 CMOS 影像感測器建立
 2
 本研究所提出之未知環境偵測物體
之影像處理演算法流程如圖 5.6 所示： 
 Original Image from DSP 
Object Exists? 
Image preprocessing 
Locate Image Block Inpainting 
Detection unknown Object in view 
Is Better then 
Stereo match 
Calculate Depth of Field 
 
 
 
 
 
 
 
 No 
Yes 
 
Send data to Controller 
No 
Yes 
 
 
 
 
 
 
 
 
 
 
 
 
圖5.6 影像處理演算法流程 
自CMOS影像感測器取得左右影像
後，必須對接收回來之影像資料進行校
正修補以避免影像歪斜扭曲，考慮到後
續影像處理繁多，為加快系統處理速度
因此進行降維（Downsize），對最後修補
後之影像資料進行色彩內差還原（Color 
Interpolation Recodes）成彩色圖片，並
進行灰階化（Gray-Scale Processing），以
完成影像前處理動作（Image 
Preprocessing）。 
前處理後之影像資料，利用雙眼立
體視覺之特性找出相對於右邊CMOS之
視差圖（Disparity Map），以求得雙眼重
疊視野中所有東西相對於視覺系統之相
對距離，並設定本研究中所在關心之相
對距離做為門檻值做為二值化
（Binarization）之依據，由於對環境以
及目標物無特定條件限制，因此為降低
雜訊與增加後續框選目標物之運算速
度，接著利用區塊門檻值二值化濾波
（Part Threshold Binarization）以濾除二
值化後之視差圖中所出現之雜訊，以期
將目標物所在位置突顯出來，再利用投
影法（Projection Algorithm）框選出目標
物所在圖面位置，完成偵測視野內未知
物體步驟（Detection unknown Object in 
view）。若無框選到任何東西或所框選到
之圖面座標不符合所需，則再重新抓取
左右影像後重新進行該步驟。 
假設利用投影法有框選出目標物之
圖面座標，為確保座標準確性以利後續
進行立體對應（Stereo Match）與景深估
測（Depth Estimation），會針對已框選圖
面座標區域內進行修補動作（Locate 
Image Block Inpainting）以期能增加框選
座標之正確率。在修補框選目標物圖面
座標後，進行左右影像立體對應以找出
左眼影像相對於右邊之圖面位置，之後
利用光學幾何關係估測該目標物之景深
以完成偵測程序。 
 
 
 
六、結果與討論 
本研究於第一年度使用系統晶片實
現移動式仿人型機器人影像伺服系統，
以下分別進行多項實驗以驗證本文所設
計架構之正確性。在影像分析實驗大致
分為視野內有單物體及多物體情況，並
檢驗其座標與大小誤差等；而影像整合
運動控制實驗則是設計幾種 Case 利用
此影像演算與仿人型機器人來執行動作
並驗證之。 
本節首先進行本研究所提出之演算
法中各個必須執行步驟之效能分析，如
表 6.1 所示，在修補框選區域與立體對
應、景深估測等由於不同物體大小以及
物體多寡會造成處理時間有很大的差
距，因此沒辦法列出數據，從每次必須
步驟中可看出，視差圖之建立佔了幾乎
 4
 物體二：  
圖 6.4 物體二影像演算法結果圖 
表 6.5 物體二估算與實際量測數據比
較 
Spend time 154.8860 (ms) 
Image Coordinate 
R 
(72, 
53)~(112, 
86) 
Image 
Coordina
te L 
(99, 
54)~(139,8
7) 
3D 
Coordinate(Estima
te / Actual) 
X: 388.87 
/ 410 
(mm) 
Y: -701.17 
/ -730 
(mm) 
Z: -130.70 / 
-140 (mm) 
Error of 3D 
Coordinate(Error / 
Rate) 
X: 
21.13(m
m) / 
0.0515(%
) 
Y: 
28.83(mm
) / 
0.0395(%) 
Z: 9.3(mm) 
/ 0.0664(%)
Size(Estimate / 
Actual) 
Height: 
181 / 300 
(mm) 
Width: 
125 / 250 
(mm) 
Length: 
180 / 200 
(mm) 
Error of Size(Error 
/ Rate) 
119(mm) 
/ 
125(mm) / 
0.5000(%) 
20(mm) / 
0.1000(%) 
0.3967(%
) 
Pixel 
Resolution(mm/Pix
el) 
5 
物體二為一圓柱形罐子上面放一頂
安全帽，由圖 6.4(a)與(h)對照可發現修
正後物體與原圖有些許差距，但仍然可
抓取大部份物體所在圖面座標，因此在
三維座標估算部份還是有一定的精確度
在。 
物體三： 
圖 6.6 物體三影像演算法結果圖 
 
 
 6
 Size(Estimate / 
Actual) 
Height: 
150 / 270 
(mm) 
Width: 
232 / 150 
(mm) 
Length: 
187 / 170 
(mm) 
Error of 
Size(Error/Rate) 
120(mm) 
/ 
0.444(%) 
82(mm) / 
0.5467(%)
17(mm) / 
0.1 (%) 
Pixel 
Resolution(mm/Pixel
) 
4.25 
Object 2. 
Image Coordinate R (85, 
43)~(119, 
91) 
Image 
Coordinat
e L 
(110, 
44)~(144, 
92) 
3D 
Coordinate(Estimate 
/ Actual)  
X: 420.60 
/ 500 
(mm) 
Y: -762.58 
/ -880 
(mm) 
Z: 
-163.48 / 
-210 
(mm) 
Error 3D 
Coordinate(Error/Ra
te)  
X: 
79.4(mm) 
/ 
0.1588(%
) 
Y: 
117.42(m
m) / 
0.13(%) 
Z: 
46.52(m
m) / 
0.2215(%
) 
Size(Estimate / 
Actual) 
Height: 
127 / 270 
(mm) 
Width: 
196 / 150 
(mm) 
Length: 
165 / 170 
(mm) 
Error of 
Size(Error/Rate) 
143(mm) 
/ 
0.5296(%
) 
46(mm) / 
0.3367(%)
5(mm) / 
0.0294(%
) 
Pixel 
Resolution(mm/Pixel
) 
5.7143 
 
 
 
 
 
七、參考文獻 
【1】 Takeo Kanade, Atsushi Yoshida, 
Kazuo Oda, Hiroshi Kano and 
Masaya Tanaka, “A Stereo 
Machine for Video-rate Dense 
Depth Mapping and Its New 
Applications,” Proceedings of the 
15th Computer Vision and Pattern 
Recognition Conference (ICVPR 
'96), June, pp. 196-202, 1996. 
【2】 Kurt Konolige, “Small Vision 
Systems: Hardware and 
Implementation,” In Proceedings 
of the 8th International 
Symposium in Robotic Research, 
pp. 203–212. Springer-Verlag, 
1997. 
【3】 Masatoshi Okutomi and Takeo 
Kanade, “A Multiple-Baseline 
Stereo,” IEEE Trans. on Pattern 
Analysis and Machine 
Intelligence, Vol. 15, No. 4, April, 
pp.  353-363, 1993. 
【4】 張維軒, “以色彩為基礎的即時
物件辨識系統應用於人形機器
人視覺 ”, 碩士論文, 淡江大學
電機工程學系碩士班, 2007. 
【5】 陳浥菁, “自走車 DSP 嵌入式影
像系統之研究”, 碩士論文, 國
立成功大學工程科學研究所 , 
2003. 
【6】 翟必君, “基於立體視覺之行動
機器人的室內環境避障”, 碩士
論文, 國立臺灣科技大學資訊工
程研究所, 2007. 
【7】 任紹棟, “具立體視覺測距之移
動機器人”, 碩士論文,國立臺灣
科技大學電機工程系, 2004. 
【8】 Kohtaro Sabe*, Masaki 
Fukuchi**, Jens-Steffen 
Gutmann**, Takeshi Ohashi**, 
Kenta Kawamoto*, and Takayuki 
Yoshigahara***, “Obstacle 
Avoidance and Path Planning for 
Humanoid Robots using Stereo 
Vision”, * Life Dynamics 
Laboratory Preparatory Office, ** 
Networked CE Development 
Laboratories, *** Broadband 
Applications Laboratories, Sony 
 8
國科會補助計畫衍生研發成果推廣資料表
日期:2011/08/01
國科會補助計畫
計畫名稱: 輪式機器人智慧型視覺導引控制技術研究
計畫主持人: 黃緒哲
計畫編號: 99-2221-E-011-023- 學門領域: 機器人學及應用
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
基於近兩年之研究成果表現 今年七月獲得 WSEAS 學會邀請為再希臘科芙島舉
行之第十五屆 WSEAS 國際性電路、系統、通訊與電腦學國際研討會，以及第四
屆 WSEAS 國際性工程力學、結構與都市計劃聯合研討會之 Plenary Lecture 
Speaker 所發表之 研究成果獲得他人好評 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
