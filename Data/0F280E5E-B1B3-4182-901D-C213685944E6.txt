 II
 
Abstract 
 
Vector field visualization is one of the most challenging research issues for 
Visualization in Scientific Computing (ViSC).  Indeed, vector fields have strong 
relevance in science and engineering community where typical examples occur in the 
visualization of computational fluid dynamics and electron physics.  Furthermore, 
vector fields have also been used in artistic domains, especially in manifesting 
sculptures and paintings.  The chief contribution of this project is the derivation of 
novel techniques that allow the computer to generate visually appealing imageries that 
look like hand-drawn paintings. 
The fulfillment of this goal adopts example-based texture synthesis algorithm.  
Texture synthesis technique originally employed for generating synthetic texture of 
arbitrary size from a small input sample.  This field has developed and grown over 
recent years, but the avenue is still wide open.  We have developed a non-iterative 
texture transfer algorithm transferring feature-matched patches from the source 
texture to the target image.  An implemented system has demonstrated the feasibility 
of this technique in the application of vector field visualization.  Besides, the 
synthesis process is fully automatic without any user intervention. 
 
Keywords: example-based, texture synthesis, vector field visualization, 
non-photorealistic rendering. 
 
 2
的計算速度倍數提昇。 
這些方法無法成功表現強度，同時方向性更會造成糢糊，可被誤解成 180
度不同的兩個方向。對於一些關鍵點如 source、sink、spiral、center 與 saddle 等
特殊點無法有效的展示出向量場的細節。於是 Turk [17]則提出了另一種
Streamline 的視覺技術，其主要訴求重點為欲使向量長線條保持在一定的密度，
他使用了一個能量函數(energy function)與 relaxation 的原理來精確控制向量線條
的變化、移動與放置，如圖 2 所示為 Streamline 實作系統的執行結果。 
 
 
圖 1  使用 LIC 技術的向量場視覺化結果 
 
 
圖 2  使用 Streamline 技術的向量場視覺化結果 
 
 
3. 研究方法 
 
在本章節我們首先將描述材質合成演算法的基礎作法，材質合成意謂根據一
張較小的範本材質，進而產生出較大張且具有相同紋理特性的新材質。材質合成
的用途之一為可進一步擴展成具限制性材質合成的應用，例如空洞填補(hole 
filling)與物體摘除(object removal)等。除此之外，我們還將之開發設計成向量場
視覺化的工具與藝術畫風圖像的自動產生器，只要使用者提供來源與目的兩張影
 4
(constrained synthesis)等，就要再進一步的設計，我們是採用如圖 3 所示的區塊
架構，其包含一個中心區域與包圍它的二個邊界區域。 
 
 
圖 3  L-shaped 區塊的設計架構圖 
 
此外，對於合成結果輸出品質最有顯著影響的是重疊邊界的處理方式，如圖
4 所示為我們新提出的整合技術說明，以求有效達成兩相鄰區塊在重疊邊界上的
一致性與平滑連貫性，第一步驟我們先採用動態規劃演算法求得一條最短路徑，
第二步驟採行加權的羽化融合技術來合併兩重疊像素。 
 
 
圖 4  整合的覆疊邊界處理技術 
 
讓 B1 與 B2 表兩個有相同 m×n 大小的覆疊邊界區域，對於每個位於位置(i, j)
的距離權重(weight)為 jie , ，如方程式(2)所示，然後我們將找到一條最短路徑從列
0 出發走到列 m-1，而方程式(3)為從列 i=m-1 遊走到列 i=0 時的計算過程， jiE , 表
示從位置(i, j)到終點列 m-1 為止所發現的最短距離值。 
 
2
ji,ji,
2
ji,ji,
2
ji,ji,
2
ji,ji,ji, )b2(b1)g2(g1)r2(r1)B2(B1e −+−+−=−=     (2) 
 


=+
==
+++−+ 2-m .. 0ifor    )E ,E ,min(Ee
1-mifor                                                  e
E
1j1,ij1,i1j1,iji,
ji,
ji,              (3) 
 6
 
 
圖 5  向量場視覺化系統介面與合成使用的參數及合成時間 
 
 
4. 結果與討論 
 
4.1 實驗結果 
 
如圖 6 所示為我們的雛型系統實驗結果，可以展示出系統有不錯的成效，的
確可成功的實現向量場視覺化。系統是執行在 Intel Core 2 Duo – 2.33 GHz 及 2G 
RAM 的個人電腦上，其總共合成時間包含訓練與合成階段都能夠在 2 秒內完
成，結果堪稱理想，但是虛擬記憶體的需求量特別大，這是未來可加以改進之處。 
 
表 1  向量場視覺化之執行時間統計(單位：秒) 
Texture 
Name 
Texture(I
nput) Size 
Vector 
Name 
Synthesis(
Output) 
Size 
Training 
Time 
Synthesis 
Time 
Total 
Time 
Carpet1 128×128 circle 256×256 1.227 0.527 1.754
Carpet1 128×128 cylinder 256×256 1.230 0.525 1.755
Carpet1 128×128 electron- 256×256 1.229 0.603 1.832
Carpet2b 256×256 circle 256×256 1.501 0.549 2.050
Carpet2b 256×256 cylinder 256×256 1.497 0.560 2.057
Carpet2b 256×256 electron- 256×256 1.501 0.649 2.150
 
 8
 
saddle2 saddle sink source 
 
 
 
 
 
 
圖 7  各種不同輸入材質與不同向量場合成之結果比較 
 10
參考文獻 
 
[1] S. Arya, D. M. Mount, N. S. Netanyahu, R. Silverman, and A. Y. Wu, “An 
Optimal Algorithm for Approximate Nearest Neighbor Searching in Fixed 
Dimensions,” Journal of the ACM, 45(6), pp. 891-923, 1998. 
[2] M. Ashikhmin, “Synthesizing Natural Textures,” in Proceedings of ACM 
Symposium on Interactive 3D Graphics, pp. 217-226, 2001. 
[3] Z. Bar-Joseph, R. El-Yaniv, D. Lischinski, and M. Werman, “Texture Mixing and 
Texture Movie Synthesis Using Statistical Learning,” IEEE Transactions on 
Visualization and Computer Graphics, 7(2), pp. 120-135, 2001. 
[4] B. Cabral and L. Leedom, “Imaging Vector Fields Using Line Integral 
Convolution,” in Proceedings of SIGGRAPH ’93, pp. 263-272, 1993. 
[5] F. Dong, H. Lin, and G. Clapworthy, “Cutting and Pasting Irregularly Shaped 
Patches for Texture Synthesis,” Computer Graphics Forum, 24(1), pp. 17-26, 
2005. 
[6] A. Efros and T. Leung, “Texture Synthesis by Non-Parametric Sampling,” in 
Proceedings of International Conference on Computer Vision, pp. 1033-1038, 
1999. 
[7] A. Efros and W. T. Freeman, “Image Quilting for Texture Synthesis and 
Transfer,” in Proceedings of SIGGRAPH 2001, pp. 341-346, 2001. 
[8] W. T. Freeman, J. B. Tenenbaum, and E. Pasztor, “Learning Style Translation for 
the Lines of a Drawing,” ACM Transactions on Graphics, 22(1), pp.33-46, 2003. 
[9] A. Hertzmann, C. E. Jacobs, N. Oliver, B. Curless, and D. H. Salesin, “Image 
Analogies,” in Proceedings of SIGGRAPH 2001, pp. 327-340, 2001. 
[10] A. Hertzmann, N. Oliver, B. Curless, and S. M. Seitz, “Curve Analogies,” in 
Proceedings of Eurographics Workshop on Rendering, pp. 233-246, 2002. 
[11] A. Hertzmann, “A Survey of Stroke-Based Rendering,” IEEE Computer 
Graphics and Applications, 23(4), pp. 70-81, 2003. 
[12] V. Kwatra, A. Schodl, I. Essa, G. Turk, and A. Bobick, “Graphcut Textures: 
Image and Video synthesis Using Graph Cuts,” in Proceedings of SIGGRAPH 
2003, pp. 277-286, 2003. 
[13] L. Liang, C. Liu, Y. Q. Xu, B. Guo, and H. Y. Shum, “Real-Time Texture 
Synthesis by Patch-Based Sampling,” ACM Transactions on Graphics, 20(3), pp. 
127-150, 2001. 
[14] A. Sanna, B. Montrucchio, P. Montuschi, and A. Sparavigna, “Visualizing Vector 
Fields: The Thick Oriented Stream-Line Algorithm,” Computers and Graphics, 
25(5), pp. 847-855, 2001. 
[15] D. Stalling and H. C. Hege, “Fast and Resolution Independent Line Integral 
