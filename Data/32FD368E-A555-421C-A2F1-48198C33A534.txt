共 116 頁，第 2 頁 
目錄 
中文摘要…………………………………………………………………………………………4 
英文摘要…………………………………………………………………………………………5 
一、簡介…………………………………………………………………………………………6 
1.1 身分確認的重要性………………………………………………………………………….6 
1.1-1 身分辨識與身分確認的技術概述……………………………………………………….6 
1.1-2 身分確認系統之應用需求量大於身分辨識系統……………………………………….7 
1.1-3 使用者對身分確認技術的接受度……………………………………………………….7 
1.2 虹膜辨識研究背景介紹……………………………………………………………………8 
1.2-1 虹膜結構………………………………………………………………………………….8 
1.2-2 虹膜用於身分確認之適用性…………………………………………………………….9 
1.2-3 自動虹膜辨識發展沿革…………………………………………………………………11 
1.2-4 自動虹膜辨識的開山鼻祖：Daugman 與 Wildes 兩套虹膜辨識方法的比較………12 
1.2-5 其他自動虹膜辨識的方法……………………………………………………………….21 
1.3 本研究成果之重要性………………………………………………………………………23 
二、虹膜辨識研究成果…………………………………………………………………………25 
2.1 虹膜紋理資訊……………………………………………………………………………….25 
2.1-1 虹膜紋理資訊分析與特徵抽取………………………………………………………….25 
2.1-2 以邊緣型別描述虹膜特徵……………………………………………………………….29 
2.1-3 虹膜特徵抽取實驗結果………………………………………………………………….31 
2.1-4 虹膜特徵抽取結語……………………………………………………………………….34 
2.2 虹膜區域定位……………………………………………………………………………….35 
2.2-1 虹膜取像模組…………………………………………………………………………….36 
2.2-2 雙 CCD 攝影機影像校正……………………………………………………………….39 
2.2-3 系統軟體流程……………………………………………………. ………………………42 
2.3 四頻譜虹膜影像定位……………………………………………………………………….43 
2.3-1 虹膜影像定位概述………………………………………………………………………..43 
2.3-2 瞳孔定位…………………………………………………………………………………..45 
2.3-3 交錯偵測與活體偵測……………………………………………………………………..46 
2.3-4 仿射矯正…………………………………………………………………………………..46 
2.3-5 虹膜定位…………………………………………………………………………………..47 
2.3-6 眼瞼定位…………………………………………………………………………………..49 
2.4 正規化虹膜影像與特徵抽取……………………………………………………………….50 
2.4-1 正規化虹膜影像…………………………………………………………………………..50 
2.5 虹膜辨識系統實驗結果……………………………………………………………………..52 
2.5-1 實驗環境…………………………………………………………………………………..52 
2.5-2 辨識結果參數說明………………………………………………………………………..52 
共 116 頁，第 4 頁 
中文摘要 
在本報告中，我們將探討利用多視角虹膜辨識及視線簽名作身份確認的方法。我們將詳
述如何實作目前最佳的 Daugman 虹膜辨識法及其參數設計方法，另外也將提出一個新的虹
膜紋理描述方法。這個虹膜紋理描述法是將虹膜影像以其局部的影像邊緣型別來加以標記。
這種虹膜特徵描述的方式不但效率高，計算方法簡單，而且精確度與 Daugman 的方法相
同。另外我們也將提出一個用來取得四頻譜虹膜影像的雙 CCD 取像系統，並修正虹膜正規
化的方法，使之可用於處理不同視角所攝得之影像上。我們總共收集了 116 組多視角虹膜影
像，建立了充足的多視角虹膜資料庫。利用這組資料測試我們的方法，其結果顯示在 +/-20o 
的取像角度內，這個多視角虹膜辨識方法可達到 0.01% 的等誤差率 (Equal Error Rate)。在
視線簽名方面，我們發展了一套使用單攝影機來追蹤人的視線理論，並利用電腦模擬驗証其
對雜訊的耐受力，同時也分析其求解的困難度。依據這分析的結果顯示使用單攝影機追蹤視
線在實務上較不可行。所以我們也提出使用視線密碼來取代視線簽名的方法，並提出利用眼
睛外觀決定視線所在區域的簡單方法。這個方法經實測可達 99.8% 的正確率。在報告中，
我們也將說明如何結合視線密碼與多視角虹膜辨識來確認身份的作法。 
 
關鍵詞：身分確認、生物測定學、虹膜辨識、視線簽名、非正向視角虹膜辨識。 
 
共 116 頁，第 6 頁 
一、簡介 
1.1 身分確認的重要性 
為了釐清責任與財產的歸屬，身分的辨識與確認自古以來便一直是人類社會中的一個重
要問題。在近代更由於電腦與網路技術的發達，在涉及個人隱私及商業或國防機密資料的
保護上也需要嚴格地確認意圖存取者的身分。但是儘管科技進步神速，身分辨識與確認科
技的進展和普及度都顯得相對緩慢。最為普遍的身分確認法是檢驗當事人是否持有如印
章、鑰匙、證照等信物，或是檢驗當事人是否知道如密碼之類的事物，但是在這種檢驗法
重視信物遠超過當事人的情形下，容易產生流弊。例如在近代塑膠貨幣獲廣泛使用後，因
為傾向於認卡不認人的策略所衍生的身分冒用漏洞，光是在台灣地區每年已造成數十億新
台幣的損失。此外由於網路駭客的入侵，個人隱私、商業機密、甚至國家機密外洩也時有
所聞。 
1.1-1 身分辨識與身分確認的技術概述 
有鑑於身分辨識及確認的重要性，科學家們很早就開始研究各式用於身分辨識及確認的
技術。而這些身分確認的技術大致上可以分為兩大類：一是以生理特徵作為分類基礎，另
一類則是以行為特徵作為分類的基礎。 
1. 以生理特徵為分類基礎的身分辨識及確認技術：可供身分確認的生理特徵必須具有不
易改變的特性，而這些特徵不外乎頭、臉、手、指紋、眼睛等相關的特徵。在英國維
多利亞時代的 Galton 爵士曾提出一些描述臉型輪廓的特徵參數量測法，供罪犯及囚
徒的身分辨識用 [Galton88]。Galton 成立了一個人體測量學實驗室，並發展一個裝設
了彈簧的機械結構來作臉型的量測，並據以將囚犯依其臉型分為 81 類。另外也有許
多人採用了如頭蓋骨的外型參數，或者是臉型及表情作身分的辨識  [Harmon81] 
[Samal92] [Penland00] [Phillips00]。此外，也有人嘗試使用掌形、掌紋、手掌血管、視
網膜血管、指紋等作為身分確認用 [Holmes91] [Miller94]。 
2. 以行為特徵作為分類基礎的身分辨識及確認技術：以行為特徵作分類主要是利用聲
紋、以及簽名和敲擊鍵盤時的動態差異等作為身分確認用 [Holmes91] [Miller94]。 
共 116 頁，第 8 頁 
 
1.2. 虹膜辨識研究背景介紹 
1.2-1. 虹膜結構 
 
 
Fig. 1-1 顯微鏡下的虹膜解剖結構。 
 
虹膜的解剖結構如 Fig. 1-1 所示，由外至內大致上有 A, B, C 三層結構。A 層是一個
多孔的組織，密佈纖維母細胞 (fibroblast) 與黑素細胞 (melanocyte)，中間點綴一些膠原纖
維。B 層是基質層，由鬆散的結締組織所構成（含纖維母細胞、黑素細胞與第一及第三型
膠原纖維）。B 層也包括了在瞳孔邊緣處，寬約 1mm，可控制瞳孔大小的不隨意肌，以及
在 C 層上方由交感神經主導支配的瞳孔擴張肌。C 層是由不透光的強韌結締組織所構成，
支撐整個虹膜結構。A、B 兩層皆呈多孔性，水樣液 (Aqueous Humor) 可以自由進出這兩
層組織，方便瞳孔大小變化時可以快速排出或吸收液體，以增快瞳孔縮放速度。由外面觀
測人的虹膜時，看到的是這多層結構的綜合影像。當 A 層的孔大到明顯可見時，則稱之為 
Crypt（如 Fig.1-2 所示），而如 Fig.1-1 所示，C 層結構會延伸到瞳孔邊緣，形成一個深色
的褶邊 (papillary frill)。虹膜外層大致上可發現有兩個紋理不同的區域，在靠近瞳孔的那一
共 116 頁，第 10 頁 
 
Fig. 1-4  虹膜的外形可以近以地表示為一個截掉尖頭的角錐面 
虹膜位於人眼透鏡的外側，由於人眼透鏡內外兩面皆為凸透鏡，所以披在外側的虹膜也
因而凸起（如 Fig. 1-4 所示）。一般而言，虹膜的外形可以近似地表示為一個截掉尖頭的角
錐面 [Wildes97]。另一方面，由於虹膜外凸的程度比起取像距離又小的可以忽略，因此在
一般的情況下也可以將虹膜近似地看成一個平面 [Daugman01]。 
 
1.2-2 虹膜用於身分確認之適用性 
最早注意到虹膜的多樣性的是解剖學家 [Adler65] 及眼科醫師 [Flom87]，在他們的職
業生涯中檢驗了大量的虹膜圖形之後，發現沒有兩個人的虹膜圖形是一樣的，即使是同一
個人的雙眼虹膜圖形也會不同。更進一步地，他們發現除了少數罹患嚴重眼疾的病人之外，
人在青春期過後終其一生其虹膜圖形也不會有明顯的變化。此外，由發展生物學 
(developmental biology) 上的發現，也為虹膜辨識作為身分確認的適用性提供了理論上的佐
證：這些生物學家發現人眼虹膜的大體結構主要是由遺傳決定，但是其細部結構 （如 crypt, 
callorette, 及其他的特徵） 的發展則與胚胎時期細胞特化成虹膜組織時的初始條件有相當
大的關係。因為每個人在胚胎期要形成虹膜組織的條件不會相同，所以兩個人擁有完全相
同的虹膜其機率非常的低 [Mann50][Kronfeld68]。人的虹膜在二歲時就大致發育完成，但是
一直到青春期時其虹膜上的顏色分佈仍會稍有變化，同時平均瞳孔大小也會隨著年齡而成
共 116 頁，第 12 頁 
1.2-4 自動虹膜辨識的開山鼻祖：Daugman 與 Wildes 兩套虹膜辨識方法的比較 
在這個小節中我們將依序介紹虹膜辨識系統的三個模組：第一個模組為虹膜取像設備，
第二個模組為虹膜影像定位，第三個模組則為虹膜影像的辨識。 
1. 虹膜取像設備：人眼中虹膜的直徑大約為 11mm，在 Daugman 的辨識系統中要求虹
膜在影像中的直徑必須在 100 至 200 個 pixels 之間，而在 Wildes 的系統中則要求
虹膜影像直徑約在 256 個 pixels 左右。配合那個時期的 video camera  解析度（約
在 640×480），他們都必須使用視角很狹小的鏡頭才可能達到這個虹膜影像解析度。
但是因為攝影機的視角狹小，所以使用者必須調整自己的頭部位置，方便取像裝置取
得適當影像。 
(a) Daugman 的虹膜取像裝置如 Fig. 1-5 所示，為了方便使用者調整自己的頭部位
置，上方的攝影機經由一個半透鏡取到使用者的眼睛影像，而取得的影像即刻顯
示在一個小型的 LCD 螢幕上。使用者可以依據所取得影像的位置與清晰度調整
其頭部位置。為了提供較高對比的虹膜影像，Daugman 在半透鏡下方裝設了一個
可見光 LED，LED 的位置經過仔細調整，使得這個光源在使用者眼鏡上的反射
光不會覆蓋在虹膜影像上（但是角膜上的反射光問題還是無法解決）。這個虹膜取
像系統會自動計算取得影像的清晰度，當影像中的 Edge Point 清晰度達到一個臨
界值，則這張合格的影像會被自動送到下一個模組中進行虹膜定位的計算。 
(b) 另一方面 Wildes 等人發現照明眼睛的光源通常會在眼睛的角膜上形成反射光，
而這些反射光可能會正好遮蓋到虹膜上的特徵。因此他們採用的取像裝置示意圖
如 Fig. 1-6 所示，將光源與攝影機同時置於圓形偏極化偏光鏡的同一側，即可消
除影像中的鏡面反射光（原理如 Fig. 1-7 所示）。同時為了讓使用者可以自我調
整頭部位置，以取得適用於虹膜辨識的影像。Wildes 等人在取像裝置前方裝置了
一大一小對準用的方框，當使用者頭部位置適當時，使用者會看到這兩個框框重
疊在一起，此時使用者必須自行壓下取像裝置上的一個按鈕通知系統取像。為了
避免照射入眼睛的光線讓使用者覺得不適，Wildes 採用了低照度攝影機，以降低
光源亮度。 
共 116 頁，第 14 頁 
 
Fig. 1-6 Wildes 等人的虹膜取像裝置  [Wildes96b]。 
 
Fig. 1-7 圓形偏極化板消除反射光示意圖 [Wildes96b]。 
2. 虹膜影像定位：虹膜影像定位的目的是要在取得的影像中找出 Limbus (角膜與鞏膜交
界) 以內、瞳孔以外的虹膜區域。一般在作虹膜定位時會採用幾項預設條件，以協助
虹膜影像定位。常用的預設條件有假設 Limbus 與瞳孔邊緣都是圓形，而上下眼皮則
個別假設為一段拋物線。Daugman 與 Wildes 的虹膜影像定位法恰好代表兩個不同類
型，前者用的是以最佳化法搜尋 Limbus 與瞳孔邊界，而後者則是以 Hough Transform 
來找尋這些邊界。 
共 116 頁，第 16 頁 
心參數搜尋過程中陷入區域最小值的問題，但缺點是在計算二值化的邊緣圖形 
(edge map) 時需要設定一個二值化的臨界值，因此會有一些需要人工調整設定的
參數。但值得注意的是因為他們的取像程序的設計較為嚴格，使得取到的影像非
常單純 （參見 Fig. 1-8），所以目前這兩套方法在實際使用中並未發生任何問題，
因此這兩套虹膜影像定位法都足以提供虹膜辨識用。 
 
 
(a) (b) 
Fig. 1-8  (a) Daugman 的取像系統與 [Daugman93] (b) Wildes 的取像系統所取得的
眼睛影像 [Wildes97]。 
 
3. 虹膜影像辨識：虹膜影像辨識必須先將新取得的影像對齊（調整影像之大小、平移量
及旋轉量） 到與存在資料庫中的資料同一基準，而後再進行特徵抽取運算，並比對
特徵以確定使用者身分。在這兩套方法的原型系統中都假設照射使用者眼睛的照明裝
置照度一致，因此並未對瞳孔的縮放所引起之虹膜形變作太多探討。另外他們假設虹
膜位置在定位之後已經補償完畢而無需考慮影像之平移量，所以在對齊影像時只需考
慮其大小及旋轉量。 
(a) Daugman 的虹膜影像辨識法：Daugman 在找到 Limbus 及瞳孔邊緣之後，即將影
像 ( )yxI ,  作正規化至某種極座標形式 ( )φρ ,I ，其中 [ ]1,0∈ρ  而 [ ]πφ 2,0∈ ；
0=ρ  代表瞳孔邊緣那一圈，而 1=ρ  代表 Limbus 外圍這一圈，完全排除不是
虹膜影像的區域，而且也選擇性地排除可能被上眼皮遮掩以及照明系統在角膜形
成的反射亮點。而因為 Daugman 虹膜特徵比對速度非常快，所以他並沒有去計
共 116 頁，第 18 頁 
Gabor wavelet 所產生出來的濾波器的實數部分減去其本身的平均值，使得該濾波
器的 DC component 響應為零，而虛數部分則因為是奇函數相互抵消，所以不需
要處理 DC component 的問題。又為了方便將虹膜資料儲存在 IS-7811 規格的信
用卡背面磁條上，Daugman 採用 1024 組 Gabor Filter ({ }kkkkk r00 ,,,, θωβα , k = 1, 
2, …, 1024)，來處理虹膜影像： 
 ( ) ( )
( ) ( )
( )∫ ∫
−−−−−−=
ρ φ
β
φθ
α
ρφθω ρφρφρθωβα ddIerh k
k
k
k
k
r
i
kkkkk ,,,,,
2
2
0
2
2
0
0
00 , (7) 
其中 ( )φρ ,I  是虹膜影像的極座標表示式。接著 Daugman 將 ( )kkkkk rh 00 ,,,, θωβα  
依其實數與虛數部份的正負號量化為兩個位元 (bits)，因此 1024 個 Gabor Filter 
的輸出共可轉為 2048 個位元（等於 256 bytes）。Daugman 稱這 256 bytes 的資
料為 Iris Code。經由實驗結果顯示這種 Iris Code 的每一個 bit 是 0 或是 1 的
機率大約都等於 0.5，因此每一個位元的熵值都已經最大化，也就是說單獨看每一
個位元，他們所含的資訊量已經是最大的。如果每一個位元都是獨立同分佈，則
這  2048 個位元的機率可以表示為一個有 2048 個自由度的  binomial 
distribution，但是因為 Gabor filter 本身會引入一些相關性（空間位置相鄰的 filter 
其訊號不免仍有相關性），所以 Daugman 經理論分析推估有效的獨立資訊應該是 
2048 位元的 4.05 分之一（約為 506 位元）。但在實際上除了 filter bank 本身會
引入訊號相關性，訊號本身的相關性也會造成有效的自由度減少。Daugman 經由
實驗結果的統計，發現在 1993 年時所收集到的 529 個眼睛的 Iris Code 的 
Hamming distance 分佈大約是一個具有 173 個自由度的 binomial distribution。但
是在 2002 年，他利用新收集到的資料重新估測過 Iris Code 的自由度大約是 
249，也就是兩個人具有相同 Iris Code 的機率是 2-249 [Daugman02]。兩組 Iris 
Code 的比對方法是採用 Normalized Hamming Distance (NHD): 
 
2048
1
1NHD
2048 j jj
A B
=
= ⊗∑ , (8) 
NHD 運算非常簡單，所以計算速度也非常快。在 1993 年的版本即可每秒比對 
共 116 頁，第 20 頁 
差。Wildes 等人採用了四層的 Laplacian pyramid 作虹膜辨識，所以總共可以計算
出四個層次 NC 的中間值。令 4Rq∈  代表這四層 NC 值的中間值，而判別這個
虹膜比對的結果是採用 Fisher 線性分類法 [Duda73] [Fisher36]。很明顯的， Wildes 
等人的方法計算量遠大於 Daugman 的方法。而在實際系統運算速度上 (Sun 
SPARCstation 20)，每檢驗一個人的速度大約需要 10 秒鐘。 
 
 
Fig. 1-9 虹膜影像的 Laplacian pyramid [Wildes96]。 
(c) Daugman 與 Wildes 的虹膜辨識方法比較：Daugman 的虹膜辨識法中最花時間的
運算是在計算 Gabor filter 的輸出，之後的比對計算基本上是非常簡單的整數運
算。另一方面 Wildes 的方法中，從虹膜影像的對齊、Laplacian pyramid 的計算、
以及 NC 的計算等等，每一個步驟都相對的耗時。但是耗時的運算如果能夠提供
較高的安全性，仍是有其必要性。雖然在目前的測試結果中這兩套系統都沒有 
False Accept 的情形出現（Daugman 的測試規模較大，累積至 2002 年已有九百多
萬人次，而 Wildes 的系統測試規模大約只有近千筆測試結果），但是九百多萬人
次比起全球幾十億人口總數其規模仍然不夠大。沒有任何理論可以保證 Daugman 
的 256-byte Iris Code 真的可以成功地區分地球上所有人的身分。必須擁有足夠龐
大的資料庫來做評比，才真正能夠評估這兩套方法的優缺點。總而言之，目前的
資料顯示虹膜圖形用來做身分辨識/確認的效果相當顯著，甚至不用太高深的圖形
辨識技術即可在大量的資料庫中成功地確認一個人的身分。 
共 116 頁，第 22 頁 
法來作辨識。這個系統的辨識錯誤率大約為 0.15 %，仍不及 Daugman 與 Wildes 的
系統 [Ma02]。 
7. 暨大電機系陳文雄教授的研究重心置於虹膜特徵之分析並且也完成了一套完整的虹
膜辨試系統，他嘗試利用碎形維 [Cheng01a] [Cheng01b] [Cheng03] 及 PCA 代表虹膜
特徵 [Cheng02]，抽取的特徵以 k-mean 分類器作訓練並以 k-nearest neighbor 作辨
識，得到相當好的辨識成果。 
8. Masek 提出其一套的虹膜辨識的辨識方法，其利用 Hough transform 抽取出眼睛影像
中的虹膜區域，並去除眼瞼、睫毛…等可能影響辨識的區域；之後並仿效 Daugman 的
方法對虹膜影像進行特徵抽取和比對，接著，將這些方法運用在兩組不同的虹膜影像
資料庫 (CASIA, LEI) 上進行一些辨識效果的比較和分析 [Masek03]。 
9. Huang 等人利用相位一致 (Phase Congruence) 的方法來找出並移除虹膜影像內睫
毛、瞳孔、上下眼瞼等雜訊 [Hunag04]。Kong 等人則試著使用 Gabor Filter 來偵測並
移除睫毛及反光等雜訊 [Kong01]。Sun 等人利用 Integrated LFC-GFC System 來辨識
具有雜訊的虹膜影像 [Sun05]。 
10. Jang 等人則是根據 Daugman 所提出的一些步驟進行評估與修正，他們利用自行架設
的取像設備來進行虹膜取像，接著利用其提出的影像檢查演算法來挑出具有雜訊和可
能為偽造的資料，以提供剩下品質較佳的影像作為特徵抽取之用；在特徵抽取這步驟
中是使用 Daubechies’wavelet 來做為特徵抽取的工具，最後使用 SVM 和 Euclidian 
distance 來進行分類；在測試過 111 位不同使用者中的 1694 隻眼睛的虹膜影像後，
發現使用 SVM 當作分類器的時候辨識率較佳，可達到 99.1 % [Jang04]。 
11. Liam 等人使用自行開發的虹膜區域定位法來對虹膜影像進行定位，之後利用 
self-organizing map neural network 進行虹膜比對；在對 150 張測試用虹膜影像作測
試，其辨識率為 83%，其中部份的影像有出現嚴重的失真現象，所以造成辨識率下降 
[Liam02]。 
12. Teo 等人利用 Block hold 搜尋法和 Integro-differential 運算子來對虹膜定位，接著利
用一維不規則形狀分析的方法來進行特徵抽取，最後比對虹膜特徵向量來檢視是否為
共 116 頁，第 24 頁 
虹膜影像。以動態虹膜影像作身分確認可以利用角膜折射對虹膜影像的影響以及瞳孔/虹膜
圖形的動態變化來排除假冒者。 
 
 
 
共 116 頁，第 26 頁 
正規化影像中此類的雜訊。完成虹膜影像正規化後，選用特定的濾波器，開始對正規化的
虹膜影像進行虹膜紋理特徵抽取，將擷取出來的虹膜特徵轉換成二進位碼，並考慮到上下
眼瞼、眼睫毛…等所帶來的雜訊，適時的將這些雜訊濾除，留下其他有用的虹膜紋理資訊。
最後是對抽取出來的虹膜紋理資訊進行比對，在這邊我們是使用 NHD 來比對兩兩虹膜的
相似度，如果兩兩虹膜比對出來的 NHD 愈小的話，表示其相似度愈高；反之，相似度愈
低。 
在虹膜特徵抽取的部分，明確的目標就是要找出 Gabor 濾波器中心應該在正規化虹膜
影像上的哪些位置和 Gabor 濾波器的長度、高度和空間頻率分別為多少，最能使得抽取出
來的虹膜特徵和之後所抽取出的虹膜紋理特徵資訊可以被有效地比對。但是由 (2) 式可以
明顯地看出來其所需要決定的自由度有：{x0i, y0i, α, β, u0, v0}。在自由度這麼高的情形下，
相對地衍生出來的複雜度也高出許多。 
在 Daugman 的方法裡面 [Daugman93]，他使用了 1024 個濾波器來進行特徵抽取，由
此可知，所要決定的參數數目高達 6144 個之多。因此，我們自行訂出一些方式來減少參
數數目。因為這 1024 個濾波器都是由四個層次的 Gabor wavelets 所組成的，所以假設第 
m 層的濾波器為 Nm，由此得到 
0 1 2 3 1024N N N N+ + + ≥                        (12) 
我們並設定 αm 和 βm 為第 m 層的 Gabor 濾波器的寬、高參數。根據在 [Daugman93] 中
所提到的 2-D Gabor wavelet， 02mmα α=  且 02mmβ β= 。由此可知，不同層次的 Gabor 濾波
器有不同大小的寬度和高度，可表示成 04 mmN N−= ，由 (12) 式推得 
16
0
2
85
N ≥ . 
另外在 [Daugman94] 中，Daugman 提出將虹膜影像等份分成八分析帶 (Analysis Band)，使
得每一個分析帶的高度皆相同，如此一來，在使用不同大小的高度的濾波器來進行特徵抽取
就變得比較沒有意義，因此，我們把每一個頻帶上濾波器的高度都設成一樣，換句話說，就
是使得 mβ  都相同。由此可知，不同層次的 Gabor 濾波器有不同大小的寬度，可表示成 
共 116 頁，第 28 頁 
造成，故暫時不考慮這垂直方向的資訊。由此可以定出在虹膜頻譜中帶有最豐富資訊的頻帶 
(most informative band, MIB) 在水平方向，而後在調整濾波器參數時，我們把濾波器組的通
帶限制住，使其不脫離 MIB 的範圍，也就是將 Gabor 濾波器的參數 v0 設定成 0。利用此
特性來訂定取樣間隔，對水平方向進行等份且較為密集的取樣，如此，便可以粗略的估測出 
Gabor 濾波器的中心位置所在。 
 決定完 Gabor 濾波器擺放在虹膜影像上面的位置之後，接著就是要找出在這些分佈位
置上面最適當大小、變化頻率的 Gabor 濾波器；而要在 Gabor 濾波器擁有這麼多自由度的
情況下，求得最能有效抽取出虹膜特徵的濾波器有著一定的困難度；因此，後續將藉由基因
演算法 (Genetic Algorithm, GA) 來求出比較適合的 Gabor 濾波器的寬度、高度和空間頻率。 
       
Fig. 2-1 由 CASIA 虹膜影像資料庫計算出來的振幅譜變化的標準差 
 在 GA 演算法中，則使用 measure decidability (MD, 定義在下列式子中) 作為其適應函數
(Fitness function): 
( ) ( )0 2 2, , / 2
a i
a i
m m
f
s s
α β ω −=
+
                     (13) 
其中 ( ) ( ), , ,a a i im s m s  分別是 authentic 與 imposter 的虹膜碼之 NHD 的平均值與標準
差。MD 在某種程度上可以反應出合法使用者與入侵者的可分辨程度。在以 MD 作標準的
情況下讓 GA 來決定最佳的濾波器參數。為了減少 GA 的訓練時間，我們將參數的範圍設
定在 [1,32]α ∈ , [1,8]β ∈  和 0 [0,0.5]u ∈ ；這樣一來 u0 會符合 Nyquist 取樣定理，而其他
的參數限制，如：α 如果超過 32，影像經過濾波器處理後會太過模糊進而會減少 inter-class 
共 116 頁，第 30 頁 
上偵測到說有一個第 A  層的 negative step edge 或是 negative ridge edge 存在。我們就利用
兩個二進位變數 ( ) ( ( ))S p u D pθ θA A  和 ( ) ( ( ))R p u L pθ θA A  來記錄計算出的 ET flag，其中 
( )u ⋅  為 unit step function。若 p 點附近的影像強度約為定值，則 ( )D pθA  和 ( )L pθA  的值將
會非常接近 0，在這種情況下，所標示的 ET flag 將會很容易受到雜訊的影響。我們有兩種
方法可以解決這問題，第一為增加 ( )D pθA  和 ( )L pθA  的量化階層，第二為利用遮罩去除易
產生雜訊的點。在這兩個方法中，第一個方法會因為取樣過密造成邊緣型別偵測對影像的對
比強度非常敏感，換句話說，就是容易因影像的對比變化而跟著有明顯的變化，而這結果不
是我們所想要的。所以我們選擇第二種方法來消除不必要的雜訊。 
描述虹膜紋理的資訊定義如下：在第 A  層，濾波器旋轉角度為 θ  的情形下，虹膜紋
理的邊緣資訊可表示為兩個 ET maps， θSA  和 θRA，以及相對應的兩個遮罩圖 (mask maps)，
s
θM
A  和 r θMA。遮罩 sMθA  和 rMθA  若為 0，代表該點的資訊不可靠。 
 除此之外，LoG 和 DoG 都是 band-pass 濾波器，影像中低及高頻的部份都會被 LoG 
和 DoG 濾波器濾除掉，也因此，由於取樣定理的關係，處理過的影像可以被適當的降低其
解析度而不會遺失其原本該有的資訊。如果第一層的 ET map 大小為 H1 × W1，則其他 A  
層的 ET map 則為 1 1
1 1
H W
β β α α×A A 。假設設定 nA  為不同大小層次的濾波器， on  表示為濾
波 器 的 旋 轉 角 度 的 數 目 ， 而 完 整 的  ET descriptor 可 以 用 
( ){ }, , , | 1,..., ; 1,...,o o o os r on o nθ θ θ θΩ = =S M R MA A A A A A  來表示。為了描述方便，我們將完整的 ET 
descriptor 當成是 ETCode。 
 相同的，我們根據所提出的參數設計方法，使用式 (13) 適應函數，經由 GA 的訓練來
設計虹膜特徵抽取濾波器，為了減少 GA 的訓練時間，我們也將參數的範圍設定在 
[1,32]α ∈A ， [1,8]β ∈A 。 
 
共 116 頁，第 32 頁 
 
 我們將測試用虹膜影像進行前製處理之後，發現部份正規化虹膜影像會因為上下眼瞼和
眼睫毛的影響，造成可辨識之虹膜區域過小，進而影響到我們對虹膜特徵抽取的效果，如 Fig. 
2-4 所示。 
 
 
Fig. 2-4 正規化虹膜影像與其遮罩 
 
 我們分別在電腦配備為  Pentium IV 3.0GHz、Pentium IV 3.2GHz，記憶體容量為 
512MB、1GB，作業系統皆為 Windows XP Professional SP2 的電腦上面進行實驗，一些基因
演算法所需要的共同參數分別為：族群大小為 50，演化次數為 200，交配機率為 0.7，變異
機率為 0.2。訓練用樣本是從 CASIA 資料庫中任意選取 30 組資料來進行參數訓練。在實
驗中，我們嚐試利用四個層次的 LoG/DoG 濾波器組和 Gabor 濾波器組虹膜進行特徵抽
取，每種濾波器再分成兩種不同的擺放方式，另外我們由 CASIA 資料庫中任意選出兩筆數
量皆為 30 組資料的虹膜影像來作為訓練用的資料，總共會有八組不同的訓練結果；再加上
我們自行以相關資訊挑選的四組濾波器參數，共有十二種結果。為方便識別這十二組參數，
我們以一個三個欄位的簡稱標示設計出來的濾波器：[LD|GF] [2W|AB][T1|T2|MS]。使用 
LoG/DoG 者標為 LD，使用 Gabor filter 者則標為 GF；濾波器寬度和高度皆呈倍數成長者
為 2W，高度固定，寬度成倍數成長者為 AB；使用第一組訓練資料者標 1 使用第二組者標
T2,而手動設計者則標上 MS。例如：GF2WT1 即表示 Gabor 濾波器對第一組測試資料使用 
2W 這種擺放方式來對正規化虹膜影像進行特徵抽取並經過 GA 訓練參數。訓練出來的參數
值如表 2-1. 
共 116 頁，第 34 頁 
 
Fig. 2-5 六組不同的 Gabor 濾波器組參數的 DET 曲線 
 
 
Fig. 2-6 六組不同的 LoG/DoG 濾波器組參數的 DET 曲線 
 
2.1-4 虹膜特徵抽取結語 
 經由實驗的驗證，可以知道我們提出的影像邊緣型別虹膜紋理描述法在辨識效果上可達
共 116 頁，第 36 頁 
許多。由此可見近紅外光灰階影像較適合進行瞳孔定位，而因東方人的虹膜在可見光的照明
下，虹膜區域呈現較暗沈的情況，與鞏膜區域的亮度值差異相當的大，所以可見光彩色影像
比起近紅外光灰階影像更容易且準確的定位虹膜邊界。此外可見光彩色影像中的上下眼瞼與
鞏膜間亮度的反差，比起近紅外光灰階影像來得更明顯，利用此特性，我們可以更方便準確
的定位上下眼瞼的位置。為了改進目前的取像系統均是以一個灰階或是彩色攝影機取得單張
受到均勻且足夠光源照射的虹膜影像的缺點，我們自行開發出一套可以克服上述缺點的取像
模組。 
 
Fig. 2-7 虹膜邊緣反差小的虹膜影像 
 
2.2-1 虹膜取像模組 
我們實驗室自行設計了一套能夠同時取得近紅線影像和可見光影像的雙 CCD 取像模
組。雙 CCD 取像模組是由一個灰階和一個彩色的高感度機板型攝影機所組成，如 Fig. 2-8 
所示，在兩個 CCD 攝影機之間，放置一片冷鏡 (Cold Mirror)，冷鏡可將通過 
共 116 頁，第 38 頁 
使得系統實際的取像距離約為 40 公分左右，經由此鏡頭所拍攝到的虹膜影像，直徑平均約
為 400 個像素左右。系統同時使用波長 700 nm 至 900 nm 的近紅外線光源與可見光光源
進行照明，近紅外線光源置於鏡頭下方約 5 公分處，可見光光源置於鏡頭兩側 15 公分處，
盡量減少使用者的不適感，同時避免若使用者穿戴眼鏡時，在眼鏡上造成不必要的反光雜
訊。並且在可見光光源前分別放置一片熱鏡 (Hot Mirror)，熱鏡可將可見光光源分為可見光
和近紅外線光，並讓可見光穿透過熱鏡且反射近紅外線光，以控制近紅外線攝影機的照度。 
為了讓使用者能夠快速的配合系統取像以及為了配合本計畫研究非正向視角虹膜影像
的特性，在第一年的計畫中，我們在使用者前方設置了六個 15 吋螢幕方便受測者在取像同
時，可以觀測到自己眼睛的狀態以利於系統取像，如 Fig. 2-10 所示。 
 
Fig. 2-10 舊有的系統硬體架構 
 
在之後更詳細的研究方面，我們額外在雙 CCD 攝影機下方設置一網路攝影機即時提供
使用者從螢幕中看見自己的眼睛是否位於系統可拍攝到的區域，進而自行調整頭部位置，並
且在鏡頭的後方擺設一個可以水平左右及垂直上下移動式 17 吋液晶螢幕，如 Fig. 2-11 所
示。由於欲取得非正向視角的虹膜影像供後續研究分析，在此我們使用下巴架協助使用者固
定頭部，盡可能將頭部移動量降至最低，再經由使用者注視螢幕上特定的點，接著移動螢幕
至不同位置以取得非正向視角的虹膜影像。 
共 116 頁，第 40 頁 
 由於組裝雙 CCD 攝影機時，無法將兩個 CCD 攝影機平面中心的法向量完全對準鏡頭
的光學軸。所以雙 CCD 攝影機影經過校正前，兩張影像上的相同特徵點的位置會有旋轉及
位移的情形發生。因此必需經由軟體修正的方式，來校正雙 CCD 攝影機所攝得的影像。由
於兩個 CCD 攝影機之間僅有一片冷鏡作為區隔，影像經過平面透鏡僅發生透射及反射的情
形，所以兩個影像之間的轉換關係可視為射影轉換式。假設攝影機的法向量與鏡頭光學軸平
行，則映射方式可簡化為仿射轉換式，這個映射方式可表示為一個 3×3 矩陣： 
11 12
21 22
1 0 0 1 1
x
y
x a a t x
y a a t y
′⎛ ⎞ ⎡ ⎤ ⎛ ⎞⎜ ⎟ ⎜ ⎟⎢ ⎥′ =⎜ ⎟ ⎜ ⎟⎢ ⎥⎜ ⎟ ⎜ ⎟⎢ ⎥⎝ ⎠ ⎣ ⎦ ⎝ ⎠
                       (16) 
我們使用校正板 (Fig. 2-12) 來計算上式中的六個未知參數。將兩台攝影機個別所拍攝到的校
正板影像，如 Fig. 2-13 所示，利用區塊分析法 (Blob Analysis) 分別求得兩個影像中相對應 
N 個圓點的中心座標位置，將其代入上式，可得到下列式子： 
 
Fig. 2-12 校正板 
 
共 116 頁，第 42 頁 
 
Fig. 2-14 經過校正的近紅外線灰階影像及可見光彩色影像 
 
 
Fig. 2-15 經過校正程序校正後的雙 CCD 攝影機所拍攝到的四頻譜虹膜影像 
 
 
2.2-3 系統軟體流程 
 整個流程圖如 Fig. 2-16 所示，系統一直保持在拍攝影像的狀態，當偵測到像瞳孔的物
體時，即利用 Tenengrad 方法來計算虹膜影像清晰程度。當虹膜影像清晰程度滿足我們的條
件時，則進行下一步的分析，反之，則返回到系統的初始狀態；接著進行活體偵測, 以防止
有心人士持偽造之虹膜影像冒用他人身份進入本系統，若通過活體偵測則進行下一步的運
算，反之，則返回系統的初始狀態。經過前面兩道手續，接著將所拍攝得的近紅外線灰階影
像及可見光彩色影像分別定出瞳孔邊界、虹膜邊界及上下眼瞼邊界，再將定位完的虹膜影像
作影像正規化，接著將正規化後的虹膜影像作特徵萃取，再依操作的狀態選擇註冊虹膜影像
共 116 頁，第 44 頁 
膜影像皆為正視的視角方便後續辨識，但在某些情況下所攝得的虹膜影像就無法適用於傳統
的辨識方法。因此，發展一套可適用於非正向虹膜影像與正向虹膜影像分析辨識的方法是必
須的。截至目前為止，僅有少數幾篇文獻討論及發展適用於非正向虹膜影像的辨識方法，以
下將列述重要的相關著作： 
1. Gaunt 等人提出如何收集非正向視角的虹膜影像並且定位出虹膜特徵的區域
[Gaunt05]。經由使用者正視近紅外線攝影機，接著移動使用者的眼睛至特定的點以
取得非正向視角虹膜影像。並且在位元平面 (Bit-plane) 上計算其區域統計值 
(Local Statistics) 以找出瞳孔的邊界與虹膜的邊界 [Bonney04]，進而定位出虹膜特
徵的區域，在他的文獻中並未提及辨識的結果。 
2. Dorairaj 等人提出對於非理想 (Non-ideal) 虹膜影像的辯識系統 [Dorairaj05]，該系
統設計處理非理想虹膜影像主要有兩個步驟：第一，評估視線注視的方向且應用射
影轉換式 (Projective Transformation) 轉換得到正向視角影像，利用兩個目標函數評
估視線方向：Hamming distance 與 Daugman 的圓型邊緣偵測濾波器，藉由所選擇
使用的目標函數得到的最佳值而決定視線的方向。第二，對於轉換後的正向視角影
像利用全域的獨立成份分析法 (Global Independent Component Analysis) 進行編碼。 
3. Abhyankar 等人提出一套利用雙正交小波網路 (Bi-orthogonal Wavelet Network, 
BWN) 的非正向視角虹膜辨識系統 [Abhyankar05]。他們假設非正向視角虹膜影像
的角度為已知, 再依據此已知的角度轉至正向視角虹膜影像進行辨識。測試的資料
是由所收集共 101 位受測者的 0° 、10° 、20° 的虹膜影像，經由仿射轉換和幾何
轉換 (Geometric Transform) 轉成其他角度的虹膜影像，再經由註冊多個角度的虹
膜影像，測試其系統辨識率。實驗結果證實他們所提出的方法可以成功辨識至 42° 
的虹膜影像。雖然註冊多個角度的虹膜影像有助於提昇辨識率，相對地，其計算時
間也會增加。 
不同視角間的虹膜影像，其眼球相較於正向視角的眼球有一旋轉量的差異，需經由轉換
式將不同視角的虹膜影像轉至正向視角, 以降低不同視角間虹膜影像的差異。本章節將介紹
如何利用雙 CCD 攝影機所攝得的近紅外線灰階影像及可見光彩色影像以更快速且正確的
共 116 頁，第 46 頁 
運算後的二值化影像，(d) 瞳孔定位的結果 
 
 
2.3-3 交錯偵測與活體偵測 
 由於大部分的機板型攝影機皆為交錯式掃描畫面 (Interlace Scanning Mode)，當眼睛處於
移動狀態下所拍攝得的影像，其影像將會產生動態模糊 (Motion Blur) 與交錯失序 
(Interlaced Disorder) 的影響，這對後續的辨識率影響甚大，因此，必須排除這類型的影像。
在正常情況下，瞳孔邊界的 x 座標可以看成是橢圓的函數，然而，當交錯失序嚴重到無法
忽略時，在 x 座標上一次微分的差值會造成像 Z 字形 (Zigzag) 般的高頻訊號。因此，計
算交錯失序的程度可表示成下列算式： 
1 1
2 2
( )( 1) ( )( 1)
H H
i i
I i i i i
i i
l l r rε − −
= =
= − − + − −∑ ∑                 (21) 
其中 H 為瞳孔區塊的列高，再者，依據瞳孔中心將瞳孔邊界分為左邊界與右邊界，li 與ri 分
別代表瞳孔左邊界與右邊界在第 i 列的 x 座標， Iε  即為左邊界與右邊界 x 座標一次微分
的差乘上 −1 的 i 次方的和相加，當 Iε  高於臨界值，則此影像的交錯失序程度不在我們
可接受的範圍內。理論上 Iε  的臨界值可經由瞳孔已知的形狀推導而得，但非正向視角的虹
膜影像其瞳孔的形狀未知。因此，其臨界值我們設為 2H，意思為當平均交錯失序程度大於 1 
個像素值，則排除此張虹膜影像。 
為了避免有心人士持偽造之虹膜影像冒用使用者身份侵入系統，在此我們依據系統所拍
攝得的近紅外線灰階影像與可見光彩色影像，其瞳孔中心的位置及縮放程度，以辨別真實的
眼睛或偽造的眼睛。 
 
2.3-4 仿射矯正 
 依據前述步驟求出瞳孔邊界的橢圓中心、長短軸及旋轉角度等參數，我們可以很容易的
建出仿射矯正 (Affine Rectification) 的幾何轉換式，如下列算式： 
1−T = RSR                           (22) 
共 116 頁，第 48 頁 
落於瞳孔中心的左方或是右方，分為屬於虹膜左邊界與右邊界的點。將左右邊界上的點
各自連接成數段平滑的線段，如 Fig. 2- 19 (c)，每段線段皆求出一正圓的函數。再依據
線段位於正圓邊上的區域，計算其分佈的角度範圍。接著限制其角度分佈的範圍，左邊
界限制的角度為 120 度至 240 度，右邊界限制的角度為 +/-60 度，並計算符合此一條
件之線段的長度，統計出左右兩邊各自最長的兩段線段。再由左邊界最長的兩段線段與
右邊界最長的兩段線段，兩兩求出一正圓函數，此時這一正圓函數再由分屬左右兩邊界
的所有線段投票，以選出最大票數之正圓函數，即為所求之虹膜邊界正圓函數，如 Fig. 
2- 19 (d)。 
 
Fig. 2- 19 (a) 可見光彩色影像，(b) 經過設定臨界值二值化並套用型態學運算元運算後的影
像，(c)經由區塊分析法並連接成數段平滑線段的影像，(d) 虹膜區域定位的結果。 
 
2. 另一方法，應用 Canny Edge Detector [Canny86] 在可見光彩色轉灰階影像上，以得到所
對應之邊的影像。如 Fig. 2- 20 (b)，限制其搜尋範圍為一倍的瞳孔半徑以外與五倍的瞳
孔半徑以內，在此一搜尋範圍內，去除一些如瞳孔邊界與光源亮點所造成的雜訊。再依
其 Canny Edge Detector 所求出的邊的方向，選擇垂直方向的邊，濾掉一些如眼瞼等雜
訊。接著利用 Support Vector Machine (SVM) [Fan05] 選出可能為虹膜邊界的點，如 Fig. 
2- 20 (c)。其特徵向量 (Feature Vector) 包含邊的強度以及出現在邊的左右兩側的四頻譜
共 116 頁，第 50 頁 
挑選出正確屬於虹膜邊界的點，再將挑選過的點所在的特徵向量丟給 SVM，以訓練出一組
訓練模型。接著由 SVM 使用訓練出來的模型篩選出可能為虹膜邊界的點，將篩選過後的點
套用 RANSAC 演算法求出一最適合眼瞼邊界的拋物線函數。Fig. 2-21 為定位出瞳孔邊界、
虹膜邊界與上下眼瞼邊界的虹膜影像。 
 
Fig. 2-21 完整定位出瞳孔區域、虹膜區域及上下眼瞼 
 
 
2.4 正規化虹膜影像與特徵抽取 
 從所拍攝得的虹膜影像中，我們可以清楚得看出不同人所拍攝得的虹膜影像，其瞳孔、
虹膜等特徵大小不盡相同。又因為瞳孔容易受到外界光線影響而收縮或放大，而改變其虹膜
區域的大小，即使同一個人同一地點，不同時間下所拍攝得的虹膜影像也不一定完全相同。
為避免此因素影響辨識系統的辨識率，我們對定位後的虹膜影像作正規化。再者，雖然虹膜
影像擁有豐富的資訊，但因其影像資料量大，直接比對正規化虹膜影像的速度偏慢，且需要
較多的記憶體。所以一般虹膜辨識系統皆需萃取虹膜影像內的特徵，來代表虹膜資訊，以此
降低計算所需的時間，再利用 NHD 計算兩兩虹膜影像的相似程度。本章節將介紹如何正規
化虹膜影像、對正規化後的虹膜影像作特徵萃取與 NHD。 
 
2.4-1 正規化虹膜影像 
 為了避免因瞳孔、虹膜等特徵大小的不同進而影響虹膜辨識系統的準確性，我們參考 
共 116 頁，第 52 頁 
 
2.5 虹膜辨識系統實驗結果 
此節將介紹使用本計畫中所設計的虹膜辨識系統所得到的實驗結果，並以這些結果來驗
證計畫中所提出的方法與推論。2.5-1 先介紹計畫中的實驗環境，包含使用平台和所收集的
虹膜影像資料庫。2.5-2 介紹評估實驗辨識結果的參數說明。2.5-3 將介紹本報告的實驗結果。 
 
2.5-1 實驗環境 
 本實驗系統的測試平台為 Pentium IV 3.4 G，記憶體容量為 1 GB，開發環境為Microsoft 
Windows XP Professional Edition，使用 Visual C++ 6.0 開發程式。我們使用雙 CCD 攝影機
共拍攝了 20 組共 10 人的虹膜影像。由於欲取得使用者不同視角的虹膜影像，我們採用下
巴架協助使用者固定頭部，將頭部移動量降至最低，接著使用者必需注視螢幕上特定的點，
再將螢幕移動至特定的位置，以取得不同視角的虹膜影像。每組虹膜資料中，皆包含了使用
者觀看十三個不同視角的虹膜影像，分別為 {-30°, -25°, -20°, …, 30°}，每個視角各紀錄了 8 
張的虹膜影像進行分析。所拍攝到的虹膜影像解析度為 640×480。每位使用者所拍攝的時間
約為 10 至 15 分鐘。從所收集的 8 張影像中，找出受到上下眼瞼遮蔽影響最小的影像做
為註冊影像，其餘影像做為測試影像，以進行分析。 
 
2.5-2 辨識結果參數說明 
  在本實驗室自行發展特徵抽取的方法 [Chou06]，使用基因演算法以求得 DoG 與 LoG 
最佳化參數。其 DoG 與 LoG 濾波器有四個維度大小，每一層濾波器皆比前一層濾波器大
四倍，最大的那層比最小的那層大六十四倍。分別置於正規化影像上的不同位置，組合而
成 2720 位元的 ETCode。計算兩兩 ETCode 的 NHD 時，允許 ETCode 可以左右旋轉 5 
度，以求得最小之 NHD。每組虹膜均有一張影像做為註冊影像，其餘的影像與註冊的影像
做比較，同一虹膜之間的比較結果為 Intra-class，不同虹膜之間的比較結果為 Inter-class。
在辨識結果的分佈範圍中，會設定一個臨界值，小於此數值則判斷此虹膜為合法使用者 
(Authentics)，若大於此數值則判斷為入侵者 (Imposters)。因此虹膜辨識系統的好壞可以由
共 116 頁，第 54 頁 
 
Fig. 2-24 Daugman 的方法與本篇論文所提出的第一種定位的方法其自動定位虹膜區域的均
分根誤差統計圖。 
 
第二個實驗為驗證本篇論文所提出虹膜區域定位的方法的準確性。利用雙 CCD 攝影機
所拍攝得的近紅外線灰階影像與可見光彩色影像，套用本篇論文所提出兩種虹膜區域定位的
方法，並分別與 Daugman 的圓型邊緣偵測濾波器作比較。使用手動定位的虹膜區域當參考
值，計算自動定位與手動定位的虹膜區域之均分根誤差，藉此判定定位的準確性。如 Fig. 
2-24，為分別使用 Daugman 的方法與本篇論文所提出的第一種虹膜區域定位的方法進行虹
膜區域定位所求之均分根誤差統計圖。經由實驗結果可看出，本篇論文所提出的第一種虹膜
區域定位的方法的準確性仍不理想，尤其在大角度的虹膜影像上， 虹膜區域定位的錯誤率
相當高。原因如同前述，大角度的虹膜影像其眼瞼遮蔽了部份虹膜區域，以至於影響定位的
準確性。其次，Fig. 2-25，為分別使用 Daugman 的方法與本篇論文所提出的第二種虹膜區
域定位的方法進行虹膜區域定位所求之均分根誤差統計圖。經由實驗結果可看出，本篇論文
所提出的第二種虹膜區域定位的方法可以準確的定位出虹膜區域，雖然在大角度的虹膜影像
上仍有少數未能精準定位的影像，原因也在於眼瞼遮蔽部份虹膜區域的問題，但總體看來效
果比 Daugman 的方法更精準。因此，所設計的辨識系統便採用本篇論文所提出的第二種定
位的方法進行虹膜區域定位。 
共 116 頁，第 56 頁 
 
Fig. 2-26 正視視角的辨識結果。 
 
 
Fig. 2-27 右方視角的辨識結果。 
 
共 116 頁，第 58 頁 
 
Fig. 2-30 右上方視角的辨識結果。 
 
 
Fig. 2-31 左上方視角的辨識結果。 
 
 
 
 
共 116 頁，第 60 頁 
 
Fig. 2-32 相同虹膜，正視視角和右方視角間 NHD 的分佈情形。 
 
 
Fig. 2-33 相同虹膜，正視視角和左方視角間 NHD 的分佈情形。 
 
共 116 頁，第 62 頁 
 
Fig. 2-36 相同虹膜，正視視角和左上方視角間 NHD 的分佈情形。 
 
 
Fig. 2-37 相同虹膜，右方視角和左方視角間 NHD 的分佈情形。 
 
共 116 頁，第 64 頁 
 
Fig. 2-40 相同虹膜，右方視角和左上方視角間 NHD 的分佈情形。 
 
 
Fig. 2-41 相同虹膜，左方視角和正上方視角間 NHD 的分佈情形。 
 
共 116 頁，第 66 頁 
 
Fig. 2-44 相同虹膜，正上方視角和左上方視角間 NHD 的分佈情形。 
 
 
Fig. 2-45 相同虹膜，正上方視角和右上方視角間 NHD 的分佈情形。 
 
共 116 頁，第 68 頁 
 
Fig. 2-47 不同視角間虹膜影像的 EER。 
 
再者，分別使用本報告所提出的第二種定位的方法及 Daugman 的方法，進行後續特徵萃
取、比對分析，以比較兩者辨識率的優劣。使用本報告所提出的第二種定位的方法所得到的
不同視角的註冊影像與測試影像比對結果，如 Fig. 2-48，與使用 Daugman 的方法所得到的
不同視角的註冊影像與測試影像比對結果，如 Fig. 2-49，縱軸為系統所註冊虹膜影像的角
度，橫軸為虹膜影像測試的角度。觀察實驗的結果，本報告所提出的第二種定位的方法在所
註冊虹膜影像的角度 [-20°, 20°] 範圍內，其 EER 介於 0.01% 至 1%，而 Daugman 的方
法其 EER 為 0.01% 至 2%。因此，我們發現虹膜區域定位的準確性影響著辨識系統的辨識
率。 
共 116 頁，第 70 頁 
 
 
-30 度 0 度 +30 度 
 
 
 
-30 度 0 度 +30 度 
 
 
共 116 頁，第 72 頁 
共 116 頁，第 74 頁 
 
Fig. 10 使用者在使用視線追蹤介面原型系統的情形。 
 
Fig. 11 視線追蹤系統計算所得的瞳孔中心以及三個近紅外線 LED 在角膜上形成的反射亮
點。 
由於台灣學生大部份患有近視，使得未載眼鏡者不易尋覓，無法找到足夠多的受測者。
因此在第二年的計畫中，我們提早實現改進視線追蹤的方法使之能適用於載眼鏡者的視線追
蹤應用上。為了要取得使用者穩定的視線，我們利用同軸（光源在鏡頭上）及異軸（光源偏
離攝影機）的紅外線光源照明取像設備，如 Fig. 3-4 所示。攝影機同時取得的白色及黑色的
共 116 頁，第 76 頁 
 
 
Fig 3-5 上左為同軸光所取得的影像，上右為異軸光所取得的影像，下左為相減的結果，而下右則為眼睛追蹤
結果。 
 
Fig 3-6 視線簽名時追蹤到的視線軌跡 
 
為改善第二年系統的缺點，我們使用 [Shih00] [Shih03] 中所發展出來的理論，在單攝影
機的架構下進行視線追蹤的分析。 
 
3.1 單攝影機三維視線追蹤原理與模擬 
在 Shih and Liu [Shih00] 的研究裡，利用兩部攝影機與兩個以上的發光二極體 (LEDs)，
已經成功推導出一套線性系統，可計算出使用者的角膜曲率中心以及眼球光學軸。在此，我
們將以他們推導的角膜反射亮點成像模型與 Ohno et al. 推導的瞳孔特徵成像模型 [Ohno02] 
為基礎，僅利用單一攝影機與兩個以上的 LEDs，發展一套非線性視線追蹤系統。而非線性
求解的部分，我們使用數值方法來求得近似解。 
共 116 頁，第 78 頁 
與角膜曲率半徑 ρ 之間的非線性關係 Ri ( Ri 不等於 R)。 
z Fig. 3-9 表示角膜曲率中心 P1 的三維座標與角膜曲率半徑 ρ 之間的非線性關係，當 
Ri 不等於 R 時，會相交於一點 A，A 所對應的座標即為我們要求的角膜曲率中心三
維座標 P1 與角膜曲率半徑 ρ。 
1
0
01
( )
( )s
f s
f ss
ρρ ⎛ ⎞⎛ ⎞ = ⎜ ⎟⎜ ⎟⎝ ⎠ ⎝ ⎠
R =                         (31) 
1 1
0 0
s P
s P
=
=  
0 0 02 sin( ) sin( 2 ) 4 sin( 2 )
2(cos(2 ) cos(2 ))
s s sθ θ γ ψ θ γρ θ γ
− − + − += +  
2
0 0 0 0
1 2
cos( ) ( cos(2 2 ) cos(2 2 ) 2( 4sin( ) ))
(cos(2 ) cos(2 ))
s s s ss θ θ γ θ γ θ ψθ γ
− + + + += +  
2 2 2 2
0 cos( ) cos( ) sin( )sψ θ γ γ=  
0
0
sin( )arctan
cos( )
s
L s
αβ α
⎛ ⎞= ⎜ ⎟−⎝ ⎠
 
 
Fig. 3-8 角膜曲率中心 P1 與角膜曲率半徑 ρ 的非線性關係。 
 
共 116 頁，第 80 頁 
以這些向量會形成一個以穿過真實瞳孔中心的向量為轉軸的橢圓錐體(Elliptic Cone)，此
時，此轉軸與眼球光學軸並不重疊，但卻會相交於真實瞳孔中心。 
 
Fig. 3-10 折射前後的瞳孔特徵向量以及角膜中心。 
 
z 從模擬程式設定的眼球光學模型可知：真實瞳孔平面必定會與眼球光學軸垂直，並相交
於真實瞳孔中心。因此，如 Fig. 3-11 我們要找出一個以眼球光學軸為法向量的平面 (I、
II、III)，此平面與前述之 (橢) 圓錐體的交集須是一正圓，則此正圓即為真實瞳孔平面，
其圓心 (Pi、Pii、Piii) 即是真實瞳孔中心。 
共 116 頁，第 82 頁 
 
Fig. 3-12 誤差函數 σ 的分布。 
 
 
Fig. 3-13 在真實 s1 與 ρ 附近誤差函數 σ 的分布情況。 
 
我們將 s1、ρ、σ 之間的關係畫出來，如 Fig. 3-12，其中真實的 s1 為 495.7mm，真實
的 ρ 為 8mm。從誤差函數的定義來看，當 s1 = 495.7mm、ρ = 8mm 時，σ 會有最小值。為
了一探究竟，我們將 σ 在真實的 s1、ρ 附近的分布，用等高線圖放大表示。如 Fig. 3-13 所
共 116 頁，第 84 頁 
訊干擾而造成誤差；因此在擺設點光源時，應調整點光源位置，使得 ω 越大越好。 
 
 
Fig. 3-15 當 s1 或 ρ 為真實的值，另一個的變化與 σ 的關係。 
 
3.2-3 視角與瞳孔輪廓方位角之關係 
 在計算視線部份，原本系統的原理是以貼合最佳之正圓的方法來尋找瞳孔中心三維座標; 
然而在雜訊的干擾下，此方法也會造成誤差。因此，我們試著找出視角與瞳孔輪廓方位角之
間的關係，利用此關係來降低雜訊造成的影響。在這一節裡的視角指的是：角膜曲率中心至
攝影機原點之向量與角膜曲率中心至螢幕上視線點之向量之夾角 η；而瞳孔輪廓方位角即
是： arccos Minor axis
Major axis
ζ ⎛ ⎞−= ⎜ ⎟−⎝ ⎠  
 利用數值方法可得到 Fig. 3-16，當使用者頭部固定，即眼球中心固定在攝影機座標系下
的 (0, 0, 500) 時，視角 η 與瞳孔輪廓方位角 ζ 之間會呈現一對一的關係。也就是說，我們
可以先透過使用者校正程序來將此關係建表，接著利用影像上貼合出來的瞳孔輪廓橢圓的方
位角，經由查表可以得到視角，而角膜曲率中心三維座標為已知，如此即可求出使用者的視
線。 
 當使用者頭部在 x±200mm、y±150mm、z±100mm 的範圍內移動時，視角 η 與瞳孔輪
廓方位角 ζ 的關係如 Fig. 3-17。將其局部放大得到 Fig. 3-18，可知利用查表法來推算視角
的角度誤差約小於 0.1 度。因此，利用視角與瞳孔輪廓方位角之關係來計算視線仍然是可以
共 116 頁，第 86 頁 
 
Fig. 3-18 頭部在 x±200mm、y±150mm、z±100mm 的範圍內移動時， 
視角 η 與瞳孔輪廓方位角 ζ 關係的局部放大圖。 
 
3.3 單攝影機三維視線追蹤之模擬結果 
3.3-1 模擬模型與參數設定 
 我們在模擬程式中使用的無失真針孔相機模型設定如下：感光元件 (CCD) 的水平與垂
直解析度 W×H 為 640×480，單位為像素 (Pixel)；而感光元件中最小單元的水平 (du) 與垂
直 (dv) 距離皆設定為 9.8 μm；攝影機光軸相交於感光元件上的點 (Principal Point) 座標 (u0, 
v0) 為 (320, 240)；至於攝影機的有效焦長 f (Effective Focal Length) 則設為 80 mm。另外，
我們將電腦螢幕座標系設定為世界座標系，世界座標系與攝影機座標系之間的旋轉矩陣 R 
只包含對 x 方向作 30 度 (degree) 的旋轉，位移向量 t 則設定為(-150, 75, -20)。 
在眼球模型方面，我們將角膜表面近似成曲率半徑為 8 mm 的光滑球面的一部分。從角
膜表面至此球心 (即角膜曲率中心) 的介質包括角膜、水樣液、水晶體，雖然每一種介質的
折射率皆不相同，但在此簡化眼球模型中，角膜表面至角膜曲率中心之折射率可以等效地用 
1.336 來近似。另外，眼球也簡化成一圓球，其曲率半徑設為 12.5 mm；瞳孔則簡化為一正
圓平面，圓心即瞳孔中心，且圓心至角膜曲率中心的連線會垂直於瞳孔平面，我們將瞳孔中
心至角膜曲率中心的距離設為 5 mm。雖然，瞳孔會隨著外在光線的強弱而縮放，我們將其
半徑假定為 2.26 mm。並將虹膜半徑設定為 5.88 mm，而因為虹膜外圈已在角膜邊緣與鞏膜
銜接處，故不對虹膜外圈作折射運算。 
共 116 頁，第 88 頁 
放 10×10×10 個點光源，每次任選其中兩個點光源即可找到各自在 A 的切線向量 V1、V2，
以及其夾角 ω。我們使用暴力搜尋法來找出使得 ω 最大的那一對點光源，然而，結果如 Fig. 
3-23 所示，最大的 ω 也只有 0.7755 degree；而當我們只在攝影機座標系下 z = 0 之 x—y 
平面上搜尋時，最大之 ω 甚至不到 0.1 degree。所以可得到一結論：點光源之擺設對於單
攝影機三維視線追蹤系統抵抗雜訊干擾的能力並無顯著的幫助。 
 
Fig. 3-20 模擬點光源之擺設。 
 
3.3-3 無雜訊之模擬 
3.3-3-1 眼睛特徵之模擬 
 Figure 3-21 是我們使用上述之參數設定得到的真實眼睛特徵三維模型；Fig. 3-22 與 Fig. 
3-23 則是我們模擬程式套用上述的成像原理與模型而產生的眼睛特徵影像。其中角膜反射亮
點、瞳孔輪廓以及瞳孔中心這三種眼睛特徵，將是我們拿來測試與驗證單攝影機三維視線追
蹤方法的原始資料。 
共 116 頁，第 90 頁 
 
Fig. 3-23 模擬眼球球心座標在 (−5, −10, 500) (In CCS)，視線凝視攝影機原點的眼睛特徵。 
 
3.3-3-2 無雜訊單攝影機三維視線追蹤之模擬 
 在無雜訊干擾的情況下，我們使用 MATLAB 裡的非線性最佳化程式 lsqnonlin，可以
精確地求得角膜曲率中心三維座標以及角膜曲率半徑的大小。接著計算瞳孔中心三維座標，
我們先利用 Fitzgibbon [Fitzgibbon99] 貼合橢圓的演算法來做貼合，再利用貼合出來的橢圓
長短軸比來做為測量真圓度 (Roundness) 的依據，以求得最佳正圓的瞳孔平面。如 Fig. 
3-24，搜尋到第 8 次時找到最佳正圓。求得瞳孔中心之後，角膜曲率中心與此瞳孔中心的連
線即是眼睛光學軸，結果如 Fig. 3-25，從圖中也驗證了單攝影機三維視線追蹤技術的正確性
與可行性。 
 
Fig. 3-24 搜尋正圓時，以橢圓作貼合的結果，其中在第 8 次找到最佳正圓。 
 
共 116 頁，第 92 頁 
 這一節裡，我們模擬利用猜測角膜曲率半徑 ρ 來計算角膜曲率中心三維座標的方法之
系統誤差。Fig. 3-27 為僅對影像上角膜反射亮點特徵加雜訊干擾的模擬結果、Fig. 3-28 是僅
對點光源之三維座標定位加雜訊干擾之系統誤差模擬結果、Fig. 3-29 是同時對影像上角膜反
射亮點以及瞳孔輪廓特徵加雜訊干擾之系統誤差模擬結果、Fig. 3-30 則是同時對點光源之三
維座標定位、影像上角膜反射亮點以及瞳孔輪廓特徵加雜訊干擾之系統誤差模擬結果。由這
些圖可得知，在半徑 ρ 猜錯 ±0.5 以內時，系統平均誤差才會在允許範圍內。這部份我們可
以藉由調整猜測的 ρ 值，來找出使得系統平均誤差最小的 ρ。然而，當加在瞳孔輪廓特徵
上的雜訊其 Noise Level 大於 0.5 時，會使得整體系統誤差呈現劇烈變化，這再次顯示我們
原始的追蹤方法裡計算視線的部分很容易受雜訊干擾。 
 
 
Fig. 3-26 僅對影像上瞳孔輪廓特徵加雜訊干擾之系統誤差模擬結果。 
共 116 頁，第 94 頁 
  
Fig. 3-29 同時對影像上角膜反射亮點以及瞳孔輪廓特徵加雜訊干擾之系統誤差模擬結果。 
 
 
Fig. 3-30 同時對點光源之三維座標定位、影像上角膜反射亮點以及瞳孔輪廓特徵加雜訊干擾
之系統誤差模擬結果。 
 
3.3-4-3 猜測角膜曲率半徑 ρ 並利用視角與瞳孔方位角關係之視線追蹤系統誤 
差模擬結果 
 在利用視角與瞳孔方位角關係的方法中，我們首先要求使用者凝視螢幕上的數個點來做
校正；經由校正可得到在這些點上的視角與瞳孔方位角之關係 (參見 Fig. 3-31 )，再利用線
性內插與外推即可得到視角與瞳孔方位角的關係表。如此，我們就能在計算出影像上瞳孔輪
廓的方位角之後，使用查表法來找出相對的視角，就能算出視線。 
共 116 頁，第 96 頁 
 
Fig. 3-33 視線採用查表法時，僅對影像上角膜反射亮點特徵加雜訊干擾之系統誤差模擬結
果。 
 
 
Fig. 3-34 視線採用查表法時，僅對點光源之三維座標定位加雜訊干擾之系統誤差模擬結果。 
 
共 116 頁，第 98 頁 
Iris Image Acquisition System
1 32
4 65
 
Fig. 3-36 使用視線輸入密碼的示意圖。 
 
使用視線輸入密碼的示意圖如 Fig. 3-36 所示。我們在牆壁上面標示出 1~6 的阿拉伯數
字，其中 1~3 為仰角約為 30 度所看到的數字，4~6 為眼睛直視正前方時所看到的數字，
並在數字 2 和 5 正下方擺放虹膜影像取像設備。由於這六個數字間隔足夠大，所以當我們
在看這幾個數字時，觀察到眼睛的變化量很大，所以可以設計較為簡單又強健的方法來追蹤
視線。 
由於瞳孔的位置可由近紅外線影像中估算之，以估算所得的瞳孔中心為基準，在虹膜影
像的瞳孔中心上、下、左、右切出四個區塊 (分別為圖中的 1、2、3、4)，這四個區塊的大
小可由試誤法決定之。由下面的圖可以知道，當視角為觀看左手邊時，在 1 這區塊中眼白
的部份會較小，而在第 3 區塊的眼白部份會相對來的多；相對地，當眼睛在看右手邊時，在 
1 這區塊中眼白的部份會較多，3 這區塊的眼白部份會較小。當眼睛直視正前方時，眼球左
右兩邊的眼白部份則分佈的較為平均。當眼睛看的視角為上方時，4 這塊區域的眼白部份會
變相對很多。 
共 116 頁，第 100 頁 
四、結論---主要研究成果與計畫成果自評 
在這三年期的計畫中我們的主要目標有兩個，第一個是完成以動態虹膜資訊作身份確認
之研究，第二則是完成視線簽名的研究。在本研究中，我們自行研製一套全新的四頻譜虹膜
取像系統。由這個取像系統可取得完整的虹膜動態資訊，再由這些瞳孔的縮放及眼球的轉動
中，我們可以初步估算出活體偵測結果。而在虹膜辨識系統方面，我們在第一年中由重現當
時最佳的 Daugman 技術著手。但是因為文獻記載中忽略掉了許多實作上的細節，而有些細
節其實會嚴重地影響實驗結果。我們在努力了一年之後在設定零錯誤接受率的條件下，只能
達到 4.54% 的錯誤拒絕率，因此在第一年中的研究成果並不是十分理想。在第二年中，我
們累積的經驗與理論，足以解開 Daugman 沒有寫在論文中的技術細節。此時即可輕易達到
與 Daugman 相同程度的辨識精確度。同年中，我們也開發出自己的虹膜分析理論，並據以
發展出一套在效率與精確度上都與 Daugman 方法相同的虹膜辨識系統。在本計畫的第三年
中，我們則是專心致力於多視角虹膜分析。在另一方面，我們也同時研發視線追蹤裝置，在
第一年中，我們先採用立體視線追蹤系統，但是由於這套系統不能用於追蹤載眼鏡人員的視
線，所以在第二年中，我們另外開發了一套單眼的視線追蹤系統。在這套單眼的視線追蹤系
統中，我們開發了一套以 HMM 為核心的視線簽名辨識系統。而後，我們更進一步將幾何
光學的理論引入這套單眼視線追蹤系統中，並將以單攝影機作視線追蹤的理論建好。在第三
年中則是進行大量的電腦模擬，分析以單攝影機作視線追蹤的優缺點。最後，我們的結論是
使用單攝影機作視線追蹤，其結果容易受雜訊影響，而且對使用者的頭部移動仍然顯得相當
敏感。所以在第三年中，我們也結合多視角虹膜定位系統，研發一套粗略但是限制較少的視
線密碼系統，用以取代視線簽名。茲將在這三年期的計畫中獲得的具體成果分為視線簽名與
虹膜辨識條列於下： 
1. 視線簽名： 
(a) 完成眼睛光學模型模擬程式，可計算在角膜內部的光點及眼睛外部光點的成像位
置。 
(b) 基於幾何光學原理，發展一套僅使用單一攝影機且適用於載眼鏡者的視線追蹤方
共 116 頁，第 102 頁 
使用者必須依據他所看到的影像來調整其頭部的方位，以取得適當的虹膜影像。 
(d) 利用這個雙 CCD 的取像系統，我們建立了由 14 個方向拍攝 116 組虹膜的多視
角虹膜影像資料庫。依生物特徵資料庫的建構標準，這組資料庫的取樣時間點共兩
段，中間間隔平均一個月左右。 
(e) 由於多視角的虹膜影像中包含許多 Daugman 在設計他的方法時沒有料到的狀
況，所以使用 Daugman 的虹膜定位方法失敗率非常高。因此我們也自行利用四頻
譜的虹膜影像發展出自動化的多視角虹膜定位系統。經過實際驗証，我們的方法與
人工手動定位的結果幾乎一致。 
(f) 發展多視角的虹膜辨識系統，將虹膜辨識系統對正對視角的限制降低。使得在 +/-20 
度內取得的虹膜影像皆可用於高精確度虹膜辨識。 
 
在這多年期的計畫中，我們共發表了四篇國際會議論文以及三篇國內的會議論文： 
1. Wen-Shiung Chen, Kun-Huei Chih, Sheng-Wen Shih and Chih-Ming Hsieh, “Personal 
Identification Technique based on Human Iris Recognition with Wavelet Transform,” 
Proceedings of the IEEE International Conference on Acoustic, Speech, and Signal Processing, 
March 18-25, 2005, Philadelphia, vol. 2, pp. 949-952. 
2. Wen-Shiung Chen, Kun-Huei Chih, Sheng-Wen Shih and Chih-Ming Hsieh, “Personal 
Identification with Human Iris Recognition based on Wavelet Transform,” Proceedings of the 
IAPR Conference on Machine Vision Applications, May 16-18, 2005, Tsukuba Science City, 
Japan, pp. 351-354. 
3. Chia-Te Chou, Sheng-Wen Shih, Wen-Shiung Chen and Victor W. Cheng, “Iris Recognition 
with Multi-Scale Edge-Type Matching”, International Conference on Pattern Recognition , 
Auguest 20-24, 2006, Hong Kong, China, vol. 4, pp. 545-548. 
4. Chia-Te Chou, Sheng-Wen Shih and Duan-Yu Chen, “Design of Gabor Filter Banks for Iris 
Recognition,” to appear in Proceedings of the IEEE International Conference on Intelligent 
Information Hiding and Multimedia Signal Processing, Pasadena, California, USA, 2006. 
共 116 頁，第 104 頁 
共 116 頁，第 106 頁 
312-316, 2001. 
[Boles97] W.W. Boles, “A security system based on human iris identification using wavelet 
transform,” Proceedings of the First International Conference on Knowledge-Based 
Intelligent Electronic Systems, Vol. 2, pp. 533-541, 1997. 
[Bonney04] B. Bonney, R. W. Ives, D. M. Etter, and Y. Du, “Iris pattern extraction using bit-plane 
analysis,” in Proceedings of the IEEE 38th Annual Asilomar Conference on Signals, 
Systems, and Computers, Vol. 1, pp. 582-586, 2004. 
[Bouis97] Bouis, http://www.algonet.se/~eyetrace/, 1997. 
[Bour97] L. Bour, “DMI—Search Scleral Coil,” Dep. of Neurology, Clinical Neurophysiology, 
H2-214, Academic Medical Centre, AZUA, Meibergdreef 9, 1105AZ Amsterdam, 
Netherlands, 1997. 
[Brault93] J.J. Brault, and R. Plamondon, “A complexity measure of handwritten curves: modeling 
of dynamic signature forgery,” IEEE Transactions on Systems, Man, and Cybernetics, 
Vol. 23, No. 2, pp. 400-413, 1993. 
[Bruce90] V. Bruce, and P.R. Green, Visual Perception: physiology, psychology and ecology, 
Second Edition, Lawrence Erlbaum Associates Ltd., Hove, UK, 1990. 
[Camus02] T.A. Camus, and R. Wildes, “Reliable and fast eye finding in close-up 
images,”Proceedings of the International Conference on Pattern Recognition, pp. 
389-394, 2002. 
[CASIA] http://www.sinobiometrics.com/. 
[Canny86] J. Canny, “A Computational Approach to Edge Detection,” IEEE Transactions on 
Pattern Analysis and Machine Intelligence, Vol. 8, No. 6, Nov. 1986. 
[Chen01] Yong-Sheng Chen, Sheng-Wen Shih, Yi-Ping Hung, and Chiou-Shann Fuh, 2001, 
“Simple and Efficient Method of Calibrating a Motorized Zoom Lens,” Journal of Image 
and Vision Computing, Vol. 19, No. 14, pp.1099-1110, 2001. 
[Chen01a] W.-S. Chen and S.-Y. Yuan, “An automatic iris recognition system based on fractal 
共 116 頁，第 108 頁 
active camera,” Proceedings of the Third IEEE International Workshop on Visual 
Surveillence, pp. 11-18, 2000. 
[Corn73] T.N. Cornweet, and H.D. Crane, “Accurate two-dimensional eye tracker using first and 
fourth Purkinje images,” Journal of Optical Society America, Vol. 63, No. 8, 1973. 
[Daugman88] J. Daugman, “Complete Discrete 2-D Gabor Transform by Neural Networks for 
Image Analysis and Compression,” IEEE Transactions on Signal Processing, Vol. 36, No. 
7, pp. 1169-179, 1988. 
[Daugman93] J. Daugman, “High Confidence Visual Recognition of Persons by A Test of 
Statistical Independence,” IEEE Transactions on Pattern Analysis and Machine 
Intelligence, Vol. 15, No. 11, pp. 1148-1161, 1993. 
[Daugman94] J. Daugman, “Biometric personal identification system based on iris analysis,” U.S. 
Patent 5 291 560, 1994. 
[Daugman01] J. Daugman, “High confidence recognition of persons by iris patterns,” IEEE 35th 
International Carnahan Conference on Security Technology, pp. 254-263, 2001. 
[Daugman01a] J. Daugman, “The importance of being random: Statistical principles of iris 
recognition,” Pattern Recognition, Vol. 36, No. 2, pp. 279-291, 2001. 
[Daugman02] J. Daugman, “How iris recognition works,” Proceedings of the International 
Conference on Image Processing, Vol. 1, pp. 33-36, 2002. 
[DbaSys97] “626 PC Eye Tracker,” DBA Systems, Inc., 1200 South Woody Bruke Road, 
Melbourne, FL 329302-0550, USA, 1997. 
[Dgbas] 行政院主計處 2004. http://www.dgbas.gov.tw/. 
 
[Dorairaj05] V. Dorairaj, N. A. Schmid, and G. Fahmy, “Performance evaluation of non-ideal iris 
based recognition system implementing global ICA encoding,” in Proceedings of the 
IEEE International Conference on Image Processing, Vol. 3, pp. 285-288, 2005. 
[Duda73] R. O. Duda and P. E. Hart, Pattern Classification and Scene Analysis. New York: Wiley, 
共 116 頁，第 110 頁 
[Goddard94] A. Goddard, “Disappointing verdict on signature software,” New Scientist, vol. 142, 
p. 20, 1994. 
[Harmon81] L.D. Harmon, M.K. Khan, R. Lasch, and P.F. Ramig, “Machine identification of 
human faces,” Pattern Recognition, Vol. 13, pp. 97-110, 1981. 
[Heisele02] B. Heisele, T. Serre, M. Pontil, T. Vetter and T. Poggio, “Categorization by Learning 
and Combining Object Parts,” Advances in Neural Information Processing Systems 14, 
Vancouver, Canada, Vol. 2, 1239-1245, 2002. 
[Ho94] T. K. Ho, J. J. Hull, and S. N. Srihari, “Decision combination in multiple classifier 
systems,” IEEE Transactions on Pattern Analysis and Machine Intelligence, Vol. 16, pp. 
66-75, 1994. 
[Holmes91] J. P. Holmes, L. J. Wright, and R. L. Maxwell, “A performance evaluation of biometric 
identification devices,” Sandia National Laboratories, Albuquerque, NM, Tech. Rep. 
SAND91-0276, 1991. 
[Huang95] K. Huang and H. Yan, “On-line signature verification based on dynamic segmentation 
and global and local matching,” Optical Engineering, Vol. 34, No. 12, pp. 3480-3488, 
1995. 
[Huang04] J. Huang, Y. Wang, T. Tan, and J. Cui, “A new iris segmentation method for 
recognition,” Proceedings of the 17th International Conference on Pattern Recognition, 
2004. 
[Hutch89] T.E. Hutchinson, K.P. White, Jr., W.N. Martin, K.C. Reichert, and L.A. Frey, 
“Human-computer interaction using eye-gaze input,” IEEE Transactions on Systems, 
Man and Cybernetics, Vol. 19, No. 6, pp. 1527-1534, 1989. 
[Huttenlocher93] D.P. Huttenlocher, G.A. Klanderman, W.J. Rucklidge, “Comparing images using 
the Hausdorff distance,” IEEE Transactions on Pattern Analysis and Machine 
Intelligence, Vol. 15, No. 9, pp. 850-863,1993. 
[Jacob91] R.J.K. Jacob, “The use of eye movements in human-computer interaction techniques: 
共 116 頁，第 112 頁 
Princeton University Press, 1994. 
[Mann50] I. Mann, The Development of the Human Eye. New York: Grune and Stratton, 1950. 
[Martens97] R. Martens, and L. Claesen, “Dynamic programming optimisation for on-line 
signature verification,” Proceedings of the Fourth International Conference on 
Document Analysis and Recognition, pp. 653-656, 1997. 
[Masek03] L. Masek and P. Kovesi, “Recognition of Human Iris Pattern for Biometrics 
Identification,” In The School of Computer Science and Software Engineering, The 
University of Western Australia, 2003, 
http://www.csse.uwa.edu.au/~pk/studentprojects/libor/. 
[McDo81] J.D. McDonald, and A.T. Bahill, “An Adaptive Control Model for Human Tracking 
Behavior,” IEEE Proceedings of the International Conference on Cybernetics and 
Society, pp. 269-273, 1981. 
[Miller94]  B. Miller, “Vital signs of identity,” IEEE Spectrum, Vol. 31, No. 2, pp. 22-30, 1994. 
[Mohamed00] M.A. Mohamed, and P. Gader, “Generalized hidden Markov models. I. Theoretical 
frameworks,” IEEE Transactions on Fuzzy Systems, Vol. 8, No. 1, pp. 67-81, 2000. 
[M-Pereda99] J.A. Martin-Pereda, C. Sanchez-Avila, and R. Sanchez-Reillo, “Minimal template 
size for iris-recognition,” Proceedings of the First Joint BMES/EMBS Conference, vol. 2, 
pp. 972, 1999. 
[Muller93] P.U. Muller, D. Cavegn, G. d’Ydewalle, and R. Groner, “A comparison of a new limbus 
tracker, corneal reflection technique, purkinje eye tracking and electro-oculography, in G. 
d’Ydewalle and J.V. Rensbergen, eds, “Perception and Cognition,” Elsevier Science 
Publishers, B.V., pp. 393-401, 1993. 
[Nalwa97] V.S. Nalwa, “Automatic on-line signature verification,” Proceedings IEEE, Vol. 85, No. 
2, pp. 215-240, 1997. 
[Ohno02] T. Ohno, N. Mukawa, and A. Yoshikawa, “Freegaze: a gaze tracking system for 
everyday gaze interaction,” in Proceedings of the symposium on ETRA 2002: Eye 
共 116 頁，第 114 頁 
[Shih98b] S.-W. Shih, Y.-P. Hung, and W.-S. Lin, “New Closed-Form Solution for Kinematic 
parameter Identification of a Binocular Head Using Point Measurements,” IEEE 
Transactions on Systems, Man, and Cybernetics, Vol. 28, No. 2, pp. 258-267, 1998. 
[Shih00] S.-W. Shih., Y.-T. Wu, and J. Liu, “A Calibration Free Gaze Tracking Technique,” 
Proceedings of the International Conference on Pattern Recognition, 2000, Vol. 4, pp. 
201-204. 
[Shih03] Sheng-Wen Shih and Jin Liu, “A Novel Approach to 3-D Gaze Tracking Using Stereo 
Cameras,” IEEE Transactions on Systems, Man and Cybernetics, Part B, Vol. 34, pp. 
234-245, 2004. 
[Spors01] S. Spors and R. Rabenstein, "A real-time face tracker for color video," Proceedings of 
the IEEE International Conference on Acoustics, Speech, and Signal Processing, Vol. 3, pp. 
1493-1496, 2001. 
[Sun05] Z. Sun, Y. Wang, T. Tan, and J. Cui, “Improving iris recognition accuracy via cascaded 
classifiers,” IEEE Transactions on Systems, Man and Cybernetics, Part C, Vol. 35, pp. 
435-441, 2005. 
[Tello88] E.R. Tello, “Between man and machine,” BYTE, pp. 288-293, 1988. 
[Toennies02] K. Toennies, F. Behrens, M. Aurnhammer, “Feasibility of Hough-Transform-Based 
Iris Localisation for Real-Time-Application,” Proceedings of the IAPR International 
Conference on Pattern Recognition, pp. 1053-1056, 2002. 
[Tsai87] R.Y. Tsai, “A Versatile Camera Calibration Technique for High-Accuracy 3D Machine 
Vision Metrology Using Off-the-Shelf TV Cameras and Lenses,” IEEE Journal of 
Robotics and Automation, Vol. 3, No. 4, pp. 323-344, 1987. 
[Ueda00] N. Ueda, “Optimal linear combination of neural networks for improving classification 
performance,” IEEE Transactions on Pattern Analysis and Machine Intelligence, Vol. 22, 
pp. 207-213, 2000. 
[Vatsa04] M. Vatsa, R. Singh, and P. Gupta, “Comparison of Iris Recognition Algorithms,” 
