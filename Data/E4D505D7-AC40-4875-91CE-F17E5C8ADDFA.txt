 i 
 
目錄 
 
一、目錄……………………………………………………… i 
二、報告內容…………………………………………………1 
三、計畫成果自評………………………………………….. 11 
 
 
 
 
 
Journal of Biomedical Science 2009, 16:25 http://www.jbiomedsci.com/content/16/1/25
Page 2 of 10
(page number not for citation purposes)
logical insight between genes. Several kinds of rules have
been successfully developed in different subjects of
molecular biology. In our earlier studies, decision rules
based on decision tree algorithms have been effectively
extracted from the thermodynamic database of proteins
and mutants to explore potential knowledge of protein
stability prediction [11-13]. On the other hand, associa-
tion rule techniques can also reveal relevant associations
between different items. Borgelt and Berthold [14] pre-
sented an algorithm to find fragments in a set of mole-
cules that help to discriminate between different classes of
activity in a drug discovery context. Oyama et al. [15] pro-
posed a data mining method to discover association rules
related to protein-protein interactions. Moreover, associa-
tion rules which demonstrate diverse mutations and
chemical treatments have been reported from 300 gene
expression profiles of yeast [16]. Carmona-Saez et al. [17]
have offered an approach which integrates gene annota-
tions and expression data to discover intrinsic associa-
tions.
Typically, a classification system may achieve high accu-
racy by non-linear models, but these models are hard to
provide rules. In contrast, a rule extraction system is nec-
essary to consider the model interpretability which can
provide a pathway to explore underlying relationships
among data; however, this restriction often affects the sys-
tem performance in classification. Hence, a learning
model which can provide accurate classification, as well as
useful rules, would be ideal. Even so, a relatively few
attempts have been made to integrate the two types of sys-
tems on microarray gene expression data. In earlier
reports, Li et al. [18] has proposed a classifier named PCL
(prediction by collective likelihoods) which is based on
the concept of emerging patterns and can provide the
rules describing the microarray gene expression data. Tan
et al. [19] have introduced a new classifier named TSP
(top scoring pair) which is based on relative expression
reversals and can generate accurate decision rules. These
studies also revealed the phenomenon of trade-off
between credibility and comprehensibility in such a
hybrid system. For that reason, I have made attempts to
design an integrated and effective framework with less
interaction between cancer classification and rule extrac-
tion functions.
In this paper, I have presented an integrated method
(named X-AI) which is based on a three-tiered architecture
from the viewpoint of system design of software engineer-
ing. Different tests have been carried out on two leukemia
datasets for evaluating the performance of X-AI. The
obtained results indicated that X-AI is able to perform well
on both functions of classification and rule extraction in
microarray analysis.
Materials and methods
Datasets and pre-processing
I used two different leukemia datasets for the following
reasons: (i) both datasets have been analyzed and dis-
cussed in many literatures, which is helpful to compare
with their results; (ii) the rules extracted from the similar
cancer type of datasets could be compared to each other;
(iii) the robustness of classification system could be
observed by the datasets that are obtained from different
experiments; and (iv) the two datasets represent the
nature of the binary classification and multi-class prob-
lems, which is useful to evaluate the effectiveness of the
proposed method for different classification problems.
The first acute leukemia data (named L1) of Golub et al.
[1] is composed of 72 samples from two different types of
acute leukemia, acute lymphoblastic leukemia (ALL) and
acute myeloid leukemia (AML). The training set has 38
bone marrow samples (27 ALL and 11 AML) and the test
set consists of 24 bone marrow and 10 peripheral blood
samples (20 ALL and 14 AML). Bone marrow mononu-
clear cells were collected by Ficoll sedimentation in the
training set and RNA was hybridized to Affymetrix oligo-
nucleotide microarrays, by which each sample has expres-
sion patterns of 7129 probes measured. The second acute
leukemia data (named L2) of Armstrong et al. [20]
includes 12582 gene expression values for 57 peripheral
blood or bone marrow samples. The training set contains
57 leukemia samples (20 ALL, 17 MLL (mixed lineage
leukemia) and 20 AML) and the test set contains 15 sam-
ples (4 ALL, 3 MLL and 8 AML). For microarray data, pre-
processing is of critical importance in downstream analy-
ses. In order to equalize expression values for each sample
and avoid the bias against samples, all values in a sample
have been re-scaled by a multiplicative factor which is
determined by linear regression of genes with present
calls. All multiplicative factors are available on the estab-
lished web server. Duoit et al. [21] applied thresholding,
filtering and logarithmic transformation steps before ana-
lyzing the leukemia dataset. Accordingly, the expression
values were limited by both upper and lower bounds.
Since it could be easy to neglect information leakage
effects during pre-processing of the proteomic profiling
on mass spectrometry data as well as the microarray
expression data [22], the upper bound is lifted to 24000
and the lower bound -800, which can increase the changes
of finding relevant genes due to a larger search space. Fur-
ther, I tried to perform the feature selection function
instead of a simple filter to systematically reduce the
number of genes. The mechanism is described in the fol-
lowing section.
More details of datasets can be found on the web server
and in Broad Institute http://www.broad.mit.edu which
evolved from research collaborations in the MIT and Har-
2
Journal of Biomedical Science 2009, 16:25 http://www.jbiomedsci.com/content/16/1/25
Page 4 of 10
(page number not for citation purposes)
selected features are effective, which generally makes the
developed rules more reliable.
Chi2 algorithm
The Chi2 algorithm [25] can discretize numeric features
and select relevant features according to the chi-squared
statistic with respect to the class. The chi-squared value of
an attribute is calculated as the following equation,
where k is the number of classes and Aij the number of
samples of the j-th class in the i-th interval. Eij means the
expected frequency of Aij, which is calculated by
where Ri is the number of samples in the i-th interval, Cj
the number of samples in the j-th class, n the total number
of samples. The algorithm mainly consists of two phases,
named Phase I and II. Phase I comprises the calculation of
the chi-squared value for adjacent intervals, and the merge
of adjacent intervals under a chi-squared threshold which
will be decrementing until an inconsistency rate of data is
exceeded; Phase II includes the finer process of Phase I for
each feature, and the evaluation of the merge degree
which reveals the relevant feature to data. For example, a
feature is regarded as an irrelevance for data if it is merged
to only one value at the end of Phase II.
In this work, I have applied the algorithm to two different
datasets to analyze the relative importance of genes for the
discrimination of tumor classes. And it was chiefly carried
out from a suit of free open-source software [26], which
provides numerous machine learning algorithms from
various learning paradigms.
Diaquadratic discriminant analysis (DQDA)
Based on Bayes decision theory, the maximum likelihood
(ML) discriminant rule discriminates the class of a feature
vector x by assigning the one which yields maximal likeli-
hood [27]. For multivariate Gaussian distributions, the
likelihood function of ωi with respect to x in the l-dimen-
sional feature space is given by
where μi is the mean of x for the ωi class, Σi the l by l cov-
ariance matrix. When the covariance matrices are diago-
nal, , the ML discriminate rule can
be written as
, which is a
special case of diagonal quadratic discriminant analysis
(DQDA). In practice, μi and Σi are estimated by corre-
sponding sample quantities. we have effectively utilized it
for the analysis of discriminating two- and three-state pro-
teins [28]. In this study, the combination of selected genes
was used as the feature vector to discriminate tumor
classes.
Generalized rule induction (GRI)
Generalized rule induction was proposed by Smyth and
Goodman [29], which applies an information theoretic
approach to automate rule acquisition. For a rule, if ante-
cedent then consequent, GRI applies J-measure quantifies its
information content:
where p(a) represents the probability of the observed
attribute value of a, as a measure of the coverage of the
antecedent; p(c) represents the prior probability of the
value of c, as a measure of the common of the observed
attribute value of c in the consequent; p(c|a) represents an
modified probability of observing this value of c after tak-
ing into account the additional information of the value
of a. For rules with more than one antecedent, p(a) is
regarded as the probability of the conjunction of the vari-
able values in the antecedent. Accordingly, a set of opti-
mal rules was then generated by ITRULE algorithm, which
calculates J-measures of rules by employing depth-first
search over possible left-hand sides.
Here, the genes selected by Chi2 algorithm were consid-
ered as the attributes of the antecedent. And the tumor
class was the only attribute of the consequent.
Performance evaluation and test procedure
Prediction accuracy
I considered the classification of the leukemia datasets L1
and L2 as the two-class and three-class problems, respec-
tively. To evaluate the performance of the classification
problems, both classification accuracy and misclassified
number were calculated along with corresponding
number of selected genes.
χ 2
11
2 2
=
−
==
∑∑ ( ) ,Aij EijEijji
k
(1)
E
Ri C j
nij
=
*
, (2)
p x
l
i
x xi i
T
i i( |
( ) / | | /
exp[ ( ) ( )],ω
π
μ μ)= 1
2 2 1 2
1
2
1
Σ
Σ− − −−
(3)
Σ i i il= diag 1
2 2( ,..., )σ σ
C x x
i
j ij ij ij
j
l
( ) arg min [( ) / log ]= − +
=
∑ μ σ σ2 2 2
1
J p a p c a
p c a
p c
p c a
p c a
p c
= + −
−
−
⎡
⎣⎢
⎤
⎦⎥
( ) ( | ) ln
( | )
( )
[ ( | )] ln
( | )
( )
,1
1
1
(4)
4
Journal of Biomedical Science 2009, 16:25 http://www.jbiomedsci.com/content/16/1/25
Page 6 of 10
(page number not for citation purposes)
Prediction performance of system
Different tests have been applied to verify the accuracy of
the classification function of X-AI. For holdout validation
test, it shows the accuracy of 96% and 99% on the test sets
of L1 and L2, respectively, using the ten genes as input
information. I have also carried out the analysis of classi-
fication accuracy along with the corresponding number of
genes by holdout validation test. Figure 3 illustrates the
classification accuracy as a function of the number of
selected genes. The genes were one by one included as the
input information according to the order of chi-squared
statistic. On the test set of dataset L1, X-AI achieves an
accuracy of 98.6% using two genes, and increasing the
number of genes to 10 did not further improve it. In addi-
tion, on the test set of dataset L2, the accuracy can increase
to 100% using eight genes. On the one hand, the training
and test sets for each dataset were combined to form a
complete dataset for LOOCV test. The test yielded the
accuracy of 96% and 94% for datasets L1 and L2, respec-
tively.
The results show that the classification function performs
well in discriminating these different classes when the
input information is provided by the feature selector func-
tion of X-AI. Namely, the integration of the both functions
can be feasible and effective for the binary classification
and three-class problems.
Comparison with other methods
The performance comparison between X-AI and other
methods has also been made on different datasets. The
results provide an overall view about the performance of
different methods. In Figure 4, the prediction perform-
ance is tested on dataset L1 by holdout validation. These
compared methods include the weighted voting machine,
which is based on a linear model [1]; support vector
machines (SVM) [31]; the emerging patterns algorithm
[32]; maximal margin linear programming (MAMA) [33];
four methods that combine the feature selector with
machine learning algorithms [30] and six methods which
have been discussed in earlier literature [34]. The numbers
of misclassified samples and of used genes vary from 0 to
5 and 1 to 132, respectively. This analysis shows that other
methods can not dominate X-AI simultaneously on the
numbers of misclassified samples and of used genes;
namely, X-AI has a relatively small number of misclassi-
fied samples or used genes.
Figure 5 shows the comparison of prediction performance
on dataset L2. the classification based on correlation/
ordering network [35] showed an accuracy of 100% using
information of 40 genes. Other seven compared methods
include three TSP-family classifiers and five machine
learning methods: C4.5 decision trees (DT), Naïve Bayes
(NB), k-nearest neighbor (k-NN), SVM and prediction
analysis of microarrays (PAM) [19]. The accuracy and the
number of used genes vary from 80% to 100% and 2 to
12582, respectively. The analysis reveals that X-AI can
achieve a relatively high accuracy using a small number of
informative genes when comparing to these methods.
Association rule development
The function of feature selection did not only reduce the
number of input genes, but also improve the efficiency of
rule development. It also results in a rational and accept-
able number of rules. Based on the genes of Table 1, X-AI
included all the samples for each dataset to establish asso-
ciation rules.
Tables 2 and 3 list all association rules that developed for
each dataset and class. The average confidence is 99% and
97% for datasets L1 and L2, respectively, showing the high
accuracy of these rules. In Table 2, the second rule means
that if the expression of M23197 (CD33) is larger than 401.5,
then the sample is classified as ALL. For dataset L1, 29.17%
samples contain the antecedent of this rule and all these
samples are correctly classified. This rule efficiently reveals
the importance of the gene in discriminating between
Prediction performance of X-AI along with different number of genes on the test set two d tasetsFigur  3
Prediction performance of X-AI along with different 
number of genes on the test set of two datasets. The 
y-axis represents classification accuracy and the x-axis is the 
corresponding number of genes which were used as informa-
tion in classification. L1: for the dataset of Golub et al. [1] L2: 
for the dataset of Armstrong et al. [20]
90
91
92
93
94
95
96
97
98
99
100
0 1 2 3 4 5 6 7 8 9 10
Number of genes
A
cc
u
ra
cy
 
(%
)
L1 L2
6
Journal of Biomedical Science 2009, 16:25 http://www.jbiomedsci.com/content/16/1/25
Page 8 of 10
(page number not for citation purposes)
AML and ALL. This finding is in accord with the results of
earlier studies [1,19]. Further, I observed the occurrence of
genes among the rules, which may related to their impor-
tance. Interestingly, the gene X95735 (Zyxin) has a high-
est percentage of occurrence (30%) and Wang et al. [30]
also gave a detailed discussion about its role in leukemia.
In Table 3, the gene 1325_at (TASK) also has a high per-
centage of occurrence (24%). However, it may need more
comparative studies for validation.
Web server for cancer classification
I have also developed a web server for classifying tumors
of acute leukemia and it is freely available at http://bioin
formatics.myweb.hinet.net/xai.htm. The prediction can
be made by taking four simple steps (see Figure 6): (i)
select "Prediction" from the main page to open an input
subpage, (ii) select a set of input genes, (iii) input the
expression values for each gene, and (iv) press the "Sub-
mit" button to start the service.
Because X-AI selected two different sets of input genes
from two datasets for training the classifiers, it results in
two classifiers with different sets of input genes. Users can
optionally assign one of both to predict cancer classes. In
addition to the cancer classification page, the web server
has provided help and reference pages for interested
researchers.
Conclusion
In this study, I have proposed an integrated method for
accurate cancer classification, relevant gene selection, and
the associate rule development from DNA microarray
data. Applying the concepts of system design, the modules
Table 2: Two different classes of rules generated from dataset L1
Consequent Antecedent Support (%) Confidence (%)
ALL L09209_s > 1056.5 & M23197 > 326.0 30.56 100
M23197 > 401.5 29.17 100
M27891 > 2096.5 27.78 100
X95735 > 994.0 & M55150 > 1250.5 27.78 100
X95735 > 994.0 36.11 92
AML U46499 < 154.5 59.72 100
L09209_s < 992.5 58.33 100
X95735 < 994.0 63.89 98
Mean 41.67 99
Table 3: Three different classes of rules generated from dataset L2
Consequent Antecedent Support (%) Confidence (%)
ALL 32847_at > 147.0 30.56 100
36239_at > 2201.0 27.78 100
AML 39318_at < 1063.0 & 32579_at < 2285.0 34.72 100
1325_at < 1501.5, 39318_at < 1063.0 & 32579_at < 2285.0 34.72 100
1325_at < 1501.5, 36239_at < 214.0 & 40191_s_at < 508.5 33.33 100
36239_at < 214.0 & 40191_s_at < 508.5 33.33 100
39318_at < 1063.0 & 35164_at < -794.5 31.94 100
40191_s_at < 519.0 & 36239_at < 167.0 31.94 100
1325_at < 1501.5, 39318_at < 1063.0 & 35164_at < -794.5 31.94 100
1325_at < 1501.5, 40191_s_at < 519.0 & 36239_at < 167.0 31.94 100
1325_at < 1501.5, 36239_at < 214.0 & 37539_at < -362.0 31.94 100
36239_at < 214.0 & 37539_at < -362.0 31.94 100
37539_at < -725.5 29.17 100
32579_at < 2285.0 36.11 96
1325_at < 1501.5 & 32579_at < 2285.0 36.11 96
36239_at < 214.0 40.28 93
MLL 1325_at < 201.0, 35260_at > 794.5 & 40191_s_at > 1107.5 19.44 100
1325_at < 201.0 & 36239_at > 214.0 23.61 94
1325_at < 201.0 37.50 67
Mean 32.02 97
8
Publish with BioMed Central   and  every 
scientist can read your work free of charge
"BioMed Central will be the most significant development for 
disseminating the results of biomedical research in our lifetime."
Sir Paul Nurse, Cancer Research UK
Your research papers will be:
available free of charge to the entire biomedical community
peer reviewed and published immediately upon acceptance
cited in PubMed and archived on PubMed Central 
yours — you keep the copyright
Submit your manuscript here:
http://www.biomedcentral.com/info/publishing_adv.asp
BioMedcentral
Journal of Biomedical Science 2009, 16:25 http://www.jbiomedsci.com/content/16/1/25
Page 10 of 10
(page number not for citation purposes)
diagnostic application to microarray gene expression data.
Comput Biol Chem 2007, 31(1):48-56.
11. Huang LT, Gromiha MM, Hwang SF, Ho SY: Knowledge acquisition
and development of accurate rules for predicting protein
stability changes.  Comput Biol Chem 2006, 30(6):408-415.
12. Huang LT, Gromiha MM, Ho SY: Sequence analysis and rule
development of predicting protein stability change upon
mutation using decision tree model.  Journal of Molecular Mode-
ling 2007, 13(8):879-890.
13. Huang LT, Gromiha MM, Ho SY: iPTREE-STAB: interpretable
decision tree based method for predicting protein stability
changes upon mutations.  Bioinformatics 2007, 23(10):1292-1293.
14. Borgelt C, Berthold MR: Mining molecular fragments: finding
relevant substructures of molecules.  The 2002 IEEE interna-
tional Conference on Data Mining, Washington, DC; 2002:51-58. 
15. Oyama T, Kitano K, Satou K, Ito T: Extraction of knowledge on
protein-protein interaction by association rule discovery.
Bioinformatics 2002, 18(5):705-714.
16. Creighton C, Hanash S: Mining gene expression databases for
association rules.  Bioinformatics 2003, 19(1):79-86.
17. Carmona-Saez P, Chagoyen M, Rodriguez A, Trelles O, Carazo JM,
Pascual-Montano A: Integrated analysis of gene expression by
Association Rules Discovery.  BMC Bioinformatics 2006, 7:54.
18. Li J, Liu H, Downing JR, Yeoh AE, Wong L: Simple rules underlying
gene expression profiles of more than six subtypes of acute
lymphoblastic leukemia (ALL) patients.  Bioinformatics 2003,
19(1):71-78.
19. Tan AC, Naiman DQ, Xu L, Winslow RL, Geman D: Simple deci-
sion rules for classifying human cancers from gene expres-
sion profiles.  Bioinformatics 2005, 21(20):3896-3904.
20. Armstrong SA, Staunton JE, Silverman LB, Pieters R, den Boer ML,
Minden MD, Sallan SE, Lander ES, Golub TR, Korsmeyer SJ: MLL
translocations specify a distinct gene expression profile that
distinguishes a unique leukemia.  Nat Genet 2002, 30(1):41-47.
21. Dudoit S, Fridlyand J, Speed T: Comparison of discrimination
methods for the classification of tumors using gene expres-
sion data.  Technical Report 576, Statistics Dept, UC Berkeley 2000.
22. Barla A, Jurman G, Riccadonna S, Merler S, Chierici M, Furlanello C:
Machine learning methods for predictive proteomics.  Brief
Bioinform 2008, 9(2):119-128.
23. Yourdon E, Constantine LL: Structured design: fundamentals of
a discipline of computer program and systems design.  Engle-
wood Cliffs, N.J., Prentice Hall; 1979. 
24. Berrar DP, Dubitzky W, Granzow M: A practical approach to
microarray data analysis.  Boston, MA, Kluwer Academic Publish-
ers; 2003. 
25. Huan L, Rudy S: Chi2: Feature Selection and Discretization of
Numeric Attributes.  Seventh International Conference on Tools with
Artificial Intelligence (ICTAI) 1995:388.
26. Witten IH, Frank E: Data Mining: Practical machine learning
tools and techniques.  2nd edition. San Francisco, Morgan
Kaufmann; 2005. 
27. Theodoridis S, Koutroumbas K: Pattern recognition 3rd edition.
Amsterdam; Boston, Elsevier/Academic Press; 2006. 
28. Huang LT, Gromiha MM: Analysis and prediction of protein fold-
ing rates using quadratic response surface models.  Journal of
Computational Chemistry 2008, 29(10):1675-1683.
29. Smyth P, Goodman RM: An information theoretic approach to
rule induction from databases.  Knowledge and Data Engineering,
IEEE Transactions on 1992, 4(4):301-316.
30. Wang Y, Tetko IV, Hall MA, Frank E, Facius A, Mayer KF, Mewes HW:
Gene selection from microarray data for cancer classifica-
tion – a machine learning approach.  Comput Biol Chem 2005,
29(1):37-46.
31. Furey TS, Cristianini N, Duffy N, Bednarski DW, Schummer M, Haus-
sler D: Support vector machine classification and validation
of cancer tissue samples using microarray expression data.
Bioinformatics 2000, 16(10):906-914.
32. Li J, Wong L: Identifying good diagnostic gene groups from
gene expression profiles using the concept of emerging pat-
terns.  Bioinformatics 2002, 18(5):725-734.
33. Antonov AV, Tetko IV, Mader MT, Budczies J, Mewes HW: Optimi-
zation models for cancer classification: extracting gene
interaction information from microarray expression data.
Bioinformatics 2004, 20(5):644-652.
34. Fort G, Lambert-Lacroix S: Classification using partial least
squares with penalized logistic regression.  Bioinformatics 2005,
21(7):1104-1111.
35. Liu CC, Chen WS, Lin CC, Liu HC, Chen HY, Yang PC, Chang PC,
Chen JJ: Topology-based cancer classification and related
pathway mining using microarray data.  Nucleic Acids Res 2006,
34(14):4069-4080.
10
