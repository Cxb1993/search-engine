 2
stimulation (FES) system to recover the 
amputee’s residual muscle in this project. 
3. For manipulating dexterously, the 
multi-fingered prosthetic hand should be able to 
handle multi-degree-of-freedom prehensile 
postures such that it can act like a human being. 
Hence, we will study the trajectory and grasp 
planning. Thereafter, the multi-fingered 
prosthetic hand will be able to show desired 
trajectories and grasp target objects precisely. 
4. Once the prosthetic hand and related 
algorithms are developed, we will develop a 
training mechanism, including a data glove and 
a user interface (UI). The training mechanism 
not only can provide real-time information for 
the prosthetic hand and data glove, but also can 
play an important role in the remote 
(master-slave) control application field. 
5. Another important issue is to develop 
thin-film tactile sensors for which they can be 
built in the fingers of the prosthetic hand. 
Besides, these sensors are able to measure 
multi-dimensional and high-resolution forces, 
including 1-D normal and 2-D shear forces. The 
above two functions are necessary for grasp 
planning. Therefore, we will design such 
thin-film tactile sensors based on MEMS 
technique. 
6. The final target of this project is to develop 
a “portable” prosthetic hand. Namely, all 
functions and algorithms will be implemented 
by: (1) high-speed processing modules, and (2) 
small-size and reduced-weight modules. 
Therefore, system-on-chip (SoC) techniques 
will be used to develop related modules, 
including EMG recognition module, prosthetic 
hand control module, and intercommunication 
module. Once the intelligent and portable 
prosthetic hand is developed, we will validate 
its performance with clinical experiments. 
三、研究方法 
z Control System of the NTU-Hand IV 
SOPC [5] is a highly integrated technique. 
Implementation of the whole system on a FPGA 
is no longer a dream. Building a system with 
SOPC technology has many advantages, such as 
acceleration of product development, high 
flexibility, reduction of system dimension, and 
ease of product test. 
Multi-Joint Control Module 
A multi-joint controller is developed to 
control each joint of the NTU Hand IV. To 
implement a multi-joint controller, the single 
joint control module should be established first. 
A single joint control module includes three 
parts: PID controller, PWM generator, and 
quadrature decoder. Each part will be detailed in 
the following sub-sections.  
As users send a position command to the 
control module, the PID controller will first 
process the command. Duty cycle and direction 
signals will be generated and passed to the 
PWM generator to produce the appropriate 
PWM signal. The PWM signal is amplified by 
the H-bridge and sent to dive a motor. 
While the motor is running, the quadrature 
decoder will acquire the motor position data 
from the encoder. In turn, the PID controller 
gets the position data and determined what kind 
of PWM signals should be generated again. The 
overall architecture is shown in Figure 1. 
 
Figure 1 The architecture of a single joint control 
module 
The architecture of a PWM generator is 
shown in Figure 2. The register will hold the 
duty cycle assigned by the user. Comparator 
will compare the value of the register and the 
counter. If the value of counter is less than 
register, the PWMOut pin will be logic 1. 
Otherwise, PWMOut pin will be logic 0. 
The generated PWM signal with 50% duty 
cycle is shown in Figure 3. The width of the 
PWM generator is 8 bits. Because precision of 
the NTU Hand IV is not critical, 8 bit PWM 
signal is sufficient. 
 4
powerful. A lot of literatures discussed about it. 
The motor position controller will be 
implemented using a PID controller here. A PID 
controller in continuous-time domain can be 
expressed as 
sk
s
kkG DIPc ⋅++=  (1)
Where kP is the proportional gain, kI is the 
integration gain, and kD is the derivative gain. A 
six state FSM (finite state machine) is designed 
to implement a PID controller. The task that a 
PID controller should do is divided into six 
parts. The state diagram is shown in Figure 7. 
The first state is called Get_Err_State. In this 
state, the PID controller will acquire position 
data from the quadrature decoder and calculate 
error. In the second state, Mul_Kp_State, the 
PID controller will multiply kP by error. Also, 
the error integration is prepared. The next state 
is called Mul_Ki_State, kI is multiplied by the 
error integration and the derivative error is 
calculated in this state. The fourth state, 
Get_Kd_State, the derivative error is multiplied 
by kD. In Get_PID_Term state, the results got 
from state second, third, and fourth are added to 
obtain a PID_Term. The last state of the FSM is 
Scale_PID_Term. To match with the 8-bit PWM 
generator, PID_Term is scaled to a suitable 
range. Figure 8 shows the timing simulation of 
the PID controller. The simulator is Quartus II. 
Besides, the sampling frequency is about 1 kHz. 
 
Figure 7 State diagram of the PID controller 
The PWM generator, the quadrature 
decoder, and the PID controller are constructed. 
The combination of these modules forms a 
single joint controller.  
Two types of motor are mounted on the 
NTU Hand IV, i.e, Maxon 118386 and Maxon 
118423. While applying the PID controller to 
these motors, the result is pretty good. 
Experimental results are shown in Figure 9 and 
Figure 10. Both of them do not have overshoot. 
The settling time for Maxon 118386 and Maxon 
118423 is about 450 ms and 200 ms, 
respectively. In addition, steady state errors are 
all zero. 
Figure 8 Timing simulation of PID controller 
-20
0
20
40
60
80
0 20 40 60 80 100
10ms
counts
postion
desired position
Figure 9 Step response of Maxon motor 118386 
0
10
20
30
40
50
60
70
0 20 40 60 80 100
10ms
counts
position
desired position
Figure 10 Step response of Maxon motor 118423 
After the PWM generator, the quadrature 
decoder, and the PID controller are ready, the 
next step is to integrate them to form a single 
joint controller. In addition to the closed loop 
control mode, the open loop control mode is 
required for reset purpose. The entire 
 6
 
Figure 15 The grasp control dialog 
 
Figure 16 The EMG control dialog 
Figure 15 shows the grasp control dialog. It 
consists of two portions: the grasp portion and 
the control portion. In the grasp portion, four 
kinds of grasp types can be chosen. They are 
ball grasp, bottle grasp, egg grasp, and key 
grasp. In the control portion, two main functions, 
the sensor monitor function and the single motor 
control function, are involved. In the sensor 
monitor portion, we can determine which type 
of sensor that we want to monitor, the force 
sensor or the position sensor. The values of all 
sensors will be updated every 500 ms. 
For the single motor control function, two 
control modes, the closed-loop control and open 
loop control mode, can be selected. The closed 
loop control mode is used in the position control 
and force control, while the open loop control 
mode is used in reset. Note that the auto-reset 
function is also added to this GUI for prosthetic 
hand initialization. The arrangement of the 
grasp control dialog just likes the shape of a left 
hand whose palm faces upward. 
Figure 16 shows the EMG control dialog. 
This dialog can be divided into three parts. The 
upper part is the training interface. Middle part 
shows some information that will be needed in 
training stage. The lower part is used for testing. 
In the training interface, three buttons are 
designed. The request button will command 
Nios to send the EMG features back. After 
collecting features completely, all features will 
be recorded in a text file. We may send the text 
file to a PC for training or train those data 
directly on the PDA. Training on the PDA is 
possible but is time-consuming due to the 
hardware limitation of the present PDA. Upon 
finishing training, the model file will be 
generated. Read model and save model buttons 
are used to read a model file or save a model file, 
respectively. 
In the testing section, the test button will 
command Nios to acquire the EMG features and 
send these features to SVM for classification 
continuously. The classified result will be sent 
to drive the NTU-Hand IV and shown in the 
result edit also. Press the stop button will turn 
off the EMG discriminative system. 
 
Figure 17 The posture control dialog 
Posture control dialog is used to command 
prosthetic hand to take some commonly used 
postures, such as power grasp, hook grasp, and 
 8
 
Figure 22 First-order active low-pass filter 
In signal collection stage, a “start” signal is 
needed to command the system to store the 
incoming signal. It may set a threshold to 
present a “start signal”. When the amplitude of 
raw EMG is larger than the threshold, the signal 
will be collected. Using this methodology, one 
may encounter several problems. If we set the 
threshold too small, large noise will initialize 
signal collection. While using a large threshold, 
the signal will be truncated. 
We propose a different method here. We 
also set a threshold, but the threshold is a 
relative big value. While the amplitude of the 
EMG signal is greater than the threshold, the 
previous 100 data and the latter 412 data will be 
collected. In this way, the more correct signal 
can be gathered. 
To classify the EMG signal in time-domain, 
many features can be applied, such as IEMG 
(integral of EMG), WL (waveform length), 
variance, zero crossing, autoregressive model, 
histogram of EMG, and so on. While in 
time-scale domain only a few features have 
been found useful in EMG classification.  
To improve the accuracy of classification 
rate, a new time-scaled feature will be proposed. 
The original idea is that we do not want to lose 
the time information while extracting the feature 
in time-scale domain. A rectangular window is 
used to hold the time information of Wavelet 
coefficients. We call the feature as windowing 
power. The steps to calculate the feature is 
stated below 
¾ Calculate D1 Wavelet coefficients. 
¾ Apply window and shift the window in D1 
coefficients. 
¾ Calculate each power of different 
windowed D1 coefficients. 
¾ Count the non-zero numbers of each 
window coefficient. 
¾ Multiply the numbers obtained from last 
step to the power. 
¾ Scale each parameter calculated from the 
last step such that the amount of them 
equal to unity.  
The rectangular window we used can be 
formulated as 
he windowbound of t
per  is the upr bound, Ms the lowewhere  N i
ise    otherw,         (k))x(d
Mkif  N(k),dkdx
j
jj
0
       ))((
=
<<=
 
(2)
Figure 23 and Figure 24 shows the 
de-noised D1 Wavelet coefficients of power 
grasp and hook grasp extracted from channel 
one. Figure 25 and Figure 26 shows the feature 
of windowing power extracted from the 
de-noised D1 Wavelet coefficients of power 
grasp and hook grasp. In this case, a window of 
length 85 is used and shifted three times. That 
means we can extract three features in each 
posture per channel. 
After extracting the features, data is 
forwarded to the SVM. The SVM we used is the 
open source code published on [1] and packaged 
by Cheng[3]. 
-1000
-500
0
500
1000
1500
0 50 100 150 200 250 300
time
amplitude
Figure 23 De-noised D1 Wavelet coefficient of power 
grasp 
Window1 Window2 Window3 
 10
where K is the motor constant. The current I can 
be derived as 
LjR
VV
I bω+
−=
 
WKV bb =  
(5)
Where bV  is the back electromotive-force 
voltage, bK  is the back electromotive-force 
voltage constant, W  is the angular velocity of 
the motor, ω  is the angular frequency of the 
current I . 
 
Object 
Finger 
Finger 
K
K 
Tactile sensor 
Force 
Object 
Figure 28 Internal spring model 
Figure 29 Electrical model of a motor 
When a contact occurs, bV  equals to zero 
because W  equals to zero. Since the frequency 
of PWM signal will not change, the angular 
frequency of the current I  is a constant. Eqns. 
(4) (5)can be re-written as 
LjR
VIKT ω+=⋅=  (6)
Eq. (6) indicates that the torque of a motor 
is proportional to the applied voltage add on the 
motor. In this way, the force control can be 
implemented. 
 
四、結論與成果 
z Experiment of Results of EMG 
Classification 
In this section, different Wavelet based 
features are compared. The best one will be 
applied to the NTU prosthetic hand system. 
Wavelet-Based Power 
In the sub-section, the power of different 
scaled Wavelet dj and scaling aj coefficients will 
be compared. 
Case I: Extract the power of wavelet 
coefficients 
Table 1 Classification rate using the power feature in 
different scaled Wavelet coefficients (%) 
 
(PG: power grasp, HG: hook grasp, WF: 
wrist flexion, LP: lateral pinch, FH: flattened 
hand, CG: centralize grip, TJC: three-jaw chuck, 
CYG: cylindrical grasp) 
It is obvious that the power of Wavelet 
coefficients is not a good feature for EMG 
classification. 
 12
perform the posture of lateral pinch. The 
NTU-Hand IV will grip the key by the thumb. 
After successfully gripping the key, the 
NTU-Hand IV then releases the key.  
Figure 31 shows the pictures about 
grasping a bottle. First, the cylindrical grasp is 
taken. Then, it approaches the bottle. Upon 
touching the bottle, the force is tracked and then 
NTU-Hand IV grasps the bottle stably. After 
grasping, the bottle is released. 
In Figure 32, the NTU-Hand IV grasps a 
ball like a pitcher. Finally, we take the 
experiment on grasping an egg. The grasping 
procedure is shown in Figure 33. After stably 
grasp the egg, we break the egg to show that it 
is a real egg. 
 
Figure 30 Grip a key 
 14
 
Figure 33 Grip an egg 
五、參考文獻 
[1]. C. J. D. Luca, “Surface Electromyography 
detection and recording,” NeuroMuscular 
Research Center (NMRC), USA, 1997. 
[2]. J. J. Craig, Introduction to Robotics 
Mechanics and Control, 2nd Edition, New York: 
Addison-Wesley Publishing Company, pp. 74- 
377, 1989. 
[3]. Y. T. Cheng, “Face Tracking and 
Recognition,” Master Thesis, Department of 
Mechanical Engineering, National Taiwan 
University, 2004. 
[4]. http://www.atmel.com/dyn/resources/prod_
documents/DOC3023.PDF 
[5]. http://www.atmel.com/dyn/resources/prod_
documents/DOC2324.PDF 
 
 
2006 年 IEEE 國際智慧型機器與系統人會議 
 
黃漢邦教授 
國立臺灣大學機械系 
 
一、 參加會議經過 
 
2006 年 IEEE 國際智慧型機器與系統人會議於 95 年 10 月 9 日-10
月 15 日於中國大陸北京召開，但此同時 2006 IEEE Conference on 
Automation Science and Engineering 也在中國上海舉行。因此，
在前往北京參加 2006 年 IEEE 國際智慧型機器與系統人會議之前，先
至上海參加 2006 IEEE Conference on Automation Science and 
Engineering。 
本 次 2006 IEEE Conference on Automation Science and 
Engineering 為第二屆，假上海國際會中心舉行。會議在 10 月 8 日
有一場 Workshop 並於傍晚舉行大會的歡迎酒會(Reception) 。10 月
9 日晚上為大會晚宴(Banquet)，10 月 10 日晚上則為餞行酒會，全部
的論文發表集中在 10 月 9 日至 10 月 10 日。我分別於 10 月 9 日和
10 月 10 日兩天各發表一篇論文。論文題目分別為: On-Line 
Rescheduling for Semiconductor Manufacturing，及 Mobile Diagnosis 
based on RFID for Food Safety。此外，並參加大會安排之參觀活動，
分別拜訪上海 Intel 公司及上海中芯國際半導體公司。 
