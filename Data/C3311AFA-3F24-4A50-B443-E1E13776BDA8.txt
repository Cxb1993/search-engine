2目錄
(一)研究計畫之目的------------------------------------------------------------------page 3；
(二)計畫執行研究成果展示—-------------------------------------------------------pp.4-56；
(第1篇) 國際會議論文：Din-Yuen Chan, Wei-Ta Chien, Chun-Yuan Chang,
Cheng-Fu Chou, Ching-Ju Lin and Junn-Yen Hu, "A Fast and Accurate
Characteristic-Based Rate-Quantization Model for Video Transmission,"
Proceedings of SPIE Symposium on Electronic Imaging, Visual Communication
and Image Processing (VCIP2007), San Jose, CA, Jan., 2007 .(EI)-- -----pp.4-16；
(第 2 篇 ) 國際會議論文：Chun-Yuan Chang, Cheng-Fu Chou, Din-Yuen
Chan,”A Novel Rate-Quantization Source Modeling Framework for
H.264/AVC,” International Conference on Acoustics, Speech, and Signal 
Processing, (ICASSP’07), Honolulu, Hawai, USA, April, 2007.
(EI)—-----------------------------------------------------------------------------pp.16-26
( 3 ) 相關計畫碩士論文一：編碼模式連結之量化參數決定演算法以強化
H.264/AVC位元率控制------------------------------------------------------pp.27—56；
( 4 ) 相關計畫碩士論文二：以 MPEG - 4 物 件 觀 念 做 系 統 設 計 之
位 元 流 控 制 機 制 -------------------------------------------------------pp.57--71；
(三)參考文獻-------------------------------------------------------------------------pp.72--73；
(四) 計畫成果自評--------------------------------------------------------------------page 74
4(二)計畫執行研究成果展示:
相關本計畫研究成果為兩篇一流國際會議論文及兩份相關本計畫碩
士論文
第1篇 國際會議論文：Din-Yuen Chan, Wei-Ta Chien, Chun-Yuan Chang,
Cheng-Fu Chou, Ching-Ju Lin and Junn-Yen Hu, "A Fast and Accurate
Characteristic-Based Rate-Quantization Model for Video Transmission,"
Proceedings of SPIE Symposium on Electronic Imaging, Visual Communication
and Image Processing (VCIP2007), San Jose, CA, Jan., 2007 .(EI)
論文內容
A Fast and Accurate Characteristic-Based Rate-Quantization Model
for Video Transmission
Din-Yuen Chanb, Wei-Ta Chienb, Chun-Yuan Changa,Cheng-Fu Choua, Ching-Ju Lina and Junn-Yen
Hua
aGraduate Institute of Networking and Multimedia, National Taiwan University, Taipei City,
R.O.C.
bDept. of Computer Science and Information Engineering, National Chiayi University, Chiayi
City, R.O.C.
left@cmlab.csie.ntu.edu.tw, Tel: 886-2-2362-5336-517, Fax: 886-2-33664898
ABSTRACT
In this paper, we analyze the limitation of ρ-domain based rate-quantization (R-Q)
model. We find out that a characteristic-based R-Q model can be derived from
ρ-domain to q-domain. Experimental data show that such a characteristic-based R-Q
model can provide a more accurate estimation of the actual bitrate than existing
models for both frame-level and macroblock(MB)-level. In addition, a simple analysis
of computational complexity of our quantization-free characteristics extraction
framework shows that our model is faster than existing variance andρ- domain based
R-Q models.
6operations are more suitable than division/multiplication. To deal with the two
problems, in [7], we have turned the concept of the ”pseudocoding”from continuous
ρ-domain to discrete q-domain, and have empirically explore a new combination of
rate characteristics for the”pseudocoding”process. We discovered that the concept of
the ”pseudocoding”process is more feasible for discrete q-domain. Extensive
experimental data shown that the prediction error is about ±3.3% on average in
frame-level. In addition, a fast characteristic extraction framework which only
involves additive operations has been developed.
In this work, we scale our frame-level R-Q model down to MB-level and discuss
the limitation ofρmodel. Then, we start withρmodel to derive our model. In addition,
we analyze the computational complexity of our quantization-free characteristics
extraction framework. Finally, the analysis of accuracy compared to variance/ρ-
domain based R-Q model are provided. Experimental data show that our model also
outperforms existing models for both frame-level and MB-level.
2. REVIEW OFρ- DOMAIN BASED R-Q MODEL
We first introduce the Uniform Threshold Quantizer [8] in video coding systems
(H.263/MPEG-2/MPEG-4). According to the definition of Uniform Threshold
Quantizer, each DCT coefficient x is quantized by a piecewise function:
(1)
.-if,
Δ
;if,
;||if,0
)(





















 


x
q
x
x
q
x
x
xC
, where C(x) is the quantized coeficient, Δ is the dead zone thresholdand q is the
quantization step size. In H.263+, dead zone threshold Δ is set to 2q and 2.5q for intra-
and inter-macroblock, respectively. Based on Uniform Threshold Quantizer, ρ–“the 
percentage of zeros among the quantized transform coeficients” can be calculated by 
integrating the histogram of DCT coefficients as follows:
(2))(.
1
)(
||



x
xD
MxM
q
, where D(x) is the histogram of DCT coefficients1 and MxM is the number of pixels
of a MB.
Following, we will discuss the first problem of ρmodel. First, we inspect the
1 In [], M represents the number of pixels of a frame
8Fig. 1 Comparisons of the relationship R-(1-ρ) among the proposed two characteristic
vectors )(1 iqQ

and )(2 iqQ

,ρ-domain based R-Q model with optimal slope 43.6opt and actual rate
curve.
3. AN EXPERIMENTAL DERIVATION OF PROPOSED MODEL
VIAρ- DOMAIN BASED R-Q MODEL
In [6], there are two characteristics have been extracted from quantized DCT
spectra -the sum of the sizes of all nonzero coefficients, denoted as )( jNZQ  , and the
sum of the sizes of all run length, denoted as )( jZQ  to model the actual bitrate for a
givenρj.
(5)).()()(ˆ jjj QWR 


, where )( jW 
 is a set of model coefficients obtained through regression method, and
the characteristic vector is T
jZjNZj QQQ ]1)()([)(  
 . Indeed, such a modeling method is
very accurate when ρj is given. But, we have to note that since ρis a real value, it is
10
First we will propose a fast approximation method to compute )( iL qQ . According to
the definition of Uniform Threshold Quantizer, )( iL qQ should be calculated by
(7)
||)(
1







 iC qQ
n i
in
q
x
, where )( iC qQ is the number of nonzero coefficients of a MB
2. We notice that for each
item 




 
i
in
q
x || in the Eq. (7), after performing a division, there is a dynamically stuffing
value αi over [0,1) padded by a ceiling operation. Thus, the Eq. (7) can be written as
following.
(8)
-|| )(
1
)(
1



iCiC qQ
n
n
qQ
n i
in
q
x 
To reduce a large of divisions, we sum up all absolute values of nonzero DCT
coefficients in advance, i.e. the item 

)(
1
||
iC qQ
n
nx , denoted as )( iSANZ qQ , and then assume that
the averaging value of αi is set to 0.5. Hence, the Eq. (8) can be precisely
approximated by following expression
(9).1)(
)()(
)(  iC
i
iCiiSANZ
iL qQq
qQqQ
qQ
0x 1x 2x 3x 4x 5x 6x
Fig. 2 1-D array B records the status of nonzero DCT coefficients and their relative
positions during applying dead zone thresholding from QP=1 to QP=31. )( iLast qP is the
position of the last nonzero coefficient after applying dead zone thresholding Δi
Thus, in fact, we just turn the attention to compute )( iSANZ qQ , )( iC qQ and )( iL qQ . We will
design a recursive extraction framework from q1 to q31. In addition, an auxiliary status
array B of a MxM block will be included to extract the three rate
12
complexity of
 1
)(
x
B xD
in the Eq. (12) is less than the computational complexity of

 1
)(
1x
xDB
x . Finally, due to the limited size of the status array B, the accumulation of
moved steps in the Eq. (15) from Shift(q0) to Shift(q31) totally will be never more than
N additive operations. That is, the total computational complexity of the recursive
extraction of )( iSANZ qQ , )( iC qQ and )( iL qQ is roughly 7N additive operations. However,
ρ–domain based R-Q model requires not only the construction of a histogram and
recursive computation of ρ(q) but also a quantization process and an amount of
logarithm operations to the status array B. Totally 6N additive operations, N division
operations and N logarithm operations are involved. Then, for variance-based R-Q
model models [1]-[3], 3M additions and 1M multiplications are involved. Extensive
experimental data shows that statistically M is 3 times of N. Therefore, the proposed
addition extraction framework is better than existing R-Q models in terms of
computational complexity.
5. EXPERIMENTAL RESULTS
We have embedded our R-Q model in TMN8 [1] and experimented on numerous
typical QCIF format videos. The encoding frame is fixed at 10 fps. Frame type is set
to IPPP. The first I frame is encoded with QP=13. In the following, we compare our
R-Q model with the variance-based R-Q model in TMN8, the adaptive variance-based
R-Q model and ρ- domain based R-Q model in terms of accuracy. For the
variance-based R-Q model in TMN8, the estimated bitrate is given by
(17),4)(ˆ 228 qAKqRTMN   ,
where A= MxM,σ is the variance of a MB and K is adaptive factor, which is updated
using a recursive method [1]. For the adaptive variance-based R-Q model in [3], the
estimated bitrate is given by
(18),
31QP,)(
QPQP,)(
QP1,)(
)(ˆ
)3(
2
)3(
)2(
2
)2(
)1(
2
)1(









qe
qe
qe
qR
Hq
HLq
Lq
MultiLog



14
[6] FOR 300 ENCODED FRAMES AT 10 FPS WITH THE UNIFORM QP
ASSIGNMENT.
EF and EM QP 1-31-1
Mthr_dotr CarPhone Salesman Highway Foreman
EF EM EF EM EF EM EF EM EF EM
Optimal ρ-domain based R-Q model 0.061 0.11 0.065 0.137 0.061 0.128 0.067 0.161 0.097 0.157
R-Q model in Multiple Logarithmic 0.429 0.868 0.242 0.597 0.644 1.275 0.104 0.371 0.334 0.628
R-Q model in TMN8 0.371 0.825 0.644 0.889 0.766 1.301 0.141 0.372 1.944 2.145
Proposed Q1 0.042 0.074 0.029 0.06 0.026 0.074 0.048 0.069 0.038 0.066
Proposed Q2 0.048 0.09 0.02 0.061 0.046 0.091 0.01 0.046 0.011 0.044
EF and EM QP 15-31-15
Mthr_dotr CarPhone Salesman Highway Foreman
EF EM EF EM EF EM EF EM EF EM
Optimal ρ-domain based R-Q model 0.077 0.139 0.048 0.124 0.063 0.128 0.096 0.157 0.049 0.121
R-Q model in Multiple Logarithmic 3.481 3.896 0.583 1.036 2.281 2.65 1.771 2.192 0.279 0.66
R-Q model in TMN8 3.216 3.645 0.653 1.022 2.554 2.996 1.683 2.207 0.279 0.664
Proposed Q1 0.055 0.105 0.026 0.099 0.042 0.097 0.042 0.11 0.022 0.088
Proposed Q2 0.037 0.096 0.028 0.098 0.034 0.093 0.048 0.108 0.025 0.09
16
7. C. Y. Chang, Tsungnan Lin, D. Y. Chan and S. H. Hung, “A Low Complexity 
Rate-Distortion Source Modeling Framework”,International Conference Acoustics,
Speech, and Signal Processing, Proceedings. (ICASSP '06), pp. 929-932.
8. M. Ghanbari, Video Coding: An Introduction to Standard Codecs, Institution of
Electrical Engineering Press, London, 1999.
9. R. J. Freund and W. J.Wilson, Regression Analysis: Statistical Modeling of a
Response Variable. New York: Academic, 1998, pp. 39–41.
第 2 篇 國際會議論文：Chun-Yuan Chang, Cheng-Fu Chou, Din-Yuen
Chan,”A Novel Rate-Quantization Source Modeling Framework for H.264/AVC,”
International Conference on Acoustics, Speech, and Signal Processing, (ICASSP’07), 
Honolulu, Hawaii, USA, April, 2007. (EI)
論文內容
A NOVEL RATE-QUANTIZATION SOURCE MODELING
FRAMEWORK FOR H.264/AVC
Chun-Yuan Chang1 , Cheng-Fu Chou1 and Din-Yuen Chan2
1Graduate Institute of Networking and Multimedia, National Taiwan University, R.O.C
2Department of Computer Science and Information Engineering, National Chiayi University,
R.O.C
{left,ccf}@cmlab.csie.ntu.edu.tw
ABSTRACT
How to perform rate control on emerging H.264/AVC, which includes the
non-normative but widely accepted rate-distortion optimization (RDO) process, i.e.,
the rate-constrained motion estimation and mode decision, has become a challenging
and difficult research issue. Usually, rate controller is useful at given residual signals
to determine quantization parameter (QP).However, to perform RDO, a QP should
first be predetermined. This leads to a classical chicken and egg dilemma. Therefore,
how to understand and predict the coding behavior after RDO with different QPs is
the core problem of the H.264/AVC rate controller. In this work, we attempt to adopt
coding behaviors of customized residues that are extracted from part of RDO to
18
calculating the direct MAD (without ME) between reference frame and current frame.
However, it still suffers from the same problem as mentioned [3]-[8].
In this work, we notice an interesting and important observation, i.e., the coding
behavior of some customized residues (extracted from part of RDO) is quite similar
with the coding behavior after the whole RDO process with different QPs. Thus, the
intuition of our approach is to employ a linear combination of the estimated bitrate
curves with customized residues to predict the actual bitrate curve after the whole
RDO process. Experiments show that such a R-Q modeling framework provides a
more accurate estimation of the actual bitrate than existing MAD-based model [1]
does. In addition, it is worth noticing that when motion estimation is performed, we
can extract customized residues to construct the proposed R-Q model and record
reusable information for subsequent rate-constrained mode selection at the same time.
Finally, a quantization-free rate-quantization (R-Q) source modeling framework is
proposed to model customized residues as well. In short, the newly proposed source
modeling framework can be easily implemented with lower computational
complexity.
This paper is organized as follows. In Sec. 2, we first review the RDO process,
and attempt to observe the coding behaviors of customized residues and RDO process,
respectively. We will propose a new source modeling framework within the part of
RDO process in Sec. 3. Then, in Sec. 4, we present a modified quantization-free R-Q
modeling framework to customized residues. Then, Sec. 5 and Sec. 6 are experimental
results and conclusion, respectively.
2. REVIEW R-D OPTIMIZATION PROCESS
2.1. Review R-D Optimization Process
In H.264/AVC standard [10], it supports a tree-structured hierarchical
macroblock partitions. In JM reference software [9], a recommended Lagrange
multiplier optimization technique [11] is adopted to offer a systematic way to select
the optimal coding mode. For an inter macroblock, the rate-constrained variable block
ME is first applied to find minimal prediction error by minimizing
J (mv,λ ) = D(s,c(mv)) +λ ⋅R(mv −pmv) (1) , where mv is the motion vector and
pmv is the predicted motion vector. The rate term, i.e., R(mv-pmv) computed by a
lookup table, presents the relative bitrate of motion vector information. D(s,c(mv)) is
the prediction error between the current block s and reference block c. Usually,
D(s,c(mv)) is computed by sum of absolute differences (SAD) or sum of absolute
diferences after Hadamard transform (SATD).λMOTION is the Lagrange
multiplier,which is given by
20
plot the actual bitrate curve of a frame after the RDO process with different QPs and
the actual bitrate curves of customized residue (16x16, 8x8 and 4x4) of a frame with
different QP. From Fig. 3, we observe that the bitrate curves of customized residues
are very similar to the actual bitrate curve after the RDO process. Therefore, we
conclude an interesting and important observation: the actual bitrate curve with the
same partition mode is a proper estimation of the actual bitrate curve after the RDO
process. Next, we are going to present how we use such important observation to
construct the R-Q source modeling framework for H.264/AVC.
Fig. 3 Plots the RRDO(q), R16x16(q), R8x8(q) and R4x4(q) .
3. PROPOSED RATE-QUANTIZATION SOURCE MODELING
FRAMEWORK
Given the above important observation, we start to employ linear combination of
the estimated bitrates of the two partition modes of sizes 16x16 and 8x8 to model the
actual bitrate3.
Where are the estimated bitrates with the same partition modes of
sizes 16x16 and 8x8, respectively. A(q), B(q) and C(q) are weighting coefficients
obtained via the regression. That is, we need to obtain the residues of a frame with
two partition modes of size 16x16 and 8x8 to estimate the corresponding bit rate.
In the RDO process, rate-constrained variable block ME is first applied to
produce the best matched residue of each partition mode. Then, the best matched
residue of each partition mode is fed into the rate-constrained mode selection to
determine the best partition of a MB. In fact, the ME of each partition mode can be
performed independently. Accordingly, we can partition rate-constrained variable
block motion estimation into two parts, 16x16/8x8 ME and other block size ME, as
illustrated in Fig. 4. In addition, it is worth noticing that when ME is performed, we
22
To avoid the operation of division [11], each coefficient at (i, j) , 0≤ i, j≤ 3 , denoted
as Xq(i,j) is quantized by
where qbits =15+ mod 6, and in which r=0
for (i,j) ={(0,0),(0,2),(2,0),(2,2)},r=1 for (i,j) = {(1,1),(1,3),(3,1),(3,3)}, and r=2,
otherwise, with
Here, we understand that the value of each quantized coefficient Xq(i,j) is strongly
associated with the weighting value of its position and quantization parameter.
4.2. Characteristic-based Extraction Framework for
H.264/AVC
First, we need to build a histogram to extract three characteristics of the input
source. As we stated before, the value of each quantized coefficient Xq(i,j) is strongly
associated with the weighting value of its position. Hence, three types of histograms
(r=0~2) of a frame are needed D0(x), D1(x) and D2(x), respectively. In addition, we
equivalently rewrite Eq. (6) as:
, where is and Qstep(q,r) is Of course, when
any transform coefficient |x(i,j)| is less than ),(),,(/2)1(),( jixrQMrQT M
qbit
M  
will be quantized to zero. Consequently, the number of quantized nonzero coefficients
QC(qi) can be easily obtained by following recursive formula:
In addition, the sum of absolute quantized nonzero coefficients QL(q) could be
computed by:
Note that for each item in Eq. (12), there is a dynamically stuffing
24
We perform rate controller recommended in [1]. Then construct the proposed R-Q
model at the same time. In Table 1, we can see that proposed R-Q model has a
substantial improvement compared
to MAD-based R-Q model [1] from high activity sequence “foreman” to low activity 
sequence “Salesman”. In Fig. 5, we also plot the estimated rate curves of “carphone” 
and “foreman”, with QP=21 and QP=27, respectively, in temporal from Table 1. We 
can also see that the estimated bitrate curve is more close to the actual coding bitrate
curve compared with MAD-based R-Q model [1].
6. CONCLUSION
In this work, we observed that coding behaviors of customized residues are very
similar with the coding behavior of RDO with different QPs. We employ this
important observation to model the coding behavior of the input source after RDO
with different QP. Experimental results show that the proposed R-Q model has a
substantial improvement to existing MAD-based R-Q model for JM 10.2 [1] in terms
of accuracy of bit rate.
Fig. 5 The number of bits among actual rate curve (RDO), proposed rate curve and
MAD-based rate curve for continuous p-frames of carphone.qcif and foreman.qcif,
respectively.
Table. 1 The relative prediction error defined as Eq. (17) from high activity sequence
“foreman” to low activity sequence “Salesman” with diferent QP and diferent 
bandwith, performing rate control in [1].
26
Video,” IEEE Trans. on Circuits and Systems for Video Technology, vol. 10, no.6, pp. 
878-894, Sep. 2000.
[6] J. Wei, B. H. Soong and Z. G. Li, “A New Rate-Distortion Model for Video
Transmission Using Multiple Logarithmic Functions,” IEEE Signal Processing 
Leters ”, vol. 11, no.8, pp. 694-697, Aug. 2004.
[7] Y. Liu, Z. G. Li and Y.C. Soh, “Adaptive Mad Prediction and Refined RQ model 
For H.264/AVC Rate Control,” International Conference Acoustics, Speech, and
Signal Processing, Proceedings, pp. 905-908, May, 2006
[8] T. Chiang and Y.-Q. Zhang, “A new rate control scheme using quadratic rate 
distortion model,” IEEE Trans. Circuits Systems Video Technology, vol. 7, pp.
246–250, Feb. 1997
[9] “JM10.2 software package,”htp:/iphome.hhi.de/suehring/tml/
[10] Draft ITU-T Recommendation and Final Draft International Standard of Joint
Video Specification, JVT-G050, Joint Video Team (JVT) of ISO/IEC MPEG and
ITU-T VCEG, 2003.
[11] K. P. Lim, G. Sulivan and T. Wiegand, “Text Description of Joint Model 
Reference Encoding Methods and Decoding Concealment Methods,” JVT-N046,
Hong Kong, Jan. 2005.
28
2 演算法大約說明
編碼模式位元率控制演算法如下：
步驟1: 編碼模式複雜度取得與預估
對不同的編碼模式進行不同的複雜度取得與預估
(A) 編碼模式MODE 為P16x16、P16x8 或P8x16 模式：
利用移動估測量化參數QPME計算λ MOTION，對目前MB進行inter 模式的移動補償，
並計算其複雜度MADMODE，MODE={P16x16, P16x8, P8x16}。其中QPME 設定為：
其中i 為MB 編號。
(B) 編碼模式MODE 為P8x8：
根據P16x16、P16x8 與P8x16 模式之中的最小複雜度MADmin 透過P8x8 複雜度線
性預測模型計算P8x8 複雜度MADP8x8。
(C) 編碼模式MODE 為I16x16：
根據SAD 判斷標準選出SAD 最小的I16x16 預測模式，並將原始MB 與預測MB
相減取得殘值並計算其複雜度MADI16x16。
(D) 編碼模式MODE 為I4x4：
根據I16x16 模式複雜度MADI16x16 利用I4x4 複雜度對數預測模型計算I4x4 複雜度
MADI4x4。
(E) 其餘編碼模式如SKIP 與IPCM：
不需要進行位元率控制，跳至步驟4。
步驟2: 計算編碼模式目標位元率
根據編碼模式的殘值複雜度MADMODE、整張畫面的預測複雜度和畫面剩餘的
位元數目
步驟3: 決定編碼模式量化參數
使考慮下列不同情況：
(A) 當目前MB 為畫面中第一個MB 時：
則不進行量化參數計算，而是直接選用上一張畫面中所有區塊的平均量化參數，
以避免畫面中第一個MB 決定出來的QP 侷限了之後MB 的QP 變動。
(B) 當剩餘的位元小於0 時：
表示畫面中先前編碼的MB 已經用盡所有的配額，則QP 應該決定的比先前區塊
的量化參數還大，才能使得所畫面產生的總位元數接近目標位元數
30
32
其中BFrame(i)為第i 張畫面的實際編碼位元數
A. 位元率為 25Kbps 時進行位元率控制實驗之各項比較:
I. 畫面位元率的比較 @ 25Kbps
(a) akiyo @ 25Kbps (b) carphone @ 25Kbps
(c) claire @ 25Kbps (d) foreman @ 25Kbps
34
(c) claire @ 25Kbps (d) foreman @ 25Kbps
36
38
40
42
44
46
48
50
52
54
56
由於大部分的 H.264/AVC 位元率控制之最大詬病為位元率控制無法立即符合
當下所需的目標位元率，儘管最終編碼位元率看似符合位元率控制之需求，但
並非即時反應而是事後補救，導致最後平均值看似符合，但是在任一時間內都
有可能導致編碼器緩衝區滿溢或欠位，因此造成畫面品質低落或使解碼器產生
解碼延遲。
要使視訊位元率變動降低，必須要更準確的將畫面編碼為符合目標位元率
的位元串流，這需要準確的計算 QP。本研究提出了一個較不同的想法，將位
元率控制在往下進行更細部的編碼模式位元率控制，對於每一個 MB 的所有
編碼模式皆決定相對應的 QP。這樣不但可取得較準確的複雜度，同時針對不
同複雜度所計算的 QP 與位元率控制的匹配性較高，較不會因為 RDO 選擇某
個編碼模式而導致位元率控制不準確。
經過實驗結果可知，無論是低頻寬或是高頻寬在位元率的控制上，本研究
皆可達到精準及穩定的輸出位元率，同時較 JM12.2 更能維持畫面的品質。在
緩衝區的穩定度上，本研究大幅的優於 JM12.2，因此更適合用於網路傳輸或
是緩衝區較小的應用。
58
I. 3.3.1 研究方法流程
圖 3-1 流程圖
圖 3-1 為我們的流程圖，此流程圖共有兩個階段，我們接著解釋每一部份詳
細的步驟。
第一階段；
步驟 1. 資訊收集；
實際的使用 Intra-VOP 之量化參數，不作位元率控制模擬壓縮該秒所有
VOP 並紀錄以下資訊；
(A)該秒之內每個 Inter-VOP 之運動補償殘值；
(B)該秒之內每個 Intra-VOP 經過壓縮之後之實際位元總量；
(C)該秒之內每個 VOP 輪廓經過壓縮之後總位元量；
(D)該秒之內每個 Inter-VOP 之非透明像素(non-transparent pixel)總數量。
步驟 2. 計算變異係數；
收集訊息
計算變異係數
初始化參數
計算量化參數
編碼
更新參數
第一階段 第二階段
下一張
畫面
60






1
0
1
0
,
N
i
M
j
Cb
ji
Cb
Cb
i
PP ，






1
0
1
0
,
N
i
M
j
Cr
ji
Cr
Cr
i
PP ，
Y
jiP , 、
Cb
jiP , 、
Cr
jiP , 分別為第 i 個 Inter-VOP 之第 j 個非透明像素的 Y、
Cb、Cr 像素值。
Y
iM 、
Cb
iM 、
Cr
iM 分別為第 i 個 Inter-VOP，Y、Cb、Cr 非透明像素
的總數量。
此一步驟為將這一秒之內所有 Inter-VOP 的 Y、Cb、Cr 像素值加總起
來。
步驟 1.2 將 YP 、 CbP 、 CrP 分別除上 Y、Cb、Cr 非透明像素的總數量，
目的在求 Y、Cb、Cr 的平均值；
Y
Y
Y
M
P
P  , Cb
Cb
Cb
M
P
P  , Cr
Cr
Cr
M
P
P  ，
YM 、 CbM 、 CrM ，分別為所有 Inter-VOP 中 Y、Cb、Cr 非透明像
素之總數量， 



1
0
N
i
Y
i
Y MM ， 



1
0
N
i
Cb
i
Cb MM ， 



1
0
N
i
Cr
i
Cr MM ，
步驟 1.3 計算總平均P ；
3
CrCbY PPP
P

 (3-1)。
步驟 2. 計算第 i 個 Inter-VOP 之變異係數， 2i；
步驟 2.1 分別計算第 i 個 Inter-VOP 之 Y、Cb、Cr 變異係數；
 



1
0
2
,
2)(
Y
iM
j
Y
ji
Y
i PP ，
62
為 VOL0，Intra-VOP 之量化參數皆為 7，那麼我們設定如下；
VO0 之 VOL0 之 P-VOP 之 QP_prev 設為 7；
VO0 之 VOL0 之 B-VOP 之 QP_prev 設為 7；
VO1 之 VOL0 之 P-VOP 之 QP_prev 設為 7；
VO1 之 VOL0 之 B-VOP 之 QP_prev 設為 7；
此參數一個 VOL只要設定一次即可。
(F) B 為一秒的總頻寬， i為目前所剩頻寬，在還沒進行壓縮之前 i=0，經由第一
階段之資訊，我們可以預先將 i扣除掉固定不會變更之位元資訊，如此我們
可以知道剩餘多少頻寬可供 Inter-VOP 所用，



N
i
SHAPE
i
VOPI
i BBB
0
_
0 )( ；
其中 VOPIiB
_ 為此 Intra-VOP 壓縮後之實際位元，如果此 VOP 不是 Intra-VOP，
那麼其 VOPIiB
_ 為 0。 SHAPEiB 為此 VOP 輪廓使用 CAE 外型編碼所花費之實際位
元，此資訊不論 Intra-VOP 或 Inter-VOP 皆會有此位元資訊。
IV. 3.3.4 Inter-VOP 量化系數之計算
我們將(2-6)式重新改寫成(3-3)式
i
i
i
Y
i
i SL
KM
Q

2* )( (3-3)，
其中 *iQ 為我們所求得之最佳量化 step size，K 為模型參數， i為該 Inter-VOP
之標準差，L 為判斷頻寬是否足夠把未編碼 Inter-VOP 編碼完之依據，
CAL ii ， 其中 i為目前所剩之頻寬， iA 為未編碼之 Inter-VOP 總面積，C
是一個模型參數。當 L < 0 時表示所剩頻寬不足以將剩餘 Inter-VOP 編碼完，此
時我們會將量化 step size 先設成最大值。
用此算出來之 *iQ 為量化 step size，在 H.263 量化規則裡，
*
iQ =2QP，故我們
需將 *iQ 除以二，如此即成為我們所需之量化參數。但這並不是我們最後之量化
64
(B-3) iA 為剩餘未編碼 Inter-VOP 面積，必須依照目前壓縮完畢之 Inter-VOP
更新， Yiii MAA 1 ；
(B-4) QP_prev 為上一張 Inter-VOP 的量化參數，
QP_prev = QP_curr；
3.4 實驗結果
我們使用 MoMuSys Codec 做實驗，此一版本的 MPEG-4 Codec 支援 VM8
的位元率控制並且也有 MoMuSys 自己所撰寫的多物件位元率控制，以下我們所
實驗之 VOP 大小皆為 CIF 352*288，播放畫面大小亦是 CIF 352*288，畫面速率
為每秒 30 張，每個 VOL 共 300 張畫面，一個畫面為兩個加上輪廓資訊之物件所
組成，我們分別比較GOV = IPPPPP…與 IBBPBBPBBPBBPBB，並且考慮加上失
真加權在不同頻寬之下的結果。
(a) Foreground (b) Background
(c) Foreground mask (d) Background mask
66
(e) Composite frame
圖 3-3 bream 之 VOP
第二種視訊序列如圖 3-3，共兩個物件，每個物件各自包含一個 VOL，稱
為 VOL0。VO0 為 bream 圖 3-3a 加上一個輪廓資訊 3-3c 圖，VO1 為一個水族箱
圖 3-3b 加上一個扣掉 bream 輪廓資訊之輪廓圖 3-3d，組合之後的圖形如圖 3-3e。
我們只使用 CIF 格式的影像序列，因為我們認為清楚的視訊才會有被大眾接
受的機會，隨著硬體的進步，很多在低頻寬低品質低處理器速度的限制將會越來
越不存在，所以我們也不將緩衝器(buffer)的變化列入實驗數據中，實際上，在現
階段生活中，多物件視訊的運用產品幾乎尚未問世，但是多物件視訊的運用，在
未來將會被廣泛的應用在生活中是可預期的。在視訊品質方面，物件化視訊所追
求的品質是必須針對物件而定的，本論文所強調的方向在於可以透過參數的調整
使得物件之重要性程度能顯示在結果之中。
在第一階段的壓縮中，我們嘗試用了許多不同的量化參數去計算每張 VOP
之變異係數，實驗結果顯示，運動補償殘值之變異係數不論是用最精細的 1 或者
是最粗操的 31，其結果皆相差不遠，也就是說量化參數 1~31 我們皆可以使用，
以下我們的實驗是使用量化參數 7 的運動補償殘值來計算變異係數，一般都會使
用量化參數為 4、8、16 做實驗，但是我們選擇一個質數 7，目的是希望能夠說
明在第一階段的量化參數值對我們的位元率控制方法影響不大。
VI. 3.4.1 實驗 1 (使用 GOV=IPPPP….之格式)
表 3-1 至表 3-4 為比較 VM8、Momusys 和我們的方法在不同頻寬之下的實
驗結果，在表 3-1 與表 3-3 中我們並沒有對物件加上失真加權，表 3-2 與表 3-4
68
由於 VM8 無法支援失真加權，所以只有列上 Momusys 與我們所建議演算法之數
據。表 3-1 與表 3-2 在有無失真加權的情形下，壓縮過後的位元率與目標位元率
皆在合理的範圍之內。在加入失真加權的情形之下，可以看出不論是在 Momusys
或我們的演算法之中，都可以做到應有的控制，例如我們的算法在 384000bps
中，在未加入失真加權的情形下，VO0 與 VO1 的 PSNR 分別為 39.58 與 47.98，
若是在加入失真加權的情形之下分別為 40.8 與 44.82，可以看的出加入失真加權
之後，VO0 的 PSNR 增加，VO1 的 PSNR 減少，這也是我們所預期的結果。
Bit Rate(1000bps) PSNR
Algorithm
Target Actual VO0 VO1 VO0 V01
Proposed 512 516.20 360.31 155.89 33.14 43.67
VM8 512 519.76 378.93 140.83 33.82 45.03
Momusys 512 522.38 400.17 122.21 34.12 44.60
Proposed 640 637.72 468.78 168.94 34.41 44.50
VM8 640 648.01 482.331 165.68 34.94 46.00
Momusys 640 649.45 513.55 135.9 35.29 45.32
表 3-3 bream 無失真加權，使用 GOV=IPPPP…之格式實驗結果
Bit Rate(1000bps) PSNR
Algorithm
Target Actual VO0 VO1 VO0 V01
Proposed 512 518.27 377.45 140.82 33.38 41.94
VM8 512 X X X X X
Momusys 512 521.98 400.19 121.79 34.09 44.66
Proposed 640 643.77 499.51 144.26 34.76 42.43
VM8 640 X X X X X
Momusys 640 649.84 517.50 132.34 35.31 45.27
表 3-4 bream 前景與背景失真加權 5:1，使用 GOV=IPPPP…之格式實驗結果
表 3-3、表 3-4 為圖 3-4 的 VOP 實驗結果，由於 bream 這個 VOP 其視訊較
70
表 3-5 與表 3-6 為圖 3-3 的 VOP 在 384000bps 與 512000bps 分別在有無失真
加權的情形下的實驗結果。由於 Momusys Codec 中的 VM8 位元率控制演算法在
B-VOP 的支援上尚有瑕疵，所以無法列出比較數據。在表 3-5 與表 3-6 中我們可
以發現在 Momusys 的演算法中雖然可以支援 B-VOP，但是壓縮之後的結果我們
發現，Momusys 對 B-VOP 的控制並不是很好，已經超出目標位元率許多。
Bit Rate(1000bps) PSNR
Algorithm
Target Actual VO0 VO1 VO0 V01
Proposed 512 517.50 328.81 186.69 33.05 43.77
VM8 512 X X X X X
Momusys 512 787.86 653.21 134.65 36.08 41.77
Proposed 640 632.72 441.00 191.72 34.10 44.23
VM8 640 X X X X X
Momusys 640 901.34 734.76 166.55 36.67 46.63
表 3-7 bream 無失真加權，GOV=IBBPBBPBBPBBPBB，15VOPs 實驗結果
Bit Rate(1000bps) PSNRAlgorithm
Target Actual VO0 VO1 VO0 V01
Proposed 512 518.40 357.19 161.21 33.24 43.22
VM8 512 X X X X X
Momusys 512 802.79 664.30 138.49 36.17 42.24
Proposed 640 634.14 468.06 166.08 34.35 43.50
VM8 640 X X X X X
Momusys 640 906.79 740.75 166.04 36.64 42.78
表 3-8 bream 前景與背景失真加權 5:1，GOV=IBBPBBPBBPBBPBB，15VOPs 實
驗結果
表 3-7 與表 3-8 為圖 3-3 的 VOP 在 512000bps 與 640000bps 分別在有無失真
72
(三) 參考文獻
Note:部分參考文獻已列在前面兩篇國際會議references中。
總整理如下：
[1] T. Berger, Rate Distortion Theory, Prentice-Hall, Englewood Cliffs, NJ, 1971.
[2] T. Chiang, A rate control scheme using a new rate-distortion model, JCoding of
Moving Pictures and Associated Audio MPEG95/0436TC1/SC29/WG11, Dallas, TX,
Nov. 1995.
[3] T. Chiang, Y.-Q. Zhang, A new rate control scheme using quadratic rate-distortion
modeling, IEEE Trans. Circuits Systems Video Technol. 7 (1997) 246-250.
[4] L.D. Davisoon, Rate-distortion theory and applications, Proc. IEEE 60 (1972)
800-808.
[5] Z. He, Y.K. Kim, S.K. Mitra, Low delay rate control for DCT video coding via ρ
-domain source modeling, IEEE Trans. Circuits Systems Video Technol. 11 (2001)
928-940.
[6] Z. He, S.K. Mitra, A unified rate-distortion analysis framework for transform
coding, IEEE Trans. Circuits Systems Video Technol. 11 (2001) 1221-1236.
[7] Z. He, S.K. Mitra, Optimum bit allocation and accurate rate control for video
coding via ρ-domain source modeling, IEEE Trans. Circuits Systems Video Technol.
12 (2002) 840-849.
[8] M. Jiang, N. Ling, On Lagrange multiplier and quantizer adjustment for H.264
frame-layer video rate control. IEEE Trans. Circuits Syst. Video Techn. 16(5):
663-669 (2006)
[9] M. Jiang, N. Ling: Frame-layer H.264 rate control improvement using Lagrange
multiplier and quantizer. ISCAS (5) 2005: 4369-4372
[10] H.-J. Lee, T. Chiang, Y.-Q. Zhang, Scalable rate control for MPEG-4 video,
IEEE Trans. Circuits Systems Video Technol. 10 (2000) 878-894.
[11] J. Lee, B. Jeon, Fast mode decision for H.264, in: Proceedings of IEEE
International Conference on Multi-media and Expo, Taipei, Taiwan, 2004.
[12] W. Li, J.-R. Ohm, M. van der Schaar, H. Jiang, S. Li, MPEG-4 video verification
model version 18.0, in: ISO/IEC JTC1/SC29/WG11 N3908, Pisa, Italy, 2001.
[13] Z. Li, F. Pan, K.-P. Lim, G. Feng, X. Lin, S. Rahardja, Adaptive basic unit layer
rate control for JVT, JVT-G012, March 2003.
[14] Y. Liu, Z.G. Li and Y.C. Soh, A Novel Rate Control Scheme for Low Delay
Video Communication of H.264/AVC Standard. IEEE Trans. Circuits System Video
Technol. 17(2007) 1051-8215.
[15] K.-P. Lim, G. Sullivan, T. Wiegand, Text Description of Joint Model Reference
Encoding Methods and Decoding Concealment Methods, JVT-N046, Jan, 2005.
74
(四) 計畫成果自評
執行完本計畫研究成果，為兩篇一流國際會議論文(VCIP 和 ICASSP) 及完成兩
份碩士論文，計畫原定至 H.263 和 MPEG4 位元率控制，由上述國際會議論文及
碩士論文成果，可知計畫研究成果已延伸至 H.264 位元率控制量化參數
(quantization parameter:簡稱 QP) 決定之改良，而且，原計畫是定兩年，但只核
可一年，所以可說執行本計畫應已有很好成果，計畫主持人已達成”善盡計畫”
之責任。
