2圖 1、霧氣瀰漫的影像
以霧氣所造成的事故來說，根據交通部臺灣區國道高速公路局從民國 92 年至 96 年的 11 月至 3 月
間因大霧所發生的交通事故統計，如表 1 所示，其中，A1 類交通事故係指造成人員當場或 24 小時內
死亡之交通事故，A2 類交通事故則是指造成人員受傷或 24 小時後死亡之案件，A3 類指車輛碰撞造成
財損，但無人員傷亡案件。
表 1、台灣區高速公路局在霧氣所釀成之災禍統計表
從上統計表可發現，因濃霧所造成的災害連年來頻傳，根據肇事緣故分析，多數事故是由於在行
駛時所造成，駕駛者在長途駕駛的過程中，因大霧或各種天候所造成的能見度降低的情形下，以致駕
駛者即使集中注意力，仍舊可能因視線不清而不及查覺突發狀況的發生，導致釀成不可預期的災禍，
特別是在山區的大霧下行駛，或是在有霧的海面上航行時，更為容易造成事故，而且海上的船隻若因
霧的影響而發生事故，那發生的損傷更是無法故計的。雖然現今的 GPS 系統雖然會告知路況，但在濃
霧的情形下，就會產生無法接收的後果，且 GPS 系統不見得能迅速回報眼前的突發狀況，勢必還是需
要肉眼的察覺及反應，為此本計畫希望能在影像處理的輔助下，有助於提升在霧中行駛的識別度。再
者，濃霧的影響，除了導路交通外，也會使光學器材或網路設備在擷取時產生無法辨識或接收的情況，
如監測、監控、自動導航、移動物追踨，都會造成極高的誤差與不可預期的後果。
研究目的暨文獻探討
近年來，經濟的發展促使交通問題愈來愈受到重視，由於交通監控系統越來越廣泛的採用電腦視
覺和和圖像處理技術，交通運輸量逐年增加，隨著各種類型的交通的研究與發展，將更進一步應用於
船隻的追蹤與計數。由於大量的交通監控相關研究便隨之而興起，然而在這些相關研究中，智慧型交
通運輸系統(Intelligent Transportation System，ITS)則是被用來解決交通問題的方法之一，它整合了通
訊，控制，電子與資訊等技術，使有限之運輸資源作最有效的利用，以提高交通安全，改善人民生活
品質及強化經濟競爭力。智慧型交通運輸系統的技術包括了微電子技術、自動化人工智慧、感測技術、
通訊系統)及控制等，其中一個最重要的項目則是電腦視覺的應用。因為 ITS 的有效運作，有賴於正確
之即時交通監控參數，而應用影像處理與電腦視覺技術，不僅成本低廉(大量降低人力成本)與安裝容
霧季所造成的事故（11 月至 3 月）
年期 A1 A2 A3
92.11.~93.03. 52 334 4,699
93.11.~94.03. 32 311 4,889
94.11.~95.03. 44 384 5,696
95.11.~96.03. 44 314 4,413
92-96 年合計 172 1343 19,697
4Computer Society Conf.On Computer Vision and Pattern Recognition, Vol. 2, pp. II186-II193, 2001
[5]Srinivasa G. Narasimhan and Shree K. Nayar, “Interactive (De)Weathering of an Image using Physical 
Models,” Proceedings of the ICCV workshop on Color and Photometric Methods in Computer Vision, pp.
1387-1394, 2003.
[6]Robby T. Tan , Niklas Pettersson and Lars Petersson, “Visibility Enhancement for Roads with Foggy or 
Hazy Scenes,” IEEE. On Intelligent Vehicles Symposium, pp. 19-24, June. 2007.
[7]Robby T. Tan, “Visibility in BadWeather from a Single Image ”,IEEE Conf. Computer Vision and Pattern
Recognition, pp.1-8, June. 2008
[8]Nicolas Hautiere and Didier Aubert , “Contrast Restoration of Foggy Images through use of an Onboard 
Camera,” IEEE Conf. On IntelligenceTransportation Systems, pp. 601-606, Sept. 2005.
[9]Rafael C. Gonzalez, Richard E. Woods, Digital Image Processing second edition, Prentice Hall, 2002 New
Jersey.
[10]尹燕輝，2005，基於視訊處理之初期火警的煙霧偵測，高雄應用科技大學，碩士論文。
[11]Kenji Mori, Tomokazu Takahashi, Ichiro Ide, Hiroshi Murase, Takayuki Miyahara and Yukimasa Tamatsu,
“Fog density recognition by in-vehicle camera and millimeter wave radar”, Internation Journal of
Innovative Computing, Information and Control, Vol.3, No.5, pp.1173-1182, Oct. 2007
[12]Kenji Mori, Tomokazu Takahashi, Ichiro Ide, Hiroshi Murase, Takayuki Miyahara and Yukimasa Tamatsu,
“Recognition of foggy conditions by in-vehicle camera an milimeter wave radar”, 2007 IEEE Intelligent
Vehicles Symposium, Vol.3, No.5, pp.87-92, June. 2007
[13]Yoav Y. Schechner, Srinivasa G. Narasimhan, and Shree K. Nayar “Instant Dehazing of Images Using
Polarization”, IEEE Computer Society Conf.On Computer Vision and Pattern Recognition, Vol. 1, pp.
I325-I322, 2001
[14]Yoav Y. Schechner, Srinivasa G. Narasimhan, and Shree K. Nayar“Polarization-based vision through
haze”,Applied Optics, Vol. 42, No. 3. January. 2003.
[15]R. Fatal “Single image dehazing”, International Conf. on Computer Graphics and Interactive Techniques,
No. 72, pp.1-9 2008.
[16]Colins, R. T., A. J. Lipton, and T. Kanade, “A System for Video Surveilance and Monitoring”, Technical
Report, CMU-RI-TR-00-12, Robotics Institute, Carnegie Mellon University, May 2000.
[17]Gupte, S., Masoud, O., Martin, R.F.K., Papanikolopoulos, N.P., "Detection and classification of vehicles,"
IEEE Transactions on Intelligent Transportation Systems, Volume 3, Issue 1, pp.37 - 47, March 2002.
[18]Bing-Fei Wu, Shin-Ping Li and Yuan-Hsin Chen, "A real-time multiple-vehicle detection and tracking
system with prior occlusion detection and resolution," IEEE International Symposium on Signal
Processing and Information Technology, pp.311 - 316, Dec. 2005.
[19]Lin Bo and Zhou Heqin, "Using object classification to improve urban traffic monitoring system," IEEE
International Conference on Neural Networks and Signal Processing, Vol. 2, pp.1155-1159, Dec. 2003.
[20]Tseng, B. L., Ching-Yung Lin, and Smith, J. R., "Real-time video surveillance for traffic monitoring using
virtual line analysis," IEEE International Conference on Multimedia and Expo, Volume 2, pp.541-544,
Aug. 2002.
[21]Wakabayashi, Y. and Aoki, M., "Traffic flow measurement using stereo slit camera," IEEE Intelligent
Transportation Systems, pp.198 - 203, Sept. 2005.
[22]Lars Petersson ,Robby T. Tan ,Niklas Petersson, “Visibility Enhancement for Roads with Foggy or Hazy 
Scenes”, IEEE. On Intelligent Vehicles Symposium, pp. 19-24, June, 2007
[23]Da-Jinn Wang, Thou-Ho (Chao-Ho) Chen, Yen-Hui Yin, Tsong-Yi Chen, “Smoke Detection for Early 
Fire-Alarming System Based on Video Processing”, Journal of Digital Information Management, Vol. 6,
No.2 , pp. 196-202, April 2008.
[24]Didier Aubert and Nicolas Hautiere, “Contrast Restoration of Foggy Images through use of an Onboard 
Camera,” IEEE Conf. On Intelligence Transportation Systems, pp. 601-606, Sept. 2005.
6圖 3、Lambert-beer 模型
在很多情況衰退和大氣光影響是同時存在的，本計畫詳述大氣散射對色度的影響，包含一般構造和分
析，而且針對影像中的霧首加以解析，因此，本計畫描述影像在能見度衰退的條件下之現象。由下圖
4 可以看到攝影機(sensor)原本是由圖中的 direct transmission 接收得到純淨無霧害影響的影像，但由於
霧微粒子的影響下，受到衰退因子的影響，及大氣散射光(airlight)的影響下，得到一個退化的影像，因
此可由衰退係數及大氣散射光的組成，得到一個衰退的線性組合[2]：
E (x ) = E d (x ) + E a (x ) (1)
d ( x )E d ( x ) = E ( x ) ( x ) e   (2)
d ( x )E a ( x ) = E ( x ) ( 1 - e ) (3)
圖 4、大氣散射光在霧中所產生影響的示意圖
Ed(x)代表經由大氣衰減後所得到的景物輻射光，也就是能見度衰退的影像，Ea(x)代表的大氣懸浮微粒
所產生的散射光，也就是大氣散射光，E∞(x)表示大氣散射環境下的大氣光亮度，ρ(x)表示一個影像的
正規化輻射度，也就是景點的反射係數，β為代表大氣衰退係數，d(x)表示攝影機至影像物體的距離。
將式(1)做反推導的動作，就可得到復原公式：
d(x )
d (x )
1
E (x) (x)=[E(x)- E (x)(1 - e )]
e

   (4)
而在衰退影像中是由物體的表面係數及大氣散射係數所建構而成的衰退模式，結合 RGB 色彩係數，由
雙色大氣散射模型(dichromatic atmospheric scattering model)[1]來表示，如圖 5 所示：
圖 5、雙色大氣模型
圖 5 中的 D 代表在景點中影像的資訊是未被大氣散射所影響的資訊，而 A 表示在影像範圍中，為在霧
的環境下亮光所及的區域。假設在晴朗的天候跟有霧的天候下，他們的明度有相同的光譜散射，因此，
本計畫可以將式(1)改寫為：
E(x)= pD+qA (5)
而 D 和 A 是代表單位純量的值，而 p 代表 Direct transmission 的量可表示為 d(x)E (x) (x)e  ，q 代表大
氣散射光(Airlight)的量也就可表示成 d(x)E (x)(1 - e ) 。因此，假設 D 和 A 不變的話，那麼就會得到大
8 ( r ) ( g ) ( b )
( rgb )
LC (x)+LC (x)+LC (x)
LC (x) =
3
(16)
若將激勵值相加取平均數，則可解決畫面色彩失調問題。因此將復原式(23)改成：
( restore ) ( rgb )
d (x )
( I)
'E (x) =[E(x) E *LC (x)]*e (17)
透過此復原式可還原霧化的影像。然而，由於還原前的影像，彩度會有所不足，因此，將還原後的影
像換至 YCbCr 色彩空間(式 26)，將 Cb 及 Cr 各乘上 1.7 倍的數值，再將 YCbCr 轉換回 RGB 色彩空間(式
27)，加強還原影像的彩度。
R R R
R
R
Y 0.299*E (r) 0.587*E (g) 0.114*E (b)
Cb (224*((E (b) / 255.0) (Y / 255.0))*0.5774 128
Cr (224*((E (r) / 255.0) (Y / 255.0))*0.7133 128
   
    
    
(18)
Correct
Correct
Correct Correct
Correct
E (r) (Y / 255) 1.402*((Cr 128) / 224)*255
E (b) (Y / 255) 1.732*((Cb 128) / 224)*255
Y 0.299*E (r) 0.114*E (b)
E (g)
0.587
 
   
 
   
   
 
(19)
Ecorrect(c)代表經由加強色度的影像輸出結果，ER (c)代表霧化增強後的影像。(c 代表 RGB 各通道) 經由
增強後的影像，影像顏色會有偏色的影響，因此進行一種改良式的直方圖均衡化的方法，讓影像色彩
校正至人眼的白光色彩。首先，將影像 RGB 各別分離成灰階的圖像 G(c)(c 代表 RGB 各通道)，再統計
各通道的灰階的直方圖機率密度函數(式 28)，接著，將各通道中直方圖的機率密度函數做調整，影像
大小假設為 320*240，則由灰階的出現次數應該都是 300，本計畫取 300 為分布圖的一個臨界調整值。
依此將影像原始亮度機率分布圖做權重的重新分配，再經由直方圖均衡化(式 29、式 30)的方式，將影
像做色彩校正。
1,......1,0
10
,)Pr(


Lk
k
n
n
r k
k
(20)
k
j
k k
j 0
k
r j k
j 0
n
S T(r )
n
P (r ) 0 r 1 k 0,1......L 1


 
    


(21)
k
k
EQ(c) S * max_ Limun
0 r 1 k 0,1......L 1

   
(22)
EQ(c)代表均衡化後的影像(c 代表 RGB 各通道)，Pr(rk)為機率密度，Sk 代表累計機率函數，nk 代表各灰
階亮度出現的次數，n 代表灰階的總出現次數，k 代表亮度階數。
霧的等級：由於在不同天候狀況下，各種不同的霧，所呈現的影像都會有所不同，所以本計畫將運用
模糊邏輯的原理以及 Sobel 邊緣檢測和標準差來區分霧的等級並可區分出霧清晰化的程度，因此利用
[23]所提及的模糊理論規則及規則庫，建立出霧等級的區別，流程圖如圖 6 所示。索貝爾運算子(Sobel
Operator)主要用來檢測影像的邊緣，它運用了偏導數運算原理，對整張影像掃描以建立出梯度(Gradient)
影像。索貝爾濾波器包含了兩個遮罩，分別是 Gx(X 軸方向)和 Gy(Y 軸方向)，負責偵測 X 與 Y 方向的
邊緣變化情形，而本計畫再計算經過 Sobel 邊緣檢測後的影像平均值：
n*m
1
Sobel _ i m age _ pixel
Sobel _ avg
n *m


(23)
其中，Sobel_avg 代表整張影像的平均值，而 Sobel_image_pixel 為 Sobel 影像中的每一個 pixel 點，n*m
代表影像的大小。一般來說，影像之標準差的值愈大代表變化大，亦表示對比度較大：反之亦然。一
般而言，標準差愈大則資訊內容愈豐富。首先，要先計算整張影像的平均值，平均值愈大則影像之平
均亮度愈亮，愈小則影像較暗：
n*m
1
(Im age _ pixel)
Im age _ avg
n * m


(24)
10
實驗結果
本實驗採用傳統 CCD 攝影機拍攝影像序列，影像解析度為 320×240 pixels，取樣率每秒 29.97 張。
圖 7(a)為國道監控影像，圖 7(b)為經本方法處理後之國道監控影像；圖 8(a)為下雨後之建築物起霧影
像，圖 8(b)為經本方法處理後之建築物影像。
(a) (b)
圖 7、(a)為國道原始影像； (b)為(a)復原後的結果。
(a) (b)
圖 8、(a)為建築物原始影像； (b)為(a)復原後的結果。
結論與建議
本計畫提出一個針對視訊中所呈現的霧化影像所提出的影像除霧方法，透過本計畫所提之方法，
去除影像中霧氣的影響，並應用於交通監視之畫面。在本計畫中，針對霧化的影像加以分析其影像中
霧的濃淡程度，再根據影像中梯度的變化程度及影像標準差，分析出有無霧的存在，再進行濾除的動
作，分析其影像中色彩三原色的變化，並計算其每個像素值的三色激勵值，再透過大氣散射原理的方
式，去除霧化的影像，由於除霧後的畫面，會有偏暗及偏色的效果存在，因此，再透過改良型的直方
圖均衡化方法，來加強影像的亮度，透過本計畫所提之演算法，可去除視訊中霧化的影像，增加監控
系統的畫面可視性。
在本方法中，除霧後的影像，雖然可得到較佳的可視性，但在偏濃的影像中濾除的效果並不佳，
如實驗結果中的 video1 所呈現的結果，雖然可看到 video1 的邊緣偵測的些微的成效，但對於整體影像，
還真是無法辨別的清楚，而 Jockey_01 雖然濾除了，可看到賽馬上的號碼，但卻無法全部看清楚，且
畫面色調也有失調的現象，因此對於濃霧的影像，可再深入分析，針對濃霧加以改善，或是利用時間
域的方式進行改良，達成視訊去霧完整目標。
12
14
國科會補助專題研究計畫項下出席國際學術會議心得報告
日期：99年 9 月 27 日
計畫編號 NSC 98-2221-E-022-010
計畫名稱 基於大氣散射原理暨色彩分析之視訊除霧方法
出國人員
姓名
王大瑾
服務機構
及職稱
國立高雄海洋科技大學資訊
管理系/助理教授
會議時間
98 年 9 月 12 日至
98 年 9 月 14 日 會議地點 日本京都市
會議名稱
(中文)第五屆智慧型資訊隱藏和多媒體訊號處理國際研討會
(英文) IEEE 2009 Fifth International Conference on Intelligent Information
Hiding and Multimedia Signal Processing(IIHMSP2009)
發表論文
題目
(英文)A Compression-Resistant Invisible Watermarking Scheme
for H.264
參與會議照片：




無研發成果推廣資料 
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
