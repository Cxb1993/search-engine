 1 
發展癌症微陣列基因晶片資料之標誌基因擷取方式之結案成果報告 
計畫編號：NSC  98 － 2221 － E － 010 － 007 － 
執行期限：98 年 8 月 1 日至 99 年 7 月31 日 
主持人：鍾翊方 國立陽明大學 生物醫學資訊所 
計畫參與人員：陳毅誠、孫行人、黃盈禛 
 
一、中文摘要 
癌症是多重基因損壞所形成的複雜疾
病，即使是同樣病理學樣貌的癌症細胞
(外表型相同)中，不同的來源器官，損壞
的基因也不盡相同(基因型不同)，因此近
年來許多研究透過分析微陣列晶片的基因
表現資料，找尋與疾病相關的標誌基因。
藉此不僅可進一步探究標誌基因在癌症致
病機制上所扮演的角色，並可用來發展有
效與正確的癌症診斷工具。而基於我們先
前針對多類別癌症晶片資料所發展的標誌
基因挑選機制(Tsai et al., 2008)，本計畫
進一步發展數個標誌基因的擷取方式，並
透過類別診斷系統之建立及註解資訊之整
合，建立一使用者操作便利的分析工具。
在未來並盼針對不同癌症晶片資料擷取相
關的標誌基因，而再配合實驗作進一步的
驗證。 
 
關鍵詞：微陣列晶片、標誌基因 
 
Abstract 
Cancer is a complex disease developing 
from accumulating multiple gene mutations. 
In different subtypes of a cancer, patients 
may carry diverse gene mutations even if 
they have similar symptoms. Therefore, 
many studies have investigated the 
mechanism of carcinogenesis by analyzing 
gene expression profiles from microarray 
data. And many investigators have tried to 
identify marker genes related to a set of 
diseases for understanding the roles played 
by the genes in cancer biology and 
developing tools for efficient and accurate 
diagnostic prediction. In our previous study 
(Tsai et al., 2008), we have already 
developed a class-specific marker gene 
selection method for multiclass microarray 
data. Based on our experience and 
achievement, in this project we extend the 
scope of this research by further developing 
several novel marker gene selection methods 
and integrating these marker gene selection 
methods into a user-friendly computational 
tool. Here we not only provide diverse 
marker gene selection methods, but also we 
provide powerful tool for identifying and 
understanding the most significant marker 
genes, and confirming early diagnosis by 
building a diagnostic system and integrating 
annotation information. In the future, we 
plan to apply our marker gene selection 
techniques to microarray data for different 
cancers and verify our simulation results by 
wet-lab experiments. 
 
Keywords: Microarray, Marker gene 
 
二、緣由與目的 
緣起 
微陣列晶片資料(microarray data)這幾
年廣泛被用來檢測幾萬個基因的 mRNA
同時表現狀況，因這可大量檢測 mRNA
表現的特性，其可用於觀察生物體內不同
組織的基因表現(如 liver vs. brain)或生物
體內相同組織因為疾病造成之基因表現的
改變(如 tumor vs. non-tumor)等。由於癌
症在病理上檢視經常可看到其變異細胞的
相似外觀(phenotype)，但深入探究卻可發
現不同基因的損壞狀況(genotype)，因此
近年來許多研究者透過微陣列晶片資料來
比對造成癌症(不同癌症或癌症亞型)之基
因表現狀況，而進一步對癌症的致病、轉
移、復發機制作深入的探究。 
 
目的 
在我們先前的研究裡 (Tsai et al., 
2008)，我們針對多類別癌症微陣列晶片
資料，發展了一個標誌基因的挑選機制，
 3 
另外我們透過決策樹作法 (decision 
tree)組合這些表達癌症不同多(或單)類別
特徵但各自具有樣本區分能力的標誌基因，
而以少數的標誌基因做好癌症分類預測的
工作。圖三展示以具單一類別特徵之標誌
基因 MME (1389_at)及具兩類別特徵之標
誌基因 KIAA0372 (40517_at)(具有高基因
表現量於 ALL 及 MLL 兩類別)當作決策
樹的輸入特性，即可達到極佳的類別預測
效果(在 57 個樣本中，只有一個樣本被錯
誤歸類)。 
 
圖三：以決策樹進行血癌亞型類別診斷機制之建
立。此處單一類別特徵之標誌基因 MME (1389_at)
及 具 兩 類 別 特 徵 之 標 誌 基 因 KIAA0372 
(40517_at)(具有高基因表現量於 ALL 及 MLL 兩類
別)當作決策樹的輸入特性。 
 
(b) 挖掘隨時間或疾病的時期而基因表現
量逐漸增加或減少的單調基因： 
此部分的研究我們發展了一個單調基
因選擇器(monotonic gene selector)，其作
法主要是透過統計檢定的克 -瓦檢定
(Kruskal and Wallis, 1952)(又稱為 H-test，
是無母數的作法)及 Anova 檢定(是有母數
的作法)對多類別資料進行一系列分析(作
法在此不詳述)，以找尋具有基因表現量
隨時間或疾病的時期而逐漸增加或減少特
性的單調基因。另外為了證明單調基因的
表現模式的確存在於微陣列晶片資料，且
可被我們發展的單調基因選擇器所挖掘，
此處以胚胎幹細胞分化為神經幹細胞資料
組為例，探討在單調基因隨時間改變其基
因表現量和細胞的關係，以補足研究基因
表現和分析基因交互作用網路的完整性。 
此研究所用的不同天數所分化的胚胎
幹細胞及神經幹細胞的微陣列晶片資料整
合自美國國家衛生院 GEO 資料庫(Zhang 
et al., 2001, GSE9940)及陽明基因體中心
所產出資料，而以分化的進程依序分為以
下幾種類型：3 片原始胚胎幹細胞 (以
ESC 表示)、3 片胚胎體(以 EB 表示)、6
片分化十天胚胎幹細胞(以 Day10 表示)、
6 片分化 17 天胚胎幹細胞(以 Day17 表示)、
9 片神經幹細胞 (以 NSC 表示 )。另外
Day10 與 Day17 樣本又可細分為是否加入
纖維母細胞生長因子 2 (Fibroblast Growth 
Factor2, FGF2)誘導(分別以 d10+、d10、
d17+、d17 表示)。 
探勘單調基因之前，首先我們先確認
是否在分化過程會造成細胞樣本的差異，
以判斷此資料是否適合使用分化經過的天
數作分類。此處利用 ESC 及 NSC 樣本，
以 T 檢定挑出 9285 個基因表現量有顯著
差異的基因(q<0.01)，然後再利用主成分
分析法(principle component analysis, PCA)
將資料降維至三維空間，呈現圖的樣本分
佈資訊，圖中每個點代表一個樣本，並將
每個依照分化時間區分的類別標示特定的
顏色。此結果可告知我們兩件事：(1)樣
本在不同類別是各自散佈在不同的區塊，
因此可以使用分化時間當成一個適當的分
類依據。(2)以添加生長因子 FGF2 與否作
分類時，因 d10 與 d10+樣本、以及 d17
與 d17+樣本幾乎重疊在一起，表示進一
步以添加生長因子做資料的分類並不適當，
因此在後續的分析上，只以時間作為分類
依據，d10 和 d10+被歸於同一類別；同樣
的 d17 和 d17+也被分類在同一個類別。 
 
 
圖四：以主成分分析法展現胚胎幹細胞分化資料
之樣本分布狀況。 
 5 
至於其他所挑選出的單調基因是否可證實
與胚胎幹細胞分化有關，則有待進一步文
獻的搜尋。  
 
圖八：POU5F1（Oct4）基因在全部樣本的基因表
現狀況。 
 
四、計畫成果自評 
我們透過本計畫的支持而成功開發兩
種標誌基因的作法，並準備將結果發表在
國際期刊。不過未來仍有以下幾件事可繼
續努力：(1)將再嘗試將所發展的具單一
類別特定表現及多類別特定表現之標誌基
因的挑選方式用於其他多類別微陣列晶片
數據分析，另外由於現今註解資料庫的多
樣化，針對所挑選出的標誌基因與生物註
解知識的搭配上，仍有許多努力的空間。
(2)亦將再嘗試將單調特徵選擇器用於其
他跟時序或發育有關的微陣列數據分析。
特別由於與癌症機制相關的基因也已被證
實會隨患病的嚴重程度相關，因此癌症分
期微陣列晶片資料將是另個值得嘗試的機
會。(3)如前面提到許多被挑選出的單調
基因仍沒有被證實與幹細胞分化相關，需
再多花時間在相關文獻的檢視。另外從結
果得知所挑選出單調基因和細胞狀態的確
具有良好的相關性，但是哪些基因改變表
現量調控細胞改變，哪些基因的表現量是
細胞狀態改變後所造成的，尚未有定論，
需要再更進一步的生物研究才得以使單調
基因的研究更趨於完備，並期待在單調基
因的輔助下能夠進一步進行基因調控網路
的分析。 
 
五、 參考文獻 
Armstrong, S.A., Staunton, J.E., Silverman, 
L.B., Pieters, R., den Boer, M.L., 
Minden, M.D., Sallan, S.E., Lander, 
E.S., Golub, T.R., and Korsmeyer, S.J. 
(2002) MLL translocations specify a 
distinct gene expression profile that 
distinguishes a unique leukemia. Nature 
Genetics, 30, 41–47. 
Kruskal, W.H. and Wallis, W.A. (1952) Use 
of ranks in one-criterion variance 
analysis. J Am Stats Assoc, 47, 583-621. 
Takahashi, K. and Yamanaka S. (2006) 
Induction of pluripotent stem cells from 
mouse embryonic and adult fibroblast 
cultures by defined factors. Cell, 126, 
663-676. 
Tsai, Y.S., Lin, C.T., Tseng, G..C., Chung, 
IF., and Pal, N.R. (2008) Discovery of 
dominant and dormant genes from 
expression data using a novel 
generalization of SNR for multi-class 
problems. BMC Bioinformatics, 9:425. 
Zhang S.C., Wernig, M., Duncan, I.D., 
Brüstle, O., and Thomson, J.A. (2001) 
In vitro differentiation of transplantable 
neural precursors from human 
embryonic stem cells. Nature, 19, 1129-
1133. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 2 
會議名稱：IEEE World Congress on Computational Intelligence 
地點：西班牙 巴塞隆納 
日期：民國99年7月18~23日 
 
IEEE 舉辦的 World Congress on Computational Intelligence 是個兩年或四
年一度的綜合性國際會議，其結合三大人工智慧計算方面的國際會議，如類
神經網路、模糊理論及演化計算等(IJCNN、Fuzzy-IEEE、CEC-IEEE)。此次
與會人士高達兩千多人，每天每個時段有十六個議程同時在進行，讓人有時
深覺分身乏術而無法兼顧所有感興趣的主題。而透過參與此會議不僅可得知
最新計算智慧的理論發展，更可進一步瞭解不同領域應用的近期成果，如生
物資訊、腦科學、電機工程等。 
而本人這次發表的文章「 Support Vector-Trained Recurrent Fuzzy 
System」被安排於大會的第三天下午進行口頭報告(7/20)，所發表的文件請見
下一頁資料。此次除了藉機得知最新計算智慧的發展外，更希望瞭解會議中
與生物資訊應用相關的主題。其中每天有數個議程是在探究演化計算於生物
資訊或生醫資訊的應用，可見此方向的題目已是一個國際性的重要研究議
題。倒是此次會議中並未得見類神經網路及模糊理論此兩大研究領域於生物
資訊的最新應用。 
此 外 由 於 明 年 度 Fuzzy-IEEE 國 際 會 議 將 於 台 灣 舉 辦
(http://fuzzieee2011.nutn.edu.tw/index.htm)，台灣許多著名教授(如交大林進燈
教務長(明年會議的General Chair)、成大郭耀煌教授(明年會議的General Co-
Chair)、台南大學李健興教授(明年會議的Program Chair)等)藉由參與此會議，
於會場中推銷明年度的Fuzzy-IEEE國際會議，並報告明年會議籌備的狀況。
而本人擔任明年此會議的Finance Chair，此次不但多認識許多國內外的學者
之外，更藉機瞭解籌備明年度會議中所需注意的事項。 
 
 
 
2
11
) ( ) exp( n n ijij jj
j
i j
i
x m
x M xμ
σ==
−
= = −
⎧ ⎫⎛ ⎞⎪ ⎪⎨ ⎬⎜ ⎟⎝ ⎠⎪ ⎪⎩ ⎭
∑∏K        (3) 
If there are r  rules in a fuzzy system, the output of the system 
calculated by the simple  defuzzification is  
1
1
( )( )
n
r i j
iji
j
y x a xμ
=
=
=∑ ∑K .                 (4) 
where 0 ( )x k  1. 
The SV-RFS proposes the idea of temporal firing strength, 
which is formed by adding a self-feedback loop to each rule. 
The temporal firing strength ikΦ  at time step k  is a 
weighted sum of the spatial firing strength ( )i xμ K  and the 
last temporal firing strength 1
i
k −Φ  using the equation 
1(1 ) ( )
i i i i i
k kxλ μ λ −Φ = − + Φ
K                (5) 
where iλ , 0 1iλ≤ ≤ , is a feedback weight and 1ik −Φ  
represents a memory term that stores previous input 
information. The value of iλ  determines the contribution 
ratio between current and previous inputs to the network 
outputs. Based on (4) and the definition of (5), the final 
SV-RFS output is  
1 0
( )
r n
i j
k ij
i j
y a x b
= =
′ = Φ ⋅ +∑ ∑                    (6) 
where a new bias b  is introduced to account for the learning 
by SVR.  
III. BASIC CONCEPT OF SVR 
This section briefly reviews the basis of the theory of 
SVR[11]. Suppose there is a set S  of labeled training set 
1 1 2 2{( , ), ( , ), ,( , )}N NS x y x y x y=
K K K"                     (7) 
where nkx ∈
K \  and ,  1, ,ky k N∈ =\ … . In ε -SVR 
regression, the main goal is to find a function ( )f xK  that has 
at most ε  deviation from the actually obtained targets ky  
for all the training data, and is as close as possible at the same 
time. First, consider the case of linear function ( )f xK , taking 
the form 
 ( )= Tf x w x b+K K K                                (8) 
where the nw∈K \  is a high dimensional weight vector and 
the bias b ∈\  is a scalar. The optimization problem is given 
by 
1Min    
2
Subject to     ( )
                    
T
w
T
k k
T
k k
w w
y w x b
w x b y
ε
ε
− + ≤
+ − ≤
K K K
K K
K K
                         (9) 
The minimization of 1
2
tw wK K  corresponds to maximizing the 
margin of hyperplane separation. The convex optimization 
problem is feasible when a function ( )f xK  that approximates 
all pairs ( , )k kx y
K
 with ε  precision in the above constrain 
exists. If the problem is infeasible or some errors are allowed, 
then the problem can be defined into: 
ˆ, ,
1
1 ˆMin    ( )
2
ˆSubject to     ( )
                    
ˆ                   , 0, 1, 2, ,
k k
N
T
k kw
k
T
k k k
T
k k k
k k
w w C
y w x b
w x b y
k N
ξ ξ ξ ξ
ε ξ
ε ξ
ξ ξ
=
+ +
− + ≤ +
+ − ≤ +
≥ =
∑K K K
K K
K K
"
          (10) 
where two slack variables ξˆ  and ξ  are introduced, one for 
exceeding the target value by more thanε , and the other for 
being more than ε  below the target. The constant 0C >  is 
a user regulated positive parameter. It controls the trade off 
between the error and margin.  
By applying the Karush-Kuhn-Tucker theorem, the 
above constrained optimization problem can be solved by 
defining a Lagrangian L [11]: 
1 1
1
1
1ˆ ˆ ˆˆ ˆ( , , , , , ) ( ) ( )
2
                    ( )
ˆˆ                   ( )
N N
T
k k k k k k k k k k
k k
N
T
k k k k
k
N
T
k k k k
k
L w b w w C
y w x b
y w x b
ξ ξ α α ξ ξ η ξ η ξ
α ε ξ
α ε ξ
= =
=
=
= + + − +
− + − + +
− + + − −
∑ ∑
∑
∑
GK K
K K
K K
      (11) 
where ˆ, ,k k kη η α and ˆkα  are Lagrange multipliers. To 
minimize ˆ ˆ( , , , , , )k k k kL w b ξ ξ α αK , the gradient of 
ˆ ˆ( , , , , , )k k k kL w b ξ ξ α αK  with respect to wG , b , kξ  and kˆξ  
must vanish, i.e., 
1
1
ˆ ˆ( , , , , , ) ˆ( ) 0
ˆ( )
N
k k k k
k k k
k
N
k k k
k
L w b w x
w
w x
ξ ξ α α
α α
α α
=
=
∂
= − − =
∂
⇒ = −
∑
∑
K K KG
K K
           (12) 
1
ˆ ˆ( , , , , , ) ˆ( ) 0
N
k k k k
k k
k
L w b
b
ξ ξ α α
α α
=
∂
= − =
∂ ∑
K
         (13) 
ˆ ˆ( , , , , , ) 0k k k k k k
k
k k
L w b C
C
ξ ξ α α
α ηξ
η α
∂
= − − =
∂
⇒ = −
K
                        (14) 
ˆ ˆ( , , , , , ) ˆ ˆ 0ˆ
ˆ ˆ
k k k k
k k
k
k k
L w b C
C
ξ ξ α α
α ηξ
η α
∂
= − − =
∂
⇒ = −
K
                       (15) 
2966
 
 
 
1
1
[( ( )) ( )]
r
i i i i
k
i
y x g x bλ μ
−
=
′′ = Φ − +∑ K K .                   (27) 
Equation (27) shows that y′′  is a linear function of 
1( ( )) ( )
i i i
k x g xμ−Φ −
K K  with weights iλ . Therefore, linear 
SVR is employed to learn weights iλ .   
V. SIMULATIONS 
This example uses a SV-RFS to predict the Henon chaotic 
discrete-time series described by the following delay 
difference equation [17]: 
2( 1) ( ) ( 1) 1.0p p py k P y k Q y k+ =− ⋅ + ⋅ − +  .                (28) 
A previous study [17] shows that (28) produces a chaotic 
strange attractor when parameters P  and Q  are set to 1.4 
and 0.3, respectively. This chaotic system has one delay. Two 
thousand patterns are generated by the initial state [ (1)py , 
(0)py ] = [0.4, 0.4]. Noisy training data was generated by 
adding Gaussian noise with mean zero and standard deviation 
0.05 to the first 1000 patterns. The remaining 1000 patterns 
are used for testing. In applying the SV-RFS to this prediction 
problem, only the current state ( )py k  is fed as a SV-RFS 
input and the desired output is ( 1)py k + . The initial width 
initσ  and threshold thμ  in structure learning are set to 0.4 and 
0.74, respectively. Learning generates six clusters. The 
insensitive value ε  is set to 0.01. Table 1 shows the 
structure, total number of parameters, training and test 
Root-Mean-Square Error (RMSE).  Figure 1 shows the 
desired outputs and test results for the last 100 samples in  the 
1000 test samples.  
For comparison, a Gaussian kernel-based SVR and a 
recurrent FNN were designed using the same set of 
input-output training data. The recurrent FNN used for 
comparison is the Takagi-Sugeno-Kang-type recurrent fuzzy 
network with supervised learning (TRFN-S) [2]. The 
Gaussian kernel-based SVR is a feedforward model, and was 
also implemented using LIBSVM software. The SVR 
regularization parameter set  ( g , C ) is set to (5, 100), which 
is  selected by an iterative exhaustive search for best 
performance. Table 1 shows the prediction results of these 
models. Results show that the SV-RFS achieves smaller test 
error than these feedforward and recurrent models. The 
disadvantage of a SVR model is that the number of 
parameters 
 
Table 1. Performance of Different Models Using Noisy Data. 
Models TRFN-S SVR SV-RFS 
Structure 4 rules 942 SVs 6 rules 
Parameter number 36 1886 31 
Training RMSE 0.1075 0.2417 0.103 
Test RMSE 0.0604 0.2219 0.04 
 
 
Fig. 1. Desired outputs and test results of the SV-RFS. 
 
 (determined by support vector number) in it is usually very 
large as shown in Table 1.  The test error of the recurrent FNN 
(TRFN-S) is smaller than the SVR.  
VI. CONCLUSIONS 
This paper proposes a new recurrent fuzzy system, the 
SV-RFS, that uses SVR for parameter leaning. The use of 
SVR shows the advantage of high generalization ability and 
helps to avoid overtraining of the noise as shown in the 
simulation example. In the proposed SVR, the antecedent part 
parameters are determined by the clustering-like learning 
approach. In addition to tuning of the antecedent part and 
feedback parameters, the learning of SV-RFS antecedent part 
parameters using SVR will be studied in the future. 
Simulations on more temporal sequence prediction problems 
will also be studied in the future.  
ACKNOWLEDGMENT 
This work was supported  by the National Science Council, 
Taiwan, R.O.C. under Grant NSC-98-2221-E-010-007. 
REFERENCES 
[1] C.F. Juang and C.T. Lin, “A recurrent self-organizing neural fuzzy 
inference network,” IEEE Trans. Neural Networks, vol.10, no. 4, pp. 
828-845, Jul. 1999. 
[2] C. F. Juang, “A TSK-type recurrent fuzzy network for dynamic systems 
processing by neural network and genetic algorithm,” IEEE Trans. Fuzzy 
Systems, vol. 10, no. 2, pp. 155-170, April 2002. 
[3] J. B. Theocharis, “A high-order recurrent neuro-fuzzy system with 
internal dynamics: Application to the adaptive noise cancellation,” Fuzzy 
Sets and Systems, vol. 157, no. 4, pp. 471-500, 2006. 
[4] C. F. Juang and J. S. Chen, “Water bath temperature control by a recurrent 
fuzzy controller and its FPGA implementation,” IEEE Trans. Industrial 
Electronics, vol. 53, no. 3, pp. 941-949, June 2006. 
[5] C. H. Lee and C. C. Teng, “Identification and control of dynamic systems 
using recurrent fuzzy neural networks,” IEEE Trans. Fuzzy Systems, 
vol. 8, no. 4, pp. 349-366, Aug. 2000. 
[6] C. J. Lin and C. C. Chin, “Prediction and identification using 
wavelet-based recurrent fuzzy neural networks,” IEEE Trans. Systems, 
Man and Cybernetics - Part B: Cybernetics, vol. 34, no. 5, 2144-2154, 
2004.  
[7] G.. Mouzouris and J. M. Mendel, “Dynamic non-singleton fuzzy logic 
systems for nonlinear modeling,” IEEE Trans. Fuzzy Systems, vol. 5, 
no. 2, pp. 199-208, May 1997. 
[8] Y. C. Wang, C. J. Chien, and C. C. Teng, “Direct adaptive iterative 
learning control of nonlinear systems using an output-recurrent fuzzy 
neural network,” IEEE Trans. Syst., Man, and Cyber., Part 
B-Cybernetics, vol. 34, no. 3, pp. 1348-1359, 2004. 
2968
無衍生研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
