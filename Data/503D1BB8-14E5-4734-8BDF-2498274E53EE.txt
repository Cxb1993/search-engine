 2
行政院國家科學委員會專題研究計畫成果報告 
視覺化運動資訊擷取、搜尋與管理核心技術之研究 (II) 
A Study on the Core Technologies of Visualized Sports Information Acquisition, 
Searching and Management (II) 
計畫編號 : NSC 97-2221-E-027-043 
執行期限 : 民國 97年8月1日 至 民國 98年7月31日 
主持人：張厥煒  國立台北科技大學資訊工程學系副教授 
計畫參與人員：吳明倫、王群智、應念廷、張竣皓 
 
一、中文摘要 
運動休閒是現代人舒解壓力，健康身
心的重要方式。運動節目的欣賞，更是日常
生活重要的調劑。體育運動項目結合電腦資
訊科技，所產生的運動資訊領域，已經是國
際運動產業的發展趨勢，也是各項競賽奪牌
的重要指標。 
過去我們曾建構了一個棒球運動資訊
平台，完成了部分運動資訊所需要的相關核
心技術，例如：文數字及視訊資料型態歷史
及短期數位內容管理的機制(記錄系統、視
訊資料庫、歷史資料管理)，運動資訊呈現
展示模式(動畫戰術)，以及經專業分析產生
運動資訊的工具(動態分析)。 
我們將嘗試從已建構的棒球資訊平台
上，進一步對具共通性的視覺化運動資訊擷
取、搜尋與管理所需使用的核心技術進行深
入的研究。因此，我們提出一個三年期的計
畫，分別是：【第一年：運動視訊中資訊內
容之擷取與型態分類】、【第二年：運動視
訊中動態物件追蹤與資訊之管理】、【第三
年：運動內容儲存方式與運動視訊資料庫之
建構】。在此三年期計畫中，將包括：運動
視訊場景分類、球員運動模式、畫面中記分
板內容辨識、球員尋找、位置追蹤、運動軌
跡記錄、運動資訊儲存格式、運動資訊資料
庫、註記與查詢操作環境等期待探討的問
題。我們將以棒球、桌球、羽球等三種運動
為主要研究測試範圍，計畫的實現將有助於
我國各項運動及其資訊系統的發展。 
本年度計畫將以96年核定之「視覺化
運動資訊擷取、搜尋與管理核心技術之研
究」計畫中，原第二年規劃內容為計畫執行
目標，因此命名為「視覺化運動資訊擷取、
搜尋與管理核心技術之研究 (II)」。 
關鍵詞：運動資訊系統、物件追蹤、視訊內
容分析、運動軌跡資料庫。 
 
Abstract 
Sports recreation is an important way for 
modern people to alleviate the pressure and 
keep the body and mind healthy. Watching 
sports TV programs is also one of the 
important entertainments for our daily life. 
The sports information new area, which is 
created by joining sports events and computer 
technologies, is a development trend of the 
international sports industry and is also a 
symbol of wining the medals of important 
contest too. 
We have built and constructed a baseball 
information system platform in the past, and 
finished some of the relevant key technologies 
for sports information, such as, the historical 
and short term digital content management 
mechanism for alphanumerical and video 
 4
球進壘點、打擊落點與接傳守備跑壘過
程等。此子系統所記錄內容，以及時間
點 區 間 (Time Interval) 事 件 註 記
(Annotation)，將提供視訊資料庫做為視
訊內容查詢與檢索 (Video Indexing)之
用。使用者如能善用視訊資料庫中視訊
內容及動態分析工具，則可對有興趣的
動作，透過電腦反覆觀察分析及比對，
而獲得較好的分析成果。 
 
 (2) 棒球視訊畫面資料庫子系統(Baseball 
Video Database Subsystem)：棒球視訊畫
面資料庫同樣共用前述記錄系統所建立
之對戰過程攻守資料，除能經查詢後播
放比賽過程視訊畫面外，並能提供後續
長期累積資料的查詢，使用前述比賽記
錄與攻守資料系統所記錄之比賽過程，
建立發生事件的時間及內容索引，並儲
存棒球比賽相關一系列對戰或重要關鍵
過程的視訊畫面，建立一個整合性的視
訊資料庫。再經由視訊資料庫搜尋，以
視訊畫面播放的方式，重播過去曾記錄
過的歷史畫面，提供比賽當時之情境搭
配對戰過程的球點圖形內容，以完整進
行評估比較。查詢時除原攻守資料查詢
子系統之查詢功能外，另可使用球員球
隊名稱及日期時間等關鍵字進行對戰組
合的查詢，查詢所獲得結果，便可點選
播放。 
 
 (3) 動態分析評估子系統(Motion Analysis 
Evaluation Subsystem)：動態分析評估系
統則可同時使用兩組視訊畫面，連續或
單格或同步來回播放，以細部了解球員
動作或比賽進行中的互動狀況，同時可
使用系統中的量測工具協助動作之分
析。使用數位視訊技術結合前述視訊資
料庫查詢結果，以多張視訊畫面，對有
興趣的球員動作或對戰過程連續畫面，
進行格對格(Frame to Frame)的視覺化比
對與量測分析，可對同一選手或不同選
手間動作差異進行比較，並可充分以視
覺化環境了解球員間的相對互動運動關
係。 
 
 (4) 棒球動畫戰術資料庫子系統(Animated 
Baseball Strategy Database Subsystem)：
在棒球活動中，除了一般靜態文數字及
圖形資料記錄查詢外，在動態戰術方面
的資訊也相當重要。因此，我們設計一
個可以記錄與查詢戰術的系統，當輸入
一個戰術的運動軌跡，便可透過相似性
量度（Similarity Measure）比對法，搜
尋運動軌跡相似的戰術，於運動軌跡播
放系統以動畫方式呈現；或利用運動軌
跡查詢系統，可搜尋特定情況下所發生
的戰術。 
 
 (5) 歷史資料管理子系統(Historical Data 
Management Subsystem)：我國歷年來在
國際棒球運動的卓越成就，使得國人對
棒球運動高度的熱愛。但是令人遺憾
的，國內迄今仍無完整的數位式棒球競
賽資訊儲存與典藏的環境或機制，使得
過去許多具有代表性重要比賽的精彩畫
面，或是比賽成績記錄，已隨時間的遠
逝而逐漸遺失或不可考。本計畫希望能
藉由如今相當成熟的數位內容與多媒體
資料庫技術，並結合網際網路環境，為
建立起國內第一套「棒球競賽記錄內容
數位化與歷史資料管理系統」，以資訊科
技與棒球專業的結合，使資訊工具充分
應用，除保存下這些珍貴的文化遺產
外，並能協助球員成績的長期追蹤，提
供選手甄選等科學數據評估作業，提升
國內棒球運動的水準與觀念。 
 6
【第二年：運動視訊中動態物件追蹤與資訊
之管理】(本年度執行計畫) 
在運動視訊中，球或球員在球場中的運
動關係，是運動資訊的重要來源。在能夠過
濾出場景種類、擷取球場及球員球衣顏色、
運動模式等基礎資訊後，接下來我們要探討
運動的本質。「運動」ㄧ詞，不外就是某種
物體在空間中活動的方式、速度、方向及位
置變化等問題。不過，在運動視訊中，有那
些視訊物件是要追蹤的目標？如何找到所
要記錄的物體？要使用何種模式追蹤？如
何連續在視訊中追蹤此一物體？如何定義
追蹤物體的軌跡？是否需要球場相關標準
化座標資訊？拍攝角度是否影響量測結
果？如何將這些活動的方式、速度、方向及
位置變化等空間中運動資料轉換後記錄？ 
本年度計畫的重要目標，在於研究如何
正確的由有效場景的視訊畫面中，自動尋找
出球、球員、球場等相關資訊。我們期望以
較易獲得的顏色資訊，處理後續的定位、追
蹤等問題。在獲得球、球員、球場等顏色資
訊後，再以顏色建立球場座標資訊，接著追
蹤球[20]或球員[26]等物件，進而對球場座
標轉換，以便記錄球、球員或球場等運動軌
跡或位置。此一視訊中物件追蹤方法，不僅
能尋找我們有興趣的球、球員等，也期望能
尋找追蹤類似廣告看板等物體，用以評估廣
告出現之效益。 
在這一年的計畫中，「球員初始位置尋
找」、「球員位置追蹤」、「軌跡透視座標轉換」
會是三個研究的重點。我們成功使用 Mean 
Shift[14][15] 及 Particle Filter[2]的合併方
法，解決運動物體追蹤的問題。 
 
三、結果與討論 
1、相關研究 
對於以數位視訊進行體育活動內容之
分析，近五年國內外及體育界人士已有逐漸
增多的研究成果發表[6][22][38][39]。在這
些研究中大多嘗試以電視視訊畫面，經由影
像處理與辨識程序，自動化的獲得比賽過程
的精彩過程或重要結果，或對視訊內容進行
場景變動偵測(Scene Change Detection)、場
景分類(Scene Classification)、畫面內容剖析
與摘要(Summarization)、內容索引(Content 
Indexing)、查詢與管理。 
其中，Hua 等人[22]整合了多媒體資
訊，包含：影像、聲音、文字等特徵，配合
自動挑選具有鑑別性特徵的最大亂度方法
(Maximum Entropy Method，MEM)，以達到
棒球場景分類的目的。 
Fan 等人[18]提出一個視訊分類的方
法。其中提到在低階特徵與高階語意間存在
著語意差距(Semantic Gap)，因此提出階層
式樹狀的概念來縮小高低階之間的語意差
距以達到場景分類的目的。 
Gueziec 等人[20]與 ESPN 合作，以三隻
攝影機即時測量攝影機的參數 (Camera 
Pan-Tilt-Zoom)，配合卡爾曼濾波器(Kalman 
Filter)追蹤球飛行的軌跡，在電視台轉播視
訊的投打畫面中，標出好球帶與投球飛行軌
跡。 
Okuma[26]針對冰球場內球員做追蹤，
先將由單一攝影機攝得畫面中冰球場上一
些特定邊線線段找出特徵點，然後以手動方
式將這些特徵點和自己建置的模型上特徵
點作連結；接著到了追蹤階段時利用
DLT(Direct Linear Transformation)使球員追
蹤到的位置對應到作者自訂模組上時誤差
最小。 
Pingali 等人[22]以網球為例，建立了一
個可立即建立索引的多媒體資料庫，並使用
多台攝影機，依據球場幾何資訊，與視訊中
物件特徵加以分割(Segmentation)，完成對
球員運動的軌跡進行追蹤與記錄。該系統並
 8
肢位置為主要考量，配合運動定律之檢驗，
以確定運動員是否充分發揮其體能。 
而 Beichner 等[5]於 1989 年首次利用
電腦影像及空間位置的重疊性，對美國高中
生進行運動力學的課程講授，以實際物體運
動影片，驗證自由落體等運動在真實世界中
運動的軌跡與模式。將數位影像帶進了另一
個新的應用領域。 
雖然近來已逐漸累積各種關於運動視
訊處理的技術，但對重要比賽的現場即時資
料分析，尤其較具實用性的情蒐系統或觀戰
系統，以及整合性的視覺化資訊系統
[40][41]，仍相當缺乏。因此本年度計畫中
運動基礎研究以及整合式系統的開發，將填
補研究與實務間的差距，使研究的方向更加
明確，使內容產業、運動科學、競技情蒐三
方面都有獲益。 
 
2、系統運作架構概述 
當我們能根據運動的活動模式，有效的
從運動視訊中偵測、辨識出有用的競賽資訊
(如記分版圖表)及活動過程(如有球員及球
場的視訊場景)，接下來的是我們希望能追
蹤出運動場地內的比賽球員、球、裁判、廣
告看板等，則可使得場內相關球員及球的運
動軌跡和行為，藉由軌跡關鍵點座標或行為
模式字串，一併與有關的畫面儲存於運動視
訊資料庫系統中。 
想要追蹤並記錄下運動軌跡，仍有許多
瑣碎的問題需要解決：在運動視訊中，有那
些視訊物件是要追蹤的目標？要使用何種
模式追蹤？如何定義追蹤物體的軌跡？是
否需要球場相關標準化座標資訊？拍攝角
度是否影響量測結果？ 
本年度研究計畫的目的，便是建立一個
自動針對輸入特定運動對戰影片，經視訊物
件分割與追蹤後，建立其中球員移動軌跡資
訊的系統。目前規劃的運作流程圖如圖 1，
將包括「球員初始位置尋找」、「球員位置追
蹤」、「軌跡透視座標轉換」等步驟。 
 
 
圖 1、物件追蹤系統架構圖 
 
3、球員初始位置尋找 
追蹤目標物選取一般是以人工框選的
方式為主。但是如果要做到自動化目標物選
取，那會是一個有些複雜的問題。我們將以
較好處理的羽球比賽為例，經過「球員初始
位置尋找」這個步驟，找出球員在片段起始
時在球場中位置，才可供「球員位置追蹤」
模組做為追蹤時球員物體最初始位置使
用。由於在「球員位置追蹤」模組建立軌跡
時，軌跡是以球員和地面接觸點(腳部)為記
錄依據，所以在此模組求出的球員初始位置
應該要包含選手腳部。除此之外，還需盡量
 10
 
圖 4、去除球場主色結果圖 
前一步驟找出球場位置後，我們便可以
得知畫面中哪些像素點屬於場內，哪些屬於
場外。接著統計場內像素點的主要顏色(場
內前 60%多的顏色)為何作為球場主色。利
用前面統計出來的球場主色，對球場內所有
像素透過 Gaussian Classifier 做顏色過濾。
將場內屬於球場顏色的像素濾除，則將只留
下球場邊線、球員物體和些許雜訊（如圖
4）。 
接下來要將球員分離，去除掉球場邊線
和雜訊。想法是由於目前存在的物件中，只
有球員是會隨時間有空間上的移動，球場邊
線和雜訊不會。根據想法決定透過移動特性
來找出球員位置，做法則是建立移動累積圖
(Motion Map)（如圖 5）。 
 
圖 5、移動累積圖 
 
圖 6、球員位於場內的位置 
 
 
圖 7、上方球員延伸偵測結果 
 
再將此移動累積圖和去除場地顏色結
果圖(圖 5)做交集(AND)運算，可找出球員
位於場內的位置(圖 6)。由圖 6 可以看到，
畫面上方球員只有位於球場內部部分被偵
測出來這是因為前述步驟都只針對場內部
份做分析。雖然下半部份已經可以提供下一
「球員位置追蹤」模組使用，但為了增加追
蹤的準確度，能提供越多球員資訊給「球員
位置追蹤」模組越佳。作法是利用圖 6 上方
中間區域中的移動移動累積圖(圖 7 B 區域
白色部分)來將上球員向上延伸(圖 7 B 區域
白色部分中的方框)，來獲得較完整的上方
球員物體(如圖 7 各方框的聯集)。至此，完
成了畫面中物體初始位置的尋找。 
 12
Kernel Function，定義如式(1)。 
⎪⎩
⎪⎨
⎧ <−+=
−
.0
1)1)(2(
2
1
)(
1
otherwise
xifxdCxK d   (1) 
其中，d 是表空間的維度，在此為二維影
像，d=2。Cd 是 d 維空間中，單位圓的面積，
在此為 π。 
利用 Epanechnikov Kernel Function 建
立的目標物體模型為式(2)。 
])([)()( *
1
2* uxbxkCuq i
n
i
i −= ∑
=
δ     (2) 
其中 ∑=
=
n
i i
xk
C
1
2* )(
1  是正規化常數，
)(xδ 是 Kronecker delta function。 
利用 Epanechnikov Kernel Function 建
立的目標物體模型為式(3)。 
])([)()( *
1
2* uxbxkCuq i
n
i
i −= ∑
=
δ     (3) 
其中
∑= −
=
n
i
i
h
xyk
C
1
)(
1 是正規化常數，
)(xδ 是 Kronecker delta function，h 是核心
函數半徑長度。 
當候選物已選定，且候選物和目標物模
型已建立好後，需要有一個模型相似度量度
比較方法來進行目標物和候選物之間模型
相 似 度 比 較 。 在 此 以 Bhattacharyya 
Coefficient 為相似度度量的方法。 
Bhattacharyya Coefficient計算方式如式
(4)。 
( ) ( ) ( )[ ] ( ) ( )∑
=
⋅=≡
m
u
uqyupuqyupy
1
,,,ρρ
               (4) 
其中，p(u,y)表候選物模型中第 u 個色彩索
引中的量，q(u)表目標物模型中第 u 個色彩
索引中的量。 
當 兩 個 物 體 模 型 越 類 似 時 ，
Bhattacharyya Coefficient 值越大，反之當兩
個物體模型越不類似時，Bhattacharyya 
Coefficient 值越小。於是在模組中藉由計算
兩個物體模型的 ρ(y)值可以量度兩個模型
的相似度。 
對於物件追蹤的方法，我們嘗試使用
Mean Shift 及 Particle Filter 兩種方式。其
中，Mean Shift 追蹤方法是在於不斷藉由計
算出 Mean Shift Vector，來挑選出下一個候
選物體，使得新挑選的候選物體相似度不斷
提高，最後收歛於目標物周圍物相似度(藉
由 Bhattacharyya Coefficient 量度)為區域最
大值(Local Maximum)的位置，這個位置就
是最後追蹤結果。 
Mean Shift Vector[14]是以梯度向量的
方式來逼近追蹤物。由於梯度向量方向為函
數 值 增 加 量 最 大 方 向 ， 也 就 是 往
Bhattacharyya Coefficient 區域最大值的移
動方向，因此可用來做為我們挑選下一時間
候選物體依據。而 Mean Shift Vector 則可以
求出逼近於梯度向量的結果，因此可以用來
作為追蹤的工具。 
Mean Shift 追蹤流程的示意圖如圖 9。
藉由圖 9 中 Mean Shift Vector(箭號)，使得
可以從上一時間點位置(yo)移動到下一時間
點，擁有區域相似度最大值得追蹤結果位置
(y1)。 
 
 
圖 9、Mean Shift Vector 示意圖 
 14
此起始點以 Mean Shift 方法進行球員追
蹤。若 Mean Shift 追蹤結果目標物和候選物
的 Bhattacharyya Coefficient 相似度小於預
先設定閥值(這裡為 0.8)，則表示追蹤失敗，
此時再切換到 Particle Filter 來追蹤。當
Particle Filter 追蹤到目標物後，在追蹤結果
位置在回到 Mean Shift 加以確認，以求較準
確結果。最後將這些位於鏡頭座標系中一系
列軌跡座標交由下一模組進行紀錄動作。 
模組中先以 Mean Shift 追蹤原因在於
Mean Shift 除了有較穩定準確追蹤結果外，
具有較 Particle Filter 快速的執行速度。但當
遇到快速移動物體，Mean Shift 可能會追蹤
失敗，此時切換到 Particle Filter 進行追蹤。
我們為了增加 Particle Filter 追蹤結果準確
度，模組使用較高粒子數目(約 400 個)，並
將追蹤結果再透過 Mean Shift 校正一次。 
 
圖 11、球員位置追蹤模組架構圖 
圖 12、軌跡記錄與播放模組流程圖 
 
(a) Particle Filter (b) Mean Shift 
(c) Particle 
Filter 搭配
Mean Shift 
圖 13、以三種追蹤方法建立的軌跡圖 
 
 16
其中，(XR, YR)為真實世界座標，(XR, YR)
為相對於真實世界座標的對應鏡頭平面座
標，CJ, J=1…8 為投影參數。(5)和(6)式中
C1~C8 八個參數，須事前依據已知球場真實
座標點和其對應球場鏡頭座標點加以校估
訂定，當參數決定之後，即可直接進行軌跡
座標點轉換工作。 
藉由輸入四組鏡頭座標/真實座標對應
座標點即可解出 C1~C8 參數。解出 C1~C8
參數後便可以對鏡頭座標系上軌跡中的每
個點透過(5)和(6)式進行投影座標轉換。而
這四組鏡頭座標/真實座標對應座標點可由
前面球場邊框偵測模組偵測出的球場四格
角落位置(鏡頭座標系)和國際羽球協會規
定的場地大小(真實座標系)得到。 
透過上述流程，自一個單純影片的輸
入，可以得到所需影片內物體運動軌跡的輸
出。有了運動軌跡，接下來可以再建立出「軌
跡查詢及播放」模組，除了將前面產生的軌
跡重新播放外，也對這些軌跡作一些簡單的
資訊分析，如平均移動距離、平均速度等。
此部分「軌跡查詢及播放」之研究，將在後
續申請的「運動內容儲存方式與運動視訊資
料庫之建構」計畫中進行。 
 
 
圖 17、桌球運動球員軌跡追蹤與記錄 
 18
6、結論 
本次計畫的目的，是建立一個自動針對
輸入特定運動對戰影片，經視訊物件分割與
追蹤後，建立其中球員移動軌跡資訊的系
統。其中包括「球員初始位置尋找」、「球員
位置追蹤」、「軌跡透視座標轉換」等研究重
點項目。 
我們以較好處理的羽球比賽為例，經過
「球員初始位置尋找」這個步驟，找出球員
在片段起始時在球場中位置，供「球員位置
追蹤」模組做為追蹤時球員物體最初始位置
使用。「球員位置追蹤」在產生攝影機影像
平面座標上的球員移動的軌跡，我們使用核
心為基礎方法完成追蹤工作。我們先以
Mean Shift 追蹤原因在於 Mean Shift 除了有
較穩定準確追蹤結果外，具有較 Particle 
Filter 快速的執行速度。但當遇到快速移動
物體，Mean Shift 可能會追蹤失敗，此時切
換到 Particle Filter 進行追蹤。我們為了增加
Particle Filter 追蹤結果準確度，模組使用較
高粒子數目(約 400 個)，並將追蹤結果再透
過 Mean Shift 校正一次。 
最後的「軌跡透視座標轉換及記錄」在
收到前面模組產生的軌跡後，會將此攝影機
影 像 平 面 座 標 上 的 軌 跡 藉 由 透 視
(Perspective)轉換方法轉換成真實世界座標
上軌跡，再將軌跡資訊存入資料庫中，供將
來「軌跡查詢與播放」模組使用。有了運動
軌跡，接下便能建立出「軌跡查詢及播放」
功能，並對這些軌跡作一些簡單的資訊分
析，如平均移動距離、平均速度等。 
 
四、參考文獻 
[1] E. L. Andrade, J. C. Woods, E. Khan and M. 
Ghanbari, Region-Based Analysis and Retrieval 
for Tracking of Semantic Objects and Provision of 
Augmented Information in Interactive Sport 
Scenes, IEEE Trans. On Multimedia, 2005, Vol.7, 
No.6, 1084-1096. 
[2] M. S. Arulampalam, S. Maskell, N. Gordon, and T. 
Clapp, “A tutorial on Particle Filters for Online 
Nolinear/Non-Gaussian Bayesian Tracking,” IEEE 
Trans. on Signal Processing, pp. 174-188, Vol. 50, 
No. 2, 2002. 
[3] J. Assfalg, M. Bertini, C. Colombo and A. D. 
Bimbo, Semantic Annotation of Sports Videos, 
IEEE Multimedia, 2002, April-June, 52-60. 
[4] N. Babaguchi, Y. Kawai and T. Kitahashi, 
Generation of Personalized Abstract of Sports 
Video, IEEE International Conference on 
Multimedia and Expo, 2001, 619- 622. 
[5] R. Beichner, M. DeMarco, D. Ettestad and E. 
Gleason, Video-Graph: a new way to study 
kinematics, Computers in Physics Instruction, 
1989, 244-245. 
[6] J. F. Canny, “A Computational Approach to Edge 
Detection,” IEEE Trans. On Pattern Analysis and 
Machine Intelligence, Vol. PAMI-8, No.6, 1986, 
pp. 679-698. 
[7] C. W. Chang and S. Y. Lee, Sports Motion 
Analysis Using Video Sequence Matching, Journal 
of Visual Language and Computing, 1997, Vol.8, 
265-287. 
[8] C. W. Chang and S. Y. Lee, Digital Video 
Management System, Proceedings of the National 
Science Council, 1997, Vol.21, No.1, 62-74. 
[9] Chueh-Wei Chang, Hua-Wei Lin and Chen-Kang 
Chang, The Construction and Applications of a 
Baseball Strategy Database with Animation 
Playback, Sports Coaching Science, 2005, Vol. 5, 
147-158. 
[10] C. W. Chang and C. K. Lu, Object Motion 
Trajectory Representation and Retrieval for a 
Baseball Strategy Database, Chung Hua Journal of 
Science and Engineering, 2005, Vol.3, No.1, 3-10. 
 20
[30] W. Tavanapong, and J. Zhou, Shot Clustering 
Techniques for Story Browsing, IEEE Trans. On 
Multimedia, 2004, Vol.6, No.4, 517-527. 
[31] X. Yu and H.W. Leong, “A Robust Hough-based 
Algorithm for Partial Ellipse Detection in 
Broadcast Soccer Video,” Proc. of IEEE Intl. Conf. 
on Computer Vision, Vol. 3, 2004, pp. 27-30. 
[32] 張厥煒，2005 年，視覺化棒球運動情蒐與資
訊系統.，Communication of IICM, Vol.8, No. 4, 
187-202. 
[33] 張厥煒、林華韋，雅典奧運棒球情蒐運作模式與
資訊系統建構，大專體育，第七十六期，
pp.25~29，2005 年。 
[34] 蔡燿駿，拼奧運是打科技戰，e 天下雜誌，
pp.58~61，2004 年 8 月號。 
[35] 朱維瑛，台灣的棒球 SPY，中華職棒雜誌，
pp.38~40，2004 年 6 月號。 
[36] 賴榮樞，中華隊前進雅典的幕後推手，微電腦傳
真，pp.61~64，2003 年 12 月號。 
[37] 陳義煌，“中華名國棒球記錄法”，中華名國棒球
協會，2002 年 7 月。 
[38] 鄭毅賢，“棒球競賽資訊管理系統之研究開發”，
國立體育學院運動科學研究所碩士論文，民國
90 年。 
[39] 林鼎智，“建構於視訊運動特徵分析之棒球比賽
事件偵測及其語意式分類”，中正大學電機工程
研究所碩士論文，民國 90 年。 
[40] 張厥煒、楊清瓏，"視覺化運動資訊系統之探討
"，中華體育季刊，第二十一卷第四期，10-21
頁，2007。 
[41] 張厥煒、楊清瓏，"一個視覺化動作比對分析系
統之設計、開發與應用"，運動教練科學，Vol. 9，
91-100 頁，2007。 
 
五、計畫成果自評 
在這一年的計畫中，「球員初始位置尋
找」、「球員位置追蹤」、「軌跡透視座標轉換」
是三個研究的重點。 
我們以較好處理的羽球比賽為例，經過
「球員初始位置尋找」這個步驟，找出球員
在片段起始時在球場中位置，供「球員位置
追蹤」模組做為追蹤時球員物體最初始位置
使用。「球員位置追蹤」在產生攝影機影像
平面座標上的球員移動的軌跡，我們使用核
心為基礎方法完成追蹤工作。我們先以
Mean Shift 追蹤原因在於 Mean Shift 除了有
較穩定準確追蹤結果外，具有較 Particle 
Filter 快速的執行速度。但當遇到快速移動
物體，Mean Shift 可能會追蹤失敗，此時切
換到 Particle Filter 進行追蹤。我們為了增加
Particle Filter 追蹤結果準確度，模組使用較
高粒子數目(約 400 個)，並將追蹤結果再透
過 Mean Shift 校正一次。最後的「軌跡透視
座標轉換及記錄」在收到前面模組產生的軌
跡後，會將此攝影機影像平面座標上的軌跡
藉由透視(Perspective)轉換方法轉換成真實
世界座標上軌跡，再將軌跡資訊存入資料庫
中，供將來「軌跡查詢與播放」模組使用。
有了運動軌跡，接下便能建立出「軌跡查詢
及播放」功能，並對這些軌跡作一些簡單的
資訊分析，如平均移動距離、平均速度等。 
本計畫最終成果如預期的在運動視訊
中，解決：有那些視訊物件是要追蹤的目
標？如何找到所要記錄的物體？要使用何
種模式追蹤？如何連續在視訊中追蹤此一
物體？如何定義追蹤物體的軌跡？是否需
要球場相關標準化座標資訊？拍攝角度是
否影響量測結果？如何將這些活動的方
式、速度、方向及位置變化等空間中運動資
料轉換後記錄？等問題。我們是以較易獲得
的顏色資訊，處理後續的定位、追蹤等問
題。再以顏色建立球場座標資訊，接著追蹤
球或球員等物件，進而對球場座標轉換，以
便記錄球、球員或球場等運動軌跡或位置。 
此一視訊中物件追蹤方法，不僅能尋找
 22
可供推廣之研發成果資料表 
□ 可申請專利  ; 可技術移轉                                   日期：98 年 7 月 9 日 
國科會補助計畫 
計畫名稱：視覺化運動資訊擷取、搜尋與管理核心技術之研究(II)
計畫主持人：張厥煒  國立台北科技大學資訊工程學系副教授 
計畫編號：NSC 97-2221-E-027-043  學門領域：WEB 技術 
技術/創作名稱 視訊物件追蹤與軌跡查詢方法 
發明人/創作人 張厥煒 
中文：我們從已建構的棒球資訊平台上，進一步對具共通性的視覺
化運動資訊擷取、搜尋與管理所需使用的核心技術進行深入的研
究。因此，我們提出一個三年期的計畫，分別是：【第一年：運動
視訊中資訊內容之擷取與型態分類】、【第二年：運動視訊中動態物
件追蹤與資訊之管理】、【第三年：運動內容儲存方式與運動視訊資
料庫之建構】。在此三年期計畫中，將包括：運動視訊場景分類、
球員運動模式、畫面中記分板內容辨識、球員尋找、位置追蹤、運
動軌跡記錄、運動資訊儲存格式、運動資訊資料庫、註記與查詢操
作環境等期待探討的問題。我們將以棒球、桌球、羽球等三種運動
為主要研究測試範圍，計畫的實現將有助於我國各項運動及其資訊
系統的發展。 技術說明 
英文：We tried to go deep to realize the kernel technologies for visual 
sports information retrieval, search and management which have 
common attributes in every kind of sports, from the baseball 
information platform we have already constructed. Therefore, we 
propose a three-year project that including [the 1st year] the content 
retrieval and data type classification in a sports video, [the 2nd year] 
the moving object tracking and related information management in a 
sports video, [the 3rd year] the method for sports content store and the 
construction of sports video database. We will use three kinds of sports, 
baseball, table tennis, badminton, as our major research targets. The 
realization of this project will help the development of sports and 
information system of our country. 
可利用之產業及 
可開發之產品 
 
技術特點  
推廣及運用的價值  
※ 1.每項研發成果請填寫一式二份，一份隨成果報告送繳本會，一份送 貴單
位研發成果推廣單位（如技術移轉中心）。 
※ 2.本項研發成果若尚未申請專利，請勿揭露可申請專利之主要內容。 
※ 3.本表若不敷使用，請自行影印使用。 
Abnormal Spatial Event Detection and Video Content Searching 
in a Multi-Camera Surveillance System 
Chueh-Wei Chang Ti-Hua Yang Yu-Yu Tsao 
Department of Computer Science and Information Engineering, 
National Taipei University of Technology, Taiwan 
cwchang@ntut.edu.tw s4598024@ntut.edu.tw s4598029@ntut.edu.tw 
 
 
Abstract 
In a traditional multi-camera surveillance system, it’s 
hard to find the routes of the suspect objects, and search 
for those video clips related to the suspect objects from 
the surveillance database. In this paper, we present a 
framework for spatial relationship construction, abnor-
mal event detection and video content searching for visual 
surveillance applications. This system can automatically 
detect the abnormal events from monitoring areas, and 
select the representative key frame(s) from the video clips 
as an index, then store the color features of the suspect 
objects into the surveillance database. A graph model 
has been defined to coordinate the tracking of objects 
between multiple views, so that the surveillance system 
can check the route of objects whether go into a critical 
path or not. A variety of spatio-temporal query functions 
can be provided by using this spatial graph model. To 
achieve the content-based video object searching, a ker-
nel-based approach is employed as a similarity measure 
between the color distribution of the suspect object and 
target candidates in the surveillance database.  
1. Introduction 
The most widely used video-based surveillance sys-
tems [3] generally employ two or more cameras that are 
connected to the monitors. This kind of systems needs 
the presence of a human operator, who interprets the 
acquired information and controls the evolution of the 
events in a surveyed environment. As the number of 
cameras increase, event monitoring by personnel is rather 
tedious, and easy to cause error. The automatic preproc-
essing of the video information by a surveillance system 
can greatly help person to improve validation of the 
events. Each camera must be capable of detecting and 
tracking moving objects of interest, and recording the 
video of the event into a surveillance database [2]. Video 
processing and understanding can be considered as a 
fundamental modality for surveillance applications. 
A real-time visual surveillance system in [5] employs 
a combination of shape analysis and tracking, and con-
structs models of people’s appearances in order to detect 
and track groups of people as well as monitor their be-
haviors even in the presence of occlusion and in outdoor 
environments. A single person tracking system in [8] 
detects moving objects in indoor scenes using motion 
detection, tracks them using first-order prediction, and 
recognizes behaviors by applying predicates to a graph 
formed by linking corresponding objects in successive 
frames. But most of the surveillance systems, just like 
the two systems we mentioned above, don’t provide the 
query functions for spatio-temporal relations and similar 
object searching in video databases. 
In this paper, we design a framework for the abnormal 
spatial event detection and the suspect video object 
searching in a multi-camera surveillance system. We will 
describe in the following sections the details of the de-
sign of our surveillance systems that utilize a large set of 
cameras and more extended and flexible processing 
strategies. In the next section, we describe the design 
concepts and process flowcharts of our surveillance sys-
tem. In Section 3, we describe the spatial relationship 
between the surveillance areas. In Section 4, we show 
the mechanism of video content searching. The system 
interface and similar measure experiments are presented 
in Section 5. Some conclusions are drawn in Section 6. 
2. System Design 
In our multi-camera surveillance system, video data 
are acquired by distributed cameras and then are trans-
mitted to the remote control center. It has the capability 
of observing and recording videos from distant places. 
It’s necessary to design more sophisticated video proc-
essing algorithms for spatial event handling and suspect 
object searching. The architecture of the proposed sur-
veillance system is shown in Figure 1. In this section, the 
main characteristics of the 3 modules are presented. 
 
Figure 1. Architecture of the proposed system. 
(2) Object density 
The object density of the nth video frame is simply 
computed as 
( ) ( ) /( )n nDensity n Size n Width Height= × ,  (2) 
where Widthn and Heightn are the width and height of the 
minimal bounding box that contains the abnormal object, 
respectively. We prefer the suspect object is solid and 
quite different from the background. 
(3) Object aspect ratio 
The object aspect ratio of the nth video frame is de-
fined as 
otherwise
HeightWidthif
nRatio nn
75.0)/(0.25 
   
0
1
)(
≤≤
⎩⎨
⎧= , (3) 
where Widthn and Heightn are the width and height of the 
minimal bounding box, respectively. We prefer the sus-
pect object is like a human shape, not as a dog or cat. 
(4) Edge change ratio 
We use the Edge Change Ratio (ECR) [9] algorithm to 
measure the edge changing between frame n and frame 
n+1. The edge change ratio can show how fast an object 
is moving in the video sequences.  
In the ECR algorithm, two kinds of edge change 
ratios are defined, one is the Exiting Edge Pixel (Outgo-
ing Edge Pixel), and the other one is the Entering Edge 
Pixel (Incoming Edge Pixel). This approach is based on a 
simple observation: during a fast move object, new in-
tensity edges appear far from the locations of old edges. 
Similarly old edges disappear far from the location of 
new edges. We define an edge pixel that appears far 
from an existing edge pixel as an entering edge pixel and 
an edge pixel that disappears far from an existing edge 
pixel as an exiting edge pixel. By counting the entering 
and exiting edge pixels we can realize how fast this ob-
ject is moving. 
The ECR algorithm takes as input two consecutive 
images In and In+1. It first performs a Sobel edge detec-
tion step and then thresholding step, resulting in two 
binary images 
thresh
nE  and 
thresh
nE 1+ .  
Next, the Exiting Edge Pixel 
out
nX  and Entering Edge 
Pixel 
in
nX 1+  are defined as 
))(( 1
dilation
n
thresh
n
out
n ENOTANDEX += ,  (4) 
))(( 11
dilation
n
thresh
n
in
n ENOTANDEX ++ = ,  (5) 
where 
dilation
nE and 
dilation
nE 1+ are the results after the mor-
phological dilation operation from 
thresh
nE  and 
thresh
nE 1+  
respectively. The AND and NOT functions are the bi-
nary logic operations. 
The Edge Change Ratio (ECR) of the nth video frame 
is computed as 
)/,/max()( 11
thresh
n
in
n
thresh
n
out
n EXEXnECR ++= .  (6) 
We prefer the suspect object is a slow changing one 
because it will have a better stable and sharpness image 
quality. 
 
(5) Frame clarity 
Because we prefer the suspect object is contrast and 
sharpness. We use the overall edge count to evaluate the 
focus value and also clarity of a frame. The frame clarity 
of the nth video frame is computed as 
∑=
yx
thresh
n yxEnEdges
,
),()( .        (7) 
(6) Histogram entropy 
How much color information in a frame can be pro-
vided by the histogram entropy. The histogram entropy 
is defined as 
)),((log),()( 2 nxpnxpnH
x
∑−=
,   (8) 
where p(x,n) is the probability of the grayscale value x in 
the luminance histogram of frame n. We prefer more 
color in the frame. 
For each abnormal event, a score function Key-
FrameScore(n) combining the different measures is 
computed as 
( ) ( ) ( ) 
                        ( ) ( )
                         ( ) ( )
Normal
size Ratio
Normal Normal
Density ECR
Normal Normal
Edges H
KeyFrame n w Size n w Ratio n
w Density n w ECR n
w Edges n w H n
= × + ×
+ × + ×
+ × + ×
,      
(9) 
where WSize, WDensity, WRatio, WECR, WEdges, WH, are the 
weighting factors of each criterion which can be adjusted 
heuristically. Finally, some of the key frames with the 
highest score are selected. 
4.2. Similarity measure 
As mentioned before, the similarity measure we de-
velop is highly dependent on the object color information. 
We modify some of the approach for the real-time track-
ing of non-rigid objects in [4].  
The feature c representing the color of the suspect ob-
ject is assumed to have a density function qc, while the 
target candidate n in the key frame of a surveillance da-
tabase has the feature distributed according to pc (n).  
The problem is then to find the target candidate n 
whose associated density pc(n) is the most similar to the 
suspect object density qc. We calculate the similarity 
between two densities according to the Bhattacharyya 
coefficient, whose general form is defined by 
[ ]( ) ( ), ( )c cn p n q p n q dcρ ρ≡ = ⋅∫   (10) 
Due to the computational complexity we use the den-
sity estimates derived from a simple histogram 
formulation. The discrete density q={qu}u=1…m (with 
1
1m uu q= =∑ ) is estimated from the m-bin histogram of the 
suspect object, while p(n)={pu(n)}u=1…m (with 
1
1m uu p= =∑ ) is estimated at a given target candidate n 
from the m-bin histogram. Therefore, the sample esti-
mate of the Bhattacharyya coefficient is given by 
[ ]
1
( ) ( ), ( )
m
u u
u
n p n q p n qρ ρ
=
≡ = ⋅∑       (11) 
