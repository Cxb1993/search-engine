 1
行政院國家科學委員會專題研究計畫成果報告 
計畫編號：NSC98-2221-E-150-073 
執行期限：98 年 8 月 1 日至 99 年 7 月 31 日 主持人：黃惠俞   
執行機構及單位名稱：國立虎尾科技大學資訊工程系 
計畫參與人員：蕭俊男(國立虎尾科技大學資工系碩士生)、 
黃智慧(國立中正大學資工所博士生) 
                    
 
一、中文摘要 
 
網路資訊的發達，藉由網路傳播其資訊
已是相當普及且是獲得資訊的的媒介之
一。在網路上互相分享著各種資訊如旅遊
的經驗、照片等，讓人有種預知或是身歷
其境的感受。透過一些影像處理技術可將
收集到之照片，進行改造尤其是對興趣的
物件進行移動、刪除等處理，進而創造出
一張新的影像，達到想要的效果是一項相
當有趣的研究議題。而本研究將利用樣本
為基(exemplar-based)影像修補技術及結合
的影像處理，設計一處理程序對影像進行
物件的移除及修補。透過物件擷取及影像
修補，可以任意的移動或是移除影像中的
物件，並可將移除物件後的影像進行修復
進而展示無物件置於前的影像。 
本計畫的主要目的是利用特徵及樣本
為主之物件修補技術，主要將前景與背景
分離過後，針對擷取出的前景物件所遺留
於背景上之空白區域進行修復，將此區域
與背景相符合的進行填充處理。最後將物
件移動及區域填充完後，則可獲得一張新
的影像。該研究主要強調影像修補的部
份，經由修補目標區域上各點之信賴度及
亮度變異度的計算推演出各點優先權值。
藉由排序修補優先權，進而找出最優先修
補區塊，並利用影像中除目標區域外的可
用資訊找尋出與該修補區塊最相似的資訊
進行填補。經實驗證明本計畫所建置之處
理程序可獲得不錯修補結果，同時被擷取
出的物件，藉由所進行的合成處理可任意
的嵌入至其他照片之中而獲得一張虛擬照
片，達到本計畫之目標。 
關鍵詞：樣本，物件擷取，影像修補，影
像合成 
Abstract 
The development of internet advances 
more and more fast; the information given 
becomes very easy and fast by mean of 
internet. People can share media or 
advantage information (such as picture, 
experience) by means of this tool.  Owing 
to the pictures are easy to obtain, human 
beings can make a new or specified picture 
by using the image processing technology 
This is, human beings can re-make who 
desired the picture into a new picture or a 
virtual scene. For remake picture scheme, it 
 3
技術[6-8]等。 
 就全域最佳化修補技術而言，雖然可
能修補結果對整體而言是最佳的，但需找
出對整體修復結果之最佳解，而導致在處
理效能上極為費時，故考量到時間因素，
本研究計劃不考慮利用此技術執行修補。 
而基於鄰近像素值修補技術而言，因
藉由修補位置之鄰近資訊作為修補參考資
料，所以對於較細微的或範圍不大的毀損
區域不僅修補效果佳且修補時間亦短。但
若遇到毀損區域過大時，則越往毀損區域
中心處其鄰近可用之原始資訊將不足，導
致毀損區域中心之修補效果產生模糊現象 
[9,10]。 
基於樣本區塊修補技術而言，則先從
待補區域中計算出最優先修補區塊，接
著，找尋待補區域外之原始資訊內最符合
修補之補片(Patch)區塊資訊，而搜尋Patch
時可能非常耗時。但由於Patch進行修補可
延續結構特性，並且對於紋理修復後較不
會產生模糊化之現象。基於此本研究計畫
將採用以樣本區塊修補技術為本進行修補
演算法之改良，達到節省修復過程之計算
時間，並達到不錯的修復結果相較於原始
的樣本區塊修補技術之修復結果亦可達同
等效果。 
3.1 基於樣本區塊修補技術 
1. 修補優先權(priority) 
修補順序若依照單純的由上至下、由左至
右的方式處理，於結構部份可能會造成損
壞，如圖 3-1 所示，此種方法於修補過程
中可能填補錯誤資訊，導致結構破壞。 
  
(a)                 (b) 
圖 3-1 結構延伸錯誤之範例。 (a)紅色區域
屬於需修補區域。(b)修復過程中產生結構
之破壞。 
 
故若先行修補結構強烈處，將有機會回復
至相近於原始影像。如圖 3-2 所示，若能
先填補黑色區塊處，將對整體修復結果有
很大的助益。 
  
(a)                 (b) 
           
(c) 
圖 3-2 依結構特性修補之例子。 (a)黑色
區塊表結構特性高，將先進行修補。(b)進
行修補順序及結果。(c)整體修復之結果。 
而為避免填入錯誤修補資訊，故樣本
區塊修補技術對於修補區域之邊界
 5
但若含有強烈結構等特殊紋理之影像時，
可能修補時導致結構修復不完整等問題。
故針對結構部份，加入了結構度之考量，
助於修補結果之完整度。 
z 結構度(Data Term) 
若只利用信賴度去計算各點之優先權
值可能對平滑影像修復結果尚可接受，但
影像中若含有大量結構時，修補時也許會
造成結構破壞，所以計算優先權值的條件
中加入結構度(Data Term)，使結構強烈的
部份也給予較高的優先權值。結構度之定
義如下: 
,
|n|
)p( ppα
⋅∇=
⊥I
D  (3-3)
⊥∇ pI 代表以 p 點為中心點之區塊中 sobel
的結構方向， pn 表示 p 點與目標區域之
邊界( Ωδ )的單位向量，α 則是正規化的
一個因子 ( 例如 : 典型的灰階影像中
α =255)。所以若 ⊥∇ pI 與 pn 的方向越相
近則表示影像中修補至目標區域之結構部
份的強度越強。反之，方向越遠則給予較
低的優先權值[11]。圖 3-5 為結構度之示意
[6]。 
 
 
圖 3-5 計算結構度之示意圖[6]。 
 
當計算完所有目標區域之邊界上各點
優先權值後，將由優先權值最高之該點區
塊先行修補，並從來源區域(Φ )中找尋最
相似於待補區塊之補片(Patch)區塊，並利
用補片區塊內來源資訊填補之。 
 
2. 找尋最合適之補片(Patch)區塊 
由目標區域(Ω )中計算出最優先修補之
區塊後，接著從來源區域(Φ )中搜尋最合
適於該修補區塊之補片區塊，定義如下: 
),,(minarg qpˆqˆ
q
ΨΨ=Ψ Φ∈Ψ d  (3-4)
其中 pˆΨ 為目標區域中優先權最高之待補
區塊， qΨ 表示以不超出影像大小為前
提，從來源區域中以各個 q 點為中心點擷
取出和 pˆΨ 相同大小之補片區塊，
),( qpˆ ΨΨd 代表著各個 qΨ 區塊與擁
有最高優先權之 pˆΨ 區塊之間的差距。簡
言之，即是由最優先修補區塊與來源區域
 7
 
圖 4-1 系統架構圖。 
 
4.1 前景/背景分離(Foreground/background 
separation) 
首先系統之步驟是進行前景與背景分離，
在此前景可謂有興趣區域(ROI)而背景可
視為是來源區域(Source region)。該項處理
主要目的是從目標區域中擷取出前景物件
範圍。為了利於後續之處理，更進而進行
膨脹(dilation)處理讓擷取出之物件邊界更
佳精緻化。 
本研究計畫以利用有興趣之區域
(Region of interest，ROI) 進行偵測並擷取
前景物件之處理，而僅針對 ROI 之區域進
行前景物件擷取處理之優點其一因該區域
中前景物件鄰近位置尚有許多來源區域的
資訊可利用，可避免產生遮蔽到不屬於前
景物件的原始影像資訊內容，以利後續修
復動作時利用。其二可明確針對需修補位
置進行修復處理可節省修補之時間。 
 基於以上之優點，將僅針對被選取之
ROI 區域進行前景物件之擷取動作。首先
針對該區域進行灰階化後，由於 R、G、B
數值皆一致，所有本研究計畫只採用 R 之
數值進行運算，將欲擷取之前景區域內所
有像素點之 R 值加總，並計算其平均 R 值
(Ave_R)。其 Ave_R 之定義如下: 
∑∑
= = ×
Ω=
s
i
t
j
R
ts
jiRAve
1 1
),(_ , (4-1)
其中 s 及 t 為 ROI 之區域範圍大小， RΩ 表
示為 ROI 之區域中之 R 值。並定義一個擷
取前景物件之門檻值(Threshold, T)，若
Ave_R 值大於 T 值，既判斷為前景物件及
物件所在位置。 
 
4.2 前景物件合成(Foreground synthesis) 
將所分離出來的前景物件合成至影像中任
意位置。由於擷取出之前景物件大致完
整，因而在進行合成處理時可獲得不錯的
合成效果。但若為了讓前景物件邊界更相
似於合成之背景處而再經由模糊化等處
理，可能會本末倒置使合成位置處更加突
兀。 
 故本研究計畫之合成處理是藉由前景
及背景的分離技術將前景物件完整擷取出
後，再直接合成至影像上之任意位置所呈
現的結果。 
 9
 
      (a)               (b) 
圖 4-3 偵測邊界之技術。 (a)黑色區域為
前景物件。(b)綠色點之遮罩為邊界處紅色
點之遮罩為前景物件內部。 
 
4.5 優先權值(priority)之計算 
先前已大致介紹基於樣本區塊修補技術之
流程，本研究計畫針對該技術當中之部份
程序有著不同的看法，考量以較短執行時
間下亦能保有較佳的修復品質之前提，進
行一系列的演算法改良。以下將說明本演
算法。對於優先權值之計算給予重新定
義，如下: 
),p()p()p( VCP =  (4-3)
(p)V 表示為亮度變異度，主要表示是在
搜尋影像中含有亮度變化及其代表強烈結
構之特性，而該值對於決定優先權值高低
計算是一項相當重要的因素。 
將計算各優先權值之區塊( pΨ )大小更改
為 11 × 11 區塊大小不同於一般所採用之
9 × 9 大小，其相關討論將於後續詳細說
明。 
1. 亮度變異度(Variation factor) 
基於樣本區塊修補技術判斷影像中是否含
有結構強烈之部份是以結構度(Data Term)
來判斷，而本研究計畫將藉由區塊之間色
彩亮度變化的差異來判斷影像中是否含有
強烈結構性及其排列優先權。亮度變異度
定義如下: 
).p()p()p( yx VVV +=  (4-4)
若只判斷單一水平或垂直方向之亮度
變異性可能會發生其他方向修復錯誤，因
此同時考慮水平及垂直雙方向之亮度變異
性，以防止其他方向之結構變化。計算雙
方向之亮度變異度方程式如下: 
,|),1(),(|)p(
1 1
pp∑∑
= =
+−=
a
i
b
j
x jiRjiRV
 
(4-5) 
,|)1,(),(|)p(
1 1
pp∑∑
= =
+−=
a
i
b
j
y jiRjiRV
 
(4-6) 
其中 a 與 b 為計算目標區域上各 P 點優先
權值之區塊( pΨ )大小，在本計畫中採用
之 區 塊 大 小 為 11 × 11 ， 
|),1(),(| pp jiRjiR +− 是針對 x 軸方
向利用像素點 R 值找出差值，其中 R 值代
表灰階值，藉由灰階值之差值，判斷出是
否含有亮度變化進而找出結構特性，同理
|)1,(),(| pp +− jiRjiR 則表示針對 y
軸方向利用像素點 R 值找出差值之計算。
以圖 4-4 為以亮度變異度為主之優先權高
低之示意圖。 
 
 11
理。 
由於信賴度之參數沒有進行取代處
理，因此可能會發生結構強烈處給予較高
之優先權，因而可能導致找到相同之補片
區塊持續進行修補，進而造成結構重複迭
代之現象。而為了避免這種情況發生，因
而提出了將計算各優先權值之區塊( pΨ )
大小由 9 × 9 更改為 11 × 11 區塊大小。
其原因在於若發生結構連續迭代之情形
時，可有效降低結構重複修補之現象，且
減少修補次數節省執行時間，以及更精準
的計算信賴度與亮度變異度，而倘若將優
先權值之區塊範圍擴充過大則會影響至修
補執行效率。將所有優先權值經由排序統
計出修補之先後順序，優先權值越大者將
優先進行修補。  
最終系統將再次檢查是否含有目標區
域，若有則持續以上流程修補直到無目標
區域為止。 
 
五、實驗結果與討論 
以下呈現部分實驗的成果。圖5-1為合成多
個物件影像。圖5-1(a)紅色區域為欲擷取之
前景位置。圖5-1(b)移除前景物件所在位置
之修補結果。圖5-1(c)合成多個前景物件實
驗結果圖。 
 
 
(a) Original image 
 
(b) Inpainting 
 
(c) Synthesis 
圖 5-1 合成多個物件影像。 
 
圖5-2為針對古蹟影像之修補合成處理。圖
5-2(a)紅色區域為部份古蹟前景物件。圖
5-2(b)移除前景物件後之修補結果。圖
5-2(c)將擷取之前景合成至任意處。 
 
 13
 
(b) Inpainting 
 
(c) Synthesis 
圖 5-4 單一前景物件合成及修補結果。 
 
圖 5-5 為針對景觀影像行修補及合成處
理。圖 5-5(a)選擇擷取前景物件。圖 5-5(b)
擷取前景物件後修復該處。圖 5-5(c)將所
擷取的前景物件合成至修復完成之影像。 
 
 
(a) Original image 
 
(b) Inpainting 
 
(c) Synthesis 
圖 5-5 針對景觀影像行修補及合成處理。 
 
由以上實驗結果得知，利用計算平均
門檻值及採取樣本修復技術，方可得到不
錯的實驗結果。但若前景物件之顏色太過
於相近背景顏色，則可能會發生擷取前景
物件時所計算之門檻值無法將其背景部份
分離。而過於複雜之紋理影像時，可能會
導致修補過程中找尋至錯誤之修補資訊，
進而使修復結果產生不必要的毀損。 
 
六、成果自評 
本研究計畫主要欲達成的目標成果是由原
始影像中隨意選取前景物件並修補該物件
移除後之區域，並可藉由擷取出之前景物
件再次合成至修補影像中或其他影像之任
意處的影像合成及修補處理系統。其中所
需的技術包含前景背景分離、計算平均門
檻值、基於樣本修補技術等。 
由於本系統採取自動計算前景物件之
擷取門檻值，但因影像中含許多影響計算
門檻值的因素而增加了擷取前景物件之困
難度，且若擷取前景物件不完整時，所剩
餘之前景物件資訊也可能造成搜尋修補資
表 Y04 1
行政院國家科學委員會補助國內專家學者出席國際學術會議報告 
                                                     九十九年七月十一日 
報告人姓名 黃惠俞 
Hui-Yu Huang 
 
服務機構
及職稱 
國立虎尾科技大學 
資訊工程學系 助理教授 
    時間 
會議 
     地點 
99 年 6 月 23 日至 6月 25 日
中國 四川成都 
本會核定
補助文號
NSC98-2221-E-150-073 
會議 
名稱 
 (中文) 第 3屆資訊科學與互動科學研討會 
 (英文) The 3rd Int. Conf. on Information Sciences and Interaction Sciences, 
China 
發表 
論文 
題目 
 (中文) 一個基於亮度變異及結構一致性之影像修補技術 
 (英文) An image inpainting technique based on illumination variation and structure 
consistency 
報告內容應包括下列各項： 
一、參加會議經過 
我的論文被選為以海報方式進行發表，並安排在六月二十四日下午的 poster section，舉
行的時間從 15：45～17：45。大會本次提供較小海報牆給 poster 使用，因而每篇論文僅能
用相當小的空間呈現研究主體及內容展示，當然為本次亦製作兩大張 A0 大小之海報資料攜至
大會會場。於會議舉行前搭乘華航航空飛抵開會地點中國成都雙流(Shuangliu airport)國際機
場。會議舉行之地點是位在成都望江賓館內進行大會之全部議程。大會早上既安排了 oral 
presentation，而大會會議之開幕式則是在二十三日(三)下午 3：00，主席 Dr. Yong Zeng 僅簡
單致歡迎詞並介紹本次研討會特色等，緊接者既進行本次會議的 4場 keynote speeches，其中
亦發表相當多於科技或工業應用在資訊科學及互動科學相關等研究的論文。此次大會議程安
排每天有四場 sessions、16 場 poster sessions 議程進行，整個會議分散在兩棟不同館中進行，
時間安排是相當充實且緊湊。 
 
二、與會心得 
此 IEEE series 會議(ICIS2010)為期三天(六月二十三號至二十五日)在中國成都舉行，而這
是我第二次到中國參加國際性會議。我的論文在會議中是以海報方式進行論文及成果展示與
報告。與會的人員有來自世界各地皆是這相關資訊科技領域的專家、科技人才及學者等，共
附件三
 
表 Y04 3
 
Topic3: Convergent Approaches: Future, Sciences and Environment 
T3S01: Technical and Futurological Issues for the Future 
T3S02: Information Technology in Environment, Green Energy and Energy Management 
T3S03: Information Technology in Sciences 
T3S04: Information Technology in Geography 
T3S05: Information Technology in Ubiquitous Computing and Environment 
T3S06: Information Technology in Housing, Building and Construction 
T3S07: Information Technology in Control, Automation and Mechanics 
T4S08: Technical Issues in Logistics, Transportation and City 
T3S09: Any other Interdisciplinary Researches and Applications relevant to Convergent 
Approaches 
Topic4: Industrial, Service, Management Issues and Applications 
T4S01: Industrial Issues of Information Technology 
T4S02: Management Issues in Logistics, Transportation and City 
T4S03: Information Technology in Management and Service Issues 
T4S04: Advances in e-Commerce 
T4S05: Information Technology in Finance 
T4S06: Information Technology in Statistics 
T4S07: Industrial Developments with Information Technologies 
T4S08: Advances in Organizational behaviors/ Human Resource Management 
T4S09: Any other Interdisciplinary Researches and Applications relevant to 
           Industrial, Service, Management Issues and Applications 
 
結合文化、人類及訊息技術、環境、綠能產業、普及計算、工業應用、服務及管理議題等跨
領域範疇的研討會。此會議每年定期在不同國度舉行，徵稿文件亦是倍數成長，被接受之論
文皆經過嚴格的審查程序處理，藉此維持高品質高水平的論文刊登於 proceeding 中。因此，
對與會的人員而言，本會議無疑是提供一個多方面跨領域且可獲得最新且更具實際應用的相
關研究範疇的一個展示平台，也是一個再學習及分享成果的優秀會議。同時亦可直接的向與
會專家學者們進行技術討論及學術交流，是相當有意義的國際會議。出席大會的學者相當踴
躍且可觀，無論是 oral presentation 或是 invited speeches 皆非常踴躍的在每一位演講者結束後
之 Q ＆ A 時間對報告者提出了問題或是建議等。 
  我的 poster session 時間被安排在會議進行的第二天(六月二十四日)下午三點四十五分後的
表 Y04 5
六、其他 
  附上會議之舉行地點及出席 poster presentation 的照片如下。 
 
 
大會會址       大會會場 
 
大會會場(場外、場內) 
 
Poster session 
 
附錄一： 
Program （節錄部分） 
ix 
 
The study for the RFID with Bluetooth Positioning System ……………….. 386
Chung-Hsin Liu ,  Jian-Yun Lo  
  
  
The study for the extension of Bluetooth Tree network ……………….. 392
Chung-Hsin Liu ,  Wen-Yan Zeng  
  
  
Research of Mobile Agent Workflow Path Dynamic 
Programming Method Based on Social Acquaintance Network 
……………….. 398
Gao Jilin ,   Zeng  Guangzhou  
  
  
A Camera Calibration Technique Based on OpenCV ……………….. 403
Y. M. Wang ,  Y. Li ,  J. B. Zheng  
  
  
Computing Invariants of Hybrid System using Quantifier 
Elimination 
……………….. 407
Yongquan Wang ,   Zhiqing Shao ,  Zhongqin Bi  
  
  
Visibility Detection Based on Traffic Camera Imagery ……………….. 411
An Ming-wei ,  Guo Zong-liang ,  Li Jibin ,  Zhou Tao  
  
An image inpainting technique based on illumination variation 
and structure consistency 
……………….. 415
Hui-Yu Huang ,  Chun-Nan Hsiao  
  
  
 A scientific assessment of home networking research trends ……………….. 421
Chi-Yen Yin ,   Jiann-Min Yang  
  
  
 A   RBAC   Model Considering the User Reliability in Workflow 
System 
……………….. 426
Su Wei ,   Zeng Guangzhou  
  
  
Segmentation of Color Image Contour Using Fuzzy Cluster 
Analysis 
……………….. 431
Ding Caihong ,  Jiang Lin ,  Du Fenghai  
  
  
  
The remainder of this paper is organized as follows. Section 
II presents the key factors which form the basis of the 
algorithm. Image inpainting method is described in Section III. 
Section IV presents the experimental results. Finally, 
conclusions give in Section V. 
 
  
(a) 
 
(b) 
 
Figure 1.  Removing objects from images. (a) Original image. (b) The region 
corresponding to the foreground object has been manually selected and then 
automatically removed. 
II. TWO KEY FACTORS  
For image inpainting, there is existed one problem that how 
to decide the initial repairing points from many points in the 
target region to fill this region. In order to solve problem, we 
adopt the structure consistency and luminance variance of each 
point in the target region to construct an efficient image 
inpainted method. The core of our algorithm takes advantage of 
the confidence feature method and the variation between the 
neighbor pixels in the gray image from exemplar-based image 
inpainting and image focus quality assessment. In the following 
subsection, we will describe and define the confidence factor 
and variance factor in detail. 
First, let I be the original image which includes a target 
region, denoted by Ω , to be inpainted and a source region, 
denoted by Φ , where patches are searched and used. Hence, 
Φ ΩI = ∪ , a contour of the target  region  is denoted Ωδ , 
the mask size of  p  is denoted Ψ p ,  q  is pixels of source 
region. Here, we use a default mask size of 9×9 pixel as an 
exemplar region. We will compute the priority of each pixel on 
the boundary from the target region, and then according to the 
level of the priority order to sequentially fill in the patch 
information. Finally, the priority of the boundary in the target 
region will be updated. 
Given a patch pΨ centered at the point p for some 
Ωp δ∈  (see Fig. 2), we define its priority function P(p)  as 
the sum of two factors. 
 ( )  ( ) ( ),P p C p V p= +  (1) 
where ( )C p  is called the confidence factor and  ( )V p is 
called the variation factor. 
A. Confidence factor 
Confidence factor may serve as a measure of the amount of 
reliable information surrounding the point p. When points are 
surrounding by more pixels from the original image, these 
patches can obtain more reliable information from the source 
region against which to match. Hence, when point p has more 
reliable information, it will obtain good filling result. Let Ωδ  
be a front contour on target region Ω  and adjacent to source 
region Φ , as shown in  Fig. 2, point p is positioned on the 
boundary of the target region Ω . We compute the initial 
confidence factor of each point in I, which is due to [14]:  
 
( ) 1  Φ and ( ) 0  Ω.C p iff p C p iff p= ∈ = ∈  
 
Based on the same notation as [14], let Ψ p  be a patch 
centered at point Ωp δ∈ . We also use the same concept to 
compute the confidence factor C(p) : 
 ( Ω)( ) ( ).pq IC p C qψ∈ ∩ −= ∑  (2) 
The function C(p) is  set  to ( ) 0,   ΩC p p= ∀ ∈  and 
( ) 1,   -ΩC p p I= ∀ ∈ . For example as shown in Fig. 3, if 
this point p stays in the source region Φ  for this mask, then 
C(p)=1, if this point p stays in the target region Ω , then 
C(p)=0. Essentially, the confidence factor computes the 
number of useful points in a patch Ψ p . Useful points mean the 
coverage of source points in Φ . These useful points are use to 
find a best matching patch in the source region. 
The factor C(p) approximately enforces the desirable 
concentric fill order. After filling process, pixels in the outer 
layers of the target region will tend to be presented by greater 
416
 ( ) ( ) ( ).x yV p V p V p= +  (3) 
The function V(p) represents the variation value of the each 
point p along the boundary in the target region, where  ( )xV p  
and ( )yV p are expressed as  Eqs. (4) and (5), respectively. 
 
 ( ) ( , ) ( 1, ) .
m n
x x x
i a j b
V p p i j p i j
= =
= − +∑∑  (4) 
 
( )xV p  denotes the MAE difference between the adjacent 
points corresponding to the x-axis direction from the patch 
centered at the point p and m×n  is a patch centered at the 
point p. 
 ( ) ( , ) ( , 1) .
m n
y y y
i a j b
V p p i j p i j
= =
= − +∑∑  (5) 
( )yV p denotes the MAE difference between the adjacent 
points corresponding to the y-axis direction from the patch 
centered at the point p. As shown in Fig. 6, a patch Ψ p  
centered at the point p contains the strong structure than other 
points on the boundary of the target region. 
Finally, we together with the confidence factor and the 
variation factor to calculate the most pixel value of the source 
information and the most strong structure property on the 
boundary for an image, these obtained properties have the high 
inpainting priorty than others location at the target region. 
 
 
Figure 6.  Illustration of the variation factors on the boundary of the target 
region. If the location is more close to the strong structure of the source region 
on the target region, then the location gives the higher priority than others 
location on the target region, which means the more the first to be inpainting. 
III. EXEMPLAR-BASED INPAINGING METHOD 
 
The proposed method mainly improves the examplar-based 
inpainting method [4], and briefly described as follows. Firstly, 
the region of the initial inpainting on the target region needs to 
find using the surrounding information pixels of the source 
region so that this region and the approximate local texture 
direction on the neighbor of the initial inpainting region are 
obtained. Then, filling properties are computed in which a 
predefined priorty function is used to compute the filling order 
for all unfilled pixels Ωp δ∈ . Next, example and 
composition are searched in which the most similar example is 
searched from the source region Φ to compose the given patch 
Ψ p  that centered on the given pixel  p. 
Finalliy, in accordance with the orders of priority, the 
inpainting up on the target region is continuing until without 
the target region in the midst of the image. 
 ˆΨ
Ψ .q q p
C
N∈
= ∑  (6) 
ˆΨ p is the source region of the initial inpainting on the 
target region centred at the point P, ˆΨq  denotes the best-match 
neighbor sample from the source region of the initial inpainting 
on the target region. C and N represent the average pixel value 
and the total of pixels of this source region for the initial 
inpainting on the target region, respectively. 
IV. RESULTS 
Our proposed algorithm has been tested a variety of 
images, ranging from full-color photographs that include 
complex textures. The environment of experiments was 
implemented on a 2.00-GHz Intel® p7350 with 4 GB of RAM 
PC.   
Comparing the different size of the inpainting mask from 
the target region, Figs. 7(b), (d), and (f) manually select a small 
range of the target region. Figs. 7(c), (e), and (g) manually 
select a wide range of the target region. 
Because of the different size of the inpainting mask, it will 
produce the difference of filling order, such as Figs. 7(d) and 
(f). The inpainting information of Figs. 7(d) and (f) is 
markedly different at the lower left in the target region. Fig. 
7(e) employs the small size of the inpainting mask, it produces 
the difference of the inpainting order, it is because the reliable 
information about the repairing region is low, the experimental 
result will cause the structure obviously destroyed. For Fig. 
7(e), the structure-destroyed situation is presented in the 
grassland on the target region. While using the large size of 
the inpainting mask is to repair, it can obtain a good visual 
quality, as shown in Figs. 7(f) and (g). 
To sum up, the size of mask is too small in the target 
region, the available information of the source is also relative 
P
Φ
Ω
Ωδ
Φ
PΨ
418
  
      (a) 
 
(b) 
 
Figure 10.  Removing large objects from photographs. (a) Original image. (b) 
Due to the target region select is incomplete, it caused the right parts of the 
inpainting in the target region have error information. 
V. CONCLUSIONS 
In this paper, we proposed an efficient image inpainting 
approach. Based on structure consistency and variance between 
the adjacent points in the target region, the initial point on the 
damaged region can decide exactly and repair fast. The results 
demonstrate that this method can recover the large or small 
damaged region and obtain good visually plausible image. 
ACKNOWLEDGEMENT 
  
REFERENCES 
[1] M. Bertalmio, G. Sapiro, V. Caselles, and C. Ballestrt, “Image 
inpainting,” in Proc. ACM Conf. on Comp. Graphics.(SIGGRA-PH), 
2000, pp. 417–424. 
[2] M. Bertalmio, A. Bertozzi, and G. Sapiro, “Navier stokes, fluid-
dynamics and image and video inpainting,” in Proc. of IEEE Computer 
Society Conf. on Computer Vision and Pattern Recognition, 2001, pp. 
1335–1362. 
[3] T. K. Shin and R. C. Chang, “Digital inpainting-survey and mulitiplayer 
image inpainting algorithms,” in Proc. of the 3th Int. Conf. on 
Information Technology and Applications, 2005, pp. 15–24. 
[4] W. H. Cheng, C. W. Hsieh, S. K. Lin, C. W. Wang, and J. Wu, “Robust 
Algorithm for exemplar-based image inpainting,” in Proc. of Int. Conf. 
on Computer Graphics Imaging and Visualization (CGIV), 2005. 
[5] J. C. Hung, C. H. Hwang, Y. C. Liao, N. C. Tang, and T. J. Chen, 
“Exemplar-based image inpainting base on structure construction,” 
Journal of  Software, vol. 3, no. 8, pp.57–64, 2008. 
[6] J. Y. Wu and Q. Q. Ruan, “A novel exemplar-based image completion 
model,” Journal of Information Science and Engineering, vol. 25, pp. 
481–497, 2009. 
[7] J. Sun, L. Yuan, J. Jiam, and H. Y. Shum, “Image completion with 
structure propagation,” in Proc. of ACM SIGGRAPH, 2005, pp. 861–
868. 
[8] N. Komodakis and G. Tziritas, “Image completion using global 
optimization,” in Proc. of IEEE Computer Society Conf. on Computer 
Vision and Pattern Recognition, 2006, pp. 442–452. 
[9] A. A. Efros and T. K. Leung, “Texture synthesis by non-parametric 
sampling,” in Proc. of the 7th IEEE Int. Conf. on Computer Vision, 1999, 
vol. 2, pp. 1033–1038. 
[10] A.  A. Efros, and W. T. Freeman, “Image quilting for texture synthesis 
and transfer,” in Proc. of SIGGRAPH 2001, pp 104–106. 
[11] P. Tang, Application of Non-parametric Texture Synthesis to Image, 
Master Thesis, University of New Mexico, May 2004. 
[12] M. M. Oliveira, B. Bowen, R. McKenna, and Y. S.  Chang, “Fast digital 
image inpainting,” in Proc. of the Int. Conf. on Visualization, Imaging 
and Image Processing (VIIP 2001), 2001, pp. 261–266. 
[13] A. Telea, “An image inpainting technique based on the fast marching 
method,” Journal of Graphics Tools, vol. 9, no. 1, pp. 25–36, 2004. 
[14] A. Criminisi, P. Pérez, and K. Toyama, “Region filling and object 
removal by exemplar-based image inpainting,” IEEE Trans. on Image 
Processing, vol. 13, no. 9, pp. 1200–1212, 2004. 
[15] W. Y. Wu, K. C. Shih, Y. C. Tsai, and J. L. Su, “Image focus quality 
assessment,” in Proc. of the 40th Int. Conf. on Chinese Society for 
Quality, 2004, pp. 82–90. 
This work was supported in part by the National Science 
Council of Republic of China under Grant No. NSC98-2221-
E-150-073. 
 
420
表 Y04 2
同在此會議上進行研究交流及經驗分享。 
此次的會議分三天進行共有 4 sections 包含 4 場 invited talks、30 場 oral presentations、16
場 poster sections 分別在會議舉行期間進行。由於本次大會與第 2 屆軟體工程與資料探勘會
議共同舉行(2nd Conf. Software Engineering and Data Mining, SEDM2010)，因此收錄了相當份量的
論文篇數於大會中進行發表。 
本次會議論文的相關議題其涵蓋的領域相當廣泛，主要分四大主題： 
Topic1: Culture, Human and Information Technologies  
T1S01: Information Technology in Education 
T1S02: Information Technology in Culture and History 
T1S03: Information Technology in Living 
T1S04: Information Technology in Healthcare 
T1S05: HCI and Cognitive Sciences 
T1S06: Advances in Digital Content and Applications 
T1S07: Information Technology in Multimedia and Game 
T1S08: Information Technology in Mass Media and Communication Art 
T1S09: Information Technology in Design 
T1S10: Any other Interdisciplinary Researches and Applications relevant to Culture, Human and 
Information Technologies 
Topic2: Advances in Information Technology 
T2S01: Advanced Information Technology 
T2S02: Advances in Wire/Satellite/Wireless Communication and Networking 
T2S03: Advances in Software 
T2S04: Advances in Data Processing and Management 
T2S05: Advances in Computational Theories, Algorithms and Applications 
T2S06: Advances in Artificial Intelligence and Expert System 
T2S07: Information Technology in Security and Assurance 
T2S08: Information Technology in Knowledge and Decision Making 
T2S09: Information Technology in Web and Language Processing 
T2S10: Advances in Pattern Recognition and Computational Graphics 
T2S11: Information Technology in Consumer’s Electronics and Electronic Devices 
T2S12: Embedded Systems/ Software and Telematics and Home Network Technology and its 
Applications 
T2S13: Advances in Computer Applications 
T2S14: Any other Interdisciplinary Researches and Applications relevant to Advances in 
Information Technology 
表 Y04 4
兩個小時，而大會安排共有 16 場 poster session 共有 60 篇的論文分別在大會報到處之兩個大
展示版上供其展示資料。由於大會並沒有安排作者需要在展示版前報告相關研究，因而參與
poster session 的作者們可選擇性出席在展示版前。這是我參加以往研討會所未見的情況，換
言之，大會鼓勵 poster session 的作者們踴躍參加 oral sessions。雖缺少與學者、專家或業界來
賓等面對面的討論略嫌有所遺憾，但卻增加的領聽更多專家學者們精闢的報告及研究成果的
分享，也是另一種不同的經驗。對我而言，這三天的會期所獲得的經驗有別於其他以往參加
國際會議的經驗，也是再一次獲得難得又相當寶貴的學習之旅，往後將更加致力於開拓更廣
更深研究領域及多參加國際性相關研究議題之會議，拓展自己的國際視野，提升自己在研究
方面能更具多樣性及應用性。因會議舉行地點在成都，而成都這具中國歷史古城及現代化的
城鎮，在參加會議期間順道瀏覽回顧三國時代的歷史遺跡及各項現代建設等，做了一次新舊
城鎮的探訪。讓本次之行除了學術的斬獲之外，也做了一番文化巡禮，真可謂受益良多。 
   
三、考察參觀活動(無是項活動者省略) 
無 
四、建議 
無 
五、攜回資料名稱及內容 
本次會議主要攜回論文摘要集一本 (proceedings)、會議光碟片 1 片及議程資料。議程包
含 invited talks(4 篇)、oral papers and poster papers 共 277 篇等全文論文。其主要目錄依日期分
列，如附錄一。 
2010 The 3rd International Conference 
on Information Sciences and Interaction 
Sciences  
 
 
 
 
ICIS 2010 
 
Table of Contents 
Modeling Knowledge Logical Organization with Intelligent 
Topic Map 
……………… 1
Guangzheng Li ,  Huimin Lu ,  Tao Wang  
  
  
Design of Ship Monitoring System Based on WebGIS ……………… 6
Xing Zi Nan ,  Li Hai Tao  
  
  
DiffServ-Aware MPLS Traffic Engineering ……………… 9
Xiaoping Li ,  Xiaoxing Lv ,  Luyang Liu ,  Wenbo Mei  
  
  
Comparative Study on Wavelet Transform and Traditional Image 
Processing 
……………… 13
Xiaoping Li ,  Lin Zhang ,  Hongjian Dong ,  Jianqiang Xu  
  
  
Algorithm for Solving Time Table Questions Based on GA ……………… 18
Xiaoping Li ,  Xiaoxing Lv ,  Wenbo Mei ,  Hu Xu  
  
  
Research on Clustering Algorithm Used to Choose the Villa 
Topographic 
……………… 22
Xiaoping Li ,  Xuelin Wu ,  Lihua Zhang ,  Zhenghong Wang  
  
  
  
  
i 
 
An image inpainting technique based on illumination 
variation and structure consistency 
 
Hui-Yu Huang 
Department of Computer Science and Information 
Engineering, 
National Formosa University 
64, Wun-Hua Rd., Huwei, Yunlin 632, Taiwan 
E-mail: hyhuang@nfu.edu.tw 
Chun-Nan Hsiao 
Department of Computer Science and Information 
Engineering, 
National Formosa University 
64, Wun-Hua Rd., Huwei, Yunlin 632, Taiwan 
E-mail: jim75810@gmail.com
 
 
Abstract—Image inpainting is that restores the damaged region 
of interest by user specified or removes areas in an image. For the 
purpose of patching up automatically, filling in large-sized 
damaged areas in the image, and lowering down the operation 
complexity, we design an exemplar-based image inpainting as our 
main framework. In order to keep the structure consistency 
between the damaged areas and the non-damaged areas, we 
redefine two factors, confidence and variation, which use to 
determine the priority of the filling order of target (damaged) 
regions. With these two newly defined factors, we propose a 
dynamic rule to choose the best target region and the suitable 
patch size in each filling step. To solve the challenging problem of 
repairing structure in image completion, we introduce a novel 
image completion approach based on automatic salient structure 
propagation. Experimental results demonstrate that this 
approach can make an effective inpainting and visual quality. 
Keywords- image inpaintin;illumination variation; structure 
consistency; 
I. INTRODUCTION 
The greatly advanced in digital technology is more and 
more fast, especially computer, people often keep their airs, 
graphics, photos or the valuable films in their computer. By the 
modern computer, these photos would delete or inpaint the 
interested object or other related applications to achieve 
visually plausible and to create a new digital image. Figure 1 
shows an example of image inpainting, where the foreground 
object (manually selected as the target region) is automatically 
replaced by data sampled from the rest of the image. And it can 
use to apply to change of image foreground, the reconstruction 
of the historic interest on image inpainting, virtual reality, etc. 
Based on the target region of the image inpainting  
techniques, they consist of three phases: pixel-based [1-3], 
exemplar-based [4-6] and full [7, 8].  Bertalmin et al. [1, 2] 
proposed a repaired method based on filled in the missing data 
by the property of isophotes (lines of equal gray value). Using 
the image smoothness information, estimated by the image 
gradient rotated 90 degree, the missing region can be filled. 
Cheng et al. [4] proposed an exemplar-based image inpainting 
technology. This system adopted a generic propriety function 
to develop robust inpainting which can apply to several kinds 
of still images.  Hung et al. [5] used the structure generation 
and Bezier curves to construct missing edge information. Using 
the structure information and reconnected contours by curve 
filling process, the damaged regions will be inpainted. Wu and 
Ruan [6] proposed a novel exemplar-based image completion 
model using the local texture information which decided a 
dynamic size of exemplar, cross-isophote diffusion data which 
obtained the structure preserving property, and a gradient 
constrained total variation interpolation which used to reduce 
seams. Sun et al. [7] introduced an image completion model 
with structure propagation. Authors firstly specified missing 
structure information by means of extending line segmentation 
in a target region, and then the image patch is copied along 
structure and consistency constraints. This model can obtain 
good image but it needs user’s interaction. Komodakis and 
Tziritas [8] proposed exemplar-based framework unifying 
image completion, texture synthesis and image inpainting. 
Author used the well-defined objective function to solve the 
optimization problem and used priority belief propagation to 
achieve a variety of image completion examples. 
Hence, for pixel-based phase, pixel-based method is to 
employ sample (pixel) synthesis of the target region (gap). For 
exemplar-based phase, it is based on a patch to take as filling 
range, and then slowly extend the range until all pixels have 
done. For full phase, this method is to find the best source 
patch from the image, that is want to fill of the best match of 
the target region, but it will increase the computing complexity 
and time consuming. 
Image inpainting techniques can be divided into two phases: 
texture synthesis [9-11] and image inpainting [12, 13]. For 
texture synthesis phase, it provided the texture sample to 
synthesize a target region (gap), this information can enough to 
fill the large region of the target region and to fit the content 
uniformity and structure material texture which can widely use 
in the field of computer graphic. For image inpainting phase, it 
employed the color characteristics of the target region for an 
image, such as R, G, B values, to carry out inpainting work. In 
this paper, an efficient inpainting scheme based on structure 
consistency and illumination variance, which modifies the 
exemplar–based method [14] and image focus quality 
assessment [15], will be proposed to achieve the inpainting the 
specified region. 
415
confidence values, and therefore be filled earlier; on the 
contrary, pixels in the center of the target will have lesser 
confidence values. 
 
Figure 2.  Mask size of the point p. For each of points in contour of the target 
region, and that computes confidence value. 
 
 
Figure 3.  Target region boundary confidence value set on an example. 
 
 
Figure 4.  Effects of the confidence factor. The confidence factor assigns 
high filling priority to out-pointing appendixes (in green) and low priority to 
in-pointing ones (in red), thus trying to achieve a smooth and roughly circular 
target boundary. 
As illustrated in Fig. 4, the upper left part of the target 
region (in green), that contains more pixels than other target 
region, and the confidence value is higher by used Eq. (2), the 
lower right of the target region (in red), that contains less pixels 
than other target region, hence, the confidence value is lower 
by used Eq. (2). 
B. Illustration variation factor 
For the target region, this region usually has the same 
structure characteristic from the source region. The 
illumination change which is one of structure characteristics is 
usually used to represent the light intensity. The measurement 
of the illumination change is computed the difference between 
the gray values of the neighbor pixels of the source structure. In 
this paper, we define this illumination change is the variation 
factor. 
Computing the variation value between the neighbor pixels 
on the boundary of the target region, it is obvious that the color 
variance of pixel on the boundary of the target region is large, 
its meaning represents the noticeably color difference between 
the adjacent pixels in the same region. In other words, this 
region may contain the structure property. On the contrary, 
when the variance value is little, it represents the close color 
intensity in the same region; therefore, the region may be 
belonged to the smooth region.   
For example shown in Fig. 5, the upper left and the lower 
right parts are higher the other target region compared to all 
boundaries of the contact location in the target region (in green), 
it is because the green location has relatively a high value of 
the variation. In other words, these two locations have a high 
priority to be selected to repair. For variation measurement, we 
use the general formula to estimate the difference, such as 
mean absolute error (MAE). 
 
 
 
Figure 5.  Effects of the variation factor. The variation factor gives high 
priority to pixels on the continuation of image structures (in green) and has the 
effect of favoring in-pointing appendixes in the direction of incoming 
structures. 
 
P
Ω
Φ Ωδ
PΨ
q
P
( ) 1C p =
( ) 0C p =
Φ
Ω
Ωδ
Φ
Ω
Ωδ
Φ
Ω
Ωδ
417
decrease; that will seriously affect the filling order and the 
repairing result. By contrast, if the mark is used the bigger size, 
it will retain the reliable information of the source region, the 
inpainting can yield the better result. Although the large mask 
can obtain more information of the inpainting in the target 
region, it also causes the heavy computational load. Figures 8-
10 show the other experimental results.   
 
 
(a) 
 
(b)                  (c) 
 
(d)                (e) 
 
 (f)                (g) 
 
Figure 7.  Effect of the different size of the inpainting mask and the different 
location of the target region on a cow photograph. (a) The original image. (b) 
Manually select a small range of the target region. (c) Manually select a large 
range of the target region. (d) Select a small size of the inpainting mask. (e) 
Employ a small size of the inpainting mask for the filling large range on the 
target region. (f) Select a largel size of the inpainting mask. (g) Employ a 
large size of the inpainting mask for the filling large range on the target region. 
 
 
 
   
(a)                   (b) 
   
(c)                        (d) 
   
(e) (f) 
 
Figure 8.  Removing objects from the cartoons image. (a) Original image. (b) 
The target region has been red out. (c)–(e) Intermediate stages of the filling 
process. (f) The target region has been completely filled and the selected 
object removed. 
 
 (a) 
 
(b)                                (c) 
 
Figure 9.  Effect of inpainting objects of the different location on the target 
region. (a) The original image. (b) Red region is the target region. (c) The 
target region has been filled via our proposed algorithm. Triangular part has a 
slight damage structural of the boundary in the target region. 
419
無研發成果推廣資料 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
其他成果 
(無法以量化表達之
成果如辦理學術活
動、獲得獎項、重要
國際合作、研究成果
國際影響力及其他
協助產業技術發展
之 具 體 效 益 事 項
等，請以文字敘述填
列。) 
本研究成果發表的情形： 
(1)部分的研究成果已發表在 EI 國際會議論文上，其發表之論文為下： 
H. Y. Huang and C. N. Hsia, An image inpainting technique based on 
illumination variation and structure consistency,in Proc. of  the 3rd Int. 
Conf. on Information Sciences and Interaction Sciences (ICIS'10), June, 
China, 2010. (NSC98-2221-E-150-073) 
(2) (EI) H. Y. Huang and C. N. Hsia,A patch-based image inpainting based 
on structure consistence, to accept the 2010 International Computer 
Symposium (ICS2010), Dec., Taiwan, 2010.(NSC98-2221-E-150-073) 
(3)另外，較完整的成果也積極整理中，準備投稿相關國際期刊論文。 
 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
