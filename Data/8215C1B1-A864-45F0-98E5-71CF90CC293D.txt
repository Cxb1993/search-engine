 2
中文摘要 
 
本文探討 Neuro-Fuzzy Filter 之映射關係在適應性訊號處理的應用。Neuro-Fuzzy Filter
與適應性濾波器有密切的關連,運用其訊號映射關係在適應性干擾訊號處理的研究,著重在
機器學習演算法對 Neuro-Fuzzy Filter 之適應性濾波。Neuro-Fuzzy Filter 融合模糊邏
輯與類神經網路的系統具備著策略法則的表達與適應能力的特性，而這樣的特性對智慧
性、適應性與容錯性上有良好的影響。濾波(filtering)的主要目的為從受雜訊干擾的數據
(Data)或訊號中淬取出想要的(有用的)資訊或訊號，主要是研究 Neuro-Fuzzy Filter 在處
理雜訊濾波的能力,使 NFS-filter 之映射關係能接近 noise 之映射關係。本研究之
NFS-filter 具有自我架構建立之能力與自由參數調整能力。本系統以語音訊號雜訊抑制為
例，說明研究方法之可行性 
 
關鍵詞：模糊類神經、隨機最佳化、最小平方估測、雜訊抑制、適應性濾波,機器學習。 
 
 4
I.   Introduction 
Generally, noise is usually highly nonlinear and correlated with uncertain factors. Traditional 
linear filters like FIR or IIR filters may not be good enough to handle with the complexity of 
noise nonlinearity. In principle, the problem of adaptive noise filtering is to extract a desired 
signal from its corrupted version [1]. Recently, adaptive filtering may provide better solution to 
noise filtering problem. Adaptive systems as adaptive filters possess the characteristics of 
self-adjustment, and/or intelligent strategy to practical applications with limited priori 
information. Engineers and scientists have focused their attention to model-free approaches and 
the intelligence-based theories such as fuzzy logic [2] and neural network [3]. Since fuzzy 
inference systems and neural networks have been shown being universal approximators [4, 5], the 
integration with neuro-fuzzy system (NFS) has widely been recognized a complementary model 
that allows for low-level learning and computational power and high-level human thinking and 
knowledge representation. The objective of soft computing based approach for adaptive noise 
filtering is to attenuate or eliminate noise from the corrupted signal. Generally, establishing an 
NFS includes the structure complexity and the parameter identification. For structure complexity, 
the partition of the input-output space and the identification of appropriate rules to achieve the 
desired performance have received much attention. Several approaches [6, 7, 8-10] have been 
addressed to achieve compact and effective system structure. However in these approaches the 
balance between the number of hidden neurons and the system performance is concerned before 
training. The grid-type partitioning is often suffered from the problem commonly referred to as 
the “curse of dimensionality”, in which the rule number will become exponentially large if the 
input dimension increases. In order to avoid the problems of over-parameterization and to ensure 
structure concision, this depends heavily on experience and a tedious trail-and-error. Thus, it is 
usually needed to have a “smarter” mechanism for system learning. A new intelligent filtering 
approach with self-constructing neuro-fuzzy system (SCNFS) is proposed for the problem of 
adaptive noise cancellation (ANC). The goal of noise cancellation is to extract the desired signal 
from its noise-corrupted version by using the proposed SCNFS as a computational intelligence 
(CI) based adaptive filter. In the report, a hybrid learning algorithm with the random optimization 
algorithm (RO) and the least square estimation (LSE) is used for the NFS to perform structure 
learning and parameter learning simultaneously. In the parameter learning phase, the RO [11, 12] 
is combined with the LSE to train the parameters of the SCNFS, where the premises and the 
consequents of the SCNFS are updated by RO and LSE, respectively. The structure learning is 
composed of two phases, which are the rule-splitting phase and rule-expanding phase. In the 
structure learning, appropriate rules can be generated and/or rearranged with the proposed 
mechanism for rule significance detection. With the proposed hybrid learning, a compact-sized 
and well-parameterized NFS can be established with good system performance. The proposed 
SCNFS filter features the following properties: 1) online rule construction, 2) intuitive and 
derivative-free learning, 3) easy to program, and 4) fast convergence and robustness. The 
problem of the adaptive noise cancellation is given in section 2. In section 3, the structure of 
neuro-fuzzy system is presented. In section 4, the RO-LSE hybrid-learning algorithm is discussed. 
In section 5, the self-construction scheme for structure learning is discussed. The proposed 
From Eq.(5), the conclusion is deducted that the power minimization of the signal  is 
equivalent to minimizing the power of noise. In the paper, the neuro-fuzzy filter is trained to 
remove the noise in the adaptive noise cancelling process. 
)(tr
 
For simplicity, an MISO (multi-input-single-output) fuzzy inference system with the crisp input 
vector   measured at time )(tH t , composed of M input variables , , is 
considered. The universe of discourse of each input dimension is defined with corresponding 
linguistic variables denoted as . In this paper, a flexible cluster-based partition method is used 
to avoid the unnecessary rules, where the partial-connected structure is exploited. Assume that 
the vector of the linguistic term   belong to the i-th input variable is given as follows.  
)(thi Mi ,,2,1 K=
ix
iV
 
 
     (6) [ TRiiii vvv ,2,1,V L= ]
kk ttyTHEN aHa
v)()( =
where R is the amount of rules   and   the k-th linguistic term of the i-th linguistic input 
variable. In the proposed SCNFS, the well-known fuzzy T-S model is exploited. Based on the 
proposed fuzzy inference process, the k-th rule description can be given as follows. 
kiv ,
MkMM
kk
thsisand
thsisandthsisIFkRule
V
VV
))((
...))(())((:
,
2,221,11
                      (7) 
where is defined as the k-th fuzzy set for the i-th linguistic variable ))((, ths iki [ ]kMkkk aaaa L10=  
the parameter vector of the consequent of the k-th rule, [ ])()(1 1 thth Ma L=H , and  the 
output of the k-th rule. Based on (7), the inferred result at time t is expressed as 
ky
)(tY
   
∑∑
∑
=
=
= =
×
=
R
k
i
a
k
K
k
k
K
k
kk
t
t
tyt
tY
1
1
1 )(
)(
)()(
)( aH vβ
β
β                 (8) 
where  kβ  is the normalized firing strength of the k-th rule. 
is composed of the layers of input 
) 
for 2,1= Th out t c e polynomial functions of the input signals. 
 premise se
 
A five-layer neuro-fuzzy structure is shown in Fig. 2, which 
(Layer 1), membership (Layer 2), rule (Layer 3), normalization (Layer 4), and output (Layer 5). 
Layer 1 accepts the input signals. Layer 2 is used to calculate the Gaussian membership values. 
The nodes of layer 3 represent the fuzzy rules. In layer 4, the normalization process is executed. 
The network before layer 4 represents the premises of the rules, and that after layer 4 represents 
the consequents of the rules. Layer 5 is the output layer. Based on the constitution of the T-S 
fuzzy model, the link weight is given as follows. 
k
akow aH
v=5                   (9
Rk ,,K . e pu an be represented as th
The ts of the SCNFS are collected as follows.  
[ ]Rmmmm L21=             (10) 
[ ]Rσσσσ L21=                (11) 
 6
Epoch counter 
EC=0
Initial 
condition
SCNFS
SCNFS
SCNFS
SCNFS
SCNFS
)(NY +
−
D(N)
LSE
)(NY +−
D(N)
)(NY +−
D(N)
)(NY +
−
D(N)
)(NY +−
D(N)
Cost    
function
Is
minimum?
pW
oW
pαW Yes
nW
oW
nαW
)0(W
RO
interpolation  
search 
)(⋅E
)(Nε
)(Nε
)(Nε
)(Nε
)(Nε
?)( TN ≥εYes
 
 
Fig. 3. RO-LSE training. 
 
ith the integration of RO-LSE, each candidate point generated by RO is viewed as a potential W
premise parameter solution. Based on Eq. (8), the relationship between the input vector 
)(NH and the desired output can be given as follows. 
)())(...)(()()(
1
110 NNhaNhaaNND
R
kkkk
    
k
MM εβ ++++×= ∑
=
    (17) 
where )(Nε  is the identification error. Let 
[ ]
)()( NN a
k Hβ=
            (18) 
                      (19) 
Eq. (17) can be represented as follows. 
1
N
k
ε+
=
 
       (20) 
Ass  Q training data pairs  to be identified as follows. 
)()()(1)()( 21 NhNhNhNN M
kkG β= K       
[ ])()()()( 21 NNNN KGGGG K=
  
)()()()( aNNNND
K
kkε =+= ∑ vGAG )(
uming there are
876876v44444 844444 7648476
ζABD
1          (21) 
M
v
M
v
L
MMMM
L
L
M
a
a
a
GGG
GGG
GGG
⎥⎥
⎥⎥
⎦
⎤
⎢⎢
⎢⎢
⎣
⎡
+
⎥⎥
⎥⎥
⎥
⎦
⎤
⎢⎢
⎢⎢
⎢
⎣
⎡
⎥⎥
⎥⎥
⎦
⎤
⎢⎢
⎢⎢
⎣
⎡
=
⎥⎥
⎥⎥
⎦
⎤
⎢⎢
⎢⎢
⎣
⎡
)(
)2(
)1(
)(
)(
)(
)()()(
)2()2()2(
)1()1()1(
)(
)2(
)1(
2
21
21
21
QQQQQD
D
D
KK
K
K
ε
ε
ε
In the proposed parameter learning, the LSE can be implemented in recursive way, called 
recursive LSE (RLSE), by which the update can be implemented with individual training pattern. 
The algorithm given below is called weighted recursive LSE (WRLSE), which provides with the 
short-term trace ability to identify time-varying phenomena.  
 
)
)()1()(
)1()()()1(
)1((
1
)(
NNN
NNNN
NN
T
T
GPG
PGGPP −+
−−−−= λλ  
        (22) P
))1(~)()()(()()1(~)(~ −−+−= NNNDNNNN T AGGPAA              (23) 
 
 8
 10
      
where 
Mikinewi ,...,2,1)()( | == σσ                                (30) 
10 1 <≤ δ   is a pre-given constant. 
 
h the r en used to cover the incoming input variables as 
ufficient as possible, however, some of the generated rules may not well “fired” at current 
 
 
Althoug ule-splitting process has be
s
sample time, i. e., the existing clusters are too far away from current input. Thus, the structure 
redundancy will cause the problem that some rule does not give contribution. In this paper, the 
rule-expanding process is provided to ensure that each rule is well-contributed. In Eq. (25), if 
kβ  is smaller than the pre-defined constant, then the index for the rule-expansion, denoted as 
1)0( =exI
ψ×                              (
k
exI  ( ), will be increased. 
 31) 
k
= kexkex II
The criterion of expanding a new rule is described as follows. 
{ } { }{ } { })1exp()1exp( −+− kexkexex II
)1exp()1exp( −−−=∆
k
ex
k
exk II                            (32)  
If  , where  a pre-given threshold, then the vathkex L≤∆ (−∈thL )0,1 riances of the k-th rule are 
given. 
,...,2,12)( == σ                            (
where
Mikiki )( |×δσ 33) 
.12 >δ  With the sim le concept f ce of the existing rules based 
on judging the rules is whether appropriately “fired” or not, the proposed rule self-construction 
 speech signal example is given to verify the performance of the SCNFS. 8000 sample data are 
0 sample data for the training purpose and the rest for testing. The parameter 
p or determining the importan
has provided an efficient way for optimising the NFS structure.  
 
III. Results 
A
collected, 40
settings for the RO-LSE algorithm are given in the following table.  
 
η  T  γ  ψ  thU  thL  1δ  2δ  
0.05 0.001 0.4 -0.4 1 1.05 0.2 1.2 
 
he inputs to the SCNFS filter are the noise signal T )()(1 tnth =  and the lagged noise 
e noise n(
signal y(t) is 
).1()(2 −= tnth  The noise channel transfer function between th t) and the contaminating 
given as follows. 
])1([1
)1())(sin(
))1(),(()( =−= ntntntnfty
2−+
−
tn
t               (34) 
Based on the priori information of received noisy signal data, the neuro-fuzzy filter attempts to 
identify the relationship of n(t) and y(t) of the nonlinear noise channel. To train the NFS filter, 
