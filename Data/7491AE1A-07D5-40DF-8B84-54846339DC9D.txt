Foreground seeds
 Background seeds
S2
S1
 Goal of boundary S1
Short-cut S2
Fig. 1. Short-cut problem of graph cuts. S1 is the goal of boundary and
S2 is the short-cut path. Although the edge weights of n-links on the goal
of boundary boundary S1 are smaller than those on the short-cut path S2,
however, the boundary S1 is to long cause the cost is bigger than short-cut
S2. Therefore, graph cuts may result in short-cut S2 instead of boundary S1.
surface model, then warp a accurately segmented brain atlas
to the result of the pre-flooded WAT by rigid registration and
deform to the accurate surface in the end. HWA is benefits of
robust by using the pre-flooded WAT and geometric constraints
of deformable surface model but is too conservative and still
containing lots of non-brain.
B. Graph cuts
Graph cuts is a method for separating foreground and
background and is similar to max-flow min-cut theorem. The
difference is that in graph cuts, each vertices has an edge (t-
link) connected to source S, an edge connected to sink T and
an edge (n-link) between neighboring vertices.
When we use graph cuts, the first step is to select foreground
seeds and background seeds. And then we assign edge weights
as capacity. The weight of n-link is according the difference
of gray value or color between neighboring points. The weight
of t-link is according the similarity to foreground seeds and
background seeds. If the intensity of a node is like to fore-
ground seeds than the weight of t-link connected to source S
is big that means this node has more chance be classified as
foreground and vise versa. Finally, according to the weights
of t-link and n-link, we can get a cut to partition foreground
and background by graph cuts algorithm.
Short-cut is a well-known problem in graph cuts and mostly
occur in thin and long region. Short-cut problem means that
the cost of desired boundary is bigger than the short-cut path
that misclassification happened. Figure1 is an example of the
short-cut problem. This problem can be solved by combining
geodesic information and graph cuts algorithm [13].
Based on [12], many applications of graph cuts were
published. Whatever no methods are perfect, therefore, user
interactive tools often come with graph cuts [14] [15] [16]
[17] [18]. Video Snap Cut [19] mentioned that graph cuts
with global statistics can’t handle complexity scene therefore
they segment with localized classifiers. The user will roughly
define the foreground and background on key frame, and get
a initial result. The localized classifiers then surround along
the initial result. Each localized classifiers will combine local
information to get a segmentation. These localized classifiers
will propagate to next frame based on optical flow and update
their local statistic. For refining the result of graph cuts, [17]
also provides a tool to compute local color distribution.
For decreasing the cost of graph cuts algorithm, Multilevel
banded graph cuts (BGC) [20] run full grid graph cuts with
the coarsest image and get an initial object , then refine the
initial object in a coarse-to-fine manner and graph cuts only
operate in a band which between eroded and dilated the object.
In this way, we can decrease memory usage and time cost
but might exclude some thin structures such as blood vessels
showed in the experiment of 3-D heart and pulmonary artery
CT volume. To tackle the problem of BGC, [21] presented
a accurate multilevel BGC by identifying thin structures and
adding to BGC system when fining the lower resolution object.
C. Motivation of this work
In the existing brain extraction methods, some have high
sensitivities whereas some have high specificities. The high
sensitivity stands for extracting large percent of the brain
region, and the high specificity value rejects large percent
of the non-brain region. The pursuits of high sensitivity and
high specificity are generally conflicting. How to comprise
between high sensitivity and high specificity is essential to
accurate brain extraction. HWA method has the advantage of
high sensitivity, but the disadvantage is its low specificity. In
this work, we planned to develop an accurate brain extraction
algorithm by using the brain region estimated by HWA method
as the initial. While maintaining high sensitivity, our algorithm
achieves high specificity by trimming non-brain regions from
the initials with multiresolutional graph cuts.
II. METHOD
A. Flowchart of multiresolutional brain extraction
The proposed brain extraction method is composed of three
major steps, as shown in Figure 2. First, we apply the HWA
method to initialize the brain region as the roughly extracted
brain. In the image of the roughly extracted brain, we remove
non-WM voxels with high intensities by segmenting the WM
tissue with region growing and excluding those voxels brighter
than the segmented WM tissue. This volume is denoted by
V L, where V L represents that this volume is at level L, in
this thesis. The deleted voxels are usually non-brain voxels,
such as fat.
The second step is the multiresolutional graph cuts and the
advantage of multiresolutional framework to this work is that
we can use the result of coarser levels as constraints to finer
levels. We downsample V L image into lower-resolution ones,
and from fine to coarse levels are V L−1, V L−2, . . . , V 0, as
shown in Figure 3. The eight voxels in L− l level (a 2 ∗ 2 ∗ 2
cube) are combined into one voxel in L − (l + 1) level, l =
0, 1, . . . , L−1. We start the multiresolutional graph cuts from
the coarsest level. The shape of brain in this level is much
easier to obtain, because of the brighter voxels not belonging
to brain are blurred. To prevent short-cut problem in graph cut,
Fig. 3. The multilevel image pyramid.
(a)
(b)
(c) (d) (e) (f)
threshold 1
threshold 2
threshold 3
Fig. 4. The four categories by Otsu’s method of the initial brain extraction.
(a) The result of initial brain extraction. (b) The histogram of single slice and
can be classified into four categories by threshold 1, threshold 2 and threshold
3. The horizontal axis is the gray value and the vertical axis is the number of
voxels. (c) The first category is below threshold 1 and composed of voxels
with gray values like CSF and non-head voxels. This image is shown the
nonzero voxels with gray value below threshold 1. (d) The second category is
between threshold 1 and threshold 2 and composed of voxels with gray values
between those of CSF and GM. (e) The third category is between threshold
2 and threshold 3 and composed of voxels with gray values of GM. (f) The
fourth category is greater than threshold 3 and composed of voxels with gray
values of WM.
using Otsu’s method, as shown in Figure 4. The first category
is composed of voxels with gray values like CSF and non-head
voxels. The second category is composed of voxels with gray
valuess between those of CSF and GM. The third category is
majorly composed of voxels with gray values of GM. The
fourth category is majorly composed of voxels with gray
values of WM. When gathering statistics of the distribution of
gray values, we only consider voxels with gray values lower
than T , where T is the gray value higher than 98 percent of
total nonzero voxels (similar to [6]). The reason to exclude
those voxels with particularly high values is that they may
dominate the third threshold of Otsu’s [25] method.
For each slice, we apply the Otsu’s method described above
to determine the three thresholds and the largest threshold is
used to segment WM voxels. We start 3-D region growing to
Fig. 5. The results of segmented white matter tissue in coronal slice. Top
row are the results of the initial brain extraction. Bottom row are the results
of the segmented white matter tissue.
find WM with voxels higher than the threshold between WM
and GM for each slices located between 2/5 and 3/5 middle
transverse slices. These starting points of region growing
locate at the center region of each slices.The center region
at superior and inferior transverse slices may be non-brain
region, therefore we limit start points between 2/5 and 3/5
middle transverse slices. Since the connectivity of 3-D region
growing is higher than that of 2-D region growing, we use a
strict threshold t as the stopping criterion of region growing, to
avoid from growing WM region to brighter non-brain region.
Thus threshold t represents the maximum intensity difference
between 3-D neighboring voxels. To improve the accuracy of
WM segmentation, we perform 2-D region growing starting
from the results of 3-D region growing, and uses the third
threshold of Otsu’s method and T as the stopping criterion.
Figure 5 demonstrates the results of WM segmentation.
To avoid the influence of bright voxels in non-WM region
on the intensity distribution, we remove those voxels with gray
values larger than the average of estimated WM subtracted by
the estimated WM standard deviation. We call this volume
V L, as shown in the bottom row of Figure 6. The reason why
we remove those voxels with high gray values is that those
voxels most likely belong to a non-brain region, such as fat
. These kind of voxels are determined as foregrounds while
doing the graph cuts algorithm. Removal of the brighter voxels
in the non-WM areas can improve the estimation of WM as
well as the brain extraction result.
C. Graph cuts for brain extraction
1) Edge weights in the graph cuts method: The proposed
method construct a graph at each level and apply the graph
cuts algorithm to extract the brain region. In the constructed
graph, neighboring voxels have a connected edge, which is
denoted by n-link. Besides, each voxel has edges, denoted by
t-link, connected to two specific vertices: foreground terminal
S and background terminal T sas shown in Figure 7. There are
two kinds of n-links that need to be assigned with weights, one
Fig. 7. Demonstration of n-link and t-link. Blue lines are the t-link connecting
to background terminal. Green lines are the t-link connecting to foreground
terminal. Orange lines are the intra slice n-link (link in the same slice). Black
lines are the inter slice n-link (link in different slices).
1) Graph cuts at the coarsest level: To get the shape of
brain, we start running graph cut with V 0, which is at the
lowest resolution. At this level, the shape of brain is much
easier to obtain, because of the brighter voxels that are not
belonging to brain were blurred. On the other hand, the
brighter voxels (WM) belonging to the brain area are set as
foreground seeds, which always be classified as foreground.
We use the region growing method, describe in Section 2.1,
to segment the WM tissue in V 0 as foreground seeds, as voxels
overlaid with warm colors in the middle row of Figure 8. On
the other hand, we use the voxels with non-zero gray values
and below the lowest threshold as background seeds, as shown
as voxels overlaid with cool colors in the middle row of Figure
8. After the graph cut of the entire brain was completed, we
get a foreground object, O0, as show in bottom row of Figure
8. Then erode O0 one voxel to get a smaller volume, E0, as
a constraint to the middle resolution level.
Fig. 8. Demonstration of foreground seeds, background seeds and results at
the lowest resolution level. Top row: the volumes are V 0, individually. Middle
row: the warm colors are foreground seeds and cool colors are background
seeds. Bottom row: the extracted brain at the lowest resolution level.
2) Graph cuts at the middle levels: The graph cuts at
middle levels is to refine the extracted brain from the lowest
resolution level. At middle dimension level l, 0 < l < L, to
get a pre-determined foreground area we first upsample the
eroded brain region, El−1, at coarser level l− 1 to level l the
pre-determined foreground area El. The upsampling equation
of the eroded volume is defined as:
E′lx,y,z = E
l−1
x
2 ,
y
2 ,
z
2
, (9)
where E′lx,y,z is the intensity at coordinate (x, y, z) and at level
l. The weights of t-link connecting to foreground terminal in
E′l, as shown in third row of Figure 9, are set to be infinity.
This ensures E′l must be classified as foreground. The pre-
determined foreground area can reduce the short-cut problem
and prevent cut at WM/GM boundary.
Considering local gray value distribution, we partition V l
into 2l×2l×2l cubes (each dimension is divided into smaller
overlapping region, as shown in Figure 10. Then we perform
graph cut for each cube individually. Each cube has 1/4 in
length overlapped with its adjacent cubes, this reduce the
inconsistent border between two cubes. Each cube has its
own foreground and background seeds. We estimate the three
thresholds with each cube by Otsu’s method. If the voxel is
brighter than the third threshold and contains in E′l then it
is be defined as foreground seed, as shown as voxels overlaid
with warm colors in the second row of Figure 9. If the voxel
intensity is nonzero and smaller than the first threshold then
it will be defined as background seed, as shown as voxels
overlaid with cool colors in the second row of Figure 9. The
bottom row of Figure 9 is the extracted brain at this resolution
and we denote this volume as Ol. The eroded Ol is defined
as El. For the overlapped region between neighboring cubes,
we integrate the results by logical OR operation.
3) Graph cuts at the finest level: Graph cuts applied at the
finest level is to get the final extracted brain. At the finest level,
the pre-determined foreground area is the upsampled EL−1,
as shown in the third row of Figure 11. We partition V L into
2L×2L×2L cubes individually and in our method the L = 2.
Then we perform graph cuts algorithm with each cube. The
way of finding foreground seeds and background seeds is the
same as in the middle levels, as shown in the second row of
Figure 11. We also upsampling OL−1 to this level, called O′L,
as shown in top row cool colors of Figure11. The equation of
upsampling OL−1 is defined as:
O′Lx,y,z =
∑1
k=−1O
L−1
x
2 ,
y
2 ,
z
2+k
3
, (10)
where O′Lx,y,z is the intensity at coordinate (x, y, z) and at
level L. Different from middle and the coarsest levels, we add
a distance term: wd×(D(xi)+D(xj)2 ), in Eq. (2.3). The distance
term D(x) is defined as the least-squares distance from x
to contour of O′L. The reason is that, the brighter voxels
belonging to non-brain region are similar to foreground seeds,
so they might be classified as foreground. But in the middle
and the coarsest levels, those brighter voxels are blurred, hence
those voxels can be judged as background seeds. Therefore,
we use the contour of O′L as a factor of the edge weight in
this level because when the n-link is closer to the contour, it
should has more chance to be cut. For the overlapped region
between neighboring cubes, we integrate the results by logical
OR operation.
Fig. 13. (a) The red circle is the dark voxels in brain but be classified
as background, and yellow circle is the voxels deleted in step1of flowchart
but belong to brain region, that both need to be post-processed. (b) We find
contour of the extracted brain from the highest resolution level. (c) Take the
outermost contour. (d) Fill the voxels which are inside the outermost contour
and the dark voxels in brain are filled.
data set.
The first IBSR data set consist of 20 MR images, each
with around 60 coronal slices, matrix size 256 mm × 256
mm, FOV 256 mm × 256 mm, and slice thickness 3.1 mm.
The most images in this data set involve apparent intensity
inhomogeneity and the large region of neck. The large region
of neck may bias the estimation of parameters in the HWA
and BET method. Therefore, the large region of neck were
manually removed before estimation [10].
The second IBSR data set is composed of 18 MR images,
each with around 128 coronal slices, matrix size 256 mm
× 256 mm, FOV 240 mm × 240 mm, and slice thickness
1.5 mm. Each image has brain region determined by manual
segmentation. The IBSR data sets as well as the brain region
images are from the Montreal Neurological Institute and are
available at http://www.cma.mgh.harvard.edu/ibsr.
The VGATPE data set contains 18 MR volumes of healthy
subjects collected by Taipei Veterans General Hospital, each
with around 124 coronal slices, matrix size 256 mm × 256
mm, FOV 260 mm × 260 mm, and slice thickness 1.5 mm.
The ages of these subjects are between 22 and 57 years
old. The brain region images of all subjects are segmented
manually.
BrainWeb phantom images from the Montreal Neurological
Institute are simulated by various levels of noise and intensity
non-uniformity. The noise levels are 0%, 1%, 3%, 5%, 7%,
and 9%. Each noise level contains three levels of intensity
non-uniformity, which are 0%, 20%, and 40%. Each image
with around 217 coronal slices, matrix size 181 mm × 181
mm, FOV 181 mm × 181 mm, and slice thickness 1mm.
B. Evaluation metrics for brain extraction
This work used five coefficients to compare the accuracy of
the brain regions extracted from existing methods.
The Jaccard similarity coefficient (JSC) is to measure the
similarity of ground truth A and the extracted brain B by the
following equation:
JSC(A,B) =
|A ∩B|
|A ∪B| , (11)
where |x| denotes the voxel number of x. The value of JSC
is between 0 and 1 and the larger JSC value means the better
overlap of A and B.
The higher sensitivity Se and higher specificity Sp means
more accurate extraction of brain region. Sensitivity Se is to
measure the ratio of extracted brain region to total brain region:
Se =
TP
TP + FN
. (12)
If more brain voxels are obtained, the Se value will be higher.
Specificity Sp is to measure the ratio of rejected non-brain
region to total non-brain region:
Sp =
TN
TN + FP
. (13)
If more non-brain voxels are rejected the Sp value will be
higher. The true positive rate, TP, is the number of voxels
extracted as brain correctly. The number of voxels incorrectly
extracted as brain is denoted by FP. The true negative rate, TN,
is the number of voxels extracted as non-brain correctly. The
number of voxels incorrectly extracted as non-brain region is
denoted by FN.
Two probabilities of miss rate, pm and pf , were defined in
[8]. The probability of missed detection of the brain voxels is
defined as:
pm =
|A−B|
|A ∪B| . (14)
The probability of miss rejection of the non-brain voxels is
defined as:
pf =
|B −A|
|A ∪B| . (15)
The lower these two miss rates means the better brain extrac-
tion.
BrainWeb provides discrete anatomical model to label tis-
sues and the CSF region provided by BrainWeb contains
ventricle areas as well as peripheral CSF areas, which are gen-
erally considered as non-brain regions. Therefore, we evaluate
the brain extraction algorithms with this data set according
to two criteria. One only considers WM and GM, the other
considers WM, GM, and CSF as the total brain region.
C. Experimental results
Tables I, II, II, III, IV, V, and VI list the performance
evaluation results of BET, BSE, HWA, ISTRIP and the pro-
posed method for different data sets. In addition to the Table
I, in other cases, although HWA has the highest Se, its poor
performance of Sp results in its worse performance of JSC.
Since some of the brain volumes in the first IBSR data set
has apparent intensity inhomogeneity and artifacts, therefore,
not all brain volumes have the satisfied result. As [10], Table I
excludes the extracted brains which the JSC value is below 0.6
TABLE I
PERFORMANCE EVALUATION USING THE FIRST IBSR DATA SET AND EXCLUDING THE FAILURE RESULTS OF EACH BRAIN EXTRACTION METHOD.
Method JSC Se Sp Pm Pf
BET 0.878 (0.017) 0.983 (0.023) 0.987 (0.004) 0.016 (0.022) 0.107 (0.021)
BSE4 0.900 (0.025) 0.954 (0.035) 0.993 (0.003) 0.044 (0.034) 0.055 (0.017)
ISTRIP 0.910 (0.018) 0.986 (0.013) 0.991 (0.005) 0.013 (0.013) 0.077 (0.027)
HWA3 0.752 (0.037) 0.974 (0.068) 0.970 (0.008) 0.022 (0.056) 0.226 (0.026)
Our method5 0.910 (0.021) 0.989 (0.012) 0.991 (0.003) 0.010 (0.011) 0.079 (0.020)
The superscripts in the first column indicate the excluded cases.
TABLE II
PERFORMANCE EVALUATION USING THE FIRST IBSR DATA SET WITHOUT INCLUDING ALL THE FAILURE CASES.
Method JSC Se Sp Pm Pf
BET7 0.881 (0.017) 0.981 (0.026) 0.988 (0.003) 0.017 (0.024) 0.102 (0.021)
BSE7 0.905 (0.025) 0.954 (0.035) 0.994 (0.002) 0.044 (0.034) 0.051 (0.010)
ISTRIP7 0.911 (0.014) 0.988 (0.015) 0.991 (0.004) 0.012 (0.014) 0.077 (0.023)
HWA7 0.762 (0.012) 0.999 (0.001) 0.967 (0.008) 0.001 (0.001) 0.237 (0.014)
Our method7 0.910 (0.021) 0.991 (0.008) 0.991 (0.003) 0.009 (0.007) 0.081 (0.020)
The superscripts in the first column indicate the excluded cases.
TABLE III
PERFORMANCE EVALUATION USING THE SECOND IBSR DATA SET.
Method JSC Se Sp Pm Pf
BET 0.891 (0.052) 0.959 (0.042) 0.989 (0.005) 0.038 (0.038) 0.071 (0.031)
BSE 0.838 (0.083) 0.957 (0.042) 0.973 (0.030) 0.041 (0.041) 0.119 (0.104)
ISTRIP 0.915 (0.018) 0.978 (0.011) 0.990 (0.003) 0.021 (0.011) 0.064 (0.022)
HWA 0.814 (0.040) 0.9997 (0.0003) 0.965 (0.016) 0.0002 (0.0002) 0.186 (0.040)
Our method 0.930 (0.011) 0.981 (0.016) 0.991 (0.005) 0.018 (0.015) 0.052 (0.017)
TABLE IV
PERFORMANCE EVALUATION USING THE VGHTPE DATA SET.
Method JSC Se Sp Pm Pf
BET 0.921 (0.009) 0.971 (0.013) 0.994 (0.001) 0.028 (0.012) 0.051 (0.011)
BSE 0.933 (0.008) 0.958 (0.011) 0.997 (0.001) 0.041 (0.011) 0.026 (0.008)
ISTRIP 0.915 (0.011) 0.984 (0.012) 0.991 (0.002) 0.015 (0.011) 0.07 (0.015)
HWA 0.847 (0.019) 0.998 (0.002) 0.979 (0.003) 0.002 (0.002) 0.151 (0.019)
Our method 0.920 (0.010) 0.982 (0.009) 0.992 (0.002) 0.017 (0.009) 0.063 (0.017)
TABLE V
PERFORMANCE EVALUATION USING THE BRAINWEB PHANTOM DATA SET AND ONLY CONSIDERING ONLY WM AND GM.
Method JSC Se Sp Pm Pf
BET 0.832 (0.010) 0.994 (0.002) 0.945 (0.005) 0.005 (0.001) 0.163 (0.011)
BSE 0.855 (0.041) 0.989 (0.005) 0.954 (0.018) 0.010 (0.004) 0.136 (0.044)
ISTRIP 0.811 (0.005) 0.998 (0.0003) 0.934 (0.002) 0.001 (0.0003) 0.188 (0.005)
HWA 0.696 (0.005) 0.9995 (0.0001) 0.876 (0.003) 0.0003 (9.00947E-05) 0.304 (0.005)
Our method 0.840 (0.025) 0.997 (0.001) 0.946 (0.011) 0.003 (0.001) 0.157 (0.026)
IV. DISCUSSION
The program execution speed of the existing methods for
brain extraction which compared in this work are fast (less
than a minute). The program execution speed of the proposed
method is about 5 minutes for an MR volume. Regarding to
the performance evaluation for brain extraction, our method
outperforms others for the second IBSR data set. Therefore,
the time cost of the proposed method is not expensive. The
compared method in this work, BET, HWA, and ISTRIP
are performed on Genuine Intel CPU 2.93GHz×16 processor
running Linux, BSE and our method are performed on Intel
Core2 Quad XP 2.83GHz processor on Windows system. Most
of the running time of our method spent on the Otsu’s method,
since it was performed frequently. Although the speed of
Fig. 18. An example of the possible disadvantage by using localized graph
cuts.
Fig. 19. An example of the possible disadvantage by using the distance
term in the finest level. (a) The extracted brain at the highest level and the
red windows show the non-brain voxles. (b) The yellow line shows the contour
used in distance term at the highest level, and the positions corresponding to
the red windows in (a) are inconsistent with the brain area. (c) The extracted
brain at middle levels. (a) and (b) are shrunk as the size of (c).
used in distance term is upsampled from the coarser level, the
contour may not be entirely consistent with the border of the
brain at the highest level, as illustrated in Figure 19.
V. CONCLUSION
We have proposed an automatic method based on multireso-
lutional graph cuts technique to segment the head MR images
into brain and non-brain regions.
The contributions of this work are 1) using distance term
at the highest level to constrain the brain contour, 2) using
pre-determined foreground from the coarser level to avoid
excluding the brain voxels, 3) and applying graph cuts al-
gorithm individually for smaller cubes to tackle the intensity
inhomogeneity problem.
We have compared to the existing methods and com-
pared with our method by using four data sets. Regarding
the performance evaluation for brain extraction, our method
outperforms others for the first/second IBSR data set and
BrainWeb phantom data set, and comparably with the BET
and ISTRIP methods for the VGHTPE data sets.
REFERENCES
[1] John Ashburner and Karl J. Friston. Voxel-Based Morphometry-The
Methods. NeuroImage, 11:805-821, 2000.
[2] Catriona D. Good, Ingrid S. Johnsrude, John Ashburner, John Ashburner,
Karl J. Friston, and Richard S. J. Frackowiak. A voxel based morpho-
metric study of ageing in 465 normal adult human brains. NeuroImage,
14:21-36, 2001.
[3] M. Kubicki, M. E. Shenton, D. F. Salisbury, Y. Hirayasu, K. Kasai, R.
Kikinis, F. A. Jolesz, and R. W. McCarley. Voxel-Based Morphometric
Analysis of Gray Matter in First Episode Schizophrenia. NeuroImage,
17:1711-1719, 2002.
[4] Andrew M. McIntosh, Dominic E. Job, T. William J. Moorhead, Lesley
K. Harrison, Karen Forrester, Stephen M. Lawrie, and Eve C. Johnstone.
Voxel-based morphometry of patients with schizophrenia or bipolar
disorder and their unaffected relatives. Biological Psychiatry, 56:544-552,
2004.
[5] Paul M. Thompson, Agatha D. Lee, Rebecca A. Dutton, Jennifer A.
Geaga, Kiralee M. Hayashi, Mark A. Eckert, Ursula Bellugi, Albert M.
Galaburda, Julie R. Korenberg, Debra L. Mills, Arthur W. Toga, and Allan
L. Reiss. Abnormal Cortical Complexity and Thickness Profiles Mapped
in Williams Syndrome. Neuroscience, 25(16):4146-4158, 2005.
[6] Stephen M. Smith. Fast Robust Automated Brain Extraction. Human
Brain Mapping, 17:143-155, 2002.
[7] Horst K. Hahn and Heinz-Otto Peitgen. The Skull Stripping Problem in
MRI Solved by a Single 3D Watershed Transform. MICCAI, 134-143,
2000.
[8] David W. Shattuck, Stephanie R. Sandor-Leahy, Kirt A. Schaper, David
A. Rottenberg, and Richard M. Leahy. Magnetic Resonance Image Tissue
Classification Using a Partial Volume Model. NeuroImage, 13:856-876,
2001.
[9] F. Se´gonne, E. Busa, M. Glessner, D. Salat,A.M. Dale, H.K. Hahn, and
B. Fischl. A hybrid approach to the skull stripping problem in MRI.
NeuroImage, 22:1060-1075, 2004.
[10] Jia-Xiu Liu, Yong-Sheng Chen, Li-Fen Chen. Accurate and robust
extraction of brain regions using a deformable model based on radial
basis functions. Joural of Neuroscience Methods, 183:155-166, 2009.
[11] Thomas H. Cormen, Charles E. Leiserson, Ronald L. Rivest, and Clifford
Stein. Introduction To Algorithms, Second Edition. 2001.
[12] Yuri Y. Boykov and Marie-Pierre Jolly. Interactive Graph Cuts for
Optimal Boundary & Region Segmentation of Objects in N-D Images.
Internation Conference on Computer Vision,vol.I,p.105, 2001.
[13] Brian L. Price, Bryan Morse, Scott Cohen. Geodesic Graph Cut for
Interactive Image Segmentation. Conference on Computer Vision and
Pattern Recognition, 2010.
[14] Yin Li, Jian Sun, Chi-Keung Tang, Heung-Yeung Shum. Lazzy Snap-
ping. ACM, 2004.
[15] Carsten Rother, Vladimir Kolmogorov and Andrew Blake. ”GrabCut”-
Interactive Foreground Extraction using Iterated Graph Cuts. ACM Trans-
actions on Graphics, 23:309-314, 2004.
[16] Jean Stawiaski, Etienne Decencie`re and Franc¸ois Bidault. Interactive
Liver Tumor Segmentation Using. MICCAI, 2008.
[17] Yin Li, Jian Sun, Heung-Yeung Shum. Video Object Cut and Paste.
ACM Transactions on Graphics, 24:595-600, 2005.
[18] J. Reese and W. Barrett. Image Editing with Intelligent Paint. EURO-
GRAPHICS, 2002.
[19] Xue Bai, Jue Wang, David Simons, Guillermo Sapiro. Video SnapCut:
Robust Video Object Cutout Using Localized Classifiers. ACM SIG-
GRAPH, 2009.
[20] Herve Lombaert, Yiyong Sun, Leo Grady, Chenyang Xu. A Multilevel
Banded Graph Cuts Method for Fast Image Segmentation. ICCV, 259-
265, 2005.
[21] Ali Kemal Sinop and Leo Grady. Accurate Banded Graph Cut Segmen-
tation of Thin Structures Using Laplacian Pyramids. 896-903MICCAI,
2006.
[22] Suresh A. Sadananthan, Weili Zheng, Michael W.L. Chee, Vitali
Zagorodnov. Skull stripping using graph cuts. NeuroImage, 49:225-239,
2010.
[23] Yuri Boykov and Vladimir Kolmogorov. An Experimental Comparison
of Min-Cut/Max-Flow Algorithms for Energy Minimization in Vision.
IEEE Transactions on Pattern Analysis and Machine Intelligence, 2004.
[24] David M. Mount and Sunil Arya. ANN: A Library for Approximate
Nearest Neighbor Searching, Internet: www.iceengg.edu/staff.html, Jan
27, 2010 [Sep. 17, 2010].
[25] Ostu N. Threshold selection method from gray-level histograms. IEEE
Trans Syst Man Cybern, 9:62-66, 1979.
 2 
二、與會心得 
第一天的議程包括最重要的 Talairach Lecture。今年大會邀請的是 Rutgers University 的 Gyorgy 
Buzsaki 教授，演講有關腦活動振盪與認知之間的關聯。他提到在海馬迴與前額葉皮質區的大範圍
神經活動整體量測會不斷地改變組合序列，且不同的起始條件會產生不同的序列。此外，深層睡
眠（deep sleep）、淺層睡眠（light sleep）、與快速動眼睡眠（REM sleep）在 arousal（wakefulness）
與 conscious level（awareness）象限分佔不同區塊，如何腦造影技術與計算來評估也是很有趣的主
題。在由  University of Liege 的 Quentin Noirhomme 教授所主持的 workshop “Measuring 
consciousness in disorders of connectivity”中，與會學者提出利用 bispectral index 來計算 conscious 
level，藉由 Granger Causality 來衡量腦部活動之複雜度與有效連結度（effective connectivity），或
利用 Default Mode Network 來評估休息狀態腦部連結等，並有學者利用這些技術進行研究，並提
出報告指出睡眠能增強左右半腦間的同步連結。另外，在 “Multi-subject surface-based analysis of 
fMRI data: challenges, solutions, and limitations” workshop 中，與會學者提到腦溝（sulci）具有很大
的變異性，因此利用腦迴與腦溝的高度或深度所呈現的摺疊模式（folding patterns）來進行腦部結
構對位，具有比較高的計算可信度。也有學者提出可將功能性磁振造影與結構性磁振造影進行對
位的 boundary-based registration 方法，以及可由訓練資料中自動學習影像對位 cost function 的技術
等等，非常豐富、深入、與多元，收穫良多。 
 
三、建議 
本會議每年均包含豐富的教育訓練課程，精彩的 Keynote Speech，以及涵蓋記憶、學習、心
理、精神、語言、情緒、認知、視覺、運動、腦結構、模型等等主題，非常值得國內相關領域研
究人員參與此會議。 
 
四、攜回資料名稱及內容 
攜回會議議程與論文列表，而論文檔案須經由大會網站下載。 
98年度專題研究計畫研究成果彙整表 
計畫主持人：陳永昇 計畫編號：98-2221-E-009-147- 
計畫名稱：腦部結構磁振造影影像量化分析與模板建立 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 1 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 1 1 100%  碩士論文 
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 4 1 100%  
博士生 1 1 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 2 0 100% 
人次 
 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
 
