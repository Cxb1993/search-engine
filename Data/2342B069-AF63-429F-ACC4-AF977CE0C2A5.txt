1 Introduction
In this project, we consider the following multiple objective optimization model:
minimize {z1(x), z2(x), · · · , zp(x)} (1)
subject to x ∈ X(A, b), (2)
where zk(x) =
∑m
i=1 ckixi is the kth crisp linear objective function, cki ∈ R, k ∈ K =
{1, 2, · · · , p}, A = (aij) ∈ Rm×n is an m × n nonnegative matrix with 0 ≤ aij ≤ 1,
b = (b1, b2, · · · , bn) is an n-dimentional vector with 0 ≤ bj ≤ 1, the feasible domain
X(A, b) is {x ∈ Rm|x ◦A = b, xi ∈ [0, 1],∀i = 1, 2, · · · ,m}, and the operation “◦” stands
for the max-t-norm composition (to be defined shortly).
To the author’ best knowledge, Wang [25] was the first paper to explore model (1)-(2)
with the max-min composition in the place of max-t-norm composition and employed
it to model. Wang characterized some properties of efficient points and transformed
the problem as a multi-attribute decision problem. Recently, Leotamonphong, Fang and
Young [15] have studied model (1)-(2) with nonlinear objective functions and the max-
min composition in the constraint. They proposed a genetic procedure to find the Pareto
optimal solutions.
Other applications of model (1)-(2) can be found in the area called “inverse problem”.
Typically, the constraint part of model (1)-(2) is one kind of inverse problems, where
matrix A stands for the relation between symptoms and causes and vector b for symptom
(we refer to [13] for an interesting application in textile industry.) [I need to talk about
the ◦ here.] The matrix A is provided by experts while b is given by an user. Each
variable xi may represent one clause for the problem. Solving for an solution of equation
(3) means to find a combination of clauses to yield the given symptom. In general, we
may associate some measures such as cost, time to completion, etc., to a combination of
clauses. Model (1)-(2) then represents selecting best combinations (achieving least cost,
least time to completion, etc.) among all feasible combinations of clauses which yield the
given symptom.
Unlike the multi-objective optimization version, model (1)-(2) with single objective
function has attracted more study in the literature. Among them, single objective op-
timization with max-min or max-product compositions in the constraint are commonly
2
gorithms (EAs) may be able to handle model (1)-(2) for the EAs have merits such as not
requiring differentiability of the objectives and the constraints. However, in this paper,
we shall employ the two-phase framework to solve the model (1)-(2). We leave for the
future research on the effectiveness of the evolutionary algorithms.
The two-phrase approach was first proposed by Lee and Li [??] to solve for multi-
ple linear programming problems. Technically, two-phase approach could overcome the
shortcomings of the min operator proposed by Zimmerman [??], that is, in some situa-
tions, the solution generated by the min operator may not be efficient and compensatory.
Guu and Wu applied two-phrase approach to solve the fuzzy multiple linear objective
optimization problem. They pointed out some managerial meanings implied by the two-
phrase approach.
Incorporation of Decison maker’s preferences or interative choice during the solution
process are interesting topics as well in solving the multiple-objective optimization prob-
lems. If the decision maker sets the satisficing goals and priority to each objective, MOLP
can be converted into the goal programming problems. There are three of the common
forms of the goal programming usually mentioned by Ignizio and Cavalier [10]. Deciding
the relative deviation of the objective functions from the ideal objective value instead of a
prior preference information, Yu and Leitman [28] presented a compromise programming
method to deal with MOLP. The step method proposed by Benayoun et al. [1] seems to
be known as one of the first interactive techniques for dealing with MOLP. Sakawa [20]
contained a rather comprehensive survey regarding to the interactive methods for MOLP.
Gardiner and Steuer [7] reviewed thirteen prominent procedures of interactive multiple
objective programming which included the ε-constraint method, the satisficing trade-off
method and so forth. Shin and Ravindran [23] provided a survey of interactive methods
for continuous decision problems and claimed that the interactive approach should be
better acceptance in practice because the decision maker is involved in the entire solution
process.
2 Preliminaries
The triangular norm (t-norm for short) is a real function mapping from [0,1]×[0,1] to
[0,1] which satisfies the following conditions:
4
(b) t(x, a) ≤ b if and only if x ≤ aϕb.
Di Nola et al. [3] showed that if with continuous t-norm and the assumption of existence
of solution, the solution set X(A, b) can completely be determined by a unique maximum
solution and a finite number of minimal solutions (see also Czogala et al [4], Higashi and
Klir [5]). It turns out that the maximum solution in solution set can easily be computed
by an analytic formula as in the following operation:
x¯ = A  b = [min
j∈J
(aijϕbj)]i∈I . (4)
Finding all minimal solutions, however, remains a challenge. Markovskii [6] showed
that solving max-product fuzzy relational equations is closely related to the covering
problem, which is an NP-hard problem. Moreover, its minimal solutions correspond to
irredundant coverings. In the same paper, the author pointed out that the relation be-
tween max-min fuzzy relational equation and the covering problem is more complex– it is
no longer possible to establish one-to-one mapping of minimal solutions and the solutions
of some covering problem. Chen and Wang [7] showed that finding all minimal solutions
of max-min fuzzy relational equations is an NP-hard problem. They also proposed an
algorithm to get all minimal solutions based on a solution-base-matrix. Algorithms for
finding all minimal solutions of the max-min fuzzy relational equations can be found in
[?????]. Algorithms for the max-product fuzzy relational equations can be found in [????].
Recently, Guu and Wu [??] proposed an algorithm for finding all minimal solutions of
max Archimedean t-norm fuzzy relational equations. In the literature, we only can find
an algorithm for the general class of max-t-norm fuzzy relational equations.
3 Major steps in Two-phase approach
According to Di Nola et al., we assume the constraint part of model (1)-(2) have l
minimal solutions. Let S = {1, 2, · · · , l} be the index set of minimal solutions and xs
denote the sth minimal solution for s ∈ S. If the set of all minimal solutions is denoted
by X(A, b) = {xs|s ∈ S}, then the solution X(A, b) can be represented by the union of l
6
min(µ1(x), · · · , µp(x)) subjected to x ∈ X(A, b). Since the feasible domain is nonconvex
and is the union of l “branches”, we need to search in what “branch” the best value we
can have for the worst objective. Therefore, for each s = 1, 2, · · · , l, we compute the
following mathematical programming problem.
maximize αs
subject to 1 ≥ µk(x) ≥ αs,∀k ∈ K, (8)
xs ≤ x ≤ x¯,
where xs ∈ X(A, b) is the sth minimal solution, s ∈ S and x¯ is the maximum solution.
In general, the solution yielded by the min operator may not be efficient and compen-
satory. Indeed, this only occurs when there are multiple optimal solutions to problem
(8). In other words, if the optimal solution of problem (8) is unique, then this solution
is efficient.
Step four calls for the involvement of the weighted average operator, the second phase
of the method. This step may yield a different solution to our model (1)-(2) if there are
multiple solutions to problem (8). And the optimal solution here is efficeint (see Guu
and Wu [??]) for each branch of the feasible region. The mathematical programming
problem of phase II is the following.
maximize βs =
p∑
k=1
ωkβ
s
k
subject to 1 ≥ µk(x) ≥ βsk ≥ αs,∀k ∈ K, (9)
xs ≤ x ≤ x¯.
where αs is the optimal value yielded by phase I in sth feasible region and
∑p
k=1 ωk =
1, ωk > 0.
The value βs denotes the optimal value in the sth branch for problem (9). We can
select the best value by
βs
∗
:= max
s∈S
{βs}.
Hence, the s∗th branch can obtain the best value βs
∗
that sum of the weighted objective
function can achieve for all feasible regions. (Be careful, We need to consider maybe
tie occur.) Traditional two-phase approach for solving the MOLPs provide an efficent
8
the average operator to generate an efficient solution for the model (1)-(2). Note that
again since the X(A, b) is the union of l branches, we need to solve for l mathematical
programming problems as follows. For s = 1, 2, · · · , l, compute the following problem:
maximize γs =
1
p
p∑
k=1
γsk
subject to 1 ≥ µk(x) ≥ γsk,∀k ∈ K, (10)
xs ≤ x ≤ x¯.
The value γs stands for the optimal value in the sth branch. We can select the best
value for problem (1)-(2) by
γs
∗
:= max
s∈S
{γs}.
It is well-known that the optimal solution obtained from the s∗th branch is an efficient
solution of problem (1)-(2).
For solving problem (1)-(2), we summarize the preceding discussion to form the pro-
cedures.
Step 1 Compute the maximum solution x¯ by (4).
Step 2 If x¯ ◦ A = b, then X(A, b) 6= ∅. Otherwise, stop the procedure and the problem
has no feasible solution.
Step 3 Find all minimal solutions. [Refer to [13])
Step 4 Compute the ideal and anti-ideal objective value for each objective function by
solving (6). (i.e. compute the possible range [z0k, z
1
k] for all k ∈ K).
Step 5 Obtain the membership function for each objective function by (7).
Step 6 Solve the min operator model (8) for each of all minimal solutions.
Step 7 Employ the phase II to solve the model (9) for each of all minimal solutions and
yield βs
∗
. If the decision maker is happy with this efficient solution, then we are
done. If the decision maker requires more choice, then we need the next step.
Step 8 Apply the average opertor as the model (10) for each of all minimal solutions to
generate the other efficient solution.
10
Step 3. Find all minimal solutions. Employing Loetamonphong and Fang’s procedure
to this example, we have four minimal solutions as follows:
x1 = [ 0.7 0.8 0 0 0 0.8 0 0 ], x2 = [ 0.7 0 0 0 0.9 0.8 0 0 ],
x3 = [ 0.7 0.8 0 0 0 0 0.5 0 ] and x4 = [ 0.7 0 0 0 0.9 0 0.5 0.8 ].
Step 4 Compute the ideal and anti-ideal objective value for all objective functions by
solving (6). They are
Objective value x1 x2 x3 x4 x5 x6 x7 x8
z01= -1.59 0.7 0.8 0 0 0.9 0 0.5 0.8
z11=5.70 0.7 0.8 0.6 0.7 0 0.8 0.5 0
z02=1.10 0.7 0.8 0.6 0 0 0 0.5 0
z12=8.10 0.7 0.8 0 0.7 0.9 0.8 0 0.8
z03= -6.06 0.7 0.8 0.6 0 0.9 0.8 0 0.8
z13=2.64 0.7 0 0 0.7 0.9 0.8 0.5 0
z04= -5.47 0.7 0.8 0.6 0 0.9 0 0.5 0.8
z14=10.94 0.7 0 0 0.7 0.9 0.8 0.5 0
Step 5. Obtain the membership function for each of four objective functions by (7) as
follows:
µ1(x) =
5.70− z1(x)
5.70− (−1.59) =
5.70− z1(x)
7.29
, µ2(x) =
8.10− z2(x)
8.10− 1.10 =
8.10− z2(x)
7.00
,
µ3(x) =
2.64− z3(x)
2.64− (−6.06) =
2.64− z3(x)
8.70
and µ4(x) =
10.94− z4(x)
10.94− (−5.47) =
10.94− z4(x)
16.41
.
Step 6. Solve the min operator model (8) for each of all minimal solutions and generate
the most achievement level αs∗ .
Considering the first minimal solution x1, for example, the min operator method
as model (8) is ready to solve:
maximize α1
subject to 1 ≥ 5.70− z1(x)
7.29
≥ α1,
1 ≥ 8.10− z2(x)
7.00
≥ α1,
12
1 ≥ 10.94− z4(x)
16.41
≥ β14 ≥ 0.5310753,
x1 = 0.7, x2 = 0.8, 0 ≤ x3 ≤ 0.6, 0 ≤ x4 ≤ 0.7,
0 ≤ x5 ≤ 0.9, x6 = 0.8, 0 ≤ x7 ≤ 0.5, 0 ≤ x8 ≤ 0.8.
For each of four minimal solutions in this example, we solve the model (9) and
obtain the following results.
s βs βs1 β
s
2 β
s
3 β
s
4
1 0.5758 0.5325 0.5310 0.7086 0.5310
2 0.5758 0.5325 0.5310 0.7086 0.5310
3 0.8283 0.8114 0.8114 0.8114 0.8789
4 0.7650 0.7693 0.7187 0.7187 0.8533
From these results, we have the best value for sum of the weighted objective function
to phase II model as
βs
∗
= max{β1, β2, β3, β4} = 0.8283 = β3.
The corresponding efficient solution is
[ x1 x2 x3 x4 x5 x6 x7 x8 ] = [ 0.7 0.8 0.48878 0 0.9 0 0.5 0.30353 ].
The objective values are
z1(x) = −0.2151, z2(x) = 2.4196, z3(x) = −4.4188 and z4(x) = −3.4834.
Step 8. Apply the average opertor as the model (10) for each of all minimal solutions
to generate the other efficient solution.
Considering the first minimal solution x1, for example, the average opertor as the
model (10) is ready to solve:
maximize γ1 = 0.25(γ11 + γ
1
2 + γ
1
3 + γ
1
4)
subject to 1 ≥ 5.70− z1(x)
7.29
≥ γ11 ,
1 ≥ 8.10− z2(x)
7.00
≥ γ12 ,
14
References
1. Benayoun, R., J. de Montgolfier, J. Tergny and O. Laritchev. (1971). “Linear pro-
gramming with multiple objective functions:Step method (STEM)”, Mathematical
programming, 1(3), 366-375.
2. Bourke M. M. and D. G. Fisher. (1998). “Solution algorithms for fuzzy relational
equations with max-product composition,” Fuzzy Sets and Systems 94, 61-69.
3. Chen, H. K. and H. W. Chou. (1996). “Solving multiobjective linear programming
problem-a generic approach,” Fuzzy Sets and Systems 82, 35-38.
4. Czogala E., J. Drewniak and W. Pedrycz. (1982). “Fuzzy relation equations on a
finite set”, Fuzzy Sets and Systems 7, 89-101.
5. Di Nola A., S. Sessa, W. Pedrycz and E. Sanchez. (1989). Fuzzy Relational Equa-
tions and Their Applications in Knowledge Engineering, Kluwer Academic Press,
Dordrecht.
6. Fang, S.-C. and G. Li. (1999). “Solving fuzzy relation equations with a linear
objective function,” Fuzzy Sets and Systems 103,107-113.
7. Gardiner, L. R. and Steuer, R. E. (1994). “Unified interactive multiple objective
programming: an open architechture for accommodating new procedures,” Journal
of Operational Research Socialty 45(12), 1456-1466.
8. Guu S.-M. and Y.-K. Wu. (2002). “Minimizing a linear objective function with
fuzzy relation equation constraints,” Fuzzy Optimization and Decision Making 1(4),
347-360.
9. Higashi M. and G. J. Klir.(1984). “Resolution of finite fuzzy relation equations,”
Fuzzy Sets and Systems 13, 65-82.
10. Ignizio, J. P. and Cavalier, T. M. (1994). Linear programming, Prentice-Hall, Sin-
gapore.
11. Lee, E.-S. and R.-L. Li. (1993). “Fuzzy multiple objective programming and com-
promise programming with Pareto optimum,” Fuzzy Sets and Systems 53, 275-288.
16
