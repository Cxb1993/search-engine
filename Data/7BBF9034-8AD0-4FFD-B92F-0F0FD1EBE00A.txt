1摘要
在本計畫中我們探討了無線通訊系統的控制與效能分析。我們的效能指標是封包在發射
台的佇列的平均延遲時間，以及平均發射功率。根據消息理論，這兩個指標具有對立權衡
(trade-off ) 的關係，我們分析的重點即在延遲不超過給定長度的情況下，最低的功率成本。
本研究所用的模型是所謂佇列極限模型 （limiting queueing model），或稱為高流量模型
（heavy traffic model），並以擴散過程（diffusion process）來表示系統狀態(即佇列長度)的
變遷，因而形成一個連續時態隨機過程 （continuous-time stochastic process）的受限最佳化
問題。本文內容簡述如下: 首先，我們簡單地介紹如何假設時間刻度在擴散過程與佇列長度變
化過程的差異性，建立極限佇列的概念。由於佇列長度變化由 input process rate 與 service
rate 所共同決定，而 service rate 又由發射功率所決定，若以發射功率代表控制項，佇列長度
代表成本，則以控制項為參數的成本函數便得以建立。運用函數型大數定理 (functional law
of large number) 與函數型中央極限定理 (functional central limit theorem)，我們得以讓極
限佇列模型收斂到反射式布朗運動模型 (refelected Brownian Motion)，並得到一個以擴散過
程為動態方程式的受限控制模型。我們的目標即在分析此模型最佳解的存在性。由於系統效能
是以長時間的平均而言，我們的分析工具是用所謂 ergodic control 觀點，藉由時間的平均性
建立系統狀態空間與決策空間的機率性，形成所謂 occupation measure。並引用古典隨機理
論的結果，得到讓一個馬可夫控制決策所對應的機率測度 (probability measure)成為原受控
擴散過程的不變機率測度 (invariant probability measure) 的充要條件，根據這個條件，我們
可以藉由解 Fokker-Planck 方程式得到此不變機率測度的密度函數 (density function)，並討
論受限最佳化的可行性 (feasibiilty) 問題。在文獻上已有一些讓受限擴散控制模型有解的充分
條件被提出，我們在文中亦將討論我們的模型如何藉引入 Lagrangian multiplier 的觀念與之
前的方法接軌。
關鍵字:
功率指派、高流量、極限佇列模型、隨機最佳化控制、受控受限擴散程序
i
1 前言
通訊、交通網路，生物資訊、生態系統，甚至財務金融，氣象分析等都是在傳統上被認為極其
複雜的隨機系統。然而， 藉由古典機率理論如大數定理和中央極限定理等，發展出以擴散過
程觀點來近似該隨機動態系統，甚至去加以控制而形成 最佳化問題等，乃是近年來學術圈一
個熱門的主題。拜電腦科技之賜，我們更可發展相關的演算法以 提供數值解答，讓人對該複
雜系統有較深入的認識，進而去加以維護或管理。
2 研究目的
近年來網路和通訊系統的普及讓其使用者的數量大大增加，使得這個系統的運作變得相當
具挑戰性。相關的議題包括系統效能（system performance）、穩定性（stability）、品質
保證 （quality assurance）、繞路（routing）、排程（scheduling）和收費（pricing）等。
系統有效率的運作並產生良好效能的前提是建立在管理者對系統的仔細分析，近而設計適
當的控制策略，讓系統運作在某種最佳的狀態下。事實上以控制的觀點來設計適當的決策
或協定，讓系統的相關效能參數達到某種最佳化，乃當今控制界一個熱門領域。在二00二
年 IEEE transactions on Automatic Control 即發行專刊，探討了網路通訊系通中所遇到諸
如壅塞控制（congestion control）、流量控制（flow control）、連線許可控制（admission
control）、穩定性和收費等問題， 以及如何以控制的角度與方法加以解決。隨著通訊和網路
系統在用戶數和使用頻寬的持續成長，許多源自通訊系統的議題也帶給控制界，特別是隨機
控制領域許多新的研究方向和挑戰。常見的系統效能參數包括：發射功率、頻寬和延遲時間
等等，其中的功率指派（power allocation）和功率控制（power control）問題更成為最近無
線網路通訊界，特別是無線感測網路（wireless sensor network）最重要的問題之一（參考文
獻 [1]）。本研究的目的，即在加入這股研究趨勢，運用傳統控制的理論，為現代複雜的網路
通訊系統的最佳化運作提供理論基礎。
3 文獻探討
在回顧最近幾年的無線通訊研究著作時（參考文獻 [3, 5, 13, 21, 41]），不難發現功率問
題乃是一個通訊系統效能的核心問題之一，例如 Viswanath等人（參考文獻 [43]）討論
在CDMA系統下功率控制與辨識序（signature sequences）選擇如何影響多重使用者接收
端（multiuser receivers）與網路通道容量（network capacity）；Hanly（參考文獻 [23]）
提出結合功率與傳送蜂巢位置選擇的演算法以達到展頻行動網路（spread spectrum mobile
1
其中 Q(j − 1) 代表在 j − 1 時刻佇列內的信息長度，則 Ii 和 Oi 兩程序之各自組成隨機變數
是 i.i.d.（identical and independent distribution），即獨立且具相同之（幾何）分佈，平
均值各為 1/λi 和 1/λo。在(2)中，當原本佇列內無信息時，若無新進信息，則不會有信息離
開，這使得信息離開的程序和到達的程序產生關聯。若欲假設信息到達的相鄰時間和在佇列
內的等待時間為兩個獨立的離散時態隨機過程，我們可以直接假設 {Ii} 和 {Oi} 彼此互相獨
立，並以下式表達 Q(j):
Q(j) = Q(0) +
j∑
i=1
Ii −
j∑
i=1
Oi1{Q((i−1)+Ii>0} . (3)
其中 1x 是所謂指示函數（indicator　function），當事件 x 發生時函數值為1，否則為0，所
以
1{Q(i−1)+Ii>0} = 1− 1{Q(i−1)+Ii=0} ,
並且，我們可以把 Q(j) 改寫成
Q(j) = Q(0) +
j∑
i=1
(Ii − λi)−
j∑
i=1
(Oi − λo) + j(λi − λo) +
j∑
i=1
Oi1{Q((i−1)+Ii=0} . (4)
上式的表示式中已經把隨機現象對 Q(j) 的影響分離出來，即：
Q(j) = Q(0) + j(λi − λo) + ”noise” .
其中的 noise 由隨機效應所造成，包含以下三項：，
j∑
i=1
(Ii − λi)−
j∑
i=1
(Oi − λo) +
j∑
i=1
Oi1{Q((i−1)+Ii=0} . (5)
值得注意的是最後一項所扮演的角色，它是為修正 Ii 和Oi 彼此互相獨立的假設。若原本佇列
內無信息（即 Q(j − 1) = 0）時，若無新進信息（即 Ii =0）則 Q(j) =0，所以若 Oi =1則
方程式(5)之第三項亦會出現一個1以防止 Q(j) < 0 的矛盾發生。 為了讓隨機程序中的一些
極限定理可以適用在(4)式，我們需討論時間刻度的問題，其內容簡單的說就是(單位時間)內
arrival process，departure process，與channel process 的相對變化頻率的問題。departure
process 乃是由 service rate 所決定。由消息理論可知，service rate 又和所施加的功率、通道
頻寬、與通道狀態有關。佇列理論的結果說明了，若是發射功率僅可讓 arrival rate 與 service
rate 相等，則 queue length 將隨時間增加而終至無限大。於是，以高流量模型作通訊發射功
率研究的文獻，主要便是在探討如何再用額外的功率以防止此情況的發生。假設頻寬固定，若
通道為狀態 s 的機率是 pis， s = 1, · · ·S，我們希望根據每個通道狀態 s 找出一種合適的發
射功率，由這個功率所決定的 service rate 能達到某種最佳狀態，比如說，queue length 最
3
其中 γs = ∂r(ps, s)/∂P。 而
1√
n
bntc∑
i=1
Oi1{Q((i−1)+Ii=0} (12)
　 則收斂至
z(t) := max
{
0,−min
t′≤t
[
x(0)−
∫ t′
0
S∑
s=1
γspisus(t
′′)dt′′ +Bi(t′)−Bo(t′)
]}
(13)
綜合以上，即成為所謂的高流量模型
dx(t) = −
s∑
s=1
γspisus(t)dt+ σdB(t) + dz(t) . (14)
其中的 diffusion 參數 σ2 為 Bi(t) 與 Bo(t) 各自 process 的變異數的和。此模型乃是標準的
反射式受控馬可夫程序。反射項 z(t) 的存在可防止 x(t) 變成負的。值得注意的是控制變數
u(t) 僅出現在 drift 項。
5 結果與討論
如前所述，本研究設定在平均 queue length 有上限限制下，尋找合適的功率發射機制，使平
均發射功率最小，所以我們可建立以下模型:
minimizea(t)∈A lim sup
T→∞
1
T
∫ ∞
0
cp(a(t))dt, a. e. (15)
subject to lim sup
T→∞
1
T
∫ ∞
0
cq(x(t))dt ≤ c¯q, a. e. (16)
其中 a(t) 表在時間 t 時的控制函數值，且對任何時刻 t，a(t) ∈ [0 , pˆ]， A 則是所有可行的控
制 (admissible control) 函數 a(t) 的集合。cp(a) 為對應控制值 a 時的功率價格函數。 x(t)
為時間 t 時的 queue length。 cq(x) 為對應 queue length x 時的時間延遲價格函數。由於
channel state 有 S 種狀態，假設第 i 種狀態的出現機率是 pii，則
a(t) =
S∑
i=1
piia
(i)(t) .
接著我們先介紹幾種 admissible control。若在時間 t 時admissible control a(t) 的值只需
由在 t時的 queue length x(t)決定，即 a(t)可寫為 a(x(t))，我們稱此種 admissible control
為 stationary control as。若 stationary control 造成的 x(t) 是 positive recurrent，則此類
stationary control 稱為 stable control ab。若 stable control 的值只有 0 與 pˆ 兩種，則稱此
5
考慮以下門檻型的 power 傳輸策略:
ae(x) =
 0 , x ≤ xTpˆ , x > xT (21)
根據 (19)式，我們可得到該策略所對應的 invariant measure 的 density function 為
fxT (x) =
βe−β(x−xT )
+
1 + βxT
(22)
其中
β =
2pˆ
σ2
S∑
s=1
γspis
: =
2pˆ
σ2
γ¯
所以 ∫ ∞
0
cq(x)fxT (x)dx =
∫ ∞
0
xfxT (x)dx
=
βx2T
2(1 + βxT )
+
1
β
(23)
所以，若我們可以定義以下限制區{
fas|
∫ ∞
0
cq(x)fas(x)dx ≤ c¯q , c¯q ≥
1
β
}
. (24)
或以 occupation measure 的概念，定義
R(c¯q) :=
{
ν(as, x)|
∫ ∞
0
cq(x)ν(das, dx) ≤ c¯q , c¯q ≥ 1
β
}
, (25)
因為 R(c¯q) 為封閉的 convex 集合，且根據 (23) R(c¯q) 非空集合。 故最佳化問題等同於尋找
一個 occupation measure ν ∈ R(c¯q)，能夠使目標函數∫
cp(as(x))ν(das, dx) (26)
最小。現在我們考慮最簡單的情況，即讓 cp(as) = as(x)， cq(x) = x，並假設 cp(·) 是 x
的 non-decreasing, bounded 函數。。在此情況下，根據所謂 one-point compactification 做
convex analysis (參考資料 [11])，我們可以證明最佳解 ae， 與其對應的 occupation measure
ν(ae, x) 與 density function fae 的存在。在文獻上提出讓最佳解存在的其他充分條件還有所
謂的 near-monotone　假設 (參考資料 [10])。 其要求
lim inf
x→∞
cp(x) > inf
ν∈R(c¯q)
∫
c dν
: = J∗(c¯q) ,
inf
a∈Ae
cq(a) > c¯q . (27)
7
其中B = maxx≥0 |b(as(x))|。所以∫ ∞
0
cp(x)fas(x)dx ≥ min
x≥1/√c¯q
{cp(x)}
∫ ∞
1√
c¯q
fas(x)dx
= min
x≥1/√c¯q
{cp(x)}
(
1−
√
c¯q
K
)
.
也就是
lim
c¯q→0
J∗(c¯q) = lim
x→∞
cp(a(x)))
: = c∞p .
綜合以上，我們可以得到
J∗λ
(
c¯q + 0
2
)
≤ 1
2
J∗(c¯q) +
1
2
J∗(0)
=
1
2
J∗(c¯q) +
1
2
c∞p (29)
由 J∗(·) 的 convexity 特性，我們定義 λ 集合Λ(c¯q)如下，
Λ(c¯q) := {λ > 0|J∗(c¯′q) ≥ J∗(c¯q) + λ(c¯q − c¯′q),∀ c¯′q ≥ 0} .
所以，當 λ ∈ Λ(c¯q)
J∗
( c¯q
2
)
)
≥ J∗(c¯q) + λ
( c¯q
2
)
即
2J∗
( c¯q
2
)
)
≥ 2J∗(c¯q) + λc¯q .
根據 (29) 式，我們得到
c¯∞p ≥ J∗(c¯q) + λc¯q
所以， λ, c¯q, a > 0，
lim inf
x→∞
L(x, a, c¯q, λ) + λc¯q ≥ lim inf
x→∞
cp(x)
≥ J∗(c¯q) + λc¯q
= J∗λ(c¯q) + λc¯q
所以，我們證明了 Lagrangian 形式的 cost function 滿足 near-monotone 假設。
9
[7] R. A. Berry and R. G. Gallager, “Communication over fading channels with de-
lay constraints”, IEEE Transactions on Information Theory, vol. 48, no. 5, pp.
1135–1149, 2002.
[8] D. P. Bertsekas, Dynamic Programming: Deterministic and Stochastic Models, Upper
Saddle River, NJ: Prentice-Hall, 1987.
[9] D. K. Borah and B. D. Hart, “Frequency-selective fading channel estimation with
a polynomial time-varying channel model”, IEEE Trans. Commun., vol. 47, pp.
862–873, June, 1999.
[10] V. S. Borkar, Optimal control of diffusion processes, Pitman Research Notes in Math-
ematics Series, vol. 203, Longman Scientific and Technical, Harlow, 1989.
[11] V. S. Borkar, “Controlled diffusions with constraints II”, Journal of Mathematical
Analysis and Application, 176 , no. 2, pp.310–321, 1993.
[12] V. S. Borkar and M. K. Ghosh, “Controlled diffusions with constraints”, Journal
of Mathematical Analysis and Application, vol. 52, no. 1, pp.88–108, 1990.
[13] S. Borst,“User-level performance of channel-aware scheduling algorithms in wireless
data networks”, Proceedings IEEE INFOCOM, pp. 321–331, 2003.
[14] R. Buche and H. J. Kushner,“Control of mobile communications with time-varying
channels in heavy traffic”, IEEE Transactons on Automatic Control, vol. 47 , no. 6,
992–1003, 2002.
[15] Thomas M. Cover and Joy A. Thomas, Elements of information theory, Wiley Series
in Telecommunications, John Wiley & Sons Inc., New York, 1991.
[16] V. I. Bogachev, N. V. Krylov, and M. Ro¨ckner, “On regularity of transition prob-
abilities and invariant measures of singular diffusions under minimal conditions”,
Comm. Partial Diff. Equat., vol. 26, no. 11-12, pp. 2037–2080, 2001.
[17] A. Das and R. Srikant, “Diffusion approximations for models of congestion control
in high speed networks”, presented, Proc. of 38th Conf. Decision Control, New York,
1998.
11
[30] H. J. Kushner, D. Jarvis, and J. Yang, “Controlled and optimally controlled multi-
plexing systems: A numerical exploration”, Queueing Syst., vol. 20, pp. 255–291,
1995.
[31] H. J. Kushner and J. Yang, “An effective numerical method for controlling routing
in large trunk line networks”, Math. Comput. Sim., vol. 38, pp. 225–239, 1995.
[32] H. J. Kushner and G. Yin, Stochastic Approximation Algorithms and Applications,
New York: Springer-Verlag, 1997.
[33] D. G. Luenberger, Optimization by vector space methods, John Wiley and Sons Inc.,
New York, 1967.
[34] A. Mandlebaum and G. Pats,“State-dependent stochastic networks. Part I: Approx-
imations and applications with continuous diffusion limits”, Ann. Appl. Probab., vol.
8, pp. 569–646, 1998.
[35] M. Médard,“The effect upon channel capacity in wireless communications of perfect
and imperfect knowledge of the channel”, IEEE Trans. Inform. Theory, vol. 46, pp.
933–946, May, 2000.
[36] M. L. Moher and J. H. Lodge, “TCMP—A modulation and coding strategy for
Rician fading channels”, IEEE J. Select. Areas Commun., vol. 7, pp. 1347–1355,
Dec. 1989.
[37] M. L. Puterman, Markov decision processes: discrete stochastic dynamic program-
ming, Wiley series in probability and mathematical statistics, John Wiley & Sons,
New York, 1994.
[38] M. I. Reiman and L. M.Wein, “Dynamic scheduling of a two class queue with
setups”, Oper. Res., vol. 46, pp. 532–547, 1998.
[39] M. I. Reiman and R. J. Williams,“A boundary property of semimartingale reflecting
Brownian motions”, Prob. Theory Rel. Fields, vol. 77, pp.87–97, 1988.
[40] H. L. Royden, Real analysis, third ed., Macmillan, New York, 1988.
13
2009美國控制會議 (ACC) 
 差旅報告內容 
 
 
行前: 
由於會議時間正值美國暑假，國際機位一票難求，雖早於2/17/2009 預定，仍訂
不到6/10/2009 會議開幕日前到達的機位，但至少訂到趕上6/12/2009 論文發表
的機位。 
 
經過: 
本人被安排於6/12/2009 下午4:40-5:00 發表論文，題目是”On the Adaptive 
Control of a Class of Partially Observed Markov Decision Processes” (部分可觀之馬
可夫決策過程之適應性控制)，此題目為馬可夫決策過程研究之新方向。我們找
到確保隨機適應性控制策略達到最佳化的一些充分條件，因而引起會議現場學者
的興趣，包含來自 UIUC，UCLA，和 Texas A&M 的學者都提出了一些問題，
本人則依序予以答覆，並有良好互動。會議結束後有機會繼續和數位學者交談，
並討論學術圈相關領域的研究概況，特別是國際頂尖學術機構目前的基礎研究與
應用方向。 
 
心得: 
本會議與IEEE conference on decision and control (IEEE CDC)同屬國際控制工程
與學術界重要之會議，每年吸引上千人參與，發表論文之質與量均具一定水準，
可惜國內參與之人數與發表之論文有下降趨勢，一方面可能因近來控制在電機領
域不如通訊或IC設計/SOC 等吸引較多目光，再則此會議固定在美國舉辦，行程
遙遠且暑假機位預訂不易，使國內有意願投稿者寧選擇其他如在中、日、韓舉行
之會議，若此情形持續下去，對國內控制領域在國際能見度方面恐有負面影響。
畢竟，雖然亞裔學者近年來在控制領域的學術研究上有很大進步，然足以擔任最
重要期刊的編審委員者仍為少數，若扣除美籍亞裔者，人數就更少了。本會議提
供一個展現國內學術水準的平台，本人將樂見有更多國內學者投稿並參與這個控
制領域的重要會議。 
 
 
攜回 
2009CDC 大會手冊與會議光碟。 
 
 
表 Y04 
行政院國家科學委員會補助國內專家學者出席國際學術會議報告 
                                                             98年 6 月 23 日 
報告人姓名 許舜斌 
 
服務機構
及職稱 
國立中興大學電機系助理教授 
 
 
時間 
地點 
6/10-6/12, 2009 
St. Louis, MO, USA 
本會核定
補助文號
97-2221-E-005-062- 
會議 
名稱 
 (中文) 2009美國控制會議 
 (英文) American Control Conference 2009 
發表 
論文 
題目 
 (中文) 部分可觀之馬可夫決策過程之適應性控制 
 (英文) On the Adaptive Control of a Class of Partially Observed Markov 
Decision Processes 
報告內容 
行前: 
     由於會議時間正值美國暑假，國際機位一票難求，雖早於 2/17/2009 預定，仍訂不
到 6/10/2009 會議開幕日前到達的機位，但至少訂到趕上 6/12/2009論文發表的機位。
經過: 
    本人被安排於 6/12/2009 下午 4:40-5:00發表論文，題目是”On the Adaptive Control of 
a Class of Partially Observed Markov Decision Processes” (部分可觀之馬可夫決策過程之
適應性控制)，此題目為馬可夫決策過程研究之新方向。我們找到確保隨機適應性控制策
略達到最佳化的一些充分條件，因而引起會議現場學者的興趣，包含來自 UIUC， 
UCLA，和 Texas A&M 的學者都提出了一些問題，本人則依序予以答覆，並有良好互
動。會議結束後有機會繼續和數位學者交談，並討論學術圈相關領域的研究概況，特別
是國際頂尖學術機構目前的基礎研究與應用方向。 
心得: 
     本會議與 IEEE conference on decision and control (IEEE CDC)同屬國際控制工程與
學術界重要之會議，每年吸引上千人參與，發表論文之質與量均具一定水準，可惜國內
參與之人數與發表之論文有下降趨勢，一方面可能因近來控制在電機領域不如通訊或 IC
設計/SOC等吸引較多目光，再則此會議固定在美國舉辦，行程遙遠且暑假機位預訂不
易，使國內有意願投稿者寧選擇其他如在中、日、韓舉行之會議，若此情形持續下去，
對國內控制領域在國際能見度方面恐有負面影響。畢竟，雖然亞裔學者近年來在控制領
域的學術研究上有很大進步，然足以擔任最重要期刊的編審委員者仍為少數，若扣除美
籍亞裔者，人數就更少了。本會議提供一個展現國內學術水準的平台，本人將樂見有更
多國內學者投稿並參與這個控制領域的重要會議。 
參訪 (6/13-6/15) 
   Washington University at St. Louis, University of Missouri at Columbia, University of 
Missouri at St. Louis, The Gateway Arch at St. Louis 
攜回 
   2009CDC 大會手冊與會議光碟。 
 
 
附件三
 
for each ψt ∈ Ψ , Ut ∈ U, and t ∈ N0, where 1{·} is the
indicator function and 1 is a column vector of 1’s with size
Nx. Write V (ψ, y, u) = ψ · Q(y, u) · 1 as the conditional
probability and
T (ψ, y, u) :=
ψ ·Q(y, u)
V (ψ, y, u)
for V (ψ, y, u) 6= 0 ,
as the posteriori conditional distribution, then the transition
kernel for the information state is given by
K(B|ψ, u) : = Prob{ψt+1 ∈ B|ψt = ψ,Ut = u}, (1)
=
∑
Yt+1∈Y
V (ψ, Yt+1, u) · 1{T (ψ,Yt+1,u)∈B}
for each B ∈ B(Ψ), ψ ∈ Ψ , and u ∈ U. So we have the
transformed five-tuple (Ψ ,U, U˜ , K, c˜) where U˜ : Ψ → B(U)
and c˜(ψ, u) :=
∑
x∈X c(x, u)ψ(x) for all ψ ∈ Ψ and u ∈ U.
For the original history space Hi of the partially observed
process up to time i where H0 := Ψ , Ht := Ht−1 × U ×
Y for all t ∈ N (the set of positive integers), we obtain a
corresponding completely observed history space: Hˆ0 := Ψ ,
Hˆt := Hˆt−1 × U× Ψ for all t ∈ N.
An admissible strategy or admissible policy pi is a se-
quence {pit}∞t=0 of Borel measurable stochastic kernels pit
on U given Hˆt satisfying pit(U˜(ψt)|ht) = 1 for all ψt ∈ Ψ ,
ht ∈ Hˆt, and t ∈ N0. An admissible policy is called
deterministic if there exists a function f : Ψ → U such
that pit(f(ψt)|ht) = 1 for all ψt ∈ Ψ , ht ∈ Hˆt and t ∈ N0.
It is shown in [7] that for an initial distribution ψ0 ∈ Ψ
and admissible strategy pi, there exists an unique probability
measure Ppiψ0 induced on the sample path (Ψ×U)∞. We use
Epiψ0 to represent the corresponding expectation operator.
B. Ergodic Control
The objective of ergodic control is to decide the optimal
strategy pi ∈ Π (the set of all admissible strategies) to
minimize the incurred long-run average cost:
J(ψ0, pi) := lim sup
T→∞
1
T
Epiψ0
[
T−1∑
t=0
c˜(ψt, Ut)
]
. (2)
The classical vanishing discount limit method approaches
this problem by extending the result from the β-discounted
cost model:
Jβ(ψ0, pi) := lim sup
T→∞
Epiψ0
[
T−1∑
t=0
βtc˜(ψt, Ut)
]
. (3)
where β is in (0,1). If piβ is the minimizing policy in the
following sense and results in a value function hβ(ψ) where
hβ(ψ) = Jβ(ψ, piβ) = inf
pi∈Π
Jβ(ψ, pi) , ψ ∈ Ψ , (4)
then the following assumption and its implication are well
known.
Assumption 2.1: c : X × U → R+ is the one-stage cost
function that is nonnegative, bounded and continuous. Also,
U → Q(y, U) is continuous for each y ∈ Y.
Lemma 2.1: [17, Chapter 2] Suppose Assumption 2.1
holds. The value function hβ(ψ) in (4) corresponding to
the β-discounted cost model in (3) can be characterized by
Bellman’s β-discounted optimality equation:
hβ(ψ) = min
u∈U
{
c˜(ψ, u) + β
∫
Y
hβ(ψ′)K(dψ′|ψ, u)
}
(5)
for all ψ ∈ Ψ where K is defined in (1). Any admissible
policy resulting in the value function hβ(·) is β-discounted
optimal.
It is well known that hβ(ψ) is the unique solution in
C(Ψ) (the space of continuous functions on Ψ ) for Bellman’s
β-discounted optimality equation. Also, it can be shown
(see [22]) that hβ(·) is concave. Suppose β0 is in (0,1) and
{βn}∞n=1 ⊂ [β0, 1) is a sequence with βn → 1. ψ∗ :=
arg minψ∈Ψ hβ(ψ), and hβ(ψ) := hβ(ψ)− hβ(ψ∗). A well-
known major condition (see [15]) that implies the existence
of the long-run average optimal policy characterized by
Bellman’s ergodic optimality equation follows.
Assumption 2.2: {hβn(·)}∞n=1 is uniformly bounded on
Ψ .
Theorem 2.2: Suppose Assumption 2.1 and Assump-
tion 2.2 hold. Then there exist a constant ρ, which is the
optimal ergodic cost, and a bounded, concave and continuous
function h: Ψ → R, such that (ρ, h(·)) is a solution of the
following dynamic programming equation:
ρ+ h(ψ) = min
u∈U
{
c˜(ψ, u) +
∫
Y
h(ψ′)K(dψ′|ψ, u)
}
. (6)
Also, the following is equivalent.
1) pi∗ is an optimal optimal.
2) pi∗(ψ) assigns a minimizer u for {·} in (6) for each
ψ ∈ Ψ .
3)
lim
t→∞
1
T
T−1∑
t=0
Epi
∗
ψ0{D(ψt, pi∗(ψt))} = 0
where the discrepancy function D : Ψ × U → R is
defined by
D(ψ, u) := c˜(ψ, u)+
∫
Y
h(ψ′)K(dψ′|ψ, u)−ρ−h(ψ) .
Proof: The results follow from [15], and [18, Propo-
sition 5.5.5].
C. Adaptive Control
When the transition matrix Q is parameterized by a
unknown vector θ ∈ Θ, where Θ ⊆ RNθ is a compact
space, an stochastic approximation-type estimation algorithm
can be designed to form a sequence {θˆt}∞t=0 such that
θˆt → θ w.p. 1 as t → ∞. For simplicity we denote the pa-
rameterized transition matrix Qˆ(yt, ut−1) = Q(yt, ut−1, θˆt)
and sometimes Q(yt, ut−1) = Q(yt, ut−1, θ). Suppose for
each parameter θ ∈ Θ, there exists an associated optimal
deterministic policy written as pi∗(·, θ). Define the adaptive
policy pia that generates a sequence of actions {ut}∞t=0 where
ut = pi∗(ψˆt, θˆt) and
ψˆt+1 :=
∑
y∈Y
ψˆtQˆ(y, ut)
ψˆtQˆ(y, ut)1
· 1{Yt+1=y}, (7)
5636
ml + 1 ≤ t ≤ ml+1. That is, θˆt is updated only at time
t = ml + 1, l ∈ N0. The assumption on the properties of the
sequence {θˆt}∞t=0 is made in the following.
Assumption 3.3: The parameter space Θ is compact and
the transition matrix Q(y, u, ·) is continuously differentiable
on Θ for every y ∈ Y and u ∈ U.
Assumption 3.4: The sequence {θˆt}∞t=0 of estimates of θ
satisfies
1) θˆt is σ(Y0, · · · , Yt)−measurable.
2) θˆt → θ as t→∞ in Ppiaψ0
3) There exists a constant M such that
‖θˆml+1+1 − θˆml+1‖1 ≤
M
l + 1
for every l ∈ N0.
We are thus ready for the following theorem.
Theorem 3.7: Suppose Assumption 2.1, 3.2, 3.3 and 3.4
are satisfied, then for each ψ0 ∈ Ψ
Epi
a
ψ0
[
‖ψt − ψˆt‖1
]
−→ 0 as t→∞ .
Proof: Let {ml}nl=0 be the sequence used in (9) and
define the following: By
t
0 = I is the identity matrix with
size Nx × Nx. For 1 ≤ i ≤ n the multi-step transition
matrix: By
t
i := Q(Ymi−1+1, Umi−1) · · ·Q(Ymi , Umi−1). For
i = n+ 1 By
t
i := Q(Ymi−1+1, Umi−1) · · ·Q(Yt, Ut−1). Bˆy
t
i
is similarly defined with Q(Y,U) replaced by Qˆ(Y,U) for
i = 1, · · ·n + 1 and Bˆyt0 = I . For l = 1, · · ·n + 1, new
information states are denoted by
ψˆl :=
ψ0Bˆ
yt
0 · · · Bˆy
t
l−1
ψ0Bˆ
yt
0 · · · Bˆy
t
l−11
,
ˆˆ
ψl :=
ψˆlBˆ
yt
l
ψˆlBˆ
yt
l 1
, ψˆl :=
ψˆlB
yt
l
ψˆlB
yt
l 1
.
Then, by triangular inequality we have with probability 1∥∥∥ψt − ψˆt∥∥∥
1
≤
n+1∑
l=1
∥∥∥∥∥ ψ0Bˆ
yt
0 · · · Bˆy
t
l−1B
yt
l · · ·By
t
n+1
ψ0Bˆ
yt
0 · · · Bˆy
t
l−1B
yt
l · · ·By
t
n+11
− ψ0Bˆ
yt
1 · · · Bˆy
t
l B
yt
l+1 · · ·By
t
n+1
ψ0Bˆ
yt
1 · · · Bˆy
t
l B
yt
l+1 · · ·By
t
n+11
∥∥∥∥∥
1
=
n∑
l=1
∥∥∥∥∥∥ ψˆlB
yt
l+1 · · ·By
t
n+1
ψˆlB
yt
l+1 · · ·By
t
n+11
−
ˆˆ
ψlB
yt
l+1 · · ·By
t
n+1
ˆˆ
ψlB
yt
l+1 · · ·By
t
n+11
∥∥∥∥∥∥
1
+
∥∥∥ψˆn+1 − ˆˆψn+1∥∥∥
1
. (10)
If Assumption 3.2 is satisfied, then by Lemma 3.4 and
Lemma 3.6-(2) we have
(10) ≤ 2
εNb

n−1∑
l=1
∥∥∥∥∥∥ ψˆlB
yt
l+1 · · ·By
t
n
ψˆlB
yt
l+1 · · ·By
t
n 1
−
ˆˆ
ψlB
yt
l+1 · · ·By
t
n
ˆˆ
ψlB
yt
l+1 · · ·By
t
n 1
∥∥∥∥∥∥
1
+
n+1∑
l=n
∥∥∥ψˆl − ˆˆψl∥∥∥
1
}
≤ 2
εNb
{
n−1∑
l=1
Nx
ε
(1− ε2)n−1−l
∥∥∥ψˆl − ˆˆψl∥∥∥
1
+
n+1∑
l=n
∥∥∥ψˆl − ˆˆψl∥∥∥
1
}
=
2Nx
εNb+1(1− ε2)
{
n−1∑
l=1
(1− ε2)n−l
∥∥∥ψˆl − ˆˆψl∥∥∥
1
+
n+1∑
l=n
∥∥∥ψˆl − ˆˆψl∥∥∥
1
}
=
2Nx
εNb+1(1− ε2)
{
n∑
l=1
(1− ε2)n−l
∥∥∥ψˆl − ˆˆψl∥∥∥
1
+
∥∥∥ψˆn+1 − ˆˆψn+1∥∥∥
1
}
.
(11)
Due to the continuous differentiability of Q(y, u, ·) on Θ
for each y ∈ Y and u ∈ U, also, for k = ml + 1, · · · ,ml+1
θˆk = θˆml+1, we apply the mean value theorem and write
that there exists a finite positive constant M such that
‖ψˆl − ˆˆψl‖1 ≤M
ml∑
k=ml−1+1
∥∥∥θˆk − θ∥∥∥
1
≤MNb
∥∥∥θˆml−1+1 − θ∥∥∥
1
for l = 1, · · · , n. With the same reason
∥∥∥ψˆn+1 − ˆˆψn+1∥∥∥
1
≤M
t∑
k=mn+1
∥∥∥θˆk − θ∥∥∥
1
≤MNb
∥∥∥θˆml−1+1 − θ∥∥∥
1
.
Therefore, following (11) there exist positive and finite
numbers M1, M2 and α ∈ (0, 1) such that∥∥∥ψt − ψˆt∥∥∥
1
≤M1
n∑
l=1
αn−l
∥∥∥θˆml−1+1 − θ∥∥∥
1
+M2
∥∥∥θˆmn+1 − θ∥∥∥
1
= M1
n−1∑
l=0
αn−1−l
∥∥∥θˆml+1 − θ∥∥∥
1
+M2
∥∥∥θˆmn+1 − θ∥∥∥
1
.
(12)
Applying the triangular inequality again we obtain∥∥∥θˆml+1 − θ∥∥∥
1
≤
∥∥∥θˆmn+1 − θ∥∥∥
1
+
∥∥∥θˆmn−1+1 − θˆmn+1∥∥∥
1
+ · · ·+
∥∥∥θˆml+1 − θˆml+1+1∥∥∥
1
=
∥∥∥θˆmn+1 − θ∥∥∥
1
+
n−1∑
i=l
∥∥∥θˆmi+1+1 − θˆmi+1∥∥∥
1
≤
∥∥∥θˆmn+1 − θ∥∥∥
1
+
n−1∑
i=l
M
i+ 1
, (13)
5638
where ψˆ0 = [ψˆ01, ψˆ02, · · · , ψˆ0Nx ] with sth component
ψ2sB
n
s.1
ψ1Bn1
, so
∥∥∥ψˆ2 − ψˆ0∥∥∥
1
=
Nx∑
s=1
∣∣∣∣ψ2sBns.1ψ2Bn1 − ψ2sB
n
s.1
ψ1Bn1
∣∣∣∣
=
Nx∑
s=1
∣∣∣∣ (ψ1 − ψ2)Bn1ψ2sBns.1ψ1Bn1ψ2Bn1
∣∣∣∣
=
∣∣∣∣ (ψ1 − ψ2)Bn1ψ1Bn1
∣∣∣∣ ≤ Nx∑
s=1
∣∣∣∣ψ1sBns.1ψ1Bn1 − ψ2sB
n
s.1
ψ1Bn1
∣∣∣∣
=
∥∥∥ψˆ1 − ψˆ0∥∥∥
1
.
That is,∥∥∥ψˆ1 − ψˆ2∥∥∥
1
≤ 2
Nx∑
s=1
∣∣∣∣ (ψ1s − ψ2s)Bns.1ψ1Bn1
∣∣∣∣
≤ 2
Nx∑
s=1
|ψ1s − ψ2s| ·max
s
{
Bns.1
ψ1Bn1
}
.
Since τ1(B) ≤ 1 for a stochastic matrix B, if given
(Bk)i1.1 ≥ ε · (Bk)i2.1, then from Lemma 3.4∥∥∥ψˆ1 − ψˆ2∥∥∥
1
≤ 2
εn
‖ψ1 − ψ2‖1
and part (1) is proved. If (Bk)i1j ≥ ε · (Bk)i2j , then from
Lemma 3.5
τ1(Bˆn) =
1
2
max
i1,i2
Nx∑
j=1
∣∣∣Bˆni1j − Bˆni2j∣∣∣
=
1
2
max
i1,i2
Nx∑
j=1
∣∣∣∣ Bni1jBni1·1 − B
n
i2j
Bni2·1
∣∣∣∣
≤ Nx
2
(1− ε2)n−1
and by Corollary 3.3∥∥∥ψˆ1 − ψˆ2∥∥∥
1
≤ 2
ε
‖ψ1 − ψ2‖1 ,
therefore part (2) is proved.
REFERENCES
[1] A. Arapostathis, S. I. Marcus. Analysis of an identification algorithm
arising in the adaptive estimation of Markov chains. Mathematics of
Control, Signal and System, 3:1–29, 1990.
[2] A. Arapostathis, V. Borkar, E. Ferna´ndez-Gaucherand, M. K. Ghosh,
and S. I. Marcus. Discrete-time controlled Markov processes with
average cost criterion: a survey. SIAM Journal on Control & Opti-
mization, 31:282–344, 1993.
[3] R. Atar and O. Zeitouni. Exponential stability for nonlinear filtering.
Probabilites et Statistiques, 33:697–725, 1997.
[4] R. Bellman. Dynamic Programming. Princeton University Press, 1957.
[5] G. Birkhoff. Extensions of jentzsch’s theorem. Transactions of the
American Mathematical Society, 85:219–227, 1957.
[6] D. P. Bertsekas. Dynamic programming and stochastic control.
Academic Press, 1976.
[7] D. P. Bertsekas and S. E. Shreve. Stochastic optimal control: the
discrete time case. Academic Press, 1978.
[8] V. S. Borkar. Ergodic control of partially observed Markov chains.
System & Control Letters, 99:185–189, 1998.
[9] D.-M. Chuang and A. Arapostathis. Some new results on the ergodic
control of partially observed Markov chains. Proceedings of the 38th
IEEE conference on decision and control, 1908–1909, 1999.
[10] D.-M. Chuang. Risk-sensitive control of discrete-time partially ob-
served Markov decision processes. Ph.D Dissertation, The University
of Texas at Austin, 1999.
[11] T. E. Duncan, B. Pasik-Duncan, and L. Stettner. Adaptive control of a
partially observed discrete time Markov process. Applied Mathematics
and Optimization, 37:269–293, 1998.
[12] E. Ferna´ndez-Gaucherand, A. Arapostathis, and S. I. Marcus. On the
adaptive control of partially observable Markov decision processes.
Proceedings of the 27th IEEE Conference Decision and Control, 1204–
1210, 1988.
[13] E. Ferna´ndez-Gaucherand. Controlled Markov processes on the infinite
planning horizon: optimal & adaptive control. Ph.D Disertation, The
University of Texas at Austin, 1991.
[14] E. Ferna´ndez-Gaucherand, A. Arapostathis, and S. I. Marcus. A
methodology for the adaptive control of Markov chains under partial
state information. Proceedings of the 31th IEEE Conference Decision
and Control, 2750–2752, 1992.
[15] E. Ferna´ndez-Gaucherand, A. Arapostathis, and S. I. Marcus. Convex
stochastic control problems. Proceedings of the 31th IEEE Conference
Decision and Control, 2179–2180, 1992.
[16] E. Ferna´ndez-Gaucherand, A. Arapostathis, and S. I. Marcus. Analysis
of an adaptive control scheme for a partially observed controlled
Markov chain. IEEE transactions on Automatic Control, 38:987–993,
1993.
[17] O. Herna´ndez-Lerma. Adaptive Markov control processes. Springer
Verlag, 1989.
[18] O. Herna´ndez-Lerma, J. B. Lasserre. Discrete-Time Markov control
processes. Springer Verlag, 1996.
[19] S.-P. Hsu, D.-M. Chuang and A. Arapostathis. On the existence of
stationary optimal policies for partially observed MDPs under the
long-run average cost criterion. Systems and Control Letters, 55:165–
173, 2006.
[20] P. R. Kumar and P. Varaiya. Stochastic Systems: estimation, identifi-
cation and adaptive control. Prentice-Hall, 1986.
[21] H. J. Kushner and C. G. Yin. Stochastic approximation algorithm and
applications. Springer-Verlag, New York, 1997.
[22] L. K. Platzman. Optimal infinite-horizon undiscounted control of
finite probabilistic systems. SIAM Journal on Control & Optimization,
18:362–380, 1980.
[23] W. J. Runggaldier and L. Stettner. Approximations of discrete time par-
tially observed control problems. Applied Mathematics Monographs,
6, 1994, Giardini Editori E Stampatori in Pisa, Italy.
[24] E. Seneta. Non-negative matrices and Markov chains. Springer Veralg,
1981.
5640
