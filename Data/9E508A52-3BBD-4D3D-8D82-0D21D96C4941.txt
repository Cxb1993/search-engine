 - 2 - 
摘要 
本研究提出最小風險神經網路(Minimum Risk Neural Networks, MRNN)，它
以倒傳遞神經網路(BPN)為基礎，加入結構風險最小原理的分類間隔最大化的觀
念，其目的為了提高 BPN 分類模型的普遍性，克服過度學習，以提高對驗證範
例的準確度。為了證明此網路的性能，本研究以 15 個實際應用的分類問題來做
測試，並與倒傳遞網路做比較。結果證明最小風險神經網路的模型準確度優於倒
傳遞網路。本文並比較 MRNN 與支援向量機的關係，為兩者建立一個統一的理
論架構，並證明權值衰減技術是 MRNN 的簡化，為此技術找到較嚴謹的理論基
礎。 
 
關鍵字：倒傳遞網路、結構風險最小原理、支援向量機、權值衰減。 
 
Abstract 
To enhance the generalization of neural network model, we proposed a novel 
neural network, Minimum Risk Neural Networks (MRNN), whose principle is the 
combination of minimizing the sum of squares of error and maximizing the 
classification margin, based on the principle of structural risk minimization. Therefore, 
the objective function of MRNN is the combination of the sum of squared error and 
the sum of squares of the slopes of the classification function. Besides, we derived a 
more sophisticated formula similar to the traditional weight decay technique from the 
MRNN, establishing a more rigorous theoretical basis for the technique. This study 
employed 15 real application examples to test the MRNN. The results led to the 
following conclusions. (1) As long as the penalty coefficient was in the appropriate 
range, MRNN performed better than pure MLP. (2) MRNN may perform better in 
difficult classification problems than MLP using weight decay technique.  
 
Key words: back propagation network, structural risk minimization, SVM, weight 
decay. 
 
壹、 前言 
倒傳遞神經網路(back-propagation neural networks, BPN)藉由學習規則來修
 - 4 - 
(4)式蘊藏「權值的修正量與權值大小反向」的概念，即當權值為正值時，
連結權值修正量會含一個與權值大小成比例的負項；當權值為負值時，連結權值
修正量會含一個與權值大小成比例的正項；兩者都有避免權值往極端方向發展的
效果，因此這種技術被稱為權值衰減。這個方法不是建立在嚴謹的理論根據上，
而是基於啟發式的直覺：「在降低網路輸出單元目標輸出值與推論輸出值之誤差
平方和的同時，盡量維持較小之權值平方和，可以產生較具普遍性的網路。」此
方法雖然有時可以改善模型的普遍性，但也經常不具實效[3-7]。 
支援向量機（Support Vector Machine, SVM）是 Vapnik 等人根據統計學理論
提出的一種新的通用學習方法，它是建立在統計學理論的 VC 維（Vapnik 
Chervonenks Dimension）理論和結構風險最小原理(Structural Risk Minimization 
Inductive Principle）的基礎上，能較好地解決小樣本、高維次、非線性和局部極
小點等實際問題，已成為機器學習界的研究熱點之一，並成功的應用於分類、函
數逼近和時間序列預測等方面[8-14]。 
支援向量機是從線性可分情況下的最優分類面發展而來的，其基本思想可用
圖 1 的二維情況說明。圖中黑點和白點代表兩類樣本，H 為分類超平面，H1、
H2 分別為過各類中距離分類超平面最近的樣本且平行於分類超平面的平面，它
們之間的距離叫做分類間隔（margin）。所謂最優分類面就是要求分類面不但能
將兩類正確分開（訓練錯誤率為 0），而且使分類間隔最大，從而提高分類預測
能力 [8-14]。在圖 1 中，雖然圖(a)與圖(b)均可完全區分兩類樣本，但圖(b)顯然
具有較佳的普遍性。因此在 SVM 中採取下列的能量函數[8-14]： 
21 EEE += = ∑
=
k
i
iC
1
ξ +
),(
1
bwp
 (5) 
其中 C=懲罰係數，C≥0，C 越大，對分類的誤差的懲罰越重。 iξ =鬆馳變數，
0≥iξ ，代表第 i 個樣本的分類誤差程度。 ),( bwp =分類間隔大小。 
 
 - 6 - 
傾向預測 Class A 的可能；H3 有過於傾向預測 Class B 的可能；兩者在預測測試
範例時都必須冒著較大的誤判風險。H 與 H2 分類函數雖然都沒有過於傾向預測
Class A 或 Class B 的可能，且兩者在預測測試範例時都有較小的誤判風險，但由
於這兩個分類中間有相當寬闊的區段沒有樣本，因此要產生 H2 分類函數是困難
的；但如果限制分類函數必須有「最小坡度」，則可能產生 H 分類函數。 
 
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
 
圖 2 一維分類問題與分類函數 
 
 
因此本文提出「最小風險神經網路」(Minimum Risk Neural Networks, 
MRNN)，其能量函數除誤差平方和以外，還考慮分類函數的坡度平方和，即一
次微分的平方和： 
21 EEE ⋅+= γ = ∑ −
j
jj YT
2)(
2
1 +
2
2 ⎟⎟⎠
⎞
⎜⎜⎝
⎛
∂
∂∑∑
i
j
i j X
Yγ  (6) 
其中γ =坡度平方和的懲罰係數，控制坡度平方和在能量函數中的比例，其值大
於等於 0。 
本文將證明(6)式的第二項可以得到與傳統權值衰減相似但更精緻的公式，
為權值衰減技術找到嚴謹的理論基礎。倒傳遞神經網路 (BPN)、支援向量機 
(SVM)、最小風險神經網路(MRNN)這三種模式之能量函數的比較如表 1 所示。 
 
表 1 三種模式之能量函數的比較 
Class B 
Class A 
H3H1 H2 H 
 - 8 - 
 
以下分成二部份推導具有一層隱藏層的神經網路其加權值與偏權值的修正
量公式： 
z 隱藏層與輸出層間之連結加權值與偏權值的修正量公式 
kjjj
kj
j
j
j
jkj
HnetfYT
net
net
Y
Y
E
W
E ⋅⋅−=∂
∂
∂
∂
∂
∂−=∂
∂− )(')(
W
1  (12) 
令 )(')( jjjj netfYT ⋅−≡δ  (13) 
則 
kj
kj
H
W
E ⋅=∂
∂− δ1  (14) 
⎟⎟⎠
⎞
⎜⎜⎝
⎛
⎟⎟⎠
⎞
⎜⎜⎝
⎛
∂
∂
∂
∂−=∂
∂− ∑∑
i j i
j
kjkj X
Y
W
E
2
2
2
1
W
 (15) 
 
上式中的一階微分可用連鎖律推導 
i
l
l
l
l l
j
j
j
i
j
X
net
net
H
H
net
net
Y
X
Y
∂
∂
∂
∂
∂
∂
∂
∂=∂
∂ ∑ ∑ ⋅⋅⋅=
l
illljj WnetfWnetf )()(
''          (16) 
 
將(16)式代入(15)式得 
∑ ∑
∑∑ ∑
⎟⎠
⎞⎜⎝
⎛ ⋅⋅⋅∂
∂−=
⎟⎟⎠
⎞
⎜⎜⎝
⎛ ⎟⎠
⎞⎜⎝
⎛ ⋅⋅⋅∂
∂−=∂
∂−
i l
illljj
kj
i j l
illljj
kjkj
WnetfWnetf
WnetfWnetf
W
E
2
2
2
)(')('
W2
1
)(')('
2
1
W
 
( )∑ ∑ ⋅⋅⎟⎠
⎞⎜⎝
⎛ ⋅⋅⋅−=
i
ikkj
l
illljj WnetfnetfWnetfWnetf )(')(')(')('  (17) 
故 
( )⎟⎟⎠
⎞
⎜⎜⎝
⎛ ⋅⋅⎟⎠
⎞⎜⎝
⎛ ⋅⋅⋅⋅−⋅=
⎟⎟⎠
⎞
⎜⎜⎝
⎛
∂
∂⋅+∂
∂⋅−=Δ
∑ ∑
i
ikkj
l
illljjkj
kjkj
kj
WnetfnetfWnetfWnetfH
W
E
W
EW
)(')(')(')('
21
γδη
γη
  
 (18) 
由於在上式中，第二項 (即參數γ 所乘的項) 之大小與輸入單元及隱藏單元
 - 10 - 
 (24) 
由於在上式中，第二項 (即參數γ 所乘的項) 之大小與輸出單元及隱藏單元
的數目成比例，故為了使第二項與第一項 ik Xδ 能夠平衡，在實際計算 ikWΔ 時，
第二項須除以 hidout NN ，其中 outN =輸出單元數目， hidN =隱藏單元數目。 
z 最小風險神經網路與權值衰減技術之關係 
為尋找最小風險神經網路與權值衰減技術之關係，因(18)式中的 )(' jnetf 與
)(' knetf 必為正值，並不影響(18)式的正負號，而因此可以考慮忽略之，故可簡
化得 
⎟⎟⎠
⎞
⎜⎜⎝
⎛ ⋅⎟⎠
⎞⎜⎝
⎛ ⋅⋅−⋅=Δ ∑ ∑ ik
i l
ljilkjkj WWWHW γδη  (25) 
同理，(24)式可簡化為 
⎟⎟⎠
⎞
⎜⎜⎝
⎛ ⋅⎟⎠
⎞⎜⎝
⎛ ⋅⋅−⋅=Δ ∑ ∑ kj
j l
ljilikik WWWXW γδη  (26) 
比較(25)式與(26)式和權值衰減技術之(4)式可知，兩者的基本原則類似，都蘊藏
「權值的修正量與權值大小反向」的概念，因此傳統的權值衰減技術可視為最小
風險神經網路的簡化，為權值衰減技術找到嚴謹的理論基礎。 
參、 應用實例 
為了證明 MRNN 可以應用在實際分類應用上，本研究選擇山崩分類問題[15]
來進行測試，並與 BPN 做比較。台灣由於受地理與氣候影響，水土災害一直是
主要的天然災害。再加上多處山坡地過度開發，往往在地震發生時帶來嚴重的山
崩及土石鬆動，造成嚴重的土石崩塌災害發生。1999 年 9 月 21 日於台灣中部發
生芮氏規模 7.3 的地震，而此次地震亦獲得大量的坡地破壞資料及地震紀錄，可
供學者們進行地震對山崩影響的研究。 
本例題資料來自文獻[15]所提供的 60000 筆資料。首先隨機抽樣山崩、未山
崩各 2000 筆樣本，做為本研究的數據。再隨機取 3200 筆為訓練範例，800 筆樣
本為驗證範例。本研究有 15 個輸入變數，如表 2。結果如圖 3。由圖可知，在適
當的 γ 參數時( γ =0.03~0.3)，MRNN 誤判率低於傳統的 BPN。當 γ 達最佳時
(γ =0.1)，MRNN 誤判率(19.1%)明顯比 BPN(20.1%)低。  
此外，本例題也以 SVM [16] 建立分類模型，並以網格法決定最佳懲罰係數
 - 12 - 
圖 3 應用實例的γ 參數與誤判率的關係 
0.01
1
100
10000
0.0
00
1
0.0
01 0.0
1 0.1
1 10 10
0
10
00
15%
20%
25%
30%
35%
40%
45%
Er
ror
 R
ate
Penalty
Coefficient
Kernel Coefficient
40%-45%
35%-40%
30%-35%
25%-30%
20%-25%
15%-20%
 
圖 4應用實例以 SVM 建模之結果(網格法 3D 圖) 
 
為了驗證 MRNN 在少量樣本數下的效果，在此取原訓練樣本的 1/5、1/10、
1/20 的樣本作為建模的訓練集，其結果如圖 5。由圖可知，在 1/5 的樣本下，
MRNN 在適當參數γ 下，其誤判率明顯比 BPN(圖上虛線)低。但隨著樣本的減
少，兩者之間的差異變小。 
0.19
0.2
0.21
0.22
0.23
0.24
0.25
0.26
0.27
0.001 0.01 0.1 1 10
Gamma
Er
ro
r R
at
e
1/5 data
1/10 data
1/20 data
 
 - 14 - 
Letter 0.3474 0.0071 0.3418 0.3315 0.0073 <0.001 * <0.001 * 
Image 0.0422 0.0008 0.0422 0.0421 0.0009 0.330 0.281  
Vehicle 0.1240 0.0020 0.1232 0.1230 0.0015 0.025 * 0.294  
German 0.2393 0.0071 0.2365 0.2362 0.0052 0.034 * 0.397  
Heart 0.1430 0.0019 0.143 0.1430 0.0019 >0.5 >0.5  
Thyroid 0.0241 0.0002 0.0231 0.0198 0.0002 <0.001 * <0.001 * 
 
肆、 結論 
本研究提出最小風險神經網路，它以倒傳遞神經網路(BPN)為基礎，加入結
構風險最小原理的分類間隔最大化的觀念，其目的為了提高 BPN 分類模型的普
遍性，以提高對驗證範例的準確度。由 15 個應用例題的驗證歸納得到 MRNN
的準確性優於權值衰退法的結論。 
本研究與其它文獻不同之處與創新的貢獻簡述如下： 
1. 改善BPN的普遍化預測能力 
BPN與SVM均可建立複雜的非線性模型。傳統的BPN是建立在誤差平方和
最小化的基礎上，雖然相對於SVM而言，BPN具有理論簡明易懂、計算過程簡
單的優點，但它也有容易過度學習，普遍化預測能力差，即對驗證範例的準確度
低的缺點。而SVM是建立在分類間隔最大化的基礎上，雖然相對於BPN而言，
SVM具有普遍化預測能力佳的優點，但它也有理論繁複難懂、計算過程複雜的
缺點。本研究提出的MRNN是以BPN依賴的誤差平方和最小化為基礎，加入SVM
依賴的分類間隔最大化的觀念，不但提高了BPN的普遍化預測能力，也避免了
SVM理論繁複難懂的缺點。 
2. 發現SVM與神經網路的數學理論相似架構 
SVM是建立在分類間隔最大化的基礎上；而傳統的BPN則建立在誤差平方
和最小化的基礎上；兩者看似無關。本研究經由提出MRNN發現了SVM與神經
網路的數學理論相似架構，為建立神經網路與SVM的統一理論架構提供一個可
能的研究方向。 
3. 證明權值衰減技術是MRNN的簡化 
權值衰減技術長期以來一直被視為是一個可以提高神經網路普遍化預測能
力的方法，但此法是建立在經驗法則的基礎上。本研究提出的MRNN經過簡化後
 - 16 - 
11. Burges, C., “A tutorial on support vector machines for pattern recognition”, Data 
Mining and Knowledge Discovery, Vol. 2, No. 2, pp.121-167 (1998). 
12. Fan, R.E., Chen, P.H., and Lin, C.J.. “Working set selection using second order 
information for training support vector machines,” The Journal of Machine 
Learning Research, Vol. 6, 1889 –1918 (2005). 
13. Glasmachers, T. and Igel, C., “Second-order SMO improves SVM online and 
active learning,” Neural Computation, Vol. 20, No. 2, pp.374-382 (2008). 
14. Glasmachers, T. and Igel, C. “Maximum-gain working set selection for SVMs,” 
The Journal of Machine Learning Research, Vol. 7, pp.1437-1466 (2006).  
15. Tsou, M. C. and Sun, C. H. “A Comparative and integrated study of a predictive 
model in spatial data mining,” Journal of Geographical Science, Vol. 38, pp. 
93-109 (2004). 
16. Chang, C.C. and C.-J. Lin. LIBSVM: a library for support vector machines, 2001. 
Software available at http://www.csie.ntu.edu.tw/~cjlin/libsvm. 
 - 18 - 
低的缺點。而SVM是建立在分類間隔最大化的基礎上，雖然相對於BPN而言，
SVM具有普遍化預測能力佳的優點，但它也有理論繁複難懂、計算過程複雜的
缺點。本研究提出的MRNN是以BPN依賴的誤差平方和最小化為基礎，加入SVM
依賴的分類間隔最大化的觀念，不但提高了BPN的普遍化預測能力，也避免了
SVM理論繁複難懂的缺點。 
2. 發現SVM與神經網路的數學理論相似架構 
SVM是建立在分類間隔最大化的基礎上；而傳統的BPN則建立在誤差平方
和最小化的基礎上；兩者看似無關。本研究經由提出MRNN發現了SVM與神經
網路的數學理論相似架構，為建立神經網路與SVM的統一理論架構提供一個可
能的研究方向。 
3. 證明權值衰減技術是MRNN的簡化 
權值衰減技術長期以來一直被視為是一個可以提高神經網路普遍化預測能
力的方法，但此法是建立在經驗法則的基礎上。本研究提出的MRNN經過簡化後
與權值衰減技術相似但較精緻，因此權值衰減技術可視為MRNN的簡化，而
MRNN也可視為權值衰減技術的進階，為權值衰減技術找到較嚴謹的理論基礎。 
佳論文獎候選(共五篇入選)，並在 2010/7/12 日下午與議場發表。並
在 2010/7/13 晚宴中發表得獎名單。最後是由另一位也是來自台灣的
學者獲獎。 
 
二、與會心得 
這次會議的研究主題包含了許多機器學習的相關議題，並請學者專
題演獎，包括： 
Multiple Classifier Systems 
How to disseminate your research results: essentials of effective 
publishing 
Multiple Kernel Learning and Feature Space Denoising 
Incompleteness in Data for Decision Making 
其中 Multiple Classifier Systems 似乎是一個重要趨勢，因為已有很多
分類器被提出，如何更進一步整合多個分類器是一個提升準確率的
可行方法。 
 
三、考察參觀活動(無是項活動者略) 
 
四、建議 
青島市是一個風景秀麗的城市，觀光資源豐富，是 2008 奧運帆
船項目場地。但除了日韓以外，外國觀光客不多。還有可以改進之
處。不過其金融中心的建設相當集中，潛力不可忽視。 
 
五、攜回資料名稱及內容 
(1) 會議論文光碟一份 
(2) 議程文件一份 
 
 
98年度專題研究計畫研究成果彙整表 
計畫主持人：葉怡成 計畫編號：98-2221-E-216-049- 
計畫名稱：類神經網路演算法之改良 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 1 1 100% 
葉怡成、程韋綸
(2010)，「可衡量輸
入變數重要性的神
經網路─灰箱倒傳
遞網路」，先進工程
學刊，第 5卷，第
1期，第 41-48 頁。
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 4 4 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 1 1 100% 
I-Cheng Yeh and 
Wei-Lun Cheng 
(2010), ＇First 
and Second Order 
Sensitivity 
Analysis of 
MLP,＇ 
Neurocomputing, 
Vol.73, No.10, 
pp. 2225–2233. 
(SCI) 
國外 論文著作 
研究報告/技術報告 0 0 100% 
篇 
 
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
