 1 
行政院國家科學委員會專題研究計畫成果報告 
以動態觀點為基準的生產規化：重複製程(3/3) 
Batch Process Monitoring Using Key Sensitivity Index 
計畫編號：NSC 95-2221-E-002-266 
執行期限：95年 08月 01日至 96年 07月 31日 
主持人：余政靖         國立台灣大學化工系 
計畫參與人員：蘇安治   國立台灣大學化工系 
 
Abstract 
 
Process monitoring is essential to maintain product 
quality in semiconductor manufacturing and the batch-wise 
processing nature makes data-based monitoring attractive. 
However, unlike chemical processes, the semiconductor 
manufacturing process exhibits the following characteristics: 
(1) much shorter (minutes) and often variable (deliberately 
adjusted) batch time, (2) multiple processing steps (10-20) 
in each batch, (3) only some particular processing steps 
(not the entire trajectory) constituting the quality 
determining steps, (4) mixed products for the same batch 
processing. In this work, instead of incorporating large 
number of trajectory data with variable batch time and 
possibly “missing” data for some process variables using 
multivariate statistics, a process-insight based approach, 
key sensitive index (KSI), is taken. From process 
knowledge, the key sensitive time-slot (KST) in the recipe 
is identified. Next, possible key sensitive process variables 
(KSV) are selected and validated according to the process 
trend correlation. Then, an index for these variables (key 
sensitive index, KSI) is sought. The KSI’s can be classified 
into: variable-based, model-based, and data-based measures. 
Two integrated circuit processing examples from real fab 
data are used to illustrate the KSI-based approach and 
results clearly indicate that process trend is captured using 
KSI-based approach.  
 
1、Introduction 
 
Batch processes play an important role in the 
production and processing of chemicals, pharmaceutical, 
and semiconductor devices. Generally, a batch process is 
characterized by prescribed processing of raw materials for 
a finite duration to convert them to products. A high degree 
of reproducibility is necessary to obtain successful batches. 
Some batch processes include a single step, whereas many 
others are carried out in a sequence of discrete steps, which 
are usually referred as recipes in semiconductor 
manufacturing. Events taking place in each step have 
impacts on the final product yield and quality. For chemical 
process industry (CPI), upon completion of a batch, a range 
of quality measurements is usually made at the quality 
control laboratory, often hours later. For semiconductor 
industry, the quality measurements are usually not 
available at the end of a single processing unit until the 
processes in several processing units have been completed. 
Therefore, monitoring and control of the intermediate 
stages of operation and intermediate product quality is as 
important as monitoring and control at the final stage. 
 
Online process performance monitoring and product 
quality prediction in real time can reduce quality variations. 
Multivariate statistical projection methods such as principal 
component analysis (PCA) and partial least squares (PLS) 
are capable of utilizing massive amounts of process data 
and compress the information data down into a lower 
dimensional latent space in which process monitoring and 
results interpreting are much easier. These methods are 
first utilized in developing multivariate statistical process 
monitoring and quality prediction techniques for continuous 
processes (Kourti et al., 1996). Nomikos and MacGregor 
(1994) pioneer the use of the large number of trajectory 
measurements collected from batch process and develop 
multi-way projection methods for statistical process 
monitoring. Batch data are recorded in terms of batch runs, 
variables, and time. They are arranged into a 
three-dimensional array in the multi-way projection 
methods and, therefore, analysis of batch processes data 
arouses a variety of challenges. Due to the nature of batch 
processes, every batch may come to completion at a 
different termination time, resulting in unequal batch data 
lengths. The unequal length batch data should be equalized 
prior to forming a three-dimensional array. The simplest 
way for equalizing batch lengths is cutting batch data 
lengths to the length of the variable with the shortest 
sequence, but this is not recommended because of the 
possible significant information loss generated by 
discarding data. Several methods for equalizing batch 
lengths, such as the indicator variable technique (IVT) 
(Nomikos and MacGregor, 1995; Neogi and Schlags, 1998), 
dynamic time warping (DTW) (Kassidas et al., 1998), and 
curve registration (Williams and Cinar, 2000), have been 
suggested in the literature. IVT is based on selecting a 
process variable to indicate the progress of the batch 
instead of the time axis. This variable should be chosen 
such that it progresses monotonically in time and has the 
same starting and ending value for each batch. But IVT 
does not account for the locations and the alignment of 
critical local features (landmarks) of each trajectory. DTW 
is used to synchronize two trajectories by appropriately 
translating, expanding, and contracting localized segments 
within the trajectories to achieve a minimum distance 
between the two trajectories. However, warping the batch 
trajectories to have the minimum distance with the 
reference batch trajectory may distort their critical features 
or fault patterns and, hence, reduce the monitoring ability. 
Curve registration is a two-step process of identifying 
landmarks within a trajectory (or set of trajectories) and 
then warping the test trajectory to the reference trajectory 
containing reference landmarks. Identifying multivariate 
landmarks is challenging because the number and location 
of landmarks may be different for different process 
variables. In addition to unequal batch data lengths, another 
 3 
time
y
A B C D E F
 
Fig. 2. Schematic of key sensitive time-slot (KST). 
 
engineers can identify critical steps with little difficulty. 
Specifications or will give indication on tool 
condition. The KSV can be classified as:  
1. Variable-based KSV: This is rather straightforward that 
the KSV is the process variable itself and it can be 
directly read from raw data. The KSV can be the 
variable at certain snapshot such as the initial value, 
final value, maximum value, and minimum value etc. 
For example, the peak value in the step B of Fig.2 may 
be used as a KSV. One should note that raw data may 
not precisely capture true behavior with a low sampling 
frequency or fast response processes. 
2. Computed feature-based KSV: Some computed values 
from raw measurement, such as slope, mean, standard 
deviation, may have important physical implications. 
Again, let us use the step F in Fig.2 to illustrate this. 
The mean value or standard deviation can be a sensitive 
measure for process trend. Another possible example is 
the area of the peak or the ramp up slope in Step B (Fig. 
2). This type of KSV, to a degree, reflects some physical 
meaning, e.g., integrated area for effective energy input. 
3. Regressed feature-based KSV: Parameters of a 
prescribed model can be used extract process feature. 
These quantities can describe process condition as batch 
progresses. Simple models, steady-state polynomial 
model or dynamical transfer function model. For 
example, one could use the initial value, steady state 
gain, and time constant to capture the behavior of a first 
order response at the current stage (step D in Fig.2). 
This is effective for identifying possible variation in 
process dynamics. 
The on-going discussion clearly shows that the introduction 
of the KST and KSV is actually doing the dimensional 
reduction for subsequent analyses. In doing this, a 
two-dimensional data matrix (the number of observation by 
the number of variables) in a single batch can be reduced to 
a vector of KSVs. Thus, it will be much easier to 
incorporate models, steady-state or dynamic model, for 
monitoring and/or fault detection. 
After obtaining candidate KSVs from process knowledge, a 
certain mechanism is necessary for validation. It is obvious, 
the intuitively correct KSVs may or may not have strong 
link to quality spec or to the tool health condition as the 
batch progresses. The candidate KSVs are sequences of 
data taken sequentially and it can be viewed as a time 
series. A straightforward approach is to exclude variables 
which exhibit the behavior of random variable. In other 
words, the KSV, to a degree, should be able to capture the 
process trend as the batch progresses. The autocorrelation 
is a simple measure to discriminate true KSV from random 
variables, as far as process trend is concerned.  The most 
satisfactory estimate of the kth lag autocorrelation of a time 
series is (Box et al., 1994): 
0
k
k
cr
c
=      (1) 
where 
( )( )
1
1 N k
k t t k
t
c z z z z
N
-
+
=
= - -å   (2) 
(k=0, 1, 2…., k) is the estimate of the autocovariance, 
and z  is the sample mean of the time series. 
 If the autocorrelation function of time series for a 
candidate is found to be significant, it is then validated. 
Otherwise, if a weak correlation is observed, it can be 
treated as a white noise sequence which offers little 
information on process trend. Thus, some candidate KSVs 
can be removed after autocorrelation analysis. If, 
unfortunately, none of the KSVs has significant expression, 
one should reevaluate KSVs, even KST. Again, it should be 
emphasized here that obtaining successful KSVs depends 
on the understanding and experience on process/equipment. 
However, a rigorous evaluation is critical for validation. 
The KSVs give more information on process condition than 
just applying all variables into a black/gray box modeling. 
Mix-products constitute a significant portion in 
semiconductor manufacturing and this type of problem is 
essential for foundries. Therefore, it is important to account 
for the product effect in the KSVs such that effective 
process trned monitoring can be achieved. The product 
indices could be linewidth, pattern density, material 
properties, etc. If a KSV shows unusual behaviors such as 
abrupt change, shifts, and spikes within a trend, very likely, 
it may be a consequence of product effects. One can verify 
this effect by analyzing the correlation between KSVs and 
product indices. To know the selected KSV having product 
effects is a challenging task, but process knowledge always 
offers some insight. Tow examples are: the removal rate of 
CMP differs with linewidth (Chiu et al., 2004) and the 
geometry of a wafer surface affects the view factor for 
radiation related processes. 
The generalized procedure for obtaining KSVs is 
given as follow: 
S1: Select possible measurements based on experience. 
S2: Define the key sensitive time-slots in a recipe. 
S3: Obtain possible key sensitive variables. 
S4: Check autocorrelation for each KSV. If no significant 
KSV is found, return to step 2 or 3. 
S5: Take out the product effects, if information on product 
type and corresponding is available. 
After this procedure, raw data of a batch process has been 
reduced into a vector in which each element is a KSV. 
Therefore, the data-drive analyses such as PCA, PLS and 
ANN could be applied straightly. In following section, we 
will propose a method to construct a time series based 
healthy index from these KSVs 
 
3、Key Sensitive Index 
 
In the case of extreme dimension reduction, a scalar index 
could be constructed as a function of many KSVs for one 
batch. This index should reveal the current status or critical 
feature of a batch trajectory, and it is very convenient for 
monitoring. This kind of index is termed as key sensitive 
indices (KSI) here which is used to describe the behavior of 
process. The choice of KSI may depend on the analysis 
done on the KSVs aforementioned. The possible ways for 
constructing KSI are described, but not limited to, as the 
following. 
 5 
0 1000 2000 3000 4000 5000
850
900
950
1000
V
3 m
ax
(a)
0 1000 2000 3000 4000 5000
850
900
950
1000
wafer #
V
3' m
ax
(b)
 
Fig. 3. The Trend of (a) KSV and (b) modified KSV in case study 1 
 
0 200 400 600 800 1000 1200 1400 1600
850
900
950
1000
E
m
ax
60
70
80
90
P
D
1+
P
D
2
1600 1800 2000 2200 2400 2600 2800 3000 3200
850
900
950
1000
E
m
ax
60
70
80
90
P
D
1+
P
D
2
3200 3400 3600 3800 4000 4200 4400 4600 4800
850
900
950
1000
E
m
ax
60
70
80
90
wafer #
P
D
1+
P
D
2
V3max
V3max
V3max
PI1+2Em
ax
P
D
1+
P
D
2
E
m
ax
P
D
1+
P
D
2
E
m
ax
P
D
1+
P
D
2
 
Fig. 4. The influence of product index in case study 1 
 
0 1000 2000 3000 4000 5000
0
5
10
15
20
Wafer #
KSI
  
Fig. 5. The resultant key sensitive index (KSI) for case study 1 
 
 
Fig. 6. Fault detection of case study 2 
 
KSI-based approach not only can be used for batch process 
trend monitoring, but also it is helpful for the engineers to 
decide when to call for tool maintenance. 
 
4.1 Case Study 2- Thin Film Process 
The concept of KSV is also been applied to another 
thin film process tool. There are three issues in this case 
study. One is virtual metrology which relates tool raw data 
and quality index, and the other two are fault detection and 
process trend monitoring. 
The engineers provide totally 23 variables raw data. 
After filtering out some constant, meaningless, and poor 
resolution variables, we attempt to obtain KSVs from two 
key sensitive time-slots. Because the data of quality is 
given, we search many numbers of KSV to match quality as 
possible. Applying the least square model obtained from 
the training set to predict the test set, the accuracy is 
R2=0.65 in which 41 KSVs are used. Although, this result 
may not be outstanding, it’s value comes from that the 
simple concept of KSV and simple least square modeling 
can hit the greater part of quality behavior. 
Besides, this process tool may produce defects that 
will no be detected until several sequential process steps 
have been proceed. A period of tool raw data that contains 
several scrapped wafers is provided. We obtain 16 KSVs, 
including wafer temperature, chamber side temperature, 
and other variables. A PCA model is built based on normal 
(no defects) wafers, and consequently use Q statistic for 
detection as shown in Fig. 6. At the end of Q line, the last 4 
wafers soar abnormally, and these wafers have also been 
classified as scrapped wafers. For diagnosis, the 
contribution analysis shows several significant weighting 
KSVs which are obtained from chamber temperature. 
According to the process engineer, there was a leakage on a 
gas tube at that time, and it resulted in chamber side 
temperature increasing abnormally. It is coincident with our 
contribution analysis. Hence, the concept also can be 
applied to fault detection and diagnosis successfully. 
Finally, for process trend monitoring, we also use 16 
KSVs as described previously. This KSI grows up with the 
progress of batch process and return to its normal value 
immediately after PM. The results again indicate that the 
process trend and the healthy condition of the tool can be 
realized using the proposed KSI. 
 
5、Conclusion 
 
The concept of using KSV to construct a KSI is easy 
and straightforward, but with great benefit. It captures the 
key features of measurements for consequential analyses 
without complicated data pre-processing.  We have 
demonstrated two successful real cases by proposed method. 
On the contrary, simplification also could possible lose 
some important information. The understanding of 
processes and equipment make KSV or other analysis 
technique working out. 
 
Reference 
 
Box, G. E. P., G. M. Jenkins, and G. C. Reinsel (1994), Time Series 
Analysis: Forecasting and Contrlo, Prentice Hall 
Chiu, J.B., A.J. Su, C.C. Yu, and S.H. Shen (2004), Planarization 
Strategy of Cu CMPInteraction between Plated Copper Thickness 
and Removal Rate, Journal of The Electrochemical Society, 151 
(4), G217-G222 
Kassidas, A., J. F. MacGregor and P. A. Taylor (1998), 
Synchronization of Batch Trajectories Using Dynamic Time 
Warping, AIChE J., 44, 846. 
Kourti, T. (2003), Multivariate Dynamic Data Modeling for Analysis 
and Statistical Process Control of Batch Processes, J. Chemom., 17, 
93. 
Kourti, T., J. Lee and J. F. MacGregor (1996), Experience with 
Industrial Applications of Projection methods for Multivariate 
Statistical Process Control, Computers Chem. Engng., 20, 
0 2 0 4 0 6 0 8 0 1 0 0 1 2 0 1 4 0 1 6 0 1 8 0
0
0 . 2
0 . 4
0 . 6
0 . 8
1
W a fe r  #
Q
參加美國化工年會 (AIChE Annual Meeting) 報告 
余政靖 
國立台灣大學化工系 
一. 參加會議經過 
    美國 2006化工年會在 San Francisco, California舉行，這是化工界相當重要
的學術會議，因為化工各領域的研究主流大都會參予，因為在舊金山舉行參加人
數都在 5000人左右。 此會提供相當好的機會了解同領域研究者的方向及進展以
及新的研究走向，這是一個值得認真參與的會議。 我們在會中有兩篇口頭報告
及一篇壁報論文，口頭報告中一篇由學生報告而另外一篇由我報告。主題分別是: 
1. Tung, S. T.; Yu, C. C. “Effects of Relative Volatility Ranking to the Design of 
Reactive Distillation”, AIChE Annual Meeting, Nov. 12- 17, San Francisco, paper 
674c, 2006. 
2. Lin, Y. D.; Chen, J. H.; Huang, H. P.; Yu, C. C. “Process Alternative for Methyl 
Acetate Conversion Using Reactive Distillation: Transesterification Versus 
Hydrolysis”, AIChE Annual Meeting, Nov. 12- 17, San Francisco , paper 303k, 
2006. 
3. Jeng, J. C.; Su, A. J.; Huang, H. P.; Yu, C. C. “Process Trend Monitoring Based 
on Key Sensitive Index: Applications Semiconductor Manufacturing”, AIChE 
Annual Meeting, Nov. 12- 17, San Francisco, paper 92a, 2006.  
 
台灣的參與者除了我以外還有台科大，台大，中央，長庚，成大的師生以及亞洲
同領域來自韓國，日本，新加坡及中國的學者。雖然會場分布相當廣，但同領域
的發表還是至於鄰近區域，也是個meet old friend and know new friends的好場合。 
 
二. 與會心得 
    這次會議中，本人參與此活動的進行，除了了解各國相關研究者對於各種題
目的研究情形，也在更宏觀的了解化工程序系統設計與控制的架構，這對未來研
究方向及構想皆有助益。整體來說，個人認為參加這種會議，能有較深入的討論
收穫良多，更了解國際上研究趨勢，並與他國學者交換彼此研究的心得。這在未
來研究規劃上相當有幫助。 
 
三. 攜回資料 
會議手冊。 
PDF created with pdfFactory Pro trial version www.pdffactory.com
