 2
like to perform part or most of the video 
processing within the embedded package, 
and communicate with other nodes only 
when necessary. 
    In this project, we would like to develop 
smart camera nodes suitable for 
image-intensive network applications. We 
would like to start with constructing the 
camera nodes in stationary deployment. Our 
main target applications are human pose 
estimation. However, our system may be 
further integrated with other applications, 
such as face detection and recognition, and 
other surveillance applications. 
 
Keywords: Smart camera, image processing 
二、前言 
    智慧型攝影系統為最近開始才被廣泛
研究的新技術領域。智慧型攝影系統的目
的為在單一的封裝中同時執行視頻訊號截
取和影像處理等動作，隨著搭載的軟體程
式的不同，智慧型攝影系統可以提供多種
不同的影像處理應用。 
在傳統上，多機攝影系統使用中央伺
服器為主要運算節點，各個攝影系統必需
將完整影像訊號傳輸至中央伺服器。在多
機攝影系統中，若各個攝影系統各要傳輸
完整影像訊號，則傳輸資料所耗費的時間
相當多，若能在各個攝影系統節點上預先
對影像做前處理，擷取出影像中應用所需
要的資訊，則可節省傳輸頻寬，也能讓中
央伺服器能更專注於處理後端影像辨識等
演算法上。 
近年來，人機介面(Human-Computer 
Interface, HCI)越來越蓬勃發展，手勢辨識
的應用日漸成熟，未來將往人體姿勢辯識
(Human Pose Recognition)發展。在實現人
體姿勢辯識之前，必需要先定位人的頭、
手與腳的位置，才能進一步的往人體姿勢
辯識發展，所以我們決定實現人體姿勢估
測(Human Pose Estimation)此一部份的演
算法。 
本計畫之目標為建置一人物動作分析
平台，針對動作分析、辨識演算法做一深
入研究。其內容與成果包括人物動作分
析、偵測演算法之開發及系統工作分配。 
三、文獻探討 
近年來有不少研究專注於人物動作分
析上，人物動作分析可大致分為幾個部
份 ： 擷 取 人 物 動 作 (Human Motion 
Extraction)、人體姿勢估測、追蹤人體
(Human Tracking) 以 及 人 物 動 作 辯 識
(Human Action Recognition)。 
利 用 背 景 去 除 (Background 
Subtraction)[1]取得人物動作是目前最常用
的方法之一。背景去除需要建立背景模型
(Background Model)，該如何決定影像中何
者為前景、何者為背景為此方法重要之議
題，背景模型的建立與更新也是此方法需
要探討之議題。 
人體姿勢估測則更多種不同的方法：
Pfinder[2]利用建立背景模型以取得移動物
體，並建立人體模型找出移動物中的人體
範 圍 ： [3][4] 星 狀 骨 架 化 (Star 
Skeletonization)抓取人體輪廓做為骨架化
的依據，但此方法受限於人的動作必須要
夠大，才能正確的抓取人體動作輪廓。 
人體追蹤的部份，近年來卡爾曼濾波
器 (Kalman Filter)[5][6] 與 粒 子 濾 波 器
(Particle Filter)[6]常用在人物追蹤上，主要
應用於追蹤行人、身體移動軌跡。當發現
人有不正常的移動軌跡時可發出警示。 
我們選用的人體姿勢估測演算法為結
合 背 景 去 除 與 膚 色 偵 測 (Skin Color 
Detection)取得頭與手的資訊，但此一方法
容易受光線所影響，所以我們針對光線影
響去做修正的動作，以提高膚色偵測的準
 4
 
 
 
此方法為根據影像平均亮度    去做
伽瑪校正(Gamma Correction)。但此方法只
對R與G做校正的動作，因為R與G與膚色
較有關係，此修正是為了讓膚色偵測更準
確： 
 
 
 
經由GW和光線修正動作後，可得到與
真實顏色較相近的影像如圖4，我們可以利
用此一影像做膚色偵測得到較好的結果。 
 
圖 4: (a)圖為擷取影像(b)為經由光線補償後影像 
 
目前以像素為基準(Pixel-Based)的膚
色 偵 測 主 要 有 幾 種 ：
Normalized-RGB(NCC)[9]、YCrCb[10]等，
各種方法皆有優缺點，平均來說NCC的效
果來得較好，但需要較多的浮點運算。我
們選用較常使用的YCrCb做為膚色偵測的
方法。根據[11]所提出修正過後的YCrCb
膚色偵測： 
 
 
 
 
   是根據光線修正後的  與  所求
得。我們可從圖5見到膚色偵測後的結果是
相當準確。 
 
圖 5: (a)圖為經由光線補償後影像(b)為膚色偵測後
之影像 
五、實驗結果 
 
圖 6: 膚色偵測(a)YCbCr 膚色偵測(b)NCC 膚色偵
測(c)[15]提出的 YCbCr 膚色偵測(d)經過光線補償
後使用[15]所提出的 YCbCr 膚色偵測 
 
我們使用320 X 240的影像作為輸入
測試經由光線補償後的膚色偵測效果，由
圖6(a)可發現YCbCr膚色偵測所造成的誤
判率很高，衣服也被視為是膚色範圍；圖
6(b)為使用NCC膚色偵測，可以看到膚色
範圍較精確，但一隻手沒有偵測到；圖6(c)
為[11]所提出的膚色偵測演算法，結果較精
確，但會有一些誤判的情況；圖6(d)可以看
到經由光線補償後的影像做膚色偵測，可
以很準確的抓出頭與手的膚色資訊。 
1.4, 64
0.6, 192
1,
avg
avg
Y
Y
otherwise

 
avgY
 
( )
( )
, ,
ij ij
ij ij
ij ij ij ij
R R
G G
C R G B


 
 
 
0.5 0.419 0.081
1, 10 45
0,
r
r
C R G B
C
Skin
otherwise
   
  
rC R G
 6
Cybernetics, Part B: Cybernetics 41 (1), Feb 
2011, art. no. 5446342, pp. 26-37  
[7] L. Chen and C. Grecos, “A Fast Skin Color 
Detector for Face Extraction”, Proceedings 
SPIE Electronic Imaging Conference, 2005  
[8] M. Bramberger, A. Doblander, A. Maier, B. 
Rinner and H. Schwabach, “Distributed 
embedded smart cameras for surveillance 
applications”, in IEEE Computer Magazine, Feb. 
2006, Vol.. 39, Issue 2, pp. 68–75. 
[9] Soriano, M., B. Martinkauppi, S. Huovinen, and 
M. Laaksonen, “Using the skin locus to cope 
with changing illumination conditions in 
color-based face tracking”, in Proc. IEEE 
Nordic Signal Proc. Symp., Kolmarden, Sweden, 
pp.383-386, July 13-15, 2000.  
[10] Phung, S. L., Bouzerdoum, A., and Chai, D., “A 
novel skin color model in YCbCr color space 
and its application to human face Detection”, 
IEEE International Conference on Image 
Processing (ICIP’2002), vol. 1, 289–292. 2002. 
[11] Yu-Ting Pai, Shanq-Jang Ruan, Mon-Chau Shie, 
and Yi-Chi Liu, “A Simple and Accurate Color 
Face Detection Algorithm in Complex 
Background”, in proceeding of 2006 IEEE 
International Conference on Multimedia & 
Expo (ICME 2006), Canada, 9-12 July 2006, pp. 
1545-1548. 
 
 2
系統或是日常生活中的電視，這些都是現在科技進步的指標，因此在這次會議中也多
多少少知道一些新的演算法與新的應用。今年ISCE有 146篇 papers從 12個 sessions
被選上，其中我最感興趣的 sessions 中包括 Multimedia Signal Processing, Digital 
Imaging 和 User Interface & HCI 等等，這些都讓我對影像處理方面的應用或是演算
法又更深的了解和認識。 
     
今年參加完這次的會議，讓我知道各國對於研究相關領域的重點所在，經過每場報告
後的討論與意見，使我更了解未來該朝哪些方向去做研究才有它的價值。 
 
參加會議或活動之出席照片 
   
  
An Economic Color Printing Algorithm Using Approximate-K 
Wei-Kai Hu, Chang Hong Lin, Mon-Chau Shie 
Department of Electronic Engineering  
National Taiwan University of Science and Technology 
M9802121@mail.ntust.edu.tw 
 
ABSTRACT 
This paper proposes a novel scheme to save the usage of 
ink or toner by an approximate-K algorithm for color 
printers. Existing printers use the mixtures of three color 
toners(C, M and Y) to print all the pixels for color images, 
and it makes color printing cost 4-4.5 times more 
expensive than monochromic printing. Since human eyes 
are not sensitive to distinguish neighboring colors in the 
color space, we can use the K toner to replace the colors 
close to gray-scale. We can then reduce the ink usage 
without affecting the image visual qualities. We use the 
saturation in the HSV color model to discover the near 
gray-scale pixels and transform those pixels to gray level. 
We then evaluate the objective image quality using the 
PSNR. From our experimental results, printing a color 
image using our algorithm needs only 77%of the original 
price in average. 
1. INTRODUCTION 
In recent years, environmentalists all over the world 
promote environmental protection. The spirit of it is to 
make the best use of everything. For example, the 
common printers in the market, both inkjet and laser ones, 
consume a huge amount of ink or toners while dealing 
with color printings. The color image printed by common 
printers in the market is consisted of four colors, C (Cyan), 
M (Magenta), Y (Yellow), and K (Black) (Figure 1). 
According to the color model transfer formula of the color 
theory, black and gray can be mixed by C, M and Y. In 
reality, current printers print all pixels, including the gray- 
scale ones, using the mixture of CMY when dealing with 
color printing. According to the market prices of ink and 
toners from three major brands, EPSON [1], HP [2], and 
Canon [3], the price of color ink need to print a pixel is 4 
to 4.5 times higher than the price of a pixel using black ink. 
If we can reduce the usage of color ink, we can save a 
great deal in terms of the cost of ink or toners. 
 
Figure 1. CMY color model. 
In this paper, we take advantage of the feature that human 
eyes are not sensitive to low frequency signals in colors. 
So, we propose a method to use the K toner to replace near 
gray-scale pixels in order to reduce the usage of CMY 
toners. Our method changes the color pixels to gray-scale 
pixels when the image quality is not affected obviously. 
The flow of our algorithm works as follows: First, it 
determines the thresholds which can distinguish the pixels 
need to be modified. Second, through approximate-K 
processing, the pixels’ values are changed to new gray-
scale values. After we get the approximated image, we 
print it out and verify the image quality by computing the 
PSNR (Peak Signal to Noise Ratio). 
This paper is organized as follows: In section 2, we 
discuss some related work. We describe our algorithm and 
architecture in section 3. In section 4, we present a detailed 
comparison of the performance of our algorithm on 
various benchmark images. Finally, we conclude the paper 
in section 5.   
2. RELATED WORK 
There have been tons of researches working on image 
processing algorithms by manipulating the pixel values of 
the original images. Image enhancement is one of the hot 
areas. For example, Song and Qiao enhanced color images 
based on luminance and saturation [4], You and Chien 
enhanced blue skies of scenery images [5], and Tang et al. 
enhanced images via chromaticity diffusion [6], while 
many researchers stretched the contrast using histogram 
equalization [7-10]. All these works focused on improving 
the image quality. On the contrary, some other researchers 
manipulated the pixels in order to hide information. 
Watermarking is one of these examples. Das et al. 
introduced invisible image watermarking on color image 
[11]. Liao and Ye hided information in digital image based 
on the similarity of image blocks [12]. Wang et al. hided 
watermarking information in gray images based on their 
histogram [13]. Caltuc and Bolon applied color image 
watermarking in HSI space [14]. The basic idea of our 
work is similar to information hiding. However, there was 
no prior art worked on algorithms to save the ink or toners. 
3. PROPOSED ALGORITHM 
Figure 2 illustrates the flowchart of our algorithm, which 
is composed of three major parts: (1) detection of near 
  
In this paper, we use formula (2) to transform the near 
gray pixels into gray-scale. The result is shown in Figure 
6(b). 
     
                       (a)                                        (b) 
Figure 6. (a) near gray pixels through saturation threshold 
process, (b) pixels through approximate gray-scale 
formula process. 
3.3 Evaluation of the Approximate K Pixels 
To evaluate the similarity between the modified image and 
the original one is a big problem in this work. The MSE 
(Mean Square Error) measures the difference between 
these two images. While the PSNR, derived from MSE, is 
the most common metric to measure the similarity 
between two images [17]. They are defined as follows [18]: 
( )
2
1 1
1 ∑∑
= =
−




=
M
i
N
j
ijij XXMN
MSE
 
db
MSE
IPSNR 





×=
2
log10
                               (3) 
M and N are the height and the width of the image,  ijX is 
the pixel value of pixel (i, j) in the original image,
 ij
X is 
the pixel value of pixel (i, j) in the reconstructed image, I 
is the maximum value that a pixel can take (equals to 255 
for 8-bit images). 
Generally, the image quality is close to the original image 
when the PSNR value is more than 70. The difference of 
processed image and original image is undetected by 
human eyes when the PSNR value is between 60 and 50. 
When the PSNR value is lower than 40, the obvious 
distortion of processed images can be easily detected. 
Therefore, the higher the PSNR value, the lower the image 
distortion. 
4. EXPERIMENTAL RESULTS 
In this paper, we perform approximate-K processing for 
six threshold values (from 0.05 to 0.3) on three test images 
(Airplane, Baboon, and Lena). All three benchmark 
images are 512 x 512 in size, but they have different 
saturation histogram distributions. As can be seen in 
Figure 7, more than 70% of the pixels in Airplane are very 
low saturated (with saturation value of [0, 0.1]); the 
saturation histogram of Baboon has Erlang-2 distribution 
with the mean value close to 0.3; the saturation histogram 
of Lena is close to normal distribution. 
Figure 7 shows the original test images along with 
modified images using our algorithm with threshold value 
varies from 0.05 to 0.3. For Airplane, it is clear that the 
airframe does not change much, while some parts of 
clouds in the background change from cyan to gray as the 
threshold value increases. However, the variations for 
Baboon and Lena are not as visible. When the threshold of 
Baboon is higher than 0.15, the hairs around the face 
change gradually from colorful to gray level. For Lena, the 
difference is undetectable when the threshold is lower than 
0.2, while the front part of the hat and right shoulder turn 
to white when the threshold goes beyond 0.25. 
 
Figure 8. The PSNR of modify images. 
 
Figure 9. The Ratio of approximate-K Pixels. 
Figure 8 shows the PSNR of the modified images in 
Figure 7. For both Lena and Baboon, the PSNR are higher 
than 45 for thresholds lower than 0.15. These results agree 
with the visual inspection that the differences to the 
original images are hard to be detected. However, since 
more than 70% of the pixels in Airplane have saturation 
values in [0, 0.1], thresholds larger than 0.1 will result in 
unacceptable images. 
Figure 9 shows the ratio of approximate-K pixels in the 
modified images. The ratio represents the portion of pixels 
that can be saved using our algorithm. It is clear that the 
higher the saturation threshold, the more pixels can be 
saved. Using PSNR=45 as the criterion (the acceptable 
image with the highest threshold), we can get 57%, 15% 
and 5% pixel savings for Airplane, Baboon and Lena, 
respectively. In terms of money, printing an image using 
our algorithm costs on average only 77% of the original 
price. 
  
5. CONCLUSION & FUTURE WORK 
In this paper, we propose a new approximate-K algorithm 
to save the usage of ink or toners of color printers. First, 
we find the pixels in an image with colors similar to gray- 
scale. Second, we transform those pixels into approximate-
K values. Finally, we compute the PSNR for image quality 
evaluation. According to our experimental results, printing 
an image using our algorithm costs on average 77% of the 
original price. 
For future work, we would like to find an automatic 
thresholding algorithm that can determine the threshold 
used in our algorithm based on the features of the images. 
Furthermore, besides of the objective evaluation method 
we used in this paper, we would like to introduce 
subjective evaluation methods to achieve higher credibility. 
6. ACKNOWLEDGEMENT 
This work was supported by the National Science Council 
under project 98-2221-E-011-103-. 
7. REFERENCES 
[1] Epson web page:  
[2] HP web page:  
http://www.epson.com/ 
[3] Canon web page:  
http://www.hp.com/ 
http://www.canon.com/ 
[4] Song G. and Qiao X.-L., “Color Image Enhancement 
Based on Luminance and Saturation Components”, 
Congress on Image and Signal processing, 3:307-310, 
2008. 
[5] You J.-Y. and Chien S.-I., “Saturation Enhancement 
of Blue Sky for Increasing Preference of Scenery 
Images”, IEEE Transactions on Consumer 
Electronics, 54(2):762-768, 2008.  
[6] Tang B., Sapiro G., and Caselles V., “Color Image 
Enhancement via Chromaticity Diffusion”, IEEE 
Transaction on Image Processing, 10(5):701-707, 
2001. 
[7] Ji T.-L., Sundareshan M. K., and Roehrig H., 
“Adaptive Image Contrast Enhancement Based on 
Human Visual “, IEEE Transactions on Medical 
Imaging, 13(4):573-586, 1994. 
[8] Xu B., Zhuang Y., Tang H., and Zhang L., “Object-
Based Multilevel Contrast Stretching Method for 
Image Enhancement”, IEEE Transactions on 
Consumer Electronics, 56(3):1746-1754, 2010. 
[9] Chang D.-C. and Wu W.-R., “Image Contrast 
Enhancement Based on a Histogram Transformation 
of Local Standard Deviation”, IEEE Transaction on 
Medical Imaging, 17(4):518-531, 1998. 
[10] Yeganeh H., Ziaei A., and Rezaie A., “A Novel 
Approach for Contrast Enhancement Based on 
Histogram Equalization”, pages 256-260, 2008. 
[11] Das S., Bandyopadhyay P., Paul S., Ray A. S. and 
Banerjee M., “A New Introduction towards Invisible 
Image Watermarking on Color Image”, IEEE 
International Advance Computing Conference, pages 
1224-1229, 2009. 
[12] Liao H.-Y. and Ye R.-S., “A Novel Digital Image 
Watermarking Approach Based on Image Blocks 
Similarity”, Congress on Image and Signal 
Processing, 5:626-630, 2008. 
[13] Wang S.-M., Fan Y., and Yu P., “A Watermarking 
Algorithm of Gray Image Based on Histogram”, the 
2nd International Congress on Image and Signal 
Processing, pages 1-5, 2009 
[14] Coltuc D. and Bolon P., “Color Image Watermarking 
in HSI Space”, International Conference on Image 
Processing, 3:698-701, 2000. 
[15] Gonzalez R. C. and Woods R. E., Digital Image 
Processing, New York: Prentice Hall, 3rd ed., 2008. 
[16] Noda H., Takao N., and Niimi M., “Colorization in 
YCbCr Space and Its Application to Improve Quality 
of JPEG Color Images”, the 14th International 
Conference on Image Processing, 4: 385-388, 2007.  
[17] Grgic S., Grgic M., and Mrak M., “Reliability of 
Objective Picture Quality Measures”, Journal of 
Electrical Engineering, 55(1): 3-10, 2004. 
[18] Almohammad A. and Ghinea G., “Stego Image 
Quality and the Reliability of PSNR”, the 2nd 
International Conference on Image Processing 
Theory Tools and Applications, pages 215-220, 2010. 
 
99 年度專題研究計畫研究成果彙整表 
計畫主持人：林昌鴻 計畫編號：99-2221-E-011-136- 
計畫名稱：低功率分散式智慧型攝影系統設計 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 6 6 100%  
博士生 0 1 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 1 1 100%  
研究報告/技術報告 0 0 100%  
研討會論文 1 1 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 6 6 100%  
博士生 0 1 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
 
