characteristic of CAVLC, an information bit is 
embedded by adaptively modifying the number of 
nonzero quantized AC coefficients in each macro- 
block of I frames. The proposed method can constrain 
the perceptual degradation and bit rate increasing, 
which are caused by embedding the information bits. 
In the 2nd year, we proposed an adaptive error 
concealment technique based on motion variation for 
H.264/AVC decoder. The method not only achieves 
significant PSNR but also is more efficient than 
well-known methods. Above-mentioned two efficient 
methods are applicable to be implemented in H.264/AVC 
CODEC. 
 
英文關鍵詞： Digital Authentication, Video Watermarking, Tamper 
Detection, Error Concealment 
 
  1
行政院國家科學委員會專題研究計畫成果報告 
H.264/AVC 標準下利用半脆弱浮水印之鑑識技術 
Forensics for H.264/AVC CODEC by Using Semi-fragile 
Watermarking  
 
計畫編號：NSC 99－2221－E－259－017－MY2 
執行期限：99 年 08 月 01 日 至 101 年 10 月 31 日 
主持人：林信鋒  國立東華大學資訊工程系 
計畫參與人員：羅昱宏、林志軒、蔣瑜婷、吳易儒、郭津伊、邱佳駿、 
歐陽龍祥、朱昱瑞、莊智堯 
 
 
一. 中英文摘要 
 
伴隨雲端議題的發酵，近年來越來越
多的產品應用與網路有密切的關聯，數位
視訊類產品亦是如此。網路頻寬的提昇與
行動網路的普及，加上視訊壓縮軟硬體技
術的躍進，使得數位視訊串流被廣泛地運
用於生活，隨時隨地可於網路上傳、觀看，
線上監控系統即是其應用之一；其次，各
類型的影音分享平台也是這類型應用之
一，如：YouTube、Facebook…等。因此，
如何對數位視訊串流做版權管理與數位驗
證，已越來越受重視，此外由於網路封包
的特性，串流在傳輸過程易有封包遺失的
狀況，尤其是無線的環境，故如何對損壞
的畫面做錯誤隱藏也是一門很重要的課
題。 
計畫第一年我們提出一種植基於浮水
印嵌入的數位驗證技術，適用於 H.264/ 
AVC 編碼端，我們利用 CAVLC 的特性，
藉由調整macro-block中非零的AC係數數
量，以達到嵌入資訊的目的，對於畫質的
破壞和位元率的增加非常輕微。第二年則
著墨於視訊串流的錯誤隱藏，我們於
H.264/AVC 解碼端提出一個以時間域資訊
為主、空間域資訊為輔的演算法，補償品
質勝過 Motion Copy，且時間複雜度僅略
增。兩年之成果，均有不錯的效果且時間
複雜度低，適合實作於 H.264/AVC 的軟硬
體架構中。 
 
關鍵詞： 
數位影像鑑識、視訊浮水印、竄改偵測、
錯誤隱藏 
 
Abstract 
 
More and more products are designed 
based on the network owing to the 
development of cloud computing technology. 
The multimedia industry also trends to the 
networking applications. On the other hand, 
  3
整個計畫的研究過程均以 H.264/AVC
為標準 CODEC，H.264/AVC [1]為目前最
先進的視訊編碼規格，擁有極高的壓縮率
與極佳的畫質，已被廣泛地運用，諸如：
藍光影音系統、廣播電視、Full-HD 數位
攝影機、監視系統…等。在學術研究上，
對於 H.264/AVC 的相關軟體實作，幾乎都
採用 JM [2]為主要架構，我們整個計畫亦
於此架構下進行模擬；第一年是在編碼（如
圖一）架構下做視訊驗證資訊的嵌入，第
二年則是在解碼架構（如圖二）下做錯誤
隱藏。 




 
圖一. H.264/AVC 之編碼流程 
 
 
圖二. H.264/AVC 之解碼流程 
 
本計畫第一年先對植基於 H.264/AVC
編碼器中的 Intra Frame視訊浮水印技術做
改善，力求 Bit Rate 變化率更低且對畫質
的破壞更小。其中，首先要改善的項目是
避開會對 Bit Rate 或畫質造成很大影響之
區域來做浮水印嵌入的動作，換句話說就
是要對嵌入區域做挑選的動作，以求之後
影響最小。 
本計畫第二年主要發展一個快速且效
果佳的視訊串流之錯誤隱藏方法：先植基
於時間域的錯誤隱藏方法，利用的是目前
公認也被採納入 JM 架構的 Motion 
Copy ； 再 根 據 我 們 的 觀 察 ， 利 用
H.264/AVC 可變區塊大小的特性（Variable 
Block Sizes）[3]，把動量較不一致的區塊
聯集起來，做空間域的錯誤隱藏方法，採
用的是期刊論文[4]所提之適應性錯誤隱
藏 順 序 調 整 的 方 法 （ Adaptive Error 
Concealment Order Determination, 以下簡
稱 AECOD）。實驗結果顯示，這樣的時間
域與空間域方法結合、互補，對於補償畫
面的畫質有顯著的提昇，且在處理時間上
也非常的快速。 
 
三. 研究方法 
 
於 H.264/AVC 上的錯誤隱藏方法，通
常有時間域與空間域兩大類，整體來說時
間域在視訊串流上的補償效果較好：
Motion Copy 是植基於時間域資料的錯誤
隱藏方法，當畫面發生毀損時，利用前一
張畫面相同位置巨區塊（Macro-block, 以
下簡稱 MB）的動量資訊，來做毀損 MB
的動量，如圖三所示。此演算法不但快速，
且補償效果極佳，補償出來畫面的 PSNR
遠比同為 JM 所採納的時間域方法 Frame 
Copy 優秀。 
 
圖三. Motion Copy 之示意圖 
 
植基於空間域的錯誤隱藏演算法方
面，AECOD[4]是一篇發表在國際知名期
刊 IEEE Transactions on Multimedia 的文
章，它會依照毀損區域周圍可用資訊做為
參考，當某方位的邊緣強度較高，則毀損
區域即從該方位之 MB 補償起，使用 BMA
（Boundary Match Algorithm）來比對周圍
可用區域，找到最合適的補償資料。圖四
[4]左為 JM 的空間域錯誤隱藏方法之預設
  5
圖七.『動量高變異性』之區域的處理流程 
 
    本方法架構於 Motion Copy 上，再加
上對於動量高變異性的區域做精進的處
理，所以效果比 Motion Copy 佳，時間上
也沒增加多少，比其他非 JM 的方法，處
理時間也少很多，實驗結果將呈現數據以
資證明。 
 
四. 結果與討論 
 
我們將此錯誤隱藏演算法實作於
H.264/AVC 的參考軟體 JM 16.2，主要比
較對象除了 JM 內建的 Motion Copy 之
外，另有兩篇知名的期刊論文（2010 年），
一為發表於 IEEE Transactions on Image 
Processing 的 HMVE[5]，另一為發表於
IEEE Transactions on Consumer Electronics 
的 RMVR[6]，兩者都是植基於時間域的錯
誤隱藏演算法：前者主要利用向量外插的
方式（Motion Vector Extrapolation），對區
域內每個 Pixel 逐一判斷，再批次做最佳
化處理；後者的概念則與我們的主架構頗
為類似，作者亦認為 Motion Copy 已經是
效果極佳的方法，所以力求於Motion Copy
上做精進，所以他們以 MB 為單位，用遞
迴的方式把 Motion Copy 而得的 MV 做最
佳化，但也因為是遞迴的關係，因此時間
複雜度相對比較高。 
 
4.1 實驗結果 
利用 JM16.2 實作時，我們的各項設
定與畫面大小如下表一所列，錯誤隱藏的
視覺品質方面，我們以 PSNR 來做比較，
表二上下組數據分別顯示整段視訊串流之
封包遺失率為 5%與 10%時，經各種錯誤
隱藏方法補償後的視覺品質比較表；處理
時間方面，則如表三所示。 
 
表一. 實作環境各項參數設定 
Profile/Level IDC 66,40 (Baseline) 
Frame Size CIF (352×288) 
Sequence Type IPPP (QP: I 28, P 28)
Frame Rate 30 frames/second 
Period of I Frame 15 
Search Range ±32 
Number of Reference 
Frame 
5 
File Mode RTP 
Packet Loss Rate 5%, 10% 
 
4.2 結論與建議 
觀察上述表二，在補償品質方面，我
們方法整體來說比 Motion Copy 進步，也
比近期兩篇期刊論文佳；其中可看出
Motion Copy 比起其他時間域錯誤隱藏的
方法[5]好，而植基於 Motion Copy 的方法
[6]則略勝一籌，我們的方法則更勝於[6]。 
根據表三的數據，在錯誤隱藏的處理
時間方面，亦可看出我們的方法在比起兩
篇期刊論文快速，且遠勝於遞迴處理的方
式[6]，而跟 Motion Copy 相比，平均下來
我們的方法在解碼時間上僅多 1~2 
ms/frame，表示我們在處理動量高變異性
區域（如圖七所示）之額外的時間負擔不
多。 
 
五. 計畫成果自評 
 
  7
表二. 與其他方法的 PSNR 比較 
Sequence(numbers) Error Free Error 
Motion 
Copy 
HMVE [5] RMVR [6] Proposed
5% 
bus(150) 35.82 21.01 28.75 28.46 29.59 30.38 
mobile(300) 35.03 18.62 32.13 30.95 32.41 32.52 
foreman(300) 36.95 19.11 34.21 33.70 33.46 34.60 
football(260) 37.06 21.48 33.48 30.83 33.42 33.62 
carphone(382) 38.01 19.71 32.07 31.63 31.53 32.20 
tempete(260) 35.85 24.18 33.98 33.63 33.98 34.15 
city(300) 35.55 24.27 33.60 33.45 33.86 34.01 
stefan(150) 36.41 19.87 30.39 29.86 30.99 31.05 
AVERAGE 36.34 21.03 32.33 31.56 32.41 32.82 
10% 
bus(150) 35.82 20.02 27.81 27.62 28.89 29.22 
mobile(300) 35.03 13.41 28.90 27.22 29.16 29.29 
foreman(300) 36.95 13.83 30.69 29.99 29.27 31.09 
football(260) 37.06 18.12 28.32 28.03 28.14 28.43 
carphone(382) 38.01 15.91 29.86 28.48 29.69 29.83 
tempete(260) 35.85 20.79 31.72 31.12 31.72 31.87 
city(300) 35.55 17.17 30.99 30.64 30.47 31.32 
stefan(150) 36.41 17.14 28.72 28.72 28.94 29.45 
AVERAGE 36.34 17.05 29.63 28.98 29.54 30.06 
 
表三. 與其他方法的處理時間比較（單位：ms/frame） 
Sequence(numbers) Error Free
Motion 
Copy 
HMVE [5] RMVR [6] Proposed 
5% 
bus(150) 8.99 9.26 14.12 84.24 9.37 
mobile(300) 9.48 9.57 17.63 17.42 10.53 
foreman(300) 7.00 7.29 14.78 37.19 8.04 
football(260) 9.38 10.92 16.67 685.54 12.31 
carphone(382) 6.78 7.11 14.08 76.20 7.85 
tempete(260) 9.29 8.88 15.32 15.41 9.54 
city(300) 6.71 7.23 15.12 14.55 7.25 
stefan(150) 9.52 8.99 15.38 36.19 9.81 
AVERAGE 8.39 8.66 15.39 120.84 9.34 
10% 
bus(150) 8.99 9.31 24.29 198.21 11.15 
mobile(300) 9.48 10.29 30.69 41.28 13.12 
foreman(300) 7.00 7.93 28.22 364.98 9.85 
football(260) 9.38 9.76 29.35 2010.01 18.5 
carphone(382) 6.78 7.71 26.11 171.55 9.48 
tempete(260) 9.29 10.15 27.82 42.24 12.82 
city(300) 6.71 7.74 28.53 28.47 8.53 
stefan(150) 9.52 9.33 24.43 180.46 10.83 
AVERAGE 8.39 9.03 27.43 379.65 11.79 
 
個人利用開會之便，受企業邀請，走訪江蘇鹽城市，與企業、大學交流互動。 
 
四、 建議 
本次會議是國際影像及信號處理會議暨第四屆國際生物醫學工程與資訊會議合併召開，學界參與
此次會議的學者不少，也發表了很多相關領域的研究成果。個人非常期待能多參與國際學術活動，建
立長期的學術研究交流。 
 
五、 攜回資料名稱及內容 
 
名稱：CISP 2011 會議論文集與 CD。 
 
六、 其他 
 
感謝國科會提供的研究經費補助，讓本人順利完成研究並至上海市發表論文。 
 
 
A. Double JPEG Compression Features 
Double JPEG compression is the secondary JPEG 
compression process for image with different quantization 
matrix q1 (initial matrix), q2 (secondary matrix). If and only if 
q1≠q2, the DCT coefficients are considered as being doubly 
compressed. Detecting tampered JPEG image via DCT 
coefficient analysis was proposed by Lin et al. [12]. They 
proved the assumption that an image containing a double 
quantization (DQ) effect is forged was wrong. In this article, 
they focused on JPEG images and proposed detecting tampered 
images by examining the DQ effect hidden among the DCT 
coefficients. 
In a more general supposition, forged images likely 
undergo a double compression. The first compression is proper 
to the un-tampered image, and the second compression is 
applied to saving the forgery image. Although double 
compression is not considered as a symptom of forgery 
systematically, it introduces specific artifacts in the DCT 
coefficient histograms that represent important cues in forgery 
detection. In fact, the JPEG compression is the rounding 
function rather than the floor function. Therefore, Lin et al. [12] 
provided the analysis of DQ effect based on quantization with 
the rounding function. Their method more accurately explains 
the DQ effect caused by double JPEG compression. This is 
shown in Figure 1. 
 
(a) Single quantized signal, q=4 (b) Single quantized signal, q=3
 
(c) Double quantized signal, 
3,4   (1st quantization step) 
(d) Double quantized signal, 
4,3    
Figure 1. Effects of double quantization on signals 
when   , the histogram can exhibit some periodic 
pattern of peaks and valleys (Figure 1 (c)). Conversely, if 
  , then n(v)=0 for some v. This means that the histogram 
after DQ has periodically missing values (also refer to Figure 1 
(d)). In both cases, it could be viewed as showing peaks and 
valleys periodically. This is called the DQ effect. 
B. Speeded Up Robust Features (SURF) 
The SURF algorithm [13] is introduced in this sub-section. 
For our application, SURF features have the most favorable 
computational characteristics. The SURF algorithm consists of 
three main steps: At first, generating SURF keypoints. After 
that, detecting interest points in the image and then 
constructing a local feature descriptor for each interest point. 
These three steps are briefly described in the following. 
1) SURF Keypoints Generation 
The SURF approach describes the keypoint detector and 
descriptor. Keypoints are found by using Fast-Hessian detector 
that bases on an approximation of the Hessian matrix for a 
given image point. The responses to Haar wavelets are used for 
orientation assignment, before the keypoint descriptor is 
formed from the wavelet responses in a certain surrounding of 
the keypoint. 
2) Interest Point Detection 
The detector in SURF uses a basic Hessian matrix 
approximation to detect interest points and the integral image is 
applied to greatly reducing the computation time. The integral 
image allows fast computation of the rectangular or square box 
type convolution filters. Given a point x=(x,y) of the integral 
image containing the sum of all pixels within the rectangle 
region from the origin to x in the input image, an image I, the 
Hessian matrix ),( xH  in x at scale   is defined as (1). 
 


),(),(
),(),(
),( 

xx
xx
x
yyxy
xyxx
LL
LL
H  
where ),( xxxL  is the convolution of Gaussian second order 
derivative )(/ 22 gx  with the image I in point x, and 
similarly for ),( xxyL  and ),( xyyL . 
In contrast with SIFT, which approximates Laplacian of 
Gaussian (LoG) with Difference of Gaussians (DoG), SURF 
approximates second order Gaussian derivatives with box 
filters. Image convolutions with these box filters can be 
computed rapidly by using integral images. The location and 
scale of interest points are selected by relying on the 
determinant of the Hessian. Hereby, the approximation of the 
second order derivatives is denoted as Dxx, Dxy, and Dyy. By 
choosing the weights for the box filters adequately, an 
approximation for the Hessian’s determinant is found by (2). 
 2)9.0()det( xyyyxxapprox DDDH   
Interest points are localized in scale and image space by 
applying non-maximum suppression in a 333   
neighborhood. Finally, the maximum found for the determinant 
of the approximated Hessian matrix are interpolated in scale 
and image space. 
3) Interest Point Description 
In first step, SURF constructs a circular region around the 
detected interest points in order to assign a unique orientation 
to the former and thus gain invariance to image rotations. In 
second step, the SURF descriptors are constructed by 
extracting square regions around the interest points. These are 
oriented in the directions assigned in the previous step. The 
local region centered on the interest point is first divided into 
44  sub-regions in order to retain some spatial information. 
Finally, the wavelet responses in horizontal dx and vertical 
directions dy are summed up over each sub-region and form the 
first set of entries in the feature vector. To bring in information 
In (5) and (6), the h(k) denotes the k-th bin of DCT 
coefficient value in the histogram h, and Pru and Prt are the 
estimative value of non-forged block and forged block, 
respectively. From the Bayesian approach, we can use the 
posterior probability to compute the forged block and non-
forged block, respectively. Note that if the block represents the 
(s0+i)-th bin, the posterior probability of it being a forged block 
or non-forged block is computed as (7). 

rurt
ru
u
rurt
rt
t PP
PisP
PP
PisP  )()( 00     ,        
Finally, we use occurrence counting for the probability of 
Pt and Pu in the image. If Pt is greater than Pu, the counting 
function count(Pt) is marked 0; otherwise, the counting 
function count(Pu) is marked 255. We can decide whether the 
image is forged or non-forged for splicing forgery by the above 
steps. 
B. The proposed Copy-move Image Detection 
Copy-move forgeries are that parts of the image are copied-
and-pasted to different location in the same image, often after 
being modified by geometrical or illumination transformations. 
Actually, the copied region has the same appearance of the 
original one, thus the keypoints extracted in this region will be 
very similar to the originals. The SURF feature descriptors 
have strong stability and a good performance on different kind 
of image post-processing such as JPEG compression, rotation, 
scaling, etc.. For this reason, the proposed copy-move forgery 
detection approach is based on SURF algorithm. 
After pre-processing, we firstly set the image I for down-
sampling by )(IYS  , where   is a scale factor. Then, we 
segment the image S into overlapping sub-blocks and name Bi. 
To avoid the size of source image being too large, we set the 
adaptive block size by si aNMB )(  , where sa  is an 
adaptive parameter. The experimental results are affected by 
the different adaptive parameter. 
To find image keypoints and collect image feature by 
SURF algorithm, each sub-blocks Bi has to extract the interest 
point together with the source image. After the keypoints of 
sub-blobks Bi and source image S are collected, we build the 
matrix of recording keypoints Bik, Sk and feature descriptors VBi, 
VS. To perform the matching decision (i.e. “Are these two 
keypoints the same or not?"), we calculate the Euclidian 
distances to all keypoints and feature descriptors between Bik, 
and Sk. If the difference of the VBi and VS are smaller than a 
predefined threshold T1 (empirically fixed to 0.3), the number 
of keypoints Ck will be counted. If Ck is greater than threshold 
T2, we have to employ the sum of absolute differences (SAD), 
(8), for block pairs in the decision of similarity among blocks. 
  




8
0
8
0
,),(),,,(
i
i
j
j
jsirSjyixSsryxSAD  
where S is the current block in source image and S’ is the 
maximum matching pairs of the sub-block. 
Based on the above matching decision, the matched 
keypoints can be found and the copied region can further be 
determined. 
C. Post-processing 
According to sub-section A, if the suspicious image of 
splicing is obtained, we perform morphological operations to 
fill the holes in the marked regions, and remove the small and 
isolated regions. There are four cases generated by the 
proposed technique. I1 is the result image of copy-move image 
detection. I2 is the result image of splicing image detection. 
These cases are defined in the following: 
 
When the suspicious image is not detected by copy-move 
and splicing approaches, the final result is non-forged image. If 
the final result is splicing image, the suspicious image could be 
detected by splicing approach. In contrary, if the final result is 
copy-move image, the suspicious image can be detected by 
copy-move approach; however, the format of suspicious image 
is JPEG compression, so the suspicious image can also be 
detected by splicing approach. We can utilize the property to 
locate the copy-move regions and actually find out non-original 
regions. Similarly, when the suspicious image is forged by 
copy-move and splicing approaches, we can utilize the property 
to automatically locate the copy-move regions and actually find 
out non-original regions. 
IV. EXPERIMENTAL RESULTS 
In our experiments, Table I lists the default values of the 
adjustable parameters in our experiment. The ISCASimages 
[14] database which consists of 20 images and the size of the 
images ranges from 1024×1024 to 2600×2000 is used in our 
experiment. 
TABLE I.  DEFAULT PARAMETER VALUES IN OUR PROPOSED TECHNIQUE 
7.0  threshold in interest point matching (Section 3.2) 
8bM  the block size of search range (Section 3.1) 
5.0  a scale factor for down-sampling (Section 3.2) 
3.01 T  the threshold of the minimum difference between VB and VS 
(Section 3.2) 
20sa an adaptive parameter of block size (Section 3.2) 
CASE forged type OF 
 1 :  IF I
1
==false && I
2
==false  
          Display “None” 
      ENDIF 
 2 :  IF I
1
==false && I
2
==true  
          Display “Splicing image” 
      ENDIF 
 3 :  IF I
1
==true && I
2
==false  
          Display “Copy-move image” 
      ENDIF 
 4 :  IF I
1
==true && I
2
==true  
          Display “Both” 
      ENDIF 
ENDCASE
國科會補助計畫衍生研發成果推廣資料表
日期:2012/12/15
國科會補助計畫
計畫名稱: H.264/AVC標準下利用半脆弱浮水印之鑑識技術
計畫主持人: 林信鋒
計畫編號: 99-2221-E-259-017-MY2 學門領域: 視訊與影像分析
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無。 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
