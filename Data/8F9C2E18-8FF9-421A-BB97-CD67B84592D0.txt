 
attentions in recent years and has become an 
important method in stock price forecasting 
problems [2,3]. 
 A stock price data may be affected by 
some underlying factors like seasonal 
variations or economic events [4,5,6]. For 
example, in [4], the observed daily stock 
returns reflected the stock market reaction to a 
few factors such as release of various 
economic indicators, company news, 
psychological factors, government 
intervention, or political issues. Kiviluoto and 
Oja [5] showed that the underlying factors 
affected the cashflow time series of several 
stores belonging to the same retail chain were 
trends, holiday effects, seasonal variation and 
competition. Therefore, in developing a SVR 
forecasting model, the first important step
price data) m
 2
 is 
 
example. Since principal 
pared to the SVR 
usually feature extraction. If the 
underlying/interesting information that can’t 
be observed directly from the observed 
original data can be revealed through 
transforming the input space into the feature 
space with suitable feature extraction methods, 
the prediction performance of SVR will be 
improved by using the features as inputs.  
 Independent component analysis (ICA) is 
a novel feature extraction technique. It aims at 
recovering independent sources from their 
mixtures, without knowing the mixing 
procedure or any specific knowledge of the 
sources [7]. The independent sources, called 
independent components (ICs), are hidden 
information of the observable data. ICA model 
can be classified as linear ICA (LICA) and 
nonlinear ICA (NLICA) models. Linear ICA 
model is mainly based on the assumption that 
the observed mixture data are generated by a 
linear mixing from ICs. Conversely, the 
nonlinear ICA model assumes that the 
observations are a nonlinear combination of 
ICs. Linear ICA is suitable when it is 
reasonable to assume that the mixing 
mechanism is linear. It has been employed 
successfully in various fields of multivariate 
data processing, from signal processing and
face recognition to time series prediction 
[4,5,6,7]. However, in many realistic cases, 
the observed mixture data (i.e. observed stock 
ight be a nonlinear mixture of 
latent source signals. Since the nonlinear 
mixing model is more realistic and practical, 
NLICA has the potential to become rather 
powerful tools. Nonlinear ICA remains an 
active field of research, few applications of 
NLICA are proposed in literatures [8,9,10].  
 In this study, a stock price prediction 
model by integrating NLICA and SVR is 
proposed. The proposed approach first uses 
NLICA on the input space composed of 
original forecasting variables into the feature 
space consisting of independent components 
representing underlying/hidden information of 
the original data. The hidden information of 
the original data could be discovered in these 
ICs. The ICs are then used as the input 
variables of the SVR for building the 
prediction model. In order to evaluate the 
performance of the proposed approach, the 
Nikkei 225 closing cash index is used as the 
illustrative 
component analysis (PCA) and kernel 
principal component analysis (KPCA) are two 
well known methods for feature extraction 
[11], the SVR models that use PCA and KPCA 
as feature extraction are generated for 
comparison. Besides, the performance of the 
proposed method is also com
  4
FORMAX method in two ways: (1) it is 
tput [10]. 
n l
nform
entropy, yy ppH (log)()( ∫−=  
ar, tra
IN
able to perform nonlinear ICA, and (2) it uses 
adaptive no
These no ated to 
the statistical distributions of the components, 
and the adaptively allows the method to deal 
with components with a wide range of 
distributions.  
 The MISEP tries to perform Eq.(4) 
according to a m  
The mutual i ation of the components of 
y is defined as [10] 
nlinearities at the ou
linearities are intimately re
utual information criterion.
 
∑ −= )()()( yy HyHI i                (5) 
 
where H denotes Shannon’s dif
continuous variables; The mutual information 
I(y) is non-negative, and is zero if the 
components of y are mutually statistically 
independent; p(y) represents the probability 
density of the multidimensional random 
variable y; )( ii yp  will denote the marginal 
density of the i-th component of y.  
 The mutual information is not affected by 
invertible transformations made on a 
per-component basis. That is, if one performs 
invertible, possibly nonline nsformations 
on individual components of y, )( iii yz
ferential 
yy d) , for
ψ= , 
then I(z)=I(y). However, Eq.(5) shows that to 
estimate mutual information I(y) one needs to 
estimate the marginal densities )( ii yp . In 
principle, the joint density p(y) should also be 
estimated. In practical situations one normally 
has access only a finite set of observations x. 
From these, the MISEP method can compute a 
finite set of vectors )(xy G= , given a 
transformation G, but it does not have access 
[10]. These 
ensities have to be estimated from those data. 
he advantage of 
mized according to a 
ngle objective function, the output entropy. 
For more detail inf
lgorithm, please refer to Almeida [10]. 
l intelligent forecasting tool based on 
to the actual densities )( ii yp
d
It estimates the components’ cumulative 
probability functions jointly with the 
optimization of the transformation G. The 
resulting ICA method has t
using a single, specialized multiplayer 
perceptron (MLP), opti
si
ormation about MISEP 
a
 
2.2 Support Vector Regression 
 
 Support vector regression (SVR) is an 
artificia
statistical learning theory and structural risk 
minimization principle [1].  
 The SVR model can be expressed as the 
following equation [1]: 
 
( ) ( )( ) bf +⋅= xzx φ                (6) 
where z is weight vect
 
or, b is bias and )(xφ  
is a kernel function which use a non-linear 
nction to transform the non-linear input to 
Vapnik [1] 
fu
be linear mode in a high dimension feature 
space. 
 Traditional regression gets the 
coefficients through minimizing the square 
error which can be considered as empirical 
risk based on loss function. 
introduced so-called ε-insensitivity loss 
function to SVR. It can be express as: 
 
⎩⎨
⎧=− ())((ε fyfL xx −−0
) εy   
otherwise
)( if ε≥− yf x    (7) 
 
where ε defined the region of ε-insensitivity, 
when the predicted value falls into the band 
  
Fig. 1. Schematic representation of the 
proposed prediction model. 
 
 
 6
 
4. Experimental Results 
 For evaluating the pe  
proposed NICA-SVR prediction model, the 
daily Nikkei 225 closing cash index is used in 
is study. In forecasting Nikkei 225 closing 
⎢⎢x
 In this study, d=3 is used and therefore 
re totally 1023 data points in the dataset and 
the daily Nikkei 225 closing cash prices are 
shown in Figure 2. The first 810 data points 
(79.17% of the total sample points) are used 
as the training sample while the remaining 211 
The prediction results of the proposed 
an
rformance of the
th
cash index, the previous day’s closing index is 
the most important forecasting variable. Since 
the feature extraction methods used in the 
study, i.e. NLICA, linear ICA, PCA and 
Kernel PCA, are restricted to using multiple 
variables, the embedding framework [14] 
using delay coordinate vectors is used in this 
study to obtain a multidimensional 
representation of the univariate forecasting 
variable. For example, a univariate forecasting 
variable of size t×1  can be reformed as 
multiple forecasting variables of size 
( )1+−× dtd  using the following equation: 
⎤⎡ +− )1(,    ,  )2(   , )1( dtxxx L
⎥⎥
⎥⎥
⎦⎢
⎢
⎣ +
+−
)( ,  ),1(),(
                               
)2(,    ,  )3(   ),2(
txdxdx
dtxx
L
MMMM
L          (10) 
 
three forecasting variables are used for 
predicting the Nikkei 225 closing cash index. 
The daily data of futures and cash prices from 
March 1, 2004 to February 29, 2008 of the 
Nikkei 225 cash index provided by 
Bloomberg are collected in this study. There
Prediction results 
Original Predicting Variables 
Support Vector Regression 
IC2 … ICn IC1 
Nonlinear independent component analysis 
Data Smoothing 
 
a
data points (20.83% of the total sample points) 
are used as the testing sample.  
 
m
an
odel are compared to the SVR model 
without feature extraction (called single SVR 
model), and the SVR models that use LICA 
(called LICA-SVR), PCA (called PCA-SVR) 
d kernel PCA (called KPCA-SVR) as 
preprocessing tool. The prediction 
performance is evaluated using the following 
performance measures, namely, the root mean 
square error (RMSE), mean absolute 
difference (MAD), me  absolute percentage 
error (MAPE) and directional accuracy (DA). 
 
10000
11000
12000
13000
00
00
00
1 101 201 301 401 501 601 701 801 901 1001
data points
pr
i
160
17000
18000
140
150
ce
Fig. 2. The daily Nikkei 225 closing prices
from March 1, 2004 to February 29, 2008. 
 
In the modeling of single SVR m l, the 
three forecasting variables are directly used as 
input variables. In selecting the parameters for 
modeling SVR, the parameter set (C=29, 
 
ode
ε =2-9) is used as the start point of grid search 
for searching the best parameters. The testing 
results of the SVR model with combinations 
  8
eviation between the actual and predicted 
values using the proposed NLICA-SVR model. 
better forecasting result than the comparison 
models in terms of prediction error and 
prediction accuracy. 
 The actual Nikkei 225 closing price values 
and predicted values from the NLICA-SVR, 
LICA-SVR, PCA-SVR, KPAC-SVR and 
e and shown in Figure 3. 
 can be observed from Figure 3 that the 
predicted valu
m
and its predicted values from the NLICA-SVR, 
LICA-SVR, -SVR and 
singl
p
R. The Nikkei 225 closing cash index 
is 
on using 
est 
rediction accuracy in the datasets. It 
outperformed t ethods used in 
is study. According to the experiments, it 
 data and improve the prediction 
成果自評 
d
PCA-SVR, KPAC
e SVR models. 
 
5. Conclusion 
This paper has resented a stock price 
prediction model by integrating nonlinear ICA 
and SV
Moreover, compared to the LICA-SVR, 
PCA-SVR, KPAC-SVR and single SVR 
models, the proposed NLICA-SVR model has 
t ti 09
ten
propos N id
the highes DA ra o which is 80. . DA 
provides a good measure of the consis cy in 
prediction of the price direction. Thus, the 
ed LICA-SVR model prov es a used in this study for evaluating the 
performance of the proposed method. This 
paper compared the forecasting performance 
of the proposed NLICA-SVR, LICA-SVR, 
PCA-SVR, KPAC-SVR and single SVR 
models in stock index predicti
prediction error and prediction accuracy as 
criteria. Experimental results showed that the 
proposed NLICA-SVR model can produce the 
lowest prediction error and the high
single SVR models are illustrated in Figure 3. 
Note that, to save space, the last 50 data points 
of the Nikkei 255 index in Figure 2 are used 
as illustrative exampl p
It he comparison m
es obtained from the proposed th
odel are closer to the actual values than 
those of the comparison models. 
 
TABLE III 
The Nikkei 225 closing prices forecasting 
results using the NLICA-SVR, LICA-SVR, 
PCA-SVR, KPCA-SVR and single SVR 
models 
Models RMSE MAD MAPE DA 
NICA-SVR 0.00474 0.00344  0.0354% 80.09%
LICA-SVR 0.00774 0.00539  0.0558% 75.36%
PCA-SVR 0.00679 0.00417  0.0432% 79.62%
KPCA-SVR 0.00811 0.00618  0.0640% 68.72%
SVR 0.00677 0.00420  0.0436% 79.62%
12500
12750
13000
13250
13500
13750
14000
14250
14500
14750
15000
15250
15500
Data points
Pr
ic
e
Actual price
NICA+SVR
LICA+SVR
PCA+SVR
Single SVR
KPCA+SVR
 測模式
can be concluded that the nonlinear ICA can 
effective discover the hidden information of 
the original
performance of SVR. 
 
六、計畫
本研究導入近年來快速發展用於訊號
分離之獨立成分分析（ICA）技術於時間序
列預測問題中。並且以較少用於實際應用問
題上的非線性 ICA 為研究工具，提出結合
非線性 ICA與 SVR之財務時間序列預測模
式。 
本研究計畫成果與原計畫內容之相符，實
驗結果顯示所提的財務時間序列預測模型
能獲得良好的預測績效。本計劃之完成有助
於發展出一新穎且完整的財務時間序列預
，作為企業界在實際進行金融投資決
策時，一項有效的評估工具。。 
  此外，本計畫之研究成果已發表兩篇研討
Fig. 3. The actual Nikkei 225 closing prices 
  10
於
w
&Other Applications of Applied Intelligent Systems)，現將此兩篇研討會文章之內容摘錄如
下 只呈
 
(1) 題目：非線性獨立成份分析於股價指數特徵萃取之研究( ) 
為例。本研究針對
指數有關的變數萃取其特徵，這 6 個變數分別為前一日現貨最高指數、前一日現貨最低指
數、當 一日現貨 數收盤 ital 
International Indices, M ex Futures)，所採用的
料期間為 2005年 1月 3日至 2008年 7月 23日共 874個交易日，圖 1為此 6個變數的時
間序
本計畫之研究成果已有一篇期刊論文正於國際
果已於兩個研討會發表，一篇已發表於
IEA-AIE 2009研討會(The T
知名期刊審稿中。此外，本計畫之部分成
年度工業工程年會暨研討會，另一篇發表
nference on Industrial, Engineering 
97
enty Second International Co
，並 均
 
本研究應用 NLICA
exchange capitalization wei
且為了節省篇幅， 現實
於股價指數之特徵萃取，並以台灣加權股價指數
ghted stock index, TAIEX)
驗成果的部分： 
發表於 97年度工業工程年會
(Taiwan stock 
6個與台灣加權股價
日現貨開盤指數、前 收盤價、前一日摩台指 價(Morgan Stanley Cap
SCI)、前一日台指期貨收盤價(TAIEX Stock Ind
資
列走勢圖。 
 
0 100 200 300 400 500 600 700 800 900
3.75
3.8
3.85
3.9
4
3.95
 0 100 200 300 400 500 600 700 800 900
3.7
3.75
3.8
3.85
3.9
3.95
4
0 100 200 300 400 500 600 700 800 900
3.7
3.75
3.8
3.85
3.9
3.95
4
 
當日現貨開盤價 
 
前一日現貨最高價 前一日現貨最低價 
0 100 200 300 400 500 600 700 800 900
3.75
3.8
3.85
3.9
3.95
4
 0 100 200 300 400 500 600 700 800 900
2.35
2.4
2.45
2.5
2.55
2.6
 0 100 200 300 400 500 600 700 800 900
3.75
3.8
3.85
3.9
3.95
4
 
前一日台指期貨收盤 前一日現貨收盤價 前一日摩台指數收盤 
圖 1 6個與台灣股價指數相關變數的走勢圖 
 
圖 2為利用 NLICA針對圖 變數所得到的獨立成份分析。
將圖 與圖 2相較可知，NLICA所估計的獨立成份可以代表股價指數中不同的資訊，如股
價指
，
1之 6個與台灣股價指數相關
1
數的主要趨勢、架構、主要波動處或是雜訊資料。 
 
0 100 200 300 400 500 600 700 800 900
-0.2
-0.15
-0.1
-0.05
0
0.05
0.1
0.15
 0 100 200 300 400 500 600 700 800 900
-0.2
-0.15
-0.1
-0.05
0
0.05
0.1
0.15
0.2
0.25
 0 100 200 300 400 500 600 700 800 900
-0.2
-0.1
0
0.1
0.2
0.3
0.4
0.5
0.6
 
IC1 IC2 IC3 
  12
training sample while the rem le points) are used 
as the testing samp
The prediction results of N model without using 
NLICA  and BPN model 
(called LICA-BPN m ance is 
evaluated using the following perf an square error (RMSE), 
mean absolute difference (MAD), mean absolute percentage error (MAPE) and directional 
accu
 
aining 201 data points (20.01% of the total samp
le.  
 the proposed model are compared to the BP
 preprocessing tool (called single BPN model), and integrated linear ICA
odel) which uses LICA as preprocessing tool. The prediction perform
ormance measures, namely, the root me
racy (DA). 
18000
20000
8000
10000
12000
14000
16000
1 201 401 601 801 1001
 
Figure 1. The daily Nikkei 225 closing cash prices from 2/2/2004 to 2/29/2008. 
 
 
Figure 2. The daily values of the four forecasting variables from 2/2/2004 to 2/29/2008. 
 
In the modeling of single BPN model, the four forecasting varia  are directly used as 
input variables. T d.  
irst, the origin d 
then pass timate ICs. U -BPN 
model uses the linear ICA model to estimate ICs from the smoothed forecasting variables. 
of the tim  
and LICA  from Figures 3 and 4 that the 
ICA or linear ICA for the estimation, can be used to represent independent and di erent 
underlying factors like trends, seasonal variations, market news, government intervention, or 
economic event , it also can be 
observed from the figures that the ICs of nonlinear ICA model can enhance/discover more 
x1 
 
 
x2 
 
 
x3 
 
 
x4 
bles
he input layer has four nodes as four forecasting variables are use
For the proposed NLICA-BPN model, f
ed to nonlinear ICA model to es
al forecasting variables are smoothed an
sing the similar process, the LICA
Figures 3 and 4, respectively, show the four ICs 
 models. It can be seen
e series data in Figure 2 using NLICA
ICs, regardless of using nonlinear 
ff
s that affect the time series of stock prices simultaneously. However
  14
Lee, T.S., Chen, N.J. 2002, Investigating the Information Content of Non-Cash-Trading Index 
Futures using Neural Networks. Expert Systems with Applications, 22, 225-234. 
  2
理之重要研究領域。圖
 
2與3為大會開幕的會場 
 
圖2 
 
圖3 
 
為了參加此一盛會，本人由國科會計劃 (NSC 97-2221-E-231-008) 之出席國際會議項目
助費用，發表一篇名為『Using Independent Component Analysis and Support Vector 
ies Forecasting』的論文。被安排於Decision Support Systems的場次發
表
此次APIEMS主辦單位將 “To enable the exchange of knowledge and research results about 
補
Regression in Time Ser
。 
 
二、與會心得與建議 
  4
 
 
 
 
附錄：發表之論文： 
Using Independent C nd Support Vector  
Regression in  Forecasting 
Department nagement 
Ching Yun Un 0, TAIWAN 
Gr nt 
Fu Jen Catholic University, T pei County 24205, TAIWAN 
omponen  Analysis at
 Time Series
 
Chi-Jie Lu†  
 of Industrial Engineering and Ma
iversity, ng-Li 32
il: jerrylu@cyu.edu
 Ju
Ema .tw  
 
Tian-Shyug Lee 
aduate Institute of Manageme
ai
Email: 036665@mail.fju.edu.tw 
 
Chih-Chou Chiu 
Institute of Commerce Automation and Management 
National Taipei University of Technology, Taipei 10608, TAIWAN 
Email: Chiu3c@ntut.edu.tw 
 
Abstract.  In this paper, a time series forecasting approach by integrating independent component 
analysis (ICA) and support vector regression (SVR) is proposed. ICA is a novel statistical si
processing technique that was originally proposed to find the latent source signals from observed 
mixture signal without knowing any prior knowledge of the mixing mechanism. SVR is an artificia
intelligence forecasting technique and has been widely applied in time series prediction problems. 
he proposed approach firs
gnal 
l 
t uses ICA to the forecasting variables for generating the independent 
s 
a ses 
the denoised build the forecasting model. In order to evaluate the 
performance of the proposed approach, the TAIEX (Taiwan Stock Exchange Capitalization 
Weighted Stock Index) closing cash index is used  the illustrative example. Experimental results 
odel outperforms the SVR mo
and random walk model.  
ysis
 
T
components (ICs). After identifying and removing the ICs containing the noise, the rest of the IC
re then used to reconstruct the forecasting variables which contain less noise. The SVR then u
 forecasting variables to 
 as
show that the proposed m del with non-filtered forecasting variables 
, support vector regression, time 
arded as one of the most challenging 
applications of time series forecasting. Neural networks 
have been found to be useful techniques for modeling time 
series due to their ability to capture subtle functional 
relationships among the empirical data even though the 
underlying relationships are unknown or hard to describe 
(Zhang et al. 1998; Vellido et al. 1999; Lee and Chen 2002; 
Lee and Chiu 2002).  
Support vector machine (SVM) based on statistical 
learning theory is a novel neural network algorithm (Vapnik 
2000). It can lead to great potential and superior 
performance in practical applications. This is largely due to 
the structure risk minimization principles in SVM. 
Therefore, the SVM has attracted the interest of researchers 
and has been applied
 
Keywords: Independent component anal
series forecasting.  
 
1. INTRODUCTION 
 
As financial time series are inherently noise and 
non-stationary it is reg  many applications such as texture 
classification, image recognition, data mining and 
bioinformatics (Norinder 2003; Li et al. 2003; Shin et al. 
2005). With introduction of Vapnik’s ε-insensitivity loss 
function, the regression model of SVMs, called support 
vector regression (SVR), has been receiving increasing 
attention to solve nonlinear regression estimation problems. 
It has been successfully applied in different problems of 
time series prediction such as production value forecast of 
machinery industry, engine reliability prediction and 
financial time series forecasting (Tay and Cao 2003, 2001; 
 problem is formulated. Consider a set of data 
{ }niii qG 1) ,( == x , where ix  is a vector of the model inputs, 
iq  is actual value and represents the corresponding scal
⎩⎨
⎧ −−=
0
)(
)),((
ε
ε
qf
qfL
x
x   
otherwise
)( if ε≥− qf x
   (4) 
where ε  is a precision parameter representing the 
ion, 
f g. 1). A schematic 
re
ar 
ou
radius of the tube locate around the re
)(x  (see the broken lines in Fi
gression funct
tput, and n is total number of data patterns. The objective 
of the regression analysis is to determine a function )(xf , 
so as to predict accurately the desired (target) outputs ( q ). 
Thus, the typical regression function can be formulated as 
δ+= )( ii fq x , where δ  is random error with
presentati  SV  using on of the R ε -insensitive loss 
function is illu  Figure 1. In Figure 1, the region 
enclosed by s known as “
strated in
 the tube i ε -insensitive zone” 
since the loss function assumes a zero value in this region 
and a result it does not penalize the prediction errors with 
magnitudes smaller than ε . 
The weight vector (v) and constant (b) in Eq. (3) can be 
estimated by minimizing the following regularized risk 
function (Vapnik 1999, 2000): 
 distribution 
of classified as 
lin
 ),N(0 2σ . The regression problem can be 
ear and nonlinear regression problems. Co ed to the 
linear regression problem, the nonlinear regression  
is more difficult to deal with. The SVR was mainly 
developed for tackling the nonlinear regression problem. 
To solve a nonlinear regression problem, in SVR, the 
inputs are first nonlinearly mapped into a high dimensional 
feature space (F) wherein they are correlated linearly with 
the outputs. The SVR formalism considers the following 
linear estimation function (Vapnik 2000):  
mpar
 problem
∑
=
+= n
i
iie qfLn 1
2
2
) ),((1CR(C) vx     
where   ),(( qfLe x is 
1     (5) 
)  ε -insensitive loss function in 
Eq. (4); 2
2
1 v  is the regularization term which controls 
the trade-off between the complexity and the approximation 
accuracy of the regression model to ens
( ) ( )( ) bf +Φ⋅= xvx                 (3) 
where, v is weight vect r, b is a constant, )(xΦ  denotes 
a mapping function in the feature space, and 
o
( )( )xv Φ⋅  
describes the dot production in the feature space F. In SVR, 
the problem of n
ure that the model 
possesses an improved generalized performance; C is 
re
trade-off betwee gularization term. 
B
gularization constan ecify the t, and is considered to sp
n the empirical risk and reonlinear regression in the lower dimension 
 
hat is, 
th
input space (x) is transformed
problem into a high dimension 
 in ressionto a linear reg
feature space (F). T
e origin optimization problem involving a nonlinear 
regression is recast as searching the flattest function in the 
e space, and not in the input space.  
A number of cost functions such as the Laplacian, 
Huber’s Gaussian and 
al 
featur
ε -insensitive can be used in the 
SVR  formulation. Among these, the robust ε -insensitive 
loss function ( εL ), given below is commonly  used 
(Vapnik 2000). 
oth C and ε  are user-determined parameters. 
i  and 
*
iξ , ni  ..., ,2 ,1=Two positive slack variables, ξ , 
can he 
bo
be used to measure the devia
undaries of the 
tion ( )( ii fq x− ) from t
ε -insensitive zone. That is, they 
represent the distance from actual values to the 
corresponding boundary values of ε -insensitive zone (see 
Fig. 1). By using slack variables, the Eq. (5) is transformed 
into the following constrained form: 
Minimize:    
 
∑
=
++= n
i
iireg CfR
1
*2 )(
2
1)( ξξv     (6) 
 6
 approach, proposed by Cheung and Xu (2001), using 
relative hamming distance (RHD) reconstruction error as 
in
 to the matrix X, 
a de-
dex is adapted to order the ICs. The RHD reconstruction 
error can evaluate the similarity between time series data. 
The smaller value represents the more similar 
between time seri  The RHD value of identical time 
series data is zero, whereas the RHD value of totally 
differ e series data is four. The equation of RHD can 
refer to Cheung and Xu (2001). 
An example is used for illustrating the concept of the 
TnA method. Figure 2 shows six financial time series data, 
each of size 7811× . They can be combined as a mixture 
matrix X of size 7816× . After using ICA
RHD 
es data.
ent tim
mixing matrix W of size 66×  and four ICs, each of 
size 7811× , can be estimated. The profiles of those six ICs 
are shown in Figure 3. It can be seen from Figure 3 that 
each IC can r esent different features of the original time 
the six ICs on capturing the ain feature of the data in 
Figure 2, the TnA approa
epr
in Figuseries data re 2. Fo g the performance of 
m
ch is then used.  
s r ion of the 
TnA ssumed as the last one in the 
ordering  in reconstructing the mixture 
 is recon tructed mixture 
reconstructed matrices considering different IC as the last 
e RHD reconstruction error 
r evaluatin
Consider a set of m IC
 algorithm, each IC is a
s, in the fir t ite at
 and is excluded
Let ky  be the last 
ture m trix
= 1  ,ya
m ],...,,[ 21= xxxX
matrix. one IC in the ordering, the 
reconstructed mix a  
∧
X  can be obtained by using 
the following equation, 
∑
≠=
≤≤m
kii
ii mk
,1
         （11） 
T
∧∧∧∧
matrix of size nm× , i
∧
x  is reconstructed forecasting 
variable, ia  is the i-th column vector of mixing matrix A, 
1−= WA , and iy  is the i-th IC. After obtaining the 
one IC in the orderi , th
∧
X
where s
ng
between each reconstructed matrix 
∧
X  and original 
mixture matrix X can be computed. That is, the RHD value 
is used to evaluate the similarity between the original 
forecasting variables ( ix ) and corresponding reconstructed 
forecasting variables ( i
∧
x ).  
Table 1 illustrates the RHD reconstruction error of every 
iteration of the TnA approach used for ordering the ICs in 
Figure 3. It can be seen from Table 1 that the reconstructed 
matrix X excluded IC4 has the smallest RHD value in the 
first iteration. This indicates that IC4 contributes the  
information in the reconstruction of original data. It 
contains less information about the main feature of the 
original forecasting variables than that of the rest ICs. Thus, 
IC4 is selected as the last one IC in the ordering and 
removed from this sorting process before next iterations. In 
the next iterations, the TnA algorithm repeat the same 
operations using Eq. (11) on the remaining 1
 least
−m  
independent components, i.e. five ICs in this example, and 
select the second-last component, …, and so forth. From 
Table 1, it can be observed that the second-last IC in the 
ordering is IC2 since the reconstruction set excluding IC2 
has the smallest RHD value in the second iteration. 
According to Table 1, the six ICs can be ordered as follows: 
IC5, IC6, IC3, IC1, IC2 and IC4. The first one IC, i.e. IC5, 
contains the most information about the main feature of the 
time series data (i.e. forecasting variables) in the Figure 2. 
Conversely, the least one IC, i.e. IC4, can be used to 
represent the noise of the data in Figure 2 since it includes 
the least main information of the data.  
Although the first one of the sorted IC contains the most 
main information of the data, the remaining ICs except the 
 8
  
1 151 301 451 751
 
601
Figure 2. Six financial time series data of size 7811× , respectively. 
 
1 151 301 451 601 751
資料點
 
Figure 3. Six ICs of the time series data in Fig. 2. 
 
. EXPERIMENTAL RESULTS  
 
4
For evaluating the performance of the proposed 
ICA-SVR forecasting model, the daily TAIEX closing 
cash index is used in this study. In forecasting TAIEX 
closing cash index, the TAIEX index futures prices and 
technical indicators are used as forecasting variables 
since technical indicators are the most widely used 
features in financial time series prediction 
(Balachandher et al. 2002, Leigh et al. 2005). There are 
two TAIEX index futures contracts traded on SGX-DT 
(Singapore Exchange-Derivative Trading Limited) and 
IC1( y )
 
IC2
IC3( 3y )
 
IC4( y )
 
IC5
IC6( 6y )
1
( 2y )
4
( 5y )
Data Points
1x  
3x  
2x
4x  
5x  
6  x
 10
 
proposed model in forecasting TAIEX closing cash 
index. 
The TAIEX closing cash price index forecast results 
by using random walk, single SVR and the proposed 
ICA-SVR models are computed and listed in Table 5. 
From Table 5, it can be found that the RMSE, NMSE 
and MAD of the ICA-SVR model are, respectively, 
45.46, 33.87 and 54.9%. It is evident that those values 
are smaller than those of random walk and single SVR 
models. It indicates that there is a smaller deviation 
between the actual and predicated values in the 
proposed ICA-SVR model. Moreover, compared to the 
random walk and single SVR models, the I
 12
CA-SVR 
 
model has the highest DS (directional Symmetry), CU 
(correct up trend) and CD (correct down trend) values 
which are 59%, 62% and 55%, respectively. DS, CU 
and CD provide a good measure of the consistency in 
prediction of the price direction. Thus, it can be
concluded that the proposed ICA-SVR model forecast 
better than the random walk and single SVR models in 
both prediction error and prediction accuracy. 
3000
1
3500
6000
6500
7000
151 301 601 751
資料點  
Figure  from 
, 2006. 
 
 
Table 2. Pe
4000
4500
5000
5500
收
盤
價
7500
451
5. The daily TAIEX closing ca
January 2, 2003 to February 27
rformance metrics and their calculations. 
sh prices
 
Metrics Calculation 
RMSE 
n
Aii − )T
RMSE
n
i
∑
== 1
2(
 
NMSE here ∑
=
−∗= n
i
ii ATnNMSE
1
22 )()/(1 σ , w
∑ −N iA(
=
−∗−=
i
An
1
22 ))1/(1σ   
MAD
n
MAD = 1  
DS 
AiT
n
i
i∑
=
−
∑
=
= n
i
idn
DS
1
100 , where 
⎩ otherwise0⎨
⎧ ≥−−= −− TTAAd iiiii 0))((   1 11  
CU 
∑=
i
idn
CU
2
100 , where 
≥−
oth
TT
d ii
0)(  (
   
0
1 1
C
n
=1
d
⎩⎨
⎧= −− − TAA iii )(1>− − anTii   0)1
erwise
D 
∑
in
C
2
100
≥−
the
 T
d iii
0)( (
  
0
1 1
Note that T d A re ual alue, 
respective is tot ata mber of 
ata points belong to up trend and n2 is number of data points 
=1
=D
n
id , where 
⎩⎨
⎧= −− − TTAA iii )(1<− − andTi   0)1
o rwise
 an present the act  and predicted v
ly, n al number of d points, n1 is nu
d
belong to down trend.  
 
 The modelT e 3. ults R 
model. 
abl  selection res  of single SV
ε C Training MSE Testing MSE 
23 0.000393977 0.000264371 
21 0.000411531 0.000259157 2-11 
2-1 0.000453082 0.000265499 
23 0.000392685 0.000265107 
21 0.000409680 0.000258890 2-9 
2-1 0.000454979 0.000269095 
23 0.000393066 0.000274756 
21 0.000408619 0.000271228 2-7 
-12  0.000449367 0.000269251 
 
 The model selection results of the proposed 
ICA-SVR model. 
Table 4.
ng in E ε C Traini  MSE Test g MS
2  0
Data Points 
7 908.0003 84 0.000256213 
25 0.00039 2 3 4519 0.000 46942-13 
39 2 2 23 0.000 9788 0.000 4975
27 0.000389726 0.000254360 
25 0.000394381 0.0002 6 46612-11 
23 0.000399758 0.000251751 
27 0.000389580 0.000255286 
25 0.000393546 0.000249195 2-9 
.000401372 0.000247172 23 0
 
Table 5. The TAIEX closing cash prices forecasting 
results using random walk, single SVR and 
