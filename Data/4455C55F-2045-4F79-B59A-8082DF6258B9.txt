 I 
 
行政院國家科學委員會專題研究計畫 精簡報告 
在 2D/3D 串流網路上之多視角合成與編碼技術 
Multiview Video Synthesis and Coding Technologies Over 2D/3D Streaming Networks 
  
中文摘要 
 
多視角立體視訊隨著視訊編碼技術的演進以及不需配戴特殊濾光鏡片之立體  LCD  的成熟而
逐漸受到矚目。為了增加傳輸和儲存多視角視訊大量影像資料的效率，包含於MPEG‐4 AVC 
Multiview High Profile  裡之多視角視訊編碼已接近完成的階段。這些壓縮技術雖然提供了比單純
做時間軸的預測編碼為優的壓縮效果，但仍未將多視角視訊的特性完全利用。另外，3D Video  以
及 Free Viewpoint Television  在MPEG  組織裡標準化的準備動作正在活躍進行中。本子計畫的目
標，著重在同儕網路上之串流服務系統，研究發展讓使用者進行互動立體視訊  (Interactive 
Stereoscopic Video)及自由視角(Freeviewpoint TV)  立體視訊服務所需之關鍵技術。包含研究多視
角視訊編碼技術，以及因應異質網路資源所對應到之二維視訊至立體視訊之合成，和多視角視訊
視角合成。並針對同儕網路在多視角立體視訊串流下網路傳輸的架構及協定進行研究，結合網路
編碼的技術來使多視角立體視訊串流的傳輸更順暢。 
 
  
關鍵詞：多視角視訊、立體視訊、視角合成、同儕式網路。 
  
  
 I 
 
目錄： 
一、  前言與研究目的 ....................................................................................................................... 1 
二、  相關文獻討論 ........................................................................................................................... 2 
三、  研究方法 ................................................................................................................................... 4 
四、  結果與討論 ............................................................................................................................... 7 
五、  總結，未來發展與計畫結果自評 ........................................................................................... 9 
六、  所發表/已接受之學術論文 ...................................................................................................... 9 
七、  參考文獻 ................................................................................................................................. 10 
 
  
 2 
 
(Interactive Stereoscopic Video)及自由視角(Free viewpoint TV) 立體視訊服務所需之關鍵技術。原
訂以三年的時間，進行包含研究多視角視訊編碼技術，以及因應異質網路資源所對應到之二維視
訊至立體視訊之合成，和多視角視訊視角合成。並針對同儕網路在多視角立體視訊串流下網路傳
輸的架構及協定進行研究。本子計畫獲核定第一年的計畫，重點在於視角合成的研究發展以及相
關的串流網路探討。 
以下為我們到目前為止所進行的相關研究。第二部分為相關文獻討論，第三部份為研究方法
簡介，第四部份為結果與討論，第五部份為結論，未來發展與計畫結果自評，第六部份為計畫所
發表之著作，以及第七部份為參考文獻。  
 
二、 相關文獻討論 
以下我們就上述所提及之各項技術在目前世界上研究的情況進行介紹。依據計畫之目的主軸，
我們分成幾個方向進行討論及評述： 
1. 景深預估(Depth estimation)  
2. 多視角視訊合成與編碼 
3. 點對點網路的串流技術 
 
(1)景深預估(Depth estimation) 
景深圖可由 3D 景深相機利用主動式照明對待測場景發射一參考光束，藉由計算回光的時間差
或相位差來換算場景中物體的距離，然而此方式容易受限環境因素尤其是在高解析度的情況下。
因此，一般做法都是由多個不同角度所拍攝的視訊來預估景深圖。Stereo Matching 一、參、[10] 
是利用左右兩台攝影機模擬雙眼，由左右兩張影像的 disparity 來算出物體深度。然而遮蔽
(occlusion)區域 一、參、[11]一、參、[12]仍是主要需要克服的問題，因為被遮蔽的像素只能被
其中一個視角所看見。有許多演算法藉由多個視角來減輕遮蔽問題以獲得較精準的景深圖。
Segment-based 一、參、[13] 的方法是建構在同一個物件或分割(segment)應該擁有相同的深度值
的假設上。 
 
圖二: Relation between disparity and depth (引自錯誤! 找不到參照來源。)  
 
 4 
 
然而對於多視角合成技術以及自由視角合成視訊而言，每一個不同擺放位置的鏡頭資料都必
須傳送，才能合成出所欲觀看之視角視訊，因此傳送的資料量非常的龐大，因此採用H.264/AVC
中multiple reference picture壓縮技術。而較常見的預測結構一、參、[3]如下。為了降低資料量不
僅在時間維度上採用hierarchical B picture的架構如下圖左，同時利用在相鄰視角極高的相依性來
預測已提高壓縮率如下圖右。雖然左圖壓縮率沒有右圖來的高，但可以每個視角資料可以隨機存
取。 
 
圖五: 左圖僅考慮在時間預測上採用 hierarchical B picture 的架構， 
右圖同時考慮時間和相鄰視角間的關係 
 
(3) 點對點網路的串流技術 
點對點技術的主要概念是每個使用者在應用層組成一個重疊網(Overlay Network)，每個使用
者既是資訊接收者亦是傳送者。P2P 架構的優點在於用戶數增加時並不會同時增加伺服端的負
載。不同於以往傳統點對點僅考慮單一重疊網資料的傳輸，若是要傳送多視角視訊資料，需要解
決多個重疊網之間互相競爭受限頻寬的問題。Wu一、參、[6]一、參、[7]等人基於遊戲理論(Game 
Theory) 提出接收端執行叫價策略，傳送端根據接收端的出價執行配置(allocation)策略來分配上
傳頻寬，透過叫價喊價的方式使得上傳頻寬能公平且較佳地分配在多個重疊網之間。 
相較於遊戲理論的方式， Wang一、參、[8]等人使用Lagrangian relaxation一、參、[5] 來分
割變數，目的是將一個問題分成好幾個子問題。藉由放寬複雜的限制式(Constraint)，使得原始的
問題簡化，由子問題找出局部的最佳解，進而求得全域近似最佳解（Near Optimal Solution）的
方法。傳送端使用梯度法(Subgradient)求得Lagrangian multiplier並將之送給接收端以調整下載頻
寬，經由不斷地重覆計算以找到最接近最佳解的一個點。 
 
三、 研究方法 
研究方法下列兩部分討論 
1. 景深改善演算法 
2. 參考視角與合成視角間距離與合成品質的關係 
 
1. 景深改善演算法 
  其流程如下圖，Depth Consistency 分別針對左右視角所產生的景深圖做 cross-checking 來判斷
每個像素的景深值是否為可信任(reliable)，其作法如圖七，左視角像素的景深求得右視角相對應
的位置，再由之反求得在左視角的位置，若位置不同則列為不可信任區域；而右視角景深圖由此
 6 
 
圖六: 景深改善演算法流程圖. 
 
圖七: Cross-checking 程序 
(a)  (b) 
圖八: 經 Cross-checking 產生之左右視角的 Depth Consistency Map。 
 
圖九: 不可信任像素景深與四個方向鄰近可信任像素關係 
   
(a)  (b) 
圖十: (a) 原來左視角的景深圖 (b) 經過景深改善演算法所求得左視角景深圖 
2. 參考視角與合成視角間距離與合成品質的關係 
    當參考視角離合成視角距離越近時所合成出來影像的品質越佳，因此我們探討參考視角距離
Using d(x,y) to map to (x’,y’) 
Using d(x’,y’) to map to (x”,y”) 
 8 
 
2.1 主觀比較結果 
本實驗拿book arrival測試影片中的View 10和View 7來合成View 8，在圖十三中，(a)為在View 
8的原始影片，(b)為VSRS所產生的目標視角的影片，(c)為所提的景深改善演算法所產生目標視
角的影片。第58個frame時，綠框部分可以清楚看出在背景部份我們所提的演算法較VSRS好。 
 
(a) 
   
(b)  (c) 
圖十三: book arrival 在第 58 的 frame 主觀比較結果. 
 
2.2 客觀比較結果 
除了PSNR，PSPNR(Peak Signal to Perceptual Noise Ratio)也是拿來衡量視角合成品質好壞的
方法，可分別針對spatial 跟 temporal 進行評估。除了原有DERS+VSRS，我們還跟J. Sung, 2009 
[18]進行比較。由表一可看出所提的方法相較於原來DESR+VSRS在PSNR上有1.58dB的改善，在
S_PSPNR有2.20dB的進步。 
表一: PSNR 和 PSPNR 比較結果 
N‐pixel 
exclusion 
PSNR  S_PSPNR  T_PSPNR 
DERS+VSRS  [18]  Proposed  DERS+VSRS  [18]  Proposed DERS+VSRS  [18]  Proposed 
No pixels 
exclusion 
31.99  32.01  33.57  33.44  33.44 35.64  47.70  47.54 50.88 
 
3. 參考視角與合成視角間距離與合成品質的關係 
以下表格是利用二次函式去求得相關係數，其中b接近於中間視角的相對距離0.5，而c值是
因為景深圖的準確與否而影響整體合成的視角的PSNR。 
 10 
 
七、 參考文獻 
 
[1]. Y. Chen, Y.-K. Wang, K. Ugur, M. M. Hannuksela, J. Lainema and M. Gabbouj "The emerging MVC standard 
for 3D video services," EURASIP Journal on Applied Signal Processing, Jan. 2009. 
[2]. Cheon Lee and Yo-Sung ho, “View Synthesis using Depth map for 3D video,” Proceedings of APSIPA, Sapporo, 
Japan, Oct. 2009. 
[3]. Philipp Merkle, Aljoscha Smolic, Karsten Muller, and Thomas Wiegand, “ Efficient Prediction Structures for 
Multi-view Video Coding,” IEEE Tran. on Circuits and Systems for Video Technology, Vol. 17, NO. 11, Nov. 
2007. 
[4]. Philipp Merkle, Aljoscha Smolic, Karsten Muller, and Thomas Wiegand, “ Multi-view Video Plus Depth 
Representation and Coding,” IEEE International Conf. on Image processing(ICIP), Texas, USA, Sep. 2007. 
[5]. Hsin-Chia Shih and Hsu-Feng Hsiao, “A Depth Refinement Algorithm for Multi-View Video Synthesis”, IEEE 
ICASSP’10,  Texas, USA, 2010. 
[6]. C. Wu, B. Li, and Z. Li, “Dynamic Bandwidth Auctions in Multi-overlay P2P Streaming with Network Coding,” 
IEEE Tran. Parallel and Distributed Systems, vol.19, no.6, pp.806–820, June 2008. 
[7]. C.Wu and B. Li, “Strategies of Conflict in Coexisting Streaming Overlays,” in Proceedings of IEEE INFOCOM, 
Anchorage, AK, May.2007. 
[8]. Miao Wang, Lisong Xu and Byrav Ramamurthy,”A Flexible Divide-And-Conquer protocol for Multi-View 
Peer-to-Peer Live Streaming,” 
[9]. Daniel P. Palomar, and Mung Chiang, “Alternative Distributed Algorithms for Network Utility Maximization: 
Framework and Application,” IEEE Tran. on Automatic Control, Vol 52, No. 12, Dec. 2007. 
[10].  D. Sharstein and R. Szeliski, “A Taxonomy and Evaluation of Dense Two-Frame Stereo Correspondence 
Algorithms”, Proc. of IEEE Workshop on Stereo and Multi-Baseline Vision, pp. 131-140, December 2001. 
[11]. P. Kauff, N. Atzpadin, C. Fehn, M. Muller, O. Schreer, A. Smolic, and R. Tanger, “Depth Map Creation and 
Image Based Rendering for Advanced 3DTV Services Providing Interoperability and Scalability”, Signal 
Processing: Image Communication. Special Issue on 3DTV, February 2007. 
[12]. M. Tanimoto, T. Fujii and K. Suzuki, “View Synthesis Algorithm in View Synthesis Reference Software 2.0 
(VSRS2.0)”, ISO/IEC JTC1/SC29/WG11, M16090, February 2009. 
[13]. S. Lee, K. Oh, and Y. Ho, “Segment-based Multi-view Depth Map Estimation Using Belief Propagation from 
Dense Multi-view Video”, Proc. of 3DTV Conference, May 2008. 
[14]. M. Tanimoto, T. Fujii and K. Suzuki, “Multi-view depth map of Rena and Akko & Kayo”, ISO/IEC 
JTC1/SC29/WG11, M14888, October 2007. 
[15].  S. Lee and Y. Ho, “Multi-view Depth Map Estimation Enhancing Temporal Consistency”, ITC-CSCC, pp. 
29-32, 2008. 
[16]. M. Tanimoto, T. Fujii and K. Suzuki, “View Synthesis Algorithm in View Synthesis Reference Software 2.0 
(VSRS2.0)”, ISO/IEC JTC1/SC29/WG11, M16090, February 2009. 
[17]. M. Tanimoto, T. Fujii, and K. Suzuki, “Reference Software of Depth Estimation and View Synthesis for 
FTV/3DV”, ISO/IEC JTC1/SC29/WG11, M15836, October 2008. 
[18]. Jaewon Sung, Yong‐Joon Jeon, Jae‐Hyun Lim, and Byeong‐Moon Jeon, “Improving view synthesis results based 
on depth quality”, ISO/IEC JTC1/SC29/WG11, M16417, April 2009. 
 
更多之參考文獻限於篇幅，敬請詳見本子計畫之計畫申請書。 
無衍生研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
在這個為期三年的子計畫裡，我們獲得第一年國科會研究計畫的補助。研究成
果除了已發表之論文外，我們也與交通大學電子系的杭老師合作，架設多視角
攝影陣列系統，方便往後多視角實驗影片的取得。在研究這當中也發現許多有
趣的研究新課題，也在後續的研究規劃內繼續進行研究。參加本計劃之研究人
員，在學理上和實務上都能受到紮實而有效的訓練。 
 
 成果項目 量化 名稱或內容性質簡述 
科 
教 
處 
計 
畫 
加 
填 
項 
目 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
計畫成果推廣之參與（閱聽）人數 0  
 
