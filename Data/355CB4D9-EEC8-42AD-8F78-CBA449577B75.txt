行政院國家科學委員會補助專題研究成果計畫 
 
MULTI-RESOLUTION STEREOVISION SYSTEM FOR REAL-TIME 
OBSTACLE DETECTION 
 
Department of Electrical and Electronic Engineering, 
Chung Cheng Institute of Technology, National Defense University. 
 
 
ABSTRACT 
 
This study proposes a multi-resolution stereovision 
system to detect obstacles for advanced safety vehicle 
(ASV). In the system, two cameras mounted on a 
vehicle to capture road scenes for detecting preceding 
obstacles. An edge-segment matching algorithm for 
computer stereo vision is proposed. The algorithm 
matches the horizontal and vertical edge-segments of a 
possible preceding obstacle to locate the obstacle. 
Because the distance of each matched segment can be 
calculated by the disparity of the matched segment, we 
collect the segments which have the same distance to 
represent the possible object by a bounding box. In this 
study, we propose a low-cost computer stereovision 
system and use an edge-segment matching algorithm to 
conquer the drawback, asynchronous snapping, of the 
low-cost system. Also, the edge-segment matching 
algorithm can overcome the shaking of a vehicle. In the 
experiments, the proposed detector is evaluated on 
several different weather and road conditions. From the 
experimental results, we find that the proposed approach 
can robustly and accurately detect and track the 
preceding vehicles in real time. 
 
Keywords: computer stereo vision, disparity, 
obstacle detection. 
 
1. INTRODUCTION 
 
Because human errors are the cause of most of 
traffic accidents, we like to provide an Advanced Driver 
Assistance Systems (ADAS) which can reduce the 
number, danger and severity of traffic accidents. Several 
ADAS, which nowadays are being researched for 
Intelligent Vehicles, are based on Computer Vision. 
Adaptive Cruise Control (ACC) has to detect and track 
other vehicles. Present day, commercial equipments are 
based on distance sensors like radars or LIDARs. Both 
types of sensors have the advantages of providing a 
direct distance measurement of the obstacles in front of 
the vehicle, are easily integrated with the vehicle control, 
are able to work under bad weather conditions, and they 
are not affected by lighting conditions. Cost for Lidars 
and a narrow field of view for radars are inconveniences 
that make computer vision an alternative or 
complementary sensor. Although it is not able to work 
under bad weather conditions and its information is 
much difficult to process, it gives a richer description of 
the environment that surrounds the vehicle.  
With lowering costs, vision system are getting 
more and more present in the automotive detection 
system, and many researchers have been working on the 
implementation of driving assistance systems based on 
computer vision. Among these, stereovision has the 
major advantage of being able to provide depth 
information and object recognition.  
Many approaches have been proposed for the 
obstacle detection using a monocular camera 
[1][2][3][4]. Because these approaches are monocular 
system, car shaking problems will cause serious 
distortion of the distance measurement.  
Currently, stereovision is more and more used, 
because it can produce a complete three dimensional 
view of the scene. In this field, various approaches have 
been proposed, focusing for example on the road 
geometry [5] or on the detection of obstacle points [6]. 
Stereovision techniques are computationally costly and 
thus a compromise between detection range and 
accuracy must be chosen. 
To ensure a maximum reliability to the obstacle 
detection systems, many researches focus on 
multi-sensor fusion approaches [7] [8]. In particular, 
using stereovision and a laser scanner seems to be an 
efficient solution [9].  
In order to provide better performances with 
low-cost equipments, we propose a real-time 
multi-resolution stereovision system with a low-cost 
stereovision system and a stereovision obstacle 
detection algorithm.  
The organization of the study is as follows. In the 
next section, the system overview is introduced. In 
Section III, we give the introduction of the stereovision 
obstacle detection algorithm. Experimental results and 
conclusion are given in Sections IV and V. 
 
 
The disparities can be calculated from the matching line 
segments. Therefore, the distances of the tips of each 
line segment can be calculated from the disparity 
amounts.  
In the obstacle searching & distance estimation 
module, the obstacles and their distances will be 
searched and estimated by the distance information of 
line segments. 
 
4. EXPERIMENTAL RESULTS 
 
In this study, the propose system uses two low-cost 
cameras to get stereo pair images. In general, the cost of 
a synchronous camera is more than twenty times as 
expensive as the low-cost asynchronous camera. 
Because the low-cost cameras can not achieve 
synchronous snapping, this study proposes the SODA 
algorithm to conquer the drawback.  
In Figure 3, the left and right images are snapped 
on the same time by two synchronous cameras. Figure 
3(a) is the NTSC signals of the two synchronous 
cameras, detected by an oscilloscope, and the Fig. 3(b) 
& (c) are the left and right images snapped by the 
synchronous cameras. Because the stereo pair images 
are snapped synchronously, the images on each row pair 
of the Fig. 3(b) and Fig. 3(c) have highly correlation. 
Two lines are drawn on the Fig. 3(b) & 3(c) in the same 
row. Obviously, we can match the left and right images 
in the same row. Therefore, many stereovision 
algorithms were proposed based on the synchronous 
cameras. 
 
  
(a) The output signal 
of the synchronous 
cameras on the 
oscilloscope. 
(b) The snapped image 
by the left camera. 
(c) The snapped image 
by the right camera. 
Fig. 3: The left and right images snapped by the synchronous 
cameras. 
 
Then, the NTSC signals and output images of the 
asynchronous cameras of the proposed system are 
shown in Fig.4. From the Fig.4(a), the NTSC output 
signals of the two cameras are asynchronous. Because 
the cameras can not snap the images at the same time, 
the time-difference will influence the positions of the 
objects in the captured images, such as the Fig.4(b) & 
Fig.4(c). Especially, when the cameras work on the 
bumpy road, the vibration of the cameras will seriously 
affect the snapped images. Therefore, we can’t follow 
the algorithms of the synchronous cameras to search and 
match the stereo pair images with the asynchronous 
cameras. 
 
(a) The output signal of 
the asynchronous 
cameras on the 
oscilloscope. 
(b) The snapped image 
by the left camera. 
(c) The snapped image 
by the right camera. 
Fig. 4: The left and right images snapped by the asynchronous 
cameras.  
 
This study proposes a SODA algorithm to detect 
the obstacles within 30 m sec with the asynchronous 
cameras. In the following experiments, the test images 
are snapped by two asynchronous cameras. The gray 
images captured by each CCD camera are 30 fps and the 
image size is 320 by 240. The system uses the platform 
Intel Pentium IV CPU 1.5GHz, 1.0GB RAM, and the 
development environment Visual C++ 2005. The 
proposed algorithm has been tested on numerous color 
image sequences captured in different road conditions. 
The time required to process each stereo pair images is 
between 23 and 27 ms. 
 
Detection zone of the proposed system: 
Before the dynamic tests on a moving vehicle, we 
set our stereovision system on a platform (shown as 
Fig.5), whose attitude can be regulated in roll, pitch, and 
altitude. In static test, we set the ambits of the detection 
distance from 3 m to 50 m, height between 105 cm and 
135 cm, pitch angles between -5° and 5°, and roll angles 
between -10° and 10° to test the proposed system. 
 
Pitch : -5° ~ 5°
Height :105 ~ 135cm
Roll : -10° ~ 10°
 
Fig. 5: The static test platform. 
 
Figure 6 shows the relationship between the 
distance error and the height of cameras. In the Fig.6, 
Platform Pitch Angle ( ° ) Distance Errors(m) 
and 
Accurate Rates(%) Up 5° Up 3° Up 1° Down 3° Down 5° 
Real Distance(m)      
3 *.** / **.** 0.15 / 95.00 0.17 / 94.33 0.12 / 96.00 0.14 / 95.33 
4 0.21 / 97.50 0.04 / 99.00 0.26 / 93.50 0.13 / 96.75 0.32 / 92.00 
5 0.17 / 97.80 0.32 / 93.60 0.21 / 95.80 0.38 / 92.40 0.09 / 98.20 
6 0.27 / 96.67 0.27 / 95.50 0.34 / 94.33 0.20 / 96.67 0.24 / 96.00 
7 0.38 / 99.71 0.08 / 98.86 0.41 / 94.14 0.21 / 97.00 0.09 / 98.71 
8 0.35 / 98.75 0.07 / 99.13 0.35 / 95.63 0.22 / 97.25 0.38 / 95.25 
9 0.16 / 98.89 0.19 / 97.89 0.31 / 96.56 0.04 / 99.56 0.15 / 98.33 
10 0.07 / 98.00 0.30 / 97.00 0.46 / 95.40 0.40 / 96.00 0.05 / 99.50 
15 0.40 / 99.33 0.70 / 95.33 1.35 / 91.00 1.30 / 91.33 0.30 / 98.00 
20 0.70 / 98.50 0.20 / 99.00 1.75 / 91.25 1.80 / 91.00 0.70 / 96.50 
25 0.20 / 92.80 0.60 / 97.60 0.73 / 97.08 0.10 / 99.60 0.10 / 99.60 
30 0.90 / 95.67 1.90 / 93.67 2.10 / 93.00 0.80 / 97.33 0.20 / 99.33 
40 1.20 / 97.25 0.50 / 98.75 1.50 / 96.25 1.80 / 95.50 1.20 / 97.00 
50 2.10 / 95.80 3.20 / 93.60 3.50 / 93.00 0.60 / 98.80 3.20 / 93.60 
Fig. 7: Distance errors vs. platform roll angles. 
 
The Fig.8 shows the relationship between the 
distance error and various pitch angles of the 
stereovision system. Referring the Fig.8, the average 
distance accurate rate is over 90.4 % and the average 
distance error is less than 2.1 m when the pitch angles of 
the system are between -5° and 5°. 
 
 
 
 
 
 
\ 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Platform Pitch Angle ( ° ) Distance Errors(m)  
and 
Accurate Rates(%) Up 5° Up 3° Up 1° Down 3° Down 5° 
Real Distance(m)      
3 *.** / **.** 0.15 / 95.00 0.17 / 94.33 0.12 / 96.00 0.14 / 95.33 
4 0.21 / 97.50 0.04 / 99.00 0.26 / 93.50 0.13 / 96.75 0.32 / 92.00 
5 0.17 / 97.80 0.32 / 93.60 0.21 / 95.80 0.38 / 92.40 0.09 / 98.20 
6 0.27 / 96.67 0.27 / 95.50 0.34 / 94.33 0.20 / 96.67 0.24 / 96.00 
7 0.38 / 99.71 0.08 / 98.86 0.41 / 94.14 0.21 / 97.00 0.09 / 98.71 
8 0.35 / 98.75 0.07 / 99.13 0.35 / 95.63 0.22 / 97.25 0.38 / 95.25 
9 0.16 / 98.89 0.19 / 97.89 0.31 / 96.56 0.04 / 99.56 0.15 / 98.33 
10 0.07 / 98.00 0.30 / 97.00 0.46 / 95.40 0.40 / 96.00 0.05 / 99.50 
15 0.40 / 99.33 0.70 / 95.33 1.35 / 91.00 1.30 / 91.33 0.30 / 98.00 
20 0.70 / 98.50 0.20 / 99.00 1.75 / 91.25 1.80 / 91.00 0.70 / 96.50 
25 0.20 / 92.80 0.60 / 97.60 0.73 / 97.08 0.10 / 99.60 0.10 / 99.60 
30 0.90 / 95.67 1.90 / 93.67 2.10 / 93.00 0.80 / 97.33 0.20 / 99.33 
40 1.20 / 97.25 0.50 / 98.75 1.50 / 96.25 1.80 / 95.50 1.20 / 97.00 
50 2.10 / 95.80 3.20 / 93.60 3.50 / 93.00 0.60 / 98.80 3.20 / 93.60 
Fig. 8: Distance errors vs. platform pitch angles. 
 
Referring to the Fig.6~Fig.8, we clearly get the 
relationship between the distance error, roll, pitch, and 
altitude of the stereovision system. The detected ranges  
of the system are from 3 m to 50 m and its average  
 
 
accurate rate is over 90 %. To generalize a conclusion 
from these static tests, the detection zone in the front of 
the windscreen can be shown as Fig.9. 
 
 
Distance Errors vs. Platform Pitch Angle
0
1
2
3
4
5
6
7
3 4 5 6 7 8 9 10 15 20 25 30 40 50
Distance(m)
D
ist
an
ce
 E
rr
or
(m
)
50%
55%
60%
65%
70%
75%
80%
85%
90%
95%
100%
D
ist
an
ce
 A
cc
ur
at
e 
R
at
e(
%
)
Up 5° Distance Error (m)
Up 3° Distance Error (m)
Up 1° Distance Error (m)
Down 3° Distance Error (m)
Down 5° Distance Error (m)
Up 5° Distance accurate rate (%)
Up 3° Distance accurate rate (%)
Up 1° Distance accurate rate (%)
Down 3° Distance accurate rate (%)
Down 5° Distance accurate rate (%)
Lower Boand of Average Distance
Accurate Rate (%)
Upper-Boand of Average Distance
Errors (m)
 
(a) The n-th frame  (b) The (n+1)-th frame 
  
(c) The (n+2)-th frame (d) The (n+3)-th frame 
  
(e) The (n+4)-th frame (f) The (n+5)-th frame 
Fig. 12: Some detection results on the freeway in 
night 
 
Various Road conditions on the urban road : 
a. Uphill or downhill road : 
In the Fig.13 and Fig.14, the image sequences are 
captured on the uphill and downhill respectively. 
Although the detected information apparently reduces, 
the system can still detect the preceding vehicles 
accurately and the detection rate of the system can reach 
up to 90 %. 
 
b. Crooked road : 
In Fig.15, the image sequences are captured on the 
crooked road. The preceding vehicle and the vehicle on 
the reverse direction can still be detected and the 
detection rate of the system can reach up to 88 %. 
 
c. Bumpy road : 
Figure 16 is the detection results on the bumpy 
road, which is under the road reconstruction works. 
From the bumpy road, the detection rate of the system is 
80 %. 
 
 
 
 
 
 
 
 
 
 
 
(a) The n-th frame  (b) The (n+1)-th frame 
 
(c) The (n+2)-th frame (d) The (n+3)-th frame 
  
(e) The (n+4)-th frame (f) The (n+5)-th frame 
Fig. 13: Some detection results on the uphill urban 
road 
 
 
(a) The n-th frame  (b) The (n+1)-th frame 
 
(c) The (n+2)-th frame (d) The (n+3)-th frame 
  
(e) The (n+4)-th frame (f) The (n+5)-th frame 
Fig. 14: Some detection results on the downhill 
urban road 
 
 
 
[11] J. Suzuki, K. Horiba, and N. Sugie, “Fast 
connected-component labeling based on sequential local 
operations in the course of forward raster scan followed  
 
by backward raster scan”, Pattern Recognition, Vol.2, 
pp.434-437, 2000. 
 
 
 
 
6. 附錄(已發表與預計投稿之文章) 
 
[1] M. L. Chung, C. C. Chiu, W. C. Chen, M. Y. Ku, “ MULTI-RESOLUTION STEREOVISION 
SYSTEM FOR REAL-TIME OBSTACLE DETECTION. ” Computer Vision and Graphics and 
Image Processing Conference ( CVGIP 2007 ), Miaoli, Taiwan, pp.982-989, August 19-21, 2007. 
 
[2] C. C. Chiu, M. L. Chung, W. C. Chen, M. Y. Ku, “ MULTI-RESOLUTION STEREOVISION 
SYSTEM FOR REAL-TIME OBSTACLE DETECTION. ” Prepare to Submit to IEEE Trans. on 
Intelligent Transportation System.  
 
 
申請中之專利： 
[1] “以立體視覺偵測障礙物的裝置與方法 / device and method for detecting obstacle by 
stereo computer vision.＂,申請案號：096117494, 中華民國發明專利,2007 年五月。 
[2] “APPARATUS AND METHOD FOR DETECTING OBSTACLE THROUGH 
STEREOVISION. ” US , 2007. 
 
 
 
 1
可利用之產業 
及 
可開發之產品 
可利用之產業: 
自動化產業、監控產業、智慧型運輸系統相關產業 
可開發之產品: 
智慧型機器視覺、智慧型監控系統、車輛碰撞警示系統、自走車 
技術特點 
結合雙鏡頭立體視覺技術之障礙物偵測並正確估算距離之技術。 
․不受顛簸路面影響偵測與距離估算 
․不受轉彎或路面歪斜的影響 
․不受架設高度的影響 
․不受 CCD 鏡頭架設角度的影響 
․不受車輛震動或是乘載重量改變的影響 
推廣及運用的價值
對於台灣智慧型車輛產業的發展，政府預計未來四年將投入 60 億
元，藉由各項關鍵系統產業聯盟方式，開創台灣車輛相關業者 3000
億元商機，協助台灣車輛產業轉型成功。本發明技術正好符合目前
政府發展方向，可以由國科會扮演產學合作的橋樑，並降低產業界
對此技術的開發成本。 
 
?? ????????????????
????
?
?????????
????????????     !"
#$ %&'!( )**)????????????
???????????????????????????????
???????????????????????????????
?????????????????????? ?????????
???????????????????????????????
???????????????????????????????
???????????????????????????????
?? ?????????? /????????????? 
! ')$??????????
???????????0????????????
???????????????????????????????
???????????????????????????????
????????????????? ?????????????
???????????????????????????????
?? ?????????????????????????????
???????????????????????????????
??????????????????????????????
?????????????????????????????
??????????????????????????

???????
    
?????? ????????????????????????
???????????????????????????????
???????????????????????????????
????????????
????????????????????????????????
?? 11??????????? %  ???????1
+
(*(2)('#$($%&'!(??
?????????????????? 11?????????
?? 
3'"???????14)#(*)(. '%
+"!"56()?


2????

???????????????????????????
???????????????????????????????
??????????
????????????????????? ??????
