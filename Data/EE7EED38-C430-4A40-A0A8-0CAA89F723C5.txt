  I
計畫中文摘要。（五百字以內） 
本計畫研究主題，將著重量化分析口語篇章韻律語料，證實指涉語流韻律的上層訊息（higher 
level information）與韻律輸出的階層式貢獻度，並建構語流語境的聲學韻律模組，作為語
音合成的語流韻律模型。我們在 2004-2006 年提出「階層式多短語韻律句群 Prosodic Phrase 
Grouping 簡稱 PG」假說，已陸續獲得量化語料證據，證明口語語流韻律所存有跨短語的基
頻走勢、音節長短配置與節奏、邊界效應與停頓停延，係來自字調、韻律詞、韻律短語和
語篇各韻律層級貢獻的總和的大範圍模版基型。本計畫將繼續分析大批語料的超音段聲學
參數，除基頻、音長、音強及邊界停頓停延四項聲學參數外，再加入基頻重設與基頻音域
在時間軸上的變化二項參數，從六項參數的交互影響，量化驗證口語韻律假說，最後並加
入認知閾限與語音產製規劃的閾限二者即時互動所造成的制約，尋找語篇語意及語言產生
即時規劃的認知意義；並進一步解釋，語流韻律必須加入更上層的語篇語意訊息造成韻律
銜接以形成韻律語境。從韻律的階層性來說，字調由詞義規範、短語句調由句法結構規範，
二者都是靜態韻律，是語段的次級韻律單位；語流韻律由語篇規範，造成短語句調系統性
的變化，是動態韻律，與語篇同為上層韻律單位。語音合成必須加入動態韻律的規律，才
能更有效的模擬語流韻律；語音識別則必須考慮動態韻律規範語流中韻律單位的完整及縮
減原則，才能掌握語流中的關鍵單位，並考慮各單位的邊界效應，而不再是每一個小語音
單位的辨識而已。 
 
 
 
 
 
 
 
 
 
 
 
 
關鍵詞：上層訊息、語篇語意訊息、口語篇章韻律、語流韻律、語音產製規劃、語言即時
規劃、韻律銜接、韻律語境、靜態韻律、動態韻律、多短語韻律句群、音節時程配置、時
長組型、音強分布、邊界停延、基頻音域、基頻走勢、基頻重設 
  III
行政院國家科學委員會補助專題研究計畫研究成果報告 
語音科技開發導向的口語篇章韻律研究 目錄 
 
計畫中文摘要...................................................................................................................................I 
計畫英文摘要................................................................................................................................. II 
目  錄............................................................................................................................................ III 
一、 前言...................................................................................................................................... 1 
二、 研究目的.............................................................................................................................. 1 
三、 研究背景與文獻探討.......................................................................................................... 1 
四、 研究方法.............................................................................................................................. 3 
(一) 透過線性回歸的統計分析方法，釐清各級韻律單位的分層貢獻度...................... 3 
(二) 以 Fujisaki Model 為基礎，發展自動擷取國語基頻曲線特徵參數系統 ............... 4 
五、 研究進度及成果.................................................................................................................. 5 
(一) 第一年研究進度及成果.............................................................................................. 5 
(二) 第二年研究進度及成果.............................................................................................. 7 
(三) 第三年研究進度及成果.............................................................................................. 9 
六、 參考文獻............................................................................................................................ 11 
七、 計畫成果自評.................................................................................................................... 19 
 
  2
律(lexical prosody)；句法結構只規範孤立句的句型結構，句調單位僅達簡單句（intonation unit 
簡稱 IU），屬句法韻律（syntactic prosody）。連讀變調其實表達的是字調之間關連性，但單
位多半只達多字詞；連讀句調會引起什麼變化，則一向不是傳統語音分析的研究重點。趙
元任先生（1968）曾以「大波浪小波浪」比喻，釐清了字調與語調之間的互動關係。然而，
一個短句以上複雜句的調型或短語群的調型描述則付之闕如，語篇中句調間如何的互動分
析也一向未受重視，實為傳統語音研究之侷限。 
因此，我們從十年前開始，採用語料庫語音學的研究方法，開始了口語語流韻律研究。蒐
集大批的口語語流語料庫，同時設計標註系統，從事量化研究，所有的假設，都用統計數
據來支持，相較於傳統語音學研究不重視語料量的做法──只強調小範圍、細部現象的觀
察，在研究方法上相當不同。在語音單位、研究角度和研究重點上提出更新的看法。以口
語語篇中的多短語語段為主要研究單位，承襲了中國語言學之父趙元任先生以『大波浪小
波浪』描述聲調與句調之間相互疊加或抵消關係的看法，提出階層式的多短語韻律模架構，
強調各短語間因受來自上層訊息的管轄，而構築了相互間的韻律關係，因此語段裡的短語，
好像兄弟姊妹一樣有了親屬關係，而不是將各短語之間視為不相關、各自擁有本身的句調
的研究觀點。從認知與生理角度出發，針對語流韻律中跨短句的抑揚頓挫、音樂性及節奏，
層層找出證據，提出多短語句群的的韻律結構，並以這個韻律結構提出跨句模組式的聲學
模型。如此由上到下（top-down）的研究取向深獲日本學者藤崎博也先生所讚揚，認為此
一研究方式乃語音分析之先驅。 
我們從事口語韻律研究，若與國內外研究漢語或中文韻律的研究相較，最大的不同在於：
一、在韻律與句法關係方面，走出只考慮構詞與句法的關係，而僅止於句法（馮勝利 1992；
1997）的框架；二、跨越僅考慮語句韻律的句法功能（葉軍 2000；馮勝利 2005）的侷限。
三、與研究漢語語篇的研究相較（如黃國文 1987； 程祥徽、田小琳 1988），我們所提出的
韻律框架，更能完整解釋「銜接手段」的語篇韻律體現與結構的具體關係。 
若與研究西文篇章（如 Hasan and Freis, 1995）的研究相比，我們的韻律研究最大的特點則
是：一、以中文口語語篇敘述的多短語韻律句群，對 subject 與 theme 提出韻律層面的具體
基型，以具體的語音體現，呼應 Longacre1996 年所提出的 monologue discourse 中 plot, peak 
與 salience 觀念。二、對於 Schiffrin 於 1987 年所提出的 discourse marker 觀念，不但提出漢
語語流中的證據，更進一步提出語流中，同時也存在對應於 discourse marker 另一個韻律單
位 prosodic filler (Tseng et al, 2005)，用來指稱：在口語連續語流中，因語意承載量最小、是
可以忽視、略過的單位。Prosodic filler 的研究發現意謂著，口語語流中，並非所有的語音
信號都承載了同樣重要的語意、語言訊息;也說明了語音縮減(reduction)的原因與來源。在
未來的研究中,我們將進一步釐清這些成分，在語篇分析（Schiffrin, 1987, 1994; Schiffrin et al, 
2001）中的角色。三、我們也將從韻律的現象，檢視如 Leech (1983)所提出的經典語篇分析
與語用的交互關係。具體言之，是從資訊承載量（Lambrecht, 1994）的角度，探究 topic, focus
的口語現象。研究主要的脈絡，較偏向以句法、語篇的語意為主的研究（如 Sgall, Hajicova 
and Panevova1986; Partee and Sgall,1996; Hajicova, Partee and Sgall,1998;）及語篇策略
（Gumperz,1982）、語篇與語用（Leech 1983）的研究。 
此外，我們研究口語語流韻律，無論是與中文或西文研究語篇或韻律的研究相比，除了上
述的不同及特色外，最大的特色，則在於：一、以口語分析為主、文本分析為輔。先分析
語料，提取韻律特徵，再進一步與文本分析結果對照。二、研究方法係以 corpus linguistics
  4
(二) 以 Fujisaki Model 為基礎，發展自動擷取國語基頻曲線特徵參數系統 
Fujisaki 等人 1984 年提出基於發聲機制的疊加式 command-response 基頻曲線模型，主張產
生基頻主要器官為聲帶 (vocal tract) 及相鄰的隨意肌。控制隨意肌時，有一定物理特性的限
制，對應於語言單位，在時間程上產生聲帶高低變化；所以基頻曲線並非任意直線或曲線，
必須受制於一定的規則在時間程所產生的變化，而此限制顯現於對數尺度之中，此為基頻
曲線的函數限制。此一 command-response 模型一般通稱為 Fujisaki Model，其特點在於將時
間程上動態變化的不規則基頻曲線，拆解為三個單位大小不同的元件函數 (component) 疊加
總合（如圖 2 所示），並分別對應發聲器官的物理特性。此三元件函數分別為 (1) 短語句調
元件  (Phrase Component Ap)，反映較大單位基頻曲線的控制與發聲限制；(2) 強調元
件 (Accent Component Aa)，反映較小單位基頻曲線的控制發聲限制；與 (3) 基底頻率 (base 
frequency Fb) 代表基本音高。此模型定義如下： 
 
 
原 Fujisaki Model 中 Phrase Component Ap 泛指短語句調或語調對全面性基頻曲線造成的影
響，其單位或範圍並未界定，一般應用是以短語句調為單位。Accent Command Aa 則泛指
強調、加重語氣對局部基頻曲線造成的影響。此模型應用於非聲調語言如英語、德語時，
Ap 用以描述片語的語調或短語的句調，即陳述句的由高走低的下傾趨勢及下傾程度；Aa
則用來描述某些局部的加重或加強 (emphasis) (Mixdorff 2001, 2002)。此模型應用於聲調語
言如國語時，Ap 不變，仍用來描述句調的高低走勢，即片語的語調或短語的句調；而 Aa
則用來描述每一個單音節的局部變化，以表現字調 (Mixdorff et al. 2003, Tseng & Pin 
2004)。本研究分析國語連續語流的基頻走勢時，以 Aa 表示字調成分，Ap 表示短語句調成
分。 
 
圖 2 強調元件與基底頻率疊加後的基頻曲線（Fujisaki & Hirose 1984） 
 
在本研究中，我們除驗證 HPG 架構，也希望探討由聽覺感知所獲之語篇韻律邊界與基頻曲
線的關係，因此我們加入邊界資訊作為自動擷取 Fujisaki Model 的 Ap 參數的輸入參數。初
  6
4. 音節及各級韻律單位在接受語流韻律的位置與階層規範後，需做何種調整。 
5. 音長調整與基頻重設的對應關係。 
6. 語流韻律的節奏代表型與各音節固有長度(intrinsic duration)如何互動調整 
 
主要研究成果包括： 
一、針對韻律邊界與相鄰韻律單位的系統性關係進行驗證研究。 
分析連續口語語流中的聲學參數，結果發現：語段內的韻律短語邊界間相鄰韻律單位超音
段參數狀態的相對性，比起相鄰韻律短語間的停頓時長，更具有區分及表達短語邊界的代
表性。而制約管轄韻律邊界相鄰聲學狀態相對性、建構此種相對韻律語境的規範，則來自
上層語篇訊息（higher level discourse information）。我們以大批語料檢驗各級韻律單位分層
貢獻度的統計數據，證明語段中韻律短語邊界後的停頓時長變化多端的來源並導出對比組
型，說明了韻律短語邊界前後的韻律詞時長與音強的明顯對比性，與邊界停頓時長無關。
因此，相鄰韻律狀態的相對性是韻律短語邊界更加重要的聲學語音特徵得到證明；同時，
口語語流中韻律短語的停頓時長變化如此多端也得到解釋。這樣的實驗結果可應用在語流
的自動語音切分（automatic speech segmentation）。此項研究成果撰寫成論文，以「Pause or 
No Pause ? --Prosodic Phrase Boundaries Revisited」為題（附件一），發表於 2007 年 10 月 21-24
日於黃山所舉行的「第九屆全國人機語音通訊會議」(The 9th National Conference on 
Man-Machine Speech Communication)，本次會議選入 120 餘篇論文，獲選論文中再遴選 36
篇（35％）由清華學報（Tsinghua Science and Tecnology）出版專刊，此篇論文獲選其中，
列入 EI 電子資料庫檢索。 
二、針對句法規則與韻律邊界之間的對應及不對應進行深入分析。 
我們就韻律單位韻律短句 PPh 與句法單位句法短句 sentence 間的不比配之處，從語段上層
訊息的貢獻度做深入分析，結果發現：韻律短語與句法結構間的不比配，韻律結構是主要
原因，只要維持了韻律單位的組型特徵，即便違反了句法規則，仍無損於聽者的理解，顯
示口語中語者溝通意圖通過韻律表達的成分制約了句法規則，因此，短句成段時，句法規
則需受韻律表達的管轄制約。此項研究成果撰寫成論文，以「What Do Speakers Do and 
Why--The Story of Prosody-Syntax Non-Overlap and Higher Level Discourse Information」為題
（附件二）發表於 2007 年 12 月 4-6 日於越南舉行的 Oriental COCOSDA (International 
Committee for Coordination and Standardization of Speech Databases and Assessments) 2007。 
三、提出研究相對語音訊息（relative phonetic information）的新角度。 
我們透過量化國語流暢敍事語料，以兩項實驗分別檢驗:(1).獨立(單一)語音聲學參數與相依
(成組)語音聲學參數的邊界鑑別力，其中包括 5 項獨立(單一)語音聲學特徵：(1)邊界停頓(2)
邊界前音節時長(3)邊界前音強(4)時長反差(5)音節音強反差；以及(2).10 組由以上 5 項聲學
特徵所組成的相依(成組)語音聲學參數。結果顯示：單一聲學線索不如成組語音聲學參數來
得有鑑別力，我們因而對韻律短語末邊界延長及邊界效應對構建語篇邊界鑑別力及語篇語
境，獲得系統性的理解，並得以強調由相對角度所獲有關超音段聲學語音訊息之理解，非
語音學研究重絕對音質之角度所能達，更進一步闡釋語篇韻律的韻律邊界與時域結構之間
  8
調成份與字調成分對應各韻律階層的貢獻度，（2）字調成分在各階層韻律單位管轄下，基
頻模型參數如何變化。結果發現：儘管大部份的字調貢獻度主要來自音節層與韻律詞層，
但（1）音節 Syl 層的貢獻度低於 50％，表示字調的貢獻度僅止於此；且（2）邊界效應的
貢獻度介於 5~7%，表示韻律邊界的效應確實存在，每一韻律階層亦皆須考慮邊界效應的貢
獻度，才能更精確的掌握基頻變化的成因。此項研究成果撰寫成論文，以「以 Fujisaki 模
型驗證連續語流中字調及韻律詞對應於階層性韻律架構 HPG 的意義」為題（附件五）發表
於 2008 年 9 月 4-5 日中華民國計算語言學會於台北所舉行的「第 20 屆自然語言與語音處
理研討會」（Proceedings of the 20th Conference on Computational Linguistics and Speech 
Processing）。 
三、提出研究語篇韻律語境（Discourse Prosody Context）的新角度。 
關於語篇韻律語境，我們假設：各韻律階層均有語境，表達不同韻律層級的語境關係；必
要的語境關係至少應包括相鄰單位的平滑銜接的呼應或對比與跨單位的呼應，因而檢視並
比較語段內與語段間不同 PG 序列位置短語的整體基頻高度與時程組型。亦即，口語連續
語流中，語篇韻律同時是由跨單位與相鄰單位的整體組型與調整所呈現，語境具有語意關
連與不同等級的韻律區辨性及意義。為驗證以上研究假設，我們分析了兩項關於韻律短語
PPh 整體組型與調整的聲學參數，分別是：語篇組織中韻律短語的「整體基頻高度調整與
語速改變」。具體而言，我們以 Commend-Response (Fujisaki) Model 擷取韻律短語 PPh 整體
基頻，並且以更精確的平均音節時長計算方式算出各級韻律單位的整體語速變化並導出每
一韻律層級的組型。結果發現（1）PG 內的韻律短語音高呈系統性。以韻律短語 PPh 為單
位，比較多短語韻律句群 PG 內三個 PG 位置首、中、尾的 Ap 平均值的結果，發現這三個
PG 位置的 Ap 組型係由高而低逐漸下降，跨短語的首尾的對比最大，相鄰的首中或中尾的
對比則均不及首尾對比，顯示韻律短語的音高表達韻律語境，跨單位的顯著整體音高對比
表達句段的首尾呼應，而相鄰單位不盡明顯的對比則表延續，三者共構語段內部韻律短語
的關連性。（2）PG 間的相鄰韻律短語音高亦呈系統性。以韻律短語 PPh 為單位，比較 PG
間相鄰韻律短語的平均 Ap，發現由前一 PG 尾到下一 PG 首間的相鄰，其組型為由低而高
突然驟升，對比差異極大，表示句段主題轉換及句段的相鄰，有短語音高對比的重要韻律
語境。（3）PG 內及 PG 間的韻律短語語速亦呈現同樣快慢對比。PG 內三個位置的韻律短
語 PPh 平均語速，由快漸慢，且同樣以 PG 首尾韻律短語的快慢對比最大；PG 間的由尾至
首的組型則為由最慢驟升到最快，表示句段主題轉換時，亦有短語快慢的重要韻律語境。
此項研究成果撰寫成論文，以「Discourse Prosody Context—Global F0 and Tempo 
Modulations」為題（附件六），發表於 2008 年 9 月 22—26 日於澳洲布里斯本所舉行的
Interspeech 2008 國際學術研討會。 
四、增加跨語言韻律轉借(Suprasegmental Borrowing)的構想。 
現今以網路為主的語音科技開發研究，必須面對中英語混用的口語，並因應相關的語音科
技設計。本計畫進一步提出韻律轉借的假設，認為有別於以音段為主的第二外語 L2 英語口
音的研究，不同韻律層級的韻律現象，亦為外語口音的重要來源。韻律層面的口音擬通過
以下的對話的設計，經由找尋韻律轉借中，國語的字調轉借到第二外語 L2 口說英語現象，
證明字調轉借是聲調語母語者的 L2 英語的特徵之一。設計包括（1）看圖描述(picture 
  10
2010 年 9 月 26—30 日於日本幕張所舉行的 Interspeech 2010 國際學術研討會，闡述聲學語
音的語流韻律與口語篇章研究的理論意義，主要找到許多母語者從聽感對口語分析處理
（spoken language processing）的策略與語音信號間的關係，解答了許多文獻上未曾討論或
解決的課題，對語篇韻律的瞭解做出貢獻。 
二、整理累積超過十年所建立的韻律語流語音資料庫 Sinica COSPRO，建立語音標註與分
析的工具平臺。 
「中央研究院口語韻律語料庫暨工具平台」(Sinica Continuous Speech Prosody Corpora & 
Toolkit，簡稱 Sinica COSPRO & Toolkit)包含九個子語料庫（共 10.58GB，其中 7.7GB 為已
處理標註語料），COSPRO 01-08 屬於麥克風朗讀語音，COSPRO 09 則為麥克風自發性語音
（76MB）。內容包羅了不同長度的語料，短至孤立詞組(1-4 字詞)，長至段落語篇（85-996
音節）。由 114 位語者因不同的研究目的錄製而成，其中包括 61 位女性，53 位男性。可供
語音研究、語音合成與語者辨識等多方面應用。而 COSPRO Toolkit 係一視窗介面
（Window-based）、好操作（user-friendly）的語音分析暨合成之工具平台，集合了 Adobe® 
Audition®, Praat© and Speech Viewer®等常見語音分析(合成)軟體之特點，其主要功能有：聲
學訊號分析功能、標記口語語流功能以及重新合成語音訊號（re-synthesizing speech signals）
功能。Sinica COSPRO 語料庫的設計主要係為了要呈現口語連續語流的韻律特徵，其特徵
是語言學導向與理論應用，強調存在於口語語流韻律中的語篇關連性或敍事效應。以上部
份研究成果首見於 Tseng 等人於 2005 年 Oriental COCOSDA 國際學術研討會發表的「Sinica 
COSPRO and Toolkit—Corpora and Platform of Mandarin Chinese Fluent Speech」，2010 年作
者增補更新研究成果，以「Sinica COSPRO—Corpus and Tools for Mandarin Fluent Speech 
Prosody」為題（附件九），撰寫專書論文，收錄於 Computer Processing of Asian Spoken 
Language 一書中。 
三、解構語流基頻信號以釐清各級韻律單位的分層貢獻度及基頻體現中的共構成分。 
我們從語篇組織角度重新定義語篇韻律單位，依「階層式多短語語流韻律 HPG 架構」
(Hierarchical Prosodic Phrase Grouping) 之層疊與覆蓋關係，解構不同韻律格式語料的音高
的構組，證明口語語流的基頻聲學體現，乃由字調、韻律詞調、句法調、語篇聯繫位置、
邊界延長、邊界停頓等成分系統性共構，並以各級韻律單位的相鄰與跨單位之對比與反差，
證明較大韻律單位與語篇邊界效應亦為韻律語境之構組成分。各級韻律單位對韻律生成均
有貢獻，層級貢獻度可透過統計分析釐清，不同韻律格式之體現反映於層級貢獻度的分布
差異。研究方法則凸顯語料庫語言學及計算語言學解析動態超音段聲學參數相對性的重要
與意義。本研究部分內容曾發表於以下兩篇會議論文：(1)〈從不同韻律格式驗證階層式韻
律架構並兼論對語音科技的應用〉（「第十九屆自然語言與語音處理研討會」，2007 年 9
月 6-7 日），及 (2)〈以 Fujisaki 模型驗證連續語流中字調及韻律詞對應於階層性韻律架構
HPG 的意義〉（「第二十屆自然語言與語音處理研討會」，2008 年 9 月 4-5 日）。彙整以
上研究結果，修訂及增添新的研究數據及成果撰寫成期刊論文，以「解構語流韻律基頻的
層疊與共構」為題，發表於 2010 年出刊的《語言暨語言學》第 11.2 期中（附件十）。 
 
  12
Edwards, J. and Beckman, M. 1987. Perception of final lengthening. The Annual Meeting of the 
Linguistic Society of America, 13 pages.  
Fon, J. and Johnson, K., 2004. Syllable onset intervals as an indicator of discourse and syntactic 
boundaries in Taiwan Mandarin. Language and Speech, 47(1): 57-82. 
Fujisaki, H. and Hirose, K. 1984. Analysis of voice fundamental frequency contours for 
declarative sentences of Japanese. The Journal of the Acoustical Society of Japan (E) 5(4): 
233-242. 
Gu, W., Hirose, K. and Fujisaki, H. 2005. Identification and synthesis of Cantonese tones based 
on the command-response model for F0 contour generation. Proceedings of 2005 IEEE 
International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2005), Vol. 1, 
I289-I292. Philadelphia, Pennsylvania, USA. 
Gumperz, J. J., 1982. Discourse Strategies. Cambridge University Press. 
Gussenhoven, C. 1997. Types of focus in English? In Daniel Buring, Matthew Gordon and 
Chungming Lee (eds.) Topic and Focus: Intonation and Meaning: Theoretical and 
Crosslinguistic Perspectives. Dordrecht: Kluwer.  
Hajicova, E., Partee, B. H., and Sgall, P. 1998. Topic-Focus Articulation, Tripartite Structures, 
and Semantic Content. Kluwer Academic Publishers. 
Halliday, M. A. K. 1967. Intonation and Grammar in British English. The Hague: Mouton. 
Hasan, R. and Fries, P. H. eds. 1995. On Subject and Theme: a Discourse Functional Perspective. 
John Benjamins Publishing Co., Amsterdam, The Netherlands.   
Jurafsky, D. and H. Martin, J. 2000. Speech and Language Processing. Prentice Hall Publishing 
U.S.A. 
Keller, E., Zellner, B., Werner, S., and Blanchoud, N. 1993. The prediction of prosodic timing: 
Rules for final syllable lengthening in French. Proceedings of ESCA Workshop on Prosody, Lund, 
Sweden, pp. 212-215.  
Keller, E. and Zellner, B. 1996. A Timing model for fast French. York Papers in Linguistics 17: 
53-75, University of York. 
Ladefoged, P. 2006. A Course in Phonetics. Boston, MA: Wadsworth, 5th Edition. 
Ladd, D. R. 1988. Declination “reset” and the hierarchical organization of utterances. Journal of 
the Acoustical Society of America 84:530-544.  
  14
Nespor, M., and Vogel, I. 1986. Prosodic Phonology. Dordrecht: Foris. 
O’Shaughnessy, D. 1995. Timing patterns in fluent and disfluent spontaneous speech. 
Proceedings of the International Conference on Acoustics, Speech and Signal Processing, pp. 
600 – 603. Detroit, Michigan, U.S.A.  
Partee, B. H., and Sgall, P. eds. 1996. Discourse and Meaning: Papers in Honor of Eva Hajicova. 
John Benjamins Publishing Co., Amsterdam, The Netherlands. 
Peng, H., Chen, C., Tseng, C. and Chen, K. 2004. Predicting prosodic words from lexical words: 
a first step towards predicting prosody from text. Proceedings of the 4th International 
Symposium on Chinese Spoken Language Processing (ISCSLP 2004), 173-176. Hong Kong 
SAR, China. 
Pike, K. L. 1943. Phonetics: A Critical Analysis of Phonetic Theory and a Technic for the 
Practical Description of Sounds. Ann Arbor: University of Michigan Press. 
Pierrehumbert, J. B. 1980. The Phonology and Phonetics of English Intonation. Cambridge: MIT 
dissertation. 
Price, P. J., Ostendorf, M., Shattuck-Hufnagel, S. and Fong, C. 1991. The use of prosody in 
syntactic disambiguation. Journal of the Acoustical Society of America, 90.6:2956-2970. 
Schiffrin, D. 1987. Discourse Markers. Cambridge University Press, Cambridge, New York. 
Schiffrin, D. 1994. Approaches to Discourse. Blackwell Publishers. 
Schiffrin, D., Tannen, D., and Heidi E. Hamilton eds. 2001. The Handbook of Discourse Analysis. 
Blackwell Publishers. 
Scott, N. C. 1941. Broad transcriptions. Le Maître Phonétique 76:48-51. 
Selkirk, E. 1984. Phonology and Syntax: The Relation between Sound and Structure. Cambridge: 
MIT Press. 
Selkirk, E. 2000. The interaction of constraints on prosodic phrasing. In Merle Horne (ed.) 
Prosody: Theory and Experiment, Dordrecht: Kluwer. pp. 231-262.  
Silverman, K., Beckman, M., Pitrelli, J., Ostendorf, M., Wightman, C., Price, P. Pierrehumbert, J. 
and Hirschberg, J. 1992. TOBI: A standard for Labeling English Prosody. In Proceedings of 
the 1992 International Conference on Spoken Language Processing, Vol. 2, pp. 867-870. 
Banff, Canada  
  16
Tseng, C. and  Fu B. 2005. Duration, intensity and pause predictions in relation to prosody 
organization. Proceedings of Interspeech 2005, 1405-1408, Lisbon, Portugal. 
Tseng, C. 2006a. Prosody analysis. In Advances in Chinese Spoken Language Processing, Lee, C., 
Li, H-Z., Lee, S-S., Wang, R.-H and Huo, Q. (eds) World Scientific Publishing, 57-76, 
Singapore. 
Tseng C. 2006b. Recognizing Mandarin Chinese fluent speech using prosody information—An 
initial investigation. The 3rd International Conference on Speech Prosody 2006, Dresden, 
Germany. 
Tseng, C., Su, Z., Chang, C. and Tai, C. 2006. Prosodic filers and discourse markers—Discourse 
prosody and text prediction. TAL 2006 (The Second International Symposium on Tonal 
Aspects of Languages), (April 27-29, 2006), La Rochelle, France.  
Tseng, C. and Su, Z. 2007. From one base form to multiple output styles-- Predicting stylistic 
dynamics of discourse prosody. Interspeech 2007-Eurospeech. 110-113. Antwerp, Belgium. 
Tseng, C. and Su, Z. 2007. What do speakers do and why –The story of prosody-syntax 
non-overlap and higher level Discourse Information. Oriental COCOSDA 2007, (December 
4-6, 2007), Hanoi, Vietnam, pp. 27-32.  
Tseng, C. and Chang, C. 2007. Pause or no pause?—Phrase boundaries revisited. The 9th 
National Conference on Man-Machine Speech Communication（NCMMSC  2007, 第九屆全
國人機語音通訊會議）, (October 21-24, 2007), 黃山, 中國 
Tseng, C. and Su, Z. 2008. Boundary and lengthening—On relative phonetic information. The 8th 
Phonetics Conference of China and the International Symposium on Phonetic Frontiers, 
Beijing, China. 
Tseng, C. and Su, Z. 2008. Discourse prosody and context–Global F0 and tempo modulations. 
Proceedings of the Interspeech 2008, (Sep. 22-26, 2008), Brisbane, Australia, pp. 1200-1203.  
Tseng, C. and Su, Z. 2008. What’s in the F0 of Mandarin Speech –Tones, Intonation and beyond. 
ISCSLP 2008 (The 6th International Symposium on Chinese Spoken Language Processing), 
(December 16-19, 2008), Kunming, China, pp. 45-48.  
Tseng, C. and Chang, C., 2008. Pause or no Pause?—Phrase boundaries revisited. Tsinghua 
Science and Technology 13.4: 500-509. 
  18
錢瑤、初敏、潘悟雲 2001. 普通話韻律單元邊界的聲學分析。第五屆全國現代語音學會議。
中國：北京，70-74。 
曹劍芬 1998. 漢語普通話語音節奏的初步研究。中國社會科學院語言研究所語音研究報告
1998。北京：中國社會科學院語言研究所。 
曹劍芬 2005. 音段延長的不同類型及其韻律價值。中國社會科學院語言研究所語音研究報
告 2005。北京：中國社會科學院語言研究所，5-12。 
鄭秋豫 2001. 語流中韻律結構的主要徵信。 第 6 屆全國語音通訊學術會議 (NCMMSC-6)， 
(Nov. 19-24, 2001)，中國：深圳，169-172。 
鄭秋豫、蘇昭宇 2007. 從不同韻律格式驗證階層式韻律架構並兼論對語音科技的應用。第
十九屆自然語言與語音處理研討會，(Sep. 6-7, 2007)，中華民國計算語言學會, 台北. 
103-115. 
鄭秋豫、蘇昭宇 2008. 以 Fujisaki 模型驗證連續語流中字調及韻律詞對應於階層性韻律架
構 HPG 的意義。第二十屆自然語言與語音處理研討會, (Sep. 4-5, 2008), 台北, 台灣. 
53-65. 
鄭秋豫. 2008. 語篇韻律與上層訊息──兼論語音學研究方法與發現。語言暨語言學，
9.3:659-719。 
鄭秋豫. 2010. 語篇的基頻構組與語流韻律體現。語言暨語言學，11.2:183-218. 
吳為章, 田小琳, 2000, 《漢語句群》, 北京：商務印書館 
程祥徽, 田小琳, 1992, 《現代漢語》, 臺北：書林 
黃國文編, 2003, 《語篇分析概要》, 湖南：湖南教育出版社 
葉 軍, 2001, 《漢語語句韻律的語法功能》, 上海：華東師範大學出版社 
馮勝利, 1997, 《漢語的韻律、詞法與句法》, 北京：北京大學出版社 
馮勝利, 2000, 《漢語韻律句法學》, 上海：上海教育出版社 
馮勝利, 2005, 《漢語韻律語法研究》, 北京：北京大學出版社 
 
 
 
 
 
  20
L2 英語，因而獲得跨語料、跨語言、跨發音人的分析，驗證假說。在此前提下，三年的
研究創獲如下： 
（1）對所提的韻律假說，完成所有聲學語音參數的驗證，並驗證韻律衍生的規律性。 
我們 2004、2005 年提出語篇韻律假說「階層式多短語韻律句群」時，在聲學參數方
面僅獲得時長的系統性證據及規則，到 2008 年已獲得其他二聲學參數音高（基頻）
和響度（音強）所需的所有證據，至此，我們的假說因而獲得完整的聲學驗證，解
釋表面雜亂多變的語篇韻律體現，其實是系統性層層數學性疊加的結果，有規則可
循、可預測也可驗證。結合實驗語音學、語言學，用計算語言學的研究方法，從預
測的正確度，全面驗證假並獲證據，在語篇韻律研究方面，至今沒有可與之相比的
論述。 
此外，我們也通過各種語言格式（如散文、詩詞、古文、氣象報告）得到證據顯示，
語篇訊息存在每種語料中，一個基型、少數的規則，只需調整各級成分的貢獻度，
便可產製出各種相對應的韻律格式，再次驗證語言的衍生，也可從韻律訊息中找到
證據。（鄭秋豫&蘇昭宇，2007、2008；鄭秋豫，2010） 
（2）從語篇組織成分解構並解釋聲調（字調）、短語調和韻律調的共組成分及其系統性。
強調聲調語言的聲學語音研究，除了單獨發音的單音節詞，連續口語韻律分析無論
採何種方法，都必須處理這些成分。 
動態音高變化的形式是表達語調和韻律調最主要的特徵，其聲學參數是基頻，然而
聲調語言裡調型不但也是動態，而且也是藉由動態音高的變化形式來表達。也就是
說，一段口語裡，韻律調、語調和字調的體現，各自都有範圍大小不同基頻變化，
這些變化混在一起互動互補後，產生了口語的整體體現。因此，研究聲調語言的語
調和韻律調有一個最大的困難，就是如何從音高（基頻）中把字調、語調和韻律調
三者的關係釐清，這比時長的解析困難太多了。我們採取了 Fujisaki 模型來處理這個
困境，因為這個模型是一個預測基頻形式的數學模型，運用三個數學參數將一段語
音（如一個複和詞或短句）的基調、整體音高走勢和這段語音裡音高特別會突起的
部分分別預測出來再加總起來，然後與原來那段語音比較預測到底準確到什麼程
度。從 1984 年以來，使用這個模型的學者不知凡幾，但直到 2000 年左右，才有德
國學者 H. Mixdorff 將之應用到各種聲調語言的研究，成功的將聲調和語調釐清。 
但採用這個模型，我們也遭遇極大的困難。參考 Mixdorff 的研究，發現他一來未能
將參數抽取自動化，以致無法處理大批語料；二來只以研究短語為主，未能應用到
語篇韻律的抽取；三來他是工科學者，無法也無意提出語言學上的解釋。這三點連
Fujisaki 教授自己也是一樣的，至今也只有語感和少量各語言的證據，沒有驗證大批
語料的證據。能否發展出自動抽取的方法處理大批語料是必須突破的困難，否則無
法使用計算語言學的方法，以模型預估的正確率驗證。從大批語料自動抽取這些參
數的模型，終於在 2007 完成。對處理基頻這個聲學信號，是一個重大突破，因為我
們可以從混在一起的信號中，將聲調和語調的成分，分別抽出並加以預測。聲調語
語調的分解，是所有研究聲調語言的聲學語音研究，都不能不面對的問題。2010 年
4 月發表在《語言暨語言學》11.2：183-218 的論文〈語篇的基頻構組與語流韻律體
現〉，就是論述如何將基頻信號以語篇層級分層拆解，釐清聲調、語調和韻律調的各
自貢獻度後，再找出其如何共構語流韻律體現。多年來只有採用 Fujisaki 模型的學
者，會將基頻信號裡的聲調和語調拆開，但從語篇結構層層拆解的，至今只有我們。
近年來有較多的工科學者們開始注意到必須將基頻信號拆解，也各自提出了數學模
型，但他們的拆解，多以單獨的短句為單位，因此只能拆解個別短句，但完全不能
解釋結構相同的短語，為何在語流中變化多端，也就是沒有考慮語篇成分。能從語
言學的角度提出全面解釋的，幾乎未見。 
 （3）除此以外，我們也對語音學一些經典的韻律課題，從語篇韻律角度獲得以下新解：
  22
詩歌、樂府、古文、氣象播報模擬。 
（2）跨語言（中、英語）的研究，提供比較語言的新證據：母語轉借的韻律現象及解釋。
2009 年開始收集以國語母語者的英語口語（L2E）、英語母語者的英語口語（L1E），
並展開國語母語（L1M）者的 L2E 的韻律轉借研究，初步獲得音節時長語言（國語）
及輕重音（英語）在節奏面的轉借證據，證明母語的韻律轉借，是以系統性的導出
（詳見 Visceglia, Tanya and Tseng, Chiu-yu. 2009. Spontaneous Speech Database Design 
for Suprasegmental Characteristics in Asian L2 English. Proceedings of the 10th National 
Conference on Man-Machine Speech Communication（NCMMSC  2009, 第十屆全國人
機語音通訊會議）, 549-554. Aug. 14-16, 2009. Urumqi, Xinjiang.）。 
 
for perceived boundary breaks by trained transcribers using 
the Sinica COSPRO Toolkit [8]. Annotation results were 
spot-checked by professional transcribers for segmental 
alignments as well as inter-transcriber consistency.. 
  
2.2. Methods of Analysis Speech Data 
We analyzed the speech data in three steps: 1. three acoustic 
parameters were extracted from annotated speech data, i.e., 
pause, syllable duration and intensity. 2. Derived acoustic 
parameters were subsequently normalized. 3. Respective 
layered contributions specified by the HPG framework were 
obtained through a step-wise linear regression model. Figure 
1 is a flowchart that shows the basic HPG analysis.  
Sinica
COSPRO 
Database
Acoustic Features 
Extraction
Speech Data
Normalization
Step-wise Linear 
Regression Model 
Contribution of Each 
Prosody Layer 
TTS System
 
Figure 1: Flowchart of Analysis by HPG Framework. 
 
Table 1 summarizes derived acoustic features of both 
speakers, where µ and σ represent the mean and standard 
deviation of each acoustic feature, pause, duration and 
intensity, respectively. 
Table 1.  Derived Acoustic features by speaker. 
Speaker μPause σPause μDuration σDuration μIntensity σIntensity 
F051P 37 106 200 65 3.65 0.07
M051P 45 138 190 60 3.62 0.05
2.3. Speech Data Normalization 
In order to eliminate between-speaker variations, each set of 
data was normalized with the mean and standard deviation of 
the entire class. The original method of normalization [4] 
would easily be affected by extreme data, causing normalized 
data distribution of to shift, and thereby making comparisons 
between speakers meaningless. To rectify the situation, we 
modified the normalization as follows: 
Ynor(n)} .Ynor(2),.. Ynor(1), { Ynor 
Y / )Y -  (Y(i)  Ynor(i)
=
= σµ  
Y(i) and Ynor(i) represent each datum in Class Y and 
Normalized Class Y respectively. µY and σY represent the 
mean and standard deviation in Class Y. The same 
modification was made for the three acoustic features under 
consideration. Hence Y would be duration, intensity and 
pause in the following sections. 
2.4. Revising the Duration Model 
A syllable duration model corresponding to the HPG 
framework was constructed previously [7] to predict and 
locating boundary breaks B2 to B5across continuous speech 
rather than simply predicting pauses. The predictions thus 
bear discourse information in relation to prosody organization 
specified by HPG. Higher level BG and PG boundary breaks 
(B4 and B5 respectively) indicating multiple-phrase speech 
paragraphs across fluent continuous speech could easily be 
located using pause durations alone (see Section 1), whereas 
lower level within-paragraph boundary breaks B3 and B2 
corresponding to PPh and PW respectively were predicted 
using both boundary break pause and durations of one 
immediate neighboring syllable.  
The goal of the present study is to revise the syllable duration 
model by altering both the Syllable (the bottom) layer and the 
PW (the immediate higher) layer of the previous regression 
model to better predict PPh boundary B3. Using the same 
step-wise regression technique [2, 3], a linear model with four 
layers [9, 10] was modified and developed to predict 
speakers’ timing behavior through temporal allocation of 
syllable duration modification. At the syllable layer, we used 
6 consonant groups and 6 vowel groups in order to decrease 
the difference between groups. The Revised Syllable Layer 
Model could be written as function (1): 
 Delta1    
abovefactor each  of constraintboundary PW     
above syllableeach  of Factorsway -3    
abovefactor each  of Factorsway -2    
FTt FVt FCt PTt PVt PCt     
Tt  CVt CCt ConstYnor
+
+
+
+
++++++
+++=
  (1) 
In function (1), we added a new condition that is constrained 
for each factor in PW boundary to include co-articulation 
effect such as tone sandhi at the PW layer. Prefix C, P and F 
represent current, preceding and following syllable, 
respectively. Ct, Vt and Tt represents consonant, vowel and 
tone type, respectively. Subsequently, residuals Delta1 that 
could not be predicted by the syllable layer are then analyzed 
in the immediate higher layer.  
Figure 2 shows the distribution of Delta 1 (the residuals of the 
syllable layer) of the revised duration model from the speech 
data where the horizontal axis represents Breaks from B1 to 
B5, and the vertical axis represents the residual value from -2 
to 3. Significant difference (p-value<0.001) was found with 
respect to the durations between the distributions of B2 and 
those greater than B2, as well as between speakers, 
respectively. The results enabled us to avoid overestimating 
contribution of B2 from the PW Layer, thus we decided to 
add a constraint condition to only calculate f(PW) in the B2 
level.  
0 1 2 3 4 5 6
Break Index
-2
-1
0
1
2
3
D
el
ta
 1
 
0 1 2 3 4 5 6
Break Index
-2
-1
0
1
2
3
D
el
ta
 1
 
Figure 2: Distribution of Delta 1 of the revised duration 
model for speakers F051P and M051P. 
The Revised PW Layer Model could be written as function 
(2): 
speakers F051P and M051P. 
-0.5
-0.4
-0.3
-0.2
-0.1
0
0.1
0.2
0.3
0.4
1 2 3 4
-0.5
-0.4
-0.3
-0.2
-0.1
0
0.1
0.2
0.3
0.4
1 2 3 4
 
Figure 7: The PW patterns of the revised duration model for 
speakers F051P and M051P. 
Figure 8 shows the duration patterns of PPh (6-11 syllables in 
length) along the temporal course by syllable number and by 
speaker from the previous model [7] while Figure 9 shows 
patterns from the current revised model. Instead of 
considering only one immediate neighboring syllable of 
annotated B3, i.e., one pre- and post-B3 syllable only, we 
defined immediate between-PPh neighborhood as the last 4 
syllables of a preceding PPh and the first 3 syllables of the 
following PPh. By this definition, PPh neighborhood is 
defined by units that would encompass boundary immediate 
PW rather than single syllables, a definition that better 
reflected the rationale of our HPG framework. Note that the 
cross-boundary contrast is more distinct in the revised model 
than that from the previous model.  
 
-0.6
-0.4
-0.2
0
0.2
0.4
0.6
0.8
1
1.2
Pre 4 Pre 3 Pre 2 Pre 1 B3 Fol 1 Fol 2 Fol 3
6
7
8
9
10
11
-0.6
-0.4
-0.2
0
0.2
0.4
0.6
0.8
1
1.2
Pre 4 Pre 3 Pre 2 Pre 1 B3 Fol 1 Fol 2 Fol 3
6
7
8
9
10
11
 
Figure 8: The PPh patterns of the previous duration model for 
speakers F051P and M051P. 
-0.6
-0.4
-0.2
0
0.2
0.4
0.6
0.8
1
1.2
Pre4 Pre3 Pre2 Pre1 B3 Fol1 Fol2 Fol3
6
7
8
9
10
11
-0.6
-0.4
-0.2
0
0.2
0.4
0.6
0.8
1
1.2
Pre4 Pre3 Pre2 Pre1 B3 Fol1 Fol2 Fol3
6
7
8
9
10
11
 
Figure 9: The PPh patterns of the revised duration model for 
speakers F051P and M051P.  
 
In addition, Figures 7 and 9 combined also show how patterns 
derived from the revised model are more contrastive in 
general than patterns derived from the previous model as 
shown in Figures 6 and 8. 
3.2. Comparison of Intensity Predictions 
Figure 10 shows the intensity patterns of PW (1-4 syllables in 
length) along the temporal course by syllable number and by 
speaker from the previous model while Figure 11 shows 
patterns from the current revised model. Similar to results 
from the revised duration model, the revised intensity 
prediction patterns at the PW layer are also opposite from 
previous predictions. Figures 12 and 13 show both the 
intensity distribution of PPh patterns from the previous and 
revised models; PPh’s ranged from 6 to 11 syllables. Note 
that the PPh patterns from the revised model decayed more 
drastically towards boundary, thus matching the tendency of 
the intensity attenuation for PPh final weakening, especially 
for speaker M051P. Once again the cross-boundary contrast is 
more pronounced from intensity predictions. Coupled with 
more phrase-final syllable lengthening found in Section 3.1, 
the prediction is closer to the physical speech data. Therefore, 
we believe the cross-boundary contrasts in both duration and 
intensity patterns are significant cues to boundary perception 
regardless of boundary pause duration. 
-0.2
-0.1
0
0.1
0.2
0.3
1 2 3 4
-0.2
-0.1
0
0.1
0.2
0.3
1 2 3 4
 
Figure 10: The PW patterns of the previous intensity model 
for speakers F051P and M051P. 
-0.2
-0.1
0
0.1
0.2
0.3
1 2 3 4
-0.2
-0.1
0
0.1
0.2
0.3
1 2 3 4
 
Figure 11: The PW patterns of the revised intensity model for 
speakers F051P and M051P. 
-0.8
-0.6
-0.4
-0.2
0
0.2
0.4
0.6
0.8
Pre4 Pre3 Pre2 Pre1 B3 Fol1 Fol2 Fol3
6
7
8
9
10
11
-0.8
-0.6
-0.4
-0.2
0
0.2
0.4
0.6
0.8
Pre4 Pre3 Pre2 Pre1 B3 Fol1 Fol2 Fol3
6
7
8
9
10
11
 
Figure 12: The PPh patterns of the previous intensity model 
for speakers F051P and M051P. 
-0.8
-0.6
-0.4
-0.2
0
0.2
0.4
0.6
0.8
Pre4 Pre3 Pre2 Pre1 B3 Fol1 Fol2 Fol3
6
7
8
9
10
11
-0.8
-0.6
-0.4
-0.2
0
0.2
0.4
0.6
0.8
Pre4 Pre3 Pre2 Pre1 B3 Fol1 Fol2 Fol3
6
7
8
9
10
11
 
Figure 13: The PPh patterns of the revised intensity model for 
speakers F051P and M051P. 
3.3. Comparison of Pause Predictions 
Due to space limit, we will present comparison of pause 
prediction from one speaker only. Figure 14 shows the 
comparison of predictions boundary pauses from the  
previous and revised models for speaker M051P where the 
horizontal axis represents the Break index of each syllable, 
and the vertical axis represents pause values from 0 to 750ms. 
We can see that the differences of pauses between the 
previous and revised models for B1 and B2 are greater 
because the previous pause model could be mistaken for 
contribution from lower Break levels. In the revised boundary 
pause model, since the contribution of B1 is about 0.4 ms 
which can not be perceived by the human ear, we ignored the 
contribution from B1 to refine the prediction of lower Breaks.  
-50
50
150
250
350
450
550
650
750
1 1 2 1 3 1 2 1 2 1 2 1 2 1 3 1 1 3 1 3 1 2 1 2 1 5
Brea k Inde x
Pa
us
e 
(m
se
c)
Origina l
P redic tion of the  P revious  P a us e  Mode l
P redic tion of the  Re vis e d P aus e  Mode l  
Figure 14: Comparison of the pause predictions between the 
previous and revised models for speaker M051P. 
 
Figure 18: An example of  F0 Contrast. The left most B3 
occurred at a PPh end where a new PPh begins afterwards and 
ends by the second B3 from left. 
4. Discussion 
Instead of analyzing the duration and intensity patterns of one 
syllable before and after annotated PW and PPh boundary 
breaks in a previous model [5, 7], we analyzed B3’s boundary 
immediate prosodic states in terms of duration and intensity 
distribution along the time domain by PW (4 syllables before 
and 3 syllables after), compared them with those from 
immediate neighboring B2’s, and found different yet 
corresponding patterns in these two acoustic parameters. 
Accordingly, we included factors of duration and intensity to 
revise and fine-tune the linear regression model [7], and 
recalculated contribution predictions from the PW layer to 
final prosody output under the HPG framework. The Total 
Residual Error (T.R.E.) of duration and intensity at the PW 
layer is improved by 10%; overall prediction of output 
prosody is consequently improved by 5%. In addition, the 
layered predictions are now more consistent with the actual 
break distribution in the speech data, 
Based on the above results, we believe that a detailed analysis 
of residual distributions of every prosodic layer (from syllable 
to PPh) can yield more stable and general patterns that lead to 
better prediction.  In Figures 6 and 10, duration and intensity 
patterns at the PPh layer yielded clearer evidences that the 
coefficients of the last 4 syllables are similar irrespective of 
PPh lengths (from 6 to 11 syllables). Thus it became clear 
that to the human ear, PW boundary break B2’s and PPh 
break B3’s can be distinguished from each other not by pause 
duration alone, but by contrastive neighborhood prosodic 
states as well. Evidence of boundary neighboring F0 contour 
patterns also showed similar results. Our analyses also 
showed how contrasts were constituted more by higher level 
constraints from discourse information than by lower level 
concatenation smoothing. To the human ear, it is clear that B2 
and B3 boundaries are within- rather than between-paragraph 
signals; their respective pause duration less relevant.  
The results enable us to better predict B3 and further argue 
that prosodic states relate more to higher level information; 
fluent speech prosody is more than lower level co-articulation 
driven smoothing.  
5. Conclusions 
We believe the above results definitely offer alternative 
rationale for automatic segmentation of fluent speech and 
speech recognition of Mandarin Chinese in general, 
especially to the most commonly adopted approach focusing 
on individual syllabic tone identities and F0 contour patterns, 
and perhaps inadvertently disregarding boundary as well as 
higher level information. The improved model can also be 
incorporated to enhance prosody output of speech synthesis, 
showing where boundary breaks CAN vary greatly to yield 
more natural prosody. Last but not least, though we drew 
evidences from Mandarin Chinese, we believe boundary 
properties in relation to higher level discourse information are 
not at all language specific. 
6. References 
[1] Tseng, Chiu-yu, Cheng Yun-Ching and Chang Chun-
Hsiang (2005). “Sinica COSPRO and Toolkit—Corpora 
and Platform of Mandarin Chinese Fluent Speech”, 
Proceedings of Oriental COCOSDA 2005, pp. 23-28. 
and also http://www.myet.com/cospro  
[2] Tseng, Chiu-yu and Lee Yeh-lin (2004). “Speech rate 
and prosody units: Evidence of interaction from 
Mandarin Chinese”, Proceedings of the International 
Conference on Speech Prosody 2004, pp.251-254. 
[3] Tseng, C., Pin, S., Lee, Y., Wang, H. and Chen, Y. 
“Fluent Speech Prosody: Framework and Modeling.” 
Speech Communication, Vol.46, issues 3-4, (2005), 
Special Issue on Quantitative Prosody Modeling for 
Natural Speech Description and Generation, pp.284-309. 
[4] Tseng, Chiu-yu (2006). “Recognizing Mandarin Chinese 
Fluent Speech Using Prosody Information—An Initial 
Investigation” The 3rd International Conference on 
Speech Prosody 2006, 
[5] Tseng, C., Chou, F., 1999. A prosodic labeling system 
for Mandarin speech database. In: Proceedings of 
ICPhS’99, pp. 2379-238  
[6] Lieberman, Philip. 1967. Intonation, Perception and 
Language, The MIT Press, Cambridge, Massachusetts. 
[7] Tseng, C. and B. Fu. “Duration, Intensity and Pause 
Predictions in Relation to Prosody Organization” 
Proceedings of Interspeech 2005, pp.1405-1408.  
[8] Sinica COSPRO and Toolkit http://reg.myet.com/cospro 
[9] Keller, E., Zellner Keller, B. “A Timing model for Fast 
French”, York Papers in Linguistics, 17, University of 
York. 53-75. (1996) 
[10] Zellner, Keller B, Keller E., “Representing Speech 
Rhythm” Improvements in Speech Synthesis. (pp. 154-
164). Chichester: John Wiley. (2001) 
Our current hypothesis is that in addition to speaker intension, 
within-paragraph prosody-syntax non-overlaps are mostly 
higher information related. More understanding of what 
speakers actually do when producing fluent speech reveals 
information fluent speech prosody bears. Since paragraph and 
discourse involve semantic cohesion above sentences, more 
information than syntactic governing exists in speech flow and 
prosody functions much more than disambiguating underlying 
syntactic structures [1, 2, 3, 4, 5]. We believe one feasible way 
to look into this aspect is to perform syntactic analyses of text 
data for nodes and boundaries [9, 10] and subsequently 
compare with actual speech data [11] to look into the speech-
syntax non-overlap. In other words, what speakers actually do 
and why they did it. 
 
We hypothesize that most of such non-overlaps are due to 
higher-level information and CNA be accounted for. We define 
overlap by mapping of annotated boundaries in speech corpora 
and punctuation marks (PM) in corresponding text; whereas 
non-overlaps are where (1.) no PM in text but a boundary is 
tagged in speech data, (2.) a PM in text but no boundary occurs 
in speech data and (3.) mismatch between PM and produced 
boundary. Three types of speech corpora differing in style and 
format were used: (1.) reading of 26 discourse pieces up to 900 
more syllables/characters by 2 radio announcers of plain text 
(CNA), (2.) reading of weather forecast by 2 untrained 
speakers (WF) and (3.) reading of three Chinese Classics in 
three different rhyming formats by 2 untrained speakers (CL). 
 
  
2. Text and Speech Data 
Three types of corpus and corresponding Mandarin speech data 
are used to examine prosody-syntax non-overlap. The three 
types of corpus contain (1.) reading of plain text of 26 
discourse pieces by 2 radio announcers (one male and one 
female) (CNA), (2.) reading of weather forecast by 2 untrained 
native speakers (WF) and (3.) reading of three formats of 
Chinese Classics by 2 untrained speakers (CL). The location 
and type of punctuation marks in text reveal syntactic 
structures of corpus. What is of interest to us whether the 
punctuation marks involve semantic cohesion above sentences 
that signify larger semantic units. The distribution of each type 
of punctuation marks by corpus is listed in Table 1.  
Table1. Distribution of punctuation marks in text by corpus type. 
    Corpus 
# of PM 
1.CNA 2.WF 3.CL 
Comma， 744 427 269 
period。 317 110 190 
Pause 、 92 83 13 
Semicolon； 20 18 8 
Exclamation！ 14 2 14 
Question？ 44 0 10 
 
 All corresponding speech data are reading of the above text 
produced in sound proof chambers. Pre-analysis annotation 
included automatically labeled segmental identities by the 
HTK toolkit in SAMPA-T notation, followed by subsequent 
manual tagging of perceived boundary breaks by trained 
transcribers using the Sinica COSPRO Toolkit [12]. 
Annotation results were spot-checked by professional 
transcribers for segmental alignments. Table2 summarizes 
speech data corresponding to three types of text corpus. 
Table2. Summary of speech data by corpus type 
Discourse   speaker # of Syl # of PPh # of Discourse 
speech rate 
(ms)/Syl 
f051 11592 1092 26 200 
CNA 
m051 11600 1207 26 189 
f054 7054 676 34 193 
WF 
m054 7096 728 34 165 
f054 3502 308 26 271 
CL  
m056 3510 318 26 202 
3.  Method of Analysis  
The purpose of the analysis is to examine the proportion of 
non-overlaps and look for patterns that CNA be used to model 
the probability of such non-overlaps. All positions of PMs are 
correlated with perceptual labels to find out the corresponding 
perceptual boundaries in speech corpora. Figure 2 shows the 
PM-boundary correlation. 
 
 
Figure 2: Correlation of annotated boundaries in speech corpora and 
punctuation marks (PM) in text. 
 
Initial investigations focus on PM analyses in relation to 
prosody boundaries. Subsequent examinations will aim at 
within-phrase syntactic analyses. 
4. Results  
Results in percentage are presented to compare the distribution 
patterns among different types of corpus and among different 
speakers. 
4.1. Distribution of annotated boundary breaks in 
relation to each type of PM  
Preliminary syntactic analyses of text data by PM are 
performed to examine the matching distribution of annotated 
boundaries in actual speech data. Results are summarized in 
Table 3. The blue blocks in Table 3 denote syntax-prosody 
overlaps and their respective distributions, i.e., PM in text vs. 
matched boundary breaks in speech data. On the other hand, 
prosody-syntax non-overlaps are defined as mismatches; their 
respective distributions presented in red.  
 
Table3. Distribution of annotated boundary breaks in relation 
to each type of PM used in Chinese text. “、” denotes a 
slight-pause mark used to set parallel words or short phrases; 
4.3. Classification of speech data  
In a previous prosody study of reading Chinese rhymed 
classics differing in degrees of regularity of employed rhyming 
template, we found that speakers’ production planning is 
conditioned by the degrees of template regularities [13]. The 
more regular the rhyming templates are; the larger the planning 
units become. In other words, speakers’ planning strategies 
fine-tuned systematically by the nature of materials to be read, 
and the prosody outputs vary. Thus we categorize the speech 
data used in the present data as a control. The speech data were 
classified as colloquial speech with no built-in rhyming 
templates (CNA&WF) and reading of Chinese classics with 
varied rhyming templates (CL) to separate colloquial speech 
from more planned reading. Our aim is to find general 
probability model for the two types of speech data by different 
prosody format.  
 
4.3.1. Distribution of boundary breaks by PM and 
prosody format CNA&WF 
In the colloquial speech data (CNA&WF), all four speakers 
exhibited similar patterns of distributions in terms of 
boundaries and pauses by PMs, comma or period. Three out of 
the four speakers also exhibited similar patterns for pause mark 
and semicolon, as the similar trajectories shown in Figure 4.  
Thus the similar distribution patterns in the majority of 
speakers CNA be regarded as the general probability model for 
specific PM. However, speaker difference does exist as 
observed in speaker f054 (W) who has exhibited semicolon- 
and pause-mark- patterns different pattern from the rest of the 
speakers.  
 
 
Comma- ， 
0.00%
20.00%
40.00%
60.00%
80.00%
100.00%
B1 B2 B3 B4 B5  
Period - 。 
0.00%
20.00%
40.00%
60.00%
80.00%
B1 B2 B3 B4 B5  
Slight-pause between parallels - 、 
0.00%
20.00%
40.00%
60.00%
80.00%
100.00%
B1 B2 B3 B4 B5
 
Semicolon-； 
 
Figure 4: Distribution of annotated boundary breaks 
corresponding to specific PM in CNA&WF 
4.3.2. Comparison of boundary break distribution by 
PM and prosody formats 
The distribution of boundary breaks in relation to PM for both 
colloquial speech CNA&WF and Chinese classics CL is 
presented in Figure 5. The average distribution of four speakers 
in CNA&WF is calculated and used to compare the 
distributions of two speakers in CL. Results show that except 
for PM comma, distribution patterns in CL are quite different 
from the pattern showed in CNA&WF. 
Comma - ， 
0.00%
10.00%
20.00%
30.00%
40.00%
50.00%
60.00%
70.00%
80.00%
90.00%
100.00%
B1 B2 B3 B4 B5  
Period- 。 
0.00%
10.00%
20.00%
30.00%
40.00%
50.00%
60.00%
70.00%
80.00%
90.00%
100.00%
B1 B2 B3 B4 B5  
Slight-pause between parallels - 、 
0.00%
10.00%
20.00%
30.00%
40.00%
50.00%
60.00%
70.00%
80.00%
B1 B2 B3 B4 B5  
Semicolon-； 
0.00%
10.00%
20.00%
30.00%
40.00%
50.00%
60.00%
70.00%
B1 B2 B3 B4 B5  
Figure 5: Distribution of annotated boundary breaks 
corresponding to specific PM in CL. 
5. Discussion  
We hypothesized that due to discourse information which 
constrains higher-level cohesion, syntax-prosody non-overlaps 
are bound to occur in fluent speech and shown through 
prosody. However, such non-overlaps are recoverable and thus 
can be accounted for. We define overlap by mapping of 
[7] Tseng, C. Pin, S. and Lee, Y., Wang, H. and Chen, Y. 
"Fluent Speech Prosody: Framework and Modeling", 
Speech Communication, Special Issue on Quantitative 
Prosody Modeling for Natural Speech Description and 
Generation, Vol. 46:3-4: 284-309, 2005. 
[8] Tseng, C and Lee Y. “Speech rate and prosody units: 
Evidence of interaction from Mandarin Chinese”, 
Proceedings of the International Conference on 
Speech Prosody 2004, 251-254, 2004. 
[9] Jurafsky, D. and H.Martin, J. Speech and Language 
Processing, Prentice Hall Publishing U.S.A, 2000. 
[10] Chen, K. Tseng, C and Tai, C. "Predicting Prosody 
from Text", 5th International Symposium on Chinese 
Spoken Language (ISCSLP 2006). Kent Ridge, 
Singapore, 2006. 
[11] Tseng, C. and Chen, D. "The Interplay and Interaction 
Between Prosody and Syntax: Evidence from 
Mandarin Chinese", 6th International Conference on 
Spoken Language Processing (ICSLP 2000). Vol.Ⅱ , 
95-97. Beijing, China, 2000. 
[12] Sinica COSPRO and Toolkit: 
http://reg.myet.com/registration/corpus/en/Main.asp 
[13] Tseng, C and Su, Z. "From One Base Form to Multiple 
Output Styles-- Predicting Stylistic Dynamics of 
Discourse Prosody", Interspeech 2007 Eurospeech. 
110-113. Antwerp, Belgium, 2007. 
 
segments were spot-checked by professional transcribers for 
identities and alignments. Table1 summarizes the speech 
material by corpus type, speaker, and the number of the HPG 
prosodic units and boundaries.  
 
Table 1 Summary of speech data by corpus type, speaker, 
and the HPG prosodic units and boundaries. The HPG 
prosodic units are the syllable (SYL), prosodic word (PW), 
prosodic phrase (PPh), breath group (BG) and phrase group 
(PG).Corresponding HPG boundaries following each of 
the prosodic units are B1, B2, B3 B4 and B5, 
respectively. 
 
corpus speaker SYL/B1 PW/B2 PPh/B3 BG/B4 PG/B5
F051 6583 3468 1092 297 151 
CNA 
M051 6661 3332 1207 270 129 
F054 1444 599 290 135 58 
CL 
M056 1551 619 318 142 47 
 
The mean syllable duration for speakers F051 and M052 is 
199ms and 189 ms; the mean syllable duration for speakers 
F054 and M056 are 265ms and 202ms. Taken as a reference to 
speaking rate, we found a positive correlation by speech 
material than by speaker. The same materials were used for all 
three experiments in the present study.  
2.1. Experiment 1   
 
We have stated in Section 1 that discourse prosody is 
mainly about relative associative information 
manifested in the supra-segmental domain, and argued 
that using relative acoustic information would result in 
better generalized pattern and discrimination of 
discourse boundaries than discrete acoustic information. 
Three discourse boundaries, PPh boundary B3, BG 
boundary B4 and PG boundary B5, were selected as the 
categories of generalization and discrimination. Three 
discrete acoustic variables were chosen to test the 
generalization and discrimination. They are (1.) 
boundary pause (BP), (2.) pre-boundary syllable 
duration (PrDu) and (3.) pre-boundary syllable intensity 
(PrIn). The following two steps were employed to 
examine patterns of generalization and boundaries 
discrimination. 
Procedures1. Whether a single acoustic factor is sufficient to 
generalize and discriminate discourse boundary identities  
The procedure involved testing whether generalization and 
discrimination could be achieved by any single acoustic factor. 
The average values of specified acoustic feature for B3, B4 
and B5 were derived from the speech materials by speaker and 
by speech type. These derived mean values across B3, B4 and 
B5 were plotted to denote the tendency among boundaries by 
speech data type and speaker. We then compared the 
trajectories among different speech data to look for whether 
the best single acoustic factor with most generalized pattern 
could be identified. We also tested whether discrimination of 
discourse boundary identities could be attributed to any one of 
these single discrete factors.  
Procedure2. Whether a relative acoustic factor is sufficient to 
generalize and discriminate discourse boundary identities 
The same rationale from Procedure 1 was utilized to test 
boundary generalization and discrimination, but using one 
relative acoustic factor at a time. Between-boundary duration 
contrast (BwDuCon) and between-boundary intensity contrast 
(BwInCon) were calculated and used as the contributing factor. 
Between-boundary duration contrasts were defined by 
subtracted outcome of cross-boundary syllables. The same 
subtraction was applied to derive the between-boundary 
intensity contrasts as well. Both duration and intensity 
contrasts specify cross-unit as well as cross-boundary relative 
acoustic information. The same averaging and comparison 
methods used in Procedure 1 were employed to see if any 
single relative factor is sufficient to discriminate the identities 
of discourse boundaries. 
2.2. Experiment 2 
We hypothesize that pairing of single factors would result in 
better generalization and discrimination than results from 
Experiment 1, and the discrimination varies by pair. We 
further hypothesize  the discrimination varies by pair, thus 
specified pairing would result in better discrimination than 
single factors of the three discourse boundaries B3, B4 and B4.  
The five acoustic features generated from Experiment 1, 
namely, (1.) boundary pause (BP), (2.) pre-boundary duration 
(PrDu), (3.) pre-boundary intensity (PrIn), (4.) duration 
contrast (DuCon) and (5.) syllable intensity contrast (InCon), 
were used as feature candidates to generate paired-
combinations as variables for ANOVA. These five features 
were first normalized then paired. A total of ten paired 
combinations were selected. These 10 paired variables were 
calculated by ANOVA for discriminating categories B3, B4 
and B5 from each other.  
2.3. Experiment 3 
We have previously established that temporal templates for 
each prosodic unit can be derived by the HPG framework 
[1][2], suggesting that default temporal patterns exists in each 
prosodic layer. Thus we hypothesize that final lengthening is 
unit/boundary specific and must be addressed with boundary 
pause information. In other words, boundary discrimination 
must include pre-boundary duration patterns by prosodic units 
and the following boundary pause to account for discourse 
effects, and final lengthening is not simply constrained by the 
intonation phrase. To test the hypothesis, we calculated pre-
boundary duration patterns by the HPG prosodic units, namely, 
the syllable, the PW and the PPh, and compared their 
respective patterns to the speech data. 
Table 2: List of Within and Between and F-ratio for 
pairs of two acoustic features.  
Pairs of 
Acoustic features PrIn+BP PrDu+BP BP+InCon 
Between 2.394360811 2.117735421 0.930326811 
Within 0.714117065 0.479096215 1.116294559 
F-ratio 3.352896784 4.420271653 0.833406204 
    
Pairs of 
Acoustic features BP+DuCon PrIn+InCon PrDu+PrIn 
Between 0.070391796 1.297194809 0.120075103 
Within 1.810655131 0.912193354 0.875052214 
F-ratio 0.038876424 1.422061237 0.137220501 
    
Pairs of 
Acoustic features PrIn+DuCon PrDu+InCon PrDu+DuCon 
Between 0.353532872 1.020569418 0.076907482 
Within 1.652913517 0.374550542 1.763574503 
F-ratio 0.213884676 2.72478425 0.043608865 
    
Pairs of 
Acoustic features DuCon+InCon   
Between 1.254027187   
Within 1.736954223   
F-ratio 0.721969048   
 
Table 3 summarizes the averaged sum of PPh-final syllable 
duration and boundary pause duration in seconds, where 
constant pattern across boundaries can be observed. 
Table 3: A list of average sum of final syllable 
duration and pause (sec by speech data type and 
speaker)  
corpus speaker B3 B4 B5 
F051 0.499738 0.607713 0.684998
CNA 
M051 0.519527 0.800465 0.880004
F054 0.52102 0.833563 1.007355
CL 
M056 0.456447 0.679508 0.774484
 
 
3.3. Experiment 3 
Figure 3 shows the phrase final duration patterns by HPG 
prosodic units the syllable, the PW and the PPh across speech 
data and speaker. We note by analyzing the pre-boundary 
duration pattern of the final syllable alone reveals a pattern 
that consistent lengthening occurs before the B3 boundary, but 
not before higher boundaries B4 and B5. The result does not 
explain why discourse boundary identities could be 
consistently perceived across listeners. However, if the same 
inconsistency was found across all boundaries, which was case 
with the patterns found for the PW, then lengthening may not 
be a reliable boundary cue, and suggest that lengthening is 
related to the lower level phrase boundary only. Nevertheless, 
a cross-speaker and cross-data-type was found in the case 
when the duration patterns were extended to include the entire 
pre-boundary PPh, shown in the lower panel of Figure 3. The 
lengthening patterns of pre-boundary PPh were also consistent 
with respect to boundary identities. Furthermore, the 
consistent pattern also implies that pre-boundary lengthening 
at the higher level applies to higher and larger prosodic units, 
suggesting more cognitive load may result in overall slower 
speaking rates for such prosodic units.   
 
  
Fig 3: Cross boundary comparison of duration patterns by 
prosodic units the syllable (SYL), the PW and the PPh. The 
horizontal axis represents indexes of the speech data and 
speaker. The vertical axis denotes normalized average 
duration of prosodic units. 
Figure 4 shows the results of average duration pattern by 
discourse boundary identities B3, B4 and B5. We found that 
discourse boundaries can be discriminated by the duration 
patterns of pre-boundary PPh across speaker and speech data 
type, as shown in the lower panel of Figure 4, but not by the 
patterns of pre-boundary SYL and PW, as shown in the top 
and middle panels. In other words, the identities of discourse 
boundaries are consistent with the respective lengthening 
patterns of the pre-boundary PPh.    
 5. Conclusion  
We have shown that (1.) overall temporal modulation within a 
fixed speaking rate involves the timing structure and temporal 
arrangement at the discourse level and result in overall 
lengthening of the pre-boundary phrase, (2.) how lengthening 
is in fact an integral part of boundary information by discourse 
units, and when coupled with boundary pause facilitates 
boundary identities to emerge, (3.) Lengthening is relative 
should be addressed with sufficient relative information, and 
(4.) global lengthening related to overall modulation of 
speaking rate shows that the timing structure of discourse 
prosody is subject to discourse organization and discourse 
association. In summary, we hope to show that relative 
phonetic information that exists in the speech events but 
usually outside the concern of phonology contributes 
significantly to speech production and speech processing.  
Such relative information would not emerge unless we adopt a 
discourse perspective of investigation and make use of 
methodological innovations.  
 
  6. Reference 
[1] Tseng, Chiu-yu, Pin, Shao-huang and Lee, Yeh-lin 2004. 
Speech prosody: Issues, approaches and implications. in 
From Traditional Phonology to Modern Speech 
Processing (語音學與言語處理前沿), edited by Fant, G., 
Fujisaki, H., Cao, J. and Xu, Y., Foreign Language 
Teaching and Research Press (外語教學與研究出版社), 
417-437, Beijing, China. 
[2] Tseng, Chiu-yu, Pin, ShaoHuang and Lee, Yeh-lin, 
Wang, Hsin-min and Chen,Yong-cheng 2005. Fluent 
Speech Prosody: Framework and Modeling, Speech 
Communication (Special Issue on Quantitative Prosody 
Modeling for Natural Speech Description and 
Generation), Vol. 46:3-4, 284-309. 
[3] Tseng, Chiu-yu 2006. “Prosody Analysis” in Advances 
in Chinese Spoken Language Processing, edited by Chin-
Hui Lee, Haizhou Li, Lin-shan Lee, Ren-Hua Wang, 
Qiang Huo, World Scientific Publishing, 57-76, 
Singapore.   
[4] 鄭秋豫 2001. 語流中韻律結構的主要徵信。 第 6屆
全國語音通訊學術會議 (NCMMSC-6)， (Nov. 19-24, 
2001)，中國：深圳，169-172。 
[5] Tseng, Chiu-yu, Cheng, Yun-ching and Chang, Chun-
Hsiang 2005. Sinica COSPRO and Toolkit—Corpora and 
Platform of Mandarin Chinese Fluent Speech, Oriental 
COCOSDA 2005, (Dec. 6-8, 2005), Jakarata, Indonesia. 
[6] 林燾 1983. 探討北京話輕音性質的初步實驗，語言
學論叢, 第 10輯，北京：商務印書館。 
[7] 曹劍芬 1998. 漢語普通話語音節奏的初步研究。中
國社會科學院語言研究所語音研究報告 1998。北京：
中國社會科學院語言研究所。 
[8] 祖漪清、陳肖霞 1999. 連續語流中的音節延長及其
作用。第四屆全國現代語音學學術會議。中國：北
京，58-63。 
[9] Zu, Y. and Chen, X., 1999. Segmental duration and 
lengthened syllables.” ICPh99`, San Francisco, 277-280. 
[10] 錢瑤、初敏、潘悟雲 2001. 普通話韻律單元邊界的
聲學分析。第五屆全國現代語音學會議。中國：北
京，70-74。 
[11] 王蓓、楊玉芳、呂士楠 2001. 漢語韻律層級邊界結
構的聲學相關物。第五屆全國現代語音學會議。中
國：北京，161-165。 
[12] Fon, J. and Johnson, K., 2004. Syllable onset intervals 
as an indicator of discourse and syntactic boundaries in 
Taiwan Mandarin. Language and Speech, 47(1), 57-82. 
[13] 曹劍芬 2005. 音段延長的不同類型及其韻律價值。
中國社會科學院語言研究所語音研究報告 2005。北
京：中國社會科學院語言研究所，5-12。 
[14] Tseng, Chiu-yu and Chang, Chun-Hsiang , 2007. Pause 
or No Pause?—Phrase Boundaries Revisited. The 9th 
National Conference on Man-Machine Speech 
Communication（NCMMSC  2007, 第九屆全國人機語
音通訊會議）, (October 21-24, 2007), 黃山, 中國.   








以Fujisaki模型驗證連續語流中字調及韻律詞對應於階層性韻
律架構HPG的意義 
 
鄭秋豫 蘇昭宇  
中央研究院語言所語音實驗室  
cytling@sinica.edu.tw, morison@gate.sinica.edu.tw  
 
摘要  
本文從台灣地區國語連續語流的字調及韻律詞基頻曲線模型，根據鄭秋豫所提出的
「階層式韻律句群HPG架構」，由下層到上層，將基頻曲線模型參數與HPG韻律階
層結合與驗證，探討（1.）句調成份與字調成分對應各韻律階層的貢獻度 與（2.）
字調成分在各階層韻律單位管轄下，基頻模型參數如何變化。結果顯示（1.）HPG
架構中各韻律層由上而下管轄制約，下層韻律單位必須承上層韻律訊息進行系統性
的調整。（2.）字調接受韻律詞的上層制約，字調層及韻律詞層對基頻輸出均有貢
獻，韻律詞與字調的基頻關係，不等於字調線性串接及平滑；表意語境所造成的制
約，才是語流韻律的主要特徵。 
關鍵詞：韻律詞，基頻曲線模型，階層式韻律句群HPG架構，句調成份，字調成分，
表意韻律 
一、 緒論  
國語連續語流韻律一向被視為充滿變異性且難以預測，本文主旨在討論韻律語境來
自階層式管轄制約，韻律語境同時包括線性串接平滑及上層語篇的跨短語表意資
訊，因此串接平滑不足以解釋語流中字調的變化。鄭秋豫由語段與語篇的角度切入，
發現表面看似複雜的連續語流韻律，事實上有系統性規則可循，這些規則及階層式
的關係，與串接共構表意韻律語境，並在物理信號上表現出特定基型，因此語者與
聽者依據此基型產製與接收來自語篇的大範圍表意韻律訊息，結合區辨詞義的字
調、區辨句法訊息的句調共同達到溝通的目的。鄭秋豫[1][2][3]於2004提出階層式語
流韻律架HPG（Hierarchical Prosodic Phrase Grouping）指出，從聲學語音訊息而言，
口語連續語流韻律的多短語階層架構是以感知為基礎[2][3]，感知的最大成分是聽者
預期，該架構主要精神在於將國語口語語流的韻律單位，定義為多短語韻律短語組
PG (Multi-phrase Prosodic Group）而非單一短語（phrase），表達上層語意訊息的連
貫性，構成韻律短語組的相鄰及跨短語的語段韻律語境，從大範圍韻律單位表示特
定語意段落的開始，延續與結束。因此此跨短語語段的韻律語境的基型，即為語者
溝通時語言即時產製與接收處理的模版，當短語形成句段時，各短語必須受上層語
篇語意資訊管轄制約而調整，呈現表意韻律語境，才能成為語意完整的語段。因此
傳統語音信號分析或串接平滑皆無法解釋的句調變異，套用HPG架構後，其實可從
韻律語境結構的角度得到解釋。我們先前也已提出基頻曲線、音節時長、能量分佈
和停頓時長對應HPG架構的證據[1][2][3]。 
出的Fujisaki Model。此模型的精神是非聲調語的一個句調單位IU (intonation unit)的
基頻曲線，必能拆解成全面句調成分與局部強調二個成分，單位大小不同，而套用
於聲調語言時，局部強調則被轉換成描述字調的成分[6, 7, 8]，此即証明且呼應了趙
元任所指大波浪與小漣漪的關係。因此，綜合趙元任先生與Fujisaki教授的看法，國
語短語句調的基頻曲線，其實是字調成分與句調成分疊加而成，亦即除相鄰字調的
連接外，還有來自上層的句調的覆蓋，因此不僅是字調的串接。若根據HPG架構，
連續語流裡還更不僅只有字調與句調兩種韻律層級與單位。我們先前依據聽感標註
得出的HPG架構進行分析，已找出句調彼此間的關連性與連貫性，即為所謂上層訊
息，及對應HPG架構中的韻律句群關係[1][2][3] ，並在稍早的研究中，特別探討如
何使用Fujisaki Model提取短語句調的成分在語段中的體現[9] 。同樣的，我們也希
望在對應HPG架構中的韻律詞層，也找到字調間關係，並確認韻律詞在連續語流中
作為基本韻律單位的韻律意義。我們知道，音段成分相同的音節，會因為字義不同
而有不同的聲調，超音段成分基頻曲線的變化由詞義決定，因此嚴格說來，只能稱
為詞義韻律(lexical prosody)，而非語流韻律的特徵或成分。因此本論文除了證明HPG
架構外，也將以韻律詞的基頻曲線變化為主要分析參數，將強調字調以上韻律詞的
在基頻曲線上的相對關係與特徵的確存在，且是連續語流中的基本韻律單位；短語
也是連續語流的基本韻律單位而非終極韻律單位。 
 
二、國語基頻曲線特徵參數自動擷取系統 
(一) Fujisaki model 簡介 
Fujisaki 等 1984 年[6]提出疊加式 command-response 基頻曲線模型，簡稱為 Fujisaki 
model，此模型的特點在於拆解看似不規則的基頻曲線為三個不同的元件函數
（component）的疊加總合，並分別可找到相對應發聲器官的物理特性來解釋這些元
件函數，此三元件函數分別為(1.)短語元件 (Phrase Component Ap)，反應較大單位
基頻曲線的控制與發聲限制；(2.)強調元件(Accent Component Aa)，反應較小單位基
頻曲線的控制發聲限制；與(3.)基底頻率(base frequency Fb) 代表基本音高。原
Fujisaki model 中的 Accent component Aa 泛指強調、加重語氣對局部基頻曲線造成
的影響，此模型應用到非聲調語言與英語、德語時，大單位指的是片語的語調或短
語的句調，即陳述句的由高走低的下傾趨勢，小單位則用來表示局部的加重或加強
（emphasis）；應用到聲調語言模擬國語時，大單位表示的成分與非聲調語相同，即
片語的語調或短語的句調，而小單位被用來表示單音節的局部變化，亦即字調。本
研究僅分析國語連續語流，所以 Aa 皆表示字調成分，因此下文均稱做字調元件。  
層的標註進行線性迴歸分析，分析及預測下ㄧ韻律層的輸入，因此可得到更上層的
預測模型與貢獻度。 逐層分析、預測後計算出各韻律層的貢獻度。圖三以圖式表
示階層式線性回歸逐層分析。 
 
圖三、以階層式線性迴歸逐層分析示意圖 （Tseng et al, 2004） 
 
本實驗以(1)Ap 為分析韻律短語句調以上語段或與篇語意之特徵 (2)Aa 為分析字調
以上韻律詞意之特徵。Ap 是對應韻律短語的基頻特徵，因此分析的步驟由階層式架
構中韻律短語層(PPh)開始、之後逐層向上，對上一層的呼吸句群層(BG)及更上一層
韻律短語句群(PG)進行的線性迴歸，分析參數如下: (1)PPh 層: 以目前 PPh 長度
(Current PPh Length)、前一 PPh 長度(Preceding PPh Length)與後一 PPh 長度(Following 
PPh Length)的組合做為分析參數，進行分析，經過線性迴歸後的殘差定義為 Delta1，
並輸入 BG 層進行分析，(2)BG 層: 以目前 PPh 在 BG 中的位置(BG Sequence)做為
分析參數，若 BG Sequence=1，表示目前 PPh 為此 BG 之起始 PPh，以此類推，進
行線性迴歸，(3)PG 層: 與 BG 層輸入參數相同，其數學函數表示如下： 
 
其中 f 表示線性迴歸函數，迴歸係數與原始值 Ap 間的差值視為上層貢獻 Delta，並
以上層的輸入參數對 Delta 再執行一次線性迴歸，此時得到的迴歸正確率視為上層
的貢獻度，以此類推。 
Aa 是對應字調的特徵，因此分析的步驟由階層式架構音節層(Syllable)開始，預測參
數包括目前的字調(Current Tone)與前後字調的組合(Preceding Tone + Following  
Tone= Tone Context)，之後對上層的韻律詞層(PW)做分析，預測參數包括韻律詞邊
界(PW Boundary Info)與此音節在韻律詞內的位置順序(PW Position Sequence)，由於
在[12]中發現，在較高層級的韻律邊界常有邊界效應發生，因此我們也將邊界效應
加入考慮，包括 1.韻律短語邊界訊息(PPh Boundary Info)、2. 韻律句群層邊界訊息
(PG Boundary Info)，將大範圍韻律單位首和尾音節的類別標記出來，進行獨立的
律層的迴歸係數的總和等於原始Fujisaki特徵參數值，Fujisaki特徵參數值完全可由階
層性多元迴歸分析正確預測。 
1. 字調元件Aa分層貢獻度 
從階層性多元迴歸分析可求出字調元件Aa在音節層與韻律詞層的貢獻度，並加入韻
律短語層以上邊界效應的考慮[13]，包括此音節前後是否有韻律短語邊界及韻律句
群層邊界。最後結果顯示Aa的正確率可達73.80%到56.25%不等，其中大部份貢獻度
來自音節層與韻律詞層，邊界效應的貢獻度則介於5~7%。 
表二、字調元件在音節層與韻律詞層的累積正確率 
Syl 層貢獻度 PW 層貢獻度  
語料 語者 
Tone Tone Context PW Boundary Info 
PW Position 
Sequence 
F054 46.21% 54.74% 60.54% 66.61% CL M056 39.12% 47.86% 57.68% 61.45% 
F051 38.40% 45.00% 48.43% 51.27% CNA M051 41.61% 47.96% 51.33% 54.53% 
 
表三、加上邊界效應後字調元件的累積正確率 
 
2. 短語元件Ap分層貢獻度 
從階層性多元迴歸分析可求出短語元件Ap在韻律短語層、呼吸句群層與韻律句群層
的累積貢獻度，我們發現古文語料CL有許多貢獻度來自於韻律短語層以上的上層資
訊，反之，白話長篇敘事語料CNA正確率則多來自目前PPh與前後PPh的長度資訊。 
表四、短語元件Ap在韻律短語層、呼吸句群層與韻律詞層的累積正確率 
語料 語者 PPh BG PG 
f054 58.79% 63.58% 76.66% 
CL 
m056 37.89% 48.99% 73.66% 
F051 80.17% 81.46% 87.71% 
CNA 
m051 81.53% 82.72% 88.20% 
PPh 層以上的邊界效應  語料 語者 
PPh Boundary Info PG Bounary Info
邊界效應的貢獻度
F054 72.98% 73.80% 7.19% CL M056 64.13% 66.89% 5.43% 
F051 54.41% 56.25% 4.98% CNA M051 57.43% 59.32% 4.79% 
同特徵，且PW末和倒數第二音節間相對於PG-Medial的對比也較大。 
對照2007以Ap為實驗，獲不同語體的階層貢獻度不同之結論[9]，經由本實驗結果可
進一步發現，由於跨語體間的韻律詞特徵，在PG-Medial最為穩定且最不明顯，因此
大 部 分 與 語 體 變 化 相 關 的 的 貢 獻 度 差 異 ， 應 來 自 PG-Initial 與 PG-Final 而 非
PG-Medial。 
 
 
圖六、扣除字調成份後，韻律詞模型在不同 PPh 位置的特徵，每條曲線表示特定長
度的韻律詞模型，橫軸表示在此韻律詞內音節順序，縱軸表扣除字調成份後的殘差。 
 
六、結論與展望 
由 Aa 實驗結果可知，字調仍為影響音節內基頻曲線的主要因素，大約佔字調元件
Aa 預測正確率的 40~45%；韻律詞 PW 的階層性貢獻佔 15~20%。但以上數據亦顯
示：從字調辨識的角度而言，字調的正確率不及一半，表示最終的語流韻律輸出中，
字調的成分並非字字可辨。由扣除字調成份的韻律詞 PW 模型可發現，HPG 架構中
的 PW 層存在ㄧ定特徵，也有一定的貢獻度，解釋了在基頻曲線中，並非只以字調
為基本單位進行串接；PW 對基頻曲線也有一定程度的影響，並在最終的語流韻律
輸出中，佔有一定的比例。以上結果和稍早 Ap 實驗的 PPh 表現的結果相符，即 PPh
的 Ap 必須考慮呼吸句群 BG 層以及韻律句群 PG 層的上層效應[9]，本研究結果顯
示 BG 層與 PG 層對句調元件 Ap 的貢獻度約佔 7~35%，語流最終的韻律輸出，各
韻律層都有貢獻。不同語體的朗讀語料，因語體而產生的韻律輸出差異，只是階層
式貢獻度的分佈差異而已，其韻律成份完全可由 HPG 架構解釋，同一基型只需調
整階層式的韻律貢獻度，便可產生不同的韻律輸出[9]。結合以上實驗結果，我們因
而得知，不論字調或句調，皆為 HPG 的次級韻律單位，各自受到 HPG 架構的層層
管轄，系統性的調整字調以及句調，以形成流暢的連續語流中的表意韻律語境，表
達句調間的連續與跨句調的呼應。我們相信這些韻律語境的模型為理解與產製語音
的重要單位，口語產製時，人們使用這些韻律基型，因此依據這些基型，可輕易快
速的將複雜的連續語流的語境歸類成最適合的語段、語篇，以進行上層語意的組織
與分析。 
我們期望這些證據及特徵能提供語音合成系統一個新的思維: 語流韻律是有架構
的，因有系統性而有跡可循，所以連續語流並非充滿變異而難以預測。語流的流暢
並非僅來自於字調與句調的線性串接的完美平滑，也必須同時包含多短語語段間的
跨短語表意韻律語境,。我們所提出的多短語階層性 HPG 架構，完整的解釋語流韻
律規範的來源及如何互動。合成的語音輸出聽起來不流暢、不自然的感覺，則大部
1999.  
[11] Keller, E., and Zellner, K.,. “A Timing model for Fast French”, York Papers in 
Linguistics, 17, University of York, pp.53-75, 1996. 
[12] Zellner, K., and Keller, E., “Representing Speech Rhythm” Improvements in Speech 
Synthesis. Chichester: John Wiley, pp. 154-164, 2001. 
[13] Tseng, C., Su, Z., “Boundary and Lengthening—On Relative Phonetic Information.”  
The 8th Phonetics Conference of China and the International Symposium on Phonetic       
Frontiers, Beijing, China., 2008 


of  paratone (an expansion of pitch range to signal topic 
shift). It has also been observed that non-native 
speakers produce a significantly narrower pitch range 
than native speakers do [11][12]. Quantitative analyses 
of Japanese English found that Japanese English was 
slower in speaking rate and shorter in sentence length 
than L1 English is [8]. The phonological characteristics 
of Asian English have been found to exhibit phonetic 
variation at many levels; thus, materials for the current 
research are designed to investigate the acoustic 
characteristics of L2 Asian English at the word, phrase, 
sentence and discourse levels. 
Recent studies have demonstrated that the segmental 
and suprasegmental properties of spontaneous speech 
differ significantly from those of read speech. At the 
segmental level, the spectral distribution of vowels in 
Japanese is significantly reduced in spontaneous 
speech [13]. At the prosodic level, Swedish data 
indicate a steeper F0 declination and stronger pitch 
resetting in read speech. In UK English, speakers tend 
to position stress differently and mark boundaries in 
different positions between read and spontaneous 
speech. Both English and Dutch spontaneous speech 
contain more pauses than read speech does; in Dutch, 
those pauses have a stronger tendency to be realized 
with pre-final lengthening. Furthermore, falling 
boundary tunes tend to occur more frequently in read 
speech. It is reasonable to predict similar differences 
between L2 read and spontaneous speech; however, 
very little data exist comparing the two speech styles in 
the L2 population [14]. Thus, it remains largely 
unknown whether read and spontaneous L2 speech 
exhibit similar properties, particularly with respect to 
suprasegmental features. Experiments designed to 
elicit a comprehensive inventory of suprasegmental 
features could efficiently collect a L2 spontaneous 
speech database, which could be used for acoustic 
phonetic research as well as for modeling and ICT tool 
development tailored to the L2 population. Our 
proposal for such a database content design will be 
described in the sections to follow. 
 
2.  Experiment 1--Picture Description Task  
The Picture Description task presents participants with 
an illustration of a man standing at the entrance of a 
supermarket holding a shopping list, preparing to do 
his grocery shopping (A reproduction of the picture 
appears in Appendix A). Participants are required to 
study the illustration, then respond to a series of 
questions, which guide them to describe different 
aspects of the scene. The purpose of this task is to elicit 
segmental and suprasegmental characteristics as they 
occur in spontaneous (unscripted) speech, including: 
lexical stress, phrase and utterance-level intonation 
contours used to mark continuation/finality as well as 
illocutionary force (e.g. question/statement), and the 
features associated with long-range prosodic planning 
of larger discourse units, such as pitch reset between 
topics and pitch downstepping within topics.   
2.1 Procedure 
Participants are asked to study an illustration of a man 
standing at the entrance of a supermarket with a 
shopping list in his hand. After participants have 
familiarized themselves with the content of the picture, 
they will then answer a series of questions. Each 
question will be presented individually on a computer 
screen, and no time limit will be imposed for answering 
the questions. Participants are permitted to continue 
looking at the picture while they answer questions. 
 
2.2 Materials 
In the picture, we can see the individual aisles of a 
supermarket, which are clearly labeled and have 
products in them: Aisle 1: fruit and vegetables; Aisle 2: 
beer and wine; Aisle 3: rice and noodles ; Aisle 4: juice 
and water; Cashier. Words appearing on the man’s 
shopping list have been deliberately chosen to 
represent a range of phonemes, syllabicities and stress 
types in order to investigate L2 speakers’ production of 
lexical stress, as well as the possibility of interaction 
between location of pitch accent and realization of 
phrase boundaries. Target words include: watermelon 
(4 syllables, initial stress); orange juice (left headed 
N-N compound); red wine (right headed Adj.-N 
compound); noodles (2 syllables, initial stress) and 
strawberries (3 syllables, initial stress).  
 
The questions participants will answer following 
picture viewing were each designed to elicit particular 
prosodic features: 
 
Question 1: “What does the man plan to buy?”  
This is designed to elicit continuation rise between the 
items on the shopping list and a final fall at the end of 
the utterance. 
Sample Answer: “The man wants to buy watermelon, 
orange juice, red wine, noodles and strawberries”. 
Question 2: “At the supermarket, what will the man do 
first, second, third, fourth and last?”   
This is designed to elicit topic-initial pitch setting, 
pitch downstep within the intonation unit, and 
production of intermediate and final phrase boundaries. 
Sample Answer: “First, he will go to Aisle 1 to get 
watermelon and strawberries, second he will go to 
Aisle 2 to get red wine, third, he will go to Aisle 3 to get 
noodles, next he’ll go to Aisle 4 to get orange juice, and 
last he will go to the cashier to pay.”  
would.  
 
For Experiment 2, we predict the following: 
  
(1) Questions, statements and imperatives: We predict 
that illocutionary intonation will be confined to 
utterance-final syllables.  
 
(2) Reduction and linking of function/unstressed 
syllables or words: We predict that L2 speakers will not 
reduce or link function words in a target-like manner. 
Instead, they will produce these words with lexical 
stress and with underlying vowel quality. 
 
(3) Broad and narrow focus, parenthetical information 
and post-focused information: 
We predict that L1 speakers of tone languages will use 
identical pitch patterns to mark nuclear and contrastive 
focus; whereas L1 English speakers will use different 
shapes of pitch accent to realize nuclear and contrastive 
stress. Moreover, L1 speakers of tone languages will 
continue to produce pitch accents on parenthetical and 
post-focused information, whereas L1 speakers never 
do.  
  
For Experiment 3, we predict the following: 
 
(1) Individual alphabetic letters and numbers: We 
predict that L1 tone language speakers will associate 
individual alphabetic letters and numbers with  fixed 
pitch patterns, which are borrowed from the L1 tone 
inventory. 
 
(2) Alphabetic letter and number strings: We predict 
that pitch patterns of individual alphabetic letters and 
numbers will remain fixed irrespective of phrase 
position for L2 speakers, whereas L1 English speakers 
will use phrase-level prosody to configure letter and 
number strings. 
 
6. Conclusion 
The experiments described above represent our initial 
efforts to elicit a comprehensive inventory of the 
segmental and suprasegmental features of 
spontaneous speech in a concentrated and easily 
implementable set of materials. Spontaneous speech 
database collection using this type of task will provide 
specific information on the greatest number of 
phonetic features with the least amount of data 
collection effort. These experiments are included in 
the phonetic database design of AESOP, which also 
includes a series of read speech tasks [16].  This kind 
of database could serve as a cross-linguistic core 
resource to increase our understanding of the ways in 
which L2 spontaneous speech differs from read speech, 
as well as the ways in which L2 Asian English differs 
from L1 English. These findings could also inform and 
help improve modeling and ICT tool development 
tailored to the Asian English speaking population. 
Other research interests represented by the AESOP 
international collaboration project are open at this 
stage. We welcome feedback and participation from 
L2 researchers in all fields. 
 
Acknowledgements 
We extend our sincere thanks to Professors Helen Meng 
and Mariko Kondo for their insightful comments and 
suggestions, and to Leonie Reyneke, the artist who 
contributed the illustration used in the picture description 
task.  
 
The AESOP consortium is initiated by Professor 
Yoshinori Sagisaka of Waseda University. Other 
collaborators include Professor Michiko Nakano of 
Waseda University, Dr. Chai Wutiwiwatchai of the 
National Electronics and Computer Technology Center in 
Thailand, Professor Sudaporn Luksaneeyanawin, 
Professor Tavicha Phadvibulaya and Professor Kulaporn 
Hiranburana of the Chulalongkorn University, Dr. 
Wai-Kit Lo, Dr. Pauline Lee and Alissa Harrison of The 
Chinese University of Hong Kong, Dr. Lan Wang of the 
CAS-CUHK Shenzhen Institute of Advanced Integration 
Technologies, and Dr. Sakriani Sakti and Dr. Dawa 
Idomuco from ATR. 
 
 
Appendix A: Picture Description Illustration 
 
 
 
Appendix B: Text of computer-prompted dialogue 
  
Introduction: You are a reservation agent for EVA 
Airlines. Help this customer reserve a flight from 
Taipei to New York.  
Customer: Hello. I’d like to reserve a ticket from 
Taipei to JFK airport in New York.  
Prompt: Ask the customer: “When would you like to 
travel?”  
When would you like to travel? 
Customer: November twenty-second.  
Prompt: Ask the customer: “Did you say the 
twenty-second or the twenty-seventh?”  
acquire the intonation of a second language?” 
In Proceedings of the ESCA workshop on 
speech technology in language learning (pp. 
17–20). Marholmen, Sweden:International 
Speech Communication Association. 
[12]. Pickering, L. 2004. “The structure and function 
of intonational paragraphs in native and 
nonnative speaker instructional discourse” 
English for Specific Purposes (23) 19-43. 
[13]. Furui, S. Nakamura, M. Ichiba, T. A[nd Iwano 
K. “Why is the recognition of spontaneous 
speech so hard?” in Text, speech and dialogue : 
Václav Matoušek, Pavel Mautner, Tomáš 
Pavelka (eds.), Springer-Verlag Berlin 
Heidelberg 2005 
[14]. Strik, H. Cucchiarini, C. and Binnenpoorte, D. 
2000. "L2 pronunciation quality in read and 
spontaneous speech", In ICSLP-2000, vol.3, 
582-585. 
[15]. Aylett, M. (2004). Merging data driven and 
rule based prosodic models for unit selection 
TTS. In Proceedings of 5th ISCA Speech 
Synthesis Workshop, Pittsburgh, PA, USA.  
[16]. Visceglia, T. Tseng, C. Kondo, M. Meng, H. 
and Sagisaka, Y. “Phonetic Aspects of Content 
Design in AESOP (Asian English Speech 
cOrpus Project)” submitted to 
Oriental-COCOSDA 2009, Aug. 10-12, 2009, 
Urumuqi, Xinjiang Autonomous Region, 
China. 
 






 
 
LANGUAGE AND LINGUISTICS 11.2:183-218, 2010 
2010-0-011-002-000277-1 
語篇的基頻構組與語流韻律體現* 
鄭秋豫 
中央研究院 
 
 
本研究從語篇組織角度重新定義語篇韻律單位，依「階層式多短語語流
韻律 HPG架構」(Hierarchical Prosodic Phrase Grouping) 之層疊與覆蓋關係，
解構不同韻律格式語料，以音高的構組為例，證明口語語流的基頻聲學體
現，乃由字調、韻律詞調、句法調、語篇聯繫位置、邊界延長、邊界停頓等
成分系統性共構，並以各級韻律單位的相鄰與跨單位之對比與反差，證明較
大韻律單位與語篇邊界效應亦為韻律語境之構組成分。各級韻律單位對韻律
生成均有貢獻，層級貢獻度可透過統計分析釐清，不同韻律格式之體現反映
於層級貢獻度的分布差異。研究方法則凸顯語料庫語言學及計算語言學解析
動態超音段聲學參數相對性的重要與意義。 
 
關鍵詞：語流韻律組織，韻律單位，韻律語境，相對韻律資訊，基頻，邊界
效應，線性相鄰，跨單位呼應，韻律階層 
1. 引言 
語流中各級語音及韻律單位的實際體現，充滿多元的變化：有時清晰完整，
有時多變而片面。本文旨在分析基頻信號，解釋表面的多變其實是有所本且有系
統規則可循的，單字調與短語句調構成語段時必須變化。本研究提供語篇韻律語
境的成分及各級韻律單位的互動證據，從聲學層面證明語段的存在，進而論述語
篇韻律的特徵及其語言學上的意義。 
                                                 
* 本研究為國科會研究計畫「新一代語音科學與技術──由基礎到應用」部分研究成果（計畫編
號：NSC 96-2218-E002-001，2005.08~2008.05）。 
參與研究人員鄭雲卿（2000 迄今）、李瑋珊（2000 迄今）、蘇昭宇（2005~2009）對本研究貢獻良
多，謹此一併致謝。 
本文部分內容曾發表於以下二篇會議論文：(1)〈從不同韻律格式驗證階層式韻律架構並兼論對語
音科技的應用〉（「第十九屆自然語言與語音處理研討會」，2007 年 9 月 6-7 日），及 (2)〈以
Fujisaki 模型驗證連續語流中字調及韻律詞對應於階層性韻律架構 HPG 的意義〉（「第二十屆自然
語言與語音處理研討會」，2008年 9月 4-5日）。 
 
 
 
語篇的基頻構組與語流韻律體現 
 
185 
音步  (foot)、韻律詞  (prosodic word)、大小韻律短語  (major and miner prosodic 
phrase)、語調短語 IP (intonation phrase)、話語 (discourse) 等，討論的重心多為音
步、韻律詞，少有比韻律詞大的討論；兼顧句法屬性的韻律單位則有莫拉
(mora)、音節、音步、韻律詞、黏附組 (clitic group)、韻律短語、語調短語 IP、語
篇等等 (Nespor & Vogel 1986)，討論的重心也多以音步、韻律詞為主。在通行多
年的語氣與停頓標註系統 ToBI (Tone and Break Indices) (Beckman & Hirschberg 1994, 
Beckman & Elam 1997) 中，也僅將短語 (phrase) 分為主要語調短語 (intonational/ 
major phrase) 和次要語調短語  (intermediate/minor phrase)，以短語為分析句調
(sentence intonation) 的單位。也就是說，一般的韻律分析中經常是將語音單位與
音系單位混用的 (Halliday 1967, Crystal 1969)，以致在使用語料從事聲學語音分析
時，單位混淆十分常見。 
未釐清以上這些單位的結果，導致音系單位 IP 既是最大的語音單位，也是
最大的韻律單位，但 IP 的身分不明，也沒有清楚界定的基本模版。試問 (1) 沒有
句法訊息時（如 Selkirk 1984），如何界定主要短語及次要短語？它們是有從屬關
係的語調短語？或是各不相關的語調短語？此時一個 IP 可以包括多少短語？是
否有基型？(2) 有句法訊息時，語調 (intonation) 單位1 最大為何？複雜句 (complex 
sentence) 與複合句 (compound sentence) 的語調如何分析？一個 IP 又可以包括多
少短語？句法分析節點與韻律節點不符時如何解釋及解決？此外，以句法訊息界
定 IP 時，最大單位止於句子 (sentence)，篇章 (discourse)2 訊息是無法考慮的，未
能將 IP 的單位擴大至篇章單位時，便無法也無力處理、解釋語篇裡相同的字調
為什麼變化多端？結構類似的短語，為什麼會呈現多樣的韻律體現？而漢語的韻
律研究受到上述研究的影響，一方面必須考慮漢字的字調，一方面又因複雜句與
短語句段的界線不明，於是，韻律研究的取向變成字調、短語句調為主的研究
(Xu 1999, 2004, Liu 2009)。 
可是，為什麼在連續說話的口語語料中，往往字調和句調的調型都有許多變
異？一方面並不是每一個音節都有清楚可辨認的字調，另一方面句調又往往沒有
清晰的下傾或上揚。本研究將分析國語語篇語料，整合聲學語音信號基頻
(fundamental frequency F0) 的分析，進一步在字調、韻律短語句調以外，加入表
語段開始、延續與結束的三個表語篇關連的因素，提取並證明各層級的韻律單位
                                                 
1 本文以句調 (sentence intonation) 一詞，表示根據句法界定為句子的單位所產生的調型；以語調
(intonation) 一詞，表示根據聲學語音信號具有可辨識的基頻走勢所產生的調型，二者的單位並非
一定相等。 
2 本文以語篇 (spoken discourse) 一詞，表示從聽感獲得的篇章單位；以篇章 (discourse) 一詞，表示
與聽感無關，從文本與標點獲得的單位，二者的單位並非一定相等。 
 
 
 
語篇的基頻構組與語流韻律體現 
 
187 
本研究一方面採語料庫語言學使用大批語料，一方面採計算語言學研究方式
量化語料驗證：構組語流韻律基頻參數最終體現的成分中，(1) 並非僅來自字調
與短語句調的調型，而是所有語篇韻律單位調型的相加與抵消；(2) 各級調型的
相加與抵消並非僅包括單位串接平滑（或平順），還需包含上層訊息的覆蓋；
(3) 各級韻律邊界對韻律單位所造成的影響，也必須在分析時加以考慮。最後我
們將討論所獲結果在語言學上的解釋性意義。 
2. 研究方法 
2.1 以 Fujisaki Model 為基礎發展自動擷取國語基頻曲線特徵參
數系統 
2.1.1 Fujisaki Model 簡介 
 
Fujisaki等人 1984年提出基於發聲機制的疊加式 command-response基頻曲線
模型，主張產生基頻主要器官為聲帶 (vocal tract) 及相鄰的隨意肌。控制隨意肌
時，有一定物理特性的限制，對應於語言單位，在時間程上產生聲帶高低變化；所
以基頻曲線並非任意直線或曲線，必須受制於一定的規則在時間程所產生的變化，
而此限制顯現於對數尺度之中，此為基頻曲線的函數限制。此一 command-response
模型一般通稱為 Fujisaki Model，其特點在於將時間程上動態變化的不規則基頻曲
線，拆解為三個單位大小不同的元件函數 (component) 疊加總合（如〈圖 2〉所
示），並分別對應發聲器官的物理特性。此三元件函數分別為 (1) 短語句調元
件 (Phrase Component Ap)，反映較大單位基頻曲線的控制與發聲限制；(2) 強調元
件 (Accent Component Aa)，反映較小單位基頻曲線的控制發聲限制；與 (3) 基底
頻率 (base frequency Fb) 代表基本音高。此模型定義如下： 
 
 
 
原 Fujisaki Model中 Phrase Component Ap泛指短語句調或語調對全面性基頻
 
 
 
語篇的基頻構組與語流韻律體現 
 
189 
Model 中的字調元件；而變化和緩的部分，則為語流中語調全面下傾的趨勢，對
應 Fujisaki Model 中的短語調元件。接著分別對三個元件進行逼近步驟：(1) 高通
濾波器的輸出定義為高通曲線 (HFC)，即為字調元件需逼近的目標曲線；(2) 扣掉
高通部分剩餘平滑曲線則定義為低通曲線 (LFC)，找出此低通曲線的最低點並定
義為通過此最低點的直線為基底直線 (Fb)；(3) 扣掉基底直線後的低通曲線 (LFC)
即為短語調元件需逼近的目標曲線。〈圖 3〉為 Mixdorff自動擷取 Fujisaki參數架
構。 
 
〈圖 3〉利用濾波器將基頻曲線分離為高通 (HFC) 及低通曲線 (LFC)，即分別為
字調元件與短語調元件需逼近的目標曲線，進行自動擷取程序 (Mixdorff 2000)；
圖中縱軸表時間，橫軸表 logF0。 
 
傳統人工調整步驟 (1) 中，遇到第三聲（字調三）跟第四聲（字調四）的音
節，通常會指派一大一小的字調元件以趨近一音節內較複雜的基頻曲線 (Wang et 
al. 1999)。然而在本研究中，為了能夠自動擷取大量語料的參數，而非使用傳統
人工逼近方式，我們在自動擷取 Fujisaki 特徵參數程式中，只採用一字調元件來
趨近一音節內高頻的基頻曲線，抽取最概括性的字調變化。 
 
2.2 加入聽感所得語篇韻律邊界的方法與自動擷取結果 
 
在本研究中，我們除驗證 HPG 架構，也希望探討由聽覺感知所獲之語篇韻
 
 
 
語篇的基頻構組與語流韻律體現 
 
191 
的預測變項，並得到此層的預測模型；(2) 將原始值與預測模型的差距（或殘
差）視為實驗來自更上層的效應而非誤差，將分析及預測某一韻律層的殘差作為
分析及預測下一韻律層的輸入，根據上一層的標註進行線性迴歸分析，以獲得上
一層的預測模型與貢獻度；(3) 逐層分析預測後，計算出各韻律層的貢獻度及疊
加後的累加貢獻度。換言之，基於 HPG 架構之階層性多元迴歸分析，是利用每
一層的標註資訊，得到各層韻律單位的模型，並依此模型進行正規化。 
 
 
〈圖 5〉基於 HPG架構之階層性多元迴歸分析示意圖 (Tseng et al. 2004) 
3. 實驗設計與分析 
本研究以 (1) Aa 為分析字調以上韻律詞意之特徵。(2) Ap 為分析韻律短語句
調以上語段或語篇語意之特徵。 
 
3.1 Aa 分析 
 
Aa 是對應字調的特徵，因此分析的步驟由階層式架構音節層 (syllable) 開
始，預測參數包括相鄰字調基頻走勢的線性串接及來自上一韻律層 PW 的管轄與
覆蓋。即以每一字調 X tone 為基準，預測其與前後字調共構的線性字調語境
(Preceding Tone + X Tone + Following Tone = Linear Tone Context)；根據 HPG架構，
除了前後字調形成的線性字調語境外，上一層的韻律詞層 (PW) 也影響了下轄音
節，韻律詞層對字調的預測參數包括韻律詞邊界 (PW Boundary Info) 及每一音節
在所屬韻律詞內的位置順序 (PW Position Sequence)。根據我們對較高層級邊
界 (BG/PG) 效應的研究中發現（鄭秋豫、蘇昭宇 2007, 2008），下層的韻律單位，
 
 
 
語篇的基頻構組與語流韻律體現 
 
193 
4. 實驗一：口語語流韻律中句調成分與字調成分對應於
階層式多短語語流韻律 HPG 架構的意義 
4.1 實驗目的及假設 
 
本實驗以台灣地區國語語篇口語的字調及韻律詞基頻曲線模型，根據「階層
式多短語語流韻律 HPG」理論架構，由下層到上層，將基頻曲線模型參數與
HPG 韻律階層結合，以驗證 (1) 句調成分與字調成分對應各韻律階層的貢獻度；
(2) 字調成分在各階層韻律單位管轄下，基頻模型參數如何變化。 
 
4.2 實驗語料 
 
文本部分，採用 (1) 古典文體（以下簡稱 CL，大約 1,600 個音節），與 (2) 長
篇敘事段落文本（以下簡稱 CNA，大約 6,700 個音節），共計 (1) 26 篇古典文體
段落（含 4篇古典散文，1首賦，1首民歌，6首古詩，6首唐代樂府詩和 8首宋
詞），以及 (2) 26則白話敘事段落。 
語料來自四位發音人，二類文本各由一男一女發音人朗讀。古典文體文本由
一男一女 (m056 & f054) 未受特別訓練之母語者朗讀，在隔音室使用 Sony ECM-
77B 迷你型麥克風及 Cool Edit 2000 錄音軟體錄製；白話敘事段落由一男一女播
音員 (m051 & f051) 朗讀。〈表 1〉為 HPG 架構下古典文體 CL 與長篇敘事段落文
本 CNA語料的韻律邊界以及相對應韻律單位次數分配表。 
 
〈表 1〉古典文體 CL與長篇敘事段落文本 CNA韻律
邊界以及相對應韻律單位次數分配 
語料 發音人 SYL/B1 PW/B2 PPh/B3 BG/B4 PG/B5 
f054 1444 599 290 135 58 
CL 
m056 1551 619 318 142 47 
f051 6583 3468 1092 297 151 
CNA 
m051 6661 3332 1207 270 129 
 
平均語速分析結果顯示：CL男性發音人 m056為 202m/syl，女性發音人 f054
為 265ms/syl；CNA 男性發音人為 199ms/syl，女性發音人為 189m/syl。二組語速
顯示：文本的格式與語速的快慢有直接的關係，與發音人的性別則無。語速與文
體的正相關，亦可作為語篇規劃與語篇組織正相關的佐證。 
 
 
 
語篇的基頻構組與語流韻律體現 
 
195 
〈表 3〉加上邊界效應後字調元件的累積正確率 
PPh層以上的邊界效應 語料 語者 
PPh Boundary Info PG Boundary Info
邊界效應的貢獻度 
f054 72.98% 73.80% 7.19% 
CL 
m056 64.13% 66.89% 5.43% 
f051 54.41% 56.25% 4.98% 
CNA 
m051 57.43% 59.32% 4.79% 
4.3.1.2 短語調元件 Ap 分層貢獻度 
我們以 HPG 架構，分別在韻律短語層、呼吸句群層與韻律句群層進行階層
性多元迴歸分析，求出 Ap 的累積貢獻度。結果顯示（見〈表 4〉）各層語篇資訊
對韻律輸出的貢獻度因語料而異，二者的階層貢獻度相反。韻律短語 PPh 在古文
語料 CL 及白話長篇敘事語料 CNA 貢獻度大不相同。CNA 的正確率多來自與前
後短語調共構的線性短語調語境，在 80% 以上，表示韻律短語句調較為分明，而
且在二發音人間並無差異（80% 與 81%）。而 CL 的 PPh 貢獻度不但較低，且有
相當的個別差異（59% 及 38%），男發音人的線性短語調語境甚至只佔了階層貢
獻度 38%；由〈表 4〉中也可發現，CL 與 CNA 最大的不同是來自上層語篇貢獻
度，表示發音人在朗讀內在韻律架構分明的文本時，上層韻律資訊的規劃及表現
較白話明顯。 
 
〈表 4〉Ap在韻律短語層、呼吸句群層與韻律詞層的累積正確率 
語料 語者 PPh BG PG 
f054 58.79% 63.58% 76.66% 
CL 
m056 37.89% 48.99% 73.66% 
f051 80.17% 81.46% 87.71% 
CNA 
m051 81.53% 82.72% 88.20% 
 
如前文所提，基頻曲線的變化由 Ap 與 Aa 構成，因此我們將 Ap 與 Aa 的預
測正確率平均作為套用 HPG架構後 Fujisaki Model對總體基頻曲線模型預測正確
率。結果如〈表 5〉。結果顯示音節字調的調值對 Aa 的貢獻度較短語調的調值對
Ap 的貢獻度為大。不過，前文已提到，語流韻律輸出是層層範圍不同的調值堆
疊而成，因此自 4.3.2節起，我們將討論如何從音節 Syl層起，建立每一韻律層的
韻律模型，及各韻律層如何疊加，共構韻律輸出。 
 
 
 
語篇的基頻構組與語流韻律體現 
 
197 
 
 
〈圖 7〉扣除字調成分，韻律詞模型在不同 PG 位置的特徵，每條曲線表示特定
長度的韻律詞模型，橫軸表示在此韻律詞內音節順序，縱軸表示扣除字調成分後
的殘差。 
2. 韻律詞 PW 受韻律短語 PPh 管轄之特徵 
同理我們將扣除字調成分的韻律詞 PW 模型依照韻律短語 PPh 位置分類後，
得到各韻律詞的特徵（見〈圖 8〉），發現韻律詞詞尾的特徵與詞首、詞中最為不
同，尤其又以 PPh-Medial 最為一致，而 PPh-Initial、PPh-Medial 最重要的特徵也
大致發生在詞尾 Aa。從 PPh-Medial 位置的韻律詞表現出一致性可以看出，PPh-
 
 
 
語篇的基頻構組與語流韻律體現 
 
199 
以上結果顯示：字調元件 Aa 分析中，音節層貢獻度的範圍是 38%-46%；加入字
調的前後相鄰字調共構的線性字調語境後，累積貢獻度提升為 45%-55%。加入
PW 層的韻律邊界訊息後，累積貢獻度提升至 48%-60%；加入 PW 層在所屬韻律
詞的位置順序後，累積貢獻度提升至 51%-67%（見〈表 2〉）。PPh 層的字調預估
加上 BG 層的邊界訊息後，累積貢獻度提升至 54%-73%；最後加上 PG 層的邊界
訊息後，累積貢獻度即 Aa 的正確率提升至 56%-74% 不等。由此可知，儘管大部
分的字調貢獻度主要來自音節層與韻律詞層，但在 Syl 層不及 50%，仍需考慮邊
界效應對字調的貢獻度。 
短語調元件 Ap 分層貢獻度分析結果，對照先前研究的分析結果顯示，當每
一個 PPh 被獨立分析時，結果顯示：正確預測只有 46.49%，53.51% 是殘差。在
考慮韻律階層中上層 PG 效應後，預測值改善了 16.03%，累積預測值正確率
為 62.52%（鄭秋豫 2008）。本實驗分析結果更進一步指出，各層語篇資訊對韻律
輸出的貢獻度因語料而異。從〈表 4〉中可發現：韻律短語 PPh 在古文語料
CL 及白話長篇敘事語料 CNA 貢獻度大不相同。CNA 的正確率多來自與前後短
語調共構的線性短語調語境，在 80% 以上，表示韻律短語句調較為分明，而且在
發音人間並無差異（80% 與 81%）。而 CL 的 PPh 貢獻度不但較低，且有相當的
個別差異（59% 及 38%），男性發音人 m056 線性短語調語境甚至只佔了階層貢
獻度 38%。因此，語流韻律的體現，並非僅由字調的連接與短語句調的串接所表
現，還包括了上層韻律資訊的規劃。 
 
5. 實驗二：不同韻律格式驗證階層式韻律架構 
5.1 實驗目的與假設 
 
本文以韻律短語的基頻曲線變化為主要分析參數，聽感的韻律邊界停頓為
輔，從 (1) 文體工整性，及 (2) 內建的韻律性來檢視、剖析朗讀古典文體語料的韻
律格式，並從階層式韻律句群及架構分析語流韻律中的韻律成分，驗證不同韻律
格式實為 HPG 階層式貢獻度的不同分布的反映，韻律格式越規則，上層韻律單
位的貢獻度越大。 
 
5.2 實驗語料 
 
除實驗一所使用的語料 CL 外，我們在實驗二加入 34 則氣象播報的語篇段
落，並依文本結構的工整規則性，分為四類韻律格式：1. 規則 (R)、2. 半規則
 
 
 
語篇的基頻構組與語流韻律體現 
 
201 
SYL、韻律詞 PW、韻律短語 PPh、呼吸句群 BG、語段（韻律句群 PG）之邊
界。 
 
〈表 7〉比較二語者朗讀古典文體韻律邊界的一致性結果 
 
5.3.2 Ap 分析 
 
〈圖 9〉比較二發音人的三種古典文體語料 Ap 預測正確率，在特定的韻律
層隨三種不同韻律格式 (R, SMR, IR) 的變化曲線，(a) PPh 層 (b) BG 層 (c) PPh 層
與 BG 層疊加後的結果，顯示不同韻律階層的差異（見 (a) (b)），加總後因相抵，
最後呈現相當一致的趨勢 (c)。 
 
 
〈圖 9〉古典文體語料分別為 (a) PPh 層 (b) BG 層 (c) PPh 層加 BG 層的 Ap 正確
率，橫軸表三種不同韻律格式 (R, SMR, IR)，縱軸表 Ap的預測正確率。 
 
各層的貢獻度在總預測率的比例分布，我們以〈圖 10〉圓餅圖表示。靛色表
示 PPh 層的貢獻比例，紫色表示 BG 層的貢獻比例，而黃色表示 PG 層的貢獻比
例。上列表男性發音人，下列表女性發音人，由左至右的分類分別為規則 (R)，
韻律邊界
發音人 SYL/B1 PW/B2 PPh/B3 BG/B4 PG/B5 
f054 97.98% 86.46% 82.79% 76.76% 62.30% 
m056 96.71% 88.69% 80.19% 76.76% 80.85% 
 
 
 
語篇的基頻構組與語流韻律體現 
 
203 
PPh 的相鄰與跨單位關係，以 Fujisaki 的 command-response model 擷取韻律短語
PPh 整體基頻，分析語篇組織中的「韻律短語 PPh 整體基頻高度組型與調整」，
呈現整體基頻組型變化，驗證此單位的整體基頻的相對高低是否與語篇組織對
應，並討論其語言學意義。 
6.2 實驗語料 
同實驗一。 
6.3 實驗過程 
6.3.1 韻律短語 PPh 作為韻律句群 PG 特定的語篇單位 
在前文已提及，不同位置的韻律短語 PPh 可表示口語段落的起始、延續和結
束，是一語篇關連的韻律單位，而語篇的關連性可由相鄰韻律單位的連接與跨單
位的呼應所構成，因此，韻律短語 PPh 在語段的位置、身分與功能亦可用來檢驗
語篇組織。 
6.3.2 韻律短語 PPh 與韻律句群 PG 位置標記 
將語料中已標記的韻律短語 PPh 按以下所列的韻律句群 PG 序列位置：PG
首、PG中與 PG尾，分成三個相關的組別： 
 
 PG-Initial when sequence index=1 
(7) PG-position = PG-Final when sequence index=M 
 PG-Medial otherwise 
 M = Number of PPh in PG 
6.3.3 韻律特徵：基頻高度的擷取 
擷取韻律短語 PPh 基頻高度的超音段聲學特徵。擷取特徵按韻律句群 PG 序
列位置加以比較，以瞭解跨語料–語者間是否表現出不同但一致的整體組型。接
著，進行統計分析，以瞭解在韻律句群 PG 不同位置的韻律短語聲學特徵差異是
否顯著。 
 
 
 
語篇的基頻構組與語流韻律體現 
 
205 
 
〈圖 11〉跨語料–語者相鄰 PG序列位置 Ap平均值範例。橫軸代表韻律邊界標記
B3, B4和 B5；縱軸代表 Ap平均值。 
6.4.2 統計分析結果 
我們針對韻律句群 PG 序列位置間韻律短語 Ap 參數值進行統計分析，為了
比較兩兩相對位置間的區辨性，採用 t-test 比較韻律句群 PG 序列位置 Ap 參數值
的韻律特性鑑別力是否顯著。其統計分析結果如〈表 8〉所示，星號 * 表示達
0.01顯著水準。 
〈表 8〉韻律句群 PG序列位置間 Ap參數值 t-test摘要表 
Speaker Initial-Medial Initial-Final Medial-Final 
f051 0.1764    * 0.313     * 0.1366    * 
m051 0.35757   * 0.4674    * 0.1098    * 
f054 0.162     * 0.286     * 0.124     * 
m056 0.509     * 0.4739    * -0.0352 
 
Ap 參數值的統計結果顯示（見〈表 8〉）：韻律句群 PG 三序列位置，不管是
相鄰單位或者跨單位，跨語料–語者間 Ap 參數值皆達顯著性差異，只有 m056 的
PG-Medial 與 PG-Final 的 Ap 參數值未達顯著水準。但對照〈圖 11〉我們可以看
出，跨語料–語者間的整體基頻組型是一致的。 
綜合來說，以韻律短語 PPh 為單位所呈現的整體基頻高低，有以下三種關
係：(1) 韻律句群 PG 內的韻律短語 PPh 基頻高度逐漸降低的漸降效應 (down-
stepping effect)，表現句段內各相鄰短語的關連性；(2) 韻律句群 PG 內首尾二韻
律短語 PPh 間的對比較任二位置短語的相對差距為大，表現句段內非相鄰的跨短
語呼應關連性；(3) 相鄰二韻律句群 PG 間，由於前一 PG 基頻降至最低與後接
 
 
 
語篇的基頻構組與語流韻律體現 
 
207 
7.2 實驗二 
 
實驗二「聽感標註的重疊性」實驗結果顯示兩語者的差異性並不大，而且從
〈表 7〉列出 HPG韻律階層上層到下層的重疊比例，可發現上層標註的重疊率雖
然不如下層，但在上層都能維持一定的重疊比例，可見在古典文體中，語篇的韻
律效應仍存有相當的一致性。 
而 Ap 分析中，我們比較了古典文體語料在單一韻律層中 Ap 正確率隨文體
（規則、半規則到不規則）的變化趨勢後發現：在韻律短語層 (PPh) 的預測，隨
著文體從規則到不規則的分類，兩語者 Ap 的正確率的預測皆呈現相同的趨勢。
也就是說，預測的正確率隨文體的不規則程度上升，顯示出越不規則的短語結構
變化，越是提供了較多的預測資訊，使不規則語料的 Ap 參數在 PPh 層獲得較準
確的預測。然而，在呼吸句群層 (BG) 的預測，卻呈現相反的趨勢，即 Ap 預測正
確率隨著文體工整性的提升，呈現上升的趨勢，顯示在文體越工整，上層韻律效
應越明顯。因此在 BG 層中，預測度隨著文體工整性與 Ap 呈正相關。若將兩層
的 Ap 預測正確率相加，可發現相加後的 Ap 預測率，對總預測率具有互補效
應。在規則語料中，BG貢獻度高，PPh層貢獻度低；不規則語料中，PPh貢獻度
高而 BG 貢獻度低；而半規則語料的 PPh 及 BG 貢獻度則介於規則跟不規則間。
兩者互補的結果，總預測率曲線則趨於平緩。 
本實驗結果顯示：語流最終的韻律輸出，各韻律層都有貢獻，其中又以 BG
層與 PG 層對短調元件 Ap 的貢獻度差異最大，約佔 7~35%。以上結果一方面與
實驗一的階層式貢獻度呼應，即 PPh 的 Ap 必須考慮呼吸句群 BG 層以及韻律句
群 PG 層的上層效應；一方面顯示因語體而產生的韻律輸出差異，只是階層式貢
獻度的分布差異而已，其韻律成分完全可由 HPG 架構解釋，同一基型只需調整
階層式的韻律貢獻度，便可產生不同的韻律輸出 (Tseng & Su 2007)。 
相對於實驗二檢視不同語體的 Ap 階層貢獻度之結果，實驗一中經由「韻律
詞受韻律句群 PG 管轄之特徵」實驗結果（〈圖 7〉）指出：跨語體間的韻律詞特
徵，在 PG-Medial 最為穩定且最不明顯，因此大部分與語體變化相關的的貢獻度
差異，應來自 PG-Initial與 PG-Final而非 PG-Medial。此結果亦顯示，線性的串接
平滑不及跨單位的呼應更具對比性，超音段訊息的相對意義比相鄰串接更具語篇
組織的意義。 
實驗二則更進一步證實，同一規劃的基型，即可生成不同的韻律格式，亦可
作為處理不同韻律格式的模版，無論從語言產製、語言習得、語言處理、認知資
源需求的角度，都符合語言學上的深層意義。韻律格式的差異，可以從不同韻律
 
 
 
語篇的基頻構組與語流韻律體現 
 
209 
look-ahead) 與整體韻律處理 (global prosody processing)，提供相對性線索，共構
出全面性的韻律語境。 
更重要的是，以階層式多短語語流韻律 HPG 架構闡釋此一實驗結果，我們
認為，在同一 PG 內 PPh 跨越單位的高–低對比反差，所呈現的正是來自上層單
位 PG 的覆蓋效應，對於同韻律層級姊妹組成成分 (sister constituent) 造成影響；
而同級相鄰 PG 間的 PPh 逆向低–高反差，則是來自更上一層單位的同級管轄效
應而非覆蓋效應，此時的相鄰同韻律層級姊妹組成成分是 PG 而非 PPh。因此，
語篇韻律語境的構成必須同時考慮相鄰單位與跨越單位的對比。另外，值得注意
的是，實驗三的研究結果亦證明了：以 PPh 為單位的基頻高低對語流韻律的體現
也有其貢獻，不容忽視；所共構出的語篇韻律語境，是語流韻律的重要特徵。而
在聲學語音研究方法上，我們強調，基頻參數不應以赫茲為測量單位，必須經過
非線性的對數轉換後，以對數值 (logarithmic value) 呈現，才能精確表達基頻高低
在聽感上的對應。動態基頻現象的解析，需將大小不同的單位明確界定，強調其
對比性，才能回歸超音段聲學語音參數的本質意義。另外，對比反差的觀察，不
應侷限於差異值的大小，而需從相對性的意義探索，才能將信號的特徵及處理，
與言語鍊裡口語的產製聽解結合，進而提出具語言意義的解釋。 
 
7.4 綜合討論 
 
根據趙元任先生的說法，短語句調與字調之間的關係，就好比波浪與連漪之
間層層疊加關係，以小波浪比喻字調，大波浪比喻短語句調，大小波浪的相疊與
覆蓋可以代數總和表示，相位相等時互相加成，相位相反時互相抵消  (Chao 
1968:39-40)。我們根據這個邏輯推斷：一個大波浪同時覆蓋於一個以上的小波浪
之上，被大波浪覆蓋的一串小波浪受制於大波浪；大小波浪之間的關係，是上下
層不對等單位的階層式管轄制約；被同一大波浪所覆蓋的多個小波浪，彼此之間
則是對等單位的線性串接。由於大小波浪擁有各自的波型，經由階層式的管轄制
約與對等的線性串接的互動後，會形成一個全新的波浪形式，因此這個全新波浪
的波型體現，既非原來的大波浪、亦非各個的小波浪的串接。同理，在 HPG 架
構裡音節 (SYL) 以上的每一個韻律層裡的同級韻律單位，即韻律詞 (PW)、韻律
短語 (PPh)、呼吸組 (BG) 和韻律句群 (PG)，都同時包含了平行線性串接和上層制
約管轄的訊息，從韻律詞到韻律句群的每一個單位都是層級不同的較大波浪，必
須同時處理與其下轄較小一波的互動。在 HPG 架構下，語流韻律的成分，不僅
止於字調與短語句調；亦即階層式的關係不只一層，我們因此要問：語流輸出
 
 
 
語篇的基頻構組與語流韻律體現 
 
211 
語音信號處理必須兼顧 HPG 架構中各層的韻律效應所造成的相鄰及跨單位韻律
關係，而不僅只是做字調與句調的線性串接及平滑，才能完整地模擬出連續語流
的特性，並計算每一韻律層對 HPG架構的分層貢獻度。 
在 HPG 架構下，語段下的不同位置的韻律短語 PPh 共同組成表意韻律語
境，用來表示語段的起始、持續與結束，三者的關係既包含由首至中到尾線性連
接所表示的語段起始、延續到結束的相鄰接續，也包含 PG 首尾二短語跨越中段
短語所表達的起始與終止呼應，建構語篇語意關連時，它們都是重要語篇成分，
缺一不可。也因為如此，位於三個 PG 位置的韻律短語，即便是句法結構相同，
如均為陳述短句，其體現則因位置不同而有所不同。語段首尾的韻律短語不但下
傾的幅度不同，語段中的韻律短語因表語篇語意尚未結束，甚至沒有明顯的下傾
現象，三者所表達的相對性關係必須一起考慮，非比較個別短語下傾斜率所能盡
述。 
因此，語流韻律語境同時包括多短語語段及語篇結構的語境，二者韻律階層
不同。語段內的多個短語間，既有相鄰短語的連接，也有表語段連貫的連接與覆
蓋。語段間的語篇關連也有同樣的關係，既有相連也有跨語段的覆蓋。二種語境
均不可僅視為短語句調的線性串接結果。我們強調，語流韻律的研究單位，必須
從單獨的短語擴及為一個短語以上的複雜句 (complex sentence) 或語段 (speech 
paragraph)，亦即 HPG 架構所提出的「多短語韻律句群 PG (Multi-phrase Prosodic 
Group)」。PG 是語篇韻律的單位 (discourse unit)，上承語篇語意的管轄，下含短
語或簡單句法句的句調單位 IU 為其直轄的次級單位，主要功能是表示特定語意
段落的開始、延續與結束。因此，單一句調單位 IU 並不是最終或最大的韻律單
位，當短語形成語段時，各短語必須受上層語篇語意資訊管轄制約而調整，呈現
表意韻律語境，才能成為語意完整的語段。從 HPG 架構的角度來看，單一 IU 走
勢或串接平滑無法解釋的句調變異，其實可從韻律語境所建構的相鄰 IU 串接平
滑及上層管轄所造成的「開始、延續與結束」三者間的相互呼應關係得到解釋。 
8. 結語 
本研究結合聲學語音學、語料庫語言學及計算語言學，解析及量化語料的聲
學基頻證據，證明口語語流中的詞意韻律、句法韻律及表意韻律如何共構語篇韻
律及語流韻律的韻律語境；呈現出較大範圍韻律單位的整體基頻走勢的具體證
據；具體提出線性輸出的語音訊號中非線性貢獻的證據，增進對口語韻律的瞭
解。本研究首先從語篇結構定義語流韻律單位，再以量化方式將由上而下的階層
 
 
 
語篇的基頻構組與語流韻律體現 
 
213 
及各級停頓節點與節點前的停延等語音信號上的對比差異特性，獲致語篇單位的
訊息。近來已有研究證明：以 HPG 架構為基礎，有效的利用語篇韻律訊息，結
合有限的句法訊息，自動將連續語流切分為小句、複雜句、語段等不同層級的單
位，可得出包括正確的語篇標點符號的識別結果 (Xie 2008, Chiang 2009)，提升語
音識別的層級。 
未來研究方向包括將 HPG 架構套用至授課等溝通意圖明顯、語篇及語段訊
息分明的自發性語料，進行量化分析研究，一方面希望進一步探討語言產製、語
篇組織與語言認知的互動，以驗證此規劃基型也存在於看似不規則的自發性語料
中，另一方面希望更全面的解釋語流中字調的變異，解構字調即韻律的迷思。 
 
 
 
語篇的基頻構組與語流韻律體現 
 
215 
引用文獻 
 
Beckman, Mary E., and Julia Hirschberg. 1994. The ToBI Annotation Conventions, 
Appendix A. Columbus: The Ohio State University Research Foundation. 
Beckman, Mary E., and Gayle Ayers Elam. 1997. Guidelines for ToBI Labelling, 
Version 3.0. Columbus: The Ohio State University Research Foundation. 
Chao, Yuen Ren. 1968. A Grammar of Spoken Chinese. Berkeley: University of 
California Press. 
Chen, Sin-Horng, Chiu-yu Tseng, and Hsin-min Wang. 2006. Tone modeling for speech 
synthesis. Advances in Chinese Spoken Language Processing, ed. by Chin-Hui 
Lee, Haizhou Li, Lin-shan Lee, Ren-Hua Wang & Qiang Huo, 77-98. Singapore: 
World Scientific. 
Chiang, Chen-Yu. 2009. Unsupervised Joint Prosody Labeling and Modeling for 
Mandarin Speech. Hsinchu: National Chiao Tung University dissertation. 
Crystal, David. 1969. Prosodic Systems and Intonation in English. Cambridge: 
Cambridge University Press. 
Fujisaki, Hiroya, and Keikichi Hirose. 1984. Analysis of voice fundamental frequency 
contours for declarative sentences of Japanese. Journal of the Acoustical Society of 
Japan (E) 5.4:233-242. 
Gu, Wentao, Keikichi Hirose, and Hiroya Fujisaki. 2005. Identification and synthesis of 
Cantonese tones based on the command-response model for F0 contour generation. 
Proceedings of 2005 IEEE International Conference on Acoustics, Speech, and Signal 
Processing (ICASSP 2005), Vol. 1, I289-I292. Philadelphia, Pennsylvania, USA. 
Halliday, Michael A. K. 1967. Intonation and Grammar in British English. The Hague: 
Mouton. 
Keller, Eric, and Brigitte Zellner. 1996. A timing model for fast French. York Papers in 
Linguistics 17:53-75. 
Liu, Fang. 2009. Intonation Systems of Mandarin and English: A Functional Approach. 
Chicago: University of Chicago dissertation. 
Mixdorff, Hansjörg. 2000. A novel approach to the fully automatic extraction of 
Fujisaki Model parameters. Proceedings of 2000 IEEE International Conference 
on Acoustics, Speech, and Signal Processing (ICASSP 2000), Vol. 3, 1281-1284. 
Istanbul, Turkey. 
Mixdorff, Hansjörg. 2001. MFGI, a linguistically motivated quantitative model of 
German prosody. Improvements in Speech Synthesis, ed. by Eric Keller, Gérard 
Bailly, Alex Monaghan, Jacques Terken & Mark Huckvale, 134-143. Chichester: 
John Wiley. 
Mixdorff, Hansjörg. 2002. An Integrated Approach to Modeling German Prosody. 
Dresden: Technische Universität Dresden dissertation. 
 
 
 
語篇的基頻構組與語流韻律體現 
 
217 
2005. Fluent speech prosody: framework and modeling. Speech Communication 
46.3-4:284-309. 
Tseng, Chiu-yu, and Zhao-yu Su. 2007. From one base form to multiple output styles—
Predicting stylistic dynamics of discourse prosody. Proceedings of the 8th Annual 
Conference of the International Speech Communication Association (INTERSPEECH 
2007), 110-113. Antwerp, Belgium. 
Tseng, Chiu-yu, and Zhao-yu Su. 2008. Boundary and lengthening—On relative 
phonetic information. Paper presented at the 8th Phonetics Conference of China 
and the International Symposium on Phonetic Frontiers. Beijing, China. 
Wang, Changfu, Hiroya Fujisaki, Sumio Ohno, and Tomohiro Kodama. 1999. Analysis 
and synthesis of the four tones in connected speech of the standard Chinese based 
on a command-response model. Proceedings of the 6th European Conference on 
Speech Communication and Technology (EUROSPEECH '99), 1655-1658. Budapest, 
Hungary. 
Xie, Lei. 2008. Discovering salient prosodic cues and their interactions for automatic 
story segmentation in Mandarin broadcast news. Multimedia Systems 14.4:237-253. 
Xu, Yi. 1999. Effects of tone and focus on the formation and alignment of F0 contours. 
Journal of Phonetics 27.1:55-105. 
Xu, Yi. 2004. Understanding tone from the perspective of production and perception. 
Language and Linguistics 5.4:757-797. 
Zellner Keller, Brigitte, and Eric Keller. 2001. Representing speech rhythm. 
Improvements in Speech Synthesis, ed. by Eric Keller, Gérard Bailly, Alex 
Monaghan, Jacques Terken & Mark Huckvale, 154-164. Chichester: John Wiley. 
鄭秋豫. 2008.〈語篇韻律與上層訊息──兼論語音學研究方法與發現〉，《語言暨
語言學》9.3:659-719。 
鄭秋豫, 蘇昭宇. 2007.〈從不同韻律格式驗證階層式韻律架構並兼論對語音科技
的應用〉，第十九屆自然語言與語音處理研討會論文。台北：中華民國計算
語言學會。 
鄭秋豫, 蘇昭宇. 2008.〈以 Fujisaki模型驗證連續語流中字調及韻律詞對應於階層
性韻律架構 HPG 的意義〉，第二十屆自然語言與語音處理研討會論文。台
北：中華民國計算語言學會。 
 
[Received 16 April 2009; revised 18 November 2009; accepted 18 December 2009] 
 
Institute of Linguistics 
Academia Sinica 
130, Sec. 2, Academia Road 
Nankang, Taipei 115, Taiwan 
cytling@sinica.edu.tw 
 中央研究院研究人員及研究技術人員出國報告表    
姓名  鄭秋豫 
服務單位及職位  中央研究院語言學研究所 研究員 
活動日期  (1)   99.05.11-05.14 
 (2)   99.05.20-05.22 
地點 (1) 美國芝加哥 
(2) 美國波士頓 
經費來源(非本院經
費支出者不需填寫
此報告)  
(1)  國科會：語音科技開發導向的口語篇章韻律研究項下 
     國外差旅費  
(2)  不足部分由研究員鄭秋豫個人項下國外差旅費支出 
出國類別 出國類別(一) 參加國際會議會議名稱: 
(外文) (1)Speech Prosody 2010 
       (2)IACL-18 (The 18th Symposium of the International Association of  
          Chinese Linguistics) & NACCL-22 
 
會議舉辦機構: (1) ISCA (International Speech Communication Association) 
                 and UIUC (University of Illinois, Urbana-Champaign) 
              (2) IACL (International Association of Chinese Linguistics)  
                 and Harvard University 
論文題目、講學或報
告題目 
論文(1) : Prosodic Patterns of Information Structure in Spoken Discourse---a   
        Preliminary Study of Mandarin Spontaneous Lecture vs. Read Speech 
論文(2)：From Ripples and Waves to Tide--Sentence Prosody and Beyond 
學術活動報告內容 
一、 如有發表論文請提供摘要 
 
論文(1) : Chiu-yu Tseng and Chao-yu Su,Prosodic Patterns of Information Structure in Spoken Discourse---a 
Preliminary Study of Mandarin Spontaneous Lecture vs. Read Speech 
Abstract The aim of the study is to explore the prosodic patterns spontaneous lecture speech vs. read speech to 
show where and how these monologues differ and why by analyzing perceived emphasis and its acoustic 
features within and between speech paragraphs. Systematic but distinct patterns are found for both speech types 
in emphasis distribution across speech, overall and local tempo modulations. Read speech is characterized by 
discourse coherence while spontaneous information structure in addition. Intricate tempo modulations 
characterizing information structure are discussed. 
 
論文(2)：From Ripples and Waves to Tide--Sentence Prosody and Beyond 
Abstract Linguistic knowledge is essentially about abstraction. This talk is about the big picture in the speech 
signal. Chao (1968) illustrated the interaction between Chinese tones and intonation with a visual analogy of 
ripples and waves whereby the smaller ripples must yield when a larger wave tops over. This talk focuses on 
why the prosody of a sentence (utterance) when it appears in a discourse context differs drastically from when it 
is uttered in isolation, and why global prosody beyond the level of sentence is an intrinsic part of naturally 
occurring speech. It is argued that prosodic chunking and phrasing occur not only at the sentence level, but also 
at the discourse level. Traces of global prosody found in lower-level speech units are abundant in the speech 
signal; their seemingly random occurrences can, in fact, be systematically derived. Read and spontaneous L1 
Mandarin speech data will be presented to illustrate our proposal that higher-level discourse information takes 
 
及在此次會議發表，但已非常令人振奮。 
 
會議二第 18 屆中國語言學國際會議 (IACL-18The 18th Symposium of the International Association of 
Chinese Linguistics) & 第 22 屆北美洲漢語語言學會議（NACCL-22 North America Conference on 
Chinese Linguistics）聯合會議(May 20-22, 2010 Cambridge, MA, USA)，主辦單位是哈佛大學語言學
系及東亞學系。 
此次會議共收到 600 餘篇論文摘要，錄取率為三分之一，與會人士超過二百人，會議共有 7 個平行
場次，同時舉行，涵蓋了中國語言學的各項次學門。會議共有四場主題報告，分別是（1）以 corpus 
linguistics 進行的歷史語言學研究，研究語言包括德語、法語，（2）音系學（3）中國語言的歷史語
言研究及（4）句法理論。這四場報告比較有創新意義的是藉由以語料庫語言學的研究方法、研究
的語言不包括漢語的研究結果，對中國語言研究所提出的啟發。此外，以實驗語音學驗證音系學研
究的論文雖然不多，卻明確的指出，音系學與語音學的介面，將更趨緊密。這兩個新方向應該對日
後的中國語言學產生非常正面的影響。我們以因此希望，以傳統中國語言學研究為主的課題，在研
究方法上也能創新，並與現代語言學理論的研究有更多的互動。 
此次會議的另一特色，是以一天的時間（5 月 21 日）慶祝亞利桑納大學語言學系教授 Rudolph Troike
執教五十年。他本是 University of Texas 的教授，指導的學生包括湯廷池、董昭輝教授，於 1970-71
年間獲得 Fulbright 基金會獎助 ，在國立台灣師範大學英語系擔任客座教授一年，除授課時間外，
並於每週三晚間再寓所舉辦小型討論會。當時受教於他並受他鼓勵前往 MIT 進修獲得語言學博士學
位的，便是現今哈佛大學語言學系的黃正德教授。同年代受教於 Troike 教授的還包括前清華大學語
言所現元智大學應用外語系教授王旭及報告人鄭秋豫。黃正德教授為此次 IACL-18 的大會主席，特
別安排一整天的 Rudy Fest 活動，由 Troike 教授的代代門生提出論文報告。報告人鄭秋豫便是受邀
參加 Rudy Fest 的學者，因此報告內容以綜述近年來提出口語語篇韻律架構的動機、語料庫語音學
的研究方法及所獲結果為主。由於第一場由賓州大學 Anthony Kroch 教授所做的主題報告，特別強
調了以語料庫語言學治學的研究，與會學者僅少數使用了本院資訊所詞庫小組的文本語料庫，以大
批語料從語音資料庫著手，進行系統性韻律現象分析、對高層訊息提出口語韻律理論架構及相對應
的數學模型的學者，僅我一人，因此獲得非常正面迴響，有許多關於研究方法的討論。 
 
三、出國成果  
出國類別: 參加國際學術會議 
     參加會議任務： 
□(1)主講人 
■(2)受邀演講 : IACL-18 & NACCL-22 
□(3)會議主席  
□(4)論文口頭發表  
■(5)論文壁報發表 : Speech Prosody 2010 
□(6)評論人 
□(7)主辦人 
 
      
                                      
96年度專題研究計畫研究成果彙整表 
計畫主持人：鄭秋豫 計畫編號：96-2221-E-001-025-MY3 
計畫名稱：語音科技開發導向的口語篇章韻律研究 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 1 1 15%  
研究報告/技術報告 0 0 0%  
研討會論文 1 1 25% 
篇 
 
論文著作 
專書 0 0 0%   
申請中件數 0 0 0%  專利 已獲得件數 0 0 0% 件  
件數 0 0 0% 件  
技術移轉 
權利金 0 0 0% 千元  
碩士生 1 1 5%  
博士生 1 1 25%  
博士後研究員 1 1 15%  
國內 
參與計畫人力 
（本國籍） 
專任助理 1 1 15% 
人次 
 
期刊論文 1 1 20% 
新世代自動語音辨
識技術之研究第二
階段(子計畫五)--
韻律屬性與語音事
件偵測之研究共同
研究成果。 
研究報告/技術報告 0 0 0%  
研討會論文 6 6 20% 
篇 
Tseng, Chiu-yu 
(2010). ＇Beyond 
Sentence 
Prosody.＇ 
Invited keynote 
paper at 
Interspeech 
2010, (Sep. 
26-30, 2010), 
Makuhari, Japan.
論文著作 
專書 2 2 15% 章/本  
申請中件數 0 0 0%  專利 已獲得件數 0 0 0% 件  
件數 0 0 0% 件  
國外 
技術移轉 
權利金 0 0 0% 千元  
 
