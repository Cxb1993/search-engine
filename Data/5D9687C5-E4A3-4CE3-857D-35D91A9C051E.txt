I 
 
Table of Content 
Table of Content .................................................................................................................................................. I 
List of Tables ...................................................................................................................................................... II 
List of Figures ................................................................................................................................................... III 
一、 中文摘要 ............................................................................................................................................ 1 
二、 英文摘要 ............................................................................................................................................ 1 
三、 背景和目的 ........................................................................................................................................ 1 
四、 研究方法 ............................................................................................................................................ 2 
1. RVC System Architecture ................................................................................................................... 2 
1.1. Software Parser ....................................................................................................................... 2 
1.2. Hardware Parser ..................................................................................................................... 3 
1.2.1 Reconfigurable Parser ..................................................................................................... 3 
1.2.2 Context-adaptive Binary Arithmetic Coding .................................................................. 5 
1.2.3 Context-adaptive Variable-length Coding ...................................................................... 5 
1.2.4 Variable Length Coding .................................................................................................. 6 
1.3. System Controller ................................................................................................................... 7 
1.4. Reconfigurable Inverse Quantization and Inverse Transform (IQIT) .................................... 7 
1.5. Intra-prediction ....................................................................................................................... 8 
1.6. Reconfigurable Inter-prediction.............................................................................................. 9 
1.7. Intra-prediction/Inter-prediction reconstruction (IIR) .......................................................... 10 
1.8. De-blocking Filter................................................................................................................. 10 
1.9. Memory Controller ............................................................................................................... 12 
五、 結果與討論 ...................................................................................................................................... 14 
1. First year ........................................................................................................................................... 14 
2. Second year ....................................................................................................................................... 14 
3. Third year ......................................................................................................................................... 14 
六、 相關著作 .......................................................................................................................................... 15 
1. First year ........................................................................................................................................... 15 
2. Second year ....................................................................................................................................... 15 
3. Third year ......................................................................................................................................... 15 
七、 參考文獻 .......................................................................................................................................... 16 
III 
 
List of Figures 
Fig. 1 RVC decoder system architecture ............................................................................................................ 2 
Fig. 2 Parser of AVC/H.264 ................................................................................................................................ 3 
Fig. 3 Parser of MPEG-2 .................................................................................................................................... 3 
Fig. 4 Reconfigurable parser of RVC decoder .................................................................................................... 3 
Fig. 5 Reconfigurable Exp-Golomb code parser for both AVC/H.264 and MPEG-2 ........................................ 4 
Fig. 6 Shared register for both AVC/H.264 and MPEG-2 .................................................................................. 4 
Fig. 7 Reconfigurable Entropy-SysCtrl FIFO .................................................................................................... 4 
Fig. 8 Bottleneck in CABAC decoder parallelization ........................................................................................ 5 
Fig. 9 State transitions in Viterbi decoder .......................................................................................................... 5 
Fig. 10 High level block diagram of CABAC decoder ...................................................................................... 5 
Fig. 11 Low level block diagram of parallel bin decoder ................................................................................... 5 
Fig. 12 Block diagram of CAVLC decoder ........................................................................................................ 5 
Fig. 13 Architecture of "CoeffToken" and "TrailingOnes" decoder ................................................................... 6 
Fig. 14 "RunBefore" decoder ............................................................................................................................. 6 
Fig. 15 Architecture of zeros insertion ............................................................................................................... 6 
Fig. 16 Constant output rate architecture ............................................................................................................ 6 
Fig. 17 Architecture with decoding one symbol per cycle ................................................................................. 7 
Fig. 18 Address generator of group detector ...................................................................................................... 7 
Fig. 19 Control flow of VLC decoder ................................................................................................................ 7 
Fig. 20 Reconfigurable IQIT module ................................................................................................................. 7 
Fig. 21 Block diagram of RIT units .................................................................................................................... 8 
Fig. 22 Micro-architecture of RIT data path ....................................................................................................... 8 
Fig. 23 Micro-architecture of RHT data path ..................................................................................................... 8 
Fig. 24 Final architecture of intra-prediction ...................................................................................................... 8 
Fig. 25 Filtering architecture of intra-prediction ................................................................................................ 9 
Fig. 26 Round & Shift & Clip of intra-prediction .............................................................................................. 9 
Fig. 27 Reconfigurable filtering PE .................................................................................................................... 9 
Fig. 28 Block diagram of proposed reconfigurable inter-prediction ................................................................ 10 
Fig. 29 Block diagram of interpolation ............................................................................................................ 10 
Fig. 30 Interface of de-blocking filter .............................................................................................................. 10 
Fig. 31 Processing order of edge within MB ..................................................................................................... 11 
Fig. 32 Original processing order of edges per MB .......................................................................................... 11 
Fig. 33 Processing order of edges in the normal/PAFF mode. .......................................................................... 11 
Fig. 34 Processing order of top MB edges in MBAFF mode ............................................................................ 11 
Fig. 35 Processing order of bottom MB edges in MBAFF mode...................................................................... 11 
Fig. 36 Block diagram of the de-blocking filter ............................................................................................... 12 
Fig. 37 I/O specification of Memory Controller............................................................................................... 12 
Fig. 38 Data storage distribution of DRAM ..................................................................................................... 13 
1 
 
前瞻可重組視訊編碼於數位家庭生活之技術(3/3) 
Advanced Reconfigurable Video Coding in Digital Home 
計畫編號：NSC 98-2220-E-006-002-MY3 
執行期限：99年 8月 1日至 100年 9月 30日 
主持人：李國君副教授 國立成功大學電機工程學系 
 
一、 中文摘要 
 本計畫於第二年度已經明確地決定所要實現
的標準分別為 MPEG-2 以及 AVC/H.264。以及
基於第二年度中所完成的可重組態視訊解碼器系
統架構、於 8×8 顆粒階層處理的高階資料流模
型、各模組輸入輸出的腳位定義、各模組之間的
緩衝記憶體大小、以及狀態與控制暫存器之定
義。我們於第三年度修改了可重組態視訊解碼器
系統架構使其更易於硬體實現以及將高階資料流
精細化成低階資料流幫助設定每一個模組，以及
整個系統的控制匯流排以及資料匯流排的寬度定
義都於這年度完成。我們藉由低階資料流所帶來
的架構資訊，包含記憶體組態和處理單元的數量
來探索出符合高階資料流的規範之可行架構。此
低階資料流模型也成為在未來驗證時的一個工
具，可以幫助實現架構時之流暢度。目前已經完
成的模組有：CABAC、VLC、Inter-prediction、
Intra-prediction，以及 De-blocking filter。未來將
會持續完成可重組態視訊解碼器系統之整合，以
便未來可以將其下線。 
 
關鍵詞：可重組態視訊解碼器、資料流模型。 
二、 英文摘要 
According to progress in the second year, the 
specification of application is determined. The 
specification of RVC supported two standards, 
MPEG-2 and AVC/H.264. The RVC system 
architecture, high level data flow model processing 
at data granularity 8 × 8, the modules' I/O 
definitions with pin accuracy, the size of local buffer, 
status and control registers are all determined. In 
this year, we modified the system architecture to 
make the system be implemented friendly and refine 
the high level data flow to low level data flow to 
assist the design each module smoothly. In addition, 
the bit-widths of control and data bus are also 
determined by the high level data flow model in this 
year. Since the low level data flow can provide the 
architectural information of the module, such as 
memory configuration and number of processing 
elements, we explored the various data flow to 
discover the feasible architecture which is 
confirmed to the specification determined by high 
level data flow. The low level data flow also assisted 
us to do the verification for each module. The 
completed modules include reconfigurable IQ/IT, 
CABAC, VLC, Inter-prediction, Intra-prediction, 
and De-blocking filter. Finally, the almost modules 
of RVC decoder is implemented and we will keep 
working on RVC for tape-out the RVC.  
Keywords: Reconfigurable Video Coding (RVC) 
decoder, data flow model.  
三、 背景和目的 
The specification of RVC decoder is depicted as 
Table 1  
Table 1 Specification of RVC decoder 
Supported Standard MPEG-2 AVC/H.264 
Resolution 1920×1080 
Color format 4:2:0 
Frame per second 30 60 
Profile Main High 
Level High 4.2 
 
In the second year, the high level data flow is 
established to assist us to design RVC decoder in the 
high level perspective. Subsequently, the module 
interface and local buffer size are also determined. 
We refined the module interface to be pin accurate 
and the determined the configuration of local buffer. 
The low level data flow assisted the design space 
exploration and found a feasible solution. The 
following sections illustrated the detailed design 
method and design space exploration result to prove 
the power of top down design methodology 
presented in the first year.  
 
3 
 
RVC decoder. The partition scheme of workload is 
based on the analysis of communication overhead 
which affects the bus utilization and the load on 
embedded CPU. Due to the hierarchical bitstream 
structure, we are able to partition the software and 
hardware at certain level. However, the partition at 
certain level results in different communication 
overhead due to the transfer between software and 
hardware partition, which is illustrated in Table 4. 
The number of transfer in one second is calculated 
according to the highest level of hardware partition 
since this level is where the transfer exists. For 
partition 1, the number of transfer in one second is 
equal to the number of pictures in one second, i.e. 
frame rate. For partition 2, the number of transfer in 
one second is equal to the number of slices in one 
second. The level limit of number of slices within 
one picture is specified in annex A of [17], which 
are 362 for 1920x1088@60fps. That is, the total 
transfer time is 362×60 = 21720. The way to derive 
the number of times of transfer for partition 3 and 
partition 4 is the same as partition 1 and partition 2. 
From the number of times of transfer, we think that 
partition 1 leaves too much room and Partition 4 is 
not acceptable. For partition 2 and partition 3, based 
on the experience of design of system architecture, 
we finally adopt partition 2 as the final decision. 
Table 4 Various software/hardware partition scheme. 
Partition 
scheme 
Software 
Parser 
Hardware 
Parser 
Number of 
transfer 
1 Sequence level 
Below 
picture level 64 
2 Above picture level 
Below  
slice level 21,760 
3 Above  slice level 
Below  
MB level 522,240 
4 Above  MB level 
Below  
block level 3,133,440 
1.2. Hardware Parser 
The main work of hardware parser is controlling 
the entropy decoder processing, bitstream fetching 
and pre-processing scheme. The entropy decoding 
and bitstream fetching is synchronized at the time of 
a marcoblock is finished since the processing time 
of entropy decoder and spent bitstream are not 
known in advanced. In addition, to match the real 
time constraints, the proposed RVC decoder shall 
pre-process ten marcoblocks for each frame to 
average the processing cycle of each marcoblock. 
Hence, we design the Hardware Parser as a FSM 
which contains some states to achieve the above 
functionalities. The hardware parser contains four 
modules, including Reconfigurable Parser, CABAC, 
CAVLC, and VLC. 
1.2.1 Reconfigurable Parser 
Reconfigurable Parser contains the 
functionalities of parsing MPEG-2 and AVC/H.264 
syntax elements. Based on the parsing flows, we can 
depict the block diagram of these two standards and 
then extract the commonality in two standards. The 
block diagrams of AVC/H.264 and MPEG-2 parser 
are shown in Fig. 2 and Fig. 3. Two blocks colored 
in the same color represent that the commonality is 
extracted between them and hence being designed 
as reconfigurable data path or control. With the 
commonality extraction, the reconfigurable parser is 
designed for both AVC/H.264 and MPEG-2, which 
is also shown in Fig. 4. The dotted green and red 
lines are control lines. The green ones represent 
common control lines in both AVC/H.264 and 
MPEG-2. The red ones mean represent individual 
control lines in either AVC/H.264 or MPEG-2. 
 
 
 
Since the data granularity of parser is in the unit 
CL: Codeword Length
Sum CL: Summation of 
               Codeword Length
MPEG-2 Parser
Lower
Register
Upper
Register
Bitstream
FIFO
VLD
Entrop-IQIT
FIFO
Not Exist
Syntax Element 
Assignmentmotion_residual
Parser
Fixed Length
Code Parser
Microprogrammed
Control
CL
+Sum CLRegister
load
Barrel Shifter
load
++ 0
Bitstream
Semantics
Decoder
Shared
Syntax Element 
Register
Entropy-SysCtrl
FIFO
Fig. 3 Parser of MPEG-2 
AVC/H.264 Parser
Lower
Register
Upper
Register
Bitstream
FIFO
CAVLD
CABAD
Entrop-IQIT
FIFO
Not Exist
Syntax Element 
AssignmentReconfigurable
Exp-Golomb
Code Parser
Fixed Length
Code Parser
Microprogrammed
Control
CL
+Sum CLRegister
load
Barrel Shifter
load
++ 0
Bitstream
Semantics
Decoder
Shared
Syntax Element 
Register
Entropy-SysCtrl
FIFO
Fig. 2 Parser of AVC/H.264 
Shared
Syntax Element 
Register
Reconfigurable Parser
Lower
Register
Upper
Register
Bitstream
FIFO
CAVLD
VLD
CABAD
Entrop-IQIT
FIFO
Not Exist
Syntax Element 
AssignmentReconfigurable
Exp-Golomb
Code Parser
Fixed Length
Code Parser
Microprogrammed
Control
CL
+Sum CLRegister
CL: Codeword Length
Sum CL: Summation of 
               Codeword Length
load
Barrel Shifter
load
++ 0
Bitstream
Semantics
Decoder
Entropy-SysCtrl
FIFO
Reconfigurable Exp-Golomb 
Code Parser Control
Codeword Length 
Control CAVLD/VLDCommunication
Sequencing
Syntax Element
Register Control
Entropy-SysCtrl  
FIFO Control
Fig. 4 Reconfigurable parser of RVC decoder 
5 
 
((1661-1324) / 1661 = 20.29%) gate count. For 
whole control, microprogrammed control saves 
8.93% (((1661+3078)-(1324+2992))/(1661+3078) = 
8.93%) gate count. That is, as a whole, the 
reconfigurable parser with microprogrammed 
control provides higher flexibility without any 
sacrifice. The access delay of the control signal is 
much less than that of finite state machine by 1.1 ns 
and the overall gate count is even less than that of 
finite state machine based parser. 
1.2.2 Context-adaptive Binary Arithmetic 
Coding 
The CABAC is a difficult module to implement 
because of the highly data dependency and high-end 
application. The bottleneck is the context model 
updating which is illustrated in Fig. 8.  
 
Hence, we proposed a high throughput parallel 
CABAC decoder to achieve the real-time constraint. 
The idea is inspired by the [18], we can map the 
state transition, which is depicted in Fig. 9, in 
parallel Viterbi decoder to CABAC and 
subsequently increase the throughput.  
 
Based on the mapping from Viterbi decoder to 
CABAC, we developed a parallel bin decoder which 
breaks the data dependency. Subsequently, we 
explore the various architectures and corresponding 
data flow at high level. Finally, the feasible solution 
is depicted in Fig. 10. 
 
We refined the high level data flow to the low 
level to extract more implementation details to assist 
the RTL coding. Hence, a low level block diagram 
of parallel bin decoder is illustrated in Fig. 11. 
 
The proposed parallel CABAC decoder has the 
degree of parallelism 3.5 times higher than the 
sequential decoding. The throughput of the 
proposed design reaches 378 Mbins per second at 
108MHz. 
1.2.3 Context-adaptive Variable-length Coding  
The CAVLC module decodes residual block in 
macroblock level from the input bitstream. Five 
kinds of symbol should be processed, including four 
variable length codes, "CoeffToken", "Level", 
"TotalZeros", and "RunBefore", and one fixed 
length code, sign flag of "TrailingOnes", and Fig. 12 
depicts the block diagram of proposed CAVLC 
decoder. 
 
In order to increase the throughput of the 
CAVLC decoder, we make much statistics on the 
bitstream provided by MPEG to predict the 
following most probable symbol. Hence, we 
expanded the degree of parallelism of CAVLC to 
increase the throughput to fit the real-time 
constraint. 
First, for decoding "CoeffToken" and sign flag of 
"TrailingOnes", we proposed a decoding flow which 
decodes these symbols concurrently and then 
Fig. 9 State transitions in Viterbi decoder 
Fig. 8 Bottleneck in CABAC decoder parallelization 
Fig. 11 Low level block diagram of parallel bin decoder 
Fig. 10 High level block diagram of CABAC decoder 
Fig. 12 Block diagram of CAVLC decoder 
7 
 
we use low-level dataflow to analyze that the cycles 
we needed to decode all quantized transform 
coefficient when worst case was occurred. 
According to the worst case in decoding syntax 
element and low-level dataflow of each architecture, 
we conclude that decoder with decoding one symbol 
per cycle is enough for the specification we 
supported when the clock rate is 108MHz. 
Analyzing various architectures by low-level 
dataflow exploration, we obtained the architecture 
with less hardware cost and the Fig. 17 illustrated 
the architecture which is capable of decoding one 
symbol per cycle. 
 
In part of symbol mapping, we alleviate and 
simplify the needed ROM size by extracting the 
commonality among tables and combining sign-bit 
of some syntax elements. Fig. 18 shows the address 
generator of group detector we proposed and Fig. 19 
is the control flow of VLC decoder. 
 
 
From the specification of supported standard, the 
required throughput is around 108M symbols per 
second is enough to fit the real-time constraint. 
 
Table 7 Synthesized result of VLC decoder 
VLC decoder 
Technology Throughput (symbols/sec) 
Gate 
Count 
Clock Rate 
(MHz) 
TSMC 
0.18um ~108M 36K 108 
1.3. System Controller 
The purposed system controller is to control the 
hardware part at lower level by sending the coding 
information to corresponding modules. The coding 
information includes the parsed syntax elements and 
decoded semantics from hardware parser and also 
the intra mode and motion vectors reconstructed by 
system controller itself. Hence, we can also say that 
system controller centralizes the control for sharing 
the coding information. Also, based on the proposed 
reconfigurable control unit idea in this thesis, the 
configuration of those data path designed as 
reconfigurable architecture, e.g. IQIT, 
Inter-prediction, IIR, can be controlled by system 
controller with a microprogrammed control which is 
able to be reconfigured as MPEG-2 or AVC/H.264 
mode and even the future supported standards with 
slightly modification and no further hardware 
resources required. The synchronization and control 
of hardware partition except for Hardware Parser 
are done by System Controller. 
1.4. Reconfigurable Inverse Quantization and 
Inverse Transform (IQIT) 
We proposed the reconfigurable inverse 
quantization and inverse transform based on 
commonality extraction. The proposed architecture 
can support the different coding standards via the 
configuration setting. Fig. 20 illustrates in detail the 
components of the reconfigurable IQIT module. The 
three main blocks are the reconfigurable IQ (RIQ) 
unit, reconfigurable HT (RHT) unit, and 
reconfigurable IT (RIT) unit. 
 
The proposed reconfigurable inverse transform 
data path is designed by 8x1 data granularity, which 
means that the eight pixels concurrently processed 
at the same time. Based on the separable property, 
the 2D transform can be achieved by row-column 
Fig. 20 Reconfigurable IQIT module 
Fig. 18 Address generator of group detector 
Fig. 19 Control flow of VLC decoder 
Fig. 17 Architecture with decoding one symbol per cycle 
9 
 
To extract the commonality of intra-prediction, 
we list all filtering functions of all modes we 
supported. By listing this table, we extracted the 
commonality of filtering, and designed the filtering 
architecture to compute the predicted samples. The 
filtering architecture is showed in Fig. 25. After the 
commonality extraction, we applied the basic 
processing elements (PEs) for reconfiguring the 
various modes for Intra-prediction. The following 
architecture can produce seven outputs once and 
increase the throughput at the same time. 
 
In addition, we also extracted the commonality 
in Round & Shift & Clip module. The 
reconfigurable Round & Shift & Clip architecture is 
depicted in Fig. 26.  
 
By setting distinct configuration of Fig. 25 and 
Fig. 26, all supported modes in Intra-prediction can 
be realized. By exploring various data granularities, 
we determined that 4×1 data granularity would be 
most suitable solution according to our specification. 
We also pointed out the worst case is occurred at the 
conditions: (I) block size is 8×8, (II) first 8×8 block 
of a marcoblock, and (III) the intra-prediction mode 
is the plane mode. It costs 33 cycles for processing 
one 8×8 block. That is, clock rate, 108MHz, is 
enough to match the real-time constraint.  
1.6. Reconfigurable Inter-prediction 
The major goal of inter-prediction is using the 
temporal information to remove the redundancy. 
AVC/H.264 inter-prediction has some features for 
higher compression ratio than MPEG-2, such as 
variable block size motion compensation, weighted 
prediction, multiple reference picture, six tap 
interpolation and quarter pixel. Both MPEG-2 and 
AVC/H.264 perform inter-prediction in decoding 
processing and hence we would like to propose a 
reconfigurable inter-prediction to support them.  
Since the interpolation operations of 
inter-prediction are the most important process that 
produces the predicted samples, we investigate all 
interpolation functions in different standards. By 
exploring those interpolation functions, we found 
out the commonality of interpolation, and designed 
the reconfigurable filtering PE to compute the 
predicted sample. The architecture of reconfigurable 
filtering PE is illustrated in Fig. 27. The 
corresponding control signals of this PE are listed in 
Table 9. This reconfigurable filtering PE has two 
sets of input: the first set is for the filter operation in 
MPEG-2 standard, including “4 pixel adder” and “2 
pixel adder & shift left 2”; the second one is for the 
filter operation in AVC/H.264 standard, including “6 
tap filter”, “2 pixel adder” and “shift left 2”. 
  
 
Table 9 Control signals of reconfigurable filtering PE 
Function Name Operation Input S0 S1 S2 Output 
4 pixel adder a+b+c+d dcab 0 1 0 A 
6 tap filter E-5F+20G+ 20H-5I+J 
GHF 
IEJ 1 0 0 A 
2 pixel adder E+J EJ - - 1 A 
shift left 2 4E E - - - C 
2 pixel adder & 
shift left 2 a+b ab - - - B 
 
Fig. 28 is the block diagram of proposed 
reconfigurable inter-prediction. The Interpolation is 
the main module to compute the predicted samples 
without considering the weight. The reference 
samples, which are the inputs of interpolation, come 
from the Memory Controller. For bi-directional 
Fig. 25 Filtering architecture of intra-prediction 
++
+
In0 In1 In2 In3
Out0 Out1 Out2
+
In4 In5
Out3
+
+
In6 In7
Out4 Out5
+
Out6
d
G H F I E J
<<4 <<2 <<2
-1
b1
c ba
<<1
0
<<2
S0 S1
S2
A B C
0          1 0          1
0          1
+
In0
Out0 Out1
<<S
>>C
1
<<R
Fig. 26 Round & Shift & Clip of intra-prediction 
Fig. 27 Reconfigurable filtering PE 
11 
 
follows the order left, right, top, and bottom. In 
addition, as the numbers 0 to 3 of 4×4 block B3 
shows in Fig. 31, the processing of edges in each of 
the 4×4 blocks B3, B7, B11, and B15 follows the 
order left, top, bottom, and right edges. 
 
Fig. 32 shows the original processing order of 
edges per MB. It is obvious that the original 
processing order is very regular, and the control 
operations of the normal/PAFF and MBAFF modes 
can be commonly used. However, we find that the 
number of edges to be filtered in each 8×8 block is 
unbalanced, and the load of processing edges is 
concentrated on the right two 8×8 blocks of top MB 
per MB pair, wherein there are 10 edges to be 
filtered in these two 8×8 blocks. This would cause 
the low utilization efficiency of the processing 
element (PE), whereas the left two 8×8 blocks of 
top MB per MB pair are processed, and extend the 
processing period of each 8×8 block in accordance 
with the maximum load of processing edges in the 
8×8 block. 
 
Hence, we develop another processing order of 
edges in the MB. Fig. 33 shows the proposed 
processing order of edges in the normal/PAFF mode. 
As indicated in the above-mentioned assumption, 
the reference data of the left neighboring MB are 
stored in the internal memory for data reuse. Blocks 
B3, B7, B11, and B15 of the current MB are stored 
in the internal memory to serve as the reference data 
of the next MB. The horizontal edges of blocks B3, 
B7, B11, and B15 in the current processed MB are 
held, to be filtered until the next MB is processed. 
 
As 8×8 block Y0 shows, edges 0~2 belong to the 
previous MB, and are filtered while 8×8 block Y0 is 
processed. The same is done for edge 17 in 8×8 
block Y2, edges 32~33 in 8×8 block U0, and edges 
40–41 in 8×8 block V0. There are nine edges to be 
filtered in 8×8 block Y0, eight in 8×8 blocks Y1, Y3, 
U0 and V0, and seven edges in 8×8 block Y2. 
Fig. 34 shows the proposed processing order of 
edges in the top MB of the MB pair. As for 
luminance, edges 0 and 1 of the bottom MB in the 
previous MB pair are filtered when 8×8 block TY0 
of the top MB in the current MB pair is processed. 
Edges 16~17 of the bottom MB in the previous MB 
pair are filtered when 8×8 block TY2 of the top MB 
in the current MB pair is processed. As for 
chrominance, edges 32~33 of the bottom 
chrominance block in relation to the previous MB 
are filtered when 8×8 block TU0 of the top 
chrominance block in relation to the current MB is 
processed. The same is done for edges 40~41. 
 
Fig. 35 shows the proposed processing order of 
edges in the bottom MB of the MB pair. As for 
luminance, edges 0~1 of the top MB in the previous 
MB pair is filtered when 8×8 block BY0 of the 
bottom MB in the current MB pair is processed. 
Edges 16~17 of the top MB in the previous MB pair 
are filtered when 8×8 block BY2 of the bottom MB 
in the current MB pair is processed. As for 
chrominance, edges 32~33 of the top chrominance 
block in relation to the previous MB are filtered 
when 8×8 block BU0 of the bottom chrominance 
block in relation to the current MB pair is processed. 
The same procedure is done for edges 40~41. 
 
According to the processing order of edges in 
each 8×8 block, we schedule a data flow to trace the 
0
1
2 16
31
Current processed blockY0
14
Y1
28
29
26
27
Y2 Y3
Left neighboring block
9
10
13
15
16
11
12
7
5
8
4 6
3
17
20
21
22
23
18
19
24
25
30
16
36
39
37
U0
44
47
45
V0
34
35
3832
33
40
41
42
43
46
Fig. 33 Processing order of edges in the normal/PAFF mode. 
36
39
37
TU0
44
47
45
TV0
0 32
31
Current processed blockTY0
13
TY1
28
29
26
27
16
TY2 TY3
Left neighboring block
8
9
12
14
15
10
11
6
4
7
3 5
2
20
21
22
23
18
19
24
25
30
1
17
16
38
34
35
32
33
40
41
46
42
43
Fig. 34 Processing order of top MB edges in MBAFF mode 
0
32
Current processed block
16
Left neighboring block
1
17
16
32
33
40
41
4
7
5
BY0
6
3
2
13
12
15
10
11
BY1
8
9
14
BY2
20
21
22
23
18
19
31
28
29
26
27
24
25
30
BY3
36
39
37
38
34
35
BU0
44
47
45
BV0
46
42
43
Fig. 35 Processing order of bottom MB edges in MBAFF 
mode 
16
16
V0 V1 V2 V3
H0
H1
H2
H3
B0 B1 B2 B3
B4 B5 B6 B7
B8 B9 B10 B11
B12 B13 B14 B15
B0 B1 B2 B3
B4 B5 B6 B7
B8 B9 B10 B11
B12 B13 B14 B15
B00 1
2
3
B30 3
1
2
B0~B15: 4×4 block
Fig. 31 Processing order of edge within MB 
16
16
29
Current processed block
4
20
5
1 3
Y0
6
7
10
11
12
13
8
9
14
15
Y1
16
17
18
19
20
21
Y2 Y3
22
23
26
27
2824
25
30
31
36
3432
37
33 35
U0
44
4240
45
41 43
V0
38
39
46
47
Fig. 32 Original processing order of edges per MB 
13 
 
According to the specification, the data 
arrangement for the luminance frame needs 136 
rows to store, and the data arrangement for the 
chrominance frame needs 34 rows to store one 
chrominance frame data individually. Data storage 
distribution of DRAM is drawn in Fig. 38, while the 
top row is used to store the unfiltered data for 
intra-prediction.  
 
In proposed data arrangement scheme, we 
allocated the frame data in block-based and zig-zag 
scan within the block. The block size we proposed 
is 64×64 and we put the first block into the first 
bank, and the next block into the second bank, and 
so on. The relationship between data stored in the 
DRAM and the data location of a frame is illustrated 
in Fig. 39. 
 
 
 
 
When the Memory Controller reads the 
reference data for inter-prediction module, the worst 
case of proposed scheme happened that the data 
shall be read was stored in the same row but 
different banks. Fig. 40 depicted the worst cased of 
reading data for inter-prediction module. 
 
 
To support the PAFF mode and MBAFF mode 
for intra-prediction, the referenced unfiltered data in 
the current picture will come from different line 
buffer according to the frame coded or filed coded 
between the top macroblock (pair) and current 
macroblock (pair). The left part of Fig. 41 is for the 
PAFF mode. The right part of Fig. 41 is the data 
arrangement for the PAFF mode, which need 1 
column to store this line buffer data. The left part of 
Fig. 42 is for the MBAFF mode. The right part of 
Fig. 42 is the data arrangement for the MBAFF 
mode, which need 1 row to store this line buffer 
data. 
Fig. 43 is the proposed architecture of Memory 
Controller. It is very important to ensure that the 
data is read and written in the correct memory 
address. Address generator is a critical module to 
generate the memory address. 
Fig. 44 is the final architecture of DRAM 
Controller, which is an important connection 
interface between DRAM and AHB data/control 
bus. 
Fig. 38 Data storage distribution of DRAM 
Y
Cb
Cr
Unfiltered data
4512*8
136
34
34
1
Row
BankColumn
Fig. 39 Data arrangement of our design 
Row
Bank
512x8 Btye
64
Image
… ……
… … …
64 Different 
row, Same 
bank
Same row, 
Different bank
Column
: Bank0
: Bank1
: Bank2
: Bank3
Image
… ……
… … …
64
64 Different row, 
Same bankSame row, 
Different bank
9
9
Fig. 40 The worst case of proposed data arrangement 
1920
1088 Image
……
…… 16
4512*8
136
34
34
1
0
1
: Macroblock pair
0
1
Fig. 42 Data arrangement for MBAFF mode 
1920
1088 Image
0
1
……
…… 16
4512*8
136
34
34
1
0
1
: Macroblock
Fig. 41 Data arrangement for PAFF mode 
15 
 
year to prove the functionalities are correct. Based 
on the achievement of this year, we published a 
journal paper and two international conference 
papers on IEEE transaction on Parallel and 
Distributed Systems [13], ISCAS 2011 [14] and 
ICASSP 2011[15]. These two international 
conferences are very popular in the electrical 
engineering field. In addition, we also applied US 
patents to the parallelization methodology of 
CABAD and reconfigurable Inter-prediction and 
one master thesis for RVC decoder [16]. Moreover, 
we also have drafted two journal papers for 
Reconfigurable Parser and high throughput CABAC 
decoder to submit. 
Although some modules are under development, 
we will keep realizing them and complete the whole 
RVC decoder.  
六、 相關著作 
1. First year 
[1] Gwo Giun Lee, He-Yuan Lin and Ming-Jiun 
Wang, "RVC Conformance Testing Working 
Draft V4.0," ISO/IEC JTC1/SC29/WG11 
MPEG w9592, Antalya, Turkey, January 2008. 
[2] Gwo Giun Lee, He-Yuan Lin, Ming-Jiun Wang, 
Bo-Han Chen and Yuan-Long Cheng, "On The 
Verification of Multi-Standard SOC'S for 
Reconfigurable Video Coding Based on 
Algorithm/ Architecture Co-Exploration," 
IEEE 2008 Workshop on Signal Processing 
Systems. 
[3] J. Gorin, M. Raulet, Y-L. Cheng, H-Y. Lin, N. 
Siret, K. Sugimoto and G.G. Lee, "An RVC 
Dataflow Description of the AVC Constrained 
Baseline Profile Decoder," IEEE International 
Conference on Image Processing (ICIP2009). 
[4] Gwo Giun Lee, Ming-Jiun Wang, Bo-Han 
Chen, Jiun-Fu Chen, Ping-Keng Jao, Ching-Jui 
Hsiao, Ling-Fei Wei, “Reconfigurable 
Architecture for Deinterlacer based on 
Algorithm/Architecture Co-Design.,” Journal 
of Signal Processing Systems, special issue on 
reconfigurable video coding, June 2009. 
[5] G. G. Lee, C.-C. Lo, Y.-C. Chen, H.-Y. Lin, 
M.-J. Wang, "High-throughput low-cost VLSI 
architecture for AVC/H.264 CAVLC 
decoding," IET Image Processing, vol. 4, pp. 
81-91, 2010 
2. Second year 
[6] Wei-Chiao Yang, "Reconfigurable 
Architecture Design of Motion Compensation 
for Multi-Standard Video Coding," Master 
Thesis, Dept. Electron. Eng., National Cheng 
Kung University, Taiwan, 2009 
[7] Gwo Giun Lee, Yen-Kuang Chen, Marco 
Mattavelli and Euee S. Jang, 
“Algorithm/Architecture Co-Exploration of 
Visual Computing on Emergent Platforms: 
Overview and Future Prospects,” IEEE 
Transactions on Circuits and Systems for 
Video Technology, Vol.19, Issue. 11, 
November 2009. 
[8] Gwo Giun Lee, Wei-Chiao Yang, Min-Shan 
Wu, He-Yuan Lin, "Reconfigurable 
Architecture Design of Motion Compensation 
for Multi-Standard Video Coding", IEEE 
International Symposium on Circuits and 
Systems (ISCAS2010) 
[9] Gwo Giun Lee, Wei-Chiao Yang, He-Yuan Lin, 
Min-Shan Wu, "Design Space Exploration 
Method of Reconfigurable Motion 
Compensation Architecture" Taiwan Patent, 
201117619, May 16th, 2011 
[10] Jia-Wei Liang, "A High Throughput Parallel 
AVC/H.264 Context-Based Adaptive Binary 
Arithmetic Decoder," Master Thesis, Dept. 
Electron. Eng., National Cheng Kung 
University, Taiwan, 2010 
[11] Tsung-Yuan Huang, "Design and 
Implementation of Reconfigurable Inverse 
Transform Architecture for Multiple Purpose 
Video Coding," Master Thesis, Dept. Electron. 
Eng., National Cheng Kung University, 
Taiwan, 2010 
3. Third year 
[12] Gwo Giun Lee, He-Yuan Lin, "Quantifying 
Intrinsic Parallelism Via Eigen-Decomposition 
of Dataflow Graphs for Algorithm/Architecture 
Co-Exploration", IEEE 2010 Workshop on 
Signal Processing Systems(SiPS2010) 
[13] G. Lee, H. Lin, C. Chen, and T. Huang, 
"Quantifying Intrinsic Parallelism Using Linear 
Algebra for Algorithm/Architecture 
Co-Exploration," Parallel and Distributed 
Systems, IEEE Transactions on, vol. PP, pp. 
1-1, 2011. 
[14] T.-Y. Huang, H.-Y. Lin, C.-F. Chen, and G. G. 
Lee, "Reconfigurable inverse transform 
architecture for multiple purpose video 
coding," in Circuits and Systems (ISCAS), 2011 
IEEE International Symposium on, 2011, pp. 
1223-1226. 
[15] L. Jia-Wei, L. He-Yuan, and L. Gwo Giun, "A 
high throughput parallel AVC/H.264 
國科會補助專題研究計畫項下出席國際學術會議心得報告 
                                     日期：100年 10月 31日 
                                 
一、參加會議經過 
 2010年 IEEE訊號處理系統研討會 (2010 IEEE Workshop on Signal Processing Systems) 於 10月 6
日至 10月 8日在法國巴黎舉行，此會議主要是在探討訊號處理系統設計的發展與創新，討論的範圍
相當廣闊，包含有 
(1.) Optimization of Signal Processing Algorithms and Architectures 
(2.) VLSI Based Design and Implementation of Signal Processing Systems 
(3.) Image & Video Signal Processing and Implementations 
(4.) Communication Systems and MIMO Applications 
(5.) Application-specific Signal Processing Architectures 
(6.) Bio-medical Signal Processing Systems 
(7.) Bio Signal Processing 
(8.) Statistical Signal Processing 
(9.) Multi-core and NoC 
(10.) Signal Processing Application Systems 
(11.) Channel Coding 
(12.) Filter Designs 
計畫編號 NSC 97-2221-E-006-252-MY3 
計畫名稱 前瞻可重組視訊編碼於數位家庭生活之技術 
出國人員
姓名 李國君 
服務機構
及職稱 
國立成功大學電機工程學系，副教
授 
會議時間 
2010年 10月 6日
至 
2010年 10月 8日 
會議地點 San Francisco Bay Area, California, 
U.S.A. 
會議名稱 
(中文) 2010年 IEEE訊號處理系統研討會 
(英文) 2010 IEEE Workshop on Signal Processing Systems 
發表論文
題目 
(中文) 藉由特徵分解資料流圖形以量化本質平行度進而達成演算法
暨架構共同探索 
(英文) Quantifying Intrinsic Parallelism Via Eigen-Decomposition of 
Dataflow Graphs for Algorithm/Architecture Co-Exploration 
QUANTIFYING INTRINSIC PARALLELISM VIA EIGEN-DECOMPOSITION OF 
DATAFLOW GRAPHS FOR ALGORITHM/ARCHITECTURE CO-EXPLORATION 
 
He-Yuan Lin and Gwo Giun Lee
 
Department of Electrical Engineering 
National Cheng Kung University 
No.1, Ta-Hsueh Road, Tainan 701, Taiwan 
Email: {n2894157, clee}@mail.ncku.edu.tw 
 
   
ABSTRACT
Algorithmic complexity analysis and dataflow models play 
significant roles in the concurrent optimization of both 
algorithms and architectures, which is now a new design 
paradigm referred to as Algorithm/Architecture Co-
exploration. One of the essential complexity metrics is the 
parallelism revealing the number of operations that can be 
concurrently executed. Inspired by the principle component 
analysis (PCA) capable of transforming random variables 
into uncorrelated ones and hence dependency analysis, this 
paper presents a systematic methodology for identifying 
independent operations in algorithms and hence quantifying 
the intrinsic degree of parallelism based on the dataflow 
modeling and subsequent eigen-decomposition of the 
dataflow graphs. Our quantified degree of parallelism is 
platform-independent and is capable of providing insight 
into architectural characteristics in early design stages. 
Starting from different dataflows derived from signal flow 
graphs in basic signal processing algorithms, the case study 
on DCT shows that our proposed method is capable of 
quantitatively characterizing the algorithmic parallelisms 
making possible the potentially facilitation of the design 
space exploration in early system design stages especially 
for parallel processing platforms. 
 
Index Terms—Algorithm/Architecture Co-exploration, 
dataflow model, complexity metrics, parallelism, eigen-
decomposition
1. INTRODUCTION 
As demands for communication, multimedia, entertainment 
and biomedical applications and many areas of information 
processing continually increase, more and more signal 
processing systems are developed to accommodate these 
increasingly more demanding requirements. In order to 
improve human experiences in these applications, the 
algorithms become ever more sophisticated and complex. 
However, the accompanied high complexity results in more 
implementation challenges.  
New emerging platforms consisting of reconfigurable 
circuits, massively parallel processing elements (PE), and 
multicore processors now have sufficient computational 
capability and flexibility for the realization of complex 
signal processing algorithms. However, mapping the 
complex algorithms onto the emerging platforms is quite a 
big challenge in exploring the huge design spaces.  
The Algorithm/Architecture Co-exploration (AAC) [1]-
[2] capable of concurrently optimizing both algorithms and 
architectures are investigated to efficiently overcome the big 
design gap in mapping signal processing algorithms to 
architectures. One of the key features in this methodology is 
to characterize the algorithmic complexity, which can 
exhibit the essential architectural information in early 
design stages. Traditional complexity measurement in terms 
of execution time based on a single-processor random-
access machine (RAM) can provides initial high level 
complexity characteristics of algorithms. However, the 
algorithmic intrinsic complexity metrics that are platform-
independent are required for the more advanced and 
emerging platforms and also distributed systems.  
The degree of parallelism embedded within signal 
processing algorithms is among one of the most essential 
complexity metrics capable of conveying architectural 
information for parallel and distributed systems at design 
stages as early as the algorithm development phase.  
Amdahl’s law introduced a theoretical maximum 
speedup of parallelization of a software program [3]. The 
theoretical maximum speedup is determined by the ratio of 
sequential part within the program, since the sequential part 
cannot be paralleled due to the high data dependencies. 
Amdahl’s law provided a brief and initial high level idea in 
characterizing parallelism. In a similar manner, graph theory 
is applied to quantify the instruction level parallelism (ILP) 
more specific for processor-oriented platforms at a coarser 
data granularity [4]. Furthermore, Prihozhy et al defined the 
parallelization potential based on the ratio between the 
computational complexity and the critical path length of 
algorithms also capable of estimating the degree of 
parallelism [5]. They measured the complexity by means of 
317978-1-4244-8933-6/10/$26.00 ©2010 IEEE SiPS 2010
eigenvectors of the Laplacian matrix L representing G, 
which is defined as [9]: 
 
°
¯
°
®
­

 
 
others.                    0
adjecent, are  vand  vif                  1
j,i  if     )degree(v
j)(i, ji
i
L       (1) 
 
where degree(vi) is the number of edges connected to the i-
th vertex vi. In the Laplacian matrix, the i-th diagonal 
element shows the number of operations that are connected 
to the i-th operation and the off-diagonal element denotes 
whether two operations are connected. So, the Laplacian 
matrix can clearly express the dataflow graph by a compact 
linear algebraic form. This paper then introduces some 
important properties of the Laplacian matrix and explains 
how and why they can facilitate the analysis of parallelism.  
Let x be a vector of n variables associated with the n 
vertexes or operations of the dataflow graph G, the value of  
xTLx is equal to the sum of square difference between the 
adjacent vertexes: 
 
2
E(G))v,(v
ji
T
ji
)xx(¦

 Lxx ,                         (2) 
 
where (vi, vj)E(G) represents all the operation pairs (vi, vj) 
whose vi and vj are adjacent to each other.  
By assigning the elements in x to be either 1 or -1, x 
can be used as an indicator vector that represents all the 
possible ways to disconnect the graph into two sub-graphs. 
In other words, one can let xi = 1 and -1 to represent that the 
i-th vertex v1 is partitioned into the first and second sub-
graphs, respectively. By doing so, the corresponding value 
of xTLx is equal to 4 × size of the edge cut, i.e. the value of 
xTLx is proportional to the number of the edges that are cut 
to separate G into two disjoint or independent sub-graphs. 
That is, in our application, xTLx represents the number of 
edge cut from the aspect of algebraic graph theory. If two 
adjacent vertexes are assigned the same value to indicate 
that the vertexes are grouped into a same sub-graph, their 
square difference will be zero. Otherwise, if two adjacent 
vertexes are assigned opposite values, which shows that 
they are grouped into different sub-graphs and the 
associated edge is cut, their square difference will be four. 
Consequently, the value of xTLx is equal to four times of 
the number of edges cut. It is worthy to note that the 
Laplacian matrix is semi-positive definite, which ensures 
that the edges cuts are always non-negative values.  
2.2. Eigen-decomposition of dataflow graphs 
So far, this paper has explained the Laplacian matrix of 
dataflow graphs and its application to edge cut. Now, what 
is more interesting is to find a pair of partitions that 
minimizes the number of edge cut, which could reveal the 
connectivity of dataflow graph and hence parallelism.   
Based on the concept of spectral graph theory, this 
minimum cut problem can be formulated as the following 
equation: 
 
x*  = arg min (xTLx) subject to xTx = 1         (3) 
 
where x* is the optimal solution of (4). In order to relax the 
operand of x, an additional constraint, xTx = 1 is involved. 
This constraint makes sure that the values in x are all finite. 
By applying the Lagrange multiplier, the above constrained 
optimization problem can be transformed into an 
unconstrained one. Eventually, by partial derivation with 
respective to x, the original problem becomes an eigen-
decomposition equation: 
 
Lx –Ox = 0,   (4) 
 
Hence, the optimal solution x* are eigenvectors and the 
corresponding values of xTLx are eigenvalues. In general, 
the eigenvector associated with the smallest eigenvalue 
provides a heuristic solution to achieve near minimum cut. 
In a similar manner, the eigenvectors corresponded to the 
second and third smallest eigenvalues could indicate the 
partitions with second and third minimum edge cut numbers.  
 In the spectral graph theory, the second smallest 
eigenvalueO2 is called the algebraic connectivity. It is the 
most representative one that can quantify how well 
connected a graph is from the aspect of the linear algebra. 
The reason is that the smallest eigenvalue of a Laplacian 
matrix is always 0 and the corresponding eigenvector is a 
vector whose elements are all ones. This case indicates that 
the partition with smallest edge cut is to put all the vertexes 
into a same sub-graph, which is a trivial solution. So, the 
eigenvector associated with the second smallest eigenvalue 
is used in [12] to achieve near minimum cut for parallel 
processing.  
However, in the case that the algebraic connectivity of 
a dataflow graph equals zero, the dataflow graph is 
inherently disconnected without any edge cut. Consequently, 
the dataflow graph contains at least two independent 
operation sets that can be executed in parallel without 
synchronization. Furthermore, in the case that the third 
smallest eigenvalue of a dataflow graph is also zero, there 
are at least two methods to partition the original graph 
without edge cut. Hence, the dataflow graph contains at 
least three independent operation sets and has high degree 
of parallelism. In summary, the number of independent 
operation sets in the dataflow graph is equal to the number 
of eigenvalue = 0 of the Laplacian matrix, which is an 
important property of the spectral graph theory that can 
assist in quantifying the degree of parallelism of the 
algorithm.  
As comparing our proposed dataflow analysis method 
with PCA, the interpretations of the eigenvalue and 
eigenvector are different, since the matrixes used in the two 
techniques posses various physical meanings. PCA employs 
319
 Ё Ё
Ё
Ё
ЁЀ
ЀЁ
Ѐ
㬍d
Ѐ ЀЀ Ѐ
ЀЀ
Ё 䐙aЀ
Ѐ Ё
Ё Ё
X(2) X(6)
x(3)x(0) x(2)x(1) x(7)x(4) x(6)x(5)
㬍b 㬍b 㬍a
㬍c㬍c
X(4)X(0)
㬍d
Ё
㬍e
Ѐ Ѐ
X(1) X(5)
㬍f 㬍g ͪ h 㬍h
Ё Ё
X(3) X(7)
㬍g 㬍f 㬍e
a: sin(22.5Ζ)/2 b: cos(22.5Ζ)/2
c: 0.353 d: cos(45Ζ)
e: sin(11.25Ζ)/2 f: cos(11.25Ζ)/2
g: sin(56.25Ζ)/2 h: cos(56.28Ζ)/2  
Fig. 2 Dataflow graph of the Chen’ DCT 
Table I Complexity analysis of the original 8-point DCT and Chen’s DCT 
 Original DCT Chen DCT[13] 
Number of 
Operations 
64 multiplications 
and 56 additions 
16  multiplications and 26 
additions/subtractions 
Critical Path 
Length 
1 multiplications and 
3 additions 
2 multiplications and 4 
subtractions 
Strict-sense 
Parallelism 8 2 
Furthermore, the critical path length consists of one 
multiplication and three additions.  
In order to reduce the number of operations in the direct 
DCT implementation, several fast algorithms have been 
proposed in the literature. One being Chen’s fast DCT 
algorithm that recursively factorizes the DCT matrix into 
sparse ones [13]. This results in a butterfly-like DCT 
dataflow. Fig. 2 illustrates the dataflow graph of the 8-point 
DCT based on Chen’s algorithm. According to our analysis 
results, the 8-point Chen’s DCT needs 16 multiplications 
and 26 additions/subtractions and its degree of parallelism is 
only two. The type of parallelism is heterogeneous. The 
critical path length has two multiplication and four 
subtractions.  
Table I tabulates the complexity comparison of the 
original and Chen’s DCT. Obviously, the number of 
operations of Chen’s is much smaller than that of the 
original DCT. However, the original DCT has the higher 
degree of parallelism and shorter critical path as compared 
to Chen’s DCT. In general, the degree of parallelism of the 
original DCT is equal to its radix, since all the transformed 
coefficients can be independently calculated by each DCT 
basis. However, the degree of parallelism of Chen’s DCT is 
always two: one set of operations is for even coefficients 
and the other is for the odd ones. In signal processing 
applications, the dataflow of an algorithm is equivalent to 
the mathematical expression. Consequently, the degree of 
parallelism quantified via analysis of the dependency of 
dataflow graphs is identical to the algorithmic analysis of 
mathematical expression. 
According to the discussions above, we could find that 
although the fast DCT algorithm is capable of reducing the 
number of operations, it also diminishes the degree of 
parallelism. Similar phenomena can be found in other fast 
algorithms such as fast Fourier transform and fast wavelet 
transform. The computational complexity reduction is due 
to the reason that some common operations in fast 
algorithms are extracted and executed only once. However, 
the original independent operations become dependent. 
Hence, the degree of parallelism is reduced. In addition, the 
critical path length of fast algorithms is longer than that of 
the original one. It is true that an algorithm having less 
number of operations was fast on past single processor 
platforms. However, with massive parallel PE and multiple 
processors, fast algorithms may not be faster anymore. 
Hence, our proposed parallelism is indeed an important 
complexity metric for characterizing algorithms in early 
design stages. In addition, by exploring dataflow, it is 
possible to trade off between the number of operations and 
degree of parallelism so as to enlarge the design space for 
various design scenarios depending target applications.  
3.2. Intrinsic complexity in AAC 
Our method is capable of exporting different mappings of 
algorithms onto system architectures constrained by design 
parameters under various design scenarios which is part of 
the algorithm/architecture co-exploration. There are three 
major scenarios in the development of signal processing 
systems. In the first scenario, a platform is specifically 
designed for a fully specified algorithm. In the second 
scenario, an algorithm is optimized with modifications and 
then mapped onto a specific platform. In the third scenario, 
both the algorithm and architecture can be freely designed 
subject to usual application constraints. Our extracted 
intrinsic complexity can facilitate developing the targeted 
architecture in the first design scenario, modifying or 
selecting the algorithm in the second scenario and 
concurrently optimizing both the algorithm and the 
architecture in the third scenario.  
In single-processor systems, for instance, Chen’s 
algorithm could be more preferable, since it requires less 
number of operations. However, as considering platforms 
such as VLIW, Superscaler, SIMD, MIMD, etc, the original 
DCT composed of eight parallel homogeneous inner-
product operations could be employed for achieving higher 
throughput. Of course signal processing algorithms studies 
at a coarser data granularity benefit multi-cores, GPU’s, etc. 
If the targeted platform has reconfigurable processors, our 
extracted repeat independent operation sets can be used for 
the design of the corresponding instruction set architecture. 
In a similar manner, the independent operation sets can also 
assist in developing application specific instruction set 
processor ASIP [14] for DCT. 
In general, the design space exploration could be an NP 
hard problem. However, our extracted degree of parallelism 
within algorithms can efficiently assist in deciding on the 
configurations of multicore or finer grain parallel platforms 
via early discarding of impractical solutions. For instance, it 
could be impractical to port the original 8-point DCT on a 
platform having more than 8 SIMD for speedup. In a similar 
manner, the parallelism extracted and dataflows can also 
321
國科會補助計畫衍生研發成果推廣資料表
日期:2011/05/10
國科會補助計畫
計畫名稱: 前瞻可重組視訊編碼於數位家庭生活之技術
計畫主持人: 李國君
計畫編號: 97-2221-E-006-252-MY3 學門領域: 積體電路及系統設計 
研發成果名稱
(中文) 基於線性代數理論之演算法本質平行度量化和分析方法
(英文) Linear algebraic methods for quantifying and extracting intrinsic parallelism of algorithm
成果歸屬機構
國立成功大學 發明人
(創作人)
李國君,林和源
技術說明
(中文) 此發明提出演算法複雜度中本質平行度的度量量化方法。這個平行度度量方法可
以幫助演算法暨架構共同設計以同時探索演算法與架構，進而最佳化整體系統設
計。演算法的複雜度分析與資料流模型，在同時最佳化演算法與架構時，扮演了
十分重要的腳色。對於前瞻及未來之訊號與資訊處理之應用，平行度毫無疑問地
是最重要的複雜度參數之一。藉由演算法資料流模型並將相關的資料流圖型映射
至線性方程式系統，進而分析相依矩陣以及Laplacian矩陣的自由度，此發明可
以有系統地量化演算法的本質平行度。更進一步地，此發明所萃取出之本質平行
度可以有效地幫助越來越複雜的訊號與資訊處理，應用在新興的平台上做設計空
間探索。而這些平台是由特殊用途積體電路、可重組態電路、大量的平行處理單
元和多核心中央處理單元所組成。
(英文) The present invention discloses the algorithmic complexity measuring methods on 
parallelisms for the novel algorithm/architecture co-design methodology capable of 
exploring both algorithms and architectures and optimize systems. Algorithmic 
complexity analysis and dataflow modeling play significant roles in the concurrent 
optimization of both algorithms and architectures. The parallelism is undoubtedly 
important complexity metrics. Based on dataflow modeling of algorithms and mapping 
the dataflow graphs onto linear equations with dependency and Laplacian matrices, the 
present invention is capable of systematically quantifying parallelisms embedded in 
algorithms by charactering the degree of freedom of the linear equation system. 
Furthermore, the parallelism extracted can effectively facilitate the design space 
exploration of new emerging platforms for ever more complicated signal and information 
processing applications.
產業別 其他專業、科學及技術服務業
技術/產品應用範圍
此複雜度度量衡標準在產業應用性包含 
1. 多媒體編碼或處理標準制訂及相關軟硬體設計 
2. 無線通訊標準制訂及相關軟硬體設計 
3. 電子系統層級及晶片設計工具軟體開發 
4. 晶片系統之設計 
技術移轉可行性及
預期效益
藉由演算法複雜度中平行度的評估，此技術可以幫助在設計的早期階段，修正演算法以
符合效能需求和成本限制，進而最佳化地實現多媒體或通訊之相關應用。此技術除了可
提供晶片設計公司在系統開發時可以最佳化其演算法並同時降低軟/硬體實作之成本，並
有助於評估選擇或開發適當的嵌入式多核心處理器及相對應的系統平和軟硬體架構以提
高系統效能(throughput)，彈性(flexibility)以及可伸縮性(scalability) ，或降低時
脈及供應電壓以減少功率消耗(low-power) ，延長電池壽命等，進而擴大產品市場範圍，
提升市場之競爭力。
註：本項研發成果若尚未申請專利，請勿揭露可申請專利之主要內容。
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
