 
中英文摘要 
 
一、中文摘要 
在計畫中，我們提出了一個新的自動處理鞋印影像的方法。鞋印是犯罪現場中十分常見之線
索，其最主要的特徵便是其紋理的方向性。論文中，我們利用影像之灰度伴隨矩陣(co-occurrence 
matrices)、方向矩陣(directional matrix)及傅立葉轉換(Fourier transform)來截取出鞋印紋理之方向性
特徵以做為比對的依據。由於在前處理上使用主軸轉換(principal component transform)，本方法並
不會因為影像之旋轉或位移等失真造成錯誤的結果。實驗結果顯示，本方法能夠有效的識別各式的
鞋印。 
 
關鍵字：法庭科學、鞋印、傅立葉轉換、灰度伴隨矩陣、主軸轉換 
 
 
二、Abstract 
In this project, we present a method for automatically classifying/recognizing the shoeprint images 
based on the outsole pattern. Shoeprints are distinctive patterns often found at crime scenes that can 
provide valuable forensic evidence. Directionality is the most obvious feature in these shoeprints. For 
extracting features corresponding to the directionality, co-occurrence matrices, Fourier transform, and a 
directional matrix are applied to the shoeprint image. And with the stage of principal component 
transform, the method is invariant to rotation and translation variance. Experiments of matching 
shoeprints are conducted on the database of 315 shoeprint images to demonstrate the performance of the 
method. 
 
Keyword: forensic science, shoeprint, Fourier transforms, co-occurrence matrix, principal component 
transform 
 
I 
similarity measure is provided. On the basis of the similarity measure, the shoeprint image in the database 
that is most similar to the input image is determined. 
   Feature  
Extraction
Pattern  
Matching 
Matched 
Result 
Preprocessing 
Fig. 1. Flow diagram of the proposed method. 
 
 
3.1 Preprocessing 
Owning to the instability during imprint and scanning process, shoeprint images captured from 
imprint and digitization would suffer many distortions. These distortions include rotation, translation, 
imprint noise and other disturbances. The aim of this stage is to reduce these distortions and produce a 
standard format for feature extraction. Steps of preprocessing are shown in Fig. 2 and described below. 
   Gray-level 
Transform Noise Removal Smooth 
 Principal 
Component 
Transform 
 
Edge Detection 
 Bi-level 
Thresholding 
 Original  
Shoeprint Image 
Fig. 2. Flow diagram of the preprocessing steps. 
 
3.1.1 Gray-scale Transformation 
Original shoeprint images are of 16777216  color level. To transform color images into 
gray-scale ones, we apply the following equations: 
)2( 24
 Let  
),( jiR  denote the red value at pixel  ),( ji
),( jiG  denote the green value at pixel  ),( ji
),( jiB  denote the blue value at pixel  ),( ji
 Then the transformation [8] is 
16),(*098.0),(*504.0),(*257.0),( +++= jiBjiGjiRjigray .       (1) 
3.1.2 Noise removal 
Noises of an image could cause disturbing values in the print. To eliminate noises occurring from 
imprint and scanning process, images are divided into blocks, each of size 16*16. For each block B , we 
calculate its mean and variance by 
∑∑
= =
=
16
1
16
1
),(
256
1)(
i j
jiBBμ                                          (2) 
∑∑
= =
−=
16
1
16
1
2)](),([
256
1)(
i j
BjiBBVar μ                                 (3) 
If the variance of the block is lower than a specified threshold, the entire block is set to white color 
value (that is, the gray level of each pixel in the block is 255). Otherwise, keep the original contents. 
2 
Shoeprint images transformed with transformation matrix  might differ in orientations in 180 
degrees. Properties of normal human thenar reveal that the front-half part of shoe has bigger size in width 
comparing to the rear one. Therefore, after applying the transform, print was further examined to see if it 
matches the rule. Otherwise, rotate the image by 180 degrees. 
A
Fig. 3(a) is the original shoeprint image. Fig. 3(b) shows the shoeprint image with its corresponding 
eigenvectors drawn with dashed lines. Fig. 3(c) is the one transformed with respect to the eigenvectors of 
the largest eigenvalue. 
 
Fig. 3. An example of principal component transform. (a) Original shoeprint image. 
(b) The shoeprint image with its corresponding eigenvectors. (c) The transformed 
shoeprint image. 
(a) (b) (c) 
 
 
 
 
 
 
 
 
3.2 Feature Extraction 
The most obvious pattern in shoeprints is directionality. From simple line direction to complex 
geometric analogy, these drafts all represent a unique model of its own pattern. Therefore, a feature 
extraction method based on directionality is designed. To estimate the energy of each direction in the 
whole image, three different approaches are provided. The first one uses co-occurrence matrices to 
calculate the relation between pixels. The second uses a region based direction mask to compute the local 
ridge orientation for the entire image. The third takes global directionality, enhanced Fourier transform 
extends from normal Fourier transform is employed. Taking only global characteristics into consideration, 
however, might lose some local information. For the sake of this flaw, enhanced Fourier transform is also 
applied to local areas of the shoeprint to extract local information. 
3.2.1 Co-occurrence Matrices 
 Co-occurrence matrix, which was first introduced by Haralick in 1979 [11], is defined over an image 
to be the distribution value of co-occurring values at a given offset. Here we will introduce the definition 
of co-occurrence matrices and its characteristics for an image.  
 Let 
T  be an image of 2 color level (pure black and pure white) 
),( qpL  be the intensity value of pixel in image ),( qp T  
),( yxv ΔΔ=  be an offset vector 
The co-occurrence matrix  is the ),( jiCv 22×  matrix defined as follows: 
∑∑
= = ⎩⎨
⎧ =Δ+Δ+==
n
p
m
q
v otherwise
jyqxpLandiqpLif
jiC
1 1 ,0
),(),(,1
),( 　　　　　　　　　　　 (8) 
 
Then a point  in C  counts the number of pixel pairs in ),( ji T  that have respectively intensity i 
and j with displacement offset . v
 It can be seen that co-occurrence matrix collects the second-order statistics of image T  with the 
characteristics that the main diagonal of the matrix with offset  is as closer to the histogram of the 
image as  is related to the corresponding direction [12]. Based on this observation, we propose a 
measure as follows: 
v
v
 Let  
)(iH  be the histogram of the image, 255 ,0=i  
4 
TABLE 1 
The Energy Result of Directional Matrix 
Corresponding to the Image in Fig. 4 (a) 
 Angle (degree) 
 0∘ 15∘ 30∘ 45∘ 60∘ 75∘ 
Energy 1 0.373 0.078 0.314 0.039 0 
 Angle (degree) 
 90∘ 105∘ 120∘ 135∘ 150∘ 165∘ 
Energy 0.255 0.137 0 0.039 0 0 
 
 
3.2.3 Global Fourier Transform 
 Fourier Transform is an operator that maps a function to another function in terms of sin and cosine 
basis functions. More specifically, for an image, the Fourier Transform represents the image as a 
summation of various sine-like or cosine-like images. Due to the property of the Fourier Transform, it is 
widely employed for processing image to analyze the frequencies contained in an image. In this section, 
we first make use of the Fourier Transform to evaluate the strength of directionality over the image. Then, 
the masking operation is performed to remove the high-frequency and low-frequency noises. 
The Fourier Transform is given below: 
 Let f  be an image of size  mn×
),(),(),(
*
1),(
1 1
)(2
vuiIvuReyxf
mn
vuF
n
x
m
y
m
vy
n
uxj +=⋅= ∑∑
= =
+− π
         (13) 
Fourier spectrum is calculated as follows 
[ ]2122 ),(),(),( vuIvuRvuF +=                                 (14) 
After applying Fourier transform on the target image, we perform the Fourier transform on the 
Fourier spectrum again to get the enhanced Fourier Spectrum. The enhanced Fourier spectrum is more 
prominent than the original spectrum. It reinforces the peaks with the same periods and contributes to the 
same frequency while for those which are not periodic ones, they do not contribute to the same frequency 
[13]. 
This phenomenon relatively enhances those peaks and eliminates the non-periodic noises in an 
image. Low frequencies correspond to the slowly varying components of an image. For prints, these 
low-frequency components are of enormous spectrum value and might result in noisy information. To 
remove these needless components, a mask for removing low-frequency elements is applied. By masking, 
only frequencies that have Euclidean distance from the zero spatial-frequency point greater than the 
predefined threshold are preserved as candidate features. 
High-frequency components which occur owing to outsole scuffs and nicks of the shoe may result in 
outstanding values over the underlying shoeprint patter [7].  
Following the procedure, the enhanced Fourier spectrum image that goes through low-frequency and 
high-frequency masks is denoted by F’ of size nn× . Base on F’, we define a feature vector 
,1,1|),('{ njnijiFGF ≤≤≤≤=   is neither low-frequency nor high-frequency components}. ),( ji
3.2.4 Local Fourier Transform 
All three methods mentioned above take the full prints into consideration. Nevertheless, features 
extracted merely from the full image might lose details in local areas. To compensate this shortage, the 
local Fourier Transform based on the frequency domain is used. 
The processed shoeprint image is divided into 15 equal regions. Following that, Fourier transform is 
performed on each region twice to get the enhanced Fourier spectrum of the area.  
Low-frequency mask and High-frequency mask are also applied on each region k to get the masked 
Fourier spectrum . The remaining values, which are denoted by kF '
15 i ),(3/,...,15/,...,1,...,1|),('{ jimjnkjiFLF k 　====  is neither in high-frequency nor in 
6 
in response to a reference image. With higher performance, the result is expected to present fewer 
nonmatching shoeprint categories before a matching category. In view of this, “Average Match Score 
(AMS)“ is used to evaluate the performance of the results. 
The “Average Match Score” measures the average percentage of the database categories before a 
correct match is delivered. In our experiments, each shoe pattern contains 3 corresponding shoeprint 
images in the database which are gathered from an identical right shoe. Hence, the performance is 
determined by counting the number of nonmatching categories until hitting the correct one. Then, the 
process continues to find the second and the third category that correctly matches to the reference 
shoeprint image with their searching cost.  
Each feature vector is conducted independently first, and then combined together for further 
assessment. The best performance is the one with the combination of all proposed features vectors. While 
for getting all three matching shoeprints, 13.88% of shoeprint database images should be examined in 
average. Results of the proposed method for different feature vectors are shown in Table 2. From the table 
we can see that 1.29%, 4.71%, and 11.59% of shoeprint database images should be examined in average 
respectively before the 1st, the 2nd, and the 3rd correct matching with the feature vector of co-occurrence 
matrix. While taking all features into consideration, 0.38%, 1.19%, and 2.75% of the database images are 
examined in average before retrieving the 1st, the 2nd, and the 3rd correct shoeprint. The proposed method 
is much more accurate than the method provided in [7]. 
TABLE 2 
Average Match Scores (%) for the Proposed Method on 735 Shoeprint Images from 
105 Individual Shoes, Database of 315 Shoeprint Images with Different Features 
 
 
Features First Data Second Data Third Data Average 
Co-occurrence 1.29 4.71 11.59 5.86 
Direction 1.61 5.68 13.71 7 
Global Fourier 0.64 3.09 7.39 3.71 
Local Fourier 0.92 3.03 7.67 3.87 
All Features 0.38 1.19 2.75 1.44 
 
5. Conclusion 
The study proposed a novel method for automatically recognizing the shoeprint image using the 
properties of directionality. Firstly, a series of preprocessing processes are applied to eliminate distortions 
in the print including rotations, translations, and noises. Four feature extraction methods based on the 
directionality are then performed on the preprocessed image. In the end, a similarity measure using SAD 
is calculated in response to the reference image.  
Based on the algorithm, a system can be built to help forensic scientists seeking for the model of a 
shoe from a shoeprint image. Experiments designed for assessment of performance showed the accuracy 
and efficiency of the proposed method. It can accelerate human observer identifying the shoeprint pattern 
with respect to the reference image. However, shoeprints used in the study were obtained under human 
controlled circumstances, while those acquired at crime scene were of lower quality and of desperate 
distortions. These shoeprints were mostly partial prints and tough for matching. Improvements may be 
achieved by employing new de-noise methods in preprocessing and delicately designed the database 
images from acquired shoeprints. 
 
參考文獻 
[1] A. Girod, “Computer Classification of the Shoeprint of Burglar Soles,” Forensic Science Int’l, vol. 82, 
pp. 59‐65
8 
, 1996. 
[2] A. Girod, “Shoeprints - Coherent Exploitation and Management,” European Meeting for 
Shoe lmark Examiners, The Netherlands, 1997. print/Too
[3] W.J. Bodziak, “Footwear Impression Evidence Detection,” Recovery and Examination, 2nd ed. CRC 
10 
可供推廣之研發成果資料表 
□ 可申請專利  □ 可技術移轉                                      日期：99 年 9 月 27 日 
國科會補助計畫 
計畫名稱：以全域與區域圖形特徵進行鞋印影像搜尋與比對系統之
研究與建置 
計畫主持人：陳玲慧 教授 
計畫編號：NSC98-2221-E-009-159- 
學門領域：影像處理 
技術/創作名稱 鞋印影像搜尋與比對系統之研究與建置 
發明人/創作人 陳玲慧 
技術說明 
中文：在計畫中，我們提出了一個新的自動處理鞋印影像的方法。
鞋印是犯罪現場中十分常見之線索，其最主要的特徵便是其紋理的
方向性。論文中，我們利用影像之灰度伴隨矩陣(co-occurrence 
matrices)、方向矩陣 (directional matrix) 及傅立葉轉換 (Fourier 
transform)來截取出鞋印紋理之方向性特徵以做為比對的依據。由
於在前處理上使用主軸轉換(principal component transform)，本方法
並不會因為影像之旋轉或位移等失真造成錯誤的結果。實驗結果顯
示，本方法能夠有效的識別各式的鞋印。 
英文：We present a method for automatically classifying/recognizing 
the shoeprint images based on the outsole pattern. Shoeprints are 
distinctive patterns often found at crime scenes that can provide 
valuable forensic evidence. Directionality is the most obvious feature 
in these shoeprints. For extracting features corresponding to the 
directionality, co-occurrence matrices, Fourier transform, and a 
directional matrix are applied to the shoeprint image. And with the 
stage of principal component transform, the method is invariant to 
rotation and translation variance. Experiments of matching shoeprints 
are conducted on the database of 315 shoeprint images to demonstrate 
the performance of the method. 
可利用之產業 
及 
可開發之產品 
法庭科學、自動化鞋印影像比對。 
技術特點 
1. 新的自動處理鞋印影像的方法。 
2. 不會因為鞋印影像之旋轉或位移等失真造成錯誤的結果。 
3. 利用影像之灰度伴隨矩陣(co-occurrence matrices)、方向矩陣
(directional matrix)及傅立葉轉換(Fourier transform)來截取出鞋
印紋理之方向性特徵以做為比對的依據。 
推廣及運用的價值 本技術以一個新的自動處理鞋印影像的方法，能夠有效的識別各式的鞋印。 
※ 1.每項研發成果請填寫一式二份，一份隨成果報告送繳本會，一份送 貴單位研發成果
推廣單位（如技術移轉中心）。 
※ 2.本項研發成果若尚未申請專利，請勿揭露可申請專利之主要內容。 
※ 3.本表若不敷使用，請自行影印使用。 
98年度專題研究計畫研究成果彙整表 
計畫主持人：陳玲慧 計畫編號：98-2221-E-009-159- 
計畫名稱：以全域與區域圖形特徵進行鞋印影像搜尋與比對系統之研究與建置 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際
已達成數)
本計畫實
際貢獻百
分比 
單位 
備註（質化說明：如
數 個 計 畫 共 同 成
果、成果列為該期
刊之封面故事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 3 3 100%  
博士生 3 3 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 1 1 100% 
篇 
M. Q. Jing, W. J. Ho 
and L. H. Chen, 
2009, ＇＇A Novel 
Method for 
Shoeprints 
Recognition and 
Classification,＇＇ 
International 
conference on 
Machine Learning and 
Cybernetics 2009, 
Baoding China, 12-15 
July. 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
博士後研究員 0 0 100% 
人次 
 
 
