在演化硬體相關的研究領域中，可自
體適應環境而動態調整邏輯電路的可演化
式硬體(Evolvable Hardware)是目前最受到
矚目的研究議題。1992 年 Hugo de Garis[2]
首先提出演化硬體這項結合機械學習、人工
智慧與硬體設計高度整合的概念，隨即
Tetsuya Higuchi[3], John Koza[4]、Adrian 
Thompson[5,6]等學者陸續發展出演化硬體
的理論和方法。 
演化硬體主要的概念是將電路編碼成
為一種可藉由演化式計算來操作的基因編
碼，例如使用 Genetic Algorithm、Genetic 
Programming、Evolutionary Programming、
或 Evolutionary Strategy 等演化式演算法，
搜尋符合問題條件限制的最佳解電路，並動
態調整邏輯電路結構。 
在組合邏輯的數位電路設計領域，過
去常被使用的 Boolean Algebra、K-MAP、
Quine-McCluskey 等人工設計方式，在面對
大型的真值表問題時都無法有效的求得問
題解答。藉由演化式硬體設計技術，不僅可
以避免人工求解的失誤，更可以取代目前常
用的 heuristic 設計方式，透過演化式計算
流程更可以有效的得到相較於人工方法更
佳的解答，以達到自動化電路設計的目標。 
大多數學者所提出的演化硬體方法係
依循 Louis[7]所提出的邏輯最小化問題，針
對一個 n-inputs/m-outputs 的真值表，在此限
定的搜尋範疇內，以人工演化方式找出最精
簡的組合邏輯電路。 
從硬體演化程序的角度，演化硬體研
究範疇可以分成內部型(intrinsic)演化硬體
與外部型(extrinsic)演化硬體兩大類。 
內在演化硬體  
硬體本身具有一演化功能的控制器，可
自行重新組織、自體繁殖、自行針對環境
作適應性調整。Intrinsic 演化硬體在 1997
首先由英國 Sussex 大學的 Thompson [4]所
提出，該作者使用 Xilinx XC6216 FPGA 
chip 建立可自體演化電路，應用在識別兩
個分別是 1K 和 10K 的音頻訊號。2004 年
Gallagher 等人[8]將精簡遺傳演算法(cGA)
整合在一個神經網路控制晶片，應用於真
實程序控制，硬體演化主要目標是對晶片
進行線上(online)電路最佳化和性能調節。 
外在演化硬體 
使用軟體模擬以離線的方式使用演化
式計算得到電路最佳參數與電路結構後，
實現於 CPLD 或 FPGA 可重組之硬體設
備。此演化硬體議題著重於演化式計算，
Ceollo[9,10]在此領域使用多種演化式演算
法對於邏輯電路最小化問題求取最佳解。 
 
根據硬體演化的層次，演化硬體研究
範疇又可分為邏輯閘層次(gate-level)演化
硬體與功能層次(function-level)演化硬體兩
種類型： 
邏輯閘層次演化硬體 
將組合邏輯電路編碼成為可演化形
式，在此層級的演化目標以邏輯閘繞線為
主。此層級的演化硬體是目前大部分研究
者研究的方向，其中以 Miller[11]所提出的
邏輯閘層次 EHW 最為著名。Iwata 等人也
在[12]提出他們的邏輯閘層次的演化架構
和演化運算子。 
功能層次演化硬體 
使用已經預先建立的功能模組如加法
器、乘法器等將其編碼成為可演化形式。
再使用演化式演算法針對電路功能性進行
演化。Higuchi[3]是演化硬體研究領域貢獻
極大的學者，他所提出 Function-Level 演化
硬體平台[13]將演化往上提升至更高的層
級更能符合實際應用的需求。許多研究者
基於此一平台發展出重要的演化硬體應
用，例如演化低耗電電路[14]、演化 G-Hz
數位電路[15]、演化無損耗影像壓縮電路
[16]、以及演化乘法器模組電路[17]等。. 
目前大部分演化硬體設計相關研究大
部分都是採用 Louis[7]所提出的隨機電路
矩陣(random circuit matrix)數位電路編碼架
構作為其演化的平台。 
隨機電路矩陣是一個二維邏輯陣列的
電路描述結構，在此陣列中的基本單元 Si,j  
其中j 表示邏輯閘stage, i 表示每一層stage
 1
 
(a)元件位置與繞線關係的 graph 
1 2 3 1 2 3 4
1
2
3
1
2
3
4
0 0 0 1 0 0 0
0 0 0 0 1 0 0
0 0 0 0 1 0 0
0 0 0 0 0 1 0( )
0 0 0 0 0 1 0
0 0 0 0 0 0 1
0 0 0 0 0 0 0
c c c v v v v
c
c
c
vA G
v
v
v
⎡ ⎤⎢⎢⎢⎢= ⎢⎢ ⎥⎢ ⎥⎢⎢⎣
⎥⎥⎥⎥⎥
⎥⎥⎦
(b)adjacency 矩陣表示 
圖 1. 邏輯電路繞線資料模型 
在實際的應用中，對此矩陣中每個單元
aij ，當其為’0’時代表沒有edge，’1’ 代
表從i-column 的node到 j-row的node存
在一edge。 
 
1,      if ( , )  and ( ) ( )
0,     otherwise.ij
i j E stage i stage j
a
∈ >⎧= ⎨⎩
此外，ci 為incoming nodes，所以在矩陣
中這些columns不需要考慮，每一個起始點
vi 的nodes 只會有兩個edges 故每一個vi 
的column都只能存在兩個’1’s，此外edges 
也必須符合所有單元的輸入端都必須來自
前級的輸出端條件限制，例如:{v1,v3}其中
[stage(v1) = 2] < [stage(v3) = 3]中就是不合法
的edge。 
4. 基於可變拓樸結構的邏輯電路表示的演
化式演算法 
基於上述三個階段的工作，我們得以使
用可變拓樸結構的邏輯電路表示來作為演
化硬體編碼結構，接著將在此基礎上發展新
的演化式演算法。在我們所定義的架構中
input stage 與 output stage 並不需演化，需
要演化的部分為位於矩陣中間的組合邏輯
電路和繞線模型。 
我們將採用標準演化式演算法的遺傳
運算子，如天擇(selection)、交配(crossover)、
突變(mutation)等運算。但基於可變拓樸結
構的邏輯電路表示式的特殊性，我們將設計
4 種不同的突變： 
Element-Mutation 
在 後 置 式 字 串 S 中 每 一 個 
nonterminated(logic element)可突變成為其
他型式的邏輯閘，但不包含 input 與 output。 
Operator-Mutation 
在後置式字串 S 中每一個 terminated 可
突變成為其他型式。 
Position-Mutation 
在後置式字串 S 中每一個 symbol 可與
其他任何一個在字串中出現的 symbol 交換
其位置。 
Edge-Mutation 
在繞線(routing)模型G中每一個edge 
form vi 其outgoing destination 可突變成為
在G中其他的nodes。 
四、結果與討論 
本計畫最後設計和實作一個以 FPGA
為基礎的演化硬體實驗平台，用以驗證計畫
中所規劃的演化硬體方法論的可用性和實
際演化電路的性能評估。 
此一實驗平台採用 ALTERA 公司 
Cyclone 產品系列中的 EP1C12 FPGA 作為
核心晶片，由於該系列晶片採用 SRAM 製
程，可支援到 12,060 個 Logic Elements 與
234K 個 RAM bits。此外尚有 2 組 PLL 與
173 I/O Pins。 
一旦離線的硬體演化完成，生成的電路
可使用ALTERA的 ByteBlasterII（Download 
Cable）從電腦對 Cyclone Device 直接做 ISP
燒錄的動作，因此此一實驗平台將具有很大
的設計彈性和方便性。 
我們將以模組化的方式來進行實驗基
板設計，並保留最大限度的 IO 接腳和擴充
性，以利未來以串接方式連結多個模組來執
行高複雜度的大型邏輯系統的硬體演化。 
總結以上的研究方法和步驟，本研究所
提出的演化硬體設計流程如圖 2 所示。 
 3
Programming and Evolvable Machines, Vol. 1, 
No. 1, pp.8-35, 2000. 
[12]. M. Iwata, I. Kajitani, Y., N., Liu, Kajihara, 
and T. Higuchi,”‘Implementation of a 
gate-level evolvable hardware chip, in 
Evolvable systems: from biology to hardware”, 
Lect. Notes Comput. Sci., 2001, no.2210, pp. 
38–49.    
[13]. T. Higuchi, M. Iwata, D. Keymeulen, H. 
Sakanashi, H. Murakawa, I. Iajitani, E. 
Takahashi, K. Toda, M. Salami, N. Kajihara, 
and N. Oesu, “Real-world applications of 
analog and digital evolvable hardware” , IEEE 
Transactions on Evolutionary Computation., 
vol. 3, pp. 220–235, Sept. 1999. 
[14]. Takahashi, E.; Murakawa, M.; Kasai, Y.; 
Higuchi, T., “Power dissipation reductions 
with genetic algorithms”, Proceedings of 2003 
NASA/DoD Conference on Evolvable 
Hardware, pp.111 – 116, July 2003. 
[15]. Marston, N.; Takahasi, E.; Murakawa, M.; 
Kasai, Y.; Adachi, T.; Takasuka, K.; Higuchi, 
T.; “An evolutionary approach to GHz digital 
systems”, Proceedings of 2000 NASA/DoD 
Workshop on Evolvable Hardware, pp.125 – 
131, July 2000.  
[16]. Sakanashi, H.; Iwata, M.; Higuchi, T., 
“Evolvable hardware for lossless compression 
of very high resolution bi-level images”, IEE 
Proceedings of Computers and Digital 
Techniques, vol. 151, Issue. 4 , pp.277–286, 
July 2004.  
[17]. Homma, N.; Aoki, T.; Higuchi, T., 
“Multiplier block synthesis using evolutionary 
graph generation”, Proceedings 2004 
NASA/DoD Conference on Evolvable 
Hardware, pp.79 – 82, June 2004.               
[18]. Gudise, V.G.; Venayagamoorthy, 
G.K. ”Evolving digital circuits using particle 
swarm”, 2003. Proceedings of the 
International Joint Conference on Neural 
Networks, vol.1 , pp.468-472, 2003. 
 
 
 
 
 5
 2
“j” means the logic gate stage and “i” means the unit number in  
each stage. Each unit can represent one two-input type logic 
gate (there are 5 types of gates: AND, NOT, OR, XOR and 
WIRE). The inputs shown in every unit can randomly connect 
with any element outputs of previous stages. Besides, this study 
will have research constrained on feed-back free circuit setting. 
Logic circuit can be encoded with binary or integer approach 
by this structure for fixed-length chromosome and make the 
simplest way of logic combination search by evolutionary 
algorithm. 
In many published evolutionary hardware reference review, 
the research workers usually fill the problem condition and 
desire function in the given truth table. They will use 5 x 5 
random circuit matrix for search framework and many 
evolutionary algorithms to evaluate the solution. For example, 
vector evaluated genetic algorithm (VEGA), GA with an 
n-cardinality alphabet and a two-stage fitness function denote 
as NGA, multi-objective genetic algorithm (MOGA), particle 
swarm optimizer…etc. Those approaches are proved good for 
their experimental results. 
III. NEW  GENETIC REPRESENTATION OF DIGITAL CIRCUIT 
Evolutionary hardware design by random circuit matrix with 
evolutionary algorithm is one of the most popular design 
approaches. Analysis from feasibility of hardware design and 
availability of evolutionary algorithm after encoding, this 
structure should be regarded as the evolutionary hardware 
pattern. However, there is still some constraints on this pattern. 
For example, using random circuit matrix will increase 
complexity of space search. Furthermore, setting the specific 
size of matrix must rely on designers' experiences. For future 
possible variety application of this model, it may not be able to 
meet the requirement of huge search space even with highly 
effective evolutionary algorithm and the fastest hardware 
design capability. In order to solve this problem, this paper 
proposes a new approach that can transfer slicing structure to 
logic circuit structure and evolve by postfix representation 
encoding. 
A. Slicing structure and postfix expression 
Slicing tree is a kind of binary tree structure. This concept 
can transfer the tree structure to space structure. Therefore, 
many people use this approach to solve the problem of printed 
circuit board minimization. In this structure, all tree terminated 
nodes are members of operand denotes as π={1,2,3…n}, and all 
tree non-terminated nodes are members of operators, two kinds 
of operators c={*,+}. The approach that transfers tree structure 
to slicing floor plan uses infix traverse starting from the left 
node. Operator ‘*’ means the right node operand located on the 
left node right operand as shown in Fig 2(a). Operator ‘+’ 
means the right node operand located on the left node top 
operand as shown in Fig 2(b). This approach can transfer the 
complicated spatial relationship to binary tree structure as 
shown in Fig 2(c). 
Tree structure information system is usually stored by 
linking list with one dimensional memory structure. Binary tree 
is an exception of tree structure. It can be shown as three 
different expressions of infix, prefix and postfix. We use 
postfix expression in this paper for evolutionary algorithm to 
compute easily. For instance, the slicing tree shown in Fig 2(c) 
can be expressed by postfix string “12*3+45*+” for storing in 
one dimensional memory array and available to encode as 
chromosome for evolutionary algorithm. Besides, a legal 
postfix string should be corresponded with n operands and n-1 
operators in itself. 
B. Postfix grammar and digital circuit representation 
The proposed approach uses slicing structure and postfix 
representation to show the logic gate topology relationship. In 
order to comprehend the subsequently expressions easily, we 
 
Fig. 1. Random circuit matrix. 
TABLE I 
SYMBOLS AND GENETIC CODED INTEGERS FOR POSTFIX REPRESENTATION 
INDICATE LOGIC ELEMENTS IN DIGITAL CIRCUIT AND THEIR NODES 
CHARACTERISTIC 
Type Symbol Integer Input/output nodes
Input c 0 0/1 
Output z 1 1/0 
NOT i 2 1/1 
AND a 3 2/1 
OR o 4 2/1 
XOR x 5 2/1 
NAND d 6 2/1 
NOR n 7 2/1 
NXOR r 8 2/1 
 
1
2
1 2
+
 
(a) 12* (b) 12+ 
5
1
+
*+
* 43
2  
(c) 12*3+45*+ (d) xa*o+id*+ 
 
Fig. 2. Slicing tree and slicing floor plan. 
 
 4
example, in the formula of {v1, v3}, [stage(v1) = 2] < [stage(v3) 
= 3]is not a feasible edge. 
D. Genotype and phenotype 
Let D be a set to represent a digital circuit matrix with 
n-input, k logic elements and m-output, that is, 
{ }**D CSZ=  
A nonempty set C+ for n-input stage is given by { }1 | { }, { }n nC x y x c y− += ∈ ∈ + ⊂ ∑  
A nonempty set Z+ for m-output stage. { }1 | { }, { }m mZ x y x z y− += ∈ ∈ + ⊂ ∑  
A nonempty string S is a postfix expression for combinational 
logic circuit. The length l of D is 
2 1l D D T D M n m k= = + = + + −I I  
where D TI and D MI are two sets of terminated and 
non-terminated symbols in D, respectively. 
For those proposed approaches, D has been used as genotype 
chromosome matrix. The length of chromosome can be 
measured through quantity of input nodes, output nodes, and 
logic gates. Phenotype, shown as logic circuit routing, can be 
evolved through slicing floor plan and graph.  
IV. EVOLUTIONARY PROCEDURE AND OPERATORS 
In this paper, we use GA in evolutionary computing for 
solution of logic optimization. We will explain GA 
evolutionary operators: mutation, crossover and selection. 
Those are manipulated in our proposed representation and 
fitness function evaluation. 
A. Initialization 
The solution for evolutionary computing usually takes 
samples from solution space as initial group. We assume that P 
is a set of population. 
( ) ( ) ( ) ( ){ }1 1 2 2 3 3, , , , , ... ,n nP D G D G D G D G=  
For initializing the logic gates and space relationship, the 
input stage and output stage are not necessary to be evolved in 
the defined matrix, but the combination logic circuits in the 
middle of matrix that is so called postfix grammar description. 
S is regarded as chromosome here. 
{ }{ }2 1 **kinitialled i I i randomD  D CS Z−∈= ∀ = , 
 where k  is size of logic elements and I  is an index set. 
 
Initialize combination logic circuit routing:  
{ }( , )initialled i iG V E= , 
{ } { }, ,i i random i randomE v x v y= U  for each i I∈  
After initialization, group P shows as below:  
( , )initialled initialled initialledP D G=  
 
B. Mutation 
We divide four types for mutation computing as following: 
 
1) Element-mutation 
In string S={ s1, s2 ,s3 …sn }, each non-terminated(i.e., logic 
element)  can be mutated to other types of logic gates, but not 
including input and output. 
{ }, { , }is x    x T c z= ∈ − ,  
where i is selected mutation symbol index in string S. 
 
2) Operator-mutation 
In string S, each terminated can be mutated to other types as 
below:  
,is x   x M= ∈  
where i is selected mutation symbol index in string S. 
 
3) Position-mutation 
In string S, each symbol can change the position with any 
other symbol in other strings. 
( ),i jswap s s  
where i,j  is selected mutation symbols index in string S. 
 
4) Edge-mutation 
In G = (V,E), each edge form vi,the outgoing destination can 
be mutated to other nodes in G. 
{ } { }, ( ) , ( )i i iE v random m v random m= U  
where  m V∈  and i is selected mutation index in string S. 
 
C. Crossover 
Crossover computing is divided into two types in this paper. 
 
1) String-Crossover 
In String-Crossover, we use two-point for crossover 
computing. Generate two crossover points randomly, exchange 
all chromosomes form two parent chromosomes between the 
two corssover points and create two offspring. 
Suppose two random points a and b belong to I, for 
a b≤ where I is an index set of string S. Also, let two parents S 
and S’ with the same length n are defined by 
Digital Circuit
Mapping
Genotype Phenotype
Chromosome
Postfix String
Graph
 
c1c2c3++iao*+z** 
 
1.( i, c1), ( i, _ ) 
2.( a, c2), (a, c3) 
3.( o, i ), ( o, a ) 
4.( z, o ), ( z, _ ) 
 
Fig. 4. 
 6
3) Topology evolution:  
After functional evolution, the best individual of population 
which produced from pervious step has been achieved the goal 
of desired function. Nevertheless, the stage of circuit is 
probably not the shortest. In order to derive circuit with 
optimum performance from the evolved best individual, this 
step only evolves the topology of logic cells to obtain minimum 
stages of feasible circuit. 
V. EXPERIMENTAL RESULTS 
 
VI. CONCLUSION 
In this paper, we propose a new circuit description which can 
be genetic encoded with evolutionary computing, variable 
routing, and function block modification. Differently from 
currently used approaches in existing evolutionary design 
frameworks, this approach is evolved in extrinsic method with 
regard of the issue on logic circuit optimization. The 
experiment results show that it can have the same efficiency 
with the typical evolutionary hardware design best designed 
hardware. This circuit description can also be applied on 
extrinsic gate-level evolutionary circuit design.  
The further development of evolutionary hardware must 
create much more efficient and variable description to meet the 
different requirement of functional applications in the future. 
The genetic coding we have proposed in this paper uses the 
structures of binary slicing tree, postfix representation and 
graph theory. The slicing tree structure is more flexible than the 
typical matrix structure on nodes modification. Thus, this 
approach can also describe the digital circuit routing and 
topology, which will develop more flexibility and evolutionary 
function complexity on evolutionary hardware. 
The future development will be based on this description to 
take over other functional building block, such as full adder, 
multiplexer, multiplier…etc. by logic gate as the element on 
circuits. The evolutionary level is expected to upgrade on 
function-level. 
REFERENCES 
[1] J. von Neumann, (1966). In A. Burks (Ed.), The theory of 
self–reproducing automata. Urbana: University of Illinois Press.  
[2] H. de Garis, “Evolvable Hardware : Genetic Programming of a Darwin 
Machine,” in "Artificial Neural Nets and Genetic Algorithms, R.F. 
Albrecht, C.R. Reeves and N.C. Steele, (eds.), Springer Verlag, pp 
441-449, 1993. 
[3] M. Karnaugh, “A map method for synthesis of combinational logic 
circuit,” Transactions of the AIEE, Communications and Electronics, 
72,No.1, pp.593-599, 195 
[4] W. V. Quine, “A way to simplify truth function,” American Mathematical 
Monthly, 62, No.9, pp.627-631, 1955 
[5] E. J. McCluskey, “Minimization of Boolean function,” Bell System 
technical Journal, 35, No.5, pp.1417-1444, 1956 
[6] Sushil J. Louis and Gregory J. E. Rawlins, “Designer genetic algorithms: 
Genetic algorithms in structure design,” In Proceedings of the Fourth 
International Conference on Genetic Algorithms, pages 53–60. Morgan 
Kauffman, San Mateo, CA, 1991. 
GA and neural networks proves the possibility of 
combining these two techniques [3][4][5]. 
     Nevertheless, there exist several obstacles in 
combining GA and neural networks for applications 
[6][7]. First of all, the applied problem must be 
formalized into input-output mapping model of 
neural networks. The possible neural network 
architectures corresponding to this model constitute a 
constrained searching space. Before seeking for the 
optimal neural network architecture, it is important to 
elaborate the encoding method, then to decide the 
required precision of the solution. The higher the 
precision is, the longer the code will become so the 
space and the time needed for searching will be 
increased. On the contrary, if the precision is too low, 
the suitable solutions may probably be missed. 
Finally, it comes to choose or to design new genetic 
operators such as selection, crossover, mutation and 
other problem related genetic operators. 
     We propose a neural network design methodology 
based on evolutionary learning, as shown in Fig.1. 
This paper is divided into five sections. In section 2, 
we will elaborate neural network building blocks, 
which provide systematically the neural network 
design specifications. In section 3, we will firstly 
determine the neural network/genetic encoding 
mapping. Then, we will define the performance 
evaluation function of neural networks and elaborate 
the evolutionary searching procedures. The section 4 
demonstrates an experiment to compare the 
conventional approach and ours. A conclusion is 
given in the last section. 
 
 
Fig. 1 The evolutionary design methodology of neural network  
 
2   Elaboration of Neural Network Building 
Blocks 
In order to acquire a modular and hierarchical 
network architecture with which we can easily 
modify, extend or build more complex neural 
network architecture, we propose a processing 
element as primitive neuron model. The neural layer 
can be constructed by assembling several neurons. 
The multilayer neural network can be finally 
constructed through cascading several neural layers. 
The constructive approach facilitates to extract 
design specifications from building blocks. The 
biggest challenge of this task comes from the 
assurance of the independence of every building 
block and the consideration of a good communication 
interface between building blocks in order to 
facilitate the design and the synthesis of complex 
networks. 
     Fig. 2 shows a single neuron building block. 
When N incoming stimulating signals reached the 
neuron, they will be multiplied by N connection 
weights wi, i = 1, 2...N. The summation of the 
multiplication will be added up by a bias b and the 
result is obtained after the transfer function f( ). 
 
w
1
b
w
N
w
2
? f( , )α α
1 2
SN
.....
(a) (b)
NL
..... .....
NL
.....
...................
.....
NL
.....
NL NN
(c)
1 2 K
SN
SN
SN
1
2
L
.....
SN
SN
SN
1
2
L
.....
SN
SN
SN
1
2
L
1
1
1
2
2
2
K
K
K
SN
SN
SN
1
2
L
 Fig 2. Neural network building blocks. (a) neuron; (b) 
neural layer; (c) neural network. 
 
We define f( ) to be a parameterized transfer function: 
the individuals of the offspring generation differ 
largely from those of the parent generation. However, 
the exploration happens only in a limited region 
around individuals of the parent generation. 
3.2 Genetic encoding of neural networks 
There are different representations for encoding a 
multilayer neural network. For example, the binary 
coding can be used for representing the {-1, 1} binary 
connection weight, see Fig. 3. Fig. 4 shows the matrix 
coding which is capable to represent the network’s 
topology. 
 
 
Fig. 3. Binary coding of neural network 
 
 
Fig. 4 Matrix coding of neural network 
 
The real-value binary string is the most common 
genetic coding used in GA [9]. Therefore, we adopt it 
for neural network encoding. We enumerate design 
parameters of neural network in series and translate 
them into binary string according to the required 
precision, so we will get a binary encoded individual. 
     For a real-value parameter, the length of its binary 
string depends on the required precision. Assume a 
variable x whose value domain is [a, b]. If the 
required precision is T decimal places for x, it implies 
that x will have (b - a)×10T resolution ranges. Thus, 
The needed length of the binary string m can be 
obtained via the following formula : 
2m-1 < (b - a)×10T ≤ 2m-1                       (3) 
As for decoding the binary string into real-value, the 
formula is : 
x=a+decimal(binary_string)× b a
m
−
−2 1
           (4) 
Fig.5 demonstrates how a single neuron is encoded 
into a binary string. In this figure, each design 
parameter is encoded in four bits. The total length of 
the binary string is NSN=(N+3)?4, where N is the 
number of the single neuron weights. Regarding the 
single neuron with L layers, the total length of the 
binary string is NNL=L?NSN. As for a neural network 
with K layers, its total length of the binary string is 
NNN=K?NNL. 
 
?
SN
w
1
b
w
N
w
2
f( , )α α
1 2
α
1 α2
......1 0 1 1 1 0 0 1 1 1 1 0 0 0 0 1 1 0 1 0 1 0 1 0
w
1 w2 wN b
Encoding Decoding
 
Fig. 5. Encoding of a single neuron by a binary string 
3.3 Evolution process of neural networks 
The population is the object of GA process. From the 
viewpoint of the optimization, if the number of 
individuals constituting the population is large, it is 
favorable for finding the global optimum, but the 
convergent speed will therefore be diminished. Since 
our purpose is to find the optimal neural network 
architecture, we generate several neural networks to 
form a population and apply the genetic operators 
including selection, crossover and mutation in the 
population to search step by step the optimal neural 
network configuration. 
     We use a set of observed data {Ii, Oi, i = 1,2, ..., 
M}? where Ii is the feature vector, Oi is the 
associated observed output, M is the number of data 
records. Taking feature vectors for input and 
performance of these two approches. 
     Fisher's iris data is a set of experimental data 
widely used in the comparison of diverse recognition 
models. It has 150 records of data with three 
categories (each category contains 50 data). Each 
record of data possesses four feature values and an 
observed category. In our experiment, the observed 
category is transformed into three observed outputs. 
Category 1 corresponds to [1, 0, 0] ; category 2 
corresponds to [0, 1, 0] ; category 3 corresponds to [0, 
0, 1]. 
     The back-propagation network adopted is an 
ameliorated version of the back-propagation 
advanced by Minia and Williams [11]. They used the 
learning rate adaptation and momentum adaptation 
techniques to accelerate the convergence of the 
learning algorithms and to increase the precision. 
Since the back-propagation network takes sigmoid 
function for the neurons' transfer function, we must 
normalize the original data to [0, 1]. The result of the 
experiment is shown in table 1, where η : momentum , 
∆η : momentum change factor per learning cycle; α : 
learning rate, ∆α : learning rate change factor per 
learning cycle. 
 
Table 1. Back-propagation neural network training 
by iris data 
 
     We apply the automatic design procedures of the 
neural networks in the same experimental data. The 
result is shown in table 2. We adopt for every 
experiment pmut =0.01 and pcross=0.6 . 
 
Table 2. Automatic design of neural networks 
 
     The comparison between table 1 and table 2 
reveals that our method is much better than the 
conventional error back-propagation algorithm both 
for the executive efficiency and for the performance. 
5   Conclusion 
The evolutionary design methodology of multilayer 
feedforward neural networks is caracterized by the 
following virtues : 
 
- The neural network building blocks are of 
modular and hierarchical structure. It is rather 
easy to organize and to modify them. Moreover, 
the transformation between neural networks and 
genetic encoding is linear and reversible. We can 
thus extend this methodology to design neural 
networks with different topology like recurrent 
neural network, bi-directional associative 
memory, etc. 
 
- The single neuron uses adjustable transfer 
function instead of the classical fixed transfer 
function. In neural network, the transfer 
functions of neurons may be different from each 
other for this reason. Such kind of neural 
networks will be more suitable for non-linear 
modeling and the models obtained will be more 
precise than conventional neural networks. 
 
- The ?1 and?2 of the formula (1) are able to 
adjust the form and the scale of single neuron's 
transfer function. That's why the training data 
need not to go through the normalization process. 
In applications like simulation and prediction of 
dynamic systems, this architecture is obviously 
more appropriate than the conventional one. 
 
- In our design methodology, the evolutionary 
computing replaces the analytical learning 
algorithms. The search is carried out by parallel 
and multi-directional ways and is thus capable of 
escaping from local optimum to find the global 
optimum. 
 
- The length of genetic codes is variable, which 
means that the designer of neural networks can 
increase the number of bits according to the 
required precision. On the contrary, if the 
efficiency is considered to be an important factor, 
the number of bits is to be decreased. For 
hardware implementation of the neural networks, 
this functionality may be helpful in the 
optimization of performance/surface. 
 
References: 
[1] M. Rocha, P. Cortez, and J. Neves. Evolutionary 
Neural Network Learning. In F. Pires and S. 
Abreu, editors, Progress in Artificial Intelligence, 
EPIA 2003 Proceedings, LNAI 2902, pages 
24--28, Beja, Portugal, December 2003. Springer 
[2] Wong, F. & Tan C., "Hybrid Neural, Genetic and 
Fuzzy Systems," in Trading on the Edge 
