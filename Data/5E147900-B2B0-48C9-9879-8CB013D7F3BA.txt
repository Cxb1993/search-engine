be one of solution of VAD problem. In this project, the 
exponential radial basis function (ERBF) is selected as a 
kernel for SVM. By the use of above feature parameters 
extracted from the de-noised speeches, one can obtain a 
trained SVM to achieve accurate VAD under in-car noisy 
environment. Using speech signals data recorded in the real 
car environments, experimental results show that the 
proposed SVM-VAD algorithm obtains a better performance 
than that of ITU G.729B [1] and ETSI AMR [2]. 
The remainder of this project report is organized as follows. 
In Section 2, the detailed description of the wavelet de-
noising method is given. Then the speech feature extraction as 
well as SVM will be described in Sections 3 and 4, 
respectively. Section 5 illustrates experimental results and 
compares to other methods. Finally, conclusion is given in the 
last Section. 
II. WAVELET DE-NOISING METHOD 
One of the most popular schemes for wavelet-based de-
noising was proposed by Donoho and Johnstone [5]. This 
scheme is based on thresholding the wavelet coefficients of 
the noise-corrupted signal and can be easily applied to speech 
de-noising. It has been shown [9] that such a wavelet 
thresholding scheme has a better performance of speech de-
noising than those of traditional methods. Lets the noisy 
speech signal to be x(n) = s(n)+σg(n), n = 1, …, N, where s(n) 
represents clean speech signal. The g(n) are Gaussian random 
variables with zero mean and variance one and σ is a known 
noise level. Then the wavelet-based speech de-noising 
algorithm can be summarized in the following three steps: 
(a) Decompose the noisy speech signal into wavelet 
coefficients. 
(b) Employ a threshold method to the wavelet coefficients 
obtained in (a). 
(c) Synthesize these thresholded wavelet coefficients 
obtained in (b) to achieve the enhanced speech signal. 
In this project, the threshold selection procedure is based 
on SURE [6] and the soft shrinkage is used. The soft 
shrinkage is defined as 
⎪⎩
⎪⎨
⎧
<+
>−
≤
=
λλ
λλ
λ
δλ
jj
jj
j
j
ww
ww
w
w
,
,
||,0
)(                                          (1) 
where ),0[ ∞∈λ  is the threshold and wj is the wavelet 
coefficient of x(n) at level j. Let the estimators of s(n) be 
)}(ˆ,),2(ˆ),1(ˆ{ˆ Nsss L=s . The mean squared risk R of sˆ  is  
∑
=
−=
N
n
nsER
1
2))(ˆ(s .                                                      (2) 
Assume that the estimators sˆ  have the form  
))(()(ˆ nxHnx λ+=s ,                                                      (3) 
where λ is a threshold level and Hλ(•) is a differentiable real 
valued function for any fixed λ. Since the true values of s(n) 
are unknown, it is impossible to calculate R explicitly. Stein 
showed that Hλ(•) is weakly differentiable, then 
))((|)(2
)),(,(
2
)(
2
1
2 nxHxH
dx
d
nxRR
nxx
N
n
λλσσ
λσ
++=
=
=
=
∑                    (4) 
This is known as Steins unbiased risk estimate (SURE). 
The Stein principle is to minimize (4) with respect to λ and 
take the minimum as a data driven estimator of the optimal λ*, 
i.e., 
)),(,(min*
0
λσλ λ nxR≥= .                                                   (5) 
The wavelet transform used in this project is implemented 
via filter banks structure. A fast discrete algorithm proposed 
by Mallat [10]. Let )(~ nh  and )(~ ng  are the analysis low-pass 
and high-pass filters. In addition, the symbol ↓2 denotes the 
down-sampling by 2. Let { } Z3 )( ∈nna  be the input to the 
analysis filter bank. Then the outputs of the analysis filter 
bank are given by 
∑ +−=
n
ii naknhka )()2(
~)( 1                                          (6) 
∑ +−=
n
ii nakngkd )()2(~)( 1                                          (7) 
where )(kai  and )(kdi  are called the approximation and 
detail coefficients of the wavelet decomposition of )(1 nai+ , 
respectively.  
III. SPEECH FEATURE EXTRACTION 
In this project, three sub-band powers, zero-crossing rate 
(ZCR), and pitch frequency extracted from de-noised speech 
will be used as feature parameters for VAD. All of them are 
calculated at every frame. The frame length is 32 ms with 
50% (16 ms) overlap. The detailed feature extraction 
processes are described as follows. 
3.1. Pre-processing  
The pre-processing is implemented via a pre-emphasizing 
filter that is defined as 
1
' *96.0 −−= nnn sss  for n = 1, …., 255                          (8) 
where Sn is the n-th sample of the frame s. Then, the pre-
emphasized frame is Hamming-windowed by 
ii
h
i hss *
'=  for  i = 1, …., 255                                   (9) 
with )255/ 2cos(*46.054.0 ihi π−= .  
3.2. Subband Power jP  
Three sections of subband power calculated in wavelet 
domain, i.e., )(0 ka , )(0 kd , and )(1 kd  of a given speech 
signal )(3 ka , are used in this project. The subband power is 
calculated by  
∑=
k
jj kwP )(
2 ,                                                             (10) 
where )(kw j  is the corresponding approximation or detail 
coefficients at level j. 
3.3. Zero-Crossing Rate (ZCR) 
The ZCR of the frame ending at time instant m is defined 
by 
V. EXPERIMENTAL RESULTS 
This project selects 100 different sentences recorded with 
in-car noise from the Aurora database [12] for evaluating the 
VAD performances. In which 50 sentences are used for SVM 
training and the remaining 50 sentences are applied for VAD 
testing. The speech signals in Aurora database were sampled 
at 8000 Hz with 16-bit resolution. Each speech signal is 
divided into frames whose length is 256 samples (32ms) with 
128 samples (50%) overlap between adjacent frames. The 
software simulations were performed using Matlab® 7.0 on a 
Pentium® IV 2.0GHz, Windows® XP PC. 
5.1. On the Choice of Wavelet Functions 
Table 1. Wavelet-based Denoising Results Using Different 
Wavelet functions 
MSE under different SNR Wavelet 20 15 10 5 0 
Db6 0.1292 0.1532 0.1956 0.3662 0.4892
Db8 0.0940 0.1016 0.1234 0.2916 0.4634
Sym6 0.1325 0.1647 0.2151 0.4972 0.6425
Sym8 0.1097 0.1083 0.1726 0.4017 0.6581
Coif6 0.1107 0.1104 0.1856 0.4602 0.7051
Coif12 0.0897 0.0983 0.2055 0.4332 0.0604
The orthogonal wavelet functions including Daubechies 
(Db), Coiflets (Coif), and Symlets (Sym) [13] are considered 
in the project. In order to select an appropriate wavelet 
function for the wavelet denoising method, a test experiment 
is given and its results are listed in Table 1. This test 
experiment was done using 100 test speech signals corrupted 
by different Gaussian white noises. The mean square error 
(MSE) used in Table 1 us defined as  
∑
=
−′=
N
n
nxnx
N 1
2))()((1MSE                                 (12) 
where x′(n) is the de-noised speech. It follows from Table 1 
that the Daubechies wavelet with length of 8 (Db8), which 
has the minimum MSE, is recommended for the wavelet-
denoising method as well as speech feature extraction.  
5.2. VAD Correction  
Due to the soft-margin SVM allows some errors during 
classification, some voice frames may be classified into non-
voice frames, and vice versa. Hence, this project proposes a 
VAD correction algorithm to overcome this problem. A 
recognizable speech signal has at least length of 300 ms; 
therefore, a voice sentence should has 20 successive frames. 
This characteristic can be used as correction criteria of the 
proposed VAD correction algorithm. If successive non-voice 
frames contain less than 20 successive voice frames, these 
voice frames will be corrected as non-voice ones. Similarly, if 
successive voice frames contain less than 20 successive non-
voice frames, these non-voice frames will be corrected as 
voice ones. Figure 3 is an example of the proposed VAD 
correction algorithm. 
 
Voice frame
Non-voice frame
Non-voice frame
Non-voice frame
Non-voice frame
· · · · · · · ·
· · · · · · · ·
Non-voice frameCorrect
Successive non-voice frames
Successive non-voice frames
(a)
Non-voice frame
Voice frame
Voice frame
Voice frame
Voice frame
· · · · · · · ·
· · · · · · · ·
Voice frameCorrect
Successive voice frames
Successive voice frames
(b)
Figure 3. An example of the proposed VAD correction 
algorithm. (a) Voice frames correct to non-voice frames. (b) 
Non-voice frames correct to voice frames. 
5.3. VAD Performances under Car Noisy Environments  
In this project, the probabilities of detection Pd and false-
alarm Pf are utilized to evaluate the VAD performances. To 
obtain Pd and Pf, the active and inactive regions of the clean 
speech signals are first marked manually. Pd is calculated as 
the percentage of test cases when the hand-marked speech 
regions are correctly detected by the VAD algorithm while Pf 
is the percentage of test cases when hand-marked noise 
regions are erroneously identified as speech. Using three 
types of noise with different SNRs, the Pd and the Pf of the 
proposed SVM-VAD algorithm are compared with those of 
the VAD Option 1 of AMR-NB codec [1] and ITU G.729B 
VAD [4]. The experimental results are summarized in Table 2. 
From Table 2, one observes the proposed VAD scheme 
presents a good alternative to these standardized algorithms. 
Table 2. Pd’s(%) and Pf’s(%) of the proposed VAD, AMR, 
and G.729B VAD under various noisy environments 
Noise SVM-VAD AMR VAD G.729B VAD
SNR Pd Pf Pd Pf Pd Pf 
20dB 99.32 6.98 98.46 20.01 97.25 42.67
15dB 98.62 7.35 97.45 21.32 98.32 45.63
10dB 97.78 8.22 96.20 39.87 98.63 45.87
5dB 96.28 8.93 94.78 54.53 98.78 46.82
0dB 91.63 9.35 94.08 54.32 98.62 47.72
VI. CONCLUSION 
A new VAD algorithm using wavelet and SVM for in-car 
environment has been presented in this project. By the use of 
wavelet de-noising method, the in-car background noise in 
the input speech can be reduced before feature extraction. 
Then the SVM with ERBF kernel can be used to train an 
optimized non-linear decision rule involving the subband 
powers, ZCR, and pitch frequency of the de-noised input 
speech. It is shown that the proposed SVM-VAD can achieve 
  
出席國際學術會議心得報告 
計畫編號 NSC 95-2221-E-366 -014 
計畫名稱 應用支稱向量機與小波轉換於車內環境中的語音活動偵測研究
出國人員姓名 
服務機關及職稱 
陳璽煌 
樹德科技大學 資工系 助理教授 
會議時間地點 96年6月27日~ 96年6月29日，日本(Japan)京都(Kyoto) 
會議名稱 The 20th International Conference on Industrial, Engineering & 
Other Applications of Applied Intelligent Systems (IEA/AIE 2007) 
發表論文題目 An Improved Voice Activity Detection Algorithm for GSM 
Adaptive Multi-Rate Speech Codec Based on Wavelet and Support 
Vector Machine 
 
一、參加會議經過： 
第20屆國際工業、工程、及應用智慧系統研討會 (The 20th International 
Conference on Industrial, Engineering & Other Applications of Applied Intelligent 
Systems, IEA/AIE 2007)從6月26日到6月29日在日本京都大學(Kyoto University)鐘
樓廳(Clock Tower Hall)舉行，IEA/AIE會議是由International Society of Applied 
Intelligence (ISAI)所舉辦，每年均會定期公開徵求論文，本屆IEA/AIE 2007收到來
自全球各地研究專家學者所投稿的462篇論文，最後獲選列入議程的論文共有116
篇，論文接受率僅有25.1%，算是水準相當高的研討會。個人投稿論文的題目為：
An Improved Voice Activity Detection Algorithm for GSM Adaptive Multi-Rate Speech 
Codec Based on Wavelet and Support Vector Machine，論文發表的場次屬於Speech分
項，排在第三天早上第二場第二位講者。由於該場次僅安排三位講者，每位講者
可有25分鐘的時間來發表論文，時間可說是相當充裕，因此在沒有時間壓力的情
況下，我把論文研究成果仔細地介紹給與會人員，會議主席，同時也是大會主席
Prof. Hiroshi G. Okuno(奥乃 博 教授)當場題問兩個議題，還好我都能當面回答。
會後還有日本Honda公司機器人部門的學者找我討論關於自動聲音偵測的研究，感
覺十分不錯。之後，個人還觀摩了其他場次的論文發表，與廠商產品簡介，作為
教學及未來研究方向的參考。 
 
二、與會心得： 
個人從本次研討會中獲得不少Speech Classification、Speech Recognition, 
Digital Watermarking等相關主題的最新研究成果，並且與來自日本、中國的研究學
者面對面交換學術意見，這些資料可作為日後研究方向的改進參考。本次會議主
辦地點是在日本京都大學的鐘樓，該鐘樓建於1925年，是京都大學最具特色的建
築，雖然至今已有80餘年的歷史，不過整棟建築維護得十分良好，是京都大學用
來舉辦各類會議的重要場所；事實上，京都大學本身也有百餘年的建校歷史，整
H.G. Okuno and M. Ali (Eds.): IEA/AIE 2007, LNAI 4570, pp. 915–924, 2007. 
© Springer-Verlag Berlin Heidelberg 2007 
An Improved Voice Activity Detection Algorithm for 
GSM Adaptive Multi-Rate Speech Codec Based on 
Wavelet and Support Vector Machine 
Shi-Huang Chen1, Yaotsu Chang2, and T.K. Truong2 
1
 Department of Computer Science and Information Engineering, Shu-Te University,  
Kaohsiung County, 824, Taiwan, R.O.C 
shchen@mail.stu.edu.tw 
2
 Department of Information Engineering, I-Shou University, 
Kaohsiung County, 840, Taiwan, R.O.C 
ytchang@isu.edu.tw, truong@isu.edu.tw 
Abstract. This paper proposes an improved voice activity detection (VAD) 
algorithm for controlling discontinuous transmission (DTX) of the GSM 
adaptive multi-rate (AMR) speech codec. First, based on the wavelet transform, 
the original IIR filter bank and the open-loop pitch detector are implemented 
via the wavelet filter bank and the wavelet-based pitch detection algorithm, 
respectively. The proposed wavelet filter bank divides the input speech signal 
into 9 frequency bands so that the signal level at each sub-band can be 
calculated. In addition, the background noise can be estimated in each sub-band 
by using the wavelet de-noising method. The wavelet filter bank is also derived 
to detect correlated complex signals like music. Then one can apply support 
vector machine (SVM) to train an optimized non-linear VAD decision rule 
involving the sub-band power, noise level, pitch period, tone flag, and complex 
signals warning flag of input speech signals. By the use of the trained SVM, the 
proposed VAD algorithm can produce more accurate detection results. Various 
experimental results carried out from the Aurora speech database show that the 
proposed algorithm gives considerable VAD performances superior to the AMR 
VAD Option 1 and comparable with the AMR VAD Option 2. 
Keywords: GSM AMR, VAD, Wavelet, Support Vector Machine. 
1   Introduction 
Voice activity detection (VAD) that can detect voice and non-voice periods in speech 
signal is an important process in improving the channel capacity for voice 
communication systems. For example, the GSM adaptive multi-rate (AMR) speech 
codec makes use of a VAD module to control the discontinuous transmission (DTX) 
and to reduce power consumption [1]. VAD is also useful in other applications such 
as speech recognition [2] and speech enhancement [3]. Various types of different 
approaches to VAD have been proposed and most of the conventional VAD 
algorithms are accomplished by applying several parameters extracted from the input 
speech signal to compare with the predetermined thresholds. If the measured 
 An Improved Voice Activity Detection Algorithm for GSM 917 
diagrams of the VAD Option 1 and Option 2 are shown in Figs. 1 and 2, respectively. 
For simplification, this paper focuses on the VAD Option 1. For more information, 
see [1]. 
Filter bank
and
computation
of sub-band
levels
VAD
decision
Pitch
detection
Tone
detection
T_op[n]
t0,t1
VAD_flag
level[n]
pitch
tone
s(i)
Complex
signal
analysis
OL-LTP
correlation
vector
complex_warning
complex_timer
 
Fig. 1. Block diagram of the VAD algorithm: Option 1 [1] 
Frequency
Domain
Conversion
shp(n)
Channel
Energy
Estimator
G(k)
Channel
SNR
Estimator
Spectral
Deviation
Estimator
Peak-to-
Average
Ratio
Ech(m)
Background
Noise
Estimator
En(m)
Voice
Metric
Calculation
{ q }
Voice
Metric
Calculation
update_flag
VAD
fupdate_flag
Etn(m) v(m)
VAD_flag
decision
Etot(m)
Etot(m), )(mEdB
 
Fig. 2. Block diagram of the VAD algorithm: Option 2 [1] 
 
 An Improved Voice Activity Detection Algorithm for GSM 919 
The VAD decision function estimates background noise levels. Intermediate VAD 
decision is calculated based on the comparison of the background noise estimate and 
levels of the input frame. That is, 
[ ]
[ ]∑
=
=
9
1
2)
_
,0.1(_
n nestbckr
nlevelMAXsumsnr
 
(1) 
In (1), the background noise estimate (bckr_est[n]) is updated using amplitude levels 
of the previous frame. The noise estimate is updated as follows: 
[ ] [ ] [ ]nlevelalphanestbckralphanestbckr mmm 11 *_*)0.1(_ −+ +−=
 
(2) 
where m is index of the frame. The VAD decision is made by comparing the variable 
snr_sum to a threshold. The threshold is tuned to get desired sensitivity at each 
background noise level. The higher the noise level the lower is the threshold. Finally, 
the VAD flag is calculated by adding hangover to the intermediate VAD decision. 
The hangover addition improves detection of low power endings of speech bursts, 
which are subjectively important but difficult to detect. 
3   Wavelet-Based Speech Features Extraction for VAD 
In this paper, the speech features used for VAD are the same as those of VAD Option 
1. The main modification is that the signal level, pitch flag, tone flag, and complex 
warning flag are calculated via wavelet transform.  
3.1   Wavelet Filter Bank and Sub-band Signal Level 
The wavelet transform mentioned here is implemented via filter bank structure, i.e., 
the fast discrete algorithm proposed by Mallat [8]. Fig. 4 is the basic structure of 
wavelet analysis filter bank where h(n) and g(n) are the analysis low-pass and high-
pass filters, respectively. Also, the symbol ↓2 denotes the downsampling by 2. Let 
aj+1(m) be the input to the analysis filter bank. Then the outputs of the analysis filter 
bank are given by 
a k h m k a mj j
m
( ) ( ) ( )= − +∑ 2 1  (3) 
d k g m k a mj j
m
( ) ( ) ( )= − +∑ 2 1  (4) 
where aj(k) and dj(k) are called the approximation and detail coefficients of the 
wavelet decomposition of aj+1(m), respectively. 
aj+1
g(-n) 2
h(-n) 2
dj
aj
 
Fig. 4. The basic wavelet analysis filter bank 
 An Improved Voice Activity Detection Algorithm for GSM 921 
(a) Decompose the noisy speech signal into wavelet coefficients. 
(b) Employ a threshold method to the wavelet coefficients obtained in (a). 
(c) Synthesize these thresholded wavelet coefficients obtained in (b) to achieve the 
enhanced speech signal. 
In this paper, the threshold selection procedure is based on SURE [7] and the soft 
shrinkage is used. Let x(n) and y(n) be the original and the de-noised speech signals, 
respectively. Then the background noise can be estimated via calculating the energy 
of {x(n) − y(n)}, namely the different between the original and the de-noised speech 
signals. 
4   Support Vector Machine 
It is well known that SVM use a known kernel function to define a hyperplane in 
order to separate given points into two predefined classes. An improved SVM called 
soft-margin SVM can tolerate minor misclassifications [5] and use in this paper. 
1+
1+
1+
1+
1+1+
1−
1−
1−
1−
1−
)1(−φ
)1(−φ
)1(−φ
)1(−φ
)1(−φ
)1(+φ )1(+φ
)1(+φ
)1(+φ
)1(+φ
)1(+φ
φ
X F
 
Fig. 5. A feature map simplifies the classification task 
Let ni RXx ⊆∈  and }1,1{ −=∈Yyi  be the input vector and the target variable, 
respectively, where Rn denotes the n-dimensional real space. Suppose a training set 
ll
ill YXyxyxS )()},(,),,{( 111 ×⊆= ="  and a kernel function >=< )(),(),( jiji xxxxK φφ  
on XX ×  is given, where >⋅⋅< ,  denotes the inner product and φ maps the input space 
X  to another high dimensional feature space F. With suitably chosen φ, the given 
nonlinearly separable samples S may be linearly separated in F, as shown in Fig. 5.  
Many hyperplanes can achieve the above separation purpose but the SVM used in 
this paper is to find the one that maximizes the margin (the minimal distance from the 
hyperplane to each points). The soft-margin SVM, which includes slack variables 
0≥iξ , is proposed to solve non-separable problems. The slack variables 
)),(,0max( bxwy iii +><−= γξ , shown in Fig. 6, measure the amount by which the 
training set fails to have margin γ, and take into account any misclassification of the 
training data. Consequently, the training process tolerates some points misclassified 
 An Improved Voice Activity Detection Algorithm for GSM 923 
Table 1. Pd’s(%) and Pf’s(%) of the proposed VAD, AMR Option 1 and Option 2 VAD under 
various noisy environments 
Proposed VAD 
Noise Train station Street Car 
SNR Pd Pf Pd Pf Pd Pf 
Clear 99.61 5.86 -- -- -- -- 
20dB 98.43 6.17 99.15 8.24 98.83 7.83 
15dB 98.13 7.81 98.97 8.48 98.24 8.51 
10dB 97.78 8.48 98.14 8.94 97.54 8.82 
5dB 97.23 9.48 97.38 9.09 95.62 9.31 
0dB 96.12 9.87 94.32 9.36 90.71 9.73 
AMR VAD Option 1 
Noise Train station Street Car 
SNR Pd Pf Pd Pf Pd Pf 
Clear 99.44 11.42 -- -- -- -- 
20dB 99.30 16.82   98.18 26.44 98.46 20.01 
15dB 98.66 25.24   98.28 31.76 97.45 21.32 
10dB 97.84 32.14   96.84 33.25 96.20 39.87 
5dB 96.13 45.34   95.82 40.87 94.78 54.53 
0dB 93.72 57.47   94.42 49.15 94.08 54.32 
AMR VAD Option 2 
Noise Train station Street Car 
SNR Pd Pf Pd Pf Pd Pf 
Clear 99.76 11.32 -- -- -- -- 
20dB 88.37 19.69 78.74 19.36 83.96 22.18 
15dB 84.37 20.02 82.78 18.72 86.42 23.29 
10dB 90.93 22.56 88.73 19.18 93.58 25.18 
5dB 96.79 30.45 94.96 27.27 95.69 30.35 
0dB 96.39 39.57 98.46 40.37 98.09 41.42 
 
From Table 1, one observes that although the probabilities of detection Pd of AMR 
VAD Option 1 and Option 2 are fine, their probabilities of false-alarm Pf are 
somewhat unsatisfied. This means that most noisy sounds have been classified as 
speech frames using AMR VAD Option 1 and Option 2. The proposed VAD scheme 
provides a good alternative to these standardized algorithms. In addition to the well 
average probabilities of detection, the proposed VAD scheme has lower probabilities 
of false-alarm Pf than all the mentioned standardized algorithms over a variety of 
noise environments. 
6   Conclusion 
An improved VAD algorithm based on the wavelets and SVMs is proposed in this 
paper. By the use of wavelet transform, the signal level at each sub-band can be 
calculated. In addition, the background noise can be estimated in each sub-band via 
