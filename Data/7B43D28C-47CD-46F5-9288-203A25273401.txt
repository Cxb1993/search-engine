 2 
mobile agent technology. If grid nodes failed, necessary software components were transferred to other 
locations through mobile agent or other mechanisms. Applications were then reconfigured there to provide 
uninterrupted services. Part of system-level components that failed was also corrected by this mechanism. 
Finally, grid node that crashed was dynamically deleted. User tasks specified with fault-tolerant sign would be 
processed correctly. 
 
 
4. System Framework 
 
The Internet comprises many autonomous network management units, e.g., enterprise’s intranets and 
campus networks. In our proposed scheme, each network management unit employs a FGIDS as its security 
system. An overview of FGIDS is shown in Figure 1. A switch that has mirror port is placed on the link 
connecting a subnet to router to collect the subnet’s inbound packets. Traffic coming from the mirror port is 
conducted to detect attacks [2, 4]. 
FGIDS, as shown in Figure 2, consists of dispatchers, scheduler, detectors, backup broker and block list 
database. Dispatcher receives packets from a switch’s mirror port and predicts possible traffic volume for the 
next second. A detector detects DoS, DDoS and logical attacks, and gathers its own feature information, such 
as CPU level, available CPU capability, memory size, available memory capacity, detection capability which 
represents the average packets the detector is able to detect in one second, number of undetected packets, etc. 
Some of the features are dynamic, e.g., available CPU capability, available memory capacity, number of 
undetected packets and detection capability, that change with system load, whereas others are static. 
Scheduler calculates feature scores for each detector as its current capability. Backup broker backups 
network traffic for future re-detection when a detector is unable to continue its detection. Block list database is 
a database holding definite intrusion information. 
 
Internet
: Server or PC
Dispatcher
Dispatcher
Dispatcher
Router
Firewall Firewall
F irewall
FGIDS
Switch
SwitchSwitch
Subnet A
Subnet C
Subnet B
network 
management unit
 
 
Figure 1 Overview of FGIDS [2, 4] 
 
 4 
Table 2 The number-of-undetected-packets score table 
Number of undetected packets, X Scores 
000,16³X  1 
000,16000,12 <£ X  2 
000,12000,8 <£ X  3 
000,8000,4 <£ X  4 
000,4<X  5 
 
4.3 Detector 
A detector consists of performance agent and IDSM (intrusion detection subsystem module). The former 
requests detector’s current feature status. The latter, which is in charge of packet preprocessing, detection, 
intrusion notification, consists of head processor, logical detector, flood detector, heap tables and intruder 
analyzer [4]. 
Header processor retrieves serveal fields from an IP packet header and passes the field values to logical 
detector and flood detector to respectively detect logical and DoS/DDoS attacks. A heap table, recording packet 
statistics from which intruder analyzer can identify intruder[4]. A heap table, created for a host, e.g., hostj, in 
underlying subnet, has seven attributes, including SIP, protocol, type, count, size, temporary_count and 
temporary_size respectively representing source IP addresses of those packets sent to hostj, communication 
protocol, packet type (e.g., syn or icmp request), packet count, accumulated packet size of a source IP, 
temporary packet count and temporary accumulated packet size.  
When completely receiving a detection subunit, flood detector updates the two fields count and size for the 
records, that have been modified, with formulas (2) and (3) respectively and finally resets the two fields 
temporary_count and temporary_size to zeros. 
count = count + temporary_count              (2) 
size = size + temporary_size                  (3) 
 
4.3.1 Normal Operation. The algorithm that scheduler uses to allocate detectors to dispatchers is as follows. 
Algorithm: Scheduler allocates detectors to dispatchers 
Input: STSC={TSC1, TSC2,…, TSCn} and STV={TV(1)t+1, TV(2)t+1,…, TV(m)t+1}; 
Output: Each detection unit is assigned to a detector. 
Begin: 
1. Let TSCj=max(TSC1, TSC2,…, TSCn); 
2. Let Di be the Dispatcher with max(TV(1)t+1, TV(2)t+1,…, TV(m)t+1 ); 
3. Notifies Di to transmit its detection unit to detector j and backup broker; 
4. Delete TV(i)i+1 from TV and reevaluate TSCj; 
5. If (all detection units are assigned to detectors) then stop, otherwise go to step 1; 
End. 
On the other hand, each time a detection subunit is sent from a dispatcher to a detector and backup broker, 
a checkpoint, which is a timestamp representing that the last packet of this subunit has been delivered. A 
detector holds packets with a queue in which it sequentially detects malicious behaviors. After completely 
collecting a detection subunit, the detector deletes the subunit and transmits the checkpoint C that follows to 
backup broker which will mark the subunit as a detection commitment. Leu et al. [4] depicted that a DoS/DDoS 
attack could be detected within one second. Therefore, after finishing detecting a detection unit, the detector 
deletes the corresponding heap table to release memory space and sends an EOT (End of Traffic) to backup 
broker. 
The performance agent of an detector, e.g., detector k, collects its own detection capability and number of 
undetected packets once per second and delivers them to scheduler to recalculate TSCk immediately so as to 
accurately reflect the detector’s current capability, k = 1,2,3,…,n since the size of a detection unit is often not 
completely equal, only approximates, to the predicted volume, e.g., TVt+1(l), if the detection unit is sent from 
dispatcher l. 
 
4.3.2 A Newly joined Detector. When a node Z joins FGIDS as a detector, scheduler transmits two test files to 
Z to obtain its detection-capability performance curve. The first one, containing 16,455 attack packets, are 4 
MB in length and transmitted to the detector within 3~4 seconds. The second consists of 16,455 unattack 
packets which are 3.6 MB in size and delivered within 30 seconds. Scheduler connects to Z, once when per 
1,000 packets are transmitted, to observe the relationship between its detection demand time and current size of 
unfinished task or tasks. Figure 3 illustrates an example of a detection-capability performance curve, which can 
be in turn expressed by 
 6 
(3) heap tables Hs from detector i, it save Hs. 
(4) a message (T-H, k, i, j) from scheduler, it transmits the following items to detector j. 
(A) uncommitted packets and their checkpoints recorded in backup table k; 
(B) undetected packets including those of unfinished and undetected task or tasks also in backup table k; 
(C) detector i’s heap tables Hs; 
(5) a message (T, k, i, j), it unmarks all marked checkpoints and delivers all the packets backuped in table k, 
including detected and undetected packets and checkpoints of underlying detection unit, e.g., detection unit 
p and undetected task or tasks, to detector j which will generate new heap tables to re-calculate detector i’s 
packet statistics. 
 
 
4.5 Block List Database 
Block list database lists the definite intrusion information, including the time an attack is discovered, 
intruder IP, victim IP, attack protocol and attack type. All detectors can access block list database to avoid 
having anyone repeatedly detecting packets issued by a known intruder so as to hugely save detection resources. 
Router or firewall can accordingly follow the block list to discard packets[2, 4]. 
 
5. Experimental Results 
 
The test-bed of our experiments comprises resources of Tunghai University. We use two dispatchers to 
gather traffic from two subnets and deploy eight detectors as shown in Table 3 to detect attacks. All detectors 
run some version of Fedora operating system and globus toolkit 3.2. Detection programs are written with Java 
language and connected to MySQL.  
 
Table 3 The detectors’ specifications 
     Attributes 
Node Processor Frequency (MHz) Memory (MB) 
Detector 1 Pentium IV 1,816.739 256 
Detector 2 Pentium IV 1,514.253 256 
Detector 3 Pentium III 797.712 256 
Detector 4 Pentium III 598.664 256 
Detector 5 Pentium IV 1,816.609 512 
Detector 6 Pentium IV 1,816.809 1024 
Detector 7 Pentium III 599.231 512 
Detector 8 Pentium III 597.448 256 
 
We tested the following security systems: Snort, Kaspersky Anti-Hacker 1.5 (Kaspersky in short), McAfee 
VirusScan Home Edition 7.0 (McAfee VirusScan in short), Panda Titanium Antivirus 2005 (Panda Titanium in 
short) and FGIDS. 
DoS/DDoS attacks can be classified into two types: bandwidth consumption, e.g., udp flood, and resource 
consumption, e.g., icmp flood. Intrusion tools were invoked to launch DoS/DDoS bandwidth and resource 
consumption attacks. Table 4 lists the details where “ANP/sec” in the field packet intensity, standing for the 
average number of launched packets per second, represents different attack intensities. Each of udp, tcp syn and 
icmp floods was performed separately ten times, and each time lasted ten seconds in order to effectively and 
consistently compare the systems mentioned. 
 
Table 4 Information about attacks 
 
Attack type 
Attack period Packet intensity 
(ANP/sec) 
tcp syn 
flood 9,160 Resource 
consumption attack icmp 
flood 705 
Bandwidth 
consumption attack 
 
upd flood 
10 seconds 
704 
 
Table 5 lists the detection results of a resource consumption attack of tcp syn flood at 9,160 ANP/sec. Let k 
(k ≤ 8) be the number of detectors really deployed to detect attacks. The items considered included: (1) average 
response time (ART) of the k detectors where response time is the time period from the beginning of the attack 
to the time the attack is discovered; (2) average blocking response time (ABRT) of the k detectors where 
blocking response time is the time period from the moment the attack is discovered to the time point an attack 
packet is firstly blocked; (3) average turnaround time (ATT) of the k detectors where turnaround time is the 
 8 
Table 8 Detection accuracy of resource/bandwidth consumption attacks  
 
Statistics 
Secu. systems True positive True negative False positive False negative Detection accuracy 
Snort 89.5% 95.2% 10.5% 4.8% 92.35% 
Kaspersky 99.2% 100% 0.8% 0% 99.60% 
McAfee VirusScan 89.5% 100% 10.5% 0% 94.75% 
Panda Titanium 87.7% 100% 12.3% 0% 93.85% 
FGIDS 99.3% 100% 0.7% 0% 99.65% 
 
Table 9 Detection accuracy of logical attacks 
 
Statistics 
Secu. systems True positive True negative False positive False negative 
Detection accuracy 
Snort 95.6% 94.4% 4.4% 5.6% 95% 
Kaspersky 100% 97% 0% 3% 98.5% 
McAfee VirusScan 100% 96.5% 0% 3.5% 98.25% 
Panda Titanium 100% 95.8% 0% 4.2% 97.9% 
FGIDS 100% 97% 0% 3% 98.5% 
 
Different nodes have different crash and low-performance thresholds due to heterogeneous detection 
environment. Figures 4 and 5 respectively show a detector’s available-CPU-capability and 
available-memory-capacity performance curves in which average available CPU capability and available 
memory capacity are 47.38% and 67.46%, respectively. Table 10 summarizes the crash and low-performance 
thresholds for this detector. According to our experience and observation, the available CPU capability’s crash 
threshold and low-performance threshold are obtained by respectively subtracting two standard deviations and 
one standard deviation from average available CPU capability. Similarly, the available memory capacity crash 
threshold and low-performance threshold are obtained by subtracting three and two standard deviations from 
average available memory capacity, respectively. 
 
 
Figure 4 A detector’s available-CPU-capability performance curve 
 
 
