 II
摘  要 
本研究主要是結合類神經網路與專家系統組成一個具動態學習
功能的智慧型線上診斷系統，用來改善製程中機台參數之漂移
（Drifting）現象所造成的誤差。我們主要是利用類神經網路主動學
習且可重複訓練的特性，並透過模糊規則萃取將類神經網路學習到的
知識以規則的型式（IF…THEN…）表現出來，而儲存於專家系統知
識庫中。由於系統包含有類神經網路的緣故，所以類神經網路神經元
的權重會隨著新資料不斷加入而導致神經元權重向量改變；而經萃取
出新規則後，再加上與規則知識庫合構成一智慧型專家系統。我們可
以依據萃取出之新規則及其信任函數，進而提供配方調整建議。我們
總共蒐集了 1425 筆資料作為類神經網路動態學習訓練樣本，並以此
智慧型線上診斷系統來對膜厚作出量化預測，進而對工程師提出配方
調整的建議。由實驗結果顯示，誤差率由原先的 10.14％經由加入新
訓練資料後下降為 6.64％，證實類神經網路動態學習能有效改善預測
誤差及達到提升良率之效。 
 
 
 
關鍵字︰類神經網路、專家系統、模糊規則萃取、動態學習。 
 IV
摘要................................................................ I 
Abstract........................................................... II 
圖目錄.............................................................VI 
表目錄............................................................ VII 
第一章 序論.........................................................1 
1.1 前言........................................................1 
1.2 研究背景與動機..............................................2 
1.3 文獻回顧....................................................3 
1.4 本文架構....................................................6 
第二章 相關理論.....................................................7 
2.1 TFT-LCD Array 製程介紹 ......................................7 
2.1.1 TFT 元件簡介 ..........................................8 
2.1.2 Array 製程 ............................................8 
2.1.3 電漿輔助化學氣相沉積（PECVD）簡介 ....................14 
2.2 類神經網路.................................................16 
2.2.1  生物神經元原理......................................17 
2.2.2  人工神經元..........................................19 
2.2.3  倒傳遞神經網路......................................22 
2.2.4  倒傳遞網路的學習方法................................25 
2.3 模糊規則萃取演算法（Fuzzy Rule Extraction）................27 
2.3.1 輸入的絡 .............................................30 
2.3.2 子絡的規則 ...........................................35 
2.3.3 規則化簡原理簡介 .....................................36 
2.4 專家系統...................................................39 
2.4.1  知識庫簡介..........................................39 
2.4.2  專家系統簡介........................................39 
第三章 資料形式與研究方法..........................................43 
3.1 資料之擷取.................................................43 
3.2 資料分析...................................................45 
3.3 網路動態學習系統...........................................47 
3.3.1 資料收集.............................................48 
3.3.2 建構類神經網路模型...................................48 
3.3.3 規則萃取.............................................48 
3.3.4 找出信任函數.........................................49 
3.3.5 建立專家系統.........................................50 
3.3.6 參數調整建議系統.....................................51 
3.3.7 類神經網路的重新訓練.................................52 
第四章 實例分析....................................................56 
 VI
圖目錄 
圖 2-1 TFT-LCD 面板製作流程示意圖........................................................................7 
圖 2-2 TFT 元件示意圖................................................................................................8 
圖 2-3 TFT-LCD Array 製程之流程示意圖...............................................................9 
圖 2-4 CVD 反應示意圖..............................................................................................10 
圖 2-5 光阻塗佈.........................................................................................................12 
圖 2-6 蝕刻.................................................................................................................12 
圖 2-7 剝膜.................................................................................................................13 
圖 2-8 五道沉膜流程示意圖......................................................................................13 
圖 2-9 PECVD 的反應機構圖......................................................................................15 
圖 2-10 生物神經元...................................................................................................18 
圖 2-11 人工神經元...................................................................................................20 
圖 2-12 學習演算法的流程說明圖............................................................................22 
圖 2-13 倒傳遞神經網路的基本架構........................................................................24 
圖 2-14 雙彎曲活化函數特性圖...............................................................................25 
圖 2-15 雙輸入神經網路二維示意圖.......................................................................36 
圖 2-16 四條規則於二維平面之示意圖...................................................................37 
圖 2-17 超平面平移之示意圖...................................................................................38 
圖 2-18 化簡後規則於二維平面之示意圖...............................................................38 
圖 3-1 玻璃基板於 PECVD 機台中流程示意圖.........................................................43 
圖 3-2 系統流程圖.....................................................................................................48 
圖 3-3 資料排序示意圖.............................................................................................53 
圖 4-1 第一次訓練後推論值與實際值之差異.........................................................58 
圖 4-2 第二次訓練後推論值與實際值之差異.........................................................66 
圖 4-3 第三次訓練後推論值與實際值之差異.........................................................67 
圖 4-4 第四次訓練後推論值與實際值之差異.........................................................68 
 
 
 
 
 
 1
第一章 序論 
1.1 前言 
半導體與薄膜電晶體液晶顯示器( TFT-LCD )產業是我國目前最
重要的兩大高科技產業，其中薄膜電晶體( TFT )前端的陣列( Array )
製程與半導體前段製程除了基板材質不同外，加工方式與過程大抵相
同，主要含沉膜、曝光、蝕刻、剝膜及檢測等項目；由於大部分 TFT
薄膜電晶體元件製程屬於複雜且非線性之化學與物理反應，加上製程
常有漂動和變異現象【1, 2】，因此隨著 TFT-LCD 面板尺寸加大，
嚴格的製程控制已成為重要且基本的要求，但目前面板廠仍藉由統計
製程管制 (Statistical Process Control, SPC) 理論來管控製程之
各種異常，並無法即時偵測製程故障，且不易查覺造成故障的真正原
因；相較之下，半導體業的技術發展則已幾乎成熟，早於 1997 年時
SIA Roadmap 便將先進製程控制技術(Advanced Process Control, 
APC)列為半導體產業的研發重點，而且國外知名大學及 IC 製造大廠
相繼投入相關技術的研發，然而卻一直未被應用於 TFT-LCD 產業上，
因此對於面板業而言，如何學習 IC 業多年來的相關技術、進而發展
出新方向，突破現有製程監控方法，是業界所致力的目標。 
 3
氣相沉積( PECVD )製程的配方參數以及其沉膜品質資料進行實例分
析，以倒傳遞神經網路架構，建立一模擬薄膜沉積機制的神經網路模
型，對膜厚進行定量的預測，再以規則萃取演算法自神經網路中擷取
出輸入與輸出間的規則，以符合人類思考邏輯的規則形式表達，將規
則集合起來即成為專家系統中的知識庫型態，不只能夠提供工程師直
觀的判斷原則，更可作為系統進行診斷的參考依據，在成品即將超出
規格設定值之前提出警告，以達到品質控管的目的。 
1.3 文獻回顧 
在 1970 年代早期，Carnegie-Mellon University 的 Newell and 
Simon 【7】提出所謂的生產系統模型( production system model )，
利用生產規則( production rules )來解決特定型問題，即現代規則
式專家系統( rule-based expert systems )的基礎。傳統的人工智
慧是以符號( symbolic )操作的方式來模擬人類的思考，其中最成功
的運用則是專家系統( expert system )，隨著技術的進步，專家系
統也漸漸被廣泛採用於各種領域，其優點為：理論成熟、擁有許多成
功的典範、知識是以規則的方式存在知識庫中、容易新增或合併知
識、能夠描述推導答案的過程，以說服使用者接受。而專家系統的潛
在問題為：需要一位專業人士與專家訪談以擷取專家的知識、需將專
家的知識轉化為知識庫的規則、系統無法自動學習【8, 9】等。由於
 5
辨認器能夠在有限度的訓練過程中，產生一個權重向量（weight 
vector），利用這個權重向量可分割這組族群。辨認器的發明在當時
震驚了該領域的所有科學家。而後 Posenblatt 於 1958 年提出一組
神經細胞可以作為一種分類器( classifier )，稱為認知機
( perceptron )，可以對線性可分割的( linearly separable )輸入
圖樣進行分類。之後，Widrow and Hoff 於 1960 年將其應用到可調
適信號處理( adaptive signal processing )，發展了最小均方
( least- mean-square，LMS ) 學習法則，又稱為 delta rule，對
電話語音信號處理有極大的貢獻【5, 6】。目前商用的 ANN 多具有
三 層 或 四 層 的 神 經 網 路 ， 稱 為 多 層 認 知 機 ( Multi-Layer 
Perceptrons，MLP )，每層約有 10 到 1000 個神經元( neurons )，
其中間層稱為隱藏層( hidden layer )，並採用類似 delta rule 的
錯誤修正監督式學習( supervised learning )法則，稱為誤差倒傳
遞學習演算法( EBP、BPN、Back-Prop、Error Back-Propagation 
algorithm )【3-6】。從現代的眼光看來，這些雖然都已是大眾極為
熟悉的技術，但更顯得類神經網路具有理論成熟、應用廣泛、能夠自
動學習等優點，故自然成為目前先進製程分析技術研發的必用手法。
做為連結專家系統與類神經網路橋樑的規則萃取法( rule 
extraction )，其演算法的研究約有十幾年歷史【13】，期間提出的
 7
第二章 相關理論 
2.1 TFT-LCD Array 製程介紹 
    所謂的薄膜液晶顯示器( TFT-LCD )指的是利用薄膜電晶體 
( Thin Film Transistor，TFT )當成開關，靠著上下兩基板間的電
場改變來控制液晶的扭轉方向，利用液晶分子的旋光性質操縱顯示器
上每一個畫素中 RGB 光源的明暗程度。就液晶顯示器而言，其製程可
分成三大部分，分別為前段陣列( Array )製程、後段面板組裝( Cell )
製程及模組組裝( Module )製程，圖 2-1 顯示此三大段製程間的關聯
性；其中的 Array 製程則是指製造 TFT 玻璃基板時的沉膜、曝光、蝕
刻及剝膜等製作流程，這也是本研究中最主要相關的部份。 
              
圖 2-1 TFT-LCD 面板製作流程示意圖 
 9
光阻塗佈、曝光、顯像、蝕刻及光阻剝離等程序，經多次反覆即可逐
層堆疊出所需之線路與元件，形成薄膜電晶體( Thin Film 
Transistor，TFT )之陣列基板。圖 2-3 為 TFT-array 之製程順序簡
圖。以下針對圖示之薄膜電晶體陣列製程，依序對其作較為深入的說
明。 
 
圖 2-3 TFT-LCD Array 製程之流程示意圖 
1. 玻璃基板投入：由於玻璃板常會因邊緣部之破損而引發各種
缺陷，因此在進入生產線前，需對玻璃板作一概略處理以及檢查，包
括裂縫有無、外型尺寸、厚度均勻性及平面精度等。 
 11
CVD 反應原理： 
（a）反應物以擴散通過介面邊界層。 
（b）反應物吸附在基板的表面。 
（c）化學沉積反應發生。 
（d）部分生成物藉擴散通過介面邊界層。 
（e）生成物與未反應的反應物進入主氣流裡，並離開系統。 
而物理氣相沉積則是在真空中使用高頻率放電在平行電極間產
生電漿，並利用電漿將反應氣體游離成離子與電子，再以電場加速離
子來撞擊靶材（target），使靶材上的原子被撞擊出來而沉積於基板
上。 
4. 光阻塗佈、曝光及顯影：由於現階段之設備通常將此三道程
序整合於一組機台內完成，而且將它們共同稱為寫真或微影製程
( Photo )，故在此一併介紹。光阻塗佈的方法包括旋塗、浸泡、滾
輪、噴霧法等，其目的在於將光阻均勻地塗佈於已鍍膜之玻璃基板
上；接下來，由曝光機光源經由光罩把欲製作之電極圖案映射至基
板，光阻經曝光後形成酸,跟鹼性溶液(顯影液)中和，再經水洗後，
光罩上之電極圖案遂顯現在基板上，此即微影之過程。 
 13
剝膜前 光阻
剝膜後
 
圖 2-7 剝膜 
    上述步驟即為 Array 製程之簡介，其中製程 3~6 在完畢後會隨機
抽取基板進行影像檢測，若抽查之樣本良率過低、或是產生嚴重缺
陷，則該批玻璃基板便停止往下一個流程，視其情況決定是流程重製
或報廢；而在整個 Array 製程中，步驟 2~6 會反覆五次，亦即完成品
總共需鍍上五層膜，這五層膜依序為：1.電極；2.島狀半導體；3.
源極、汲極電極；4.接觸孔；5.畫素電極。每一層薄膜的詳細名稱與
製程如圖 2-8 所示，當五層薄膜加工完畢後，便會進入最後的電路檢
測( Array test，A 檢 )，通過測試後的成品方可繼續下一道的面板
組裝( Cell )製程。 
 
圖 2-8 五道沉膜流程示意圖 
 15
電漿鞘（Sheath）構成（2）反應機構不同。 
 
 
圖 2-9 PECVD 的反應機構圖 
傳統化學氣相沉積法的化學反應，遵循反應的熱力學與動力學；
而電漿輔助化學氣相沉積法的化學反應則是完全由碰撞所決定，所以
電漿內的電子密度（即電漿密度）與電漿的均勻度都會決定反應的機
制。 
電漿輔助化學氣相沉積法較一般傳統的熱裂法為佳，其原因是在
低壓下電漿可使氣相原料分子活化，並產生活性自由基；如此一來便
能改變化學反應路徑，並且降低反應活化能及反應溫度，而達成所要
的化學反應。 
 
 17
2.2.1  生物神經元原理 
生物神經網路是由許多神經細胞( neuron ) ─ 或稱為神經元所
組成，一個典型的生物神經元構造如圖 2-10 所示，含有一個細胞體
( cell body 或 soma )，一個軸突( axon )和好幾個的樹突
( dendrite )；訊息經由樹突傳入細胞體，細胞體即為構成神經單元
的主要細胞部分，所有訊息於此進行彙集轉換，再經由軸突傳出，一
個生物神經元只有一個軸突，其末端的分支會形成特化的末梢，稱為
突觸末端( synaptic terminal )，其與目標細胞的接觸處稱為突觸
( synapse )，它就像神經網路上的記憶體，決定著兩神經元間訊息
傳遞時的權重，突觸末端處積存著大量的神經傳導物質
( eurotransmitter )，藉由神經傳導物質的釋出，就能將神經訊息
傳給下一個細胞，亦即不同神經元間是依靠神經傳導物質來傳遞訊
息。 
 19
2.2.2  人工神經元 
如同神經元在生物神經網路中扮演的角色一般，在類神經網路之
中，也有一個具備簡單資訊處理能力的神經元。人工神經元
( Artificial Neuron )，又稱為處理單元( Processing Element，
PE )，其結構如圖 2-11 所示，與生物神經元原理類似，在這個模型
裡，它擁有三種基本的構成要素： 
1. 神經鍵：作為兩神經元間的連結，而且每一個神經鍵都擁有
各自的強度( strength )，或稱為比重、加權值( weight )，影響著
該神經元所連接的神經元輸入。舉例而言，一神經元 n與另一神經元
m 之間存在一個神經鍵 Wmn，當前一個神經元藉由第 n個樹突傳送訊號
Xn到神經元 m 的時候，神經元 m 所得到的訊號將變成訊號與神經鍵的
積 Wmn*Xn。 
2. 加法器( adder )：將所有傳送到神經元的訊號進行加總。 
3. 活化函數( active function )：用來調整經加法器處理後的
值，使其變化能被限制在某些區間之中，例如[0 1]或是[-1 1]。 
 21
類神經網路就是將上述的神經元以神經鍵相互連結起來所形成
之網路架構，依照內部的神經鍵及輸出連接的不同、神經元層次的增
減或者是神經鍵自我調整與活化函式的差異，就能建立出不同種類的
類神經網路來。在學習方面，與生物神經網路原理類似，類神經網路
的學習是藉著各種演算法來調整網路中各神經元間的“連結＂強
弱，亦即將所謂的“知識＂改以神經鍵的強度表示，完成訓練後的網
路可藉由已轉化為加權值的知識去判斷將來輸入資料的屬性，從而決
定輸出結果【20】。 
前 面 所 提 之 神 經 元 ， 其 內 部 資 訊 傳 遞 為 前 向 式
( feed-forward )，各神經元僅疊加輸入資訊經過活化函數轉換後送
出對應之輸出資料給下一個神經元。這樣的架構雖然已仿效神經元的
基本特性，但卻沒有真正仿效到生物神經元最重要的學習能力等特
性。因應前向式網路不足之處，其後許多具有學習能力的神經網路亦
逐漸發展出；至今，就學習過程而言，類神經網路可概略區分為兩大
分支 ─ 監督式( Supervised )及非監督式( Unsupervised )。監督
式學習是從訓練範例中學習到輸入值和目標值之間的對應規則或關
係，其學習機制是利用目標值與網路輸出值之間的差異來調整網路加
權值，以降低其輸出值誤差；而非監督式學習是從訓練範例裡學習其
內在規則關係，無須目標值來加以修正，神經網路透過自我組織
 23
換言之，可以期望在學習過程中，使網路的輸出值與預設的目標值能
夠極為接近。若在輸出層不能得到目標輸出值，則轉為反向傳播，將
誤差訊號沿原來的連結通路回傳，透過修改各層神經元的權重與偏權
值，使誤差達到容忍範圍之內而停止，這也是此類網路被稱為倒傳遞
類神經網路的原因。 
    標準倒傳遞網路架構如圖2-13，為三層神經網路，包含輸入層、
隱藏層與輸出層： 
    1. 輸入層( Input Layer )：僅輸入資料，通常不對資料做任何
處理。 
    2. 隱藏層( Hidden Layer )：由數個隱藏層處理單元組成，用
以彙集、處理輸入單元的資料，絕大多數倒傳遞類神經網路只需一至
二層隱藏層的網路結構，就可有效分析輸入資料的內涵結構及特性，
並提供輸出層進一步分類、預測訓練樣本的輸出值。 
    3. 輸出層( 0utput Layer )：由一層處理單元所組成，使用非
線性轉換函數彙集、處理隱藏層輸入的資料。 
 25
如圖 2-14 所示，這種函數有一種特性，當 net 趨近於正負無窮大時，
f 便趨近於 0 或 1。此外，相較於其他形式的活化函數(如門檻二值
化函數、片段線性函數等等)，由於 S 形函數可微分，因此可利用於
最陡坡降法的學習過程中以修正權重與偏權值，使誤差值逐次減小，
達到學習目的。 
 
圖 2-14 雙彎曲活化函數特性圖 
 
2.2.4  倒傳遞網路的學習方法 
若 yk 為輸出層第 k 個神經元的輸出值，dk 為第 k 個神經元之輸
出目標值，則定義誤差函數 E ( Error Function )為： 
         2)(
2
1E ∑ −=
k
kk yd    …………………….. (2-5) 
 27
每輸入一組訓練範例，各連結權重即依此式加以調整。 
倒傳遞類神經網路的主要架構設定條件為隱藏層的層數與隱藏
層神經元的個數；BPN 的第一步必須決定隱藏層的層數來決定網路的
大小以建構一個好的模式，在許多理論的研究結果顯示，隱藏層的層
數不需超過兩層以上，至於一層與兩層隱藏層哪個比較好，則在不同
的研究或問題中有不同的結論，其必須依照網路大小、訓練時間、精
確度以及對硬體的需求來決定。而各隱藏層的神經元個數多寡將對神
經網路有相當大的影響（1）決定網路參數的多寡（2）影響神經網路
其歸納推演的能力。所以過少的神經元個數無法建構是當的函數來描
述問題；反之，過多的神經元個數則對於訓練範例過度的描述，甚至
引含了雜訊的描述，而失去歸納推演的能力。所以，必須經由一些方
法如網路修剪法（pruning algorithm）與網路增長法（constructive 
algorithm）來嘗試訓練神經網路以找出適當的神經元個數。 
2.3 模糊規則萃取演算法（Fuzzy Rule Extraction） 
最早應用分類描述方法在萃取類神經網路中相關規則的是 L. 
M. Fu【22】，發展至今約有十多年的歷史；基本上，依照其原理不
同，規則萃取可分為三種類型【23】：教導型( pedagogical )、分解型
( decompositional )與折衷型( eclectic )。在教導型的方法中【23-26】，
相關規則的產生主要是利用經驗分析的方式來分析輸入與輸出間的
 29
範例一、 
xi是神經元的一個輸入，而且 0 ≦ xi ≦ 1。我們可以把這個輸入區分
到這些集合｛Zi1，Zi2，Zi3｝的其中之一，而 Zi1 這個集合的範圍是[0，
0.33]，Zi2 這個集合的範圍是[0.33，0.66]，Zi3 這個集合的範圍是[0.66，
1]。如果 xi 被分派到 Zi2，也就是表示 0.33 ≦ xi ≦ 0.66。 
 
相同的，神經元的輸出值 y也可屬於模糊集合 [ ]pyyyy ZZZZ ,...,, 21∈
其中的一組集合，每個模糊集合 ykZ （k=1~p）有其相對應之模糊區間
[ Lkvy , Ukvy ]，其中 10 ≤≤≤≤ UkLk vyyvy 。 
另外， ukZ 為 ykZ 在 u(x)定義域內的一組相對應的模糊集合，亦有
一 組 對 應 之 模 糊 區 間 [ Lkvu , Ukvu ] ， 其 中 Lkvu = )(log 1 Lkvysig − ，
U
kvu = )(log 1 Ukvysig − 。 
 
範例二、 
y 是神經元的一個輸出，而且 0 ≦ y ≦ 1。我們可以把這個輸出區分
到這些集合｛Zy1，Zy2，Zy3｝的其中之一，而 Zy1 這個集合的範圍是[0，
0.33]，Zy2 這個集合的範圍是[0.33，0.66]，Zy3 這個集合的範圍是[0.66，
1]。如果 y 被分派到 Zy2，也就是說 0.33 ≦ y ≦ 0.66。 
而在 u(x)的定義域裡，對應於 Zy2 的集合是 Zu2 而且此集合的範圍為︰ 
[ Lvu2  , 
Uvu2 ] = [logsig
-1( Lvy2 ) , logsig
-1( Uvy2 )] 
= [logsig-1(0.33) , logsig-1(0.66)] = [-0.7082 , 0.6633] 
如果 y 被區分到 Zy2，也就是表示-0.7082 ≦ y ≦ 0.6633。 
 
 
 31
根據以上我們可以很容易的發現，當 u(x)為絕對最大值時，所
有帶正值的權重(wi)所對應的輸入值(xi)皆為 1，而所有帶負值的權
重(wi)所對應的輸入值(xi)皆為 0；相反地，當 u(x)為絕對最小值時，
所有帶正值的權重(wi)所對應的輸入值(xi)皆為 0，而所有帶負值的
權重(wi)所對應的輸入值(xi)皆為 1。因此，絡的上限即為偏權值(w0)
與帶有正值的權重(wi)之總和；絡的下限即為偏權值(w0)與帶有負值
的權重(wi)之總和。 
為了從被激發的神經元中萃取出模糊規則，神經元的絡必須分解
成子絡，並且從模糊集合 Zyk 的模糊區間[ Lkvy , Ukvy ]中找出子絡的邊
界。這表示絡的所有輸入值 x 將使得神經元的輸出 y 屬於 ykZ 這個集
合。我們必須做的是將 1x 區分為數個區間［ 11Z ~ mZ1 ］，因此原本的絡
被分解為 m 個子絡，且 1x 的每個輸入會屬於集合 1Z 其中的一組集合。
相同的，每個子絡可依 2x 再分解為更小的子絡。然後，隨著越多的 ix
分解子絡，可獲得越多子絡的更小集合。 
定義三、子絡（sub-cube）： 
在神經元中，子絡是輸入向量 x 的一個子集合。當絡中的某一個
輸入向量 xi的前 k項被指定分解，一個子絡經過 k 次的分解可以
用下面的式子來表示︰ 
  cube(w*,Z1Z2…Zk) 
 33
定義四、子絡的範圍（bound of sub-cube）： 
子絡的邊界也就是 u(x)在子絡中的最大值與最小值。描述如下︰ 
bound(cube(w*,Z1Z2…Zk)) = [lbound , ubound] 
其中，lbound 為子絡中 u(x)的最小值 
ubound 為子絡中 u(x)的最大值 
 而 lbound(cube(w*,Z1Z2…Zk)) 
= min{ u(x)|  x ∈ cube(w*, Z1Z2 ... Zk)} 
= 00,10,10,1 wwwvwv
n
wkj j
k
wi i
U
i
k
wi i
L
i
jjj
+++ ∑∑∑ <+=<=≥=  （2.10） 
   ubound(cube(w*,Z1Z2…Zk)) 
= max{ u(x)|  x ∈ cube(w*, Z1Z2 ... Zk)} 
= 00,10,10,1 wwwvwv
n
wkj j
k
wi i
L
i
k
wi i
U
i
jjj
+++ ∑∑∑ ≥+=<=≥=  （2.11） 
 
範例五︰ 
  延續範例四， 
The lbound of cube(w*, Z11) = v11L × w1 + w3 + w0  
= 0 × 0.7 + -0.4 + -0.5 = -0.9 
The ubound of cube(w*, Z11) = v11U × w1 + w2 + w0  
= 0.3 × 0.7 + 0.3 + -0.5 = 0.01 
The lbound of cube(w*, Z11Z23) = v11L × w1 + v23L × w2 +w3 + 
 35
而 bound(cube(w*, Z23)) 
= [-0.9 + v23L × w2 , 0.5 – (1-v23U) × w2 ] 
= [-0.9 + 0.7 × 0.3 , 0.5 – (1-1) × 0.4]  
= [-0.69 , 0.5].                        
上述的方程式更為簡單，所以我們可以即時獲得子絡的邊界值。經由
計算邊界值，我們額外定義一些特殊的絡。 
定義五、定絡（certain cube）： 
 若是一個子絡同時符合 lbound > Lkvu 以及 ubound < Ukvu ，則其稱
為定絡。這表示此絡的所有輸入都將使得這個神經元的輸出範圍座落
於集合 Zyk的模糊區間中。 
定義六、未定絡（uncertain cube）： 
 一個子絡若其非為定絡則其為未定絡。 
 
2.3.2 子絡的規則 
 由於每個絡的邊界範圍皆會符合集合 Zyk 的某個模糊區間
[ Lkvu , Ukvu ]，所以某個絡 cube(w*,Z1Z2…Zk)藉由模糊規則決定的輸出
可描述為“假如 x1屬於 Z1且 x2屬於 Z2且…且 xk屬於 Zk，則神經元的
輸出將座落於 Zyk的範圍中。＂ 
 37
 
圖 2-16 四條規則於二維平面之示意圖 
    規則化簡( rule pruning )之原理即為令 wi所構成的超平面進行
一平移±b，其構成之區間中所包含的資料點可任意歸類；以圖 2-17
為例，在超平面平移產生的區間中，兩個分類共有 7個資料點處於區
間中，若將其均歸為第一類，則可以得到新的規則為 (如圖 2-18)： 
1. 若 x1 < 5 且 x2 < 4.2，則該點之輸出為第一類 
2. 若 x1 < 7 且 x2 < 3.6，則該點之輸出為第一類 
兩者相較之下，經過化簡後的規則數減少，然而也因為區間中資
料點會有分類錯誤的現象，使得正確率會有下降的情形。簡而言之，
規則化簡即為將分界線附近的資料點暫不加以分類，然後根據規則精
簡程度之需要歸納其類別，而界線的平移範圍、亦即區間的大小可由
人工設定；一般而言，區間取得愈大，規則數目愈少，然其準確度也
會下降。 
 39
2.4 專家系統 
2.4.1  知識庫簡介 
所謂的知識庫技術，是從人工智慧中所衍生出來的一個分支，其
目的為儲存專家(或特殊領域)的專門知識，就其訊息的特徵以及其應
用層面而言，則與數據庫相似，亦即透過電腦運算，根據條件對訊息
進行分析、萃取與查詢等。所以，知識庫可視為一種特殊的數據庫，
一般來說，其中應包括某一領域內的定義、定理和運算推理法則，在
定義與定理方面可用一般數據庫的方式表示，對於運算推理法則採用
“if... then...＂的邏輯表達。對專家系統而言，其問題的解決方
式是運用專家所提供的知識來模擬專家思維進行推斷，而專家系統的
能力則取決於其知識庫中所含有的知識數量與質量，所以正確知識庫
的建立，是決定專家系統的性能優劣的關鍵因素。 
2.4.2  專家系統簡介 
近年來，隨著知識工程技術以及相關理論的發展，加上電腦軟硬
體設備的進步，使得專家系統有愈來愈普遍的應用。對人類而言，由
於知識的學習與轉移速度極慢，所以一位專家的養成往往得經過長時
間的培育，然而人類的專家卻常因種種因素使得所累積的經驗知識有
流失之虞 ；另外，其決策也常受情緒以及其他主觀的因素而產生不
 41
溝通與說明時難免有所誤解與落差，造成知識擷取耗時費力，且取得
之知識法則品質未能滿足需求，有鑑於此，許多歸納性的學習方法
( inductive learning method )如類神經網路、規則歸納法與決策
樹等相繼被採用來解決此一問題【36】。 
    一般來說，類神經網路有絕佳的能力能夠經由各式輸入資料的聚
類來學習【3-6】。在類神經網路中的知識是儲存於每個神經元的神經
鍵數值( weight，即所謂權重值 ) 與神經元的組成架構當中，而類
神經網路中的知識是以訓練的資料經由學習的機制所得到的。類神經
網路學習過程是將訓練資料一筆一筆逐次的放入系統中去看實際輸
出的結果與預期輸出有何不同，再將兩者的差距回饋至每個神經元中
去調整神經鍵，如次反覆的訓練直到輸出與預期的輸出一致；不像專
家系統，類神經網路的學習過程並沒有人力的介入，單純靠訓練資料
與學習機制來完成；此外，專家系統沒有自我學習的功能，儲存在知
識庫當中的知識，專家系統無法動態的以經驗學習來訂正與調整，只
能靠人力的介入來修改或新增規則，而自我學習則是類神經網路主要
的優點。因此，將類神經網路用在專家系統的主要優點有： 
    1. 使新專家系統具有學習能力：透過類神經網路所具有的學習
特性，可以使專家系統能有自我學習、改進、擴充能力，以解決知識
擷取的瓶頸問題。 
 43
第三章 資料形式與研究方法 
3.1 資料之擷取 
    本研究中所分析的參數資料，係來自液晶面板廠的電漿化學氣相
沉積( PECVD )機台。PECVD 的沉膜過程可大致分為：基板搬入、抽
真空、反應器( reactor )預熱、氣體導入、穩定氣體流量、供給電
源(膜沉積開始)、關閉電源、基板取出、清潔反應器、基板冷卻、基
板搬出等步驟，圖 3-1 為 PECVD 機台之上視簡圖，基板匣( cassette )
為玻璃基板放置處，而基板於機台中的流程亦如圖 3-1 所示，未沉膜
之基板經機械手臂由基板匣運入 LL\IN 中，待腔室抽真空後，再經由
TC 的機械手臂運入 PC1、PC2 進行沉膜；沉膜完畢後，TC 的機械手臂
會將加工完畢之基板運至 LL\OUT，再由外側機械手臂將其放回基板
匣中，一道沉膜手續便告完成。 
  
圖 3-1 玻璃基板於 PECVD 機台中流程示意圖 
 45
3. Logfile：記錄該批基板於機器中的各步驟參數紀錄，惟其數值已
經過均化處理，就其中的數據性質而言，我們可將其視為精簡版
的配方( recipe )。 
3.2 資料分析 
    由於模糊規則萃取是由訓練完成之類神經網路模型中擷取規
則，因此規則的正確性會受到模型準確度之影響。故在開始類神經網
路訓練前對於資料的處理非常重要。本研究中所蒐集的資料來自華映
電腦之 data base，而 data base 的資料是由液晶面板廠的電漿化學
氣相沉積反應（PECVD）機台中取得，經整理後再存於其中；本研究
所分析的資料為在製程穩定狀態下，島狀半導體(SE)形成【18】的第
二層成膜（SiNx/a-Si/n+Si）中之參數與膜厚。 
    由 data base 所蒐集之資料中包含 27 種參數其包括十一種氣體
(SIH4、H2_PH3、H2、N2、HE、SF6、NF3、O2、N2_OXY、NH3、N2_BACK)
之流量以及下列五種參數之平均值、最大值及最小值，其分別為
DC_BIAS（直流偏壓）、DELIVER_PWR（傳遞功率）、REACTOR_TEMP（反
應器溫度）、REFLECT_PWR（反射功率）、RF_PEAK（系統使用射頻功率
之峰值，RF 為 radio-frequency 的簡稱）。但在神經網路建立時，訓
練資料裡的輸入項對於系統的代表性越高越好，換言之，若存在太多
無意義的輸入參數，會影響神經網路訓練結果之準確度；因此，為了
 47
       ∑= −=
N
i
i xxN 1
2)(1σ                    （3-1） 
其中 ix 為各點膜厚， x 為 25 點膜厚之平均值 
而 U 值之計算公式為 
       
minmax
minmax
TT
TT
−
−
                  （3-2） 
其中 maxT 為 25 點中之膜厚最大值， minT 為膜厚最小值。 
3.3 網路動態學習系統 
 類神經網路會把從訓練資料所學習到的知識儲存在神經元中，但
這對我們來說卻是一大困擾，因為我們無法了解整個推論過程。而這
也是專家系統的一大優點─可以明確敘述整個推理的過程。傳統的專
家系統的知識庫建立不易，需要透過知識工程師與領域專家的會面交
談，而把知識加以組織。因此本論文提出的智慧型系統其中包含有類
神經網路以及專家系統兩大模組，我們主要是利用類神經網路主動學
習的特性來對我們所收集的訓練資料作分析學習，再使用規則萃取演
算法從學習好的類神經網路中將知識以規則的型式呈現出來，並且用
這些知識來建立專家系統模組的知識庫，使得此系統能對我們所想要
了解的問題來提供解決方案，以下則是對系統流程的一個簡單介紹︰ 
 
 49
數值（亦稱為權重值）與神經元的組成架構之中的知識，透過一種分
解型的規則萃取演算法萃取出相對應的規則，並儲存於專家系統中的
知識庫裏。 
3.3.4 找出信任函數 
 經由第三步驟的規則萃取找出相對應的規則後，由於我們無法了
解每一條規則的重要性，所以我們在第四步驟中，針對每一條規則去
計算與原先訓練資料之間的信任度（Trust Value），以瞭解每一條規
則的信任程度。 
我們所定義的信任度是依據訓練資料規則 D=[ZD1 ZD2…ZDn]與規
則萃取之規則 R=[RD1 RD2…RDn]之間的漢明距離 HM（hamming 
distance）大小而產生，而 HM 如式(3-3)所示︰ 
∑== ni ihHM 1 ， ( )⎩⎨
⎧
≠−
==
0,
0,0
R
i
D
i
R
i
R
i
i ZZZabs
Z
h   （3-3） 
範例︰ 
  假設輸入資料為［x1 x2 x3］而且他們的範圍都在［0～1］。 
每一個輸入都被分配到五個小區間［0, 0.2］［0.2, 0.4］［0.4, 
0.6］［0.6, 0.8］［0.8, 1］。 
現在有一條規則 R=［ZR13ZR21ZR34］，它代表“IF x1 is assigned in 
ZR13 AND x2 assigned in ZR21 AND x3 assigned in ZR34 then …＂。 
 51
3.3.6 參數調整建議系統 
 以第五步驟所建立的知識庫作為依據，針對所要求的輸出，提供
信任程度數值最高且參數調整幅度最小的規則作為參數調整的參考
規則。 
 參數調整建議系統的主要目的是找出最符合輸出目標的規則，即
使找出的規則需要對輸入作小幅度的更動。因此，被建議的規則與原
本輸入資料之間的 HM 越小越好。另外，為了確保正確性，規則的信
任指數也必須高於某個門檻。我們提出一個範例如下︰ 
範例︰ 
假設有一訓練資料 D = [ZD13ZD22ZD32]，我們想把它的輸出範
圍從 Zy3調整到 Zy4，我們發現有三條規則符合需求，分別為 
R1 = [ZR12ZR22ZR32]，R2 = [ZR12ZR23ZR32]，R3 = [ZR11ZR23ZR33] 
我們分別計算規則與訓練資料的 HM 
HMR1 = abs（2-3）+ abs（2-2）+ abs（2-2）= 1 + 0 + 0= 1 
HMR2 = abs（2-3）+ abs（3-2）+ abs（2-2）= 1 + 1 + 0= 2 
HMR3 = abs（1-3）+ abs（3-2）+ abs（3-2）= 2 + 1 + 1= 4 
根據 HM，我們所提供的建議為 R1，它代表“IF x1 is assigned in ZR12 
AND x2 assigned in ZR22 AND x3 assigned in ZR32 then …＂ 
 53
 
夠同時保有這兩個特性，我們對訓練資料提出兩種不同的訓練策略來
作比較，以下是兩種策略的概述︰ 
《訓練策略一》 
假設原先機台所收集得到資料為 m（m1～mk），我們把 m1～mk資料用
來作為類神經網路的訓練資料，而從機台所新收集得到的新資料為
N，則作為類神經網路訓練完成後用來檢查類神經網路是否準確的測
試資料。 
《訓練策略二》 
假設原先的資料為 m（m1～mk），第一次帶入類神經網路的訓練資料
為 m1～mk（TD1），第二次帶入類神經網路的訓練資料為 m2～mn
（TD2），之後依此類推，直到帶入資料到 mk（TDk）為止，而測試資
料則是使用機台新收集得到的資料 N。 
 
 
 
 
 
 
圖 3-3 資料排序示意圖 
TD2 TD3 
mk 
︰︰︰：：：：︰︰︰︰︰
mk mk 
︰︰︰：：︰︰︰︰
︰︰︰：：：︰︰︰︰︰
 
m2 
m3 
TD1 
m1 
 55
根據上述方式，我們將資料序列隨著輸入時間由近到遠，把每一筆資
料都拿來作比較，直到第 Sk筆資料被歸類到 An區，也就表示當資料
回收到第 Sk筆時，我們就有了 N 種代表性的資料群，整群資料就達
到了我們所要求的擁有足夠代表性，因此我們把這 k 筆資料(S1～Sk)
用來作為類神經網路的再訓練資料(TD1)。而 TD2、TD3、…、TDk
也是如同上述的資料擷取方式，來用作類神經網路的再訓練資料。 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 57
表 4-2 類神經網路輸出參數 
 
 
 
 
 
4.2 建構類神經網路模型 
在建構類神經網路模型時，我們從前一步驟已知，此網路有八項
輸入值及四項輸出值。我們將原先的 1425 筆機台資料分為 D1～D5 五
組，在一開始我們以 D1 作為類神經網路的訓練資料，而訓練完成後，
我們以 D2 作為測試資料；得到的結果如表 4-3 所示。 
表 4-3 類神經網路第一次訓練結果 
 訓練資料 測試資料 訓練資料誤差率 測試資料誤差率
第一次訓練 D1 D2 3.7% 10.14% 
 
而圖 4-1 為以 D2 作為測試資料，測試類神經網路的推論值與 D2 的實
際值之比較圖，其中紅圓為類神經網路之推論值而藍點為 D2 之實際
值； 
1y The average of membrane thickness 
2y The maximum of membrane thickness 
3y The minimum of membrane thickness 
4y The uniformity of membrane thickness 
 59
 
2x ︰OUT Temperature 
  Z21=[289.8～289.92] 
  Z22=[289.92～290.16] 
  Z23=[290.16～290.4] 
  Z24=[290.4～290.64] 
  Z25=[290.64～290.88] 
  Z26=[290.88～291] 
  
 
3x ︰RF Power 
  Z31=[5700～5740] 
  Z32=[5740～5820] 
  Z33=[5820～5900] 
  Z34=[5900～5980] 
  Z35=[5980～6060] 
  Z36=[6060～6100] 
  
 
4x ︰Pressure 
  Z41=[1720～1730] 
  Z42=[1730～1750] 
  Z43=[1750～1770] 
  Z44=[1770～1790] 
  Z45=[1790～1810] 
  Z46=[1810～1820] 
  
 
5x ︰Flow of Gas NH3 
  Z51=[4085～4128] 
  Z52=[4128～4214] 
  Z53=[4214～4300] 
  Z54=[4300～4386] 
  Z55=[4386～4472] 
  Z56=[4472～4515] 
  
 
 
 61
 
 3y ︰Minimum of membrane thickness 
  Zy31=[2650～2710] 
  Zy32=[2710～2770] 
  Zy33=[2770～2830] 
  Zy34=[2830～2890] 
  Zy35=[2890～2950] 
 
 4y ︰Uniformity of membrane thickness 
Zy41=[0～0.026] 
  Zy42=[0.026～0.052] 
  Zy43=[0.052～0.078] 
  Zy44=[0.078～0.104] 
  Zy45=[0.104～0.13] 
 
 63
表 4-5 膜厚平均值在 Zy3模糊區間之規則 
由表 4-5 得知，膜厚平均值在 Zy3模糊區間所被分析出的部分規
則，而表中每條規則的數字[1，2，…，6]分別代表著輸入值所座落
的模糊區間[Zi1，Zi2，…，Zi6]；而數字“0＂代表著此規則與 xi項輸
入沒有關聯。我們選擇一個範例 R1[ Z32 Z42 Z51 Z71 Z81]來作說明︰ 
若 x3座落於第二個模糊區間 Z12、且 x4座落於第二個模糊區間 Z32、且
x5座落於第一個模糊區間 Z51、且 x7座落於第一個模糊區間 Z71、且 x8
座落於第四個模糊區間 Z81，則膜厚平均值會座落於第三個模糊區間
Zy3。也就代表著︰ 
 1x  2x  3x  4x  5x  6x  7x  8x  
R1 0 0 2 2 1 0 1 1 
R2 0 0 3 1 1 0 1 1 
R3 0 0 3 2 2 0 1 1 
R4 0 0 4 1 2 0 1 1 
R5 0 0 4 2 3 0 1 1 
R6 0 0 5 1 3 0 1 1 
R7 0 0 1 5 4 0 1 1 
R8 0 0 5 2 4 0 1 1 
 65
SR2︰[Z31Z45Z54Z73Z82] 
若 x3座落於第一個模糊區間 Z31、且 x4座落於第四個模糊區間 Z45、且
x5座落於第四個模糊區間 Z54、且 x7座落於第三個模糊區間 Z73、且 x8
座落於第二個模糊區間 Z82， 
則膜厚平均值會座落於第二個模糊區間 Zy2。 
則由以上兩條規則得知，工程師只要控制 N2氣體流量保持在 21140～
21180（SR1），或是控制反射功率維持在 10～20（SR2），則平均膜厚
值將會座落於 2870～2930Å。 
 
4.6 類神經網路動態學習 
在 4.2 節中，我們已經將類神經網路模型做好第一次的訓練，而
接下來我們增加一組新資料 D3，並再次訓練類神經網路；我們以
（D1+D2）作為訓練資料，訓練完成後，以 D3 作為測試資料；得到的
結果如表 4-6 所示。 
表 4-6 類神經網路第二次訓練結果 
 訓練資料 測試資料 訓練資料誤差率 測試資料誤差率
第二次訓練 D1+D2 D3 4.76% 9.82% 
 
 67
 
0 20 40 60 80 100 120 140 160 180 200
2600
2700
2800
2900
3000
3100
3200
3300
3400
 
 
Prediction
Real value
 
圖 4-3 第三次訓練後推論值與實際值之差異 
 
最後我們將新資料 D5 一併帶入，並再次訓練類神經網路；我們以
（D1+D2+D3+D4）作為訓練資料，訓練完成後，以 D5 作為測試資料；
得到的結果如表 4-8 所示。 
 
表 4-8 類神經網路第三次訓練結果 
 訓練資料 測試資料 訓練資料誤差率 測試資料誤差率
第四次訓練 D1+D2 +D3+D4 D5 4.59% 6.64% 
 
而圖 4-4 為以 D4 作為測試資料，測試類神經網路的推論值與 D4 的實
際值之比較圖，其中紅圓為類神經網路之推論值而藍點為 D4 之實際
值。 
膜 
厚 
值 
（Å） 
資料筆數 
 69
第五章 結論 
在本研究中，我們建構了一個運用動態學習技術的智慧型線上診
斷系統，並以生產線上的實際數據作範例，而誤差率也由原先的10.14
％經由依次加入新訓練資料後而下降至 6.64％；整體而言，此智慧
型線上診斷系統在預測膜厚、建議配方及動態學習等項目中皆有良好
的表現。我們使用類神經網路針對 PECVD 成膜厚度進行定量化的預
測，再使用模糊規則演算法從類神經網路之神經元權重向量中擷取出
規則，作為專家系統之知識，再把這些知識儲存於知識庫中，爾後工
程師則可透過電腦在短時間內的運算，提供定量化的解析數據，而電
腦所提出的參數調整建議，則可作為工程師在調整配方時之依據。 
但在實驗過程中，我們也遭遇到一些狀況。首先，在資料收集部
分，由於此系統是依據我們所提供的輸入資料來讓類神經網路學習並
分析參數之間的關係，因此在輸入資料方面除了資料筆數要足夠多之
外，其代表性也是需要考量的條件。在實驗中，我們是以平均膜厚之
誤差率來作為我們判斷此系統優劣的準則，但真實情況中，並非僅僅
只需考慮平均膜厚即可；在針對某些特殊案例而言，也許需要考慮的
是最大膜厚或是最小膜厚，這必須依照案例不同而有所改變。再者，
以本研究範例而言，我們的輸入參數全部來自於機台資料庫中與製程
配方有關的部分數據，而根據我們與現場操作機台人員討論之結果來
 71
參考文獻 
【1】  F. Jansen,“AVS Short Course: PECVD,＂American Vacuum 
Society, 1990. 
【2】 莊達人,“VLSI 製造技術,＂高立圖書有限公司, 2000. 
【3】 S. Haykin,“Neural Networks,＂Prentice Hall International, 1999. 
【 4 】  J. A. Freeman and D. M. Skapura,“ Neural Networks,＂
Addison-Wesley, 1992. 
【5】 葉怡成,“類神經網路模式應用與實作,＂儒林圖書有限公司, 
1999. 
【6】 張裴章, 張麗秋, 黃浩倫,“類神經網路理論與實務,＂臺灣東華書局
股份有限公司, 2004. 
【 7 】  A. Newell and H. A. Simon,“Human Problem Solving,＂
Englewood Cliffs, NJ: Prentice Hall, 1972. 
【8】 B. G. Buchnan and E. H. Shortliffe,“Rule-based Expert Systems,＂ 
Addison-Wesley, 1984. 
【9】 P. Jackson,“Introduction to Expert Systems,＂Addison-Wesley, 
1999. 
【10】M. Negnevitsky,“Artificial Intelligence,＂Addison-Wesley, 2002. 
【11】 S. Russell and P. Norvig,“Artificial Intelligence,＂Prentice Hall, 
1995. 
【12】W. S. McCulloch and W. Pitts,“A Logical Calculus of Ideas 
Immanent in Nervous Activity,＂Bull, 1943. 
【13】L. Y. Pratt, J. Mostow, and C. A. Kamm,“Direct Transfer of 
 73
【21】D. E. Rumelhart, G. E. Hinton, and R. J. Williams,“Learning 
Internal Representation by Error Propagation in Parallel 
Distributed Processing,＂Vol.1, pp.318-362, D. E. Rumelhart and J. 
L. McClelland (Eds.), M.I.T. Press, Cambridge, MA, 1986. 
【 22 】L. M. Fu,“Rule Generation from Neural Networks,＂ IEEE 
Transactions on System, Vol. 28, No. 8, pp.1114-1124, Man and 
Cybernetics, 1994. 
【23】R. Andrews, J. Diederich, and A. B. Tickle,“Survey and Critique of 
Techniques for Extracting Rules from Trained Artificial Neural 
Networks,＂Knowledge Base Systems, Vol.8, No.6, pp.373-389, 
1995. 
【24】S. Thrun,“Extracting Provably Correct Rules from Artificial 
Neural Networks,＂Technical Report IAI-TR-93-5, University of 
Bonn, Institut für Informatik III, 1993. 
【25】M. W. Craven and J. W. Shavlik,“Using Sampling and Queries to 
Extract Rules from Trained Neural Networks,＂Proceedings of the 
Eleventh International Conference on Machine Learning, pp. 37-45, 
New Brunswick, NJ, 1994. 
【26】E. Pop, R. Hayward, and A. Diedrich,“RULENEG : Extracting 
Rules from a Trained Neural Network Using Stepwise Negation,＂
Queensland University of Technology, Neurocomputing Research 
Centre, 1994. 
【27】G. G. Towell and J. W. Shavlik,“Knowledge-Based Artificial 
行政院國家科學委員會補助國內專家學者出席國際學術會議報告 
                                                         2006 年 11 月 13 日 
報告人姓名   
    章 明 
 
服務機構
及職稱 
 
中原大學機械工程學系教授 
 
     時間 
會議 
     地點 
2006.11.5~2006.11.10 
奧克蘭 
紐西蘭 
本會核定
補助文號
 
會議 
名稱 
 (中文) 第十二屆亞太區非破壞檢測研討會(APCNDT2006) 
 (英文) 12th Asia-Pacific Conference on Non-Destructive Testing 2006 
發表 
論文 
題目 
 (中文)一種應用模糊邏輯技術執行薄膜化學汽相沉積製程的虛擬監控系統
 (英文)A virtual inspection system for PECVD manufacturing process utilizing 
fuzzy logic technique 
附件三
 
表 Y04 
表  Y04 
但一般如超音波等非破壞檢測技術較難達到此要求，故 x 射線與熱像技術結合影像
處理與感測器的應用愈來愈蓬勃，目前國內的研究則仍多偏超音波等技術，在遙測
技術與高溫環境的研究也極缺乏，整體而言，對未來非破壞評估技術的全面發展會
有相當瓶頸，這是值得帶回國內探討的重要子題。 
    此外，傳統 NDT 皆以對成品的瑕疵檢測為主，在這次研討會已經看到在設計
階段引入此觀念，例如針對材料的特性、成品生產及應用等早期考量時即使用非破
壞評估技術，使其更實際且有益於降低成本，自動化技術與人工智慧也開始與 NDT
技術結合，這些都可能是未來努力的方向之一。 
  此次有一位台灣十年前赴紐讀書目前在雪梨大學讀博士的學生與會，這位國外
長大的孩子的主動積極的態度遠勝於台灣學生，係主動來參加這次的研討會，台灣
的研究生則常自認英文不佳而多為被教授要求下才會參加，對此現象深感憂心，建
議指導教授平常即須經常灌輸研究生出國參與國際學術會議的概念，期盼以後學生
都能有自覺，有企圖心接觸全世界的專家學者，有信心建構英文的溝通環境，未來
才會有真正的全球競爭能力。 
整體而言，這次會議提供許多有關非破壞評估檢測之最新應用技術與未來發展
趨勢，亞太地區在此領域的多位專家學者均與會，論文與邀請的專題演講都相當傑
出，參展的廠商也極為踴躍，是一次相當成功的學術研討會，唯一美中不足的是較
看不到此領域在半導體廠與平面顯示器廠的應用。 
 
三、考察參觀活動(無是項活動者省略) 
  會議期間，筆者順便就近參觀了奧克蘭大學工學院，該院有數位中國教授及一
位台灣的博士研究員，研究生亦有數位中國籍與少數台灣籍，整體而言，該院的設
備並不比台灣的國立大學強，但該校全世界排名遠在台大之前，顯示母語發表論文
確佔優勢，不過學生主動性確實較台灣學生為佳，在實驗室的經費不見得比台灣充
裕情形下仍有很好的研究成果，語文能力與主動性一直是台灣研究生較缺乏的部
份，未來須在此方面多為加強。參訪中特別與該院副院長化工材料系高唯教授與機
械系徐旬副教授談及未來合作計畫，其中與高副院長已討論到奈米材料研製與奈米
操控技術發展之合作項目，未來將派研究生互訪，徐教授專長在製造與神經網路，
預定明年七月將來台參訪，故屆時將代為安排申請國科會經費，期盼透過未來的合
作，能對學生的訓練有較大的幫助。 
12th A-PCNDT 2006–Asia-Pacific Conference on NDT, 5th –10th Nov 2006, Auckland, New Zealand
A VIRTUAL INSPECTION SYSTEM FOR PECVD MANUFACTURING
PROCESS UTILIZING FUZZY LOGIC TECHNIQUE
Ming, Prof Chang1, Jen-Cheng, Mr. Chen2, Jia-Sheng, Prof Heh3
1 Department of Mechanical Engineering, Chung Yuan Christian University, Chung Li,
Taiwan 32023
2 Department of Electronic Engineering, Chung Yuan Christian University, Chung Li
Taiwan 32023
3 Department of Information and Computer Engineering, Chung Yuan Christian University,
Chung Li, Taiwan 32023
Abstract
A virtual inspection system for the on-line monitoring of the chemical vapor deposition (CVD)
manufacturing processes utilizing fuzzy logic technique is presented. The system is a hybrid intelligence
system combining the expert system with a neural network. In general a neural network is work as a black
box; it means that the decision process of the system is unknown. Here the main structure is the expert
system, but the expert knowledge library and the initiative learning mechanism are achieved by neural
network with the on-line manufacturing process parameters. Combining the merits of these two techniques,
a powerful and efficient rule extraction system is then established with a fuzzy logic method. These
extracted rules can be used as an on-line diagnosis tool of manufacturing processes that offers a quantitative
analysis of the variation caused by the change of process parameters. Experiments were implemented with a
plasma enhanced chemical vapor deposition (PECVD) process. The obtained results show that the accuracy
of the prediction of the deposited membrane thickness was roughly 90%, which prove this model can
simulate the situation of membrane deposition and the on-line monitoring and e-maintenance of the
manufacturing equipment could be expected with this technique.
1. Introduction
The semi-conductor and TFT-LCD are the two most
important high-technology industrials currently. The
manufacturing processes in the deposition stage of
the twos are similar, with only the substrate material
different. The R&D results in these two products are
compatible and can be applied each other. In general,
there are many factors would influence the
deposited membrane quality. Most of them can be
adjusted by changing the recipe, which are the
process parameters of the working machines.
Finding out a suitable and steady recipe and on-line
real-time controlling the recipe is the target that
process engineers devote to. Unfortunately, these
processes are usually operated with complex and
nonlinear reactions and the process parameters
always drifting and varying [1], thus the
development of on-line inspection and control of
parameters is becoming increasingly important in
these two industrials.
Generally speaking, the recipe adjustment is based
on the accumulation of experiences or learning from
the try and error results. However, the process of
thin film deposition is a very complicate and
nonlinear system. It is very difficult to find out the
relationships between the variation of process
parameters and membrane quality. Therefore, a
hybrid intelligence system was developed here to
simulate the CVD’s processby combining the
expert system with a technique of neural network [2,
3]. The expert system [4] is used for on-line
inspection of manufacturing process and was set up
by extracting out the regular rule between process
inputs and outputs from the trained neural network
[5], which could provide references to engineers for
the need of on-line recipe adjustment. The neural
network model is developed by using parameters of
PECVD process and deposited membrane thickness,
then extracting the ration fuzzy rules between input
and output from neural network with fuzzy rule
extraction algorithm [6, 7].
The data of analysis was collected from the PECVD
machines in the TFT-Array factory of ChungHwa
Picture Tubes (CPT), LTD. The machine parameters
including the rates of all gases, temperature,
pressure and bias of the chamber in membrane
Definition 4(bound of sub-cube):
The bound of a sub-cube is the maximum and
minimum of )(xu in the sub-cube and can be shown
as
bound(cube(w*, Z1Z2 ... Zk) ) = [lbound , ubound]
where the lower bound lbound of the sub-cube is the
minimal u(x) in the sub-cube, and the upper bound
ubound of the sub-cube is the maximal u(x) in the
sub-cube, where
lbound(cube(w*, Z1Z2 ... Zk))
= min{u(x) | xcube(w*, Z1Z2 ... Zk)}
= 00,10,10,1 wwwvwv
n
wkj j
k
wi i
U
i
k
wi i
L
i
jjj
   , (1)
and
ubound(cube(w*, Z1Z2 ... Zk))
= max{u(x) | xcube(w*, Z1Z2 ... Zk) }
=
00,10,10,1
wwwvwv
n
wkj j
k
wi i
L
i
k
wi i
U
i
jjj
   . (2)
The calculations of bounds via above equations are
complicate. Since the bounds of a cube have been
counted when the cube being divided into sub-cubes,
a more effective method to find out the new bounds
of the sub-cube can be achieved with a simpler
calculation from the original bounds of the cube.
That is, for any cube cube(w*, Z1Z2 ... Zk) with
bounds of [lboundk, uboundk], the bounds of the new
sub-cube cube(w*, Z1Z2 ... ZkZk+1) with xk+1 be
sorted can be obtained from













0,
0,
]*,*)1([
]*)1(,*[
],[
1
1
1111
1111
11
k
k
k
L
kkk
U
kk
k
U
kkk
L
kk
kk
w
w
wvuboundwvlbound
wvuboundwvlbound
uboundlbound
(3)
The above equations are much simpler, so that the
values of the bounds of the sub-cube could be real-
time obtained. Through the calculated values of the
bounds, some special cubes are defined as following.
Definition 5(certain cube):
A sub-cube is called a certain cube if its lbound >
vukL and ubound < vukU. That means the output of
the neuron would always fit in the fuzzy range of the
set Zyk for all inputs of the cube.
Definition 6(uncertain cube):
A sub-cube is an uncertain cube if it is not a certain
cube.
2.3. Rules of sub-cube
Since a certain cube’s bound range always fits in the
fuzzy range [vukL , vukU] of Zyk, the fuzzy rule to
decide the output of a certain cube cube(w*, Z1Z2 ...
Zk) can be described as“IF x1 is assigned in Z1 AND
x2 assigned in Z2 AND … AND xk assigned in Zk
then the output of the neuron falls in the range of
Zyk”.
2.4. Algorithm
Bound Decomposition Tree
Input: A neuron’s weights and bias
Output: Extract rules of the neuron
Step 1. Set certain cube sets c1~cp as empty
Set uncertain cube set as cube(w*)
Set rule sets r1~rp as empty
Step 2. Select a cube(w*)a form uncertain cube set
Step 3. Divide the cube(w*)a into m sub-cubes:
cube(w*)a1 ~ cube(w*)am
Step 4. Calculate the bound of cube(w*)a1 ~
cube(w*)am with Eq. (3)
Step 5. Check cube(w*)a1~ cube(w*)am separately,
If the cube is a certain cube of Zyk, add it to
certain cube set ck
Else add it to uncertain cube set
Step 6. If the uncertain cube set is not empty go to
Step 2.
Step 7. For each certain cube sets ck
Transform each cube in ck into a rule and
insert it into the rule set rk.
Step 8. Then, each rule set rk contains the rules
which make the neuron’s output fit in the
range of Zyk.
3. Results and Discussion
3.1. Training data
Here the training data of the neural network, process
parameters and membrane thickness, were collected
from the CVDs' Quality control (QC) department of
CPT. These data has 700 sets of records from
several CVD machines. The raw records contains 27
kinds of parameters, include flow rates of 11 gases,
the maximum, minimum, and average value of DC
bias (DC_BIAS), deliver power (DELIVER_PWR),
reactor temperature (REACTOR_TEMP), reflect
power (REFLECT_PWR), and radio-frequency peak
(RF_PEAK). Five values of membrane thickness
including maximum, minimum, average, uniformity,
and standard deviation are chosen to be the outputs
of the training data.
The correlation values between each input and
outputs were first determined, and only the
parameters which have high correlation with outputs
were chosen as the inputs of the neural network.
Finally 10 inputs were chosen as following
 x1. Average of DELIVER_PWR
 x2. Average of DC_BIAS
