2 
 
圖一、自動化會議記錄器與其相關應用系統架構圖  
 
(三) 文獻探討                                                               
美國NIST (National Institute of Standards and Technology)是自從1996年起舉辦語者辨識評比
(Speaker Recognition Evaluation ,SRE)，每年所有參賽單位均使用NIST所提供的標準對話電話語料
(Conversational Telephone Speech)，其評比項目就包含了語者分段(Speaker Segmentation)。但電話語音
多半是兩個人對話；因此就會議部份；從2002年以來NIST的Rich Transcription在會議室環境中同時佈
置了不同種類的麥克風；並錄製其語音作為資料庫，供有興趣的學者或參賽單位加以索取。而語者的
切換點偵測(語者切割)與群聚，其目的就是在評估一段冗長的會議錄音中標示出who spoke when (又稱
為speaker diarization)，也就是將不同語者講話的區段標示出來，最後一併判定語者性別。在這個評估
中系統將會找出有多少語者在說話並同時加以群聚(clustering)，最後輸出每位語者的群聚語音段落出
來。目前國內投入NIST speaker diarization相關研究的團隊不多[5]，因此也促使了本計畫的研究動機。 
日本一家 IT 公司 Kayac 和日本慶應大學合作開發了一個稱為 “Kage Roi”的產品。此產品結合了
語音辨識、智慧搜尋與投影技術，能夠自動辨識使用者在腦力激盪時所討論的話語，再連接到網路搜
尋相關資料，並且投影在會議室的圓桌上。此產品應用在一般公司會議時是非常有效率的服務，因為
開會過程進行腦力激盪時，不再需要針對關鍵字逐一搜尋資料，能夠大幅增進開會效率，是充分結合
新興人機輸入介面與智慧型分析技術的典範案例。這項產品為人機匯流(Human-Computer Confluence)
在智慧空間的應用，藉由感測使用者談論的話題提供智慧化系統與使用者間的互動，但目前在語言辨
識與自然語言處理上面尚有很大的改善空間。(以上內容節錄自: 資策會創新應用服務研究所（IDEAS）
- FIND 研究群網頁: http://www.find.org.tw/find/home.aspx?page=news&id=5220 )。 
Emanuele Principi 等人提出一套語音介面系統用來增強桌上對話時的相關博物館數位內容搜尋
[11]，該系統是假想在一個博物館的咖啡桌上，已經參觀過文物的遊客若是在談話中提及該博物館的
4 
(2). 語音參數選用:  
倒頻譜係數(Cepstral Coefficients)、線性預估係數 (Linear Prediction Coefficients)、過零率(Zero 
Crossing Rate)、音框能量(Energy)、基本週期(pitch)等。MPEG-7 相關描述子、MFCC 參數。 
 
(3).現有的語者切換點偵測方法分析 
unsupervised 語者切割之研究 [1], [6], [8], [10], [21]。而這些方法主要分為 decoder-based、
metric-based 與 model selection-based 三類: 
Decoder-based Segmentation 
最直覺也是最基本的方法是認定語者切換點發生在靜音段落[8], [15-16]，因此靜音與非靜音段
的邊緣就是本方法之語者切換點結果，一般來說可以在 decoder端採用一個靜音偵測 function即可，
另外直接測量 energy or zero‐crossing rate [8], [32], [35], [55],[56]在利用一個 threshold 判定也是實現
方法。然而實際上，靜音段落語實際語者切換點沒有直接的相關性存在。 
Model selection-based Segmentation 
由 Schwarz[11]所提出的貝氏訊息準則為一以模型複雜度加以 penalize 的可能性準則(likelihood 
criterion)，被廣泛使用在語者切換點偵測上[1-2], [4], [6-7], [10], [16-20] ，然而 BIC 往往需要足夠
的資訊蒐集量才足以判斷出不同語者的切換點，對於短時距的語者片段無法有效的切割[10]。 
Metric-based Segmentation 
此方法在語音串列以平移的方式  [3-4], [8-9], [13-14], [24]，使用許多聲學距離：如 
Kullback-Leibler distance (KL, KL2) [8], [25], generalized likelihood ratio (GLR) [10], [28], 
Mahalanobis distance, ΔBIC 與 Bhattacharyya distance [9] 來評估兩個相鄰 window 的相似度；藉此
產生距離曲線(distance curve)；經由一個低頻濾波器濾除因為雜訊造成的微小波動後[3], [9-10]；取
出區域最大值的時間點做為切換點的輸出。雖然可以有效的加速判斷，但也有許多缺點： 
 需要一個臨界值來選取區域最大值，無法確保所有的語音訊號都適用。 
 只利用鄰近兩個 window 蒐集的資料來判斷相似度。 
 若使用貝氏訊息準則為基礎來做相似度判斷[3]；兩秒鐘以下的切換點無法有效偵測[10]。 
 
(4).基於分類器訓練錯誤率所設計的語者切換點偵測 
不論就 model-selection 法或是 matric-baed 法，都是基於“兩個音段間相似度”來計算出一個分數；
接下來再藉由分數的判斷出是否為同質音段(Homogeneous Segment)。也因此有很多文獻與學者都在
討論相似度的計算準則。然而；資料蒐集量的大小對於相似度的計算效果有關鍵性的影響，也就是說
不論哪一種相似度計算方法都必須蒐集足夠的音訊資訊，否則便無法建立一個足夠反映出音訊本質的
模型。而資料量的收集就音訊來說就是時間的長短，這也就是為何現有演算法無法對短時距的語音段
做有效判斷並加以分段的原因。 
針對這樣的限制，若是可以採用分類器的方式來處理(例如 SVM)，對於不同的語者而言，可以利
用 hyperplane 來將資料分成兩類(+1 與-1)：相反地，如果是同一個語者的語音特徵，hyperplane 將無
法有效的將資料分成兩類。因此我們可以利用 SVM 在訓練的過程中所找到的 hyperplane 用於計算訓
練分類錯誤率(training misclassification rate)來作為語者是否為同一人的判斷，這種錯誤率稱為 SVM 的
training misclassification rate(STMR) [46]，可以分為兩種，其中被當作(-1)類做訓練，辨識時誤判為(+1)
的比率我們定義為 )( ^kmis 。而被當作(+1)類做訓練，辨識時誤判為(-1)的比率我們定義為 )( ^kmis 。 
對於同一個語者的語音特徵而言，由於系統所訓練出來的hyperplane無法有效的將資料分為兩類；
)( ^kmis 與 )( ^kmis 都會相當高；相反地；對於不同語者的語音特徵而言，由於系統所訓練出來的
hyperplane可以有效的將資料分為兩類；因此 )( ^kmis 與 )( ^kmis 都會接近於零。 
 
6 
Miss-classification Rate) [46] 來當作抽離式分群演算法凝聚時的距離。群聚過程中，取出一段語音段；
找出其與所有群聚間之STMR，取代傳統不同群聚之間的距離。而STMR最大的好處在於能夠針對兩
秒以下音段有效分類。 
在語者的切換點已經找出來並已經做過確認與合併動作之後，接下來在群聚部分；本計畫提出新
穎的抽離式比對群聚法取代傳統的階層式群聚法。可以由圖三示意圖來表示。 
 
A AB BC
B C B
C
1 2 3 4 5 6
2 4 6
4
4
C
Step.(a)
Step.(b)
Step.(c)
Step.(d)
2 6
B
1 3 5
A
× × ×oo
×: STMRs 都小於
threshold
O:其中一個STMR 
大於 threshold
1 3 5
A
× o
2 6
B
1 3 5
A
A
 
圖三、抽離式演算法示意圖 
 
(1) 首先將語音資料中的第一個音段取出對其他每一個音段作SVM訓練並分類產生STMRs。如果
STMRs中只要有其一個小於threshold，則意味著這兩段語音是屬於相同語者；則將此音段從語音
資料中抽離出來，並加以合併。在本範例中第1、3、5段被判斷是相同語者的聲音，因此被抽出。 
(2) 將剩下的語音資料段(本範例之第2、4、6段)繼續執行如同 (1) 的比對動作。 
(3) 接著將這些判斷後都視為B語者的音段作群聚合併並抽離；將剩下的語料繼續執行如同(1) 的比
對動作直到最後一個音段。 
(4) 最後若剩下一段語音沒有被合併，擇判斷為獨立一群，如C語者音段所示。直到所有音段都標示
分群為止。 
以 SVM 與 GMM 為基礎之語者聚類 
    在支援向量機為基礎的語者聚類系統，本實驗將切割過後的音段，使用抽離比對分群法取出兩段
音段訓練出一 hyperplane 來判斷，作為聚類演算法，其實驗結果如圖四、表一與表二所示。由實驗結
果，表示本論文提出的方法可以在兩秒鐘的音段仍然得到不錯的群聚效果，針對 3秒以短語音段STMR
提供比 GTMR 更好的 K 值，當段落的長度增加，STMR 與 GTMR 效能皆有所提升，當超過四秒時
STMR 與 GTMR 有幾乎相同的效果，針對 90 段四秒鐘的語料 STMR 可以達到接近 0.82 的效果。 
 
圖四、 STMR 與 GTMR 於不同長度音段的 K 值比較 
 
8 
擷取談話性節目之語
音。 
已分別針對電視談話性節
目、廣播電台錄製六種不同
的題材的談話性節目。 
 
100% 
針對收集到的語音做
人工標記；包含:背景
聲音、語者切換點、群
聚結果...等，以便日後
進行演算法之效能評
估。 
配合錄影畫面，將已將錄製
好的語音標上人工標記，詳
細記錄每一個語者說的時間
點。 
 
100% 
索取國內外其他會議
語音資料庫光碟。 
索取 NIST 2010 會議與音資
料光碟，做詳細分類以便實
驗研究使用。 
NA 100% 
2.雜訊處理
與信號增
強 
收集去雜訊與信號強
化技術之相關論文及
文獻。 
已完成收集相關噪音消除及
語音信號增強之相關論文技
術及其演算法。 
 
100% 
分析會議常見之噪音
與雜訊下之語音訊號
特性。 
已完成會議語音之噪音成分
分析，包含：冷氣機噪音、
投影機風扇聲音。 
NA 100% 
測詴頻譜相減法
(Spectral Subtraction) 
已了解頻譜相減法之理論並
使用 Aurora資料庫之噪聲檔
進行測詴。 
 
100% 
測詴訊號子空間強化
(Signal Subspace 
Enhancement) 
已了解訊號子空間語音增強
之技術並以麥克風錄製音檔
進行測詴。 
 
100% 
10 
提出一套完整的最佳
化參數設定步驟，以期
獲得最佳的效能。 
已完成門檻值參數求取之完
整方法，運用完整實驗結
果，求出最佳解之參數設定。 
 
100% 
4.語者群聚
方法之建
構 
收集語者群聚技術之
相關論文及文獻。 
已參考近五年來國外的語者
群聚技術之相關論文。 
A AB BC
B C B
C
1 2 3 4 5 6
2 4 6
4
4
C
Step.(a)
Step.(b)
Step.(c)
Step.(d)
2 6
B
1 3 5
A
× × ×oo
×: STMRs 都小於
threshold
O:其中一個STMR 
大於 threshold
1 3 5
A
× o
2 6
B
1 3 5
A
A
 
100% 
設計以分類器為基礎
之語者群聚演算法架
構。 
已提出基於分類器訓練錯誤
率結合抽離式比對群聚演算
法，發表於國外會議論文上。 
NA 100% 
評估各種分類器的演
算法效能。 
目前使用過 SVM、GMM、
NNBPN、K-means 評估各種
分類器的效能。 
NA 100% 
6.分析平台
與圖形化
介面 
利用 Matlab 建立會議
語音之分析平台。 
目前已完成第一年初步語者
切換點與語者群聚之會議語
音之分析平台。 
NA 60% 
建立“who spoke when”
與語者群聚結果之圖
形化使用者GUI介面。 
已完成第一年規劃之批次語
音前處理之視窗介面程式，
包含 CUI界面。 
NA 100% 
 
本研究加入多種分類器進行評估，以作為往後相關研究之參考。因此本研究不僅對自動
會議記錄的切換點、群聚有所貢獻，對自然語言相關研究亦相當有價值。在執行本計畫一年的
時間以來，申請三項發明專利、6篇會議論文。採用新穎的群聚方法取代傳統的階層式凝聚法，適於
短時程資料量少的音檔上，且有效的降低運算量，提高分群凝聚後的正確率，進而在國外與國內研討
會上發表。 
 
專利申請 
 尋找不同語者之語音分界之方法、尋找相同語者數位音訊而加以群聚之方法、聲音識別之方法 
 
已發表主要相關會議論文 
1. Po-Chuan Lin*, Yeh-Yi Jui, Tsai-Sung Ying, Yeong-Chin Chen, and Menq-Jion Wu, “Unsupervised 
Speaker Clustering Using SVM Training Missclassification Rate for Short-Duration Speech Signals”, 
the Fourth International Conference on Genetic and Evolutionary Computing (ICGEC-2010), Dec. 
13-15, 2010, Shenzhen, China. 
12 
參考文獻 附件 
[1]. S. Chen and P. Gopalakrishnan, “Speaker, environment and channel change detection and clustering via 
the Bayesian information criterion, “in Proc. DARPA Broadcast News Transcription Understanding 
Workshop, Feb. 1998, pp. 127-132. 
[2]. M. Cettolo, M. Vescovi, Efficient Audio Segmentation. Algorithms Based on the BIC, IN Proc. ICASSP, 
6, 2003, pp. 537-540. 
[3]. Shih-Sian Cheng and Hsin-min Wang "METRIC-SEQDAC: A Hybrid Approach for Audio 
Segmentation," in Proc. International Conference on Spoken Language Processing (ICSLP 2004), Jeju 
Island, Korea 2004. 
[4]. S. S. Cheng and H. M. Wang, “A sequential metric-based audio segmentation method via the Bayesian 
Information Criterion,” Proceedings of Eurospeech 2003. 
[5]. 王新民，蔡偉和，鄭士賢，曾俊翰, “音訊內容之語者自動分段標記”，行政院國家科學委員會專
題研究計畫期中進度報告，96.08.01~99.07.31。 
[6]. B. W. Zhou, and John H. L. Hansen, “Unsupervised audio stream segmentation and clustering via the 
Bayesian Information Criterion,” Proceedings of ICSLP 2000.  
[7]. A. Tritschler and R. Gopinath, “Improved speaker segmentation and segments clustering using the 
Bayesian Information Criterion,” Proceedings of Eurospeech 1999. 
[8]. M. Siegler, U. Jain, B.Raj, and R. Stern, “Automatic segmentation, classification and clustering of 
broadcast news audio,” in Proc. DARPA Speech Recognition Workshop, Feb, 1997,pp. 97-99  
[9]. J.W. Hung, H.M. Wang, and L.S. Lee. “Automatic Metricbased speech segmentation for broadcast news 
via principal component analysis,” Proceeding of ICSLP 2000.  
[10]. P. Delacourt, C. J. Welkens, “DISTBIC, A Speaker-based segmentation for Audio Data Indexing,” 
Speech Communication, v. 32, pp 111-126, 2000.  
[11]. Emanuele Principi, Simone Cifani, Cesare Rocchi, Stefano Squartini and Francesco Piazza, 
“Experimental Study on a Speech-Interfaced System for Fostering Group Conversations in Tabletop  
Scenarios,” ISCAS 2009 (under review).  
[12]. D. Lee, B. Erol, J. Graham, J. J. Hull, and N. Murata, “Portable Meeting Recorder,” in Proc. ACM 
Multimedia, pp. 493–502, 2002. 
[13]. Beigi and S. Maes, “Speaker, channel and environment change detection'', Proceedings of the World 
Congress on Automation,” 1998.  
[14]. Luis Perez-Freire and Carmen García-Mateo, “A Multimedia Approach For Audio Segmentation In Tv 
Broadcast News,” ICASSP 2004. 
[15]. F. Kubala et al., “The 1996 BBN Byblos Hub-4 transcription system,” Proceedings of the Speech 
Recognition Workshop, pp 90-93, 1997.  
[16]. S. Chen et al., “IBM's LVCSR System for Transcription of Broadcast News Used in the 1997 Hub4 
English Evaluation,” Proceedings of the Speech Recognition Workshop, 1998. 
[17]. M. Harris, X. Aubert, R. Haeb-Umbach, and P. Beyerlein, “A study of broadcast news audio stream 
segmentation and segment clustering,” in Proc. EUROSPEECH, Budapest, Hungary, 1999, vol. 3, pp. 
1027–1030.  
[18]. P. Sivakumaran, J. Fortuna, and A. M. Ariyaeeinia, “On the use of the Bayesian Information Cri terion 
in multiple speaker detection,” in Proc. EUROSPEECH, Aalborg, Denmark, 2001, vol. 2, pp. 795–798. 
[19]. M. Cettolo, “Segmentation, classification and clustering of an Italian broadcast news corpus,” in Proc. 
of the 6th RIAO-Content-Based Multimedia Information Access - conference, Paris, France, 2000.  
[20]. A. Raftery, “Bayesian Model Selection in Social Research,” Tech. Reports, Dept. of Stat., Univ. of 
Washington, 1994. 
[21]. R. Bakis et al., “Transcription of broadcast news shows with the IBM large vocabulary speech 
recognition system,” Proceedings of the Speech Recognition Workshop, pp 67-72, 1997. 
[22]. G. Lathoud and I. McCowan, “Location based speaker segmentation,” in Proc. IEEE Int. Conf. 
Acoustics, Speech, and Signal Processing (ICASSP), 2003, pp. 621–624. 
[23]. G. Lathoud, I. A. McCowan, and D. C. Moore, “Segmenting multiple concurrent speakers using 
microphone arrays,” in Proc. Eur. Conf. Speech Commun. Tech. (EUROSPEECH), 2003, pp. 
2889-2892. 
[24]. Laurent Couvreur and Jean-Marc Boite, “Speaker Tracking in Broadcast Audio Material in the 
14 
Change Detection Using SVM Training Misclassification Rate,” IEEE Transactions on Computers, 
Sept. 2007, Vol.56, Issue 9,pp:1212-1244. 
[47]. 張智星，資料分群與樣式辨認，http://mirlab.org/jang/books/dcpr/。 
[48]. 蘇峻慶，錄音資料中的語者切割與分群，國立清華大學電機工程學系，2005，新竹。 
 
 
 
99.11.22(一) 參加 TENCON2009 研討會，當天包含 Oral 與 Poster，當天照片紀錄如下圖所示： 
  
99.11.23(二) 參加 TENCON2009 研討會，並於下午發表論文 4F 413 室，與相關學者交流及討論，並
推廣台灣主辦 2010 年 ISCSLP 之研討會。報告當天照片紀錄如下圖所示： 
 
 
 
99.11.24(三) Technical Sessions、Closing(介紹下一屆 TENCON 2011 研討會主題與地點)，此外參加大
會提供之參觀行程。 
  
 
 
99.11.25(四)前往福岡機器人中心，了解對話型機器人、寵物機器人，3D 攝影互動機器人、機器人模
報告二 
會議名稱；The Fourth International Conference on Genetic and Evolutionary Computing 
 
一、 出國日期：99 年 12 月 11 日起至 99 年 12 月 15 日 
二、 會議地點：深圳 哈爾濱工業大學深圳校區 
三、 會議投稿議題 
 
 
四、 出席會議經過及行程 
99.12.11(六) 
    搭乘班機到澳門轉乘船艇到深圳蛇口轉計程車到達哈爾濱工業大學深圳分校。 
  
 
 
99.12.14(二) 
參加 Keynote Speech II 與 Keynote Speech III。與參展廠商討論 “智慧型生物辨識教學實驗系統” 之語
者辨識相關技術內容，以及教材教具之規格。 
 
 
99.12.15(三) 
與成功大學 王駿發教授、樹德科大 陳璽煌教授、陳毓璋教授、林峻立教授拜會中國科會願深圳先進
技術研究院人員，商討兩岸交換學生短期研究之可能性。 
  
 
99.12.15(四) 搭乘班機由香港返回高雄小港機場。 
 
五、與會心得 
1. 參加 ICGEC 2010 會議，首先由 Ajith Abraham 教授講演 “Nature Inspired Heuristics: Quo Vadis” 
主要談及自然界重要性元啟發式技術解決一些複雜的全局優化問題。從一些流行的算法基礎演變，專
注於一些菌群優化最佳法 bacterial foraging optimization (BFO) 和 music（harmony search）。利用研究
實驗，說明演算法的性能於解決全局優化問題。 
 
2. 另參訪中國科會願深圳先進技術研究院，與研究員討論有關語音處理與機器人設計之研究成果交
流，包括服務型機器人、家用寵物機器人、語音合成分析，聲道模型動畫製作等。其中，語音訊號處
理部分包含：語音檢索技術、麥克風陣列語音處理、以及語音合成之評估方法等主題均與本次執行之
國科會計畫研究方向有直接相關性。 
98年度專題研究計畫研究成果彙整表 
計畫主持人：林博川 計畫編號：98-2221-E-272-002- 
計畫名稱：基於分類器分類能力之自動會議記錄器語者切換點偵測、群聚與識別技術 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 2 0 100% 
篇 含主要相關論文
一篇；次要相關一
篇 
論文著作 
專書 0 0 100%   
申請中件數 3 1 300%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 2 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 0 0 100% 審核中 
研究報告/技術報告 0 0 100%  
研討會論文 4 0 100% 
篇 含主要相關論文一篇；次要相關三
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
 
