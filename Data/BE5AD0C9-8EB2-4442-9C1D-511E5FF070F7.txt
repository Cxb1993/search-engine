Abstract
With all its remarkable performance, the classic turbo code (CTC) suffers from pro-
longed latency due to the relatively large iteration number and the lengthy interleaving
delay required to ensure the desired error rate performance. We present a systematic
approach that solves the dilemma between decoding latency and error rate performance.
Our approach takes both algebraic and hardware constraints into account. From the
algebraic point of view, we try to build large interleavers out of small interleavers.
The structure of CTC implies that we are constructing long CTCs from short CTCs
in the spirit of R. M. Tanner. However, we go far beyond proposing a new class of
CTCs. The proposed inter-block permutation (IBP) interleavers meet all the implemen-
tation requirements for high throughput/parallel decoding such as memory content free,
limited routing complexity and simple memory addressing circuit. The permutations
have simple algebraic forms; they also allow flexible degrees of parallelism and are easily
adaptable to variable interleaving lengths. Even without parallel decoding consideration,
the IBP design is capable of improving the distance property with increased equivalent
interleaving length but not the decoding delay except for the initial blocks.
We proposed the streaming IBP interleavers which are designed for pipeline decoding
architecture which is suitable for high throughput applications but has to pay the price
of larger hardware complexity. In order to achieve optimal trade-off between hardware
complexity and decoding throughput, a dynamic decoder architecture is proposed. We
address the issues of decoding schedule and memory management and introduce novel
early stopping rules that incorporate both CRC code and sign check. With a proper
decoding schedule, memory manager and early stop rule, we are able to reduce the
hardware complexity and achieve improved error rate performance with a shorter average
latency.
In order to describe various iterative decoding schedules and analyze their behaviors,
we develop a graphic tool called multi-stage factor graphs. Based on this new tool
ii
Contents
Chinese Abstract i
English Abstract ii
Contents iv
List of Figures ix
List of Tables xiv
1 Introduction 1
1.1 Turbo decoding . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1
1.2 Performance analysis and graph codes . . . . . . . . . . . . . . . . . . . . 3
1.3 Low latency/high performance interleavers . . . . . . . . . . . . . . . . . 4
1.4 Statement of purpose: main contributions . . . . . . . . . . . . . . . . . 7
1.5 Existing interleavers as instances of IBPI . . . . . . . . . . . . . . . . . . 9
1.6 Overview of chapters . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10
2 Fundamentals of Turbo Codes 13
2.1 Digital communication system . . . . . . . . . . . . . . . . . . . . . . . . 14
2.1.1 Discrete memoryless channel model . . . . . . . . . . . . . . . . . 15
2.1.2 Mapper and de-mapper . . . . . . . . . . . . . . . . . . . . . . . . 16
2.1.3 Error control system . . . . . . . . . . . . . . . . . . . . . . . . . 17
2.2 Convolutional code . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17
iv
3.5.1 The achievable weight-2 lower bound . . . . . . . . . . . . . . . . 55
3.5.2 Analytical results . . . . . . . . . . . . . . . . . . . . . . . . . . . 59
4 Streaming-type inter-block permutation Interleavers 62
4.1 Streaming-type IBP interleaver and the associated encoding storage . . . 63
4.2 Streaming-type IBPTC encoding . . . . . . . . . . . . . . . . . . . . . . 63
4.3 Pipeline decoder and the associated message passing on the factor graph 65
4.4 Bound and Constraints modification for S-IBP interleaver . . . . . . . . . 67
4.5 Codeword weight upper-bounds of streaming-type IBPTC . . . . . . . . 70
4.5.1 Streaming-type upper-bound for weight-2 input sequences . . . . 71
4.5.2 Streaming-type upper-bound for weight-4 input sequences . . . . 74
4.5.3 Interleaving gain comparison . . . . . . . . . . . . . . . . . . . . . 76
4.5.4 Streaming-type IBP algorithm . . . . . . . . . . . . . . . . . . . . 77
4.6 Modified semi-random interleaver . . . . . . . . . . . . . . . . . . . . . . 78
4.7 Simulation Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 78
4.7.1 Covariance and convergence behavior . . . . . . . . . . . . . . . . 79
4.7.2 Error probability performance . . . . . . . . . . . . . . . . . . . . 81
5 Dynamic IBPTC decoder and stopping criteria 89
5.1 IBPTC with early stoppings . . . . . . . . . . . . . . . . . . . . . . . . . 90
5.1.1 System model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 90
5.1.2 Iterative decoder with variable termination time . . . . . . . . . . 92
5.1.3 Graphical representation of an IBPTC and CRC codes . . . . . . 95
5.2 Dynamic decoder and the associated issues . . . . . . . . . . . . . . . . . 97
5.2.1 Dynamic decoder . . . . . . . . . . . . . . . . . . . . . . . . . . . 97
5.2.2 Decoding delay . . . . . . . . . . . . . . . . . . . . . . . . . . . . 98
5.2.3 Memory contention and decoding schedule for multiple ADUs . . 101
5.2.4 Memory management . . . . . . . . . . . . . . . . . . . . . . . . . 103
vi
Bibliography 152
viii
4.2 (a) An S-IBPTC decoding module for 1 iteration; (b) An S-IBPTC pipeline
decoder. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66
4.3 The time diagram of the pipeline decoder with 4 APP decoders or Imax = 2. 68
4.4 A factor graph representation for an S-IBPTC encoded system with the
S-IBP span 1. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 69
4.5 Partition of equivalence classes into subsets; L = 68, Λ = 27, Tc = Ts = 3. 72
4.6 Pre- and post-interleaving nonzero coordinate distributions of weight-4
input sequences that result in low-weight IBPTC codewords. . . . . . . . 75
4.7 Covariance between a priori information input and extrinsic information
output. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 80
4.8 Exit chart performance of the S-IBPTC and the classic TC at different
Eb/N0’s. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 81
4.9 SNR evolution chart behavior of the S-IBPTC and the classic TC at
different Eb/N0’s. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 82
4.10 A comparison of covariance of bit-level and symbol-level inter-block per-
mutation. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 83
4.11 BER performance of the S-IBPTCs with interleaver delay ≈ 800, block
size L = 402 and interleaver span S = 1 and the classic TCs with block
sizes L = 400, 800. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 84
4.12 BER performance of the S-IBPTCs with interleaver delay ≈ 800, block
size L = 265 and interleaver span S = 2 and the the classic TCs with
block sizes L = 400, 800 are also given. . . . . . . . . . . . . . . . . . . . 85
4.13 BER performance of S-IBPTCs and the classic TC with interleaver delay
1320 and the 3GPP interleaver. . . . . . . . . . . . . . . . . . . . . . . . 86
4.14 BER performance of S=IBPTCs and the classic TC with interleaver delay
1320 and the modified semi-random interleaver. . . . . . . . . . . . . . . 87
x
5.11 Average APP DR performance for various decoding schemes and condi-
tions. Curves labelled with infinite memory are obtained by assuming
no memory constraint; “fixed DRs” means no early-stopping condition is
imposed. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 115
5.12 Block error rate performance of a classic TC using various STs; L = 800
bits and Dmax = 30 DRs. . . . . . . . . . . . . . . . . . . . . . . . . . . . 116
5.13 The effect of various STs on the average APP DR performance of a classic
TC with L = 800 and Dmax = 30 DRs. . . . . . . . . . . . . . . . . . . . 117
6.1 (a) Factor graph representation of an LDPC code; (b) grouped factor
graph; (c) node grouping. . . . . . . . . . . . . . . . . . . . . . . . . . . 121
6.2 Multi-stage factor graph for conventional BP. . . . . . . . . . . . . . . . 122
6.3 Multi-stage factor graph for horizontal-shuﬄed BP. . . . . . . . . . . . . 123
6.4 Multi-stage factor graph for the new scheduled BP which reduces cycle
effect. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 124
6.5 Factor graph representation of a CRC- and S-IBPTC-coded communica-
tion link. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 125
6.6 (a) Node grouping; (b) grouped factor graph. . . . . . . . . . . . . . . . . 126
6.7 A multi-stage factor graph representation of an S-IBPTC decoding pro-
cedure. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 127
6.8 A multi-stage factor graph representation of an aggressive S-IBPTC de-
coding procedure. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 128
6.9 (a) The multi-stage factor sub-graph associated with Fig. 6.9; (b) the
multi-stage factor sub-graph associated with Fig. 6.3; (c) the multi-stage
factor sub-graph associated with Fig. 6.4; (d) the initial multi-stage factor
sub-graph associated with Fig. 6.4. . . . . . . . . . . . . . . . . . . . . . 129
6.10 (a) The multi-stage factor sub-graph extracted from Fig. 6.7; (b) the
multi-stage factor sub-graph extracted from Fig. 6.8. . . . . . . . . . . . 130
xii
List of Tables
3.1 (α, β) for some RSC codes. . . . . . . . . . . . . . . . . . . . . . . . . . . 59
4.1 S-IBP Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77
E.1 Puncturing patterns for code rate=3/4. . . . . . . . . . . . . . . . . . . . 152
E.2 Puncturing patterns for code rate=4/5. . . . . . . . . . . . . . . . . . . . 152
E.3 Puncturing patterns for code rate=8/9. . . . . . . . . . . . . . . . . . . . 152
xiv
information needed in its MAP decoding. Such a turbo-like iterative feedback decod-
ing procedure divides the formidable task of maximum likelihood (ML) decoding of the
complete codeword into much simpler subtasks of computing the log likelihood ratio
(extrinsic information) associated with each systematic bit locally and exchanging this
information between each other. It turns out this turbo decoding scheme is very effective
and the resulting performance comes very close to that of the corresponding ML decoder.
Because of its outstanding performance and moderate hardware complexity, the class of
turbo codes has found its way into industrial standards like 3GPP [66, 67, 70], IEEE
802.16 [71], DVB-RCS/RCT [68, 69], etc.
The turbo decoding process was formulated by Hagenauer et al. [47] as a soft-in soft-
out inference process that accepts soft inputs–including a priori and channel values–and
generate soft outputs which consists of the a priori and channel values and the extrinsic
values. The extrinsic value is then used as an a priori value for the ensuing decoding
round. The turbo decoding procedure and the way the extrinsic information is passed is
often referred to as the turbo principle. This principle has been applied to construct and
decode serial concatenated convolutional codes [11], turbo TCMs [14], turbo BCH codes
[73], turbo product codes or block turbo codes (BTCs) [9, 10], turbo Reed-Muller codes
[73], and asymmetric turbo codes [16] (which has different component convolutional
codes and offers better performance). Replacing the inner code of a serial concate-
nated coding system by a differential phase shift keying modulator or signal mapper,
one obtains turbo DPSK [22] or iterative-decoded bit-interleaved coded modulation (ID-
BICM) [24, 23]. Modelling a channel with memory as a linear FIR filter or equivalently
a finite-state machine so that the combination of coding and channel effects becomes
a serial concatenated system with the channel performing inner coding, one can detect
the received signal by iteratively equalizing the channel effect and then decoding, re-
sulting in turbo equalization [17], turbo space-time processing [18] and turbo (iterative)
MIMO detection [25], [112]. By using more than two component codes and multiple
2
output of a component decoder is well approximated by Gaussian random variables and
channel values are also Gaussian distributed when the only noise source is AWGN–an
observation first noticed by Wiberg [55]. As a Gaussian distribution is completely char-
acterized by its first two moments, the density evolution information can be replaced by
SNR transfer. Both [59] and Divsalar et al. [62] use similar SNR measures to study the
convergence of turbo decoders. ten Brink [60, 61] proposed a technique called extrinsic
information transfer (EXIT) chart based on mutual information to describe the flow of
extrinsic information through the component decoders.
A special class of graphs called factor graphs [57, 58] can be used to describe the
behavior of a turbo-like algorithm. A factor graph decomposes the algorithmic structure
into function nodes and variable nodes with edges connecting these two classes of nodes.
McEliece et al. [82] discovered the connection between the turbo decoding algorithm
and the belief propagation (BP) algorithm in artificial intelligence. The graphic and
BP interpretations of the turbo decoder have great impacts and opened new arenas on
many fronts: new decoding algorithms, schedules and new (graph) codes were proposed,
a unified view on iterative decoding algorithm, Kalman filter, the forward-backward,
Baum-Welch, and Viterbi algorithms become possible, connection between turbo codes
and LDPC codes was established, that amongst coding theory, statistical inference,
physics was exploited to the benefits of all research communities involved.
1.3 Low latency/high performance interleavers
The role played by the interleaver in determining the decoding latency, weight dis-
tributions and performance of a CTC is of critical importance. A CTC usually employ
a block-oriented interleaving so that the message-passing process associated with an it-
erative decoder is confined to proceed within a block. The performance of such a CTC
improves as the block size increases. This is in part due to the fact that the range (inter-
leaving length) of the extrinsic information collected for decoding increases accordingly.
4
values through hardwires. Thus the parallel decodable requirement implies that the
interleaver structure must be memory contention free and allow simple interconnecting
network for hardwire routing. Next, practical system design concerns call for flexible de-
grees of parallelism and arbitrary continuous interleaving length so that one has flexible
choice on both the number of ADUs and the frame (packet) size.
Random interleavers, though offer satisfactory error rate performance, incur seri-
ous memory contention. Implementing temporary memory buffer [88] to avoid memory
contention is a viable solution but the storage grows linearly with the number of de-
coding units. Resolving the contention by a sophisticated memory mapping function
[99] requires a table for each interleaving length. The table requires memory storage
for addressing and memory control which results in extra hardware complexity. A large
number of interleaving lengths thus need many memory addressing tables and causes
increased hardware complexity. New industrial standards such as 3GPP [66, 67, 70],
DVB-RCS/RCT [68, 69], IEEE 802.16 [71] do not favor this approach for they have
specified large number of interleavers (interleaving lengths) and applying memory ad-
dressing table seems too complex. A variable length interleaver structure that resolves
memory contention with on-fly generated memory mapping function is an efficient and
wlecome approach.
Some of the existing interleavers like the DRP, ARP and QPP do have simple alge-
braic structures and possess the memory contention free property, the DRP even yield
a minimum distance that is close to the known upper bound, resulting in outstanding
performance especially for frame error rate below 10−6. However, none of them takes
into account the other requirements which are of concern mainly to the circuit design
community.
A fully connected network can be used but the complexity grows in proportion to
the square of the parallelism degree. The average routing length also increases, bringing
about longer routing latency and higher power consumption. The network configuration
6
interleaver structure is general enough to encompass all known important interleavers
as special cases yet viable for generating new solutions.
We summarize the main contribution of the work documented in this report as fol-
lows.
1. We present an unified approach and design flow to build interleavers that not
only have good distance properties but also meet all the major implementation
requirements for high speed parallel turbo decoders. More specifically, the resulting
interleaver structure (i) is maximum memory contention free, (ii) allows efficient
routing network structure and simple signalling circuits, (iii) offers flexible choice in
the degrees of parallelism, (iv) is easily tailored to serve the continuous interleaving
length requirement, (v) supports high-radix decoder structure and (v) includes all
existing good interleavers as its subclasses.
2. For a stream-oriented application, our technique overcomes the dilemma between
increasing the range of message exchange and extrinsic information collection and
reducing the interleaving size (and therefore the decoding delay). It outperforms
CTCs with the same decoding delay and offers new design choices and tradeoffs
that are unavailable for conventional CTC design.
3. We derive codeword weight bounds for weight-2 and weight-4 input sequences.
More importantly, we use these bounds and computer simulations to prove that
the advantages mentioned in 1-2 are achieved with little or no loss in error rate
performance.
4. We present a dynamic corporative pipelined decoder structure that incorporate an
efficient memory manager and a class of highly reliable early-stopping rules. The
proposed decoder structure gives improved performance with reduced latency and
memory requirement.
8
Pre-Permutation
Post-Permutation
1 2 3 4
1 2 3 4
b4,4 b3,1 b2,2 b1,3b2,4 b1,1 b4,2 b3,3 b3,4 b4,1 b1,2 b2,3b1,4 b2,1 b3,2 b4,3
b4,1 b4,2 b4,3 b4,4b2,1 b2,2 b2,3 b2,4 b3,1 b3,2 b3,3 b3,4b1,1 b1,2 b1,3 b1,4
Figure 1.1: An inherent IBP structure can be found in most practical interleavers.
relation between a block and other blocks in the same group does not follow the same
permutation rule. In contrast, product codes and the proposed IBPTCs have much more
regular local interleaving structures. An appropriate regular local interleaving (and dein-
terleaving) structure makes implementation easier and, as mentioned before, provides
properties that are useful for parallel decoding, e.g., (memory access) contention-free
and simple routing requirement. Moreover, with or without parallel decoding, as the
examples in Section 6.2 show, it also results in reduced decoding delay. Regular (identi-
cal) local interleaving structure supports large range of interleavers, makes the resulting
IBPI expandable and minimize the associated implementation cost, e.g. 3GPP LTE
QPP [70], IEEE 802.16 [71].
1.6 Overview of chapters
In order that this report be self-contained we provide major background material
related to our work in Chapter 2. Two fundamental guidelines are provided in Chapter
3 for constructing IBP interleavers with good distance and maximum contention free
properties. The first rule demands that the IBP rule be block-invariant and identical
intra-block permutation e used. The second rule implies that the permutation should
be periodic within its span. Following these and other minor guidelines we are able to
10
coding schedule is important in rendering satisfactory performance, e.g., the horizontal
shuﬄed belief propagation algorithm [107] outperforms conventional belief propagation
algorithm [57] in terms of the number of iterations required to achieve a desired er-
ror rate performance. Multi-stage factor graphs can be used to show the cycle effect
and design new decoding schedule to avoid short cycles. We propose a novel decoding
schedule for a streaming IBPTC that requires much less memory storage and slightly
increased computation but yields similar error rate performance. Finally, in Chapter 8
we summarize the main results of our work.
12
Information
Source
CRC Code
Encoder
Channel
Encoder
Modulator
De-modulator
Channel
Decoder
Error
Detector
Information
Sink
}{
i
d=D
Channel
Distortion
Noise
}{ ju=U }{ lc=C )(ts
)(tr}{ ly=Y}ˆ{
ˆ
ju=U}
ˆ{ˆ id=D
(a)
Symbol
Mapper
Symbol
De-mapper
}{ ks=S
}{ kx=X
Modulator De-modulator
S X
kα
(c)
kn
ks kx
)(ts )(tr
)(tα
(b)
)(tn
Waveform Channel
Discrete Channel
Figure 2.1: (a) Block diagram of a generic digital communication system; (b) block dia-
gram of a simplified channel model; (c) block diagram of a discrete memoryless channel
model.
2.1 Digital communication system
Fig. 2.1 (a) shows a generic digital communication system block diagram which
includes three parts: 1) channel; 2) modulation, demodulation, mapper and de-mapper;
3) error correction and detection. Channel imposes non-ideal effects and distorts the
modulated continuous waveform. Demodulator and de-mapper convert the distorted
waveform into samples. Error correction recovers these samples and renders decoded
sequences. At last error detection verifies the correctness of decoded sequences. The
following subsections will elaborate these three parts.
14
The shadowing effect is a long-term effect and generally lasts more than one coding
block. The effect can be modelled into the noise strength. Therefore the simplified
memoryless discrete channel model properly covers most scenarios and this report will
applied this model as our simulation assumption.
2.1.2 Mapper and de-mapper
Mapper bridges channel encoder and modulator; de-mapper generates log-likelihood
or log-likelihood ratio for code bits corresponding to a sample xk. Mapper maps n code
bits into a modulated symbol Sm ∈ S by a mapping rule
Φ : {bm,0, bm,1, . . . , bm,n−1} → Sm, (2.2)
where bi,j ∈ {0, 1} and |S| = 2n. Based on the mapping rule, de-mapper can apply
maximum a posteriori (MAP) algorithm to render log-likelihood ratio of the tth code
bit corresponding to the ith mapping bit as
L(ct) = log
∑
bm,i=0,bm,j ,j 6=i p(Sm|xk)∑
bm,i=1,bm,j ,j 6=i p(Sm|xk)
. (2.3)
L(ct) is generally applied as yt to the following channel decoder.
We further consider a binary phase shift keying (BPSK) and the mapping rule is
Φ :
{
b0,0 = 0→ S0 = +1
b1,0 = 1→ S1 = −1 . (2.4)
If P (ct = 0) = P (ct = 1) = 0.5 and the pdf of x given Sm and channel attenuation α is
pX|Sm,α(x|Sm, α) =
1√
2piσ2
exp−
(x−αSm)
2
2σ2 (2.5)
with σ2 = N0/2, the log-likelihood ratio in (2.3) with k = t becomes
L(ct) = log
p(S0|xt, αt)
p(S1|xt, αt) = log
pX|S0,α(xt|S0, αt)
pX|S1,α(xt|S1, αt)
+ log
p(S0)
p(S1)
=
4αtxt
N0
. (2.6)
16
F0 F1 F2 FmFm-1
c
Q0 Q1 Q2 Qm-1
......
......
......
u
Qm
......
......
(a)
Fm Fm-1 Fm-2 F0F1
c
Qm Qm-1 Qm-2 Q1
......
......
......
u
Q0
......
......
(b)
1σ 2σ 3σ mσ
1σmσ 1−mσ 2−mσ
Figure 2.2: (a) The controller canonical form; (b) The observer canonical form.
the only only element with its inverse and F2[D] is a ring.
F2(D) denotes the field of binary rational functions. Each element in F2(D) is ex-
pressed by x(D)
y(D)
, where each pair x(D), y(D) ∈ F2[D] with y(D) 6= 0. Apparently all
elements x(D)
y(D)
∈ F2(D) are invertible and they form a field.
We further denote by Fa×b2 [D] and F
a×b
2 (D) the a× b matrix of ring of binary polyno-
mials and the a×bmatrix of the field of binary rational functions respectively. All entries
in Xa×b(D) ∈ Fa×b2 [D] and Y a×b(D) ∈ Fa×b2 (D) belong to F2[D] and F2(D) respectively.
If b = 1, the notations are simplified as Fa2[D] and F
a
2(D).
18
Definition 1 A code rate R = a/b (binary) convolutional code encoder over the field of
rational functions F2(D) is a linear mapping
Φcc : F
a
2(D) → Fb2(D)
u(D) 7→ c(D)
which can be represented as
c(D) = u(D)G(D),
where G(D) ∈ Fa×b2 (D) is an a× b transfer function matrix of rank a and c(D) is a code
sequence generated from the information sequence u(D).
Systematic and recursive convolutional code is of our interests. The systematic code
has information bits in a code sequence and the transfer function matrix G(D) can be
G(D) = [Ia R(D)], (2.12)
where R(D) ∈ Fa×(b−a)2 (D). The recursive code generates large number of nonzero code
bits if u(D)Q−1(D) /∈ Fa2[D]. For both structures, we gives definitions as below.
Definition 2 A rate R = a/b convolutional code encoder whose information sequence
appears unchanged among the code sequences is called a systematic encoder.
Definition 3 A rate R = a/b convolutional code encoder whose transfer function matrix
G(D) has Q(D) 6= Ia is a recursive encoder.
2.2.3 State space, state diagram and trellis representation
The encoders shown in Fig. 2.2 are finite state machines and the values in regis-
ters characterize the state space Σ, i.e. σ = (σ1, σ2, · · · , σm) ∈ Σ. When information
sequence is input, the state varies with time. In order to record the state change, we
20
00
01
10
11
00
01
10
11
t
σ
1+t
σ
21σσ
0/00
1/01
1/10
0/11
0/11
1/10
0/00
1/01
(c)
00
21σσ
01
11
10
211
/ ccu
0/00
1/01
0/11
0/00
1/01
1/10
0/11
1/10
(b)
211
/ ttt ccu
1σ 2σ
1
tu
1
tc
2
tc
(a)
Figure 2.3: (a) The encoder associated with G(D) = (D + D2, 1 + D + D2); (b) state
diagram; (c) trellis segment.
Figs. 2.3 (b) and (c) depict the graphical representations. According to eqns. (2.13) and
(2.14), we draw the state diagram shown in Fig. 2.3 (b). A trellis segment associated with
σt and σt+1 is plotted in Fig. 2.3 (b). Given a initial state condition and a termination
scheme, a complete trellis diagram can be obtained by connecting these trellis segments.
2.2.4 Termination
Tail-padding and tail-biting are two popular termination methods for a convolutional
code encoding an input information sequence of finite length L. The tail-padding ter-
minates codeword at a specific state by padding bits and avoids an unknown end state
on decoder side. The tail-biting keeps the initial state and end state the same and the
decoder can guess the both states. However the first scheme decreases code rate and the
second scheme requires extra computation.
The tail-padding assigns extra bits behind an information sequence to terminate the
end state to all zero state . The bit assignment is different for recursive and non-recursive
convolutional codes. For the non-recursive code, we pad a · m zeros behind an input
22
The encoder acquires the zero-state solution σL,[zs] by inputting information sequence
and calculates the initial state σ0 by eqn. (2.19). Then the encoder applies the initial
state σ0 to generate a codeword.
The length of input information determines if the tail-biting termination is applicable.
An invertible matrix I + AL is a necessary condition to calculate the initial state σ0.
There exists an L such that I + AL = 0. The tail-biting can not generate the initial
state and fails. Take 3GPP turbo code [66] as an example. The state matrix is A = 0 0 11 0 0
0 1 1
 and A7 = I3. It can not encode information sequence when the length is
multiple of 7.
2.2.5 Soft output decoding algorithm for convolutional code
Soft output convolutional code decoding algorithms are applicable for iterative decod-
ing and of our interest. Popular convolutional code decoding algorithms can be roughly
classified into three classes: maximum a posteriori (MAP) algorithm [45], Viterbi algo-
rithm [49, 50] and sequential decoding algorithm [74]. The MAP algorithm sums up the
likelihoods of all codeword sequences corresponding to a symbol at time t and chooses
the most likely symbol as a decision. The algorithm achieves the best symbol error
rate performance but requires the highest complexity due to large amount of codewords.
Thanks for the independent noise corruption assumption, Bahl et al. [45] provides a
simplified decoding algorithm and the complexity is affordable. The Viterbi algorithm
is a well-known maximum likelihood decoding algorithm. Due to independent noise
corruption assumption, the algorithm can discard codewords with less likelihood and
minimize the complexity as searching a most likely codeword. However the complexity
of both algorithms are linear to the number of state and the state grows exponentially
with the length of the constraint length or the number of registers. In fact, only partial
codeword sequences are necessary to record at high SNR and the complexity can be
further minimized by sequential decoding algorithm. Sequential decoding algorithm is a
24
segment. The likelihood of information symbol ut = {u0t , u1t , · · · , ua−1t } given Y is
p(ut|Y)
=
1
p(Y)
∑
σt,σt+1∈Σ
∑
c∈C(σt,ct,ut,σt+1)
p(Y, c)
=
1
p(Y)
∑
σt,σt+1∈Σ
∑
c∈C(σt,ct,ut,σt+1)
p(Y[0,t), c[0,t), σ
t)p(yt, ct, σ
t+1|σt,Y[0,t), c[0,t))
p(Y[t+1,L), c[t+1,L)|σt+1,Y[0,t+1), c[0,t+1))
=
1
p(Y)
∑
σt,σt+1∈Σ
∑
c∈C(σt,ct,ut,σt+1)
p(Y[0,t), c[0,t), σ
t)p(yt, ct, σ
t+1|σt)p(Y[t+1,L), c[t+1,L)|σt+1)
=
1
p(Y)
∑
σt,σt+1∈Σ
∑
c∈C(σt,ct,ut,σt+1)
p(Y[0,t), c[0,t), σ
t)p(yt|ct, σt+1, σt)p(ct, σt+1|σt)
p(Y[t+1,L), c[t+1,L)|σt+1)
=
1
p(Y)
∑
σt,σt+1∈Σ
p(Y[0,t), σ
t)p(yt|ct)p(ut, σt+1|σt)p(Y[t+1,L)|σt+1)
=
1
p(Y)
∑
σt,σt+1∈Σ
α(σt)γ(ut)β(σ
t+1), (2.20)
where Y[e,f) = {ye,ye+1, · · · ,yf−1}, c[e,f) = {ce, ce+1, · · · , cf−1}, α(σt) = p(Y[0,t), σt),
γ(ut) = p(yt|ct)p(ut, σt+1|σt) and β(σt) = p(Y[t,L)|σt). The likelihood function p(ut, σt+1|σt)
can be further decomposed as
p(ut, σ
t+1|σt) = p(ut)δ(ut, σt+1|σt), (2.21)
where p(ut) is the a priori likelihood and δ(ut, σ
t+1|σt) is an indicator function.
δ(ut, σ
t+1|σt) =
{
1 ,B(σt,ut, σt+1) ∈ T
0 , otherwise
. (2.22)
α(σt) and β(σt) can be recursively calculated and eqns. (2.23) and (2.24) show the
26
The Log-MAP algorithm can be acquired by transforming the likelihood into the
log-likelihood ratio and the relation is
L(uit) = log
p(uit = 0|Y)
p(uit = 1|Y)
. (2.26)
The ratio can be computed on the log-domain and the corresponding computation can
be further simplified as
L(uit) = log
∑
u
j
t ,j 6=i
∑
σt,σt+1∈Σ α(σ
t)γ(ut|uit = 0)β(σt+1)∑
u
j
t ,j 6=i
∑
σt,σt+1∈Σ α(σ
t)γ(ut|uit = 1)β(σt+1)
= log
∑
u
j
t ,j 6=i
∑
σt,σt+1∈Σ exp
αˆ(σt)+γˆ(ut|uit=0)+βˆ(σt+1)∑
u
j
t ,j 6=i
∑
σt,σt+1∈Σ exp
αˆ(σt)+γˆ(ut|uit=1)+βˆ(σt+1)
, (2.27)
where αˆ(σt) = logα(σt), βˆ(σt) = log β(σt), γˆ(ut|uit) = log γ(ut|uit) and γ(ut|uit) =
p(yt|ct)p(ut, uit, σt+1|σt). The forward and backward recursions become
αˆ(σt) = log
∑
σt−1
expαˆ(σ
t−1)+γˆ(ut−1) (2.28)
βˆ(σt) = log
∑
σt+1
expβˆ(σ
t+1)+γˆ(ut) . (2.29)
Both recursions can be acquired by the following function [48]
max∗(A,B) = log
(
expA+expB
)
= max(A,B) + log
(
1 + exp−|A−B|
)
(2.30)
and the function composes of a maximization and a compensation function which can
be implemented by a look-up-table. Although log and exponential are high complexity
operations, both operations can be implemented by less complexity operation. The
function also can be recursively calculated as
max∗(A,B,C) = max∗(A,max∗(B,C)), (2.31)
and the log-sum on multiple terms is capable. Therefore the log-MAP algorithm trans-
fers the multiplication and addition on real domain into addition, maximization and
compensation on the log domain.
28
Recursive Systematic
Convolutional Code
Encoder
Recursive  Systematic
Convolutional Code
Encoder
Interleaver
u
c0
c1
c2
(a)
(b)
APP Decoder 1
APP Decoder 2
Interleaver Interleaver
Y1
Y0
Y2
De-Interleaver
1
exL
2
exL
1
priorL
2
priorL
Figure 2.4: (a) The block diagram of turbo code encoder; (b) the block diagram of turbo
code decoder.
2.3.1 Interleaver
The interleaver determines the error floor and an interleaver and component code joint
design improves the error floor shape. The design and performance of interleaver is the
focus of this report and is addressed in Chapters 3, 4 and 5. The following subsections
will describe the encoding and decoding methodologies.
2.3.2 Encoder
Turbo code encoder, shown in 2.4 (a), composes of two recursive systematic con-
volutional codes and an interleaver. The interleaver permutes information sequence to
30
extrinsic information. The decomposition is shown as follows.
L(uit)
= log
∑
u
j
t ,j 6=i
∑
σt,σt+1∈Σ α(σ
t)γ(ut|uit = 0)β(σt+1)∑
u
j
t ,j 6=i
∑
σt,σt+1∈Σ α(σ
t)γ(ut|uit = 1)β(σt+1)
= log
∑
uit=0,u
j
t ,j 6=i
∑
σt,σt+1∈Σ α(σ
t)p(yt|ct)p(ut)δ(ut, σt+1|σt)β(σt+1)∑
uit=1,u
j
t ,j 6=i
∑
σt,σt+1∈Σ α(σ
t)p(yt|ct)p(ut)δ(ut, σt+1|σt)β(σt+1)
= log
p(yit|cit = 0)
p(yit|cit = 1)
+ log
p(uit = 0)
p(uit = 1)
+ log
∑
uit=0,u
j
t ,j 6=i
∑
σt,σt+1∈Σ α(σ
t)
(∏
0≤j<b,j 6=i p(y
j
t |cjt)
)(∏
0≤j<a,j 6=i p(u
j
t)
)
δ(ut, σ
t+1|σt)β(σt+1)∑
uit=1,u
j
t ,j 6=i
∑
σt,σt+1∈Σ α(σ
t)
(∏
0≤j<b,j 6=i p(y
j
t |cjt)
)(∏
0≤j<a,j 6=i p(u
j
t)
)
δ(ut, σt+1|σt)β(σt+1)
= Lc(u
j
t) + Lprior(u
j
t) + Lex(u
j
t), (2.35)
where Lc(u
j
t) = log
p(yit|cit=0)
p(yit|cit=1)
and Lprior(u
j
t) = log
p(uit=0)
p(uit=1)
. Then the APP decoder simply
generates Lex(u
j
t) by
Lex(u
j
t) = L(u
i
t)− Lc(ujt)− Lprior(ujt). (2.36)
Non-binary iterative decoding algorithm
The decomposition is derived from the eqn. (2.20).
p(ut|Y)
=
1
p(Y)
∑
σt,σt+1∈Σ
α(σt)γ(ut)β(σ
t+1)
=
p(ut)p
(
y
[0,a)
t |c[0,a)t
)
p(Y)
∑
σt,σt+1∈Σ
α(σt)p
(
y
[a,b)
t |c[a,b)t
)
δ(ut, σ
t+1|σt)β(σt+1)
= p(ut)p
(
y
[0,a)
t |c[0,a)t
)
pex(ut), (2.37)
where y
[i,j)
t = {yit, yi+1t , · · · , yj−1t }, c[i,j)t = {cit, ci+1t , · · · , cj−1t } and c[0,a)t = ut due to the
systematic encoding. The extrinsic information pex(ut) is acquired by
pex(ut) =
p(ut|Y)
p(ut)p
(
y
[0,a)
t |c[0,a)t
) . (2.38)
32
: Convolutional code
: Equality
Interleaver
Convolutional code
Convolutional code
0
σ
1
σ
2
σ
3
σ
4
σ
5
σ
6
σ
7
σ
8
σ
0
0c
0
1c
0
2c
0
3c
0
4c
0
5c
0
6c
0
7c
1
0c
1
1c
1
2c
1
3c
1
4c
1
5c
1
6c
1
7c
2
0c
2
1c
2
2c
2
3c
2
4c
2
5c
2
6c
2
7c
0~
σ
1~
σ
2~
σ
3~
σ
4~
σ
5~
σ
6~
σ
7~
σ
8~
σ
0
0u
0
1u
0
2u
0
3u
0
4u
0
5u
0
6u
0
7
~c
Figure 2.5: An exemplary factor graph of turbo code.
Fig. 2.5 provides a factor graph example for turbo code. The code applies one bit
to terminate both convolutional codes. 7 information bits are encoded and 25 code bits
are generated; the code rate is 7/25. The graph composes of two kinds of factor nodes:
convolutional code and equality. The code node connect information bit, code bits and
states of convolutional code. The equality node connect information bit and interleaved
information bit. Both APP decoders generate the extrinsic information. Then APP
decoder passes the generated extrinsic information through the equality node to the
interleaved or de-interleaved coordinates for the other APP decoder. The graph also
shows that decoder does not generate and exchange the extrinsic information of the
terminating bits. The iterative decoding process is visualized and turbo code structure
is understood.
34
information source only based on the statistic and the independent output assures the
input to the next APP decoder is independent. However the independence assumption
does not always hold and the input information is correlated during the iterative pro-
cess. Although we acquire an estimated SNR, the actual minimum SNR is higher for
the correlated source. We take turbo code as an example. The error rate curves are
not steep when interleaver length is small due to highly correlated input information.
Therefore the method fails as the interleaver is small. Fortunately both assumptions
asymptotically holds for a large code and the method is still quite helpful in searching
a good code.
We describe the relation between the variance and the mutual information. Assume
the Gaussian distributed random variable and information bit random variable are G
and U . Note the conditional probability density function of a priori information G = g
given the information bit U = u by
pG(g|u) = 1√
2piσ2G
exp
−
(
g−
uσ2
G
2
)2
2σ2
G , (2.42)
and pG(g|u) = pG(−g|u) expgu. The mutual information IG between the a priori infor-
mation and information bit is
IG = I(G;U)
=
∑
u
∫ ∞
−∞
pG,U(g, u) log2
pG,U(g, u)
pG(g)pU(u)
dg
=
1
2
∑
u
∫ ∞
−∞
pG|U(g|u) log2
pG(g|u)
1
2
pG(g|U = 0) + 12pG(g|U = 1)
dg, (2.43)
where 0 ≤ IG ≤ 1. The relation between the variance σG and IG is represented as
IG(σG) = 1−
∫ ∞
−∞
1√
2piσ2G
exp
−
(
g−
σ2
G
2
)2
2σ2
G log2(1 + exp
g)dg. (2.44)
We can apply Eqn. (2.44) for the a priori information and extrinsic information to
generate input random variable for decoder and calculate the corresponding output
mutual information.
36
Chapter 3
Modularized Interleavers and Their
Properties
We have described most building blocks of a turbo code in the preceding chapter. In
[?], [?], we have proposed an interleaver structure based on the concept of inter-block
permutation (IBP) and shown that the structure yields good distance properties when
it is used to construct turbo codes. A general IBP interleaver [?] encompasses many
existing interleavers as special subclasses. It is built upon smaller interleavers and a re-
permutation is applied on these interleavers to construct a larger interleaver. By using a
suitable IBP rule, an IBP turbo code (IBPTC) can possess good distance properties. It
is therefore reasonable to conjecture that the distance spectrum of an IBPTC applying
separate encoding would offer some desired properties.
Consider a reasonable good interleaver of size N . Partitioning an N -bit group into
L = dN/W e or bN/W c-bit blocks, we find the interleaving rule renders an inter-block
permutation structure like that shown in Fig. 1. Such a structure can be found in other
codes such as product codes (block turbo codes, BTCs). Hence both classic convolu-
tional turbo codes (CTCs) and BTCs can be considered as subclasses of the recently
proposed inter-block permuted (IBP) turbo codes (IBPTCs) [?] whose interleaver per-
form consecutive intra- and then inter-block permutations.
However, an interleaver used in a classic CTC, after the above virtual partition,
usually yields a non-regular local interleaving structure, i.e., the interleaving relation
38
Tail-Biting
Convolutional Code
Encoder
Tail-Biting
Convolutional Code
Encoder
Interleaver
u
c0
c1
c2
Segmentator
Segmentator
Figure 3.1: The block diagram of inter-block permutation turbo code encoder.
analyzing the effects of selected particular system parameters on this general bound we
obtain some useful design guidelines. We apply a simplified partition rule presented
in [33] and a regular permutation function to derive the bound. We also examine some
special cases and evaluate distance lower bounds of the weight-2 error events for different
block lengths.
3.1 Inter-block permutation turbo code
Fig. 3.1 shows the block diagram of an IBPTC encoder. The main difference is that
the encoder includes extra two segmentators which partition information sequence and
permuted information sequence into multiple short blocks in accordance with the block
length of an IBP interleaver. The recursive systematic convolutional (RSC) code encodes
these blocks and can apply these three termination methods, namely continuous [5], tail-
padding and tail-biting [7]. In accordance with these options, we define a continuous
IBPTC (C-IBPTC) as one that encodes each data block using the end state of the
previous coded block as the initial state and adds the tail-bits only for the last data
block. On the other hand, a discontinuous IBPTC (D-IBPTC) encodes each data block
individually, either by appending the tail-bits at the end of a block or by using the tail-
biting encoding . We refer to the former class as the tail-padding IBPTC (TP-IBPTC)
while the latter class as the tail-biting IBPTC (TB-IBPTC).
40
......
1-Nintra,Πintra,2Πintra,1Πintra,0Π
interΠ
0u 1u 2u 1-Nu
2u′1u′0u′ 1−′Nu
...... R
1-Nintra,Π
R
intra,2Π
R
intra,1Π
R
intra,0Π
R
interΠ
0u 1u 2u 1-Nu
2u′1u′0u′ 1−′Nu
(a)
......
......
......
......
(b)
...... S,2
1-Nintra,Π
S,2
intra,2Π
S,2
intra,1Π
2,S
intra,0Π
S
interΠ
0u 1u 2u 1-Nu
2u′1u′0u′ 1−′Nu
......
(c)
S,1
1-Nintra,Π
S,1
intra,2Π
S,1
intra,1Π
S,1
intra,0Π
......
......
R
intraΠ
intraΠ
S,1
intraΠ
S,2
intraΠ
Figure 3.2: (a) Inter-block permutation interleaver; (b) Reversed inter-block permutation
interleaver (c) Sandwich inter-block permutation interleaver.
Πinter and Π
−1
inter are further characterized by fn(i, j), fb(j), f
d
n(i, j), f
d
b (j), and the
permutation rules are
piinter(i, j) = (fn(i, j), fb(j)) (3.3)
pi−1inter(i, j) = (f
d
n(i, j), f
d
b (j)), (3.4)
or
piinter(i) = fn(||i||L, |i|L) · L+ fb(|i|L) (3.5)
pi−1inter(i) = f
d
n(||i||L, |i|L) · L+ fdb (|i|L). (3.6)
42
permutation interleaver is constructed by ΠSibp = Π
S,2
intra ◦ΠSinter ◦ΠS,1intra shown in Fig. 3.2
(c). Because ΠS,2intra only permutes symbols in each block to the same block, there exists
a Π′inter = Π
S,2
intra ◦ ΠSinter and ΠSibp = Π′inter ◦ ΠS,1intra which is identical to an inter-block
permutation interleaver. The properties of ΠRibp and Π
S
ibp are equivalent to that of Πibp
and the discussion of ΠRibp and Π
S
ibp are omitted.
3.3 IBP properties
This section discusses the properties of an inter-block permutation Πinter while an
intra-block permutation Πintra is unknown, where Πintra,i = Πblock ∀i. Denote by C =
{c0, c1, c2} a turbo code codeword associated with an input information sequence u,
where cj is the output parity-bit sequence of the jth component code while c0 = u
represents both the input sequence and the systematic (uncoded) output sequences. A
sequence cj also can be partitioned into N blocks corresponding to an input sequence
u and the corresponding sequence is cj = {cj0, cj1, · · · , cjN−1}. These sequences are not
necessary with the same length and various lengths do not influence our results.
Define two equivalent relations “∼” and “∼=” on the set of integers Z by
|i− j|Tc = 0 ⇐⇒ i ∼ j
||i||L = ||j||L ⇐⇒ i ∼= j
where i, j ∈ Z, Tc is the period (to be defined later) of an RSC code. Clearly, i  j or
i  j means i is not equivalent to j in either sense. The first relation i ∼ j indicates
(i, j) pair causing a finite weight codeword corresponding to the RSC code with period
Tc, and distance property discussion mainly focuses on this kind of finite weight error
event. The second relation i ∼= j indicates that (i, j) pair is in the same block and
simplifies our discussion.
44
then implies that the free distance of Cibp, dfree(Cibp) satisfies
dfree (Cibp) =
∑
i
∑
j
wt(c¯
i
j) ≥
∑
i
wt
(⊕
j
Ml(c¯
i
j)
)
≥ dfree (Cblock) (3.9)
For a D-IBPTC, the sub-codewords c¯ji associated with each input block automat-
ically satisfy the requirement on all blocks. Since both tail-padding and tail-biting
convolutional codes are linear codes, we have
Corollary 3.1 For a classic TC CTC, the corresponding D-IBPTC Cibp has a free dis-
tance greater than or equal to that of Cblock if Πinter is a Type I permutation.
3.3.2 Second property: periodic permutation
The encoder of an RSC code acts like a scrambler and can be realized by using a shift
register with both feedback and feedforward branches shown in Fig. 2.2. It is obvious
that such an encoder would have a periodic impulse response. The rate 1/2 RSC code
is specified by the transfer matrix [1, Q−1(D)F (D)], where Q(D), F (D) ∈ F2(D) and
Q(D) is usually a primitive binary polynomial of degree m. The period of the impulse
response of the non-systematic part, Q−1(D)F (D), is given by Tc whose maximum value
is 2m − 1. We denote by uij = {uk = 1, k = i, j} a weight-2 input sequence whose only
nonzero elements are at coordinates i and j; the corresponding codeword is denoted
by Cij. Therefore, Tc is also the smallest integer such that u
ij, i ∼ j, will generate a
finite-weight output parity sequence. It is thus easy to show [32]
Lemma 3.1 Let uij be an input sequence to a scrambler with period Tc and scrb(u
ij)
be the corresponding output parity sequence. If i ∼ j, then there exists α ∈ N and β ∈ Z
such that
wt
(
scrb(uij)
)
= α|i− j|/Tc + β, (3.10)
where N is the set of positive integers and α, β depend on the encoder (scrambler) struc-
ture.
46
fdn(p, g) or equivalently, by fn(r, g). Obviously, the codeword weight of the weight-2
information sequence upi
−1
ibp
(g)pi−1
ibp
(h) is large, if u′gh with g  h. As we are concerned
with w2,min, only those weight-2 sequences with nonzero coordinate pairs in the set,
{(g, h)|g ∼ h ∼ j, for some j and g, h ∈ Sjl for some l} have to be considered.
Assume that ∀ j, l all pairs {(g, h) ∈ Sjl} satisfy the inequality |g − h| > Tc · Ts. For
any pair (g, h) ∈ Sjl, g < h and the associated interior set V = {g+1, g+2, · · · , h−1}, we
have |V | > Tc ·Ts. If Sjl∩V 6= φ, there exists a pair (g′, h′) ∈ Sjl, where |g′−h′| < |g−h|.
Otherwise, if Sjl∩V = φ, by the pigeonhole principle [75], there exists a set Suv such that
|Suv
⋂
V | > 2, which implies that there is a pair (g′, h′) ∈ Suv, where |g′ − h′| < |g − h|.
As both cases lead to contradictions, we conclude that there exists a pair (g, h) ∈ Sjl
for some j, l, such that |g − h| ≤ Tc · Ts. Since it is always possible to find Πintra such
that |pi−1ibp(g)− pi−1ibp(h)| = Tc, (3.12) and (3.13) then imply that w2,min ≤ 2 + α((Tc + Tc ·
Ts)/Tc) + 2β = 2 + α(Ts + 1) + 2β.
Theorem 3.2 indicates that lack of control on the intra-block permutation imposes
an upperbound for w2,min which an IBPTC can achieve. The coordinates of nonzero
elements of the interleaved sequence u′ij with i ∼= j will either remain in the same block
or be in the different blocks with probabilities close to 1/Ts and (Ts − 1)/Ts when all
coordinates in one block are evenly permuted to these blocks. The resulting codewords
for the latter case are very likely to have large weights while those for the former case
have smaller weights with the worst-case weight of 2 + 2α+ 2β only.
To avoid generating low weight codewords for uij, we first notice that (3.12) im-
plies w˜2,min ≥ 2 + α(δmin/Tc) + 2β. The IBP along with the intra-block permuta-
tion determines the relation between |i − j| and |piibp(i) − piibp(j)|, and their struc-
tures can be optimized to maximize δmin. For a pair of coordinates (i, j) ∈ sm, if
the integer-valued function fdn(p, k) is injective and satisfies the locally-periodic prop-
erty for some p, fdn(p, k) = f
d
n(p, k + nTs), for L|k|L ≤ n + kTs < L(|k|L + 1), then the
requirements, i ∼= j and piibp(i) ∼= piibp(j) imply |piibp(i) − piibp(j)|Ts = 0 and therefore
48
We denote by uk the weight-1 sequence whose only nonzero element is at coordinate
k and by s˜crb(·) the RSC encoder that encodes a length-L sequence and terminates
at the all-zero state using proper tail-bits. Based on the above definitions, we further
define, for 0 ≤ i, j < L
f1(i, j) =
{
α|i− j|+ β, if i ∼ j
wt(s˜crb(u
ij)), otherwise
(3.17)
f2(i, j) = wt(s˜crb(u
i)) + wt(s˜crb(u
j)) (3.18)
f3(i, j) =
{ |i− j|, if i ∼ j
∞, otherwise (3.19)
f4(i, j) = min(f3(i, j), f3(i, j + L), f3(i, j − L)). (3.20)
As the way a low weight codeword is generated depends on how the encoder terminates
its state at the end of a block, we begin with TP-IBPTC.
3.4.1 TP-IBPTC
For the class of TP-IBPTC, a weight-2 input sequence uij, (i, j) /∈ sm, can not
generate an infinite-weight codeword because the encoder state is forced to be terminated
at the all-zero state at the end of each block. On the other hand, low-weight codewords
may be generated if
dL(i) + dL(j) + dL (piibp(i)) + dL (piibp(j)) < lcm(Ts, Tc) + Tc (3.21)
where dL(n) = L−|n|L and in addition, (i) both i, j and piibp(i), piibp(j) are near the ends
of different blocks, (ii) i ∼= j, piibp(i) ∼= piibp(j) and both pairs lie close to the end of a
block, or (iii) i  j or piibp(i)  piibp(j) but both pairs lie close to the end of a block. To
avoid generating low weight codewords out of case (i), we require that
f2(|i|L, |j|L) + f2 (fb (piblock(|i|L)) , fb (piblock(|j|L))) ≥ B(Tc, Ts) (3.22)
where B(Tc, Ts) = α [Tc + lcm(Tc, Ts)/Tc] + 2β. Similarly, for cases (ii)-(iii), Πblock must
satisfy
f1(|i|L, |j|L) + f1 (fb (piblock(|i|L)) , fb (piblock(|j|L))) ≥ B(Tc, Ts), (3.23)
50
3.4.2 TB-IBPTC
We discusse the constraints of intra-block permutation Πintra for TB-IBPTC. The
tail-biting encoding results in the codeword weight of weight-1 and weight-2 input in-
formation sequence determined by block length L. We give two definitions as follows.
Definition 14 scrbltb(u) is the weight of a length−L tail-biting convolutional code output
for an input sequence u.
Definition 15
Sk =
∞⋃
l=k
[S1(l) ∪ S2(l)] , (3.28)
where
S1(l) =
{
M = α+ 2scrbltb(u
i) |0 ≤ i < l}
S2(l) =
{
M = scrbltb(u
ij) + scrbltb(u
piblock(i)piblock(j)) |i  j, i  j ± l, piblock(i)  piblock(j),
piblock(i)  piblock(j)± l, 0 ≤ i, j < l} (3.29)
Let mk be the smallest integer of the set Sk. Obviously, {mk} is a nondecreasing series
of k. Denote the least integer k such that mk ≥ B(Tc, Ts) by kmin.
We observed that, for a TB-IBPTC whose block size L ≥ kmin, a weight-2 sequence
uij generates a codeword whose weight is not larger than the bound B(Tc, Ts) only if
(i, j) ∈ ΓTs and (i, j) satisfies the following conditions:
min {|(|i− j|)|Tc , |(L− |i− j|)|Tc} = 0 (3.30)
min {|(|piibp(i)− piibp(j)|)|Tc , |(L− |piibp(i)− piibp(j)|)|Tc} = 0. (3.31)
min {|i− j|, L− |i− j|}+min {|piibp(i)− piibp(j)|, L− |piibp(i)− piibp(j)|} < lcm(Tc, Ts)+Tc.
(3.32)
Such (i, j) pairs will not exist if Πinter is of Type III and the corresponding Πblock satisfies
f4(|i|L, |j|L) + f4(fb(piblock(|i|L)), fb(piblock(|j|L))) ≥ Tc + lcm(Tc, Ts), 0 ≤ i, j < L,
52
The above discussion shows that the Type IV permutation possesses some desired
properties and should be used in conjunction with a proper intra-block permutation.
Hokfelt et al. [28] showed that, as the correlation function of the extrinsic output is
exponentially decayed, the interleaver should separate neighboring bits as far as possible.
The local periodicity requirement of Type IV permutation is consistent with this intuition
and let bits or samples within the neighborhood of Ts−1 blocks be moved to the different
blocks.
3.5 TB-IBPTC bounds of codeword weights for weight-
2 input sequences
Number of blocks for D-IBPTC is of our interest. Classic TC encodes information
sequence and permuted information sequence continuously and this is equivalent to the
D-IBPTC with only one block. On the other hand, the product code [7] arranges N
information bits in a two dimensional array and encodes each row and column separately
(discontinuously). The number of blocks for pre-permutation and post-permutation
associated with the D-IBPTC are number of rows and columns respectively. Obviously
both coding schemes are two special cases of D-IBPTC and the optimum blocking rule
is our concern.
We investigate the properties of TB-IBPTC. TB-IBPTC and TP-IBPTC, two D-
IBPTC options, are distinguished by termination methods. The tail-padding assigns
termination bits and some low weight codeword events are associated with these bits.
However the extrinsic information of these bits does not exchange during iterative de-
coding and this causes low weight codeword for TP-IBPTC. The tail-biting avoids these
error events induced by the termination bits and the associated codeword weight de-
pends on the length of a block. Furthermore avoiding termination bits does not induce
a loss in spectral efficiency. Therefore we derive the codeword bounds for TB-IBPTC.
54
input information sequence permuted to two different blocks and the RSC generates
two codewords associated with the weight-1 input information sequence. In order to
facilitate our discussion, we give two definitions as follows.
Definition 16 Given a tail-biting recursive convolutional code, we have
W2(L) = min
i,j,|i−j|Tc 6=0,|L−i+j|Tc 6=0
scrbLtb(u
ij
k ), (3.36)
where uijk is a weight-2 input sequence with nonzero elements at coordinates i and j in
the kth block.
Definition 17 Given a tail-biting recursive convolutional code, we have
W1(L) = min
i
scrbLtb(u
i
k), (3.37)
where uik is a weight-1 input sequence with nonzero element at coordinate i in the kth
block.
The weight of weight-2 input sequence is our main concern. The codeword weight
scrbLtb(u
ij
k ) associated with two coordinates i, j satisfying |i− j|Tc 6= 0, |L− i + j|Tc 6=
0 is lower-bounded by W2(L). When two coordinates i, j satisfy |i − j|Tc = 0 or
|L − i + j|Tc = 0, the associated codeword weights are lower-bounded by α |i−j|Tc + β or
α (L−|i−j|)
Tc
+ β respectively. We have
W (i, j, L) =

α |i−j|
Tc
+ β , |i− j|Tc = 0
αL−|i−j|
Tc
+ β , |L− |i− j||Tc = 0
W2(L) , otherwise
. (3.38)
Furthermore, if the puncturing is not applied, W2(L) can be bounded by
α·(L−Tc)
Tc
+ β ≤
W2(L) ≤ α·(L+Tc)Tc + β.
Since the RSC code output weights of the weight-2 error events are lower-bounded
by the difference of a coordinate pair (i, j), the weight of a tail-biting encoded classic
TC is lower-bounded by
min
i,j
(2 +W (i, j, L) +W (pi(i), pi(j), L)) (3.39)
56
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
1
0
27
28
30
31
32
34
35
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
n=8
36
38
39
40
41
42
43
44
9
21
=
+NN
8
121
=
−+NN
N2=6
29
33
45
63
64
65
37
Figure 3.4: Set mapping; N1 = 3, N2 = 6 and n = 8.
where 2W1(L) ≥ 2+αDmin+W2(L) + β, Dmin = dTs−
⌈
N2
Nmax
⌉
, Dmax = dTs−
⌊
N2
Nmax
⌋
,
N2 = dTs −
∣∣L
d
∣∣dTs, Nmax = ⌈ Ld2Ts⌉, d=gcd(|L|Tc , Tc) and Ts is the number of blocks
involved in encoding.
Proof: See C.
If L ≥ (Tc + 2d)M , we have
TcDminmin(2|N2|Nmax ,
√
Nmax) + TcDmaxmax(
√
Nmax − 2|N2|Nmax , 0)
≤ TcdTs
⌈√⌈
L
d2Ts
⌉⌉
< Md
(√
L
d2Ts
+ 1 + 1
)
≤
√
T 2c TsL+ d
2M2 + dM
≤
√
(L− 2dTcTs)L+ d2M2 + dM ≤
√
L2 − 2dML+ d2M2 + dM = L, (3.42)
where M = TcTs. Then
αDminmin
(
2|N2|Nmax ,
⌈√
Nmax
⌉)
+ αDmaxmax
(⌈√
Nmax
⌉
− 2|N2|Nmax , 0
)
+ β
≤ αL
Tc
+ β ≤ W2(L) + α, (3.43)
if no puncturing is applied for the RSC code.
58
gap would be much reduced if these events were taken into account.
0 200 400 600 800
20
40
60
80
100
120
140
 T
s
=1
 T
s
=2
 T
s
=4
 T
s
=6
 T
s
=8
 Upperbound [4]
T
h
e
 W
e
ig
h
t-
2
 B
o
u
n
d

Interleaver Length
Figure 3.5: The weight 2 lower bound for the Scrambling function 1+D
2
1+D+D2
.
We derive a general achievable codeword weight lower bound for the weight-2 error
events when a TB-IBPTC uses two identical RSC code. The bound implies separate
encoding stands a better chance to obtain a weight-2 lower bound larger than that of
the conventional continuous encoding scheme if the block length is not too small and is
properly chosen. The relationships between these two parameters and the lower bound
provide useful design guideline for TB-IBPTC.
60
Chapter 4
Streaming-type inter-block
permutation Interleavers
Streaming-type IBPTC (S-IBPTC) suits for high throughput pipeline decoding archi-
tecture and outperforms classic TC under the same interleaver delay. Pipeline decoder
is constructed by multiple APP decoders. These APP decoders serially decodes code-
word sequences and the interleaver delay determines the latency between two adjacent
APP decoders. Since multiple APP decoders process at the same time, high throughput
decoding is achievable. For example: [92] applies 10 APP decoders to achieve 352Mb/s
throughput and interleaver delay is 2048 bits or 5.82µs. However, these APP decoders
decode these classic TCs independently and the performance is limited by the length
of each code. In order to pass information to neighboring blocks to improve perfor-
mance, we apply IBP to construct a streaming-type IBP (S-IBP) itnerleaver with the
same interleaver delay. Due to extra relation between neighboring blocks, information
can be passed to the neighboring blocks in each decoding iteration. The more decod-
ing iteration, the more information gathered, the better performance. By the way, we
can apply good block interleaver as an intra-block permutation and the resultant S-IBP
interleaver would have good distance properties. Therefore, S-IBPTC have better per-
formance and distance properties than classic TC under the same interleaver delay and
high throughput decoding still stands.
62
IBP interleaved
Sequence
1 2 103 4 5 ...... 100 101 102 3 104 105 ...... 200 ......
Information
Sequence
1 2 3 4 5 ...... 100 101 102 103 104 105 ...... 200 201 202 203 204 205 ...... 300
IBP interleaved
Sequence
...... 101 202 3 104 205 ...... 200 201 102 203 204 105 ...... 300
Information
Sequence
1 2 3 4 5 ...... 100 101 102 103 104 105 ...... 200 201 202 203 204 205 ...... 300
Information
Sequence
1 2 3 4 5 ...... 100 101 102 103 104 105 ...... 200 201 202 203 204 205 ...... 300
IBP interleaved
Sequence
1 2 103 4 5 ...... 100 101 3 104 ...... 200 202 205 ......
I II III
I II III
(a)
(b)
Figure 4.1: (a) Conventional inter-block permutation (S = 1); (b) Storage saving inter-
block permutation (S = 1).
TC and IBPTC encoders. In general both interleavers have to store complete permuted
sequence then encoding because the interleaving finishes almost when complete informa-
tion sequence is input. Therefore, the storage is equal to the entire information length.
In contrary to classic TC and IBPTC, the storage is not an entire information length for
S-IBPTC because the interleaving of S-IBP interleaver can output permuted sequence
in advance. The S-IBPTC encoder encodes the interleaved block u′i after the (i+ Sb)th
block ui+Sb received and permuted while the (i+ Sb)th block ui+Sb is also permuted to
the (i+ Sb + Sf )th block u
′
i+Sb+Sf
. After encoding of the block u′i, the encoder discards
the block u′i and the necessary temporary storage is equal to at most (Sf + Sb + 1)L
symbols instead of an entire information sequence. Even the input information length
is infinite, the temporary storage for S-IBPTC does not exceed the total blocks within
its S-IBP interleaver span.
64
IBP
Interleaver
(SL)
APP
decoder 1
(L)
APP
decoder 2
(L)
IBP
Interleaver
(SL)
IBP
Deinterleaver
(SL)
IBP
Deinterleaver
(SL)
Delay (L)
Delay
(2SL+2L)
Delay
(SL+L)
Delay
(SL+L)
Delay (L)
Decoding
Module 1
Decoding
Module Imax
Decoding
Module 2
......
(a)
(b)
0
ky
1
ky
2
ky
1
kAPP 2
kAPP
1
kEx
2
kEx
Figure 4.2: (a) An S-IBPTC decoding module for 1 iteration; (b) An S-IBPTC pipeline
decoder.
to that proposed by Hall [19] is shown in Fig. 4.2(b). The pipeline structure renders
short decoding latency at the expense of increased complexity that is proportional to
the number of the decoding modules. APP1k and Ex
1
k represent the a priori and the
extrinsic information associated with the kth block uk, and APP
2
k and Ex
2
k represent
the a priori and the extrinsic information associated with the kth interleaved block u′k.
APP1k and APP
2
k are acquired from the S-IBP deinterleaver and S-IBP interleaver, and
the corresponding storage for both interleavers is (Sf+Sb+1)L symbols which is similar
to the temporary storage in the encoding. If ΠS−inter is a swap interleaver, the storage
can be further reduced to (S + 1)L symbols.
We apply the factor graph and decoding time diagram to demonstrate the edge of
the S-IBPTC to classic TC under the same interleaver delay 2L when high throughput
66
0 L 2L 3L 4L 5L 6L 7L 8L 9L 10L 11L 12L
Streaming-type IBPTC with block length L
1st APP
Decoder
2nd APP
Decoder
3rd APP
Decoder
4th APP
Decoder
1u
1u
1u′
1u′
2u
2u
2u′
2u′
3u
3u
3u′
3u′
4u
4u
4u′
4u′
5u
5u
5u′
5u′
Classic turbo code with block length 2L
1st APP
Decoder
2nd APP
Decoder
3rd APP
Decoder
4th APP
Decoder
1u
1u
1u′
1u′
2u
2u
2u′
2u′
3u
3u
3u′
3u′
6u
6u
6u′
6u′
Figure 4.3: The time diagram of the pipeline decoder with 4 APP decoders or Imax = 2.
Πinter, whose spans are specified by (4.4), ∃ Πintra such that the corresponding S-IBPTC
satisfies w2,min ≤ 2 + α ·min(Sf + 2, Sb + 2) + 2β, if L > Tc ·min(Sf + 1, Sb + 1).
To accommodate the S-IBP ranges defined by (4.4) for the finite-length inputs, the
range of fn(||i||L, |i|L) and the period Ts of a Type II or III inter-block permutation must
be adjusted according to
max (−Sb,−|i|L) ≤ fn(||i||L, |i|L) ≤ min (Sf , N − 1− |i|L) , (4.5)
Ts(n) =

n+ Sf + 1, if 0 ≤ n < Sb
N − n+ Sb, if N − Sf ≤ n < N
Sf + Sb + 1, otherwise
, (4.6)
where 0 ≤ n < N .
Even with the above modifications, low-weight codewords can still be generated for
some weight-2 input sequences and block lengths for the first and last blocks must be
68
Finite-length versions of Lemmas 3.3-3.4 can also be established if the block length
and the corresponding S-IBP rule meet the requirements stated in the above lemma. For
a streaming-type C-IBPTC (S-C-IBPTC), however, Πblock needs to satisfy the additional
requirement that for all 0 ≤ i, j < L such that ||piblock(i)− piblock(j)||Ts = 0
f1(i, j) + f1(piblock(i), piblock(j)) ≥ 2 + α
[
Tc + lcm(Tc, Sb + 1)
Tc
]
+ 2β. (4.9)
When this requirement is also met then we have
min
i,j
wt(C
ij) ≥ 2 + α
[
Tc + lcm(Tc, Sb + 1)
Tc
]
+ 2β. (4.10)
4.5 Codeword weight upper-bounds of streaming-
type IBPTC
This section derives upper-bounds for the weights of S-IBPTC codewords associ-
ated with weight-2 and weight-4 input sequences. These upper-bounds are valid for all
streaming-type inter- and intra-block interleavers.
Recall that Lemma 3.1 implies that, the minimum codeword weight, w2,min, for the
weight-2 input sequences whose coordinates (i, j) of nonzero elements satisfy i ∼ j and
pi(i) ∼ pi(j) is upper-bounded by
w2,min ≤ 2 + α ·
( |i− j|+ |pi(i)− pi(j)|
Tc
)
+ 2β, (4.11)
where it is understood that the constants α and β might not have the same values
as those of (3.12). A bound much tighter than (4.11) can be obtained by applying
the approach suggested by Breiling [33] who partitions the coordinates set associated
with both pre-interleaved and post-interleaved sequences into equivalence classes induced
by the equivalent relation “∼”. Each equivalence class is further divided into subsets
zz = {z +mTc,m = 0, 1, · · · , |zz| − 1}, where z is the smallest index in zz.
An output (parity) sequence will be of finite weight if the coordinate pair (i, j)
associated with the weight-2 input sequence uij belongs to the same equivalence class.
70
parameter values, we consider the following (subset) partition.
z
(k)
i =

{
|i|M + [i− |i|M ]
⌈
L
Λk
⌉
+Mj| 0 ≤ j <
⌈
L
Λk
⌉
, 0 ≤ i < |L|Λk − |L|M
}
,{
|i|M + [|L|Λk − |L|M ]
⌈
L
Λk
⌉
+ [i− |i|M − |L|Λk + |L|M ]
⌊
L
Λk
⌋
+Mj|
0 ≤ j <
⌊
L
Λk
⌋
, |L|Λk − |L|M ≤ i < Λk −M
}
,{
|i|M + [|L|Λk − |L|M ]
⌈
L
Λk
⌉
+ [Λk − |L|Λk −M + |L|M ]
⌊
L
Λk
⌋
+Mj|
0 ≤ j <
⌈
L
Λk
⌉
, Λk −M ≤ i < Λk − (M − |L|M)
}
,{
|i|M + [|L|Λk − |L|M ]
⌈
L
Λk
⌉
+ [Λk − |L|Λk −M + |L|M ]
⌊
L
Λk
⌋
+Mj|
0 ≤ j <
⌊
L
Λk
⌋
, Λk − (M − |L|M) ≤ i < Λk
}
.
(4.13)
An exemplary partition of (4.13) is shown in Fig. 4.5 where the integers represent
the coordinates of either an input or output sequence and each row consists of three
segments with a segment representing a subset of size 3 or 2. The S-IBP rule sends bits
in rows labelled by different capital letters to different blocks while those in the same
row are interleaved to the same block.
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
A
B
C
1
0
Ts=3
Tc=3
Tc=3
Tc=3
Figure 4.5: Partition of equivalence classes into subsets; L = 68, Λ = 27, Tc = Ts = 3.
By using an argument similar to that leading to (4.12) and invoking the partition of
(4.13) along with the permutation rule (i)-(iv) mentioned at the beginning paragraph of
this subsection, we obtain
72
4.5.2 Streaming-type upper-bound for weight-4 input sequences
Let the coordinates of nonzero elements of a weight-4 input sequence be (i, j, k, l),
where i < j < k < l. If we divide these coordinates and their permuted positions
respectively into two pairs each according to their natural order, i.e., (i, j), (k, l) and
say, (pi(i), pi(k)), (pi(j), pi(l)), then a low-weight codeword results if each pair belongs to
the same subset. More specifically, the minimum codeword weight, w4,min, for weight-4
input sequences whose nonzero coordinates (i, j, k, l) are such that i ∼ j, k ∼ l, pi(i) ∼
pi(k), pi(j) ∼ pi(l) satisfy
w4,min ≤ 4 + α ·
( |i− j|+ |k − l|+ |pi(i)− pi(k)|+ |pi(j)− pi(l)|
Tc
)
+ 2β (4.19)
or
w4,min ≤ 4 + α ·
( |i− j|+ |k − l|+ |pi(i)− pi(j)|+ |pi(k)− pi(l)|
Tc
)
+ 2β. (4.20)
if (i, j, k, l) are such that i ∼ j, k ∼ l, pi(i) ∼ pi(j), pi(k) ∼ pi(l).
These upper-bounds are obtained by considering the three pre- and post-interleaving
distributions of the 4-tuple (i, j, k, l) shown in Fig. 4.6 (a)-(c). These three are the
distributions that most likely lead to low-weight codewords. There are other candidate
distributions (e.g., Fig. 4.6 (d)) but the corresponding upper-bounds are likely to be
larger that those given by (4.19) and (4.20).
Following an approach similar to that of [33] and taking into account the extra
degrees of freedom offered by an S-IBP interleaver, we obtain
Theorem 4.5 The S-IBPTC minimum codeword weight for weight-4 input sequences is
upper-bounded by
w4,min ≤ 4 + 2α
(
min
(Λ1,Λ2)
{⌈
TsL
Λ1
⌉
+
⌈
TsL
Λ2
⌉}
− 2
)
+ 4β (4.21)
when (Λ1,Λ2) ∈ D × D, where D = {1, 2, · · · , bL/2c}, satisfies (i) Λ1
(
Ω
2
)
>
(Λ2
Ts
2
)
,
(ii) (Ts−k)
Ts
· Λ1Ω2 >
(
Λ2
Ts
)2
, and (iii) |Λi|M = 0, i = 1, 2, where Ω = b LΛ1 c and k =
74
1, 2, · · · , Ts − 1. Moreover, for the special case, Λ1 = Λ2 and if L > 103 T 3s + T 2s − Ts3 and
TS > 1 the upper-bound yields the compact expression
w4,min,ibp ≤ 4 + 4α TsL
C − TsTc + 4β, (4.22)
where
C =
Ts + 2T
2
s
3
+
3
√
−q1
2
+
√(p1
3
)3
+
(q1
2
)2
+
3
√
−q1
2
−
√(p1
3
)3
+
(q1
2
)2
(4.23)
p1 = 3T
2
s L−
1
3
(Ts + 2T
2
s )
2, (4.24)
q1 = −T 2s L2 + (T 3s + 2T 4s )L−
2
27
(Ts + 2T
2
s )
3. (4.25)
Proof: See Appendix B.
Again, we observe that for large L, the upper-bound grows linearly with (TsL)
1
3 . The
minimum codeword weights associated with weight-2 and weight-4 input sequences are
upper-bounded by the increasing functions of TsL.
4.5.3 Interleaving gain comparison
The minimum weight codeword upper-bound of weight-2 and weight-4 input se-
quences are derived above and S-IBPTC outperforms classic TC in distance properties
when the interleaver delay is the same for both S-IBPTC and classic TC. We consider
the interleaver delay is (S + 1)L and the equivalent block size of classic TC is also
(S + 1)L. Let w2,min,block and w4,min,block be the minimum codeword weights associated
with weight-2 and weight-4 input sequences of classic TC with block size (S+1)L, then
we have [33]
w2,min,block ≤ 2 + 2α (S + 1)L√
(S + 1)L− Tc
+ 2β (4.26)
w4,min,block ≤ 4 + 4α (S + 1)L
((S + 1)L− 1) 23 − ((S + 1)L− 1) 13 + 1− Tc
+ 4β. (4.27)
76
4.6 Modified semi-random interleaver
Semi-random interleavers [30] are designed to eliminate “short cycles” that send
two close-by bits to the vicinity of each other after interleaving. These interleavers are,
however, originally designed to work in the block interleaving setting, therefore they can
not avoid two new classes of short cycles arising in S-TB-IBPTC and S-C-IBPTC. A tail-
biting convolutional code begins and ends at the same state, hence if two close-by bits
in a block are respectively intra-block permuted to the beginning and the ending parts
of that block, and if the two bits remain in the same block after the S-IBP interleaving,
a short cycle will result as the proposed S-IBP does not alter their relative positions
within a block. For the class of S-C-IBPTC, we also want to prevent similar intra-block
interleaving results because the S-IBP interleaver may send such a pair to the ending
and beginning parts of two neighboring blocks. We therefore modify the constraint of
[30] as
dmin(i, j) + dmin(pi(i), pi(j)) > S2, 0 ≤ i, j < L (4.28)
where dmin(i, j) = min(|i− j|, L− |i− j|). This new constraint excludes the possibility
that two symbols at the beginning and the ending parts of a block would remain there
after the interleaving.
4.7 Simulation Results
This section shows extrinsic information updating behavior and provides error rate
performance. As mentioned in section 4.3, inter-block permutation provides relation
across adjacent blocks and the information are spread to other blocks by the assistance
of message passing but this is only an intuitive explanation for the edge of S-IBPTC.
In order the visualize the effect of message passing, we demonstrate the behavior of the
evolution between the a priori information and extrinsic information at each iteration,
and covariance, mutual information and SNR are used to measure this evolution. The
78
0 5 10 15 20 25 30
0.0
0.2
0.4
0.6
0.8
1.0
S-IBPTC
 0.5dB
 1.0dB
Turbo Code
 0.5dB
 1.0dB
 1.5dB
 2.0dB
C
o
v
a
ri
a
n
c
e
 b
e
tw
e
e
n
 a
 p
ri
o
ri
 i
n
fo
rm
a
ti
o
n
 
a
n
d
 e
x
ti
rn
s
ic
 i
n
fo
rm
a
ti
o
n

Number of APP decoding rounds
Figure 4.7: Covariance between a priori information input and extrinsic information
output.
Both figures also reveal that our code has a much faster convergence speed. The much
larger step of the S-IBPTC curves means the associated APP decoder generates more
information or extrinsic information with larger signal to noise ratio for the next stage
decoder. Such a trend has been expected when we examine the factor graph structure
of the S-IBPTC in Fig. 4.4.
Bit-level and symbol-level inter-block permutation are compared and duo-binary
turbo code (DTC) defined in DVB-RCS/RCT [68, 69] is adopted. This code applies
duo-binary RSC and a symbol-based interleaver. This interleaver applies intra-and inter-
symbol permutation and two bits in one symbol are grouped and permuted to very close
destination. However [86] indicated that interleaver should lower down the covariance of
the a priori information of two bits if two bits are close and a good interleaver permutes
two close-by bits as far as possible. Intuitively this symbol-based interleaver results in
that high covariance of the extrinsic information for two bits belong to one symbol and
this may be harmful to error rate performance. Therefore two options of S-IBP are
compared: bit-level and symbol-level S-IBPs. Fig. 4.10 shows a simulation examples of
80
0 2 4 6 8 10 12 14
0
2
4
6
8
10
12
14
S-IBPTC
 0.5dB
 1.0dB
Turbo Code
 0.5dB
 1.0dB
 1.5dB
 2.0dB
  
S
N
R
 o
f 
a
 p
ri
o
ri
 i
n
fo
rm
a
ti
o
n
 o
f 
2
n
d
 d
e
c
o
d
e
r
=
 S
N
R
 o
f 
e
x
tr
in
s
ic
 i
n
fo
rm
a
ti
o
n
 o
f 
1
s
t 
d
e
c
o
d
e
r
SNR of a priori information of 1st decoder
= SNR of extrinsic information of 2nd decoder
Figure 4.9: SNR evolution chart behavior of the S-IBPTC and the classic TC at different
Eb/N0’s.
modified semi-random interleaver of (4.28) for the intra-block permutation while the
S-IBP follows the algorithm of Table 4.1. Each simulation run consists of 1000 blocks
for S-IBPTC. We use the Log-MAP or MAX-Log-MAP algorithms to decode classic TC
and streaming-type TP-IBPTC (S-TP-IBPTC) and the sliding-window Log-MAP or the
sliding-window MAX-Log-MAP algorithms to decoding streaming-type TB-IBPTC (S-
TB-IBPTC) and S-C-IBPTC. In most cases, we compare the performance of classic TC
and S-IBPTC under the assumption that either both codes have the same interleaver
delay.
Figs. 4.11 and 4.12 show the BER performance of rate 1/3 turbo coded systems
with 10 iterations and Log-MAP algorithm. The interleaver parameter values for the S-
IBPTCs are L = 402, S = 1 or L = 265, S = 2. Compared with the performance of the
classic TC with L = 400, the S-IBPTCs yield 0.7–0.9 dB performance gain at BER=10−4
and 1.0–1.2 dB gain at BER=10−6. When both codes have the same interleaver delay,
the S-IBPTCs provides 0.4–0.6 dB performance gain at BER between 10−4 and 10−6.
Figs 4.13 and 4.14 show the BER performance of rate 1/2 turbo coded systems. The
82
0.0 0.2 0.4 0.6 0.8 1.0 1.2 1.4 1.6 1.8 2.0
1E-6
1E-5
1E-4
1E-3
0.01
0.1
S-IBPTC
L=400,S=1
S-C-IBPTC
 3GPP
 S
2
=20
S-TB-IBPTC
 3GPP
 S
2
=20
S-TP-IBPTC
 3GPP
 S
2
=20
Turbo Code
L=400
 3GPP
 S
2
=20
L=800
 3GPP
 S
2
=27
R=1/3 PCCC
8-state (13/15)
10 iterations
Log-MAP
3GPP interleaver
B
it
 E
rr
o
r 
R
a
te

E
b
/N
0
 in dB
Figure 4.11: BER performance of the S-IBPTCs with interleaver delay ≈ 800, block size
L = 402 and interleaver span S = 1 and the classic TCs with block sizes L = 400, 800.
Fig. 4.15 shows the BER performance of rate 1/3 S-IBPTCs that use the 3GPP
interleaver as the intra-block interleaver. Either the Log-MAP algorithm or the Log-
MAP algorithm is used and 15 decoding iterations is assumed. All these S-IBP parameter
values, (L, S) = (660, 1), (440, 2) or (330, 3), give the same interleaver delay of 1320 bits.
The performance is consistent with our prediction: the larger the interleaver span is,
the better the system performance becomes. The performance deteriorates when the
period of encoder, Tc, and the period of the S-IBP interleaver, Ts, are the same. For
this case the lower-bound of (3.16) becomes 2(1 + α + β) which is much smaller than
the corresponding upper-bound given in Theorem 3.2. By contrast, the two bounds are
much closer if Tc 6= Ts and both bounds give identical value if Tc and Ts are relative
prime.
Finally, we want to show that the S-IBPTC requires an interleaver latency much
smaller than that of classic TCs with similar BER performance. Fig. 4.16 shows the
BER performance of rate 1/3 turbo coded systems that employ 10 decoding iterations
and the Log-MAP algorithm. All the interleavers are taken from the 3GPP interleaver.
84
0.6 0.8 1.0 1.2 1.4 1.6 1.8 2.0 2.2 2.4
1E-7
1E-6
1E-5
1E-4
1E-3
0.01
0.1
1
R=1/2 PCCC
8-state (15/13)
10 iterations
MAX Log-MAP
3GPP interleaver
S-IBPTC
S-TP-IBPTC
 L=440,S=2
 L=660,S=1
S-TB-IBPTC
 L=440,S=2
 L=660,S=1
S-C-IBPTC
 L=440,S=2
 L=660,S=1
Turbo Code
 L=1320
B
it
 E
rr
o
r 
R
a
te

E
b
/N
0
 in dB
Figure 4.13: BER performance of S-IBPTCs and the classic TC with interleaver delay
1320 and the 3GPP interleaver.
also used in this simulation. Figs. 4.17 shows the simulation results. Bit-level and
symbol-level S-IBPDTCs outperform DTC with 53Bytes by 0.8−1.0dB and 0.6−0.8dB
at frame error rate (FER)=10−4. If we consider the same interleaving delay Bit-level
and symbol-level S-IBPDTCs outperform DTC with 53Bytes by 0.5− 0.9dB and 0.2−
0.6dB at frame error rate (FER)=10−4. Naturally S-IBPDTCs outperform DTC. As
our prediction, bit-level inter-block permutation outperforms symbol-level inter-block
permutation.
86
0.0 0.2 0.4 0.6 0.8 1.0 1.2 1.4 1.6
1E-6
1E-5
1E-4
1E-3
0.01
0.1
R=1/3 PCCC
8-state (15/13)
10 iterations
Log-MAP
3GPP interleaver
S-IBPTC
S-TP-IBPTC
 L=265,S=2
 L=400,S=1
S-TB-IBPTC
 L=265,S=2
 L=400,S=1
S-C-IBPTC
 L=265,S=2
 L=400,S=1
Turbo Code
 L=800
 L=1200
 L=2000
 L=2800
 L=3600
B
it
 E
rr
o
r 
R
a
te

E
b
/N
0
 in dB
Figure 4.16: BER comparison of S-IBPTCs and the 3GPP defined turbo code of various
block sizes.
0.0 0.2 0.4 0.6 0.8 1.0 1.2 1.4 1.6 1.8 2.0 2.2 2.4
1E-5
1E-4
1E-3
0.01
0.1
1
DTC
L=53 Bytes
 SW LM
 SW MLM
L=106 Bytes
 SW LM
 SW MLM
IBPDTC
L=53 Bytes
Bit Level
 SW LM
 SW MLM
Symbol Level
 SW LM
 SW MLM
DVB-RCS Defined
DTC & Interleaver
15 iterations
Code Rate=1/3
F
ra
m
e
 E
rr
o
r 
R
a
te

E
b
/N
0
 in dB
Figure 4.17: A comparison of S-IBPDTC over bit-level and symbol-level permutation
and conventional DTC using both Log-MAP and MAX Log-MAP APP decoders.
88
plexity and power consumption for S-IBPTC. The multiple round stopping test will be
described in the later section.
5.1 IBPTC with early stoppings
This section presents a reliable stopping mechanism for an IBPTC codec system.
The extrinsic information used in a conventional turbo decoder is usually generated in
the course of decoding a component code and there are many well-developed soft output
decoding algorithms. An error detection code that is often used in a packet switching
network can also generate extrinsic information with no extra cost/complexity when the
corresponding undetectable error probability is negligibly small. However, the detector
output is generally used for making a stopping decision only. In order to utilize this
stopping message, we can partition an information sequence into multiple blocks and
these blocks are separately CRC-coded. If one block is stopped and some blocks are
unstopped, the pass message can be passed to the unstopped blocks as the a priori
information. IBPTC suits this nature and can have better performance by paying little
incremental complexity and slightly extra CRC overhead. The detail will be expounded
in the following subsections.
5.1.1 System model
Shown in Fig. 5.1 is a generic block diagram for a joint stopping test iterative
encoding and decoding system using an IBPTC. The input data sequence D is parti-
tioned into blocks of the same length, {d1,d2, · · · }, where di is a row vector of length
L − KCRC representing the ith block. They are CRC-encoded into u = {u1,u2, · · · },
where ui = {ui0, ui1, · · · , ui(L−1)} is a row vector with length L. u is formed by padding
at the end of each data block parity bits that are the coefficients of the remainder poly-
nomial r(x) obtained by dividing a data polynomial associated with a data block by a
binary generator polynomial g(x) of order KCRC . Of course, the degree of r(x) is less
90
leads to the decision to stop (terminate) decoding the block in question and this is the
only possible early-stopping opportunity for classic TCs. Besides such a regular early-
stopping, however, there are two other early-stopping opportunities for IBPTCs since
no matter whether the decoder output passes the ST, the corresponding soft output
is interleaved or de-interleaved to the neighboring blocks. The ADU will then examine
each related block to see if a block’s content has been filled with stop-decoding decisions.
If such a block is found the ADU will issue a termination decision accordingly. The ADU
can also run STs on these blocks and make a termination decision. We refer to the latter
two early-stopping possibilities as extended (or pre-decoding) early-stoppings.
Note that a decoding iteration consists of two DRs that are respectively responsible
for decoding the pre-permuted (non-interleaved) c1j and post-permuted (interleaved)
blocks c2j and CRC check is feasible for pre-permuted blocks only. Hence in the first
DR one can perform both regular and extended early-stopping tests, but in the second
DR, only extended early-stopping is viable unless the ST does not involve a CRC check.
Examples are given in Section 5.2.4 to further elaborate this property of IBPTCs.
5.1.2 Iterative decoder with variable termination time
A conventional iterative decoder is composed of one or more APP decoders that will
not stop decoding until a fixed number of decoding iterations have been performed. With
an early-stopping mechanism in place, as shown in Fig. 5.1, the decoding procedure can
stop (terminate) at the end of an iteration (two decoding rounds) or at the end of a
decoding round (DR). We refer to such a decoder as a variable termination time APP
(VTT-APP) decoder or simply a VTT decoder. When a stopping test (ST) is included
in the turbo decoding process, the test results in either a stop- or a continue-decoding
decision. Given the decision, which is very useful side information, our computation of
the extrinsic information and soft output should be modified accordingly.
Note that all STs, whether they are used in classic TCs or IBPTCs, incur additional
92
noise power spectral density.
For the ith DR of the jth data block, the VTT-APP decoder in charge uses baseband
vectors y0j ,y
1
j or y
2
j and the a priori information {Λ(i−1)e (ujk)}k=L−1k=0 as its input and
outputs {Λ(i)e (ujk)}k=L−1k=0 for use in the next DR as the a priori information until i =
Dmax, where Dmax is the maximum allowed APP DRs; see Fig. 5.1.
A tentative decision uˆijk on the kth bit of the jth block at the end of the ith APP
DR can be obtained by
uˆijk =
{
0 , Λ(i)(ujk) ≥ 0,
1 , Λ(i)(ujk) < 0.
. (5.2)
Let Q(ûij) be the stopping indicator for the tentative decision vector of the jth block
at the ith DR, ûij = (uˆ
i
j0, uˆ
i
j1, · · · , uˆij(L−1)), 0 < i ≤ Dmax, where
Q(ûij) =
{
1, if ûij satisfies the ST
0, otherwise
. (5.3)
Given the ST result, the conditional soft value Λ
(i)
S (ujk) and the extrinsic information
Λ
(i)
e,S(ujk) are given by
Λ
(i)
S (ujk) =
 log
P [ujk=0|Q(ûij)=1 ]
P [ujk=1|Q(ûij)=1, ] , Q(û
i
j) = 1
Λ(i)(ujk), Q(û
i
j) = 0
(5.4)
and
Λ
(i)
e,S(ujk) = Λ
(i)
S (ujk)− Λ(i)(ujk). (5.5)
The extrinsic information Λ
(i)
e,V TT (ujk) of an APP decoder then becomes
Λ
(i)
e,V TT (ujk) = Λ
(i)
e,S(ujk) + Λ
(i)
e (ujk) = Λ
(i)
S (ujk)− Λ(i−1)e,V TT (ujk)− Lcyjk. (5.6)
The resulting VTT-APP decoder is shown in Fig. 5.1.
To ease the burden of computing the conditional log-likelihood function that appears
in (5.4), we make the idealized assumption that the stopping test is perfect, i.e.,
P (uˆijk is correct|Q(ûij) = 1) = 1, ∀ k.
94
Scheduler
APP
Decoders
IBP
Interleaver
IBP
De-interleaver
Memory
(Extrinsic
Information)
Memory
(Received
Samples)
Figure 5.3: IBPTC dynamic decoder.
S = 1 and an input data sequence u partitioned into five blocks. Each block is encoded
by CRC code. The dark, gray, crossed and blank squares represent respectively the
functions of convolution codec, CRC code, S-IBP interleaving and the channel effect.
The CRC function is connected to the permutation and equality node. This graph
further indicates the relation between IBPTC and CRC codes and shows the message
passing for the VTT-APP decoder.
Section 4.3 has elaborated the message passing regarding to an S-IBPTC. An S-
IBPTC decoder can exploit information collected from 4SI + 1 adjacent blocks in I
iterations as the number block is large enough, e.g. the message of the block u3 in Fig.
5.2 can be passed to u1 and u5 in one iteration. The extra CRC nodes in Fig. 5.2 provide
extra information after each APP decoding round. If the decoded block passes the CRC
check condition, the CRC node generates extra extrinsic information for the block and
the information will be passed to the other blocks as the a priori information to decode.
Therefore the graph brings out the message passing associated with the further CRC
funtions.
96
5.2.2 Decoding delay
Decoding delay is perhaps the most important issue in high speed decoder design.
The decoding delay associated with S-IBPTC for a parallel decoder is minimized by
using a proper decoding schedule. Even if only one APP decoder is used, as we will
see shortly, the decoding schedule still plays a pivotal role in minimizing the decoding
delay of an S-IBPTC. The delay associated with B-IBPTC is similar to classic TC but
B-IBPTC provides more decoding options due its IBP nature. The decoding delay can
also be reduced by a proper scheduling as S-IBPTC and will be discussed later.
We first analyze the decoding delays when only one APP decoder is used. The
single-round interleaving (or de-interleaving) delay is proportional to the interleaving
delay. But the total decoding delay is a much more complicated issue. For a decoder
that uses a single ADU, the decoding delay depends mainly on three variables: the
single-round interleaving delay (SRID), the single-round APP decoding delay, and the
number of decoding iterations. As the single round APP decoding delay (speed) is
usually much less than the SRID, we ignore the APP decoding delay in the subsequent
discussion.
For the first decoding of each incoming block, there can be zero waiting time, but
for later DRs the corresponding delays depend on, among other things, the decoding
schedule used. With the same block size, the decoding delay of the first received block
for the classic TC is definitely shorter than that for the S-IBPTC. But if one considers
a period that consists of multiple blocks (otherwise one will not have enough blocks to
perform inter-block permutation) and takes the decoding schedule into account, then
the average decoding delay difference can be completely eliminated. This is because
the APP decoder (including the interleaver and deinterleaver) will not stay idle until
all blocks within the span of a given block are received. Instead, the APP decoder will
perform decoding-interleaving or deinterleaving operations for other blocks according to
a predetermined decoding schedule before it can do so for the given block (and the given
98
for the S-IBPTC decoder are 14, 18, 22, 25, 27 and 28 DT cycles, respectively. So in
the end, both approaches reach the final decision at the same time.
It can be shown that, for a decoder with Dmax DRs and S = 1, both decoders result
in a constant delay of Dmax(Dmax−1)
2
DT cycles between two adjacent output blocks,
except for the first block and the last Dmax − 1 blocks. For an S = 1 S-IBPTC, the
decoder requires a first-block decoding delay of Dmax(Dmax+1)
2
DT cycles while that for
the classic TC is only Dmax DT cycles. The inter-block decoding delays, i.e., decoding
latency between two consecutive output blocks, for the last Dmax − 1 output blocks
of the S-IBPTC decoder using a decoding schedule similar to that shown in Fig. 5.4
(e.g., the one shown in Fig. 5.5) form a monotonic decreasing arithmetic sequence{
Dmax(Dmax−1)
2
− 1, Dmax(Dmax−1)
2
− 3, · · · , 0
}
(in DT cycles). The inter-block decoding
delay of a classic TC decoder remains a constant Dmax DT cycles. On the average, both
codes give the same inter-block decoding delay.
Although we have assumed a stream-oriented scenario so far, our arguments are
valid for the conventional block-oriented consideration as well. It is thus of paramount
importance that we recapture the IBP concept from the block-oriented viewpoint before
returning to the main discourse.
Consider the example illustrated in Fig. 5.4. For a classic TC with an interleaving
(block) size of 7L bits, the first-block decoding delay for a 2-iteration single-ADU decoder
is 28 DT cycles. But if one divides this 7L-bit block into 7 subblocks and uses a special
block-oriented interleaver which performs successive intra-subblock and inter-subblock
permutations on these subblocks, the corresponding (2-iteration single-ADU) decoding
delays in DT cycles for these subblocks are 14, 18, 22, 25, 27 and 28, respectively.
Therefore, although both code structures result in identical total decoding delay the
IBPTC structure is able to supply partial decoded outputs much earlier. This feature,
when combined with proper intra-(sub)block and inter-(sub)block interleaving rules,
multiple ADUs, optimized decoding schedule and implementation resource management,
100
  Block
  Number
APP
Decoding
Round
1
2
3
4
5
6
1 2 3 4 5 6 7 8 9
a11 b11
b12
c11
c12
c13
d11
d12
d13
d14
a21
a22
a23
a24
a25
b21
b22
b23
b24
b25
b26
c21
c22
c23
c24
c25
c26
d21
d22
d23
d24
d25
d26
a31
a32
a33
a34
a35
a36
10 11 12
b32
b33
d32
b31 c31
c32
d31
d45
c46
c45
b46
b45
c44b44
b43
a46
a45
a44
a43
d36
d35
d34
d33
c36
c35
c34
c33
b36
b35
b34
a42
a56d46
Figure 5.5: A multiple zigzag decoding schedule for IBPTCs with an interleaving span
S = 1.
derive much more benefit in block error rate (BER) performance.
We have demonstrated the importance of the decoding schedule in minimizing the
decoding delay. Parallel decoding is a popular design option to shorten the latency.
Fig. 5.5 shows a multiple expanding-window zigzag scheduling table for decoding an
S-IBPTC with the span S = 1 and four ADUs, denoted respectively by a, b, c and d.
Data blocks processed in the odd rows are in the original (pre-permutation) order while
those processed in the even rows are in the interleaved (post-permutation) order. Each
dashed or dotted zigzag curve represents the schedule for an ADU. The symbol xmn
denotes the nth DR of the mth phase in the ADU x’s schedule, where a DR represents
the APP decoding of a pre- or post-permuted block and the associated interleaving or
de-interleaving and the mth phase refers to the mth parallel line associated with an
ADU’s decoding schedule. Obviously, the mth decoding phase of x is followed by the
(m+ 1)th decoding phase to its right.
Taking the decoding schedule of ADU c as an example, its first DR of the first
phase c11 corresponds to the first DR of Block 3 while the first phase’ second DR c12
corresponds to the second DR of Block 2. c12 can be performed, as the scheduling
102
decoding. The management of the last category, assuming no buffer overflow, requires
only an indicator signal to forward a new block of received samples to the part of the
storage area designated for category (I) that was just released due to a stopping decision.
Category (III) is needed because of the stopping time variation across blocks. Its
management is straightforward and, besides, it requires much less storage space. As
mentioned in Subsection 5.1.2, assigning the extrinsic values for ST-approved bits a
constant large value is equivalent to using a (special) binary-valued bit to indicate which
partial paths should survive in the APP decoding process. Hence the decoded bits serve
the dual purposes of representing the decoder decisions and bookkeeping the survivor
paths. The management of categories (I) and (II), however, needs more efforts and
careful considerations.
As long as the probability of termination-defying blocks exists, practical latency
consideration will force us to set an upper limit Dmax on the number of DRs. It can be
shown that an unterminated block prevents the decoder from discarding y2 associated
with those terminated blocks within its span. When the number of blocks that terminate
at or around theDmaxth DR is large so will be the memory required. Hardware constraint
thus imposes another thresholdMmax, the maximum affordable (allowable) memory units
(MU) where an MU refers to the space for storing categories (I) and (II) associated with
a block of data in the decoder. As our sole purpose is to demonstrate the critical role
a memory manager plays in the VTT-APP decoder, we assume, for simplicity, that
the same number of bits is used to represent the extrinsic information of a bit and the
corresponding received sample. An MU is thus assumed to contain KL bits, where a
K-bit word is used to store either the extrinsic information or received baseband sample
associated with a transmitted bit.
Because of the stopping time variation nature of our decoder, a memory manager
has to take into account both thresholds, Dmax and Mmax so as to optimize the perfor-
mance. When a block has failed to pass the ST for Dmax times, it will automatically be
104
the complexity is moderate at most.
Denote by MF , Md and MR, the numbers of free (unused) MUs, ADUs, and the
required MUs for storing one received block. It follows that MR = x for a rate R = 1/x
turbo code. The decoder is initialized with MF = Mmax. An ADU begins a phase
by checking if MF > MR (Box 2) where the additional MU is for storing extrinsic
information. If MF does not meet the condition, the memory manager determines
which block is to be discarded, makes a forced ESDs, and releases the related storage
space (Box 4). Otherwise, the decoder moves the received samples of the new block from
where they were saved (in the buffer area) to the corresponding category (I) MUs (Box
3).
Deciding which block is to be given up is simple and clear since our decoding schedule
allows only a single most ancient block in its left-most active column at any time. When
a forced ESD is made the ADU makes hard decisions on the block to be discarded and
releases the related categories (I) and (II) MUs. As the discarded block is always the
most ancient block and our decoding schedule is such that all blocks to its left must
have been terminated for one reason or another, we are left with the problem of dealing
with the related unstopped blocks,the S adjacent blocks to its right for S-IBPTC, if they
have not been terminated. At least two alternatives exist for solving this problem. The
first solution, which leads to better performance at the cost of higher complexity, is to
interleave or de-interleave the extrinsic values for use in decoding the related unstopped
blocks, the S blocks to its right for S-IBPTC, without further updates. The second one
is to make hard-decisions (stop any further decoding) on all related unstopped blocks,
S blocks within its (right) span for S-IBPTC, releasing their category (I) MUs while
keeping their category (II) MUs for use in decoding other related blocks.
At beginning of each DR, we ask the decoder whether the scheduled DR is needed
(Box 5). Unless the decoder has been notified to by-pass the ensuing DR, we still have
to ask if the space for storing the extrinsic information of the coming DR is available.
106
are consistent. The soft value stopping test (SVST) compares the soft value(s) with a
threshold; the soft values can be the reliability of tentative decoded soft bits, the average
soft value of a block, the extrinsic value of the least reliable bit etc. The CRC stopping
test (CRCST) uses the CRC result to decide if further decoding of a block is needed.
SCST and CRCST operate over bit level but SVST operates over the real domain. The
performance of SVST is subject to the choice of the threshold which, in turn, is a function
of the channel condition and code structure. Moreover, the convergence rate of soft bit
values also depends on the above two factors [79, 80]. In short, the classes of CRCST,
SCST or their variations have the complexity and robustness advantages over the class
of SVST.
5.3.1 A general algorithm
All early stopping tests are sequential in nature. They either compare or manipulate
some values corresponding to two consecutive DRs, or just check a single DR output
to make a stop-or-continue decoding decision. In contrast, our proposed tests make
a stop-decoding decision based on multiple observations and are thus referred to as
multiple-round stopping tests (MRSTs)
It is well known that a statistical decision based on a single observation is inferior to
that based on multiple observations which, however, require a longer observation time
(or equivalently, larger sample size). The MRST has the distinct capability of balancing
performance (reliability of the test) and cost (time or sample size needed to make a
termination decision). A dismissal on a decoder output is issued as soon as it fails a
single test but a decision to stop decoding a block has to wait until the same block is
verified by several rounds of test. Therefore, incorrect tentative decoder outputs are
quickly discarded while any final decision on a block is prudently made. While the
first round of an MRST provides an initial tentative decision, the additional verification
test rounds greatly reduce the probability of false stopping and give more robust and
108
be regarded as a quality indicator, m is the required quality condition and Dmax is the
maximum number of DRs allowed. Either p = m or i = Dmax will force the decoding
process to be terminated. As discussed in Subsection 5.1.2, an ST is performed at the
end of an iteration (even DRs) or the beginning of an odd DR. For the latter case, an
ST means checking if all pre-permuted blocks within its span have satisfied the stopping
condition. A special case of MRST is the multiple-round SCST of [79]. It was found
that the block error rate performance improves as the number of test rounds increases.
As mentioned before, we shall not consider the class of SVSTs. Multiple-round
CRCST, SCST and a hybrid CRC-SC ST are briefly defined in the following.
5.3.2 T1.m: the m-round CRCST
This scheme is based on an m-round CRC test. A block is said to pass the m-round
CRCST if all m consecutive tentative decision vectors ûi−m+1j , û
i−m+2
j , · · · , ûij succeed
in passing the same CRC test, i.e., ICRC(û
l
j) = 1, l = i −m + 1, i −m + 2, · · · , i and
i ≤ Dmax, where
ICRC(û) =
{
1, û passes CRC condition
0, otherwise
. (5.8)
As the error detection capability of a CRC code is an increasing function of the code
length, one can trade the order m for the code length.
5.3.3 T2.m: the m-round SCST
This ST [79] compares tentative decoded bits in m (m ≥ 2) consecutive DRs or
iterations. The decoder stops when the nth tentative decision vector, i ≤ Dmax, are the
same with the previous m− 1 tentative decision vectors, i.e.,
uˆi−m+1jk = uˆ
i−m+2
jk = · · · = uˆijk, ∀ k, 0 ≤ k < L. (5.9)
Note that MR-SCST checks the convergence of tentative decisions, it does not guarantee
the convergence to the correct decisions.
110
0.0 0.2 0.4 0.6 0.8 1.0 1.2
1E-4
1E-3
0.01
0.1
1
Turbo Code
L=800 D
max
=30
 Genie
S-TB-IBPTC
Variable DRs
D
max
=30
 T1.2
 T1.3
 T2.3
 T2.5
 T3.2
 T3.3
 Genie
Fixed DRs
 D
max
=20
 D
max
=30 
B
lo
c
k
 E
rr
o
r 
R
a
te

E
b
/N
0
 (dB)
Figure 5.8: Block error rate performance of various stopping tests; no memory constraint;
Dmax = 30 DRs.
the hybrid test not only gives better performance but also requires less average DRs.
This is another advantage of IBPTCs that is not shared by classic TCs.
5.4 Numerical Examples
The simulation results reported in this section is based on the following assumptions
and parameters. The component code of the rate=1/3 TC, G(D) =
[
1, 1+D
2+D3
1+D+D3
]
,
and the CRC-8(=“110011011”) code used are the same as those specified in the 3GPP
standard [66] except that the component code is tail-biting [7] encoded. The APP
decoder uses the Log-MAP algorithm and the S-IBP algorithm of Table 4.1 while the
interleaving length and S-IBP span are left as variables; MR = 3 MUs and N = 1000
per computer run are assumed. Except for the Genie ST, our simulations do not assume
perfect block termination.
The effects of various STs on the S-IBPTC VTT-APP decoder performance for the
system with S = 1, L = 400, Dmax = 30 and tail-biting encoding are shown in Figs. 5.8
and 5.9. Multiple-round CRCST, SCST and HST are considered. For comparison, we
112
0.0 0.2 0.4 0.6 0.8 1.0
1E-4
1E-3
0.01
0.1
1
Infinite Memory
Vairable DRs
 D
max
=200
Fixed DRs
 D
max
=20 84 MUs
 D
max
=30 124 MUs
Finite Memory
D
max
=30
 50 MUs
 60 MUs
 80 MUs
 100 MUs
100 MUs
 D
max
=50
 D
max
=100
B
lo
c
k
 E
rr
o
r 
R
a
te

E
b
/N
0
 (dB)
Figure 5.10: The effect of memory constraint and management on the block error rate
performance. Curves labelled with infinite memory are obtained by assuming no memory
constraint; “fixed DRs” implies that no early-stopping test is involved.
sign-check tests, all STs require less than 20 or 10 APP DRs (10 or 5 iterations) when
Eb/N0 is greater than 0.2 or 0.6 dB. Considering both block error rate and average
latency performance, we conclude that, among the STs we have examined, T3.2 is the
best choice.
The numerical results presented so far assume no memory constraint. Figs. 5.10 and
5.11 reveal the impact of finite memory size for the system that employs a T3.2-aided
VTT-APP decoder and the memory management algorithm of the previous section with
block length L = 400, the span S = 1 and Md = 1. Fig. 5.10 shows block error rate
performance for different memory constraints. For convenience of comparison, we also
present three cases without memory constraint, one with Dmax = 200, the other two with
fixed DRs. It is reasonable to find that larger memory sizes give better performance.
At higher Eb/N0(> 0.8 dB), all performance curves converge to the same one since
all VTT-APP decoders finish decoding after only a few DRs (see also Fig. 5.11) and
memory size is no longer a problem. The fact that the cases Dmax = 100 with 100
114
0.0 0.2 0.4 0.6 0.8 1.0 1.2 1.4 1.6 1.8 2.0 2.2 2.4
1E-5
1E-4
1E-3
0.01
0.1
1
 Genie
T1.1
 CRC-8
 CRC-12
 CRC-16
 CRC-24
T1.m CRC-8
 T1.2
 T1.3
T2.m
 T2.3
 T2.5
T3.m CRC-8
 T3.2
 T3.3
B
lo
c
k
 E
rr
o
r 
R
a
te

E
b
/N
0
 (dB)
Figure 5.12: Block error rate performance of a classic TC using various STs; L = 800
bits and Dmax = 30 DRs.
stoppings, saving computing power and memory at the cost of a small performance loss.
Finally, we find that, comparing with our proposed schemes, the two decoders with fixed
DRs (20 and 30) usually need much more memory and DRs.
The effectiveness of various STs on the performance of a classic TC with L = 800
are shown in Fig. 5.12 and Fig. 5.13 where Dmax = 30 DRs and tail-biting encoding
are assumed. The performance of T1.1 with CRC-24 is worse than those of T1.2 and
T3.2 with CRC-8. Using CRC-8, T2.3 provides error rate performance similar to that
of T3.2 but at the cost of one more DR. Both tests yield performance very close to
that of the genie ST. In summary, these two figures show that (i) the proposed MRSTs
can also be used in classic TC-coded systems and (ii) using a proper MRST has the
benefits of reduced CRC overhead and DRs (decoding latency) without compromising
the performance. The latter conclusion implies that a multiple-round test with a short
CRC code is better than a single-round test with a much longer CRC code. Of course,
the same advantages are shared by IBPTC-coded systems as well.
116
Chapter 6
Multi-stage factor graph
Multi-stage factor graph (MSFG) extended from factor graph [57, 58] elaborates
message-passing for iterative decoding. Factor graph expounds a code structure and one
can operate belief propagation (BP) algorithm on the graph. However, the graph only
shows the paths on the graph but does not indicate the schedule of real message-passing
flow. The MSFG, a directed graph, describes the message-passing flow which reflects a
decoding schedule. With the assistance of this graph the impact of the decoding schedule
on computing complexity and storage requirements can be analyzed. Moreover, our
representations avoid ambiguous description of cyclic or loopy message-passing events.
Multi-stage factor sub-graph (MSFSG) and causal multi-stage sub-graph (CMSSG)
shorten representation of the lengthy MSFG without demonstration loss of message
passing flow. The MSFG is a regular graph and looks like a duplication of a sub-
graph when the decoding schedule is regular. MSFSG, a sub-graph extracted from
MSFG, describes the operation flow associated with decoding round or iteration and it
is useful to represent block-type code such as B-IBPTC, conventional TC, LDPC [108],
etc. Causal multi-stage sub-graph (CMSSG), a sub-graph extracted from the MSFG,
describes the operation flow associated with each input bit or block of the streaming-
type code such as S-IBPTC, convolutional LDPC code [106, 109], etc. A schedule can
be acquired from the MSFSG and CMSSG. The dynamic decoder shown in Fig. 5.3 can
directly apply this schedule to coordinate multiple APP decoders.
118
• Edge redirection, wiping and adding connect multiple layers and reschedule message-
passing flow. The first purpose of edge redirection connects multiple layers. The
second purpose of edge redirection is to redirect the edge to prior stage or later
stage to increase or detain message-passing. Edge wiping removes edges and the
corresponding message-passing and node operations are avoided. At last edge
adding amends edges when a node requires a message when redirection removes
some edges at the initial stages.
We apply LDPC code [108] and S-IBPTC code to demonstrate multi-stage factor
graphs. For LDPC code, we compare conventional belief propagation (BP) algorithm [57]
and horizontal-shuﬄed BP algorithm [107]. Furthermore we will provide another graph
to demonstrate the BP algorithm reducing the cycle effect but requires more storage.
We also plot two MSFGs for the S-IBPTC associated with Fig. 5.2. One graph is in
accordance with the S-IBPTC pipeline decoding and the other is an aggressive algorithm
to increases message-passing speed. Both LDPC code and S-IBPTC are described in
the following two subsections.
6.1.1 LDPC code
Fig. 6.1 (a) shows a (7, 3) LDPC code factor graph with communication link and
the associated parity check matrix is Eqn. (6.1). The LDPC-encoded code bit ci is cor-
rupted by noise before becoming the received sample yi. On this graph, the round node
corresponds to the equality function and the cross square node corresponds to the parity
check function. Conventional BP algorithm floods information based on this graph. The
round node generates the extrinsic information based on the equality relation for the
cross square nodes, and the cross square node generates the extrinsic information based
on the parity check relation for the round nodes. After several iteration, it converges
and we apply the estimated reliability on the round to acquire to the decoded codeword.
However the decoded codeword may not be optimal because the cycle enhances the effect
120
2
1O
2
2O
2
3O
2
4O
4
1O
4
2O
4
3O
4
4O
6
1O
6
2O
6
3O
6
4O
1
1O
1
2O
1
3O
1
4O
1
5O
1
6O
1
7O
3
1O
3
2O
3
3O
3
4O
3
5O
3
6O
3
7O
5
1O
5
2O
5
3O
5
4O
5
5O
5
6O
5
7O
7
1O
7
2O
7
3O
7
4O
7
5O
7
6O
7
7O
Figure 6.2: Multi-stage factor graph for conventional BP.
H =

1 0 0 0 1 1 0
0 1 0 0 1 0 1
0 0 1 0 0 1 1
0 0 0 1 1 1 1
 . (6.1)
We plot the message corresponding to horizontal-shuﬄed BP (HSBP) algorithm [107]
shown in Fig. 6.3. This algorithm groups check nodes and scheduled the operation of
these grouped check nodes. In Fig. 6.3, the nodes {Oi1, Oi2} and the nodes {Oi3, Oi4} are
grouped separately, where the group {Oi1, Oi2} and the group {Oi3, Oi4)} process in turn.
Then the edges corresponding to {O21, O22, O61, O62, O43, O44, O83, O84} are wiped out.
The fact that the HSBP algorithm outperforms conventional BP algorithm can be
explained by Figs 6.2 and 6.3. In Fig. 6.2, start from the O15, there are two message-
passing routes: O15 → O21 → O36 → O44 → O55 and O15 → O24 → O36 → O41 → O55. Both
122
2
1O
2
2O
2
3O
2
4O
4
1O
4
2O
4
3O
4
4O
6
1O
6
2O
6
3O
6
4O
1
1O
1
2O
1
3O
1
4O
1
5O
1
6O
1
7O
3
1O
3
2O
3
3O
3
4O
3
5O
3
6O
3
7O
5
1O
5
2O
5
3O
5
4O
5
5O
5
6O
5
7O
7
1O
7
2O
7
3O
7
4O
7
5O
7
6O
7
7O
Figure 6.4: Multi-stage factor graph for the new scheduled BP which reduces cycle effect.
nodes {O21, O22, O23, O24}. Start from the node Oi5, there are two message-passing routes:
O15 → O21 → O36 → O64 → O75 and O15 → O24 → O36 → O61 → O75. These two routes merge
at the seventh stage and this decreases the influence of the node O5. However the cost
is extra buffer. Take the nodes O43 and O
6
3 as an example, the node accesses information
from the node O16 and the information from the node O
3
6 has to be stored. Comparing
to both conventional BP and the HSBP algorithms, the cycle effect decreases but the
necessary storage increases.
6.1.2 S-IBPTC
Fig. 6.5 the same as Fig. 5.2 shows a hierarchical factor graph representation of a
coded communication link based on S-IBPTC and CRC codes. There are five data blocks
124
The grouping and labelling step is used to simplify the following drawings and dis-
cussions. We use nodes Oi and Oi to denote the upper branch that includes the set of
nodes {di, ui, c0i , c1i , y0i , y1i } and the lower branch–nodes {u′i, c2i , y2i }–respectively;
see Fig. 6.6 (a). Fig. 6.6 (b) shows the grouped factor graph of the system shown in
Fig. 6.5.
i
O iO
1O
1O
2O
2O
3O
3O
4O
4O
5O
5O
(a)
(b)
iu
0
ic
1
ic
0
iy
1
iy
id
iu′
2
ic
2
iy
Figure 6.6: (a) Node grouping; (b) grouped factor graph.
We extend undirected factor graph to a directed multi-stage factor graph (MSFG).
Fig. 6.7 shows a directed factor graph extended from the simplified graph shown in Fig.
6.6 (b). Nodes Oi and Oi are stamped by O
j
i and O
j
i respectively, where j denotes the
jth APP decoding round (ADR) corresponding to the ith block. This graph has three
layers and the corresponding numbers of iterations and stages are 3 and 6 respectively.
The performance of Fig. 6.7 is equivalent to the pipeline decoder, the pipeline decoder
requires the least memory storage and is the shortest latency realization, when the
stopping mechanism is not considered. We refer this schedule to standard schedule.
126
1
1O
1
2O
1
3O
1
4O
1
5O
2
1O
2
2O
2
3O
2
4O
2
5O
3
1O
3
2O
3
3O
3
4O
3
5O
4
1O
4
2O
4
3O
4
4O
4
5O
5
1O
5
2O
5
3O
5
4O
5
5O
6
1O
6
2O
6
3O
6
4O
6
5O
7
1O
7
2O
7
3O
7
4O
7
5O
8
1O
8
2O
8
3O
8
4O
8
5O
Figure 6.8: A multi-stage factor graph representation of an aggressive S-IBPTC decoding
procedure.
6.2 Multi-stage factor sub-graph
Multi-stage factor sub-graph (MSFSG) shortens the MSFG without demonstration
loss of message-passing. The MSFG clearly shows message-passing flow but requires
multiple stages. In general the graph is huge due large number of iterations or stages.
Fortunately, the MSFG is regular and can be composed of multiple small graphs. We
extract a this small graph from the MSFG and the graph is MSFSG. The same as
the previous section, we shows LDPC code and S-IBPTC code in the following. These
exemplary graphs may be not the most compact graph but this help us to acquire
drawing guidelines.
6.2.1 LDPC code
Fig. 6.9 shows the MSFSGs corresponding to the (7,3) LDPC code shown in Fig.
6.1 (b), where these graphs are sub-graphs of Figs. 6.9, 6.3 and 6.4. Conventional BP
algorithm provides the most regular graph and three stages sub-graph shown in Fig. 6.9
128
i
O1
i
O2
i
O3
i
O4
i
O5
1
1
+i
O
1
2
+i
O
1
3
+i
O
1
4
+i
O
1
5
+i
O
2
1
+i
O
2
2
+i
O 23
+i
O
2
4
+i
O 25
+i
O
(a)
i
O1
i
O2
i
O3
i
O4
i
O5
1
1
+i
O
1
2
+i
O
1
3
+i
O
1
4
+i
O
1
5
+i
O
2
1
+i
O
2
2
+i
O 23
+i
O
2
4
+i
O 25
+i
O
3
1
+i
O
3
2
+i
O
3
3
+i
O
3
4
+i
O
3
5
+i
O
(b)
Figure 6.10: (a) The multi-stage factor sub-graph extracted from Fig. 6.7; (b) the
multi-stage factor sub-graph extracted from Fig. 6.8.
stages the nodes {O12, O14, O16} pass messages to the second and fourth stages. This
irregularity requires an extra initial sub-graph drawn in Fig. 6.13 (d) to complete the
representation of MSFSG.
6.2.2 S-IBPTC
Fig. 6.11 plots the S-IBPTC MFSFG associated with Figs. 6.7 and 6.8. The stan-
dard schedule only passes information to the next stage and three stages are enough to
represent the associated MSFG; Fig. 6.11 (a) plots the associated MSFSG. The new
S-IBPTC schedule shown in Fig. 6.8 passes messages across three stages and therefore
four stages are necessary to represent the complete graph. Fig. 6.11 (b) shows the
associated MSFSG.
6.2.3 Discussion
The MSFG is generally regular and the extraction of the MSFSG depends on the
number stages an edge across. The irregularity often occurs at initial stages and we can
draw a sub-graph for this case.
130
(a)
1
43
P
1
43P
1
45P
1
44
P
(b)
1
70
P
1
71P
1
73P
1
72
P
1
40
P
1
41P
1
75P
1
74
P
Figure 6.12: Virtual nodes.
6.11 (a) and (b) from Figs. 6.7 and 6.8. In Fig. 6.7, the CMSSG is composed of
{O14, O23, O32, O41}; real-line denotes message-passing for the instance of the 4th block
input and dashed-line denotes message-passing with the other sub-graphs. We elimi-
nate dashed-line and tilt sub-graph to render the corresponding CMSSG Fig. 6.11 (c)
composed of {P 140, P 141, P 142, P 143}. Similarly, we can have the CMSSG Fig. 6.11 (d)
corresponding to Fig. 6.8.
Decoding schedule for each input instance is also clearly pointed out by these graphs.
In Fig. 6.11 (c), decoder decodes align nodes P 140 → P 141 → P 142 → P 143. In Fig. 6.11
(d), decoder decodes align nodes P 141 → P 241 → P 142 → P 242 → P 143 → P 243.
The ordinal number of the stage to the node P ijl or P
i
jl for the original MSFG can
be counted as follows. Define the maximum stage of each column in the CMSSG by
NS(l) = argimax(P
i
jl, P
i
jl). The ordinal number of P
i
jl or P
i
jl is i +
∑l−1
m=1NS(m). P
i
jl
and P ijl in the CMSSG can be simply mapped to O
i+
∑l−1
m=1NS(m)
j−l and O
i+
∑l−1
m=1NS(m)
j−l in
the MSFG respectively.
The CMSSG not only successively describes schedule but also is useful in memory
counting. Each CMSSG represents the operation range. Fig. 6.11 (d) requires memory
storage for 4 blocks of received samples and temporary extrinsic information; necessary
storage is easily counted.
Virtual node concept is introduced for finite steaming-type codes to deal with the
132
1
1i
O
−
1
2i
O
−
1
3i
O
−
1
i
O
1
4i
O
−
1
5i
O
−
2
1i
O
−
2
2i
O
−
2
3i
O
−
2
i
O
2
4i
O
−
2
5i
O
−
3
1iO−
3
2iO−
3
3iO−
3
iO
3
4iO−
3
5iO−
4
1i
O
−
4
2i
O
−
4
3i
O
−
4
i
O
4
4i
O
−
4
5i
O
−
Figure 6.14: Multi-stage factor graph representation of Fig. 6.13.
SNRs as early-stopping implemented in the dynamic decoder, leading to more forced
early-terminations and deteriorated performance. A candidate solution to avoid forced
early-terminations is to start a new decoding round before all the information within
its span becomes available. Inevitably, such an early-start decoding has to use some
non-updated extrinsic information. Invoking the early-start concept, we propose the
decoding schedule shown in Fig. 6.13. There are three schedule-related parameters:
iteration number (IN), repeated decoding rounds (RDR) and decoding window width
(DWW). When the maximum numbers l of P ijl of both schedule are set to 5, the decoding
procedure for each input block shown in Fig. 6.7 undergoes at most 6 ADRs but the
proposed schedule undergoes at most
(IN+DWW)(IN+1)RDR
4
+ 1 = 25 ADRs. Since
the information associated with each block is used more often, the decoder converges
with less information (but worse performance) and therefore requires smaller memory
space.
The kth incoming block can be immediately decoded and interleaved by the pre-
permutation node P 1k0 whose post-permutation counterpart will not be initiated until
all related blocks are received. Fig. 6.14 shows the corresponding partial MSFG with
4 stages and one can find the pre-permutation part successively processed by twice at
beginning. This benefits the S-IBPTC performance but pays the computation power.
At low SNRs, the convergence speed is slow and the required memory is large. The
134
0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0
1E-6
1E-5
1E-4
1E-3
0.01
Standard Schedule
 MEM=50
 MEM=60
 MEM=80
B
it
 E
rr
o
r 
R
a
te

E
b
/N
0
 (dB)
Schedule A
MEM=40
 IN=10 RDR=2 DWW=2
MEM=45
 IN=10 RDR=2 DWW=2
 IN=10 RDR=2 DWW=3
MEM=50
 IN=10 RDR=2 DWW=1
 IN=10 RDR=2 DWW=2
Schedule B
 MEM=50 IN=10 
           RDR=2 DWW=2 
Figure 6.15: BER performance as a function of SNR for three decoding schedules.
0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0
5
10
15
20
25
30
35
Standard Schedule
 MEM=50
 MEM=60
 MEM=80
Schedule A
MEM=40
 IN=10 RDR=2 DWW=2
MEM=45
 IN=10 RDR=2 DWW=2
 IN=10 RDR=2 DWW=3
MEM=50
 IN=10 RDR=2 DWW=1
 IN=10 RDR=2 DWW=2
Schedule B
MEM=50
 IN=10 RDR=2 DWW=2
A
v
e
ra
g
e
 n
u
m
b
e
r 
o
f 
A
P
P
 d
e
c
o
d
in
g
 r
o
u
n
d
s

E
b
/N
0
 (dB)
Figure 6.16: Average APP decoding round number performance as a function of SNR
for three decoding schedules.
136
and a memory management scheme. The stopping rule requires short overhead but of-
fers very reliable stopping decisions, giving improved latency and error rate performance.
The memory manager makes efficient use of the memory space available and offers new
tradeoff between complexity and performance.
To analyze and describe various decoding schedules for IBPTCs we generalize the
static factor graph representation and develop the multi-stage factor graphs. This tech-
nique is capable of expounding the behaviors of streaming IBPTCs and LDPC codes.
Using MSFGs, we develop a new decoding scheduling for streaming IBPTCs with re-
duced memory storage.
We have addressed almost all critical performance and implementation issues con-
cerning the design of high throughput CTCs and provided good, if not the best, solutions.
Some algorithms proposed here are also applicable to other applications. For examples,
the early-stopping rules can be used for other iterative decoding or equalization schemes,
and the multi-stage factor graphs are useful in designing new LDPC or general graph
code’s decoding schedules or even new graph codes with enhanced performance.
138
This permutation function is q-invariant in that
|piP (|i− q|P )− piP (|j − q|P )|P
=
∣∣∣∣∣∣∣∣r(i− q) + (i− q)− |i− q|qq
∣∣∣∣
P
−
∣∣∣∣r(j − q) + (j − q)− |j − q|qq
∣∣∣∣
P
∣∣∣∣
P
=
∣∣∣∣∣∣∣∣ri+ i− |i|qq
∣∣∣∣
P
−
∣∣∣∣rj + j − |j|qq
∣∣∣∣
P
∣∣∣∣
P
= |piP (i)− piP (j)|P (A.4)
We now show that both the remaining cases can be converted into the above case.
(A) For the case i < j and 0 < j − i < r, we have |i− j|P = |i+ P − j|P = |i+ P −
mq− (j−mq)|P = |i′− j′| and |piP (|i+P −mq|P )−piP (|j−mq|P )|P = |piP (i)−piP (j)|P ,
P > i′ = |i+ P −mq|P > j′ = |j −mq|P ≥ 0 for some m > 0.
(B) If i > j, P − |i − j|P = |P + j − i|P = |P + j −mq − (i −mq)| = |j′ − i′| and
|piP (|i−mq|P )−piP (|P + j−mq|P )|P = |piP (i)−piP (j)|P , P > i′ = |i+P −mq|P > j′ =
|j −mq|P ≥ 0 for some m > 0.
140
Appendix C
Proof of Theorem 3.3
Tail-biting encoding results in low-weight codewords whose nonzero coordinates are
confined to the tail and the head parts of two consecutive sets. This happens if one
nonzero coordinate of a weight-2 input sequence belongs to z
(k)
i and the other one
belongs to z
(k)
|i+Tc−|L|Tc |Tc . One can then place the set z
(k)
|i+Tc−|L|Tc |Tc right after the set
z
(k)
i so that they form a cycle. If gcd(|L|Tc , Tc) = d, we have d cycles with the mth
cycle being z˜
(k)
m =
{
z
(k)
m ,z
(k)
|m+Tc−|L|Tc |Tc ,z
(k)
|m+2(Tc−|L|Tc )|Tc , · · · , z
(k)
|m+(Tcd −1)(Tc−|L|Tc )|Tc
}
,
where 0 ≤ m < d.
Mapping the coordinates in z˜
(k)
m sequentially to the integers in the interval
[
0, |z˜(k)m | − 1
= L
d
− 1], we obtain the set S|z˜(k)m | = {0, 1, 2, · · · , Ld − 1}. We further partition S|z˜(k)m |
into dTs sets {Si}, where |Si| = Nmax =
⌈
L
d2Ts
⌉
for 0 ≤ i < N1 =
∣∣L
d
∣∣dTs and
|Si| = Nmin =
⌊
L
d2Ts
⌋
for dTs − N2 =
∣∣L
d
∣∣dTs ≤ i < dTs. According to Lemma
3.7, we can maximize the minimum separation of Si to Dmin = dTs −
⌈
N2
Nmax
⌉
and
Dmax = dTs −
⌊
N2
Nmax
⌋
for 0 ≤ i < N1 and dTs −N2 ≤ i < dTs respectively.
We can construct an IBP rule such that p ∈ Si and q ∈ Sj are permuted to the same
block iff |i−j|Ts = 0. Since all blocks can apply the same partition rule for permutation,
such an IBP rule does exist.
Incorporating separate encoding results in that two indexes in two different blocks
produce a codeword weight larger than the bound, either the pre-permuted or the post-
permuted pair makes the codeword weight 2W1(L). Therefore we consider the case two
142
Appendix D
Proof of Theorem 4.5
We first notice that, besides those finite weight codewords resulting from termination,
as illustrated in Fig. 4.6, there are three conditions under which a weight-4 input se-
quence of an S-IBPTC will generate a finite-weight codeword. In Case (a), the codeword
consists of two finite-weight segments (in different blocks) generated respectively by two
weight-2 input sequences and thus the corresponding codeword weight upper-bound is
simply twice that given in Theorem 4.4. Case (b) considers the situation when two
pairs of coordinates from z
(1)
i and z
(1)
j of either the same block or different blocks are
permuted to the same block with one coordinate from each pair mapped to two subsets
z
(2)
k and z
(2)
l , where the pair (k, l), k 6= l belongs to the same equivalence class while the
remaining two coordinates mapped to another two subsets z
(2)
m and z
(2)
n with m 6= n in
another equivalence class. Case (c) is similar to Case (b) except that the two subsets
that contain the two permuted pairs are in different blocks.
Note that if k = l and m = n then the both cases will result in a codeword weight
upper-bound similar to that obtained in [33]. But this is impossible as coordinates from
different blocks will not be mapped into coordinates in the same subset (defined by
(4.13)) by an optimal interleaver. This is because the spatial symmetric structure of a
classic TC implies that, for every input sequence u of the code C that uses the inter-
leaver pi, ∃ u′ such that the codewords generated by (u, pi) and (u′, pi−1) have identical
weight. This observation and the fact that both component encoder outputs, c1 and c2,
144
blocks in which each block contains Λ1
Ts
supersubsets and each supersubset has at most
(Ω+1)2 and at least Ω2 coordinates pairs to the two designated blocks. Therefore, finite
weight codewords result if
(Ts − k)Λ1
Ts
Ω2 >
(
Λ2
Ts
)2
(D.2)
and we obtain upper-bounded
w4,min,ibp ≤ 4 + 2α ·
(
min
(Λ1,Λ2)
{⌈
Ts · L
Λ1
⌉
+
⌈
Ts · L
Λ2
⌉}
− 2
)
+ 4β (D.3)
where (Λ1,Λ2) are subject to the constraints, (C1): ||Λ1||M = ||Λ2||M = 0, (C2): Λ1
(
Ω
2
)
>(Λ2
Ts
2
)
, and (C3): (Ts−k)
Ts
Λ1Ω
2 >
(
Λ2
Ts
)2
. Since Ω = b L
Λ1
c > L
Λ1
− 1, we rewrite (D.1) and
(D.2) as
Λ1
(
L
Λ1
− 1
)(
L
Λ1
− 2
)
≥
(
Λ2
Ts
− 1
)
Λ2
Ts
(D.4)
Ts − k
Ts
Λ1
(
L
Λ1
− 1
)2
≥
(
Λ2
Ts
)2
(D.5)
We carry out the minimization with respect to (Λ1,Λ2) by first finding the two minimums
with respect to the constraints (C1)/(C2) and (C1)/(C3), respectively, and then select
the smaller one of these two. Using the simplified assumption [33] that the cardinalities
of Λ1 and Λ2 are the same and to distinguish the two candidate minimums, we set
Λ1 = Λ2 = Λ3 in (D.5) and Λ1 = Λ2 = Λ4 in (D.5) so that the above two inequalities
become
Λ33 − (Ts + 2T 2s )Λ23 + 3T 2s Λ3L− T 2s L2 ≤ 0 (D.6)
Λ34 − Ts(Ts − k)Λ24 + 2Ts(Ts − k)Λ4L− Ts(Ts − k)L2 ≤ 0 (D.7)
By definingX1 = Λ3−Ts−2T
2
s
3
andX2 = Λ4−Ts(Ts−k)3 , we rewrite the above inequalities
as
X31 +
(
3T 2s L−
1
3
(Ts + 2T
2
s )
2
)
X1 +
(
−T 2s L2 + (T 3s + 2T 4s )L−
2
27
(Ts + 2T
2
s )
3
)
≤ 0
(D.8)
146
q2 − q1
= −Ts(Ts − k)L2 + 2
3
T 2s (Ts − k)2L−
2
27
T 3s (Ts − k)3 + T 2s L2 − (T 3s + 2T 4s )L+
2
27
(Ts + 2T
2
s )
3
> kTsL
2 +
2
3
T 2s (Ts − k)2L− (T 3s + 2T 4s )L > LTs
(
L+
2
3
T 2s − (T 2s + 2T 3s )
)
> LTs
(
10
3
T 3s + T
2
s −
Ts
3
− (T 2s + 2T 3s )
)
> 0. (D.15)
These results imply (p1
3
)3 + ( q1
2
)2 > 0, (p2
3
)3 + ( q2
2
)2 > 0 and
Λ3 ≤ Ts + 2T
2
s
3
+
3
√
−q1
2
+
√
(
p1
3
)3 + (
q1
2
)2 +
3
√
−q1
2
−
√
(
p1
3
)3 + (
q1
2
)2
def
= C(D.16)
Λ4 ≤ Ts(Ts − k)
3
+
3
√
−q2
2
+
√
(
p2
3
)3 + (
q2
2
)2 +
3
√
−q2
2
−
√
(
p2
3
)3 + (
q2
2
)2
def
= D.(D.17)
It can be shown that
G =
3
√
−q1
2
+
√
(
p1
3
)3 + (
q1
2
)2 +
3
√
−q1
2
−
√
(
p1
3
)3 + (
q1
2
)2 > 0 (D.18)
H =
3
√
−q2
2
+
√
(
p2
3
)3 + (
q2
2
)2 +
3
√
−q2
2
−
√
(
p2
3
)3 + (
q2
2
)2 > 0 (D.19)
are zeros of f(x) = x3+p1x+q1 and h(x) = x
3+p2x+q2, respectively. As both f(x) and
g(x) are monotonically increasing functions and f ′(x) = 3x2 + p1 > g′(x) = 3x2 + p2 >
0,∀ x, f(x) < g(x),∀ x < xˆ, where xˆ is the single intersection point given by
xˆ =
q2 − q1
p1 − p2 > 0.
The fact that
f(xˆ) = (
q2 − q1
p1 − p2 )
3+p1
q2 − q1
p1 − p2+q1 = (
q2 − q1
p1 − p2 )
3+
p1q2 − p2q1
p1 − p2 > (
q2 − q1
p1 − p2 )
3+
p2q2 − p2q1
p1 − p2 > 0.
implies that the only real zero of f(x), G, is larger than that of g(x), H, and thus C > D.
Substituting Λi = C into (A.3), we obtain an upper-bound with a very complicated
expression. To have an upper-bound with a simpler form, we notice that ||Λi||M=TcTs = 0
gives
max Λi = TsTc
⌊
C
Ts · Tc
⌋
> C − TsTc (D.20)
148
real numbers and
T 4s
(
10
3
T 3s + T
2
s −
Ts
3
)
− (T
3
2
s + 3T
5
2
s )
2 =
10
3
T 7s + T
6
s −
T 5s
3
− 9T 5s − 6T 4s − T 3s
>
40
3
T 5s + 2T
5
s −
T 5s
3
− 9T 5s − 6T 4s − T 3s
> 12T 5s − 6T 4s − T 3s > 0.
Hence E is positive and so
4 + 4α · TsL
C − TsTc + 4β < 4 + 4α
TsL√
TsL− TsTc
+ 4β = 2
(
2 + 2α
TsL√
TsL− TsTc
+ 2β
)
.(D.25)
150
Table E.1: Puncturing patterns for code rate=3/4.
Regular Puncturing Pattern
C0 11111111 11111111 11111111 11111111 11111111 11111111
C1 10000010 00001000 00100000 10000010 00001000 00100000
C2 10000010 00001000 00100000 10000010 00001000 00100000
Irregular Puncturing Pattern
C0 10111111 10111111 10111111 10111111 10111111 10111111
C1 01000100 01000100 01000100 01000100 01000100 01000000
C2 01000100 01000100 01000100 01000100 01000100 01000000
Table E.2: Puncturing patterns for code rate=4/5.
Regular Puncturing Pattern
C0 11111111 11111111 11111111 11111111 11111111 11111111
C1 10000000 10000000 10000000 10000000 10000000 10000000
C2 10000000 10000000 10000000 10000000 10000000 10000000
Irregular Puncturing Pattern
C0 10111111 10111111 10111111 10111111 10111111 10111111
C1 01000100 01000000 01000100 01000000 01000100 01000000
C2 01000100 01000000 01000100 01000000 01000100 01000000
property may be improved.
The performance gain for the B-IBPTC is more than that for 3GPP Rel’6 turbo code.
When code rate=3/4 and 4/5, the performance curves for interleaver length 4096 bits
are crossed but this does not occur for the B-IBPTC. Our irregular puncturing pattern
benefit more a turbo code with better distance property.
Table E.3: Puncturing patterns for code rate=8/9.
Regular Puncturing Pattern
C0 11111111 11111111 11111111 11111111 11111111 11111111
C1 10000000 00000000 10000000 00000000 10000000 00000000
C2 10000000 00000000 10000000 00000000 10000000 00000000
Irregular Puncturing Pattern
C0 10111111 11111011 11111111 10111111 11111011 11111111
C1 10100000 00000100 00000000 01000000 00000100 00000000
C2 10100000 00000100 00000000 01000000 00000100 00000000
152
2.0 2.5 3.0 3.5 4.0 4.5 5.0
1E-5
1E-4
1E-3
0.01
0.1
1
B-IBPTC
 L=128, N=2
 L=64, N=8
 L=128, N=8
 L=128, N=16
 L=128, N=32
3GPP Rel'6
 K=256
 K=512
 K=1024
 K=2048
 K=4096
F
ra
m
e
 E
rr
o
r 
R
a
te

E
b
/N
0
 (dB)
Figure E.3: Frame error rate comparison between 3GPP Rel’6 turbo code and B-IBPTC
for code rate=3/4 irregular puncturing pattern.
2.0 2.5 3.0 3.5 4.0 4.5 5.0 5.5
1E-5
1E-4
1E-3
0.01
0.1
1
Regular Puncturing
 K=256
 K=512
 K=1024
 K=2048
 K=4096
Irregular Puncturing
 K=256
 K=512
 K=1024
 K=2048
 K=4096
F
ra
m
e
 E
rr
o
r 
R
a
te

E
b
/N
0
 (dB)
Figure E.4: Frame error rate comparison between regular and irregular puncturing pat-
terns for code rate=4/5 3GPP Rel’6 turbo code.
154
3.0 3.5 4.0 4.5 5.0 5.5 6.0 6.5 7.0 7.5
1E-5
1E-4
1E-3
0.01
0.1
1
Regular Puncuring
 K=256
 K=512
 K=1024
 K=2048
 K=4096
Irregular Puncturing
 K=256
 K=512
 K=1024
 K=2048
 K=4096
F
ra
m
e
 E
rr
o
r 
R
a
te

E
b
/N
0
 (dB)
Figure E.7: Frame error rate comparison between regular and irregular puncturing pat-
terns for code rate=8/9 3GPP Rel’6 turbo code.
3 4 5 6 7 8
1E-5
1E-4
1E-3
0.01
0.1
1
Regular Puncturing
 L=128, N=2
 L=64, N=8
 L=128, N=8
 L=128, N=16
 L=128, N=32
Irregular Puncturing
 L=128, N=2
 L=64, N=8
 L=128, N=8
 L=128, N=16
 L=128, N=32
F
ra
m
e
 E
rr
o
r 
R
a
te

E
b
/N
0
 (dB)
Figure E.8: Frame error rate comparison between regular and irregular puncturing pat-
terns for code rate=8/9 B-IBPTC.
156
Bibliography
[1] C. Berrou, A. Glavieux, and P. L. Thitimajshima, “Near Shannon limit error-
correcting coding and decoding: turbo-codes,” in Proc. Proc. IEEE Int’l Conf.
Commun., Geneva, Switzerland, pp. 1064-1070, May 1993.
[2] C. Berrou, M. Je´ze´quel, “Non-binary convolutioanl codes for turbo coding,” Elec-
tronics. Letters, vol. 35, no. 1, pp. 39-40, Jan 1999.
[3] C. Berrou, M. Je´ze´quel, C. Douillard, S. Kerouedan, “The advantages of non-binary
turbo codes,” in Proc. ITW2001, Sep. 2001.
[4] A. Perotti, S. Benedetto, “A new upper bound on the minimum distance of turbo
codes,” IEEE Trans. Inform. Theory, vol. 50, no. 12, pp. 2985-2997, Dec. 2004.
[5] S. Benedetto, G. Montorsi,“Performance of continuous and blockwise decoded turbo
codes,” IEEE Commun. Lett., vol. 1, no. 3, pp. 77-79, May 1997.
[6] J. L. Massey, M. K. Sain, “Codes, automata, and continuous systems: explicit
interconnections,” IEEE Trans. on Automatic Control, AC-12:644-650, 1968.
[7] C. Weiss, C. Bettstetter and S. Riedel, “Code construction and decoding of parallel
concatenated tail-biting codes,” IEEE Trans. Inform. Theory, Vol. 47, no. 1, pp.
366-386, Jan. 2001.
[8] L. C. Perez, J. Seghers, D. J. Costello, “A distance spectrum interpretation of turbo
codes,” IEEE Trans. Inform. Theory, Vol. 42, no. 6, pp. 1698-1709, Nov. 1996.
158
[19] E. K. Hall, S. G. Wilson, “Stream-oriented turbo codes,” IEEE Trans. Inform.
Theory, vol. 47, no. 5, pp. 1813-1831, Jul. 2001.
[20] V. Poor, S. Verdu´, “Probability of error in MMSE multiuser detection,” IEEE
Trans. Inform. Theory, vol. 43, no. 3, pp. 858-871, May 1997.
[21] H. Jin, A. Khandekar, R. McEliece, “Irregular repeat-accumulate codes,” in Proc.
3rd Int’l Sympo. on Turbo Codes & Related Topics, Brest, France, pp. 1-8, Sep.
2000.
[22] P. Hoeher, J. Lodge, ““Turbo DPSK”: iterative differential PSK demodulation and
channel decodign,” in IEEE Trans. Commun., vol. 47, no. 6, pp. 837-843 , Jun.
1999.
[23] S. Y. Le Goff, “Signal constellations for bit-interleaved coded modulation,” in IEEE
Trans. Inform. Theory, vol. 49, no. 1, pp.307-313, Jan. 2003.
[24] X. Li, J. A. Ritcey, “Trellis-coded modulation with bit interleaving and iterative
decoding,” in IEEE J. Select. Areas Commun., vol. 17, no. 4, pp. 715-724, Apr.
1999.
[25] S. Baero, J. Hagenauer, M. Witzke, “Iterative detection of MIMO transmission
using a list-sequenctial (LISS) detector,” in Int’l Conf. Commun., Anchorage, USA,
May 2003.
[26] W. Feng, J. Yuan, B. S. Vucetic, “A code-matched interleaver design for turbo
codes,” in IEEE Trans. Commun., vol. 50, no. 6, pp. 926-937, Jun. 2002.
[27] E. Boutillon, D. Gnaedig, “Maximum spread of D-dimensional multiple turbo
codes,” IEEE Trans. Commun., vol. 53, no. 8, pp. 1237-1242, Aug. 2005.
160
[37] J. Ryu, O. Y. Takeshita, “On quadratic inverses for quadratic permutation poly-
nomials over integer rings,” in IEEE Trans. Inform. Theory, vol. 52, no. 3, pp.
1254-1260, Mar. 2006.
[38] O. Y. Takeshita, “On maximum contention-free interleavers and permutation poly-
nomials over integer rings,” in IEEE Trans. Inform. Theory, vol. 52, no. 3, pp.
1249V1253, Mar. 2006.
[39] O. Y. Takeshita, “Permutation polynomial interleavers: an algebraic-geometric per-
spective,” in IEEE Trans. Inform. Theory, vol. 53, no. 6, pp. 2116-2132, Jun. 2007.
[40] C. Berrou, Y. Saouter, C. Douillard, S. Ke´roue´dan, M. Je´ze´quel, “Designing good
permutations for turbo codes: towards a single model,” in Proc. IEEE Int’l Conf.
Commun., Paris, France, vol. 1, pp. 341-345, Jun. 2004.
[41] S. Crozier, J. Lodge, P. Guinand, A. Hunt, “Performance of turbo codes with
relative prime and golden interleaving strategies”, in Proc. of the 6th Int’l Mobile
Satellite Conference (IMSC ’99), Ottawa, Ontario, Canada, pp. 268-275, Jun. 16-
18, 1999.
[42] S. Crozier, P. Guinand, “Distance upper bounds and true miimum distance restuls
for turbo codes with DRP interleavers,” in Proc. 3rd Int’l Sympo. on Turbo Codes
& Related Topics, Brest, France, pp. 169-172, Sep. 2003.
[43] O. Gazi, O¨. Yilmaz, “Fast decodable turbo codes,” in IEEE Commun. Letters, vol.
11, no. 2, pp. 173-175, Feb. 2007.
[44] F. Daneshgaran, P. Mulassano, “Interleaver pruning for construction of variable-
length turbo codes,” in Trans. Inform. Theory vol. 50, no.3, pp. 455-466, Mar.
2004.
162
[53] M. C. Valenti, J. Sun, “The UMTS turbo code and an efficient decoder implemen-
tation suitable for software-defined radios,” in Int’l Journal of Wireless Information
Networks, vol. 8, no. 4, pp. 203-215, Oct. 01.
[54] S. Paraharalabos, P. Sweeney, B. G. Evans, “Constant log-MAP decoding algorithm
for duo-binary turbo codes,” Electronics Letters, vol. 42, no. 12, pp. 709-710, Jun.
2006.
[55] N. Wiberg, “Codes and decoding on general graphs,” Dept. Electrical Eng., Linkop-
ing Univ., Linkoping, Sweden, 1996.
[56] S. Benedetto and G. Montorsi, “Unveiling turbo codes: some results on parallel
concatenated coding schemes,” IEEE Trans. Inform. Theory, vol. 42, no. 2, pp.
409-428, Mar. 1996.
[57] F. R. Kschischang, B. J. Frey, H.-A. Loeliger, “Factor graphs and the sum-product
algorithm,” IEEE Trans. Inform. Theory, vol. 47, no. 2, pp. 498-519, Feb. 2001.
[58] G. D. Forney, Jr., “Codes on graphs: normal realizations,” IEEE Trans. Inform.
Theory, vol. 47, no. 2, pp. 520-548, Feb. 2001.
[59] H. El Gamal and A. R. Hammons,Jr., “Analyzing the turbo decoder using the
Gaussian approximation,” IEEE Trans. Inform. Theory, vol. 47, no. 2, pp. 671-686,
Feb. 2001.
[60] S. T. Brink, “Convergence of iterative decoding,” Electronics Letters, vol. 35, no.
13, pp. 1117-1119, Jun. 1999.
[61] S. ten Brink, “Convergence behavior of iteratively decoded parallel concatenated
codes,” in IEEE Trans. Commun., vol. 49, no. 10, pp. 1727-1737, Oct. 2001.
164
[73] S. B. Wicker, Error control systems for disgital communication and storage 2nd ed.,
Prentice Hall, 1995.
[74] R. Johannesson, K. Sh. Zigangirov, Fundamentals of convolutional codes, IEEE
Press, 1999.
[75] R. Brualdi, Introductory combinatorics, Amsterdam, The Netherlands: North-
Holland, 1977.
[76] W. Gellert, H. Justner, M. Hellwich, H. Kastner, The VNR concise encyclopedia of
mathematics, Van Nostrand Reinhold, pp. 97-99, 1977.
[77] W. WolfModern VLSI design-system on chip design, 3rd ed., Baker & Taylor Books,
2002.
[78] R. Y. Shao, S. Lin, and M. P. C. Fossorier, “Two simple stopping criteria for turbo
decoding,” IEEE Trans. Commun., vol. 47, no. 8, Aug. 1999.
[79] A. Matache, S. Dolinar, F. Pollara, “Stopping rules for turbo decoders,” in TMO
Progress Report 42-142, 15 Aug. 2000.
[80] D. Agrawal, A. Vardy, “The turbo decoding algorithm and its phase trajectories,”
IEEE Trans. Inform. Theory, vol. 47, no. 2, pp. 699-722, Feb. 2001.
[81] J. B. Anderson, S. M. Hladik,“Tailbiting MAP decoders,” IEEE J. Select. Areas
Commun., vol. 16, no. 2, pp. 297-302, Feb. 1998.
[82] R. J. McEliece, D. J. C. MacKay, J.-F Cheng “Turbo decoding as an instance of
Pearl’s “Belief propagation” algorithm,” IEEE J. Select. Areas Commun., vol. 16,
no. 2, pp. 260-264, Feb. 1998.
[83] I. Sason, S. Shamai,“Improved upper bounds on the ML decoding error proba-
bility of parrallel and serial concatenated turbo codes via their ensemble distance
spectrum,” IEEE Trans. Inform. Theory, vol. 46, no. 1, pp. 24-47 Jan. 2000.
166
[92] P. Urard, L. Paumier, M. Viollet, E. Lantreibecq, H. Michel, S. Muroor, B. Gupta,
“A generic 350Mb/s turbo-codec based on a 16-states SISO decoder,” in ISSCC
Dig. Tech. Papers, pp. 424-536, 2004.
[93] G. Prescher, T. Gemmeke, T. G. Noll, “A parametrizable low-power high-
throughput turbo-decoder,” in IEEE ICASSP 2005, vol. 5, pp. 25-28, Mar. 2005.
[94] E. Boutillon, W. J. Gross, P. G. Gulak, “VLSI architectures for the MAP algo-
rithm,” IEEE Trans. Commun., vol. 51, no. 2, pp. 175-185, Feb. 2003.
[95] M. J. Thul, F. Gilbert, N. Wehn, “Optimized concurrent interleaver for high-speed
turbo-decoding,” in Proc. IEEE Int’l Conf. Electronics, Circuits Sys., Dubrovnik,
Croatia, pp. 1099-1102, Sep. 2002.
[96] M. Thul, N. Wehn, L. Rao, “Enabling high-throughput turbo-decoding throughput
concurrent interleaving,” in Proc. IEEE Int’l Sympo. on Circuits and Systems, pp.
897-900, Phoenix, USA, May 2002.
[97] O. Muller, A. Baghdadi, M. Je´ze´quel, “ASIP-based multiprocessor SOC design for
simple and double binary turbo decoding,” in Proc. Design, Automation and Test
in Europe, pp. 6-10, Mar. 2006,
[98] H. Moussa, O. Muller, A. Baghdadi, M. M. Je´ze´quel, “Butterfly and Benes-based
on-chip communication networks for multiprocessor turbo decoding,” in Proc. De-
sign, Automation and Test in Europe, pp. 654-659, Apr. 2007.
[99] A. Tarable, S. Benedetto, “Mapping interleaving laws to parallel turbo decoder
architectures,” IEEE Commun. Letters, vol. 8, no. 3, pp. 162-164, Mar. 2004.
[100] A. Tarable, S. Benedetto, G. Montorsi, “Mapping interleaving laws to parallel
turbo and LDPC decoder architectures,” in IEEE Trans. Inform. Theory, vol. 50,
no. 9, pp. 2002-2009, Sep. 2004.
168
[109] R. M. Tanner, D. Sridhara, A. Sridharan, T. E. Fuja, D. J. Costello “LDPC block
and convolutional codes based circulant matrices,” IEEE Trans. Inform. Theory,
vol. 50, no. 12, pp. 2966-2984, Dec. 2004.
[110] M. P. C. Fossorier, “Quasi-cyclic low-density parity-check codes from circulant
permutation matrices,” IEEE Trans. Inform. Theory, vol. 50, no. 8, pp. 1788-1793,
Aug. 2004.
[111] S. Winograd, “On computing the discrete Fourier transform,” Mathematics of
Computation, vol. 32, pp. 175-199, 1978.
[112] D. W. Bliss, A. M. Chan, N. B. Chang, “MIMO wireless communication channel
phenomenology,” IEEE Trans. Ant. Propag., vol. 52, no. 8, pp. 2073-2082, Aug.
2004.
[113] M. A. Kousa, A. H. Mugaibel, “Puncturing effects on turbo codes,” IEE Proc.
Commun., vol. 149, pp. 132-138, Jun. 2002.
[114] K. Hasung, G. L. Stu¨ber, “Rate compatible punctured turbo coding for W-
CDMA,” in Proc., IEEE Int’l Conf. Personal Wireless Commun., pp. 143-147,
Dec. 2000.
170
表 Y04                                                                                     2/2 
 
 
二、與會心得 
此次我國參與人員包括交通大學 王蒞君教授、張仲儒教授、伍紹勳教授、台北科
技大學林丁丙、林信標、劉玉蓀教授、暨南大學魏學文教授等，高雄、長庚、義守、
淡江、亞洲、輔仁、東華大學及台科大、虎尾、明新科大、多位教授與研究生發表論
文數共計二十七篇。 
參與本次會議的主要目的，其一是發表近期對於在 MIMO-OFDMA 系統下進行無
線資源分配管理之研究成果。近年來，通訊系統下的資源分配管理一直是研究的熱門
主題，在 MIMO-OFDMA 系統下，不同使用者可以經由不同的 eigen-channel 傳輸資料
而不會造成干擾，因此在這個系統下，carrier、eigen-channel、bit、power 皆是可以進
行分配管理的資源，我們在第一篇論文中，便針對 MIMO-OFDMA 系統提出兩個演算
法對系統資源進行有效率的分配。第一個演算法具有較低的複雜度，一開始先決定每
個使用者所擁有的 eigen-channel 數量，再根據相對應的 eigenmode 強度與 SNR 進行
eigen-channel 分配，最後再用傳統的 bit-loading 演算法分配 bit 與 power。第二個演算
法是一個 multi-stage 的演算法，一開始先讓所有的使用者擁有所有 eigen-channel 的使
用權，然後每一個 stage 再決定相對應的 carrier 上所有的 eigen-channel 該分配給哪些
使用者會有較好的效率。模擬結果顯示兩個演算法在 uplink 與 downlink 的情況下都提
供了相當不錯的 performance，而模擬結果也顯示兩個演算法與最佳解相當的接近。  
第二篇論文是發表近期對於 relay-based OFDMA 系統下資源分配的研究成果。
Resource Management(RRM)在現在與未來的行動通訊受到越來越多的重視，因為在講
求高速傳輸以及高品質通訊的時代，如何有效的利用現有的資源並充分的分配來達到
更高的效率已經是個重要的課題。合作式通訊(Cooperative communication)在近幾年
也受到高度的重視，利用通訊環境較佳的使用者或者是中繼站來幫忙傳送訊息，藉此
達到更好的成效。我們結合了這兩種重要的議題(RRM 和 Cooperative 
communication)，提出了合作式通訊下資源分配的演算法。在現存的即時系統中，我
們不可能去實現最佳化的分配結果，因為所需要的計算複雜度太高，計算的時間遠超
過及時通訊環境的變化，也就是當我們的分配結果計算出來時，環境已經改變，如此
分配已不再是最佳化的分配，因此不適用於我們現在的環境。我們所提出的演算法雖
然不是最佳化的分配，但是所需要的計算複雜度是遠遠小於最佳化分配的結果，且利
用我們演算法分配所得到的成效比之最佳化分配不會相差太多，可說是達到一個可接
受且恰當的平衡點。 
可以被分配且利用的資源包括能量(power)、載波(subcarrier)、使用哪座中繼站
(relay)、資訊(information)載在哪些載波上等。我們所提出的演算法是針對在同個系統
中的所有使用者來進行資源分配，透過選擇何者使用者來當作中繼站，並分配系統中
的所有載波給每位使用者，使得整體系統所花費的能量是最少的，並達到每位使用者
不同要求的服務品質(quality of service, QoS)。與會的聽眾對於細節提問並給予實質的
建議，在互相交流的過程當中，並認識各國的學者。 
在此次會議中日本與韓國所發表的論文數都比我國的論文數還要多些，且參與的
Resource Allocation for MIMO-OFDMA based
Wireless Mobile Networks
Chih-Lun Weng, Yuan-Bin Lin, and Yu T. Su
Department of Communications Engineering
National Chiao Tung University
Hsinchu, 30056, TAIWAN,
Email: ytsu@mail.nctu.edu.tw
Abstract The Multiple-Input Multiple-Output based Orthog-
onal Frequency-Division Multiple Access (MIMO-OFDMA) is a
promising high rate wireless transmission scheme. The capacity
and coverage of such a system can be signicantly enhanced
by proper resource allocation (RA). In this paper, two adaptive
RA algorithms for MIMO-OFDMA systems are proposed. The
proposed algorithms are designed to minimize the total required
power while meeting each user’s quality of service (QoS) require-
ment. Numerical results show that the proposed algorithms offer
performance gain much larger than those of the existing RA
algorithms for the same system.
I. INTRODUCTION
The Orthogonal Frequency-Division Multiple Access
(OFDMA) is an Orthogonal Frequency-Division Multiplexing
(OFDM) based multiple access (MA) scheme that assigns
disjoint subsets of subcarriers to different users. When used
for wireless MA, it can provide high spectral efficiency
with robust performance and thus has been considered as a
candidate 4G air interface technology.
On the other hand, the multiple-input multiple-output
(MIMO) technique that uses multiple antennas at the base
station (BS) and mobile stations (MS) as well has promised
significant system capacity increase with respect to single-
antenna systems. It provides not only spatial diversity and mul-
tiplexing gain but also makes possible space-division multiple
access (SDMA).
In contrast to a conventional OFDMA system in which
each subcarrier can only be allocated to an user, in a MIMO-
OFDMA system different users can simultaneously transmit
over the same subcarrier through distinct eigen-channels [1]-
[2] without causing cochannel interference (CCI). With the
spatial channels as part of the radio resource, a MIMO-
OFDMA system enjoys larger degrees of freedom in ap-
propriating its radio resource and adaptive RA methods for
maximizing the capacity or throughput have been proposed
[3]-[5]. Taking users’ quality of service (QoS) requirements
into account, [6]-[8] propose adaptive RA algorithms that
minimize the total transmit power. The resource allocation
schemes proposed in this paper differ from these earlier results
in that spatial multiuser interference is avoided through simple
cooperative precoding so that the detection performance is sig-
nificantly improved at no cost of rate reduction when sufficient
channels in spatial and frequency domains are available.
In order that multiple user signals over the same subcarrier
can be perfectly decoupled at the receiver, we follow the
conventional approach invoking the Singular Value Decom-
position (SVD) to obtain the pre-processing and the post-
processing vectors for different users through proper linear
combinations of the singular vectors. Based on the above
concept, we propose two adaptive RA algorithms that take
care of subcarrier/power assignment, pre-processing and post-
processing vectors selection. They are designed to minimize
the total power and meet each user’s QoS requirement.
The rest of this paper is organized as follows. Section II
describes the channel model of the MIMO-OFDMA system
as well as the transmitter and receiver structures. In Section
III, the resource optimization problem is formulated and two
adaptive resource allocation algorithms are presented. The
performances of the proposed algorithms are given in Section
IV while conclusion is drawn in Section V.
II. SYSTEM AND CHANNEL MODELS
A. System parameters and transceiver model
Consider a MIMO-OFDMA system with a single base
station (BS) equipped with Tx antennas and K mobile station
(MS) users, each equipped with Rx(< Tx) antennas. The
frequency band used contains M subcarriers which are to be
allocated to the K MS’. Besides subcarriers, such a system
provides additional spatial channels for transmission. Some
iterative orthogonalization schemes have been proposed [1]-
[2] for MIMO precoding such that the CCI can be minimized.
A basic assumption used is that there exits enough orthogonal
spatial channels that each user will have access to at least one
of them, which, unfortunately, may not always be valid.
Let the kth MS’ channel matrix for subcarrier m be denoted
by the Rx × Tx matrix Hmk. Applying SVD to Hmk gives
Hmk = UmkΛmkV
†
mk (1)
where Umk contains the left singular vectors of Hmk and
Um,k contains the right singular vectors of Hmk. Λmk is
the diagonal matrix with diagonal entries being the singular
values (SVs). In order to separate the signals from different
user perfectly the proposed scheme provides at most R eigen-
channels on the same subcarrier where R is the rank of the
MIMO channel matrix. It is well known that the right and left
R∑
r=1
k∑
k=1
Armk = R ∀ m (10b)
Armk ∈ {0, 1} ∀ r,m, k (10c)
prmk ≥ 0 ∀ r,m, k (10d)
brmk ≥ 0 ∀ r,m, k (10e)
where prmk = f(BERk, brmk, SNRmr) if Armk = 1.
BERk represents user k’s target BER and f(·, ·, ·) usually has
a closed-form expression. If an M -ary quadrature amplitude
modulation (M-QAM) is employed, then f(·, ·, ·) or prmk is
given by [9]
prmk =
1
SNRmr
ln
(
1
5BERk
)
2brmk−1
1.5
(11)
To find the optimal solution all transmission resources–
subcarriers, eigenchannels, bits and power–should be jointly
allocated, which, unfortunately requires very high computa-
tional complexity. Suboptimal but affordable-complexity solu-
tions are perhaps more practical and desirable.
B. A low complexity resource allocation algorithm
We first determine the required eigenchannel number for
each user and assign the eigenchannels to the users using a
modified version of the two-phase algorithm of [10]-[11]. Then
we use the conventional bit-loading algorithm to allocate bits
over each user’s eigenchannel subset and compute the required
transmit power.
In the first phase we compute the required eigenchannel
number for each user according to the QoS and the average
channel condition. For each subcarrier, say, the mth, we sort
the maximum eigenmodes λmax(k,m) of the channel matrices
Hmk, k = 1, 2, · · · ,K in descending order, i.e.,
λmax(k1,m) > λmax(k2,m) > · · · > λmax(kK ,m), where
ki = arg max
k∈IK\{k1,k2,ki−1}
λmax(k,m), IK = {1, 2, · · · ,K}
and set Armk = 1 if k = kr. If R < K we set ARmk = 1
for those k = ki, i > R. The computing of the weighting
coefficients and the corresponding SNR follow that described
in Section II-B. Define the average channel condition for user
k by
Tk =
1
M
M∑
i=1
R∑
j=1
AjikSNRij(k). (12)
Let bmin and bmax be the minimum and maximum numbers
of bits per subcarrier. The minimum required eigenchannel
number for user k is dRk/bmaxe. The actual eigenchannel
number given ck is determined by iteratively verifying the rel-
ative reduction of the total transmit power after the allocation
of an additional subcarrier. The detailed algorithm is given in
Table I.
After determining ck’s, we then assign the eigenchannels
on all subcarriers to each user based on the eigenmode
magnitudes of the channel matrix and SNRs as described
in Section II-B. The ordering of subcarriers in the channel
assignment process is important as once the eigenchannels of
a subcarrier are assigned, no re-assignment is allowed. We sort
the subcarriers according to their largest SV λmax(k1,m) in
descending order, i.e., the mith subcarrier is the one such that
mi = arg max
m∈IM\{m1,m2,··· ,mi−1}
λmax(k1,m) (13)
Let the kth eigenchannel of the mth subcarrier be represented
by (k,m). The channel assignment follows the order (1, 1) →
(1, 2) → · · · → (1,M) → (2, 1) → (2, 2) → · · · →
(2,M) → (3, 1) → · · · ; see Table II for details. After channel
assignment, we use the conventional bit-loading algorithm to
allocate bits and compute the corresponding transmit power
for each user.
C. A multi-stage resource allocation algorithm
The second algorithm begins with a fair initial condition
that gives all users the opportunity to access all its eigen-
channels over all subcarriers. Each user uses a bit-loading
process to obtain the local power minimization solution based
on the allocated eigenchannel subset. The proposed channel
allocation process consists of a series of M -stage deletion
decisions. At each stage, the eigenchannels associated with
a subcarrier is given to the users who have the desired spatial
channel condition. These eigenchannels are then removed from
the serving channel subsets of all other users. The order of
subcarriers assignment is the same as Algorithm I and the
assignment process is carried out on a search tree whose
root node has KR outgoing branches to represent possible
assignments of subcarrier 1.
Similarly, every node at any given level of the search tree,
say the tth level, has KR outgoing branches (to KR child
nodes), each represents a possible eigenchannel assignment
(removal) decision and a tentative eigenchannels allocation.
The resource allocation is tentative because only the eigen-
channels for the first t subcarriers are assigned and those
for the remaining M − t subcarriers are still unassigned.
Given the initial fair channel allocation and the ultimate
object of minimizing the required total power, the cost for a
decision at any level should be the minimum required power
for the corresponding tentative eigenchannel allocation. After
repeating such a channel assignment and power allocation
process for M times, we finish the search over the M -
level tree, allocating all the eigenchannels and subcarriers;
the corresponding power/rate allocations are accomplished
simultaneously.
First, we let Armk = 1 for all r,m, k and re-index subcarri-
ers by the same order described in Algorithm I. The channel-
deletion process begins at the 1st subcarrier and continues
until the last one. Let F (m)i = [f1 f2 · · · fR]T be the ith
eigenchannel assignment vector for the mth subcarrier that
assign the ith eigenchannel to user fi. There are Rk candidate
eigenchannel assignment vectors in total, each represents a
possible eigenchannel assignment. Reset Armk based on F
(m)
i ,
