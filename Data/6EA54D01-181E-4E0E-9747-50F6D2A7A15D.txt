II
??
近二十年來，海底探測漸為各國所重視，水下載具的發展與應用遂成為關鍵性的一
環。台灣既為西太平洋海域裡的一個小島，本就應為發展海洋研究的理想地點。本研究
計畫乃為三年期「水下載具應用於海底管線檢修之關鍵性技術研發」整合型計畫中七個
子計畫之一，負責發展水下遙控載具視覺伺服控制系統之建立，以利水下載具進行海底
管線檢修作業。本研究團隊於前一階段三年期國科會整合型專題研究計畫中，對於水下
遙控載具之關鍵技術與系統整合已培養了具體的開發能力。此另一階段三年期研究計畫
將以前期計畫累績之經驗與實力為基礎，持續結合成功大學與中山大學之力，探索水下
技術之研究疆域。本計畫除可厚植我國自行研究開發水下遙控載具之關鍵性技術，並可
進而提升我國水下技術之水準。
本子計畫藉由水下載具現有之攝影機系統作為相對定位之回授感測裝置，以視覺影
像為基礎研究開發載具位置與姿態之伺服控制架構，為水下無人載具在海底管線檢測之
實際應用提供有效且可行的相對定位策略。本子計畫以三年分期陸續完成以下工作，第
一年期：建立以視覺輔助載具位置與姿態伺服控制之初步架構，並以管線路徑依循為階
段性之目標；第二年期：針對定點留滯任務需求，提出以視覺輔助載具位置與姿態伺服
控制完整之策略方法，並對於水下多變環境之影像伺服發展有效之訊號處理技術，以提
高相對定位之效果；第三年期：為配合機械手臂之操作，將建構攝影機與機械手臂之協
同作業模式，即利用第二攝影機的設置，以視覺伺服技術使攝影機能依循機械手臂之運
動，提供適當之操控視野並增進作業效率。
關鍵詞：管線依循、機器視覺、管線檢修、水下遙控載具、水下技術、視覺伺服。
1??? ??
1.1 ?????
我們居住的地球是一個充滿著水的星球，其中海洋便佔了地表面積的四分之三，蘊
藏豐富的資源。海洋中生存的動、植物，以及海床底下的石油與天然氣等礦產，對人類
而言，海洋似乎是一個巨大的藏寶庫。然而自古以來，海洋由於其深不可及與不可捉摸
的特性，一直就是人類眼中的神秘世界。自公元前 4000 年，埃及人用蘆葦造船在地中
海沿岸航行開始，人們便一直不斷用各種方法去探究這塊未知的領域，希望能解開她神
秘的面紗。
早期海下探勘是由潛水人員執行，但是因為水下作業的範圍有限，危險性高，支援
設備龐大而且昂貴，所水下載具（Underwater vehicle）便因應而生了。最早的水下只是
一個簡單充滿空氣的球殼，施放於水面下，操縱人員則在球體內觀察外面的狀況，球體
本身是靠著纜繩由水面的船隻拖曳而行。不過這樣的運動方式並不方便，缺少了觀測的
機動性與即時性，因此便發展出擁有自身動力源的載人水下載具。然而，雖然因此運動
性能提高了，但是搭乘人員、動力系統、與維生系統所佔據的空間，使得體積與重量大
幅增加，限制了其靈敏度。於是，世界各國紛紛投入新型無人水下載具的研究開發。
無人水下載具除了沒有上述幾項缺點外，對於危險性高和人力無法到達深度的探測
與作業更易於勝任，因此逐漸在水下探勘與研究扮演著不可或缺的角色。無人水下載具
一般可以分成兩大類：自主式水下載具（Autonomous Underwater Vehicle, AUV），以及
水下遙控載具（Underwater Remotely Operated Vehicle，ROV）。前者雖然機動性強，但
通常必須事先以程式設定行進軌跡，在未知、不確定、與多變的水下環境中執行任務時
較具危險性，因此目前只受限於某些特定的實際應用上。而水下遙控載具由於可以人為
操控，又具有良好之長期作業性、安全性及多樣性的水下作業性能，自 80 年代起，即
被用於外海油田之檢查維修工作上，近幾年也被廣泛運用於海洋生物、地質、水文的研
究，以及打撈救援的任務。主要應用範圍包括：科學研究方面（如海床地質的調查與取
樣、海洋生物與海底地形的觀察等），工程建設方面（水下結構物的佈放、架設與檢修、
鑽油平台作業支援等），以及軍事支援方面（救援受損潛艇、水下目標物的偵蒐與識別、
水下爆裂物的處理等）。較著名的實例上有：1983 年韓航波音 747 客機於庫頁島上空被
擊落後，使用 ROV 在失事海域搜尋黑盒子；1985 年利用 ROV 找出鐵達尼號的正確沉
沒地點並且完成定位工作；1986 年太空梭挑戰者號於美國佛羅里達外海爆炸後，使用
ROV 搜尋殘骸；1988 年非洲模里西斯外海由深達 4500m 的海床上成功打撈起南非航空
失事的波音 747 客機黑盒子等。
3將以過去三年累績之經驗與學識為基礎，著眼於水下無人載具在海底管線檢測維修應用
各項關鍵技術之研究開發。本計畫即為此整合型計畫中之子計畫五－「以視覺輔助水下
載具位置與姿態之伺服控制」，以三年期時程負責水下遙控載具利用攝影機系統進行相
對位置與姿態之定位視覺伺服控制，以利海底管線檢測維修作業之進行。與各子計畫的
相關性則可從圖 1.3 的分工關聯性圖示清楚掌握。相信經過三年與各子計畫間相互的合
作與努力，利用水下載具執行海底管線檢測維修的相關研究開發與技術發展之基石將可
奠立，台灣的水下技術於焉將可提升至另一層次。
對於水下無人載具應用於海底管線之檢測作業，依其任務需求之不同，大致可分為
(1)路徑依循與(2)定點留滯兩大工作模式。路徑依循乃在要求載具追循既定之路徑軌
跡，通常為規劃之管線鋪設路徑，以確認管線實際舖設以及週遭環境的狀態。而定點留
滯則在針對特定固定目標之觀察與檢測，以提供近距離之影像顯示並作為機械手臂之穩
定平台，方便機械手臂之作業操控。水下定位系統雖能提供水下載具基本之定位功能，
但面對水下環境之諸多不確定性，如洋流、纜繩張力等，樣樣均對載具之運動行為造成
多變與不可預期之影響，而使得水下載具之手動操控面臨極大之挑戰，更遑論達到路徑
依循或定點留滯之既定任務。再加上水下定位系統通常已能將載具帶入一定之可視工作
空間，但通常並無法對於真正執行路徑依循或定點留滯任務所需要之確切位置提供數
據。因此，此刻絕對的載具位置既不可得，也不再如此地重要，取而代之的則是水下載
具與環境特定目標（如管線）相對位置之確保。藉由此相對位置之保持，不但足以提供
適當且穩定之觀測影像，更可以建立合宜之工作距離，以方便機械手臂作業之操控與檢
視。因此本子計畫將藉由水下載具現有之攝影機系統作為相對定位之回授感測裝置，以
視覺影像為基礎研究開發載具位置與姿態之伺服控制架構，為水下無人載具在海底管線
檢測之實際應用提供有效且可行的相對定位策略。
本子計畫將以三年分期陸續完成以下工作，第一年期：建立以視覺輔助載具位置與
姿態伺服控制之初步架構，並以管線路徑依循為階段性之目標；第二年期：針對定點留
滯任務需求，提出以視覺輔助載具位置與姿態伺服控制完整之策略方法，並對於水下多
變環境之影像伺服發展有效之訊號處理技術，以提高相對定位之效果；第三年期：為配
合機械手臂之維修操作，將建構攝影機與機械手臂之協同作業模式，即利用第二攝影機
的設置，以視覺伺服技術使攝影機能依循機械手臂之運動，提供適當之操控視野並增進
作業效率。
1.2 ???????????
本研究計畫乃為三年期「水下載具應用於海底管線檢修之關鍵技術研發」整合型計
畫之七個子計畫中之一—子計畫五—負責建構水下遙控載具之視覺伺服系統以達成相
對定位的效果，而有助於海底管線檢測與維修作業的進行。其他子計畫各有所屬發展方
向，彼此分工合作但又息息相關且相互支援影響。其他子計畫名稱整理如下：
5控制迴路。如能經由適當的控制器策略，即可使攝影機具有追循所給定目標影像之功
能，而達到維持攝影機與目標物相對位置之目的。其之主要特點即在可以快速擷取影像
中的未知運動目標，而不須要事先掌握任何目標特徵的資訊，因此很適合應用於未知的
水下環境之追循作業。所以藉由水下遙控載具現有配備之攝影機系統，即可結合以光流
為基礎的視覺伺服技術，而達成路徑依循與定點滯留兩大作業任務。再者，為確保機械
手臂作業之效率與正確性，攝影機的鏡頭必須具有追循機械手臂爪部的功能。因此尚須
安裝第二架攝影機系統，與水下遙控載具現有配備不同的是，此增加之攝影機系統必須
具有可以改變視野方向的功能，方能動態地跟隨機械手臂爪部的位置與方向。綜而言
之，本子計畫採用光流為基礎之視覺伺服架構，以三年的時程完成以視覺輔助水下載具
位置與姿態之伺服控制。
????
第一年期：建立以光流為基礎之初步視覺伺服架構，而鎖定以海底管線依循為階段
性目標。即透過影像分析技術掌握海底管線輪廓與延伸方向，而可使水下遙控載具自動
依循管線路徑行駛，進而紀錄海底管線實際佈放狀況。
第二年期：以本子計畫第一年期成果為基礎，發展以光流為基礎之完整視覺伺服技
術。使能根據操作者之指示，在纜繩與洋流等未知且高複雜的外力干擾下，保持恆定的
水下載具位置與姿態，而能達到定點滯留，進而能對於管線特定目標執行較長時間的觀
察作業。
第三年期：海底管線維修作業得依賴子計畫四所研發的機械手臂。而為了使操作者
能易於操控機械手臂進行維修任務，則需有第二攝影機的安置，且此攝影機須具備運動
功能，以能追循機械手臂爪部的位置。因此本年期計畫配合所研發出的水下機械手臂，
設計並組裝具運動功能之第二攝影機系統，並達成攝影機與機械手臂的協同作業。
??????
第一年期(96.8.1–97.7.31)
1. 掌握影像光流與水下載具行為彼此之運動關係。
2. 提出管線路徑依循的追蹤控制策略。
3. 完成以視覺輔助水下載具伺服控制之管線路徑依循作業。
第二年期(97.8.1–98.7.31)
1. 建立完整之以視覺輔助水下載具位置與姿態伺服控制架構。
2. 完成以視覺輔助水下載具伺服控制之定點滯留作業。
3. 提出適用於水下多變環境之影像伺服技術，並比較相對定位改善之成效。
第三年期(98.8.1–99.7.31)
7??? ????
2.1 ??
海底管線常被建造來滿足能源與資訊傳輸需求。就本國而言，常見的海底管線包括
中華電信的海底光纜、苗栗外海的天然氣管線，以及由本島輸送至外島的淡水管線等。
其中傳輸石油、天然氣等資源的管線，其平均直徑約為一公尺，而電力、光纖纜線的直
徑約為五十公分。針對這些管線的例行監測，一個常見的方法是使用水下無人載具，以
人工的方式遙控載具沿著管線上方航行，藉由裝置在載具前方的攝影機，即時觀察管路
表面，判斷破損與腐蝕程度。當管線傳輸距離增加時，這個監測與遙控載具的任務變的
冗長且易引發人為疏失，一般皆會期望有一套系統可以自動導航載具，並且辨認出管路
破損的位置。本論文針對導航載具的部分，試著開發一種自主追循系統，取代人工遙控
駕駛。此系統利用攝影機的影像回授，自動辨認管線，並推算管線位置作為載具導航資
訊，以利後繼管線破損辨識與載具控制器的開發。
在管線檢測相關的文獻中，部份研究採用磁力計，量測電力或通訊纜線引發的磁場
來追蹤管線，此法在管線受到掩蓋時仍可完成辨認。另一方面的研究以聲納儀掃瞄管
線。而對於管徑較大的線路，則有利用載具在管路內部運行的檢測方法。
一般來說，上述方法所採用的感測設備需要較大的體積，容易造成載具結構設計的
困難。此外，這類設備成本較高，且需要較大的電源系統。在考量辨識可靠度與設備簡
易性的前提下，以攝影機的影像回授作為輔助辨認工具，應是一個有效的解決方案。
關於以影像資訊為回授的研究中，Hallset (1992)與 Ito (1995)以邊緣與長方形的形狀
特徵作為辨認依據。Balasuriya et al. (1997)結合管線地圖與載具定位，作為影像上管線
位置的判斷與預測。Zingaretti & Zanoli (1998)則將影像切割成數個橫切片，以每個切片
的平均值與變異數去進行管線邊緣的篩選。Foresti (2001)分析載具姿態相對於管線的 3D
模型，並以影像資訊作為回授，去推算整個模型的變動。Foresti & Gentili (2002)採用類
神經分類法將影像區分成前景、背景與邊緣，再以角度與對稱性判斷管線位置。Ortiz
等(2002)針對淺水區域，依據顏色差異將影像區分成不同區塊，再以直線特徵作為辨認
管線的依據。潘(2003)針對淺水域的管線，同時使用影像與聲納資訊進行辨認。
而在牽涉到管線追循與載具控制的研究中，常採用卡爾曼濾波器(Kalman filter)整合
載具與影像資訊。其中較單純者包含以卡爾曼濾波器針對影像平面上管線角度與位置做
預測，其他則有使用卡爾曼濾波器整合影像資訊、控制器資訊、小艇姿態與管線 3D 模
型。
當考慮到演算法的效率與複雜性時，利用邊緣偵測與霍夫轉換(Hough transform)去
9範圍的亮度凸起與凹陷即為雜訊與干擾物所造成。
圖 2.1 管線影像橫切片的亮度分布
因此本研究利用這個差異，以訊號濾波的概念，採影像型態學中的灰階斷開與閉合
運算作為前處理，去除畫面中細小的物件，留下比較單純的管線邊緣。灰階斷開與閉合
是針對每個圖素，以鄰近區域的最大值或最小值去取代其亮度，達到填平亮度的凸起與
凹陷，而藉由指定鄰近區域的大小，可決定被過濾物件的大小程度。灰階斷開與閉合運
算的形式如下：
   bDyxyyxxAbA  '''' ,|,max (2.1)
   bDyxyyxxAbA  '''' ,|,min (2.2)
需注意的是，斷開－閉合運算容易在畫面上造成微弱的波紋狀雜訊。因此，在上述
型態學的處理後，再配合高斯濾波器降低這些波紋的影響。下列圖片中，(a)與(b)為原
始影像與經過前處理的影像，(c)是對(b)進行影像增強，藉此觀察波紋的分佈與影響。
(a)
(b)
(c)
圖 2.2 (a)原始影像，(b)經過前處理後的影像，(c)經過增強後的影像
11
(a)
(b)
圖 2.4 骨架化前後的影像
經過上述的處理，由相對雜亂的場景中，取出比較單純的管線邊緣，接著便可進行
直線偵測，計算代表管顯邊緣的兩條直線。霍夫轉換的轉換方程式下：
 sincos yxr  (2.4)
其中(x, y)為影像平面的座標值，(r,θ)為霍夫平面的座標值。影像平面上共線的點，經過
霍夫轉換後，會在霍夫平面上聚集。因此，藉由搜尋霍夫平面上大量聚集的位置，即可
推算出影像平面上最可能的直線位置（圖 2.5、圖 2.6）。
圖 2.5 霍夫平面上的交點
圖 2.6 影像平面上的直線
13
當攝影機與管線有一段距離時，在影像中所呈現的是一個顏色相同的區塊，而非管
線細部的細節。同樣的，當距離夠遠時，海床在影像上呈現的是一個同顏色的區塊。要
分離出不同的顏色區塊時，常見的作法是建立影像的色階圖，再以分水嶺決定不同的顏
色區塊。但如前面所述，由於海底環境光源微弱，造成影像對比度低，傳統的色階圖無
法提供足夠資訊，因此必須考慮其他可以提供資訊的因素。
Ortiz et al. (2002)提出一個稱為二維色階圖的方法，將原本處理夜視鏡影像的分割
技巧(Panda & Rosenfeld, 1978)導入海底影像處理，解決管線上佈滿植物的情況。此方法
是建立包含亮度與邊緣值等兩個維度的色階圖，加強物體在色階圖中的分水嶺，以利影
像分割。
考慮一個單純由物件與背景構成的影像，物件的灰階值為 I0，背景的灰階值為 I1，
其內部顏色相近，因此在二維色階圖中（圖 2.8），落於邊緣值接近 0 的群集，而影像平
面上物體與背景交界的邊緣部分，在二維色階圖中落於 r 處。如此一來，便可使物件與
背景的分水嶺變的更加明顯。
圖 2.8 二維色階圖
建立色階圖後，使用前面使用過的層遞式分類法以二維的方式將不同顏色區塊分
離。一個場景中的影像與其色階圖處理展示如下。其中圖 2.9 的分水嶺部分，在圖 2.10
中得到增強，而圖 2.11 是以二維色階圖進行影像分割的結果。
圖 2.9 管線影像與其色階圖
15
z
fy
y
z
fx
x  '' (2.5)
當攝影機焦距 f、深度 y 以及圖素位置(x’, y’)皆為已知時，即可求解真實世界的座
標(x, y)。
2.6 ????????
當在前一個影格中求出管線的位置後，通常可以利用載具運動的資訊，去推算下一
個時刻，管線可能出現在影像中位置，進而針對這個區域套用辨識法，藉此提高辨識成
功的機會，並降低運算時間。此處我們試著純粹以影像的資訊，去判斷前後兩個影格的
移動量，進而推算關注區域(Region of Interest, ROI)。基於前述海底影像的特性，選擇
以光流技術(Horn & Schunck, 1980)估測影像的移動量。
影像中的物體是由亮度的圖樣所構成，當物體或攝影機移動時，這些亮度圖樣是連
續移動的，如果物體或攝影機的移動量很小，則可以假設影像中的這些亮度圖樣是不動
的，也就是說，可以建立一個如下的亮度守恆方程式。
   tyxEttyyxxE ,,,,  (2.6)
其中 E(x, y, t)代表影像上(x, y)於 t 時刻的亮度值。將等號左邊展開並忽略高階項可得下
式：
0 vEuEE yxt (2.7)
其中 u 與 v 即為相對於 x 與 y 方向的光流值。
剛才假設影像中亮度的變化是由於物體或攝影機的移動所造成的，但此任務中，光
源是由裝置在載具上的聚光燈所提供，因此必須考慮光源移動時所造成的亮度變化。修
正後的亮度守恆方程式如式所示(Negahdaripour & Yu, 1993)。
CtyxMEttyyxxE  ),,(),,( (2.8)
其中
17
圖 2.14 霍夫轉換示意圖
圖 2.15 霍夫平面落點
經過直線檢測擷取出管線邊緣後，由管線的四個角落( 1v
, 2v
, 3v
, 4v
)去定義管線位
置，作為稍後座標轉換的依據。管線位置的定義方式如下：
4
4321
0
vvvv
v

  (2.9)
影像平面上，管線位置隨時間分佈的數據如下圖。
19
(a)
(b) (c)
圖 2.19 載具位置：(a)x-y 關係 (b)x 方向 (c)y 方向
21
所提供的高度資訊，以視覺伺服完成無人載具水下懸停控制。 Plotnik & Rock (2006)，
以人造標誌作為目標物，並加入非察覺型卡爾曼濾波器，配合傾斜計與陀螺儀完成水下
無人載具的懸停控制。
本研究採用海利斯角隅偵測(Harris & Stephens, 1988)做為特徵選取的方法，不需事
先得知目標物的模型與位置參數。利用特徵比對，估測水下無人載具水平位置移動量，
並以比例積分控制器設計一視覺伺服控制器完成水下無人載具的懸停控制，在 3D
Studio Max 8 建構的虛擬場景中，以 Simulink 中的 Virtual Reality Toolbox 進行模擬實驗。
3.2 ????
當我們對水下無人載具下達懸停的指令後，系統便將當時攝影機所拍攝到的影像記
錄下來，作為目標影像。其後藉著攝影機拍攝到的目前影像不斷與目標影像做匹配，估
測水下無人載具相對於目標的位移量，使推進器輸出適當的回饋，不斷修正水下無人載
具的位置，進而達到懸停的目的。
???
當觀測者與空間中物體產生相對運動時，在影像平面上各個像素所產生的移動，稱
為影像流。如圖 3.1 所示，空間中一點 M 相對於攝影機座標系統 ),,( ZYX 的位移量 D，
其在影像平面座標系統 ),( yx 上的投影 d 即是所謂的影像流。其中 f 表示攝影機的焦距。
利用相似三角形的比例關係，我們可得下列關係式：
f
d
Z
D 
(3.1)
圖 3.1 影像幾何模式
23
其中 k：常數，介於 0.04~0.06；det(M)：矩陣的行列式值；Trace(M)：矩陣的對角元素
和。
為了避免太多的特徵點造成後續特徵匹配的時間過於冗長，需設定一角隅強度的門
檻值。
????
本研究所採用的特徵匹配分為兩個階段，第一階段初步確保特徵點一對一的對應關係；
第二階段將做進一步篩選，刪除不適合的特徵點。
所採用雙異數自相關係數(VNC)來計算兩個特徵點間的相似程度，其值介於-1 與 1
之間，1 代表相似程度 100%，-1 則代表相似程度 0%。公式定義如下：
  
)'()(
)'()'()()(
)',(
22
)'('),(
2211
21
mmN
mInImInI
mmVNC
II
mNnmNn





(3.6)
其中 m、m′：分別代表影像 I1 與 I2 之特徵角隅；N(m)、N(m′)：分別表示 m 與 m′為中心
的區域範圍； )(1 mI 、 )'(2 mI ：以特徵點為中心區域範圍的平均灰階值； )(
2
1
mI 、
)'(2
2
mI ：以特徵點為中心區域範圍的灰階值的變異數
為避免因資料量太少而導致匹配錯誤率上升，在此選擇以特徵點為中心 5×5 的區域
來做灰階值比對。在配對時，為縮短特徵配對時間，以帶比對特徵點為圓心，半徑 100
pixels 範圍內的特徵點才進行比對。在做特徵比對後，將每一組匹配像元對的移動距離
與方向畫出來，如圖 3.2，可清楚發現少數幾組配對錯誤的匹配像元對的移動方向和大
部分的匹配像元對不一致。接下來將進一步說明如何剔除這些配對錯誤的匹配像元對。
圖 3.2 匹配像元對移動方向
25
假設所有特徵點的移動量為一致，可以式(3.8)表示所有特徵點的座標轉換：
hBA
(3.8)
其中











1
...
1
)1(
)1(
)1(
1
)1(
1
k
k
y
x
y
x
A
為特徵點在目標影像中的座標位置( )1(ix ,
)1(
iy )











1
...
1
)2(
)2(
)2(
1
)2(
1
k
k
y
x
y
x
B
為與 A 對應之特徵點在目前影像中的座標位置( )2(ix ,
)2(
iy )











100
232212
131211
hhh
hhh
h
為座標轉換矩陣。計算式(3.8)的最小平方解，可求得座標轉換矩陣 h 為：
  TT ABBBh 1
(3.9)
由圖 3.5 可以看出，當水下無人載具產生漂移時，空間中一點 M 在影像上的座標 m
會產生變動。因此在求出影像上的座標轉換矩陣後，假設水下無人載具的攝影機與目標
27
???????
整個水下無人載具的控制架構如圖 3.6 所示。其中的視覺系統為前一章所提的利用
影像特徵估測水下無人載具移動量。
圖 3.6 水下無人載具控制架構
重點在於視覺控制器的設計，因此暫不考慮水下無人載具的動態行為，將圖 3.6 中
虛線部份以單位增益代替，整個動態系統方塊圖如圖 3.7 所示：
圖 3.7 動態系統方塊圖
其中 Xd 表示水下無人載具的目標位置，X 則是水下無人載具目前的位置。此處的
disturbance 泛指會造成水下無人載具速度上產生變化的外界干擾，如海流…等。
一般來說，推進器沒有作用的載具在具有海流的環境下，受到載具大小形狀的影
響，載具受海流干擾而產生的速度應該小於或等於海流的速度，在此我們假設為最壞的
情況：載具受海流干擾產生的速度相等於海流的速度。為了達到我們所要求的目標位
置，設計一控制器 Gc(s)輸出適當的速度 Vd。由於在此假設水下無人載具的動態系統為
單位增益，因此載具的輸出速度 V 即為 Vd。
由於水下無人載具在水下活動時，外界干擾會造成穩態誤差，因此在加入控制器
後，希望能夠達到三個基本要求：
1. 穩態誤差為零。
2. 最大超越量為 5%。
29
虛擬場景和數位影像間有一比例關係 kf，可由式(3.13)求出模擬裝置的 kf 值：
Z
Xk
x fd 
(3.13)
其中
xd：數位影像寬度，115 pixels
X：實際寬度，120 cm
Z：攝影機與影像的垂直距離，300 cm
因此
pixelsk
k
pixels f
f 5.287
300
120
115 


(3.14)
可以推測，在 300 cm 的距離下，虛擬場景的 x 方向與 y 方向有 1.043 cm 的位移時，會
在影像上造成約 1 個像素的變化。
藉由虛擬場景中的水下無人載具所獲得的虛擬海床影像，估算載具目前的移動量，
再經由控制系統輸出適當的回饋，實際反映到場景中的載具位置。場景的中心點定義為
座標的原點。
載具懸停控制實驗，設定載具初始位置在(0, 0, 300)，距離目標物約 300 cm 的高度。
當懸停命令下達後，系統隨即擷取載具當時位置的影像作為目標影像，以視覺伺服進行
載具的懸停控制，抵抗外界海流干擾。本研究所探討的是載具在水平位置的懸停控制，
因此模擬情況皆假設深度變化為零，並假設載具的方位角度變化為零。
??????????
一般來說，海流的速度大概在 1~2 節，亦即 0.5~1 m/s 之間。故在此假設海流在 x
方向與 y 方向均為 0.5 m/s，針對載具在固定方向海流干擾下作模擬實驗，探討所設計
之控制器在外界干擾下是否能正常運作。圖 3.10 為在海流干擾下懸停控制的目標影像。
模擬結果如圖 3.11 至圖 3.13 所示。
31
圖 3.13 軌跡圖(0.5 m/s 海流干擾懸停控制)
由於受到海流的干擾，若推進器沒有適當補償，水下無人載具會產生漂移，從圖
3.11 至圖 3.13 可看出，系統大致上能夠達到目標追循與懸停控制的要求，但在穩定之
後，X 方向與 Y 方向皆產生些微的震盪，震盪幅度大約在 2 cm ~ -2 cm。
????????????
設定水下無人載具的 X 方向與 Y 方向皆受到正弦海流干擾，X 方向與 Y 方向的平均
大小均為 0.5 m/s，振幅大小為 0.5 m/s，週期為 40 秒，速度曲線如下圖所示。
圖 3.14 正弦海流干擾
懸停控制的目標影像同圖 3.10。模擬結果如圖 3.15 至圖 3.17 所示。
33
在正弦海流的干擾下，系統仍可抵抗干擾，達到目標追尋與懸停控制的要求。表
3.1 為正弦海流干擾下，懸停控制的誤差表。統計平均值時，為了避免正負數值加總產
升零誤差的假象，所以必須先取所有數值的絕對值再計算其平均值。可以發現平均誤差
皆小於 1.043 cm，也就是視覺系統可解析的移動量範圍內。
表 3.1 正弦干擾懸停控制追尋誤差
軸向
最大誤差
(cm)
平均絕對誤
差(cm)
標準差
(cm)
X 10.1571 0.5744 0.7429
Y 9.8429 0.5706 0.6875
??????
由於所採用的視覺伺服系統是以特徵在不同影像間的位移量作為誤差訊號，而非水
下無人載具的實際位置誤差。在 300 cm 的高度下，實際位置有 1.043 cm 的變動才會在
影像中產生 1 像素的變化，因此載具的實際位置誤差量在 1.043cm~ -1.043cm 之間。礙
於像素解析度的限制，無法在影像上表現出來，因此由影像回傳的誤差訊號為 0，所以
系統無法更進一部作補償，而產生一穩態誤差。
因而在海流干擾下懸停控制實驗，發現系統在穩定後，會有震盪的現象產生，即為
水下無人載具的位置誤差在 1.043cm~ -1.043cm 之間。無法從影像上偵測出來，造成控
制器所輸出的速度對海流速度補償不足，尚有微小的速度量，導致水下無人載具位置誤
差的累積，直至影像上產生偏移，系統才會加以補償，因此產生穩態震盪的現象。
35
( , )I x y
0a 1a 2a
7a 3a
6a 5a 4a
 /3G R G B   (4.1)
0.299 0.587 0.114G R G B   (4.2)
邊緣特徵為常應用於樣本比對(Li et al., 2005)，常見偵測方法(Sobel, 1978; Canny,
1986)通常以灰階影像做運算，可突顯輪廓強度（Intensity）作為特徵。本文採用索貝爾
運算子（Sobel operator）進行影像邊緣化，以 I(x, y)代表影像像素，則可呈現如下：
72 3 4 0 6( , ) ( , ) ( 2 ) ( 2 )x xf I x y S x y a a a a a a        (4.3)
56 4 0 1 2( , ) ( , ) ( 2 ) ( 2 )y yf I x y S x y a a a a a a        (4.4)
梯度θ的方向定義，梯度的方向與 fx、fy 正負值相關，其範圍為0~2π：
1tan y
x
f
f
  (4.5)
以方向碼為特徵的樣本比對(Ellah et al., 2001, 2004; Urano et al., 2005; Miyamotol et
al., 2005)是由邊緣化運算擴展出來，對於灰階影像做不同方向的邊緣偵測後，再利用反
正切函數運算可以得到梯度的方向特徵進行比對。
像素可以經過(4.5)式運算得到方向梯度（範圍0到2π之間）。為了節省運算時間，
可將方向梯度範圍分為 N 等分，則每一個區間的範圍角度 Δθ 則為2π/N。從逆時針
方向為每一個區間編上一組號碼，則此號碼稱之為方向碼（Orientation code），方向碼
為本文比對樣本與目標是否吻合的特徵之ㄧ。該影像位置(i, j)處的方向碼 c(i, j)如下：
-1
-1
1
1
0:xS -2
0
0
2
-1
1
-1
1
0:yS 00
-2
2
37

2
1
( ) [ ( ) ]w w
M
u
w
o x
o
h
p C k b x u

  
  
  (4.8)
其中，oT、o 為樣本及候選影像中心，M 為列入計算的像素點總數，δ為 Kronecher
delta function，k 為核心函數，h 為帶寬，其大小為樣本影像長度的一半。而常數 CT、C
為正規化常數，使 
1
0
1
m
u
u
q


 、 
1
0
( ) 1
m
u
u
p o


 ，則定義 CT 如下：
2
*
*
1
( )
1
T
T w
w
M
w
o x
b x u
h
C
k 

       


(4.9)
2
1
( )
1
w
w
M
w
o x
b x u
h
C
k 

       


(4.10)
特徵索引數值的密度函數，其精確度與索引數值的單位格有一定程度的相關，單位
格越細越多，其相對精確度會提高，但是計算量也伴隨增加，相反地，若是索引數值的
單位格越少，雖然計算量減少，而使處理速度變快，但也有可能因為資訊量太少而造成
誤判的情形發生，本文中所使用的兩個特徵：方向碼與灰階值。其中方向碼通過閥值的
劃分為16等分，未通過閥值的為同一區，因此方向碼的特徵分布密度直方圖有17柱，而
灰階值部分則劃分為16等分。
對於上述所建立的樣本影像模型與候選影像模型都是根據特徵索引值所出現的次
數，然後配合上核心函數所加權的結果，而在文獻(Zhang et al., 2007)中更進一步考慮其
出現的位置區域。將其像素點出現的特徵配合上其出現位置結合直方圖來做計算。將其
出現的位置依據搜尋視窗的位置劃分為四等分，並給予編號：
0 region0
1 region1( , )
2 region2
3 region3
R i j  (4.11)
其中，R 代表像素點在(i, j)位置時的區域編號，如圖4.2，正方形代表樣本影像或候
選圖像，將其分為四個區域。
39
2(1 ) 1
0E
x if xK
otherwise


  (4.17)
而
2( ) ( )K x k x ，其二維空間的立體圖如下頁圖4.3所示。
圖4.3 Epanechnikov Kernel Function
當樣本影像與後選影像的模型建立完成後，Bhattacharyya 係數將來做為相似性的依
據，在這裡 Bhattacharyya 係數表示如下：
  
1 1
0 0
( ) ( )
m k
us us
u s
o p o q
 
 
 (4.18)
當 Bhattacharyya 係數最大的時候，則表示其目標物最有可能在此位置上。
本研究以方向碼及灰階索引值作為特徵比對，在這裡我們以匹配來確定樣本影像與
候選影像之間對應像素點的差異性，在文獻(Ullah et al., 2004)中，以方向碼之間的差異
性來決定是否為目標物，在此，除方向碼外加入灰階值這一特徵來比較兩影像之間的差
異性，並以下列的式子來表示：
( , )
1 ( ( , ), ( , ), ( , ), ( , ))T T
i j
D d O i j O i j G i j G i jM E  (4.19)
其中，O 為候選影像的方向碼影像，OT 則為樣本影像的方向碼影像，G 為候選影
像的灰階索引值影像，GT 則為樣本影像的灰階索引值影像，M 為匹配像素點的總數，E
41
Similarity OS
Similarity GS
Similarity MS
圖 4.4 目標追蹤流程圖
??????
全區域搜尋法（Full search）是最簡單且直接的方法。在輸入影像中，取一個與樣
本影像一樣大小的範圍為搜尋視窗，然後使搜尋視窗由左而右，由上而下的方式一一比
對尋找擁有最大相似值的視窗區塊。如圖4.5，由左上開始一次移動一個像素點，依序
與樣本做比對，求出相似值，可以求出24個相似值，其中最大相似值所在，即為目標在
影像中的位置。此種搜尋方法被視為最傳統的搜尋法，搜尋出的結果可靠度最高，但由
於每一個資料點都需要計算，因此運算量相當龐大。
圖 4.5 全區域搜尋法示意圖
43
 

 
  

1
1 1
1
( )
( )
k k
Tk k k
T Tk kk k
k k kk k
kk k
x Ax
P AP A Q
K P H H P H R
x x K z H x
P I K H P

 
 
  

 
 
  
 
(4.23)
若是想更進一步預測出 1k時刻狀態值，則可使用下式：
 1k kx Ax (4.24)
4.3 ??????????
?????
本研究使用透視投影法，也被稱為針孔攝影機模型（Pinhole camera model）。如圖
4.7，空間中一點 P(X, Y, Z)投影到影像座標系統中則可以標示成 p(x, y)，其對應關係如
下：
0
0
Xx x f Z
Yy y f
Z
 
 
(4.25)
其中 f 為有效焦距，(x0, y0)為 Z 軸通過影像平面之交點座標。
Y
X
y
x
( , , )P X Y Z
Z
( , )p x y
f
圖 4.7 針孔攝影機模型
而在實際使用上，我們了解目標在數位影像上的座標必須轉換成實際的長度單位才
能應用。將目標在 CCD 晶片上的位置轉換成影像空間取樣單位 pixel，分別引入參數
Kx 與 Ky，其單位為 pixel/length，ud、vd 分別代表影像平面中的 x、y 方向與中心點的偏
45
ox
L
IZ
Z
( ,0, )o o IP x Z L
o
o
X
f
du
圖 4.8 攝影機機台模型
假設目標物只在與 X-Y 軸平行且距離鏡頭中心 ZI 的平面上運動，如圖4.8所示。目
標物 Po 與 Z 軸夾角為θ，投影位於影像平面上與中心產生偏移量 ud pixels。而透過此
偏移量，可以驅使馬達轉動機台，將攝影機旋轉使目標物重新回到影像中心。
目標物位於 Po 點之位置與旋轉中心夾角可以表示如下：
1tan
I
o
o
x
Z L
  (4.30)
其中，ZI 為目標物與鏡頭中心的距離，L 則為鏡頭中心至旋轉中心的距離。而以針
孔攝影機模型，在理想狀況下目標物移動前後之位置與鏡頭中心的夾角ψo可表示如下：
tan Io d do o
x xI
u Z ux xZ K f K f
    (4.31)
根據影像平面中，目標物與影像中心的偏移量 ud 可計算出實際目標物與 Z 軸的距
離，而影像中心到目標物的距離與旋轉中心到目標物距離相差 L。我們將(4.31)式代入
(4.30)式可求得夾角θo、xo、f 之間的關係如下：
 
1 1 1tan tan tan
I d
Ixo d
o
I I x I
Z u
Z uK fx
Z L Z L K f Z L
        (4.32)
亦可用(4.29)結合(4.32)式，求得：
47
 
 
1 1
1
1
tan tan
( )sec
1 cos sec
tan
( )sec
1 cos
tan ( )
x
c
d
xd
M
cIc
c cI d
x cI
cI d
x I
PC un u K f
Z LPO
Z L u
K f Z L
Z L u
K f Z L
 
 


 


 
  
 
  
  
 
 
 
 
(4.35)
??????? PAN-TILT ??
本研究應用卡爾曼濾波器於機台旋轉角度之預測，而機台角度的旋轉量取決於目標
物的移動量。PAN-TILT 的運動為旋轉運動，定義角速度ω及角加速度α如下：
d
dt
 (4.36)
2
2
d d
dt dt
   (4.37)
其中θ為角位置，t 則為時間。當旋轉為等角速度運動時，角位置為：
u u T    (4.38)
而當旋轉為等角加速度時，角位置定義如下：
21
2u u T T       (4.39)
u與 u分別為初始角位置與初始角加速度。因此可以將系統轉移矩陣 A定義如下：
2
2
11 0 0 0
2
10 1 0 0 2
0 0 1 0 0
0 0 0 1 0
0 0 0 0 1 0
0 0 0 0 0 1
T T
T T
A T
T
 
 
 
 
 
 
 
 
 
 
 
  
 (4.40)
狀態向量則定義如下：
49
圖 4.10 實驗設備架構流程圖
個人電腦：控制攝影機端追蹤及影像處理的電腦（Intel CoreTM2 CPU 6300、1GB
RAM），作業系統為 Windows XP，開發程式之應用軟體為 Borland C++ Builder 6.0版。
影像擷取卡：ADLINK RTV-24，30 fps，影像大小為320×240（pixel）。
CCD 攝影機：所採用的 CCD 攝影機是 SAMPO 高解析之彩色攝影機，影像感應裝
置為1/4彩色 CCD 晶片。
PAN-TILT 攝影機機台：歐洲 Directed Perception 公司所開發，由台灣史賓納科技
公司所代理，型號為 PTU-46-17.5。最大轉動速度為300°/sec，機台位置解析度為0.051428
°。PAN 旋轉範圍為±159°，TILT 旋轉範圍向上約31°，向下約46°。機台外型如下圖所
示。
圖 4.11 PAN-TILT 機台
機械臂：圖(a)為ELEKIT MR-999LE黑白機械臂，圖(b)為自製金屬機械臂(洪，2006)。
(a) (b)
圖 4.12 機械手臂
51
(a) (b)
(c) (d)
圖 4.15 黑白機械臂被遮蔽，(a)初始影像，(b)第 100 張，(c)第 120 張，(d)第 160 張影像。
此實驗中，將對在影像中目標物變形的情況下做辨識追蹤。目標物在影像中經過平
移旋轉後先是夾爪收縮，如圖4.16而目標物在影像上變形也都能鎖定目標。在圖4.17中，
人手握拳時以及手掌翻轉時都能鎖定目標。圖4.18顯示在影像模糊的情況下仍對目標物
有效辨識追蹤。
(a) (b)
(c) (d)
圖 4.16 黑白機械臂變形之追蹤，(a)初始影像，(b)第 280 張，(c)第 330 張，(d)第 400
張影像。
53
??? ???????
本研究計畫為國科會三年期「水下載具海底管線檢測關鍵技術之研發」整合型計畫
中六個子計畫之一(編號 NSC 96-2221-E-110-103-MY3)，主要任務在發展以視覺輔助水
下載具位置與姿態之伺服控制。於三年期間針對海地管線檢測之關鍵技術，陸續完成管
線依循、載具之視覺懸停控制、以及機械臂之視覺伺服協同控制三項主要研究工作。根
據模擬與實驗的結果顯示，均達預期設定之研究目標。其中對於機械臂之視覺伺服協同
控制更可以推廣至變形物體的視覺追循，將可應用於水下生物或不固定形體之追蹤作
業。唯一欠缺的是實海域的實際航行測試，此項作業尚需諸多因素的配合方期可行。
各年期計畫結論與未來展望將分段敘述於後：
????
第一年期計畫乃針對海底管線追循的任務，設計一個分析影像回授資訊的方法。此
方法是以管線邊緣的直線特徵為辨認依據去推算管線位置。霍夫轉換是一個常被採用的
直線檢測方法，但本質上容易受到雜訊與干擾物的影響，因此，一般使用霍夫轉換的前
提是影像必須相對地單純。本研究針對著個問題，使用型態學濾波器作為前處理，提高
霍夫轉換在海底管線追循上的應用性。另一方面，針對載具航行過程所伴隨的畫面變
動，以層遞式分類法處理影像二值化問題，使演算法能夠對抗畫面變動造成的影響。此
外，為了避免實際運作時各種感應器的使用，在影像的 ROI 估測上採用光流法的方式，
純粹利用畫面上的亮度變化去估算畫面移動量。經過虛擬場景的測試，此演算法可在場
景中正確地辨認出管線位置並達成追循任務。
在研究過程中，發現仍有一些值得探討的問題，因此提出幾項觀點提供日後改進與
研究方向：
1. 在影像前處理中，高斯遮罩的濾波程度是以離線的方式人工調整出最佳值，此處建
議可以進一步建立自動調整的機制，使演算法可以處理畫面變動更大的場景。
2. 延續前述畫面變動的問題，一個可能發生的情況是海水混濁度隨著載具航行而變
動，另一個情況是被揚起的泥沙飄入畫面的範圍，這些情況都會造成畫面光影效果
的變動。演算法對於這些變動的容忍程度，與容忍程度的提升都是可以繼續探討的
主題。
3. 在問題的設定上，建議可以繼續考慮其他可能發生的情況，譬如泥沙掩蓋部分管線，
使得邊緣無法呈現足夠的直線特徵，此時必須建立其他辨識方法，並設計邏輯判斷
的機制使演算法自動切換。
4. 在追循模擬中，由於重點是要測試演算法能否處理變動的場景，因此僅對載具的運
動特性作簡單假設。後續若能結合完整的載具運動特性與控制器設定，則能進行更
55
2. 本研究在影像辨識部分是考慮目標物與攝影機之間的距離無太大的變化，若是目標
物在深度變化不大時，仍可追蹤，若是變化過大，會影響其準確度，未來可將深度
變化列入演算法以增強追蹤效能。
3. 本研究使用機台架構是採用旋臂式，因此會產生震動的影響。因為震動導致擷取出
來的影像模糊，雖然研究中對模糊情況下的辨識有一定的強韌性，但若是過於嚴重
則可能使影像辨識錯誤。如果在追尋時讓機台稍做停頓，待震動停止後，再進行追
尋，則會嚴重影響追蹤速度。未來可以改良機台，減少影像辨識錯誤的機率。
57
14. Hallset, J. O. (1992) “A vision system for an autonomous underwater vehicle,” 
Proceedings of International Conference on Pattern Recognition, pp. 320-323.
15. Harris, C. and M. Stephens (1988) “A combined corner and edge detector,” Proceedings
of the 4th Alvey Vision Conference, pp. 147-151.
16. Hartigan, J. A. (1975) Clustering Algorithms, Wiley: New York.
17. Horn, B. K. P. and B. G. Schunck (1980) “Determining optical flow,” Artificial
Intelligence, Vol. 17, pp. 185-204.
18. Huertas, A. and G. Medioni (1986) “Detection of intensity changes with subpixel
accuracy using Laplacian-Gaussian masks,” IEEE Transactions on Pattern Analysis and
Machine Intelligence, Vol. 8, No. 5, pp. 651-664.
19. Kalman, R. E. (1960) “A new approach to linear filtering and prediction problems,” 
Transactions of the ASME, Ser. D., Journal of Basic Engineering, No. 82, pp. 34-45.
20. Li, R., B. Zeng, and M. Liou (1994) “A new three-step search algorithm for block motion
estimation,” IEEE Trans. CASVT, Vol. 4, No. 4, pp. 438-442.
21. Li, Y., J. Liu, J. Tian, and H. Xu (2005)”A fast rotated template matching based on point 
feature,” Proceedings of SPIE - The International Society for Optical Engineering, Vol.
6043 II, MIPPR 2005: SAR and Multispectral Image Processing, pp. 60431P.
22. Matsumoto, S. and Y. Ito (1995) “Real-time vision-based tracking of submarine-cables
for AUV/ROV,” Proceedings of Oceans ’95, Vol. 3, pp. 1997-2002.
23. Mitani, K. and H. Saji (2005) “Robust template matching by using variable size block
division,” Proceedings of SPIE - The International Society for Optical Engineering, Vol.
6051, Optomechatronic Machine Vision, pp. 60510X.
24. Miyamotol, D., S. Nara, S. Takahashi, and S. Kaneko (2005) “Tracking control system 
based on orientation code matching,” Proceedings of SPIE - The International Society for
Optical Engineering, Vol. 6052, Optomechatronic Systems Control, pp. 60520D.
25. Moravec, H. P. (1980) Obstacle Avoidance and Navigation in the Real World by a Seeing
Robot Rover, Tech. Report CMU-RI-TR-80-03, Robotics Institute, Carnegie Mellon
University & doctoral dissertation, Stanford University, USA.
26. Negahdaripour, S. and C. H. Yu (1993) “A generalized brightness change model for
computing optical flow,” Proceedings of the 4th International Conference on Computer
Vision, pp. 2-11.
27. Negahdaripour, S., X. Xu, and L. Jin (1999) “Direct estimation of motion from sea floor
images for automatic station-keeping of submersible platforms,”IEEE Journal of
Oceanic Engineering, Vol. 24, pp. 370-382.
28. Ortiz, A., M. Simo, and G. Oliver (2002) “A vision system for an underwater cable 
tracker,” Machine Vision and Application, Vol. 13, No. 3, pp. 129-140.
????????????????????????????
九十九年九月五日
報 告 人
姓 名
程 啟 正 服 務 機 構
及 職 稱
中 山 大 學 機 械 與
機 電 系 教 授
時間
會 議
地點
2009年 12月 19日至 12月 24日
中國桂林
本 會 核 定
補 助 文 號
NSC 96-2221-E-110-103-
MY3
會 議 名 稱
（中文）2009 IEEE 機器人與仿生學國際研討會
（ 英 文 ） 2009 IEEE International Conference on Robotics and
Biomimetics (ROBIO 2009)
發表論文題目
（中文）應用影像金字塔技術之改良式視覺追循
（英文） Improved Visual Tracking Using the Technique of Image
Pyramid
報告內容應包括下各項：
一、 參加會議經過
二、 與會心得
三、 考察參觀活動（無是項活動者省略）
四、 建議
五、 攜回資料名稱及內容
六、其他
附
件
三
12月 19日從高雄小港機場先搭港龍航空 KA 437班機至香港，轉乘中國南方
航空 CZ 3032 航班飛往桂林。到達桂林兩江國際機場時，已是夜間 9 時左右。
在機場巧遇澳大利亞阿徳雷得大學(University of Adelaide)機器人研究實驗室
(Robotics Research Laboratory)主任盧添福教授，相談甚歡，並偕同一起搭乘計程
車前往市中心，筆者住宿地為位於中山中路的杉湖大酒店(Shanhu Hotel)，從旅
館徒步至會議場所桂林漓江大瀑布酒店僅需約五分鐘左右。
會議結束於 12月 22日，23日大會安排漓江游船與銀子岩景區旅遊。儘管天
公不作美，下起濛濛細雨，但仍可感受到「陽朔山水甲桂林」之氣勢。24 日下午
5點 5分搭中國南方航空班機 CZ 3031踏上回程，經香港機場轉機 KA 450，於當
日晚上 11點 15分飛抵高雄，結束出席 2009 IEEE 機器人與仿生學國際研討會總
共五日之行程。
?? ????
本屆 IEEE 機器人與仿生學國際研討會的會議時間乃從 12月 19日至 22日，
總共約四天的時間。會議場所均在位於杉湖北路的桂林漓江大瀑布酒店內。19 日
當天只安排了註冊與歡迎晚宴，由於到達桂林時已是夜晚，因此錯過了這場盛
會。整個會議的論文報告則從 20 日開始起，連續三天，口頭論文報告大致上分
為四個時段，上下午各有兩個，每個時段有六個場次分別在六個討論室同步舉
行。另有一間會議廳則做為海報展示之用。每天早上論文口頭報告之前均安排有
專題演講。每天晚上均有大會晚餐，22 晚上則是歡送晚宴，讓與會學者專家以較
輕鬆的心情齊聚一堂，共享佳餚。
此屆國際研討會總計共有來自德國、澳大利亞、新加坡、日本、西班牙、伊
朗、美國、韓國、法國、中國大陸、荷蘭、義大利、土耳其、瑞典、埃及、南
非、印度、英國、加拿大、以色列、泰國、沙烏地阿拉伯、紐西蘭、香港、澳
門、與台灣等大約 26 個國家地區的四百餘篇論文發表。台灣此次共報告了 6 篇
論文。參與學校與研究單位包括了中山大學、台灣大學、中原大學、虎尾科技大
學、龍華科技大學、與工業技術研究院等。
本屆研討會各個場次的主題包括：微奈米系統(Micro/Nano Systesms)、多機
「未來生醫與生命科學之微奈米機器人」 (Nano/Micro Robotics for Future
Biomedicine and Life Science)。最後一天安排了美國密西根州立大學(Michigan
State University) Ning Xi 教授的「奈米生物系統之原位感測與操控」(In Situ
Sensing and Manipulation in Nano Bio Systems)。
?? ???????
此次會議筆者發表的論文題目是「應用影像金字塔技術之改良式視覺追循」
(Improved Visual Tracking Using the Technique of Image Pyramid)，被安排於 12月
20日的下午「視覺伺服與追蹤」(Visual Servo and Tracking) 之場次。此論文內容
為所指導碩士班學生何忠興所撰寫碩士論文的部分研究成果。本論文目的在針對
以光流(Optical flow)為基礎的運動目標物追尋方法，結合影像金字塔的技術，以
有效提昇追尋的成效。由於以光流為基礎的運動目標物追尋方法不需事先掌握目
標物的特徵，因此適用於一般實際的追尋作業。然而，採用標準的光流計算方法
通常並無法提供準確的追尋效果，尤其是對於快速運動的目標物。因此本篇論文
針對未知運動物的追尋作業，發展了一結合滑動模式控制(Sliding-mode Control)與
影像金字塔技術具強韌性之視覺伺服架構。滑動模式控制主要在處理系統不確定
性問題。影像金字塔乃依據一張相同影像發展出不同解析度之一組影像，並將其
堆疊成層式之金字塔架構的影像技術。對於快速運動物體只需以低解析度之影像
即可維持滿意的追尋效果。而當所偵測運動速度超越了既定之最大關鍵速度
(Maximum Critical Speed)，就必須進行層次的切換。透過實際追尋實驗可證實出
使用所提出的控制策略能有效地改善追尋效果。
最近十年中國大陸積極參與全世界的學術活動，而相對地，台灣學者出國參
與學術研討會的人數卻是每況愈下。深究其中原因，台灣學術界過於重視期刊論
文，而對於研討會論文並無給予適當之權重對待應該是其主因。此外，中國大陸
各地對於主辦學術研討會更是不遺餘力，主動扮演著學術強國的角色。儘管此舉
使得在大陸地區主辦的學術會議審查標準參差不齊，然而其正面積極的態度卻正
是台灣方面所欠缺而需加強之處。另外，台灣似乎宜策略性規劃適合本國發展且
具潛力的長期研究主題，主動積極爭取相關學術研討會的主辦權。如此不但可爭
取台灣在學術領域的能見度，更可讓台灣進一步在相關領域佔上一席之地。此舉



無研發成果推廣資料 
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
本計畫所發展對於變形物體之視覺伺服控制架構，可提升水下技術操作的能
力，並可擴充至一般廣泛之實際視覺追循應用，例如水下生物以及各式形體目
標物的追蹤紀錄等。 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
