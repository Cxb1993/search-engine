 
一、簡介與文獻探討 
 
 叢集化(clustering)代表的是在一組沒有已知分類的資料當中找出其中的叢集(cluster)的
過程。一個叢集是原資料組的一個子集合，其中的資料點具有高度的相關性或是具有相
近的性質。我們將由一組資料區分出的所有叢集稱之為這個資料組的一個分群 
(partition)。叢集化是一個非監督學習 (unsupervised learning) 的過程，必須靠著資料點之間
的關係來找出其中的叢集。即使對於同樣一組資料，由於計算資料點之間關係方法的不
同，或者是由這些關係來找出叢集的演算法的不同，或是所使用的參數或初始化條件不
同，都會產生不同的叢集化結果。用於叢集化的演算法很多，但是各方法所適用的資料
組特性以及所能找出的叢集特性都有其限制。 
 近幾年的一個趨勢是使用叢集整合 (cluster ensemble) 技術，對同一組資料產生多個不同
的叢集化結果，再結合這些個別結果來產生一個具有共識的、更穩定也更能代表實際資
料分佈的分群。叢集整合的另一個優點是它非常適合於平行的與分散式的資料分析，甚
至儲存在多個不同地點的資料可以先分別作叢集化，再將其結果整合。 
 早期關於叢集整合的一篇重要論文是 Strehl 與 Ghosh 在 2002 所發表[1]。這篇論文說明
了"知識再利用" (knowledge reuse) 用於叢集的概念，在此"知識"所代表的即是個別分群
（有可能是在不同的時間點所得到的）。對於叢集整合的優點，實驗結果在許多個別研
究中都有，而[2]由理論的角度證明叢集整合在穩定度及正確性方面的優點。 
 叢集整合的先決條件是要能對同一組資料產生多個不同的分群結果。在這方面一個具
代表性的方法可算是使用同一個叢集演算法但是不同的隨機初始化[3,4]。另一個常見的
方法是將高維度的特徵向量(feature vectors)投影到多個隨機的低維度次空間(subspace) [5]
或隨機的選擇部份的特徵値來進行叢集化 [6]。這一類方法對高維度資料的叢集化特別有
用。其他的方法還包括將資料隨機分為幾個較小的資料組，並且對這些資料組作叢集化
[7]。這一類方法的好處是當資料量很大時，每次進行叢集化都只使用部分資料可以較有
效率，甚至分散在不同地點的資料可以被分別叢集化，再透過叢集整合得到整體的分群
結果[8]。除此之外，當大量資料必須以線上(on-line)的方式叢集化時，也可以透過改變各
資料點被處理的順序而得到不同的分群結果再做整合，如[9]。此外也可以使用數個不同
的叢集化演算法來產生個別分群再做整合，如[10]中的方法。 
 Co-association 矩陣可算最常被使用的叢集整合的資料結構，而原因應是由於其觀念非
常單純易懂，所需的演算法也單純。代表性的方法包括[1]所提出的 Cluster-based Similarity 
Partitioning Algorithm (CSPA) 以及 [3]的 EAC 。其中 EAC 使用階層聚合 (hierarchical 
agglomeration)來從 co-association 矩陣算出最終分群。與其他的叢集整合演算法比較，EAC
具有以下幾個優點：（一）利用如單一連結 (single-link; SL) 或平均連結 (average-link; AL)
的階層聚合，可以找出具有延伸性、任意形狀的叢集；（二）不需事先指定最終分群的
叢集個數，而可利用階層聚合的最大生命期條件來選擇最終分群。 
 EAC 所用的 co-association 矩陣最大的問題即是其運算複雜度（至少 O(N2)，N 為資
料量）。由於此矩陣所含的資訊有許多重複性，若能利用這些重複性來降低 co-association
矩陣大小而減少運算量，則可大大提升 EAC 與其他基於 co-association 矩陣的演算法的實
用性。這方面的成果是本計畫最主要的貢獻。 
複性。我們針對這一點舉例說明如下：假如有兩個資料點 xi 和 xj 很接近到一個程度，在
每個個別分群當中，這兩個資料點都被分配到同一個叢集當中。在這種情形下，就叢集
整合而言，xi 和 xj 是無法分辨的。因此，我們可以把 xi 和 xj 合併成一個新的資料點看待，
因而減少了得到最終分群的計算量。 
    以下我們以一個例子來進一步說明。圖一(a)是一個包含 100 個點的資料組。這 100 個
點大約平均分配在 4 個叢集當中。圖一(d)-(g)是 4 個使用 k 均值法所得到的分群，其中叢
集的總數是從 3 到 6。各圖中皆以不同的顏色與符號代表各點所屬的叢集。在圖一(b)當
中我們將資料點分成 9 個核心群 (core group)。一個核心群的定義是其中每個資料點的叢
集標籤向量都是相同的，也就是說，這些資料點在所有個別分群中都被分到同一個叢集。
因此，在將所有 co-association 矩陣當中重複的行與列合併後，我們得到的是一個 9x9 的
矩陣（圖一(c)），而非原來 100x100 的矩陣，而且仍保有所有的資訊。這對降低計算量的
效果是顯而易見的。 
 
(a) (b)
(d) (e) (f) (g)
1
1
1
1
1
2
2
2
2
2
3
3
3
3
3
4
4
4
4
5
5
5
6
6
7
8
9 (c)
 
圖一：(a)資料組；(b) 9 個核心群（數字為核心群的編號）； (c) 由核心群算出的
co-association 矩陣；(d)-(g)四個個別分群（數字為每個分群中的叢集標籤）。 
 
    在以上的範例中，一個直覺的做法是先建立完整 100x100 的 co-association 矩陣，再將
重複的行與列去除。然而，這樣做的缺點是我們仍然必須先處理一個有 N2 個元素的矩
陣，因此運算複雜度仍然是 O(N2)，並不能真正達到我們降低複雜度的目的。在這方面我
們已設計了一個階層式的方法，藉由建立一個樹狀結構，直接將所有資料點分成核心群。
這樹狀結構在根節點(root node)之下的每一層對應到一個個別分群，而每一個葉節點(leaf 
node)則對應到一個核心群。雖然會因為各個別分群加入的順序不同而得到不同的樹狀結
構，然而所得到的核心群則不受影響。以下圖二是根據圖一的資料與個別分群所產生的
樹狀結構（個別分群的順序是圖一(d)-(g)），各節點當中的數字是在該個別分群的中的叢
集標籤，而最下方的數字是核心群的編號（對應到圖一(b)）。對於每個核心群，將其從根
節點到葉節點的路徑上所有的叢集標籤組合即是其叢集標籤向量。此樹狀結構即是我們
的 CA-tree。 
 
 
 
圖四: 使用叢集整合偵測主曲線的流程圖 
 
 
三、結果與討論 
 
    針對 CA-tree 的部分，我們使用六個資料組（見表一）進行結果分析。其中三個是自行
產生的資料組（見下圖五）。在圖六及圖七中，我們分別顯示了在不同 threshold（即圖中之
）之下，近似核心群個數相對於原資料點個數的比例，以及叢集化準確率的結果。我們可
以看出即使只有極少的近似核心群，仍能維持極好的叢集化準確率。 
 
表一：資料組 
資料組名稱 資料點個數 正確叢集個數 
Spherical5 250 16 
Half-rings 800 2 
3Rings 900 2 
8d5k [10] 1000 8 
Opt-digits 3823 64 
Pen-digits 10992 16 
 
(a) (b) (c)
 
圖五：自行產生之資料組。 
(a) (b)  
圖九：EAC 結合 CA-tree 用在影像像素分割的範例。(a)原圖；(b)分割結果（三群）。 
 
    對於以叢集整合偵測主曲線的部分，以下圖十是圖四流程圖的結果範例。 
    
(a)                           (b) 
    
(c)                            (d) 
    
(e)                             (f)  
圖十：流程圖（圖四）各個步驟所產生的結果。(a)第一階段分群結果；
(b)第二階段分群結果；(c)第三階段分群結果；(d)紅色個別分群的資料
集合；(e)從(d)所得到的主曲線；(f)整合數段主曲線所得到的結果。 
 
 
參考文獻 
 
[1] A. Strehl and J. Ghosh "Cluster ensembles -- a knowledge reuse framework for combining 
multiple partitions", J. Machine Learning Research, vol. 3, pp. 583-617, 2002. 
[2] A.P. Topchy, M.H.C. Law, A.K. Jain, and A.L. Fred, "Analysis of consensus partition in cluster 
ensemble", Proc. 4th IEEE Int'l Conf. Data Mining (ICDM), pp. 225-232, 2004.  
[3] A.L.N. Fred and A.K. Jain, "Combining multiple clusterings using evidence accumulation", 
IEEE Trans. Pattern Analysis Machine Intelligence, vol. 27, pp. 835-850, 2005. 
[4] H. Luo, F. Kong, and Y. Li, "Combining multiple clusterings via k-modes algorithm", LNAI, 
vol. 4093, pp. 308 – 315, 2006. 
[5] L.I. Kuncheva and D.P. Vetrov, "Evaluation of stability of k-means cluster ensembles with 
無研發成果推廣資料 
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
