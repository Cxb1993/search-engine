By the full study of our research team from early 
2007, we find that UCT can be applied to other 
computer games, and obtain significant performance 
improvement. Remarkably, because UCT has the 
characteristics of Monte Carlo Method, we can adjust 
the simulation times to fine-tune the program＇s 
strength. By these characteristics, the same program 
can be suitable for different levels of users, which 
is difficult to reach by the traditional game tree 
method. 
This project will spend three years to research how 
to apply UCT to computer games. The first of all, we 
will improve UCT and apply UCT to the perfect 
information games such as Go, Chinese Chess and 
connect6. Secondly, we will research how to apply UCT 
to the imperfect information games such as Dark Chess 
and Russian Poker. 
This project is a subfield of digital gaming 
development corresponds to the important research of 
National Science Council. The result of this project 
could help the development of gaming industry. During 
the work of this project, we have completed 12 papers 
which are from the contents. The game programs of 
this project attended international tournaments every 
year, and won 8 gold medals in those tournaments. 
 
英文關鍵詞： Computer games、UCT、MCTS、Randomize algorithm、
Digital games、Go、Connect6、Chinese Dark Chess 
 
計畫摘要 
 
關鍵詞：電腦對局、隨機演算法、蒙地卡羅樹搜尋、數位遊戲、圍棋、六子棋、暗棋 
 
「蒙地卡羅上界信賴樹狀搜尋演算法」（UCB for Tree Search, UCT）是一個結合上界信賴演
算法(Upper Confidence Bound, UCB)以及蒙地卡羅演算法，應用於樹狀搜尋的 2007 年開始發展的
嶄新演算法，這個演算法應用在圍棋上，不但能夠對當時最佳的圍棋程式取得極高的勝率，甚至
能在九路小棋盤上打敗職業棋士。這個成果，使得此演算法成為人工智慧領域當紅的研究課題。 
這個演算法，經過我們團隊自 2007 年初開始的全力研究後，發現即使對於其他種類的棋牌
遊戲，都可以應用此方法，並且取得極大的效能改善。最值得注意的是，由於此一演算法具有蒙
地卡羅法的特性，因此可以藉由調整模擬次數，來精確微調程式的實力，這樣一來，同一個程式
可以適合各種不同等級的使用者，這是傳統的對局樹方法所難以達成的。 
本計畫將以三年的時間，研究 UCT 在棋牌類遊戲上的應用，我們首先將改良 UCT 應用在圍
棋、象棋與六子棋等透明資訊遊戲，然後也將研究如何改進，應用在有隱藏資訊成分的遊戲，包
括暗棋、十三張等。 
本計畫會有以下貢獻：UCT 對於對局類遊戲的發展，包括兵棋推演，都將會有革命性的影
響，我們投入此研究，將使得台灣在此方面不至落後。執行計畫的學生，將來畢業時，能夠將此
方法應用在產業界與國防工業，對於培養前瞻性科技與技術研發人才將有所貢獻。計畫進行時，
也將開發出一些學術或技術上創新的隨機搜尋演算法，圖形理論及機器學習理論，目前已經有 6
篇相關期刊論文與 5 篇研討會論文發表。所研發製作出的電腦對局程式，每年將參加國際性的比
賽，目前為止共計獲得 8 面金牌，在圍棋、象棋、六子棋與暗棋本計畫所發展的棋類都繼續保持
在世界前兩名的佳績。 
 
 目錄 
1  前言............................................................................................................................................................ 1 
2  研究目的.................................................................................................................................................... 1 
3  文獻探討.................................................................................................................................................... 2 
3.1  蒙地卡羅上界信賴樹狀搜尋演算法(MCTS) .............................................................................. 3 
3.1.1  上界信賴演算法........................................................................................................................ 3 
3.2  蒙地卡羅上界信賴樹狀搜尋演算法............................................................................................ 3 
3.3  蒙地卡羅上界信賴樹狀搜尋演算法在圍棋上的應用................................................................ 4 
3.4  六子棋............................................................................................................................................ 7 
3.4.1  六子棋的搜尋策略.................................................................................................................... 7 
3.4.2  六子棋的迫著搜尋.................................................................................................................... 7 
3.5  象棋................................................................................................................................................ 8 
3.6  暗棋................................................................................................................................................ 8 
3.7  十三張............................................................................................................................................ 9 
3.7.1  遊戲策略.................................................................................................................................. 10 
3.8  參考文獻...................................................................................................................................... 11 
4  研究方法.................................................................................................................................................. 14 
4.1  第一年：建立瀏覽器模式執行的對奕網站與研究 MCTS演算法在圍棋上的應用................ 14 
4.1.1  AJAX之研究 .......................................................................................................................... 14 
4.1.2  AI連接介面之研究 ................................................................................................................ 15 
4.1.3  研究 MCTS應用於圍棋上的基本架構，並研究如何讓模擬更準確.................................... 15 
4.1.4  研究如何使 MCTS的節點有效地減少.................................................................................... 16 
4.1.5  研究如何結合開局資料庫與MCTS ...................................................................................... 16 
4.2  第二年：研究MCTS在六子棋及象棋上的應用 ..................................................................... 17 
4.2.1  整合迫著搜尋方法與MCTS來增加搜尋正確性的方法 ..................................................... 17 
4.2.2  利用迫著搜尋方法所建立的搜尋樹，作為 MCTS的基礎.................................................... 18 
4.2.3  研究象棋程式中的 MCTS架構................................................................................................ 19 
4.2.4  研究象棋程式中的MCTS ...................................................................................................... 19 
4.3  第三年：研究MCTS在暗棋、十三張與大老二等的應用 ..................................................... 22 
4.3.1  MCTS在暗棋程式的應用 ...................................................................................................... 22 
4.3.2  使用 MCTS於十三張的出牌模擬伸縮牌的防守、攻擊獲勝機率........................................ 23 
4.3.3  研究MCTS在大老二撲克牌遊戲上的運作模式 ................................................................. 24 
5  結果與討論.............................................................................................................................................. 25 
5.1  本計畫完成工作項目.................................................................................................................. 25 
5.2  對於參與之工作人員，獲得之訓練.......................................................................................... 26 
5.3  本計畫貢獻.................................................................................................................................. 26 
5.4  本計畫發表之論文列表與索引.................................................................................................. 27 
 
 2
 
 
3 文獻探討 
 
電腦對局(computer game)的研究自從 1950 年由 Shannon 提出利用電腦來下西洋棋的概念以來，
電腦對局就成為人工智慧領域中最吸引人的課題之一。1997 年 IBM 在超級電腦上開發出來的＂深
藍＂(Deepblue)戰勝了人類西洋棋冠軍，可說是人工智慧的一個重要的里程碑 [Herik et. al. 2002]。近
年來遊戲產業日益受到重視，棋牌類遊戲被視為耐玩度最高，永不退流行的遊戲，另一方面，圍棋
及象棋也被視為可以幫助訓練大腦機能的遊戲，教育部在 2007 年也正式指定圍棋為推薦甄試的參考
項目之一。因此電腦對局的研究，近年來也進入實用階段。 
人工智慧運用在電腦對局相關領域，還包括認知科學(cognitive science)、軟體工程(software 
engineering)、機器學習(machine learning)和組合對局理論(combinatorial game theory)。對於目前世界
上較廣為流傳的棋盤遊戲，我們可分析其複雜度如表 1。[Bouzy and Cazenave, 2001] [Yen et.al. 2004]  
Chechers(西洋跳棋)、Othello(黑白棋)在電腦上的發展，已到達超越人類思考的程度；Chess(西洋
棋)而言，電腦已到達世界冠軍的水準；至於 Chinese Chess(象棋)、Connect6(六子棋) 、Go(圍棋)的
比賽中，仍然是人腦勝過電腦，在這些棋類中，仍有很大的進步空間。 
  
棋類名稱 log10(E) log10(A) 相關程式與人類
最強棋士比較 
Checkers 17 32 Chinook>H 
Othello 30 58 Logistello>H 
9×9 Go 40 85 <<H 
Chess 50 123 Deep Blue>=H 
Chinese Chess 48 150 ELP<H 
Connect6 172 160 <<H 
19×19 Go 160 400 <<H 
表 1. 七種代表性棋類複雜度比較 
由表 1 中可以看出象棋、六子棋、圍棋的複雜度都很高，這是因為這些棋類的盤面都比較大，
如果使用暴力法搜尋，由於每層的分支數過多，將無法搜尋很深。因此，一些全域搜尋的方式通常
不適合用於圍棋這種複雜度太高的遊戲。但是這種局面被近年來被提出的新演算法給打破了，使得
圍棋也可以進行全域搜尋，並且大幅地提升了圍棋程式的棋力。這個新的演算法，便是本計畫的主
角--蒙地卡羅上界信賴樹狀搜尋演算法(UCB for Tree Search, UCT) [ Levente Kocsis and Csaba 
Szepesvári, 2006]。 
蒙地卡羅上界信賴樹狀搜尋演算法是一種全域搜尋的演算法，它以蒙地卡羅模擬演算法作為局
面評估的依據，又利用上界信賴演算法使得搜尋樹可以往較優秀的子點展開成為一棵不平衡樹，從
而達到裁剪的目的以增加搜尋深度，適用於解決高複雜度的問題。此方法運用於圍棋領域，已然取
得極大的成功，使用此演算法的圍棋程式囊括了 2007 年電腦奧林匹亞圍棋項目的前三名，並且對
2006 年的冠軍取得了接近百分之百的勝率。 
本章節中將詳述這個研究計畫之文獻探討，包括蒙地卡羅上界信賴樹狀搜尋演算法，圍棋，象
棋，六子棋，暗棋及十三張等。 
 4
點開始，利用上界信賴公式計算每個子點的上界信賴值，選擇此值最高的子點，然後
重複此方式，不斷往下搜尋，直到遇到葉節點為止。 
STEP 2. 拓展(Expansion)：若步驟 1 最後找到的葉節點已經拜訪過，則我們會產生此葉 節點
的子節點，以找到從未拜訪過的葉節點。 
STEP 3. 模擬(Simulation)：找到從未拜訪過的葉節點後，我們會使用蒙地卡羅模擬以得到此葉
節點的收益值。 
STEP 4. 倒傳遞(Backpropagation)：根據步驟 3 得到的收益值，更新這條從根節點到葉節點的
最佳路徑上所有節點的收益值。 
STEP 5. 重複步驟 1~4，直到指定的時間或次數用盡為止。 
經過上述步驟所得到的搜尋樹，其根節點之下，收益值最佳之子點，即為解。對於在短時間內
找到最佳解的問題上，蒙地卡羅上界信賴樹狀搜尋演算法是優於傳統的 alpha-beta 搜尋的。蒙地卡羅
上界信賴樹狀搜尋演算法和 alpha-beta 搜尋比較起來，主要有三項優點： 
1. 蒙地卡羅上界信賴樹狀搜尋演算法可停止於任意時間，時間控管方便。 
2. 蒙地卡羅上界信賴樹狀搜尋演算法在處理難以預料的事物時較強健 
3. 蒙地卡羅上界信賴樹狀搜尋演算法是非對稱性展開，對於好手會展開較深。 
3.3 蒙地卡羅上界信賴樹狀搜尋演算法在圍棋上的應用 
在上節中，我們已經介紹了蒙地卡羅上界信賴樹狀搜尋演算法的理論。蒙地卡羅上界信賴樹狀
搜尋演算法使用在圍棋上，主要的概念，就是每個節點代表一個盤面，此節點的分支代表此盤面下
的合法著手，每個分支連結到的子節點，就是原盤面加上分支代表的著手後，所產生的新盤面。一
般而言，目前盤面為根節點，根節點的分支代表目前盤面下的合法著手，根節點的子節點代表根節
點的盤面加上分支代表的著手後所形成的新盤面，如圖 1 所示： 
 6
                     
 
圖 2：蒙地卡羅上界信賴樹狀搜尋的流程 
上圖中，所謂「得到最佳路徑」，指的是從根節點開始，根據上界信賴公式向下搜尋，直到找到
葉節點為止的過程。所謂葉節點，就是未曾拜訪過的節點。當搜尋時，若拜訪到的節點雖非葉節點，
但仍無子點，則會產生子點，子點的多寡，直接影響到搜尋的深度與棋力的高低，因此對於產生出
來的子點，必須加以裁減，搜尋的效率才會提高。 
第三個步驟是模擬棋局。所謂的模擬棋局，就是由上一個步驟所找到的葉節點開始，由電腦接
手下完，並回傳勝負結果，以更新蒙地卡羅上界信賴搜尋樹。模擬棋局的核心就是其決定著手的方
法。最簡單的方法，就是純粹隨機落子(除了非法著手或自填眼位以外)，這種方法的好處就是快速、
簡單，且符合蒙地卡羅法的精神。但缺點則是用這種方法做出來的圍棋程式，棋力低落。有研究者
指出，要使棋力進步的重點，在於棋局的手順要有意義 [Sylvain Gelly, Yizao Wang, Rémi Munos, and 
Olivier Teytaud, 2006]，而不是像隨機落子一樣，天南地北地亂下。 
以當前盤面建立
根節點
更新上界信賴搜尋樹
模擬次數加一 
判斷是否達到目
標模擬次數
否
是
回傳根節點底下勝率最高的
子點作為搜尋的結果
 由根節點開始， 
得到最佳路徑
執行模擬棋局 
 8
但是，迫著搜尋並無法讓六子棋解決所有的搜尋問題。因為當盤面出現可攻擊線(Attack Line)時，
可利用迫著搜尋方法來搜尋連續威脅取勝程序，當找出連續威脅取勝程序時即可經由此程序進行攻
擊。可是在無攻擊線或迫著搜尋方法無法找到連續威脅取勝程序時，此時著手的策略只能利用評估
函數來構思下一個著手，評估函數的設計是一個需要高度專家經驗法則的方法，從上一節的敘述可
以了解很難有完美的評估函數設計。因此，本研究擬採蒙地卡羅的觀念，利用模擬來評估著手獲勝
的機率，並從中找出最佳著手，本計劃將研究如何利用蒙地卡羅上界信賴樹狀搜尋演算法來做六子
棋的搜尋。 
3.5 象棋 
本計劃在於使電腦遊戲的評估函數更加趨近於遊戲使用者。目前象棋的電腦程式所使用的評估
函數都是用棋子本身的權重與棋子在棋盤上的位置權重兩者相加所得到的分數為此棋子所擁有的價
值。這樣的評估函數難免會出現一些與人思考方向有所誤差，因此使用蒙地卡羅上界信賴樹狀搜尋
演算法的方法算出一個機率值以符合人類思考方式。使其能計算出其所下的著手在以後的勝率大約
的數值。 
決定電腦象棋程式棋力的兩個主要因素是："搜尋深度"和"審局函數"。其中搜尋深度可以從改善
程式的搜尋技巧和加速機器的硬體速度兩方面來努力。至於審局函數則有賴專家知識與經驗的參
與。不過搜尋深度和審局函數只是對局主體的一部分而已，這種方法仍然沒有足夠長遠的眼光，可
以防止水平效應的出現。因此針對象棋的各個階段，仍須有不同的措施以提高棋力： 
 開局：須利用開局知識庫記憶大量開局譜以防電腦走入對手的陷阱。[許 1990a, 1990b][顏 2003] 
[Yen et.al. 2004] 
 中局：除了各類搜尋技巧的應用外，為了使電腦能針對特殊狀況加深搜尋的深度，須發展"連將
殺"與"停著殺"的搜尋技巧。 
 殘局：使用各種不同的目標導向經驗知識，以解決不同類型的殘局，此類殘局以目前的中局搜
尋技巧仍然無法解決。 
依照傳統的 alpha-beta 搜尋技巧，結合 A 類搜尋，雖然可以得出較佳著手(如吃到對方的馬)，但
往往會漏掉更好的著手(如直接將死對方)，這是由於搜尋層數太少所致。因此如前述廖嘉成，曹國明
先生皆曾提出連將殺的概念，針對紅黑雙方只有將軍與解將，每層步數較少的特性，而將搜尋層數
往下延伸數層。如此遇有連將殺時，電腦才不會只走出得子的步，忽略奪將的步，從而達到提高棋
力的目的。但光是這樣是不夠的。依造人類對局的經驗，步數算得愈多，愈準，愈快，棋力也就愈
高。初級棋手可能只能針對少數重要著手算五、六步(層)，懂得簡單得子的技巧;中級棋手算的步數
更多，能得出十幾步之後的連將殺;高級的棋手則能算出步數更多的催殺步。 
3.6 暗棋 
在暗棋的對局中，蓋著的棋子是影響著勝負的微妙決勝點，當開局沒得吃棋的情況下，要翻哪
個位置是很難讓電腦去學習的，連玩家其實也很多是靠運氣來亂翻，可是還是有許多規則可循。但
若是用 TABLE 查表的方法，則規則太多無法詳述，使用搜尋的方法，則蓋著的棋子為不完全的資訊
取得，若要全部考慮的話，將使得分支度十分的大，搜尋的深度將會不夠深，而使得棋力薄弱。蒙
地卡羅上界信賴樹狀搜尋演算法在暗棋上，運用的是開局的模擬，而終局是使用 alpha-beta 搜尋來完
成。 
 10
葫
蘆  Full House  
以三條加對子的方式組成五張牌。比三張牌的
數字大小。  
Q 、 Q 、 Q 、 5 、 5 ＞ 6 、 6 、 6 、
8 、 8  
鐵
支 
Four of a 
Kind 
又稱鐵支，四張相同數字的牌，打的時候還需
要加一張隨意牌湊成五張打出。 8 、  8 、
8 、 8 ＞ 6 、 6 、 6 、 6  
同
花
順  
Flush 
Straight 
又稱柳丁，同一種花色五張連續牌，比最大數
字牌的大小。  
最大為 10、J、Q、K、A，最小為 1、2、3、4、
5。  
一
條
龍  
Dragon  13 張點數不重複的連續牌，花色也不相同。 
同
花
青
龍  
 Flush 
Dragon 相同花色的一條龍，稱為同花青龍。 
 
表 2：十三張的牌型由小至大排列 
 
3.7.1 遊戲策略 
十三張的勝負結果，「運氣」部分約佔 75％，「技巧」只佔 25％，但是擁有技巧的一方在長時間
的征戰中必能勝出，其中最重要的技巧為「伸縮牌的決定」與「機率牌的推敲」。 
一般來說，相同的 13 張牌會有 5 種以上的排法，而決定哪一種排法就必須靠「伸縮牌的決定」
與「機率牌的推敲」兩種技巧並用。大致上排法可以分為『防守』與『進攻』兩種，『防守』意思是
要防止被打槍的牌組，『進攻』就是可以打別人槍的牌組。技巧分析如下例： 
 
 A K Q J C 9 8 7 6 5 4 3 2 
黑桃          ● ●   
紅心    ● ●  ●     ● ● 
磚塊     ●   ● ●     
梅花    ●   ●  ●     
 
表 3.機率牌實例 
 
最正確的進攻排法應為 JJ7-CC886-65432（1-2-順），若排出 JC6-87654-JC832（0-順-同），因為
只拿到兩張 J，尚有 14 張比 J 大的牌，因此前敦要取得勝利的機率不高，而尾敦（JC 同花）是同花
中是平均之下的牌組，因此（0-順-同）被打槍的機率來得比（1-2-順）為高。 
 
 
 12
14. M. Ginsberg, "Gib: Imperfect Information in a Computationally Challenging Game," Journal of Artificial 
Intelligence Research, vol. 14, pp. 303-358, 2001.  
15. Huang, S. C., Coulom, R. and Lin, S. S. (2010).Monte-Carlo Simulation Balancing Applied to 9×9 Go. 
ICGA Journal, Vol. 33, No. 4, pp. 191-201. 
16. G. Chaslot, J.T. Saito, J. Uiterwijk, B. Bouzy, and H.J. Van der Herik, "Monte Carlo Strategies for 
Computer Go," in Proceedings of the 18th Benelux Conference on Artificial Intelligence, 2006, pp. 83-90. 
17. R.Coulom. ―Efficient selectivity and backup operators in Monte-Carlo tree search . In: Proceedings of the 
5th international conference on computers and games. Springer-Verlag; 2006:72–83. 
18. L. Kocsis, C. Szepesvari, "Bandit Based Monte Carlo Planning," Machine Learning: ECML, vol. 4212, pp. 
282-293, 2006. 
19. Y. Wang and Gelly S., "Modifications of UCT and Sequence-like Simulations for Monte-Carlo Go.," in 
Proceedings of the 2007 IEEE Conference on Computational Intelligence and Games, 2007, pp. 175 -182. 
20. S Gelly and D Silver, "Combining Online and Offline knowledge in UCT," in Proceedings of the 24th 
International Conference on Machine Learning, Corvalis, Oregon, 2007, pp. 273-280. 
21. G Chaslot, C Fiter, JB Hoock, A Rimmel, O Teytaud. ―Adding expert knowledge and exploration in 
Monte-Carlo Tree Search . Advances in Computer Games. pp. 1-13, 2010. 
22. G. Chaslot, M. Winands, J. Uiterwijk, and H.J. Van der Herik, "Progressive Strategies for Monte Carlo 
Tree Search," in Proceedings of the 10th Joint Conference on Information Sciences (JCIS 2007), 2007, pp. 
655-661. 
23. L. Kaelbling, M. Littman, and A. Cassandra. ―Planning and acting in partially observable stochastic 
domains . Artificial Intelligence, 101:99-134, 1995. 
24. S. Russell and P. Norvig, Artificial Intelligence, A Modern Approach. Third Editon, Pearson 2010. 
25. N Sturtevant, "An analysis of UCT in Multiplayer Games," in Proceedings of the 6th International 
Conference on Computers and Games. , volume 5131 of Lecture Notes in Computer Science, pp. 37–49. 
Springer, 2008. 
26. J Long, N Sturtevant, M Buro, and T Furtak, "Understanding the Success of Perfect Information Monte 
Carlo Sampling in Game Tree Search," in Proceedings of the 24th AAAI Conference on Artificial 
Intelligence, Atlanta, 2010. 
27. M. Zinkevich, M. Johanson, M. Bowling, and C. Piccione, "Regret Minimization in Games with 
Incomplete Information," in Proceedings of the 21st ACNIPS, 2007, pp 1729 – 1736. 
28. D. Koller and N. Megiddo. ―The complexity of two-person zero-sum games in extensive form . Games 
and Economic Behavior, pp 528–552, 1992. 
29. M Lanctot, K Waugh, M Zinkevich, and M Bowling, "Monte Carlo Sampling for Regret Minimization in 
Extensive Games ," in Proceedings of the 23rd ACNIPS, , 2009, pp. 1078-1086. 
30. M. Bowling et al, ―A Demonstration of the Polaris Poker System , in Proceedings of the 8th International 
Conference. on Autonomous Agents and Multiagent Systems (AAMAS 2009), May 2009, Hungary, pp. 
1391 –1392. 
31. T. Cazenave and N. Jouandeau, "On the Parallelization of UCT," in ACG 2007, pp 93-101. 
32. G.M.J-B. Chaslot, M. Winands, and H.J. van den Herik, "Parallel Monte-Carlo Tree Search," in 
Proceedings of the 6th International Conference on Computers and Games, volume 5131 of LNCS, pp. 
60–71. Springer, 2008. 
33. H.J. Berliner, Some Necessary Conditions for a Master Chess Program, Proceedings of the 3rd 
International Joint Conference on Artificial Intellignce, (Menlo Park: SRI), Stanford, 1973, pp. 77-85. 
34. Bernard Helmstetter, Chang-Shing Lee, Mei-Hui Wang, Fabien Teytaud, Olivier Teytaud, Shi-Jim Yen, 
"Random positions in Go," 2011 IEEE Conference on Computational Intelligence and Games, 2011, Seoul, 
South Korea. 
35. Van Lishout, F., Chaslot, G., Uiterwijk, J.: Monte-Carlo Tree Search in Backgammon. In: Computer 
Games Workshop, pp. 175–184 (2007) 
36. G. Van den Broeck, K. Driessens, J. Ramon, Monte-Carlo tree search in poker using expected reward 
distributions, in: Advances in Machine Learning, First Asian Conference on Machine Learning, ACML 
2009, pp. 367–381.. 
37. Borsboom, J., Saito, J.-T., Chaslot, G., and Uiterwijk, J. W. (2007b). A comparison of monte-carlo 
methods for phantom go. BNAIC 2007, Utrecht, The Netherlands. 
38. P. Ciancarini and G.P. Favini, “Monte Carlo tree search in Kriegspiel,” Artificial Intelligence, vol. 174, Jul. 
2010, pp. 670-684. 
39. M. Enzenberger, M. Müller, B. Arneson and R. Segal. “Fuego - An Open-Source Framework for Board 
Games and Go Engine Based on Monte Carlo Tree Search,” IEEE Transactions on Computational 
Intelligence and AI in Games, 2(4), 259-270, 2010. 
40. Bouzy, B. and Chaslot, G. (2006). Monte-Carlo Go Reinforcement Learning Experiments. 2006 IEEE 
Symposiumon Computational Intelligence and Games(eds. G. Kendall and S. Louis), pp. 187-194, Reno, 
USA. 
41. Bernard Helmstetter, Chang-Shing Lee, Mei-Hui Wang, Fabien Teytaud, Olivier Teytaud, Shi-Jim Yen, 
"Random positions in Go," 2011 IEEE Conference on Computational Intelligence and Games, 2011, Seoul, 
South Korea. 
42.  
43. Silver,D. (2009). Reinforcement learning and simulation-basedsearch in computer Go. Ph.D. dissertation, 
University ofAlberta. 
 14
 
 
4 研究方法 
4.1 第一年：建立瀏覽器模式執行的對奕網站與研究 MCTS 演算法在圍棋上的應用 
 （2009 年 8 月至 2009 年 10 月）AJAX 之研究。 
 （2009 年 11 月至 2010 年 4 月）AI 連接介面之研究。 
 （2000 年 8 月至 2000 年 12 月）研究 MCTS 應用於圍棋上的基本架構及演算法，研究如何讓模擬
更準確。 
 （2010 年 1 月至 2010 年 4 月）研究如何使 MCTS 的節點有效地減少。 
 （2010 年 4 月至 2010 年 7 月）研究如何結合開局資料庫與 MCTS。 
4.1.1 AJAX 之研究 
利用 AJAX 技術來開發線上遊戲，僅需透過網頁即可遊戲，不需下載軟體安裝，以簡單、人性
化為目標！目前網路上相關遊戲網站，皆為軟體模式或非即時網頁模式，本系統要達到無需安裝軟
體及即時互動功能，讓使用者方便使用。系統也能收集使用者下棋的棋步當作日後資料探勘使用。
但因為瀏覽器種類眾多，AJAX 無法相容於所有瀏覽器，需要查出相關通用指令來做開發，已達到
大部份瀏覽器皆能使用此遊戲平台，目前以 Internet Explorer 及 Mozilla Firefox 為主要參考瀏覽器，
並遵守 W3C 原則做網頁開發。 
網頁開發語言採用 ASP (Application Service Provider)，主要在於所產生的執行結果都是標準的 
HTML 格式，而且這些程式是在網路伺服器端中執行，使用一般的瀏覽器 (如 IE 或 Netscape 等) 都
可以正確的獲得 ASP 的『執行』結果，並且將這 ASP 執行的結果直接在瀏覽器中『瀏覽』。 
本階段已完成以下兩個部份： 
1. 本平台可以提供各類遊戲於單一平台上，不限於任何遊戲。採用 AJAX 開發，僅需透過瀏覽
器即可執行。 
2. 本平台可以提供 人對人、人對 AI、AI 對 AI，可使用於對局、教學、AI 對局測試使用。 
 16
 
4.1.4 研究如何使 MCTS 的節點有效地減少 
蒙地卡羅上界信賴搜尋樹是一棵極小極大樹，而圍棋又是以分支度極高而著名的。因此常常使
得蒙地卡羅上界信賴搜尋樹的深度嚴重受限，並因此耗費時間與資源於一些極可能是壞點的節點
上，從而阻礙了棋力的進步。有鑒於此，如何有效地裁減蒙地卡羅上界信賴搜尋樹的節點，就成了
當務之急。若能有效地將一些不必要的分支不加以展開，甚至予以裁剪，則蒙地卡羅上界信賴搜尋
的深度可以更深，其結果也將更加準確。要達到此一目的，目前有幾種作法，如只將前兩手的棋塊
附近的空點當作子點，或是利用漸近展開，亦即對所有空點依其價值作排序，然後隨模擬次數漸增，
逐漸開放空點作為子點。如此一來，就會抑制子點的大量產生，而將精力集中於較有可能的空點上。
但是此一方法的問題在於，價值判斷從何而來。換言之，若價值判斷準確，則不需 MCTS，亦可選出
好點；若價值判斷不夠準確，則排名在後的空點卻本來可能是好點。根據上述的討論，我們找出的
方法可以有效且快速地對蒙地卡羅上界信賴搜尋樹的節點作裁剪，以使其搜尋更深，進而獲得更佳
的棋力。 
4.1.5 研究如何結合開局資料庫與 MCTS 
當有了前面的基礎，我們所要考慮的，就是 MCTS 所適用的階段。以目前此演算法的表現而言，
它在佈局時常下出完全背離一般佈局知識的著手，而使得大局落後，但是其近身搏鬥以及官子收束
表現卻相當出色，因此如何截長補短，就是這一階段的重要目標了。若能結合優秀的開局資料庫與
MCTS 中後盤攻殺的實力，則棋力可望更上一層樓。但是此處的難點在於，如何判斷「序盤結束」、
「中盤開始」，也就是此一銜接處到底在何處？目前的構想是，在圍棋中，雙方一人一著，逐步搶佔
大場，因此照常理判斷，棋盤上空點的價值應是線性地逐漸變小，此時，若突然有超過上一手價值
的大棋產生，則可推論有攻殺產生，如此一來，即進入中盤狀態，MCTS 也可在此適時接手，以達
到有效的結合。 
綜觀目前有使用 MCTS 的圍棋程式，絕大部分的序盤皆任此演算法放手施為，倘若此時能實現
開局資料庫與 MCTS 的有效結合，則可在序盤便取得優勢，則取勝機率也隨之變大。 
 18
而 MCTS 在每一回合的模擬中，採用隨機選擇候選著手的模擬方式，來計算某一候選著手成功
的機率。它並不需計算 Line 的資訊，所需的計算只有在產生合法的候選著手和是否遊戲已經終止上，
因此計算量遠小於迫著搜尋方法。 
因此本研究結合兩種搜尋策略的優點，採用將 MCTS 加入迫著搜尋方法的方式。即在迫著搜尋
時，先建立搜尋樹，當在迫著搜尋的過程中，如果產生數量過大的候選著手時，先針對每一個候選
著手進行蒙地卡羅上界信賴樹狀搜尋。 
此種作法所增加的計算量不大，但卻可以加快迫著搜尋方法的速度，因為在迫著搜尋的過程中，
有時在搜尋樹的不同階層中，都會存有解。利用 MCTS 可以了解哪一個候選著手有較大找到解的機
會。此外，所建立的搜尋樹，對下一階段的蒙地卡羅上界信賴樹狀搜尋也有很大的幫助。 
 
4.2.2 利用迫著搜尋方法所建立的搜尋樹，作為 MCTS 的基礎 
以深度優先搜尋為主的迫著搜尋方法中，當搜尋至葉節點後，仍然無解時。可以針對所建立的
搜尋樹的每一個葉節點，繼續進行蒙地卡羅模擬，再往回推算出第一階候選著手的機率值。此種作
法符合 MCTS 的精神，因為在挑選候選著手時，能夠產生迫著的著手本來就具有較大的獲勝機會，
因此可以針對這些著手進行模擬。 
在很多的研究中，將 MCTS 應用在遊戲的搜尋上，所得到的結果大致都讓人相當滿意。但是尚
未有人將此方法應用在六子棋的搜尋策略中，因此預計在六子棋的搜尋策略應用上，可能遭遇之困
難及解決途徑如下所述。 
4.2.2.1 結合MCTS與迫著搜尋方法的困難 
迫著搜尋方法是一個相當花費時間的搜尋方法，但是它的搜尋結果卻是相當明確的結論，因此
如何適當的結合 MCTS 來進行迫著搜尋候選著手的評估，是本研究會面臨的第一個問題。 
在此問題的解決上，因為我們只是利用蒙地卡羅上界信賴樹狀搜尋來加快迫著搜尋方法的速
度，所以模擬的局數將不會選擇太多。太多的模擬局數花費太多時間，反而大幅增加迫著搜尋所必
須花費的時間。在此部份，正確性比較不是那麼重要，速度才是第一考量的因素。 
關於迫著搜尋後，所搜尋過的盤面，應該要將資訊都保存下來，才不至於在執行蒙地卡羅上界
信賴樹狀搜尋時，又再度重複計算相同盤面的資訊。在此問題上，本研究擬採用樣式比對的方式來
避免相同的搜尋。雖然樣式比對也會花費時間，但此方式所帶來的效益遠大於比對本身所必須花費
的時間。 
4.2.2.2 建立蒙地卡羅上界信賴搜尋樹的問題 
利用蒙地卡羅上界信賴樹狀搜尋的最主要目的，乃在於找出第一階候選著手中獲勝機率最大的
著手。因此在模擬過程中並無必要建立整個蒙地卡羅上界信賴搜尋樹，如此將會浪費記憶體的使用
以及增加處理的時間。 
本研究擬採取迭代擴張的方式來建立搜尋樹，也就是在每一個模擬的回合中，只針對尚未展開
的子結點展開一階，而不是將整個模擬的子節點都展開。 
4.2.2.3 蒙地卡羅上界信賴樹狀搜尋的問題 
在 MCTS 中，所必須面對的問題有：模擬局數的考量、候選著手數的篩選以及搜尋深度的考量，
茲分述如下。 
 模擬局數的考量 
我們知道在蒙地卡羅上界信賴樹狀搜尋中，模擬的局數越多所得到的結果也會越準確，但是多
 20
而且圍棋不同於象棋，圍棋只要把盤面填滿就算結束。但象棋如果也是隨機下子則有很大的機
會會形成各個棋子亂走，沒辦法吃掉對方的將軍造成和局。如此一來將無法利用模擬棋局來當做評
估函數。但模擬棋局的著手的計算也不能太過複雜。由於在搜尋樹的每一個點都要模擬到結束。因
此他得必須儘快選擇要下哪一個著手，不需要考慮太多，用越簡單的方法判斷越好。 
因此我們採用利用極小極大樹往下只搜尋一層所有著手的方式，將得到的分數取前幾名，用亂
數選其中一個好的著手來下子。同時為了避免形成迴圈的走法，限制每次模擬只模擬雙方各 50 手。
因為目前人類所下的棋面大約是 30 到 40 手左右就會結束，因此一但達到雙方各 50 手就自動停止並
以一般的評估函數進行分數的估算，哪一方分數較高則該方獲勝。紅方勝利則回傳 1，黑方勝利回傳
-1。 
用亂數下子的意義在於如果目前盤勢真的較優時，則在雙方大量亂下的情況下還是能夠獲勝。
再來由於目前的評估函數不一定是百分百正確，大量亂數選前幾手好的著手有助於評估目前的局勢。 
我們將 MCTS 運用於象棋的流程如圖 4 所示： 
 
 22
4.3 第三年：研究 MCTS 在暗棋、十三張與大老二等的應用 
 （2011 年 8 月至 2011 年 12 月）MCTS 在暗棋程式的應用 
 （2011 年 11 月至 2012 年 3 月）使用蒙地卡羅模擬演算法於十三張的出牌模擬伸縮牌的防守、
攻擊獲勝機率 
 （2012 年 2 月至 2012 年 7 月）研究 MCTS 在大老二撲克牌遊戲上的運作模式 
4.3.1 MCTS 在暗棋程式的應用 
在這個階段，我們研究暗棋的開局，研究暗棋程式中 MCTS 架構，以及此演算法對暗棋棋規的
影響，加速方法包括排序及勝率的判斷。 
決定電腦程式棋力的兩個主要因素是："搜尋深度"和"審局函數"。其中搜尋深度可以從改善程式
的搜尋技巧和加速機器的硬體速度兩方面來努力。至於審局函數則有賴專家知識與經驗的參與。不
過搜尋深度和審局函數只是對局主體的一部分而已，這種方法仍然沒有足夠長遠的眼光，可以防止
水平效應的出現。因此針對暗棋的各個階段，仍須有不同的措施以提高棋力： 
開局：在未知的盤面，以及運氣成分的同時，以專家經驗輔以 MCTS 來選出更有利的盤面。 
殘局：在全部蓋著的棋子都被翻開的時候，表示已經沒有運氣成分的存在，鑒於盤面所剩下的
棋子不多，且步法簡單易暸，依照傳統的極小極大搜尋技巧，結合 alpha-beta 裁減便可以得出較佳著
手。 
有鑑於此，發展電腦暗棋的開局實有其必要。研究開局，也就更需要 MCTS 來輔助。若是使用
經驗法則來對照，容易出現盲點，因此出現人類來下可輕鬆獲勝，但電腦來下則盤面循環，該勝變
和。雖在殘局時，使用遊戲樹的搜尋可以走出較好的棋步，但在極度失勢的情況下仍會容易失敗。
在這種情況下，電腦若能使用模擬的方式來考慮，未至殘局之前已取得決定性優勢，能使勝率提高
許多。 
 24
4.3.3 研究 MCTS 在大老二撲克牌遊戲上的運作模式 
電腦棋類遊戲中，敵我雙方的行動皆為公開、不隱藏的資訊，所以被歸類為＂ 完全資訊＂（Perfect 
Information）類型的遊戲。這一類型的遊戲大多是利用暴力搜尋法（Brute Force Search）再輔以經驗
法則以省去多餘的搜尋，來計算出我方最好的一步。這代表著哪一方所犯的錯誤越多，獲得比賽勝
利的可能性就越小。 
在撲克牌遊戲裡，大多是不完全資訊類型的遊戲，亦即不知道對方的牌為何。因此必須先猜測
對方的牌，然後再根據對方所出的牌來獲取資訊，進而慢慢修正對於對方手牌的猜測，大老二便屬
於這種類型的遊戲。 
在本計畫中，我們試圖運用 MCTS 於大老二撲克牌遊戲，以結合傳統的記牌、猜牌模式與最新
的樹狀搜尋演算法，作為出牌的依據。 
結合的方式簡述如下：一開始拿到手牌之後，扣除手上的手牌，將剩下的牌隨機分成三份給三
家。然後每當對手出牌時，若與所猜之牌有所差異，則根據差異之處輔以經驗法則作換牌的動作，
以修正誤差。這部份便是傳統的猜牌方式。 
當輪到自己時，則將牌局情況(包含自己的手牌以及其餘三家猜測的手牌，還有目前可出牌型等
等資訊)視為一個節點，然後將可以出的牌組(若可以 PASS，則包含 PASS)當作分支，由此分支所抵
達的子節點，則為出了分支所代表的牌組後的牌局情況。由這些節點所組成的，即為搜尋樹。 
實際搜尋時，便根據 MCTS，以目前牌局情況為根節點，重複找最佳路徑、拓展搜尋樹、模擬
牌局、倒傳遞更新最佳路徑上所有節點之勝率等四個步驟，直到達到指定的次數，或可用時間消耗
殆盡為止，此時根節點下最佳之分支即為解。 
其中，在執行模擬牌局時，即根據目前所猜測的資訊來進行。模擬時亦可加入專家知識，例如 2
通常是危險牌，則打出 2 的機率就較高，以防最後打不出去，有分數加倍的風險；或是拆牌會導致
牌型零散，則拆牌的機率便下降等等。也就是說，可將原本用於判斷出牌的一些法則用於模擬牌局
上，使得模擬可以有事半功倍之效果。 
 26
大老二撲克牌遊戲上的運作模式。相關研究內容已發表在以下期刊論文與研討會論文，論文全文內
容請參考附件。 
 期刊論文 
Shi-Jim Yen*, Jung-Kuei Yang+, Kuo-Yuan Kao, and Tai-Ning Yang, "Bitboard Knowledge Base System 
and Elegant Search Architectures for Connect6," Knowledge-Based Systems, 0950-7051, vol. 34, 2012, pp. 
43-54. ( IF =2.422/1.967, 15/111 = 13.5%) 
Cheng-Wei Chou+, Jr-Chang Chen, Hideki Kato, and Shi-Jim Yen*, "The 5th GPW Cup 9x9 and 13x13 
Computer Go Tournaments," ICGA Journal vol. 35, no.1, pp. 59-60, 2012.( IF=1.154/1.048, 31/103= 30%) 
 研討會論文 
Shi-Jim Yen, Cheng-Wei Chou, Jr-Chang Chen, I-Chen Wu, and Kuo-Yuan Kao, “The Art of the Chinese 
Dark Chess,” International Computer Symposium, 2012. 
5.2 對於參與之工作人員，獲得之訓練 
對於參與的人員，將對人工智慧中的電腦對局、各種搜尋方式、機器學習和資料探勘方法有更
深入的瞭解及產生相關的研究成果。執行計畫的學生，將來畢業時，能夠將 MCTS 應用在產業界與
國防工業，對於培養前瞻性科技與技術研發人才將有所貢獻。目前國內數位遊戲產業中，由於在數
位遊戲領域，人工智慧應用的範圍越來越廣，所以相當缺乏遊戲人工智慧人才，以本實驗室為例，
通常畢業前就有很多遊戲製作公司來詢問人才。本計劃可幫助學生具有此一方面的能力，可以培養
相關技術研發人才，畢業後投入業界，提升產業競爭力，對相關產業發展有所幫助。 
5.3 本計畫貢獻 
MCTS 對於對局類遊戲的發展，包括兵棋推演，都會有革命性的影響，我們投入此研究，使得
台灣在此方面不至落後。計畫的成果不僅可以幫助研發出棋力高強的電腦對局程式，也可應用於電
腦遊戲上，這些開發出的技術，也可幫助國內遊戲廠商開發相關遊戲，提高國際競爭力。 
目前世界上流傳最廣的棋類有象棋、圍棋、西洋棋等，其中以圍棋人口為最多，象棋次之，而
六子棋則是新興遊戲。相關的數位內容發展，已漸漸成為華人世界的焦點之ㄧ。大陸的各學術單位
近年來對此著力頗深，已經有一年一度的省對抗電腦對局比賽及世界級的電腦對局比賽，已漸漸威
脅台灣在此方面的領先地位，本計劃可提升我們電腦對局研究團隊的競爭力。 
計畫進行時，也開發出一些學術或技術上創新的 MCTS 相關搜尋演算法及其應用，及機器學習
理論，目前共有包括 IEEE TRANS.等級 的 SCI 期刊論文 6 篇與 5 篇包括 IEEE 等級的研討會議論文
發表，論文詳列於本章後段。 
所研發製作出的電腦對局程式，三年來都有參加國際性的比賽，在日本主辦的國際奧林匹亞電
腦對局競賽共獲得四金二銀的佳績，金牌的項目包括象棋、暗棋、邏輯繪圖與點燈拼圖，銀牌的項
目則是六子棋與數牆。荷蘭主辦的國際奧林匹亞電腦對局競賽獲得一金二銅，金牌的項目是象棋、
銅牌為暗棋、NoGo。日本遊戲設計會議 2011 GPW 杯電腦圍棋比賽 1 面銀牌。TCGA 2012 電腦對局
比賽 3 金(象棋、暗棋、Killall Go)， 2 銅(六子棋、NOGO)，共計獲得 8 金 3 銀 4 銅。在圍棋、象棋、
六子棋與暗棋等，繼續保持在世界前兩名的佳績。 
綜合以上所述，本計劃已經達到預期的目標，確實完成預定的成果。 
 
This article appeared in a journal published by Elsevier. The attached
copy is furnished to the author for internal non-commercial research
and education use, including for instruction at the authors institution
and sharing with colleagues.
Other uses, including reproduction and distribution, or selling or
licensing copies, or posting to personal, institutional or third party
websites are prohibited.
In most cases authors are permitted to post their version of the
article (e.g. in Word or Tex form) to their personal website or
institutional repository. Authors requiring further information
regarding Elsevier’s archiving and manuscript policies are
encouraged to visit:
http://www.elsevier.com/copyright
1
Author's personal copy
extremely large. The concept of multistage search is to control the
timing of the generating different candidate moves. In any game
position, candidate moves are classiﬁed to various types, and are
generated in multistage search based on the types. In Connect6,
those types are double-threat, single-threat and non-threat. Numer-
ous differences exist among the types. For example, in the case of
double-threat moves, because Defender requires two stones to
block threats, it has fewer branching factors. Thus, search of dou-
ble-threat is faster than that of other types.
2.2. Threat space search
Threat Space Search (TSS) [30] is a common searching method
in Connect-k games. TSS focuses on the moment when Attacker
plays threat move, at which point Defender should play the corre-
sponding blocking move. TSS uses the threat moves to control the
response moves of Defender. Attacker then performs a deeper
search. TSS is divided to double-threat TSS and single-threat TSS
based on the number of threats generated by the move.
For double-threat TSS, Defender needs two stones for blocking
threats. In contrast, for single-threat TSS, Defender needs only
one stone for blocking. Therefore, Defender is free to place the
other stone. The branching factors of double-threat TSS are smaller
than that of single-threat TSS.
In a node of a Connect6 search tree, the subtree of the node
formed by double-threat TSS is called T2 subtree. In a T2 subtree,
if Attacker can identify to achieve a win, Attacker is said to have
identiﬁed its T2 solution. Otherwise, this T2-subtree is labeled T2
Fail.
In a node of a Connect6 search tree, the subtree of the node
formed by Attacker’s double-threat and single-threat moves is
called TSS subtree. In a TSS subtree, Attacker is said to have ob-
tained its TSS solution when it identiﬁes a process to achieve a
win. Otherwise, this TSS subtree is labeled TSS Fail.
According to the blocking moves played by Defender while
searching, double-threat TSS is divided into Normal TSS and Con-
servative TSS, as detailed below:
2.2.1. Normal TSS
In a game position, a defense set is a set of Defender’s moves that
block threats of Attacker. If Defender can only place two stones of
the defense set based on the rules of Connect6, this search method
is called Normal TSS, or simply TSS. In Fig. 2, the defense set in-
cludes the stones 1–4. This search should expand the move as in
(A), (B), and (C) of Fig. 2, separately. If the T2 solution is very deep,
the state space of the search will be large.
2.2.2. Conservative TSS (CTSS)
CTSS assumes Defender can place all stones of the defense set at
a time [30], like (D) in Fig. 2. Because there is only one child node of
defensive side, CTSS can search toward very deep levels.
2.3. Proof-Number Search
Proof-Number Search (PNS), developed by Allis [2] and [4], is a
reliable algorithm that aims to prove or disprove a binary goal. For
Connect6, this binary goal is the TSS solution. PNS was successfully
used to prove or solve theoretical values of game positions for
many games, such as Checkers, Chess, Connect-Four, Go, Gomoku,
Lines of Action, Renju, and Shogi [2–5,14,22,26,27,29]. The core
idea of standard PNS is to order moves efﬁciently. To achieve such
an ordering, the PNS algorithm selects moves based on two num-
bers in each node: proof number and disproof number. PNS uses
the AND/OR search tree. Table 1 lists the rules that PNS uses to se-
lect the most-proving node. In the OR-Node, PNS selects the mini-
mum proof number from its successors; while in the AND-Node, it
selects the minimum disproof number.
This kind of search skill focuses on the node with fewer
branches, which helps ensuring effectiveness and speed. The selec-
tion of the most-proving node R in Fig. 3 is given by the bold path.
3. Bitboard knowledge base design
Many researches use bits to encode the board states and the
related bitwise operations to model the real problems [12,19,28,
35,36]. This paper uses the bitboard concept to design a knowledge
base for Connect-k games. In Connect-k games, connection infor-
mation of cells is rather important. This property is different to
Chess, Shogi and other games [9,10,23].
Connection is an important property for Connect-k games. The
deﬁnition of connection was mentioned in [35,36]. The same idea
of the two papers is using a data structure to record the connection
information of each line of a game position. Then, these connec-
tions were stored in a knowledge base in advance. Xu’s paper
[35] deﬁned the connection mathematically and focused on
decreasing the space complexity of the knowledge base of Con-
nect-k games with n  n board. Xu’s paper [35] also studied on a
precise classiﬁcation criterion for connection and a precise classiﬁ-
cation for the cells.
This paper follows the results of our previous work [36]. We de-
ﬁne the data structures of the Line, Connection, and shape. Then,
the shape information table and Connection set table are designed
for the knowledge base. Compared to Xu’s paper [35], our paper
B
L M
C
A
D G H
O Q R
E
Level 0
Offensive side to play
I J K
N P
F
S
AND-Node
OR-Node
Level 1
Defensive side to play
Level 2
Offensive side to play
Level 3
Defensive side to play
Fig. 1. An AND/OR search tree. The rectangle represents an OR-Node (Offensive
side), and the circle represents an AND-Node (Defensive side).
  
Fig. 2. The double-threat pattern and its blocking stones. (A), (B), and (C) refer to
the normal defense, while (D) refers to the conservative defense.
Table 1
Rules which PNS uses to select the most-proving node.
Rules for AND-node Rules for OR-node
pnðnÞ ¼ P
s2successor ðnÞ
pnðsÞ pnðnÞ ¼ min
s2successor ðnÞ
fpnðsÞg
dnðnÞ ¼ min
s2successor ðnÞ
fdnðsÞg dnðnÞ ¼ P
s2successor ðnÞ
dnðsÞ
44 S.-J. Yen et al. / Knowledge-Based Systems 34 (2012) 43–54
3
Author's personal copy
each other. This mistake can be ﬁxed by comparing the length of
the two shapes. Thus, when a shape is encoded, the length of the
shape (shape length) is also recorded.
3.2. Design of the bitboard knowledge base
The goal of Connect-k games is to form a Connection with a con-
secutive k stones. Most of the searching methods used in Connect6
program is threat-based search, such as TSS [30,31] and Relevance-
Zone-Oriented Proof (RZOP) search [32]. In those searching meth-
ods, shape information is very important because it can speed up
the understanding of threats on the board, and offers possible
moves for threat based search. Shape information is developed
base on pattern. Pattern is a special kind of shape. If a shape has
a special meaning, it is called pattern. For the meaning and devel-
opment of pattern, please refer to [30,31,35].
Connection set table and shape information table are the two
main important components of the bitboard knowledge base.
When playing a game, the program analyzes the game position
and stores the information of all Connections of a game position
in the Connection set table. The evaluation value of an empty cell
is calculated by the information of its Connections. An empty cell
may fall into different Connections; the cell gets different score
with respect to different Connection from the shape information
table. We sum up these scores as the cell’s ﬁnal evaluation value.
3.2.1. The shape information table
This paper encodes each shape of all possible Connections in
Connect6 and calculates its inherent information in advance. This
information is put into the shape information table. Any Connec-
tion’s shape information can be retrieved from the table in con-
stant time.
The number of all possible shapes with length n is 2n. This paper
starts the encoding from the shortest shape with length k for Con-
nect-k games, and the range of the values in the encoding is from 0
to 2k  1. In the shape information table, the encoding shape index
is from the shortest shape to the longest shape. In Connect-k
games, the shape index is calculated by the following formula:
Uðn; cÞ ¼ 2n  2k þ c
where n is the length of the shape, c is the shape code. For example,
if the length of a Connection is 10, and the shape code is 128, the
shape index will be 1088 in Connect6. Fig. 7 shows that the struc-
ture of the shape information table. There are two ﬁelds in the
information table: number of threats and type. In Connect6, the
length of the table is 220  26  1.
3.2.2. Connection set table
A Connection set is a set of all Connections in a speciﬁc Line. For
a game board, each useful Line is assigned a serial number as Line
index. The Line index is given as the formula in Table 2. Starting
from 0 and based on the order of the four direction: vertical, slash
west, horizontal and slash east. The Line index is the index of the
Connection set table. Given the board coordinate of a cell, the cor-
responding four Connection sets can be found in the Connection
set table. The formulas are shown in Table 2. Fig. 8 illustrates the
concept of addressing method from the board coordinate of cells
to the index of related Connection set.
4. Bitwise operation algorithms on the bitboard information
Most programming languages offer bitwise operators. Bitwise
operators are very efﬁcient. Based on the proposed bitboard
(A)
(B)
Fig. 6. The shape code of the shape in the Connection.
2
1
3
0
26-1
0
0
0
0
Shape
index
Fields
#threats
Dead 1
Dead 1
Dead 2
Empty
type
...
...
220-26-1 Connected
... ...
Fig. 7. The structure of the shape information table.
Table 2
The Line index and mapping functions of a cell.
Direction length Line index Line index of cell (x, y)
Vertical m From 0 to m  1 x
Slash west m + n  2k + 1 From m to 2m + n  2k m + n + x  y  k
Horizontal n From 2m + n  2k + 1 to
2(m + n  k)
2m + n  2k + y + 1
Slash east m + n  2k + 1 From 2(m + n  k) + 1 to
3m + 3n  4k + 1
2(m + n  k) + x + y + 1
Fig. 8. Illustration of the Connection set table and the Line index.
46 S.-J. Yen et al. / Knowledge-Based Systems 34 (2012) 43–54
5
Author's personal copy
sum of stones checked in a sliding window. The number of jumping
equals to the number of stones to form a threat window minus the
sum of stones in a sliding window and minus one. Take Fig. 12B as
an example. In the round one of sliding window checking pro-
cesses, the starting point is the ﬁrst cell as in Fig. 12B. In the ﬁrst
sliding window, there is only one stone; therefore, the second
checking point is the fourth cell. The reason is that it is impossible
to meet a threat window inside two rounds of checking. Therefore,
rounds two and three are omitted in Fig. 12A.
Secondly, if the inspection meets a threat window, we go onto
check behind the farthest empty cell inside the Threat Window.
In Fig. 12B, the inspection in round three meets the threat window,
so the next checking point is that of the round four as in this ﬁgure.
In Wu’s algorithm, when sliding window becomes threat window,
it marks all the empty squares in the window. It means that it does
not jump over the threat window.
5. Generating threat move
As mentioned in [30–32], threats are the key to play Connect6
as well as Connect-k games. For a game position with n Connec-
tions, the time complexity of traditional method for generating
threat moves is O(n2). This section introduces two efﬁcient algo-
rithms for generating two kinds of threat moves, respectively.
The time complexities of the two algorithms are O(n), which is bet-
ter than the traditional method.
5.1. Connection diversity
Connections are divided into three types as follows:
 Threat-Connection: If Attacker can generate k consecutive
stones by placing one or two stones on a Connection, this Con-
nection is a threat Connection. If Defender can block the threat
by a single stone, the Connection is a single-threat Connection.
A single-threat Connection has a threat. Meanwhile, a double-
threat Connection has two threats and can only be defended
by two Defender’s stones.
 Attack-Connection: The Connection itself has no threat, but
Attacker can generate the Threat-Connection on it by one or
two stones. The Attack-Connection provides the basis of TSS.
In TSS, if a threat move can generate another Attack-
Connection, TSS can perform a deeper search on the new
Attack-Connection.
 Indirect-Attack-Connection: The Connection is neither a Threat-
Connection nor a Attack-Connection. If one stone is enough to
make threats in TSS, the Indirect-Attack-Connection can be pro-
moted to the Attack-Connection by another stone. Then TSS can
generate more threat moves.
The general threat move generating method is to check the pat-
terns of the Attack-Connections in a game position. For example,
given a1live-2 Attack-Connection, Attacker can generate a live-4
Threat-Connection. When search all the threat moves on the board,
if multiple Attack-Connections exist, it is necessary to consider
whether an intersection cell exist between Attack-Connections or
not. In Fig. 13, if Attacker places a stone on the intersection cell,
the two dead-3 Connections will transform to two dead-4 Attack-
Connections, respectively.
Checking whether an intersection cell exists between Connec-
tions associated with a position is a complex problem. It is neces-
sary to examine whether an intersection exists between each pair
of Attack-Connections. Suppose the number of Attack-Connections
is n, the time complexity of the examination is O(n2).
5.2. Threat-cell and threat-pair
This subsection provides the deﬁnitions of Threat-Cell and the
Threat-Pair. Threat-Cell and Threat-Pair are the main concepts for
generating threat moves in this section.
Deﬁnition 1. In a game position, if threats can be generated after
playing a stone on an empty cell, this cell is labeled Threat-Cell. If a
Threat-Cell can form one threat, that cell is labeled T1-Cell. If a
Threat-Cell can form two threats, the cell is labeled T2-Cell. Tn-Cell
set is the set of Tn-Cell.
Deﬁnition 2. In a game position, if two empty cells can generate a
threat, the cell pair is labeled Threat-Pair. If the Threat-Pair can
generate one threat, the pair is labeled T1-Pair. If the number of
threats formed by a Threat-Pair equals two, the Threat-Pair is
labeled the T2-Pair. Tn-Pair set is the set of Tn-Pairs.
Table 3 lists transitions of different Attack-Connection patterns.
The table lists the changes in patterns after playing one or two
stones, and related Threat-Cell and Threat-Pair.
In TSS, Attacker should generate one or two threats so Attacker
can continue TSS. When generates the threat moves, Attacker
should also consider Defender’s threat. If Defender has no threat,
(A)
(B)
Fig. 12. The concept for counting the number of threats in a shape.
Fig. 13. Intersection cell of two Connections. White can use a single stone to make
two threats according to the two dead-3 Connections.
Table 3
Patterns, Threat-Cells, and Threat-Pairs.
Pattern The pattern after
adding one stone
Set of used
Threat-Cell
The pattern after
adding two stones
Set of used
Threat-Pair
Live-3 Live-4 T2-Cell set Live-5 T2-Pair set
Dead-4 T1-Cell set Dead-5 T1-Pair set
Dead-3 Dead-4 T1-Cell set Live-5 T2-Pair set
Dead-5 T1-Pair set
Live-2 Live-4 T2-Pair set
Dead-4 T1-Pair set
Lead-2 Dead-4 T1-Pair set
1 Live-2 is a Connect6 pattern, and so as live-n and dead-n, where n is between 1
and 5 [30].
48 S.-J. Yen et al. / Knowledge-Based Systems 34 (2012) 43–54
7
Author's personal copy
Proof. For two T1-Pair sets, since each of the T1-Pair set is
formed by a single Attack-Connection, a T1-Pair set generated
by Attack-Connection must be located on the same straight line
as the Connection deﬁnition. A maximum of one intersection
can exist for two lines on the board. Thus, giving two T1-Pairs,
the Connections forming these T1-Pairs must be the same Con-
nection, contradicting the deﬁnition of Connection. Conversely,
the intersection Pair differs between the T2-Pair and T1-Pair
sets. h
5.4. Generating the threat move using a single stones
In a game position, if Attacker should use a single stone to block
the threat of Defender, only one stone is available to generate the
threat move. Attacker generates double-threat and single-threat
moves based on every blocking cell. The algorithm is as follows.
The analysis of this algorithm is similar to the algorithm in Section
5.3. The time complexity is also O(n).
5.4.1. Algorithm for generating the threat move using a single stone
Step 1: Use the following steps to deal with every blocking cell in
order.
Step 2: Examine the new position after playing a stone on the
blocking cell. Search all the Threat-Connections and
Attack-Connections of Attacker, and classify the Attack-
Connections according to the Pattern.
(a) Calculate the sum of the threats generated by the
blocking cell based on the Threat-Connection.
(b) If the blocking cell generates more than two threats, it
is termed a winning cell, and makes a winning move
to end the search.
Step 3: Generate the T2-Cell set for every live-3, and generate the
T1-Cell set for every dead-3.
(a) If the generated T2-Cell set intersects with the previ-
ous one, this intersection must indicate a winning cell,
forming a winning move together with the blocking
cell to end search.
(b) When generating the T1-Cell set, if an intersection
exists with the previous T1-Cell set, this cell is a T2-
Cell, and thus is included in the T2-Cell set. If this
T2-Cell intersects with the T2-Cell set, it must be a
winning cell, and thus forms a winning move together
with the blocking cell to end the search.
Step 4: If a blocking cell generates two threats according to Step 2,
the situation is dealt with as follows:
(a) If the T2-Cell or T1-Cell sets is not empty, a winning
move is performed together with the blocking cell to
end the search.
(b) Otherwise generate double-threat moves sequentially
for the Connections live-2, live-1, dead-2 and dead-1.
Step 5: If a blocking cell generates one threat according to Step 2,
the situation is dealt with as follows:
(a) If T2-Cell set is not an empty set, a winning move is
formed together with the blocking cell to end the
search.
(b) If T1-Cell set is not an empty set, a single-threat move
is formed together with the blocking cell.
(c) Check if the Threat-Connection can play another stone
to form a double-threat move, as the two special dead-
4 in Fig. 14.
Step 6: If the blocking cell generates no threat according to Steps
2, this algorithm generates corresponding threat moves
based on the T2-Cell set and T1-Cell set formed in Step 3.
(a) Check if an intersection cell exists between the T2-Cell
set and the T1-Cell set generated from different Con-
nections. If such a cell exists, this cell is a winning cell,
which forms a winning move together with the block-
ing cell and thus ends the search.
(b) Make the blocking cell and T2-Cell set form double-
threat moves.
(c) Make the blocking cell and T1-Cell set form single-
threat moves.
(d) Check if the Threat-Connection can play another stone
to form a double-threat move.
6. Multistage Search and PNS implementation
Multistage Search is based on the concept that, at any game po-
sition, different candidate moves can be developed in different
stages according to their importance, respectively. This design is
mainly used for sudden-death games. For Connect-k games, the
priority of candidate move depends on number of threats by the
move. Monte-Carlo Tree Search (MCTS) is a best-ﬁrst search, which
uses stochastic simulations[1,6–8,15,25]. It has advanced the
development of computer Go substantially [6,16,40]. The 2-Stage
MCTS for Connect6 was proposed in [38]. This paper proposes
Multistage PNS. The two searching methods are compared in
Section 7.
PNS was proposed by Allis et al. [2,4]. PNS was successfully used
to prove or solve of game positions for many games
[2–5,14,22,26,27,29]. Many variations of PNS were proposed, such
as DF-PN, PDS, PN⁄, PN2, and parallel PNS [5,11,13,21,22,24,27,29,
34]. This paper provides the Multistage PNS search for Connect6.
In practice, the proposed Multistage PNS may be combined with
some of the variations to improve the efﬁciency.
6.1. Search architecture
Three kinds of moves exist in Connect6: double-threat, single-
threat and non-threat moves. Thus, Multistage Search is divided
into four strategies with respect to the combinations of the three
kinds of candidate moves, as listed in Table 4.
Fig. 15 shows the architecture of Multistage PNS. Candidate
moves of each node are generated via stages. The timing of the
generation of different candidate moves are based on the stage
Fig. 14. One stone can transform the dead-4 into a live-5.
Table 4
The kinds of moves in different Multistage Searches.
Strategy Stage
First stage Second stage Third stage
1-Stage Double-threat
Single-threat
Non-threat
Type-I 2-stage Double-threat Single-threat
Non-threat
Type-II 2-stage Double-threat Non-threat
Single-threat
3-Stage Double-threat Single-threat Non-threat
50 S.-J. Yen et al. / Knowledge-Based Systems 34 (2012) 43–54
9
Author's personal copy
efﬁciency is about 10 times. Therefore, bitboard knowledge base
signiﬁcantly improves the search efﬁciency.
7.2. Multistage PNS experimental results
The accuracy and efﬁciency of the Multistage PNS are analyzed
in this section. Since Multistage PNS is a best-ﬁrst search, it re-
quires of maintaining the whole search tree in memory. Thus,
many variations were proposed to avoid this problem [5,21,
22,34]. In this paper, the total memory space of the Multistage
PNS tree is restricted to 60,000 nodes. This number is enough to
solve most puzzles in the experiments. The limit time for each side
in a game is 30 min in most tournaments. The restricted number is
also enough to let Kavalan ﬁnish each game in those tournaments.
The 55 test puzzles contains T2 solution and TSS solution puz-
zles. Five algorithms are implemented for performing the compar-
ison. The ﬁrst and second algorithms are brute-force algorithms:
depth-ﬁrst search (DFS) and breadth-ﬁrst search (BFS). Basic DFS
has no depth limit, but the outcome is bad for these puzzles with
T2 and TSS solutions. Therefore, this paper tests the results of lim-
iting the search depth of DFS to 14. Besides, the search of DFS and
BFS is limited to threat moves, and excludes other candidate moves
(non-threat moves). The third algorithm is Standard PNS. It gener-
ates candidate moves by using heuristic knowledge to order empty
cells and uses them to generate moves. The fourth algorithm is
type-I 2-stage PNS, and generates double and single-threat moves
in stages. Finally, the ﬁfth algorithm is type-II 2-stage PNS, and
does not especially distinguish the threat moves.
This paper limits the memory space of search tree developed
from the ﬁve algorithms to 60,000 nodes, the number of probing
cells to 12. The information of the ﬁve algorithms is as in Table 6.
In the experiment, the bitboard knowledge base system is
used in every algorithm. The search time and the number of
searching nodes (inside the parenthesis) of the results are listed
in Tables 7 and 8. The unit of time is second. The searching nodes
include the nodes used in CTSS for node evaluation as described
in Section 6.2.4. If the CTSS fails, the memory space of the nodes
in the CTSS will be released. Thus, the total number of searching
nodes may be larger than 60,000. The experimental results of 2-
Stage MCTS (Type-II) are from [38] except the puzzles of 2008
series.
From the experimental results, the search efﬁciency of brute-
force algorithms is low. They cannot ﬁnd the solution on most
TSS solution puzzles, especially DFS. Therefore, the brute-force
algorithms are only suitable on simple puzzles. In comparison to
the success rate of ﬁnding the solution of puzzles, standard PNS
is worse than 2-stage PNS. Thus, standard PNS is not suitable for
sudden-death game.
For the three 2-stage algorithms, Type-II 2-stage MCTS is gener-
ally better in Table 7. However, the difference is not signiﬁcant be-
cause the state space of the T2 solution is small.
Table 5
The efﬁciency of the knowledge base system.
Type-II Multistage PNS
Total time
(24 puzzles of 2008 series)
Use the system 474.367 (s)
Does not use the system 4512.006 (s)
Table 7
The result for the puzzles with T2 solution.
Puzzles Algorithms
DFS with depth limit to 14 BFS Standard PNS Type-I 2-stage PNS Type-II 2-stage PNS Type-II 2-stage MCTS [34]
2007-Q4-2-5 3.859 (51,458) 6.218 (65,959) X 0.015 (238) 0.015 (238) 0.062 (238)
2007-Q4-2-6 0.031(638) 0.015 (517) 0.031 (197) 0.062 (1061) 0.062(1061) 0.062(1061)
2007-Q4-3-1 X 0.296 (4312) 0.001 (221) 0.001 (61) 0.001 (61) 0.001 (61)
2007-Q4-3-4 X 0.687 (9058) 0.015 (500) 0.015 (517) 0.015 (517) 0.031 (517)
2007-Q4-3-5 X 6.000 (60,901) 0.015 (154) 0.001 (131) 0.001 (131) 0.001 (131)
2007-Q4-3-6 0.156 (2480) 0.001 (104) 0.001 (23) 0.001 (22) 0.001 (22) 0.015 (22)
2007-Q4-4-4 0.015 (134) 0.001 (224) 0.001 (119) 0.001 (43) 0.001 (43) 0.001 (43)
2007-Q4-4-6 X 8.046 (70,102) X 0.171 (3024) 0.421 (3681) 1.046 (4911)
2007-Q4-5-1 0.046 (892) 0.001 (72) 18.156 (147,298) 0.001 (144) 0.031 (144) 0.015 (144)
2007-Q4-5-2 X 0.001 (238) 0.001 (58) 0.001 (31) 0.001 (31) 0.015 (31)
2007-Q4-5-3 0.015 (334) 0.078 (982) 0.001 (42) 0.001 (38) 0.001 (38) 0.015 (38)
2007-Q4-5-4 0.001 (56) 0.001 (247) 0.001 (55) 0.001 (30) 0.001 (30) 0.001 (30)
2008-Q1-1-1 0.219 (4785) 0.016 (202) 0.001 (78) 0.016 (84) 0.001 (84) 0.001 (84)
2008-Q1-1-2 0.391 (8062) 11.469 (70,263) X 0.031 (554) 0.031 (554) 0.031 (554)
2008-Q1-2-1 0.984 (23,071) 0.078 (884) 0.001 (97) 0.001 (89) 0.001 (89) 0.001 (89)
2008-Q1-2-2 2.906 (70,184) 0.953 (10,003) 0.094 (1311) 2.921 (4475) 0.265 (4475) 0.406 (4475)
2008-Q1-3-1 4.281 (103,946) 0.078 (705) 0.031 (610) 0.047 (563) 0.047 (563) 0.031 (563)
2008-Q1-3-2 5.250 (120,907) 0.031 (581) 12.890 (105,130) 0.001 (27) 0.016 (27) 0.001 (27)
2008-Q2-1-1 1.203 (26,558) 1.672 (15,734) X 0.359 (54) 0.438 (54) 0.001 (54)
2008-Q2-1-2 1.719 (43,917) 3.062 (15,661) 0.453 (67) 0.172 (50) 0.188 (50) 0.001 (50)
2008-Q2-2-1 0.046 (914) 0.047 (487) 0.313 (48) 0.219 (56) 0.266 (56) 0.016 (56)
2008-Q2-2-2 0.609 (13,320) 0.250 (2263) 0.219 (46) 0.188 (29) 0.172 (29) 0.001 (29)
2008-Q3-1-1 9.813 (233,264) 0.016 (168) 6.156 (1610) 0.234 (1200) 0.359 (1200) 0.031 (208)
2008-Q3-1-2 0.001 (26) 0.031 (202) 0.234 (54) 0.172 (18) 0.172 (18) 0.001 (18)
Table 6
The search strategy of different algorithms.
Algorithm Search strategy
DFS  DFS with depth limit to 14.
 When DFS searches T2 solution, it focuses the candidate
moves on double-threat moves.
 When DFS searches TSS solution, it generates double and
single-threat moves at the same time.
BFS  When BFS searches T2 solution, it focuses the candidate
moves on double-threat moves.
 When BFS searches TSS solution, it generates double and
single-threat moves at the same time.
Standard PNS  Using empty cell score to generate candidate moves
 If the proof number of an OR-Node is bigger than 66, it
adds new candidate moves.
Type-I 2-
stage PNS
 Generating single-threat moves after double-threat
moves search fail.
Type-II 2-
stage PNS
 Generating double-threat and single-threat moves at the
same time.
52 S.-J. Yen et al. / Knowledge-Based Systems 34 (2012) 43–54
11
Author's personal copy
[14] A. Kishimoto, M. Müller, Search versus knowledge for solving life and death
problems in Go, in: Twentieth National Conference on Artiﬁcial Intelligence
(AAAI-05), 2005, pp. 1374–1379.
[15] L. Kocsis, C. Szepesvári, Bandit based Monte-Carlo planning, in: J. Fürnkranz, T.
Scheffer, and M. Spiliopoulou, (Eds.), Proceedings of the 17th European
Conference on Machine Learning (ECML), 2006, pp. 282–293.
[16] C.-S. Lee, A. Rimmel, O. Teytaud, S.-R. Tsai, S.-J. Yen, M.-H. Wang, Current
frontiers in computer Go, IEEE Transactions on Computational Intelligence and
AI in Games 2 (4) (2010) 229–238.
[17] P.-H. Lin, I-C. Wu, NCTU6 wins in the man–machine Connect6 championship
2009, ICGA Journal 32 (4) (2009) 230–232.
[18] H.-H. Lin, D.-J. Sun, I-C. Wu, S.-J. Yen, TAAI computer game tournament report
in 2010, ICGA Journal 34 (1) (2011) 51–54.
[19] P. San Segundo, R. Galan, D. Rodriguez-Losada, F. Matia, A. Jimenez, Efﬁcient
search using bitboard models, in: Proceedings XVIII International Conference
on Conference on Tools for AI, Washington, 2006, pp. 132–138.
[20] Taiwan Connect6 Association, Connect6 homepage, <http://www.connect6.
org/>.
[21] A. Nagai, Df-pn algorithm for searching AND/OR trees and its applications, PhD
thesis, University of Tokyo, Japan, 2002.
[22] J. Pawlewicz, L. Lew, Improving depth-ﬁrst PN-search: 1+e trick, 5th
International Conference on Computers and Games, in: H.J. van den Herik, P.
Ciancarini, H.H.L.M. Donkers (Eds.), Lecture Notes in Computer Science (LNCS
4630), Computers and Games, Springer, Heidelberg, 2007, pp. 160–170.
[23] F. Reul, New architectures in computer chess, Ph.D. thesis, Tilburg University,
Tilburg, The Netherlands, 1990.
[24] J.T. Saito, M.H.M. Winands, H.J. van den Herik, Randomized parallel proof-
number search. Advances in computer games conference (ACG’12), in: H. Jaap
van den Herik, Pieter Spronck, (Eds.), Lecture Notes in Computer Science (LNCS
6048), Palacio del Condestable, Pamplona, Spain, 2010, pp. 75–87.
[25] M.P.D. Schadd, M.H.M. Winands, M.J.W. Tak, J.W.H.M. Uiterwijk, Single-player
Monte-Carlo tree search for SameGame, Knowledge-Based Systems (2011),
http://dx.doi.org/10.1016/j.knosys.2011.08.008.
[26] J. Schaeffer, N. Burch, Y.N. Björnsson, A. Kishimoto, M. Müller, R. Lake, P. Lu, S.
Sutphen, Checkers is solved, Science 5844 (317) (2007) 1518–1552.
[27] M. Seo, H. Iida, J.W.H.M. Uiterwijk, The PN*-search algorithm: application to
tsumeshogi, Artiﬁcial Intelligence 129 (1-2) (2001) 253–277.
[28] S. Tannous, Avoiding rotated bitboards with direct lookup, ICGA Journal 30 (2)
(2007) 85–91.
[29] M.H.M. Winands, J.W.H.M. Uiterwijk, H.J. van den Herik, PDS-PN: a new proof-
number search algorithm: application to Lines of action. Computers and
Games 2002, in: J. Schaeffer, M. Müller and Y. Björnsson (Eds.), Lecture Notes
in Computer Science (LNCS 2883), Computers and Games, Springer,
Heidelberg, 2003, pp. 61–74.
[30] I-C. Wu, D.-Y. Huang, H.-C. Chang, Connect6, ICGA Journal 28 (4) (2005) 235–
242.
[31] I-C. Wu, D.-Y. Huang, A new family of k-in-a-row games, the 11th Advances in
Computer Games Conference (ACG 2005), in: H. Jaap van den Herik, Shun-Chin
Hsu, Tsan-sheng Hsu, H.H.L.M. Donkers (Eds.), Proceedings of the 11th
Computers and Games, Lecture Notes in Computer Science (LNCS 4250),
2006, pp. 180–194.
[32] I-C. Wu, P.-H. Lin, Relevance-zone-oriented proof search for Connect6, IEEE
Transactions on Computational Intelligence and AI in Games 2 (3) (2010) 191–
207.
[33] I-C. Wu, P.-H. Lin, S.-J. Yen, Morethanﬁve wins Connect6 tournament, ICGA
Journal 33 (3) (2010) 179–180.
[34] I-C. Wu, H.-H. Lin, P.-H. Lin, D.-J. Sun, Y.-C. Chan, B.-T. Chen, Job-level proof
number search for Connect6, in: J. van den Herik, H. Iida, A. Plaat (Eds.),
Proceeding of the Computers and Games 2010, Lecture Notes in Computer
Science (LNCS 6515), 2011, pp. 11–22.
[35] C.-M. Xu, Z.-M. Ma, X.-H. Xu, A method to construct knowledge table-base in k-
in-a-row games, in: Proceedings of the 2009 ACM Symposium on Applied
Computing, 2009, pp. 929–933.
[36] S.-J. Yen, J.-K. Yang, The bitboard design and bitwise computing in Connect6,
in: Proceedings of the 14th Game Programming Workshop, 2009, pp. 95–98.
[37] S.-J. Yen, T.-C. Su, I-C. Wu, The TCGA 2011 computer-games tournament, ICGA
Journal 34 (2) (2011) 108–110.
[38] S.-J. Yen, J.-K. Yang, Two-stage Monte Carlo tree search for Connect6, IEEE
Transactions on Computational Intelligence and AI in Games 3 (2) (2011) 100–
118.
[39] S.-J. Yen, T.-C. Su, I-C. Wu, The TCGA 2011 computer-games tournament, ICGA
Journal 34 (2) (2011) 108–110.
[40] S.-J. Yen, C.-W. Chou, C.-S. Lee, H. Doghmen, O. Teytaud, The IEEE SSCI 2011
human vs. computer-Go competition, ICGA Journal 34 (2) (2011) 106–107.
54 S.-J. Yen et al. / Knowledge-Based Systems 34 (2012) 43–54
13
60 ICGA Journal January 2012 
 BLA ZEN AYA COLD GOE Score Rank 
BLAST - 1-0 1-0 1-0 1-0 4 1 
ZEN 0-1 - 1-0 1-0 1-0 3 2 
AYA 0-1 0-1 - 1-0 1-0 2 3 
COLDMILK 0-1 0-1 0-1 - 1-0 1 4 
GOEMON 0-1 0-1 0-1 0-1 - 0 5 
Table 3: The cross-table of the 13x13 tournament. 
In the 13x13 tournament, each side has thirty minutes to play. Each program only played one game in each 
round. The process of the 13x13 tournament was tortuous, and the result was beyond everybody’s 
expectations. BLAST beat ZEN by a time-out because of a time-counting bug. Then, it beat COLDMILK and 
AYA continuously and won the gold medal by winning all of the games. ZEN won three of the four games 
and ranked the 2nd place. AYA ranked the 3rd place. Finally, BLAST wrote down the biggest surprise in this 
year's competitions - even with some good luck. Table 3 shows the detail. 
 
Selected Games 
 
 
  
Figure 1: COLDMILK(White) vs. AYA(Black), W+R. 
 
Figure 2: ZEN(Black) vs. BLAST(White), W+Time out. 
 
Game 1: COLDMILK vs. AYA W+R 
Black gets an advantage situation until move 25. If the game normally carries on, White will lose. Thus, 
White plays move 26 actively to enter the Black’s territory. Black makes a mistake in move 27, this move 
should be played at E8. After White plays move 28, Black cannot connect, or else White will make an eye 
and kill Black’s group in the upper left corner. Until the move 37, White reduced the Black’s territory by 
sente. When white occupies B2, Back has no chance to win. 
 
Game 2: BLAST vs. ZEN W+Time out 
Before black’s time out, Black actually leads around 30 points because Black captures White’s group in the 
upper left corner. However, Black makes a time-counting bug and lose the game. 
 
 
15
YEN AND YANG: TWO-STAGE MONTE CARLO TREE SEARCH FOR CONNECT6 101
Fig. 1. AND/OR search tree. Rectangles represent an OR-Node, and circles
represent an AND-Node.
1) an introduction to threat space search (TSS) was used in
k-in-a-row games and related subjects;
2) develop a search structure that allows MCTS to be used to
play Connect6;
3) discuss the heuristic knowledge that can be used to im-
prove MCTS according to the features of Connect6;
4) analyze the accuracy and performance of the new structure
developed by this paper for MCTS in Connect6.
The remainder of this paper is organized as follows. Section II
discusses the TSS, which is a sudden-death feature incorporated
into k-in-a-row games. Section III then proposed an algorithm
for double-threat TSS (like VCDT as mentioned in [26]) in Con-
nect6, which is termed the iterative threat space search. Subse-
quently, Section IV introduces MCTS implementation to Con-
nect6. This section provides a new structure for MCTS, called
two-stage MCTS. Section V introduces a heuristic knowledge
that can be used in Connect6. Section VI then explains the ex-
perimental method and results. Finally, Section VII presents
conclusions.
II. BACKGROUND AND RELATED WORK
A. Search in Connect6
1) AND/OR Tree: AND/OR trees can be used to describe
problems involving Connect6. In Connect6 search, the player
who is the search target is the offensive side, and the opposing
player is the defensive side. The search begins on the offensive
side, which represents the initial search position, and ends when
one side wins or a draw occurs.
Fig. 1 is an AND/OR search tree of Connect6. The root node
is the position after the defensive side move, and is the initial
searching position, which is termed level 0 (or root node) of
the search tree. Based on the position of level 0, level 1 shows
the moves of the offensive side, like nodes B or C, and level
1 of the search tree. Similarly, level 2 shows the moves of the
defensive side based on the move of the offensive side in level
1. The search tree is formed in this manner.
The position after the move of the defensive side is an
OR-Node. Among the children of this OR-Node, whenever
a node is identified that demonstrates a win for the offensive
side, it is proved that the offensive side achieves this victory
under this OR-Node, like nodes B or C in the figure. Whenever
a node (B or C) is proved victorious, the offensive side wins
under the position of node A.
The position after the move of the offensive side is an AND-
Node. For the offensive side, regardless of the defensive efforts
of the defensive side, the offensive side must win because only
then can it be seen as a winner. For example, nodes D and E
in Fig. 1 are defensive moves of the defensive side under the
position of node B. we have to prove that, whether in node D or
E, the position where the offensive side wins can be searched.
Victory for the offensive side can then be shifted to node B.
2) Candidate Moves: Forming candidate moves of Connect6
is a very difficult decision because, except for the first move,
every move involves two stones. For a given position, the only
candidate moves are those involving various combinations of
empty cells. Thus, the amount of candidate moves at every level
is very large, which will exert a strong contradictory influence
on searching.
Moves that comply with the game rules are called legal
moves. Legal moves are the basic requirements that generate
candidate moves in a game searching. However, when forming
moves, moves formed by considering winning or losing condi-
tions are termed rational moves.
Taking Connect6 for example, if there is any threat from one
side, the other sidemust make blockingmoves, or lose the game.
Moves made under these conditions are called rational moves.
It is easier to make legal moves with the knowledge of which
cells on the board are empty. Rationalmoves are those generated
based on consideration of threats in Connect6. The candidate
moves presented in this paper must be based on the considera-
tion of threats on some position, and thus correspond with the
requirement that moves be rational.
B. Threat Space Search
TSS is the most common search method in Connect- games
[1], [2], [9], [17], [23]. TSS controls the candidate moves by
using the situation in which Defender2 must block the threats
that occur after the move of Attacker.
According to the definition of the threats used by Wu [20]
“one player, sayW, cannot connect six. B is said to have t threats,
if and only if W needs to place t stones to prevent B from winning
in the next move of B.” This paper assumes that when one of
the players makes a threat, their opponent will make a blocking
move.
Therefore, the TSS features require Attacker to make a threat
whenever it makes a move. For Connect6, the threat can be
single or double, and this paper calls the move that can make
one or two threats, Threat-Move. According to this concept, At-
tacker must select one among numerous candidate moves to ful-
fill this need, and this paper calls this kind of search TSS (like
VCST as mentioned in [26]).
Attacker can belong to the offensive or defensive sides of
the search tree. Thus, the TSS begins when one player makes
threats, with that player being called Attacker. TSS aims to gen-
erate the number of threats that are bigger than the number of
legal stones to play and Defender cannot block, resulting in a
2TSS search can be used in the offensive or defensive sides of the game tree
search. To distinguish the offensive and defensive sides of the TSS-subtree and
whole search tree, this paper labels the offensive side Attacker and the other
side Defender in TSS. 17
YEN AND YANG: TWO-STAGE MONTE CARLO TREE SEARCH FOR CONNECT6 103
Fig. 6. Defender’s threat caused by conservative defense (numbers in the figure represent the cells in each searching level). (A) The initial position of searching.
(B) The double-threat move of Attacker and the blocking moves of Defender. (C) The position when black stones are played on the cells numbered 2 in CTSS.
(D) The position of searching end in CTSS, the white wins.
Attacker and Defender nodes can be combined in Attacker node,
like the nodes in the ellipses of Fig. 4.
Because the depth of the search tree is reduced to half of the
height, the search states can decrease significantly, increasing
the search speed. Consequently, this paper obtains the following
property.
4) Property 2: In the AND/OR tree for the two-player game,
Attacker and Defender nodes are combined into an OR-Node if
Attacker has just one child. Therefore, the height of the search
tree is halved, and the AND/OR tree is transformed into an OR
tree.
Using conservative defense to decrease the branching factors
and the depth of the search tree accelerates the search speed.
However, this approach is excessively defensive and ignores
lots of the state space when searching.
This approach can be considered favorable for searching by
Defender: in each defense, the number of Defender stones in-
creases faster than the number of Attacker stones. Take the Live
4 Connection for example; Defender can increase by a max-
imum of four stones at a time, which naturally puts Attacker at
a disadvantage, and impedes the finding of a solution.
In double-threat TSS, if Attacker finds the T2 solution based
on the conservative defense of Defender, the solution that is
found by using CTSS in a position is said to have a CTSS solu-
tion. Thus, the following property is obtained.
5) Property 3: When playing the CTSS in a Connect6 posi-
tion, a CTSS solution that can be obtained under a position is
definitely the correct answer; otherwise, no CTSS solution ex-
ists for the position.
Anyhow, CTSS has the advantage of rapid search speed and
the disadvantage of higher error rate. CTSS thus is a high-risk
search method.
C. Search Goal
Considering the above discussion and the characteristics of
Connect6, the search goals in this game are summarized below.
1) If the game-theoretic value [9] of the initial position has
been determined, that value must be identified. The game-
theoretic value of Connect6 is the TSS solution. The
of the node in the AND/OR tree is as follows:
.
2) If no TSS solution exists in the initial position, the most
promising move is obtained from the first level.
Achieving these objectives requires considering numerous is-
sues. First, this paper discusses the Iterative TSS of Connect6.
III. THE ITERATIVE THREAT SPACE SEARCH
This section proposes a new search structure for double-threat
TSS, termed as the iterative threat space search (iterative TSS
or ITSS).
A. Disjoint Relation
Like the discussion on double-threat TSS, the existence of
two threats after Attacker plays a move requires Defender to
make different defensive moves. Fig. 5 shows that when white
faces two threats, white can respond with the following three19
YEN AND YANG: TWO-STAGE MONTE CARLO TREE SEARCH FOR CONNECT6 105
Fig. 8. Example of ITSS finding the double-threat solution.
Fig. 9. Structure of the search tree for the ITSS solution. White makes a move
on the cells numbered 1 in Fig. 8(a).
structure of the search tree for this solution. If Attacker makes
a move on the cells numbered 1 in Fig. 8(a), the correspondent
solution is obtained.
C. The Search Architecture of ITSS
In the first iteration of searching, this paper uses CTSS to
rapidly search all the double-threat moves. In this iteration, the
search ends if any CTSS solution exists; otherwise, the search
proceeds in its next iteration.
The second iteration uses normal defense to deal with the
double-threat moves generated from the first iteration. After
performing the defensive moves, new double-threat moves are
made based on the defensive moves. Simultaneously, CTSS is
repeated on these double-threat moves. Because Defender uses
normal defense in the second iteration, the problem of disjoint
relation of moves, which occurs in the conservative defense of
Defender, is excluded from the search result of the double-threat
moves in the first iteration.
Fig. 10 illustrates the search architecture of ITSS. Node A is
the initial position of the board. First, ITSS performs CTSS on
the double-threat moves, nodes B, C, and D. If one node can ob-
tain a solution using CTSS, the CTSS-subtree can be preserved
and the search process can be completed in that iteration. Other-
wise, the branch built by CTSS is deleted. Because no possible
Defender moves exist in the conservative defense, the branch
built by CTSS is deleted.
This approach canmaintain the efficiency of CTSS. As for the
position where the double-threat solution can be obtained using
CTSS, benefits still exist for quickly obtaining the solution, such
as those shown in the first half of Fig. 10.
When the solution for nodes, B, C, and D cannot be obtained
in the first iteration, ITSS forms normal defense moves, such
as nodes E, F, G, H, I, J, K, and L, based on the double-threat
moves of B, C, and D in the second iteration, and continues
making double-threat moves of Attacker based on every defen-
sive move. Currently, ITSS can use the same approach as in the
first iteration, performing CTSS on these double-threat moves,
like nodes, M, N, O, P, Q, and R in Fig. 10. 21
YEN AND YANG: TWO-STAGE MONTE CARLO TREE SEARCH FOR CONNECT6 107
TABLE I
THE TYPES OF Two-STAGE MCTS
tion, expansion, play random game (or playout), and back-prop-
agation. The four steps are repeated according to the settled
times until the search time is used up. Fig. 11 shows the out-
line of MCTS, and illustrates the four simulation steps.
MCTS is a best-first search [5], [19], which uses playout to
predict candidate moves, and simultaneously builds the search
tree, from top to bottom, to improve the precision of the pre-
diction in the upper position. Hence, in the simulation of every
round, MCTS uses playout to predict the leaf node, and corrects
the ancestor 5 value from the leaf node based on the result
of the playout to improve the search quality.
1) two-Stage Search: Basic MCTS does not search in
stages, but rather takes the candidate moves as those with equal
importance, and distinguishes the significance of different
moves based on the playout results. However, since Connect6
is a sudden-death game, one side tends to immediately lose if it
neglects the threats possessed by the opponent. Therefore, this
paper divides the development of candidate moves into two
stages. The core idea of stages is that the focus is on solving the
sudden-death problem during the first stage, and on searching
for the most promising move during the second stage. This
form of MCTS is labeled two-Stage MCTS.
This paper uses an AND/OR tree to develop the search tree
to fit the situation of Connect6. As described in “Section II-C,”
for determining the game-theoretic value of the initial position,
the AND/OR tree is an appropriate means of doing this.
2) Types of Two-Stage MCTS in Connect6: Connect6 in-
volves three kinds of moves, including double-threat, single-
threat, and nonthreat moves. The use of two-stage MCTS to de-
velop candidate moves thus can be divided into two types, as
listed in Table I. The difference between the two types involves
the stage in which single-threat moves are generated.
Selection of two-stage MCTS is a strategic decision. In the
initial position, in the event of double-threat or single-threat
solutions, using different types will exert different effects on
searching efficiency. This paper employs an experimental
method to compare the two types.
If, in initial position, neither double-threat or single-threat so-
lutions exist, using two-stage search and focusing on TSS may
negatively impact the search for other candidate moves. Thus,
when playing games, it is necessary to make a suitable distribu-
tion according to usable resources.
B. The Four Strategic Steps of two-stage MCTS
As for the four steps of MCTS, this paper details the strategy
used in two-stage MCTS step-by-step form below.
1) Selection Strategy: Regarding selection strategy, this
paper uses UCT Selection because this approach is easy to
5PV is the value of back-propagation, which is the result of playout and eval-
uation for the leaf node in every simulation.
use and has performed well in numerous studies [5], [6], [11],
[13]. This approach is developed from the multiarmed bandit
problem [10], and it considers the balance between exploitation
and exploration. This approach not only selects the best node
based on the information obtained, but also selects less visited
nodes. In Formula 1, this approach chooses nodes from its
children, as follows:
where (1)
In two-stage MCTS, each node represents a given position
of a game. Let be the chosen node from the current node ,
be the child node of , and be the set of nodes that are the
children of node .
A node contains two pieces of information: and .
represents a value which is the result of playout and evaluation
for node and will be discussed in Subsection 4. denotes the
number of visits for node , and its value will be increased by
1 if it is a node in the simulation path. is the rate, and
represents a value like the win rate in MCTS, but its value may
be negative (opponent wins), and is calculated as described in
Formula 1.
Furthermore, is the exploration factor, and controls the bal-
ance between exploitation and exploration. Two-stage MCTS
uses different selection strategies for different types of candi-
date moves.
2) Type I of Two-Stage MCTS: During the first stage, to con-
sider the possible solution of double-threat moves, Type I of
two-stage MCTS equally develops double-threat moves. This
design aims to find whether T2 solution exists in a position,
and the experimental results indicate that BFS is more efficient
than DFS. This paper thus modified Formula 1. When two-stage
MCTS develops the T2-subtree of double-threat TSS, the devel-
opment of the T2-subtree resembles that of BFS. In T2-subtree,
this paper selects a node from its children using Formula 2
(2)
During the second stage, to offer more choices to the node
which is not T2 Fail6, this paper adds a value in the computation
of UCT selection, which is called Heuristic value . The
aim of the is to direct the search according to the heuristic
knowledge, and it increases the number of search times for the
T2-subtree. This approach is UCT selection enhancement, and
is a widely applied concept [5], [11].
Taking Fig. 12 as an example, when node A is T2 Fail, it
develops other candidate moves, such as nodes E and F. Eval-
uating node E involves double-threat moves for the defensive
side. Therefore, this node becomes the root of T2-subtree for
the defensive side, and thus is assigned an value.
The value is a heuristic value that increases the times of
selecting the T2-subtree. If a position has finished the first stage
search, and the T2 solution cannot be identified, the candidate
moves developed after the first stagemust search the T2 solution
6T2 Fail means the solution of double-threat TSS does not exist, and TSS Fail
means the solution of double-threat and single-threat TSS does not exist.23
YEN AND YANG: TWO-STAGE MONTE CARLO TREE SEARCH FOR CONNECT6 109
eration method is used. Whenever two-stage MCTS generates
second-stage candidate moves, it uses a fixed number of probing
cells to generate candidate moves at a time.
The number of probing cells selected is a strategic consider-
ation. If the number is too large, it will result in excessive can-
didate moves, which may decrease search depth. However, too
few probing cells may ignore certain important cells in the be-
ginning.
Besides, to prevent excessively rapid search tree develop-
ment, and avoid wasting excessive time on search tree construc-
tion, two-stage MCTS establishes a leaf node in every simula-
tion.
8) Play Random Game (Playout) Strategy: MCTS uses
playout to forecast the possible condition of leaf node. This is a
strategic consideration. When selecting moves in playout, if one
simply randomly selects moves to place stones on empty cells,
the prediction is inadequate. Therefore, the playout method of
selecting moves should be identical to the expansion strategy
of the search tree in the simulation.
The strategy used in this step is making Threat-Moves the pri-
mary consideration, since if Threat-Moves exist in a position,
the likelihood of obtaining the TSS solution is higher. There-
fore, Threat-Moves are the first choice.
This paper limits the depth of playout based on the feature of
Connect6. This strategy supposes that the probability of a draw
increases with reducing the number of cells. Furthermore, if a
CTSS solution can be obtained when evaluating a position, this
position has no need to perform playout in prediction because
the of this position is determined.
9) Back-Propagation Strategy: Back-propagation describes
the mechanism whereby after every simulation, the result of the
evaluation or playout of the leaf node is propagated back to the
ancestor of the relevant node. This mechanism affects the se-
lection in the next simulation. Because this paper not only uses
playout to predict the leaf node, but also uses CTSS to search
for double-threat moves, it includes the reporting-back of both
situations.
The first situation involves reporting-back when CTSS finds
the T2 solution. This form of reporting-back can correct the an-
cestorValue above a node, and correct it according to every node
type (AND-Node or OR-Node).
Besides, when one position is determined, that position is as-
signed a larger value of playout . According to [29], the
number this paper used is that if offensive side wins, gain
10; if defensive side wins, lose 5.
The second situation is reporting-back after playout. The way
we use that is if offensive side wins, gain 1; if it is a draw,
earn 0; if defensive side wins, lose 1.
C. The Search Architecture of two-stage MCTS
This section describes the search architecture of two-stage
MCTS. Two-stage MCTS generates candidate moves in two
stages. The division of candidate moves is a strategic decision,
and is made based on the features of the game. Regardless of
stage strategy adopted, the difference of two-stage MCTS lies
in the mechanism that generates the candidate moves and the
stage-transition condition.
Fig. 14. Search architecture of two-stage MCTS.
1) The Development of Two-Stage Search: Fig. 14 illustrates
the development of the search tree for two-stage search. When
seeking a goal from an initial position, failure to identify a goal
means this position has no such goal. Simultaneously, changing
our target to the successors of the initial position examines
whether this goal exists for the successors, and developing other
candidate moves. When new candidate moves are generated,
it is necessary to examine whether this goal exists under these
new generated nodes.
Fig. 14 shows that when the goal of node A search fails, it is
necessary to examine whether this goal exists under nodes B and
C. Furthermore, when creating nodes H and I, it is necessary to
examine whether this goal exists under nodes H and I. Taking
the two-stage MCTS of Connect6 as an example, the goal of
Type I is a T2 solution, while that of Type II is a TSS solution.
The development of two-stage search proceeds in this way.
Following this developing mode, if the goal of the offen-
sive side cannot be identified, the development of the candi-
date moves of the offensive side will consider whether the goal
exists in the defensive side in two-stage MCTS. This method
can be accelerated to understand whether the offensive side will
encounter resistance from the defensive side in the candidate
moves of offensive side for fear that the defensive side wins.
2) Stage Transition: The above illustration demonstrates
that the search tree contains the first-stage subtree (T2-subtree
for Type I; TSS-subtree for Type II, see Figs. 12 and 13).
The second-stage search tree, shown in Fig. 14, represents the
inclusion relation between the first-stage subtree and the search
tree.
Type I of two-stageMCTS takes the double-threat solution as
its search target during the first stage. Thus, in the T2-subtree, if
the root of T2-subtree is T2 Fail, the stage transition is initiated.
Meanwhile, Type II takes the double-threat and single-threat
solutions as its search target during the first stage. Thus, when
the root of the TSS-subtree is TSS Fail, the stage transition is
initiated. 25
YEN AND YANG: TWO-STAGE MONTE CARLO TREE SEARCH FOR CONNECT6 111
Fig. 17. Item (A) is a Connect6 Joseki obtained as described in [16], (B) is the
black CTSS solution, and (C) is the relevance zone based on the CTSS solution
for black. (A) The initial position. (B) A CTSS solution. The marked numbers
represent the order of stones placement for black and white. (C) The relevance
zone of the black CTSS solution comprises the area of gray cells.
forming a counter-threat segment or an inversion that prevents
Attacker from replaying.
Fig. 17(c) shows that the relevance zone .7
and are the set of empty cells in the initial position. The is
those cells in which one stone can form a counter threat segment
or an inversion, and is those cells in which two stones can
form a counter threat segment or an inversion. Note that since
and are incremental, .
Because relevance-zone search is embedded into two-stage
MCTS, the relevance zone in Fig. 17(c) is based on the initial
position and the CTSS solution for black. In Fig. 17(c), con-
struction of the relevance zone does not consider whether white
plays themove on (A, B). Therefore, if whitemakes a null move,
black can surely get this CTSS solution and construct this rele-
vance zone based on the CTSS solution.
In Fig. 17(c), the relevance zone derived in the CTSS solution
can be used for Defender. According to the initial position, if
Defender does not place any stone in the relevance zone
, Attacker can win based on this CTSS solution.
1) Property 4: Assume that Defender constructs the rele-
vance zone based on both the CTSS solution
and the initial position of Defender. If Attacker finds a CTSS
7In this paper, the relevance zone is described using the notation in [26].
solution, the cells in the relevance zone can clearly prevent
the CTSS solution from replaying.
Property 4 shows that if a CTSS solution exists on one side in
the situation where Defender has two stones to defend the CTSS
solution, the opposing side has two possible defenses:
1. place one stone in the relevance zone ;
2. make a Defender threat-move before Attacker establishes
the final winning position.
Making a Defender threat-move may not be done inside the
relevance zone . Although cells C and D in Fig. 17(c) are not
included in , they can form a counter threat segment. Rele-
vance-zone search is performed if Attacker presents two threats,
presents one threat, or presents no threat.
B. The Design of Relevance-Zone Search
The design of the relevance-zone search in this paper is based
on a CTSS solution. When one side has a CTSS solution, the
other side runs a relevance-zone search to generate candidate
moves. Relevance-zone search is performed depending on the
number of threats that Attacker has; therefore, the initial posi-
tion of relevance-zone search is determined in one of three sit-
uations. Explanations for these three situations are as follows.
1) Case 1: Attacker has Two Threats: Attacker presents two
threats, so Defender must place two stones to block the threats.
Thus, possible defensive moves are checked to determine if De-
fender can defend against the CTSS solution of Attacker. Case
1 of relevance-zone search is as follows.
Steps 1: Find the relevance zone based on
the new CTSS solution.
Steps 2: Judge whether the other defensive moves can de-
fend against the CTSS solution based on the relevance zone
generated in Steps 1.
The judgment of Steps 2 can be made based on the Property
4. In Fig. 18(a), white already makes two threats, so Defender
(black) considers the cells where it can place stones, namely A,
B, C, and D. The normal defense moves are (A, C), (A, D), (B,
C), and (B, D). Defender considers the situation where black
makes the move (A, C), and white obtains the CTSS solution,
as shown in Fig. 18(b). From relevance zone , cell B does
not occupy the relevance zone , and does not form threats
with black stones. Defender thus judges that defensive move (B,
C) cannot defend against the CTSS solution. By using this ap-
proach, black can quickly determine whether to defend from this
position. Consequently, the only problem is searching moves
(A, D) and (B, D) to determine whether white has a CTSS so-
lution.
2) Case 2: Attacker Has Only One Threat: Because one
threat already exists in this case of relevance-zone search, one
stone is to block one threat. Only one stone can currently defend
against the CTSS solution. Therefore, this case of relevance-
zone search is based on the blocking cells to check whether the
cell can defend the CTSS solution respectively.
When constructing the relevance zone, the position must in-
clude the blocking cell in this case, and it is sufficient to con-
struct relevance zone . For Fig. 19(a), black plays a move on
(A, B), and white finds a CTSS solution in Fig. 19(b); therefore,
black has to determine whether blocking cell A is indefensible.27
YEN AND YANG: TWO-STAGE MONTE CARLO TREE SEARCH FOR CONNECT6 113
Fig. 20. Example of intersection computed for relevance zones. (A) The constructed based on the Fig. 19(c). (B) The subset of relevance zone, which is the
intersection of Figs. 19(d) and 20(a).
Fig. 21. Example of the relaxed critical defense for single threat.
• one stone is in , but not in , and the other is outside
;
• the move cannot form the threat before Attacker estab-
lishes the winning position.
According to Property 4, the relevance zone is a critical
relevance zone. If Defender places one stone in , it can pre-
vent the CTSS solution from replaying. The proposed strategy
in this case is to defend the relevance zone in the first place.
The steps for Case 3–1 of the relevance-zone search are as fol-
lows.
Steps 1: Find the relevance zone based on
the new CTSS solution.
Steps 2: Define nodes as indefensible if they are already
produced and cannot be defended.
Steps 3: Generate candidate moves based on the relevance
zone .
The aim of generating candidate moves in this part is to verify
whether cells in relevance zone are indefensible. Therefore,
candidate moves are generated for every two cells in relevance
zone . In Fig. 22, relevance zone has 73 cells, so it can
generate 37 candidate moves. If the number of cells in is odd,
it randomly selects a cell in but not in to form a move. In
the next part, it must prove that every cell in is indefensible.
5) Case 3-2: Verify Whether the Cells in Relevance Zone
Can Defend Black CTSS Solution: When Attacker finds the
other CTSS solution, it starts to check whether the two cells
of the move are indefensible. The procedure is the same as in
Case 2 of the relevance-zone search because the two cells can
be considered the blocking cells. In Fig. 23(a), white plays a
move on cells A and B, which are in the relevance zone
of Fig. 22, and black finds a new CTSS solution. In this sit-
uation, relevance-zone search starts to verify whether cells A
and B are indefensible. Therefore, the relevance zones are con-
structed based on white playing a stone on cell A and B as in (B)
Fig. 22. Relevance zone obtained as in Fig. 17(c).
and (C), respectively, in Fig. 23. Case 3–2 of the relevance-zone
search is same as Case 2.
6) Case 3-3: Verify the Cells That are in but not in :
When all cells in the critical relevance zone have proven to fail
in defending Attacker CTSS solution in part two, relevance-
zone search starts to verify whether cells that are in but not
in are indefensible. Candidate moves generated in this part
are based on cells that can form threat-move.
In Fig. 17(c), cells E, F, and G are qualified, but cell H is not
qualified because cell H was proven indefensible in part two.
The defensive moves formed by these three qualified cells are
(E, F), (E, G), and (F, G), respectively. If all the defensive moves
formed by cells that are in but not in fail, Case 3 of the
relevance-zone search fails.
C. Conclusion in Relevance-Zone Search
Relevance-zone search can be used not only when the offen-
sive side defends a CTSS solution of the defensive side, but also
when the offensive side searches for promising moves in the
search tree. If the offensive side makes a move, a CTSS solution
exists for the associated position. Meanwhile, relevance-zone
search can be performed on the offensive side to judge whether
the defensive side can defend against the CTSS solution. Such
a search can significantly assist the offensive side in seeking
useful moves and can improve overall search efficiency.29
YEN AND YANG: TWO-STAGE MONTE CARLO TREE SEARCH FOR CONNECT6 115
TABLE III
THE CONTROL VARIABLE AND ITS VALUE
TABLE IV
SEARCH ALGORITHM COMPARISON FOR THE T2 SOLUTION
The playout step begins when MCTS enters a position that
has not yet been identified as a determined position in the search
tree. Elaborating an efficient playout strategy is a difficult issue.
In Kavalan, the number of moves per playout is limited because
the purpose of playout is estimating the given position. For Con-
nect6, the TSS solution under a position may exceed one, so
finding the nearest solution is helpful. Therefore, if playout re-
quires excessive computing resources to estimate positions, per-
formance is adversely affected.
1) Double-Threat TSS: To understand the efficiency of the
two-stage MCTS search algorithm, this paper compares it with
the traditional MCTS and the brute-force methods, BFS and
DFS. Table IV lists the results with the unit of search time is
seconds. The number under the search time (inside the paren-
thesis) is the number of node expansions, including the CTSS
search positions for double-threat moves.
At the beginning of developing MCTS, this paper does not
use value to distinguish between threat and nonthreat
moves. The results demonstrate that solutions are unavailable
for most puzzles. This paper thus finds that it is difficult to
find sudden-death property of Connect6 in a position if simply
using playout to control search tree development.
The difference between the two types of MCTS during the
first stage is that type I only generates double-threat moves
while type II simultaneously generates both double-threat and
single-threat moves.
When the T2 solution occupies the initial position, Type I
searches fewer positions while Type II searches more. However,
if double-threat moves are assigned a value and given reg-
ular search times during the first stage, it is possible to improve
the efficiency when using Type II to search for those puzzles
with T2 solution.
The experimental results demonstrate that the extra calcula-
tion time associated with using CTSS to assess double-threat
moves does not compromise the searching efficiency, but rather
significantly improves it.
Although two-stage MCTS does not offer the fastest
searching in all these testing puzzles, the total time clearly
demonstrates that regardless of type of two-stage MCTS,
MCTS has superior search efficiency to BFS and DFS. Fur-
thermore, ITSS-Example-5 clearly demonstrates that ITSS
can demonstrate greater search efficiency in the case of more
difficult T2 solutions.
The experimental results show that new Kavalan using ITSS
can solve 100% puzzles with T2 solution.
2) Single-Threat TSS: Among the 18 puzzles of TSS solu-
tions, this paper excludes two, 2008-Q1–1–3 and 2008-Q3–1–4,
because they lack TSS solution. Table V lists the results.
Searching single-threat solution is a more difficult ques-
tion. Because Type I of two-stage MCTS does not generate
single-threat first in candidate moves, it is hard to search for
the TSS solution based on the experimental results. Type II of
two-stage MCTS generates single-threat moves during the first
stage. Thus, it can focus its search on all threat moves.
The experimental results show that relevance-zone search is
helpful in searching for single-threat moves. The new Kavalan
using Type II of two-stage MCTS with relevance-zone search
can solve 75% (12/16) of puzzles with TSS solutions.
3) The Efficient Analysis in MCTS: The experimental result
shows that the two-stage MCTS works in Connect6. A node
expansion involves the search of CTSS for examining double-
threat moves and the playout for nondetermined moves. From
the Table V, the average time for nodes expansion is about 8300
nodes/s whether the relevance-zone search is used or not for
proving some positions.
B. Performance Analysis in Kavalan
Threat Space Search is the most common search method in
Connect6 as described in [17], [20], [23], and [26], and rel-
evance zones are used to accelerate the proof for some posi-31
YEN AND YANG: TWO-STAGE MONTE CARLO TREE SEARCH FOR CONNECT6 117
Fig. 25. ITSS-Example-1: White to play and win.
Fig. 26. ITSS-Example-2: White to play and win.
For the position for which double-threat solution exists, the
ITSS search structure provided in this paper is clearly more
efficient than BFS, DFS, or traditional MCTS.
According to the two-stage MCTS search structure, if the
solution can be obtained via CTSS under the initial posi-
tion, it can also be obtained through CTSS with an equiv-
alent search time.
Because ITSS develops T2-subtree via iteration, it can
avoid extending all the search branches and wasting calcu-
lation time. Though using CTSS to evaluate double-threat
moves involves repetitive calculations, the time costs of
this additional calculation are outweighed by the other
time savings.
• Relevance-zone search
To accelerate the demonstration of a defensive side (OR-
Node) fails versus offensive side (AND-Node) wins, this
paper uses the relevance-zone search.
According to heuristic knowledge of Connect6, this paper
proposes using relevance-zone search to accelerate the
demonstration of whether offensive side wins or defen-
sive side fails. The experiment proves that this approach
can avoid unnecessary searches of extensive state space,
reducing time spent on the demonstration.
B. Future Work
This paper divides candidate moves using a two-stage
scheme. Because three kinds of candidate moves exist for
Connect6, candidate moves can be divided into three-stages.
Whether three-stages can improve search efficiency is worth
discussing.
Furthermore, ITSS is the search architecture for double-threat
TSS, and can be combined with numerous search methods to
develop the search tree. This paper only used MCTS to develop
Fig. 27. ITSS-Example-3: Black to play and win.
Fig. 28. ITSS-Example-4: White to play and win.
Fig. 29. ITSS-Example-5: White to play and win.
ITSS. Whether PNS can improve the efficiency of T2 or TSS
solutions deserves exploration.
APPENDIX
ITSS EXAMPLES
The figures above are the ITSS test puzzles in the experi-
ments. Therefore, from Fig. 25 to Fig. 29 are the puzzles in
which CTSS cannot find the T2 solution, but the T2 solution
can be found by ITSS discussed in Section III. The numbers in
figure represent the order of moves. 33
35
 ICGA Journal June 2011 244
In 13x13 Go, the computer programs played with two handicaps, and komi is 3.5. The thinking time is 30 
minutes per side. Every program plays two games. Both of MANYFACES and ZEN won all of the games against 
professional Go players. MANYFACES and ZEN are strong in 13x13 Go, and they have won the Computer 
Olympiad and GPW Cup in 2011, respectively (Huang and Yen, 2010; Chou, Yen and Kato, 2011). Table 5 
shows that both Fuego and MoGoTW had two loses. 
Table 4: The results of 9x9. 
Game Black White Black First Move Result 
1-1 Chun-Hsun Chou (9P) MOGOTW 4-5 point B+R 
1-2 Ping-Chiang Chou (5P) MANYFACES 4-5 point B+R 
1-3 Joanne Missingham (5P) FUEGO 4-4 point B+R 
1-4 Kai-Hsin Chang (4P) ZEN 5-5 point W+4.5 
3-1 Chun-Hsun Chou (9P) ZEN 4-4 point W+R 
3-2 Ping-Chiang Chou (5P) FUEGO 4-5 point B+R 
3-3 Joanne Missingham (5P) MOGOTW 4-5 point B+R 
3-4 Kai-Hsin Chang (4P) MANYFACES 5-5 point B+R 
Table 5: Results of 13x13 games. 
Game Black White Result 
1-1 FUEGO Chun-Hsun Chou (9P) W+R 
1-2 MOGOTW Ping-Chiang Chou (5P) W+R 
1-3 MANYFACES Joanne Missingham (5P) B+1.5 
1-4 ZEN Kai-Hsin Chang (4P) B+9.5 
3-1 MOGOTW Chun-Hsun Chou (9P) W+R 
3-2 ZEN Ping-Chiang Chou (5P) B+5.5 
3-3 FUEGO Joanne Missingham (5P) W+R 
3-4 MANYFACES Kai-Hsin Chang (4P) B+3.5 
In 19x19 Rengo, the handicaps were 6 stones. The thinking time was 45 minutes per side. Every computer 
program played one game, but only ZEN won. Table 5 shows that the continuity of the policy is not important 
for a Rengo game with a large of handicap stones. The strength of human players seems almost the same as the 
strength in a general Go game.  
Table 6: Results of 19x19 Rengo game. 
Game Black White Result 
2-1 MoGoTW Chun-Hsun Chou (9P)/Joanne Missingham (5P) W+R 
2-2 ZEN Ping-Chiang Chou (5P)/Kai-Hsin Chang (4P) B+R 
4-1 MANYFACES Chun-Hsun Chou (9P)/Joanne Missingham (5P) W+R 
4-2 FUEGO Ping-Chiang Chou (5P)/Kai-Hsin Chang (4P) W+R 
In 19x19 Go, the handicaps were 6 stones for Black, too. The thinking time was 45 minutes per side. Every 
program played two games, but also only ZEN won all games and defeated Chun-Hsun Chou (9P). It is the first 
time that computer Go program wins the top professional Go player with 6 handicaps. MoGo ever won against 
a 1P Go player with handicap 6 in Tainan, Taiwan, 2009. (Lee, et.al. 2010) Chun-Hsun Chou, won the LG cup 
in 2007, is a top human player and he said that it is very hard to win ZEN with 6 handicaps. Next year, human 
vs. computer Go competition will be held in 2012 IEEE World Congress on Computational Intelligence (IEEE 
WCCI 2012), Brisbane, Australia. Chou expects that ZEN may beat a Pro with Handicap 5. Table 7 shows the 
results of 19x19 game. 
Table 7: Results of 19x19 game. 
Game Black White Result 
3-1 MANYFACES Chun-Hsun Chou (9P) W+R 
3-2 FUEGO Ping-Chiang Chou (5P) W+R 
3-3 ZEN Joanne Missingham (5P) B+R 
3-4 MoGoTW Kai-Hsin Chang (4P) W+R 
4-1 ZEN Chun-Hsun Chou (9P) B+14.5 
4-2 MANYFACES Ping-Chiang Chou (5P) W+R 
4-3 MoGoTW Joanne Missingham (5P) W+R 
4-4 FUEGO Kai-Hsin Chang (4P) W+Disconnecting 
37
 ICGA Journal June 2011 246
move. White 6 is a solid move. Black 7 tries to cut White groups. Due to the heavy komi, White 8 and 10 are 
enough to win. Black 11 is an invasion move. Finally, all of the invasion stones are dead. 
 
(a)  (b) 
 
Figure 1: Opening moves in 7x7 games. Figure 2: ZEN vs. Chun-Hsun Chou. 
 
Game 2: Kai-Hsin Chang (White) vs. MANYFACES (Black). Handicaps = 3.5, B+R. 
In Figure 3: The key move in this game is the move 127. This move should play N4 to eat the Black's right 
down group and get a big advantage situation. However, White played N6 in this game, and Black played N4. 
White cannot eat the Black's right down group easily, which causes the White's down group is captured and 
White lost this game. 
Game 3: Chun-Hsun Chou (White) vs. ZEN (Black). Handicaps = 6. B+14.5.  
In Figure 4, Chun-Hsun Chou said ZEN was leading from the beginning to the end. Black 14 and 24 are good 
moves in handicap game. Black 48 is an aggressive move. Black intends to kill the White group by ko. This ko 
fight is not end until Black 116, which is a good ko threat. If White continues to response it, there would be 
many ko threats for Black. Thus, White ends the ko with move 117. Black holds the center territory by move 
118. White has to invade into the center or lose. But Black plays very solid until the end. Finally, the total 
points of the center territory of Black are 48. This number is larger than all of White’s territory, which is 46. 
Black wins with 14.5 points totally. 
 
Figure 3: Kai-Hsin Chang vs. MANYFACES. Figure 4: Chun-Hsun Chou vs. ZEN. 
 
Photos from NUTN’s website 
 
39
94 ICGA Journal June 2011 
SHIGA WINS CHINESE CHESS TOURNAMENT 
 
Shi-Jim Yen1, Tsan-Cheng Su2 and I-Chen Wu3 
 
Taiwan 
The computer Chinese chess tournament was held on September 25th and 26th at Kanazawa, Japan, as part 
of the 15th Computer Olympiad. Five programs from the China, Netherlands and Taiwan participated in the 
tournament. The tournament was a double round-robin match; all programs had to compete with each other 
in two games, one of which is played as the first player and the other as the second player. The Asian rule 
was adopted. Each program must complete all the moves within thirty minutes for one game. Most 
programs took less than 25 minutes to complete a game in this tournament. Table 1 contains the 
information of the participants. 
SHIGA has won five Computer Olympiad silver medals at 2001, 2002, 2005, 2006 and 2007. However, it 
never got any gold metal until this year. In the 15th Computer Olympiad, it won all the games, and hence 
rewarded as the gold medal finally. SHIGA is designed to support multiprocessor computer. It can search 
more than 20 plies by type-B search. The deeper search power, background thinking and the well-sound 
opening book turn out to be the key factors of the victory. TMSK is the runner-up. The program got the gold 
medal in 14th Computer Olympia. The third place is CHIMO which won the same medal last year. The 4th is 
HAQIKID which is the only program from the Westerns. The 5th is a new comer, SUNRISE. In Table 2, the 
final standings are given. SHIGA won the tournament. 
Program Author Operator Hardware Country 
CHIMO Wen-Jie Tseng, Wei-Lun Kao, Hung-Hsuan Lin, 
Chun-Bin Hsu, I-Chen Wu, Shun-Chin Hsu 
Wen-Jie 
Tseng 
Intel Xeon 
2.6G 
Taiwan 
HAQIKID Harm Geert Muller Harm Geert 
Muller 
Intel Core 
2 2.4G 
Netherlands
SHIGA Ming-ChengCheng, 
Shi-Jim Yen   
Tsan-Cheng 
Su 
AMD X6 
3.3G 
Taiwan 
SUNRISE Hao Cui, Jiajia Guo, Xiaowei Hu, Zhao Jianbo, 
Xiaomeng Yang 
Tournament 
Staff 
Intel Xeon 
2.6G 
China 
TMSK Bing-Jie Shen, Ruei-Ping Li, Tsan-Sheng Hsu  Bing-Jie 
Shen 
Intel Core 
2 2.8G 
Taiwan 
Table 1: The participants of the 15th Computer Olympiad 
Program Chi HQ Shi Sr TM Points Rank 
CHIMO - 1.5 0 2 0.5 4 3 
HAQIKID 0.5 - 0 2 0.5 3 4 
SHIGA 2 2 - 2 2 8 1 
SUNRISE 0 0 0 - 0 0 5 
TMSK 1.5 1.5 0 2 - 5 2 
Table 2: The Results of the 15th Computer Olympiad.  
SELECTED GAMES 
We present four interesting game records from the tournament. These abbreviations for Chinese Chess 
notations are as following: the letter K stands for the King, A for the Assistant, E for the Elephant, R for the 
Rook, H for the Horse, C for the Cannon, and P for the Pawn. (Yen, et.al. 2004) 
 
                                                 
1 Dept. of Computer Science and Information Engineering, National Dong Hwa University, Hualien, 
Taiwan. Email: sjyen@mail.ndhu.edu.tw 
2 Dept. of Computer Science and Information Engineering, National Dong Hwa University, Hualien, 
Taiwan. Email: d9821009@ems.ndhu.edu.tw 
3 Dept. of Computer Science, National Chiao Tung University, Hsinchu, Taiwan, Email: 
icwu@csie.nctu.edu.tw 
41
230 ICGA Journal December 2010 
 
MODARK WINS CHINESE DARK CHESS TOURNAMENT 
 
Shi-Jim Yen1, Shih-Yuan Chiu1 and I-Chen Wu2 
 
Taiwan 
 
The computer Chinese dark chess tournament was held as part of the 15th Computer Olympiad, which took 
place in Kanazawa, Japan, from September 25th to 26th, 2010. Five teams participated in the Chinese dark 
chess tournament. Table 1 lists the participants and the final standings. This tournament is the first 
international Chinese dark chess tournament. Chinese dark chess use the same stone and a half of board of 
Chinese chess [Yen, et.al. 2004]. There are many different types of Chinese dark chess. In this tournament, 
the rules were applied [Chen, et.al. 2010]. The games were played according to a round-robin system in 
which one program played twice against all the other programs. For each game, the winner scored 1 point 
and the loser scored nothing. For a draw, both scored 0.5. 
 
Rankin
g 
Program Author Points SoDOS 
1 MODARK Xue-Cheng Lai, Chang-Wei Gong, Shi-Jim Yen 5 7
2 DARKCHESSBETA Cheng-Hsiao Hsieh, Shun-Shii Lin 5 6.5
3 LEAVE-OR-LOSE Meng-Tsung Tsai 4.5 
4 FLIPPER Bo-Nian Chen, Tsan-Sheng Hsu 2.5 
5 DARK_CHESSER Hung-Jui Cheng 2 
Table 1: The participants and final standings. 
 
 
Program DARKCHESSBETA DARK_CHESSER FLIPPER LEAVE-OR-LOSE MODARK 
DARKCHESSBETA - 2 1 1.5 0.5 
DARK_CHESSER  0 - 1.5 0 0.5 
FLIPPER 1 0.5 - 1 1 
LEAVE-OR-LOSE 0.5 2 1 - 1 
MODARK 1.5 1.5 1 1 - 
Table 2: The cross table. 
 
MODARK won the gold of the 15th Computer Olympiad by 5 points and 7 SoDOS. The next one teams, 
DARKCHESSBETA with 5 points too, but it have only 6.5 SoDOS. The cross table is listed in Table 2. 
 
Selected Games 
This report comments the two games, one between MODARK (the gold) and LEAVE-OR-LOSE (the bronze), 
and one between DARKCHESSBETA (the silver) and LEAVE-OR-LOSE.  
 
Game 1:  MODARK (B) vs. LEAVE-OR-LOSE (R)  
In figure 3a, the Black Minister is moved from c2 to c3, and prepared to leave Pawn for c2 from d2 in the 
next run. Thus the Red King in b2 is impossible to escape. At the same time, the Red part moves Red 
Guard from b2 to c6 and decides to capture Red King. In the meantime, Red part should flip over the piece 
in a2, b3 or c1 and try to protect Red King. When Red King may capture the piece in a2 or b3 in advance, 
even Black Pawn attempting to take Red King from d2, it still has chance to escape. 
However, to flip c1 is a good choice for Red part. As long as c1 is in Red side and could be other pieces 
expect for Cannon, it is possible to take Black Pawn in d2. Under this situation, Black Pawn will not close 
to Red King. 
                                                 
1 Dept. of Computer Science and Information Engineering, National Dong Hwa University, Hualien, Taiwan, Email: 
sjyen@mail.ndhu.edu.tw and d9621005@ems.ndhu.edu.tw. 
2 Dept. of Computer Science, National Chiao Tung University, Hsinchu, Taiwan, Email: icwu@csie.nctu.edu.tw. 
43
Using Global Corresponding Move Bias on MCTS 
Cheng-Wei Chou 1, Shi-Jim Yen 2 and Jung-Kuei Yang 3  
 
1, 2  Dept. Of Computer Science and Information Engineering, National Dong Hwa University, Taiwan 
3 Dept. of Applied Foreign Languages, Lan Yang Institute of Technology, I Lan, Taiwan 
 
Abstract—In this paper we propose an efficient method to improve Monte Carlo Tree Search (MCTS) for the 
reuse information between different branches of MCTS and get very well experimental results. MCTS cannot 
share the result of semeai problem between different branches, but this paper try to use Global 
Corresponding Move Bias to improve this problem. The experiment result shows although this method is 
simple, but useful. 
Keywords- MCTS, UCT, Computer Game, Go 
1.  INTRODUCTION 
The game of Go is a very old and popular 
game. [1] In recent years, the strength of Go 
program is benefited by the Monte Carlo 
Tree Search (MCTS) algorithm [2]. However, 
a common problem still perplexes the 
researchers of the computer Go field. When 
applying MCTS, some branches have clearly 
found the best moves of some semeai 
problems locally, but other ones still require 
finding the best move again, as in fig. 1. If 
the found results could be reused, the 
performance of tree search could be 
increased, and the strength of Go programs 
could be improved. 
This paper proposes a method called 
global corresponding move bias to improve 
this problem. This method is inspired by 
RAVE [3] and LGRF [4]. Useful information 
is obtained by gathering the total visit counts 
of the responding moves of every location on 
the board. The information could be used to 
guide the direction of MCTS and make it 
more efficient. Related work, included 
MCTS, RAVE and LGRF will be introduced 
in section2. The detail of our method will be 
described in section 3. The experimental 
results of section 4 demonstrate that this 
method can improve the strength of Go 
program. This paper is concluded in section 5 
 
Figure 1 : The semeai problem of right bottom corner 
may be calculated several times in the same search tree. 
2. RELATED WORK  
2.1 MCTS 
MCTS is a well-known and useful 
method in the field of Computer Game, 
especially for the game of Go. This method 
uses Monte Carle method to evaluate 
situations. Basically, MCTS has four basic 
stages, as fig. 2. MCTS repeats these four 
stages to build a search tree in memory until 
time out. Finally, MCTS select the best child 
by reward or visit counts of children of root. 
It is a best-first method, but uses some 
method, for example, UCB, to deal with the 
Exploitation vs. Exploration problem. 
45
H. Baier and P. D. Drake proposed a 
method, LGR (Last Good Reply), this method 
will remember the last win reply. They 
improved LGR to LGRF (Last Good Reply 
Forget), this method will forget the lost reply. 
These methods improve the quality of 
simulation and increase the strength of Go 
program. 
3. GLOBAL CORRESPONDING MOVE 
BIAS 
  There is a problem in MCTS, the result of 
semeai problem in some branches of search 
tree cannot be used in other branches. For 
example, as fig. 3, there is a semeai problem in 
left bottom, and the result is black can capture 
white stones. Although in some branches, the 
result may be calculated, however, others 
branches cannot reuse the result, even the 
problem is almost same.  
Of course, this is a big problem, and it is 
difficult to cut or distinguish if a situation or a 
semeai problem of certain branch is similar to 
another. Hence, we try to use more simple 
method. Because a semeai problem usually 
need ten or more steps, it is difficult to be 
reused. Our method try to focus on one move, 
this idea is inspired by LGR and LGRF. We try 
to record the replies of some move in search 
tree, and don’t consider the situation is the 
same or not. We call this method as Global 
Corresponding Move Bias (GCMB). GCMB is 
similar to LGRF, but they are different. LGRF 
is used in playout, but GCMB is used to search 
tree. GCMB is similar to RAVE, too. However, 
RAVE use the move of both playout and 
search tree, but GCMB just uses the reply 
moves in search tree. Unexpectedly, this 
simple method obtains possible results. The 
remaining part of this section will describe the 
detail of GCMB.  
In MCTS, we maintain a global table and 
record the total visit counts of responding 
moves of every move which is in the search 
tree regardless of the position. As the example 
in fig. 4, the visit counts of responding moves 
of move E4 are recorded. However, fig. 4 
doesn’t consider the colors. In fact, the 
information is recorded separately for different 
colors. These values will be cleared before 
beginning of search every time.  
 
Global corresponding move bias of 
E4 
Move Visit Count 
E5 120 
F3 42 
F2 30 
 
Figure 4 : An example of the global corresponding move bias.
1
E5 F3 F2 E4 
E5 
F2
F2 F3120  10 15 
20 32 
E4 
Figure 3 : Now turn is black. Black win the left bottom 
semeai problem and doesn't need to play anymore. 
47
5. CONCLUSION & DISCUSSION 
In this paper, we try to obtain the 
information by recording the information of 
global corresponding moves and use the 
information to improve the performance of 
MCTS. The experiment results prove this 
method could steady increase the winning rate 
of the MCTS Go program. 
Acknowledgments 
The authors thank anonymous reviewers for 
their valuable comments, and thank the 
National Science Council of the Republic of 
China (Taiwan) for financial support of this 
research under contract numbers NSC 96-
2628-E-259-020-MY3 and NSC 98-2221-E-
259-021-MY3. 
References 
[1] Martin Müller. Computer Go. Artificial 
Intelligence, 134:145-179, 2002.. 
[2] Gelly, S., Wang, Y., Munos, R., & Teytaud, O. 
(2006). Modification of UCT with patterns in 
Monte-Carlo Go (Technical Report 6062). INRIA. 
[3] Gelly, S. and Silver, D. (2011) Monte-Carlo tree 
search and rapid action value estimation in 
computer Go. Artificial Intelligence. Vol. 175, 
Issue 11, July 2011, pp. 1856-1875. 
[4] H. Baier and P. D. Drake  "The power of 
forgetting: Improving the last-good-reply policy in 
Monte Carlo Go",  IEEE Trans. Comput. Intell. AI 
Games,  vol. 2,  no. 4,  pp.303 -309 2010. 
 
49
  
(a)                        (b)                        (c)                        (d) 
Figure 3. Possible ways for a island to connect 
In addition to the ways of connection, we do some simple 
judgments to decrease possible ways of connection, increasing 
the possibility of finding out solutions of intersection method, 
and decrease the use of elimination search. The way to judge is 
to delete impossible connection. For example, in Fig. 4(a), if 
two islands with number 2 connect each other with two bridges, 
they are impossible to connect other islands, which is against 
rule 5. Thus, in this step, this possible will be deleted; likewise, 
in Fig. 4(b), two islands with number 1 connecting together 
will be against rule 5. 
 
 
(a)                              (b) 
Figure 4. Connections against rules will be deleted. 
Table I lists how the possible connections of two 
highlighted islands with number 2 will change after the 
judgment above. Here, we use U(Up), D(Down), L(Left), and 
R(Right) to represent the connecting directions around a island, 
and add numbers after directions to show the numbers of 
bridges. For example, U2 means the island has two bridges 
connecting the island in the up direction. 
 
TABLE I. HOW THE POSSIBLE CONNECTIONS OF THE TWO 
HIGHLIGHTED ISLANDS WITH NUMBER 2 IN FIG.4 WILL CHANGE 
Original 
Possible 
Connections
Impossible 
Connections 
Actual 
Possible 
Connections
Up Islands 
R2 
D1 R1 
D2 
R2 
D2 
D1 R1 
 
Down 
Islands 
U1 R1 
U2 
U2 U1 R1 
 
C. Intersection method 
We can use an example to illustrate the main concept of 
intersection method. Assume an island only has two connecting 
ways, D1 L1 R2 and D2 L1 R1.  Because both of the two 
possibilities include D1 L1 R1, we can believe that the three 
bridges, D1, L1, and R1, must exist. In other words, finding 
possible points in common among lots of possibilities to get 
information is the concept of intersection method. 
Before using intersection method, according to present 
board, we can use more advanced way of sieving to decrease 
the possibility of matching so that the intersection method can 
probably get more information. We use three major ways of 
sieving here.  
Because bridges cannot have branches or cross each other, 
if island a and island b are separated by bridges not connecting 
them, there will be no possibility for the two islands to connect. 
The first kind of sieving is used to exclude these impossible 
matches. For example, like Fig. 5(a), there are five possible 
connections for the highlighted island, but through some 
information calculation, the board situation will change into 
Fig. 5(b). The highlighted island’s connection downward is 
blocked, so all the connections including down are excluded for 
its impossibility. Table II shows the specific information. 
 
 
(a)                                    (b) 
Figure 5. An example of first kind of sieving 
TABLE II. HOW THE POSSIBLE CONNECTIONS OF THE 
HIGHLIGHTED ISLANDS WITH NUMBER 2 IN FIG.5 WILL CHANGE
Original 
Possible 
Connections
Impossible 
Connections Actual Possible Connections 
R2
L2 
R1 L1 
D1 L1  
D1 R1 
 
 
D1 L1  
D1 R1 
R2 
L2 
R1 L1 
 
 
When some islands construct bridges, their ability of 
containing new bridges will decline; therefore, we can make 
use of this information to exclude some impossible connections. 
Like Fig. 6(a), there are five possible connections for the 
           
Figure 2. Flow chart of Hashi Solver 
Intersection method 
Whether there is 
new information? 
Whether the 
problem is solved?
Elimination search
Yes 
No 
Yes 
Complete 
No 
Start 
Basic information calculation 
186 51
 
Figure 9. A board that should use elimination search 
We use an example below to illustrate the three steps. 
Assume the present board is like Fig. 9. Highlighted islands 
represent those solved, and other islands unsolved. Meanwhile, 
because intersection method cannot find any information, we 
will select an unsolved island, and assume some connection is 
true. For example, possible connections for the unsolved island 
with number 2 on the left button are R2, U2, and R1U1. 
Assume the island’s connection is U2, and the board will 
become Fig. 10. The dotted lines are assumed connections. 
Next, use extending ratiocination for the new board, and 
use mistake testing for the board with extending ratiocination 
to make sure whether it is against rules. Fig. 11 is the board 
after using extending ratiocination for Fig. 10. The dotted lines 
are results after using extending assumption. After using 
mistake testing, we find that because the nine islands in the 
circle on the left in Fig. 11 cannot connect any direction, they 
are against rule 5. Besides, the island with number 3 in the 
center on the up direction can only connect the right direction 
which is against rule 2 because the capability to contain new 
bridges of islands on its left, right, and down is 0.  
If it is against rules, it is proved that the assumption is not 
true. In other words, one possibility is excluded, which means 
we get new information. Because elimination search is slower 
than intersection method, as long as elimination search has new 
 
Figure 11. The board after using intersection method 
information, we will use intersection method to test if more 
new information can be found. If it is not against rules after 
mistake testing, keep using elimination search. In the example 
above, if the assumption is not true, possible connections for 
the island with number 2 in the center on the left are U1R1 and 
R2. After using intersection method, it is found that there must 
be a bridge connecting the island on the right. 
The worst situation is that after using elimination search for 
all the islands’ possibilities, the problem still cannot be solved. 
However, when we test questions of large size (25X25), we 
haven’t found questions that intersection method and 
elimination search method cannot solve. Thus, we believe 
merely using intersection method and elimination search 
method is enough to deal with the need of solving Hashi. 
III. EXPERIMENT RESULTS 
We use the method in the second section to actually solve 
questions of Hashi, and list the result here. We use MATLAB 
2009 to implement Hashi Solver, and randomly select one 
thousand questions of 25X25 to the tested objectives from 
Internet [9]. Our experimental environment is formed by using 
Intel E8400 CPU, 8G RAM, and the operation system is 
VISTA64. Testing the one thousand questions, the average 
time took to solve every question is 0.0342 seconds. Among 
them, we need only intersection method to solve 76.6% 
questions without using elimination search, and these questions 
are those which can be solved without using the rule that "all 
the islands must connect together." About the comparison 
between intersection method and elimination search, we list it 
in Table VI. From the experimental results, intersection method 
is four times faster than elimination search, which proves that it 
is a correct way to use intersection method right after finding 
new information by using elimination search. 
TABLE VI.  THE COMPARISON BETWEEN INTERSECTION METHOD AND 
ELIMINATION SEARCH 
Method 
Average 
Solving 
Proportion 
Average  
Time 
Cost 
Average Time 
Cost per 1% 
Proportion 
Intersection 98.9% 0.0327s 3.3064 x 10-4s 
Elimination 
search 1.1% 0.0015s 13.6364 x 10
-4s 
 
Figure 10. “Assumption” step in a elimination search 
188 53
Towards a Solution of 7x7 Go with Meta-MCTS
Cheng-Wei Chou3, Ping-Chiang Chou, Hassen Doghmen1, Chang-Shing Lee2,
Tsan-Cheng Su3, Fabien Teytaud1, Olivier Teytaud1,2, Hui-Ming Wang2,
Mei-Hui Wang2, Li-Wen Wu2, and Shi-Jim Yen3
1 TAO (Inria, Lri, Univ. Paris-Sud, UMR CNRS 8623), France
2 Dept. of Computer Science and Information Engineering,
National University of Tainan, Taiwan
3 Dept. of Computer Science and Information Engineering, NDHU, Hualian, Taiwan
Abstract. Solving board games is a hard task, in particular for games
in which classical tools such as alpha-beta and proof-number-search are
somehow weak. In particular, Go is not solved (in any sense of solv-
ing, even the weakest) beyond 6x6. We here investigate the use of
Meta-Monte-Carlo-Tree-Search, for building a huge 7x7 opening book.
In particular, we report the twenty wins (out of twenty games) that were
obtained recently in 7x7 Go against pros; we also show that in one of the
games, with no human error, the pro might have won.
1 Introduction
The main approach for solving board games consists in using alpha-beta with
several improvements such as transposition tables, killer moves, symmetry, and
expert knowledge for ranking moves; proof-number-search[1] is used for prefer-
ring nodes with a small branching factor. Some successes have been obtained in
particular for Ponnuki-Go [16] and there are results for all rectangular boards
until 30 locations[17]. In the case of diﬃcult games, these techniques have been
combined with Monte-Carlo evaluation[13]. The use of Monte-Carlo techniques
is often eﬃcient in diﬃcult board games and in particular for the game of Go[8];
it can be used for exact solving[5]; however, 7x7 remains beyond the capabilities
of the current computers and algorithms.
Meta-MCTS has been proposed [2] (a mixing between nested Monte-Carlo[6]
and Monte-Carlo Tree Search[8]) precisely for cases in which exact solutions are
beyond our capabilities. Some variants have been applied in one-player cases[12].
This paper is devoted to (1) the application of Meta-MCTS for building huge
opening books in 7x7 Go, and (2) to checking Meta-MCTS’ ability to learn on
speciﬁc variations. As in [2], we will see that human expertise is necessary for
top-level performance; a main diﬀerence with 9x9, however, is that in 7x7 a
reasonable computation time leads to openings outperforming a given ﬁnite set
of variations - a diﬀerence in the context of this study (compared to previous
works in 9x9) is that we work with an adjusted Komi, i.e., Komi 9.5 for White
and Komi 8.5 for Black, so that the problem is well posed and a solution exists,
at least if we trust the widely believed assumption that “7x7 fair Komi is 9”. In
all, the paper and the experiments are based on MoGoTW 4.86 Soissons.
H.J. van den Herik and A. Plaat (Eds.): ACG 2011, LNCS 7168, pp. 84–95, 2012.
c© Springer-Verlag Berlin Heidelberg 2012
55
86 C.-W. Chou et al.
– Possibly, some side information I(n) (I(n), and also K1(n) or K2(n) below,
are meant as a short notation for the many MCTS improvements in the
literature which are based on expert rules or patterns[8,7,11]).
– A father F (n), which is the father node of n; this is not deﬁned for the root.
– A value V (n); this value is the Bellman value; it is known since [18,3] that
V (n), equal to the expected value of the reward if both players play optimally,
is well deﬁned.
– For each simulation index t ∈ {1, 2, 3, 4, . . .},
• nt(n) ∈ {0, 1, 2, . . .} is the number of simulations with index in
1, 2, . . . , t− 1 including node n, possibly plus some constant K1(n):
nt(n) = #{i < t;n ∈ si}+K1(n). (1)
• wt(n) ∈ R is the sum of the rewards of the simulations with index in
1, 2, . . . , t− 1 including node n, possibly plus some constant K2(n):
wt(n) =
∑
i<t;n∈si
reward(si) +K2(n), (2)
where reward(si) is Reward(l) if l is the last node of simulation si.
• If n is not the root, scoret(n) = score(wt(n), nt(n), nt(F (n)), I(n), t);
we will see which properties we have, depending on the score function.
The score function is usually an estimate of the quality of a node.
We consider algorithms as in Figure 1.
The algorithm relies on a good score formula. We refer to the many papers
about MCTS for the scores classically used in MCTS implementations[8,7,11].
The score used for Meta-MCTS (following the same principles) will be discussed
in Subsection 2.2.
2.2 Meta-MCTS
Meta-MCTS is MCTS in which the random policy is replaced by a MCTS policy.
This makes simulations rather slow; but the tree of preferred moves is of high
quality, and can eﬃciently be used as an opening book. The reader is referred to
[6] for nested-Monte-Carlo (with good results, including world records, in some
puzzles), and to [2] for nested MCTS, with application to Go. We might deﬁne
extensions of Meta-MCTS as follows.
– MCTS is built on top of a default (somehow naive) playout policy.
– Meta-MCTS is built on top of a MCTS policy.
– Meta-Meta-MCTS is built on top of a Meta-MCTS policy.
– . . .
To the best of our knowledge, such nested levels have been successfully used in
Monte-Carlo, but not yet in MCTS; we here only use Meta-MCTS.
57
88 C.-W. Chou et al.
opening book), it can concentrate on one move only, in spite of a success rate
converging to 0, if all other moves have an empirical success rate 0 due to an
unlucky ﬁrst simulation. The typical example is as follows:
– there are two legal moves, one good (leading to a forced win) and one bad
(leading to a loss);
– the good move has success rate 0, because it has been tested once, and,
unluckily, it was a loss;
– the bad move has been tested N times, with only one win, and has therefore
a success rate 1/N .
The bad move will be tested again and again, because 1/N is always> 0, whereas
the good move is never tested again and keeps a success rate 0. For more details
on this anomaly, and in particular a consistency proof when using rule 2 during
the tree building phase, we refer to [4]; alternate consistent rules consist in using
a regularized score (number of wins plus K divided by number of simulations
plus 2K), or a Upper Conﬁdence Bound-like formula - but using such a formula
implies that all the nodes in the tree will be visited, whereas other rules above
can lead to a smaller visited tree.
2.4 Existing Handcrafted 7x7 Openings
A classical partial solution for 7x7 has been proposed by Davies[9], and developed
by several authors (posts on mailing lists refer to contributions by J. Tromp
[14]). J. Tromp’s homepage contains an interesting analysis [15]. However, the
proposed opening is far from solving all cases.
Our methodology (detailed below) did not ﬁnd any mistake in these openings.
However, it developed interesting variations that were not, to the best of our
knowledge, in these openings. Such a new variation is shown in Fig. 3 for Black;
this variation was not analyzed after the third move in the existing openings.
Also, many variants in professional games discussed below (Section 4) were not
discussed in the existing openings; in particular, the critical variation D4-D5-E4-
C4 leads to complicated variations and we have seen that even pros can make
mistakes in it.
3 Experimental Results of Meta-MCTS Before
Modifications by Human Expertise
We used Senseis’ work (see homepage) on 7x7 Go in two manners: (1) as a
preliminary opening book, and (2) as a sparring partner. This means that the
Meta-MCTS tree is initialized at Senseis’ solution, and is trained versus this so-
lution. Meta-MCTS is based on a tree equipped with statistics, possibly encoded
59
90 C.-W. Chou et al.
that programs do not (by far) play perfectly without opening book; learning
the opening book improves the success rate.
– Before the use of Senseis’ openings, we might have believed that the program
was playing almost perfectly as the success rate is close to 100%; however,
the ﬁrst games against Senseis’ variations were not that good. After some
learning, the program can play correctly against Senseis’ variations and has
developed many new variations.
– We will see below that even at this point, there were some important varia-
tions which were not yet analyzed; this conﬁrms [9]’s claim that 7x7 Go is
hard even at the best human level. More on this in later sections and in the
conclusion.
4 Games against Humans
We tested the generated opening book against humans.
In order to check that the fair Komi is 9, we tested games as follows.
MoGoTW plays as Black, with Komi 8.5; and MoGoTW plays as White, with
Komi 9.5. If MoGoTW was unbeatable in this context, it would imply that the
right Komi (in the sense: the Komi leading to a draw) is 9. We cannot know if
a program is unbeatable just by a ﬁnite set of experiments, but we tested many
games against many professional players. MoGoTW won all games; 10 games
as Black against 10 diﬀerent pros (Fig. 5), and 10 games as White against these
same 10 pro players (Fig. 6). However, importantly, the second game won as
Black by MoGoTW could have been a loss - MoGoTW made a mistake, but
won thanks to a mistake by the human player; the corrected variation V , with
the modiﬁcation by Shi-Jim Yen and pros, is discussed in Fig. 4.
5 Introduction of Human Expertise in the Grid-Based
Learning
Human experts found that a pro might have won a game: the second game as
Black (see Fig. 4). Therefore, we reran the grid-based experiment (Meta-MCTS)
speciﬁcally on this variation V - i.e. now the white opponent of the black Meta-
MCTS is playing variation V . The complete run on the Grid is therefore as
follows.
– First set of experiments: (already discussed in Section 3)
• Meta-MCTS for Black with Komi 8.5; against White openings in Senseis’
solution (introduced during the run, i.e., N is increasing).
• Meta-MCTS for White with Komi 9.5; against Black openings in Senseis’
solution (introduced during the run, i.e., N is increasing).
61
92 C.-W. Chou et al.
Games played by Cheng-Jui Yu (3P), Chun-Yen Lin
(2P), Hsiang-Chieh Wang (1P), Hsiang-Jen Huang
(5P), Kai-Hsin Chang (4P), Shao-Chieh Ting (2P),
Ting-Yi Lin (1P), Yin-Nan Chou (4P), Yu-Hsiang
Lin (4P), and Yu-Pang Kou (1P) respectively.
Fig. 5. Games played as Black against pros
63
94 C.-W. Chou et al.
6 Conclusion
We applied directly the methodology from [2] to 7x7 Go. This methodology is
Meta-MCTS (i.e., MCTS with a MCTS as a default policy), with archiving of
statistics as an opening book. This provided a version of MoGoTW specialized
for 7x7 Go, with a big opening book (1˜2,000 games). Many moves in games
against pros were played automatically. Results in self-play were very good; yet,
the games against the pros have shown that there was still a mistake; as the
pro also made a mistake, we might have believed that MoGoTW had played
perfectly - but a careful analysis by human experts has shown that humans had
an opportunity of winning one of the games, and lost only because even pros can
do mistakes in 7x7 Go. Incorporating variation V into the learning procedure
provided good results: Meta-MCTS could ﬁnd by itself the correction by Meta-
MCTS. Nonetheless, if variation V had not been integrated in the experiments,
Meta-MCTS might have not studied this variation (so, MoGoTW found the
solution by itself, but it did not ﬁnd the trouble by itself). Our main claims are
summarized below.
– Meta-MCTS builds opening books which make MCTS stronger in 7x7 Go.
– MCTS plus an opening book learned by Meta-MCTS is much stronger than
MCTS; however, there were still variations in Senseis’ SGF ﬁle which were
not correctly played by Meta-MCTS.
– MCTS plus Senseis’ variations plus the opening book automatically learned
by Meta-MCTS plus training against Senseis’ variations is much stronger;
however, our games against pros have shown that it was still possible for a
pro to ﬁnd a mistake in the opening. We have been lucky that the pro did
not play correctly the rest of the game. This conﬁrms that 7x7 can be quite
hard even for the best humans.
Further Works. A possible further work is the exact solving of 7x7 Go. Our
algorithm is not an exact solving algorithm; but it provides rather strong opening
books. Maybe a possible approach is the following:
– make MoGoTW deterministic (just by using a ﬁxed random seed);
– play all possible openings againstMoGoTW, collect the leafs of the opening
book;
– solve all these leafs.
A diﬀerent further work would be the experimentation of Meta-MCTS in real-
time. We all know that MCTS is weak in, e.g., Semeai and in combining several
local ﬁghts; maybe Meta-MCTS can be a successful new approach, in the mid-
game and not only in the opening.
Acknowledgements. We are grateful to Grid5000 for support in parallel versions of
the algorithms, to the BIRS seminar on Combinatorial Game Theory, to the Dagstuhl
seminar on the Theory of Evolutionary Algorithms, and to the Bielefeld seminar on
Search Methods, to National Science Council (Taiwan) for NSC grants 99-2923-E-024-
003-MY3 and NSC 100-2811-E-024-001.
65
-90- 
 
 
This paper proposed a new simulation strategy of Monte 
Carlo Tree Search for Connect6. The core idea of the new 
simulation strategy is to put the search on proving or 
disproving a sudden-death property at first stage, and it 
searches the most promising move at second stage when the 
first stage cannot find its solution. The experimental results 
show that the new simulation strategy of MCTS can 
perform much efficiency than traditional MCTS on those 
positions that has TSS solution in Connect6. 
I. INTRODUCTION 
A. Monte-Carlo Tree Search 
Searching is a way we use to solve problems as well as 
a skill of programs to exhibit their intelligence. Recently, 
MCTS has become a very popular game search method, 
and it has been applied to many game searches. The core 
idea of MCTS is to sample from enormous branches by 
playout from leaf node, and it corrects the mistakes in the 
upper sampling position 1  by developing the 
correspondent branches of search tree. 
Traditional MCTS does not fit with the property of 
sudden-death game. Sudden-death is a property of 
quickly deciding the winner of a game. Therefore, in 
every position, one has to consider whether there is 
sudden-death. If one neglects this feature, the other side 
will win. 
 
Shi-Jim Yen is with the Department of Computer Science and 
Information Engineering, National Dong Hwa University, Hualien, 
Taiwan (e-mail: sjyen@mail.ndhu.edu.tw). 
Jung-Kuei Yang is a Ph.D. candidate in the Department of Computer 
Science and Information Engineering, National Dong Hwa University, 
Hualien, Taiwan, and he is also with the Department of Applied Foreign 
Languages, Lan Yang Institute of Technology, I Lan, Taiwan. (e-mail: 
jungkuei@gmail.com). 
 
1 Position represents all the state sets of cells on the board after one 
side play stones. The state of cell is divided into three types: Empty, 
Black, and White. 
B. The Introduction of Connect6 
Connect6 has two important features: enormous 
candidate moves and sudden-death. Enormous candidate 
moves make its branching factors quite high; 
sudden-death makes searching complexity increase. The 
property of sudden-death in Connect6 is Threat Space 
Search, TSS [1][2]. TSS is the common search method in 
Connect-k games. About the definition of threat in 
Connect6 and its kinds, please refer to [4][5]. Connection 
is a most commonly used information when searching in 
Connect-k games. For information on saving and 
calculating Connection, please see [6][7]. 
When in one position, if any side can find the process 
to win through TSS, this side can win through it. Because 
the rules of Connect6 allow the player to place two stones 
simultaneously except for the first move, TSS can be 
divided into double-threat TSS and single-threat TSS in 
Connect6. This paper uses T2 solution to represent the 
process to win through double-threat TSS and TSS 
solution to represent the process to win through 
single-threat TSS. 
 
     
Figure 1. A sudden-death position with T2 solution and 
its CTSS solution 
 
Figure 1 is an example of T2 solution. For this position, 
New Simulation Strategy of MCTS for Connect6 
Shi-Jim Yen and Jung-Kuei Yang 
Department of Computer Science & Information Engineeering, National Dong Hwa University, Hualien, 
Taiwan, R.O.C. sjyen@mail.ndhu.edu.tw 
67
 -93- 
3
C. Playout Strategy 
For sudden-death game, the key to win is to search for 
sudden-death position. When one side reaches this state, 
this side can win. Because Connect6 has enormous 
candidate moves in every position, this study thinks how 
to find the nearest sudden-death position from the initial 
search position is more important than to explore the 
endgame position.  
Therefore, this study limits the depth of playout 
according to the property of sudden-death game. 
D. Back-propagation Strategy 
Because this study not only uses playout to predict the 
leaf node, but also uses CTSS to search for double-threat 
moves, it includes the reporting-back of both situations. 
For the situation of reporting-back when CTSS finds 
the T2 solution, this study uses different Wins value 
based on the level of the evaluation node. This design is 
in order to highlight the importance of sudden-death in 
different level from the initial search position. 
From Figure 4, it is much important to find the 
sudden-death from level 2 to level 4. Therefore, this 
study decrease the Wins value based on the level of 
search tree. The Wins value of node A is greater than 
node B in Figure 4. 
This strategy is only used at when Attacker finds the 
CTSS solution. This study does not use this strategy on 
when Defender finds the CTSS solution. 
 
Figure 4. The strategy of expanding nodes from leaf node 
for MCTS in Connect6 
E. Conclusion for new simulation strategy 
There are four key points for the new simulation 
strategy which we proposed. 
1. It uses 2-Stage to develop candidate moves. 
2. It expands two level nodes in every simulation. 
3. It limits the depth of playout. 
4. It uses different Wins value when CTSS finds T2 
solution in different level. 
III. EXPERIMENT 
The experiment aims to analyze positions with T2 
solution and TSS solution, the accuracy and efficiency of 
new simulation strategy of MCTS. This study developed 
a new version of Kavalan 4.0, named Kavalan 4.1. 
Kavalan 4.0 was developed based on MCTS technique, 
and has participated in the 2010 Computer Olympiad, 
Connect6. Kavalan 4.0 wins the second prize in the 
tournament of 15th Computer Olympiad, Connect6. 
The puzzles this study used in experiment are obtained 
from Connect6 web site [3]. This study gathers the latest 
year puzzles, and obtains 30 puzzles for use as an 
experimental test benchmark for the algorithm. Among 
the 30 puzzles, this study excludes two, 2008-Q1-1-3 and 
2008-Q3-1-4, because they lack T2 or TSS solution. For 
the 28 puzzles, 13 questions belong to T2 solution, and 
15 belong to TSS solution. The classification of puzzles 
is showed in Table 1. 
 
TABLE 1. THE CLASSIFICATION OF PUZZLES 
T2 
solution 
2008-Q1-1-1 2008-Q1-1-2 2008-Q1-2-1 2008-Q1-2-2 
2008-Q1-2-4 2008-Q1-3-1 2008-Q1-3-2 2008-Q2-1-1 
2008-Q2-1-2 2008-Q2-2-1 2008-Q2-2-2 2008-Q3-1-1 
2008-Q3-1-2    
TSS 
solution 
2008-Q1-1-4 2008-Q1-1-5 2008-Q1-2-3 2008-Q1-2-5 
2008-Q1-3-3 2008-Q1-3-4 2008-Q1-3-5 2008-Q2-1-3 
2008-Q2-1-4 2008-Q2-1-5 2008-Q2-2-3 2008-Q2-2-4 
2008-Q2-2-5 2008-Q3-1-3 2008-Q3-1-5  
 
The experiments were performed on 2.0 GHz with 2 
GB of memory running Windows XP. The control 
variable of MCTS is assigned as Table 2. 
 
TABLE 2. THE CONTROL VARIABLE AND ITS VALUE 
Control Variable Value 
Maximum Probing Positions 60,000 
Probing Cells 12 
Exploration Coefficient 1.2 
Heuristic Value to double-threat moves 300 
The depth of playout 30 
Back-Propagation 
CTSS – Attacker Win 12 
CTSS – Attacker Fail -5 
Playout – Attacker Win 1 
Playout – Attacker Fail -1 
69
The Art of the Chinese Dark Chess Program DIABLE 
 
Shi-Jim Yen1, Cheng-Wei Chou2, Jr-Chang Chen3, I-Chen Wu4, Kuo-Yuan Kao5 
1, 2 Dept. of Computer Science and Information Engineering, National Dong Hwa University, Taiwan 
3Dept. of Applied Mathematics, Chung Yuan Christian University, Taiwan 
4Dept. of Computer Science, National Chiao Tung University, Hsinchu 30050, Taiwan. 
5Dept. of Information Management, National Penghu University, Taiwan 
1 sjyen@mail.ndhu.edu.tw, 2 d9721002@ems.ndhu.edu.tw, 3jcchen@cycu.edu.tw, 4 icwu@csie.nctu.edu.tw,  
5stone@npu.edu.tw 
 
Abstract. DIABLE is a famous Chinese dark chess program, which won the Chinese dark chess tournaments in TAAI 
2011, TCGA 2011, and TCGA2012 computer game tournaments. Chinese dark chess is an old and very popular game 
in Chinese culture sphere. This game is played with imperfect information. Most computer Chinese dark chess 
programs used alpha-beta search with chance nodes to deal with the imperfect information. DIABLE used a new 
nondeterministic Monte Carlo tree search model for Chinese dark chess. These tournament results show that the 
nondeterministic Monte Carlo tree search is promising for Chinese dark chess. 
 
Keywords: Chinese dark chess, Monte Carlo tree search, Chance node, Partially observable games, Nondeterministic 
action.  
I. Introduction 
DIABLE is a famous Chinese dark chess program, which won many Chinese dark chess tournaments. [7][22][23] Chinese 
dark chess, similar to Chinese chess, is a popular game played in oriental countries. Chinese dark chess is a two-player 
partially observable game. Most Chinese dark chess programs use the alpha-beta search with chance nodes [5], which 
usually explore only shallow levels because the chance nodes increase the branching factor massively. On the other hand, 
recent studies have shown that Monte Carlo Tree Search (MCTS) is an efficient algorithm not only for complete information 
games such as Go and Amazons [9][11][13], but also for some incomplete information games such as Poker, Kriegspiel, 
Backgammon and Phantom Go [2][8][16][1].  
DIABLE extends MCTS, by incorporating the chance node concept, to a nondeterministic search model that deals with 
partially observable information, and apply the new model to Chinese dark chess. During the simulation, MCTS may suffer 
from repetition situations which are not forbidden in Chinese dark chess. We also propose two concepts – “shorter 
simulation is better” and “prediction of game length” to solve this problem. 
The structure of this paper is organized as follows: Section 2 describes the rules of Chinese dark chess briefly. Section 3 
gives an overview of the alpha-beta search with chance nodes in Chinese dark chess. Section 4 presents our methods. Section 
5 demonstrates the experimental results and Section 6 makes conclusion. 
II. Chinese Dark Chess 
The kinds and quantities of pieces used in Chinese dark chess are the same as those used in Chinese chess. One player, 
called Red, owns sixteen red pieces, and the other, called Black, owns sixteen black pieces. The sixteen pieces for each 
player include one King (K/k), two Guards (G/g), two Ministers (M/m), two Rooks (R/r), two Knights (N/n), two Cannons 
(C/c), and five Pawns (P/p), where, in the parentheses, the upper-cased letters are for Red and the lower-cased letters are for 
Black. Table 1 shows the pieces of Chinese dark chess. The board size of Chinese dark chess is 4×8 squares, as shown in 
Figure 1(a). All the thirty-two pieces are placed face-down at the beginning of a game, as shown in Figure 1(b), and thus 
their states are all hidden (or face-down). 
 
  
8     
7     
6     
5     
4     
3     
2     
1     
 a b c d 
 
(a) (b) (c) 
Figure 1. (a) The board. (b) The initial state. (c) An example of the Cannon’s ability. 
 
K 
M 
c 
P 
R 
71
 
Figure 2. The Expectiminimax game tree for Figure 1(c). The possible types of the face-down pieces are P, k and g. 
Most programs in the past tournaments [5][7][22][23] used the game tree search with modified chance nodes or heuristic 
functions for flipping actions. As mentioned in [5], the weakness of the expectiminimax game tree in Chinese dark chess is 
that it takes too much time computing flipping actions. To avoid the exponential explosion in searching, the Chinese dark 
chess program FLIPPER, developed by Bo-Nian Chen and Tsan-sheng Hsu [5], considered chance nodes for flipping moves 
only at the first level of search tree. The articles in [17] and [19] used null move concept for flipping moves: searched two 
different trees, one including chance nodes at the first level and the other not, and then chose the better result between them. 
Furthermore, Shih and Lin [20] used a bitboard structure to improve the search efficiency. Lai [15] used Table 2 to give a 
weight to each face-down piece based on the adjacent face-up pieces.  
Table 2. The weights of face-down pieces (p) influenced by their neighboring face-up pieces (p'). 
p' weight 
of p' 
itself 
Weight of p (p' is the 
opponent’s / the 
player’s)  
Weight of p (p' is the 
opponent’s / the 
player’s), where p' is 
one-step-jump from p.  
King 55000 -5000/-5000 +100/-1000 
Guard 50000 -800/800 +100/-1000 
Minister 25000 -600/600 +100/-1000 
Rook 10000 -400/200 +50/-100 
Knight 8000 -200/100 +50/-100 
Cannon 30000 +200/-5000 -5000/500 
Pawn 8000 -5000/-500 +50/-100 
 
When the player neither captures nor flips any piece within forty plies, the game ends with a draw. Since it is difficult to 
search more than 40 plies in Chinese dark chess by game tree search, inefficient moves may cause the result to draw. For 
example, Red should spend at least 12 moves to capture one Black piece in the game shown in Figure 3. If there are more 
than 8 inefficient moves, Red will not be able to capture any Black piece and this game will be a draw. To avoid playing 
inefficient moves, Chen [6] used 5-men endgame databases to solve this problem. MODARK used the influence-value as in 
Table 3 to avoid inefficient moves. This value will be added into the evaluation of the game tree. For example, the 
influence-values of the attacker’s Guard to the defender’s Minister are 60. The influence-value list is 30, 60, 30, 15, 8, 4, 2, 
and 1 with respect to distance 1-8 from the Minister. The influence values for the Red Guard to the Black Minister are as the 
numbers in Figure 3. MODARK, developed by Lai and Yen, used the flipping heuristic as in Table 2 and the influence-value as 
in Table 3, won the first Chinese dark chess tournament in Computer Olympiad 2009 [24]. 
Table 3. The influence-value of Red piece vs. Black piece. 
 k g m r n c p 
K 120 108 60 36 24 48 0 
G 0 106 60 36 24 48 12 
M 0 0 58 36 24 48 12 
R 0 0 0 34 24 48 12 
N 0 0 0 0 22 48 12 
C 0 0 0 0 0 0 0 
P 108 0 0 0 0 0 10 
 
8 30   15 
7 60 30 60 30 
6 30 60 30 15 
5 15 30 15 8 
4 8 15 8 4 
3 4 8 4 2 
2 2  2 1 
1 1 2 1  
 a b c d 
Figure 3. An example of the influence-value. 
1/2 
a6(g) 
a6(?) 
1/4 
a6(P) 1/4 
a6(k) 
b5(?) b2(?) 
d2(?) 
… 
… … … … … 
… … 
… … 
G
   K
   
c5-a5  c5-c2  c5-c6 c5-d5 
m   n 
73
node n selects b2(?) action and then chooses k. Since the temporary state node k0 is a leaf node, the selection process stops, 
and Figure 7(b) shows the tree after the backpropagation stage. 
 
         
 
(a)                         (b) 
Figure 6. (a) The early stage of the tree in Figure 5. (b) The tree after the backpropagation. 
         
 
(a)                            (b) 
Figure 7. (a) The tree after Figure 6. (b) The tree after the backpropagation. 
In Figure 7, assume that node n selects b2(?) action and then chooses P again. Since P1 is not a leaf node (P1 has been 
visited once), it continues selecting the best child node of P1. Assume the a6(?) is selected and k is chosen as the temporary 
state. Node k0 is a leaf node and the selection process stops. The last tree in Figure 8 is the tree after the backpropagation.  
 
            
         
 
          (a)                  (b)                                           
 
Figure 8. (a) The trees after Figure 7. (b) The tree after the backpropagation. 
4.2 Simulation 
This stage will play the game from the position of the leaf node to the end, and obtain the simulation result, which is a win, 
draw or lose in Chinese dark chess. The result will be used in the backpropagation stage, as described in Section 4.3. The 
basic default policy of simulation only uses the “capture-first” heuristic (abbr. CF), that is “If there is some capturing move 
to capture the opponent's piece, choose the move. Otherwise, we randomly select a legal action”. The legal action includes 
moving action and flipping action. This paper proposes two other heuristics as follows. 
The “capture stronger piece first” heuristic (abbr. CSPF) gives each capturing move a weight. If there is more than one 
capturing move, the heuristic will assign a probability to each of these capturing moves. The probability distribution is based 
on the scores of the pieces which are under the capturing threats. The scores of piece types are shown in Table 4. For 
example, if Black can only capture Red King and Guard, the probabilities of capturing moves, Red King and Guard, are 
( 5500 / ( 5500 + 5000 ), 5000 / (5500 + 5000 ) ), respectively. If there is no capturing move, we randomly select a legal 
action. Another heuristic is the “capture and escape stronger piece first” heuristic (abbr. CESPF), which considers both 
capturing and escaping moves. The probability distribution is also based on the score of the related pieces, as in Table 4. 
 
b2(?)    … 
n
  
c2-a5 
…    
    
  k
1  g0 
a6(?)   
b2(?)    … 
n
    
c2-a5 
…
    
    
  k
0  g0 
a6(?)   
b2(?)    … 
n
    
c2-a5 
…    
    
  k
0  g0 
a6(?)   
b2(?)    … 
n
    
c2-a5 
…
    
    
… 
n
    
c2-a5 
…
    
    
b2(?)    … 
n
  
c2-a5 
…    
    
b2(?)    … 
n
    
c2-a5 
…    
    
b2(?)    … 
n
    
c2-a5 
…
    
    
… 
n
    
c2-a5 
…    
    
… 
n
    
c2-a5 
…    
    
… 
n
    
c2-a5 
…
    
    
Choose 
b2(P)    
Choose 
b2(k)    
Choose 
b2(P)    
Select 
a6(?) 
action 
Choose 
a6(k)    
b2(?)    b2(?)    b2(?)    
P0  k0  g0 P0  k0  g0 P1  k0  g0 
b2(?)    
P1  k1  g0 
P1  k1  g0 P1  k0  g0 P1  k0  g0 
P1  k1  g0 
P1  k1  g0 P1  k1  g0 
P2  k1  g0 
75
5.2   Shorter simulation is better 
In this part, the experiments are performed by changing the influence value d in formula (2) in Subsection 4.2. The times of 
games and simulations per move are the same as the setting in Subsection 5.1. The experimental results of changing the 
value d in Table 6 and Figure 10 show this concept is useful in Chinese dark chess. First, the average length of games 
becomes shorter with the increase of d. This demonstrates that this concept can avoid inefficient moves. Second, the 
performance with d = 0.01 outperforms those with d = 0, in terms of the win and loss rates. This shows this concept actually 
improves the strength of the Chinese dark chess program. Finally, the optimal value of d is 0.01. When d is larger than 0.01, 
the program is forced to select the shorter game length and ignores the result of the game. 
Table 6. The result of changing the d value. 
influence value d Average length of games Win Loss  Draw 
0 178.46 45.25% 13% 41.5% 
0.001 166.63 47.5% 9.5% 43% 
0.005 156.71 49.75% 9.75% 40.5% 
0.01 150.82 53.75% 7.75% 38.5% 
0.015 149.485 45.25% 10.25% 44.5% 
0.03 145.38 34.5% 16.25% 49.25% 
 
 
Figure 10. The result of changing the value d. 
5.3   Simulation heuristics 
Table 7 lists the comparison of the three heuristics, called CF, CSPF and CESPF in Subsection 4.3. The number of 
simulations is 10,000, and “shorter simulation is better” heuristic is used. There are 400 games; our program played 200 
games as being the first and the second players, respectively. The result of CESPF heuristic is the best. The loss rate of 
CESPF is 4.75% only. Table 6 also shows another interesting result: it favors the second player in Chinese dark chess. It is 
because the only choice for the first player in the beginning is a flipping action, which makes the second player have more 
information than the first player. 
Table 7. Comparison of the three heuristics in simulation. 
 Turn Win Loss Draw 
CF 
First 108 54.00% 15 7.50% 77 38.50% 
Second 107 53.50% 16 8.00% 77 38.50% 
Total 215 53.75% 31 7.75% 154 38.50% 
CSPF 
First 105 52.50% 14 7.00% 81 40.50% 
Second 108 54.00% 15 7.50% 77 38.50% 
Total 213 53.25% 29 7.25% 158 39.50% 
CESPF 
First 120 60.00% 9 4.50% 71 35.50% 
Second 126 63.00% 10 5.00% 64 32.00% 
Total 246 61.50% 19 4.75% 135 33.75% 
5.4   Scalability 
Table 8 and Figure 11 show the scalability of our program. As most MCTS programs, the win rate of the program grows as 
the number of simulations increases, but reaches a plateau after simulating 60,000 times. When the number of simulations is 
larger than 10000, the loss rate is below 5%. Then more simulations increase the winning rate and decrease the draw rate 
slightly. When the number of simulation is 240,000, it takes 30 seconds per move and the loss rate is only 1%. Our program 
with this setting is used to compare the three versions of the baseline program, named VAR1, VAR2 and VAR3 in [5], 
which are designed based on Alpha-Beta with three different flipping policies. Table 9 is the experimental results, and our 
program outperforms all the three versions. Compared to the results in Table 8, our version clearly decreases the draw rate 
and increases the win rate of the games. 
Table 8. Scalability of our program. 
Simulations Sec. / move Win Loss  Draw 
3000 0.4 38% 16. 5% 45.5% 
10000 1.25 61.5% 4.75% 32% 
20000 2.5 73.25% 3% 27.5% 
60000 7.5 81% 1.75% 17.25% 
240000 30 83.5% 1% 15. 5% 
30% 
50% 
0 0.01 0.02 0.03 w
in
ni
ng
 r
at
e 
d value 
77
[16] F. Van Lishout, G. Chaslot, J. Uiterwijk. “Monte-Carlo Tree Search in Backgammon,” Proceedings of the Computer Games Workshop 2007 (CGW 
2007), Amsterdam, The Netherlands, 2007, pp. 175-184. 
[17] W.-C. Lou, Artificial Intelligence Improvement of Chinese Dark Chess, National Taiwan Normal University, Master thesis, 2011. (in Chinese) 
[18] S. Russell and P. Norvig. Artificial Intelligence: A Modern Approach 2/e, Prentice Hall, 2003. 
[19] Y.-A. Shieh, The Design and Implementation of Computer Dark Chess, National Taiwan Normal University, Master thesis, 2008. (in Chinese) 
[20] H.-C. Shih and S.-S. Lin, “The Design and Implementation of Computer Dark Chess,” Proceeding of TCGA workshop 2012, Hualien, Taiwan, 2012. pp. 
29-36. (in Chinese) 
[21] J. Veness, K. S. Ng, M. Hutter, W. Uther, and D. Silver, “A Monte-Carlo AIXI Approximation,” J. Artif. Intell. Res., vol. 40, pp. 95–142, 2011. 
[22] J.-K. Yang, T.-C. Su and I-C. Wu, “TCGA 2012 Computer Game Tournament Report,” submitted to ICGA Journal, 2012. 
[23] S.-J. Yen, T.-C. Su and I-C. Wu, "The TCGA 2011 Computer-Games Tournament," ICGA Journal, vol. 34, no. 2, pp. 108–110, 2011. 
[24] S.-J. Yen, S.-Y. Chiu and I-C. Wu, " Modark Wins Chinese Dark Chess Tournament," ICGA Journal, vol. 33, no. 4, pp. 230–231, 2010. 
 
79
1Shi-Jim Yen
寄件者: ICGA Tournaments 2011 [icga@conftool.net]
寄件日期: 2011年11月1日星期二 下午 1:32
收件者: olivier.teytaud@inria.fr
副本: kapakapa@gmail.com; cabon1224@hotmail.com; hassen.doghmen@lri.fr; changshing.lee@gmail.com; 
tcsu@mail.ndhu.edu.tw; fabien.teytaud@gmail.com; ming1966@gmail.com; mh.alice.wang@gmail.com; ada7465
@gmail.com; sjyen@mail.ndhu.edu.tw
主旨: ACG13: Final Version 142 Received
Dear Dr. Olivier Teytaud, 
 
the final version of your contribution has been received. 
 
Submission Details 
================== 
Contribution ID: 142 
Type                      : Full Paper 
Title                    : Towards a solution of 7x7 Go with Meta‐MCTS 
Author(s)            : Teytaud, Olivier; Chou, Cheng‐Wei; Chou, Ping‐Chiang; 
Doghmen, Hassen; Lee, Chang‐Shing; Su, Tsan‐Cheng; Teytaud, Fabien; Teytaud, Olivier; Wang, Hui‐Min; 
Wang, Mei‐Hui; Wu, Li‐Wen; Yen, Shi‐Jim 
 
Uploaded Files 
============== 
1st file      : 77go.pdf 
Last Upload: 1st Nov 2011, 06:31:36am CET 
 
 
With best regards, 
Your ACG13 organizers. 
 
‐‐ 
Advances in Computer Games 13 
20‐22 November 2011, Tilburg University, The Netherlands info@icga.org 
https://www.conftool.net/acg13 
https://www.conftool.net/acg13/ 
 
 
Exact Komi in Go. In Go, two players play a game, leading to a partition of
the board into a black area, a white area, and possible a no-man’s land which
does not belong to anyone (so-called Seki). Black has won if its area is bigger than
White’s area (usually modified by a bonus, termed Komi, which is intended to
offset the advantage of Black who plays first). We here recall simple math around
Komi, showing that there exists a Komi such that the game, in case of perfect
play, is a draw.
Consider the 7x7 case. The board has size S = 49. Consider B the Black area
(i.e. the number of black stones plus the number of empty locations surrounded
by black stones, after removal of dead stones), and K the no-man’s land, i.e.
the Seki locations which do not belong to anyone. Then White score is W =
S−B−K. The difference between White and Black territory is (S−B−K)−B =
S −K − 2B. So the optimal strategy for Black consists in maximizing 2B +K.
If there is a number T such that B can ensure 2B + K = T (and no more than
this), then the difference between the territories is, in case of optimal play, S−T ;
if the Komi is S − T (this is an integer), this leads to a draw. The ideal Komi is
S − T .
This just shows that an ideal Komi exists, and that this Komi is an integer;
it does not tell us which Komi is the good one. If there is no Seki at optimal play,
then the Komi is odd in 7x7, because the board size is odd and 2B is certainly
even. It is widely assumed that the ideal Komi is 9 and we will see that our
results confirm this (but do not prove it).
2 Technical points
We present Monte-Carlo Tree Search in section 2.1 and Meta-Monte-Carlo Tree
Search in section 2.2. Section 2.3 will present the score functions used in our
Meta-MCTS algorithm, and Section 2.4 will discuss existing opening books for
7x7 Go.
2.1 Monte-Carlo Tree Search (MCTS)
Monte-Carlo Tree Search [5, 10] is an algorithm for 1-player or 2-player games.
A game is (here) a finite set of nodes, organized as a tree with a root. Each node
n is of one of the following types:
– max node (nodes in which the max player chooses the next state among
descendants);
– min node (nodes in which the min player chooses the next state among
descendants);
– terminal node; then, the node is equipped with a reward Reward(n) ∈ [0, 1];
In all cases, we note D(n) the set of children of node n. We assume, for the
sake of simplicity, that the root node is a max node. We will consider algorithms
which perform simulations; the first simulation is s1, the second simulation is s2,
etc. Each simulation is a path in the game, from the root to a leaf. Each node n
is equipped with:
Input: a game.
for t = 1, 2, 3, . . . (until no time left) do
st ← () // empty simulation
s = root(game) // the root of the game is the initial state
while s is not terminal do
st ← st.s // s is added to the simulation
switch s do
case max node
s← arg maxn∈D(s) score(n)
end
case min node
s← arg minn∈D(s) score(n)
end
end
// the arg min or arg max can be replaced by a -greedy rule
// or other stochastic rules
end while
st ← st.s // s is added to the simulation
end for
decision = arg maxn∈D(root) nt(n) // decision rule
Output: a decision, i.e. the node in which to move.
Fig. 1. A framework of Monte-Carlo Tree Search. All usual implementations fall in
this schema depending on the score function. The decision step is sometimes different,
without impact on our results. The score(.) function, when the number of simulations
is 0, defines the default policy (i.e. the policy when no statistics are available); when
the score function does not depend on numbers of wins and on numbers of simulations,
MCTS boils down to the old Monte-Carlo algorithms. We recall that D(n) is the
number of children of node n.
2.3 Scoring functions used in our Meta-MCTS
In our Meta-MCTS, as well as in classical MCTS, we use a different rule for
choosing moves when using our algorithm for really playing a game, than for
choosing moves when using our algorithm for building the tree. The two rules
are as follows:
1. play the move with highest empirical success rate. This rule is used for
playing a real game;
2. play the move with highest empirical success rate, if such a move has success
rate ≥ 10%; otherwise, choose a move by the default policy (in Meta-MCTS,
the default policy is a MCTS). This rule is used in self-play games aimed at
building the tree.
The reason for introducing the second rule is that the seemingly natural rule
1 is not consistent[16]. During the learning steps (i.e. for building the opening
book), it can concentrate on one move only, in spite of a success rate converging
– Black starts with a subset of the N Senseis variations.
– White is a MCTS algorithm possibly with opening book, and plays either
• no opening at all (pure MCTS algorithm), with probability 1/(N + 1);
• one (randomly and uniformly chosen) variation of Senseis’ opening, each
of them with probability 1/(N + 1).
Experimental results are provided in Fig. 2, Top (learning as Black) and Bottom
(learning as White). The main conclusions are:
Fig. 2. These curves are learning curves of Meta-MCTS. Top: learning as black (Komi
8.5). Bottom: learning as white (Komi 9.5). In both curves, the x-axis is log2(number
of simulated games). Each game is of order 2h; so the total learning time (distributed
on a cluster) is a few years of computation, distributed on Grid5000. The y-axis is the
moving average (window of size 55) of the winning rate. The Komi is 9.5 when the
learner is White and 8.5 when the learner is Black, so that if the right Komi is 9 then
the learner can possibly reach 100%. At the beginning, Meta-MCTS learns against
MoGoTW White with no opening; then variations of Senseis’ SGF file are used as
opening (they are randomly chosen, together with no opening at all); at this point the
success rate starts to decrease, but it quickly increases again close to 100%.
– Meta-MCTS quickly learnt against any fixed set of variations: the curve
increases, between each introduction of a new Senseis’ variation. This shows
– Second set of experiments: after the 20 games against pros, a variation
V was found by a pro and corrected by Shi-Jim Yen (6D); we reran a Meta-
MCTS for Black with Komi 8.5, against this specific variation. The Meta-
MCTS quickly found good moves (see Fig. 3).
Fig. 3. Left: a bad move by black (visible in games against variation V discussed in
Section 4): black E3 should be black E5. Middle: the correction, as found by Meta-
MCTS (after a long time) and by human Pro players - in this situation black has a safe
win. Right: the success rate of Meta-MCTS, when learning specifically on variation V .
All these experiments show that Meta-MCTS quickly adapts to given oppo-
nents: Fig. 2 shows that it could find good strategies against the MCTS algo-
rithm, and against Senseis’ variations; and Fig. 3 shows that it finds the solution
to a new variation found by human experts. However, Meta-MCTS needs some
external “coach”, i.e. here, first, Senseis’ variations, and, later, the variation V ,
for developing new knowledge in reasonable time.
Fig. 4. Left: here an opening which was not correctly played by MoGoTW as black;
fortunately for the bot, the human made a mistake and lost the game (see Fig. 5,
second game, played by Chun-Yen Lin 2P). Right: the game that the human should
have played in order to win.
References
1. L. V. Allis, “Searching for solutions in games and artificial intelligence,” Ph.D.
dissertation, The Netherlands: University of Limburg, 1994.
2. E. C. D. van der Woerf, J. W. H. M. Uiterwijk, and H. J. van den Herik, “Solving
ponnuki-go on small boards,” in GAME-ON, 2002.
3. E. C. D. van der Werf and M. H. M. Winands, “Solving go for rectangular boards,”
ICGA Journal, vol. 32, no. 2, pp. 77–88, 2009.
4. J.-T. Saito, G. Chaslot, J. W. H. M. Uiterwijk, and H. J. Van Den Herik,
“Monte-carlo proof-number search for computer go,” in Proceedings of the
5th international conference on Computers and games, ser. CG’06. Berlin,
Heidelberg: Springer-Verlag, 2007, pp. 50–61. [Online]. Available: 1
5. R. Coulom, “Efficient Selectivity and Backup Operators in Monte-Carlo Tree
Search,” In P. Ciancarini and H. J. van den Herik, editors, Proceedings of the
5th International Conference on Computers and Games, Turin, Italy, pp. 72–83,
2006.
6. T. Cazenave and A. Saffidine, “Score bounded monte-carlo tree search,” in Com-
puters and Games, ser. Lecture Notes in Computer Science, H. J. van den Herik,
H. Iida, and A. Plaat, Eds., vol. 6515. Springer, 2010, pp. 93–104.
7. P. Audouard, G. Chaslot, J.-B. Hoock, J. Perez, A. Rimmel, and O. Teytaud, “Grid
coevolution for adaptive simulations; application to the building of opening books
in the game of Go,” in Proceedings of EvoGames. Springer, 2009, pp. 323–332.
8. T. Cazenave, “Nested monte-carlo search,” in IJCAI, 2009, pp. 456–461.
9. J. Me´hat and T. Cazenave, “Combining uct and nested monte carlo search for
single-player general game playing,” IEEE Trans. Comput. Intellig. and AI in
Games, vol. 2, no. 4, pp. 271–277, 2010.
10. L. Kocsis and C. Szepesvari, “Bandit based Monte-Carlo planning,” in 15th Euro-
pean Conference on Machine Learning (ECML), 2006, pp. 282–293.
11. R. Coulom, “Efficient Selectivity and Backup Operators in Monte-Carlo Tree
Search,” In P. Ciancarini and H. J. van den Herik, editors, Proceedings of the
5th International Conference on Computers and Games, Turin, Italy, 2006.
12. G. Chaslot, M. Winands, J. Uiterwijk, H. van den Herik, and B. Bouzy,
“Progressive Strategies for Monte-Carlo Tree Search,” in Proceedings of the 10th
Joint Conference on Information Sciences (JCIS 2007), P. Wang et al., Eds.
World Scientific Publishing Co. Pte. Ltd., 2007, pp. 655–661. [Online]. Available:
papers\pMCTS.pdf
13. C.-S. Lee, M.-H. Wang, G. Chaslot, J.-B. Hoock, A. Rimmel, O. Teytaud,
S.-R. Tsai, S.-C. Hsu, and T.-P. Hong, “The Computational Intelligence of
MoGo Revealed in Taiwan’s Computer Go Tournaments,” IEEE Transactions
on Computational Intelligence and AI in games, 2009. [Online]. Available:
http://hal.inria.fr/inria-00369786/en/
14. E. Zermelo, “Uber eine anwendung der mengenlehre auf die theorie des
schachspiels,” in Proc. Fifth Congress Mathematicians. Cambridge University
Press, pp. 501–504.
15. R. Bellman, Dynamic Programming. Princeton Univ. Press, 1957.
16. V. Berthier, H. Doghmen, and O. Teytaud, “Consistency modifications for auto-
matically tuned monte-carlo tree search,” in Lion4, Italie venice, 2010, p. 14 p.
17. J. Davies, “7x7 go,” American GO Journal, vol. 29, no. 3, p. 11, 1995.
Games played respectively by Cheng-Jui Yu (3P),
Chun-Yen Lin (2P), Hsiang-Chieh Wang (1P),
Hsiang-Jen Huang (5P), Kai-Hsin Chang (4P),
Shao-Chieh Ting (2P), Ting-Yi Lin (1P), Yin-Nan
Chou (4P), Yu-Hsiang Lin (4P), Yu-Pang Kou (1P).
Fig. 6. Games played as white against pros.
98年度專題研究計畫研究成果彙整表 
計畫主持人：顏士淨 計畫編號：98-2221-E-259-021-MY3 
計畫名稱：電腦對局隨機演算法之研究 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 6 6 100%  
博士生 3 3 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 6 6 50%  
研究報告/技術報告 0 0 100%  
研討會論文 5 5 50% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
國科會補助專題研究計畫成果報告自評表 
請就研究內容與原計畫相符程度、達成預期目標情況、研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）、是否適
合在學術期刊發表或申請專利、主要發現或其他有關價值等，作一綜合評估。
1. 請就研究內容與原計畫相符程度、達成預期目標情況作一綜合評估 
■達成目標 
□未達成目標（請說明，以 100字為限） 
□實驗失敗 
□因故實驗中斷 
□其他原因 
說明： 
2. 研究成果在學術期刊發表或申請專利等情形： 
論文：■已發表 □未發表之文稿 □撰寫中 □無 
專利：□已獲得 □申請中 ■無 
技轉：□已技轉 □洽談中 ■無 
其他：（以 100字為限） 
3. 請依學術成就、技術創新、社會影響等方面，評估研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）（以
500字為限） 
蒙地卡羅上界信賴樹狀搜尋演算法對於對局類遊戲的發展，包括兵棋推演，都會有革命性
的影響，我們投入此研究，使得台灣在此方面不至落後。計畫的成果不僅可以幫助研發出
棋力高強的電腦對局程式，也可應用於電腦遊戲上，這些開發出的技術，也可幫助國內遊
戲廠商開發相關遊戲，提高國際競爭力。 
目前世界上流傳最廣的棋類有象棋、圍棋、西洋棋等，其中以圍棋人口為最多，象棋次之，
而六子棋則是新興遊戲。相關的數位內容發展，已漸漸成為華人世界的焦點之ㄧ。大陸的
各學術單位近年來對此著力頗深，已經有一年一度的省對抗電腦對局比賽及世界級的電腦
對局比賽，已漸漸威脅台灣在此方面的領先地位，本計劃可提升我們電腦對局研究團隊的
競爭力。 
計畫進行時，也開發出一些學術或技術上創新的 MCTS 相關搜尋演算法及其應用，及機器
學習理論，目前共有包括 IEEE TRANS.等級 的 SCI 期刊論文 6篇與 6篇包括 IEEE 等級的
研討會議論文發表，論文詳列於計畫結案完整報告。 
所研發製作出的電腦對局程式，三年來都有參加國際性的比賽，在日本主辦的國際奧林匹
亞電腦對局競賽共獲得四金二銀的佳績，金牌的項目包括象棋、暗棋、邏輯繪圖與點燈拼
圖，銀牌的項目則是六子棋與數牆。荷蘭主辦的國際奧林匹亞電腦對局競賽獲得一金二
銅，金牌的項目是象棋、銅牌為暗棋、NoGo。日本遊戲設計會議 2011 GPW 杯電腦圍棋比
賽 1 面銀牌。TCGA 2012 電腦對局比賽 3金(象棋、暗棋、Killall Go)， 2 銅(六子棋、
NOGO)，共計獲得 8金 3 銀 4 銅。在圍棋、象棋、六子棋與暗棋等，繼續保持在世界前兩
