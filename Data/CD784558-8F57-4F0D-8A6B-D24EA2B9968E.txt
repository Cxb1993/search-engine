摘要
近年來生物科技日漸蓬勃發展, 生物資訊更是引人注目。 分子生物學家於研究生物資訊時,
衍生出許多計算問題。 其中 「演化樹」 的建構問題更是生物學家研究的課題之一。 本計畫研究
三個與演化樹相關的問題: 最大同意子樹問題、 多基因重排問題、 以及最大一致樹問題。 這三
個問題的變形問題以及相對的問題解法,已經有著極為廣泛的討論和研究。我們計畫在兩年內
分別針對每個問題中特定的變形問題設計更有效率的演算法以及實作。本計畫在執行期間,已
經在 「最大同意子樹問題」、「最大一致樹問題」 和 「多基因重排問題」 的研究上, 有著極為不錯
的成果。針對 「最大同意子樹問題」 和 「最大一致樹問題」 問題,我們更設計出比前人更有效率
的演算法。 其中, 在 「最大同意子樹問題」的研究上, 我們的研究成果已經被期刊 Information
Processing Letters 所接受, 並且刊登在2005年的期刊上 (請參考附件一)。 在本報告中, 我們
將分別針對這三個問題的研究成果進行說明。
關鍵詞: 分支限制演算法, 多基因重排, 同意子樹, 一致樹, 演化樹
i
Contents
1 Introduction 1
2 The Maximum Agreement Subtree Problem 3
2.1 Bryant’s Algorithm for the MAST Problem . . . . . . . . . . . . . . . . . 6
2.2 A Faster Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8
3 The Maximum Consensus Tree Problem 11
3.1 A Branch-and-Bound Algorithm for the MCTT Problem . . . . . . . . . . 16
3.1.1 The branching method . . . . . . . . . . . . . . . . . . . . . . . . . 16
3.1.2 The persistent data structure . . . . . . . . . . . . . . . . . . . . . 19
3.1.3 The upper bound and the lower bound . . . . . . . . . . . . . . . . 22
3.1.4 The branch-and-bound algorithm . . . . . . . . . . . . . . . . . . . 33
3.2 The result of experiments . . . . . . . . . . . . . . . . . . . . . . . . . . . 37
3.2.1 The Environment of the Experiments . . . . . . . . . . . . . . . . 37
3.2.2 The Results of Running Time . . . . . . . . . . . . . . . . . . . . . 37
4 The Multiple Genome Rearrangement Problem 42
4.1 The Reversal Median Problem . . . . . . . . . . . . . . . . . . . . . . . . 47
4.1.1 An Algorithm for Finding an Exact Median . . . . . . . . . . . . . 51
4.1.2 Bounds . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51
4.1.3 The Upper Bound of Reversal Distance . . . . . . . . . . . . . . . 54
4.1.4 The Branch and Bound Algorithm . . . . . . . . . . . . . . . . . . 56
4.1.5 Implementation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59
4.1.6 Experimental Results . . . . . . . . . . . . . . . . . . . . . . . . . 62
4.2 The Reversal Phylogeny Problem . . . . . . . . . . . . . . . . . . . . . . . 70
4.2.1 Previous results of the multiple genome rearrangement problem . . 71
4.2.2 An exact algorithm for the reversal phylogeny problem . . . . . . . 81
iii
1 Introduction
Molecular biology has witnessed tremendous advances since the structure of DNA was
unraveled in 1953. Demands for sophisticate analysis of biological sequences are driv-
ing forward the newly created and explosively expanding research area of computational
molecular biology, or bioinformatics. There are several difficult problems in computational
molecular biology, or bioinformatics. Among them, the problem of constructing evolution-
ary trees is one of the fundamental tasks in computational biology because the evolution-
ary relationship of species provides a great deal of information about their biochemical
machinery. For example, RNA’s secondary structure is most accurately determined by
selecting correlated mutations of a class of related species. We focus on three important
problems that are encountered frequently in the study of computational molecular biology,
or bioinformatics: (1) the maximum agreement subtree problem, (2) the maximum con-
sensus tree problem, and (3) the multiple genome rearrangement problem. Many variants
and methods for them have been proposed and extensively studied. Among the variants
of these three problems, we concentrate on the maximum agreement subtree problem (the
MAST problem) for a set T of k rooted leaf-labelled trees on n leaves where T contains
a binary tree, the problem of finding a maximum consensus tree from rooted triples (the
MCTT problem), the reversal median problem (RMP), and the reversal phylogeny prob-
lem (RPP). The MCTT problem is a variant of the maximum consensus tree problem.
RMP and RPP are variants of the multiple genome rearrangement problem. RMP, RPP,
and the MCTT problem have been shown to be NP-hard. We use the branch-and-bound
techniques to develop algorithms for solving them. The MAST problem is polynomial-
time solvable for a set T of k rooted leaf-labelled trees on n leaves where T contains a
binary tree. We develop a new algorithm to improve the time complexity of the best
previously known one. In this project, we solve the problems mentioned above in two
years.
During past two years of this project, we have obtained the following achievements:
1
The first one has been written down in a paper and has been published in:
[1] Chuan-Min Lee, Ling-Ju Hung, Maw-Shang Chang, Chia-Ben Shen and
Chuan-Yi Tang , An improved algorithm for the maximum agreement subtree
problem, Information Processing Letters, Vol. 94, No. 5, 2005, 211–216.
The paper is included in this report as Appendix I. In the following, we show the research
details of our achievements for the maximum agreement subtree problem, the maximum
consensus tree problem, and the multiple genome rearrangement problem in Section 2,
Section 3, and Section 4, respectively. In Section 5, we make some remarks on our results.
2 The Maximum Agreement Subtree Problem
In biological research, evolutionary trees are often used to help understand the evolution-
ary history for a set of species and further explain the relationship among the species.
Let L be a set of species and |L| = n. With the assumption that all species evolve from
one common ancestor, an evolutionary tree T on L is a rooted , leaf-labelled tree such that
every leaf of T is uniquely labelled by an element of L, and every internal node of T has
at least two children. Constructing evolutionary trees is one of the fundamental tasks in
computational biology. There are many different approaches for constructing evolutionary
trees. Different methods may yield different trees for the same set of species. It leads
to the study of finding an agreement of different evolutionary trees for the same set of
species. When such an agreement has been obtained, we have different lines of evidence
to support that the agreement reflects the true evolutionary history on some species.
Definition 1. For a rooted tree T on set L and a subset X ⊆ L, T (X) is the minimal
subtree of T containing X by removing all nodes without descendants in X. For rooted
trees, we use the degree of a node to denote the number of its children. Let T |X be the
induced subtree of T by contracting every edge incident with a degree 1 node in T (X)
into its child.
Figure 1 shows a rooted tree T with leaves labelled by {a, b, c}, T (X) and the induced
3
T1
T2 T3
T
a a a
a
bb b
b
dc c cd d
d
ee e
e
Figure 2: T is a maximum agreement tree for {T1, T2, T3}
degree is NP-hard [1]. For other variants of the MAST problem, a number of efficient
algorithms have been developed [1, 3, 4, 6, 7, 8, 9, 13, 14, 17]. Consider the MAST
problem for a set T of k rooted leaf-labelled trees on n leaves where at least one tree has
maximum degree d. For this type of the MAST problem, Farach et al. gave an algorithm
solving the problem in O(kn3 +nd) time [7]. Bryant proposed another algorithm to solve
the problem in the same time complexity [3].
In this project, we focus on the MAST problem for a set T of k rooted leaf-labelled
trees on n leaves where T contains a binary tree. Binary trees are important models for
constructing evolutionary trees over species because in nature, it is rare that more than
two species evolved simultaneously from one ancestor. There are many results of inferring
evolutionary trees under the model of binary trees (see [10]). In [4], Cole et al. mentioned
the importance of the model of binary trees from the biological taxa case. Therefore,
the task of reaching an agreement of evolutionary trees where one of them is binary is
of great importance. This variant of the MAST problem can be solved in O(kn3) time
by the algorithms given by Farach et al. [7] and Bryant [3], respectively. We show that
the O(kn3)-time dynamic-programming algorithm proposed by Bryant [3] can be imple-
mented in O(kn2 + n2 logk−2 n log log n) and O(kn3−
1
k−1 ) time by using multidimensional
5
a a a ab c b b bc c c
Figure 3: All rooted trees of three leaves with leaves labelled by {a, b, c}.
Definition 6. A rooted triple ab|c fits a rooted tree T if the path from a to b does not
share any vertex with the path from c to the root. The set r(T ) is the set of rooted triples
that fits T . The rooted triple set R of T is the set ⋂1≤i≤k r(Ti).
Notice that T contains a binary tree Tk. Any induced subtree of Tk is still binary.
Therefore, any agreement subtree T of T is binary and any three species in T do not share
the same lowest common ancestor. An agreement subtree of T can be found by considering
only the binary induced subtrees of each evolutionary tree in T . Consequently, we can
restrict our attention only to the rooted triple set R of T . The following two lemmas are
shown in [3].
Lemma 1. [3] A tree T is an agreement subtree for T if and only if r(T ) ⊆ R.
Lemma 2. [3] If a 6= b, then
mast(a, b) = max{mast(a, x) : x ∈ A}+max{mast(b, y) : y ∈ B}
where A = {x : ax | b ∈ R} ∪ {a} and B = {y : by | b ∈ R} ∪ {b}.
Based upon Lemma 2, we have the following procedure to compute mast(a, b):
Procedure mast
1. If a = b then return 1
2. Choose x∗ ∈ {x : ax | b ∈ R} ∪ {a} that maximizes mast(a, x∗)
3. Choose y∗ ∈ {y : by | a ∈ R} ∪ {b} that maximizes mast(b, y∗)
4. Return mast(a, x∗)+mast(b, y∗)
7
Definition 9. For a ∈ L and ~ab ∈ {~a}, let the weight of vector ~ab, denoted by w(~ab), be
mast(a, b). Therefore w(~ab) = w(~ba) for a, b ∈ L.
By Theorem 3, choosing an x∗ ∈ {x : ax|b ∈ R}∪ {a} that maximizes mast(a, x∗) and
a y∗ ∈ {y : by|a ∈ R}∪{b} that maximizes mast(b, y∗) in Bryant’s algorithm become find-
ing a vector ~ax ∈ {~a} with maximum weight among all vectors in {~a} and dominated by
~ab, and a vector ~by ∈ {~b} with maximum weight among all vectors in {~b} and dominated
by ~ba, respectively. And w(~ab) = w(~ba) = w(~ax) + w(~by). Based upon this observation,
we give the following algorithm:
Algorithm MAST
Input: A set T = {T1, . . . , Tk} of k rooted leaf-labelled trees on a set L of n elements,
and Tk is a binary tree.
Output: A maximum agreement subtree for T .
Step 1: For each pair (x, y) ∈ L × L, compute ~xy.
Step 2: [Initialization.] For each a ∈ L and ~ab ∈ {~a}, w(~ab) = 1 if a = b; otherwise
w(~ab) = 0.
Step 3: For all pairs (a, b) ∈ L×L in the partial order of the domination relation in tree
Tk do:
1. Find a vector ~ax ∈ {~a} with maximum weight among all vectors in {~a} and domi-
nated by ~ab and find a vector ~by ∈ {~b} with maximum weight among all vectors in
{~b} and dominated by ~ba.
2. Set mast(a, b) = w(~ab) = w(~ba) = w(~ax) + w(~by).
Step 4: Return max{mast(a, b) : (a, b) ∈ L × L}.
We see that Step 3 can be supported efficiently by any multidimensional range search
data structure. For more information on multidimensional range search data structures,
refer to [16]. To use a more efficient data structure to speedup the algorithm, we modified
Step 2 and 3 in the above algorithm as follows:
9
in O(kn2 + n2 logk−2 n log log n) time using the data structure proposed by Gabow et. al.
for orthant searching for maximum with activation [12].
Notice that the multidimensional binary search tree [2, 15, 16] can also support the
operations we need in Step 2’ and 3’. It supports the following three operations: updating
the weight of an inactive vector in constant time, activating a vector (i.e. set the state of
a vector active) in O(d log n) time, and finding a vector with maximum weight among all
active vectors dominated by a query vector in O(dn1−
1
d ) time where d is the dimension
of vectors. Such a data structure can be constructed in O(dn) storage and O(dn log n)
preprocessing time. By using this data structure, Step 2’ can be done in O(kn2 log n)
time and Step 3’ can be done in O(n2(kn1−
1
k−1 )) time since d = k − 1 and we construct
n such data structures and make n2 queries. Hence, we have the following theorem.
Theorem 5. Let T = {T1, . . . , Tk} be a set of k rooted leaf-labelled trees on a set L of n
elements, where k ≥ 2 and Tk is a binary tree. The MAST problem on T can be solved in
O(kn3−
1
k−1 ) time using the multidimensional binary search tree proposed by Bentley [2].
3 The Maximum Consensus Tree Problem
An evolutionary tree is represented as the relationship among a set of species, and rooted
binary trees with three species are called as rooted triples. A rooted triple (a(bc)) means
that lca(a, b) = lca(a, c) is an ancestor of lca(b, c), in which lca(a, b) represents the lowest
common ancestor of a and b. Biologists often want to combine many evolutionary trees
into a single and bigger one and get more information from it. There are many methods
for combining the evolutionary trees [27, 29], and one of the methods is the consensus
tree method that is used in this project. Given a set of rooted evolutionary trees G =
{t1, t2, ..., tm}, the consensus tree problem is to find a rooted evolutionary tree T such that
the relationship among these species in ti are also represented in T for i = 1, 2, ...,m. In
other words, the consensus tree problem is to find a rooted tree T that satisfies all input
trees from t1 to tm. We say T satisfies ti when ti is topologically equivalent to a subtree
11
The exact algorithm ExactMCTT [20] for the MCTT problem was given by Bang-Ye
Wu. This algorithm uses the dynamic programming strategy. The time complexity of this
exact algorithm is O((m+ n2)3n), where m is the number of triples and n is the number
of species. The detail will be introduced in the next section. In 2004, Ming-Chang Dong
gave the other exact algorithm BBMCTT [18]that uses the branch-and-bound algorithm.
In this project, we improve BBMCTT by using a persistent data structure that will be
introduced in section 3.1.2 . With a persistent data structure, we can enhance the speed
of branching and save more memory space. So, in the following sections, we will show
how the persistent data structure help us to improve the branch-and-bound algorithm.
Because the MCCT problem is NP-hard [20], the heuristic algorithm was desired.
The heuristic algorithm Dynamic-programming-With-Pruning [19], or DPWP, was also
proposed by Bang-Ye Wu. This algorithm uses the dynamic programming that is similar
to the exact algorithm ExactMCTT. The complexity of DPWP is O(n2K2(n3 +K)), in
which K is a number from the input. So, if K is bigger, DPWP needs more time to
compute the answer. However, the answer is more precise if K is bigger. In this project,
we use DPWP to evaluate the initial lower bound for the branch-and-bound algorithm.
In the following, we introduce the heuristic algorithms DPWP and the exact algorithm
ExactMCTT. These two algorithms are used as tools in the branch-and-bound algorithm
BBMCTT.
Definition 10. Given a set of rooted triples G={t1, t2, . . . , tm} and a set of species
S={s1, s2, . . . , sn}, the maximum consensus tree T is a rooted binary tree that satisfies
the triples in G as many as possible.
In the following, we define some notations and introduce the exact algorithm ExactM-
CTT.
Definition 11. Let V ⊂ S, B(V ) is the set of all bipartitions of V . For example, if
V = {1, 2, 3}, B(V ) = ({1, 2}{3}, {1, 3}{2}, {2, 3}{1}).
In the maximum consensus tree, each leaf denotes a species. We label each internal
node z with the leaves of the subtree rooted at it. If there is an internal node that is labeled
13
Algorithm 1 The exact algorithm for MCTT algorithm
ExactMCTT(G, S)
Input: a rooted triples set G, nonempty set S of species containing all species in G. All triples
are stored in a matrix M of lists. M [i, j] is a list of elements of set {x | (x(ij)) ∈ G}
Output: a rooted binary tree T satisfying with as many triples in G as possible.
1: Step 1: Compute the maximum of satisfied triples.
2: for i = 1 to n do
3: for each subset V with cardinality i do
4: for each bipartition (V1, V2) of V do
5: Compute w(V1, V2) by counting the number of elements in M [i, j]\V for each i ∈ V1
and j ∈ V2;
6: end for
7: score(V ) = max{score(V1) + score(V2) + w(V1, V2)}, in which the maximum is taken
over all bipartitions of V .
8: Record the best bipartition of V at Partition(V ).
9: end for
10: end for
11: Step 2: Construct the tree by backtracking Partition(S).
12: Start from V = S.
13: If V contains only one species, create a leaf vertex for it.
14: Otherwise recursively construct trees T1 and T2 for V1 and V2 respectively, where (V1, V2)
is the best bipartition of V recorded at Step 1.
15: Step 3: Output the tree.
15
Algorithm 2 The heuristic algorithm for MCTT problem
DPWP(G, S,K)
Input: A rooted triples set G, nonempty set S of species containing all species in G. A valueK.
All triples are stored in a matrix M of lists. M [i, j] is a list of elements of set {x|(x(ij)) ∈ G}
Output: a rooted binary tree T .
1: Array Q1 contains all subsets of singleton, and Qi is empty for 2 6 i 6 n.
2: For each subset V in the arrays, score2 is the currently best score and partition(V ) is the
bipartition corresponding to score2(V ).
3: for i = 1 to n− 1 do
4: for j = 1 to i do
5: for each V1 in Qi and V2 in Qj do
6: Compute the score2(V1, V2);
7: Search Qi+j for V = V1 ∪ V2;
8: If V exists, keep the better score
9: else put V into Qi+j ;
10: If |Qi+j| > K, delete the set with smallest score;
11: end for
12: end for
13: end for
14: Construct the tree by backtracking partition(S).
15: Output the tree.
17
Algorithm 3 Construct a consensus tree from a consistent set of rooted triples
OneTree(G, S)
Input: a rooted triples set G , nonempty set S={s1, s2, . . . , sn} over G.
Output: a rooted binary tree T .
1: Create a vertex v.
2: If n = 1, set T = v with species s1 and return. If n = 2, create T by attaching two new
vertices to v, label them s1 and s2 return.
3: Create sets Ai = {si}, i = 1, . . . , n.
4: For each triple (a(bc)), merge the two sets Ai and Aj containing b and c (if i 6= j).
5: If there is now only one set Ai, set T = ∅ and return.
6: For each set Ai, set G
′ :=the set of triples containing only those species in Ai, and call
T ′ =OneTree(G′, Ai). If T
′ = ∅, then set T = ∅ and return. Otherwise, attach the root of
T ′ to v which is the root of T .
G(4) = {(3(45))} and G(5) = {(3(45)), (5(21)), (3(51))}. m(1)=3, m(2)=2, m(3)=3,
m(4)=1, and m(5)=3.
When we implement this algorithm, we assume m(1) ≥ m(2) ≥ . . . ≥ m(n). If the
input species set do not satisfy this inequality, we relabel the species such that the species
set can satisfy it.
Definition 17. Denote U(j) = {t ∈ G | S(t) = {i, j, k} and i < j < k}. For example the
triple (4(35)), species 4 is the median. So the triple (4(35)) ∈ U(4). If there are n species
in G, the input triples G is divided into n-2 sets from U(2) to U(n − 1).
3.1.2 The persistent data structure
In this project, we use the branch-and-bound algorithm with persistent data structure
to solve the MCTT problem. With the persistent data structure, we can enhance the
speed of branching and save more memory space. In Figure 6, the node x in branch-and-
19
mn
o
p q u
m
n
Tx
create_stack
fp
1 2 3
m
n
o
p q u
Tx
1 2 3 4
s
m
n
o
p q u
Tx
1 2 3 4
s
tnode
m
n
create _stack
fp
Figure 7: Create the first child for node x
bound tree was branched. Using the persistent data structure, the children of x share the
common nodes with Tx. If the persistent data structure is absent, it needs 40 new tree
nodes to generate the five children of x. However, with the persistent data structure, it
only needs 17 new tree nodes to generate them. So, we can save more memory space and
solve the instance with more species. Because it needs fewer new tree nodes to generate
the children, we can branch the node x faster. In the following sections, we will show how
the branch-and-bound algorithm work on this persistent data structure.
In Figure 7, we want to branch node x and generate all children of x. At the beginning,
we push the root of Tx, say m, and the left child of root, say n, into a empty stack
create stack. Now, we start to create the first child step by step as follows. The procedure
of branching will generate the other children of node x continuously. The procedure was
shown in Algorithm 4.
(1) Push the root m and the left child of root n into create stack. Set v = m
21
Algorithm 4 Branch
Input: The branch-and-bound tree node d.
Output: All children of node d in the branch-and-bound tree.
1: Set v to be the root of Td, push v into create stack
2: Set v to be the left child of v; push v into create stack
3: while true do
4: while v is not null do
5: Create a tree node s; let pointer fp point to the top of create stack
6: temp = create stack(fp) ; fp = fp− 1
7: Let temp and the new species be the children of s
8: while fp dose not point to the bottom of stack do
9: temp = create stack(fp) ; fp = fp− 1
10: Create a tree node tnode corresponding to temp.
11: Decide the left child and right child of tnode
12: end while
13: Let v be the left child of v.
14: if v is not null, push v ito create stack
15: end while
16: temp = create stack.pop() ; temp1 = create stack.pop();
17: while temp is the right child of temp1 do
18: temp = temp1 ; temp1 = create stack.pop()
19: end while
20: If create stack is empty, break;
21: v = temp1 ; push v to create stack
22: Let v be the right child of v ; push v into create stack
23: end while
23
GG (S )01 3 G (S )2 3 G (S )3 3
1 2 3
Nodex
N=6
r(x)=3
S(Tx)=S ={1,2,3}3
Tx
G={ (1(23)) , (3(45)) , (4(12)),
(4(51)) , (2(56)) , (1(25)) , (1(36))
, (2(35)) }
(3(45))
(4(51))
(2(56))
(4(12)) (1(25))
(1(36)) (2(35))
(1(23))
G (S ) G(4)2 3 Ç G (S ) G(5)2 3 Ç G (S ) G(6)2 3 Ç
(1(2 )) (2(3 ))5 5 (1(3 ))6( (12))4
m
n
Figure 9: According to S3, the input triple set G was divided into three subsets G01(S3), G2(S3)
and G3(S3).
on how to compute δ(Tx, G3(Sr(x))), δ(Tx, G2(Sr(x))) and δ(G01(Sr(x))) for node x.
Definition 21. Let I(Tx, e, a) denote the evolutionary tree T
′ that is generated by in-
serting the species a at edge e of Tx.
Theorem 7. Let y be the child node of x in the branch-and-bound tree and Ty = I(Tx, e, i)
where i = r(x) + 1. δ(Ty , G3(Si)) ≤ δ(Tx, G3(Sr(x))) + δ(I(Tx, e, i), G2(Sr(x)) ∩G(i)).
In Figure 9, the only one triple in G3(S3) is (1(23)) that is not consistent with Tx, so
δ(Tx, G3(S3)) = 0. For an edge in Tx, let Ty be I(Tx, e, 4) and G
′ be the maximum subset
of G2(S3) ∩G(4) such that G′ ∪ {Ty} is consistent. In this case, Ty satisfies (4(12)), the
only one triple in G2(S3) ∩ G(4) , so G′ = {(4(12))}. Therefore, Ty satisfies the triples
in G′. However, G3(S4) = G3(S3) ∪ (G2(S3) ∩G(4)), so δ(Ty, G3(S4)) = δ(Tx, G3(S3)) +
δ(I(Tx, e, 4), G2(S3) ∩G(4)) = 0 + 1 = 1.
Definition 22. G2(Sr(x)) =
⋃n
j=r(x)+1G2(Sr(x)) ∩G(j).
25
wz
a
Tx
b
a b j
Figure 10: To satisfy (a(bj)) , j must be inserted at edge e that is in the left of z.
w
z
b
Tx
a
a b j
Figure 11: To satisfy (a(bj)) , j must be inserted at edge e that is in the right of z.
27
1 2 3 4
G (S )2 4
G (S ) G(5)2 4 Ç G (S ) (6)2 4 Ç G (S ) G(7)2 4 Ç
(1(35))
(5(23))
(3(54))
(4(52))
(2(36))
(6(21))
(3(64))
(4(61))
(2(74))
(7(31))
(3(74))
(3(72))
m
n
p
G (S )01 4G (S )3 4
G
d u k v
Figure 13: W lz,W
r
z and W
A
z
of triples (a(bj)), in which j must be inserted at edge that is in the left of z = lcaTx(a, b). In
formal, W zl [j] is the number of triples in G
′ where G′ = {(a(bj))|j /∈ Sr(x), z = lcaTx(a, b)
and b ∈ S(Tx(l))}. In Figure 13, the lowest common ancestor of species 4 and species 2
is p. To satisfy (4(52)), 5 must be inserted at edge e that is in the left of p, so it causes
W pn [5] to be increased by 1.
For each internal node z in Tx, let r be the right child of z. W
z
r [j] is the number of
triples (a(bj)), in which j is not in Sr(x) and j must be inserted at edge e ∈ E(Tx(r)) or
e = (z, r) for consistency. Otherwise, W zr [j] is the number of triples (a(bj)), in which j
must be inserted at edge e that is in the right of z = lcaTx(a, b). In formal, W
z
r [j] is the
number of triples in G′ where G′ = {(a(bj)) | j /∈ Sr(x), z = lcaTx(a, b) and b ∈ S(Tx(r))}.
In figure 13, the lowest common ancestor of species 1 and species 3 in Tx is n, To satisfy
(1(35)), 5 must be inserted at edge e that is in the right of n, so it causes W nk [5] to be
increased by 1.
For each internal node z in Tx, W
z
A[j] is the number of triples (j(ab)), in which j is not
in Sr(x) and j must be inserted at edge e where e ∈ E(Tx) and e /∈ E(Tx(z)). Otherwise,
W zA[j] is the number of triples (j(ab)), in which j must be inserted at edge e that is in
29
1 2 3 4 1 2 3 45
Tx Ty
m
n
p
k
vu
U(5)
(6(25))
(3(65))
(5(74))
t
R
Figure 15: Update the three arrays of internal nodes in Ty
in Tx. SW
R
A [j] is also can be defined as follows.
SWRA [j] =
∑
u∈N(Tx)
W uA[j].
Theorem 10. Assume T ′ = I(Tx, e, j) where e = (z,w) and z is the parent of w. Let
P (w) be the path from w to the child of R in Tx. Notice that R is the root of Tx. Then
δ(T ′, G2(Sr(x)) ∩G(j)) = SWRA [j] +
∑
(u,v)∈P (w) W
u
v [j]−
∑
(u,v)∈P (w) W
u
A[j].
According to Theorem 10, we can compute δ(I(Tx, e, j), G2(Sr(x)) ∩ G(j)) for each
edge e in Tx, and the maximum one is the value of δ(Tx, G2(Sr(x))∩G(j)). We know that
δ(Tx, G2(Sr(x))) =
∑n
j=r(x)+1 δ(Tx, G2(Sr(x)) ∩G(j)). However, δ(Tx, G2(Sr(x)) ∩G(j)) is
computed for j > r(x), so δ(Tx, G2(Sr(x))) is also computed.
In Figure 15, the node x is branched, and let y is a child of x. How do we decide the
value of arrays W zl , W
z
r and W
z
A for each internal node in Ty? At first, the three arrays
of m are copied to the corresponding node p in Ty, and the three arrays of n are copied
to the k. We initiate the three arrays of node v. Then we modify the three arrays for
each node z ∈ N(Tx). But, how to modify them? When x is branched, only the triples
in U(r(y)) was moved from G01(Sr(x)) to G2(Sr(y)). So, for z ∈ N(Ty), the three arrays
of node z are only modified by the triples in U(r(y)). For the triple (j(ab)) ∈ U(r(y)),
j must be inserted into the edge e that is in the outside of z = lcaTy(a, b), so W
z
A[j] is
31
is called for G3 recursively. The detail of GUN is shown in Algorithm 5.
For each level i in branch-and-bound tree, G is divided into three subsets fromG3(Si+1)
toG01(Si+1) because the species set in the level i is Si+1. So we can computeGUN(G01(Si+1))
for each level i before the branch-and-bound algorithm and store GUN(G01(Si+1)) in
C[i+ 1].
Theorem 11. For the node x in the branch-and-bound tree, UB(x) =
δ(Tx, G3(Sr(x))) + δ(Tx, G2(Sr(x))) + C[r(x)] ≥ δ(Tx, G3(Sr(x))) + δ(Tx, G2(Sr(x)))
+ δ(G01(Sr(x))) ≥ δ(Tx, G).
The following formula is used to compute the lower bound for the nodes in the branch-
and-bound tree.
LB(x) = δ(Tx, G3(Sr(x))) + δ(Tx, G2(Sr(x))).
3.1.4 The branch-and-bound algorithm
At beginning, the value of dpwp(S,G, 100) is used as the initial value of IB where IB is
the current best lower bound. In the branch-and-bound tree, the species set of the nodes
that are in the level i is Si+1 = {1, 2, · · · , i+ 1}. In Figure 5, the species set of the nodes
that are in level 2 is S3 = {1, 2, 3}. So G is divided into three subsets from G3(S3) to
G3(S3) in level 2. So G is divided into three subsets from G3(Si+1) to G3(Si+1) in level
i. Therefore, before entering branch-and-bound algorithm, C[i+1] is computed for each
level i. Our algorithm uses a variation of Depth-First search strategy to branch the nodes
in the branch-and-bound tree. If a node x is branched, all children of x are generated,
and the child with maximum upper bound is selected to branch continuously. We use a
priority queue Q to implement it. If the node x is branched in level i, we push the children
of x into Q. We set the priority of each child y of x as 100000 ∗ (i+1)+UP (y), in which
UP (y) is the upper bound of y. So we select the node with maximum priority in Q to
branch.
Under the condition UB(y) ≤ IB, y is not branched because it represents that the
children of y are impossible to get a better answer than IB. Under the condition UB(y) >
33
xy
Level1
Level 2
Level 3
2*1 -1=1
2*2 -1=3
2*3 -1=5
Figure 16: The maximal number of nodes that are in the priority queue for level i is 2 ∗ i− 1
IB, y is branched unless y is a leaf. However, if y is a leaf, y will not be branched, and
IB will be updated by UP (y). In addition, if LB(y) > IB, IB will be updated by LB(y).
So y is not branched if one of the following cases occur.
1. When UB(y) ≤ IB, y is not branched because it represents that the children of y
are impossible to get a better answer than IB.
2. Under the condition UB(y) > IB, if y is a leaf of branch-and-bound tree, y is also
not branched. In this case, IB is updated by UP (y).
Observation 4. Because we use the variation of Depth-First search strategy to branch
the nodes, we will push at most 2 ∗ i− 1 nodes into priority queue Q for level i. However,
there are n−1 levels in the branch-and-bound tree, so the maximum number of nodes that
can be in priority queue Q simultaneously is
∑n−1
1 (2 ∗ i− 1) = (n− 1)2.
35
n 10 11 12 13 14 15 16 17
# of instances 10 10 10 10 10 10 10 10
ExactMCTT 1 1 1 1.91 6.76 24.1 85.1 300
BBMCTT 1 1 1.9 4.72 7.75 16.6 141.62 79.77
PersistentMCTT 1 1 1 2.06 3.06 8.63 37.7 50.7
n 18 19 20
# of instances 5 5 3
ExactMCTT 1045 3632 12650
BBMCTT 649 594 2119
PersistentMCTT 232 524 1009.67
Table 1: The average running time (seconds) for different numbers of triples with m = 25.
3.2 The result of experiments
3.2.1 The Environment of the Experiments
We have implemented the algorithm PersistentMCTT in C++ programming language
on a personal computer equipped with Intel Pentium 4-2.4GHz CPU and 768M bytes
memory. The operating system is Fedora Core 4 that is a Linux operating system, and
the compiler we use is g++ of GNU. The input triples are generated randomly.
3.2.2 The Results of Running Time
Let m be the number of triples and n be the number of species. The x-axis of following
figures denotes the number of species, and y-axis denotes the running time.
37
n 10 11 12 13 14 15 16 17
# of instances 10 10 10 10 10 10 10 10
ExactMCTT 1 1 1 1.91 6.8 24 85.1 300
BBMCTT 1 2.2 3.2 12.2 33.2 83.76 298.3 375
PersistentMCTT 1 1 1.1 4.4 10.96 28.9 128.3 184.3
n 18 19 20 21
# of instances 5 5 3 3
ExactMCTT 1045 3632 12650 -
BBMCTT 11550.5 5004.67 14716 119672
PersistentMCTT 1696.4 3642.67 7734 53042
Table 2: The average running time (seconds) for different numbers of triples with m = 50.
n 10 11 12 13 14 15 16 17
# of instances 10 10 10 10 10 10 10 10
ExactMCTT 1 1 1 1.92 6.77 24.1 85.1 300
BBMCTT 1 2.6 7.1 42.16 126.13 550.96 1706.1 13435.9
PersistentMCTT 1 1 1.9 10.5 26.9 112.93 514.4 2323.4
n 18 19
# of instances 5 5
ExactMCTT 1045 3632
BBMCTT 6528 74034.7
PersistentMCTT 4837 15523
Table 3: The average running time (seconds) for different numbers of triples with m = 100.
39
 1
 10
 100
 1000
 10000
 100000
 10  11  12  13  14  15  16  17  18  19
Ti
m
e/
se
c
number of species
BBMCTT
PersistentBBMCTT
ExactMCTT
Figure 19: For each test data, the number of input triples is 100. The number of species of test
data is between 10 to 19.
41
organisms.
Mathematical Models. In the Genome Rearrangement Problem we use the noun
operations to represent mutations on evolution. The operations of genome rearrangement
can be separated into Intra-chromosomal events and Inter-chromosomal events, as follows:
1. Intra-chromosomal events
• Reversal [57]: Inversion of a contiguous segment of genes from 5’ → 3’ to 3’ →
5’ or from 3’ → 5’ to 5’ → 3’.
• Transposition [75]: A portion of the chromosome is broken and placed else where
in the same chromosome.
• Block-Interchange [43]: Two non-intersecting gene segments of any length are
swapped in the chromosome. It can be viewed as a generalization of transposi-
tion.
• Transversal [65]: A transversal is an operation composed of a transposition and
a reversal.
2. Inter-chromosomal events
• Translocation [61]: Gene segments are exchanged between two chromosomes.
Fusion and fission are special cases of translocations, where
• fusion is to let two chromosomes fuse into one; and
• fission is to let one chromosome broken into two.
Although from literal meaning, it seems that a genome rearrangement problem and a
typical sorting problem are not equivalent, rearrangement within a single chromosome’s
genome can easily turn into a sorting problem. A genome of n genes can be described
as a permutation π = (π1, ..., πn) on the integers {1, ..., n}. Each πi represents a gene
in the given genome and we usually assume that each number appears once. There are
two kinds of permutations: signed and unsigned. In a signed permutation, each element
of the permutation has an additional sign, the sign represent the direction of gene in
chromosome. Suppose our two species have the chromosomes as shown in Figure 20. We
can number the genes from left to right in the first species (turnip) and then use the same
43
Definition 25. [54] The minimum number of reversals needed to transform one permuta-
tion σ to another permutation τ is called the reversal distance d between them. It is equal
to find the reversal distance between τ−1 · σ and the identity permutation ι (Here, τ−1 is
an inverse permutation of permutation τ , and an identity permutation is a permutation
without breakpoints.). The actual input that we consider is the permutation π = τ−1 · σ.
We denote d(π) to be the minimal number of reversals required to sort π.
SSPBR Problem (Sorting Signed Permutations By Reversal)[54]
The problem of sorting signed permutations by reversal is to find, for a given signed
permutation π, a sequence of reversals of minimum length that transforms π to the identity
permutation ι = (+1, +2, ..., +n).
For example, assume σ = (4, 3, 2, 5, 1) and τ = (1, 3, 5, 4, 2), then τ−1 = (1, 5,
2, 4, 3), τ−1 · σ= (4, 2, 5, 3, 1). The minimum number of reversals needed to transform
permutation σ to permutation τ is equal to find the reversal distance between τ−1 ·σ and
the identity permutation ι = (+1, +2, +3, +4, +5).
Definition 26. [74] Define S(π)={q | q = πr(i, j) for all 1 ≤ i ≤ j ≤ n}, which is the
collection of all permutations that can be obtained from π by one signed reversal. S(π) is
called a sphere (or reversal neighborhood) of π. Let P be a collection of permutations. A
reversal neighborhood (or sphere) of P is defined as S(P ) =
⋃
pi∈P S(π). Define S1(P ) =
S(P ), S2(P ) = S(S1(P )), and Sk(P ) = S(Sk−1(P )) , the k-neighborhood (or k-sphere) of
P .
MGRBSR Problem (Multiple Genome Rearrangement By Signed Reversal)[73]
Given two collections of permutations P = (p1, p2, . . . , pm) and Q = (q1, q2, . . . , qn) on an
alphabet X (e.g., the set of genes), each of pi and qi stands for a genome, we generate
Q from P in a minimum number of signed reversals, i.e., to find a collection of signed
permutations tk(1 ≤ k ≤ d) on X such that (1) any qj is obtained from some pi by a
series tk1, tk2, ..., tkj , where each tki+1 is obtained from tki by one signed reversal, i.e.,
45
4.1 The Reversal Median Problem
Given m permutations π1, . . ., πm ∈ Σn, where m ≥ 3 and Σ is the alphabet of permuta-
tions. Each genome contains the same content of genes. The Reversal Median Problem
(RMP) calls for a permutation σ ∈ Σn such that δ(σ) =
∑m
j=1 d(σ, πj) is minimized,
where d(πi, πj) is the reversal distance between πi and πj. It is a restricted and an easier
version of the general problem, called the Reversal Phylogeny Problem (RPP). Unlike
the RMP, the RPP calls for a minimum weight phylogenetic tree to connect the nodes
corresponding to the input permutations π1, . . ., πm. RMP can be used iteratively to
reconstruct the local parsimonious phylogeny. Sankoff and Blanchette [47] proposed the
median-based reconstruction algorithm, which iterates over a tree and repeatedly resets
the permutation on each internal node to be the median of its three nearest neighbors
until the process converges, as illustrated in Figure 1.1. Caprara proved that the RMP
and RPP are APX-hard [36, 33]. Note that, if a problem is APX-hard then it has no
Polynomial-Time Approximation Scheme (PTAS) unless P = NP.
Siepel [78, 30] and Caprara [34, 33] devoted to this problem in a few years. Siepel
handled the median problem of three permutations. Caprara provided a graph-theoretic
relaxation as a lower bound for a branch-and-bound algorithm. Since it is time-consuming
for the instances of more than three permutations, he proposed a linear-programming
based heuristic to speed up the running time. Though the solution is not optimal, it
provides a near optimal solution for time-consuming instances. GRAPPA [79] is a package
which can solve the RMP problem, but it cannot handle for more than three permutations
both on Siepel’s program and Caprara’s integrated program. We developed a branch-and-
bound algorithm and extend the upper bound and the lower bound to be more general.
The bounds are adapted to more than three permutations and will be discussed later. In
the following, we start with some concepts of sorting by reversals and related terms and
propose the main branch-and-bound algorithm with a general upper bound and a general
lower bound. We also give some experimental results compared to GRAPPA. Finally, we
47
from πi to πj is the reversal distance between πi and πj , denoted by d(πi, πj) (di,j for
short). The reversal distance is three on the above example because we cannot turn the
permutation into the identity using less than three reversals. The process of transforming
one permutation into another is also called Sorting By Reversal (SBR). SBR is a general
problem of computing reversal distance. It calls for finding a series of reversals to reach
the minimum number of reversals. Once we solve the SBR, we also know the reversal
distance. In addition to the above O(n4)[72], O(n3)[40, 39] and O(n2)[54] algorithms
for SBR, Siepel introduced the sorting reversals and developed an O(n3) algorithm of
enumerating all sorting reversals [32, 31]. Though the asymptotical complexity is not
better than the previous, he provided an algorithm of finding all sorting reversals and
then applied the algorithm to the problem of finding all minimum sequences of sorting
reversals. Inspired by Ozery-Flato and Shamir’s observation that a central question in
the study of genome rearrangements is whether one can obtain a subquadratic algorithm
for sorting by reversals [64], Tannier and Sagot proposed an O(n
√
n log n) time algorithm
for SBR [49]. However, there are some approximation algorithms of SBR on unsigned
permutations.
Let π and γ be signed permutations of size n, which are represented as π = (π1, π2, . . . , πn)
and γ = (γ1, γ2, . . . , γn). Let the unsigned permutation π
′ = (π′0, π
′
1, . . . , π
′
2n+1) be de-
fined as follows: π′0 = 0, π
′
2n+1 = 2n + 1, and π
′
2i = 2πi, π
′
2i−1 = 2πi − 1 (if πi > 0) or
π′2i = 2|πi|−1, π′2i−1 = 2|πi| (if πi < 0) for all i (1 ≤ i ≤ n). Let the unsigned permutation
γ′ = (γ′0, γ
′
1, . . . , γ
′
2n+1) be defined as well with respect to γ. Two elements πi and πi+1
are said to be adjacent in π, and the corresponding elements π′2i and π
′
2i+1 are said to
be adjacent in π′; similarly for γ and γ′. The breakpoint graph B of π with respect to γ
is constructed by arranging a sequence of 2n + 2 vertices in a line, corresponding to the
elements of π′ (the vertices must obey the order of π′). To simplify the term, the following
mentioned breakpoint graphs are on one permutation to the identity permutation. We
join vertices π′i and π
′
i+1 by a black edge for all i is even, and every pair (π
′
i, π
′
j) for that
reflects an adjacency in γ′ with a grey edge. A cycle in B is a sequence of connected
49
minimum sum the median score. If the median is one of the given permutations, we call
such a median a trivial median. Furthermore, a permutation γ is called a neighbor of
permutation π if d(γ, π) = 1 . A median is called a perfect median if its median score is
exactly the initial lower bound, which is the theoretical optimum of the RMP. A reversal
ρ is called a sorting reversal of π to σ if d(ρπ, σ) = d(π, σ) − 1
4.1.1 An Algorithm for Finding an Exact Median
RMP is an NP-hard problem. It has no polynomial time algorithm available now. When
the permutation size is 10, there are nearly two hundred quadrillion (seventeen of zeros)
permutations needed to check out with a na¨ıve approach. The number of permutations
grows exponentially with the permutation size n. Because it consumes lots of time in
processing each permutation to find an optimal solution, we adopt the branch-and-bound
methodology, which is one of the most efficient strategy to solve large combinatorial
problem, to solve our problem. In this section, we propose a branch-and-bound algorithm
to find a median on more than three permutations. First of all, we describe the bounds of
three permutations in [30] and develop a general upper bound and lower bound for more
than three permutations.
4.1.2 Bounds
Lemma 12. [30] Suppose there are three permutations all with the same gene-content,
and the pairwise distances are d1,2, d2,3, d1,3. The median score δ(σ) lies between the
following bounds:
⌈d1,2 + d2,3 + d1,3
2
⌉ ≤ δ(σ) ≤ min{(d1,2 + d2,3), (d1,2 + d1,3), (d2,3 + d1,3)}
51
are counted twice.) Thus, the median score is at least the half of the cost of a HC. Max
TSP returns the HC with the maximum cost. The half of the cost of Max TSP is the
greatest lower bound than the lower bounds provided by the cost of any other HC.
Lemma 14. The upper bound of the median score among π1, π2, . . ., πm is
min
i∈K
∑
j∈K\i
d(πi, πj), K = {1, 2, . . . ,m},
such a median is so-called the Min-Star topology.
Proof. It is obvious to see that every permutation is a trivial median. We can regard
each permutation as the median and compute each median score. Choose the minimum
median score for the upper bound. Such a median with the minimum median score is the
lowest upper bound, it has a tighter upper bound than other permutations.
The permutation with the lowest upper bound seems to be the median of the star. We
explore the branch-and-bound tree from the permutation as be rooted at it.
We take the term mRMP for short to represent the reversal median problem on more
than three permutations.
Theorem 15. The median score of the mRMP is between the above lower bound and
upper bound.
Proof. It is showed from the former two lemmas.
Reversal distance determines the distance between two permutations. It also decides
whether we need to explore more ”deeply” to find the median. Since every permutation
in the branch-and-bound tree is a feasible solution, and it is unbounded to search on all
permutations, we set the height of the branch-and-bound tree to limit the depth while
53
(a) (b)
Figure 23: (a) is the hurdle with one cycle. (b) is the hurdle having two cycles.
there is one more cycle extra while considering a super hurdle. How many super
hurdles accompany how many additional cycles. Besides, the cycles are more than
the hurdles even count the cycles of oriented component in. Similarly, h is less than
c, the reversal distance is no more than n+ 1.
The reversal distance is n+1 in the case of c = h and f = 0. That is, all components are
unoriented, all unoriented components are simple hurdles, and each component contains
only one cycle. In Figure 25, there are one cycle and one hurdle, but no fortress. The
reversal distance to the identity is 11.
Follow the above general bounds and set the depth of searching tree, we propose a
branch-and-bound algorithm to solve the mRMP in the next section.
0 9 10 1 2 5 6 3 4 7 8 11 12 21 22 13 14 17 18 15 16 19 20 23 24 33 34 25 26 29 30 27 28 31 32 35 36 38 37 39 40 41
Figure 24: The breakpoint graph is a fortress. The permutation is π =(5 1 3 2 4 6 11 7 9 8 10 12 17
13 15 14 16 18 -19 20) [81].
55
Algorithm 7 A Branch-and-Bound Algorithm for the Reversal Median Problem on More than
Three Permutations
Input: m signed permutations and each has the same size n.
Output: A median permutation Median and its median score.
1: PriSta is the priority stack. distmatrix is the distance matrix. pCurrent is the current
being examined permutation.
2: distmatrix = pRevDistKG (m permutations)
3: root ← permSubUB (distmatrix)
4: root.UB ← intSubUB (distmatrix)
5: root.LB ← intSubLB (distmatrix)
6: Median← root, MedianScore← root.UB
7: push (PriSta, root)
8: while PriSta is not empty do
9: pCurrent← pop (PriSta)
10: if pCurrent.depth > n+ 1 then
11: continue
12: end if
13: if pCurrent.LB ≥MedianScore then
14: continue
15: end if
16: Get next neighbor
17: while next neighbor is not NULL do
18: if pCurrent is retraversed then
19: Get next neighbor, then continue
20: else
21: Mark pCurrent as traversed
22: end if
23: Update the distance matrix
24: w ←invdist(pCurrent, root)
25: pCurrent.LB ← w + intSubLB(distmatrix)
26: pCurrent.UB ← w + intSubUB(distmatrix)
27: if pCurrent.LB < MedianScore then
28: if pCurrent.LB = pCurrent.UB then
29: Median← pCurrent, MedianScore← pCurrent.UB
30: else
31: if pCurrent.UB < MedianScore then
32: Median← pCurrent, MedianScore← pCurrent.UB
33: end if
34: Set priority and push (PriSta, pCurrent, priority)
35: Get next neighbor
36: end if
37: else
38: Get next neighbor
39: end if
40: end while
41: end while 57
4.1.5 Implementation
Instead of generating all its neighbors within one reversal at once while branching, get next
neighbor is to produce the next permutation - one once. There are two indices shifting
iteratively along the permutation. The two indices represent the two ends of reversal.
First of all, set the two indices zero and keep track of itself as the parent permutation.
While generating the next permutation, there are three cases of shifting on the two indices
along the parent permutation: One is the rear index shifts one to right and the front index
stay behind. Or the rear index is in the end of permutation and the front index shifts one
to right, then the rear index is set the same with the front one. Otherwise, the front and
rear indices are both in the end of permutation, it returns null to mean that all neighbors
are generated. The priority stack can be maintained with few elements if there are the few
permutations pushed in the stack finally, instead of pushing all neighbors into the stack
first then examining each one by the bounds. The larger permutation size n is, the more
memory required is. It saves memory storage while generating nearly O(n2) neighbors
once a branch.
How we compute the Max TSP is to modify the input and output of the TSP algorithm.
In other words, Max TSP is implemented by the tunnel of the TSP. The input of TSP is a
modified matrix called complementary matrix. That’s, each entry of the complementary
matrix is n+1 (n is the permutation size, and n+1 is the upper bound of reversal distance
from Theorem 16) minus its original value (you can also view the complementary matrix
as an universal matrix with n+ 1 on each entry minus the original matrix). After calling
for the TSP procedure, we get one minimum-cost tour and its cost is called c. It is
the least-cost tour of the complementary matrix. Now ”complement” the output again,
subtract c from m(n+ 1) and it extracts the maximum TSP of the original matrix from
the outcome of the TSP.
For example, there is a distance matrix in Figure 26 (a). Taking each entry of the
59
Max TSPMatrix
TSPComplementary
Matrix
Complement Complement
Call TSP
procedure
Figure 27: The matrix is transformed to the complementary matrix then apply TSP procedure to
compute the TSP tour. Furthermore, take the complement of the cost of TSP and it is the same to
compute the Max TSP directly from the original matrix.
regard the farthest nodes are having the largest depth on the branch-and-bound tree).
While the two are the same far from the root, we choose the one with the lowest lower
bound first. Moreover, select the one with the lowest upper bound as the third criterion
if the above two rules are fail.
To avoid the repeated permutations while branching, we use a hash table to record
each traversed permutation. When one permutation is generated, search it in the hash
table at first. If the hash table returns null, i.e., the permutation is not traversed, insert
the permutation into the hash table. The permutation is visited if it is found in the hash
table, then discard the permutation and get the next neighbor. It saves lots of time if we
can avoid doing the duplicate things. The hash table subroutine of the package GRAPPA
is also included and used in our program.
It is a heuristic that we search the median within the maximum radius, that is the
distance between the farthest permutation and the root. In fact, there are many medians
with the optimal score, and it is certain to have a median on the branch-and-bound tree
with the height that is no more than the maximum radius. It looks like searching on a
circle centering at the root within a radius of maximum radius, seeks the median around
61
the permutation from i to j. If i = j, then the sign of gene i is changed. The platform
of all experiments are on a personal computer with Intel Pentium IV 2.8 GHz CPU, 2
GB of memory, and the codes are compiled under Linux Fedora Core 1 with GNU gcc
compiler (version 3.3.2). We compared our program mRMP with Siepel’s and Caprara’s
from GRAPPA. Notice that Caprara’s integrated program to the GRAPPA is based on
three permutations.
The results seem ours is hardly comparable to theirs (see Figure 29), especially to
Caprara’s. He proposed a combinatorial lower bound of Cycle Median Problem (CMP)
which is computed in O(nm2). The branching approach corresponds to the edge con-
traction (see [33]). The solution of RMP is derived by modifying the method of CMP.
Siepel and Caprara adopted the trick that if the best solution found so far equals the
initial lower bound, the program terminates immediately and outputs the solution as the
optimal, instead of using the bounds to exam the rest of elements in the stack. If there is
no such a perfect median, they search the median with the median score of initial lower
bound plus one. It repeatedly raises the ”target” score until a solution is found. Further-
more, Siepel included the sorting reversals to improve the algorithm. While branching,
it selects the reversals toward other two permutations in its neighbors, in other words,
choose the reversal ρ such that d(ρπ1, π2) = d(π1, π2)− 1 and d(ρπ1, π3) = d(π1, π3)− 1 if
we explore the median from π1. Otherwise, select the reversal that is a sorting reversal to
one permutation and does not alter the reversal distance to other permutation. That is,
pick the reversal ρ with d(ρπ1, π2) = d(π1, π2)− 1 and d(ρπ1, π3) = d(π1, π3). It searches
the median along one minimum sequence of sorting reversals.
Figure 29 shows the relation of the average running time in millisecond and various
permutation size n. As the permutation size becomes larger, the time grows exponentially.
Both of Siepel’s and Caprara’s perform well in this case. Another figure shows that when
the permutation size is 20, the running time is in proportion to the number of random
reversals. Caprara’s implementation seems effortlessly to find a median on a series of
63
Table 4: The experiments are on the data sets provided from [79]. The time is measured in seconds,
and the time limit is 30 minutes.
m n r # inst. mRMP(# Opt) Siepel(# Opt) Caprara(# Opt)
3 10 2 10 0.025(10) 0.008(10) 0.001(10)
3 10 4 10 0.128(10) 0.047(10) 0.002(10)
3 10 8 10 0.053(10) 0.002(10) 0.000(10)
3 10 16 10 0.094(10) 0.013(10) 0.000(10)
3 20 2 10 0.073(10) 0.000(10) 0.000(10)
3 20 4 10 150.038(8) 14.095(8) 0.025(10)
3 20 8 10 184.950(7) 73.032(5) 0.042(10)
3 20 16 10 364.280(6) 79.312(7) 0.088(10)
65
Table 6: The experiments are based on various number of permutations m and different size of
permutation n. The data set are mentioned earlier and generated by our program. The time unit is
second.
m n r # inst. # Opt. Ave.Time(mRMP) Ave.Score
3 10 4 10 10 0.009 10.5
4 10 4 10 10 0.025 14.5
5 10 4 10 10 0.055 19.1
6 10 4 10 10 0.497 21.8
7 10 4 10 10 0.308 27.5
3 20 4 10 10 0.052 11.6
4 20 4 10 10 0.074 16.0
5 20 4 10 10 0.110 19.6
6 20 4 10 10 0.174 23.8
7 20 4 10 10 0.280 27.6
3 30 4 10 10 0.155 12.0
4 30 4 10 10 0.165 15.6
5 30 4 10 10 0.281 20.0
6 30 4 10 10 0.457 24.0
7 30 4 10 10 0.823 28.0
3 40 4 10 10 0.245 12.0
4 40 4 10 10 0.361 16.0
5 40 4 10 10 0.588 20.0
6 40 4 10 10 0.872 24.0
7 40 4 10 10 1.352 27.9
67
 0
 200
 400
 600
 800
 1000
 1200
 1400
 3  4  5  6  7
R
un
ni
ng
 T
im
e 
(m
s)
m
Average Running Time for m > 3, r = 4
n = 10
n = 20
n = 30
n = 40
 0
 3
 6
 9
 12
 15
 3  4  5  6
R
un
ni
ng
 T
im
e 
(m
se
c) 
thr
ou
gh
 ln
(x)
m
Average Running Time for m > 3, n = 10
r = 2
r = 4
r = 8
r = 16
Figure 30: Top: Average running time for permutations of r = 4. The figure shows the relation
between the running time, various number of permutations m and size of permutation n. Bottom:
Average running time for permutations of n = 10 on various r and m. Notice that the y is the
logarithm of x with base e. 69
rearrangement problem.
4.2.1 Previous results of the multiple genome rearrangement problem
Breakpoint Analysis Method Multiple alignment of macromolecular sequences gen-
eralizes from N = 2 to N ≥ 3 the comparison of N sequences which have diverged
through the local processes of insertion, deletion and substitution. Gene order sequences
diverge through non-local genome rearrangement processes such as reversal and transpo-
sition. Sankoff and Blanchettethe [47] showed which formulations of multiple alignment
have counterparts in multiple rearrangement. Based on difficulties inherent in rearrange-
ment edit distance calculation and interpretation, they presented the concept of break-
point analysis. The breakpoint distance between two genomes is defined as the number of
consecutive pairs of genes that are adjacent in one genome but not in the other. Break-
point analysis is one of the earliest methods for genome rearrangement problem based
on gene orders. Consensus-based multiple rearrangement of N ≥ 3 can be solved exactly
through reduction to instances of the Traveling Salesman Problem (TSP). They proposed
a branch-and-bound solution to TSP particularly suited to these instances.
Their simulations show how non-uniqueness of the solution is attenuated with increas-
ing numbers of data genomes. Tree-based multiple alignment can be achieved to a great
degree of accuracy by decomposing the tree into a number of overlapping 3-stars cen-
tered on the non-terminal nodes, and solving the consensus-based problem iteratively for
these nodes until convergence. Accuracy improves with very careful initializations at the
non-terminal nodes.
The degree of non-uniqueness of solutions depends on the position of the node in the
tree in terms of path length to the terminal vertices. GRAPPA is short for Genome
Rearrangements Analysis under Parsimony and other Phylogenetic Algorithms. It is
written by Moret, Wyman, Bader, Warnow, and Yan. It greatly improves on the results
71
g1
g
2
g
3
X
i
Figure 31: The solution grid.
neighborhood of P1 and closer to g3 than P1, and repeatedly improves a series of reversal
path to get a closest reversal path Pk (in some neighborhood of Pk−1) to g3. Next, it
constructs a grid by Pk and g3. Finally, a local optimal solution is obtained by searching
on the grid. This simplifies Sankoff’s Grid search algorithm.
Greedy Split Algorithm. Bourque and Pevzner [53] proposed a multiple genome
rearrangement algorithm based on recursively greedy splitting. It is based on the rear-
rangement distance and that is applicable to both unichromosomal and multichromosomal
genomes.
For the given genomes g1, g2, ..., gm, see Figure 33, the algorithm at first connects the
nearest pair, say g1 and g2 by a shortest reversal path. Suppose g1, g2, ..., gm−1, have been
connected by some reversal paths. Then the algorithm finds a nearest point (the split
site) on all these paths and connects gm to the split site.
EG-Graph Method. In spite of a well-known fact that genome rearrangements are
73
supposed to be viewed in the light of the evolutionary relationships within and between the
species involved, no formal underlying framework based on the evolutionary considerations
for treating the questions arising in the area has been proposed. If such an underlying
framework is provided, all the basic questions in the area can be posed in a biologically
more appropriate and useful form: e.g., the similarity between two genomes can then
be computed via the nearest ancestor, rather than directly, ignoring the evolutionary
connections.
Korkin and Golefarb [46] outline an evolution-based general framework for answering
questions related to the multiple genome rearrangement. In the proposed model, the
evolutionary genome graph (EG-graph) encapsulates an evolutionary history of a genome
family. For a set of all EG-graphs, they introduce a family of similarity measures, each
defined via a fixed set of genome transformations. Given a set of genomes and restricting
themselves to the transpositions, an algorithm for constructing an EG-graph is presented.
This EG-graph turns out to be very close to the corresponding known evolutionary tree.
Neighbor-Perturbing Algorithm. Wu and Gu [74] discusses a multiple genome
rearrangement problem by signed reversals. Given a collection of genomes, it generates
them in the minimum number of signed reversals. It is NP-hard and equivalent to finding
an optimal Steiner tree to connect the genomes by reversal paths. The authors design
a polynomial running time approximation algorithm (Neighbor-perturbing algorithm) to
find the optimal Steiner nodes of the problem. It searches for the optimal Steiner nodes by
perturbing initial Steiner nodes nearby their neighborhoods and improving them better
and better until convergence.
For a median problem, initial, the algorithm rearranges the genomes {g1, g2, g3} so
that the path g1, g2, g3 forms a minimum spanning tree. g2 is then chosen as the initial
Steiner node, i.e., s0 = g2. Then the algorithm starts perturbing from g2 so that the
iteration converges fast. It recursively perturbs each si and find a better si+1 ∈ S(si)
(Figure 34). Here S(π) is a sphere of π. The Steiner nodes are improved better and
75
g2
g
3
g
1
s
i+1
s
1
s
i
s
Figure 35: Steiner node path: s0, s1, ..., si, si+1, ..., s.
s
1
g
i+2
g
1
x
s
i(old)
g
2
g
i+1
g
m
g
m-1
g
i
s
i(new)
s
i-1
s
m-2
s
i+1
Figure 36: Neighbor-perturbing, general case.
77
g2
g
3
g
1
s
1
s
x
Figure 37: s1 is shared.
sj. As shown in Figure 39, the relations between all candidates of different generations
can by expressed as a tree. Let B be the set of all candidates (branches) and L the set
of all the current generations (leaves). For each leaf b ∈ L, check all x ∈ S(b) − B, if x
satisfies Equation 1, then x is a new candidate and it is then put into both the branch
set B and the leaf set L. If d∗(x,G) < d∗(s,G), then update the optimal Steiner node s
by x. New leaves b1, b2, ..., bk are obtained from b (Figure 40). b is removed from L and
becomes an internal node in next iteration. The algorithm repeats the process until no
new branch can be found.
79
g2
g
3
g
1
x
b
b
k
b
1
b
2
Figure 40: Process of branch growth.
4.2.2 An exact algorithm for the reversal phylogeny problem
In the previous pragraph, there are a lot of approaches for solving the reversal phylogeny
problem. Some of them are heuristic algorithms and Some of them fix a tree shape to find
an optimal solution. Unfortunately, all of these algorithm can not guarantee to find the
optimal solution without fixing any tree shape. In this project, we give an exact algorithm
(Algorithm 8) without giving the tree shape previously.
The algorithm 8 to find a optimal solution of the reversal phylogeny problem. Ob-
viously, the running time of algorithm 8 is not only exponential but also factorial. The
reason is that we generate
m−2∑
i=1
(
n!×2n
i
)
complete graphs to find all of their minimum span-
ning trees and give a minimum score finally. We implement algorithm 8 in C program.
The platform of all experiments are on a personal computer with Intel Pentium IV 2.8
GHz CPU, 1 GB of memory, and the codes are compiled under Windows with GNU gcc
compiler (version 3.4.5). The running time of the program grows exponentially. If the
81
In the MCTT problem, with the persistent data structure, we can speed up the running
time of branching and save more memory space. Furthermore, under the same input
species set, the running time of our program is better than the previous one when the m
is small, in which m is the number of input triples.
In RMP problem, we propose a branch-and-bound algorithm to find an optimal reversal
median on more than three permutations. The lower bound is computed with the easier
concept of Max TSP, and is implemented using the TSP procedure. Since the simulated
instances are applied the same number of random reversals from one common ancestor,
all nearly either have the perfect medians or have optimal median scores which are the
initial lower bound plus one. The program of Siepel and Caprara both return the optimum
immediately because they adopt the strategy of finding the perfect median first. If the
instances does not have the perfect median, they turn to search the permutation with a
”theoretical suboptimal” score by increasing the initial lower bound. It has no guarantee
to show that they still have good performance on biological data or the instances without
perfect medians. We hope to develop a general algorithm rather than the algorithm
specified to some instances.
Furthermore, we can use sorting reversals to improve the algorithm. It is helpful
to perform reversals toward the medians more certainly if the reversals are the sorting
reversals to other m − 1 permutations. In other words, we perform the reversals which
make the reversal distances to the m−1 permutations all minus one. If there is no such a
wonderful reversal, select the reversals which are the sorting reversals to k permutations
(k ≤ m− 1), such that k is the maximum.
In RPP problem, we propose an exact algorithm to find an optimal solution, but it is
not very efficient. The experiment results and complexity analysis the solution space is too
large. We can not find an optimal solution quickly without an significant algorithm such
as branch-and-bound algorithm. For developing a branch-and-bound algorithm, finding
good bounds is very important. The most important further work is how to develop an
83
[9] M. Farach and M.Thorup. Sparse dynamic programming for evolutionary-tree com-
parison. SIAM J. Comput., 26:210–230, 1997.
[10] J. Felsenstein. Inferring phylogenies. Sunderland, MA, Sinauer Associates, 2004.
[11] C.R. Finden and A.D. Gordon. Obtaining common pruned trees. J. Classification,
2:255–276, 1985.
[12] H. N. Gabow, J. L. Bentley, and R. E. Tarjan. Scaling and related techniques for
geometry problems. Proceedings of the sixteenth annual ACM symposium on Theory
of computing, pp. 135–143, 1984.
[13] M.Y. Kao. Tree contractions and evolutionary trees. SIAM J. Comput., 27:1592–
1616, 1998.
[14] E. Kubicka, G. Kubicki, and F.R. McMorris. An algorithm to find agreement sub-
trees. J. Classification, 12:91–100, 1995.
[15] D.T. Lee and C.K. Wong. Worst-Case Analysis for Region and Partial Region
Searches in Multidimensional Binary Search Trees and Balanced Quad Trees. Acta
Informatica, 9:23–29, 1977.
[16] K. Mehlhorn. Data structures and Algorithms 3. Multi-dimensional Searching and
Computational Geometry. Springer, Berline Heidelberg, New York, 1984
[17] M. Steel and T. Warnow. Kaikoura tree theorems: Computing the maximum agree-
ment subtree. Inform. Process. Lett., 48:77–82, 1993.
[18] Maw-Shang Chang and Ming-Chang Dong. An Exact Algorithms for Constructing
a Maximum Consensus Tree from Rooted Triples. Master thesis, National Chung-
Cheng University, Chiayi, Taiwan, 2004.
[19] Bang Ye Wu Constructing evolutionary trees from rooted triples. Journal of Infor-
mation Science and Engineering, 20:181–190, 2004.
85
[31] A. C. Siepel. An algorithm to enumerate sorting reversals for signed permutations.
Journal of Computational Biology. 10(3/4):575-597 2003.
[32] A. C. Siepel. An algorithm to enumerate all sorting reversals. Proceedings of the
Sixth Annual International Conference on Computational Biology (RECOM 2002).
281–290 2002.
[33] A. Caprara. The reversal median problem. INFORMS Journal on Computing.
15(1):93–113 2003.
[34] A. Caprara On the practical solution of the reversal median problem. in Proceedings
of the First International Workshop on Algorithms in Bioinformatics (WABI 2001).
238–251 2001.
[35] A. Caprara. Sorting permutations by reversals and eulerian cycle decompositions.
SIAM Journal on Discrete Mathematics. 12(1): 91–110 1999.
[36] A. Caprara. Formulations and hardness of multiple sorting by reversals. in Pro-
ceedings of the Third Annual International Conference on Computational Molecular
Biology (RECOMB 1999). 84–93 1999.
[37] A. Caprara. Sorting by reversals is difficult. In Proceedings of the 1st Conference on
Computational Molecular Biology (RECOMB97), pp. 75− 83, Santa Fe, NM, ACM
Press, 1997.
[38] A. Bergeron, J. Mixtacki, and J. Stoye. Reversal distance without hurdles and
fortresses. in Proceedings of the 15th Annual Symposium on Combinatorial Pattern
Matching (CPM 2004). 388–399 2004.
[39] A. Bergeron. A very elementary presentation of the Hannenhalli-Pevzner theory.
In Proceedings of the 12th Annual Symposium on Combinatorial Pattern Matching
(CPM 2001). 106–117 2001.
87
of the 15th Annual Symposium on Combinatorial Pattern Matching (CPM 2004).
1–13 2004.
[50] F. K. Hwang, D. S. Richards, and P. Winter. The steiner tree problem. Elsevier
Science Publishers B.V., 1992.
[51] D. A. Bader and B. M. E. Moret and M. Yan. A linear-time algorithm for computing
inversion distance between signed permutations with an experimental study. Journal
of Computational Biology. 8(5):483–491 2001.
[52] D. Sankoff. Genome rearrangement with gene families. Bioinformatics. 15(11):909–
917, 1999.
[53] G. Bourque and P. Pevzner. Genome-Scale Evolution: Reconstructing Gene Orders
in the Ancestral Species. Genome Research. 12(1):26–36, 2002.
[54] H. Kaplan, R. Shamir, and R.E. Tarjan. A faster and simpler algorithm for sorting
signed permutations by reversals. SIAM Journal of Computing , 29(3):880–892,
1999.
[55] J. Tang and B. M. E. Moret Linear programming for phylogenetic reconstruction
based on gene rearrangements. in Proceedings of the 16th Annual Symposium on
Combinatorial Pattern Matching (CPM 2005). 406–416 2005.
[56] J. Tang and B. M. E. Moret. Phylogenetic reconstruction from gene-rearrangement
data with unequal gene content. in Proceedings of the 8th International Workshop
on Algorithms and Data Structures (WADS 2003). 37-46 2003.
[57] J. Kececioglu and D. Sankoff. Exact and approximation algorithms for the inversion
distance between two chromosomes. Lecture Notes in Computer Science. 684:87–
105, 1993.
[58] J. Kececioglu and D. Sankoff. Exact and approximation algorithms for sorting by
89
[68] P. Berman and S. Hannenhalli. Fast Sorting by Reversal. Proceedings of the 7th
Annual Symposium on Combinatorial Pattern Matching, Laguna Beach, CA, 1996.
Lecture Notes in Computer Science, 1075:168-185, , 1996.
[69] P. Berman, S. Hannenhalli, and M. Karpinski. 1.375-Approximation algorithm for
sorting by reversals. in Proceedings of the 10th Annual European Symposium on
Algorithms (ESA 2002). 200–210 2002.
[70] P. A. Pevzner and G. Tesler. Genome rearrangements in mammalian evolution:
lessons from human and mouse genomes. Genome Research. 13(1):37-45, 2003.
[71] S. Hannenhalli and C. Chappey and E. V. Koonin and P. A. Pevzner. Genome
sequence comparison and scenarios for gene rearrangements: a test case. Genomics.
30(2):299–311 1995.
[72] S. Hannenhalli and P. Pevzner. Transforming cabbage into turnip (polynomial
algorithm for sorting signed permutations by reversals). In Proceedings of the 27th
Annual Symposium on Theory of Computing (STOC95), pp. 178− 189, Las Vegas,
NV, ACM Press, 1995.
[73] S. Wu and X. Gu Multiple Genome Rearrangement By Reversals. Pacific Sympo-
siumon Biocomputing. 7:259–270, 2002.
[74] S. Wu and X. Gu. Algorithms for multiple genome rearrangement by signed rever-
sals. Pacific Symposium on Biocomputing , 8:363–374, 2003.
[75] V. Bafna and P. Pevzner. Sorting by transpositions. In Proceedings of the 6th
Annual ACM-SIAM Symposium on Discrete Algorithms, pp. 614− 623, 1995.
[76] V. Bafna and P. Pevzner. Genome rearrangements and sorting by reversals. SIAM
Journal on Computing. 25(2):272–289, 1996.
[77] Y. C. Lin, C. L. Lu, H.-Y. Chang, and C. Y. Tang. An efficient algorithm for sorting
91
Appendix I
93
212 C.-M. Lee et al. / Information Processing Letters 94 (2005) 211–216
1. Introduction
In biological research, evolutionary trees are of-
ten used to help understand the evolutionary history
for a set of species and further explain the relation-
ship among the species. Let L be a set of species and
|L| = n. With the assumption that all species evolve
from one common ancestor, an evolutionary tree T on
L is a rooted, leaf-labeled tree such that every leaf of
T is uniquely labeled by an element of L, and every
internal node of T has at least two children. Construct-
ing evolutionary trees is one of the fundamental tasks
in computational biology. There are many different ap-
proaches for constructing evolutionary trees. Different
methods may yield different trees for the same set of
species. It leads to the study of finding an agreement of
different evolutionary trees for the same set of species.
When such an agreement has been obtained, we have
different lines of evidence to support that the agree-
ment reflects the true evolutionary history on some
species.
Definition 1. For a rooted tree T on set L and a subset
X ⊆ L, T (X) is the minimal subtree of T containing
X by removing all nodes without descendants in X.
For rooted trees, we use the degree of a node to denote
the number of its children. Let T |X be the induced
subtree of T by contracting every edge incident with a
degree 1 node in T (X) into its child.
Fig. 1 shows a rooted tree T with leaves labeled by
{a, b, c}, T (X) and the induced subtree T |X, respec-
tively, where X = {b, c}.
Fig. 1. A rooted tree T with leaves labeled by {a, b, c}, T (X) and
the induced subtree T |X where X = {b, c}.
Definition 2. Let lcaT (a, b) be the lowest common an-
cestor of nodes a and b in T , and let lcaT (a, a) be the
node a itself. Two trees T1 and T2 with the same leaf
labels are isomorphic if there is a 1–1 mapping func-
tion f between their nodes, mapping leaves to leaves
with the same labels and for any two distinct leaves
a, b of T1, f (lcaT1(a, b)) = lcaT2(f (a), f (b)).
Finding a maximum agreement subtree is one
widely studied method to obtain an agreement of dif-
ferent evolutionary trees for the same set of species.
A maximum agreement subtree for a set T = {T1, T2,
. . . , Tk} of k rooted leaf-labeled trees on set L is de-
fined as follows: An agreement subtree for T is a tree
T such that T1|X,T2|X, . . . , Tk|X, and T are mutu-
ally isomorphic where X is the set of leaves of T .
A maximum agreement subtree for T is an agreement
subtree with the largest number of leaves. The maxi-
mum agreement subtree problem (the MAST problem)
is to find a maximum agreement subtree for T . Fig. 2
illustrates an example of a maximum agreement sub-
tree for a set T of three leaf-labeled trees.
The MAST problem was introduced by Finden and
Gordon [10]. They gave a heuristic algorithm for com-
puting a maximum agreement subtree of two binary
trees. Amir et al. showed that computing a maximum
agreement subtree of three trees with unbounded de-
gree is NP-hard [1]. For other variants of the MAST
problem, a number of efficient algorithm have been de-
veloped [1,3–8,12,13,16]. Consider the MAST prob-
lem for a set T of k rooted leaf-labeled trees on n
leaves where at least one tree has maximum degree
d . For this type of the MAST problem, Farach et al.
gave an algorithm solving the problem in O(kn3 +nd)
Fig. 2. T is a maximum agreement tree for {T1, T2, T3}.
214 C.-M. Lee et al. / Information Processing Letters 94 (2005) 211–216
Lemma 2 [3]. If a = b, then
mast(a, b) = max{mast(a, x): x ∈ A}
+ max{mast(b, y): y ∈ B},
where A = {x: ax | b ∈ R} ∪ {a} and B = {y: by | a ∈
R} ∪ {b}.
Based upon Lemma 2, we have the following pro-
cedure to compute mast(a, b):
Procedure mast
1. If a = b then return 1.
2. Choose x∗ ∈ {x: ax | b ∈ R} ∪ {a} that maximizes
mast(a, x∗).
3. Choose y∗ ∈ {y: by | a ∈ R} ∪ {b} that maximizes
mast(b, y∗).
4. Return mast(a, x∗) + mast(b, y∗).
Bryant’s algorithm computes mast(a, b) for all (a, b) ∈
L × L using the dynamic-programming technique.
It computes mast(c, d) before mast(a, b) if (c, d) ≺
(a, b). The set R can be computed in O(kn3) time.
Then sets A and B be obtained in O(n) time. Therefore
Steps 2 and 3 take O(n) time. Bryant’s algorithm com-
putes mast(a, b) once for each (a, b) ∈ L×L. Clearly
mast(T ) = max{mast(a, b): (a, b) ∈ L × L}. Hence,
Bryant’s algorithm computes the number of leaves of
a maximum agreement subtree for T in O(kn3) time.
3. A faster algorithm
Definition 7. For each pair (x, y) ∈ L×L, let dTi (x, y)
denote the number of edges in the path from x to
lcaTi (x, y), and let xy be a k-dimensional vector such
that xy[i] = dTi (x, y) for i = 1, . . . , k.
It is not hard to see that all such vectors xy for T
can be computed in O(kn2) time by traversing each
tree of T from leaves to the root. For each a ∈ L, let
{a} be the set of {ax : x ∈ L}.
Definition 8. Let x and y be k-dimensional vectors.
A vector x is dominated by a vector y if x[i] < y[i]
for i = 1, . . . , k. We say a vector x is dominated by
a vector y in the first h dimensions if x[i] < y[i] for
i = 1, . . . , h where 1  h < k.
Theorem 1. Assume that R is the rooted triple set of
T . Then, a rooted triple ax|b ∈ R if and only if ax is
dominated by ab .
Proof. ax|b ∈ R ⇔ ax|b fits Ti for i = 1, . . . , k.
⇔ lcaTi (a, x) is a proper descendent of lcaTi (a, b)
for i = 1, . . . , k.
⇔ dTi (a, x) < dTi (a, b) for i = 1, . . . , k.
⇔ ax[i] < ab[i] for i = 1, . . . , k.
⇔ ax is dominated by ab. 
Definition 9. For a ∈ L and ab ∈ {a}, let the weight of
vector ab , denoted by w(ab), be mast(a, b). Therefore
w(ab) = w(ba) for a, b ∈ L.
By Theorem 1, choosing an x∗ ∈ {x: ax | b ∈ R} ∪
{a} that maximizes mast(a, x∗) and a y∗ ∈ {y: by |
a ∈ R} ∪ {b} that maximizes mast(b, y∗) in Bryan-
t’s algorithm becomes finding a vector ax ∈ {a} with
maximum weight among all vectors in {a} and dom-
inated by ab , and a vector by ∈ {b} with maximum
weight among all vectors in {b} and dominated by ba ,
respectively. And w(ab) = w(ba) = w(ax) + w(by).
Based upon this observation, we give the following al-
gorithm:
Algorithm MAST
Input: A set T = {T1, . . . , Tk} of k rooted leaf-
labeled trees on a set L of n elements, and Tk
is a binary tree.
Output: A maximum agreement subtree for T .
Step 1: For each pair (x, y) ∈ L×L, compute xy .
Step 2: [Initialization] For each a ∈ L and ab ∈ {a},
w(ab) = 1 if a = b; otherwise w(ab) = 0.
Step 3: For all pairs (a, b) ∈ L×L in the partial order
of the domination relation in tree Tk do:
1. Find a vector ax ∈ {a} with maximum weight
among all vectors in {a} and dominated by
ab and find a vector by ∈ {b} with maximum
weight among all vectors in {b} and dominated
by ba .
2. Set mast(a, b) = w(ab) = w(ba) = w(ax) +
w(by).
Step 4: Return max{mast(a, b): (a, b) ∈ L×L}.
