行政院國家科學委員會專題研究計畫成果報告 
數位化居家照護系統研究─子計畫四：智慧型看護機器人之監測、規劃與控制(3/3) 
Monitoring, Planning and Control Techniques for an Intelligent Homecare Robot(3/3) 
計畫編號：NSC-95-2218-E-009-007- 
執行期限：95年10月01日至96年09月30日 
主持人：宋開泰教授  國立交通大學電機與控制工程學系 
 
 
一、中文摘要(關鍵字：家用機器人、定位系
統、無線感測網路、姿態估測） 
隨著社會上老年人口的增加，近年來老
人生活的照顧變得愈來愈重要，尤其是獨居
老人。本計劃研發出一個能夠處理家中緊急
情況的看護機器人，並結合多模感測及控制
功能來幫助獨居老人。在看護機器人上完成
的功能包括有：人臉追蹤互動控制、遠端視
訊傳送、室內定位系統、機器人室內導航、
人體姿態估測、緊急電話通訊等實用性功
能。當老人身上配戴的人體姿態估測模組偵
測到發生跌倒時，會經由 Zigbee 無線感測網
路傳送到機器人端，機器人先發送緊急手機
簡訊至家人的行動電話中，在第一時間通知
家人或醫院；接著機器人會透過 Zigbee感測
網路定位出老人的位置所在，主動移至老人
身邊，並藉由雷射掃描儀能閃過路途中的障
礙物；此時機器人頂部的攝影機自動的追蹤
老人的臉部，並經由無線網路將影像即時的
傳送至遠端，在遠處的親人及家庭醫生可由
電腦或 PDA觀看老人的即時影像，掌握最新
最正確的情況，以給予老人適當的援助，讓
老人在家中的安全得到更多的保障。本計畫
研發之看護機器人系統參加 2007 東元機器
人競賽，獲得亞軍。 
 
Abstract: 
With increasing number of aging people, 
taking care of the elderly will become more and 
more important in the near future, especially 
for those elders living alone. In this project, an 
autonomous robot: Robot of Living Aid, Rola 
has been developed. Rola can handle certain 
emergency conditions in a home setting to help 
elderly people through multi-modal sensing and 
control functions. The implemented functions 
include visual tracking, video transmission, 
location aware, navigation, elder pose 
estimation and emergency call out. Rola can 
accommodate smoothly the movement of the 
elder through face tracking while the elder uses 
robot-assisted video conferencing. Further, 
Rola follows the elder smartly in the living 
room using the developed Zigbee-based 
location aware system. It avoids obstacles in a 
narrow space using laser range finder. Rola also 
can help the elder as he/she falls down 
carelessly at home. This abnormal motion can 
be estimated with an accelerometer mounted on 
the waist of the elder. In the meanwhile, she 
approaches to the elder through location aware 
system and provides emergency help through 
automatic call out and wireless video 
transmission. 
 
Keywords: Home robots, Location aware 
system, Wireless sensor network, Pose 
estimation. 
二.計畫緣由與目的 
近幾年來服務型機器人的發展十分蓬
勃，不久之未來機器人可以輔助人類做各種
實用的工作且會被引入到家庭中。一項機器
人可以擔任之工作是被用來當作家庭看護，
提供老年人各種生活輔。舉例來說，日本三
菱的機器人牛若丸，就具有看護的功能。它
每天主動叫老人起床，提醒老人吃藥，老人
無聊時就陪老人猜謎語。老人外出，可以借
助牛若丸的無線網路功能方便地查到電車時
刻表和最佳出行路線。超過預定時間若老人
沒有回家，牛若丸就會打電話報警。日本松
下電器產業開發獨居老人護理機器貓
Tama，不但能夠跟主人談天，還能夠利用電
話跟健康中心聯絡，將醫療資訊傳達給醫
  
 
圖二、看護機器人系統架構圖
本機器人系統更包含一室內環境之定位
功能。經由在環境中布置數個 Zigbee無線模
組，建置無線感測網路，再利用被定位物體
(老人身體)配戴之 Zigbee 模組所接收各節點
不同的訊號強度 (Received Signal Strength, 
RSS)當作環境的空間特徵，藉此判斷出物體
或老人的實際位置。人體之定位資訊結合機
器人上之雷射掃描儀偵測周圍環境資訊，即
可達成使機器人主動避開障礙物並追蹤老
人，移動至老人身邊察看情況並傳送影像。 
3.2 人臉追蹤互動控制與遠端影像傳輸 
為了要監控獨居老人在家中的狀況，我
們設計出一人臉偵測與追蹤控制系統：利用
機器人上的攝影機擷取影像並偵測出畫面中
人臉的位置；設計一個控制器，並實現在擁
有 pan-tilt能夠上下左右移動的視覺平台上，
可穩定的移動攝影機並追蹤靜止及移動中老
人的臉部，讓機器人能確實的掌握到老人的
情況；最後利用無線網路將影像傳送出去，
讓遠處的親人也能看到家中老人的狀況。 
要能順利的追蹤人臉，首先便要能夠在
影像中正確的偵測出人臉的位置，我們使用
了基於膚色偵測的即時人臉偵測方法，並使
用適應性的膚色搜尋法逹到人臉的穩定追蹤
[1]。圖三為人臉偵測與追蹤演算法的流程
圖：利用Web Camera將影像擷取，除了即時
的影像傳送外，也開始人臉偵測的演算流
程，利用膚色偵測得知人臉可能的位置；在
ROI(Region of Interest)區域中定義出一適應
性膚色視窗，此視窗為統計膚色分佈閥值之
區域，在我們的設計中是使用 YCrCb色彩，
圖三上方即為色彩的 Histogram 統計圖，先
計算此視窗內之平均亮度並且根據平均亮度
以得到 YCrCb三維色彩分佈之上下閥值，然
後我們定義出上下限範圍來篩選，只留下中
間多數具有此時代表性的膚色色彩範圍作為
下次膚色分割的依據。 
由於能即時的更新膚色分割的色彩範
圍，讓此人臉偵測系統具有能對抗光源變化
的特性，在光源變亮或是變暗的情況下，也
能在影像中分割出人臉膚色的區域，偵測到
人臉的正確位置，圖四為在光源變化下之人
臉追蹤實驗結果。這種適應性的膚色搜尋法
能更穩定的追蹤人臉的膚色區塊，讓我們的
人臉偵測與追蹤能更加的穩定。成功分辨出
人臉區塊位置後，即能使用追蹤控制法則，
並透過機器人的伺服控制器控制 Pan-Tilt 移
動平台上的馬達來使攝影機能夠轉動，讓攝
影機能一直朝向人臉位置。 
  
 
圖五、Zigbee無線感測網路示意圖 
傳送到 RoLA身上的 Zigbee模組，系統根據
接收到的訊號強度與定位資料庫比對，找出
被看護者在環境中的位置。 
在環境中佈建了五個Zigbee模組，在被看
護者身上裝戴一個Zigbee模組，以及在機器
人身上安裝一個Zigbee模組。如圖五所示，
環境中的Zigbee模組從被看護者端接收到的
訊號強度，傳送到機器人端，跟定位資料庫
比對，估測被看護者的位置。Zigbee定位是
使用接收到的訊號強度 Received Signal 
Strength(RSS)當作工作環境的空間特徵，提
供物體實際位置資訊。RSS的基本概念是利
用環境中的Zigbee模組偵測被看護者端所傳
送的訊號強度，當作空間特徵，與系統中的
定位資料庫比對，找出被定位者的位置。定
位系統在建立時，分成兩個階段[4]，建立定
位資料庫以及位置估測。 
使用 RSS當作空間特徵都要先建立一個
定位資料庫，在每個參考點上收集到的訊號
強度樣品，都記錄其對每個 Zigbee的訊號強
度平均值，所以在定位資料庫中記錄的每一
筆資料都是以(xi,yi,ss
1
i,ss
2
i,……,ss
n
i)來表示，
其中 xi, yi表示環境中第 i個參考點的位置，
ss
1
i,ss
2
i, ……,ss
n
i 表示在(xi, yi)收集到各個
Zigbee 的平均訊號強度，其中 n 是環境中佈
置的 Zigbee數目，用這些訊號強度可以分辨
每個參考點的位置。 
我們所使用的判定演算法是 Nearest 
Neighbor Algorithm(NNA)及Nearest Neighbor 
Average Algorithm(NNAA)。Nearest Neighbor 
Algorithm 是直接根據所取得的 RSS 值和定
位資料庫中的資料做比對，以最接近的一組
對應位置為目前使用者所在位置，此法由環
境中 Zigbee佈置所建構的資料庫已決定定位
精準度的大小，因此在 Zigbee的佈置上需要
多加考量，使用判定法最主要的關鍵在於最
後做判定的關係判定式，定位判定式可以表
示為： 
( ) ( )
1
1
1 1
| |
N P
P
p RSSI RSSI
i i
L User i Base i
N W
=
⎛ ⎞
= −⎜ ⎟
⎝ ⎠
∑
(1) 
Wi表示此筆 RSSI 之可信賴度的權重值，LP
表示關係判定的比較距離，代表位置與距離
之特徵，最常使用有歐幾里得距離(Euclidean 
distance，P=2)，也有使用曼哈頓量測距離
(Manhattan distance，P=1)等，判定關係式使
用的是歐幾里得距離。最小的一筆 LP就判定
為和機器人接收到訊號強度最接近的參考
點，藉由這個方法來判定機器人目前的位
置。圖六是整個判定法的流程圖。 
由於這個方法只能判斷機器人接收的訊
號強度最接近那個參考點，所以當參考點的
數量太少，估測出來的位置誤差就有點大，
所以 Nearest Neighbor Average Algorithm加
強了這部分的缺點。Nearest Neighbor Average 
Algorithm 基 本 上 跟 Nearest Neighbor 
Algorithm很類似，從一開始的收集參考點上
的訊號強度到建立定位資料庫都是一樣的步
驟，最大的不同在於 Nearest Neighbor 
Algorithm只要找到一個資料庫中訊號強度 
最接近的參考點，而 Nearest Neighbor 
Average Algorithm是要從資料庫找出M個訊
號強度最接近的參考點，藉由平均這些參考
點在工作環境的位置，去估測機器人即時的
位置，如下式： 
( )
( )
i
1
,
,
M
i
x y
x y
M
=
=
∑
    (2) 
式中(x,y)i 是第 i 個最接近的參考點，(x,y)
是由M個最接近的參考點取平均得到的位置
估測。這個方法的好處是可以推測物體在多
個參考點之間的位置，也可以避免因為資料
庫取樣參考點太少所造成的誤差，還可以利
用調整M個參考點來改變機器人的定位精確
度。 
  
層(Input layer)是等待辨識的圖樣輸入，在此
的輸入端是由雷射資訊所分成 5 組數據而成
的一個有序向量，5 組數據分別表示 RoLA
的左側、左前、正前方、右前、右側這 5 個
方向的障礙物距離資訊。得到輸入後，在距
離層(Distance layer)利用 2-範數(2-Norm)的
方法去計算與典型圖樣(W0~Wc-1)的相差距
離(d0~di(c-1))，而我們設計的典型圖樣如圖九
所示。在第三層歸屬層(Membership layer)則
是去計算輸入的向量與典型圖樣的歸屬程度
(u0~ui(c-1))，其歸屬程度並非行為融合比重，
而是輸入的向量與設計的典型圖樣的相似
度，搭配上半部規則表所建立的八種典型圖
樣的融合比重跟定義出來的目標方位，即可
算出對應於輸入的環境訊息所應產生的行為
融合比重。我們即利用行為融合比重來計算
出 RoLA 兩輪的轉速修正值，以達成機器人
RoLA的導航行為。 
3.5 人體姿態偵測 
我們應用 Zigbee模組及三軸加速度感測
器開發出一姿態估測模組，如圖十所示，基
於模組上的加速規感測人體的加速度訊號，
在其上的微控器時現人體姿態估測演算法， 
 
圖八、行為融合啟發性網路架構 
 
圖九、環境典型圖樣  
 
圖十、姿態估測模組 
再將估測出的人體姿態透過 Zigbee無線網路
傳送給 RoLA。目前我們可以判斷出的人體
姿態有：站、坐、躺、跌倒、走路、上樓、
下樓七種生活上常見的姿態，估測演算法流
程圖如圖十一。當機器人發覺到老人家有跌
倒、久臥不起等異常狀況時，機器人會以手
機簡訊通知家人或看護者前去察看，並可透
過 PDA 手機傳送機器人所看到的及時畫
面。透過此感測模組與看護機器人分攤照顧
老年人的心力，讓獨居老人的居家安全更加
保障。 
將加速規模組配置於人體的腰部，因為
腰部附近是人體的重心所在，測量這個位置
的加速度值也最能夠代表整個人體的狀況。
定義人體右方為 X 軸方向正上方為 Y 軸方
向，正後方為 Z軸方向。加速規不但可以感
測到人體的動態加速度也可以感測到由地心
引力產生重力加速度，而跌倒這個姿態只與
人體產生的動態加速度有關。因此我們需要
先將加速度訊號經過前處理，分離動態與靜
態加速度，而將動態加速度訊號用來跌倒偵
測。 
人體的運動頻率絕大多數皆小於
20Hz，我們採用的取樣頻率為 128Hz，以微
控器的 Timer 之溢位中斷來控制取樣頻率。
為了兼顧系統的反應時間及提供足夠的資料
量，我們選擇每收集兩秒的資料作一次姿態
演算法的處理流程，即每 256 筆資料作一次
處理。利用小波轉換的方式來計算出靜態加
速度，因為我們所取的資料有 256 筆，可以
作 8層的 Haar小波轉換，我們只取最低頻的 
  
 
圖十四、控制整合之狀態流程圖 
考點值。實驗結果記錄於表一，M為取用鄰
近老人位置的參考點數目，表一中的第二行
表示取三個最鄰近老人估測位置的參考點數
值平均的誤結果，第三行、第四行分別代別
取四個、五個鄰近老人的參考點作平均的誤
差結果。在此實驗中，Zigbee 定位系統之平
均誤差為 1.26公尺，此結果可符合視覺系統
中用來開始追蹤人臉的需求。 
在姿態估測的實驗中，共有五位受測者，
而姿態估測模組則裝置在受測者的腰上，實
驗前先對受測者觀測其走路、上樓、下樓的
一些參數，在設定各參數後則開始姿態估測
的實驗。實驗結果列表於表二，其中 default
代表無法估測出為七種姿態之中，基本上站
立及躺下都可以 100%偵測成功，而異常狀態
跌倒的偵測也有 94%的高成功率，估測成功
率最差的姿態為上樓的 79%，總合來說，系
統姿態估測成功率約有 91%，驗證姿態估測
模組可成功的估測七種姿態於實際應用中。 
四. 結論與未來展望 
本計畫之看護機器人可透過遍佈式感測
網路定位出老人所在的位置，並可即時的偵
測到老人跌倒情況的發生，傳送緊急手機簡
訊通知家人，機器人能主動移至老人身邊，
傳送即時影像至遠端的電腦或 PDA，家人能
快速的得知老人的情況，讓受傷的老人能儘
快得到救援。藉由本計畫所設計的家用機器
人系統，可在獨居老人在家中發生跌倒情況
時做出及時的處理，讓老人的安全獲得更多
的保障。 
本計畫所發展出來的遍佈式感測網路將
來亦可應用在許多其他情境，機器如人保全
上。在感測網路上的各個節點可整合可偵測
人體通過的紅外線 Pyrosensor，或是可偵測
玻璃被擊破之麥克風 sensor 與振動感測
sensor，當這些 sensor 感測到這些異常現象
時，機器人便可從感測網路系統中得知，可
自主前往事發地點處理(如傳送即時影像給
家人)，使機器人不但能提供居家看護功能，
也能提供保全服務。 
本計畫執行期間共完成兩篇國際期刊論
文與 10篇研討會論文，另有兩項專利提出申
請。2007年 9月本計畫所研發之看護機器人
系統參加 2007東元機器人競賽，獲得亞軍。
圖十五是參加東元機器人競賽的照片。 
 
五. 參考文獻 
[1] K.-T. Song, J.-S. Hu, C.-Y. Tsai, C.-M. 
Chou,  C.-C. Cheng, W.-H. Liu and 
C.-H. Yang, “Speaker Attention System for 
Mobile Robots Using Microphone Array 
and Face Tracking,” in Proc. of IEEE 
International Conference on Robotics and 
Automation, Orlando, Florida, 2006, 
pp3624-3629. 
[2] C.-Y. Tsai and K.-T. Song, “Face Tracking 
Interaction Control of a Nonholonomic 
Mobile Robot,” in Proc. IEEE/SRJ Int. 
Conf. on Intelligent Robots and Systems, 
Beijing, China, 2006, pp. 3319-3324 
[3] C.-Y. Tsai and K.-T. Song, “Robust 
Tracking Control of a Mobile Robot with a 
Tilt Camera,” in Proc. of 2006 CACS 
Automatic Control Conference, Taipei, 
Taiwan, 2006, pp. 36-41. 
[4] P. Bahl and V. N. Padmanabhan, “RADAR: 
An In-Building RF-Based User Location 
and Tracking Systems,” in Proc. of IEEE 
Conf on Computer Communications, Tel 
Aviv, Israel, Mar. 2000, pp.775-784. 
[5] T. Huntsberger and P. Ajjimarangsee, 
“Parallel Self-organizing Feature Maps for 
Unsupervised Pattern Recognition,” Int’l. J. 
General Systems, vol. 16, no.4, pp.357-372, 
1990. 
