I摘要
本研究計畫之目的為設計並發展一新式具競標(auction)機制之分散式(distributed)
排程系統來滿足現代製造系統任務之需求。隨著交易市場全球化的影響，需求的變化
已日益快速且多樣化，製造業者面臨到客戶對於供應速度、品質、生命週期縮短等愈
來愈嚴苛的要求，專業分工以及跨國生產的製造模式儼然已成為趨勢。由此，我們將
現代分散式製造體系供應鏈中，製造業者與供應商以及下游客戶之間工作排程的問
題，建構為一具備區域性自主決策結構(locally autonomous decision structure)之分散式
排程問題。此分散式排程問題在學理上而言是屬於混合型整數規劃(Mixed Integer
Programming)問題。有識於問題數學模型的可分解性，數學規劃法 (Mathematical
programming approaches)，如拉氏釋限法(Lagrangian Relaxation)，在求解可分解的
(decomposable)最佳化問題時，擁有計算速度上的優勢。拉氏釋限法屬於一類原始-對
偶(primal-dual)之求解演算法。而次梯度(Subgradient)佳化方法則被用來佳化拉氏乘數
(Lagrangian Multiplier)與對偶函數；從經濟學角度出發，次梯度佳化拉氏乘數之方法等
效於競標市場中『價高者得』概念。本研究分別展示四種次梯度佳化方法，並應用於
求解一非線性規劃(Nonlinear Programming)問題與一混合型整數規劃問題，以進行佳化
效能評估與優劣比較。
關鍵字：競標、分散式排程、拉氏釋限法、次梯度、最佳化
11 Introduction
Discrete optimization deals with problems of maximizing or minimizing a function of many
variables subject to inequality and equality constraints and integrality restrictions on some or all
of the variables [1]. An important and widespread area of applications concerns the
management and efficient use of scarce resources to increase productivity, such as manufacturing
scheduling [2], transportation, cargo-loading, and network routing problem, etc. Long
computational time is usually needed to solve these real-life complex scheduling problems.
Moreover, applications of discrete optimization are in a period of rapid development because of
the widespread use of microcomputers and the data provided by information systems. This is
particular relevant in the manufacturing sector of the economy where increased competition and
flexibility provided by a new technology make it imperative to seek better solutions from large
and more complex sets of alternatives. Mixed integer programs can be used to formulate these
discrete optimization problems. The mixed integer programming problem is NP-hard in
computational complexity [3]. For problems of such a high complexity, dynamic programming
and exhaustive search techniques are either too time-consuming or impractical for optimal
solutions. Rule-based or heuristics approaches can reduce the computation time drastically but
the resultant optimality is not guaranteed. For large-scaled, time-critical mixed integer
programming problem, it is important but difficult to generate a dedicated schedule within limited
computational time.
Playing a fundamental role in constrained optimization in Economics and Mathematics over
decades, Lagrangian relaxation [4] has been designed to solve scheduling problems of realistic
sizes because it is powerful for the optimization of separable nonlinear programming [5] or
integer programming problems. Lagrangian relaxation belongs to a class of primal-dual
algorithm [3] and consists of two parts. In the first part, coupling constraints are relaxed with
the help of Lagrangian multipliers [6, 7] to decompose the minimization primal problem into
several easily solvable subproblems and to form a maximization dual problem. As the solution
of the dual problem does not produce a primal feasible solution, in the second part, a heuristic has
to be implemented in order to modify this solution into a feasible one. Different approaches are
available for the solution of the Lagrangian dual. The correct choice of approach is critical both
for the computational efficiency and solution quality. The subgradient method (SG) [8] is
frequently used to optimize the dual function in Lagrangian Relaxation, where all subproblems
must be optimally solved to obtain a subgradient direction, and the Lagrangian multipliers are
updated along this subgradient direction. For problems of large size, the optimization of all
subproblems are time consuming. It is therefore desirable to obtain a good enough subgradient
direction with less computational efforts. In the surrogate subgradient method (SSG) [9],
however, only approximate optimization of one subproblem is needed to get a proper surrogate
subgradient direction and the directions are smooth for problems of large size. Since there are
many ways to implement approximate optimization, this method provides a framework of
allowing creative variations. The surrogate modified subgrradient method (SMSG) [9]
improves the direction of the surrogate subgradient method with a linear combination of the
3   iiTiiTii
x
i
x
i xcxaxJL   minmin, (7)
Hence, subproblem (IPi) can be written as
(IPi)  iiTiiTii
x
xcxaxJ  min
subject to constraint (4).
The Lagrangian dual problem (LD) to (IP) after Lagrangian relaxation is defined as
(LD)  

,max
,
 (8)
Subject to mR (9)
kRuu  ,0 (10)
3 Subgradient-Based Solution Methodologies
Based on the Lagrangian relaxation framework [4], problem (IP) can be converted into a
two-level optimization problem. The low-level consists of a number of subproblems, and the
high-level consists of updating the multipliersand; the low-level subproblems and high-level
subproblem are solved iteratively until the dual solution converges. The optimal solution of
(LD) is denoted as ).,( *** u
3.1 Framework of SG, SSG, and SMSG
Due to the integral requirements in subproblems, the Lagrangian dual function ),(  is
polyhedral concave made up of many facets and is non-differentiable [3]. In the subgradient
method, the value of ),(  can be calculated by solving all the subproblems for a given set of
Lagrangian multipliers,  ., Let  ixx kik  , be the solutions of subproblems for a given set
of Lagrangian multipliers  kk , at the kth iteration. The subgradients of ),(  with respect
to Lagrangian multipliers  , are
   ;, Axbxg 

 

(11)
   ., Cxdxg 

 

(12)
The Lagrangian multipliers are then updated by
;1 kkkk g  (13)
kkkk g 1 (14)
where  kk xgg  and k is the step size at the kth iteration determined by
22
* )(
kk
k
ek
gg 


 , 20  . (15)
5where 0w is the penalty weighting factor and )( pc is the pth row of C. This penalty term
tends to reduce the constraint violation and alleviate the solution oscillations. The Lagrangian
dual problem (PD) to (IP) is reformulated as
(PD)    







xLw
Zx
w
in
ii
,,minmax,max
,,


(22)
subject to constraints (9) and (10)
Since  ,w is no longer decomposable, only one subproblem is solved at each iteration.
Whereas, the cost function  xLw ,, is still decomposable, since the solutions to the other
subproblems are fixed. A subproblem (IPw,i) is defined as
(IPw,i) iw
x
L ,min (23)
subject to constraint (4)
where
     


k
p
p
PT
ii
T
ii
T
iiiw dxcwbAxbAxwxcxaxJL
1
2)(
, ,0min (24)
As a result, the homogenous subproblems are not solved simultaneously with the same
multipliers and their solutions will be different. The technique of the surrogate subgradient
method is also used to update the Lagrangian multipliers so that the solution of only one
subproblem is needed to form a proper search direction.
4 Numerical Experiments
In this section, a nonlinear programming problem is first tested. The convergence speed
and the quality of directions are compared among SG, SSG, and SMSG methods. Second, the
PSS method is applied to solve a scheduling problem with homogenous subproblems in order to
demonstrate its applicability to the realistic problem.
4.1 Nonlinear Programming Problem
Consider the following non-linear programming problem (P1).
(P1) 2221 1.05.0min xx
x
 (25)
subject to 482.0 21  xx (26)
2505 21 xx (27)
Rxx 21, (28)
It is known that the optimal value of (P1) is 1203 when x1=49 and x2=5, the optimal Lagrangian
Multipliers λ1=22 and λ2=5.4 for constraints (26) and (27), respectively. From Section 2, the
subproblems (P11) and (P12) are
(P11) 121121 55.0min
1
xxx
x
 
74.2 Mixed Integer Programming Problem
The oscillations caused by the homogenous subproblems are illustrated by the following
single-stage scheduling problem with two identical subproblems.
(P2)  


2
1
2
,
100min
i
ii
zx
zxJ (29)
subject to 2
2
1

i
ii zx (30)
2,1,31  ixi (31)
  2,1,1,0  izi (32)
the optimal solution of (P2) is
either z1=1, z2=0, x1=2, 1x23
or z1=0, z2=1, 1x13, x2=2
and the optimal value of (29) is 104. Four solution choices of (P2) are summarized in Table 2.
Table 2: Four Solution Choices of (P2)
z1, z2 z1=z2=0 z1=1, z2=0 z1=0, z2=1 z1=z2=1
x1 Infeasible 2 1x13 1
x2 Infeasible 1x23 2 1
J Infeasible 104 104 202
Infeasible: constraint (30) is not satisfied.
4.2.1 Solution Oscillation by SSG Method
The Lagrangian dual problem (D2) to (P2) is given as follows.
(D2)
 
 





















 



2
1
2
1
2
1,0
31
2100minmax
i
ii
i
ii
z
x
zxzx 

(45)
subject to R
and two identical subproblems (P2SSG,1) and (P2SSG,2) are
(P2SSG,1)  1121100min
1
zxx
x

subject to 31 1x
(P2SSG,2)  2222100min
2
zxx
x

subject to 31 2 x
For a given, the optimal solutions to (P2SSG,1) are summarized in Table 3.
9Table 4: Optimal Solutions of (P2PSS,1)
z1 0 1
  0222 221  zxwx    0222 2211  zxxwx 
x1
  010042 12221  xwzwxx      01004221 12221  xwzwxxw 
The numerical results at each iteration 15,...,2,1k is shown in Table 5 with the penalty factor
25w and the step size [10]
 
  .,
10495.0
2kk
k
wk
zxgk 



Table 5 indicates that the solutions from the two identical subproblems are different and thus the
solution oscillations have been eliminated.
Table 5: Numerical Results of PSS
Iterations 1z 1x 2z 2x  w
1 0 0 0 0 0 100
2 0 0 0 0 1.9 103.8000
3 0 0 0 0 1.9475 103.8950
4 0 0 0 0 1.9641 103.9283
5 0 0 0 0 1.9726 103.9453
6 0 0 0 0 1.9778 103.9557
7 1 1.9612 0 0 1.9814 103.9608
8 1 1.9638 0 0 2.1183 103.9660
9 1 1.9660 0 0 2.2301 103.9699
10 1 1.9678 0 0 2.3235 103.9730
11 1 1.9693 0 0 2.4031 103.9755
12 1 1.9706 0 0 2.4721 103.9776
13 1 1.9718 0 0 2.5325 103.9793
14 1 1.9728 0 0 2.5862 103.9808
15 1 1.9737 0 0 2.6341 103.9821
5 Conclusion
Mathematical programming approaches, such as Lagrangian relaxation, have the advantage
of computational efficiency when the optimization problems are decomposable. In many cases,
the computational time increases almost linearly with the problem size. By using Lagrangian
multipliers to relax the coupling constraints, a minimization (maximization) primal problem can
be converted into a maximization (minimization) dual problem. The subgradient method is
commonly used to optimize dual function by optimizing all subproblems to obtain a zigzagging
subgradient direction. The surrogate subgradient and surrogate modified subgradient methods
save efforts in obtaining a smooth surrogate subgradient direction to achieve a faster convergence.
In order to avoid or alleviate homogenous solution oscillations on problems with identical
1Appendix: Problem Formulations of Auctioneer and Bidder
Notations:
i Job index, i=1,2,….,I
t Time slot index, t=1,2,…T; T is the time horizon for planning
k Job or service provider (bidder), k=1,2,…,K
ESi Earliest starting date for job i
Ri Release date of job i
Di Due date of job i
ri Earliness penalty of job i
di Tardiness penalty of job i
ρik Operation cost of provider k for processing job i
PTik Processing time of job i by provider k
γi Minimal tardiness penalty of job i
pik Reported price(quote) of job i by provider k
pi Price (payment) of job i,
fi Penalty on job i if it is not assigned; note that fi> pik
Ckt Capacity of bidder k at time slot t ( no. of jobs)
I. Auctioneer’s Problem Formulation
The decision variable of auctioneer and the bid indicator variable are as follows,
respectively:



otherwise,0
biddertoassignedisjobif,1 ki
Aik ,i ,k; (1)



otherwise,0
jobonbidsbidderif,1 ik
Bik
,i,k. (2)
Single Assignment Constraint
1
1


K
k
ikA
,i,k. (3)
Bid-based Assignment Constraint
ikik BA  ,i,k. (4)
The auctioneer’s decision problem (ADP) is
(ADP)
i
I
i
K
k
ikik
I
i
K
k
ik
A
fApA
ik
 
  





1 11 1}{
1Minimize
(5)
subject to (1)-(4).
Note the payment or price of job i is 


K
k
ikiki pAp
1
.
