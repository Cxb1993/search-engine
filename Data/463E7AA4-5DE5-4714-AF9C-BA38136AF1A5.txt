motion vectors are estimated in the 
lowest resolution subimage. Then, they 
are scaled with different resolutions and 
propagated to all of the higher resolution 
subimages as initial motion vectors. In 
order to reduce the high cost of motion 
estimation, we use a threshold to 
determine whether the motion vectors 
need to be refined with further searching 
or not. In the second step, a second 
threshold is used to decide if the refined 
motion vectors are appropriate. If the 
threshold is satisfied, the block is 
labeled as intercoded. Otherwise the 
block is labeled as intracoded. As 
compared to MRME, the thresholding 
technique is able to improve the motion 
estimation performance substantially, 
since it preserves a good motion 
prediction and discards a bad one that 
could deteriorate the performance. It 
also provides a better performance under 
an error-prone environment, since the 
intracoded blocks for decoding do not 
depend on the other information of the 
coded video bit stream. These 
intracoded blocks stop the error 
propagation resulting from the corrupted 
reference block in motion estimation 
and prediction. 
    The experiments have shown better 
results from several test video sequences 
with various motion characteristics. The 
proposed algorithm gives a PSNR of 
about 0.2 - 0.7 dB better than either 
MRME or new MRME. The processing 
time of new MRME is about 78% less 
than that of MRME. And the processing 
time of the proposed algorithm is about 
20% - 50% less than that of MRME. 
     
一. 緣由與目的 
   In video coding, we can acquire 
better compression effect if interframe 
redundancy is removed efficiently. 
Motion compensation has been used as 
an efficient temporal prediction. After 
motion compensation, the residual video 
signal tends to be highly non-stationary. 
In transform coding approaches such as 
H.264, MPEG-4, the residual video 
signals are divided into many small 
rectangular blocks. The hardware 
implementation becomes more feasible 
and advantageous with smaller block 
size. However, the block transform 
coding approach suffers from the blocky 
effect in low bit rate applications. 
Wavelet decomposition provides an 
alternative approach to represent 
non-stationary video signals and residual 
signals after motion compensation. 
As compared to transform coding, 
wavelet representation is more flexible 
and can be easily adapted to the nature 
of the HVS. It is also free from blocky 
artifacts due to the nature of its global 
decomposition. Wavelet transform 
decomposes a video frame into a set of 
subbands with different resolutions, each 
corresponding to a different frequency 
band. These multiresolution subbands 
also provide a representation of motion 
structure at different scales. The motion 
activities for the subbands that are 
expanded by the same filter are, hence, 
technique to determine whether the 
motion vectors need to be refined with 
further searching or not. At first, the 
SAVA of all of the wavelet coefficients 
within the current motion block is 
defined to be [24] 
1 1
0 0
SAVA ( , )
N N
p q
C p q
 
 
                        (1) 
where C( p, q) represents the pixel value 
at coordinates ( p, q) of the current block 
of size N2 . 
        At first, the block matching is 
initiated in the lowest resolution 
subimage at the highest level to obtain 
an initial estimation of motion vectors. 
The estimated motion vectors are 
propagated to the other subimages at the 
same level as initial motion vectors. 
Then, we calculate the SAD between the 
current block and reference block 
pointed by the initial motion vectors. If 
the SAD is less than the predefined 
threshold, the initial motion vectors are 
accepted; otherwise, the full search 
algorithm (FSA) is performed to find the 
best match in a predefined search range. 
When the motion estimation at the 
highest level is completed, the motion 
vectors are appropriately scaled 
according to different resolutions and 
used as the initial motion vectors for the 
other subimages at lower levels. Again, 
at lower levels, we make the same 
comparison between the current block 
and reference block pointed by the 
initial motion vectors. If the predefined 
threshold satisfied, the motion vectors 
are accepted; otherwise, the block 
matching is performed for further 
searching. The same continues until the 
bottom level is reached. On the other 
hand, we use one bit to indicate if the 
motion vectors need to be refined. 
        The choice of threshold has a direct 
influence on the performance. The 
threshold used is related to SAVA. The 
reason is as follows. The SAD can be 
seen as the energy of the block 
difference between the current block and 
the reference block. And the SAVA can 
be seen as the energy of the current 
block. Via the comparison between the 
SAD and SAVA, we can easily detect if 
the motion estimation predict well. Now, 
we define threshold-factor as the ratio of 
the threshold and SAVA. Small 
threshold-factor can give a better motion 
estimation and thus increasing the 
computation. On the other hand, a large 
threshold-factor can save the 
computation and thus deteriorating the 
quality of the reconstructed image. The 
typical threshold-factor equal to 0.5 is 
used in our implementation. 
    Further, we note that the 
transformed coefficients may have 
severe variations in the high frequency 
subimages. Some regions may contain 
large coefficients, while others may 
contain small coefficients. For the 
regions containing small coefficients, 
the threshold based on SAVA may be 
inefficient. Hence, we use a fixed 
threshold for further thresholding. The 
value of the fixed threshold in our 
implementation is 2× 2N  
‘1’for intracoded mode. 
    As compared to MRME, the 
thresholding technique is able to 
improve the motion estimation 
performance substantially, since it 
preserves a good motion prediction and 
discards a bad one that could deteriorate 
the performance. It also provides a better 
performance under an error-prone 
environment, since the intracoded 
blocks for decoding do not depend on 
the other information of the coded video 
bit stream. These intracoded blocks stop 
the error propagation resulting from the 
corrupted reference block in motion 
estimation and prediction. Furthermore, 
we can even divide the block into four 
small blocks and then perform the 
comparison between SAD and SAVA 
for the subblocks to achieve better 
performance. In the case, if we also use 
one bit to code the discrimination 
between two modes for a subblock, the 
cost for coding this information will 
increase greatly. Here, we use a simple 
approach to code the comparison results 
in each block. The coding approach is 
described as follows. At first, we 
perform the comparison between SAD 
and SAVA for each subblocks of a block. 
If SAD is less than SAVA in 
all of the subblocks, we only use one bit 
‘0’to code it. Otherwise, we first sent 
one bit ‘1’, then four bits for indicating 
the subblocks intercoded or intracoded. 
The process is illustrated by the 
following example. As shown in Fig. 1, 
the modes of blocks onthe left are coded 
as ‘0010’. The modes of subblocks on 
the right are coded as 
‘00110010’. 
 
三. 研究結果 
   To verify the effectiveness of the 
proposed algorithm, extensive 
experiments were performed. The 
thresholding for saving the computation 
is defined as Threshold 1; the other for 
discarding the mismatched block is 
defined as Threshold 2. The proposed 
algorithm was implemented in two 
different ways: one (Method 1) employs 
the Threshold 2 for each block with 
motion estimation; the other (Method 2) 
employs the Threshold 2 for each 
subblock divided from a block. The 
performance of Methods 1 and 2 was 
evaluated and compared with the other 
existing MRME methods in terms of the 
percentage of motion vectors satifying 
thresholding one and/or two respectively 
and the processing time. 
    Table 2 gives the performance of 
Methods 1 and 2, compared with the 
original MRME and new MRME. The 
average number of bits needed to code 
the motion vectors and modes per frame 
for all the four methods is given in Table 
Threshold 1, the less the bits for coding 
the motion vectors. As the motion 
information decrease, we can spend 
more bits in coding the 
motion-compensated residue and thus a 
better coding performance can be 
obtained. On the other hand, the smaller 
the average percentage of prediction 
motion vectors that satisfy the Threshold 
2, the more blocks are labeled as 
intracoded and thus the more 
improvement it can provide over the 
MRME method.  From our experiments 
with several test video sequences of 
different type, the modified algorithm 
gives a PSNR of about 0.2 - 0.7 dB 
better than either MRME or new MRME. 
The processing time of new MRME is 
about 78% less than that of MRME. And 
the processing time of the modified 
algorithm is about 20% - 50% less than 
that of MRME. 
    
四. 文獻 
[1] ITU-T Rec. H.264/ISO/IEC 
11496-10, “ Advanced Video 
Coding, ”  Final Committee Draft, 
Document JVT-E022, September 
2002. 
[2] M. Antonini, M. Barlaud, P. 
Mathieu, and I. Daubechies, 
“ Image Coding Using Vector 
Quantization in the Wavelet 
Transform Domain, ” Proc. IEEE 
ICASSP,1990, 2297-2300. 
[3] M. Antonini, M. Barlaud, P. 
Mathieu, I. Daubechies, “ Image 
Coding Using Wavelet Transform,”
IEEE Trans. on, Vol. 1, Issue 2, pp. 
205-220, Apr. 1992. 
[4] G. Van der Auwera, A. Munteanu, 
G. Lafruit, J. Cornelis, “ Video 
Coding Based on Motion 
Estimation in the Wavelet Detail 
Images, ” Speech and Signal 
Processing, Vol. 5, 12-15 May 
1998 Page(s):2801-2804. 
[5] M. Barlaud, P. Sole, M. Antonini, 
and P. Mathieu, “ A Pyramidal 
Scheme for Lattice Vector 
Quantization of Wavelet Transform 
Coefficients Applied to Image 
Coding,”Proc. IEEE ICASSP, 1992, 
23-26. 
[6] P. Burt and E. Adelson, “ The 
Laplacian Pyramid as a Compact 
Image Code,”IEEE Trans. Commun. 
31, 1983, 532-540. 
[7]  Weiting Cai, and Malek Adjouadi, 
“ Wavelet-Domain Shift Invariant 
Motion Estimation and 
Compensation,”Video and Speech 
Processing, 20-22 Oct. 
2004,Page(s):49-52. 
[8] R. L., Jr. Claypoole, R. G. Baraniuk, 
and R. D. Nowak, “ Adaptive 
Wavelet Transforms via Lifting,”
Proc. Int. Conf. ASSP, Vol. 3, pp. 
1513-1516, May 1998. 
[9] I. Daubechies, “ The Wavelet 
Transform, Time-Frequency 
Localization and Signal Analysis,”
IEEE Trans. on Inform. Theory, 
Vol. 36, No. 5, pp. 
961-1005,September 1990. 
[10] T. Koga, K. Iinuma, A. Hirano, Y. 
Iijima, and T. Ishiguro, 
“ Motion-Compensated Interframe 
