  2
關系統的研究。終於在 1997 年時，國際上最權威的
人工智慧系列學術大會：第 15 屆國際人工智慧聯合
大會（The 15th International Joint Conference on 
Artificial Intelligence，簡稱 IJCAI-97），機器人足球
競賽被正式的列為人工智慧的一項挑戰。至此，機
器人足球競賽成為人工智慧和機器人的重要主題。 
機器人足球競賽就是以數台機器人組成的隊伍
在一定的規格限制與規則之下比賽，而且比賽的時
候不能有人為操控的介入。機器人足球競賽是一項
跨領域的研究，其必須使用許多的理論與整合許多
的技術方能順利的完成比賽，所以此項研究在世界
上愈來愈受到學術界與產業界的重視，目前在國際
上主要有 RoboCup 與 FIRA 這兩大機器人足球聯盟
正在努力的推動此項研究，而且每年都會在不同的
國家舉辦世界盃機器人足球大賽以及國際性的研討
會，此外美國、中國大陸、德國、荷蘭、法國、義
大利、瑞典、澳大利亞、日本、韓國、新加坡等十
餘個國家已分別成立國家級的委員會組織來規劃其
相關發展。RoboCup 聯盟的最終目標是希望在公元
2050 年能發展出一隊全自動的人形機器足球員與世
界盃足球賽的冠軍隊伍比賽並能贏得勝利。 
目前大多有關人形機器人的研究，仍著重探討
如何使其穩定的行走，此乃因行走之驅動及平衡控
制，為多軸運動動態規劃設計之基本問題。人形機
器人的行走方式大致可分為主動式與被動式兩種。
主動式行走就是在人形機器人上安裝許多致動器，
例如馬達，然後在控制致動器的動作；而被動式的
行走則是利用人形機器人本身的重力及慣性來達成
運動。Murakami 等人利用模糊控制[1]達成人形機器
人的行走控制，使用人形機器人重心位置及各關節
馬達的角速度與角度作為模糊控制器的輸入，並將
模糊控制器分成用於支撐腳與自由腳兩種來達成對
人形機器人之主動式行走控制，最後使用軟體作模
擬驗證。Kim 等人 [2]提出利用 ANFS (Adaptive 
Neuro-Fuzzy System) 將人形機器人行走時 ZMP 
(Zero-Moment Point) 的移動路徑建模，並且實現在
一隻擁有十個自由度的人形機器人上，且會根據實
際環境的地形變化來學習調整模形，使得人形機器
人得以克服不同的地形與坡度。Zhou 等人[3]提出使
用 ANFIS 控制人形機器人的運動，藉由 ANFIS 學習
後自動增減模糊規則數，使得人形機器人的運動能
夠對環境有著更好的適應能力。Juang 於 [4] 提出使
用模糊類神經系統來產生人形機器人的姿態，根據
軟體模擬結果顯示，該系統在經過學習之後已經成
功的使人形機器人穩定的行走。而在被動式的行走
研究方面，Spong 找出了人形機器人在三度空間的
運動軌跡，並可以任意拓展至多軸人形機器人[5]。 
此外，許多學者以神經系統控制為出發點，提
出應用生物的中樞模式產生器（Central Pattern 
Generator, CPG）模型爲核心建立兩足機器人運動控
制系統 [6-9]。根據觀察人類的肢體運動關係，通過
學習方法，訓練 CPG 網路產生反覆、有節奏的關節
運動軌跡。透過模擬與實驗證明了基於 CPG 的機器
人運動控制方法是有效的。而也有基於傳統控制觀
點，提出數學模型計算每一個時間點人形機器人的
各關節旋轉角度，同時此數學模型整合了穩定性分
析與控制，目前也已實現在機器人應用上 [10-11] 。 
機器足球員大賽自 1997 年舉辦第一屆以來，世
界各國皆相繼投入研究，國內對於這方面的研究也
是不勝枚舉[12-21]。陳[12]以適應性 Q-Learning 發展
出一個具有學習能力的競賽策略，使得各機器足球
員在比賽中能互助合作、協調。郭[13]提出以環形電
位場為基礎的控制法，來操控機器足球員的行為並
導引進入容易射門的角度。黃[14]則自行設計一黑白
環狀標籤，嘗試以建立最少的顏色模形方式來分辨
出敵我雙方，使得依靠影像作為迴授訊號的機器足
球員系統能夠具有穩定且有效率的影像處理程序。 
在國外方面，關於機器足球員的研究更是豐
富，包括中小型機器足球員機構或是運動控制的研
究[22-27]，或者是競賽策略的設計與切換 [28-31]。
而最近較受矚目的則是人形的機器足球員賽事。最
近，在德國所舉辦的 RoboCup2006 的人形組賽事，
第一、三名都由日本 Osaka 大學包辦 [32]，另外獲
得第二名的是德國 Freiburg 大學，該研究所開發的機
器人[33,34]是以碳纖維作為骨架，搭配 PDA 作為控
制器的實現平台，並提出一套簡單的演算法，使得
系統可以即時的計算，讓機器人進行全方位的行
走。而國內在人形足球機器人的研究目前仍處於起
步階段[35-37]，未來仍有許多空間可以發展。 
由於機器足球員競賽之最終目標係希望在 2050
年之前，可以擊敗人類的世界足球冠軍隊，這樣的
目標也使得機器足球員之發展有更嚴格卻統一之研
究方向。為求公平之設計原則，2002 年 RoboCup 開
始發展人形機器足球員競賽後，即要求機器人之形
體、功能、大小或重量等，均應對等於一般的人類，
這也說明未來人形機器人之設計發展趨勢及限制。
其中，可預見的是如何設計對等於人類感知能力之
多感知系統，將成為人形機器人設計的重點之一。
由於人形機器人運動控制之設計，不像輪形機器人
那麼單純只是驅動兩輪（或多輪）即可前進後退轉
彎等，因此多感知系統的功能協助將顯得更加重要。 
三、研究方法、結果與討論 
本計畫為整合型計畫之子計畫三，第一年度主
要發展人形機器人的基本感知功能，特別是視覺、
聽覺及觸覺功能之開發。此部分之研究將由一對一
之人形機器人足球賽來予以驗證，驗證目標將以機
器人能完成行走、踢球、避障、尋物、阻擋、負重、
走固定路徑、跌倒站立、基本盤球等動作，因此各
感知系統亦將以完成各動作之目標來設計。 
3.1 視覺功能之設計 
人形機器人的基本動作大多倚賴視覺功能之設
計，以視覺迴授控制方式來達成機器人精確動作之
控制；以行走為例，如僅欲進行前進、後退等步行
功能，吾等設計使機器人驅動一固定模式之多軸關
節運動，即可執行跨行前進或後退之動作；然而，
如果前方有障礙物或機器人依任務及環境資訊應進
行轉彎或踢球等動作時，則應以視覺功能來進行環
境感知之計算。 
  4
圖 3 中的第二個處理流程為色彩空間轉換，由於
本研究之影像辨識過程對光線的影響是相當敏感
的，而 YCrCb 色彩空間係將亮度資訊從顏色中分離出
來，與能夠將亮度資訊分離的 HSV 色彩空間均可克
服光線影響因素，然因幾乎所有取像裝置取得的影像
資訊均為 RGB 色彩，因此可透過色彩空間模型轉換
方式來進行比較。(1)式為 RGB to HSV 轉換公式，(2)
式為 RGB to YCrCb 轉換公式。由(1)式與(2)式之比較
可看出，轉換至 HSV 空間需要大量反餘弦的計算，
對於人形機器人之硬體實現較為不利，且訊號處理之
即時性亦較難達成，因此吾等採用 YCrCb 色彩空間來
降低光線的影響。 
( )( )
( ) ( )( )
( ) ( )
( )
( )
1
2
cos
2
max , , min , ,
max , ,
max , ,
255
R G R B
H
R G R B G B
R G B R G B
S
R G B
R G B
V
−
⎛ ⎞− −⎜ ⎟= ⎜ ⎟− + − −⎝ ⎠
−=
=
       (1) 
0.257 0.504 0.098
0.148 0.219 0.439
0.439 0.368 0.071
Y R
Cr G
Cb B
⎡ ⎤ ⎡ ⎤ ⎡ ⎤⎢ ⎥ ⎢ ⎥ ⎢ ⎥= − −⎢ ⎥ ⎢ ⎥ ⎢ ⎥⎢ ⎥ ⎢ ⎥ ⎢ ⎥− −⎣ ⎦ ⎣ ⎦ ⎣ ⎦
     (2) 
 
圖 4  黃色與藍色在 YCbCr 空間中之分布圖 
利用 PC 程式環境先完成色彩模型之建立後，即
可將各模型以數據表存至影像處理的晶片中，以加速
辨識速率並提高辨識正確率。吾等將相同色系在各種
亮度下的像素值進行分析，圖 4 說明黃色與藍色在
YCrCb 色彩空間上之分佈圖。本子計畫第一年於此子
題所完成之功能主要為足球場上目標物與障礙物之
偵測與定位。而其中目標物以及障礙物顏色之定義如
表 1 所示，本子計畫目前以 RoboCup 規定之顏色為設
計依據。所以，本子計劃於目前完成之視覺伺服系統
係主要利用物體顏色作為主要判斷依據。由於目前吾
等選用的取像裝置，其擷取介面速度不夠足以應付即
時之需求，因此目前仍以單攝影機的架構來進行取
像。根據圖 3 所提出之彩色影像辨識流程。在濾波器
的部份，由於受到硬體性能之限制，影像濾波器由中
值濾波器改成平均濾波器，提高影像處理速度。 
視覺功能的第三個處理流程係利用跳躍搜尋法
逐一對各像素做比對。利用跳躍搜尋法可以減少系統
的計算負載量，不過對於跳躍步長的選擇是相當重要
的。若選擇太長的跳躍步長則會有搜尋不到目標物的
問題或是目標物的像素點數太少造成不精確的問
題。而此計畫目前以跳躍步長為 2 進行研究，此方式
可比不跳躍時減少約 4 倍的搜尋時間。 
  
(a) 視覺系統搜尋目標物之情形 
 
(b) 本計畫之機器人（左）參與競賽之情形 
圖 5  完成之機器人視覺裝置及功能圖例 
視覺功能的第四步驟為使用面積和重心法求顏
色區塊之中心位置，計算公式如(3)式。其中 Xc、Yc
表示顏色區塊中心位置，xn 與 yn 表示每個像素的位
置，n 則表示像素的總點數；最後在經過一連串的影
像處理後，系統可以得到在影像中各種顏色的位置座
標。而由於視覺伺服系統架構已改為單攝影機，所以
在座標轉換與距離檢測的部份則以計算顏色區塊中
心與機器人中心相對於 X 軸之夾角取代之，如(4)式所
示。其中，
cθ 代表顏色區塊中心與機器人中心相對於
X 軸之夾角，( )0 0,x y 代表機器人中心於影像上的座標。 
1
1
/
/
n
c n
n
c n
X x n
Y y n
=
=
∑
∑
                       (3)  
( ) ( )( )1 0 057.796 tanc c cx X y Yθ −= × − −        (4) 
目前已完成所有功能之雛形（如圖 5），剩餘之計
畫執行期間將加強功能正確性之測試及校正。這部分
之研究部分成果，亦已於『2006 台灣智慧型機器人大
賽』獲得兩項競賽獎項（亞軍、季軍）[38, 39]，並於
國際會議完成發表[40-42]。 
3.2 聽覺及語音功能之設計與實現 
近年來，如何設計合適的機器人來為人類服務，
並增進人類的生活品質與效率，是機器人相關研究之
重要方向。同時，如何增進機器人與使用者間之互動
性，亦成為此領域之熱門課題之ㄧ。大多之研究均以
提高機器人的擬人特性，來改善機器人與人類之互動
能力。在機器人感官功能的模擬上，最早也是目前開
發最為成熟的技術為機器視覺，其次則為聽覺系統。 
機器人的聽覺功能多利用取音裝置（如麥克風）
接受聲波後，轉換成電壓來進行語音及語意之辨識，
這如同人類的耳朵接收到聲音，轉換成訊號刺激大腦
一般。聲波主要透過空氣進行傳遞，而在一個密閉的
環境下(例如：展覽館、辦公室等)，空氣中同時有其
Visual system 
  6
表2  FSLR 系統之模糊規則庫 
V1 
V2 VS S M B VB
VS C C N VN VN
S C C C N VN
M F C C C N 
B VF F C C C 
VB VF VF F C C 
(when V1，V2=A，B or B，C or C，D or D，A) 
 
圖 9 系統方塊圖 
 
 
圖 10 類神經控制器結構圖 
3.3  觸覺及平衡感知功能之設計 
基於神經科學的觀點而言，人類在行走的時候，
每一個關節所旋轉一連串的角度可以視為是一個具
有週期性的訊號，而這些訊號都是屬於一種反射動
作。是故，有研究就利用模擬生物體的中樞模式產生
器(central pattern generator)來控制機器人的運動。而
在本年度的計劃中，所探討的是平衡感知的功能。一
般而言，在進行控制器設計之前，都會需要一個能夠
表示受控體的數學模型，如此才能夠設計合適的控制
器。但是在實際的應用上，受控體的數學模型通常是
難以找到或是過於複雜而難以表示。而本子計畫所欲
應用之受控體為一多自由度之兩足機器人也是屬於
此一類型。所以，藉由類神經網路能夠即時學習的能
力，吾等所設計之控制器可以在受控體模型未知的情
況之下，直接將其套用實際的系統當中，使得控制器
能夠根據輸入映射出適當的修正量，使得機器人達到
平衡的姿態。 
對於運動上的控制，本子計畫預先設定的各關節
在每一時間點所應旋轉的角度，並將該資料建表。此
外，吾等設計一個類神經網路的平衡控制器，針對目
前機器人的姿態對角度作一調整已達到平衡。而控制
器主要的輸入使用一個兩軸陀螺儀，並且將其安裝在
機器人軀幹之中心點，分別感測機器人橫向與縱向之
傾斜角度。整體系統方塊圖如圖 9 所示。其中，圖中
Motion Data 表示的是各關節的旋轉角度參數，經由類
神經網路控制器修正之後，在輸入給機器人，而控制
器的回授訊號則由陀螺儀所量測得到。值得注意的
是，吾等所設計之類神經姿態平衡控制器為即時學
習，不需要預先準備訓練資料使得控制器達到收斂狀
態才能使用在真實的系統上。 
而該類神經控制器之結構如圖 10 所示。此控制
器共有三層，分別為輸入層、隱藏層與輸出層。其中，
各符號所代表之意義如表 4 所示。吾等所設計之控制
器輸出為每一關節之旋轉角度的修正量，是故隱藏層
所選用的觸發函數為雙曲線正切函數，該函數的輸出
範圍在[ 1,1]− 之間，以 ()htsf 表示，如式(5)所示。 
( )
q q
q q
v v
hts q v v
e ef v
e e
−
−
−= +
                    (5) 
首先，類神經網路的輸入層沒有做任何處理。而
輸入訊號傳遞隱藏層後，便由式(6)計算輸出向量
qh 。
而後，隱藏層的輸出在傳遞到輸出層成為輸入，並且
經過式(7)的計算後得到輸出向量
qy 。 
1
n
q hts j xh xh
j
h f x w b
=
⎛ ⎞= −⎜ ⎟⎝ ⎠∑                 (6) 
1
l
q hts j hy hy
j
y f h w b
=
⎛ ⎞= −⎜ ⎟⎝ ⎠∑                 (7) 
基本上，吾等所設計之類神經網路唯一基本型態
之多層感知機，並且經由倒傳遞學習演算法使得該網
路達到收斂，如下所示。首先，計算輸出層的誤差訊
號，如式(8)所示。其中，
dy 表示期望的輸出值而 qy 代
表類神經網路的實際輸出值。 
( )( )( )1 1i i i i iy d d d qe y y y y= + − −%              (8) 
( ) ( )1 ih q q hy ye h h w e= − ×% %                  (9) 
而後，根據倒傳遞演算法，誤差訊號為一層層的
傳遞回到前面，如式(9)所示。式(8)以及(9)分別所計
算的是輸出層與隱藏層的誤差訊號，而各層中間的權
重與神經元的偏權值則依誤差訊號進行調整，如式(10)
與(11)所示，其中，β 表示的是學習速率。 
( , ) 1 ( , )
1
hy hy
l m l m y q
hy hy
m m y
w w e h
b b e
β
β
+
+
⎧ = + × ×⎪⎨ = − ×⎪⎩
%
%
                 (10) 
( , ) 1 ( , )
1
xh xh
n l n l h q
xh xh
l l h
w w e x
b b e
β
β
+
+
⎧ = + × ×⎪⎨ = − ×⎪⎩
%
%
                 (11) 
表 3 符號解釋 
qx  輸入向量 1 2[ ]
T
nx x xL  
qh  隱藏層輸出向量 
T
qy  輸出層向量 
T
,xh hyw 神經元連結權種值 
,xh hyb 神經元偏權值 
,y he%  誤差訊號 
  8
四、研究成果自評 
本研究完成人形機器足球員之實體製作並於比
賽中獲得良好之成果驗證，可持續朝多感知系統進行
整合設計及實現。同時，初步完成人形機器人之雛形
設計，可進行簡單行走、單腳站立、踢球、避障、完
成指定路線行走等功能。 
此計畫之成果已參與 94 年 11 月於成大舉辦的
2005 台灣智慧型機器人大賽，獲得人形機器人競賽組
的第三名，該研究完成人形機器人（Achilles）之雛形，
其中機器人係以 CMOS 攝影機與 DSP 晶片模組進行
影像處理，提供機器人之視覺功能；另以紅外線感測
器（IR Sensors）及彩色感測器（Color Sensors）進行
避障判斷並提供機器人之視覺輔助；此外，人形機器
人之運動控制則由陀螺儀（Gyroscope）及運動控制器
（RCB-1）來執行，這些訊號將交由一 FPGA 架構之
控制系統進行整合，使機器人 Achilles 可以進行各項
動作及運動。 
為完成人形機器人之各項動作如前進、轉彎、單
腳站立、踢球等，我們將先建立各項動作之運動模
式，我們於本年度之計畫中，亦已將前進所需各關節
的轉動情形加以學習及記錄，建立一前進模式，機器
人只需反覆執行該模式即可一直向前行走。而機器人
之運動控制則由運動控制器（RCB-1）依照各感知系
統迴授之外界訊號進行判斷，決策出該進行的模式為
何，即可完成各項動作。本研究之成果也已參加 2006
台灣智慧型機器人大賽，獲得『RoboCup 人形機器人
競賽組』的亞軍及『FIRA 人形機器人競賽組』的第
三名。[38,39] 同時已將成果發表於 2007 ICM、2007 
ISND、2007CACS 等國際研討會發表[41,42,45]，並延
伸為往後研究之基礎。 
此外，本研究計畫共有 3 篇碩士論文及 6 篇會議
論文[40-45]完成發表，並已整理投往國際期刊，相關
研究亦將持續進行。 
五、參考文獻 
[1] Murakami, S.; Yamamoto, E.; Fujimoto, K. “Fuzzy 
control of dynamic biped walking robot,” in Proceedings 
of 1995 IEEE International Conference on Fuzzy Systems, 
Volume 1, 20-24 Mar. 1995, p.77-82. 
[2] Kim, D.; Seo, S.-J.; Park, G.-T. “Zero-moment point 
trajectory modelling of a biped walking robot using an 
adaptive neuro-fuzzy system,” IEE Proceedings of 
Control Theory and Applications, Volume 152, Issue 4, 8 
July 2005, p.411-426. 
[3] Changjiu Z.; Jagannathan, K. “Adaptive network based 
fuzzy control of a dynamic biped walking robot,” in 
Proceedings of 1996 IEEE International Joint Symposia 
on Intelligence and Systems, 4-5 Nov. 1996, p.109-116. 
[4] Juang, J.-G. “Fuzzy neural network approaches for robotic 
gait synthesis,” IEEE Transactions on Systems, Man and 
Cybernetics, Part B, Volume 30, Issue 4, Aug. 2000, 
p.594-601. 
[5] Spong, M.W.; Bullo, F. “Controlled symmetries and 
passive walking,” IEEE Transactions on Automatic 
Control, Volume 50, Issue 7, July 2005, p.1025-1031. 
[6] Reil, T.; Husbands, P. “Evolution of Central Pattern 
Generators for Bipedal Walking in a Real-Time Physics 
Environment,” IEEE Transactions on Evolutionary 
Computation, Volume 6, No. 2, Apr. 2006, p.159-168. 
[7] Matsubara, T.; Morimoto, J.; Nakanishi, J.; Sato, M.; 
Doya, K. “Learning CPG-based biped locomotion with a 
policy gradient method,” Robotics and Autonomous 
Systems, Volume 54, Issue 11, Nov. 2006, p.911-920. 
[8] Pinto, C. A.; Golubitsky, M. “Central pattern generators 
for bipedal locomotion,” Mathematical Biology, Volume 
53, 2006, p.474-489. 
[9] Geng, T.; Porr, B.; Wörgötter, F. “A Reflexive Neural 
Network for Dynamic Biped Walking Control,” Neural 
Computation, Volume 18, 2006, p.1159-1196. 
[10] Huang, Q.; Yokoi, K.; Kajita, S.; Kaneko, K.; Arai, H.; 
Koyachi, N.; Tanie, K. “Planning Walking Patterns for a 
Biped Robot,” IEEE Transactions on Robotics and 
Automation, Volume 17, No. 3, June 2001, p.280-289. 
[11] Huang, Q.; Nakamura, Y. “Sensory Reflex Control for 
Humanoid Walking,” IEEE Transactions on Robotics, 
Volume 21, No. 5, Oct. 2005, p.977-984. 
[12] 陳建成，以適應性 Q-Learning 為基礎發展足球機器人
合作策略，中正大學電機工程研究所碩士論文，2002。 
[13] 郭有鎮，設計實現環型電位場控制法於三對三足球機
器員競賽系統，成功大學電機工程學系碩士論文，
2001。 
[14] 黃雋博，小型機器人足球系統之即時影像處理，淡江
大學電機工程學系碩士論文，2002。 
[15] 旦瑞誠，機器人足球賽五對五模擬組之策略設計，淡
江大學電機工程學系碩士論文，2001。 
[16] 李錫慶，五對五機器足球員競賽之設計與實現，成功
大學電機工程學系碩士論文，2002。 
[17] 李青煌，加強式學習應用於足球機器人多重策略之合
作，中正大學電機工程研究所碩士論文，2002。 
[18] 鄧宏志，中型機器人足球系統之即時影像處理，淡江
大學電機工程學系碩士班論文，2005。 
[19] 駱佑瑋，輪型足球機器人之整合型小腦模型控制器設
計與路徑規劃，淡江大學電機工程學系碩士論文，
2005。 
[20] 陳偉生，中型足球機器人之即時影像定位與動態路徑
規劃之研究，成功大學電機工程學系碩士論文，2005。 
[21] 林政隆，中型足球機器人之動態環境資訊共享與動態
行為策略之實現，成功大學電機工程學系碩士論文，
2005。 
[22] Bonarini, A.; Aliverti, P.; Lucioni, M. “An omnidirectional 
vision sensor for fast tracking for mobile robots,” IEEE 
Transactions on Instrumentation and Measurement, 
Volume 49, Issue 3, June 2000, p.509-512. 
[23] Schmitt, T.; Hanek, R.; Beetz, M.; Buck, S.; Radig, B. 
“Cooperative probabilistic state estimation for 
vision-based autonomous mobile robots,” IEEE 
Transactions on Robotics and Automation, Volume 18, 
Issue 5, Oct. 2002, p.670-684. 
[24] Weigel, T.; Gutmann, J.-S.; Dietl, M.; Kleiner, A.; Nebel, 
B. “CS Freiburg: coordinating robots for successful soccer 
playing,” IEEE Transactions on Robotics and Automation, 
Volume 18, Issue 5, Oct. 2002, p.685-699. 
[25] Marques, C.; Lima, P. “Avoiding obstacles - multisensor 
navigation for nonholonomic robots in cluttered 
environments,” IEEE Robotics & Automation Magazine, 
Volume 11, Issue 3, Sep. 2004, p.70-82. 
[26] Gupta, G. S.; Messom, C. H.; Demidenko, S. “Real-time 
identification and predictive control of fast mobile robots 
using global vision sensing,” IEEE Transactions on 
Instrumentation and Measurement, Volume 54, Issue 1, 
Feb. 2005, p.200-214. 
[27] Klancar, G.; Kristan, M.; Karba, R. “Wide-angle camera 
distortions and non-uniform illumination in mobile robot 
tracking,” Robotics and Autonomous Systems, Volume 46, 
Issue 2, Feb. 2004, p.125-133. 
[28] Hwang, K.-S.; Tan, S.-W.; Chen, C.-C. “Cooperative 
strategy based on adaptive Q-learning for robot soccer 
systems,” IEEE Transactions on Fuzzy Systems, Volume 
12, Issue 4, Aug. 2004, p.569-576. 
[29] Uchibe, E.; Asada, M. “Incremental coevolution with 
