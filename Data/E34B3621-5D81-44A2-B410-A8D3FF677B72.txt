  1
一、前言 
       近年來，行動通訊技術蓬勃發展，使我們能夠隨心所欲的使用語音，透過手機，來做
社交活動以及商業交易等行為。然而語音並非只有溝通的功能，每個人的聲音特性以及說
話習慣並不相同，如果能夠以口語的方式來劃分使用者權限，以及身分認證等重要存取活
動的話，豈不是可以使我們的生活更加便利。此時辨識系統的準確度將是非常重要的需
求，特別是在具有噪音的日常生活環境中，因此我們需要一個很穩健的技術，來提升系統
的安全性和可靠性。 
語者辨識是近年來被極廣泛討論的課題，對人類而言，互相判斷說話者是誰並不困
難，但對電腦而言，卻不是件容易的事情。每個人的聲學特徵都不相同，即使同一個人說
同樣的話，每次所顯示的語音特徵也不會一模一樣，特別是在日常的工作環境中，又必須
考慮到雜訊的干擾，則正確辨識的難度又更高。因此若能擷取說話過程中咽喉的額外資
訊，輔以優良的辨識方法，使電腦能夠藉著發聲過程中的充分資訊來判斷語者，使得無論
在安靜或帶有噪音的環境中，都能大幅降低判斷結果的誤差，是許多學者研究的課題。 
 
二、研究目的 
本研究的動機是著眼於美國的 Lawrence Livermore 國家實驗室所提出的以電磁咽喉微
振動感測技術(Electromgagnetic Glottal Micro-Motion Detection Technology，EMGODT) 輔
助語者辨識上的構想[1]，以及 Aliph 公司利用這樣的技術推出的音聲雜訊消除產品[2]。其
技術主要是透過電磁波照射咽喉部位，以萃取每個人發音的聲門振動特徵。在發聲的過程
中，聲帶的震動提供產生的聲音的激發函式(Excitation function)，是與個人的生理解剖及
生理特徵密切相關[3]；而經由聲道、鼻腔及口腔的聯合作用所形成的聲音，則和個人的發
音習慣和技巧有關，可以模仿習得；因此人類發聲時聲帶部位的振動可以提供發聲時的生
理作用特徵，且和語音訊號有密切相關。 
       因此本研究師法美國的 Lawrence Livermore 實驗室所提出的以咽喉特徵輔助語音特徵
的研究方向，並將其使用電磁波的構想，在實驗環境的限制底下，改以微振動感測器來量
測咽喉的振動訊號，同時結合近幾年來在語音處理以及語者辨識的技術發展，以開發出具
有高效能以及高抗雜訊能力的語者辨識系統。 
 
三、文獻探討 
Burnett 等人(1999)[4]比較以傳統聲音訊號和使用電磁波咽喉微振動感測器(glottal 
electromagnetic micro-power sensor，GEMS)所擷取的聲音在語者驗證上之效能，實驗結果
顯示：使用電磁波咽喉微振動感測到的訊號，在不同白雜訊訊噪比之下，皆比只使用傳統
聲音訊號有更高的辨識率。Burnett 等人(2000)[5]進一步將電磁波所偵測到的咽喉訊號，輔
助傳統聲音訊號，設計出適當的濾波器。發現若能輔以電磁波所偵測到的咽喉訊號，能大
幅改善只使用聲音的雜訊消除效能。Campbell 等人(2003)[6]將電磁波咽喉微振動感測器與
聲帶振動量測器(EGG)及生理麥克風(P-mic)等用來擷取咽喉訊號的技術，使用支持向量機
做為系統的分類器，於語者確認上做一個比較。也驗證了這些方法皆能夠改善傳統只使用
聲音之語者辨識效能。 
另外在分類器方面， Wan 等人(2000)[7]將支持向量機的技術應用於處理語者辨識的
研究上，採用 12 階的 LPCC 倒頻譜參數以及 12 階的差量倒頻譜參數為輸入參數。探討使
用核函數為 polynomial 時，當階數高時(order=10，error rate=4.5%)其辨識效果比階數
  3
4.2 前處理 
        所取得的語音訊號，必須先做端點偵測(End Point Detection)[10] 以移除靜音段或背景
雜訊，再將語音訊號 )(ns 通過一個高通濾波器： 
 )1(*)()(2 −−= nsansns                                   (1) 
在這裡的 a值設為 0.96，其目的除了消除發聲過程中聲帶和嘴唇的效應，並補償語音信號
受到發音系統所壓抑的高頻部分。        
接著是將語音資料音框化，將整段訊號切成 256 點的音框進行短時段語音訊號處理。
為了避免相鄰兩音框的變化過大，所以我們必須讓兩相鄰音框之間有一段重疊區域，這樣
比較能看到語音特徵改變的延續性，然而因個人說話習慣而導致訊號時間長短不一，因此
採用變動重疊寬度  (Dynamic-size overlap) 音框的方法 [11]來計算重疊比率 (約重疊
1/4~1/2)，使不同長度的語音訊號能取到固定音框長度下的相同分析框數量(50 個音框)，
以簡化後續的特徵擷取及辨識架構。最後再乘上 256 點之漢明窗(hamming window)以改進
音框左右兩端之連續性，並增強訊號的頻譜特性。 
4.3 特徵擷取 
        梅爾倒頻譜參數 (Mel-frequency cepstral coefficients，MFCC)[12]近幾年普遍的應用於
語音以及語者辨識系統。因為考慮到人類聽覺系統，對低頻的聲音感知能力較強，在 1 
kHz 以下約呈線性關係；而對高頻的聲音感知能力較弱，在 1 kHz 以上約呈對數關係，。
因此 MFCC 在求取特徵參數時具有低頻部份多取，而高頻部份少取的特性。在本實驗中
採用 12 維之梅爾倒頻譜參數。 
4.4 多類別支持向量機 
        在辨識開始之前，首先必需建立一個語者模型。目前常見於語者辨識系統的語者模型
非常多，其中效能較佳且較典型的如隱藏馬可夫模型 (Hidden Markov Model, HMM)[13]、
高斯混合模型(Gaussian Mixture Model, GMM)[14]、類神經網路(Neural Networks)[15]，以
及近幾年被廣泛運用的多類別支持向量機(Multi-class SVM)[8][16]等，考慮演算的複雜度
和分類的效能，本研究所採用的是速度訓練速度快速的多類別支持向量機來建立語者模
型。 
        支持向量機早期是設計用來解決兩類別的分類問題，後來才延伸為處理多類別的分類
[17]，目前許多學者所提出的多類支持向量機的相關文獻研究，主要可分為 Bottou 等人 
(1994)所提的一對全部(one-against-all)、Friedman (1996) 以及 KreBel (1999)等多位學者所
提的一對一(one-against-one)與 Platt 等人(1999)所提出的 DAGSVM 等三種方法。根據 Hsu 
和 Lin (2002)的研究中以實際的資料測試的結果，其實並沒有哪一種在處理多類別的問題
時能絕對比其它方法有用，只是在處理大量資料時採用一對一的方法配合 DAGSVM 在訓
練階段(training phase)會比其它方法有效率。 
       因此本研究之架構採用的是複雜度較低的一對全部(one-against-all)的方法，如圖二所
示，每一個 SVM 各代表一位語者，舉 SVM 1 為例，我們將第一位語者設為 1 類，其他的
語者則為第 2 類，依據這樣的方式，依序建立每位語者的模型。當測試語料輸入系統時，
將資料送進每一個支持向量機，每個支持向量機各會得到一個分數，選取分數最高者即為
分類的結果。同時亦比較兩種高效能且常用的核函式 (Kernel functions)，即多項式
(Polynomial, poly)和徑向基函數(Radial-basis function, RBF)的效能。 
 
  5
圖四為在安靜的實驗室環境下其中一位語者唸 “523” 時所測得的兩種訊號波形圖。我們發
現聲音以及咽喉訊號波形的變化非常類似，因此我們嘗試將咽喉訊號播放出來，以感受在
聽覺上兩訊號之間的差異性。此時很意外的發現咽喉訊號在聽覺上居然和麥克風所收到的
聲音訊號非常類似，只是咽喉訊號比較沉悶一些，不如麥克風所收到的聲音來的宏亮。 
 
 
圖四： 安靜環境下的波形圖 
 
        接下來我們測試在吵雜的環境之中，兩種訊號受到干擾的情形。同樣在一般實驗室的
環境底下，於受測者身邊播放高音量的音樂作為背景雜訊來源，由圖五中可以明顯觀察到
麥克風受到背景雜訊非常大的干擾，完全無法在圖中看到受測者唸 “523” 所應顯示的波
形，但是加速規所量測的訊號 卻完全不受影響，完整的顯示出在安靜環境下所測得的原
有波形。這是因為加速規主要收到的訊號是以人類發聲時，氣流通過咽喉導致聲帶發生振
動，藉由皮膚傳達至加速規上。而麥克風則是透過周圍的聲波推動內部振膜，然後震膜帶
動線圈，利用磁力線的改變產生微弱的電壓而產生的訊號。因此聲波無法被加速規所接
收，所以不受聲波干擾而呈現出原本清楚的波形。 
 
 
圖五：  吵雜環境下的波形圖 
  7
5.5 安靜環境下之實驗 
        接下來我們以左側 15 次做為訓練資料，另外 5 次做為測試資料。於表 II 的辨識結果
中我們可以發現到，只使用聲音訊號的資料下，其語者辨識率最高可達 94%。而只使用咽
喉訊號的辨識效果上，可達到 92%。這樣的數據看起來兩者之間的辨識率其實不相上下，
也可以了解到其實只使用咽喉訊號做為辨識的參數時，可以達到一般語者辨識系統所使用
的聲音特徵。如果將兩種特徵結合在一起，更能夠輔助傳統語者辨識系統進一步將辨識率
提高至 96%。 
 
表 II： 安靜環境下之語者辨識結果 
 Voice Glottal Voice & 
Glottal 
Poly 92% 92% 96% 
RBF 94% 92% 96% 
 
 
5.6 吵雜環境下之實驗 
        為了驗證吵雜環境下咽喉訊號的輔助能力，我們先以最極端的雜訊做測試，因此重新
錄製一組新的資料於實際吵雜之環境中。由表 III 中我們可以發現，只使用聲音做為辨識
之架構其辨識率大幅下降，最高只有 20%，但咽喉部份卻不受外在噪音所影響，最高可達
88%。實驗結果證明傳統聲音非常容易受到外在噪音所干擾，雖然咽喉訊號與表 II 相比有
下降趨勢，但此為重新錄製之訊號，因此在資料上才會不完全一致。 
 
 
表 III： 吵雜環境下之語者辨識結果 
 Voice Glottal Voice & 
Glottal 
Poly 0% 80% 34% 
RBF 20% 88% 42% 
 
        透過上述實驗的測試，我們了解到咽喉訊號的抗雜訊能力，因此我們以合成的方式將
吹風機運轉噪音加入於無殘響室所錄製之資料庫中，觀察在不同訊/噪比之下，咽喉訊號
對於傳統語者辨識系統之輔助能力。結果分別表示在表 IV 及圖七中，在安靜的環境中聲
音辨識率為 94%，隨著訊噪比值的下降，辨識率也會隨之降低，直到訊/噪比為 0~5dB
時，聲音訊號的辨識率只剩下 20.03%，和表 III 實際環境下錄製的聲音訊號辨識率幾乎相
同，約在 20%。 
       其中訊/噪比在 0~5dB 時，聲音辨識率完全相同，但是結合咽喉振動特徵時，卻明顯上
升了約 14%。這是因為兩者的聲音辨識率恰巧都在 20.03%，但是其中所挾帶的資訊並不
相同，透過咽喉振動特徵的輔助，而將辨識率的精確度提高。 
隨著聲音訊號辨識率的上升，咽喉特徵所帶來的影響也越趨明顯，當訊/噪比達到
10dB 時，咽喉訊號即可輔助聲音將辨識率提高至 90%，具有相當良好的效果。 
 
 
 
  9
七、參考文獻 
[1] J. F. Holzrichter, “New ideas for speech recognition and related technologies,” Lawrence 
Livermore National Laboratory, UCRL-UR-120310, 1995. http://www.ntis.gov. 
[2] 美國舊金山 Aliph 公司網址 http://www.aliph.com/main/ 
[3] L. R. Rabiner and B. H. Juang, Fundamentals of Speech Recognition, Prentice Hall, pp. 200-
232, 1993. 
[4] T. J. Gable, G. C. Burnett, J. F. Holzrichter, and L. C. Ng, “Speaker verification performance 
comparison based on traditional and electromagnetic sensor pitch extraction.” in the 138th 
Meeting of the Acoustical Society of America, Columbus, Ohio, Nov. 2, 1999. 
[5] L. C. Ng, G. C. Burnett, J. F. Holzrichter, and T. J. Gable, “Denoising of human speech 
using combined acoustic and EM sensor signal processing", in Proc. International 
Conference on Acoustics, Speech, and Signal processing ICASSP 2000, June 5-9,2000. 
[6] W. M. Campbell, T. F. Quatieri, J. P. Campbell, and C. J. Weinstein, “Multimodal speaker 
authentication using nonacoustic sensors,” in Proc. Workshop Multimodal User 
Authentication, pp. 215–222, Santa Barbara, CA, Dec. 2003. 
[7] V. Wan, W. M. Campbell, “Support vector machines for speaker verification and 
identification,” in Proc. Neural Networks for Signal Processing X, vol. 2, pp 775-784, Dec. 
11-13, 2000. 
[8] F. Hou and B. Wang, “Text-independent speaker recognition using support vector machine,” 
in Proc. Int. Conf. Info-tech and Info-net 2001, ICII 2001, Beijing, China, vol. 3, pp 402-407, 
Oct. 29- Nov. 1, 2001. 
[9] M.-I. Faraj and J. Bigun, “Synergy of lip-motion and acoustic features in biometric speech 
and speaker recognition” IEEE Trans. Computers, vol. 56, no. 9, pp. 1169-1175,  Sep. 2007. 
[10] A. Hussain, S. A. Samad and L. B. Fah, “Endpoint detection of speech signal using neural 
network,” in Proc. TENCON 2000, vol. 1, pp. 651-654, Malaysia, Sep. 2000. 
[11] 陳松琳, “以類神經網路為架構之語音辨識系統,”中山大學電機工程學系碩士論文,2002
年 6 月. 
[12] J.-S. R. Jang, 線 上 中 文 教 材 ： 音 訊 處 理 與 辨 識 Home page ：
http://neural.cs.nthu.edu.tw/jang/books/audioSignalProcessing 
[13] L. Zhang, Z. Yang, and B. Zheng, “A new method to train VQ codebook for HMM-based 
speaker identification,” Proc. 7th Int. Conf. Signal Processing, vol.1, pp.651-654, Aug. 2004. 
[14] D. A. Reynolds and R. C. Rose, “Robust text-independent speaker identification using 
Gaussian mixture speaker models,” IEEE Trans. Speech and Audio Processing, vol. 3, no1, 
pp. 72-83, Jan.1995 
[15] Y. A. Alotaibi, “High performance Arabic digits recognizer using neural networks,” in Proc. 
IEEE Int. Joint Conf. Neural Networks, vol. 1, pp670-674, July 2003  
[16] S.-Y. Sun, C. L. Tseng, Y. H. Chen, S. C. Chuang, and H. C. Fu, “Cluster-based support 
vector machines in text-independent speaker identification,” IEEE Int. Joint Conf. Neural 
Networks, vol. 1, pp. 25-29, July 2004. 
[17] H. Lei and V. Govindaraju, “Half-Against-Half Multi-class Support Vector Machines,” in 
Proc. 6th Int. Workshop on Multiple Classifier Systems (MCS'05), pp. 156-164, Mar. 2005. 
 
Sung-Nien Yu1 and Kuan-To Chou1, 2
yusn@ee.ccu.edu.tw, gdchou@mail.wfc.edu.tw
1Department of Electrical Engineering, National Chung Cheng University, Taiwan 
² Department of Electronic Engineering, Wu Feng Institute of Technology, Taiwan 
Abstract—We propose a method that uses independent 
component analysis (ICA) and backpropagation neural network 
to classify electrocardiogram (ECG) signals. In this study, ICA 
is used to extract important features from ECG signals. A 
backpropagation neural network follows to classify the input 
ECG beats into one of eight beat types. The independent 
components are calculated from the training ECG beats and 
serve as the ICA bases of the system. The ECG beat samples are 
then projected on the bases to build the ICA features for 
different beat types. The features based on ICA and the time 
interval between successive ECG beats are constituted into a 
feature vector and serve as inputs to the backpropagation 
neural network. In the study, 9800 QRS samples, including eight 
different ECG types, were extracted from the MIT-BIH 
arrhythmia database for experiments. Half of the samples were 
used in the training phase and the other half in the testing phase. 
The experiments showed an impressive highest accuracy of 
98.37% under the condition that only 23 independent 
components were used. The results demonstrate the capability 
of the proposed method in the computer-aided diagnosis of 
heart diseases based on ECG signals. 
I. INTRODUCTION
HE electrocardiogram (ECG) has become one of the most 
important tools in the diagnosis of heart diseases because 
it is noninvasive in nature and abundant in diagnostic 
information. Early and quick detection and classification of 
ECG arrhythmia is important, especially for the treatment of 
patients in the intensive care unit. This requisite gives rise to 
the recent intensive studies in developing computer-aided 
diagnostic systems based on ECG. The capability of a 
computer-aided diagnostic system depends on its ability to 
discriminate the various ECG types based on their 
morphological features. In this study, we propose to use 
independent component analysis (ICA) method to extract 
features from the ECG beats. These ICA features together 
with the RR interval then serve as inputs to a backpropagation 
neural network classifier to separate the ECG signals into 
different pathological types. 
Independent component analysis (ICA) [1]-[3] is an 
effective statistical technique developed originally to deal 
with problems that are related to the cocktail-party problem. 
This technique expresses a set of random variables as linear 
combinations of random variables that are statistically 
mutually independent. ICA is mainly applied to solve 
problems such as blind source separation (BSS) and feature 
extraction. The application of ICA to biomedical signal 
analysis includes, but is not limited to, the separation of fetal 
and maternal ECG signals [4], blind Electrogastrogram (EGG) 
separation [5], EEG and MEG recordings analysis [6], and 
the characterization of ECG signals [7]. 
In the application of ICA to ECG signals, Owis et al. used 
ICA to calculate the components in the Fourier transformed 
domain that are statistically mutual independent [7]. The 
features were calculated by projecting the ECG signals onto 
the subspace constituted by the independent components 
(ICs). By using the ICA-based features to classify five ECG 
beat types, they attained a high accuracy of 100% in 
classifying normal beats, under the condition that more than 
219 ICs should be used. However, the accuracies in 
discriminating the other arrhythmias were moderate. 
Carefully inspecting the spectra of different ECG beats, we 
discovered that three out of the five types of arrhythmias have 
similar spectral density, which could be the reason that causes 
the misclassification. Moreover, the large number of ICs can 
cause the calculation burden in the training stage when large 
database is used. 
In this study, we intend to classify eight ECG beat types, 
including the normal rhythm and seven arrhythmias, with 
combined ICA features and a backpropagation neural 
network. The important features of the ECG signals are 
extracted by applying ICA in the time-domain. The ICA 
features together with the RR interval then serve as inputs to 
the following backpropagation neural network for 
classification. Experiments are designated to evaluate the 
capability of the system. 
II. METHOD
We assumed that the ECG signal is composed of the 
weighted sum of a set of basic components. These basic 
components could be estimated with blind source separation 
method such as independent component analysis (ICA). In 
this section, we first give a short introduction of the 
independent component analysis (ICA) method and then 
describe the proposed method of our system in details. 
A. Independent component analysis (ICA) 
Independent component analysis (ICA) is a signal 
processing technique whose goal is to express a set of random 
variables as linear combinations of statistically independent 
component variables [3]. Assume that at time instant t the 
observed m random variables x 1 (t), …, x m(t), are modeled as 
linear combinations of n random variables s1(t), …, s n (t).
Combining Independent Component Analysis and Backpropagation 
Neural Network for ECG Beat Classification 
T
Proceedings of the 28th IEEE
EMBS Annual International Conference
New York City, USA, Aug 30-Sept 3, 2006
FrC01.1
1-4244-0033-3/06/$20.00 ©2006 IEEE. 3090
Table 1 Records and number of ECG samples used in this study.       
N: normal beat, L: left bundle branch block beat, R: right bundle 
branch block beat, A: atrial premature beat, V: premature ventricular 
contraction, P: paced beat, I: ventricular flutter wave, and E: 
ventricular escape beat. 
found in the annotation files of the records in the MIT-BIH 
database. The ICA features and the RR interval are then built 
into a feature vector and serve as inputs to the 
backpropagation neural network for classification. 
3) Backpropagation neural network classifier 
The backpropagation neural network [8] used in this study 
is a three-layer feedforward structure. In the structure, the 
first layer contains the same number of neurons as that of the 
ICA features and RR interval, the second layer have 40 
neurons, and the output layer has eight neurons, which is 
equal to the number of ECG types to be classified.  
There are three commonly used activation functions in the 
backpropagation multiplayer neural network, namely the 
logistic function, hyperbolic tangent function, and identity 
function [8].  In this study, the hyperbolic tangent functions 
are used in the first and second layers, and the identity 
function is employed in the output layer. The weight and bias 
values in the neural network are updated by Levenberg- 
Marquardt optimization method [8] with a learning rate of 0.1. 
A criterion of 0.01 in the mean-square-error is empirically 
determined to terminate the iterations in the training phase of 
the classifier. 
III. RESULT AND DISCUSSION
A total of 9800 sample segments attributing to eight ECG 
beat types was selected from the MIT-BIH arrhythmia 
database for experiments. The eight beat types employed in 
this study are normal beat (N), left bundle branch block beat  
10 20 30
85
90
95
100
(L), right bundle branch block beat (R), atrial premature beat 
(A), premature ventricular contraction (V), paced beat 
(P),ventricular flutter wave (I), and ventricular escape beat 
(E). The information about the R-peaks and RR intervals was 
given in the corresponding annotation files. 
The numbers and types of the ECG beat samples are 
summarized in Table 1, in which half of the ECG beats were 
selected for training and the other half for testing the 
classifiers.
The performances of the classification are expressed in 
terms of specificity, sensitivity, and overall accuracy. The 
specificity is defined as the fraction of correctly classified 
normal rhythms. The sensitivity of an arrhythmia is defined as 
the fraction of that specific arrhythmia correctly classified. 
The overall accuracy is the fraction of the total ECG beats 
correctly classified.
In the estimation of ICs, we sequentially calculated 100 ICs 
from the 100u200 data matrix in the training phase. The first 
35 ICs are exploited in this study. Experiments were 
developed to investigate the effects of the numbers of the ICs 
in the classification by varying the number from 5 to 35 in the 
training and testing experiments. In each experiment, the 
same procedures were repeated ten times and the results were 
averaged.
Figure 2 depicts the overall accuracy versus the number of 
ICs used in the classifier. The result shows that the highest 
accuracy of 98.37% was achieved with only 23 ICs. Further 
increase in IC number does not further raise the accuracy of 
the classifier. Rather, the accuracy moves slightly up and 
down because of the random order in acquiring the ICs. The 
specificity and sensitivities of different ECG beat types are 
summarized in Table 2 for comparison. The specificity and 
the sensitivities of all of the arrhythmias under study are high. 
The specificity is 99.65 %. Most of the specificities are over 
96 %. Even in the arrhythmia with the lowest sensitivity, an 
accuracy of 90.13 % can be achieved. The high classification 
Type MIT-BIH data file Training 
(samples/file)
Testing
(samples/file)
N 100, 101, 103, 105, 108 
112, 113, 114, 115, 117 
121, 122, 123, 202, 205 
219, 230, 234 
      100 
      100 
      100 
      100 
      100 
      100 
      100 
      100 
L 109, 111, 207, 214       100       100 
R 118, 124, 212, 231       100       100 
V 106, 119, 200, 203, 208 
213, 221, 228, 233 
116
201
210
215
      100 
      100 
        54 
        98 
        96 
        82 
      100 
      100 
        54 
        98 
        96 
        82 
A 209, 222, 232 
220
223
      100 
        47 
        35 
      100 
        47 
        35 
P 102, 104, 107, 217       100       100 
I 207       236       236 
E 207         52         52 
Total      4900     4900 
Fig. 2 Accuracy (%) versus number of ICs
Number of ICs 
A
cc
ur
ac
y 
( %
 ) 
100
95
90
85
1 2
3092
Comparison of Different Wavelet Subband Features in the 
Classification of ECG Beats Using Probabilistic Neural Network 

Ying-Hsiang Chen and Sung-Nien Yu 
yhchen@samlab.ee.ccu.edu.tw, yusn@ee.ccu.edu.tw
Department of Electrical Engineering, National Chung Cheng University, Taiwan
Abstract—In this paper, an electrocardiogram (ECG) beat
classification system based on wavelet transformation and 
probabilistic neural network (PNN) is proposed to discriminate 
six ECG beat types. The effects of two wavelet decomposition 
structures, the two-stage two-band and the two-stage full binary
decomposition structures, in the recognition of ECG beat types
are studied. The ECG beat signals are first decomposed into
components in different subbands using discrete wavelet
transformation. Three statistical features of each decomposed
subband signals as well as the AC power and instantaneous RR
interval of the original signal are exploited to characterize the
ECG signals. A PNN then follows to classify the feature vectors.
The result shows that features extracted from the decomposed
signals based on the two-stage two-band structure outperform 
the two-stage full binary structure. A promising accuracy of 
99.65%, with equally well recognition rates of over 99%
throughout all type of ECG beats, has been achieved using the
optimal feature set. Only 11 features are needed to attain this
performance. The results demonstrate the effectiveness and
efficiency of the proposed method for the computer-aided
diagnosis of heart diseases based on ECG signals. 
I. INTRODUCTION
HE recognition and classification of the
electrocardiogram (ECG) beat is an important subject for 
diagnosing different cardiac diseases. In recent years, many
algorithms have been developed for the detection and 
classification of the ECG beat [1]-[4]. Although these
methods have shown impressive results in some classification
tasks, they usually failed to demonstrate equally well
discrimination throughout all types of ECG beats. Wavelet
transformation (WT) opens another category of methods that
represent the signal in different translations and scales.
Furthermore, the discrete wavelet transformation (DWT)
decomposes a signal into signals of different coarseness.
Features extracted from the wavelet coefficients were capable 
of effectively representing the characteristics of the original
signal.
However, because a signal can be decomposed in different 
ways and the number of features grows quickly with the
number of stages, we designated to study the effects of
different subband features in the classification of ECG beats.
The objective is to find an efficient and effective combination
of subband features for ECG beat recognition. 
In this study, we consider two wavelet decomposition
structures, in which different combinations of subband
features are extracted and their effects on ECG classification 
are investigated. Besides of the features extracted from the 
decomposed signals, the instantaneous RR interval is 
considered as another feature and its effect is justified.
We use a probabilistic neural network (PNN) to test the
performance of different feature sets. The PNN classifier is a 
kind of artificial neural network (ANN) classifier, which is 
noted for its simplicity and generality. Comparing with the
most popular ANN, the multilayer perceptron (MLP), PNN 
considerably reduces the intensive computation in the MLP 
[5]. Therefore, we choose PNN as the classifier for the
comparison of different wavelet subband feature
combinations in the recognition of six ECG beat types.
II. METHOD
A. Discrete wavelet transformation (DWT)
Discrete wavelet transformation has been widely used in
signal processing tasks. The major advantage of the DWT is
that it provides great time and frequency localization.
Moreover, the multi-scale feature of the DWT allows the
decomposition of an ECG signal into different scales. Among
various wavelet bases, the Haar wavelet is the shortest and 
simplest basis that provides satisfactory localization of signal
characteristics in time domain [6]. Therefore, the Haar
wavelet was chosen as the mother wavelet in this study.
There exist several wavelet decomposition structures. The 
two most popular wavelet decomposition structures are 
illustrated in Fig. 1. The wavelet decomposition structures in
Fig. 1 show two stages of decomposition. In each stage, the 
input signal is decomposed into two subband signals, which
is called a DWT of order two. Theoretically, each 
decomposed signal is obtained by convoluting the input
signal with a specific filter and down-sampling the filtered
signal. A high-pass filter, g(n), and a low-pass filter, h(n), are 
employed in the decomposition process. These filters are 
derived from the Haar mother wavelet and can be
mathematically expressed as 
  1 1,
2 2
g n ­ ½ ® ¾
¯ ¿
,       (1)
  1 1,
2 2
h n ­ ½ ® ¾
¯ ¿
.        (2)
Apparently, these filters based on Haar wavelet are capable of
performing an orthonormal multiresolution analysis of a
signal. The symbol Ļ2 represents down-sampling the filtered
signal by two.
Fig. 1(a) is the two-stage two-band decomposition
T
Proceedings of the 28th IEEE
EMBS Annual International Conference
New York City, USA, Aug 30-Sept 3, 2006
ThC01.2
1-4244-0033-3/06/$20.00 ©2006 IEEE. 1398
in the competition layer in our experiments.
E. Experimental procedure 
The QRS complex of the ECG signal associates with the 
electrical ventricular activation of the heart and is one of the
most important ECG features. We extracted the QRS
complexes from the ECG data files for the study. Based on 
the R-peak position labeled in the annotation file provided by
the MIT/BIH database [8], 64-point QRS segments centered
at R-peaks were extracted from the record. 
After the DC value of each QRS segment was removed, the
DC-free QRS segment was decomposed with the two wavelet
decomposition structures introduced in Section II.A. For each 
decomposed signal in individual subband, the three features
described in Section II.B were calculated and normalized to
characterize the signal. 
To investigate the influence of different wavelet
decomposition structures in ECG beat classification, we 
consider different feature sets obtained in different
decomposition structures. The feature sets selected for this
study are summarized in Table 1, in which the feature sets F1
to F5 are obtained from the full binary decomposition
structure while feature sets F6 and F7 are obtained from the
two-stage two-band decomposition structure.
F1 consists of features extracted from all of the four 
subbands in the full binary decomposition structure. To 
evaluate the importance of different subband signals, we
eliminate features from one subband and formulate feature
sets F2 to F5 for different combinations of subband features.
Similarly, feature sets F6 and F7 consist of features extracted 
from the decomposed signals in the two-stage two-band
decomposition structure. The only difference between F6 and 
F7 is that the RR interval is included in F6 but not in F7.
Please note that, besides of features extracted from the 
wavelet decomposition, the variance of the original ECG beat
signal is included in F1 to F7 and the instantaneous RR 
interval is included in F1 to F6. With this arrangement, the
influence of the RR interval on ECG beat classification can be
revealed by comparing the result using F7 with that using
other feature sets.
III. RESULTS AND DISCUSSION
The MIT-BIH arrhythmia database [8] contains 48 records
from 47 subjects. To eliminate possible bias due to lacking of
sufficient pathological beats in certain records, we exclude 
the records that contain very small number of ECG beats and 
select the 23 representative ECG records for analysis and
recognition. These records include six ECG beat types which
are the normal beat (N), the left bundle branch block beat
(LBBB), the right bundle branch block beat (RBBB), the
atrial premature beat (APB), the premature ventricular
contraction(PVC), and the paced beat (PB). This process 
results in totally 23200 QRS complexes extracted from the 23 
records ready for analysis. Half of these segments are used as
the training data set, and the other half are used as the test set.
Table 1: Different feature set used to characterize QRS complexes. ıx is the 
variance of the original signal, ıR is the variance of the autocorrelation 
function, P is the power of the decomposed signal, Q is the relative 
morphological characteristic, RRI is the successive RR interval, and N is the
number of features for the corresponding feature set.
F1 F2 F3 F4 F5 F6 F7
x[n] xV 9 9 9 9 9 9 9
RV
P
L
Q
RV 9 9
P 9 9
H
Q 9 9
RV 9 9 9 9 9 9
P 9 9 9 9 9 9
LL
Q 9 9 9 9 9 9
RV 9 9 9 9 9 9
P 9 9 9 9 9 9
LH
Q 9 9 9 9 9 9
RV 9 9 9 9
P 9 9 9 9
HL
Q 9 9 9 9
RV 9 9 9 9
P 9 9 9 9
HH
Q 9 9 9 9
RRI 9 9 9 9 9 9
N 14 11 11 11 11 11 10
For the purpose of conformity, signals recorded with ML II
are exploited in the experiments.
Three statistics indices are employed to evaluate the 
performance of our proposed method, which are defined,
separately, as follows
# of correct classified normal beats
#  of total normal beats
specificity    (7) 
#  of correct classified abnormal beats
#  of total corresponding abnormal beats
sensitivity   (8) 
# of correct classified beats
#  of total beats
accuracy       (9)
The classification results, represented as specificity (sep.),
sensitivity (sen.), and overall classification accuracy (acc.),
are summarized in Table 2. The results are impressive:
wavelet subband features in both different decomposition
structures demonstrate imposing classification accuracies. 
Amongst them, F6 achieves the highest average accuracy of 
99.65% and F5 has the lowest average accuracy of 98.65%.
However, all of the feature sets under study demonstrate their
high capabilities for discriminating different ECG beat types.
Recall that F1~F5 are feature sets extracted based on the 
two-stage full binary decomposition structure. In this
category of subband feature sets, F5 shows the lowest
accuracy. Since F5 contains all the subband features except 
those extracted from the LL subband, we infer that the
1400
Abstract—In view of the parallel processing and easy 
implementation properties of CNN, we propose to use digital 
CNN as the image processor of a tactile/vision substitution 
system (TVSS). The digital CNN processor is used to execute the 
wavelet down-sampling filtering and the half-toning operations, 
aiming to extract important features from the images. A 
template combination method is used to embed the two image 
processing functions into a single CNN processor. The digital 
CNN processor is implemented on an intellectual property (IP) 
and is implemented on a XILINX VIRTEX II 2000 FPGA board. 
Experiments are designated to test the capability of the CNN 
processor in the recognition of characters and human subjects 
in different environments. The experiments demonstrates 
impressive results, which proves the proposed digital CNN 
processor a powerful component in the design of efficient 
tactile/vision substitution systems for the visually impaired 
people. 
I. INTRODUCTION
HE visually impaired people have confronted 
inconvenience in their daily lives. Thanks to the recent 
development in technologies, they now may benefit from the 
electronic mobility aids that transform visual cues into other 
sensory modalities. 
As early as 1977, Guarniero [1] proposed an electronic 
device which converted visual information to tactile 
stimulations. In 1991, Spisz and Weed designed a 
Tactile/Vision Substitution (TVS) System, which integrated a 
video camera and a real-time image processing subsystem, 
was capable of providing a 16×16 vibrator-tactile stimulator 
array as output [2]. Ram and Sharf verified and confirmed the 
effectiveness of the TVS systems, and emphasized that the 
electronic mobility aids could help the visually impaired 
people in raising their confidence and independence in 
mobility [3]. 
In this study, we propose to use Cellular Neural Network 
(CNN) to implement TVSS. CNN was first proposed in 1988 
[4][5] and has evolved to cover a wide range of applications. 
Most of these applications were in image processing [6]-[9]. 
Using CNN for image processing has advantages in hardware 
implementation and real-time processing. Several analog 
CNN chips and universal machines (UMs) based on the chips 
are now available in the market and their specifications were 
compared in [10]. However, an efficient approach to study 
CNN functions is to emulate CNN functions on digital 
CNN-UM architectures [11]-[13]. This approach utilizes 
numerical methods to solve the partial differential equations 
in CNN, such that complex dynamics of the CNN system can 
be easily implemented and functions be tested.
We propose to use CNN as the image processor for a 
tactile/vision substitution system (TVSS). In a TVSS, a series 
of images are acquired from the acquisition module. The 
acquired images must be down-sampled, features be 
enhanced, and then serve as input to a vibrator-tactile 
stimulator array. In this study, we focus on the image 
processing part of the TVSS. The two image processing 
functions are implemented on a single digital CNN processor 
with the embedding method published previously from our 
group [14]. An FPGA board is employed to demonstrate and 
verify the functions of the digital CNN processor. 
II. THE PROPOSED METHOD
The block diagram of the prospected TVSS is shown in Fig. 
1. The TVSS contains a CCD camera, a FPGA-based CNN 
processor, and a vibrator-tactile stimulator array. Since this 
study focuses on the image processing of the acquired images 
using CNN, we will briefly introduce the image acquisition 
module and describe the CNN image processing in details.
A. Image Acquisition: 
The image acquisition module includes a CCD camera and 
an image cutting circuit which limits the output image to a 
preset size for the following processing. Since the intended 
output, the vibrator-tactile stimulator array, has 32u32 small 
vibrators, we need to down-sample the acquired image into 
that size. However, our preliminary experiments showed that 
directly using 32u32 images has poor effect on the final 
results. On the contrary, the information would be better 
preserved if we acquire larger images and down-sample the 
Image Processing for a Tactile/Vision Substitution System Using 
Digital CNN 
Chien-Nan Lin, Sung-Nien Yu, and Jin-Cheng Hu 
cnlin@samlab.ee.ccu.edu.tw, yusn@ee.ccu.edu.tw, macoto_hu@baycom.com.tw
Department of Electrical Engineering, National Chung Cheng University, Taiwan 
T
Vibrator-tactile 
Stimulator Array 
Wavelet 
Filter
Feature
Extraction
CNN
Fig 1. Block diagram of the Tactile/Vision Substitution System 
(TVSS)
CCD
Proceedings of the 28th IEEE
EMBS Annual International Conference
New York City, USA, Aug 30-Sept 3, 2006
SaBP13.15
1-4244-0033-3/06/$20.00 ©2006 IEEE. 5261
L L
1 1 3 1 1
6 4 3 2 3 2 3 2 6 4
1 1 3 1 1
3 2 1 6 1 6 1 6 3 2
3 3 9 3 3W M
3 2 1 6 1 6 1 6 3 2
1 1 3 1 1
3 2 1 6 1 6 1 6 3 2
1 1 3 1 1
6 4 3 2 3 2 3 2 6 4
  ª º
« »
« » « »
« »
« » « »  
« »
« » 
« »
« »
  « »
« »¬ ¼
The CNN half-toning B, template 2 in [15] is 
. . . . .
. . . . .
. . . . .
. . . . .
. . . . .
0 0 2 0 0 7 0 1 0 0 0 7 0 0 2
0 0 7 0 3 2 0 4 6 0 3 2 0 0 7
B 0 1 0 0 4 6 0 8 1 0 4 6 0 1 0
0 7 0 3 2 0 4 6 0 3 2 0 0 7
0 0 2 0 0 7 0 1 0 0 0 7 0 0 2
ª º
« »
« »
 « »
« »
« »
« »¬ ¼
The resulting B’ templates can be calculated from Eq. (5) and 
the result is summarized as follows: 
»
»
»
»
»
»
¼
º
«
«
«
«
«
«
¬
ª
 
0.03110.0158-0.0271-0.0158-0.0311
0.0158-0.23920.42170.23920.0158-
0.0271-0.42170.56250.42170.0271-
0.0158-0.23920.42170.23920.0158-
0.03110.0158-0.0271-0.0158-0.0311
B'
5. The Emulated Digital CNN Implementation 
The analog array structure of the CNN Universal Machine 
(CNN-UM) was proposed in 1993 to implement the original 
analog CNN paradigm [16]. Later, in 1994, the digital version 
of CNN-UM was published in an attempt to provide an 
efficient emulator system for the analog CNN [11]. Several 
different hardware structures and emulation strategies have 
been proposed to improve the performances of the digital 
CNN-UM [12][13]. In this study, we intended to employ the 
distributed coefficient method [11] to implement the Digital 
CNN image processor for the TVSS. 
We used an FPGA board (VIRTEX-II 2000, XILINX) to 
implement the digital CNN image processor in the TVSS. The 
FPGA board is an embedding system which uses XILINX 
xc2v2000 chips to implement the digital circuits and use 
MicroBlazeTM as the soft processor core of the system. The 
acquired image data was first transmitted into the local 
memory on the FPGA board. These data serve as inputs to the 
digital CNN processor on the FPGA chips. The operations of 
the system and the control of data flows are managed by the 
MicroBlaze core through the OPB data bus. The digital CNN 
processor was designed into an intellectual property (IP), in a 
form that benefit from the integrality and reusability of the 
FPGA circuit. 
III. EXPERIMENT AND RESULT
Three experiments were designated to test the performance 
of the system. In the first experiments, we test an important 
application of the TVSS system: the character recognition. 
The ability to recognize characters can help the visually 
impaired people regain some of their ability to read books and 
acquire useful information, such as road signs, from the 
environment. The characters were first captured with the 
CCD camera. The images were manipulated with the digital 
CNN image processing unit, and then sent to the vibrator 
array as output. Fig. 3 shows the original images and the 
processed results of the characters. Fig. 3(a) is a Chinese 
character “Lin”, (b)-(d) are the English letters “Q”, “R’, and 
“S”, respectively. The character and letters can be easily 
recognized. The results show that the combination of wavelet 
filter and the half-toning function is proven to work quite well 
in the extraction of features for character recognition. 
The second experiment is the processing of a sequence of 
images when s subject is walking across the scene with a 
white background. The result is depicted in Fig. 4. The 
images in the upper row show the original images and that in 
the lower row are the images after CNN wavelet filtering, 
down-sampling, and half-toning. The subject can be easily 
located in the processed images, even with the very low 
resolution of 32u32. The upper part of the subjects which 
shows quite different gray-level with the background is 
obvious in the images. The lower part of the subject, which is 
similar to the background in color, also can be distinguished 
from the background, although some blurs may be seen.  
The third experiment is to test the performance of the 
system with complex background such as buildings and stairs, 
which is usually concurred in an outdoor environment. A 
subject was asked to stand on the stairs while the TVSS was 
moving slowly toward the subject in order to mimic the 
mobile experience of the TVSS users. The results are shown 
in Fig. 5. Similar to Fig. 4, images in the upper row show the 
acquired images and that in the lower row are the processed 
results. These images show an impressive result of this 
system. The subject can be easily located in the processed 
images. However, some information of the background may 
be lost, probably because of the down-sampling process and 
the limited resolution of the intended tactile vibrator array.  
Please note that the size of the binary output image is only a 
quarter of the input image. This is confined by the fact that the 
high-resolution visual information must be transformed to the 
much lower resolution of the tactile sensation. Therefore, just 
as suggested in many previous TVSS reports, an (electric) 
guide stuck is usually recommended when using the TVSS in 
the outdoor environment. However, from the impressive 
results demonstrated in our experiments, the use of CNN as 
image processor in a TVSS did prove to be a good solution of 
the high computation problem of the system. The application  
Fig. 3 The processed image of (a) Chinese character “Lin”, and English 
letters (b) “Q”, (c) “R”, and (d) “S”, respectively. 
(a) (b) (c) (f)
5263
