΋ǵύमЎᄔा 
1. ύЎᄔा 
ܭ౜ՉԾ୏ϯғౢس಍ύǴႝတຎ᝺ගٮᐒᏔ(Γ)ຎ᝺ϐૈΚаᔈбᕉნϐׯᡂǴ٬
ځૈ࿶૽ግࡕ຾ՉόӕϐπբǶЀځǴຎ᝺س಍ගٮس಍ύނҹϐՏ࿼ǵБӛϷελϐၗ
ૻǴЪёܭՉ୏ύᗉխምᛖނǶҁࣴزۯុ߻යϐࣴزǴЬाҞޑӧၮҔႝတຎ᝺מೌǴ
่ӝނҹϐຼᜐϐԔ౗ȐK-curvatureȑϷԾ࣬ᜢ߯ኧϐόᡂ܄ȐInvariant propertyȑǴࡌҥ
΋ԖਏޑΒᆢނҹϐຎ᝺ᒣ᛽س಍Ƕҁࣴز࿶җٿ໘ࢤ੝܄ᘏڗȐFeature extractionȑǴம
ϯ੝ቻॶϐόᡂ੝܄Ǵׯ๓а۳ၨᜤլܺϐނҹᡂϯᒣ᛽ୢᚒǶࣴزϣ৒Ьाӧόӕفࡋ
ȐOrientationȑǵᕭܫКٯȐScaleȑǴϷՏ౽ȐTranslationȑΠǴ௖૸Βᆢკ׎ϐόᡂ܄ǹ२
ӃǴஒΒᆢკ׎ӃբΒॶϯǴᙖҗࠠᄊᏢ(Morphology)ᘏڗނҹᜐᗺϐ০኱ॶǴӆճҔӅ
ᡂ౦ંତ(Eigenvalue of covariance matrices)ϐ౛ፕ؃ளނҹᜐࣚϐԔ౗੝ቻॶǴ೸ၸܜኬڗ
ளڰۓኧໆϐ੝ቻॶ(Re-sampling)Ǵ٠ीᆉځԾ࣬ᜢ߯ኧȐAutocorrelation coefficientȑǴ܌
ளϐԾ࣬ᜢ߯ኧӛໆᆶ኱ྗኬҁϐԾ࣬ᜢ߯ኧӛໆ຾Չ࣬՟܄ໆෳǶ 
ҁीฝࣁচΟԃයीฝύϐಃΒϷಃΟԃ೽ҽǴಃ΋ԃЬा୺ՉΒᆢނҹϐόᡂ܄ϩ
݋Ǵхࡴ:ނҹϐڗႽǵᜐᗺϐᘏڗǵӅᡂ౦ંତǵre-samplingǵϷԾ࣬ᜢόᡂ܄ϐᙯඤǴ
၀೽ϩςֹԋǴ٠а׫ዺᕇ Expert Systems and Applications୯ሞයт܌ௗڙ*ǹಃΒԃЬा
а K-curvatureࣁࣴزЬᡏǴ٠аΟᅿϩᜪᏔ଺ނҹϩᜪϐКၨǹಃΟԃ߾ჴሞࡌҥނҹᒣ
ຎس಍ǴӃа 25ҹ synthetic ނҹ଺س಍ᡍ᛾Ǵӆа 25ҹόӕϐჴሞނҹ଺س಍ෳ၂Ǵ٠
ஒᆶځдόᡂ܄ނҹᒣຎБݤ଺КၨǶҁԃࡋࣴزύаԪᜢᖄࡋϩ݋ (Grey relational 
analysis)ჹނҹ଺ϩᜪǴ຾ԶղۓځᘜឦǴ٠ᆶќΒᅿϩᜪݤനλຯᚆݤȐMinimum distance 
measureȑǵϷॹ໺ሀᆛၡݤȐBack propagation networkȑ଺КၨǶҁΟԃࣴزीฝЬाԋ݀
ςว߄ܭ୯ሞයтፕЎ (SCI)ٿጇǶ 
ᜢᗖӷǺނҹᒣ᛽, eigenvalues of covariance matrix; K-curvature, Ծ࣬ᜢ߯ኧ, ੝܄ᘏڗ, Ԫ
ᜢᖄ 
 II
 IV
coefficient, feature extraction 
 
 6
2. Literature Review 
The literature reviewed is classified into the following three sections: 
2.1 Review of Boundary Representation Using Curvature 
Various boundary descriptors, such as chain code, curvature, and Fourier Descriptor (FD), have been 
developed.  The Freeman chain code (Freeman and Davis, 1977) is easy to use and can be treated as a 
polygonal approximation of a contour, although it is less efficient and accurate.  Fourier descriptors (Bandera 
et al. 1999; Sánchez-Marín, 2000) have been successfully applied to contour enhancement and object 
inspection, providing position, scale and orientation invariant properties by normalization.  However, they 
require heavy computation when calculating the complex equations of the forward and backward 
transformations.  Curvature, defined as the change rate of the slope, has been widely employed in different 
applications such as shape representation, feature extraction, corner detection and object recognition (Han and 
Jang, 1990; Lim et al. 1995; Tsai, 1997; Byun and Nagata, 1996; Park and Han, 1998; Bandera et al., 1999; Li 
et al., 1998). 
Different numeric curvature estimation approaches have been discussed in literature.  Rosenfeld and 
Johnston (1973) initially defined curvature as a K-cosine function, where K denotes a region of support on the 
boundary.  Mokharian and Mackworth (1986), Teh and Chin (1989), and Sohn et al. (1994) expressed 
curvature with a formula involving its first- and second-order directional derivatives.  Liu and Srinath (1990) 
evaluated the curvature by convolving the edge direction function with the first derivative of a Gaussian 
function at each pixel.  Fairney et al. (1994) experimented with several different measures of digital 
curvature and found them to be unreliable in the presence of noise.  Tsai and Chen (1994) computed directly 
the curvature by measuring the first- and second-order derivatives of the continuous functions.  Tsai (1997) 
measured the curvature by using neural networks to identify the included angles at boundary points.  Later, 
Tsai et al. (1999) employed the eigenvalue of covariance matrices to measure the curvature and detect the 
sharp corners in a contour.  Arrebola et al. (1997) evaluated the curvature as the correlation factor coefficient 
of the forward and backward histograms in a K-vicinity of a given point.  Among them, the eigenvalue of 
covaraince matrices is an effective boundary representation method which provides the translation-free 
property and therefore is adotped in this project. 
 8
(2005) evaluated different Fourier methods for 2D object (shape) recognition and retrieval, in which six 
different FD’s were discussed and evaluated.  Wong et al. (2007) developed a method of object retrieval 
using support vector machines (SVM), Fourier descriptors and self-organizing maps. A list of predicted 
classes for an input shape is obtained using the SVM, ranked according to their estimated likelihood. 
2.3 Review of Autocorrelation 
Autocorrelations have been widely used as features for 1D and 2D signal classification in a range of 
applications such as character recognition, texture classification, face detection and recognition, signal 
classification and so forth (Popovici and Thiran, 2004).  Loui (1992) proposed a method based on 
mathematical morphology transformation (called MAT) of an image, which is composing of a family of 
geometrical correlation functions, for 2D object recognition. Kurtia et al. (1994) developed a two-stage 
feature extraction, higher-order local autocorrelation and multivariate analysis method, to provide effective 
features fro face recognition.  Guoudail et al. (1996) investigates the performance of the face recognition 
method based on the computation of 25 local autocorrelation coefficients.  Kreutz et al. (1996) proposed a 
framework and a complete implementation of a translation and scale-invariant image recognition system 
(linear classification) using higher-order autocorrelation features of scale space data.  Purton (1997) 
conducted experiments in word recognition based on digital autocorrelation analysis and pattern matching.  
Pham and Wagner (1998) used the autocorrelation method of autoregressive modeling as a benchmark for 
comparison with the linear prediction analysis of speech. Pashos (1998) used chromatic correlation features 
extracted from the correlation directional histograms for color texture classification. Brochard and Khoudeir 
(2003) presented a method for computing the movement parameters of textured surfaces moving in a 3D 
environment based on the face that the autocorrelation function of an image and of its affine transformed 
version.  Carkacioglu and Yarman-Vural (2003) proposed a texture descriptor, Statistical Analysis of 
Structural Information (SASI), based on statistics of clique autocorrelation coefficients that calculated over 
structuring windows, for image retrieval.  Popovici and Thiran (2004) presented an autocorrelation-based 
pattern recognition scheme that avoids the computation of autocorrelation coefficient and successfully applied 
to a large scale of patterns. 
2.4 Review of Grey Relation 
Grey system theory (GTS) was first initiated by Dr. Deng in 1982 (Deng, 1982; Deng, 1989). It is a 
 10
 
Figure 1. Relation of different sequences  
 Grey relational analysis is a tool for analyzing the relationship between one major sequence (called 
reference) and the other comparative ones in a given set. Given a reference set. Let Sr={sr1, sr2, …, srn} denote 
a collection of n (n 1) reference sequences. The element in Sr is of the form sri=(sri(1), sri(2), …., sri(p)) for a 
positive integer p.  In addition, let Sc={sc1, sc2, …, scm} be a collection of m (m 1) comparative sequences 
and each element in Sc is also of the form as sci=(sci(1), sci(2), …., sci(p)). The purpose of grey relational 
analysis is to find the most similar sequence from Sc to a specified reference sequence in Sr. Therefore, grey 
relational coefficient between the reference and all comparative sequences at the kth datum is defined as  
 
  pk
k
ksksg
ij
cjri  ..., 2, ,1         ,
)(
))(),((
max
maxmin !
"#$"
"#$"
!
%
%
    (1) 
where , |)()(|)( ksksk cjriij &!" )(maxmaxmax kijkj "!" , )(minminmin kijkj "!" , for j=1, 2, …, m, andʳ  
 is a coefficient (also called distinguish coefficient) that controls the resolution betweenʳ!max and !min. 
When all the grey relational coefficients are determined, the grey relational grade, which is the weighted 
average of grey relational coefficient g(
.
), is defined as 
]1 ,0('
         (2) (
!
#!
p
k
cjriicjri ksksgkssr
1
)](),(()([),( )
where )(ki)  is the weighting factor of the grey relational coefficient  and . 
Generally, 
))(),(( ksksg cjri 1)(
1
!(
!
p
k
i k)
)(ki)  is be chosen evenly distributed as 1/p for all k.  Accordingly, 0< <1 and 
0< <1 for any i'{1, 2, …, n} and j= 1, 2, …, m.  Four major properties of GRA, including 
Normalized, Coupled symmetric, Global property, and Approximating property, which can also be found in 
Chang and Yeh (2005) and Jiang et al. (2002). 
))(kscj),(kri(sg
), cjs( risr
 
 Figure 2. Flow of the proposed method 
 
 
 
 
 
 
 12
             
(a) Original object    (b) Dilation      (c) Subtract: B - A 
Figure 3Boundary extraction using dilation operation and image subtraction. 
 
3. Feature extraction 
The purpose of feature extraction process is to derive transition, scaling, and rotation invariant features 
based on the sequential boundary derived from the previous stage.  This study represents the boundary using 
the K-curvature to obtain the transition invariant property; the proposed re-sampling process is to obtain 
scaling invariant property; and then the transformation of autocorrelation is to ensure orientation-invariant 
property. 
3.1 Boundary representation using K-curvature 
K-curvature is a curvature-based boundary descriptor developed by Rosenfeld and Johnston (1973).  
Accordly, the K-curvature (or say K-cosine) is defined as below. 
<Definition > K-curvature  
 Given an object whose boundary is defined by S={ Pi | i=1, 2, 3, …, m}, the curvature (K-cosine) of 
each boundary point Pi is defined as 
)()(
)()(
cos)(
KbKa
KbKa
Kc
ii
ii
ii   
  
#
#
!! / ,        (5) 
As depicted in Figure 4, =)(Kai
 
P
 
i+K P
 
i, )(Kbi
 
= P
 
i K P
 
i, ! denotes the angle between )(Kai
 
 and 
)(Kbi
 
, and K is a natural number (N).  
 14
 (a) Original object     (b) K=2 
   
(c) K=11         (d) K=22 
Note: the first corner has been broken in 2 peaks (first and last) 
Figure 5  Boundary representation using different K values 
 
 3.2 Re-sampling of K-curvature 
The boundary representation derived previously is scale dependent when using a same starting-point.  A 
digital object with different scales will be converted into different numbers of K-curvature, ci(K) , by 
re-sampling.  Figure 6 shows the boundary representation of the original object in Figure 2 when the size is 
reduced to 1/4.  The total number of boundary point is reduced, and the shapes will be similar with different 
numbers of points.  The purpose of re-sampling is to acquire the same number of ci(K) for a given object 
with different scales and to derive the scale-invariant property.  This process can be achieved through simply 
sample the K-curvature proportionally to the numbers of ci(K) extracted.  For example, given a digital part of 
two different scales in Figure 7(a) and (b), the numbers of two ci(K)  sequences are 32 and 16 for example.  
In order to obtain the same number of features such as 8, the re-sampling process will sequentially sample one 
of every four features along the first sequence, and one of every two features along the second sequence.  
 16
 18
(c) Re-sampling the first and second sequence into 8 pixels 
Figure 7 The process of re-sampling 
3.3 Autocorrelation Transformation  
Autocorrelations have been widely used as features for 1D and 2D signal classification in a range of 
applications such as character recognition, texture classification, face detection and recognition, signal 
classification and so forth (Popovic portant 
information about matching pattern in tim ht, 1978).  The formula of 
K is as follow: 
i and Thiran, 2004).  Autocorrelation coefficient provides im
e series data (Makridakis and Wheelwrig
autocorrelation coefficient of time lag 
"
"
#
$
#
$
#
%
n
t
Kn
t
K
t
Ktt
r
1
1
)r(
&          (6) 
where K
$$ rr
2
)r)(r(
& denotes autocorrelation coefficient, K is the length of the time lag (K =1, 2,…, n); n is the number 
of observations; rt denotes the value of the variable at rtime t; and denotes the mean of rt. 
The advantage of using autocorrelation coefficient is its shift-invariant property which produces the 
orientation-invariant property.  After applying Equation (4), th
invariant to starting points.  Figure 8 is an illustration of boundary sequence with different starting points 
io comes invariant to 
translation, scaling, and rotation. 
e sampled boundary sequence becomes 
after applying the autocorrelation function.  After the boundary representation with the eigenvalue of 
covariance matrices, re-sampling, and autocorrelation transformat n, the feature pattern be
 
Figure 8. Boundary sequence after autocorrelation transformation. 
   
 
Figure 9. Standard patterns 
     
(a) Rotating 30°    (b) Rotating 60°    (c) Rotating 90°  (d) Rotating 150°    (f) Rotating 200°  
     
(g) Rotating 300°   (h) S1     (i) S2    (j) T1   (k) T2 
Note: S1 and S2 de e 1/4 and 1/8 reductions in size, and T T2denote two random translationsnot 1 and . 
 20
 22
Eventually, w  used Objects  2, and 22, f stance, to dem tness of the 
proposed method. Figure 11 illustrates the extracted invariant features after applying the 
proposed method. The boundary representation using the smaller eigenvalue of covariance 
matrices for Objects 1, 2, and 22, are shown in Figure 11(d), (e), and (f), which have 706, 612 
and 1191 nces were re-sampled into 
 depict the 
patterns after autocorrelation  square pattern (Object 
1) an
e 1, or in onstrate the robus
 boundary points respectively. After that, the boundary seque
300 features as shown in Figures 11(g) (h) and (i). Then, Figures 10(j) (k) and (l)
transformation with K=250. Obviously, the
d rectangle pattern (Object 2) have distinct sequences which can be easily differentiated. In 
addition, the extracted features of Object 22 have conspicuous difference to Objects 1 and 2’s. 
              
(a) Object 1          (b) Object 2    (c) Object 22 
 
    
(d) n=706, s=71    (e) n=612, s=61       (f) n=1191, s=111 
 
    
(g) Re-sampling (n=300)      (h) Re-sampling (n=300)     (i) Re-sampling (n=300) 
 
   
(j) Autocorrelation K=250   (k) Autocorrelation K=250    (l) Autocorrelation K=250 
Figure 12. Recognition using different positions, orientations, and scales 
After obtaining the invariant feature patterns, BPN and minimum Euclidean distance methods were 
implemented for classification. After an experimental design, we selected a two-layer BPN with learning 
rate=0.5, momentum=0.8, and 300-190-100 architecture based on the ability of minimizing the mean square 
error without overtraining. The experimental results, with the selected best parameter combination, are listed 
in Table 2, which shows that both s MD. 
 
      Methods 
 methods obtained high recognition rates and BPN slightly outperform
Parameters 
BPN MD 
Region of Support 20 
Re-sample 200 
Lag 100 
Recognition RateȐ%ȑ 99.5% 97.2% 
ognition results N and MD 
 
Phase III -- Invariant 2D n Using KRA and GRA
6. Methodology of Phase III 
6.1 KRA feature extractor 
The proposed KRA erive trans otation, and scaling -free features through 
the sequential boundary.  This urvature to obtain the position 
property; and then the transformation 
re orientation-invariant property. The basic operation is similar to the method 
o the details are omitted. 
6.2 Object recognition using Grey Relational Analysis 
Table 2. Rec  of BP
 Object Recognitio  
 feature extraction is to d lation, r
study represents the object profile with the K-c
invariant property; a re-sampling process is to obtain scaling invariant 
of autocorrelation is to ensu
discuss in previous phase, s
 24
"#
p
ii kgkr0 )](
1
[)(   
#k n1
al ordinal) for all the sequences. 
is gu
Step7. Sort the grey relational grades (or called gray relation
In this study, the d tin ish coefficient (  is .5 according to Jiang et al. ( determined as 0 2002).  After all, 
onal grades. 
7. Implementation 
The proposed method was implemented on a personal computer (PC) with a USB controlled X-Y Table 
is 
ned at resolution 640 × 480 (pixels) as 
(a) for verification.  For each standard pattern, 10 test patterns with various positions (T1, 
and 
the testing object is classified with the highest grey relati
 
and 2D objects were digitized through a black/white CCD connected to a frame grabber. Its configuration 
shown in Figure 13.  Fifty synthetic testing images were first scan
shown in Figure 14
T2, randomly), orientations  (3˃̓, 60̓, 90̓, 150̓, 200̓, 300̓) and scales (S1=1/4 reduction, 50% and 
S2=1/8 reduction, 25%) were created. Figure 10(b) shows ten test patterns generated using standard pattern 10 
of Figure 14(a).  Therefore, there were 500 test patterns for validation.  All standard and test patterns then 
were segmented with a pre-determined threshold and stored as binary images. For the image preprocessing 
such as color image thresholding and boundary following, the library of e-Vision image processing software 
(EasyAccess 6.0) was used.  The rest of the recognition processes were implemented in C++ language under 
Borland C++ Builder 6.0 environment.  After that, a set of 50 real parts, as shown in Figure 15, were 
acquired.  
 
 
 
 
 26
 28
            
(g) Rotating 300°  (h) S1   i) S2     (j) T1       (k) T2 
N . 
(b) Ten test patterns with various translations, rotations, and scaling. 
Figure 14. Standard part patterns and testing images 
         (    
ote: S1 and S2 denote 1/4 and 1/8 reduction in size, and T1 and T2 denote two random translations
 
Figure 15. Real parts of system validation 
A three-factor experimental design was first conducted to determine the parameters, including region of 
support (K), number of points sampled (n), and lag (L), used in the proposed method.  Since the testing 
objects were scaled into various sizes, using a fixed region of support could not properly represent the 
boundary feature.  Thus, this stu er different scales as follows.   
ber of re-sam
trial-and-error.  The time lag of autocorrelation coefficient, L, determines the number of features stored in 
database for recognition.  The larger the value the gr o
dy determines the region of support (K) und
K= (number of points on boundary) ʏs        (6) 
where s is controlled factor, which was determined as nine levels including 10, 15, 20, 25, 30, 35, 40, 45 and 
50.  For the num pling, n, this study arbitrarily selected two levels (n = 200 and n=300) after 
eater time and mem ry required.  On the other hand, 
 30
(a) n=200 
ʳ  ʳ  ʳ  ʳ  Region of support ʳ  ʳ  
Lag ( ) s s s s s s sL s=10  =15 s =20  =25  =30  =35  =40  =45  =50 
100 
150 
10.4 
11.1 
55.7 87.3  
70.2 52.6 39.9 31.1 23.4 18.6 
250 12 55 81.3 7 9 40.1 31.7 24.1 19.6 
*
83.2 
74.1 
72.9 
54 
53.2 40 31.6 24 18.3 
40.9 32.5 24.8 18.7 
56.8 
200 12.1 54.8 81.3 
0 52.
* is th h est reco ion rate 
 n=2
 4. R ition sing Minimum distance met
 seco perim ere cted to demonstrate the effect for the proposed two classifiers when 
 10 to 100 to reveal the effect of number of objects. 
Combining synthetic and real object images, had 1000 testing images for validation. The 
experimental results are presented in Table 5 and the recognition trend is shown in Figure 16.  Accordingly, 
the GRA-based m
e igh gnit
(b) 00 
Table ecogn rate u hod 
The nd ex ents w condu
the number of the testing objects increased from
the study 
ethod outperformed minimum distance method (MD), even though the MD method still 
owned 95% of recognition rate when the number of patterns reaches 100. 
    Number of Testing Images    
Classifier 10 20 30 40 50 60 70 80 90 100 
GRA 100 99.0 99.0 97.8 97.6 97.5 97.0 96.7 97.0 96.8 
MD 100 98.5 98.6 96.5 96.6 96.8 96.1 95.8 96.0 95.7 
Table 5. Recognition rates of different number of testing images 
 32
translation, rotation, and scaling-free 2D object recognition method, which adopts K-curvature boundary 
representation to derive position-invariant property, re-sampling to achieve scaling-invariant property, and 
autocorrelation transform to obtain orientation-invariant property.  In addition, the proposed method 
incorporated with Grey Relational Analysis method to recognize the 2D digital objects with a high recognition 
rate.  A set of fifty synthetic images, each of them was acquiring with ten different positions, orientations and 
scales, were used for validation, and another fifty real objects were obtained for validation.  Eventually, the 
proposed method was benchmarked with Lee’s method and experiments showed the proposed method was 
superior in recognition rate.  Experimental results also reveal that the proposed method with either GRA or 
MD methods is effective and reliable for part recognition. Conclusively, the proposed KRA feature extractor 
incorporated with GRA classifier, not only successfully obtained position, orientation, and scaling- invariant 
features, but also classified the features in an excellent performance. It is also expected that the proposed 
method may be applied to various applications such as part sorting, automated visual inspection, robot 
positioning, control and monitoring system.  In particular, this project has been published two journal papers 
in SCI international journal. 
 
ΟǵୖԵЎ᝘ 
Bruckstein, A., Shaked, D. (1997), Skew-symmetry via invariant signatures, Pattern Recognition 31 (2), 
181-192. 
Cao, W., Hao, F., Wang, S., (2004), The application of DBF neural networks for object recognition, 
Information Sciences 160, 153-160. 
Jones III, G., Bhanu, B. (2001), Recognizing articulated objects in SAR images, Pattern Recognition 34, 
469-485. 
Haralick, R.M and Shapiro, L.C. (1992), Computer and Robot Vision, Addison-Wesley, Reading, MA. 
Huang, X, Wang, B., Zhang, L. (2005), A new scheme for extraction of affine invariant descriptor and affine 
motion estimation based on independent component analysis, Pattern Recognition Letters 26, 1244-1255. 
Khalil, M.I., Bayoumi, M.M. (2002), Affine invariants for object recognition using the wavelet transform, 
Pattern Recognition Letters 23, 57-72. 
Khalil, M.I., Bayoumi, M.M. (2002), Invariant 2D object recognition using the wavelet modulus maxima, 
Pattern Recognition Letters 21, 863-872. 
Kreutz, M., Vöpel, B., Janben,(1996) Scale-invariant image recognition based on higher-order autocorrelation 
features, Pattern Recognition 29,pp.19-26. 
Kyrki, V., Kamarainen, J.-K., Kålviåofo (2004), Simple Gabor feature space for invariant object recognition, 
Pattern Recognition Letters 25, 311-318.  
Lee, Y.H., Moon, S., Lee, H. (1997), A new approach for automated parts recognition using time series 
Ѥǵीฝԋ݀Ծຑ!
ҁीฝЬाϐࣴزሦୱࣁ 2D ނҹϐᒣ᛽س಍໒วᆶᔈҔǴीฝύගٮΟӜࣴزғୖϒࣴزᐒ
཮Ǵᙖҗ 2D ނҹϐᒣ᛽ୢᚒϐ௖૸ǵࣴزБݤϐჴ፬ǴୖᆶीฝϐࣴزғёჴሞᏢಞှ،ჴ୍܄ୢ
ᚒϐБݤǴ٠ၲډ౛ፕܭჴ୍่ӝϐҞޑǹҁࣴزϐԋ݀ᙁॊӵΠǺ 
1. ჹܭᏢೌࣴزǵ୯ৎว৖ϷځдᔈҔБय़ϐଅ᝘ 
ҁࣴزჹ 3E ނҹόᡂ܄ᒣ᛽ܭ GNT!)GND ܈ spcpu*฻س಍ஒԖჴ୍܄ϐᔈҔǴܭ౛ፕᆶჴ୍ϐ่
ӝ΢ᔈԖ࣬྽ϐଅ᝘ǴЪܭᏢೌ΢ܭ୯ሞයтύว߄ΒጇϐፕЎǴ٠ୖᆶΟۛ୯ሞࣴ૸཮Ǵܭ୯
ሞ໔ว߄୯ϣϐࣴزԋ݀Ƕ!
2. ჹܭୖᆶϐπբΓ঩܌ᕇளϐ૽ግ 
ҁࣴزႣीஒԖϤӜࣴزғୖᆶࣴزǴځܭΒԃϣёႣයϐԏᛘӵΠǺ 
(1) ႝတຎ᝺س಍ϐࢎ೛ᆶਠ҅ǹ 
(2) ႝတቹႽϐೀ౛ᆶϩ݋ǹ 
(3) კ׎ϟय़ϐำԄ೛ीϷቹႽೀ౛מѯϐ૽ግǹ 
(4) όᡂ܄ᒣ᛽ϐ౛ፕǴϷ the K-curvature, re-sampling, autocorrelation coefficients฻БݤϐᔈҔǹ 
(5) Ԫᜢᖄࡋϐ౛ፕᆶჴሞᔈҔǶ 
3. ჴᡏԋ݀ 
(1) 2Dނҹϐόᡂ܄ᒣ᛽س಍ϐ᏾ᡏ೛ीӵΠკ: 
(2) Eigenvecotr of covariance matricesǵRe-samplingǵautocorrelationǵBPNǵGrey theoryǵGrey 
Relationship AnalysitǵMinimum Distatnce฻࣬ᜢמೌϐำԄว৖ 
34
 
 
 
 
 
 
 
 
       
 
 36
୯ࣽ཮ံշीฝ़ғࣴวԋ݀௢ቶၗ਑߄
ВයǺ!!!ԃ!!Д!!В
୯ࣽ཮ံշीฝ!
ीฝӜᆀǺ!
ीฝЬ࡭ΓǺ! ! ! ! ! ! ! ! !
ीฝጓဦǺ! ! ! ! ! ! ! ! ! ! ! ! ! ሦୱǺ!
ȐύЎȑ!
ࣴวԋ݀Ӝᆀ! ȐमЎȑ!
ԋ݀ᘜឦᐒᄬ! ! วܴΓ!)ബբΓ*!
!
ȐύЎȑ!
!
!
!
Ȑ311.611 ӷȑ!מೌᇥܴ!
ȐमЎȑ!
ౢ཰ձ!
!
מ 0ೌౢࠔᔈҔጄൎ!
!
מೌ౽ᙯёՉ܄ϷႣය
ਏ੻!
!
!!!!!ຏǺҁ໨ࣴวԋ݀ऩۘ҂ҙፎ஑ճǴፎϮඟ៛ёҙፎ஑ճϐЬाϣ৒Ƕ!
!
!
!
!
ᕴᡏԶقǴ೸ၸԜԛ ICAOR ཮᝼Ǵᆶ୯ϣѦᏢޣԖؼӳྎ೯ǵҬࢬǴӢԜԛୖᆶ
ϐ୯ϣᏢޣΓኧόϿǴᆶЬᒤൂՏࡌҥؼӳϐᜢ߯Ǵ٠வύΑှ྽жբ཰ࣴزᆶᆅ౛ࣽ
ᏢሦୱϐࣴزЬᚒǴుགڙ੻ؼӭǶനࡕǴନΑࣴ૸཮ᏢೌҬࢬѦǴќ΋ख़ाԏᛘࢂૈ
ᒃԾᡏ཮ډኻࢪᅽճ୯ЎϯǶ
Ԝԛࣴ૸཮࣬ᜢϐ࣬Т૶ᒵӵΠǺ
྽Вൔډ ঁΓൔ֋
!
!
!
!
!
!
!
!
էᙦᄪ!Դৣൔ֋௃׎! !!!!!!!!!!!!!!!!!!!!!! ӕ session! ᖱޣൔ֋௃׎
!!!!!!!!!!
ࢫਁബ ! Դৣൔ֋௃׎     ླྀεک! Դৣൔ֋௃׎
Οǵឫӣၗ਑ӜᆀϷϣ৒
ҁԛࣴ૸཮٠҂ගٮӀᅷǴࡺឫၗ਑ӵΠǺ
1.ࣴ૸཮ፕЎ໣΋н
2.ӭ໨ࣴ૸཮ᆶ୯ሞයт Call for Paperϐၗૻ
97年度專題研究計畫研究成果彙整表 
計畫主持人：田方治 計畫編號：97-2221-E-027-073-MY2 
計畫名稱：二維物件不變性自動辨識之研究 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 1 1 100% NSC report 兩份
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 1 1 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 1 1 100% 
人次 
 
期刊論文 2 2 100% 
本計畫預期達成
兩篇國際期刊發
表,實際已達成 
研究報告/技術報告 0 0 100%  
研討會論文 2 2 100% 
篇 
參與兩次國際研
討會 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
 
