 2
仿生物知覺系統之先進電腦感知技術與系統晶片
開發及其應用  
 
摘 要 
  複雜的生物系統具有許多迷人的特性，例如具有演化、適應性、感知乃至高階
的學習、思考與推論等能力，這是許多工程研究長期追求然一直無法企及的目標。
因此近年來仿生物研究引發工程學界的熱潮，企圖透過模仿生物體所具有的各種優
異特質，發展各種先進的感知與智慧科技。本研究計畫將以我們過去在仿生物知覺
相關技術的研究成果為基礎，建構一完整之先進電腦感知技術與系統晶片設計。我
們將運用資訊工程科技來即時實現仿生物視覺與聽覺的效果，並進一步結合人工智
慧技術使得本系統具有人性化的自我學習與建構的能力。本計劃之研究課題將致力
於電腦感知技術與系統晶片之開發。其中包含五大子題：(一) 仿生物推理機制之電
腦感知訊號處理技術開發；(二) 仿生物視覺系統之電腦視覺技術開發；(三) 仿生物
聽覺系統之電腦聽覺技術開發；(四) 仿生物知覺神經網路之系統晶片開發；(五) 仿
生物電腦感知技術於居家社區保全監控之應用。由於第三子題＂仿生物聽覺系統之
電腦聽覺技術開發＂在期中報告內已做頗為詳細的介紹，因此本文將針對另外四項
子題相關技術分別做詳細報告。 
 4
GAs represent highly effective techniques for evaluating system parameters and finding 
global solutions while optimizing the overall structure. Thus, many researchers have 
developed GAs to implement fuzzy systems and neuro-fuzzy systems in order to 
automate the determination of structures and parameters [7]-[9]. 
It has been fully demonstrated that GAs are very powerful in searching for the true 
profile. However, the search is extremely time-consuming, which is one of the basic 
disadvantages of all GAs. Although the convergence in some special cases can be 
improved by hybridizing GAs with some local search algorithms, it is achieved at the 
expense of the versatility and simplicity of the algorithm. Similar to GAs, differential 
evolution (DE) [10]-[12] also belongs to the broad class of evolutionary algorithms, but 
DE has many advantages such as the strong search ability and the fast convergence 
ability over GAs or any other traditional optimization approach, especially for real valued 
problems [12]. In addition, the DE algorithm has gradually become more popular and has 
been used in many practical areas, mainly many researches [12] demonstrated that DE is 
robust, simple in implementation and use, easy to understand, and requires only a few 
control parameters. 
This study proposes a rule-based symbiotic modified differential evolution (RSMODE) 
for a functional-link-based neuro-fuzzy network (FLNFN). The neuro-fuzzy system is 
based on our previous research [13], and combines a fuzzy system with a functional link 
neural network (FLNN) [14]. The consequent part of the fuzzy rules that corresponds to 
an FLNN comprises the functional expansion of input variables. 
The proposed RSMODE learning algorithm consists of structure learning to generate 
initial rule-based subpopulation, and parameter learning to adjust the FLNFN parameters. 
The structure learning can determine whether or not to generate a new rule-based 
subpopulation which satisfies the fuzzy partition of input variables. Initially, there is not 
any subpopulation. The rule-based subpopulation is automatically generated from 
training data by entropy measure. The parameter learning combines two strategies 
including a subpopulation symbiotic evolution (SSE) and a modified differential 
evolution (MODE). The SSE in which each individual represents a single fuzzy rule 
differs from original symbiotic evolution [15]. Each subpopulation allows the rule itself 
to evolve. The MODE adopts a method to effectively search between the best individual 
and randomly chosen individuals. 
II. STRUCTURE OF FUNCTIONAL-LINK-BASED NEURO-FUZZY NETWORKS 
This subsection describes the FLNFN model [13], which uses a nonlinear combination 
of input variables (FLNN) [14]. Each fuzzy rule corresponds to a sub-FLNN, comprising 
a functional link. Figure 1 presents the structure of the proposed FLNFN model. The 
FLNFN model realizes a fuzzy if-then rule in the following form. 
Rulej: NjNijijj AxAxAxAx  is  and ...  is  and ...  is  and  is  IF 2211  
MMjjj
M
k
kkjj
www
wy
φφφ
φ
+++=
= ∑
=
...
ˆ THEN
2211
1
                    (1) 
where xi and jyˆ  are the input and local output variables, respectively; Aij is the linguistic 
 6
∑
=
⋅=
M
k
kkjjj wuu
1
)3()4( φ                             (5) 
where wkj is the corresponding link weight of a functional link neural network and kφ  is 
the functional expansion of input variables. The functional expansion uses a 
trigonometric polynomial basis function, given by 
[ ]) (cos ) (sin  ) (cos  ) (sin 222111 xxxxxx ππππ  for two-dimensional input variables. Therefore, 
M is the number of basis functions, NM ×= 3 , where N is the number of input variables. 
Moreover, the output nodes of a functional link neural network depend on the number of 
fuzzy rules of the FLNFN model. 
The output node in layer 5 integrates all of the actions recommended by layers 3 and 4 
and acts as a defuzzifier with, 
∑
∑
∑
∑ ∑
∑
∑
=
=
=
= =
=
= =
⎟⎠
⎞⎜⎝
⎛
=== R
j
j
R
j
jj
R
j
j
R
j
M
k
kkjj
R
j
j
R
j
j
u
yu
u
wu
u
u
uy
1
)3(
1
)3(
1
)3(
1 1
)3(
1
)3(
1
)4(
)5(
ˆφ
  (6) 
where R is the number of fuzzy rules, and y is the output of the FLNFN model. 
III. A RULE-BASED SYMBIOTIC MODIFIED DIFFERENTIAL EVOLUTION FOR THE FLNFN 
MODEL 
This section represents the proposed rule-based symbiotic modified differential 
evolution (RSMODE) for the functional-link-based neuro-fuzzy network (FLNFN). The 
RSMODE comprises structure learning and parameter learning. The structure learning 
uses the entropy measure that determines proper input space partitioning and finds the 
mean and variance of the Gaussian membership function and the number of rules. Next, 
the initial rule-based subpopulation is created according to a range of the mean and 
variance of the membership function. The parameter learning consists of a subpopulation 
symbiotic evolution (SSE) and a modified differential evolution (MODE). Each 
individual in each subpopulation evolves separately using a modified differential 
evolution. But in order to evaluate each individual, the individual is composed a fuzzy 
system using other individuals (rules) in other subpopulations. The detailed flowchart of 
the proposed RSMODE learning algorithm is presented in Fig. 2. 
 8
(1), where ijm  and ijσ  are the mean and variance of a Gaussian membership function, 
respectively, and kjw  represents the corresponding link weight of the consequent part 
that is connected to the jth rule node. In this study, a real number represents the position 
of each individual. 
j1σ j2σ ijσ  
Fig. 3. Coding a fuzzy rule into an individual in the proposed RSMODE method. 
 
2) Initialization Step 
For training data, finding the optimal solution is difficult because the range of training 
data is wide. Therefore, the data must be normalized. Let training data be transformed to 
the interval of [0, 1]: 
'
min_
'
max_
'
min_
'
ˆˆ
ˆˆ
ˆ
ii
ii
i xx
xx
x −
−=                            (7) 
where ixˆ  is the value after normalization; 'ˆ ix  is the vector of the ith dimension to be 
normalized; ' min_ˆix  is the minimum value of vector 'ˆ ix ; ' max_ˆix  is the maximum value of 
vector 'ˆ ix . 
Before the RSMODE method is designed, the individuals that will constitute R initial 
subpopulation must be created. The first step in structure learning is to create the initial 
first individual in each subpopulation to satisfy the fuzzy rule partition of input variables. 
The fuzzy rule partition strategy can determine whether a new rule should be extracted 
from the training data and determine the number of fuzzy rules in the universal of 
discourse of each input variable, since one cluster in the input space corresponds to one 
potential fuzzy logic rule. For each incoming data ixˆ , the rule firing strength can be 
regarded as the degree to which the incoming data belongs to the corresponding cluster. 
Entropy measure between each data point and each membership function is calculated 
based on a similarity measure. A data point of closed mean will has lower entropy. 
Therefore, the entropy values between data points and current membership functions are 
calculated to determine whether or not to add a new rule into the initial first individual 
and create a new rule-based subpopulation space. For computational efficiency, the 
entropy measure can be calculated using the firing strength from )ˆ( iA xijμ  as follow;  
∑
=
−=
N
i
ijijj DDEM
1
2log                        (8) 
where ( )1)ˆ(exp −= iAij xuD ij  and ]1,0[∈jEM . According to Eq. (8), the measure is used to 
generate a new fuzzy rule and new functional link bases for new incoming data is 
described as follows. The maximum entropy measure 
jRj
EMEM
≤≤
=
1max
max                             (9) 
is determined, where R is the number of existing rules. If EMEM ≤max , then a new rule 
and a new rule-based subpopulation space are generated, where ]1,0[∈EM  is a 
 10
j2σj1σ ijσ
 
Fig. 4. Structure of the individual in the rule-based symbiotic modified differential 
evolution. 
 
Step 2.1. Parent Choice Phase 
Each individual in the current generation is allowed to breed through mating with 
other randomly selected individuals from the subpopulation. Specifically, for each 
current individual gkx , , k=1, 2, …, PS, where g denotes the current generation and PS 
denotes the population size, three other random individuals grx ,1 , grx ,2  and grx ,3  are 
selected from the subpopulation such that r1, r2, and r3 { }PS,...2,1∈  and 321 rrrk ≠≠≠ . 
This way, a parent pool of four individuals is formed to breed an offspring. 
Step 2.2. Offspring Generation Phase 
After choosing the parents, MODE applies a differential operation to generate a 
mutated individual 1, +gkv , according to the following equation: 
)()()1( ,,,,1, 1321 grbestgrgrgrgk xxFxxFxv −⋅+−⋅−+=+  (16) 
where F, commonly known as scaling factor, is defined as G
g  to control the rate at 
which the subpopulation evolves, g denotes the current generation, G is the maximum 
number of generations, and bestx  is the corresponding parameter of the current best 
fuzzy system. To complement the differential operation search strategy, then uses a 
crossover operation, often referred to as discrete recombination, in which the mutated 
individual 1, +gkv  is mated with gkx ,  and generates the offspring 1, +gku . The element of 
trial individual 1, +gku  are inherited from gkx ,  and 1, +gkv , determined by a parameter 
called crossover probability ( ]1 ,0[∈CR ), as follows: 
 12
After the above process yielded offspring, no new information is introduced to the 
each subpopulation at the site of an individual. As a source of new sites, mutation 
should be used sparingly because it is a random search operator. In the following 
simulations, a mutation rate was set to 1/(2*N+M), meaning that, on average, only one 
trial parameter is mutated, where N is the number of input variables, M is the number 
of basis function of SOFNS, and 2*N+M is the length of each individual. Mutation is 
an operator that randomly alters the allele of a element. The mutation adopted in 
MODE to yield diversity. The individual suffers from a mutation to avoid falling in a 
local optimal solution and to ensure the searching capacity of approximate global 
optimal solution. Figure 6 shows the mutation of an individual. The mutation value is 
generated according to Eqs. (13)-(15), where mij and σij are the corresponding mean and 
variance, respectively, of the current individual. Following the mutation step, a new 
individual can be introduced into the each subpopulation. 
j2σj1σ ijσ
j2σj1σ ijσ  
Fig. 6. A mutation operation in the rule-based symbiotic modified differential evolution. 
 
Table 1: Parameter settings before 
learning. 
Parameter Value 
Population Size 50 
Maximum Number of 
Generation 2000 
Crossover Rate 0.9 
Mutation Rate 1/(2*N+M)
Coding Type Real Number 
IV. SIMULATION RESULTS 
This study evaluated the performance of the proposed rule-based symbiotic modified 
differential evolution (RSMODE) for a functional-link-based neuro-fuzzy network 
(FLNFN) to control nonlinear systems. This section presents several examples and 
compares the performance with that of other mehtods. In the nonlinear system control 
problems, FLNFN-RSMODE is adopted to design controllers in twp simulations - control 
of water bath temperature system [16], and control of the ball and beam system [17]. 
Table 1 presents the parameter settings before learning used in the three computer 
simulations. 
Example 1: Control of Water Bath Temperature System 
The goal of this section is to elucidate the control of the temperature of a water bath 
 14
yp(k+1)
yref(k+1)
yp(k+1)
1
3
S1
Z-1
2
4
S2
)(ˆ ku
)(ku
+
Plant
Z-1
–
FLNFN
Controller
 
Fig. 7. Conventional online training scheme. 
 
Fig. 8. Learning curves of best performance of the FLNFN-REMODE, FLNFN-RSDE, 
FLNFN-DE and FLNFN-GA in Example 1. 
 
The first task is to control the simulated system to follow three set-points. 
   
⎪⎩
⎪⎨
⎧
≤<
≤<
≤
°
°
°
=
.12080
8040
40
,75
,55
,35
)(
k
k
k
for
for
for
c
c
c
kyref .              (21) 
Figure 9(a) presents the regulation performance of the FLNFN-RSMODE controller. The 
regulation performance was also tested using the FLNFN-RSDE controller, the 
FLNFN-DE controller and the FLNFN-GA controller. Figure 9(b) plots the error curves 
of the FLNFN-RSMODE controller, the FLNFN-RSDE controller, the FLNFN-DE 
controller, and the FLNFN-GA controller. In this figure, the FLNFN-RSMODE controller 
obtains smaller errors than the other three controllers. To test their regulation 
performance, a performance index, the sum of absolute error (SAE), is defined by 
∑ −=
k
ref kykySAE )()(                       (22) 
where )(kyref  and )(ky  are the reference output and the actual output of the simulated 
system, respectively. The SAE values of the FLNFN-RSMODE controller, the 
FLNFN-RSDE controller, the FLNFN-DE controller, and the FLNFN-GA controller are 
352.66, 352.81, 352.91, and 372.85, which values are given in the second row of Table 2. 
The proposed FLNFN-RSMODE controller has a much better SAE value of regulation 
performance than the other controllers. 
 16
 
Fig. 13. Ball and beam system. 
 
Ball and beam system can be written in state space form as  
1
4
3
2
41
2
4
3
2
1
,
1
0
0
0
0
)sin(
xy
u
x
xGxxB
x
x
x
x
x
=
⎥⎥
⎥⎥
⎦
⎤
⎢⎢
⎢⎢
⎣
⎡
+
⎥⎥
⎥⎥
⎦
⎤
⎢⎢
⎢⎢
⎣
⎡
−=
⎥⎥
⎥⎥
⎦
⎤
⎢⎢
⎢⎢
⎣
⎡
&
&
&
&
                 (23) 
where TT rrxxxxx ),,,(),,,( 4321 θθ &&≡=  is the state of the system and rxy ≡= 1  is the output 
of the system. The control u is the angular acceleration (θ&& ) and the parameters B = 
0.7143 and G = 9.81 are set in this system. The purpose of control is to determine u(x) 
such that the closed-loop system output y will converge to zero from different initial 
conditions. 
According to the input/output-linearization algorithm [17], the control law u(x) is 
determined as follows: for state x, compute )()()()()( 10213243 xxxxxv φαφαφαφα −−−−= , 
where 11 )( xx =φ , 22 )( xx =φ , 33 sin)( xBGx −=φ , 344 cos)( xBGxx −=φ , and αi are chosen so 
that 0122334 αααα ++++ ssss  is a Hurwitz polynomial. Compute 3cos)( xBGxa −=  and 
3
2
4 sin)( xBGxxb = ; then )(/)]()([)( xaxbxvxu −= . 
In the simulation herein, the differential equations are solved using the 
second/third-order Runge-Kutta method. The FLNFN is trained to approximate the 
aforementioned conventional controller of a ball and beam system. )(/)]()([)( xaxbxvxu −=  
is used to generate the input/output train pair with x obtained by randomly sampling 200 
points in the region U=[-5,5]×[-3,3]×[-1,1]×[-2,2]. In initialization phase, 14 
subpopulations are generated. This example was simulated 30 times. Figure 14 plots the 
learning curves of the best performance of the FLNFN-RSMODE controller for the 
fitness value, the FLNFN-RSDE controller, the FLNFN-DE controller and the 
FLNFN-GA controller, after the learning process of 2000 generations. The 
FLNFN-RSMODE controller after learning was tested under the following four initial 
conditions; x(0) = [2.4, -0.1, 0.6, 0.1]T, [1.6, 0.05, -0.5, -0.05]T, [-1.6, -0.05, 0.5, 0.05]T 
and [-2.4, 0.1, -0.6, -0.1]T. Figure 15 plots the output responses of the closed-loop ball 
and beam system controlled by the FLNFN-RSMODE controller and the FLNFN-RSDE 
controller. These responses approximate those of the controller under the four initial 
conditions. In this figure, the curves of the FLNFN-RSMODE controller tend quickly to 
stabilize. Figure 16 also shows the behavior of the four states of the ball and beam system, 
starting for the initial condition [-2.4, 0.1, -0.6, -0.1]T. In this figure, the four states of the 
system decay gradually to zero. The results show the perfect control capability of the 
trained FLNFN-RSMODE controller. The performance of the FLNFN-RSMODE 
controller is compared with that of the FLNFN-RSDE controller, the FLNFN-DE 
 18
Fitness Value 
(Best) 0.9653 0.9447 0.9441 0.9131 
V. CONCLUSION 
This study proposes a rule-based symbiotic modified differential evolution (RSMODE) 
for a functional-link-based neuro-fuzzy network (FLNFN). The proposed RSMODE 
learning algorithm consists of structure learning to generate initial rule-based 
subpopulation, and parameter learning to adjust the FLNFN parameters. The proposed 
RSMODE learning algorithm allows that each individual in each subpopulation evolves 
separately using a modified differential evolution. The experimental results demonstrate 
that the proposed RSMODE can obtain a better performance than other existing methods 
under some circumstances. 
REFERENCES 
[1] C. T. Lin and C. S. G. Lee, Neural Fuzzy Systems: A Neuro-Fuzzy Synergism to 
Intelligent System, NJ: Prentice-Hall, 1996. 
[2] D. Nauck, F. Klawoon, R. Kruse, Foundations of Neuro-Fuzzy Systems, New York: 
John Wiley, 1997. 
[3] R. Fuller, Introduction to Neuro-Fuzzy Systems, New York: Physica-Verlag, 1999. 
[4] E. Sanchez, T. Shibata, L. A. Zadeh, Genetic Algorithms and Fuzzy Logic Systems: 
Soft Computing Perspectives, Singapore: World Scientific, 1997. 
[5] O. Cordon, F. Herrera, F. Hoffmann, L. Magdalena, Genetic Fuzzy 
Systems-Evolutionary Tuning and Learning of Fuzzy Knowledge Bases, Singapore: 
World Scientific, 2001. 
[6] P. P. Angelov, Evolving Rule-Based Models: A Tool for Design of Flexible Adaptive 
Systems, Physica-Verlag, Heidelberg, 2002. 
[7] M. Russo, “FuGeNeSys: a fuzzy genetic neural system for fuzzy modeling,” IEEE 
Trans. Fuzzy Systems, vol. 6, pp. 373-388, 1998. 
[8] I. F. Chung, C. J. Lin, and C. T. Lin, “A GA-based fuzzy adaptive learning control 
network,” Fuzzy Sets and Systems, vol. 112, no. 1, pp. 65-84, 2000. 
[9] G. Alpaydin, G. Dandar, and S. Balkir, “Evolution-based design of neural fuzzy 
networks using self-adapting genetic parameters,” IEEE Trans. Fuzzy Systems, vol. 10, 
no. 2, pp. 211-221, 2002. 
[10] R. Storn and K. V. Price, “Differential evolution-A simple and efficient heuristic for 
global optimization over continuous spaces,” J. Global Opt., vol. 11, no. 4, pp. 
341-359, Dec. 1997. 
[11] R. Storn, “System design by constraint adaptation and differential evolution,” IEEE 
Trans. Evolutionary Computation, vol. 3, no. 1, pp. 22-34, Apr. 1999. 
[12] K. V. Price, R. M. Storn, and J. A. Lampinen, Differential Evolution: A Practical 
Approach to Global Optimization, Germany: Springer-Verlag, 2005. 
[13] C. H. Chen, C. T. Lin, and C. J. Lin, “A functional-link-based fuzzy neural network 
for temperature control,” 2007 IEEE Symposium on Foundations of Computational 
Intelligence, Honolulu, Hawaii, USA, pp. 53-58, April 1-5, 2007. 
 20
(二) 仿生物視覺系統之電腦視覺技術開發 
  Biologically-Inspired Model for Hybrid-Order 
Chromatic Texture Boundary Detection 
 
Abstract: A hybrid-order texture boundary detection technique inspired from 
human visual system (HVS) was presented. The proposed algorithm integrates three 
important visual primitives: luminance, texture, and color into a functional system. 
At present, the related works were developed for specific applications such that an 
overall investigation of the texture segregation process would be inaccessible. 
Therefore, the thesis focuses on relevant fundamental researches on HVS and 
systematic integration to investigate the task of texture boundary detection 
thoroughly. Moreover, some critical but ignored issues from the procedure of 
hybrid-order feature extraction, such as false response, weights selection, etc., were 
also discussed and solved in this thesis. In addition to satisfying testing results, 
processing employed in this algorithm is very simple and intuitive with only few 
assumptions and no training procedure involved. Compared with the present 
researches, the proposed algorithm has a good application potential.  
 
Keywords and Phrases: hybrid-order; human visual system; texture; color; Gabor  
1. INTRODUCTION 
Both biological and computational evidences have suggested that some kinds of feature 
extraction and data compression occur at very early stages in visual processing and 
human visual system is capable of integrating basic primitives to form our rich sensation 
and perception. Some researchers approached related visual tasks by attempting to 
replicate human behavior. The integration of these primitives to describe visual behavior 
well is, however, still a difficult problem. In this thesis, we will propose a novel approach 
integrating hybrid-order features for the texture segregation task.  
At present, the relevant works for texture segregation were usually developed for 
specific applications such that an overall investigation of the process would be 
inaccessible. The process of texture feature extraction can be divided into three stages: 
Gabor filtering, rectification, and Gaussian smoothing. Among them, Gabor filtering is 
the critical part. After Daugman firstly present a framework composed of multiple Gabor 
filters narrowly tuned to specific orientations and spatial frequencies [1], similar 
approaches were proposed by many researchers, e.g., filter-design approaches, where the 
Gabor filters are designed for specific tasks; and filter-bank approaches, where the Gabor 
filters are selected from predominated partitions in the frequency domain.  Good 
segregation/segmentation results have been demonstrated in these approaches. However, 
for more general cases, the incompleteness of these approaches would appear since they 
were developed for “pure texture” cases.  
In practice, a static binocular image usually has three important visual primitive: 
luminance, texture, and color. It is obvious that a complete description of the image 
 22
further processes. Roughly speaking, the visual pathway from retina to V1 is usually 
called the early vision level where large amounts of previous analyses and investigations 
focus on. Most of our computational model was developed based on biological evidences 
at this level.  
2.2. Color Vision and the Opponent Theory 
Color is not a physical quantity but perception. There are two kinds of receptors on 
retina, known as rods and cones. The rods are the only functioning receptors at very low 
light levels. Cones, on the other hand, do not respond to dim light but be responsible for 
our ability to see fine details and for our color perception. There are three types of cones 
and each of them is categorized by the wavelength sensitivity. We usually call the three 
cones as L-cone, M-cone, and S-cone (long, median, and short wavelength sensitive). It is 
well believed that color perception is originated from the differences in wavelength 
selectivity of the three types of cones. The responses of the three cones are summed 
within a region and delivered to the brain which roughly analyzes the content of 
perceived spectrum and gives us the perception of color. Hering proposed the opponent 
theory considering the antagonism between colors occurred in the retina [7]. As shown in 
Fig. 2, after the layer of receptors, color information is delivered in three opponent 
channels including red-to-green channel, blue-to-yellow channel (two chromatic 
 
Figure 1: Model of the human visual system 
 
Figure 2: Schematic diagram of the opponent theory 
 24
3.2. False Responses to Non-Textured Regions 
For a pure texture segregation/segmentation task, there is no difference of average 
luminance between regions. The Gabor-Rectification-Gaussian process is a standard and 
acknowledged procedure. However, if there are luminance differences between regions, 
the procedure will induce some false response. Usually, the false response occurs near the 
boundary. Fig. 4 is a schematic diagram demonstrating an extreme case. If only the 1st- 
order feature exists, after applying a Gabor filter with the same orientation to the 
boundary, there will be a peak-valley pair apart from the width of Gabor filter’s mainlobe. 
Along the procedure of texture feature extraction: rectification and Gaussian smoothing, 
the 2nd- order feature will appear a significant peak on the boundary. Applying local 
variance calculation to find the boundary, we will detect the boundaries which are located 
at two sides of real boundary (as the dotted lines in Fig. 4). At present, the most 
successful approach considering the issue is the grating cell operator, which is inspired 
 
Figure 3: Flow chart of the proposed framework 
 
Figure 4: Schematic diagram demonstrating the false responses to non-textured regions. 
 26
 
3.3. Hybrid-Order Boundary Detection 
Our procedure to find the boundary is based on the concept that the locations where 
features change obviously would be more likely the boundaries. The extracted features 
can be described in a vector and the degree of how much the vector changes can be 
considered as an indicator of boundary. In our approach, all features from three channels 
are combined into two feature spaces as the 1st- order feature space and the 2nd- order 
feature space. By applying local variance criterion, we can localize two kinds of 
boundaries individually by both feature spaces. After all the features are arranged well, 
local variances within 55×  mask are calculated in both feature spaces. The two 
boundaries carry individual information of their own such that the combination can be 
implemented properly based on a criterion considering the reliability and compactness of 
boundary defined by each feature space.  
For segregation task, previous researches revealed that there should be a common site 
integrating boundaries defined by different attributes. Also, it was verified that 
combining multiple attributes posterior to a decision of localizations is advantageous to 
get more precise boundaries. If there are conflictions between boundaries defined by 
different features, the weights of all features are mediated by the measurement of 
reliabilities. A larger weight would be assigned to a boundary which is more reliable and 
linear summation for combining multiple features was suggested. After applying a 
threshold to the raw data of boundary, we will get a compact and continuous black-white 
boundary if the feature space is reliable. Oppositely, for a feature space which does not 
provide sufficient discriminable information, we will get only some noise-like fractals. 
Opening operation is one kind of morphological process that it can be used as a 
geometrical selection. By applying opening operation to the binary boundary image, for 
more compact and reliable boundary, more region areas will be reserved after opening 
operation. Thus the weights for combination can be selected from the region area ratio 
after and before opening operator. The whole procedure for boundary combination could 
be given as follows:  
(i) Normalize the 1st- and 2nd- order boundaries to values of 0-1.  
 
   
 
 
(a)        (b)  
 
      
(c)         (d)  
Figure 6: An example demonstrating the essentiality of color information: (a) input image; (b) luminance L* component; (c) 
chromatic a* component; (d) chromatic b* component.  
 
 28
with considering color information.  
The second case shown in Fig. 9 straightly demonstrates the effects of hybrid-order 
features. Fig. 9 (b) and Fig. 9 (c) are the raw data of detected boundaries by the 1st- and 
2nd- order features respectively. It is obvious that it is insufficient to detect all boundaries 
by a single order feature. Only considering hybrid-order features simultaneously can 
detect all the boundaries successfully.  
4.2. Representative Results by the Proposed Model  
The proposed algorithm was widely tested by a large amount of textures randomly 
chosen from “Outex database.” We synthesized five textures in each image, which results 
in eight boundaries. Here we will show some representative results.  
Fig. 10 and Fig. 11 demonstrate some results where all the boundaries between 
different textures are detected and weak edges within single texture are also detected. 
These results are consistent to our visual perception. The testing images demonstrated 
contain discriminable 1st- and/or 2nd- order features, and thus all boundaries are 
successfully detected with considering hybrid-order features simultaneously. And, of 
course, a region with more regular texture and/or more uniform luminance or color can 
provide better discriminability than others, and boundaries surrounding it will be much 
more obvious and compact than others.  
In Fig. 12 and Fig. 13, we demonstrate results where some boundaries are not correctly 
TABLE I: PARAMETERS OF EXPERIMENTS 
Parameters Values 
Pattern Size 746 x 746 pixels 
Number of Orientations 6 (0∘, 30∘, 60∘, 90∘, 120∘, 150∘) 
Number of Frequencies 3 
Lowest Frequency Ul 0.06 cycles/pixel 
Highest Frequency Uh 0.24 cycles/pixel 
STD of Gaussian Filter 25 pixels 
          
 (a)                     (b) 
          
(c)                  (d) 
Figure 9: An example demonstrating the effects of hybrid-order features: (a) input image; (b) 1st- order boundary; (c) 2nd- order 
boundary; (d) combined boundary.  
 30
2) Another issue to be improved is about the adaptive weights selecting mechanism. In 
Section 4.2, we discussed some cases where some boundaries were not detected. The 
main reason is that the present approach mimics one sight of vision system and 
extracts most significant parts in one view. To deal with more complex cases, a 
mechanism capable of multiple focuses is undoubtedly required, such that weights of 
the 1st- and 2nd- order boundaries can be determined rather locally than globally. By 
someway analyzing local information, it is believed that weights can be assigned 
more properly to different parts of an image.  
REFERENCES 
[19] J. D. Daugman, “Two dimensional spectral analysis of cortical receptive field 
profiles,” Vision Research, vol. 20, pp. 847-856, 1980.  
[20] T. V. Papathomas, R. S. Kashi, and A. Gorea, “A human vision based computational 
model for chromatic texture segregation,” IEEE Transactions on System, Man, and 
Cybernetics-Part B: Cybernetics, vol. 27, pp. 428-440, 1997.  
[21] D. Marr, Vision. San Francisco, CA: W. H. Freeman, 1982.  
[22] S. A. Chen, “CNN-based texture boundary detection technique and its analog circuit 
implementation,” Master Thesis, National Chiao-Tung University, 2004.  
[23] S. W. Kuffler, “Discharge patterns and functional organization of mammalian 
retina,” Journal of Neurophysiology, vol. 16, pp. 37-68, 1953.  
   
(a)    (b)     (c) 
Figure 11: Fully boundary detection: (a) raw data of boundaries; (b) boundaries after peak detection; (c) superposition of boundaries 
and image.  
   
(a)      (b)     (c) 
Figure 12: Partially boundary detection: (a) raw data of boundaries; (b) boundaries after peak detection; (c) superposition of 
boundaries and image.  
   
(a)        (b)     (c) 
Figure 13: Partially boundary detection: (a) raw data of boundaries; (b) boundaries after peak detection; (c) superposition of 
boundaries and image.  
 32
(三) 仿生物知覺神經網路之系統晶片開發 
Chip Design of CNN-Based Local Motion Estimation for Image 
Stabilization Processing  
 
Abstract   
The objective of this paper is to investigate the hardware design in image 
stabilization (IS) technique for local motion vectors (LMVs) in the image sequences. 
The IS technique is used to remove unwanted shaking phenomena in the image 
sequences captured by hand-held camcorders without affecting moving objects in 
image sequences and the intentional motion of panning condition, etc. It consists of 
motion estimation and motion compensation. Most of the complex and time 
consuming computations occur in motion estimation, an application-specific IC is 
designed to solve this problem. Cellular Neural Network (CNN) technology is used 
to implement the local motion estimation chip. CNN adaptive threshold template is 
proposed to extract reliable motion vectors from a given region. The design of global 
output connected chains can easily decode the LMV address. The local analog 
memory (LAM) is designed to store image difference information. The size of CNN 
array is 19×25 pixels. The chip has integrated in the total area of 8.1mm2 by using 
TSMC 0.35um mixed-signal process. Results with HSPICE simulation and CNNUM 
analysis prove that the performance of the proposed CNN-based local motion 
estimation is better than that of a digital signal processor. So that the IS system has 
the capability of real-time operations.  
 
Index Terms— image stabilizer (IS), motion vector, local motion vector 
(LMV), Local Analog Memory (LAM), Cellular Neural Network (CNN). 
 
III. INTRODUCTION 
Image stabilization (IS), also known as vibration reduction, which is a digital 
camcorder technology that helps preventing images from blurring. It reduces vibration 
caused by camcorder shake, slow shutter speed or when using a long telephoto lens 
without a tripod. For developed video camcorders, image stabilization is finding a way 
into more consumer and professional digital camcorders. Various image-stabilizing 
                                                 
 
 34
 
Fig 2. The block diagram of LMVs and IMV estimation. 
IV. DIGITAL IMAGE STABILIZATION 
The architecture of the proposed image stabilizer technique shown in Fig. 1 is divided 
into two processing blocks as motion estimation and motion compensation. The motion 
estimation block consists of three estimators: the local motion vectors (LMVs), the 
ill-conditioned motion vector (IMV), and the global motion vector (GMV) estimators. 
The motion compensation unit consists of the compensating motion vector (CMV) 
estimation and image compensation. The two incoming consecutive images (at time (t-1) 
and time (t)) will be firstly divided into four regions. A LMV will be derived in each 
region by the representative point matching (RPM) algorithm [1], [3]. The motion 
estimation block also contains a reliability detection function that will generate an 
ill-conditioned motion vector for the irregular image conditions such as the lack of 
features or containing large low-contrast area, etc. The GMV estimation determines a 
global motion vector among LMVs, the IMV, and other pre-selected motion vectors 
through background-based evaluation function. Finally, the compensating CMV is 
generated according to the resultant GMV and the image sequences will be compensated 
based on the CMV in the motion compensation unit.  
2.1 Motion Estimation  
The motion estimation unit shown in Fig. 1 contains the LMVs, IMV, and GMV 
estimators. As shown in Fig. 2, the LMVs and IMV estimation is to generate the LMVs 
and IMV for global motion vector estimation. The LMVs can be obtained from the 
correlation between two consecutive images by the representative point matching (RPM) 
algorithm . The IMV can be obtained from LMVs by evaluating the corresponding 
confidence indices through the irregular condition detection and the proposed IMV 
generation algorithm. A background-based evaluation function is proposed to generate 
GMV by using  LAMs, IMV, zero motion vector (ZMV), and the past GMV. The motion 
estimation unit in Image Stabilizer Algorithm treats the image as 19 times 25 pixels’ 
macro-blocks, and computes the motion vectors and errors separately between them. The 
better the motion estimation is, the better the image compensation is. 
2.2 Motion  Compensation  
It is necessary to generate the compensating motion vectors (CMVs) for removing the 
undesired shaking motion while keeping the steady motion of the image sequence. The 
conventional compensating motion vector estimation was given by   
( ) ( ( 1)) ( ( ) (1 ) ( 1))CMV t k CMV t GMV t GMV tα α= − + + − −              (1) 
where t represents the frame number, 0 1k< <  and 0 1α≤ ≤ . In the case, there is the 
tremendous lag condition due to the steady panning effect. It will reduce the available 
effective image area. The CMVs are generated by Eq. (1) with the clipper function [7] as 
( ),)()(
2
1))(()( ltCMVltCMVtCMVclippertCMV −−+==          (2) 
 36
3.1 CNN Template Consideration 
3.1.1 Image Difference 
The first step of RPM method will subtract the present sub-region pixels with past 
representative point pixel color. We can implement subtraction step with image inversion 
and current addition.  The inversion template [10] lists in Eq. (5). The input of CNN is 
grayscale representative sub-region. 
              
⎥⎥
⎥
⎦
⎤
⎢⎢
⎢
⎣
⎡
−=
⎥⎥
⎥
⎦
⎤
⎢⎢
⎢
⎣
⎡
−=
000
020
000
000
010
000
BA TT
         (5) 
3.1.2     Global Minimum 
To search the minimum position in a specify area not only takes time but also 
consumes lots power. Comparing previous value and storing the minimum value is the 
basic processing step. The larger area need to be determined, the more clock cycle, ie., 
power, it takes. Therefore, we propose to use CNN adaptive threshold template with 
capability of finding the global minimum position in larger array and can process with 
less clock period. The adaptive threshold template lists in Eq. (6). 
⎥⎥
⎥
⎦
⎤
⎢⎢
⎢
⎣
⎡
=
⎥⎥
⎥
⎦
⎤
⎢⎢
⎢
⎣
⎡
=
000
010
000
000
020
000
BA TT
         z=-z* ,-1<z*<1  (6) 
The adaptive threshold template not only simplifies the CNN state equation (2), but 
also makes the template easier to implement in VLSI. We can write an equation to 
represent Eq. (7) as: 
IuYXIBuAYXX +++−=+++−= 2.             (7) 
VI. CIRCUIT DESIGN OF CNN BASED LMV ESTIMATION 
The process of finding LMV is very computationally intensive, requiring billions of 
operations for each image.  The steps of finding LMV are listed below.  
   
 
 1) Cut each incoming image into four equal regions.  
  2) Segment the prescribed sequence region (t-1) and (t) into sub regions which each 
of them is 19 times 25 pixels as shown in Fig. 6(a).  
  3) Map all the pixels with the central point in each sub-regions(t-1). The mapping 
array is called representative point macro-block (RPM) as shown in Fig. 6(b).      
  4)  Subtraction : | Msub(t) | :=  sub region(t)-RPM(t-1) to provide absolute error 
for the Msub(t) array. 
  5)  Add : Add all the  | Msub(t) | in the prescribed region to form an 19 times 25 
difference value array as shown in Fig. 7(a)(b) . 
  6) Min : Find the minimum difference position of the difference value array as the 
vibrate noise vector for the prescribed region. 
The most complexity operations occur in 1) computing the motion vector and the 
difference value and 2) storing the difference value with the position information if it is 
 38
In order to compare the position information with the simulation of circuit, the shifts to 
vertical and horizontal templates are used and their output is shown in Fig. 12 (c) and (d). 
The output results shows the correct coordinate (X, Y) should be (6,4) and the position is 
the same as in  Fig. 12(a).   
⎥⎥
⎥
⎦
⎤
⎢⎢
⎢
⎣
⎡
−
=
010
020
010
A  ,  
⎥⎥
⎥
⎦
⎤
⎢⎢
⎢
⎣
⎡
=
000
000
000
B  
⎟⎟
⎟⎟
⎟⎟
⎠
⎞
⎜⎜
⎜⎜
⎜⎜
⎝
⎛
=
=
=
Pimageofcolumnverticaleachinholesverticalof
numbertheshowsthatimageBinaryOutput
I
PscaleimageStaticgrayState
bias ,0
 
⎥⎥
⎥
⎦
⎤
⎢⎢
⎢
⎣
⎡
−=
000
121
000
A  ,  
⎥⎥
⎥
⎦
⎤
⎢⎢
⎢
⎣
⎡
=
000
000
000
B  
⎟⎟
⎟⎟
⎟⎟
⎠
⎞
⎜⎜
⎜⎜
⎜⎜
⎝
⎛
=
=
=
Pimageofrowhorizontaleachinholeshorizontalof
numbertheshowsthatimageBinaryOutput
I
PscaleimageStaticgrayState
bias ,0
 
    
                       (a)                     (b) 
Fig. 6  (a) Cut the image into 4 region and each region divide into a 19 times 25 pixels’ 
array. (b) Map all the pixels with the central point in each sub-regions(t-1). 
 
      
     (a) 
 40
 
 
Fig.9. Components of the ASCNN processing unit. 
 
 
Fig.10. Schematic of an ASCNN processing unit (inside the rectangle) with CNN bias circuit. 
 
Fig.11. Complete FSM for the ASCNN controller design.  
 
 42
      
                     (a)                        (b) 
Fig. 14 (a)Layout of mixed-signal ASCNN chip. (b) Specification of ASCNN chip. 
VIII. CONCLUSIONS 
In this thesis we propose the local motion estimation chip based on CNN architecture 
for image stabilization and combine the motion compensation method to construct the 
image stabilization system. To obtain reliable LMVs from the video sequence captured in 
various conditions and to reduce the computational complexity in finding candidate of 
motion vectors, these are two challenges for an image stabilization system. According to 
the simulation results, the proposed technique demonstrates the remarkable performance 
in both quantitative and qualitative (human vision) evaluations compared with the 
existence of approaches. The ASCNN chip is implemented for real-time video 
stabilization applications. 
In particular, CNN is used to reduce computational complexity occurring in motion 
estimation and the ASCNN chip has superior performance compared with DSP 
processors. An 8-bit D/A converter is designed to transform digital input into analog 
current and stored in LAM. LAM is designed to store SAD values and the memory cell is 
made of MOS capacitance. Various SAD voltage stored in LAM can produce input 
current of CNN by the VCC circuit. An adaptive and adjustable bias current circuit is 
combined with CNN to automatically increase the threshold level and detect the global 
minimal SAD position. The global output connected chains which take the CNN 
connection properties are used to decode LMV position without wasting more processing 
cycles in searching address. The proposed CNN-based method can be implemented on 
VLSI, and CNNUM is able to perform the idea of the proposed design. Results with 
mixed-signal simulation based on TSMC 0.35μm 2P4M process have demonstrated the 
superior functionality of the designed circuit. 
REFERENCES 
[1] C. Morimoto, D. DeMenthon, L. Davis, R. Chellappa, and R. Nelson, “Detection of 
independently moving objects in passive video,” Proc. of Intelligent Vehicles 
Workshop, pp. 270-275, Sep. 1995. 
[2] Y. Egusa, “An application of fuzzy set theory for an electronic video camera image 
stabilizer,” IEEE Trans. on Fuzzy Systems, vol. 3, pp. 351-356, Aug. 1995. 
 44
(四) 仿生物電腦感知技術於居家社區保全監控之應用。 
 
基於改良式獨立成分分析之人物偵測與追蹤 
摘      要 
近幾年來，人物偵測及追蹤在電腦視覺中是一項常被深入探討的領域，且其可
被廣泛應用在居家照護、保全及病人監控等系統。本研究提出一改良式獨立成分分
析(ICA)技術的人形自動偵測系統。我們用 ICA (Independent Component Analysis)
抽取辨識特徵，且以 Entropy 作為特徵選擇的依據，以此得到具有良好辨識能力且
具有代表性的特徵。強建的 SVM(Support Vector Machine)則為系統中主要的數據
分類法。實驗環境包含室內及室外，而監視畫面中的移動物體則有行人、動物及車
子等等。 
以背景相減法取出畫面中的移動物體。為了處理複雜背景的情況，使用高斯混
合模型來建構背景。針對移動物體被部分遮蔽的情形，提出金字塔型橢圓形頭部偵
測法來分離。此外，利用簡單的色彩資訊及 Kalman Filter 進行移動物體的追蹤及
動向預測。 
 
一、 緒論 
現今保全攝影設備已經非常普遍，不只在住家、公司行號、商店、街道上等等
都可以輕易看見。但如果只是錄影作為記錄，則既耗費儲存設備又浪費各種效益，
同時攝像記錄無法長久保存以及搜尋所需影像不易等因素，都是讓保全攝影設備無
法發揮效果的原因。但如果攝影設備可藉由偵測各種狀況，例如可疑人物進入、不
明物體侵入等等判斷系統的輔助，則可大大提升記錄儲存以及保全能力的效益。而
如果能夠進行人或非人的判斷，則更可提升後段分析及整理的成果。本系統便是在
這樣的理由下進行研究。 
因為近年來保全議題受到重視，已經有許多即時人形辨識系統(Real-Time 
Human Detection System)的研究提出，如[1]。但是依然有許多具有挑戰性的議題
需要研究，例如前景的取得，以及辨識速度等問題。在對於人的偵測方面，許多利
用監督式的學習分類法(Supervised Classification)也已經被提出。大致上來說，
這些方法都可被分成兩個步驟：(1)移動物體的分離，與 (2)移動物體的辨認。當一
個移動物體進入所觀測的場景後，系統首先會偵測到此移動物體在畫格中位置，再
將其從畫格中分離處理。最後，辨認此物體為人或非人。 
(1) 移動物體的分離 
移動物體的分離目的在找出連續畫格中的移動物體。光流(Optical Flow) 可以
被用來偵測單一移動物體的移動情形。在[13]中，光流的技術被使用在交通工具的
偵測上。但使用此技術偵測移動物體的缺點就是其計算的複雜度相當高，若是想要
將系統運用在即時(Real-Time)的行人偵測上，運算速度會是一個相當重要的考量。
此外，光流的技術在對於非剛性物體的移動偵測並不適用。根據這幾種原因，我們
 46
 
圖 2： 橢圓形遮罩 
 
圖 3：人物分割示意圖 
 
因人的頭部是全身都重疊的情況下最有可能保持獨立不重疊的部分，且其形狀
較為特殊容易區別，故以頭部的橢圓形作為分離移動物體主要的依據。圖 2 為一個
橢圓形遮罩，(0,0)為此遮罩的中心點，“●＂表頭位的位置而“*＂則為背景的位
置。根據此遮罩設定一定範圍對前景作搜尋，符合一定相似程度者則有可能為頭部
之位置。 
經過前面的搜尋會得到部分符合條件的中心位置，如圖 3 頭部中間範圍。將這
些中心點在 X 軸上做累積-圖 3 上，可以分離出主要的幾個群體，此例子為兩群，此
兩群的群中心-圖 3 頭部中的點則為最後判定頭部的位置，因此我們決定這一個移動
物體中實際上是含有兩個不同的物體，可以將它們分割再做辨識。但若是人手舉高
等可能造成頭部位置之誤判，為了避免此問題，我們將整個移動物體在 X 軸上做累
加-圖 3 下，符合峰值者才有可能為頭部之位置。 
 48
1u 2u nuK× ××
 
圖 6:以 ICA 之基底重建影像 
 
三、人與非人的辨識 
圖 4 為人形辨識系統之流程圖。首先，將每一個移動物體正規化成 40X40 的大
小，以便於之後的辨識比較。訓練影像共有:人 1483 張，非人 2066 張；而測試資料
有:人 3178 張，非人 2847 張。 
在 off-line 訓練過程中，使用 ICA 來擷取訓練資料的特徵作為辨識之用。ICA
假定觀測到的資料(訊號)為混合訊號，是由多個互相獨立的源訊號所合成，而 ICA
就是用來估測出這些獨立的源訊號，也可稱之為基底。圖 5 為訓練資料透過 ICA 所
得到之基底。每張觀測影像皆可以基底影像經過線性組合來重建出近似的影像，圖
六為重建示意圖，其中 u 為線性組合的係數，也是之後作為辨識用之特徵。 
透過 ICA 也可以同時將資料量降維，在我們的實驗中，最後得到 76 維的基底。
這 76 個基底辨識能力有好有壞。為了降底計算時間及得到較好的辨識率，選取具有
代表性特徵是整個系統中非常重要的一環。 
 
圖 7:理想的資料分佈 
 
圖 8:實際的資料分佈 
 50
表 1：實驗結果比較表 
 
 
(a) 特徵數-辨識率 
 
(b) 特徵數-Support vector 數 
圖 9：特徵選擇方法之比較 
 
各種特徵選擇法的比較折線圖如圖 9 所示，橫軸為特徵數的選擇，由 10 到 60。(a)
表示取每一特徵數所相對應的辨識率，(b)則為相應所需的 Support Vectors(SVs)
數量，SVs 愈少表示分類愈穩定，且其分類所需之計算量也愈小。我們可以明顯地
觀察到無論是辨識率、穩定度或是計算時間上，本論文所提之特徵選取方法
Conditional Entropy 之效能明顯優於其他方法。 
 52
參考文獻 
[1] K Lo, M Yang, R Lin - “Shadow Removal for Foreground Segmentation,” PSIVT , 
LNCS 4319, pp. 342-352, 2006. 
[2] T. Zhao and R. Nevatia. “Tracking multiple humans in complex situations,” IEEE T. 
Pattern Analysis and Machine Intelligence, Vol. 26, No. 9, pp. 1208-1221, Sept. 
2004. 
[3] R. Venkatesh Babu, P. P´erez, and P. Bouthemy. “Robust tracking with motion 
estimation and local kernel-based color modeling.” Image Vis. Comput. In Press, 
2007. 
[4] M.S. Bartlett, J.R. Movellan and T.J. Sejnowski, “Face recognition by independent 
component analysis. “ IEEE Transaction on Neural Networks, Vol. 13, No. 6 , pp. 
1450–1464,2002. 
[5] L. Zhao and C. E. Thorpe, “Stereo- and neural network-based pedestrian detection,” 
IEEE Transactions on Intelligent Transportation Systems, vol. 1, no. 3, pp. 148-154, 
Sept. 2000. 
[6] C. E. Smith, C. A. Richards, S. A. Brandt, and N. P. Papanikolopoulos, “Visual 
tracking for intelligent vehicle-highway systems,” IEEE Transactions on Vehicular 
Technology, Vol. 45, No. 4, pp. 744-759, Nov. 1996. 
[7] C. Curio, J. Edelbrunner, T. Kalinke, C. Tzomakas, and W. von Seelen, “Walking 
pedestrian recognition,” IEEE Transactions on Intelligent Transportation Systems, 
Vol. 1,No. 3, pp.155-163, Sept. 2000. 
[8] L. Zhao and C. Thorpe, "Stereo- and Neural Network-Based Pedestrian Detection," 
Proceedings Of The IEEE, 1998. 
[9] S. M. Yoon and H. Kim, “Real-time multiple people detection using skin color, 
motion and appearance information, ” Proceedings of the 2004 IEEE International 
Workshop on Robot and Human Interactive Communication Kurashiki, Okayama 
Japan, pp. 20-22, Sept. 2004. 
[10] Y. Ou, X. Wu,H. Qian and Y. Xu, “A Real Time Race Classification System,” IEEE 
International Conference on Information Acquisition, pp. 378-383, 2005. 
[11] C. Stauffer and W.E.L Grimson, “Adaptive Background Mixture Models for 
Real-Time tracking,” In IEEE Conference on Computer Vision and Pattern 
Recognition, pp. 246-252, June 1999. 
[12] J. Zhou and J. Hoang, “Real Time Robust Human Detection and Tracking System,” 
Proceedings of the 2005 IEEE Computer Society Conference on Computer Vision and 
Pattern Recognition (CVPR’05) 2005. 
[13] P. H. Batavia, D. E. Pomerleau, and C. E. Thorpe, “Overtaking vehicle detection 
using implicit optical flow,” IEEE Conference on Intelligent Transportation System, 
Nov.1997, pp. 729-734. 
[14] M. Bertozzi, A. Brogi, M. Del Rose, M. Felisa, A. Rakotomamonjy and F. Suard, ” A 
Pedestrian Detector Using Histograms of Oriented Gradients and a Support Vector 
Machine Classifier,” IEEE Intelligent Transportation Systems Conference, pp. 
143-148, 2007. 
 
 CT970516_美國西雅圖 1
出席國際學術會議心得報告 
                                                                97 年 6 月 30 日 
 
計畫編號 NSC 96-2221-E-009-058- 
計畫名稱 仿生物知覺系統之先進電腦感知技術與系統晶片開發及其應用(3/3) 
出國人員姓名 
服務機關及職稱 
林進燈 國立交通大學電控系教授 
會議時間地點 2008/5/18~2008/5/21 美國，西雅圖 
會議名稱 
（中文）2008 年 IEEE 國際電路與系統研討會 
（英文）The 2008 IEEE International Symposium on Circuits and Systems 
(ISCAS 2008) 
發表論文題目 
（中文）應用於可攜式生醫信號擷取系統之低雜訊可調式增益/頻寬之前端
類比放大器 
（英文）Front-End Amplifier of Low-Noise and Tunable BW/Gain for Portable 
Biomedical Signal Acquisition 
 
一、參加經過 
2008 ISCAS 會議期間為 5月 18 日至 5月 21 日，個人與資工系同仁范倫達教授、鍾仁峰
博士，以及博士班學生洪紹航，於五月十六日，搭乘長榮航空班機，啟程前往西雅圖參加本
屆 ISCAS 2008。本屆會議於五月十八日正式開始，除了舉行開幕茶會以外，其他諸如事務性
之會議以及部分會議已經開始。 
 在本次會議之中，交大腦科學中心發表 2 篇壁報論文，以及 1 篇口頭報告論文。5 月 19
日與 20 日進行壁報論文的張貼，以及回答當天參訪者之問題。口頭報告於當地時間 5 月 21
日早上進行，本次論文報告題目為：Front-End Amplifier of Low-Noise and Tunable BW/Gain 
for Portable Biomedical Signal Acquisition，成果豐碩且反應熱烈。 
 
二、心得 
會議第一天(5/18)主要是進行事務性會議，以及教學型課程，第一天下午(5/19)發表第
一篇壁報論文，第二天(5/20)下午一篇壁報論文，以及第三天(5/21)上午一篇口頭報告論文。
在 Brain Computer Interface 系統的壁報論文上，許多非 BCI 研究的學者們對於該篇論文表
示很高的興趣，同時亦激盪出許多不同的想法。在口頭報告的討論上，許多學者均針對此作
品提出意見以及看法，而這些意見是對該論文精益求精之見解。會中亦有學者鼓勵，由於本
篇規格優於 2007 年所發表在 JSSC 上的論文，故本篇是極有機會能夠被刊登在期刊論文之上。
由此可見，本次報告真是獲益匪淺。 
在本次的研討會之中，亦有發現許多電路上設計的巧思應用於不同需求的設計上，舉例
而言，在這次研討會中看到了一篇由 Lisbon 大學所發表的” A Reconfigurable A/D Converter 
for 4G Wireless Systems”，本篇論文之目的在於設計可應用於 GSM，BLUETOOTH，WCDMA 已
