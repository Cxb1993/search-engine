 2 
have the characteristics of simultaneous feature selection and parameters optimization. This research 
will have a significant improvement in this research topic and generate several SCI papers in two 
years.  
 
Keywords: Data Mining, Classification, Feature Selection, Genetic Algorithm 
 
 
計畫內容 
一、緣由與目的 
 
 資料探勘(Data Mining)是由大量資料中探勘出不明確的、未知的以及潛在的有用資訊之過
程(Han and Kamber 2001)，資料探勘有許多不同的功能，如做分類(Classification)、預測
(Prediction)、關聯法則(Association)、分群(Clustering)等。其中「分類」是從已定義類別的屬
性集合中，根據目標屬性建立出在資料間的法則，來描述屬性與類別之間關係的模型，此模
型可以對其它新的未知資料進行分類，以得到決策的依據。分類問題是資料探勘或者機器學
習(Machine Learning)領域最常被探討的問題，而在資料探勘的工具中可以做分類的方法有很
多，例如：統計方法、類神經網路、決策樹等(Michie et al. 1994)，各適用在不同的情況與資
料性質。 
分類問題首要任務是選擇輸入變數，也就是屬性篩選(Feature Selection)。當遇到資料集有
相當多的屬性，但並非每個屬性都會影響到分類結果，亦即某些屬性可能對目標值(Target 
Value)的影響相當小。屬性篩選可以去除這些不重要的屬性以提高資料探勘的正確率。屬性
篩選的方法相當多，如：逐步迴歸法(Stepwise Regression)、熵法(Entropy)、特徵權重法(Feature 
Weighting)等，按照屬性篩選運作的方式不同，又可以分為 filter與 wrapper兩種方法，若要求
能有效的提高分類器的準確度，則 wrapper法比 filter 法好，然而 wrapper 法之計算較為耗時
(Liu and Motoda, 1998)。 
常見的分類方法有很多，例如：類神經網路系統、決策樹，還有近幾年被提出的支援向
量機(Support Vector Machine，以下簡稱為 SVM)等。SVM是近年來被普遍採用且分類效果很
好的分類方法，支援向量機是由統計學習理論(Statistical Learning Theory)衍生而成的學習演算
法，從統計學習理論中的簡易向量分類器(Simple Vector Classifiers)，逐漸發展成為超平面分類
器(Hyperplane Classifiers)，到目前大家所熟悉的支援向量分類器(Support Vector Classifiers)。支
援向量機在處理分類與預測方面的問題都有不錯的表現(Schőlkopf and Smola 2000; Pedroso 
and Murata 2000)，且廣泛的運用於不同的領域，例如：影像辨識、手寫辨識(Pontil and Verri 
1998)，文字分類(Joachims 1998)與生物科技(Brown et al. 1999)等相關分類問題都獲得相當好
的成果。 
SVM分類器會面臨兩個重要議題： 
 4 
                          min
max min
a
a a
vv -¢ =
-
                  (13) 
 
 
尺度化
測試資料訓練資料
輸入資料
達到結束條件
訓練
S V M 分類器
計算適應度
否
是
  最佳化參數 (C,gamma)
分類正確率
遺傳基因操作
基因型轉換表現型
基因母體
屬性篩選
篩選後
測試資料
篩選後
訓練資料
參
數
基
因
參數基因之表現型
最佳分類器
屬
性
選
取
基
因
屬
性
基
因
之
表
現
型
訓練後之
S V M 分類器
 
圖 1 應用遺傳演算法建立支援向量機分類系統 
 
(2)基因型轉換表現型 
 由初始化的基因母體中，將每條染色體中代表參數的基因透過(11)，將基因型的參數基因
 6 
1998)、利用最陡坡降(Gradient Descent)法去尋找二維向量(表示屬性之有無)之最佳屬性集合 
(Weston et al. 2001)、利用遞迴屬性刪除法(Guyon et al. 2002)、與使用區別函數刪除分析
(Discriminative Function Pruning Analysis) (Mao 2004)等。上述研究採用各種不同方式去做屬性
篩選，本研究將採用與上述研究不相同的方法。 
 
3. 截至目前為止，還沒有相關研究提出以 GA同時做 SVM 的屬性篩選與參數調整以得到最
佳組合的研究。 
 Raymer et al. (2000), Yang and Honavar (1998), Emmanouilidis et al. (2000), 以及Moser and 
Murty (2000)等研究皆為以 GA做屬性篩選的研究，然而，上述研究在設計 GA的染色體時，
並沒有考慮到分類器的參數最佳化。 
 吳智鴻(2003)，曾提出以 GA做 SVM參數最佳化之研究，不過此研究沒有處理屬性篩選
問題。 
 Fröhlich (2003)曾經提出以 GA做屬性篩選之研究，此方法以一般化的 SVM誤差為適應
度函數，透過 GA求算最佳化的屬性子集合，也可以同時求算最佳化的參數 C(參數 C之定義
參看 3.1節 SVM的介紹)，但是此方法無法求算某些具有特定參數的核心函數(Kernel Function)
之最佳化參數，例如，RBF核心函數(Radial Basis Function Kernel)之 gama參數。 
 因此，以 GA同時做 SVM的屬性篩選與參數調整以得到最佳組合，解決此議題可以說頗
有貢獻性。 
 
 總而言之，對於能夠同時做 SVM的屬性篩選與參數調整以得到最佳組合的研究，截至目
前為止，相關研究幾乎還沒有出現。此研究可以被用在各個應用領域，例如：商業、教育、
工程、醫學等領域的分類與預測問題上。此議題仍很值得投入更多的研究，本研究對此研究
議題上可以說十分重要。 
 
計畫成果自評 
 
 本研究採用遺傳演算法調整支援向量機參數並進行屬性篩選，對 SVM同時進行參數調整
與屬性篩選，以得到較少的屬性個數並保持 SVM 分類器之分類正確率。研究成果以“A 
GA-Based Attribute Selection and Parameter Optimization for Support Vector Machine”為題，投稿
於 Expert Systems with Applications (SCI, Impact factor 2004: 1.247)，已經接受刊登。 
 另外也已經發表一篇研討會論文(黃與王 2004a)，以及另外一篇衍生的研討會論文(黃與
王 2004b)。此兩篇論文都是利用遺傳演算法調整支援向量機(與支援向量迴歸)之參數並進行
屬性篩選，得到初步的成果，展示了本研究所提出的方法之可行性以及結果的準確性。 
 
 
參考文獻 
中文部份： 
吳智鴻 2003 年，結合基因演算法最佳化「支持向量機」參數〜財務危機上之應用，國立台
北大學，企業管理學系博士論文 
