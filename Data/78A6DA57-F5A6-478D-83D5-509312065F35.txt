??
本計畫的主要目標是開發智慧型機器人
之系統晶片發展平台。利用系統晶片與嵌入
式軟硬體技術，將多種軟硬體設計整合於單
一晶片中，使整個視覺系統便成可攜式的設
備，是使機器人視覺具有實用性的關鍵技
術。本系統晶片平台將提供各模組之間的系
統介面，並開發許多共用的影像處理與辨認
核心演算法及晶片模組，使未來從事此類研
究的人員可以以此平台快速開發完成其特殊
應用條件的機器人視覺系統。
關鍵詞：機器人、電腦視覺、系統晶片、影
像處理、支援向量機
Abstract
The main objective of the project is to
develop a system-on-a-chip(Soc) platform for
developing intelligent robot vision system. By
using Soc with embedded system technologies,
the proposed platform integrates versatile
hardware and software modules into a portable
device, and also increases the practicability of
the system. The proposed platform includes all
interfaces in the whole system, and links
together all modules into a single device. It will
also provide some kernel modules for imaging
processing and recognition with the form of
software algorithm and hardware chip blocks.
Based on this platform, the researches can fast
develop an application-specific robot vision
system in the future.
Keywords: Robot, computer Vision, SoC,
Image Processing, Support Vector Machines
1. ??
由於機器人在未來世界中將扮演越來越
重要的角色，且它的視覺系統也常常因為不
同的應用而需要更改，但是到目前為止並沒
有一個共用的機器人視覺發展平台可供研發
人員快速開發。我們計畫提出一個通用型的
機器人視覺平台，研發者可以直接在此一平
台上使用已完成的模組或是開發所想要的程
式，將大量的減少機器人開發的時間成本。
2. ????
本計畫預計先研究機器人之視覺系統相
關功能，並進行軟體平台模組的細部規劃與
設計，以及未來要開發的硬體模組。本計畫
初期先以ARM 與DSP 來執行相關模組，當遇
到速度瓶頸時，再將此模組製成加速晶片。
3. ??????
在整個智慧型機械人視覺系統之中，最
主要的部份是影像處理流程。經由影像處理
流程所得到的影像一定要是正確無誤的， 整
個機械人視覺系統才能夠有效的執行。
影像處理流程是處理從感測器上擷取的
原始資料，使其到最後是正確顏色和色調的
照片。在本計劃所提出整合過的影像處理流
程中，包含了一個新的色彩及色階重現演算
法。這裡提出的影像處理流程和新的色彩處
理演算法在處理各種場景在各種光源下都得
到不錯的結果。
3.1 ?????????
圖一 所提出的整合式影像處理流程
我們提出了一個整合型的影像處理流
程，如圖一所示。其中包含了以下的步驟：
（a）自動白平衡。對 CCD/CMOS 感測器所讀
到的原始 RAW 資料來做。
向量估計。由於這些計算的計算量相當大，
DSP 系統已無剩餘的計算資源進行其它運
算。所以本研究強調如何充分利用 DSP 所算
得的資料，再進一步分析人臉的可能位置。
5.1 ???? YCbCr ????
針對每一個畫面 MPEG-4 壓縮過程中會
先將 R/G/B 影像轉成 4:2:0 的 YCbCr 影像。
目前將整個畫面切成許多 16x16 圖素為單元
的 Macro block，以一 320x240 的影像經由此
步驟處理後可得 20×15=300Macro blocks。而
每個 Macro block 具有一個 DCY、DCCb、
DCCr 的值，因為 ARM 微處理器根據這 300
個 DCY、DCCb、DCCr 計算膚色成分。
5.2 Skin Color Detection
根據我們以此膚色範圍來做膚色偵測發
現很多近似的背景顏色都被認定為膚色，所
以我們使用 2500張無人臉的照片以及 125張
膚色樣本去統計 Cb Cr (0,255)內每一點為膚
色(圖五)以及為非膚色(圖六)的機率。
膚色與非膚色之間的分布，事實上是有
一些 overlap 的現象，因此單純用一個方框來
定義膚色範圍無法得到較穩定的結果。定義
的太窄，有些膚色會偵測不到，定義的太寬，
很多背景色會被認定是膚色。所以，我們取
膚色相鄰四點機率相加的值 a，而非膚色相
鄰四點機率相加的值為 b。
       
       
4
1,1,11,,
4
1,1,11,,


jiNSjiNSjiNSjiNS
b
jiSjiSjiSjiS
a
若 a/(a+b) > b/(a+b)，則我們認定該點為膚
色，反之則否。所以我們會得到一個 128*128
大小的膚色機率分布圖(圖七)。該圖記錄著每
一組 Cb Cr 是膚色或是非膚色。我們就根據
這張膚色表來判斷該點是膚色的機率。
圖五、膚色資料統計圖
圖六、非膚色資料統計圖
圖七、正規化後的膚色機率統計圖
5.3 Skin Boundary Detection
輸入影像的每一點的 Cb Cr 經過上一個
步驟的查表法後，我們將查得的結果記錄下
來，膚色(1)或是非膚色(0)，這塊記憶體大小
就跟影像經過 DSP 處理後，存放 DCCb DCCr
記憶體大小一樣是 20×15。根據這張膚色圖，
我們用改良過後的迷宮演算法，沿著膚色邊
緣搜尋這塊膚色的最上、最下、最左、最右
的邊界，不管是走完一圈回到原點，或是最
後退回原點，我們都可以找出這塊膚色的邊
界。
DcY AcY1 AcY5 AcY6 AcY27AcY15AcY14 AcY28
AcY2 AcY4 AcY7 AcY13 AcY29AcY26AcY16 AcY42
AcY3 AcY8 AcY12 AcY17 AcY41AcY30AcY25 AcY43
AcY9 AcY11 AcY18 AcY24 AcY44AcY40AcY31 AcY53
AcY10 AcY19 AcY23 AcY32 AcY52AcY45AcY39 AcY54
AcY20 AcY22 AcY33 AcY38 AcY55AcY51AcY46 AcY60
AcY35 AcY36 AcY48 AcY49 AcY62AcY58AcY57 AcY63
AcY21 AcY34 AcY37 AcY47 AcY59AcY56AcY50 AcY61
8
8
圖十 zigzag scan示意圖
1 2 3 4 5 6 616615614613612… … … … … …f f f f f f f ff f f fi
圖十一 人臉辨認特徵向量示意圖
6.3 ??????
由於 SVM 的長處在於將兩個類別的
特徵映射到高維度後，線性切割以辨認出
兩個類別。假設有 10 個類別，我們先計
算每個類別每個特徵維度的平均值。
統計出第 1類別之第 1個維度的平均
值 11，統計出第 1 類別之第 2 個維度的平
均值 21，類推到第 1 類第 616 維的平均
值 6161 。統計出第 2 類別之第 1 個維度的
平均值 12，統計出第 2 類別之第 2 個維度
的平均值 22，類推到第 2 類第 616 維的
平均值 6162 。同理類推到第 10 類的第 616
維的平均值 61610 。其中 ij的μ代表平均
值，i 代表維度，j 代表類別。
計算完平均值後接著計算每個類別
之特徵維度的變異數。統計出第 1 類別之
第 1 個維度的變異數 11，統計出第 1 類別
之第 2 個維度的變異數 21，類推到第 1 類
第 616 維的變異數 6161 。統計出第 2 類別
之第 1 個維度的變異數 12，統計出第 2 類
別之第 2 個維度的變異數 22，類推到第 2
類第 616 維的變異數 6162 。同理類推到第
10 類的第 616 維的變異數 61610 。其中 ij的
ν代表變異數，i 代表維度，j 代表類別。
ν代表變異數 (variations)。
當我們有了平均值與變異數後，計算
同一個維度對不同類別之間的差異。利用
算出的平均值來計算差異值。計算出來的
差異值越大表示兩類間差別越大。 ,
k
m nd 表
示平均值相減的平方。我們會得到(10×9)
/ 2 = 45個不同兩類間差異的d向量，如圖
十二所示，其中k表示所屬的特徵維度，
下標的兩個數字m、n表示所要分類的兩
個類別。其中d的計算方式由下式得到：
nmnm
kd kn
k
m
k
nm


,10,1
1,...616for,)( 2, 
計算完 ,
k
m nd 後，就可以利用剛剛產生的 ,
k
m nd 與
之前計算的變異數來計算可以用來區別兩類
的特徵區別值ω。計算方法如下式。根據公
式來看，若是同類之間的變異數越小，表示
兩類之間自己與自己類越相像。而兩類間的
,
k
m nd 越大就表示這兩類越不像。因此，若是
所計算出來的ω值越大，表示這個值越可以
區分出這兩類，這個特徵越重要。
nmnm
kd kn
k
m
k
nm
k
nm


,10,1
1,...616for,)/(,, 
計算完兩類與兩類之間的特徵區別值ω
後，我們就可以知道針對不同的兩個類
別，哪一個特徵維度的特徵值是對於分辨
這兩類有幫助的，值越大表示對於分類越
有利。經過排序後我們就可以知道，使用
哪幾個特徵維度是這兩類的最佳辨識。由
於是兩類與兩類之間的辨識，針對不同的
兩個類別取相對應此兩類的最佳分類特
徵維度的做法就會比一般將所有類別一
起訓練出一個分類模型的分類效果來的
好，而且可以用到更少的特徵。取多少特
徵維度來辨認則是取決於當初訓練時最
要的視覺處理功能，而不需要重新設計模組
與改寫程式，對於不同應用規格，抽換或是
增加相關模組，就可以換成不同場合應用的
機器人視覺系統。
8. ????
本計畫第一年實現部分視覺系統模組包
括三邊濾波器與支援向量機，以及以ARM實
現移動物件偵測與膚色偵測，在第二年進行
評估區域性與整體性的效能分析與改進，包
括區域對比增強、離散餘弦轉換、特徵分析，
上述研究成果，達到第一、二年所規劃的進
度。
?????:
[1] Wen-Chung Kao, Sheng-Hong Wang,
Lien-Yang Chen, and Sheng-Yuan Lin,
“Design considerations of color image
processing pipeline for digital cameras.”
IEEE Trans. Consumer Electronics, vol.
53, no. 4, Nov 2006.(SCI)
[2] Wen-Chung Kao, Hong-Shuo Tai,
Chia-Pin Shen, Jia-An Ye, and Hong-Fa
Ho, “A Pipelined Architecture Design for 
Trilateral Noise Filtering,” Accepted for 
presenting in Proc. IEEE International
Symposium Circuits and Systems (ISCAS),
United States, May 2007. (EI)
[3] Wen-Chung Kao, Chia-Ping Shen,
Chih-Chung Kao, Ming-Chai Hsu, and
Hung-Hsin Wu, “Adaptive feature 
selection for real-Time face recognition in
portable surveilance systems,” in Proc.
IEEE International Conference on Systems,
Man and Cybernetics, Canada, Oct. 2007,
pp. 1083–1088 (EI)
[4] Wen-Chung Kao, Wei-Chi Huang,
Lien-Yang Chen, Hong-Shuo Tai, and
Hung-Hsin Wu, “Taking images in 
extremely high dynamic range scenes by
fusing multiple exposed images and tone
reproduction,” in Proc. IEEE International
Conference Consumer Electronics (ICCE),
Las Vegas, January 2008. (EI)
[5] Wen-Chung Kao, “High dynamic range 
imaging by fusing multiple raw images
and tone reproduction,” IEEE Trans.
Consumer Electronics, vol. 55, no. 1, pp.
10 - 15, Feb. 2008. (SCI)
[6] Wen-Chung Kao, Ming-Chai Hsu, “Local 
contrast enhancement for human face
recognition in poor lighting conditions,” in 
Proc. IEEE International Conference on
Systems, Man and Cybernetics, Singapore,
Oct. 2008. (EI)
二、與會心得
參加這次如此盛大的國際會議讓我獲益良多。個人進入學界三年多以來，參加了數次的
國際研討會，在每一次的研討會中，聽取多國研究人員及教授所做研究的簡報時，都深感需
要學習之處甚多。非常感謝國科會補助我此次出國發表論文，使得我有機會和各國的研究人
員有交流討論的機會，也有機會接觸到不同的新研究方向。這次和多位教授互相討論研究心
得之後，感受到了世界一些知名的大學對於學術研究的努力，尤其是日本等國不吝於花費高
額的研究經費，讓研究人員做尖端的研究並發表成果，使該校的研究成果能迅速的累積且技
術成熟。
出國參加國際研討會是與世界各國學術界接觸的一個重要機會。台師大今年起成立電子
系大學部，在國際上的知名度並不高，要有效提昇本校在此學術研究領域的知名度最快、最
有效的方式，是在世界一流的國際會議發表優良的研究成果。此次唯一稍微可惜之處是部份
我國教授因為機票與颱風因素臨時取消行程，而這群教授中，許多人在 IEEE SMC society 中
擔任重要的 Technical Committee 與期刊編輯職務，也同時兼任本次大會許多 session 的
chairman, 可以說旅行社的疏失影響本次大會甚巨。幸經台北科技大學李校長忙進忙出去請代
班主持人，才讓許多 session 得以順利進行。而我個人能在 IEEE 的 SMC 年度大會上發表，
並認識國外知名的學者，並有一些實質的討論，是此行的最大收獲。
pixel with respect to the center pixel is measured based on 
ROAD statistic. All of the three weighting functions are with 
Gaussian kernels. 
A trilateral filter applied to an NM ×  image 
)1,1()( , NjMixf ji ≤≤≤≤ produces an output 
image ,( ) (1 , 1 )i jh x i M j N≤ ≤ ≤ ≤  as defined in 
(1), where (x, y)Tω defined in (2) integrates three 
weighting factors for considering distance, similarity, and 
impulsivity, respectively. The normalized factor Ω is the 
summation of Tω in the filtering window. The weighting 
functions correspond to domain filtering, range filtering, and 
impulsive statistic are defined in (3), (5), and (7), 
respectively. The geometric spread parameter dσ  in (3) is 
chosen based on the desired amount of low pass filtering. A 
larger dσ blurs the image stronger, which combines values 
from more distant image locations. Similarly, the 
photometric spread parameter rσ  in the image range is set to 
achieve the desired amount of combination of pixel values.  
( ), , , ,1( ) ( ) ,j ni mi j i j T p q i j
p i m q j n
h x f x x xω
++
= − = −
=
Ω ∑ ∑  (1) 
)y,x()y,x(1 )y()y,x()y,x()y,x( JI
J
RDT ωωωω
−
=  (2) 
21 (x,y)( )
2(x, y) d
d
D e
σω
−
=  (3) 
(x,y) x-yd =  (4) 
21 ( (x), (y))( )
2(x, y) r
f f
R e
δ
σω
−
=  (5) 
( (x), (y)) (x) (y)f f f fδ = −  (6) 
2
1 (x)
2(x) I
ROAD
I e
σω
 
−   
=  (7) 
21 (x)+ (y)( )
8(x, y) 1 J
ROAD ROAD
J e σ
−
= −  (8)   
The definition of ROAD function is a measure of how 
close a pixel value is to its four most similar neighbors. The 
concept of the definition is that an impulse noise usually has 
great variation from its neighbors. The formula of ROAD 
function is defined in (9), where (x)ir is defined as 
absolution difference of the photometric values for the i-th 
most similar neighboring pixels as defined in (10) and y is 
one of the eight neighboring pixels for a pixel x. 
4
1
(x)= (x)iiROAD r=∑  (9)   
(x) the th smallest ( (x), (y))ir i f fδ=  (10) 
III. THE PROPOSED PIPELINED HARDWARE 
ARCHITECTURE DESIGN 
The proposed architecture for trilateral noise filtering is 
based on a sequence of pipeline stages in order to reduce the 
cycle time of the system clock. The formula of trilateral 
noise filter is reorganized as a hardware-friendly form and 
the entire circuit is partitioned into several pipeline stages for 
performance considerations. Observing the equations of 
trilateral noise filtering listed in (1)-(10), the bottleneck of 
the algorithm would be the evaluation of exponential 
function and the ROAD function which contains the data 
sorting and selection operations. 
The reorganized formulas are stated and derived in (11), 
where the parameters ( dσ , rσ , Iσ , Jσ ) are set as the fixed 
values (5, 20, 40, 50), which are suggested in [5], for 
simplifying hardware design. (x,y)E  is defined in (12) and 
(x,y) ( (x) (y)) / 2R ROAD ROAD= + .  
2 2 2 22( x ,y ) ( x ,y )
2 22 50 2 502 2 2
2 2( x ,y ) ( x ,y )2 2 22 22 50 2 50
2 2 2
1 (x,y) (x,y)
x y (x) (y) (y)
(1 )2 5 2 20 2 40
x y (x) (y) (y) (1 )
2 5 2 20 2 40
(x, y) (x, y) (x, y) (y)
( ) ( )
R R
R R
J J
T D R I
f f ROAD
e e
f f ROADe e
e e e
e
e
ω ω ω ω
− −
× ×
− −
× ×
−
− − − −
−
−× × ×
− − − −
−
+ + −
× × ×
−
=
= × ×
=
=
2 2( x ,y ) ( x ,y )
2 22 2 22 50 2 50
2 22 2
2 22 2
1 1 (64 x y 4 (x) (y) (y) (1 ))
50 64
1 1 (64 x y (y) (4 (x) (y) (y) ) (x,y))
50 64
1 (64 x y (y) (4 (x) (y) (y) ) (x,y))1 50 64( )
R R
f f e ROAD e
ROAD f f ROAD E
ROAD f f ROAD E
e
e
− −
× ×× − + − + −
−
× − + + − −
− + + − −
−
=
=
(11) 
 
( )
( )
2
2
1 1 (x ) (y)
625 32
1 (x) (y)1 32
625
(x,y)
ROAD ROAD
ROAD ROAD
E e
e
−
× +
+
−
=
 
=   
 (12) 
The hardware design based on the reformulated equations 
is much simpler than the original one. The multiplication and 
division operations with specific constant values such as 4, 
32, and 64 can be realized by simply shifting the data lines. 
Hence there is no extra circuit needed for such operations. It 
is easy to observe the most time consuming operations are 
the evaluation of ROAD function calculation and the two 
exponential functions with the bases 1/ 50e−  and 1/ 625e− .  
As shown in Fig. 1, the input data of this design are the 
photometric values of a pixel x as well as its 24 neighboring 
pixels in the 5 5× window. We assume the photometric value 
of a pixel is 8 bit resolution.  Each neighboring pixel is 
sequentially processed in the pipeline. The values of the 
central pixel x and a neighboring pixel y  are latched into 
3416
Authorized licensed use limited to: NATIONAL TAIWAN NORMAL UNIVERSITY. Downloaded on October 20, 2008 at 21:37 from IEEE Xplore.  Restrictions apply.
In stage , 0 7i i≤ ≤ , only the bits y [ ],0 7k i k≤ ≤  of 
the eight input data ( 0 7y y− ) are observed and compared. 
The bit comparison is performed from the most significant 
bit (MSB) to least significant bit (LSB) from the first stage to 
the eighth stage. The circuit in each stage aims at selecting 
the smaller ones which must be included into ROAD 
measurement, or finding the larger ones, which must be reset 
to zero. It consists of four basic blocks in each stage: (a) 
decision circuit, (b) alive circuit, (c) request circuit, and (d) 
result circuit. The role of decision circuit is counting the 
number of zero in the current bit location with referring to 
the status register (Ain) of input data (Din) at the same time. 
The register Ain, which has eight bits, records whether a 
specific data input yi  is alive or not. The input data yi  is 
bypassed in the current stage if the corresponding bit (Ain [i]) 
has been reset to zero in the previous stages. The “alive 
circuit” and “request circuit” are used for selecting the useful 
input data according to the data selection (DS) output sent 
from decision circuit. Finally, the “result circuit” generates 
the output data for the current stage, where the behavior of 
MASK circuit is stated in (13). 
Dout[ ] (Ein[ /8]& Din[ ]) | Rin[ ], 0 63k k k k k= ≤ ≤   (13) 
Parallel
Counter
E[1]
E[2]
E[3]
E[4]
E[5]
E[6]
E[7]
E[0]
8
4
4
invert
3
8
sub
sub DU
4
4
2
3
DS
SUB
D1
D2
D3
D4
D5
D6
D7
Ain
REin
Eout
D0[i]
D1[i]
D2[i]
D3[i]
D4[i]
D5[i]
D6[i]
D7[i]
D0 Din[0]
Din[1]
Din[2]
Din[3]
Din[4]
Din[5]
Din[6]
Din[7]
 
(a) 
11                
00                      
10                
01                     
E            
A           
A            
A & E
E           
8
2
8
8
DS
Ein
OutAin
DS
A & E
Aout
MUX
 
11                      
00                            
10                     
01                        
0
3
3
SUBin
REin
DS
2
DS
3
3
REoutOut
MUX
 
(b)  (c) 
00               
01                     
10              
11                  
64
64
64
64 Ein
Din
Rin
64
8
Ein
Rin
Din
DS
2
DS
Out Rout
MASK Dout
 
(d) 
Figure 3.  The detailed module designs of ROAD circuit. (a) the decision 
circuit, (b) the alive circuit, (c) the request circuit, and (d) the result circuit. 
V. THE IMPLEMENTATION RESULT AND DISSCUSSION 
The digital architecture described here has been 
implemented with Verilog HDL and tested on Xilinx FPGA 
Virtex II, XC2V6000. The timing analysis shows the overall 
system clock can reach to 96.5 MHz. Since there are 24 
neighbors needed to be fed into the circuit for processing a 
pixel, the image data processing speed would become 
96.5/ 24 4≈ MPixels/second. The performance is 
dramatically improved compared to running the algorithm in 
computers, which may take one minute to process the same 
data amount in typical personal computers. 
The system bottleneck would be in the Phase 1 if we do 
not apply the proposed bitwise ROAD measurement circuit. 
This is because it needs to sort the data or perform many 
times of data comparison. With the proposed ROAD 
measurement circuit shown in Fig. 2, the critical path is 
moved to the exponential circuits in Phase 3 and Phase 5. In 
the current implementation, we use piecewise linear 
approximation to exponential function evaluation. In the 
future, we will improve it with other high-performance 
architecture for exponential function evaluation or trying 
other kernels instead of exponential functions. 
REFERENCES 
[1] L. Yin, R. Yang, M. Gabbouj, and Y. Neuvo, “Weighted median 
filters: a tutorial,” IEEE Trans. Circuits and Systems II: Analog and 
Digital Signal Processing, vol. 43, no. 3, pp.157 – 192, Mar. 1996. 
[2] M. J. Black, G. Sapiro, D. H. Marimont, and D. Heeger, “Robust 
anisotropic diffusion,” IEEE Trans. Image Processing, vol. 7, no. 3, 
pp. 421 – 432, Mar. 1998. 
[3] P. Perona and J. Malik, “Scale space and edge detection using 
anisotropic diffusion,” IEEE Trans. Pattern Analysis and Machine 
Intelligence, vol. 12, no. 7, pp. 629 – 639, July 1990. 
[4] C. Tomasi and R. Manduchi, “Bilateral filtering for gray and color 
images,” in Proc. 6th Int.  Conf.  Computer Vision, Bombay, India, 
1998, pp. 839-846. 
[5] R. Garnett, T. Huegerich, C. Chui, and W. He, “A universal noise 
removal algorithm with an impulse detector,” IEEE Trans. Image 
Processing, vol. 14, no. 11, pp.1747-1754, Nov. 2005. 
[6] C. B. Wu, B. D. Liu, and J. F. Yang, “A fuzzy-based impulse noise 
detection and cancellation for real-time processing in video 
receivers,” IEEE Trans. Instrumentation and Measurement, vol. 52, 
no. 3, pp. 780 – 784, 2003. 
[7] S. A. Fahmy, P. Y. K. Cheung, and W. Luk, “Novel FPGA-based 
implementation of median and weighted median median filters for 
image processing,” in Proc. International Conference Field 
Programmable Logic and Applications, Aug. 2005, pp. 142 - 147. 
[8] A. A. Colavita, A. Cicuttin, F. Fratnik, and G. Capello, “SORTCHIP: 
a VLSI implementation of a hardware algorithm for continuous data 
sorting,” IEEE Journal Solid-State Circuits, vol. 38, no. 6, pp. 1076-
1079, June 2003. 
[9] J. Martínez, R. Cumplido, C. Feregrino, “An FPGA-based parallel 
sorting architecture for the burrows wheeler transform,” in Proc. 
IEEE The 2005 International Conference on Reconfigurable 
Computing and FPGAs, Sep. 2005, pp 28-30. 
[10] C. R. Castro-Pareja, J. M. Jagadeesh, S. Venugopal, R. Shekhar, 
“FPGA-based 3D median filtering using word-parallel systolic 
arrays,” in Proc. IEEE International Symposium Circuits & Systems, 
May 2004, vol. 3, pp. 157-160. 
3418
Authorized licensed use limited to: NATIONAL TAIWAN NORMAL UNIVERSITY. Downloaded on October 20, 2008 at 21:37 from IEEE Xplore.  Restrictions apply.
 
 
In the following sections, we will first overview the entire 
recognition. Then the details of the proposed fast 
segmentation with optimal face features matching, adaptively 
feature extraction, and classification with SVMs are given in 
Section III and IV.  The experimental results and conclusion 
are given in Section V and VI. 
II. RECOGNITION SYSTEM OVERVIEW  
To realize a surveillance system on a digital camera 
platform, which contains CCD imaging system, embedded 
microprocessor, and digital signal processor (DSP), we adopt 
macro block as the basis of face recognition to be compatible 
with standard MPEG compression flow. A macro block, 
which contains 16×16 pixels, is the standard unit for MPEG 
video compression. The DC values of Y, Cb, and Cr 
components for each macro block can be easily got from 
MPEG compression task. For a typical video frame with 
320× 240 pixels, only the data of 300 (20× 15) macro blocks 
are processed in one frame.  The computation complexity can 
be drastically reduced and the algorithm is simple enough to 
be realized on a typical embedded microprocessor. 
 
Skin Region
Segmentation
Skin Color
Detection 
Skin Boundary 
Detection
DCT Coefficients 
of macro blocks 
sent from DSP 
Horizontal/Vertical
Histogram
Eye
Detection
Nostril
Detection
Mouth
Detection
Matching with Face Features 
Location Probability Model
Adaptive Feature 
Extraction
Classification by
SVMs
Recognition
Result  
 
Fig. 1. The proposed real-time face recognition flow in digital camera. 
 
Similar to most of pattern recognition problems, the 
proposed face recognition system is separated into several 
stages as shown in Fig. 1. It starts from skin color detection as 
well as skin region segmentation, face location determination 
with optimal matching the positions of six facial features, 
adaptive feature extraction, and classification to decide which 
class the segmented face belongs to. The face detection as 
well as segmentation algorithm first analyzes the colors to 
find the face region and calculates histograms in both 
horizontal and vertical directions to locate possible human 
eye/mouse/nostril positions. Then the final face location is 
determined by finding the best alignment with pre-trained 
probability model of facial features. 
All of features used for segmentation and recognition are 
DCT coefficients, which are generated from the standard 
MPEG compression flow. No extra computation is needed for 
getting these data. In the hardware/software platform that the 
proposed surveillance system runs on, two types of 
processors are included: embedded microprocessor and DSP 
subsystem. The DSP subsystem is responsible for video 
compression and it may not have remaining resources for 
other types of calculations, whereas the embedded 
microprocessor only hosts all control process in the camera 
and performs audio recording. It usually runs in idle state for 
waiting the response from DSP. The remaining 
computational capability of embedded microprocessor can be 
used to run face recognition process. 
The classifier we adopted is the SVMs, which map the 
extracted feature vectors to a higher dimensional space and 
makes the decision based on structural risk minimization. The 
inherit property of SVM can only determine the hyperplane 
between two different classes. Any samples must be 
processed for all combinations between arbitrary two classes. 
The final result is determined by voting the classification 
results from all hyperplanes. Based on this voting scheme, the 
remaining face recognition problem becomes finding the 
decision hyperplane of every class pairs. 
Note that the recognition system does not include all DCT 
coefficients into a feature vector. For each hyperplane, which 
corresponds to a decision problem between two classes, only 
a few DCT coefficients are adaptively selected by analyzing 
in-class stability and the capability of differentiating the two 
class of a hyperplane. The types of features are specific for 
each hyperplane but not universal for all hyperplanes. 
III. FACE SEGMENTATION 
In the proposed system, the process of human face 
segmentation is refined into two steps: skin color detection 
and final face region segmentation which is based on specific 
face features and probability model. In the following 
subsections, the details of these steps are given.  
A. Skin Color Detection 
Since the color space adopted in MPEG compression is 
YCbCr color space. Segmenting regions of faces with YCbCr 
has also been shown to be a powerful descriptor for extracting 
the human faces [3], [6], [11]. Hence the proposed system 
works in YCbCr color space for the skin color analysis. 
Unlike traditional analysis approach which only uses a 
simple bounding box on Cb-Cr chrominance plane to define 
the region of skin colors, the adapted approach is based on the 
distribution analysis of the skin and non-skin colors. Over 
than 2500 face and non-face pictures, which are captured in 
several scenes, are used for the analysis. The details of the 
skin model can be found in [12]. 
B. Face Region Segmentation Based on Specific Features 
The face region segmentation first uses a modified maze 
router with adding some constraint rules to trace all possible 
face regions. The rules guide the search directions and ensure 
only the macro blocks located on the boundary of human 
faces will be traversed. The main issue needed to be 
1084
Authorized licensed use limited to: NATIONAL TAIWAN NORMAL UNIVERSITY. Downloaded on October 20, 2008 at 21:41 from IEEE Xplore.  Restrictions apply.
 
 
features is ( , )d a b  , where ( , )d a b h≤ . The useful 
features can be determined by the proposed importance 
evaluation function.  
 
   
Y 1
Y 2
Y 3
Y 4
8
8
C b
C r
8
D C T
8
8
8
8
8
8
8
8
8
8
8
D S P  
D C T  Y 1
D C T  Y 2
D C T  Y 3
D C T  Y 4
D C T  C b
D C T  C r
 
(a)          (b) 
DcY AcY1 AcY5 AcY6 AcY27AcY15AcY14 AcY28
AcY2 AcY4 AcY7 AcY13 AcY29AcY26AcY16 AcY42
AcY3 AcY8 AcY12 AcY17 AcY41AcY30AcY25 AcY43
AcY9 AcY11 AcY18 AcY24 AcY44AcY40AcY31 AcY53
AcY10 AcY19 AcY23 AcY32 AcY52AcY45AcY39 AcY54
AcY20 AcY22 AcY33 AcY38 AcY55AcY51AcY46 AcY60
AcY35 AcY36 AcY48 AcY49 AcY62AcY58AcY57 AcY63
AcY21 AcY34 AcY37 AcY47 AcY59AcY56AcY50 AcY61
8
8
 
(c) 
Fig. 4. The coefficients of DCT transform for a macro block. (a) the macro 
blocks, (b) the DCT blocks, and (c) the detailed coefficients of a block. 
 
To explain the proposed adaptive feature extraction, we 
assume the resolution of a video frame is normalized to 
320 × 240 first and the segmented face region is fixed at 
128 224× pixels which can be divided into 8 14× macro 
blocks as shown in Fig. 4-(a). All  DCT coefficients are 
passed from DSP subsystem of the camera. For each macro 
block, there are four luminance blocks and two chrominance 
blocks as shown in Fig. 4-(b) and each block consists of 64 
transform domain coefficients as shown in Fig. 4-(c). In this 
paper, the DC and the first three AC coefficients of the four 
luminance blocks are used as feature candidates. Then the 
features are arranged into a vector which consists of 1792 
(8 14 4 4× × × ) elements as shown in Fig. 5. 
As claimed above, the features used in the classification of 
any two classes are not identical. We propose a simple 
equation defined in (2) to evaluate the importance index 
( , , )I a b k of a specific feature , 1 1792k k≤ ≤  for a 
hyperplane ,a bΩ , where ,a kµ  and ,a kσ denote the mean and 
standard deviation values of the feature k for all training 
samples in class a, respectively. 
 
( )2, ,
2 2
, ,
( , , ) a k b k
a k b k
I a b k
µ µ
σ σ
−
=
+
 (2) 
 
ImportanceHigh Low
Sorting by 
importance index
……… ..
Selected
features
……… ..f1 f1792
 
Fig. 5. The adaptive feature selection. 
 
This equation evaluates the differentiation capability 
between the two classes as well as the stability in the same 
class for a type of feature k. For each hyperplane, the 
importance of each feature is needed to be calculated first, 
and then they are sorted by descendant order. The types of 
selected features are usually different for different decision 
hyperplanes. Even the numbers of selected features are also 
inconsistent for each hyperplane. The length of feature vector 
is determined in training phase which has the best recognition 
rate. Using higher dimension feature vectors may not always 
get better results. For some particular cases, the recognition 
rate may be reduced if too many unimportant features are 
applied. 
B. Classification by Support Vector Machines 
Due to the fact that the inherit property of SVM can only 
determine the hyperplane between two different classes, any 
testing samples must be processed for all combinations 
between arbitrary two classes. The final recognition step is to 
find the maximum likelihood among all candidates by voting 
the classification results for all hyperplanes. Based on this 
scheme, we only need to consider the classification problem of 
two different classes. 
Given a training set of instance-label pairs 
( , ),1i iy i l≤ ≤x , where ix and iy  denote the input and 
output domains, respectively, and l denotes the total number of 
training samples, all training samples are mapped into a higher 
dimensional space Φ by the kernel function first. The linear 
estimation function can be defined in (3), where w  represents 
the weight vector characterizing the classifier and b is a bias 
term. 
( ) ( ) ( )1, nT i iif b bφ φ== + = +∑x w w x w x  (3) 
The margin with (3) between the two classes is proportional 
to 2 / w . Maximizing 2 / w  is equivalent to 
minimizing / 2Tw w . After data are mapped into a higher 
dimensional space, the number of variables ( , )bw  becomes 
very large or even infinite. A typical approach to handle this 
difficulty is solving the dual problem shown in (4). 
 
1086
Authorized licensed use limited to: NATIONAL TAIWAN NORMAL UNIVERSITY. Downloaded on October 20, 2008 at 21:41 from IEEE Xplore.  Restrictions apply.
