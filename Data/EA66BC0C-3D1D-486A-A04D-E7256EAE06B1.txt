一、 前言 
數十年來，數學規劃法運用在各種領域最佳化問題的研究，已有許多具體成果，其中
利用梯度方向做為搜尋方向的資訊，對問題的極值求解具有很好的計算效率。此種方法的
特點為初始點位在最佳化問題的最佳解附近，便很容易搜尋到；或設計空間凸區域的問題
其極值亦為全域最佳解。然而，遇到含多極值點的最佳化問題時，全域最佳解的搜尋，則
端賴初始點的選擇，如果初始點位於局部最佳解處附近時，則容易收斂於局部最佳值。 
為了改善傳統數學規劃法的缺點，近年來已有越來越多的研究採取仿生物智慧的概
念，利用在各種領域最佳化問題的研究上，其主要的共同特點為：非線性、類似生物推理
思考的方法、能利用自我學習(Self-learning)、對雜訊更具強建性(Robust)。 
然而，為了應付工程上複雜的問題以及更高維度的挑戰，多目標最佳化的研究也顯得
相當的重要。在一些工程上，常常碰到希望能夠找到一些參數的最佳值，但在調整的過程
中，參數之間也將互相的影響，例如在建造橋樑時，會希望整體建材的重量越低但這也使
得堅固的程度降低，而不是預期中的提高。在飛機設計時，希望能夠最佳化燃油使的效率，
整體的載重量以及整架飛機的重量這幾個參數中取得有效平衡的解。除了在工程上，商業
上也希望藉由最佳化來使得風險最小，但希望同時所得到的財務回收能夠最大化。如何在
這麼多的變數中做取捨及調整，就必需藉由好的多目標最佳化的演算法來達成。 
最佳化 (Optimization) 是在一個有許多限制和條件相互衝突的環境下找尋一個最合適
解決方式的過程。因此最佳化是一個複雜度和解決結果好壞的平衡點；最適當的答案表示
最好的妥協。在實際應用上，改進是相當重要的。甚至連極微小的改進都非常值得的。想
想看在工廠作業上和股票市場中，5％的改善會有多大的影響。即使絕對的最好解答無法被
找到，一個跟這個答案相當接近的解決方案對原本的問題也有相當多的改善。 
縱使目前電腦普遍擁有強大的運算能力，但許多較複雜的NP-complete問題，仍無法在
合理的時間內求得最佳解，因此有待發展出更有效率的演算法以解決日常生活中種種最佳
化問題。 
二、 研究目的 
本計畫提出以粒子群最佳化演算法，並針對原PSO架構提出以下缺失改良方法，以期
能在高維度問題提高求解效率及正確性。 
1. 改善其它演算法容易陷入局部最佳解的缺點 
當初始粒子分佈不均勻或過於集中時，加上演化策略不健全，則易形成狹隘的搜尋
解空間，這將會使粒子群在搜尋空上產生盲點而受限於局部最小值，需經過較多世
代演化才有機會跳脫，但卻無法保證一定能跳脫，大多只搜尋到次佳解即完成收斂。
因此針對此一缺失，我們在研究方法中提出改良辦法。 
2. 提高求解效率，節省計算時間 
初始粒子分佈不均勻或過於集中時，除了易造成狹隘的粒子搜尋空間，也會使粒子
群花費較多時間在解空間的探測(Explore)與開發(Exploit)上，降低了整體搜尋的效率
與效能。 
佳解的效率。PSO 已經被應用來解決許多靜態問題的最佳化，且其求解性能也被證明是極
具效率的。然而，多數的的實際問題與應用是屬於非線性的動態系統。Eberhart 和 Shi 發
現：在 PSO 的參數設定中，固定、或線性遞增的慣性權重對於動態系統的求解較無效率。
考慮實際應用中的特性，他們在[21] 以隨機的方式來設定慣性權重，藉以更適切的應用於
動態問題求解。 
改善 PSO 效能的另一個有趣的方法，由 Angeline [22]所提出。考慮粒子當下的適應函
數，而採用競賽的方式來做取捨。這個方法是將粒子群中表現較優的前百分之五十選出來，
將其內涵資訊複製出來，用以取代粒子群中表現較差的（後百分之五十）粒子，但是，並
不去改變被取代粒子的個人最佳解（personal best）。  
在局部最佳版的 PSO，lbest 對應的是環狀的鄰域架構（neighborhood structure）。粒子
們都將會被其鄰近粒子的最佳位置所影響正如他們各自的過去最佳解也會影響自己的移動
一般。一旦 lbest 的收斂速度比 gbest 慢，代表的是 lbest 有較佳的求解結果且其搜尋了大
部分的搜詢空間[23]。 
近期中，Kennedy 研究了其他鄰域拓墣架構發現馮紐曼拓墣架構可以產生較好的效能
與結果[24]。在[25]中，Parsopoulos 和 Vrahatis 提出了聯合式粒子群最佳化演算法（Unified 
particle swarm optimizer, UPSO），它是結合了”全域版（Global version）”與”局部版（Local 
version）”的 PSO 演算法。 而合作式粒子群最佳化演算法（Cooperative particle swarm 
optimizer, CPSO）也於 [26]中被提出，它包含了兩種版本：CPSO-S 和 CPSO-H。其中，CPSO-S
是將 CCGA 直接套用在標準 PSO 上；而 CPSO-H 則是結合標準 PSO 和 CPSO-S，並且將
二者在每次的演化是代中交替執行。CPSO 將解向量空間分成數個子空間，每一個子空間
個別使用一組粒子族群（Swarm）來求解；也就是說，CPSO 使用的是一維空間的粒子族群
來求解單一維度問題，待所有維度求解完成，再將其合併。另外，Peram 等人提出了以適
應距離率為主的粒子群最佳化演算法（Fitness-distance-ratio based particle swarm optimization, 
FDR-PSO）[27]，該演算法在粒子族群中定義了 n 個距離最接近其自身粒子的其他粒子為
鄰域，而此距離的計算，即為粒子間的歐幾里得距離（Euclidean distance）。在 In [28]中，, 
轉向因子( turn-around factor)被提出來，並加入原始 PSO 架構之中以解決動態問題，如：
隱蔽式訊號分離問題( blind source separation)。在動態系統中的時變型最佳化問題中，由於
最佳解的所在地將會隨時間而改變，這將會使得粒子群無所適從(上一次的最佳經驗或搜尋
方向，在下個時間點可能不適用)，假如僅僅依據先前的經驗求解，將可能會導致搜尋結果
不如預期。El-Abd 和 Kamel 提出了階層式合作粒子群最佳化演算法( hierarchal cooperative 
particle swarm optimizer) [29]，該演算法結合了兩種前期提出的演算法 CONPSO [30]和
CPSO-S。這樣的結合方式是讓兩種演算法各自的粒子群各自求解，並進行資訊交換已得到
較好的收斂性。在近期，有一個廣泛式學習粒子群最佳化演算法( comprehensive learning 
particle swarm optimizer, CLPSO) [31]被提出來。它的學習策略使捨棄全域最佳解的資訊，
取而代之的是其他粒子的過去最佳解，並藉以決定每一個粒子的下一個移動速度向量。 在
多模態問題中，CLPSO 可以有效的改善原始 PSO 的求解效能。 
由於有越來越多的 PSO 版本與變形陸續被提出來，然而那一個版本可以被稱之為”標
準”則難有定論，因此制定”標準 PSO”的構想也被提出來。這個構想是由 James Kennedy 與 
Maurice Clerc 所主導的。將現有的 PSO 每年整理一次，並制定哪一個版本可稱之為標準以
免研究學者在比較時無所適從。標準 PSO 的制定並非在提出一個現有最佳的演算法，而是
以最接近原始 PSO (1995 被提出年版本)並添加些許改良的改良版[32]。 
algorithm,” in Proc. of WCICA 5th world congress on Intelligent Control and Automation, 
vol. 3, pp. 2240-2244, 2004. 
[18] P. Zheng, Y. Liu, L. Tian and Y. Cao, “A blind source separation method based on 
diagonalization of correlation matrices and genetic algorithm,” in Proc. of WCICA 5th 
world congress on Intelligent Control and Automation, vol. 3, pp. 2127-2131, 2004. 
[19] J. Kennedy and R. Eberhart, “Particle Swarm Optimization,” in proceeding of the Fourth 
IEEE International Conference on Neural Networks, pp. 1942-1948, 1995. 
[20] Y. Shi and R. C. Eberhart, “A modified particle swarm optimizer,” in Proc. of IEEE World 
Congress on Computational Intelligence, pp. 69-73, May 1998. 
[21] R. C. Eberhart and Y. Shi, “Tracking and optimizing dynamic systems with particle 
swarms,” in Proc. of IEEE world congress on Evolutionary Computation 2001 (CEC 2001), 
pp. 94-97, May 2001.  
[22] P. Angeline, “Using selection to improve particle swarm optimization,” in Proc. of 
International joint conference on Neural Networks (IJCNN’99), pp. 84-89, Jul. 1999. 
[23] A. P. Engelbrecht, Computational intelligence an introduction, Wiley, pp.185-195, 2002.  
[24] J. Kennedy and R. Mendes, “Population structure and particle swarm performance,” in Proc. 
of IEEE world congress on Evolutionary Computation 2001 (CEC 2002), pp. 1671-1676, 
May 2002. 
[25] K. E. Parsopoulos and M. N. Vrahatis, “UPSO—A unified particle swarm optimization 
scheme,” in Lecture Series on Computational Sciences, pp. 868-873, 2004. 
[26] F. van den Bergh and A. P. Engelbrecht, “A cooperative approach to particle swarm 
optimization,” IEEE Trans. on Evolutionary Computation, vol. 8, pp. 225-239, Jun. 2004. 
[27] T. Peram, K. Veeramachaneni and C. K. Mohan, “Fitness-distance-ratio based particle 
swarm optimization,” in Proc. of Swarm Intelligence Symposium, pp. 174-181, 2003. 
[28] C. L. Lin, S. T. Hsieh, T. Y. Sun and C. C. Liu, “PSO-based learning rate adjustment for 
blind source separation,” in Proc. of International Symposium on Intelligent Signal 
Processing and Communications Systems (ISPACS), pp. 181-184, Dec. 2005. 
[29] M. El-Abd and M. S. Kamel, “A Hierarchal Cooperative Particle Swarm Optimizer,” in 
Proc. Swarm Intelligence Symposium, pp. 43-47, 2006. 
[30] S. Baskar and P. N. Suganthan, “A novel concurrent particle swarm optimization,” in Proc. 
of IEEE Congress on Evolutionary Computation, vol. 1, pp. 792-796, 2004. 
[31] J. J. Liang, A. K. Qin, P. N. Suganthan and S. Baskar, “Comprehensive learning particle 
swarm optimizer for global optimization of multimodal functions,” IEEE Trans. on 
Evolutionary Computation, vol. 10, pp. 281-296, Jun, 2006. 
[32] http://particleswarm.info/ 
四、 研究方法 
本研究以粒子群最佳化演算法[20]為基礎，針對其搜尋特性加以研究，由於在(3.1)式
velocity 的更新方程式中，粒子的移動向量，將會根據自身先前的移動向量以及過去最佳的
位置以及群中最佳位置來前往新的地點進行最佳解的搜尋。由於群中最佳解極有可能僅只
是搜尋空間的局部最佳解(Local optimum)。當一群粒子江搜尋焦點集中在某一個局部最佳
解時，對於廣泛探索以求取新解是沒有幫助的，因此，如果可以適度的加入擾動的機制，
Particle 1
Particle 2
Global best 
solution Past best 
solution 
 
圖4.2 粒子移動 
  因此，為了擴展搜尋解空間的範圍，以提升PSO整體搜尋能力及加速探測與開發時間，
我們構想出了新的PSO移動機制: 
  )]}()()[(                               
)]()()[()({)1(
22
11
gxggbestgrc
gxgpbestgrcgwvTgv
i
iiii
i
i


    (4.2) 
 其中T為轉向因子(turn-around factor),令所有奇數粒子的T為1,偶數粒子的T為-1，如圖4.3
所示，可以發現加入轉向因子(T =-1)後，粒子會做一個與目前學習經驗相反的移動，以圖
中例子說明，此機制會較有效率的搜尋到最好的解。 
Global best solution 
Past best 
solution 
Particle’s next position by (4.2)
Particle’s current position 
Particle’s next position 
by (3.1) or (4.2) Optimal solution 
 
圖3.7 加入轉向因子的粒子移動空間 
五、 結果與討論 
 為了驗證計畫中所提出的方法在搜尋最佳解中的效能改進，計畫中採用了 CEC 2005 
Benchmark 的測試函數(詳參附錄)，並挑選 Std. PSO 2006 (標準 PSO 2006 版)做為比較驗證
的對象。在測試函數中，最佳解值越小越好，而初始設定與最佳解的位置詳列於附錄中。 
 計畫中挑選 CEC 2005 Benchmark 其中的 12 個函數，從複雜問題以致於高度複雜的混
合問題，以做為驗證演算法搜尋能力優劣的依據。我們針對每一個問題都值型 25 次的搜
尋，計算的 FEs(Fitness Evaluations)設定為 50,000，並計算其求解的最大值、最小值、平均
附錄 
A. 測試函數 
1) Shifted Schwefel Problem 1.2 with Noise in Fitness 
],...,,[ ,
_))1,0(4.01(* 1
2
1 1
1
N
i
i
j
j
xxx
biasfNzf








  
 
xoxz 21 N
   (12) 
2) Schwefel Problem 2.6 with Global Optimum on Bounds 
0*)(],3 ,1[*,...1
},52,72max{ 2121


xfxni
xxxxf  
Extend to N dimensions: 
] ..., , ,[ ,
...1 ,_}max{
21
22
N
ii
xxx
Nibiasff


xoxz
BxA         (13) 
where A is a N*N matrix, aij are integer random numbers in the range [-500, 500], 
, Ai is the ith row of A. Bi=Ai*o, o is s N*1 vector, oi are random in the range[-100, 
100]. After load the data file, set oi=-100, for 
0)det( A
]4/[,...,2,1 Ni  , oi=100, for . NNi ],...,4/3[
3) Shifted Rotated Ackley Function with Global Optimum on Bounds 
 
]..., , ,[ ,*)(
_20)2cos(1exp
12.0exp20
21
3
1
1
2
3
N
N
i
i
N
i
i
xxx
biasfez
N
z
N
f












xMoxz
      (13) 
where M is the linear transformation matrix, condition number=100. 
4) Shifted Rastrigin Function 
]..., , ,[ ,
_)10)2cos(10(
21
4
1
22
4
N
N
i
iii
xxx
biasfzzzf



xoxz
     (14) 
5) Shifted Expanded Griewank plus Rosenbrock Function 
Griewank Function:  
 

N
i
N
i
ii
a j
xx
f
1 1
2
1)cos(
4000
       
Rosenbrock Function:     

 
1
1
22
1
2 1100
N
i
iiib xxxf        
] ..., , ,[ ,1
_)),(()),((
...)),(()),((
21
511
32215
N
NbaNNba
baba
xxx
biasfzzffzzff
zzffzzfff




xoxz
       (16) 
6) Hybrid Composition Function 1 
f6 is composed using ten different benchmark functions: two Rastrigin functions, two Weierstrass functions, 
two Griewank functions, two Ackley functions and two Sphere functions. 
B 函數初始設定 
 
f 全域最佳解 初始範圍 搜尋範圍 函數偏移植 
f1 -450 [-100, 100]N [-100, 100]N -450 
f2 -310 [-100, 100]N [-100, 100]N -310 
f3 -140 [-32, 32]N [-32, 32]N -140 
f4 -330 [-5, 5]N [-5, 5]N -330 
f5 -130 [-3, 1]N [-3, 1]N -130 
f6 120 [-5, 5]N [-5, 5]N 120 
f7 120 [-5, 5]N [-5, 5]N 120 
f8 10 [-5, 5]N [-5, 5]N 10 
f9 10 [-5, 5]N [-5, 5]N 10 
f10 10 [-5, 5]N [-5, 5]N 10 
f11 260 [-5, 5]N [-5, 5]N 260 
f12 260 [-2, 5]N No Boundary 260 
 
 
全文完 
 
 圖一 會場剪影 
在 6 月 5 號當天，早上有 Takeshi Yamakawa 主講的 Bio-inspired Self-Organizing 
Relationship Network as Knowledge Acquisition Tool and Fuzzy Inference Engine，也引發會
場學者的熱烈討論，模糊推論引擎的相關研究與方法也被充分的交流。 
下午安排本人的報告是屬於 Special Session 之一，是針對高維度複雜問題所開設的主題，
首先大家都針對不同的最佳化方法加以說明，並導入各自所提出的新方法，並於報告後
給予 10~30 分鐘的問題討問，也因為討論非常熱烈，因此結束時間也遠超過原本的議程。
圖二是論文報告的剪影，本人的報告時間大約為 15 分鐘。 
 
圖二 論文報告 
二、與會心得 
WCCI 是 2 年舉辦一次的超大型國際會議，會議結合了三個原本規模就不小的研討會。
本次出的研討會，的確得以觀摩許多優秀的研究與的論文，當中有些方法極富巧思，參考他
人的理論以及解決問題的技巧，也很能激發許多在未來研究方向的想法，在會中的晚宴，更
是促進交流的最佳管道，與一些在會場中認識的國際友人討論他們的論文內容、方法與理論，
或是閒話家常的對話，無形中也交流了一些不同的價值觀點。有趣的是，在會場也遇到台灣
的教授帶領學生一同出席，也有一些以往曾在會議中認識的人一同參與會議，不但能夠了解
不同地區或是不同國家的學者在做研究上面的態度，更能了解自我存在的渺小以及尚待努力
加強的地方。 
在本會議期間，包學生所發表的論文在內，台灣所發表的論文只有寥寥幾篇，相較之下，
大陸的學者在相關的研究領域就有比較多的貢獻。可能是因為在香港舉辦，所以大陸的學者
投稿也比較踴躍。其實，看到其他研究單位對於一個研究總是很願意投入充分的時間、人力
和經費，如此一來也可以累積較多的研究成果。總有時候回頭看看自己的研究資源，的確是
還有很多可以努力的空間，如果可以有教充足的經費與人力支援，相關的研究也可以推展得
更順利。 
 
 
For all , is the velocity of j-th dimension of the
i-th particle, the c1 and c2 denote the acceleration coefficients,
r1 and r2 are elements from two uniform random sequences in
the range (0, 1), and g is the number of generations. The new
position of a particle is calculated as follows:
Nj ...1 jiv ,
)1()()1(
,,,
 gvgxgx jijiji (2)
The past best position of each particle is updated using
        
      	






gpbestfgxfgx
gpbestfgxfgpbest
gpbest
iii
iii
i 1if,1
1if,
1


(3)
and the global best position gbest found from all particles
during the previous three steps is defined as:
sigpbestfggbest i
ipbest
 1)),1((minarg)1( (4)
The value of moving vector vi can be restricted to the range
[-vmax, vmax] to prevent particles frommoving out of the search
range
B. Some Variants of PSO
Since Kennedy and Eberhart [1] introduced PSO in 1995,
many researchers have worked on improving its performance
in various ways. One of the variants introduces a parameter
called inertia weight of velocity w into the original PSO,
introduced by Shi and Eberhart [6]. The new velocity update
algorithm is shown as follows:
)]()()[(
)]()()[()()1(
,22
,,11,,
,
,
gxggbestgrc
gxgpbestgrcgwvgv
jij
jijijiji
ji
ji

 (5)
It plays the role of balancing the global search and local
search. It can be a positive constant or even a positive linear
or nonlinear function of time. This value is typically setup to
vary linearly from 1 to 0 during the course of a training run.
The inertia weight is similar to the momentum term in a
gradient descent neural network training algorithm.
In population-based optimization methods, how the local
and global exploration is controlled will influence efficiency
on finding the optimal solution directly. PSO has been proven
to be effective while applied to optimizing static problems in
earlier developments. Even so, most real-world applications
are identified as nonlinear dynamic systems. Eberhart and Shi
[7] found that the fixed or liner decreased inertia weight for
PSO is not very effective for tracking dynamic systems.
Considering the dynamic nature of real-world applications, a
random inertia weight factor was proposed for tracking
dynamic systems instead.
Another interesting approach to improve PSO performance
was proposed by Angeline [8] who used a tournament
selection process based on the particles’ current fitness. This
method copies the current positions and velocities of the
better half of the population to replace the worse half, without
changing the “personal best” values of any of the particles in
current step.
The local best version of PSO, lbest, reflects the circle
neighborhood structure. Particles are influenced by the best
position within their neighborhood, as well as their own past
experience. While lbest is slower in convergence than gbest,
lbest results in much better solutions and searches a larger
part of the searching space [9].
More recently, Kennedy investigated other neighborhood
topologies, finding that the von Neumann topology resulted
in superior performance [10]. In [11], Parsopoulos and
Vrahatis proposed a unified particle swarm optimizer (UPSO)
which combined both the global version and local version. A
cooperative particle swarm optimizer (CPSO) [3] which
include two versions: CPSO-S and CPSO-H were also
proposed. The CPSO-S model is a direct application of
Potter' s CCGA model to the standard PSO, while the
CPSO-H model combines the standard PSO with the CPSO-S
model, and performs them both in each generation. CPSO
split the space (solution vector) into several sub-spaces
(smaller vectors) where each sub-space is optimized using a
separate swarm, i.e. CPSO use one-dimensional swarms to
search each dimension separately, the results are then
integrated. Peram et al. proposed the fitness-distance-ratio
based particle swarm optimization (FDR-PSO) [12], which
defines the “neighborhood” of a particle as its n closest
particles of all particles in the population (measured in
Euclidean distance). In [13], the turn-around factor was
involved in original PSO to solve dynamic problems such as
blind source separation. Due to the time-varying optimal
solutions in dynamic systems, it may be harder for the
particles to catch up to various variations in each time slot,
and may produce undesirable results if they move according
to previous experiences only. El-Abd and Kamel proposed a
hierarchal cooperative particle swarm optimizer [14] which
combines two previously proposed models, CONPSO [15]
and CPSO-S. The combination is achieved by having two
swarms searching for a solution concurrently for solution
exchange and performing better convergence. Recently, a
comprehensive learning particle swarm optimizer (CLPSO)
[4] was proposed. Its learning strategy abandons the global
best information, and all other particles’ past best information
is used to update particles’ velocity instead. CLPSO can
significantly improve the performance of the original PSO on
multimodal problems. There are more and more improved
variants of PSO have been proposed, but it is hard to define
which variants of PSO is the standard one. Thus, the idea of
the standard PSO is to define a real standard at least for one
year, validated by some researchers of the field, in particular
James Kennedy and Maurice Clerc. This PSO version does
not intend to be the best one on the market (in particular there
is no adaptation of the swarm size nor of the coefficients) but
simply very near of the original version (1995) with just a few
improvements based on some recent works [16].
III. EFFICIENCT POPULATION UTILIZATION STRATEGY FOR
PARTICLE SWARMOPTIMIZER (EPUS-PSO)
Although PSO algorithms have been applied to a wide
range of optimization problems and numerous variants of the
PSO exist, solving high complexity problems with efficient
1778 2008 IEEE Congress on Evolutionary Computation (CEC 2008)
Authorized licensed use limited to: National Dong Hwa University. Downloaded on February 4, 2009 at 21:35 from IEEE Xplore.  Restrictions apply.


	










ijijr
jijiji
ijij
jijiji
ji
Psrandifgxgpbestgrc
gxgpbestgrcgwv
Psrandifgxggbestgrc
gxgpbestgrcgwv
gv
i
i
i
i
)]()()[(
)]()()[()(
)]()()[(
)]()()[()(
)1(
,,22
,,11,
,22
,,11,
,
(6)
where Psi denotes the solution sharing probability, whose
definition will have a detail description later, of the ith
particle. It will decide if the moving vector of the third item in
the velocity update equation is referring to the gbest or
another particle’s pbest (pbestr). The pbestr can be any other
particle’s pbest, not including its own.
In [4], Liang et al. found that different Learning
Probability values will affect the results for the same problem
if the same value of learning probability was used for all the
particles in the swarm. Thus, each particle will be given a
unique sharing probability. Before the particle’s new velocity
is calculated, a random number will be generated. If this
number is larger than or equal to Psi, the guide of the third
item of the velocity update equation will be the gbest. On the
other hand, if this number is smaller than Psi, the particle will
learn from another particle’s pbest. In other words, the guide
of the third item (gbest) of the velocity update equation will
be replaced by pbestr. The selection of pbestr is stated as
follows.
If the random number is smaller than Psi
1) Randomly choose two particles’ pbest from the
population (Except the pbesti).
2) Compare the fitness values of both pbest and select the
better one as pbestr.
3) pbestr will share its own information of all dimensions.
Thus, the solution searching of all the particles refer to not
only their own pbest but also have the chance for learning
from other particles’ pbest.
Since the dimensional information is incorporated in
calculating the particles’ solution sharing probability. The
definition of learning probability in [4] was referred to define
the solution sharing probability for each particle:
 
N
s
iN
Psi
1
1
1
exp1
5.0









 (7)
where N denotes the dimension of problems and s is the
population size. The solution sharing strategy will be not
necessary while solving one-dimensional problems. The
solution sharing probability will be set as zero due
to .01N
There are two main differences between the solution
sharing strategy and the comprehensive learning strategy [4].
1) The solution sharing strategy not only learns from other
particles’ experiences but also refers to gbest’s
information.
2) For each particle, the solution sharing strategy picks
another particle’s pbest as one of the guides for current
movement instead of fine tuning dimensions one by
one.
C. Searching Range Sharing (SRS)
According to the searching behavior of PSO, the gbest will
be an important clue in leading particles to the global optimal
solution. But it is unavoidable for the solution to fall into the
local minimum while particles try to find better solutions. In
fact, after several generations, particles will gather in several
clusters, or even just one cluster, which is the local minimum.
Each particle in the cluster may perform a local search to
follow evolution, but not be able to explore other better
solutions.
In order to allow the solution exploration in the area to
produce more potential solutions, and find unsearched
solution space. The searching range sharing (SRS) strategy, a
mutation-like evolutionary strategy, was introduced to the
EPUS-PSO algorithm. The SRS strategy can be classified
into two versions: local and global. The two versions of SRS
are classified according to a restricted boundary. Similar to
mutation operation, the SRS activates under a predefined
SRS rate which can be setup to vary linearly from 0 to 0.2
during the course of a training run. Note that this is similar to
the temperature adjustment schedule found in Simulated
Annealing (SA) algorithm.
In the local version, the particle’s new position will be
restricted in the boundary of all past best solution of all
particles ( ). Through local SRS, the
perturbed particles will start solution searching in the reduced
range. This will increase efficiency of solution searching for
particles. Similarly, in the global version, the particles’ new
positions will be restricted in the search boundary as an initial
state ( ). Through global SRS, the perturbed
particles are randomly distributed in the initial search range.
It will increase the probability of finding potential solutions
in un-searched areas. The local version can share particles’
searching ranges to make solution searching for particles
more efficient. The global version can prevent solution from
being trapped in the local optimum.
],[ maxmin pbestpbest
],[ maxmin XX
TABLE I
SEARCH RANGE SHARING STRATEGY
Local version Global version
For
Particles
To perturb selected particle
and place them in reduced
range ],[ maxmin pbestpbest
To perturb particle and place
them in initial range
],[ maxmin XX
For
Dimensions
To perturb selected
dimension (d1) of current
particle to another selected
dimension (d2)’s searching
range ],[
maxmin 22 dd pbestpbest
To Perturb selected
dimension (d1) of current
particle to another selected
dimension (d2)’s searching
range ],[ maxmin XX
The SRS not only can share searching range between
particles but also share searching range between dimensions.
For particles, the particles’ current positions (solution) for all
dimensions will be perturbed. This particle will be placed at a
new position in the restricted boundaries while the SRS is
activated. For dimensions, a dimension will be picked up
randomly; all particles’ corresponding dimensions will be
1780 2008 IEEE Congress on Evolutionary Computation (CEC 2008)
Authorized licensed use limited to: National Dong Hwa University. Downloaded on February 4, 2009 at 21:35 from IEEE Xplore.  Restrictions apply.
IV. EXPERIMENTS
In the experiments, seven CEC 2008 test functions
including two unimodal and five multimodal functions was
chosen for testing the proposed method. The system
environments are listed as follows:
TABLE II
ESTIMATED RUNTIME FOR THE TEST SUITE
System Windows XP (SP2)
CPU
Intel Core 2 Duo E4400 (2.0 GHz x
2). Only one of the processors was
used.
RAM 1 G
Language Matlab 7.4
Algorithm EPUS-PSO
Although the system is with a Core 2 Duo processor, for fair
comparison, one of the two processors was used, i.e. only
50% computation resource of this CPU was used.
In the experiments, the parameters of the proposed method
are listed as follows:
 Inertia weight (w):
)2ln(*2
1
w
 Acceleration coefficients (c1 and c2): )2ln(5.021  cc
The experiments of the proposed approaches on the seven test
functions with 100, 500 and 1000 dimensions are executed
for 500000, 2500000 and 5000000 FES respectively. Table
IV, V and VI present the 1st (best), 7th, 13th (median), 19th, 25th
(worse), mean, and standard deviation of 25 runs of the
proposed method on the 7 test functions with 100, 500 and
1000 dimensions respectively. The median convergence
graphs (7th) of the 7 test functions with 1000 dimensions are
presented in Fig. 3 and 4.
The estimated runtime for the test suite are listed as follows:
TABLE III
ESTIMATED RUNTIME FOR THE TEST SUITE
Dimensions 1000-D
Problems Function 1-7
Algorithm EPUS-PSO
Runs Only one time
Max_FEs 5,000,000
PC
CPU: Intel Core 2 Duo E4400
(2.0 GHz x 2). Only one of the
processors was used.
RAM: 1 G
Runtime 6 h 10m 53s
The proposed method spends about 6 hours to execute all the
7 functions with 1000 dimensions for single run.
TABLE IV
ERROR VALUES ACHIEVED FOR PROBLEMS 1-7, WITH D=100
Problems
1 2 3 4 5 6 7FES
1st (Best) 1.59e+05 6.30e+01 2.15e+10 1.51e+03 1.35e+03 2.00e+01 -8.92e+02
7th 1.87e+05 7.53e+01 3.53e+10 1.55e+03 1.61e+03 2.04e+01 -8.19e+02
13th (Median) 2.15e+05 8.03e+01 4.51e+10 1.60e+03 1.68e+03 2.05e+01 -8.12e+02
19th 2.19e+05 8.44e+01 5.11e+10 1.64e+03 1.73e+03 2.06e+01 -7.98e+02
25th (Worst) 2.42e+05 8.82e+01 5.46e+10 1.66e+03 1.94e+03 2.07e+01 -7.84e+02
5.00e+3
Mean 2.07e+05 7.94e+01 4.28e+10 1.60e+03 1.68e+03 2.05e+01 -8.12e+02
Std 2.14e+04 6.81e+00 9.41e+09 4.85e+01 1.42e+02 1.65e-01 2.25e+01
1st (Best) 2.81e+03 3.47e+01 3.33e+07 8.14e+02 2.47e+01 1.13e+01 -8.92e+02
7th 3.76e+03 3.71e+01 5.87e+07 9.48e+02 3.19e+01 1.38e+01 -8.40e+02
13th (Median) 4.17e+03 3.86e+01 8.24e+07 9.90e+02 3.79e+01 1.52e+01 -8.32e+02
19th 4.94e+03 4.08e+01 1.39e+08 1.14e+03 4.46e+01 1.72e+01 -8.22e+02
25th (Worst) 6.81e+03 4.75e+01 2.44e+08 1.47e+03 5.31e+01 2.02e+01 -8.13e+02
Mean 4.43e+03 3.93e+01 9.87e+07 1.06e+03 3.87e+01 1.55e+01 -8.34e+02
5.00e+4
Std 9.46e+02 3.19e+00 4.84e+07 1.91e+02 8.60e+00 2.43e+00 1.75e+01
1st (Best) 4.43e-01 1.46e+01 6.34e+02 3.67e+02 2.52e-01 1.04e+00 -8.92e+02
7th 6.14e-01 1.72e+01 8.63e+02 4.26e+02 3.40e-01 1.78e+00 -8.64e+02
13th (Median) 7.49e-01 1.85e+01 1.59e+03 4.71e+02 3.73e-01 2.00e+00 -8.53e+02
19th 8.82e-01 2.01e+01 8.27e+03 5.18e+02 4.04e-01 2.35e+00 -8.43e+02
25th (Worst) 1.04e+00 2.32e+01 1.68e+04 5.60e+02 5.25e-01 2.90e+00 -8.37e+02
Mean 7.47e-01 1.86e+01 4.99e+03 4.71e+02 3.72e-01 2.06e+00 -8.55e+02
5.00e+5
Std 1.70e-01 2.26e+00 5.35e+03 5.94e+01 5.60e-02 4.40e-01 1.35e+01
1782 2008 IEEE Congress on Evolutionary Computation (CEC 2008)
Authorized licensed use limited to: National Dong Hwa University. Downloaded on February 4, 2009 at 21:35 from IEEE Xplore.  Restrictions apply.
Fig. 3 Convergence Graph for Functions 1-6.
Fig. 4 Convergence Graph for Functions 7.
V. CONCLUSIONS
This paper presents an efficiency population utilization
strategy for particle swarm optimizer (EPUS-PSO) for
solving large scale global optimization which with both
unimodal and multimodal problems. The proposed
population manager and sharing principle can significantly
improve particles’ searching abilities, to more easily find the
global optimal solution. It also makes PSO more robust,
prevents particles from falling into the local minimum, and
drives particles more efficiently.
Seven test functions were adopted for testing through a
reasonable average and the results are very reliable. Although
the EPUS-PSO contains three main parts which differentiates
from the original PSO, each of them introduce a simple
concept of strategy for particles’ movement and adjustment
of swarm size. Thus, the EPUS-PSO is simple and easy to
implement for solving optimization.
REFERENCES
[1] R. C. Eberhart and J. Kennedy, “A new optimizer using particle swarm
theory,” in Proc. 6th Int. Symp. Micro Machine and Human Science,
Nagoya, Japan, pp. 39-43, 1995.
[2] D. E. Goldberg, Genetic Algorithms in Search, Optimization, and
Machine Learning, Addison-Wesley, 1989.
[3] F. van den Bergh and A. P. Engelbrecht, “A cooperative approach to
particle swarm optimization,” IEEE Transactions on Evolutionary
Computation, vol. 8, pp. 225-239, Jun. 2004.
[4] J. J. Liang, A. K. Qin, P. N. Suganthan and S. Baskar, “Comprehensive
learning particle swarm optimizer for global optimization of
multimodal functions,” IEEE Transactions on Evolutionary
Computation, vol. 10, Jun. pp. 281-296, 2006.
[5] V. G. Gudise and G. K. Venayagamoorthy, “Comparison of Particle
Swarm Optimization and Backpropagation as Training Algorithms for
Neural Networks.” IEEE Swarm Intelligence Symposium, pp. 110-117,
Apr. 2003.
[6] Y. Shi and R. Eberhart, “A modified particle swarm optimizer”, in Proc.
of IEEE World Congress on Computational Intelligence, pp. 69-73,
May 1998.
[7] R. C. Eberhart and Y. Shi, “Tracking and optimizing dynamic systems
with particle swarms,” in Proc. IEEE world congress on Evolutionary
Computation 2001 (CEC 2001), pp. 94–97, May 2001.
[8] P. Angeline, “Using selection to improve particle swarm optimization,”
in Proc. International joint conference on Neural Networks (IJCNN’99),
pp. 84–89, Jul. 1999.
[9] A. P. Engelbrecht, Computational intelligence an introduction, Wiley,
pp.185-195, 2002.
[10] J. Kennedy and R. Mendes, “Population structure and particle swarm
performance,” in Proc. IEEE world congress on Evolutionary
Computation 2001 (CEC 2002), pp. 1671–1676, May 2002.
[11] K. E. Parsopoulos and M. N. Vrahatis, “UPSO—A unified particle
swarm optimization scheme,” in Lecture Series on Computational
Sciences, pp. 868–873, 2004.
[12] T. Peram, K. Veeramachaneni, and C. K. Mohan,
“Fitness-distance-ratio based particle swarm optimization,” in Proc.
Swarm Intelligence Symposium, pp. 174-181, 2003.
[13] C. L. Lin, S. T. Hsieh, T. Y. Sun and C. C. Liu, “PSO-based learning
rate adjustment for blind source separation,” in Proc. of International
Symposium on Intelligent Signal Processing and Communications
Systems (ISPACS), pp. 181-184, Dec. 2005.
[14] M. El-Abd and M. S. Kamel, “A Hierarchal Cooperative Particle
SwarmOptimizer,” in Proc. Swarm Intelligence Symposium, pp. 43-47,
2006.
[15] S. Baskar and P. N. Suganthan, “A novel concurrent particle swarm
optimization,” in Proc. IEEE Congress on Evolutionary Computation,
vol. 1, 2004, pp. 792–796.
[16] http://particleswarm.info/
1784 2008 IEEE Congress on Evolutionary Computation (CEC 2008)
Authorized licensed use limited to: National Dong Hwa University. Downloaded on February 4, 2009 at 21:35 from IEEE Xplore.  Restrictions apply.
 圖一 會場剪影 
在 6 月 5 號當天，早上有 Takeshi Yamakawa 主講的 Bio-inspired Self-Organizing 
Relationship Network as Knowledge Acquisition Tool and Fuzzy Inference Engine，也引發會
場學者的熱烈討論，模糊推論引擎的相關研究與方法也被充分的交流。 
下午安排本人的報告是屬於 Special Session 之一，是針對高維度複雜問題所開設的主題，
首先大家都針對不同的最佳化方法加以說明，並導入各自所提出的新方法，並於報告後
給予 10~30 分鐘的問題討問，也因為討論非常熱烈，因此結束時間也遠超過原本的議程。
圖二是論文報告的剪影，本人的報告時間大約為 15 分鐘。 
 
圖二 論文報告 
