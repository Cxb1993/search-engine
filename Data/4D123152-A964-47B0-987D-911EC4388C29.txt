 1
 
 
行政院國家科學委員會專題研究計畫成果報告 
 
可彈性調整的實體密碼分析防禦法(3/3) 
Flexible Countermeasures against Side-Channel Attack 
 
計畫編號：NSC 95-2221-E-008-044-MY3 
執行期限：97 年 8 月 1 日至 98 年 7 月 31 日 
主持人：顏嵩銘  國立中央大學 資訊工程系 
e-mail address:  yensm@csie.ncu.edu.tw 
http://www.csie.ncu.edu.tw/~yensm/ 
 
一、中文摘要 
 
對於密碼系統安全性的探討一般可分
為兩大類： 密碼系統本身的理論安全性以
及實作密碼系統後產品的安全性。傳統
上，密碼系統本身的理論安全性多半基於
數學上的未解難題並以數學解析為工具，
其攻擊難度常以時間及空間的複雜度來表
示。密碼系統之安全性一般藉由數學之證
明分析說明其所達到之安全等級，其安全
等級通常以破解其私密金鑰所需之複雜度
定義之。相對地，一個密碼系統或模組實
作的安全性檢測與評估也有其攻擊環境假
設及重要評估方針。由於資訊與通訊安全
逐漸受到全球之重視，實際實作出之密碼
系統或模組安全性評量方式於是也廣受探
討。智慧卡(Smart card)於資訊與個人通訊
安全系統之實作上佔有舉足輕重之地位，
如何分析與檢測其安全性自然也成為應用
密碼領域的重要課題之一。自 1996 年起國
際間密碼學者開始發現，理論上安全之密
碼系統亦可能遭受實作上之攻擊，此類之
攻擊法藉由密碼硬體(如智慧卡)執行密碼
運算時所洩漏之物理特性(旁通道)而推得
私密金鑰值，此稱為旁通道攻擊法 
(Side-channel attack) 或 實 體 攻 擊 法 
(Physical attack) 。 Shamir 教 授 於
ASIACRYPT 2003 之邀請演講 (講題 : 
Cryptography--State of the Science)中曾明
白提到密碼分析研究已經由傳統之理論與
純數學分析演化至與電子分析方式(其清
楚地指出為實體密碼分析; side channel 
attack)相互結合，並明確指出密碼研究於
1995 年至 2000 年間兩大新興研究主題之
一即為實體密碼分析。事實上實體密碼分
析之研究方興未艾，仍有相當多重要之研
究課題等待開發與深入探討。近幾年來，
密碼系統實作的安全分析被廣泛地討論，
亦有不少的研究成果被提出。這類的研究
通常稱為實體密碼分析，包含了簡單能量
分析、差分能量分析、時間攻擊法和錯誤
攻擊法等，也包含了相對應的防禦法之設
計與安全分析。 
該類型的安全分析研究，已經超越了
 3
IC 卡 
 
 
二、緣由與目的 
 
以往有關密碼系統實作的研究，均著
重於效率與正確性，而公開金鑰密碼系統
中的指數運算演算法，則是此領域研究的
焦點，各類型的高效能指數運算演算法相
繼被提出。然而密碼系統執行的平台通常
不是一個完全和外界隔離的黑盒子，隨著
密碼系統的執行，與內部運算相關的資訊
通常會透過旁通道 (side-channel) 洩露，
攻擊者藉由分析收集到的能量消耗或運
算時間等旁通道資訊，即可達到快速破解
密碼系統之目的。相對於傳統的密碼分
析，這種新的攻擊方式稱為旁通道攻擊 
(side-channel attack) 或是實體密碼分析 
(physical cryptanalysis)。 
自 1996 年起國際間密碼學者開始發
現，理論上安全之密碼系統亦可能遭受實
作上之攻擊，此類之攻擊法藉由密碼硬體 
(如智慧卡)執行密碼運算時所洩漏之物理
特性(旁通道)，如運算耗電量(如 Power 
analysis ，主要可分為簡單能量分析
(SPA)、差分能量分析(DPA))、運算時間 
(如 Timing attack)、發散之電磁波  (如
Electromagnetic radiation analysis)、物理特
徵模型分析 (如 Template attack) 與錯誤
分析 (如 Fault injection attack) 等，而推得
私密金鑰值。 
SPA能量分析藉由分析密碼系統運行
時所消耗的能量，從中判讀出系統運行的
流程或執行的指令，並據以推導出隱藏在
系統內部的金鑰。比如說指數運算中包含
了乘法和平方運算，若兩種運算採用不同
的演算法，則在能量消耗的波形上將有不
同的表現。相對於 SPA 能量分析以程式流
程或相異的指令為目標，DPA 能量分析則
以指令的運算域  (operand) 為分析的目
標。然而運算域所造成的能量消耗差異極
為微小，難以直接觀察，必須使用統計學
的技巧放大其差異，因此 DPA 能量分析
多半需要收集較多的樣本 (能量消耗波
形)。運算域的數值會造成能量上的差異，
DPA 能量分析的概念就是將所量測到的
樣本，依推測的數值所對應的推測消耗能
量，分為高耗能及低耗能兩類，將兩類數
值的平均值相減，若出現明顯的特定差異
則代表推測正確。 
智慧卡密碼模組安全分析近年來大
量受到各國研究單位之重視並進行更嚴
謹之分析與攻擊性研究，如何防範各種旁
通道攻擊分析所將帶來之安全危機及進
一步如何加以杜絕成為相當重要之研究
課題。綜觀全球過去十年來於智慧卡安全
性分析與檢測的研究，國際間有如下具體
發展趨勢及結果： 
(1) 由於完美的硬體密碼模組 (就理論上
視其為一計算黑盒子) 並不存在，此類實
體安全分析不僅已於學術上自成一項獨
立之研究主題，而且已經於國際間智慧卡
實務界  ( 例如 : 德國 Infineon 、法國
Gemplus、韓國 Samsung) 成為目前最熱門
與首要之課題。由於此主題逐漸受到重
視，國際密碼學研究學會  (IACR ，
International Association for Cryptologic 
Research) 也有針對密碼系統硬體實作與
其安全性為討論議題的重要國際會議
International Workshop on Cryptographic 
Hardware and Embedded Systems (簡稱
CHES)。 
(2) 為應變旁通道攻擊分析法所造成之
 5
以 0 與±1 所組成的數字集合(digital set) 
重新編碼，稱為二元有號數編碼(binary 
signed digit recoding)。由於此類編碼的結
果並不唯一，若在執行指數運算前，將指
數隨機地轉換為有號數編碼，則可得到一
個不固定的運算過程，許多隨機式的指數
運算演算法皆以此為發展基礎。但有號數
二進位和傳統的二進位編碼差異有限，從
左向右 (即 MSB 向 LSB) 掃描時，中間值
的差異為 0 或 1，而從右向左 (即 LSB 向
MSB) 掃描時，差異為 0 或 2k。由於差異
量固定及可預測，因此這類型的隨機式指
數運算演算法容易遭到差分能量分析之攻
擊。本計畫提出一種新的隨機式編碼法，
其所使用的數字集合 (digit set) 不再是固
定的 0 與±1，而是 0、1 與 s，其中的 s 滿
足 s mod 4 = 3。該新編碼法可視為傳統非
相鄰格式編碼的一般化表示法，當 s = −1
時就是常見的由數字集合0與±1所組成的
非相鄰格式編碼，當 s = 3 時就是視窗大小
為二的滑動視窗 (sliding window) 編碼。
這類編碼法的結果，非零位元的數量為其
長度的三分之一，將位元長度為 n 的指數
以此演算法編碼後，指數運算所需要的乘
法和平方運算的平均數量為 1.33n + 
O(1)。本計畫發展的編碼法，由於參數 s
是隨機選取的亂數，即使使用固定式的非
相鄰格式編碼也不會得到固定的編碼結
果。令 s 之二進位表示法最大之位元數為
r，則參數 s 共有 2r−1種可能的選擇 (包含
正數與負數兩種可能性)，相對於其他固定
式的編碼法，該新編碼法對差分能量分析
具有相當大之防禦能力。初步之研究結果
顯示，使用該新編碼法時若要成功實施差
分能量分析，則所需要收集的能量消耗樣
本數將成長為傳統方式之 (2r−1)2 倍。因此
當 s 的位元數增加時，差分能量分析的困
難度將呈指數成長。進一步之理論分析及
差分能量分析實驗驗證，將是未來之研究
重點。 
此外，預計該類演算法(防禦法)將可再
延伸為多位元的非相鄰格式 (n-NAF)，以
空間換取指數運算效率的提升，此亦是兼
具實務與理論研究價值之延伸主題。 
 
利用新型非相鄰格式的 Ha-Moon 編碼
法設計 
對於同一數的所有二元有號數編碼
中，存在一種最佳化的非相鄰格式 (NAF, 
nonadjacent form) 編碼，其非零數字的個
數為所有二元有號數編碼中最少的，平均
數量為其位元長度的三分之一。Ha-Moon
編碼法利用此最佳化的非相鄰格式編碼，
及另外一種非最佳化的相鄰格式  (AF, 
adjacent form) 編碼，於指數轉換為二元有
號數的過程中，隨機地在兩種編碼法間切
換，平均地選擇兩種編碼法而達到隨機編
碼的目的。原有的著名Ha-Moon編碼法(為
了防禦差分能量分析)，因二元有號數編碼
的基本特性，導致其無法對差分能量分析
進行有效之防禦。經由本計畫提出之新編
碼法，可以去除二元有號數編碼的缺點，
但仍然可保持效率上的優勢，因此本計畫
利用該新提案的編碼法以建構改良式的
Ha-Moon 演算法(防禦法)。 
本計畫也進行改良的 Ha-Moon 演算法
於簡單能量分析方面之安全性探討。於原
有的 Ha-Moon 方法中，其同樣受到二元有
號數編碼基本特性的影響，攻擊者可經由
收集多次運算的能量消耗數據，反推出運
算的乘法與平方運算序列。雖然運算中的
兩種乘法 (相對應於+1 與−1) 無法直接被
 7
進行探討與研究，例如: (a)上述演算法運
算效率的精確估計，包含最差狀況的上
限、運算時間的機率分佈等等; (b)利用相
關的方法進一步加速運算以提升效率，例
如滑動視窗法(sliding window method)、非
相鄰格式 (nonadjacent form)的有號數編
碼(signed digit recoding)等; (c)演算法高效
率的實作研究。並且探討在實作這類演算
法時，如何降低記憶體的使用量，或是降
低其他附屬運算所造的額外負擔。 
本計畫第三年度針對前一年度所研發
之基於二元最大公因數運算之指數運算演
算法進行延續性之研究及應用探討，設計
出較以往之多指數運算演算法優異許多之
方法。 
多指數運算演算法於近代密碼系統之
實現具有相當關鍵之重要性，然而相關之
研究仍然不多見，而且多數集中於雙指數
運算演算法 (Double-exponentiation)之探
討，於實際應用上仍嫌不足。以往之多指
數運算演算法幾乎皆根基於著名學者
Shamir 所提之 Simultaneous squaring 的概
念。本計畫採用第二年度所研發之基於二
元最大公因數運算之指數運算演算法為基
礎，擴充設計為適用於多指數運算之演算
法。 
與前人之方法 (根基於 Simultaneous 
squaring)比較，本計畫所設計之多指數運
算演算法不但具有較佳之效能，同時也能
確保實作時使用較少量之記憶體，此特性
對目前使用於實現密碼系統之智慧卡具有
絕對關鍵之重要性，因為該類計算元件之
記憶體相當稀少。同時值得一提的是，本
計畫所設計之多指數運算演算法於高維度
(High dimension)時之效能尤其優異，此與
一般目前之多指數運算演算法之特性恰好
相反，因此實用性特別突出，具有高實務
價值。造成上述優點之主因為，本計畫所
設計之多指數運算演算法並不需要如同前
人之方法一樣於運作前建立大型之表格
(Pre-computation table)，這不但大幅節省
記憶體，同時一般也節省不少計算量。 
於研究該多指數運算演算法效能時我
們遇上極大之難度，經過許多時日仍然難
以採用簡潔精緻之解析方式(數學解析)得
到精簡且正確之運算效能評估式子。雖然
得到一些解析結果，但是本團隊最後還是
決定退而求其次採用電腦模擬(Simulation)
之方式來探討該新演算法與前人方法效能
上之差異(見下圖)，同時與數學解析之結
果印證其正確性。然而，為了讓電腦模擬
能夠真實達到本計畫所要探討之高維度
(High dimension)之情況，因此花費相當之
時日進行計算與資料整理始得到模擬之結
果。 
 
 
 
 
 
 
 
 
 
本計畫所設計之高效能多指數運算演
算法的一項重要應用為整批數位簽章驗證
(Batch verification of digital signatures)，該
技術原本於根基在 Prime field 之數位簽章
已經得到多次之探討，計畫主持人為全球
首先與法國另一研究團隊同時獨立開發出
整批數位簽章驗證之發明人。由於近幾年
來整批數位簽章驗證之研究範疇已經由
The Separated Non-Adjacent Form
Sung-Ming Yen and Wei-Chih Lien
Laboratory of Cryptography and Information Security (LCIS)
Dept of Computer Science and Information Engineering
National Central University, Chung-Li, Taiwan 320, R.O.C.
E-mail: {yensm;cs222058}@csie.ncu.edu.tw
http://www.csie.ncu.edu.tw/~yensm/
Abstract. Binary non-adjacent form (NAF) with the property of hav-
ing minimal Hamming weight has been proved to be a good method
to speedup the computation of scalar multiplications defined on elliptic
curves. The randomized NAF recoding has been considered as a typical
countermeasure against side-channel attacks (SCA). In this paper, the
separated non-adjacent form (sNAF) is introduced as a generalization of
NAF. It will be shown that both sNAF and NAF can perform equally
well when used to speedup the computation of scalar multiplications. A
recoding algorithm is developed which can be used to recode a binary
sequence to the NAF representation as well as the sNAF representation.
Furthermore, based on the proposed sNAF, two randomized sNAF re-
coding schemes will be developed as SCA countermeasures which are
much superior to the randomized NAF recoding from the viewpoint of
security.
Keywords: Cryptographic algorithms, Non-adjacent form, Side-channel at-
tack, Signed-digit representation.
1 Introduction
Low-cost computation of a scalar multiplication, kP (k times of a point P ), over a
finite additive group defined on an elliptic curve [12, 17] has been considered as an
important issue for resource-limited devices, such as smart cards. A well-known
approach is the binary scalar multiplication algorithm, e.g., Fig. 1-(A), based on
an addition chain derived from k’s binary representation [11]. The computational
complexity of this category of scalar multiplication algorithms depends on the
bit-length and also the Hamming weight of k’s binary representation.
The cost of computing point inversion, −P , is comparatively much smaller
than that of computing a scalar multiplication. Therefore, a feasible approach
of speeding up the computation of a scalar multiplication is to find some special
addition-subtraction chains of k with a shorter length and based on these shorter
chains more efficient scalar multiplication algorithms can be developed. Some
kinds of signed-digit representations have been employed or developed for this
The Separated Non-Adjacent Form 3
2 Preliminary Background and Related Works
2.1 Scalar Multiplication Algorithm and Simple Power Analysis
Let (kn−1, · · · , k0)2 be the binary representation of an n-bit integer k. Given a
point P on an elliptic curve, Fig. 1-(A) shows the basic scalar multiplication
algorithm to compute Q = kP in which O is the infinite point. The algorithm
in Fig. 1-(A) takes n point doubling operations DOUBLE(Q) in Step 3 and on
average 0.5n point addition operations ADD(Q,P ) in Step 4.
Input: k = (kn−1, · · · , k0)2;P
Output: Q = kP
01 Q← O
02 For i from (n-1) to 0 do
03 Q← DOUBLE(Q)
04 If (ki 6= 0) do Q← ADD(Q,P )
05 Return Q
(A) Basic algorithm
Input: k = (kn−1, · · · , k0)2;P
Output: Q = kP
01 Q[0]← O;Q[1]← P ; i← n-1;x← 0
02 While (i ≥ 0) do
03 Q[0]← ADD∗(Q[0], Q[x])
04 x← x⊕ ki; i← i− ¬x
05 Return Q[0]
(B) Atomic algorithm against SPA
Fig. 1. Scalar multiplication algorithms.
In the usual implementations, the elliptic curve point doubling operation
DOUBLE(Q) and the elliptic curve point addition operation ADD(Q,P ) are different
and are therefore distinguishable. This algorithm is vulnerable to the SPA attack
[14] due to the distinguishable different point operations. To prevent SPA, a
modified algorithm in Fig. 1-(B) with regular processing and indistinguishable
point operation ADD∗(Q[0], Q[x]) (to name as the atomic addition) has been
suggested in [3]. This enhanced algorithm also takes 1.5n point operations to
compute kP .
2.2 Non-Adjacent Form
The computation of elliptic curve point inversion, say given a point P to compute
−P , is cost effective when compared with the scalar multiplication. So, a point
subtraction Q− P can be achieved by an addition operation ADD(Q,−P ) if −P
is precomputed. Many fast scalar multiplication algorithms have been suggested
based on the above trick as well as advanced integer recoding techniques [8, 18,
22, 24]. Among them, the NAF recoding [24] is the most well known one by which
the minimal average Hamming weight of a binary signed digit representation of
an integer can be obtained. A representation of k with a smaller Hamming
weight enables the scalar multiplication in Fig. 1-(A) to achieve an improved
performance.
Definition 1. A sequence of signed digits with a digit-set SD2 of {0, 1,−1} is
called the binary NAF (or NAF for short) iff it satisfies:
The Separated Non-Adjacent Form 5
A randomized NAF recoding scheme is proposed by Ha and Moon [6] as a
countermeasure against DPA. The right half of the Table 1 shows the simplified
Ha-Moon randomized NAF recoding with ki+1 and ri being combined (for the
original Ha-Moon recoding table the readers can refer to [6]). A random bit ri ∈R
{0, 1} will be generated when recoding ki to di such that the usual NAF recoding
will be performed if ri = 0 while an alternative recoding will be performed if
ri = 1. Analysis of the Ha-Moon randomized recoding scheme shows that the
recoded di has a random distribution in {0, 1, 1¯} with probabilities of {12 , 14 , 14},
respectively.
It was expected in [6] that this randomized NAF recoding can disable (or per-
secute substantially) DPA. However, an observation on the intermediate values
of the randomized NAF recoding has been made by Sim et al. [25] that
(dn, · · · , di)2 = (kn−1, · · · , ki)2 + ci (1)
where ci (0 < i ≤ n) is a random carry bit generated during the randomized
recoding process. Given (kn−1, · · · , ki+1), the attacker can guess (ki, ci) as (1,1)
or (0,0) (the other cases of (0,1) and (1,0) are indistinguishable1) and mounts a
usual DPA on (dn, · · · , di)2 to derive the value of ki. If ci is uniformly distributed
on {0, 1} and ki is guessed correctly, then only 50% of the collected power traces
are manipulated appropriately by a DPA statistical analysis. All other 50% of the
collected power traces become noise due to the countermeasure and the expected
correlation coefficient of a DPA statistical analysis is reduced.
According to the analysis of assessing the number of needed power traces
in [15, Sections 6.4 and 8.1.1] (summarized in the following rule of thumb), in
order to mount a successful DPA on the protected device using randomized NAF
recoding, four times of power traces are needed.
Rule of Thumb 1 (Quadratic Rule) If a device is protected by using a coun-
termeasure, assuming that with probability pˆ the collected power traces will cor-
respond to the power traces of that device without protection, then in practice
the expected correlation coefficient of a DPA statistical analysis is reduced to pˆ
of its original one. Furthermore, in practice, reducing the correlation coefficient
by a factor of pˆ−1 means that pˆ−2 times more power traces are needed.
3 The Proposed Recoding Method
It is well known that the property of low Hamming weight of the NAF rep-
resentation comes from the non-adjacent distribution of its non-zero digits. In
this paper a generalization of the conventional NAF recoding (with digit-set SD2
{0, 1, 1¯}) will be given. In the proposed generalized NAF recoding, a digit-set
1 Suppose the secret bit ki = 0 and the attacker selects (ki, ci) = (0, 1). This will have
a 50% correct guess of (dn, · · · , di)2 due to the random carry bit ci. But another
selection of (ki, ci) = (1, 0) also leads to a 50% correct guess of (dn, · · · , di)2 even if
the exact value of ki is zero.
The Separated Non-Adjacent Form 7
Theorem 1. The recoded result d by using the rule given in the Table 2 and the
original input k both represent the same value.
Proof. Let the (n+g)-digit registers used to recode k into d be t = (tn+g−1, · · · , t1, t0)SD.
At each recoding step, values of V1 = ci+g · 2i+g +
∑n+g−1
i=0 ti · 2i and V2 =
ci+g+1 · 2i+g+1 +
∑n+g−1
i=0 ti · 2i = 2 · ci+g+1 · 2i+g +
∑n+g−1
i=0 ti · 2i are assumed
to represent the values before and after the recoding. It can be checked that
V1 = V2 for all the cases listed in the recoding Table 2 since only ti+g, ti, and
the auxiliary carry-in/carry-out bit will be changed at each recoding step. Fur-
thermore, both the initially assigned value of ci+g = 0 (so initially V1 = k) and
the final result of ci+g+1 = 0 (thus finally V2 = d), and this fact proves k = d. uunionsq
Theorem 2. The recoded result by using the rule given in the Table 2 is of a
g-sNAF representation.
Proof. Either di or the updated bit ki+g of the right half part in the Table 2
after being recoded will be zero. This guarantees that the recoded result d will
be of a g-sNAF representation. uunionsq
Theorem 3. The recoded result d of a given n-bit k generated by the proposed
g-sNAF recoding algorithm has at most (n+ g) digits.
Proof. When the proposed g-sNAF recoding algorithm recodes each ki to di as
a digit in {0, 1, s} and updates ki+g in binary for i from zero to (n−1), the digit
string of the recoded result satisfies a form {0, 1}e||{0, 1, s}n, where “||” means
a concatenation of two digit strings and e is the extended digit-length.
As an example, the recoded result of a given k = 2n−2n−g−1 (only with 1(s)
in the front (g + 1) bits) can be computed as 1||0g||sg||0n−g−1 and has (n + g)
digits. This example shows that a recoded result from the proposed recoding
algorithm can have at least (n+ g) digits.
Suppose that a digit string satisfying the aforementioned form with an e =
(g + 1) and without leading zeros can also represent an n-bit integer in binary.
Thus an example presenting the minimal value can be 1||0g||sn and the presented
value is
2n+g + (2n − 1) · (−2g + 1) = 2n + 2g − 1.
However, when a g ≥ 1 is originally assumed in the proposed recoding algorithm,
this value is bigger than 2n and conflicts with the assigned supposition. This
contradiction leads that a recoded result from the proposed recoding algorithm
has less than (n + g + 1) digits and precisely has at most (n + g) digits by the
former example. uunionsq
We wish to emphasize that the proposed g-sNAF recoding algorithm in the
Table 2 is of a universal form which can be used to recode the NAF represen-
tation (in fact the 1-sNAF) as well as the g-sNAF representation for g ≥ 2. For
g = 1, g-sNAF is reduced to the NAF and in this case both ki+g and ki are
continuous digits. In this reduced case, the fourth and the eighth rows of Table 2
The Separated Non-Adjacent Form 9
Afterward when trying to reduce Table 3 from the transformed input (ki, k′i+g, c
′
i+g+1)
and the output (di, ki+g, ci+g+1), we can find that the joined distribution of di
and ki+g depend on both ki and k′i+g. The new recoding rules can be summarized
by an arithmetic transition function F described as follows.
– If ki ·k′i+g = 0, then F encodes di as ki and updates ki+g as k′i+g and ci+g+1
as c′i+g+1.
– If ki · k′i+g = 1, then F encodes di as s and computes the final updated ki+g
and ci+g+1 from k′i+g and c
′
i+g+1 with a hidden (implicitly active in Table 2)
carry-in chi+g = ki ·k′i+g, such that 2 · ci+g+1+ki+g = 2 · c′i+g+1+k′i+g+ chi+g.
The Table 3 with one more step to transform the read input before recod-
ing gives the reduced g-sNAF recoding algorithm with F-summarized simpler
recoding rules than in Table 2. When the reduced g-sNAF recoding algorithm
can perform equally to recode sNAF representations, we intend to analyze the
Hamming weight of the sNAF representation from the output distributions of
Table 3 case by case in the following.
Table 3. The reduced g-sNAF recoding algorithm.
g-sNAF (g ≥ 1)
Input preUpdate F Output
ki ki+g ci+g ki k
′
i+g c
′
i+g+1 ki · k′i+g di ki+g ci+g+1
0 0 0
0
0
0
0 0
0
0
0 1 1 1 1
0 0 1
1 0 1 0
0 1 0
1 0 1
1
1 0 1 s 0 1
1 1 0
1 0 0
0
0
0 1 0
0
1 1 1 1 1
Output analysis of Table 3. We assume that the given n-bit integer k is
uniformly distributed in the range [0, 2n − 1], where n is close to the infinite.
Lemma 1. Each ki for i from zero to (n− 1) is uniformly distributed in {0, 1}.
Proof. Based on the assumption of k being uniformly in [0, 2n − 1], each ki for
i from zero to (n − 1) can be generated a value zero or one with the same
probability 12 , and thus can have a uniform distribution in {0, 1}. uunionsq
By Lemma 1, we make an initial assumption about the read ki or ki+g in
each recoding step with a uniform distribution in {0, 1}. Suppose an increasing
index i of recoding steps from zero to (n− 1), the distribution of the recoded di
is analyzed from different cases in the following.
The Separated Non-Adjacent Form 11
Proof. By Lemma 3 and 4, the distributions of the recoded digits can be sepa-
rated into two independent cases. If the read ki is zero, then di is always zero.
If the read ki is one, then di is always non-zero and di+g is always zero.
By Lemma 1, these two cases will happen with the same probability 12 . There-
fore, the expected Hamming weight density of an sNAF representation d can be
calculated HWD(d) = 0.5×0+0.5×10.5×1+0.5×2 =
1
3 plus an ² for a negligible error. uunionsq
By Theorem 4, the expected Hamming weight of d is 13 ·(n+g). In our exper-
iment, 10,000 256-bit random integers are recoded to 2-sNAF representations.
The result shows that the average Hamming weight per sample is 85.8962, which
is close to the expected one, (256 + 2)/3 = 86.
3.3 Application to Secure Cryptosystem Implementation
In this section, an SPA-immune scalar multiplication algorithm with sNAF rep-
resentations is proposed as in Fig. 2. For more security considerations, a DPA
countermeasure can be combined with this method, and Section 4 gives two
examples.
Input: d = (dn+g−1, · · · , d0)SD; g;P
Output: dP
00 Pre-compute: Q[2]← −(2g − 1)P ; //compute by (−2gP + P )
01 Q[0]← O; Q[1]← P ; i← n+ g − 1; x← (00)2
02 while (i ≥ 0) do
03 Q[0]← ADD∗(Q[0], Q[x])
04 x← x⊕ di; i← i− ¬(x0 ⊕ x1)
05 Return Q[0]
Fig. 2. The proposed scalar multiplication algorithm with g-sNAF representations.
Notice that sNAF is a universal representation using the digit-set SD with
three signed-digit elements {0, 1, s}. When applying sNAF to speeding up the
computation of a scalar multiplication, a 2-bit binary code is minimally required
to denote one kind of digits. Without loss of generality, we assume the 2-bit
binary codes, (00), (01), and (10) being used to denote the digit elements 0, 1,
and s of SD respectively.
Based on the atomic addition function in [3], Fig. 2 shows an SPA-immune
scalar multiplication algorithm with g-sNAF representations. Compared with
Fig. 1-B, one precomputation of −(2g − 1)P is additionally needed, and the
digit loader x is extended from one bit to two bits. Therefore, a flag used at the
end Step-04 to indicate whether a non-zero digit is loaded in x can be achieved
by a bitwise exclusive-or operation with both x’s two bits, say x0 and x1, as
input.
When the expected Hamming weight of a g-sNAF representation is proved
(n + g)/3 in Section 3.2, the proposed scalar multiplication algorithm takes
The Separated Non-Adjacent Form 13
a dP computation. For example, if a G = 10 is selected, on average 10.7 2 ad-
ditional dummy operations per dP computation are enough to fix the operation
amount and rule out the enhanced DPA. Therefore, by the former analysis 100
times more power traces are required for a usual DPA in this case.
Remarks. Another generalized integer recoding scheme, such as the wNAF
recoding, can also be developed as a DPA countermeasure by using the multiple-
rail strategy. However, the multiple-rail wNAF may not be practical as Mr-sNAF
on a memory-limited smart card. When the number of positive digits used by
wNAF is 2w−2 [19], the number of needed registers for a scalar multiplication
will increase by a power (w − 2) of 2. Therefore, due to the limited memory
on a smart card, the DPA resistance of multiple-rail wNAF can be somewhat
bounded by the restricted amount of applicable wNAF representations.
We wish to emphasize that constant and few (precisely 3) registers are enough
for a smart card to load Mr-sNAF as a protection of scalar multiplications against
DPA, since sNAF is a universal representation with three signed digits. More-
over, the Mr-sNAF based scalar multiplications can be performed with a lower
computational complexity 1.33(n + G) + G + O(1) than 1.5n, which is usually
taken by approaches with conventional binary representations, such as Fig. 1-B.
From these two viewpoints, Mr-sNAF is much significant for being a low-cost
solution to prevent side channel attacks.
4.2 The Randomized g-sNAF Recoding
Motivated by the concept of the randomized NAF recoding scheme by Ha and
Moon [6], we intend to randomize the sNAF recoding as another DPA counter-
measure.
Notice that in each g-sNAF recoding step, di is encoded as a digit in SD,
ki+g is updated, and an auxiliary carry ci+g+1 is produced. Let (ci+g+1, ki+g, di)
denote the concatenated output in the right half part of Table 2, which presents
a partial value ci+g+1 · 2i+g+1 + ki+g · 2i+g + di · 2i of the recoded d, i.e., k.
Therefore, we can consider one case of the output (ci+g+1, ki+g, di) = (0, 0, 1)
having another representation (0, 1, s) with the same value, such that
0 · 2i+g+1 + 0 · 2i+g + 1 · 2i = 0 · 2i+g+1 + 1 · 2i+g + (−2g + 1) · 2i.
The case of (1, 0, 1) has another representation (1, 1, s), and the case of (1, 0, s)
has another representation (0, 1, 1) with the same value.
To randomize the g-sNAF recoding, we tend to use a random bit ri ∈R {0, 1}
in each recoding step as a decision factor to choose one alternative representa-
tion of (ci+g+1, ki+g, di) from above pair-wise examples. A randomized g-sNAF
recoding algorithm is given in Table 4.
2 In this case, the maximum of point operations needed is (n + 10) · 4
3
+ 10 + 1 for
g = 10, when the minimum is (n + 1) · 4
3
for g = 1. Therefore, on average 1
10
· ( 7
3
·
0 + 7
3
· 1 + . . .+ 7
3
· 9 + 2) = 10.7 additional dummy operations are needed.
The Separated Non-Adjacent Form 15
4.3 Hamming Weight Analysis of the Randomized sNAF
Representation
To simplify the Hamming weight analysis of the randomized sNAF representa-
tion, a problem reduction of the randomized sNAF recoding process is obtained
in Table 5 by using the same strategy applied in Section 3.2, transforming the
input by pre-updating ki+g with ci+g and then trying to reduce the new recod-
ing table. Table 5 shows that the distribution of di depends on both ki and a
random bit ri, and the new recoding rules can be summarized by an arithmetic
transition function T described as follows.
– If ri · ki = 0, then T encodes di as ki and updates ki+g as k′i+g and ci+g+1
as c′i+g+1.
– If ri · ki = 1, then T encodes di as s and computes the updated ki+g and
ci+g+1 from k′i+g and c
′
i+g+1 with a hidden (implicitly active in Table 4)
carry-in chi+g = ri · ki, such that 2 · ci+g+1 + ki+g = 2 · c′i+g+1 + k′i+g + chi+g.
Table 5. The reduced randomized g-sNAF recoding algorithm.
Randomized g-sNAF (g ≥ 1)
Input preUpdate T Output
ki+g ki ci+g ri ki ri k
′
i+g c
′
i+g+1 ri · ki ci+g+1 ki+g di
0 0 0 0
0
0
0 0
0
0 0
0
0 0 1 0 1 0 0 1
1 0 0 0 1 0 0 1
1 0 1 0 0 1 1 0
0 0 1 1
1
1 0 0 1
1 0 0 1 1 0 0 1
0 0 0 1 0 0 0 0
1 0 1 1 0 1 1 0
0 1 0 0
1
0
0 0 0 0
1
0 1 1 0 1 0 0 1
1 1 0 0 1 0 0 1
1 1 1 0 0 1 1 0
0 1 0 1
1
0 0
1
0 1
s
0 1 1 1 1 0 1 0
1 1 0 1 1 0 1 0
1 1 1 1 0 1 1 1
When the reduced version of the randomized g-sNAF recoding algorithm in
Table 5 can perform equally to recode randomized sNAF representations, we
intend to analyze the Hamming weight of the randomized sNAF representation
from the output distributions of Table 5.
The Separated Non-Adjacent Form 17
Proof. By Lemma 6 and 7, the distribution of the recoded di for i from zero to
(n− 1) can be separated into two independent cases. If the read ki is zero, then
di is always zero. If the read ki is one, the di is always non-zero. By Lemma 1,
these two case will happen with the same probability 12 . Therefore, the Hamming
weight density of the randomized g-sNAF representation d can be calculated
HWD(d) =
1
2 ·0+ 12 ·1
1
2 ·1+ 12 ·1
= 12 plus an ² for the front g digits out of this analysis. uunionsq
By Theorem 7, the expected Hamming weight of the randomized sNAF rep-
resentation is (n+ g) · 12 , which leads an efficient and randomized scalar multi-
plication dP with a computational complexity 32 · (n+ g)+ g+O(1) on average.
4.4 DPA-resistance Analysis of the Randomized sNAF Recoding
An observation on the intermediate value of the randomized g-sNAF represen-
tation is possible as follows.
At the end of the (i− 1)th randomized g-sNAF recoding step, we know that
all kj(s) for j from zero to (i − 1) have been recoded to dj(s) and all kl(s) for
l from i to (i + g − 1) have been updated and ci+g has been produced, when
the other km(s) for m from (i+ g) to (n− 1) have not been manipulated. Let kˆl
denotes the updated kl. Therefore, we can consider an
I = ( ˆki+g−1, . . . , kˆi)2 − (ki+g−1, . . . , ki)2 + ci+g · 2g
being a summed impact value on kl(s) and ki+g due to the 0th to (i−1)th recoding
steps. When the following recoding steps after the (i−1)th will manipulate kˆl(s)
and km(s) as well as ci+g to encode di to dn+g−1 sequentially, (implicitly by
Theorem 5) an observation on the intermediate value of the recoded d can be
shown as
(dn+g−1, . . . , di)SD
= (kn−1, . . . , ki+g)2 · 2g + ci+g · 2g + ( ˆki+g−1, . . . , kˆi)2
= (kn−1, . . . , ki+g)2 · 2g + ci+g · 2g + I + (ki+g−1, . . . , ki)2 − ci+g · 2g
= (kn−1, . . . , ki)2 + I
or as
I · 2i + (di−1, . . . , d0)SD = (ki−1, . . . , k0)2,
where I · 2i is also the value presented by the extended g (by Theorem 6) digits
when recoding (ki−1, . . . , k0)2. I is a random value in the range [0, 2g − 1].
Therefore, given (kn−1, . . . , ki+1) an attacker can guess (ki, I) as (1, 2g − 1)
or (0, 0) (the other cases are indistinguishable as like a situation reviewed in Sec-
tion 2.3) and mounts a usual DPA on the intermediate value (dn+g−1, . . . , di)SD
to derive ki. If ki is guessed correctly, the collected power traces as well as the
corresponding target intermediate values can be correctly manipulated with a
probability of I = 2g − 1 or I = 0. The probability pˆ defined in Rule 1 in this
attack A can be offered by
pˆ(A) = max{Pr(I = 2g − 1), P r(I = 0)}.
The Separated Non-Adjacent Form 19
respectively with two upper bounds. The result shows that a DPA attacker can
get a better probability pˆ(A) = ( 34 )g, if (ki, I) is guessed with (0, 0) correctly. By
Rule 1 at least ( 169 )
g times more power traces should be collected for a successful
DPA in this case.
We wish to emphasize that when the amount of required power traces in-
creases by a power g of 169 ≈ 1.78, the proposed randomized sNAF recod-
ing scheme is much superior to Mr-sNAF and the randomized NAF recoding
scheme [6, 25] from the viewpoint of security. For example, if a small g = 10 is
selected, it can persecute the attacker to collect at least 315 times more power
traces for a successful DPA.
Remarks. In the above analysis, the probabilities of I = 2g − 1 and I = 0
are estimated by taking off the impact factor of ci on I. However, when hi
is in the range [0, 2g − 1] and ci is in the range [0, 1], the impact factor of
hi on I is somewhat bigger than of ci, if g is larger than one. Therefore, the
above estimations on Pr(I = 2g − 1) and Pr(I = 0) are significant for some
g much larger than one, and only give the loose bounds for some g close to
one, e.g., specially g = 1. For the case of g = 1, we give precise calculations of
Pr(I = 21 − 1 = 1) and Pr(I = 0) in the following.
From Equation 2, given an x = i− 1 we can obtain
ci =
1
2
· (ki−1 + chi−1 − ˆki−1 + ci−1)
=
1
2
· (ki−1 + chi−1 − ˆki−1) +
1
4
· (ki−2 + chi−2 − ˆki−2 + ci−2)
=
...
=
y=i−1∑
y=g
ky · 2y−i +
y=i−1∑
y=g
chy · 2y−i −
y=i−1∑
y=g
kˆy · 2y−i + cg · 2g−i
for a digit index y from g to (i− 1). Multiplying 2i to both sides, we then have
ci · 2i = [(ki−1, . . . , kg)2 + (chi−1, . . . , chg )2 − ( ˆki−1, . . . , kˆg)2 + cg] · 2g. (3)
When cg is initially zero in the g-sNAF recoding scheme, Equation 3 means
that ci is a carry-out from summing up (ki−1, . . . , kg)2 and (chi−1, . . . , c
h
g )2, and
( ˆki−1, . . . , kˆg)2 is the remained sum.
For the case of g = 1, hi = chi is a value of ˆki−1 · ri−1. When the distribution
of the ˆki−1 will be bias under the condition of ci = 0 or ci = 1, it is how and
why hi and ci are dependent. Therefore, to precisely calculate the probabilities
Pr(I = 0) and Pr(I = 1) in this case, the distributions of ˆki−1 under the
conditions of ci = 0 and ci = 1 should be concerned.
Based on the carry look-ahead technique in [28], the ci in Equation 3 can be
presented also as
ci = gi−1 + (pi−1 · gi−2) + (pi−1 · pi−2 · gi−3) + · · ·+ (pi−1 · pi−2 · . . . · pg+1 · gg),
The Separated Non-Adjacent Form 21
Remark that sNAF is a universal representation with three signed digits.
Based on this property, Mr-sNAF is developed as a low-cost solution to pre-
vent DPA from both the viewpoints of low computational complexity and few
memory spaces required for the computation of scalar multiplications. When
the Mr-sNAF based scalar multiplication algorithm has a lower computational
complexity 1.33(n+G)+G+O(1) and owns a better DPA-resistance factor G2
of the number of required power traces, Mr-sNAF is superior to the randomized
NAF recoding scheme.
The randomized sNAF recoding scheme is a deluxe DPA countermeasure.
When the DPA-resistance of the randomized sNAF recoding scheme is bounded
by a factor ( 169 )
g of the number of required power traces, it is much stronger
than of both Mr-sNAF and the randomized NAF recoding scheme. Moreover,
when the Hamming weight of the randomized sNAF representation is proved on
average 12 · (n + g) in this paper, the computational cost for scalar multiplica-
tions with randomized sNAF representations can be asymptotically low as with
conventional binary representations if g is selected much smaller than n.
The selections on G and g can be treated as trade-offs of Mr-sNAF and of
the randomized sNAF recoding scheme between the effect to speed up scalar
multiplications and the DPA resistance.
5 Conclusions
In this paper, sNAF is proposed as a generalization of the conventional NAF.
When NAF is often applied to speed up scalar multiplications over elliptic curves,
it is shown that sNAF has the same effect for the case of 1-sNAF and has the
asymptotic effect for other cases. A recoding algorithm is proposed to generate
sNAF representations, including NAF.
To prevent DPA, Mr-sNAF is proposed as a low-cost but stronger solution
than the randomized NAF recoding scheme. Moreover, the randomized sNAF
recoding scheme is proposed as a much more superior DPA countermeasure than
both Mr-sNAF and the randomized NAF recoding scheme. A trade-off between
the effect to speed up scalar multiplications and the DPA resistance is available
on both Mr-sNAF and the randomized sNAF recoding scheme.
References
1. D. Agrawal, B. Archambeault, J. R. Rao, and P. Rohatgi, “The EM side chan-
nel(s),” The 4th International Workshop on Cryptographic Hardware and Embed-
ded Systems – CHES 2002, vol. 2523 of Lecture Notes in Computer Science, pp.
29–45, Springer-Verlag, 2003.
2. J.-S. Coron, “Resistance against differential power analysis for elliptic curve cryp-
tosystems,” The 1st International Workshop on Cryptographic Hardware and Em-
bedded Systems – CHES 1999, vol. 1717 of Lecture Notes in Computer Science, pp.
292–302, Springer-Verlag, 1999.
The Separated Non-Adjacent Form 23
19. J. A. Muir and D. R. Stinson, “Minimality and other properties of the width-w
nonadjacent form,” Mathematics of Computation, vol. 75, no. 253, pp. 369–384,
July 2005.
20. K. Okeya and K. Sakurai, “On insecurity of the side channel attack countermeasure
using addition-subtraction chains under distinguishability between addition and
doubling,” The 7th Australian Conference on Information Security and Privacy
– ACISP 2002, vol. 2384 of Lecture Notes in Computer Science, pp. 420–435,
Springer-Verlag, 2002.
21. K. Okeya and D.-G. Han, “Side channel attack on Ha-Moon’s countermeasure
of randomized signed scalar multiplication,” The 4th International Conference on
Cryptology in India – INDOCRYPT 2003, vol. 2904 of Lecture Notes in Computer
Science, pp. 334–348, Springer-Verlag, 2003.
22. K. Okeya, K. Schmidt-Samoa, C. Spahn, and T. Takagi, “Signed binary representa-
tion revisited,” The 24th Annual International Cryptology Conference – CRYPTO
2004, vol. 3152 of Lecture Notes in Computer Science, pp. 123–139, Springer-
Verlag, 2004.
23. E. Oswald and M. J. Aigner, “Randomized addition-subtraction chains as a coun-
termeasure against power attacks,” The 3rd International Workshop on Crypto-
graphic Hardware and Embedded Systems – CHES 2001, vol. 2162 of Lecture Notes
in Computer Science, pp. 39–50, Springer-Verlag, 2001.
24. G. W. Reitwiesner, “Binary arithmetic,” Advances in Computers, vol. 1, pp. 231–
308, 1960.
25. S. G. Sim, D. J. Park, and P. J. Lee, “New power analysis on the Ha-Moon algo-
rithm and MIST algorithm,” The 6th International Conference on Information and
Communications Security – ICICS 2004, vol. 3269 of Lecture Notes in Computer
Science, pp. 291–304, Springer-Verlag, 2004.
26. K. Hwang, Computer arithmetic principles, architecture and design. Reading, Wi-
ley, New York, 1979.
27. D.-G. Han, T. Izu, and T. Takagi, “Some explicit formulae of NAF and its left-to-
right analogue,” Cryptology ePrint Archive: 2005/384.
28. J. P. Hayes, Computer architecture and organization. Reading ISBN: 0-07-027355-
3, 3rd ed., Electrical and Computer Engineering, McGraw-Hill, Singapore, 1998.
A The Proof of Theorem 8
Proof. Based on the carry look-ahead technique [28], the carry bit ci in Equa-
tion 3 (initially cg = 0) can also be presented as
ci = gi−1 + (pi−1 · gi−2) + (pi−1 · pi−2 · gi−3) + · · ·+ (pi−1 · pi−2 · . . . · pg+1 · gg),
where gy = ky · chy means a cy+1 = 1 independent of cy can be generated if both
ky and chy are ones, and py = ky ⊕ chy means a cy+1 = 1 propagates another
cy = 1 if one of ky and chy is one for y from g to (i− 1).
Let c˜i = ¬ci denote the inverse ci. Based on the carry look-ahead technique
c˜i can be presented as
c˜i = zi−1 + (pi−1 · zi−2) + (pi−1 · pi−2 · zi−3) + · · ·+ (pi−1 · pi−2 · . . . · pg+1 · zg)+
(pi−1 · pi−2 · . . . · pg+1 · pg),
where zy = (¬ky) · (¬chy) means a cy+1 = 0 independent of cy can be generated
if both ky and chy are zeros for y from g to (i− 1).
The Separated Non-Adjacent Form 25
– if zi−1 = 1:
This case happens with a probability Pr(zi−1 = 1) = 38 . And this case means
that a zero ci independent of ci−1 is generated when both ki−1 and chi−1 are
zeros. Therefore, the (remainder) ˆki−1 is the value of ci−1 and has a random
distribution in {0, 1} with probabilities {34 , 14} by Lemma 8.
– if (
∏w=i−1
w=v+1 pw · zv) = 1:
This generalized case happens with a probability
Pr(
w=i−1∏
w=v+1
pq · zv = 1) = (12)
i−v−1 · 3
8
for v from one to (i − 2). This generalized case means that a zero ci is
generated from no carry propagation of cv+1, which is independent of cv
when both kv and chv are zeros. Therefore, the remainder bit ˆki−1 is fixed to
pi−1 = 1 in this case.
– if (
∏y=i−1
y=1 py) = 1:
This special case happens with a probability
Pr(
y=i−1∏
y=1
py = 1) = (
1
2
)i−1.
This case indicates a zero ci is generated when a value (2i−1−1) is obtained
from summing up (ki−1, . . . , k1)2 and (chi−1, . . . , c
h
1 )2. The ˆki−1 is fixed to
one in this case.
The calculation of the probability Pr(hi = 1, ci = 0). Due to the T func-
tion, we have chi−1 = ˆki−1 · ri−1. When g = 1 is assumed, we have hi = chi .
Based on the above derived distributions of ˆki−1 under the condition of c˜i = 1,
the probability Pr(hi = 1) under each independent case generating ci = 0 is
computed as follows.
– if zi−1 = 1:
In this case, ˆki−1 has a random distribution in {0, 1} with probabilities
{34 , 14}. Therefore, the probability Pr(hi = 1) under this condition can be
computed
Pr(hi = 1|zi−1 = 1) = 14 ·
1
2
=
1
8
for the case of ( ˆki−1, ri−1) being (1, 1).
– if (
∏w=i−1
w=v+1 pw · zv) = 1:
In this case, ˆki−1 is always one. Therefore, the probability Pr(hi = 1) under
this condition can be computed
Pr(hi = 1|
w=i−1∏
w=v+1
pw · zv = 1) = 1 · 12 =
1
2
for the case of ( ˆki−1, ri−1) being (1, 1).
The Separated Non-Adjacent Form 27
– if (
∏y=i−1
y=g(=1) py) = 1:
In this case, ˆki−1 is always one. Therefore, the probability Pr(hi = 0) under
this condition can be computed
Pr(hi = 0|
y=i−1∏
y=1
py = 1) = 1 · 12 =
1
2
for the case of ( ˆki−1, ri−1) being (1, 0).
Based on the above derived results, the probability Pr(hi = 0, ci = 0) can
be calculated from summing up the probabilities Pr(hi = 0) due to independent
cases:
Pr(hi = 0, ci = 0)
= Pr(hi = 0|zi−1 = 1) · Pr(zi−1 = 1)
+
v=i−2∑
v=1
Pr(hi = 0|
w=i−1∏
w=v+1
pw · zv = 1) · Pr(
w=i−1∏
w=v+1
pw · zv = 1)
+Pr(hi = 0|
y=i−1∏
y=g
py = 1) · Pr(
y=i−1∏
y=g
py = 1)
=
7
8
· 3
8
+
v=i−2∑
v=1
(
1
2
· (1
2
)i−v−1 · 3
8
) +
1
2
· (1
2
)i−1
=
21
64
+
3
16
·
t=i−2∑
t=1
(
1
2
)t + (
1
2
)i ≈ 21
64
+
3
16
· 1 + 0 = 33
64
approximately for a large i.
The calculation of the probability Pr(hi = 0, ci = 1). Notice that the terms
in the right side of the carry look-ahead equation of ci denote independent cases
to generate a carry ci = 1. Therefore, the probability Pr(hi = 0, ci = 1) can be
calculated from summing up probabilities of hi = 0 due to independent cases.
However, as aforementioned in Section 4.4, I(= hi + ci) has a random dis-
tribution in {0, 1} for g = 1. Therefore, the probability of hi = 0 under each
independent case generating ci = 1 is fixed to one (or say the probability of
hi = 1 is zero in these cases), and then the probability Pr(hi = 0, ci = 1) can
be calculated as follows.
Pr(hi = 0, ci = 1)
= Pr(hi = 0|gi−1 = 1) · Pr(gi−1 = 1)
+
v=i−2∑
v=1
Pr(hi = 0|
w=i−1∏
w=v+1
pw · gv = 1) · Pr(
w=i−1∏
w=v+1
pw · gv = 1)
Memory Efficient Multi-Exponentiation
Algorithm Based on Binary GCD Algorithm
Sung-Ming Yen1, Chien-Ning Chen1, and SangJae Moon2
1 Laboratory of Cryptography and Information Security (LCIS)
Dept of Computer Science and Information Engineering
National Central University, Chung-Li, Taiwan 320, R.O.C.
E-mail: {yensm;ning}@csie.ncu.edu.tw
http://www.csie.ncu.edu.tw/~yensm/
2 School of Electronic and Electrical Engineering
Kyungpook National University
Taegu, Korea 702-701
E-mail: sjmoon@ee.knu.ac.kr
Abstract. In this paper, a series of new algorithms for evaluation of
multi-exponentiation, e.g., XaY b, is proposed based on the binary great-
est common divisor algorithm. The multi-exponentiation computation
becomes particularly important for implementation of many public-key
cryptographic schemes. However, till now, existing research results on
speeding up multi-exponentiation usually require a lookup table, and
some of them require inversion computations as well. The algorithms pro-
posed in this paper are simple for implementation, space efficient, and
inversion free. For double-exponentiation with 1024-bit exponents, the
proposed algorithm only requires 1566 multiplications (includes squar-
ings) on average, and it needs less amount of memory space than existing
methods with compatible performance. The proposed algorithms can be
very useful for the implementation of many public-key cryptosystems on
small devices with limited memory space, e.g., smart cards.
Keywords: Binary GCD algorithm, Euclidean algorithm, Exponentiation,
Greatest common divisor, Multi-exponentiation, Public-key cryptography, Side-
channel attack.
1 Introduction
Exponentiation evaluation is one of the most important computational primitives
for implementing modern public-key cryptography, e.g., RSA [6] and ElGamal [8]
systems. For security reasons, public-key cryptosystems always use very large
system parameters and this will slow down the performance. Therefore, the
design of high speed exponentiation algorithms becomes highly demanded.
Many research results on exponentiation algorithms can be found in the
literature, and these algorithms can be classified into two categories. The first
Title Suppressed Due to Excessive Length 3
Section 5 will discuss the immunity of the proposed algorithms against the side-
channel attacks. Finally, Section 6 concludes this paper.
2 Preliminary Background
2.1 Euclidean algorithm
The Euclidean algorithm is a well-known method to compute the greatest com-
mon divisor based on the following two facts:
1. gcd(a, b) = gcd(a− b, b) = gcd(a, b− a), as well as
2. gcd(a, 0) = gcd(0, a) = a.
The Euclidean algorithm computes the greatest common divisor by performing
gcd(a, b) = gcd(b, a mod b) recursively, and in each step this algorithm requires
a division (modular operation) to find the remainder. The reader can refer to
[1, 5] for the average computational complexity which takes about 0.584 lg n (=
0.843 lnn) rounds of division operations when a and b are independent and
uniformly distributed over [0, n]. The intermediate results will form a decreasing
series of integers, starting from s0 = a, s1 = b (let a ≥ b), si+1 = si−1 mod si,
and ending at sE = gcd(a, b). In this paper, we call this series the Euclidean
chain or the Euclidean series.
2.2 Binary GCD algorithm
When computing the greatest common divisor of multi-precision integers (long
integers) by the Euclidean algorithm, it requires multi-precision division and
which might be more difficult than the basic subtraction operation to implement
for most processors. An alternative method for finding the greatest common
divisor is the binary GCD algorithm [4] (or refer to [1, p.338]) which requires only
right shifting bit operation (i.e., divided by 2) and multi-precision subtraction.
The binary GCD algorithm is designed based on the following three facts:
1. gcd(a, b) = gcd(a− b, b), when a ≥ b;
2. gcd(a, b) = 2 gcd(a/2, b/2), when both a and b are even;
3. gcd(a, b) = gcd(a/2, b), when a is even and b is odd.
Comparing to multi-precision division in the ordinary Euclidean algorithm, right
shifting and multi-precision subtraction in the binary GCD algorithm are much
easier to implement for most processors.
Figure 1 shows the binary GCD algorithm which computes the greatest com-
mon divisor of two positive integers a and b. Lines 3–4 of this algorithm imple-
ment the second fact in the previous paragraph, and at most one of s and t will
be even in the main loop (lines 5–13). Lines 6–9 implement the third fact, and
lines 10–13 implement the first fact. Since at least one of the parameters s and t
will be decreasing in each round of the main loop, this algorithm will eventually
quit the main loop with s = 0 (because of the condition set in line 10) and t
Title Suppressed Due to Excessive Length 5
INPUT: g, q, a = (an−1 · · · a0)2 and b = (bn−1 · · · b0)2
OUTPUT: gaqb
01 R0,0 = 1, R1,0 = g, R0,1 = q, R1,1 = g × q
02 for i = n− 1 to 0 step −1
03 R0,0 = R0,0
2
04 if (ai, bi) 6= (0, 0) then R0,0 = R0,0 ×Rai,bi
05 return R0,0
Fig. 2. Simultaneous double-exponentiation algorithm.
Sliding window techniques [1, 9] can further reduce the number of multipli-
cations required in an exponentiation, but applications in multi-exponentiation
encounter the difficulty of the expense of considerably more memory space for the
lookup table. For k-dimensional multi-exponentiation withm-bit sliding window,
it requires a lookup table of O(2mk) elements and which becomes impractical
for small devices with limited memory space. For example, computing gaqb by
the 2-bit sliding window method requires to precompute and store all elements
of the form gAqB such that 0 ≤ A,B < 22 and at least one of A and B is odd.
This leads the result to store 12 precomputed values of g, q, gq, gq2, gq3, g2q,
g2q3, g3, g3q, g3q2, g3q3, and q3.
Recoding the exponent to a signed digit representation is another approach
to reduce the number of multiplications. The Non-Adjacent Form (NAF) re-
coding [2] or its left-to-right recoding analogue [21] can decrease the average
Hamming weight of the n-bit exponent from 12n to
1
3n. When evaluating double-
exponentiation, recoding the exponents a and b individually to NAF can achieve
the average joint Hamming weight (i.e., the total number of corresponding bits
of either a or b being non-zero) of 59n. The Joint Sparse Form (JSF) method
[22] recodes a and b to signed digit representation simultaneously and lowers the
average joint Hamming weight to 12n. However, evaluating multi-exponentiation
with signed digit recoded exponents requires a large lookup table, and the multi-
plicative inverse of all the base numbers are required as well when preparing the
table. For example, evaluating gaqb with signed digit recoded exponents a and b
by the algorithm in Fig. 2 requires preparing additional six values, R−1,0 = g−1,
R0,−1 = q−1, R1,1 = gq, R−1,−1 = g−1q−1, R1,−1 = gq−1, and R−1,1 = g−1q. In
k-dimensional multi-exponentiation, the lookup table will contain 3k − 1 combi-
nations of ga11 · · · gakk with a1, . . . , ak ∈ {−1, 0, 1} and not all ai = 0.
Most existing multi-exponentiation algorithms are designed based on simul-
taneous squaring combining with sliding window techniques and/or signed digit
recoding. Those algorithms require preparing a lookup table and are impracti-
cal for higher dimensional multi-exponentiation. If the base numbers of multi-
exponentiation are variable, the computational cost of preparing the table is also
non-negligible.
Title Suppressed Due to Excessive Length 7
where X ′ = Xf can be obtained without any additional computational cost
during the evaluation of Xq.
06.01 AUX = Rt
06.02 if (q is odd) then R1−t = R1−t ×AUX
06.03 while (q ≥ 2)
06.04 q = q/2, AUX = AUX2
06.05 if (st is even) then st = st/2, Rt = AUX
06.06 if (q is odd) then R1−t = R1−t ×AUX
Fig. 4. Implementation detail of line 6 in Figure 3
Both of the algorithm and its improved version require six variables. Three
variables, s0, s1, q are used to manipulate the GCD evaluation on exponents.
Two variables are used to load the two base numbers and to handle the ex-
ponentiation operations. The last one is an auxiliary variable for the small ex-
ponentiation Rtq in line 6 of Fig. 3. The detailed implementation of the small
exponentiation is given in Fig. 4. Line 06.05 is the modification for the improved
algorithm, and the fundamental algorithm can be obtained by removing this line.
The computational complexity is retrieved by simulation experiments. When
evaluating double-exponentiation with two 1024-bit exponents, the fundamental
version and its improvement respectively require 1647 and 1619 multiplications
(includes squarings) on average.
3 The Proposed Binary GCD Multi-exponentiation
Algorithm
Similar to the Euclidean double-exponentiation algorithm, we can develop the
binary GCD double-exponentiation algorithm based on the computational se-
quence of the binary GCD algorithm. Support that both s and t are positive
integers and the double-exponentiation xsyt will be computed. When the binary
GCD algorithm updates exponents s and t to calculate gcd(s, t), the base num-
bers are updated simultaneously to keep the value xsyt invariant. The quadruple
parameters (two exponents and two base numbers) can be updated by
(si+1, ti+1, xi+1, yi+1) =

(si − ti, ti, xi, xiyi)
(si, ti − si, xiyi, yi)
(si/2, ti, xi2, yi)
(si, ti/2, xi, yi2)
,
where si, ti, xi, yi are intermediate values in the i-th iteration. Refer to the
binary GCD algorithm in Fig. 1, the binary GCD double-exponentiation are
developed and presented in Fig. 5.
Title Suppressed Due to Excessive Length 9
On the contrary, the multiplication of base numbers coming with the subtrac-
tion of exponents has various performance which depends on the ratio of two
exponents, s/t. When two exponents satisfy s ≈ t, this multiplication has bet-
ter performance on reducing the bit length of the minuend exponent, but when
sÀ t or s¿ t, it contributes almost nothing.
In the first proposed binary GCD double-exponentiation algorithm, multipli-
cation only occurs when both exponents are odd integers. If rearranging the order
of operations such that multiplication always occurs when s ≈ t, the modified
algorithm may have better performance but does not require any extra memory
space. In our simulations, whether s ≈ t is specified by whether the difference
in length between two exponents is less than (or equal to) 1 bit. The modified
algorithm requires 1.73 lg a multiplications (includes squarings) on average when
initial two exponents a and b are of the same length.
However, some worse situations still occur in the first improvement (only
rearranging the order of operations). Without loss of generality, we assume two
intermediate exponents s ≥ t. When s À t and t is an even integer, t will be
divided by 2 in the first improvement, but this operation increases the ratio
s/t. One or more squarings (coming with dividing t by 2) will occur until t/2i
is an odd integer. In this situation, our simulations show that subtracting 1
from the odd exponent s and dividing s− 1 by 2 will be a better solution than
dividing t by 2. This modification requires an additional variable R2, and the new
algorithm will maintain the property xsytR2 = gaqb. When subtracting 1 from
s, a multiplication R2 = R2 × x occurs simultaneously, and xs−1yt(R2 × x) =
xsytR2 = gaqb holds.
Similar to windowing technique, additional memory space can further im-
prove the performance. In the above paragraph, the last significant bit of s is
cleared by subtracting 1 from s. Here, we remove the last two significant bits of
s by subtracting 1 or 3 from it. This leads to the requirement of the second extra
variable R3, and the equation xsyt × R2 × R33 = gaqb always holds. Figure 6
presents this new algorithm, in which we use the intermediate parameters of ex-
ponents s0 and s1 instead of s and t in previous algorithms. The algorithm with
only one extra variable (described in the previous paragraph) can be retrieved
by removing the variable R3 and line 7.
This new algorithm has fairly good performance. Our simulation tells that
it requires 1566 multiplications (includes squarings) on average when evaluating
1024-bit double-exponentiation, that is, its average complexity is about 1.53n
for n-bit exponents. It only requires four variables for base numbers and two
variables for exponents, which is the same as Shamir’s method in Fig. 2. In
addition, employing the third additional variable when st mod 8 = 7 can further
lower the average complexity to 1.496n.
3.2 Analogy between the conventional single-exponentiation
algorithm and the proposed algorithm
Our double-exponentiation algorithms can reduce to the binary right-to-left
single-exponentiation algorithm. The single-exponentiation ga can be extended
Title Suppressed Due to Excessive Length 11
INPUT: bases g1, · · · , gk, exponents a1, · · · , ak.
OUTPUT: multi-exponentiation
∏k
i=1
(gaii ).
01 s1 = a1, s2 = a2, · · ·, sk = ak
02 R1 = g1, R2 = g2, · · ·, Rk = gk
03 (t1, t2) = L2(s1, s2, · · ·, sk)
04 while (st2 > 0)
05 if (length(st1) − length(st2) < 2) then
06 st1 = st1 − st2, Rt2 = Rt2 ×Rt1
07 elseif (st1 is even) then
08 st1 = st1/2, Rt1 = Rt1
2
09 else
10 t3 = L2O(s1, s2, · · ·, sk)
11 if (t3 = null) then
12 st2 = st2/2, Rt2 = Rt2
2
13 else
14 st1 = st1 − st3, Rt3 = Rt3 ×Rt1
15 (t1, t2) = L2(s1, s2, · · ·, sk)
16 return Rt1
st1
Fig. 7. Multi-exponentiation algorithm based on improved binary GCD algorithm
in Sec. 3.1 is equivalent to evaluating the triple-exponentiation gaqb11. This
observation motivates that converting k-dimensional multi-exponentiation to a
(k + 1)-dimensional one by attaching the trivial term 11 might improve the
performance. In addition, since the function L2O() always finds an odd exponent
when the term 11 is attached, the conditional jump in line 11 of Fig. 7 as well
as lines 12–13 can be omitted to simplify the algorithm.
4 Performance Comparison
This section summarizes the performance of the proposed double-exponentiation
algorithms and compares them with the Euclidean double-exponentiation algo-
rithm as well as algorithms based on Shamir’s simultaneous squaring method.
The proposed algorithms are the binary GCD double-exponentiation algorithm
and its three improvements (in Sec. 3.1). The Euclidean double-exponentiation
algorithm and its improvement are reviewed in Sec. 2.4. Three algorithms based
on Shamir’s simultaneous squaring method (shown in Fig. 2) are also compared,
and of which the exponents are recoded to binary (unrecoded), NAF, and JSF
respectively.
Time and space complexity comparisons are summarizes in Table 1. The per-
formance of the proposed algorithms is obtained by 106 simulations of 1024-bit
double-exponentiation with randomly generated exponents. The time complexity
(Comp.) is the number of operations (Sum) divided by the bit length of exponents.
Table 1 also provides the space requirements. In the proposed algorithms and
the Euclidean double-exponentiation algorithm, the input (initial) values of base
Title Suppressed Due to Excessive Length 13
significantly lower, and the attached term 11 can help to avoid the worse situ-
ation (the largest exponent is the only odd one). The lower half of Table 2 is
the simulation results of various length multi-exponentiation. It shows that the
proposed algorithm has stable performance for various length of exponents.
Table 2. Time complexity of multi-exponentiation evaluated by algorithm 3.3
Dimension Avg. # of Operations Complexity
(# of Terms) Length Square Mul. Sum Sum/Leng. Comp./Term
2 1024 725.0 1047.4 1772.4 1.7308 0.8654
∗2 1024 502.9 1107.3 1610.3 1.5725 0.7863
5 1024 119.4 2102.3 2221.7 2.1697 0.4339
∗5 1024 111.9 2103.0 2214.9 2.1630 0.4326
10 1024 20.9 3300.6 3321.4 3.2436 0.3244
∗10 1024 20.8 3301.1 3321.9 3.2440 0.3244
100 1024 3.0 18465.8 18468.7 18.0359 0.1804
1000 1024 5.7 123843.0 123848.7 120.9460 0.1209
10 160 4.0 519.1 523.1 3.2691 0.3269
10 512 11.0 1652.4 1663.3 3.2487 0.3249
10 2048 40.7 6596.4 6637.1 3.2408 0.3241
100 160 2.9 2908.8 2911.7 18.1979 0.1820
100 512 3.0 9247.3 9250.2 18.0669 0.1807
100 2048 2.9 36902.6 36905.6 18.0203 0.1802
We compare the proposed algorithm with existing high-dimensional multi-
exponentiation algorithms. Most of those algorithms require lookup table, and
Lim-Lee’s precomputation technique [12] is the most famous one. Algorithms re-
quiring lookup table have better performance when evaluating multi-exponentiation
with longer exponents. BGMW method [11] is another category, and it uses a
particular computational sequence to remove the requirement of lookup table.
BGMWmethod has better performance for higher dimensional multi-exponentiation.
Comparing to existing methods [20], the proposed algorithm achieves good per-
formance in all conditions (various length of exponents and various dimension).
System designers can use the proposed algorithm to fulfill all requirements of
exponentiation computation.
5 Countermeasure Against Side-Channel Analysis
Side-channel analysis (SCA) is a new threat to the implementation of cryptosys-
tems. A real implemented cryptosystem always leaks information related to its
internal operations and states through various channels, e.g., execution time [15],
power consumption [17, 19], and electromagnetic radiation [23]. The attacker can
Title Suppressed Due to Excessive Length 15
y, the expected values f(xi, y) will respectively appear in each computation, and
he can confirm the appearance by DPA.
When analyzing conventional exponentiation algorithms by DPA, the at-
tacker randomly generates base numbers g1, g2, . . . and collects the power con-
sumption traces when evaluating g1E , g2E , . . . . If these exponentiations are eval-
uated by the binary square-and-multiply exponentiation algorithm, the interme-
diate values gs(en−1···ei+1ei) will appear in each computation respectively. When
the attacker already retrieves most significant bits of the exponent (en−1 ∼ ei+1),
he can calculate the values gs(en−1···ei+11) = gs2(en−1···ei+1)×gs and test whether
these values appear in each computation by DPA. If these values appear, the bit
ei is 1.
Existing countermeasures against DPA are usually developed by employing
random variables to prevent the attacker from forecasting intermediate values.
The intermediate values f() will not only depend on known variables and un-
known constants but also depend on some unpredictable random variables. The
proposed algorithms can be converted to a DPA countermeasure by attaching a
trivial term 1r to the original exponentiation. The exponent r in the attached
term is randomly generated before each computation and is of the same bit
length as the largest exponent of the original exponentiation. The intermedi-
ate values become unpredictable because the attached term 1r will alter the
computational sequence. Blinding the intermediate values [15, 18] is another ap-
proach to prevent DPA. The intermediate values in the proposed algorithms can
be blinded by attaching rφ to the original exponentiation where r is a random
number and φ is the order of the multiplicative group. The intermediate values
of base numbers will become unpredictable because r is unknown to the attack.
The attached term 1r or rφ will only slightly influence the performance.
The single exponentiation ga will be extended to ga1r11 or garφ11. Evaluat-
ing these ∗2-dimensional multi-exponentiation by the proposed algorithm in
Sec. 3.3 requires 1.5725n multiplications (includes squarings) where n is the
length of exponents. The computational complexity is slightly higher than the
complexity 1.5n (evaluating ga by the binary square-and-multiply algorithm).
Furthermore, double-exponentiation will be extended to a ∗3-dimensional multi-
exponentiation which requires 1.7461n multiplications.
6 Conclusions
A series of multi-exponentiation algorithms are proposed in this paper. Com-
paring to other existing methods, the proposed algorithms have the advantages
of good performance and memory efficiency. In addition, they are inversion free
and can be employed in most groups. The proposed algorithms are also suitable
to develop the side-channel countermeasure – the randomized exponentiation
algorithm for single- or multi-exponentiation. System designers can fulfill all
requirements of single-exponentiation, multi-exponentiation, and side-channel
countermeasures by a single algorithm proposed in this paper.
Title Suppressed Due to Excessive Length 17
19. Paul C. Kocher, Joshua Jaffe and Benjamin Jun, “Differential power analysis,”
Advances in Cryptology – CRYPTO ’99, LNCS 1666, pp. 388–397, Springer-Verlag,
1999.
20. Chae Hoon Lim, “Efficient multi-exponentiation and application to batch verifi-
cation of digital signatures,” unpublished manuscript, August 2000. Available at
http://dasan.sejong.ac.kr/~chlim/pub/multi exp.ps
21. Marc Joye and Sung-Ming Yen, “Optimal left-to-right binary signed-digit recod-
ing,” IEEE Trans. on Computers, vol. 49, no. 7, pp. 740–748, 2000.
22. Jerome A. Solinas, “Low-weight binary representations for pairs of integers,”
Combinatorics and Optimization Research Report CORR 2001-41, Centre for
Applied Cryptographic Research, University of Waterloo, 2001. Available at
http://www.cacr.math.uwaterloo.ca/techreports/2001/corr2001-41.ps
23. Dakshi Agrawal, Bruce Archambeault, Josyula R. Rao, and Pankaj Rohatgi, “The
EM Side-Channel(s),” Cryptographic Hardware and Embedded Systems – CHES
2002, LNCS 2523, pp.29–45, Springer-Verlag, 2003.
2 Sung-Ming Yen and Chien-Ning Chen
evaluating high dimension multi-exponentiation. In this paper, we propose a
multi-exponentiation which is not based on simultaneous squaring but is devel-
oped based on the concept of finding the greatest common divisor of exponents.
Comparing with the existing methods, our algorithm has better performance
and is memory efficient when evaluating high dimension multi-exponentiation.
The rest of this paper is organized as follows. Lim-Lee’s algorithm and
BGMW method are reviewed in Sec. 2, and our new multi-exponentiation al-
gorithm based on the GCD computation is presented in Sec. 3. Comparison of
those three algorithms is given in Sec. 4, and the application of batch verification
is discussed in Sec. 5. Section 6 concludes this paper.
2 Multi-Exponentiation Algorithm
The naive method to evaluate multi-exponentiation g1s1g2s2 · · · gksk is to com-
pute each exponentiation gisi respectively and then multiply those individual
results together. In 1985, Shamir [3] pointed out that squaring operations in
each individual exponentiation can be merged when evaluating those single-
exponentiation by the left-to-right exponentiation algorithm. This is the ba-
sic concept of most multi-exponentiation algorithms. Figure 1 is the sketch of
Shamir’s simultaneous squaring method.
INPUT: base numbers g1 ∼ gk,
exponents s1 ∼ sk where sj = (sj,n−1 · · · sj,0).
OUTPUT: g1
s1 × . . .× gksk.
01 R = 1
02 for i = n− 1 to 0 step −1
03 R = R2
04 R = R× (g1s1,i × · · · × gksk,i)
05 return R
Fig. 1. Simultaneous Squaring Multi-Exponentiation Algorithm
In Shamir’s method and succeeding algorithms, the number of squaring oper-
ations is equal to the binary bit length of exponents. The only difference between
those algorithms is how they handle those multiplications in line 04 of Fig. 1. The
most straightforward method is to perform each multiplication separately, and it
requires 0.5nk multiplications in average for k-dimension multi-exponentiation
with n-bit exponents. Preparing a pre-computation table containing multiplica-
tive combinations of base numbers, e.g., g1× g2, g1× g2× g3, . . . , will lower the
number of multiplication, but it also causes additional memory requirements.
In addition, if base numbers vary, the pre-computation table should be rebuilt,
and constructing the table requires the same number of multiplications as the
number of table entries.
4 Sung-Ming Yen and Chien-Ning Chen
(gx1)s1 × · · · × (gxk)sk where a = s1x1 + · · · + skxk and those base numbers
gi = gxi are pre-computed and stored. The multi-exponentiation is evaluated
by the simultaneous squaring algorithm with w-bit window. Original window
method requires a pre-computation table consisting of gi2 ∼ gi(2w−1) for each
base number gi. BGMW method employs a special computational sequence to
remove the requirement of the pre-computation table. For example, g1 × g22 ×
g3
2 × g43 will be re-organized into g4 × (g4g3g2)× (g4g3g2g1). When evaluating
the k-dimension multi-exponentiation, computing the values in the parentheses
requires k − 1 multiplications, and computing the product of those parentheses
requires h− 1 multiplications if the largest exponent is h.
INPUT: base numbers g1 ∼ gk,
exponents s1 ∼ sk where sj = (sj,n−1 · · · sj,0),
window size ws.
OUTPUT: g1
s1 × . . .× gksk.
01 R0 = 1, t = n, w = ws
02 while (t > 0)
03 R1 = 1
04 for i = 2w − 1 to 1 step −1
05 for j = 1 to k step 1
06 if ((sj,t−1 · · · sj,t−w) = i) then R1 = R1 × gj
07 R0 = R0 ×R1
08 t = t− w
09 if (t < w) then w = t
10 R0 = R0
2w
11 return R0
Fig. 2. Simultaneous Squaring Algorithm with BGMW method
Figure 2 is the sketch of BGMW method. Lines 04 to 07 represent the tech-
nique to compute the small multi-exponentiation in each w-bit window. Since the
partial exponents in each w-bit window are nonzero with probability (1 − 12w ),
each window requires (1− 12w )k + 2w − 2 multiplications in average. The whole
algorithm requires (n− w) squaring operations and averagely
CBGMW(k, n, w) =
(
(1− 1
2w
)k + 2w − 2
)
(d n
w
e−1)+
(
(1− 1
2w′
)k + 2w
′ − 2
)
−1
multiplications where w′ is the size of the last window and is equal to or less
than w.
The optimal window size is mainly decided by the dimension of the multi-
exponentiation. In addition, it also slightly influenced by the length of exponents,
because BGMW method has better performance when the length of exponents
is a multiple of the window size.
6 Sung-Ming Yen and Chien-Ning Chen
only odd number), null will be returned. When actually implementing, scanning
all exponents is inefficient in multi-exponentiation with extremely high dimen-
sion. We can improve those two functions by maintaining a linking list sorted
by their values or lengths.
In each iteration (the main loop in lines 05 to 15 of Fig. 3), this algorithm
firstly tests whether the largest two exponents have similar length or not. When
they are of similar length, the operation in line 6 will have better performance
on reducing the minuend (the largest exponent). If the largest exponent is far
larger than all other exponents, and it is an even number, dividing it by 2 still
stably reduces its length. When the largest two exponents are not of similar
length, and the largest exponent is an odd number, this algorithm will fall into
worse states. Subtracting other odd exponent from the largest exponent will
convert the largest exponent into an even number. If the largest exponent is the
only odd exponent, it divides the second largest exponent by two. The overall
performance can be improved by more complex rules, but it will require a more
complex algorithm and may also cause higher memory requirement.
This algorithm lowers the value of one exponent and updates the correspond-
ing base number in each iteration. This algorithm will finally exit the main loop
with st2 = · · · = stk = 0, and the result of the multi-exponentiation will be
retrieved by evaluating the single-exponentiation Rt1
st1 if st1 is greater than 1.
In most cases, st1 is equal to 1 when exiting the main loop because the greatest
common divisor of all exponents is usually equal to 1.
It is hard to predict the actual (or expected average) number of the iterations
which is equal to the total number of multiplication and squaring operations.
Even a single bit flip in one exponent will affect other exponents after few itera-
tions and cause huge variations of the computational sequence in our algorithm.
Contrarily, in the simultaneous squaring algorithm, bit flips only cause local
variations, and the actual number of operations can be calculated by simply
scanning all exponents.
We analyze the performance of our algorithm by actually simulating on lots
of randomly generating samples. The simulation results show that the largest two
exponents are of similar length (satisfying the condition of line 5 in Fig. 3) with
high probability, and the probability approaches 1 when the dimension increases.
When evaluating 5-dimension 512-bit multi-exponentiation, the probability is
equal to 0.91. When evaluating 10-dimension 512-bit multi-exponentiation, the
probability is greater than 0.98. Figure 4 sketches the relationship between the
largest and the second largest exponents while evaluating the 512-bit multi-
exponentiation with various dimensions. The logarithmic-scale x-axis indicates
the ratio of the two exponents, st1/st2 , and the y-axis indicates the distribution.
Conjecture 1. The performance of the proposed algorithm grows linearly while
the dimension grows exponentially.
Because the largest two exponents are of similar length with high probability,
the performance almost depends on how many bits will be removed from the
largest exponent by the operation in line 6 of Fig. 3. The decrease of st1 is about
8 Sung-Ming Yen and Chien-Ning Chen
as well as 10, 20, . . . , 100, 200, . . . , 1000, 2000, . . . , 10000 terms respectively. De-
tailed simulation results are provided in Sec. A. In addition, because Lim-Lee’s
algorithm and BGMW method have explicit formulas of performance evalua-
tions, we also calculate their expected computational complexity and compare
with the simulation results.
0
0.1
0.2
0.3
0.4
1 10 100 1000 10000
Lim-Lee 160 bits
Lim-Lee 160 bits simulation
Lim-Lee 512 bits
Lim-Lee 512 bits simulation
Lim-Lee 1024 bits
Lim-Lee 1024 bits simulation
BGMW 160 bits
BGMW 160 bits simulation
BGMW 512 bits
BGMW 512 bits simulation
BGMW 1024 bits
BGMW 1024 bits simulation
GCD 160 bits simulation
GCD 512 bits simulation
GCD 1024 bits simulation
Dimension
Complexity
Fig. 5. The Time Complexity of Three Algorithms
Figure 5 illustrates both the expected complexity and the simulation results
for various dimensions. The logarithmic-scale x-axis indicates the dimension of
multi-exponentiation, and the y-axis indicates the complexity which is equal to
the amount of multiplications divided by both the length and the dimension. We
use δ = 0.8 as the squaring to multiplication performance ratio when computing
the complexity. The lines in the figure represent the complexity evaluated from
the expected performance formulas, and the dots around the lines represent the
simulation results. The simulation results of our algorithm are also connected by
straight lines for readability, although we still cannot find and prove the explicit
formula.
The figure clearly shows that the performance of Lim-Lee’s algorithm de-
pends on the length of the exponents. Its complexity will approach a fixed value
when the dimension increases. Referring to the performance formula, Lim-Lee’s
algorithm expectantly requires CpreLL (k,w) + C
exp
LL (k, n, w) multiplications and
(n− 1) squaring operations, and its average complexity will approach
(CpreLL (k,w) + C
exp
LL (k, n, w) + δ × (n− 1)) /nk ≈
1
w
(
2w − w − 1
n
+ 1− 1
2w
)
10 Sung-Ming Yen and Chien-Ning Chen
the base number yi (yi = y for all i) can be merged into a single exponentiation
y
∑
ciri , and this will also improve the performance.
When verifying K ElGamal signatures by batch verification, the verifier need
to perform the (K + 2)-dimension or (2K + 1)-dimension multi-exponentiation
for single or multi signers scenario respectively. It is difficult to evaluate the
multi-exponentiation in the batch verification of a great amount of signatures by
algorithms based on pre-computation because the pre-computation table requires
a huge amount of memory and is not reusable because base numbers ri (and yi in
multi signers scenario) vary between each computation. Only algorithms without
pre-computation are considerable.
Our multi-exponentiation algorithm can fulfill the requirement in batch veri-
fication because it has good performance and does not need the pre-computation
table.
6 Conclusions
This paper presents a multi-exponentiation based on the computation of finding
the greatest common divisor of exponents. We estimation its performance by
huge amount of simulations. The proposed algorithm is memory efficient and
has good or even better performance when comparing with existing algorithms.
References
1. Donald E. Knuth, The Art of Computer Programming, Volume 2, Third Edition,
Addison Wesley, 1998, Chapters 4.5.2 and 4.5.3.
2. J. Stein, “Computational problems associated with Racah algebra,” Journal of
Computational Physics, vol.1, issue 3, pp.397–405, Elsevier, 1967.
3. T. ElGamal, “A public key cryptosystem and a signature scheme based on discrete
logarithms,” IEEE Transactions on Information Theory, vol.31, no.4, pp.469–472,
July 1985.
4. Jurjen Bos and Matthijs Coster, “Addition Chain Heuristics,” Advances in Cryp-
tology - Crypto 8´9, LNCS 435, pp.400–407, Springer-Verlag, 1989.
5. E.F. Brickell, D.M. Gordon, K.S. McCurley, and D. Wilson, “Fast exponentia-
tion with precomputation,” Advances in Cryptology - EUROCRYPT9´2, LNCS 658,
pp.200–207, Springer-Verlag, 1993.
6. C.H. Lim and P.J. Lee, “More flexible exponentiation with precomputation,” Ad-
vances in Cryptology - CRYPTO9´4, LNCS 839, pp.95–107, Springer-Verlag, 1994.
7. S.M. Yen, C.S. Laih, and A.K. Lenstra, “Multi-Exponentiation,” IEE Proceedings:
Computers and Digital Techniques, vol.141, no.6, pp.325–326, Nov. 1994.
8. P. de Rooij, “Efficient exponentiation using pre-computation and vector addi-
tion chains,” Advances in Cryptology - EUROCRYPT9´4, LNCS 950, pp.389–399,
Springer-Verlag, 1995.
9. M. Bellare, J.A. Garay, and T. Rabin, “Fast batch verification of modular ex-
ponentiation and digital signatures,” Advances in Cryptology - EUROCRYPT9´8,
LNCS 1403, pp.236–250, Springer-Verlag, 1998.
12 Sung-Ming Yen and Chien-Ning Chen
Table 2. Simulation Results for 512-bit Multi-exponentiation
Proposed Algorithm BGMW method Lim-Lee’s Algorithm
Length Dim. Squ. Multiply Comp. Squ. Multiply Comp. Squ. Multiply Comp. Memory
512 10 10.89 1653.84 0.325 510 2421.86 0.553 511 1043.78 0.284 3,328
512 20 2.32 2694.30 0.263 509 4001.16 0.431 511 1815.00 0.217 19,008
512 30 1.94 3637.77 0.237 508 5370.54 0.376 511 2804.00 0.209 18,240
512 40 2.00 4523.23 0.221 508 6584.92 0.341 511 3660.89 0.199 40,064
512 50 2.20 5368.59 0.210 508 7786.83 0.320 511 4652.70 0.198 53,760
512 60 2.32 6183.52 0.201 508 8991.19 0.306 511 5514.22 0.193 62,144
512 70 2.54 6976.04 0.195 507 10019.60 0.291 511 6279.09 0.187 76,800
512 80 2.76 7747.96 0.189 507 11019.10 0.279 511 7359.24 0.190 84,736
512 90 2.82 8503.61 0.185 507 12020.01 0.270 511 8096.37 0.185 95,808
512 100 2.94 9249.21 0.181 507 13014.72 0.262 511 9174.15 0.187 107,584
512 200 3.76 16174.80 0.158 506 22154.34 0.220 511 18070.79 0.180 215,744
512 300 4.08 22566.16 0.147 506 30599.19 0.202 511 26934.43 0.178 326,208
512 400 4.54 28654.77 0.140 505 38371.31 0.189 511 36050.73 0.178 437,760
512 500 4.88 34524.04 0.135 505 45664.60 0.180 511 45038.16 0.178 545,536
512 600 4.97 40245.09 0.131 505 52960.04 0.174 511 53897.37 0.177 654,464
512 700 5.04 45829.22 0.128 505 60250.09 0.169 511 62797.41 0.176 768,000
512 800 5.30 51312.31 0.125 504 67255.75 0.165 511 71975.66 0.177 875,584
512 900 5.48 56700.16 0.123 504 73632.26 0.161 511 80869.38 0.176 983,744
512 1000 5.66 62013.48 0.121 504 80009.35 0.157 511 89733.97 0.176 1,094,208
512 2000 6.34 111737.94 0.109 503 142591.27 0.140 511 179500.93 0.176 2,190,464
512 3000 6.99 157042.06 0.102 503 199482.08 0.130 511 269271.49 0.176 3,287,744
512 4000 7.22 199746.90 0.098 503 256368.56 0.125 511 359038.96 0.176 4,385,536
512 5000 7.88 240591.60 0.094 502 310631.98 0.121 511 448770.56 0.175 5,483,584
512 6000 7.97 280156.14 0.091 502 362330.29 0.118 511 538449.73 0.175 6,581,760
512 7000 8.01 318681.95 0.089 502 414034.71 0.116 511 627991.51 0.175 7,680,000
512 8000 8.07 356431.83 0.087 502 465733.85 0.114 511 717729.76 0.175 8,774,208
512 9000 8.32 393394.52 0.085 501 516835.78 0.112 511 807494.59 0.175 9,870,464
512 10000 8.62 429744.76 0.084 501 563802.71 0.110 511 897263.51 0.175 10,967,744
Table 3. Simulation Results for 1024-bit Multi-exponentiation
Proposed Algorithm BGMW method Lim-Lee’s Algorithm
Length Dim. Squ. Multiply Comp. Squ. Multiply Comp. Squ. Multiply Comp. Memory
1024 10 20.33 3301.85 0.324 1022 4836.57 0.552 1023 2034.54 0.279 6,656
1024 20 2.92 5375.60 0.263 1021 8000.52 0.431 1023 3336.51 0.203 38,016
1024 30 1.91 7261.16 0.236 1020 10740.19 0.376 1023 4864.67 0.185 102,144
1024 40 1.98 9031.28 0.221 1020 13166.50 0.341 1023 6334.56 0.175 158,080
1024 50 2.20 10720.75 0.209 1020 15576.74 0.320 1023 8372.22 0.180 189,824
1024 60 2.31 12348.19 0.201 1020 17982.49 0.306 1023 9838.68 0.173 222,720
1024 70 2.54 13929.36 0.194 1019 20010.93 0.291 1023 11201.03 0.168 260,224
1024 80 2.69 15470.22 0.189 1019 22003.06 0.279 1023 12669.70 0.165 316,160
1024 90 2.85 16984.65 0.184 1019 23991.41 0.269 1023 14697.05 0.168 191,616
1024 100 2.90 18464.55 0.180 1019 25982.02 0.262 1023 16174.94 0.166 380,800
1024 200 3.72 32293.20 0.158 1018 44206.40 0.220 1023 31673.20 0.159 790,400
1024 300 4.04 45062.39 0.147 1018 61038.62 0.201 1023 47852.07 0.158 1,171,200
1024 400 4.43 57210.20 0.140 1017 76636.01 0.189 1023 63349.88 0.157 1,580,800
1024 500 4.94 68946.37 0.135 1017 91203.26 0.180 1023 79526.12 0.157 1,961,600
1024 600 4.98 80351.74 0.131 1017 105770.25 0.173 1023 95026.12 0.156 2,371,200
1024 700 5.09 91515.28 0.128 1017 120325.35 0.169 1023 111200.85 0.156 2,752,000
1024 800 5.30 102457.41 0.125 1016 134509.61 0.165 1023 126699.09 0.156 3,161,600
1024 900 5.48 113226.89 0.123 1016 147261.33 0.161 1023 142873.48 0.156 3,542,400
1024 1000 5.70 123842.06 0.121 1016 160014.11 0.157 1023 158374.64 0.155 3,952,000
1024 2000 6.45 223804.97 0.109 1015 285299.09 0.140 1023 316752.95 0.155 7,904,000
1024 3000 6.94 316339.99 0.103 1015 399079.42 0.130 1023 475125.67 0.155 11,856,000
1024 4000 7.10 404422.49 0.099 1015 512852.93 0.125 1023 633491.66 0.155 15,808,000
1024 5000 7.70 489441.07 0.096 1014 618452.70 0.121 1023 791873.07 0.155 19,760,000
1024 6000 7.91 572183.89 0.093 1014 721292.64 0.118 1023 950251.05 0.155 23,712,000
1024 7000 7.97 653213.30 0.091 1014 824130.67 0.115 1023 1108648.71 0.155 27,664,000
1024 8000 8.06 732713.82 0.089 1014 926967.89 0.113 1023 1267032.30 0.155 31,616,000
1024 9000 8.31 810994.20 0.088 1014 1029807.86 0.112 1023 1425387.44 0.155 35,568,000
1024 10000 8.70 888190.11 0.087 1013 1124831.65 0.110 1023 1583750.68 0.155 39,520,000
2009 年資訊安全與密碼國際會議 
2009 International Conference on Security and Cryptography 
(SECRYPT 2009) 
出國開會報告書 
 
顏嵩銘  教授 
國立中央大學   資訊工程學系 
Tel: (03) 4227151  Ext-35316 
Fax: (03) 4222681 
E-mail: yensm@csie.ncu.edu.tw 
http://www.csie.ncu.edu.tw/~yensm 
 
參加會議經過: 
此次「2009 年資訊安全與密碼國際會議」(2009 International 
Conference on Security and Cryptography) 縮寫為 SECRYPT 2009，係
由國際學術組織 INSTICC (Institute for Systems and Technologies of 
Information, Control and Communication)所主辦，並由國際密碼學研究
學會 (IACR，International Association for Cryptologic Research) 以及
ACM (SIGART) 所協辦。會議於義大利之米蘭舉辦，會期自 98 年 7
月 7 日至 7 月 10 日。 
該會議已舉辦多年，會中所發表之論文兼具實務與理論重要性。
該 SECRYPT 2009 會議探討與資訊安全、公開金鑰密碼學、私密金鑰
密碼學、資訊隱私保護、軟體與通訊安全 等諸多相關議題。會議涵
蓋範圍廣泛且諸多論文探討之主題相當有趣，本次大會接受 40 篇正
式口頭發表之 Full paper 論文，以及接受 16 篇短篇型式之 Poster 論
文。 
於本次會議所發表的論文中有一篇談及全球普遍使用中的一項
MiFare 非接觸式智慧卡 (Contactless smart card) – MiFare Classic (其
採用 Crypto-1 密碼系統為加密器) 之安全缺失，論文所指出之事實令
人震驚。該論文之作者為著名法國密碼學專家 Nicolas T. Courtois，其
論文指出目前全球使用量達兩億份之 MiFare Classic 非接觸式智慧卡
能夠輕易的被複製，該攻擊法並非單純之理論性探討，而是探討系統
層次之資訊系統重大安全缺失。尤其值得注意的是 Courtois 所提出之
