同步狀態轉換系統之可構組性研究 
Composability of Synchronous Finite State Transition Systems 
計畫編號：NSC 94-2218-E-002-083- 
執行期間： 94 年 11 月 1 日至 95 年 10 月 31 日 
計畫主持人：台大電子所 江介宏 助理教授  
 
摘要 
藉由「設計再利用」(design reuse)，模
組化(component-based)之積體電路設計方式
為極具前景的有效方法，用以克服愈趨複雜的
超大型積體電路系統設計，並能大幅提升電路
設計者的產能。於單晶片實現多系統(即所謂
的 SoC 設計) ，為目前超大型積體電路系統設
計的主要課題與挑戰。然而，以目前的積體電
路設計流程，要從個別的模組設計(例如矽智
產(intellectual properties))組合成單一完
整系統，並無簡單有效的設計自動化程序。此
困難起因於複雜的同時(concurrent)行為與
可能的即時函數求值互依(cyclic)關係(所謂
的組合環(combinational cycles)) 。為克服
這些困難使模組化設計能被有效自動化，構組
狀態轉換系統(state transition system)所
延生的基本特性必須被徹底了解。此計畫之目
的在探討系統構組最基礎的合法性。 
Abstract 
Component-based IC design methodology is one of 
the most promising approaches to combat the 
ever-increasing design complexity and to improve circuit 
designers’ productivity through design reuse. Integrating 
systems on a single chip, mainly for SoC designs, becomes 
a major task and a grand challenge in VLSI design. 
However, assembling an entire system from individual 
components, e.g., intellectual properties (IPs), cannot be 
automated easily in most current design flows. This 
difficulty emerges from the sophistication of concurrent 
behaviors and the possible instantaneous cyclic 
dependencies in function valuations (the so-called 
combinational cycles). To overcome the difficulty, 
fundamental properties resulted from composing state 
transition systems need to be studied carefully before 
component-based design can be automated effectively. 
This project studies the ultimate legitimacy of composition, 
more specifically, the connection between causality and 
composition. Since not any direct (parallel) composition of 
two synchronous transition systems yields electrically 
well-behaved circuitry, understanding the causes is the 
first step towards the cure of composition failure. 
1. Main Results 
We tackle the problem of FSM composability in three 
different aspects, namely, FSM initialization, retiming and 
resynthesis, and FSM optimization with register-latch 
tradeoff.  
1.1 FSM initialization 
The problem of FSM initialization was first 
formulated by Pixley [1]. It is well known that not all 
FSMs can be initialized implicitly by reset sequences. The 
exact analysis of resetability [2] requires state space 
exploration and thus is not applicable to large designs. We 
resolve the problem that, if an FSM is not resetable, how 
to select a minimum number of registers to reset such that 
the FSM can be initialized to some specified reset state. 
We take advantage of the partial scan technique [3] 
in testing, which relies only on structural analysis and thus 
are scalable to large designs. However, ours differ from 
prior work in that we consider the length constraints of 
initialization sequences. In addition, instead of pure 
structural analysis, we perform simplified state exploration 
other with retiming and resynthesis operations? 
2. Verification complexity: What is the computational 
complexity of verifying if two synchronous systems 
are equivalent under retiming and resynthesis? 
3. Initialization: How does the transformation of 
retiming and resynthesis affect the initialization of a 
synchronous system? How can we correct 
initialization sequences? 
Our main results include 
1. Characterize constructively the transformation power 
of retiming and resynthesis.  
2. Prove the PSPACE-completeness of verifying the 
equivalence of systems transformed by retiming and 
resynthesis operations when the transformation 
history is lost. 
3. Demonstrate the effects of retiming and resynthesis on 
the initialization sequences of synchronous systems. 
Present an algorithm correcting initialization 
sequences. 
1.3 Register-latch tradeoff 
As the semiconductor fabrication technology 
advances to the sub-100nm feature size regime, 
sensitivities of IC designs to process variations and 
environmental fluctuations are ever-increasing. To 
maintain design robustness against these uncertainties, it 
becomes more and more apparent that traditional design 
methodologies need to be modified and consider variations 
at the early stage of a design flow since not all process 
variations can be diminished with technology advances 
after all. 
In recent years, statistical approaches to circuit 
analysis and optimization have been revolutionizing the 
EDA community. They are mostly centered around delay 
and power issues, the two main concerns affected by 
design uncertainties. We focus on the timing issue. 
Traditional approaches to timing optimization were based 
on worst-case analysis. For instance, any gate delay under 
a certain operation condition may be set as a deterministic 
value fixed at the 6σ point in statistics to ensure enough 
margin tolerating variations. However, worst-case analysis 
is too conservative especially for more and more stringent 
design constraints in timing. Furthermore, when designs 
become more sensitive to process variations, it is harder to 
make design safe under worst-case variations. Due to the 
inadequacy of traditional worst-case analysis, the need of 
statistical analysis emerges, and motivates intensive 
research efforts, see e.g. [12] [13] [14] [15]. As more 
efficient and accurate algorithms are developed, they are 
applicable for statistical optimization and design for yield. 
Based on statistical timing analysis, most existing 
statistical optimization approaches focused on gate sizing, 
e.g., [16] [17] [18] [19] [20], and clock skew scheduling, 
e.g., [21] [22] [23] [24]. Rather, we propose a new 
statistical optimization methodology, which is orthogonal 
and complementary to gate sizing and can possibly be 
combined with clock scheduling for further improvement. 
We take advantage of the transparency property of 
level-sensitive latches for tolerating delay uncertainties. In 
fact, there were prior efforts focusing on the tradeoff 
between flip-flops and latches in other optimization 
context. For instance, flip-flops may be replaced with 
latches to optimize storage [25] or power [26]. However, 
to the best of our knowledge, there was no work done in 
the context of optimizing timing yield in the statistical 
domain.  
Given a design with edge-triggered D-FF 
implementation of state-holding elements (i.e. registers), 
we substitute level-sensitive latches for D-FFs such that 
timing yield is maximally improved. In addition, this 
substitution also enhances the tolerance to clock skew 
uncertainty as was known in the timing community. Based 
on dynamic programming, we devise an optimal algorithm 
for pipelined circuits, and generalize it for arbitrary 
sequential circuits. The proposed method can be used for 
pre-layout optimization under a statistical model of design 
uncertainties. Moreover, because latches are of smaller 
