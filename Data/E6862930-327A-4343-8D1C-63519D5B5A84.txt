行政院國家科學委員會補助專題研究計畫
■ 成果報告   
□ 期中進度報告 
 
改善動態翻譯及優化以支援多核心虛擬化平台— 
子計畫三：支援虛擬化之可重定目標的動態二元碼翻譯技術研究 
 
計畫類別：□ 個別型計畫  ■整合型計畫 
計畫編號：NSC 99-2221-E-002 -111 –MY3 
執行期間：2010年 08月 01日 至 2013 年 07月 31日 
 
計畫主持人：劉邦鋒教授 
共同主持人：王建民副研究員 
計畫參與人員：許俊琛、洪鼎詠、施書帆、張晁睿、林敬棋、謝孟儒 
 
成果報告類型(依經費核定清單規定繳交)：□精簡報告  ■完整報告 
 
本成果報告包括以下應繳交之附件： 
□赴國外出差或研習心得報告一份 
□赴大陸地區出差或研習心得報告一份 
□出席國際學術會議心得報告及發表之論文各一份 
□國際合作研究計畫國外研究報告書一份 
 
 
處理方式：除產學合作研究計畫、提升產業技術及人才培育研究計畫、列管計
畫及下列情形者外，得立即公開查詢 
          ■涉及專利或其他智慧財產權，□一年■二年後可公開查詢 
          
 
執行單位：國立臺灣大學資訊工程學系暨研究所 
中   華   民   國  102  年  10  月   26  日 
target applications; thus, afford DBT of more sophisticated optimization techniques as well as 
its retargetability. 
The experiment results indicate that the x86-to-x86_64 LnQ translator achieves an average 
speedup of 1.62X in integer benchmarks, and 3.02X in floating point benchmarks than QEMU. 
For multi-thread applications, our approach achieves 25X speedups over QEMU for the 
PARSEC benchmarks. 
中英文關鍵字：二元碼動態翻譯(Dynamic Binary Translation)，程序模式虛擬機器(Process   
              Mode Virtualization)、多執行續(Multi-thread) 
二、 報告內容： 
1. Introduction: 
 Dynamic binary translation is a just-in-time (JIT) compilation from binary code of a guest ISA to a 
host ISA. When the guest ISA is different from the host ISA, we refer to it as a cross-ISA binary translator. 
Cross-ISA binary translator enables application to migrate from one hardware platform to another, or to 
provide a virtualized platform to run an application without the speciﬁc hardware. For example, FX! 32 
[1] enables application to migrate from IA-32 to Alpha and IA-32EL [2] enables application to migrate 
from IA-32 to Itanium. QEMU [3], VmWare [4] use binary translation technique to provide server 
virtualization.  
 It takes tremendous efforts to build a cross-ISA translator. A cross-ISA translator must prepare a 
carefully hand-optimized translation template for each guest instruction. As a result it takes tremendous 
Figure 1: The architecture of LnQ framework 
for the following three reasons. First, the LLVM compiler infrastructure provides modular and reusable 
components for building an efficient just-in-time (JIT) runtime system. The LLVM infrastructure reduces 
the time and cost to develop LnQ framework. Second, LLVM is an open source project and is 
well-documented. We believe that an open source project greatly improves component interoperability 
and enables future extension of our research work. Thirdly, LLVM IR is well-deﬁned and can be easily 
manipulated by a rich set of API. 
 
2.2 IR Library and Instruction Description Table 
 To support a new guest ISA in LnQ framework, we provide LnQ the IR library and the instruction 
description table of the guest ISA. The IR library consists of pre-built LLVM IR templates for every guest 
instruction. These templates are referred to as translation functions. Each translation function implements 
the semantics of a guest instruction in C, and is compiled into LLVM IR with LLVM-enabled compliers, 
such as clang, llvm - gcc. In addition to IR library we also need to provide an instruction description table 
that describes the properties of parameters related to the translation function of each guest instruction. A 
property of a parameter contains the type of the parameter (e.g. a constant or a register ID), and how to 
obtain the parameter (e.g. from the immediate operand of the decoded guest instruction). This property 
approach improves guest ISA retargetability because guest ISA speciﬁc IR libraries and instruction 
description tables can be “plugged into” an LLVM IR translator. To support a new guest ISA, we only 
need to implement the semantics of all guest instructions with LLVM IR. Since the translation functions 
are written in C rather than in LLVM IR, it becomes much easier to support a new guest ISA in our LnQ 
framework.  
 
2.3 LLVM IR Translator 
 
Figure 3: Illustration of the translation process. 
guest basic 
block and add an entry into the directory. After the translated basic block is executed, the execution 
control transfers back to the emulation engine, which is referred to as context switching. The process is 
repeated until program terminates. 
 
.  Runtime Optimization: 
 We also integrate runtime optimizations that manipulate LLVM IRs to further improve the 
performance in LnQ framework. Those optimizations should be retargetable and not depend on either 
guest ISA or host ISA. Retargetability is an important goal of LnQ framework, and those optimization 
techniques can be reused in all binary translators for all ISAs. We implemented three classic optimizations 
that reduce the frequency of context switch between emulation engine and code cache. The three 
optimizations are block linking, indirect branch target caching, and shadow stack. We describe each of 
them in the following sections. 
 
4.1 Block Linking   
 Block Linking links translated blocks in code cache so that program execution transfers directly from 
one code block to another so as to eliminate expensive context switching. Block linking targets at blocks 
that have a direct branch, a conditional direct branch, or a direct call instruction as the last instruction. We 
use “exit” to refer to these jump or call instruction that are at the end of a block, and each exit has an 
unique exit ID, and the destination of an exit is refer to as branch target.  
 Block Linking links translated blocks in code cache so that program execution transfers directly from 
one code block to another so as to eliminate expensive context switching. Block linking targets at blocks 
that have a direct branch, a conditional direct branch, or a direct call instruction as the last instruction. We 
use “exit” to refer to these jump or call instruction that are at the end of a block, and each exit has an 
unique exit ID, and the destination of an exit is refer to as branch target.  
 Block linking can be either proactive or lazy. Proactive block linking links translated basic blocks 
whenever a new block is generated. A lazy block linking links translated basic blocks when a context 
switch occurs. We choose lazy block linking for two reasons. First, lazy block linking links translated 
basic blocks only when the execution actually goes from one block to another. Second, when a new block 
is generated, proactive block linking must update the branch targets of all exits that go to the newly 
generated block, therefore we need a data structure that maps branch address of exits to the starting 
Figure 5: Illustration of execution steps of block linking optimization. 
  Shadow stack (SS) optimizes function return mechanism in binary translation, and was first 
introduced in FX!32. Despite that a function return instruction can be viewed as an indirect branch, it can 
be optimized without indirect branch cache lookup. This is because the guest return address is known 
when the translator translates a guest call instruction since the call pushes the guest return address onto 
the stack. 
 If the translated basic block of the guest return address exists in code cache, the translator can push 
the memory location of the translated basic block onto a shadow stack, from which we can fetch the host 
return address when the function ends without looking up indirect branch cache or going back to 
emulation engine. However, if the block of the guest return address is not translated, we push the address 
that goes back to emulation engine.  The details of our implement of shadow stack are as follow. We 
assign a memory location, called address box, to each guest call instruction, which stores either the host 
return address or the return address back to emulation engine. If the guest return address does not yet have 
its translated basic block in code cache, we marks the address box as untranslated and stores the return 
address back to emulation engine in the address box. Then, when the translator generates a translated 
basic block, it checks whether there is a address box that should store the address of this translated block 
but is marked untranslated. If such address box is found, the translator marks the address box as translated 
and stores the address of translated basic block into the address box. For each guest call instruction, we 
insert instructions to push the content of its address box on top of the shadow stack. Please refer to Figure 
7 as an illustration. 
 As for each guest return instruction, we insert pop shadow stack instructions in the end of the 
translated block. Note that we need to perform a check to see whether the guest return address is matched 
to the one stored on top of the shadow stack. If they are matched, the execution directly transfers to the 
address that is popped from the shadow stack. If the addresses are not matched, we flush the shadow stack 
since the shadow stack is no longer valid, and the execution transfers back to the emulation engine.    
 
5. Emulation of Multi-thread Programs 
QEMU has two modes in emulating an application binary: (1) full-system emulation, in which all 
OS kernels involved are also emulated, and (2) process-level emulation, in which only application 
binaries are emulated. In this project, we focus on process-level emulation. When emulating a 
Figure 7: Illustration of execution steps of shadow stack optimization. 
IBTC and IB inlining, we effectively reduce the overhead by keeping the execution threads staying in the 
code cache for as long as possible. 
 
5.2 Atomic Instruction Emulation 
 
Figure 8: An example of translating two atomic instructions using global lock and  
lightweight memory transactions. 
 
The emulation of guest atomic instructions, which are usually used to implement synchronization 
primitives, poses another design challenge. The correctness and efficiency of emulating atomic 
instructions are critical to a DBT system, especially when emulating multi-threaded applications. To 
ensure the correctness, the DBT system must guarantee that the translated host code be executed 
atomically. To emulate the atomicity of a translated guest atomic instruction, QEMU uses a simple 
approach by surrounding the translated code region that corresponds to the guest atomic instruction with a 
lock-unlock pair to make it a critical section on the host machine. Thus, concurrent accesses to the 
emulation code by different threads are serialized. However, QEMU uses the same lock variable for all 
such critical sections. Figure 8(a) shows how two guest atomic instructions, atomic INC and atomic 
XCHG, are translated into critical sections protected by lock-unlock pairs using the same lock variable 
global lock. The reason that QEMU uses the same global lock variable for all such critical section is 
because the DBT cannot determine if any two memory addresses are aliases at the translation time. 
Although the global lock scheme of QEMU is portable, it has several problems: (1) Wang et al. 
proved that this approach could still have correctness issues that may cause deadlocks; (2) accesses to 
non-aliased memory locations (e.g. two independent mutex variables in the guest source file) by different 
threads are serialized because of the same global lock; (3) the performance is poor due to the high cost of 
 Figure 10: Performance results of x86 to x86-64 emulation for PARSEC with  
native input set. (Unit of time: second) 
 
 7. Conclusion 
We have achieved the goal of the first year of this project: to build a binary translator framework.  We 
have built the LnQ (LLVM+QEMU) framework to build dynamic binary translator.  We also built a 
x86-to-x86_64 binary translator as our first binary translator which is built by LnQ framework.  The 
experiment results show that the performance improves 62% in SPEC CINT 2006 and 3 times faster the 
QEMU in SPEC CFP 2006.  In the next year, we will keep on extend our works to more targets, both for 
guest ISAs and host ISAs.  For example, we will use LnQ to build a arm-to-x86 dynamic binary 
translator, or x86-to-arm binary translator. 
 
8. 參考文獻： 
 
[1] A. Chernoff, M. Herdeg, R. Hookway, C. Reeve, N. Rubin,T. Tye, S. B. Yadavalli, and J. Yates, 
“FX! 32: A profile-directed binary translator,” IEEE Micro, vol. 18, no. 2, pp. 56–64, 1998 
[2] L. Baraz, T. Devor, O. Etzion, S. Goldenberg, A. Skaletsky, Y. Wang, and Y. Zemach, “Ia-32 
execution layer: a two-phase dynamic translator designed to support ia-32 applications on 
itanium-based systems,” in Microarchitecture, 2003. MICRO-36. Proceedings. 36th Annual 
IEEE/ACM International Sym-posium on, Dec. 2003, pp. 191–201. 
[3] F. Bellard, “Qemu, a fast and portable dynamic translator,”in USENIX Annual Technical 
Conference, FREENIX Track, 2005, pp. 41–46. 
[4] S. DEVINE, E. BUGNION, and M. ROSENBLUM, “Virtualization system including a virtual 
machine monitor for a computer with a segmented architecture,” United States Patent 6,397,242. 
[5] C. Lattner and V. Adve, “Llvm: A compilation framework for lifelong program analysis & 
transformation,” in CGO’04: Proceedings of the international symposium on Code generation and 
optimization. Washington, DC, USA: IEEE Computer Society, 2004, p. 75. 
[6] Z. Wang, R. Liu, Y. Chen, X. Wu, H. Chen, W. Zhang, and B. Zang, “COREMU: a scalable and 
portable parallel full-system emulator,” in Proc. PPoPP, 2011, pp. 213–222. 
 
三、 計畫成果自評： 
So far, we have achieved the goal of the first year of this project: to build a binary translator 
framework.  We have built the LnQ (LLVM+QEMU) framework to build dynamic binary 
translator.  We also built a x86-to-x86_64 binary translator as our first binary translator which is 
built by LnQ framework.  The experiment results show that the performance improves 62% in 
SPEC CINT 2006 and 3 times faster the QEMU in SPEC CFP 2006.  In the next year, we will 
keep on extend our works to more targets, both for guest ISAs and host ISAs.  For example, we 
will use LnQ to build a arm-to-x86 dynamic binary translator, or x86-to-arm binary translator. 
Dynamic binary translation have been integrated with the critical annotations developed by 
國科會補助專題研究計畫成果報告自評表 
請就研究內容與原計畫相符程度、達成預期目標情況、研究成果之學術或應用
價值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）、是否
適合在學術期刊發表或申請專利、主要發現或其他有關價值等，作一綜合評
估。 
1. 請就研究內容與原計畫相符程度、達成預期目標情況作一綜合評估 
■達成目標 
□ 未達成目標（請說明，以 100 字為限） 
□ 實驗失敗 
□ 因故實驗中斷 
□ 其他原因 
說明： 
 
 
 
2. 研究成果在學術期刊發表或申請專利等情形： 
論文：■已發表 □未發表之文稿 ■撰寫中 □無 
專利：□已獲得 □申請中 ■無 
技轉：□已技轉 □洽談中 ■無 
其他：（以 100 字為限） 
 
  共已發表國際會議論文兩篇，已投稿期刊論文一篇，撰寫中之論文一篇 
 
 
3. 請依學術成就、技術創新、社會影響等方面，評估研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）（以
500 字為限） 
二元碼翻譯研究仍有很大的發展空間，也具有高度的產業發展性。如以處理器公司而
言，能快速將目前市場上主流的處理器上的應用程式移植到自身的平臺上，將有利於推
廣新的處理器。我們的成果將有助於快速發展一個新的且具高效能的二元碼翻譯器。初
步的結果顯示出我們的 LnQ 架構的性能優於廣泛使用的 QEMU，且也讓我們具備了一個
研究平臺，為將來的研究奠定了一個基礎。 
 
 
 
 
This is a report for my business trip to the 42nd International Conference on Parallel 
Processing, (ICPP), held in Lyon, France, from October 1st to 4th, 2013. 
 
The International Conference on Parallel Processing provides a forum for engineers 
and scientists in academia, industry and government to present their latest research 
findings in any aspects of parallel and distributed computing. 
 
This year my laboratory presents the following paper in the conference. 
 
 Chin-Hao Chang, Jan-Jan Wu, Pangfeng Liu, and Wei-Chung Hsu, “Sampling-Based 
Phase Classification and Prediction for Multi-threaded Program Execution on Multi-core 
Architectures”, International Conference on Parallel Processing, (ICPP), October, 
2013 
 
We believe that the paper is well received and we do attract attention from the 
research in the field of dynamic binary translation. Several questions and comments 
were raised during and after the presentation. 
 
There are three keynote speakers in the conference. All the speakers are well 
established in their research community.  
 
 "The Coming Era of Adaptive Control Systems in HPC", Jack Dongarra, Parallel 
Programming Laboratory, University of Illinois at Urbana-Champaign, U.S.A. 
 "Distributed Routing Algorithms in Networks: A Game Theory Approach," Bruno 
Gaujal, large-scale computing project (Mescal), INRIA Grenoble Rhones-Alpes, 
France. 
 "Many-core GPUs: Achievements and future perspectives", Manuel Ujaldon, 
Computer Architecture Department, University of Malaga, Spain.  
 
I am very interested in the Many-core GPU architecture, and I believe that the new 
generation of GPU, and the new 3D IC design will bring new aspects to my research. 
99 年度專題研究計畫研究成果彙整表 
計畫主持人：劉邦鋒 計畫編號：99-2221-E-002-111-MY3 
計畫名稱：在多核虛擬平台上的動態二元碼翻釋及最佳化之改進--子計畫三:支援虛擬化之可重定目標
的動態二元碼轉譯技術研究 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 3 3 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
