 I 
摘要 
本論文提出兩種萃取影像(image)特徵(feature)的方法來做為影像查詢的依據。此
外，也提出一套相似影像過濾(filter)技術，作為影像比對時的初步篩選，藉以縮短系統
在查詢影像時所需之比對時間。第一個影像特徵為影像顏色(color)及紋理(texture)特徵，
本文稱為多向顏色複雜度(multi-orientation and resolution color complexity, MORCC )。第
二個影像特徵是顏色空間(color space)分布特徵的取出技術，稱之為顏色空間關係(color 
spatial relation, CSR )。 
MORCC 係先將一個影像相鄰像素(pixel)之間的差值之絕對值取出，其中相鄰像素
可以是水平、垂直與斜角等方向的相臨 1 個、2 個、…、n 個像素。為判別不同差值大
小所代表影像顏色及紋理的意義， MORCC 將不同差值依照大小區分成數個群組
(group)。最後，再以統計方法對每個群組進行分析，以此做為此影像顏色及紋理的特徵
值。CSR 則使用 K-means 分群演算法將影像所有的像素值分成數個群組，接著再計算各
群組內所有像素之間的空間位置距離的總和，做為此影像的顏色空間分布的特徵。 
影像的特性與內容不同，代表著此影像擁有不同的特徵，有些影像對顏色及紋理特
徵比較明顯，而有些影像對顏色空間特徵比較敏感。因此，本文結合MORCC 及CSR 的
特徵來做為影像查詢。此外，本論文也提出一套權重(weight)值自動產生器，分別訓練
出最適合MORCC 及CSR 特徵之權重，更有效的改善查詢的正確率。 
為加速查詢影像與影像資料庫的特徵值之比對，本論文也提出了一個相似影像過濾
技術。針對影像資料庫內相似的影像做初步的篩選，保留少部分比較相似的影像，作為
本查詢系統最後詳細部分的比對。主要的技術係將影像資料庫所有影像之CSR的特徵，
依 K-means 演算法分成數個群組，而查詢影像CSR的特徵值將分別與這些群組做歐式距
離計算，並選擇距離最小的數個群組，做為本文相似影像過濾的依據。最後，本文實驗
的部分將依MORCC 特徵值、CSR特徵值、結合MORCC 及CSR特徵值和套用權重值自
動產生器及過濾器做一系列的比較與分析。 
關鍵字：影像查詢、顏色、紋理、K-means、QR、CBIR
  1
1. Introduction 
1.1 Background 
Much attention has been drawn to the design of image databases over the past few years 
[1-6]. Image retrieving is an important task in many image database applications, such as 
office automation, medical image archiving, digital library, multimedia publishing, 
computer-aided design and geographic information systems. Traditional image retrieval 
systems [1, 3] use textual features, such as filenames, captions, and keywords to annotate and 
index images. As these systems are applied to a large database, the textual-features-based 
method becomes not only cumbersome but also inadequate to represent the image contents. 
Many content-based image retrieval (CBIR) systems hence have been proposed in the related 
literatures [6-18]. 
Low-level features, such as spatial relations [13], colors [12-15], textures [6, 8, 16], and 
objects [19] are extensively used to index image features of CBIR systems. The color and 
texture attributes have been very successfully used in retrieving images with similar feature 
distributions. However, since these attributes do not describe the spatial distributions of pixel 
colors in an image, the retrieved results do not often make a lot of sense. For example, above 
features cannot describe the spatial distributions of the pixel colors in a landscape image with 
blue sky on the top and green countryside at the bottom. Spatial layout is about the absolute or 
relative position of color, texture, or shape information. Therefore, the attribute of the spatial 
relations among objects or pixels is also an important component for image content 
description and image access. To get the retrieval more accurate, this paper proposes a 
color-space and color-texture based image retrieval system (CSCTIR system).  
Color histogram [20] is one of the most commonly used color features in color-based 
image retrieval systems. The advantages of color histogram include simple procedures and 
quick calculations. In addition, color histogram can resist noise and rotation variations of an 
image. However, it can state merely the principal colors rather than the texture of the image. 
Instead, multi-orientation and resolution color complexity ( MORCC ) was presented in 
depicting the relationship between pixel colors and the textures of that image. The spatial 
distribution of the pixel colors in an image generally contains meaningful information. To 
indicate the spatial distribution of the pixel colors, an image feature called similar color space 
relation (CSR ) is presented.  
When a query image Q  scanned into the system, the CSCTIR  system compares the 
feature values of the query image with those of the pre-feature-extracted images in database. 
The database images with the closest distance value to Q  are delivered to the user. The 
MORCC  and CSR  can characterize different properties of an image. To increase the 
performance of an image retrieval system, a clustering based filter using the CSR  feature to 
accelerate execution of this system is addressed. Both MORCC  and CSR  features were 
integrated to develop a CSCTIR  system. The image properties as color, texture, and space 
relations are integrated into this image retrieval system.  
1.2 Motivation 
Image retrieval has raised lots of attention as the growth of image database. The filed for 
image retrieval also become wider and wider, such as medical image, facial recognition and 
fingerprint recognition. Different image database property has different feature extraction 
method. Among related image retrieval researches, some are based on the content of an image, 
such as color, object and texture. Color is often used as the feature for retrieval because of its 
easiness extraction from image. In this thesis, we extract color features by analyzing the 
  3
Finally, retrieval system calculate the distance between query and remaining images after 
filtering with MORCC  and CSR  features and feedback the results for users. 
The remains of this proposal are organized as following: Section 2 briefly introduces 
several related works; Sections 3.1 and 3.2 respectively describe the MOCC and CSR features; 
Section 3.3 discusses the feature selection scheme by using principle component analysis; 
Section 3.4 analyzes the automatic weight generator in detail; Section 3.5 depicts the CSCTIR 
system; Section 3.6 delineates the clustering based filter; The experiments that we want to 
take are explained in section 4, including the influence of MOCC and CSR features alone, the 
combined system retrieval accuracy, the feature selection scheme, automatic weight generator 
and fast filter on the combined retrieval system. 
2. Related Works 
Many researches retrieve image through its content [6-19], such as color [13-15], object 
[12, 19] and texture [6, 12]. Feature extraction approach varies among different feature 
characteristics. Take object in an image for example, to calculate the contour of object is 
sometimes a tough task, especially when the image is a natural or texture image. For this 
reason, this thesis is based on the analysis of color and texture of an image because of its 
easiness extraction. Color can represent the composition of pixels in an image and their 
relationship. Texture is the construct of an image which can be defined as the variation of 
color and its direction.  
2.1 Color Histogram 
Color histogram [20] is widely used for describing the constitution of colors in an image 
because of its easy and fast calculation. Swain and Ballard [20] proposed a retrieval system 
based on color histogram features in 1991. The method is as follows: firstly, system use 
K-means [23] algorithm to separate all the pixels of all images in the database into k  groups. 
Secondly, system would calculate the mean of all pixels in each group and use it as the new 
initial value for further training. Each group corresponds to a color in color histogram which 
is generally called bin. Thirdly, system would calculate the distance between each pixel and 
bin. Finally, system would put each pixel into the bin with minimum distance value. Each bin 
and pixel within it constitutes the color histogram of that image. 
Color histogram can display the color distribution but no spatial layout of an image. 
Consider two images with similar color histogram; system might take them as the same. The 
distance (Dist) between database image DI  and query image QI  can be defined as follow: 
( )
∑
∑
=
== k
i
Q
i
k
i
Q
i
D
i
H
HH
Dist
1
1
,min
               (2-1) 
where DiH  and 
Q
iH  represent the total pixels in i -th bin of color histogram DI  and 
QI  separately. 
Although color histogram can distinguish each feature through color distribution, the 
lack of differentiating spatial relation makes it insufficient to be a separator. Take Figure 2.1(a) 
and 2.1(b) for example; though these pictures have almost the same color histogram, they are 
so different from appearance actually. If one uses color histogram as a discriminator only, 
  5
firstly segmented into several regions. Each region has similar colors and textures features. 
Each image is thus represented by a region-based feature matrix. Different images may have 
different number of regions. All neurons in GHSOQM have a fixed number of row vectors in 
feature matrices which mean that all neurons represent images with fixed number of regions 
in feature space. The GHSOQM can incrementally learn new incoming images without 
retraining all images. 
2.4 Wavelet Correlogram: A New Approach for Image Indexing and Retrieval 
Moghaddam [8] proposed a method based on combination of multi-resolution image 
decomposition and color correlation histogram. The wavelet coefficients of the image are 
computed first using a directional wavelet transform such as Gabor wavelets. A quantization 
step is then applied before computing one-directional auto correlograms of the wavelet 
coefficients. Finally, index vectors are constructed using these one-directional wavelet 
correlograms. 
2.5 Content Based Image Retrieval Using Motif Cooccurrence Matrix 
Jhanwar et al. [18] proposed image retrieval using motif cooccurrence matrix (MCM). 
The MCM is derived from the motif transformed image. The whole image is divided into 2×2 
pixel grids. Each grid is replaced by a scan motif which minimizes the local gradient while 
traversing the 2×2 grid forming a motif transformed image. The MCM is then defined as a 
3D matrix whose ( )kji ,,  entry denotes the probability of finding a motif i  at a distance k  
from the motif j in the transformed image. Conceptually, the MCM is quite similar to the 
color cooccurrence matrix (CCM); however, the retrieval using the MCM is better than the 
CCM since it captures the third order image statistics in the local neighborhood. 
3. Proposed Methods 
Two image features are studied in this thesis: multi-orientation and resolution color 
complexity ( MORCC ) and color space relation (CSR ). MORCC describes the relationship 
between pixel colors and textures of an image while the CSR  represents the spatial 
distributions of similar pixel colors in an image. Both features have their own distinguishable 
characteristics. 
3.1 Multi-Orientation and Resolution Color Complexity(MORCC) 
Let ZNNyxG yx →×:),(  be the gray levels of an yx NN ×  image I , and 
}255,...,1,0{=Z . The ),( yxG  of each pixel ),( yxP  in I  corresponds to a grey level 
difference ),( yxGΔ  related to ),( yx δδ , where ),( yxP  is located at the coordinates ),( yx . 
),( yx δδ  is the displacement vector specifying the relative position of the pixels ),( yxP  and 
),( yx yxP δδ ++ . ),( yxGΔ  is defined as: ),(),(),( yxGyxGyxG yx −++=Δ δδ . 
),,,( ΔgNP yx δδ  is a function the number of pixels ),( yxP ’s in I , where 
),( yxGg =  and ),( yxGΔ=Δ . 
yx
GD δδ  is a 256256×  matrix. Cell ],[ jiGD yxδδ = 
),,,( jiNP yx δδ  gives the number of pixels for ),( yxGi =  and ),( yxGj Δ= . ],[ jiGD yxδδ  
and ),,,( ΔgNP yx δδ  hence counts the pixel number of those ),( yxP  with gray-level g  
and Δ  (the grey level difference between ),( yxG  and ),( yx yxG δδ ++ ). Let 
yx
MORCC δδ  be the 1K  groups in the g  and 2K  groups in the Δ  which is the MORCC  
  7
mean, standard deviation, and skewness. Hence, there are 2133 KK ×××  feature vectors in 
MORCC  of a color image.  
3.2 Color-Space Relationship(CSR) 
The color and texture attributes had been very successful in retrieving images with 
similar feature distributions [6-9, 13-18]. However, since these attributes do not describe the 
local properties of an image, the retrieved results often came out nonsense. In this section, as 
an image feature, the color-space relation (CSR ) between the pixel colors and their spatial 
distributions is discussed. The CSR  describes the spatial distribution of similar pixel colors 
in a color image. 
In a full color image, a pixel color is generally described using a 24 -bit memory space. 
There are a total of 242  different possible pixel colors. Before computing CSR  of an image, 
the pixels of whole the database images are categorized into 3K  clusters using K-means 
algorithm [23] according to their colors. The mean of all the pixel colors in each cluster is 
considered to be one color value in a color palette. With 3K  different colors, this color 
palette is used as the common color palette (CCP ) for all images (including all database 
images and query images). 
Considering there are too many pixels in each 3K  which makes system performance 
poor, we made a little adjustment on the CSR  feature extraction. To extract the CSR  of an 
image I , each pixel color C  in I  is replaced by the color in CCP  that is most similar to 
C . Every pixel in I  was classified into 3K  clusters. Each 3K  cluster consists of similar 
color pixels. Let ),( ki
k
i yx  be the coordinates of pixel i  in k th cluster, and 
kn  be the total 
pixel numbers in the k th cluster. The CSR  of an image I  is to summarize the distance 
between each pixel ),( ki
k
i yx  and the center of each cluster. The center ),(
k
c
k
c yx  of k th 
cluster can be figure out with: 
k
cx  = ∑
=
kn
i
k
ik xn 1
1
,                      (3-7) 
k
cy  = ∑
=
kn
i
k
ik yn 1
1
.                  (3-8) 
The CSR  feature of an image is still a 3K -dimension array whose k th element 
][kCSR  is defined as follows:  
∑
=
−−−=
kn
i
k
c
k
i
k
c
k
i yyxxkCSR
1
22 )()(][               (3-9) 
CSR  can be used to characterize the spatial distribution of similar color pixels in an 
image. With similar color histograms, one image has most of pixels with homologous colors 
scattered over the whole image, while other image has most of pixels of the analogous colors 
gathering in some small regions.  
CSR can be used to characterize the spatial distribution of similar color pixels in an 
image. With similar color histograms, one image has most of pixels with homologous colors 
scattered over the whole image, while other image has most of pixels of the analogous colors 
  9
Let qW  be the first q  columns of W  and let 
q
nwww ℜ∈,...,, 21  be the rows of the 
matrix qW . Each vector iw  represents the projection of the i th feature (variable) of the 
vector iMORCC  to the lower dimensional space; that is, the q  elements of iw  
correspond to the weights of the i th feature on each axis of the subspace. The key 
observation is that the features which are highly correlated or contain considerable overlap in 
information having similar absolute value weight vectors iw . In the two extreme cases, two 
independent variables have maximally separated weight vectors while two perfectly 
correlated variables have identical weight vectors (up to sign). 
To find the best subset, we use the structure of rows iw  to first find the subsets of 
features that are highly correlated and choose one feature from each subset. The chosen 
features represent each group optimally in terms of greatest variation. 
3.4 Auto-Weight Generator 
We have already explained a lot of MORCC  and CSR  in section 3.1 and 2.2. To 
promote retrieval accuracy, an auto-weight generator was proposed for combining these 
features to form a color-space and color-texture based image retrieval system (CSCTIR  
system). 
In this section, we would try to make use of the relation between MORCC  and CSR  
features. First, system trains the weight between image 1df  and similar image 2df . Suppose 
the distance between image 1dif  and similar image 2dif  in the i th training are 
t
id  and 
s
id  
for MORCC  and CSR  features respectively. We can product them with 1w  and 2w  
separately to make the distance between image 1dif  and 2dif  shorter. The formula is as 
follow:  
021 =+ wdwd siti ,  Ni ,...,2,1=           (3-11)  
N  is the total number of training images. tid  is the MORCC  Euclidean distance between 
training image 1dif  and its’ opposed training similar image 2dif . sid  is the CSR  Euclidean 
distance between training image 1dif  and its’ opposed training similar image 2dif . 1w  is the 
weight of MORCC  Euclidean distance in the whole images and 2w  is the weight of CSR  
Euclidean distance in the whole images. To compute the weight of 1w  and 2w ,  Equation 
(3-11) can be written in matrix form as follows: 
1
122
1
2
22
11
0
0
0
×
×
×
⎪⎪⎭
⎪⎪⎬
⎫
⎪⎪⎩
⎪⎪⎨
⎧
=
⎭⎬
⎫
⎩⎨
⎧
⎥⎥
⎥⎥
⎥
⎦
⎤
⎢⎢
⎢⎢
⎢
⎣
⎡
NN
s
N
t
N
st
st
w
w
dd
dd
dd
MMM
                 (3-12)  
, and the condition is 121 =+ ww . We can rewrite in the following matrix form: 
BAw =                      (3-13)  
where 
  11
1
)min()max(
r
dC
k
dC
k
dC
k
qC
kC
k SS
SSS ⎟⎟⎠
⎞
⎜⎜⎝
⎛
−
−=Δ , and 
1r  is a constant. )max(
dC
kμ , max( dCkσ ), and max( dCkS ), as well as min( dCkμ ), min( dCkσ ), and 
min( dCkS ) are defined as the maximal and minimal values of 
dC
kμ , dCkσ , and dCkS  among 
images in database for C  = R , G , and B .  
Considering CSR  ( df1 , 
df2 , …, 
d
Kf 3 ) and (
qf1 , 
qf 2 , …, 
q
Kf 3 ) of images Q  and D  
are obtained from equation (3-9), the image matching distance CSRΔ  of Q  and D  based 
on FCSR  is formulated as the following: 
2
3 2∑
1 )min(-)max(
-r
K
k
r
d
k
d
k
d
k
q
kCSR
ff
ff
=
⎟⎟⎠
⎞
⎜⎜⎝
⎛=Δ ,                   (3-16) 
where 2r  is a constant; ( )dkfmax  and ( )dkfmin  are the maximal and minimal values 
among dkf ’s of all database images. 
CSCTIR  system combines the MORCC  with the CSR  to quantize the similarity of 
Q  and D . Using such retrieval system, one can define the image matching distance CSCTIRΔ  
between Q  and D   as:  
CSCTIRΔ = 1w × MORCCΔ + 2w × CSRΔ ,                    (3-17) 
where 1w  and 2w  are given in equation (3-14). Generally, 
CSCTIRΔ  decreases with 
increasing similarity of Q  and D . Hence, CSCTIR  system can deliver the image with the 
minimal CSCTIRΔ  from the database. 
3.6 CSR-Based Filter 
In section 3.2, we proposed a filter based on CSR  features to rule out most dissimilar 
images in the database. For obtaining better system performance, we proposed another filer 
also based on CSR  filter. This clustering-based filter still classifies all database images into 
G  groups by K-means algorithm based on CSR  features from equation (3-9). Let icCSR  
=( ]1[icCSR , ]2[
i
cCSR , …, ][ 3KCSR
i
c ) be the average c  of the CSR  of all the images in 
each group i , where .,...2,1 Gi =  
For given a query image Q , the clustering-based filter initially computes the image 
matching distance CSRfΔ  between the CSR =( ]1[CSR , ]2[CSR ,…, ][ 3KCSR ) of Q  and the 
respective feature icCSR  =( ]1[
i
cCSR , ]2[
i
cCSR , …, ][ 3KCSR
i
c ) of i th group from 1=i  to 
3K , and also selects g  groups with the minimal 
CSR
fΔ . Then the filter compares Q  with 
each image in those g  groups via the corresponding CSRfΔ . With such process, cluster-based 
filter, MORCC ,CSR  , and  are integrated as CSCTIR system through the minimal CSRfΔ  
relative to Q .  
  13
 
 
 
Figure 4.1 (b) The database images corresponding to the images in Figure 4.1(a) 
 Figure 4.1 Some examples of image set 1. 
In each experiment, every qiI  is used as the query image. For each query, the system 
responds to the user L  database images with the shortest image matching distances opposite 
to qiI . If 
d
iI  exists among the L  database images, we say the system correctly finds the 
desired image. Otherwise, the system is considered failed in finding the desired database 
image. The accuracy rate of replying a query also is explained with (%)ACC .  
4.1 The Performance of MORCC Feature 
The first experiment is to find the best value of 1K  and 2K . Table 4.1 shows the result 
with ( ) ( )0,1, =yx δδ  and 11 =r . Since each cell of MORCC  contains three values: mean, 
standard deviation, skewness and three color components: R , G  and B , the feature 
numbers of a cell are 933 =× . If 2221 ×=× KK , the feature number of a cell is 36922 =×× . 
Looking from Table4.1, 3321 ×=× KK obtains better ACC than 2221 ×=× KK , 
4421 ×=× KK , 5521 ×=× KK , and 6621 ×=× KK . Therefore, 3321 ×=× KK  is 
choused from MORCC  system. 
Table 4.1 The ACC  for 1=L and value of 21 KK ×  with ( ) ( )0,1, =yx δδ  and 
11 =r  
21 KK ×  22× 33×  44×  55×  66×  
(%)ACC  55.14 59.36 51.79 56.12 54.83 
Number of features 36 81 144 225 324 
The second experiment is to find the best values of 1r  and ( )yx δδ ,  with 3321 ×=× KK . 
The best ACC  with ( )yx δδ ,  and 1r  were underlined in Table 4.2. For example, ( ) ( )8,0, =yx δδ  and 3.01 =r  obtains the best ACC . This means that MORCC scans image 
in horizontal order with 8 pixels interval and 3.01 =r  owns the best ACC . 
  15
Our second experiment for CSR  is to find the suitable value of 2r  with 3K =20. Table 
4.5 shows that 2.02 =r  obtained 71.21% accuracy for 1=L  which is better than any other 
values. 
Table 4.5 ACC  for 203 =K  and various 2r  
 
1 2 3 4 5 10 
2 59.25 67.43 71.94 74.33 75.99 81.97 
1 65.59 75.07 78.10 80.40 82.43 86.75 
0.9 66.33 75.25 78.66 81.32 82.70 57.30 
0.8 67.53 76.36 81.78 81.78 82.80 87.86 
0.7 68.45 77.74 80.59 82.34 83.81 88.87 
0.6 69.27 78.29 81.42 83.44 84.73 89.88 
0.5 70.75 79.02 82.15 83.90 85.10 90.89 
0.4 71.08 79.85 82.52 84.82 86.48 91.08 
0.3 71.11 79.94 83.53 85.37 87.21 90.98 
0.2 71.21 79.94 82.52 84.94 87.92 91.25 
0.1 66.51 73.87 76.54 79.02 80.77 85.28 
4.3 The Performance of Feature Selector 
In section 3.3, we talked about the feature selector for reducing the dimension of feature 
vectors. In this section, we test how many features could be ruled out by using the feature 
selector. Figure 4.2 is the result of feature selector. Figure 4.3 is the ACC  with different 
number of features eliminated by the feature selector. Parameters for the experiments 
are 3321 ×=× KK , ( ) ( )8,0, =yx δδ + ( )0,4 ,and 3.01 =r . From Figure 4.2, 90.382% cumulative 
could be obtained if we set component number=20.  
-0.2
0
0.2
0.4
0.6
0.8
1
1.2
1 6 11 16 21 26 31 36 41 46 51 56 61 66 71 76 81
Component Number
Ei
ge
nv
alu
e
 
Figure 4.2 The result of feature selector. 
Figure 4.3 shows that system obtained 73.21% ACC  by removing 26 MORCC features for 
setting component number=20. The MORCC features are reduced from 81 to 55. 
ACC  L  
2r  
20th principle component; cumulative: 90.382% 
  17
Table 4.7 ACC  for CSCTIR  system and Huang and Dai’s approaches 
 
1 2 3 4 5 10 
CSCTIR  79.59 88.02 90.86 92.58 93.93 95.94 
Hung and Dai [6] 61.10 70.80 73.60 76.20 77.40 82.70 
4.6 The Performance of CSCTIR System on Other Image Sets 
In this section, three images sets were used to test the performance of CSCTIR  system. 
Image set 2 contains 112 gray level texture images of size 512×512 pixels available on 
http://www.ux.his.no/~tranden/brodatz.html. Each image was then partitioned into 16 
non-overlapping images with size 128×128 pixels. Image set 3 contains 163 images with 14 
groups available on http://vismod.media.mit.edu/vismod/. 
4.6.1 The Performance of CSCTIR System on Image Set 2 
In this section, we use the recall and precision efficiency measurement (Mehtre et al., 
1995) on image set 2. Figure 4.4 are some examples of the images. The retrieval )(Rrecall and 
)(Pprecision is defined as the following: 
( ) ,LnkP k=                             (4-1) 
( ) ,NnkR k=                             (4-2) 
where L  is the number of retrieved images; kn  is the number of relevant images in the 
retrieved images and N is the number of all relevant images in the database. Two image sets 
were used for evaluating system performance. Because the images in image set 1 contain 
many types, most parameters of CSCTIR  system were retained in this chapter except 1w  
and 2w . 
     
     
Figure 4.4 Some examples of image set 2. 
Table 4.8 shows the recall of CSCTIR  system and Huang and Dai’s approaches. 
Parameters for CSCTIR  system are 3321 ×=× KK , ( ) ( )8,0, =yx δδ + ( )0,4 , 
3.01 =r , 203 =K , 2.02 =r , 64281.01 =w , and 35719.02 =w . Since the CSCTIR  system 
takes the variation of pixel in different resolution and the pixel spatial relation into 
consideration, the CSCTIR  system possesses 6.4% higher recall (90.4%) than the Hung 
L  
(%)ACC  
  19
      
        
Figure 4.6 Some examples of image set 3. 
Figure 4.7(a) are 9 images retrieved by N. Jhanwar et al.[18] approach which combines the 
color histogram [20] and MCM [18] as two independent features and 4.7(b) are those 
retrieved by CSCTIR  system with parameters 3321 ×=× KK , ( ) ( )8,0, =yx δδ + ( )0,4 , 
3.01 =r , 203 =K , 2.02 =r , 564726.01 =w  and 435274.02 =w . The image on the top 
left is the query. Images from left to right and top to bottom are retrieved in order. 
         
        
        
(a) Retrieved images by N. Jhanwar’s [18]   (b) Retrieved image by CSCTIR  
approach.                             system. 
Figure 4.7 Images retrieved by N. Jhanwar et al. [18] andCSCTIR  approaches: the top is the 
query. Left to right and top to bottom are retrieved images in order. 
Both N. Jhanwar et al. [18] and CSCTIR  systems retrieved the same number of 
relevant images as shown in Figure 4.7. Since CSCTIR  system recognizes images with 
similar color distribution well, retrieved images are more similar to the query image in the 
former ranks and more color relevant than N. Jhanwar et al. approach.   
4.7 The Performance of Fast Filter on CSCTIR System 
Next experiment evaluates the proposed fast filter on CSCTIR  system in image set 1. 
Table 4.10 addresses different combinations of G  and g . Parameters are 3321 ×=× KK , ( ) ( )8,0, =yx δδ + ( )0,4 , 3.01 =r , 303 =K , 2.02 =r , 63284.01 =w  and 36716.02 =w . We 
assume that the images in each G  and each g  are the same. Since the  ACC for different 
  21
[4] Y. Rui, and T. S. Huang, “Image Retrieval: Current Techniques, Promising Directions, 
and Open Issues,” Journal of Visual Communication and Image Representation, Vol. 10, 
pp. 39–62, October, 1999. 
[5] M. Stricker, and M. Orengo, “Similarity of color images,” SPIE: Storage Retrieval 
Image and Video Database III, Vol. 2420, pp. 381–392, February, 1995. 
[6] P. W. Huang, and S. K. Dai, “Image Retrieval by Texture Similarity,” Pattern 
Recognition, Vol. 36, No. 3, pp. 665-679, 2003. 
[7] SitaoWu, M.K.M. Rahman and Tommy W.S. Chow, “Content-based image retrieval 
using growing hierarchical self-organizing quadtree map,” Pattern Recognition, Vol. 38, 
pp. 707-722, 2005. 
[8] H. Abrishami Moghaddam, T. Taghizadeh Khajoie, A.H. Rouhi, and M. Saadatmand 
Tarzjan, “Wavelet correlogram: A new approach for image indexing and retrieval,” 
Pattern Recognition, Vol. 38, pp. 2506-2518, 2005. 
[9] R. Brnuelli, and O. Mich, “Histograms Analysis for Image Retrieval,” Pattern 
Recognition, Vol. 34, pp. 1625-1637, 2001. 
[10] J. M. Fuertes, M. Lucena, N. Peres de la Blanca and J. Chamorro-Martinez, “A Scheme 
of Color Image Retrieval From Databases,” Pattern Recognition, Vol. 22, No. 3, pp. 
323-337, 2001.   
[11] Y. D. Chun, S. Y. Seo, and N. C. Kim, “Image Retrieval Using BDIP and BVLC 
Moments,” IEEE Transactions on Circuits and Systems for Video Technology, Vol. 13, 
Issue 9, pp. 951-957, 2003. 
[12] B. C. Ko, and H. Byun, “FRIP: A Region-Based Image Retrieval Tool Using Automatic 
Image Segmentation and Stepwise Boolean AND Matching,” IEEE Transactions on 
multimedia, Vol. 7, No. 1, pp. 105-113, 2005. 
[13] Y. K. Chan and C. Y. Chen, “Image Retrieval System Based on Color-Complexity and 
Color-Spatial Features,” The Journal of Systems and Software, Vol. 71, Issue 1-2, pp. 
65-70, 2004. 
[14] C. C. Chang and Y. K. Chan, “A Fast Filter for Image Retrieval Based on Color 
Features,” SEMS2000, Baden-Baden, German, pp. 47-51, 2000.  
[15] H. Nezamabadi-Pour and E. Kabir, “Image Retrieval Using Histograms of Uni-color and 
Bi-color Blocks and Directional Changes in Intensity Gradient”, Pattern Recognition 
Letters, Vol. 25, Issue 14, pp.1547-1557, 2004. 
[16] S. Liapis, and G. Tziritas “Color and Texture Image Retrieval Using Chromaticity 
Histograms and Wavelet Frames,” IEEE Transactions on Multimedia, Vol. 6, No. 5, pp. 
676-686, 2004. 
[17] R. M. Haralick, B. Shanmugam, and I. Dinstein, “Texture Features for Image 
Classification,” IEEE Transactions on Systems, Man, and Cybernetics, Vol. 3, No. 6, pp. 
610–621, November, 1973. 
[18] N. Jhanwar, S. Chaudhurib, G. Seetharamanc, and B. Zavidovique, “Content Based 
Image Retrieval Using Motif Co-occurrence Matrix,” Image and Vision Computing, Vol. 
22, pp. 1211–1220, 2004. 
[19] B. M. Mehtre, M. Kankanhalli, and W. F. Lee, “Shape Measures for Content-Based 
Image Retrieval: A Comparison Info,” Processing & Management, Vol. 33, pp. 319–337, 
1997. 
[20] M. J. Swain, and D. H. Ballard, “Color Indexing,” International Journal of Computer 
Vision, Vol. 7, pp. 11-32, 1991. 
[21] I. Daubechies, “Orthonormal Bases of Compactly Supported Wavelets,” 
Communications on Pure and Applied Mathematics, Vol. 41, pp. 909-996, 1998. 
[22] R. M. Haralick, and L. G. Shapiro, “Computer and Robot Vision,” Vol. I, 
