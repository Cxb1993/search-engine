 2 
1. Introduction 
Wavelet analysis has quickly established itself as a standard method for data 
compression and noise reduction.  In statistics, wavelet based estimation models 
have been widely held for their nice asymptotic properties and computational 
efficiency.  However, because of the linearity of the operation, the filter cannot 
change the intrinsic property of the original noised signal, such as regularity, etc., 
Indeed, the linear filter is a kind of linear manipulation of the spectrum of a signal 
because the complex exponential function is the eigenfunction of a linear system.  
Therefore, it is difficult to suppress the noise and keep the speech signal using linear 
filters when the spectrum of a signal is somewhat wideband and nonstationary, which 
is the usual case. 
 
The main wavelet thresholding scheme are the hard- thresholding and soft- 
thresholding.   This technique is effective because the energy of a function with 
some smoothness is often concentrated on few coefficients while the energy of noise 
is still spread in all coefficients in the wavelet domain.  The fact that the 
thresholdings obtained by Donoho and Johnstone [1] lacked adaptivity, led to better 
adaptive rules inspired from conventional tools in nonparametric estimation.  More 
contemporary technology [2-5] were influenced by complexity theory where some 
 4 
2. Wavelet Thresholding Neural Network 
We construct a type of thresholding neural network to perform the thresholding in 
the transform domain to achieve noise reduction.  The neural network structure is 
shown in Ref. [8].  The transform, in Ref [8], can be any linear orthogonal transform.  
The linear transform performed on observed data samples can change the energy 
distribution of signal and noise samples.  By thresholding, the signal energy may be 
kept while the noise is suppressed.  
 
  The SUREShrink procedure that is based on Stein’s unbiased risk [9] was among 
the early estimatiors in this spirit.  Here the soft thresholding function    ),( tyi is 
weakly differentiable [9], can be calculated numerically by a gradient-based 
optimization algorithm [9, 10].  In learning step k , the parameter t  can be adjusted 
as follows: 
)()()1( ktktkt    and  
)(
1
0
)( |
ˆ
)(|
)(
)()(
ktt
N
i
i
ktt
t
v
k
t
tJ
kkt



 





        (1) 
where )](),(),([)( 21 kkkdiagk p   is the learning rate matrix at each step.  
 
In this study, we will extend the proposed methods in [8] to a time adaptive 
stochastic learning algorithm.  The extension can be improved the noise suppression 
power of each wavelet feature. 
 6 
adjusted adaptively by  
( )
( )
( ) ( ) |i t t k
J t
t k k
t
 

 

                            (5) 
Especially, for SURE based algorithms, the SURE risk can be used to estimate the 
instantaneous square error risk in the transform domain 
2
,
( )
( ) 1 ( ) 2 ii SURE i
i
g u
J t g u
u

  

                      (6) 
In this case, the linear orthogonal transform should be implemented in real time.  
Usually, we can use a specific filter bank depending on the transform.    
 
 
4. Convergence of the Adaptive Stochastic Learning Algorithm  
  The analysis of the algorithm will be based on stationary signals, although our 
nonlinear adaptive filter method is designed to track nonstationary random input.  
For the stochastic signal model described in Eq. (2) and (3), assume the following 
learning algorithm is used: 
( 1) ( ) ( )t i t i t i                                 (7) 
where 
ˆ
( ) ( ) i i
x
t i i
t
 

 

( )[ ( )],     ( )
0,                        | | ( )
( )[ ( )],      ( )
i i
i
i i
i n t i y t i
y t i
i n t i y t i


  

 
  
                (8) 
 
 8 
= 
*
*
( )| ( ( ))[ { ( 1) | ( )}] ( )
t
t ip t i t E t i t i dt i

   + *
*
( ) ( ( ))[ { ( 1) | ( )} ] ( ) |t i
t
p t i E t i t i t dt i

   
= (1 )i
*
( )| ( ( ))[ ( ) ] ( ) |t ip t i t i t dt i


 = (1 )i
*| { ( )} |E t i t .                 (13) 
Since 0 1 1i   , it follows 
*lim | { ( )} | 0
i
E t i t

  .  i.e., the above learning 
algorithm is convergence in the mean. 
 
 
5. Classification of speaker data 
  In this paper, we decompose a speech signal into wavelet orthogonal bases. We 
classify the decomposed signals by N  uniform sub-bands.  We use the energy of 
each sub-band as a wavelet feature.  We apply the features to thresholding neural 
network and Gaussian mixture model (GMM) to a text independent speaker 
recognition system.  
 
As a typical, Gaussian mixture model (GMM) [11, 12] has been used to 
characterize speakers’ voice in the form of probabilistic model.  The given speech 
signal series y  and the reference speech signal series xy  are used as the training 
set.  For an wavelet feature vector denoted as ˆtx  belonging to a specific speaker s , 
the GMM is a linear combination of N  Gaussian components, identification is 
performed by using the maximum likelihood classification 
 10 
  Several speaker recognition experiments were performed to evaluate the various 
WT.  For speaker recognition experiments, the results for four methods are reported 
in Table 1.  The best recognition rate of adaptive stochastic learning algorithm in 
wavelet feature obtained was 94% in TALUNG database.  
 
Table 1.  Speaker recognition rates (TALUNG database) 
method                      Feature 16 24 32 
WT [8] 87% 90% 93% 
Hard thresholding WT [4] 84% 87% 89% 
Soft thresholding WT [3] 87% 91% 93% 
Adaptive Stochastic Learning WT  89% 92% 94% 
 
 
7. Conclusion 
  The text-independent speaker recognition system proposed in this paper shows 
excellent performance in TALUNG databases.  We developed a new type of 
thresholding method for adaptive noise reduction, which combines the linear filtering 
and thresholding methods.  It is prove that the stochastic learning algorithm is 
convergent in certain statistical sense in ideal conditions.  The results show that hard 
and soft thresholding are difficult to suppress the noise and keep the speech signal 
 12 
[12] Shung-Yung Lung,: “Wavelet Feature Selection Based Neural Networks with 
Application to the Text Independent Speaker Identification”, Pattern 
Recognition, Vol. 39, August 2006, pp. 1518-1521 
 
 
 
 
 
 
 
 
 
 
the speaker feature training.  Section V presents the 
traditional classifiers (Gaussian mixture model, GMM) 
methodology.    Section VI reports speaker identification 
and simulation results.  Conclusions are drawn in Section 
VII. 
 
 
2.  Wavelet Vector (WV) 
We begin with orthogonal wavelets on R.  Let ϕ  be a 
bounded and compactly supported function on R.  We 
define )2(2)( 2, jxx
kk
jk −= ϕϕ  for all integers k  
and j .  The collection of functions }{ , jkϕ  is called an 
orthonormal wavelet basis.  If for any speech signal f   
∑∑ ><=
k j
jkjkff ,,, ϕϕ                      (1) 
and  
                ∑∑ ><=
k j
jkff
2
,
2
2 |,||||| ϕ                     (2)   
 
Associated with ϕ  is a scaling function φ , from 
which one generates the signals 
)2(2)( 2, jxx
kk
jk −= φφ .  The set }{ , jkφ  is 
orthonormal for each k .  With these signals jk ,φ , we 
have 
∑∑∑ ><+><=
l
lklk
k j
jkjk fff ,,,, ,, φφϕϕ            
(3) 
and  
                 
∑∑∑ ><+><=
l
lk
k j
jk fff
2
,
2
,
2
2 |,|,||||| φϕ                                                
(4)  
for all integer l .  
 
  We assume that for a given scaling function φ , there 
exists a finite sequence ( nh ) such that ∑=
n
nnh ,1φφ  
and ∑=
n
nng ,1φϕ , where 11)1( +−+−= nnn hg .  For 
details, see, e.g., [2, 7]. 
 
As a first step, assume Vxui ∈)(  and Vx ~)( ∈ϕ . Thus, 
it is desirable that the basis that spans V~  has piecewise 
polynomial approximation capabilities equal to V .  
Assuming Vxui ∈)( , we thus have )()( xDxu φ= , 
)( xluu iil Δ= , and 1−−=Δ kk xxx .  Since the primary 
scaling functions are interpolating, the coefficients ilu  are 
just samples of )(xu .  The detail can be seen in Ref [1]. 
 
3.  3-D Adaptive Fuzzy C-means Algorithm 
(3-D AFCM) 
In this section, we generalize the AFCM [12] objective 
function to 3-D speaker data volume [15] and describe an 
algorithm for minimizing the objective function.  
The data we wish to compress are from a digit 
sequence where each data is 10 256 elements in matrix, 
and the 20 matrix for each speaker.  For each speaker, the 
total sizes are 10*256*20.  This defines a tri-dimensional 
data space (x, y and z).  To reduce the number of initial 
regions, the 3-D data space can be split into regions such 
that the value in each region is closely approximated by a 
3-D polynomial. 
 
First, we consider the entire data sequence, trying to 
approximate it by a single polynomial.  As the speaker 
data sequence does not usually have a homogeneous 
volume, its approximation by one polynomial is not 
usually acceptable, resulting in a large approximation 
error.  If that is the case, the entire data space is split in 
the three directions (x, y and z) to get 8 smaller volumes, 
and the approximation is performed on each of those 
volumes.  If the approximation error is too high for a 
given volume, the volume is split again, and so on.  The 
process stops when the approximation error for each sub-
volume is lower than a predefined value.  The resulting 
sub-volumes will then be consider as initial regions 
 
  If the gain field is assumed to be a scalar field 
g
, then 
we use the following objective function [2]: 
           
∑∑∑∑
∑∑∑
∑∑
Ω∈ = =
Ω∈ =
Ω∈ =
+
+−=
j
R
r
R
s
jsr
P
i
jj
R
r
r
P
i
j
C
k
kjj
q
jkAFCMV
gDD
gD
vgyuJ
1 1
2
2
2
1
1
2
1
)**(                
)*(               
λ
λ
                              
                                                                                       (5) 
This equation is applicable to 2-D speaker data when 
R =2 and to 3-D speaker data when R =3.  Here, Ω  is 
the set of voxel location in the speaker data domain, q  is 
a parameter that is constrained to be greater than one, 
jku  is the membership value at voxel location j  for 
class k .  The total number of classes C  is assume to be 
known. Where rD  is a known finite difference operator 
along the rth dimension of the speaker data.  The notation 
jgD )*(  refers to the convolution of g  with the kernel 
D  and taking the resulting value at the jth data. The 
notation j
G
 is a diagonal matrix whose entries are equal 
)}()(
2
1exp{
||)2(
1)(
,
1
,,
2
1
,
2
1
ijtjij
T
ijtj
ij
tji
uyuy
yb
−∑−−
∑
=
−
π  
with mean iju , and variance matrix ij ,∑ . 
 
The mixture weights satisfy the constraint that 
∑∑
= =
=
K
j
M
i
ij
j
p
1 1
, 1 .  In here, we assume that the mixture 
number in each cluster is constant and same: 
MMM K ===L1 . 
 
The parameter set λ  is obtained by maximizing the 
likelihood function (13).  The λ  could not be solved 
directly.  However, it can be obtained iteratively using 
EM algorithm [16].  Each iteration consists of expectation 
step (E-step) and maximization step (M-step). 
 
  E-step: compute the expected value of the complete log-
likelihood, conditioned on the data and the current 
parameter estimate, 
∑∑∑
∑∑∑
= = =
= = =
+=
=
K
j
M
i
T
t
tiijt
K
j
M
i
T
t
tt
j j
j
jj
j j
j
jj
yppyijp
yijpyijpQ
1 1 1
,
1 1 1
)}(log){log,|,(            
)|,,(),|,();(
λ
λλλλ
 
where λ  is an initial model and λ  is a new model to 
estimate. 
  M-step: the new model parameters is estimated by 
maximizing the expectation of log-likelihood as  
);(maxarg λλλ Q=  
 
  In EM algorithm, the new model becomes the initial 
model for the next iteration and the process is repeated 
until some convergence threshold is reached. 
 
 
6. Experiment results   
Several speaker recognition experiments were performed 
to evaluate the various data compression method.   The 
experimental can be subdivided into three parts: data 
compression ratio, computation time, and recognition 
rates. 
I. Compression Ratio: Data redundancy is a central issue 
in speaker data compression.  If 1n  and 2n  denote the 
number of information carrying units in two data sets that 
represent the same information, the compression ratio, is 
2
1
n
nCR = .  In our problem domain, the sizes of 1n  is 
51200 ( 2025610 ×× ) units and 2n  is about 16000 
units, implying significant compression ratio 2.3≈RC  
 
II. Computation Time:  Table 2-A shows the effect of 
speaker data compression algorithm on average time 
required.  Table 2-B shows the effect of intra-speaker 
covariance on average time required. Table 2-C shows the 
effect of inter-speaker covariance on average time 
required. Table 2-D shows the effect of eigenvectors on 
average time required.  The results show that the 3-D 
AFCM WT has faster than other methods.  
 
Table 2.  Average time (Milliseconds) by pentium-V 
 
III. Recognition Rates: For speaker recognition 
experiments, the results for four methods are reported in 
Table 3.  In a comparison between WT, 2-D AFCM WT, 
and 3-D AFCM WT, the correct classification rates are 
89% for WT, 85% for 2-D AFCM WT , and 93% for 3-D 
AFCM WT.  The best recognition rate of 3-D AFCM WT 
obtained was 93%. 
Table 3.  Speaker recognition rates 
  
7.  Conclusion 
We have presented a speaker 3D data compression 
algorithm for text independent speaker recognition.  The 
algorithm is fully automated, except for the initial 
specification of some parameters.   
 
We showed the role that 3D data compression can play in 
determining how to segment and compression the 
different speaker sources of wavelet feature. 
 
Experimental results show that the performance of this 
system is very good.  Not only are the small memory 
space and little computation required, in the speaker 
identification system, but, more importantly, it shows 
strong robustness on noisy sources. 
 
 
 
 
method 
Type    
WT [12] 2-D AFCM 
WT [12]  
3-D AFCM 
WT 
A 0 1080 410 
B 280 200 90 
C 300 140 110 
D 490 270 150 
                      Dim      
 method  
16 24 32 
WT [12] 78% 83% 89% 
2-D AFCM WT [12] 84% 87% 91% 
3-D AFCM WT 86% 89% 93% 
