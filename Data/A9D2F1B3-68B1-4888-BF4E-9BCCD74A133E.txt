結案報告 
一、 前言 
最佳化這個問題一直為各個領域所追求的目標，而最佳化理論與演算法是一
個重要的數學分支，其所研究的問題是討論在眾多的方案中，什麼方案是最佳的，
以及如何找出最佳的方案。這類的問題普遍存在於各個領域中。最佳化是個古老
的課題，長期以來，人們對最佳化問題進行探討和研究由於科學研究突飛猛進的
發展，特別是電腦日益廣泛的應用，使最佳化問題的研究不僅成為一種迫切需
要。 
最佳化理論一般是應用在數學的結果或是數值方法中，但隨著科技的進步，
漸漸也將工程上的問題藉由最佳化的理論，來尋找出最佳的設計方法，或是如何
能夠節省最多的成本。因此，最佳化的方法的進展也影響著工程上的突破。因此，
最佳化理論演算法的發展，形成一個新的科學，最佳化理論和尋優演算法在實際
應用中正在發揮越來越大的作用。 
由於最佳化問題的可能解集合空間往往相當大，而且無法找到多項式時間可完成
(NP‐complete)的演算法，因此在本計畫中使用一啟發式(heuristics)搜尋機制，粒
子群優(Particle Swarm Optimization, PSO)演算法，以期在可接受時間內找到次佳
解(sub‐optimal)，甚至最佳解。 
二、 研究目的 
近年來，從國際上的學術研討會可以發現，多目標的問題越來越受到重視，
也越來越多的相關研究不斷出現，從先前的利用基因演算法，到最近的粒子群聚
最佳化演算法，甚至類免疫系統(Immune System)演算法，都一直是大家研究的對
象。關鍵仍然在於如何擴大在搜尋時的空間(Search Space)，以及收斂的速度，當
然解的好壞更是最基本的要求。 
本計劃的研究目的在於設計出有效的方法，挑選適合的 Local Guide，以利找
到更多不受支配的解(non‐dominated  solution)，而且能夠分布均勻的在 Pareto 
Front上。在許多研究都指出，在多目標最佳化的過程中，要決定如何選擇 global 
best  是困難的，選擇的結果會影響最後結果的好壞。最後，當一群最佳解被演
算法尋得之後，如何在有限的資料中保存具備特色的解，以利正確的描繪出
Pareto front。 
就對族群依據不受支配的特性做排序，並給予較好的不受支配解依被支配的程度
擁有不同的適應值，並可在 NSGA的執行過程，使解朝向 Pareto‐optimal Front  移
動，不過因為沒有提出保持解的差異性之機制，使收斂不穩定常會發生搜尋的解
過於集中同一區域的結果。 
Horn 等人亦於 1994 年提出計算利基的 Pareto 基因演算法(Niched  Pareto 
Genetic Algorithm, NPGA) [6]，與前述的 VEGA、WBGA及 NSGA在選擇的機制有明
顯的不同，NPGA採用一種二元競賽式的選擇  (binary tournament selection)  而不
需再給定一個精確的適應值，NPGA是第一個提出使用競賽式選擇的MOGA演算
法，但是對於較多目標的最佳化問題，NPGA會出現計算效率的問題。 
此後，其他基於前述架構加入的機制，例如菁英策略  (elitism)  及外部暫存
器  (external memory or archive)等陸續被提出，如 Zitzler和 Thiele在 1999年提出
的強化式 Pareto遺傳演算法(Strength  Pareto  Evolutionary  Algorithm,  SPEA)  [7]。
SPEA 利用明確的保留菁英策略，額外儲存一組不受支配解的族群，每個世代新
找到的不受支配解與外部儲存的不受支配解做比較，並保留較好的解。 
Joshua  D.  Knowles 等人於 2000 年提出 Pareto 空間演化策略(Pareto  Archive 
Evolution Strategy, PAES) [8]，PAES採用(1+1)  演化策略  (Evolution Strategy, ES)，以
一組固定大小的外部暫存器存取目前為止找到的不受支配解。在演化的過程，將
搜尋空間切割為許多區塊，藉由同一區塊中鄰近解的數量，決定子代是否在下世
代取代原先的母代，以保持解的差異性。因此，如何決定外部暫存器的大小及區
塊切割的大小是 PAES 面臨的困難點；當目標函數增加時切割空間將呈現指數的
成長，更加難以保持解的較佳延展性。 
Zitzler 和 Thiele 在 2001 年提出 SPEA 的第二代強化式 Pareto 遺傳演算法
(Strength Pareto Evolutionary Algorithm 2, SPEA2) [9]，增加了改進 SPEA的給定適應
值的架構，包含將被支配及支配的解都納入計算，並加入計算附近解的密度，使
得在尋找解的過程中可以有更多的精確引導。SPEA2 承繼 SPEA 的優點，當找到
一個新的落在 Pareto‐optimal front上的解就儲存在外部的族群中，在過程中的聚
集方法可以使外部儲存的解有更好的延展性。但是，如同 MOGA 所擁有的問題
一般，擁有相同排序的不受支配解，並不會擁有同等的地位。 
Deb 在 2002 年提出 NSGA 第二代的不受支配解排序的基因演算法
(Nondominated Sorting Genetic Algorithm II, NSGA‐II) [10]，NSGA‐II為一個同時擁有
菁英保留及明確的保持差異性機制的演算法，在產生大小為 N的子代後，與原本
最後的目的是要藉由這組解的集合來描述最後的 Pareto front，因此在粒子搜尋的
過程中，建立一個外部儲存空間保留搜尋到的不受支配解，但是儲存空間的容量
不可能沒有限制，因此必須挑選出最必要儲存的內容。而後，Coelle 在 2006 年
又針對演化式多目標最佳化(evolutionary  multi‐objective  optimization)[17]做了廣
泛的討論，對於兩個或兩個以上互相衝突的最佳化問題，皆屬此問題的討論範
疇。   
而 Ho 和 Tay 在 2008 年，利用組合式演化演算法[18]建構出一個多目標最佳
化局部搜尋的機制(guided local search, GLS)，並且將其應用在 Job‐shop scheduling
的應用中。在該論文中，使用了隨機區域搜尋(random local search)來搜尋鄰近的
解，並且利用其提出的 GLS來加速對於 Pareto‐optimal solutions 的收斂速度。 
四、 研究方法 
為了增進多目標最佳化演算法的效能，本計畫針對以下幾個研究來深入探
討： 
Local Guide 的選擇 
取代原先的 Sigma Method，採用類似氣體擴散式的方法來搜尋 local guide。
希望藉由此機制，來達成更廣的搜尋進而描繪出真正的 Pareto  Front，而不是向
原點集中。 
分布均化的問題 
將原先在MOGA所使用的 sharing function  及 niche count  來提昇MOPSO最
後的分布性。延續前人對 PSO應用在多目標最佳化的研究，而提出新的選擇 local 
guide 的機制，使得演算法能夠找出較好的不受支配的解，並且這些解能夠均勻
的分布在 Pareto  Front 上。Sigma  所採取的方法由原點向各個 non‐dominated 
solution 延伸，取最相近的 sigma值的 non‐dominated solution 來做為這個粒子的
local guide 以此來計算出下一個時間飛行後的位置，如圖 3.1所表示的。Sigma與
其他先前所提出的研究比較起來，具有較佳的分佈性，但在非連續的目標函數上，
表現就比較差。而本研究所採取的方法為一個類似擴散效應的方法來尋找 local 
guide，藉由類似氣體擴散的概念，利用現有所搜尋到的 non‐dominated  solution
中，計算出一個接近分佈情況的圓心，並由圓心向各個 non‐dominated  solution
來延伸，試圖將 Pareto Front的邊界描繪的更加完整。 
聚類機制 
  雖然外部暫存器可以保留所有已搜尋到的互不支配的解，但在 Pareto  front
為連續性的情況可能造成計算與比對的龐大負擔。因為連續性的 Pareto  front 有
無限多組最佳的互不支配的解組合，有可能發生互不支配的每個解在解空間都非
常接近，使得原本只需少量解的組合便可描繪出的 Pareto  front 充斥大量極度相
似解的組合，每代演化過程搜尋到的最佳解都必須與外部暫存器保留的大量相似
解逐一比較，如此勢必在解的比較工作耗費更多時間。基於前述的理由，提出聚
類機制的構想，以便適當的剔除存於外部暫存器中太過於相似的解，如此有助於
降低計算時間且不會影響 Pareto front的分布特性。 
Pbest與 Gbest的定義 
  傳統單目標 PSO，Pbest 代表該粒子走過路徑中最佳的一組結果，而 Gbest
代表所有 Pbest中最好的一組解。但是多目標 PSO目標函數的維度增加，解與解
之間並不一定有絕對的優劣之分(有可能為互不支配的關係)，於是一個粒子的
Pbest 不一定只有一個，因為該粒子過去得到的解中，極可能有多組世代的解彼
此互不支配，因此在多目標最佳化的問題 Pbest可以有各種不同的方式定義，同
理 Gbest 也是一樣。良好的 Pbest 與 Gbest 的定義可使粒子較快收斂至真正的
Pareto front附近，並且可以避免搜尋到的解過於聚集在同一處或是某些部份的解
過於疏散；反之若定義不適當，則有可能需要花費較多的時間才能達到所需的要
求，或是由於影響搜尋機制造成的缺陷會使某些特殊解極難被搜尋出來。 
擾動機制 
  單目標 PSO的目標單一，所以每個粒子的每個變數都有一個固定的搜尋方向。
因此，除了粒子與粒子間整組變數同時學習的方式外，尚有其他的學習方法在多
組粒子間只取同一維度的變數互相學習，其原理皆由於目標單一，無論從粒子或
變數維度的觀點來看，收斂方向皆只有一個。 
        但是上述的學習方法在多目標 PSO並不可行，因為解與解之間除了優與劣的
分別外，尚存在互不支配的可能關係，若解與解之間的關係為互不支配，則二組
解中同一維度的變數值或許會不同，但想分辨其優劣卻是很困難的事，因為不同
的變數數值或許有助於解空間某一維度的需求，但是也可能劣化解空間的其他維
度，所以針對單一維度之間的互相學習是無意義的。因此，粒子之間的學習還是
只能依照整組變數同時學習的方式，而此方式雖能保證學習的解會進步，但並不
參考文獻 
[1] J. D.  Schaffer, Multiple Objective  Optimization  with  Vector  Evaluated  Genetic 
Algorithms, Ph.D. thesis, Vanderbilt University, 1984. 
[2] J. D.  Schaffer,  “Multiple  objective  optimization with  vector  evaluated  genetic 
algorithms,”  in  proceeding  of  the  First  International  Conference  on  Genetic 
Algorithms, pp. 93‐100, 1985. 
[3] P.  Haiela  and  C.  Y.  Lin,  “Genetic  search  strategies  in  multi‐criterion  optimal 
design,” Structural and Multidisciplinary Optimization, vol. 4, no. 2, pp. 99‐107, 
1992. 
[4] C.  M.  Fonseca  and  P.  J.  Fleming,  “Genetic  algorithms  for  multiobjective 
Optimization: Formulation, discussion and generalization,” in proceeding of the 
Fifth International Conference on Genetic Algorithms, pp. 416‐423, 1993. 
[5] N.  Srinivas  and  K.  Deb,  “Multiobjective  optimization  using  nondominated 
sorting  in  genetic  algorithms,”  Evolutionary  Computation,  vol.  2,  no.  3,  pp. 
221‐248, 1994. 
[6] J. Horn, N. Nafpliotis and D. E. Goldberg, “A niched pareto genetic algorithm for 
multiobjective  optimization,”  in  proceeding  of  IEEE  World  Congress  on 
Computational Intelligence, vol. 1, pp. 82‐87, 1994. 
[7] E. Zitzler and L. Thiele, “Multiobjective evolutionary algorithms: A comparative 
case  study  and  the  strength  pareto  approach,”  IEEE  Transactions  on 
Evolutionary Computation, vol. 3, no. 4, pp. 257‐271, 1999. 
[8] J. D. Knowles and D. W. Corne, “Approximarting the nondominated front using 
the pareto archived evolution strategy,” Evolutionary Computation, vol. 8, no. 2, 
pp. 149‐172, 2000. 
[9] E. Zitzler, M.  Laumanns and  L. Thiele,  “SPEA2:  improving  the performance of 
the  strength pareto evolutionary algorithm,” Technical Report 103, Computer 
Engineering and Communication Networks Lab (TLK), Swiss Federal Institute of 
Technology (ETH) Zurich, 2001. 
[10] K. Deb, A. Pratap, S. Agarwal and T. Meyarivan, “A fast and elitist multiobjective 
genetic algorithm: NSGA‐II,” IEEE Transactions on Evolutionary Computation, vol. 
以黃金切割與禁忌搜尋為基礎之基因演算法 
                 謝昇達                             徐裕隆 
        亞東技術學院 通訊工程學系      亞東技術學院 資訊與通訊工程研究所 
        E-mail: fo013@mail.oit.edu.tw       E-mail:980130116@mail.oit.edu.tw 
 
摘要 
 本論文提出了一個以黃金切割搜尋法
(Golden Section Search)與禁忌搜尋法(Tabu Search)
為基礎的基因演算法(Genetic Algorithm)。其原理
是將基因演算法演化完成後的最佳解，導入黃金切
割搜尋法與禁忌搜尋法來改善傳統的基因演算對
於解空間搜尋效率不佳的缺點。論文的實驗中採用
了 CEC Benchmark 2005測試函數，藉以比較本論
文所提出的方法與既有方法之間搜尋特性。由實驗
結果得知，相較於其他演算法，本論文所提出的方
法對於搜尋全域最佳解的問題效率更高且收斂速
度更快。 
關鍵詞：實數基因演算法，禁忌搜尋法，禁忌實數
基因演算法，黃金切割搜尋法 
Abstract 
In this paper, a new variant of genetic algorithm 
is proposed. It combines both golden section search 
and tabu search concepts named Golden-section and 
Tabu Search based Real-parameters Genetic 
algorithm (GTS-RGA). The proposed method can 
improve search ability of genetic algorithm to obtain 
more optimal solutions in solution space. In the 
experiments, the CEC benchmarks 2005 are adopted 
for comparing the proposed method with related 
works. From the results, it can be observed that the 
proposed method exhibits higher efficiency and rapid 
convergence for solving global optimization 
problems. 
Keywords ： Real-parameters Genetic Algorithms, 
Tabu Search, Golden Section Search 
1. 前言 
 基因演算法(Genetic Algorithm, GA)是解決全
域最佳化的方法，並已廣泛的應用於各種領域 
[6]。基因演算法的基本概念是由 John  Holland 於
1975年首先提出，是基於自然選擇過程的一種最佳
化搜尋機構。其基本精神在於仿效達爾文「進化論」
為基礎發展出來的「適者生存；不適者淘汰」，生
物界中物競天擇、優勝劣敗的自然進化搜尋法則
[11]。從初始族群中選擇具有較好特性的母代，再
經由複製、交配、突變三大機制產生下一代新的子
代族群(population)[1]。在1996年 Tazawa [12]所提
出的基因演算法雖然具有極佳之全域搜尋能力，但
對於最佳局部解的搜尋效率不高，並且還有提早收
斂的現象，族群大小會影響收斂與結果如族群大則
收斂速度慢，反之族群小則容易掉入局部最佳解和
收斂速度快。而禁忌搜尋法(Tabu Search, TS) 是在
1977年由 Glover 在時提出，他是屬於為一種萬用
的啟發式演算法，用於解決組合最佳化問題，其所
搜尋的解與一般區域搜尋法最大的差別是它可接
受比目前最佳解還差的解，這樣的方式得以讓搜尋
跳脫出區域最佳解，而達到全域最佳解[4][7][8]。
例如在圖1 的最小化問題中設定的起始解為 xi，而
它的最佳鄰近解為 xlocal，因為在 xlocal 的所有鄰近
解 M(xlocal)中沒有辦法找到比目標函數值 f(xlocal)還
佳的解，但是禁忌搜尋法可以允許往比目前最佳解
還差的解進行移動，所以有可能跳脫出區域最佳解
xlocal，而才能在接下來的搜尋中找到全域的最佳解
xglobal[2][3]。禁忌搜尋法雖然具有很強的局部搜索
能力，但如果初始解不理想而就有能缺乏全局搜索
能力[14]。 
 
 
  
 
 
 
 
 
 
 
v
 
圖 1. 禁忌搜尋法基本原理 
 由於求解最佳化問題的過程中，如何有效的改
善演算法在解空間搜尋能力不佳的缺點，一直是值
得探討的議題。本論文在基因演算法的每ㄧ次演化
完成後，再導入黃金切割搜尋法來改善族群大小的
問題並結合禁忌搜尋法來記憶過去走過的路徑，改
善傳統的基因演算的局部搜尋能力。 
2. 傳統基因演算法 
 傳統基因演算法有以下特點：(1)初始化及編碼
(2)計算適應值評估(3)複製良好的母代(4)交配產生
新的子代(5)突變跳脫局部最佳解，分別說明如下： 
 (1)個體編碼方式(Coding of Individual) 
 本文是使用實數型基因演算法，因為實數編碼
M(x0) M(xlocal) 
xglobal
xlocal 
xp xi 
f(x) 
Solution space 
???????????? 2010 ?18屆???????用???
714
禁忌名單是用來紀錄過去搜尋中每一次的移
步，作為一個提供禁忌限制的記憶體結構，以避免
搜尋重複所造成的循環。在本論文是所使用的禁忌
名單的記憶結構為長期記憶，過去研究中有Glover 
建議禁忌名單為數字7 [10]。 
(4)鄰近解搜尋(Search of Neighboring Solutions) 
 在基因演算法完成一次迭代後會產生許多新
的個體，這些個體都代表著一個可行解， 在本文
中的鄰近解的計算必須先將所有變數進行擾動
(Perturbation)，擾動的方法是使用增加 /減少法
(Increasing/Decreasing)，即是將某變數增加某定
值，或是減少某定值，以得到新的目標函數值。 
PXX '               (6) 
其中 P 表示為一隨機值或權重值，在本論文設定
為變數值的 1% ~ 10%，且在執行擾動之前本文預
先隨機產生一個 0 ~ 1 之間的變數 r，若變數 r < 
0.5 則執行減去法；反之，若變數 r ≥ 0.5 時程式
則執行增加法。 
(5)候選解名單 (Candidate List)  
將擾動產生的變數帶回原目標函數中即成為
該個體的一個候選解，而所有候選解的集合減去所
有禁忌名單中的解，就稱為候選解名單。本論文從
候選者名單中選出來的候選最佳解還必須跟該個
體由基因演算法求出的解做比較，如果優於基因解
則該解可直接取代基因解，反之，則保留原基因
解。 
(6)停止原則（Stopping Criterion）  
在停止條件的設定中，為了公平與客觀起
見，設定適應函數的計算次數(Fitness Evaluations, 
FEs )做為停止條件。 
 
本論文演算法詳細流程圖如圖5所示，各步驟說
明如下： 
步驟一：開始先設定初始值：族群大小、交配率、
突變率等的參數。 
步驟二：定義目標函數適應值及變數範圍。 
步驟三：執行基因演算法複製、交配、突變。 
步驟四：完成基因演算法產生出新的族群與執行黃
金切割法選擇良好族群當作起始解。 
步驟五：搜尋附近的鄰近解，並且找出鄰近解中最
佳的解，且必須不在禁忌解之中。 
步驟六：移步到該解上並且更新禁忌名單。 
步驟七：判斷解是否優於原先基因演算法所求出的
基因解。  
步驟八：是否達到終止條件?若否則返回步驟三。 
 
 
圖 5. 黃金切割禁忌基因演算法流程圖 
開   始 
初始化設定參數及目標函數 
計算適應含數值 
複製 
交配及突變 
評估所有鄰近解找出 
(1)最佳鄰近解(2)非禁忌解 
移步 
更新禁忌表 
黃金切割法選擇 
是否優於各族群現解 
採用 TS 解 採用 GA 解
是否達到終止條件 
結束 
是 
是 
否 
否 
???????????? 2010 ?18屆???????用???
716
表 2. 測試函數 
測試函數 測試目標函數 搜尋範圍 參考最佳解 
f1 


N
i
ixf
1
2
1  ix  [-100, 75] 0 
f2    

 

 
1
1
22
1
2
2 1100
N
i
iii xxxf  ix  [-2.048, 1.048] 0 
f3 


N
i
iii xxxf
1
22
3 )10)2cos(10(   ix  [-5.12, 3.5] 0 
f4 

 





Ni
i
i
xround
i
i
N
i
iii
x
xx
y
yyyf
i ,...,2,1for 
2
1
2
1
2
)2(
1
22
4 )10)2cos(10( 
 ix  [-5.12, 3.5] 0 
f5 
ex
N
x
N
f
N
i
i
N
i
i

















20)2cos(1exp
12.0exp20
1
1
2
5

 ix  [-32.768, 25] 0 
f6  
 




N
i
N
i
ii
i
xxf
1 1
2
6 1cos4000
 ix  [-600, 500] 0 
f7  


N
i
ii xxNf
1
7 sin9829.418  ix  [-500, 400] 0 
f8 
 
 
20max,3.0,5.0
)5.02cos(
))05(2cos(
max
0
1
max
0
8





 

 

 
kba
baN
xbaf
k
k
kk
N
i
k
k
i
kk


 ix  [-0.5, 0.35] 0 
 
表 3. 實驗結果 
測試函數 RGA GTS-RGA TS-RGA 
f1 4.08×103 10.23 2.76×103 
f2 214.1 76 157.22 
f3 87.33 52.01 69.68 
f4 54.29 38.57 79.35 
f5 14.19 12.02 14.03 
f6 36.65 3.33 27.7 
f7 3670 2390 3480 
f8 12.94 7.76 12.95 
???????????? 2010 ?18屆???????用???
718
Sharing Mutation Genetic Algorithm for Solving 
Multi-objective Problems 
 
Sheng-Ta Hsieh 
Department of Communication Engineering 
Oriental Institute of Technology 
New Taipei City, Taiwan, R.O.C. 
fo013@mail.oit.edu.tw 
Shih-Yuan Chiu and Shi-Jim Yen 
Department of Computer Science and Information 
Engineering 
National Dong Hwa University 
Hualien, Taiwan, R.O.C. 
 
 
Abstract—Multi-objective optimization (MO) has been an active 
area of research in last two decade. In multi-objective genetic 
algorithm (MOGA), quality of new generated offspring of 
population will affect the performance of finding Pareto optimum 
directly. In this paper, an improved MOGA is proposed named 
SMGA to solving multi-objective optimization problem. For 
improving solution searching efficiency, an effective mutation 
named sharing mutation is adopted for generating potential 
offspring. Experiments were conducted on CEC-09 MOP test 
problems. The results showed that the proposed method exhibits 
better performance when solving these benchmark problems 
compared to related multi-objective evolutionary algorithm 
(MOEA). 
Keywords-genetic algorithm, multi-objective, optimization, 
sharing mutation. 
I.  INTRODUCTION 
Multi-objective optimization (MO) problems contain more 
than one objective that needs to be achieved simultaneously. 
Such problems arise in many applications, where two or more, 
sometimes conflict and/or incommensurable objective 
functions have to be minimized concurrently.  
In such problems, there is no single optimal solution instead 
a set of potential solutions in one of the objectives will be 
involved to improve other objectives. Due to the multi-criteria 
nature of MO problems, the “optimal” of a solution needs to 
be redefined. Such set of potential solutions are called Pareto-
optimal or non-dominated solutions to multi-objective 
optimization problems (MOPs). In contrast to the single–
objective optimization case, MOPs are characterized by trade-
off. 
A solution x1 is said to dominate the other solution x2, if both 
statement below are satisfied.  
y The solution x1 is no worse than x2 in all objectives. 
y The solution x1 is strictly better than x2 in at least one 
objective. 
The plot of the objective function whose non-dominated 
vectors are in the Pareto optimal set is called the Pareto front. 
II. RELATED WORKS 
Many evolution-based MO algorithms have been proposed 
in last two decades. Hajela and Lin proposed a Weight-based 
Genetic Algorithm (WBGA) [1], which gives a weighted 
value for each objective function, and accumulates them as the 
fitness value. This algorithm possesses simple concepts, but 
performed worse when the optimal solutions are distributed as 
non-convex Pareto graph. The Multi-Objective GA (MOGA) 
[2] was proposed by Fonseca and Fleming. The found non-
dominated solutions are classified and then ranked to enhance 
the searching abilities for finding non-dominated solutions, 
and to maintain the diversity of the found solutions. But it 
cannot ensure that a solution with a worse rank will always be 
mapped to a worse fitness value. This will give the algorithm 
slower convergence and more instability. Later, Srinivas and 
Deb proposed a Non-dominated Sorting Genetic Algorithm 
(NSGA) [3], which ranks populations according to its 
characteristic of non-domination, and gives higher fitness 
values for better non-dominated solutions. The Niched Pareto 
Genetic Algorithm (NPGA) [4] was proposed by Horn et al.  It 
introduced a binary tournament selection but does not assign a 
definite fitness value, but problems with more optimized 
objectives will influence the computational efficiency of 
NPGA. 
Several efficient strategies were then introduced based on 
these algorithms, such as Elitism, external repository, or 
archive. Zitzler and Thiele proposed the Strength Pareto 
Evolutionary Algorithm (SPEA) [5], which introduced an 
elitism strategy to store an extra population that contains non-
dominated solutions. New found non-dominated solutions will 
be compared with the extra stored population, and the better is 
kept. The SPEA2 [6] is an advanced version of SPEA. SPEA2 
inherited the advantages from SPEA and improved fitness 
assignment to take both dominated and non-dominated 
solutions into account. SPEA2 also considered neighboring 
solutions’ diversity to produce more capable guides.  Similar 
to MOGA, all these approaches have the same problem; the 
non-dominated solutions with the same ranks may not have 
the same status. In [7], Knowles et al. proposed Pareto 
Archive Evolution Strategy (PAES), which employs (1+1) 
1833978-1-4244-7835-4/11/$26.00 ©2011 IEEE
E. Selection 
After cross-over and mutation operations, all chromosomes, 
including parents and offspring in a population, will be larger 
than the initialization. In order to produce better offspring, the 
elitism operation is adapted to select p better chromosomes 
which will survive in next generation.  
The GA optimization is combined with operations 
mentioned above and repeats the evolution process until it 
reaches the pre-defined terminated conditions. 
IV. PROPOSED METHOD 
Although there are numerous approaches of MOGA, 
premature convergence, diversity and solutions located 
on/closer to the Pareto front when solving MO problems are 
still the main deficiency. In MO problems, more than one 
conflicting objectives need to be optimized simultaneously. 
Thus, non-dominated solutions which are located on/near the 
Pareto front will be more than one. Each non-dominated 
solution can provide its position information to guide current 
population for finding better solutions. 
A. Cross-over operations 
In general, cross-over operation in GA is to generate new 
(better) offspring (chromosomes) based on their parents. It is 
to combine two chromosomes’ information which was also 
generated by chromosomes in a previous generation and 
evaluated by the cost function. Finally, the better 
chromosomes will be kept in the population. If a chromosome 
discovers a new probable solution, its offspring will move 
closer to it to explore around the region deeply in following 
cross-over process.  
Thus, in this paper, both the exploration and the exploitation 
are adopted to generate new offspring [14]. Due to the 
exploitation will restrict the searching range and make it 
smaller, but the exploration will extend the searching range. 
The exploration and exploitation cross-over strategies are 
showed in Fig. 1. 
Figure 1. Exploration and exploitation cross-over strategies 
The cross-over operation of proposed MOGA is that all the 
genes, N-dimensions, are involved to produce new 
chromosomes. Each pair of parents will produce 2 offspring 
which are generated by either exploration or exploitation 
randomly.  
B. Sharing Mutation 
In general, mutation is adopted to generate new 
chromosomes, mutate one or more genes, to avoid 
chromosomes that fell into the local optimum. It can help 
population to explore other potential searching spaces and to 
produce more potential solutions. Furthermore, it can also 
explore unsearched solution space. Thus, performance of 
mutation will affect solution searching directly.  
In order to improve mutation, the sharing mutation (SM) is 
adopted for increased efficiency while exploring solution 
space. The proposed sharing mutation can be classified into 
two versions: local sharing and global sharing. The activating 
probability of local and global sharing is 2 to 1. The main 
difference between the local sharing mutation and global 
sharing mutation is dimension selection. 
For the local version of sharing mutation, one of the 
dimensions will be picked randomly; the mutating 
chromosome’s corresponding dimension will be perturbed and 
restricted as this dimension’s solution for all chromosomes. 
For example, a randomly selected dimension (d1) of the 
chromosome i will be perturbed in the range between 
],[
maxmin 11 dd
SS , where
min1d
S and 
max1d
S are the minimal and 
maximal solution of d1 of all chromosomes respectively. In 
other words, the local version is the sharing of searching 
ranges of selected dimensions among chromosomes to 
efficiently generate new solutions. This will ignore other 
dimensions but can fine tune the solutions of specific 
dimensions one by one in the chromosome. 
The same principle applies for global version of sharing 
mutation; current chromosome’s dimension d1 will be 
perturbed and restricted as the initial boundary. For example, 
the chromosome i will be perturbed in the range between 
],[ MaxMin XX , where XMin and XMax are the minimal and 
maximal initial boundary respectively. The global version of 
sharing mutation can prevent solutions of a particular 
dimension from being trapped in the local optimum.  
Whether it’s the local version or the global version of 
sharing mutation, they will ignore other dimensions but can 
fine tune the solutions of chosen dimensions one by one in the 
chromosomes. 
The same as generic mutation rate of GA, different mutation 
rates will affect performance of solution exploration directly, 
plus, after numerous generations, chromosomes will gather in 
several clusters, and therefore increase the demands of SM. 
Due to a lower SM activating rate may not be able to rescue 
chromosomes that were trapped into local minimal, and a 
higher one would interfere chromosomes’ convergence deeply. 
To keep better solutions will be found efficiently and also to 
avoid chromosomes perform local search. The concept of 
linearly variation inertia weight for PSO [15][16] is adopted. 
The mutation rate rm for each generation is defined as 
following:  
OC 
C2 
C1 
α(C1-C2) 
(a) Exploration cross-over (b) Exploitation cross-over
C1 
C2
OC 
-α(C1-C2) 
1835
1   [0,1]x[ 1,1]
10, 0.1, 30
nsearch space is
N nε
−
−
= = =                                                   (7)
 
6) Problem 6 
1 1
2 2
1 1 1
2
1
2 1 1
2
2
1 2
1max{0, 2( ) sin(2 )}
2
202   (4 2 cos( ) 2)
11 max{0, 2( )sin(2 )}
2
202   (4 2 cos( ) 2)
{ |     2 }, { |     2 }.
s
i
j
j J j J
i
j
j J j J
j j
f x N x
N
yy
J j
f x N x
N
yy
J j
J j j is odd and j n J j j is even and j n
y x
ε π
π
ε π
π
∈ ∈
∈ ∈
= + +
+ − +
= − + +
+ − +
= ≤ ≤ = ≤ ≤
= −
∑ ∏
∑ ∏
1
1
in(6 ), 2,...,
   [0,1]x[ 1,1]
2, 0.1, 30
n
jx j n
n
search space is
N n
π
π
ε
−
+ =
−
= = =     (8)
 
7) Problem 7 
1
2
25
1 1
1
25
2 1
2
1 2
1
1
2
21
{ |     2 }, { |     2 }.
sin(6 ), 2,...,
   [0,1]x[ 1,1]
30
j
j J
j
j J
j j
n
f x y
J
f x y
J
J j j is odd and j n J j j is even and j n
jy x x j n
n
search space is
n
π
π
∈
∈
−
= +
= − +
= ≤ ≤ = ≤ ≤
= − + =
−
=
∑
∑
     (9) 
8) Problem 8 
1
2
3
2
1 1 2 2 1
1
2
2 1 2 2 1
2
2
3 1 2 1
3
1
2cos(0.5 ) cos(0.5 ) ( 2 sin(2 ))
2cos(0.5 )sin(0.5 ) ( 2 sin(2 ))
2sin(0.5 ) ( 2 sin(2 ))
{ | 3 ,   -1    
j
j J
j
j J
j
j J
jf x x x x x
J n
jf x x x x x
J n
jf x x x x
J n
J j j n and j is a multuplication of
π
π π π
π
π π π
π
π π
∈
∈
∈
= + − +
= + − +
= + − +
= ≤ ≤
∑
∑
∑
2
3
2 2
 3}
{ | 3 ,   - 2     3}
{ | 3 ,        3}
   [0,1] x[ 2,2]
30
n
J j j n and j is a multuplication of
J j j n and j is a multuplication of
search space is
n
−
= ≤ ≤
= ≤ ≤
−
=    (10) 
9) Problem 9 
1
2
3
2
1 1 1 2
2
2 1
1
2
2 1 1 2
2
2 1
2
2
3 2 2 1
3
1
0.5[max{0,(1 )(1 4(2 1) )} 2 ]
2   ( 2 sin(2 ))
0.5[max{0,(1 )(1 4(2 1) )} 2 ]
2   ( 2 sin(2 ))
21 ( 2 sin(2 ))
{ | 3 ,  
j
j J
j
j J
j
j J
f x x x
jx x x
J n
f x x x
jx x x
J n
jf x x x x
J n
J j j n and
ε
π
π
ε
π
π
π
π
∈
∈
∈
= + − − +
+ − +
= + − − +
+ − +
= − + − +
= ≤ ≤
∑
∑
∑
2
3
2 2
 -1     3}
{ | 3 ,   - 2     3}
{ | 3 ,        3}
   [0,1] x[ 2,2]n
j is a multuplication of
J j j n and j is a multuplication of
J j j n and j is a multuplication of
search space is −
= ≤ ≤
= ≤ ≤
−                          
  
30, 0.1n ε= =                                                                       (11) 
10) Problem 10 
1
2
3
2
1 1 2
1
2
2 1 2
2
2
3 1
3
2 1
1
2cos(0.5 ) cos(0.5 ) [4 cos(8 ) 1]
2cos(0.5 )sin(0.5 ) [4 cos(8 ) 1]
2sin(0.5 ) [4 cos(8 ) 1]
2 sin(2 ),  3,...,
{ | 3 ,   -1 
j i
j J
j i
j J
j i
j J
j j
f x x y y
J
f x x y y
J
f x y y
J
jy x x x j n
n
J j j n and j i
π π π
π π π
π π
π
π
∈
∈
∈
= + − +
= + − +
= + − +
= − + =
= ≤ ≤
∑
∑
∑
2
3
2 2
    3}
{ | 3 ,   - 2     3}
{ | 3 ,        3}
   [0,1] x[ 2,2]
30
n
s a multuplication of
J j j n and j is a multuplication of
J j j n and j is a multuplication of
search space is
n
−
= ≤ ≤
= ≤ ≤
−
=                (12) 
B. Parameter Settings and Initialization 
All the MOGA algorithms were implemented using 
MATLAB 2010. The experiments were executed on Core-2 
Quad 2.66 GHz (Hyper Threading function enable) with 4GB 
RAM on Windows 7 professional operating system. The 
MOGAs’ parameters were listed in Table I. 
The maximal Number of Function Evaluations (FEs) is set 
to be 300,000 for all the problems.  Each algorithm was run 30 
times and calculated their mean values and standard deviation 
for the results. The initial and the variation of mutation rate (rm) 
for sharing mutation were set as 0.001 and 0.009 respectively. 
Thus, the SM rate will keep increasing linearly, from 0.001 to 
0.01, while solution searching is in progress.  
TABLE I 
PARAMETERS’ SETTING OF MOGAS 
Parameters 
MOGAs 
Cross-over rate  Mutation rate 
Proposed  
Method 1.0 
vary linearly from  
0.001 to 0.01 
MOEA/D 1.0 0.005 
NSGA-II 1.0 0.005 
C. Performance Metric (IGD) [17] 
Let *P  be a set of uniformly distributed points along the PF 
(in the objective space). Let A be an approximate set to the PF, 
the average distance from *P  to A is defined as: 
*
) ,( 
*) ,( *
P
Avd
PAIGD Pv∑ ∈=   (13) 
where ),( Avd  is the minimum Euclidean distance between 
v  and the points in A. If  *P  is large enough to represent the 
PF very well, *) ,( PAIGD  could measure both the diversity 
and convergence of A in a sense. To have a low value of 
1837
EUROGEN 2001. Evolutionary Methods for Design, Optimization and 
Control with Applications to Industrial Problems, pp. 95-100, 1993. 
[7] J. D. Knowles and D. W. Corne, “Approximarting the nondominated 
front using the pareto archived evolution strategy,” Evolutionary 
Computation, vol. 8, no. 2, pp. 149-172, 2000. 
[8] K. Deb, S. Agrawal, A. Pratab and T. Meyarivan, “A fast elitist non-
dominated sorting genetic algorithm for multi-objective optimization: 
NSGA-II,” in Proceedings of the Parallel Problem Solving from Nature 
VI Conference, pp. 849-858, 2000. Springer, Lecture Notes in Computer 
Science No. 1917. 
[9] K. Deb, A. Pratap, S. Agarwal and T. Meyarivan, “A fast and elitist 
multiobjective genetic algorithm: NSGA-II,” IEEE Transactions on 
Evolutionary Computation, vol. 6, no. 2, pp. 182-197, Apr. 2002. 
[10]  F. Campelo, F. G. Guimaraes and H. Igarashi, “Overview of artificial 
immune systems for multi-objective optimization,” Springer-Verlag 
Lecture Notes in Computer Science, No. 4403,  pp. 937-951, 2007. 
[11] S. Elaoud, T. Loukil and J. Teghem, “The Pareto fitness genetic 
algorithm: Test function study,” European Journal of Operational 
Research 177 (3), pp. 1703-1719, 2007. 
[12] Q. Zhang and H. Li, "MOEA/D: A Multiobjective Evolutionary 
Algorithm Based on Decomposition," IEEE Transactions on 
Evolutionary Computation, vol. 11, no. 6, Dec. 2007.  
[13] S. F. Adra and P. J. Fleming, “Diversity Management in Evolutionary 
Many-Objective Optimization,” IEEE Trans. on Evolutionary 
Computation, vol. 15, no. 2, pp. 183-195, Apr. 2011. 
[14] Z. Michalewicz, T. Logan, and S. Swaminathan, “Evolutionary 
operations for continuous convex parameter spaces,” in Proc. of the 3rd 
Annual Conference on Evolutionary Programming, pp. 84-97, 1994. 
[15] F. van den Bergh and A. P. Engelbrecht, “A cooperative approach to 
particle swarm optimization,” IEEE Transactions on Evolutionary 
Computation, vol. 8, pp. 225-239, Jun. 2004. 
[16] J. J. Liang, A. K. Qin, P. N. Suganthan and S. Baskar, “Comprehensive 
learning particle swarm optimizer for global optimization of multimodal 
functions,” IEEE Transactions on Evolutionary Computation, vol. 10, pp. 
281-296, Jun. 2006. 
[17] Technical Report CES-487, http://www.ntu.edu.sg/home/EPNSugan 
 
1839
The annual IEEE Congress on Evolutionary Computation is one of the leading 
events in the area of evolutionary computation. The conference will be take place at 
Ritz Carlton in New Orleans, USA, from June 5th ~ 8th, 2011. 
IEEE CEC 2011 will feature a world-class conference that aims to bring together 
researchers and practitioners in the field of evolutionary computation and 
computational intelligence from all around the globe. Technical exchanges within 
the research community will encompass keynote lectures, special sessions, tutorials 
and workshops, panel discussions as well as poster presentations. In addition, 
participants will be treated to a series of social functions, receptions, and networking 
to establish new connections and foster everlasting friendship among fellow 
counterparts. The conference covers all topics in evolutionary computation, 
including: 
 Ant colony optimization 
 Artificial ecology  
 Artificial immune systems  
 Artificial life  
 Autonomous mental & behaviour development  
 Bioengineering  
 Bioinformatics & computational biology  
 Classifier systems  
 Coevolution & collective behaviour  
 Cognitive systems & applications  
 Combinatorial & numerical optimization  
 Computational intelligence in games  
 Computer vision  
 Concurrent collaboration  
 Constraint & uncertainty handling  
 Cultural algorithms  
 Developmental systems    
 Differential evolution  
 Distributed evolutionary computation  
 Dynamic & uncertain environments  
 Emerging areas  
    The proposed paper was presented in poster session on Tuesday afternoon, June 
7. During the session of the conference, I met many scholars who come from 
everywhere including Taiwan. Especially, two old friend; Prof. Yen; the president of 
IEEE Computational Intelligence; and Prof. Suganthan were also attendant this 
conference. We talked several minutes and also exchange name card during the 
banquet. 
  
主旨: IEEE CEC 2011 Paper #381 Decision Notification
從: Alice Smith <cec2011@ieee-cis.org>
日期: 2011/3/23 上午 02:41
到: fo013@mail.oit.edu.tw, d9621005@ems.ndhu.edu.tw, sjyen@mail.ndhu.edu.tw
Dear Author(s),
Congratulations! On behalf of the IEEE CEC 2011 Technical Program Committee
and the program chairs, we are pleased to inform you that your paper:
    Paper ID:   381
    Author(s):  Sheng-Ta Hsieh, Shih-Yuan Chiu and Shi-Jim Yen
    Title:      Sharing Mutation Genetic Algorithm for Solving Multi-objective 
Optimization Problems
has been accepted for presentation at the 2011 IEEE Congress on Evolutionary
Computation and for publication in the conference proceedings published
annually by IEEE. This email provides you with all the information you require
to complete your paper and submit it for inclusion in the proceedings.  A
notification of the presentation format (oral or poster) and timing of that
presentation will be sent by mid-April.
Here are the steps you must follow:
1. Please see the REVIEWERS' COMMENTS below for your paper, which are intended
to help you to improve your paper for final publication. The listed comments
should be addressed, as acceptance is conditional on appropriate response to
the requirements and comments.  Please adhere to the formatting instructions
carefully.
2. Please prepare your manuscript for final camera ready submission following
the same PDF format guidelines as for the initial submission. Papers are
limited to eight (8) pages in length or an over length fee will be imposed,
must be IEEE eXpress-compatible, and must follow the formatting instructions
provided at:
    http://cec2011.org/submission.htm 
The PDF file must be the result of processing you paper through IEEE pdf
eXpress:
    http://cec2011.org/pdfexpress.htm
(please use login: cec2011x).
When you have completed your paper and are ready to submit it, please go to:
    http://ieee-cis.org/conferences/cec2011/upload.php?PaperID=381
to submit your final camera-ready paper.  On this page you will need to use
the following password:
IEEE CEC 2011 Paper #381 Decision Notification
1／5 2011/10/26 下午 07:46
promises to be an excellent meeting.
Sincerely, Alice Smith <cec2011@ieee-cis.org>
                          REVIEWERS' COMMENTS
----------------------------------------------
REVIEW NO. 1
Originality:              Accept
Significance of topic:    Accept
Technical quality:        Accept
Relevance to IEEE CEC 2011:Accept
Presentation:             Accept
Overall rating:           Accept
Reviewer's expertise on the topic: Medium
Suggested form of presentation:    Any
Best Paper Award nomination:       No
Comments to the authors:
    I recommend that authors should review previous studies about multi-ojective 
    problems and other techniques as well as genetic algorithm. And then summarize 
    related studies in their paper.
----------------------------------------------
REVIEW NO. 2
Originality:              Neutral
Significance of topic:    Accept
Technical quality:        Weak Reject
Relevance to IEEE CEC 2011:Accept
Presentation:             Weak Reject
Overall rating:           Neutral
Reviewer's expertise on the topic: Medium
Suggested form of presentation:    Poster
Best Paper Award nomination:       No
Comments to the authors:
    The main contribution of this paper is a new mutation method, "Shared Mutation", 
    to improve the performance of the multi-objective genetic algorithms. The 
    proposed mutation method help algorithm fine tune the dimensions one at a time. 
    The authors provides experimental results on the comparison of the new algorithm 
    and the two other algorithms on the ten benchmark problem. 
    
    
    Some parts of the paper were hard to follow. For instance, the first paragraph 
    of the Section III is not very clear. the following statement is not true: 
    "There is only one optimal solution in single-objective problems" There can be 
    multiple optimal solutions for single objective problems. I think, it should be 
    changed as follows: "There is only one optimal solution in unimodal problems". 
    In any case, this statement does not contribute to the argument and probably 
IEEE CEC 2011 Paper #381 Decision Notification
3／5 2011/10/26 下午 07:46
    More information, please.
IEEE CEC 2011 Paper #381 Decision Notification
5／5 2011/10/26 下午 07:46
evolution strategy (ES) and uses a mutation operator for local 
searches. A map of a grid is applied in the algorithm to 
maintain the diversity of the archive. Thus, there will be a 
trade-off to define the size of both the external repository and 
grid of the map. Deb proposed an enhanced NSGA named 
NSGA-II [8][9] which employs a fast non-dominated 
approach to assign ranks to individuals and crowded 
tournament selection for density estimation. In the case of a tie 
in rank during the selection process, the individual with a 
lower density count will be chosen.   
In recent years, many evolutionary algorithm based multi-
objective optimization (MOEA) methods have been suggested 
and developed. In 2007, Campelo et al. [10] suggested that the 
negative selection, danger theory and other immune 
mechanisms may improve the existing MOIAs. In the same 
year, Elaoud et al. proposed Pareto fitness genetic algorithm 
(PFGA) [11]. It modified ranking procedure and a promising 
way of sharing. Zhang and Li [12] proposed an interested MO 
algorithm named MOEA/D. It decomposes a multi-objective 
optimization problem into a number of scalar optimization 
sub-problems and optimizes them simultaneously. Recently, 
for many-objective problem (objectives are more than 3), Adra 
and Fleming proposed diversity management mechanisms [13] 
to investigate solution convergence of such problems. 
Although, mass MO approaches have developed. Solution 
searching efficiency of MO algorithm is still an import issue. 
In this paper, an efficient mutation called sharing mutation 
(SM) is adopted to assist multi-objective genetic algorithm for 
exploring optimal solutions. It can significantly improve 
multi-objective optimizer’s solution searching ability. 
Chromosomes will more capable to find more solutions which 
located on/near to the Pareto front.  
The rest of the paper is organized as follows: in Section II 
describes genetic algorithm briefly, Section III describes the 
proposed method, Section IV presents the experimental results 
and Section V of the paper contains the conclusion. 
III. GENETIC ALGORITHM 
The traditional genetic algorithm (TGA) had following 
features: 
y A bit string representation. 
y Proportional selection. 
y Cross-over is the primary method to produce new 
individuals. 
y Mutation is for disturbing evolution to avoid solutions 
falling into the local search.  
y Elitism policies are used.  
In this section, a brief introduction of genetic algorithm will 
be described. 
A. Chromosome Representation 
Considering that a problem is presented as ( )Nxxxf ,,, 21 …  
which consists of N tunable parameters to be optimized. In GA, 
it can be encoded by vector representation (i.e., chromosome) 
as [ ]mNm xxx ,,, 21 …=C  , pm …,2,1= , where p denotes the 
population size. For high-dimension or complex problems, GA 
will require a larger population for uniform distribution of 
population in the searching space; otherwise it may be unable 
to explore all possible solutions. The value of p is always 
given experimentally. 
B. Initial Population 
For most optimal techniques, the final solutions are usually 
restricted by the initialization. However, GA is able to 
overcome this drawback with the cross-over and mutation 
operation. Therefore, chromosomes can be scatter on an area 
in first generation. The initial population will be used to 
generate p chromosomes which will be distributed over the 
searching space uniformly. 
C. Cross-over 
The cross-over operation is to produce new chromosomes 
(offspring) by choosing two random parent chromosomes, but 
it doesn’t guarantee that all the offspring are better than the 
parent. However, after adopting “exploration” and 
“exploitation” for performing cross-over will obtain good 
results because the offspring will be generated around the 
better parent. The detail of “exploration” and “exploitation” 
are described in Section III-A. The number of individuals 
which will be joined during cross-over is based on a pre-
defined parameter cr  which is called cross-over rate. Thus, 
there will be ( )crpround ×  individuals (parents) joined to 
perform cross-over. 
D. Mutation 
The mutation operator is to randomly change some subparts 
of a chromosome. When GA is learning, the chromosomes 
will move to the nearest optimal solution to itself, but that may 
be not a global optimization. Therefore, some disturbances to 
extend the searching range are quite important. In general, the 
offspring of mutation Om is generated inside the searching 
space randomly as 
α=mO                  (1) 
where α  denotes a mutation vector with random components 
of uniform distribution in searching space. The number of 
parents which joins mutation is based on a predefined 
parameter rm which is called mutation rate. Thus, there are 
( )mrpround ×  individuals (parents) that will be joined to 
perform mutation. 
In general, the fitness of mutated offspring may be better or 
worse than their parents and/or any cross-over offspring. On 
the other hand, adopting the mutation operation will extend the 
searching range in order to explore unsearched area in the 
searching space for finding the potential optimal solution.  
1834
max_gens
*009.0001.0)( ggrm +=   (2) 
where g denotes the generation number and max_gens is 
maximum generations. The probability of mutation will keep 
increasing linearly, from 0.001 to 0.01, while solution 
searching is in progress. 
C. Archive 
The function of the repository controller is to make decision 
for adding certain solutions into the archive or not. The 
decision-making process is stated as follows.  
1. If the archive is empty, any new solution NS found will 
always be accepted and stored in archive (Case 1, in Fig. 
2).  
2. If the new solution is dominated by any individual in the 
archive, then such a solution will be discarded (Case 2, in 
Fig. 2).  
3. If none of the solutions contained in the archive 
dominates the new solution, then such a solution will be 
stored in the archive (Case 3, in Fig. 2).  
4. Otherwise, if there are solutions in the archive that are 
dominated by the new solution, then such dominated 
solutions will be removed from the archive (Case 4, in 
Fig. 2).  
Finally, after updating all non-dominated solutions, the 
cluster procedure will then be activated to eliminate similar 
solutions for keeping lower diversity of non-dominated 
solutions. 
 
Figure 2. Possible Cases for Archive Controller 
V. EXPERIMENTS 
A. Test Functions 
Several unconstrained (bound constrained) MOP test 
problems of CEC 2009 technic report [17] were adopted for 
testing proposed method and compare it to MOEA/D [12] and 
NSGA-II [9]. All the test problems are listed as follows: 
1) Problem 1 
1
2
2
1 1 1
1
2
2 1 1
2
1 2
-1
2 sin(6 )
21 sin(6 )
{ |     2 }  { |     2 }
   [0,1] [-1,1]
30
j
j J
j
j J
n
jf x x x
J n
jf x x x
J n
J j j is odd and j n and J j j is even and j n
search space is x
n
π
π
π
π
∈
∈
⎡ ⎤
= + − +⎢ ⎥⎣ ⎦
⎡ ⎤
= − + − +⎢ ⎥⎣ ⎦
= ≤ ≤ = ≤ ≤
=
∑
∑
(3) 
2) Problem 2 
1
2
2
1 1 1 1
2
1 1 1 1 2
2
1 1
1
2
2 1
2
1 2
4[0.3 cos(24 ) 0.6 ]cos(6 )    
4[0.3 cos(24 ) 0.6 ]sin(6 )    
2
21
{ |     2 }  { |     2 }
j
j
j
j J
j
j J
j jx x x x x j J
n n
j j jx x x x x j J
n n
f x y
J
f x y
J
J j j is odd and j n and J j j is even and j n
y
π π
π π
π π
π π
∈
∈
− + + + ∈
− + + + ∈
= +
= − +
= ≤ ≤ = ≤ ≤
=
∑
∑
1
-1   [0,1]x[-1,1]
30
nsearch space is
n
⎧⎨⎩
= (4) 
3) Problem 3 
1 1
2 2
2
1 1
1
2
2 1
2
1 2
3( 2)0.5(1.0 )
2
1
202 (4 2 cos( ) 2)
2021 (4 2 cos( ) 2)
{ |     2 }  { |     2 }
, 2,3, 4,5,...,
   [0,1
i
j
j J j J
i
j
j J j J
j
n
j j
yf x y
J j
yf x y
J j
J j j is odd and j n and J j j is even and j n
y x x j n
search space is
π
π
∈ ∈
∈ ∈
−
+
−
= + − +
= − + − +
= ≤ ≤ = ≤ ≤
= − =
∑ ∏
∑ ∏
]
30
n
n = (5) 
4) Problem 4 
1
2
1 1
1
2
2 1
2
1 2
1
2
1
2 ( )
21 ( )
{ |     2 }  { |     2 }
sin(6 ), 2,...,
( )
1
   [0,1]x[ 2,2]
30
j
j J
j
j J
j j
t
n
f x h y
J
f x h y
J
J j j is odd and j n and J j j is even and j n
jy x x j n
n
t
h t
e
search space is
n
π
π
∈
∈
−
= +
= − +
= ≤ ≤ = ≤ ≤
= − + =
=
+
−
=
∑
∑
(6) 
5) Problem 5 
1
2
1 1 1
1
2 1 1
2
1
2
1
2
1 2( ) sin(2 ) ( )
2
1 21 ( ) sin(2 ) ( )
2
{ |     2 } 
 
{ |     2 }. N is an integer, >0
sin(6 ), 2,...,
( ) 2 cos(4 )
j
j J
j
j J
j j
f x N x h y
N J
f x N x h y
N J
J j j is odd and j n
and
J j j is even and j n
jy x x j n
n
h t t t
ε π
ε π
ε
π
π
π
∈
∈
= + + +
= − + + +
= ≤ ≤
= ≤ ≤
= − + =
= −
∑
∑
1+                          
 
Case 2 Case 1 
NS S1 S1 NS NS 
S1 
NS 
S1 
NS NS 
 
S1 
 
NS
Case 3 Case 4
1836
*) ,( PAD , The set A must be very close to the PF and cannot 
miss any part of the whole PF. 
D. Experimental Results 
Table II presents the mean and standard deviation of 30 runs 
of the proposed MOGA, MOEA/D and NSGA-II on the ten 
test problems. The best results among the three approaches are 
shown in bold.  
From the results, the proposed MOGA performed with better 
results can be observed. Furthermore, the proposed method 
surpasses all other algorithms in solving all functions and a 
significant improvement on the results of problems 4, 5, 6, 8, 9 
and 10.  
VI. CONCLUSION 
In this paper, the proposed method has been presented to 
solve multi-objective optimization problems. The sharing 
mutation was adopted to improve chromosomes’ searching 
abilities. It also makes proposed SMGA more robust, prevents 
chromosomes from falling into the local optimum. Ten 
unconstrained (bound constrained) MOP test problems of CEC 
2009 technic report were selected for experiments. The 
experiments results show that the proposed method can find 
more solutions located on/near to the Pareto front.  
VII. ACKNOWLEDGEMENT 
This work was supported in part by National Science 
Council of Taiwan, Taiwan, R.O.C. under Grant NSC 99-
2221-E-161-008. 
REFERENCES 
[1] J. D. Schaffer, “Multiple objective optimization with vector evaluated 
genetic algorithms,” in Proc. of 1st IEEE Int. Conf. Genetic Algorithms, 
pp. 93–100, 1985. 
[2] C. M. Fonseca and P. J. Fleming, “Genetic algorithms for multiobjective 
Optimization: Formulation, discussion and generalization,” in Proc. of 
the 5th International Conference on Genetic Algorithms, pp. 416-423, 
1993. In Stephanie Forrest, editor, Proceedings of the Fifth 
International Conference on Genetic Algorithms, pp. 416-423, San 
Mateo, California, University of Illinois at Urbbna-Champaign, Morgan 
Kauffman Publishers, 1993. 
[3] N. Srinivas and K. Deb, “Multiobjective optimization using 
nondominated sorting in genetic algorithms,” Evolutionary 
Computation, vol. 2, no. 3, pp. 221-248, Fall, 1994. 
[4] J. Horn, N. Nafpliotis and D.E. Goldberg, “A niched pareto genetic 
algorithm for multiobjective optimization,” In Proceedings of the First 
IEEE Conference on Evolutionary Computation, IEEE World Congress 
on Computational Intelligence, vol. 1, pp. 82-87, Jun. 1994. 
[5] E. Zitzler and L. Thiele, “Multiobjective evolutionary algorithms: A 
comparative case study and the strength pareto approach,” IEEE 
Transactions on Evolutionary Computation, vol. 3, no. 4, pp. 257-271, 
Nov. 1999. 
[6] E. Zitzler, M. Laumanns, and L. Thiele, “SPEA2: Improving the strength 
pareto evolutionary algorithm,” In K. Giannakoglou et al., editor, 
 
TABLE II 
RESULTS OF CEC 2009 TEST PROBLEMS 
                MOGAs 
Problems Proposed method MOEA/D NSGA-II 
P1 Results 2.10e-01 ± 9.70e-02 3.85e-01 ± 3.76e-02 1.26e+00 ± 2.30e-01 
P2 Results 1.11e-01 ± 4.36e-02 3.17e-01 ± 1.91e-02 5.83e-01 ± 1.28e-01 
P3 Results 3.10e-01 ± 2.89e-02 6.89e-01 ± 3.12e-02 1.18e+00 ± 6.77e-02 
P4 Results 7.50e-02 ± 1.14e-02 1.13e-01 ± 2.42e-03 1.45e-01 ± 3.43e-02 
P5 Results 3.20e-01 ± 9.00e-02 2.67e+00 ± 9.98e-02 5.06e+00 ± 9.42e-01 
P6 Results 2.90e-01 ± 7.61e-02 1.65e+00 ± 1.25e-01 5.77e+00 ± 6.64e-01 
P7 Results 2.70e-01 ± 1.85e-01 3.99e-01 ± 6.80e-02 1.36e+00 ± 1.61e-01 
P8 Results 3.71e-01 ± 1.01e-01 1.29e+00 ± 2.39e-01 2.56e+00 ± 1.00e+00 
P9 Results 4.29e-01 ± 6.69e-02 1.47e+00 ± 2.33e-01 2.57e+00 ± 9.22e-01 
P10 Results 8.34e-01 ± 3.15e-01 8.39e+00 ± 1.09e+00 1.39e+01 ± 2.92e+00 
 
1838
國科會補助計畫衍生研發成果推廣資料表
日期:2011/10/25
國科會補助計畫
計畫名稱: 多目標最佳化演算法的改良以及其在系統排程問題的應用
計畫主持人: 謝昇達
計畫編號: 99-2221-E-161-008- 學門領域: 人工智慧
無研發成果推廣資料
Part B –
Cybernetics, 
2011. 
研究報告/技術報告 0 0 100%  
研討會論文 1 1 100% 
Sheng-Ta Hsieh*, 
Shih-Yuan Chiu, 
and Shi-Jim 
Yen, ’Sharing 
Mutation Genetic 
Algorithm for 
Solving 
Multi-objective 
Optimization 
Problems,’ in 
Proc. 2011 IEEE 
Congress on 
Evolutionary 
Computation (CEC 
2011), pp. 
1833-1839 New 
Orleans, USA, 
Jun. 5-8, 2011.
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 1 1 100%  
博士後研究員 0 0 100%  
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
科 
教 
處 電腦及網路系統或工具 0  
