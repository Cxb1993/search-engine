  I
 
摘要 
 
本計畫是延伸上一個三年期的計畫「新世代自動語音辨識技術之研究」，提出將語言學與
語音學知識引進到資料驅動模式語音辨識系統的觀念，繼續先進的語音辨識技術研究。系統架
構分成五個功能方塊，針對這些功能方塊，由各子計畫進行特定議題的研究，包括(1)自動語
音標記及語音資料庫確認，(2)語音屬性與事件之辨識模型，(3)語音事件整合、證據確認與後
處理，(4)韻律屬性與語音事件偵測，(5)國語及方言之音節階層事件偵測，及(6)跨環境之強健
性語音屬性與事件偵測器。為了讓參與研究的人員有交流管道，每年寒暑假都在中央研究院資
訊所舉辦講習會，由各個子計畫主持人實驗室的研究生與研究人員作專題報告，進行實驗室間
的交流，同時對外公開研究心得。此外也建立資源共享平台，將各子計畫發展的語料庫、軟體
工具、研究成果、論文與報告等都放在平台上，除了提供各子計畫作為交流平台之外，也給一
般研究人員使用。此計畫之執行已有若干成果在期刊與國際研討會中發表，也培育許多博碩士
班學生，他們以此研究完成博碩士論文。 
 
關鍵詞: 自動語音辨識、語音標記、語音屬性與事件偵測、韻律屬性、音節階層事件偵測，資
源共享平台 
 
 
  III
目錄 
 
摘要 
一、前言 
二、自動標音及語音資料庫確認 
 2-1 自動音素分段技術改良 
 2-2 國語語料庫的音素自動標記及人工修訂 
 2-3 語音事件偵測技術改良 
 2-4 基於偵測之自動語音辨識系統的建置與改良 
 2-5 韻律特徵(Prosodic Feature)對語音特徵偵測影響評估 
三、語音屬性與事件之辨識模型研究 
 3-1 以條件隨機場模型作國語語音屬性之辨識 
 3-2 不知語言內容的自動音素分段 
 3-3 以隨機森林模型作爆發音事件偵測 
 3-4 濁音起始時間之估測 
四、語音事件整合、證據確認，與後處理 
 4-1 加伯特徵參數 
 4-2 整合加伯特徵參數與梅爾倒頻譜係數之事後機率 
 4-3 階層式多層感知器 
 4-4 整合加伯特徵參數以及階層式多層感知器之 TANDEM 辨識系統 
五、韻律屬性與語音事件偵測之研究 
六、國語及方言之音節階層事件偵測及其相關研究 
七、跨環境之強健性語音屬性與事件偵測器研究 
 7-1 最小錯誤率麥克風陣列 
 7-2 強健性新特徵參數求取 
 7-3 雜訊與語者特徵空間快速模型調適 
八、結果與討論 
九、計畫成果自評 
參考文獻 
附錄 
 已發表的論文 
 相關的博碩士論文 
 
 
  2
研究針對台灣口音之英語語音作語音音段屬性之偵測，並查驗是否有某一個語音事件的發生，
得出一個事件序列。 
 
(二) 國語語音屬性與事件偵測 
設計發音方法與發音位置之偵測方法，先以英語 TIMIT 語料作實驗，採用 GMM 方法作
偵測，然後應用到對 TCC300 國語語音資料庫作初始切割，及進行發音方式的偵測。並對
TCC-300 語料庫作切割校正，完成標音的語料庫，可提供國內研究單位使用。 
 
(三) 語言與音韻知識庫之建構 
做語音的自動音素分段，提出最小邊界誤差(minimum boundary error)的訓練方法 [Kuo and 
Wang 2006]。第二年的研究則發展一個以 SVM 方法作音素邊界調整的技術 [Lo and Wang 
2007]，將所發展的技術用在 MATBN 電視新聞語料的音素自動標記，同時作人工修訂，完成
的語料庫可提供各研究單位使用。 
 
(四) 證據確認技術之應用 
這個研究是針對一序列語音事件或音素進行驗證，我們以循序機率比檢定(sequential 
probability ratio testing, SPRT)技術，作樹狀結構中最可能路徑(optional probable path)的解碼。
接著作初步實驗，討論偵測斷點時面對的震盪問題，以及信心量度(confidence measure)的評量
方式，並將此方法作連續語音辨識的實驗。 
 
(五) 合作設計與評量之共享平台 
在一部 2U 伺服器上，我們建立一個共享平台，讓參與計畫的研究人員可以在此平台上分
享程式與語音資料，同時也公開研究成果，有興趣的人可以經由網路取得這個計畫的相關資
訊。目前在程式與語料庫分享方面已設計了兩個基本功能：(1)研究人員可以將所開發的程式
上傳到伺服器，在伺服器的 Linux 環境下建構執行檔，進行測試，或供其他人員使用。(2)研究
人員可以將所收集或整理的語料庫上傳到伺服器，提供其他研究人員使用，也可以將要處理的
語料庫上傳到伺服器，利用共享的程式作語料庫的處理。 
 
第二階段計畫之說明 
發展一個新的語音辨識技術需要長期投入，第一階段計畫所做的研究只是個開始，偏重在
聲學模型與語音特徵參數的研究，以及語料庫的標音與建立，也建立研究的共享平台，啟動一
個合作研究的機制。為維持此研究團隊的繼續合作，我們提出後續的三年整合型計畫「新世代
自動語音辨識技術之研究－第二階段」，為簡便起見，後續的三年整合型計畫簡稱為第二階段
計畫，此計畫擴大了參與人員與研究範圍，所規劃的語音辨識系統如圖 2-2 所示； 
 
(一) 語音屬
性與事件之
偵測 
 
(二) 語音事
件之整合與
證據確認 
(四) 語音辨
識之強化、
及後處理 
(五) 外加已
有知識 
(三) 語料庫、知識庫、模型、工具 
語音
訊號 
辨識
結果 
共享平台 
 
圖 2-2、 新世代自動語音辨識系統—第二階段之系統規劃 
  4
 
我們在第一階段三年期計畫提出一個基於HMM強迫校準(forced alignment)及SVM邊界調
整的兩階段自動音素分段技術，本計畫針對HMM強迫校準及音素邊界調整分別提出改良的技
術。 
 
(1) HMM自動音素分段技術改良 
 
就 HMM 聲學模型訓練而言，我們在第一階段三年期計畫所提出的最小邊界誤差(minimum 
boundary error, MBE)訓練法相較於傳統的 ML 訓練方式已有相當大的突破[Kuo and Wang 
2006a][ Kuo and Wang 2006b]。在第二階段三年期計畫我們新推導了一個最小排序錯誤
(minimum rank error, MRE)HMM 模型訓練法，理論上會比先前提出的最小邊界誤差(minimum 
boundary error, MBE)訓練法更好，但新方法目前只能實作在 N-best 邊界序列所組成的可能邊
界序列集合，效能仍無法勝過可實作在音素圖(phone graph)所組成的可能邊界序列集合的舊方
法，故還需要進一步研究。 
 
(2) 音素邊界調整技術改良 
 
在第一階段三年期計畫中，我們以支向機(SVM)對 HMM 音素分段的結果進行音素邊界調
整，獲得相當不錯的效果[Lo and Wang 2007][Kuo, et al. 2007][Wang, et al. 2007]。由於支向機
分類器處理的是二元分類問題，在利用支向機作音素邊界調整時，僅利用真正邊界之特徵向量
作為正例，離邊界較遠之特徵向量作為反例來訓練支向機分類器。這樣的訓練方式屬於硬式決
定(hard decision)。事實上可以將近似邊界的特徵向量資訊加入邊界調整的訓練資料，採用軟式
決定(soft decision)的訓練方式，將邊界調整看成排序(ranking)問題。在第二階段三年期計畫我
們測試排序支向機(Rank SVM)和排序提升法(Rank Boost)，實驗結果顯示效果比先前使用的支
向機(SVM)分類器更好，這部份的研究成果發表在 ISCSLP2010 國際會議[Lo and Wang 2010]。 
 
2-2 國語語料庫的音素自動標記及人工修訂 
 
我們從 MATBN 公視新聞口語語料庫選取將近 1.5 小時的語句，利用所提出的自動音素分
段技術進行自動標記。由於人工修訂非常費力耗時，我們僅能就其中 20 分鐘的語料完成人工
修訂。 
 
2-3 語音事件偵測技術改良 
 
在第一階段三年期計畫我們已探討三種不同語音特徵系統的音素辨識率[Chen and Wang 
2008]，發現支配音韻特徵系統(Government Phonology (GP) feature system)能提供後端語音事件
整合辨識最豐富的語音資訊，從而達到最佳的辨識效果。因此，在第二階段三年期計畫我們以
支配音韻特徵做為語音事件偵測之主要研究對象。支配音韻特徵系統是透過聲學頻譜的分析，
將語音音素中各種互補的獨立成分抽取出來。此方法共取得 11 項獨立成分(即"A", "I", "U", "E", 
"S", "h", "H", "N" 與 "a", "i", "u")，透過此 11 項獨立成分之組合可表示任何語音音素。 
    針對 GP 語音特徵系統，我們進一步設計兩種新的語音事件偵測器架構，並與第一階段三
年期計畫期間採用的架構進行比較。三種架構均使用多層感知器(multi-layer perceptron, MLP)
作為語音事件機率模型之核心。舊有語音特徵事件偵測器之多層感知器輸入向量使用 13 維梅
爾倒頻譜係數，輸出則為 GP 系統 11 個語音特徵事件之事後機率所形成之 11 維向量。第一種
新開發之語音特徵暨音素事件偵測器之輸入向量同樣使用 13 維梅爾倒頻譜係數，輸出則為 GP
  6
從語句韻律結構下手，將所有語句切割成句首、句中、與句尾三部分，再對這些語句片段依其
韻律特徵進行 K-Means 分群後，對每群語料各別訓練獨立語音特徵事件偵測器。 
 實驗語料我們一樣採用 TIMIT 英語語料庫，韻律特徵的抽取則使用 Praat 語言處理程式所
提供之音高、音強、與語速抽取功能。這部份實驗結果的分析工作目前仍在進行中，希望可以
獲得更好的語音特徵偵測結果。 
 
 
三、語音屬性與事件之辨識模型研究 
 
本子計畫完成以下幾個語音屬性與事件辨識模型之研究； 
 
3-1 以條件隨機場模型作國語語音屬性之辨識 
 
機率圖模型(Probabilistic Graphical Model) [Bishop 2006] [Jordan and Weiss 2002]是近年來
蓬勃發展的研究議題之一，它以機率觀點出發，將許多在資訊電機領域中現行的模型，整合到
統一的框架裡。條件隨機場是(conditional random field, CRF)其中一種，屬於無向性圖模型
(undirected graphical model)，其應用以影像處理及自然語言處理居多，近年來有人將其應用在
語音辨識上 [Gunawardana, et al. 2005]。我們的構想是將條件隨機場作為中文音節辨識的後
端，偵測出的屬性標籤就是條件隨機場的輸入，然後進行辨識。 
    實驗語料為在台灣錄製的 TCC300 語料庫[ Lin and Wang 2008]，錄音格式為 16-bit PCM，
取樣頻率為 16kHz，使用的訓練集包括 24742 句話，總和長度約 24 小時，測試集包含 2595 句
話，總和長度為 2.5 小時，表 3-1 列出前端屬性偵測器得到的屬性辨識正確率與精確率，正確
率不考量插入型錯誤。 
表 3-1 屬性偵測器之辨識正確率及精確率 
 Correction (%) Accuracy (%) 
manner 81.39 76.34 
Final onset type 86.12 82.59 
Final ending type 87.14 82.89 
place 83.82 80.77 
aspiration 88.61 84.72 
voiced 86.71 83.93 
 
3-2 不知語言內容的自動音素分段 
 
對於不知其語言內容的一句語音，若能先進行自動音素分段，就能在做語音辨識之前先知
道其所含有的音素數目與音素邊界，這對於提升語音辨識正確率會有幫助。自動音素分段也可
以對錄音的語音訊號作音素邊界偵測與標記，有助於語音資料庫的建立。 
本研究提出一個不知其語音內容的二階段偵測音素邊界的方法，第一階段使用離散小波轉
換(Discrete Wavelet Transform)，找出音素邊界點的候選位置，第二階段用二維倒頻譜參數建立
音素邊界模型，加上頻譜轉變量測(spectral transition measurer, STM)，進行音素邊界點之確認，
得出偵測音素邊界點的結果。將 TIMIT 語料中的音素分成六類，連同靜音數，可以有 49 種連
  8
表 3-6  不同容忍度時的表現 
容忍度  F-值  R-值  HR  PRC  OS  
20ms  81.4  84.0  79.7  83.0  -3.7  
15ms  76.8  80.1  75.3  78.4  -3.7  
10ms  67.0  72.0  65.6  68.4  -3.7  
 
在 20ms 容忍度下與其他研究結果比較，我們的方法有不錯的表現。表 3-8 列出其他方法的結
果，他們在 TIMIT 或 NTIMIT 語料上測試，測試語料量也不同，評量時計算方式也不盡相同，
我們就其報告的數據，盡可能對照。其召回率也就是擊中率，但是多數沒有看多分率。 
表 3-7  與其他研究結果比較 
 Method  F(%) RCL(%) OS(%) 
1 Jump function [Aversano et al. 2001]  73.58 0 
2 STM [ Dusan and Rabiner 2006]  75.3  
3 DISTCOMP [Almpanidis et al. 2009] 73.6 74.5  
4 DISTCOMPR [Almpanidis et al. 
2009] 
74.7 75.4  
5 SVF [Almpanidis et al. 2009] 67.7 70.4  
6 DCF [Almpanidis et al. 2009] 70.1 73.3  
7 Our method 81.4 97.7 -3.7 
 
 
3-3 以隨機森林模型作爆發音事件偵測 
     
隨機森林(random forest) [Breiman 2001]的演算法係由 L. Breiman 於 2001 年提出，是一個
分類與回歸方法，我們將此方法改用於聲學訊號的處理，需要做一些調整。隨機森林是由一群
決策樹(decision tree)組成，它包含三個觀念，(1)分類與回歸樹(Classification and Regression Tree, 
CART)[ Breiman, et al. 1984]、(2)拔出與集成(bootstrapping and aggregation, 簡稱 bagging) 
[ Breiman 1996]、及(3)隨機子空間(random subspace)[ Ho 1998]。 
建立隨機森林模型時，總共用了九個語音屬性不同的音段類別，(1)有聲塞音爆發音
(VSB)、(2)無聲塞音爆發音(USB)、(3)塞音吐氣音(SA)、(4)塞擦音(AF)、(5)擦音(F)、(6)鼻音(N)、
(7)半母音與流音(SVG)、(8)母音(V)，及(9)非語音段(NS)，在往後提到爆發音就是指(1)與(2)
兩類，而其他類別皆為非報發音。特徵參數取自二維倒頻譜係數。 
 
 
圖 3-1 一個從 TDC 取出特徵參數向量的做法 
 
Extract 55 
coefficients 
55x1 
vector 
  10
 
 
圖 3-4 爆發音偵測可以提升對於塞音與塞擦音的辨識正確率 
 
3-4 濁音起始時間之估測 
 
濁音起始時間(voice onset time, VOT)是指塞音中從爆發音起始點(burst onset)到濁音起始
點(voice onset)之間的時間間隔，濁音起始時間會隨著塞音與後續母音的發音方式而有不同，
因此可以用來辨識塞音。我們採用與爆發音偵測同樣的方法，以二維倒頻譜[Ariki, et al. 1989]
係數作為特徵參數，建立濁音起始點的隨機森林模型[Breiman 2001]。 
我們使用的實驗語料來自 TIMIT 語料庫[Garofolo, et al. 1993]，從測試集中取 1348 個語句
作實驗，其中含有 2344 個詞有詞首塞音(word-initial stop)，1440 個詞有詞中塞音(word-medial 
stop)，分散在 968 個不同的詞中。 
 
表 3-4 實驗語句中塞音的分布。 
 
詞中塞音(word-medial stop)的偵測較難，我們先以詞首塞音(word-initial stop)為實驗對象。VOT
的估測結果則列在表 3-5。 
 
表 3-5  VOT 的估測結果 
Tolerance limits 
 <5ms <10ms <15ms <20ms 
/b/ 58.5 85.4 96.2 99.1 
/d/ 54.3 89.7 97.8 99.1 
/g/ 49.1 78.6 92.5 96.5 
/p/ 60.3 78.8 89.6 94.1 
/t/ 61.6 82.0 91.2 94.8 
/k/ 56.2 81.0 90.5 93.9 
  12
且整合加伯特徵參數與梅爾倒頻譜係數之事後機率。圖 4-2 是整合加伯特徵參數以及梅爾倒頻
譜係數之事後機率的 TANDEM 語音辨識系統示意圖。首先，將四組加伯特徵參數各自通過對
應之多層感知器，得到四組對於多層感知器分類目標之事後機率。由於四組加伯特徵參數分別
攜帶由不同時間長度抽取之語音資訊，因此這裡將四組由加伯特徵參數得到的事後機率做一個
合併，共同估測分類目標之事後機率，作法為取四組加伯特徵參數事後機率之幾何平均，取對
數結果後，與一般 TANDEM 語音辨識系統中梅爾倒頻譜係數得到的事後機率取對數結果後串
接。相較於傳統 TANDEM 語音辨識系統，在加入加伯特徵參數後，由多層感知器獲得之事後
機率向量之維度是原本的兩倍。獲得加伯特徵參數與梅爾倒頻譜係數共同估測之分類目標事後
機率後，進一步使用線性鑑別分析(linear discriminant analysis)降低維度，串接於原先抽取之梅
爾倒頻譜係數之後，做為觀察序列(observation sequence)進行隱藏式馬可夫模型(hidden markov 
model, HMM)的訓練以及語音解碼(decoding)。 
 
 
圖 4-2 整合加伯特徵參數之 TANDEM 語音辨識系統 
 
 
4-3 階層式多層感知器 
 
 在前述之 TANDEM 語音辨識系統中，皆是使用一個多層感知器直接由特徵參數獲得分類
目標之事後機率。在本子計畫中，我們提出一種階層式多層感知器(clustered hierarchical 
multi-layer perceptron, CHMLP)架構，以更好的估測分類目標之事後機率。首先利用階層凝聚
分類法(hierarchical agglomerative clustering, HAC)，根據辨識結果中容易混淆的程度，對所有
分類目標建立樹狀結構，並且在每一個內部結點(internal node)以及樹葉結點(leaf node)設立一
個多層感知器，如圖 4-3 所示。如此一來，對於每一個內部結點，其分類法則就是對應的子結
點多層感知器之軟性決定權重(soft decision weight)，而對於每一個樹葉結點，分類法則即是對
應之全部分類目標中子集合的事後機率。在辨識過程當中，當得到每一個內部結點所對應之軟
性決定權重，以及每一個樹葉結點中分類目標之事後機率後，將每一個分類目標由樹葉結點得
到之事後機率乘上該樹葉結點多層感知器所獲得的軟性決定權重，即可認定其為該分類目標之
整體事後機率，因此對於階層式多層感知器來說，輸入端的特徵參數以及輸出端之事後機率向
量，其維度與數量皆相同，只是在估測事後機率的過程當中，經過階層式的分類架構，所有分
類目標之事後機率能夠獲得較好的估測。 
  14
 
圖 4-5 整合加伯特徵參數獲得樹葉結點事後機率 
 
 在此以加伯特徵參數以及階層式多層感知器改良之語音辨識系統中，我們使用公視新聞語
料(Mandarin Across Taiwan Broadcast News, MATBN)做為效能評估基準，所對應之實驗數據如
表 4-1 所示。 
 
表 4-1 實驗結果 
ASR system  CER (%)  
(A) MFCC (non-Tandem)  24.6  
(B) MFCC, MLP, PCA  22.6  
(C) MFCC, MLP, LDA  22.2  
(D) Gabor, MLP, LDA  22.2  
(E) Integration, MLP, LDA  21.1  
(F) Integration, CHMLP, LDA  20.6  
 
從實驗結果中我們可以看到，梅爾倒頻譜係數與加伯特徵參數各自攜帶不同的語音資訊並
且具有互補性，整合梅爾倒頻譜係數以及加伯特徵參數能夠有效的降低字元辨識錯誤率，同時
使用階層式多層感知器也能夠更好的估測分類目標之事後機率。在本子計畫之實驗中，結合加
伯特徵參數以及階層式多層感知器之語音辨識系統相較於傳統 TANDEM 語音辨識系統，能夠
降低約 8.8%的相對字元辨識錯誤率。 
 
 
五、韻律屬性與語音事件偵測之研究 
 
本子計畫研究的重點，是釐清連續語流中不變的恆態成分，與動態的相對成分如何共組語
音信號中的表意成分，順利達成口語溝通的目的。研究成果如下： 
(1)偵測語流中的韻律邊界特性，可供辨識韻律單位所需的資訊。 
(2)提出不同於以往單一字調正確率辨識的研究觀點，找出「連續語流中整體韻律脈絡（global 
prosodic context）」，有助語音辨識率的提升。 
(3)分析自發性課程口語篇章的韻律特性及跨語體韻律屬性比較，應有助辨識快語速連續語流
時可能遇到的信號失真問題。 
  16
CNA 
f051 54.41% 56.25% 4.98% 
m051 57.43% 59.32% 4.79% 
 
表 5-3 句調成分 Ap 在韻律短語層、呼吸句群層與韻律詞層的累積正確率 
語料 語者 PPh BG PG 
CL f054 58.79% 63.58% 76.66% 
m056 37.89% 48.99% 73.66% 
CNA 
f051 80.17% 81.46% 87.71% 
m051 81.53% 82.72% 88.20% 
 
在跨語體韻律屬性比較方面，考量到目前語音辨識仍以單句且語速較慢的語料為主，而在
實際的應用中，快語速的連續語流是未來語音辨識所需解決的課題。從信號分析的角度，連續
語流中存有相當大程度的信號失真，我們因而預期若能獲得自發性口語韻律特徵，應可用來提
升辨識快語速且較模糊語音的正確率。本計畫執行期間，我們取得臺大電機系李琳山老師「數
位語音處理」的課程口語語料 NTU DSP Lecture Corpus（簡稱 NDLC，共計 45 小時），屬於
自發性語料。課程講課的口語在性質上是準備充分的自發性語料，有別於朗讀語料，多了自發
性語料的特性；但相較於口語對話語料，課程口語語料不但少了許多情感表達性副語言成分
（如：笑、哭等情緒表現與情感交流意圖），課程口語還具有流暢度高、篇章韻律訊息極為明
確、語速快、強調成分多等特性。此外，語者咬字清晰、語段分明，語音中使用上層語篇單位
（higher level discourse unit）規劃的證據極為明確，是利用 prosody 研究 discourse unit、discourse 
speech planning、discourse automatic segmentation 極好的素材。由於資料量極為龐大，取得時
只有文本轉寫，沒有任何語音標註。我們投入許多人力，進行文本聽校、HTK 文本轉音標以
及音段邊界人工等語料前處理上，除此之外，還有訓練有素的標音員依聽感完成韻律邊界停延
標記，才得以進行量化分析。分析課題如下，主要為跨語體自發性口語語料 NDLC 與朗讀語
料的比較分析： 
(1) 跨語體、跨韻律格式韻律組織比較。語體有自發性口語語料與朗讀語料二類，韻律格式則
有自發性口語 NDLC/ SpnNS、朗讀散文 CNA（平鋪直敍長段落）與古典詩詞 CL 三類。比
較以下 HPG 架構特性：語篇規劃範圍，語篇邊界中短語層的語速調節，主題轉換的
整體短語基頻走勢組型等。獲得自發性口語語料與朗讀敍事語料的一致性與差異性組型，
及自發性語篇韻律的韻律特徵。結果顯示：與朗讀語料相比，自發性課程口語語料是由較
大範圍語段所構成（NDLC/ SpnNS: 654 音節；RS: 77-90 音節），語句段落的韻律構組較
朗讀複雜，語速是朗讀語料的 2-3 倍，表示語者可運用較大的規劃尺度（planning scale）傳
遞主題明確組織完整的敍事訊息，支持了規劃尺度與認知閾限靈活性的研究假說。亦即規
劃良好的自發性口語語料的資訊結構性具清晰主題，因而與且戰且走的朗讀語料不同。此
外，分析相關聲學參數後也發現：複雜語句形成長篇語段時，語段內表「主題持續效應」
（topic on-going effect）關連性的特徵，與語句間語速的快慢調節有關；而語段間表主題轉
換（topic change）的特徵，則與上層韻律邊界特性及韻律單位結尾之基頻組型、停頓時長
有關。簡言之，以上表語段關連性及主題轉換性之韻律特徵，均與階層式的語篇韻律單位
有關，呈系統性對應，共構出韻律輸出的變異。（Tseng et al, 2008）。 
(2) 區辨跨語體自發性課程口語語料與朗讀語料的韻律邊界聲學參數有何不同?我們分別檢驗
自發性口語語料與朗讀語料中的(a.) 獨立(單一)語音聲學參數與相依(成組)語音聲學參數
的邊界區辨力，包括：  邊界停頓 邊界前音節時長邊界前音強時長反差音節音
強反差；以及(b.) 10 組由以上 5 項聲學特徵所組成的相依(成組)語音聲學參數。結果發現：
  18
持語篇的連貫性，而 SpnNS 在不同的韻律層因為關鍵訊息不同的分布與位置則具有更加複
雜的節拍調節組型。其中最值得注意的是在段落結尾是關鍵訊息分布最多的地方，造成韻
律邊界成分出現沒有單位結尾延長（unit-final lengthening）的輸出變異[Tseng et al., 2010]。 
 
 
 
圖 5-2 自發性口語語料 SpnNS（上圖）與朗讀敍事語料 RS（下圖）節拍（tempo）組型 
 
在跨語體韻律感知強調方面，上述透過跨語體資訊結構比較分析，得到：朗讀語料與自發
性口語語料具有不同的感知強調/韻律突顯組型，我們便進一步想瞭解：口語連續語流中的韻
律突顯組型是否語體相關（genre related）？如何與語篇結構（DS）產生交互作用？如
何顯示語言深層的資訊結構？是否可由大量的語料分析得出系統性的聲學組型？是否分
層疊加於語篇結構之上？所獲結果顯示：韻律突顯組型與語體相關，不同語體具有不同的韻律
突顯組型；連續語流中關鍵信息分布的不同可歸因於語言內容與溝通需求；韻律突顯是疊加於
語篇韻律結構之上、額外的語言訊息。韻律突顯功能在於傳達口語語流中的重要資訊，而語篇
韻律結構則表達著語言關連性，二者各有所指，因而並不衝突[Tseng et al., 2011]。 
 
 
六、國語及方言之音節階層事件偵測及其相關研究 
 
在本子計畫中，我們提出的新世代語音辨認技術中的事件偵測及語音屬性偵測，採取的步
驟就以偵測 Articulation change 也就是所謂的 landmark 做為系統的第一級。根據 landmark 的定
義，我們所做的 syllable-level landmark detector 是以 sample-based 的觀點來製作，希望達到較
高的精確度。 
在過去有一些 phone boundaries segmentation/detection 研究中都是使用傳統語音辨認所使用
  20
  
在國語語料 TCC-300 的端點標示(boundary alignment)方面，我們使用上述架構訓練一個監
督式(supervised)MLP 類音素端點偵測器。訓練類音素端點偵測器流程，其方塊圖如圖 6-3。 
 
圖 6-3、使用 MLP 架構之類音素端點偵測流程 
實驗結果以 frame-based HMM 架構之切割位置來比較，觀察本研究所提出的方法切割位
置之精準度是否有進一步地提升。所使用的國語語料庫為 TCC-300 麥克風語音資料庫之長文
語料，是由國立交通大學、國立成功大學所錄製的部分，並隨機選取六分之五的部份當作訓練
語料，其它部分為測試語料。首先使用 SAT 及 SA 技術之 HMM phone alignment 流程，獲得較
佳的 HMM 模型後進行強迫對齊之切割結果，作為 TCC-300 語料庫之類音素起始切割位置。 
獲得 MLP 端點偵測器後，將 sample-based MLP 類音素端點偵測器偵測之端點範圍限制於
HMM 初始切割結果之正負 100 ms 範圍內進行 Viterbi search 的到最佳的切割結果，由結果皆
可證實其 sample-based 的聲學參數具有偵測發音特徵變化之效能。 
我們對 TCC-300 語料庫中 1698 個音節作人為標記的標準答案。統計 HMM 自動分段位置
和實驗結果對人為標記的端點位置的誤差並以不同絕對偏差值之包含比率來表示，如圖 6-4。
可以證明我們所提出之方法較 HMM 為佳。 
 
圖 6-4：所提出之國語端點標示方法與人為標記位置之誤差在 
不同絕對偏差值的包含比率直方圖，藍色線(左側)為所提出之方法 
之誤差，紅色線(右側)為使用 HMM 之初始自動分段位置之誤差。 
 
我們也將英文語料庫上提出之 sample-based 的語音參數所訓練的音素端點偵測器(phone 
boundary detector)的優異效能，應用於客家話語料中並觀察其特性。 
所測試之客語語料為四縣客家話的語料庫，文章來源主要由苗栗退休教師龔萬灶老師所主
  22
離說話環境，產生的語音殘響失真與雜訊所造成語音辨認效能降低。主要的動機是因為傳統
的陣列訊號只注重在處理訊號的訊雜比，即語音訊號增強，但語音訊號增強的結果，實際上
並不能保證語音辨認系統可以得到最佳的辨認效果。因此我們直接利用語音辨認模型所提供
的知識，來回饋並調整麥克風陣列的參數，使其求取出來的語音參數，可以與辨認器配合達
到強健語音辨認系統的辨認率的目的。我們所提出的最小錯誤鑑別式演算法，其架構如圖 7-1
所示。調適方式為利用後級的語音辨認器，計算錯誤率，並依錯誤率高低之回饋，以最小錯
誤率準則（MCE）調整麥克風陣列參數。 
 
圖 7-1 最小錯誤鑑別式演算法 
麥克風陣列消除房間殘響實驗結果：我們使用 TCC300 語料庫，挑選其中 23248 句做為
建立語音的模型。435 句做為測試語句，其中共有 29 人錄音，每人 15 句話。並且挑選 5 句
串連成 1 句做為已知答案的麥克風陣列響應濾波器調適使用，每個人的其餘 10 句做測試使
用。環境設定使用 Real World Computing Partnership（RWCP）所提供的房間脈衝響應來測試，
並將 TCC300 語料庫的測試語句與脈衝響應做摺積（Convolution），以模擬房間的殘響效應。
下表是在三個不同大小房間（殘響 0.3、0.47 與 1.3 秒）中的實驗結果。 
 
表 7-1 實驗結果 
 
 
其中 S-LIMABEAM 是先前別人提出的 maximum likelihood beamforming 的方法，
S-MCEBEAM-1 是先經過 S-LIMABEAM 調整後，再以 MCE 繼續調整，S-MCEBEAM-2 則是
直接以 MCE 調整麥克風陣列參數。由表中可見以 MCE 調整麥克風陣列參數，效果最好。 
 
7-2 強健性新特徵參數求取 
 
目前最通用的語音辨認參數是 MFCC，但其抵抗環境雜訊的能力並不好，通常需要再加
上一些額外的正規化的處理，才能達到差強人意的效果。因此我們嘗試求取具鑑別性且巨強
  24
 
我們進一步提出基於機率主成份分析之強健性 MLLR（Probabilistic Principal Component 
Analysis Maximum Likelihood Linear Regression，PMLLR ）模型調適系統，主要是透過機率
主成份分析在特徵空間上做即時語音辨認模型補償（online recognition model compensation）
以消除雜訊、語者、通道等對語音辨認器的干擾因素。其模型調適架構與流程如圖 7-4： 
 
ˆΛ
( ){ }, , , ,, , 1 ~n n s k n s kW A b n N= =
O
, 1 ~nO n N=
, , , ,
ˆˆµˆ µ= +s k s k s k s kA b
( )P P P, , ,,=s k s k s kW A b
2
={M , y , }θ σ
 p
 p  p  p
w
ˆW = argmax P(O| ,W ,x) P(W ,x | )θΛ
 
 
圖 7-4 模型調適架構與流程 
 
Aurora2 實驗結果：實驗使用 Aurora2 語料庫，在複合情境訓練模式下，數字的辨認結果
如圖 7-5 所示： 
 
 
 
圖 7-5 數字的辨認結果 
 
我們發現在使用 55 維特徵空間的情形下，PMLLR（辨識字錯誤率：6.05%）與 EMLLR
（辨識字錯誤率：6.09%）相當，且優於傳統 MVA(7.97%)、HEQ(8.66%)、ETSI Adv. Frontend 
(8.65%)與 RMW(7.29%)約 17～30％相對錯誤率。 
 
 
 
  26
每次參加人數約 80 人到 100 人。此計畫結束之後，資源共享平台將由清華大學電機系移轉到
中央研究院資訊所，繼續提供服務。 
 
 
 
參考文獻 
 
[1] A. Acero (1992), Acoustical and Environmental Robustness in Automatic Speech Recognition, 
Kluwer Academic Publishers, 1992 
[2] A. M. A. Ali, J. Van der Spiegel, P. Mueller (2001), “Acoustic-Phonetic Features for the 
Automatic Classification of Fricatives,” J. Acoust. Soc. Am., Vol. 109, No. 5, pp.2217-2235, 
May 2001. 
[3] G. Almpanidis, M. Kotti, and C. Kotropoulos (2009), “Robust Detection of Phone Boundaries 
Using Model Selection Criteria With Few Observations,” IEEE Transactions on Audio, Speech, 
and Language Processing, vol.17, no.2, pp.287-298, 2009 
[4] Y. Ariki, S. Mizuta, M. Nagata, and T. Sakai (1989), “Spoken-word recognition using dynamic 
features analyzed by two-dimentional ceprteum,” IEE Proceedings, v. 136, pp. 130140, 1989. 
[5] G. Aversano, A. Esposito, and M. Marinaro (2001), “A new Text-Independent Method for 
Phoneme Segmentation,” Proc.IEEE International Workshop on Circuits and Systems, vol.2, 
pp. 516-519, 2001 
[6] M. Bishop (2006), Pattern Recognition and Machine Learning, Springer, 2006. 
[7] L. Breiman, “Bagging predictors (1996), Machine Learning, vol. 24, pp. 123–140, 1996. 
[8] L. Breiman, “Random forests (2001), Machine Learning, vol. 45, no. 1, pp. 5–32, 2001. 
[9] C. Sidney Burrus, Ramesh A. Gopinath, and Haitao Guo (1998), Introduction to Wavwlets and 
Wavelet Transforms: A Primer, Prentice Hall, 1998. 
[10] S. Y. Chang and L. S. Lee (2008), “Data-driven Clustered Hierarchical Tandem System for 
LVCSR, “ InterSpeech 2008, pp. 2250-2253. 
[11] S. Y. Chang and L. S. Lee (2009), “Improved clustered hierarchical tandem system with 
bottom-up processing,” International Conference on Acoustics, Speech, and Signal Processing, 
ICASSP 2009, pp. 4441-4444. 
[12] I. F. Chen and H. M. Wang (2008), "An Investigation of Phonological Feature Systems Used In 
Detection-Based ASR," International Symposium on Chinese Spoken Language Processing, 
ISCSLP2008, Kungming, China, 2008. 
[13] I. F. Chen and H. M. Wang (2009), "Articulatory Feature Asynchrony Analysis and 
Compensation in Detection- Based ASR," Interspeech2009, pp.3059-3062. 
[14] T. Chi, Y. Gao, M. C. Guyton,P. Ru, and S. A. Shamma (1999), “Spectrotemporal modulation 
transfer functions and speech intelligibility,” J. Acoust. Soc. Am., 106:2719–2732, 1999. 
[15] D. A. Depireux, J. Z. Simon, D. J.  Klein, and S. A. Shamma (2001), “Spectro-temporal 
response field characterization with dynamic ripples in ferret primary auditory cortex”, J. 
Neurophysiology, vol. 85, pp. 1220–1234, 2001. 
[16] X. Domont, M. Heckmann, F. Joublin, and C. Goerick (2008), “Hierarchical spectro-temporal 
features for robust speech recognition”, in Proc. ICASSP, 2008. 
[17] Sorin Dusan and Lawrence Rabiner, “On the Relation between Maximum Spectral Transition 
Positions and Phone Boundaries (1993), ”, in Proc. Interspeech 2006,  pp. 17–21. 
[18] S. Ganapathy, S. Thomas, and H. Hermansky (2010), “Robust spectrotemporal features based 
on autoregressive models of Hilbert envelopes”, in Proc. ICASSP, 2010. 
[19] J. S. Garofolo, L. F. Lamel, W. M. Fisher, J.G. Fiscus, D. S. Pallett, and N. L. Dahlgren (1993),  
DARPA TIMIT Acoustic-Phonetic Continuous Speech Corpus,  U. S. Dept. of Commerce, 
NIST. Gaithersburg, MD, Feb. 1993.  
[20] D. Gelbart (2008), Ensemble feature selection for multi-stream automatic speech recognition, 
  28
[41] C.Y. Lin and H.C. Wang (2011), "Burst Onset Landmark Detection and Its Application to 
Speech Recognition," IEEE Trans. on Audio, Speech, and Language Processing, vol.19, no.5, 
pp.1253-1264, 2011. 
[42] C.Y. Lin and H.C. Wang (2011), "Automatic estimation of voice onset time for word-initial 
stops by applying random forest to onset detection," Journal of Acoustical Society of America. 
(accepted) 
[43] Y. C. Lin and H. C. Wang (2005), “Nasal detection in continuous Mandarin speech,” Oriental 
COCOSDA workshop 2005, Jakarta, Indonesia, 2005 
[44] Y. Y. Lin and Y. R. Wang (2009), “Sample-based phone-like unit automatic labeling in 
Mandarin speech,” ROCLING 2009, pp. 137-149. 
[45] Sharlene A. Liu (1996), “ Landmark detection for distinctive feature-based speech recognition, 
“, J. Acoust. Soc. Am. 100 (5), November 1996, pp. 3417-3430. 
[46] H. Y. Lo and H. M. Wang (2007), "Phonetic Boundary Refinement Using Support Vector 
Machine," ICASSP2007. 
[47] H. Y. Lo and H. M. Wang (2010), "Phone Boundary Refinement Using Ranking Methods," Int. 
Symposium on Chinese Spoken Language Processing (ISCSLP2010). 
[48] C. F. Lu and H. C. Wang (2010), “A Metric-based Phone Segmentation Method using Wavelet 
Transform,” Oriental COCOSDA workshop 2010, Kathmandu, Nepal, 2010, paper_ 10 
[49] S. Mallat (1989), “Multifrequency channel decomposition of images and wavelet models,” 
IEEE Transactions on Acoustics, Speech, and Signal Processing, vol.37, pp.2091-2110, 1989. 
[50] B. Meyer and B. Kollmeier (2009), “Complementarity of MFCC, PLP and Gabor features in 
the presence of speech-intrinsic variabilities”, in Proc. Interspeech, 2009. 
[51] H. Misra, S. Ikbal, H. Bourlard, and H. Hermansky (2004), “Spectral entropy based feature for 
robust ASR,”, in Proc. ICASSP 2004, pp. 193–196. 
[52] P. Niyogi and M. M. Sondhi (2002), “Detecting stop consonants in continuous speech,” 
Journal of Acoustical Society of America, vol. 111, pp. 1063–1076, February 2002. 
[53] Mari Ostendorf, Salim Roukos (1989), “ A Stochastic Segment Model for Phoneme-based 
Continuous Speech Recognition, “ IEEE Trans. On ASSP, Vol. 37, No. 12, pp. 1857-1869, Dec., 
1989. 
[54] H.-F. Pai and H.-C. Wang (1993), “Two-dimensional cepstral distance measure for speech 
recognition,” in IEEE International Conference on Acoustics, Speech and Signal Processing, 
vol. 2, pp. 672–675, 1993. 
[55] O. J. Rasanen, U. K. Laine, and T. Altosaar (2009), “An Improves Speech Segmentation 
Quality Measure: the R-value,” Interspeech 2009 
[56] S. Ravuri and N. Morgan (2010), “Using Spectro-Temporal Features to Improve AFE Feature 
Extraction for ASR”, in Proc. Interspeech, 2010. 
[57] Jia-lin Shen, Jeih-weih Hung, Lin-shan Lee (1998), "Robust Entropy-based Endpoint 
Detection for Speech Recognition in Noisy Environments", Proc. ICSLP 1998. 
[58] P. Schwarz, P. Matejka, and J. Cernock (2006), “Hierarchical structures of neural networks for 
phoneme recognition”, in Proc. ICASSP, 2006 
[59] C. Stilp and K. Kluender (2010), “Cochlea-scaled entropy, not consonants, vowels, or time, 
best predicts speech intelligibility”, in Proc. National Academy of Sciences of the USA, 2010 
[60] K. T. Sung, H. C. Wang (2006), “A study of knowledge-based features for obstruent detection 
and classification in continuous Mandarin speech,” International Symposium on Chinese 
Spoken Language Processing, ISCSLP2006, Singapore, 2006. 
[61] S. Thomas, S. Ganapathy, and H. Hermansky (2008), “Recognition of Reverberant Speech 
Using Frequency Domain Linear Prediction”, IEEE Sig. Proc. Let., Vol. 15, pp. 681-684 
[62] S. Thomas, N. Mesgarani, and H. Hermansky (2010), “A Multistream Multiresolution 
Framework for Phoneme Recognition”, in Proc. Interspeech, 2010. 
[63] D. T. Toledano, L. A. H. Gomez, L. V. Grande (2003), "Automatic phonetic segmentation," 
  30
9. C. Y. Lin and H. C. Wang (2007), “Attribute-based mandarin speech recognition using 
conditional random fields,” INTERSPEECH 2007, Antwerp, Belgium, 2007, pp. 1833-1836. 
10. C. Y. Lin and H. C. Wang (2008), “Mandarin stops classification based on random forest 
approach,” International Symposium on Chinese Spoken Language Processing, ISCSLP2008, 
pp.241-244. 
11. C. Y. Lin and H. C. Wang (2010), “Using burst onset information to improve stop/affricate 
ohone recognition,” IEEE International Conference on Acoustics, Speech, and Signal 
Processing, ICASSP2010, Dallas, Texas, 2010, pp. 4862-4865. 
12. C.Y. Lin and H.C. Wang (2011), "Burst Onset Landmark Detection and Its Application to 
Speech Recognition," IEEE Trans. on Audio, Speech, and Language Processing, vol.19, no.5, 
pp.1253-1264, 2011. 
13. C.Y. Lin and H.C. Wang (2011), "Automatic estimation of voice onset time for word-initial 
stops by applying random forest to onset detection," Journal of Acoustical Society of America. 
(accepted) 
14. You-Yu Lin and Yih-Ru Wang (2009), “ Sample-based Phone-like Unit Automatic Labeling in 
Mandarin Speech, “, Proc. of ROCLING 2009, Taichung, ROC. pp. 137-149, Sept. 2009. 
15. You-Yu Lin, Yih-Ru Wang and Yuan-Fu Liao (2010), “Phone Boundary Detection using 
Sample-based Acoustic Parameters, “, Proc. of INTERSPEECH-2010, Makuhari, Japan, pp. 
1397-1400, Spet., 2010. 
16. H. Y. Lo and H. M. Wang (2007), "Phonetic Boundary Refinement Using Support Vector 
Machine," ICASSP2007. 
17. H. Y. Lo and H. M. Wang (2010), "Phone Boundary Refinement Using Ranking Methods," Int. 
Symposium on Chinese Spoken Language Processing (ISCSLP2010). 
18. C. F. Lu and H. C. Wang (2010), “A Metric-based Phone Segmentation Method using Wavelet 
Transform,” Oriental COCOSDA workshop 2010, Kathmandu, Nepal, 2010, paper_ 10 
19. Chiu-yu Tseng and Chun-Hsiang Chang (2008), “Pause or No Pause ? –Prosodic Phrase 
Boundaries Revisited.” Tsinghua Science and Technology, 13.4: 500-509. 
20. Chiu-yu Tseng, Lin-shan Lee and Zhao-yu Su (2008),“Spontaneous Mandarin Speech 
Prosody—the NTU DSP Lecture Corpus.” Oriental COCOSDA 2008, Kyoto, Japan. 171-174. 
21. Chiu-yu Tseng and Zhao-yu Su (2008),  “What’s in the F0 of Mandarin Speech –Tones, 
Intonation and beyond.” ISCSLP 2008 (The 6th International Symposium on Chinese Spoken 
Language Processing), Kunming, China. 45-48. 
22. Chiu-yu Tseng and Zhao-yu Su, (2009), “Boundary and Lengthening—On Relative Phonetic 
Information.” in Frontiers in Phonetics and Speech Science (現代語音學前沿文集 ) edited 
by G. Fant, H. Fujisaki and J. Shen, 北京商務印書館, 369-379, 北京. 
23. Chiu-yu Tseng, Zhao-yu Su, and Lin-shan Lee (2009), “Mandarin Spontaneous Narrative 
Planning—Prosodic Evidence from National Taiwan University Lecture Corpus.” Interspeech 
2009, Brighton, U.K. 2943-2946. 
24. Chiu-yu Tseng, Zhao-yu Su, and Lin-shan Lee (2010). “Prosodic Patterns of Information 
Structure in Spoken Discourse—a Preliminary Study of Mandarin Spontaneous Lecture vs. 
Read Speech.” Speech Prosody 2010, Chicago, U.S.A. 
25. Chiu-yu Tseng and Chao-yu Su. (2011). Dynamic Discourse Speech Tempo and Phonological 
Timing. Accepted by ICPhS (International Congress of Phonetic Sciences)2011, 4 pages. Hong 
Kong, China. 
26. Chiu-yu Tseng, Chao-yu Su, and Chi-Feng Huang (2011), “ Prosodic Highlights in Mandarin 
Continuous Speech—Cross-genre Attributes and Implications,” Accepted by Interspeech 2011, 
the 12th Annual Conference of Speech Communication Association, Florence, Italy. 
27. H. M. Wang, J. W. Kuo, and H. Y. Lo (2010), "Improved HMM-SVM-based  Automatic 
Phoneme Segmentation," Computer Processing of Asian Spoken Languages, Consideration 
Books, c/o The Americas Group, Los Angeles, CA, USA. 
國科會補助計畫衍生研發成果推廣資料表
日期:2011/09/19
國科會補助計畫
計畫名稱: 總計畫：新世代自動語音辨識技術之研究 – 第二階段
計畫主持人: 王小川
計畫編號: 97-2221-E-007-070-MY3 學門領域: 自然語言處理與語音處理
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
1.建立資源共享平台，計畫結束之後，資源共享平台將由清華大學電機系移轉
到中央研究院資訊所，繼續提供服務。 
 
2.每年寒暑假都在中央研究院資訊所舉辦講習會，由各個子計畫主持人實驗室
的研究生與研究人員作專題報告，交換研究心得。這個講習會，也對外公開，
讓國內其他研究單位與產商了解我們研究的結果，每次參加人數約 80 人到 100
人。 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
