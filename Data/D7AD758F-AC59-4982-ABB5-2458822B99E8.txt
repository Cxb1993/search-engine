Computing Systems and Applications (IEEE RTCSA'2005), August 17-19, 
2005, Hong Kong Baptist University, Hong Kong, China (EI). 
2. Ching-Wen Chen, Chang-Jung Ku, Chuan-Chi Weng, "Design of A 
Power-aware Embedded System by Reducing of Memory Access and Address 
Transformation," accepted as a full paper by Proceedings of International 
Computer Symposium 2006 (ICS'2006), Dec. 2006. Taipei, Taiwan. 
3. Ching-Wen Chen, Ming-Chi Huang, Chang-Jung Ku, “利用區域性與變動位
址偏移量設計高效率的追蹤檔壓縮方法” submitted to Proceedings of 
National Computer Symposium 2007 (NCS'2007), Dec. 2007. Taichung, 
Taiwan. 
 
 
 
1. Ching-Wen Chen, Chang-Jung Ku, and, Chih-Hung Chang, "Designing a High 
Performance and Low Energy-Consuming Embedded System with 
Considering Code Compressed Environments", accepted as a full paper by 
The 11th IEEE International Conference on Embedded and Real-Time 
Computing Systems and Applications (IEEE RTCSA'2005), August 17-19, 
2005, Hong Kong Baptist University, Hong Kong, China (EI). 
2. Ching-Wen Chen, Chang-Jung Ku, Chuan-Chi Weng, "Design of A 
Power-aware Embedded System by Reducing of Memory Access and Address 
Transformation," accepted as a full paper by Proceedings of International 
Computer Symposium 2006 (ICS'2006), Dec. 2006. Taipei, Taiwan. 
3. Ching-Wen Chen, Ming-Chi Huang, Chang-Jung Ku, “利用區域性與變動位
址偏移量設計高效率的追蹤檔壓縮方法” submitted to Proceedings of 
National Computer Symposium 2007 (NCS'2007), Dec. 2007. Taichung, 
Taiwan. 
檔壓縮的研究分析與設計』就是更廣，更深入來分析與研究如何設計省電的嵌
入式系統與如何壓縮追蹤檔以便管理需要超大儲存空間的壓縮檔。我們主要延
續過去的研究並且對於過去著墨比較少的省電部分作更深入的分析與探討，本
計畫的主要目標為分析，評估與設計具省電效果的嵌入式系統與如何壓縮追蹤
檔的大小。 
 
第二章 本計畫研究成果 
此次的計畫我們的研究主要針對在系統中有快取以及無快取下如何兼顧
效能與省電，另外，由於在許多嵌入式系統的研究當中經常需要去分析 trace 
files，然而 trace files 是相當龐大的，因此我們在此次的計劃當中也提出了一個
有效率的 trace files 壓縮方法。本計畫完成之工作包括： 
一、 系統中無快取之省電研究 
1. 壓縮常用指令來減少記憶體存取： 
在過去的研究我們知道記憶體存取佔了系統總電力消耗相當可觀的
一部份，而這些耗電的記憶體存取絕大部分的時間都是在存取常用
指令，在這一部份研究我們主要透過將多道常用指令編碼成一道虛
擬指令，使得一次的記憶體存取能提取多道指令來降低記憶體存取
的次數，常用指令壓縮設計方法如下：(見圖 1) 
(1) 分析應用程式的 Trace 檔，然後依照 Trace 檔來統計哪些指令為
常用指令。 
(2) 將同一個 basic block 中的數道指令連續的編碼並封裝進入一道
虛擬指令。 
(3) 將常用指令放入常用指令參考表中，並將這些指令用常用指令
參考表的索引值取代。 
(4) 指令執行時，解壓所引擎會根據常用指令參考表將虛擬指令解
析出多道連續的常用指令，並將這些連續指令暫存在解壓縮引
擎中的指令暫存器中，以供處理器後續使用。 
07 6 5 4 3 2 18927 26 2524 23 22 2120 19 18 17 16 15 14 13 12 11 103130 29 28
1 01001 1 1
Table
000
Table
010
Table
001
Table
011
Table
100
Table
101
Table
110
Table
111
Controller
 
圖 2 多重參考表指令解碼流程圖 
3. 利用一對一的編碼方法來減少記憶體介面傳輸時的耗電： 
因為對常執行的指令部分作較短編碼壓縮 (將常用指令替換成參考表
的索引值) 的關係，會讓記憶體內的指令位址與原來的位址不同，在
這樣的情況下，如果要做記憶體指令的抓取就必須將原來的位址轉換
成現在的位址，這樣才可以抓到正確想要的指令，但是這份真實與原
來位址的轉換表往往都放在記憶體中，所以如果要做位址轉換將會造
成多一次的記憶體存取次的動作，為了解決這個問題，我們提出了一
對一的多道虛擬指令的方法來編碼常用指令的區塊，也就是說，當一
個常用指令區塊有幾道時 (至少大於等於兩道指令以上)，我們就放入
幾道的虛擬指令如圖 3 所示，因為常用指令佔據原始指令相當少的部
分，所以就算用一對一的方式也不會增加太多記憶體空間需求，但是
這一部份的指令卻佔據大部分的執行時間，所以對於省電而言確有很
大的差異。 
MSB LSB
b
b
c
c
c
a
g f e
g
g f
p
p
p
p
p
p
a
b
c
e
f
g
MSB LSB
b. 編碼後的記憶體架構a. 編碼前的記憶體架構
（ ）一般指令 非常用指令 
常用指令
p 虛擬指令
編碼後的常用指令
未使用  
圖 3 一對一多道虛擬指令的記憶體內容配置 
如果這個表如果設計成完全關連模式 (Fully Association , FA) 的話，
當然可以直接存取，但是 FA 的設計卻是比較耗電的，圖 4 為使用
CACTI模擬64K的快取在各種不同集合關連 (Set Association) 的快取
設計下存取一次所需的耗電量。為了有效的，快速並減少耗電的方式
來得到我們想要的指令，我們提出了具項目連結的常用位址參考表，
如圖 5 所示，透過項目連結參考表的設計，當處理器發出下一道指令
的位址且常用指令位址時，可以快速得到想要的指令，而不用存取記
憶體。 
Cache Way & Power Consumption
0
7.5
15
22.5
DM 2 4 8 16 32 FA
Cache Way
Po
w
er
 (n
J)
 
圖 4 不同的集合關連快取存取一次所需耗電量 
00008034
00009420
00008DD0
0000802C
00008030
00008DE0
0000A1C0
00009684
Address InstructionValid
00008034
00008DD0V
V
Link
0000200D
00002508
00002374
0000200B
0000200C
00002378
00002870
000025A1
0000802CV
V 00008DE0
V 00009684
000
011
010
001
111
110
101
100
00008030N
N
N
010
00009420
110
111
0000A1C0
Null
Null
Null
Null
Null
e2400b01
b2600000
bafffffa
3afffffc
34832004
e0d1c0f2
e1a04001
e1530001
Word
address
最常使用的記憶體位置
Byte
Address
Word
Address 常用指令參考表  
圖 5 具項目連結的常用位址參考表 
三、 Trace files 的壓縮方法 
     在計算機結構的研究範疇中，追蹤檔的分析與模擬是一項不可或缺的
技術，透過追蹤檔的分析不僅能夠得知一個系統複雜的執行行為，也能夠
去評估一個新開發的系統所能產生的效益。然而，追蹤檔是記錄了程式執
行時所執行過的指令以及位址，而在程式執行中，往往會有數以百萬計的
指令被執行，因此儲存追蹤檔所需要的容量也相當龐大，雖然隨著科技的
發展，儲存裝置的容量也大量的增加，但對於儲存如此龐大的追蹤檔而言，
還是有著許多挑戰與不便。 
使壓縮效果下降以外，在解壓縮的過程中也會對效能造成負面的影響。 
因此，在追蹤檔壓縮方面，我們提出了“利用區域性與變動位址偏移量設
計高效率的追蹤檔壓縮方法  (Trace File Compression with Locality and 
Adaptive Address Offset, LAAO) ＂來壓縮追蹤檔，有效縮減重複記錄位址
偏移量的問題，為了解決偏移量記錄位元的問題，我們提出了三個模式來
因應不同的程式，並且改善了標頭或識別碼對壓縮率所造成的影響。在本
論文的方法中，我們將追蹤檔中的指令分為循序位址與非循序位址，對於
非循序指令的位址加以運算後儲存在動態參考表當中，透過動態參考表的
使用來減少位址偏移量重覆記錄造成空間浪費的問題，最後，利用記錄動
態參考表的索引值取代記錄位址偏移量，來縮減儲存時所需要的空間。 
過去研究指出，大部分的程式都能夠以 16 位元來表示 99%的位址偏移量，
若將 32 位元的位址偏移量以 16 位元取而代之，則可再提高壓縮率將近
50%，也就是追蹤檔經過壓縮後的空間大小約為原始追蹤檔的 25%左右。
此外，因為追蹤檔裡的位址偏移量具有區域性的特質，我們設計了具有類
似快取特性的動態參考表來輔助壓縮，動態參考表的功能是用來暫時存放
位址偏移量，透過動態參考表的存取，可以減少減少重覆儲存相同位址偏
移量的次數。另外，我們記錄動態參考表欄位的索引值來減少記錄完整位
址偏移量所需的空間。 
第三章 設計方法模擬驗證分析 
在本計畫的計畫中，我們設計了多個有效的方法來解決嵌入式系統中電量
消耗、效能的相關問題。為了驗證我們的設計方法可以確實的達到我們所要求
的目標，我們將我們的設計方法作了一系列的模擬與驗證，以下為我們各個設
計的實驗結果分析。 
一、 系統中無快取之省電研究 
1. 壓縮常用指令來減少記憶體存取 
在記憶體存取時，越大的記憶體一次存取的電量相對越大，在這一部
份，我們除了壓縮常用指令來減少記憶體存取外，我們也針對不常用
指令進行壓縮來減少記憶體需求量已縮減記憶體大小。由於常用指令
與不常用指令在執行時的特性大有差異，因此，我們也針對執行的特
性對於常用語不常用指令使用不同的壓縮方法。 
在程式的目的碼當中，由於程式執行具有區域性，因此大約有 90%的
時間都在執行 10%的指令；換句話說，這些常用的指令就足以支配整
當一道虛擬指令被抓取時，這(32 – M)位元就會被解析出多道指令，換
句話說，我們在一次的記憶體存取就可以提取出 ⎡ ⎤NLogM 2/)32( − 道
指令。為了避免在虛擬指令解壓縮時造成記憶體存取，我們將參考表
放置在解壓縮引擎當中，在這個參考表中包含了常用指令的原始型態
以提供解壓縮所需之查找。解壓縮時，解壓縮引擎會抓出虛擬指令中
的 code word，並將其當作索引值來存取參考表以得到原始的常用指
令。由於常用指令的個數非常少，因此在解壓縮引擎中因為參考表所
需要的額外空間也將當的小。若常用指令的個數為 64 或 128 個且指令
的長度為 32 位元(4 位元組)，則在解壓縮引擎當中需要額外的參考表
空間個別為 256 或 512 位元組。圖 7 顯示了我們所提出的嵌入式系統
結構。 
Mircoprocessor
Core Decompress
Engine
Register 1
Frequently
Used
Instruction
Table Instruction
MemoryRegister 3
Register 2
Register n 0
1
.
.
.
CPU
 
圖 7 具單一常用指令參考表之系統結構 
在實驗環境以及標竿程式的部分，我們使用 ARM SDT 2.5 模擬工具來
執行 Media Bench 標竿程式，以下我們列出存取記憶體以及解壓縮引
擎中參考表的電量資訊： 
z 存取主記憶體所需花費的電力：4.4nJ. 
z 表 1 說明了存取不同大小的參考表所需耗費的電量。此電力資訊由 CACTI 
3.0 模擬工具在 0.25μm 所提供。 
表 1 存取不同大小參考表所需耗費的電量 (nJ) 
The number of the FIs Reference table size (Byte) Energy (nJ) 
16 64 0.403 
32 128 0.413 
64 256 0.422 
128 512 0.443 
數之縮減 (LAT 表位於記憶體) 
在 LAT 表放置於解壓縮引擎當中且 10%的常用指令以不壓縮的型態存
放在記憶體當中，記憶體存取次數將縮減為 63.72%，而記憶體的需求
將增加為 6%，如圖 10 所示。 
50%
60%
70%
80%
90%
100%
0 5% 10% 15% 20% 30% 35% 40% 45% 50%
Percentage of freq. instructions
Pe
rc
en
ta
ge
 o
f m
em
or
y
ac
ce
ss
 ti
m
es
g721encode
g721decode
pegwit_e
pegwit_d
sorts
timing
50%
60%
70%
80%
90%
100%
0 5% 10% 15% 20% 30% 35% 40% 45% 50%
Percentage of freq. instructions
Pe
rc
en
ta
ge
 o
f m
em
or
y
ac
ce
ss
 ti
m
es
avg
 
圖 10 不同比例的常用指令以不壓縮的方式存在於快取之中所造成的記憶體存
取數之縮減 (LAT 表位於解壓縮引擎) 
這一部分我們將模擬透過將常用指令編碼並將多道編碼過的常用指令
包裝成一道虛擬指令以減少記憶體存取次數在電力消耗與效能的影
響。我們將針對幾個不同的常用指令個數進行實驗。在本次的實驗當
中我們考慮當常用指令為 24, 25, 26 … 及 29 且參考表放置於解壓縮
引擎當中的情況。 
從圖 11 及圖 12 的實驗結果我們可以發現，當常用指令數為 256 道時
的電力消耗與字典壓縮法相比縮減了 50%。而在壓縮率方面卻較字典壓
縮法增加 2%~4%，如圖 13 所示。這是因為某些虛擬指令當中只包含一
道常用指令所導致，而這樣的情況也將導致壓縮率的下降。為了解決
這樣的問題我們將這一類的虛擬指令作下列兩種處理。1)利用字典壓
縮法壓縮這類指令。這樣的方法能夠讓壓縮率提升，但是由於字典壓
縮法在解壓縮時需要多次記憶體存取，因此可能導致電力消耗上升。
2)完全不壓縮這類指令。這樣的做法無法改善壓縮率，但由於不需要
解壓縮時所需的記憶體或參考表存取，因此電力消耗將獲得改善。 
70
72
74
76
78
80
D-B 16 32 64 128 256 512
Number of FIs
C
om
pr
es
sio
n 
ra
tio
 (%
)
g721decoder g721encoder timing sorts
pegwit_d pegwit_e avg.
t
 
圖 13. 不同常用指令數下的壓縮率 
 
 
65
70
75
80
D-B 16 32 64 128 256 512
Number of FIs
C
om
pr
es
sio
n 
R
at
io
 (%
)
g721decoder g721encoder timing sorts
pegwit_d pegwit_e avg.
 
圖 14. 不同常用指令數下的壓縮率  
(若虛擬指令中只包含一道常用指令則使用字典壓縮法壓縮該指令) 
 
010
20
30
40
50
D-B 16 32 64 128 256 512
Number of FIs
Po
w
er
 C
on
su
m
pt
io
n 
  (E
-0
2 
n
J)
g721decoder g721encoder timing sorts
pegwit_d pegwit_e avg.
 
圖 16. 不同常用指令數下的電力消耗 (若虛擬指令中只包含一道常用指令則該
道指令不壓縮) 
2. 利用多重參考表來減少記憶體存取的次數 
根據 1.的說明，我們知道總常用指令數與在虛擬指令中可以容納的
code word 數恰好構成了系統中效能與電力消耗的 trade off。若希望常
用指令的數量能大到足以涵蓋整個系統主要的執行時間，那麼常用指
令在編碼過後所形成的 code word 長度勢必會增加。因此，在每次存
取記憶體所能提出的常用指令變少的情況下，系統的效能與電力消耗
將會受到影響。相對的，若希望一道虛擬指令能包含更多的 code 
word，那麼總常用指令就必須少，而這些常用指令所涵蓋的執行時間
會相對變少。這樣一來會導致無法有效縮減因為這些常用指令所造成
的頻繁記憶體存取。 
為了解決這樣的問題，我們提出一個多重參考表的方法，將原本在解
壓縮引擎中單一的參考表改為多重參考表，使得一道虛擬指令能夠容
納更多的 code word 進而減少記憶體存取的次數。 
在我們的方法中，我們將所有的常用指令(N)分成 K 個群組，每個群組
約有相同數量的常用指令(≈ N/K)。在分群的方法中，我們讓會連續被
執行的常用指令分配在同一個群組當中。在常用指令分群之後，每一
道指令都會被編碼成固定長度的 code word ⎡ ⎤)/( 2 KNLog ，並將多道連
續並屬於同一個群組的 code words 封裝進一道虛擬指令。在虛擬指令
當中必須有 個位元來識別虛擬指令當中的 code word 屬於哪
個參考表。依照這樣的分群方法，虛擬指令中編碼過的 code word 長
⎡ )( 2KLog ⎤
舉例說明： 
若常用指令為 512 道佔了總執行指令數的 95%且 Load/Store 指令佔了
總執行指令的 30%，由上面的式子推導得知，使用兩個參考表比使用
單一參考表減少了 20.65%的記憶體存取。 
圖 11 與圖 12 為我們在封裝方法的設計之下所得到的電量消耗與
跟字典壓縮法的比較，一般來說，封裝的方法在各個標竿程式的模擬
之下皆可以有效的節省字典壓縮法的電量消耗。其效果在使用 256 道
常用指令時更為明顯，所得到的電量消耗約可以減少字典壓縮法 40～
50％的電量消耗。值的注意的是圖 11 與圖 12 中，在 512 道常用指令
的封裝方法之下，整體的電量消耗遠遠大於 256 道常用指令的電量消
耗。這樣的結果也直接反映了我們在計畫內容中所述『多重參考表』
方法設計的必要性（詳見計畫內容）， 
在本計畫的計畫中，我們為了使封裝的方法得到最大的電量節省
與效能提升，我們在計畫內容中提出了多字典表的封裝方法，在實驗
中我們利用兩個 256 道的常用指令字典表來與一個 512 道指令字典表
比較。從表 2 中我們可以明顯的看出，我們的多字典表方法確實能夠
讓封裝方法在常用指令個數較多時得到更好的解決方案。 
表 2. 封裝方法中利用一個 256、512 道常用指令字典表與兩個 256 道常用指令
字典表的道常用指令字典表的電量消耗表 
g721decoder 3.31e-02 1.70e-02 2.02e-02 1.57e-02
g721encoder
timing
sorts
pegwit_d
pegwit_e
2.38e-02 1.25e-02 1.45e-02 1.10e-02
1.02e-01 5.31e-02 6.63e-02 5.17e-02
1.54e-01 8.62e-02 1.01e-01 8.90e-02
2.62e-01 1.35e-01 1.61e-01 1.28e-01
4.48e-01 2.40e-01 2.81e-01 2.36e-01
Dictionary-
Based Code 
Compression 256 512
Two 256 instructions 
reference tables
Power consumption with various lookup table size (nJ)
Number of the frequently used instrucions
 
從先前的實驗結果我們可以發現，透過節省記憶體存取次數可以有效
的改善效能與電力消耗。然而，改善的程度必須依賴常用指令的數量
以及一道虛擬指令能包裝多少常用指令。當常用指令數增加時，一道
虛擬指令所能包裝的常用指令數就會減少，記憶體存取次數也會隨之
增加。為了解決這樣的問題我們提出「多重參考表」，這個方法能在常
用指令數多的情況下使編碼後的 code word 長度較短。我們將使用多
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
256 512 Two 256 inst.
Reference tableThe Number of the FIs
N
or
m
al
iz
ed
 P
ow
er
C
on
su
m
pt
io
n
g721decoder g721encoder timing sorts
pegwit_d pegwit_e avg.
Dictionary-Based
 
圖 19. 在使用單一 256 道指令參考表、單一 512 道指令參考表以及兩個 256 道
指令參考表下所造成的電力消耗 (與字典壓縮法相比) 
3. 利用一對一的編碼方法來減少記憶體介面傳輸時的耗電 
我們在本計畫計畫中提出一對一的編碼方法，是對於壓縮過後記憶體
內部的指令位址與原來的位址不同，在記憶體做指令抓取時必須將原
來的位址轉成現在位址，而此份轉換表往往放於記憶體內部，造成多
一次的記憶體存取動作。在實驗中我們使用一對一的編碼方法，也就
是說，當一個常用指令區塊有幾道時 (至少大於等於兩道指令以上)，
我們就放入幾道的虛擬指令如圖 20 所示，在記憶體做指令抓取時不須
做位址轉換的動作。以下說明常用指令的編碼過程：當一個常用指令
區塊有 K 道指令並且假設一道虛擬指令可以放入三道編碼過的常用指
令且 K 大於等於三，則第一道虛擬指令放入常用的一到三，第二道放
入二到四，第三道放入三到五等等，第 K-2 道放入 K-2 到 K，第 K-1
道放入 K-1 到 K，最後第 K 道放入第 K 道編碼過的指令。如此的話，
每一道虛擬指令裡面的第一道都是原來的指令的索引值，所以當處理
器發出抓取指令時如果抓到的是虛擬指令的話，透過解壓縮引擎，這
道虛擬指令將可以解出原來的指令，如果這道虛擬指令含有多道的索
引值時，這些指令將留在解壓縮引擎內部，以作為後續使用。如此不
僅可以減少記憶體存取的次數，對於跳躍指令也可以正確無誤地抓到
要目地指令而不用經過複雜的轉換。 
表 3 在各個不同數量的常用指令個數下（16～512），使用一對一方法所得到的
整體系統電量消耗量表 
g721decoder 1.21e-02 9.32e-03 943e-03 8.14e-03 7.82e-03 7.40e-03 8.62e-03
g721encoder
timing
sorts
pegwit_d
pegwit_e
Average 
Saving
8.68e-03 6.92e-03 6.67e-03 5.79e-03 5.65e-03 5.40e-03 6.16e-03
1.03e-01 9.44e-02 8.15e-02 7.48e-02 7.16e-02 6.63e-02 7.58e-02
1.76e-01 1.55e-01 1.33e-01 1.25e-01 1.24e-01 1.15e-01 1.30e-01
6.01e-02 4.02e-02 3.97e-02 3.81e-02 4.10e-02 4.06e-02 4.59e-02
3.69e-02 3.33e-02 2.77e-02 2.28e-02 2.26e-02 2.29e-02 2.75e-02
0% 17.7% 24.86% 32.9% 33.5% 36.22% 26.55%
Original
Arch. 16 32 64 128 256 512
Power consumption under various reference table sizes (nJ)
Reference table size (Byte)
Benchmarks
 
二、 系統中有快取之省電研究 
1. 利用混合壓縮與解壓縮程式碼的 Cache，來提高命中率： 
當快取存在於系統當中，且快取中存放的為壓縮過的指令時，一旦資
料需要存快取送到處理器執行時，都必須經過繁複的解壓縮程序，這
樣的解壓縮程序不僅會對效能造成嚴重的影響，解壓縮所造成的電力
消耗更會影響嵌入式系統產品的價值。然而，由於程式執行具有區域
性，因此大部分的解壓縮時間都是在處理少部分的指令，因此，為了
降低解壓縮所需要的代價，我們提出了混合式快取的方法，利用區域
性針對不同特性的指令採用不同的型式存放於快取當中。設計方法如
下：  
（1） 為了在固定大小的 Cache 下能夠兼顧執行的效能與提高 Cache
的命中率。我們設計了混合式的 Cache 架構，如 22 所示。 
（2） 讓壓縮過的與解壓縮過的程式碼並存在 Cache 中。首先將
Cache 分成兩塊，一塊放置解壓縮過的，一塊放置壓縮過的，
Cache 有自己的替換策略。 
（3） 系統將依照規定來決定，哪些程式碼應該用壓縮的方式存在
Cache 中或是用解壓縮的方式存在 Cache 中？如圖 22 所示，
Cache Refill Engine 具有解壓縮功能並將壓縮過的或是解壓縮
過的程式碼放到 Cache 的功能，當 CPU 要資料或程式碼而且
資料在 Cache 時，可以抓取解壓縮過的，或是立即做解壓縮的
動作。 
Pegwit_d
0
20
40
60
80
100
128 256 512 1024 2048 4096 8192 16384 32768
cache size (in byte)
po
w
er
 c
on
su
m
pt
io
n 
(m
J)
PreCache PostCache Hybrid coutead in cache
 
圖 24. 標竿程式 Pegwit_d 使用 pre-cache、post-cache 與混合式快取在不同 cache 
size 下電源消耗圖 
timing
0
20
40
60
128 256 512 1024 2048 4096 8192 16384 32768
cache size  (in byte)
po
w
er
 c
on
su
m
pt
io
n
(m
J)
PreCache PostCache Hybrid coutead in cache  
圖 25. 標竿程式 timing使用 pre-cache、post-cache與混合式快取在不同 cache size
下電源消耗圖 
2. 透過 Link-Cache 的技術來改善快取衝突並提高快取命中率 
為了減少在執行常用指令時所需要的記憶體存取，我們提出了快速有
效的常用指令參考表的設計，就是希望當處理器發出下一道指令的位
址時，如果這道指令存在常用指令參考表中，就可以直接存取而不需
要到記憶體抓取這道指令的索引值。要達成這樣的目的，就是要重新
設計與安排常用指令的參考表，讓處理器發出位址的時候可以直接或
是透過運算來參考這個表。當然，如果這個表如果設計成完全關連模
式 (Fully Association , FA) 的話，當然可以直接存取，但是 FA 的設計
卻是比較耗電的，圖 26 為使用 CACTI 模擬 64K 的快取在各種不同集
合關連 (Set Association) 的快取設計下存取一次所需的耗電量。為了
有效的，快速並減少耗電的方式來得到我們想要的指令，我們提出了
Link 欄位時，如果此欄位不為 NULL，則沿著連結一直找下去只到找
到 NULL 為止。於是將 NULL 的值填入目前這道指令填入的位址。就
是用這樣的方式將所有衝突的指令填完為止，於是，如果有 N 道常用
位址的指令，這些指令將會被填入具有 N 個項目的常用位置參考表
中。在圖五我們以八道指令為例子，說明這八個項目的常用位址參考
表是如何被填入的。當常用位址參考表填入完成後，以下我們將解釋
如何應用這個表來減少記憶體存取的次數。 
00008034
00009420
00008DD0
0000802C
00008030
00008DE0
0000A1C0
00009684
Address InstructionValid
00008034
00008DD0V
V
Link
0000200D
00002508
00002374
0000200B
0000200C
00002378
00002870
000025A1
0000802CV
V 00008DE0
V 00009684
000
011
010
001
111
110
101
100
00008030N
N
N
010
00009420
110
111
0000A1C0
Null
Null
Null
Null
Null
e2400b01
b2600000
bafffffa
3afffffc
34832004
e0d1c0f2
e1a04001
e1530001
Word
address
最常使用的記憶體位置
Byte
Address
Word
Address 常用指令參考表  
圖 27. 具項目連結的常用位址參考表 
當處理器發出下一道指令的位址時，這時候我們利用直接對應的方式
來算出這道指令應該出現在常用位址參考表的哪一個位置，接著，我
們看那個位置的 Valid 欄位，如果這個欄位的內容為 N 表示這道指令
不屬於常用的位址指令，不存在表內，表示就要到記憶體抓取，如果
欄位的值為 V 表示，這道指令可能在表內，於是我們就看其位址欄位，
如果對了，表示命中，於是就將相對的指令送給處理器，如果沒有，
就沿著 Link 欄位的項，一項一項查下去，直到 Link 欄位為 NULL 為
止。如果一直追蹤到 NULL 表示這個位址的指令不存在常用位址參考
表中，所以必須到記憶體抓取。當然這樣的設計可能一道指令會多次
存取常用位址參考表。但是，因為這個表是收集常用的百分之九十的
位址來填入的，也就是，這樣的設計會讓百分之九十的執行指令，在
這個參考表中內被找到，進而大幅的減少記憶體存取的次數。同時我
們也將評估，因為減少記憶體參考所節省的電源與多次參考表的額外
負擔所造成的影響的評估，進而設計出較為省電的具項目連結常用位
址參考表，另外，根據 CACTI 的評估數字，Direct Mapping 存取一次
的耗電與 2-Way Set Association 的耗電並不會相差太多，但是，使用
K-Way Set Association 的方式卻可以減少因為連結造成多次讀取參考
表的延遲情況。所以，我們除了要評估 Direct Mapping 的方式外，我
們同時也會評估其他 Way Set Association 耗電量。並且做出設計的建
表 5. 連結式快取與不同關聯度的傳統快取電量比較表 
g721decoder 1.28e-02 1.22e-02 4.93e-03
g721encoder
pegwit_d
Pegwit_e
sorts
timing
8.65e-03 9.32e-03 3.71e-03
9.62e-02 9.97e-02 2.81e-02
1.66e-01 1.72e-01 5.68e-02
5.42e-02 5.51e-02 1.32e-02
3.92e-02 3.67e-02 8.70e-03
512-instructions 
link cacheD.M. Two-way Four-way Eight-way
Power consumption with cache size 2k bytes (nJ)
Associativity
7.61e-03
5.86e-03
4.78e-02
8.97e-02
2.21e-02
1.51e-02
1.64e-03
1.28e-03
2.26e-02
4.17e-02
6.26e-03
3.86e-03  
三、 Trace files 壓縮方法 
(一) 壓縮追蹤檔的設計 
過去在處理器與記憶體的研究中，通常會透過追蹤檔來做模擬，但追蹤檔的
檔案往往都很大，因此造成儲存上的困難，所以為了減少追蹤檔的大小，就勢必
需要做追蹤檔的壓縮。而因追蹤檔是儲存程式執行的過程，在其中會有區域性的
特徵，使用一般常見的壓縮方法並不能有效的減少其儲存空間。另外，為了研究
上的方便，追蹤檔的壓縮方法必需能夠支援即時的解壓縮功能，而為了有效的提
升解壓縮的時間，我們在設計上將採用固定長度的編碼方式，來降低解壓縮的複
雜度。 
在我們的壓縮方法中，將追蹤檔分為四個部分來儲存，分別是位址與指令對
照表、循序位址表、壓縮表以及記錄檔來儲。以下我們將一一說明上述四個表的
設計重點與原理。 
1. 位址與指令對照表：對於追蹤檔中的指令，我們只需儲存一份位址對應
到指令的參考表，並利用此參考表，即可還原出該道位址所執行的指令。
程式執行時，是由處理器發出一道位址，並且透過該位址到記憶體中存
取指令。而追蹤檔則是記錄程式的執行行為，其中每個欄位都是由位址
與該位址所對應到的指令所組成，每道位址會對應到唯一一道的指令，
所以只要儲存位址與指令的對應，那麼就可以透過位址來還原指令，所
以可以節省大約一半的儲存空間。並且，因為指令的區域性並沒有位址
來的強烈，所以我們希望利用此區域性來對位址做壓縮，來得到更好的
壓縮率。 
2. 連續位址的壓縮：根據過去的研究指出，跳躍指令約佔執行指令的 20% ~ 
25%，其中這些跳躍指令，要做跳躍又佔 53%，所以總體來說，追蹤檔
中會跳躍的指令只佔 10% ~ 13%的比例。換句話說，大部份的指令 (90% 
~ 86%) 都是執行下一道指令，即是循序執行的指令，而下一道指令的位
址即為 PC = PC+4。所以對於這些循序執行的指令，若我們能夠盡可能的
減少其儲存的空間，那麼便可能很有效減少追蹤檔的大小。 
基於上述的動機與分析，我們可以將追蹤檔的位址分成兩類，循序
位址 (PC=PC+4) 與非循序位址，針對兩種不同的類型，我們分別使用了
以使用簡單的方式來表示之，然而，對於非循序位址而言，因位址偏移
量相差的數值並不固定，所以必需記錄此偏移量值。在壓縮時，若為非
循序指令時，將循序位址表當中記錄為 1，並且計算其位址與上一道位址
的位址偏移量，再記錄到原始位址偏移量表當中，如圖 29 所示。而程式
執行時，分支指令產生了非循序執行的情形，而分支指令可能會往前執
行或往後執行，偏移值可能為負數，所以我們使用 2 補數的方式來表示
正負數。  
經由上兩步驟的壓縮，大約可達到的壓縮率計算方法如下：假設追
蹤檔中有 C 道指令，所以追蹤檔共需要 2*C*32 bits 的空間 (2*C 為指令
與位址)，假設非循序指令的有 K 道，經過我們的設計，所需的儲存空間
為 (K*32+C)/2*C*32，因為 K 大約為 C 的十分之一，所以壓縮率約為 
(0.1*32+1) /2*32 = 6.56%。 
3. 減小位址偏移量表的大小：透過以上的分析我們發現，原始變動位址表
中的容量大小佔了全部的四分之三左右 ( k*32/(K*32+C) )，如果可以減
少原始位址偏移量表中記錄的長度，那麼將有助於壓縮率的提升。而在
這一部份我們使用 16 位元的長度來取代記錄 32 位元的偏移值，並將之
記錄在變動位址表中，如圖 30 所示。 
透過過去學者研究指出，在執行 Spec92 的標竿程式，有 75%左右的
指令只需要 12 位元的位址偏移量，將可以得到以下的壓縮率：
(0.1*(3/4*12+1/4*12)+1)/2*32=4.218%，而將位址偏移量的記錄長度設定
成 16 位元的話，則可以覆蓋到 99%的位址，並得到以下的壓縮率：
(0.1*(0.99*16+0.01*32)+1)/2*32=4.088%。雖然使用 12 位元的位址偏移量
可達到較好的壓縮率果，但是有 25%的位址無法使用 12 位元的長度來記
錄，所以對這些位址必需額外增加標頭來區別，反而會造成壓縮效果不
如預期。而使用 16 位元來記錄位址偏移量，則可包含 99%的位址偏移量，
只有 1%的偏移量需要做額外的處理，經由此計算，壓縮率則可到達
2.5%。而對於無法使用 16 位元所表示的偏移值我們將在 3.4 節討論。 
00008000
00000014
FFFFFFF8
FFFFFFF8
FFFFFFF8
00001E04
原始位址偏移量
32 bits
0000
0014
FFF8
FFF8
FFF8
1E04
變動位址表
16 bits
化簡
 
圖 30 減化位址偏移量的大小 
4. 利用動態參考表取代位址偏移量表：在第三部分我們已經將變動位址表
的每個偏移量的寬度變小，但在圖 30 當中，我們可以發現，變動位址表
中會記錄重複的位址偏移量，此一部分我們將要再利用其具有的區域
性，來進一步的縮短位址偏移量表的大小。 
位址偏移量表當中記錄著非循序位址的偏移量，若遇到迴圈，則會
產生大量重複的位址偏移量。比如說如果迴圈執行 1000 次，每當執行到
表，反之亦然。為了得到最佳的動態參考表欄位數目，我們會對各個欄
位數進行模擬。 
(二) 壓縮流程 
我們提出的壓縮方法會將追蹤檔分成四個部分記錄，分別是位址與指令對照
表、循序位址表、壓縮表以及記錄檔，其壓縮的流程如下： 
1. 透過靜態程式碼，產生位址與指令的對照表。 
2. 計算位址是否為循序指令，若為循序位址則在標示為 0，若遇到非循序
位址則標示為 1，並將之儲存到循序位址表中。 
3. 對於非循序位址，在儲存循序位址表的同時，計算其 16 位元的位址偏移
量，並接續壓縮流程 4。 
4. 尋找動態參考表中是否已有此筆偏移量，如果有，就在壓縮表中記錄 1
與動態參考表欄位的索引值。如果動態參考表中沒有這筆資料，就將此
筆偏移量依照取代的策略放入動態參考表的欄位中，並且在壓縮表中記
錄 0 與所放置的欄位索引，最後將此筆偏移量放入變動位址表中儲存起
來。 
(三) 解壓縮流程 
在我們的設計當中，變動位址表 (如圖 29 所示) 記錄著每道非循序指令與
其上一道指令之間的位址偏移量，動態參考表在解壓縮的過程扮演著類似快取的
角色，在動態參考表當中儲存著最近被使用到的幾個位址偏移量，而壓縮表則告
訴我們目前欲解壓縮的指令其位址偏移量是否存在於動態參考表當中，並清楚的
指出該指令的位址偏移量存在動態參考表的第幾個欄位。除了一般的批次解壓縮
外，這個解壓縮方法也支援了在執行時的動態解壓縮，以下，我們將依序的說明
本論文中所提出的解壓縮流程： 
1. 參考圖 32(a)，先循序讀取壓縮表，若目前壓縮表欄位中的資料開頭為 0
表示該位址偏移量不存在動態參考表當中，此時我們依據壓縮時所產生
的紀錄檔(見圖 31)依序載入一個位址偏移量至動態參考表的欄位中(壓
縮表欄位中第一位元以後的值即為此該位址偏移量在動態參考表中的索
引值)，並將此位址偏移量依序記錄於位址偏移量表當中。 
2. 若壓縮表欄位中資料開頭為 1 表示該位址偏移量存在動態參考表當中，
我們依據壓縮表欄位中的索引值至動態參考表中提取出位址偏移量並記
錄於位址偏移量表中。 
3. 當位址偏移量表產生完成後，就可以依據循序指令表以及位址偏移量表
來還原指令位址，此時參考圖 32(b)解壓縮步驟，依序讀取循序指令表，
當讀取到第一個 1 時，我們將位址偏移量表中第一個位址偏移量與起始
位址相加並將結果記錄於指令位址表當中，之後，若在循序位址表中讀
取到 1，則依據將位址偏移量表中的位址偏移量與指令位址表中最後一
道位址相加，並且將結果記錄於指令位址表當中。 
4. 若在循序位址表中讀取到 0，表示此道指令與前一道指令的位址連續，
此時只需要將指令位址表中最後一道指令位址加 4 並記錄於指令位址表
中即可。 
5. 在還原指令位址之後，就可以透過指令位址與指令的對應來還原出原始
0000
0014
FFF8
FFF8
FFF8
1E04
FFFC
FFFC
FFFC
位址偏移量表
1
0
0
0
0
1
0
0
0
0
1
0
0
1
0
0
1
0
0
0
1
循序位址表
1 bits
00008000
起始位址
1
0
1
0
1
0x008000
0x008004
0x008008
0x00800C
0x008010
0x008024
0x008028
0x00802C
0x008030
0x008034
0x00802C
0x008030
0x008034
0x00802C
0x008030
0x008034
0x00802C
0x008030
0x008034
0x008038
0x00AE3C
位址
32 bits
0x00AE38
0x00AE3C
0x00AE38
0x00AE3C
0x00AE38
起始
位址
加偏
移值
前一位址
加偏移值
 
圖 32 解壓縮流程圖 (b) 
當程式中指令的位址偏移量大多是超過 16 位元能表示時，則使用常態模
式，在常態模式下每道指令的位址偏移量都以 20 位元表示。 
在特別模式下，我們將 cjpeg，pegwit_d 以及 pegwit_e 這三個標竿程式的追蹤檔
做特別處理，在這些標竿程式的追蹤檔我們以 20 位元來記錄位址偏移量，而其
他的標竿程式的追蹤檔則用 16 位元處理位址偏移量。 
(五) 實驗結果 
在本次的實驗我們採用 Media Bench 中的 cjpeg、g721decoder、g721encoder、
pegwit_d、pegwit_e、sorts 以及 timing 作為標竿程式並以 ARM STD2.5 來模擬
ARM 系統的工作環境。實驗的流程如下：首先，我們將標竿程式導入 Strong ARM 
STD2.5 中，編譯器會將程式編譯成 ARM7 所能夠執行的靜態程式碼，利用分析
此靜態程式碼可以得知整個程式未壓縮前的空間大小，我們使用 ARM STD 2.5
的 Debugger 執行前一步所產生的靜態程式碼，並產生追蹤檔。 
 
以下的實驗將對我們所提出的方法中三種模式進行模擬，針對 Media Bench
中的七個標竿程式在不同的動態參考表欄位數下進行壓縮率及壓縮時間的模擬。 
在動態模式下，位址偏移量仍然以 16 位元為主，若有指令其位址偏移量需
要大於 16 位元表示，則在此指令之前一道位址偏移量後加入識別碼來告知，在
圖 33 中，我們發現到當動態參考表欄位數為 32 時表現最為突出，平均壓縮率達
3.189%，而在此圖 32 中，可以發現又以 pegwit_e 的壓縮率最出色。在壓縮時間
 
圖 35 常態模式下的壓縮率 
 
圖 36 常態模式下的壓縮時間
在特別模式中，我們僅對 cjpeg，pegwit_d 以及 pegwit_e 這三個標竿程式的
追蹤檔做特別處理，以 20 位元來記錄位址偏移量，而其他的標竿程式的追蹤檔
則用 16 位元處理位址偏移量，圖 37 與圖 38 顯示了特別模式下所產生的壓縮率
以及壓縮時所需要的時間，對於不同的標竿程式同樣是在變動位址表欄位數為
32 時有最佳表現。 
 
圖 39 三種模式的壓縮率比較圖 
 
圖 40 三種模式下的壓縮時間比較圖 
在比較本論文方法中的三種模式後，以下我們將就本論文所提出的壓縮方法
與過去其他的壓縮方法(PDAT，LBTC，SBC)進行壓縮率、壓縮時間以及解壓縮
時間的比較。 
在圖 41 中，同樣的我們使用 Media Bench 中的六個標竿程式進行壓縮率方
面的比較，從圖中可以發現，我們所提出來的壓縮方法在各個標竿程式中都達到
最佳的壓縮率表現。而在 LBDT 的壓縮率偏高的原因，如同之前所提，因為 LBDT
需要在每道壓縮的位址後面加上識別碼，並且如果沒有在快取命中的情形下，就
必須用記錄整道位址以及指令，所以此壓縮效果比較不理想。另外，SBC 壓縮
法在壓縮率上整體表現皆不甚理想，其原因是此壓縮法較適合用在迴圈數量多且
每個迴圈會被多次執行的程式上，所以對於迴圈數較少的標竿程式就難達到較好
的壓縮率，值得注意的是，在 pegwit_d 以及 pegwit_e 這兩個標竿程式當中具有
較多執行頻率較高的迴圈，因此，對於這樣的標竿程式 SBC 壓縮法就能達到較
好的壓縮效果。 
判斷一個壓縮方法的優劣，除了從壓縮法所能夠達到的壓縮率來判斷以外，
壓縮時的效率也是非常重要的因素。然而，希望達到好的壓縮率經常需要犧牲掉
壓縮時間或解壓縮時間。比較圖 41、圖 42 我們可以發現，雖然在這四個壓縮方
法當中，本論文提出的壓縮方法具有最佳的壓縮率，但在平均壓縮時間上的表現
也是最佳。 
計畫成果自評 
在本計畫的計畫中，我們已經達成了以下的目標： 
一、 系統中無快取之省電研究 
1. 壓縮常用指令來減少記憶體存取： 
當我們將常用指令數設定為 256 道時並且把多道常用指令編碼成
一道虛擬指令與使用字典壓縮法壓縮所有的指令相比在執行時的
總電力消耗縮減了 50%。而在壓縮率方面卻只較字典壓縮法增加
2%~4%。 
2. 利用多重參考表來減少記憶體存取的次數： 
當我們使用兩個 256 道常用參考表比起使用一個 512 道常用參考
表再節省 12.11%的電源消耗。 
3. 利用一對一的編碼方法來減少記憶體介面傳輸時的耗電： 
在常用指令在 128 與 256 道時，比使用原始指令可達到電量節省
33%到 36%。 
二、 系統中有快取之省電研究 
1. 利用混合壓縮與解壓縮程式碼的 Cache，來提高命中率： 
在快取大小2K bytes、常用256道指令，在電源消耗上比post-cache
平均節省少 28.9%，另外使用混合式快取在記憶體存取次數比
pre-cache 平均減少 23%。 
2. 透過 Link-Cache 的技術來改善快取衝突並提高快取命中率： 
使用直接對映的連結式快取在電量消耗上可比使用完全關聯度的設
計達到平均節省 43%。另外，使用連結式快取與使用各種不同關聯
度的傳統快取相比，電量消耗約只有傳統關聯式快取的 53%–83%。 
三、 Trace files 的壓縮方法 
在實驗中，我們將我們的方法與 PDAT、LBTC 及 SBC 三種壓縮方法進行比
較，實驗結果顯示，無論在壓縮率以及壓縮時間我們所提出的 LAAO 壓縮
方法都有最好的表現，在解壓縮時間上也僅次於 SBC 壓縮法。 
 
 
行政院國家科學委員會補助國內專家學者出席國際學術會議報告 
                                                            95 年 9 月 19 日 
報告人姓名 
陳青文 
(Ching-Wen Chen) 
服務機構
及職稱 
逢甲大學 
資訊工程系 
助理教授 
     時間 
會議 
     地點 
9 月 13 日至 15 日 
新加坡假日酒店 
本會核定
補助文號
 
會議 
名稱 
 (中文) 第十四屆網際網路國際會議 (IEEE ICON-2006) 
 (英文) The 14th International Conference on Networks (IEEE ICON-2006) 
發表 
論文 
題目 
 (中文) 在無線網路環境下使用連接頻寬與剩餘電量提出有效的繞路協定
 (英文) Power-Aware Routing Protocols with Link-Bandwidth and Path 
Remaining Power in Mobile Ad Hoc Networks 
報告內容應包括下列各項： 
一、參加會議經過 
此次在新加坡舉行的第十四屆網際網路國際會議 (IEEE ICON-2006)，於新加坡假日酒店
召開為期三天(9/13-9/15)，在 9 月 13 日從台灣搭乘長榮航空到新加坡樟宜國際機場，並
於 9 月 16 日從新加坡樟宜國際機場搭乘長榮航空回到台灣，感謝國科會補助此次行程
費用。在為期三天的會議過程中，共有來自全世界六十餘個國家的學者與專家參加，接
受論文篇數為 95 篇。此次研討會包含網路架構、次世代網路、群播網路技術、有線網
路與網格計算、無線隨意網路與感測網路、網路安全等許多相關主題。 
 
    大會安排在第一天的早上有Keynote speeches，其中第一天的keynote speaker 為紐西
蘭坎特伯里大學Ray Hunt演講，演講主題為Security in Wireless and Mobile Networks。其
內容主要談到，首先談到最近幾年來網路安全在商業上應用與在Wireless LANs, PANs, 
Wireless WANs, WiMAX and Wireless Broadband networks的安全的發展與相關議題。接著
討論WLANs的發展與未來的計畫，其中包含幾個重要的議題：加密工具的議題上有設
備、裝置、移動環境與驗證機制，安全議題上對於WLAN/3G與標準協定的安全測試、
計算、效能與傳輸品質作討論。此外也針對新的IEEE 802.11i的安全機制作效能的評估，
並且經由評估出來的結果提出更有效的解決方法與更好的安全機制可以使用在實際的
網路環境。除了Keynote speeches的演講外，我們聽取的多位的與會的演講。並在第三天
的下午發表我們的文章，同一時段還有其他兩位來自澳洲與一位法國與一位台灣的朋友
發表大家表現都很不錯，台下聽眾也很熱烈發問。 
 
除次之外，我們也聽取多位學者發表他們的文章，其中印象比較深刻的大都是在省
電與 Qos 相關。其中一位的題目為“Energy Aware Neighbourhood Protocol for Anycast 
Routing in Ad Hoc Sensor Networks＂。主要是討論在感測網路上能源消耗的問題並且如
何有效的降低封包接收時間與維持節點高傳輸量是系統上需要加以考量的。而此篇
Paper 討論的是利用 Recursive Aggregation 來增加資料傳輸量。 
   
另一位報告的題目為“A Reliable Qos Routing Protocol for Mobile Ad Hoc Networks 
with Multi-path Strategy’’。此篇 Paper 提出一個新的方法來增進無線隨意網路的傳輸品
質。作者利用 GPS 的輔助將 Mobile nodes 間連結時間與所經過的節點數，利用這兩項資
訊來找尋出一條穩定且不易斷線的路徑。並且經由模擬的結果驗證出這樣的方式可以有
附件三
 
行政院國家科學委員會補助國內專家學者出席國際學術會議報告 
                                                        96 年 3 月 21 日 
報告人姓名 
陳青文 
(Ching-Wen Chen) 
服務機構
及職稱 
逢甲大學 
資訊工程系 
助理教授 
     時間 
會議 
     地點 
3 月 11 日至 15 日 
香港喜來登及半島酒店 
本會核定
補助文號
 
會議 
名稱 
 (中文) 2007 年無線通訊及網路會議 IEEE 國際會議 ( IEEE WCNC 2007 )
 (英文) IEEE Wireless Communications and Networking Conference ( IEEE 
WCNC 2007 ) 
發表 
論文 
題目 
 (中文) 行動隨意網路中利用多通道之重疊子通道方法來改進效能的設計
 (英文) Multiple Channels with Overlapping Data Sub-Channel Method for 
Mobile Ad Hoc Networks 
報告內容應包括下列各項： 
七、參加會議經過 
2007 年無線通訊及網路會議 IEEE 國際會議 ( IEEE WCNC 2007 )，今年 (2007) 於香港
喜來登以及半島酒店召開，為期五天 ( 3/11-3/15 )，我們於 3 月 11 日從台灣搭乘中華航
空到香港赤臘角機場，並於 3 月 14 日從香港赤臘角機場搭乘中華航空回到台灣，感謝
逢甲大學補助此次行程費用。在為期五天的會議過程中，共有來自全世界二十餘個國家
的學者與專家參加，投稿論文篇數多達為 1721 篇來自 63 個國家，接受有 835 篇。此次
研討會主要是無線通訊與網路相關主題。 
 
    大會安排在第二天與第三天的早上有 Plenary/Keynotes，其中第三天的 Plenary 
speaker 為暨南大學校長張進福教授演講，演講主題為 Broadband and Wireless 
Communications Developments。其內容主要談到，在台灣由於 ICT 工業的成長，大概有
90％的Wi-Fi產品遍及全球，而針對其發展程度，所以台灣政府也極力促進Mobile Taiwan 
(M-Taiwan)的計劃，以建立一個 Wi-Fi 的生態系統，包含著 WiMAX equipment vendors, 
network service operators 以及 broadband wireless application。而在同一時間，台灣也積極
推動 4G 方面的研究，而張教授則針對這兩個部份進行一場深入的演說。除了
Plenary/Keynote speeches 以外，我們還聽取了多位與會的演講。並且在第二天的下午發
表我們的文章，同一時段還有其他兩位來自台灣以及美國地區的朋友發表大家表現都很
不錯，台下聽眾也很熱烈發問。 
 
除此之外，我們也聽取多位學者發表他們的文章，其中印象比較深刻的大都是在實
體層以及媒體存取層相關。其中一位的題目為“A Traffic-Load oriented Power Saving 
Mechanism for MAC Protocol in Ad Hoc Networks＂。主要是討論在行動隨意網路中媒體
存取層能源消耗的問題，作者提出動態調整睡眠週期並且以 Traffic-Load 導向來解決媒
體存取層能源消耗問題。 
   
另一位報告的題目為“A Power Control Scheme for Directional MAC Protocols in 
MANET’’。此篇 Paper 提出一個能源控制的方法，透過傳輸的方向性，並且考慮到時間
的因子，以達到增加傳輸量以及節省能源的目標。作者主要使用單一通道來完成 4-way 
handshaking 的通訊，並且考量到 hidden terminal 的問題，透過接收端取得傳輸端發送
RTC 的訊號強度，以及傳輸端取得接收端的 CTS 訊號強度，來完成兩者之間的通訊，
附件三
 
Power-Aware Routing Protocols with Link-Bandwidth and Path Remaining 
Power in Mobile Ad Hoc Networks  
Ching-Wen Chen, Keng-Hao Lai, Ching-Lung Chan 
Information Engineering and 
Computer Science 
Feng Chia University 
chingwen@fcu.edu.tw 
 
Computer Science and 
Information Engineering 
Chaoyan University of 
Technology 
s9327620@mail.cyut.edu.tw 
Information Engineering and 
Computer Science 
Feng Chia University 
m9492953@fcu.edu.tw
ABSTRACT 
In the power-aware routing protocols, the main purpose is to find the path which has the lowest power 
consumption and which extends the overall lifetime of the network. However, in the most previous 
research, the bandwidth between two mobile nodes is treated as identical no matter what the distance is 
between these two mobile nodes. In this paper, for the long lifetime routing protocol that we propose, 
we consider the fact that the bandwidth between two mobile nodes should be different when distances 
are different. With regard to our proposed long lifetime routing protocol, we find a path with the 
predictive remaining power of mobile nodes after data transmission to maximize the overall network 
lifetime. In the simulation, we compare our proposed power-aware routing protocol with the MTPR 
and MMBCR in terms of the overall network lifetime, the power consumption per bit, and the number 
of active mobile nodes after a period of time. According to the simulation results, when the bandwidth 
is considered, our proposed methods can efficiently improve the throughput and extend the overall 
network lifetime.  
Keywords: MANET, bandwidth, power-aware routing algorithm, GPS 
 
1. Introduction 
Mobile ad-hoc networks (MANETs) have received much attention lately because mobile nodes 
in such networks can communicate with each other without any infrastructure or base stations. 
Therefore, a MANET can be established quickly anytime and anywhere for use, such as in battle zones, 
secluded areas, or any other hard to reach places. However, in such networks, how to transmit data is 
important. In MANETs, each mobile node can be used as a router to forward packets; that is, a routing 
path may consist of multiple mobile nodes to which form a multi-hop path, as shown in Figure 1. When 
a path is found in a MANET, a source node can send data to the destination through these routers. 
Methods for routing in previous routing research on MANETs can be divided into two categories, 
table-driven and on-demand, as shown in Figure 2.  
In table-driven routing protocols, each mobile node has to broadcast its routing table to its 
neighboring nodes periodically. When a node receives the broadcast information, it updates its routing 
table according to the received information. As a result, a mobile node has the information of all the 
other nodes in its routing table when it receives the periodically broadcasted messages. DSDV [1], 
CGSR [2], GSR [3], and WRP [4] belong to this category. In the DSDV (Destination Sequenced 
Distance Vector) protocol, each mobile node periodically broadcasts its routing table to update the 
routing table information of other nodes. A mobile node with the DSDV method can find a routing path 
by looking up the routing table in terms of the next hop for the destination. CGSR ( Clusterhead 
Gateway Switch Routing) [2] bases its construction of a hierarchy cluster topology on DSDV. In 
CGSR, a cluster consists of a cluster head, cluster members, and gateway nodes that belong to two or 
more clusters. When a cluster member wants to transmit data to a destination that is not in the same 
cluster, it sends the data to the cluster head. Then, the cluster head sends the data to another cluster 
head using the gateway node. Finally, when the cluster head of the destination’s cluster receives the 
data, it forwards the data to the destination. GSR (Global State Routing) [3] is also a table-driven 
method. GSR is different from DSDV. In GSR a mobile node records all link states in its routing table. 
According to the routing table, a mobile node in GSR can find more routing paths. Then it can choose 
the best path from these paths. Although table-driven methods can be easily and quickly used to find 
the routing path using the local routing table, they have the overhead cost of periodic broadcasting.  
On-demand routing protocols resolve the periodic broadcasting overhead found in table-driven 
methods by adding a routing procedure before sending data. A mobile node in an on-demand protocol 
processes a procedure to find a routing path. It then uses a found path to transmit data. AODV [5], DSR 
[6], LAR [7], and ABR [8] belong to this category. AODV (Ad hoc On-Demand Distance Vector) [5] 
uses the fastest or shortest path as the routing path. When a mobile node receives a routing request, it 
helps to broadcast the request only if it has not received the same request before. As a result, same 
requests arriving later at this mobile node will be discarded. Different from AODV, DSR (Dynamic 
Source Routing) [6] collects all paths and chooses one path from these paths. ABR (Associatility-Based 
Routing) [8] chooses a stable path from the routing procedure to reduce the number of times rerouting 
2. Related Research 
In this section, we introduce power-aware related research. With regard to power-aware related 
research, we introduce a method, like Minimum Total Transmission Power Routing (MTPR) [10], that 
selects the path with the lowest power consumption path and a method, like Minimum Battery Cost 
Routing (MBCR) and Min-Max Battery Cost Routing (MMBCR) [11], that selects the path with the 
maximal remaining power. In addition, we also introduce the Conditional Min-Max Battery Cost 
Routing (CMMBCR) [12], which combines MTPR and MMBCR. 
In power-aware research related to on-demand routing protocols, MTPR [10] computes the 
power consumption of all links and chooses the path with minimal power consumption from all routing 
paths. MTPR adds the power consumption information to the RREQ. When the destination node 
receives the RREQs from different mobile nodes, it chooses the path with minimal power consumption 
and returns a RREP to the source node along the path that delivered that RREQ. Instead of computing 
the power consumption, MBCR [11] computes the sum of the remaining power of the mobile nodes in 
the path. MBCR chooses the path with maximal remaining power to improve path lifetime. Eq. (1) and 
Eq. (2) are the main equations in MBCR that are used to compute the maximal remaining power. In Eq. 
(1), the inverse of the remaining power  of a mobile node is represented by fi( ). According to 
the inverse of the remaining power fi( ), the overall remaining power of a path can be represented by 
Rj , as shown in Eq. (2)  
t
iC
t
iC
t
iC
∑−
=
=
1
0
)(
Df
i
t
iij CfR                                                                   (2) 
Finally, the destination node can use Eq. (3) to select the minimal Ri from all paths and return a RREP 
along the path used to deliver the RREQ. 
}|min{ AjRR ji ∈=                                                               (3) 
The MBCR routing protocol mainly computes and uses the sum of the remaining power of all the links 
in a path as the principle criterion for selecting a path, but the method may choose a path in which there 
is a mobile node with low power. Thus, the low power mobile node may cause path breakage. 
MMBCR [11] addresses the problem in MBCR and has a routing protocol that selects the path that has 
mobile nodes with minimal remaining power. Each path in MBCR is evaluated by the value of the 
minimal remaining power of the mobile nodes. Therefore, the destination node selects the maximal 
value of all paths and returns the RREP to the source. Eq. (4) shows the selection rule. 
)]_/1(max[min nRnSRMMBCR CapacityBatteryP ∈∈=                                          (4) 
CMMBCR [12] combines MMBCR with MTPR to save power consumption and improve the overall 
network lifetime. They pre-define a battery protection threshold to decide which methods are applied. 
If the remaining power of all mobile nodes in the paths is larger than the threshold, the MTPR method 
is used as the routing protocol. Otherwise, the MMBCR method is used.  
Although the previous power-aware routing protocols mentioned above can efficiently improve 
power consumption or overall network lifetime, these methods do not consider the link bandwidth that 
affects the remaining power and the power consumption. In the next section, we consider the link 
bandwidth issue and propose a long lifetime routing protocol. 
3. Proposed On-demand Routing Protocols 
In this section, we consider link bandwidth and predicted link lifetime and propose an on-demand 
high performance routing protocol that computes the possible amount of data that can be transmitted. 
In addition, we also present an on-demand power-aware routing protocol that improves the overall 
network lifetime by computing the possible remaining power after data transmission. 
3.1 The High Performance Routing Protocol 
In high performance on-demand routing protocols, to reduce the number of times rerouting 
occurs due to path breakage, we select the path which transmits the maximum amount of data possible. 
We use link bandwidth and possible link lifetime between two mobile nodes to compute the amount of 
data transmitted of the link and subsequently to obtain the amount of data transmitted of a path. In the 
following, we present the methods that can be used to obtain the link bandwidth and predict the link 
( ) ( )
( )
( ) bbbbb
bbbbb
bbbbb
bb
yxx
ryxy
x
ryxyyxxxx
ryyxyxxxxxx
ryxxx
ααβα
ββ
ββααβα
βαβαβα
βα
2221
2
2222
02222
2
2222
22222
2222222
222
−−++
+−−−=⇒
+−−−=−++−⇒
=−+−−++++−⇒
=−++−
                      (8) 
According to the coordinates A’ and the relative moving speed of node A, node B can obtain the 
link lifetime T. Finally, node B can use Eq. (9) to compute the distance f(t) between node A and B. 
rTfwheretvrytvrxtf yrxr =+++= )()*()*()( 22              (9) 
We let the distance-to-bandwidth relationship in Table 1 be the function g(d), where d is the 
distance between two nodes and f(t)=d from Eq. (9). Node B can use Eq. (10) to compute the possible 
amount of data transmitted according to the link bandwidth and the link lifetime.   
∫= T dttfgonTransmissiDataTotal 0 ))((__                                          (10) 
Knowing the possible amount of data transmitted between two mobile nodes, we can now 
describe, in the following, our proposed power-aware routing protocol.  
3.2 The Proposed Power-Aware Routing Protocol 
In wireless networks, some processes, including data transmission, data reception, and system 
idle, consume power. The authors of [16, 17] pointed out that the quantity of power consumption 
increases linearly with the amount of data transmitted. The power consumption equation can be written 
as in Eq. (11), where the variable m is the power consumption for transmitting a data unit and the 
variable b is the basic power consumption.  
bm*sizeCost +=                                                              (11) 
Feeney and Nilsson [17] used an IEEE 802.11b Lucent Wave LAN wireless network adapter to 
measure power consumption, as shown in Table 2. They pointed out that the power consumption for 
transmitting and receiving a data unit is different. From Table 2, we can see that transmitting a data unit 
consumes about 4 to 5 times more power than receiving a data unit. 
Besides the difference in power consumption for transferring and receiving data, the link 
bandwidth between two mobiles also affects power consumption. As a result, we modify Eq. (11) by 
taking into account the bandwidth. We divide the decay bandwidth by the non-decay bandwidth to get 
the decay bandwidth ratio p. If a mobile node takes time T to transmit data with a non-decay bandwidth, 
it takes T*1/p time to transfer the same amount of data with a decay bandwidth and the same fixed 
transmission rate. With the bandwidth taken into consideration, the power consumption for transferring 
data is as given in Eq. (12). 
b
bandwidthdecay
bandwidthdecaynom*sizeCost +=
_
__*                                            (12) 
With Eq. (11), a node can predict the power remaining after data is transmitted by computing the 
possible amount of power consumed. Based on the predicted remaining power, we propose our 
power-aware routing protocol that improves the overall network lifetime. We introduce our proposed 
routing protocol in terms of route discovery, route reply, and route maintenance. 
1) Route discovery: When a source node wants to transmit data to a destination node, it 
broadcasts a RREQ (route request) packet to its neighbors. In our proposed power-aware routing 
protocol, some fields are added to the RREQ packet in terms of the desired amount of data to be 
transmitted (DataAmount, DA), the intermediate sender’s remaining power (ReqPower, RP), and the 
current minimal predicted remaining power (MinPower, MP) of intermediate nodes. When a node 
receives a RREQ packet, it computes the sender’s possible power consumption and records the 
precedent node that has maximal power remaining (LocalMaxPower, LMP) after data transmission, as 
shown in Algorithm . In the following, we describe the procedure when a node receives a RREQ 
request. We assume that node A sends a RREQ request to node B. 
Algorithm : Procedure in node B when it receives a RREQ packet from node A { 
a. Node B gets the current minimal predicted remaining power (MinPower, MP) of intermediate 
nodes in the path, original IP address, and RREQ ID from the RREQ packet; 
b. Node B checks whether it has received a RREQ packet with the same original IP and RREQ ID 
before; 
nodes. However, if the distance is not found in Table 1, interpolation is used to obtain the link 
bandwidth. In addition, we use random waypoint model to generate node movement that has a speed of 
2~25m/s. We simulate two kinds of node density with areas of different sizes, 500x500 square meters 
and 1000x1000 square meters. The detailed parameters are listed in Table 3 .  
 
Table 2. Power consumption with IEEE 802.11b 
Lucent Wave LAN 
 
Table 3. The parameters in our simulation. 
Radio Mode Energy Consumption
Point-to-point send Cost= 1.9 * size uWs / byte + 420 uWs 
Broadcast send Cost= 1.9 * size uWs / byte + 250 uWs 
Point-to-point recv Cost= 0.42 * size  uWs / byte+ 330 uWs
Broadcast recv Cost= 0.42 * size uWs / byte+ 56 uWs 
  
Simulation time
Node speed  
Simulation range
400s
2-25(m/s)
500m*500m、1000m*1000m
Packet size 512 bytes
Parameters Values
Traffic model CBR
Data Size 100M bytes
Node Power 50W
Radio range 250m
 
With regard to the experimental results of power-aware methods, we compare our power-aware 
routing protocol with MTPR and MMBCR in terms of the route lifetime, the ratio of dead nodes, and 
the throughput. In Figures 4 and 5, in a 500x500 square meter area, the average route lifetime of our 
proposed method is longer than those of MTPR and MMBCR by 25% and 65%, respectively. In 
addition, in a 1000x1000 square meter area, the average route lifetime is also longer than those of 
MTPR and MMBCR by 15% and 60%, respectively. 
Basically, MTPR only considers the route with the least amount of power consumption. Thus 
MTPR might find a path with a minimal number of hops, like AODV when the bandwidth issue is not 
taken into consideration. However, in our simulation, we consider the bandwidth issue in MTPR; that is, 
MTPR considers the least amount of power consumption by taking into account the number of routing 
hops and the power consumption per bit. This is the reason why MTPR performs better than MMBCR. 
As a result, because MTPR does not consider the power remaining, MTPR might have a better average 
route lifetime than our proposed method when the numbers of nodes are 110 and 130 in a 1000x1000 
square meter area, as shown in Figure 5. However, MTPR has a lower ratio of active nodes than that in 
our proposed power-aware method, as shown in Figures 6 and 7. From Figures 4 and 5, we can see that 
the power consumption per bit can efficiently increase the route lifetime and that the remaining power 
also affects the overall network lifetime. 
Average route lifetime vs. Node number
0
500
1000
1500
2000
2500
50 90 13
0
17
0
21
0
25
0
29
0
node number
lif
et
im
e(
s)
our protocol MTPR MMBCR
Average route lifetime vs. node number
0
500
1000
1500
2000
50 90 13
0
17
0
21
0
25
0
29
0
node number
lif
et
im
e(
s)
our protocol MTPR MMBCR
Fig. 4. The route lifetime of our proposed 
power-aware method, MTPR, and MMBCR for 
different numbers of mobile nodes in a 500x500 
square meter area. 
Fig. 5. The route lifetime of our proposed 
power-aware method, MTPR, and MMBCR for 
different numbers of mobile nodes in a 
1000x1000 square meter area
We measure the ratio of dead nodes by computing the number of the remaining active nodes after 
400 seconds in 500x500 and 1000x1000 square meter areas. In Figures 6 and 7, the results show that 
Accordingly, we choose a path with maximal remaining power after data transmission to improve the overall network 
lifetime. From our simulation, our proposed power-aware method has better route lifetime, lower ratio of inactive nodes, 
and higher throughput than MTPR and MMBCR. In addition, from the simulation results, we also analyzed various 
issues, including bandwidth, path lifetime, and remaining power, and found that they affect the performance and the 
overall network lifetime. 
References 
[1] C. E. Perkins and P. Bhagwat, “Highly Dynamic Destination-Sequenced Distance-Vector Routing (DSDV) for 
Mobile Computers,” Computer Communications Review, pp. 234-244, October1994. 
[2] C. C. Chiang, H. K. Wu, W. Liu, and M. Gerla, ”Routing in Clustered Multi-Hop Mobile Wireless with Fading 
Channel, ” Proceedings of IEEE SICON 1997, pp. 197-211, April 1997.  
[3] T. W. Chen, M Gerla. “Global State Routing: A New Routing Scheme for Ad-hoc Wireless Networks,” 
Proceedings of IEEE Int'l Conference on Communications (ICC'98), 1998. 
[4] S. Murthy, J.J. Garcia-Luna-Aceves, “An Efficient Routing Protocol for Wireless Networks,” ACM Mobile 
Networks and App. J., Special Issue on Routing in Mobile Communication Networks, pp. 183-197, October 1996. 
[5] C.E. Perkins, E.M. Royer, “Ad-hoc on-demand distance vector routing,” Mobile Computing Systems and 
Applications, 1999. Proceedings. WMCSA '99. Second IEEE Workshop on 25-26 pp. 90 - 100 Feb. 1999. 
[6] D.B. Johnson and D.A. Maltz, “Dynamic Source Routing in Ad-Hoc Wireless Networks,” Mobile Computing, T. 
Imielinski and H. Korth, Eds., Kluwer, pp153-181,1996 
[7] Y. Ko and N. H. Vaidya, “Location-Aided Routing (LAR) in Mobile Ad Hoc Networks,” Proceedings of ACM 
MOBICOM 1998, pp. 66-75, October 1998. 
[8] C.-K. Toh, “Associativity-Based Routing for Ad Hoc Mobile Networks,” Wireless Personal Communications, 
Volume 4, no. 2, pp.1-36, March 1997. 
[9] Dongkyum Kim, C.-K. Toh, Yanghee Choi, “LAWS: Location-Aware Long-life Route Selection in Wireless Ad 
Hoc Networks,” IEE ELECTRONICS LETTERS Volume 36, no.18, 31st, pp. 1584-1586, Aug. 2000. 
[10] S. Singh, M. Woo, C. S. Raghavendra, “Power-aware routing in mobile ad hoc networks,” in the fourth annual 
ACM/IEEE international conference on Mobile computing and networking, pp. 181-190, 1998. 
[11] C.-K. Toh, “Maximum battery life routing to support ubiquitous mobile computing in wireless ad hoc networks,” 
IEEE Communications Magazine, Volume 39, pp. 138-147, 2001. 
[12] C.-K. Toh, “Performance evaluation of battery-life-aware routing schemes for wireless ad hoc networks,” IEEE 
International Conference on Communications, Volume 9, pp. 2824-2829, 2001. 
[13] Jang-Ping Sheu, Chen-Wei Lai, Chih-Min Chao, “Power-aware routing for energy conserving and balance in ad 
hoc networks,” Networking, Sensing and Control, 2004 IEEE International Conference on Volume 1, 21-23 pp. 
468 – 473, March 2004. 
[14] Shih-Lin Wu, Yu-Chee Tseng, Jang-Ping Sheu, “Intelligent medium access for mobile ad hoc networks with busy 
tones and power control,” Selected Areas in Communications, IEEE Journal on Volume 18, Issue 9, pp.1647-1657, 
Sept. 2000. 
[15] Yu-Chee Tseng, Shih-Lin Wu, Chih-Yu Lin, Jang-Ping Sheu, “A multi-channel MAC protocol with power control 
for multi-hop mobile ad hoc networks,” Distributed Computing Systems Workshop, 2001 International 
Conference on 16-19, pp.419-424, April 2001. 
[16] Long Gan, Jiming Liu, Xiaolong Jin, “Agent-Based, Energy Efficient Routing in Sensor Networks,” Proceedings 
of the Third International Joint Conference on Autonomous Agents and Multiagent Systems - Volume 1, July 
2004. 
[17] Laura Marie Feeney “An energy consumption model for performance analysis of routing protocols for mobile ad 
hoc networks,” Mobile Networks and Applications, Volume 6, Issue 3, June 2001. 
[18] Baruch Awerbuch, David Holmer, and Herbert Rubens, “High throughput route selection in multi-rate ad hoc 
wireless networks,” Technical report, Johns Hopkins University, Computer Science Department, Version 2. 
March 2003. 
[19] C.X. Mavromoustakis, H.D.Karatza, “Adaptive energy conservation model using dynamic caching for wireless 
devices,” Simulation Symposium, 2004. Proceedings. 37th Annual 18-22 pp. 257-264 April 2004.  
表 Y04 
 (a)                   (b) 
Fig. 1 (a) The hidden terminal problem and (b) the exposed terminal problem. 
 
 
(a)                (b) 
Fig. 2 (a) The restricted area in CSMA and (b) the restricted area in the IEEE 802.11 DCF MAC protocol. 
 
 
(a)                       (b) 
Fig. 3 (a) The restricted area without decreased the power and (b) the restricted area with decreased power. 
 
 
(a)                  (b) 
Fig. 4 (a) Only one communication pair works in the single channel design and (b) two more communication pairs work if there are two data 
sub-channels. 
In order to solve the hidden terminal problem and the exposed terminal problem, two methods were proposed. 
One uses the power control mechanism [3, 6-7]. The second uses the multiple channel mechanism [8-11]. We show the 
power control method in Figures 3(a) and 3(b). However, using the power control method may result in poor signal 
quality. From [5], we can see that the strength of signals is significantly related to the distance between mobile nodes. 
As a result, using the power control method may increase the number of re-transmissions because of poor quality 
signals.  
The second method that attempts to solve the exposed terminal problem uses the multiple channel method. The 
multiple channel method can be achieved by using FDMA (Frequency Division Multiple Access) or CDMA (Code 
Division Multiple Access). The principle of the multiple channel method is to divide a single channel into several 
sub-channels. Mobile nodes can use different sub-channels to communicate with other mobile nodes without 
interference. Therefore, the overall throughput can be improved because more communication pairs work 
simultaneously.  
To solve the exposed terminal problem, the multiple channel method allows multiple communication pairs to 
communicate with each other [8-11]. However, there are some problems in designing multiple channels. One is the data 
channel assignment problem. In a multiple data channel environment, the sender and the receiver have to agree which 
data sub-channels are to be used for data transmission and broadcast the assigned data sub-channel to the neighboring 
mobile nodes in their respective transmission ranges to avoid using the same data sub-channel. For example, DCA [8] 
divides a single channel into multiple sub-channels. In order to avoid sending signals in each sub-channel, DCA makes 
one sub-channel the control sub-channel and the others the data sub-channels. DCA modifies the IEEE 802.11 DCF 
表 Y04 
any signal, but they can receive data. From this, we get the second result.  
2. When a sender is sending data to a receiver, the mobile nodes in the RP area cannot use the same channel to 
send data to another node, but they can use the same channel to receive data from another node.  
Finally, we consider the CP area. Because the mobile nodes in the CP area can hear the signals from the sender 
and the receiver, the mobile nodes in the CP area cannot send data to another node nor receive data from other node. As 
a result, we get the third result below.  
3. When a sender is sending data to a receiver, the mobile nodes in the CP area cannot use the same channel to 
send data to or receive data from another node.  
From the three results mentioned above, when a communication pair is using a data channel, the mobile nodes in 
the TP/RP areas can send/receive data to/from another node using the same data channel. Accordingly, using the 
overlapping data sub-channel method solves the exposed terminal problem to by allowing more communication pairs 
work simultaneously to improve the overall throughput. 
 
B. Designing the Overlapping Data Sub-Channel Method  
 
The overlapping data sub-channel method proposed above allows more communication pairs to use a data 
channel simultaneously to efficiently solve the exposed terminal problem. However, the signals in a frame include data 
signals, handshaking signals (RTS/CTS signals), and confirmed signals (ACK), so the sender and the receiver have to 
send and receive signals during a packet transmission period. As a result, an interference problem caused by control 
signals and data signals arises in our proposed overlapping data sub-channel method.  
In Figure 6, we show the interference problem caused by the control signals and data signals with the overlapping 
data sub-channel in a single channel environment. When node A is sending data to node B, according to the second 
result mentioned above, node C can send data to node D. If, after node C sends a RTS signal to node D, node D sends 
back the CTS signal to node C to complete the handshaking process, a collision occurs at node C because node C 
receives data signals from node A and a CTS signal from node D, respectively. In addition, another similar interference 
problem occurs when the sender is receiving the ACK signal from the receiver and another mobile node in the 
transmission range of the sender is sending data signals to a mobile node. In this case, the sender receives two kinds of 
signals. In order to make the overlapping data sub-channel method work, we use the multiple channel mechanism to 
solve this problem. In the following, we describe how we use the multiple channel mechanism to make our proposed 
overlapping data sub-channel method work.  
 
Fig. 6 The interference of the data signals and the control signals in the overlapping data sub-channel method. 
 
C1 C3C2
Control
Channe
data channel Ack
Channel  
Fig. 7 The model with three sub-channels including, the control sub-channel, the data sub-channel, and the ACK sub-channel. 
 
The main interference problem for the overlapping data sub-channel method is that a channel is used by a mobile 
node to both transmit and receive control signals. If the data signals and the control signals can be transmitted or 
received in different channels, then the interference problem in the overlapping data sub-channel method can be solved. 
Accordingly, we divide the single channel into three kinds of sub-channels for three kinds of signals, including 
RTS/CTS signals, data signals, and ACK signals, which can each be transmitted/received in each of the three different 
sub-channels. This solves the interference problem, as shown in Figure 7.  
We assume that each mobile node is identical, that is, the transmission range of each mobile node is the same. In 
addition, each mobile node has to maintain a structure array, Ch[n], where n is the total number of data sub-channels, to 
record the status of each data sub-channel. With regard to the structure array Ch, we use two fields to record the status 
of each data sub-channel and describe the meanings of these two fields as follows:  
表 Y04 
     }  
 9. When a neighboring node receives the RES signal, it can see that data sub-channel Sel_Ch will be used to 
transmit data. Therefore, it performs the following steps.  
 a) Switch (Ch[Sel_Ch].Permit ) {  
Case “Free”:  
Ch[Sel_Ch].Permit = “SendOnly”;  
Break;  
Case “ReceiveOnly”:  
Ch[Sel_Ch].Permit = “Used”;  
Break;  
default:  
Ch[Sel_Ch].Permit keeps the original status;  
}  
b) Set Ch[Sel_Ch].NAV_time to TData.  
 10. When node A finishes the data transmission in data sub-channel Sel_Ch, node B replies to node A with an 
ACK signal to complete data transmission.  
}  
 
According to Algorithm 1, more communication pairs can work simultaneously by using the overlapping data 
sub-channel method with the multiple data sub-channel design. Figure 8 shows the situation in which the two 
communication pairs (A, B) and (C, D) in Figure 7 use the same data channel to transmit data over a period of time.  
ACK ch.
data ch.
CTRL ch. R C E R C E
Time i i +1 i +2 i +3
A
Overlap
i +4
A
Di Di +1
A to B
C to D
 
Fig. 8 Two communication pairs, (A, B) and (C, D), communicate using the overlapping data sub-channel method over a period of time. 
 
IV. Experimental Results 
 
In this section, we present our simulation results that verify our proposed bandwidth allocation strategy in a 
multiple channel environment and that measure the throughput improvement obtained by using the overlapping data 
sub-channel method with bandwidth allocation strategy. We first simulate the various bandwidth allocation ratios for 
the control and data sub-channels and verify whether our bandwidth allocation ratio results in a better throughput than 
those resulting from other bandwidth allocation ratios. In addition, we also present the extra throughput enhancement 
that results from using our proposed overlapping data sub-channel method with bandwidth allocation strategy by 
comparing it with the IEEE 802.11 DCF MAC protocol. Before presenting the simulation results, though, we first 
define the term “throughput” as follows:  
timesimulation
sizepacketpackettotal
Throughput
_
__ ×=  
 
TABLE 1. THE PARAMETERS USED IN OUR SIMULATION 
Model
Parameter 
802.11 M-yD O-yD 
表 Y04 
