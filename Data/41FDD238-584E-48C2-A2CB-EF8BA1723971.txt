  2
行政院國家科學委員會專題研究計畫成果報告 
計畫編號：NSC 95-2221-E-150-091 
執行期限：95 年 8 月 1 日至 96 年 7 月 31 日 主持人：黃惠俞   
執行機構及單位名稱：國立虎尾科技大學資訊工程系 
   計畫參與人員：魏台軍(國立中正大學資工所) 
 
 
一、中文摘要 
 
由於數位科技資訊產業的鵬勃發展，人
民對生活品質及生活周遭環境的安全有
了更加的重視。因而數位監控攝影器材更
是最佳的器具，然其品質不斷的提高且價
格也是相當平易近人的。數位視訊攝影器
材除了提供的娛樂外更是協助周遭環境
安全監控的好工具，具即時性操控性佳。
另也提供的監錄、網路視訊教學等應用。
經由網際網路的資訊交換及分享，我們希
望研究一個能夠對相同環境或是建築物
周遭環境做描述的數位顯像，並透過環場
接圖技術的協助，初步建立出由這系列所
取得的全景影像，形成一組2D的影像資
訊。同時更進一步的利用電腦視覺及虛擬
實境上的技術，建立出此建築物或是環境
的3D model，並將3D model與2D的影像資
訊加以結合，形成一個十分逼近實物的3D
的視覺環境，並且透過建立出的3D環境，
進行一系列延伸的應用開發，使得使用者
可在遙遠的彼端，也能有身歷其境的感
覺。     
本計劃主要之目的是研發一個以環場
接圖技術為基礎之視訊影像監控輔助系統
(An Auxiliary Surveillance System based on 
Image Mosaic, ASSIM)，可應用於如古蹟
修復、數位典藏、室內設計、虛擬實境、
3D 遊戲等相關應用上。 
 
關鍵詞：影像鑲嵌,影像接合,物件偵測,
視訊鑲嵌。 
Abstract 
 
As the speed growing of the Information 
technology advance, the digital camera 
becomes more powerful in the quality or the 
capability and cheaper in the prices recently. 
However, humans are most important them 
life quality and environment security, the 
digital surveillance device is the best tool. 
Hence, we can observe more and more 
applications in digital image filed are 
achieved. For example, the reservation of 
memory in the past time and e-learning via 
the multimedia information shared in the 
internet. Because of the information 
exchanged or shared in the internet, we want 
to investigate these image sequences that 
relate to other images. Then, we reconstruct 
the 2D panorama information by image 
mosaic technology. We adopt the related 
technology in computer vision and the 
virtual technology to build a 3D model of 
the building or the environment. The 
approximate 3D vision environment will be 
formed by the 2D and 3D information. 
Finally, the system will support the extended 
applications that are operating in our system. 
Regardless of time or space, they will be 
stay in the scene when the users are 
executing our system. 
The main goal of our approach is to 
develop a system that called an auxiliary 
surveillance system based on image mosaic 
technique (named ASSIM). This system can 
support some applications, such as the 
reconstruction of historic interest, the digital 
book reservation, interior design, virtual 
reality, 3D game, and etc.  
 
Keywords: 3D environment reconstruction, 
virtual reality, image mosaic, interaction. 
  4
三、結果與討論 
 
I. 研究方法步驟： 
本研究系統處理流程主要有多攝影機
監控環境全景圖建置、物件分析處理與即
時物件行為分析、物件修正、警訊系統處
理。在圖一系統流程圖中左邊支線部分表
示多攝影機監控環境全景圖建置，而右邊
支線則表示物件分析處理與即時物件行為
分析、物件修正、警訊系統處理。首先，
我們將對於監控環境架設適當個數之監控
攝影機進行對該環境視訊影像資料的收集
統整，並對所拍攝得知的影像資料進行影
像邊緣調整，以避免下一步影像接合技術
處理時，接圖效果及準確性受到具有曲度
之影像邊緣干擾。而在視訊影像前置調整
完畢後，則是將前幾個 Cycle 時間內之監
控環境影像，以我們先行執行(94)國科會
計畫所提出之影像接合(image registration)
技術[1]，將所有攝影機所取得之影像進行
接合處理，並經過細部調整後取得對該監
控環境之全景圖；同時，我們也將在該段
時間內，進行取得測試之監控視訊影像資
料的蒐集及整理，並將透過背景相減法，
即時判斷出於那個時間點、那個攝影機監
控畫面出現了入侵物體，因而將該段出現
入侵物體時段之視訊影像，另行儲存於所
設置之監控視訊影像資料庫中，緊接著進
行對此段時間內之入侵物體，做物體前置
處理，包含物體個數判斷，物體外觀取得、
物體方位等進行處理，以提供後續之物體
行為分析等程序使用。 
在入侵物體偵測及行為分析方面，將
透過物體行為分析模組與建議防堵策略模
組的協助，使得監控人員得以於監控螢幕
上更清晰且具有更佳的觀看角度下觀看入
侵物體的一舉一動。同時，該物體行為分
析模組也將會於短暫時間內判斷出該入侵
物體之未來可能的走向，並建議防堵策略
模組溝通，發出一提醒監看人員注意及建
議防堵策略的警報訊息。最後，由監測中
心之監控人員於第一時間內做出最適當的
應對處理方式，以達成本研究計畫所追求
之目標–更加人性化的即時監控輔助系
統。 
以下為 [2]所提出 Video Alignment 
Algorithm 步驟敘述。 
Video Alignment Algorithm: 
{ 1. For each frame: 
z Extract the invariant features at 
the interest points  
z Match to the previous frame 
z Match to the previous key frame 
z Estimate the overlap with the 
previous key frame  
z Mark as a key frame if the 
overlap is too low 
{ 2. For each frame: 
z Match to the next or the 
“forward” key frame 
{ 3. For each key frame: 
z Match to all other key frames 
{ 4. Compress the matched measurements  
{ 5. Estimate the image orientations from 
the compressed matches using the 
bundle adjustment 
 
根據上述的步驟我們先處理有關 key 
frames 的挑選動作: 
(1) Frames cluster：我們將收集之影像，其
大小為 720×480，針對一段時間內的影
像進行 cluseter 的動作，例如一段 5 分
鐘的視訊影像，只處理當中 I frames 的
分類，因為過多 frames 若是皆需進行
接合處理，數量過於龐大，因而只挑出
I frames 的部份處理分類。由眾多相似
的 I frames 歸類成一個 group，每個
  6
的類別當中。 
我們採用以上之處理程序藉以獲得正
確的 frames cluster 結果，以利後續進行影
像的接合時避免大量的 frames 接合，以少
數具有代表性的 frames接合取代無意義且
計算量大之全部 frames 接圖動作，藉以提
昇整體計算效能。 
 
II. 實驗結果和討論： 
 
我們以將所攝影到視訊影片進行分析
後，因為所有的片段所分析出的曲線大多
相近，我們以其中之一個 5 分鐘的片段影
片作為分析結果之例，如圖三所示，橫軸
代表相似度區域所佔的比例，縱軸為
frames 數目的多寡意指表示在此相似度的
門檻值下會有多少 frames。 
 
 
圖三 視訊影像相似度門檻分析圖 
 
由上面實驗可以明顯看出，當在相似
度門檻值為 45 時，開始有著大幅下滑的趨
勢，同時在 65 以上也會有著這樣的現象，
這樣的現象說明了當使用過低或是過高的
門檻值時，由於門檻值的條件不易達到或
是過於容易達到，而造成分類效果不佳的
狀況。 
例如過小的門檻值時，所分類出的結
果將會是比較少的 groups，因為要間隔很
多個 I frame 才會造成無法通過門檻值進
而分類到另個分類，因此每個 groups 中
所代表的 key frame 反而會有著差異性過
大不利於後續接圖處理。相對的，在過高
的門檻值中會造成很短的間隔就必須分
類，使得 groups 個數過多，連帶使 key 
frames 個數變多，在最差的狀況下幾乎沒
有分類。所以無論過低或是過高的門檻值
都不是個適當的結果。從圖五到圖八為實
驗不同門檻值所展示出的分類結果圖。 
另外使用特徵點偵測的方式實驗結果
如圖四(a)與(b)所示。 
 
 
(a) 
 
(b) 
圖四 視訊影像特徵點圖(a)與(b) 
  
從圖四(a)和(b)的結果中可以看出特徵點
過數過少，這是由於視訊影片本身對比以
及影像內容進行 edge 處理時所可採用的
資訊並非十分充足，因而無法有著較多的
特徵點可用導致準確率下滑。圖五至八分 
  8
    
    
    
 
圖八 門檻值 70%下所分類結果圖 
 
別在不同的門檻值下所獲得的分類結果。 
 
四、成果自評 
 
本研究計畫之最終目標是為建構出一
個更具人性化且具有聰明的建議防堵策略
之監控輔助系統為主要的研究主軸，研發
如何從現存攝影機所拍攝出之具關聯性的
影像/視訊資料，利用 Image Mosaic 技術
實作監控環境全景重建，並且搭配其後續
之物件行為分析模組與警報發佈模組，將
這些有效且豐富的訊息精確地顯示於監控
螢幕上，建構出人性化的監控輔助系統。
藉由探討相關理論及技術開發，如前景、
背景區分、背景相減法、物件動態向量等
技術，統整出能夠提供精確、具有監控環
境全景圖，即時通報入侵物體動向且帶有
建議防堵策略的視訊影像監控輔助系統，
並且提供未來如動態物體偵測及追蹤、社
區安全等相關後續延伸的設計應用、開發
研究等技術之基礎。 
目前已將有關 key frames 挑選部份進
行處理，結果呈現如前述的圖五至八中，
部分結果並不是讓人滿意，正試著結合其
他不同的作法進行改善，但系統尚存在一
些困難點，也正積極克服中，為期能建構
完整的環場監控圖。未來將更進一步的改
良技術及改善系統效能，以建構完善的人
性化監控輔助系統。 
 
五、參考文獻 
 
[1] H. Y. Huang and T. C. Wei, "Fast 
Locating Detection of Covering Region 
in Image Mosaic," in Proc. of the 2nd 
European Workshop on the Integration 
of Knowledge, Semantic and digital 
Media Technologies, PP. 301-308, IEE 
Savoy Place, 
London,  UK,  Nov.30~Dec. 1, 2005 
[2] D. Steedly, C. Pal and R. Szeliski, 
An effective watermark embedding algorithm for high JPEG compression 
Hui-Yu Huang 
Department of Computer Science and Information 
Engineering, National Formosa University, Taiwan 
E-mail: hyhuang@nfu.edu.tw 
Chi-Hung Fan, and Wen-Hsing Hsu 
Department of Electrical Engineering,  
National Tsing Hua University,  Taiwan 
Abstract 
Digital watermarking is an important technology that has 
been widely applied many applications. In this paper, we 
present an effective embedding watermark method for JPEG 
image which can resist high compression attack and retain a 
good image quality. The proposed algorithm consists of 
three parts which are searching the optimal embedded 
position, embedded value, and embedded/extracted 
processing for watermark in images.  First, the embedded 
position search, which performed in DCT domain, are
achieved the optimal watermark embedding position by
means of finding the number of zero in low frequency region 
after compressing. Next, according to above result, we 
calculate the distortion difference between the original 
image and compressed image to decide the best tolerant 
range and assign the embedded value. Last, based on
quantization index modulation (QIM), the embedded 
processing can further achieve effectively to inset the 
watermark in images. Thus this approach can effectively 
resist high JPEG compression and protect the embedded 
information and media ownership. The experimental results 
are presented to demonstrate the effectiveness of our 
approach. 
1. Introduce 
Owing to the quickly evolvement of networked multi media 
systems in last few years, the protection of digital media has 
been necessitated and more important scheme, especially the 
protection and enforcement of intellectual property rights. 
Copyright protection involves the authentication of data 
(text/image/video) ownership and the identification of illegal 
behavior such as copies. Techniques are needed to prevent 
the copying, forgery and unauthorized distribution of images 
and video.  However, digital watermarking technology is 
usually applied to protect the intellectual property of digital 
data which are freely available on the WWW and transmitted 
over network. 
A large number of watermarking systems address the 
problems of implementing invisible watermarks. There have 
been a number of corresponding works [1-3] dedicated to 
image/video/audio watermarking. These scholars define a 
digital watermark as an identification code which carrying 
information about the copyright owner, the creator of the 
work, the authorized consumer, etc. It is permanently 
embedded into digital data for copyright protection and may 
be used for checking whether the data have been modified 
illegally [1]. Cox et al. [3] proposed a secure (tamper-
resistant) algorithm to construct the watermark as an 
independent and identically distributed Gaussian random 
vector which is inserted in a spread-spectrum-like fashion 
into spectral component of the data. It can effectively 
resisted against the transformed watermarked image. Owing 
to the time-consuming computation for spread-spectrum 
method, Chen [4] proposed the quantization index 
modulation (QIM) and distortion-compensated (DC-QIM) 
methods to embed the watermark in order to improve this 
program. By using of the (QIM) algorithm, it can achieve 
against arbitrary bounded and fully informed attacks and 
further arise to currently popular spread-spectrum method. 
Wong [5] used the human visual system (HVS) model to 
estimate the JEPG-to-JEPG data hiding capacity of JPEG 
image and the maximum number of bits embedded in JPEG-
compressed images. Wong et al. [6] proposed three 
techniques which include single watermark embedding, 
multiple watermark embedding, and iterative watermark 
embedding to embedded watermarks in order to remain good 
image quality and robust in varying degree to JPEG 
compression. This algorithm can successively embedded 
watermark when the quality factor is low, but when the 
quality factor is low. However, this approach makes high 
computation complexity of the iterative loop. These methods 
are also existed the problems of either complexity or time-
consuming computation. 
Generally, the watermark scheme hopes the abilities of 
resisting some attacks such as noise, copying, rotation, 
scaling, lossy compression, etc. However, we find out that 
many researches do not have an effective method to solve 
this problem well. Although, a lot of watermarking systems 
designed for compression have been proposed, most of them 
may not make a balance point between image quality and 
compression intensity. Therefore, we design an optimal 
method in order to solve this problem between image quality 
and compression intensity. In this paper, our proposed 
system will concern with resisting high lossy compression 
for JPEG to protect the intellectual property rights of owner 
against the illegal infringement.  
256
MVA2007 IAPR Conference on Machine Vision Applications, May 16-18, 2007, Tokyo, JAPAN
8-8
2.3 Embedded and extracted processing 
2.3.1 Embedded processing 
In order to obtain the optimal positions to embed 
watermark, we have to further find out the embedded
watermarking positions ),( nmEWP and values 
),( nmEWV corresponding the coordinates ),( nm of 
watermark. According to above processing, all of the optimal 
embedded points ),( qpOEP can be found which can 
tolerant higher JPEG compression ratio corresponding to the 
pth row and qth column of block location and have the 
relatively number of zero coefficient by compression 
processing. Now we use this information to decide 
the ),( nmEWP . The searching rule is that the number of 
zero coefficient for ),( nmEWP  must be greater than a 
threshold value and the searching path is started at the 
threshold to 100. In our experiment, this threshold is set to 
30, namely, searching the ),( nmEWP  position is started 
from 30 to 100. While the number of ),( nmEWP  are 
equal to the number of embedded watermark, the searching 
process is stopped. Every ),( nmEWP  has the 
corresponding ),( nmEWV  value that can easy to obtain 
by means of the optimal embedded value ),( qpOEP . Here, 
our system will not search ),( nmEWP  from 0 to 100, it is 
because that if the threshold is set to 0, it will cause the 
serious distortion of watermark image. Actually, it is a 
reasonable situation; a point which is the low number of zero 
coefficient can serve as a sensitive point under JPEG 
compression. 
Figure 2 is shown in the embedded method based on 
improved quantization index modulation mechanism. All of 
the embedded procedures will be distributed as follows.
Figure 2 The diagram of the proposed embedded method.
Step1: Load the information of ),( nmEWP  to know where 
is the embedded point and also read-out its original 
host image DCT value ( ),( yxQi ) in this point. 
Step2: Find out the positive index range )(iPIR  and 
negative index range )(iNIR  for the ith point that 
will be used to extracted process and this information 
serves as secure key. 
®¯­  
  
),(),()(
),(),()(
)(
iMDRyxOiiPIR
iMDRyxOiiNIR
IIR         (2) 
where ),( yxQi  is the DCT value of the original host 
image corresponding to the embedded point. 
Step3: Define the index range (IR).
®¯­ dt
dd 
),,()(),()(here,1
),(),()(here,0
)(
yxWiPIRoryxWiNIRw
iPIRyxWiNIRw
iIR
ii
i       (3) 
where ),( yxWi  is the DCT value of embedded point 
for watermark image. 
Step4:  Insert the watermark in the host image. 
®¯­
u 
0,embedif),,(
1,embedif),(2),(
),(
yxO
iEWVyxO
yxW
i
i
i
        (4) 
If we want to embed index (=0), we don't need to 
change its value. If we want to embed index (=1), we
need to move the original DCT value out of the index 
range. 
Step5: Repeat step1 to step4 until all of the watermarks are 
embedded. 
2.3.2 Extracted processing 
In extracted method, we must make use of the secure key 
obtained by the embedded process which is denoted the 
negative index range )(iNIR  and positive index 
range )(iPIR  information. By above the information, then it 
is easy to detect the embedded watermark. And its procedure 
is expressed by 
®¯­ dt
dd 
),,()(),()(,1
,)(),()(,0
)(
yxWiPIRoryxWiNIRif
iPIRyxWiNIRif
iIR
ii
i (5)
where ),( yxWi  is the DCT value of embedded point of the 
watermark image. 
3. Experimental Results and Discussion 
In this section, we show some experimental results by our 
proposed algorithm. Here we use the size 720×480 of
Mandrill standard image to be our host image and the 30×20 
size of the watermark shown in Figure 3. A similarity 
measurement (NC) of the extracted and the referenced 
watermarks is defined as: 
,
)],([
),(ˆ),(
0 0
2
0 0
¦¦
¦¦
  
   
m
i
n
j
m
i
n
j
jiw
jiwjiw
NC           (5) 
where ),( jiw and ),(ˆ jiw denote the original watermark 
and the extracted watermark corresponding to the 
coordinates ),( ji  respectively. 
Figure 4 shows the NC value in the different QFactor 
value. From the Figure 4, it is obvious that the NC value can 
258
表 Y04 1
行政院國家科學委員會補助國內專家學者出席國際學術會議報告 
                                                     九十六年五月二十二日 
報告人姓名 黃惠俞 
Hui-Yu Huang 
 
服務機構
及職稱 
國立虎尾科技大學 
資訊工程學系 
助理教授 
    時間 
會議 
     地點 
2007 年 05 月 16 日至 05 月
18 日  
日本國 東京  
本會核定
補助文號
NSC95-2221-E-150-091 
會議 
名稱 
 (中文) 第十屆機器視覺及應用研討會 
 (英文) 2007 Machine Vision and Applications, Tokyo, Japan 
發表 
論文 
題目 
 (中文) 高 JPEG 壓縮下一個有效的浮水印嵌入演算法 
 (英文) An effective watermark embedding algorithm for high JPEG compression
報告內容應包括下列各項： 
一、參加會議經過 
我的論文被選為以海報方式進行發表，並安排在 5月 17 日中午的 poster section，舉行的
時間從 13：00～14：30。本次以製作 A0 大小之海報資料攜至大會會場。於會議舉行前搭乘
長榮航空飛抵開會地點日本國東京成田(Narita Airport)國際機場。會議舉行之地點是位於東京
大學之生產科技研究所內(Institute of Industrial Science)。會議開幕式準時開始於十六日(三)
早上 9:00，主席 Mr. Johji TAJIMA 僅簡單致歡迎詞並介紹本次研討會特色並同時將前九屆的
MAV 論文集結成一片紀念 DVD 片贈於每位與會的來賓。隨即進行第一場的 oral presentation 及
相關的 poster presentation。此次大會議程安排每天有三場 sections、一場 poster section、及每
天皆有一場的 invited talk 進行，整個會議相當充實且緊湊。 
 
二、與會心得 
這次出國是我第五次接受補助出國參加在國際會議，而特別的是這 MAV 會議是我第二次
參加，地點皆在日本舉行，此會議為期三天(五月十六號至十八日)。我的論文在會議中是以
海報形式進行論文報告。與會的人員有來自世界各地在這機器視覺方面的先進、科技人才及
學者等，一起在這會議中進行交流及經驗分享。 
 
附件三
 
表 Y04 3
的心境參與此次會議。在這將近兩小時的 poster representation 時間獲益良多，因與會來賓有
學者、專家或業界等，基於他們的專業知識而提出不同見解及疑問，因而給了不同角度的思
考思緒，對問題或研究有了更新的思考。每一位前來討論來賓做詳盡的報告及解說之外，同
時也交換彼此在這方面的心得及看法，亦同時獲得良好的建議及對我研究的讚賞等。對我而
言，這又是再一次非常難得既寶貴的學習經驗，往後將更加努力於研究方面及多參加國際間
相關研究舉行之會議，拓展自己的視野，增廣自己的研究領域，也適時的將自己的研究分享
於外。因會議舉行地點在東京大學內，於參加會議期間仔細觀察了校園裡的環境，設備，學
生們的互動等，做了一次校園尋訪。 
   
三、考察參觀活動(無是項活動者省略) 
無 
四、建議 
無 
五、攜回資料名稱及內容 
本次會議主要攜回論文集一本 (proceedings)及會議光碟片有兩片,其一是將過去
(1988~2005)所有 MAV 的論文整理成一片 DVD 片。另一則是本次會議的所有資料包含大會議
程時間表（program）、invited talks(3 篇)、oral papers ( 43 篇) and poster papers (96 篇)等全文
論文。其主要目錄依日期分列如下: 
3-22 A Comparison of New Generic Camera Calibration 
with the Standard Parametric Approach 
Aubrey K. Dunne, John Mallon and Paul F. Whelan, 
Ireland 
3-23 Pre-processing Algorithms on Digital Mammograms 
Hengameh Mirzaalian, Mohammad Reza Ahmadzadeh, 
Saeed Sadri and Mehdi Jafari, Iran 
3-24 License Plate Recognition from Low-Quality Videos 
Chih-Chiang Chen and Jun-Wei Hsieh, Taiwan 
3-25 Adaptive Modified PCA for Face Recognition 
Youness Aliyari Ghassabeh, Hamid Abrishami 
Moghaddam and Mohammad Teshnehlab, Iran 
3-26 Fingerprint Core and Delta Detection by Candidate 
Analysis 
Tomohiko Ohtsuka, Daisuke Watanabe and Hiroyuki 
Aoki, Japan 
3-27 Japanese Phone Recognition Using Lip Image In-
formation 
Takeshi Saitoh, Mitsugu Hisagi and Ryosuke Konishi, 
Japan 
3-28 A SVM Based Method to Detect Color Shift Defects 
in IC Packages 
R.M.C.B. Ratnayake, Craig Hicks and M.A. Akbari, 
Japan 
3-29 Object Type Classification Using Structure-based 
Feature Representation 
Tomoyuki Nagahashi, Hironobu Fujiyoshi and Takeo 
Kanade, Japan 
3-30 A Review of Tracking Methods under Occlusions 
Zui Zhang and Massimo Piccardi, Australia 
3-31 Fast Graph Segmentation Based on Statistical Ag-
gregation Phenomena 
Frank Nielsen and Richard Nock, Japan 
3-32 Tracking Features with Global Motion Compensa-
tion for Drone Camera Servoing 
Benoît Louvat, Laurent Bonnaud, Nicolas Marchand 
and Gerard Bouvier, France 
 
Session 4: Invited Talk 1 (14:30  15:30) 
Chair: Katsushi Ikeuchi 
4-1 Computational Cameras 
Prof. Shree K. Nayar, Columbia University, USA 
 
Break (15:30  15:50) 
 
Session 5: Motion and Image Sequence Analysis 
(15:50  17:50) 
Chairs: Bjorn Stenger and Atsuto Maki 
5-1 A Method for Estimating Rigid Object Motion Us-
ing Regularized Scene Flow 
Hiroki Mizuno and Hironobu Fujiyoshi, Japan 
5-2 Probabilistic Motion Segmentation of Videos for 
Temporal Super Resolution 
Arasanathan Thayananthan, Masahiro Iwasaki and 
Roberto Cipolla, UK 
5-3 Robust and Efficient 3-D Reconstruction by 
Self-Calibration 
Hanno Ackermann and Kenichi Kanatani, Japan 
5-4 Linear Tracking of Pose and Facial Features 
Jose Alonso Ybanez Zepeda, Franck Davoine and 
Maurice Charbit, France 
5-5 A Video Motion Capture System for Interactive 
Games 
Ryuzo Okada, Nobuhiro Kondoh and Bjorn Stenger, UK 
5-6 Using Space-Time Interest Points for Video Se-
quence Synchronization 
Daniel Wedge, Du Huynh and Peter Kovesi, Australia 
 
 
 
 
Thursday, May 17, 2007 
 
Session 6: Image Processing & Graphics (9:00  10:20) 
Chairs: Chu-song Chen and Hiroaki Nakai 
6-1 Real-time Soft Shadows in Mixed Reality Using 
Shadowing Planes 
Tetsuya Kakuta, Takeshi Oishi and Katsushi Ikeuchi, 
Japan 
6-2 A High-Speed and Compact Vision System Suitable 
for Wearable Man-machine Interfaces 
Takashi Komuro, Björn Werkmann, Takashi Komai, 
Masatoshi Ishikawa and Shingo Kagami, Japan 
6-3 Synthesis Arbitrary Views from Two Images Based 
on Improved View Morphing Technique 
Huagang Liang, Shogo Tokai and Hiroyuki Hase, 
Japan 
6-4 Noisy Image Segmentation Based on a Level Set 
Evolution 
Khaled Issa and Hiroshi Nagahashi, Japan 
 
Break (10:20  10:40) 
 
Session 7: Multimedia (10:40  12:00) 
Chairs: Massimo De Gregorio and Shuji Senda 
7-1 Patch Based Localization of Visual Object Class 
Instances 
Alexandra Teynor and Hans Burkhardt, Germany 
7-2 Correction of Geometric and Photometric Distor-
tion of Document Images Using a Stereo Camera 
System 
Yusuke Suzuki, Atsushi Yamashita and Toru Kaneko, 
Japan 
7-3 A Local Keypoint Matching Technique for Transi-
tion Detection 
Chun-Rong Huang, Huai-Ping Lee and Chu-Song Chen, 
Taiwan 
7-4 New Image Encryption Method Based on ICA 
Ayman Alfalou and Ali Mansour, France 
 
Lunch (12:00  13:00) 
 
Session 8: Poster Session 2 (13:00  14:30) 
8-1 View-invariant Human Action Recognition Based on 
Factorization and HMMs 
Xi Li and Kazuhiro Fukui, Japan 
8-2 Gesture Recognition Using Temporal Templates 
with Disparity Information 
Kazunori Onoguchi and Masaaki Sato, Japan 
8-3 Vision-based UAV Navigation in Mountain Area 
Jihwan Woo, Kilho Son, Teng Li, Gwansung Kim and In 
So Kweon, Korea 
8-4 Identifying Hand Gesture Images by Using Genetic 
Algorithms 
Tetsuji Kobayashi and Norifumi Machida, Japan 
8-5 Enhanced Blood Vessels in Laparoscopy by Using 
Narrow-Band Imaging 
Hamed Akbari, Yukio Kosugi, Kazuyuki Kojima, 
Toshiaki Ohya, Hideki Akamatsu and Naofumi Tanaka, 
Japan 
8-6 An Iris Image Quality Assessment Method Based on 
Laplacian of Gaussian Operation 
Jing Wan, Xiaofu He and Pengfei Shi, China 
8-7 Calculation of Bedding Angles Inclination from Drill 
Core Digital Images 
Thomas Quiniou, Nazha Selmaoui, Christine 
Laporte-Magoni and Michel Allenbach, New Caledonia 
8-8 An Effective Watermark Embedding Algorithm for 
High JPEG Compression 
Hui-Yu Huang, Chi-Hung Fan and Wen-Hsing Hsu, 
Taiwan 
Friday, May 18, 2007 
 
Session 11: Industrial Applications (9:00  10:20) 
Chairs: Naoufel Werghi and Akio Nakamura 
11-1 Goniometric Imaging of Paper Gloss 
Tomi Kauppi, Albert Sadovnikov, Lasse Lensu, 
Joni-Kristian Kämäräinen, Pertti Silfsten and Heikki 
Kälviäinen, Finland 
11-2 One Fish, Two Fish, Butterfish, Trumpeter: Recog-
nizing Fish in Underwater Video 
Andrew Rova, Greg Mori and Lawrence M. Dill, 
Canada 
11-3 Machine Vision Based Lumber Grain Measurement 
Matti Niskanen and Olli Silven, Finland 
11-4 Geometrical and Statistical Visual Inspection of 
Imprinted Tablets 
Marko Bukovec, Ziga Spiclin, Franjo Pernus and 
Bostjan Likar, Slovenia 
 
Break (10:20  10:40) 
 
Session 12: Medical Image Analysis & Biometrics 
(10:40  12:00) 
Chairs: Aurélio Campilho and Yasuyo Kita 
12-1 An Unsupervised Learning Approach Based on 
Hopfield-like Network for Assessing Posterior Cap-
sule Opacification 
Naoufel Werghi, Rachid Sammouda and Fatma AlKirbi, 
UAE 
12-2 Microscopic Image Segmentation with 
Two-dimensional Exponential Entropy Based on 
Hybrid Microcanonical Annealing 
Amir Nakib, Hamouche Oulhadj and Patrick Siarry, 
France 
12-3 Fingerprint Verification Using Perturbation Method 
Satoshi Otaka, Yoshihisa Nishiyama, Takahiro Hatano 
and Toru Wakahara, Japan 
12-4 Automatic Cell Image Segmentation Using a 
Shape-Classification Model 
Shishir Shah, USA 
 
Lunch (12:00  13:00) 
 
Session 13: Poster Session 3 (13:00  14:30) 
13-1 Evaluation of Stereo Matching Systems for Real 
World Applications Using Structured Light for 
Ground Truth Estimation 
Martin Humenberger, Daniel Hartermann and Wilfried 
Kubinger, Austria 
13-2 Stabilizing Illumination Chromaticity Estimation 
Using the Illumination Line Segment 
Rei Kawakami and Katsushi Ikeuchi, Japan 
13-3 Probabilistically Semantic Labeling of IR Image for 
UAV 
Teng Li, Jihwan Woo and In So Kweon, Korea 
13-4 Shadow Elimination in Traffic Video Segmentation 
Hong Liu, Jintao Li, Qun Liu and Yueliang Qian, China 
13-5 3D Precise Inspection of Electronic Devices by Sin-
gle Stereo Vision 
Takashi Watanabe, Akira Kusano, Takayuki Fujiwara 
and Hiroyasu Koshimizu, Japan 
13-6 Facial Expression Recognition by SVM-based 
Two-stage Classifier on Gabor Features 
Fan Chen and Kazunori Kotani, Japan 
13-7 Vehicle Orientation Detection Using Vehicle Color 
and Normalized Cut Clustering 
Jui-Chen Wu, Jun-Wei Hsieh, Yung-Sheng Chen and 
Cheng-Min Tu, Taiwan 
13-8 Human Tracking Based on Particle Filter in Out-
door Scene 
Mototsugu Muroi and Heitoh Zen, Japan 
13-9 Extracting Object Regions Using Locally Estimated 
Probability Density Functions 
Hidenori Takeshima, Takashi Ida and Toshimitsu 
Kaneko, Japan 
13-10  A Three Resolution Framework for Reliable Road 
Obstacle Detection Using Stereovision 
Mathias Perrollaz, Raphael Labayrade, Romain Gallen 
and Didier Aubert, France 
13-11 Human Body Region Extraction from Photos 
Yi Hu, Japan 
13-12 A Fast Surface-Based Visual Hull Reconstruction 
Sofiane Yous and Masatsugu Kidode, Japan 
13-13 Automatic Detection of Anatomical Structures in 
Digital Fundus Retinal Images 
Anantha Vidya Sagar, S. Balasubramanian and V. 
Chandrasekaran, India 
13-14 Illumination-robust Change Detection Using Tex-
ture Based Features 
Kentaro Yokoi, Japan 
13-15 Feature Extraction from Biological Motion of Hu-
man Gait Patterns for Emotion Discrimination 
Hidenori Maruta and Masahiro Ishii, Japan 
13-16 Robust Real Time Multi-Layer Foreground Seg-
mentation 
Simon Denman, Vinod Chandran and Sridha Sridharan, 
Australia 
13-17 Tumor Detection Based on Spatial and Inter-Slice 
Analyses for MRI Breast Imaging 
Guo-Shiang Lin, Sin-Kuo Daniel Chai, Wei-Cheng Yeh 
and Lin-Jie Cheng, Taiwan 
13-18 Appearance Manifold with Embedded Covariance 
Matrix for Robust 3D Object Recognition 
Lina, Tomokazu Takahashi, Ichiro Ide and Hiroshi 
Murase, Japan 
13-19 A Robust Coarse-to-Fine Method for Pupil Local-
ization in Non-ideal Eye Images 
Xiaoyan Yuan and Pengfei Shi, China 
13-20 Facial Caricaturing Robot COOPER Exhibited at 
EXPO2005 and Its Improvements 
Naoya Tokuda, Takayuki Hoshino, Takashi Watanabe, 
Takuma Funahashi, Takayuki Fujiwara and Hiroyasu 
Koshimizu, Japan 
13-21 Extraction of Corresponding Points from Stereo 
Images by Using Intersections of Segments 
Hiroshi Unno, Keikichi Hayashibe and Hitoshi Saji, 
Japan 
13-22 Rat Mammary Gland Analysis in T1 Weighted MR 
Images 
Bin Wang, Jianhua Xuan, Matthew T. Freedman, Peter 
G. Shields and Yue Wang, USA 
13-23 A Lawn Weed Detection in Winter Season Based on 
Color Information 
Ukrit Watchareeruetai, Yoshinori Takeuchi, Tetsuya 
Matsumoto, Hiroaki Kudo and Noboru Ohnishi, Japan  
13-24 A Novel Approach of 3D Face Reconstruction Using 
Ellipse Fitting 
Charoenpong Theekapun, Hiroyuki Hase and Shogo 
Tokai, Japan 
13-25 A Facial Sketch Animation Generator for Mobile 
Communication 
Yuehu Liu, Yuanqi Su, Yang Yang, Fengjuan Wang, 
Maojun Yuan and Zhen Ren, China 
13-26 Lane Detection and Tracking through Affine Recti-
fication 
Qiang He and Chee-Hung Henry Chu, USA 
13-27 Statistical Background Subtraction Based on the 
Exact Per-pixel Distributions 
Youngbae Hwang, Hanbyul Joo, Jun-Sik Kim and In-So 
Kweon, Korea 
13-28 Periodic Pattern Inspection Using Convolution 
Masks 
Y. S. Weng and M. H. Perng, Taiwan 
