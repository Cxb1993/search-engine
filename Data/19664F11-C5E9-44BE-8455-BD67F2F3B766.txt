 2
 
 The reversible data embedding and restoration phases for content authentication are illustrated 
in Figs. 2 and 3, respectively. The host image is first transformed from media space into reversible 
marking space by a particular function, in which some information might be produced to avoid 
irreversible distortion and be reserved for original content restoration. Such information is called 
restoration aid. The image authentication code could be a hash value or a set of invariant image 
features. The payload is the data associated with the product which is desired to be transported 
along with the product; for example, the patient’s personal information, his/her medical histories, 
and the description of the image are desired to be embedded into the image and transferred along 
with it. The watermark is formed by concatenating the image authentication code, payload, and 
restoration aid. Then the system embeds the watermark into the reversible marking space, 
producing the watermarked image. In the decoding and authentication process, the watermarked 
image is also transformed by the same function as in the embedding process. And then the 
watermark extractor obtains the watermark and removes it from the image, followed by decoding it 
to produce the image authentication code, payload, and restoration aid. The restoration aid is later 
used to restore the original content, provided the watermarked image is identified as authentic. 
 
 
Fig. 2: The embedding phase. 
 
 
 
Fig. 3: The restoration phase. 
 
Transformed Data 
Watermarked 
Image 
Watermark 
Original 
Image 
Authentication 
Code 
Restoration Aid 
Reversible 
Watermark 
Embedding
Compute the  
Authentication 
Information 
Payload 
Concatenate
Media Space  
Transform 
Reversible 
Marking Space 
Transform 
Transformed Data 
Watermarked 
Image 
Watermark 
Original 
Image 
Authentication 
Code 
Restoration Aid 
Reversible 
Watermark 
Embedding
Compute the  
Authentication 
Information 
Payload 
Concatenate
Media Space  
Transform 
Reversible 
Marking Space 
Transform 
 4
Recoverable Authentication of Wavelet-Transformed Images 
 
 
Yuan-Liang Tang* and Chih-Jung Hung 
Department of Information Management, Chaoyang University of Technology 
168 Jifong E. Rd., Wufong Township, Taichung County 41349, Taiwan (R.O.C.) 
*Email: yltang@cyut.edu.tw 
http://www.im.cyut.edu.tw 
 
Abstract 
In this paper, a recoverable image content authentication 
algorithm based on digital watermarking is proposed. The 
host image was first divided into equal-sized blocks and 
then analyzed to obtain two pieces of information: one 
for tamper detection and the other for image recovery. 
For tamper detection, the relations between image blocks 
were established in order to discourage an adversary’s 
attempt to alter the image. In addition, the authentication 
system was designed in such a manner that it is very 
insensitive to common image processing operations. For 
image recovery, in order to achieve a better recovery 
result, an image block with more complex contents 
(referred to as an edge block) was further divided into 
sub-blocks. A non-edge block, if tampered with, would 
be recovered using its pixel intensity mean embedded 
previously, whereas an edge block would be 
reconstructed by recovering the intensities of its 
sub-blocks. Due to the different recovery strategies for 
edge and non-edge blocks, the quality of the 
reconstructed image is more satisfactory. Our 
experiments demonstrated that the proposed algorithm is 
able not only to detect tampered areas but also to recover 
the tampered blocks.1 
 
Keywords: Image content authentication, digital 
watermarking, tamper recovery. 
 
1. Introduction 
Due to the rapid development of the digital technologies, 
digital products become very popular and it is easy to 
create, transmit, duplicate, and manipulate digital videos, 
photos, voices, and so on. Such convenience however 
leads to a problem, that is, it is also easy to tamper with 
the content of a digital product. The situation can be very 
serious especially when the media content is critical, for 
example, when an image is used as a piece of evidence in 
the court, there has to be some ways to prove that the 
image is original or the semantics of the original image is 
well preserved. Such an application is referred to as 
content authentication and digital watermarking 
techniques are generally used as solutions. Current image 
authentication techniques can be classified into two 
approaches. One is signature based techniques, in which 
the sender first extracts the features from the original 
image and then uses a private key to encrypt the features, 
resulting in the signature. The receiver thus can use the 
sender’s public key to decrypt the signature in order to 
authenticate the received image. The signature is usually 
                                                 
1 This research is supported by a grant f om National Science 
Council, Taiwan, R.O.C. (NSC 92-2213-E-324-024) 
stored somewhere other than in the media itself. For 
example, Dittmann et al. [1] computed the edge 
characteristics of the image and transformed them into 
feature codes, that is, the content-based digital signature. 
Bhattacharjee and Kutter [2] generated a digital signature 
by encrypting the feature points. The authentication was 
accomplished by comparing the positions of the feature 
points against those decrypted from the previously 
encrypted feature points. 
The other approach is watermarking-based techniques, 
which exploit the redundancies of an image to embed the 
content protection information. Such an approach embeds 
information into an image that is later extracted to verify 
the authenticity of the image. Most of the recent 
researches focused on watermarking-based techniques 
[3−13]. Nopporn and Wasin [13] proposed an image 
verification scheme based on the relative similarity 
between neighboring image blocks. In their scheme, the 
spatial-domain spread spectrum method was used to 
embed the watermark. The main drawback of their 
method is that the protection information is easily 
destroyed due to image compression, and an attacker can 
also analyze the relative similarity to conduct the collage 
attack [17, 18]. Some researchers chose to perform 
watermarking in the transform domain, in which the 
coefficients are thresholded and quantized in order to 
utilize the redundancy of the image. Kim [4] selected the 
low-frequency coefficients of the discrete cosine 
transform (DCT) of the image and quantized them. If 
malicious manipulations occurred, tampered areas tend to 
have another value. Inoue et al. [8] proposed a 
watermarking scheme which embedded a robust 
watermark into the low frequency components using 
controlled quantization. A fragile watermark was used to 
determine whether the image has been altered. 
Besides tamper proofing, recently some researchers 
proposed watermarking techniques which have the 
additional ability of image recovery, in which tampered 
areas in the image are detected first, followed by 
reconstruction of the original image. Hung et al. [7, 14] 
used the vector quantization (VQ) technique to obtain an 
abstract of the image and then the VQ indices and the 
codebook are embedded into the mid-frequency 
components of the DCT-transformed image. Such 
embedded information can discourage an adversary’s 
attempt to tamper with the image and the altered area can 
be recovered. Li et al. [15] utilized the discrete wavelet 
transform (DWT) technique to extract image information 
from the low-frequency coefficients. The information 
was hidden in the mid-frequency components for tamper 
detection and recovery. Wang et al. [10] combined the 
fractal image compression and watermarking schemes to 
 6
block is not selected more than once, the authentication 
information would be a list, md(xi, yi), where i = 
0…N/b–1, as illustrated in Figure 2(a). 
Since a meaningful malicious attack usually tries to 
alter the semantics of the image, a large number of blocks 
are expected to be modified and they tend to cluster 
together. Based on such reasoning, selection of blocks not 
only has to be random, but the selected block also has to 
be at some distance away from the selecting one in order 
to resist bulk modifications of the image. Figure 2(b) 
depicts the strategy of block selection: the image is first 
divided into four equal-sized areas, and then the block 
B(xk, yk) can only select those in the areas other than 
where it resides. In addition, the selected block should be 
outside the gray area as well in order to ensure some 
distance between the two. The height and width of the 
gray area was set to N/2 in our experiments. 
 
 
B(xk, yk) 
B(xk−1, yk−1) 
B(xk+1, yk+1) 
md(xk, yk) 
(a) 
 
B(xk, yk)
(b) 
Figure 2. (a) Random selection of image blocks, 
(b) the strategy of block selection. 
 
2.2 Obtaining the Edge Block Recovery Information 
To obtain the edge block recovery information, the 
intensity variance of block B(x, y) is first computed by 
[ ] .),(),(1),( 1
0
1
0
2
2
2 ∑∑−
=
−
=
−++=
b
i
b
j
yxmjybixbI
b
yxσ  
An image block is called an edge block if its intensity 
variance is greater than a certain threshold, whereas the 
others are referred to as non-edge blocks. The threshold is 
determined such that there are totally N2/4b2 edge blocks 
due the capacity information embedding. Figure 3 shows 
the edge information in which edge blocks are shown in 
black. In order for better preserving the details of the 
image, an edge block is further decomposed into four 
sub-blocks of size b/2×b/2. Letting ms(p, q), 0 ≤ p, q < 2, 
be the intensity mean of a sub-block, the four-bit 
difference of the intensity means between the sub-block 
and its parent is computed by 
dxy(p, q) = [m(x, y) – ms(p, q) + 256]/32. 
If an edge block is identified to be tampered with, the 
four intensity differences dxy(p, q), together with the 
intensity mean m(x, y), will be used to recover its content. 
For a non-edge block, it will be recovered by m(x, y) 
only. 
The edge information is represented by 0s (non-edge) 
and 1s (edge) in order to determine if a block is an edge 
block. Also, for the purpose of robustness, we make three 
copies of such information, each of which is embedded 
into different subbands of the wavelet coefficients. One 
of the advantages of such a design is that majority voting 
can be performed if an image block needs to be recovered. 
Selection of wavelet coefficients for embedding the 
recovery information is also random for the purpose of 
security. 
 
 
Figure 3. The edge information (edge 
blocks are shown in black). 
 
2.3 Watermark Embedding 
Let Ii
θ denote a wavelet subband, where i is the resolution 
level and θ is the orientation, θ = 0…3. The image is first 
decomposed by three-level wavelet transformation such 
that the number of wavelet coefficients in subband I2
0 is 
equal to that of the image blocks. Because a coefficient in 
I2
0 corresponds to four coefficients in I1
1 and I1
3, 
respectively, the eight-bit authentication information 
md(xk, yk) will be embedded into the eight coefficients in 
I1
1 and I1
3, respectively, which correspond to block 
B(xk+1, yk+1). When embedding the recovery and edge 
information, the same technique as described in Section 
2.1 is used to select wavelet coefficients in order to 
maintain certain distance between neighboring image 
blocks. Such a design is also for the purpose of resisting 
the bulk modification attack. Consequently, the four-bit 
edge block recovery information dxy(p, q) is embedded 
into subband I1
2, and the three copies of edge information 
are embedded into subbands I2
1, I2
2, and I2
3, respectively. 
Figure 4 delineates the embedding process. 
 8
be decomposed into four sub-blocks, followed by further 
adding the amount of d'xkyk(p, q)×32 to the recovered 
result to signify the details of the block. 
 
3. Experimental Results 
In our experiments, the 512×512 grayscale image Lena 
was used as the host image, as shown in Figure 6(a). The 
quantization intervals were set to 82 for subbands I1
1, I1
2, 
and I1
3, and 40 for I2
1, I2
2, and I2
3, respectively. Figure 6(b) 
shows the watermarked image, whose PSNR value is 
about 30.2 dB. The image is then modified by placing a 
bird on Lena’s hair (Figure 6(c)). The result of 
authentication is shown in Figure 6(d), in which the 
tampered areas are correctly identified. Figure 6(e) 
shows the recovery result without considering edge 
blocks and Figure 6(f) is the result taking edge blocks 
into consideration. It is obvious that the image quality is 
greatly improved using the recovery information. We 
also made an attack by cropping the image. Figure 7 
shows the results of cropping, authentication, and 
recovery. Finally, a number of common image processing 
operations were performed to measure the algorithm’s 
robustness, including blurring, sharpening, JPEG 
compression with 75% quality factor, brightness 
increasing and decreasing by 20, and Gaussian noise 
addition (zero mean and variance = 4). The results all 
showed that our algorithm didn’t report any tampering. 
Hence, it is very robust to common image processing 
operations. 
 
(a) (b) 
(c) (d)
(e) (f) 
Figure 6. (a) Original image, (b) watermarked, (c) 
tampered, (d) authentication result, (e) recovery without 
considering edge blocks (PSNR=28.8), (f) recovery 
taking edge blocks into consideration (PSNR=29.1). 
 
(a) (b) 
(c) 
Figure 7. (a) Image cropped at lower-right corner, (b) 
authentication result, (c) recovery result (PSNR = 28). 
 
4. Conclusions 
An image authentication and recovery algorithm which 
operates in the wavelet domain is proposed in this paper. 
The image is first divided into blocks, followed by 
computation of their intensity means. By carefully 
establishing the relations among image blocks, this 
method is able to identify malicious changes made on the 
image, while very insensitive to common image 
processing. In addition, the system is able to recover the 
tampered blocks using different recovery strategies 
according to the characteristics of the image blocks. The 
experimental results clearly demonstrate that the 
proposed algorithm is very effective both for tamper 
proofing and image recovery. 
 
5. References: 
[1] J.A. Dittmann and R. Steinmetz. Content-Based 
Digital Signature for Motion Pictures Authentication 
and Content-fragile Watermarking. In Proceedings 
of the International Conference on Multimedia 
Computing and Systems, Vol. 2, 1999. 
[2] S. Bhattacharjee and M. Kutter. Compression 
Tolerant Image Authentication. In Proceedings of 
the International Conference on Image Processing, 
1998. 
[3] N. Chotikakamthorn and W. Sangiamkun. Digital 
Watermarking Technique for Image Authentication 
by Neighbouring Block Similarity Measure. In 
Proceedings of the International Conference on 
Communications, Vol. 2, 1999. 
[4] I. Kim, S.S. Han, and J.H. Shin. An Improved 
Tamper-Detection Method for Digital Images. In 
Proceedings of the International Symposium on 
Industrial Electronics, Vol. 1, 2001. 
[5] D. Kundur and D. Hatzinakos. Towards a Telltale 
Watermarking Technique for Tamper-Proofing. In 
Proceedings of the International Conference on 
Image Processing, Vol. 2, 1998. 
[6] C.T. Li, D.C. Lou, and T.H. Chen. Image 
Authentication and Integrity Verification via 
 10
 
 
 
 12
as invertible operations. However, their approach 
has a low embedding capacity and it produces 
perceptual artifacts similar to the salt-and-pepper 
noise as a result of the modular operation. Until 
recently, reversible data embedding techniques 
have drawn more and more attention and they can 
be classified into three categories according to the 
techniques associated with restoration. Type-I 
approaches [2, 3] rely on lossless compression to 
achieve reversibility and exploit the redundant 
space created by compression. The space thus 
created is used for data embedding and for 
preserving the original pixel values. In general, the 
capacity with regard to compression-based 
algorithms is dependent on the nature of the image 
and is restricted to the performance of lossless 
compression techniques. Kalker et al. [4] have 
proven the theoretical capacity bounds for 
reversible data embedding based on lossless 
compression. The reversible watermarking 
algorithms, which entirely rely on lossless 
compression to create space for embedding the 
payload, are restrained in the capacity improving. 
As wavelet transform becomes popular, Type-II 
approaches [5, 6, 7, 8, 9] use it to map integers to 
integers so that the basic property of reversibility 
can be achieved. The integer wavelet transform is 
used by many researchers to produce high 
embedding capacity. One of the drawbacks of 
Type-II approaches is that the original data about 
the host image and related metadata should also be 
embedded into the image, thus also taking up the 
capacity. 
Type-III approaches are based on histogram 
manipulation [10, 11, 12, 13], and they are 
relatively simple and efficient. Furthermore, by 
appropriately modifying the distribution of the 
pixel values of an image, the watermarked image is 
very similar to the original and the image content 
can be well preserved. Such approaches are usually 
restrained in the capacity, but there is no need to 
embed the original values regarding the host image. 
Techniques based on lossless compression and 
integer wavelet transform embed the original 
values concerning the host image to restore the 
exact original content. 
In this paper, a novel Type-III reversible data 
embedding methods is proposed, in which exact 
recovery of the original host image is possible, 
very high embedding capacity is achievable, and 
the distortion of the image is within an acceptable 
range. The rest of this paper is organized as follows. 
Section II contains a detailed explanation of the 
algorithm of contrast stretching. The novel 
reversible data embedding method is described in 
Section III. Data extraction and content restoration 
are discussed in Section IV. In Section V, the 
proposed algorithm is implemented and the 
simulation results are presented. Further analysis is 
also discussed in the same section. And finally, 
Section VI gives some concluding remarks. 
II. Contrast Stretching 
Contrast stretching, one of the histogram 
manipulations, tries to extend the narrow range of 
image pixel values over a wider range. It is often 
used to improve the image quality by stretching the 
range of intensity values such that image contrast 
could be enhanced. Unlike histogram equalization, 
contrast stretching is a linear mapping between the 
input and output pixel values. The result is less 
dramatic but tends to avoid the sometimes artificial 
appearance of equalized images. Furthermore, the 
image histogram after stretching contains many 
created gaps, which are actually a missing set of 
particular intensity values. Such missing values are 
used for data embedding. 
The watermark is embedded in the gaps in the 
histogram of each image block. Fig. 1 illustrates 
the idea of contrast stretching for data embedding, 
in which every pixel intensity value in the original 
histogram are stretched a position left or right from 
the peak value, hence creating the missing intensity 
values. As large gaps of missing intensity values 
together could produce a downgraded look, the 
width of a gap is defined as one pixel value at 
most. 
 14
the full coverage situation. Often, the pixel values 
in an image block are contained within a restricted 
range so that they could be stretched. 
III. Reversible Data Embedding 
The reversible data embedding algorithm can be 
summarized using the steps below. 
1. The original image is divided into equal-sized 
(N×N), non-overlapping image blocks, and N is 
set to be less than 16 such that the full coverage 
problem is avoided.  
2. The histogram statistics is computed for each 
image block, including the gray level with the 
most counts, the minimum and maximum gray 
levels in the image histogram, and the number of 
pixels. If there are more than one peak values in 
a block, p is defined as the one with greatest 
gray level.  
3. Contrast stretching is performed on each image 
block to create extra embedding space. 
4. Each block is then divided into two sub-block 
sets: L (left of the histogram) and R (right of the 
histogram), according to the pixel values being 
less or greater than p. With some exceptional 
cases, if the peak value is minimum or 
maximum gray level at the same time, this block 
is only divided into R or L. If all pixels in the 
block have the same value, this block would be 
discarded. 
5. Two disjoint sets of sub-blocks, S (slack) and E 
(extreme), are created, where S is the set in 
which each sub-block doesn’t contains the 
extreme values and E is the opposite to S. If R or 
L doesn’t include extreme values, add it to S, 
otherwise add it to E. The extractor needs to 
know how to extract the embedded watermark 
and restore the original values. The embedding 
order should be determined. The data are 
embedded into the sub-blocks in S first. After the 
embedding capacity in S is exhausted, the rest of 
bitstream are embedded into the sub-blocks in E. 
The actual embedding order in S or E can be 
chosen by a cryptographic key.  
6. For image restoration, the sub-blocks in S can 
use p to get back to the original state. The p is 
kept intact, i.e., the peak value in an image block 
is invariant before and after data embedding. 
However, the sub-blocks in E need e1 or e2 
which is lost after data embedding. Therefore, 
the e1 or e2 should be collected for each 
sub-block in E. Such information, denoted by A, 
is referred to as reverse-aid and needs to be 
embedded in order to facilitate decoding. An 
end-of-stream (EOS) symbol is appended to A in 
order to identify the end of A. 
7. The reverse-aid A and the data payload P are 
embedded all together, the payload is the image 
authentication code or the data associated with 
the product which is desired to be transported 
along with the product. They are combined to 
form a binary bitstream as a watermark W: W = 
A||P = w1w2 ⋅⋅⋅ wm, where wn ∈ {0, 1}, 1 ≤ n ≤ m, 
and m is the length of W. The watermark is 
embedded into the generated space by contrast 
stretching and the embedded image is obtained. 
The data embedding within the sub-block starts 
with scanning the pixel values, and all pixel 
values in the embedding area are modified by 
either adding or subtracting one bit of W to these 
pixel values. This means that 
( , ) = ( , ) + , if ( , ) ,
( , ) = ( , ) , if ( , ) ,
n
n
b'' i j b' i j w b' i j L
b'' i j b' i j w b' i j R
∈
− ∈

 (4)
where b"(i, j) denotes the pixel value after data 
embedding. Then the embedded image is 
produced. 
IV. Data Extraction and Image Restoration 
To read the watermark and restore the original 
image, the steps below are followed. 
1. The received image is divided into image blocks 
by the same size N.  
2. Compute the peak value of each block by the 
histogram statistics.  
3. Each image block is further divided into two 
sub-block sets, L and R, using the same method 
during the data embedding process. 
4. All sub-blocks could be classified into only two 
categories: extreme values included or not. Two 
disjoint sets of sub-blocks, S and E, are created. 
If the sub-block doesn’t include intensity value 0 
or 255, add it to S, otherwise add it to E. 
 16
C
ap
ac
ity
(b
pp
))
0.55
0.6
0.65
0.7
0.75
0.8
0.85
0.9
2 4 8 16 32
Block Size
F-16 Peppers Lena
Boat Baboon
 
Fig. 2: The relationship between capacity and block size. 
It is obvious that the proposed algorithm 
achieved a satisfactory and stable performance for 
embedding capacity. All capacities are greater than 
0.5 bits/pixel (bpp), and the highest is 0.85 bpp. 
Compared with Celik’s high capacity method [3], 
the difference of bit rate between the best and 
worst case is less than 0.12 bpp in Fig. 2. However, 
the resulting embedding capacity in Celik’s scheme 
is about 1.04 and 0.17 bpp in the same embedding 
level for the best (F-16) and the worst (Baboon) 
cases, respectively.  
 For the images with a large number of smooth 
regions (as F-16), the capacity slightly decreases 
since there are lots of blocks which contain the 
same pixel values and the peak value of block 
would not be used to embed data. For the images 
with a large number of rough regions (as Baboon), 
they can be embedded great amount of data and 
tolerates image downgrading at the same time. 
We conclude that increasing the block size does 
not dramatically increase the capacity and the 
larger block size leads to lower image quality. 
Since each image block is stretched individually 
without considering the distribution of adjacent 
blocks, the block effect becomes apparent and the 
image quality is degraded. 
As the preliminary experimental results, the 
contrast stretching produces high and stable 
embedding capacity, and the proposed method 
outperforms most of the existing techniques in the 
aspect of embedding capacity. Table 2 shows the 
comparison. 
Table 2: Comparisons of bit rates among existing techniques. 
Approach Bit Rate (bpp) 
Celik et al. [3] < 1.0 
Tian [5] < 0.5 
Xuan et al. [9] <0.35 
De Vleeschouwer et al. [11] < 0.06 
Zhicheng et al. [12] 0.05 
The proposed method > 0.5 
 
(a)  (b) 
(c)  (d) 
Fig. 3: Experimental results of F-16. The original image (a), the 
watermarked versions with block size 2×2 (b), 4×4 (c), and 8×8 
(d), respectively. 
(a)  (b) 
(c)  (d) 
Fig. 4: Experimental results of Lena. The original image (a), the 
watermarked versions with block size 2×2 (b), 4×4 (c), and 8×8 
(d), respectively. 
(a) 
  
(b)  
 18
MULTILAYERED HIGH-CAPACITY REVERSIBLE DATA EMBEDDING 
 
 
Yuan-Liang Tang* and Hui-Tzu Huang 
Department of Information Management 
Chaoyang University of Technology 
168 Jifong E. Rd., Wufong Township, Taichung County 41349, Taiwan (R.O.C.) 
*Email: yltang@cyut.edu.tw 
 
 
ABSTRACT 
Digital watermarking is a key ingredient to 
multimedia protection. However, most existing 
techniques distort the original content as a side 
effect of watermark embedding. To overcome 
such a problem, reversible data embedding has 
been introduced and is growing rapidly. In 
reversible data embedding, the original content 
can be completely restored after the removal of 
the watermark, and it is very useful to protect the 
images that require high visual quality such as 
legal or medical images. In this paper, we 
propose a novel multilayered reversible data 
embedding algorithm based on histogram 
stretching. Histogram stretching is employed to 
produce extra space for data embedding, and such 
redundancy in an image is exploited to achieve 
very high embedding capacity. In addition, with 
multilayered embedding, the embedding process 
is able to achieve even higher capacity. The 
proposed algorithm was implemented and tested 
on various standard grayscale images. Evidently, 
the experimental results demonstrated a 
promising outcome. 
 
KEY WORDS 
Reversible data embedding, histogram 
manipulation, and histogram stretching 
 
 
1. Introduction 
 
As multimedia becomes an important form of 
information exchange, a large number of digital 
products are created and transmitted via the 
Internet. One of the characteristics of digital 
products is that they are very easy to create, store, 
duplicate, transmit, and modify. This results in a 
serious problem because unauthorized use, 
copying, or modification of the products also 
becomes very easy. How to protect the products 
in various aspects thus presents a problem that 
challenges the academia and business. A general 
solution to such a problem is by the use of digital 
watermarking techniques, in which information is 
embedded into the product for the purpose of 
content protection of important products. 
Digital watermarking techniques attempt to 
imperceptibly embed one signal into another. 
Even if the presence of the watermark is 
imperceptible, the embedding process usually 
introduces irreversible degradation of the original 
image. The distortion might be very slight, but 
zooming in on the image to emphasis some 
details would result in a visual effect below what 
is acceptable. To solve the problem, reversible 
data embedding techniques incorporate the 
property of reversibility, namely, it is possible to 
completely restore the product content to its 
original state after the removal of the embedded 
data. Some applications that require accurate data 
may not tolerate too much image distortion, for 
example, legal or medical images, remote sensing, 
media asset management, electronic diagnosis, 
etc. Therefore, an embedding process that is 
reversible can be very useful for high-quality 
images. 
The concept of reversible data embedding first 
 20
 
Based on the above reasoning, let b be the 
image block of size N×N and b(i, j) denotes the 
original pixel value at location (i, j), where 
0 ≤ i, j ≤ N–1. The histogram stretching is defined 
as 
b' (i, j) = p + 2[b(i, j) – p] = 2b(i, j) – p, 
where b'(i, j) is the pixel value after stretching 
and p is the gray level with the highest count in 
the histogram. As grayscale values are bounded 
in range [0, 255], we have 0 ≤ b'(i, j) ≤ 255, 
which is equivalent to 0 ≤ 2b(i, j) – p ≤ 255. To 
prevent the over/underflow problem (the range of 
shifted pixel values may be less than 0 or greater 
than 255) and the extreme value problem 
(intensity 0 or 255 exists), the pixel values in an 
image block must satisfy the following 
constraint: 
p/2 < b(i, j) < (p + 255)/2. 
In other words, if the pixel values satisfy the 
above condition, they could be stretched. On the 
contrary, pixels dissatisfying the above condition 
are stretched using the following equation instead 
without causing overflow or underflow: 



+>+=′
−<−=′
+≤≤−−=′
,),(  if  ,),(),(
,),(  if  ,),(),(
,),(  if  ,),(2),(
22
11
21
epjibejibjib
epjibejibjib
epjibeppjibjib
 
where e1 and e2 are the numbers of empty bins in 
the histogram from 0 to the minimum gray level 
and from the maximum gray level to 255, 
respectively. The number of the gray levels to be 
stretched will then be the number of the missing 
intensities clustered at one end of the histogram. 
If the range of grayscale values in the 
histogram covers the full possible set of values, 
straightforward histogram stretching will achieve 
nothing; that is, the histogram should have at 
least one gap on the left or right side of the peak 
in order to provide room for stretching. As a 
consequence, the block size should be carefully 
chosen (e.g., N < 16) in order to avoid the full 
coverage situation. For a natural image, however, 
the pixel values in an image block are usually 
within a restricted and small range; full coverage 
of the intensity range is very rare. 
 
 
3. Reversible Data Embedding 
 
The reversible data embedding algorithm can be 
summarized as the steps below. 
8. The original image is divided into equal-sized 
(N×N), non-overlapping image blocks. And 
the histogram statistics is computed for each 
image block, including the gray level with the 
most counts, p, the minimum and maximum 
gray levels in the image histogram, and the 
number of pixels. If there are more than one 
peak values in a block, p is defined as the one 
with a greater gray level. 
9. Perform histogram stretching on each image 
block to create extra embedding space. 
10. Each block is then divided into two sets of 
subblocks: L (left of the histogram) and R 
(right of the histogram), according to the 
pixel values being less or greater than p. With 
some exceptional cases, if p happens to be the 
minimum or maximum gray level, this block 
is only divided into R or L. If all pixels in the 
block have the same value, it would be 
marked useless. 
11. Create two disjoint sets of subblocks, S (slack) 
and E (extreme), where S is the set of 
subblocks that don’t contains the extreme 
values and E contains the rest of the 
subblocks. If R or L doesn’t include extreme 
values, add it to S, otherwise add it to E. The 
extractor needs to know how to extract the 
embedded watermark; hence the embedding 
order should be predefined. In our 
experiments, the data are embedded into the 
subblocks in S first. After the capacity in S is 
exhausted, the rest of the bitstream are 
embedded into the subblocks in E. The actual 
embedding order in S or E can also be 
randomly chosen with a cryptographic key to 
enhance the system’s security. 
12. During image restoration, as p is kept intact 
during embedding, it is used to restore the 
subblocks in S back to their original states. 
However, the subblocks in E need e1 or e2 for 
restoration, which is lost after data 
embedding. Therefore, e1 or e2 should be 
 22
various 512×512 standard grayscale images, 
including F-16, Peppers, Lena, Boat, and Baboon. 
The images range from smooth images (e.g., 
F-16) to rough images (e.g., Baboon). The 
payload data is randomly generated. The 
relationship between the block sizes and the 
performance of the proposed algorithm is 
delineated in Fig. 2. 
C
ap
ac
ity
, b
pp
-
0.55
0.6
0.65
0.7
0.75
0.8
0.85
0.9
2 4 8 16 32
Block Size
F-16 Peppers Lena
Boat Baboon
 
Fig. 2: Relationship between capacity and 
block sizes. 
It is obvious that the proposed algorithm 
achieved a satisfactory and stable performance in 
terms of embedding capacity. All capacities are 
greater than 0.5 bits/pixel (bpp), and the highest 
is 0.85 bpp. The bit rate difference at a same 
block size is always less than 0.12 bbp, which 
means our method is relatively more stable than 
Celik’s method [3], in which the capacities for 
the best (F-16) and worse (Baboon) cases are 
1.04 and 0.17 bpp, respectively, with a difference 
of 0.87 bbp. For smooth images (e.g., F-16), the 
capacity decreases slightly because there are lots 
of useless blocks. For rough images (e.g., 
Baboon), a great amount of data can be 
embedded. In addition, increasing the block size 
does not effectively increase the capacity, and a 
larger block size tends to produce lower image 
quality. Since each image block is stretched 
individually without considering the distribution 
of adjacent blocks, the block effect becomes 
apparent. The experimental results shown in 
Table 1 demonstrate that our method outperforms 
most of the existing techniques, except for Celik 
et al.’s method, in terms of the embedding 
capacity. However, it will be apparent from 
Section 6 that the embedding capacity could be 
made much higher using the multilayered 
embedding approach. The visual quality of the 
embedded images is shown in Figs. 3−5 for F-16, 
Lena, and Baboon, respectively. It is also obvious 
that the image quality is somewhat sacrificed for 
high embedding capacity. 
Table 1: Comparisons of embedding capacities. 
Approach Bit Rate (bpp) 
Celik et al. [3] 
Tian [5] 
Xuan et al. [9] 
De Vleeschouwer et al. [11] 
Zhicheng et al. [12] 
Our method 
< 1.0 
< 0.5 
< 0.35 
< 0.06 
= 0.05 
> 0.5 
 
(a) (b) 
(c) (d) 
Fig. 3: (a) The original F-16 image, (b) embedded with 
block size 2×2, (c) 4×4, and (d) 8×8, respectively. 
 
(a) (b) 
(c) (d) 
 24
 
Fig. 8: The relationship between the embedding layers 
and the headers. 
 
At the first embedding layer, H1 is set to 0 and 
it is combined with A1 and P1, where A1 is the 
reverse-aid at layer 1 and P1 is part of the payload, 
P. The watermark, W1, to be embedded at layer 1 
becomes W1 = H1 ||A1 || P1. Following the same 
manner, the parameter pair, denoted by Hi+1, at 
layer i will be the header at layer i+1, and it will 
be combined with the payload to form the 
watermark Wi+1. The final header, Hf+1, will not 
be embedded into the image; it is transmitted 
along with the embedded image, Iw. During 
multilayered data extraction, the received Hf+1 is 
used to extract the watermark at the final 
embedding layer and to recover the image. In the 
same way, header Hi is used to extract the 
watermark at layer i−1. The data extraction and 
restoration process will continue until the header 
equals 0. The image will then be restored exactly 
the same as the original content if no tampering 
has ever occurred 
 
 
7. Experimental Results 
 
The performance of the multilayered method is 
compared against those of high-capacity and 
low-distortion algorithms, namely, the lossless 
G-LSB method [3] and the Difference Expansion 
method [5], as shown in Fig. 9. It is obvious that, 
in average, the proposed method outperforms the 
other two, in terms of both the embedding 
capacity and the quality of the embedded images. 
 
 
8. Conclusion 
 
In this paper, a novel multilayered data 
embedding algorithm for digital images is 
presented. The proposed technique is based on 
histogram stretching and uses multilayered 
approach to repeatedly embedded information 
into an image. It has the ability of recovering an 
embedded image to its original state and the 
embedding capacity is relatively high, compared 
with most of the existing methods. The proposed 
algorithm is very useful for applications that 
require high-quality images. 
 
 
0
0.2
0.4
0.6
0.8
1
1.2
1.4
20 25 30 35 40 45
PSNR (dB)
G-LSB DE Proposed
(a)
 
0
0.2
0.4
0.6
0.8
1
1.2
1.4
20 25 30 35 40 45
PSNR (dB)
G-LSB DE Proposed
(b)
 
Fig. 9: Capacities (bpp) compared against the G-LSB 
and DE methods using (a) Lena (b) Barbara as test 
images. 
 
 
Acknowledgements 
 
This research is supported by a grant from 
National Science Council, Taiwan, R.O.C. 
(NSC94-2213-E-324- 019). 
 
 
References 
 
[14] C.W. Honsinger, P. Jones, M. Rabbani, and 
J.C. Stoffel, Lossless Recovery of an 
Original Image Containing Embedded Data, 
000101010110
101011110001
010100000011
010001101001
001100010101
000110011100
000101010110
101011110001
010100000011
010001101001
001100010101
000110011100
Embedding Layer 1 
Embedding Layer 2 
Final Embedding 
Layer 
Original Image
Header H1
Header H2
Header Hf 
00010101 1
10101111 0
01010000 1
010001101001
001100010101
000110011100
