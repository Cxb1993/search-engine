1 
行政院國家科學委員會專題研究計畫成果報告 
類人型機器人之動態感測與控制及系統整合 
Dynamic sensing and control and system integration of humanoid robot. 
計 畫 編 號：NSC  96-2221-E-002-318 
執 行 期 限：98 年 08 月 01 日 至 99 年 07 月 31 日 
主 持 人：羅仁權 教授 台灣大學電機系 
計畫參與人員：吳士強 台灣大學機械研究所 
一、中文摘要 
此子計畫之目標是建立類人形機器人之
完善感測系統，使雙足機器人有良好感測能
力與環境互動。本子計畫分別對機械手臂、
機械視覺與機器人自動尋找充電站並賦歸充
電站這三部分進行研究。機器手臂部分，利
用 CCD Camera 與雷射測距儀(LRF, Laser 
Range Finder)進行感測融合，使機器手臂能
自動尋找抓取物，並找到適合之抓取點進行
抓取。而在機器視覺方面，我們使用 Adaboost
演算法，使用大量正片與負片樣本進行訓
練。經過一系列的訓練，可以攝影機擷取之
畫面上自動鎖定人臉與人體目標，得以實現
機器人對人臉或人體追蹤。最後，利用 LRF
與 Camera 這兩個感測器，並使用變異數交互
關係法(CI, Cross Intersection)感測融合方
法，降低機器人尋找充電站的不確定性，機
器人進行同時定位與建地圖之功能(SLAM, 
simultaneous localization and mapping)找出自
身所在位置，並往充電站方向移動，進行充
電之功能。 
關鍵詞：感測融合、SLAM 同時定位與建地
圖、Adaboost 演算法、變異數交互
關係法(CI, Cross Intersection) 
Abstract 
In order to make humanoid robot have 
better ability to detect the environment, this 
project aims to develop multi sensor fusion 
system. By using CCD camera and LRF, we 
have image and distance information. After 
fusing them, it’s easy for the arm to detect the 
potential target and find a suitable point to 
grasp. About machine vision, we take camera 
with employing the adaboost algorithm and 
taking a series of training to detect the face and 
human body. Once it detects targets, it does 
tracking. Last but not least, we reduce the 
uncertainty of detecting the charging station by 
taking advantage of LRF and Camera with CI 
(Cross Intersection) approach. Robot does 
SLAM to find the location where it is. Then it 
docks to do charging. 
Keywords: Sensor Fusion, SLAM, Adaboost 
algorithm, Cross Intersection (CI) 
二、緣由與目的 
    近年來國內自動化技術逐漸發展成熟，
全球各項科技也都有許多創新突破，國內許
多產業界、學術界、研究單位開始思考繼電
子資訊產品之下一波具有廣大應用價值的市
場。也因此機器人產業被列為下一世代具有
強大發展潛力革命性產品之一。 
    然而國內機器人研究主要集中在輪型機
器人功能的開發與改善，由居家保全、到娛
樂等領域的應用都主要以輪型機器人發展為
主。而輪型機器人在環境中克服障礙物之能
力卻有其限制。近幾年，許多專家學者將其
注意力轉移至雙足步行機器人之研究上。 
一個具備多個感測器的智慧型移動機器
3 
    圖 5 是人臉跟踪的實驗結果，使用紅色
框框將辨識到的目標框出來，分別有人體偵
測，與人臉偵測。圖 6 是人體追踪的實驗結
果，經過訓練後，可以得到較好的追蹤效果。 
 
圖 5 單一人臉追蹤實驗結果 
 
圖 6 雙人人體追蹤 
3.2 Eye in Hand 抓取物體之多重感測回饋 
我們結合多個傳感器馬達編碼器、CCD
和雷射測距儀。利用 CCD 鏡頭設計機器人手
臂路徑規劃：得到的資訊，提供鑑於機器人
的環境作為一個輸入一個Adaboost的學習過
程，構建了串列分類器(Cascade Classifier)。
但相機影像的品質強烈受到環境的影響。為
了減少相機受到環境的影響，我們的系統是
整合從雷射測距儀提供的距離資料，在處理
過程中，比對影像與距離資訊便可完成物件
辨識與分類。 
3.2.1 機械手臂系統架構  
為了探討仿人形機器人可行性，我們建
立了一個裝有傳感器構造機器人手臂進行初
步研究。機器手臂構造使用鋁合金。系統主
控制器的規格如下：PC (Personal Computer) 
with a Intel(R) Core™ 2 Duo CPU 2.26GHz 
與 4GB RAM，8 個馬達驅動器 1 夾爪和配備
了兩個不同的傳感器：CCD 相機和雷測測距
儀。我們利用 PC 的高速運算能力控制機器
人，可編程和更靈活的控制，甚至它提供的
整合開發環境，具有豐富的軟體和硬體支
援。使用 MOXA UPort 的 1650-8 USB 到串列
轉換器提供高穩定性的機器人實時控制。最
後，我們開發了六自由度手臂配合視覺伺服
系統和雷射測距儀在手。機器人臂的硬體系
統架構如圖 7。 
 
圖 7 手臂物體抓取之系統架構 
機器人手臂的設計與六自由度能達到
的工作範圍在三維空間中。為瞭解機器手臂
動態的運動情形，首先每一個關節空間的影
響必須建立從底座到手臂末端的關係。圖 8(a)
為使用 Denavit – Hartenberg 法則建立每一個
環節之間的關係座標系統的六自由度手臂。 
 
圖 8 (a)手臂與夾爪之設計圖 (b)手臂上之座標系統 
該機器人手臂控制程序結合微軟 C
＃、WPF(Windows Presentation Foundation)
和在 Microsoft.Net frame 下的 MATLAB。該
程式使用 C＃，提供友好的人機界面的顯示
5 
便往水壺的位置靠近。圖 12 顯示了機器手臂
抓取水壺一連串的過程。在前兩張圖片中，
CCD 影像中被偵測到較短的線特徵，很明顯
地被視為手把，然後控制機械手臂接近該線
特徵，再由 CCD 影像作回授確認，再進行抓
取。 
 
圖 11 利用視覺伺服回授進行水壺夾取點之偵測與選
取 
 
圖 12 機械手臂自主抓取水壺連續鏡頭 
3.3 自主移動機器人之賦歸與充電 
在本節中，我們開發了多傳感器融合方
法。使用 Covariance Intersection 方法進行強
度和範圍數據融合，以達到使機器人賦歸並
進行充電之功能。利用一個人工的 landmark
做為充電站影像上線索，通過逆透視投影以
便確認該位置。同時，獲得的數據的範圍由
雷射測距儀的建模為多線段，假設是在環境
中的牆壁。然後，通過使用變異數交互關係
法的方法能更加精確地估計機器人與充電站
之間的幾何關係。透過實驗結果，我們成功
證明該演算法的可行性。 
3.3.1 影像模型  
圖 13 說明了相機和測距儀的幾何關
係，彩色相機安裝在雷射測距儀上方。一個
額外的伺服控制裝置是執行測距儀的傾斜功
能。範圍資料平面的數據是由擺動 LRF 所產
生。彩色圖像則由相機所捕捉到。各種數據
和圖像數據的收集和計算主要由安裝在機器
人上的個人電腦進行處理。 
 
圖 13 機器人上 ICS 與 RCS 座標系統之幾何關係 
我們使用 4 × 4 同質矩陣 將 RCS 轉
換成 ICS 座標系。轉換矩陣 的定義為： 
                  (10)           
然後， 
           (11) 
3.3.2 相機模型  
    我們定義相機模型為： 
I=AX,                              (12) 
I 是行向量 ，代表在影像平面的
齊次坐標。 X 是行向量 代表在世
界坐標系統下的齊次座標（即為 ICS）。A是
4 × 3 矩陣，將三維世界座標系的點座標映射
7 
圖 16 IEPF 疊代分割 
3.3.3.2 IEPF 之權重 
圖 17（a）顯示利用 IEPF 在附近的一個
角落裡進行雷射掃描之結果。由於頂點的角
落，是超越距離的測量（3 米），IEPF 將導
致了三個線段。顯然，在最短的線段是 不是
真正的目標。在這個實驗中，我們修改 IEPF
加入加權總和。當第一點線段的是，比前一
個閾值(threshold value)（例如閾值為 5），線
段從 IEPF 所得到的結果是有效的。否則，該
線段就不是我們所想要的。圖 17（b）顯示
IEPF 的加權總和的門檻。 
3.3.3.3 霍夫轉換之不確定性估測 
Hough轉換是一種在 IEPF線特徵提取方
面，十分流行的方法。然而，在這一節中，
我們利用 Hough 轉換將這些已聚集成組的加
權 IEPF 共線點重新取樣。 
 
圖 17 (a) 不具權重 IEPF 之結果(b) 具權重 IEPF 之
結果 
 
圖 18 霍夫轉換 
圖 18 顯示了 Hough 變換的結果。最大
投 票 值 表 示 最 有 可 能 線 功 能 在
。 不 過 ， 周 邊 地 區 的
也顯示了不 確定性。為此，我
們可以重新採樣霍夫領域內的黑暗橢圓估計
均值，方差和協方差線的功能。圖 19（a）
顯示了兩個線段的比重 IEPF 和圖 19（b）顯
示行在兩個偏差值間線特徵的不確定性。 
 
圖 19 線特徵不確定性之估測 
3.3.4 利用 Covariance Intersection 方法作
感測融合 
一般來說，為了提取充電站之特徵，我
們可以從視覺系統得到可靠的方向資訊
(orientation)，但深度資訊則會比較粗糙。另
一方面，LRF 模型的處理上，不同於視覺資
訊的處理，LRF 模型具有較容易獲得距離方
面精確的資訊，而在空間特徵的擷取上，則
較為薄弱，不易辨識環境中的特徵。在這個
方法中我們結合相機所或的之影像資訊，與
LRF 所得到之所得到之距離模型來降低偵測
或辨識充電站的特徵上的不確定性。感測融
合利用不同的感測器針對相同的目標物，進
行感測互相彌補彼此不足之資訊，改善量測
各項資訊的性能。 
兩部分信息， 和 ，要融合在一起，
得出一個輸出 ，其中 和 的估計，從視
覺和雷射測距系統模型，和 ， 和 是
他們的變異數。變異數交互相關(Covariance 
Intersection, CI）方法是用於這些融合。交集
的特色是交互組合變異數。變異數交互相關
演算法如下： 
                                                          
     
其中ω ∈ [1, 0]，和ω修改相對權重分配給
和 。不同的選擇的 ω 可以對於不同的性
能要求，用來最佳化變異數的估計，如最小
化 的 determinant 值。事實上，此資料更
新對每個 ω 相對較為保守，可以透過下面這
個矩陣證明： 
9 
我們開發使用充電站和機器人賦歸之機
構，提出的數據融合與變異數交互關係法中
實現服務機器人自動賦歸充電站進行充電之
功能。一個具有人工 Landmark 作為視覺線索
的充電站，通過逆透視投影以便確認該位
置。同時，由雷射測距儀獲得的範圍數據的
建模為多線段，其假設該線段是在環境中的
牆壁。然後，機器人與充電戰之間的幾何關
係可經由變異數交互相關法更加精確地被估
計。透過使用變異數交互關係的方法。我們
提出的方法在減少不確定性方面，比單獨使
用雷射測距儀或相機所擷取到的資訊進行自
動賦歸充電功能擁有更佳的表現。 
 
3.5 利用模糊虛擬彈簧阻尼產生器避震 
 人形機器人在行走時，尤其是腳與地面
接觸時會產生震動。為了消除該振動，我們
提出了模糊虛擬彈簧阻尼產生器(Fuzzy 
Virtual Spring - Damper Generator 
(FVSDG))，在踝關節以及髖關節的地方產生
了一個近似直線的彈簧扭矩和阻尼扭矩。 使
用 FVSDG，這些關節的動態將會向避震器一
樣吸收振動。FVSDG 是由 3個部分組成:第一
個部分是虛擬彈簧扭矩產生器；第二個部分
是虛擬阻尼扭矩產生器；第三個部分是非理
想扭矩消除器。下圖為 FVSDG 控制系統架構
圖。參數 A式馬達減速機的減速比，而 kt 式
馬達的扭矩常數。 
 
            圖 23 FVSDG 控制系統。 
 
3.5.1 虛擬彈簧產生器 
    根據虎克定律，輸入角位置θ 與輸出的
扭矩 sT 可用式子(26)描述: 
θ⋅−= kTs                     (26) 
而 k是彈力常數。也就是說 sT 的大小與 θ 的
大小成正比且現性關係。因此，我麼可以利
用模糊系統去模仿彈簧的行為:定義輸入和
輸出的參數分別為θ 和 sT 。他們的歸屬函數
分別是圖 24.(a)和圖 24.(b)。 
 
     圖 24.(A)虛擬彈簧產生器的輸入歸屬函數 
 
圖 24.(b)虛擬彈簧產生器的輸入歸屬函數 
 參數 As 和 Bs 是輸入範圍參數,而 ∗θ 是虛擬
彈簧的平衡點。Cs 和 Ds 則式輸出的範圍參
數。一般而言，彈簧的輸入和輸出無論在拉
伸或壓縮方面皆呈現對稱，因此我們可將各
參數關西用以下式子描述: 
                              
                                                                       
 
        DsCs −=                                  
而模糊規則則如下所示: 
 
 
 
為觀察虛擬彈簧產生器的行為,我們設定 
As=0, Bs=5, ∗θ =2.5, Cs= -100, Ds=100,並
將Ts與θ  的關係由 MATLAB 畫在圖 25 上。 
2
BsAs+
=
∗
θ
If θ  is N, then Ts is P  
If θ  is P, then Ts is N  
 
(27) 
(28) 
11 
這 4個參數來達到控制該虛擬阻尼的特性。 
 
3.5.3 非理想扭矩消除器 
    在馬達中有很多非理想效應, 像是減速
機中的摩擦力和背隙。這些效應會被輸出端
的減速機所放大。假如我們希望實際的效應
可以像彈簧-阻尼一般，我們必須消除這些飛
理想效應。 由一般觀察，這些非理想效應產
生的扭矩與轉動方向相反。這些性質就像摩
擦力一般。 因此，我們可以將其當成常數
Tn，大小為 Tc。 而方向與角速度相反θ&。 圖
28 為非理想扭矩 Tn 關係圖。 
 
 
 
 
 
 
 
           圖 28 Tn的關係圖 
 
Tc 可藉由以下步驟量測到: 
1. 施一小電流於馬達上並逐漸增加其強度
直到馬達旋轉。 
2. 讀取回授電流並乘上 kt與幾速比 A， 此
值即為 Tc。 
 
為了消除非理想扭矩 Tn，我們設計了非
理想扭矩消除器來產生一個與 Tn 大小相同
但方向相反的 Tr。圖 29 為 Tr 的關係圖。 
 
 
 
 
 
 
 
 
圖 29 Tr的關係圖 
有了 Tr 來消除 Tn我們可以說 FVSDG 的輸出
確實如同彈簧-阻尼的動態效應。 
 
3.5.4 行走實驗 
    我擷取了機器人在行走時軀幹上的姿態
感測器(IMU)的兩個訊號作為震動指標(圖
30)，一個是加速度，另一個是角速度。另外，
我們亦比較了有無使用FVSDG 控制系統的資
料。 該姿態感測器的取樣頻率為 100 Hz. 
 
 
 
 
 
 
 
 
 
 
0 2 4 6 8 10 12 14 16 18 20
-20
-10
0
10
20
time (s)
a
c
c
e
le
ra
ti
o
n
 (
m
/s
2
)
 
 
0 2 4 6 8 10 12 14 16 18 20
-20
-10
0
10
20
time (s)
a
c
c
e
le
ra
ti
o
n
 (
m
/s
2
)
 
SSP 
DSP(without FVSDG) 
SSP 
DSP(with FVSDG) 
圖 31 無使用 FVSDG 的加速度曲線 
圖 32 使用 FVSDG 的加速度曲線 
 
圖 30 實驗用雙足機器人 
13 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
(f) 
 
(h) 
 
(i) 
 
(j) 
 
(k) 
 
(l) 
 
(m) 
 
(n) 
15 
四、結論 
本子計畫已實現利用 Camera 與透過
Adaboost 演算法進行人臉與人體追蹤，並且
獲得良好之效果。同時也建立六軸機器手臂
之感測融合系統與機械手臂控制之人機介
面。藉由機械手臂前端之雷射測距儀感測到
之物體位置與相機鏡頭得到之影像資訊比
對，可判斷出欲抓取目標與選取適當抓取點
進行抓取。實驗結果顯示，透過本實驗之感
測系統架設，確實有助於提升機械手臂抓取
物體之準確度。友善之人機界面之建立也令
使用者更易進行機械手臂之操作。關於機器
人自動返回充電站進行充電部分，利用 LRF
透過 Hough Transform 去估測機器人周遭環
境之資訊，降低不確定性。在利用機器人頭
上之 Camera 所得到之影像之資料，將其與
LRF 之距離資訊透過 Covariance Intersection
進行資料感測，令機器人找出確切充電站之
位子進行充電。在雙足移動方面，我們也利
用了力感測器與編碼器來使其達到行走目
的，並利用 IMU 進行實驗數據的擷取。 
五、成果統計 
名稱 次數 說 明 
國際研
討會 
1 Ren C. Luo, C.T Liao, Y.J. Chen, 
“Robot - human face tracking and 
recognition using relative affine 
structure” IEEE International 
Conference on Advanced Robotics and 
its Social Impacts Taipei, Taiwan, Aug. 
23-25, 2008 
國際研
討會 
1 R. C. Luo, Cheng-Tse Chen, ” Internet 
Based Remote Supervisory System for 
Tele-medicine Robotics Application” 
IEEE Workshop on Advanced Robotics 
and its Social Impacts (ARSO 2009), 
Tokyo, Japan, November 23-25, 2009 
國際研
討會 
1 Ren C. Luo, Chung T. Liao, and Shih 
C. Lin, “Multi-Sensor Fusion for 
Reduced Uncertainty in Autonomous 
Mobile Robot Docking and 
Recharging,” Preprint submitted to The 
2009 IEEE/RSJ International 
Conference on Intelligent Robots and 
Systems. Received June 10, 2009 
國際研
討會 
1 Ren C. Luo, Nai W. Chang, Shih C. Lin 
and Shih C. Wu, “Human Tracking and 
Following Using Sensor Fusion 
Approach for Mobile Assistive 
Companion Robot,” Preprint submitted 
to The 35th Annual Conference of the 
IEEE Industrial Electronics Society. 
Received July 17, 2009 
國際研
討會 
1 Ren. C. Luo, M. H. Li, H. L. Jhu, J.W. 
Chen, “Multi-Sensors Feedback for 
Grasping Objects With Laser Ranger in 
Hand” Preprint submitted to The 35th 
Annual Conference of the IEEE 
Industrial Electronics Society 
國際研
討會 
1 Ren C. Luo, Ogst Chen,"Indoor Human 
Dynamic Localization and Tracking 
Based on Sensory Data Fusion 
Techniques," Preprint submitted to The 
2009 IEEE/RSJ International 
Conference on Intelligent Robots and 
Systems. Received June 10, 2009 
國際研
討會 
1 R. C. Luo, H. L. Jhu and Y. C. Lin, “3D 
Landmark Recognition Using 
Combined Range and Intensity Image 
Sensor Fusion Approach”International 
Conference on Service and Interactive 
17 
[9] A. Yilmaz, O. Javed, and M. Shah, "Object 
tracking: A survey," ACM Computing Surveys 
(CSUR), vol. 38, 2006. 
[10] K. Shafique and M. Shah, "A non-iterative 
greedy algorithm for multi-frame point 
correspondence," IEEE International 
Conference on Computer Vision, pp. 110-115, 
2003. 
[11] A. Yilmaz, X. Li, and M. Shah, 
"Contour-Based Object Tracking with 
Occlusion Handling in Video Acquired Using 
Mobile Cameras," IEEE Transactions on 
Pattern Analysis and Machine Intelligence, pp. 
1531-1536, 2004. 
[12] H. Bang, D. Yu, S. Lee, I. H. Suh, " An 
object recognition system based on color 
co-occurrence histogram and geometric 
relations of pyramidal image patches," 
Intelligent Robots and Systems, 2008.(IROS 
2008). Proceedings. 2008 IEEE/RSJ 
International Conference on,, September 22-26, 
2008 Page(s):3591 – 3596. 
[13] P. Viola and M. Jones, "Rapid object 
detection using a boosted cascade of simple 
features," Proc. CVPR, vol. 1, pp. 511–518, 
2001.  
[14] Terawaki, “Measuring Distance Type 
Obstacle Detection Sensor PBS-03JN 
Instruction Manual”, Hokuyo Automatic Co., 
LTD., April 2004, pp. 1-19. 
[15] [Hokuyo Automation, 2005] Hokuyo 
Automation. Scanning laser range finder for 
robotics. 
http://www.hokuyo-aut.jp/products/urg/urg.htm, 
2005. 
  
Automation and its role in the rapidly evolving fields of medicine and the environment will be 
addressed by presenting relevant ongoing research in centers in the Ira A. Fulton Schools of 
Engineering and the Biodesign Institute at Arizona State University along with other relevant results 
in these fields.  The technologies presented are being applied to fundamental problems of biology 
and health including cancer, heart disease, and stroke. Further development of the technology to 
make it small, robust in the real environment (human body, oceans, etc.), fast, and low power will 
enable in vivo diagnostics in humans and real-time monitoring of microbial populations in the 
environment. The talk will delve into exciting possibilities for the future. 
 
Towards a 10,000 Mobile Robot Smart Warehouse 
Order fulfillment is a multi-billion dollar business. Existing solutions range from the highly 
automated -- cost effective but inflexible -- to people pushing carts around in warehouses manually 
filling orders -- flexible but not cost effective. In this talk I will describe a radical new approach to 
order fulfillment that is both flexible and cost effective. The key idea is to use hundreds of 
networked, autonomous mobile robots that carry inventory-storing pods to human operators. The 
result is a distribution facility that is dynamic, self-organizing, and adaptive. 
Various challenges had to be overcome in order to make this an economically viable system, 
including the design of robust autonomous mobile robots, real-time wireless control of hundreds of 
moving agents, the coordination of these agents, and the design of various algorithms that allow the 
system to adapt and reconfigure itself based on the environment and operating conditions. I will 
discuss these challenges and new ones, and the research opportunities in the space of mobile robot 
enabled smart warehouses. 
 
Automation and Robotics 
The relation of factory automation and robotics is addressed. The main idea is to view an 
automated factory as an object of scientific study, furthering the primary goal of robotics, which is 
to understand the principles of animated machines. Factories offer many advantages to the aspiring 
roboticist. You can vivisect a factory without impeding its operation, and without moral concerns. 
You can discuss its design with its creator. And, since factory automation was not contrived by 
robotics researchers, the study of automated factories is closer to a natural science than, say, study 
of robotic origami. One question is whether factory automation, as a "structured" task domain, is so 
fundamentally different from "unstructured" task domains, as to limit the scope of any principles 
learned. The talk will include an attempt to bring some precision to the concepts of structured and 
unstructured task domains. 
 
Robots for Energy and Environment: Evolution and Revolution 
Robotic devices are routinely used for many tasks related to environmental investigation, 
extraction of energy resources, and in support of energy production and distribution. Approaches in 
these areas vary greatly in terms of scale, operating costs, and potential improvement in productivity. 
In many cases these advances represent the evolution of existing paradigms, with the new robotic 
systems offering improved productivity, data quality, or safety. For example, towed deep-sea sonar 
sleds have been largely replaced by autonomous vehicles, which can survey faster and provide 
higher data quality yet are still usually operated from support vessels in a conventional 
expeditionary manner. However, systems are emerging that represent revolutionary capabilities. 
These new systems will be able to accomplish tasks that are impossible through conventional 
methods while fundamentally altering the infrastructure required to support the work. For example, 
networks of gliding autonomous vehicles will be able to survey the ocean without an attending 
support vessel. In this talk, examples of both present and future robots with both evolutionary and 
revolutionary characteristics will be presented from a variety of perspectives, including ocean 
exploration, offshore oil and gas production, and weather forecasting. 
 
Robotics in Medical and Life Sciences 
Some of the most challenging applications of robotics arise in the medical and life sciences. A 
host of applications have become significant in recent decades in terms of the impact of robots in 
biomedical endeavours. From automating research and clinical laboratory procedures to assisting in 
neurosurgery, many new niches are being exploited and robotics research issues unique to these 
domains are being identified. While some laboratory applications amount to standard applications 
of well known automation principles, and some surgical applications amount to tranditional 
teleoperation, this talk will emphasize frontiers where these traditional solutions are not sufficient. 
Some constraints unique to the biomedical problem space will be identified and some currently 
國科會補助計畫衍生研發成果推廣資料表
日期:2010/11/15
國科會補助計畫
計畫名稱: 智慧型類人型機器人之感測融合及控制設計與研製
計畫主持人: 羅仁權
計畫編號: 98-2221-E-002-156- 學門領域: 人形狀機器人
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
