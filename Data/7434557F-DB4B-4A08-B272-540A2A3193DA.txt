I目錄
目錄....................................................................................................................................................................... I
中文摘要.............................................................................................................................................................III
ABSTRACT....................................................................................................................................................... IV
第一章 緒論.........................................................................................................................................................1
第二章 第一年研究計畫成果.............................................................................................................................2
2.1 前言.................................................................................................................................................... 2
2.2 研究目的............................................................................................................................................ 2
2.3 文獻探討............................................................................................................................................ 2
2.4 研究方法............................................................................................................................................ 3
2.4.1 研究一......................................................................................................................................... 3
2.4.2 研究二......................................................................................................................................... 5
2.4.3 研究三......................................................................................................................................... 6
2.5 實驗結果............................................................................................................................................ 7
2.6 討論與建議........................................................................................................................................ 8
參考文獻.................................................................................................................................................. 9
第三章第二年研究計畫成果.............................................................................................................................12
3.1 前言.................................................................................................................................................. 12
3.2 研究目的.......................................................................................................................................... 12
3.3 文獻探討.......................................................................................................................................... 12
3.4 研究方法.......................................................................................................................................... 13
3.4.1 研究一....................................................................................................................................... 13
3.4.2 研究二....................................................................................................................................... 15
3.4.3 研究三....................................................................................................................................... 16
3.5 實驗結果.......................................................................................................................................... 18
III
中文摘要
美國麻省理工學院（MIT）將『生物測定學（biometrics）』或『生物認證（biometric recognition）』
稱為具有改變世界的十大最具潛力的科技之一。以人類身上天生擁有的生物特徵來辨識或驗證使用者
個人身份的一門技術即為生物辨識技術。傳統的方法，如：身份證、信用卡、密碼等，都很容易被竊
取、遺失或忘記，而使用生物特徵的身份確認系統則可以改善這些缺失。隨著網路之普及造成網路資
訊安全之需求日益殷切，如智慧型卡片、門禁管制系統、自動提款機、資料存取安全系統、身份辨識
系統等，皆屬於生物辨識應用之範圍。身份確認在二十一世紀資訊化社會將扮演愈來愈重要的角色。
截至目前，由研究文獻與商業產品可發現較成熟與受到重視的辨識技術包括：指紋、顏面、虹膜、
聲紋與掌形等等。指紋辨識技術最成熟，但是存在個人資料隱私權的問題，始終爭議不斷，亦因此造
成其應用範疇有所限制。顏面紋辨識技術為最自然最簡便的方式，但是由於外在環境影響與顏面本身
的高度變化性及易改變性，造成技術上卻極困難，多年來研究並無太大進展。虹膜辨識為一具高度安
全性技術，但其資料擷取較困難，造成便利性與使用者接受度較低，因此亦限制了其應用範疇，比較
不適用於一般商業性應用。聲紋亦為一自然且簡便的辨識技術，但技術還不太成熟值得探討。
近年來一些研究發現人手掌中之掌形（hand-shape）與掌紋（palmprint）皆具有獨特的特徵，尤其
是每一個人的掌紋更是獨一無二，兩人相同的機率甚至較指紋來得低且極不易作假，同時掌紋與掌形
影像資料擷取的便利性與接受度又較虹膜及視網膜影像擷取來得高。又由於網路資訊安全之需求，使
得以掌紋與掌形為基礎之生物辨識技術之應用益發突顯其重要性。因此，可想見未來以掌紋與掌形特
徵為基礎生物辨識系統之研究在學術上確具重要之價值，在實用上亦有機會與目前主流的指紋、聲紋
等生物辨識系統相抗衡，絕對是一極有潛力之發展方向。目前掌形辨識大都採用固定機架，且有環境
控制，故應用範圍有限。因此本計畫最重要的研究目的是要打破上述限制因素，使此技術應用更彈性、
更自由、更廣泛。本三年期研究計畫針對一般非高度安全性需求之商業應用，如門禁管制系統、可攜
帶行動型設備（電腦、手機、PDA 等）之使用者簽入（log in）系統，以融合掌形與掌紋特徵為基礎，
設計一簡易、低成本、使用者友善、無環境控制的生物辨識技術，實作一套身份確認系統。
本三年期計畫中之自動融合掌形與掌紋辨識系統的整體架構分為四大模組：影像擷取模組、前處
理模組、特徵萃取模組與型樣識別模組。在影像擷取模組中，將採用數位相機與 CCD 攝影機，甚至
webcam，探討在具環境控制及無環境控制時，影像資料擷取的問題。當然擷取環境變化必定引申出影
像前處理時的一些問題，本研究提出一些較佳演算法來解決。在特徵萃取模組中，掌形部分我們採用
包括：一般幾何特徵、統計不變矩、固有矩、霍夫轉換、B-樣條曲線等作為特徵；而掌紋部分我們採
用包括：凌波轉換、灰階伴隨矩陣、共生矩陣、主成份分析（PCA）、線性識別分析（LDA）及其 2-D
法等作為特徵。在型樣識別模組中，我們採用最小距離分類器與支撐向量機（SVM）作為分類法則。
本計劃在三年的研究中已發展出一套無環境控制的自動融合掌形與掌紋辨識技術之雛型系統，最
終完成一套雙模式身份確認系統，本計劃以三組不同的資料庫對系統進行測試，獲得令人滿意的結果。
同時並建置一套掌形與掌紋的影像資料庫提供相關研究使用。
關鍵詞：生物測定學、生物辨識系統、個人身份確認、影像處理、電腦視覺、影像分析、影像分割、
型樣識別、掌型、掌紋、凌波轉換、主成份分析、線性識別分析、灰階伴隨矩陣、共生矩陣、霍夫轉
換、B-樣條曲線、統計不變矩、固有矩、支撐向量機。
1第一章
緒論
由於近十年間，人們對於安全問題的重視，使得以生物辨識為基礎之身份辨識技術的重要性迅速
提升。而在多種生物辨識技術中，本計劃將深入探討以掌紋與掌形特徵為基礎的身份辨識系統，自行
建立一套手掌影像資料庫，並實作一套具有良好辨識率的身份辨識系統。
目前掌形辨識大都採用固定機架，且有環境控制，故應用範圍有限。因此本計畫最重要的研究目
的是要打破上述限制因素，使此技術應用上更彈性、更自由、更廣泛。本三年期研究計畫將針對一般
非高度安全性需求之商業應用，如門禁管制系統、可攜帶行動型設備（電腦、手機、PDA 等）之使用
者簽入（log in）系統等，以融合掌形與掌紋特徵為基礎，設計一簡易、低成本、使用者友善、無環境
控制的生物辨識技術，以製作一套身份確認系統。
本計畫的第一年度將先建構辨識系統的雛形，並先以門禁系統為基礎，在我們所控制的環境之下
將其完整呈現出辨識系統初步的原型，系統架構包含四個模組：影像擷取、前處理、特徵萃取與分類
辨識模組。本年度已初步完成建立掌紋掌形辨識系統雛形，並同步進行三項研究。計畫的第二年度則
是將原本設計的控制環境放寬一些控制條件，例如：原始建構的辨識系統是建立在黑箱中，且在擷取
手掌影像時有手部支撐架來固定手掌與相機之間的距離與位置，因此在第二年度將此二個限制條件拿
掉，並將擷取設備換為 CCD 數位攝影機，而這些條件的改變則會使所擷取出的手掌影像對後續影像的
處理會造成一些影響，所以必須針對影像前處理的方法及特徵萃取的方法這二方面來進行改善。第三
年度的研究中，除沿用原先的數位相機與 CCD 數位攝影機外，同時將 webcam 考慮進來，並將所有的
控制條件拿掉，也就是說在ㄧ般光源下或自然光源下擷取手掌影像，在此將會遭遇更多的問題，並探
討是否需外加光源來提升手掌影像的品質，所以在此將針對影像前處理做更進一步的研究，並在針對
最後的分類辨識時尋找適合的分類器來改善辨識系統的效能。
3辨識率；2000 年，R. Sanchez-Reillo 與 C. Sanchez-Avila [2][3]，同樣，以 CCD 擷取設備，擷取影像，
再利用高斯混合模型和自行定義的 25 個手指寬度的特徵值，歐氏距離來辨識其相似程度，得到不錯的
結果；2004 年，Y. L. M 與 W. T. Hewitt [6]等人利用 CCD 作為擷取設備，無固定支架將手掌置於平台
上，擷取所需的掌形影像，以 B 樣條曲線作為特徵，計算手指曲線之間的誤差進而達到辨識的效果；
2005 年，Xiong, Toh, Yau 與 Jiang [7]等人探討生物辨識系統中可變形之掌形辨識的問題，以及無任何
裝置來固定手掌位置，這也減少掌形與手指變形的情形發生，以及採用橢圓的模型來描述手指特徵，
在辨識時使用歐式距離來辨識多個明確的手指；2006 年，G. Amayeh [19]等人利用 CCD 擷取手掌影像
後，使用 Zernike moment 與主成份分析計算出 30 個特徵值，經過歐式距離比對，也得到很好的辨識率。
2.4研究方法
2.4.1研究一
1. 影像擷取模組
在影像擷取模組中，如圖 1 所示，採用 Sony DSC-F717 數位相機，在一個可控的環境下來擷取手
掌影像，並利用 2 支固定光源的燈管分別從上面及下面集中照射在手掌上，且不使用閃光燈，來減少
其它外在光源的影響，而利用手部支撐架來固定手掌及擷取設備之間的距離。資料庫包含 100 位自願
者，總共 600 張手掌影像。
圖 1 手掌影像擷取單元硬體機構圖
2. 前處理模組與特徵萃取模組
A. 前處理模組
在前處理模組中，將影像擷取模組所擷取到之手掌影像，在此模組中將分別對掌形及掌紋影像進
行處理，其流程圖（圖 2）及步驟如下：
步驟1. 轉換影像檔案格式
步驟2. 彩色影像轉換至灰階影像
步驟3. 灰階影像轉換至二值化影像
步驟4. 邊緣影像偵測
步驟5. ROI 參考點的偵測
步驟6. ROI 區域的定位、切割
步驟7. 影像強化
步驟8. 在第 4 步驟時可以取得整張掌形邊緣輪廓的影像，再透過形態學的方法來強化掌形影像。
步驟9. 在掌紋影像前處理中，於第 5 步驟時利用手腕的中點來找出 5 個指尖點，再找出食指與
中指和中指與無名指間的 2 個谷點，以此來找出 7 個參考點，在第 6 步驟時透過幾何的
5複製
原始影像
DWT/QSW
二次樣條
小波轉換
離散小波轉換
H
V D HV
梯度方向之
角度計算
梯度方向之
角度計算
格雷碼編碼 格雷碼編碼
分類辨識模組
特徵萃取模組
X 方向Y 方向
圖 3 掌紋特徵萃取模組流程圖
2.4.2研究二
第二項研究主要的目的是利用霍夫轉換來萃取出掌紋主軸線的特徵，然後以歐氏距離來進行比對。
A. 前處理模組
這部分與研究一前處理的步驟 1 至 4 相同，主要的差異在於：
i. 找出中指長度，以中指長度的 0.7 倍作為 ROI 的邊長。接下來，根據 V2 和 V4 與水平軸的夾角
來作為旋轉的依據如圖 4(a)，然後以 V2 和 V4 的中點向下延伸 0.2 倍中指長，以此來得到 ROI
的參考點。最後，我們以這個參考點來定義出 ROI，即可切割出掌紋主軸線影像如圖 4 (b)(c)。
ii. 我們在取掌紋主軸線特徵之前，將優先對掌紋的主軸線（ROI 影像）做強化的處理。而整個強
化的過程是先對 ROI 影像做γ、k 影像與最大濾波器的處理，再對影像進行二值化、去除雜訊及
骨架化來取得主軸線的二值影像。
1V
2V 3V
4V1F
2F
3F
4F
5F
(a) (b) (c)
圖 4 掌紋定位 (a) 計算旋轉角度 (b) ROI 定位 (c) 掌紋主軸線 ROI 影像
B. 特徵萃取
針對主軸線的二值影像施以霍夫轉換來抽取特徵。首先，將二值影像做等分切割成不重疊的區塊，
如圖 7 所示為 2×2 的分割區塊。接著對每一個區塊進行霍夫轉換以萃取出掌紋主軸線的三個特徵(角
度，長度與截距)。最後，把所萃取的特徵以歐氏距離進行比對。
72.5實驗結果
A. 研究一
以下則為不同尺度下離散小波轉換與二次樣條小波轉換的影像、錯誤接受率（FAR）與錯誤拒絕
率（FRR）性能曲線圖，如圖4及圖5所示。由表1可得知，比較等錯誤率（EER）值，QSW在尺度為3
時有最佳的結果。在高安全度的情形下（FAR = 0%）時，QSW在尺度為3時仍有最佳的結果。
(a) (b) (c)
圖8 離散小波轉換，小波尺度 (a) 1 (b) 2 (c) 3
B. 研究二
在特徵萃取過程中，對二值影像分別以五種不同分割區塊數量來進行特徵萃取，並且和選取特徵
數目多寡進行交叉實驗。表2為實驗結果的彙整。在分割區塊數量的實驗中，當分割區塊數量為8×8時，
具最低的EER值（EER=3.55%）。
(a) (b) (c)
圖9 二次樣條小波轉換，小波尺度 (a) 1 (b) 2 (c) 3
C. 研究三
在此將做兩個不同的實驗，分別為單一特徵與特徵結合來進行辨識。單一特徵辨識包括控制點、
指寬和曲率分等結構特徵別進行辨識。特徵融合包含以控制點結合曲率、指寬結合曲率、指寬結合控
制點與結合所有特徵等方式來進行辨識，由表3 可得知，使用指寬結合控制點有最佳的辨識結果。
表1 QSW與DWT特徵萃取方式之辨識率比較表
Mode
Feature extraction
module
RA (%) AA (%) AF (%) RF (%)
EER
DWT
L1 7.5 92.5 7.5 92.5
L2 5.0 95.0 5.0 95.0
L3 8.8 91.2 8.8 91.2
QSW
L1 5.8 94.2 5.8 94.2
L2 3.3 96.7 3.3 96.7
9質必定劣於研究一的手掌影像，所以在前處理時，必須運用較多影像處理的技術來得到較佳的影像，
其中包括雜訊的濾除及手掌位置定位，以及分割ROI的方法也必須有所改變，因此在研究二中ROI分割
方法上也進行改善，首先將手掌影像進行旋轉，進而取出ROI並且將ROI正規化至相同大小，並在特徵
萃取模組中透過霍夫轉換來獲得其結構特徵；我們於研究三中提出利用B樣條曲線擬合手指形狀，以及
其所萃取出的特徵較不會受到不同影像大小而有所影響。
圖10 影像擷取環境
由研究一中可知其缺點，可利用研究二及研究三中前處理改善的方式，來改善其不足的地方，進
而提高系統的辨識效能。由表2可得知，二值影像分割區塊數目越多則EER值應該會越低。但是當區塊
數目為16×16時，在各種特徵選擇的情況下，反而不如分割成8×8個區塊的辨識率。這是因為分割的區
塊數目太多，所偵測到的資訊太多，而使得影像中不可避免的雜訊也被當成特徵，而導致辨識錯誤率
提高。從各種特徵選擇的實驗結果得知選取長度作為特徵的EER值最低，但是其他特徵和多個特徵的
辨識效果都不甚理想，尤其是以角度做特徵的辨識效果最差。EER值高的原因在於選擇角度做特徵時，
會受到拍攝手掌影像的角度所影響；而且選擇多個特徵進行辨識也會受到角度因素的干擾，使得整體
便是變差。因此，我們建議選擇分割區塊數目為8×8及長度特徵會得到最佳的辨識效果。研究二中使用
掌紋特徵來進行辨識，若與研究三的掌形辨識進行融合，可望將會提高辨識的效率。
參考文獻
[1] A. K. Jain and N. Duta, “Deformable matching of hand shapes for user verification,” ICIP 99 Image
Processing, 1999.
[2] R. Sanchez-Reillo, C. Sanchez-Avila and A. Gonzalez-Marcos, “Biometric identification through hand 
geometry measurements,” IEEE Trans. on Pattern Analysis and Machine Intelligence, vol. 22, No. 10,
pp. 1168-1171, Oct 2000.
[3] R. Sanchez-Reilo, “Hand geometry patern recognition through gaussian mixture modeling,”Pattern
Recognition, vol. 2, pp. 937-940, 2000.
[4] G. Amayeh, G. Bebis, A. Erol and M. Nicolescu, “Peg-free hand shape verification using high order
zerhike moment,” IEEE Conf. on computer Vision and Pattern Recognition Workshop, pp. 40-40, 2006.
[5] J. Canny, “A computational approach to edge detection,” IEEE Trans. on Pattern Analysis. and Machine
Intelligence., vol. 8, No. 6, pp. 679-698, 1986.
[6] Y. L. Ma, F. Polick and W. T. Hewit, “Using B-spline curves for hand recognition,” Proc. of IEEE,
International Conference on Pattern Recognition (ICPR), vol. 3, pp. 274-277, 2004.
[7] W. Xiong, K. A. Toh, W. Y. Yau and X. Jiang, “Model-guided deformable hand shape recognition
11
blood vessels from red-free and fluorescein retinal images,”Proceedings of International Medical
Image Analysis, vol. 11, no. 1, pp. 47-61, 2007.
[30] A. K. Jain and N. Duta, “Deformable matching of hand shapes for user verification,” Proceedings of
International Conference on Image Processing, 1999.
[31] R. Sanchez-Reillo, C. Sanchez-Avila and A. Gonzalez-Marcos, “Biometric identification through hand 
geometry measurements,” IEEE Trans. on Pattern Analysis and Machine Intelligence, vol. 22, pp.
1168-1171, 2000.
[32] R. Sanchez-Reilo, “Hand geometry pattern recognition through Gaussian mixture modeling,” Pattern
Recognition, vol. 2, pp. 937-940, 2000.
[33] J. Canny, “A computational approach to edge detection,” IEEE Trans. on Pattern Analysis and Machine
Intelligence, vol. 8, No. 6, pp. 679-698, 1986.
13
特徵向量對臉部影像進行降維的動作。(2D)2-LDA 於 2006 年，S. Noushath 等人為了改善 2D-LDA 所產
生的龐大特徵矩陣[13]，於是就導入(2D)2-PCA 的觀念，利用影像的行與列方向求出類別間散佈矩陣及
類別內散佈矩陣最佳化特徵矩陣，而這種投影方式就如同(2D)2-PCA 之概念。
Isomap 演算法於 2000 年，由 J. B. Tenenbaum 等人所提出[16]，將原始高維度的資料空間中是為圖
形（graph），若彼此是鄰居就以 edge 來進行連結，接下來再計算每個頂點之間的最短路徑，最後再透
過多元尺度法（Multidimensional scaling, MDS）對其作非線性的映射，最後將會得到一較低維度的非
線性流形（Non-linear manifold），此非線性流形將可用來表示原始高維度的資料空間。
3.4研究方法
3.4.1研究一
1. 影像擷取模組
在影像擷取模組中，採用 Sony DSC-F717 數位相機，在一個不完全可控的環境下來擷取手掌影像，
並利用 2 支固定光源的燈管分別從上面及下面集中照射在手掌上，且不使用閃光燈，手掌與擷取設備
之間的距離固定為 30cm，影像擷取環境如圖 11 所示。
圖 11 影像擷取環境
2. 前處理模組與特徵萃取模組
A. 前處理模組
在前處理模組中，將影像擷取模組所擷取到之手掌影像，在此模組中將對掌紋影像進行處理，其
流程圖（如圖 12 所示）及步驟如下：
步驟1. 轉換影像檔案格式
步驟2. 彩色影像轉換至灰階影像
步驟3. 灰階影像轉換至二值化影像
步驟4. 邊緣影像偵測
步驟5. ROI 參考點的偵測
步驟6. ROI 區域的定位、切割
步驟7. 影像強化
在第 3 步驟，使用Otsu’s method決定臨界值方法選擇較佳的臨界值，將灰階影像轉換成二值化影
像。在上年度則是使用固定的臨界值的方式將灰階影像轉換至二值影像，而由於影像受到外在光源影
響的關係，每張影像灰階的變化勢必不同，為了取得較佳的二值化影像，固定臨界值的方法並不適用，
所以在此則透過Otsu’s method決定臨界值方法，來決定每張影像由灰階影像轉二值化影像的臨界值。
在第 5 步驟將整張掌形邊緣輪廓的影像，透過形態學的方法來強化掌形影像，並利用放射狀距離
15
圖 14 掌紋特徵萃取模組流程圖
3.4.2研究二
第二項研究主要的目的是利用(2D)2-PCA 與(2D)2-LDA 萃取手指的特徵，最後以歐氏距離來進行比
對。以下為研究的基本流程：
A. 前處理模組
這部分與研究一前處理的步驟大致相同，主要的差異在於：
i. 為了精確的找出指尖點，在此對掌形邊緣影像透過骨架化的方法求得指尖，如圖 15（a）和（b）
所示。再透過其連通成分找出谷點，如圖 15（c）所示。隨後利用指尖及谷點切割出手指並加以
旋轉成水平方向，如圖 15（d）和（e）所示。我們在取手指特徵之前，會重新調整每根手指在
影像中的位置。作此步驟主要原因為，手指影像經旋轉後並非每隻手指都會在相同的區域中，
在這種情況之下無法完全萃取出手指的特徵。因此，我們使用以下程序來解決此問題。首先利
用距離轉換（distance transform）的方法找出手指的中心點（如圖 13（a）所示）再以中心點為
基準找出手指水平（左右）與垂直（上下）四個邊緣點 (如圖 13（b）所示)。
(a) (b) (c)
17
(a) (b)
圖 17 資料庫掌型樣本 (a) Database 1 (b) Database 2
Isomap 演算法主要目的為，使用一個低維的 nonlinear manifold，來描述原始高維的資料。因此，
我們使用 Isomap 演算法對掌形影像做非線性映射的動作，期望透過此方法能在另一個空間中得到一個
正規化手掌影像。此正規化動作是讓每個人每隻手指位置，都在固定的地方。
i. 手掌影像在解析度上的不同：於此Database 1的解析度分別為 85×64，64×48及 51×38。而Database
2 的解析度分別為 77×102，64×85 及 55×73。此兩個 Database 下使用三種不同解析度來分析，
在此 k-nearest neighbor 則固定為 8，實驗結果如圖 18（a）（b）（c）與圖 19（a）（b）（c）所示。
(a) (b) (c)
圖 18 手掌影像在解析度上的不同-Database 1：(a) 85×64 (b) 64×48 (c) 51×38.
(a) (b) (c)
圖 19 手掌影像在解析度上的不同-Database 2：(a) 77×102 (b) 64×85 (c) 55×73.
ii. Isomap 演算法中選擇不同的 k-nearest neighbor 下的變化：於此 Database 1 的解析度分別為
85×64，64×48 及 51×38。而 Database 2 的解析度分別為 77×102，64×85 及 55×73。此兩個 Database
下使用三種不同解析度來分析，在此 k-nearest neighbor 則固定為 8，實驗結果如圖 20（a）（b）
（c）與圖 21（a）（b）（c）所示。
19
(a) (c) (e)
(b) (d) (f)
圖 23 NGLDM 結合 3D-GLCM（三維統計指標）距離分佈圖
表 4 不同特徵萃取方法之辨識率辨識率比較表
模式 特徵萃取方法
特徵碼
長度
真實拒絕
RA（%）
真實接受
AA（%）
仿冒接受
AF（%）
仿冒拒絕
RF（%）
EER
NGLDM+3D-GLCM
（投影方式）
64 bytes 2.0000 98.0000 2.0000 98.0000
3D-GLCM
（投影方式）
64 bytes 4.3333 95.6667 4.3333 95.6667
NGLDM+3D-GLCM
（三維統計指標）
64 bytes 8.0277 91.9723 8.0277 91.9723
3D-GLCM
（三維統計指標）
64 bytes 11.0236 88.9764 11.0236 88.9764
NGLDM+2D-GLCM 64bytes 4.1583 95.8417 4.1583 95.8417
2D-GLCM 64 bytes 6.7272 93.2728 6.7272 93.2728
(2) 研究二
在特徵萃取過程中，我們對手指影像分別使用(2D)2-PCA, 2D-PCA, PCA, (2D)2-LDA, 2D-LDA 和
LDA 萃取手指特徵，隨後再將透過 2D-PCA+2D-LDA 及(2D)2-PCA+(2D)2-LDA 對手指影像進行特徵
萃取，再以歐氏距離來進行比對。我們比較以上幾種特徵萃取的方法，來觀察其辨識效果的優劣。其
ROC（Receiver Operating Characteristic）曲線圖，如圖 8 所示。由表 2 可知(2D)2-PCA+(2D)2-LDA 在特
徵向量長度為 105 且變異比例為 95 時，有最佳的辨識效能，其 EER 值為 2.29 %。
21
特徵名稱
特徵碼長
bytes
門檻值
Threshold
錯誤拒絕
FR(％)
正確接受
CA(％)
正確拒絕
CR(％)
錯誤接收
FA(％)
控制點 128 0.0131 4.45 95.55 95.55 4.45
指寬 96 0.0178 3.16 96.84 96.84 3.16
曲率 32 0.0102 14.3 85.7 85.7 14.3
控制點及曲率 160 0.0128 7.74 92.26 92.26 7.74
指寬及曲率 128 0.0124 8.37 91.63 91.63 8.37
指寬及控制點 224 0.0222 2.16 97.84 97.84 2.16
所有特徵 256 0.0152 4.91 95.09 95.09 4.91
3.6討論與建議
於本年度中，研究一的手掌影像，在前處理時，需透過較多影像處理的技術來獲得較佳品質的影
像，除了手掌位置定位及掌紋影像 ROI 的取得外，必須在對其影像進行影像增強的處理，在特徵萃取
模組中使用 NGLDM+3D-GLCM（投影方式）來獲得其統計上的特徵。在研究二中，使用(2D)2-PCA 與
(2D)2-LDA 方法萃取手指影像代數的特徵；我們於研究三中提出針對影像前處理方面進行研究，期望
透過 Isomap 演算法來對手掌影像進行正規化。
研究一與上一年度掌紋辨識系統進行比較，本年度的掌紋辨識系統辨識率為 98%，若與上一年度
使用霍夫轉換萃取掌紋特徵的掌紋辨識系統，其辨識率為 96.45%，有顯著的改善。而研究二的掌形辨
識系統其辨識率為 97.71%，若與上一年度使用 B-樣條曲線（B-Spline curves）來擬合掌形作為特徵的
辨識系統[21]，其辨識率為 97.84%，雖辨識率略微降低，但整體辨識系統執行的時間為 5.23sec 優於使
用 B-樣條曲線為特徵的掌形辨識系統。
由研究三中可發現，影像解析度的大小確實會對映射到低維的影像空間中會有所影響。但影響最
大的主要原因為影像中，每個資料點利用歐基里德距離的方法來計算與全部的資料點之間的距離，因
此，當使用 k-nearest neighbor 方法來找鄰近點，並不適用在掌形影像中，而此種方式在圖形結構中是
屬於無向圖形。改善的方法，可朝向將掌形影像視為有向圖形，來改善在低維影像空間中，手指之間
edge 有相連的情形。
參考文獻
[1] R. M. Haralick, K. Shanmugam and L. Dinstein, “Textural features for image classification,” IEEE
Trans. on Systems, Man and Cybernetics, vol. 3, No. 6, pp. 610-621, Apr. 1973.
[2] S. E. El-Khamy. O. A. Abdel-Alim, and M. M. Sal, “Neural network face recognition using statistical 
feature and skin texture parameters,” IEEE Proc. Of the Eighteenth National Publication, vol. 1, pp.
233-240, Mar. 2001.
[3] M. A. Dabbah, W. L. Woo and S. S. Dlay, “Secure authentication for face recognition,” Proc. of IEEE
Symposium on Computational Intelligence in Image and Signal Processing (CIISP), pp. 121-126, Apr.
2007.
[4] M. Yazdi et al., “Novel ridge orientation based approach for fingerprint identification using 
co-occurence matrix,” Proc. of World Academy of Science, Engineering and Technology (WASET), col.
26, pp371-375, Dec. 2007.
[5] A. Busch et al., “Texture for script identification,” IEEE Trans. on Pattern Analysis and Machine
23
第四章
第三年研究計畫成果
4.1前言
生物辨識是指辨別出個人生理或行為上的特徵確定其身分，而好的生物特徵具有普遍性、獨特性
及持久性的特性。本計畫在探討以掌型特徵為基礎的辨識系統，辨識系統架構主要包含三個模組：影
像前處理、特徵萃取與分類辨識模組。在掌型辨識的發展上，多數的輸入圖像為單純背景，或提供一
個擷取影像的平台，而本計畫系統驗證則是針對非控制環境下的掌型圖像擷取，並執行影像特徵萃取，
得到我們所需要的特徵值做為分類辨識比對之用。這裡我們選用了特徵矩（Eigenmoment）做為特徵萃
取的方法，從掌型影像中計算出代表性的特徵值和特徵向量，作為辨識所需的特徵碼。採用支持向量
機（Support vector machine）來做比對的動作，並以 Moment，如 Zernike moment 及 Hu moment 做辨識
率比較。
掌型生物特徵辨識系統測試於三組資料庫，影像前處理模組結合膚色偵測及 canny edge 其偵測率
可達 83.63%。在單純背景中 Eigenmoment 的辨識率能達到 97%，在較為複雜的背景環境下也能達到
85%的正確率。
4.2研究目的
掌型特徵辨識[1]-[7]是利用每個人的手掌形狀彼此不同的現象，來進行辨識。它利用 CCD 來擷取
手掌的形狀和特徵，有的系統甚至簡化至僅記錄中指和食指。由於僅記錄部份量測數據，因此樣本檔
案相當小，大都低於 100 bytes[15]-[25]。掌型特徵辨識技術由於簡單且可靠性高，因此接受度高，但
是受限需量測掌型，儀器體積無法縮小，不適合用在小型移動資訊家電上。
本計畫的研究目標即為在使用低成本且隨手可得的影像擷取儀器如視訊攝影機建構出一套辨識系
統。由本實驗室所拍攝建立的掌型影像資料庫進行實驗。主要流程圖如圖 25，分為四個步驟：第一步，
手掌影像擷取，使用相機及視訊攝影機拍攝手掌圖像。第二步，影像前處理，從拍攝到的手掌影像中
將掌型擷取出來，並做影像強化。第三步，對第二步驟所獲得的影像做特徵萃取，以取得代表每個人
的特徵碼。最後一步則將第三步驟所得到的特徵碼來進行辨識。
圖 25 系統架構圖
4.3文獻探討
(1) 掌型擷取設備
25
[22]等人則取了手指和手掌的長、寬等 30 個幾何特徵，並以柴比雪夫多項式（Chebyshev polynomial）
來分類。2003 年 C. Oden [23]計算包含幾何特徵及手指的固有多項式不變量等 16 個值作為比對特徵，
以馬式距離來分類，辨識率可高達 99%。2004 年 N. Pavesi 等人[24]仍舊找了 24 個手指的長寬和手掌
的厚度等幾何特徵來做辨識，分類器則用正規化的歐式距離來做比對，FAR 達到 0.01，FRR 則為 0.001。
同年，D. M. Sun 和 Z. D. Qiu [25]以手掌邊緣輪廓的曲率半徑作為特徵值，並以隱藏馬可夫模型（Hidden
Markov model, HMM）來做分類辨識，實驗後辨識率也可高達 96%左右。
2005 年 R. N. J. Veldhuis [26]取手掌輪廓座標及角度當特徵，並在高斯模型假設下找最大近似值來
分類，其 EER 約在 0.00001~0.002 之間。D. L. Woodard [27]等人將基於三維的表面曲率作形狀指數，
並記錄起來作為特徵，用正規化的相關係數概念作分類，結果所得到的 EER 為 0.09。2006 年 E.
Konukoglu [28]除了幾何特徵外，還用獨立成分分析（Independent component analysis, ICA）來作為特徵
萃取的方法，最後再用改良豪斯多夫距離（Modified Hausdorff distance）和餘弦距離（Cosine distance）
來做分類器，而 EER 的結果為 0.01~0.02。同年，G. Amayeh [29]結合 Zernike 矩和主成分分析（Principal
component analysis, PCA）來做特徵萃取，並以歐式距離作分類，實驗結果也還不錯，FAR 為 0.01，FRR
為 0.02。2008 年 A. Morales [30]則只從三隻手指的寬來記錄 40 個特徵值，再經過支持向量機（Support
vector machine, SVM）計算特徵向量所形成的超平面間的距離來分類，EER 值差不多為 0.034。Juan
Manuel Ramirez-Cortes [31]等人則是以光譜模型來取出 25 個特徵，並對幾種分類辨識方法做實驗比
較，其中歐式距離的辨識率約為 97%，類神經網路（Neural network, NN）辨識率為 98%，SVM 則辨
識率最高，可達到 99%。
4.4研究方法
本計畫研究方向著重在以下幾個方面，首先是使用簡單的影像擷取設備，在非控制的自然環境下
得到掌型影像，其次，針對擷取掌型時不固定的情況，使用對於旋轉、位移及比例變化有不變性的矩
來做特徵萃取，最後使用支持向量分類器作為比對的工具，最後在對整個辨識系統做分析與統整。
4.4.1研究一
1. 基於 Eigenmoment之掌型辨識系統的基本架構
圖 26 為掌型辨識系統的基本架構，本實驗系統主要分為三大部分，分別是影像前處理模組、特徵
萃取模組和分類辨識模組，以下依序介紹三個模組：
圖 26 掌型辨識系統流程圖
27
圖 27 掌型偵測系統流程圖
i. 掌型邊緣檢出：主要採用Canny Edge的邊緣檢測方式，雖然較容易得到雜訊，但是可以保持邊
緣的連續性。
ii. 掌型色彩分離：這裏使用的是RGB色彩空間，透過設定RGB的條件及關係，將感興趣的膚色範
圍訂定出來。
iii. 最大連通成份：由於外在環境的影響，可能會有一些並非手掌的部份也被偵測是為膚色，而通
常在做掌型辨識時所擷取的影像，手掌大多佔了圖片最大範圍，因此我們便可透過最大連通成
份的尋找，來偵測出手掌。
iv. 強化掌型可分離性：背景與手掌顏色相近」這個問題。
以下說明強化掌型可分離性的實際作法，在非控制的環境下所拍攝的手掌影像，會出現與背景相
似的情況，如圖 28（a）。假若我們直接執行膚色偵測及最大連通成份選取，會出現圖 28（b）與膚色
相近的範圍也圈選，也就是黃色線部份框選了不必要的部份。
(a) (b)
(c) (d)
圖 28 膚色偵測範例
從圖 28（b）可以發現，最主要的原因在於背景與手掌在色彩分類上被判定是同一類，進而造成
在選取最大連通成份時出了錯，為了解決這個問題，最直接的想法便是將手掌區域與背景劃分開來，
使手掌與背景有明顯的分界。於是我們便將原圖與經過 Canny 邊緣偵測過後的圖結合起來，強化原圖
的邊緣特性，如圖 29 所示。
29
對於一張 n×n 的影像，將所有像素串接成一列長度為 n2×1 的特徵向量，傳統主成份分析需要計算
n2×n2 共變異矩陣的特徵值與特徵向量，計算量實在是相當龐大，於是我們先使用幾何矩（Geometric
moment）進行一次降低維度的動作，也就是將原本的 Signal space 轉換到 Moment space，舉例來說我
們對原始影像取 7 階的幾何矩，那麼原始影像的維度將會從 n2 降到 36 維，這個步驟簡化了主成份分
析時所要計算的共變異矩陣特徵值與特徵向量的複雜度，但是因為幾何矩的核心函數 xpyq 並非正交，
因此接下來使用主成份分析來改善這個問題。
幾何矩所形成的特徵向量經由主成份分析能找到一個正交的基底 W，原本在 Moment space 的資料
便能透過 W 投影到一個正交空間，解決了幾何矩核心函數 xpyq 並非正交的問題，我們知道經過主成份
分析運算後最大的特徵值所對應的特徵向量即具有最大的投影平方和，對投影之前的資料具有最大的
解釋比例，也可以說，越小的特徵值（趨近於零）對原資料的解釋比例就越低，我們可以將這些趨近
於零的特徵值捨棄來改善 Moment space 中資訊多餘的問題。以下扼要敘述整個應用過程：
輸入一張灰階影像 f(x,y)，為了轉換到矩空間，套入已正規化的 GM 來取得矩
  
x y
qpqp
pq yxfyyxxyyxxM ),()]cos()()sin()([)]sin()()cos()[(
2  (1)
其中 ),(),(
00
01
00
10
m
m
m
m
yx  為影像 f(x,y)的質心，且
0000 mm
S (2)
0220
111 2tan
2
1
mm
m

  (3)
此處 Sm00 為根據圖像性質的一個比例因子（換算係數）， Sm00 在像素為 1 和 0 的二值圖像中通常設為
1（m00 通常很小），但若當圖像像素值是在 0 到 255 的灰階時，較適合設高一點的值，這樣高階矩的值
才不會因為 ap+q+2 被縮小到一個無意義的值。在本計畫中，則使用與 Yap 所訂定的相同的值，也就是令
Sm00 =100。
至此我們已經獲得了所需要的矩並轉換到矩空間，接著便將所得到的矩拿來做 PCA 運算。PCA 最
後還有一項重點，也就是選取前幾大特徵值來代表整張圖像的資訊，達到降維的作用，而我們要如何
知道該選取多少個特徵值，這時就靠比例變異方法
pq
qR







21
21
(4)
其中 p ,,, 21  為由大到小排序後的特徵值，若只取最大的 q 個特徵值代替原有的 p 個特徵值，
則這q個特徵值解釋的變異比例就為R ，一般以能解釋原有變數的比例變異達 70%以上為原則。
4.5實驗結果
計畫掌型辨識系統測試於國立暨南大學視覺資訊處理暨信息通訊實驗室（Visual Information
Processing and Cyber Communications Lab.）所擷取掌型影像作為資料庫進行實驗，分類辨識所需
SVM[36]使用台灣大學所開發的 Libsvm[37]（A library for support vector machines），核心函數使用 RBF
（Radial basis function）函數。
31
0
0.2
0.4
0.6
0.8
1
1 3 5 7 9 11 13 15 17 19 21 23 25 27
前q大特徵
變
異
比
例
圖 33 變異比例
表 10 Eigenmoment 與 Zernike moment 的辨識率比較
Database Zernike Eigen
單純背景 95.37% 97.222%
複雜背景 I 85.915% 87.324%
複雜背景Ⅱ 80.435% 85.87%
最後，不同環境下的所有方法之辨識率比較如圖 34 所示，可以明顯看出 Eigenmoment 在各種環境
下，其效能表現都優於其他種 Moments。
圖 34 辨識率比較圖
4.6討論與建議
本研究計畫建構一個掌型辨識系統，主要的研究重點在於掌型偵測和特徵萃取上，因此我們分別
對其實驗結果做個結論。首先在影像前處理部份，也就是掌型偵測，我們用了 RGB 的色彩空間來做膚
色的分類，並以最大連通成份框選出感興趣的區域，但對於一些複雜背景常遇到的問題，解決的能力
還是有很大的進步空間，而透過影像前處理所擷取出來的影像，其好壞對於後續在特徵萃取及分類辨
識上影響都很大。再來是特徵萃取部份，我們使用 Eigenmoment 這個新的特徵萃取方式，並與其他矩
如 Zernike moment 和 Hu moment 來做比較，實驗結果驗證了 Eigenmoment 較好的特徵萃取能力，以
及更好的抗雜訊能力。配合 SVM 能夠得到更佳辨識率表現。整體而言，本計畫最後所建立的掌型辨識
系統跟我們一開始設定的目標相去不遠。
參考文獻
[1] R. P. Miler, “Finger dimension comparison identification system,” U. S. Patent, no. 3576538, 1971.
33
[22] Y. Bulatov, S. Jambawalikar, P. Kumar and S. Sethia, “Hand recognition using geometricclassifiers,” 
DIMACS Workshop on Computational Geometry, pp. 14-15, 2002.
[23] C. Oden, A. Ercil and B. Buke, “Combining implicit polynomials and geometric features for hand 
recognition,”Pattern Recognition Letters, vol. 24, pp. 2145-2152, 2003.
[24] N. Pavesi, S. Ribari and D. Ribari, “Personal authentication using hand-geometry and palmprint features:
the state of the art,” Proc. of Int. Conf. on Pattern Recognition, 2004.
[25] D. M. SUN and Z. D. QIU, “Automated hand shape verification using HMM,” Proc. of Int. Conf. on
Signal Processing, vol. 3, pp. 2274-2277, 2004.
[26] R. N. J. Veldhuis, A. M. Bazen, W. Booij and A. J. Hendrikse, “Hand-geometry recognition based on
contour parameters,”SPIE Biometric Technology for Human Identification II, pp. 344-353, 2005.
[27] D. L. Woodard and P. J. Flynn, “Finger surface as a biometric identifier,” Computer Vision and Image
Understanding, pp. 357-384, 2005.
[28] E. Yoruk, E. Konukoglu, B. Sankur and J. Darbon, “Shape-based hand recognition”,  IEEE Trans. on
Image Processing, vol. 15, pp. 1803-1815, 2006.
[29] G. Amayeh, G. Bebis, A. Erol and M. Nicolescu, “Peg-free hand shape verification using high order
Zernike moments”,Conf. on Computer Vision and Pattern Recognition Workshop, pp. 40-48, 2006.
[30] A. Morales, M. Ferrer, F. Díaz, J. Alonso andC. Travieso, “Contact-free hand biometric system for real
environments,” Conf. on European Signal Processing, 2008.
[31] M. R. C. Juan, G. G. Pilar, S. P. Gabriel and B. L. David, “A feature extraction method based on the
pattern spectrum for hand shape biometry,” Proc. of the World Congress on Engineering and Computer
Science, pp. 22-24,2008.
[32] M. K. Hu., “Visual pattern recognition by moment invariants,” IRE Trans. on Information Theory, vol. 8,
pp. 179-187, 1962.
[33] M. R. Teague, “Image analysis via the general theory of moments,” Journal of the Optical Society of
America, vol. 70, Issue 8, pp. 920-930, 1980.
[34] R. Mukundan and K. R. Ramakrishnan, “Fast computation of legendre and zernike moments,”Proc. of
Int. Conf. on Pattern Recognition, vol. 28, issue 9, pp. 1433-1442,1995.
[35] P. T. Yap and R. Paramesran, “Eigenmoments,” Proc. of Int. Conf. on Pattern Recognition, vol. 40, issue
4, pp. 1234-1244, 2007.
[36] C. J. C. Burges, “A Tutorial on Support Vector Machines for Patern Recognition,”Data Mining and
Knowledge Discovery, vol. 2, pp. 121-167, 1998.
[37] C. C. Chang and C. J. Lin, LIBSVM : a library for support vector machines, 2001.
[38] R. Kjeldsen and J. Kender, “Visual hand gesture recognition for window systemcontrol,”Proc. of Int.
Workshop Automatic Face-and-Gesture-Recognition, pp. 184-188, 1995.
行政院國家科學委員會補助國內專家學者出席
國際學術會議報告 
報 告 人 
姓   名 
 
陳  文  雄 
 
服務機構 
及 職 稱 
國立暨南國際大學  
電機工程學系 
教授 
      時間 
會議 
      地點 
自 99年 07月 13日至 99年 07月 16日 
日本 大阪（Osaka, Japan） 
本會核定 
補助文號 
 
NSC 96-2221-E-260-
016-MY3 
 
會 議 名 稱 
 (中文) 2010年第八屆國際工業資訊學會議 
 
(英文) 2010 8th IEEE International Conference on Industrial Informatics（INDIN2009） 
發表 論文
題目 
 (中文)虹膜辨識之快速非線性正規化演算法 
 
 (英文) Fast Non-Linear Normalization Algorithm for Iris Recognition 
 
一、 前言：IEEE 為國際電機電子工程師學會，INSTICC（Institute for Systems and Technologies of 
Information, Control and Communications）為一贊助科技、控制與通訊研發之國際性科學非營利
組織，此兩大學會所共同支持舉辦 International Conference on Computer Vision Theory and 
Applications（VISAPP2010）為國際間有關電腦視覺相當重要且知名的國際會議，每年舉辦一
次。會議集合了全世界各國電腦視覺領域理論與應用相關之研究學者發表最近一年的研究成果，
今年為第三屆，今年的 VISAPP2010 會議於 2010 年 5 月 17 日至 5 月 21 日共五天在世聞名風光
明媚的法國安傑（Angers, France）舉行。所發表的論文均經嚴格之審查，本人此次投稿發表的
論文是：”Fast Non-linear Normalization Algorithm for Iris Recognition”， 5月時已安排好所有事宜準
備機前往，奈何天不從人願，會議前幾天冰島火山爆發，火山灰災難影響全歐，直至 5 月 15 日幾
經考慮，衡量安全與其他因素忍痛取消行程，緊急通知主辦單位天災因素取得諒解，但已註冊繳
費 595歐元（註冊收據如附件），只好自行負擔。 
但因計劃已有相關經費，再投稿其它會議時間上已晚，為充分且有效使用該項經費，決定找
一會議地點較近且與本人研究領域相關的會議，前往參加雖無論文發表，但可吸引一些國際上的
新研究與新知，因此選擇在日本大阪舉辦的 INDIN2010。8th IEEE International Conference on 
Industrial Informatics（INDIN2010）為 IEEE 工業電子學會與 IEEJ 聯合舉辦的國際工業資訊學
會議。本年共投稿約 259 篇，經審查後共僅接受 180 篇。今年的 INDIN2010 會議於 2010 年 7
月 13 日至 7 月 16 日共五天在日本大阪（Osaka, Japan）舉行。INDIN2010 整個會議包含一場
Welcome address、三場 keynote speeches、三場 Tutorial Sessions、以及 52 場 Oral 
Sessions。keynote speech 的講員分別為來自日本 Yokogawa Electric Corp.的 Mr. Toshiaki 
Shirai，講題為”Measurement and Control Technologies for Sustainable Low Carbon Society”；
來自奧地利 Austrian Research Institute of Technology 的 Dr. Brigitte Bach，講題為” Building 
automation at the beginning of a new era How can we use recent results in innovation research 
to tackle new challenges efficiently?”；來自美國 University of California, Irvine 的 Prof. Kwei-
Jay Lin，講題為 ”A Real-Time Service-Oriented Framework to Support Sustainable Cyber-
Physical Systems”。Tutorial Presentation 的講題為”Green IT technology in Japan”、”Industrial 
Informatics in Smart Power Grids”、 ”From IEC 61131-3 to IEC 61499: Migration vs. 
Harmonization”。論文議程共分為 52場 Oral Sessions。 
 
二、參加會議經過：由於 INDIN2010會議正值暑假期間，故無補課問題。本人於 7月 12日搭乘長榮班
機由桃園出發，於日本當地時間同一天中午左右抵達大阪，隨即 check in於下榻的旅館 Swissotel 
 3 
 
FAST NON-LINEAR NORMALIZATION ALGORITHM FOR 
IRIS RECOGNITION 
  
Wen-Shiung Chen, Jen-Chih Li, Ren-He Jeng 
VIPCCL, Department of Electrical Engineering, National Chi Nan University, Puli, Nantou, Taiwan 
wschen@ncnu.edu.tw , s96323552@ncnu.edu.tw  
Lili Hsieh 
Department of Information Management, Hsiuping Institute of Technology, Dali, Taichung, Taiwan 
lily@mail.hit.edu.tw  
Sheng-Wen Shih 
Department of Computer Science and Information Engineering, National Chi Nan University, Puli, Nantou, Taiwan 
swshih@ncnu.edu.tw  
Keywords: Biometrics, Non-linear Normalization, Law of Cosine. 
Abstract: In biometrics, human iris recognition provides a high-level security. However, the size of eye 
pupil always varies with different illumination, resulting in the iris texture deformation. Thus, 
how to precisely predict the deformation degree of the iris is an important issue. A fast algorithm 
simply using the law of cosine is proposed to make Yuan and Shi’s non-linear normalization 
model used in iris recognition suitable for real-time personal authentication applications. 
1 INTRODUCTION 
In biometric-based automatic identity authentication 
techniques, the iris recognition is one of the most 
reliable methods. Iris texture possesses a lot of 
distinctive information helpful for discriminating 
people's identity. Nowadays the existing iris 
recognition systems have a very good performance 
(J. Daugman, 1993; R. Wildes, 1997; L. Ma et al., 
2003; L. Ma et al., 2004). However, the iris texture 
can be deformed due to variation of pupil size 
resulting from different illumination. How to 
compensate the effect of pupil size variation 
becomes an important issue. In most of the iris 
recognition techniques, a normalization process is 
always performed. 
In general, the human eye pupil's diameter is of 
about 1.5mm ~ 7mm, and always varies with 
different illumination from exterior into eye. The 
human iris is an annular region circumjacent the 
pupil, and having the width of around 12mm. The 
iris is an enormous complex meshwork of pectin ate 
ligament tissue resulting in patterns of almost 
infinite variety. The pupil size varies with different 
illumination, as a result the iris deforms, such as 
contract or expand, even torture, caused by papillary 
variations. The purpose of normalization is to 
facilitate the subsequent processing (e.g., feature 
extraction), and most importantly, to restore 
precisely various degrees of deformation of the iris 
structure in a minimal state of distortion. Among the 
normalization methods, The approach, proposed by 
Daugman (J. Daugman, 1993), is the most popular 
and widely used in many systems, in which iris is 
assumed to be homogenous 'rubber-sheet' model. In 
this approach the annular iris region is linearly 
mapped or transformed into a fix-sized rectangular 
block via the following formulas: 
 
{
 (   )  (   )  ( )     ( )
 (   )  (   )  ( )     ( )
 (1)   
 
where (  ( )   ( ))  and (  ( )   ( ))  are the 
polar coordinates of the inner and outer boundary 
points in the direction  , (   )  is the Cartesian 
   ( )  
 (      )
(   )
                
 
 
Its corresponding point   on the    (   ) can be 
solved by: 
 
{
    
   (     
 )
   (    )
    
  (5)   
 
where 
 
    
   
 ⁄ .  
 
By solving these two simultaneous equations (4) 
and (5), the Cartesian coordinates,    and   , of the 
point   are obtaind. Since it needs to solve two 
equations simultaneously, the computing time must 
be high. In the next section a simple and fast 
approach is then proposed to reduce the computing 
time tremendously. 
Algorithm I: Non-linear Normalization Algorithm. 
for     to     do  
begin 
    Generate eq.(4); 
    Solve eq.(4) by newton’s method; 
    Generate eq.(5); 
    Solve eq.(5) by newton’s method; 
end 
3 FAST ALGORITHM OF NON-
LINEAR NORMALIZATION 
According to the non-linear normalization model 
mentioned above, we realize that the final goal is to 
find out the Cartesian coordinates    and    of the 
sampled point  , indirectly by first knowing the 
coordinates of the virtual point   . If we know the 
length of    between the point   and the pupil 
center  , and the angle   ( )  between     and  -
axis, the coordinates of the point   may be 
determined. It is observed from Figure 1 that the two 
points    and   are colinear, so    and     have the 
same angle   ( ). Obviously, the three points, the 
point   , the pupil center   and the center    of the 
   (    ) , form a triangle       , as shown in 
Figure 2. Since the lengths of three sides of the 
triangle are known, the angle   ( )  can be 
determined according to the law of cosine.  
A’
A
P’O
2o
1o
I’
P
r
refr
R
1r2r
)(ir
)(2 i
1( )i
)(ik
 
Figure 2: Observation. 
Similarly, the three points, the point  , the pupil 
center   and the center    of the    (   ) , form 
another triangle      , as shown in Figure 2. In this 
triangle only    is unknown. According to the law 
of cosine and the law of sine, the length of    may 
be determined from   ( ) which might be obtained 
from       . Trivially, the coordinates,    and   , 
of the sampled point   are computed by 
 
{
     ( )   (  ( ))
     ( )   (  ( ))
 (6)   
 
where 
 
  ( )     
  [
  
  (       ( ))
 
   
 
   (       ( ))
] 
 
 
and 
 
  ( )  (  
    
          (  ( )))
  ⁄
  
 
 
Finally, we adopt the Cartesian coordinates of all 
of the sampled point   on the    (   ) to construct a 
non-linear normalization model directly. The 
detailed procedure is shown in algorithm II. 
Algorithm II: Fast Non-linear Normalization Algorithm. 
for     to     do  
begin 
    Compute   ( ); 
    Compute   ( ); 
         ( )   (  ( )); 
         ( )   (  ( )); 
end 
無研發成果推廣資料 
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
