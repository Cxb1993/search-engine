mechanism and the powerful constraint solving 
capability of the constraint logic programming. This 
test case generator supports a testing platform 
description language so that it can generate test 
cases from the same model for multiple programming 
languages and multiple testing frameworks. 
英文關鍵詞： software testing, model-based testing, test case 
generation, Universal Modeling Language, Object 
Constraint Language, constraint logic programming, 
retargetability. 
 
 2 
中文摘要 
 
要開發高品質的軟體目前仍然非常困難。軟體測試目前依舊是確保軟體品質的主要方法。軟體測
試包含測試案例的產生及測試案例的執行。測試案例的執行目前已經成功的自動化了。雖然過去幾十
年已經開發了許多產生測試案例的技術，但是那些產生測試案例的技術目前仍然用人工的方式操作。
因此軟體測試的成本非常高，通常可以佔到整體軟體開發成本的一半。 
 
這個研究計畫的目標是開發一個可多目標平台的模型式測試案例產生器。這個工具使用通用模型
語言的圖形及物件限制語言來塑造軟體的模型。這個測試案例產生器可以自動產生方法層級單元測
試、類別層級單元測試、及整合測試的測試案例。這個測試案例產生器利用限制邏輯程式的一致化機
制及強大的限制求解能力，提出一個合一的方法來同時產生測試輸入及預期輸出。這個測試案例產生
器支援一個測試平台描述語言，使得它可以根據同一個模型來產生多程式語言及多測試框架的測試案
例。 
 
關鍵詞：軟體測試、模型式測試、測試案例產生、通用模型語言、物件限制語言、限制邏輯程式、
可多目標平台性 
 
 
 4 
I. INTRODUCTION 
According to 2006 CHAOS report of the 
Standish Group, high quality software is still very 
hard to achieve in general [16] . Software testing is 
one of the main activities to assure software quality. 
Software testing consists of test case generation 
and test case execution. Automatic test case 
execution is rather mature. There are several 
popular testing frameworks available that automate 
the execution of test cases. For example, JUnit is a 
testing framework for Java unit testing [3] , and 
CUTE is a test framework for C++ unit testing [6] . 
Both JUnit and CUTE support plug-in in extensible 
development platform Eclipse [13] . 
Automatic test case generation is the most 
difficult task in software testing and is still usually 
performed manually. Manual generation of test 
cases is the main reason to cause the cost of 
software testing usually taking about half of the 
cost of the entire software development process. 
This is also the main reason to hinder the 
achievement of high quality software. 
There are two types of techniques for generating 
test cases: black-box testing (or specification-based 
testing) and white-box testing (or program-based 
testing) [2] . The black-box techniques are based on 
the functional specification of a software system 
and focus on the coverage of the specified external 
behaviors of the software system. The white-box 
techniques are based on the source code and focus 
on the coverage of the internal structure of the 
source code. These two types of techniques are 
complementary. The white-box techniques alone 
may fail to reveal that some portions of the 
specification are missed in the source code. On the 
other hand, the black-box testing techniques alone 
may fail to reveal that some portions of the source 
code are not contained in the specification. We use 
model-based test case generation as a black-box 
testing technique. 
Test case generation and automatic test case 
execution are keys for Test-driven development [2] . 
Most of the software systems were tested right after 
implemented. However, when the test results show 
problems, some of the problems might because of 
defects from fundamental designs. Since the system 
has been implemented, addition resources need to 
involve correcting the major defects. For 
test-driven development, developer should firstly 
create test cases according to the specification and 
the followed up programming activities are to pass 
the test cases. Tests can be executed frequently and 
guide the implementation not to go too far away 
from the specification. 
“Design by contract” is a kind of systematic 
software developing approach for an error free 
software system [9] . The contracts of a software 
system define the functions and behaviors of 
classes in the system and the interactions between 
the system and the users. Once the contract defined 
terms are fulfilled, the software system is 
guaranteed to obey the required specifications. 
Although to define the contracts of software system 
is not a strike forward task. But, it is the most 
preliminary requirement for a correctly designed 
software system. There are three types of 
constraints from design contracts, 1. Invariant: 
stands for all objects of a same class, during their 
entire life cycle, 2. Precondition: conditions must 
be met right before invoking a method, to ensure 
the correctness of call to the function, 3. 
Postcondition: conditions must be met right after a 
function call [10] . 
Unified Modeling Language, UML, is a generic 
standardized modeling language. It can model 
various components and behaviors for a software 
system. Each UML symbols have their definitions 
clearly, thus, it can deliver exact system 
specifications to the developers. Class diagram is 
one of the important graph from UML. It is used to 
define the types and attributes of each class and 
also describes static relationships between classes. 
A class diagram includes name, attributes and 
methods of the class. However, UML is not enough 
to describe some detailed information about the 
class, descriptions in OCL, Object Constraint 
Language, can aid to fulfill the need to design by 
contract. Use OCL can avoid misunderstandings 
that resulted by natural language descriptions. OCL 
is commonly used as an extension to UML. 
This paper generates test cases for both of 
class-level and method-level. We also retarget the 
test cases generation and generate test cases for 
JUnit and CUTE. JUnit is a test framework for Java, 
 6 
   else  
                “Scalene”  
    endif 
   endif 
  endif 
 
 
 The precondition of function category is true 
and that means there are no constraints must be met 
before calling the function. While the postcondition 
of function category, states that the conditions of 
the three edges, e.g., a@pre, b@pre and c@pre 
must be met and return a string that describe the 
type of the triangle. The term a@pre, represents the 
value of a before the function call.  
Test case generator can generate constraint 
diagram from the OCL spec of a function. Figure 3 
is the constraint diagram of the OCL postcondition 
for function category. We select five paths from the 
constraint diagram to meet the requirement of 
all-paths coverage. The associated input and output 
of the five paths are found through ECLiPSe[7] by 
translation the paths from the constraint diagram 
into CLP programs. The in/out sets along the test 
paths resemble platform independent test cases. 
A CLP program contains two predicates: 1, the 
<platformDescription> 
  <testImport> 
  #include "cute.h" 
  #include "ide_listener.h" 
  #include "cute_runner.h" 
  #include "$[classname].h" 
  </testImport> 
  
  <testClass> 
    <classHead> 
        class $[className]Test { 
        public: 
    </classHead> 
 <foreachConstructor> 
     <constructorHead> 
            static void test$[className]$[constructorNo]() { 
     </constructorHead>        
     ...  
 </foreachConstructor>   
    <foreachMethod> 
        <methodHead> 
         static void test$[methodName]$[methodNo] {    
     </methodHead> 
        ... 
    </foreachMethod> 
 ...  
 <testSuite>  
     ... 
 </testSuite> 
 ...  
 </testClass> 
 <testDriver> 
     int main() { 
         $[className]Test::suite(); 
         return 0; 
     } 
 </testDriver> 
</platformDescription> 
List 1, Templates for CUTE test platform 
Figure 3, Constraint diagram for postcondition 
<platformDescription> 
  <testImport> 
    import junit.framework.TestCase; 
    import $[packageName.$[className]; 
  </testImport> 
  
  <testClass> 
    <classHead> 
        public class $[className]Test extends TestCase{ 
    </classHead> 
 <foreachConstructor> 
     <constructorHead> 
            public void test$[className]$[constructorNo]() { 
     </constructorHead>        
     ...  
 </foreachConstructor>   
    <foreachMethod> 
        <methodHead> 
            public void test$[methodName]$[methodNo] {    
     </methodHead> 
        ... 
    </foreachMethod> 
 ...  
 <testSuite>  
     ... 
 </testSuite> 
 ...  
 </testClass> 
 <testDriver> 
 </testDriver> 
</platformDescription> 
% Include constraint solving library 
:- lib(ic). 
testClassNameMethodName(PathNo, OState, Arg, Result, 
NState) :- 
% Constraint on variables 
OState = [Ovar1, …, Ovari], NState = [Nvar1, …, Nvari], 
% Domains of variables 
[Ovar1, …, Ovari] :: value range, 
[Nvar1, …, Nvari] :: value range, 
ClassNameMethodName(PathNo, OState, Arg, Result, 
NState), 
% Solving constraints 
indomain(Ovar1), …, indomain(Ovari), 
indomain(Nvar1), …, indomain(Nvari), 
locate([Ovar1, …, Ovari,Nvar1, …, Nvari], 0.1). 
List 2, CLP program format 
List 3, Templates for JUnit test platform 
 8 
   result = "Coffee is ready. Thank you!" 
   and money = money@pre 
 
Where “pre” is the preconditions that must be 
fulfilled before invoking the function; “post” is the 
postconditions that represent the changes right after 
the function was called. Beside, “money” is the 
variable that represents the value of the class’s 
attribute “money”. It’s value before the function 
call is termed as “money@pre”. 
State diagram [5] describes the behaviors of a 
class during it’s life cycle. The behaviors are 
represented by a set of “states” and “transitions” 
between states. In a state diagram the nodes are 
“states” and edges are “transitions”. The transitions 
between states happened when some events occur 
and the most commonly events are function calls. A 
same event might cause transitions from one state 
to different states. This is because the current status 
of the source states are different. However, one 
event is not always permitted to be executed if it’s 
guarding conditions are not valid.  
Figure 5 is the state diagram of CoffeeMachine 
class. In this diagram, there are three states, e.g., 
Idle, Ready and Cooking. Ten transitions associates 
with 10 events. “Initial” and “Final” nodes are two 
special nodes as starting and ending points of a 
state diagram. The format of a transition is in the 
form of {event}[guard condition]. 
  
Figure 5, State diagram of CoffeeMachine class 
 
Figure 6, Data flow diagram for CoffeeMachine 
State diagram shows the possible interactions 
between methods of a class. A serial of transitions 
resemble potential test scenarios. To systematically 
generate test cases, we need to transform the state 
diagram into analytic flow diagrams and produce 
// path 1 
[<[],[],[0]>,<[1],[],[10]>,<[],[10],[0]>]  
// path 2 
[<[],[],[0]>,<[1],[],[10]>,<[1],[],[20]>,<[],[20],[0]>] 
// path 3 
[<[],[],[0]>,<[1],[],[10]>,<[],[],[0]>,<[],["Coffee is ready. Thank 
you!"],[0]>] 
// path 4 
[<[],[],[0]>,<[1],[],[0]>,<[],[10],[0]>,<[1],[],[10]>,<[],[10],[0]>] 
// path 5 
[<[],[],[0]>,<[1],[],[10]>,<[1],[],[20]>,<[1],[],[30]> ,<[],[30],[0]>] 
// path 6 
[<[],[],[0]>,<[2],[],[20]>,<[],[],[10]>,<[],[ "Coffee is ready. Thank 
you!"],[10]> ,<[],[10],[0]>] 
// path 7 
[<[],[],[0]>,<[1],[],[10]>,<[],[],[0]>,<[],[0],[0]> ,<[],[ "Coffee is 
ready. Thank you!"],[0]>] 
// path 8 
[<[],[],[0]>,<[1],[],[10]>,<[1],[],[20]>,<[],[],[10]> ,<[],[ "Coffee is 
ready. Thank you!"],[10]>, <[],[10],[0]>] 
// path 9 
[<[],[],[0]>,<[2],[],[20]>,<[],[],[10]>,<[],["Coffee is ready. Thank 
you!"],[10]>, <[1],[],[20]>, <[],[20],[0]>]  
// path 10 
[<[],[],[0]>,<[2],[],[20]>,<[],[],[10]>,<[],["Coffee is ready. Thank 
you!"],[]> ,<[],[],[0]>,<[],["Coffee is ready. Thank you!"],[0]>] 
// path 11 
[<[],[],[0]>,<[1],[],[10]>,<[],[],[0]>,<[],["Coffee is ready. Thank 
you!"],[0]> , <[1],[],[10]>, <[],[10],[0]>] 
// path 12 
[<[],[],[0]>,<[1],[],[10]>,<[],[],[0]>,<[1],[],[10]> , <[],["Coffee is 
ready. Thank you!"],[10]>, <[],[10],[0]>] 
// path 13 
[<[],[],[0]>,<[1],[],[10]>,<[],[],[0]>,<[1],[],[10]> ,<[],[10],[0]>,<[],["
Coffee is ready. Thank you!"], [0]>] 
// path 14 
[<[],[],[0]>,<[1],[],[10]>,<[],[],[0]>,<[],[0],[0]> ,<[],[0],[0]>,<[],["Cof
fee is ready. Thank you!"],[0]>] 
// path 15 
[<[],[],[0]>,<[1],[],[10]>,<[],[],[0]>,<[1],[],[10]> ,<[1],[],[20]>,<[],[ "
Coffee is ready. Thank you!"], [20]>,<[],[20],[0]>] 
// path 16 
[<[],[],[0]>,<[1],[],[10]>,<[],[],[0]>,<[],[0],[0]> ,<[1],[],[10]>,<[],[ "C
offee is ready. Thank you!"], [10]>,<[],[10],[0]>] 
List 6, Input/output sets for 16 paths 
 10 
AutoFOCUS [5] [18]  is a tool for modeling 
and analyzing the structure and behavior of 
distributed, reactive, and timed computer-based 
systems. AutoFocus use structural diagram and 
state diagram of UML to describe the interactions 
between components. It also use OCL to generate 
input/output sets automatically [6] [14] [15] . Our 
approaches are most similar to AutoFocus on 
platform independent test case generations. 
Moreover, our system retargets the platform 
independent test cases into popular test platforms 
for different programming languages. 
III. CONCLUSIONS 
The contributions of this paper are: 1. test cases 
can be generated automatically under certain test 
coverage criteria, 2. Both of class-level and 
method-level test cases generation are considered, 
3. Test cases are now retargetable for different test 
platforms. The current implementation demos the 
methods of above concepts. However, there still 
acquire intensively development both on supported 
features and improvements on operational aspects. 
REFERENCE 
[1] K. R. Apt and M. G. Wallace, Constraint 
 Logic Programming Using ECLiPSe, 
Cambridge University Press, 2007. 
[2] B. Bezier, Software Testing Techniques, 2nd 
 Edition, Van Nostrand, 1990. 
[3] K. Beck and E. Gamma, JUnit Cookbook, 
 http://junit.sourceforge.net/, 2011. 
[4] Y. Cheon, A. Cortes, M. Ceberio, and G. T. 
 Leavens, Integrating Random Testing with 
 Constraints for Improved Efficiency and 
 Diversity, Proceedings of the 20th 
International Conference on Software 
Engineering and Knowledge Engineering, 
2008. 
[5] F. Huber, B. Schatz, G. Einert, Consistent 
 Graphical Specification of Distributed 
Systems, Proceedings of the Conference on 
 Industrial Applications and Strengthened 
 Foundations of Formal Methods, 1997, pp. 
 15-19. 
[6] Institute for Software, CUTE User Guide, 
http://cute-test.com/, 2011. 
[7] G. T. Leavens, A. L Baker, and C. Ruby, JML: 
A Notation for Detailed Design, In H. Kilov, B. 
 Rumpe, and I. Simmonds (editors), Behavioral 
 Specifications of Businesses and Systems, 
Kluwer, 1999, pp. 175-188. 
[8] H. Lotzbeyer, A. Pretschner, and Er Pretschner, 
AutoFocus on Constraint Logic Programming, 
Proceedings of (Constraint) Logic 
Programming and Software Engineering, 2000. 
[9] B. Meyer, “Design by Contract,” In Advances 
 in Object-Oriented Software Engineering, eds. 
 D. Mandrioli and B. Meyer, Prentice Hall, 
 1991, pp. 1-50. 
[10] B. Meyer, Eiffel: the Language, Prentice Hall, 
 1991. 
[11] B. Meyer, H. Ciupa, A. Leitner, and L. Liu, 
 Automatic Testing of Object-Oriented 
Software, SOFSEM 2007: Theory and Practice 
 of Computer Science, Springer, 2007, 
 pp.114-129. 
[12] Object Management Group, Object 
Constraint  Language Specification, 
Version 2.0, 2006. 
[13] Object Technology International 
Incorporation, Eclipse Platform Technical 
Overview, 2003. 
[14] A. Pretschner and H. Lotzbeyer, Model 
Based Testing with Constraint Logic 
Programming: First Results and Challenges, 
Proceedings of Second International Workshop 
on Automated Program Analysis, Testing and 
Verification, 2001, pp. 1-9 
[15] A. Pretschner, O. Slotosch, E. Aiglstorfer, 
and  S. Kriebel, Model Based Testing for Real: 
The  Inhouse Card case Study,” International 
 Journal on Software Tools for Technology 
 Transfer, 5(2-3):140-157, March 2004. 
[16] Standish Group, 2006 CHAOS Report, 2007. 
[17] A. Leitner , I. Ciupa, Reconciling Manual 
and Automated Testing: the AutoTest 
Experience, In Proceedings of the 40th Hawaii 
International Conference on System Sciences - 
2007, Software Technology 
[18] F. Hoelzl, M. Spichkova, D. Trachtenherz, 
AutoFocus Tool Chain, Techreport of 
Technische Universitaet Munchen 
國科會補助計畫衍生研發成果推廣資料表
日期:2012/10/31
國科會補助計畫
計畫名稱: 可多目標平台的模型式測試案例產生器
計畫主持人: 林迺衛
計畫編號: 100-2221-E-194-033- 學門領域: 程式語言與軟體工程
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
