2 
因此，如何建立一個合宜的機制，使得每個網路的使用者都能看到適合的內容，已經是
刻不容緩的課題。 
我國自 2005 年 10 月 25 日正式執行網路內容分級制度 [1, 9, 13]，對於這樣的計畫，
入口網站大多保守以對，傾向於要求資訊提供者自律，畢竟網路內容一來無國界之分，
二來網路資訊出版量又多又快，而且根據台灣終止童妓協會發表的兒少上網安全成果報
告，華文成人色情網站將網路位址設在國外者大幅增加，因此，除非全球各國嚴格執行
相當的規範，否則網路資訊很難依過去電影出版的概念來處理 [9]。我們認為實施網站
內容區分級之前，最重要的工作是要能將限制級的網站內容（例如色情、暴力、毒品等）
與其他非限制級的內容做適當的區分，然後再進行其他級別的篩選。同時，我們認為限
制級的網站內容可以透過資訊技術來篩選，其他級別（尤其是輔導級、保護級）多少具
有自由心證，短期內難以透過資訊技術來區分。 
目前許多企業或機關都利用已篩選過的黑名單對限制級內容進行URL Blocking, 例
如教育部主管的 TANet 主要以紀錄與分析使用者之瀏覽足跡來蒐集黑名單，以便採取
「阻擋」策略防止讀取不當資訊，例如國立成功大學計算機中心的不當資訊防治系統
(http://tanet110.ncku.edu.tw/)，分析資料來自包含台大、交大、中興、中山與成大本身等
五個區網中心之 14 台 PROXY 的瀏覽記錄 [2]；還有在中央大學 TANet 桃園地區骨幹也
設置一套PWFS (Pornographic Website Filtering System) [3]以管制使用者對列管色情網站
的存取。有別於 TANet 這種 log-based 方式，我們在已結案的國科會計畫（一個蒐集色
情黑名單的網路內容分級機制之研究， NSC 93-2213-E-155-035）中，先以 Crawler 自
動從 Seed URLs 開始大量蒐集網站，再運用統計推論中的卡方分配 (chi-square) [6]對網
路內容中的文字部分做運算，為每一個網頁計算出一個介於 0 到 1 之間的色情指標值
(Indicator Value, I value )，然後將 I 值範圍分隔成三個間斷(distinct)的區間，分別是色情
(Porn)、未確定(Unsure)與非色情(Non-Porn) [28]。實驗結果顯示，本機制在分類英文網
頁的準確率為 97.56%，分類中文網頁的準確率為 96.44%，不過我們認為上述機制仍有
改善的空間，首先是網頁能判別的語文太少，而且無法自動判別網頁使用的語言；其次
4 
我們可以處理中文網頁。更重要的是，我們可以清楚得追蹤文字 tokens 對色情指標值
的貢獻度，有利於系統訓練與效能調校。  
(b) 圖片分析 
    這個方法對色情圖片做影像處理 [5, 14, 15, 16]，找出圖片中可能和人體皮膚區塊
有關的部份，根據皮膚的統計描繪出輪廓，再經由大批圖片的訓練找到色情圖片的型
樣(pattern)，然後做型樣識別(pattern recognition)判斷是否為色情圖片。以整個網站來
看，則是根據網站中色情圖片的有無多寡，判別是否為色情類別。 
(c) 圖文綜合分析 
     Smith et al. [23] 曾提出一個混合式方法來分辨色情內容，首先該方法偵測有大
量皮膚區塊的圖片，然後分析圖片相關的文字，最後再把兩者的得分整合以去除不想
要的內容，例如銷售內衣的圖文內容或者衛教用的圖文，該研究宣稱色情內容分類的
準確率很高，但並未提出具體數字佐證。 Hammami et al. [17]提出 Web Guard 系統架
構，結合文字內容、圖片內容和 URL 建構出特徵向量(feature vector)，再利用資料探
勘 (data mining)技術將網頁區分為正常網頁 (Normal URLs)和嫌疑網頁 (Suspect 
URLs)，該方法實驗初步結果指出判別的精確度為 95.0%。國內朝陽科技大學陳榮靜
教授亦從事圖文整合判讀色情網頁之研究，目前測試的網頁僅數百個，影像分析準確
率只有 84% [7] 。 
3.  以卡方為基礎的網頁分類 
在去年度的研究中 [28]，我們建立一個以卡方為基礎的網頁分類機制，其系統架構
如圖 1 所示，共分為資料蒐集 (Data Gatherng)、訓練 (Training)、內容分類 (Content 
classification) 三階段， 各階段細節將於以下分別說明。 
6 
料根據字典1 斷詞輸入至資料庫；單位元組語文 (例如英文) 則先去除常用的 stop 
words，再利用字詞間之空白字元做為區隔，並將字詞斷出輸入至資料庫。此外，
英文部分還採用 MI (Mutual Information) 之斷詞法，以斷出片語類之字詞 [29]。以上
語言之斷詞過程皆會將斷出字詞的Term frequency (TF) 和Document frequency (DF) 
一併儲存至資料庫。 
y 步驟 3 : Calculate Inappropriateness Tendency  
利用 TF 以及 DF 等資訊，計算每個字詞之不當傾向値(Tendency)。 
y 步驟 4 : Select Candidate Tokens 
此步驟透過柴比雪夫不等式挑選 outliers 做為 distinctive tokens。 
 
3.3 內容分類 (Content classification) 
給定一個測試網頁，系統會先判定網頁編碼與語言，然後將文字內容斷成一組
tokens，以及找出 tokens 其所對應之不當傾向值，並透過卡方運算計算該網頁之 I 值，
最後根據 I值判斷該網頁之類別。 
 
圖 2：內容分類流程 
                                                 
1 StarDict [27]是一套網路上廣為流傳的 open source(GPL) 翻譯軟體，目前已有多國語言版本的字典檔，
並且可以使用轉換軟體自行轉換成所需之格式。 
8 
均數加上兩倍標準差之 tokens，即為可辨識網頁類別之特徵詞組。但此方法並不能保證
挑出之關鍵詞組具有鑑別度，故需額外透過人工調校，將不適當之 tokens 剔除。為了克
服此缺點，本研究改用資訊熵數概念來篩選特徵詞組。 
就分類的角度言，一個具有分類價值的特徵詞，應該滿足下列三條件： 
(a) 頻率 (Frequency)：當一字詞在某類別中，出現頻率夠高時，則其必有一定之引
用價值。倘若此界限值訂為 TF，小於界限值 TF 則予以捨棄 [10,11]。 
(b) 集中度 (Conformity)：又稱為 ICF (Inverted conformity frequency)，一個有分類
價值的字詞，應該要集中出現在某一類(色情、賭博)中，而不是平均出現在各類中。對
於一個字詞 Ti 於類別 Cj 中之 Entropy 值為： 
        , where    (4) 
 
dij為類別 Cj中出現字詞 Ti的文件數。以色情與非色情為例，總類別為二，因此 Hi的
值將介於 0（最集中）與 log2（最分散）之間。倘若此界限值訂為 E，大於界限值 E
則予以捨棄 [10,11]。 
(c) 廣度 (Uniformity)：在某一類中出現頻率高的字詞，如果是出現在此類中許多篇文
件中，則它愈具有分類價值；反之，若只集中在此類的某一、兩篇文章中，則原因可
能只是一突發事件，或是特定撰稿者的特殊寫作風格所致，相對地，此字詞較無分類
價值。 
  , where   (5) 
， iktf 為文件 K 出現字詞 Ti 的文件數，n 為字詞 Ti出現於類別 Cj之文件總數。倘若此
界限值訂為 U，小於界限值 U 則予以捨棄 [10,11]。 
4.2 字詞之傾向値計算 
在先前研究中，我們對不當傾向値的定義如下: 
1
1 1
_ __
_ _ '_ '_t
X tf X dfX Tendency
X tf X df X tf X df
−
− −
×= × + ×        (6) 
 
1
l o g
n
i i j i j
j
H p p
=
= − ∑
1
ij n
j
d i jp
d ij
=
=
∑
1
l o g
n
i j i k i k
k
U q q
=
= − ∑ 1 2
1
ik ik
ik n
i i in
ik
k
tf tfq
tf tf tftf + + +
=
= =
∑ L
10 
門檻值依序為 0.01、0.02、0.03、0.04、0.05、0.06、0.07、0.08、0.09、0.1 十種；廣度
值暫取其平均值 0.5 一種。 
(3) 依以上門檻值所搭配出之 160 (4*4*10) 種組合，依序實驗並紀錄其結果。 
Threshold&Precision
0.5
0.6
0.7
0.8
0.9
1
1.1
200
_20
0_0
09
200
_20
0_0
04
200
_40
0_0
09
200
_40
0_0
04
200
_60
0_0
09
200
_60
0_0
04
200
_80
0_0
09
200
_80
0_0
04
400
_20
0_0
09
400
_20
0_0
04
400
_40
0_0
09
400
_40
0_0
04
400
_60
0_0
09
400
_60
0_0
04
400
_80
0_0
10
400
_80
0_0
05
600
_20
0_0
09
600
_20
0_0
04
600
_40
0_0
09
600
_40
0_0
04
600
_60
0_0
09
600
_60
0_0
04
600
_80
0_0
09
600
_80
0_0
04
800
_20
0_0
09
800
_20
0_0
04
800
_40
0_0
09
800
_40
0_0
04
800
_60
0_0
09
800
_60
0_0
04
800
_80
0_0
09
800
_80
0_0
04
Threshold
Pre
cis
ion
np_Precision
p_Precision
av_Precision
 
圖 4：不同門檻值組合與準確率之對應關係圖(整體) 
由圖 4 中，我們可發現其由左往右的共同趨勢為，隨著集中度與詞頻之門檻值愈嚴苛，
則平均準確率(色情類與非色情類準確率之平均值)愈高。 
Threshold&Precision
0.6
0.65
0.7
0.75
0.8
0.85
0.9
0.95
1
800
_80
0_0
09
800
_80
0_0
08
800
_80
0_0
07
800
_80
0_0
06
800
_80
0_0
05
800
_80
0_0
04
800
_80
0_0
03
800
_80
0_0
02
Threshold
Pr
ec
isi
on np_Precision
p_Precision
av_Precision
 
Threshold&Precision
0.6
0.65
0.7
0.75
0.8
0.85
0.9
0.95
1
200
_20
0_0
09
200
_20
0_0
08
200
_20
0_0
07
200
_20
0_0
06
200
_20
0_0
05
200
_20
0_0
04
200
_20
0_0
03
200
_20
0_0
02
Threshold
Pr
ec
isi
on np_Precision
p_Precision
av_Precision
 
圖 5：不同門檻值組合之準確度對應關係圖 
我們以 TF 門檻值 800 和 200 來做進一步說明。如圖 5 所示， “*_*_*”第一個與第
二個數字代表的是 TF 門檻值，第三個數字則是指集中度，數字愈小表示愈集中(嚴苛)，
經由比較圖 5 中的左圖與右圖，可發現高 TF 門檻值之平均準確率較高(左圖之平均準確
率皆在九成以上)，而且集中度愈嚴苛，準確率也愈高；不過挑選門檻值的準則除了
av_Precision (整體準確率) 要高之外，np_Precision (非色情準確率)與 p_Precision (色情準
12 
4.5 內容分類實驗結果 
截至目前為止，主要成果有以下幾項: 
(1) 我們已經完成中英日三種語文的色情網頁分類以及英文賭博網頁之分類。實
驗結果顯示，英文色情準確率為 97.2%，英文賭博準確率為 96.5%，中文色情
準確率為 96.4%，日文色情準確率為 98.6%。 
(2) 在網頁測試過程中，網頁中有許多為轉址或是框架頁，目前已能解決將轉址
寫在 META 中之網頁以及寫在 HTML 中之框架頁，但以 JavaScript 撰寫之轉
址網頁，本系統無法完全解譯，如能藉助其它瀏覽器之程式幫助判斷轉址後
之 URL，將可解決轉址網頁無法跟上之難題。 
5.  結論與未來研究 
本研究提出一個新的不當傾向値定義，以及一個運用資訊熵數來挑選有鑑別度
的特徵字集之機制，以改良先前提出的以卡方為基礎的不當網頁分類系統。實驗結
果顯示，這個方法可以在不經人工調校下，使系統準確率提高，而且已在日文色情
網頁以及英文賭博網頁實驗中獲得成效。 
這個研究未來仍有許多發展的空間，例如 
(1) 利用資訊熵數來挑選特徵詞庫之方法，可快速找出有鑑別度之特徵字詞，而
且幾乎不需人工挑選，而且已知集中度門檻值愈嚴苛，其準確率愈高，但仍
需要測試與調整不同之門檻值組合才能得到最佳準確率。因此，我們正在模
擬測試資料之分布情形，意即模擬不當資訊網頁與正常網頁之可能組合情
形，並發展出一套模擬流程，搭配經由門檻值 (Frequency, Conformity, 
Uniformity) 挑選後之特徵詞庫，以快速預測各種門檻值組合之準確率。 
(2) 許多歐洲語文 (例如: 法、德、瑞典、挪威) 都和英文共用西歐 (ISO 8859-1) 
編碼，在網頁呈現與編碼識別都沒有問題，但是在訓練資料的選擇與distinctive 
tokens 的挑選會造成混淆，如何兼顧多國語文與精確率，則有待進一步探索。 
14 
14. Bosson, A., G. C. Cawley, Y. Chan and R. Harvey, “Non-retrieval: blocking pornographic 
images,” in Proceedings International Conference on the Challenge of Image and Video 
Retrieval, Lecture Notes in Computer Science, Vol. 2383, pp 60- 69, Springer-Verlag, 
London, 2002.  
15. Chan, Y., R. Harvey, D. Smith, “Building systems to block pornography.” In Eakins, J., 
Harper, D., eds.: Challenge of Image Retrieval, BCS Electronic Workshops in 
Computing series (1999), pp.34–40. 
16. Chan, Y., R. Harvey, J. A. Bangham, “Using colour features to block dubious images,” in 
publication at Eusipco 2000, Tampere, Finland. 
17. M. Hammami, Y. Chahir, L. Chen, “WebGuard: Web Based Adult Content Detection and 
Filtering System,” Web Intelligence, 2003. WI 2003. Proceedings. IEEE/WIC 
International Conference, 13-17 Oct. 2003, pp.574 – 578 
18. Lee, P. Y., S. C. Hui, and A. C. M. Fong, “Neural Networks for Web Content Filtering,” 
IEEE Intelligent Systems, September/October 2002, pp. 48-57. 
19. Lee, P.Y., S. C. Hui, and A. C. M. Fong, “A structural and content-based analysis for web 
filtering,” Internet Research: Electronic Networking Applications and Policy, Vol. 13, No. 
1, 2003, pp. 27-37.  
20. Robinson, G., “A Statistical Approach to the Spam Problem,” Linux Journal, Vol. 2003, 
Issue, 107, March 2003, available at http://www.linuxjournal.com/article.php?sid=6467. 
21. Robinson, G., “Why Chi?” Version. 0.93,  
http://www.garyrobinson.net/2004/05/why_chi.html , posted on May 3, 2004 
22. Robinson, G., “Handling Redundancy in Email Token Probabilities,” Version 0.94 
http://www.garyrobinson.net/2004/04/improved_chi.html , posted on April 28, 2004 
23. Smith, D., R. Harvey, Y. Chan and J. A. Bangham, “Classifying web pages by content,” 
IEE European Workshop on Distributed Imaging, November, 1999, Vol. 99/109, IEE, 
pp.8/1-8/7, 1999, UK ISSN 0963-3308 - Reference No: 1999/109.  
24. Unicode, Inc., http://www.unicode.org/ 
25. Java port of Mozilla charset detector, http://sourceforge.net/projects/jchardet/, accessed 
12/21/04. 
26. Code Pages Supported by Windows, 
http://www.microsoft.com/globaldev/reference/wincp.mspx 
27. StarDict, http://stardict.sourceforge.net/, accessed 12/21/04 
28. Lung-Hao Lee, “A Web Content Classification System for Pornographic Blacklist 
Generation”, A Thesis Submitted to Department of Information Management School of 
Informatics Yuan Ze University in Partial Fulfillment of the Requirements for the Degree 
of Master in Business Administration, June 2005. 
29. CHANG Bao-Bao, “Translation Equivalent Pairs Extraction Based on Statistical 
Measures”, CHINESE JOURNAL OF COMPUTERS, Vol. 26 No. 5 May 2003. 
 
