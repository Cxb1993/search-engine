2develop a system without special equipments
for recognizing human gestures in a general
environment, target body modeling should be
as simple as possible. The instance-based 2D
shape template is a good choice due to easy
creation and manipulation. Consequently, al-
gorithms for detection and recognition of
dynamic gestures could be the instance-based
approach. As Yilmaz et al. [11] described,
tracking objects would be complex without
assumptions about the target to be tracked or
about the conditions of environments. Global
target object detection without replying on
the success of the object tracking is thus
more straightforward to the system to be
developed.
To this end, the generalized Hough trans-
form (GHT) and the dynamic time warping
(DTW) algorithm are an appropriate combi-
nation for recognizing dynamic human ges-
tures because they are both instance-based
approaches, and the GHT is a global shape
detector. However, since the shape of the
target object would be changed in sequent
video frames, the GHT should be with mul-
tiple shape templates. High computational
cost would prohibit directly applying the
GHT with multiple shape templates on de-
tecting the target objects in sequent video
frames. Furthermore, the traditional GHT
cannot make use of temporal information
in sequent video frames. In this project, a
progressive version of the GHT is developed,
and the A* search is proposed to integrate the
GHT and the DTW algorithm together so that
the total computation cost can be reduced by
avoiding unnecessary votes of the GHT, and
the temporal information in sequent frames
can be utilized for target object detection as
well.
The organization of this report is as fol-
lows. Section 2 presents the A*-guided DTW
algorithm. Section 3 presents a revision of
the A*-guided GHT [12]. Section 4 shows
experimental results. Concluding remarks are
in the last section.
II. THE A*-GUIDED DYNAMIC TIME
WARPING ALGORITHM
Let M1, . . ., MM denote M dynamic
gesture models, each of which contains Ni
key frames Kij , j = 1,. . ., Ni. Let I denote
N input frames I1, . . ., IN to be identified as
one of the M dynamic gesture models. The
proposed approach uses the DTW algorithm
to match the input frames against every dy-
namic gesture model, and the input frames
are identified as the model with the highest
matching score. The DTW formula for this
study is defined as
W (N,Ni;I,Mi) = S(N,Ni; I,Mi)+
max
W (N − 1, Ni; I,Mi)W (N − 1, Ni − 1; I,Mi)
with
W (1, j; I,Mi) = S(1, j; I,Mi)
W (j, 1; I,Mi) = S(j, 1; I,Mi),
where S(j, k; I,Mi), which is called the
score matrix for Mi, denotes the matching
score of input frame Ij and key frame Kik
obtained by the GHT. The local constraint
on the mapping path is defined in such a way
that every key frame should have at leat one
matching input frame, and every input frame
should have one and only one matching key
frame. Figure 1 sketches the global constraint
on the mapping path.
A straightforward implementation of this
idea may be as follows.
1) First, for every model Mi, the GHT is
used to detect every key frame of Mi
on every input frame to fill the score
4Fig. 2: A flow-chart of the proposed ap-
proach.
Figure 2 gives an illustration of the proposed
approach. Since every iteration of Step 3 al-
ways chooses the best mapping path, and the
score of the chosen mapping path is always
not less than the best of those derived from
the exact score matrices, this algorithm is the
A*-search to find a mapping path with the
optimal matching score among the M score
matrices although the score matrices may not
be formed exactly. Thus, this algorithm is
coined as the A*-guided dynamic warping
algorithm.
III. A REVISION OF THE A*-GUIDED
GENERALIZED HOUGH TRANSFORM
The GHT obviously plays a key role of
the proposed approach. The multi-stage GHT
is based on a series representation of the R-
table of the traditional GHT, which is called
the A*-guided GHT [12]. In this project, the
A*-guided GHT is modified so that it is more
space-saving, and more focused on the region
containing the target object. In order not to
be out of focus, only the main modifications
are presented as follows.
1) The Definition of the Kernel Function:
The function Ψ of the gradient direction θ is
redefined as Ψ(θ) = [ v0 ... v359 ]T where
v0, ...,v359, are defined as:
vi =

1√
2ε+1
if min
 |θ − i|360− |θ − i|
 ≤ ε;
0 elsewhere.
That is, vi is 1√2ε+1 if the angle difference
between the gradient direction θ and i is
not greater than ε; otherwise, vi is zero. The
similarity between two gradient directions θ
and θ′ is defined by the standard dot product
of Ψ(θ) and Ψ(θ′); therefore, we have
< Ψ(θ),Ψ(θ′) >=
1− min{|∆θ|, 360− |∆θ|, 2ε+ 1}
2ε+ 1
,
where ∆θ = θ− θ′. Now, the kernel function
k is re-defined as
k(x,Ψ(θ);x′,Ψ(θ′)) =
< Ψ(θ),Ψ(θ′) > exp
(
−‖x− x
′‖22
σ2
)
,
where x and x′ are the positions of two
boundary points with gradient directions θ
and θ′, respectively. The function k is a
valid kernel function because it is the tensor
product of two kernel functions: one is a
standard kernel and the other is a Gaussian
kernel [13], [14], in which the first term of k
measures the similarity between the gradient
directions of two boundary points and the
second term measures the consistency of the
two points in positions. Hence, once two
boundary points are far from each other or
have quite different gradient directions, their
mapped vectors in the kernel feature space
are almost orthogonal, and vice versa.
2) The A*-Guided Voting Process: Once
a voting process of the original version is
issued, all edge points in the input image are
all participated in this process. However, only
the edge points in some blocks are involved
6experiments were carried out on a computer
which has an IntelrCore2 2.13GHz CPU
and three gigabytes of RAM, and runs the
Windows XP operating system.
Figure 4 shows the key frames of
three dynamic gesture models, which are
adopted from the RWTH Fingerspelling
database [15]. The RWTH Fingerspelling
database contains 35 bare hand gestures.
The input frame is of size 320x240. In or-
der to reduce the number of edge points
in the input video frames, only the edge
point nearby skin-color pixel was retained
for detection and recognition. The developed
system takes about eight seconds to identify a
video sequence of twelve frames as one of the
three dynamic gesture models, whereas the
straightforward implementation takes about
forty-five seconds. A small scale of experi-
ments have been conducted. Figure 5 shows
the recognition results of three different video
sequences. Successful experimental results
demonstrate the feasibility of the proposed
approach.
V. CONCLUSION
In this project, a novel approach to simul-
taneously detecting and recognizing dynamic
gestures has been developed. Since the gen-
eralized Hough transform is a global shape
detector, the proposed approach does not suf-
fer from the error-recovery problem of the
tracking technique. Besides, since the DTW
algorithm is incorporated into the detection
process, the proposed approach also makes
use of the temporal information across se-
quent frames of the training dynamic gesture
patterns naturally.
In the future, a larger scale of experi-
ments should be conducted. Although a dra-
matic amount of unnecessary computation
(a) Model 1
(b) Model 2
(c) Model 3
Fig. 4: The key frames of three dynamic
gesture models.
is avoided, efforts to reduce the total com-
putation cost should be made. Making use
of the multi-core technology of the modern
CPU, and clustering the frames of the training
dynamic gesture patterns to reduce the total
number of key frames to be matched are two
promising directions. Automatically gesture
spotting is also worth of investigation in the
future.
