 I
研究計畫中英文摘要： 
（一）計畫中文摘要 
智慧型機器人已成為國家產業重點發展領域之ㄧ，本計劃旨在發展仿人類眼球機器人
系統，盼能藉由學習以及推理，與人產生良好互動。研究的主要內容將整合智慧型理論及
預測演算法則，以三年為期，模仿人類三種基本的眼球運動：平滑追蹤、跳視、前庭視覺
反射(注視)。目前已設計且製作一台仿人眼機器人系統，採用類神經網路系統為基礎設計
一智慧型運動描述系統，根據人腦所認知運動狀態來識別不同的運動事件，包含”拿起物
件”，”放下物件”和”丟下物件”。運動狀態的認知以及運動事件的識別是透過觸發式類神經
網路以及運動的分類器。觸發式類神經網路可以把運動狀態序列轉成觸發的運動狀態序
列，運動的分類器則採用遞回式類神經網路，可達到很好的運動事件的識別效能且不受未
知運動狀態序列影響。在雙眼立體視覺部份，則利用類神經網路訓練此機器計算物體深度，
而不需要利用相機的相關參數進行三角測量。 
關鍵字：眼球運動；平滑追蹤；類神經網路；運動描述；深度計算。 
 1
報告內容 
I. Introduction 
The robot has appeared incrementally and plays an important role in the future. They will be 
extensively used such as security, entertainment, companion…. and so on. It is worthwhile to 
research the area of robot. However, there are still lots of limitation in vision cognitions of robot 
which make the robot unintelligent. The intelligence of human being is constructed from learning 
and reasoning abilities. The so-called learning ability is to learn and memorize something and 
reasoning ability is to reasoning something with experience. Therefore, a gifted artificial 
intelligent neuron is birth to emulated brain neuron. Basically, the artificial neural network based 
on the human neural network contains many neurons connected with synaptic weights. Thus, it is 
intelligent by learning, recalling, and reasoning from test data like a human brain. 
The developed Human-like Eye Movement System (HEMS) consists of two cameras and 
five degrees of freedom, so that two images of the same scene can be taken at the same time by 
the right camera and the left camera from two different perspectives. The pair of these two 
images is called a stereo pair. The main problem in HEMS is the perception of depth, because the 
depth information obtained from stereo vision is very useful for robot navigation in complex 
environments. Stereo vision consists of matching corresponding points in a stereo pair and 
estimating depth from their disparity which means the difference in positions of corresponding 
points. 
II. Related Works 
In recent years, many researchers have been devoted to developing artificial intelligence 
system, consisted of following theory, High-level Vision [1], representation and reasoning [2], 
spatial and temporal reasoning [3-7] and neural network[6, 7]. In general, the spatial temporal 
reasoning adopts the concept of state machine to describe an object motion event represented by a 
specified state sequence; however, it is not intelligent to design a state machine manually. If a 
new state is added, the state machine must be redesign and all the transition probabilities should 
be changed accordingly which makes the spatial temporal reasoning not extendable. In order to 
solve above problems, we proposed a system combined neural network and spatial temporal 
reasoning together. However, it is difficult only plain neural network to learning the motion 
movement related time; therefore, a recurrent neural network is introduced for learning state 
machine automatically [10-18]. 
Usually in stereo vision systems, the depth is calculated from disparity by using the 
triangulation. The process of triangulation is needed to find the intersection of two known rays in 
space. This kind of classical technique needs careful calibration of the imaging system while 
calibration is an error sensitive process and it cannot always be performed online [20]. Therefore, 
there are some other approaches that calculating depth map without using camera parameter [18], 
[20]. In this thesis we have estimated depth in a human visual system using neural networks. By 
using neural networks we have estimated depth without getting camera parameters and 
situation between hand and object which can be very-far, far or near. 
Motion Event 
 Analyzer 
(MEA) 
Motion States 
Sequence 
Image 
Sequence 
Image Data 
Sequence 
Motion Data 
Generator 
(MDG) 
Image Data 
Retriever 
(IDR)
Motion Data 
Sequence 
Motion States 
Encoder 
(MSG) 
Motion Events 
Output 
Motion Events 
Description 
Motion Event 
 Analyzer 
(MEI) 
CCD 
Camera 
Scene 
 
 3
Figure 2. Intelligent Motion Description Systems. 
 With the motion da Dropping-down, could 
State Joint O_mov O_grnd
ta, the motion state, Picking-up, Putting-down and 
be encoded via Table 1. 
S(1) -1 -1 1 
S(2) -1 1 1 
S(3) 1 -1 1 
S(4) 1 1 1 
S(5) 1 -1 -1 
S(6) 1 1 -1 
S(7) -1 -1 -1 
S(8) -1 1 -1 
Ta ta ncode
Motion Event Learning 
n event by a state sequence, it is often based on a fixed number of states, 
i.e.,
sifier, there are four triggered state sequence at time k, denoted by qk(1), 
qk(2)
ble 3. S te e r. 
 To describe a motio
 a state sequence of fixed length. However, a general motion event usually happens during an 
uncertain time. For example, an object may be picked up quickly or slowly and thus the motion 
of the object is hard to be represented by a fixed-length state sequence. To solve the problem, the 
motion event analyzer (MEA) is developed to contain a trigger net and an event classifier shown 
in Figure 3. Actually, the trigger net is the key technology to analyze a motion event represented 
by a state sequence in unfixed length. In fact, a motion event is identified according to the 
changes of states in a state sequence, i.e., a state is not useful to analyze a motion event as it is the 
same as former state. To neglect these useless states, the trigger net is designed to be triggered 
only when the current state is different to former state. 
Feed-forward classifier 
For the motion clas
, qk(3) and qk(4). They parallel go to the input layer of the feed-forward classifier for 
 5
machine is set up as shown in Figure 6 and used to generate a string of 
mot
elligent Depth Computation 
St eras can be utilized to compute the depth of a point by 
using
ing of a set of grid points is placed in front of the HVS for depth detection 
and
An IMDS which contains image data retriever, motion data generator, MSE and MEA is 
condition given in Table 3. 
Experimental Results 
The motion event 
ion event. Each motion event generates trigger state sequence with different probability. The 
state sequence is generated with length 4000 and used for motion event classification task. The 
training data can be obtained according to Table 6 where the motion state S(j), j=1,2,…,8, will be 
padded to the left of three states of motion event for fixed four training data. Testing data in Table 
7 is possessed from an image sequence captured by camera. The output ok will be determined by 
tolerance type MEI and feed-forward classifier. The tolerance type MEI will be implemented by 
neural network. The recurrent neural network adopted in this paper has three layers which contain 
two hidden layers and one output layers. There are 24 and 8 neurons in first and second hidden 
layers respectively. The output layer consists of three neurons to indicate three motion events 
respectively. The hyperbolic tangent and linear function are adopted as the activation functions in 
hidden and output layers respectively. The Levenberg-Marquardt method is used to be the 
training algorithm. After 1000 epochs in training phase, the system with recurrent neural network 
can recognize the motion event with 97% which is higher than the one with feed-forward neural 
network. 
V. Int
ereo pair obtained from two cam
 the traditional depth computation, i.e., triangulation. However, to apply this computation, 
parameters of each camera need to be experimentally obtained in advance. Therefore, artificial 
neural networks (ANN) is adopted to train the system for eliminating the complicate computation 
process. The network model used is shown in Fig. 6. and consists of four input neurons, five 
hidden neurons and three output neurons. The input of ANN are the matched points found in the 
stereo images (ul, vl) and (ur, vr) which are the object positions in the left and right images 
respectively. These points are generated by the same world and formed the input data set for 
training. The output data are the corresponding position (X, Y, Z) w.r.t. the world coordinate. 
Furthermore, one output neuron which only indicated the depth has been tested and shown the 
worse performance than the network with three output neurons mentioned above. The network 
was trained in an interesting range of actual depth. 
Experiment Design 
 A board consist
 shown in Fig. 7. With the use of these two cameras, the HVS captures images of a specified 
cross at various distances, ranging from 65 to 165 cm. To verify the usefulness of the proposed 
ANN depth detection algorithm, the experiment was performed by changing the distance Z 
between the HVS and the board, where Z starts from 65 cm to 165 cm at an increment of 10 cm. 
The experimental results show that an acceptable accuracy can be obtained but it is not easy to 
reach high accuracy by using only neural networks. Although ANN has a good generalization 
capability in the trained range. 
VI. Conclusion 
 7
計畫相關之學生畢業論文與已發表之研討會論文 
, and Yon-Ping Chen, “Design of Intelligent Motion 
參考
,“Temporal Scene Analysis - Conceptual Descriptions of Object Movements,＂ 
[2] ic reasoning among 3D models and 2D images,＂ Artificial 
[3] a, A., Hogg, D., Hazarika, S,“Towards an Architecture for 
[4] -Temporal Predicates,＂ IEEE Trans. on Knowledge 
[5] of motion based on spatiotemporal 
[6] nce Learning via Bayesian Clustering by 
[7] 
[8] e Spatial 
[9] on and Applications”, Prentice Hall, 1982. 
 ormation.＂ 
[11] ., vol. 14, pp.179–211, 1990. 
rent 
[13] e,” Carnegie Mellon Univ., 
[14] e Giles," Fuzzy Finite-State Automata 
from traditional depth computation by triangulation which has some restrictions when using. 
 
本
[1] 藍琦佑，，碩士論文，2008。 
[2] 張倍榕，，碩士論文，2008。 
[3] 黃志榮，，碩士論文，2008。 
[4] Shih-Hung Yang, Chi-You Lan
Description System,” Vision Information Processing 2008 and Southern Taiwan University, 
Taiwan. 
文獻 
[1] Badler, N
Report TR 80, 1975 
Brooks, R,“Symbol
Intelligence,1981 , 285--348 
Cohn, A., Magee, D., Galat
Cognitive Vision using Qualitative Spatio-Temporal Representations and Abduction,＂ 
Spatial Cognition III, Springer, 2003 
M. Erwig and M. Schneider,“Spatio
and Data Engineering (TKDE), 14,(4,):1–42, 2002,. 
Muller. 1998b. P. Muller,“A qualitative theory 
primitives,＂  In A.G. Cohn, L.K. Schubert, and S.C. Shapiro, editors, Principles of 
Knowledge Representation and Reasoning: Proceedings of the Sixth International 
Conference (KR’98). Morgan Kaufmann, 1998. 
Sebastiani, P., Ramoni, M., Cohen, P,“Seque
Dynamics, Sequence Learning: Paradigms, Algorithms, and Applications,＂ Springer, 2000 
Mohnhaupt, M., Neumann, B,“Understanding Object Motion: Recognition, Learning and 
Spatiotemporal Reasoning, Toward Learning Robots,＂ MIT Press, 1993 , 65-92 
Galata, A., Cohn, A., D., M., Hogg, D,“Learning Temporal and Qualitativ
Components of an Interaction Model,＂ Proc. ECCV Workshop on Vision and Modelling of 
Dynamic Scenes (VAMODS), 2002 
K.S. Fu, “Syntactic Pattern Recogniti
[10] Tijsseling, A. and Berthouze, L,“A neural network for temporal sequential inf
Proceedings of the 8th International Conference on Neural Information Processing, 
Shanghai (China), pp. 1449–1454, 2001. 
J. L. Elman, “Finding structure in time,” Cognitive Science
[12] R. J. Williams and D. Zipser, “A learning algorithm for continually running fully recur
neural networks,” Neural Computa., vol. 1, pp.270–280, 1989. 
S. E. Fahlman, “The recurrent cascade-correlation architectur
Pittsburgh, PA, Tech. Rep. CMU-CS-91-100, 1991. 
Christian W. Omlin, Karvel K. Thornber, and C. Le
 9
計畫成果自評 
 This project has developed an intelligent motion description system (IMDS), a human-like 
eye movement system (HEMS) and a depth computation with neural networks. 
1. The IMDS adopts the recurrent neural networks as the structure and learn how to descript the 
motion from image data. 
2. The HEMS consists of two cameras and five motors as five degrees of freedom. 
3. A depth computation is developed via neural networks and can compute the depth well in the 
trained range. 
The future work might focus on 
1. Train the robot to describe the events without prior motion state encoding, i.e., the robot does 
not necessarily to know the exact motion sequence for each event and learn to recognize the 
events. 
2. How to use neural networks to improve the computational performance and accuracy in 
stereo vision application. Then the system could extract stereo information easily. 
 
