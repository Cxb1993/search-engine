中文摘要 
多媒體之應用，通常需要執行大量資料的運算，而本研究計畫所採用的 H.264(或稱為
MPEG-4 Part 10)是一種新型的影像編碼標準，它與 MPEG-2 相比，在相同的影像品質下，只需要
MPEG-2 一半的位元率(bit rate)。同時，在編碼效率、錯誤修正與網路友善性上，它也有顯著的改
善。 
本研究計畫的目的，主要在探討如何加速處理 H.264 影像編碼。計畫中將研究和分析所提出
之架構，並將經由叢集平台上各節點的平行處理來實現。 
我們曾提出一種建構於 ARM 處理器的可擴式小型叢集計算系統，以達到低成本、低耗電和
高效能的目的。在本計畫中，我們將發展一 ARM 模擬程式，將 H.264 編碼技術實現在以 ARM 為
主的叢集平台上。此模擬程式將具有實用性與彈性，可隨時加以擴充，建立各種 ARM 處理器和系
統的模型，以便在正式生產前，可進行各項系統模擬。 
我們相信使用所發展之 ARM 模擬程式，其產生之高品質的結果，將能為如何加速處理 H.264 影像
編碼，提供一正確的方向。 
關鍵詞：H.264、ARM 處理器、叢集計算。 
Abstract 
Multimedia applications typically require computations for large amount of data. An emerging video 
coding standard named H.264 or MPEG-4 Part 10 aims to code video sequences at approximately half the 
bit rate compared to MPEG-2 at the same quality. It also aims at having significant improvements in 
coding efficiency, error robustness and network friendliness.  
In this research project, the H.264 encoding to accelerate the video processing is investigated. The 
scheme will be studied and analyzed, as also it will be performed in parallel through the nodes of a cluster 
platform, in order to speedup such processing.  
A scalable wallet-size cluster computing system based on ARM is proposed, in order to obtain 
low-cost, low-power consumption and high-performance platform. We will concentrate our efforts to 
implement H.264 encoding technology into a ARM-based cluster platform, via ARM simulator. Besides 
practical and flexible, the simulator can be extended to model modified ARM processors and systems 
anytime, even before they reach production.  
 
1. Introduction 
The new H.264/AVC video coding standard has gained even more attention recently, mainly due to 
its higher coding efficiency over previous standards. Not only the video the performance of data 
compression is enhanced, significant improved features and functionalities relative to previous standards 
are rate-distortion and coding efficiency, error robustness and network friendly. 
Multiprocessor Systems-on-chip systems have been proposed as a way to achieve high performance 
as well as low power consumption, that is, they offer superior performance and potentially better 
energy-reduction than single processor systems. Multiple cores on a single chip offer higher parallelism 
and thus, potentially higher performance. In addition, by lowering the supply voltage and operating 
frequency for processor cores, the energy consumption of the system can be reduced significantly. On the 
other hand, to take advantages of the computation power provided by the multiprocessor system, 
applications need to be parallelized. Therefore, all depends on how well the application can be mapped 
onto the architecture, resulting in different levels of performance optimization.  
Software solutions for H.264/AVC have become feasible, by providing higher coding efficiency 
require low power consumption and fast memory bandwidth access. To make a chip with low cost, high 
flexibility, and low power, a programmable processor is suitable for adaptive processing and various 
algorithms. However, power consumption of high-performance processors is high. On the other hand, 
dedicated hardware has lower power and higher performance than software implementation.  
Basically, H.264 can be widely used in video communication servers in IP network and wireless 
environment. Its key features when compared to its antecessors are: 
— Enhanced motion estimation with variable, 
— Enhanced entropy coding, 
— Integer block transform, 
— Improved in-loop deblocking filter. 
The H.264 is an international video coding standard with superior objective and subjective image 
quality, reducing average bit rate of 50% given fixed fidelity when compared to any other standard. The 
main goals of JVT can be summarized as significant coding efficiency, simple syntax specifications and 
seamless integration of video coding into all current protocols and multiplex architectures (network 
friendliness). H.264 meets requirements from the various video applications that aims at supporting video 
streaming, video conference, over fixed and wireless networks and over different transport protocols, etc. 
H.264 has grouped its capabilities into profiles and levels - Baseline, Main and Extended profile. A 
"profile" is a subset of the entire bit stream of syntax that is specified by the international standard. Within 
each profile, there are a number of levels designed for a wide range of applications, bit rates, resolutions, 
qualities and services. A "level" has a specified set of constraints imposed on parameters in a bit stream. It 
is easier to design a decoder if the profile, level and hence the capabilities are known in advance. Baseline 
profile can be applied to video conferences and video telephony, the main profile can be applied to 
broadcast video, and the extended profile can be applied to streaming media. 
 
2.1 Architecture of H.264 Decoder 
Figure 1 shows a block diagram of H.264. Synchronous DRAM, accumulated image data, and the 
microprocessor are controlled by the host parameters. The decoder consists of a 32-bit RISC processor and 
dedicated hardware engines. The dedicated engines are implemented for fixed functions in H.264, such as 
input stream control (ISC), entropy decoder, inverse quant (IQ), inverse transform (IT), reconstruction 
(REC), intra-frame prediction (IPRED), inter-frame prediction and motion compensation (MC) prediction, 
deblocking filer (DB), host interface (HIF), and clock generator (CLKGEN).  
The local memory (LM) reduces accessibility to the external memory and power dissipation rate for 
real-time application. The DMA controller can transfer data among local memories and access external 
memory. The RISC is a 32-bit ARM7TDMI processor with three-stage pile-line at the decoding mode. The 
RISC processor acts as a scheduler and high entropy decoder, and executes syntax synthesis and syntax 
parsing. Direct memory access and external memory interface blocks perform a data transfer between 
internal memory and external frame memory. The data transfer of the chip has one cycle operation 
between local memory and external frame memory. The DMA supports several mode operations with 
  
Figure 3. Experimental scheme of the proposed ARM-based processor cluster 
 
MultiplexerScheduler
H.264
bitstream
Video Sequence
Slice 1~5
Slice 6~10
Slice 11~15
Slice 16~20
Slice 21~25
Slice 26~30
Slice 31~35
 
Figure 4. The structure of the Small sized cluster system for H.264 encoding 
 
3.2 H.264 Encoding Structure 
As the input video sequence arrives (see Figure 4), the scheduler in master node send slices to slave 
nodes for encoding, according to the predefined pattern. The slave nodes send back the encoded slices to 
the master node to form an output bit stream. 
By analyzing the dependencies among the sequence of the input frames to be encoded, a higher 
degree of parallelism can be obtained. I frame in the video can be encoded or decoded independently. P 
frame represents predicted frame, it is predicted from a previously encoded I frame or P frame. Thus, it is 
impossible to encode two consecutive P frames simultaneously, since the existence of the dependency. B 
frame is the bi-directional predicted frames. It is predicted from two previously encoded I and P frames. B 
frames are assumed to refer the nearest encoded or I and P frames. 
 
4. Algorithm Strategies 
There are two sequences in the codec. One is the displaying sequence and the other is the encoding 
sequence. For instance, the displaying sequence in a GOP (Group of Picture) is IBBBPBBBP, the 
encoding sequence is actually IPBBBPBBB. For an IPBBBPBBB sequence, the first encoded frame is I0, 
P4 is encoded next, and then three B frames, B3 to B5, are encoded. P8 is encoded by referencing I0 and 
P4. Three B frames between P4 and P8 are encoded finally. The encoding sequence is illustrated in Figure 
5. 
There are two sequences in the codec. One is the display sequence and the other is the encoding 
without an OS to full operating systems such as ARM Linux. The company plans to provide 
"near-complete" simulation of the StrongARM SA-110 and Sharp Zaurus SL-5500. Additionally, the 
simulator can be extended to model modified ARM processors and systems before they reach production.  
Information was obtained from the website http://www.linuxdevices.com/news/NS4665550218.html . 
 
5.2 RealView 
The RealView Development Suite Instruction Set Simulator (RVISS) provides simulation of ARM 
and Thumb core-based processors, which allows application users to develop code before hardware is 
available. The features of this simulator are as follows: 
— Support for ARM cores including ARM7, ARM9E, ARM10 and ARM11 processor families, 
— Benchmarking on ARM7, 
— Simulation of exceptions, such as interrupts and aborts, 
— User extensible to add support for custom peripherals, 
— Easily customizable memory configuration to match target system. 
An external interface is defined, to allow application developers to add models written in either C or 
C++ to simulate target hardware processor. All ARM cores from ARM architecture V4T upwards but not 
including V7 are supported in RVISS. 
 
5.3 ARMn 
ARMn is a multiprocessor cycle-accurate simulator which can simulate a cluster of ARM processor 
cores connected by custom communication schemes, such as wormhole based packet-switching, fully 
connected crossbar switches or regular standalone buses. The topology supported includes mesh, torus and 
star shape.  
The PE model used by ARMn is based and coupled with the fast ARM simulator SimIt-ARM (to be 
described in subsection 2.5). The communication part is written in SystemC which wraps the PE model 
around and enables it to communication with other communication modules (also written in SystemC). 
Major features of this simulation tool is listed as: 
— A C/C++ (SystemC) written cycle-accurate communication architecture simulator, 
— A library of reusable communication modules such as buffers (channel), arbiters and crossbars, 
— Fully integrated with an accurate ARM PE model. Can simulate message passing based 
application binaries compiled by cross compilers, 
— Fast Simulation Speed. (> 10K cycles per second for a 9PE cluster), 
— Designed for Fast Prototyping and Validation. 
 
As the codec standard becomes increasingly complex, the encoding and decoding processes require 
additional computation power. In this research, we have analyzed the encoding characteristics, so as to 
build several models for estimating the processing time if ARM processor-based cluster environment is 
applied to the processing of the H.264 encoding. We have modified the sequence of the input files for 
encoding, and therefore, a shorter encoding time, higher PSNR, lower total bits and bit rate can be 
obtained.  
As ongoing research, our team plan to utilize other simulation tools available, such as SimIT and 
ARMn, to evaluate other algorithmic strategies under development. Our primary estimations indicate that 
a better performance can be achieved. Additionally, more performance evaluation will be performed for 
real time H.264 encoding, as models are built in these systems, to show the availability and operability of 
ARM-based processor cluster environments. 
 
Publications 
- L.-T. Lee, C.-Y. Tseng, K.-C. Li, K.-Y. Liu, and C.-H. Hung, “Design of a Wallet-Size Cluster 
System for Multimedia Applications”, Proceedings of the 2004 Symposium on Digital Life and 
Internet Technologies, 2004. 
- L.-T. Lee, C.-Y. Tseng, K.-Y. Liu, and K.-C. Li, “A Wallet-Size Cluster for H.264 Encoding”, in 
ICITA'2005 The IEEE International Conference on Information Technology and Applications, 
Sydney, Australia, 2005 
 
Self Evaluation 
Researches conducted in this research project could provide us a unique experience, working on 
several issues related to the proposed research, instead to tackle directly on the problem. We believe that 
the approaches we investigated this project is in its right way. I believe that we have succeeded in 
developing techniques and strategies. There are research papers under work and discussions, although the 
time period for this research project has finished.  
I personally am very grateful with the opportunity to receive this research grant, what has contributed 
in giving me opportunity to teach and effective implementation through a number of discussions. 
 
References 
1. M. Horowitz, A. Joch, F. Kossentini, A. Hallapuro, “H.264/AVC baseline profile decoder complexity 
analysis”, in IEEE Trans on Circuits and Systems for Video Technology, vol. 13, Issue 7, pp. 704-716, 
July 2003.  
2. A.Luthra, G.J. Sullivan, T. Wiegand, “Introduction to the special issue on the H.264/AVC video 
coding standard”, in IEEE Trans on Circuits and Systems for Video Technology, vol. 13, Issue 7, pp. 
557- 559, July 2003. 
3. W. Qin, S. Malik. “Flexible and Formal Modeling of Microprocessors with Application to 
Retargetable Simulation. Design”, Automation, and Test in Europe (DATE), March, 2003. 
4. T. Wiegand, G.J. Sullivan, G. Bjntegaard, A. Luthra, ”Overview of the H.264/AVC video coding 
可供推廣之研發成果資料表 
□ 可申請專利  □ 可技術移轉                                   日期：95年 10 月 31日 
國科會補助計畫 
計畫名稱：ARM 叢集計算平台於 H.264 錄影譯解之研究 
計畫主持人：李冠憬 
計畫編號：94-2218-E-126-001  學門領域： 
技術/創作名稱  
發明人/創作人  
技術說明 
多媒體之應用，通常需要執行大量資料的運算，而本研究計畫所採
用的 H.264(或稱為 MPEG-4 Part 10)是一種新型的影像編碼標準，
它與 MPEG-2 相比，在相同的影像品質下，只需要 MPEG-2一半的位
元率(bit rate)。同時，在編碼效率、錯誤修正與網路友善性上，
它也有顯著的改善。本研究的目的，主要在探討如何加速處理 H.264
影像編碼。計畫中將研究和分析所提出之架構，並將經由叢集平台
上各節點的平行處理來實現。 
我們曾提出一種建構於 ARM處理器的可擴式小型叢集計算系統，以
達到低成本、低耗電和高效能的目的。在本計畫中，我們將發展一
ARM模擬程式，將 H.264編碼技術實現在以 ARM為主的叢集平台上。
此模擬程式將具有實用性與彈性，可隨時加以擴充，建立各種 ARM
處理器和系統的模型，以便在正式生產前，可進行各項系統模擬。 
 
The proposed collaborative research attempts to accelerate H.264 
encoding, by clustering low power consumption ARM processors, 
considering its low cost and high availability. In addition, the coding 
and embedding process into system is yet quite simple, what possibly 
make this approach feasible. A number of new features present in 
H.264 video coding standard, summarized by its superior coding 
efficiency and seamless integration of video coding into all current 
protocols and multiplex architectures, motivating us for this 
investigation. A major challenge in this proposal is to research novel 
load balancing and scheduling parallel algorithms with low time and 
space complexity, so that proper code can be described and embedded 
into a cluster of ARM processors system. Investigations should start by 
analyzing first the sequence of input frames and its dependencies, and 
try to extract existing and hidden parallelisms. 
附件二 
