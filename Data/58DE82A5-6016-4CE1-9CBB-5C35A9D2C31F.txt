然而，要管理這樣複雜的設計，就必須有
一套作業系統能不只管理軟體工作和資源，也
要同時管理硬體工作和相關的FPGA資源。這
個計劃的目標是設計並且實作出一個支援可
重組系統的作業系統。我們在計畫中探討的研
究議題包含以下所列。第一，OS4RS 核心提
供的基本服務以及其實作。第二，OS4RS 架
構的必備元件以及其實作。第三，OS4RS的基
本抽象化 (abstractions)以及其設計。第四，
OS4RS 的效能評估及改進的平台。 
為因應以上的議題，我們所提出的OS4RS 
提供基本的硬體管理服務，例如硬體工作的載
入、環境儲存、分割、排程及擺置。OS4RS 的
架構包含一個載入器、分割器、排程器及擺置
器。作業系統支援的抽象化將包含共用硬體工
作介面、軟硬體溝通介面及硬體工作的重置
性 。 OS4RS 的效能評估包含空間分片
(fragmented)面積、排成產量、工作反應時間及
工作可攜性。 
在這個計畫中，第一年，我們提出『可重
組式系統設計空間探索的框架工具』(Perfecto 
framework)，使其可以用於選擇或修改OS4RS
中的各個演算法，包含分割、排程與擺置。第
二年，我們去探討硬體工作的排程，加入我們
提出硬體可中斷的服務，設計一套針對即時可
重置工作的排程與空間配置演算法。第三年，
我們OS4RS的設計引入階層式的方法來提高
系統的彈性及擴充性，並加入可重組硬體設計
虛擬化的機制來進一步提高可重組式硬體設
計的使用率。除了匯流排(Bus)的支援外，我們
的OS4RS也進一步支援晶片的網路溝通架構
(Network-on-Chip, NoC)，以提高硬體工作的平
行 度 及 系 統 效 能 。 其 中 ， 包 含 Perfecto 
framework[11]以及即時可重置工作的排程
(RHSS)，都已經發表於兩篇國際頂尖期刊論
文 ACM Transactions on Reconfigurable 
Technology and Systems。 
三、 研究方法及成果 
在一個嵌入式系統中通常同時存在軟體
功能元件和硬體功能元件。用軟體來實現功能
通常有較佳的彈性，但是執行效能則較差。而
用硬體來實現功能在執行效能會比軟體來的
好，可是成本也相對的提高許多且系統會比較
缺乏彈性。為了要在系統效能與彈性之間取得
一個平衡，動態部分重組式系統變成了一個可
行的方法，可以同時有軟體程序執行在微處理
器上及硬體模組執行在FPGA裝置上，並且工
作可以從軟體切換到硬體或硬體切換到軟
體。在這樣如此有彈性的系統中要管理所有的
資源是相當複雜的，所以我們就需要一個針對
動態部分重組式系統的作業系統來管理這些
軟硬體工作與資源。 
類似網路OSI七層的方法，我們設計一個
階層式可重組式系統的作業系統設計(如圖
1)，包含application、function、management、
interface、communication和configuration六個階
層設計。在這樣分層的架構下，每層的設計都
是獨立且透明，在符合各層之間的溝通介面
下，各層都可以各自開發。我們也提出統一化
的 溝 通 機 制 (Unified Communication 
Mechanism) [9] ， 新 的 硬 體 功 能 只 要 和
configuration階層的可部分重組式硬體工作模
組 (Partially Reconfigurable Hardware Task 
Template, PR template) [9, 10, 14]整合，並更新
function 階層的硬體控制資料庫 (Hardware 
Control Library)，新的硬體功能便可以在
OS4RS上執行，有助於系統的開發。 
在Management階層，為了減少FPGA上碎
裂空間的問題，我們提出了一套針對即時可重
置工作的排程與空間配置演算法 [3, 42]，使得
這些工作可以滿足各自的時間限制，並且可以
讓裝置上的碎裂變得更少；考慮到系統加入硬
體可中斷的能力，我們提出了一個可重置軟硬
體排程的方法(Relocatable Hardware-Software 
Scheduling, RHSS) [1, 25] (如圖2)，利用偷取工
 
圖3. Perfecto模擬流程 
 
硬體切割、排程和硬體工作配置演算法都可以
依據不同的可重組式系統設計而調整, 而應
用模組是一組有方向性的工作圖  (task 
graph)。當使用者給定一個系統架構模組及應
用模組，Perfecto將可以自動使用SystemC的交
易層模組(Transaction-Level Models, TLM)來
模擬並分析不同的可重組系統的設計。因此，
包含軟硬體的切割、匯流排的存取衝突、即時
系統的排程與硬體工作在FPGA上的配置的演
算法都可以很方便的被評估，做為實現一個可
重組式系統的依據。該成果在計劃第二年也已
經刊登於國際頂尖期刊 ACM Transactions on 
Reconfigurable Technology and Systems。 
為了進一步提升可重組式硬體功能的使用
率，在Interface階層我們提供硬體資源虛擬化
的機制 (Hardware Virtualization Mechanism) 
[9] ( 如 圖 4) ， 包 含 邏 輯 虛 擬 化 (Logic 
Virtualization)和硬體裝置虛擬化 (Hardware 
Device Virtualization)。 
在有兩個以上軟體應用要求硬體功能
 
圖4. 硬體虛擬化機制 
 
HW1時，系統將啟動邏輯虛擬化的機制。如圖
4(a)所示，Application2會透過另一個裝置節點
(/dev/comm3)和kernel module對應到相同的
HW1的硬體電路，系統會利用Application1在
使用HW2硬體電路時，讓Application2使用
HW1硬體電路。對Application1和Application2
而言，因它們是屬於user space的應用程式，因
此各自認定擁有HW1硬體電路的使用。然而，
在即時系統的需求下，對Application1而言，
不斷地open和close會造成應用的負擔，會盡量
減少這樣的動作以保護其QoS。然而，使用邏
輯虛擬化的方式可以透過系統kernel space內
部的控制，達到如同pipeline的效果，有效地
應用硬體資源，而當Application的數量越多，
對系統整體而言將可以得更好的QoS。 
當系統接受到Application要求依序存取HW1
和HW2時，系統將啟動硬體裝置虛擬化的機
制。如圖4(b)所示，系統會將原本連接HW1的
kernel module再連到HW2，透過這樣的方式，
HW1的結果可以直接透過kernel module傳到
HW2，不用再經過kernel和user space這樣
loading很大的資料搬移的過程，最後再利用
HW2對應的裝置節點(/dev/comm2)將結果存
回user space，達到應用加速的效果。透過這個
硬體虛擬化的機制，device nodes、kernel 
modules和on-demand可重組式硬體功能將可
以依據不同的系統應用需求動態連結，不再是
以前的一對一關係。在一個動態可重組式的網
路安全系統中，相對於使用一般Linux的方
法，硬體資源虛擬化的機制將可以讓更多的軟
硬體使用量也較低，而分享式記憶體架構可達
到較佳的執行時間，但相對來說，所付出的硬
體成本將會較高。而在可重組式NoC內部，我
們也提出一個新型態的封包交換網路交換器 
[4, 17]。透過我們提出的仲裁機制，不僅可提
供服務品質支援，還可避免封包飢餓的情形發
生。基於回合式優先權的概念，且透過我們的
估算模型，將時機。舉例來說，使用單一輸出
FIFO架構的執可預測出最短及最長的封包傳
輸延遲。在所呈現的實驗結果中：於公平性比
較，回合式優先權優於純粹優先權；於服務品
質支援中，回合式優先權勝過輪轉式仲裁。在
傳輸延遲預測方面，當晶片網路中沒有擁塞發
生及過於頻繁的動態重組，藉由估算模型所產
生的預測，其命中率可高達 90%。 
    另一方面，由於有越來越多的程式在NoC
上執行，這些程式間的運算及溝通造成了NoC
上能源消耗及電路干擾的現象。為了減低這些
問題的影響，我們同樣的利用動態可重組的技
術來動態載入和應用需求相對應的編碼方
法，藉此降低傳輸過程中因為複雜的電位變化
(bit transitions)而造成的能源消耗及電路干擾 
[5, 15]。為了管理此動態可重組式NoC，我們
提供一個類神經網路(Artificial Neural Network, 
ANN)學習架構來根據不同的需求管理底層硬
體電路的重新組態，藉此來充分發揮動態可重
組的功能，以達到更高的彈性、更佳的硬體資
源使用率、更低的干擾現象及能源消耗。當我
們考慮到平均每道指令的干擾率，應用領域，
以及不同的系統特性時，與傳統的NoC架構相
比，在付出同樣的負擔下(效能及硬體資源)，
我們所提出的可重組式NoC架構可達到71%, 
32%, 以及277%的平均crosstalk干擾和動態功
率消耗減少率。 
就傳統硬體設計來說，並不像軟體工作如
此具有彈性，在動態部分可重組的架構亦是如
此，就算是具有較高優先權的硬體工作，仍必
須等待已經在 FPGA 上執行的較低優先權硬
體工作完成，釋放其所佔的 FPGA 資源後，才
 
圖 7. 硬體重組專用 Wrapper 架構 
 
可以使用其 FPGA 資源。為了達到類似軟體工
作可被中斷和內文交換的能力，目前研究方法
可分為 reconfiguration-based和 design-based兩
種。我們採用 design-based 的方式，在
configuration 階層提出一個動態可切換的硬體
設計方法[12, 24, 30, 32]，使正在 FPGA 上執行
的低優先權的硬體工作先暫停目前執行，把所
佔用的 FPGA 資源釋放給高優先權的硬體工
作使用，等到硬體排程器決定讓其執行，並再
次規畫到 FPGA，便會由之前切出去的狀態往
下繼續執行。為了使一個硬體電路具有可動態
切換的能力，我們提出 generic wrapper [12, 24, 
30, 32] (如圖 7)的設計來整合硬體電路。我們
的 wrapper 設計包一個 context buffer 來暫存硬
體電路的 context data，一個資料轉換元件 
(Data Transformation Component, DTC) 將
context data 封裝成可以儲存在 context buffer
的格式。DataPath 元件負責一般的信號傳送，
而 swap controller 負責主要的切換機制。 
我 們 提 出 generic wrapper 可 分 成 Last 
低功率和降低空間碎裂等議題，我們也提出數
個相對應的演算法，也都順利發表在期刊與國
際會議。除了匯流排的系統溝通架構外，NoC
的溝通架構的設計也已經考慮在我們的
OS4RS 的設計，並有初步的成果發表在國際會
議。另外，針對可重組式系統的設計空間探
索，我們提出 Perfecto 和基於 UML 的軟硬體
設計平台，將可以提供系統實作前的效能和管
理方法的評估，也都發表成果在期刊與國際會
議中。 
本研究群的相關研究結果，由 94 年開始，
我們研究團隊已發表期刊 7 篇、會議論文 20
篇、書籍著作 1 本和 14 篇碩士論文。 
 
五、參考文獻 
1. P.-A. Hsiung, C.-H. Huang, J.-S. Shen, and C.-C. 
Chiang, "Scheduling and Placement of 
Hardware/Software Real-Time Relocatable Tasks in 
Dynamically Partially Reconfigurable Systems," ACM 
Transactions on Reconfigurable Technology and 
Systems (TRETS), 2009 (to appear). 
2. P.-A. Hsiung, M. D. Santambrogio and C.-H. Huang, 
Reconfigurable System Design and Verification, CRC 
Press, USA, ISBN: 978-1420062663, 2009. 
3. P.-A. Hsiung, C.-H. Huang, and Y.-H. Chen, 
"Hardware Task Scheduling and Placement in 
Operating Systems for Dynamically Reconfigurable 
SoC," Journal of Embedded Computing (JEC), Vol. 3, 
No. 1, pp. 53-62, IOS Press, 2009 
4. C.-H. Lu, K.-C. Chiang, and P.-A. Hsiung, 
"Round-based Priority Arbitration for Predictable and 
Reconfigurable Network-on-Chip," Proceedings of 
the International Conference on Field-Programmable 
Technology (FPT), December 2009.  
5. J.-S. Shen, C.-H. Huang, and P.-A. Hsiung, 
"PRESSNoC: Power-Aware and Reliable Encoding 
Schemes Supported Reconfigurable Network-on-Chip 
Architecture," Proceedings of the Fourth 
International Conference on Embedded and 
Multimedia Computing, (EM-Com), December 2009. 
6. C.-H. Lu, H.-W. Liao, and P.-A. Hsiung, 
"Multi-Objective Placement of Reconfigurable 
Hardware Tasks in Real-Time System," Proceedings 
of the International Workshop on Reconfigurable and 
Multicore Embedded Systems, (WoRMES), IEEE CS 
Press, August 2009. 
7. W.-W. Lin, “Reconfigurable NoC with OS 
Management,” M.S. thesis, Department of Computer 
Science and Information Engineering, National Chung 
Cheng University, Chiayi, Taiwan, June, 2009. 
8. C.-T. Lan, “Hardware Mediator for Reconfigurable 
Hardware-Software Systems,” M.S. thesis, 
Department of Computer Science and Information 
Engineering, National Chung Cheng University, 
Chiayi, Taiwan, June, 2009. 
9. C.-H. Huang and P.-A. Hsiung, "Hardware Resource 
Virtualization for Dynamically Partially 
Reconfigurable Systems," IEEE Embedded Systems 
Letters (ESL), Vol. 1,  Issue 1,  pp. 19-23, May 
2009.(DOI: 10.1109/LES.2009.2028039)  
10. C.-H. Huang and P.-A. Hsiung, "On the Use of a 
UML-Based HW/SW Co-Design Platform for 
Reconfigurable Cryptographic Systems," Proceedings 
of the IEEE International Symposium on Circuits and 
Systems (ISCAS), pp. 2221-2224, IEEE Press, May 
2009. 
11. P.-A. Hsiung, C.-S. Lin, and C.-F. Liao, "Perfecto: A 
SystemC-based Design Space Exploration Framework 
for Dynamically Reconfigurable Architectures," ACM 
Transactions on Reconfigurable Technology and 
Systems (TRETS), Vol. 1, No. 3, Article 17, 
September 2008. 
12. C.-H. Huang and P.-A. Hsiung, "Software-Controlled 
Dynamically Swappable Hardware Design in Partially 
Reconfigurable Systems," EURASIP Journal on 
Embedded Systems, vol. 2008, Article ID 231940, 11 
pages, 2008. doi:10.1155/2008/231940. 
13. J.-S. Shen, W.-W. Lin, and P.-A. Hsiung, "Efficiently 
Reconfigurable NoC with Operating System Support," 
Proceedings of the Conference on Innovative 
Applications of System Prototyping and Circuit 
Design, October 2008. 
14. C.-H. Huang and P.-A. Hsiung, "UML-Based 
Hardware/Software Co-Design for Partially 
Reconfigurable Systems," Proceedings of the 13th 
IEEE Asia-Pacific Computer Systems Architecture 
Conference (ACSAC), August 2008. (DOI: 
10.1109/APCSAC.2008.4625436. 
15. J.-S. Sheng, P.-A. Hsiung, and K.-C. Chang, "A 
Novel Spatio-Temporal Adaptive Bus Encoding for 
Reducing Crosstalk Interferences with Trade-Offs 
Between Performance and Reliability," Proceedings 
of the 13th IEEE Asia-Pacific Computer Systems 
Architecture Conference (ACSAC), August 2008. 
16. C.-H. Lu, H.-W. Liao, and P.-A. Hsiung, 
"Multi-Objective Placement of Reconfigurable 
Hardware Tasks in Real-Time Systems," Proceedings 
of the VLSI Design / CAD Symposium, August 2008. 
17. K.-C. Chiang, “Predictable and Adaptive 
Reconfigurable Network-on-Chip,” M.S. thesis, 
37. Y.-H. Chen and P.-A. Hsiung, "Hardware Task 
Scheduling and Placement in Operating Systems for 
Dynamically Reconfigurable SoC," Proceedings of 
the 2005 IFIP International Conference on Embedded 
and Ubiquitous Computing (EUC'2005), Lecture 
Notes in Computer Science (LNCS), Vol. 3824, pp. 
489-498, Springer Verlag, December 2005. 
38. C.-H. Tseng and P.-A. Hsiung, "UML-based Rapid 
Prototyping Design Flow for Dynamically 
Reconfigurable Computing Systems," Proceedings of 
the VLSI Design / CAD Symposium, August 2005.  
39. C.-F. Liao and P.-A. Hsiung, "A SystemC-based 
Performance Evaluation Framework for Dynamically 
Reconfigurable SoC," Proceedings of the VLSI 
Design / CAD Symposium, August 2005. 
40. C.-F. Liao. “A SystemC-Based Performance 
Evaluation Framework for Dynamically 
Reconfigurable SoC” Master’s thesis, Department of 
Computer Science and Information Engineering, 
National Chung Cheng University, Taiwan, ROC., 
June 2005. 
41. C.-H. Tseng. “UML-Based Rapid Prototyping Design 
Flow for Dynamically Reconfigurable Computing 
Systems” Master’s thesis, Department of Computer 
Science and Information Engineering, National Chung 
Cheng University, Taiwan, ROC., June 2005. 
42. Y.-H. Chen. “Hardware Scheduling and Placement in 
Operating Systems for Reconfigurable SoC” Master’s 
thesis, Department of Computer Science and 
Information Engineering, National Chung Cheng 
University, Taiwan, ROC., June 2005. 
 
2 · Pao-Ann Hsiung et al.
most applications are executed by hardware chips to increase computing power, the
system will have unacceptably high energy consumption. With the rapid progress in
digital convergence through integration of complex applications, it has become in-
creasingly difficult to achieve a good tradeoff between computing power and energy
consumption.
Hardware is characterized by high computing power with high energy consump-
tion, while software is characterized by low computing power with low energy con-
sumption. Under this observation, to achieve a good tradeoff between computing
power and energy consumption simply amounts to trading off between hardware
and software. However, conventional embedded systems have fixed hardware and
software, which makes this trade-off difficult. As a solution to this issue, run-time
reconfigurable logic devices such as FPGA has made possible the dynamic switch-
ing between hardware and software implementations of the same function. This
is the general motivation for this work on scheduling tasks that can dynamically
switch between their hardware and software implementations. With increasing sys-
tem workload, a multimedia task that requires high computing power can switch
from software to hardware. With decreasing battery energy, a network application
that requires high energy consumption can switch from hardware to software.
With the advent of the run-time partial reconfiguration technology in FPGA
devices such as Xilinx Virtex series, hardware designs can now be preempted and
restored just like software tasks. The gradually fading distinction between hard-
ware and software has made possible for a function to be executed both as soft-
ware on microprocessors and as hardware in reconfigurable logic. As a result, the
hardware-software partitioning of a system can be dynamically changed through
task relocation, which preempts a hardware task and restores it as a software task
with the same functionality, or vice-versa. For task relocation, system architectural
support such as a common unified communication interface is required among hard-
ware and software tasks. A typical state-of-the-art example is the POSIX threads
API that is used by both software pthreads and hardware hthreads [Andrews et al.
2008; Peck et al. 2006]. However, task relocation requires hardware reconfigura-
tions which take a significant amount of time, probably affecting the schedulability
of the tasks, and also consume a significant amount of power, effectively shortening
the system life-time. Thus, we also need an efficient relocatable task scheduler,
which can maximize the utilization of reconfigurable hardware resources, while still
satisfying all real-time and energy constraints of the tasks.
Most existing methods schedule hardware and software tasks separately and do
not consider dynamic relocation of the tasks. An exception, the Adaptive Hardware-
Software Allocation (AHSA) method [Pellizzoni and Caccamo 2006] considers dy-
namic task relocation and aims to maximize reconfigurable hardware utilization.
But the method uses a group-wise swap operation between hardware and software
tasks such that not only is the algorithm computationally expensive, but is also
not quite feasible under real hardware placement restrictions. The algorithm time
complexity is quadratic in the number of tasks and it does not consider the restric-
tion of contiguous area requirements of hardware tasks. In this work, we propose
a much simpler Relocatable Hardware-Software Scheduling (RHSS) method whose
time complexity is linear in the number of hardware tasks. Compared to AHSA,
ACM Transactions on Reconfigurable Technology and Systems, Vol. V, No. N, Month 20YY.
4 · Pao-Ann Hsiung et al.
switching from one implementation to another at the preemption points allows
continued correct execution of the function. In Figure 2, state S in software and
state T in hardware constitute a pair of matching preemption points. For example,
a Discrete Cosine Transform (DCT) function could be designed, in both hardware
and software, to preempt after processing a block of 8 × 8 pixels, but before the
full image is transformed. In DPRS, a hardware implementation could be a partial
bitstream that is used to configure the desired function into Xilinx FPGA devices,
and a software implementation is simply an executable program.
S
T
SW
HW
SW to HW 
relocation
HW to SW 
relocation
Fig. 2. Relocatable Tasks
Informally, our target problem can be stated as follows. Given a dynamically
partially reconfigurable system with a reconfigurable resource area of limited size
and a set of relocatable tasks with real-time constraints, we need to find a run-time
feasible schedule for the tasks such that all task-related and architecture constraints
are satisfied and the hardware resource utilization is maximized. In proposing a
solution to this problem, the main issues are as follows.
—How do we determine the initial system partitioning into hardware and software
tasks?
—How do we identify the scheduling points at which the system partitioning may
have to be modified?
—How can we satisfy task constraints such as deadlines and architecture constraints
such as RRA size limit?
—What are the criteria to follow for performing dynamic hardware-software parti-
tioning?
—How do we maximize hardware resource utilization?
Our proposed solution to the target problem will answer the above questions as
follows.
—A greedy admission policy is used such that a newly arrived task is always first
executed as software, while it is being configured into hardware if there is enough
resources in RRA.
—Two scheduling points are identified including when a hardware task terminates
and when a new task arrives into the system.
—All constraints are checked before a relocation is performed. A task relocation is
rejected if constraints are violated.
ACM Transactions on Reconfigurable Technology and Systems, Vol. V, No. N, Month 20YY.
6 · Pao-Ann Hsiung et al.
of the scheduling horizon list. The free space list is a set of intervals [x1, x2] that
identifies currently unused resource intervals. When a task arrives, the stuffing
scheduler will find a suitable space from the free area. The stuffing technique has
better performance than the horizon method.
An improved version of stuffing called classified stuffing was proposed by Chen
and Hsiung [Chen and Hsiung 2005] to reduce fragmentation in RRA. In this
technique, two lists were used to record placement information, namely task list
and space list. The task list stores information of tasks placed into FPGA, and
the space list provides information for the placer to find a suitable free space for
a task. Based on the RRA space utilization ratio (SUR), tasks were classified into
two types. The placer used different placement strategies for the two types of tasks.
This technique shows significant benefits in both a shorter schedule and a compact
placement.
As far as pure placement strategies are concerned, existing methods usually target
at different goals, including the reduction of RRA fragmentation such as in best-
fit placement [Bazargan et al. 2000], adjacency-based heuristic and fragmentation-
based heuristic placements [Tabero et al. 2004], and fragmentation-aware placement
[ElFarag et al. 2007], the minimization of average routing costs for communicating
hardware tasks [Ahmadinia et al. 2004; Ahmadinia et al. 2004; Ahmadinia et al.
2005], the efficiency in placing a task such as in first-fit and bottom-left placements
[Bazargan et al. 2000], and the reduction of configuration overhead such as in least-
interference-fit [Ahmadinia and Teich 2003]. A multi-objective hardware placement
method [Liao 2007] was also proposed recently to target at satisfying multiple goals
at the same time, including the minimization of fragmentation, minimization of the
routing resources, and minimization of the time for location selection.
Besides the above fitting strategies, the efficiency of resource management has
also become a major concern because it is quite time consuming to maintain the
data structures such as the task list, the free space list, and the reserved space
list during dynamic placement. Well-known methods include the maximal empty
rectangles (MER) [Bazargan et al. 2000; Handa and Vemuri 2004], the contour
of union of rectangles (CUR) [Ahmadinia et al. 2004], the non-overlapping empty
rectangles (NER) [Bazargan et al. 2000], 2D Hash structure [Steiger et al. 2003;
Walder et al. 2003], staircase data structure [Handa and Vemuri 2004], and vertex
list set [Tabero et al. 2004]. In contrast to the above methods that record free
spaces, Ahmadinia et al. recorded the occupied spaces instead [Ahmadinia et al.
2004; Ahmadinia et al. 2005], which grow more slowly than the free spaces. A very
good comparison among the various data structures such as MER, CUR, NER, and
Hash, in terms of the placement quality, time complexity, space complexity, and
applicable fitting strategies, can be found in the core allocation strategy proposed
by Morandi et al. [Morandi et al. 2008].
Among all the existing hardware-software coscheduling methods, very few address
the issue of scheduling relocatable tasks. The method that most closely matches
ours is the Adaptive Hardware-Software Allocation (AHSA) method proposed by
Pellizzoni and Caccamo [Pellizzoni and Caccamo 2006], which consists of a greedy
allocation algorithm for generating the initial hardware-software system partition
and a group-based system-wide swapping algorithm for dynamically changing the
ACM Transactions on Reconfigurable Technology and Systems, Vol. V, No. N, Month 20YY.
8 · Pao-Ann Hsiung et al.
—Rtype is the type of reconfiguration technology. This could be paged 1D (slot-
based), segmented 1D, or 2D. In RHSS, we choose the segmented 1D model
because that is the most flexible reconfiguration technique available for Virtex II
Pro FPGAs.
—Rctrl is the reconfiguration controller. In RHSS, we choose the Xilinx ICAP
reconfiguration controller.
—Rarea is the size of the RRA, which is the maximum amount of reconfigurable
resources available for hardware tasks. The units could be columns of CLB
(Configurable Logic Blocks) for 1D reconfiguration as in Xilinx II Pro FPGA or
tiles of CLB for 2D reconfiguration as in Xilinx 4 and 5 series of FPGAs.
—Rplace is the placement algorithm used for hardware tasks. We will discuss the
low-fragmentation placer implemented in RHSS in Section 4.4.
—Rswitch is the method for hardware preemption and for context save and restore.
We adopt the generic wrapper design model [Huang et al. 2007; Huang and
Hsiung 2008] for hardware preemption, context saving, and restoring.
The software, the hardware, and the communication characteristics of a DPRS
system model directly influence how relocatable tasks are to be scheduled because
without the support of the operating system having a software task scheduler and
a hardware task placer, the hardware preemption techniques, and the unified task
communication interfaces, scheduling relocatable tasks becomes impossible. Nev-
ertheless, when all the parameters of the system model have taken appropriate
values, the scheduling of relocatable tasks becomes feasible. We further define the
task model as follows.
3.2 Relocatable Task Model
Besides being a basic unit of computation and an atomic target for scheduling,
a task, as mentioned in Section 1, is called relocatable if there are at least two
different implementations of the same function with one or more pair of matching
preemption points. A relocatable task is formally defined as follows.
Definition 2. Relocatable Task. A relocatable task Ti with index i is defined
by the tuple 〈ai, di, pi, ki, T si (SEi, Ui), Thi (HEi,HCi,HSi), Pi〉, where, given N as
the set of integers,
—ai ∈ N ≥0 is the arrival time,
—di ∈ N >0 is the relative deadline,
—pi ∈ N >0 is the period,
—ki ∈ N >0 is the number of jobs (periods) the task is supposed to be executing
before it terminates,
—T si (SEi, Ui) is the software implementation of the task with worst case execution
time SEi and microprocessor utilization Ui,
—Thi (HEi,HCi,HSi) is the hardware implementation of the task with worst case
execution time HEi, configuration time HCi, and reconfigurable resource re-
quirement of HSi units (columns or tiles), and
—Pi is the task priority.
ACM Transactions on Reconfigurable Technology and Systems, Vol. V, No. N, Month 20YY.
10 · Pao-Ann Hsiung et al.
Table I. Example Task Set
Ti ai di pi ki SEi Ui = SEi/pi HEi HCi HSi Pi = Ui/HSi
T1 0 16 16 7 6 3/8 4 10 1 3/8
T2 0 24 24 3 12 1/2 10 20 2 1/4
T3 0 48 48 3 6 1/8 6 20 2 1/16
T4 40 8 8 8 2 1/4 1 5 2 1/8
T5 58 12 12 5 7 7/12 3 9 3 7/36
From this small example, we can already observe that it is neither straightforward
nor easy to check if the set of tasks T is schedulable in the system S or not. This
also shows the motivation for our work. The complexity in schedulability checking
is mainly due to two reasons, namely the dynamic reconfigurability of the system
and the relocatability of the tasks. The scheduling results for this system will be
illustrated in Section 4 after we propose the RHSS method.
3.5 System Architecture
To support hardware-software task relocation, we now present a physically feasible
system that fits the DPRS system model given in Definition 1. Figure 3 illustrates
a reconfigurable system implemented on the Xilinx ML310 platform containing a
Virtex II Pro XC2VP30-FF896 FPGA device, two PowerPC (PPC) 405 hard cores,
256 MB DDR DIMM, 512 MB CompactFlash (CF) card, RS-232 port, and JTAG
port. We implemented this reconfigurable architecture with an operating system
for reconfigurable systems (OS4RS) running on one of the PPC405 processor cores
attached to the Processor Local Bus (PLB) along with SDRAM memory. Self-
reconfiguration was made feasible by attaching an ICAP device through a hardware
ICAP interface (HWICAP) to the On-Chip Peripheral Bus (OPB) bus. The recon-
figurable region constitutes the dynamically reconfigurable part of the architecture,
while the rest are statically configured as the top module of the system. The re-
configurable region is attached to the OPB via a set of Xilinx bus macros (tri-state
buffers) such that the reconfiguration performed in the reconfigurable region does
not affect the static part. The partial bitstreams corresponding the hardware tasks
are all stored in the CF card.
In this architecture, hardware and software are implemented as hardware threads
called HThreads and software threads called PThreads. Since HThreads and PThreads
adopt the same set of POSIX standard application programming interface (APIs),
they can communicate seamlessly. The OS4RS was an extension of the Linux OS
with a scheduler, a placer, ICAP driver, and an implementation of POSIX APIs.
It must be noted that usually in a reconfigurable system, due to the FPGA device
restriction and heterogeneity, a partial bitstream must the manipulated before we
can configure it into a desired location in the reconfigurable region. This bitstream
manipulation can be performed either using a software tool such as PARBIT [Horta
and Lockwood 2001] and BanMaT [Corbetta et al. 2007] or a hardware filter such
as REPLICA [Porrmann et al. 2005] and BiRF [Corbetta et al. 2007]. Since bit-
stream relocation is out-of-scope here, we do not go into the details of such tools or
filters, rather we assume that the partial bitstream of a hardware for each possible
location is generated at design time and stored in the CF card. We know that this
takes up a lot of space. We will improve on this by using the manipulation tools or
ACM Transactions on Reconfigurable Technology and Systems, Vol. V, No. N, Month 20YY.
12 · Pao-Ann Hsiung et al.
Relocatable
HW/SW 
SchedulerSoftware 
Tasks
Hardware 
Tasks
Relocatable
Tasks
Placer
FPGA
EDF 
Scheduler
System 
Configurations
Microprocessor
Context 
(re)store
Common 
HW-SW Task 
Interface
Fig. 4. Relocatable Hardware-Software Scheduling Flow
input: a list Q of ready tasks, sorted by decreasing order of priorities
begin
Rleft ← Rarea
foreach Ti ∈ Q do
if HSi ≤ Rleft then
hi ← 1
Rleft ← Rleft −HSi
else
hi ← 0
end
end
end
Algorithm 1: Greedy Initial Scheduling Algorithm
of resources currently left remaining in RRA, which is initialized as the total area
Rarea of the RRA. The algorithm scans through the ready list to determine the
tasks that can be executed on the reconfigurable device. The tasks with higher
priorities will be placed first until the area of the device is fully occupied.
However, all currently available FPGA devices only allow sequential hardware
configurations because of a single configuration controller in each device. Hence, a
task that is initially scheduled as hardware, might miss its deadline in the first few
periods. For our illustration example in Table I, tasks T2 and T3 are configured se-
quentially only after T1 is configured because of their task priorities. However, they
both will miss their deadlines in the first periods. For example, T1 requires 10 ms
and T2 requires 20 ms for hardware configurations, which add up to 30 ms, however
the deadline of T2 is 24 and is violated when T2 is configured at 30. Similarly, task
T3 requires 20 ms for configuration and thus when it is configured at time 50, the
deadline 48 of T3 is already violated. To solve these initial deadline violations, such
ACM Transactions on Reconfigurable Technology and Systems, Vol. V, No. N, Month 20YY.
14 · Pao-Ann Hsiung et al.
the new task. If there exists a hardware task Tj with lower priority (Pj < Pi), its
area HSj is not smaller than that of the new task (HSj ≥ HSi), and Uj+Ucpu ≤ 1,
then Tj is replaced by the new task Ti. Note that from the above 3 conditions,
Uj < Ui. However, if no single task can be replaced by the new task, the scheduler
will try to find a set of tasks to be replaced. Algorithm 4 is the algorithm for the
function FindSwitchTaskSet(). It scans through the hardware tasks to remove all
tasks with priorities higher than that of the new task, and puts the remaining into
a list. It continues scanning through the list to remove all tasks in contiguous areas
that are smaller than that of the new task. Then, it selects a task set R with the
most suitable area (best-fit) that at the same time satisfies the feasibility conditions
given in Definition 3, which specifies that the sum of the utilization of task set R
and the original utilization on the microprocessor must not exceed 1 because this
replacement must not affect other tasks currently running on the microprocessor,
and the utilization of the task set R must not be larger than the utilization of
task Ti. If the feasibility conditions are met, the task set R will be returned by
Algorithm 4. Task set R will thus be replaced by the new task Ti.
input: arrived-task Ti
begin
if SearchEnoughArea(Ti) = true then
PlaceTask(Ti)
else if HaveLowPriorityHw(Ti) = true then
// (Find a single hw task for replacement)
foreach Tj ∈ Th with Pj < Pi do
if HSi ≤ HSj + FreeArea(HSj) and CheckFeasibility({Tj}, Ti)
then
// (FreeArea(HSj): total free area adjacent to HSj)
WaitUntilNextSwitchPoint(Tj)
AddSwReadyQueue(Tj)
PlaceTask(Ti)
return
end
end
// (Find a set of hw tasks for replacement)
R← FindSwitchTaskSet(Ti)
if R 6= φ then
AddSwReadyQueue(R)
PlaceTask(Ti)
else
StayInSw(Ti)
end
else
StayInSw(Ti)
end
end
Algorithm 3: Scheduling at New Task Arrival
ACM Transactions on Reconfigurable Technology and Systems, Vol. V, No. N, Month 20YY.
16 · Pao-Ann Hsiung et al.
The placer uses two lists to record the allocation situations in the RRA. The
free area list Lfree is used to record the free areas in RRA, and the task area list
Ltask is used to record areas currently occupied by tasks. Initially, Lfree = {A0}
and Ltask = {}, where A0 is the full RRA, i.e., |A0| = Rarea and |A| is the size
of a free area A in terms of columns. The new tasks are placed in the RRA
starting from the left side, i.e. from the leftmost CLB column. After the scheduler
determines that a task Ti is ready to be placed in the RRA, the placer will select
a free contiguous area Aj that is at least as large as and best fits the size of the
task, that is Aj ∈ {Ak | |Ak| = min|A|≥HSi(A ∈ Lfree)}. The placer removes the
selected free area Aj from the free area list and adds a new free area A
′, such that
|A′| = |Aj | − HSi, that represents the area left over after Ti is placed. The free
area list is thus updated as follows: Lfree = Lfree\{Aj} ∪ {A′}. Specifically, if
|Aj | = HSi, then Lfree = Lfree\{Aj}. Further, the placer also adds the newly
allocated task area to the occupied list, that is, Ltask = Ltask ∪ {Aj}.
The above method is basically the best fit placement strategy. However, to re-
duce the external fragmentation in segmented 1D placement, we propose a Reduced
Fragmentation Placement (RFP) method. If the size of the selected free area Aj is
greater than the size of the task Ti, that is |Aj | > HSi, then the placer will check,
from the task area list, the finish times of tasks that have been placed on the two
sides of this free area. If the task on the left side of Aj will finish first, then the
new task Ti would be placed towards the rightmost column of the free area. If the
task on the right side of Aj will finish first, then the new task Ti will be placed
towards the leftmost column of the free area. As a result, when the early-finishing
task Ak terminates, the original remaining area A
′ can be combined with the area
freed by that task into one contiguous area 〈Ak, A′〉, where 〈. . .〉 represent merging
of two areas into one contiguous area.
In the special case of Aj being adjacent to only one task and the other side
being the periphery of RRA, then the new task Ti is placed towards the periphery
because we can think of the periphery as a task that never terminates. This kind
of placement strategy also helps reduce external fragmentation.
As an example, consider the situation shown in Fig. 5. We would like to place a
task with two columns into the reconfigurable area, and the free areas on the device
is of three columns and four columns. According to the best fit strategy, the placer
selects the three column area, which is larger than this task, so the placer will check
the finish times. The placer finds that the task on the left side of the three column
area will finish first, so it determines that the new task is to be placed towards
the rightmost column of the free area. As shown in Fig. 6, when the task on the
left side finishes, the remaining area will become a contiguous area of 3 columns.
The result is that there will be only two free areas of 3 columns and 4 columns. In
contrast, if the new task was placed adjacent to the early-finishing task Ak, then
when Ak terminates, there will be three free areas of sizes 2 columns, 1 column, and
4 columns. From this small example, it is evident how RFP reduces the external
fragmentation in segmented 1D placement.
Compared to the existing placement methods that target at reducing fragmenta-
tion such as best-fit [Bazargan et al. 2000], adjacency-based heuristic and fragmentation-
based heuristic [Tabero et al. 2004], and fragmentation-aware placement [ElFarag
ACM Transactions on Reconfigurable Technology and Systems, Vol. V, No. N, Month 20YY.
18 · Pao-Ann Hsiung et al.
P
la
c
e
m
e
n
ts
 in
 
R
R
A
CPU
(EDF)
time
2010 30 4032 50 5816
T1
T2
T3
T1,2 T1,3 T1,4
T3,2
T2,1 T3,1
48 64 70
T5,1
T4,1 T4,2 T4,3
T5
67
T4,4 T4,5
40 48 58 65 72
T5,2
73
0 18 24
T2,3
T2,2
T1,5
T4,8
96
… T3,3
98
…
T1,7
96
104
109
T5,4 T5,5…
T1,1
6 56
100
Fig. 7. RHSS Scheduling Results of Example
considered in AHSA and if the placement was at least linear in complexity, then
the actual complexity of AHSA would become at least O(n3).
4.6 Scheduling Illustration Example
We applied our relocatable hardware-software scheduling algorithm to the illustra-
tion example introduced in Section 3.4. Recall that the system is S = 〈PPC405,
EDF, CoreConnect, Pthreads/Hthreads, segmented 1D, ICAP, 5 columns, RFP,
Hardware Wrapper〉 and the set T of 5 tasks was specified in Table I. The RHSS
and AHSA scheduling results are shown in Figures 7 and 8, respectively, where the
upper part represents the software scheduling results using EDF and the lower part
represents the hardware scheduling results using RHSS and AHSA, respectively.
We observe that T is schedulable in S in both cases.
First, Algorithm 1, the initial scheduling algorithm, is applied to T for the first
three tasks T1, T2, T3 that have arrived at time 0. All three tasks are scheduled to
be executed eventually as hardware, except in their first periods. Since T1 has the
highest priority P1 = 1/2, it is placed first. As described in Section 4.1, all the 3
tasks are executed as software in their first periods, and then as hardware starting
from their second periods because after their hardware configurations are complete,
their deadlines will be violated, that is, HC1+HC2 > d2 and HC1+HC2+HC3 >
d3. Note that RHSS conforms to the current restriction of all FPGAs on sequential
configuration, that is, only one hardware configuration can be performed at a time.
Though AHSA does not consider placement restrictions explicitly, we impose the
same restriction on AHSA for a fair comparison. The three tasks are placed in
order of decreasing priority, that is, T1, T2, T3, and they occupy the full RRA of 5
columns.
At time 40, when task T4 arrives, there is no hardware task executing in RRA
that has priority lower than than of T4, hence Algorithm 3, the new task scheduling
algorithm in RHSS, decides that T4 should execute as software. However, as shown
in Figure 8, AHSA performs another greedy allocation at time 40, which results
in task T3 being preempted while it was still under configuration (not yet started
ACM Transactions on Reconfigurable Technology and Systems, Vol. V, No. N, Month 20YY.
20 · Pao-Ann Hsiung et al.
of tasks. More importantly, AHSA does not consider hardware configuration time
and placement restrictions explicitly, which results in non-realistic configuration
model. On the other hand, RHSS explicitly considers both configuration time
and placement restrictions.
—Performance: The time complexity of AHSA is O(n2), while that of our RHSS
algorithm is O(n), where n is the number of tasks. Our algorithm performs and
scales better when the number of tasks is very large. For the simple illustration
example, AHSA takes 60 ms and 20,480 bytes, while RHSS takes only 30 ms and
12,288 bytes.
—Resource Utilization: Intuitively, it might appear that AHSA will result in higher
RRA resource utilization, however the hardware configurations incurred by AHSA
is more frequent than that by RHSS, which results in RHSS giving a higher RRA
resource utilization. For the simple illustration example, AHSA results in 22.34%
and RHSS results in 30.06% hardware utilization, which shows that even for this
small example, RHSS improves over AHSA by 34.5%. The applications described
in Section 5 will illustrate this result further.
—Frequency of Configurations: As mentioned by the authors of AHSA [Pellizzoni
and Caccamo 2006], their method is not suitable for tasks with short inter-arrival
times because of the large number of reconfigurations incurred by group swap-
pings. RHSS does not perform group swappings, thus the number of reconfig-
urations is controlled and it is thus suitable for tasks with short inter-arrival
times such as real-time applications. For the simple illustration example, RHSS
incurred 8 reconfigurations and AHSA incurred 10 reconfigurations. Note that
before each task reconfiguration should be an empty reconfiguration (bitstream)
is required to reset the resources.
—Feasible Placements: AHSA does not explicitly consider placement feasibility,
instead AHSA restricts the sizes of groups to be swapped, uses dummy (place-
holder) tasks, and hopes the relocations are feasible. However, RHSS not only
considers task placement explicitly but also tries to reduce external fragmenta-
tion. At time 100, RFP in RHSS results in 2 columns being free, instead of 1
column as in conventional placement methods. Thus if we have a task of size
2 columns, then it can be configured at time 100. For a fair comparison, we
employed RFP for AHSA, too, as shown in Figure 8.
5. APPLICATION EXPERIMENTS
The proposed RHSS/RFP method and the state-of-the-art AHSA [Pellizzoni and
Caccamo 2006] method were both implemented in the standard C++ programming
language on a FreeBSD v6.2 workstation with two Intel Pentium 4 2.8 GHz CPUs
and 1 GB RAM. In the experiments, our target system was S = 〈PPC405, EDF,
CoreConnect, Pthreads/Hthreads, segmented 1D, ICAP, 100 columns, RFP, Hard-
ware Wrapper〉. We compared the performances of the two methods for randomly
generated task sets and also for a reconfigurable network security system example
that supports 5 different encryption/decryption functions including MD5, SHA-1,
DES, Triple-DES, and AES. The details of the experiments are discussed in the
rest of this section.
ACM Transactions on Reconfigurable Technology and Systems, Vol. V, No. N, Month 20YY.
22 · Pao-Ann Hsiung et al.
Table II. Six Cases of Random Task Sets
Case |T | pi SEi HEi HCi HSi
A Varying [80, 100] 3×HEi [1, 5] 5×HSi [1, 5]
B 50 Varying 3×HEi [1, 5] 5×HSi [1, 5]
C 50 [80, 100] Varying [1, 5] 5×HSi [1, 5]
D 50 [80, 100] 3×HEi Varying 5×HSi [1, 5]
E 50 [80, 100] 3×HEi [1, 5] Varying [1, 5]
F 50 [80, 100] 3×HEi [1, 5] 5×HSi Varying
Varying: 10 different value ranges
which Ti was executed as a hardware task. HU represents the total RRA area-
time utilization. Note that the original metric used by the authors of AHSA
[Pellizzoni and Caccamo 2006] for estimating hardware utilization was simply
HUAHSA =
∑
hi=1
Ui =
∑
hi=1
SEi/pi, which was an inaccurate estimation
because it did not consider the task size HSi and the actual number of jobs k
′
i.
In contrast, our metric HU gives a more accurate estimation by considering not
only HSi and k
′
i, but also HEi.
—Total simulation time (ST ), which is the total number of seconds a scheduler
takes for scheduling and placing all the tasks,
—Total memory usage (MU), which is the total amount of memory, in MB, a
scheduler requires for scheduling and placing all the tasks.
The resulting characteristics of RN , HU , ST , and MU for Case A are shown
in Figure 9. We can easily observe that RHSS performs better in terms of the
time and memory usage requirements for scheduling and placement of the tasks.
Compared to AHSA, the scheduling time ST is reduced by 43% to 80%, while the
memory usageMU is reduced by 50% to 92% in RHSS. This is intuitive because the
complexity of RHSS is linear, while that of AHSA is quadratic. As far as the quality
of the scheduling results is concerned, the RHSS scheduling results demonstrate
higher average hardware utilization (HU) consistently by at most 34.6% of that by
the AHSA scheduling results. This shows that RHSS can make better usage of the
limited hardware in RRA. For 150 tasks, the number of task rejections in RHSS is
around 29% more than AHSA, however when the number of tasks increases to 300,
RHSS rejects only 8% more tasks than AHSA. This shows that the number of tasks
rejected do not scale with the total number of tasks. RHSS sacrifices some tasks
for better hardware utilization and for more efficient scheduling and placement.
For the other five cases B to F, as illustrated in Figures 10 and 11, we only
show the amounts of improvements in HU , ST , and MU that RHSS scheduling
demonstrates over that of AHSA because the number of task rejections is almost
the same. A positive improvement means that RHSS outperforms AHSA, while
a negative one means AHSA outperforms RHSS. Out of the total 60 experiments
performed, for HU , we found RHSS outperforms AHSA in 52 experiments, AHSA
outperforms RHSS in 2 experiments, while they give the same results in 6 exper-
iments. In the two experiments that AHSA outperforms RHSS, namely the 6th
and the 7th experiments in Case F, AHSA generated only 0.28% and 0.79% higher
utilization than RHSS, respectively. We observe that for all 60 experiments, RHSS
requires significantly lesser CPU time and memory space requirements than AHSA.
From the six cases illustrated in Figures 9, 10, and 11, we can make the following
ACM Transactions on Reconfigurable Technology and Systems, Vol. V, No. N, Month 20YY.
24 · Pao-Ann Hsiung et al.
observations on the quality of the scheduling results from RHSS and AHSA and
their respective performances.
—In Cases B and D, the average hardware utilization (HU) increases rapidly with
the increasing average task utilization AU and with the increasing maximum
hardware execution time HEi. However, in case C, HU decreases rapidly with
the increasing software execution time SEi. Further, in Cases E and F, HU
is basically unaffected by either increasing hardware configuration time HCi or
increasing hardware task size HSi. All of the above results conform to our
expectations because HU is related to only the task execution time and period
represented by AU , HEi, and SEi.
—In 87% of the task sets, the scheduling results of RHSS demonstrated a higher
average hardware utilization HU , which shows that RHSS can make better uti-
lization of the limited RRA hardware resources than AHSA. Further, from the
HU curves on the right-hand-side RHSS vs. AHSA Improvements (%) graphs,
we can observe that RHSS can increase HU by more than 40% compared to
AHSA. The increase in hardware utilization by RHSS becomes significant, that
is more than 8% compared to AHSA, in each of the following situations: (a) large
number of tasks |T | ≥ 40 (Case A), (b) high average task utilization AU ≥ 0.08
(Case B), (c) limited software execution time SEi = c × HEi, c ∈ [1, 5] (Case
C), (d) limited hardware execution time 8 ≤ HEi ≤ 20 (Case D), (e) moderate
configuration time HCi = m×HSi, m ∈ [10, 70], HSi = [1, 5] (Case E). (f) small
and large maximum hardware task sizes, Max HS ∈ [5, 25] ∪ [40, 45] (Case F).
—As far as the number of task rejections is concerned, out of the total 60 experi-
ments performed, in 43 experiments RHSS and AHSA rejected the same number
of tasks. However, in 16 experiments, RHSS rejected more tasks than AHSA
to achieve a better hardware utilization and to make scheduling and placement
more efficient. Only in one experiment, RHSS rejected lesser tasks than AHSA.
—As far as the performance of the RHSS and AHSA methods are concerned, we
can observe from Figures 9, 10, and 11 that the total amount of time taken for
task scheduling and placement by AHSA is reduced by RHSS by at least 43.3%
to at most 89.5%, with an average reduction between 60% to 80%. Similarly,
in the case of memory usages, the reduction achieved by RHSS over AHSA is
at least 50% to at most 96.4%, with an average reduction between 80% to 90%.
Reductions occur for scheduling and placing each of the 60 task sets, which
strictly conforms to the linear time complexity of RHSS versus the quadratic
time complexity of AHSA.
5.2 Experiments with Real Data
Besides performing extensive experiments with random data by varying all the fea-
tures of a task set, we also evaluated the scheduling results and performance of
RHSS and AHSA when applied to real application data. Note that due to limited
resource in our Xilinx ML310 platform, we only simulated the experiments with in
this section. Our target application is a Dynamically Reconfigurable Network Secu-
rity (DRNS) system, which supports five different encryption/decryption functions
including MD5, SHA-1, DES, Triple DES, and AES. Each function has a software
ACM Transactions on Reconfigurable Technology and Systems, Vol. V, No. N, Month 20YY.
26 · Pao-Ann Hsiung et al.
 










U
ti
li
za
ti
o
n
 (
%
)








 
            
H
a
rd
w
a
re
 U
Hardware Configuration Time (Multiple of Task Size)
	


	

 





 	
 




  


 
 








           




 

 
ﬀﬁ
ﬂ


ﬃ
 !" #
 $%
&
' (
)* 
+
(
%
&
 
,
(-
#
 .
/
*0
+
(1
0#
 %
'
 
,
23
 4
(
5#6
78
9
Varying Hardware Configuration Time (Case E)
 
 












 
 
	
 


 

 












 





ﬀ

ﬁ
 
ﬂﬃ
  !
"ﬁ
#$%%
&$%&
 




	


 
 












 
 
 


  

	

ﬀ
ﬁﬂﬃﬁﬂ 
 
!
ﬁ"#
 $%
& 
'(
)
Varying Hardware Task Size (Case F)
Fig. 11. Hardware Utilizations and Improvements in Case (E)–(F)
and a hardware implementation. A task in DRNS executes one of the functions in
hardware or software. The DRNS system supports the dynamic relocation of the
tasks between the PowerPC 405 microprocessor and the 100 column RRA with the
aim of enhancing system performance through hardware acceleration and efficient
hardware resource usage.
The attributes of the five functions are shown in Table III. For each task, the
software execution time, the hardware execution time, the configuration time, and
the task size in number of columns are fixed as shown in Table III, however the
arrival time, the period, and the number of jobs are randomly generated for each
task, that is, ai ∈ [50000, 2000000], pi ∈ [HCi + 2000,HCi + 5000], ki ∈ [1, 3]. The
deadline is the same as the period for each task. In contrast to the random task
attributes, the real tasks do not exhibit an exact multiple relationship between SEi
and HEi. For example, the software and hardware execution times for MD5 are
almost the same, whereas the software execution time for the Triple DES is 28 times
the hardware execution time. Further, due to the segmented 1D placement model,
the configuration time HCi is still a multiple of the RRA resource requirement
HSi, that is, HCi = 33200 ×HSi, where the constant 33, 200 is simply in ns the
time required for configuring a single column in RRA. Similar to the random task
sets, we also assume here that there is no precedence relation between the tasks.
To experiment with different compositions of the five encryption/decryption
functions, we performed ten different experiments represented by the ten cases
as shown in Table IV, where each case represents the emphasis (many tasks) or de-
emphasis (few tasks) of a typical feature of the task set such as uniform distribution
ACM Transactions on Reconfigurable Technology and Systems, Vol. V, No. N, Month 20YY.
28 · Pao-Ann Hsiung et al.
  
 
 
 
U
ti
liz
at
io
n 
(%
)
 
  
  
  
  	 
      
H
ar
dw
ar
e 
U
Task Cases in DNRS 


(a) Hardware Utilization (HU)
 




 

	
 

 




         
 ﬀ
ﬁ 	
ﬂ ﬃ



 !
"#
 $
!
"%"
 &' (
)*+
,--
-
(b) Scheduling Time (ST)
 



U
sa
ge
 (M
B)



  	 
      
M
em
or
y 
U
Task Cases in DNRS


(d) Memory Usage (MU)
 





	





 
 







        ﬀ ﬁ
ﬂﬃ


 
	  
 
!
ﬃ

!  
"

# $
%&
 '
$
%(%
 )* +
,-.
/0
1
(d) RHSS vs. AHSA Improvements (%)
Fig. 12. Experiment Results for Ten Cases of Real Tasks
ACM Transactions on Reconfigurable Technology and Systems, Vol. V, No. N, Month 20YY.
30 · Pao-Ann Hsiung et al.
Bazargan, K., Kastner, R., and Sarrafzadeh, M. 2000. Fast template placement for recon-
figurable computing systems. IEEE Design and Test of Computers 17, 1 (Jan.-Mar.), 68–83.
Chen, Y.-H. and Hsiung, P.-A. 2005. Hardware task scheduling and placement in operating
systems for dynamically reconfigurable SoC. In Proc. of the 2005 IFIP International Conference
on Embedded and Ubiquitous Computing (EUC). Vol. 3824. Springer Verlag, 489–498.
Corbetta, S., Ferrandi, F., Morandi, M., Santambrogio, M., and Sciuto, D. 2007. Two
novel approaches to online partial bitstream relocation in a dynamically reconfigurable system.
In Proc. of the Annual Symposium on VLSI. IEEE CS Press.
Danne, K. and Platzner, M. 2005. Periodic real-time scheduling for FPGA computers. In Proc.
of the Third International Workshop on Intelligent Solutions in Embedded Systems (WISES).
IEEE Computer Society, 117–127.
ElFarag, A. A., El-Boghdadi, H. M., and Shaheen, S. I. 2007. Miss ratio improvement for
real-time applications using fragmentation-aware placement. In Proc. of the IEEE International
Parallel and Distributed Processing Symposium.
Handa, M. and Vemuri, R. 2004. An efficient algorithm for finding empty space for online FPGA
placement. In Proc. of the 41st Design Automation Conference (DAC). ACM Press, 960–965.
Horta, E. and Lockwood, J. W. 2001. Parbit: A tool to transform bitfiles to implement partial
reconfiguration of field programmable gate arrays (FPGAs). Technical Report WUCS-01-13,
Washington University, USA. July.
Hsiung, P.-A. and Liu, C.-W. 2007. Exploiting hardware and software low power techniques for
energy efficient co-scheduling in dynamically reconfigurable systems. In Proc. of the 17th Inter-
national Conference on Field Programmable Logic and Applications (FPL). IEEE Computer
Society Press, 165–170.
Huang, C.-H., Chang, S.-S., and Hsiung, P.-A. 2007. Generic wrapper design for dynamic
swappable hardware IP in partially reconfigurable systems. International Journal of Electrical
Engineering 14, 3 (June), 229–238.
Huang, C.-H. and Hsiung, P.-A. 2008. Software-controlled dynamically swappable hard-
ware design in partially reconfigurable systems. EURASIP Journal on Embedded Sys-
tems 2008, 231940. (doi:10.1155/2008/231940).
Koch, D., Haubelt, C., Streichert, T., and Teich, J. 2007. Modeling and sythesis of hardware-
software morphing. In Proc. of the IEEE International Symposium on Circuits and Systems.
2746–2749.
Liao, H.-W. 2007. Multi-objective placement of reconfigurable hardware tasks in real-time sys-
tems. M.S. thesis, National Chung Cheng University, Chiayi, Taiwan.
Loo, S. M. and Wells, B. E. 2005. Task scheduling in a finite-resource, reconfigurable hard-
ware/software codesign environment. INFORMS Journal on Computing 18, 2, 151–172.
Mei, B., Schaumont, P., and Vernalde, S. 2000. A hardware-software partitioning and schedul-
ing algorithm for dynamically reconfigurable embedded systems. In Proc. of the 11th ProRISC
Workshop on Circuits, Systems and Signal Processing.
Morandi, M., Novati, M., , Santambrogio, M., and Sciuto, D. 2008. Core allocation and
relocation management for a self dynamically reconfigurable architecture. In Proc. of the Annual
Symposium on VLSI. IEEE CS Press, 286–291.
Peck, W., Anderson, E., Agron, J., Stevens, J., Baijot, F., and Andrews, D. 2006. Hthreads:
A computational model for reconfigurable devices. In Proc. of the International Conference on
Field Programmable Logic and Applications. 885–888.
Pellizzoni, R. and Caccamo, M. 2006. Adaptive allocation of software and hardware real-time
tasks for FPGA-based embedded systems. In Proc. of the 12th IEEE Real-Time and Embedded
Technology and Applications Symposium (RTAS). IEEE Computer Society Press, 208–220.
Porrmann, M., Kalte, H., G., L., and Ru¨ckert, U. 2005. Replica: A bitstream manipulation
filter for module relocation in partial reconfigurable systems. In Proc. of the 12th Reconfigurable
Architectures Workshop.
Steiger, C.,Walder, H., and Platzner, M. 2004. Operating systems for reconfigurable embed-
ded platforms: Online scheduling of real-time tasks. IEEE Transactions on Computers 53, 11
(November), 1393–1407.
ACM Transactions on Reconfigurable Technology and Systems, Vol. V, No. N, Month 20YY.
17
Perfecto: A SystemC-Based Design-Space
Exploration Framework for Dynamically
Reconfigurable Architectures
PAO-ANN HSIUNG, CHAO-SHENG LIN, and CHIH-FENG LIAO
National Chung Cheng University
To cope with increasing demands for higher computational power and greater system flexibility,
dynamically and partially reconfigurable logic has started to play an important role in embedded
systems and systems-on-chip (SoC). However, when using traditional design methods and tools,
it is difficult to estimate or analyze the performance impact of including such reconfigurable logic
devices into a system design. In this work, we present a system-level framework, called Perfecto,
which is able to perform rapid exploration of different reconfigurable design alternatives and to
detect system performance bottlenecks. This framework is based on the popular IEEE standard
system-level design language SystemC, which is supported by most EDA and ESL tools. Given
an architecture model and an application model, Perfecto uses SystemC transaction-level models
(TLMs) to simulate the system design alternatives automatically. Different hardware-software
copartitioning, coscheduling, and placement algorithms can be embedded into the framework for
analysis; thus, Perfecto can also be used to design the algorithms to be used in an operating system
for reconfigurable systems. Applications to a simple illustration example and a network security
system have shown how Perfecto helps a designer make intelligent partition decisions, optimize
system performance, and evaluate task placements.
Categories and Subject Descriptors: C.0 [Computer Systems Organization]: General—Model-
ing of computer architecture; D.4.7 [Operating Systems]: Organization and Design—Real-time
systems and embedded systems; D.4.8 [Operating Systems]: Performance—Simulation
General Terms: Design, Experimentation, Performance, Verification
Additional Key Words and Phrases: Reconfigurable systems, partitioning, scheduling, placement,
performance evaluation, design-space exploration
ACM Reference Format:
Hsiung, P.-A., Lin, C.-S., and Liao, C.-F. 2008. Perfecto: A SystemC-based design-space
exploration framework for dynamically reconfigurable architectures. ACM Trans. Reconfig.
This work was supported by the National Science Council, Taiwan, under project grant NSC96-
2221-E-194-065-MY2.
Authors’ address: P.-A. Hsiung (corresponding author), C.-S. Lin, C.-F. Liao, National Chung
Cheng University, 168 University Road, Min-Hsiung, Chiayi, Taiwan-62102, ROC; email:
hpa@computer.org.
Permission to make digital or hard copies of part or all of this work for personal or classroom use is
granted without fee provided that copies are not made or distributed for profit or direct commercial
advantage and that copies show this notice on the first page or initial screen of a display along
with the full citation. Copyrights for components of this work owned by others than ACM must be
honored. Abstracting with credit is permitted. To copy otherwise, to republish, to post on servers,
to redistribute to lists, or to use any component of this work in other works requires prior specific
permission and/or a fee. Permissions may be requested from Publications Dept., ACM, Inc., 2 Penn
Plaza, Suite 701, New York, NY 10121-0701 USA, fax +1 (212) 869-0481, or permissions@acm.org.
C© 2008 ACM 1936-7406/2008/09-ART17 $5.00 DOI 10.1145/1391732.1391737 http://doi.acm.org/
10.1145/1391732.1391737
ACM Transactions on Reconfigurable Technology and Systems, Vol. 1, No. 3, Article 17, Pub. date: September 2008.
Perfecto: A SystemC-Based Design-Space Exploration Framework • 17:3
Fig. 1. SoC architectures: (a) traditional; (b) reconfigurable.
Section 3.1 will give a formal definition of the reconfigurable architecture
model used in Perfecto.
—Application Model. How must one define an application model such that a
generic application can be executed on the architecture model? Section 3.2
will give a formal definition of the application model used in Perfecto.
—Design Algorithms. What kind of design algorithms must be supported
by the framework such that the execution of the application model on
the architecture model can be thoroughly analyzed? Partitioning, schedul-
ing, and placement algorithms are considered in Perfecto and described in
Sections 3.3, 3.4, and 3.5, respectively.
—System Evaluation. What kinds of system features must be evaluated such
that they are of use to system designers? Section 3.6 will give the four task
features and five partition features that are evaluated in Perfecto.
—Guidelines. In what ways can Perfecto guide designers in choosing the right
design alternatives that meet user requirements? Perfecto helps design-
ers in three ways: (a) making intelligent partition decisions, (b) optimiz-
ing performance, and (c) evaluating task placements. Examples are used in
Section 4 to illustrate these guidelines.
Perfecto is based on SystemC [OSCI 2008], an IEEE 1666 standard system-
level modeling language supporting both software and hardware specifications.
Executable specification with simulation is an added benefit of SystemC, which
is rapidly becoming the language of choice for system-level design. This is partly
due to the fact that all large EDA vendors support or plan to support SystemC in
their tools. Perfecto takes full advantage of unique features of SystemC, such as
built-in simulation, transaction-level modeling, software-hardware modeling,
communication modeling, and performance evaluation.
The rest of the article is organized as follows. Related previous work is de-
scribed in Section 2. Section 3 describes the Perfecto framework in detail, in-
cluding the SystemC-based reconfigurable architecture model, the application
model, and the sample partitioning, scheduling, and placement algorithms im-
plemented. Section 4 illustrates the benefits of Perfecto by applying it to two
examples. Section 5 gives some conclusions with consideration for future work.
2. PREVIOUS WORK
Being a simulation-driven system description language, the IEEE 1666-2005
SystemC standard language has been used for design-space exploration at
ACM Transactions on Reconfigurable Technology and Systems, Vol. 1, No. 3, Article 17, Pub. date: September 2008.
Perfecto: A SystemC-Based Design-Space Exploration Framework • 17:5
partitioning, scheduling, and placement are performed for an architecture-
application combination.
The newly proposed Perfecto framework is most similar to SyCERS because
we are also trying to find a match between an application model and a reconfig-
urable architecture TLM model. Its difference from DRCF, DRC, and SyCERS
is that instead of considering fixed algorithms, Perfecto evaluates partition-
ing, scheduling, and placement algorithms along with an architecture and an
application. Further, in Perfecto, design-space exploration is automatically per-
formed by providing an interface to random task graph generation, evaluating
multiple partitionings of the system, detecting performance bottlenecks, and
evaluating the placement of all reconfigurable tasks in each partitioning. A
designer can choose the best architecture by referring to the partition evalua-
tions in Perfecto. Section 3.6 will present more details on how Perfecto performs
design-space exploration.
3. PERFECTO FRAMEWORK
Design-space exploration and performance evaluation are extremely important,
but difficult for reconfigurable system designers to achieve, due to the complex
dynamic nature of such systems and due to the multitude of combination possi-
bilities in hardware-software partitioning, reconfigurable hardware scheduling,
and reconfigurable hardware placement. Moreover, scheduling and placement
must be concurrently considered for a feasible design solution. Perfecto is a
framework proposed for integrating the design algorithms and for the design-
space exploration of dynamically reconfigurable systems through performance
evaluation.
As shown in Figure 2, the design flow for dynamically reconfigurable systems
is divided into two phases, namely, a front-end design and a back-end design.
The front-end design phase takes an architecture model and an application
model, which might be derived from user-given system specifications, and then
generates three kinds of tasks, namely, hardware task, reconfigurable hardware
task, and software task. The back-end design phase synthesizes the three kinds
of tasks, performs more detailed hardware-software cosimulation, and then
implements the full system using back-end tools such as a hardware synthesis
tool, software compiler, gate-level simulator, and power estimation tool. Perfecto
nicely fits into the front-end design phase as the main tool for design-space
exploration and performance evaluation.
As shown in Figure 3, Perfecto takes two inputs, namely an architecture
model and an application model, which will be defined later in Sections 3.1.4
and 3.2, respectively. Hardware-software partitions are then generated by
Perfecto. For each partition, the scheduler in Perfecto schedules the reconfig-
urable hardware and the software tasks (it is assumed here that the fixed hard-
ware accelerators are part of the DRSoC architecture and thus not scheduled
by Perfecto). Then, Perfecto simulates the execution of the software tasks on a
processor, places the hardware tasks in the reconfigurable logic, and simulates
their execution on the DRCL. Finally, after all task executions in all partitions
ACM Transactions on Reconfigurable Technology and Systems, Vol. 1, No. 3, Article 17, Pub. date: September 2008.
Perfecto: A SystemC-Based Design-Space Exploration Framework • 17:7
Fig. 3. Perfecto simulation flow.
3.1 Reconfigurable Architecture Model
For performance evaluation, we need a basic architecture model of the target
dynamically reconfigurable system. As shown in Figure 4, the basic reconfig-
urable system architecture model in Perfecto consists of a processor model, a
memory model, a function ROM model, a bus model, an arbiter model, and a
dynamically reconfigurable logic (DRCL) model. We use the SystemC design
language [OSCI 2008] to develop this architecture model because we are doing
design-space exploration at the system level and because the design contains
both hardware and software functions. In this architecture, a simple bus model
is used as communication infrastructure for the hardware tasks. Here, “sim-
ple” means that there is no pipeline and no split transaction. The bus model
eliminates the need to do global routing after tasks are placed into the DRCL.
Function ROM is a memory storage to save configurations (e.g., bitstreams)
that will be loaded into and executed in DRCL. The other system models are
described in the rest of this subsection.
3.1.1 Processor Model. A processor is required to execute the software in
a DRSoC. Besides controlling peripheral devices, it has mainly two behaviors.
ACM Transactions on Reconfigurable Technology and Systems, Vol. 1, No. 3, Article 17, Pub. date: September 2008.
Perfecto: A SystemC-Based Design-Space Exploration Framework • 17:9
Fig. 6. DRCL behaviors.
configuration controller is embedded within the DRCL model, which is similar
to the embedded ICAP controller in Xilinx Virtex FPGAs.
Reconfigurable logics can be divided into two configuration styles, namely,
full configure (static) and partial configure (dynamic). The DRCL model in Per-
fecto can simulate both types of configuration. However, we must note here that
SystemC does not allow dynamic binding of modules with their behaviors and
also does not allow a module to have multiple behaviors that can be configured
at runtime. We can thus say that SystemC does not support reconfiguration
of any kind. There are several workarounds for simulating reconfiguration in
SystemC. A straightforward method is the static binding of a SystemC mod-
ule to multiple behaviors and then selecting one of the behaviors for dynamic
execution. This method is the simplest, but quite inflexible because for every
new function, we need to modify the DRCL model. Similar to DRCF [Pelkonen
et al. 2003] and DRC [Qu et al. 2004], Perfecto adopts this method because
it is simple and fast to simulate. For design-space exploration, speed of sim-
ulation is of utmost importance. Other methods include the use of C function
pointers [Santambrogio 2008] and C++ templates, all of which might cause
an overhead in SystemC simulation performance and are thus not very suit-
able for design-space exploration. Further, multiple sc threads are used in the
DRCL for modeling partial reconfiguration. To avoid the use of function point-
ers, Perfecto uses a function table and a task table, with interfaces for automatic
insertion of new functions and new tasks.
3.1.4 Architecture Model and Parameters. In Perfecto, the basic architec-
ture model as illustrated in Figure 4 is simulated using the aforesaid models of
the processor, memories, the arbiter, and the DRCL. A software task executes
in the processor model by accessing the memory. A reconfigurable hardware
task executes in the DRCL model by accessing the memory for input and out-
put data. Communications between a software task and a hardware task are
accomplished by the processor and the DRCL models. A hardware function
reconfiguration is accomplished by the DRCL model by accessing the function
ROM. The arbiter grants access to the bus for memory accesses by the processor
and the DRCL.
If Perfecto simulates only a fixed basic architecture model, then it will be
of little use to a designer who wants to experiment with different system de-
sign alternatives. Thus, Perfecto allows a system designer to tune the basic
architecture model through several architecture parameters, as described in
the following definition.
ACM Transactions on Reconfigurable Technology and Systems, Vol. 1, No. 3, Article 17, Pub. date: September 2008.
Perfecto: A SystemC-Based Design-Space Exploration Framework • 17:11
Fig. 7. SystemC function behavior code for simple example.
of DRCL required by the function in terms of the number of slices, where a
slice is basic unit of configuration such as a frame, column, or tile in Xilinx
Virtex FPGAs; and fcode is the function behavior code implemented as Sys-
temC transaction-level code and is used to model the function behavior (see
Figure 7 for an example).
Note that the same function can be invoked by different tasks, but without
any data sharing between the different invocations.
— E is a set of edges representing the task precedence relations. An edge
(u, v) ∈ E means that task v must wait for task u to complete before starting
execution.
An application is specified by a designer through several task parameters
extracted from Definition 3.2, including the set of tasks and functions, the map-
ping between tasks and functions, the six function attributes, and the prece-
dence relations among the tasks. Note that modeling a new application into an
appropriate set of tasks could be a complicated job, which is out of the scope of
the current work.
To illustrate the aforesaid task parameters, we will use a simple application
that has six tasks invoking four functions as given in Table I(a), where the
mappings between tasks and functions are given and where it is also specified
that task T3 starts execution only after task T5 is done. The function attributes
specified by the user are shown in Table I(b). For example, function F3, when
implemented in software, requires 1300ns execution time without considering
memory accesses, and when implemented in hardware requires 150ns config-
uration time, 600ns execution time, and uses 2 slices. A generic example of
function behavior code is shown in Figure 7. Thus, Table I and Figure 7 depict
the task parameters.
ACM Transactions on Reconfigurable Technology and Systems, Vol. 1, No. 3, Article 17, Pub. date: September 2008.
Perfecto: A SystemC-Based Design-Space Exploration Framework • 17:13
By selecting the mapping criteria, we can have different partitioning algo-
rithms. A mapping result of a partitioning algorithm is called a system partition,
or simply partition. A partitioning algorithm thus generates a set of system
partitions. For experiment purposes, Perfecto implemented three hardware-
software partitioning algorithms, namely function-based, common-hardware-
first, and random partitioning, as described next.
The function-based partitioning algorithm maps each function into hardware
and/or software, according to the function attributes. For a set F of functions, at
most 2|F | partitions are generated, irrespective of the number of tasks. Hence, in
a partition, even if the same function is invoked by multiple tasks, all of them are
mapped to the same implementation (either hardware or software, depending
on the partition). Though nonexhaustive, this mapping greatly reduces the
number of partitions generated since the number of functions is usually smaller
than the number of tasks.
The common-hardware-first partitioning algorithm first counts the number
of times each function is invoked, denoted by c( f ) for a function f ∈ F . If
c( f ) > 1, then f is called a common function. The common functions are then
sorted in descending order according to c( f ). Given a parameter k > 0 repre-
senting the number of common hardware functions desired, we map the first k
common functions from the ordered list into hardware and map the rest of the
functions into software. This partitioning algorithm is useful because several
scheduling and placement algorithms often employ heuristics based on common
hardware functions, for example, energy-efficient hardware-software schedul-
ing [Hsiung and Liu 2007] and configuration-reuse scheduling and placement
methods [Noguera and Badia 2003; Resano and Mozos 2004].
A third random partitioning method generates random partitions according
to user requirements. We did not employ any complex partitioning algorithm
in Perfecto because our purpose was not to propose a new partitioning algo-
rithm; our purpose was merely to check whether the framework can be used to
efficiently evaluate dynamically reconfigurable system designs.
Though several partitioning algorithms were implemented in Perfecto, users
have to compare the results of the different partitioning algorithms manually
after Perfecto has generated the partitions, by applying the algorithms one-
by-one. The partitioning results of different algorithms can be compared by
considering either the total number of partitions generated by an algorithm
or the quality of the partitions generated. After Perfecto applies the parti-
tioning, scheduling, and placement algorithms, the quality of the partitions
can be gauged. Details of the characteristics of partitions can be found in
Section 3.6. An ideal partitioning algorithm is one that can generate the op-
timal partition within a minimal number of partition results. Optimality in
quality and minimality in quantity are conflicting goals, and thus a real parti-
tioning algorithm can only generate a near-optimal partition in a manageable
number of partitions. Users can thus select a partitioning algorithm based on
the desired trade-off between quality and quantity.
Users can also invent a new partitioning algorithm and implement it into
Perfecto to check whether the evaluated performance improves. Perfecto was
modularly designed such that independent data structures were used for the
ACM Transactions on Reconfigurable Technology and Systems, Vol. 1, No. 3, Article 17, Pub. date: September 2008.
Perfecto: A SystemC-Based Design-Space Exploration Framework • 17:15
algorithm or select the best for a specific application. Due to modular design and
the well-defined interfaces in Perfecto, users have merely to modify or rewrite
the Scheduler() function. This function takes two sets of tasks Q1 and Q2 and
sorts them according to some criteria, where Q1 is a set of ready hardware tasks
and Q2 is a set of ready software tasks.
3.5 Placement
A placement algorithm tries to find a feasible location in a fixed-size DRCL
for a given hardware task of some fixed size. The placement algorithm de-
pends on the underlying configuration model, namely, paged one-dimensional,
segmented one-dimensional, or two-dimensional, where the basic units of con-
figuration are a fixed-size slot, a column, or a tile, respectively. In Perfecto, an
abstract model is used where the basic unit of configuration is simply called a
slice. Thus, in Perfecto the underlying configuration model could be any of the
three.
Definition 3.5. Given a DRCL of Nslice slices, a list Lused of spaces al-
located to tasks, a list Lfree of free spaces, and a task Tj of size nslice(Tj )
slices to be placed, a placement algorithm is defined as Aplace(Tj , Lused, Lfree) =
〈loc, L′used, L′free〉, where loc is either NULL or a pointer to a feasible location
for the task Tj in the DRCL such that nslice(loc) ≥ nslice(Tj ). Suppose that after
placing Tj in loc, the used part of loc is denoted as loc′ and the remaining free
part, if any, is denoted by loc′′, that is, nslice(loc) = nslice(loc′)+nslice(loc′′), where
nslice(loc′) = nslice(Tj ). Then, the lists are updated as follows: L′used = Lused ∪{loc′}. L′free = Merge Adj(Lfree\{loc} ∪ {loc′′}), where the function Merge Adj()
tries to merge adjacent free spaces into contiguous blocks of free space.
By changing the selection criteria for the feasible location to place a task,
different placement algorithms can be invented. Currently in Perfecto, a place-
ment policy whereby the DRCL selects a block for configuration according to
the following rules.
(1) If there exists a block which is already configured with the same circuit but
which is not executing currently, that is, it is in the done status, then reuse
the block by selecting it for the current task.
(2) If there exists a configured block with the same slice count, but with a
different function and at the done status, then configure the new task in
this block.
(3) If there exists an unconfigured block, that is, in the idle status, with enough
slices, then configure in this block.
(4) If there is no free block with enough slices, the blocks at the done status
will be released into the idle status, then check rule 1 to rule 3 again.
An example is shown in Figure 8(a), where a DRCL is divided into several
slices, S0 to S5. Suppose there are three circuits already configured in the
DRCL, but that C1 and C3 are at the done status, while C2 is in the execute
status. If a request for circuit C2 is issued to the DRCL, then, according to
aforesaid placement rules, this task will be configured and executed in S0. If a
ACM Transactions on Reconfigurable Technology and Systems, Vol. 1, No. 3, Article 17, Pub. date: September 2008.
Perfecto: A SystemC-Based Design-Space Exploration Framework • 17:17
RR(t, P ) = 0, while for a hardware task ET(t, P ) = thw, CT(t, P ) = tcfg, and
RR(t, P ) = nslice.
For each task t in each system partition P , Perfecto accurately evaluates the
total task execution time (TET(t, P )), which is the sum of the computation time
(ET(t, P )), configuration time (CT(t, P )), memory-access time (MAT(t, P )), and
bus-wait time (BWT(t, P )). The first two are as defined earlier, and the last two
are obtained through simulation.
For each partition P , Perfecto evaluates five attributes of the partition, called
partition evaluations, which include the total partition execution time (PET ) in
nanoseconds, the average DRCL utilization (ADU %), the maximum number
of DRCL slices used (MS), the percentage of average configuration time (ACT
%), and the percentage of average bus-waiting time (AWT %). Out of these
five attributes, the values of PET and MS depend on the scheduler and the
placer chosen in Perfecto, respectively. The other three attributes are defined
as follows.
ADU(P ) =
∑
t(TET (t, P ) × RR (t, P ))
PET × MS , ACT (P ) =
∑
t CT (t, P )∑
t TET (t, P )
,
AWT (P ) =
∑
t BWT (t, P )∑
t TET (t, P )
The bus-access conflicts show the real-time information of the number of
tasks competing for bus access and also the tasks that are actually making
requests. From this information, a designer can detect whether there is a bot-
tleneck in system performance. The real-time placement information for each
task in each partition can be used for further tuning and optimization.
After simulation, by analyzing the aforementioned results generated by
Perfecto, a designer can then decide to select one or more partitions that best
fit his/her needs. The criterion could be the least total execution time, least
average DRCL utilization, or least average bus-waiting time. All of these re-
sults would be more apparent and intuitive through application examples, as
described in Section 4.
4. APPLICATION EXAMPLES
We implemented the proposed performance evaluation framework Perfecto in
IEEE 1666-2005 SystemC on a Linux Fedora Core-3 workstation with Intel
Pentium 4 2.4 GHz CPU and 1GB RAM. Perfecto was applied to several de-
signs. We use a simple example to illustrate the framework and then show its
application to a more complex real-world network security example. Note that
the partitioning, scheduling, and placement algorithms applied to the examples
in this section are all the default ones in Perfecto, so that we can focus on the
framework itself.
4.1 Simple Illustration Example
The simple illustration example was introduced in Section 3.2, which has six
tasks invoking four functions, with a precedence relation (T5, T3). Note that
from the function attributes in Table I, we can conclude that F1 has a software
ACM Transactions on Reconfigurable Technology and Systems, Vol. 1, No. 3, Article 17, Pub. date: September 2008.
Perfecto: A SystemC-Based Design-Space Exploration Framework • 17:19
T
ab
le
II
I.
E
va
lu
at
io
n
by
P
er
fe
ct
o
of
H
ar
dw
ar
e-
S
of
tw
ar
e
P
ar
ti
ti
on
s
fo
r
a
S
im
pl
e
E
xa
m
pl
e
C
T
|M
A
T
|B
W
T
T
as
k
E
xe
cu
ti
on
T
im
e
(n
s)
,
w
h
er
e
T
as
k
E
xe
cu
ti
on
T
im
e
=
E
T
+
C
T
+
M
A
T
+
B
W
T
P
E
T
A
D
U
A
C
T
A
W
T
P
#
(n
s)
(%
)
M
S
(%
)
(%
)
T
1
T
2
T
3
T
4
T
5
T
6
P
0
20
33
54
.6
3
3
11
.9
6
2.
28
0
24
0
0
15
0
20
3
10
0
90
0
10
0
90
62
20
0
60
40
0
20
0
44
0
77
3
69
0
75
2
13
25
62
0
P
1
31
19
29
.5
4
5
7.
27
2.
80
0
24
0
0
15
0
20
4
0
90
0
10
0
90
61
0
60
0
15
0
20
89
44
0
77
4
59
0
75
1
20
85
85
9
P
2
30
83
17
.1
6
2
4.
62
1.
23
0
24
0
0
0
20
0
0
90
0
10
0
90
51
20
0
60
29
0
20
0
44
0
13
20
59
0
74
1
20
85
13
20
P
3
51
69
5.
19
1
1.
54
0.
94
0
24
0
0
0
20
0
0
90
9
10
0
90
52
0
60
0
0
20
0
44
0
13
20
59
9
74
2
20
85
13
20
P
4
26
23
33
.4
5
5
9.
16
0.
20
0
24
0
0
15
0
20
2
0
90
0
0
90
0
20
0
60
0
15
0
20
9
44
0
77
2
10
90
10
90
12
85
77
9
P
5
47
09
13
.2
0
4
4.
79
0.
22
0
24
0
0
15
0
20
3
0
90
0
0
90
0
0
60
0
15
0
20
11
44
0
77
3
10
90
10
90
20
85
78
1
P
6
52
65
4.
88
1
3.
06
0.
00
0
24
0
0
0
20
0
0
90
0
0
90
0
20
0
60
0
0
20
0
44
0
13
20
10
90
10
90
12
85
13
20
P
7
73
51
0.
00
0
0.
00
0.
00
0
24
0
0
0
20
0
0
90
0
0
90
0
0
60
0
0
20
0
44
0
13
20
10
90
10
90
20
85
13
20
P
E
T
:p
ar
ti
ti
on
ex
ec
u
ti
on
ti
m
e;
A
D
U
:a
ve
ra
ge
D
R
C
L
u
ti
li
za
ti
on
;
M
S
:m
ax
im
u
m
u
sa
ge
of
D
R
C
L
sl
ic
es
(o
u
t
of
a
to
ta
ll
y
of
5
sl
ic
es
);
A
C
T
:a
ve
ra
ge
co
n
fi
gu
ra
ti
on
ti
m
e;
A
W
T
:a
ve
ra
ge
bu
s-
w
ai
ti
n
g
ti
m
e;
E
T
:p
u
re
ex
ec
u
ti
on
ti
m
e
∈
{t s
w
,t
h
w
};
C
T
:c
on
fi
gu
ra
ti
on
ti
m
e
∈
{0
,t
cf
g
};
M
A
T
:m
em
or
y-
ac
ce
ss
ti
m
e;
B
W
T
:b
u
s-
w
ai
t
ti
m
e.
ACM Transactions on Reconfigurable Technology and Systems, Vol. 1, No. 3, Article 17, Pub. date: September 2008.
Perfecto: A SystemC-Based Design-Space Exploration Framework • 17:21
Fig. 9. Bus-access conflicts for partition P1 of the simple example.
ACM Transactions on Reconfigurable Technology and Systems, Vol. 1, No. 3, Article 17, Pub. date: September 2008.
Perfecto: A SystemC-Based Design-Space Exploration Framework • 17:23
Table IV. Comparisons of Security System Implementations
Implementation Cryptography Algorithm Update Throughput Flexibility
Software Update Software Low High
Hardware Change Device High Low
Reconfigurable Logic Reconfigure with Bitstream High High
Table V. Task Set of Network Security System Example
fname MD5 SHA-1 DES 3-DES AES
Number of Invocations 2 2 7 6 6
Table VI. Function Parameters for Network Security System
Algorithm SW Exec Time Config Time HW Exec Time Slice Count
Function ( fname) tsw(ns) tcfg(μs) thw(ns) (nslice)
F1 MD5 200 119.2 190 478
F2 SHA-1 670 141.7 190 568
F3 DES 990 63.6 60 255
F4 3-DES 1960 190.3 70 763
F5 AES 910 33.2 220 133
It is also assumed that the DRCL size is fixed, irrespective of a change in bus
width.
4.2.1 Making Intelligent Partition Decisions. Perfecto generates all 32 pos-
sible partitions for the network security system as shown in Table VII. For in-
stance, in partition 25, DES and 3-DES are implemented in hardware, while
MD5, SHA-1, and AES are implemented in software, which gives a total of 13
hardware and 10 software tasks.
For legibility, in Table VIII, we show the detailed Perfecto simulation results
for 8 representative partitions out of the total 32 partitions in the network
security system, which include P0, P1, P2, P4, P21, P25, P26, and P31. All
functions are implemented in hardware in partition P0. There are four functions
that are implemented in hardware and one in software for partitions P1, P2, and
P4. There are two functions implemented in hardware and three in software
for partitions P21, P25, and P26. All functions are implemented in software in
partition P31.
From Table VIII, the following conclusions can be drawn.
(1) Conventionally, for nonreconfigurable system designs a full-hardware sys-
tem implementation usually has the shortest execution time compared to a
hardware-software system. However, the all-hardware partition P0 of the
network security system does not have the shortest execution time. Com-
pared with the total execution time of 944.6μs for P0 with 1-word bus width,
there are at least two other partitions, P1 and P25, that have shorter exe-
cution times, that is, 637.9μs and 504.9μs, respectively. The reason is that
ACM Transactions on Reconfigurable Technology and Systems, Vol. 1, No. 3, Article 17, Pub. date: September 2008.
Perfecto: A SystemC-Based Design-Space Exploration Framework • 17:25
T
ab
le
V
II
I.
S
u
m
m
ar
y
R
es
u
lt
s
of
A
pp
li
ca
ti
on
s
w
it
h
D
if
fe
re
n
t
B
u
s
W
id
th
s
in
N
et
w
or
k
S
ec
u
ri
ty
S
ys
te
m
E
xa
m
pl
e
B
u
s
W
id
th
=
1
w
or
d
B
u
s
W
id
th
=
2
w
or
ds
P
ar
ti
ti
on
A
vg
.
M
ax
A
vg
.
A
vg
.B
u
s
P
ar
ti
ti
on
A
vg
.
M
ax
A
vg
.
A
vg
.B
u
s
E
xe
cu
ti
on
D
R
C
L
S
li
ce
C
on
fi
g.
W
ai
ti
n
g
E
xe
cu
ti
on
D
R
C
L
S
li
ce
C
on
fi
g.
W
ai
ti
n
g
T
im
e
U
ti
li
za
ti
on
U
sa
ge
T
im
e
T
im
e
T
im
e
U
ti
li
za
ti
on
U
sa
ge
T
im
e
T
im
e
P
#
(μ
s)
(%
)
(M
ax
S
)
(%
)
(%
)
(μ
s)
(%
)
(M
ax
S
)
(%
)
(%
)
0
94
4.
6
57
.5
8
14
06
88
.4
4
0.
71
90
5.
2
56
.9
7
13
44
93
.9
1
0.
23
1
63
7.
9
64
.9
5
13
31
82
.1
7
2.
32
57
5.
6
66
.6
5
13
31
90
.3
2
0.
80
2
29
92
.1
10
.5
5
13
44
84
.2
3
1.
36
29
62
.1
7.
37
13
44
87
.4
9
1.
60
4
13
51
.4
28
.5
9
13
31
81
.4
0
1.
95
13
25
.2
26
.9
1
13
31
89
.8
1
0.
50
21
17
18
.2
12
.2
9
13
31
64
.1
8
1.
60
16
72
.6
11
.3
2
13
31
77
.1
7
0.
68
25
50
4.
9
45
.9
4
12
73
72
.2
1
6.
14
45
9.
9
43
.6
8
12
73
84
.3
8
2.
38
26
30
16
.0
3.
06
14
08
71
.4
0
3.
95
29
75
.0
2.
77
14
08
83
.8
6
0.
42
31
47
23
.8
0.
00
0
0.
00
0.
00
46
42
.1
0.
00
0
0.
00
0.
00
M
a
x
S
:M
ax
im
u
m
U
sa
ge
of
D
R
C
L
S
li
ce
s
(o
u
t
of
to
ta
ll
y
14
20
sl
ic
es
).
ACM Transactions on Reconfigurable Technology and Systems, Vol. 1, No. 3, Article 17, Pub. date: September 2008.
Perfecto: A SystemC-Based Design-Space Exploration Framework • 17:27
Fig. 12. Bus-access conflicts for partition P25 of the network security system.
Fig. 13. Placement diagram of DRCL in the network security system example.
bottlenecks and try to eliminate the latter by modifying the tasks themselves,
or by changing the schedules or partitions.
4.2.3 Evaluating Task Placements. To explore how the tasks are placed in
a partition, Perfecto allows designers to study the detailed real-time placement
of each task in a reconfigurable system. For partition P25 of the network secu-
rity system, the task placements in a DRCL (Xilinx Virtex-II Pro XC2VP2-7) of
1420 slices are illustrated in Figure 13, where the x-axis represents the slices
ACM Transactions on Reconfigurable Technology and Systems, Vol. 1, No. 3, Article 17, Pub. date: September 2008.
Perfecto: A SystemC-Based Design-Space Exploration Framework • 17:29
CHIANG, C.-C. 2007. Hardware/Software real-time relocatable task scheduling and placement
in dynamically partial reconfigurable systems. M.S. thesis, National Chung Cheng University,
Chiayi, Taiwan.
COMPTON, K. AND HAUCK, S. 2002. Reconfigurable computing: A survey of systems and software.
ACM Comput. Surv. 34, 2 (Jun.), 171–210.
DESMET, D., AVASARE, P., COENE, P., DECNEUT, S., HENDRICKX, F., MARESCAUX, T., MIGNOLET, J.-Y., PASKO,
R., SCHAUMONT, P., AND VERKEST, D. 2002. Design of Cam-E-leon, a run-time reconfigurable Web
camera. In Proceedings of the Embedded Processor Design Challenges: Systems, Architectures,
Modeling, and Simulation (SAMOS). Lecture Notes in Computer Science, vol. 2268. Springer,
274–290.
DICK, R. P., RHODES, D. L., AND WOLF, W. 1998. TGFF: Task graphs for free. In Proceedings of
the 6th International Workshop on Hardware/Software Codesign (CODES). IEEE Press, 97–
101.
HSIUNG, P.-A., HUANG, C.-H., AND CHEN, Y.-H. 2008. Hardware task scheduling and placement in
operating systems for dynamically reconfigurable SoC. J. Embed. Comput. (to appear).
HSIUNG, P.-A. AND LIU, C.-W. 2007. Exploiting hardware and software low power techniques for
energy efficient co-scheduling in dynamically reconfigurable systems. In Proceedings of the 17th
International Conference on Field Programmable Logic and Applications (FPL). IEEE Computer
Society Press, 165–170.
LIAO, H.-W. 2007. Multi-Objective placement of reconfigurable hardware tasks in real-time sys-
tems. M.S. thesis, National Chung Cheng University, Chiayi, Taiwan.
LIU, C.-W. 2006. Energy efficient hardware/software co-scheduling in reconfigurable systems.
M.S. thesis, National Chung Cheng University, Chiayi, Taiwan.
LOO, S. AND WELLS, B. 2006. Task scheduling in a finite resource reconfigurable hardware/software
co-design environment. INFORMS J. Comput. 18, 12 (Spring), 151–172.
MEI, B., SCHAUMONT, P., AND VERNALDE, S. 2000. A hardware-software partitioning and scheduling
algorithm for dynamically reconfigurable embedded systems. In Proceedings of the 11th ProRISC
Workshop on Circuits, Systems and Signal Processing Veldhoven.
NOGUERA, J. AND BADIA, R. 2003. System-Level power-performance trade-offs in task scheduling
for dynamically reconfigurable architectures. In Proceedings of the International Conference on
Compilers, Architectures, and Synthesis for Embedded Systems (CASES). ACM Press, New York,
73–83.
(OSCI), O. S. I. 2008. SystemC User’s Guide. http://www.systemc.org/.
PELKONEN, A., MASSELOS, K., AND CUPA´K, M. 2003. System-Level modeling of dynamically recon-
figurable hardware with SystemC. In Proceedings of the 10th Reconfigurable Architectures Work-
shop, International Parallel and Distributed Processing Symposium, 174–181.
QU, Y., TIENSYRJA¨, K., AND MASSELOS, K. 2004. System-Level modeling of dynamically reconfig-
urable co-processors. In Proceedings of the 14th International Conference on Field Programmable
Logic and Application (FPL). Lecture Notes in Computer Science, vol. 3203. Springer, 881–
885.
RAKHMATOV, D. AND VRUDHULA, S. 2002. Hardware-Software bipartitioning for dynamically re-
configurable system. In Proceedings of the 10th International Workshop on Hardware-Software
Codesign (CODES), 145–150.
RESANO, J. AND MOZOS, D. 2004. Specific scheduling support to minimize the reconfiguration over-
head of dynamically reconfigurable hardware. In Proceedings of the 41th Annual Design Automa-
tion Conference (DAC). ACM Press, New York, 119–124.
RISSA, T., DONLIN, A., AND LUK, W. 2005. Evaluation of SystemC modelling of reconfigurable em-
bedded systems. In Proceedings of the Design, Automation and Test in Europe (DATE), vol. 3,
253–258.
SANTAMBROGIO, M. 2008. Hardware-Software codesign methodologies for dynamically reconfig-
urable systems. Ph.D. thesis, Politecnico Di Milano, Italy.
STEIGER, C., WALDER, H., AND PLATZNER, M. 2004. Operating systems for reconfigurable embed-
ded platforms: Online scheduling of real-time tasks. IEEE Trans. Comput. 53, 11 (Nov.), 1393–
1407.
TIENSYRJA¨, K., QU, Y., ZHANG, Y., CUPAK, M., RYNDERS, L., VANMEERBEECK, G., MASSELOS, K., POTAMI-
ANOS, K., AND PETTISSALO, M. 2004. SystemC and OCAPI-xl based system-level design for
ACM Transactions on Reconfigurable Technology and Systems, Vol. 1, No. 3, Article 17, Pub. date: September 2008.
出席國際學術會議心得報告 
                                                             
計畫編號 NSC-96-2221-E-194-065-MY2  (第二年) 
計畫名稱 設計與實作動態可重組式系統之作業系統(II) 
出國人員姓名 
服務機關及職稱 
熊博安 
國立中正大學 資訊工程學系 教授 
會議時間地點 九十八年五月十六日 至 九十八年五月二十四日 加拿大溫哥華 
會議名稱 
2nd International Workshop on Multicore Software Engineering (IWMSE) 
In conjunction with 31st International Conference on Software Engineering 
發表論文題目 Model-Driven Development of Multi-Core Embedded Software 
 
一、參加會議經過 
原本計劃書中規劃的會議因為沒有論文發表，故改為參加並發表論文於 IWMSE 國際多
核心軟體工程研討會。此主題與計畫主題是相符的，因為 multicore system 與
reconfigurable system 已漸漸經由 Network-on-Chip (NoC)的發展，開始整合為同一種系
統。主要原因是同質(homogeneous) reconfigurable system，其實就是用 NoC 連接的
multicore system。IWMSE 今年有相當多高品質的論文發表。同時，在最後一天也有舉行
一整天的 多核心系統教學(tutorial)。 
 
本人盡量參加了所有的論文簡報，並且也參加最後一天的 multicore tutorial。論文發表時，
有至少三位與會者提問，本人逐題回答並闡述想法。事後，也有 Sun 公司的資深工程師，
再找我單獨討論我們論文研究的相關議題。主要，他很好奇為何我們僅使用 Intel 的平台
做實驗。他說應該可以用 Sun Niagara 2 multicore processor 作為實驗的平台，應該會有更
好的實驗數據。同時，也交換一些簡報技巧方面的想法。有提到，簡報應該要 focus 在
某一兩個議題比介紹很多還好。總而言之，與會者大都對本論文相當肯定，並表示願意
進一步尋求合作機會。 
 
二、與會心得 
我覺得此次最值得的莫過於就是那一整天的 tutorial。原因主要是此次安排了兩位業界
Intel 的資深工程師以及兩位德國的教授專家進行說明以及實際在筆記型電腦上操作。筆
電也是 Intel 借給我們使用的，裡面事先安裝好 Intel 最新尚未上市的 Profiler 工具。早上
的時間，德國教授介紹一些平行計算的理論，並且釐清我們一般人的錯誤觀念。例如，
我們都會認為，Amdahl’s Law 是絕對的，其實，其中沒有考慮資料量的問題，所以也不
是平行化絕對的限制。 
 
另外，因為歐美等洲有數個大型的跨國計畫在研究多核心系統的設計與程式撰寫。因此，
IWMSE 提供了一個很好的交流平台。 
 
Model-Driven Development of Multi-Core Embedded Software
Pao-Ann Hsiung1†, Shang-Wei Lin1, Yean-Ru Chen2, Nien-Lin Hsueh3, Chih-Hung Chang4,
Chih-Hsiong Shih5, Chorng-Shiuh Koong6, Chao-Sheng Lin1, Chun-Hsien Lu1, Sheng-Ya Tong1,
Wan-Ting Su1, William C. Chu5
1National Chung Cheng University, 2National Taiwan University, 3Feng Chia University,
4Hsiuping Institute of Technology, 5Tunghai University, 6National Taichung University,
†hpa@computer.org
Abstract
Model-driven development is worthy of further research
because of its proven capabilities in increasing productiv-
ity and ensuring correctness. However, it has not yet been
explored for multi-core processor-based embedded systems,
whose programming is even more complex and difficult that
that for conventional uni-processor systems. We propose a
new VERTAF/Multi-Core (VMC) framework to bridge this
gap. In this work, we mainly show how VMC generates code
automatically from user-specified SysML models for multi-
core embedded systems. We illustrate how model-driven
design based on SysML can be seamlessly integrated with
Intel’s threading building blocks (TBB) and the Quantum
Framework middleware. We use a digital video recording
system to illustrate the benefits of VMC. Our experiments
show how SysML/QF/TBB make multi-core embedded sys-
tem programming easy, efficient, and effortless.
1 Introduction
With the proliferation of multi-core architectures [1] for
embedded processors, multi-core programming for embed-
ded systems is no longer a luxury. We need embedded soft-
ware engineers to be adept in programming such proces-
sors; however, the reality is that very few engineers know
how to program them. The current state-of-the-art technol-
ogy in multi-core programming is based on the use of lan-
guage extensions such as OpenMP [8] or libraries such as
Intel Threading Building Blocks (TBB) [9]. Both OpenMP
and TBB are very useful when programmers are already ex-
perts in multithreading and multi-core programming; how-
ever, there still exists a tremendous challenge in this urgent
transition from unicore systems to multi-core systems. To
aid embedded software designers in a smoother transition,
we are in the process of extending our tool, Verifiable Em-
bedded Real-Time Application Framework (VERTAF) [4],
for multi-core embedded software design and verification.
Our primary goal is model-driven architecture (MDA) de-
velopment for such software. In this article, we focus on
the code generation for multi-core embedded software us-
ing TBB. We use an example to illustrate the transition.
TBB is a library, expressing parallelism in a C++ pro-
gram, that helps us to leverage multi-core processor per-
formance without having to be a threading expert. It rep-
resents a higher-level, task-based parallelism that abstracts
platform details and threading mechanisms for performance
and scalability. Additionally, it also realizes the concept of
scalability of writing an efficient scalable program, i.e. a
program can benefit from the increasing number of proces-
sor cores. TBB Tasks are the basic logical units of com-
putation. The library provides a task scheduler, which is
the engine that drives the algorithm templates. The sched-
uler maps the TBB tasks onto physical threads. Neverthe-
less, it requires expertise in parallel programming before a
software engineer can correctly apply the different parallel
programming interfaces provided by TBB.
Several issues crop up when developing a model-driven
architecture for multi-core embedded software. First of all,
how much and what kinds of explicit parallelism must be
specified by a software engineer through system modeling.
Second, how can we automatically and correctly realize the
user-specified models into multi-core embedded software
code. Third, how do we test and validate the generate code.
Finally, how do we apply a software engineering process to
the development of multi-core embedded software. We will
try to provide partial solutions to the above issues, which
are still open to more research work.
Mainly, the proposed VERTAF/Multi-Core (VMC)
framework takes SysML models as input, which contains
user specified model-level explicit parallelism, and gener-
ates corresponding multi-core embedded software code in
C++, which are scheduled and tested for a particular plat-
PREPRESS PROOF FILE CAUSAL PRODUCTIONS1
Interaction 
Diagrams
Timed State
Machines
SysML Models
Class Diagrams 
with 
Deployment
Design 
Patterns
Requirement 
Diagrams
Thread
Mapping
Thread
Scheduling
Extended
Timed
Automata
Generation
Model Check
Schedulable ?
Specification
Satisfied ?
Architecture
Mapping
Code
Generation
Yes Yes
Testing
Multicore
Embedded
Software
Backend
Frontend
Display
Unshedulability 
Information
No
Display 
Counterexample
in SysML 
Interaction 
Diagrams
No
Figure 1. VMC Design Flow
ming design patterns such as parallel pipeline models.
Scheduling: In VMC, the pthreads are scheduled by the
Linux OS, and the TBB threads are scheduled by the TBB
library along with thread migration among different cores.
Formal Verification: In VMC, formal timed automata
models are generated automatically from user specified
SysML models by a flattening scheme that transforms each
state machine into a set of one or more timed automata,
which are then merged into a state-graph. We have modeled
real-time task scheduling, task migration between proces-
sor cores, and several load balancing policies into the SGM
model checker, which is used in VMC to formally verify the
automata models.
Architecture Mapping: All hardware classes specified in
the deployments of the class diagram are those supported
by VMC and thus belong to some existing class libraries.
The architecture mapping phase then becomes simply the
configuration of the hardware system and operating sys-
tem through the automatic generation of configuration files,
make files, header files, and dependency files. Multi-core
processor architecture configurations can also be set in this
phase. For example, the number of processor cores avail-
able, the number of cores to be used, the number of TBB
threads, the amount of buffer space, the number of net-
work connections, the amount of hard disk space available,
the number and type of I/O devices available, the security
mechanisms, and the allowed level of processor core load-
ings are some of the configurations to be set in this phase.
Code Generation: As shown in Figure 2, we adopt a
multi-tier approach for code generation: an operating sys-
tem layer (Linux), a middleware layer (QF), a multicore
threading library layer (TBB), and an application layer.
Since both QF and TBB are very small in size and very ef-
ficient in performance, they are quite suitable for real-time
embedded system software implementation. Later in this
section, we will discuss the TBB task model and how we
mapped it into VMC.
Multicore Processor 
Linux 
Quantum Framework (Middleware) 
TBB Library 
Multithreaded Multicore Application
Figure 2. VMC Code Architecture
Testing: After the multi-core embedded software code
is generated, the code needs to be tested for several is-
sues, such as functional validation, non-functional evalua-
tion, deadlock detection, and so on. A remote debugging
environment is used to perform testing, monitoring test re-
sults, and checking if the cross-compiled code running on
the target system works as expected and satisifies all the
user-specified requirements.
4 Multi-Core Code Generation
A typical embedded system consists of input units such
as sensors or devices, computation units such as encoders,
transformers, or decoders, and output units such as actuators
or network devices. Multi-core embedded systems are typi-
cally computation and/or communication intensive, because
otherwise there is no need for powerful multi-core proces-
sors. In VMC, a multi-core embedded system application is
3
4.3 Code Generation
VMC generates multi-core embedded software code au-
tomatically from the user-specified SysML state machine
models. As introduced in Section 3, the code leverages two
existing open-source software code, including the Quantum
Framework (QF) and the Intel Threading Building Block
(TBB) library. QF is a set of application programming
interfaces implemented in C++ for executing hierarchical
state machines. TBB is a user-level thread library that helps
programmers avoid the tedious job of thread management
across multiple processor cores. QF has a very small foot-
print and TBB is a very lightweight library, thus they are
both quite suitable for embedded systems that have con-
strained physical resources such as memory space and com-
putation power.
VMC realizes each SysML state machine as a QF ac-
tive object by generating code that invokes the QF APIs for
states, transitions, and communication events. Each active
object is executed by a user-level Pthread that maps to a ker-
nel thread in the Linux OS. Within an active object, each
do method that is executed in a state, is encapsulated as a
TBB task or a TBB task graph depending on the complexity
of the method and its ability to be parallelized. Thus, there
are basically two sets of user-level threads, namely Pthreads
and TBB threads.
The distinction between these two sets of threads is
mainly due to the requirement of UML state machines to
satisfy the run-to-completion (RTC) semantics. The RTC
semantics is required by both the do methods in a QF
active object and a TBB task. A QF active object cannot be
modeled as a TBB task because the active object never ter-
minates execution and thus will violate the RTC semantics
if it is a TBB task. Hence, a devoted user-level pthread is
used instead.
Another effect of the RTC semantics is that whenever
there is an indefinite polling of some I/O devices such as a
remote controller, that is, the polling task never terminates,
then the polling task can neither be a QF do method nor a
TBB task because otherwise the RTC semantics will be vi-
olated. VMC addresses this issue by modeling such polling
tasks as an independent state machine with a single state, a
self-looping transition, and a single triggering event such as
data input. Since the specific state machine need not do any-
thing else, it waits on the single event and thus there is no
need to follow the RTC semantics, which is required only
if there is more than one type of event incoming to a state
machine.
In Section 5, we will use a real-world application exam-
ple to illustrate the various strategies employed in VMC as
described in this section.
5 Digital Video Recording: A Case Study
We use a real-world example called Digital Video
Recording (DVR) system to illustrate how VMC works and
the benefits of applying VMC to multi-core embedded soft-
ware development. DVR is a real-time multimedia system
that is typically used in concurrent remote monitoring of
multiple sites. The DVR server can perform both real-time
and on-demand streaming of videos to multiple clients si-
multaneously. Several digital video cameras provide the in-
put for real-time video streaming and previously recorded
videos are stored for on-demand streaming. We chose DVR
as an illustration example because there is not only task par-
allelism, but also data parallelism and data flow parallelism
in the system.
The overall architecture of DVR is illustrated in Fig-
ure 3, which shows that DVR has two subsystems, namely
Parallel Video Encoder (PVE) and Video Streaming Server
(VSS). PVE is responsible for collecting videos from multi-
ple cameras and encoding them into more compressed data
format such as MPEG. VSS is responsible for allowing con-
nections from multiple Remote Monitor Clients (RMC), for
servicing the clients with status information, real-time video
streams, and on-demand video streams, and for storing the
encoded video streams in large video databases.
In the rest of this section, we will describe how task par-
allelism, data parallelism, and data flow parallelism, i.e.,
parallel pipeline, are automatically realized in the embed-
ded software code generated from user-specified models of
the PVE. We will also describe how conventional thread
parallelism is integrated into the embedded software code
generated from user-specified models of the VSS. Finally,
we will summarize on the amount of software components
generated by VMC for the DVR system.
5.1 Parallel Video Encoder
The PVE subsystem has three functions including the
capturing of raw video data from all digital cameras, the en-
coding of the raw video from each camera into more com-
pressed data format for efficient network transmission and
for smaller storage space requirement, and the transmission
of the encoded video data to the buffer manager in the VSS
subsystem. PVE is a very good illustration example for all
the three issues of real-world concurrency [2] as described
in the rest of this section.
5.1.1 Task Parallelism
Capturing and processing video from each camera is an in-
dependent task. However, due to the requirement of RTC
semantics in UML and QF, as described in Section 4.3, we
need to segregate the capture and the processing of the video
5
PutEF that collects all encoded data blocks and composes
an encoded frame for transmission to the video buffer.
The 3 parallel filters in PVE pipeline are responsible for
computing in parallel the functions: DCT, quantization,
and Huffman encoding.
Connection
Server
Remote 
Monitor 
Client
Video
Streaming
Manager
Status
Manager
Encoded
Data Buffer 
Manager
Parallel
Video
Encoder
Request
Connection
Get Status Request Videos
Get/Put 
Video Frames
Real-Time
Video Frames
On-Demand
Video Frames
Database
Server
Figure 5. Architecture of Video Streaming
Server
Connection Server 
INIT
exit/EndInit
IDLE
do:
wait_connreq() 
/ Init_End
Recv_RMC_Req /
Req_Transmit 
entry/Init_CS
exit/FreeResource
DISPATCH
do:
create_port() 
// fork()
Dispatch_Done/
RMC_Req_Done
Figure 6. State Machine Model of the Connec-
tion Server
5.2 Video Streaming Server
We use the Video Streaming Server (VSS) subsystem
as a typical example of how conventional or legacy multi-
threaded software can be integrated into the VMC frame-
work such that the integration between the threads in legacy
multi-threaded software, the POSIX threads for executing
QF active objects, and the TBB threads work together seam-
lessly. The main functions of the (VSS) include (1) accept-
ing multiple connections from remote clients, (2) streaming
multiple real-time videos and/or on-demand videos to the
remote clients, (3) providing requested server status infor-
mation to the remote clients, and (4) recording the encoded
videos into storage devices. The architecture of the VSS
subsystem is shown in Figure 5 and the functionalities of
each component in VSS are described as follows.
5.2.1 Legacy Threads
Legacy threads are simply multiple threads that exists in
legacy software. This is illustrated in the Connection Server
(CS) and the Video Streaming Server (VSM).
The connection server is responsible for handling con-
nections and invoking services corresponding to multiple
client requests. Traditionally, this has almost always been
implemented as an iterative or concurrent TCP server us-
ing either the select or the fork mechanism. The state
machine for the connection server is shown in Figure 6. In
the DISPATCH state, the server simply forks a new thread
for servicing a new request from a client. The threads that
are forked from the concurrent TCP server are what we call
legacy threads. It is simply unreasonable to forsake well-
established proven concurrent artifacts such as a concurrent
TCP server. This example shows that the VMC framework
does not force one to model everything for TBB or QF. An-
other reason for not applying the TBB principle here is that
the parallelism is explicitly designed into the system and it
is required for providing real-time services to the clients.
The video streaming manager is also a typical concurrent
manager that creates new streams at run-time to serve client
requests. Due to quality-of-service (QoS) requirements, the
manager simply forks new threads to serve new requests. A
thread pool is managed for efficiency so that thread creation
and destruction are avoided at run time. In DVR, because a
minimum QoS of 15 frames per second (fps) is required for
video streaming, VSM manages a pool of legacy threads.
The state machine of VSM is illustrated in Figure 7, where a
new thread is used for servicing each new request, either for
a real-time video streaming or an on-demand video stream-
ing.
5.2.2 TBB Tasks/Threads
The VMC framework uses TBB tasks mainly for two rea-
sons as follows: (a) A job is parallelizable, but there is no
real-time constraints, or (b) A job is parallelizable, but the
underlying hardware device is not. The first case is illus-
trated by the Status Manager (SM) and the second case
by the Database Server (DS) and the Encoded Data Buffer
7
