 1
研究內容： 
一、 動機及目的： 
 近年來，由於通訊科技大幅進步與多媒體影音壓縮技術的成功發展，多媒體通訊市場
呈現蓬勃的發展，其中有關即時視訊傳輸的應用，如視訊電話(video phone)、視訊會議(video 
conference)、隨選視訊(video on demand)、即時監控系統(surveillance system)等，均是相當
熱門的應用。在即時視訊傳輸的應用中，當透過有線或是無線網路傳輸經過壓縮的視訊信
號時，因現今所採用的視訊壓縮標準如 H.26x 系列、MPEG 系列等，均採用預測編碼
(predictive coding)與可變長度編碼技術使資料量大幅降低，但也使得被保存下來的資訊對傳
輸錯誤所造成的影響更為敏感。因而必須適當處理所有可能發生的傳輸通道錯誤，以降低
解碼端因為錯誤發生所造成的不良影響。 
 針對視訊會議和視訊電話的應用，視訊方面主要的傳輸內容是以人臉為主體的影像，
而所採取的 H.261 或 H.263 視訊壓縮標準並未針對以人臉為主的視訊信號而特別設計，倘
若能在視訊編碼之前，先利用臉部偵測定位技術找出人臉位置及範圍，讓關注區域獲得更
多的保護，則將會更適合於易發生錯誤的網路環境的視訊會議與視訊電話等應用。一般關
注區域視訊編碼的研究其探討重點大都擺在如何提升關注區域視覺品質的編碼器設計上，
較少有關錯誤保護能力的改善研究，且均須變更編解碼器的設計，如此將無法與現有視訊
編碼標準相容，使其應用受到限制。本計畫目標為提出一個可抵抗錯誤(error-resilient)人臉
為主的關注區域(Region-of-Interest ROI)視訊編碼方法，利用獨立的前後級處理，直接可應
用於現有的視訊編碼標準上，使得編碼後的位元串在關注區域其抵抗錯誤的能力獲得顯著
改進，進而提升其應用價值與範圍。 
 
二、 文獻探討 
與此計劃相關之研究可分為以下幾類，臉部定位技術，視訊壓縮標準及錯誤回復技術
之研究 
z 臉部定位:偵測定位以及辨識的技術經歷了數十年的發展[6-12]，至今仍未能有一個百
分之百準確的方法誕生，畢竟所謂的人臉在圖形資料中也不過是一組數值的組合罷
了，再加上人臉大小，位移，旋轉，歪斜，表情，姿勢以及攝影環境等等的因素都會
對辨識造成影響，所以這方面的研究仍然不斷的繼續進展中，主要的方法分成四類，
分別為 knowledge-based method、feature invariant approach、template matching method
及 appearance-based method。其中以結合 knowledge-based method 及 feature invariant 
approach 的技術較廣為採用，其中膚色先行找出可能區域再根據人臉特徵決定是否為
臉部的區域便屬於此兩類的結合。 
z 視訊壓縮標準：由於目前的視訊壓縮標準種類不少，如：H.261、H.263、MPEG-1、
MPEG-2、MPEG-4 、H.264，及 WMV 等[1-5]，每種視訊壓縮標準各有其主要應用訴
求及各有其優缺點，分別針對不同頻寬的傳輸通道及不同解析度的顯示設備加以設計
訂定。但不論是何種視訊壓縮標準，均有相當多的研究在於發展能產生最佳品質的編
碼器技術。而以視訊電話及視訊會議為主要應用的 H.263 視訊壓縮標準，亦有類似的
發展，但大部份的研究均著重於編碼器本身如何利用較好的移動估算方法或較佳量化
尺度設定等方法以獲得更好的壓縮品質，近來則有較多的研究是以人臉為主體的視訊
信號編解碼技術的發展與相關抗誤技術的研發。 
 3
上，且人臉的形狀及特徵具有規則性，因此可較容易自動定出人臉關注區域。 
在人臉關注區域的自動切割方法上，我們主要採用 Lienhart[11]所提的物件偵測法，以
及 Bradski[12]所提的 CAMSHIFT〈Continuously Adaptive Mean-Shift〉物件追蹤法。
利用 Viola 與 Jones 所提的方法先偵測出第一張有人臉的影像及人臉的起始位置，由
於上述臉部偵測定位方法需較多計算量，為達即時處理的要求我們僅以該方法找出起
始畫面內的臉部位置，接著利用 Bradski 所提出的 CAMSHIFT 物件追蹤法快速獲得後
續畫面的人臉位置。底下簡單說明這兩個方法。 
¾ Lienhart 物件偵測法 
Lienhart 所提的物件偵測法最初是由 Viola 與 Jones[10]所提出的一種 Haar-like 物
件偵測法，Lienhart 對這一方法再加以改善所產生的方法，其適用的偵測對象不
僅可偵測人臉亦可偵測其他物件，亦可同時偵測多個目標物件。首先，利用訓練
樣本的 Haar 特徵進行分類器的訓練，得到一個串聯分類器(cascaded boosted 
classifier)。其中所選用的訓練樣本又分為正例樣本(positive sample)和反例樣本
(negative sample)，正例樣本代表待偵測物件樣本(如人臉)，反例樣本則為非偵測
物件的任意影像，將所有的樣本圖片縮放成同樣的尺寸大小，然後進行串聯分類
器的訓練。分類器訓練完以後，就可以應用於輸入圖像中的關注區域的偵測。 
 
而為了對整張圖像進行偵測，利用在圖像中移動搜尋視窗的方式，來檢測每一個
位置以確定可能的目標。同時為了在圖像中搜尋不同大小的目標物件，串聯分類
器被設計為可以進行尺寸調整。因此，為了在圖像中偵測未知大小的目標物件，
通常需要用不同比例大小的搜尋視窗對圖片進行多次掃描。 
 
另外，串聯分類器中的串聯是指最終的分類器是由幾個簡單分類器串接組成。在
圖像偵測中，搜尋視窗依次通過每一級分類器的篩選，這樣經過層層的篩選，可
有效降低計算的複雜度，因為前級分類器可將大部分的候選區域過濾掉，而完全
通過每一級分類器檢測的區域即成為目標區域。每一級的分類器是由基礎分類器
的自我訓練得到，基礎分類器是至少有兩個葉結點的決策樹分類器，並以上述的
Haar-like 特徵作為基礎分類器的輸入。主要採用的 Haar-like 特徵如圖 2，共分成
三種特徵類型，分別是 4 種 edge 特徵、8 種 line 特徵及 2 種 center-surround 特徵。 
 
【圖 2】Haar-like 特徵 
 
¾ CAMSHIFT 物件追蹤法 
 5
一樣水準，那麼這樣的犧牲將是值得的。 
由於在現有的視訊編碼標準中，都有使用預測編碼及移動估算及補償等技術，這些方
法其處理的單位通常是一 16x16 大小的巨方塊(macroblock)，因此，我們首先將前面
關注區域切割模組處理所得到的關注區域大小做一調整，將關注區域調整到巨方塊的
邊界上與整數倍大小。緊接著對調整後的關注區域內容進行非線性轉換處理，我們採
取 Jerbi 等人[23]所提的非線性轉換方法，將調整後的關注區域內的每個巨方塊在垂直
方向做一複製，而形成完全相同的一對巨方塊並列在垂直方向的連續位置。因此當非
線性轉換處理完成，巨方塊的數量將增為原來的兩倍，亦即增加了一倍的累贅資訊。
當這些巨方塊繼續進行下一階段的編解碼處理，即使傳輸的過程有可能有錯誤發生，
但由於關注區域內的每個巨方塊均有一累贅巨方塊，且由於我們要求所採用的視訊編
碼標準應支援資料分割(data partition)的功能，因此一對巨方塊同時出現錯誤的機會應
很小，如此關注區域的內容將可獲得保護。底下簡單說明 Jerbi 等人所提的非線性轉
換方法。正轉換的公式如下式。 
 
其中，x 及 y 表示原像素的座標；yg 表示轉換後 y 軸的座標；xs,ROI，xe,ROI，ys,ROI，ye,ROI
表示原影像關注區域的邊界；xns,ROI，xne,ROI，yns,ROI，yne,ROI表示轉換後影像關注區域
的邊界；my,offset = ⎣(y- ys,ROI)/16⎦；sy,top = ⎣yns,ROI/ ys,ROI⎦；sy,bot = ⎣(fty-yne,ROI)/ (fy-ye,ROI)⎦；
fty及 fy分別表示轉換後影像及原影像的高度。 
 
3 後級處理模組 
 在後級處理中，包括關注區域還原(ROI Restoration)與錯誤隱蔽(Error Concealment)兩部
份。其中關注區域還原主要負責關注區域的影像還原，而錯誤隱蔽則負責對關注區域的影
像進行修補以隱藏錯誤所造成的影響。 
z 關注區域還原(ROI Restoration)  
由於在前級處理部份的關注區域保護模組中，我們對關注區域進行一非線性轉換，因
此須對解碼後的影像其關注區域進行逆轉換的處理，使關注區域恢復原有大小，逆轉
換的公式如下式。 
其中，mpy,offset = ⎣( yg - yns,ROI)/32⎦，其他參數如正轉換公式所述。此外，因為錯誤發生
對前級處理所產生的巨方塊與累贅巨方塊可能不同，假設 MB1 與 MB2 分別代表巨方
 7
 
   (a)       (b)      (c) 
【圖 3】(a) 原始畫面；(b) 採用 Jerbi 方法，在遺失 22%的移動向量資料的情況下解碼後的
畫面；(c) 未採用 Jerbi 方法，在遺失 22%的移動向量資料的情況下解碼後的畫面。(資料來
源出自:[23]) 
 
 
參考文獻 
[1] ITU-T Recommendation H.261, Video Codec for Audiovisual Services at p*64 kbits/sec, 
1993. 
[2] ITU-T Recommendation H.263 Version 2, Video Coding for Low Bit Rate Communication, 
1998. 
[3] ISO/IEC 14496-10 Information technology -- Coding of audio-visual objects -- Part 10, 
2005. 
[4] G. Cote, B. Erol, M. Gallant, and F. Kossentini, “H.263+: Video coding at low bit rates,” 
IEEE Trans. Circuits Syst. Video Technol., vol. 8, pp. 849–866, Nov. 1998. 
[5] T. Wiegand, G. J. Sullivan, G. Bjontegaard, and A. Luthra, “Overview of the H.264/AVC 
video coding standard,” IEEE Trans. Circuits Syst. Video Technol., vol. 13, no. 7, pp. 
560–576, Jul. 2003. 
[6] M.-H. Yang, D. J. Kriegman, N. Ahuja, “Detecting Faces in Images: A Survey “IEEE Trans. 
Pattern Analysis and Machine Intelligence, vol. 24, no. 1, Jan. 2002. 
[7] D. Chai and K.N. Ngan, “Face segmentation using skin-color map in videophone 
applications,” IEEE Trans. Circuits Syst. Video Technol., vol. 9, no. 4, pp.551-564, June 
1999. 
[8] Waring, C. Xiuwen, Liu, “Spectral histogram based face detection,” Neural Networks, 2003. 
Proceedings of the International Joint Conference on, Volume 2, pp.1263 - 1267, July 2003. 
[9] R.L. Hsu, M. Abdel-Mottaleb, A.K. Jain, “Face detection in color images,” IEEE Trans. on 
Pattern Analysis and Machine Intelligence, vol. 24, Issue 5, pp.696 - 706 May 2002. 
[10] P. Viola and M. Jones, “Rapid Object Detection using a Boosted Cascade of Simple 
Features,” Proceedings of Conference on Computer Vision and Pattern Recognition, pp. 
511-518, 2001. 
[11] R. Lienhart, A Kuranov, V. Pisarevsky, “Empirical Analysis of Detection Cascades of 
 9
可供推廣之研發成果資料表 
□ 可申請專利  □ 可技術移轉                                      日期：97 年 1 月 26 日 
國科會補助計畫 
計畫名稱：具備強健錯誤抵抗能力之人臉關注區域視訊編碼技術之
研發 
計畫主持人：蔡建戊 
計畫編號：NSC 95-2221-E-130 -023 學門領域：影像處理 
技術/創作名稱 具備強健錯誤抵抗能力之視訊編解碼技術 
發明人/創作人 蔡建戊、林宜穎、林欣瑜 
本計畫提出一個可抵抗錯誤人臉為主的關注區域視訊編碼方法，利
用獨立的前後級處理，直接可應用於現有的視訊編碼標準上，使得
編碼後的位元串在關注區域其抵抗錯誤的能力獲得顯著改進。在前
級處理中，採用物件偵測法及 CAMSHIFT 物件追蹤法定位出每張
畫面的人臉位置，再利用非線性轉換方法，進行關注區域的複製，
讓關注區域的資料累贅提高，使得錯誤發生時，得利用重複之資訊
降低錯誤的影響，使得關注區域的影像品質獲得多一點保障。 
技術說明 
In this project, an error-resilient face-based ROI video coding 
technique is proposed. Independently adopting a pre-processing before 
the encoder and a post-processing after the decoder, the proposed 
method can be applied to existing video coding standards and the 
error-resilient capability for the compressed video data in the ROI can 
be improved apparently as well. Firstly, the initial location of face 
region is computed from the first frame by using an object detection 
technique based on Harr-like features. Then, a fast hue-based 
CAMSHIFT object tracking scheme is applied to the follow-up frames 
to find the face area of each frame. Finally, an nonlinear transformation 
applied to the ROI region to duplicate the pixels in ROI. Thus, when 
channel errors occurred, the duplicated data can be used to compensate
the corrupted area and make ROI region more robust to channel errors
可利用之產業 
及 
可開發之產品 
z 視訊電話 
z 視訊會議 
z 監控系統 
z 人機控制介面 
技術特點 
可正確及快速的定位及追蹤視訊中人臉位置，進而在視訊編碼時可
將人臉區域以更能抵抗錯誤的關注區域視訊編解碼方法，利用獨立
的前後級處理，直接可應用於現有的視訊編碼標準上，使得編碼後
的位元串在關注區域其抵抗錯誤的能力獲得顯著改進，進而提升其
應用價值與範圍。 
