 1
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
第一年計畫成果 
 
 
 
 
 
 
 
 
 
 
 
 
 3
Automated Visual Defect Inspection of LED Chips and  
Transparent Encapsulations (I) 
 
 
Hong-Dar Lin* 
Department of Industrial Engineering and Management 
Chaoyang University of Technology 
168 Jifong E. Rd., Wufong Township, Taichung County 41349, Taiwan (ROC) 
 
        ABSTRACT 
 
Light-emitting diodes (LEDs), owing to their lower power requirements, higher efficiency, 
and longer lifetimes, are widely used in modern electronic devices.  Nevertheless, tiny de-
fects that often appear in the surface of LEDs impair not only their appearances but also 
their functions.  This paper proposes a global approach for the automated visual inspection 
of tiny surface defects in non-diffused LED encapsulations.  The proposed method, taking 
advantage of the discrete cosine transform (DCT) and grey relational analysis techniques, 
overcomes the difficulties of inspecting tiny defects on uneven illumination images of 
LEDs.  We apply the grey relational analysis to the frequency components in the DCT 
domain, and select the large-magnitude frequency components that represent the back-
ground texture of the surface.  Then, by reconstructing the frequency matrix without the 
selected frequency values, we eliminate not only random texture but also uneven illumina-
tion patterns and retain anomalies in the restored image.  Experimental results demonstrate 
the effectiveness of the proposed method in inspecting tiny defects in non-diffused LED 
surfaces.  
 
Keywords: LED encapsulations, Tiny defect detection, Discrete Cosine Transform (DCT), 
Gray relational analysis (GRA), Uneven illumination.   
 
1. INTRODUCTION 
A light-emitting diode (LED) is a 
semiconductor device that emits visible light when an 
electric current passes through the semiconductor 
chip.  Compared with incandescent and fluorescent 
illuminating devices, LEDs have lower power re-
quirement, higher efficiency, and longer lifetime.  
Typical applications of LED components include 
indicator lights, LCD panel backlighting, fiber optic 
data transmission, etc.  The basic structure of an 
LED consists of the light emitting semiconductor 
chip, a lead frame where the chip is actually placed, 
and the encapsulation epoxy which surrounds and 
protects the chip.  Figure 1 shows the basic LED 
structure diagram, LED product and LED lamp.  To 
meet consumer and industry needs, LED products are 
being made in smaller sizes, which increase difficul-
ties of product inspection. 
With the popularity of LEDs, inspection of 
surface defects has become a critical task for manu-
facturers who strive to improve product quality and 
production efficiency of LEDs.  Surface defects 
affect not only the appearances of LEDs but also their 
functionality, efficiency and stability.  With diame-
ters of 3, 5, or 10 mm, LEDs are small in size, light in 
weight, and suitable for large-lot-sized production.  
However, in the surfaces of LEDs often exist tiny 
defects that cause problems such as producing 
non-uniform emitting light and reducing light’s 
strength although the defects occupy only an ex-
tremely small area.  For an LED image of 256 x 256 
pixels, the size of its tiny defect falls within the range 
of 1~15 pixels and occupies 0.0015%～0.0229% of 
the image area.  Surface defects of this magnitude 
are defined as tiny defects in this research. 
 
Fig. 1  Light-emitting diode, (a) basic LED structure, 
(b) LED product, (c) LED lamp 
 
LED light output varies with the type of chip, 
style of encapsulation and operating current.  Lu-
minous intensity is roughly proportional to the 
amount of current supplied to the LED; the greater 
5 
As to inspecting defects of LEDs, Fadzil et al. 
[6] proposed a vision system to inspect scratches, 
bubbles, contamination, blister/blemish, fuzzy dome 
and off centre defects on diffused LEDs.  Lin [16] 
used economic web cameras to capture images of 
LEDs and then applies back-propagation neural net-
work algorithm to analyze and inspect the luminosity 
functions of LEDs.  Liu [17] developed an auto-
matic optical inspection (AOI) system for inspecting 
surface defects of high brightness LED chips.  This 
AOI system first segments the chips by a 
multi-thresholding method and then computes object 
features by a blob analysis.  Therefore, most of the 
existing researches focus on inspections of LED 
chips, luminosity functions, and diffused encapsula-
tions.  They do not detect defects with the properties 
of tiny defects on non-diffused LED encapsulations.  
Consequently, we present a new global image recon-
struction scheme using discrete cosine transform and 
grey relational analysis for tiny surface defect detec-
tion. 
Ahmed et al. [1] first defined DCT as 
one-dimensional (1-D) and suitable for 1-D digital 
signal processing.  Most of the researchers that ap-
ply DCT for image processing focused on image 
compression and image reconstruction, because DCT 
has the property of packing the most information into 
the fewest coefficients [8].  However, due to the 
lack of an efficient algorithm, DCT had not been ap-
plied as widely as its properties imply.  Only until 
recently, many algorithms and VLSI architectures for 
the fast computation of DCT have been proposed [12].  
Wei [24] proposed a new image segmentation ap-
proach based on situational DCT descriptor.  To 
enhance edges of remote sensing image data in the 
DCT domain, Chen et al. [3] developed new and fast 
algorithms that involve three steps: high-pass filtering, 
gray levels adding, and contrast stretching. 
The grey relational analysis is a method of dis-
crete data analysis first proposed by Deng [5] in 1984.  
The gray theorem determines the gray relational 
grades of all of the selected factors by choosing the 
highest gray relational grade, even under incomplete 
information circumstances.  Jiang et al. [11] pro-
posed a machine vision-based grey relational theory 
applied to IC marking inspection.  Peng and Kirk 
[20] used the theory of grey relational grades com-
bined with fuzzy logic to classify six types of metal-
lic wear debris.  Fung [7] proposed the grey rela-
tional analysis based on the Taguchi method’s re-
sponse table as a way of studying the optimization of 
injection molding process factor level.  Lai et al. [13] 
used the grey relational analysis model to examine 
the relationship between product form elements and 
product image, thus identifying the most influential 
elements of product form for a given product image.  
Therefore, grey system theory has been successfully 
applied in the fields of engineering inspection, classi-
fication, factor selection, product design, etc. in re-
cent years. 
3. PROPOSED METHOD 
By regarding an input image as a matrix, we 
can perform the DCT transformation to transform a 
spatial domain image into the frequency domain.  
The DCT frequency spectrum values are used to cal-
culate grey relational grades.  Some outliers of the 
grey relational grades are detected by using kσ con-
trol limits.  Thus, we can select the proper number 
of frequency components with larger grey relational 
grades (outliers) to represent the random structure 
features of the LED surface.  Then, we set the se-
lected frequency components to zero and reconstruct 
the image in spatial domain.  For a faultless LED, 
the reconstruction process will result in a uniform 
image.  For a defective LED, the anomalies will be 
reserved and the random texture and uneven illumi-
nation patterns will be eliminated in the restored im-
age.  Finally, a simple segmentation method is ap-
plied to set the threshold for distinguishing between 
defective regions and uniform regions in the restored 
image.   
3.1 Image Pre-progressing 
In most computer vision systems, the region of 
interest (ROI) is a rectangle (block) that contains the 
object to be investigated.  The use of ROI can avoid 
the interference of uninterested regions when mask 
(template) computations or frequency transformations 
are conducted.  If an image containing uninterested 
regions is transformed into the DCT domain, the un-
interested region (e.g. background) can significantly 
interfere in the frequency analysis of the ROI.  
Therefore, after we use CCD and XYZ electronic 
control table to acquire the image of the target LED, 
we produce a target mask to delineate the ROI, the 
region of the target LED.  Then we obtain a mixed 
image by combining the target region with a manipu-
lated background to decrease the interference of an 
uninterested region (the original background).  This 
mixed image will then be used as the input for further 
DCT transformation. 
When capturing the images of our testing sam-
ples, we set the LEDs on a carrier plate which is at-
tached to an XYZ electronic control table and which 
moves while the camera stays fixed.  As the carrier 
plate moves to have the image of the next LED cap-
tured, the movement of the carrier plate might cause 
the CCD to deviate from its original position and the 
image capturing device to vibrate.  Thus, the images 
of all the LEDs might be captured with slight differ-
ences; that is, not all LEDs are located in the exactly 
same positions in their individual images.  As a re-
sult, a target mask is needed for each image to spec-
ify the location of the target LED.  Figure 3 presents 
7 
Eq.(1) gives the expression for computing the 
DCT of a digital image dx,y of size M x N.  This ex-
pression must be computed for all values of u=0, 1, 
2, …, M-1, and also for all values of v=0, 1, 2, …, 
N-1.  Similarly, given Du,v, we can obtain dx,y via the 
inverse DCT transform, as shown in Eq.(2) for x=0, 1, 
2, …, M-1 and y=0, 1, 2, …, N-1.  Eqs.(1) and (2) 
comprise the two-dimensional DCT pair.  While u 
and v are frequency variables, x and y are spatial 
variables. 
 
1 1
, ,
0 0
(2 1) (2 1)( ) ( ) cos cos
2 2
M N
u v x y
x y
x u y vD u v d
M N
π πρ ρ − −
= =
+ +⎡ ⎤ ⎡ ⎤= ⎢ ⎥ ⎢ ⎥⎣ ⎦ ⎣ ⎦∑∑    (1) 
 
1 1
, ,
0 0
(2 1) (2 1)( ) ( ) cos cos
2 2
M N
x y u v
u v
x u y vd u v D
M N
π πρ ρ− −
= =
+ +⎡ ⎤ ⎡ ⎤= ⎢ ⎥ ⎢ ⎥⎣ ⎦ ⎣ ⎦∑ ∑    (2) 
 
where 
⎪⎪⎩
⎪⎪⎨
⎧
−=
−=
−=
−=
⎪⎪⎩
⎪⎪⎨
⎧
−=
=
=
⎪⎪⎩
⎪⎪⎨
⎧
−=
=
=
1...,,2,1,0
1...,,2,1,0
1...,,2,1,0
1...,,2,1,0
,
1...,,3,2,1,2
0,1
)(,
1...,,3,2,1,2
0,1
)(
Ny
Mx
Nv
Mu
Nv
N
v
Nv
Mu
M
u
Mu ρρ
.   
The power spectrum P(u, v) of image dx,y is defined 
as: 
 
2
,( , ) u vP u v D=                              (3) 
 
That is, the energy of the image can be obtained by 
adding up the squares of the DCT coefficients. 
As the origin of the DCT coefficients has a 
very huge frequency value, it is sometimes called the 
Direct Current (DC) component of the spectrum, 
while other coefficients are called the Alternating 
Current (AC) components.  The DC coefficients in 
the upper left corner reflect information of lower fre-
quencies, whereas the AC coefficients in the lower 
right corner reflect that of higher frequencies.  DCT 
has the property of concentrating the dominant en-
ergy of a typical image in the low-frequency compo-
nents.  This means that the coefficients of the 
high-frequency components are close to zero, and 
therefore negligible in most cases [8]. 
The high-pass filter attenuates low frequencies 
and passes high frequencies.  A high-pass filtered 
image is sharper than the original image because the 
low frequencies have been attenuated.  Based on the 
DCT filtering property, we can obtain a restored im-
age with enhanced transitional gray level details, if 
we apply a high-pass filtering operation in the fre-
quency domain and then perform an inverse DCT.  
However, a non-diffused LED image due to signifi-
cantly uneven illumination on the surface of trans-
parent encapsulation has a different energy distribu-
tion in DCT frequency domain.  The 2-D and 3-D 
DCT spectrum diagrams of an LED image in Fig. 4 
(b) and (c) show that not only a lot of energy concen-
trates in the origin (u=0, v=0) and that the energy 
decreases gradually from the origin and the low fre-
quency zone on the top-left side to the high frequency 
zone on the bottom-right side but also two higher 
energy values occur in the medium and high fre-
quency zones. 
Based on the fluctuations of the energy trend, 
we design an energy filter to filter out the frequency 
components with high energy values in the spectrum 
image.  An adequate threshold is first determined 
for the energy filter in the spectrum space.  Fre-
quency components with high energy values beyond 
the threshold are then set to zero, and those lower 
than the threshold are retained.  Finally, the inverse 
DCT is applied to transform the filtered image back 
to the spatial domain.  Choosing a right threshold 
based on the degree of energy changes for the en-
ergy-filtering operation can significantly enhance the 
tiny defects in the spatial domain; the enhanced ef-
fects can be easily observed in the restored image.  
This research proposes applying grey relational 
analysis to determine the threshold for the DCT en-
ergy-filtering operation.   
(b)
 
v
u
（0,0）
(c)
 x
y
 u
v
Eg. (1)Image pre-
processing
3-D
vie
w
Input 
testing 
image
(a) 
 
Fig. 4  Examples of the DCT transformation (a) an 
LED image with a defective surface after 
pre-processing; (b) the 2-D DCT domain image; (c) 
the power spectra in 3-D perspective 
3.3 Grey Relational Analysis 
In the grey relational analysis, the data that 
contain various features are regarded as a series, thus 
the order of features in all series must be the same.  
The relationship between two series is determined by 
the difference of two series, and the difference meas-
ure refers to a value of background for generating a 
grey relational grade [25].  As compared to tradi-
tional methods, there are three advantages in gray 
relational analysis: 1) No large amount of data is 
needed; 2) No specific statistical data distribution is 
required; and 3) There is no requirement for the in-
dependency of the factors to be considered [5].  This 
9 
gray level of 8 bits.  The tiny defect detection algo-
rithm is edited in C language and executed on the 
sixth version of the C++ Builder complier on a per-
sonal computer (Pentium-4 2.6 GHz and 512 MB 
D-RAM).  Figure 6 shows the interface of the de-
veloped system. 
(a) (b)  
Fig. 5  Environmental configurations of scanning 
testing LED samples: (a) Hardware setup of experi-
ments; (b) testing LED samples are placed on XY 
table 
 
To verify the performance of the proposed 
method and other approaches, we compare the results 
of our experiments against those provided by profes-
sional inspectors.  Two indices are used to evaluate 
the performances of the proposed method: Type I 
error α (false alarms, which detect normal regions as 
defects.) and Type II error β (missing alarms, which 
fail to alarm real defects).  We divide the number of 
erroneously detected defects by the number of total 
testing images to obtain Type I errors, and the num-
ber of missing defects by the number of total defects 
to obtain Type II errors.  For all of the two indices, 
the smaller the index value, the better the detection 
result. 
Figure 7 shows partial results of detecting tiny 
defects by the Iterative method [10], the Otsu method 
[19], Lin and Ho method [15], the proposed method, 
and the professional inspector, individually.  The 
two spatial domain techniques, the Iterative and Otsu 
methods, make lots of erroneous judgments (false 
alarms) on tiny defect detection.  The two frequency 
domain techniques, the Lin and Ho approach and the 
proposed method, detect most of the tiny blemishes 
and make less erroneous judgments.  Therefore, the 
frequency domain approaches outperform the spatial 
domain techniques in the tiny defect detection of 
LED surfaces. 
More specifically, we compare the difference 
between the Lin and Ho approach and the proposed-
method.  Figure 8 indicates the difference between 
the two methods in detail.  The Lin and Ho method 
performs high-pass filtering for removing the low 
frequency components within a radius of a sector 
centered at the origin while the proposed method 
executes high energy filtering for removing not only 
the low frequencies but also the medium and/or high 
frequency components with high energy values in the 
DCT domain.  Since significantly uneven illumina-
tion derived from the self-illuminating lighting occurs 
on the testing images, removals of the frequency 
components with high energy values are important 
for the tiny defect detection.  
Table 1 summarizes the detection results of our 
experiments.  Two spatial domain approaches and 
two frequency domain techniques are evaluated 
against the results by professional inspectors.  The 
features of detected defects include the pixels of cor-
rectly detected defects and pixels of erroneously de-
tected defects.  The total normal and defective areas 
are 1,528,712 and 1,226 pixels of 55 LED samples, 
respectively.  The average defect detection rates (1-β) 
of all testing samples by the four methods are, re-
spectively, 100% (Iterative method), 100% (Otsu 
method), 87.77% (Lin and Ho method), and 94.78% 
(proposed method).  However, the two spatial do-
main methods have significantly higher false alarm 
rates (α), 65.65% (Iterative method) and 26.90% 
(Otsu method).  On the contrary, the other two fre-
quency domain approaches have rather lower false 
alarm rates, 0.07% (Lin and Ho method) and 0.03% 
(proposed method).  More specifically, the proposed 
method not only has a higher detection rate than does 
the Lin and Ho method but also its false alarm rate is 
more than two times lower than that of the latter 
method applied to LED images.  In industrial prac-
tices, a more than 90% detection rate and a less than 
10% false alarm rate are a good rule of thumb for 
performance evaluation of a vision system.  The 
proposed method overcomes the difficulties of de-
tecting tiny defects on uneven illumination images 
and excels in its ability of correctly discriminating 
tiny defects from normal regions.   
Table 1.  Summarized comparison table of tiny de-
fect detection for four different methods 
 
5.  CONCLUSION 
This research proposes a novel and global ap-
proach that applies discrete cosine transform and grey 
relational analysis for the automatic inspection of tiny 
defects in randomly textured surfaces of LED encap-
sulations.  Requiring neither textural features for 
detection of local anomalies nor a reference image for 
comparison, the proposed method avoids the limita
11 
REFERENCES 
 
1. Ahmed, N., T. Natarajan and K. R. Rao, “Dis-
crete cosine transform,” IEEE Transactions on 
Computer, 23(1), 90-93 (1974).   
2. Chan, C. H. and G. K. H. Pang, “Fabric defect 
detection by Fourier analysis,” IEEE Transac-
tions on Industry Applications, 36(5), 
1267-1276 (2000).   
3. Chen, B., S. Latifi and J. Kanai, “Edge en-
hancement of remote sensing image data in the 
DCT domain,” Image and Vision Computing, 
17, 913-921 (1999).   
4. Cho, C. S., B. M. Chung and M. J. Park, “De-
velopment of real-time vision-based fabric in-
spection system,” IEEE Transactions on Indus-
trial Electronics, 52(4), 1073-1079 (2005).   
5. Deng, J. L., “The theory and method of socio-
economic grey systems,” Social Sciences in 
China (in Chinese), 6, 47-60 (1984).   
6. Fadzil, M. H. A. and C. J. Weng “LED cos-
metic flaw vision inspection system,” Pattern 
Analysis & Applications, 1 (1), 62-70 (1998).   
7. Fung, C. P., “Manufacturing process optimiza-
tion for wear property of fiber-reinforced 
polybutylene terephthalate composites with 
grey relational analysis,” Wear, 254, 298-306 
(2003).   
8. Gonzalez, R. C. and R. E. Woods, Digital Im-
age Processing, 2nd Ed., Prentice Hall, New 
Jersey, 472-486 (2002).   
9. Huang, C. J., “Clustered defect detection of 
high quality chips using self-supervised multi-
layer perceptron,” Expert Systems with Appli-
cations, 33, 996-1003 (2007).   
10. Jain, R., and R. Kasturi, and B. G. Schunck, 
Machine Vision, International Editions, 
McGraw Hill, New York, 76-86 (1995).   
11. Jiang, B. C., S. L. Tasi, and C. C. Wang, “Ma-
chine vision-based gray relational theory ap-
plied to IC marking inspection,” IEEE Trans-
actions on Semiconductor Manufacturing, 
15(4), 531-539 (2002).   
12. Kok, C. W., “Fast algorithm for computing dis-
crete cosine transform,” IEEE Transactions on 
Signal Processing, 45(3), 757-760 (1997).   
13. Lai, H. H., Y. C. Lin, and C. H. Yeh, “Form 
design of product image using grey relational 
analysis and neural network models,” Com-
puter & Operations Research, 32, 2689-2711 
(2005).   
 
 
14. Latif-Amet, A., A. Ertüzün and A. Ercil, “An 
efficient method for texture defect detection: 
sub-band domain co-occurrence matrices,” 
Image and Vision Computing, 18, 543-553 
(2000).   
15. Lin, H. D., D. C. Ho, “Detection of surface 
pinhole defects using DCT based enhancement 
approach in computer vision systems”, 
IEEE/ASME International Conference on Ad-
vanced Intelligent Mechatronics, 373-378 
(2005).   
16. Lin, P. Y., “An application of back-propagation 
network in LED auto-inspection system for 
electronic products,” Master thesis, Tatung 
University, Taipei, Taiwan, 2005.   
17. Liu, M. C., “A surface defect inspection tech-
nique for high brightness LED chips,” Master 
thesis (in Chinese), National Chi-Nan Univer-
sity, Nan-Tou, Taiwan, 2005.   
18. Okuno, A., Y. Miyawaki, N. Oyama, and W. 
Dongxu, “Unique white LED packaging sys-
tems,” IEEE Electronic Components and 
Technology Conference, 1599-1601 (2003).   
19. Otsu, N., “A threshold selection method from 
gray level histogram,” IEEE Transactions on 
Systems, Man and Cybernetics, 9, 62-66 
(1979).   
20. Peng, Z. and T. B. Kirk, “Wear particle classi-
fication in a fuzzy grey system,” Wear, 225-229, 
1238-1247 (1999).   
21. Shankar, N. G. and Z. W. Zhong, “Defect detec-
tion on semiconductor wafer surface,” Micro-
electronic Engineering, 77, 337-346 (2005).   
22. Tsai, D. M. and S. K. Wu, “Automated surface 
inspection using Gabor filters,” International 
Journal of Advanced Manufacturing Technol-
ogy, 16, 474-482 (2000).   
23. Tsai, D. M. and B. Hsiao, “Automatic surface 
inspection using wavelet reconstruction,” Pat-
tern Recognition, 34, 1285-1305 (2001). 
24. Wei, J., “Image segmentation based on situ-
ational DCT descriptors,” Pattern Recognition 
Letters, 23, 295-302 (2002).   
25. Wong, C. C. and H. R. Lai, “A new grey rela-
tional measurement,” The Journal of Grey Sys-
tem, 4, 341-346 (2000). 
 
 
 
 13
發光二極體 LED 晶粒與透明封裝之外觀瑕疵自動化視覺檢測
(II) 
 
 
林宏達 
朝陽科技大學  工業工程與管理系 
41349 台中縣霧峰鄉吉峰東路 168 號 
Email: hdlin@cyut.edu.tw 
 
 
摘要 
 
    發光二極體(Light Emitting Diode; LED)具有壽命長、耗
電量低、體積小與堅固耐震等特性，隨著高亮度的需求，LED 未
來可能取代傳統的白熾燈與螢光燈。LED 之晶粒(chip)主宰發光
品質，但是細微瑕疵經常發生在 LED 晶粒表面，將影響發光亮
度、降低發光效率與破壞 LED 產品功能。本研究提出使用自動化
電腦視覺檢測技術來檢測 LED 晶粒之表面不良瑕疵與水漬瑕
疵，此瑕疵具有漸層式之灰階值並且橫跨 LED 晶粒之兩種不同背
景紋路，增加檢測其表面細微瑕疵的困難度。本研究應用一階
Haar 小波轉換得到四個小波特徵作為描述表面紋路之特性，並
搭配能降低維度且整合多變數之主成份分析(Principle Com-
ponent Analysis; PCA)或因素分析(Factor Analysis; FA)整合
四個小波特徵，找出最具代表原始小波特徵之少數主成份或少數
因素，最後則針對 PCA 之分數或 FA 之分數進行簡單的閥值切割
以找出異常瑕疵之位置。實驗結果顯示，本研究所提之主成份分
析在瑕疵面積檢出率為 93.75%、型一誤差為 3.64%；因素分析在
瑕疵面積檢出率為 94.86%、型一誤差為 4.37%，皆優於傳統之
Otsu、T2 statistics 方法。   
 
關鍵詞：LED chip、瑕疵檢測、Haar 小波轉換、主成份分析、Hotelling
統計量。 
 
 
 
 
 15
process. Automated inspection of a water-spot defect 
is difficult because the blemish has a semi-opaque 
appearance and a low intensity contrast with the 
rough exterior of the LED chip. With a width of 
0.21mm, an LED chip comprises an aluminum-pad 
(bonding pad) in the central area and a metal oxide 
semiconductor (emitting area) in the outer area, as 
shown in Fig. 2 (a). Texture of the central area has a 
random pattern while that of the outer area has a 
uniform appearance. A water-spot blemish may fall 
across the two areas of significantly different 
textures, which complicates the defect detection 
procedure. Figures 2 (b)-(d) display the LED chip 
images with water-spot blemishes of different 
shapes.  
 
 
Fig. 1  (a) LED product (b) LED structure diagram 
 
 
 
Fig. 2  LED chip images (a) normal chip (b)-(d) 
defective chips with water-spot defects of different 
shapes 
 
     Defect detection techniques compute a set of 
textural features in a sliding window and search for 
significant local deviations among the feature values. 
The detection techniques are generally classified 
into the spatial domain and the frequency domain. 
Siew et al. [8] applied the co-occurrence matrix 
method, a traditional spatial domain technique, to 
assess carpet wear by using two-order gray level 
statistics to build up probability density functions of 
intensity changes. For another spatial domain 
example, Latif-Amet et al. [9] presented wavelet 
theory and co-occurrence matrices for detection of 
defects encountered in textile images and classified 
each sub-window as defective or non-defective with 
a Mahalanobis distance.  
     As to techniques in the frequency domain, 
Chan and Pang [10] proposed a simulated fabric 
model based on Fourier transform for inspection of 
structural defects in fabric. Since a 
three-dimensional frequency spectrum is very 
difficult to analyze and defects occur mostly along 
the horizontal and vertical axes, the central spatial 
frequency spectrum approach has been proposed to 
increase efficiency of the analysis process. Seven 
significant characteristic parameters can be extracted 
from the central frequency spectrums for describing 
the defect types. Kumar and Pang [11] presented a 
new multi-channel filtering scheme for unsupervised 
fabric defect detection using a class of self-similar 
Gabor functions. Also, Lin [12] developed a novel 
approach that applies discrete cosine transform 
decomposition and cumulative sum techniques for 
the detection of tiny defects on passive component 
chips.  
     Regarding defect detection applications in the 
electronic industry, Lin and Chiu [13] used 
multivariate Hotelling T2 statistic to integrate 
different coordinates of color models for 
MURA-type defect detection on Liquid Crystal 
Displays (LCD), and applied ant colony algorithm 
and back-propagation neural network techniques to 
develop an automatic inspection procedure. Lu and 
Tsai [14] proposed a global approach for automatic 
visual inspection of micro defects such as pinholes, 
scratches, particles and fingerprints. The Singular 
Value Decomposition (SVD) adopted by Lu and Tsai 
suits the need for detecting defects on the TFT-LCD 
images of highly periodical textural structures. 
Furthermore, in the recent decade, many vision 
systems have been developed for the inspection of 
surface defects on semiconductor wafers [15-17]. 
For instance, Fadzil and Weng [18] implemented a 
vision inspection system that achieves a 90% 
probability of accurately classifying defects, 
scratches, contamination, blemishes, off center 
 17
coordinate system obtained by rotating the axes of 
the original system (the p’s). The new axes represent 
the directions of maximum variability.  
     The basic intent of principal components is to 
find the new set of orthogonal directions that define 
the maximum variability in the original data, and 
this will lead to a description of the process 
requiring considerably fewer than the original p 
variables. The information contained in the complete 
set of all p principal components is exactly 
equivalent to the information in the complete set of 
all original process variables, but hopefully we can 
use far fewer than p principal components to obtain 
a satisfactory description [24].  
     The WPCA approach decomposes an image of 
size (M x N) pixels into a set of a x b multivariate 
processing units. Therefore, an original image has g 
x h (i.e. M/a x N/b) multivariate processing units. 
For each multivariate processing unit, the region of 
size a x b pixels can be applied the wavelet 
transform to obtain four wavelet characteristics A, 
D1, D2 and D3 through calculations. The PCA 
integrates the multiple wavelet characteristics into a 
PC score for each multivariate processing unit. This 
PC score can be regarded as an distance value of a 
multivariate processing unit. The larger the PC score, 
the more the difference between the region and 
normal area. Therefore, this region can be judged as 
a defective region, otherwise this region has no 
defect.  
     Let the four random variables 1x , 2x , 3x , 
4x  be the four wavelet characteristics and be 
represented by a vector [ ]1 2 3, , , TA D D D=X  with 
covariance matrix Σ, and let the eigenvalues of Σ be 
1λ , 2λ , 3λ , 4λ . Then the constants ije  are simply 
the elements of the ith eigenvector ie  associated 
with the eigenvalue iλ . Basically, if we let E be the 
matrix whose columns are the eigenvectors, then 
 
′ =E EΣ Λ                            (5) 
 
where Λ  is a 4 × 4  diagonal matrix with main 
diagonal elements equal to the eigenvalues 
1 2 4... 0λ λ λ≥ ≥ ≥ ≥ . More specifically, the equation 
can be expressed by the eigenvalues and the 
eigenvectors as follows:  
[ ]
1 2 3
1 1 1 2 1 3
2 2 1 2 2  3
3 3 1 3 2 3
2
, , , 
1 1
2
 , , , 2
1 2 3 4 2
3 ,  ,   , 
2 4
 ,  ,  ,  
              0   0   0
         0 
   
       
      
A A D A D A D
D A D D D D D
D A D D D D D
D A D D D D D
σ σ σ σ λ
σ σ σ σ
σ σ σ σ
σ σ σ σ
⎡ ⎤ ⎡ ⎤⎢ ⎥ ⎢ ⎥⎢ ⎥ ⎢ ⎥ =⎢ ⎥ ⎢ ⎥⎢ ⎥ ⎢ ⎥⎢ ⎥ ⎣ ⎦⎢ ⎥⎣ ⎦
e
e
e e e e
e
e
2
3
4
     0   0
0   0      0
0   0   0   
λ
λ
λ
⎡ ⎤⎢ ⎥⎢ ⎥⎢ ⎥⎢ ⎥⎣ ⎦
(6) 
 
The principal component analysis can be performed 
by computing the eignvalues and eignvectors [25].  
     The variance of the ith principal component is 
the ith eigenvalue iλ . Consequently, the proportion 
of variability in the original data explained by the ith 
principal component is given by the ratio 
1 2 4λ (λ λ λ )i + +⋅⋅⋅+ . Therefore, one can easily see 
how much variability (for instance, 80 to 90%) is 
explained by retaining just a few (say, r) of the 4 
principal components simply by computing the sum 
of the eigenvalues for those r components and 
comparing that total to the sum of all 4 eigenvalues.  
     Once the principal components have been 
calculated and a subset of them selected, we can 
obtain new principal component observations yij 
(principal component (PC) scores) simply by 
substituting the original observations xij into the set 
of r retained principal components. After conducting 
many experiments, we find the first one principal 
component accounts for most of the variability in 
this study. If we have retained the first one (i.e. r=1) 
of the original four principal components, then the 
PC score ( , )M x yY  of the multivariate processing unit 
( , )M x y  of a testing image can be defined as:  
 
( )( , )( , )  1  -  M x yM x y TeY XX=                (7) 
 
where 
 ( , )
( , )1
( , ) ( , )2
( , )3 4 1
A x y
D x y
XM x y D x y
D x y
⎡ ⎤⎢ ⎥⎢ ⎥⎢ ⎥⎢ ⎥⎢ ⎥⎢ ⎥⎢ ⎥⎢ ⎥⎢ ⎥⎣ ⎦
=
×
, and 
 
max max
min min
1 1
minmin
2 22
minmin
33
1 ,
 
 
:  maximum value of  in a normal image
:  minimum value of  in a normal image
:  minimum value of  in a normal image
:  minimum value of 4 1
A A s
D D s
D sD
DD
A
DX
D
D
⎡ ⎤⎢ ⎥⎢ ⎥⎢ ⎥⎢ ⎥⎢ ⎥⎣ ⎦
=
× 3  in a normal images
 
and 11 12 13 14[ , , , ]e e e e=T1e  is the first eigenvector of 
the Σ of a testing image. Normal texture images are 
used to estimate the parameters of standard texture 
characteristics for bonding pad and emitting area, 
respectively. The sample expected matrix of the 
wavelet characteristics ( X ) describes the properties 
and relations between normal and defect images. 
The threshold value (T) is defined as follows:  
 
YT Y Kσ= +                           (8) 
 
 19
The sample mean matrix (a x b) and the sample 
covariance matrix (S) describe the properties and 
relations between normal and defect images. The X  
and S are defined as:  
 
1
2
3 4 1
 
A
D
X
D
D ×
⎡ ⎤⎢ ⎥⎢ ⎥= ⎢ ⎥⎢ ⎥⎢ ⎥⎢ ⎥⎣ ⎦
                          (17) 
 
, , , 1 2 3
, A , , 1 1 2 1 31
, , , 22 2 1 2 3
, , , 3 3 1 3 2 3
2                     
2                  
2                
2             
4 4
A A D A D A D
D D D D DD
D A D D D DD
D A D D D D D
S S S S
S S S S
S
S S S S
S S S S
⎡ ⎤⎢ ⎥⎢ ⎥⎢ ⎥⎢ ⎥⎢ ⎥⎢ ⎥⎢ ⎥⎢ ⎥⎣ ⎦
=
×
        (18) 
 
where 2pS  is the sample variance of the p-th 
wavelet characteristic of an image; ,p qS  is the 
sample covariance of the p-th and the q-th wavelet 
characteristics of an image. 
     The T2 statistic value of the multivariate 
processing unit ( , )M x y  of a testing image can be 
defined as: 
 
2 1
( , ) ( , )( , )
T
M x y M x yM x yT a b X X S M X
−⎡ ⎤ ⎡ ⎤= × − −⎢ ⎥ ⎢ ⎥⎣ ⎦ ⎣ ⎦
(19) 
 
where a x b is the number of wavelet process units 
in a multivariate processing unit. ( , )M x yX  is the 
mean matrix of image characteristics in the 
multivariate processing unit of a testing image. The 
X  and S are respectively the mean matrix and the 
covariance matrix of image characteristics of a 
normal image. The upper control limit is as follows: 
 
, ,( - - 1)
( -1)( -1)
- - 1 p mn m p
p m n
F
mn m p θ ++             (20) 
 
,where F is a tabulated value of the F distribution at 
the significance level of θ .  
 
 
3   Experiments and Analyses 
To evaluate the performance of the proposed 
approaches, experiments are conducted on real LED 
chips provided by a company that manufactures high 
quality LED chips in Taiwan. We test 180 LED chip 
images, of which 60 have no defects and 120 have 
various water-spot defects. All of the samples are 
randomly selected from the manufacturing process 
of LED chips. All experiments are implemented on a 
Pentium IV personal computer with 2.6GHz CPU 
and 512 MB RAM; and all programming is done in 
the C language.  
     To increase the number of LED chips on a 
wafer, every chip is located very close to its 
neighboring chips. As the carrier plate moves to 
have the image of the next chip captured, the 
movement might cause the CCD to deviate from its 
original position and the image capturing device to 
vibrate. Thus, the images of all the chips might be 
captured with slight differences. That is, not all the 
chips are located in the exactly same positions in 
their individual images. As a result, two areas are 
needed for each image to specify the locations of 
two different background textures in which 
water-spot defects may possibly exist. The LED 
emitting area and bonding pad need to be separated 
first and then individually apply the proposed 
methods to detect defects.  
     In the outer area of an LED chip is an emitting 
area which contains uniform texture. Since wavelet 
transform can process images of rectangular shapes, 
a specially made background must be added to 
convert the different shape region into a rectangular 
one. Thus, we change gray levels of the area falling 
outside the outer area to the average gray level of 
normal chip images in Fig. 3(a). With such a 
manipulated background, we not only obtain a 
rectangular region for wavelet transform but also 
minimize the affect non-emitting region. Once the 
mixed image is transformed into the wavelet domain, 
the non-emitting region will not interfere in the 
feature extraction of the emitting region.  
 
 
Fig. 3  The mixed images (a) for the bonding pad 
(b) for the emitting area  
 
     Similarly, this procedure is also applied to 
defect detection on LED bonding pad except 
additionally taking median filtering operation. In the 
 21
86.6% (Otsu method), 91.3% (WHS method), and 
93.8% (WPCA method). The average false alarm 
rates (α) of all testing samples are, respectively, 
9.3% (Otsu method), 5.8% (WHS method), and 
3.6% (WPCA method). The proposed wavelet based 
multivariate statistical approaches have higher 
detection rates (1-β) and correct classification rates 
(CR) than does the traditional method applied to 
LED chip images. The WPCA method not only 
excels in its ability of correctly discriminating 
water-spot defects from normal regions but also has 
the lowest false alarm rate. The average computation 
time for processing an image of 256 x 256 pixels is 
as follows: 1.84 seconds (Otsu method), 2.32 
seconds (WHS method), and 2.26 seconds (WPCA 
method). Both of the multivariate statistical 
approaches based on the wavelet characteristics 
have the same processing time.  
     As the decision threshold value changes, so do 
its false alarm rate (α) and detection rate (1-β), 
both of which are used to describe the performance 
of a test according to hypothesis testing theory [30]. 
When various decision thresholds (Eqs. (8) and (20)) 
are used, their pairs of false alarm rates and 
detection rates are plotted as points on a Receiver 
Operating Characteristic (ROC) curve. Figures 5 and 
6 present the two ROC curves of the WHS and 
WPCA approaches, and the one point of the Otsu 
method for the bonding pad and the emitting area 
respectively. The upper-left corners of Figs. 5 and 6 
are the optimum points, which have a 100% 
detection rate and a 0% false alarm rate. The more 
the ROC plot approaches the upper-left corner, the 
better the test performs. In industrial practices, a 
more than 90% defect detection rate and a less than 
10% false alarm rate are a good rule of thumb for 
performance evaluation of a vision system. 
Accordingly, the proposed WPCA approach, with its 
ROC plots closer to the upper-left corner, 
outperforms the WHS method and the traditional 
Otsu method.  
     The WPCA approach achieves good 
performance in detecting surface defects of LED 
chips as well as semi-opaque and 
low-intensity-contrast water-drop blemishes that fall 
across two different background textures. Since the 
computation of multivariate statistics is based on the 
mean vector and covariance matrix of the training 
samples, lighting changes may lead to an increase of 
variation in statistics and result in a decline of defect 
detection performance. Thus, it is recommended to 
re-compute the mean vector and covariance of the 
training samples whenever illumination is 
significantly changed. In addition, the proposed 
method is not recommended for detecting blemishes 
embedded in structural textures because it is 
designed to identify defects in random textures. 
0.6
0.7
0.8
0.9
1.0
0.0 0.1 0.2 0.3 0.4
False Alarm Rate (α)
D
et
ec
tio
n 
Ra
te
 (1
-β
)
Otsu method
WHS method
WPCA method
 
Fig. 5  ROC plots of the Otsu, WHS, and WPCA 
methods for the bonding pad 
 
 
0.6
0.7
0.8
0.9
1.0
0.0 0.1 0.2 0.3 0.4
False Alarm Rate (α)
D
et
ec
tio
n 
Ra
te
 (1
-β
)
Otsu method
WHS method
WPCA method
Fig. 6  ROC plots of the Otsu, WHS, and MPCA 
methods for the emitting area 
 
 
4   Conclusion 
Machine vision technology improves productivity 
and quality management, and provides a competitive 
advantage to industries that employ this technology. 
This research applies wavelet-based multivariate 
statistical approaches combined with machine vision 
techniques to detect water-spot blemishes that fall 
across two different background textures of LED 
chips. The research methods use the principal 
component analysis and Hotelling statistic, 
respectively, based on wavelet characteristics to 
judge the existence of water-spot defects through 
multivariate processes of combining image 
characteristics from wavelet decomposition of local 
image blocks.  
     Experimental results show that the WPCA 
approach achieves detection rates of above 93.8% and 
 23
[20] Arivazhagan, S. and Ganesan, L., Texture 
segmentation using wavelet transform, Pattern 
Recognition Letters, Vol.24, 2003, 
pp.3197-3203.  
[21] Bashar, M.K., Matsumoto, T., and Ohnishi, N., 
Wavelet transform-based locally orderless 
images for texture segmentation, Pattern 
Recognition Letters, Vol.24, 2003, 
pp.2633-2650.  
[22] Mirapeix, J., Garcia-Allende, P.B., Cobo, A., 
Conde, O.M., and Lopez-Higuera, J.M., 
Real-time arc-welding defect detection and 
classification with principal component analysis 
and artificial neural networks, NDT & E 
International, Vol.40, No.4, 2007, pp.315-323. 
[23] Thomaz, C.E., Boardman, J.P., Counsell, S., 
Hill, D.L.G., Hajnal, J.V., Edwards, A.D., 
Rutherford, M.A., Gillies, D.F., and Rueckert, D., 
A multivariate statistical analysis of the devel-
oping human brain in preterm infants, Image and 
Vision Computing, Vol.25, 2007, pp.981-994. 
[24] Montgomery, D.C., Introduction to Statistical 
Quality Control, 5th edn, John Wiley & Sons, 
Hoboken, NJ, 2005, pp.491-504.  
[25] Johnson, R.A. and Wichern, D.W., Applied 
Multivariate Statistical Analysis, 5th edition, 
Prentice-Hall, Inc., Upper Saddle River, NJ, 
2002, pp.426-437. 
[26] Hotelling, H., Multivariate quality control, in: 
Eisenhart C, Hastay M W & Wallis W A (Eds.), 
Techniques of Statistical Analysis, McGraw-Hill, 
New York, NY, 1947, pp.111-184.  
[27] Lowry, C.A. and Montgomery, D.C., A review 
of multivariate control charts, IIE Transactions, 
Vol.27, 1995, pp.800-810.  
[28] Jain, R., Kasturi, R., and Schunck, B.G., 
Machine Vision, International edn, 
McGRAW-Hill, New York, NY, 1995, pp.80-83.  
[29] Otsu, N., A threshold selection method from 
gray-level histogram, IEEE Transactions on 
Systems, Man, Cybernetics, Vol.9, 1979, 
pp.62-66.  
[30] Montgomery, D.C. and Runger, G.C., Applied 
Statistics and Probability for Engineers, 2th edn, 
John Wiley & Sons, New York, NY, 1999, 
pp.296-304.  
 
 
 
 
 
 
表 Y04 
一、 參加會議經過 
2008 Applied Computing Conference (ACC-2008) 2008年應用計算國際研討會議在土耳其
(Turkey)之伊斯坦堡市（Istanbul）舉辦，由世界科學與工程學會與協會WSEAS (World 
Scientific and Engineering Academy and Society)組織主辦，從97年5月27日起至5月30日止，為
期四天。ACC-2008應用計算國際研討會為工程界每年重要之研討會，今年研討會參與投稿之
論文篇數接近兩百篇，參與之學者亦超過一百多人（來自世界35餘國），來自台灣的教授與學
生亦不在少數，且有逐漸增加的趨勢。參與此類研討會不僅可吸收最新之科學與工程及相關
領域之研究，而且可與來自世界各國之眾多學者交流，亦為國民外交之最佳表現。而此研討
會之主辦單位WSEAS為是專業的科學及工程學會，是國際知名且權威的學術研究學會，發行
相當多的國際知名期刊並收錄在EI中。 
本次會議共計4天，ACC-2008今年選定的會議主題包含最新之應用計算等相關主題：例
如Software Engineering, Hardware Engineering, Data Bases, Expert Systems, Artificial Intelligence, 
Knowledge Engineering, Industrial systems, Autonomic and autonomous systems, Knowledge data systems, 
Knowledge Mining, Web-based education, E-Activities (E-Commerce, E-Education, E-Health, 
E-Goverment), Security, Cryptology, Computer Vision, Intelligent Techniques, Computer Logic, Multimedia, 
Video Systems, Internet Technologies, Signal Processing, Image Processing, Language-Speech processing, 
Digital Systems Design, Remote Sensing, Quantum Computing, Nano-Computing, DNA Computing and 
Biologically Inspired Algorithms, Robotics, Computer Vision, Visualization and Virtualization, 
Computational Intelligence (Neural Networks, Fuzzy Logic, Evolutionary Computing), Cognitive Systems, 
Systems performance, Networking and Telecommunications, Digital Communications, Applied 
Electromagnetics (Microwaves, Antennas, Radar, Scattering), Numerical Analysis and Scientific 
Computation, Algorithms and Complexity, Graph Theory, Pattern Recognition, Parallel and Distributed 
Systems, Supercomputing, Computers in Education等，會議內容之學術領域差異頗大且許多議程同
時進行，無法一一參與，因此縮小可參與議程之範圍，僅參與跟自身研究相關領域之議程。 
會議地點在伊斯坦堡市的Best Western-The President Hoel 進行，此旅館之環境設備相當不
錯，讓與會人士能在舒適的開會環境中進行學術交流。本次會議型式包括4個 Plenary speeches 
by world-renown scholars；8 個 Parallel sessions of oral presentations (Numerical analysis and 
scientific computation, Computational methods, Advanced computer technologies and algorithms, 
Software engineering, Computational intelligence, Applied software engineering and artificial 
intelligence, Modeling optimization and applications, Software engineering and computational 
intelligence)，以多樣式的學術交流方式，讓參與者除了能從學術文章發表的議程中瞭解他人
研究成果，而且透過由研究極有成就之學者與專家擔任的演講及討論，將最新的研究議題之
內容與進度做一精闢的論述，內容相當豐富。   
筆者此次所發表的論文安排在第二天口頭發表(Oral presentation)的 Software engineering 
& computational intelligence 場次，因大會安排得宜，此場次所發表之論文性質極為接近。此
次筆者所發表的論文題目為「小波轉換為基礎之主成份分析應用於自動化表面瑕疵偵測」，本
研究應用一階 Haar 小波轉換得到四個小波特徵作為描述表面紋路之特性，並搭配能降低維度
且整合多變數之主成份分析(Principle Component Analysis; PCA)整合四個小波特徵，找出最具
Wavelet-based Principal Component Analysis Applied to Automated 
Surface Defect Detection 
 
HONG-DAR LIN1, CHUNG-YU CHUNG1, WAN-TING LIN2 
 
1Department of Industrial Engineering and Management 
Chaoyang University of Technology 
168 Jifong E. Rd., Wufong Township, Taichung County, 41349 
TAIWAN 
hdlin@cyut.edu.tw 
 
2College of Business, University of Missouri-Columbia 
213 Cornell Hall, Columbia, MO 65211 
USA 
 
Abstract: - Automated visual inspection, a crucial manufacturing step, has been replacing the more 
time-consuming and less accurate human inspection. This research explores automated visual inspection of 
surface defects in a light-emitting diode (LED) chip. Commonly found on chip surface are water-spot defects 
which impair the appearance and functionality of LEDs. Automated inspection of water-spot defects is difficult 
because they have a semi-opaque appearance and a low intensity contrast with the rough exterior of the LED 
chip. Moreover, the defect may fall across two different background textures, which further increases detection 
difficulties. The one-level Haar wavelet transform is first used to decompose a chip image and extract four 
wavelet characteristics. Then, wavelet-based principal component analysis (WPCA) approach is applied to 
integrate the multiple wavelet characteristics. Finally, the principal component analysis of WPCA judges the 
existence of defects. Experimental results show that the proposed method achieves detection rates of above 
93.8%, and false alarm rates of below 3.6%. A valid computer-aided visual defect inspection system is 
contributed to help meet the quality control needs of LED chip manufacturers.  
 
Key-Words: - Surface defect detection, Wavelet characteristics, Principal component analysis, Computer vision 
system.  
 
1   Introduction 
Quality control is designed to prevent defective 
products from reaching the customer. Visual 
inspection constitutes an important part of quality 
control in the industry. In most cases, quality control 
through visual inspection is still conducted by 
humans. However, difficulties exist in detecting 
defects by human eyes because inspectors are very 
likely to make erroneous judgments due to personal 
subjectivity or eye fatigues. Visual inspection 
determines product properties using visual 
information and is most often automated by 
employing machine vision techniques. Therefore, 
automated visual inspection of surface defects has 
become a critical task for manufacturers who strive to 
improve product quality and production efficiency 
[1-4]. In this study, we use machine vision techniques 
for automated surface inspection of light-emitting 
diode (LED) chips.  
     LED is a semiconductor device that emits visible 
light when an electric current passes through the 
semiconductor chip. Compared with incandescent 
and fluorescent illuminating devices, LEDs have 
lower power requirement, higher efficiency, and 
longer lifetime. Typical applications of LED 
components include indicator lights, LCD panel 
backlighting, fiber optic data transmission, etc. The 
basic structure of an LED consists of the light 
emitting semiconductor chip, a lead frame where the 
chip is actually placed, and the encapsulation epoxy 
which surrounds and protects the chip. To meet 
consumer and industry needs, LED products are 
being made in smaller sizes, which increase 
difficulties of product inspection.  
 
(a) (b) (c)  
Fig. 1  LED chips images (a) normal chip (b) and (c) 
defective chips with water-spot defects 
 
APPLIED COMPUTING CONFERENCE (ACC '08), Istanbul, Turkey, May 27-30, 2008.
ISBN: 978-960-6766-67-1 245 ISSN: 1790-2769
In this research, we apply a standard decomposition 
that covers wavelet row and column transfers to do 
the wavelet transform of a two-dimensional image. 
The Haar transform can be computed stepwise by the 
mean value and half of the differences of the 
tristimulus values of two contiguous pixels. We 
perform the 2-D wavelet transform by applying 1-D 
wavelet transform first on rows and then on columns. 
Based on the transfer concept of the one-dimensional 
space, the Haar wavelet transform can process a 
two-dimensional image of (M x N) pixels in the 
following way:   
( )
( ) ( )
:
, 2 ( , 2 1)
( , ) ,
2
, 2 , 2 1
( , ) ,
2 2
0 ( 1), 0 1, [ ] .
2
R
R
Row transfer
g p q g p q
g p q
g p q g p qNg p q
Nwhere p M q is Gauss symbol
⎧ ⎡ ⎤+ +=⎪ ⎢ ⎥⎪ ⎣ ⎦⎪ ⎡ ⎤− +⎪ ⎡ ⎤+ =⎨ ⎢ ⎥⎢ ⎥⎣ ⎦ ⎣ ⎦⎪⎪ ⎡ ⎤⎪ ≤ ≤ − ≤ ≤ −⎢ ⎥⎪ ⎣ ⎦⎩
  (2) 
( )
( ) ( )
:
2 , (2 1, )
( , ) ,
2
2 , 2 1,
( , ) ,
2 2
0 1, 0 ( 1).
2
R R
C
R R
C
Column transfer
g p q g p q
g p q
g p q g p qMg p q
Mwhere p q N
⎧ ⎡ ⎤+ +=⎪ ⎢ ⎥⎪ ⎣ ⎦⎪ ⎡ ⎤− +⎪ ⎡ ⎤+ =⎨ ⎢ ⎥⎢ ⎥⎣ ⎦ ⎣ ⎦⎪⎪ ⎡ ⎤⎪ ≤ ≤ − ≤ ≤ −⎢ ⎥⎪ ⎣ ⎦⎩
                   (3) 
     In the above expressions (Eqs. (2)-(3)), ( , )g p q  
represents an original image, ( , )Rg p q  the row 
transfer function of ( , )g p q , and ( , )Cg p q  the 
column transfer function of ( , )Rg p q . As ( , )Cg p q  is 
also the outcome of the wavelet decomposition of 
( , )g p q , the outcomes of a wavelet transform can be 
defined as:   
( ) ( )
( ) ( )
1
2 3
, ( , ); , ( , );
2
, ( , ); , ( , );
2 2 2
0 1, 0 1.
2 2
C C
C C
NA p q g p q D p q g p q
M M ND p q g p q D p q g p q
M Nwhere p q
⎧ ⎡ ⎤= = +⎪ ⎢ ⎥⎣ ⎦⎪⎪ ⎡ ⎤ ⎡ ⎤ ⎡ ⎤= + = + +⎨ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥⎣ ⎦ ⎣ ⎦ ⎣ ⎦⎪⎪ ⎡ ⎤ ⎡ ⎤≤ ≤ − ≤ ≤ −⎪ ⎢ ⎥ ⎢ ⎥⎣ ⎦ ⎣ ⎦⎩
(4) 
     One level of wavelet decomposition generates one 
smooth sub-image and three detail sub-images that 
contain fine structures with horizontal, vertical, and 
diagonal orientations. An image is decomposed by 
wavelet transform into one approximation sub-image 
(A) and three detail sub-images (D1, D2 and D3). 
These four sub-images, each of which has a size of 
(M/2 x N/2) pixels, form the wavelet characteristics. 
Wavelet transform provides a convenient way to 
obtain a multi-resolution representation, from which 
texture features can be easily extracted. The merits of 
using wavelet transform include local image 
processing, simple calculations, high speed 
processing and multiple image information [16-18].  
 
 
2.2 Wavelet-based principal component 
analysis 
Principal component analysis (PCA) is a popular 
technique for data compression and has been 
successfully used as initial step in many computer 
vision tasks [19-20]. The principal components of a 
set of process variables 1x , 2x , …, px  are just a 
particular set of linear combinations of these 
variables. Geometrically, the principal component 
variables 1y , 2y , …, py  are the axes of a new 
coordinate system obtained by rotating the axes of 
the original system (the p ’s). The new axes 
represent the directions of maximum variability.  
     The basic intent of principal components is to find 
the new set of orthogonal directions that define the 
maximum variability in the original data, and this 
will lead to a description of the process requiring 
considerably fewer than the original p  variables. 
The information contained in the complete set of all 
p  principal components is exactly equivalent to the 
information in the complete set of all original process 
variables, but hopefully we can use far fewer than p  
principal components to obtain a satisfactory 
description [21].  
     Let the four random variables 1x , 2x , 3x , 4x  be 
the four wavelet characteristics and be represented by 
a vector [ ]1 2 3, , , A D D D ′=X  with covariance matrix 
Σ, and let the eigenvalues of Σ be 1λ , 2λ , 3λ , 4λ . 
Then the constants ije  are simply the elements of the 
ith eigenvector ie  associated with the eigenvalue iλ . 
Basically, if we let E be the matrix whose columns 
are the eigenvectors, then 
′ =E EΣ Λ                               (5) 
where Λ  is a 4 × 4  diagonal matrix with main 
diagonal elements equal to the eigenvalues 
1 2 4... 0λ λ λ≥ ≥ ≥ ≥ . More specifically, the equation 
can be expressed by the eigenvalues and the 
eigenvectors as follows:  
[ ]
1 2 3
1 1 1 2 1 3
2 2 1 2 2  3
3 3 1 3 2 3
2
, , , 
1 1
2
 , , , 2
1 2 3 4 2
3 ,  ,   , 
2 4
 ,  ,  ,  
              0   0   0
         0 
   
       
      
A A D A D A D
D A D D D D D
D A D D D D D
D A D D D D D
σ σ σ σ λ
σ σ σ σ
σ σ σ σ
σ σ σ σ
⎡ ⎤ ⎡ ⎤⎢ ⎥ ⎢ ⎥⎢ ⎥ ⎢ ⎥ =⎢ ⎥ ⎢ ⎥⎢ ⎥ ⎢ ⎥⎢ ⎥ ⎣ ⎦⎢ ⎥⎣ ⎦
e
e
e e e e
e
e
2
3
4
     0   0
0   0      0
0   0   0   
λ
λ
λ
⎡ ⎤⎢ ⎥⎢ ⎥⎢ ⎥⎢ ⎥⎣ ⎦
(6) 
APPLIED COMPUTING CONFERENCE (ACC '08), Istanbul, Turkey, May 27-30, 2008.
ISBN: 978-960-6766-67-1 247 ISSN: 1790-2769
suggests the probability of producing false alarms, i.e. 
detecting normal regions as defects. Statistical type II 
error β implies the probability of producing missing 
alarms, which fail to alarm real defects. We divide 
the area of normal region detected as defects by the 
area of actual normal region to obtain type I error, 
and the area of undetected defects by the area of 
actual defects to obtain type II error. The correct 
classification rate (CR) is defined as:   
( ) / 100%cc dd totalCR N N N= + ×           (9) 
where ccN  is the pixel number of normal textures 
detected as normal areas, ddN  is the pixel number of 
ripple defects detected as defective regions, and totalN  
is the total pixel number of a testing image.  
 
 
Fig. 2  Partial detection results of the Otsu, WPCA, 
and the professional inspector 
 
     The average detection rates (1-β) of all testing 
samples by the two methods are, respectively, 86.6% 
(Otsu method) and 93.8% (WPCA method). The 
proposed wavelet based multivariate statistical 
approach has higher detection rates (1-β) and correct 
classification rates (CR) than does the traditional 
method applied to LED chip images. The WPCA 
method excels in its ability of correctly 
discriminating water-spot defects from normal 
regions. The average computation time for 
processing an image of 256 x 256 pixels is as follows: 
1.84 seconds by the Otsu method, 2.26 seconds by 
the WPCA method. 
     As the decision threshold value changes, so do its 
false alarm rate (α) and detection rate (1-β), both of 
which are used to describe the performance of a test 
according to hypothesis testing theory [24]. When 
various decision thresholds (Eq. (8)) are used, their 
pairs of false alarm rates and detection rates are 
plotted as points on a Receiver Operating 
Characteristic (ROC) curve. Figure 3 presents the 
two ROC curves of the WPCA approach, and the two 
points of the Otsu method for the bonding pad and the 
emitting area respectively. The upper-left corner of 
Fig. 3 is the optimum points, which have a 100% 
detection rate and a 0% false alarm rate. The more the 
ROC plot approaches the upper-left corner, the better 
the test performs. In industrial practices, a more than 
90% detection rate and a less than 10% false alarm 
rate are a good rule of thumb for performance 
evaluation of a vision system. Accordingly, the 
proposed WPCA approach, with its ROC plots closer 
to the upper-left corner, outperforms the traditional 
method.  
0.6
0.7
0.8
0.9
1.0
0.0 0.1 0.2 0.3 0.4
False Alarm Rate (α)
D
et
ec
tio
n 
Ra
te
 (1
-β
)
Otsu method for bonding pad
WPCA method for bonding pad
WPCA method for emitting area
Otsu method for emitting area
 
Fig. 3  ROC plots of the Otsu and MPCA methods for 
bonding pad and emitting area 
 
 
4   Conclusion 
Machine vision technology improves productivity 
and quality management, and provides a competitive 
advantage to industries that employ this technology. 
This research applies wavelet-based multivariate 
statistical approach combined with machine vision 
techniques to detect water-spot defects that fall 
across two different background textures of LED 
chips. The proposed approach uses the wavelet-based 
principal component analysis to judge the existence 
of water-spot defects through multivariate processes 
of combining image characteristics from wavelet 
decomposition of local image blocks.  
     Experimental results show that the WPCA 
approach achieves detection rates of above 93.8% 
and false alarm rates of below 3.6% in detecting 
water-spot blemishes across two different 
background textures. As indicated in the ROC curve 
analysis, the WPCA approach has lower false alarm 
rates and better detection rates than does the Otsu 
method. This research contributes a solution to a 
common surface defect detection problem of LED 
chips and offers a computer-aided visual defect 
inspection system to meet the inspection and quality 
control request.  
 
 
APPLIED COMPUTING CONFERENCE (ACC '08), Istanbul, Turkey, May 27-30, 2008.
ISBN: 978-960-6766-67-1 249 ISSN: 1790-2769
