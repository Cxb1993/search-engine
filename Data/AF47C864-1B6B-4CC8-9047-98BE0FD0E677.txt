 目錄： 
報告內容 
一、 研究計畫中文摘要 
二、 研究計畫英文摘要 
三、 前言 
四、 研究目的 
五、 文獻探討 
六、 研究方法 
七、 結果與討論 
參考文獻 
計畫成果自評 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 二、研究計畫英文摘要：  
Keywords: colorization, automation, texture synthesis, tree-structured vector quantization 
 
Colorizing greyscale images has become an important research area in recent years since Welsh 
et al.’s groundbreaking work on “transferring color to greyscale images”. Despite the following 
work on improving the quality of the resulting images, there are still two issues remaining 
unsolved. The first issue is the automation of colorization process. Without automation, such a 
process will definitely become tedious in the face of greyscale images with heterogeneous 
contents, let alone the generalization to colorizing greyscale video where far more human effort 
will be expected. In fact, to our knowledge, there is only one paper titled as “automatically 
choosing the source image in the coloring process of greyscale images” by Vieira et al., which 
bears a similar objective, but their approach, as evidently suggested by its title, is quite different 
from ours. Inspired by the recent burst of papers on texture synthesis, we have observed hundreds 
of nature textures and are convinced that there should be just a relatively small number of 
possible textures assuming a target greyscale image was taken from a natural scene. Based on this 
observation, we first form a repertoire with appropriately chosen color textures, represented as a 
“micro-images” with fixed size, such as a 5×5 images. At the run time, given a greyscale image, 
each object (region), according to its texture, or more concretely its statistical property, it should 
be able to find the best match from the repertoire thus acquiring the desired color. The second 
issue is regarding the performance, as this colorization process often requires a lengthy execution 
time. We could borrow ideas from texture synthesis such as the “tree-structured vector 
quantization” to speedup the colorization process. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 們相似，然而其做法卻如其標題所示，與我們的想法有所不同。至於我們的靈感主要係得
自於最近蓬勃發展之有關「材質合成」 (texture synthesis)的論文，其沿革我們將於相關文
獻處細談。這其中我們觀察了上百種自然界中的材質，導致我們相信由自然界攝取的灰階
影像，其中所包含的可能材質的種類數目應不會太多，另一方面，一般自然界中常見的材
質種類其數目應該也是十分有限。根據如此的觀察出發，我們首先可以建造一個包含各類
材質的資料庫，而資料庫內所包含的是固定的大小的「微影像」(micro image)，例如 5×5
的影像。接著在程式執行時，針對所欲著色的灰階影像中的物件(區域)的材質，或是更具
體地說，物件(區域)的統計性質，我們由資料庫中找出最相近的具顏色的材質，接著即可
將該有色材質之顏色移轉至原 灰階的影像上。其次是 能(performance)的問題，根據
Welsh等人的數據，在 2002年時 Pentium 800MHz的PC執 其演算法，一張 640×480的灰
階影像費時約 15秒至 1分鐘，
像庫或影片時，此速度就顯得不
對此，我們可以借用在材質合
vector quantization)的想法來加快
參見之後的參考文獻。材質在我
如地形、植物、礦物質、毛皮和
很重要的目標，當我們對材質呈
如手繪或掃描一個圖片。手繪圖
圖片大小總是不合用或和在我們
們可以是很自由的方試來合成材
複。當我們對材質的邊界做處理
也是很廣，如去除雜訊、填充材
 
四、研究目的（引用文獻請
 
本研究的目的在於設計出一套高
用於大量灰階影像的著色，精確
還有最重要的即是自動化部分。
色的結果做得再好，也僅能適用
相對降低。將灰階影像著色可以
影像，電子顯微鏡影像等，由於
以著色，則增加色彩後不僅增加
見圖三。灰階影像著色更可以應
色電影，例如電影「亂世佳人」
色的技術尚未發展出來。 
 
 
 
 
 
 
 
 
 
 
 
Source  來
以
就單張影像而言此速度固然
足了。此主要因為替灰階影
成論文中所提及的「樹狀結
整個灰階影像著色過程。
們四處都很常見到。它可以
皮膚。在實體的世界中對
像時，也是希望如此。這
片很具有美感，但是它很
材質貼圖重複的部份會有
質。因為材質大小可以改
時，我們可以將材質如拼
質、和幫助資料壓縮。 
參見之後的參考文獻部
速而精確的灰階影像自動
係指其著色結果經人為檢
一旦缺少自動化，其應用
於少量灰階影像的著色工
應用在許多層面。例如將
影像的成像原理的限制，
了可看度，也可能再某些
用來將早期的黑白電影(事
就曾經歷過這樣的轉變，
+
Target
圖三(引自[9]) 效
行
不慢，然而若考慮數量龐大的影
像著色需涉及冗長的搜尋過程。
構向量式量化」(tree-structured 
在此對材質做一簡介，其詳述可
用一個表面特徵的變化來描述，
電腦圖學而言真實的重現是一個
些材質可以由不同的來源獲得，
難像照片般真實。大部份的掃描
縫線產生。材質合成時，其實我
變，所以我們必須避免讓材質重
圖般互相拼湊。材質的其它應用
分）： 
著色系統。高速係指此系統應可
驗(抽驗)後符合人的視覺經驗，
的價值即大幅降低，因為即使著
作，如此一來電腦介入的意義已
衛星影像，醫學上X射線(X-Ray)
經常都以灰階的形式呈現。若予
意義上而言提供了更多的資訊，
實上是灰階電影)著色後轉為彩
即使當時完全自動的灰階影像上
=
Final 
 間彼此的關聯度降低。這個空間是基於資料導向的人類視覺研究，而在此空間中彼此的關
聯性很低。 
 
5. Levin等人的「以最佳法來著色」(Colorization using Optimization)[13]: 
一般為灰階視訊的上色工作通常得先將某一張影像進行「區塊化」(segmentation)的動作，
對個別區塊著色後，再「追蹤」(track)各區塊在下一時間時的位置，因大部分的區塊形狀
及位置變化不大，其著色應可以沿用，至於一些變化較大或新出現的區塊，則需手動進行
修改。本篇論文嘗試提出一個簡單的方法既不需要精確的區塊化的動作，也不需要追蹤的
動作。使用者僅需在各區塊中描畫出想要的顏色，如圖四(a)，則此演算法則自動將之著色，
如圖四(b)。 
 
 
 
 
 
 
 
 
 
 
 (a) (b)
圖四(引自[13]) 
 
如此做法主要係根據一個簡單的前提：在時空上相鄰的像素應該具有相近的顏色。以此前
提，Levin等人定義一個二次的(quadratic)「價值函數」(cost function)，在以此函數為基準，
將著色問題視為一個解決「最佳化」(optimization)的問題，再以一些現存的技術來解此一
問題。相較之下，Welsh等人所提出的一個半自動化的方法，在其中將要轉換的灰階圖片
必須參考另一張彩色圖片，並轉換出具有參考圖片風格的彩色圖。Welsh等人調查像素鄰
域的亮度值並且從參考的圖片中轉換顏色給灰階影像。在明亮度的群組差異很大且有很大
不同的材質時出來其方法效果很好，而在其它的例子中，使用者必需直接利用帶狀來指示
相對應的區域在兩張影像中做搜尋，而其方法出來的結果也讓人印像深刻。注意到在Welsh
等人的做法中，藝術家對結果的支配上並非那麼直接：他必需先找到一個參考的彩色圖，
且在其內容中有要轉換的材質顏色，而在有問題的某些地方可能很難去找到一個會具有好
結果的圖案。相對的，使用本篇方法時，畫家可以直接選擇顏色而且如果有需要的話能在
草圖上再對顏色做精緻化。而且Welsh等人的方法不直接強迫顏色的連續性，且在一些影
像中它很有可能在相同的顏色亮度上卻給有不同的值，本篇的方法則較不具此缺點。 
 
6. Markle等人的彩色化過程[17]： 
在其過程中，一個彩色遮罩至少要手工上色一張影像來當參考畫面。動作偵測和追蹤也會
被應用到，只要沒有移動發生，顏色會自動傳遞到其它畫面的相對區域。移動的邊的附近
區域的顏色則會用「光流」(optical flow)的方法給值，通常在操作的時候仍需要手工的校
準。雖然大部份工業用的彩色化系統不是眾所皆知的，仍然有跡象[18]顯示這些系統還是
要在畫面中依定義的區域和軌跡來上色。Blackmagic[19]等商用的軟體在彩色化靜態影像
時提供了實用的刷子(brushes)和調色盤(color palettes)，但是分割(segmentation)的動作還是
要由使用者來做。 
 
7. Wei 等人的「以樹狀向量式量化進行之快速材質合成」(Fast Texture Synthesis using 
Tree-structured Vector Quantization)： 
 色成另一個材質的影像[54]，而且也可使用多樣材質組成來展示一個「3D的網格」(3D 
mesh)[53]。此方法一也可結合和Wei等人的方法來做影像類比。最近發表的成果中，
Ashikhmin [20]提出一個材質合成的方法，盡可能地利用貪婪法擴張存在的補丁(patch)而不
是在樣本材質中搜尋。這個演算法很快，而且出來的結果也比之前的方法來的好。然而，
這個方法當補丁在快結束的部份時會面臨一些問題，使得在材質合成的結果中造成突然不
連續的部份。此外Ashikhmin等人的方法也可以讓使用者依目標材質來繪想要的彩色影
像，也和Hertzmann等人所提方法中的「由多張圖片來做材質合成」(texture-by-numbers)
的動作很相似。另一個與影像類比相關的重要應用是從不同的樣本藝術樣本中自動材質合
成。在過去幾年，在計算機上已經有很多創造藝術風格的成果[26, 34, 37, 38, 42, 46, 49, 50, 
56, 57]，其中一個著名的領域就是NPR。在之前成果中的一個缺陷就是只能符合特定的呈
像的風格。相對的，使用影像類比對即使是一些沒有良好創作的風格，我們仍然能很有效
率地轉換它。 
 
10. 其餘有關影像類比的文獻： 
有關影像類比的一個核心問題是機械學習。所謂「類比」的推論就是說要去解決、學習、
和創造[41, 42, 61]。在此原因下，早期的人工智慧目標就是建立一個系統能做類推的動作；
而早期的成果包含Evan等人的ANALOGY程式[30]和Winston等人所提出的，具有同步尋找
與利用能力的簡單而又有開創性的理論[58]。最近，在電腦圖學上一些機械學習的應用的
問題已經被發表了，包含視訊重寫[23]、聲音木偶(voice puppetry)[22]、視訊材質(video 
texture)[51]、機械風格(machine style)[62]。最近和類比最相關的研究有Freeman等人[31]，
他們利用「馬可夫隨機場」(Markov Random Field)來學習影像，想要學習一種從一些已獲
得的影像推到另一影像的轉換，像是從低解析度資訊中來粹取高解析度的資訊，即「超解
析」，或是從一對影像中推論其「光學流」 (optical flow)的資訊。另外，在最近幾年，在
計算機圖學和電腦視覺上在材質合成領域中有很多成果已發表出來:能創造出一與給定的
數位圖片外貌相符的材質圖片。在 1995年Heeger和Bergen[36]在電腦圖學社群中就提到這
個問題了。還有，De Bonet[21]和Efros和Leung[27]提出用最近鄰域搜尋來一個做材質合
成，分別用多尺度(mulitsacle)和單一尺度(singescale)的方式，在一個單獨過程中就可以得
到很好的結果。(這個研究可以看做是一種近似於對一個MRF做取樣。(Zhu等人[60]和
Portilla和Simoncelli[48]有使用到這方法。) Wei 和Levoy[55]統合這些方法，使用粗略的尺
度(coarser scale)和現在相同的尺度(current scale)的像素鄰域來決定像素值。「向量量化」 
[33]或分群可以加速其中對「最近鄰居」(nearest neighbor)的計算[31, 44, 45, 47, 55]。在一
份尚未發表的成果中，Eilhauer[29]等人提出了一個能和輸入影像相似的材質合成的方法，
稱其為「材質轉換」(texture transfer)。在這些相似的研究中，Efros和Freeman[28]提出一個
材質合成的改進方法，而且也能在材質上做轉換。另外與影像類比相關的是「範例呈像」 
(example-based rendering)，主要目的係設法利用NPR的方式來處理其他影像。最早的例子
就像Adobe PhotoShop的 clone brush或是Corel Painter的 image hose。最近有大量的
EBR(example-based rendering)式的NPR在不同的研究中被提出來[24, 39, 40, 59]。或許其中
與類比精神最相似的方法就是由樣本來創造筆觸的方式 [35]。 
 
11. 其餘有關材質合成的文獻： 
在材質分析和合成的領域中方法已經有很多，以下簡單地說明在其他三個相關領域的發展
情況。一、在「物理模擬」 (Physical Simulation)方面，我們可以直接利用一些物理產生的
過成中合成一些表面。其中一些生物的圖樣，如:毛髮、鱗、和皮膚可以使用一些「回饋擾
動」(Reaction-diffusion) [71]和「細胞材質基礎函數」(cellular texture basis function)[72]。一
些風化和礦石的現象也可以在這方法中忠實詳細地模擬出來[64]。這些技術也可以直接由
3d網格來做材質合成，以避免材質映射時扭曲的情況。然而，不同的材質通常有不同的物
理生成方式，所以這樣的方法只能限定在某些材質上。二、在「馬可夫隨機場和吉伯斯抽
樣」 (Markov Random Filed and Gibbs Sampling)方面，有許多演算法用馬可夫隨機場來模
 3. 資料庫內容選取 
除了資料庫的表示是一個問題外，另一個更重要的問題是資料庫內容的選取。不論是微影
像或完整影像，當我們可以從網路上下載成千上萬張影像時，究竟要如何選取適當的內容
放進資料庫，成為另一項重要的決定。將所有找得到的影像皆選入並不是一個睿智的決
定，這可以由考慮以下的例子來說明。假設目標灰階影像之內容為樹，而所有彩色來源影
像中必定有包含樹的各式各樣的影像或微影像，其中有白天的樹，夜晚的樹，冬天的枯樹，
春夏的綠樹以及秋天泛黃的樹，更別提世上還有可能存在一些亮度分布類似，而根本不是
樹的東西。簡而言之，若我們的資料庫將之照單全收，則因為其樣本空間變大，則其亮度
分布之重複的機率也變大，導致錯誤率也提高。較合理的做法可能事先侷限我們可處理問
題的空間，在該空間先尋求較合理或完滿的解答，再設法將空間的侷限去除或是所有的問
題空間可細分為數個不同的空間分別處理，其屬性雖不同，但解決的方式卻大同小異。例
如我們可先從白天的，戶外的，春夏之交的自然場景著手，如此一來問題所考慮的空間即
大大縮小。但如前所述，即便在如此侷限的場景可能仍無法避免出現亮度相近但顏色相距
甚大的情形。對此我們可能會考慮以人為介入的方式消除其模糊性或者加入註解以方便於
適當時處理。注意此處的人工處理係於建資料庫執行，為前置處理時間。整體言之，在場
景的侷限下，不論是以微影像或是全影像的表示，我們將會計算一個輸入的單元其與目前
資料庫內已存在的單元相比是否更具有代表性，若如此，則資料庫中的單元則被替換；否
則，此新輸入者將被捨棄。如此的做法具有「貪婪法」(greedy method)的精神，雖不見得
可以從所有的輸入影像中就資料庫的給定大小找出最佳的代表集，然而應也相去不遠。其
實問題的核心在於「測量標準」(metric)的問題，因為我們可能無法自動，定量地來決定哪
一張(微)影像具有更高的代表性，因而可能僅能使用「近似的」(approximated)的測量標準。
例如兩張影像的「距離」(distance)或「不相似度」(dissimilarity)可以定義為其「差向量」
(difference vector)的L2 Norm，意即其各個對應點的值之差的平方和。如此的近似可能導致
結果的誤判，但也方能使得人為的介入大幅降低，提高解決問題的可行性。一旦在一侷限
場景成功，而欲將之推廣到其他場景時，我們事實上還得面臨兩個問題：一是如何將龐大
的彩色來源影像分類？二是如何自動地知道一張給定的灰階影像是屬於哪一類？頭一個
問題的解決由於是在前置處理時間，在時效上較無壓力；況且可能於每一類我們所選入資
料庫內的(微)影像的數目並不大，手動尚可應付。至於第二個問題十分明顯地我們將不想
訴諸手動，否則與其他研究相較本研究即失去意義，故一個「自動灰階影像分類系統」可
能就變得十分重要。目前的想法是利用「數值分布圖」(histogram)來作為判斷依據，但實
際的成效必須做過實驗方知。 
4. 加快上色速度 
最後是有關效能的問題，此可分為兩個層面來談。第一，Welsh等人的原始做法速度上如
前所述已顯得有些緩慢，尤其是若要針對影片的處理，其速度的提昇更是必須。第二，相
對於Welsh等人的做法，我們所需進行比對的資料庫大小很可能較原始做法中的來源影像
還大，因此在速度上若無加速，將更顯得其效能的減緩。關於此，我們可以借用Wei等人
的做法[55]，以「樹狀結構的向量式量化」(tree-structured vector quantization), 將資料庫中
的操作單元，微影像或全影像，依其向量式量化的方式分群。注意到此處若無分群的處理，
面對灰階影像上的任一點，所有資料庫內的樣本皆須被一一比較後才能找出最近者，而在
分群後，相當於我們對所有資料庫內的資料建立一「樹狀的資料結構」(tree structure)，故
而其搜尋時間可由「線性的」(linear time complexity)縮短為「對數的」(logarithmic time 
complexity)，或者換句話說，採用資料庫的想法才可能行得通。當然這其中尚有許多細節
有待釐清，例如如何分群？一張彩色來源影像該分幾群？或者分幾群應非絕對，而是與「資
料相關」(data-dependent)，那麼其「門檻值」(threshold)應如何隨資料而相關地設定？另外
在每一群內要如何訂定「代表向量」(representative vector)？這些都需要詳細地加以測量與
界定。 
 
進行步驟： 
  
  
  
  
  
  
 
   
原始影像 A1                        灰階影像 A2
  
         
  
  
  
  
  
  
Welsh結果 A3              我們結果A4 
 
 
    
  
  
  
  
  
  
  
  
 
    原始影像 B1                           灰階影像 B2
    
 
   
  
  
  
  
        
 
 
 
  Welsh結果 B3       我們結果B4              Blasi結果B5 
 
 
 
 
 
   
  
  
  
  
  
  
我們實作圖 1              我們實作圖 2 
 
  
  
  
  
  
  
我們實作圖 3 
圖六 以Welsh方法下無人為介入之實作圖 
參考文獻： 
[1] C. Yang and T. Chiueh, “I/O Conscious Volume Rendering”, VisSym ’01, Joint Eurographics 
- IEEE TCVG Symposium on Visualization, May 2001. 
[2] T. Mitra, C. Yang and T. Chiueh, “Application-Specific File Prefetching for Multimedia 
Programs”, IEEE Multimedia 2000, pp. 459-462, July 2000. 
[3] C. Yang, T. Mitra and T. Chiueh, “A Decoupled Architecture for Application-Specific File 
-Prefetching”, Usenix Annual Conference, FREENIX track 2002, pp. 157-170, June 2002. 
[4] T. Chiueh, C. Yang, T. He, H. Pfister and A. Kaufman, “Integrated Volume Compression and 
Visualization”, IEEE Visualization ’97, pp. 329-336, October 1997. 
[5] C. Yang, T. Mitra and T. Chiueh, “On-the-Fly Rendering Of Losslessly Compressed Irregular 
Volume Data”, IEEE Visualization ’2000, pp. 101-108, October 2000. 
[6] T. Chiueh, T. Mitra, A. Neogi and C. Yang, “Zodiac: A History-Based Interactive Video 
Authoring System”, ACM Multimedia 1998, pp. 435-444, September 1998. 
[7] T. Chiueh, T. Mitra, A. Neogi and C. Yang, “Zodiac: A history-based interactive video 
authoring system”, Multimedia Systems, vol. 8, no. 3, pp. 201-211, 2000. 
[8] Chiang-Han Hung and C. Yang, “A New Approach of Seed-set Finding for Iso-Surface 
Extraction”, International Computer Symposium, December 2004. 
[9] T. Welsh, M. Ashikhmin, and K. Mueller, “Transferring Color to Greyscale Images”, 
Proceedings of SIGGRAPH 2002, July 2002. 
 [32] William T. Freeman, Joshua B. Tenenbaum, and Egon Pasztor”, An Example-Based 
Approach to Style Translation for Line Drawings”, Technical Report TR99-11, MERL, February 
1999. 
[33] Allen Gersho and Robert M. Gray, “Vector Quantization and Signal Compression”, Kluwer 
Academic Publishers, 1992. 
[34] Paul E. Haeberli, “Paint By Numbers: Abstract Image Representations”, In Computer 
Graphics (SIGGRAPH ’90 Proceedings), volume 24, pages 207–214, August 1990. 
[35] J. Hamel and T. Strothotte, “Capturing and Re-Using Rendition Styles for 
Non-Photorealistic Rendering”, Computer Graphics Forum, 18(3):173–182, September 1999. 
[36] David J. Heeger and James R. Bergen, “Pyramid-Based Texture Analysis/ Synthesis”, 
Proceedings of SIGGRAPH 95, pages 229–238, August 1995. 
[37] Aaron Hertzmann, “Painterly Rendering with Curved Brush Strokes of Multiple Sizes”, In 
SIGGRAPH 98 Conference Proceedings, pages 453–460, July 1998. 
[38] Aaron Hertzmann and Denis Zorin, “Illustrating smooth surfaces”, Proceedings of 
SIGGRAPH 2000, pages 517–526, July 2000. 
[39] Youichi Horry, Ken ichi Anjyo, and Kiyoshi Arai, “Tour Into the Picture: Using a Spidery 
Mesh Interface to Make Animation from a Single Image”, Proceedings of SIGGRAPH 97, pages 
225–232, August 1997. 
[40] AllisonW. Klein,WilmotW. Li, Michael M. Kazhdan,Wagner T. Corrˆea, Adam Finkelstein, 
and Thomas A. Funkhouser, “Non-photorealistic Virtual Environments”, Proceedings of 
SIGGRAPH 2000, pages 527–534, July 2000. 
[41] Arthur Koestler, “The Act of Creation. Picador”, London, 1964. 
[42] Michael A. Kowalski, Lee Markosian, J. D. Northrup, Lubomir Bourdev, Ronen Barzel, 
Loring S. Holden, and John Hughes, “Art-Based Rendering of Fur, Grass, and Trees”, 
Proceedings of SIGGRAPH 99, pages 433–438, August 1999. 
[43] G. Lakoff and M. Johnson, “Metaphors We Live by”, University of Chicago Press, Chicago, 
IL, 1980. 
[44] Thomas Leung and Jitendra Malik, “Recognizing Surfaces using Threedimensional 
Textons”, 7th IEEE International Conference on Computer Vision, September 1999. 
[45] Jitendra Malik, Serge Belongie, Jianbo Shi, and Thomas Leung, “Textons, Contours, and 
Regions: Cue Integration in Image Segmentation”, 7th IEEE International Conference on 
Computer Vision, September 1999. 
[46] Barbara J. Meier, “Painterly Rendering for Animation”, In SIGGRAPH 96 Conference 
Proceedings, pages 477–484, August 1996. 
[47] Kris Popat and Rosalind W. Picard, “Cluster-Based Probability Model and Its Application to 
Image and Texture Processing”, IEEE Transactions on Image Processing, 6(2):268–284, 
February 1997. 
[48] J. Portilla and E. P. Simoncelli, “A Parametric Texture Model based on Joint Statistics of 
Complex Wavelet Coefficients”, International Journal of Computer Vision, 40(1):49–71, 
December 2000. 
[49] Michael P. Salisbury, Sean E. Anderson, Ronen Barzel, and David H. Salesin, “Interactive 
Pen–And–Ink Illustration”, In Proceedings of SIGGRAPH ’94 (Orlando, Florida, July 24–29, 
1994), pages 101–108, July 1994. 
[50] Michael P. Salisbury, Michael T. Wong, John F. Hughes, and David H. Salesin, “Orientable 
Textures for Image-Based Pen-and-Ink Illustration”, In SIGGRAPH 97 Conference Proceedings, 
pages 401–406, August 1997. 
[51] Arno Sch¨odl, Richard Szeliski, David H. Salesin, and Irfan Essa, “Video Textures”, 
Proceedings of SIGGRAPH 2000, pages 489–498, July 2000. 
 Conference Proceedings, Annual Conference Series, pages 291–294. ACM SIGGRAPH, 
Addison Wesley, Aug. 1996.  
[73] S. Zhu, Y. Wu, and D. Mumford, “Filters, Random Fields and Maximun Entropy (FRAME) 
- towards a Unified Theory for Texture Modeling”, International Journal of Computer Vision, 
Vol. 27, No, 2, pp.107–126, 1998. 
[74] G. Di Blasi, D. Reforgiato, “Fast Colorization of Gray Images”, In Proceedings of 
Eurographics Italian Chapter 2003. 
 
計畫成果自評： 
 
在轉換的成果上來看，本方法所轉換出的影像效果不錯，尤其是在複雜的材質變換上能夠
正確的選擇材質進行顏色轉換。其品質並不遜於 Welsh 的結果，且在大部份的影像上能得
到比 Welsh更佳的影像上色品質。而且在我們的方法中，更利用兩種不同的鄰域選擇，使
得在鄰域的選定上可以較固定，不須隨影像的變換而更改鄰域的大小。這在使用Welsh的
方法時會是一個很大的變因，因不同的鄰域選取將造成不同的品質，而如何才能選擇一個
最適合此影像的鄰域大小是一個很重要的且很難解決的問題。因此利用我們的方法可以減
少人為的介入，朝全自動化邁向一大步。另外在轉換顏色時所花費的時間上，我們利用分
群樹來有效的減少時間，尤其在對大量影像彩色化時，更可以大大的加快彩色化速度。 
 不過我們的方法仍然會有失敗的時候，例如當我們的兩材質特性十分相似時，在其判
定上就可能出錯，如下圖: 
  
  
  
 
 
  
  
  
原始圖 K1            灰階圖 K2 
   
  
  
 
  
  
  
  
Welsh法 K3        我們結果 K4 
 
圖七 失敗結果比較圖 
 
在 K1 圖中包含有沙灘、海和天空，但是這些影像在轉成灰階影像後以人眼方式來判別可
能會認為其存在且能辨認，但是兩者無論是以 L2 norm或是以統計方式求平均值、變異數
或是梯度都難以發現這三者(沙灘、海和天空)有任何顯著的不同，當然在轉換上必然會出
現誤差，也使得海、天和沙灘出現顏色傳遞上的錯誤。在灰階圖形轉換上，這仍然有很大
的進步空間。未來也許可以結合人工智慧和影像分割的技術來更確定各物件，讓上色能以
物件方式來決定，這也將使顏色轉換的準確性提高。 
 至於在未來的發展上，為了能夠完全自動化，我們希望能夠建立影像資料庫，找出具有代
出席國際學術會議心得報告 
                                                             
計畫編號 NSC 95-2221-E-011-123 
計畫名稱 有關灰階影像自動上色技術之研究 
出國人員姓名 
服務機關及職稱 
楊傳凱 
國立台灣科技大學資訊管理系助理教授 
會議時間地點 May 23~25/2007, Norrkoping, Sweden 
會議名稱 EuroVis 2007 
發表論文題目 並無發表論文 
 
一、參加會議經過 
歐洲資料視覺化會議是一年一度的會議，其會議地點係在歐洲各國輪流舉行。該會
議原名為 VisSym(Visualization Symposium，資料視覺化會議)，在前年正式更名為
EuroVis(歐洲資料視覺化會議)，雖然其歷史僅有九年，但已成為在歐洲有關資料視覺化
(visualization)最重要的會議。今年約有 120 篇的投稿，而僅接受其中的 35 篇，錄取
率約為三分之一。歐洲資料視覺化會議的參與者來自世界各地，尤以歐美的研究者為眾。 
 
本人由台灣搭乘長榮航空的班機，過境巴黎，到達斯德哥爾摩，並於 5 月 22 凌晨抵達
Norrkoping。其間參與了大部分的會議歷程(5/23 ~~ 5/25)，更於互相討論交流中獲得
許多第一手的相關知識，也結識了許多異國的研究者，可謂收穫良多。回程時也順道在
瑞典遊玩參訪，北歐傳統的建築風情及各博物館內的豐富館藏都令人流連忘返。最後回
程時由倫敦轉機，經曼谷於 5/27 日深夜抵達台灣。 
 
二、與會心得 
    如前所述，本次會議共有 35 篇論文入選，且皆為口頭報告的形式。會議的進行係採
「單軌制」(single track),亦即同時間僅有一篇論文的發表。這樣做的好處是有興趣的
人不會錯過任何一篇論文，但缺點即是會議時間容易拖得過長。但由於此會議的論文總
數不多，所以並無時間過長的問題。  
 
本次會議共計討論過以下的主題： 
 
Time-Series Visualization 
Text and Document Visualization  
Graph Visualization 
Interaction Design 
Multivariate Visualization and Rendering 
Visualization Systems for Applications 
Feature Extraction 
