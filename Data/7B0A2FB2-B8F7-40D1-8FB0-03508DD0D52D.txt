 1
1. INTRODUCTION 
 
The music similarity measurement is important for the automated analysis of melodic fragments. Some 
factors must be considered when developing algorithms for this measurement, including the feature selection, 
the music data format, and the tolerance to noise. Since melodic fragments may be transformed or distorted in 
various ways, music matching must be able to tolerate such variation. Music is made up of musical notes, 
each of which has many attributes such as pitch, duration, loudness, timbre, and so on. Byrd et al. [5] 
indicated that pitch alone is not sufficient for searching in a large database. Smith et al. [18] concluded that 
pitch and pitch duration are the most important attributes, and their findings will be followed in this research. 
Symbolic music representation and the audio wave format [8] are the most commonly used methods in 
practice. While symbolic music represents the musical attributes of music notes including pitch, duration, and 
loudness, the audio wave format specifies the amplitude of sound over a time series. 
For comparing two melodic fragments, techniques based on geometric matching have been explored over 
the past few years, including point set matching [6][24] and sweeping-line matching [1][12][13]. The 
advantage of geometric matching is its high accuracy rate of search; while its drawback is its time complexity 
usually exceeding a polynomial of degree 2. 
String matching techniques are more efficient than geometric matching and have also been extensively 
explored in the literature [2][4][5][7][9][10][14][16][18], including dynamic time warping (DTW), longest 
common subsequence (LCS)-based methods, and alignment [10][20][21]. The DTW algorithm "warps" two 
sequences non-linearly in the time dimension to evaluate the similarity value, and is suitable for audio or 
speech comparison [11][23]. The LCS method evaluates the similarity between two sequences by counting the 
number of matched symbols without considering the local correlation between the matched subsequence 
(common subsequence) and each of the two sequences. As a result, the LCS method does not characterize the 
local information such as gaps or mismatched symbols of the common sequence, and it belongs to sort of 
global alignment [10], which is not suitable for matching a shorter music segment against a much longer one. 
Most LCS-based techniques are associated with a penalty function to overcome the problem of global 
alignment, to become so called local alignment matching. 
Mongeau et al. [16] used a type of edit distance for music dissimilarity measure, which was calculated by 
 3
The remainder of this project is organized as follows. Section 2 provides a detailed description of our 
proposed method. The use of the filtering algorithm is described in Section 3. Section 4 shows the 
experimental results of the proposed method and compares them with a method of local alignment. Finally, 
we draw our conclusions and provide suggestions for future work in Section 5. 
2. LCS AND ROUGH LCS (RLCS) 
For string-based methods, a melody (music segment) is represented by a string (or sequence) of entries, 
where each entry specifies the features of one music note. In this section, we present a modified version of the 
longest common subsequence (LCS) matching method, called the rough longest common subsequence (RLCS) 
matching method. Although, for simple explanation, the music notes are characterized by pitches and 
durations in this section, they are characterized by pitch intervals and duration ratios in our proposed system 
to achieve key invariance and tempo invariance. In section 2.1, we briefly introduce the LCS and define WAR 
and WAQ for measuring the local similarity between two sequences. We then define the RLCS and describe 
how to apply it in music matching in Section 2.2. In section 2.3, the evaluation of RLCS is described. 
 
2.1 LCS 
 
Let X = <x1, x2, ..., xm> be a sequence (or a string) of m characters. Then a subsequence of X must be of 
the form X’ = <xi1, xi2, ..., xik>, miii k ≤<<<≤ ...1 21 ; while a substring of X must be of the form X’’ = <xj, 
xj+1, ..., xj+d>, mdjj ≤+≤≤1 . Therefore, any substring of X must be also a subsequence of X. 
In the longest-common-subsequence (LCS) problem, we are given two sequences and wish to find a 
maximum-length common subsequence of them. This problem can be solved efficiently using dynamic 
programming. LCS solution has been widely adopted for music matching. However, its value alone is not 
enough to reflect the degree of similarity or matching of two sequences. For the sequence X = <x1, x2, ..., xm>, 
we define its subsequence (or substring) as X[i..j] = <xi, xi+1, ..., xj> and ith prefix as Xi = <x1, x2, ..., xi> for 0 ≤ 
i ≤ j ≤ m. It is obviously that Xi = X[1..i]. 
Given two sequences X = <x1, x2, ..., xm> and Y = <y1, y2, ..., yn>, called reference and query, respectively. 
The length of the longest-common-subsequence (LCS) of the prefixes Xi and Yj can be evaluated by the 
 5
⎪⎪
⎪
⎩
⎪⎪
⎪
⎨
⎧
<≠>⋅−
=−≥≠>⋅
>−≥≠>⋅+−
=>⋅+−−
=⋅
=
].1[]1[ , ,0]1,[
,0],1[],1[]1[ , ,0 0
,0],1[],1[]1[ , ,01 ],1[
      , ,0 1 ]1,1[
                                         ,00
],[
i, j -  c , ji - cyxjijiw
jiwi, j -  c , ji - cyxji
jiwi, j -  c , ji - cyxjijiw
yxjijiw
ji
jiw
ji
R
R
ji
R
ji
R
ji
R
R
     (2) 
 
 
⎪⎪
⎪
⎩
⎪⎪
⎪
⎨
⎧
=−<≠>⋅
>−<≠>⋅+−
≥≠>⋅−
=>⋅+−−
=⋅
=
.0]1,[],1[]1[ , ,00
 ,0]1,[],1[]1[ , ,0 1]1,[
     ],1[]1[ , ,0 ],1[
      , ,01 ]1,1[
                                                                        ,00
],[
jiwi, j -  c , ji - cyxji
jiwi, j -  c , ji - cyxjijiw
i, j -  c , ji - cyxjijiw
yxjijiw
ji
jiw
Q
ji
Q
ji
Q
ji
Q
ji
Q
Q
     (3) 
 
With the three tables c, wR and wQ, we may fairly search for the best match of the query prefix Yj against 
the reference prefix Xi as follows. The terms c[i, j]/ Rw [i, j] and c[i, j]/ Qw [i, j] represent how densely the LCS 
of Xi and Yj is distributed over these two prefix sequences and can be used to fairly evaluate the match. In this 
work we define the score of the match as the product of the weighted average of these two measures and the 
ratio of the length of the LCS to that of the query, as given in (4), where β  is a weighting parameter and ρ  
is a required matched rate on the entire query sequence. It is obvious that 0 ≤ s[i, j] ≤ 1, and it indicates an 
exact match when s[i, j] =1. 
 
⎩⎨
⎧ ≥⋅−+=
         otherwise                                     0
],[if)/],[(]),[/],[)1(],[/],[(
],[
njicnjicjiwjicjiwjic
jis
QR ρββ         (4) 
 
In the example of music sequence matching given in Figure 2, for the query Y, X is a relevant reference 
but X’ is not. The lengths of LCSs of the pair (X, Y) and the pair (X’, Y) are both 5, and thus the similarity 
measure for Y and X would be equal to that for Y and X’ while using LCS. The score defined in (4) can be 
used to provide a fairer similarity measure as follows: Since WAR(X, Y) = 5, WAQ(X, Y) = 5, WAR(X’, Y) = 
15, WAQ(X’, Y) = 5, and LCS(X, Y) = LCS(X’, Y) = 5, with the setting β = 0.5 and ρ = 0.8, we have the 
scores for the matches of Y against X and X’, (0.5)(5/5)+(0.5)(5/5) = 1 and (0.5)(5/15)+(0.5)(5/5) ≈ 0.667, 
respectively. As a result, the use of the score function defined in (4) can fairly distinguish the relevant 
reference from the database. 
 
 7
sequences R and Q by the recursive formulae given in (6) ~ (8). Note that, cr[i, j] representing the “length” of 
the RLCS of Xi and Yj is a real number. For each match of a pair of notes, the length of the RLCS is increased 
by (1– d(ri, qj)/Td) rather than 1 as LCS usually does. The increment (1– d(ri, qj)/Td) is between 0 and 1 since 
d(ri, qj) ≤ Td. The smaller the distance is the greater the increment is. We called this length “weighted length”. 
The weighted length is always not greater than the true length. 
 
⎪⎩
⎪⎨
⎧
≈>⋅−−
≈>⋅+−−
=⋅
=
. !  and  0]),1[  ],1,[max(
,  and  0))/(-1(  ]1,1[
              ,0                                        0
],[
jirr
jidjirr
qrjijicjic
qrjiT,qrdjic
ji
jic                      (6) 
 
 
⎪⎪
⎪
⎩
⎪⎪
⎪
⎨
⎧
<≈>⋅−
=−≥≈>⋅
>−≥≈>⋅+−
≈>⋅+−−
=⋅
=
].1[]1[ ,!  ,0]1,[
,0],1[],1[]1[ ,!  ,0 0
,0],1[],1[]1[ ,!  ,01 ],1[
  , ,0 1 ]1,1[
      ,00
],[
i, j -  c , ji - cqrjijiw
jiwi, j -  c , ji - cqrji
jiwi, j -  c , ji - cqrjijiw
qrjijiw
ji
jiw
rrji
R
r
R
rrrji
R
rrrji
R
r
ji
R
r
R
r
 (7) 
 
⎪⎪
⎪
⎩
⎪⎪
⎪
⎨
⎧
=−<≈>⋅
>−<≈>⋅+−
≥≈>⋅−
≈>⋅+−−
=⋅
=
.0]1,[],1[]1[ ,!  ,00
 ,0]1,[],1[]1[ ,!  ,0 1]1,[
],1[]1[ ,!  ,0 ],1[
   ,  ,01 ]1,1[
 ,00
],[
jiwi, j -  c , ji - cqrji
jiwi, j -  c , ji - cqrjijiw
i, j -  c , ji - cqrjijiw
qrjijiw
ji
jiw
Q
rrji
Q
rrrji
Q
r
rrji
Q
r
ji
Q
r
Q
r
 (8) 
 
 
2.3 Evaluation of RLCS 
 
Let Z = <z1, z2, …, zk> be the LCS of Ri and Qj and assume it corresponds to the subsequences <ri1, 
ri2, …, rik> and <qj1, qj2, …, qjk> of Ri and Qj, respectively, obtained in the matching process. That is, <z1, 
z2, …, zk> = <ri1, ri2, …, rik> = <qj1, q j2, …, qjk>. Note that k = cr[i, j], Rrw [i, j] = ik – i1 + 1, and Qrw [i, j] = jk – 
j1 + 1. The terms cr[i, j]/ Rrw [i, j] and cr[i, j]/ Qrw [i, j] denote the matched rates for the range across the reference 
prefix Ri and the range across the query prefix Qj, respectively, which can be used to evaluate a match. For 
this purpose, we define the matching score sr as the product of the weighted matched rate and the weighted 
length of the corresponding common sequence in (9), where β  is a weighting parameter and ρ  is a 
required matched rate on the entire query sequence. 
 9
Algorithm RLCS (R = <r1, r2, …, rm>, Q = <q1, q2, …, qn>) 
1   for i ← 1 to m; 
2     do  cr[i, 0] ← 0; Rrw [i, 0] ← 0; Qrw [i, 0] ← 0; 
3   for j ← 0 to n 
4     do  cr[0, j] ← 0; Rrw [0, j] ← 0; Qrw [0, j] ← 0; 
5   for i ← 1 to m; 
6    do for j ← 1 to n 
7      do if ri ≈  qj; 
8        then  cr[i, j] ←cr [i-1, j-1] + ))/ ,(1( dji Tqrd−  
9                b[i, j] ← "↖"; 
10          Rrw [i, j] ← Rrw [i-1, j-1] + 1; 
11          Qrw [i, j] ← Qrw  [i-1, j-1] + 1; 
12        else  if cr [i-1, j] ≥ cr [i, j-1]  
13           then  cr [i, j] ←cr [i-1, j];  
14                 b[i, j] ← "↑"; 
15                  Qrw [i, j] ← Qrw [i-1, j]; 
16               if Rrw [i-1, j] > 0 
17                then Rrw [i, j] ← Rrw [i-1, j] + 1 
18                 else Rrw [i, j] ← 0 
19            else cr [i, j] ←cr [i, j-1]; 
20              b[i, j] ← "←"; 
21              Rrw [i, j] ← Rrw [i, j-1]; 
22              if Qrw [i, j-1] > 0      
23                 then Qrw [i, j] ← Qrw [i, j-1] + 1 
24                 else Qrw [i, j] ← 0; 
25          if njicr ⋅≥ ρ],[  
26            then sr[i, j] ← ],[/]),[()1(],[/]),[( 22 jinwjicjinwjic QrrRrr ββ −+  
27            else sr[i, j] ← 0; 
28  score ← maxi,j sr[i, j]; 
29  return score 
 
 11
niknc
n
scq
ciShift sisk ≤≤−Σ∈⎩⎨
⎧ == −>  ,for  
otherwise
existsif}{min
),( 0                   (11) 
 
Both the Badchark and the Shiftk tables can be precomputed. Some of the potential reference areas that 
have to be checked with the RLCS algorithm might be overlapped, and so are then the matching processes. To 
address this problem, instead of individually checking each potential reference area with the RLCS algorithm, 
we check the union of all the potential reference areas with the RLCS algorithm. The RLCS matching 
algorithm combined with the filtering algorithm, called FRLCS, is summarized below. The preprocess of the 
filtering algorithm moves the query, which is generally much smaller than the reference, along the reference 
multiple steps at a time. It searches for possible fragments of the reference that are about the same length as 
the query to match against. As a result the computation time for matching is greatly reduced. If we let τ denote 
the error tolerance rate, then k = τ n (n is the size of the query). 
 
 13
computation time for exact matching and for approximate matching with a low error tolerance, but not for 
approximate matching with a high error tolerance for which the reference won’t be filtered to any extent. To 
maintain the retrieval rate and the ranking, the error tolerance rate must be greater than the noise rate of the 
query; i.e., the value of k must be at least the noise rate of the query set times the size of the query. 
 
move * 3 5 9 … 12 4 3 … 10 …
j 15 18 23 32 … 245 249 252 … 376 …
kbad ≥  1 0 0 1 1 0 0 0 1 0 …
area * [7,20] [12,25] * * [234,247] [238,251] [241,254] * [365,378] …
ext. area * [11,27] * * [234,254] * [365,378] …
R’ [11,27][234,254][365,378] 
Fig. 4. An example of filtering: m = 500, n = 15, τ = 2/15, k = 2, λ= 3, m’ = 50. 
 
4. EXPERIMENTAL RESULTS 
In this work, each music fragment is considered a sequence of musical notes, whose pitches and duration 
ratios form a pitch sequence and a duration ratio sequence, respectively. As stated by Moles [15] and Suyoto 
et al. [20], the duration ratio is less important than the pitch for matching, thus the duration ratio d[i] for note i 
is quantized into d’[i], an integer between 0 and 4, as shown in (12). 
 
⎪⎪
⎪
⎩
⎪⎪
⎪
⎨
⎧
≤
<≤
<≤−
−<≤−
−<
=
][log2                4
2][log1           3
1][log1        2
1][log2     1
2][log              0 
]['
2
2
2
2
2
id
id
id
id
id
id                        (12) 
 
We used a corpus of 3497 pieces of music obtained from the internet, consisting of a total of 6,524,476 
music notes. A subset of 50 pieces of music were randomly selected, from each of which a theme, as 
suggested by Barlow et al. [3], was extracted to form a query consisting of 10 to 36 music notes. As a result, a 
set of 50 queries were introduced, called query set A. We varied query set A to form two query sets B and C 
with different ranges of noise rates by randomly changing the pitch of some notes within an octave, deleting 
some notes, or inserting some notes in each query. Query set B has noise rates between 5% and 10%, query set 
C has noise rates between 10% and 30%. In addition, a query set of the same size, named D, was generated by 
the users. The performance will be evaluated by retrieval rank and retrieval rate. The retrieval rank is the rank 
of the correct reference melody in the list of the melodies based on the magnitude of matching scores. The 
 15
ranks for the RLCS and the Local-Alignment are 1.40 and 31.00, respectively. 
For invariance to transposition, we replace the feature of pitch with pitch interval and compare the 
performance of RLCS and the Local-Alignment using the new feature. As demonstrated in Figure 7, the 
RLCS is superior over Local-Alignment tested on both query sets. Table 2 shows that the average ranks 
yielded by the RLCS and the Local-Alignment are 9.15 and 86.05, respectively. 
 
retrieval rates for top-n  lists
60%
65%
70%
75%
80%
85%
90%
95%
100%
1 2 4 8 16 32 64 128 256 512 1024 2048 3497
n
re
tri
ev
al
 ra
te
RLCS Local-Alignment
retrieval rates for top-n  lists
60%
65%
70%
75%
80%
85%
90%
95%
100%
1 2 4 8 16 32 64 128 256 512 1024 2048 3497
n
re
tri
ev
al
 ra
te
RLCS Local-Alignment  
(a)                                      (b) 
Fig. 6. Retrieval rates on top-n lists using RLCS and Local-Alignment based on pitch and duration ratio and 
tested on (a). query set C and (b). query set D. 
Table 1. Average retrieval rank (based on pitch and duration ratio) 
 
algorithm
query set 
RLCS  Local-Alignment 
C 3.28 53.36 
D 1.40 31.00  
average 2.34 42.18 
 17
maintaining the same effectiveness (ranking). When testing on query set B with a noise rate of between 5% 
and 10%, the use of a filtering algorithm with k = 0.1n and 0.05n reduces the retrieval time from 14.516 
seconds to 3.935 and 3.874 seconds, respectively. With k = 0.1n the average rank is maintained; but with k = 
0.05n the average rank drops down to 560.0 since some of the queries have a noise rate greater than the error 
tolerance rate of 5% and their matches were abandoned in the filtering process. When testing on query set C 
with a noise rate between 10% and 30%, the use of a filtering algorithm with k = 0.3n, 0.2n, and 0.1n reduces 
the retrieval time from 14.893 seconds to 13.157, 7.591, and 4.295, respectively; but with k = 0.4n the 
retrieval time increases to 16.845 seconds. This is because with a high error tolerance very little to nothing in 
the reference is filtered, and the extra time taken by the filtering simply increases the time required. As a result, 
the filtering is of no benefit for approximate matching with an error tolerance rate greater than about 20%. 
Table 3. Performance with or without filtering 
RLCS with Filtering RLCS without 
Filtering 
query 
set 
noise rate 
k retrvl 
time 
rank retrvl 
time 
rank 
A 0% 0 3.868 1.0 14.315 1.0 
B 5%~10% 0.1n 3.935 3.02 14.516 3.02 
B 5%~10% 0.05n 3.874 560.0 * * 
C 10%~30% 0.4n 16.845 16.14 14.893 16.14 
C 10%~30% 0.3n 13.157 102.52 * * 
C 10%~30% 0.2n 7.591 322.12 * * 
C 10%~30% 0.1n 4.295 2697.88 * * 
4. CONCLUSIONS AND FUTURE WORK 
In this work, we presented a music similarity measurement, which calculates the similarity score between 
a query and a reference using the length of their RLCS, the WAR and the WAQ, to address the problem 
introduced by local alignment. This modified version of the LCS algorithm has two benefits: (1). The 
definition of rough equality for two notes provides a fairer approximation match than the conventional LCS, 
and (2). The use of width-across-query and width-across-reference for the score measurement reflects the 
local comparison. The use of pitch interval and duration ratio makes the proposed method RLCS invariant to 
both transposition and tempo, but causes the anti-symmetry effect [14] while altering the pitch or the duration 
of a single note in a musical sequence. That is, altering the pitch/duration of a single note would alter two 
consecutive pitch intervals and two consecutive duration ratios and thus the difference for both features would 
be counted twice. Solving this problem is part of the focus of our current work. We improved the time 
 19
REFERENCES 
1. G. Aloupis, T. Fevens, S. Langerman, T. Matsui, A. Mesa, Y. Nunez, D. Rappaport, and G. Toussaint, 
“Algorithms for computing geometric measures of melodic similarity,” Computer Music Journal, Vol. 30, 
No. 3, 2006, pp. 67-76. 
2. D. Bainbridge, M. Dewsnip, and I. H. Witten, “Searching digital music libraries,” Information Processing 
and Management, Vol. 41, No. 1, 2005, pp. 41-56. 
3. H. Barlow and S. Morgenstern, A dictionary of musical themes, Crown Publishers, Inc., New York, 1975. 
4. B. Bhar and N. Chaki, “Design of a new deterministic algorithm for finding common DNA subsequence,” 
International Journal of Computer Science and Information Technology (IJCSIT), Vol. 1, No. 1, 2009, pp. 
11-25. 
5. D. Byrd and T. Crawford, “Problems of music information retrieval in the real world,” Information 
Processing and Management, Vol. 38, Issue 2, 2002, pp. 249-272. 
6. R. Clifford, M. Christodoulakis, T. Crawford, D. Meredith, and G. Wiggins, “A fast, randomised, maximal 
subset matching algorithm for document-level music retrieval,” in Proceedings of the International 
Conference on Music Information Retrieval, 2006, pp. 150-155. 
7. S. Doraisamy and S. Rüger, “A polyphonic music retrieval system using n-grams,” in Proceedings of the 
International Conference on Music Information Retrieval, 2004, pp. 204-209. 
8. J. Foote, “An overview of audio information retrieval,” Multimedia Systems, Vol. 7, Issue 1, 1999, pp. 2-10. 
9. A. Guo and H. Siegelmann, “Time-warped longest common subsequence algorithm for music retrieval,” in 
Proceedings of the International Conference on Music Information Retrieval, 2004, pp. 10-15. 
10. D. Gusfield, Algorithms on strings, trees, and sequences: computer science and computational biology, 
Cambridge University Press, New York, 1997. 
11. J. S. R. Jang, H. R. Lee, J. C. Chen, and C. Y. Lin, “Research and development of an MIR engine with 
multi-modal interface for real-world applications,” Journal of the American Society for Information 
Science and Technology, Vol. 55, No. 12, 2004, pp. 1067-1076. 
12. H. J. Lin, H. H. Wu, and Y. T. Kao, “Geometric measures of distance between two pitch contour 
行政院國家科學委員會補助國內專家學者出席國際學術會議報告 
                                                         99 年 7 月 26 日 
  報    告    人 
  姓          名  
林慧珍  服 務 機 關 
 及   職  稱 
淡江大學資工系 
 
副教授 
           時  間  
  會   議 
           地  點   
民國 99 年 7 月 5~7 日 
 
日本北九州           
 本 會 核 定 
            
 補 助 文 號 
NSC 98-2221-E-032 -034
 
                    
會  議  名   稱 
 (中文) 2010 年商業與資訊國際研討會 
 (英文) The 2010 International Conference on Business and 
        Information 
                    
 發 表 論 文 題 目 
 (中文) 以 DWT 為基礎結合轉換圖之浮水印技術 
 (英文) DWT-Based Watermarking Technique Associated with 
        Translation Maps 
報告內容應包括下列各項： 
一、參加會議經過   
The 2010 International Conference on Business and Information (BAI2010)國際學術會議是由
International Business Academics Consortium (iBAC) and Academy of Taiwan Information 
Systems Research (ATISR)主辦。會議地點在日本北九州的Rihga Royal Hotel Kokura 
。會議只佔用該大樓的兩層。會議時程共三天，此次總共發表一篇論文，安排在最後一天
(7/7)上午報告。 
二、與會心得 
在會場有許多專家學者參加此次會議，可與來自世界各地的專家學者研討並交換資訊、經
驗與心得。在論文報告的場次中同時瞭解了其他專家學者所做的研究，收穫豐富。也利用
了休息時間認識了許多來自各國投入相關研究領域的學者，並與他們交換研究心得而學習
到許多寶貴的資訊與意見。此次日本北九州之行獲益良多。 
三、考察參觀活動(無是項活動者省略) 
無 
四、建議 
無 
五、攜回資料名稱與內容 
攜回資料為會議論文集(BAI2010)的光碟片。會議論文集中包含有所有在會議中發表的文
章全文。 
六、其他 
無 
1.  INTRODUCTION 
 
The use of networking has made the manipulation and transmission of digital 
multimedia products such as text, image, video, and audio much more convenient. 
However, unrestricted copying and malicious tampering cause huge financial losses 
and problems for intellectual property rights. Therefore, information hiding has 
become a prominent research area. Information hiding techniques consist mainly of 
steganography [3-10] and digital watermarking [11-17]. 
 
Steganography requires the quality of the stego image to be as high as possible 
and the amount of embedded information to be as much as possible; while digital 
watermarking requires not only a high quality of the stego image but also the 
capability of a person to judge whether or not the stego image was attacked. The 
embedded watermark can be extracted later to verify the ownership. 
 
In this paper, we shall focus on digital watermarking. Watermarking schemes can 
be categorized into visible and invisible ones. The latter are more popular and are 
further categorized into robust and fragile watermarks. Robust watermarking schemes 
must be able to extract the watermark after one or more of a variety of attacks such as 
JPEG compression, blurring, adding Gaussian noise, rescaling, rotation, cropping, 
sharpening, histogram equalization,…etc. After an attack and when the watermark has 
been extracted, the watermark should be as correlated as highly as possible with the 
original watermark. Contrary to a robust watermark, fragile watermarks become 
totally deformed after even the slightest modification of the media, and are used 
mainly for authentication purposes. In addition, based on the type of information 
needed in the detection or extraction process, digital watermarking can be classified 
into three categories, blind, semi-blind, and non-blind watermarking. While extracting 
watermarks, blind watermarking schemes do not require the original media nor the 
original watermark, while non-blind ones require the original media and the original 
watermark, and semi-blind watermarking requires only the original watermark. 
 
Several watermarking schemes have been proposed in the literature. Lin et al. [11] 
proposed a spatial-fragile watermarking scheme. Here the original image is divided 
into several blocks, which are then permuted according to a secret key. This scheme 
can resist counterfeiting and tampering attacks, and even restore the tampered images. 
Wang et al. [12] proposed a copyright protection scheme, which first extracts the 
image features from the host image by using the discrete wavelet transform (DWT) 
and singular value decomposition (SVD). The extracted features are then classified 
The remainder of this paper is organized as follows. Section 2 describes the 
details of the proposed scheme. In Section 3, the experimental results are presented to 
demonstrate the effectiveness of the proposed scheme. Other applications of the 
proposed method are shown in Section 4. Finally, Section 5 we draw our conclusions. 
 
2. THE PROPOSED SCHEME 
 
In 2009, V. Aslantas et al. [17] presented a fragile watermarking method based on 
Discrete Cosine transform (DCT). However, the DCT is so complex in computation 
that the process of GA become very time-consuming and that the watermarks 
embedded into the LSBs (least significant digits) of the low frequency coefficients 
result in being incapable of resisting some attacks. Therefore, we propose to 
overcome these problems. Our scheme is based on DWT instead due to its ease of 
computation so as to save computation time. The watermarks embedded in the LSB of 
some HL coefficients. A set of translation maps is then trained by a PSO scheme. The 
translation maps are then adopted by an embedding rule to embed watermarks. The 
details of the proposed method are described in the following. 
 
First, we apply 1-Level DWT in the host image and divide the HL sub-band into 
non-overlapping blocks of size 4*4. The watermarks are then embedded in the least 
significant bits (LSBs) of the coefficients from the diagonal of every block. As shown 
in Fig. 1, the four coefficients are selected from the diagonal of a 4*4 block. Finally, 
the IDWT (inverse DWT) is performed, and then the IDWT transformed image is 
divided into non-overlapping blocks of size 8*8. For each block, an optimal 
translation map of the same size is searched by means of PSO. Finally the coefficients 
in each of the divided blocks of the IDWT transformed image are adjusted from real 
numbers to integers associated with its translation map. The way of adjustment is as 
follows: For each map bit of 0, decimal fraction of the corresponding IDWT value is 
just truncated. For each map bit of 1, the decimal fraction of the corresponding IDWT 
value is truncated and then plus 1. 
     
Size: 128*128             Size: 4*4 
Fig. 1. HL embedded position figure. 
each block. 
step 4. Perform IDWT on the embedded image to obtain an image IIDWT, which is then 
divided into non-overlapping blocks of size 8*8. 
Step 5. Use PSO to train and search the best translation map for each divided block. 
Step 6. Adjust the values in each of the divided blocks of IIDWT to obtain the image 
IADJ using an embedding rule associated with the corresponding translation 
map Map, as shown in (5), in which the trunc function returns the integer part 
of a floating point number. 
⎪⎩
⎪⎨
⎧
=
=+
=
0),( if)),((
1),( if1)),((
),(
nmMapnmItrunc
nmMapnmItrunc
nmI
IDWT
IDWT
ADJ
             (5) 
The extracting process can be described as follows: 
Step 1. Apply 1-Level DWT on an M*N stego image. 
Step 2. Extract the LSBs of embedded elements in the HL subband to be the extracted 
watermark bits. 
 
3.  EXPERIMENTAL RESULTS 
The experiments are implemented in an environment using the Intel Core 2 Duo 
1.83GHz CPU, 1.99G RAM, and Microsoft XP. In the experiments, we use 100 
gray-scale images of size 256*256 as host images and 10 binary images of size 64*64 
as watermarks. Two test host images and one watermark are selected from the data set 
and shown in Fig 2. To compare the performance, the value of PSNR (peak signal to 
noise ratio) of the stego image and the value of the NC (normalized correlation) of the 
extracted watermark are evaluated. The formulae for PSNR and NC are as given in (7) 
and (8), respectively, where H0 and W0 denote the height and the width of the 
watermark, and w(i, j) and w’(i, j) denote the bit values at position (i, j) of the original 
watermark and extracted watermark, respectively. The MSE (mean square error) used 
in the formula for PSNR is defined in (6), where H and W denote the height and width 
of the image. In general, a PSNR value greater than 30 dB is perceptually acceptable, 
and an NC value greater than 0.50 is acceptable. 
∑∑ −
= =×=
W
i
H
j
jiIjiIHWMSE 1 1
2)),('),((1                   (6) 
)/255(log10 210 MSEPSNR ×=                        (7) 
          )0W/(Hj)(i,w'j)w(i,NC 0
Ho
1i
Wo
1j
××= ∑∑
= =
                  (8) 
 
Fig.s 4 and 5 show some tested results by the method proposed by V. Aslantas et 
al. [17] and our method. Table 1 compares the PSNR values of the stego images and 
the NC values of the extracted watermarks under a variety of attacks for the two 
methods. The comparison shows that the proposed method requires less run time and 
resists all the attacks listed in the table, but the method proposed by V. Aslantas et al. 
can not resist some attacks such as noise adding, and JPEG compression. 
 
              
(a)                 (b)                (c)                 (d) 
Fig. 4. Tested results of V. Aslantas’s method: (a) & (c) watermarked images, (b) & (d) extracted 
watermarks 
 
                
           (a)                (b)                 (c)               (d) 
Fig. 5. Tested results of our method: (a) & (c) watermarked images, (b) & (d) extracted watermarks 
Table 1. The run time, PSNR, NC with/without attacks for the two methods 
 
Host images 
  
Attacks\Methods V. Aslantas our method V. Aslantas our method 
# generations required 100 10 100 10 
time(embedding&extracting) 34 min 2 min 34 min 2 min 
PSNR 52.73 50.12 52.73 50.19 
NC (unattacked) 1.00 0.99 1.00 0.98 
NC (noise adding  prob. = 0.01) 0.28 0.92 0.29 0.91 
NC (noise adding  prob. = 0.02) 0.12 0.88 0.13 0.87 
NC (noise adding  prob. = 0.04) 0.06 0.81 0.03 0.80 
NC (cropping 1) 0.89 0.99 0.89 0.98 
NC (cropping 2) 0.98 0.98 0.98 0.97 
NC (JPEG QF = 99) 0.12 0.73 0.08 0.75 
quality of watermarked images and the extracted watermarks with/without attacks and 
attacks are satisfactory. 
 
       
(a)              (b)             (c)              (d) 
Fig. 7. Tested results of our method: (a) & (c) watermarked images, (b) & (d) extracted watermarks 
 
Table 2. The PSNR, NC with/without attacks for our method tested on color images 
 
 
Attacks\Host images 
  
PSNR 54.93 54.98 
NC (unattack) 0.99 0.98 
NC (noise adding prob. = 0.01) 0.90 0.89 
NC (noise adding prob. = 0.02) 0.87 0.85 
NC (noise adding prob. = 0.04) 0.79 0.79 
NC (cropping 1) 0.98 0.98 
NC (cropping 2) 0.98 0.98 
NC (scribbling) 0.98 0.95 
NC (tampering) 0.98 0.96 
NC (illumination +10) 0.99 0.97 
NC (illumination -10) 0.98 0.90 
NC (inversing) 0.99 0.96 
NC (water wave effect) 0.84 0.83 
NC (chrominance +10) 0.52 0.54 
NC (chrominance -10) 0.57 0.60 
NC (wind effect) 0.89 0.88 
NC (sharpening) 0.99 0.96 
NC (vortex effect) 0.88 0.87 
NC (mosaic effect) 0.85 0.86 
NC (spheroid effect) 0.86 0.86 
 
 
         
   (a) watermarked image (b) tampered image (c) extracted data (d) tampered position 
Fig. 11. Detection results of host image F7 
           
(a) watermarked image (b) tampered image (c) extracted data (d) tampered position 
Fig. 12. Detection results for host image F8 
 
5. CONCLUSIONS 
 
In this paper, a new DWT-based image watermarking scheme associated with an 
embedding rule is proposed. An optimal translation map corresponding to each 
divided block in the IDWT-transformed watermarked image is trained by using PSO 
mechanism and then adopted by an embedding rule. To further improve the robustness, 
the proposed scheme embeds watermark into the HL subband. The use of PSO on 
training the translation maps for divided blocks of the IDWT-transformed image make 
it converges much faster than the use of GA on IDCT. The PSO used in our algorithm 
needs only 10 generations to converge; while the GA used in V. Aslantas’s method 
requires about 100 generations. The experimental results show that compared with V. 
Aslantas’s method our method requires less time cost retaining about the same 
robustness and the same quality of stego images. In addition, our method has the 
capability of detecting exactly where the image is tampered. In the future, we would 
like to give some security protection for watermarks such as reshaping or visual 
cryptography before embedding, and try to find better positions for embedding. 
 
   REFERENCES 
 
[1] Jina, Y. X., Chenga, H. Z., Yanb, J. Y. and Zhangb, L. 2007. New discrete method 
for particle swarm optimization and its application in transmission network 
expansion planning. Paper presented at Electric Power Systems Research, 77(3-4), 
227-233. 
[16] Lee, Z. J., Lin, S. W., Su, S. F. & Lin, C. Y. 2008. A hybrid watermarking 
technique applied to digital images. Paper presented at Applied Soft Computing, 
8(1), 798-808. 
[17] Aslantas, V., Ozer, S. & Ozturk, S. 2009. Improving the performance of 
DCT-based fragile watermarking using intelligent optimization algorithms. 
Paper presented at Optics Communication, 282(14), 2806-2817. 
[18] Kennedy, J. & Eberhart, R. 1995. Particle Swarm Optimization. Paper presented 
at IEEE International Conference on Neural Networks, Perth, Australia, 4, 
1942-1948. 
[19] Lin, H. J. & Yeh, J. P. 2010. A hybrid optimization strategy for simplifying the 
solutions of support vector machines. Paper presented at Pattern Recognition 
Letters, 31(7), 563-571. 
國科會補助專題研究計畫成果報告自評表 
請就研究內容與原計畫相符程度、達成預期目標情況、研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）、是否適
合在學術期刊發表或申請專利、主要發現或其他有關價值等，作一綜合評估。
1. 請就研究內容與原計畫相符程度、達成預期目標情況作一綜合評估 
■達成目標 
□未達成目標（請說明，以 100字為限） 
□實驗失敗 
□因故實驗中斷 
□其他原因 
說明： 
2. 研究成果在學術期刊發表或申請專利等情形： 
論文：■已發表 □未發表之文稿 □撰寫中 □無 
專利：□已獲得 □申請中 ■無 
技轉：□已技轉 □洽談中 ■無 
其他：（以 100字為限） 
本計畫之研究成果已寫成兩篇被期刊(分別為 journal of multimedia 與 Journal of 
Information Science and Engineering)所接受之論文。 
3. 請依學術成就、技術創新、社會影響等方面，評估研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）（以
500字為限） 
網路的普及化已成為必然之趨勢，網際網路上數位音樂資料的必定持續地與日俱增。同
時，隨著行動設備的普及化，無線網路頻寬與日俱增的趨勢下，未來在行動設備上查詢與
瀏覽多媒體的需求勢必大量增加。因此將查詢平台轉換至行動設備必然是未來的趨勢。 
對於國家資訊發展策略上，此一應用除了能幫助推動無線網路多媒體應用之外，更適合用
於數位典藏。雖然數位典藏的核心是內容 (content) 而非技術，然而以現今的技術層面
而言，仍有許多不足且值得改進的地方。當然，此研究亦可運用於其它方面，例如，輔助
學術單位建立數位音樂圖書館。許多藝術相關的學術單位，想必有典藏大量的音樂資料，
例如傳統音樂錄製、口述歷史等等。這方面的典藏將來勢必全面數位化，面對越來越龐大
的音樂資料，搜尋的重要性也越顯重要。本計畫之研究成果已寫成兩篇被期刊(分別為
journal of multimedia 與 Journal of Information Science and Engineering)所接受
之論文，並已被肯定與接受，其無論在學術或應用上必有一定的價值。 
