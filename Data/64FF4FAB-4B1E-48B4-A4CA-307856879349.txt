 2
行政院國家科學委員會專題研究計畫成果報告 
             最佳控制的機械學習法 
     Optimal control approaches to machine learning 
 
計畫編號：NSC 98-2221-E-011-053 
執行期限：98 年 8 月 1 日至 99 年 7 月 31 日 
主持人：水谷英二 (Eiji Mizutani)   國立台灣科技大學工業管理系 
 
中文摘要 
這是一份與加州大學柏克萊分校之名譽教授 Stuart Dreyfus 對於機器學習法的共同研究計
畫。我們發展實際的學習演算法，基於最佳控制理論與數值線性代數。因為我的中文表達
比較不順，詳細的內文細節會用英文在下面敘述。 
 
 4
一、研究目的 
The main purpose of the posed research project is to continue and extend the joint research with  
Stuart Dreyfus, Professor Emeritus at the University of California at Berkeley  
(see www.ieor.berkeley.edu/People/Faculty/dreyfus.htm). 
 
I have been working with Stuart Dreyfus since 1994. Dreyfus is a world-widely renowned 
pioneer of Dynamic Programming and Optimal Control. Our major approaches are based on 
efficient stagewise optimal-control techniques. For our first-year NSC project, we set two 
specific goals: We aim (1) at developing efficient dynamic programming algorithms to 
circumvent the curse of dimensionality, and (2) at attacking challenging neural-network learning 
problems for the Hessian analysis to understand the mechanism of plateau phenomena. 
 
For the first goal, we develop so-called ``stage look-ahead’’ dynamic programming methods for 
several stochastic problems including linear dynamic and quadratic criterion problems and 
equipment replacement problems in the context of time-delayed control dynamics.  
 
For the second goal, we take advantage of our newly-developed tool for the Hessian evaluation; 
that is, a very efficient second-order stagewise backpropgation procedure for evaluating a given 
non-linear objective function. In particular, we consider a multi-layer neural-network model, for 
which the objective function E is the sum of squared errors; hence, a neural-network nonlinear 
least squares problem. Our stagewise backpropagation procedure, derived from the second-order 
optimal control theory, can evaluate the full Hessian matrix H of E faster than ``standard'' 
methods that obtain only the Gauss-Newton Hessian matrix G (that is still used in Matlab 
NN-toolbox); this is a truly tremendous breakthrough in the nonlinear least squares sense. Here is 
our 2008 theorem that mathematically verifies our procedure:  
 
Theorem (Mizutani & Dreyfus, 2008): 
The full Hessian H = G + S can be evaluated at the same cost as the Gauss-Newton Hessian G. 
 
It can apply ``broadly'' to yet unexplored domains including other classical nonlinear regression 
benchmark problems. Moreover, it can be employed to enhance the performance of Automatic 
Differentiation (AD) since AD uses the so-called adjoint variables in a computational graph, 
which has a stagewise structure. This implies that our stagewise procedure is applicable to any 
differentiable function in the spirit of AD. This is definitely worth investigating.  
 
In reality, the full Hessian matrix may not be positive (semi-)definite during the parameter 
updating (i.e., learning) phase, but the widely-employed trust-region nonlinear optimization 
method can deal excellently with the indefinite Hessian since the underlying theory has thrived 
on the ``negative curvatures'' over the last two decades.  The trust-region approach based on the 
full Hessian matrix is of immense value in solving real-world ``large-residual'' nonlinear least 
 6
二、研究架構與方法 
Recall our two specific goals described above: (1) efficient dynamic programming algorithms 
and (2) Hessian analysis on challenging problems. 
 
For (1), we consider three stochastic problems: linear dynamics quadratic criterion, 
minimum cost path, equipment replacement in the context of time-delayed control dynamics. 
We introduce the concept of stage-lookahead in order to reduce the number of arguments in the 
optimal value function of dynamic programming and therefore to alleviate the so-called curse of 
dimensionality. A recent research trend in the literature on dynamic programming is to develop 
approximate dynamic programming and neuro-dynamic programming to overcome the main 
obstacle ``curse of dimensionality.’’ This term is coined by Richard Bellman, who initiated the 
research on dynamic programming. We have investigated neuro-dynamic programming 
approaches to non-Markovian domain problems (see related work posted at the homepage of 
Stuart Dreyfus at UC Berkeley: www.ieor.berkeley.edu/People/Faculty/dreyfus.htm), but here, we 
resort to a classical stage-lookahead method, which was first introduced for attacking stochastic 
backlogging inventory control problems. We extend the basic stage-look-ahead concept to the 
aforementioned three stochastic applications so that the number of arguments of the optimal 
value function can be further reduced (hence, more efficient). 
 
For (2), we have first made a thorough survey in the literature on neural-network learning, and 
then found several dubious claims about local-minimum issues in neural-network learning. We 
then applied our recently-developed stagewise second-order backpropgation procedure for 
evaluating the Hessian matrix of the sum-of-squared residuals. An analysis on the Hessian matrix 
has been made from the perspective of numerical linear algebra. In particular, we conduct 
eigenvalue analysis on the computed Hessian matrix. Typically, the so-called singularity region 
can be characterized by negative curvature (hence, indefinite Hessian matrix). We also examine 
singular saddle points, where the Hessian becomes positive semi-definite. This is certainly the 
limitation of the Hessian analysis. Yet, small perturbations to such pathological cases changes the 
eigen-spectrum of the Hessian matrix, resulting in indefinite Hessian matrices. We then exploit 
negative curvature for parameter optimization; this is certainly worth trying because such a 
negative-curvature direction tends to be very different from the steepest-descent direction. Here, 
we want to emphasize the usefulness of our efficient stagewise procedure to evaluate the Hessian 
matrix. Without such a tool, the numerical evidence is hard to obtain. Hence, the computational 
convenience is immense. 
 
 8
implicit (sparse) Hessian-vector multiply. I have been working on those Krylov methods with 
James Demmel (加州大學柏克萊分校之教授 in Computer Science Division; the joint work 
on this subject has been published in several papers before). From this perspective, it would be of 
our great interest to further investigate the negative-curvature issues in a large-scale setting.  
 
Furthermore, when the parameters separate into linear and nonlinear ones, we propose to modify 
the well-known variable projection method of Golub and Pereyra so as to include the full Hessian 
information. We then exploit negative curvature if it exists. This is the on-going joint work with 
James Demmel since 2002. Part of the joint work was presented in the 2009 SIAM Conference 
on Applied Linear Algebra. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 10
五、本案研究所衍生之成果 
學術期刊論文 
1. Eiji Mizutani and Stuart Dreyfus. An analysis on negative curvature induced by singularity in 
multi-layer neural-network learning. To appear in Advances in Neural Information Processing 
Systems, vol. 23, MIT Press, 2010. 
 
學術期刊論文(Draft) 
1. Eiji Mizutani and Stuart Dreyfus. LQ-subproblem approaches towards the discrete-time  
stagewise Newton methods. In preparation for IEEE Transactions on Automatic Control. 
2. Eiji Mizutani and Stuart Dreyfus. The dynamic time warping algorithms (over 21 pages). Part 
of the work was used for the invited one-week lecture at the Department of System Design, 
Tokyo Metropolitan University, JAPAN, 2006, based on the 1990 draft of Stuart Dreyfus. 
3. Eiji Mizutani. Auxiliary value function approaches to dynamic programming (11 pages draft). 
4. Eiji Mizutani and Stuart Dreyfus. Automatic differentiation by stagewise backpropagation.  
An extended version of the conference presentation at the 20th Internationa Symposium on 
Mathematical Programming, page FA19, Chicago, USA, August 23--28, 2009. 
5. Eiji Mizutani and James Demmel. Trust-region variable projection methods for separable 
nonlinear least squares learning (an expanded version of a paper presented at the 2009 SIAM 
conference on Applied Linear Algebra). 
6. Eiji Mizutani and Kung-Jeng Wang. A note on Veeramani and Wang’s forward dynamic 
programming algorithm for a scheduling problem with job-family setup times. This paper will 
serve as Corrigendum to a journal paper written by Dharmaraj Veeramani and Kung-Jeng 
Wang entitled ``Bid construction scheme for job flow time reduction in auction-based 
fully-distributed manufacturing systems,’’ which appeared in International Journal on 
Advanced Manufactoring Technology (2006), Vol.28, pp.541-550. 
7. Eiji Mizutani and Stuart Dreyfus. The hidden-node teaching algorithms for multi-stage neural 
network learning. This is a substantially revised version of our WCCI 2002 conference paper 
appeared in Proceedings of IEEE IJCNN, part of WCCI, vol.3. pp.2831-2836. 
 
國際學術會議 論文 
1. Eiji Mizutani and Stuart Dreyfus. Stage-lookahead dynamic programming alogirhtms for 
stochastic problems with time-lagged control dynamics. In Proceedings of the 2009 IEEE 
Conference on Industrial Engineering & Engineering Management (IEEM 2009), 
pp.301—305,  Hong Kong, December 2009. 
 
國際學術會議 Presentations 
2. Eiji Mizutani and Stuart E. Dreyfus. ``Effient Hessian evaluations by stagewise 
backpropagation in nonlinear least squares problems." Abstract appeared in the booklet of the 
20th Internationa Symposium on Mathematical Programming, page FA19, Chicago, USA, 
August 23--28, 2009. This is the largest Conference on Mathematical Programming. 
表 Y04 
行政院國家科學委員會補助國內專家學者出席國際學術會議報告 
                                                         2010 年 10 月 28 日 
報告人姓名       Eiji Mizutani 
      (水谷英二) 
 
服務機構 
及職稱 
 
  台灣科技大學 工管系 
       助理教授 
 
     時間 
會議 
     地點 
 December 8 to 11 
 Hong Kong 香港 
本會核定 
補助文號 
  
  NSC 98-2221-E-011-053- 
會議 
名稱 
 (中文) IEEE 國際會議 工業工程與工程管理 (IEEM 2009) . 
 (英文) The 2009 IEEE International Conference on Industrial Engineering and   
Engineering Management (IEEM 2009). 
發表 
論文 
題目 
 (英文) Stage-lookahead dynamic programming algorithms for stochastic problems with 
time-lagged control dynamics 
報告內容應包括下列各項： 
一、參加會議經過 
 
  The posed IEEE conference is one of the most popular conferences in the field of Industrial Engineering.
In 2009, it was located in Hong Kong; therefore, there were many Chinese attendees (from Mainland China 
as well as from Taiwan), but also quite a few attendees from the other countries including USA, Saudi 
Arabia, Australia, Japan, Thailand. During the four-day period, more than 200 papers were presented in a 
dense format.   
 
二、與會心得 
The conference covers a broad area related to Industrial Engineering and management including decision 
analysis, human factors, quality control, supply chain management etc. It was a very good opportunity to 
meet different researchers, exchange opinions, and discuss mutual research interests. I personally did 
choose presentations related to scheduling problems. (In this semester, I am teaching this subject at 
NTUST.) 
 
三、建議 
Since this is an IEEE conference, the paper circulation is good and the conference quality is kept relatively 
high. The conference itself is quite internationalized. Yet, the poster session was small unlike the NIPS 
Conference, the best conference in Machine Learning, where all attendees must do poster presentations to 
encourage researchers to discuss research stuff. I hope the future IEEM will expand the poster session so as 
to provide more space for research discussion. (I already talked about this issue with one of the program 
committee.) Beside this, overall, the conference was very good. 
 
四、攜回資料名稱及內容 
 
   Conference proceedings (USB flash disk), program booklet. 
A. Decisions precede random events
Instead of arguing for general λ, for our concrete dis-
cussion purpose, we demonstrate our DP algorithm on the
stochastic LQ problem with three-stage time-lagged control
dynamics (i.e., λ=3); that is, we wish to find a control
sequence yi (at stage i) that minimizes the expected value
of J , a quadratic cost function of state xi and control yi of
the following form:
J =
1
2
N−1∑
i=1
(
xTi Aixi + 2x
T
i Bi−3yi−3 + y
T
i−3Ci−3yi−3
+2dTi xi + 2e
T
i−3yi−3 + fi
)
(3)
+
1
2
(
xTNANxN + 2d
T
NxN + fN
)
,
subject to the linear dynamics below
xi+1 = Gixi +Hi−3yi−3 + zi (4)
with given initial conditions: y−2,y−1,y0, and x1. Here is
our three-stage lookahead DP algorithm:
(1) Definition of the optimal value function:
Vi(wi)
def= min expected cost-to-go from stage i+3 on to
end with an m-vector state wi defined by
wi
def= Gi+2Gi+1Gixi +Gi+2Gi+1Hi−3yi−3
+ Gi+2Hi−2yi−2 +Hi−1yi−1.
(5)
(2) DP recurrence relation:
Vi(wi)=min
yi
E
{
1
2
(
xTi+3Ai+3xi+3 + 2x
T
i+3Biyi + y
T
i Ciyi
+2dTi+3xi+3 + 2e
T
i yi + fi+3
)
+ Vi+1(wi+1)
}
,
(6)where
wi+1 = Gi+3wi +Hiyi +Gi+3Gi+2Gi+1zi, (7)
and E {.} is the expectation with respect to zi, zi+1, zi+2.
(3) DP Boundary condition at Stage N−λ (λ=3):
VN−3(wN−3)=E
{
1
2
(
wTN−3ANwN−3
+2
[
dTN + v
T
NAN
]
wN−3 (8)
+vTNANvN + 2d
T
NvN + fN
)}
,
where the terminal cost 12
(
xTNANxN +2d
T
NxN + fN
)
is
expressed in terms of wN−3 with Equation (5) and{
xN = wN−3 + vN
vN ≡ GN−1GN−2zN−3 +GN−1zN−2 + zN−1.
(9)
For seeking the solution to the posed LQ problem, we
assume a quadratic form of the optimal value function:
Vi+1(wi+1)≡ 12
(
wTi+1Pi+1︸ ︷︷ ︸
m×m
wi+1 + 2qTi+1wi+1︸ ︷︷ ︸
m×1
+ ri+1︸︷︷︸
1×1
)
.
We then substitute Vi+1(wi+1) using Equation (7) into
Equation (6), and take the expectations with respect to zi,
zi+1, and zi+2. Differentiating the resulting expression with
respect to yi, and setting it equal to zero eventually yields
the optimal control of the following form:
y∗i = −S−1i
(
Ui [wi +Gi+2Gi+1z¯i]
+ BTi [Gi+2z¯i+1 + z¯i+2] + ti
) (10)
where ⎧⎪⎪⎪⎪⎪⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎪⎪⎪⎪⎪⎩
Si︸︷︷︸
n×n
def= Ci +HTi Pi+1︸ ︷︷ ︸
m×m
Hi
Ui︸︷︷︸
n×m
def= BTi +H
T
i Pi+1Gi+3
ti︸︷︷︸
n×1
def= ei +HTi qi+1︸︷︷︸
m×1
.
(11)
Substitution of y∗i back into Equation (6) leads to the
following Riccati recurrence relation for Pi:
Pi︸︷︷︸
m×m
= Ai+3 +GTi+3Pi+1Gi+3 −UTi S−1i Ui, (12)
and the recurrence relation for qi:
qTi = z¯
T
i G
T
i+1G
T
i+2Pi
+
[
z¯Ti+1G
T
i+2 + z¯
T
i+2
] [
Ai+3 −BiS−1i Ui
]
+ dTi+3 + q
T
i+1Gi+3 − tTi S−1i Ui.
(13)
Here, we omit the relation for ri, which has nothing to
do with the determination of optimal control y∗i . Note in
Equation (13) that Pi of Equation (12) is used. The boundary
conditions for those recurrence relations are obvious from
Equations (8) and (9); that is,{
PN =AN ,
qTN =d
T
N +[GN−1GN−2z¯N−3+GN−1z¯N−2+z¯N−1]
TAN .
For illustration, we next show a small numerical example.
B. A numerical example (scalar) for λ=3 and N=6
Given initial conditions (x1=1, y−2=2, y−1=2, y0=1),
we want to find optimal control yi so as to minimize the
expected value of
J = 12
(
2x21 + 3x
2
2 + x
2
3
)
+ 12
(
2x24 + 4x4y1 + y
2
1 + 2x4 + 4y1 + 1
)
+ 12
(
3x25 + 2x5y2 + 3y
2
2 + 4x5 + 2y2 + 2
)
+ 12
(
3x26 + 2x6 + 2
)
(14)
subject to the linear dynamics below⎧⎪⎪⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎪⎪⎩
x2 = 2x1 + y−2 + z1
x3 = x2 + 2y−1 + z2
x4 = x3 + 3y0 + z3
x5 = 2x4 + y1 + z4
x6 = x5 + 2y2 + z5
(15)
y1
3
4
3
−1
2
2
3
1
3 x
Level 0
Level 1
4
41
1
3 2
55
J
KG
F H
IE
D
C
BA
Fig. 1. A directed two-level five-stage minimum cost stochastic path.
III. A STOCHASTIC MINIMUM-COST PATH PROBLEM
Next, we illustrate a directed “two-level” N -stage mini-
mum cost stochastic path problem with λ-stage delay. For
concreteness, we employ N = 5 (five stages) and λ = 2
(two-stage lag); see Figure 1. The goal is to minimize the
sum of arc costs from vertex A (0, 0) to the right end
points, either K or J. We assume two admissible decisions:
Decision U at vertex (x, y) results in an upward move from
vertex (x+2, y) to (x+3, 1) when it is implemented two stages
later at stage x+2 with probability 34 , and it results in a
downward move from (x+2, y) to (x+3, 0) two stages later
with probability 14 . Decision D is like Decision U except the
probabilities, 34 and
1
4 , are interchanged. Due to λ= 2, we
further assume for x < 2 that at vertices A, B, and C the
probability of moving upward and that of moving downward
each equal 12 . (See also p.129 [1].) For our convenience, the
arc cost from vertex (x, y) in an upward move is denoted
by au(x, y), whereas the arc cost from (x, y) in a downward
move is by ad(x, y).
A straightforward DP algorithm based on zero-stage looka-
head uses the optimal value function having four arguments
in the form V (x, y, d1, d2) as the minimum expected cost-
to-go from the current state (x, y) to end, and dj denotes the
decision made in stage x−j (for j = 1, 2); e.g., see pp.130–
131 [1] for such a standard algorithm. Below, we show a
DP algorithm that uses two-stage lookahead with only two
arguments for the value function, and exploits the two-level
structure (y=0 or y=1).
Algorithm T (a specially-geared two-stage lookahead):
(1) Definition of the optimal value function:
T (x, d) def= min expected cost-to-go from stage x+2 on to
end, and d is the decision made in stage x−1 (one-stage
back) with d=U or d=D.
(2) Recurrence relation:
T (x, U)=min
2
6664
U: T (x+1, U)+ 3
4
˘
3
4
au(x+2, 1)+
1
4
ad(x+2, 1)¯
+1
4
˘
3
4
au(x+2, 0)+
1
4
ad(x+2, 0)¯
D: T (x+1, D)+ 3
4
˘
1
4
au(x+2, 1)+
3
4
ad(x+2, 1)¯
+1
4
˘
1
4
au(x+2, 0)+
3
4
ad(x+2, 0)¯
3
7775 .
Similarly, define T (x,D).
When x = 0,
T (0,−)= min
2
6664
U: T (1, U)+ 1
2
˘
3
4
au(2, 1)+
1
4
ad(2, 1)¯
+1
2
˘
3
4
au(2, 0)+
1
4
ad(2, 0)¯
D: T (1, D)+ 1
2
˘
1
4
au(2, 1)+
3
4
ad(2, 1)¯
+1
2
˘
1
4
au(2, 0)+
3
4
ad(2, 0)¯
3
7775 .
(3) Boundary Conditions: T (N − 2, d) = 0.
The answer is given by T (0,−), and for the optimal cost-
to-go value from (0,0) to end, add 12 [au(0, 0)+ad(0, 0)] and
1
4 [au(1, 1)+ad(1, 1)+au(1, 0)+ad(1, 0)] .
IV. AN EQUIPMENT REPLACEMENT PROBLEM WITH
DELIVERY LAG
We now examine a stochastic equipment-replacement
problem (e.g., see Chap.10 [1]), where we either keep or
replace our current machine at the start of each (year)
period over the next N periods. We assume that the cost for
operating the machine is a random variable, dependent upon
the age of the machine; for our computational convenience,
the expected stage cost for operating an i-year-old machine is
evaluated in advance as ci (independent of stage/period k).
We further assume that our machine of age i in working
order at the start of a period fails at the end of that period
with probability qi, and then it must be replaced by a new
machine. But a new machine bought at the beginning of
period k arrives at the start of period k+λ. The posed λ-
period lag in delivery complicates the situation:
(1) If no “good” (i.e., working) machine is available to use
for a period, then a penalty cost A is assessed during
that period.
(2) The purchase price p of a new machine is paid at the
time of delivery, when the old machine of age i is traded
in with a (trade-in) value ti or ui, depending on its
condition “working” or “failed.”
(3) The machine deteriorates with age only when it is
operated. Therefore, no failed machine ages.
(4) No machine is allowed to be purchased at the start of
period N−λ+1 (or later) since it is not delivered in
time to be used because of the delivery lag λ.
Initially, a working machine of age y is available at the start
of period 1, when no new machine is scheduled to arrive (i.e.,
no order in pipeline). Finally, let si be the salvage value at
the start of period N+1 of a working machine just turned
age i, whereas vi be that value of a failed one of age i.
We compare three DP algorithms for a case where the
delivery lag is two (λ = 2).
Algorithm A (zero-stage lookahead; cf. Chap. 9, Sec. 7 [1]):
(1) Definition of the optimal value functions:
Sk(i, d1, d2)
def= min expected cost-to-go from period k on
to end when a machine of age i in working order is
available at the start of period k, and dj indicates the
situation of the order made in period k−j (j = 1, 2)
with dj = ∅ for no order in pipeline, or dj = Y for a
new machine ordered j stages back in pipeline.
Vk(i, d1, d2)
def= min expected cost-to-go from period k on
to end when the available machine is of age i (i ≥ 1)
and in failed condition at the start of period k, and dj
is the order delivery status as defined above.
無衍生研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
這研究計畫是  一份與加州大學柏克萊分校之名譽教授 Stuart Dreyfus 之重
要國際合作。 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
