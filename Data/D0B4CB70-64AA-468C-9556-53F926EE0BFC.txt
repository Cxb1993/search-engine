1 
1. 前言 
在所有的網路應用中，電子郵件為目前最廣泛使用的網路應用之一。然而，因發送電
子郵件的便利性與其低成本的特性，使用者不想收到的垃圾郵件 (Spam Mail) 也越來越
多；這些垃圾郵件也造成使用者使用電子郵件上的困擾。為了解決垃圾郵件所帶來的問題，
垃圾郵件的過濾機制一直是一個主要的研究議題。許多垃圾郵件過濾機制的研究著重在找
出垃圾郵件的特徵並提出機械學習的演算法來過濾垃圾郵件。 
目前最常用來過濾垃圾郵件的自由軟體為 SpamAssasian[17]，SpamAssasian 是以規則
為基礎 (Rule-Based) 的過濾器。SpamAssasian 的每一條規則有對應的分數，符合某些垃圾
郵件規則的分數將會加總起來；當超過某個臨界值 (Threshold) 時則該郵件就被歸類為垃
圾郵件。 
另外在目前垃圾郵件防範的研究中以貝式分類器 (Bayes Classifier)[13][15]和支持向量
機 (Support Vector Machine)[6] 等機械學習的演算法為主。這些演算法基於數學模型並擷取
郵件的特徵；例如擷取郵件內文的特徵字、URL 或是郵件的標頭做為特徵，並對已知的資
料集擷取特徵後進行訓練並產生判斷的模組。 
近年來垃圾郵件的發送者開始使用圖像式垃圾郵件 (Image Spam) 來避免被以內文為
主的郵件過濾器攔截；這些郵件發送者將所要傳達的訊息嵌在圖像中，以避過以文字過濾
為基礎的垃圾郵件過濾技術。且為了應付以 OCR 為主的過濾器攔截[8]，垃圾郵件者發送
者會利用 CAPTCHA (Complete Automated Public Turing Test to Tell Computers and Humans 
Apart)[18]的技術將圖像做些微的變化，再開始發送大量不同的相似圖像。為了處理圖像式
垃圾郵件，在觀察了垃圾圖像和合法圖像的差異後，許多研究以分析圖像的內容並擷取視
覺特徵再加上機械學習的演算法來分類圖像以過濾垃圾郵件。 
一般而言，針對垃圾郵件的過濾有兩個主要的研究議題： 
z 特徵選取：電子郵件包含郵件標頭、內文、附件等等。目標是找出能夠區隔正常
郵件與垃圾郵件的特徵。 
z 分類演算法：在擷取郵件特徵後，我們必須選擇適合的分類演算法。目標為找出
準確率和效率較好的分類演算法。 
2. 研究目的 
雖然目前在防範圖像式垃圾郵件上大部份的系統都有不錯的準確率，但是相對花費在
處理圖像上的成本也較高；而且這種方法會重複的處理大量的相似圖像式垃圾郵件。由於
圖像式垃圾郵件發送者會適應新的過濾技術並變更圖像的特徵，因此如果沒有持續的更新
機械學習演算法判斷的資訊將會造成系統的誤判，降低準確率。 
因此本計畫的目的是針對圖像式垃圾郵件，設計一個具自我調整能力之二階層式圖像
垃圾郵件系統。這個圖像式垃圾郵件過濾系統可以有效的判斷出垃圾圖像。對於大量發送
的垃圾圖像而言，這個系統可以快速的過濾相同或相似的垃圾圖像，如此可以提高系統的
效率；對於新型態的垃圾圖像而言，這個系統使用較精確的分類演算法以判斷是否為垃圾
3 
區域分開擷取視覺特徵的方法，分別從這兩個區域擷取文字區域的大小、顏色飽和度、顏
色的異質性(種類)，並使用 SVM 作為分類的演算法。 
另一方面，為了解決處理圖片計算量較大的問題，Dredze 等人[5]提出了擷取圖像資訊
的方法，包含了檔案格式、檔案大小、圖像長寬等，另外配合圖像顏色的平均值、飽滿度、
邊緣偵測、常用顏色等等作為偵測垃圾圖像的特徵。因為在分類上並不需要所有的特徵，
且特徵數量較多時浪費擷取特徵與計算的時間和儲存空間，作者利用選取特徵的演算法，
取得最具有代表性特徵配合決策樹的分類法加快系統處理的速度。 
在圖像的相似度偵測上，Wang 等人[16]提出了相近圖像的偵測方法，這方法主要的概
念為自然圖像的特性與分佈較不容易改變而垃圾圖像為了躲避偵測而隨者時間變化。且垃
圾郵件發送者會送出大量程式自動產生的圖像，而同一批產生的圖像是非常相似的，且利
用增加隨機雜訊的方法通過以 hash-based 的垃圾圖像過濾器。作者提出了多個圖像過濾器
的概念，分別為顏色直方圖過濾器、哈爾小波轉換 (Haar Wavelet Filter)過濾器和方位直方
圖 (Orientation Histogram)的特徵，並使用距離函式決定圖像的相似度，最後以投票的機制
決定是否為垃圾圖像。 
在 Cormack 等人[4]的研究中，比較了使用批次學習與即時學習的分類器的差異性，因
為電子郵件使用者的使用習慣會隨者環境和時間改變，而這些改變是合理並可預期的。作
者分別比較了多種機械學習的方法，結果顯示及時學習的分類器的分類較批次學習的分類
效果好。 
4. 研究方法 
我們所提的自我調整圖像式垃圾郵件過濾系統為一個二階層式系統；第一層利用顏色
比例相似度分類器來進行圖像式垃圾郵件分類，第二層則使用視覺特徵分類器來進行圖像
式垃圾郵件分類。此外，我們也提出一個自我調整的機制。這個自我調整的機制能讓系統
適應不同或是新型的垃圾圖像，並讓系統的準確性能逐步提升。 
本章以下的內容將分別從系統概述、顏色比例相似度分類器、視覺特徵分類器和自我
調整機制四個部分來分別討論。 
4.1 系統概述 
圖 1 為系統架構圖，本系統主要分成兩大模組，分別為決策模組 (Decision Module) 與
訓練模組 (Training Module)。決策模組主要處理未分類的圖像郵件，訓練模組擷取經由決
策模組分類後的圖像特徵，並將這些特徵儲存在資料庫 (Training Pool) 中以實作本系統的
自我調整機制。以下分別介紹這兩個模組： 
z 決策模組：以特徵擷取模組 (Feature Extraction Module) 及分類器 (Classifier) 為
基礎。當系統運作時，原始圖像將會分別經由兩個階層的特徵擷取模組先取出特
徵，再經由分類器判斷該圖像屬於垃圾圖像或正常圖像。本系統會同時將圖像資
訊與分類的結果傳送給訓練模組。 
z 訓練模組：此模組儲存垃圾圖像和合法圖像的特徵資訊，其中包含事先用來訓練
5 
者我們計算這 20 種色比例，表示為 Pi = Ci/N，在這邊 i = 1,2, …, 20。在垃圾郵件的分類中，
特徵愈多，儲存特徵所需要的空間愈大，處理的時間越久；因此我們進行實驗以找出最佳
的顏色比例數量，實驗的結果這個值定為 20。 
當垃圾圖像發送者對圖像進行位移或扭曲時，顏色的比例並不會改變；因為我們系統
只在乎主要顏色的比例。若改變背景或是改變圖像中主要的顏色時，對於顏色比例也不會
改變。如果垃圾圖像發送者對圖像加入雜訊，加入的雜訊通常量不會太多，也不會造成主
要特徵的變化。如果所送的圖像是合法圖像，因為合法圖像較沒有大量發送的特性，且顏
色比例較多樣化，因此我們所提的顏色比例相似度過濾法可以抵抗大量的相似垃圾圖像攻
擊，較不容易造成誤判。 
由於在產生垃圾圖像，有成本的問題，垃圾圖像發送者通常只會對圖像做些微的變化，
但是隨者時間的流逝，未來還有大量的未知的垃圾郵件。我們的顏色比例相似度分類器只
針對已知的垃圾圖像資訊攔截垃圾圖像，如果沒有及時的更新垃圾圖像資料庫將會造成大
量的垃圾圖像進入使用者的信箱。為了避免此問題，我們提出了如圖 1 的二階層的架構，
並利用自我調整的機制來解決此一問題，下一節，我們將介紹第二層的視覺特徵分類器。 
4.3 視覺特徵分類器 
如果在第一階層的顏色比例相似度分類器無法判斷的部分，將由視覺特徵分類器來處
理。因我們所提的系統為二階層的系統，在此第二階層分類的結果為系統最終判斷的結果。 
根據我們的觀察，和一些影像處理的研究[7][9][12][14]和圖像式垃圾郵件的研究
[1][2][5][10][11]，垃圾圖像的特徵是使用的顏色較單調，顏色的變異度較大，圖像的紋理
較單純，內嵌的文字較多等等。所以在視覺特徵分類器中我們使用顏色動差與顏色飽滿度
這兩種特徵。 
使用視覺特徵的好處是較可以忽略背景的複雜度以及圖像的大小與形狀，根據機率理
論，顏色動差可以表現顏色分布的特徵，而大多的圖像資訊都集中在低階的顏色動差[12]
所以根據我們之前的研究[11]，在我們的系統中，使用一階動差與二階動差做為特徵。垃圾
圖像多為人造圖像，與自然的圖像比較可以知道垃圾圖像的顏色飽和度較高，因為大多數
垃圾圖像所使用的顏色較少且較單純。 
在這個分類器中，我們使用了七個視覺特徵並應用 SVM 的演算法。當未知圖像的顏色
比例不符合第一層的垃圾圖像資訊，視覺特徵分類器將會做最後的決策。如果在第一層攔
截了大多數的相似垃圾圖像，將會減少許多垃圾圖像在第二層被誤判成正常圖像的機會。 
4.4 自我調整機制 
由於垃圾郵件發送者會隨時間改變垃圾郵件的訊息或是針對反垃圾郵件系統改變攻擊
的手法。傳統上的反垃圾郵件系統需要管理者手動的收集資訊並重新訓練系統以應付新的
手法。然而在現實狀況中並沒有辦法即時的處理新型態的攻擊，使系統的準確率下降，導
致短時間內有大量的垃圾郵件進入使用者信箱並對使用者造成困擾。所以在本計畫中我們
提出了系統自我調整的機制。 
7 
實驗以驗證系統的適應性、準確率與效能。我們的實驗環境在硬體上使用 Intel Core 2 Duo 
E7300 2.67GHz 處理器與 3GB 記憶體當作模擬的平台，並使用 JAVA 語言與 LIBSVM [3]的
函式庫，所使用的資料集如表 1 所示。實驗的方法主要分為兩種類別，一種以不同的資料
集分別做為訓練與測試之料，以驗證系同的適應性；第二種則是將資料集混和後視為同一
種類別的資料，以驗證準確率；最後我們分析第一層分類器過濾比例的比例與變化，以驗
證系統的處理效能。以下分別說明這三個實驗的結果。 
表 1. 實驗使用的資料集 
Data set NHam NSpam 
TREC07 934 8050 
TREC05 252 1227 
Dredze 1852 3237 
Image Spam Hunter 810 929 
z 適應性 
為了解系統是否能適應新形態的圖像，我們以不同的資料集作為訓練與測試資
料。這邊我們使用 TREC07 作為測試資料，Image Spam Hunter 與 Dredze 作為訓練資
料。為了模擬系統適應的狀況，我們將測試資料集分為五等分，第一等分為使用者回
饋資訊，我們取兩百筆資料當作使用者回饋資訊；另外四等分我們分別對系統進行測
試，當每一等分完成時，除了評估其準確率，系統也將判斷的資訊回饋給訓練的資料
庫做為重新訓練之用，完成這四等分的測試之後，準確率變化如圖 2。 
   
                    (a)                                     (b) 
圖 2.(a) TREC05 and Image Spam Hunter for training, TREC07 for testing; (b) Dredze for 
training, TREC07 for testing 
圖 2 是針對不同訓練資料集，相同測試資料集實驗的準確率變化。我們可以從這
兩張圖得知，當系統遇到不同型態的資料集時，使用自我調整的機制能使準確率逐漸
的提升；當使用即時回饋(real-time feedback)機制時，第二層即時回饋垃圾圖像資訊給
第一層，但第二層不更新訓練模組下，準確率也會上升。另外從圖 2.(a)與圖 2.(b)中，
可以知道不論使用何種資料集作為訓練資料，使用自我調整的機制依然可以使準確率
逐漸提升。從以上的實驗，我們驗證了本系統可以適應新型態的垃圾圖像。  
z 處理時間與效能 
在我們的階層式圖像式垃圾郵件過濾的系統中，第一層是一個較快速的分類器。
若比對資料符合第一層垃圾圖像資訊，則不需要第二層進一步的判斷。因此我們分別
9 
別的結果存入自我調整資料庫，利用批次學習的方法更新第二層的分類模組。實驗結果顯
示本系統能夠達到適應新型態垃圾圖像並且兼顧系統效能及準確性。 
雖然本計畫已完成主要的目標，但仍有許多研究議題以及改善的空間，在未來希望能
應用在分散式的環境中，結合郵件標頭資訊、內文資訊、圖像資訊與附件資訊，以協同合
作的觀念共同防範垃圾郵件，並研究更具有區隔性的郵件特徵，使系統能自動化的判別並
適應垃圾郵件。 
6. 參考文獻 
[1] H. B. Aradhye, G. K. Myers and J. A. Herson, “Image Analysis for Efficient Categorization of 
Image-based Spam E-mail,” Proceeding of the Eighth International Conference on Document 
Analysis and Recognition, Vol 2, pp. 914-918, September 2005. 
[2] B. Byun, C.H. Lee, S. Webb and C. Pu, “A Discriminative Classifier Learning Approach to Image 
Modeling and Spam Image Identification,” Proceeding of the 4th Conference on Email and 
Anti-Spam, August 2007. 
[3] C. C. Chang and C. J. Lin, LIBSVM: a library for support vector machines, 2001. Software available 
at http://www.csie.ntu.edu.tw/~cjlin/libsvm 
[4] G. V. Cormack and A. Bratko, “Batch and Online Spam Filter Comparison,” Proceeding of the 3rd 
Conference on Email and Anti-Spam, July 2006. 
[5] M. Dredze, R. Gevaryahu and A. Elias-Bachrach, “Learning Fast Classifiers for Image Spam,” 
Proceeding of the fourth conference on email and anti-spam, August 2007. 
[6] H. Drucker, D. Wu and V. N. Vapnik, “Support Vector Machines for Spam Categorization,” IEEE 
Transactions on Neural networks, Vol. 10, No.5, September 1999. 
[7] C. Frankel, M. Swain, and V. Athitsos, “Webseer: An Image Search Engine for the World Wide 
Web,” Univ. of Chicago Techniacal Report TR96-14, 1996. 
[8] G. Fumera, I. Pillai, and F. Roli, “Spam filtering based on the analysis of text information embedded 
into images,” Journal of Machine Learning Research, Vol. 7, pp.2699-2720, June 1999. 
[9] J. Hu and A. Bagga, “Categorizing images in Web documents”, IEEE MultiMedia, vol. 11, pp. 22-30, 
2004. 
[10] Q. Liu, Z.Q. Qin, H.R. Cheng, and M.C. Wan, “Efficient Modeling of Spam Images,” Proceeding of 
the third International Symposium on Intelligent Information Technology and Security Informatics, 
pp.663-666, April 2010.  
[11] T.J. Liu, W.L. Tsao, and C.L. Lee, “A High Performance Image-Spam Filtering System,” IEEE 
Proceeding of the Ninth International Symposium on Distributed Computing and Applications to 
Business Engineering and Science, pp. 445-449, August 2010. 
[12] Y. Rui, T. S. Huang, and S. F. Chang, “Image Retrieval: Current Techniques, Promising Directions, 
and Open Issues,” Journal of Visual Communications and Image Representation, vol. 10, pp. 39-62, 
1999. 
[13] M. Sahami, S. Dumais, D. Heckerman, and E. Horviz, “A Bayesian approach to filtering junk 
e-mail,” In AAAI’98 Workshop on Learning for Text Categorization, July 1998. 
[14] M. Stricker and M. Orengo, “Similarity of color images,“ SPIE Conference on Storage and Retrieval 
for Image and Video Databases III, vol. 2420, pp. 381-392, February 1995. 
[15] M. Uemura and T. Tabata, “Design and Evaluation of a Bayesian-filter-based Image Spam Filtering 
Method,” International Conference on Information Security and Assurance, pp. 46-51, May 2008. 
[16] Z. Wang, W. Josephson, Q. Lv, M. Charikar, and K. Li, “Filtering Image Spam with Near-Duplicate 
Detection,” Proceedings of the Fourth Conference on Email and Anti-Spam, August 2007. 
[17] SpamAssasian: http://spamassassin.apache.org/ 
[18] The Official CAPTCHA Website: http://www.captcha.net/ 
 2
MPJ2-RSA Digital Signature Scheme”。 
其中 Prof. Tsui 提到目前 Cloud-Based Knowledge Services 在商業應用及研究發展的挑
戰與問題；如何有效的利用 Cloud-Based Knowledge Service 來即時整合資料及進行決策，將
是 Cloud-Based Knowledge Services 研究的重點。Prof. Tsui 也同時討論如何應用 Cloud-Based 
Personal Learning Environment 來提供個人化的教育學習環境；這也是 Cloud-Based Knowledge 
Services 的一種應用。 
本次國際會議聚集世界各地從事有關 Software Engineering, Management science and 
services, Web Information Systems and Applications, Computer Network and Application 
Technology, Knowledge Management and E-Business and E-Commerce 等領域中的專家學者。各方
的專家學者聚集在一起討論及交換各類議題的研究心得以及最新知識，讓我與陪同前往的學生
都可以了解目前各方最新的研究方向與狀態。 
三、考察參觀活動(無是項活動者略) 
無。 
四、建議 
建議學校能夠鼓勵與補助研究生參與國際研討會。這樣不只能夠培養學生的國際觀，增
加學生的英文報告能力，對於學生的視野及溝通能力的提升有極大的幫助。 
五、攜回資料名稱及內容 
參與本次的國際會議，攜回資料名稱及內容如下: Proceedings, 2011 2nd IEEE International 
Conference on Software Engineering and Service Science。 
 
     
into clusters like LEACH[4]. In each cluster, a cluster head is 
chosen to collect the data from the nodes in its cluster. After 
the cluster head collect all the data in the cluster, it will send 
the data back to the sink. 
Recent research constructs a tree-based routing backbone 
in the network by neighbors’ information. Nodes in the 
backbone have the responsibility to collect the data and relay 
them to the sink. Wu et al. [11] proposed analgorithm to let 
sensor nodes to find the backbone members by exchanging the 
neighbor information. PEDAP[10] is a centralize algorithm to 
find a minimum spanning tree in the network based on prim’s 
algorithm [9]. Prim's algorithmfinds a minimum weight 
spanning tree based on the greedy method. In[12], Yang et al. 
solve the problem by finding the shortest path between any 
two nodes. Each node in the wireless sensor network willfinda 
node that has the smallest distance to the sink and let this node 
be its parent. The algorithm guarantees that every parent has 
the smallest distance to the sink, and these parent nodes form a 
shortest path routing backbone. 
Minimum connected dominating set solutions are also used 
in the routing constructing phase for wireless sensor networks. 
Although, finding a MCDS in the network has been shown as 
a NP-complete problem, we can still design an approximation 
algorithm to solve the problem. The algorithms can be 
classified into two categories: the centralized solutions and the 
distributed solutions. 
The centralized solutions require the information of all 
nodes in the network. The leader (usually the sink) will 
construct the backbone by this information, and then sends 
notification information to the backbone member.The first 
centralized algorithm for this problem is proposed by Das [2] 
in 1997. The algorithm constructs a virtual backbone by 
finding a CDS in the network. 
The distributed solution solves the problem by the 
collaboration of all nodes in the network. Every node decides 
the dominator based on the information of neighbors and itself. 
After the dominators are found, these dominators will form a 
routing backbone of the network. Usually, the algorithm starts 
from a special node called initiator (the sink can play this role). 
The initiator will broadcast a notification to all nodes, and 
nodes begin to find the dominator after receiving the 
notification. The algorithm in[8]first finds a MIS in the 
network; then the algorithm chooses some nodes(called 
connector) to connectthese MIS members. Raei et al. [7]find 
the MIS members based on the countdown mechanism. The 
countdown timer of a node is setbased on its degree. The node 
with bigger degree will become the members of MIS. After 
find the MIS members in the network, the sink will send a 
notification again to find the connectors. The MIS members 
and connectorswill form a routing backbone of the network. 
III. THE PROPOSED ALGORITHM 
In this section we discuss the proposed algorithm. In 
Subsection A, we briefly discuss the idea and parameters used 
in the algorithm. The proposed algorithm is in Subsection B. 
A. Preliminary 
Due to the energy constrain in wireless sensor networks, 
the usage of energy must be very efficient. As we have 
mentioned in Section I, the energy used for data transmission 
is more than the energy used in computing and sensing. 
Therefore, to reduce the energy consumption of the network, 
we have to prevent the unnecessary message transmission. The 
proposed algorithm reduces the energy consumption in the 
following two mechanisms. First, every node makes decision 
only based on its own information. Such a mechanism 
prevents the message transmission for collecting the 
information of neighboring nodes. Second, the algorithm 
constructs a connected dominating set in the networks. Only 
the nodes in the CDS have to relay the collected data to the 
sink node. The other nodes only forward the collected data to 
the neighbor in the CDS. Besides, the selecting of CDS 
members is based on the remaining energy of nodes. Only the 
nodes with more remaining energy will be selected as the CDS 
member. Such a mechanism will prolong the lifetime of the 
network.In the following of this subsection, we will discuss 
the idea and the parameters used in the algorithm. 
We assume that the sensor nodes are randomly deployed on 
a two-dimension plane. The sensor nodes are homogenous, and 
each node has a unique identification (ID). Notation Eiis to 
represent the remaining energy of nodei.The value of Ei will 
decrease due to the energyconsumption. To construct the CDS, 
each node maintains a weight variable Wi. The formula to 
calculate the weight is as follows. 
 
Et in the formula is a threshold. If the node’s remaining 
energy is smaller than the threshold, Et, the node is not 
suitable for being a dominator. We set the weight of the node 
to Wc, whereWc is a small constant. 
To reduce the message transmission for collecting the 
neighbor information, the proposed algorithm uses the timeout 
mechanism to select the dominator.When a node needs to 
make a decision, it will trigger a timer. If it does not receive 
any packet from neighbors before the timer counts down to 
zero, it will become a dominator. The countdown timer ΔT is 
calculated by following formula. 
ΔT= Tmax / Wi + Tc  (2) 
In the formula, the Tmax is a maximum value of timer. 
From formula(2), the node with more remaining energy has 
smaller ΔT. Therefore, the node with more remaining energy 
will change its state and become a dominator faster. 
First, the sink node initializes the algorithm. The 
neighboring nodes of the sink begin the dominator decision 
process after they receive the notification messages. After the 
decision process, the dominators set the sink as their parent 
and begin the dominator decision process. In the algorithm, Pi 
in each node irecords the parent information. 
)1(
,
,
Wi





otherwiseE
EEifW
i
tic
44
     
received packets. In the experiment, we fix the size of the 
square area.If the number of nodesin the area increases, the 
average degree will also increases.Therefore, the number of 
received packets increases also. The proposed algorithm only 
bases on the local information. No discovery message is 
needed. However, Raei’s algorithm has to calculate the degree 
of nodes. A lot of discovering messagesare necessary. In the 
simulation result, we ignore the discovering messages used by 
Raei’s algorithm. The simulation result also shows that the 
proposed algorithm is better than Raei’s algorithm if the 
number of received packets is considered. 
Now, let us focus on the number of packets transmitted by 
nodes. As was mentioned, the energy consumption for 
transmitting packets is higher than the other operations. 
Therefore, if the number of transmitting packets decreases, the 
energy consumption of the network also decreases. Figure4 is 
the result of the experiment. In the simulation result, we also 
ignore the number of packets transmitted for discovering. The 
simulation result also shows that the proposed algorithm is 
better than Raei’s algorithm if the number of transmitted 
packets is considered. 
At the end, we discuss the backbone size that is the number 
of nodes in CDS.If the number of CDS members is small, the 
number of nodes that have to relay the messages is small. 
Figure 5 shows the simulation result of the number of nodes in 
CDS. It shows that the CDS size generated by the proposed 
algorithm is smaller than CDS size generated by the Raei’s 
algorithm. 
The simulation result shows that the proposed algorithm is 
better than Raei’salgorithm no matter in the total number of 
received/transmitted packets or the size of CDS. Besides, the 
proposed algorithm selects the nodes with higher remaining 
energy to become dominators. Therefore, the overall network 
lifetime can be prolonged. 
V. CONCLUSION 
In this paper, we proposed an energy-awarebackbone 
construction algorithm. The proposed algorithm selects the 
backbone members based on the remaining energy.The nodes 
with higher remaining energy (means longer lifetime) will be 
selected as the backbone member.The proposed algorithm 
operates only based on the local information of each node; the 
algorithm combines with the countdown mechanism to avoid 
the discovering phase. We also compare the proposedalgorithm 
with the traditional degree-based algorithm to showthat the 
proposed algorithm can efficiently prolong the backbone 
lifetime. 
REFERENCES 
[1] B.N. Clark, C.J. Colbourn, D.S. Johnson, “Unit Disk Graphs”,Discrete 
Math., vol. 86, nos. 1-3, pp. 165-177, Jan. 1990. 
[2] B. Das, R. Sivakumar, V. Bharghavan, “Routing in Ad Hoc Networks 
Using a Spine”,Proc. Sixth Int’l Conf. Computer Comm. and Networks 
(IC3N ’97), p. 34, 1997. 
[3] L.M. Feeney, M. Nilsson, “Investigating the Energy Consumption of a 
Wireless Network Interface in an Ad Hoc Networking Environment”, in 
IEEE INFOCOM, 2001. 
[4] W. R. Heinzelman, A. Chandrakasan, H. Balakrishnan, “Energy-
efficient communication protocol for wireless microsensor networks,” in 
33rd Annual Hawaii International Conference on System Sciences, 2000, 
pp. 3005 – 3014. 
[5] C. Intanagonwiwat, R. Govindan, D. Estrin, J. Heidemann, F. 
Silva,“Directeddiffusion for wireless sensor networking”, IEEE/ACM 
transactionson networking, pp. 2-16, vol. 11, 2003 
[6] C.J. Lin, P.L. Chou, C.F. Chou, ”HCDD: hierarchicalcluster-based data 
dissemination in wireless sensor networks with mobilesink”, In 
Proc.International Conference on Wireless Communications andMobile 
Computing (IWCMC’06), pp. 1189-1194, 2006 
[7] H. Raei, M. Sarram, F. Adibniya, F. Tashtarian,“Optimal distributed 
algorithm for minimum connected dominating sets in Wireless Sensor 
Networks”, in IEEE conference on Mobile Ad Hoc and Sensor Systems, 
pp. 695-700, 2008. 
[8] H. Raei, M. Sarram, B. Salimi, F. Adibnya,“Energy-Aware Distributed 
Algorithm for Virtual Backbone in Wireless Sensor Networks”, in IEEE 
international conference on Innovations in Information Technology, pp 
435-439, 2008. 
[9] R. C. Rrim,“Shortest Connection Networks And Some Generalizations”, 
in the Bell system technical journal, pp.1389-1401, Nov. 1957. 
[10] H.O. Tan, I. Korpeoglu, I. Stojmenovic, "Computing Localized Power-
Efficient Data Aggregation Trees for Sensor Networks", in IEEE 
Transactions on Parallel and Distributed Systems, pp. 1-14, 2010. 
[11] J. Wu, H. Li, “On Calculating Connected Dominating Set for Efficient 
Routing in Ad Hoc Wireless Networks,” Proc. Third Int’l Workshop 
Discrete Algorithms and Methods for Mobile Computing and Comm. 
(DIALM ’99), pp. 7-14, 1999. 
[12] Y. Yang, H.H. Wu, H.H. Chen,“SHORT: Shortest Hop Routing Tree for 
Wireless Sensor Networks”, in IEEE International Conference 
onCommunications(ICC '06.), vol. 8, pp. 3450-3454, 2006. 
[13] Y.B. Ko, J.M. Choi, J.H. Kim, “A New DirectionalFlooding Protocol for 
Wireless Sensor networkss”, ICOIN 2004, LNCS3090, pp. 93–102, 
2004. 
 
Figure 5 The comparison of the number of nodes in CDS. 
0
5
10
15
20
25
100 200 300
Th
e 
nu
m
be
r o
f C
D
S 
m
em
be
rs
The number of nodes
The proposed algorithm Raei's algorithm
 
Figure 4 The comparison of the total transmitted packets. 
0
100
200
300
400
500
600
100 200 300
To
ta
l t
ra
nm
itt
ed
 p
ac
ke
ts
The number of nodes
The proposed algorithm Raei's algorithm
46
          
monitor the availability of other backup copies. Such an 
implementation also improves the system reliability. 
Today, the cost of computer becomes cheaper. Many 
distributed file system are implemented based on these cheaper 
computers. These file systems include Hadoop distributed file 
system (HDFS) [14][15], Google file system (GFS) [5] and 
YaFS [8]. 
HDFS provides a reliable, high performance distributed file 
system over many cheaper computers. It assumes that failure 
probability of these computers is very high. Thus, the design of 
the system has to consider the fault-tolerance issues. The 
system architecture of DHFS is distributed. It consists of one 
Namenode and many Datanode. The Namenode manages 
metadata and file namespace. The centralized management 
mechanism simplifies the entire file system structure. Besides, 
there are also much research [4][9] that improves the HDFS. 
The Google file system (GFS) [5] is for distributed 
computing; and it is used for storing the large number of web 
files. The file update and consistence maintenance of GFS is 
based on the primary chunk server. To reduce the loading of 
the master server, the master server will assign a primary chunk 
server to update files and maintain the consistence of file 
copies when a client writes a file. The consistence checking 
will be done when the loading of the master server becomes 
light. 
III. THE PROPOSED SYSTEM 
In this section, we discuss the proposed system. As it was 
shown in Figure 1, the proposed system contains three 
components: metadata servers, data servers and access servers. 
Metadata servers record the partition information of the 
proposed file system and the metadata of files. Data servers 
store the user file blocks. Access servers handle the user 
requests. Furthermore, to balance the loading of the proposed 
file system, we design a load detection module. The load 
detection module detects the data server with high loading; and 
it checks if this high loading data server will decrease the 
overall system performance or not. 
Access servers provide the interface for users. Users access 
the files in the proposed file system by sending requests to the 
access server. Based on the interface provided by the access 
server, users access the proposed file system just like access 
their local file system. 
In the proposed system, data servers are FTP servers. These 
FTP servers provide the storage space for users. When the 
storage space is not enough, users increase the storage space by 
simply adding FTP servers, or increasing the disk space on the 
FTP servers. The files stored in the proposed system will be 
replicated and the copies will store on different FTP servers in 
the different local area network. 
Metadata server stores the partition information, metadata, 
data server information, file attributes and the location 
information of replications. The metadata server also maintains 
the consistency of the replications. To improve the reliability of 
the proposed system, metadata servers are also divided into the 
active metadata server and the standby metadata server.  
The core of the proposed file system is the access server. 
To improve the system performance, the proposed system 
consists of many access servers. The loading of the file 
accesses is shared by these access servers. The functional 
blocks of the access server includes the file interface module, 
the file manager, the distributed storage manager, the  
dissemination / aggregation module, the load detection module, 
the recover module and the FTP client. 
In the following of this section, we will briefly discuss the 
function of these functional blocks. 
 File interface module 
The file interface module provides an interface for user to 
access the files stored in the proposed system. Users can access 
the proposed file system just like accessing a local file system 
by this interface. 
 File manager 
The access server communicates with the metadata server 
based on the file manager. The file manager will get and 
process the partition information and the metadata stored in the 
metadata server. The metadata includes a file/folder name, type 
(file or folder), file list, file size, location of replications, and 
the number of blocks in a segment. The partition information 
includes IP of data servers, username, password, disk quota, 
and file list. 
 Distributed storage manager 
The distributed storage manager will split a file into several 
blocks of fixed size; and it will replicate the file blocks 
according to user’s configuration. Then, the dissemination / 
aggregation module will save the file blocks and its replications 
in different data servers. 
 Dissemination / aggregation module 
The distributed storage manager will split the file into 
several blocks. Then, the dissemination / aggregation module  
Figure 1. System architecture 
48
          
all the data servers. When a user reads a file from the system, 
the access server concurrently gets file blocks from multiple 
data servers. Therefore, the file writing time is longer than the 
reading time. 
We also want to know the relation between the network 
throughput and the number of access requests. In the 
experiment, we use a gigabits switch to connect all devices; 
and each access server reads only one file. The file size in the 
experiment is 1024 Mbytes. The experimental result is in 
Figure 4. When we increase the number of access server (the 
number of request) to eleven, the overall network throughput 
reaches 896 Mbits/sec.  
When the loading of some data server is high, the overall 
system performance will decrease. As it was mentioned, the 
load detection module detects the data server with high loading 
and tries to improve the system performance by stopping the 
service from these high loading servers. In the following 
experiments, we simulate the high loading data server by 
limiting the network bandwidth from these servers. It is 
because that the throughput of data transmission will decrease 
if the loading of server is high. In the experiment, we 
respectively limit the bandwidth of one data server to 1 
MBytes/sec and 2 MBytes/sec. We make two experiments; the 
block sizes for each experiment are set to 64MBytes and 
128Mbytes respectively. 
Figures 5 and 6 show the experimental result for the 
reading performance. We can find that the load detection 
module can improve the overall performance while the loading 
of data servers is high.  
V. CONCLUSION 
This paper proposes a high performance and low-cost 
distributed file system. The proposed system integrates several 
commodity computers into a large capability distributed file 
system. The propose system increase the reliability by 
replicating files in different data servers. To prevent the 
decreasing of the overall system performance when the loading 
of some data server is high, we design a load detection module. 
The experimental result shows that the load detection module 
can improve the overall system performance when the loading 
of some data servers is high. 
REFERENCES 
[1] P. J. Braam, “The Coda Distributed File System,” Linux Journal, Jun. 
1998. 
[2] L. Cao, Y. Wang, J. Xiong, “Building Highly Available Cluster File 
System Based on Replication,” 2009 International Conference on 
Parallel and Distributed Computing, Applications and Technologies, 
pp.94-101, 2009. 
[3] H.C. Chao, T.J. Liu, K.H. Chen and C.-R. Dow, “A seamless and 
reliable distributed network file system utilizing webspace,” 
Proceedings of The 10th IEEE International Symposium on Web Site 
Evolution (WSE 2008) , Beijing, China, Oct. 2008. 
[4] B. Dong, J. Qiu, Q. Zheng, X. Zhong, J. Li, Y. Li, “A Novel Approach 
to Improving the Efficiency of Storing and Accessing Small Files on 
Hadoop: a Case Study by PowerPoint Files,” 2010 IEEE International 
Conference on Services Computing (SCC), pp.65-72, 2010. 
[5] S. Ghemawat, H. Gobioff, and S.T. Leung , “The Google File System,” 
Proceedings of the nineteenth ACM symposium on Operating systems 
principles(SOSP’03), vol. 37, Issue 5, Dec. 2003. 
[6] J. H. Howard ,“An Overview of the Andrew File System,” Proceedings 
of the USENIX Winter Technical Conference, USENIX Association, 
Dallas, US, pp.ʳ23-26 , Feb. 1988. 
[7] R. Jones, ̌ Gmail Filesystem – GmailFS, ̍ 
http://richard.jones.name/google-hacks/gmail-filesystem/gmail-
filesystem.html. 
[8] Y. Lu, H. Mao, “J. hen, “A Distributed Filesystem Framework for 
Transparent Accessing Heterogeneous Storage Services,” IEEE 
International Symposium on Parallel & Distributed Processing (IPDPS 
2009), pp.1-8, May. 2009. 
[9] Y. Lin, Y. Chen, G. Wang, B. Deng, “Rigel: A Scalable and Lightweight 
Replica Selection Service for Replicated Distributed File System,” 10th 
IEEE/ACM International Conference on Cluster, Cloud and Grid 
Computing (CCGrid) , pp.581-582, 2010. 
[10] J. K. Ousterhout, A. R. Cherenson, F. Douglis, M.N. Nelson, and B.B. 
Welch. “The Sprite Network Operating System,” IEEE Computer 
Society, vol. 21, Issue 2, pp. 23-36, Feb. 1988. 
[11] S. Shepler, B. Callaghan. “RFC 3530: Network File System (NFS) 
version 4 Protocol ,” Sun Microsystems Inc. , Apr. 2003. 
[12] J. Xiong, J. Li, R. Tang, Y. Hu, “Improving Data Availability For A 
Cluster File System Through Replication,” IEEE International 
Symposium on Parallel & Distributed Processing (IPDPS 2008), pp.1-8, 
2008. 
[13] Lustre File Ssystem : High-Performance Storage Architecture and 
Scalable Cluster File System , SUN microsystems White Paper, 2003. 
[14] Hadoop, The Apache Software Foundation, Available at 
http://hadoop.apache.org/core/ 
[15] HDFS Architecture, The Apache Software Foundation, Available at 
http://hadoop.apache.org/core/docs/current/hdfs_design.html 
[16] Object Storage Architecture, Panasas White Paper, 
http://www.panasas.com, Oct. 2003. 
 
Figure 6. Reading performance (block size = 128MB) 
 
Figure 5. Reading performance (block size = 64MB) 
50
99 年度專題研究計畫研究成果彙整表 
計畫主持人：劉宗杰 計畫編號：99-2628-E-035-051- 
計畫名稱：具自我調整能力之圖像垃圾郵件過濾系統之研究 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 1 1 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 6 6 100%  
博士生 1 1 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 0 1 100% 
已將本計畫研究
成 果 整 理 成 論
文，投稿到國際期
刊。 
研究報告/技術報告 0 0 100%  
研討會論文 2 2 20% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
 
