2 
 
 
圖一 Android 軟體堆疉 
（一）應用程式層  
Android 提供一系列的核心應用程式，包含 E-mail、簡訊程式、行事曆、Google 地圖、瀏覽器、
通訊錄等等。所有的應用程式皆必需以 Java 程式語言開發。 
（二）應用程式框架層  
應用程式框架提供 Android 所釋出的 API，開發應用程式時可以存取使用這些標準介面函式，達到
簡化及重複利用元件的功能。另外，藉由此框架所提供的介面函式，可以重新改寫 Android 原有
的核心應用程式，例如通訊錄加入照片顯示的功能等。 
Android 應用程式框架提供了以下函式介面： 
 Views System：用來建構一個應用程式的基本原件。 
 Content Providers：讓應用程式可以存取其他應用程式的資料。 
 Resource Manager：提供非程式碼資源，如多國語言編碼，圖片、音效。 
 Notification Manager：讓應用程式在狀態列顯示自訂的警示訊息。 
 Activity Manager：管理所有應用程式的生命週期。 
 Window Manager：管理視窗程式。 
 Package Manager：管理 Android 系統內所有安裝的程式。 
（三）函式庫 
Android 系統元件是由 C/C++函式庫所組成，應用程式需要透過標準 API 使用這些功能。主要的核
心函式庫，包括 System C 函式庫、多媒體函式庫、網路函式庫、資料庫函式庫、3D 函式庫、字
型函式庫…等等，這些函式庫大多是為嵌入式系統改良過的程式，程式執行效率較佳、功能較簡
化。 
（四）執行層 
Android 系統使用自有的 Android Runtime 來執行程式，執行層可分為兩大部份：核心函式庫與
Dalvik 虛擬機。核心函式庫包含許多執行 Java 程式所需使用的函式，Android 程式經過編譯之後，
會產生類似 Java Bytecode 的 Dalvik EXcutable（.dex）格式，並且於 Dalvik 虛擬機執行。另外，
Android 系統參考 Java 虛擬機器設計出適合嵌入式系統的 Dalvik 虛擬機，除了程式佔用較少的記
憶體空間，也可以同時執行多個應用程式。 
（五）作業系統層 
Android 是基於 Linux Kernel 2.6 版本的作業系統。Android 所使用的 Linux Kernel 提供安全性、記
憶體管理、排程管理、網路堆疊、驅動程式模組等系統服務。另外，在上述的軟體堆疊與硬體間
建立一個抽象層，將所有的硬體資源管理都交由 Linux Kernel 負責。 
3.2 OpenCORE 多媒體框架（Multimedia Framework） 
    OpenCORE多媒體框架是由Packet Video為Android系統所提供的多媒體函式庫，用以實現Android
4 
 
系統實作流程可分為四大部分： 
（一）掛載數位電視廣播模組 
於 Linux 系統核心內新增數位電視廣播模組，設定調諧整器的參數，以順利接收傳輸串流，並且
將取得的傳輸串流封包資訊傳送至多媒體來源節點（Source Node）。 
（二）OpenCORE 多媒體框架之數位視訊廣播元件 
定義傳輸串流的多媒體資料結構，以及透過 OpenCORE 多媒體框架所提供的介面，實作出數位視
訊廣播元件，使其能解析出傳輸串流中的視訊、音訊資料，並將這些資料交由底層的媒體解碼器
進行解碼。 
（三）實作 OpenMAX 整合層之 Mpeg2 元件 
依循 OpenMAX 整合層規格實作 MPEG2 多媒體元件，提供標準化解碼器或數位訊號處理器的
API，讓多媒體框架之工作節點能夠直接調用 OpenMAX 元件與硬體溝通。 
（四）數位電視播放器 APK 之實現 
使用 Eclipse IDE 開發數位視訊廣播應用程式，以測試實作系統之效能。 
4.1 數位電視廣播模組之實現 
    數位電視訊號會先經過數位壓縮將視訊、音訊串流組合成封包，再以傳輸串流的方式送出，為了
讓一般的電腦主機或微處理器能夠接收天線、纜線、衛星傳輸的數位電視封包，就必須使用數位電視
調諧器。因此，在為 Android 系統開發行動數位電視收播系統之前，應先在系統核心內加入數位電視
廣播模組，並且重新編譯核心；系統核心的數位電視廣播模組分為兩部分，第一部分為程式核心，管
理最底層於系統和記憶體間的資料流，第二部分是前端裝置，主要與數位調諧器的參數調整和串流擷
取有關。此模組根據系統實際連接的裝置建立/dev/dvb/adapterX 目錄，目錄中包含 demux、dvr、frontend
節點，demux 節點用在 PID 的過濾，dvr 用來接收串流，frontend 用來調整解調變器參數，如頻率
(frequency)、正交振幅調變(Quadrature Amplitude Modulation, QAM)參數、頻寬(Bandwidth)、傳輸率
(Transmission Rate)等等。 
      最後，修改 android/system/core/init/devices.c，一旦數位調諧器被安裝時，Android 系統便能夠
辨識出此數位調諧器，並自行掛載在/dev/dvb/adaptor0。 
4.2 OpenCORE 多媒體框架之數位視訊廣播元件 
    目前，OpenCore 多媒體框架支援的音、視訊類型為 MPEG4、H.264、MP3、AAC、AMR、JPG、
PNG、GIF 等格式。因此，要讓使用者能夠在 Android 系統上觀賞數位電視，則需自行在 OpenCore 多
媒體框架之中加入數位視訊廣播媒體格式及相關元件。新增的元件目錄及功能說明如下： 
 recognizer/pvmp2ffrecognizer：避免 OpenCORE 多媒體框架無法識別 Mpeg2 的 MIME
（Multipurpose Internet Mail Extensions）類型，需要實作一Mpeg2檔案格式辨識器（Recognizer）
用來識別 Mpeg2 資料的類型或內容。 
 fileformats/mp2 目錄：提供 Mpeg2 媒體格式的資料結構和解析工具。 
 nodes/pvmp2ffparsernode：實作一 Mpeg2 檔案格式解析器（Parser node），主要是將接收進來
的數位視訊廣播的傳輸串流封包，依照其規格解析串流封包所過濾出的視訊與音訊 PID 封
包，並形成視訊/音訊封包化單位串流，再去除標頭資訊，取出負載部分（Payload）結合成單
位串流，將音訊單位串流與影像單位串流分別送至聲音和影像解碼節點（Audio/Video Decode 
Node）。 
 codecs_v2：依據 OpenMAX 整合層標準，分別在 omx 目錄下實作出 Mpeg2 聲音及影像的
OpenMAX 元件；video/audio 為軟體編解碼器（Software Codec）和硬體編解碼器（Hardware 
Codec）API 所在的目錄，此次實作 Mpeg2 音訊解碼使用 Fraunhofer Institute 釋出的 Mpeg1 
Layer1/2/3 解碼器；視訊解碼部份，透過嵌入式平台提供的數位訊號處理器 API，便可以調用
數位訊號處理器的 MPEG2 解碼演算法來進行影像解碼。 
6 
 
1. 多媒體框架的工作節點首先調用 OMX_Init( )初始化 OpenMAX 核心，接著 OpenMAX 核心會
載入所有的 OpenMAX 元件，並且依各個元件於註冊時所寫入的元件名稱、角色（role），建
立起一個註冊清單（Registry）。 
2. 完成 OpenMAX 核心的初始化之後，然後便開始 OpenMAX 元件的初始化，並且列舉出相關
應 元件的 功能（Capabilities）以及音訊、視訊元件能使用多少的埠，根據其功能定義可以知
道 元件是否支援 UseBuffer( ) 或者 AllocateBuffer( ) 等等內容。 
3. 完成所有初始化後，元件將進行輸入、輸出緩衝區（Buffer）的設定。一開始，透
過 OMX_GetParameter( ) 取得輸入、輸出緩衝區的初始參數，接著使
用 OMX_SetParameter( ) 對輸入、輸出緩衝區進行參數設置。 
4. 結束輸入、輸出緩衝區的設置之後， OpenMAX 元件則會改變為載入（Loaded）狀態，而被
載入的元件首先會進入閒置（Idle）狀態，並且在輸入、輸出埠設定緩衝區。 
5. 進入閒置狀態以後， OpenMAX 元件便能將狀態改變成執行（Execute）狀態來處理媒體數據。
元件可以透過 OMX_EmptyThisBuffer( )向某個輸入埠發送資料，並且取得緩衝區中的資料進
行處理 ，同樣元件可藉由 FillThisBuffer( )要求某個輸出埠填充解碼或者編碼完的資料。 
6. 最後，如果釋放 OpenMAX 核心，則調用 OMX_Deinit() 來釋放資源。 
5.2 數位電視播放器應用程式  
 Android 軟體框架管理著應用程式包的生命週期，無法由應用程式直接控制，開發者只能在程式中
添加一些各狀態相對應的流程，每次 Activity 改變狀態時，就會執行相對應的行為。Android 應用程
式與使用者的互動，稱為 Activity。Activity 類別除了 OnCreate 函式之外，還定義 OnPause、OnResume
等等的基本行為，當從某個 Activity 切換到另一個 Activity 的時候，原本的 Activity 將經過一連串的
狀態改變。 
 
圖七 Android Activity 生命周期[33] 
5.3 數位電視收播系統應用程式 
在數位行動電視收播系統的應用程式實作方面，本計劃以按鈕（Button）類別建立數位電視的頻道
列表，使用 VideoView Widget 作為播放器，並且在按鈕中加入 listener 監看應用程式的行為，若使用者
點擊了某個節目按鈕，便會觸發事件並執行對應的函式，而實際的多媒體處理則是調用 OpenCORE 多
媒體框架來進行。圖八為實際硬體執行結果。 
8 
 
號格式，設計一套可運行於 OpenCORE 多媒體框架的數位電視收播元件，使其實現行動數位電視、多
核心協同工作與影音解碼播放的功能，並且分析此系統於硬體平台上的執行效能。 
 
    文中採用 OpenCORE 多媒體框架為基礎，針對數位視訊廣播規格設計其媒體資料處理流程，並且
依循 OpenMAX 整合層標準實作出 MPEG2 元件，作為多媒體框架和底層解碼器之間的溝通介面。將
來使用者只需要開發 Android 應用程式，即可執行數位行動電視播放系統，不必花費太多的時間於系
統軟硬體整合。不過，本計劃實作系統其畫面更新率仍為達到標準值，仍需對其流程最佳化，方可成
為較完善之數位行動電視播放系統。 
 
    對於本計劃實作的行動數位電視系統，未來可以規畫以下研究方向： 
 Dual DSP 解碼。目前行動數位電視系統於嵌入式平台上，只使用單一數位訊號處理器作為影像解
碼，未來可考慮將音訊解碼由微處理器換成另一顆數位訊號處理器來負責解碼，降低微處理器的
負載量，達到更好的執行效能。 
數位電視訊號強度偵測。數位電視訊號容易受到外界的干擾，使得訊號衰減或變形，導致接收端無法
取得正確或完整的串流封包資料。如果能夠整合數位電視調調器所量測到的資料，例如：訊號品質、
位元錯誤率、錯誤的資料量等等，便可提供使用者作為數位電視頻道流暢度的指標。 
參考文獻 
[1] “Embedded System”, http://en.wikipedia.org/wiki/Embedded_system, retrieved on Feb. 2010 
[2] ITRI, “嵌入式 Design Report”, 2008 
[3] ITRI, “PACDSP V3 Software Developer’s Manual Volume 1: Processor Architecture”, 2008 
[4] ITRI, “EMDMA Controller User Manual”, 2008 
[5] Reimers, U., "The DVB project-digital television for Europe," DVB (Digital Video Broadcasting): The 
Future for Television Broadcasting?), IEE Colloquium on (Digest No.1995/142) , vol., no., pp.1/1-1/7, 27 
Jun 1995 
[6] Reimers, U.H., "DVB-The Family of International Standards for Digital Video Broadcasting," 
Proceedings of the IEEE , vol.94, no.1, pp.173-182, Jan. 2006 
[7] “What is Android?”, http://developer.android.com/guide/basics/what-is-android.html, retrieved on March 
2010. 
[8] “PacketVideo web site”, http://www.pv.com/, retrieved on March 2010 
[9] JAVIER TAPIA, JIM KOSMACH, “INTRODUCTION TO THE OPENCORE AUDIO COMPONENTS 
USED IN THE ANDROID PLATFORM”, AES 34th International Conference, Jeju Island, Korea, 
August 2008. 
[10] JIM KOSMACH, KRISDA LENGWEHASATIT, “INTRODUCTION TO THE OPENCORE VIDEO 
COMPONENTS USED IN THE ANDROID PLATFORM”, 1st International Workshop on Video 
Coding and Video ProcessingShenzhen, China ,November 2008. 
[11] “OpenMAX™ web site”, http://www.khronos.org/openmax/, retrieved on March 2010. 
[12] The Khronos Group Inc. ,“OpenMAX™ Integration Layer Application Programming Interface 
Specification Version 1.1.2, 2008 
[13] Hee-Beom K.; Choon-Sik J.; Hyoung-Gil K.; Sang-Keun L.; Cheul-Hee H., "MPEG-2 transport stream 
multiplexer for recording," Consumer Electronics, 2005. ICCE. 2005 Digest of Technical Papers. 
International Conference on , vol., no., pp. 113-114, 8-12 Jan. 2005 
[14]  “MPEG transport stream”, http://en.wikipedia.org/wiki/MPEG_transport_stream, retrieved on May 
2010. 
[15] “Program Specific Information”, http://en.wikipedia.org/wiki/Program_Specific_Information, retrieved 
on May 2010. 
[16] “Specification for Service Information (SI) in DVB systems”, 
http://www.vdr-settings.com/download/a038r3.tm1217r14.dEN300468.V1.8.1.pdf, retrieved on May 
2010. 
10 
 
 
 
 
Special Issue:                    ACM Multimedia Systems Journal SI on Wireless Multimedia 
Transmission Technology and Application 
  
Date:  August 9, 2011 
Title of Paper:  Design and Integration of the OpenCore based Mobile TV 
framework for DVB-H/ T Wireless Network 
 
Corresponding Author:           Prof.  Yueh-Min Huang 
Department of Applied Geoinformatics 
Chia Nan University of Pharmacy & Science 
Tainan, Taiwan 
Email: huang@mail.ncku.edu.tw 
 
Authors: Prof. Chin-Feng Lai, Institute of Comp. Sci & Info. Engr.,  
National Ilan University, Taiwan  (cinfon@ieee.org)                           
                                                     Prof.  Yueh-Min Huang, Department of 
Applied Geoinformatics,  
Chia Nan University of Pharmacy & Science, Taiwan  (huang@mail.ncku.edu.tw)   
                                                     Prof. Jiann-Liang Chen, Department of 
Electrical Engineering, National Taiwan University of Science and 
Technology, Taiwan (Lchen@mail.ntust.edu.tw) 
Dr. Wen Ji, Dept of Computing, Hong Kong Polytechnic University 
     (jiwen@ieee.org) 
                          Prof. Min Chen, Dept. of Comp Sci & Eng,  
Seoul National University, Korea  (minchen@ieee.org)    
 
 
 
Abstract 
 
In the array of mobile communication techniques, the application of a mobile phone combined with television 
is a new technique under development. As TV program is a real-time video/audio service, in comparison with 
either traditional video/audio file downloads or network video/audio streams, there are more technical 
difficulties to be overcome, in particular, how to satisfy the playback functions of TV programs in hand-held 
device. OpenCore is a Multimedia Framework, which has recently been widely applied in hand-held devices, 
but it does not offer functions of mobile TV. To solve this problem, this study incorporates the function of 
mobile TV into the OpenCore framework, in order to support both formats of TV signals, i.e. DVB-H and 
DVB-T. The incorporated function, DVB-H/T, has different characteristics, so that users can select TV signals 
according to their receiving environments and fulfill their needs in TV programs selection. 
 
 
 
Keywords: OpenCore, Mobile TV, DVB Wireless Network 
 
 
Design and Integration of the OpenCore based Mobile TV 
附件 已接受論文 
12 
 
OpenCore. DVB-H/T mobile TV realization consists of two main parts: OpenCore DVB-H/T parser node and OpenMax 
DVB-H/T component. The former is used to interpret relevant information in DVB-H/T signal, extract, and then send 
audio/video data to the Decode Node, while the latter enables communication between OpenCore and the OpenMax 
DVB-H/T component.  
The remainder of this paper is organized as follows: Section 2 discusses relevant technologies of OpenCore and 
DVB-H/T; Section 3 describes the complete OpenCore based mobile TV framework, including flow and methods of 
OpenCore DVB-H/T parser node and OpenMax DVB-H/T component; Section 4 presents practices and results; Section 
5 gives conclusions. 
 
II. RELATED WORK 
 
A. Mobile TV 
 
Mobile TV usually denotes that TV programs can be watched on handheld devices and has been developed as 
“mobile-centric”.  At present, two methods are available to watch TV programs on handheld devices: 1) the 
manufacturer can transmit TV programs to the mobile phones users in the form of 3G stream [6-8]; 2) digital video 
broadcast can be realized through terrestrial TV station transmission systems [9]. The main difference between the two 
methods is that 3G transmits signals through wireless communication, and thus, may be subject to limitations in 
transmission rates and band width. Digital video broadcast transmits TV programs through terrestrial TV station 
transmission systems; thus, the problem of transmission network congestion may be avoided. As the broadcast networks 
starts making the content available online, there are many standards for digital video broadcasting. Digital Video 
Broadcasting (DVB) is utilized in Europe and Asia, while Advanced Television Systems Committee (ATSC) is used in 
North America. 
About the researches on mobile TV, most papers either focus on the transmission control between front-end 
transmitters and receivers for mobile devices to maintain video quality and signal reliability or propose interactive 
service mechanisms with TV return channels [10-14]. However, the challenges on mobile devices are discussed less 
frequently, especially when mobile TV services become more and more popular. Due to the different characteristic of 
each platform, developers spend much time in attempting to overcome hardware limits. Therefore, this study 
incorporates mobile TV services supported DVB-H/T format into the OpenCore framework to reduce development 
time. 
 
B. OpenCore 
 
Figure 2 shows OpenCore, also known as PacketVideo. In fact, PacketVideo is the name of a company, and 
OpenCore is the name of the software layer of the multi-media framework. In Android development, both have the same 
meaning. In comparison with other link libraries of Android, OpenCore has a large number of codes, which are realized 
based on C++, and defines all-functional porting layers of the operating system. Various basic functions are 
encapsulated as categories, and most interfaces among the different layers apply modes, such as succession. The 
OpenCore framework can be separated into the following components in terms of its functions.  
PVPlayer: provides functions of a media player, and complete playback functions of various audio/video streams.  
PVAuthor: provides functions of media stream recording, and complete functions of capturing audio/video streams 
and static images.  
PVPlayer and PVAuthor are provided to the developer in the form of SDK, on which several application programs 
are based, and services can be established. Common multi-media application programs applied in the mobile terminal 
include a media player, a camera, a video recorder, and a sound recorder.  
To better organize the whole framework, in the macro level, software layers of OpenCore are separated into several 
layers:  
The Operating System Compatibility Library (OSCL) includes some basic operations of the operating system in 
order to better realize porting among the different operating systems. These include base data type, configuration, 
character string tool, IO, error treatment, execution, etc.  
PacketVideo Multimedia Framework (PVMF): consists of a parser, a composer, and an encoding/decoding node; 
and it may replace its universal interface, thus, realizing nodes in the user layer.  
PVPlayer/ PVAuthor Engine: provides interfaces necessary for transmitting data packets between application 
programs and the OpenCore framework, and combine with the Node to realize such functions as encoding/decoding and 
stream control.  
In fact, OpenCore has many contents; from the viewpoint of playback, PVPlayer input (Source) is file or network 
media stream, and output (Sink) is a video/audio output device, its basic functions including media stream control, file 
parsing, and video/audio stream decoding. In addition to playing media files, it also includes an RTSP stream connected 
14 
 
The encapsulating format of the whole DVB-H/T and the encapsulating format of IP data of various layers of the 
whole DVB-H are shown in Figure 4. IP packages are inside the MPE Section, and redundant data are inside the FEC 
Section. After the Section formats are encapsulated, they are end-to-end connected in the encapsulating format, within 
the MPE Section and FEC Section into Section data stream. Following this, each Section data stream is cut into 
184-byte intervals from its first byte, and a 4-byte transport stream file head is added to each 184-byte data length at its 
head, in order to complete one complete transport stream package. In other words, the length of MPEG2 Transport 
Stream Packet is of 188 bytes, and it consists of two parts, a data Header, occupying 4 bytes, and providing such 
information as Sync. Byte=47hex, error indications, and stream package identification synchronous at the transmission 
and receiving terminals, and the payload, occupying 184 bytes. The IP and UDP packages contain package file headers. 
The RTP package is encapsulated according to RFC3984, and carries H.264 images and AAC compressed voices. The 
DVB-T has relatively simple package format. After the MPE Section is decoded, the MPEG-2 images and AC-3/MPEG 
voices will occur. 
 
Figure 4 DVB-H/T encapsulating format 
 
III. Proposed Architecture 
 
A. Overall Architecture 
 
At present, audio/video types supported by OpenCore include MPEG4, H.264, MP3, AAC, AMR, JPG, PNG, GIF, 
etc. Therefore, it is necessary to add the DVB-H/T file format, DVB-H/T parsing components to the OpenCore 
framework. In the OpenCore framework, the MEPG-2 data structure is defined, and developed DVB-H/T components 
are added to the original OpenCore framework as shown as Figure  5, and its development flow is described as below:  
1. Adjust modem parameters, such as frequency, Quadrature Amplitude Modulation (QAM), Bandwidth, 
Transmission Rate, and Guard Interval. Transport streams can be smoothly received only through modulating used 
parameters, and then acquired stream packet information is transmitted, until the Source Node is completed.   
2. Parse transport streams:  
i. Reject incomplete packages. 
ii. Apply DVB-H/T file format parser, as completed in PVMF, to parse videos, audios, captions, and multi-lingual 
stream PID from the data stream transmitted by the Source Node.  
iii. Processing mode of video stream: as the unit stream is in the DVB-H/T compressed format, decoding is 
required for playback. Therefore, the DVB-H/T decoding algorithm is used for decoding video unit streams. 
iv. Processing mode of audio stream: same as the video stream, the MPEG2 Layer1 decoding algorithm is used for 
audio unit stream servers for decoding.  
 
3. Decoded and adjusted frames are sent to the constructed Sink Node. Here, the video frame buffer, which is housed 
within the system memory section, corresponds to the memory of solid display. The video decoder converts the 
digital data inside the frame buffer into analog composite signals and output to the screen.  
4. After decoding, audio waveform data are sent to the constructed Sink Node through a sequence audio port, which 
is an audio output port.  
5. The A/V synchronous mechanism established by the OpenCore framework is used to simultaneously send out 
images and voices. 
16 
 
(SI) and Program Specific Information (PSI). In DVB-H, the streams are transmitted in the format of MPEG2-Section. 
Relevant information in the Section Header, such as table_id, Network_ID, length, section_no, and other flags, are used 
to analyze streams, SI, and PSI. Four tables are included in PSI, the Program Association Table (PAT), the Program Map 
Table (PMT), and the Conditional Access Table (CAT) Network Information Table (NIT). MPEG specifications do not 
define the details CAT or NIT, which are defined by the manufacturers. PAT records the list of all programs in the 
streams, and gives each program one 16-bit program code. Each program has one PID of program corresponding table, 
and the PID of the program index table is defined as 0. See Figure 8 for examples. From the packet with a PID of 0, it 
may be found that several programs are included in the transport streams. PID codes of corresponding tables of each 
program, information of PMT recording programs, video unit streams PID of programs, audio unit stream PID, and 
caption unit stream PID are included in this table. Figure 9 show an examples. The relationship between PAT and PMT 
is shown in Figure 10. After the data are parsed by the Parser Node, Audio/Video Data are sent to Audio/Video Decode 
Node and EPG is shown on the TV Player Interface. 
 
 
Figure 7 MPEG2-PES Format 
 
Figure 8 PAT Data Example 
 
 
Figure 9 PMT Data Example 
18 
 
component, list the capabilities of the corresponding component, and obtain a valid port number of the 
Audio/Video component. According to such capabilities, whether the component supports part of the 
frame, and whether the component supports Usebuffer or AllocateBuffer will be known.  
3. The PVMF communicates with the omx component input/output buffer after initializing both omx core and 
omx component. OMX_GetParameter is first used to obtain input/output port buffer parameters, then the 
obtained parameters are verified, and last, the OMX_SetParameter is called to set buffer parameters for 
the input/output port.  
4. After the initialization and communication with input buffer, the OMX component is loaded, and then enters 
into an idle state. Then, PVMF will allocate buffers for all input/output ports.  
5. After entering into an idle state, The OMX component will move into an execution state to process data, and 
conduct a data exchange with the PVMF. First, PVMF gives commands to the omx component to 
transform the state from Idle to Execute. Next, the PCMF will send data to a certain input port of the 
component, through OMX_EmptyThisBuffer, forcing the component to acquire data from the buffer for 
processing. At the same time, PCMF requires the component to fill decoded or encoded data into its one 
output port, through FillThisBuffer. Before PCMF uses emptythisbuffer to re-allocate the buffer to the 
component, the component cannot operate the buffer.  
6. At last, PVMF calls OMX_Deinit() to release the omx core. 
 
 
Figure 12 Call sequence of OpenCore and Omx components 
 
 DVB-H/T Data are transmitted to an DVB Decode Component for decoding Audio and Video. First, the DVB 
Decode Component will inquire through OpenMAX IL Core, upon intervals, whether the OMX node has data for 
decoding. If it has, OpenMAX IL Core will clear the required OMX Input buffer and store the data in the OMX node for 
decoding in the OMX buffer. Then, data in OMX Input buffer are migrated to EMDMA Buffer for decoding, and then, 
the OpenMAX IL Core will continually inquire whether EMDMA Buffer decoding is finished. After the decoding, the 
OpenMAX IL Core will immediately clear the required OMX Output buffer, and then transmit decoded data in the 
EMDMA Buffer to the OMX Output Buffer, and then, inquire whether there are data in the Input Buffer for decoding. 
The Component will continually repeat this loop until no data are available for decoding. Figure 13 is the process of 
whole DVB Decode Component. 
 
20 
 
is that the reference mode of H.264, in the respect of frames, is different from that of MPEG2. 
 
Figure 15 CPU Utilization of Openmax DVB-H/T component 
 
B. Power Consumption 
 
To clearly measure the consumed power when this framework plays back TV programs, this study tests the power 
consumed when all TV programs are played back, and the mobile system is in an idle state, as shown in Figure 16. 
When the system is out of service, consumed power is 0.9 watt. Figure 17 shows the consumed power when DVB-H/T 
TV signals are played back. As seen, as DVB-H applies the Time Slicing technique, namely, only during the period 
when signals are sent (burstduration), the receiver is turned on to receive, and otherwise, it is in off state. This method 
greatly reduces the power consumption of the DVB-H Header (turner plus demodulator); however, operations, such as 
compression of h.264 at rear end, and filtering at MPE-EFC and IP Header would increase the DVB-H power 
consumption, but as a whole, power consumption of DVB-H is less than that of DVB-T. 
 
Figure 16 Power Consumption of the Mobile TV 
 
 
22 
 
REFERENCES 
 
1. L. Zhou, N. Xiong, L. Shu, A. Vasilakos and S.-S. Yeo, “Context-Aware Multimedia Service in Heterogeneous Networks,” 
IEEE Intelligent Systems, vol. 25, no. 2, pp. 40-47, Mar./Apr. 2010.   
2. Cosmas J, Itegaki T, Cruickshank L et al., “Converged DVB‐T and GPRS service scenarios and application 
production tools,” Proc. CONFTELE 2003, Aveiro, Portugal, 2003. 
3. L. Zhou, B. Geller, B. Zheng, A. Wei, and J. Cui, “Distributed Resource Allocation for Multi‐Source 
Multi‐Description Multi‐Path Video Streaming over Wireless Networks,” IEEE Transactions on 
Broadcasting, vol. 55, no. 4, pp. 731‐741, Dec. 2009. 
4. L. Zhou, X. Wang, W. Tu, G. Mutean, and B. Geller, “Distributed Scheduling Scheme for Video Streaming 
over Multi‐Channel Multi‐Radio Multi‐Hop Wireless Networks,” IEEE Journal on Selected Areas in 
Communications, vol. 28, no. 3, pp. 409‐419, Apr. 2010. 
5. L. Angrisani et al, “Power Measurements in DVB‐T Systems: New Proposal for Enhancing Reliability and 
Repeatability,” IEEE Transactions on Instrumentation and Measurement, vol. 57, no. 10, pp. 
2108‐2117, October 2006. 
6. H. Fuchs and N. F¨arber, “Optimizing Channel Change Time in IPTV Applications,” Proc. IEEE Broadband 
Multimedia, Las Vegas, USA, 2008. 
7. S. Parkvall et al., “Evolving 3G Mobile Systems: Broadband and Broadcast Services in WCDMA,” IEEE 
Commun. Mag., vol. 44, no. 2, pp. 68–74, Feb. 2006. 
8. Y. Solomon, “The Economics of Mobile Broadcast TV,” Mobile DTV Alliance Whitepaper, Jan. 2007. 
9. Rauch C, Kelleler W, “Hybrid mobile interactive services combining DVB‐T and GPRS,” Proc. the 
European personal mobile communications conference (EPMCC) 2001, Vienna, Austria, 2001 
10. Y. Zhang, C. Zhang, J. Cosmas and K. K. Loo, et al, “Analysis of DVB-H Network Coverage With the Application of 
Transmit Diversity,” IEEE Transactions on Broadcasting, vol. 54, no. 3, pp. 568-577, Sept. 2008. 
11. D. G´omez-Barquero and A. Bria, “Forward Error Correction for File Delivery in DVB-H,” Proc. IEEE VTC Spring, Dublin, 
Ireland, 2007. 
12. B. D. Lee, J. Song and Y. K. Nam, "Converged mobile TV services supporting rich media in cellular and DVB-H systems," 
IEEE Transactions on Consumer Electronics, vol. 54, no. 3, pp. 1091 - 1097, August 2008. 
13. G. Gardikis, G. Kormentzas, G. Xilouris, H. Koumaras and A. Kourtis, “Broadband data access over hybrid DVB-T networks,” 
Proc. the 3rd conference on heterogeneous networks (HETNETs) ‘05, Ilkley, UK, 2005 
14. D. Gómez-Barquero and A. Bria, “Error repair for broadcast transmissions in DVB-H systems,” Wireless Communications 
and Mobile Computing, vol. 9, no. 6, pp. 733-744, June 2009. 
15. ETSI EN 302 304 (2004) Digital Video Broadcasting (DVB): transmission system for handheld terminals (DVB-H), European 
Standard, v.1.1.1 
16. ETSI TR 102 401 (2005). Digital Video Broadcasting (DVB); transmission to handheld terminal (DVB-H), Validation Task 
Force Report 
17. ETSI TR 102 377 v1.3.1, “Digital Video Broadcasting (DVB); DVB-H Implementation Guidelines,” May 2007. 
18. ETSI, “Digital Video Broadcasting (DVB); Framing Structure, ChannelCoding and Modulation for Digital Terrestrial 
Television,” ETSI EN300 744 v1.4.1, 2001. 
19. ETSI TS 102 472 v1.2.1, “IP Datacast over DVB-H: Content Delivery Protocols,” Dec. 2006. 
20. M. Kornfeld and G. May, “DVB-H and IP Datacast - Broadcast to Handheld Devices,” IEEE Trans. on Broadcasting, vol. 53, 
no. 1, pp. 161-170, March 2007. 
 
 
 2
ISCAS 是 IEEE Circuit and System Society 最主要的一個研討會，此會議提供了一個論壇給與研究人
員、系統開發商、服務提供商、學術研究學者在快速發展的技術中進行思想交流、設計和經驗上的討
論。此次 ISCAS2011 在巴西里約熱內盧舉行，共有多個國家參與。在巴西的生活體驗亦增加了個人不
少的體驗，對於巴西的都市建築、生活環境、飲食習慣、資訊技術、學術研究上都帶給我不一樣的認
識，更加仔細觀察巴西的點點滴滴。 
 
三、考察參觀活動(無是項活動者略) 
四、建議 
 感謝國科會的提供此出國經費。 
五、攜回資料名稱及內容 
1.會議論文集電子檔一份 
2.大會議程手冊一本 
 
Parallel Dynamic Voltage Frequency Scaling for Stream Decoding using  
a Multicore Embedded System 
Ying-Xun Lai, Chin-Feng Lai,Yueh-Min Huang 
Department of Engineering Science 
National Cheng Kung University 
Tainan, Taiwan 
eetaddy@gmail.com, cinfon@ieee.org, 
huanh@mail.ncku.edu.tw 
Ljiljana Trajkovic 
School of Engineering Science 
Simon Fraser University 
Vancouver, Canada 
ljilja@cs.sfu.ca 
 
 
Abstract—Parallel structures can be used to increase system 
processing speed in case of large amount of data or highly 
complex calculations.. For simpler calculations, Dynamic 
Voltage Frequency Scaling (DVFS) can be used to decrease the 
system frequency or voltage and achieve lower power 
consumption. Combining the two mechanisms can lead to higher 
effciency and lower power cost. In this paper, we introduce a 
parallel decoder streaming process for power efficiency in a 
multi-core embedded system. We describe a parallel low power 
design on the system level Under the condition of preserving the 
original decoder stream, we manage the system multimedia 
buffer area by considering the spontaneous streaming transfer 
and tuning the decoding process scheduling time by using the 
DVFS system in order to decrease the multimedia data 
dependency and offer multi-core embedded system with 
accurate and low power detection mechanism. 
Keyword: Parallel decode; DVFS; Streaming 
I. INTRODUCTION 
Many current products begin to use embedded systems. The 
increased quality of commercial products and demand 
multimedia applications were needed with increasing number 
of data operations. Under the demand of the increased system 
frequencies, the proposed hardware embedded systems begun 
using multi-core designs. These new architectures pose many 
challenges to a developer:  
1) Many embedded multimedia applications exhibit 
dependency problems during decoding processes that refer the 
previous segment to perform decoding. Applications of single 
core platforms are different and a multi-core systems 
developer should consider how to effectively distribute the 
data to different cores for processing and avoid dependency 
problems. 
2) Compared to single core platforms, multi-core systems 
need a power managing mechanism to prevent excess power 
usage, especially in case of embedded systems such as hand 
held and battery devices. Dynamic Voltage Frequency Scaling 
(DVFS) is a good solution: it dynamically lowers the system 
voltage or frequency during low calculation applications and it 
is effective for decreasing power cost. The challenge is how to 
predict the system voltage or frequency with a running 
application process in order to achieve low power and to 
prevent.  
3) An important and realistic problem is the overhead. For a 
system developer, overhead determines the time to be invested 
to change the single core system platform to a fully working 
system. This remains a major issue to for developers and 
manufacturers.   
In this paper, we introduce a front end parallel power 
management stream decoding system. We consider the entire 
system structure. While preserving the original structure, the 
parallel decoding implementation is achieved by using a 
simple yet effective front-wave concept: combining the buffer 
management mechanism under the acceptable limits for the 
end-user to remove the time slack and estimation error and 
considering parallel processing for `using the power efficient 
oriented mechanism.  
In Section II, we introduce the DVFS system and review 
related research in the area of parallel structures and single 
core decoding procedures. In Section III, we introduce the 
front-end parallel DVFS system, including system structure 
and module design. The implementation of the experimental 
platform and power efficiency prediction is given in Section 
IV. We conclude with Section V. 
 
II. RELATED WORK AND BACKGROUND 
We classify related proposals in two types: parallel decoding 
and the DVFS system. We use the H.264/AVC decoding as 
an example to introduce the structure and procedure of the 
embedded system with heterogeneous core platform. 
A.  Parallel Decoding 
There are many designs dealing with parallel decoding. If a 
complete decode frame is used as a separation point, the 
designs can be grouped into two main types: as front-wave 
parallel processing or internal parallel processing. 
 
 Front-Wave Parallel Processing 
       
          
    the adjustable frequency under Vx voltage. 
If the system starts from frequency      
   and achieves      
  , 
according to (2) we can calculate the workload defined by 
system frequency and cycle as: 
 
       
            
                             (4) 
 
where    is the chosen frequency and     is the respective 
workload. Predictions are made according to worst case 
scenario to perform prediction and satisfy condition: 
                                     .        (5) 
 
The ideal situation is that the predicted workload satisfies the 
applied deadline. If the system frequency cannot completely 
satisfy  =     , time slack occurs. Hence, we propose a 
time-orgiented prediction that differs from the worst-case 
prediction rule. It is based on finding the closest       
frequency given by the inequality : 
 
                                          .  (6) 
 
This ensures the prevention of estimation errors and the next 
time segment can then be estimeted as 
 
                              .               (7) 
 
We then use      to estimate the prediction of the system 
voltage and frequency of the next time segment. 
 
 
Fig. 2 The DVFS algorithm for independent frames. 
 
D.  DVFS Algorithm for dependent Frames 
In this Section, we discuss the immediate data dependency 
problem stream system to set a respective voltage and 
frequency. Since the ED decoding process has no data 
dependency problem, when the third column of the reference 
frame completes decoding the entire system may begin 
decoding. Hence, we only need to ensure that the column 
number remains above 3, as shown in the equation: 
 
   
       
       
                              ,  (8) 
 
where        
    is the time spent for ED decoding,    
    is the 
reference time needed for ED decoding, and    
    is the time 
needed to decode the first three columns of the frame., We 
use (8) and the system average priority to determine    
    and 
   
    
 
   
      
   
    
                                  (9) 
   
    (     
   )  
 
      
        ,           (10) 
where       is the frame column number that can decide the 
voltage and frequency needed by the decoding frame in the 
ED process. In ideal circumstances, this can correct the data 
dependency problem. However, in realistic decoding schemes, 
different frame format decoding have different speeds. 
 
IV. IMPLEMENTATION AND ANALYSIS  
A. Implements of DVFS Algorithm on HUM Platform 
This proposed system uses the PAC Duo as the hardware 
platform and implements the proposed power efficiency 
perceptive system on the Android OpenCORE. The system 
structure and operating procedure are shown in Fig. 3. The 
system operates from the upper application layer APK that 
calls the OpenCORE multimedia framework to perform video 
playback. OpenCORE is responsible for coordinating the DSP 
for processing. It uses DVFS predictor decoder load to 
perform prediction for the appropriate DVFS level. It then 
uses I/O controller to transfer data to the DSP PM Driver, then 
performs DSP voltage frequency control for the DVFS 
controller to achieve coordination. Finally, OpenCORE 
activates DSP to perform video decoding. 
 
 
Fig. 3 The Android system structure and procedure. 
 
國科會補助計畫衍生研發成果推廣資料表
日期:2011/08/05
國科會補助計畫
計畫名稱: Android OpenCORE之數位視訊廣播收播機制於嵌入式平台之設計與整合
計畫主持人: 賴槿峰
計畫編號: 99-2218-E-197-003- 學門領域: 計算機結構與計算機系統
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
