1一、中英文摘要
中文摘要
本計畫為二年期計畫，第一年計畫包含兩部分，分別為利用連續覆蓋演算法與證據理論
從支撐向量機器中產生模糊規則與利用支撐向量機器改善紋理(texture)辨識效能；第二年計畫亦
包含兩部分，分別為修改支撐向量機器的架構以改善多元分類的效能與提出演繹式演算法以自
動調整支撐向量機器的控制參數並獲得最佳效能。至目前為止提案人已完成了此兩年計畫內的
所有研究並已將研究結果投稿至國外期刊中，符合當初提案時所設立之預期進度。
首先在第一年第一部分的計畫中提案人以支撐向量機器為基礎提出一個二階段的模糊法
則建構演算法，此演算法先利用證據理論與叢集演算法利用此性質進行支撐向量的擷取，接著
再以連續覆蓋演算法的精神利用支撐向量對模糊法則進行法則建立，最後再將剩餘的模糊法則
帶入粒子群最佳化演算法以產生最適切的模糊法則。在第二部分中提案人提出最小面積橢圓分
析方法來克服影像因經過旋轉或位移後所產生的辨識問題。本計畫中所提出之演算法利用三種
不同的紋理特徵擷取方法以達到互補的作用。第一種特徵擷取方法以賈伯濾波器在空間頻率域
的不同位置來求得紋理影像中主要的紋理成份。第二種特徵擷取方法以二維統計方法取得紋理
影像之鄰近灰階相依矩陣。第三種方法採用最小面積橢圓旋轉不變的概念，利用最小面積橢圓
含括特徵點，再利用橢圓長寬和橢圓內像素灰階值的平均值和標準差來當作資料的特徵值並進
行辨識。經實驗證明本計畫所提出的方法可獲得令人滿意的分類效能。
接下來在第二年的計畫中針對多元分類的問題以及調整支撐向量機器的控制參數部分提
案人分別提出演算法來改善目前的效能。在控制 C與γ參數的設定部分本研究提出以模糊規則
為基礎的演算法來設定這兩個參數的數值，在此模式中模糊法則詮釋支撐向量機器參數與訓練
資料間的關係，並以模糊推論機制來調整支撐向量機器的參數值，使得此參數值可依不同情況
進行調整以達到訓練誤差最佳化的狀態。在模糊法則中使用四個語意變數(linguistic variable)，
分別為 Entropy、Mean、Mean of square與類別內外差益比。利用後三個參數來估算訓練資料中
類別內的資料與類別間的資料於空間中分佈的情況以評估分類誤差率以及誤差量，藉以提供設
定 C值得參考。另外則是利用 Entropy與Mean of square來估算類別內資料的分佈情形以提供
設定核心函數參數時的依據。依據以上參數於此部分的計畫中共規畫出十一條模糊規則分別控
制 C值與高斯函數的 sigma值。
最後在本計畫的第四部分提案人針對支撐向量機器面臨多元分類時效率不佳的情況提出
一個新的架構，在此部分中提案人先證明擴充目前的二元分類架構至多元分類架構是可行的，
唯一的問題在於如何安排類別分類的順序。接下來則針對類別分類的順序提出以基因演算法為
基礎的演算法藉由學習中安排理想的類別分類順序。
關鍵詞： 模糊法則、多元類別、證據理論、連續覆蓋演算法、粒子群最佳化演算法、紋理影像、
賈柏濾波器、基因演算法。
3二、報告內容
（一）、前言
本計畫為二年期計畫，計畫內容共分成四部分，分別為第一部分：利用連續覆蓋演算法
(sequential covering algorithm)與證據理論(evidence theory)從支撐向量機器中產生模糊規則、第
二部分：利用支撐向量機器改善紋理(texture)辨識效能、第三部分：利用模糊理論控制支撐向量
機器訓練時的參數數值以及第四部分：解決支撐向量機器處理多元分類時效率不佳問題。至目
前為止提案人已完成了此四部分的研究並已將研究結果投稿至國外期刊中，符合當初提案時所
設立之預期進度。以下為此四部分之完整報告。
至目前為止有為數眾多的學者提出有關系統法則建立相關的研究，這些研究約歸類成三
類：學習式(learning based)、分解式(decomposition)以及折衷式(eclectic)。這些研究雖然有不錯
的效能，然而也存在著一些缺點。因此在本計畫中我們以支撐向量機器為基礎提出一個兩階段
的模糊法則建構演算法，相較於以上所提的演算法此演算法的優點在於除了所產生的法則具有
法則數量較少以及保持高正確性外，另外其效率亦較其他演算法來得高。此研究中我們先分析
支撐向量的性質，接著在第一階段結合證據理論與叢集演算法利用此性質進行支撐向量的擷
取；第二階段中先以連續覆蓋演算法的精神對模糊法則進行法則建立與整併之動作，接著再將
剩餘的模糊法則帶入粒子群最佳化演算法以產生最適切的模糊法則。
此外本研究亦將提出一個新的演算法以改善經過旋轉以及位移後的紋理影像的辨識能
力。本計畫中所提出之演算法利用三種不同的紋理特徵擷取方法以達到互補的作用。第一種特
徵擷取方法以空間頻率方法中的賈伯濾波器(Gabor filters)在空間頻率域的不同位置來求得該空
間頻率域內是否存在主要的紋理成份。第二種特徵擷取方法以二維統計方法取得紋理影像之鄰
近灰階相依矩陣(Neighboring Grey Level Dependence Matrix，NGLDM)，經由計算 NGLDM 矩
陣得到影像特徵向量。第三種特徵擷取方法以最小面積橢圓旋轉不變的概念來處理，首先利用
叢集法(clustering algorithm)找出紋理影像中具代表性的幾個特徵點，接著引入最小面積橢圓含
括這些特徵點，最後利用橢圓長寬和橢圓內像素灰階值的平均值和標準差來當作資料的特徵
值。在辨識階段，本計畫中引入 SVMs 來進行紋理特徵的辨識，分別將賈伯濾波器、NGLDM
以及最小面積橢圓特徵擷取方法所擷取出來的特徵向量輸入 SVMs做分類，最終以這三組分類
器輸出值的強度來判定分類結果，經實驗證明本計畫所提出的方法可獲得令人滿意的分類效能。
第三部分中本研究針對支撐向量機器的訓練過程中須設定的控制參數包含 C與γ提出以
模糊規則為基礎的演算法來設定這兩個參數的數值，在此模式中模糊法則詮釋支撐向量機器參
數與訓練資料間的關係，並以模糊推論機制來調整支撐向量機器的參數值，使得此參數值可依
不同情況進行調整以達到訓練誤差最佳化的狀態。在模糊法則中使用四個語意變數(linguistic
variable)，分別為 Entropy、Mean、Mean of square與類別內外差益比。利用後三個參數來估算
訓練資料中類別內的資料與類別間的資料於空間中分佈的情況以評估分類誤差率以及誤差量，
藉以提供設定 C值得參考。另外則是利用 Entropy與Mean of square來估算類別內資料的分佈
情形以提供設定核心函數參數時的依據。依據以上參數於此部分的計畫中共規畫出十一條模糊
規則分別控制 C值與高斯函數的 sigma值。
最後在本計畫的第四部分提案人針對支撐向量機器面臨多元分類時效率不佳的情況提出
一個新的架構，在此部分中提案人先證明擴充目前的二元分類架構至多元分類架構是可行的，
5亮度相互關係矩陣，Neighboring Gray Level Dependence Matrix (NGLDM)[13, 14]。更高階的統
計量如三階統計量，計算影像空間中多個鄰近具有相同灰階值像元值長度的方法 Gray Level
Run Length Matrix (GLRLM)。
空間頻率法是將影像經由各種轉換法則轉換至頻率域內或其他轉換域 (transform
domain)，透過轉換後影像頻譜的呈現用以辨別紋理的特性，一般較為常見的是利用小波轉換
(wavelet transform)及賈伯濾波器(Gabor filters)在多解析度分析上進行紋理分析。Arivazhagan等
作者使用三種抽取特徵值的方法。第一種方法為小波統計特徵值(wavelet statistical features,
WSF)。第二種方法為小波共生矩陣特徵值(wavelet co-occurrence features, WCF)，即由一階小波
轉換後計算出七項紋理特徵值。第三種方法為結合WSF 及WCF 的特徵值。
Randen與 HusØy整理了一些不同的特徵擷取方法[15]，發現並沒有一種單獨的特徵可以
對所有種類的紋理影像都達到最有效的分類。在目前已發表的論文大多數研究者均以賈伯濾波
器(Gabor filter)為基礎進行旋轉影像的辨識[16, 17]，藉由調整賈伯濾波器中的參數值即可有效
的偵測不同旋轉角度的影像。然而此種方法最大的問題在於事前必須先提供不同角度偵測後所
得到的數據以供學習，因此不僅訓練時間耗時且若所提供的數據不足時辨識率亦不佳。因此在
本計畫中提出最佳面積橢圓分析方法，藉由橢圓可旋轉的特性比對橢圓的長短軸長度以及橢圓
覆蓋區域內的資料，利用此方法於訓練階段時僅需提供未旋轉影像的資料，如此可大幅度降低
訓練時所需時間，此外利用此方法可有效的偵測較細微的旋轉角度，其結果則反映在辨識率上。
在本計畫的第三部分針對支撐向量機器訓練參數的選擇進行探討。目前已發表的論文中
大部分均針對 ,C 與 kernel parameter進行探討[18, 19, 20, 21, 22, 23, 24]。首先 Schölkoph提出
以設定參數來取代的設定，參數代表在-tube範圍外的實驗資料所佔的比例，此方法以
使用者憑經驗自訂為主，此舉方式對於無經驗者造成無所適從。Mattera and Haykin則在 1999
年則提出將設定為 50% [24]，然而在許多的實驗中可輕易的發現此數值並不適用。Kwok和
Smola等人在 2001年提出依據雜訊的程度設定的數值，此種方式的缺點主要在於未考量實驗
資料的數量，理論上實驗資料數量龐大時的數值則相對會較小。
在 C值的設定上Mattera and Haykin在 1999年亦提出 C值與實驗資料的輸出間存在一致
的關係 [24]，此理論僅初步規範了 C值範圍，卻因未考量雜訊值的影響使得應用尚未臻理想。
隨後的研究中部分學者利用 cross-validation 的方式找出這些參數的理想數值，利用
cross-validation 的方式雖然可找出理想數值，然而龐大的時間複雜度以及可能落入局部最佳值
的問題卻也使得此方法在實際應用上有困難。另外有些學者(如 Hastie 等人)針對特定的雜訊類
型達成支撐向量機器訓練參數的最佳化設定，此種方式雖然效果不錯，然基本前提建立在雜訊
類型已事先了解上。
在 2004 年時 Cherkassky 依據訓練資料的輸出值的平均值和標準差來設定 C 值的範圍
[19]，利用訓練資料的數量來設定參數，另外 Huang等人則是利用基因演算法過去相近案例
中找尋這些參數的初值，此兩種方法均可能因個案的不同將導致些微或甚大的差異，此外針對
核心函數的參數部分尚無突破性的研究，因此本研究計畫中提出以模糊理論規範調整其參數數
值並配合基因演算法、PSO演算法以求得最佳效能並加速學習過程。
在支撐向量機器的研究上如何處理多元分類一直是個重要的問題 [25, 26, 27, 28, 29]，目前
的研究包含兩種解決方式。第一種結合許多二元分類器(binary classifier)來處理分類問題，此種
方式包含 one-against-one與 one-against-all等方法 [30, 31, 32]，第二種解決方式則是將所有的分
類器(classifier)問題合成一個最佳化問題 [33, 34, 35]，因此當利用訓練資料學習時僅需考慮一個
7general)，在這兩種法則建立策略中法則的建立方式不同，其刪減的策略亦不相同。
基本理論介紹 - 證據理論(evidence theory)
假設代表 unversal set 且 P()為此集合的 power set。基本機率設定(basic probability
assignment, BPA)可定義為   1,0: Pm ，  0m 且  1A Am 。m(A)代表證據顯示 A為”
真”的程度。若對於同一個觀測對象但以兩個不同的角度取得兩個 BPA 值 1m 與 2m 時，此時可
利用 Dempster-Shafer theory來結合此兩個 BPA值[44]：

 










Aif
Aif
K
CmBm
Am ACB
,0
,
1
21
2,1 (3.1.1)
上式中    CB CmBmK 21 。一般表示法通常將 2,1m 表示為 212,1 mmm  ，當同一個觀測對
象的觀測值變多時可變動為 iKi
K mmmmm 1
21
  。
欲利用 evidence theory從 BPA中推算出最佳解時可利用機率函數 P 來取得：
 

 
AA A
Am
P


,
(3.1.2)
上式中選定適當的θ時即可求得最佳解。
基本理論介紹 -粒子群最佳化演算法（PSO）
粒子群最佳化演算法（Particle Swarm Optimization）為人工智慧領域中的一個新興技術
[45]，屬於軟性計算典範（Soft Computing Paradigm）中演化式演算法（Evolutionary Algorithms）
的一個新分支。最早是由 Kennedy and Eberhart提出來的最佳化推測演算法[46]，其概念乃是模
仿自然界中鳥類搜尋食物的機制而設計出來的演算法。
最佳粒子群演算法建立在群體（Swarm）間協同呼應的組織性運作機制上，演化的過程
中群體的每個粒子（Particle）會不斷地在解的空間（Problem space）內探索，而且本身能記憶
自己在嘗試過程中最好的值，我們稱之為最佳值（Particle best value；pbest），此外，粒子群彼
此之間也能夠傳遞群體中最好的粒子的位置，這種全域最佳粒子我們稱之為群體最佳值（Global
best value；gbest），或是鄰近地區最好的粒子所在位置，這種區域最佳粒子我們稱之為區域最
佳值（Local best value；lbest），最佳粒子群集演算法尋優步驟就是依據 pbest及 gbest（或 lbest）
來決定每個粒子所要探索的方向，藉由尋優步驟使得整體的粒子群集逐漸接近在解空間內的目
標位置，其演算法如下，更新過程圖如圖四所示：
步驟 1、初始化粒子群（Initialization）
依據問題範圍及複雜程度來產生 N個粒子（Particle），每個粒子以隨機亂數的方式設
定 d維度內的 value及 Velocities。
步驟 2、計算 fitness值
將每個粒子透過 fitness function計算得到。
步驟 3、比較粒子最佳值（pbest）
9平面以求得最佳結果，除此之外若能先發掘出支撐向量時亦可藉由支撐向量來建構出。如同圖
三所示，雖然訓練資料數量非常多，然而除了少數的訓練資料可用來建構出支撐平面外，其餘
的訓練資料均扮演著可被忽略的角色。而這些用來建構出支撐平面的訓練資料均為落於支撐平
面上，亦即落於 1bxwT 與 1bxwT 這兩個平面的訓練資料。而這些滿足 Eq. (3.1.4)限制
條件且符合 1)( bxwy iTi 的訓練資料又稱為支撐向量(support vector)。
圖二、支撐向量機器運作模型
此外，圖二中亦顯示出若欲以模糊法則解釋支撐向量機器運作模式時，支撐向量代表著
分類區域的軟性(soft)邊界。理想上每一個分類區域可由一個或一個以上的模糊法則所規範出，
而這也代表著若分類區域的邊界為已知的情況下這些模糊法則可輕易的產生出來。因此本計畫
中第一階段將提出新的支撐向量萃取演算法以便更精確的從訓練資料中直接選取支撐向量。
那如何找出這些支撐向量(support vector)呢？藉由觀察訓練資料於空間的分佈狀況可發
現支撐向量幾乎均分佈於資料叢集(data cluster)的周圍地區，此現象可由圖六中展現。在圖六中
訓練資料以 normal distribution的方式分佈於二維空間中，而圖中 z軸部分所顯示的曲線代表此
處訓練資料集中的密度。而根據 normal distribution的機率分佈，大部分的訓練資料集中在一個
距中心點一個標準差的距離內(由虛線所框起的範圍內)。
11
    
              
       jkkkjiii
j
T
jj
T
kk
T
kj
T
jj
T
ii
T
i
jkji
xxKxxKxxKxxK
xxxxxxxxxxxx
xxxx
,2,,2,
22
22





當核心函數採用 radial-basis function（   



  222
1
exp, jj xxxxK 
）時，假設
22
jkji xxxx  ，代表著    jijk xxKxxK , ，因此可得到
         0,21,2122  jkjijkji xxKxxKxxxx 
因此可得到     22 jkji xxxx   ，這也證明了 radial-basis function為monotonic
核心函數。 □
Lemma 1 證明了 radial-basis function 具有 monotonic 的特性，然而 polynomial function
（    PjTj xxxxK 1, ）並不具有此特性，這部分可藉由代入數值得証，例如當 xi = (2, 2), xj =
(−3,−3), xk = (−5,−5)時即不符合 monotonic的定義。
Theorem 1：在資料空間(data space)內落於資料叢集(data cluster)周圍地區的訓練資料當經過符
合 Lemma 1的映射函數將資料映射至特徵空間(feature space)後，這些訓練資料仍
落在資料叢集的周圍地區。
以上證明了存在一些映射函數使得訓練資料經由此映射函數映射至特徵空間後其相對位置並
不會隨之改變。因此藉由找出叢集中心點和界定叢集周圍區域後可輔助界定出可能為支撐向量
的訓練資料。接下來我們提出支撐向量擷取演算法，此演算法將結合叢集演算法和證據理論
此外，若欲以模糊法則解釋支撐向量機器運作模式時，支撐向量代表著分類區域的軟性
(soft)邊界。理想上每一個分類區域可由一個或一個以上的模糊法則所規範出，而這也代表著若
分類區域的邊界為已知的情況下這些模糊法則可輕易的產生出來。
[模糊規則萃取演算法]
第一階段：結合證據理論與叢集演算法進行支撐向量的擷取
-----支撐向量擷取演算法----
在這演算法中   Liii yx 1, 代表訓練資料，其中  0,1iy 。 1iC 及 0jC 分別代表叢集化(data
clustering)後分類 1的第 i個叢集及分類 0的第 j個叢集，S為支撐向量的集合，Cc為叢集中心
點的集合。
步驟一、設定叢集密度後利用減法叢集法(subtractive clustering)對訓練資料進行分類
[57]，假定分類後隸屬分類 1與分類 0的叢集各為 m與 n個，並將所有的從及中
心點加入 Cc中。
步驟二、設定 k的數值（建議值為 1），針對每個叢集移除距離叢集中心點 k個標準差範圍
13
步驟二、利用步驟一所產生的超矩形區域檢視 iA 內其餘的資料，可被此超矩形區域涵蓋的
訓練資料則移除。
步驟三、重複步驟一與步驟二，直至 iA 中所有的資料均已移除；若有訓練資料未移除者將
此訓練資料加入集合 Di中並從新定義此超矩形範圍。
步驟四、針對所有叢集的資料均進行步驟一至步驟三。
步驟五、針對每個 Di中的資料設定其  xsigm , 或  xgaus ,, 函數，若 Di所代表的超矩
形區域包含叢集中心點時設定  xgaus ,, ，若 Di所代表的超矩形區域未包含叢
集中心點時設定  xsigm , 函數。
集合 Di中的每一筆資料分別代表一個超矩形區域，R(‧)代表計算體積的函數。
----模糊法則調整演算法----
步驟一、以法則產生演算法所產生的資料當成初始化粒子群（Initialization）。
步驟二、以 )(
iC
H 為 fitness 的值，其中為資料分類錯誤率， )(
iC
H 為涵蓋此分類
Ci內資料數量。
步驟三、比較粒子最佳值（pbest）。比較粒子與在演化過程中最好的解，如果目前的值比
之前的值來得好，則設定目前的狀態為 pbest。
步驟四、比較群體最佳值（gbest）。比較粒子與群體中最好的解，如果目前的值比群體中
最佳值來的好，則設定目前的狀態為 gbest。
步驟五、調整每個法則中  xsigm , 或  xgaus ,, 函數中的參數。
步驟六、如果經由 fitness未得到理想值或是還沒有到達演化限制數，則重覆步驟三。
3.2利用支撐向量機器改善紋理(texture)辨識效能
在紋理影像分類的問題上，紋理影像在經過旋轉、放大或是縮小時，雖然影像仍是相近
似，但內容的組成與成分的比例已有相當程度的變化。作為紋理影像分類依據的特徵，應具備
有在經過這些改變後，仍然能夠擷取到相近似特徵值的能力。紋理影像的內容千變萬化，有許
多研究提出了一些不同方式來計算影像中的特徵，Randen 與 HusØy 整理了一些不同的特徵擷
取方法，發現並沒有一種單獨的特徵可以對所有種類的紋理影像都達到最有效的分類。所以，
近年來的一些研究趨向於結合不同的影像特徵，利用多維度的特徵空間來分類影像，藉由數種
特徵值間的互補作用，達成更好的分類結果。
有鑑於至目前為止對於紋理影像在影像旋轉以及位移的處理上學者們所提出的演算法人
有相當大的改進空間，因此本計畫中將提出一個新的演算法以改善經過旋轉以及位移後的紋理
影像的辨識能力。本計畫中所提出之演算法利用三種不同的紋理特徵擷取方法以達到互補的作
用。第一種特徵擷取方法以空間頻率方法中的賈伯濾波器(Gabor filters)在空間頻率域的不同位
置來求得該空間頻率域內是否存在主要的紋理成份，因為如果賈柏濾波器觀察到了主要紋理成
份，其輸出響應將會比沒有觀察到主要紋理成份的濾波器輸出響應來的大，而我們便可以藉此
特性來區分出紋理影像中主要的紋理成份。第二種特徵擷取方法以二維統計方法取得紋理影像
之鄰近灰階相依矩陣(Neighboring Grey Level Dependence Matrix，NGLDM)，經由計算 NGLDM
矩陣得到影像特徵向量，比較起 NGLDM，另一種直接取得紋理空間特性的灰階共生矩陣
15
圖四、賈伯濾波器在空間域與頻率域的分佈圖，其中 2F  ， 0    ，45，90，135
由上面公式推導可知 ( , )F 的值由 ( , )U V 決定，但在頻率域中，不只有 ( , )F 兩個變數而
已，仍有兩個重要變數需定義，分別是頻率頻寬B和方向頻寬， ( , )B  決定了賈柏濾波器在
頻率域觀察範圍的大小，而這兩個變數和高斯空間域 ( , )x y 方向的標準差有絕對的關係，其關係
式如下
ln 2(2 1)
2 (2 1)
B
x BF




(3.2.6)
ln 2
2 tan( / 2)y F




(3.2.7)
其中B：頻率頻寬
：方向頻寬
F：濾波器中心頻率
x：空間域中高斯函數 x方向的標準偏差值
y：空間域中高斯函數 y方向的標準偏差值
由上面的介紹可以了解賈柏濾波器在空間頻率域的特性，可以藉由改變賈柏濾波器在空間頻率
域的位置來求得該空間頻率域內是否有主要的紋理成分存在，如果賈柏濾波器觀察到了主要的
紋理成分，其輸出響應會比沒有觀察到主要紋理成分的賈柏濾波器來的大，而我們可以藉此特
性，來區分出紋理影像中主要的紋理成份。
基本理論介紹 -鄰近灰階相依矩陣(Neighboring Gray Level Dependence Matrix, NGLDM)
鄰近灰階相依矩陣是取得像素間亮度關係，針對每一個像素，統計其鄰近，固定距離外
與該像素具有相同亮度的像素數量。產生 NGLDM主要步驟如下：
（1） 輸入一張如圖五之紋理影像，當距離參數 1d 時，紋理檢測範圍是受檢測像素為中
心向外延伸一個像素距離的方形區域，如圖五的虛線框，因此 4 4 的影像實際受檢像素只
有中心亮度為 4、1、1、5 四個像素。
（2）計算受檢測像素亮度與鄰近周圍像素亮度相同的數量，以圖五中央像素亮度為 4的像
素為例，鄰近像素亮度與其相同者有 2 個，可以記為 (4,2)。完成檢測四個像素後，可以得
到集合 (4,2), (1,2), (1,3), (5,0) 。
17
正規化因子是共生矩陣內所有數值的總和。NGLDM 矩陣Q是大小為 256 9 的陣列，參數
K是像素的灰階範圍，參數 S是與中心像素灰階值相同的周邊像素之個數。
[最小面積橢圓分析方法]
雖然 NGLDM對於影像旋轉的敏感度較低，但是經過實驗驗證，NGLDM對於結構性紋
理影像旋轉的問題不如預期的效能，此外，如圖七所示，紋理影像(花)在經過位移之後，經由
NGLDM 所擷取出來的特徵值也會跟原始影像的特徵值不一樣，進而造成分類率的降低，所以
本論文提出基於最小面積橢圓旋轉不變的概念應用於上述問題。
圖七、紋理影像(花)位移例子
紋理影像經過二值化轉換後，利用叢集演算法(clustering algorithm)分別對黑色像素(black
pixel)與白色像素(white pixel)影像找出叢集點(cluster points)，再透過本計畫自訂的演算法找出具
代表性的特徵點，最後找出最小面積橢圓來含括這些特徵點。
(一)叢集演算法
紋理影像經過二值化後，分別以黑色像素及白色像素當作資料點，利用叢集演算法找出
叢集中心點，結果如圖八所示。本論文使用的叢集演算法是由 Chiu 所提出的減法叢集法
(subtractive clustering)。主要概念是將所有資料點視為潛在中心點，並根據其周圍的資料點密度
作為選取叢集中心點的標準。
首先選取周圍資料點密度最高的點為叢集中心點，也就是在資料點最密集之處選取最具
代表性的點為叢集中心點；接著排除該叢集中心點附近的資料點被選為叢集中心點的可能性，
也就是修正周圍資料點密度的計算方式後，再選取下一個叢集中心點；繼續採用類似程序選擇
下一個叢集中心點，直到達到終止條件為止。
此叢集中心點選取概念與山形叢集法(mountain clustering)相似，但將所有資料點視為潛
在叢集中心點，所以此叢集法的計算量與系統維度的複雜性無關，僅與資料筆數多寡成正比。
減法叢集演算法：
Step1：考慮在 M 維的空間中有 N 組資料，並假設該資料皆已正規化(normalize)；將計算資
料點周圍的資料點密度定義為密度量度(density measure)：
2
21
exp
( / 2)
N
i j
i
j
a
X X
D
r
     
 (3.2.14)
半徑 ar 指中心點附近的距離，設定為常數且大於零。
19
 | ( ) ( ) 1n T n nx R x c E x c c R E S       ， 、 (3.2.16)
橢圓的面積可表示為
1
10 2
0( ) det( )det( )
v
Vol v E
E
   (3.2.17)
0v 為在維度n中單位超球面的面積，透過改變一些變數，原本橢圓公式可定義為
  1/ 22| 1nx R Ax b b E c    1/2，A=E 、 (3.2.18)
而最小面積橢圓的最佳化問題可定義為
,min A b 1log det( )A
subject to
1 1, ,
0
Ax b i m
A
   

(3.2.19)
式(3.2.18)中限制式 1Ax b 可表示為
0
( ) 1
i
T
i
I Ax b
Ax b
   
(3.2.20)
因此(3.2.20)為一個凸面最佳化問題，此最佳化問題可利用 Lagrangian function轉換成對偶問題
(dual problem)，再利用梯度上升法(gradient ascent method)找出最佳解。
最小面積橢圓找尋結果如圖十所示。
(a) (b)
圖十、 最小面積橢圓找尋結果(a)原始影像 (b)旋轉後
在特徵值擷取方面，如果只使用橢圓的長寬來做判別，有可能會出現兩張不一樣的紋理
影像所擷取出來的橢圓長寬卻非常相似的情形，所以本計畫除了擷取橢圓的長寬之外，另外針
對橢圓內的像素灰階值使用統計的方法計算出平均值和標準差。
[紋理分類-混合型濾波器]
本計畫中最終所使用的濾波器為結合三種不同特質的混合型濾波器。第一種特徵擷取方
法是以賈伯濾波器將影像轉換到空間頻率域中，藉由改變賈柏濾波器在空間頻率域的位置來求
得紋理影像在該空間頻率域內的紋理特徵值，第二種特徵擷取方法是以 NGLDM 紋理分析方法
在空間域中計算紋理特徵值，第三種特徵擷取方法是以最小面積橢圓旋轉不變的概念，先找出
影像中具代表性的數個特徵點，以最小面積橢圓含括這些特徵點，最終利用橢圓長寬及統計橢
圓內灰階值的平均值和標準差來當作資料的特徵值，在辨識階段，分別利用三組 ESVMs 進行
21
量機器模組均以訓練完成時將產生 k個決定函數(decision functions)
  
  
   kTk
T
T
bxw
bxw
bxw







22
11
(3.3.2)
在此情形下若欲決定 x屬於哪一個類別則藉由下列方程式判斷
class of    iTi
ki
bxwx 


,,2,1
maxarg

(3.3.3)
除了 one-against-all外另一個常見的方法為 one-against-one，在 one-against-one架構下若欲
分類成 k個類別時則須建構出
 
2
1kk
個支撐向量機器模組，每次訓練資料時則取兩個類別的資
料進行訓練，因此若訓練的資料為第 i 個和第 j 個個類別的資料時，此時的支撐向量機器可定
義為
   
t
Tjiji
t
jiTji
bw
wCww
ijijij

 2
1
min
,,
(3.3.4)
   jitjitTji bxw   1 , if yt=i
   jitjitTji bxw   1 , if yt≠i
0jit 。
上述 one-against-all及 one-against-one均屬第一種解決方式，在第二種解決方式中 Weston
提出一個類似 one-against-all的方法。在Weston的方法中將所有 k個決定函數(decision function)
合併在一個最佳化問題內，而其最佳化問題如下：
  mimiTmy
L
i ym
i
T
y
m
i
k
m
m
T
mbw
bxwbxwCww
i
i
i


 
 
2
2
1
min
11
,,
(3.3.5)
0mi , i=1, 2,…, L,   iykm \,,2,1 
藉由下列方程式判斷 x屬於哪一個類別
class of  mTmkm bxwx   ,,2,1maxarg  (3.3.6)
[快速多類別支撐向量機器]
支撐向量機器的目標為找到一個最佳分割平面(optimal separating hyperplane) 0bxwT
使得此分割平面可以將所有的訓練資料完美的分類，在此情況下每個訓練資料滿足下列條件：
23
值即可得知此實驗資料屬於哪一個分類。
本計畫中以上述架構為主，藉由將訓練資料映射至特徵空間中達到區隔不同類型的訓練
資料的效果。針對 n類的訓練資料，經過映射至特徵空間後，從特徵空間找出一組平行的分割
平面  1bxwT 、  2bxwT …  1 nbxwT 使得這些分割平面可區隔不同類別的資
料。當欲辨識資料屬於哪一分類時僅需判斷  bxwT  的數值為何，即可得知此資料屬於哪一
分類。在此架構下僅需訓練一組參數，可大幅減少訓練實其所花費的時間，而進行辨識時也僅
需測試一組參數後即可得知屬於哪一分類。
在以上的敘述中已敘述本計畫中所提出的快速多類別支撐向量機器的概念，基本上訓練
資料經過映射函數映射至特徵空間後其資料分佈可能與資料空間中不同，因此是否存在至少一
個映射函數使的訓練資料經過此映射函數映射至特徵空間後其資料可被  1bxwT 、
 2bxwT …  1 nbxwT 這樣一組的分割平面完美分類。以下的定理將證明至少存在
一個以上的映射函數具有此種映射的特性。
Lemma 3.3.1：至少存在一個映射函數  使得訓練資料   Niii yx 1, ，  myi ,,2,1  經由此映射
函數映射至特徵空間後可找到一組參數使得訓練資料可被  1bxwT 、
 2bxwT …  1 mbxwT 這 m-1個平行的分割平面完美分類。
Proof：假設不存在任何的映射函數  使得訓練資料經由此映射函數映射至特徵空間後可找到
一組參數使得訓練資料可被  1bxwT 、  2bxwT …  1 mbxwT 這 m-1個
平行的分割平面完美分類。
假設訓練資料為   Niii yx 1, ，  myi ,,2,1  ，  NxxxX ,,, 21  ，令 jxˆ 代表屬於第 j 類
訓練資料所成的集合， 
m
j
jxX
1
ˆ

 ， jj xXx ˆ 。今若訓練資料可被分類，則代表訓
練 資 料 gxˆ 與 gx中 存 在 一 個 映 射 函 數 g 使 得   0ˆ  ggsgTg bxw  與
  1 ggsgTg bxw  ，其中 gsxˆ 表第 j類訓練資料中的第 s個資料。因此 1xˆ 與 1x中存在映
射函數 1 使得  0ˆ 1111 bxw sT 與   11111  bxw sT ， 2xˆ 與 1x中存在映射函數 2 使
得   0ˆ 2222 bxw sT 與   12222  bxw sT ，餘此類推。
令  ])(,1),(,,)(,1),(,)(,1),([ˆ 111122221111   mmTmmTT bwbwbw   ，
]5.0,,,,5.1,,,5.0,,[ˆ 1
1
2
2
1
1   mbwbwbww mm ，可發現
25
假設訓練資料為   Niii yx 1, ，  myi ,,2,1  ，  NxxxX ,,, 21  ，令 jxˆ 代表屬於第 j類訓
練資料所成的集合， 
m
j
jxX
1
ˆ

 ， jj xXx ˆ ， )(f 函數代表類別資料經映射至特徵空間
後輸出的類別代號。
1. 將每一個類別當成一個叢集，計算每一類別的叢集的中心點，並以 jC 代表第 j 類叢集
的中心點，  mj ,,2,1 
2. 計算每個叢集中心點與其他所有叢集中心點的距離，以 jd 代表第 j類叢集的中心點與其
他所有叢集點的距離總和
3. 從所有 jd ，  mj ,,2,1  中找出最小的 sd ，將 )(sf 定為 0
4. 重新計算每個叢集中心點至第 s個叢集中心點的距離，並依距離數值由小至大進行排序
5. 設定 i=1,j=1,k=-1針對步驟四的排序結果，從 i=1開始，選取第 i個最小距離的類別，
將其 )(f 定為 j，並將 i,j均增加 1。
6. 選取第 i 個最小距離的類別，計算此類別與 1)(  jf 這類別叢集中心點的距離是否超
過與第 s個叢集中心點的距離，若是的話將其 )(f 定為 k，並將 i增加 1，k減少 1；若
否的話將其 )(f 定為 j，並將 i,j均增加 1。
7. 重複執行步驟六直至所有類別均已處理完。
在以上的演算法中訓練資料於特徵空間的類別歸屬值已初步訂出，此初始值是否理想可
藉由支撐向量機器進行訓練階段時由訓練誤差值來判斷是否該更改類別歸屬值。為了解決如何
更改類別歸屬值的問題，在此學習階段我們使用基因演算法來改變類別歸屬值以獲得較佳結
果。基因演算法的流程圖如圖十四。
27
正的動作。
3.4利用利用模糊理論控制支撐向量機器訓練時的參數數值
在本計畫中提案人將利用模糊法則來詮釋支撐向量機器參數與訓練資料間的關係，並以
模糊推論機制來調整支撐向量機器的參數值，使得此參數值可依不同情況進行調整以達到訓練
誤差最佳化的狀態。首先列出此模糊法則將使用之語意變數(linguistic variable)。
語意變數
針對此系統提出四個語意變數（1）亂度 Entropy；（2）平均值Mean；（3）Mean of Square，
簡稱 MS；(4)類別內外差益比，簡稱 DIO。這四個不同的語意變數分別代表訓練資料間的關係
與特性，其與支撐向量機器的參數值間的關係陳述如下。
對於支撐向量機器最佳化問題中的 C值，主要利用第二種語意變數平均值、第三種語意
變數越零率與第四個類別內外差益比來控制。首先 C值的大小主要用以調節訓練誤差與分隔區
域大小的比例。訓練誤差與分隔區域的大小一般呈現反比的傾向。而分隔區域的大小則影響測
試資料的正確性，亦可說是影響錯誤分類的容忍度。當 C值越大時代表著重於降低訓練誤差的
大小，反之則代表著重於分隔區域的大小。
基本上，藉由訓練資料的空間分佈可初步估計訓練時的訓練誤差量。若對訓練資料進行
叢集化分類後，類別內資料密集度、類別內部涵蓋範圍與類別間距的數值可用以判斷於訓練階
段時訓練資料所造成的誤差量。一般而言，當類別內的資料密集度相當高時訓練資料的分類率
亦較高，其資料誤差值相對較小；反之資料密集度較低時較易呈現出分類率較低，資料誤差數
值較大的情形。除了資料密集度外，資料平均值的大小亦會些微影響誤差值的數值。當資料數
值平均較大時，在相同數量的訓練資料產生誤差時平均值較大的誤差量亦相對會大一些。在以
上兩個參數中，資料密集度僅能反映類別資料分散情形，無法偵測類別間資料分佈情況，藉由
類別與類別間的邊界部分的資料分佈狀態幾乎可直接判斷分類誤差的數量或比例，若不同類別
的資料在邊界間呈現完整分隔的情形，則訓練時的誤差必相當小，反之若邊界間的資料呈現交
錯混雜的情形其誤差必相對大。為分辨此種情形在此計畫中提案人加入類別內外差益比來偵測
此情況。
類別內外差益比的定義如下：
假設訓練資料為   Niii yx 1, ，  myi ,,2,1  ，  NxxxX ,,, 21  ，令 jx 代表所有屬於第 j
類訓練資料的平均值(亦可視為類別中心點)，以此類別中心點為圓心，計算 Rj的數值使得在 Rj
範圍內包含 75%的類別資料，利用 Rj與 Rk計算類別內外差益比
kkj
j
jk Rmm
R
CIO

 。
另外在控制核心函數的部分本計畫中使用 Entropy 來估算核心函數中使用的參數，此處
參數指的是高斯函數中的σ值。若訓練資料的差異性足夠大時經過一般的高斯函數轉後後亦可
表現出其差異性。然而當訓練資料間的差異性並不大時，為了增進資料間的差異性，因此可藉
由控制高斯函數中的σ值使得訓練資料間的差異變大，因此利用 Entropy 來估算訓練資料間的
差異性可提供判斷σ值設定的依據。然此處需特別注意的是 over-fit與 under-fit這兩種情況的避
免。
29
因此僅有分佈於邊緣地帶的訓練資料可能會造成分類誤差，此類型的資料所造成的分類誤差
量雖不大亦不會太小，因此建議 C值的設定為一般偏大的數值。
第五條：
If DIO = Low and MS = High and Mean = Low then C = Mid Low
此條規則適用情況同第四條規則，但因資料的平均值較小因此此類型的資料所造成的分
類誤差量較第五條規則小，因此建議 C值的設定為一般偏小的數值。
第六條：
If DIO = Low and MS = Low and Mean = High then C = Mid Low
此條規則適用於當類別資料分佈狀態集中在類別中心點附近，MS 的數值低代表大部分
的資料集中在中心點附近，僅由為數極少的資料分佈在邊緣地區，因類別與類別間的距離相
對較遠，在加上資料的平均值較高，因此分佈於邊緣地帶的訓練資料所造成分類誤差可能不
會太小，因此建議 C值的設定為一般偏小的數值。
第七條：
If DIO = Low and MS = Low and Mean = Low then C = Low
此條規則適用於當類別資料分佈狀態集中在類別中心點附近，MS 的數值低代表大部分
的資料集中在中心點附近，僅由為數極少的資料分佈在邊緣地區，因類別與類別間的距離相
對較遠，在加上資料的平均值較低，因此分佈於邊緣地帶的訓練資料所造成分類誤差可能相
當低，因此建議 C值的設定較低。
第八條：
If Entropy = High and MS = High then sigma = High
此條規則適用於類別資料分佈狀態很混亂時，MS的數值大且 Entropy的數值大代表著資
料混雜分散在空間的各個地方，在這種情況下高斯函數涵蓋的範圍若過大時將造成核心函數
數值過於接近以致資料無法辨識，因此此狀況 sigma的值適用高數值。
第九條：
If Entropy = High and MS = Low then sigma = Mid
此條規則適用於類別資料分佈狀態混亂程度不是很高，大部分資料集中於類別中心點附
近，MS 的數值低代表大部分的資料集中在中心點附近，僅由為數不多的資料分佈在邊緣地
區，此種情形受到部分偏離的資料的影響，建議 sigma值的設定適用一般值。
第十條：
If Entropy = Low and MS = High then sigma = Mid
此條規則適用於當類別資料均勻分布在空間的各個地方，MS 的高數值代表資料均勻分
散或部分資料遠離中心點其餘聚集於中心點附近，而由 Entropy 的低數值可排除部分資料遠
離中心點這狀況。因資料均勻分配於各區域，為保持資料經核心函數後的辨識程度，因此建
議 sigma值的設定適用一般值。
第十一條：
If Entropy = Low and MS = Low then sigma = Low
此條規則適用於當類別資料分佈狀態集中在類別中心點附近，在此種情況下不同類別間
的距離或差異性極大，因此即使使用涵蓋範圍較大的高斯函數仍舊可保持差異性，但若 sigma
的數值採用高數值的話則容易造成 over-fit的情況發生，因此建議 sigma值的設定較低。
31
表二、法則擷取比較
演算法 Accuracy Number of rules
CART 95.22% 3.2
C 4.5 94.96% 7.0
Ripper 95.48% 4.3
TREPAN 94.30% 4.7
Minerva 94.52% 4.2
Our proposed method 95.23% 4.1
從表二中可看出利用我們所提出的演算法可有效的降低法則數量且能兼顧分類正確率。
計畫中第二部分所使用的紋理實驗資料庫為 Brodatz 紋理資料庫中的 25種紋理影像，如
圖十五所示，原始影像大小為512 512 。
訓練資料：
將原始影像512 512 平均切割成128 128 (16張)的影像，總訓練影像共有16 25 400  張。
測試資料：
將原始影像512 512 從10 ~ 90 每隔10做旋轉，每種角度隨機取出五張128 128 的影像，總
測試影像數量9 5 25 1125  。
圖十五 Brodatz textures中的 25種紋理影像(D1, D4, D5, D6, D9, D11, D16, D17, D18,
D20, D21, D26, D29, D32, D34, D47,D57, D64, D65, D77, D82, D83, D84, D101, D102)
實驗結果如表三所示，可以很明顯的看出紋理影像旋轉對於分類效能會產生很大的影響，不同
的特徵擷取方法可以克服不同紋理影像旋轉的問題，基於這特性，所以本計畫將不同的特徵擷
取方法做結合，以達到特徵值互補的作用。本計畫所提出的方法對於紋理影像旋轉的問題，仍
舊能達到不錯的分類效能。
表三、結合三種不同特徵擷取方法的分類效能
Gabor NGLDM+SVMs Ellipse+SVMs Hybrid rotated
33
三、參考文獻
[1] H.Huysmans, R. Setiono, B. Baesens and J.Vanthienen, “Minerva: sequential covering for fule
extraction,”IEEE Trans. on Systems, Man, and Cybernetics –Part B: Cybernetics, vol. 38, no. 2,
2008, pp 299-309.
[2] J. L. Castro, L. D. Flores-Hidalgo, C. J. Mantas and J. M. Puche, “Extraction of fuzzy rules from
support vector machines,”Fuzzy Sets and Systems, vol. 158, 2007, pp. 2057-2077.
[3] R. Andrews, J. Diederich, and A.B. Tickle, “A survey and critique of techniques for extracting rules
from trained artificial neural networks,” Knowledge Based Systems, vol. 8, 1995, pp. 373-389.
[4] H. Núñez, C. Angulo, and A. Catala, “Rule-extraction from support vector machines,” Proc.
European Symp. Artificial Neural Networks, 2002, pp. 107-112.
[5] Y. Zhang, H. Su, T. Jia, and J. Chu, “Rule extraction from trained support vector machines,” Proc.
Ninth Pacific-Asia Conf. Advances in Knowledge Discovery and Data Mining, 2005, pp. 61-70.
[6] X. Fu, C. Ongt, S. Keerthit, G. Hung, and L. Goh, “Extracting the knowledge embedded in support 
vector machines,” Proc. IEEEInt’l Conf. Neural Networks, 2004, pp. 291-296.
[7] N. Dasguptaand L. Carin, “Texture analysis with variational Hidden Markov trees,” IEEE Trans. on
Signal Processing, vol. 54, no. 6, 2006, pp. 2352-2356.
[8] Y. –W. Shou and C. –T. Lin, “Image descreening by GA-CNN-Based texture classification,” IEEE
Trans. on Circuits and Systems–I: Regular Papers, vol. 51, no. 11, 2004, pp. 2287-2299.
[9] X. Liu and D. Wang, “Texture classification using spectral histograms,” IEEE Trans. on Image
Processing, vol. 12, no. 6, 2003, pp. 661-670.
[10] M. Nagao, H. Tanabe and K. Ito, “Agricultural land use classification of aerial photographs by 
histogram similarity method,” In Proc. 3rd int. Joint Conf. Pattern Recognition, 1976, pp.669-672.
[11] G. Fan and X. –G. Xia, “Wavelet-based texture analysis and synthesis using Hidden Markov
models,” IEEE Trans. on Circuits and Systems –I: Fundamental Theory and Applications, vol. 50,
no. 1, 2003, pp. 106-120.
[12] R. Chelappa and R. L. Kashyap, “Texture synthesis using 2-D noncausal autoregressive models,” 
IEEE Trans. Acoust., Speech, Signal Process, vol. 33, no. 1, 2003, pp. 194–203.
[13] C. Sun and W. G. Wee, “Neighboring Gray Level Dependence Matrix for Texture Classification,” 
Computer Vision, Graphics and Image Processing, 1982, Vol. 23, pp. 341-352.
[14] R. M. Haralick, K. Shanmugam and I. Dinsten, “Texture feature for image classification,” IEEE
Transactions on System, Man and Cybernetics, 1973, Vol. 3, No. 6, pp. 610-621.
[15] T. Randan and J. H. HusØy, “Filtering for texture classification: A comparative study,” IEEE
Transactions on Pattern Analysis and Machine Intelligence, 1999, Vol. 21, No.4, pp. 291-310.
[16] D. Liu, K. M. Lam and L. S. Shen, “Optimal sampling of Gabor features for face recognition,” 
Pattern Recognition Lett., vol. 25, no. 2, 2004, pp. 267-276.
[17] W. -P. Choi, S. -H. Tse, K. -W. Wong and K. -M. Lam, “Simplified Gabor wavelets for human face
recognition,” Patern Recognition, vol. 25,2008, pp. 1186-1199.
[18] O. Chapple and V. Vapnik, “Model selection for support vector machines,”Advances in Neural
35
[36]J. Weston and C. Watkins, “Multi-class support vector machines,” presentedat the Proc. ESANN99,
M. Verleysen, Ed., Brussels, Belgium, 1999.
[37] C. -C. Chang, C. -W. Hsu and C. -J. Lin, “The analysis of decomposition methods for support vector
machines,” IEEE Trans. on Neural Networks, vol. 11, no. 4, 2000, pp. 1003-1008.
[38] C. -W. Hsu and C. -J. Lin, “A simple decomposition method for supportvector machines,” Machine
Learning, vol. 46, 2002, pp. 291–314.
[39]T. Joachims, “Making large-scale SVM learning practical,” in Advances in Kernel Methods-Support
Vector Learning, B. Schölkopf, C. J. C. Burges and A. J. Smola (Eds.), MIT Press, Cambridge, MA,
1998.
[40] J. C. Plat, “Fast training of support vector machines using sequential minimal optimization,” in 
Advances in Kernel Methods-Support Vector Learning, B. Schölkopf, C. J. C. Burges and A. J. Smola
(Eds.), MIT Press, Cambridge, MA, 1998.
[41] C. Saunders, M. O. Stitson, J. Weston, L. Bottou, B. Schölkopf, and A. Smola, “Support Vector 
Machine Reference Manual,” Univ. London,London, U.K., Tech. Rep. CSD-TR-98-03, 1998.
[42] N. H. Barakat and A. P. Bradley, “Rule extraction from support vector machines: a sequential
covering approach,” IEEE Trans. on Knowledge and Date Engineering, vol.. 19, no. 6, 2007, pp.
729–741.
[43] J. Huysmans, R. Setiono, B. Baesens, and J. Vanthienen, “Minerva: sequential covering for rule
extraction,” IEEE Trans on Systems, Man, and Cybernetics-Part B: Cybernetics, vol. 38, no. 2, 2008,
pp. 299-309.
[44] A. Laha, N. R. Pal and J. Das, “Land cover classification using fuzzy rules and aggregation of
contextual information through evidence theory,”IEEE Trans. on Geoscience and Remote Sensing,
vol. 44, no. 6, 2006, pp. 1633-1641.
[45] R. A. Krohling and L. d. S. Coelho, “Coevolutionary particle swarm optimization using gaussian
distribution for solving constrained optimization problems,”IEEE Trans on Systems, Man, and
Cybernetics-Part B: Cybernetics, vol. 36, no. 6, 2006, pp. 1407-1416.
[46] J. Kennedy and R. Eberhart, “Particle swarm optimization,” In Proceedings of IEEE International
Conference on Neural Networks, pages 1942-1948, IEEE Press, Piscataway, NJ, 1995.
[47] S. L. Chiu, “A Cluster Estimation Method with Extension to Fuzzy Model Identification,” Proc.
IEEE Internat. Conf. on Fuzzy Systems, 1994, Vol. 2, No.3, pp. 1240-1245.
[48] ----, “Ultraconservative Online Algorithms for Multiclass Problems,”School Comput. Sci. Eng.,
Hebrew Univ., Tech. Rep., 2001.
1
出席國際學術會議心得報告
第一年 (2010年)
計畫編號 NSC 98－2221－E－324－023－MY2
計畫名稱 提升支撐向量機器之規則建構技術、模型建構效率以及多類別之分類效能
出國人員姓名
服務機關及職稱
姚志佳
朝陽科技大學資訊工程系 助理教授
會議時間地點
日本
March 23-26, 2010
會議名稱 2010 International Conference on Computational Science and Applications(ICCSA 2010)
發表論文題目 C. –C Yao and M. -H. Tsai, “Adaptive fuzzy filter for speech enhancement”, ICCSA 2010, LNCS 6018, part 3, pp. 511-525, Springer-Verlag, 2010. (EI)
一、參加會議經過
本人於三月二十二日至三月二十六日出席於日本九州產業大學所舉辦的 2010
International Conference on Computational Science and Applications (ICCSA 2010)，這是第
十屆舉辦此會議, 過去之舉辦歷史如 Sowon, Korea (2009), Perugia, Italy (2008), Kuala
Lumpur, Malaysia (2007), Glasgow, UK (2006), Singapore (2005), Assisi, Italy (2004),
Montreal, Canada (2003), and (as ICCS) Amsterdam, The Netherlands (2002) and San
Francisco, USA (2001)。 本次會議參與的人數接近 500 人，個人並於會中發表一篇論文。
ICCSA 主要是針對計算科學在不同領域上的應用 , 其中包括五大領域
Computational Methods, Algorithms and Scientific Application、 High Performance
Computing and Networks、 Graphics and Visualization、Emerging Applications、Information
Systems and Technologies。這個會議在資訊與通訊技術應用提供一個完整且廣泛的研究。
而其會議論文集 Proceedings of the ICCSA2010 是由 The proceedings of the conference is
published by Lecture Notes in Computer Science (edited by Springer).
今年大會於日本九州產業大學舉行，為期 4 天(3 月 23 日~3 月 26 日)。與會者來自
3
舉辦十屆,而且每屆的論文集皆由Springer 所出版,內容水準相當整齊。本人非常感謝國
科會計畫此次可以補助本人赴會並與國際相關學者討論與建立關係。
四、 攜回資料名稱及內容
本人攜回 Proceedings of the ICCSA2010 國際會議論文集，內容包含與會發表之論
文。會議論文集是由是由 Lecture Notes in Computer Science (edited by Springer, LNCS
6018) 所出版。
五、 出席國際會議發表論文
C.–C Yao and M. -H. Tsai, “Adaptive fuzzy filter for speech enhancement”, ICCSA 2010,
LNCS 6018, part 3, pp. 511-525, Springer-Verlag, 2010. (EI)
六、論文摘要
5
第二年 (2011年)
計畫編號 NSC 98－2221－E－324－023－MY2
計畫名稱 提升支撐向量機器之規則建構技術、模型建構效率以及多類別之分類效能
出國人員姓名
服務機關及職稱
姚志佳
朝陽科技大學資訊工程系 助理教授
會議時間地點
韓國
June 21-23, 2011
會議名稱 7th International Conference on Networked Computing and AdvancedInformation Management (NCM 2011)
發表論文題目
Chih-Chia Yao, “Adaptive microphone array-based filter in the speech
enhancement”, 7th International Conference on Networked Computing and
Advanced Information Management (NCM2011), Korea, June 21-23, pp.
232-236 2011. (EI)
一、參加會議經過
個人於六月二十一日至三月二十三日出席於韓國慶州希爾頓飯店所舉辦的 7th
International Conference on Networked Computing and Advanced Information Management
(NCM2011)，這是第七屆舉辦此會議, 過去之舉辦歷史皆在韓國各個地方舉辦。 本次會
議與 The 2nd International Conference on Next Generation Information Technology 共同舉
辦，參與的人數接近 300 人。個人並於會中發表一篇論文, 題目為 Adaptive microphone
array-based filter in the speech enhancement。
International Conference on Networked Computing and Advanced Information
Management 主要是針對 Theory, Development, Applications, Experiences and Evaluation of
Networked/Ubiquitous Computing and Advanced Information Management.。這個會議在資訊
與通訊技術應用管理上提供一個完整且廣泛的研究。而其會議論文集 Proceedings of 7th
International Conference on Networked Computing and Advanced Information Management
國際會議論文集，內容包含與會發表之論文。會議論文集是由是由 IEEE press 所出版並
7
求其在五年內能進入相關 Abstract 及 indexing (如 EI, SCI), 他們現在非常積極的爭
取舉辦國際會議也開始擴大出版國際期刊,並且一直希望建立國際合作的積極態度留下
非常深刻的印象,雖然韓國不論在資訊電子領域是我們的競爭對手，他們也開始在學術上
奮力向前。
三、建議
International Conference on Networked Computing and Advanced Information
Management 自從 2005 年來已經舉辦七屆, 而且每屆的論文集皆由 IEEE 出版,內容水準
相當整齊。本人非常感謝國科會計畫此次可以補助本人赴會並與國際相關學者討論與建
立關係。
四、攜回資料名稱及內容
本人攜回 Proceedings of 7th International Conference on Networked Computing and
Advanced Information Management 國際會議論文集，內容包含與會發表之論文。會議論
文集是由是由 IEEE press 所出版並被包括在 IEEE eXplore 電子資料庫。
五、出席國際會議發表論文
Chih-Chia Yao, “Adaptive microphone array-based filter in the speech enhancement”, 7th
International Conference on Networked Computing and Advanced Information Management
(NCM2011), Korea, June 21-23, pp. 232-236 2011. (EI)
六、論文摘要
國科會補助計畫衍生研發成果推廣資料表
日期:2011/10/30
國科會補助計畫
計畫名稱: 提升支撐向量機器之規則建構技術、模型建構效率以及多類別之分類效能
計畫主持人: 姚志佳
計畫編號: 98-2221-E-324-023-MY2 學門領域: 圖形辨識
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
