可供推廣之研發成果資料表 
□ 可申請專利  ■ 可技術移轉                                    日期：97年08月20日 
國科會補助計畫 
計畫名稱：科學與技術文獻之主題趨勢探勘 
計畫主持人：曾元顯 
計畫編號：NSC 96-2221-E-003-017- 學門領域：資訊學門 II 
技術/創作名稱 文獻主題趨勢探勘系統 
發明人/創作人 曾元顯 
中文： 
 
給定一些文件，系統可輸出從該些文件分析出來的關鍵詞或主題，
以及按照趨勢排序的關鍵詞或主題列表，並針對各主題進行各個面
向的頻次分析，如該領域之高生產力作者、時間篇數序列變化等。
除此之外，系統亦可視覺化顯示主題關係遠近的主題地圖或主題
樹。 
技術說明 英文： 
Given a set of documents, our system can output a set of keywords or 
topics based on the texts from the given documents. The keywords or 
topics can be sorted in decreasing order of interest to reveal which are 
hot topics or emerging trends. Facet analysis is provided on a per topic 
basis. Also a topic map or topic tree can be generated to reveal the 
relationship among topics. 
可利用之產業 
及 
可開發之產品 
資訊檢索、知識管理、科技政策管理、資訊管理、資訊服務、決策
支援系統、商業智慧 
技術特點 其具備的文字探勘技術，不是一般資料庫管理系統或（結構化資料之）資料探勘系統，所能提供之分析功能。 
推廣及運用的價值 
本項技術或系統可運用於上述產業，針對非結構化之文字資料，協
助專家進行大量的文件分析，建議決策方向。此項智慧型分析工
具，乃影響科技、產業發展方向的重要分析工具。 
※ 1.每項研發成果請填寫一式二份，一份隨成果報告送繳本會，一份送 貴單位
研發成果推廣單位（如技術移轉中心）。 
※ 2.本項研發成果若尚未申請專利，請勿揭露可申請專利之主要內容。 
※ 3.本表若不敷使用，請自行影印使用。 
 
the scientific and technological literatures for 
users, but also assist experts in analyzing and 
tracking the trend evolution in science and 
technology. Furthermore, due to their 
generality, they can be applied to many fields 
such as education, agriculture, high-tech 
industrial, biology, sociology, economy, etc... 
Topic trend mining is a research topic that 
receives much attention in recent year due to 
its increasing importance in many aspects, 
such as business, policy making, and 
intelligence. Through serious researches, we 
expect to contribute some interesting findings 
to the academic community by exploring this 
topic under the support of this project. 
Keywords: trend detection, topic discovery, 
evolution tracking, concept linkage 
 
三、 報告內容 
現今知識經濟的時代，各先進及發展中
國家，在科學與技術方面的進步，可謂一日
千里。因此而引發的國與國之間的經濟與政
治影響力的競爭，越發激烈。在數位媒體發
達的今天，從大量龐雜的文獻資料中，透過
先進資訊擷取、檢索、組織、分析等探勘工
具的輔助，來快速掌握科學領域與主題的發
展趨勢，對科技政策之分析與擬定，可提供
相當有價值的資訊。 
例 如 ， 歐 盟 委 員 會 （ European 
Committee）便極為關注此一問題，曾資助
大型計畫，在 2001年發表 9大冊的的研究
報告。其透過大量科學論文與專利技術的書
目文獻，進行各種引用（citation）以及領域
（domain）分析，來發掘其中隱含的事證與
趨勢，作為制訂歐盟各國科技政策的參考。
又如，日本科學技術政策研究所，在 2004
年發表「科學技術中長期發展全瞻性預測調
查」報告，同樣也透過大量科學書目文獻的
引用與領域分析，以探勘各國科學與技術發
展現況及趨勢。此外，荷蘭 Leiden 大學的
科學與技術研究中心，也長期利用科學論文
與專利文獻，發表多種分析技術，觀測各主
要科技領域的發展趨勢。在美國，研究贊助
機構眾多，其中海軍研究辦公室（Office of 
Naval Research），更早在 1998年嚐試以文
字探勘技術，來支援科學與政策的管理任
務。 
本計畫從大量的高品質科技文獻（學術
論文、專利文件等），探勘並分析科學與技
術的發展主題與趨勢，其具體方法與流程如
下： 
一、文獻分析與整理：蒐集並整理國內
外相關探勘技術與工具之文獻。 
二、篩選分析領域與主題：與專家互
動，以文獻型態、領域別、年度別、國家別，
或文獻被引用情形等各構面，篩選出適合進
行趨勢探勘與分析之文獻，以進行後續研究
與分析。 
三、相關文獻的下載：根據上一步驟，
從學術或專利文獻資料庫，以人工、半自
動、或全自動方式下載該群指定的文獻資
料，以供後續處理操作。 
四、資料剖析：將文獻之出刊時間、標
題、摘要、或引用資料切割、分欄擷取、正
規化、解剖儲存至關聯式資料庫中，以便於
管理與運用，並進行初步量化分析與圖表製
作，以便掌握其統計特性，並對其有初步之
認識。 
五、索引建立：刪除停用詞、正規化詞
彙（取英文詞幹）、擷取關鍵詞（key-phrase 
extraction）、分析關聯詞 （ association 
analysis）、建立詞彙到文件的反向索引資訊
檔案，以便利爾後的文件檢索，並加速後續
的分析處理。 
六、主題偵測：利用文件中共同出現的
詞彙，計算相似度，將文件歸類起來，自動
偵測文獻中記載的技術主題，便於人工或電
腦進一步分析。 
七、多階層歸類：將「詞彙」或「文件」
歸類成「概念」、「概念」歸類成「主題」、「主
A Comparison of Methods for Detecting Hot Topics 
 
Yuen-Hsien Tseng*, Yu-I Lin**, Yi-Yang Lee***, Wen-Chi Hung***, Chun-Hsiang Lee*** 
*samtseng@ntnu.edu.tw 
Information Technology Center, National Taiwan Normal University, Taiwan, 106 
**jg141@mail.tpc.edu.tw 
Taipei Municipal Univ. of Education, Taiwan, 100 
*** (yylee, wchung, chlee)@mail.stpi.org.tw 
Science & Technology Policy Research and Information Center, National Applied Research Lab., Taiwan, 106 
 
Abstract 
In scientometrics for trend analysis, parameter choices for observing trends are often 
made ad hoc in past studies. For examples, different year spans might be used to create the 
time sequence and different indices were chosen for trend observation. However, the 
effectiveness of these choices was hardly known, quantitatively and comparatively. This work 
provides clues to better interpret the results when a certain choice was made. Specifically, by 
sorting research topics in decreasing order of interest predicted by a trend index and then by 
evaluating this ordering based on information retrieval measures, we compare a number of 
trend indices (percentage of increase vs. regression slope), trend formulations (simple trend vs. 
eigen-trend), and options (various year spans and durations for prediction) in different 
domains (safety agriculture and information retrieval) with different collection scales (72500 
papers vs. 853 papers) to know which one leads to better trend observation. Our results show 
that the slope of linear regression on the time series performs constantly better than the others. 
More interestingly, this index is robust under different conditions and is hardly affected even 
when the collection was split into arbitrary (e.g., only two) periods. Implications of these 
results are discussed. Our work does not only provide a method to evaluate trend prediction 
performance for scientometrics, but also provides insights and reflections for past and future 
trend observation studies. 
 
Keywords: Clustering, Trend Index, Eigen-Trend, Linear Regression, Evaluation, Information Retrieval. 
 
This work was accepted by the journal: Scientometrics (SCI & SSCI) on 2008/04/28.  
 1
computerized approach to evaluate different methods based on the evaluation measures in 
information retrieval to know which one is better, quantitatively. 
This work reports our methods and findings about this evaluation. In particular, a 
number of trend prediction indices, including those used in scientometrics and in basic 
statistics, are examined and compared. In the next section, the trend indices used by previous 
studies are briefly surveyed. Following is the description of the methods for automatic upward 
trend detection. The metrics for evaluating their effectiveness are introduced. We then 
describe the data collections for trend analysis and show how domain experts helped in 
labelling the trend type for each identified topic. With the experts’ feedback, various 
comparisons are made and the results are shown. Finally, we conclude this paper with the 
discussion of the implication of our findings. 
 
Previous Work 
 
Previous studies on trend watch based on quantitative time series data, such as the 
document distribution over a period of time for a particular topic, have used various methods 
and options. Noyons et al (Noyons, Moed, & van Raan, 1999; E. C. M. Noyons & A. F. J. van 
Raan, 1998) often split the publications to be analyzed into two periods and a percentage of 
increase (or decrease) in the second period relative to the first period was used to suggest the 
trends of the identified topics. 
To suggest rapidly developing research areas, the National Institute of Science & 
Technology Policy in Japan has used a similar measure (STFC, 2004), except that this 
percentage of increase was calculated on a per year basis and averaged over the watched years. 
Chen in his CiteSpace tool (Chen, 2006) allows users to vary the time slice for 
interactive analysis and visualization of emerging trends.  
In order to determine what topic areas are appearing in the papers at the SIGIR 
conferences from the last 25 years, Smeaton et al (Smeaton, Keogh, Gurrin, McDonald, & 
Sodfing, 2003) mapped these trends in a topic-document matrix. They listed the clustered 
topics in rows and number of documents per year in columns and sorted the rows 
approximately in order of a combination of the year of the first appearance of the topics, and 
the number of papers published. With this vision friendly map, they then predicted an ideal 
paper title, with all the hot topics in it, to appear in the SIGIR conference of the following 
year.  
 3
the above simple trend. Specifically, if there are m sources (journals or countries), the number 
of documents contributed by each source in each interval can be expressed in the following 
matrix D as: 
⎥⎥
⎥⎥
⎦
⎤
⎢⎢
⎢⎢
⎣
⎡
=
mnmm
n
n
ddd
ddd
ddd
D
L
MOMM
L
L
21
22221
11211
 
Through singular value decomposition, matrix D can be recast into the multiplication of three 
matrices D=USVT or as follows: 
⎥⎥
⎥⎥
⎦
⎤
⎢⎢
⎢⎢
⎣
⎡
×
⎥⎥
⎥⎥
⎦
⎤
⎢⎢
⎢⎢
⎣
⎡
×
⎥⎥
⎥⎥
⎦
⎤
⎢⎢
⎢⎢
⎣
⎡
=
⎥⎥
⎥⎥
⎦
⎤
⎢⎢
⎢⎢
⎣
⎡
nnnn
n
n
mnmmmm
m
m
mnmm
n
n
vvv
vvv
vvv
s
s
s
uuu
uuu
uuu
ddd
ddd
ddd
L
MOMM
L
L
L
MOMM
L
L
L
MOMM
L
L
L
MOMM
L
L
21
22221
11211
22
11
21
22221
11211
21
22221
11211
00
00
00
 
 
Multiple eigen-trends can then be derived from the above decomposition. However the most 
important one (contain major and most trend information) is the first eigen-trend computed by 
the multiplication of the first eigen-value s11 in matrix S with the first column in matrix VT. 
The authority of each source, i.e., the relative importance of individual source in contribution 
to the overall trend, can also be derived from the decomposition and is simply the first column 
of matrix U for the first eigen-trend. In comparison, the simple trend and simple authority are 
all computed from the matrix D, which are just the column sum and row sum of D, 
respectively. The following formula sum up the above discussion: 
Simple Trend: [d1, d2, …, dn], where ∑ == mi ijj dd 1 for each time interval j 
Simple Authority: [a1, a2, …, am], where ∑ == nj iji da 1  for each source i 
 (First) Eigen-Trend: [s11v11, s11v21, ..., s11vn1] 
(First) Eigen- Authority: [u11, u21, …, um1] 
 
Chi et al showed that, by suddenly changing the contribution patterns of some sources at 
a certain interval, eigen-trends are more sensitive to the contribution changes of those high-
authority sources while less affected by noise (or those low-authority sources). Their 
examples illustrated that in eigen-trends, for a source to have high impact on a topic, a track 
record is needed to be built over time, and one-time shot does not count very much. 
 
 5
Trend Evaluation 
To identify upward trends for experts, the identified structures are sorted by a trend 
index in decreasing order. If the trend index is a good predictor, the inspection in this order 
should be efficient in finding upward trends. To know which orderings perform better than 
the others, the tool called trec_eval (Buckley) is used2. This tool is widely adopted in many 
large information retrieval evaluation tasks, such as those in TREC3, NTCIR4, and CLEF5. 
Two metrics can be read from the output of this tool, i.e., NAP (Non-interpolated Average 
Precision rate) and Pre@R (Precision rate at Recall position). NAP is defined as: 
∑ == Ri
iRank
i
R
NAP
1
1  
where R is the number of all relevant items (true upward trends) and Ranki is the position of 
the ith relevant item in the ordering. For Pre@R, it denotes the precision rate at the R-th 
position in the ordering, i.e., r/R, where r is the number of relevant items in the top R items.  
To better understand these two metrics, Table 1 shows examples of the two metrics 
applied to three different orderings. Assume that A-E and V-Z are ten items to be sorted and 
A-E (in boldface) are the five items that are relevant (to our interest), while V-Z are not. As 
shown in Table 1, ordering S1 has all the five relevant items sorted in the top 5 positions, 
ordering S2 has all of them in the last 5 positions, and ordering S3 evenly distributes these 5 
relevant items. Obviously, ordering S1 is the best, S3 the second, and S2 the worst. The 
values of the two metrics for these three orderings are: 
NAP(S1) = (1/1+2/2+3/3+4/4+5/5)/5=1.0, Pre@R(S1) = 5/5=1.0 
NAP(S2) = (1/6+2/7+3/8+4/9+5/10)/5=0.3547, Pre@R(S2) = 0/5=0.0 
NAP(S3) = (1/1+2/3+3/5+4/7+5/9)/5=0.6787, Pre@R(S3) = 3/5=0.6 
As can be seen, the above two metrics reflect this precedence perfectly, although in different 
values. Note that these two metrics require that the relevant items are known in advance. The 
Pre@R measure is equivalent to counting the number of genuine hot topics above a threshold 
figure which happens to be the number of all genuine hot topics. The NAP delays the decision 
of the threshold until the last relevant item is found. Up to that last position, the weighted 
density of relevant items is then calculated. To sum up, the Pre@R measure is a coarser 
metric but is simpler to interpret, while the NAP measure is more complicated but can 
distinguish slightly different orderings.  
                                                          
2 A similar tool trec_eval.prl rewritten in Perl provided by the host of the NTCIR workshop was actually used. 
3 Text REtrieval Conference, http://trec.nist.gov/ 
4 NTCIR (NII Test Collection for IR Systems) Project, http://research.nii.ac.jp/ntcir/ 
5 CLEF (The Cross-Language Evaluation Forum), http://www.clef-campaign.org/ 
 7
are 2,765,938 citations in total (among these 72500 papers) and 11,248,898 coupling pairs. 
Due to this large volume, our clustering program failed to result in any clusters. After 
removing those pairs having less than 5 common citations, 145,471 document pairs remained 
and they resulted in 20,795 clusters with zero similarity between any clusters. This set of 
clusters exhibited highly skewed size distribution, i.e., most clusters (93.85%) are small 
containing less than 4 documents, only 16 clusters have more than 10 documents, and the 
largest one have only 16. As such, these clusters were not used in later evaluation. 
The next approach is a co-word analysis based on the free texts in the title and abstract 
fields. Keywords (and key-phrases) were extracted alone with their co-words (commonly co-
occurred terms in the same sentences) by Tseng’s algorithm (Tseng, 2002). Terms, after 
stemming, occurs in more than a specified document number were clustered based on 
common co-words they share. This resulted in 423 clusters or more (depending on the 
similarity threshold) and their distribution is less skewed than that from bibliographic 
coupling. However, the quality of these term clusters as topics varies from cluster to cluster. 
The low precision in cluster quality may waste experts’ efforts in providing feedback for trend 
detection. Although this set of clusters may contain most comprehensive topics in these 
documents, we decide to leave it for future studies after we obtained reliable techniques in 
upward trend detection. 
Our final approach for topic identification applied the co-word analysis based on 
controlled terms, i.e., terms from the field of SC and DE. An initial analysis showed that there 
are 1.8 SC terms for each record on average and only 2.8% of these SC terms occur in their 
title or abstract, and there are 5.52 DE terms on average and about 46.35% of them can be 
found in these two free text fields. In total there are 179 SC terms each occurs in more than 10 
documents and this number is 3632 for DE terms. In short, these controlled terms exhibit 
manageable size and different facets from the free texts for analysis. 
For their co-word analysis, terms from each field (SC or DE) co-occurred in the same 
records were counted. This pair-wise count was normalized by the individual occurrence of 
each term. Similarity based on this calculation was used in a complete link clustering 
algorithm. From the SC field, a total of 80 clusters (out of 179 SC terms) were found and 
from the DE field, there were 1617 clusters (out of 3632 DE terms). 
It is noted that the SC terms are broader terms, each of which alone represents a topic 
category of a field. Clustering of them leads to new topics that may be the intersection or 
union of the topics they contains. For DE terms, they are more like free text terms, defining 
concepts in a narrower topic. The quality of their clusters may be affected by their coverage. 
 9
the cluster or sub-cluster, the third is the minimum similarity between any terms in the same 
group, and the rest of columns are self-explained by their column titles. 
Table 4 shows the statistics of the experts’ judgment. As can be seen, 43 term groups 
(43/155=27.74%) from SC were inconclusive in their trend type. This percentage for DE is 
22.89%. Since the overall tendency is upward, there is no sharp decreasing case for SC and 
DE. The decreasing cases are also rare.  
 
Table 3. Examples of experts’ feedback on trend type labelling. 
cid nt Sim Trend DE Terms df 96 97 98 99 00 01 02 03 04 05
9 6 0.025 = 
osmoregulation; chloride cell; 
metamorphosis; thyroid hormone; flounder; 
flatfish 
147 3 9 17 14 16 26 17 12 14 19
9 4 0.066 = osmoregulation; chloride cell; metamorphosis; thyroid hormone 106 2 4 16 11 13 16 11 10 9 14
9 2 0.178 - osmoregulation; chloride cell 74 1 2 13 8 10 14 7 4 7 8
9 2 0.192 + metamorphosis; thyroid hormone 36 1 2 3 3 4 3 4 6 2 8
9 2 0.120 ? flounder; flatfish 46 1 5 1 4 5 11 6 2 5 6
28 5 0.032 ++ food allergy; anaphylaxis; IgE; gelatin; allergen 102 4 6 4 5 10 15 15 14 15 14
28 2 0.138 ++ food allergy; anaphylaxis 67 3 5 4 4 5 12 10 8 9 7
28 3 0.164 ++ IgE; gelatin; allergen 46 1 2 1 2 6 5 6 8 7 8
28 2 0.196 + IgE; gelatin 34 1 2 1 1 6 4 3 8 4 4
 
Table 4. Statistics of experts’ judgment. 
Field (sub-)clusters ++ + = - -- ?
SC 155 18 57 37 0 0 43
DE 249 20 61 97 14 0 57
 
 
Information Retrieval: Collection, Clusters, and  Hot Topics 
For the second data set, we use the collection prepared by Smeaton et al. They collected 
the titles, author names, and abstracts of all the 853 papers published from the first ACM 
SIGIR conference to the 25th.  Using a commercial software package called Clustan Graphics, 
29 non-overlapping clusters were generated from the document set. They then inspected each 
cluster manually and assigned a topic description to reflect the theme of the majority of the 
papers in each cluster. To add some structure to this clustering, and see how topics were 
spread over the 25 SIGIR conferences, they mapped the documents in each cluster to the year 
of the SIGIR in which they appeared, as shown in Table 5. In the table, the rows, representing 
clusters or topics, are sorted approximately in order of a combination of the year of their first 
appearance, and the number of papers published. The ID column denoting the sorting order 
was inserted by us for the convenience of later discussion. 
 
 11
represent two possible judges of the relevant topics in Table 5 based on the session titles in 
Table 7. 
 
Table 6. Three set of hot topics for SIGIR 2003 based on the of ideal paper title expected by 
Smeaton et al. 
J5 J8 J10 
Question answering 
Probabilistic & Language models 
Evaluation 
Document summarisation 
Cross lingual 
Question answering 
Probabilistic & Language models 
Evaluation 
Document summarisation 
Cross lingual 
Clustering 
Filtering 
Text categorisation 
Question answering 
Probabilistic & Language models 
Evaluation 
Document summarisation 
Cross lingual 
Clustering 
Filtering 
Text categorisation 
Message understanding & TDT 
Topic distillation & Linkage retrieval
 
Table 7. Fourteen session titles (topics) in the SIGIR 2003 conference. 
Topics df S13 S10 
Retrieval Models (Language Models, Evaluation) 3 14 14 
Question Answering (Evaluation) 3 26 26 
Web (Hyperlink, Classification) 3 5  
Human Interaction 6 10  
Text Categorization 6 3 3 
Multimedia Information Retrieval 3 15 15 
Structured Documents (XML) 2   
Text Representation (Term Modelling) 2 19  
IR Theory (LSA) 3 4 4 
Filtering and Retrieval Models (LSA) 3 17 17 
Clustering 3 22 22 
Distributed Information Retrieval (Source Selection, Topic Segmentation) 3 7 7 
Novelty and Topic Change (Text Segmentation) 3 18 18 
Cross-Lingual Information 3 1 1 
 
 
Results 
 
Safety Agriculture 
It is our concern to distinguish the sharp increasing or increasing cases from the others. 
The performance in this regard for each of the above trend index is shown in Table 8. Based 
on the NAP and Pre@R measures, slp and slpz perform best, the two eigen-trends are the 
second, and the percentage-of-increase type indices are the worst.  
The fact that the linear regression indices are the best verifies their widely use for trend 
prediction in statistics. The fact that the eigen-trends did not perform significantly well 
suggests that the effect of authorities or uneven contribution of individual sources does not 
 13
are only two periods, which can be verified by calculating its value from its definition6. The 
low variation on its values makes it difficult to sort the trends in a meaningful way. 
The next evaluation is to know how performance would be affected if we only use the 
first n years of data for prediction. As shown in Figure 3, for the slp index the NAP 
performance may drop as low as 25% for the sharp increase cases when only the first 8 years 
of data were used. In other words, when we are at the 8th year to predict the trends in the 10th 
year, the performance is 75% of that when we have the full 10 years of data. 
 
0
0.2
0.4
0.6
0.8
1
1.2
1 2 5
api(SC)
api(DE)
slp(SC)
slp(DE)
slp_z(SC)
slp_z(DE)
(a) NAP for + or ++. 
0
0.1
0.2
0.3
0.4
0.5
0.6
1 2 5
api(SC)
api(DE)
slp(SC)
slp(DE)
slp_z(SC)
slp_z(DE)
(a) NAP for ++. 
0
0.2
0.4
0.6
0.8
1
1 2 5
api(SC)
api(DE)
slp(SC)
slp(DE)
slp_z(SC)
slp_z(DE)
(c) Pre@R for + or ++. 
0
0.1
0.2
0.3
0.4
0.5
0.6
1 2 5
api(SC)
api(DE)
slp(SC)
slp(DE)
slp_z(SC)
slp_z(DE)
(d) Pre@R for ++. 
Figure 2. Prediction effectiveness when year span varies from 1, 2, to 5. 
 
-80.00%
-70.00%
-60.00%
-50.00%
-40.00%
-30.00%
-20.00%
-10.00%
0.00%
10 8 6 4 2
SC(+or++)
DE(+or++)
SC(++)
DE(++)
-100.00%
-80.00%
-60.00%
-40.00%
-20.00%
0.00%
20.00%
40.00%
10 8 6 4 2
SC(+or++)
DE(+or++)
SC(++)
DE(++)
Figure 3. Percentage of performance drop for slp using only the first n years of data, where 
n=10, 8, 6, 4, and 2. Left figure is for NAP, right figure is for Pre@R. 
 
                                                          
6 Let the sequence be (x1, x2). Its Z-sequence would be ((x1-avg)/stderr, (x2-avg)/stderr)=( (x1-x2)/2 / |(x1-x2)/2|, (-x1+x2)/2 / |(x1-x2)/2| ). Thus 
only 3 values result from the Z-sequence: (-1, 1), (1, -1), (0, 0), which in turn yield only 3 possible slopes: +2, -2, and 0. 
 15
Implications and Conclusions 
 
We have learned from the scientometrics literature that different year spans may be used 
to create the time sequence and different indices may be chosen for trend observation. 
However, the effectiveness of these parameters was hardly known, quantitatively and 
comparatively. Based on sorting research topics in decreasing order of interest predicted by a 
trend index and then evaluating this ordering by way of information retrieval measures, we 
have compared a number of metrics (percentage of increase vs. regression slope), trend 
formulations (simple trend vs. eigen-trend), and options (various year spans and durations for 
prediction) in different domains (safety agriculture and information retrieval) with different 
collection scales (72500 papers vs. 853 papers) for different topic sources (SC vs. DE terms). 
Our work provides clues to better interpret the results when a certain choice was made. For 
example, when api was chosen for trend prediction, it should be noted that it is only effective 
for large year span or short time series. Also when the collection is split into only two periods, 
both slp and api can be used. Thus the work of Noyons et al that often used api to analyze two 
periods of publications remained effective. In any cases, slp is recommended since it performs 
consistently well under the various conditions that we evaluated. 
The validity of the above insights is based on the validity of the relevance judgments that 
were used in our evaluations. The fact that the judges were allowed to use the trends in the 
data to make their judgement does not jeopardize their validity. As the case of the SIGIR data 
(Table 5) shows, even when the data were viewed visually, it does not prevent their authors to 
select a low ranking topic (e.g., “Question Answering” at the 26th position) as a genuine hot 
topic and vice versa (“Distributed IR” at the 7th position was not regarded as a hot topic). 
Furthermore, despite the different relevance judgments as shown in Table 9, high performing 
index still performs high in general. This phenomenon is often observed in other similar tasks 
involving human judgment (such as those in the work of (Tseng & Teahan, 2004)). Thus the 
inevitable discrepancy in judgments among individual experts can be safely ignored. 
Our goal is to explore the best way to predict upward trends in an environment where a 
large number of topics are to be monitored. Our work is important to know which index is the 
best under a certain condition. If a good trend index is used, the inspection in the order sorted 
by the index should be efficient, which could relieve the burden of analysts on monitoring any 
upward trends from a large stream of scientific publications.  
 17
Smeaton, A. F., Keogh, G., Gurrin, C., McDonald, K., & Sodfing, T. (2003). Analysis of Papers from 
Twenty-Five Years of SIGIR Conferences: What Have We Been Doing for the Last Quarter of a 
Century ? ACM SIGIR Forum, 37(1), 49-53. 
STFC. (2004). The 8th Science and Technology Foresight Survey - Study on Rapidly-Developing Research 
Areas - Interim Report: National Institute of Science & Technology Policy, Japano. Document 
Number) 
Tseng, Y.-H. (2002). Automatic Thesaurus Generation for Chinese Documents. Journal of the American 
Society for Information Science and Technology, 53(13), 9. 
Tseng, Y.-H., Lin, C.-J., Chen, H.-H., & Lin, Y.-I. (2006, Oct. 16-18). Toward Generic Title Generation for 
Clustered Documents. Paper presented at the Proceedings of Asia Information Retrieval 
Symposium, Singapore. 
Tseng, Y.-H., Lin, C.-J., & Lin, Y.-I. (2007). Text Mining Techniques for Patent Analysis. Information 
Processing and Management, 43(5), 1216-1247. 
Tseng, Y.-H., & Teahan, W. J. (2004, July 25 - 29). Verifying a Chinese Collection for Text Categorization. 
Paper presented at the 27th International ACM SIGIR Conference on Research and 
Development in Information Retrieval - SIGIR '04, Sheffield, U.K. 
 
 
 19
Emerging Trend Detection for Science and Technology Watch 
 
Yuen-Hsien Tseng, samtseng@ntnu.edu.tw, National Taiwan Normal University, Taiwan, 106 
Yu-I Lin, jg141@mail.tpc.edu.tw, Taipei Municipal Univ. of Education, Taiwan, 100 
Yi-Yang Lee, Wen-Chi Hung, Chun-Hsiang Lee, (yylee, wchung, chlee)@mail.stpi.org.tw 
Science & Technology Policy Research and Information Center, National Applied Research Lab., Taiwan, 106 
 
 
Abstract 
We develop a decision support approach for 
monitoring emerging trends in science and technology 
based on text mining of scientific publications. Papers or 
patents collected from online databases are analyzed for 
topic extraction. The history of each extracted topic is 
then evaluated with a trend index measure. Topics are 
ranked by their trend indices for emerging trend 
investigation. Evaluation of the results shows that the 
approaches presented in this work perform better than 
some other alternatives. Such a system can be used in 
scientific development prediction and/or technology 
watch. 
 
1. Introduction 
 
Monitoring research trends has always been a 
concern of policy makers of science and technology, 
since it helps resource allocation and technology forecast. 
Increasingly important research topics are of particular 
interest to those policy makers. These topics have been 
also termed as hot topics, upward trends, or emerging 
trends. Although delicate distinctions among these terms 
can been made (such as degree of increase and/or lateness 
of existence), we treat them synonymously in this work. 
As suggested by their literal meaning, they seem to highly 
correlate with the strength of attention received over time. 
However, such topics can not be identified simply by 
their increasing trend of publications, because genuine 
hot topics are more than their publication numbers can 
reveal (as we may see in our experiments later).  
Therefore, domain experts are often consulted for 
this purpose because they are good at identifying 
interesting research trends based on their knowledge and 
experience accumulated over time. However, their 
observations do not generalize effectively to the fields 
beyond their expertise. Besides, when a large number of 
research topics need to be prioritized, inconsistent 
decision may result from different experts’ opinions. 
Thus automatic mechanism for monitoring research 
trends, especially increasingly important topics, would be 
of great help. 
Automatic detection of emerging trends can be 
implemented by a modified information retrieval system 
in two major steps: (1) Documents (or terms) are 
clustered to yield topics. (2) For each topic, a time series 
of number of publications over time is created. Topics are 
then ranked by a trend metric based on these series. In 
such an approach, the input to the emerging trend 
detection system is a set of scientific or technological 
documents, each with a title, publication date, keywords, 
or other information for analysis. The output of the 
system is a ranked list of topics in descending order of 
interest.  
There have been studies on detecting these trends in 
scientometrics [1], decision sciences [2, 3], web mining 
[4], and other fields alike [5]. However, most encountered 
the lack of expert feedback to the results [6]. After several 
studies of this kind, Noyons and van Raan pointed out 
that “Domain experts are often hard to find, due to busy 
schedules. On the other hand, policy makers are often too 
much overwhelmed by the amount of resulting 
information. They have a hard time in understanding what 
kind of information the detected results show, and then 
conclude that they know too little of the field in order to 
be able to extract relevant information.” From this 
observation, it can be seen that an effective ordering of 
the detected topics would help a policy maker to identify 
hot topics more efficiently.  
In a project, funded by Science & Technology Policy 
Research and Information Center in Taiwan, to analyze a 
large set of scientific publications in the agricultural areas, 
we have the opportunity to detect upward trends for a 
group of experts and have their feedback in trend type 
labelling. We then analyze the effectiveness of our 
detection and prediction methods based on this feedback. 
To better utilize the valuable expert feedback, we propose 
a computerized approach to evaluate different methods 
based on the evaluation measures in information retrieval 
to know which one is better, quantitatively. 
This work reports our methods and findings for this 
kind of trend detection. In particular, a number of trend 
prediction indices are examined and compared. In the 
next section, related studies are briefly surveyed. 
Following is the description of the methods for automatic 
upward trend detection. The metrics for evaluating their 
effectiveness are introduced. We then describe the data 
collections for trend analysis and show how domain 
experts helped in labelling the trend type for each 
identified topic. With the experts’ feedback, various 
comparisons are made and the results are shown. Finally, 
we conclude this paper with the discussion of the 
implication of our findings. 
 
2. Previous Work 
 
Previous studies on trend watch based on 
quantitative time series data, such as the document 
3.2 Trend Indices 
From the above time series (simple trends or eigen-
trends), a trend prediction index can be calculated to 
summarize their tendencies. There are a number of such 
trend indices used in previous studies. They were 
examined and compared in the following to know which 
one is the best predictor. 
The first one is the average percentage of increase 
(api): 
∑ −= + −−= 11 111 ni i ii d
dd
n
api  
This index has been used in a foresight survey in Japan 
[8]. It is also the trend indicator used by Noyons et al [7] 
when n=2.  
The second index, denoted as slp, is the slope of the 
linear regression line that best fits the data in the time 
series1: 
∑
∑
=
==
n
i i
n
i ii
x
yx
slp
1
2
1 , where ∑
=
−=
n
i
i in
ix
1
1  and ∑
=
−=
n
i
iii dn
dy
1
1  
This is the most commonly used prediction method in 
statistics [18]. However, it has a large variation among 
sequences of different frequency scales, which may make 
it difficult for humans to predict its trend type based on its 
value.  
Thus the third index is to convert all the numbers in 
the time series into their z scores (computed as zi=(di-
avg)/stderr) and calculate the slope of the regression line 
based on the new sequence. This is denoted as slpz. 
The fourth index, denoted as slppi, is a combination 
of the first and the second index. The original time series 
is converted into a time series in which each data point is 
the percentage of increase as defined in the first index. 
Thus the length of the new series is shorter by one than 
that of the original series. The slope of the linear 
regression line that best fits the data in the new series is 
then calculated as the index. To get positive values for 
this index, the series should have a tendency that the 
percentage of increase is greater and greater in each 
successive interval. Thus it may be ideal for sharp 
increasing trend detection. 
The fifth index is denoted as slpc. It is the slope of 
the (first) eigen-trend of the original series when breaking 
down by countries. 
The sixth index is denoted as slpj. It is the slope of 
the (first) eigen-trend of the original series when breaking 
down by journals. 
 
4. Evaluation Method 
To identify upward trends for experts, the identified 
structures are sorted by a trend index in decreasing order. 
If the trend index is a good predictor, the inspection in 
this order should be efficient in finding upward trends. To 
know which orderings perform better than the others, the 
tool called trec_eval [19] is used2. This tool is widely 
                                                          
1 A module in Perl programming language called Statistics::Regression 
was used for regression computation. 
2 A similar tool trec_eval.prl rewritten in Perl provided by the host of the 
NTCIR workshop was actually used. 
adopted in many large information retrieval evaluation 
tasks, such as those in TREC3, NTCIR4, and CLEF5. Two 
metrics can be read from the output of this tool, i.e., NAP 
(Non-interpolated Average Precision rate) and Pre@R 
(Precision rate at Recall position). NAP is defined as: 
∑== Ri
iRank
i
R
NAP
1
1  
where R is the number of all relevant items (true upward 
trends) and Ranki is the position of the ith relevant item in 
the ordering. For Pre@R, it denotes the precision rate at 
the R-th position in the ordering, i.e., r/R, where r is the 
number of relevant items in the top R items.  
To better understand these two metrics, Table 1 
shows examples of the two metrics applied to three 
different orderings. Assume that A-E and V-Z are ten 
items to be sorted and A-E (in boldface) are the five items 
that are relevant (to our interest), while V-Z are not. As 
shown in Table 1, ordering S1 has all the five relevant 
items sorted in the top 5 positions, ordering S2 has all of 
them in the last 5 positions, and ordering S3 evenly 
distributes these 5 relevant items. Obviously, ordering S1 
is the best, S3 the second, and S2 the worst. The values of 
the two metrics for these three orderings are: 
 
NAP(S1)     =(1/1+2/2+3/3+4/4+5/5)/5=1.0, 
Pre@R(S1) = 5/5=1.0 
NAP(S2)     =(1/6+2/7+3/8+4/9+5/10)/5=0.3547, 
Pre@R(S2) = 0/5=0.0 
NAP(S3)     =(1/1+2/3+3/5+4/7+5/9)/5=0.6787, 
Pre@R(S3) = 3/5=0.6 
 
Table 1. Examples of NAP and Pre@R applied to three 
orderings. 
Rank S1 S2 S3 
1 A V A 
2 B W V 
3 C X B 
4 D Y W 
5 E Z C 
6 V A X 
7 W B D 
8 X C Y 
9 Y D E 
10 Z E Z 
NAP 1.00 0.35 0.68 
Pre@R 1.00 0.00 0.60 
 
As can be seen, the above two metrics reflect this 
precedence perfectly, although in different values. Note 
that these two metrics require that the relevant items are 
known in advance. The Pre@R measure is equivalent to 
counting the number of genuine hot topics above a 
threshold figure which happens to be the number of all 
genuine hot topics. The NAP delays the decision of the 
threshold until the last relevant item is found. Up to that 
last position, the weighted density of relevant items is 
                                                          
3 Text REtrieval Conference, http://trec.nist.gov/ 
4  NTCIR (NII Test Collection for IR Systems) Project, 
http://research.nii.ac.jp/ntcir/ 
5  CLEF (The Cross-Language Evaluation Forum), http://www.clef-
campaign.org/ 
 
Table 2. Number of records from 1996 to 2005. 
Year 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 Total
Rec. 5448 6056 6363 6211 6773 7475 8028 7700 9178 9268 72500
 
• 8 terms : 0.1740 (ciprofloxacin: 8.0, lincospectin: 7.9, cefquinom: 6.7)  
o 7 terms : 0.209 (lincospectin: 8.4, cefquinom: 7.1, ciprofloxacin: 6.0)  
 2 terms : 0.2990 (tmp: 3.3, lincospectin: 2.5, oxacillin: 1.3)  
 1506 : oxytetracycline  
 1631 : neomycin  
 5 terms:0.2358 (cefquinom: 5.4, clavulanic: 4.8, sulfisoxazole: 4.6) 
 2 terms : 0.3962 (sulfisoxazole: 3.3, lincospectin: 2.5)  
 900 : tetracycline  
 1686 : streptomycin  
 3 terms : 0.3263 (clavulanic: 3.9, ciprofloxacin: 3.3)  
 2 terms : 0.4432 (dicloxacillin:2.0, cefadroxil:2.0)  
 1385 : ampicillin  
 1391 : penicillin  
 2604 : enrofloxacin  
o 1928 : erythromycin  
• 4 terms : 0.0288   
o 2 terms : 0.1117  
 441 : oxytetracycline  
 689 : tetracycline  
o 2 terms : 0.1818  
 2056 : chlortetracycline  
 2437 : tetracyclines  
 
Figure 1. Result examples from co-word analyses. Left figure is based on title and abstract, where common co-words are 
shown in the parentheses. Right figure is from the DE field. 
 
Table 3. Examples of experts’ feedback on trend type labelling. 
cid nt Sim Trend DE Terms df 96 97 98 99 00 01 02 03 04 05
9 6 0.025 = osmoregulation; chloride cell; metamorphosis; thyroid hormone; flounder; flatfish 147 3 9 17 14 16 26 17 12 14 19
9 4 0.066 = osmoregulation; chloride cell; metamorphosis; thyroid hormone 106 2 4 16 11 13 16 11 10 9 14
9 2 0.178 - osmoregulation; chloride cell 74 1 2 13 8 10 14 7 4 7 8
9 2 0.192 + metamorphosis; thyroid hormone 36 1 2 3 3 4 3 4 6 2 8
9 2 0.120 ? flounder; flatfish 46 1 5 1 4 5 11 6 2 5 6
28 5 0.032 ++ food allergy; anaphylaxis; IgE; gelatin; allergen 102 4 6 4 5 10 15 15 14 15 14
28 2 0.138 ++ food allergy; anaphylaxis 67 3 5 4 4 5 12 10 8 9 7
28 3 0.164 ++ IgE; gelatin; allergen 46 1 2 1 2 6 5 6 8 7 8
28 2 0.196 + IgE; gelatin 34 1 2 1 1 6 4 3 8 4 4
 
Table 3 shows examples of the trend type labelling 
made by experts against some DE clusters. In this table, 
the first column is the cluster ID, the second is the 
number of terms in the cluster or sub-cluster, the third is 
the minimum similarity between any terms in the same 
group, and the rest of columns are self-explained by their 
column titles. 
 
Table 4. Statistics of experts’ judgment. 
Field (sub-)clusters ++ + = - -- ?
SC 155 18 57 37 0 0 43
DE 249 20 61 97 14 0 57
 
Table 4 shows the statistics of the experts’ judgment. 
As can be seen, 43 term groups (43/155=27.74%) from 
SC were inconclusive in their trend type. This percentage 
for DE is 22.89%. Since the overall tendency is upward, 
there is no sharp decreasing case for SC and DE. The 
decreasing cases are also rare.  
 
5.3 Information Retrieval: Collection, Clusters, and  
Hot Topics 
For the second data set, we use the collection 
prepared by Smeaton et al. They collected the titles, 
author names, and abstracts of all the 853 papers 
published from the first ACM SIGIR conference to the 
25th.  Using a commercial software package called 
Clustan Graphics, 29 non-overlapping clusters were 
generated from the document set. They then inspected 
each cluster manually and assigned a topic description to 
reflect the theme of the majority of the papers in each 
cluster. To add some structure to this clustering, and see 
how topics were spread over the 25 SIGIR conferences, 
they mapped the documents in each cluster to the year of 
the SIGIR in which they appeared, as shown in Table 5. 
In the table, the rows, representing clusters or topics, are 
sorted approximately in order of a combination of the 
year of their first appearance, and the number of papers 
published. The ID column denoting the sorting order was 
inserted by us for the convenience of later discussion. 
Apart from attempting to track the evolution of topic 
areas in the information retrieval field, they extrapolated 
and predicted the "hottest" topics for the following year. 
The ideal paper title expected by Smeaton et al to appear 
in SIGIR 2003 is "Evaluation of a Language Model 
Implementation of a Topic-Based, Cross-Lingual 
Question-Answering and Summarisation System", an 
aggressive title containing all the hot topics at that time. 
Based on their expectation, we listed three sets of relevant 
topics for evaluation in Table 6. The reason for 
enumerating three judgment sets is due to our uncertainty 
about the word “topic-based” in their ideal paper title. We 
6. Results 
6.1 Safety Agriculture 
It is our concern to distinguish the sharp increasing 
or increasing cases from the others. The performance in 
this regard for each of the above trend index is shown in 
Table 8. Based on the NAP and Pre@R measures, slp and 
slpz perform best, the two eigen-trends are the second, 
and the percentage-of-increase type indices are the worst.  
The fact that the linear regression indices are the best 
verifies their widely use for trend prediction in statistics. 
The fact that the eigen-trends did not perform 
significantly well suggests that the effect of authorities or 
uneven contribution of individual sources does not prevail 
in this collection. In fact, when we examined the data, we 
found that the simple authority vectors are almost the 
same as the eigen-authority vectors and the slopes of the 
simple trends coincide with the slopes of the eigen-trends. 
As such, no advantage was gained from the singular value 
decomposition of the break-down trend matrix. The fact 
that the percentage-of-increase type indices perform 
worst, when the year span is 1, is somewhat surprising to 
know, since these indices are intuitively simple to use and 
interpret. Especially, that the index slppi performs poorly 
for sharp increasing trends suggests the complication of 
trend judgement. 
 
Table 8. Performance of different trend indices. 
The Avg rows are the averages of the values in the SC 
and DE rows. 
Yearly Judgment + or ++ ++ 
Index Field NAP Pre@R NAP Pre@R
SC 0.6093 0.6533 0.1733 0.1111
DE 0.4454 0.5062 0.1587 0.1500api 
Avg 0.5273 0.5798 0.1660 0.1306
SC 0.9521 0.8800 0.4552 0.3333
DE 0.8254 0.7407 0.4293 0.5500slp 
Avg 0.8887 0.8104 0.4423 0.4417
SC 0.9524 0.8933 0.2992 0.2778
DE 0.8424 0.7654 0.5689 0.5500slpz
Avg 0.8974 0.8294 0.4340 0.4139
SC 0.7250 0.7733 0.2051 0.1667
DE 0.3807 0.3704 0.0867 0.0000slppi
Avg 0.5528 0.5719 0.1459 0.0833
SC 0.9295 0.8533 0.4457 0.2222
DE 0.7846 0.6914 0.4574 0.4500slpc
Avg 0.8570 0.7723 0.4516 0.3361
SC 0.9214 0.8267 0.4722 0.4444
DE 0.8041 0.7284 0.4084 0.3500slpj
Avg 0.8627 0.7775 0.4403 0.3972
 
Previous studies have used different intervals or year 
spans to create the frequency sequence for trend 
observation. This was evaluated in Figure 2 for index api, 
slp, and slpz where the year span varies from 1, 2, to 5. A 
year span of 5 corresponds to dividing the 10-years 
collection into two periods. It is again surprising to know 
that even with only two periods, the performance of the 
slp index remains virtually the same. Also interesting is 
that the performance of api increases as the year span 
increases. In contrast, the slpz index drops in performance 
drastically. This is because it yields only three values +2, 
0, and -2 when there are only two periods, which can be 
verified by calculating its value from its definition6. The 
low variation on its values makes it difficult to sort the 
trends in a meaningful way. 
The next evaluation is to know how performance 
would be affected if we only use the first n years of data 
for prediction. As shown in Figure 3, for the slp index the 
NAP performance may drop as low as 25% for the sharp 
increase cases when only the first 8 years of data were 
used. In other words, when we are at the 8th year to 
predict the trends in the 10th year, the performance is 
75% of that when we have the full 10 years of data. 
 
0
0.1
0.2
0.3
0.4
0.5
0.6
1 2 5
api(SC)
api(DE)
slp(SC)
slp(DE)
slp_z(SC)
slp_z(DE)
(a) NAP for ++. 
0
0.1
0.2
0.3
0.4
0.5
0.6
1 2 5
api(SC)
api(DE)
slp(SC)
slp(DE)
slp_z(SC)
slp_z(DE)
(b) Pre@R for ++. 
Figure 2. Prediction effectiveness when year span varies 
from 1, 2, to 5. 
 
-80.00%
-70.00%
-60.00%
-50.00%
-40.00%
-30.00%
-20.00%
-10.00%
0.00%
10 8 6 4 2
SC(+or++)
DE(+or++)
SC(++)
DE(++)
-100.00%
-80.00%
-60.00%
-40.00%
-20.00%
0.00%
20.00%
40.00%
10 8 6 4 2
SC(+or++)
DE(+or++)
SC(++)
DE(++)
Figure 3. Percentage of performance drop for slp using 
only the first n years of data, where n=10, 8, 6, 4, and 2. 
Upper figure is for NAP, lower figure is for Pre@R. 
 
 
                                                          
6 Let the sequence be (x1, x2). Its Z-sequence would be ((x1-avg)/stderr, 
(x2-avg)/stderr)=( (x1-x2)/2 / |(x1-x2)/2|, (-x1+x2)/2 / |(x1-x2)/2| ). Thus 
only 3 values result from the Z-sequence: (-1, 1), (1, -1), (0, 0), which in 
turn yield only 3 possible slopes: +2, -2, and 0. 
