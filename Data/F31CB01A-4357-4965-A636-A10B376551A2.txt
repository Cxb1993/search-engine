中文摘要： 
本計畫之主要目的在研究如何改善傳統廣義盒中腦神經網路(Generalized Brain-State-in-a-Box Neural 
Network,簡稱GBSB)之神經元架構與學習演算法，並利用複域GBSB神經網路來做高雜訊環境下數位灰階
影像之影像復原，以改善傳統GBSB神經網路在影像儲存與回憶上之缺點。本研究主要以256灰階數影像
為實驗影像，所運用之方法及步驟為：(a) GBSB之複變延伸研究：我們將Hui與Zak所提出之GBSB拓展
至複數領域。(b) GBSB在複變領域之穩定性探討與學習演算法研究：我們將GBSB之狀態空間由傳統之
多 維 (Multi-dimensional) 單 位 超 立 方 體 (Unit-Hypercube) 延 伸 至 多 維 之 單 位 複 變 超 立 方 體
(Unit-Complex-Hypercube)，並將網路之整體穩定性(Global Stability)加以探討。在學習演算法方面，我們
推導出複域GBSB在同步與非同步(Synchronous and Asynchronous Update Mode)下權值矩陣之穩定條件，
並依此找出對應之權值矩陣學習演算法。(c)真實影像之應用模擬與性能比較：為了證實本計劃所提出之
方法之合法性與有效性，我們以256x256, 256 灰階之真實影像為範例影像來比較不同方法之(1)影像過濾
雜訊之能力(2)計算代價與(3)記憶體需求等，以驗證本方法之實用性。 
 
關鍵詞：影像復原、廣義盒中腦神經網路、複變神經元、假記憶 
 
Abstract- The main objects of this project are to improve the neuron structure and learning rule of the 
generalized brain-state-in-a-box neural network (GBSB), and to use it for restoring digital gray-level images 
under high noise environment. This project uses standard 256 gray-level images as the experiment images. The 
project consists of the following three main procedures: (a) Research of the complex domain extension of the 
GBSB: The GBSB proposed by Hui and Zak is extended to complex domain. (b) Stability analysis and learning 
rule research of the complex GBSB: because the state space of the GBSB is extended from conventional 
multi-dimensional unit-hypercube to multi-dimensional unit-complex-hypercube, the global stability of the 
network is discussed. As to the learning rule, we derived stability conditions of the weight matrices of the 
GBSB under synchronous and asynchronous update modes, respectively. Based on these results we can further 
find the learning rules of the weight matrices. (c) Real image simulation and performance comparison: In order 
to demonstrate the validity and effectiveness of the proposed method, 256×256 resolution, 256 gray-level 
images are used as the example images to compare (1) noise filtering capability, (2) computational cost, and (3) 
memory requirement, under different methods so that the practical value of our method can be demonstrated. 
 
Keywords: image reconstruction, GBSB, complex neuron, spurious memory 
 
一、前言 
 
近年來有關數位影像之壓縮、儲存與辨識之研究相當的多，隨著寬頻多媒體應用的風行，亦促使數
位視訊網路服務迅速普及。與數位影像相關之應用包含有線電視、數位電視、衛星電視以及智慧型代理
人等相關領域，並將其應用於遠距教學、多人視訊會議以及虛擬實境廣播等。然而在影像傳輸的過程中，
往往因為通訊通道(Channel)之雜訊干擾而使得接收端所獲得之影像與原始影像有相當大的出入，此種情
況在無線通訊應用中最為明顯。傳統之 JPAG 影像壓縮僅適用於低雜訊環境(位元誤差率小於 )，在高
雜訊環境下(例如利用手機傳輸壓縮影像) 位元誤差率將高達 ，JPAG 與傳統之 entropy 編碼就不再適
用[1]。有鑑於上述的缺點近年來以類神經網路應用於數位影像之相關研究相當的多[2]-[8]，此乃因類神
經網路具有強健之抗雜訊能力。在眾多之類神經網路模式中，又以聯想記憶神經網路(Associative Memory 
Neural Networks)之抗雜訊能力最佳，它本身又具備影像辨識的功能，因此聯想記憶神經網路之研究近年
來一直是很熱門的領域。在 90 年代，Bohner 等人[9]與 Varga 等人[10]提出了以盒中腦神經網路
610
210
提出 Brain-State-in-a-Convex-Body 與 Brain-State-in-a-Convex-Domain (BSCD)兩種 GBSB 模式，
前者以最接近點映射(Nearest-Pint-Map)[9]做為網路之激發函數，後者以廣義之凸集域(Convex 
Domains)[10]做為 GBSB 之狀態空間。Tao 等人[28]亦提出將 BSB 之狀態空間延伸至一以儲存範
本所生成(Spanned)之凸集(Convex Body)。以上這些方法雖可使 BSB model 能夠儲存與回憶灰階
範本，卻缺乏明確之學習演算法。 
 
前述之各種方法大多是在實域(Real Domain)上面探討，近年來相當熱門的方法是 Jankowski 等人[29]所提
出之複值神經網路(Complex-valued Neural Networks, CVNN, 如圖一)，該架構將狀態向量元素值之定義
域由傳統之二值(Binary)拓展至 K 個大小為 1 而相位為 .1,...,1,/2  KvKv 之複數，此 K 個相位角平均
分佈於 0 到 2
2n
之間(如圖二)，分別對應於灰階影像之 K 個不同之灰階值，網路之神經元個數為 n，連結
權重之數目為 。此網路之狀態方程式為： 



 

n
j
jiji xsx
1
                                (1) 
其中 )(Z 為一複變激發函數： 
  
 
 








 





0
)2/(
0
0
)2/(
0
0
)2/(
arg)1()1(2exp
2arg2exp
arg0)0exp(
)(
0
0







KZeK
K
Kj
Ze
K
j
Zej
Z
j
j
j

 
  
 
 
 
 
 
圖一. CVNN 之架構圖，  為神經元 j 至神經元 i 之連結權重值 ijS
 
Re
Im
K
2
0je
K
je
2Kje
4
K
je
6
圖二. 狀態向量之元素座落圖 
 
 
(3)式亦可寫成 
))(())()(()1( kTXkXSIkX    
其中 SIT   
 
我們提出以下的定理： 
 
Theorem 1： 假設 CDBSB 之初態 且連結矩陣 S 為對稱且正定。令 0)0(X
,
))(1log(
)0(loglog
min
2
1
S
Xn
k 
  
其中 表之邊界。則 CDBSB 之狀態至多在 k 次調整之內到達U U 。 
 
證明： 
假設 且 X 在 k 次調整前均在 之內部 0)0(X U
)0()())0(()1( XSIXTX   
)0())(1()1( min XSX   
)0())(1()( min XSkX
k  
))(1log()0(log)(log min SkXkX   
所以 
,
))(1log(
)0(loglog
))(1log(
)0(log)(log
min
2
1
min S
Xn
S
XkX
k  

  
故 CDBSB 之狀態至多在 k 次調整之內到達 U 。 
 
Theorem 2： 假設連結矩陣 S 為對稱且正定，則 CDBSB 之狀態軌跡一旦觸碰到 就永遠停留在U U 。 
證明： 
利用矛盾證法，假設 但UkX )( UkX  )1( ，則 1)1( kX  
)()()1( kXSIkX   
)())(1()1( min kXSkX   
)(
)1(
)(1 min kX
kX
S
 <1 (矛盾) 
 
Theorem 3：定義 CDBSB 之能量函數為 TXXXE *
2
1)(  其中”*”表示共軛轉置。若 )()1( kXkX  則
，換句話說，當狀態有改變時系統之能量一定會遞減，因此 CDBSB 為整體穩定。 ))(())1(( kXEkXE 
證明： 
令  ))(())1(( kxEkXEE 
 
圖四. 3張256x256, 256灰階範例影像 
 
 
圖五. 將圖四之影像加入20%之胡椒鹽雜訊(salt and pepper noise)後所得到之測試影像  
 
圖六. 將圖五之測試影像以3 x 3 medium filter處理後所得到之結果 
 
圖七. 將圖五之測試影像以CDBSB處理後所得到之結果 
 
 
 
 
 
hierarchical clustering,” IEEE Trans. Neural Networks, Vol. 12, No. 5, pp. 1147-1162, Sept. 2001. 
[9] M. Bohner and S. Hui, “Brain state in a convex body,” IEEE Trans. Neural Networks, vol. 6, no. 5, pp. 
1053-1060, Sept. 1995. 
[10] I. Varga, G. Elek, and S. H. Zak, “On the brain-state-in-a-convex-domain neural models,” Neural Networks, 
vol. 9, no. 7, pp. 1173-1184, Sept. 1996. 
[11] J. Anderson, J. Silverstein, S. Ritz, and R. Jones, “Distinctive features, categorical perception, and 
probability learning: Some applications of a neural model,” Psych. Rev., vol. 84, pp. 413-451, 1977. 
[12] S. Hui and S. H. Zak, “Dynamical analysis of the brain-state-in-a-box (BSB) neural models,” IEEE Trans. 
Neural Networks, vol. 3, no. 1, pp. 86-100, Jan. 1992. 
[13] W. E. Lillo, D. C. Miller, S. Hui, and S. H. Zak, “Synthesis of brain-state-in-a-box (BSB) based associative 
memories,” IEEE Trans. Neural Networks, vol. 5, no. 5, pp. 730-737, Sept. 1994. 
[14] R. Perfetti, “A synthesis procedure for brain-state-in-a-box neural networks,” IEEE Trans. Neural 
Networks, vol. 6, no. 5, pp. 1071-1080, Sept. 1995. 
[15] H. Y. Chan and S. H. Zak, “On neural netwoks that design neural associative memories,” IEEE Trans. 
Neural Networks, vol. 8, no. 2, pp. 360-372, Mar. 1997. 
[16] J. Park, H. Cho, and D. Park, “Design of GBSB neural associative memories using semidefinite 
programming,” IEEE Trans. Neural Networks, vol. 10, no. 4, pp. 946-950, July. 1999. 
[17] S. H. Zak, W.. E. Lillo, and S. Hui, “Learning and forgetting in generalized brain-state-in-a-box (BSB) 
neural associative memories,” Neural Networks, vol. 9, no. 5, pp. 845-854, 1996. 
[18] D. Casali, G. Costantini, R. Perfetti, and E. Ricci, “Associative memory design using support vector 
machines,” IEEE Trans. Neural Networks, vol. 17, no. 5, pp. 1165-1174, Sept. 2006. 
[19] R. D. Goyal and G. Nagaraja, “Generalized brain-state-in-a-box based associative memory for correcting 
words and images,” in Proc. 9th Int. Conf. on Neural Information Processing (ICONIP’02), pp. 291-295, 
Nov. 2002. 
[20] K. Starczewski, “Spoken digit recognition using generalized brain-state-in-a-box model,” in Proc. Int. 
Conf. on Power Electronics and Intelligent Control and Energy Conservation (PELINCEC 2005), paper 
ID:264, June 2005. 
[21] Y. V. Bodyanskiy and N. A. Teslenko, “Adaptive learning of fuzzy BSB and GBSB neural models,” 
Cybernetics and Systems Analysis, vol. 42, no. 6, pp. 786-794, Nov. 2006. 
[22] C. Oh and S. H. Zak,, “Associative memory design using overlapping decomposition and generalized 
brain-state-in-a-box neural networks,” Int, J. Neural Systems, vol. 13, no. 3, pp. 139-153, June 2003. 
[23] C. Oh and S. H. Zak, “Large scale pattern storage and retrieval using generalized brain-state-in-a-box 
neural networks,” IEEE Trans. Neural Networks, to appear. 
[24] G. Costantini, D. Casali, and R. Perfetti, “Neural associative memory storing Gray-coded fray-scale 
images,” IEEE Trans. Neural Networks, Vol. 14, No. 3, pp. 703-707, May 2003. 
[25] G. Costantini, D. Casali, and R. Perfetti, “Associative memory design for 256 gray-level images using a 
multilayer neural network,” IEEE Trans. Neural Networks, Vol. 17, No. 2, pp. 519-522, March 2006. 
[26] M. Cottrell, "Stability and attractivity in associative memory networks," Biol. Cybern. Vol. 58, pp. 129-139, 
1988. 
[27] J. Bruck and J. W. Goodman, "A generalized convergence theorem for neural networks," IEEE Trans. 
Inform. Theory, vol. 34, no. 5, pp. 1089-1092, Sept. 1988. 
[28] Q. Tao, J. Cao, and X. Liu, “The BSB neural network in the convex body spanned by the prototype 
patterns for associative memory,” Applied. Mathematics. and Computation, vol. 132, pp. 575-587, 2002. 
國科會補助計畫衍生研發成果推廣資料表
日期:2011/07/07
國科會補助計畫
計畫名稱: 一複域盒中腦模型與其在256灰階影像復原上之應用
計畫主持人: 李棟良
計畫編號: 99-2221-E-130-019- 學門領域: 影像處理
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
