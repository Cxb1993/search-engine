 2
 
圖二 
由於 DBLP 資料庫所提供的資料並沒有包含每篇論文的主題資訊，與主題相關的欄
位只有“論文標題” ，因此我們針對每一篇論文標題進行文字處理。首先移除 stop words
並進行英文原型化處理(stemming)，再擷取出其中的 bigrams。由一個設定門檻值 α去除
掉一些不常出現的 bigrams，以留下的 bigrams 當作論文的各種主題。 
然而並不能只以標題包含之常見 bigrams 相同當作判別相關研究主題的依據，例如
從論文 A 的標題所擷取出的常見 bigram 為"Data Mining"，另從一篇論文 B 所擷取出的
常見 bigram 為"Association Rule"，雖然這兩個 bigrams 並不相同，但從電腦科學的背景
知識可得知："Association Rule"是"Data Mining"領域中重要的研究問題之一。因此我們
運用外部資源 CiteSeerX 網站(http://citeseerx.ist.psu.edu/)來探勘 bigrams 之間所隱含的主
題階層式關聯。CiteSeerX 網站是美國賓州大學所建構的一個數位化圖書資料庫，截至
目前為止收集了超過一百四十萬篇以上的電腦與資訊科學相關領域中的電子論文，提供
搜尋引擎讓使用者下達查詢關鍵字，並回傳符合該關鍵字的論文筆數及結果給使用者。 
我們主要利用包含給定關鍵字的論文筆數來計算 bigram 之間的關聯性。首先以擷
取出來的 bigrams，以及兩兩 bigram 所形成的配對分別當作查詢關鍵字，由 CiteSeerX
所提供的搜尋引擎查詢在 CiteSeerX 中包含符合該 bigram 或 bigram 配對的論文筆數。
在得到所有符合 bigrams 與 bigram pairs 的論文筆數後，運用關聯規則探勘來找出 bigram
間可能隱含的階層式關聯。根據關聯規則的確信度值(confidence)，當 conf(B→A)為 1 且
conf(A→B)不為 1 時，表示只要 B 有出現，一定會有出現 A，反之則不成立。以集合包
含的概念而言，即可推論具有 bigram B 的論文所成的集合被包含在具有 bigram A 的論
文所成的集合當中，表示 A 所涵蓋的概念是較廣的。 
以 A、B、C、及 D 表示 bigrams，將兩兩 bigram 間關聯規則的確信度值滿足以下
情 況 時 ， 則 可 建 構 出 如 圖 三 所 示 之 階 層 式 概 念 架 構 : conf(A→B)=p 且
conf(B→A)=100% ， conf(A→C)=q 且 conf(C→A)=100% ， conf(C→D)=r 且
conf(D→C)=100%，conf(A→D)=s 且 conf(D→A)=100%，其中 0<p, q, r, s<1。 
 
圖三 
實際在建立 bigram 間的階層式概念架構時，考量概念與子概念的包含關係並非如
此分明，因此我們放寬了 conf(B→A)自信度值為 100%的條件要求，而是設定一個門檻
值 β，即 conf(A→B)與 conf(B→A)皆需大於等於 β，且 conf(A→B)必須小於 conf(B→A)，
則我們就推論 B 的概念是被包含在 A 的概念下。 
 4
門的話題可能會有上百篇回應文章，使用者若一篇一篇點閱會花費許多時間。此外，由
於回應文章是由一般使用者自由討論發表的內容，其所涵蓋的觀點及內容重點可能非常
多樣化，甚至可能會有些不相關的文章內容。有時候使用者可能只想要閱讀有關於某一
個觀點的相關文章，若能將文章依據關鍵字分類，提供使用者選擇有興趣的關鍵字或分
類來閱讀相關的討論文章將可讓使用者在瀏覽網路論壇的討論文章時更有效率。 
以YAHOO!奇摩新聞－全民話頭條這個網站為例，該網站目前的討論話題會有一組
已事先定義好的話題標籤，但是這些話題標籤並不能夠完全涵蓋該主題討論的內容；這
個論壇也有提供搜尋的功能，但是只限於搜尋話題，不能搜尋相關的文章，所以對於使
用者來說一樣很難找出想要閱讀的文章。很多文章中討論的觀點不會只有單一觀點，使
用者會在文章中不同的段落討論不同的觀點，而傳統的分類方法只會針對文章內容，將
文章分類到一個討論的主題，這樣就不能顯示出這一篇文章的其它主題。因此本研究的
目的希望能夠依據文章的內容自動找出使用者在這些話題文章中討論的觀點，然後將每
一篇文章依照內容與這些觀點的相關性分類文章，讓使用者可以針對不同觀點閱讀屬於
同一觀點的文章。而對於每一篇文章我們會找出多個討論的觀點，而不是只找出單一討
論的觀點。 
 
2.2.2 研究方法 
    本研究方法的系統流程分為三大部份： 
1. 資料蒐集及資料前處理：本研究所採用的資料來源為YAHOO!奇摩新聞－全民話頭
條(http://tw.forum.news.yahoo.com/)；資料前處理包括斷句、斷詞處理及候選面向集
合的產生。 
2. 產生各主題的面向：這一個步驟先是從候選面向集合中選出每一個主題相關的面
向，接著調整面向集合並建立面向的階層架構。 
3. 每篇文章的面向選定：先探勘出每一個面向的擴展相關字詞集合，接著計算面向與
文章的相關性，以此相關性決定文章內容所包含的面向。 
以下將針對各部份詳細說明。 
(1)資料蒐集及資料前處理 
本研究研究所使用之新聞討論文章資料來源為Yahoo!奇摩新聞全民話頭
（http://tw.forum.news.yahoo.com/），我們從論壇中取得的資料有：話題標題及話題中
所有討論的文章。每一篇文章由許多部分所組成，在本研究中只需使用到文章標題及內
文的部分，因此我們必須進行前處理分別取出文章標題和內文的部分。    將文章標題
和文章內文分別取出之後，針對文章內文部分我們還必須進行兩個步驟的處理，第一步
是將文章斷句，因為在之後計算文章與面向的相關性的時候也需要計算句子和面向之相
關性，所以在前處理的部分要先將文章內容依照句子一句一句斷好。由於文章來源檔案
為HTML格式的檔案，因此除了文字、標點符號之外還包含有HTML標籤，如圖3.5所示，
因此我們利用標點符號（,.?!~;，。～；！？等）、html標籤（<br>、<p>、<div>等）及
空格來將文章內容進行斷句。斷句完之後的文章內容，我們再利用事先建立好的約包含
五萬兩千多字的字典及斷詞程式來進行斷詞處理。在此後的處理皆是以此斷句且斷詞完
之後的檔案內容來做為比對、計算的依據。經過斷詞處理若存在字典中的字詞即會被保
留並以空格分隔出來，若字典中沒有的字詞則會被刪去。 
(2) 建立各主題之面向 
(i) 建立候選面向集合:本研究的目標是要找出隱藏在文章內容中的面向，因此可以代表
話題的面向關鍵字必須出現在文章內容中。因此，一開始我們取全部話題主題的文章所
形成的文章集合C，從經過斷句及斷詞處理後的文章內容中計算各字詞cw 的整體文件出
現頻率gdf C (cw)，並刪除gdf C (cw) 值太高或太低的字詞。gdf C (cw) 值太高表示是太廣泛
不具有代表性的字詞，例如：『這個』、『那個』等使用者很常使用的字詞，這一類指
示代名詞或是一些疑問語氣詞出現地很頻繁，且不具有明確的概念含義，因此不能夠用
 6
我們認為若有兩個面向常常出現在同一篇文章中，那麼這兩個面向就很可能是在討
論同樣的一件事。換句話說，如果兩個面向的相關文章集合之交集相對於其相關文章集
合佔很大比例，這兩個面向就有很大的機率為同義字。因此我們檢查兩個面向fA和fB的
相關文章集合RiA和RiB，如果RiA及RiB中各別的交集文章數|RiA∩ RiB|有超過RiA 和RiB 的文
章數一半以上，也就是說|RiA∩ RiB|/|RiA|0.5且|RiA∩ RiB|/|RiB|0.5，就可以進行下一個合併
的步驟。接著檢查fA和fB這兩個面向是否可以合併成一個字詞當面向fA為面向fB的子字
串，或是面向fB為面向fA的子字串，這種情況下只保留字數比較多的面向，刪除字數較
少的面向。若面向fA和面向fB沒有共同的子字串，我們會試著將這兩個面向前後合併組
出一個新的字詞，如果新組出來的詞可以在文章標題中找到，就保留新的字詞，刪除面
向fA及fB。 
(iv)面向集合產生之後，有些面向為涵蓋範圍較大的面向，即該面向所包含的文章集合
較大，被較廣泛的討論。若以這幾個面向來對文章分析所屬面向，則可能大部分的文章
都會被分到與這幾個面向相關，因此無法有效地達到依面向瀏覽的效果。為了解決這一
個問題，我們進一步建立面向的階層架構。對於此種有廣泛含義的面向，我們將這類面
向挑選出來當成上層的面向，這些面向底下再細分成多個與這個面向相關的討論子面
向，以此建立出面向的階層架構。在面向階層架構中，上層的面向含有較廣泛的意義，
而與這個面向相關的文章中，又可以再細分出幾個子面向，為決定哪些面向為上層面
向，因此我們計算任兩個面向fA及fB所組成的關聯規則之確信度值來決定兩個面向是否
有高度的關聯性，以此來架構出階層關係。若conf (f Af B)> conf (f Bf A)，我們可以推出
fB 為上層的面向，fA 為fB 底下細分出的其中一個子面向。反之則fA為上層的面向，fB為fA
底再細分出的其中一個子面向。 
(3)文章面向選定 
(i)面向的擴展字詞探勘: 我們在計算一篇文章或一個句子與面向的相關程度時，若只以
面向這個字詞為依據時，只能以文章或句子中是否出現面向這一個字詞來決定，以此計
算出來的相關度不是1 就是0，只要沒出現該面向關鍵字便被判定與面向不相關。然而
有一些與某一面向關聯性很高的字詞，如果有出現在文章裡面，就算沒有出現該面向關
鍵字，也應該被認為是與該面向相關。所以我們對每一個面向，從該面向之相關文章集
合中找出與該面向有高度相關之字詞集合，以此字詞集當成該面向之擴展字詞集。為取
出與面向fg相關的擴展字詞，我們從面向fg的相關文章集合Rig中的字詞集WRig中挑選出重
要字詞，透過計算WRig中的每一個字詞的tf_idf 數值，以這個數值來決定字詞的重要程
度。若一個字詞的tf_idf 值高，就表示這個字詞在面向fg的相關文章集合Rig中是重要的
詞，也就是這個字詞與面向fg有很高的相關性。在本研究中tf_idf 數值的門檻值設為
0.003，對於面向fg，WRig中每一個字詞cw 皆計算出tf_idfcw值後，若tf_idfcw值有高於這個
門檻值的字詞cw 才會保留做為面向fg的擴展字詞。另外，我們在篩選擴展字詞的時候，
若一個字詞為太常出現或不具代表性的字詞，那麼這個字詞就不會被包含進來，因為這
個字詞很可能跟許多面向都有相關，若在面向的擴展字詞集合中加入這個字詞，在後續
處理裡會無法有效辨別文章內容是和哪一個面向最為相關。此外，若擴展字詞為已存在
面向集合中的其它字詞，也不會被選為擴展字詞，這是因為若將另一個面向fy選為當做
面向fg的擴展字詞，容易造成判斷文章所屬面向時概念重覆性太高，因此我們排除這些
字詞，不將它們選為面向fg的擴展字詞。我們將一個面向fg的擴展字詞集合以Eig來表示，
在稍後計算文章與面向的相關程度的時候，若句子或文章中有出現擴展字詞集合Eig 中
的字詞，就可以視為該句子或文章與面向fg有相關。此外在以面向fg及其擴展字詞集合Eig
計算文章包含面向fg的相關程度時，需要對每個字詞給定一個權重值，這個權重值也表
示該擴展字詞與面向fg的相關程度，若權重值愈大，表示該字詞和面向fg相關性愈高。我
們分配給面向一個權重值a ，然後利用擴展字詞cwx 的tf_idf 值為比例分配各擴展字詞
cwx 的權重值，使得Eig中各擴展字詞的權重值加總值為1a 。 
 8
篇文章的平均Recall 值為0.46。其中約有半數（14篇）文章的Recall值達到0.6以上。以
亂數方式挑選每一篇文章的面向，再計算這個模擬情況的Recall 值為0.35，本研究實驗
的Recall 值為0.46，表示本研究系統的面向挑選結果比隨機選取面向的情況好。 
另外我們想要實驗看看我們的方法用在區分文章主題的應用是否可行，所以在實驗
二我們將多個主題的文章混合在一起，然後從這個混合主題的文章集合中找出面向，同
樣對每一篇文章指定其所屬面向。每一個主題應該具有它特有的、與該主題非常相關，
但和其它主題較不相關的面向，實驗二就是評估當有多個主題的文章混合在一起，系統
是否同樣可以找出這些主題特有的面向。因此我們對每一個面向檢查系統指定具有該面
向的相關文章是否都屬於同一個主題，若面向的相關文章都是同一個主題，表示這個面
向是可以代表該主題的概念。我們以『你支持台獨嗎？』及『菸害防制法新制上路』這
兩個主題下文章的面向分析結果來檢驗找出面向用於文章分群的效果。由這兩個主題所
找出之各個面向，以及系統指定具有該面向之文章數分屬兩個不同主題下所佔的百分比
例值建立統計圖，可看出大部分具有特定面向的相關文章都是屬於同一個主題的文章，
只有少數幾個面向是兩個主題下的文章都有涵蓋，但佔的比例也不高，當這幾個面向剛
好在這兩個主題下的文章中都會有使用者討論到，才會發生這樣的情況。 
 
2.3 動態資料集中常見項目集之變動探勘 [3] 
2.3.1 研究動機 
    以往對動態資料集的研究大多著重在如何有效率的探勘出常見項目集，但若只是對
動態資料持續進行常見項目集探勘，在每一時間列舉出當時出現的常見項目集，在常見
項目集數量繁多時，使用者並不容易直覺得知常見項目集的變化狀況。由於動態資料中
的資料出現狀況可能會隨著時間改變，因此變動資料中的概念變動(concept drift)探勘亦
為一個重要的探討議題。然而以往提出的研究多是以統計分析的觀點來看資料出現分佈
的改變，而較少探討實際常見項目集的變動探勘。若在初始時間提供常見項目集的探勘
結果，接下來的時間點皆提供有哪些常見項目集不再是常見項目集，以及有哪些新產生
的常見項目集，使用者就可以很快的得知常見項目集合的變動狀況。欲提供常見項目集
變動探勘，在以滑動視窗模型為概念的情況下，直覺的作法是由各時間點探勘出常見項
目集再進行比較，來得知狀態產生變動的項目集。這個方法雖然簡單，但要列舉並儲存
各時間點的常見項目集，不僅需要耗費大量的計算成本，亦需要相當大的記憶體空間。
當狀態改變的項目集相對於所有的常見項目集是屬於少數的情況下，則連續探勘出的常
見項目集有大部分是相同的，如果能避免重複探勘這些項目集，就能有效節省計算成本
及記憶體空間需求。 
    為解決上述問題，本研究探討如何能快速找出出現頻率狀態上有變動的項目集之探
勘方法，也就是找出由常見變為非常見，或由非常見變為常見的項目集。另外，為了對
這些狀態上有變動的項目集之變動狀況提供一個整體總結資訊，本研究並進一步探討分
析項目集的變動週期，將變動項目集分類成相對常變動或不常變動，以及相對變動週期
較穩定或是不穩定的類別，以提供使用者更多關於項目集變動特性的資訊。 
 
2.3.2 研究方法 
在目前交易視窗CTWt中包含資料項目集P的交易筆數稱為P在時間點t時的最近支持
度計數值，以SCt(P)表示。當使用者給定一個介於0到1之間的最小支持度門檻值Smin，則
由|CTWt|Smin所得到的值稱為時間點t時的最小支持度計數門檻值SCmin(t)。由於本研
究假設在每個單位時間點 |CTWt|為固定，因此SCmin(t)在個時間點為相等，可簡寫為
SCmin。對一個資料項集P，若SCt(P)大於或等於SCmin(t)，則稱P在時間點t為一個最近常
見項目集；若SCt(P)小於SCmin(t)，則稱P在時間點t時為一個最近非常見項目集。 
隨著時間的改變，最近常見項目集之集合及最近非常見項目集之集合可能發生變
動。令時間點t時，CTWt中最近常見項目集所成之集合以Ft表示，最近非常見項目集所
 10
變動幅度。 
    當變動時間點愈來愈多，為了不將所有變動時間點都儲存下來，對於一個資料項目
集P在一個變動快照可以只儲存各變動時間間隔總和sum=

1
1
n
j
idt 、時間間隔平方和
sqr_sum= 

1
1
2
n
j
idt 及時間間隔個數 |CTt(P)|。而狀態變動項目集的時間間隔平均
avg(CTt(P))及時間間隔變動率cr(CTt(P))可從中推導計算出來。接下來針對S(t/SI)所儲
存之各狀態變動項目集及計算出之時間間隔平均avg(CTt(P))、時間間隔變動率 
cr(CTt(P))，本研究利用k-means分群演算法將S(t/SI)中各項目集之avg(CTt(P))值分成兩
群，區別出狀態變動時間間隔相對較短(Short)及狀態變動時間間隔相對較長(Long)的兩
群；對於各項目集之cr(CTt(P))同樣也以k-means分群演算法分成兩群，區別出狀態變動
時間間隔相對較為穩定(Stable)及狀態變動時間間隔相對較不穩定(Unstable)的兩群。組
合一個項目集P的avg(CTt(P))和cr(CTt(P))在這兩個分群中的結果，可將P分成變動時
間間隔短而穩定(SS)，變動時間短而不穩定(SU)，變動時間間隔長而穩定(LS)，變動時
間間隔長而不穩定(LU)四類。對於在S(t/SI)中只發生一次狀態變動的項目集，由於無法
計算狀態變動時間間隔，因此狀態變動的時間間隔平均為無限大，狀態變動的時間間隔
標準差不存在，因此變動率也不存在，故自成一類，稱為狀態演進(Status Evolution)，
簡稱SE。另外，當項目集在快照記錄期間內只出現兩次狀態變動，或是產生狀態變動的
時間間隔皆相同，此情況下能夠計算出狀態變動的時間間隔平均，但其狀態變動的時間
間隔標準差的值等於0，變動率也等於0，我們將此類型的狀態變動項目集也另外歸成一
類，稱為週期變換(Periodic Shift)，簡稱PS。因此對於S(t/SI)中的狀態變動項目集共可分
為六個類別。 
     隨著時間會累積愈來愈多的狀態變動項目集快照，當產生的歷史快照數量太多
時，便會面臨到儲存空間有限的問題。因此將離目前時間點愈遠的快照資料與鄰近快照
合併，使該快照對應到較長區間內資料的概況，以便有效節省儲存空間。引此本研究引
用研究中所提出之金字塔式時間框架做為儲存快照的架構，此架構以分層的方式儲存記
錄不同區間的快照。其概念是愈接近目前時間點，使用者對資料解析度的要求愈高，對
愈久遠的資料則能接受較為概括的結果，可有效節省快照儲存空間。 
 
2.3.3 實驗評估 
    為顯示本研究方法的執行效能，在實驗中我們的基本比較方法是以FP-growth方法在
每一時間點探勘出滑動視窗中所有的常見項目集，再比較與前一時間點的常見項目集，
找出狀態變動的項目集。綜合實驗結果得知，當交易資料變動不多，或是新增資料集的
資料相較於滑動視窗中的資料為少量時，相較於FP-growth，本研究所提出的CV-SCD演
算法能很有效率的探勘出狀態變動項目集。此外，當資料集中所包含的項目種類愈多，
以及Smin設定值愈小時，相較於FP-growth更能增進狀態變動項目集的探勘效率。加入快
照的資料結構的儲存分析，對於CV-SCD探勘狀態變動項目集的執行效能影響太大，並
能提供使用者狀態變動項目集在指定區間的變動特性分析資訊。 
 
參考文獻 
[1] Chien-Liang Wu and Jia-Ling Koh, Hierarchical Topic-based Communities Construction 
for Authors in a Literature Database,＂Prepare for publication. 
[2] 施佩君, “Mining Multi-facets on News Forums,＂碩士論文, 國立台灣師範大學資訊
工程研究所, 2009. 
[3] 李蕙君, “Mining Recently Frequent Itemsets Change over Data Streams,＂碩士論文, 
國立台灣師範大學資訊工程研究所, 2009. 
出席國際學術會議心得報告 
                                                             
計畫編號 97-2221-E-003-007 
計畫名稱 資料連結探勘技術及其應用之研究 
出國人員姓名 
服務機關及職稱 
  柯佳伶 副教授 
  臺灣師範大學資訊工程系 副教授 
會議時間地點  20-23, April 2009, Brisbane, Australia 
會議名稱 
The 14th International Conference on Database Systems for Advanced 
Applications (DASFAA 2009) 
發表論文題目 
 Concept Shift Detection for Frequent Itemsets from Sliding Windows   
over Data Streams  
 
一、參加會議經過 
國際高等應用資料庫系統研討會(The International Conference on Database Systems for 
Advanced Applications (DASFAA 2009))為國際間資料庫及相關應用領域之學者重要的學術及
技術交流聚會，每年舉辦一次，皆於三或四月間在亞太地區召開，今年已是第十四屆。今年
由澳洲昆士蘭大學主辦，於 4 月 20 日至 23 日，在澳洲布里斯本昆士蘭大學舉行。 
由於此次會議舉行的前兩天適逢周末，因此安排提前兩天到達布里斯本，順道進行旅遊
參訪行程。我於 4 月 17 日晚間在桃園機場搭乘澳航與長榮航空聯營班機直飛澳洲布里斯本，
在當地時間 4 月 18 日上午抵達布里斯本機場。搭乘機場快速列車到達布里斯本市區約三十分
鐘，到達下塌旅館已是中午時分了。 
今年 DASFAA 有四個 workshop 及三場 Tutorial，在第一天為兩個 workshop 的論文以及
Tutorial 各有一個 session 進行，另兩個 workshop 的論文及研討會論文則在第二天到第四天發
表。我此次所被接受的論文: Concept Shift Detection for Frequent Itemsets from Sliding Windows 
over Data Streams，是在其中的 ” The First International Workshop on Mobile Business 
Collaboration (MBC 2009)，並被安排於第三天上午 10:00 的 session 第一位發表。我於 4 月 20
日開始參加會議，第一天主要參加 Tutorial，其講題包括 Techniques for Searching Databases, 
Top-K algorithm & applications, 以及 Knowledge Discovery over the Deep Web, Semantic Web 
and XML，可顯示資料庫近來探討的研究中，資料搜尋與知識擷取仍是很受重視的核心技術。
此篇被接受論文考慮從資料流中滑動視窗探勘最近常見樣式的問題，我們認為在常見樣式沒
有顯著變化的情況下，先前探勘出的常見樣式可以近似代表目前的常見樣式，因此本論文針
對特例資料流和一般化資料流環境提出監視常見樣式的方法 FCDS 和 FCDG，藉由監視滑動
視窗內的樣式出現次數，在每個時間點估算出最新的最近常見樣式集合和先前所探勘出來的
常見樣式集合是否有顯著的改變差異，以提供是否重新進行探勘的判斷。由實做 FCDS 和
FCDG 之實驗結果顯示，監視常見樣式之出現次數及狀態變化情況，可有效偵測出最近常見
Concept Shift Detection for Frequent Patterns from
Sliding Windows over Data Streams
Jia-Ling Koh and Ching-Yi Lin
Department of Computer Science and Information Engineering
National Taiwan Normal University
Taipei, Taiwan
Email: jlkoh@csie.ntnu.edu.tw
Abstract. Many algorithms have been proposed for mining frequent itemsets
from sliding windows over data streams. However, in many practical situations
where the data arrival rate is very high, continuous mining the data sets within a
sliding window is unfeasible. For such cases, we propose an approach whereby
the data stream is monitored continuously to detect any occurrence of a concept
shift. In this context, a “concept-shift”means a significant number of frequent
itemsets in the up-to-date sliding window are different from the previously
discovered frequent itemsets. Our goal is to detect the notable changes of
frequent patterns according to an estimated changing rate of frequent itemsets
without having to perform mining of the frequent itemsets at every time point.
The mining algorithm is required to discover the complete set of new frequent
patterns only when any significant change is observed. The experimental results
show that the proposed methods detect concept shifts of frequent patterns both
effectively and efficiently.
Keywords: Frequent Itemsets, Data Streams, Change Detection.
1 Introduction
Frequent itemset mining is well recognized as a fundamental problem in important
data mining tasks such as finding sequential patterns [11], [12], clustering [13], and
classification [9]. Since the problem was first identified by Agrawal et al. [1], many
efficient algorithms for mining frequent itemsets on static databases have been
proposed over the last decade [4], [5].
In recent times, data stream mining has received more attention due to the
increasing number of streaming applications such as web log and click-stream mining,
network traffic analysis, market-basket data analysis, and sensor networks. Unlike
mining static databases, mining data streams presents many new challenges. Since the
amount of data over a data stream has no theoretical boundary, it is unrealistic to keep
the entire stream. Accordingly, the traditional methods of mining static datasets using
multiple scans are unfeasible. Additionally, a great deal of processing power is
required to keep up with the high data arrival rate.
only when any significant change is observed.
In a sliding window model, when the window slides, the previously discovered
frequent itemsets which are no longer applicable within the new window can be
obtained by monitoring their change in frequency over windows. However, the
difficulty lies with incrementally discovering the newly generated frequent itemsets
without keeping their previous counts. To handle such a challenge, this paper applies
the power-law distribution of supports for itemsets to estimate the amount of newly
generated frequent itemsets. Furthermore, two Frequent itemsets Change Detection
methods, FCDT and FCDB, are proposed to monitor the changing ratios of frequent
itemsets over a data stream based on a sliding window updated per Transaction and
updated per Batch, respectively. The experimental results show that FCDT and FCDB
can detect concept shifts of frequent patterns both effectively and efficiently. The
execution time of FCDT and FCDB is significantly less than the time required to
mine frequent patterns over a sliding window at each time point. Furthermore, the
information of frequency change for frequent patterns is provided from the
maintained data structures.
The remaining sections of this paper are organized as follows. The problem of
concept-shift detection for frequent patterns is defined in Section 2. In Section 3 and 4,
the proposed data structures and monitoring methods of the FCDT and FCDB
algorithms are introduced. The performance study is reported in Section 5, which
shows the effectiveness and efficiency of the proposed methods. Finally, in Section 6,
we conclude this paper and discuss directions for our future studies.
2 Problem Definition
Let I = {i1, i2, …, im} denote the set of items in the specific application domain where
a transaction is composed of a set of items in I. A basic block is a set of transactions
arriving within a fixed unit of time. A data stream, DS = [B1, B2, …), is a continuous
sequence of basic blocks, where each basic block Bi, associated with a time identifier i,
consists of a various number of transactions {Ti1, Ti2,…,Tij}. A special case occurs
when there is exactly one transaction in each basic block, which is categorized into a
data stream being updated per transaction [3]. The general case is a data stream being
updated per batch. Let DS[i,j] denote the set of transactions collected from basic
blocks of DS from time i to j. Under a predefined window size w, the sliding window
at time t, denoted as SWt, corresponds to DS[t-w+1, t]. The number of transactions in
SWt is denoted as |SWt|. Supposing that t’denotes current time, the corresponding
window SWt’is named current sliding window.
An itemset (or a pattern) is a set consisting of one or more items in I, that is, a non-
empty subset of I. The number of elements in an itemset p is called the length of p. If
the itemset p is a subset of transaction T, we say that T contains p. The number of
transactions in SWt which contain e is named the support count of p over DS at t,
denoted as SCt(p). Given a user specified minimum support threshold between 0 and 1,
denoted as Smin, an itemset p is called a frequent itemset at t over DS if SCt(p) 
Smin×|SWt|. Otherwise, p is an infrequent itemset at t. In the following, Smin×|SWt|
is known as a minimum support count threshold, which is denoted as SCmin.
Let t’denote the current time identifier. Since only frequent itemsets at time t are
maintained in the PM-tree, when a pattern not in Ft appears at t’(t’>t), its support
count within the sliding window SWt’is unknown. However, for each itemset p, it
satisfies the following inequality:
SCt’(p)min({SCt’(Ii) | Iip}). (2)
Therefore, an auxiliary array, THead, is maintained to keep the support count of each
single item at the current sliding window, which is used to estimate the upper bound
of the support count for a new pattern in the monitoring process.
3.2 The Pattern Monitoring Process of the FCDT Algorithm
The pattern monitoring process starts from the next time point after the PM-tree is
constructed. Initially, all the patterns in the PM-tree belong to Ft. During the pattern
motoring process, in addition to maintaining the information of the support count and
the changing status of patterns in the PM-tree, the patterns recently inputted are
inserted into the tree if they become frequent according to their estimated support.
However, each pattern which does not belong to Ft will be removed from the PM-tree
when it becomes infrequent.
For estimating the ratio of frequent patterns which change, two types of counters
are used to record the amounts of the status changing patterns. The variable
removenum is an integer, which is used to count the number of patterns in Ft
-(t’).
Moreover, an integer array, addnum, is used to maintain the number of newly
generated candidates of frequent itemsets according to their increased support counts.
There are two tasks in maintaining the changing information of patterns when the
window slides: the first is to append the newly inputted transaction, and the second is
to remove the expired transaction. These tasks are described in detail below.
1) Appending the newly inputted transaction Tt’
For each item contained in Tt’, the corresponding entry in THead is increased by 1.
For each itemset p contained in Tt’, the PM-tree is searched to find the
corresponding node Np. If node Np exists in the PM-tree, the value of Np.fd is
increased by 1. Additional processing is required for updating the pattern changing
counters according to the value of Np.R:
<1> Np.R=0: That is, p belongs to Ft. If Np.C is equal to 1, it means that pattern p
has become infrequent in an earlier stage. In this case, the newly inputted
transaction will make p return to being frequent if the value of Np.fd is 1.
Consequently, removenum is reduced by 1 and Np.C is set to 2. If Np.C is equal
to 0 or 2, either p remains a frequent pattern or p became frequent from
infrequent. For these two cases, the pattern changing counters remain
unchanged.
<2> Np.R=1: That is, p does not belong to Ft. If the node of p existed in the PM-tree,
the cumulated count of p starting at t is increased from (Np.fd-1) to Np.fd.
Therefore, the counter addnum[Np.fd] is increased and addnum[Np.fd-1] is
reduced.
frequent itemsets, |Ft
+(t’)|, is also highly-estimated. For solving this problem, the
power-law relationship appears in the distribution of supports of itemsets is used to
adjust the value of |Ft
+(t’)|.
In [13], the author identified that the power-law relationship appears in the
distribution of supports of itemsets. Let si denote a value of the support count and fi
denote the number of itemsets with their support counts being equal to si. The power-
law relationship is described by the following equation:
log(fi) =log(si)+. (3)
In other words, the amount of patterns with a specific support can be estimated after
the characteristics of the power-law relationship are extracted.
Among the frequent itemsets at t, which are known, the number of frequent patterns
with support count si is counted and denoted as fi. By sampling (fi, si) pairs of frequent
itemsets, the parameters and  in the power-law relationship are extracted after
solving the linear regression problem. Accordingly, when assigning a value k
(SCmin>k1) to si, the number of infrequent patterns with support count being k is
approximately estimated. An auxiliary array PLArray is used to store these values,
where PLArray[k] keeps the estimated value of the number of patterns with support
count being equal to k.
During the pattern monitoring process, the addnum array cumulates the number of
possible newly generated frequent itemsets according to their appearance frequency
after time t. In other words, for each pattern which contributes one count in addnum
[k], it appears k times after t. If it actually becomes a frequent itemset, its support
count at t must be no less than (SCmin-k).
Let addnum_up[k] denote the number of new frequent patterns with appearance
frequency k after time t. Accordingly, the value of addnum_up[1] must be no more
than both addnum[1] and PLArray[SCmin-1]. Thus, addnum_up[1] is set to be the
smaller value of addnum[1] and PLArray[SCmin-1]. In general, the value of
addnum_up[k] is obtained according to the following equation:
addnum_up[k]=min(addnum[k], PLArray[SCmin-k]+


1
1
k
i
di),
where di = (PLArray[SCmin-i]- addnum_up[i]) if PLArray[SCmin-i]> addnum_up[i],
otherwise, di =0. (4)
Consequently, |Ft
+(t’)|is estimated using the following equation:
|Ft
+(t’)|= 


1
1
minSC
k
addnum_up[k] (5)
On the other hand, |Ft
-(t’)|is obtaineddirectly from the value of removenum.
Finally, the value of FChanget(t’) is estimated using equation (1) defined in section
2 to decide whether a concept shift of frequent patterns occurs. If FChanget(t’) is
under the given threshold value, the monitoring process continues. Otherwise, the task
of frequent pattern mining is triggered to discover the complete set of frequent
itemsets in SWt’. After resetting the monitoring environment, including resetting t to
Two tasks exist for maintaining the changing information of patterns when the
window slides: the first is to process the newly inputted block, and the second is to
remove the expired block. Let t’ denote the current time identifier.
1) Append the newly inputted block Bt’={Tt’1, Tt’2,…,Tt’j}
For each item contained in Tt’i, the corresponding entry in THead is increased by 1.
For each itemset p contained in Tt’i, the PC-tree is searched to find the
corresponding node Np. If node Np exists in the PC-tree, the value in Np.fd is
increased by 1. Otherwise, a new node Np of pattern p with Np P=p and Np fd =1 is
inserted into the PC-tree.
2) Remove the expired block Bt’-w={T(t’-w)1, T(t’-w)2,…,T(t’-w)k}
For each item contained in T(t’-w)i, the corresponding entry in THead is reduced by 1.
For each itemset p contained in T(t’-w)i, if the corresponding node Np exists in the
PC-tree, the value of Np.fd is reduced by 1. Otherwise, a new node Np of pattern p
with Np P=p, Np fd =-1 is inserted into the PC-tree.
4.3 The Modified Estimation Method of the Changing Ratio
In a data stream which is updated per batch, the number of transactions in a block
is not fixed. Whether the frequency status of a pattern at t’ with respect to t is changed
not only depends on its cumulated count, but also on the size of SWt’with respect to
SWt.
For each node Np in the PC-tree, let p denote the pattern stored in Np.P. The
changing trend and changing status of the pattern p att’with respect to t are defined
according to Np.fd and the sizes of SWt and SWt:
<1>If Np.fd 0, the changing trend of the pattern p at t’ with respect to t is
“increased”. Otherwise, the changing status of pis “decreased”. 
<2>If
min
'
.
S
SWSW
fN
tt
dp 

, the changing status of p at t’ with respect to tis “frequent”.
Otherwise, the changing status of p is“infrequent”.
The possible status changing cases for pattern p are shown in Table 1.
Accordingly, the PC-tree is traversed to visit each node Np. For each node Np, the
BP-tree is searched to find the corresponding node of Np.p to get the status of p in SWt.
By combining the cases of changing trend and changing status of p, the possibility of
status change for p in SWt’, with respect to the status of p in SWt, is determined as
shown in Table 1. If the status change of p is possible, further verification is required:
<1> p is in the BP-tree: Let N’ denote the node of p in the BP-tree. Consequently,
SCt’(p) is obtained by adding Np.fd and N’.f. If SCt’(p) is larger than or equal to
Smin×|SWt’|, p remains a frequent pattern at t’. Otherwise, the status of p has
changed. The counter removenum is increased by 1.
<2> p is not in the BP-tree: Since the support count of p at t is not maintained, it is
estimated using methods similar to those described in the previous section. That
is, SCt’(p) is set to the smaller value between UBt’(p) and (Smin×|SWt|-1+Np.fd).
If SCt’(p) is less thanSmin×|SWt’|, the status of p remains infrequent. Otherwise,
In the following two subsections, the accuracy of the estimated changing ratios
and execution time were measured to show the effectiveness and efficiency of the
proposed FCDT and FCDB algorithms.
5.1 Experimental Results of the FCDT Algorithm
The experiments presented here used the dataset T5I4D60K to simulate a data stream
with a transaction occurring at every time point. Furthermore, the following
experiments were performed with Smin = 0.03 and w = 1000. The FP-growth algorithm
is used to discover frequent itemsets from a sliding window at every time point.
Consequently, with respect to the time when the sliding window is full initially, the
true frequent pattern changing rates at the following time points are obtained to
evaluate the accuracy of the ones estimated by the FCDT algorithm. The execution
time of the FCDT was compared against the performance of the FP-growth algorithm
over each sliding window.
As stated in section 3.3, to estimate the amounts of infrequent itemsets with various
supports at t, the parameters of the power-law relationship are extracted by solving
the linear regression problem. In order to reduce the cost of computation, only part of
the (fi, si) pairs of frequent itemsets at t are selected to solve parameters θand Ω in
equation (3). In the first experiment, we observe how the amount of selected pairs
influences the accuracy of the estimated changing ratio. Let the real changing ratio be
known as“real”. A curve denoted by“SCminn”represents the estimated result of the
FCDT obtained by selecting samples of (fi, si) with SCminn fi SCmin. When n is
varied from 2, 4, 6, 8, to 10, the results of the estimated changing ratios are shown in
Figure 1(a). As indicated in the figure, when n increases, the estimated result
approaches the real value. However, the results of n = 6, 8, or 10, are almost identical.
Accordingly, in the following experiments, n = 6 is used as a base for selecting (fi, si)
pairs to solve the parameters in the power-law distribution of supports of itemsets.
According to the results of the previous experiment, it is observed that the
estimated distribution of supports of itemsets is highly-estimated according to the
solved parameters. Therefore, given the selected values of fi, the standard derivation
of the estimated values and real values of si is computed to compensate for the
estimation error from the estimated values of si. The obtained experimental result is
shown in Figure 1(b), where the curve is labeled with “SCmin6-SD”.
For simulating the occurrence of changes in frequent patterns, two data sets, TD1
and TD2, consisting of 1000 transactions, are generated individually. Let the initial
sliding window contain the data of TD1. After frequent itemsets in the initial window
are discovered, the pattern monitoring process begins. At the beginning, from time
point 1 to 1000, the data in TD1 is inputted. From time point 1001 to 2000, 90% of
the data comes from TD1 and 10% of the data comes from TD2. From time point
2001 to 3000, half of the data comes from TD1 and the other half comes from TD2. It
is indicated in Figure 1(c) that the trend of estimated changing ratios is consistent
with the trend of their real values. The average error of the estimated values for
changing ratios is 0.025.
To evaluate the performing efficiency of the FCDT, the cumulated execution times
of the FCDT and FP-Growth at every 100 time points is measured as shown in Figure
00.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
1 3 5 7 9 11 13 15 17 19 21 23 25 27 29 31 33 35 37 39
Block Number
C
ha
ng
in
g
R
at
io
.
real
FCDB
0
0.5
1
1.5
2
2.5
3
3.5
0 5 10 15 20 25 30 35 40
Ex
ec
ut
ion
Tim
e
(se
c.)
Block Number
FCDB
real
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
1 4 7 10 13 16 19 22 25 28 31 34 37 40
Ch
an
gi
ng
Ra
tio
Block Number
real
*6
*6-SD
(a)
(b)
(c)
Figure 2. The experimental results of the FCDB.
1(d). The time required by the FCDT is almost 1/100 of the cost required by FP-
Growth to discover complete frequent itemsets.
5.2 Experimental Results of the FCDB Algorithm
In set of experiments, the dataset T5I4D60K is used to simulate a data stream with
each basic block consisting of 1000 transactions. Furthermore, when running the
FCDB algorithm, the parameters Smin and w are set to be 0.02 and 20, respectively. By
minSC
minSC
