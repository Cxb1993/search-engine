1 
 
行政院國家科學委員會補助專題研究計畫
成果報告   
□期中進度報告 
 
棒球比賽影片內容與網路轉播文字之對應 
 
計畫類別：個別型計畫   □整合型計畫 
計畫編號：100-2221-E-415-017- 
執行期間：  100 年 8 月  1 日至 101  年 7 月 31  日 
 
執行機構及系所：國立嘉義大學資訊工程系 
 
計畫主持人：邱志義 
共同主持人： 
計畫參與人員：謝承宇、李勝暘、蔡宗翰、蔡雨龍 
 
 
成果報告類型(依經費核定清單規定繳交)：精簡報告  □完整報告 
 
本計畫除繳交成果報告外，另須繳交以下出國心得報告： 
□赴國外出差或研習心得報告 
□赴大陸地區出差或研習心得報告 
出席國際學術會議心得報告 
□國際合作研究計畫國外研究報告 
 
 
處理方式：除列管計畫及下列情形者外，得立即公開查詢 
            □涉及專利或其他智慧財產權，□一年□二年後可公開查詢 
 
中   華   民   國  101 年  10 月  31  日 
  
3 
 
high risk to deal with a new scoreboard pattern that 
is different from the templates or violates the rules. 
Moreover, the scoreboard is not always superim-
posed on video frames; sometimes there is no 
scoreboard to be recognized. 
The machine learning technique is also widely 
used in baseball event detection. Unlike the score-
board recognition technique, the machine learning 
technique tries to characterize the context between 
shots by some probabilistic models. Chang et al. [5] 
conducted hidden Markov models (HMMs) to de-
tect baseball events. They classified the video shots 
into predefined states, and HMMs were employed 
to learn the state transition probability. Four HMMs 
were designed for classifying four events: home run, 
catch, hit, and diamond play. The paradigm is gen-
erally followed by subsequent studies with some 
modifications [6][7]. Since the machine learning 
technique only use low-level audiovisual features, 
without the help of the high-level semantic infor-
mation, it is difficult to distinguish some ambiguous 
cases. That is why the machine learning technique 
detects fewer events than the scoreboard recogni-
tion technique does. Overall speaking, the two 
event detection techniques require a great deal of 
human effort to collect, analyze, and label video 
content. They work well for the cases conforming 
the predefined rules and training models but have 
difficulty handling unknown cases. 
In this study, we propose a novel annotation 
framework for baseball videos by utilizing both 
video content and webcast text. The annotation 
problem is transformed to find the alignment be-
tween video content and webcast text. Several cues 
are extracted from both video content and webcast 
text, including batter counts, batter image similarity, 
video length estimation, change of 
left-handed/right-handed batter, and event likeli-
hood, and they are fused through the proposed ge-
netic algorithm optimization methods. We consider 
that integrating webcast text in video content analy-
sis can effectively improve the generality and ro-
bustness of the work. Experiment results on a vari-
ety of baseball video content validate our view-
point. 
 
II. Framework Overview 
Let  be a half-inning in a baseball game; V 
= {(PS1, ES1), (PS2, ES2), ... , (PSN, ESN)} be the 
video content of  with N pairs of pitch segments 
(PS) and event segments (ES); and W = {WT1, 
WT2, ... , WTM} be the webcast text of  with M 
webcast text items (WT), each of which corresponds 
to a batter’s at bat event; N  M. Our objective is to 
map each of N video segment pairs {(PSi, ESi)} to 
one of the text items {WTm} correctly, denoted as 
PSi  WTm; it means the mth batter’s at-bat event 
WTm can be tagged to the ith video sequence (PSi, 
ESi). We call this annotation task the alignment 
problem between video content and webcast text of 
baseball videos. 
The alignment problem can be formulated as a 
bipartite graph that models the mapping relation 
between V and W. The mapping is expressed by 
an onto function f: V  W, where each ele-
ment in W is mapped to at least one element in 
V . Note that the mapping cannot be a crossing, 
i.e., 
    
            

          
                                 .   (1) 
 
Figure 1 shows a mapping relation between video 
content and webcast text. 
5 
 
with M webcast text items, and N >> M generally. 
We present two alternative methods to solve the 
alignment problem. The first method is batter clus-
tering, which applies hierarchical agglomerative 
clustering to merge batter images based on their 
SIFT-Bag descriptors. The clustering stop criterion 
is set according to the number of batters recorded in 
W. The second method utilizes a genetic algo-
rithm for the alignment. An objective function is 
formulated based on the similarity measures of 
video content and webcast text cues, including bat-
ter images, video length estimation, change of 
left-handed/right-handed handed, and event likeli-
hood. The genetic algorithm searches for the solu-
tion that best fits the objective function through the 
evolutionary process. 
 
III. Experiments 
To evaluate the proposed framework, we com-
piled a video dataset for use in several experiments. 
Dozens of baseball games played in the MLB 2008 
regular season were recorded from TV broadcasts 
as our baseball video dataset. They vary in terms of 
the teams, stadiums, and broadcasting channels. 
The   t set’s  orm t  s 720480 frame pixels and 
29.97 frames per second. The corresponding 
webcast text for the recorded games was down-
loaded from the MLB official website 
(http://www.mlb.com). 
Twenty half-innings of ten games and two 
full-length games were selected from our video da-
taset to evaluate the proposed HAC and GAO 
alignment methods. The configuration of GAO was 
set as follows: chromosome population size 32, 
crossover probability 0.75, mutation probability 
0.0075, and maximal evolution iterations 20. Four 
GAO’s measures, including batter image similarity 
(BS), video length estimation (VL), change of 
left/right handed batters (LR), event likelihood (EL), 
were evaluated individually. 
The experiment results are summarized in Table 
I. The first column lists the dates of the ten test 
games, which are played by different teams, held in 
different stadiums, and broadcast by different 
channels. The second column gives the inning in-
formation, including the number of ground-truth 
pitch segments (G), the number of detected pitch 
segments (N), and the number of individual batters 
(M). The remaining columns show the accuracy 
rates of the HAC and GAO methods. Each field has 
two rates: the Hamming similarity and the Jaccard 
coefficient. 
 
IV. Conclusions 
Conventional baseball annotation frameworks 
do not utilize webcast text effectively, and existing 
multimodal fusion frameworks do not fit baseball 
videos very well. To address the above issues, we 
present a novel framework for baseball video anno-
tation based on aligning video content and webcast 
text. The alignment problem can be resolved by the 
proposed genetic algorithm optimization method, 
which integrates multimodal cues from both 
low-level video content and high-level webcast text. 
In addition, an unsupervised method based on 
Markov random walk is developed for pitch seg-
ment detection to reduce the need for human inter-
ventions. Experiments on various video content 
styles of baseball games show a robust result 
against a variety of video content and high automa-
ticity in baseball annotation. 
Actually, webcast text preserves many detailed 
information occurred in a baseball game, for exam-
ple, each batter’s pitch count and each pitch’s speed, 
type, and event. The future work can exploit each 
pitch’s information in webcast text to find its cor-
responding video segments, so that we can provide 
detailed event retrieval and browsing functions for 
baseball videos. 
 
7 
 
Reference 
[1]  C. Xu, Y. F. Zhang, G. Zhu, Y. Rui, H. Lu, and 
Q. Huang, “Using webcast text for semantic 
event detection in broadcast sports video,” 
IEEE Trans. Multimedia, Vol. 10, No.7, pp. 
1342-1355, 2008. 
[2]  H. Xu and T. S. Chua, “Fusion of AV features 
and external information sources for event de-
tection in team sports video,” ACM Trans. 
Multimedia Comput. Commun. Applicat., Vol. 
2, No. 1, pp. 44-67, 2006. 
[3]  M. H. Hung and C. H. Hsieh, “Event detection 
of broadcast baseball videos,” IEEE Trans. 
Circuits Syst. Video Technol., Vol. 18, No. 12, 
pp. 1713-1726, 2008. 
[4]  W. T. Chu and J. L. Wu, “Explicit semantic 
events detection and development of realistic 
applications for broadcasting baseball videos,” 
Multimedia Tools and Applications, Vol. 38, 
No. 1, pp. 27-50, 2008. 
[5]  P. Chang, M. Han, and Y Gong, “Extract high-
lights from baseball game video with hidden 
Markov models,” In Proceedings of IEEE In-
ternational Conference on Image Processing 
(ICIP), Vol. 1, pp. 609-612, New York, USA, 
Sep. 22-25, 2002. 
[6]  R. Ando, K. Shinoda, S. Furui, and T. Mochi-
zuki, “A robust scene recognition system for 
baseball broadcast using data driven approach,” 
In Proceedings of ACM International Confer-
ence on Image and Video Retrieval (CIVR), pp. 
186-193, Amsterdam, The Netherlands, Jul. 
9-11, 2007. 
[7]  C. C. Cheng and C. T. Hsu, “Fusion of audio 
and motion information on HMM-based high-
light extraction for baseball games,” IEEE 
Trans. Multimedia, Vol. 8, No. 3, pp. 585-599, 
2006. 
[8]  N. Dalal and B. Triggs, “Histograms of ori-
ented gradients for human detection,” In Pro-
ceedings of IEEE International Conference on 
Computer Vision and Pattern Recognition 
(CVPR), pp. 886-893, San Diego, USA, Jun. 
20-26, 2005. 
[9]  X. Zhou, X. Zhuang, S. Yan, S. Chang, M. 
Hasegawa-Johnson, and T. S. Huang, 
“SIFT-Bag kernel for video event analysis,” In 
Proceedings of ACM International Conference 
on Multimedia (ACM-MM), pp. 229-238, 
Vancouver, Canada, Oct. 26-31, 2008. 
[10] D. G. Lowe, “Distinctive image features from 
scale-invariant keypoints,” Int. J. Comput. Vi-
sion, Vol. 60, No. 2, pp. 91-110, 2004. 
[11] C. Liang, C. Xu, and H. Lu, “Personalized 
sports video customization using content and 
context analysis,” International Journal of 
Digital Multimedia Broadcasting, pp. 
836357:1-20, 2010. 
 
2 
 
著去克服多年來人工智慧與機器學習所面臨的挑戰：機器可以推導出人類的知識結構嗎？目前不
行，因為有太多的變因參數需要去考慮，其規模通常遠大於訓練用的資料量。過去類神經網路試
著模擬人類大腦的結構來進行訓練，但是因為效能上的考量，通常神經元的連結只有兩至三個階
層。然而此一問題在 2006 年出現關鍵性的突破，學者們開始提出新的訓練方式與結構，自此 deep 
learning 躍上學術研究的主流議題，並應用在許多非監督式學習的應用之上。此一教學性質的演
講著實令人獲益非淺。 
 
  (2011/10/20)第 2天下午 15:00 – 16:40 是有關 Image/Video 分析處理的特別議程，是本人口頭
發表論文的場次，由葉家宏教授主持。由於葉教授也有鑽研究過棒球影片註解的議題，在會中我
們對此議題分享許多經驗，另外也有大陸與日本的學者提問交換意見。同一場次還有台灣的學者
鐘國亮教授發表論文，題目是 “Local brightness preservation for dynamic histogram equalization”。
此一技術在影像處理上非常實用，會後也進一步向鍾教授和他的學生交流請益，頗有收穫。 
 
二、與會心得 
APSIPA 吸引來自亞太各地，尤其是亞洲區的學者專家齊聚一堂共同研討，安排了多場教學性質
的演講，除了提供學術與經驗之交流外，亦可藉此機會結識志同道合的朋友。國內與會人士主要
是以電機系較多，讓本人有機會多接觸電機相關之基礎理論與實務研究，進而增進彼此視野及後
續之交流，實屬難得的經驗，令人獲益良多。 
 
三、考察參觀活動(無是項活動者略) 
略 
 
四、建議 
略 
 
五、攜回資料名稱及內容 
本次會議攜回一張光碟片，收錄本會出版之論文集。論文集名稱：Proceedings of Asia-Pacific Signal 
and Information Processing Association Annual Summit and Conference 2011 (APSIPA 2011)。 
 
六、其他 
略 
12/9/19 https://mail.ncyu.edu.tw/cgi-bin/msg_read?cmd=print_mail&m=34889550&mbox=@.05&msgid=90_6…
https://mail.ncyu.edu.tw/cgi-bin/msg_read?cmd=print_mail&m=34889550&mbox=@.05&msgid=90_6…
status of each registering author) for the abstract to be listed in the Student Symposium programme. Please
note that student symposium paper will not appear in the Conference Proceedings.
3. One of the authors MUST ATTEND the conference to present the work.
Detailed Registration Guidelines (fees and steps) will be available very soon. We will notify you via email and
conference website as soon as they are ready.
======
At the mean time, you are cordially invited to attend the tutorials scheduled within the activities of APSIPA
ASC 2011. The tutorials will be delivered by world renowned researchers in their fields and will be very
beneficial to attendees. To encourage more people to attend the tutorials, the registration fee is decided to be
minimal. Please refer to www.apsipa2011.org/tutorials.html for more details about the topics.
======
Finally, congratulations on your fine work!  Look forward to welcoming you in Xi’an!
Best Regards,
Thomas Fang Zheng
APSIPA ASC 2011 General Co-Chair
Yanning Zhang
APSIPA ASC 2011 Technical Program Co-Chair and Coordinator
APSIPA ASC 2011 Website: http://www.apsipa2011.org
Hosted by Northwestern Polytechnical University and Tsinghua University
We treat the mapping as an optimization problem and seek for 
the best solution by the genetic algorithm. An objective 
function is formulated to consider the similarity measures 
with respect to the batter image similarity, video length 
estimation, change of left/right handed batters, and event 
likelihood. The genetic algorithm searches for the solution 
that best fits the objective function through a mimicked 
evolution process. Finally, the mapping is expressed as 
ሼ Φ݂ሺܲ ௜ܵ, ܧ ௜ܵሻ ൌ ܹ ௠ܶ ሽ 
where i = 1, 2, ... , N and m = 1, 2, ... , M. The webcast text 
item WTm for the mth batter can be tagged to the ith video 
sequence (PSi, ESi). For simplicity, we write PSi → WTm for 
the mapping hereafter. 
IV. CONTENT ANALYSIS 
Given a half-inning of a baseball video, we first apply an 
unsupervised method based on Markov random walk to detect 
pitch segments [2]. Then, based on the detected pitch 
segments, we extract the batter information from them. The 
objective is to represent each batter with a discriminative 
feature, so that we can categorize pitch segments according to 
their respective batters. The extraction includes two steps, 
namely, batter detection and feature extraction. A human 
detection method based on histogram of oriented gradients 
(HOG) [4] is used as a batter detector. We use the batter 
detector to locate batters in pitch segments PSi ∈ Φ, i = 1, 
2, ... , N, where N is the number of the detected pitch 
segments in Φ. 
Denote the detected batter image sets in PSi as BIi. For each 
of the batter image sets, a SIFT-based feature is employed to 
characterize. Since the SIFT-based feature is a sparse 
representation of image keypoints, it would be more 
discriminative for low-resolution batter images than the HoG 
descriptor. In this study, we employ a modified version of the 
SIFT-Bag descriptor [8] to represent the batter feature as 
follows. We employ k-means clustering to partition the SIFT 
feature space at the global clustering step. Let SKi be a set of 
SIFT feature vectors extracted from batter image set BIi. The 
training corpus is all SIFT feature vectors in the half-inning Φ, 
i.e., {SKi | i = 1, 2, ... , N}. k-means clustering is applied on 
the training corpus to obtain K global cluster centers, denoted 
as {GCk | k = 1, 2, ... , K}. At the specialized clustering step, 
we adapt the batter image set based on the global cluster 
centers. Each SIFT keypoint of SKi is assigned to its nearest 
global cluster centers. The specialized cluster center SCi,k is 
obtained: 
ܵܥ௜,௞ ൌ ܿ݁݊ݐሺሼܵܭ௜,௞ሽሻ, 
where SKi,k is the subset of SKi whose elements are assigned 
to GCk, and cent(⋅) returns the centroid of the set, i.e., the 
average of the set. Consequently, the ith batter image set BIi is 
characterized by the SIFT-Bag descriptor with K specialized 
cluster centers, denoted as SBi = (SCi,1, SCi,2, ... , SCi,K). Figure 
1 shows a SIFT-Bag example of a batter image set. 
 
  
(a)                                                        (b) 
Figure 1.  A SIFT-Bag example: (a) SIFT keypoints of a batter 
image; (b) the SIFT-Bag descriptor SBi of the ith batter image set BIi. 
V. GENETIC ALGORITHM OPTIMIZATION 
We propose to use the genetic algorithm (GA), a 
probabilistic global search technique, to find the solution of 
matching VΦ and WΦ. In GA, the solution domain is encoded 
as chromosomes, and their fitness scores are evaluated by an 
objective function. By mimicking the nature evolution of 
selection, mutation, and crossover, GA assumes a population 
of chromosomes will evolve toward the best fitness, i.e., the 
best solution. 
We define the representation scheme of chromosomes in 
this study. Let A ∈ {1, ... , M} be a alphabet set, where M is 
the number of batters in the half-inning Φ (recorded in 
webcast text). Each chromosome x ∈ AN is an alphabet string 
of length N, where N is the number of pitch segments in Φ 
(detected from video content). xi, the ith alphabet of x, 
represents the batter index of the ith pitch segment PSi. x is a 
sorted string, i.e., xi ≤ xj for i < j. We take an example to 
illustrate the representation scheme. Suppose there are three 
batters and nine pitch segments in Φ; we have A = {1, 2, 3} 
and N = 9. A chromosome "111223333" represents the 
candidate solution of the mapping relation: {PS1, PS2, PS3} → 
WT1, {PS4, PS5} → WT2, and {PS6, PS7, PS8, PS9} → WT3. 
To initialize GA, we randomly select a set of chromosomes 
as the first population. The evolution operations are applied 
on the population and suitable chromosomes are selected to 
produce the next population. The selection is based on an 
objective function f(x) that evaluates the fitness of 
chromosome x. The roulette-wheel scheme is employed to 
select chromosomes the population into a mating pool with 
probabilities proportional to their fitness, and the one-point 
crossover operation is used to generate offspring 
chromosomes from the mating pool. The mutation operation 
randomly changes a chromosome's alphabet in the mating 
pool with a predefined probability. In addition, we apply the 
elitism mechanism that copies the best-so-far chromosomes 
into the new population. 
A critical issue of GA is the objective function f(x). In this 
study, we define f(x) as a blending function that fuses 
multimodal information: 
݂ሺݔሻ ൌ ߙ · ܤܵ௫ ൅ ߚ · ܸܮ௫ ൅ ߛ · ܮܴ௫ ൅ ߩ · ܧܮ௫. 
BSx, VLx, LRx, and ELx are the measures of chromosome x 
with respect to batter image similarity, video length 
estimation, change of left/right handed batters, and event 
likelihood, respectively; α, β, γ, and ρ are the corresponding 
coefficients in the interval [0, 1], and α + β + γ + ρ = 1. These 
measures are detailed in the following subsections. 
a SIFT-Bag kernel through a SVM for each event-category 
classifier. 
We selected six half-innings of three games from our video 
dataset for this experiment. The configuration of the genetic 
algorithm was set by the chromosome population size 32, 
crossover probability 0.75, mutation probability 0.0075, and 
maximal evolution iterations 20. We further list five 
combinations of measures in the genetic algorithm: batter 
image similarity only (BS), video length estimation only (VL), 
change of left/right handed batters only (LR), event likelihood 
only (EL), and all measures combined (ALL). The quadruple 
parameters (α, β, γ, ρ) for GAO's combinations are BS: (1, 0, 
0, 0), VL: (0, 1, 0, 0), LR: (0, 0, 1, 0), VL: (0, 0, 0, 1), and 
ALL: (0.05, 0.35, 0.3, 0.3). 
Given the video content and webcast text of a half-inning 
as input, the proposed methods will yield an alphabet string as 
output, i.e., the mapping ݔכ ൌ ൛ݔ௜כ|݅ א ሼ1,2, . . . , ܰሽ, ݔ௜כ א
1,2,...,ܯ, where ݔ݅כ is the batter index of the ith pitch segment, 
N is the number of pitch segments, and M is the number of 
batters in the half-inning. Let ݔො  be the ground truth of the 
half-inning. The similarity between ݔො and ݔ௜כ is defined based 
on the Hamming distance 
ܪܵሺݔො, ݔכሻ ൌ 1 െ
∑ ሺݔො௜⊕ݔ௜כሻே௜ୀଵ
ܰ
 
where ⊕ is the XOR logical operator that returns zero if the 
two operands are the same; else returns one. 
The experiment results are listed in Table II. The three 
games are played by different teams and broadcasted by 
different channels. In the second column, G, N, and M 
represents the number of ground-truth pitch segments, the 
number of detected pitch segments, and the number of 
individual batters, respectively. Overall speaking, the VL and 
LR measures outperform the BS and EL measures. We 
consider that the BS measure is formulated based on SIFT-
Bag descriptors; it would be sensitive to abrupt visual changes. 
For the EL measure, we find that there are other video 
segment types such as close-ups and audience views. These 
types do not belong to any of the three event categories listed 
in Table I. Their likelihoods of the three event classifiers 
might be incorrect, making the EL measure abnormal in some 
cases. We summarize that each GAO's measure has its unique 
power to assess an interesting cue derived from video content 
and webcast text. Their combination would complement each 
other to deal with a variety of video content styles in baseball 
games. Our viewpoint is obviously supported by the 
experiment result of the ALL measure, which demonstrates 
the highest accuracy rate and the most robust performance in 
general. 
VII. CONCLUSION 
Conventional baseball annotation approaches do not utilize 
webcast text well, whereas existing multimodal fusion 
frameworks do not fit baseball video properly. To address the 
above issues, we present a novel approach for baseball video 
event detection by mapping video content and webcast text. 
The mapping problem is conquered by the proposed genetic 
algorithm optimization, which integrates interesting properties 
extracted from both low-level video content and high-level 
webcast text. Experiments on various styles of baseball video 
content demonstrate a robust result, manifesting that the 
proposed approach is widely adaptable and mostly automated 
in baseball event detection. 
 
TABLE I.  THE CATEGORIZATION OF BASEBALL EVENTS 
Category Non-hitting Infield Outfield 
Event Strike out, walk, 
hit by pitch 
Infield ground 
out, infield fly 
out, infield hit, 
double play 
Outfield fly out, 
outfield hit, 
homerun 
 
TABLE II.  THE ACCURACY OF THE PROPOSED GENETIC ALGORITHM 
OPTIMIZATION. 
Game Inning (G / N / M) 
BS VL LR EL ALL
2008/06/24 (MY9) 
NYY vs. PIT 
2 top  (13/13/4) 0.85 0.85 1.00 0.85 1.00 
5 top  (10/10/3) 0.70 0.80 0.90 0.90 0.90 
2008/07/05 (FOX) 
BOS vs. NYY 
4 bot. (16/16/4) 0.60 1.00 0.88 0.88 1.00 
5 top  (12/12/4) 0.33 0.67 0.75 0.33 0.83 
2008/08/25 (FSN) 
LAD vs. PHI 
4 top  (16/16/5) 0.31 0.75 0.69 0.75 0.88 
4 bot. (8/8/3) 0.38 1.00 0.75 0.75 1.00 
REFERENCES 
[1] C. C. Cheng and C. T. Hsu, “Fusion of audio and motion 
information on HMM-based highlight extraction for baseball 
games,” IEEE Transactions on Multimedia, Vol. 8, No. 3, pp. 
585-599, 2006. 
[2] C. Y. Chiu, P. C. Lin, W. M. Chang, H. M. Wang, and S. N. 
Yang, “Detecting pitching frames in baseball game video using 
Markov random walk,” In Proceedings of IEEE International 
Conference on Image Processing (ICIP), pp. 1493-1496, Hong 
Kong, China, Sep. 26-29, 2010. 
[3] W. T. Chu and J. L. Wu, “Explicit semantic events detection 
and development of realistic applications for broadcasting 
baseball videos,” Multimedia Tools and Applications, Vol. 38, 
No. 1, pp. 27-50, 2008. 
[4] N. Dalal, and B. Triggs, “Histograms of oriented gradients for 
human detection,” In Proceedings of IEEE Conference on 
Computer Vision and Pattern Recognition (CVPR), pp. 886-893, 
San Diego, USA, Jun. 20-26, 2005. 
[5] Y. H. Huang and L. H. Tung, “Semantic scene detection system 
for baseball videos based on the MPEG-7 specification,” In 
Proceedings of ACM Symposium on Applied Computing (SAC), 
pp. 941-947, Sierre, Switzerland, Mar. 22-26, 2010. 
[6] C. Xu, Y. F. Zhang, G. Zhu, Y. Rui, H. Lu, and Q. Huang, 
“Using webcast text for semantic event detection in broadcast 
sports video,” IEEE Transactions on Multimedia, Vol. 10, No. 7, 
pp. 1342-1355, 2008. 
[7] H. Xu and T. S. Chua, “Fusion of AV features and external 
information sources for event detection in team sports video,” 
ACM Transactions on Multimedia Computing, Communications 
and Applications, Vol.2, No. 1, pp. 44-67, 2006. 
[8] X. Zhou, X. Zhuang, S. Yan, S. Chang, M. Hasegawa-Johnson, 
and T. S. Huang, “SIFT-Bag kernel for video event analysis,” In 
Proceedings of ACM International Conference on Multimedia 
(ACM-MM), pp. 229-238, Vancouver, Canada, Oct. 26-31, 2008. 
 
100 年度專題研究計畫研究成果彙整表 
計畫主持人：邱志義 計畫編號：100-2221-E-415-017- 
計畫名稱：棒球比賽影片內容與網路轉播文字之對應 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 1 1 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 4 4 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 1 1 100%  
研究報告/技術報告 0 0 100%  
研討會論文 1 1 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
