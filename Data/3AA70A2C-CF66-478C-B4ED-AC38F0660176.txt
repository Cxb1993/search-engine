solving MOD problem, in which background subtraction 
is the most popular one. After surveying these 
approaches, we find that there are still many 
problems that could be improved, such as adaptive 
learning capability, robustness, condition 
constrains, detection accuracy, execution time, etc. 
Therefore, this motivates our discussion and 
research.  
        In this research, we have proposed a robust 
texture-based background subtraction algorithm for 
moving object detection in video sequences. Our 
approach is nonparametric, multimodal, recursive, and 
pixel-based, and mainly includes three phases, i.e., 
local fuzzy pattern (LFP)-based texture extraction, 
foreground detection, and background modeling. 
Firstly, employing our proposed LFP to extract the 
texture histogram of each pixel in the considering 
video frame. After that, the similarity between the 
extracted LFP histogram of each pixel and each LFP 
histogram of the pixel＇s corresponding background 
models is calculated. The calculated similarities are 
employed to classify each pixel into the foreground 
(moving object) or background. Finally, the extracted 
LFP histogram of each pixel is employed to create or 
update the corresponding background models. Compared 
with the other approach, experimental results have 
shown that our approach possesses the better 
robustness and correctness. Besides, our approach 
also possesses advantages of the low computation 
complexity and fast calculation.  
        The execution of this project has reached the 
research goal. The related research results have been 
published in an international conference and 
submitted to an international journal for publishing. 
The further results have also been collected and 
refined, and will be submit to the international 
conferences and journals. Besides, the proposed 
texture descriptor of local fuzzy pattern and its 
application to moving object detection have been 
written as a patent application, and will be 
submitted for applying patents of R.O.C. and USA. In 
the end, we appreciate the funding and support from 
 I 
中文摘要  
移動物件偵測為許多數位影像應用重要且關鍵的前置處理步驟，其主要目的在於將影像
中具有明顯變化或移動性質之有意義物件偵測出來，提供後續進行追蹤、辨認或其他分析。目
前已有不少方法被提出來解決移動物件偵測問題，其中又以背景相減法最受歡迎。綜觀目前大
部分的方法，在適應學習能力、強韌性、條件限制、偵測正確率、執行時間等方面仍然還有許
多待改善之處，是故引發了我們探討與研究的動機。 
本研究提出一種具強韌性的基於紋理之背景相減演算法來偵測影像中移動物件。該方法
屬於無參數型、多模型、遞迴型、基於像素型，且主要包含三大步驟：基於局部模糊樣本之紋
理特徵擷取、背景建模及前景偵測。首先，利用我們所提出的「局部模糊樣本」對所考慮的影
像畫面中每個像素擷取其紋理特徵直方圖。局部模糊樣本為著名紋理特徵描述子「局部二元樣
本」之改進與推廣版本，具有更佳的紋理特徵描述能力與強韌性。接著，利用每個像素所擷取
出的紋理特徵直方圖與其背景模型中的紋理特徵直方圖進行相似度計算，藉以分類該像素點為
前景(移動物件)或背景。最後，利用每個像素所擷取出的紋理特徵直方圖來建立或更新其背景
模型。相較於其他方法，實驗結果顯示我們的方法對於複雜背景、陰影影響、光線變化等情況
具有較佳的容忍度與準確度。此外，我們的方法同樣具有低複雜度及快速運算之優點。 
本計畫之執行已達成原先設定之目標，相關研究成果業已發表一篇國際會議論文，並投
稿至一個國際期刊。後續進一步的研究成果亦已整理與撰寫，預計將可再發表於國際會議與國
際期刊。此外，所提出的局部模糊樣本紋理特徵描述子與其於影像中移動物件偵測的應用業已
撰寫成專利申請書，預計將申請中華民國及美國專利。最後，感謝國科會的補助與支持。 
 
關鍵詞：移動物件偵測、背景相減法、紋理特徵、局部模糊樣本、局部二元樣本、背景建模、
前景偵測、背景更新。 
  
 1 
一、前言  
近年來，影像中移動物件偵測(moving object detection)已經成為相當重要且熱門的研究題
目之一。主要的原因在於許多影像應用須仰賴事先將影像中主要的移動物件偵測出來，才能
夠進一步地進行追蹤(tracking)、辨認(recognition)或作其他分析。這些應用包含視覺監控(visual 
surveillance)、行為分析(behavior analysis)、異常事件偵測(anomaly event detection)、交通管控
(transportation control)、醫療看護(medical care)、犯罪預防(crime prevention)…等等。正確且完
整的移動物件偵測結果將有助於後續處理的正確性及效率之提昇；反之，將會導致後續處理
產生錯誤，甚至失敗。因此，移動物件偵測常成為這些影像應用的前置處理(preprocessing)步
驟，並且佔著相當重要且關鍵的地位。 
一般而言，在移動物件偵測問題中，移動物件乃是定義成影像中重要或使用者所感興趣，
並且具有明顯變化(variation)或移動(movement)性質之有意義物件，例如:人(human)、車子(car)、
動物(animal)、飛行器(aircraft)…等等，亦可稱為前景(foreground)。影像中其他的部分則視為
背景(background)，通常是具有較為穩定(stationary)或靜態性質的物件或場景(scene)部分。換
言之，影像中的每個畫面(frame)將被分割成移動物件(前景)及背景，如圖一所示。因此，移動
物件偵測問題可以定義如下: 
給定一個影像序列(image sequence)集合 }1|)({ TttFV ≤≤= ，其中 )(tF 表示第 t個影像畫
面 ， T 表 示 影 像 畫 面 總 數 。 求 出 其 所 對 應 的 最 佳 移 動 物 件 遮 罩 (mask) 集 合
}1|)({ TttMM ≤≤= ，其中 )(tM 表示對應於第 t個影像畫面 )(tF 之移動物件遮罩。遮罩
中的值為 1 或 0 的二元值，1 表示該對應像素(pixel)為移動物件之像素；反之，0 表示
該對應像素為背景之像素。  
上述問題中所謂最佳移動物件遮罩集合M 可以定義成具有最小誤差 ),( GMME 之遮罩集合，
其誤差之定義如下: 
∑∑
==
+=+=
T
t
T
t
tGMtMfnwtGMtMfpwGMMFNwGMMFPwGMME
1
2
1
121 ))(),(())(),((),(),(),(  (1) 
其中 }1|)({ TttGMGM ≤≤= 為由使用者定義之理想移動物件遮罩集合，亦即為 ground truth；
))(),(( tGMtMfp 為 false positive，亦即第 t個影像畫面中錯誤分類成移動物件之背景像素個數；
))(),(( tGMtMfn 為 false negative，亦即第 t個影像畫面中錯誤分類成背景之移動物件像素個數；
1w 及 2w 為權重值，其值可視影像應用由使用者決定。 
 
圖一	 	 移動物件偵測	 
 3 
三、文獻探討  
解決移動物件偵測問題的方法大致可以分成三大類:連續畫面差異法(temporal difference)、
光流法(optical flow)及背景相減法(background subtraction)，分別介紹如下: 
1. 連續畫面差異法 :此法主要是利用像素或區域(region)在連續數個畫面中的差異性做為偵
測其為移動物件或背景之依據。如果差異性較大，則視該像素或區域為移動物件；反之，
則視其為背景。此法的優點為事先不需要建立移動物件或背景模型，且具有較佳之環境改
變適應性。但其缺點為容易在移動物件內部或背景部分產生誤判點，導致移動物件內部破
碎或背景出現雜點之偵測結果。 
2. 光流法: 此法主要是透過計算像素或區域在一連串畫面中所產生的光流，來進行移動物件
偵測。其基本概念乃是基於一個連續運動變化的物體在一連串畫面中會產生像素位移，此
種位移的相對運動速度即為光流。通常光流計算法有個重要的假設，即移動物件的某個像
素在不同的畫面中，具有相同或極為相似的亮度特徵。基於這個假設我們可以透過光流方
程式(optical flow equation)計算此像素點在畫面間的移動向量(motion vector)。此法的優點
在於不需事前了解移動物件或背景環境的特性，因此較適用於未知環境中進行移動物件偵
測。但其缺點為計算複雜度較高，且較不適合用於具有較複雜變動性質的背景中。 
3. 背景相減法: 此法的基本概念乃是先對影像背景建立統計模型(statistical model)，再將欲
進行偵測之畫面與此背景模型作一對一的像素或區域比對，藉此偵測出前景物件之像素或
區域，並進一步處理獲得完整的移動物件。一般而言，背景相減法可以分成四大步驟：前
置處理(preprocessing)、背景建模(background modeling)、前景偵測(foreground detection)及
資料驗證(data validation)。在前置處理步驟中，經由一些影像處理技術可以將原始輸入影
像處理成較有利後面步驟進行的形式，例如: 雜訊去除、影像大小調整、色彩空間轉換…
等等。背景建模則為整個背景相減法過程中最為重要且關鍵的步驟，此步驟著重於建立並
更新完整且正確之影像背景模型，此模型描述了整個影像背景的統計性質，其正確與否將
是之後前景偵測步驟是否成功的一大關鍵。前景偵測則是將欲分割之影像與前述步驟所得
之影像背景模型作一對一的像素或區域比對，藉以找出與背景模型差異性較大的像素或區
域，將之視為前景像素或區域。最後，透過資料驗證的步驟，對於所偵測出來的前景像素
或區域作進一步的驗證與修正，以輸出最後所得到之前景遮罩。此法之優點為較適用於具
有複雜變動性質的背景中，且具備移動物件或背景的描述能力。但對於快速且劇烈變化背
景的適應能力，較前述兩種方法差，通常需要較多時間來更新背景模型。 
目前為止，已有為數不少的方法被提出來解決移動物件偵測問題。依前述三大類之分法，
其中以背景相減法最多，亦最受歡迎。主要是其背景或前景模型之建立，可以運用許多發展
成熟的機率統計、數值分析、人工智慧、機器學習及資料探勘技術，且適用的情況亦較廣泛。
當然亦有少數幾個方法是採混合式，即結合兩類或兩類以上。以下針對幾個較具代表性的方
法進行分析與探討。 
 5 
(principle component analysis; PCA)[13][14]及獨立成份分析(independent component analysis; 
ICA)[22]。 
2. 單模型(unimodal)或多模型(multimodal): 若影像中的每個像素或區域之背景模型僅採單
一簡單樣式，即為單模型；反之，若採用多個，則為多模型。就計算複雜度及時間而言，
單模型較具優勢，但僅適合較穩定之簡單背景，如室內環境。對於一般較為複雜之背景，
如戶外大自然環境，特別是含有變動性之背景，採用多模型會有比較好的表現效果。當然
採用多模型的代價就是必須付出較大的計算複雜度及較多的計算時間。 
Monnet et al. [14]、Maddalena & Petrosino [16]、Tsai & Lai [23]、Jung [26]、Kim et al. [27]
及 Zhang et al. [28]皆屬於單模型方法。而 Heikkilä & Pietikäinen [7]、Maddalena & Petrosino 
[16]、Wang et al. [18]、Liu et al. [19]、Bhaskar et al. [20]、Culibrk et al. [21]、Huang et al. [22]
及 Jodoin et al. [24]皆屬於多模型方法。 
3. 遞迴型(recursive)或非遞迴型(non-recursive): 在遞迴型方法中，背景模型的建立或更新
乃是隨著每次所輸入的畫面而進行。而在非遞迴型的方法中，則是事先將數個連續的畫面
儲存在緩衝空間(buffer)中，經由計算這些畫面的時變特徵而取得建立或更新背景模型之依
據。遞迴型方法因不需事先儲存數個畫面，因此較為節省記憶體空間，但每個畫面對於背
景模型的影響較為明顯。而非遞迴型方法則需要耗費較多的儲存空間，但由於採用多個畫
面的統計性質，因此較能夠避免單一畫面的不當影響。 
Heikkilä & Pietikäinen [7]、Ridder et al. [6]、Monnet et al. [14]、Maddalena & Petrosino 
[16]、Wang et al. [18]、Liu et al. [19]、Bhaskar et al. [20]、Culibrk et al. [21]、Huang et al. [22]
及 Jodoin et al. [24]皆屬於遞迴型方法。而 Chiu et al. [17]、Tsai & Lai [23]、Jung [26]、Kim 
et al. [27]及 Zhang et al. [28]則是屬於非遞迴型的方法。 
4. 基於像素型(pixel-based)或基於區域型(region-based): 基於像素型的方法乃是假設像素
之間的時變性質是彼此獨立的，故為每個像素各自建立或更新其背景模型。而基於區域型
的方法則是考量相鄰像素點之間的關係，將整個畫面分割成數塊區域，這些區域可能是具
有規則形狀及排列的區塊(block)，或是具有不規則形狀或排列的聯通像素集合。利用這些
分割的區域直接建立各自的背景模型，或是用其來改善基於像素型方法的分割結果。前者
直接以區域為基礎的處理方式，可以大幅節省時間；後者則是額外付出更多的時間，但可
以參考到相鄰像素之間的關係，對於結果有修正的效果。 
Stauffer & Grimson [2]、Heikkilä & Pietikäinen [7]、Elgammal et al. [4]、 Maddalena & 
Petrosino [16]、Chiu et al. [17]、Liu et al. [19]、Culibrk et al. [21]、Tsai & Lai [23]、Jodoin et 
al. [24]、Jung [26]、Kim et al. [27]及 Zhang et al. [28]皆屬於基於像素型方法。基於區域型
方法中，Toyama et al. [5]提出一個 wallflower 演算法，此法基於三個層次:像素、區域及畫
面來進行背景表示及維護。Wang et al. [9]提出基於 Markov random field 之高階處理法來整
合像素點的資訊。Lin et al. [15]以 block 為單位。Wang et al. [18]建立每個 block 之 DCT 係
數模型。Bhaskar et al. [20]採用群(cluster)。Huang et al. [22]提出一 region-based motion 
 7 
p(xi, yi )，我們分別以下式計算其強度值編碼成 1 及 0 的歸屬值µ1(xi, yi )及µ0 (xi, yi )： 
µ1(xi, yi ) =
1
1+ e−α ( "I (xi ,yi )− "I (x0 ,y0 )) ,                               (3) 
µ0 (xi, yi ) =1−µ1(xi, yi )                                     (4) 
其中α > 0為一使用者自訂參數。接著，計算 p(x0, y0 )之局部模糊樣本

h(x0, y0 ) = (h1,h2,...,h2P )： 
hj = µk1 (x1, y1)×µk2 (x2, y2 )×...×µkP (xP, yP )                    (5) 
其中 k1,k2,...,kP ∈ {0,1}且 j = kl ×2l−1
l=1
P
∑ 。 
最後，計算 p(x0, y0 )之局部模糊樣本
H (x0, y0 )： 
H (x0, y0 ) =
1
| N(x0, y0 ) |
h(x, y)
P(x,y)∈N (x0 ,y0 )
∑                           (6) 
其中N(x0, y0 )為使用者所訂之以 p(x0, y0 )為中心、 R2為半徑的圓形鄰域， | N(x0, y0 ) |為鄰域所
包含的像素個數。 
4.2 前景偵測   
在前景偵測步驟中，將所考慮的影像畫面中每個像素 p(x, y)與其所對應的背景模型作相似
度比較。由於採用多模型，故每個像素所對應的背景模型為數個，其中每個背景模型乃是由一
個 局 部 模 糊 樣 本 直 方 圖 所 表 示 ， 並 且 由 背 景 建 模 步 驟 所 初 始 化 及 維 護 。 假 設
{ H1(x, y),
H2 (x, y),...,
HM (x, y)}及{w1,w2,...,wM}表示像素 p(x, y)之M 個背景模型集合及其對應
之權重集合，其中M 為一使用者自訂參數。此外，令 H (x, y)表示所考慮畫面中像素 p(x, y)之
局部模糊樣本直方圖，將其分別與 p(x, y)的M 個背景模型計算相似度 S( H (x, y), Hm (x, y))，如
下式所示： 
S( H (x, y), Hm (x, y)) = min(an,bn )
n=1
2P
∑ 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 (7)	 
其中 an 及bn分別表示
H (x, y)及 Hm (x, y)之第 n維度值。接著，將M 個背景模型依其權重值遞
減順序作排序，並取具有較大權重值的前 B個背景模型作為前景偵測之依據，此 B個背景模
型之權重和必須為首度符合下列式子：	 
wi1 +wi2 +...+wiB > TB 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 (8)	 
其中 i1, i2,..., iB 為背景模型排序後前 B個之指標。若此 B個背景模型中，至少有一個之相似度值
超過門檻值TF，則將像素 p(x, y)分類成背景；若否，則將像素 p(x, y)分類成前景(移動物件)。
上述門檻值TB及TF 皆為使用者自訂參數。	 
  
 9 
事實上，根據我們多個實驗顯示，除非陰影很明顯，否則 LFP-based 方法並不會產生誤判；但
LBP-based 方法在陰影明顯或不明顯的情況下，皆很容易產生誤判。	 
在「開燈」這個實驗中，由於桌燈開啟造成桌面局部區域的亮度產生劇烈變化。由圖五	 (c)
可以看到 LBP-based 方法在該亮度劇烈變化區域產生很嚴重的誤判；而而由圖五(d)可以看到
LFP-based 方法在該區域的誤判較少，幾乎可以容忍該亮度劇烈變化之干擾。	 
由上述三個具代表性的實驗結果可知，我們所提出的 LFP-based 方法相較於他人的
LBP-based 方法，較具強韌性，較不易受到陰影變化與亮度變化之干擾。此外，對於較複雜之
背景變化亦具有較佳之適應性。	 
 
 
  
圖三	 	 實驗一「搖動的樹」結果	 
  
圖四	 	 實驗二「兩個人」結果	 
  
圖五	 	 實驗三「開燈」結果	 
 11 
Shadows in Video Streams,” IEEE Transactions on Pattern Analysis and Machine Intelligence, 
vol. 25, no. 10, pp. 1337–1342, 2003. 
[13] F. De la Torre and M.J. Black, “Robust Principal Component Analysis for Computer Vision,” 
in Proceedings of 8th IEEE International Conference on Computer Vision, Vancouver, Canada, 
vol. 1, pp. 362–369, Jul. 2001. 
[14] A. Monnet, A. Mittal, N. Paragios, and V. Ramesh, “Background Modeling and Subtraction of 
Dynamic Scenes,” in Proceedings of 9th IEEE International Conference on Computer Vision, 
Nice, France, pp. 1305–1312, Oct. 2003. 
[15] H.-H. Lin, T.-L. Liu, and J.H. Chunag, “Learning a Scene Background Model via 
Classification,” IEEE Transactions on Signal Processing, vol. 57, no. 5, pp. 1641-1654, 2009. 
[16] L. Maddalena and A. Petrosino, “A Self-Organizing Approach to Background Subtraction for 
Visual Surveillance Applications,” IEEE Transaction on Image Processing, vol. 17, no. 7, pp. 
1168-1177, 2008. 
[17] C.-C. Chiu, M.-Y. Ku, and L.-W. Liang, “A Robust Object Segmentation System Using a 
Probability-Based Background Extraction Algorithm,” IEEE Transactions on Circuits And 
Systems for Video Technology, vol. 20, no. 4, pp. 518-528, 2010. 
[18] W. Wang, J. Yang, and W. Gao, “Modeling Background and Segmenting Moving Objects from 
Compressed Video,” IEEE Transactions on Circuit and Systems for Video Technology, vol. 18, 
no. 5, pp. 670-681, 2008. 
[19] L.Y. Liu, N. Sang, and R. Huang, “Background Subtraction Using Shape and Colour 
Information,” Electronics Letters, vol. 46, no. 1, pp. 41-43, 2010. 
[20] H. Bhaskar, L. Mihaylova, and A. Achim, “Video Foreground Detection Based on Symmetric 
Alpha-Stable Mixture Models,” IEEE Transactions on Circuits and Systems for Video 
Technology, vol. 20, no. 8, pp. 1133-1138, 2010. 
[21] D. Culibrk, O. Marques, D. Socek, H. Kalva, and B. Furht, “Neural Network Approach to 
Background Modeling for Video Object Segmentation,” IEEE Transactions on Neural Networks, 
vol. 18, no. 6, pp. 1614-1627, 2007. 
[22] S.-S. Huang, L.-C. Fu, and P.-Y. Hsiao, “Region-Level Motion-Based Background Modeling 
and Subtraction Using MRFs,” IEEE Transactions on Image Processing, vol. 16, no. 5, pp. 
1446-1456, 2007. 
[23] D.-M. Tsai and S.-C. Lai, “Independent Component Analysis-Based Background Subtraction 
for Indoor Surveillance,” IEEE Transactions on Signal Processing, vol. 18, no. 1, pp. 158-167, 
2009. 
 13 
[36] B. K. P. Horn and B. G. Schunch, “Determining optical flow,” Artificial Intelligence, vol. 17, 
pp.185-203, 1981. 
[37] S. Negahdaripour, “Revised Definition of Optical Flow: Integraion of Radiometric and 
Geometric Cues for Dynamic Scene Analysis,” IEEE Transactions on Pattern Analysis and 
Machine Intelligence, vol. 20, no. 9, pp. 961–979, 1998. 
[38] J. L. Barron, D. J. Fleet, and S. S. Beauchemin, “Performance of Optical Flow Techniques,” 
International Journal of Computer Vision, vol. 12, no. 1, pp.43-77, 1994. 
[39] Y.-J. Du and Y.-J. Jin, “Log-polar Coordinate Domain Gradient Optical Flow Tracking Study,” 
Computer Engineering and Applications, vol. 45, no.10, pp.184-187, 2009. 
[40] M. Yeasin, “Optical Flow in Log-mapped Image Plane-A New Approach,” IEEE Transactions 
on Pattern Analysis and Machine Intelligence, vol. 24, no.1, pp.125-131, 2002. 
[41] H. Zhang and M. Zhou, “Objects Tracking Based on Optical Flow in Polar-log Images,” 
Journal of Computational Information Systems, pp.829-832, 2006. 
[42] J. Schmüdderich, V. Willert, J. Eggert, S. Rebhan, C. Goerick, G. Sagerer,  and E. Körner,  
“Estimating Object Proper Motion Using Optical Flow, Kinematics, and Depth Information,” 
IEEE Transactions on Systems, Man, and Cybernetics, Part B, pp.1139-1151, 2008. 
[43] B. K. P. Horn and B. G. Schunck, “Determining optical flow.” Artificial Intelligence, vol 17, 
pp 185-203, 1981. 
 
 
 
 
 2 
及國內知名學者，在High	 Speed	 Networks、Wireless	 Networks、IPv6	 based	 Networks、Digital	 
Creative	 Arts	 and	 Digital	 Divide 等方面的研究成果皆相當豐碩，也擔任過數個國際期刊的編輯
委員，在其演講中分享了有關演化式計算於未來網路的新趨勢、方法與應用。之後，連同下午
時段共參加了大會所安排的三個 session，分別是「Innovative	 Mobile	 Services」、「Intelligent	 
Computing	 and	 Its	 Applications	 in	 Multimedia	 (I)」及「Intelligent	 Computing	 and	 Its	 Applications	 in	 
Multimedia	 (II)」，於 session 中獲知不少有關行動計算、智慧型計算新方法與其於多媒體應用，
對未來研究方向與工作頗有助益。	 
4. 第四天(8/28)上午先參加了大會所安排的 keynote	 speeh，講者為來自日本 Osaka	 Prefecture	 
University 的 Hisao	 Ishibuchi 教授，講題為「Hot	 Issues	 in	 Evolutionary	 Many-Objective	 
Optimization」。Ishibuchi 為國際知名學者，在 multi-objective	 optimization、fuzzy	 rule-based	 
systems、evolutionary	 games 等方面的研究成果皆相當豐碩，也擔任過數個國際期刊的編輯委
員，在其演講中分享了有關演化式多目標最佳化的新趨勢、方法與應用。Ishibuchi 教授多次曾
經拜訪台灣各大學，曾與之有數面之緣，並互相交換研究心得。之後，參加了大會所安排的一
個 session「Intelligent	 Video	 Processing」，於 session 中獲知不少有關智慧型影像處理的新方法
與應用，其中部分方法對未來研究方向與工作頗有啟發。	 
	 
	 	 	 	 	 	 
圖一	 會議註冊	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 圖二	 	 發表論文	 
 4 
三、發表論文全文或摘要	 
Abstract-- -In	 this	 paper,	 we	 propose	 a	 robust	 texture-based	 background	 subtraction	 algorithm	 for	 
moving	 object	 detection	 in	 video	 sequences.	 A	 robust	 texture	 descriptor	 so-called	 local	 fuzzy	 pattern	 (LFP)	 
histogram	 is	 proposed	 and	 employed	 to	 initialize	 and	 maintain	 the	 background	 models	 of	 each	 pixel	 in	 a	 
video	 frame.	 The	 calculated	 LFP	 histogram	 of	 each	 pixel	 in	 the	 new	 frame	 is	 compared	 to	 its	 corresponding	 
background	 models	 for	 classifying	 the	 pixel	 into	 the	 class	 of	 foreground	 or	 moving	 objects.	 Compared	 with	 
the	 other	 approach,	 experimental	 results	 show	 that	 our	 approach	 possesses	 better	 adaption	 and	 tolerance	 
abilities	 for	 the	 conditions	 of	 shadows	 and	 illumination	 variation.	 
四、建議	 
未來的工作建議將分成三大階段，分述如下：	 
1. 蒐集最新參考文獻並研讀：關於移動物件偵測、紋理圖片分類、影像檢索、影片摘要、多目標最
佳化的文獻仍然持續被發表出來。因此，將陸續蒐集相關文獻及資料，進一步了解並分析目前各
種方法之優缺點以及改進之可能性。	 
2. 改進目前所提出之方法：由於在論文報告過程中，獲得一些相關的意見及建議，例如系統參數決
定、學習演算法、實驗分析…等等，因此，將參考這些建議，進一步改進目前方法之效率與正確
性，並與他人所提之方法作比較，以驗證所提方法之優越性。	 
3. 應用解決紋理圖片分類、影像檢索、影片摘要、多目標最佳化問題：如同前述，我將深入探討此
新型紋理特徵應用其他影像主題之可能性與優越性，例如:紋理圖片分類、影像檢索、影片摘要等
應用，此當可為我們未來研究方向之一。此外，我亦打算將我所研究的模糊類神經網路運用於多
目標最佳化問題方面。期待能夠拓展自己的研究領域與成果。	 
五、攜回資料名稱及內容	 
所攜回的資料如下：	 
1.	 ICGEC	 2012 論文集光碟乙片。	 
2.	 ICGEC	 2012 議程及論文摘要集一本。	 
3.	 其他與會者相關研究論文著作 3篇。	 
4.	 其他相關國際會議 Call	 For	 Paper。	 
六、其他	 
如前所述，此次參加會議之任務為發表論文、與國際學者交流及蒐集會議舉辦資訊，圓滿地達成。
此外，亦積極吸收關於影像處理、軟式計算與機器學習技術的最新發展趨勢與研究方向，並擴展學校
及個人的研究知名度。參加會議之後，由於獲得一些建議與啟發，特別是探討關於我們所提出的新型
紋理特徵應用其他影像主題之可能性與優越性，例如:紋理圖片分類、影像檢索、影片摘要等應用，以
及將我所研究的模糊類神經網路運用於多目標最佳化問題方面。因此，未來將配合目前正在執行的國
科會計畫的資源協助，帶領學生研究團隊，將目前所提出之方法做進一步之改善，進而運用在解決紋
理圖片分類、影像檢索、影片摘要等領域問題。	 
100年度專題研究計畫研究成果彙整表 
計畫主持人：歐陽振森 計畫編號：100-2221-E-214-065- 
計畫名稱：基於時間及空間遞迴型模糊類神經網路之影像中移動物件偵測技術 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際
已達成數)
本計畫
實際貢
獻百分
比 
單位 
備註（質化說明：如
數 個 計 畫 共 同 成
果、成果列為該期刊
之封面故事...等）
期刊論文 0 0 100%  
研究報告/技術報告 1 0 100% 本專題計畫研究成果報告。 
研討會論文 1 2 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 1 100% 
已將計畫所研發之
local fuzzy pattern 
(LFP)影像紋理特徵描
述子及其於影像中移動
物件偵測的應用寫成專
利申請書，預計送出申
請中華民國專利。 
專利 
已獲得件數 0 0 100% 
件 
 
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 1 1 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 0 2 100% 
1. 計畫研究成果已經
撰寫一篇 full paper，
並投稿至 elsevier 出
版社所發行之國際期刊
Information Sciences 
(SCI)。 
2. 目前已將進一步的
研究成果整理並撰寫，
將 投 稿 至 IEEE 
Transactions on 
Circuits And Systems 
for Video Technology 
(SCI)。 
研究報告/技術報告 0 0 100%  
國外 論文著作 
研討會論文 1 2 100% 
篇 
1. 計畫相關研究成果
已經於國際會議 The 
Sixth International 
Conference on Genetic 
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
