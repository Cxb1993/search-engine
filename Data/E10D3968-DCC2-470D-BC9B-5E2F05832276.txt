  2 
大量頻寬的優點，Traffic grooming 成為光
纖網路上的一個重要研究課題。 
Traffic grooming 的研究根據 traffic的
特性大致可分為兩類: static traffic grooming
及 dynamic traffic grooming。Static traffic 
grooming 所考慮的 traffic 為所有連結要求
（connection request）都已事先知道。Static 
traffic grooming 的主要目標是如何在現存
的 logical topology上去做 lightpath/light-tree
的 routing 以盡量降低網路資源的使用，
Static traffic grooming問題已經有一些研究
提出一些方法 [1,2,3,4,5,6,7,8]。Dynamic 
traffic grooming所考慮的 traffic則是事先不
知道 connection requests，在 connection 
request 抵達時，才會做 traffic grooming，
當 connection結束時，該 connection所使用
的網路資源將被釋放。Dynamic traffic 
grooming 問題也已經有一些研究提出一些
方法[9,10,11,12]。 
在本年度計劃的研究中，我們的目標
是要有效利用全光 WDM 光纖網路的網路
資源，降低 connection blocking probability。
在為期一年的計劃中，我們研究每個節點都
具有 splitter以及 grooming能力的光纖網路
中 dynamic multicast traffic grooming 的問
題，提出一個新的 dynamic multicast traffic 
grooming 演算法，充分利用網路上已經存
在的 light-trees來進行 traffic grooming，盡
量讓每個 light-tree 上的頻寬能充分被使
用，增加每個 light-tree頻寬的 utilization。 
三、研究成果  
根 據 一 些 過 去 研 究 過 的 Traffic 
grooming 演算法，可以發現每個演算法的
基本精神皆在於尋找一個已經存在
multicast tree 使用其剩餘頻寬來完成資料
傳輸，來達到增加頻寬使用率的目標，我們
針對 dynamic multicast traffic grooming提出
一個新的演算法，希望找尋多個 multicast 
tree來達成 Traffic grooming的目標。 
所謂 WDM 光纖網路上的 dynamic 
multicast traffic grooming 問題可以被公式
化為以下。 
A. Inputs: 
1. 給定一個實體網路拓撲 Gp(Vp，Ep) ，
Vp 代表整個光纖網路上節點的集合
而 EpVpVp 代表所有的 fiber link
的集合，分別用 N以及 L代表節點跟
fiber link的數目，每個 link分別指派
一個 cost value以便於路徑計算之用。 
2. 每條 fiber所能提供的wavelength個數
用 W 來表示，每條 wavelength 所能
提供的 capacity用 C來代表，並假設
所有的 fiber links 配置的 wavelength
數量皆為相同。 
3. 使用 Tx跟 Rx分別表示 transmitter以
及 receiver的數量。 
4. 一個multicast連接要求可以被表示成
為 r(s，D，b，△T) ，sVp表示 source 
node， D  Vp 表示要求的所有
destinations，b 代表所要求之頻寬，
而△T表示傳送資料所要占用的時間。 
B. Constraints: 
1. Wavelength Constraints:如果Wa(m，n)
表示一組可用的 wavelengths 從節點
m 到節點 n，則當透過 physical link 
e(m，n)來建立一棵 light-tree 時，
Wa(m，n)≠必定為真。 
2. Transceivers Constraints:當建立新的
light-tree從節點 m傳輸資料到節點 n
時，節點 m 必須要有一個可用的
transmitter 而節點 n 必須要有一個可
用的 receiver，也就是說 Tx(m) 1 且
Rx(n) 1。 
3. Light-tree capacity Constraints:一棵
  4 
 
圖 3-1 
 
B. Grooming Cost介紹 
   對於 light-tree的 grooming cost設計會影
響到選出的 light-tree組合，在光纖網路的環
境下，我們必須考慮使用 light-tree可能付出
的代價，例如使用這個 light-tree是否會傳輸
其他非 request所要的 destination或是從
request的 source傳送資料到這個 light-tree
的距離是不是太長等等，在經過分析整理之
後，我們用下面的圖例來說明 grooming cost
的設定方法。 
    在[11]作者提出了兩種名詞一個是”to 
destinations light-tree”(TDLT)，另一個是” 
from source lightpath”(FSLP)，所謂的 TDLT
是指這棵 light-tree雖然能傳送資料到我們所
需要的 destinations，但是這棵樹的 source與
request的 source並不相同，所以如果要使用
這棵樹來 groom traffic則必須先把資料傳送
到 TDLT的 source，為此必須尋找所謂的
FSLP來傳輸資料到 TDLT，FSLP就是指一
條 lightpath其起點是 request的 source而終
點是 TDLT的 source，讓 request的資料能夠
經由 FSLP先傳送到 TDLT最後再傳到
destinations，由於建立新的 FSLP需要使用
網路的資源例如 transmitter、receiver、optical 
fiber等，所以我們認為在設計 grooming cost
時，FSLP會有很大的影響，FSLP的長度為
多少就應該增加多少的 grooming cost，以下
用圖例來說明，圖 3-2為一個簡單的網路，
假設上面現在有一個現存的 light-tree，其
source是節點 8，destinations分別是節點 7
跟節點 9，然後現在有個 request希望從節點
2傳輸資料到節點 7跟節點 9，如果選擇這棵
light-tree作為 grooming的對象則必須建立一
段 FSLP從節點 2到節點 8，一共會用掉 2
個 wavelength-link，所以我們決定其
grooming cost的值加 2，同樣在圖 3-3中可
以看到這次存在的 light-tree的 source剛好跟
request的 source一樣，代表不需要建立
FSLP，可以視為 FSLP長度為 0，所以
grooming cost的值就是加 0。 
 
      圖 3-2             圖 3-3 
   考慮選擇 light-tree作為 grooming的目標
時，是否會傳輸到並非 request所要的
destinations的節點，因為如果傳輸到不必要
的節點會造成頻寬的浪費，但由於各種
request的頻寬不盡相同，所以造成浪費的程
度也不同，所以我們決定當有浪費的情形發
生時，grooming cost使用的計算方式為
request所要求的頻寬除以一個
wavelength-link所能提供的最大頻寬再乘以
傳輸到不必要的節點個數，以下同樣用圖例
來說明，在圖 3-4上現在存在一棵 light-tree
其 source是節點 8，destinations分別是節點
4、節點 6、節點 7以及節點 9，然後現在有
個 request希望從節點 8傳輸資料到節點 7
跟節點 9而且要求的頻寬為 1，如果選擇這
棵 light-tree作為 grooming的對象，我們可
以發現會將資料多傳輸到節點 4以及節點 6
這兩個節點，我們假設一個 wavelength-link
最大頻寬為 4，所以 grooming cost的計算為
1除以 4再乘以 2，grooming cost的值必須加
上 2分之 1。 
  6 
彼此間可能有連接關係。 
 
圖 3-6 
    舉個例子來說明，假設圖 3-6上找到兩
棵候選 light-tree，分別是 source是節點 5到
節點 4跟節點 8以及 source是節點 8到節點
7跟節點 9，假設 request的 source是 2，原
本必須從節點 2建立一段新的 FSLP連接節
點 5以及節點 8，一共要花費兩個
wavelength-link，但我們發現其中一棵
light-tree它的 destinations中有包含另一棵
light-tree的 source，從圖上看來就是節點 8，
因此我們可以利用這樣的關係將資料先傳到
節點 5的 light-tree，再利用此 light-tree傳送
到節點 8，如此一來所需要的 FSLP便只需
花費一個 wavelength-link即可，而且也能節
省 receiver的使用，就如同把兩棵 light-tree
合併為一棵，所以在選完所有的 light-tree之
後我們會檢查 light-tree之間是否能夠合併。 
    由於選完所有的 light-tree之後，並不能
保證所有的 request所要的 destinations都能
包含，所以我們將剩下沒有被包含的
destinations另外做處理，在處理完 light-tree
的合併之後，我們將從 request的 source新建
一棵新的 light-tree，其 destinations就是選出
的 light-tree再經過合併之後依然需要建立
FSLP的 light-tree的 source以及那些沒有辦
法被現存 light-tree所包含的 request的
destinations，如此一來 light-tree新建完後便
完成了 grooming的動作。 
    整個WSCT演算法的流程整理如下: 
1. 等待 request到來，如果是 connection 
request則跳至 2.;如果是 release request
則跳至 6.。 
2. 載入紀錄目前網路狀態的輔助圖，並暫時
拿去剩餘 capacity不足容納 request所要
求的頻寬的 wavelength-link edge，於演算
法結束後在恢復到輔助圖上。 
3. 開始檢查網路上所有目前存在的
light-tree並計算 grooming cost， 
grooming cost計算完成後，計算 cost 
effectiveness，然後從候選區選取候選
light-tree，若候選區中沒有任何 light-tree
則對 request採取直接新建 light-tree的方
式，如果能成功新建就跳至 4.否則此
request就被 block然後回到 1.，若候選區
中有 light-tree可以選便從 cost 
effectiveness最小的 light-tree開始選取，
然後重新計算每棵 light-tree的 cost 
effectiveness，反覆選取直到全部的候選
light-tree都選完或 request所要的
destinations都被覆蓋為止，選完之後檢
查 light-tree之間是否有某些 light-tree的
source剛好是其它 light-tree的
destination，若有表示兩樹可以合併則合
併之，重複合併直到確定已經無法再合併
為止，接著在輔助圖上新建一棵 light-tree
其 source為 request的 source，destination
為選出的 light-tree再經過合併之後依然
需要建立 FSLP的 light-tree的 source以
及那些沒有辦法被現存 light-tree所包含
的 request的 destinations，如果建立成功
跳至 4.，否則此 request會被 block，然後
回到 1.。 
4. 開始分配網路資源，更新被 request所使
用的現存 light-tree的頻寬資訊，如果要
增加新的分支到達新的 destination時則
在調整 light-tree後記錄相關資訊，並修
改輔助圖相關的部份，更新 transmitter
以及 receiver的數量，如果有新建新的
  8 
目，可以發現每條 fiber上的 wavelength越
多，越能降低 blocking probability，同樣的
WSCT都能比其他方法有更好的效能。 
0.01
0.1
1
6 8 10 12 14
B
lo
ck
in
g 
P
ro
ba
bl
it
y
LFSEQSH
MDTGA
WSCT
圖 4-3 
    最後我們比較在相同的 network load之
下 transmitter的數量對於 blocking probability
的影響，圖 4-4中我們固定 rx=8，w=10，
λ=150，改變 transmitter的數目，可以發現
transmitter的數量越多，越能將低 blocking 
probability，同樣的WSCT都能比其他方法
有更好的效能。 
0.1
1
6 8 10 12 14
B
lo
ck
in
g 
P
ro
ba
bl
it
y
LFSEQSH
MDTGA
WSCT
圖 4-4 
六、計劃成果自評  
    在本計畫之中，我們針對 dynamic 
multicast traffic grooming提出一個新
的演算法，這個演算法以weighted set 
cover的概念，來做為篩選 light-tree的
方 式 ， 利 用 多 棵 light-tree 來 完 成
grooming的 目 的 ， 模 擬 的 結 果 顯 示
WSCT演算法確實有較好的效能表現。 
參考文獻  
[1] J. Q. Hu and B. Leida, “Traffic grooming, 
routing, and wavelength assignment in optical 
WDM mesh networks,” in Proceedings of the 
IEEE INFOCOM , vol. 1, pp. 495-501, Mar. 
2004. 
[2] Z. K. G. Patrocinio Jr. and G. R. Mateus, “A 
Lagrangian-Based Heuristic for Traffic 
Grooming in WDM Optical Networks,” in 
Proceedings of the IEEE CLOBECOM, vol. 5, 
pp. 2767-2771, Dec. 2003. 
[3] I. Chlamtac, A. Ganz, and G. Karmi, 
“Lightpath Communications: An Approach to 
High Bandwidth Optical WANS,” IEEE 
Transactions on Communications, vol. 40, pp. 
1171-1182, July 1992. 
[4] H. Siregar, H. Takagi, and Y. Zhang, “Efficient 
Routing and Wavelength Assignment in 
Wavelength-Routed Optical Networks” in Proc. 
7th Asia-Pacific Network Oper. and Mgmt 
Symposium, pp. 116-127, Oct. 2003. 
[5] S. Baroni and P. Bayvel, “Wavelength 
Requirements in Arbitrary Connected 
Wavelength-Routed Optical Networks,” 
IEEE/OSA Journal of Lightwave Technology, 
vol. 15, pp. 242-251, Feb. 1997.  
[6] R. Ul-Mustafa and A. E. Kamal, “Design and 
Provisioning of WDM Networks with 
Multicast Traffic Grooming,” IEEE Journal on 
Selected Areas in Communications, Part II: 
Optical Communications and Networking, vol. 
24, pp. 37-53, April 2006. 
[7] A. L. Chiu and E. H. Modiano, “Traffic 
Grooming Algorithm for Reducing Electronic 
Multiplexing Costs in WDM Ring Networks,” 
IEEE Journal of Lightwave Technology, vol. 
18, pp. 2-12, January 2000. 
[8] R. Dutta, S. Huang, and G. Rouskas, “On 
Optical Traffic Grooming in Elemental 
Network Topologies,” in Proceedings of 
OptiComm, pp.13-24, 2003 
[9] W. Yao and B. Ramamurthy, “A Link Bundled 
Auxiliary Graph Model for Constrained 
□ 赴國外出差或研習 
□ 赴大陸地區出差或研習 
■ 出席國際學術會議 
□ 國際合作研究計畫出國 
心得報告 
計 畫 名 稱 分波多工光纖網路(WDM 
Optical Networks)中群播
疏導(Multicast Traff     
ic Grooming)之研究 
 
計 畫 編 號 
NSC 98-2221-E-007-061 
報 告 人 
姓 名 
林華君 
服 務 機 構 
及 職 稱 
資訊工程學系副教授 
會議/訪問時間 
 地點 
2010年 5月 23日 - 27日，南非，開普敦 
會 議 名 稱 IEEE International Conference on Communications (ICC 2010) 
發表論文題目 
1. A Weighted Sliding-frame Strategy for Distributed Location 
Management in Wireless Mobile Networks 
2. Constructing Maximum-lifetime Data Gathering Trees in Sensor 
Networks with Data Aggregation 
 
一、主要任務摘要 
    本次出席 IEEE ICC 2010國際會議，主要任務是發表兩篇文章。 
 
二、對計畫之效益 
    本次出席 IEEE ICC 2010國際會議對計畫之效益主要有兩項，第一項是發表過去
的研究成果，第二項是了解參與國際會議的學者專家，在本人的研究領域相關議題的
發展， 
 
三、經過 
 
5/22 19:20 搭乘國泰航空班機至香港轉南非航空班機至約翰尼斯堡，由於抵達約
翰尼斯堡時，距離轉機時間還早，於是便搭早一班南非航空的班機，於 5/23 12:10抵
達開普敦，搭車抵達旅館後，便至開會會場報到，傍晚參加大會的 Reception。 
    今年的 ICC 會議共有 11 個 technical symposia，2 個 plenary sessions，6 個 business 
panels，20 個 tutorials，9 個 workshops。今年 ICC 共收到 2618 篇文章，經過審查之後，
接受了 1035 篇文章，我的兩篇文章被安排在 5/24下午及 5/26下午，其他時間聽聽其
他作者發表文章。 
    會議在5/27結束，5/28便離開旅館至開普敦機場搭飛機，由於提早到開普敦機場，
便提早搭南非航空班機至約翰尼斯堡，再轉機至香港，再由香港轉國泰航空班機，於
5/29 16:30底達台灣。 
 
四、心得 
 
A Weighted Sliding-frame Strategy for Distributed
Location Management in Wireless Mobile Networks
Hwa-Chun Lin and Chien-Yi Ho
Depatment of Computer Science
National Tsing Hua University
Hsinchu, 30013, Taiwan
Abstract—This paper proposes a distributed location man-
agement strategy called weighted sliding-frame strategy for
wireless mobile networks in which the processing speeds of the
location information databases (LIDs) are heterogeneous. In the
proposed strategy, a number of consecutively numbered location
information databases are arranged into a frame. A frame of
location information databases overlaps with the next frame
except one database. Each frame is assigned a weight which
is used to distribute the location information of the mobile hosts
among the frames. The number of mobile hosts whose location
information are stored in a frame is proportional to the weight
assigned the frame. A nonlinear convex programming problem
is formulated and solved numerically in order to find the set of
weights that minimize the average database response time. Our
numerical results show that the proposed weighted sliding-frame
strategy is able to properly distribute the location information
of the mobile hosts among the frames such that the average
database response time is significantly lower than that of the
sliding-frame strategy proposed in our previous work.
I. INTRODUCTION
The wireless mobile network architecture considered in this
paper is a cellular network architecture. In a cellular network,
each cell has a base station that provides wireless access to
mobile hosts. A number of base stations are controlled by
a base station controller (BSC) whose primary function is
to manage the radio resources of the base stations under its
control. Each base station controller (BSC) is connected to
a mobile switching center (MSC) via a wired network. A
mobile switching center (MSC) provides switching functions
and call delivery. The area under the responsibility of a mobile
switching center (MSC) is called a location area (LA).
In cellular networks, hierarchical databases consisting of
one home location register (HLR) at the top level and a number
of visitor location registers (VLRs) at the second level are used
for location management. The location information of a mobile
host needs to be updated at the home location register (HLR)
whenever the mobile host moves from the serving area of a
visitor location register (VLR) to the serving area of another
visitor location register (VLR). A visitor location register
(VLR) is commonly collocated with a mobile switching center
(MSC), and they are collectively referred to as an MSC/VLR.
A home location register (HLR) is also referred to as a location
information database (LID) in a number of researches [16]–
[21]. The terms HLR and LID will be used interchangeably
in this paper.
The architectures of the location information databases
(LIDs) used in the location management strategies in the
literature can be classified into centralized and distributed
architectures. Centralized and distributed architectures of LIDs
can be found in [1]–[9] and [10]–[22] respectively. A cen-
tralized LID architecture suffers from the problems of single
point of failure and traffic concentration. A distributed LID
architecture can be used to distribute the traffic for location
management among a number of LIDs.
In our previous work [22], we used a distributed LID
architecture similar to those used in [19]–[21], and proposed
a sliding-frame strategy for distributed location management
strategy in which the traffic and load for updating and finding
the locations of mobile hosts are evenly distributed among
the LIDs, and the size of the subsets of databases need not be
specially designed. A number of consecutively numbered LIDs
are arranged into a frame. A frame of LIDs overlaps with the
next frame except one database. The location information of
a mobile host is replicated and stored in the databases in the
same frame. When the location area of a mobile host changes,
the new location information is stored in the next frame of
databases. It has been shown that the average communication
cost and average database response time incurred by the
sliding-frame strategy are always lower than or equal to those
incurred by the strategy proposed in [20].
The LIDs considered in [16]–[22] are homogeneous. Hence
the strategies proposed in these works are able to balance
the loads among the LIDs as well as provide fault tol-
erance. However, these strategies may lead to significantly
imbalanced loads when the processing speeds of the LIDs
are heterogeneous. The processing speeds of the LIDs could
be heterogeneous due to a number of possible deployment
scenarios. One possible scenario is that the LIDs are deployed
in multiple phases and different hardware are used for the LIDs
in different phases due to availability of the hardware or cost
consideration. Another possible scenario is that failed LIDs are
replaced by LIDs with new hardware due to unavailability of
the same original hardware or cost-effectiveness consideration.
This paper considers LIDs with heterogeneous processing
speeds and develops a strategy called weighted sliding-frame
strategy to distribute the load among the heterogeneous LIDs
such that the average response time of the LIDs is minimized
while providing fault tolerance as well.
Similar to the sliding-frame strategy proposed in our previ-
ous work [22], the proposed weighted sliding-frame strategy
arranges a number of consecutively numbered LIDs into a
frame. A frame of LIDs overlaps with the next frame except
one LIDs. In order to distribute the load among the LIDs with
heterogeneous processing speeds, each frame is assigned a
weight such that the number of mobile hosts whose location
information are stored in the frame is proportional to the
978-1-4244-6404-3/10/$26.00 ©2010 IEEE
This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the IEEE ICC 2010 proceedings
i = 1, 2, · · · , N . This can be easily verified by modeling the
evolution of the frame used to store the location information
of the mobile host by an embedded Markov chain as shown
in Fig. 2, where the states represent the IDs of the frames and
the transition points are the time instants when the mobile
host changes location areas. It can be easily calculated that
the steady state probability of state i is wi, i = 1, 2, · · · , N ,
i.e., the location information of the mobile host is stored in
frame i with probability wi, i = 1, 2, · · · , N .
When a query request for the location of a mobile host is
received by an MSC/VLR, the MSC/VLR randomly selects an
initial LID. Without knowing the frame of LIDs that stores the
desired location information, selecting an initial LID randomly
is a reasonable strategy. Suppose that the ID of the selected
initial LID is i. The MSC/VLR queries the set of LIDs
with IDs ((i + jk − 1) mod N) + 1, j = 0, · · · , Nk  − 1.
Let the set of LIDs queried for a query request be referred
to as a query set. The query set with initial LID i is
referred to as query set i which contains the set of LIDs
with IDs ((i + jk − 1) mod N) + 1, j = 0, · · · , Nk  − 1.
Some properties of the query sets are given in the following.
Property 1: When the total number of LIDs, N , is divisible
by the replication factor, k, the total number of different query
sets is k.
Property 2: When the total number of LIDs, N , is not
divisible by the replication factor, k, the total number of
different query sets is N .
Property 3: When the total number of LIDs, N , is divisible
by the replication factor, k, the location information of a
mobile host is stored in exactly one of the LIDs in each query
set.
Property 4: When the total number of LIDs, N , is not
divisible by the replication factor, k, the location information
of a mobile host is stored in one or two LIDs in each of the
query sets. The number of query sets that contains exactly one
LID that stores the location information of the mobile host is
2N − kNk . The number of query sets that contains exactly
two LIDs that store the location information of the mobile host
is kNk  −N .
Properties 1 and 3 are obvious. The proofs of Properties 2
and 4 can be found in our previous work [22]. Properties 3 and
4 ensure that at least one of the LIDs in the chosen set of LIDs
contains the location information of the mobile host. The set
of LIDs are queried in parallel to minimize the query delay.
Upon receiving a query request from the MSC/VLR, each of
the Nk  LIDs queried sends a response to the MSC/VLR. The
desired location information can be obtained from one of the
responses from the Nk  LIDs.
Another way for the MSC/VLR to query the set of LIDs
with IDs ((i + jk − 1) mod N) + 1, j = 0, · · · , Nk  − 1,
is to perform the queries sequentially. With sequential query,
the query process can be stopped as soon as the location
information of the mobile host is obtained such that less traffic
is generated. There is a trade-off between querying the set of
LIDs in parallel and in sequential. Querying the set of LIDs
λ
λ
λ
Network
2
3
N
Arrival rate of query requests
Arrival rate of update requests
M + 1
M 
M + 1
LID   1
LID   2
LID   3
LID   N
γ
γ
γ
1γ
Query one or 
 more LIDs
Update one or
 more LIDs
Fig. 3. System model of the location information databases.
sequentially generates less traffic while suffers from longer
query delay. Querying the set of LIDs in parallel is able to
minimize the query delay; however, more traffic is generated.
This paper chooses to have the MSC/VLR query the set of
LIDs in parallel to minimize the query delay.
III. MINIMUM AVERAGE DATABASE RESPONSE TIME
In the proposed weighted sliding-frame strategy described
in Section II, the purpose of assigning different weights to
the frames is to distribute the load among the LIDs. The
goal of this paper is to select the weights assigned to the
frames in order minimize the average database response time
of the LIDs. The database response time is defined as the time
interval starting from a query or update request is submitted
to an LID until the request is processed by the LID. The
average database response time is the average of the response
times of all query and update requests submitted to the
LIDs. The problem will be formulated as a nonlinear convex
programming problem. A standard method can be used to
solve the problem.
A. Average Database Response Time
The system model used for analyzing the average database
response time is shown in Fig. 3. Let the total arrival rate of
requests (including update and query requests) to the system
be λ. Let M be the call to mobility ratio which is the expected
number of calls received by a mobile host during the period
it stays in a location area, i.e., one update request is followed
by M query requests on the average. Thus, the arrival rates
of update and query requests are λ1+M and
λM
1+M respectively.
As was verified in Section II, the location information of
the mobile host is stored in frame i with probability wi,
i = 1, · · · , N . Suppose that a mobile host, whose location
information is stored in frame l, initiates an update request.
The update request is delivered to LID i if l ∈ {[((N − k −
1) + i + j) mod N ] + 1 | j = 1, · · · , k} since LID i is
a member of frame [((N − k − 1) + i + j) mod N ] + 1,
j = 1, · · · , k. In addition, the update request is delivered
to LID i with probability τ/w[((N−k−1)+i) mod N ]+1 if l =
[((N−k−1)+ i) mod N ]+1. Let vi be the expected number
of requests delivered to LID i for each update request initiated
This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the IEEE ICC 2010 proceedings
60 80 100 120 140 160 180
0
0.02
0.04
0.06
0.08
0.1
0.12
0.14
0.16
M = 0.1
M = 0.1M = 1
M = 1
M = 2
M = 2
Sliding−frame strategy:
Weighted sliding−frame strategy:
A
ve
ra
ge
 d
at
ab
as
e 
re
sp
on
se
 ti
m
e 
(s)
Total arrival rate of requests (λ)
Fig. 4. Comparison of average database response time, N = 7, k = 3,
τ = 0.05, (μ1, μ2, · · · , μ7) = (100, 95, 85, 75, 70, 80, 90) requests per sec-
ond.
50 60 70 80 90 100 110 120
0
0.02
0.04
0.06
0.08
0.1
0.12
0.14
0.16
M = 0.1 M = 1
M = 2
M = 2
M = 1
M = 0.1
Sliding−frame strategy:
Weighted sliding−frame strategy:
A
ve
ra
ge
 d
at
ab
as
e 
re
sp
on
se
 ti
m
e 
(s)
Total arrival rate of requests (λ)
Fig. 5. Comparison of average database response time, N = 7, k = 3,
τ = 0.05, (μ1, μ2, · · · , μ7) = (100, 90, 70, 50, 40, 60, 80) requests per sec-
ond.
sliding-frame and the sliding-frame strategies for different
values of call to mobility ratio M . The difference between
Fig. 4 and 5 is that the sets of values, (μ1, μ2, · · · , μ7), for
the processing speeds of the LIDs are different. The values for
the processing speeds of the LIDs used to produce Fig. 4 are
(100, 95, 85, 75, 70, 80, 90) requests per second, while those
used to produce Fig. 5 are (100, 90, 70, 50, 40, 60, 80) requests
per second. Note that the values for the processing speeds of
the LIDs used to produce Fig. 5 has higher heterogeneity than
those used to produce Fig. 4.
From Figs. 4 and 5, we can observe that when the total
arrival rate of requests is medium to high, the weighted sliding-
frame strategy yields significantly lower average database
response times than the sliding-frame strategy, especially when
the heterogeneity of the processing speeds of the LIDs is
high. By assigning appropriate weights to the frames, the
weighted sliding-frame strategy is able to properly distribute
the location information of the mobile hosts to the frames such
that the average database response time is reduced significantly
under medium to heavy load condition. The average database
response times of the two strategies are similar when the total
arrival rate of requests is low to medium. From these two
figures, we can also observe that the amount of improvement
of the weighted sliding-frame strategy over the sliding-frame
strategy increases as the heterogeneity of the processing speeds
of the LIDs increases.
B. The effect of call to mobility ratio M on the average
database response time
Figs. 4 and 5 are also used to study the effect of call to
mobility ratio M on the average database response time. The
average database response time of the sliding-frame strategy
decreases as the call to mobility ratio M increases as can
be observed from Figs. 4 and 5. The reason is explained
as follows. For the sliding-frame strategy, the total of rates
of requests received at the LIDs is λ[Nk ( M1+M ) + (k +
1)( 11+M )] [22]. For N = 7 and k = 3, the number of LIDs
queried for each query request is Nk  (i.e., 3), and the number
of LIDs updated for each update request is k + 1 (i.e., 4).
Hence, for a given value of λ, the total of rates of requests
received at the LIDs decreases as M increases. Thus, the
average database response time decreases as M increases.
For the weighted sliding-frame strategy with N = 7, k = 3,
τ = 0.05 and a given value of λ, the total of rate of requests
received at the LIDs decreases as M increases according to
(8). However, the average database response time does not
necessary decrease as M increases as can be observed from
Figs. 4 and 5. We shall concentrate on analyzing the reason
behind this for heavy load condition since the average database
response times are similar for different values of M when the
load of the system is low to medium.
When the heterogeneity of the processing speeds of the
LIDs is low, the weighted sliding-frame strategy is able to
distribute the location information of the mobile hosts more
evenly among the frames such that the average database
response time is not significantly dominated by that of the
LIDs with lower processing speeds. Thus, in general, the
average database response time decreases as M increase for
a given value of λ (i.e., the total rate of requests received at
the LIDs decreases) as can be observed from Fig. 4.
However, when the heterogeneity of the processing speeds
of the LIDs is high, the weighted sliding-frame strategy
distributes significantly more location information of the mo-
bile hosts to those LIDs with higher processing speeds and
significantly less location information of the mobile hosts
to those LIDs with lower processing speeds. The average
database response time of the entire system is dominated by
those of the LIDs with lower processing speeds when the
load of the system is heavy. It is clear from (3) that, for a
given value of λ, the rate of query requests received at all
LIDs increases as M increases. Hence, the average database
response times of those LIDs with lower processing speeds are
dominated by the response times for processing query requests
when the load of the system is heavy and M is large since
query requests are evenly distributed over the LIDs regardless
of their processing speeds. Thus, when the load of the system
is heavy, the average database response time of those LIDs
with lower processing speeds increases as M increases for a
given value of λ. Therefore, when the load of the system is
This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the IEEE ICC 2010 proceedings
Constructing Maximum-lifetime Data Gathering
Trees in Sensor Networks with Data Aggregation
Hwa-Chun Lin, Feng-Ju Li, and Kai-Yang Wang
Depatment of Computer Science
National Tsing Hua University
Hsinchu, 30013, Taiwan
Abstract—This paper studies the problem of constructing
maximum-lifetime data gathering trees in sensor networks in
which the power levels of sensors are heterogeneous and ad-
justable. In-network data aggregation is also employed to ag-
gregate sensor data while they are being forwarded toward the
base station. For sensor networks in which sensors have fixed
and the same transmission power level, Wu et al. has derived
an upper bound on the lifetime of the optimal data gathering
tree and developed an approximation algorithm for constructing
data gathering trees. The model considered in this paper is more
general than that considered by Wu et al. in that the transmission
power levels of sensors are heterogeneous and adjustable. For
this more general model, this paper derives an upper bound on
the lifetime of the optimal data gathering tree. Given an initial
tree, an algorithm is developed to construct a data gathering
tree by iteratively rearranging the current tree and improving
the lifetime of the current tree. The worst-case computational
complexity of the algorithm is shown to be polynomial.
I. INTRODUCTION
In environments where power outlets are not available,
sensors are battery powered. Depending on the environments
where sensors are deployed, replenishment of power resources
of the sensors may be inconvenient or even infeasible. With
limited battery power in each sensor, it is desirable to maxi-
mize the lifetime of the sensor network.
In-network data aggregation is a technique that sensor data
from different sensors are combined at intermediate sensors ac-
cording to certain aggregation function, and delivered toward
the base station (or sink). Several data aggregation functions
including COUNT, MIN, MAX, SUM, and AVERAGE were
studied based on the TinyOS platform in [1]. It has been shown
that such data aggregation can reduce the amount of data that
needs to be transmitted by a sensor, which in turn reduces
power (energy) consumption at a sensor [1].
For energy efficient data gathering in a sensor network, a
tree rooted at the base station (or sink) spanning the sensors
in the coverage area is commonly used. Sensor data are
aggregated at intermediate sensors (or nodes) and forwarded
toward the base station along the tree. To maximize the
lifetimes of sensor networks with in-network data aggregation,
several researches [2], [4]–[6] focus on finding the amount of
time (or number of rounds) each of the trees in a set of pre-
calculated candidate trees should be used in order to maximize
the total lifetime (or total number of rounds). The set of pre-
calculated candidate trees is usually the set of all possible trees
rooted at the base station. A drawback of using a set of pre-
calculated candidate trees is that the number of all possible
spanning trees rooted at the base station is huge for a large
sensor network. Enumeration of all spanning trees for a large
sensor network is computationally prohibited.
Another approach is to construct a tree without replying on
a set of pre-calculated candidate trees. The works in [7]–[9]
take this approach. The advantage of this approach is that
it does not need to enumerate all possible spanning trees.
However, gathering the sensor data using a single tree found by
this approach may be substantially suboptimal. This problem
can be alleviated by constructing new trees periodically or at
appropriate time instants.
The PEDAP protocol proposed in [7] computes a spanning
tree that minimize the total energy expenditure in a round of
data gathering using the Prim’s algorithm [10]. The amount
of energy consumption for sending a message from a node
to a neighbor node is used as the cost of the edge between
the two nodes. The PEDAP-PA protocol proposed in [7] is a
power-aware version of the PEDAP protocol, that takes the
remaining energy of each node into account.
The model considered in [8] neglects the energy consump-
tion for receiving messages. The MNL algorithm proposed
in [8] constructs a spanning tree that maximizes the minimum
residual energy among the nodes. The MNL algorithm starts
with the base station as the initial tree. A node is chosen to
be included in the current tree if it maximizes the minimum
residual energy among the tree nodes including itself. The
nodes are included in the current tree one at a time until all
nodes are included.
Wu et al. [9] considered a model in which all sensors have
fixed and the same transmission power level. They proved
that finding a single tree that yields the maximum lifetime is
an NP-complete problem. Instead of maximizing the lifetime
of the sensor network, the problem was transformed into
an equivalent problem that minimizes the inverse lifetime.
A lower bound on the inverse lifetime of the optimal data
gathering tree was derived, which is equivalent to the upper
bound on the lifetime of the optimal data gathering tree. An
approximation algorithm was developed based on the Fu¨rer
and Raghavachari approach [11] for the minimum-degree
Steiner tree problem.
This paper also takes the approach that does not rely on
a set of pre-calculated candidate trees. This paper considers
a model in which the transmission power levels of sensors
are heterogeneous and adjustable, which is more general than
the model used in [9] in which all sensors have fixed and
the same the transmission power level. A lower bound on the
normalized load of the optimal data gathering tree is derived,
which is equivalent to an upper bound on the lifetime of
the optimal data gathering tree. An algorithm is proposed to
iteratively improve the lifetime of an initial tree by partially
rearranging the tree until no improvement can be made to
any heavily loaded node. Simulations are performed to study
the lifetimes of the data gathering trees constructed by the
proposed algorithm. Our simulation results show that the
average lifetime of the data gathering trees produce by the
978-1-4244-6404-3/10/$26.00 ©2010 IEEE
This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the IEEE ICC 2010 proceedings
IV. LOWER BOUND ON THE NORMALIZED LOAD OF THE
OPTIMAL TREE
In this section, we derive a lower bound on the normalized
load of the optimal data gathering tree, which is equivalent to
the upper bound on the lifetime of the optimal data gathering
tree.
Theorem 1: Let G = (V,L) be a given sensor network. Let
H∗ be a minimum-load data gathering tree in G and W ∗ be
the normalized load of H∗. Given a data gathering tree H in
G. Suppose that there is a set R ⊆ V such that the removal
of R from H creates a set of disconnected components which
are also disconnected in G. Then
W (H∗) ≥ min
vi∈R
Wi(H)− |R|(e
r + δ
t
)− er∑
vi∈R ei
, (7)
where δti = eti − eti and δ
t
= maxvi∈Vs δ
t
i .
Proof: From (5), we have
W (H∗) = max
vi∈Vs
Wi(H∗) ≥ max
vi∈R
Wi(H∗)
= max
vi∈R
ci(H∗)er + eti(H
∗)
ei
≥
∑
vi∈R(ci(H
∗)er + eti(H
∗))∑
vi∈R ei
(8)
Let y be the number of disconnected components created by
removing R from H . Let di(H) denote the degree of node i in
H . Since the disconnected components created by removing R
from H are disconnected in G, they must be also disconnected
in H∗. However, each of the y disconnected components may
consist of one or more components in H∗. Let y∗ be the
number of disconnected components created by removing R
from H∗. Then, y∗ is greater than or equal to y, i.e., y∗ ≥ y.
Since H∗ is a tree, the number of edges in H∗ that connect
these disconnected components and the nodes in R is exactly
y∗ + |R| − 1 which is less than or equal to
∑
vi∈R
di(H∗), i.e.,
∑
vi∈R
di(H∗) ≥ y∗ + |R| − 1 . (9)
Since H is a tree, the number of edges in H that connect these
disconnected components and the nodes in R is y + |R| − 1.
There are at least
∑
vi∈R
di(H) − (|R| − 1) edges connecting
the nodes in R and the disconnected components created by
removing R from H . Hence, we have
y + |R| − 1 ≥
∑
vi∈R
di(H)− (|R| − 1) . (10)
From (9), (10), and that y∗ ≥ y, we have∑
vi∈R
ci(H∗) ≥
∑
vi∈R
ci(H)− (|R| − 1) . (11)
Substituting (11) into (8), we obtain
W (H∗) ≥
∑
vi∈R(ci(H)e
r + eti(H
∗))− (|R| − 1)er∑
vi∈R ei
. (12)
It is clear that∑
vi∈R
eti(H
∗) ≥
∑
vi∈R
eti(H)− |R|δ
t
. (13)
Substituting (13) into (12), we obtain
W (H∗) ≥
∑
vi∈R(ci(H)e
r + eti(H))∑
vi∈R ei
− (|R| − 1)e
r + |R|δt∑
vi∈R ei
≥ min
vi∈R
Wi(H)− |R|(e
r + δ
t
)− er∑
vi∈R ei
. (14)
Corollary 1: Let G = (V,L) be a given sensor network.
Let H∗ be a minimum-load data gathering tree in G and W ∗
be the normalized load of H∗. Given a data gathering tree H
in G and an  > 0, let
Vh = {vi : (k − 1) < Wi(H) ≤ k} (15)
be the set of heavily loaded nodes, where k = W (H) . Let
Vm = {vi : (k − 1)− e
r + δti
ei
< Wi(H) ≤ (k − 1)} (16)
be the set of medium loaded nodes, where δti = eti − eti.
Suppose that there is a set R ⊆ (Vh∪Vm) such that the removal
of R from H creates a set of disconnected components which
are also disconnected in G. Then
W ∗ > W (H)− − 2(e
r + δ
t
)
e
, (17)
where e = minvi∈Vs ei.
Proof: Since the normalized loads of any node vi in R
is greater than (k − 1) − er+δtiei and k ≥ W (H), it followsfrom Theorem 1 that
W (H∗) > (k − 1)− e
r + δ
t
e
− |R|(e
r + δ
t
)− er∑
vi∈R ei
> W (H)− − e
r + δ
t
e
− |R|(e
r + δ
t
)
|R|e
= W (H)− − 2(e
r + δ
t
)
e
. (18)
V. THE PROPOSED ALGORITHM
Starting from an arbitrary spanning tree rooted at the base
station v0 and spanning the set of sensors Vs, the proposed
algorithm tries to reduce the normalized load of one of the
heavily loaded nodes by partially rearranging the current tree
to create a new tree. Such a reduction of the normalized load of
a heavily loaded node is called an improvement. The proposed
algorithm tries to make improvements until no improvement
can be made to heavily loaded nodes.
A. Making an improvement
Let H be the current tree. For a heavily or medium loaded
node vz , we can try to reduce (or improve) its normalized
load as follows. If there is an edge in G but not in H between
two nodes vi and vj , both are neither heavily nor medium
loaded, such that adding this edge to H creates a cycle with
vz , vi, and vj on the cycle as shown in Fig. 1, an improvement
can be made to decrease the normalized load of node vz by
This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the IEEE ICC 2010 proceedings
not in H , connecting the components in Q. Thus, Corollary 1
cannot be applied. In this case, Theorem 1 can be applied to
obtain the lower bound of the normalized load of the optimal
tree.
To find the lower bound of the normalized load of the opti-
mal tree using Theorem 1, the nodes are sorted in descending
order according to their normalized loads. Then the nodes are
removed from H one by one starting from the node with high-
est normalized load until a set of disconnected components is
created, and the components are also disconnected in G. In the
worst case, there is only one component left after removing
the nodes from H . At this stage, the set of nodes R has been
found. Thus, Theorem 1 can be used to provide the lower
bound of the normalized load of the optimal tree.
D. Computational complexity of the algorithm
Each iteration of Step 2) through Step 8) of the algorithm
reduces the normalized load for a heavily loaded node, say
vi, by at least erei . It takes at most  er/ei  iterations to
reduce the normalized load of vi by . Let H˜ be the initial
data gathering tree and k˜ = W (H˜) . Let V jh be the set
of nodes whose normalized loads are greater than j, i.e.,
V jh = {vi : j < Wi(H˜)}, j = 1, 2, · · · , k˜−1. It takes at most∑
vi∈V k˜−1h
 er/ei  iterations to reduce the normalized loads of
the nodes in the set V k˜−1h until their normalized loads are no
more than (k˜ − 1), and at most ∑
vi∈V k˜−2h
 er/ei  iterations
to reduce the normalized loads of the nodes in the set V k˜−2h
until their normalized loads are no more than (k˜ − 2), and
so on. Thus, the total number of iterations of Step 2) through
Step 8) is at most
1∑
j=k˜−1
∑
vi∈V jh
 er
ei
 ≤
k˜−1∑
j=1
⎛
⎜⎝ 
er
∑
vi∈V jh
ei + |V jh |
⎞
⎟⎠ . (19)
For each node in the set V jh , we have j <
ci(H˜)e
r+eti(H˜)
ei
.
Then, jei < ci(H˜)er + eti(H˜). Summing over all nodes in
the set V jh , we have
j
∑
vi∈V jh
ei <
∑
vi∈V jh
(
ci(H˜)er + eti(H˜)
)
<
∑
vi∈V jh
di(H˜)er + net
< n(2er + et) . (20)
where et = maxvi∈Vs eti. The last inequality is due to the fact
that the total degree of the vertices of a tree consisting of n
vertices is 2(n− 1). From (20), we obtain

∑
vi∈V jh
ei <
n(2er + et)
j
. (21)
Combining (20) and j∑vi∈V jh ei > j|V jh |e , we have
n(2er + et) > j|V jh |e. Thus, we obtain
|V jh | <
n(2er + et)
je
. (22)
TABLE I
TRANSMISSION RANGE AND ENERGY CONSUMPTION
Power level 1 2 3 4 5
Transmission
range (m) 9.97 18.78 22.32 25.04 28.10
Energy
consumption (mJ) 0.1016 0.1248 0.1449 0.1562 0.1618
Power level 6 7 8 9
Transmission
range (m) 29.76 31.53 33.40 37.47
Energy
consumption (mJ) 0.1750 0.1800 0.1963 0.2107
Substituting (21) and (22) into (19), we have
1∑
j=k˜−1
∑
vi∈V jh
 er
ei
 < n(2er + et)
(
1
er
+
1
e
) k˜−1∑
j=1
1
j
< n(2er + et)
(
1
er
+
1
e
)
[1 + ln(k˜ − 1)] . (23)
The last inequality is because that the (k˜−1)st partial sum of
the harmonic series is bounded from above by 1 + ln(k˜ − 1).
It is clear from (4) that the normalized load of any node is
less than ne
r+et
e . Hence, k˜ is at most ne
r+et
e . Thus, the
total number of iterations of Step 2) through Step 8) is at
most of O(( 1er +
1
e )nlog(
ner+et
e )). Each iteration of Step 2)
through Step 8) involves no more than m union operations
of disjoint sets at Step 6f), where m is the total number of
edges in G. The worst-case computational complexity of m
union operations of disjoint sets is O(mα(m,n)) [12], where
α(m,n) is the inverse of Ackermann’s function. Therefore
the worst-case computational complexity of the algorithm is
O(( 1er +
1
e )nmα(m,n)log(
ner+et
e )).
VI. SIMULATION STUDY
The performance of the proposed algorithm is studied via
simulations. To the best of our knowledge, no previous work
employs the same model as the model used in this paper. It is
not fair to compare algorithms that are designed for different
models. In order to make a fair comparison, we modify the
PEDAP-PA protocol proposed in [7] such that the edge cost
between two neighbor nodes is calculated according to the
model use in this paper. The simulation results for the modified
PEDAP-PA protocol will be labeled “Modified PEDAP-PA” in
the figure to be presented.
In our simulations, the values of the parameters related to
a sensor is selected according to the data sheet of the Texas
Instruments CC2520 Zigbee/IEEE 802.15.4 RF transceiver for
the 2.4 GHz unlicensed ISM band [13]. The data rate is 250
kbps. The size of the message is selected to be 560 bits (or 70
bytes). The amount of energy for a sensor to receive a 560-
bits message is 0.116 millijoules, i.e., er = 0.116 millijoules.
The transmission power level of each sensor ranges from 1
to 9. The transmission range and the amount of energy for
a sensor to transmit a 560-bits message using each power
level are given in Table I which is calculated according to
the output power and current consumption measured on the
cc2520 reference design [13] and a path-loss formula with a
path-loss exponent of 4 [14]. The initial amount of energy of
a sensor is randomly selected between 1 and 10 joules.
This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the IEEE ICC 2010 proceedings
無衍生研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
研究成果有助於後續對 multiccast traffic grooming in WDM networks 之更
深入研究，本計畫之研究成果就與後續之研究成果一併撰寫論文，投稿至知名
國際會議或期刊。 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
