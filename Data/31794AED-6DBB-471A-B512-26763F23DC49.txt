2 
 
目  錄 
 頁碼 
一、摘要……………………………………………………………………………3 
二、前言……………………………………………………………………………5 
三、研究目的………………………………………………………………………6 
四、文獻探討………………………………………………………………………8 
五、研究方法………………………………………………………………………10 
六、研究結果………………………………………………………………………19 
七、計畫成果自評…………………………………………………………………26 
八、參考文獻……………………………………………………………………27 
4 
 
資料重要性與彈性保護機制，做最佳節點選擇與彈性視訊資料保護，已達到在節點擾動(peer 
churn)的環境之下，節點能有接收穩定的視訊品質。 
Abstract： 
With the announcement of service of the third-generation mobile networks and the growth of 
technology of WiFi and WiMAX, people can link to the internet using any device at anytime and 
anywhere. With the rapid growth of wireless networks, the networks of home and office will be 
wireless and make it possible to access multimedia data on the move. However, wireless 
communication isn’t reliable as wired. Video transport over wireless networks may suffer from 
signal fading, noise interference and network congestion which will usually cause data error or 
packet loss, and lead to serious video quality degradation. To handle the problem, the most popular 
approach is to use error resilience source coding tools.  
In the three years of this project, we study the error resilience technology for mobile devices to 
transmit multimedia data over wireless networks. Our research can enhance the efficiency of 
transmission, so as to improve the visual quality significantly. In the first year, we focus on power 
controlling to keep the video quality for mobile devices with energy-constrained on local wireless 
networks application. According to the contents of video, we use the suitable source coding 
compression mode to reduce the effect of error propagation. In the second year, we address the 
main problem of multicasting which is the diversity of receivers. The diversity may cause different 
receiving constrains for modulations. So, the transmitter should choose proper modulations to 
achieve the satisfactions of most receivers. Therefore, our research in-tends to adjust the modulation 
scheme of each coding video layer in each group of picture (GOP) time according to the size of 
video layer, receiver distribution, and available symbols of this video session. In the third year, we 
propose a new P2P streaming method involving peer selection, video coding, and packet protection 
to improve video quality under peer churn situation. 
 
 
 
 
 
 
 
6 
 
三、 研究目的 
First year 
 
Video transport over wireless networks may suffer from signal fading, noise interference and 
network congestion which will usually cause data error or packet loss, and lead to serious video 
quality degradation. To handle the problem, the most popular approach is to use error resilience 
source coding tools. But it always is a problem to implement error resilience and transmission 
schemes for mobile devices optimally under its constraint of memory, power and computing 
limitation. 
At first year, we focus on power controlling to keep the video quality for mobile devices with 
energy-constrained on local wireless networks application. According to the contents of video, we 
use the suitable source coding compression mode to reduce the effect of error propagation. We will 
focus on the error resilience and transmission scheme to optimize the control of coding, especially 
for multicast transmission. 
 
Second year 
The IEEE 802.16 standard (commonly known as WiMAX), which has been proposed as a 
new wireless broadband standard, is capable of delivering very high data rate and covering wide 
area. Furthermore, the video multicast service would become one potential application over 
WiMAX with the popularity of streaming applications in the Internet. The main purpose of this 
research is to propose a low-complexity decision mechanism for the modulation of video coding 
layers to ensure the efficiency of bandwidth usage. 
The main problem of multicasting is the diversity of receivers. The diversity may cause 
different receiving constrains for modulations. So, the transmitter should choose proper 
modulations to achieve the satisfactions of most receivers. Therefore, this research intends to adjust 
the modulation scheme of each coding video layer in each group of picture (GOP) time according to 
the size of video layer, receiver distribution, and available symbols of this video session. From 
above-mentioned factors, an optimization problem can be formulated and then solved with 
weighted average and minimax methods.  Furthermore, a GA-based algorithm is proposed to 
reduce the complexity of modulation decision. Simulation results are shown to compare the 
above-mentioned three optimization methods.  
 In addition, this report also makes a study on allocation of given total downlink symbols to 
OFDMA subcarriers in several multicast video sessions. 
8 
 
四、 文獻探討 
In this research, the topics include content-based error-resilient coding, adaptive modulation, 
and P2P Video streaming. The content-based error-resilient coding (CBERC) scheme proposed in 
[1] takes video content into account in making intra-refresh decisions by using the zero-motion 
concealment error to identify important macroblocks. However, simply using error concealment 
error without considering motion information may not be able to capture the error propagation 
effect very well. The method presented in [2] proposes a rate-distortion framework with analytical 
models that characterize the error propagation of corrupted video bitstream subjected to bit errors. 
These models are then used to guide the selection of spatial and temporal localization tools: 
synchronization marker and intra-refresh to achieve optimal combinations of spatio-temporal 
error-resilience and transmission bit-rate under different conditions. Although the method achieves 
good performance, its computational complexity may be too high to meet real-time requirements. In 
[3], an error-resilience transcoder was proposed for GPRS (general packet ratio services) 
mobile-access networks. The transcoder is placed at a video proxy located at the edge of two or 
more networks. Two error-resilience tools: adaptive intra-refresh (AIR) and reference frame 
selection (RFS) with feedback control signaling (FCS), are exploited adaptively to reduce error 
effects, while preserving the transmission rate management feature of the video transcoders. 
 The problem of multicasting a video program to multiple clients with disparate channel loss 
profiles is important and pratical. Ammar et al. [4] proposed a destination set grouping (DSG) 
protocol to improve inter-receiver fairness for multicast communication. The paper defined a single 
receiver fairness fuction that maps from the actual operating rate to a fairness value of users. The 
fairness function is in general application dependent. In [5], a single fairness function was also 
defined to deal with the inter-receiver fairness of receivers for multicast. The inter-receiver fairness 
was achieved by maximizing the weighted sum of the individual fairness values of each receiver 
with different reception capability in a multicast group to perform max-min fair allocation. The 
method presented in [6] further extended the results in [5] to provide inter-session fairness among 
similarly controlled multicast sessions based on a specific two-group model. The method presented 
in [7] minimizes the maximum performance degradation for all users in video broadcasting. A 
gradient-based optimization scheme was proposed to find the optimal operating point. In [8], in 
order to constrain the quality variation for a group of heterogeneous receivers, two multicast 
performance metrics, weighted average quality and MINMAX degradation, were evaluated. The 
proposed method dynamically adapts quantization parameters, intra frame rate and channel coding 
rate to optimize a chosen multicast performance metric, based on the video quality curves 
achievable with different operating points for different possible channel conditions. However, how 
10 
 
五、 研究方法 
1. Content-Aware Intra-Refresh Transcoding with profit tracing 
(CAIR-PT) 
Adding error-resilience to video bitstream for robust video delivery to users thusbecomes 
a very important issue. In this work, we propose a two-pass intra-refresh transcoding scheme 
for inserting error-resilience features to a compressed video at the media gateway of a 
three-tier streaming system. The proposed transcoder can adaptively vary the intra-refresh rate 
according to the video content and the channel’s packet-loss rate to protect the most important 
macroblocks against packet loss. In the first-pass encoding, the encoder estimates the amount 
of error propagation at MB level, and then generates side information as transcoding hints for 
use at the transcoder. In the second-pass transcoding, the error-resilient transcoder adaptively 
determines the intra-refresh rate and the locations of macroblocks to perform intra-refresh 
according to the side information. 
In this work, we adopt the two-pass error-resilience transcoder. In the architecture, after 
the first-pass front-end encoding, the transcoder uses the side information received from the 
streaming server and the channel statistics (e.g., the packet loss rate) collected from a feedback 
channel to determine an intra-refresh allocation for each frame of a GOP. The transcoder then 
performs intra-refresh on a number of high-priority macroblocks with highest loss-impact 
factors according to the intra-refresh allocation.  
 
Figure 1: Profit tracing of each refreshed macroblock. 
 
The macroblock-level error propagation EPMB is estimated by summing up the 
loss-impact values of the pixels in the previous frame that are referenced by this macroblock in 
the motion-compensated prediction process. However, it is very likely that temporally 
correlated macroblocks along a prediction path between successive frames all have high EPMB 
12 
 
In (1), for the sake of simplicity, we use the packet loss rate PLR to approximate the pixel 
loss rate in a GOP, since the two loss rates usually have close values for a sufficiently large 
amount of data (e.g., a GOP). As such, a pixel in frame n-1 has a probability of (1-PLR) to 
provide a correct reference value to the succeeding macroblocks of frame n which reference 
the pixel value. According to SRF(x,y,n)-, the transcoder will determine the intra-block 
allocation for frame n. After the mode decision, the intermediate value SRF(x,y,n)- will be 
transferred to a refreshed value SRF(x,y,n)+ based on the coding mode. SRF(x,y,n)+ is set to be 
1, if pixel (x,y) belongs to an intra-refreshed macroblock. Otherwise, SRF(x,y,n)+ remains the 
same as SRF(x,y,n)-. The initial values, SRF(x,y,0)- , are all set to 0. Besides, in an initial 
I-frame, the values of SRF(x,y,0)+ are all equal to 1. In summary, the SRF values are 
determined as follows: 
 
 
(2)
 
As depicted in Figure 2, we use the motion information to map pixel-level SRF(x,y,n-1)+ 
from the previous frame to obtain the macroblock-level ( , )MBSRF m n  with value of ranging from 
0 to 1, as follows:  
(3)
where SRF(x,y,n)- is calculated using (1), and SIZEMB represents the number of pixels in a 
macroblock.  
After computing ( , )MBSRF m n , we select a total of Nintra(n) macroblocks with top-ranking 
EP MB (m,n)⋅ {1− ( , )MBSRF m n } values to perform intra-refresh for the n-th frame of a GOP. 
 
2. Adaptive Modulation for Video Multicast Over WiMAX Network 
This work is built on top of WirelessMAN-OFDMA system. The OFDMA PHY mode of 
IEEE 802.16 en-ables a BS to support multiple users at the same time. Furthermore, a BS 
utilizes the available channel by dividing the subcarriers into subchannels that can be assigned 
to mul-tiple users in an adaptive and elaborate way. As a matter of fact, users can be assigned 
to different bandwidths and configured by dif-ferent modulations based on various conditions 
14 
 
must meet some constraints, e.g., 1 ( ).....≤ ≤BL EL EL LMod Mod Mod .  
To measure the performance of each combination of modulation schemes, we use the 
peak signal-to-noise ratio (PSNR) as the distortion metric in formulating the optimization 
problem. The symbol size allocated to each layer given a modulation combination (ModBL, 
ModEL1, …,ModEL(L)) is calculated as in (4), under the assumption that the available symbol 
number is more than that required for BL so that BL will be received completely.  
 
GOP( )BL BLSize Mod BL=  (4)
 
 
⎪⎪⎩
⎪⎪⎨
⎧
×⎟⎟⎠
⎞
⎜⎜⎝
⎛ −−−−−
≥−−−−
=
−
elseByte
Byte
jEL
Byte
EL
Byte
BL
Symbol
Byte
ELj
Byte
EL
Byte
BL
SymbolifELj
ModModModSize
ELj
jEL
GOP
EL
GOP
BL
GOP
rtPS
ELj
GOP
EL
GOP
BL
GOP
rtPSGOP
ELjELBLELj
,
)1(
...
1
0...
1
,
),...,,(
)1(1
1
1
 
(5)
where SymbolrtPS is the available number of symbols reserved for the rtPS service. Then, we 
convert the allocated symbol size to the transmission rate for each layer. 
frame
GOP
( ) ( )BL BL BL BL
RRate Mod Size Mod
N
= ×  (6)
 
GOP
frame
1
1
),...,,(
),...,,(
N
RModModModSize
ModModModRate
ELjELBLBL
ELjELBLELj
×=
 
(7)
where Rframe presents the frame rate of sequence and NGOP denotes the GOP size. The receiving 
rate of user c when the modulation combination is (ModBL, ModEL1, …,ModEL(L)) can be 
expressed by (8) according to the transmission rate and PER of each layer, where 
PERELj,c(ModELj) denotes the packet error rate of receiver c for the j-th EL which is modulated 
by ModELj. 
 
[ ][ ]
[ ]∑
=
×−
+=
×−+
+×−+=
L
j
ELjELBLELjELjcELj
BLBL
LELELBLLELLELcLEL
ELBLELELcELBLBL
LELELBLc
ModModModRateModPER
ModRate
ModModModRateModPER
ModModRateModPERModRate
ModModModRate
1
1,
)(1)()(),(
111,1
)(1
),...,,()(1
)(
),...,,()(1...
),()(1)(
),...,,(
 
(8)
As shown in (9), the PER of layers for receiver c is set either 0 or 1. We assume if the 
SNR of receiver c is larger or equal to the SNR of ELj determined by the modulation of ELj, 
the PER of ELj for receiver c is 0; otherwise, PER is 1.  
⎪⎩
⎪⎨
⎧
<
≥=
ELjc
ELjc
ELjcELj SNRSNR
SNRSNR
ModPER
,1
,0
)(,  (9)
 failur
peer 
peer’
desce
Diffe
both 
peer 
propo
redun
 
 
T
good
const
video
peers
lowe
meth
pack
recog
it de
contr
and B
be of
have
propo
depe
e peer hav
cannot find
s streamin
ndant peer
rent effects
peers B an
C cannot r
se a peer
dancy. 
he main co
1) Childre
 video qual
raint. A ch
 data or ha
 to share d
ring down 
od for rank
et/video blo
nize a well
serves. Sup
ibuted mor
 have to fi
fered with 
 more desc
se a new m
ndency. W
e to find a
 a replacem
g session w
s will turn
 caused by
d C cannot 
eceive the 
 selection 
 Figure 4
ncept behi
n selection
ity for well
ild-peer is c
s delivered
ata with oth
their utilit
ing a peer’
cks the pe
-behaved p
pose that 
e base-laye
nd a replace
higher prio
endant peer
etric for r
e use the 
nother repl
ent peer i
ill be int
 to starvat
 peer leavin
receive vid
video, whi
scheme to 
: Different
nd the prop
: In incenti
-behaved c
onsidered 
 data to mo
er peers; o
y. Howeve
s contributi
er has cont
eer in a vid
peer A ha
r chunks th
ment peer.
rity to resu
s of B whi
anking a pe
mean squa
16 
acement pe
n time dur
errupted, w
ion, namely
g., in the c
eo. In the d
ch can be 
protect im
 effects cau
osed peer s
ve-based P
hildren pee
well-behave
re peers. G
therwise, p
r, most th
on are the 
ributed. Us
eo delivery
s contribut
an A. Whe
 In tradition
me its vide
ch may tur
er’s contrib
red error (
er to resum
ing the lea
hich is ca
 chain rea
hain reacti
irect effec
resolved b
portant da
sed by peer
election sch
2P streamin
rs under th
d if it has b
enerally, in
oor-behave
e metrics u
peer’s uplo
ing such si
 path to ser
ed more da
n a parent
al incentiv
o data deliv
n to starvat
ution that 
MSE) disto
e the sessi
ving/failure
lled direct 
ction. As 
on, if peer A
t, if peer B 
y using MD
ta as well 
 
 leaving. 
eme has tw
g, a parent
e parent-pe
een contri
centive-bas
d child-pee
sed in ex
ad bandwid
mple metri
ve them w
ta than pe
 peer of A 
e-based me
ery than B
ion. To add
takes into a
rtion of a
on. In the 
 of a paren
effect. Mo
depicted in
 leaves (th
leaves (the
C. In this
as to redu
o aspects: 
-peer shou
er’s upload
buting mor
ed methods
rs will be p
isting incen
th, and the
cs may not
ith better re
er B, whe
and B leav
thods, A w
. However
ress this p
ccount the
 video pac
case that a
t peer, the
reover, its
 Figure 4:
e solid X),
 dotted X),
 paper, we
ce coding
ld maintain
 bandwidth
e important
 encourage
unished by
tive-based
 amount of
 be able to
source that
reas B has
es, peers A
ill typically
, there may
roblem, we
 video data
ket, which
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
18 
 
parent peers.  Therefore, the rank of a candidate parent peer among grand-parent peers 
should also be taken into consideration. The proposed method jointly considers the 
availability, rank, and available download bandwidth as follows: 
(1 )parent parent parent availableS A R BW= ⋅ − +  ( 15)
1 m
parent
m m
rankR
M T
= ∑ ( 16)
 
where Aparent denotes the availability of the candidate parent-peer, Rparent represents the 
average rank among grand-parents, M is the number of grand-parent peers, rankm is the parent 
rank in the m-th grand-parent,  Tm is the number of children peers of the m-th grand-parent 
peer, BWavailable is the available download bandwidth, and Rparent, rankm are from 0 to 1. 
Higher Sparent rank implies higher stability of a peer. The ranking information can be attached 
into gossip messages. Chunks are requested from the lowest layer to high layers, therefore 
base layer chunks should be transmitted by the most reliable parent peers. Each child should 
keep maximizing the sum of Sparent dynamically. 
Since developing an optimized channel protection method is not the central focus of this 
work, we here use a heuristic algorithm to decide the amount of the redundancy data, as 
shown in Table 1, where distributed_count[j] is the number of delivered churns for the j-th 
layer, and redundancy[j] is the number of additional churns for data protection. The key idea 
behind the protection algorithm is that more protection data in layer j should be given to the 
peers which contributed more churns in layer j. 
Table 1 : Heuristic algorithm to decide the amount of protection data. 
if (0 < distributed_count[j] && distributed_count [j] ≤ 5)  
    redundancy[j] = 1; 
if (5 <  distributed_count[j] && distributed_count[j] ≤ 10)   
redundancy[j] = 2; 
if (10< distributed_count[j] && distributed_count[j] ≤ 20) 
redundancy[j] = 3; 
else if (20 <  distributed_count[j])      
redundancy[j] = 4; 
 
 
 
20 
 
indicates that the CAIR-PT scheme achieves more significant improvement on low-activity 
video than on high-activity ones. This is because the EPMB value of a low-activity macroblock 
in a frame tends to be most inherited by a single macroblock rather than shared by several 
macroblocks in the following frame, thereby resulting in a longer sequence of high EPMB 
macroblocks along a prediction path, which usually leads to poorer intra-refresh allocation 
efficiency in the CAIR transcoder. The results also show that the improvements under lower 
PLRs are typically larger than those under higher PLRs, because SRF will have a relatively 
higher probability of (1-PLR) to propagate to the following frames in situations with lower 
PLRs. 
Table 3 shows the run-time analysis of the first-pass encoding and second-pass 
transcoding on an Intel Pentium- Ⅲ  1-GHz PC. With the proposed error-propagation 
estimation method, the first-pass encoding consumes significantly more time than the original 
one. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
22 
 
2. Adaptive Modulation for Video Multicast Over WiMAX Network 
We adopt the ns-2 module for WiMAX developed by NDSL [18] as our simulation 
platform and implement the proposed modulation selection scheme as a part of the MAC 
layer protocol. The propagation model used in our experiment is the Two-Ray Ground 
Reflection model. The simulation parameters are Pt =25 dBm, Gt =15 dBi, Gr =1 dBi, ht = 
32m, hr = 1.5m, T = 298K, and NF = 7dB. We use the SVC JSVM 2.0 reference coder to 
generate the video layers. The QCIF (176x144) test sequences are pre-encoded at 15 fps. The 
GOP size is 16, and the number of FGS layers is 3. The total number of receivers is fixed as 
five. The coverage range of BS is a circle with a radius of approximate 39Km. The 
transmission from BS to SS is direct one-hop without any relay. 
(Foreman)   Disto rtion  v .s Time(GOP num ber)
40
60
80
100
120
140
G OP0 G OP1 G OP 2 G O P 3 G OP4 G OP5 G OP 6 G OP 7
Tim e(GOP num ber)
To
tal
 D
ist
ort
ion
(M
SE
)
(0,0)
(0,1)
(0,2)
(0,3)
(0,4)
(0,5)
(1,1)
(1,2)
(1,3)
(1,4)
(1,5)
(2,2)
(2,3)
(2,4)
(2,5)
(3,3)
(3,4)
(3,5)
(4,4)
(4,5)
(5,5)
proposed  
      Figure 7 : Distortion of various EL modulations with time when SS distribution (0 1 2 0 1 1) 
and the number of available symbols = 900. 
 
When the number of available symbols and the SS group number (m0 m1 m2 m3 m4 m5) = 
(0 1 2 0 1 1), the variable factor in the optimal modulation selection scheme is the size of each 
video layer. Since the data sizes of GOPs are not the same, the sizes of layers are also 
different. We deal with this variable factor by performing the optimal modulation selection 
scheme for each GOP. The impact on the size of each video layer in the optimal modulation 
selection scheme can also be observed. From another point of view, if we directly apply the 
optimal modulation for GOP #1 to the following GOPs, this may result in higher distortion in 
the following GOPs compared to their corresponding optimal results. Figure 7 reveals the 
ability of adaptation of the proposed scheme as well as justifies that our scheme always 
maintains the lowest average distortion.  
Figure 8 shows the average distortion with varying available symbols for three 
optimization methods. According to this figure, the GA-based algorithm does not accuracy in 
24 
 
Table 4 : Heterogeneous peers distribution[19] 
Class Downlink Uplink Percentage 
1 512 kbps 256 kbps 56% 
2 1.5 Mbps 384 kbps 21% 
3 3 Mbps 896 kbps 9% 
4 20 Mbps 2 mbps 3% 
5 20 Mbps 5 mbps 11% 
 
Table 5 : Bandwidths and average PSNR qualitites of heterogeneous peers 
Layer 
Rates 
(kbps) 
PSNR 
Laye
r 
Rates 
(kbps) 
PSNR 
0 150 28.93dB 3 300 36.99dB 
1 200 31.14dB 4 300 38.13dB 
2 250 33.99dB 5 300 40.35dB 
 
The metrics we use for evaluating video quality include playback continuity, average 
decodable PSNR, and the variation of decodable PSNR. The continuity metric is defined as 
follows: 
Number of decodable GOPs
Total number of GOPs
Cont =  (17)
For an SVC coded bitstream, if the base-layer of a GOP is decodable, the GOP can be 
played back with baseline quality. Therefore the continuity metric is a measurement of the 
reliability of the base-layer data being received. The average decodable PSNR is defined as 
1
1 ( , )
L
n
avgPSNR PSNR m n
L =
= ∑  (18)
where L is the on-line time of this peer. Since peers may not successfully receive enhancement 
layer chunks, the decodable video quality would fluctuate with the number of lost video chunks. 
Hence we evaluate video quality variation by 
_ STD( ( , )),  (1, )std PSNR PSNR m n n L= ∈  (19)
We compare three strategies: (a) a non-incentive-based method that implements random 
parent/child-peer selection without data protection, denoted as “random”; (b) an incentive 
method that choose child-peers according to the contributed upload bandwidth of peers, 
chooses parent-peers according to the maximum available upload bandwidth, and implements 
adaptive data protection, denotes as “maxBW”; (c) Our proposed incentive peer selection 
scheme and with adaptive data protection, denoted as “maxReliable”. 
 
26 
 
七、 計畫成果自評 
We have proposed a two-pass error resilience transcoding scheme with profit tracing by 
using prioritized intra-refresh. The profit tracing mechanism can improve the efficacy of 
intra-fresh allocation by avoiding wasting intra-refresh resources in macroblocks of high 
error-propagation ranks in the same prediction path. Experimental results show that the 
proposed transcoder mitigates the error propagation due to packet loss much more effectively 
so as to improve the visual quality significantly compared to the regular intra-refresh, random 
intra-refresh and CBERC transcoders. Incorporating the proposed profit tracing mechanism 
into the CAIR transcoder can further achieve significant PSNR performance improvement over 
the CAIR scheme itself. 
In the second year, we proposed an optimal rate allocation scheme for scalable video 
multicast over WiMAX. Our proposed method makes best use of available symbols through 
adaptive modulation selection in each GOP time by taking into account the size of each video 
layer, SS group numbers, the available rate, and mobility property of SS. The different 
performance metrics were exploited in the optimization. We have also proposed a GA-based 
scheme to reduce the computational complexity of the proposed rate allocation scheme. 
In the third year, we proposed an incentive-based peer selection method for reliable P2P 
scalable video streaming. We have also proposed a modified MD-FEC scheme which takes 
into account both video scalability and efficient bandwidth utilization. In our proposed method, 
video layer dependency and peer topology information are jointly considered to combat 
against chain reactions caused by peer churns. We adopted video distortion as the metric of our 
incentive method for child-peer selection. In parent-peer selection, availability and rank are 
applied to find robust parent peers. The proposed adaptive protection scheme avoids the direct 
effect of peer leaving as well as mitigates the chain effect. Simulation results show the 
proposed method improves video playback continuity and achieves better PSNR quality when 
peer churns occur. 
The results of this project are published in [21]~[27]. 
 
 
 
28 
 
[16] G. Cote and F. Kossentini, “Optimal intra coding of blocks for robust video communication 
over the internet,” Signal Processing: Image Communication, vol. 15, pp. 25-34, 1999. 
[17] W.-H. J. Chen and J.-N. Hwang, “The CBERC: A content-based error-resilient coding 
technique for packet video communications,” IEEE Trans. Circuits Systems Video Technol., 
vol. 11, pp. 974-980, 2001. 
[18] J. Chen, C.C. Wang, Frank C.D. Tsai, and C.W.Chang,"The designand implementation of 
WiMAX module for ns-2 simulator," in Proc. ACM SESSION., vol. 202, no. 5, 2006.  
[19] E. Setton, P. Baccichet, and B. Girod, “Peer-to-peer live multicast: A video perspective,” 
Proc. IEEE, vol. 96, no. 1, pp. 25–38, Jan. 2008. 
[20] ITU-T and ISO/IEC JTC1, JVT-O202, Joint Scalable Video Model JSVM-2, Apr. 2005. 
[21] Chih-Ming Chen, Chia-Wen Lin, and Yung-Chang Chen, "Adaptive error-resilience 
transcoding using prioritized intra-refresh for video multicast over wireless networks,” Signal 
Processing: Image Communication (Special Issue on Mobile Video), vol. 22, no. 3, pp. 
277-297, March 2007.  
[22] Chih-Ming Chen, Chien-Min Chen, Chia-Wen Lin, and Yung-Chang Chen, “Error-resilient 
video streaming over wireless networks using combined scalable coding and multiple 
description coding,” Signal Processing: Image Communication, vol. 22, no. 4, pp. 403-420, 
April 2007.  
[23] Chih-Ming Chen, Chia-Wen Lin, Hsiao-Cheng Wei, and Yung-Chang Chen, “Robust Video 
Streaming over Wireless LANs Using Multiple Description Transcoding and Prioritized 
Retransmission,” Journal of Visual Communication and Image Representation, In Press, 
Corrected Proof, Available online 15, Feb. 2007. 
[24] Chih-Ming Chen, Chia-Wen Lin, and Yung-Chang Chen, “Adaptive error-resilience 
transcoding and fairness grouping for video multicast over wireless networks,” in Proc. IEEE 
International Conference on Communications (ICC’07), 24-28 June 2007. 
[25] Chih-Ming Chen, Chia-Wen Lin, and Yung-Chang Chen, "Cross-layer error protection for 
video streaming over wireless LANs using content-aware packet retry limit adaptation," 
submitted to IEEE Trans. Circuits and Systems for Video Technology. 
[26] Yung-Chang Chen, and Chih-Ming Chen, “Optimal Rate Allocation for Scalable Video 
Multicast over WiMAX ,” IEEE Int. Symp. Circuits and Systems, May 2008, Seattle, WA, 
USA  
[27] Chi-Wen Lo, Chia-Wen Lin, and Yung-Chang Chen, “On Peer Selection and Protection for 
Reliable Peer-to-Peer Video Streaming,” IEEE Pacific-Rim Conference on Multimedia, Dec. 
2009.  
次會議在新加坡舉辦。 
        本次會議的主題演講由以色列 The Hebrew University of Jerusalem 的 Shmuel Peleg 教
授講 Non-Chronological Video Editing and Video Synopsis，對於長時間錄下來的影帶提出
如何在時空上予以壓縮，可以在極短時間內看出所有的活動的方法，十分簡單可行。另
外在十五日與十六日上午的特邀演講，分別由早稻田大學的森島繁生教授講 Instant 
Casting System “Dive into the Movie”，與東京大學五十嵐健夫准教授講 Interactive “smart” 
computers 都非常精采，與會者皆受益良多。 
        我受邀擔任 OS5:Multiview Geometry 的 Session Chair，該 Session 在十五日上午 10：
30 至 12：00，總共有 4 篇口頭報告論文，導引聽眾聽講並鼓勵參與討論，成效良好，其
中一篇並於當晚的晚宴獲選為最佳大會論文，其論文題目是”Compact Fundamental Matrix 
Computation”。我與學生合著的兩篇論文”Integrated Expression-Invariant Face Recognition 
with Constrained Optical Flow”, “Improved Two-Level Model Averaging Techniques in 
Drosophila Brain Modeling”分別在十五日下午時段與十六日上午時段發表，跟與會者充分
討論，收穫良多。 
        晚宴在著名的「椿山莊」舉行，其庭園特別有特色，並且宴會場頗莊嚴，據說是十
九世紀日本決定其國家未來大政的場地，非常特別。因為是 Steering Committee Member，
被安排坐主桌，與幾位東京大學、東北大學名教授同桌聯誼，覺得受益不淺。 
 
integrated via a surface warping with specific landmarks, such as the brain cortex or 
specific neuropils. Two-level model averaging techniques [5] are introduced to 
construct the average shape model for the cortex and neuropils of the Drosophila 
brain. The first step is coarse-level model averaging. Global characteristics of 
different individual models are averaged in this step. After coarse-level model 
averaging, each individual model is transformed into a corresponding pseudo-average 
model. 
In the fine-level model averaging step, the average model can be obtained by 
determining the shape average of the globally-registered pseudo-average models. A 
3D distance field [6] is utilized to generate the signed distance map for each pseudo-
average model.  
Many efforts have been made on building a signed distance map of a triangular 
mesh. The procedure can be separated into two parts: sign determination and distance 
transformation. In the first half, a famous method is to count the intersection of a ray 
going from the given point to infinity. The point is determined to be within the model 
if the intersection number is odd and vice versa [7]. Another well known method 
utilizes the normal of the closest feature on mesh of the given point. Angle weighted 
pseudo normal method [8] computes the normal of all faces, edges, and points on the 
triangular mesh. In the distance transformation part, brute force algorithm directly 
computes all of the distance from the given point to the mesh points. Many methods 
have been proposed to improve the computational efficiency [9]. 
In the two-level model averaging algorithm, a linear time algorithm for distance 
transformation is applied. With the improvement of microscopic scanning technology, 
images of higher resolution can be acquired. The memories required for computing 
the distance transformation become the bottleneck of the system when the source 
images are of high resolution. In the mean while, the increase of time consumption for 
the algorithm is in proportion to the number of points needed for distance 
transformation. 
In this paper, improved two-level model averaging techniques are proposed to 
generate the average model from a set of triangular mesh models. Three 
improvements are made in the proposed algorithm. First, a two-scale distance map 
creation is introduced to reduce the memory cost. Second, the computational time 
consumption is reduced by a point-reduction scheme in the distance transformation. 
Third, an outlier rejection procedure is implemented to improve the robustness of the 
proposed algorithm.  
The paper is organized as follows. Section 2 overviews the proposed algorithms. 
Section 3 and 4 describe the coarse-level and the fine-level model averaging 
accordingly. The outlier rejection procedure is presented in Section 5. Section 6 
contains experimental results and conclusions are made in Section 7. 
2   System Overview 
Original datasets used in this study are confocal microscopic image slices. An 
experienced expert helps to label the object to be averaged from the image slices. The 
object boundary in each image is assumed to be composed of several non-crossing 
The final step is an outlier rejection to improve the robustness of the average model. 
Outliers can be picked out by an outlier rejection procedure. A refined average model 
can be obtained by performing the improved two-level model averaging algorithm 
with the remaining inliers.  
3   Coarse-Level Model Averaging 
The coarse-level model averaging is implemented by a rigid registration. In general, 
the affine registration can achieve better alignments than that of the rigid registration. 
However, the shearing and scaling are two unwanted properties in the coarse-level 
model averaging. The affine registration is easily biased by an improper reference 
model. If the reference model is a tilted model, all other individual models will be 
tilted after transformation.  
  Instead, the rigid registration allows only translation and rotation of the target 
model. The geometry of the model is preserved under rigid transformation. For 
globally registering the individual models, the rigid registration is a reliable choice. 
  A rigid transformation is define as:  
( )- .′ = + +x R x C C T  (1) 
 
where x  is the position vector of the original point on the target model.  
′x  is the position vector of the transformed point. [ ]Tx y zC ,C ,C=C  is 
the center of rotation. [ ]Tx y zT ,T ,T=T  is the translation matrix. R  is 
the rotation matrix, which is represented by the product of three 
elementary rotation matrices  
.x y z=R R R R  (2) 
 
where xR , yR , and zR  are defined by 
cos 0 sin cos sin 01 0 0
0 cos sin 0 1 0 sin cos 0
sin 0 cos0 sin cos
y y z z
x x z z
y yx x
x y z
θ            θ  θ     θ                     
   θ    θ ,                        ,  - θ     θ      
- θ           θ     - θ    θ
= = =
⎡ ⎤⎡ ⎤ ⎢ ⎥⎢ ⎥ ⎢ ⎥⎢ ⎥ ⎢ ⎥⎢ ⎥⎣ ⎦ ⎣ ⎦
R R R  .
0  0 1                      
⎡ ⎤⎢ ⎥⎢ ⎥⎢ ⎥⎣ ⎦
 
 
  The average distance between target and reference model is defined as: 
 (2) 
 
(3) 
 
 
 
 
 
 
iM , and how far it is from the surface boundary. x
v
 is on the surface 
if ( ) 0iSDM x =v  . 
  The cumulative signed distance map ( )R xv  is defined as: 
( ) ( )
1
M
K
i
i
R x SD x
=
= ∑v v  (8) 
 
where K  is the number of pseudo-average models. The surface of the final average 
model can be extracted by zero-crossing detection of ( )R xv  . 
  A 2D example is shown is Fig. 2. The inputs are two ellipses (Fig. 2(a) and 2(b)). 
The signed distance maps is computed for both ellipses and drawn in 3D(Fig. 2(c) and 
2(d)). The cumulative signed distance map is shown in Fig. 2(e). The averaging result 
of the inputs is a flattened ellipse (Fig. 2(f)). 
  In [6], a linear time algorithm is proposed for computing the Euclidean distance 
transform. The algorithm has a serial computational complexity linear in the number 
of image pixels. However, memories required for storing the signed distance map 
depend on the voxel number of the model. The memory cost becomes the bottleneck 
of the system when the source images are of high resolution. A two-scale distance 
map creation algorithm is proposed to reduce the memory cost.  
  A point-reduction scheme is introduced to reduce the time expense for computing 
the distance transform. This is achieved by computing the distance transform only on 
the necessary voxels.  
 
       
               (a)                                (b) 
 
       
              (c)                                 (d) 
  
 Fig. 3. An ellipse down-sampled by a factor of β . and E F  are the closest feature points of 
{A,  ,   and }.B C D  
4.2   Point-Reduction Scheme in the Distance Transform  
The computational time consumption is reduced by a point-reduction scheme in the 
distance transformation. Recall that the surface of the final average model is extracted 
by zero-crossing detection of the cumulative signed distance map. After coarse-level 
model averaging, the pseudo-average models are aligned to the same coordinate space. 
Voxels in this coordinate spaces can be classified into three groups: 1) voxels inside 
every models; 2) voxels outside every models; 3) the remaining voxels. 
  For the first group of voxels, the value of the signed distance map of the same 
voxel is negative for all pseudo-average models. For the second group of voxels, the 
value of the signed distance map of the same voxel is positive for all pseudo-average 
models. Thus, the cumulative distance map of such voxels will never be zero. In other 
words, the first and second group of voxels well not be on the surface boundary of the 
average model. These voxels can be assigned to be inside or outside of the average 
model directly.  
  Only the third group of voxels need to compute distance transform. The two-scale 
distance map creation method is applied on these voxels for each pseudo-average 
model. 
β  
A B
C D
E F 
G
6   Experimental Results 
There are 34 datasets of female Drosophila used in this study. Fig. 4 shows the 
results for model averaging of the brain cortex. The superposition of 34 pseudo-
average models after coarse-level averaging is shown in Fig. 4(a). The average model 
and the superposition of 34 pseudo-average models are depicted in Fig. 4(b).  
  
              (a)                                 (b) 
Fig. 4. The results for model averaging of the brain cortex. (a): 34 pseudo-average models after 
coarse-level model averaging. (b): The average model (opaque) and the superposition of 34 
pseudo-average models (transparent).  
Fig. 5 illustrates the point-reduction scheme and the two-scale hierarchy in the 
distance transform. Given pseudo-average models, Fig. 5(a) shows the points needed 
to compute the distance transform in a slice. The corresponding region for the two-
scale distance map creation is depicted in Fig. 5(b). 
       
                (a)                                (b)   
Fig. 5. Example of the point-reduction scheme and the two-scale hierarchy in the distance 
transform. (a) The points needed to compute the distance transform. (b) The corresponding 
region for the two-scale distance map creation. 
The performance improvement in the distance transform is shown in Table 1. 
Measurements were obtained using a workstation with Intel dual Xeon 2.0GHz CPU. 
This workstation was equipped with 4 GBytes of memory. The linear time distance 
transform algorithm will be out of memory for images constructed from the high 
7   Conclusions 
In this paper, an improved two-level model averaging algorithm is proposed for the 
Drosophila brain modeling. Two improvements are made in the fine-level model 
averaging. A two-scale distance map creation is introduced to reduce the memory cost. 
The computational time consumption is reduced by a point-reduction scheme in the 
distance transform. With these two improvements, average model can be constructed 
from high resolution confocal microscopic images.  
An outlier rejection procedure is implemented to improve the robustness of the 
model averaging algorithm. A refined average model can be obtained by performing 
the improved two-level model averaging algorithm with the remaining inliers.  
References 
1. Talairach, J., Tournoux, P.: Coplanar Stereotaxic Atlas of the Human Brain. Thieme 
Medical, New York (1988) 
2. Friston, K. J., Holmes, A. P., Worsley, K. J., Poline, J. P., Frith, C. D., Frackowiak, R. S. J.: 
Statistical Parametric Maps in Functional Imaging: A general Linear Approach. Human 
Brain Mapping vol. 2, 189--210 (1995) 
3. Brandt, R., Rohlfing, T., Rybak, J., Krofczik, S., Maye, A., Westerhoff, M., Hege, H.-C., 
Menzel, R.: Three-Dimensional Average-Shape Atlas of the Honeybee Brain and its 
Applications. J. Comp. Neurol. vol. 492, 1--19 (2005) 
4. Rein, K., Zockler, M., Mader, M.T., Grubel, C., Heisenberg, M.: The Drosophila Standard 
Brain. Current Biology 12, 227-231 (2002) 
5. Chen, Y. C., Chen, Y. C., Chiang, A. S.: Two-Level Model Averaging Techniques in 
Dorsophila Brain Imaging. Proceedings of 2002 IEEE International Conference on Image 
Processing, Vol. 2, pp. 941--944, Rochester, New York (2002) 
6. Maurer, C. R., Qi, R., Raghavan, V.: A linear time algorithm for computing exact Euclidean 
distance transforms of binary images in arbitrary dimensions. IEEE Trans. on Pattern 
Analysis and Machine Intelligence, 25, pp. 265--270 (2003) 
7. Dachille, F., Kaufman, A.: Incremental Triangle Voxelization. Proc. Graphics Interface, pp. 
205--212 (2000) 
8. Baerentzen, J. A., Aanaes, H.: Signed Distance Computation Using the Angle Weighted 
Pseudonormal. IEEE Trans. on Visualization and Computer Graphics, Vol. 11, No. 3, 243--
253 (2005) 
9. Gue´ziec, A.: Meshsweeper: Dynamic Point-to-Polygonal Mesh Distance and Applications. 
IEEE Trans. on Visualization and Computer Graphics. Vol. 7, No. 1, pp. 47--60, (2001) 
10. Chen, Y. C., Chen, Y. C., Chiang, A. S., Hsieh, K. S.: A Reliable Surface Reconstruction 
System in Biomedicine. Computer Methods and Programs in Biomedicine, Vol. 86, Issue 2, 
pp. 141--152 (2007) 
11. Rohlfing, T., Maurer, C. R.: Shape-Based Averaging. IEEE Trans. on Image Proc. Vol. 16, 
No. 1, 153--161 (2007) 
MSRM-P1 Poster Session。因為會議的安排錯誤，原本論文接受時是決定為口頭報告，但
是在議程安排好之後，卻變成了是海報呈現的方式，對此，會議主辦單位也承認錯誤，
但無法作修改。七月三日深夜(美國當地時間)則搭中華航空 CI011 班機於 23 時 45 分回
台，於七月五日 6 時 15 分抵達。 
 
二、與會心得 
本次大會有 633 以上的論文投稿，主辦單位為了同時能維持論文的品質，以及提高
世界上對於多媒體領域的研究興趣，共接受了 349 篇論文。礙於時間與場地的因素，錄
取的論文中只有 41%是口頭報告，59%是以張貼海報的方式(Poster)呈現，主要是為了方
便在更自由交談的情況下，增加作者與聽眾間的交談機會，充分達到學術交流目的。 
本次會議計有五場次 Tutorials，三場次 Keynote 演講，多場的座談會，同時有五場
次的 Oral Sessions 並行，再加上 Poster Sessions，可謂內容十分豐富，含蓋多媒體編碼與
處理、多媒體內容分析、多媒體資料庫、多媒體聯網、多媒體品質、多媒體互動、多媒
體系統與應用等。 
Keynote 演講第一位是由美國 HP Labs 的 John Apostolopoulos 博士介紹 The road to 
immersive multimedia communication。主要在介紹高品質的視訊會議系統的發展，讓不同
地點的使用者都可以有身歷其境的感受。像 HP 所提出的 Halo system 就是一個朝這個方
向所發展的系統。 
第二場 Keynote 是由哥倫比亞大學的 Shih-Fu Chang 教授主講 Image/Video 
Classification and Search: Addressing Semantic Gap and User Gap。在攝影機/照像機越來越
普及的現在，多媒體的資料在網路上有爆炸性的增加，如何讓使用者可以快速找到自己
需要的資訊，便越來越重要。許多單位都有關於 video search system 的研究，像是”IBM 
IMARS”, “Vision Go, National U. Singapore”, “MediaMill, U. of Amsterdam”, “CuZero, 
Columbia U.”, 和 “Information, CMU”等等。最近也有殺手級的應用出現，利用手機取得
附近景點的影像，透過網路，便可以得知這個景點的相關介紹。 
第三場 Keynote 演講是由美國 UCLA 的 Wen-mei W. Hwu 教授講 Parallel Computing: 
Revolution in Video Processing。主要介紹如何平行計算的方式，讓在影像與影片資料量
越來越大的時候，可以有效的提升計算速度，並同時控制記憶體的使用量，亦極精彩。 
我們的 Paper : 2D Expression-Invariant Face Recognition with Constrained Optical Flow 
發表七月一日的 MSRM-P1 Poster Session。在兩個小時的張貼時間中，和很多相關研究
領域的人一起討論，亦有不少的收穫。 
2D EXPRESSION-INVARIANT FACE RECOGNITION  
WITH CONSTRAINED OPTICAL FLOW 
 
Chao-Kuei Hsieh1, Shang-Hong Lai2, Yung-Chang Chen1 
 
1 Department of Electrical Engineering, National Tsing Hua University, Taiwan 
2 Department of Computer Science, National Tsing Hua University, Taiwan 
 
ABSTRACT 
 
Face recognition is one of the most intensively studied 
topics in computer vision and pattern recognition. A 
constrained optical flow algorithm, which combines the 
advantages of the unambiguous correspondence of feature 
point labeling and the flexible representation of optical flow 
computation, has been developed for face recognition from 
expressional face images. In this paper, we propose an 
integrated face recognition system that is robust against 
facial expressions by combining information from the 
computed intra-person optical flow and the synthesized face 
image in a probabilistic framework. Our experimental results 
show that the proposed system improves the accuracy of 
face recognition from expressional face images. 
 
Index Terms—Face recognition, expression recognition, 
constrained optical flow, expression normalization  
 
1. INTRODUCTION 
 
Face recognition has been studied for the past few decades. 
Even though the 2D face recognition methods have been 
actively studied in the past, there are still inherent 
disadvantages and drawbacks. It was shown that the 
recognition rate can drop dramatically when the head pose 
and illumination variations are too large, or when there is 
expression on the face image. Pose, illumination, and 
expression variations are three essential issues to be dealt 
with in the research of face recognition.  
Some authors have proposed different approaches to deal 
with such expression variations. One way [1] is to compute 
the optical flow between the testing and training face image. 
Another way [2] used a mask or a morphable model for the 
image registration in a face recognition system. In our 
previous work, we combined the advantages of the above 
two approaches: the unambiguous correspondence of feature 
point labeling and the flexible representation of optical flow 
computation. A constrained optical flow algorithm was 
proposed, which can deal with position movements and 
intensity changes at the same time when handling the 
corresponding feature points. We have applied the algorithm 
not only to the application of face recognition from 
expression normalization [3], but also on the inter- and intra-
person optical flow analysis [4], which can be used for 
further face and expression recognition. Both methods can 
improve the accuracy of the face recognition from 
expressional face images, even though different information 
is utilized in these two algorithms. In this paper, we propose 
to exploit two different types of information, i.e. the 
computed optical flow and the synthesized image, to 
improve the accuracy of face recognition. Experimental 
validation is given to show the improved performance of the 
proposed face recognition system. 
The remainder of this paper is organized as follows. The 
proposed face recognition system is presented in section 2. 
Section 3 gives some experimental results and section 4 
concludes this paper. 
 
2. PROPOSED FACE RECOGNITION SYSTEM 
 
We treat the expression-invariant face recognition system 
as a probabilistic maximum a posteriori (MAP) 
classification problem. To do this, we formulate the problem 
as follows:  
( )
,
arg max , | , 1,2,...,
i
i
E
P E i N=
N
N I , (1)
where I is the input image, Ni is the neutral face image for 
the i-th subject in training data set, and E denotes the 
expression movement between I and Ni. The optical flow 
field E is not specifically defined yet, which will be 
discussed later. Based on the posterior probability, equation 
(2) can be rewritten as 
( ) ( ) ( )
,
arg max | ,
i
i i
E
P P E P E
N
N I N . (2)
Furthermore, the occurrence probability of each candidate is 
assumed equally probable, i.e. P(Ni) is constant for all i. The 
formulation can be simplified as  
( ) ( )
,
arg max | ,
i
i
E
P E P E
N
I N . (3)
There are two parts in equation (3), i.e. the probability of the 
expression movement P(E), and the probability of the input 
image under the condition of the subject Ni with the 
expression E.  
 
2.1 Probability of the expression movement 
that warps the source image S to a new one through the 
motion vector v, as depicted in Fig. 3(a). Although the 
motion vectors and intensity variation coefficients are 
obtained in our optical flow estimation, this operator only 
involves geometric warping determined by the optical flow 
and the brightness variations is not used in the face synthesis. 
We define the operation ( )( ); ;Syn OFS S T , as an OF-Syn 
operator, and symbolize it as depicted in Fig. 3(b). Under 
such procedure, the source image S can be transferred to the 
expression and geometry of any target image T, and the 
variation between images due to expression can be reduced.   
The conditional probability ( )| ,iP EI N  is defined as the 
similarity between input image I (used as the target image) 
and the synthesized image from neutral face Ni and the 
computed optical flow movement. Since the optical flow 
used for synthesizing neutral face Ni to a certain expression 
must be represented with the same geometry of Ni, the intra-
person optical flow ( )
0@
,x y
N
u  in the previous section is not 
appropriate in this circumstance. An estimated intra-person 
optical flow under the geometry of Ni is needed, i.e. 
( )@ ,iN iOFu N I . Considering each pixel as an 
independent normally distributed random variable, the 
conditional probability can be further defined as follows: 
( ) ( )
2
,
2
1
1| , exp
22
P
p i p
i
p pp
P E
σπσ=
⎡ ⎤
−⎢ ⎥= −⎢ ⎥⎣ ⎦
∏ I SI N , (7)
where Si is the synthesized image ( )( ); ,i iSyn OFN N I , p is 
the index of pixel, P is the total number of valid pixels, and 
pσ  is the standard deviation of each pixel. 
 
2.3 Overall system flowchart 
 
The overall flowchart of the proposed expression-invariant 
face recognition system is depicted in Fig. 4. For each 
candidate in the dataset, two components are needed: one is 
the intra-person optical flow at the geometry of global 
neutral face N0, and the other is the intra-person optical flow 
at the geometry of Ni. The first one is used for the 
occurrence probability of such an estimated motion vector, 
while the second is for image synthesis and further 
conditional probability calculation. CB and CP operators 
stand for probability combination operation and comparison 
operation, respectively.   
 
3. EXPERIMENTAL RESULTS 
 
Our experiments were performed on the Binghamton 
University 3D Face Expression (BU-3DFE) Database [6]. 
The BU-3DFE database contains face images and 3D face 
models of 100 subjects (56 females and 44 males), each with 
a neutral face and 6 different expressions (angry, disgust, 
fear, happy, sad, and surprised) at different levels (from 
level 1 (weakest) to 4 (strongest)). Note that only the 2D 
face images were used in our experiments. We manually 
labeled 21 feature points, including 3 points for each 
eyebrow and 4 points for each eye, one at the nose tip and 
the other 6 around the mouth region. With the labeled points, 
the distance between the outer corners of both eyes is used 
as the reference to normalize face images.  
 
3.1. Benchmark test 
 
Since our goal is to solve the expressive face recognition 
problem under the restriction of one single training sample 
per class, the training database in the benchmark test 
contains only neutral face images with one neutral face 
image per subject, i.e. 100 face images for 100 classes in 
total. There are 24 expression variant images for each 
subject, and we used totally 2400 images for all 100 subjects 
for testing.  
Benchmark experiments are conducted with (1) 95% 
energy preserved PCA subspace computation and (2) direct 
subtraction without PCA pre-processing. The average 
recognition rate is 56.88% and 60.71%, respectively. 
 
3.2. Face recognition with proposed system 
 
As described in the previous section, we follow the 
flowchart shown in Fig. 4. Among the database, 34 subjects 
are randomly selected for intra-person optical flow training, 
and the others are used as the testing set. We apply a mask 
(Fig. 5(b)) defined from the global neutral face N0 (Fig. 5(a)) 
to extract the region of interest. Moreover, the region inside 
the mouth is discarded, as illustrated in Fig. 5(e). Both the 
optical flow and the grayscales of the synthesized image 
within the mask will be used in face recognition process. 
Some experimental images are shown in Fig. 5. For an input 
image (Fig. 5(d)), we first position the corresponding mask 
(Fig. 5(e)) to obtain the masked image (Fig. 5(f)). After that, 
for each candidate in the database (Fig. 5(g) and 5(j)), the 
intra-person optical flow, i.e. intra@Ni, is computed and 
used for virtual image synthesis (Fig. 5(h) and Fig. 5(k)). 
# #
 
Figure 4. Overall flowchart of the proposed system 
