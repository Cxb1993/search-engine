 行政院國家科學委員會補助專題研究計畫 
■ 成 果 報 告   
□期中進度報告 
 
ASCEND: 基於同儕網路之 3D網路虛擬環境設計與實作 
 
 
計畫類別：■ 個別型計畫  □ 整合型計畫 
計畫編號： NSC 95－2221－E－008－048－MY3 
執行期間： 95年 8月 1日至 98年 7 月 31日 
 
計畫主持人：黃興燦 
共同主持人：江振瑞 
計畫參與人員：胡舜元、詹謨澤、邱俊翔、陳泓翔、黃宇立、宋偉綸、
張少榛、黃俊傑、黃冠宇、簡建豪 
 
成果報告類型(依經費核定清單規定繳交)：□精簡報告  ■完整報告 
 
本成果報告包括以下應繳交之附件： 
□赴國外出差或研習心得報告一份 
□赴大陸地區出差或研習心得報告一份 
■出席國際學術會議心得報告及發表之論文三份 
□國際合作研究計畫國外研究報告書一份 
 
 
處理方式：除產學合作研究計畫、提升產業技術及人才培育研究計畫、
列管計畫及下列情形者外，得立即公開查詢 
          □涉及專利或其他智慧財產權，□一年□二年後可公開查詢 
          
執行單位：國立中央大學資訊工程學系 
 
中   華   民   國  98  年  10   月   01  日 
 2 
一、前言 (Introduction) 
 
In recent years, 3D multi-user networked virtual environments (NVEs) [1]  such as Massively 
Multipalyer Online Games (MMOGs) [2]  have become a major form of digital entertainment, 
where popular games commonly host millions of subscribers and thousands of concurrent users. As 
MMOGs grow to be a major form of social medium, one natural question is whether worlds 
scalable to millions of concurrent of users or as numerous as the WWW sites today would become 
feasible. Although the current client-server architectures for MMOGs can support thousands of 
concurrent users within a single world instance, sustaining millions of users can pose severe 
constrain on server-side resources and incur prohibitively expensive construction and maintenance 
costs. We thus would like to find alternative architectures that may be more scalable and affordable. 
 
Peer-to-peer (P2P) systems utilize client-side resources (e.g., CPU, memory, bandwidth) to support 
highly scalable computations or storages at low costs to operators or service providers. Successful 
P2P applications to date include file-sharing [3] , voice-over-IP [4] , and distributed hash tables 
(DHTs) [5] . An interesting possibility for more scalable and affordable NVEs is thus to utilize P2P 
architectures so that system resources may scale, instead of being consumed, with the increase in 
user size. 
 
ASCEND investigates the major unaddressed issues in P2P-based NVEs (P2P-NVEs), i.e., the 
issues of 3D streaming in content management, dynamic load balancing in state management, and 
topology-awareness in overlay management [6] . 
 
二、研究目的 (Research Goals) 
 
The first-year goal of ASCEND has been to investigate methods for real-time 3D content delivery 
(i.e. 3D streaming) over P2P networks, as we try to answer the question: how can 3D steaming are 
realized for millions of concurrent users within the same VE? 3D streaming refers to the continuous 
and real-time delivery of 3D contents (such as meshes, textures, animations, and scene graphs) over 
network connections to allow user interactions without a full download. Similar to audio or video 
media streaming, 3D content is fragmented into pieces on a server, before they can be transmitted, 
reconstructed, and displayed at the client side. Unlike media streaming, as each user often has a 
different visibility or interest area, the transmission sequence in 3D streaming varies from user to 
user and may require individualized visibility calculations (i.e. the transfer is non-linear). 
 
ASCEND’s second-year goal is to investigate ways to distribute game states to a large number of 
clients, while ensuring adequate consistency control, load balancing, and fault tolerance, so that 
NVEs with millions of concurrent users can be built. As a fundamental requirement for NVEs is the 
maintenance of game states, which are the various attributes of game objects such as the locations, 
possessions, and current status of players and computer-managed non-player characters (NPCs). 
Our aim is to allow object states be managed collaboratively by both servers and clients in a 
scalable and seamless manner. We also would like to utilize existing client-server-based consistency 
controls to make state management transparent for application developers, so that applications can 
be developed in manners similar to existing client-server-based NVEs. Due to the scope of the 
problem, our state management scheme would first only consider heterogeneity and churn issues. 
 
Our third year goal is to develop a robust and efficient P2P overlay that can support basic primitive 
operations in a NVE, while considering the reality of P2P networks (e.g, heterogenous peer 
resources, fluctuating network conditions, and dynamic join and leave of peers) and specific 
application requirements (e.g, latency constrains due to the interactive nature of NVEs). 
 4 
Figure 1: A conceptual model for P2P-based 3D scene streaming. 
FLoD's main design rationale is that as users in large-scale NVEs tend to see each other or cluster at 
hotspot locations, a user might have overlapped visibility with other users that are situated within its 
view (i.e. the area of interest, or AOI, for the user, see Fig. 2). It is thus likely that such AOI 
neighbors already possess relevant 3D content. By requesting data from the neighbors first, the 
server can be relieved from serving the same data repetitively. To discover AOI neighbors without 
relying on a server, we assume the existence of a P2P virtual environment overlay that provides the 
AOI neighbors' information given a position and AOI-radius. The information should include the 
neighbors' IDs, coordinates, and IP addresses. As a user moves around, it would constantly update 
the overlay with its own position and get refreshed information on AOI neighbors. Once AOI 
neighbors are known, requests for 3D data pieces can then be sent by utilizing certain peer and 
piece selection strategies. 
 
 
 
Figure 2: Concept of AOI. Circle indicates the AOI of a given user; triangles are other users; and objects are represented 
as irregular shapes. 
 
P2P State Management (i.e., dynamic load balancing) 
 
We note that the central issue is to effectively partition and distribute game states among 
participating nodes, such that resource usage at all nodes is bounded. A simple way thus is to 
distribute game objects among all user nodes, where each object is managed by the nearest user (i.e., 
the node whose position is closest to the object on the virtual map). Note that the VE will then 
partition into a number of Voronoi cells with user positions as the sites of each cell (Fig. 3L). 
Within a cell, the user node can govern all object updates in a client-server fashion. As some events 
may affect objects in nearby cells, each node also needs to connect with neighboring nodes in 
charge of the other objects (i.e. the area of interest, or AOI neighbors, whose Voronoi cells are 
covered by a given AOI, see Fig. 3R). Voronoi-based Overlay Network (VON) [7] can be used to 
keep connections with AOI neighbors. However, this approach has three potential problems: 1) 
When users are crowded inside a small area, each node’s connection would grow at O(n2), where n 
is the number of AOI neighbors. 2) Due to the unequal distribution of user locations, certain cells 
may be quite large with large number of objects beyond what a user node can handle. 3) The users 
are always moving, making object ownerships difficult to determine precisely. 
 
 6 
 
 
Figure. 5. VAST Architecture 
 
We consider a large-scale P2P VE, where avatars (i.e., clients) are arbitrarily distributed in the 
virtual world. Each avatar may be interested to receive updates from one or multiple arbitrary 
convex areas, which constitutes its area(s) of interest (AOI). An illustration of the VE is shown in 
Fig. 5 (A). Each avatar in the VE represents a user of the application in the physical world. 
 
Peers in a P2P network can be highly heterogeneous, with drastically different CPU capacity, 
bandwidth, and stability. Practical P2P systems thus often utilize super-peers, which are peers with 
higher CPU/bandwidth capacities and better stability, to help maintain the overlays, e.g, ultrapeers 
in Gnutella or super-peers in Skype. To address peer heterogeneity and utilize fully the peer 
resources, we divide peers in the P2P VE into super-peers (called relays) and regular peers (called 
clients), according to their capacity, stability, and trustworthiness. In VAST, every client in the P2P 
overlay is attached to a relay. Relays are assumed to have public IP addresses and can reach each 
other directly, forming a relay backbone or relay mesh. Each client performs SPS operations, while 
a relay manages overlay connectivity and message delivery with the clients’ pub/sub information, 
i.e., the pub/sub messages to/from a client are forwarded by the relay it connects to via the relay 
mesh. As a super-peer may also map to an avatar, it may also contain a client component that could 
perform SPS operations by attaching to itself. The P2P overlay with clients and relays is shown in 
Fig. 5 (B). An illustration of the mapping between the VE and the P2P overlay is as follows: Avatar 
a and b map to client a’ and b’ in the P2P overlay, respectively; if avatar a sends a pub message to 
avatar b, the message is passed from client a’ to R1 (the relay it attaches to), then forwarded from 
R1 to R2 (the relay b’ attaches to), and will be passed on by R2 to b’, eventually reaching avatar b. 
Note that the maximum number of hops is three for any client-to-client communications, and can be 
two if both clients connect to the same relay. 
 
Since each relay in VAST forwards messages for the clients connected to itself, it needs to maintain 
the pub/sub relationship for all the attached clients. Ideally, when a publication request reaches the 
relay, the relay could simply look up a mapping table to find and deliver message to the subscriber’s 
relay. How to achieve this effectively becomes an important design challenge. We address this issue 
by utilizing a VON [7] and noting that it is possible to support SPS by slightly extending VON’s 
functions. 
 
We note that it is trivial to discover and maintain pub/sub relations among nodes on a VON, by 
specifying the subscription area as the AOI of a node. Subscribers can thus learn of potential 
publishers by performing AOI neighbor discovery. As such knowledge is mutual, potential 
publishers are also aware of their subscribers continuously. Publications can thus be sent directly 
from publishers to subscribers. Although the original VON uses circular AOI, we note that AOI can 
in fact be of arbitrary convex shapes without affecting VON’s correctness. In VAST, we thus also 
consider flexible AOIs, which can either be of arbitrary convex shape, or may constitute of multiple 
disjoint areas. 
 8 
managing arbitrator → neighboring arbitrator(s) → peers in nearby cells). VSM can scale as 
client resources can be added, while aggregation in crowded areas helps to balance loads. Fault 
tolerance is supported by state replications on backup nodes, which may immediately transfer out 
ownerships or assume managing responsibilities for aggregators. Finally, as virtual peers and 
aggregators can be provided by servers, VSM allows both server and client resources to integrate in 
the same framework, thus provides a transition from client-server to P2P NVEs 
 
P2P Overlay Management 
 
The evaluation of VAST involves answering certain questions related to VAST’s design goals. The 
main questions we would like to answer are: 1) How practical is VAST if deployed in a real world 
situation? 2) How does the size of relays affect the overall performance and correctness of VAST? 
We use simulations for our evaluation as it can be done within a more controlled environment. We 
choose to simulate a Second Life region, with a dimension of 256 x 256 meters, and maximum 
concurrent users of about 100 [24] . As we are mainly interested in VAST’s steady state behavior, 
we allow the full 90 nodes to join the system first, before allowing them to move with a given 
behavior pattern. We adjust relay size from 1 to 90 to simulate both a classical client-server (i.e., 1 
relay) and fully distributed P2P (i.e., 90 relays) and any in-between range. 
 
Fig. 8(L) shows the upload bandwidth for both the gateway and the relays under topology-aware and 
topology-unaware join mechanisms. We focus on upload as it is often the main bottleneck for both 
clients and servers. We can see that gateway upload is about 1.3 MB/s under a single relay (i.e., 
client-server, or C/S-like), and gradually decreases to only about 40 KB / sec in 90 relays (or, pure 
P2P). We also note that gateway’s upload increases first to 1.8 MB/s and 1.5 MB/s when the 
number of relays increases to 2 and 4, before falling down to 1.3 MB/s again at 6 relays, and further 
down to 500 KB/s at 25 relays. This shows that initially, due to the increased inter-relay 
communications, bandwidth usage may in fact increase before falling down.  
 
Another important aspect to VAST’s performance is the latencies incurred for transmissions. We 
specifically measure the latencies for movement updates, as these are often the most time-critical 
updates for VE applications. From Fig. 8 (R), we see that under C/S the average (and the maximum) 
latency is about 200ms, while the average latencies under pure P2P are 110ms, which is roughly the 
average end-to-end latency in our dataset. With the increase in relays, the average latencies increase 
quickly to a high of 340ms, before decreasing continuously. One important observation is that while 
the average latencies initially increase with the usage of relays, they would decrease to a point where 
it is about as good as C/S (at roughly 50 relays), and even better. Thus, there is a sweet spot in relay 
size (between 50 and 90 relays), where the system has equal or better average latencies than C/S, yet 
requires much lower upload bandwidth.  
 
   
Figure 8: Performance Evaluation of VAST. (Left) Bandwidth usage (Right) transmission latency 
 10 
 
Journals 
1. Mo-Che Chan, Shun-Yun Hu, and Jehn-Ruey Jiang "An efficient and secure event signature (EASES) protocol 
for peer-to-peer massively multiplayer online games," Computer Networks, vol. 52, no. 9, pp. 1838-1845, Jun. 
2008.  
2. Guan-Yu Huang, Shun-Yun Hu, and Jehn-Ruey Jiang, "Scalable Reputation Management with Trustworthy 
User Selection for P2P MMOGs," International Journal of Advanced Media and Communication (IJAMC), 
Vol. 2, No.4 pp. 380 - 401, 2008.  
3. Jehn-Ruey Jiang, Jiun-Shiang Chiou and Shun-Yun Hu, "Enhancing Neighborship Consistency for Peer-to-Peer 
Networked Virtual Environments," Journal of Internet Technology, Vol. 10, No. 1, pp. 29-36, 2009.  
4. Jehn-Ruey Jiang, Yu-Li Huang and Shun-Yun Hu, "Scalable AOI-cast for Peer-to-Peer Networked Virtual 
Environments," Journal of Internet Technology, Vol. 10, No. 2, pp. 119-125, 2009.  
5. Mo-Che Chan, Shun-Yun Hu, and Jehn-Ruey Jiang, "Secure Peer-to-Peer 3D Streaming," Multimedia Tools 
and Applications, vol. 45, no. 1-3, Oct. 2009, pp. 369-384.  
6. Shun-Yun Hu, Jehn-Ruey Jiang, and Bing-Yu Chen, "Peer-to-Peer 3D Streaming," IEEE Internet Computing, 
to appear, 2009.  
7. Jehn-Ruey Jiang and Hung-Shiang Chen, "Peer-to-Peer AOI Voice Chatting for Massively Multiplayer Online 
Games," International Journal of Electrical Engineering (IJEE), to appear, 2009.  
Conference / Workshop 
1. Shun-Yun Hu, "A Case for 3D Streaming on Peer-to-Peer Networks," in Proc. International Web3D 
Symposium (Web3D 2006), Apr. 2006, pp. 57-63.  
2. Mo-Che Chan, Shun-Yun Hu, and Jehn-Ruey Jiang, "An Efficient and Secure Event Signature (EASES) 
Protocol for Peer-to-Peer Massively Multiplayer Online Games," LNCS (Proc. IFIP Networking 2007), vol. 
4479, May 2007, pp. 1037-1046.  
3. Jehn-Ruey Jiang and Hung-Shiang Chen, "Peer-to-Peer AOI Voice Chatting for Massively Multiplayer Online 
Games," in Proc. 13th International Conference on Parallel and Distributed Systems (ICPADS 2007) 
workshop P2P-NVE, Dec. 2007.  
4. Jyun-Jie Huang, Shao-Chen Chang and Shun-Yun Hu, "Searching for Answers via Social Networks," in Proc. 
5th Annual IEEE Consumer Communications & Networking Conference (CCNC), Jan. 2008.  
5. Shun-Yun Hu, Shao-Chen Chang, and Jehn-Ruey Jiang, "Voronoi State Management for Peer-to-Peer 
Massively Multiplayer Online Games," in Proc. 4th IEEE Intl. Workshop on Networking Issues in Multimedia 
Entertainment (NIME), Jan. 2008.  
6. Guan-Yu Huang, Shun-Yun Hu, and Jehn-Ruey Jiang, "Scalable Reputation Management for P2P MMOGs," in 
Proc. IEEE Virtual Reality workshop Massively Multiuser Virtual Environment (MMVE’08), Mar. 2008.  
7. Shun-Yun Hu, Ting-Hao Huang, Shao-Chen Chang, Wei-Lun Sung, Jehn-Ruey Jiang, and Bing-Yu Chen, 
"FLoD: A Framework for Peer-to-Peer 3D Streaming," in Proc. IEEE INFOCOM, Apr. 2008.  
8. Wei-Lun Sung, Shun-Yun Hu, and Jehn-Ruey Jiang, "Selection Strategies for Peer-to-Peer 3D Streaming," in 
Proc. 18th International workshop on Network and Operating Systems Support for Digital Audio and Video 
(NOSSDAV), May. 2008.  
9. Jehn-Ruey Jiang, Yu-Li Huang, and Shun-Yun Hu, "Scalable AOI-Cast for Peer-to-Peer Networked Virtual 
Environments," in Proc. 28th International Conference on Distributed Computing Systems Workshops 
(ICDCSW) Cooperative Distributed Systems (CDS), Jun. 2008.  
10. Chien-Hao Chien, Shun-Yun Hu and Jehn-Ruey Jiang, "Delaunay State Management for Large-scale 
Networked Virtual Environments," in Proc. 14th Intl. Conference on Parallel and Distributed Systems 
(ICPADS 2008) workshop P2P-NVE, Dec. 2008.  
11. Shun-Yun Hu, "Spatial Publish Subscribe," in Proc. IEEE Virtual Reality (IEEE VR) workshop Massively 
Multiuser Virtual Environment (MMVE'09), Mar. 2009.  
12. Chang-Hua Wu, Shun-Yun Hu, and Li-Ming Tseng, "Discovery of Physical Neighbors for P2P 3D Streaming," 
in Proc. International Conference on Ultra Modern Telecommunications (ICUMT), Oct. 2009.  
13. Chien-Hao Chien, Shun-Yun Hu, and Jehn-Ruey Jiang, "Bandwidth-Aware Peer-to-Peer 3D Streaming," in 
Proc. Network and Systems Support for Games (NetGames), Nov. 2009.  
參加 “Eighth International Symposium on Stabilization, 
Safety, and Security of Distributed Systems (formerly 
Symposium on Self-stabilizing Systems) (SSS 2006) November 
17th-19th, 2006, Dallas, Texas, USA.” 報告 
報告人: 黃興燦 教授 
 
第八屆 International Symposium on Stabilization, Safety, and 
Security of Distributed Systems (formerly Symposium on 
Self-stabilizing Systems) (SSS 2006)。會期自十一月十七日至十九
日為期三天。 
 
Dallas 人口一百二十多萬，是人口上美國第九大城，德州第三大
城。美國已故甘迺迪總統就是在 Dallas 市區遇刺身亡，所以是美國歷
史上相當知名的城市。雖然人口不少，但是地更大，所以顯得人煙相
當稀疏。 
 
報告人和所指導的清大博士生曾志宏共有兩篇文章被接受發
表，據大會統計共有 139 篇論文投稿，最後接受 36 篇 接受率兩成五
左右，挑選相當嚴謹，能有兩篇接受發表，應屬不錯。 
論文 Self-Stabilizing Asynchronous Phase Synchronization in 
General Graphs, Chi-Hung Tzeng (National Tsing Hua University), 
Jehn-Ruey Jiang, and Shing-Tsaan Huang (National Central University) 
及論文 Distributed Edge Coloration for Bipartite Networks, Shing-Tsaan 
 此趟出國開會尚有一特別經驗。由於國際恐怖活動均以美國為目
標，所以上飛機之前的安全撿查工作相當徹底。不能隨身攜帶危險物
品包括液態的東西。全身檢查要求要脫鞋子，真是令人困擾。也不知
甚麼原因，回程時我的登機證竟然被印上幾個大 S‧以至於經過安全
檢查時受到特別待遇，等特別的安撿人員進行很徹底的檢查，安撿人
員的口氣也表現得不很友善。美國在國際舞台四處以老大自居，為此
付出的代價不可謂不高。 
 
 
end-to-end connectivity. Current networks are still much manually configured and 
need pre-provisioning. However, there is little sense if two users in the same room 
want to communicate but have to go through the global IP cloud in order to exchange 
messages. He concludes by predicting that there is a great unexplored space for 
overlay constructions and deployments, and that’ll likely provide unified services (for 
example, multi-user conferencing communication among a group of distant 
collaborators, or the streaming of videos), or across different mediums (e.g., PCs, 
notebooks, PDAs) in future. 
 
The second day begins with a full day of paper sessions, where I presented in the first 
session of our paper “Selection Strategies for Peer-to-Peer 3D streaming”, after the 
presentation of Wei Cheng (a Ph.D student of our collaborator Prof. Wei Tsang Ooi 
from National University of Singapore) on “Receiver-Driven View-Dependent 
Streaming of Progressive Mesh”. Both of our papers were in the “Networking for 
Virtual Worlds” sessions (other sessions include NOSS – networking and operating 
systems support; DAV – digitial and audio; video streaming in wireless environments; 
analysis and conclusions; streaming with P2P support), and it was interesting there 
were two papers both on 3D streaming. After the technical sessions, we were taken on 
a boat in the river Oker around the city to a restaurant for the dinner, which was very 
pleasant and interesting.  
 
Discussions 
 
During the first night reception, I had an interesting discussion with the keynote 
speaker, Jorg Liebeherr of Univ. of Toronto, who had just recently became an IEEE 
Fellow, on the topic of the proliferation of paper publications, new 
workshop/conferences, and the increased loading to publish or review papers. I asked 
his opinion on this situation, whether it’s a healthy thing, and what people may do 
about it. He agreed with me that such scenario is probably not conductive to actually 
moving or pushing science forward, and unfortunately, every time some metric is set 
up to evaluate a person’s performance, there are always ways to optimize the metric 
(for example, if paper count is used, then people start to get good at having lots of 
publications, if citation is used, then people would start to write more survey papers). 
On the other hand, he also thinks that the system is here for a reason, and that it’s not 
very useful to simply disregard the system, because if one ceases to “play by the 
rules”, then you will either not get resources (i.e., grant and funding), or become 
irrelevant (people will not know you or your work if you do not publish). However, he 
thinks that this becomes a personal issue and choice, where one may still be able to 
need to face in order to obtain financial support for conference attendance. 
 
A second recommendation is the layout of the workshop, which focuses on a smaller 
group or community of researchers, and various social events interleaving in between 
the technical presentations, as well as demo sessions that gave many people a good 
chance to talk and showcase their work. That was certainly very helpful and 
conductive to more research ideas generation and progress. These things are 
experiences which I believe we can borrow in the future.  
Selection Strategies for Peer-to-Peer 3D Streaming
Wei-Lun Sung, Shun-Yun Hu, Jehn-Ruey Jiang
Department of Computer Science and Information Engineering
National Central University, Taiwan, R.O.C.
ABSTRACT
In multi-user networked virtual environments such as Sec-
ond Life, 3D streaming techniques have been used to pro-
gressively download and render 3D objects and terrain, so
that a full download or prior installation is not necessary. As
existing client-server architectures may not scale easily, 3D
streaming based on peer-to-peer (P2P) delivery is recently
proposed to allow users to acquire 3D content from other
users instead of the server. However, discovering the peers
who possess relevant data and have enough bandwidth to
answer data requests is non-trivial. A naive query-response
approach thus may be inefficient and could incur unnec-
essary latency and message overhead. In this paper, we
propose a peer selection strategy for P2P-based 3D stream-
ing, where peers exchange information on content availabil-
ity incrementally with neighbors. Requestors can thus dis-
cover suppliers quickly and avoid time-consuming queries.
A multi-level area of interest (AOI) request is also adopted
to avoid request contention due to concentrated requests.
Simulation results show that our strategies achieve better
system scalability and streaming performance than a naive
query-response approach.
Categories and Subject Descriptors
I.3.2 [Computer Graphics]: Graphics Systems–Distributed
/ network graphics
Keywords
3D streaming, virtual environment, peer-to-peer
1. INTRODUCTION
In recent years, networked virtual environments (VEs)
[19] have become more and more popular. Commercial VEs
such as Massively Multiplayer Online Games (MMOGs) of-
ten contain large 3D content to present realistic, immersive
environments for user interactions. Most MMOGs today
need to be fully installed beforehand with CDs or DVDs for
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for profit or commercial advantage and that copies
bear this notice and the full citation on the first page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior specific
permission and/or a fee.
NOSSDAV ’08 Braunschweig, Germany
Copyright 2008 ACM 978-1-60588-157-6/05/2008 ...$5.00.
easier content access. However, as content gets larger and
more dynamic, it would become increasingly inconvenient
for new users to try, or for existing users to update the con-
tent. A better way thus is to acquire only the content of
interest progressively via 3D streaming techniques [20, 6, 3].
3D streaming refers to the continuous and real-time de-
livery of 3D content such as meshes, textures, animations
and scene graphs over networks to allow user interactions
without a full download [8]. A client renders the content
according to certain data descriptions while downloading
other data pieces concurrently. Similar to audio or video
media streaming, the content needs to be fragmented into
pieces before transmission. However, a major difference ex-
ists between 3D and media streaming: data is fragmented
into sequentially ordered pieces and transmitted linearly in
media streaming, whereas 3D content’s transmission order is
not fixed and requires individual visibility calculation based
on the user’s viewpoint and behavior [20, 13].
Existing 3D streaming schemes are based on the client-
server architectures – all content is stored at a central server,
and transmitted to clients upon requests [12]. However, as
more clients join with more requests, the server becomes a
bottleneck when the data requirement exceeds its capacity.
To address this, peer-to-peer (P2P) delivery has been pro-
posed to achieve better scalability [6]. As each peer has some
data in its local cache, other clients could request from their
peers first when in need of similar content. The system’s
serving capacity may thus improve dramatically. However,
with a P2P approach, the issue of peer selection naturally
arises. The purpose of peer selection is to choose suitable
candidates so that content retrieval can be done quickly and
efficiently. However, peer selection for P2P 3D streaming
differs from file-sharing or media streaming due to data lo-
cality – peers who are nearby to each other in the virtual
world see similar views and possess similar content. Suitable
peers thus may be discovered with some predictability, but
they also change constantly due to user movements. How
to discover nearby neighbors and their data availability effi-
ciently and continuously thus is the main challenge.
In this paper, we propose some new peer selection strate-
gies for P2P 3D streaming. Peers periodically exchange in-
cremental content availability with neighbors to allow re-
questors to learn of providers quickly, saving both message
overhead and time. We also adopt a multi-level AOI request
to avoid request contentions. In the rest of this paper: Sec-
tion 2 provides background and related work; we describe
our proposed methods in Section 3, and simulation evalua-
tions in Section 4; conclusion is given in Section 5.
Cavagna et al. [2, 16] have proposed another P2P 3D
streaming scheme for urban scenes stored in a hierarchical
and progressive tree structure called Level of Detail Descrip-
tion Tree, or LODDT. In this tree, each node represents a
level of detail (LOD) for a certain region. The root node rep-
resents the roughest detail and also the whole environment.
As the level increases, the details of the geometric data be-
come more delicate and refined. Each node also has an aura
representing a viewable area (i.e., similar to an AOI), of
which if a peer enters, the appropriate LOD would be ac-
quired by the peer. To facilitate peer selection, each peer
informs its Time to Serve (TTS) to neighbors periodically.
When peers enter an aura but do not possess the descrip-
tion data, they estimate what their neighbors might hold
based on the neighbors’ positions. With a list of potential
candidates, a peer chooses the one with the least TTS to
request. However, an obvious drawback is that, although
requestors could select candidates inside the aura based on
position info, some neighbors may be new and yet have any
data to serve. Requests sent to these neighbors would be
invalid and prolong the overall latency. Request contention
may also occur as peers with the least TTS may receive more
requests than others.
3. PROPOSED STRATEGIES
We observe that peer selection can be divided into two
phases: source discovery and source selection. Source dis-
covery is to find out which nodes might possess the desired
data, and source selection is to choose a few nodes among po-
tential candidates to request the actual data. Note that we
assume that there are existing methods to allow each node to
always connect with its AOI neighbors, and maintain them
(i.e., discover new ones as nodes move) via a P2P-VE over-
lay such as VON[7, 8]. Direct message exchange among AOI
neighbors is also possible. In this section, we describe our
peer selection strategies according to these two phases.
3.1 Source discovery
We propose an active exchange method to discover data
sources. Peers would periodically notify AOI neighbors about
their own data availability incrementally. Besides an index
number of message type, a notify message only contains the
object ID (Obj ID) and the maximum continuous piece ID
(Max PID) (Figure 3), which specifies up to which pieces
have already been received (e.g., if pieces with IDs 1, 2, 4,
5 are received, 2 is the maximum continues piece ID). As
peers can request data from multiple neighbors, the pieces
received may be out of order. Here we assume that object
re-constructions are strictly linear, so only the piece ID from
the base piece (i.e., the first piece) to the maximum contin-
uous piece are usable. Peers distribute the full availability
information only to new AOI neighbors. For existing neigh-
bors, only incremental updates are sent as new data pieces
arrive. This way, peers spend less overhead to learn of the
neighbors who might hold the desired data. Requestor can
also easily create the list of request candidates based on the
exchanged information, reducing the source discovery time.
Additionally, as non-AOI neighbors might also possess rel-
evant data, a peer would keep its neighbors’ data availability
information even after they move out of AOI, and would still
exchange the neighbors’ positions until they are beyond a
specified distance. In Figure 4 (solid circles are the original
AOI and dotted circles are the extended candidate buffer),
Figure 3: Format for an availability update.
we assume that peer B already has the scene description
and the object data. When both A and B move into each
other’s AOI, they would learn of each other’s data availabil-
ity. After B moves out of A’s AOI, peer A would still keep
B’s information. So when A needs to request new objects,
it can add B into the candidate list as B is still within the
extended buffer. The potential data sources can thus be
increased with few overheads. These peers additionally fa-
cilitate content dissemination, as with more providers, the
load will be shared by more peers.
Figure 4: Extended candidate buffer.
3.2 Source selection
Once we have a list of candidate sources, we need to select
the suitable ones for efficient retrieval. Although random se-
lection is quite simple and achieves local load balancing, it
may cause request contention when multiple nearby peers
are requesting from the same data. In order to reduce con-
tention, we propose a multi-level AOI request for source se-
lection.
Figure 5: Original vs. multi-level AOI request: (L)
Original AOI (R) Multi-level AOI, the shaded area
has the highest request priority.
The idea for multi-level AOI is to divide the original AOI
into several concentric levels, where each level closer to the
center (in terms of virtual coordinates) has a higher request
priority than those further out (Figure 5). Peers within the
higher levels are requested first. If there is more than one
candidate at the same level, the requestor then chooses ran-
domly. The central concept is to concentrate data requests
closer to the requestor itself, so that contention is avoided
Figure 7: Hit ratio.
Figure 8: Base latency.
Figure 8 shows the latency to acquire the base piece, which
indicates how fast the outline of an object can be shown once
it becomes visible. We can obviously see that the original
strategies used by FLoD need longer time to acquire the
base pieces, in order to wait for the response from the data
providers. With our discovery strategies, peers may reduce
the base latency by almost half (i.e., it takes only a round-
trip of 200ms to see the base piece). Multi-level requests also
help to reduce latency, because it decreases the probability
for request contention to occur, and enhances the hit ratio
of peers, needless re-requests thus are avoided.
From Figure 7 and 8 we already see that our methods
achieve better performance when the number of peers in-
creases. Figure 9 shows the overall fill ratio, which further
validates these results, where the fill ratios are generally
higher than the original FLoD strategies. Moreover, Figure
10 shows the time series of the overall fill ratio. When the
peers start moving, the overall fill ratio first drops then re-
stores to a steady state. We can see that the naive strategies
used by FLoD requires a longer time to achieve the steady
state, which shows that the original peer selection is slower
in disseminating data. A possible reason is that in the orig-
inal selection, peers who receive queries do not necessarily
possess the data. So there are fewer actual providers than
the number of query targets. The requestors are thus unable
to acquire the desired data effectively.
4.2.2 System scalability
Scalability describes whether a system is flexible enough
Figure 9: Overall fill ratio.
Figure 10: Overall fill ratio time series.
to allow users to join simultaneously. Note that although
we mainly discuss about the number of total users in the
system (or system scalbility), and not the scalability of users
within the AOI (or AOI scalability [9]), the two are directly
related in our simulations as the world size is fixed (i.e.,
the increase in total number of users directly relates to an
increase in user density). We can judge whether a system
is scalable by considering its resource consumption. In a
P2P system, the main limiting resource is the bandwidth
used by both the server and the clients [7]. The system
can scale as long as bandwidth consumptions stay below the
capacity limits of all nodes. Figure 11 shows the server’s
bandwidth consumption. We can clearly see that the peer
selection in the original FLoD consumes more bandwidth
than our proposed strategies due to longer latency and the
lack of data sources. When peers need more time to inquire
for data, there would be fewer nodes with available data to
serve. When the limited data sources cannot serve, the only
way for peers to acquire data is to request from the server.
Additionally, the original FLoD limits the number of query
messages at a time, in order to avoid request congestion, but
it also makes the peers to be aware of fewer candidates. The
peers who possess the data but do not receive queries thus
will be unable to serve. As data is disseminated slowly, the
central server will thus get more requests and consume more
bandwidth.
Figure 12 shows the average source discovery bandwidth
of peers, which is the main overhead of using a P2P ap-
 ICDCS 2008 Report 
Scalable AOI-Cast for Peer-to-Peer Networked Virtual Environment 
Shun-Yun Hu 
 
(Registration & Ticket supported by NSC 95-2221-E-008-048-MY3) 
 
 
Summary of Trip (參加會議經過) 
 
This is a brief trip report from one week spent at ICDCS 2008 in Beijing. This year's 
ICDCS appears to have the theme of focusing on the integration of computer science 
with other areas/domains, starting from the keynote speech by Richard Karp, (1985 
Turing Award laureate, who has been working on genomics lately). Karp tried to 
present the view that traditional computer science areas may already be fairly 
well-studied, but computer science as tools (or "lens") for seeking new insights in 
other science disciplines, is something that's yet vastly underexplored. Of particular 
interest, he draws the similarity between statistical physics and computer science, 
saying that both fields study macroscopic properties that arise from local interactions. 
So likely that ideas / theories across the fields might produce interesting new insights. 
 
Another keynote speaker, Taieb Znati from NSF, talked about how large-scale 
complex systems are designed ("end-to-end principles") but also the direction of 
Cyber-Physical systems, where we will probably be seeing / working on more 
systems that have both physical presence (sensors, robotics) but are under the control 
of computerized systems, possibly large-scale, self-organizing, and intelligent. 
There'll also be the challenge of how to design such system, so that human manual 
involvement is minimized, and the system is highly reliable / dependable that we can 
trust our lives to it. I asked the obvious "singularity" question (wouldn't this all point 
to the direction of accelerating "singularity" / Terminator world? see the recent IEEE 
Spectrum report: http://spectrum.ieee.org/singularity), of which he gave a quite 
interesting and positive answer: perhaps we should not think of the future in terms of 
master / slave, but how both human and machine intelligence can co-work together to 
the maximal benefit for all (not exactly his words, but something similar in meaning). 
Although he failed to mention the rise of virtual worlds, but I think that's one aspect 
most of us here are well aware of. 
 
 
to address is how to scale up the current two-site operations of 3D video conferencing 
(i.e., multiple video streams with depth info are exchanged between two users). The 
main solution idea is to not send everything, but only those relevant / visible 
(basically, interest management), and to utilize overlays so that data streams are 
relayed. 
 
Richard Han (Univ. Colorado Boulder) presented a very interesting paper in the 
workshop WCPS on how to build the Holodeck ("Towards Cyber-Physical Holodeck 
Systems Via Physically Rendered Environments (PRE's)") The main idea is to use 
some moving physical pixels called "moxels" to dynamically "render" a physically 
touchable surface in real-time. Very bold and ambitious in its final aim, but also the 
type of "space-shuttle" project that might just end up impacting many things. 
 
Giuseppe Ateniese (John Hopkins Univ.) attacks the problem of "how do you verify 
the integrity / valid possession of hundreds of TBs of data (say, the library of 
Congress collection) efficiently?" in the paper "MR. PDP: Multiple-Replica Provable 
Data Possession". 
 
 
Recommendations (建議) 
 
This year we presented a paper at the ICDCS workshop Cooperative Distributed 
Systems (CDS), titled “Scalable AOI-Cast for Peer-to-Peer Networked Virtual 
Environments”. However, it was quite a disappointment that the attendees of the CDS 
workshop were few and uninterested at the work being presented. Although I 
personally consider the paper of some importance and contribution, it was not 
well-received (probably due to the lack of attendee interest and expertise). I would 
thus recommend submitting future papers to more relevant and well-known workshop 
/ conference so that the importance of our research works can be recognized properly 
(also to obtain more useful feedbacks). 
Scalable AOI-cast for Peer-to-Peer Networked Virtual Environments
Jehn-Ruey Jiang, Yu-Li Huang, and Shun-Yun Hu
Department of Computer Science and Information Engineering
National Central University, Taiwan
Abstract
Networked virtual environments (NVEs) are computer-
generated virtual worlds where users interact by exchang-
ing messages via network connections. Each NVE user of-
ten pays attention to only a limited visibility sphere called
area of interest (AOI) where interactions occur. The dis-
semination of messages to other users within the AOI (i.e.,
the AOI neighbors) thus is a fundamental NVE operation
referred to as AOI-cast. Existing studies on NVE scala-
bility have focused on system scalability, or the ability for
the system to handle a growing number of total users, by
using multicast or peer-to-peer (P2P) architectures. How-
ever, another overlooked, yet important form of scalability
relates to the handling of a growing number of users within
the AOI (or AOI scalability). In this paper, we propose two
AOI-cast schemes, called VoroCast and FiboCast, to im-
prove the AOI scalability of P2P-based NVEs. VoroCast
constructs a spanning tree across all AOI neighbors based
on Voronoi diagrams, while FiboCast dynamically adjusts
the messaging range by a Fibonacci sequence, so that AOI
neighbors would receive updates at frequencies based on
their hop counts from the message originator. Simulations
show that the two schemes provide better AOI scalability
than existing approaches.
1. Introduction
Networked virtual environments (NVEs) are distributed
systems where geographically dispersed users assume vir-
tual representations called avatars to interact by exchanging
network messages. Each user in a NVE can be seen as a co-
ordinate point on a 2D plane with a bounded visibility called
area of interest (AOI) [24]. AOI is often a circular area cen-
tered at the user, and other users within this area are called
the AOI neighbors. As users need to be aware of the current
states of its AOI neighbors, each user has to send messages
about its state changes, such as its current position and ac-
tions, to users whose AOIs cover itself. If we assume that
all AOIs are of the same size, as most NVEs do, then each
user has to send messages to all of its AOI neighbors. In
this paper, we use the term AOI-cast to refer such message
propagation. As AOI-cast is a fundamental NVE operation,
our goal is to develop efficient and scalable AOI-cast.
Creating scalable NVEs is an important topic, as suc-
cessful NVEs often host many users. For example, Mas-
sively Multiplayer Online Games (MMOGs) are NVEs that
support hundreds of thousands of simultaneous users. How-
ever, two forms of scalability exist for NVE systems: system
scalability indicates a NVE’s ability to handle a growing
number of total users in the system; whereas AOI scalabil-
ity refers to the ability to handle a growing number of users
within a particular AOI. Both are important, but different
properties of a NVE system.
Client-server is the main architecture for today’s NVEs.
However, since a server (or server cluster) has only limited
resources at any given moment, server-only designs have
inherently limited system scalability. Recent researches
thus point to peer-to-peer (P2P) architectures to improve
NVE’s system scalability (e.g., Solipsis [15, 9], SimMUD
[16], VON [11], N-tree [10], COVER [19], OPeN [8],
APOLO [17], Skip Delaunay Network (SDN) [21], Colye-
sus [4], Peers@Play [23] and HyperVerse [5]). By distribut-
ing loads to all user nodes (or peers), clients become not
just resource consumers but also providers. Besides system
scalability, other P2P-NVE issues such as overlay partition-
ing [14], voice-chatting [13], secure messaging [6] and 3D
streaming [12], have also been investigated.
While system scalability is studied extensively with P2P
approaches, the issue of AOI scalability has received less
attention. The problem is also known as the hotspot, crowd-
ing problem [11], or the user density challenge. AOI scal-
ability is potentially improvable by a P2P-based AOI-cast.
Existing schemes can be classified by how connections are
made. On one end of the spectrum are direct connection
schemes where each node exchanges messages with all AOI
neighbors directly (e.g., Solipsis, VON, COVER, OPeN,
and Colyseus). Direct connections allow small latency and
robustness, but incur high bandwidth costs. When there are
many AOI neighbors, peak bandwidth usage may exceed
the peer’s bandwidth limit (see Figure 1), causing overload
Figure 3. Different neighbor types in VON
In VON, a node directly connects to all of its AOI neigh-
bors to send its current position and states periodically. The
boundary neighbors should also preform neighbor discov-
ery (i.e., the notification of new AOI neighbors) when they
receive position updates from a moving node, so that a mov-
ing node may learn of new AOI neighbors. This is possible
because new AOI neighbors are always the enclosing neigh-
bors of existing boundary neighbors. VON thus has low
message overhead, short latency and high consistency for
node positions [11].
VON-forwarding [7] is based on VON, but each node
connects only to the enclosing neighbors rather than all AOI
neighbors. Since a node’s enclosing neighbors are limited
(e.g., 6 on average [18]), each node’s connection size is
basically constant. When sending messages, the message
is first sent to each of the enclosing neighbors, which in
turn forwards the message to their own enclosing neighbors.
The forwarding continues until all AOI neighbors have the
message. VON-forwarding also uses message packing and
compression to reduce the overall bandwidth usage. How-
ever, redundant messages may be sent during the forward-
ing, which incurs unnecessary overhead (see Figure 4).
Figure 4. VON forwarding model [7]
3. Scalable AOI-cast
3.1. VoroCast
The basic idea of VoroCast is to construct a multicast tree
spanning all AOI neighbors for each node. Messages can
then be sent along the tree edges without redundancy. As in
VON, the AOI is partitioned by a Voronoi diagram based on
AOI neighbors’ coordinates. Each node has a unique ID and
two types of neighbors. The first is called one-hop neigh-
bors, which are basically the enclosing neighbors in VON.
Note that our definition differs from the 1-hop neighbors
in APOLO [17], which is a superset of the enclosing neigh-
bors. The second is called two-hop neighbors, which are the
one-hop neighbors of one-hop neighbors except for redun-
dant ones. Nodes always connect to their one-hop neigh-
bors to exchange the one-hop neighbor lists (containing the
neighbors’ IDs, positions and IP addresses) so that two-hop
neighbors are properly known. Messages generated by a
root node r are first sent to all of r’s one-hop neighbors.
Upon receiving the message, an intermediate node x then
forwards it to uniquely selected child nodes within r’s AOI.
To construct the spanning tree, no two nodes should se-
lect the same node as child to avoid transmission redun-
dancy. We observe that while many potential child nodes
exist when growing a tree from a root, it is possible to select
just one parent for every node, given a root location (e.g.,
the closest to the root may be selected as parent). Therefore,
to uniquely select a child, we can do so from the perspective
of the child that is selecting a parent.
In the following child selection procedure (Figure 5),
x.N stands for the one-hop neighbor set of node x; x.P
is the parent of x; r.AN is the AOI neighbor set of r; and
min dist(S, r) refers to the node from the node set S with
minimal Euclidean distance to r. To begin, node x checks
for each one-hop neighbor y, excluding its own parent or
any direct children of the root (i.e., y ∈ ((x.N − x.P −
r.N) ∩ r.AN)). If x is the closet to r among all of y’s
one-hop neighbors, it would be y’s parent. Node y is thus
selected as one of x’s children to receive forwarded mes-
sages. Upon receiving a message, y would also record x as
its parent. Note that when two nodes are equidistant from r,
their unique IDs can break the tie for choosing the parent.
// node x selects a child node to forward r’s messages
SelectChild(x, r)
// find out which child y would select x as its parent
for each y ∈ ((x.N − x.P − r.N) ∩ r.AN )
z = min dist(y.N, r);
if (z equals x)
add y as a child of x;
Figure 5. Child selection procedure
4.2. Simulation results
4.2.1 Bandwidth consumption
Bandwidth usage is a good indicator for a system’s scala-
bility, as the main resource bottleneck in large-scale NVEs
is the bandwidth [11]. Systems are scalable as long as the
bandwidth usage of each node remains bounded. Figure 7
shows the per-node, per-second bandwidth consumption of
VoroCast, FiboCast and VON. We can see that the proposed
schemes incur less bandwidth than VON. This is because
our schemes are based on forwarding and can apply mes-
sage packing and compression to reduce bandwidth usage.
If we set a bandwidth limitation for each node, we can see
that FiboCast accommodates the most nodes, followed by
VoroCast and VON (e.g., if each node has only 15 KB/s
bandwidth, then FiboCast, VoroCast and VON can accom-
modate a total of around 1000, 500, and 200 nodes, respec-
tively). Note that by simulating a growing number of nodes
with a fixed AOI, our simulations test the performance for
both system and AOI scalability (i.e., AOI scalability is di-
rectly related to system scalability in our scenarios).
0
5
10
15
20
25
30
35
40
100 200 300 400 500 600 700 800 900 1000
Number of nodes
KB
yte
/se
c p
er 
no
de
VoroCast
FiboCast
VON
Figure 7. Bandwidth consumption
4.2.2 Neighborship consistency
While the scalability of VoroCast and FiboCast may be su-
perior than the original VON, we should also evaluate their
main drawbacks in terms of the reduced consistency due to
more latency and less updates. Neighborship consistency
[14] can be a good indicator and is defined as follows.
NCi =
KNi
ANi
NCi is the neighborship consistency for node i, and is
defined as the ratio of the number of known AOI neighbors
KNi to the number of total, actual AOI neighbors, ANi.
For example, if a node has 100 AOI neighbors but is only
aware of 90, its neighborship consistency is 90%. A global
neighborship consistency NC can also be calculated by av-
eraging those from the individual nodes. Figure 8 shows
the global neighborship consistency of VoroCast, FiboCast
and VON. In VON, each node sends messages to all AOI
neighbors directly, so it maintains very high consistency.
The consistency of VoroCast is above 95%, which is ac-
ceptable. The overall consistency of FiboCast is worse than
VoroCast. However, if we look more closely at the consis-
tency within a smaller zone from the AOI center (e.g., 25%,
50%, 75% and 100% of the AOI radius from the center),
we see that neighborship consistency is actually higher than
95% for the 25%, 50%, and 75% zones, which means that
for practical purposes good consistency is still maintained.
85%
90%
95%
100%
100 200 300 400 500 600 700 800 900 1000
Numbor of nodes (system)
Ne
igh
bo
rsh
ip 
Co
ns
ist
en
cy
FiboCast (25%)
FiboCast (50%)
FiboCast (75%)
FiboCast (100%)
VoroCast
VON
Figure 8. Neighborship consistency
4.2.3 Drift distance
Drift distance is another way to measure the consistency in
node positions, and is the difference between the real and
observed positions of nodes. It is defined as follows [11].
DDi = AVG |OPj −RPj |
j∈AOIi
DDi is the average drift distance for node i calculated
from the set of i’s known AOI neighbors (AOIi). OPj and
RPj are, respectively, the observed and the actual positions
of a known AOI neighbor j of node i. Again, a global drift
distance DD can be calculated by averaging those from the
individual nodes. Drift distance reflects the accuracy of AOI
neighbor positions, and is basically determined by message
latency. Since FiboCast adjusts the update frequency adap-
tively, its latency is highly variable, and we exclude it from
the comparisons.
Figure 9 shows the drift distances of VoroCast and VON
for 50 to 500 nodes. Drift distances for VON are near
0 since all updates are transmitted in one hop. VoroCast
  
 
 
 
 
 
附件 
發表之期刊論文 
 
 
 
 
 
 
 
 
 
 
 
 
 
performs an action such as running, shooting, turning, etc.,
an eventmessage is sent to the server, which subsequently
processes the events and updates the game states. The ser-
ver then periodically sends state updates to the affected
players to synchronize their local copies of the game states
with the server’s. Under such processing model, the server
maintains all the information to ensure a global ordering
for event executions and fair gameplay. However, when
we turn to a P2P approach, game state maintenance and
game logic execution could be distributed to individual
players, creating opportunities for players to cheat.
Cheating gives a player various advantages in multi-
player games. It is especially attractive as gaining valuable
items or winning over others is central to the MMOG
gameplay. Valuable virtual items can even be sold in ex-
change for real-world money, which increases the motiva-
tions to cheat. Cheat-prevention thus is a serious issue to
game designers. Games may adopt cryptographic tech-
niques to prevent cheating by concealing a player’s actions
from others before submitting the ﬁnal decisions [10]. In
such countermeasures, a secure event update protocol is
often used, and includes: 1. a commitment scheme to ensure
that players do not change their actions after decisions are
made and 2. a digital signature scheme to ensure that play-
ers cannot deny the actions they have done. If the commit-
ments are digitally signed, we can also prevent
impersonation and dodging [12,13]. Commitment and dig-
ital signatures together thus provide a fair environment for
games even when players do not trust each other [12,13].
However, public-key cryptography has some time-con-
suming exponential operations when signing signatures,
so a large amount of computation is required to sign and
verify all event updates. We begin this research by consid-
ering the question: can the authentication and non-repudi-
ation properties of digital signatures still be achieved,
without incurring the heavy costs of signing messages
continuously?
In existing cryptography schemes, when a large docu-
ment needs to be signed, a hash function can be used to re-
duce the computations. The document is ﬁrst hashed into a
much smaller digest, which is then signed to be a digital
signature. The digest can be used to characterize the origi-
nal document. As it is very hard to ﬁnd another document
that can produce the same digest, signing the digest can be
seen as signing the original document. By using a digest,
the computation time to sign a document can be greatly
reduced. Unforgeability and veriﬁability are the two require-
ments for digital signatures that currently can only be
achieved via public-key cryptography; together they pro-
vide the non-repudiation (i.e., undeniableness of user ac-
tions) of the signature. Two event update protocols
[11,14] have been proposed to use digital signatures to
sign every event update to avoid cheating in P2P-based
MMOGs. However, both protocols may not be practical
due to the excessive use of public-key cryptographic signa-
tures. As shown in [15], digital signatures consume much
more computation than hash functions and symmetric
encryptions. Since the use of digital signatures is unavoid-
able to prevent users from denying their behaviors, our
main concern is thus how to use digital signature only min-
imally while achieving the same cheat-proof properties. We
propose an efﬁcient and secure event signature (EASES) pro-
tocol to efﬁciently sign a sequence of event updates by
using the hash-chain keys based on the concept of one-time
signatures [16]. We further describe a dynamic version of
EASES that does not require the pre-production of hash-
chain keys to reduce key preparation time and memory
usage at the expense of an extra one-round delay of mes-
sage commitment. We perform measurement experiments
for EASES and compare the experimental results with those
of existing digital signature-based approaches. As we will
show, EASES has low computation and bandwidth costs,
and is thus applicable to P2P-based MMOGs.
In the following sections, we ﬁrst review related work
for cheat-proof mechanisms in Section 2 and present a
message signing model in Section 3. We propose the EASES
protocol in Section 4, and extend it to a dynamic version
where the production of signature keys can be done
dynamically in Section 5. We evaluate the security and
performance of EASES in Section 6 and conclude the paper
in Section 7.
2. Related work
Several papers have investigated the types of cheats and
security requirements of multiplayer games. Kirmse and
Kirmse [17] present the security goals for online games
in respect to the protection of sensitive information and
the provision of fair play. Dickey et al. [11] shows that sev-
eral types of cheats may occur when honest players’ ac-
tions are known in advance by cheaters, who can then
respond unfairly to their advantages. Smed [18] describe
considerations in multiplayer games such as the network
resources, communication architectures, scalability and
security. Yan [19] demonstrates several security require-
ments for online games via a simple client–server bridge
game.
Besides the above work, several cheat-proof mecha-
nisms have also been proposed. Baughman and Levine
[10] present the ‘‘lockstep” mechanism to solve the cheat-
ing problem. Based on the concept of bucket synchroniza-
tion [20,21], their mechanism divides a game session into
‘‘time buckets” (i.e., time intervals, or ‘‘rounds”) for game
state synchronization. In each round, a player ﬁrst sends a
cryptographically secure one-way hash value of its state
update as a commitment, and then sends the plaintext up-
date to reveal the commitment in the next round. This
prevents any player from knowing other players’ actions
ahead of time. Cronin et al. [22] further improve the per-
formance of lockstep with ‘‘sliding pipeline” by sending
out several updates in advance without waiting for
acknowledgements from other players. GauthierDickey
et al. propose the new event ordering (NEO) protocol
[11] to improve the work of Baughman and Levine [10]
and Cronin et al. [22]. NEO claims to prevent common
protocol-level cheats with low latency. However, Corman
et al. [14] later show that NEO cannot prevent all cheats
as claimed, and present an improvement called secure
event agreement (SEA) as a remedy. Since our work is
mostly inspired by NEO and SEA, we detail the two proto-
cols below.
M.-C. Chan et al. / Computer Networks 52 (2008) 1838–1845 1839
4.1. Initialization phase
Before starting the game, each player must ﬁrst gener-
ate a series of one-time signature keys. The following key
generation operation can be done before a user logins the
game, or before the ﬁrst event update is sent.
1. Each playeri ﬁrst picks an unpredictable random num-
ber as the master key MKi to compute a series of n
one-time signature keys, where n is a system parameter
that speciﬁes the maximum number of updates (i.e.,
rounds) in a session. Choosing larger n increases the
costs to compute and store the keys, but may save com-
puting time during the later update stage.
2. We begin the key generationwith the last key, so the nth
one-time signature key is computed by Kni ¼ HðMKiÞ.
And for the other rth round, where r ¼ ðn 1Þ; . . . ;0,
the signature key is computed by Kr1i ¼ HðKri Þ.
After these one-time signature keys (i.e., a hash-chain
keys) are generated, playeri signs the ﬁrst one-time signa-
ture key by its secret key to get the signature
Di ¼ SskðK0i Þ. Note that keys are used in the reverse order
of their production (i.e., the last key produced is the ﬁrst
key used in the game session and needs to be signed).
See Fig. 1 for a schematic of the key production.
4.2. Signing phase
In the rth round, playeri computes the signature of the
event updates dri ¼ HðKri jUri Þ, where Uri is playeri’s rth event
update. Playeri then sends the signature d
r
i , the previous
event update Ur1i and its associated key K
r1
i to other play-
ers. The below equation shows the message sent by playeri
d1i ¼ HðK1i jU1i Þ;Di;K0i in the first round;
dri ¼ HðKri jUri Þ;Ur1i ;Kr1i in the subsequent rth round:
(
ð5Þ
For instance, playeri sends out the message d
1
i ¼ HðK1i jU1i Þ;
Di;K
0
i in the ﬁrst round. In the second round, playeri sends
out d2i ¼ HðK2i jU2i Þ;U1i ;K1i . In a subsequent rth round, playeri
sends out dri ¼ HðKri jUri Þ;Ur1i , and Kr1i .
4.3. Veriﬁcation phase
On receiving messages from playeri, each player verify
the messages as follows:
1. In the ﬁrst round, each player receiving d1i ¼
HðK1i jU1i Þ;Di;K0i , veriﬁes Di with playeri’s public-key
and K0i to see if the key K
0
i is legitimate.
2. In the rth round, r ¼ 2; . . . ;n, each player receiving
dri ;U
r1
i ;K
r1
i veriﬁes:
(a) Kr2i 9HðKr1i Þ to see if the signature key Kr1i is
authentic (i.e., the signature key Kr2i was gener-
ated from Kr1i ).
(b) dr1i 9HðKr1i jUr1i Þ to see if the update has been
tampered.
For example, in the second round, a player should verify
K0i9HðK1i Þ as well as d1i9HðK1i jU1i Þ for playeri. If the veriﬁ-
cation passes, then a player can be sure that the update is
from playeri and is not tampered.
4.4. Re-initialization phase
The signature keys have to be re-generated when they
are depleted for a session. One basic method is for players
to start over from the initialization phase to generate and
use new signature keys. However, a more efﬁcient way is
for playeri to perform the following actions in the nth
and ðnþ 1Þth round.
1. In the nth round, playeri generates a series of new one-
time signature keys NewK0i ; . . . ;NewK
n
i with a new ran-
dom number (i.e., a master key NewMKi). In practice,
playeri can generate the keys in advance to avoid
sudden computing load. Playeri signs (hashes) the new
signature key NewK0i with the key K
n
i to have
dni ¼ HðKni jUni jNewK0i Þ. Playeri then sends dni ;Un1;Kn1i
to other players as usual.
2. In the ðnþ 1Þth round, playeri sends
dnþ1i ¼ HðNewK1i jUnþ1i Þ;Un;Kni and NewK0i to other
players.
3. In the ðnþ 2Þth round, in addition to the regular mes-
sage, playeri should also send the old master key MKi
(i.e., the pre-image of Kni ).
Besides the regular veriﬁcations, the receivers now
should perform the following additional veriﬁcations.
1. On receiving dnþ1i ;U
n;Kni in the ðnþ 1Þth round, the
receiver should verify dni9HðKni jUni jNewK0i Þ to check
the authenticity of NewK0i .
2. In the ðnþ 2Þth round, the receiver should also verify
Kni9HðMKiÞ.
If the above veriﬁcations pass, NewK0i is authenticated
to be sent by playeri and the series of new keys
NewK0i ; . . . ;NewK
n
i can be used after the ðnþ 2Þth round
according to the normal procedures.
4.5. Late joining
If the set of receivers is ﬁxed during a game session, then
playeri only needs a single set of keys to sign updates. On the
other hand, playeri may need separate sets of keys for each
playerj if we allow a newplayers to join an on-going session.Fig. 1. Production rule for the one-time signature keys.
M.-C. Chan et al. / Computer Networks 52 (2008) 1838–1845 1841
attacker from sending different updates to different play-
ers [14]. However, those topics are beyond our current
scope.
6.2. Security analysis
EASES supports message non-repudiation via commit-
ments. The event update Uri is committed by K
r
i at round
r and revealed in the next round. This property is based
on EASES’ support of the two fundamental requirements
for digital signatures: unforgeability and veriﬁability.
Unforgeability means that no one can generate a legal sig-
nature for a speciﬁc message except the signer. Only the
signer keeps the correct private key for generating a legal
signature veriﬁable by the corresponding public-key. Veri-
ﬁability means that everyone can verify whether a digital
signature is legal. Below, we analyze EASES according to
these two requirements.
Unforgeability: In EASES, one cannot claim to have
signed Uri and produced the signature d
r
i unless K
r
i is pre-
sented. However, no one can show the signing key Kri for
the current update Uri before the original signer reveals it.
The cryptographic hash used by EASES also has the follow-
ing secure properties: for any given hashed value, it is
computationally infeasible to ﬁnd its pre-image due to
the one-way property of hash functions (i.e., for any given
message x, it is computationally infeasible to ﬁnd another
message x0 such that HðxÞ ¼ Hðx0Þ). Moreover, strong colli-
sion resistance exists in some hash functions, meaning that
it is computationally infeasible to ﬁnd any pair of ðx; yÞ
such that HðxÞ ¼ HðyÞ, where x 6¼ y. EASES is unforgeable
since it adopts a secure hash function that has the above
properties. With unforgeability, non-repudiation can be
achieved in EASES.
Veriﬁability: Cryptographic hash function is a public
standard that can be installed and executed on every
player’s computer, so everyone can re-compute the hash
value of a given signature key Kri and message U
r
i to verify
if it equals the previously received signature by checking
dri9HðKri jUri Þ.
Dynamic EASES: Both the basic and the dynamic ver-
sion of EASES maintain their security under ‘‘lockstep”
game environment (i.e., the players will only advance
game rounds together, making the adversary unable to
gain advantages via uneven information across rounds).
We can especially appreciate this property by observing
the dynamic version. In dynamic EASES, the ﬁrst and
the second messages can be undoubtedly authenticated
by the sender’s public-key. In the third round, the player
receives HðU3i jK3i jK2i Þ;K1i ;Uri , so the adversary must know
K2i in order to replace U
3
i jK3i and forge messages after-
wards. However, K2i will only be revealed in the fourth
round. For example, the message U3i whose commitment
was received in the third round can be revealed and con-
ﬁrmed, when its committing keys K2i and K
3
i are received
in the fourth and ﬁfth round. K2i cannot be forged because
all K2i keys that appear in rounds 2, 3 and 4 can be com-
pared. Likewise, K3i cannot be forged because all K
3
i keys
in rounds 3, 4 and 5 can be compared. The authenticity
of message U3i is thus ensured as K
2
i ;K
3
i are veriﬁable in
the fourth and the ﬁfth rounds.
6.3. Performance analysis and comparisons
Computation cost: The major beneﬁt of EASES is compu-
tational efﬁciency. There is at least one signature operation
and one veriﬁcation operation for each event update in the
schemes such as NEO and SEA. In comparison, there are
only two hash operations for each event update in EASES
and one traditional signature operation during the initiali-
zation phase in EASES. The approximate CPU cycles for
some cryptographic functions are listed in Table 2.
Memory consumption: EASES requires a player to pre-
pare a block of memory to store the list of one-time signa-
ture keys. The exact memory size depends on the hash
value length and the chosen round size n. For example, if
MD-5 is used and n ¼ 1000, then each player will need
1000  128 = 128,000 bits = 16,000 bytes of memory to
store the one-time signature keys.
Bandwidth consumption: Except for the ﬁrst update,
EASES needs to transfer the one-time signature for every
event update, with the size of a hash value. This is much
shorter than the size of traditional digital signatures. For
example, SHA-1 uses 192 bits for each hash value, whereas
1024-RSA uses 1024 bits for each signature. EASES thus
only needs a size about twice the hash value.
We brieﬂy compare EASES with NEO [11] and SEA [14],
both of which adopt traditional digital signatures to sign
updates in every round (see Table 3). NEO uses two signa-
ture operations, and SEA uses one. EASES replaces the sig-
nature by hash operations. NEO and SEA need one
signature operation in each round. EASES needs one signa-
ture operation only for initialization of the one-time signa-
ture keys, and only hash operations are used afterwards.
6.4. Experimental results
We perform simulation experiments on an Intel Pen-
tium-4 3.4 GHz PC for evaluating the performances of the
two versions of EASES and the digital signature-based
Table 2
Approximate CPU cycles for some cryptographic functions [14,15]
Primitive type Example Clock cycles
Hash function SHA-1 15/byte +1040
Symmetric encryption AES 25/byte +504
Digital signature RSA-PSS 42,000,000
Table 3
The comparisons of NEO, SEA and EASES
Message sizea Memory space Computation
cost
NEO 1 ds + 1 en + 1
dk
None 1 ds + 1 en
SEA 1 ds None 1 ds + 1 hash
Basic EASES 2 hashes n hash-chain
keys
2 hashes
Dynamic
EASES
2 hashes None 1 hash
ds: digital signature; en: encryption; and dk: decrypting key.
a The actual game update message is excluded.
M.-C. Chan et al. / Computer Networks 52 (2008) 1838–1845 1843
[15] B. Preneel, B. Van Rompay, S. Ors, A. Biryukov, L. Granboulan, E.
Dottax, M. Dichtl, M. Schafheutle, P. Serf, S. Pyka, Performance of
Optimized Implementations of the NESSIE Primitives, <http://
www.cosic.esat.kuleuven.ac.be/nessie/deliverables/>, 2003.
[16] L. Lamport, Password authentication with insecure communication,
Communications of the ACM 24 (11) (1981) 770–772.
[17] A. Kirmse, C. Kirmse, Security in online games, Game Developer 4 (4)
(1997) 20–28.
[18] J. Smed, Aspects of networking in multiplayer computer games, The
Electronic Library 20 (2) (2002) 87–97.
[19] J. Yan, Security design in online games, in: Proceedings of the 19th
Annual Computer Security Applications Conference, 2003, pp. 286–
295.
[20] L. Gautier, C. Diot, J. Kurose, End-to-end transmission control
mechanisms for multiparty interactive applications on the
internet, in: Proceedings of the IEEE Infocom, 1999.
[21] C. Diot, L. Gautier, A distributed architecture for multiplayer
interactive application on the internet, IEEE Network 13 (1999).
[22] E. Cronin, B. Filstrup, S. Jamin, Cheat-prooﬁng dead reckoned
multiplayer games, in: Proceedings of the Application and
Development of Computer Games, 2003.
[23] The MIT Kerberos Team, The Network Authentication Protocol,
<http://web.mit.edu/Kerberos/>.
[24] M. Bellare, P. Rogaway, Optimal asymmetric encryption, Advances in
Cryptology – Eurocrypt’94, Springer-Verlag, 1994. pp. 92–111.
[25] W. Dai, Crypto++ Library 5.5.2, <http://www.cryptopp.com>.
[26] D. Pittman, C. GauthierDickey, A measurement study of virtual
populations in massively multiplayer online games, in: Proceedings
of the 6th ACM SIGCOMM Workshop on Network and System
Support for Games, 2007, pp. 25–30.
Mo-Che Chan is currently a Ph.D. student
with the Department of Computer Science
and Information Engineering at National
Central University, Taiwan. His current
research interests encompass distributed
systems and network security.
Shun-Yun Hu (syhu@csie.ncu.edu.tw) is cur-
rently a Ph.D student at National Central
University, Taiwan. He received his M.Eng.
degree in computer science and information
engineering from Tamkang University in
2005. His main research interests are net-
worked virtual environments and peer-to-
peer systems. He has published in IEEE Net-
work and IEEE INFOCOM, and was a co-orga-
nizer of the IEEE Virtual Reality workshop
Massively Multiuser Virtual Environments
(http://peers-at-play.org/MMVE08/). He has
been inspired and fascinated by the possibilities of virtual worlds since
ﬁrst playing with computer games at the age of 7. He started the
SourceForge project VAST (http://vast.sourceforge.net) in 2005 and
ASCEND (http://ascend.sourceforge.net) in 2006, to provide open source
libraries for creating scalable peer-to-peer-based virtual environments.
Jehn-Ruey Jiang received his Ph.D. degree in
Computer Science in 1995 from National
Tsing-Hua University, Taiwan, ROC. He joined
Chung-Yuan Christian University as an Asso-
ciate Professor in 1995. He joined Hsuan-
Chuang University in 1998 and became a full
Professor in 2004. He is currently with the
Department of Computer Science and Infor-
mation Engineering, National Central Univer-
sity. He was a recipient of the Best Paper
Award of the 32nd International Conference
on Parallel Processing, 2003, and a recipient of
Excellent Paper Award of Mobile Computing 2004. His research interests
include distributed computing, mobile computing, pervasive computing
and peer-to-peer computing.
M.-C. Chan et al. / Computer Networks 52 (2008) 1838–1845 1845
380 Int. J. Advanced Media and Communication, Vol. 2, No. 4, 2008
Scalable reputation management with trustworthy
user selection for P2P MMOGs
Guan-Yu Huang, Shun-Yun Hu
∗
and Jehn-Ruey Jiang
Department of Computer Science and Information Engineering,
National Central University,
Taiwan, ROC
E-mail: aby@acnlab.csie.ncu.edu.tw
E-mail: syhu@csie.ncu.edu.tw
E-mail: jrjiang@csie.ncu.edu.tw
∗Corresponding author
Abstract: Recent research on Peer-to-Peer Massively Multiplayer Online
Games (P2P MMOGs) has tried to ﬁnd more scalable and affordable
solutions to build virtual environments via the resource sharing of clients.
However, P2P approaches face the problem of client misbehaviours where
game rules are not processed properly, undermining a game’s fairness and
normal operations. In this paper, we present REPS, a distributed reputation
management system for P2P MMOGs that allows trustworthy clients be
identiﬁed to perform important tasks. REPS ﬁrst considers the generation,
storage, and query for certain reputation factors that could be the basis to
evaluate user trustworthiness. We then propose Trustworthy user Selection
(TuS) to adjust the weights of each factor to give preference to the more
important ones. Based on the mutual rating among users and reputation
queries, REPS provides a scalable and reliable mechanism to facilitate
decisionmaking, from choosing trustworthy superpeers, to deciding whether
to interact with particular users.
Keywords: P2P; peer-to-peer; virtual environments; trustworthy user
selection; distributed reputation management.
Reference to this paper should be made as follows: Huang, G-Y., Hu, S-Y.
and Jiang, J-R. (2008) ‘Scalable reputation management with trustworthy
user selection for P2P MMOGs’, Int. J. Advanced Media and
Communication, Vol. 2, No. 4, pp.380–401.
Biographical notes:Guan-YuHuang is currently aMaster student atNational
Central University, Taiwan. His current research interest encompasses
distributed systems.
Shun-Yun Hu is currently a PhD student at National Central University,
Taiwan. His main research interests are networked virtual environments
and peer-to-peer systems. He started the SourceForge project VAST
(http://vast.sourceforge.net) in 2005, to provide open source libraries for
creating scalable peer-to-peer-based virtual environments.
Copyright © 2008 Inderscience Enterprises Ltd.
382 G-Y. Huang et al.
One challenge for reputation schemes in a distributed environment is how to deal
with the disruptions from malicious users. The reputation scores given by users might
not be accurate enough to reﬂect true trustworthiness, because malicious users can
give false reputation ratings. Also, ratings related to speciﬁc user behaviours may not
be generalisable to judge the overall trustworthiness of a user. Therefore, considering
more game parameters may help to increase the estimation accuracy and restrain the
interruptions from malicious users. Reputations in a game can be affected by many
factors (i.e., the reputation factors). Besides mutual ratings among peers, accumulated
online time, the number of completed tasks or trades, etc., all can be the basis to judge
trustworthiness. However, the importance of each factor can be different, so we need
to give appropriate weights to each factors. Here we deﬁne importance as how well
a given factor can discriminate among users (i.e., the users have a higher degree of
variability in respect to the factor), because with higher discriminability, it indicates
that the factor can better discern the differences among users. How to utilise various
parameters to decide trustworthiness and assign weights for each relevant factors are
thus the main problems for us.
In this paper,weproposeREPS, a reputationmanagement systemforP2PMMOGs
based on peer-rated reputations. Each user has a reputation value based on other
users’ subjective opinions during their interactions. The reputation data is stored
distributively among all users for scalability and security reasons. We also propose
the process of Trustworthy user Selection (TuS) to choose trustworthy users. TuS uses
a statistical regression to combine all potential reputation factors and compute their
importance weights, so that only users matching the strictest reputation criteria are
chosen as trustworthy users.
The rest of this paper is organised as follows. Section 2 provides background on
reputation management and P2P NVEs. Section 3 presents our problem formulation
and challenges in distributed reputationmanagement.We describe the design of REPS
in Section 4 and the design of TuS in Section 5. Evaluations for REPS are performed
in Section 6, while concluding remarks are given in Section 7.
2 Background
2.1 Reputation management
Recently, there have been a number of reputation systems proposed for P2P
applications, often in the context of e-commerce (e.g., Atif, 2002; Dellarocas, 2001;
Aberer and Despotovic, 2001; Xiong and Li, 2004; Ismail and Josang, 2002; Josang
et al., 2007). The goal of these systems is to compute the reliability of a user and
predict future behaviours in respect to a speciﬁc metric, and the P2P approach is to
reduce the overhead for servers. Such predications are based on past experiences and
interactions with the user, who is often a buyer or seller in an existing distributed or
semi-distributed e-commerce environment. The reputation value represents a global
view for the user’s behaviour, and can be used as reference towarn of or convince other
users. Users may also quickly identify whether another user in contact is trustworthy,
and could thus avoid interactions with malicious users who cheat for private beneﬁts.
The reputation systems in these P2P applications calculate a peer’s reputation value
by collecting the local evaluations from other users. For example, in Kamvar et al.
384 G-Y. Huang et al.
event notiﬁcations) for other users. Lo et al. (2005) describe superpeers as having a
special role that can provide services to non-superpeers.
Figure 1 Large circle is the AOI of the centre star user (see online version for colours)
For many P2P NVE schemes that adopt superpeers, whether the selected clients are
trustworthy is essential for the system’s proper operations. One of the implications for
our proposed distributed reputation management thus is to provide a reliable method
for selecting trustworthy nodes that may assume important superpeer functions.
3 Problem formulation and challenges
Our goal is to build a scalable reputation management system that supports
P2PMMOGs by developing a distributed method to rate, store, and query reputation
values. Trustworthy users can then be selected based on these reputation evaluations.
The main problem is how to store the reputation scores on reliable peers and query
them effectively. We ﬁrst make the following assumptions:
• Every user has a ﬁxed AOI radius, where users see each other only when they are
within each other’s AOI. Between two mutually visible users, certain
game-speciﬁc interactions can occur (e.g., talking, ﬁghting, trading, etc.).
The users within AOI, or AOI neighbours, change periodically due to users’
positional changes as they move.
• We assume that a P2P NVE overlay exists to provide a list of AOI neighbours
for each user (e.g., Knutsson et al., 2004; Bharambe et al., 2006; Hu et al., 2006).
So any user may connect and exchange messages directly with its AOI
neighbours.
• Two mutually visible users can rate each other multiple times with a score of
positive, neutral, or negative (+1, 0,−1) based on past interactions.
A reputation record follows the form of (rater, rated-user, evaluation), where
rater is the user making the rating, rated-user is the user being evaluated, and
evaluation records the actual rating.
• We assume that the probability for a user to cheat decreases with a person’s
reputation value, especially if the reputation has exceeded certain threshold, as
possibly a lot of effort has been spent to build the reputation (Figure 2).
386 G-Y. Huang et al.
4.1 Localised reputation evaluation
In REPS, users performmutual rating when they are within each others’ AOI, because
interactions can only occur with AOI neighbours. For example, in Figure 3, users C
and F could rate A because they are within A’s AOI. Rating may occur with a
probability related to the intensities of interactions. To ensure that rating would only
occur after user interactions, interactingusers have togenerate a rating rightauthorised
by the rated user to the potential rater, so that the rater can give a rating at some later
time, while preventing users to rate people whom they have never interacted with. The
rating right contains the rated user’s unique identiﬁer and IP address, and is recorded
at the rater so that rating may be performed at a later, more convenient time. Rating
right can be generated via Proxy Signature (Das et al., 2006), which basically provides
amethod to authorise a user to act on behalf of the authoriser to perform certain tasks.
In our case, the rated user authorises the rater to modify his or her reputation value
at another third party node (called reputation manager that will be described later).
However, the details of such authorisation is beyond the scope of this paper.
Figure 3 The rating condition in REPS
As an example, if user C rates userAwith the score of 1, then a rating record of (C,A, 1)
will be stored at A’s reputation manager, which would update A’s reputation based
on A’s existing reputation value.
4.2 Reputation storage and query
Similar to EigenTrust (Kamvar et al., 2003) and Powertrust (Zhou and Hwang, 2007),
inorder to scalably store the reputation records, auser choosesM users as its reputation
managers to store and retrieve reputation data, where M is a system-wide parameter.
The reason for having M reputation managers is to prevent the loss or corruption of
reputation data due to the failure of malicious act of any single reputation manager.
Reputation managers are chosen by hashing unique user identifers using M different
Distributed Hash Table (DHT) functions such as Chord (Stoica et al., 2001) or CAN
(Ratnasamy et al., 2001).DHTprovides anuniquemappingbetween akey (such as user
identifer) and a user node locatedwithin a logical coordinate space, so by usingM hash
functions,M separate nodes can be selected to store the reputation data for any given
user. As the hash functions are well-known and agreed upon in advanced, any other
user can also easily locate the M reputation managers for a given user. Reputation
managers are in charge of saving and computing the reputation score, while making
sure that only users with the proper rating right can modify the respective reputation
score. Potential raters thus send their ratings to a rated user’s reputation managers
by hashing the rated user’s identifer via M different hash functions. Users can also
388 G-Y. Huang et al.
Take two reputation factors for example, we use the most popular reputation factors
total score, S(u), and rating ratio, R(u), to explain how TuS chooses trustworthy
users. Total score is the summation of every score S(i, u) an user u receives from each
rater i, and the rating ratioR(u) indicates the proportion between the total score S(u)
and the total number of ratings T (u) that user u receives. The higher S(u) or R(u),
the more trustworthy user u is
S(u) =
∑
S(i, u) R(u) =
S(u)
T (u)
.
But which reputation factor is more important If user A scores 30 out of 100 ratings,
and user B scores 9 out of 10 ratings. According to S(u) alone, A is more trustworthy
as its total is higher than B’s. But the ratio R(u) of B is higher than A’s, making B
more trustworthy. Yet since 100 people have rated A and only ten persons have rated
B, the A’s rating may be more signiﬁcant. Some proportionality distortions thus exist
(Table 1).
Table 1 Example of proportionality distortions
User S(u) T (u) R(u)
A 30 100 0.3
B 9 10 0.9
Ideally, wewould like to combine the effects of both the total score and the rating ratio,
as they can both be meaningful. However, we do not know which is more important
as it may differ across regions or MMOGs, where the willingness to rate can vary.
So it is better for TuS to combine S(u) and R(u) in a ﬂexible way.
Figure 4 illustrates the concpet of TuS by a two-factor example, where the x-axis
represents all possible values for the rating ratio and the y-axis represents all possible
values for the total score. A user u can be selected as a trustworthy user if its
reputation point lies within the trust region (satisfying the conditions of R(u) > mR
and S(u) > mS , where mR is between 0 and 1 and mS is between the most negative
rating and the most positive rating). If we want to select N trustworthy users, we can
adjust the thresholdsmR andmS so that there are exactlyN points (i.e., user reputation
values) in the trust region.
To adjust the thresholds of mR or mS , we deﬁne the value wS,R as the absolute
value of the regression coefﬁcient (i.e., the slope of the regression line for all points
in the trust region). wS,R can be used as the relative importance weight for reputation
factors from S(u) to R(u). We can also deﬁne wR,S , the relative importance weight
fromR(u) to S(u), as the inverse ofwS,R. IfR is the averageR(u) and S is the average
S(u) for all users within the trust region, then:
wR,S =
1
wS,R
wS,R =
∣∣∣∣∣∣
∑
(R(u) − R)(S(u) − S)∑
(R(u) − R)2
∣∣∣∣∣∣ .
390 G-Y. Huang et al.
Figure 5 Process ﬂow of TuS. n = number of selected trustworthy users; N = number of
required trustworthy users
5.3 Multivariate analysis for weight adjustment
In Multivariate Analysis, (Mardia et al., 1979) describe the statistical principles
of multivariate statistics, which involves observations of more than one statistical
variable. The method is used to perform tradeoff studies across multiple dimensions
while taking into account the effects of all variables of interest. It analyses the
principal components of all input variables to determine the component that is most
discriminating. In mathematical terms, this means ﬁnding the distribution direction
that will create the largest variations for weighted averages, and the weights for each
variable guaranteed to generate the largest difference among all variables.
In TuS, we take r different reputation factors as the variables, s total users,
and xi,j as the value for user i’s jth reputation factor. In order to compute the
weight of each reputation factor relative to the ﬁrst factor, TuS ﬁnds each regression
coefﬁcients relative to the ﬁrst reputation factor according to all current xi,j values
by multivariate analysis. TuS then takes the regression coefﬁcients as the reputation
factor weights relative to the ﬁrst reputation factor w2,1, w3,1, . . . , wr,1 (for brevity,
we usew2, w3, . . . , wr to represent them). The computations for the weights are shown
as follows:


x1,1
x2,1
· · ·
xs,1

 =


1 x1,2 · · · x1,r
1 x2,2 · · · x2,r
1 · · · · · · · · ·
1 xs,2 · · · xs,r




w1
w2
· · ·
wr

+


ε1
ε2
· · ·
εr


or equivalently:
X0
(s ∗ 1) =
X
(s ∗ r)
W
(r ∗ 1) +
ε
(s ∗ 1).
We ignore ε during computation because ε = 0 based on the assumption of Mardia
et al. (1979) where the expected error for each reputation factor is minimum.
392 G-Y. Huang et al.
To evaluate the accuracy of selections, we require each user to identify a number
of most trustworthy neighbours. The number is chosen to be 20, as this is roughly
25% of the average AOI neighbours in the most crowded scenario. The main accuracy
metric is deﬁned as whether the chosen trustworthy users are indeed the most
trustworthyones, basedon theirmisbehaviour probability (i.e., the number of correctly
identiﬁed users with the lowest misbehaviour probabilities). For example, if a method
correctly identiﬁes 9 out of 10 neighbours with the lowest misbehaviour probability,
then the reputation accuracy is 90%. The average reputation accuracy represents
the mean reputation accuracy for all users. Another useful matric is convergence
time, deﬁned as the average time for average reputation accuracy to exceed 95%.
Convergence time shows how fast a given method can select the most trustworthy
users.
6.1 Accuracy analysis
In the ﬁrst set of simulations, we compare the average reputation accuracy for the
following four methods: TuS, Total score + Rating Ratio (T+R), Total Score only
and Rating Ratio only. T+Rmeans that the reputation thresholds ∆mi are adjusted
using the same initial ratio. Total Score and Rating Ratio choose trustworthy users
simply based on the highest total score or rating ratio, respectively. In other words,
T+R adjusts the trust region without considering the relative importance of a given
metric, while Total Score, and Rating Ratio determines trustworthiness based on only
a single metric.
If we set the rating frequency f = 10% (Figure 6(a)), the average relative weight of
total score to rating ratio wS,R turns out to be 1.72 (i.e., total score is more important
than rating ratio). Therefore, we expect that the average accuracy for the Total Score
method should be higher than that of Rating Ratio, which is indeed the case. Because
the Rating Ratio method considers the factor that may be less relevant for reputation
(i.e., the total number of ratings) in this case, the consideration thus interferes with
the accuracy to choose trustworthy users. By combining total score and rating ratio,
TuS shows a much higher accuracy than other methods, including T+R (29.55%, i.e.,
64.27–34.72%, see Table 2). This is because the relative weight of each metric may shift
during the simulation, so an adaptive weighting scheme such as TuS would perform
better than a non-adaptive scheme such as T+R.
When the rating frequency increases to f = 50%, as shown in Figure 6(b), the
difference between Total Score and Rating Ratio becomes smaller. By combining
considering both total score and rating ratio, TuS and T+R now achieve better
accuracy than the other two naive schemes. The weight wS,R = 1.07 shows that the
difference in accuracy between TuS and T+ S gets smaller as their relative importance
becomes more similar.
When f = 90%, all the schemes have enough samples in reputation ratings to
distinguish users’ trustworthiness after 1000 steps, as shown in Figure 6(c). All four
schemes are able to converge to the highest accuracy of 100% as time goes. However,
TuS converges the fastest among the schemes, i.e., convergence time for TuS is only
76.66%of thenext-best scheme,T+R,andonly 62.31%and55.91%of the convergence
time of Total Score and Rating Ratio (see Table 3). These results show that better
selection accuracy can be achievedwith a properly chosen scheme, and that TuS adapts
to different conditions with a generally shorter convergence time.
394 G-Y. Huang et al.
Table 2 Average reputation accuracy under different rating frequencies
Scenario Average reputation accuracy (%)
Rating frequency (f) wS,R TuS T + R Total score Rating ratio
10% 1.72 64.27 34.72 42.54 25.27
50% 1.07 71.36 70.9 56.45 48.36
90% 1.13 74.72 67.09 61.18 57.45
Table 3 Convergence time under different rating frequencies
Scenario Convergence time (time-steps)
Rating frequency (f) TuS T + R Total score Rating ratio
10% – – – –
50% 607 635 – –
90% 496 647 796 887
‘−’ indicates when convergence is not achieved within 1000 steps.
6.2 Effect of malicious behaviours
In order to test the robustness of each scheme, we assume that some malicious users
exist and act as follows:
• They give a score of −1 when meeting normal behaviour, and a score of 1 when
seeing bad behaviour.
• Malicious users give a score of 1 to each other regardless of whether the
encounter is normal or bad.
Malicious users are assumed to have the same misbehaviour probability between 0
and 1 as normal users and their activities are not detected (so that malicious acts
can occur continuously to produce inaccurate ratings). In order to determine each
scheme’s robustness in face of malicious behaviours, we use Reputation Aggregation
Error (RAE) to represent the departure of the chosen trustworthy users and the truly
trustworthy ones under the interference from malicious users. RAE is deﬁned as:
RAE =
√√√√√∑si=1
(
ri − r`i
ri
)2
s
where ri is the ranking of the chosen trustworthy user from all AOI neighbours,
r`i is the true ranking based on misbehaviour probabilities, and s is the number of
selected trustworthy users at the moment. RAE is a relative metric that reﬂects the
difference between the rankings of all the selected users against the rankings of the
truly trustworthy group of users. The smaller the RAE value, the closer the selected
set is to the actual set of trustworthy users.
396 G-Y. Huang et al.
froma user pool with ever stricter criteria. For example, if a selectionmethod is capable
to identify only the best 30% in a group, then when the requirement is to identify the
best 10%, the results returned may not be accurate enough for the stricter demand.
We are thus also interested in how selective TuS can identify an ever-smaller group of
trustworthy users. As the average AOI neighbour for 2000 nodes is about 80, we want
to see how good TuS can choose 5, 10, 15, 20, 25, and 30 trustworthy users (i.e., 6.25,
12.5, 18.75, 25, 31.25 and 37.5% of AOI neighbours, respectively) from an average of
80 neighbours.
Figure 9 shows the accuracy of TuS and T+R to choose a speciﬁed number of
trustworthy users under different rating frequencies (e.g., f = 10% and f = 50%).
WeuseT+Rfor comparisonas it is the secondbest scheme fromprevious experiments.
In general, we see that better average accuracy is achieved when more trustworthy
users are required, because the penalty for incorrect selection is less (e.g., one missed
selection produces a 20% inaccuracywhen selecting 5 users, but only 3.3% for 30 users).
We can also observe that TuS has better accuracy than T +R regardless of the number
of selected users, especially when the rating frequency is low. That is, even with a small
number of ratings, TuS is still good at identifying the top users.
Figure 9 Effect of different selectivity on TuS accuracy (see online version for colours)
We also see that reputation aggregation error decreases with increasing numbers of
selected users fromFigure 10, as less penalty formissed selection reduces the reputation
aggregation error. Here, TuS also has less errors than T +R, which shows that TuS
selects the real set of trustworthy users better than T+R.
6.4 Accuracy in higher dimensions
In order to see how TuS performs under multiple dimensions (i.e., more than two
reputation factors), besides total score and rating ratio, we consider one more
reputation factor called latest score, L(u), which is deﬁned as follows:
L(u) =
∑
i
LS(i, u)
398 G-Y. Huang et al.
Table 4 Effect of three reputation factors on accuracy and convergence time
Scenario wS,R w(L,Ran),R ARA (%) CT
Reputation factor f (%) 2D 3D 3D 2D 3D 2D 3D
Latest score 50 1.07 1.11 1.24 71.36 81.27 607 413
Random score 50 1.07 0.88 0.14 71.36 65.81 607 679
∗ARA: Average Reputation Accuracy; CT: Convergence Time.
Random score is a randomﬁxed value between 0 and 1 assigned to each user. Its weight
to other reputation factors is thus relatively lower than the weight of latest score.
In Figure 12, we compare the accuracy of two dimensional and three dimensional
TuS using random score as the third reputation factor. We can see that the effect of
a random factor to both the accuracy and convergence time is low, and the average
difference between 2D TuS and 3D TuS is below 5%, as the weight of the random
factor is low under multivariate analysis. In order to ﬁlter less relevant reputation
factors like random score, we can set a threshold . If the weight of a reputation factor
less then , we can discard this factor to increase the accuracy for the whole system.
Therefore, we can conclude that TuS can ﬁlter out less relevant reputation factors by
lowering their weights, and by combing inﬂuential reputation factors, overall system
performance would improve.
Figure 12 2D and 3D TuS accuracy with random scores (see online version for colours)
7 Concluding remarks
7.1 Discussions
Reputation evaluation: REPS uses direct rating between users as the main
representation for reputations, where users give a simple score of (−1, 0, 1) to indicate
400 G-Y. Huang et al.
References
Aberer, K. (2001) ‘P-Grid: a self-organizing access structure for P2P information systems’,
CoopIS 2001, Vol. 2172, June, pp.179–194.
Aberer, K. and Despotovic, Z. (2001) ‘Managing trust in a peer-to-peer information system’,
Proc. ACM CIKM, pp.310–317.
Atif,Y. (2002) ‘Building trust in e-commerce’, IEEE InternetComputing, Vol. 6,No. 1, pp.18–24.
Bharambe, A., Pang, J. and Seshan, S. (2006) ‘AColyseus: a distributed architecture for online
multiplayer games’, Proc. NSDI, pp.155–168.
Buchegger, S. and Le Boudec, J-Y. (2004) ‘A Robust reputation system for P2P and mobile
ad-hoc networks’, Proceedings of SASN ’04, October.
Das, M.L., Saxena, A. and Phatak, D.B. (2006) ‘Algorithms and approaches of proxy signature:
a survey’, International Journal of Network Security.
Dellarocas, C. (2001) ‘Analyzing the economic efﬁciency of Ebay-like online reputation
reportingmechanisms’,Proceedings of the 3rdACMConference onElectronic Commerce,
pp.171–179.
Ganeriwal, S. and Srivastava, M.B. (2004) ‘Reputation-based framework for high integrity
sensor networks’, Proc. Wksp Economics of P2P Systems, June, pp.66–77.
Hu, S.Y., Chen, J.F. and Chen, T.H. (2006) ‘VON: a scalable peer-to-peer network for virtual
environments’, IEEE Network, Vol. 20, No. 4, pp.22–31.
Hu, S-Y., Chang, S-C. and Jiang, J-R. (2008) ‘Voronoi state management for peer-to-peer
massively multiplayer online games’, Proc. 4th IEEE Intl. Workshop on Networking Issues
in Multimedia Entertainment (NIME), pp.1134–1138.
Hyytia, E., Lassila, P. and Virtamo, J. (2006) ‘A Markovian waypoint mobility model with
application to hotspot modeling’, Proceedings of IEEE ICC 2006, pp.979–986.
Ismail, R. and Josang, A. (2002) ‘The beta reputation system’, Proc. 15th Bled Conf. on
Electronic Commerce, p.41.
Josang, A., Ismail, R. and Boyd, C. (2007) ‘A survey of trust and reputation systems for online
service provision’, Decision Support Systems, Vol. 43, No. 2, June, pp.618–644.
Kamvar, S., Schlosser,M.andGarcia-Molina,H. (2003) ‘The eigentrust algorithmfor reputation
management in P2P networks’, Proc. WWW, May, pp.640–651.
Knutsson, B., Lu, H., Xu, W. and Hopkins, B. (2004) ‘Peer-to-peer support for massively
multiplayer games’, Proc. INFOCOM, pp.96–107.
Lee, H.H. and Sun, C.H. (2006) ‘Load-balancing for peer-to-peer networked virtual
environment’, Proc. NetGames, October, Article No. 4.
Lo, V., Zhou, D., Liu, Y., Dickey, C.G. and Li, J. (2005) ‘Scalable supernode selection in
peer-to-peer overlay networks’, Proc. HOT-P2P, pp.18–27.
Mardia, K.V., Kent, J.T. and Bibby, J.M. (1979)Multivariate Analysis, Academic Press.
Mui, L., Mohtashemi, M., Ang, C., Szolovits, P. and Halberstadt, A. (2001) ‘Ratings in
distributed systems: a Bayesian approach’, Proc. Workshop on Information Technologies
and Systems.
Ratnasamy, S., Francis, P., Handley, M., Karp, R. and Shenker, S. (2001) ‘Scalable
content-addressable network’, Proc. ACM SIGCOMM, pp.161–172.
Srivatsa, M., Xiong, L. and Liu, L. (2005) ‘Trustguard: countering vulnerabilities in reputation
management for decentralized overlay networks’, Proc. WWW, pp.422–431.
Stoica, I., Morris, R., Karger, D., Kaashoek, F. and Balakrishnan, H. (2001) ‘Chord: a scalable
peer-to-peer lookup service for internet application’, Proc. ACM SIGCOMM, pp.149–160.
Xiong, L. and Li, L. (2004) ‘PeerTrust: supporting reputation based trust for peer-to-peer
electronic communities’, IEEE TKDE, Vol. 16, No. 7, pp.843–857.
  
 
 
 
 
 
附件 
發表之期刊論文 
 
 
 
 
 
 
 
 
 
 
 
 
 
3D streaming is a technique that delivers 3D content over networks in real-time to 
allow users to navigate a VE without a complete content installation. Similar to audio 
or video media streaming, 3D streaming requires the content be fragmented into 
pieces before it can be transmitted, reconstructed, and displayed. However, unlike the 
linearly streamed audio or video, 3D streaming is highly interactive and non-linear in 
nature, where the streaming sequence is based on the visibility or interest area of each 
user, making it individually unique among the users. 
Current 3D streaming schemes adopt the client-server model for content delivery. 
However, such architecture is difficult to scale as 3D streaming is both data- and 
processing-intensive. Prohibitively vast amount of server-side bandwidth and CPU 
power are required for a massive audience. On the other hand, highly scalable yet 
affordable computing and content sharing systems have been built successfully with 
peer-to-peer (P2P) networks. As users in a 3D scene could own similar content due to 
overlapped visibility, they may obtain content from each other in a P2P manner. 
However, while P2P media streaming has progressed significantly in recent years, it 
may not be directly applicable to 3D content due to different content access patterns. 
In both live and on-demand media streaming, content is often sent linearly after a 
starting point, whereas access to 3D content is rather arbitrary and nonlinear, and 
depends much on real-time user behaviors [4]. New insights and novel designs are 
thus needed for P2P-based 3D streaming. 
In this article, we describe the P2P approach to 3D streaming with a conceptual model 
and some recent designs [5] [6] [7]. Through prototyping (see Fig. 1) and simulations 
of our proposed framework, FLoD [7], we show that P2P holds great promises to 
provide scalable and affordable content delivery for future 3D virtual worlds. 
 
 
3D Streaming Requirements 
To understand how 3D streaming could work on P2P networks, we must first identify 
its requirements and challenges from the perspectives of both clients and servers. 
There are four main types of 3D streaming today: object streaming, scene streaming, 
visualization streaming, and image-based streaming [7]. In the context of virtual 
worlds, our main focus would be on scene streaming, whose goal is to provide each 
user a navigation experience within a scene by progressively delivering the 3D objects 
within the user’s area of interest (AOI) (i.e., the area currently visible to the user, 
often denoted as a circle around the user [2]). We may assume that each object 
consists of 3D models (e.g., meshes) and other associated data (e.g., textures, height 
maps, light maps, and animations), plus a certain position and orientation described in 
some form of scene description. To facilitate delivery, each object is first fragmented 
into a base piece and many refinement pieces in application-specific manners, using 
methods such as progressive meshes [8] or geometry images [9] for models, or 
progressive GIF, JPEG, or PNG for textures. Once a set of base pieces is obtained, an 
initial rendering of the scene can be performed to allow timely navigation. Additional 
time in the scene will allow users to download and render models in more details, 
given certain Quality of Service (QoS) requirements [10]. The two main requirements 
for a 3D streaming system thus are: 
z Streaming quality 
From the user's perspective, the main concern for 3D streaming is its visual 
quality. However, as visual quality can be subjective, a more definable concept is 
the streaming quality in terms of “how much” and “how fast” a client obtains 
data. For the former, we could use the ratio between the data already downloaded 
and that required to render the current view (i.e., a fill ratio). A ratio of 100% 
indicates the best visual quality (i.e., the same as pre-installed content). For the 
latter, we may use base latency and completion latency to indicate the time to 
obtain the base piece or the full data of an object. Base latency indicates the 
delay to display a basic view of the scene, while completion latency indicates the 
time needed to fully inspect objects. The goal thus is to maximize fill ratios 
while minimizing the latencies. 
 
z Scalability 
From the server's perspective, the main goal is to maximize the number of 
concurrent users by distributing transmission and processing loads to clients as 
much as possible. For transmissions, it is preferable if most content is delivered 
by clients and not by the server. For processing, the server should minimize its 
z Content Exchange: 
To optimize the visual (or streaming) quality for a given bandwidth budget, a 
client can then leverage its knowledge on peers to schedule content requests 
based on visibility, content availabilities and network conditions. Interestingly, 
as 3D streaming can be view-dependent [8], where data pieces may be applied 
arbitrarily to reconstruct objects. As long as the piece dependencies are satisfied, 
only a roughly sequential transfer is needed (as opposed to the strictly sequential 
video streaming). Concurrent downloads can also be exploited to accelerate the 
retrieval for pieces that do not involve dependencies. Depending on the results of 
initial requests, additional peers or requests may then be needed. 
In client-server 3D streaming, object discovery is performed by the server, which 
possesses complete knowledge of all objects, and may determine for each client the 
viewable objects. Source discovery is not an issue as there is only one data provider. 
Full data availability is assumed for the server, and content delivery is unidirectional 
from the server to clients. In P2P 3D streaming, all of the above issues need to be 
addressed, with considerations to performance and scalability. 
A Conceptual Model 
Given the above requirements and challenges, we present a categorization of the main 
tasks for a P2P-based 3D scene streaming as follows (Fig. 2): 
 
 
Fig. 2. A conceptual model for P2P-based 3D scene streaming, where obtaining 
movements and performing rendering are the only task when content is locally 
available. Object preprocessing, determination, transmission, and reconstruction are 
additional stages for networked 3D streaming. In client-server 3D streaming, only 
fragmentation, prefetching, and prioritization are needed. Partition and selection are 
the new tasks introduced for P2P-based 3D streaming. 
 
To allow client-side visibility determination, the VE is partitioned into square grids, 
each of which has a small scene description for the objects within. Each client can 
then determine the visible objects by retrieving scene descriptions for cells covered by 
its AOI. When entering a new area, a client first prepares some scene requests to 
obtain scene descriptions from its AOI neighbors or the server. Prioritized piece 
requests based on preferences are then sent for the visible objects. A view is rendered 
progressively as data pieces arrive from either the peers or the server (which acts as 
the final data source for unfilled peer requests). A query is also made to neighbors on 
content availability before actual requests are sent to randomly selected neighbors that 
answer the query. The process is repeated as a client moves in the environment. 
To demonstrate how FLoD works in real scenarios, we implement a prototype (Fig. 1) 
that performs all the major 3D streaming tasks except prefetching. We experiment 
with the prototype by setting up a Linux server to load the initial scene and respond to 
client requests, as users login to navigate and explore the scenes. The experiment 
shows that the server bandwidth usage is about half of a pure client-server approach, 
as clients can be self-sufficient in content serving [7]. 
To investigate large-scale behaviors, we then perform simulations with bandwidth 
limits (i.e., 1 Mbps download / 256 Kbps upload for clients, and 10 Mbps symmetric 
for the server). Objects are placed randomly on a 2D map, with sizes based on our 
prototype (i.e., 15 KB per object, with 3 KB base piece and 1.2 KB refinement pieces, 
and 300 to 500 bytes per scene description). The nodes move with constant speeds 
using random way-points [11] for 3000 time-steps, and request scene descriptions or 
data pieces as needed. 
Scalable systems need to keep resource usages bounded at all relevant system nodes. 
Fig. 3(a) shows the upload bandwidth for both a client-server (C/S) server and a 
FLoD server. As the server upload limit is 10 Mbps, the C/S server exhausts its 
bandwidth at 1250 KB/s when serving 200 nodes. On the other hand, a FLoD server's 
upload stays relatively constant below 50 KB/s. This reduction is explained in Fig. 
3(b), which shows that the upload and download bandwidth of FLoD clients converge, 
indicating that as the system scales (i.e., the number of AOI neighbors increases), 
FLoD clients become self-sufficient in content serving. However, some bandwidth 
overhead exists for using the P2P overlay, as the overlay needs to exchange user 
positions and notify peers of new neighbors [7]. This overhead thus grows as AOI 
neighbor density increases. While this overhead growth indicates a certain scalability 
limit, it also means that if the user density in each region is controlled, the entire 
system can accommodate users in a scalable manner. 
Comparisons and Open Questions 
FLoD addresses object discovery by using grid-based scene descriptions, and queries 
AOI neighbors from a P2P-VE overlay for source discovery. A query-response 
approach is used for state exchange, and random selection from peers for content 
exchange. Though this basic design is simple, the data sources are limited and the 
query for content availability may be slow. In a subsequent work [12], we let clients 
keep historic AOI neighbors as extra sources, and proactively push content 
availability to AOI neighbors to reduce the query-response delay. Piece requests are 
also sent to closer AOI neighbors first to avoid concentrating requests. Simulation 
results show that both fill ratio and base latency improve with the enhancements. Two 
recent designs have since been proposed for P2P 3D streaming, and represent 
alternative approaches in the solution space: 
LODDT: Level-of-detail description tree (LODDT) [5] is a tree structure that stores 
urban cityscape hierarchically. Clients thus can progressively perform visibility 
determination given a partial tree covered by the user’s AOI. A few peer selection 
strategies based on object proximity and estimated content availability are also 
evaluated. Object discovery thus is based on a distributed tree, while source discovery 
is performed with a P2P-VE overlay similar to FLoD. However, as only a selected set 
of connectivity peers provides the AOI neighbors, LODDT is more of a super-peer 
than a fully distributed design. To learn of the client states, queries and responses are 
also exchanged among the peers. Content availability is not exchanged, but inferred 
from the relative positions between neighbors. Based on response time and estimated 
content availability, requests are then made randomly to potential sources. 
HyperVerse: HyperVerse [6] utilizes a group of public servers to construct a static, 
structured overlay that maintains the user positions for a VE. The clients learn of 
other peers from the servers, and exchange content by forming a loosely-structured 
overlay. Object discovery and source discovery thus are performed centrally by the 
server that notifies clients of relevant peers and objects. There is no explicit state 
exchange policy, while content is also requested from random neighbors. 
We compare these designs with FLoD in a taxonomy based on the main challenges 
below (Fig. 4), while outlining the potential solution space for P2P 3D streaming: 
       Approach 
Stage 
FLoD 
LODDT HyperVerse 
Basic Enhanced 
Object Discovery Grid-based scene descriptions Hierarchical scene 
descriptions 
Server-provided list 
Source Discovery AOI neighbors 
(from peers) 
extended AOI 
neighbors 
(from peers) 
n nearest neighbors 
(from super-peers) 
AOI neighbors 
(from server) 
State Exchange Query-response 
(Pull)  
Incremental 
update (Push) 
Query-response 
(Pull) 
N/A 
Content Exchange Random 
selection 
Multi-level 
AOI selection 
RTT and estimated 
peer loading 
Random selection 
 
Fig. 4. Taxonomy of P2P 3D streaming approaches. FLoD [7] relies on 
grid-partitioned scene descriptions and a fully-distributed P2P-VE overlay to discover 
objects and sources, while using both push and pull to exchange content. LODDT [5] 
utilizes a hierarchical tree to partition the scene, while prioritizing requests based on 
network conditions. HyperVerse [6] designates the discovery phase as a server task, 
and uses clients only for content exchange purposes. 
Related Work 
Schmalstieg and Gervautz [2] first introduce scene streaming where a server 
determines and transmits visible objects at different level-of-details (LODs) to clients. 
Teler and Lischinski use pre-rendered image-based impostors as the lowest LOD to 
allow faster initial visualizations [3]. Cyberwalk [11] adopts progressive meshes to 
avoid the data redundancy from multiple LODs, and focuses on caching and 
prefetching to enhance visual perceptions. Social MMOGs such as ActiveWorlds4, 
There.com5, and Second Life [1], as well as the 3D Instant messenger IMVU6, utilize 
scene streaming to support dynamic content, but little of their mechanisms are 
publicly known. Our work complements the above works with distributed deliveries. 
Mayer-Patel and Gotz present the concept of non-linear media streaming [4] where 
interactive content (e.g., images for a virtual museum) is divided and sent through 
multicast channels subscribed by clients. The system supports a large number of 
receivers by sending the content via application-layer multicast (ALM). However, 
ensuring proper content partition (so that only relevant content is received) and 
bounded latency (important for interactive applications) are non-trivial issues. Under 
                                                 
4 http://www.activeworlds.com/ 
5 http://www.there.com/ 
6 http://www.imvu.com/ 
References 
[1] Philip Rosedale and Cory Ondrejka, "Enabling Player-Created Online Worlds 
with Grid Computing and Streaming," Gamasutra Resource Guide, 2003. 
[2] Dieter Schmalstieg and Michael Gervautz, "Demand-Driven Geometry 
Transmission for Distributed Virtual Environments," Computer Graphics 
Forum, vol. 15, no. 3, 1996, pp. 421—432. 
[3] Eyal Teler and Dani Lischinski, “Streaming of complex 3D scenes for remote 
walkthroughs,” Computer Graphics Forum, vol. 20, no. 3, 2001, pp. 17—15. 
[4] Ketan Mayer-Patel and David Gotz, "Scalable, Adaptive Streaming for 
Nonlinear Media," IEEE Multimedia, vol. 14, no. 3, 2007, pp. 68—83. 
[5] Jerome Royan et al., "Network-Based Visualization of 3D Landscapes and City 
Models," IEEE CG&A, vol. 27, no. 6, 2007, pp. 70-79. 
[6] Jean Botev et al., "The HyperVerse - Concepts for a Federated and Torrent 
Based '3D Web'," Intl. Journal of Adv. Media and Comm., Vol. 2, No.4, 2008. 
[7] Shun-Yun Hu et al., "FLoD: A Framework for Peer-to-Peer 3D Streaming," in 
Proc. INFOCOM, 2008, pp. 1373-1381. 
[8] Hugues Hoppe, “View-dependent refinement of progressive meshes,” in Proc. 
SIGGRAPH, 1997, pp. 189—198. 
[9] Nien-Shien Lin, Ting-Hao Huang, and Bing-Yu Chen, “3D Model Streaming 
based on JPEG 2000,” IEEE Trans. Consumer Electronics, vol. 53, no. 1, 2007, 
p.182—190. 
[10] George V. Popescu and Christopher F. Codella, “An Architecture for QoS Data 
Replication in Network Virtual Environments,” in Proc. IEEE Virtual Reality 
(IEEE VR), pp. 41-48, 2002. 
[11] Jimmy Chim et al., “CyberWalk: A Web-Based Distributed Virtual Walkthrough 
Environment,” IEEE Trans. Multimedia, vol. 5, no. 4, 2003, pp. 503—515. 
[12] Wei-Lun Sung, Shun-Yun Hu, and Jehn-Ruey Jiang, "Selection Strategies for 
Peer-to-Peer 3D Streaming," in Proc. NOSSDAV, May 2008. 
[13] Huiguang Liang, Mehul Motani, and Wei Tsang Ooi, “Textures in Second Life: 
Measurement and Analysis,” in Proc. IEEE ICPADS workshop P2P-NVE, Dec. 
2008. 
[14] Shun-Yun Hu, Jui-Fa Chen and Tsu-Han Chen, “VON: A scalable peer-to-peer 
network for virtual environments,” IEEE Network, vol. 20, no. 4, 2006, pp. 
22—31. 
[15] Mo-Che Chan, Shun-Yun Hu, and Jehn-Ruey Jiang, “Secure Peer-to-Peer 3D 
Streaming,” to appear in Multimedia Tools and Applications, 2009. 
 
