 2
演化式支持向量機推論系統-應用於營建管理之決策 
第 3 年期末進度報告(完整版) 
Abstract- Problems in construction management are complex, full of uncertainty, and vary based on 
site environment. Two tools, the fast messy genetic algorithms (fmGA) and support vector machine 
(SVM) have been successfully applied to solve various problems in construction management. 
Considering the characteristics and merits of each, this paper combines the two to propose an 
Evolutionary Support Vector Machine Inference Model (ESIM). In the ESIM, the SVM is primarily 
employed to address learning and curve fitting, while fmGA addresses optimization. This model 
was developed to achieve the fittest C and γ parameters with minimal prediction error. This research 
further integrates the developed ESIM with an object-oriented (OO) computer technique to create 
an Evolutionary Support Vector Machine Inference System (ESIS). Simulations conducted to 
demonstrate the robustness of the model in application indicate that ESIS may be used as a 
multifarious intelligent decision support system in decision-making to help solve a wide range of 
construction management problems. 
Keywords: Fast messy genetic algorithms; Support vector machine; Object-oriented system 
development. 
1. Introduction 
Construction engineering comprises a number of disparate activities, which relate to and impact 
upon one another and are affected by various uncertainties, such as weather, geological 
characteristics, human judgment, and market fluctuation. Professional construction management is 
necessary for construction engineering to accomplish construction objectives efficiently and is 
essential to project success [1]. 
Construction management is a process of accomplishing construction objectives through the 
application of available resources. Due to uncertainties and the changing nature of the construction 
industry, practical construction management problems are complex and ill-structured [2]. 
Developing a deterministic mathematical model to solve problems of construction management is 
difficult and expensive. Approximate inference, which is fast and cost effective, represents a viable 
alternative.   
Inference is the process of deriving new facts from previously known information. When known 
information changes, the inference process should adapt accordingly.  Construction management 
problems are complex and full of uncertainties, vagueness and incomplete or inexact data. Thus, 
“known” information is subject to continuous change. Therefore, the inference process must be 
adapted to fit environmental realities [3]. Humans are able to learn and capable of processing 
 4
management problems opens up a new agenda for future research. 
2. Support vector machines approach 
The theory that underlies support vector machines (SVM) represents a new statistical technique 
that has drawn much attention in recent years. This learning theory may be seen as an alternative 
training technique for polynomial, radial basis function and multi-layer percept classifiers. SVM are 
based on the structural risk minimization (SRM) induction principle [10], which aims to restrict the 
generalization error (rather than the mean square error) to certain defined bounds. SVM have been 
shown to deliver higher performance than traditional learning machines and have been introduced 
as powerful tools to solve classification and regression problems.  
For the classification case, SVM identify a separating hyper plane that maximizes the margin 
between two classes. Maximizing the margin is a quadratic programming (QP) problem that can be 
solved from its dual problem by introducing Lagrangian multipliers. 
Linear programming (LP)-SVM [7] is an important innovation due to its linearity and flexibility 
when used on large datasets. The term “linear programming” means the algorithm is based on linear 
programming optimization. Many experiments have demonstrated that the efficiency and 
performance of LP-SVM exceeds that of QP-SVM for purposes that include solving problems with 
very large sample sizes, improving computational speeds, and reducing support vector numbers. 
Recent research work has demonstrated the convergence of QP-SVM. 
In most cases, identifying a suitable hyper plane in input space is an application that is overly 
restrictive in practical applications. The solution to this situation is to map the input space into a 
higher dimension feature space, and then identify the optimal hyper plane within this feature space. 
Without any knowledge of the mapping, an SVM locates the optimal hyper plane using dot product 
functions in feature space known as “kernels”. The kernel trick based on the Mercer theorem is used 
in SVM to map input data into high-dimensional feature spaces, wherein simple functions defined 
on pairs of input patterns are used to compute dot products and design a linear decision surface. For 
input space X, if there is a mapping HX →:φ  that maps any Xzx ∈,  into Hilbert space H then 
a kernel, RXXK →×: , is constructed as ( ) ( ) ( )
H
zxzxK φφ ,, =  , where 
H
⋅⋅,  is the scalar 
product operator in H. The kernel function K satisfies the Mercer condition: the kernel matrix 
formed by restricting K to any finite subset of X is positive semi-definite, and, hence, K is usually 
called the Mercer kernel. The Mercer condition is essential to kernel design, as it is the key 
requirement for a unique global optimal solution to the kernel-extended pattern analysis algorithms 
based on convex optimization (e.g., SVM). 
The solution of the optimal hyper plane can be written as a combination of a few input points 
known as “support vectors”. Regression problem equations in SVM are the same as those of 
classification problems, with the exception of their respective target variables. By introducing the 
ε-insensitive loss function and modifying slightly the equation formation, the SVM theory can be 
 6
d
jiji xxxxk )1(),( ⋅+=  (4) 
Radial basis function kernel: 
)exp(),(
2
jiji xxxxk −−= γ  (5) 
Sigmoid kernel: 
)tanh(),( δ−⋅= jiji xkxxxk  (6) 
This paper suggests that, in general, RBF is a reasonable first choice. The RBF kernel maps 
samples nonlinearly into a higher dimensional space. Therefore, unlike the linear kernel, it can 
handle cases where relationships between class labels and attributes are nonlinear. Furthermore, the 
linear kernel is a special case of RBF, the linear kernel with a penalty parameter C has the same 
performance as the RBF kernel with some parameters (C; γ). In addition, the sigmoid kernel 
behaves like RBF for certain parameters. The second reason is that the number of hyper parameters 
that influences model selection complexity. The polynomial kernel has more hyper parameters than 
the RBF kernel. Finally, the RBF kernel presents fewer numerical difficulties. Moreover, we must 
note that the sigmoid kernel is not valid (i.e., not the inner product of two vectors) under certain 
parameters [7]. However, there are certain situations where the RBF kernel is not suitable. In 
particular, when the number of features is very large, one may just use the linear kernel. 
3. Fast messy genetic algorithms approach 
fmGA, developed by Goldberg et al. [14], can find efficiently optimal solutions for large-scale 
permutation problems [15]. The fmGA-based approach is known for its flexibility in allowing 
hybridization with other methodologies to obtain better solutions [16]. fmGA elements and 
processes are described briefly in the following: 
3.1. Messy representation 
In the fmGA, genes of a chromosome are represented by the paired values “allele locus” and 
“allele value”. Allele locus indicates gene position and allele value represents the value of the gene 
in that position. For example, two messy chromosomes ((3 1)(1 0)(2 1)(4 1)(5 0)) and ((2 1)(5 0)(3 
1)(1 0)(4 1)) are both equivalent to the binary string 01110. In addition, chromosomes may have 
various lengths. For instance, chromosomes S1:((5 1)(1 1)(3 0)(1 0)(4 1)(3 1)(2 1) (4 0)(5 0)) and 
S2: ((3 0)(1 1)(5 0)) both represent valid strings of length five. As the above example shows, messy 
chromosomes may be ‘‘over-specified’’ and ‘‘underspecified’’ in terms of encoding bit-wise strings. 
Chromosome S1 is an over-specified string which has two different values in the positions of genes 
1, 3, 4, and 5. To evaluate an over-specified chromosome like S1, the string may be scanned from 
left to right following the first-come-first-served rule. Thus, S1 represents the bit string 11011. On 
 8
3.3. The fmGA organization 
There are two loops, the outer loop and the inner loop, within the fmGA. The outer loop iterates 
over the order k of the processed Building Blocks (BBs). BBs are the schemata, which may be 
designated as “short”, “low-order”, or “high-performance”. The order of BBs is defined as the 
number of fixed values in the chromosome. For example, if the BB is 011*1**, BB order equals 4. 
* symbolizes a “don’t care” value. Every cycle of the outer loop is designated as one “era”. When a 
new era starts, the inner loop, which includes the initialization phase, the primordial phase, and the 
juxtaposition phase, is invoked. The goal of the initialization phase is to create a population of 
strings containing all possible BBs of order k. fmGA performs the so-called ‘‘probabilistically 
complete initialization’’ process, which randomly generates n chromosomes of length γ, where k<γ
≦l and l represent problem length. The value of γ can be chosen arbitrarily, which is usually 
defined as l-k. The population size n can be approximated by using (7) for the binary-coded 
problem [17]. 
( ) ( ) kmc
k
kl
k
l
n 212 2 −
⎟⎟⎠
⎞
⎜⎜⎝
⎛
−
−
⎟⎟⎠
⎞
⎜⎜⎝
⎛
= βα
λ
 (7) 
Where, c(α) represents the square of a normal random deviate corresponding to tail-probability α, 
β represents the signal-to-noise ratio (i.e., the ratio of fitness deviation to the difference between 
two competing BBs). Variable m represents the number of BBs and k represents BB order. Those 
parameters may be set arbitrarily, in accordance with the problem. The primordial phase filters out 
the ‘‘bad’’ genes that do not belong to BBs, so that the resultant population encloses a high 
proportion of ‘‘good’’ genes belonging to BBs. Two operations, building-block filtering and 
threshold selection, are performed during the primordial phase. In the juxtaposition phase, those 
good genes (BBs) are combined by using selection and messy operators to form a high quality 
generation, which, perhaps, contains the optimal solution. Where the inner loop of the fmGA 
terminates, the outer loop of the fmGA begins, with processing BBs of order k +1. In addition, the 
competitive template is replaced by the best solution found so far, which becomes the new 
competitive template for the next era. The whole process is repeated until the maximum number 
required kmax is reached. In addition, fmGA can perform over “epochs”, the term used to describe a 
procedure that starts from a first era and finishes with kmax. Epochs can be performed as many times 
as desired. In addition, the best solution found so far is that passed to epochs though the competitive 
template. 
4. Evolutionary Support Vector Machine Inference Model 
4.1.Chromosome design 
To implement the proposed approach, this research used the RBF kernel function for the SVM 
 10
Default
C, gamma
SVM training 
model
Average accuracy
(fitness function)
fmGA parameters
search
Training data set
Termination 
criteria
Optimized 
parameters
NO
YES
 
Fig. 4. Structure of the ESIM. 
4.4.Model Adaptation Process 
The ESIM adaptation process is described by the following pseudo code algorithm. 
 
Begin  
Epoch = 1; 
Generate the competitive template = random string;  
While (not termination condition) //Outer Loop  
{ 
Repeat //Inner Loop 
{ 
 //Initialization Phase 
Era = 0; 
Probabilistic_Initialize(Pop(Era), Epoch);  
Evaluate(Pop(Era), template); //Evaluate fitness value 
//Primordial Phase 
While (not primordial termination condition) 
{ 
Episode = 0;  
While (Episode < Episode_max(Era)) 
{ 
Thresholding_Selection(Pop(Era));  
Episode = Episode + 1; 
} 
Building-Blocks_Filtering(Pop(Era)); 
Evaluate(Pop(Era),template); //Evaluate fitness value 
} 
//Juxtapositional Phase  
 12
Cut_and_Splice：In this step, a cut probability is used to recombine different strings to create new 
strings. 
Mutation：The mutation produces spontaneous random changes in various chromosomes, which 
protects against premature loss of important notations.  For the ESVM, the purpose of mutation is 
to adjust the value of C and γ for better performance. It alters one or more genes with a probability 
( gep ), which is smaller than or equal to the rate of mutation ( mup ). Mutation operation compares 
the gene’s gep  with mup  bit by bit.  If muge pp ≤ , then the value of the gene will be altered. 
5. SYSTEM ANALYSIS AND DESIGN 
This research integrates the ESIM with OO computer technique to develop the Evolutionary 
Support Vector Machine Inference System. The system is developed based on three concepts, 
including the OO approach, incremental and iterative model, and Unified Modeling Language 
(UML). The OO approach is used to exploit the benefits of OO to develop the system. The 
incremental and iterative model is employed to increase developed system quality and reduce 
development time. UML is a standard OO specification language adopted by the Object 
Management Group (OMG) for specifying, visualizing, understanding, and documenting OO 
software. For that reason, the development procedure workflow is arranged to reflect the logical 
dependencies of UML artifacts and regular system development needs. Within a single development 
cycle, major tasks include analysis and design work. 
5.1.System Analysis 
Analysis is the investigative process to determine essential system functions. The analysis phase 
of system development focuses on understanding and representing the requirements and concepts 
related to a system [19]. OO analysis focuses on identifying and describing required objects in the 
problem domain. The following activities are used in ESIS analysis: 
5.2.Defining System Requirements 
System requirements describe the needs / desires of system users [20]. The primary goal of this 
activity is to identify and document such requirements. The aim of this research was to develop an 
intelligent inference system to solve problems related to construction management.  Hence, the 
ESIS is designed to address the application needs of various users.  System users are defined as 
those who want to solve construction management problems using a conceptual approach and may 
be project managers, engineers, schedulers, cost controllers, designers, contractors, architects, 
government officials, industry associations, or others who fit the description of a system user. ESIS 
integrates the ESIM through the use of OO computer techniques. System functions, designed to 
meet the abovementioned requirements, are summarized in Table I. “Evident” indicates that users 
should be cognizant that the related function is performed, while “hidden” indicates that function 
execution happens outside users’ field of awareness. 
 14
of related concepts or packages. It represents system concepts in a high level way within simple 
groups. ESIS is a complex system comprising multiple concepts. To reduce system complexity, this 
research assembled concepts together to partition the system into smaller subsets. Derived domain 
concepts for the system are shown in Fig. 5. 
Legend
Package
Dependency
Adaptation Management
Inference
 
Fig. 5. System Concepts 
5.4.System Design 
A design describes how a system works and extends analyzed results to produce specifications 
for system implementation. During analysis, system development focuses on identifying software 
programs that need to be developed and implemented. In the system design phase, decisions are 
taken with regard to how requirements will be satisfied. OO system design focuses on defining 
logical software objects. The blueprints for implementing the ESIS are discussed in the following: 
5.5.Defining System Architecture 
Architecture, the organization or structure of a system, serves as the basis for system 
understanding, re-use, and evolution. It is also the abstraction of a system’s implementation [21]. 
The common architecture of information systems, known as “three-tier” architecture, includes 
user interface, application logic, and storage. The logical architecture of the system is designed 
based on the three-tier architecture. The architecture package diagram for ESIS is shown in Fig. 6. 
In the diagram, packages illustrate groups of elements. This research work isolates the application 
layer in the middle layer. Therefore, these three tiers are independent so that the system enables to 
process different tasks simultaneously. This research divides the common three-tier architecture into 
multi-tiered architecture in order to decompose software complexity and exploit reusability 
advantages. In this paper, the application logic tier is decomposed into domain and service layers. 
The multi-tiered OO architecture can be characterized as having layers and partitions, with layers 
representing vertical tiers and partitions representing horizontal divisions of relatively parallel 
 16
ESIM
User
Solution
(from management)
Fast Messy 
Genetic Algorithm
Support Vector 
Machines SVM parameter
Adaptation datum
(from management)
OperationProbabilistic_Initialize
Cut_and_Splice Mutation
Evaluate
Selection
Input pattern
(from management)1 1
1
1
1
1
1
1
1 1
1
1
1 1 n1..n
1
1..n
1 1..n
1..n0..n
1
1
1 1
1
1..n
Desired output
(from Management)
(from Domain)
0..n0..n
Observes
Solution
(from Management)
0..n
1
Selects
Case
(from Management)
0..n1
Selects
Evaluation
(from Adaptation)
1
1..n
Initiates
1
0..n
Import to
1
0..n
Import to
Actual output
(from Management)
0..1
1
Compare with
0..n
0..n
Observes
1 1..n
Derives
User
Data record
Input pattern
Solution
Case
Result
Desired 
Output
Actual 
Output
Adaptation 
datum
0..n 0..n
1
1
1
0..n
0..n
1..n
1 1..n 1 1..n
(A)
(B)
(C)
User
 
Fig. 7. (A) Class Diagram: Adaptation Concept; (B) Class Diagram: Management Concept; (C) Class 
Diagram: Inference Concept 
6. MODEL VALIDATION 
6.1 Preparations for Model Validation 
6.1.1 Data Preprocessing  
Pattern outputs are determined in accordance with problem outcome characteristics.  Principles 
for determining pattern outputs are described as follows:   
Either-Or Outputs 
Either-or outputs such as “yes or no,” “on or off,” etc. are assigned values of either 1 or -1.   
Clear Boundary Outputs 
For clear boundary outputs such as degree, score, similarity, possibility and so on, problem 
answers are normalized directly in the 0 to 1 range.   
Unclear Boundary Outputs 
Unclear boundary outputs such as cost, duration, number and so on must be normalized before 
ESIM is applied.  As the inference results of new problems may be greater or smaller than the 
 18
using SVM-Light, obtained at website http://svmlight.joachims.org/ (Joachims 2002).  RMSE was 
employed to evaluate the performance of each method.  Detailed information about the 
SVM-Light implemented in this research is summarized in Table 5.2.  All validation problems 
were implemented on a standalone Personal Computer (PC) with a 1.6 Giga Hertz (GHz) Intel 
Pentium® dual processor and 2048 MegaByte (MB) of Random-Access Memory (RAM) running 
Microsoft® Windows XP®.   
Table 5.2 Detailed Information on SVM Implementation 
Property Method 
Tool SVMLight 
Model SVMlight is an implementation of Support Vector Machines 
in C language 
Parameter C=1 
γ =1/nip 
niv is the number of input values. C and γ  were suggested by Hsu et al. (2003). 
6.2 Exclusive-Or (XOR) 
6.2.1 Problem Statement 
The Exclusive-OR (XOR) is a nonlinearly separable problem that requires the use of hidden 
neurons to learn the task (Minsky and Papert 1969).  Since nonlinearly separable patterns are a 
common occurrence, the XOR problem has historically been considered a good test of models.  
Before applying the ESIM to solve real construction management problems, this research work uses 
the XOR problem to demonstrate the potential of ESIM to solve real world problems.   
6.2.2 Model Application 
The exclusive-or (XOR), a simple nonlinear problem, has historically been considered a good test 
of models. The XOR function maps two binary inputs to a single binary output as (Input 1, Input 2, 
Output) = (0,0,1), (1,0,1), (0,1,1), (1,1,-1). Table 5.3 illustrates the simulation results generated 
during the search process. This table shows that the classification model quickly and successfully 
searched for the global optimal solution with zero prediction error. In addition, the regression model 
searched for the optimal solution. As results show, the ESIS simultaneously obtained the global 
optimal solution with minimum prediction error.   
 20
Three reasons make the ESIM suited to estimating conceptual building costs.   
(1) The ESIM can identify complex input-output relationships.  The model uses SVM to 
represent complex input-output mappings.  Thus, the model can identify complex 
relationships between project conditions and building costs.  This characteristic addresses 
the difficult situation faced in current conceptual cost estimations. 
(2) The ESIM allows reuse of previous cases.  The model uses fmGA to evolve optimal 
solutions from examples.  Previous cases, therefore, are reused in the same manner that 
human experts utilize prior experience and historical data to measure building costs.   
(3) The ESIM can acquire knowledge and experience fundamental to problem solving.  The 
proposed model represents problem domain knowledge and experience acquired by SVM 
architects.  Consequently, the ESIM can acquire the underlying knowledge and 
experience underpinning conceptual cost estimation.   
Identify Influencing Factors 
Hsieh (2002) identified 10 factors influencing building cost in the conceptual phase.  These 
factors can be categorized into two groups, including preliminary owner requirements and site 
investigations.   
Collect Input and Test Patterns 
Table 5.4 reveals 26 input patterns and three validation cases collected by Hsieh (2002).  These 
patterns are based on real data from actual housing projects constructed in reinforced concrete (RC) 
and built in northern Taiwan between 1997 and 2001.   
 22
Table 5.4 Patterns for the Conceptual Estimation of Building Costs (Continued)  
Test patterns 
Pattern 
no. 
Building 
costs 
Input Output 
(1) (2) (3) (4) (5) (6) (7) (8) (9) (10) (11) 
27 25285.42 1748.88 1 36 1 86 13736.74 12 2 3 3 0.7059 
28 22656.32 2315.94 1 147 1 83 12034.57 11 2 1 3 0.5812 
29 16016.88 3146.93 2 52 1 144 18691.88 9 2 1 2 0.2664 
Note: explanation of number notations above - (1): Site area (in square meters); (2): Geological 
property; (3): Number of households affected by development; (4): Earthquake impact; (5): Planned 
number of households in completed development; (6): Total floor area (in square meters); (7): 
Floors aboveground (in stories); (8): Floors belowground (in stories); (9): Decoration class; (10): 
Facility class; (11): Normalized building cost.  Building cost is stated in NTD (New Taiwan 
Dollars) per square meter. 
Quantitative factors are outlined in Table 5.4, (1), (3), (5), (6), (7), and (8). Columns (2), (4), 
(9), and (10) provide qualitative factors.  Qualitative factors are described in Table 5.5.   
Table 5.5 Description of Qualitative Factors Involved in Conceptual Cost Estimations 
Influencing factor Qualitative option Value 
Geological property Soft 1 
Medium 2 
Hard 3 
Earthquake impact Low 1 
High 2 
Decoration class Basic type 1 
Normal type 2 
Luxury type 3 
Facility class Basic type 1 
Normal type 2 
Luxury type 3 
Preprocess Data 
According to the principles of determining pattern outputs, building costs are defined by 
 24
complete relevant tasks (Wang, Yung and Ip 2001). To improve chances of project success, various 
initiatives have been introduced to regulate the subcontractor appointment process. 
Each subcontractor is required to provide an appropriate combination of staff, materials, 
machines/equipment and skills necessary to accomplish subcontracted work tasks. As a tardiness 
penalty may be assessed if a construction project is not completed on time, subcontractor 
performance directly affects overall project success (Hsieh 1998).  
In practice, a general contractor cannot supply all resources needed on a construction site and, to 
reduce costs, relies on the assistance of subcontractors to complete most projects (Huang 1995). 
While an effective subcontractor can be expected to accomplish assigned tasks within a specified 
time period, budget and level of quality, poorly performing subcontractors produce defective work 
that requires additional commitments of budget and time (Kale and Arditi 2001; Schaufelberger 
2003). A ‘subcontractor rating’ is usually assigned by general contractor management for reference 
use when selecting effective subcontractors (Albino and Garavelli 1998). This rating generally 
reflects an evaluation of the received bid and potential subcontractor characteristics, including 
reliability and size, among other variables. General contractors use a reference index of 
subcontractor performance to determine the potential subcontractor most capable of handling a 
particular subcontracted job (Bent 1978; Ramirez and Alarcon 2004). In general, the evaluation 
process consists of the two stages of primary and final scoring. Primary scores are examined by 
field superintendents, while final scores are evaluated afterward by general contractor management. 
The difference between primary and final scores reflects evaluation perspective. While the 
subcontractor rating process does not embrace precise rules, it represents a coherent approach to 
problem solving rooted in intuition, experience and common sense rather than exploitable rules 
(Albino and Garavelli 1998). Due to the complexity of this approach, an alternative objective 
evaluation method is thus urgently needed for decision makers to make proper decisions. 
Sergio Maturana et al. (2007) developed an on-site evaluation method based on lean principles 
and partnering practices. Ekstrom et al. (2003) developed a tool to evaluate 
architecture/engineering/construction (AEC) bidders by calculating a weighted rating based on 
source credibility theory. Performance evaluation of subcontractors that fluctuates according to the 
changing environment is inherently complex and uncertain, and suffers from a lack of data 
completeness. Kumaraswamy and Matthews (2000) proposed a pro forma approach to assessing 
subcontractors that was constructed of eight items that included partnering experience, response to 
construction thoughts, quality awareness and so on. Subcontractors were subjectively evaluated and 
results obtained by multiple evaluator were averaged. 
     This validation exercise worked to show that the ESIM can assist general contractors to 
predict subcontractor performance so that they may make proper decisions to make optimal 
subcontractor choices and enhance project benefits.   
 26
Table 5.7 Influencing Factors for Performance Prediction of Subcontractor 
Factor no. Influence factor 
1 Construction technique 
2 Time control 
3 Cooperativeness 
4 Material wastage 
5 Services provided after completion of formal work tasks 
6 Collaboration with other subcontractors 
7 Safety and protection 
8 Tool usage habits (tools borrowed from contractor) 
9 Workspace cleanliness 
10 Management ability 
11 Subcontractor attitudes 
12 Financial status 
Collect Input and Test Patterns 
This study quotes historical subcontractor performance reported by Wu (2001).  The contractor, 
established in 1956, had a business focus on construction engineering, was ISO 9002 certified and 
was capitalized at around 11 million US dollars. The 34 subcontractor performances noted represent 
actual cases based on 14 subcontractors in Taiwan.  The 22 input patterns and 12 test sets are used 
to, respectively, evolve and validate the model.  Historical data are presented in Table 5.8. 
 28
Table 5.8 (Continued) Subcontractor Historical Data 
Sub 
contractor 
Contract no. Factor1 Factor2 Factor3 Factor4 Factor5 Factor6 Factor7 Factor8 Factor9 Factor10 Factor11 Factor12 Output
E 
Work_E_01 8 6 6 6 6 4 6 6 4 4 8 8 70 
Work_E_02 6 6 6 8 6 4 6 6 4 4 8 8 72 
Work_E_03 6 6 6 8 6 4 4 6 6 4 6 6 68 
Work_E_04 6 6 4 6 4 4 4 6 4 6 6 8 66 
F 
Work_F_01 6 6 6 6 4 4 4 4 4 6 6 8 62 
Work_F_02 6 6 6 6 4 4 6 4 4 4 6 8 66 
Work_F_03 6 6 6 6 4 4 4 4 4 4 6 6 60 
Work_F_04 6 4 4 4 6 4 4 4 4 6 6 6 58 
Work_F_05 6 4 4 4 4 4 4 4 4 4 6 6 56 
G 
Work_G_01 8 6 6 6 6 6 6 6 6 6 6 6 76 
Work_G_02 6 6 4 8 6 4 6 6 6 6 8 8 74 
Work_G_03 8 6 6 6 6 6 6 6 6 6 6 8 76 
Work_G_04 8 8 8 6 6 6 6 6 6 6 8 8 80 
Work_G_05 8 8 6 6 6 6 6 6 6 8 8 8 86 
Work_G_06 8 6 6 6 8 6 8 8 8 6 8 8 88 
H 
Work_H_01 8 8 8 8 6 6 6 8 6 8 8 8 86 
Work_H_02 8 8 6 6 6 6 6 6 6 6 8 8 80 
Work_H_03 8 8 6 6 6 6 6 6 6 8 8 8 80 
Work_H_04 8 6 6 6 6 6 6 6 6 6 8 8 76 
I 
Work_I_01 6 6 6 6 4 4 6 6 4 4 6 8 66 
Work_I_02 8 6 6 6 6 4 4 6 4 6 6 6 68 
Work_I_03 6 6 6 4 6 4 6 6 4 6 6 8 66 
Work_I_04 8 6 6 6 4 4 4 6 4 6 8 8 70 
Work_I_05 6 6 6 6 4 4 6 6 6 6 8 8 70 
Work_I_06 8 6 6 6 6 6 6 6 6 6 8 8 76 
 
 
 
 30
Table 5.9 Subcontractor Test Case 
Sub 
contractor 
Contract 
no. 
Factor1 Factor2 Factor3 Factor4 Factor5 Factor6 Factor7 Factor8 Factor9 Factor10 Factor11 Factor12 Output
N 
Work_N_01 6 6 6 6 6 4 6 6 6 4 8 6 66 
Work_N_02 6 6 6 6 6 4 4 6 6 6 6 6 68 
Work_N_03 6 8 4 4 4 4 6 6 4 4 6 8 66 
Work_N_04 6 6 4 6 4 4 4 6 4 6 8 8 66 
Work_N_05 6 6 6 6 4 6 6 6 6 6 6 6 70 
Work_N_06 8 6 6 6 6 6 6 6 6 6 6 6 76 
Work_N_07 6 6 4 8 6 4 6 8 6 4 8 8 74 
Work_N_08 6 8 6 8 6 6 6 6 6 6 6 8 76 
Work_N_09 6 6 6 6 6 6 6 6 6 6 6 8 76 
Work_N_10 8 8 6 6 6 6 6 8 6 6 8 8 80 
Work_N_11 8 8 6 6 8 6 6 8 6 6 8 8 86 
Work_N_12 8 8 6 8 8 6 8 8 8 6 8 8 88 
Preprocess Data 
Each item listed in Table 5.7 was scored as follows: excellent (8 points), good (6 points), normal 
(4 points), poor (2 points), and bad (0 points). Factors were scored by field superintendents during 
the construction phase. Fourteen subcontractors working for the general contractors were collected 
by Wu (2001), as shown in Tables 5.8 and 5.9. The final scores displayed in the last column were 
evaluated by general contractor management. Scores ranging from 56 to 88 are sufficient to cover 
most cases performed by subcontractors. 
Validate the Derived Solution 
ESIM captured the mapping between evaluation factors and subcontractor performance. The 
RMSE for 61 training patterns was 0.0475. The evaluation accuracy for 12 unknown cases is shown 
in Table 5.10. In the table, the ESIM accesses the performances of unknown projects with 0.0448 
RMSE when C equals 35 and gamma equals 0.0001, values which approximate final scores 
measured by managers. 
 32
Finite element analysis has previously been employed to simulate a braced diaphragm wall 
system (Clough and Hansen 1981; Powrie and Li 1991). However, results are heavily dependent 
upon the constitutive behavior of soil. As model parameters are usually obtained from laboratory 
tests, they are unable to fully represent in-situ soil properties due to sample disturbance, in-situ 
environmental conditions, the diverse effects of construction and so on. Feedback analysis is 
commonly applied to field measurements to determine soil parameters (Gioda and Sakurai 1987). 
Whitted et al. (1993) applied finite element analysis to model the top-down construction of a 
seven-story, underground parking garage at Post Office Square in Boston. By using optimization 
approaches, factors were modified to improve agreement with measured data without recourse to 
parametric iteration.  Ou and Tang (1994) proposed a nonlinear optimization technique to 
determine soil parameters for deep excavation finite element analysis and studied a hypothetical 
excavation case under a variety of ground conditions. Chi et al. (2001) obtained optimized 
parameters by applying an optimization technique for back-analysis that produced results in good 
agreement with field measurements. 
This validation aimed to show that the ESIM can assist planners to apply diaphragm wall 
deflection data previously compiled from 18 metropolitan Taipei projects to improve prediction 
result accuracy. 
6.5.2 Model Application 
Study Feasibility on the ESIM 
The ESIM is appropriate to predict diaphragm wall deflection in deep excavations for the 
following reasons:   
‧ The ESIM can represent complex input-output relationships.  The proposed model uses 
SVM to establish relationships between antecedences and consequences. By applying ESIM, 
a strict understanding of parameters or their effects is not required. The magnitude of 
deflection and the position where maximum displacement occurs in deep excavation 
diaphragm walls can, therefore, be predicted to ensure safety during the construction 
process.   
‧ The ESIM is able to search for the optimal solution automatically.  The proposed model 
evolves the optimal solution from input patterns by fmGA.  For that reason, the derived 
solution is able to adapt continuously to a changing environment.  This study applied 
diaphragm wall deflection data previously compiled from Taipei projects to the ESIM to 
improve prediction result accuracy.   
‧ The ESIM is able to incorporate experts’ knowledge and experience.  The model is 
 34
Figure 5.1 Representation of the Diaphragm Wall Structure 
Table 5.11 Patterns for Diaphragm Wall Deflection Prediction of Deep Excavations 
Factor 
no. 
Factors of Influence 
1 W Diaphragm wall thickness 
2 Hd Excavation depth 
3 N  Equivalent SPT-N value between H+0.25He and H-0.25He 
4 R Factor of an observation point factor interpolated linearly by its 
depth 
5 Di-1 Deflection of the observation point in the last stage, i.e., the 
(i-1)-th stage in the current i stage in excavation 
6 Di-2 Deflection of the observation point in the (i-2)-th stage 
7 Di-3 Deflection of the observation point in the (i-3)-th stage 
Output Di represents the deflection of the observation point in i-th stage.   
To prevent the absence of fifth to seventh inputs, i has to be greater than or equal to three. 
When i=3, the Di-3 is set as zero. 
Collect Input and Test Patterns 
Eighteen historical cases from metropolitan Taipei, Taiwan were collected. These cases are listed 
in Table 5.12, which provide information on number of excavation stages, excavation depth and 
construction method used (top-down or bottom-up). Number of stages in these cases varied from 
four to seven. As each stage was treated individually, these cases comprised 93 stages in total. 
Excluding the first and second construction stages allowed collection of 57 stages of valuable data. 
The first seventeen construction cases, including 52 stages in total, were used for training. The 
remaining five stages of the 18th case were employed in testing. Nineteen observation points were 
set, although excavation depths were not uniform. Therefore, 19 sets of data were collected at each 
stage.  Based on the above, 52×19 = 988 training data sets and 5×19 = 95 testing data sets were 
collected. 
 36
0
20
40
60
80
100
120
0 20 40 60 80 100 120
Maximum predicted diaphragm wall displacements (mm)
M
ax
im
um
 m
ea
su
red
 di
ap
hr
ag
m 
wa
ll d
isp
lac
em
en
ts 
(m
m) Training
Testing
 
Figure 5.2 Measured vs. Predicted Maximum Diaphragm Wall Displacements. 
The typical deep excavation project has many stages and the deflection observed in any given 
stage is highly correlated to deflection parameters in previous stages. Therefore, diaphragm wall 
deflection data from prior stages are important inputs to help predict the values of deflection 
variables in succeeding stages of an excavation project. As diaphragm deflections accumulate 
during an excavation, data from previous stages can be employed to predict deflection in the 
following stage with improved accuracy. Based on the above, project No. 18 data (shown in Table 
5.12) are treated as a new excavation project. In this project, the depth of the diaphragm wall was 
35 meters and total excavation depth measured 19.7 meters. Seven excavation stages were adopted 
as follows: 1st stage: 2.8 meters; 2nd stage: 4.9 m; 3rd stage: 8.6 m; 4th stage: 11.8 m; 5th stage: 
15.2 m; 6th stage: 17.3 m and 7th stage: 19.7 m.  Monitored data from preceding stages may be 
added to training data as a new excavation project progresses from stage to stage. 
For each excavation stage after the 2nd, data compiled from previous stages were added into the 
training data to reflect instantaneously the individual characteristics of this particular project. As 
shown in Table 5.13, this modified process helped reduce errors and improve accuracy. The 
modified process significantly improved ACCtesting compared to the previous result (from 0.8898 to 
0.8927). Detailed results on wall deflection at every stage are shown in Figure 5.3. According to 
results, the improvement works due to the addition of data from previous stages of the current 
project. Such data may be highly related to the prediction target based on a project’s discrete 
characteristics. 
 38
into multiple subcontracts. Large numbers of participants are, therefore, involved in project 
planning and implementation phases. The only way to ensure expectations are met is by conducting 
a comprehensive analysis of participants (Sanvido et al. 1992). Key measurements of project 
success in the construction industry include cost, schedule, performance and safety. Hughes et al. 
(2004) developed a Construction Project Success Survey instrument to identify important success 
metrics before the start of a project and evaluate the level of success achieved at project completion. 
Metrics measured by this instrument include both objective (e.g., cost, schedule, performance and 
safety) and subjective considerations. Griffith et al. (1999) developed an objective metrics covering 
the four variables of budget achievement, schedule achievement, design capacity and plant 
utilization. The authors discovered that, despite the complexities involved in measuring project 
success, a measurement can be developed based on objective project performance. Nguyen et al. 
(2004) uncovered success factors for large projects using factor analysis. A survey questionnaire 
was used to collect data from practitioners. These factors were grouped under the four categories of 
comfort, competence, commitment and communication. Based on the results of a mailed 
questionnaire survey, Chan et al. (2004) analyzed a set of success factors using factor and multiple 
regression analyses. Identification of success factors can help formulate effective strategies to 
minimize construction conflicts, while project performance can be improved by incorporating 
success factors into a research model to predict level of success. Parfitt and Sanvido (1999) 
proposed a checklist for building professionals to use as a guideline to predict project success. Items 
represented on the checklist include questions similar to those used initially to gather information 
for identifying critical project success factors. Chua et al. (1997) developed a predictive model of 
project success using neural networks to forecast construction project budget performance. Previous 
results in measuring and predicting project success show that measurements of project success are 
crucial to control projects in order to achieve project objectives. In addition, statistical methods 
provide a theoretical basis for analyzing factors of project success from questionnaire surveys and 
collected data.  
However, previous research into predicting project success either adopted fixed factors at various 
points in time or used an inference method.  These approaches present several important 
difficulties that render them inadequate for general application. The construction industry is replete 
with myriad uncertainties that make management exceedingly complex. Factors for success, 
therefore, vary from project to project. Although human experts can often achieve a satisfactory 
project outcome, shortfalls nearly always occur due to managers failing to take all relevant factors 
into consideration and lacking access to all relevant information.   
The objective of this validation was to develop a dynamically predictive methodology using 
ESIM.  Once developed, project mangers should be able to employ this methodology to make 
appropriate decisions regarding project control in real time.   
6.6.2 Model Application 
 40
A threshold level of significance must be selected to identify factors of greatest significance. 
CAPP recommends identifying a referenced factor as a factor with an attached alpha of less than 0.1. 
In this paper, the alpha threshold was set at less than 0.025 to reduce the quantity of identified 
factors.  CAPP defines four degrees of project success, including “successful”, “on time or on 
budget”, “less than successful”, and “disastrous” (Russell et al. 1997) (see Table 5.14). 
Table 5.14 Project Assessment for Dynamic Prediction of Project Success 
No. Project performance 
1 Successful 
2 On time or on budget 
3 Less than successful 
4 Disastrous 
CAPP can calculate significant factors sequentially and then analyze those factors (see Figure 
5.4). 
 
Figure 5.4 CAPP Graphics for Cost of Change Orders 
The histogram in CAPP Graphics shows a level of significance that achieves a high degree of 
effectiveness at low quantity levels. With project progress set at 67%, the histogram value is 
approximately 0.02 (below the threshold 0.025), identifying “cost of change orders” as a significant 
factor in this study. A total of 11 factors significant to project success were identified (see Table 
5.15). 
 42
8 0.185 0.987 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.333 
9 0.111 0.000 1.000 0.228 1.000 0.000 0.000 0.000 0.000 0.000 0.000 1 
10 0.148 0.000 0.773 0.000 0.000 1.000 0.000 0.000 0.076 0.033 0.000 0.667 
11 0.000 0.000 0.127 0.000 0.000 0.165 0.000 0.000 0.009 0.000 0.000 0.667 
12 0.000 0.000 0.164 0.000 0.000 0.223 0.000 0.000 0.033 0.100 0.125 0.667 
13 0.000 0.000 0.000 0.000 0.020 0.026 0.000 0.000 0.045 0.011 1.000 0 
14 0.000 0.000 0.000 0.000 0.000 0.067 0.000 0.000 0.005 0.056 0.000 1 
15 0.000 0.000 0.000 0.056 0.006 0.167 0.000 0.000 0.107 0.078 0.246 0 
16 0.037 0.266 0.000 0.000 0.188 0.451 0.116 0.000 0.000 0.000 0.020 0.667 
17 0.000 0.000 0.000 0.042 0.000 0.099 0.000 0.000 0.008 0.000 0.622 0.667 
18 0.000 0.000 0.109 0.000 0.061 0.080 0.000 0.000 0.000 0.000 0.000 0.667 
19 0.000 0.000 0.457 0.000 0.404 0.592 0.000 0.000 0.334 0.111 0.300 1 
20 0.000 0.710 0.000 0.000 0.448 0.000 0.000 0.000 0.023 0.000 0.000 0.667 
21 0.000 0.159 0.000 0.000 0.051 0.000 0.000 0.000 0.000 0.000 0.000 0.667 
Table 5.16 (Continued) Patterns for Dynamic Prediction of Project Success (CAPP® Database 
Shown and Reused with CII’s Kind Permission) 
Input patterns 
Pattern no. 
Input Output
1 2 3 4 5 6 7 8 9 10 11 12 
22 0.000 0.000 0.118 0.150 0.154 0.135 0.000 0.000 0.251 0.456 0.861 0.000 
23 0.000 0.000 0.000 0.048 0.000 0.000 0.022 0.000 0.043 0.144 0.000 1 
24 0.000 0.000 0.211 0.050 0.418 0.188 0.394 0.000 0.000 0.000 0.000 1 
25 0.444 0.511 0.000 0.000 0.000 0.000 0.995 0.000 0.000 0.011 0.000 1 
26 0.296 0.031 0.726 0.000 0.318 0.026 0.010 0.000 0.024 0.033 0.000 0.667 
27 1.000 0.000 0.021 0.233 0.021 0.027 0.000 0.864 0.145 0.000 0.021 1 
28 0.000 0.143 0.029 0.000 0.044 0.000 0.000 0.000 0.000 0.000 0.000 0.667 
29 0.000 0.123 0.123 0.000 0.025 0.000 0.000 0.000 0.000 0.000 0.000 1 
30 0.444 0.058 0.033 0.000 0.027 0.000 0.000 0.000 0.000 0.000 0.000 1 
32 0.000 0.007 0.000 0.009 0.010 0.003 0.019 0.000 0.025 0.067 0.000 1 
33 0.000 0.111 0.045 0.000 0.021 0.000 0.140 1.000 0.042 0.067 0.013 1 
34 0.000 0.926 0.498 0.000 0.000 0.000 0.581 0.000 0.179 0.267 0.180 1 
35 0.000 0.148 0.035 0.000 0.000 0.029 0.029 0.000 0.141 0.156 0.000 0.333 
37 0.000 0.149 0.085 0.000 0.000 0.108 0.108 0.000 0.113 0.944 0.000 1 
 44
Testing Case Pattern no. Predicted Output Desired Output Training RMSE 
1 22 0.0978  0.0000  
0.1781  
2 31 1.0527  1.0000  
3 36 0.6347  0.3330  
4 41 0.8199  0.6670  
K-means clustering is a multi-variable analysis data clustering method that aggregates similar 
data and identifies discrepancies between clustered categories. CAPP database data used in this 
study were gathered from different construction companies and vary in terms of project attributes 
(e.g., type of construction, cost, procurement approaches, etc.) To improve assessment accuracy, 
K-means clustering was used prior to ESIM learning to collate training datasets that were most 
similar to the assessment target. SPSS, a commercial statistics software package, was the tool used 
to conduct K-means clustering analysis for this purpose. After the cluster number had been set, each 
cluster center iterated toward the fittest location by Euclidean distance measurement. Cluster 
number was chosen as 2 to represent positive and negative qualities. Four testing datasets (CS1, 
CS2, CS3, and CS4) were treated as clustering targets. For CS2, K-means clustering was employed 
for the 42 training datasets and CS2. Clustering results are shown in Table 5.19, where CS2 is 
attached to cluster 2, which has 17 datasets. Similarly, there were 25 training cases for CS1, 26 for 
CS3, and 17 for CS4. In other words, for each new project assessment, K-means clustering was 
applied to the 42 training projects as well as the new one with 2 cluster sets. Thus, SPSS generated 
2 cluster centers. Finally, datasets in which the new project had been clustered were treated as 
training data (part of 42 training projects, without the new one) for sequential ESIM learning to 
assess new project performance. The reason for setting 2 sets of clusters was to avoid having an 
overly small number of projects for ESIM learning. Therefore, the selected number of clusters could 
be increased if the data pool in other studies was sufficiently large. In summary, time-dependent 
factors were not the only factors that changed dynamically with CAPP analysis. Training datasets 
also varied for different project performance assessment targets with K-means clustering.   
Table 5.19 Results of K-means Clustering 
 Initial Cluster Centers Final Cluster Centers 
 Cluster Cluster 
Variable 1 2 1 2 
C5_16 1.000  0.000  0.087  0.122  
C3_10 0.000  1.000  0.088  0.472  
C2_14 0.021  0.327  0.055  0.379  
C2_13 0.233  0.000  0.102  0.090  
C3_28 0.021  0.675  0.028  0.292  
 46
Table 5.20 Comparisons of Performance Assessment Results for K-means Clustering 
 Testing Case Predicted Output Desired Output Training RMSE 
Without  
K-means 
Clustering  
1 0.0978  0.0000  
0.1781   
2 1.0527  1.0000  
3 0.6347  0.3330  
4 0.8199  0.6670  
With  
K-means 
Clustering 
1, CS1 0.0083  0.0000  
0.0071 
2, CS2 0.9932  1.0000  
3, CS3 0.3237  0.3330  
4, CS4 0.6678  0.6670  
 
7. Conclusion 
Two steps were used to validate research hypotheses: (1) analyze ESIM mechanism using a 
theoretical approach and (2) compare analyzed results with model experiments.  Conclusions 
follow:   
fmGA can concurrently search for optimal parameters required for the SVM. 
The ESIM was able to use fmGA to search concurrently for optimal parameters required in the 
SVM. 
By fusing fmGA and SVM, domain knowledge and experience may be acquired and accumulated 
for problem solving. 
This research fused fmGA and SVM to develop the ESIM.  In the formulated model, the fmGA 
and SVM were primarily concerned, respectively, with optimization and input-output mapping.  
SVM stored domain knowledge and experience using a prediction model to represent complex 
antecedence and consequence relationships.  The ESIM used fmGA to optimize SVM parameters 
from input patterns (real word data).  Therefore, the ESIM was able to acquire and accumulate 
domain knowledge and experience automatically.  In the model validation section, the ESIM 
derived dissimilar SVM parameters for different input patterns and distinct problems.  Validation 
results prove that the ESIM can acquire and accumulate domain knowledge and experience.  In 
construction management applications, users can reuse derived knowledge and experience to solve 
practical problems. 
A relatively accurate inference result can facilitate decision-making in construction management. 
Proper decision-making relies on correct information.  A relatively accurate inference result 
 48
[17] D.E. Goldberg, K. Deb, B. Krob, Don’t worry, be messy, Proceedings of the Forth 
International Conference on Genetic Algorithms and their Applications, San Diego, USA, pp. 
24– 30, 1991. 
[18] Hsu, C. W., & Lin, C. J., A simple decomposition method for support vector machine, Machine 
Learning, vol. 46(1–3), pp. 219–314, 2002. 
[19] Larman, C., Applying UML and patterns: an introduction to object-oriented analysis and 
design, Prentice Hall PTR, Upper Saddle River, New Jersey, 1998. 
[20] Satzinger, J. W., Jackson, R. B., and Burd, S. D., System Analysis and Design in a Changing 
World, Course Technology, Cambridge, Massachusetts, pp. 67-75, 2000. 
[21] D’Souza, D. F., and Wills, A. C., Objects, components, and frameworks with UML: the 
catalysis approach, Addison-Wesley, Reading, Massachusetts, 1999. 
[22] Booch, G., Object-oriented analysis and design with applications, 2nd Ed., Benjamin, 
Redwood City, California, 1994. 
[23] Jacobson, I., The road to the unified software development process, Cambridge University 
Press, Cambridge, United Kingdom, pp. 103-108, 2000. 
 
國科會補助計畫衍生研發成果推廣資料表
日期:2011/08/09
國科會補助計畫
計畫名稱: 演化式支持向量機推論系統-應用於營建管理之決策
計畫主持人: 鄭明淵
計畫編號: 97-2221-E-011-126-MY3 學門領域: 營建管理
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
