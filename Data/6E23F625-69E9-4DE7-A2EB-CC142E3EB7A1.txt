in the FPGA by using the training data which is also 
built in the memory of the FPGA. Then the weights of 
the neural network could be adjusted to provide 
better performance. 
英文關鍵詞： Eye-robot, stereo matching, Hopfield neural network, 
genetic algorithm 
 
 2 
常仿人類視覺系統具有兩個攝影機，而可
以從不同角度得到影像。此系統又分為主
動式與被動式立體視覺，其中被動式立體
視覺已被廣泛研究以及應用[2], [3]。主要
利用視差(disparity)來偵測一個物體或者一
個點的深度，所謂視差乃由不同攝影機擷
取相同物體的影像所構成，而其在不同影
像的位置資訊差異即為視差，可由三角定
位法(triangulation principle)[4]取得三維的
深度資訊。一旦雙眼視覺擷取到雙眼影
像，在取得視差的過程當中，最為困難以
及耗時的部份在於影像特徵點的匹配，也
就是如何從左邊影像特徵點當中，找出與
右邊影像對應的特徵點，這也就是所謂的
立 體 視 覺 對 應 問 題 (stereo matching 
problem)，而本研究將基於類神經網路與基
因演算法，開發有效且有智慧的立體視覺
對應系統。 
目前探討立體視覺對應的研究當中，
主要可分為兩大類：基於區域之方法
(area-based method)[5]-[7]，基於特徵之方
法(feature-based method)[8]-[11]。基於區域
之方法通常利用固定尺寸的視窗來計算兩
張影像的相關程度，其計算量相當龐大。
而基於特徵之方法採用特徵抽取來搜尋影
像當中主要的元件，例如：線段、角落、
輪廓等，此法之計算量就相對減少許多，
也因此廣為研究。一般而言，基於特徵之
方法採用以下步驟：影像擷取、特徵抽取、
影像匹配、深度偵測。 
近年來，許多研究者已經提出使用霍
夫菲爾網路(Hopfield neural networks)來解
決立體影像對應問題。主要將對應問題轉
換為最佳化問題，把所有的限制條件轉換
成網路中的目標函數。霍夫菲爾網路採用
能量函數的概念解決最佳化問題[12]。在很
多霍夫菲爾網路應用當中，首先建構能量
函數來表達問題的限制條件，而霍夫菲爾
網路利用調整神經元的狀態來尋找能量的
最低點，也就是最佳解的位置。在文獻當
中，研究者使用相似性、順滑性以及唯一
性來建構類比霍夫菲爾網路的能量函數
[13]。另有研究者利用多重類比霍夫菲爾網
路來解決即時障礙物偵測的應用[14]。有研
究者提出採用唯一性、順滑性、幾何限制
來對應特徵點[14]。文獻[15]在[14]的能量
函數中加入相似性，用以提高對應正確率。 
 根據上述的文獻，本計劃將採用基於
特徵之方法，增加運算之效率與速度，首
先擷取灰階的雙眼影像，利用哈利士角落
偵測器 (Harris corner detector)萃取特徵
點，由於離散型霍夫菲爾網路計算較為簡
單，所以採用離散型霍夫菲爾網路作為立
體視覺對應的基礎，也將改善[14]與[15]計
算較慢的缺點，提升對應的準確性。 
II. 智慧型立體視覺對應 
本計劃在立體視覺對應部分，結合霍夫
菲爾網路與基因演算法，經由機器人擷取雙
眼影像，並採用哈利士角落偵測器萃取特徵
點，再設計霍夫菲爾網路的能量函數，以建
立正確的立體視覺影像對應，並精確計算視
差。本計劃採用霍夫菲爾網路的神經元輸出
為對應的解，其流程圖如圖 1 所示，首先萃
取雙眼影像的特徵點，再搜尋可能的匹配
對，且設定神經元的輸出，接下來進入更新
網路的步驟，首先隨機選取可能的匹配對，
再找出鄰近的匹配對，接著利用鄰近批配對
的資訊更新神經元，按照此流程，將可以找
出正確的匹配對。為了搜尋匹配的對應特徵
點，本計劃採用二維霍夫菲爾網路，其中一
個維度的輸入為左眼影像的特徵點，另一個
維度的輸入為右眼影像的特徵點，每個神經
元都有來自於這兩個維度的輸入，以及跟其
他神經元的鏈結，每個神經元的輸出，即代
表左右眼特徵點的對應關係，若神經元 nik
的輸出為 1，則代表左眼第 i 個特徵點與右
眼第 k 個特徵點是對應的，反之則異。 
基於上述的概念，本計劃首先建構一個
Nl×Nr 的霍夫菲爾網路，其中 Nl 與 Nr 分別
代表左眼與右眼的特徵點數量，接著設計一
個適合的能量函數，首先是唯一性，基本上
此系統假設每個特徵點最多只能有一個對
應關係，亦即左右眼影像的特徵點最多是一
對一的對應，根據這個概念，唯一性的能量
函數可設計為 
 
2 2
1
1 1 1 1
(1 ) (1 ) .
l lr rN NN N
ik ik
i k k i
E y y
= = = =
= − + −∑ ∑ ∑ ∑  (1) 
對於每張圖的一個特徵點，在另一張圖的
總和預期小於等於 1，使得此能量函數可達
到最小值。 
 4 
上述的霍夫菲爾網路仍有θc λc θs λs 四
個參數需要設計，為了有效率地設計參
數，本計畫採用基因演算法，除了藉由設
計霍夫菲爾網路的能量函數之外，本計劃
也預期採用基因演算法最佳化霍夫菲爾網
路，其流程如圖 2 所示，首先給定一群個
體，也就是一群霍夫菲爾網路，再計算每
個網路的適應值(fitness)，計算適應值的過
程，將給定一對訓練圖樣(Training image)，
也就是一組已知對應關係的雙眼影像，待
霍夫菲爾網路穩定後，即可知道該網路在
對應關係的正確率，此即為該網路的適應
值，接著根據適應值挑選母代的個體，執
行交配(crossover)以及突變(mutation)，即可
產生子代，在計算子代的適應值後，母代
與子代競爭，存活的個體即可進入下一
代。這樣的流程將一直執行，直到搜尋到
最佳的霍夫菲爾網路。 
III. 嵌入式系統 
在嵌入式系統部分，本計畫研發具有學
習能力的類神經網路硬體架構，將其應用於
影像邊緣偵測與膚色擷取，此架構提供應用
與學習兩種操作模式，分別用於類神經網路
之前饋運算與權重值之學習。在應用模式方
面，採用單層多工(layer multiplexing)的方
法，藉由重複使用單一神經層來達成多層的
運算。 
本計畫使用 Altera 的 FPGA 平台，此
FPGA 有許多外部功能，如 SDRAM、
SRAM、以及 RS232。其規格為 68,416 Les、
250 M4K RAM blocks、1,152,000 total RAM 
bits、150 embedded multipliers。 
本計畫設計的類神經網路架構稱為
Learning On Chip Artificial Neural 
Network(LOCANN)，其硬體分成六個區塊
[17] ， ANN Unit(ANNU) 、 Learning 
Unit(LU) 、 Weight Array Unit(WAU) 、
Pattern-Target ROM(PTR)、UART、以及
Main Controller(MC)，如圖 3 所示。ANNU
與 LU 為 LOCANN 的重要區塊，分別用於
前饋計算與權重值的學習。WAU 用來儲存
網路架構的權重值，PTR 為儲存訓練類神
經網路所需要的樣本，UART 則是用來與電
腦溝通、傳遞資料，而 MC 為整個架構的
核心，主要功能為協調網路的運作。 
ANN
Unit
Learning
Unit
Main
Controller
WAU
Pattern
Target
ROM
clk
en
mode
Go_NN
NNDone
start
Rdone
Go_learn
learndone
OUTPUT
UART
TXD
RED
 
圖 3.立體視覺對應訓練結果 
IV. 實驗結果 
在立體視覺對應的實驗部分，首先在
室內場景擷取雙眼影像，經由哈利士角落
偵測器，萃取影像中的特徵點，如圖 4 所
示，+號代表擷取到的特徵點。其中[19]的
方法(簡稱 SMA)的對應結果如圖 4 (a1-a2)
所示，而圖 4(b1-b2)為本計劃提出的方法但
不採用垂直視差(簡稱 SMAWVD)，而本計
劃提出的方法(簡稱 SMAVD)的對應結果
如圖 4(c1-c2)所示，為了更容易分析其對應
的結果，圖 4(a3,b3,c3)表現其對應後的視
差，其中 L 跟 R 分別表示左右圖相對應的
特徵點的位置，從圖 4 (a3)可以知道 SMA
的對應結果中，正確的匹配對擁有一致的
視差方向，而錯誤的匹配對則不同，如匹
配對 1 和 7。而且匹配對 1 不只方向不同，
就連視差長度也不一樣。反觀圖 4(b3)，
SMAWVD 雖然不含垂直視差比對，但匹
配的正確率可大幅提高，縱使匹配對 6 仍
然是錯誤的。而圖 4(c3)表示 SMAVD 透過
基因演算法搜尋霍夫菲爾網路的參數後，
可以達到 100%的正確率。表 1 分析了三種
方法的數據，其中 CMP 代表正確的匹配
率，雖然 SMA 需要較少的迴圈數讓能量收
斂，可是 SMAVD 可以用更短的計算時間
達到更高的 CMP，這是因為 SMAVD 採用
的相似性以及順滑性計算時間較少，且使
用了垂直視差來減少錯誤的匹配對，也利
用基因演算法加強霍夫菲爾網路的穩健
性。為了更進一步分析由基因演算法搜尋
的參數是否也適用於其他室內環境影像，
採用四組室內環境的雙眼影像作為測試
組，如圖 4 所示，其測試結果數據分析如
表 2 所示，由表 2 可知道 SMAVD 的 CMP
 6 
Reference: 
 
[1]  Y. Wu and T. S. Huang, “Hand modeling 
analysis and recognition for vision-based human 
computer interaction,” IEEE Signal Process 
Mag.—Special Issue on Immersive Interactive 
Technology, vol. 18, no. 3, pp. 51–60, 2001. 
[2]  N. Badler, “Temporal Scene Analysis - 
Conceptual Descriptions of Object Movements,” 
Report TR 80, 1975. 
[3]  R. Brooks, “Symbolic reasoning among 3D 
models and 2D images,” Artificial Intelligence, 
pp. 285-348, 1981. 
[4]  K. Nishihara and T. Poggio, “Stereo vision for 
robotics,” Proc. Robotics Research, First Int. 
Symp. , pp. 489–505, 1984. 
[5]  D. J. Kriegman, E. Triendl and T. O. Binford, 
“Stereo vision and navigation in buildings for 
mobile robots,” IEEE Trans. Robotics and 
Automation, vol. 5, No. 6, 1989. 
[1] D. Murray and J. J. Little, “Using real-time 
stereo vision for mobile robot navigation,” 
Autonomous Robots, vol. 8, No. 2, pp. 161–171, 
2000. 
[2] M.Bertozzi and A. Broggi, “GOLD: A parallel 
real time stereo vision system for genetic 
obstacle and lane detection,” IEEE Trans. 
Image Processing, vol. 7, pp. 62-81, Jan. 1998. 
[3] L. Zhao, and C. E., Thorpe, “Stereo  and 
Neural  Based Pedestrian Detection,”  IEEE 
Trans. Intelligent Transportation Systems, Vol. 
1, No. 3, pp. 148–154, Sep. 2000. 
[4] W. Y. Yau and H. Wang, “Fast Relative Depth 
Computation for an Active Stereo Vision 
System,” Real-Time Imaging, vol. 5, No. 3, 
pp.189 202, June, 1999.  
[5] G. Medioni and W. H. Tsai, “Segment based 
stereo matching,” Computer Vision Graphics 
Image Process, Vol. 31, pp. 2 18, 1985.  
[6] Y. Shirai, Three Dimensional Computer 
Vision, Springer Verlag, New York, 1987.  
[7] J. J. Lee, J. C. Shim and Y. H. Ha, “Stereo 
correspondence using the Hopfield neural 
network of a new energy function,” Pattern 
Recognition vol. 27, No. 11, pp. 1513 1522, 
Nov. 1994. 
[8] W. E. L. Grimson, “Computational experiments 
with a feature based stereo algorithm,” IEEE 
Trans. Pattern Anal. Mach. Intell. , vol. 
PAMI 7, pp. 17 34, 1985.   
[9] G. Medioni and R. Nevatia, “Segment based 
stereo matching,” Comput. Vision Image 
Processing, vol. 31, pp. 2 18, 1985.  
[10] T. Ozanian, “Approaches for stereo matching – 
A review,” Modeling Identification Control, vol. 
16, pp. 65-94, 1995. 
[11] G. Pajares and J. M. Cruz, “Local stereovision 
matching through the ADALINE neural 
network,” Pattern Recognition Letters, vol. 22, 
pp. 1457 1437, 2001.  
[12] J. Hopfield, and D. W. Tank, “Neural 
computation of decisions in optimization 
problems,” Biological Cybernetics, Vol. 52, pp. 
141 152, 1985.  
[13] G. Pajares, J. M. Cruz and J. Aranda, 
“Relaxation by Hopfield network in stereo 
image matching,” Pattern Recognition, vol. 31, 
No. 5, pp. 561 574, 1998.  
[14] Y. Ruichek, “Multilevel- and 
Neural-Network-Based Stereo-Matching 
Method for Real-Time Obstacle Detection 
Using Linear Cameras,” IEEE Trans. Intelligent 
Transportation Systems, Vol. 06, No. 1, pp. 
54 – 62 , Mar. 2005. 
[15] N. M. Nasrabidi and C. Y. Choo, “Hopfield 
network for stereovision correspondence,” IEEE 
Trans. Neural Network, Vol. 03, No. 1, pp. 
123 135, Jan. 1992.  
[16] K. Achour and L. Mahiddine, “Hopfield Neural 
Network Based Stereo Matching Algorithm,” 
Journal of Mathematical Imaging and Vision, 
Vol. 16, No. 1, pp. 17 29, Jan. 2002.  
[17] A. R. Omondi, and J. C. Rajapakse, FPGA 
implementation of neural network: Springer, 
2006. 
[18] S. Himavathi, D. Anitha, and A. 
Muthuramalingam, “Feedforward neural 
network implementation in FPGA using layer 
multiplexing for effective resource utilization,” 
IEEE Trans. on Neural Networks, vol. 18, no. 3, 
pp. 880-888, 2007. 
[19] S. H. Yang, C. Y. Ho and Y. P. Chen, 
“Intelligent stereo matching algorithm based on 
Hopfield neural network and genetic algorithm,” 
Far East Journal of Experimental and 
Theoretical Artificial Intelligence, vol. 6, no. 
1-2, pp. 1-23, 2011. 
[20] S. H. Yang, C. Y. Ho and Y. P. Chen, “Neural 
network based stereo matching algorithm 
utilizing vertical disparity,” in Proc. of the 36th 
Annual Conf. of the IEEE Industrial Electronics 
Society, IECON’10, pp.1149-1154, 2010. 
 8 
可供推廣之研發成果資料表 
日期：100 年 10 月 14 日 
國科會補助計畫 計畫名稱： 
自走式仿人眼機器人之立體影像對應與類神經網路控制器之研發 
計畫主持人：陳永平 
計畫編號：NSC 99-2221-E-009-107 
學門領域：控制學門 
技術/創作名稱 自走式仿人眼機器人之立體影像對應與類神經網路控制器 
發明人/創作人 陳永平 
技術說明 本技術研發自走式仿人眼機器人之立體視覺影像對應，用以計算雙眼
影像的視差。本計劃結合霍夫菲爾網路與基因演算法解決此對應問
題，實現的方法是藉由雙眼攝影機從室內場景擷取影像，採用哈利士
角落偵測器萃取特徵點，再設計霍夫菲爾網路的能量函數，由於能量
函數的設計是網路的關鍵技術，現有文獻提出的能量函數運算時間較
長且對應結果的正確率不高，因此本計劃分析立體視覺影像的特性，
設計低運算量且高性能的能量函數，使得霍夫菲爾網路可以建立正確
的立體視覺影像對應，而為了有效設計霍夫菲爾網路，本計畫結合基
因演算法來最佳化網路，使得立體視覺影像對應的正確率大幅提升，
可精確地計算視差。為了建構低耗能、低成本的運算器，目前利用
FPGA 實現類神經網路，而類神經網路的學習法則以及儲存訓練資料
的記憶體也規劃於此 FPGA 當中，使得類神經網路可調整其權重值，
提供更好的運算能力。 
可利用之產業 
及 
可開發之產品 
1. 以霍夫菲爾網路為基礎，配合基因演算法之技術，使用雙眼機器
人，設計出一穩健且高正確率之立體視覺對應系統。 
2. 以 FPGA 為基礎，以單層多工的技術，設計出一擁有兩層隱藏層、
16 顆神經元的類神經網路。 
技術特點 1. 在學術研究方面，整合霍夫菲爾網路與基因演算法，提高立體視覺
對應的穩定性與正確率。 
2. 在實際應用方面，縮短對應所需的運算時間，使此對應系統可應用
於雙眼機器人於環境偵測之應用。 
推廣及運用的價
值 
 
 
    本研討會的主軸在於工業電子的設計與應用，其中包含了相當多機器人領域
的研究，與本人的研究領域相符，因此藉這機會觀摩其他機器人的研究領域，例
如控制、機器視覺、人工智慧等研究。在機器人與人工智慧的報告當中，很多作
者嘗試利用人工智慧解決控制器與濾波器的設計問題，因此有機會在這個研討會
了解大家常用的方法以及思考的路徑。 
    這次研討會有眾多國內頂尖的學者參加，本人在研討會遇到宋開泰老師以及
羅仁權校長，他們分享參與國際研討會的經驗，了解到學術研究的歷程以及籌備
研討會的必要性，從他們身上學習到許多知識，相當值得。 
二、與會心得 
 很高興能參與這次學術的盛會，不僅可以現場聆聽作者們的報告，也可以現
場提問，更深入了解該作者的想法。在這我要感謝我的指導老師陳永平教授，在
平常的例行會議，要求我們以英文報告，而且鼓勵我們提問，來到這裡，我才發
現，提問是一個相當大的學問，也需要勇氣，在這研討會中，唯有透過提問，才
能要求自己充分掌握作者的報告，小小的提問對作者而言，也是一種鼓勵，讓他
知道現場的觀眾努力在聽。 
在研討會中，我們也遇到浙江大學、杭州大學的學生，他們僅是大學部的學
生，但已經能夠撰寫國際研討會論文，站上國際舞台，甚而國際頂尖研討會，由
此可見他們在學術領域的蓬勃發展，讓我了解到我們正在跟全世界接軌與競爭，
從他們的談吐中，我發現我們要面對的不是只有國內的各大學，而是全球的大
學，這也應證了老師在課堂上提的：我們跟旁邊的同學要合作，而不是競爭，要
競爭的對象是全世界的人。 
由於會議舉行在美國鳳凰城，不僅報告需要使用英文，生活也需要英文，人
在國外，特別感受到英文聽與說的重要性，在這裡重要的是敢不敢講，就算英文
程度不好，也要勇敢開口說，表達自己的權利，我想這是最重要的，也感謝我的
指導老師平常訓練我們用英文報告，增加聽與說的能力。 
感謝國科會提供經費讓我們可以參與頂尖國際研討會，不僅開闊眼界，也學
習別人的做事方法。 
 
三、考察參觀活動(無是項活動者省略) 
 
四、建議 
 
五、攜回資料名稱及內容 
1. 論文摘要集 
2. 論文全文電子檔 
99 年度專題研究計畫研究成果彙整表 
計畫主持人：陳永平 計畫編號：99-2221-E-009-107- 
計畫名稱：自走式仿人眼機器人之立體影像對應與類神經網路控制器之研發 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 1 1 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 3 3 100%  
博士生 1 1 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 1 1 100%  
研究報告/技術報告 0 0 100%  
研討會論文 1 1 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
