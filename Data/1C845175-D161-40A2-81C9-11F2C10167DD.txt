1摘要
在本研究中，研製的影像式地滑監測系統，藉由「機械視覺」(Machine Vision)的原理辨識地滑。研
究在各種情況之下，僅以單一影像畫面，藉由數位影像處理(Digital Image Processing)的方法辨識地滑是
否發生，就能實現非接觸式地滑監測的功能。監測設備為一雷射投射器與自製量測箱體，將雷射投射器
設置於不動點，量測箱體設置於待測點，監測原理乃以雷射光束投射至待測面上，經過垂直校正之後，
在影像畫面中只會產生一投射亮點。當地滑發生時，雷射與量測箱體偏移產生角度，在影像畫面中即產
生兩投射亮點。經由辨識影像畫面中兩亮點之間的像素值，將判斷結果代入本文中所提出的公式計算，
即可得知位移量與位移角度。本系統提出的量測方法，將可量測傾斜面上任一兩點的距離及傾斜面與雷
射之間的角度，根據監測系統的分析，研判是否需要對大眾發布警報，以減少生命財產損失。
關鍵字:地滑監測系統、機械視覺、雷射投射器、數位影像處理。
Abstract
A novel image-based landslide monitoring system proposed in this paper. This research focus on in any
conditions by using one single image through digital image process to detect landslide occurred or not, and to
realize a non-contact landslide monitoring system. The equipments of this system include: a high power laser
projector and a measurement box, setup high power laser projector in“fixed point”and setup the measurement
box in“test point”. The laser projector generates a laser spot on measurement board; after adjust the vertically
and horizontally correcting technology, there is only a single laser spot generates in image. When landslide
occurred, the measurement box and laser projector will create an offset angle, it will produce two laser spots in
image. When it produce two laser spots, identify the pixel numbers between two laser spots and calculate by
equation from this paper, it accomplished the displacement. The system can decide to alarm or not according
by the analysis result.
Keyword: Landslide Monitoring System, Machine Vision, Laser Projector, Digital Image Process.
1. 簡介[1]-[15]
台灣地處歐亞板塊與菲律賓板塊的交界處，板塊運動激烈，為地質構造活躍地區，因此地震發生的
頻率密集與頻繁。又台灣地形狹窄山多加上是海島型氣候多雨，往往當有一場大雨、梅雨季或是夏季颱
風就會造成山崩、走山、土石流…等的自然災害。
每年夏、秋兩季平均都有三到四個颱風侵襲臺灣，颱風為台灣提供了充沛的水分，但由於降雨空間
和時間分佈十分不均，容易引發洪水與土石流等災害，不僅天氣變化詭譎、地質鬆散，再加上都市人口
成長迅速，不僅都市土地不夠用，連郊區範圍都已過度開發進而朝山坡地進行開墾，造成坡地開發過度，
雖然政府已投入大量的人力、物力進行保持，但是破壞的速度總是超過了保護的速度，因此每當自然災
害發生時，總是伴隨著許多的地表破壞、人民生命財產嚴重的身心靈傷害或財務上的損失。
1644 年後的 250 年間，被稱為研究地震史的一個階段，這階段各種地震情形被記錄於書中，其內
容記載均極簡單，且於地震強弱之敘述僅憑人身之感覺及個人觀察所得，是一種客觀的感覺且十分的不
精確的紀錄。；日治時期，全台各大城市於此後陸續設立測候所，並啟用葛芮米爾式（Grag-Milus type）
地震儀，1896 年以後迄今，台灣地震情形因有儀器觀測而益趨明瞭，這之間，由於科學進步，各測候
所使用之儀器亦迭次更替為較精密者。計 1928 年起，台灣已擁有倍率較大之「威豪爾」（Wiechert）式
地震儀；1935 年（民國 24 年）新竹、台中烈震（中部大地震）後，又增添若干新式地震儀並增設新竹
測站；1951 年（民國 40 年）花蓮烈震後，各主要測候所又增設加速度地震儀，以配合地震工程之研究；
1963 年（民國 52 年）增設世界標準地震儀於中央氣象局大屯山鞍部測候所，此種地震儀包括三成分長
3的傳輸，故能長期全域地滑位移量與地滑方向及偏移角度紀錄，預判發生地滑的區域。以利及早發佈地
滑警戒資訊，爭取更多進行疏散或管制的時間，使地滑的災害減到最低，來保障人民的安全。以下為目
前現有的監測設備之簡介:
台灣擁有多元的自然氣候及各種地形的高密度開發國家，為了避免人民因天災所受的損失，針對大
地監測有著大量的研究，針對目前各項研究計畫中所使用的地滑監測設備，大都使用 TDR 及地表伸縮
計，目前使用於大地監測設備可分為下列三大項:
I. 水文監測:
1. 水位觀測井:測量水位變化，如圖(2) 所示。
2. 雨量計:測量降雨的多寡，如圖(3)所示。
3. 流量計:測量液體流量的大小，如圖(4)所示。
4. 水位計:監測水位的高低，如圖(5)所示。
圖(2)水位觀測井 圖(3)雨量計
圖(4)流量計 圖(5)水位計
II. 地層穩定性監測:
1. 地表沉陷點:地表垂直的變化監測
2. 地表伸縮計:地表水平的變化量監測，如圖(6)所示。
3. 傾斜觀測管:地層滑動點的位移、速度、深淺的監測，如圖(7)所示。
5備，使得攝影機並不只是用來監視，也可拿來作為監測設備。
2-1 系統架構
圖(12)系統流程圖
I、Server端：
1. 將位於遠端觀測區土石尚未崩塌或地滑前的「地滑監測系統」所監測的影像，透過RF無線影
音傳輸器，將監視影像傳回固定式觀測站內的「數位錄影系統」，再經由網際網路到client端個
人電腦內，將影像資料收集、處理、辨識，並做即時位移量判斷。故此「地滑監測系統」系屬
「事前型觀測儀器」。
2. 遠端觀測區發生規模較大的土石位移異常現象時，監測裝置除了可偵測相關物理量做出即時反
應外，監測裝置往往會隨著土石移動、掩埋或受外力被破壞，但本系統最多可裝設16支攝影監
視器，故同一觀測點亦可在安全區另外架設一支攝影監視器，做為該觀測點即時動態監視之
用。全時紀錄土石崩塌、移位的過程，以利事後研究。故此「攝影機裝置」屬「事發型觀測儀
器」。
3. 本系統可利用影像位移偵測功能，對有可能發生土石崩塌、地滑區域設定位移偵測，一旦偵測
到土石崩塌，便會立即顯示於client端個人電腦內，並透過預設的簡訊或錄音，撥打電話、手
機、發送文字或語音訊息。而遠端監控人員收到文字或語音訊息，不論何時何地可透過有網路
功能的手機、PDA、個人電腦，即時監看現場狀況，以利快速判斷，降低生命、財產損失。
II、Client端：
即時接收遠端觀測區動態影像資料，並利用Labview軟體所自行開發影像監控程式，利用影像辨識技
術，將遠端觀測區內的「地滑監測系統」中雷射亮點影像之上(隆起)、下(下陷)、左(左移)、右(右移)、
旋轉、傾斜位移量資訊，做長期記錄與分析。並設定位移警戒值，如超過便會發出警報提醒相關人員，
將土石災害降至最低。
72-3.像素差異法距離量測原理說明
maxN
1hD
2hD
l
1hN
2hN
1hPa 1hPb
2hPa 2hPb
Sh
OP
2h 1h
h
圖(15)像素差異法距離量測原理
maxN ：攝影機每一條水平掃瞄線的最大像素
)( 1hD ： 1h 時的最大水平寬度
)( 2hD ： 2h 時的最大水平寬度
)( 1hN ： 1h 時 l所佔的像素值
)( 2hN ： 2h 時 l所佔的像素值
OP ：攝影機光學原點
sh ：攝影機光學原點所在位置的高度
21 hhh  :攝影機位移的距離
)()()()( 2211 hPhPhPhPl baba  的距離，於先前之研究，已證實在同一條掃描線上，其實際距離的大
小與所佔的像素值（或掃描時間）成正比，則我們固定一支攝影機量測同一個物體遠近時大小像素值的
差異，公式可表示如下:

max
1
1)( N
hD
hN
l  (1)
9●
●


X
Y
U
V
( , )x y
( , )u v
1 1( , )u v
●
●
1 1( , )x y
Nx
Nv
Cx
Cv
mX
NX
mV
NV
0 0( , )x y
0 0( , )u v
●
●
mUNU
mY
NY
hs
1h
2h
h
●
op
Camera
濾光片
衰減片
max( )N DN
max( )H DH
圖(31) 雷射亮點座標位移法應用於地滑監測系統示意圖
maxmax , HN : 1h 時,攝影機每一條水平及垂直掃描的最大像素
HN DD , : 1h 時,攝影機每一條水平及垂直掃描的最大距離
OP :攝影機的光學原點
Sh :攝影機光學原點所在位置的高度
h : 21 hh  的垂直距離，為已知10.5cm
mYmX , : 1h 時的最大水平及垂直寬度
mVmU , : 2h 時的最大水平及垂直寬度
XC : 1h 時， yx, 座標到 11, yx 座標的水平距離
XN : 1h 時， XC 所佔的像素值
VC : 2h 時， 11,vu 座標到 vu, 座標的垂直距離
VN : 2h 時， VC 所佔的像素值
 :前後傾斜的角度
 :左右旋轉的角度
 :前後傾斜的角度
 00 , yx :濾光片上的十字中心點
 00 ,vu :衰減片上的十字中心點
11
SHmm hDh  cot2
1
22 (12)
依(8)- (12)及已知數位相機（攝影機）垂直與水平解析度。任意廠牌之數位相機（攝影機）經我們
所設計的架構，皆可測得其量測 Hcot 與 Sh 參數。
2-5.地滑監測系統與雷射光軸之垂直投射校正

Laser
地滑監測系統
坡地
不動點
動點
利用筆電螢幕影像，校正
地滑監測系統與雷射光束
坡地
圖(17)地滑監測系統與雷射光束之垂直投射校正示意圖
地滑監測系統的架設，必須依地形條件，選擇安全又方便架設的地點，並非所有地方都能完成垂直
投射，即雷射投射器與地滑監測箱體裝置，並非位於在同一等高線上，如圖 17 所示。若雷射投射器(置
於不動點)位置較地滑監測器(置於動點)低，則必須由下往上發射雷射光束，就必須旋轉地滑監測箱體裝
置，使得雷射光束均能垂直於濾光片與衰減片上。而攝影機和濾光片與衰減片乃固定在同一基座上，其
相對距離及角度始終不會改變，將使濾光片與衰減片上的雷射亮點影像圖形的大小也保持不變，便能由
雷射亮點的座標位置，得知雷射光軸是否和濾光片與衰減片成垂直投射狀態。
為了能夠即時又簡單的完成垂直投射的校正工作，所以本研究又寫了一個專為地滑監測器與雷射投
射器可即時相互校正的程式，能夠在地滑監測現場立即做好地滑監測器(置於動點)與雷射投射器(置於不
動點)之間的校正與架設工作，步驟如下：
1. 調整攝影機左右、高低位置，藉由電腦螢幕得知，攝影機鏡頭十字線與濾光片十字線的中心點位置。
如圖18、19所示.
2. 只要調整攝影機呈現在電腦螢幕上的十字線與濾光片上的十字線相互重疊在一起如圖20、21，便完
成地滑監測器的校正工作，無須任何公式計算。而且以上的第1步驟與第2步驟不用到現場就可以事
先做好校正工作，以減少架設時間。
3. 我們利用雷射的準直性，高亮度、高單色性、高相干性，再將調校好的地滑監測器十字線中心點與
雷射投射器光軸連成一線，就已經完成垂直投射的校正工作。因為如果沒有讓雷射光軸通過 W,P
兩點如圖 18 所示，電腦的校正螢幕上會出現兩個亮點如圖 22 所示，就表示雷射光軸尚未垂直 U,V
13
圖(22)雷射光軸未通過 W,P 兩點的實際測試圖 圖(23)雷射光軸通過 W,P 兩點的實際測試圖
圖(24)螢幕內顯示兩個雷射亮點實際測試圖 圖(25)螢幕內顯示兩個雷射亮點影像辨識實際測
試圖
2-6.由影像中取得資訊
圖26 影像辨識流程圖
在執行地滑監測系統位移判斷前，必須要先能辨識出螢幕內的兩個雷射亮點，那一個是濾光片上的
亮點，那一個又是衰減片上的亮點。如此才能得知雷射光軸的方向，才能將正確的座標帶入公式內，計
算出地滑監測器位移量、位移方向與偏移角度。本研究將提出兩種辨識與區別亮點的方法，說明如下：
15
比較雷射亮點 21 xx  和 21 yy  那一組座標相距最大，如果兩個雷射亮點X軸座標相距較大則座落位
置較偏Y軸其辨識度較高，可用 10 xx  與 20 xx  運算，則那一組座標相減相距最短，也就是較接近 0x 中
心點，便可判斷該組座標就是濾光片上的雷射亮點，如圖(26)、(27)、(28)流程圖說明。
方法二：利用顏色分辨雷射亮點
當雷射發射器投射雷射到地滑監測箱體內時，首先會通過濾光片(隔離紫外線)，將400nm以下的射線
隔離掉，維持可見光及紅外光高穿透率，然後再通過衰減片，將雷射光強度衰減50%，以利影像辨識。
因此螢幕畫面上會有一個比較亮另一個比較暗的亮點，如圖(4-5-1)，但是電腦要如何分辨呢？本研究以
顏色深淺做為辨別的依據，首先將兩個亮點中心座標找出來，以中心座標為中心，在上下左右各加5個
pixel值，框選出一個 5 X 5 (pixel)²的正方形面積，分析正方形面積內有那些顏色成份，比較白色成份較
多的也就是較亮的區域，便是濾光片上的雷射亮點。如圖(29)、圖(30)
圖(29)雷射亮點顏色分析圖 I 圖(30)雷射亮點顏色分析圖II
本研究採用方法一：找出與 00 , yx 最接近的座標，較為簡便快速，而方法二：利用顏色分辨雷射亮
點，是不須要預設地滑監測器箱體重心，但須要增加顏色辨識功能，過程較為複雜，但各有優點。
2-8地滑監測器箱體移動判斷
射發射器投射在濾光片上的亮點 yx, 座標與投射在衰減片上的亮點 vu, 座標，對地滑監測器箱體
X ,U 軸做左右平移。
判斷式如下：
假設 vyyuxx  00 ,
則
 
max
0 N
D
xxx N (13)
箱體左右平移的距離x
若 0x 則箱體向左平移，如圖(32)所示。
否則 vyyuxx  00 ,
0x 則箱體向右平移，如圖(33)所示。
17
3. 影像辨識地滑監測系統之開發
隨著現代科技進步，生產線上的人工被自動化機器所取代的趨勢越來越明顯，為節省時間及人力成
本，許多需要勞力密集的工作紛紛以自動化機器所取代，為了滿足不同的需求，各種不同功能的機器人
因應而生， 如：工業用機器人、土木建設用機器人、農業用機器人、安全檢查用機器人、環境探測用
機器人等。
機器視覺技術運用的層面很廣，但是用在土石位移監測方面的發表文獻確有限，本研究想利用機器
視覺影像辨識技術，達到非接觸量測與監測功能。然而在機器視覺技術中，數位影像的分析，及景深資
訊的取得， 更是一項重要的課題。機器視覺應用於地滑監測之方法與步驟中有詳細說明。以下將說明
影像辨識地滑監測系統之軟硬體設備
3-1.設備說明
本地滑監測系統是以低解析度的攝影機做為監測裝置，利用可見光雷射做遠距離的投射，於待測區
的地滑監測箱體裝置內濾光片與衰減片上產生兩個投射亮點，以影像辨識方法，完成攝影機只要於近距
離攝取投射亮點於濾光片與衰減片上的影像圖形，便能以簡單的公式，計算出地滑位移量的大小及地滑
的方向[15]-[20]。
本系統採用軟硬體協同設計概念，首先需訂定系統規格，對此作系統分析並把某些功能分別以軟硬
體實現。至於何種功能需用軟體或硬體實現則必須考慮系統的效率與成本；因為硬體處理速度較快但是
成本較高，通常將常用且便宜的部份做成硬體，確定軟硬體分割後即可對軟硬體部分開始實作。
a. 軟體部份
1.Windows XP（或更新的版本）作業系統
2. NI LabVIEW 8.2 版的軟體
本系統採用 NI LabVIEW 8.2 版的圖控軟體，使用 LabVIEW 圖形化系統設計方式可縮短嵌入式設
計的時間，以整合傳統的理論式設計與原型製作。選擇圖形化或文字式程式設計，以完成所有程序。以
多核心處理器， 與新的匯流排技術，以建立高效能的測詴系統，可於生產線上平行處理、平行量測，
甚至平行測詴。內建的 I/O 與通訊程式庫具有通用連結功能，可連接任何儀器、感測器， 或軟體介面，
以輕鬆整合測詴應用中的多項元件。
本研究利用 functions tools 中的VISION AND MOTION tools 建立影像輸出輸入, 影像分析, 影像
辨識的功能。 而IMAQ Vision Assistant則用於輔助影像處理的工具。傳統軟體撰寫，必須將軟體完成、
執行後，才能看到圖形影像處理後的情形，倘若不滿意處理後的結果，需進入程式修改其參數，重覆執
行上述動作，直到滿意為止，這樣的動作相當浪費時間。而IMAQ Vision Assistant 卻可以直接觀看其影
像處理結果，並將步驟儲存起來，最後可將影像處理步驟轉換為LabVIEW 的虛擬儀表(VIs)物件，可節
省設計程式時除錯的時間。
19
量和傾斜角度。
1. 攝影機組
圖(38) 攝影機組
2.綠光雷射模組
投射雷射光束，其在濾光片與衰減片上產生的亮點，為判斷地滑監測器是否偏移的重要依據。
圖(39) 綠光雷射模組
3.隔離紫外線片:反射紫外線，並維持可見光及紅外光高穿透率。
圖(40) 隔離紫外線片
4.衰減片 :讓雷射光強度衰減，以利影像辨識。
21
圖(44) DVR數位錄放影機
8.個人筆記型電腦一台 :
利用筆記型電的輕巧便利，做為現場攝影機和雷射定位與校正工具
圖(45)個人筆記型電腦
3-2.系統程式設計
本系統使用 LabVIEW圖控程式軟體，它是一種圖形程式化語言(Graphic Language，簡稱 G 語言)，
其特點就是為了容易讓使用者可憑直覺來操作，利用滑鼠直接點取功能選項列或程式方塊圖(Icons)編譯
成機械碼，這樣的圖形化介面與資料流的程式設計邏輯，大大的降低在週邊整合上程式設計的困難度。
本系統設計流程如下：
23
3-4.子影像抽取與分割
將影像要分析的部份裁剪下來，去掉不相關的部份，以利後續影像辨識如圖(48)所示。但必須先設定欲
抽取的子影像大小座標，又因為影像抽取存檔中，有時會截取到空白影像檔，在子影像分割後，圖(47-c)和
圖(47-d)雷射亮點會自動做影像辨識與分析，取得亮點座標 yx, 、 vu, 與中心點座標 00 , yx 比對計算，便
可得知地滑位移量和傾斜角度。但是雷射亮點圖如果是一張空白影像檔，便會影響地滑位移量和傾斜角度的
判斷，故在子影像分割存檔前，利用本人所設計的影像畫素探針， 在圖片鑑別度大或辨識率高的座標位置
上截取一段圖片影像畫素值，再取平均值加係數。大於此數則將此幅圖檔存檔，小於則再取另一幅圖檔判斷
如圖(49)所示，以此方法可完全篩選出有效與無效的圖檔。
開始
影像來源
影像截取
子影像抽取
設定影像畫素探針
擺放位置的座標
將探針放在空白的子
影像畫面上，截取探
針上的所有畫素值 P
1 2 3 1....
N
K
N K
P
P P P P
E
N N
     

E = 所有pixel的平均值
R = 1 (經驗值係數)
判斷
(E + R)值
存檔
大於(E + R)值
小於(E + R)值
圖(48) 影像畫素探針判斷流程圖 圖(49) 子影像抽取
25
圖(62)箱體尚未移動 圖(63)箱體下沉 0.5cm
圖(64)箱體尚未移動之亮點分析圖 圖(65)箱體下沉 0.5cm 之亮點分析圖
(C)箱體左移
圖(90)箱體尚未移動 圖(91)箱體左移 0.5cm
圖(92)箱體尚未移動之亮點分析圖 圖(93)箱體左移 0.5cm 之亮點分析圖
(D)箱體右移
27
1.5 -1.482 1.21
2 -1.989 0.55
2.5 -2.535 1.38
3 -3.003 0.1
3.5 -3.4515 1.41
4 -3.978 0.55
4.5 -4.407 2.11
5 -4.8945 2.16
5.5 -5.5575 1.03
6 -5.9865 0.23
6.5 -6.4935 0.1
(3)箱體左移
表(三)箱體左移之實驗數據
實際移動距離(cm) 量測位移距離(cm) 誤差(%)
0.5 0.5075 1.48
1 1.015 1.48
1.5 1.5225 1.48
2 2.0475 2.32
2.5 2.5725 2.82
3 3.08 2.6
3.5 3.535 0.99
4 4.0075 0.19
4.5 4.5325 0.72
5 5.04 0.79
5.5 5.5825 1.48
6 6.125 2.04
6.5 6.6325 2
7 7.1225 1.72
7.5 7.6125 1.48
(4)箱體右移
表(四)箱體右移之實驗數據
實際移動距離(cm) 量測位移距離(cm) 誤差(%)
0.5 -0.5075 1.48
1 -1.015 1.48
1.5 -1.5225 1.48
2 -2.0125 0.62
2.5 -2.5725 2.82
29
6. 結論
我們完成成品的精度
隆起或下沉位移量(cm)最小精度:1pixel=0.037cm
左右位移量(cm)最小精度:1pixel=0.032cm
本計劃所研究的影像式地滑監測系統，以雷射光束做遠距離的投射，就不必使用銦鋼纜，真正實現遠距
非接觸式的監測系統，並將攝影機當做量測儀器使用，而使攝影機在地滑監測中，不再只有「監看」的功用。
而濾光片和衰減片與攝影機固定在同一基座上，則濾光片和衰減片與攝影機之間的相對距離與角度將始終保
持不變，影像畫面將一直為同一範圍的影像圖形。其中只有投射亮點的圖形影像，會隨地滑的發生而改變其
所在位置的座標值，如此一來縱使於夜間無法看得到四周景物，也因投射亮點因背景變暗而更容易分辨其影
像圖形座標所在的位置，優點在於夜間時，不必外加任何光源，也能輕易地辨識出雷射亮點的座標，而直接
得知地滑的位移量及地滑偏移的方向。
本系統的特點，其一是俱有網路功能，不論何時何地皆可收集地滑監測現場資訊，可更有效管理。另一
個特點是在同一個地滑監測區如有多個地滑監測點，一個地滑監測點僅用一支 CCD 攝影機加上一支雷射投
射器，只要確認監測箱內兩個雷射亮點在影像畫面中相隔的像素值，就能以簡單的公式快速完成單一攝影機
非接觸式的地滑監測功能。並且本系統在同一個地滑監測區最多可同時監測 16 個地滑監測點，並且可搭配
其他感測儀器使用，達到因地制宜相輔相成的效果。本研究把攝影機當做地滑位移量、方向、與傾斜角度量
測裝置，並能完成全天候日夜 24 小時具有量測功能的地滑監測系統，期盼監測資料紀錄提供給各相關單位
及學術單位研究使用，為本計畫研究的初衷與目的。
參考資料
1. 行政院農業委員會水土保持局 土石流防災資訊網 http://246.swcb.gov.tw/default-3.asp
2. 詹錢登(1994)，「土石流危險度之評估與預測」，中華水土保持學報，第 25 卷，第 2 期，pp95~102.
3. 張達德，坡地社區災害的簡易偵測、預警通報與潛勢評估之基礎研究－子計畫：坡地社區災害潛勢
劃定與評估方法之研究，中原土木工程學系，國科會永續會.
4. 段錦浩，坡地災害警戒值訂定與土石流觀測示範站之應用(統籌計畫)，中興大學水土保持學系，行
政院農業委員會水土保持局.
5. 周憲德，坡地災害次聲特性及監測系統之研究，中央大學土木工程學系，行政院農委會水土保持局
6. 林銘郎，坡地土石流發生機制研究－子計畫：坡地災害之邊坡穩定機制研究(1/2)，台灣大學土木工
程學系，國科會永續會.
7. 黃宏斌，坡地土石流發生機制研究－子計畫：坡地災害之邊坡穩定機制研究(1/2)，台灣大學水工試
驗所，國科會永續會.
8. 陳榮河，坡地災害引起土石流發生機制之整合研究－子計畫：邊坡破壞引發土石流之機制研究－以
土石流源頭為對象(1/2)，台灣大學土木工程學系 國科會永續會.
9. 張守陽，「土石流偵測方法之研究」，第二屆海峽兩岸山地災害與環境保育學術研討會，（2000）.
10. 張守陽，「機械視覺監測土石流發生之研究」，臺北：行政院國家科學委員會專題研究計畫成果報
告(計畫編號：NSC-90-2627-Z-027-001)（2002）.
 1
 
出席國際學術會議心得報告 
計畫編號 NSC 97-2221-E-129-006-MY2
計畫名稱 智慧型非接觸式地滑監測系統設計與研製 
出國人員姓名 
服務機關及職稱 
盧明智 
聖約翰科技大學 電子工程系 副教授 
會議時間地點 美國德州奧斯汀(Austin, Texas, USA)，2010 年 5 月 3-6 日 
會議名稱 
2010 IEEE 國際儀器儀表與測量技術研討會  
2010 IEEE International Instrumentation and Measurement Technology 
Conference 
發表論文題目 
中文：(共兩篇論文) 
1. 以影像為基底的物體傾斜面之量測系統 
2. 以 CCD 影像畫面像素差異為基礎之傾斜面物體距離及角度量測系統 
英文： 
1. Image-Based System for Measuring Objects on an Oblique Surface 
2. Distance and Angle Measurement of Distant Objects on an Oblique Plane 
Based on Pixel Variation of CCD Image 
 
一、參加會議經過 
2010 IEEE 國際儀器儀表與測量技術研討會 (2010 IEEE International Instrumentation 
and Measurement Technology Conference, I2MTC)係 IEEE儀器儀表與測量學會 (IEEE 
Instrumentation and Measurement Society)第27屆年會，不僅與會人數眾多，發表之論文皆經
嚴格審查，具崇高學術地位。本次研討會主題是：Innovative and Integrated Applications of 
Instrumentation and Measurement，研討會廣泛徵求儀器儀表與量測科學與技術領域上的研
究、發展、與應用方面的學術論文，包含自主機器人導航以及影像式量測技術等技術領域，
非常契合本人目前之研究方向，因此投稿兩論文獲得接受，得以有機會與相關領域的專家
學者齊聚一堂，進行學術之交流。本年度研討會於2010年5月3～6日在美國德州的奧斯丁
（Austin, TX）舉行，舉辦地點為Hilton Austin，交通非常便利，研討會一連舉行四天，來
自全世界的學者專家齊聚一堂，共同研討I2MTC所涵蓋之相關主題，共發表學術論文300餘
篇。筆者於5月3日到達會場開始參加研討會相關活動，論文發表時間為5月4日下午1:15PM 
～  5:00PM之Poster Session I，該場次所涵蓋之領域很廣泛，包含：Electromagnetic 
Measurements、Flow Measurements、Optical Measurements、Robotics and Automation、Chemical 
and Biological Measurements 、 A/D and D/A Conversions 、 Dielectric and Magnetic 
Measurements、Signal Processing、Sensor Networks等領域，共44篇論文發表。議程主席是
Prof. Bernardo Tellini (University of Pisa, Italy)，他非常仔細地穿梭在各個場地與報告人討
論，隨後也有多位與會學者針對相問題提出討論，由於事前已妥為準備，實驗數據及理論
尚稱完備，因此均能與在場人士交流討論，順利完成論文發表。實際上本場次研討會參加
人數超過50人，討論過程非常熱烈，大家互相交換名片及研究心得，分享對於問題的看法，
達到學術交的目的，圓滿達成任務。 
圖三、與議程主席Prof. Tellini進行討論 圖四、另一篇論文之進行狀況 
 
圖五、與參與研討會的學者合影  
 
 3
( ) ( )measure the photographing distance, the distance between two 
arbitrary points on the oblique surface, and the incline angle. 
h(O
)
Hθ
 
Figure 1. Configuration of the image-based distance measuring system 
(IBDMS). 
 
III. PROPOSED METHOD FOR MEASURING TARGET OBJECTS 
ON AN OBLIQUE PLANE 
If the target plane is not perpendicular to the optical axis, 
relationships derived in the previous section to obtain the 
photographing distance will be different. Figure 2 shows a 
configuration of the proposed image-based system for 
measuring target objects on an oblique surface, where an 
incline angle mθ  exists between the perpendicular and oblique 
planes. Thanks to the oblique plane, there exists a new 
relationship of the pixel counts between points A and B.  
Referring to Fig. 2, pixel count ( )A
)
m
N  on the image plane is 
smaller and  is larger if point A is farer from and point B 
is closer to the CCD camera. As a result, formulas (1) and (2) 
do not apply in this case. 
(BN
To solve this problem, a virtual plane is introduced to 
establish relationships to measure the incline angle θ . Virtual 
planes, for example planes VP_A and VP_B in Fig. 2, are 
intangible planes which are perpendicular to the optical axis. 
Thus, photographing distances between the camera and the 
virtual planes can be respectively obtained via (1) as: 
 ( ) ( ) SHHS hNAN
DAh −×××= θcot
2
1
max_
 (3) 
 ( ) ( ) SHHS hNBN
DBh −×××= θcot
2
1
max_
 (4) 
As a result, the photographing distance to point O on the 
oblique plane, h(O), can be obtained through (3) and (4): 
 
( )
( ) ( )( )
( ) ( ) SHHS hNBNAN
DBNAN
BhAhOh
−××⋅
+=
+=
θcot
4
2
max_
m
 (5) 
The incline angle θ  can be obtained through an implicit 
relationship between h(A) and h(B) as: 
( ) ( )
 ( ) ( )
( ) ( )
( ) ( )
( ) ( ) ⎥⎦
⎤⎢⎣
⎡ ×⋅
−×=
×⋅
−×=
−× =
−
HHm
HHm
mS
BNAN
ANBNN
BNAN
ANBNN
BhAhD
θθ
θθ
θ
cot
4
1tan
cot
4
1tan
tan2
max_
1
max_
 (6) 
To determine the distance between two arbitrary points P 
and Q on the target plane, we need to divide the points on the 
oblique plane into two groups separated by point O. For any 
point P with a larger photographing distance than h(O), that is 
h(P)>h(O), the distance between points O and P can be derived 
as follows: 
( ) ( ) mSAN
DPNPO θsec××=  (7) 
For any point Q with a smaller photographing distance than 
h(O), that is h(Q)<h(O), the distance between points O and Q 
can be derived as follows: 
 ( ) ( ) mSBN
DQNQO θsec××=   (8) 
As long as the distances PO  and QO  are obtained, the 
distance between two arbitrary points, P and Q, can be 
obtained as: 
  (9) QOPOQP +=
 
IV. DIFFUSION EFFECT OF THE PROJECTED SPOTS 
Figure 3 shows the mechanism of the measuring system, 
where Laser A, Laser B, and optical origin of the CCD form a 
straight line. Thanks to the diffusion effect when measuring far 
away objects, the laser-projected spots in a CCD image 
become larger than they should be. However, the area of the 
projected spots in the CCD image becomes smaller as 
photographing distance increases. The shaking of camera when 
taking pictures also causes shift of the laser-projected spots 
away from the 
max_2 V
N1 scan line. These phenomena are 
illustrated in Fig. 4, where circles in different diameters in the 
video signal represent the projected spots because of the 
diffusion effect due to different photographing distances. 
 
 
Figure 5. Setup of the proposed image-based system for measuring objects on 
an oblique surface. 
A. Distance ( ( )Oh ) measurement: 
Table 1 shows the experiment results in measuring 
photographing distances ranging from 0.5 m to 3.5 m by (5). 
TABLE I.  MEASUREMENT OF PHOTOGRAPHING DISTANCES RANGING 
FROM 50 TO 350 CM  
Distance 
(cm) 50 100 150 200 250 300 350 
Angle 
( degrees) 60 60 45 45 30 30 45 
Estimated 
distance 
(cm) 
51.17 101.2 151.7 202.3 251.8 301.6 352.5 
Error (%) 2.34 1.2 1.13 1.15 0.53 0.71 0.71 
B. Angle ( mθ ) measurement 
Table 2 shows the experiment results in measuring incline 
angles ranging from 30 to 60 degrees by (6). 
TABLE II.  INCLINE ANGLE MEASUREMENT THROUGH (6) 
Distance 
(cm) 50 100 125 150 175 200 250 
Angle 
( degrees) 30 45 60 30 45 60 30 
Estimated 
angle ( )mθ  30.39 45.22 60.44 30.36 44.87 60.96 29.75
Error (%) 1.3 0.49 0.73 1.2 -0.29 1.6 -0.83
C. Distances between two arbitrary points 
Table 3 shows the experiment results in measuring distance 
between two arbitrary points on the oblique plane. The actual 
distance between these two points is 45 cm. 
 
TABLE III.  DISTANCE MEASUREMENT BETWEEN TWO ARBITRARY POINTS 
Photograph
ing 
distance 
(cm) 
50 100 150 200 250 300 350 
Incline 
angle 
( degrees) 
30 45 60 30 45 60 30 
Estimated 
distance 45.73 45. 45.  45.  45.  16 57 93 45.1 44.09 51
Error(%) 1.62 0.36 1.27 2.07 0.22 -2.02 1.13 
 
VI. CONCLUSIONS 
This paper presented a general framework for measuring 
target objects on an oblique plane, overcoming the problems 
encountered by the IBDMS method. Not only photographing 
distance from the oblique plane but also the incline angle 
between the perpendicular and oblique planes can be measured. 
Thanks to its capability in measuring distance between two 
arbitrary points on the oblique plane in addition to the 
photographing distance, the proposed method can be further 
extended to localize objects for autonomous mobile robots by 
mounting a CCD camera on the robot. Because of its 
simplicity in implementation, any CCD cameras can be used to 
establish the proposed measuring system. To provide better 
accuracy for distance measurement, the optical origin of any 
CCD cameras needs to be taken into consideration. As shown 
in the paper, the proposed measuring system has demonstrated 
itself as a simple way in measuring distances while 
sim ltaneously recording images. 
 
 NSC 97-2628-E-003-002- 
MY d NSC 97-2221-E-032-032. 
 
rumentation 
lications,” IEEE Sensors Journal, vol. 1, 
trumentation and Measurement, vol. 
entation and Measurement, vol. 45, vo. 2, pp. 677-682, April 
 “Range finder system,” US patent of 
 ACC system,” JSAE review, vol. 20, no. 4, 
stems, Man and Cybernetics, vol. 19, no. 6, pp. 1489-
,” Machine Vision and Applications, vol. 6, 
strumentation and 
Measurement, vol. 39, no. 3, pp. 512-516, June 1990. 
u
ACKNOWLEDGEMENT 
This work was partially supported by the National Science 
Council (NSC), Taiwan, under Grant
2 an
REFERENCES 
[1] F. Gueuning, M. Varlan, C. Eugene, and P. Dupuis, “Accurate distance 
measurement by an autonomous ultrasonic system combining time-of-
flight and phase-shift methods”, IEEE Transactions on Inst
and Measurement, vol. 46, no. 6, pp. 1236-1240, Dec. 1997. 
[2] A.Caarullo and M. Parvis, “An ultrasonic sensor for distance 
measurement in automotive app
no. 2, pp. 143-147, Aug. 2001. 
[3] K. Nakahira, T. Kodama, S. Morita, and S. Okuma, “Distance 
measurement by an ultrasonic system based on a digital polarity 
correlator”, IEEE Transactions on Ins
50, no. 6, pp. 1478-1752, Dec. 2001. 
[4] A. Carullo, F. Ferraris, and S. Graziani, “Ultrasonic distance sensor 
improvement using a two-level neural network”, IEEE Transactions on 
Instrum
1996. 
[5] H. Kazuya, M. Seiichi, Y. Hideo, A. Tsuyoshi, F. Tadahide, S. Tamotsu, 
H. Shigeru, and I. Tomonori,
invention, no. 4123650, 1978. 
[6] K. Osugi, K. Miyauchi, N. Furui, and H. Miyakoshi, “Development of 
the scanning laser radar for
pp. 549-554, Oct. 1999. 
[7] U. R. Dhond and J. K. Aggarwal, “Structure from stereo-a review,” IEEE 
Transactions on Sy
1510, Nov. 1989. 
[8] P. V. Fua, “A parallel stereo algorithm that produces dense depth maps 
and preserves image features
no. 1, pp. 35-49, Dec. 1993. 
[9] M. A. Sid-Ahmed and M. T. Boraie, “Dual camera calibration for 3-D 
machine vision metrology,” IEEE Transactions on In
Distance and Angle Measurement of Distant Objects 
on an Oblique Plane Based on Pixel Variation of 
CCD Image 
 
Ming-Chih Lu 
Department of Electronic Engineering 
St. John’s University 
499 Tam King Rd., Sec. 4, Tam-Sui, Taipei, Taiwan. 
 
Chen-Chien Hsu and Yin-Yu Lu 
Department of Applied Electronic Technology 
National Taiwan Normal University 
162 He-Ping East Rd., Sec. 1, Taipei, Taiwan. 
 
Abstract—This paper presents an image-based system for 
measuring target objects on an oblique plane based on pixel 
variation of CCD images for digital cameras by referencing to 
two arbitrarily designated points in image frames. Based on an 
established relationship between the displacement of the camera 
movement along the photographing direction and the difference 
in pixel counts between reference points in the images, 
photographing distance between the camera and an object on the 
oblique target plane can be calculated via the proposed method. 
Keywords- distance measurement; pixels; oblique plane; incline 
angle; digital cameras; CCD images; image-based measuring 
systems. 
 
I. INTRODUCTION 
As far as non-contact distance measurement is concerned, 
ultrasonic-based [1]-[5] and laser-based [6]-[7] techniques are 
among the most commonly-used methods. Unfortunately, 
measurement accuracy via the laser- and ultrasonic-based 
methods heavily depended on surface reflectivity of the object 
under measurement. If the reflection surface is undesired, the 
measuring system generally performed poorly or not at all. 
These methods also have difficulties in recording images of the 
objects while measuring distance. Alternatively, imaged-based 
methods have been proposed for distance measurement by 
using CCD cameras. Thanks to the advantages in providing a 
rich source of environment information, imaged-based 
methods are becoming more and more popular in various 
applications, for example localization of mobile robots. 
However, traditional vision-based systems generally required 
two cameras set up at different positions to capture two 
different pictures for further analysis. As a result, pattern 
recognition [8]-[12] or image analysis [13]-[15] of a whole 
image frame were required to extract features from the images 
for obtaining the distance measurement. Thus, huge amount of 
storage capacity and high-speed DSP processors are required 
for system so established, inevitably resulting in disadvantages 
in terms of system complexity, processing speed, and 
establishment cost. As a result, performance of real-time 
measurement via the pattern recognition or image analysis 
methods was generally not satisfactory because of the speed 
constraint. As an attempt to solve this problem, an image-
based distance measuring system (IBDMS) [12], [16] was 
proposed to measure distance and area using two laser 
projectors and a CCD camera based on a triangular 
relationship. Unfortunately, the IBDMS is valid only for 
measuring objects or surfaces that are perfectly perpendicular 
to the optical axis. Any tilt in the plane formed by the target 
surface that intersects the two laser beams will have an adverse 
effect on the determination of pixel counts. Furthermore, 
measurement accuracy of the IBDMS depended on the 
distance between the laser projectors. Incorporation of the 
measuring system into a digital camera might become 
cumbersome if higher measuring resolution is required. There 
was also a distance measurement method based on pixel 
number variation of images [17]. Unfortunately, this approach 
failed to solve the problem in measuring objects on an oblique 
plane, similar to the IDBMS method. It is therefore the 
objective of this paper to propose an image-based system 
overcoming the above-mentioned difficulties for measuring 
objects on an oblique plane. 
 
II. DISTANCE MEASUREMENT BASED ON PIXEL NUMBER 
VARIATION 
Figure 1 shows the relationship between distance and 
variation of pixel counts at different photographing distances 
of the distance measuring method. To be applicable, the target 
plane formed by points A, O, B needs to be perpendicular to 
the optical axis. Based on a simple relationship between the 
displacement of the camera movement, Δ , and the difference 
in pixel counts between the reference points in the images at 
different photographing distances, we can measure the distance 
of an object on the perpendicular plane. Assume that actual 
distance between reference points A and B will not change. We 
have the following relationship between pixel counts and 
distances: 
h
max
1
1
)(
)(
)(
N
hD
ABN
ABD =   (1) 
 ( ) ShhANANAh −Δ×−= )()( 12
1
2
AN )(
( )
 (10) 
 
ShhBNBN
BNBh −Δ×−= )()(
)(
12
2
1
 (11) 
 ( ) ShhBNBN
BNBh −Δ×−= )()(
)(
12
1
2
 (12) 
where h1(A) and h1(B) are distances from the camera at 
position 1 to virtual plane VP_A and virtual plane VP_B, 
respectively. h2(A) and h2(B) are distances from the camera at 
position 2 to virtual plane VP_A and virtual plane VP_B, 
respectively.  stands for the pixel counts in the image 
plane for point P when image is taken at position n . 
)(PNn
( ) ( ) ( ) ( )
( ) mBA d
kBhAhBhAh
θtan
2211
+
Δ=
From (9), (10), (11), and (12), we have: 
 
dk =Δ
−=−
 (13) 
 
BA
m dd
k
+
Δ= −1tanθ
kΔ
 (14) 
where  is the distance between the virtual planes VP_A and 
VP_B, and mθ  is the incline angle. dA and dB represent the 
distance from point A and point B to the optical axis, 
respectively, which can be expressed as follows: 
 ( ) ( )( ) HA hAN
ANANd θtan
(
2
2
×Δ=
( ) ( )
( )
HNAN )() max_1
21 ××−
 (15) 
 
H
H
B hNBNBN
BNBNd θtan
)()(
2
max_12
21 ×Δ××−=
 (16) 
To this end, the distance from the optical origin at positions 
1 and 2 to the oblique plane intersecting the optical axis can be 
expressed as: 
 ( ) ( ) ( )( ) ( ) ( ) mBmA
mBmA
dBhdAhOh
dBhdAhOh
θθ
θθ
tantan
tantan
222
111
+=−=
+=−=  (17) 
In order to determine the position of target objects in the 
real-world environment, we represent the distance between two 
arbitrary points A and B as ( )ABD , which can be derived as: 
 ( ) ( ) mBA ddABD θsec+=  (18) 
 ( ) mBA ddABD θsec−=  (19) 
Depending on the position of points A and B, different 
formulas apply. For example, if points A and B lie at different 
sides of origin O, (18) is used to solve the problem, and (19) is 
used to solve the problem when points A and B lie at the same 
side. 
 
Hθ
mθ kΔ
max_H max_V
H
 
Figure 2. Configuration of the proposed image-based system for measuring 
objects on an oblique surface based on variation of pixel counts. 
 
IV. EXPERIMENT RESULTS 
Figure 3 shows the setup of the proposed image-based 
system for measuring target objects on an oblique surface 
based on pixel variation of CCD images. The CCD camera 
adopted to conduct the experiments in this paper is Canon 
400D with N =3888 pixels and N =2592 pixels. 
Internal parameters of the camera include: θcot =1.55,  
Vθcot Sh 50=h=2.33, =4.11 cm, and  Δ  cm, which were 
obtained by a calibration method in advance. Various 
photographing distances and incline angles are measured to 
evaluate the performance of the proposed approach, as shown 
in Tables 1, 2 and 3. Pictures showing various oblique planes 
under measurement via the proposed method are shown in 
Figures 4, 5, 6, and 7, respectively. As demonstrated in these 
tables, satisfactory measurement of photographing distance 
and incline angle can be obtained via the proposed method, 
relaxing the application constraints faced by the existing 
IBDMS, which is only valid for measuring objects or surfaces 
that are perfectly perpendicular to the optical axis. In the 
distance measurement experiment as shown in Table 1, small 
incline angles do not significantly affect the measurement 
results. When incline angle become larger, however, the error 
in measuring photographing distance are dramatically affected. 
For example, the error can be as high as 12.1% in measuring 
  
ACKNOWLEDGMENT 
This work was partially supported by the National Science 
Council (NSC), Taiwan, under Grant NSC 97-2221-E-129-
006-MY2 and NSC 98-2221-E-003-023. 
 
REFERENCES 
[1] F. Gueuning, M. Varlan, C. Eugene, and P. Dupuis, “Accurate distance 
measurement by an autonomous ultrasonic system combining time-of-
flight and phase-shift methods”, IEEE Transactions on Instrumentation 
and Measurement, vol. 46, no. 6, pp.  1236-1240, Dec. 1997. Figure 5. Picture showing the oblique plane under measurement via the proposed method where the incline angle and photographing distance are 45° 
at 50 cm, respectively.  [2] A.Caarullo and M. Parvis, “An ultrasonic sensor for distance measurement in automotive applications,” IEEE Sensors Journal, vol. 1, no. 2, pp. 143-
147, Aug. 2001. 
[3] K. Nakahira, T. Kodama, S. Morita, and S. Okuma, “Distance 
measurement by an ultrasonic system based on a digital polarity 
correlator”, IEEE Transactions on Instrumentation and Measurement, vol. 
50, no. 6, pp. 1478-1752, Dec. 2001. 
 
[4] A. Carullo, F. Ferraris, and S. Graziani, “Ultrasonic distance sensor 
improvement using a two-level neural network,” IEEE Transactions on 
Instrumentation and Measurement, vol. 45, no.2, pp. 667-682, Apr. 1996 
[5] K. T .Song and W. H. Tang, “Environment perception for a mobile robot 
using double ultrasonic sensor and a CCD camera,” IEEE Transactions on 
Industrial Electronics, vol. 43. no.3, June 1996. 
[6] H. Kazuya, M. Seiichi, Y. Hideo, A. Tsuyoshi, F. Tadahide, S. Tamotsu, 
H. Shigeru, and I. Tomonori, “Range finder system,” US Patent of 
Invention, No. 4123650, 1978. 
[7] K. Osugi, K. Miyauchi, N. Furui, and H. Miyakoshi, “Development of the 
scanning laser radar for ACC system,” JSAE Review, vol. 20, no. 4, pp. 
549-554, Oct. 1999. 
Figure 6. Picture showing the oblique plane under measurement via the 
proposed method where the incline angle and photographing distance are 30° 
at 100 cm, respectively.  [8] C. C. Peng, “A compact digital image sensing distance and angle 
measuring device,” M.S. thesis, Optical Science Center, Nation Central 
Univ., Taoyuan County, Taiwan, 2001. 
[9] T. Egami, S. Oe, K. Terada, and T. Kashiwagi, “Three dimensional 
measurement using color image and movable CCD system,” The 27th 
Annual Conference of the IEEE Industrial Electronic Society, pp.1932-
1936, 2001. 
 
[10] M. C. Lu, “Image-based height measuring system for Liquid or particles 
in tanks,” ROC patent of invention, No. 201536, 2004 
[11] D. Katsoulas and A. Werber,  “Edge detection in range images of piled 
box-like objects,” Proceedings of the 7th International Conference on 
Pattern Recognition, Vol. 2, pp. 80-84, 2004. 
[12] M. C. Lu, W. Y. Wang, and C. Y. Chu, “Image-based distance and area 
measuring system,” IEEE Sensors Journal, vol. 6, no. 2, pp. 495-503, Apr. 
2006. 
[13] T. Kanade, H. Kano, and S. Kimuram, “Development of a video-rate 
stereo machine,” Proceedings of IEEE International Conference on 
Intelligent Robots and Systems 95, Pittsburgh, PA, pp. 95-100, Aug. 5-9, 
1995. 
Figure 7. Picture showing the oblique plane under measurement via the 
proposed method where the incline angle and photographing distance are 45° 
at 100 cm, respectively. [14] Y. Tanaka, A. gofuku, I. Nagai, and A. Mohamed, “Development of a  
compact video-rate range finder and its application,” Proceedings of 3rd 
International Conference on Advanced Mechatronics, Okayama, Japan, pp. 
97-102, Aug. 1998. 
 
[15] H. Yan, “Image analysis for digital media applications,” IEEE Computer 
Graphics and Applications, Vol. 21, No. 1, pp. 18-26, Jan. 2001. V. CONCLUSION  
This paper presented a novel method to measure the 
photographing distance of remote objects locating on an 
oblique plane as well as the incline angle. With the proposed 
method, distance between any two arbitrary points in the image 
can be obtained with desired results. As demonstrated in the 
paper, the proposed measuring system has overcome problems 
and difficulties encountered by conventional image-based 
measuring methods and demonstrated itself as a simple yet 
accurate way in measuring distance and incline angle for 
objects on an oblique surface while simultaneously recording 
images. 
[16]  C. C. Hsu, M. C. Lu, W. Y. Wang, and Y. Y. Lu, “Three dimensional 
measurement of distant objects based on laser-projected CCD images,” 
IET Science, Measurement & Technology, vol. 3, no. 3, pp. 197-207, May 
2009. 
[17] C. C. Hsu, M. C. Lu, W. Y. Wang, and Y. Y. Lu, “Distance measurement 
based on pixel variation of CCD images,” ISA Transactions, Vol. 
國科會補助專題研究計畫成果報告自評表 
請就研究內容與原計畫相符程度、達成預期目標情況、研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）、是否適
合在學術期刊發表或申請專利、主要發現或其他有關價值等，作一綜合評估。
1. 請就研究內容與原計畫相符程度、達成預期目標情況作一綜合評估 
■達成目標 
□未達成目標（請說明，以 100字為限） 
□實驗失敗 
□因故實驗中斷 
□其他原因 
說明： 
2. 研究成果在學術期刊發表或申請專利等情形： 
論文：■已發表 □未發表之文稿 □撰寫中 □無 
專利：□已獲得 ■申請中 □無 
技轉：□已技轉 ■洽談中 □無 
其他：（以 100字為限） 
此次國科會計劃在中興大學水土保持系主任陳樹群教授的指導之下，完成跨領域的合作。
並取兩件發明專利及三件審察中的發明專利，並發表論文於國際期刑(SCI)及 IEEE 國際研討
會、國際天然災害研討會。 
3. 請依學術成就、技術創新、社會影響等方面，評估研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）（以
500字為限） 
本國科會計劃，針對目前國內有關大地工程的監測方法及設備，做深入的研究與分析及歸
類，發現其監測設備多數為國外進口，價格昂貴且不同廠牌的設備很難完成彼此之間系統
的整合，故本國科會計劃乃以專利技術為基礎，將原理轉置為數學模型及實際電路製作以
取得量測數據，發表兩篇論文於國際期刑(SCI) 和兩篇論文 IEEE 國際研討會及一篇於國
際天然災害研討會。期間己得到兩件發明專利及三件審察中的發明專利，分別是影像數據
傳輸系統與方法、遠距影像座標地滑監測系統及其方法、遠距雷射投影地滑監測系統。 
論文所推導的數學模型及所取得的相關專利技術與方法，可以轉置成實用的大地監測設備
與產品，將能以此次國科會計劃的成果做為理論與技術的整合平台，去研發更高品質的監
測設備與產品，將能改善並整合目前地滑、土石流、堰塞湖、橋樑震動、邊坡傾斜、水位
高低⋯等，量測與監測於同一系統中。除了大大降低成本外，也能喚起更多電子、電機、
通訊領域的人才可以共同執行跨領域的合作，爭取因氣候暖化所衍生新興產業的技術領
先，環境變異與大地變異監測設備的需求，將會以級數的速度上升，而其中產品的穩定度
及整合度和方便度，將是未來研究與製造必須更精進深入的項目。 
