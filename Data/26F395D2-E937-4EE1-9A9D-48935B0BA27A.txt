 I 
■ 中、英文摘要及關鍵詞(keywords)：（此部分的頁碼編寫請用羅馬字 I 、II、 III…標在
每頁下方中央） 
■ 目錄：（此部分的頁碼編寫請用羅馬字 I 、II、 III…標在每頁下方中央） 
■ 報告內容：（「報告內容」至「附錄」部分請以阿拉伯數字 1.2.3.…順序標在每頁下方中
央） 
●計畫緣由及目的 
●研究方法 
●結果與討論：含結論與建議 
●參考文獻 
※若該計畫已有論文發表者，可以 A4 紙影印，作為成果報告內容或附錄，並請註明發
表刊物名稱、卷期及出版日期。 
※若有與執行本計畫相關之著作、專利、技術報告、或學生畢業論文等，請在參考文獻
內註明之，俾可供進一步查考。 
 
■ 計畫成果自評：請就研究內容與原計畫相符程度、達成預期目標情況、研究成果之學術
或應用價值、是否適合在學術期刊發表或申請專利、主要發現或其他有關價值等，作一
綜合評估。 
■ 可供推廣之研發成果資料表：凡研究性質屬應用研究及技術發展之計畫，請依國科會提
供之表格，每項研發成果填寫一份。 
■ 附錄（或附件） 
  - II -
Abstract 
The optical burst switchings (OBS) has proved to play an important role in the 
optical network switching technology. It is due to the fact that the OBS provides 
improvements over wavelength routing in terms of bandwidth efficiency comparing 
with optical circuit switching (OCS) and transmits the burst without the memory 
contrast to optical packet switching (OCS). However, how to provide the QoS in the 
OBS network still has no proper solution. Here, we have proposed a new 
channel-scheduling scheme called burst priority scheduling with FDL reassignment 
(BPS-FR) in OBS networks using PPJET signal protocol. Simulation results show that 
BPS-FR achieves 43% improvement in the average system dropping probability and 
reduces 75% in the dropping probability for low-priority traffic over PLAUCVF. 
In the meantime, we consider a traffic routing and grooming problem with the 
dynamic, multicast and nonuniform traffic in bi-directional optical ring networks. A 
maximum utilization and minimum hops (MUMO) scheme is proposed to reduce the 
new call blocking probability and to maximize the used wavelength’s utilization. The 
MUMO scheme contains two main operations: multicast traffic routing with 
minimum hops and multicast traffic grooming with maximum utilization. They are to 
achieve better system utilization without changing the lightpath topology. Simulation 
results show that the performance of the MUMO scheme is much better than one of 
the other conventional schemes no matter in which environment.  
Finally, a PRNN/ERLS-based predictive QoS-promoted dynamic bandwidth 
allocation (PQ-DBA) scheme is proposed for upstream transmission in Ethernet 
passive optical network (EPON) systems. This scheme originally divides incoming 
packets of voice, video, data service traffic into six priorities, where packets having 
less room before QoS requirements violation or being in starvation situation will be 
dynamically promoted to high priority cycle-by-cycle. It predicts packets arriving at 
prediction interval for ONUs using pipeline recurrent neural network 
(PRNN)/extended recursive least squares (ERLS) so that the bandwidth allocation can 
be more up-to-date and then accurate. Simulation results show that the proposed 
PQ-DBA scheme achieves higher system utilization and lower average voice, video, 
data packet delay time than the DBAM scheme by 4%, and 21%, 90%, 43%, 
respectively, and the PQ-DBA scheme but without prediction by 2%, and 26%, 29%, 
34%, respectively. 
Keywords： Optical Burst Swtiching (OBS), schedule, Ethernet Passive Optical 
Networks (EPON), Dynamic Bandwidth Allocation (DBA), Fairness, QoS, Traffic 
Grooming, Integer Linear Problem, Annealing Method 
 
 1 
I. Introduction and Motivation 
In our proposal isuues, we consider the design and analyses of the OBS resource 
reservation algorithm in the QoS-guaranteed metro/ring optical networks, of the 
uni-cast and multicast traffic grooming in the metro optical ring network which 
connects the backbone by an OBS node, and of the DBA algorithm in EPON or 
GPON. In recent years, since the bandwidth of the metro optical network is rapidly 
increasing according to the Dense Wavelength-Division Multiplexing (DWDM) swift 
development, the metro optical network with DWDM equipment would come true. 
The optical burst switchings (OBS) plays an important role in the optical network 
switching technology. The OBS provide improvements over wavelength routing in 
terms of bandwidth efficiency comparing with optical circuit switching (OCS) and 
transmits the burst without the memory contrast to optical packet switching (OCS). 
However, how to provide the QoS in the OBS network still has no proper solution. In 
the meanwhile, synchronous optical network (SONET) ring networks have been 
widely deployed for the optical network infrastructure. The progresses of optical 
networks evolve with time; meanwhile, the carried traffic streams surge. The 
transmission capacity of an optical network largely increases because of the 
development and application of wavelength division multiplexing (WDM) 
technologies. Nevertheless the required bandwidth of a traffic stream is also much 
smaller than the bandwidth capacity of a wavelength. However, if we additionally 
consider the multicast traffic which is the result of the video online, then the traffic 
grooming technology would become more complexity. Fiber to the home (FTTH) is 
used to provide the higher bandwidth and more quickly connect to the network than 
ADSL. Many authorities think that it would widely develop and popularize from 2006 
to 2008. Hence, how to attend to the QoS and the fairness by a dynamic bandwidth 
allocation algorithm it is still worth to research in EPON or GPON. 
 
A. Burst Priority Scheduling with FDL Reassignment for Optical 
Burst Switch Networks 
 
Optical burst switching (OBS) is a new data transmission/switching method to 
realize IP over WDM. It strikes a balance between optical circuit switching and 
optical packet switching [1], [2]. In OBS networks, the ingress node assembles a 
number of IP packets, which go to the same egress node, into a data burst (DB). For 
each DB, there is a control burst (CB) associated with it. A signaling protocol, called 
just-enough-time (JET), was proposed [3], where the CB is first transmitted to the 
next node to reserve the bandwidth and then the DB is sent after an offset time. The 
 3 
and terminated at arbitrary time and static traffic means the traffic streams are set up 
all at once and fixed thereafter.  
Many researches on traffic grooming in WDM network have exclusively dealt 
with unicast and static traffic [10 - 15].  Only some multicast problems have been 
investigated [16 - 20]. However, it is expected that a sizable portion of the traffic in 
future high performance networks will be multicast, such as , multi-party 
conferencing, HDTV, and web content distribution. However, most multicast service 
applications require only sub wavelength capacity (for example, HDTV needs only 
20Mbps). It would be inefficient to assign a whole lightpath to each lower-rate 
multicast streams. So the problem of multicast traffic grooming over optical networks 
has received significant attention [9]. 
In the multicast researches, a mesh network and the dynamic multicast traffic 
grooming were considered in [16], [17], and they are to minimize the loss probability. 
In [16], two simple approaches were proposed to groom dynamic traffic. The first 
approach is the single-hop (SH) traffic grooming. A new call has the same source and 
destination(s) with a working lightpath (or light tree) and then the new call will be 
groomed with the lightpath if it has enough bandwidth to support. The second 
approach is the multi-hop (MH) traffic grooming. It firstly search a lightpath (or 
light-tree) with the same destination(s) and enough bandwidth which called “to 
destinations light-tree” (TDLT), and another lightpath between the source of the new 
call and the source of TDLT by SH approach was selected. Note that only grooming 
by the SH, the traffic can be transmitted all-optically before reaching the 
destination(s). In [17], an approach called hybrid multi-hop (HYMH) is proposed to 
improve MH by combination of provisioned and un-provisioned lightpath. 
Since ring is a widely used metro network, we are motivated to study the traffic 
grooming problem in optical bidirectional ring network with dynamic non-uniform 
multicast traffic. We propose the node architecture which is equipped in ring network 
and have the ability of traffic grooming and light splitting. Their object is to reduce 
the new call blocking probability and maximize the utilization of used wavelength. 
 
C. PRNN/ERLS-based Predictive QoS-Promoted DBA Scheme for 
Upstream Transmission in EPON 
 
The Ethernet passive optical network (EPON), which represents the combinations 
of low-cost Ethernet equipment and low-cost fiber infrastructure, is considered to be 
the cost-effective solution of the optical access network [21]. The EPON system has 
to support triple-play services in optical access networks, and must fulfill the 
quality-of-services (QoS) requirements of each service. Kramer, Mukherjee, and 
 5 
bandwidth reallocation (PFEBR) scheme was introduced in [31], where the modified 
linear estimation credit from DBAM [29] was used to ensure fairness of all ONUs. 
Yin, Luo, Ansari, and Wang proposed a nonlinear prediction-based dynamic 
bandwidth allocation (NLPDBA) scheme [32] to improve the upstream transmission 
efficiency and prediction accuracy. The NLPDBA scheme used the same LMS update 
algorithm as the LSTP scheme [30] and controlled the estimated result for stability. 
However, when the predictor underestimates or overestimates the traffic, it may drop 
packets or waste bandwidth and cannot show how soon it will converge. Thus the 
NLPDBA scheme is hard to decide the precise granted bandwidth for ONUs in the 
next cycle. 
 7 
the CBF will buffer its CB for a span whose length is the same as the FDL. If a DB is 
rescheduled and buffered by an FDL, the CBF buffers the new CB for a period of time. 
The duration of the time period is the difference between the residual time and the 
offset time if the residual time is larger than the offset time, where the residual time is 
defined as the time interval between the current time and the time the DB will be sent 
out in this reschedule. Otherwise, the duration is zero, denoting the new CB will be 
sent immediately. In this way, The offset time can be still kept the same as the original 
one and the router can easily know how many routers the burst still needs to pass 
through.  
 
B. Burst Priority Scheduling with FDL Reassignment (BPS-FR) 
The burst priority scheduling scheme with fiber delay line reassignment (BPS-FR) 
scheme has the following scheduling principles. It makes the longer high-priority 
burst successfully go through a router with large probability by that the high-priority 
burst preempts the low-priority one and further the longer high-priority burst can 
replaces the shorter one. And BPS-FR uses FDLs to reschedule the preempted burst 
and lets a high-priority burst be delayed with a free minimum unit FDL if necessary. 
The flowchart of the BPS-FR scheme is shown in the Fig. 2.  
When a CB arrives, the BPS-FR scheme first sets t, denoted the number of the 
reassignment, to be zero and denotes its DB as b. Then, BPS-FR checks the priority of 
b. If b is low-priority, the scheme finds whether a channel CA with a minimal free 
FDL is available to use (the free FDLs are used from the shortest to the longest). If 
there is no CA, b will be dropped. Otherwise, the scheme assigns b into CA. If b is 
high-priority, BPS-FR first finds whether a channel CA with a minimum unit free FDL 
is available to use. If CA does not exist, it further finds whether a channel CL for b 
with a minimal free FDL is available to use, where the channel CL has given to a set 
of the low priority bursts BL which blocks b and has the minimum sum length. If CL 
exists, the scheme will allocate CL to b, remove the bursts which are in BL from CL 
and denote the longest burst in BL, called bL, as the replaced burst bR. If CL does not 
exist, BPS-FR looks into whether a channel CH for b with the minimal free FDL is 
available to use, where CH has given to a set of the bursts BH which blocks b and has 
the minimum sum length but the sum length of the high-priority bursts is smaller than 
b. If CH exists, the scheme will also allocate CH to b, remove the bursts which are in 
BH from CH and denote the longest high-priority burst in BH, called bH, as bR. If there 
is no CH, b will be dropped. The BPS-FR scheme will reassign bR, unless bR does not 
exist. If there is no free FDL, then the BPS-FR scheme drops bR. Otherwise, the 
number t is added by 1. However, the scheme would end if t is larger than T, where T 
is the maximum reassignment times between the two new successional CBs. If there 
 9 
It can be found that as the traffic load increases, the dropping probability for both two 
schemes increases. We can also find that BPS-FR has the lowest average dropping 
probability, whereas PLAUC-VF has the highest dropping probability. It is due to bR 
will still be reassigned into the wavelength by BPS-FR whether bR is high-priority or 
low-priority. Thus, it can reduce both dropping probabilities of high-priority and 
low-priority bursts. Since the longer high-priority burst which is blocked by some 
short scheduled high-priority and the low-priority ones which blocks some 
high-priority burst will both be dropped. Therefore, the average system dropping 
probability of BPS-FR is better than one of PLAUC-VF. 
 
Fig. 4 (a) and Fig. 4 (b) show the dropping probabilities of low-priority bursts and 
high-priority bursts for different traffic load, respectively. In Fig. 4 (a), the BPS-FR 
has the lowest dropping probability whereas the PLAUC-VF has the highest dropping 
probability. Although the BPS-FR drops the low-priority bursts which belong to BL, it 
reduces the dropping probability by reassigning bR whose length is the longest in BL. 
Therefore, the dropping probability of low-priority in BPS-FR is less than one in 
PLAUC-VF. However, since PBSFA reassigns bR such that the number of the free 
FDLs is decreasing rapidly in high traffic load. Compliantly, the less free FDLs cause 
the dropping probability of low-priority burst arises rapidly in traffic load 0.8. In Fig. 
4(b), the dropping probability of the high-priority burst is also the lowest in BPS-FR 
whereas the dropping probability is the highest in PLAUC-VF. In BPS-FR, a 
high-priority burst has one more chance to preempt the low-priority one which arrives 
later and a longer high-priority burst also can preempt the shorter highpriority burst, 
whereas in PLAUC-VF, a high-priority burst only preempts the low-priority ones 
which arriver between the duration from the high-priority arrival time to departure 
time. Accordingly, the dropping probability of the high-priority burst is the highest in 
PLAUC-VF. 
 
 11 
III. A Maximum Utilization and Minimum Hops 
Scheme for Bidirectional Optical Ring Networks 
A.  System Model  
1.)  Network Architecture 
The network topology considered is a WDM metro ring architecture, which 
consists of N nodes, labeled as 1, 2, …, N counterclockwise. Each node provides 
several passive optical networks (PONs) to building users (BUs). There is a pair of 
fibers between node i and node i+1, 1≤i≤N-1, and also between node N and node 1, 
one carrying traffic stream in counterclockwise direction and the other one carrying 
traffic stream in clockwise direction, in addition, each fiber contains W wavelengths.  
2.)  Node Function and Operations 
Each node in the metro access ring is equipped with an optical add-drop 
multiplexer (OADM), an optical line terminal (OLT), W tunable transmitter/receiver 
pairs, and a fixed transmitter/receiver pair, as shown in Fig. 5 A tunable transmitter 
(receiver) processes the capability of transmitting (receiving) any of W wavelengths. 
The tunable and fixed transmitter executes electrical-to-optical conversion, while the 
receivers execute optical-to-electrical conversion. Additionally, the OADM chooses 
the wavelength whose traffic streams are required to be dropped out of the node.  
An OADM provides three functions. One is that it optically bypasses some 
wavelengths from the incoming links directly to their corresponding outgoing links 
and second is that it optically drops some wavelengths from the incoming links to the 
tunable receivers. Beside, a splitter is imposed on an OADM, so it has the capability 
of tapping a small amount of optical power from a wavelength to a tunable receiver 
and forwarding the rest to its corresponding out-going link. The capability is termed 
as drop-and–continue (DaC) which can support multicast effectively. An OLT grooms 
multiple low-speed streams originating from BUs to a high-speed stream, and extracts 
some low-speed streams out of a high-speed stream. It also can make a copy of the 
traffic stream and have the capability of reconstructing and amplifying the electric 
traffic stream. In addition, it is assumed that each node has the information of total 
traffic streams in each wavelength, and every element in each node is coordinated by 
out-of band control signals. According to the information, the procedure of traffic 
grooming can be executed by the OLT at each node. 
 13 
II and III represent the notations and the definitions we used. For simplicity, the 
following tables only show the notations for counterclockwise direction. The 
notations for clockwise are represented by replacing ccw with cw on the subscript of 
that for counterclockwise (i.e. lccw and lcw). 
 
 Table I: Notation of parameter in mathematical formulation 
    Notation                   Definition 
W The number of wavelength per fiber. We assume all the fibers in the network have 
the same number of wavelength. 
C The capacity of each wavelength.  
(i, j, w) ccw A lightpath which traverse from node i to node j on wavelength w in 
counterclockwise direction without optical-electric conversion. i, j ∈V , i j≠  
and 1 w W≤ ≤ .  
(s, D) A multicast (unicast) call with source s and destination set D= {d1, d2, …, dn} 
where d1, d2…dn are the n destination nodes of the multicast call (in 
counterclockwise order). The multicast (unicast) call may traverse through a 
single or multiple lightpaths.  s D∉  
maxk  Maximum number of destinations on a lightpath (the destinations do not include the originating node of the lightpath)  
Lccw The fiber link from node l to l+1. l∈V  
 
Table II: Notation of the sets in mathematical formulation 
   Notation                   Definition 
L(i, j) ccw A set that consists of all the lightpaths that originate at node i and terminate at 
node j in counterclockwise direction. L(i, j)={ (i, j, w) 1 w W≤ ≤ } 
( , )i ccwC s d  Lightpath set consists of successively non-overlapping lightpaths which form a 
complete path from node s to node id . Each lightpath in the set can’t use the same 
fiber link.  
( , )s DR  The routing complete path for (s,D)  ( , ) ( , )s d s DR ∈Ω  where ( , )s DΩ  is the set 
contains all kind of spanning tree for (s,D). 
 
Table III: Definition and Notation of the variable for mathematical formulation 
Notation                   Definition 
( , )' ccwi jt  The total traffic load carried by lightpaths belonging to L (i, j)ccw after acceptance of new multicast (unicast) call or the release of a out-gong multicast (unicast) call.
i) If a new multicast (unicast) call with traffic load R (3m) is accepted and 
lightpath in L(i, j)ccw is used by the new call ,  
      ( , )' ccwi jt = ( , )ccwi jt +R 
ii)    If an out-going multicast (unicast) call with traffic load R (3m) on lightpath 
belonging to L (i, j)ccw is released.  
      ( , )' ccwi jt = ( , )ccwi jt -R     
iii)   If a new call or a out-going call do not affect the lightpaths belong to L(i, 
j)ccw 
     ( , )' ccwi jt = ( , )ccwi jt      
'( , , )ccwk i j w  The number of destinations on lightpath (i, j, w)ccw (exclude the originating node of the lightpath) after the acceptance of a new call. Note that the destinations on 
the lightpath come from all sessions that use the lightpath. 
( , , )ccwi j w
Z  The lightpath (i, j, w)ccw indicator ( , , )i j wZ =1 if only if a lightpath (i, j, w)ccw 
exists    
( , )' ccwi jb  The number of wavelength in L (i, j)ccw after the acceptance of a new multicast (unicast) call or the release of an on-going multicast (unicast) call. 
 15 
z Light power constraint: 
       
max( , , ) 'ccwk i j w k≤ , , ,i j w∀ ,                                      …..(8) 
max( , , ) 'cwk i j w k≤ , , ,i j w∀ ,                                     .....(9) 
z Routing constraint: 
      
1 ( , )( , ) ( , )i ccw i cw s DC s d C s d R+∪ = , 1 0, 1, ,, { ... }i i nd d d d d+ ∈ ,                   .(10) 
 
The traffic constraint represents that the traffic from node i to node j must be less 
than the maximum capacity. The lightpath constraint indicates that the bound imposed 
by the total number of wavelengths. The wavelength assignment constraint expresses 
that a wavelength in the same fiber link can only be assigned to a lightpath. The light 
power constraint indicates a lightpath at most passes max 1k −  splitters. So there are at 
most maxk  destinations on a lightpath. The routing constraint expresses the traffic 
stream must be groomed according to the route.  
The dynamic traffic-grooming problem can be seen as a static one from the 
snapshot view. When a new call arrived or a current call left, it could be considered as 
a new traffic matrix. However, the complex computation is needed to find the optimal 
solution for the new traffic matrix and many current calls are necessary to be 
rearranged. The optimal solution is impractical for dynamic model. Therefore, we 
propose a new heuristic scheme, called Maximum Utilization and Minimum Hops 
(MUMO) scheme, to solve the problem. The MUMO is divided into two main parts: 
multicast traffic routing with minimum hops, and multicast traffic grooming with 
maximum utilization. 
1.)  Multicast Traffic Routing With Minimum Hops 
We give a brief overview about the routing of multicast call in ring networks and 
propose an adaptive routing scheme. We consider a new call with source s and 
destination set D={d1,d2,…,dn} (in counterclockwise order) arrivals. The ring would 
be divided into { }s D∪ =n+1 arcs by the source and the destinations. Let d0=s and 
Arc(s,D)={q0 1d d ,q1 2d d ,…, q0nd d }={A0, A1,…, An} be the set which contains all arcs. A 
possible route can be obtained by omitting one of the arc in Arc(s,D). If the arc q1i id d +  
is absent, the traffic from source s to {d1,d2,…,di} will use the fiber links in 
 17 
spanning tree (CMST) route. The CMST is the route in which the least resources are 
used under the constraint that there are unsatisfactory fiber links. In CMST, if all 
unsatisfactory links are in the same direction, we will find the arc contains the 
unsatisfactory link which closest to source along the direction. Then, all arc before the 
arc which contains the first unsatisfactory link (include itself) can be chosen to be the 
omitting arc. We will choose the longest one. However, if there are unsatisfactory 
links in both direction. We will do above action for both directions, respectively. Then 
we will find the common arc that can be chosen to be the omitting arc for both 
directions. We will choose the longest one in these common arcs. 
2.)  Multicast Traffic Grooming With Maximum Utilization  
After we decided the route, we divide the new call into two sub-calls: 
counterclockwise sub-call, denoted by Sccw, and clockwise sub-call, denoted by Scw. 
We let S= {Sccw, Scw} be the sub-call set. Fig. 7 is the flowchart of arranging a new 
call. A sub-call can be arranged into network by two ways: grooming with current 
lightpaths (which is called grooming subproblem) and setting up new lightpaths 
(which is called wavelength assignment subproblem).  
i. Grooming subproblem 
This subproblem is considered as how to groom the traffic of a sub-call into 
lightpaths suitably according to a decided route. It’s due to that the utilization 
efficiency of used wavelengths increases as long as the sub-calls can be groomed with 
the used lightpaths. We propose a grooming scheme which contains two parts: directly 
grooming and partially grooming. Directly grooming is to find a direct lightpath to 
groom, and the lightpath has the same source and terminating node as the sub-call and 
also has enough capacity to satisfy the sub-call. After grooming with the sub-call, the 
number of destinations of the lightpath must less or equal to kmax. If we directly 
groomed successfully, the arrangement of the sub-call would end. If we cannot find a 
direct lightpath, we will find a lightpath to partially groom. We first search a 
co-destination lightpath which is similar to a direct lightpath but is allowed to have 
different source as the sub-call. If there is no co-destination lightpath, then we search 
a partial-destination lightpath which has the same source and the terminating node of 
the lightpath is one destination of the sub-call. We will choose one of several satisfied 
partial-destination lightpaths, which can arrange maximum number of destinations of 
the sub-call to partially groom. After partially grooming, the remained part of the 
sub-call forms a new sub-call and we repeat above action until we can’t find any 
lightpath to groom or the whole sub-call has been groomed. 
 19 
ii. Wavelength assignment subproblem 
After the grooming block, the whole sub-call or partial sub-call may not be 
arranged into the ring by grooming. We need to setup new lightpaths for the whole 
sub-call or partial sub-call. This subproblem is how to assign a wavelength to create 
new lightpaths. We assign wavelength under the constraint which any two lightpaths 
pass through the same fiber link are assigned different wavelengths. Although many 
wavelength-assignment approaches were proposed, all of them were found to perform 
similarly. Because of the result, we choose the simple approach, first-fit, to solve the 
wavelength assignment subproblem. In first-fit, all wavelengths are numbered as 1, 2, 
3…W. When we want to setup a new lightpath, we will search an available 
wavelength according to number. An available wavelength with the least number will 
be considered first. As we setup new lightpath for a sub-call, the number of 
destinations of the sub-call may be larger than kmax. We may need to setup more than 
one lightpath. We will try to setup new lightpath for the first kmax destinations of the 
sub-call. if we setup successfully, the rest part of the sub-call form a new sub-call and 
then retry to find lightpath to groom.  
C.  Simulation Results  
In this section, we show the performance of the MUMO scheme and the 
comparisons with other grooming schemes. In the network we simulated, each fiber 
contains 20 wavelengths. The capacity of each wavelength is OC-48 (2.5G/s). The 
MUMO scheme was compared with other schemes in different cases. The MUMO 
scheme is compared with the two schemes: Single-Hop (SH) and Hybrid Multi-Hop 
(HYMH).The simulation results of the comparisons in these cases are presented and 
discussed.  
Two performance measurements for MUMO, SH and HYMH are revealed. The 
first is about the new call blocking rate of the three schemes. The second is about the 
utilization efficiency of the used wavelength of the three schemes. According to these 
issues, there are two kinds of graphs in the simulation.  
Assume that the network parameters: W=20, N=20, C=48, maxk =10, mμ =0.05, 
R= {1, 3, 12, 16}, 1 2 3 4( , , , )p p p p   = (0.25, 0.25, 0.25, 0.25) is considered in the Fig. 8, 
Fig. 9, and Fig. 10. As for the multicast ratio, the arrival rate and the max number of 
destination of a multicast call, we will give these parameters for each different figure. 
Fig. 8 and Fig. 9 show the blocking probability and the utilization efficiency of the 
used wavelength versus traffic load, respectively, where the ratio of multicast call is 
0.5 and the max number of destination of a multicast call is 19. It can be seen that the 
blocking probability of the MUMO scheme is much less than that of the other two 
schemes and the utilization efficiency of the MUMO scheme is much higher that of 
the others. It is because the MUMO scheme would search partial-destination lightpath. 
 21 
Fig. 10 shows the blocking probability versus the ratio of multicast calls where, 
the arrival rate is 10 (call/sec) and the max number of destinations of a multicast call 
is 19. It can be seen that the blocking probabilities of the MUMO scheme increases 
much slower than that of the other two schemes as the multicast ratio increases. It is 
because that they cannot deal with the multicast traffic efficiently. Beside, the MUMO 
scheme only needs to find the lightpath that has the same terminating node; it helps a 
multicast call finding lightpaths to groom. It also can be found that the HYMH can 
have good performance when all traffics are unicast. As the multicast ratio increases, 
the blocking probability of HYMH increases rapidly. When the multicast ratio up to 
0.8, the blocking probability of HYMH even higher than the blocking probability of 
SH. It results from that the HYMH may serve a new call with provisioned and 
un-provisioned lightpaths, the HYMH scheme may setup a new lightpath that only 
one destination on the new lightpath. Since the HYMH scheme need to find a 
lightpath has the same destinations as the destinations of the new call; these lightpaths 
may be groomed hardly when the multicast ratio is high. 
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
Multicast Ratio 
B
lo
ck
in
g 
P
ro
ba
bi
lit
y
 
 
HYMH (20,20,10)
SH (20,20,10)
MUMO (20,20,10)
 
Figure 10 The blocking probability versus multicast ratio 
 
Fig. 11 reveals that the blocking probability versus the maximum number of 
destination of a multicast call, where arrival rate is 10 (call/sec) and the ratio of 
multicast calls is 0.5. As the max number of destinations increases, it becomes hard 
for the SH scheme and HYMH scheme to find a lightpath to groom. Then, the 
blocking probabilities of the two schemes increase slowly. As for the MUMO scheme, 
from Fig. 7, when the number of destinations is less than 11, the blocking probability 
 23 
IV. PRNN/ERLS-based Predictive QoS-Promoted 
DBA Scheme for Upstream Transmission in EPON 
 
A.  System Model 
Assume that there is one optical line terminal (OLT) and M optical network units 
(ONUs) split by 1: M splitter in an EPON system. The line rate is RE bps between 
OLT and each ONU, and the line rate RU bps between ONU and its own end users. 
Two wavelengths are used to serve downstream and upstream traffic individually. The 
system supports three types of services, real-time voice, real-time video, and 
non-real-time data. In ONUi, three types of queues are provided to store real-time 
voice, real-time video, and non-real-time data packets, which are denoted by Q0,i, Q1,i, 
and Q2,i, respectively, 1 ≤ i ≤ M. The incoming packets from users will be put into the 
corresponding queues at ONU according to their service types. The arriving packet 
will be dropped if its queue is full, and the packet will be discarded if its QoS 
requirement is violated. 
There is a GATE (REPORT) message sent from OLT (ONU) to ONU (OLT) to 
manage the transmission between OLT and ONUs. Fig. 13 shows the upstream 
transmission between the PQ-DBA at OLT and ONUs in an EPON system. Assume 
that the EPON system is at the present cycle (n − 1), which starts from when OLT 
sends the GATE message for ONU1 at cycle (n − 1), denoted by G1(n − 1), to when 
the OLT sends the G1(n) for the next cycle n. The PQ-DBA assumes a prediction 
interval for ONUi at cycle (n − 1), denoted by Ti(n − 1), 1 ≤ i ≤ M, which starts from 
when OLT receives the first packet from ONUi with the (n − 1)-th REPORT message 
(at time Ti of Fig. 1) to when OLT receives the first packet of ONUi with the n-th 
REPORT message (at time TM+i of Fig. 1). The Ti(n − 1) is not necessarily equal to the 
Tj(n − 1), n∀ , when i ≠ j, and 1 ≤ i, j ≤ M. Also assume that the PQ-DBA can know 
when the TM+i will be. 
The GATE message for ONUi at cycle (n − 1), Gi(n − 1), is a set of {G0,i(n − 1), 
G1,i(n − 1), G2,i(n − 1)}, where Gm,i(n − 1) denotes the granted bandwidth for the type 
m of service traffic in ONUi, m∈ {0, 1, 2}, 1 ≤ i ≤ M. When the ONU receives the 
GATE message from the OLT, it transmits packets at its assigned timeslot and 
piggybacks a REPORT message at the end of the packet. The REPORT message from 
ONUi to OLT at cycle (n − 1), denoted by Ri(n − 1), is a set of {L0,i(n − 1), L1,i(n − 1), 
L2,i(n − 1), Ldp,i(n − 1), Ld,i(n − 1), Lw,i(n − 1)}. The Lm,i(n − 1) is the occupancy of 
queue Qm,i at cycle (n − 1), m∈ {0, 1, 2}, and the Ldp,i(n − 1), Ld,i(n − 1), and Lw,i(n − 
1) are numbers of bytes that had better be transmitted at the next cycle otherwise these 
 25 
transmitted at the next cycle. The x is given in Eq. (11). Thus, a number of packets 
among these x packets, denoted it by y, must be transmitted otherwise the requirement 
of video packet dropping probability, Pd*, will be violated. Then y can be obtained by 
          ⎡ ⎤ +×−+= )  ( *dd PNxNy ,                          ( 1 3 ) 
where (a)+ = a if a ≥ 0, (a)+ = 0 if a < 0; and ⎡ ⎤b  denotes the smallest integer greater 
than b.  Then the Ld,i(n − 1) can be derived by 
          ∑
=
=−
y
k
kid SnL
1
,1,   1)( ,                            ( 1 4 ) 
where Sk,1 means the number of bytes of the k-th packet’s size in Q1,i, 1 ≤ i ≤ M. 
The Lw,i(n − 1) is the total amount of bytes of non-real-time data packets whose 
waiting time will be larger than a starvation-threshold time, denoted by Tw*, at the 
next cycle. It tells OLT how much bandwidth is required for non-real-time data 
packets in Q2,i to prevent starvation. Denote Tw,k to be the waiting time of the k-th data 
packet in Q2,i of ONUi, 1 ≤ i ≤ M, at the present cycle (n − 1). Then a number of 
packets with a waiting time larger than the starvation-threshold time, Tw*, had better 
be served at the next cycle. Denote the number of packets to be z, and the z is given 
by 
          }  and , , ,{ min arg *,
*
, 0TTikTTz wkwwkwk >−∀−=                  (15) 
Then the Lw,i(n − 1) can be obtained by 
          ∑
=
=−
z
k
kiw SnL
1
,2,   1)( ,                           ( 1 6 ) 
where Sk,2 means the number of bytes of the k-th packet’s size in Q2,i, 1 ≤ i ≤ M. The 
non-real-time data packets do not have strict delay criterion, but they ought to be 
protected from such an unfair condition by an inappropriate bandwidth assignment. 
Similar to the random early detection (RED) scheme [33], the starvation-threshold 
time Tw* starts a mechanism to keep data packets from reaching a starvation situation. 
 
B.  PQ-DBA Scheme 
The PQ-DBA begins the prediction procedure for the i-th ONU when it receives 
the i-th ONU REPORT message at the present cycle (n − 1), Ri(n − 1), 1 ≤ i ≤ M. It 
adopts a pipeline recurrent neural network/extended recursive least square 
(PRNN/ERLS) for prediction, which has good nonlinear prediction capability and fast 
convergent time. When the predictions for all ONUs have accomplished, the PQ-DBA 
performs the bandwidth allocation. The PQ-DBA scheme classifies the three types of 
 27 
1)),(~ ..., 2),(~  1);( ..., 2),((1)(~ ,,,,, −−−−−−=− qnnpnnHn imimimimim λλλλλ  
                                                                 (19) 
where H( • ) is an unknown nonlinear function and the PRNN is adopted to 
approximate it. The PRNN refers to the RNN predictor with a pipelined structure, 
which consists of q levels of processing, and each level has a RNN module with N 
neurons, (d + N + 1) input nodes and a comparator, where d = p − q + 1 and q × N = 
R.  
Here the extended recursive least square (ERLS) is applied as the learning 
algorithm for PRNN. In order to reduce the complexity, all the modules of the PRNN 
are designed to have exactly the same synaptic weight matrix. Hence, each level of 
the PRNN is a sub-prediction and each RNN module has a prediction error, and the 
total prediction errors of the PRNN predictor must be combined for weight adjustment. 
The prediction errors for the k-th RNN module around prediction interval Ti(n − 1), 
denoted by ek(n − 2), 1 ≤ k ≤ q, and for the PRNN predictor, denoted by Em,i(n − 2) are, 
respectively, defined as 
          ),2()1()2( , −−−−=− nyknne kimk λ                      (20) 
and 
          ),2()2( 21
1
, −=− −
=
∑ nenE kkq
k
im ξ                         (21) 
where yk(n − 2) is the output of k-th RNN module, and ξ ∈  (0,1] is the forgetting 
factor. The term ξ k−1 is an approximate measure of the memory of the individual 
modules in the PRNN. The cost function of ERLS, denoted by )2(ERLS −nε , is 
defined as 
          ).()2( ,
2
2  
1
ERLS kEn im
kn
n
k
−−−
=
∑=− ξε                         (22) 
The ERLS algorithm minimizes the cost function in Eq. (22) and then updates 
the weights of the neurons in the modules accordingly. The ERLS considers present 
and previous errors, so it can minimize the margin of errors. When the PRNN/ERLS 
predictor has finished the prediction of the packet arrival rate during Ti(n − 1), 
1)(~ , −nλ im , the amount of estimated arrival packets of Qm,i in bytes at prediction 
interval Ti(n − 1), m∈ {0, 1, 2}, 1 ≤ i ≤ M, denoted by 1)  (~ , −nD im , can be calculated 
by 
          .1)(1)(~ 1)(~ ,,  nTnλnD iimim −×−=−                       (23) 
 29 
priorities 
To ensure the QoS requirements of video packets, the PQ-DBA secondly 
allocates the bandwidth to the video packets which will be dropped if they are not 
transmitted at the next cycle. Denote '1,iG  as the allocated bandwidth to video 
packets with the second and the third priorities in Q1,i. Based on the reported video 
packet with problem of dropping probability and delay, Ld,i, Ldp,i, and the residual 
bandwidth of fiber link, ∑
=
−
M
i
iGB
1
'
0, , the allocated bandwidth to video packets with 
the second and the third priorities '1,iG  is given by 
    
⎪⎪
⎪⎪
⎪⎪
⎩
⎪⎪
⎪⎪
⎪⎪
⎨
⎧
≤−×−
<−<
−
−×+−+
≥−
=
∑∑∑∑
∑∑∑∑∑
∑∑
==
=
+
=
===
=
=
+
==
M
i
id
M
i
iM
i
id
id
M
i
i
M
i
idp
M
i
i
M
i
idM
i
ididp
ididp
M
i
idiid
M
i
idp
M
i
iidp
i
LGB
L
L
GB
LGBL
LL
LL
LGBL
LGBL
G
1
,
1
'
0,
1
,
,
1
'
0,
1
,
1
'
0,
1
,
1
,,
,,
1
,
'
0,,
1
,
1
'
0,,
'
1,
.  if                                   ,  )(
, if , 
)(
])[(
, if                                                                 ,
(26) 
[Step 3]: Bandwidth allocation to data packets with the fourth priority 
The PQ-DBA continues to allocate the bandwidth to the data packets whose 
waiting time exceeds the starvation-threshold time Td*, to ensure QoS requirement of 
data service and avoid starvation. Denote '2,iG  as the allocated bandwidth in Q2,i. 
Based on the amount of reported data packets considering starvation, Lw,i, and the 
residual bandwidth of fiber link, ][ '1,
1
'
0, i
M
i
i GGB +− ∑
=
, '2,iG  is given by 
          
⎪⎪⎩
⎪⎪⎨
⎧
×+−
>+−
=
∑∑
∑∑
=
+
=
==
.elsewhere ,  ])[(
, ][ if              ,
1
,
,'
1,
1
'
0,
1
,
'
1,
1
'
0,,
'
2,
M
i
iw
iw
i
M
i
i
M
i
iwi
M
i
iiw
i
L
L
GGB
LGGBL
G                (27) 
[Step 4]: Bandwidth allocation to video packets with the fifth priority 
The PQ-DBA assigns the bandwidth to the unallocated video packets. Denote ''1,iG  as 
 31 
     
⎪⎪
⎪
⎩
⎪⎪
⎪
⎨
⎧
+
×++++−=
+
×++++−=
∑∑
∑∑
=
+
=
=
+
=
. 
)(
])[(
, 
)(
])[(
1
1,0,
1,''
2,
''
1,
'
2,
'
1,
1
'
0,
'''
1,
1
1,0,
0,''
2,
''
1,
'
2,
'
1,
1
'
0,
''
0,
M
i
ii
i
iiii
M
i
ii
M
i
ii
i
iiii
M
i
ii
PP
P
GGGGGBG
PP
P
GGGGGBG
          (30) 
[Step 7]: GATE message generation 
Based on the allocated bandwidth, '0,iG , 
'
1,iG , 
'
2,iG , 
''
0,iG , 
''
1,iG , 
''
2,iG  and 
'''
1,iG , 
the final granted bandwidth in GATE message iG0, , iG1, , and iG2,  for ONUi are 
given by 
          ,
,
2,2,2,
1,1,1,1,
0,0,0,
⎪⎪⎩
⎪⎪⎨
⎧
+=
++=
+=
.GGG
GGGG
GGG
''
i 
'
i i
'''
i 
''
i 
'
i i
''
i 
'
i i 
                            ( 3 1 ) 
The { iG0, , iG1, , iG2, } are included in the GATE message iG , and the OLT sends 
the GATE message to the ONUi, 1 ≤ i ≤ M. Each ONU follows the information in the 
GATE message to transmit its own packets. At the same ONU, if there is some 
bandwidth left at some queues, the rest bandwidth can be reallocated to other queues 
of the same ONU. The PQ-DBA scheme not only decreases packet delay and packet 
dropping probability but also increases bandwidth efficiency. 
 
C.  Simulation Results and Discussions 
An event-driven packet-based simulation is elaborated to show the performance 
comparison among three upstream transmission schemes: the proposed PQ-DBA, the 
proposed PQ-DBA but without prediction, and the DBAM [29]. In the simulations, 
the considered EPON system is in an OLT with 32 ONUs connected configuration, 
and there is one 1:32 splitter located at 20 km away from OLT, and at 5 km distance to 
each ONU. The downstream rate RE = 1 Gbps, and the upstream rate RU = 100Mbps. 
Each queue in ONU is with the same buffer space of 1 Mbytes. The guard time for 
laser ON/OFF between each ONU transmission is set to 1 μs. For simulation 
convenience, the system cycle and the prediction interval of all ONUs are assumed to 
be fixed at 0.72 ms. Every simulation result includes 100 simulation cycles, and each 
of which contains 1,000 updating periods. As for the PRNN predictor, parameters are 
 33 
constraint, it can be found that the proposed PQ-DBA has higher system utilization 
than the DBAM and the PQ-DBA without prediction by an amount of 4%, and 2% in 
average, respectively. It is because the PQ-DBA and the PQ-DBA without prediction 
allocate bandwidth step by step to six priorities, rather than the DBAM by a limited 
bandwidth allocation (LBA)to each class in advance. Also, the PQ-DBA and the 
PQ-DBA without prediction dynamically promote some video packets cycle by cycle 
to avoid packet dropping due to the violation of delay requirement, whereas the 
DBAM scheme just applies priority queueing. Moreover, the PRNN/ERLS also helps 
the PQ-DBA scheme to enhance the efficiency of bandwidth allocation by providing 
more precise estimation and thus more accurate allocation bandwidth for ONUs than 
the PQ-DBA without prediction and the DBAM scheme with linear prediction. 
Fig. 15 shows the average voice packet delays versus traffic intensity. It can be 
observed that as traffic intensity is larger than 0.3, the average voice packet delay of 
the PQ-DBA outperforms by about 21 % and 26 % in average over the DBAM 
scheme and the PQ-DBA without prediction, respectively. It is because the PQ-DBA 
with PRNN/ERLS makes a precise prediction for new voice packet arrivals during 
each prediction interval. The DBAM also adopts prediction, but the prediction is 
linear which would be less sophisticated than the nonlinear PRNN/ERLS. Notice that 
the three schemes have the voice packets as the first priority to serve. 
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0
1.1
1.2
1.3
1.4
1.5
1.6
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
Traffic Intensity
V
oi
ce
 P
ac
ke
t D
el
ay
 (s
)
DBAM
PQ-DBA w/o predictor
PQ-DBA
x 10
-3
Voice Delay Requirement
 
Fig. 15.  The average voice packet delay versus traffic intensity. 
Fig. 16 shows the average video packet delay versus the traffic intensity. It can 
be observed that the video packet delays of the three schemes are within the delay 
requirement when the traffic intensity is below 0.9. The PQ-DBA with PRNN/ERLS 
improves the video packet delay time by about 90% better than that in DBAM scheme 
(and 29% over PQ-DBA without prediction) when the traffic intensity is below 0.8. It 
is because the PQ-DBA makes the video packet with the problem of delay 
requirement be transmitted with a higher priority in order to decrease the delay and 
 35 
0.0
0.1
0.2
0.3
0.4
0.5
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
Traffic Intensity
D
at
a 
Pa
ck
et
 D
el
ay
 (s
)
DBAM
PQ-DBA w/o predictor
PQ-DBA
Data Starvation Threshold
 
Fig. 17.  The average data packet delay versus traffic intensity. 
 
 37 
[14] J. Xu and Q. Zeng, “Dynamic traffic grooming in interconnected WDM SDH/SONET rings,” 
IEEE Proceeding of SPIE Opticomm, vol. 4527 2001. 
[15] K. Zhu and B. Mukherjee, “Dynamic Traffic Grooming in Optical WDM Mesh Networks with 
Distributed Control,” IEEE Proceeding of SPIE Opticomm, vol.4585, 2001. 
[16] A. Khalil, C. Assi, A. Hadjantonis, G. Ellinas and A. Ali,”On Multicast Traffic Grooming in 
WDM Networks,” IEEE ISCC, vol. 1, pp.282-287, July 2004.  
[17] A. Khalil, A. Hadjiatonis, and M. Ali, “Sequential and Hybrid Grooming Approaches for 
Multicast Traffic in WDM Networks,” IEEE GLOBECOM, vo3, pp.1808-1812, Dec 2004. 
[18] C. Lu, X. Nie and L. Li, “Efficient Dynamic Multicast Traffic Grooming Algorithm on WDM,” 
Proc. of SPIE, vol. 6022, no.30 pp.1-9, 2003.  
[19] D. Buchfuhrer, T. Carnes and B. Tagiku, “Traffic Grooming for Single-Source Multicast 
Communication in WDM Rings,” IEEE ICC, vol.3 pp.1613-1619, May 2005. 
[20] H. V. Madhyastha, N. srinvas, G. V. Chowdhary and C. Siva ram Murthy, “Grooming of Multicast 
Sessions in WDM Ring Networks,” Proc. Optical Networking and Communications, pp.1-12, 
Oct. 2003.  
[21] MaGarry, M. P., Maier, M., Reisslein, M., “Ethernet PONs: A survey of dynamic bandwidth 
allocation (DBA) algorithms” IEEE Optical Communications, vol. 42, pp. S8- 15, 2004. 
[22] Kramer, G., Mukherjee, B., Pesavento, G, “IPACT: A dynamic protocol for an Ethernet PON 
(EPON)”, IEEE Communication Magazine, vol. 40, pp. 74-80, 2002. 
[23] IEEE Standard 802.3ah-2004. 
[24] Cheng, H., Chen, M., Xie, S., “A dynamic bandwidth allocation scheme supporting different 
priority services in EPON”, Proceedings of International Society for Optical Engineering (SPIE), 
pp. 1123-1127, 2005. 
[25] Assi, C. M., Ye, Y., Dixit, S., Ali, M. A., “Dynamic bandwidth allocation for quality-of-service 
over Ethernet PONs”, IEEE Journal on Selected Areas in Communications, vol. 21, pp. 
1467-1477, 2003. 
[26] Xie, J., Jiang, S., Jiang, Y., “A dynamic bandwidth allocation scheme for differentiated services 
in EPONs”, IEEE Communications Magazine, vol. 42, pp. S32-S39, 2004.  
[27] Yang, Y., Nho, J., Mahalik, N. P., Kim, K., Ahn, B., “QoS provisioning in the EPON systems 
with traffic-class burst-polling based delta DBA”. IEICE Transaction on Communications, vol. 
 39 
VI. Comment 
A. Burst Priority Scheduling with FDL Reassignment for Optical Burst Switch 
Networks 
We have proposed a new channel-scheduling scheme called burst priority 
scheduling with FDL reassignment (BPS-FR) in OBS networks using PPJET signal 
protocol. Since the high-priority burst (real-time packets) is more important than the 
low-priority burst (non-real-time packets) and the shorter burst is more easily 
scheduled into the void than the longer one, BPS-FR allows high-priority bursts to 
preempt low-priority bursts and longer high-priority bursts to replace shorter ones. 
However, in order to reduce the dropping probability due to the preempted bursts, 
BPS-FR reschedules the longest and highest-priority burst between those preempted 
bursts by using FDL assignment. Through simulation experiments, BPS-FR achieves 
43% improvement in the average system dropping probability and reduces 75% in the 
dropping probability for low-priority traffic over PLAUC-VF. 
This method was accepted by the tenth IEEE International Conference on 
Communication Systems in Singapore from 31st October to 2nd November. It can 
prove that the scheme is trusted and worth to implement. The scheme effetely uses the 
FDLs to re-deal with the preempted low-priority burst and lets the high-priority burst 
have the highest priority to make the bandwidth reservation. The burst priority 
scheduling with FDL reassignment (BPS-FR) scheme with predictor is a good 
research to reduce the dropping burst probability. 
B. A Maximum Utilization and Minimum Hops Scheme for Bidirectional 
Optical Ring Networks 
We propose the MUMO scheme to solve a dynamic multicast traffic routing and 
grooming problem in a bi-directional ring network and to effectively maximize the 
utilization and reduce the new call blocking rate. The MUMO scheme contains two 
main parts, multicast traffic routing with minimum hops and multicast traffic 
grooming with maximum utilization. The multicast traffic routing determines the 
route of a new call with minimum hops distance. The multicast traffic grooming 
decides how to arrange the new call into the network according to the route chosen by 
the routing scheme. The utilization of used wavelength can be increased and the new 
call blocking rate can be reduced by the MUMO scheme. 
The MUMO scheme is compared to the two conventional schemes: single-hop 
(SH) and hybrid multi-hops (HYMH) scheme here. Simulation results show that the 
performance of the MUMO scheme always performs better than those of SH and 
HTMH scheme in all kinds of parameter setting. The results demonstrate once again 
the superiority of the MUMO scheme. The MUMO scheme is sophisticated and 
