 1
具錯誤更正能力之訊息碼-其整合式訊源/通道編解碼設計 
Joint Source/Channel Coding Schemes for Error-Correcting Entropy Codes 
計畫編號：NSC 95-2221-E-260 -029 -MY2 
執行期限：95 年 8 月 1 日至 97 年 10 月 31 日 
計畫主持人：黃育銘   國立暨南國際大學資訊工程學系助理教授 
Email : ymhuang@csie.ncnu.edu.tw
 
摘要 
在一個頻寬有限且錯誤率比較高的無線通道裏傳送多煤體資料。首先，音訊、影像、
或視訊資料都得透過訊源編碼（source coding）技術，以降低其龐大之資料量。霍夫曼碼
（Huffman code）及算術碼（arithmetic code）是目前廣範地被採用之兩種訊息碼（entropy 
codes）。接者，通常對於壓縮過的資料會反過來加入一些多餘訊息（redundancy），即所
謂通道編碼（channel coding），藉以保護壓縮過的資料。上述作法，通常採用Shannon 的
分離理論（separate theory），也就是訊源編碼與通道編碼獨自設計，理論上整體系統效能
不減，不過，這只適用於訊源編碼及通道編碼都是最佳時方成立(也就是訊源編碼能除去訊
源裏之所有多餘訊息作最佳壓縮，而通道編碼能更正所有通道錯誤)。實際上，訊源編碼與
通道編碼分離設計，其整體系統複雜度不見得比較低且效能也未必佳，因此，如何整合這
兩種技術將是一個非常具有挑戰性及相當豐富的研究題材。 
在本計畫裏，首先，我們將針對霍夫曼碼及算術碼，從訊息碼本身如何重新設計，使
其更能具有：抗雜訊（error-resilient）、錯誤偵測（error-detecting）、低編解碼之
計算複雜度（low-computational complexity）等特性。接者，探討如何利用較具抗雜訊
能力之訊息碼的特性及壓縮資料裏之某種結構（有較多多餘訊息）性質，設計一
Trellis-based Maximum A Posteriori (MAP) 解碼演算法，具有錯誤偵測，甚至錯誤更正
等能力，也就是，此時該Trellis-based MAP 解碼演算法同時具有訊源解碼器及通道解碼
器的功能。最後，更進一步地研究如何加入適當的通道碼，以再提升整體系統效能。 
 
關鍵詞：訊息碼、霍夫曼碼、算術碼、訊源編碼、通道編碼、抗雜訊、錯誤蔓延、錯誤偵
測、錯誤更正 
 
 
 
 3
z 霍夫曼碼：許多圖像或視訊壓縮標準，例如：JPEG、 MPEG-1、MPEG-2、H.263++ 等，
都採用這類變動長度碼（ Variable Length Code，VLC）技術。 
z 算術碼：JPEG2000 及 MPEG4 壓縮標準採用。 
然而無論採用霍夫曼碼或算術碼編碼後之位元串流（bit-stream），當傳輸通道有雜訊
時，相當不具有抗錯（error-resilient）能力，也就是說，在傳送的位元串流中，僅僅只有一
個位元發生錯誤，對解碼器來說，就足以造成一連串的解碼錯誤，此現象即所謂錯誤蔓延
（error-propagation）。 
接者，為解決這個問題，通常對於壓縮過的資料會反過來加入一些多餘訊息
（redundancy），即所謂通道編碼（channel coding），藉以保護壓縮過的資料。 
上述作法，通常採用 Shannon [2] 的分離理論（separate theory）方式，也就是訊源編
碼與通道編碼獨自設計，理論上整體系統效能不減，不過，這只適用於訊源編碼及通道編
碼都是最佳時方成立(也就是訊源編碼能除去訊源之所有 redundancy 作最佳壓縮，而通道編
碼能更正所有通道錯誤)。但是，資料的特性往往相當複雜，redundancy 不容易地被單一壓
縮技術就能完全消除，往往仍保有一些資料彼此相關的訊息，且對各種通道，有不同的通
道特性，因此要找出最佳的通道編碼方式也實屬不易。所以，訊源編碼與通道編碼獨自設
計，其整體系統複雜度不見得比較低且效能也未必佳[3]，因此，存在訊源間彼此的相關性
在未被壓縮技術完全消除情況下，如何整合訊源及通道編碼這兩種技術將是一個非常具有
挑戰性及相當豐富的研究題材。 
Guillemot and Christ [4] 在他們的文章(Joint source-channel coding as an element of QoS 
framework for ‘4G’ wireless multimedia)裏，詳細指出整合訊源 / 通道編碼（ Joint 
Source/Channel Coding (JSCC)） 技術為未來在 4G 無線通道裏傳送多煤體資訊，例如：
MPEG4 視訊等，其重要核心技術之一。 
文獻上，JSCC 技術，跟據[5]，主要有以下三類： 
z Concatenated Joint Source/Channel Coding 
串接某一訊源編碼器（source encoder）及某一通道編碼器（channel encoder），在某
一固定位元率（bit per second, bps）通道下，如何分配最後在通道上所傳送的總位元，
其分別由訊源編碼器及通道碼編碼器所產出，那些是由訊源編碼器所輸出？那些是由
通道編碼器所輸出？ 以達到最佳系統效能。 
z Unequal Error Protection Joint Source/Channel Coding 
某一訊源編碼器所產生的各個位元，當在通道上傳輸時，受雜訊影響可能遺失或改變，
對訊源解碼器（source decoder）所重建回來的原始影像或視訊，會造成不同程度的品
算法。 
z VLECC 再串接一迴旋碼(convolutional code; CC) 其最佳/次佳整合式訊源/通道解碼演
算法。 
 
(A) Reverse Variable-Length Codes (RVLCs) with minimum average codeword length 之建構演
算法 
Table I. COMPARISON OF VARIOUS SYMMETRICAL RVLCS 
FOR THE CANTERBURY CORPUS FILE SET 
 
Table II. COMPARISON OF VARIOUS ASYMMETRICAL RVLCS 
FOR THE CANTERBURY CORPUS FILE SET 
 
Table III. Symmetrical RVLC (256 codewords) for Kennedy.xls with average codeword length = 
4.21507667, maximum codeword length = 17, and bit length vector = 
 5
4.65015, maximum codeword length = 12, and bit length vector = (0,0,1,6,8,8,7,5,8, 10,14,7) 
000 
0010 
0100 
0110 
1001 
1010 
1011 
00111 
01110 
01111 
10001 
11100 
11101 
11110 
11111 
001100 
001101 
010101 
010111  
100001 
110011 
110101 
110111 
0101100 
0101101 
1000001 
1100011  
1100101 
1101100 
1101101 
01010011 
10000001 
11000011 
11000101 
11010011 
010100011 
010100101 
100000001 
110000011 
110000101 
110010011 
110100011 
110100101 
0101000011 
0101000101 
1000000001 
1100000011 
1100000101 
1100010011 
1100100011 
1100100101 
1101000011 
1101000101 
01010000011 
01010000101 
01010010011 
10000000001 
11000000011 
11000000101 
11000010011 
11000100011 
11000100101 
11001000011 
11001000101 
11010000011 
11010000101 
11010010011 
010100000101
010100010011
010100100011
010100100101
100000000001
110000000011
110000000101
表一、利用 A*演算法觀念, 我們分別對 symmetrical RVLCs 及 asymmetrical RVLCs，提出
該碼之建構演算法，讓這些碼均擁有最小平均字碼長度(average codeword length), 如
TableI-TableIV 所示。 
 
(B) Variable-Length Error-Correcting Codes (VLECCs) 之最佳/次佳整合式訊源/通道解碼演
算法 
Let  be a binary variable-length code (VLC) that has C K  codewords  with 
corresponding probabilities 
1 2
{ ,..., }
Kc c c,
1 2{ ,..., }Kp p p, . The respective lengths of the codewords are 
1 2{ ,..., }K,A A A . A bitstream, , is a concatenation of  codewords from . Let X L C
1 2( ,..., )LX x x x= , , the length in bits of the -th codeword be k kx| | , and 1
L
kk
N x== |∑ |  be the 
length of the bitstream in bits. In this work, the bitstream is transmitted over an additive white 
Gaussian noise (AWGN) channel without channel coding protection and the received vector in 
bits  is the transmitted bits corrupted by the additive white Gaussian noise. We 
assume that no bits are deleted by the channel and the length of bitstream  is known at the 
receiver.  
1 2( ,..., )Nr r r r= ,
N
The transmitted bitstream can be represented as a path in a trellis where each state is a 
position in the bitstream following a valid codeword [15]. Since the number of codewords is K , 
at most K  branches are out from each state. The codeword, that presents a symbol, labels each 
branch or transition in the trellis. Since  is known, nodes in the final stage will have only 
those branches corresponding to codewords of appropriate lengths to terminate in node . A 
simple example of trellis of a bitstream of length 99 is given in Fig. 1. Once a trellis is 
constructed, an MAP decoding can be applied on it whenever the MAP metric of each branch is 
specified. 
N
N
(1) We first derive the MAP metric of the above MAP decoding problem, and then proposed two 
 7
 
圖三、Trellis diagram for a code C with three codewords 0,10,11 and M = 3,  
where ”00” is a dummy codeword and (a,b) denotes (#bits, register state). 
 
 
表二、AVERAGE AND MAXIMUM NUMBER OF BRANCH METRIC COMPUTATIONS 
 
 
圖四、 Symbol error rate (SER) of joint decoding algorithms 
 
三、 計畫成果自評 
本計畫相關研究成果如下： 
1. 吳庭伊,”On Constructing the Reversible Variable Length Code with Minimal Average 
Codeword Length by Using A* Algorithm”, 暨大資工系碩士論文, Jun. 2007. 
2. 吳威怡,” Bit- and Trellis- Based Joint Huffman and Convolutional Sequential Decoding 
Algorithms,” 暨大資工所碩士論文, Jul. 2008. 
 9
表 Y04 
行政院國家科學委員會補助國內專家學者出席國際學術會議報告一 
                                                          97 年  5 月 18 日 
報告人姓名  黃育銘 
 
服務機構
及職稱 
 
暨南國暨大學資訊工程學系 
 
     時間 
會議 
     地點 
 97.3.24 – 97.3.27 
美國鹽湖城 
本會核定
補助文號
 
計畫編
號:NSC95-2221-E-260-029-MY2 
會議 
名稱 
 (中文)  
 (英文) International Conference on Data Compression (DCC2008) 
 
發表 
論文 
題目 
 (中文)  
 (英文) Trellis-Based Joint Huffman and Convolutional Soft-Decision 
Priority-First Decoding 
表 Y04 
 
4. Dimension Reduction and Expansion: Distributed Source Coding in a Noisy Environment. 
Anna N. Kim and Fredrik Hekland† 
Norwegian University of Science and Technology, †ABB Corporate Research Centre 
目前因sensor network的盛行, “Distributed Source Coding” 的研究相當盛行, 未來我會朝著”Distributed 
Joint Source-Channel Coding做研究。 
 
(三) 3/27 
 
SESSION 10 (Multiple Description Coding) 
 
1. Noise-Shaped Predictive Coding for Multiple Descriptions of a Colored Gaussian Source 
Yuval Kochman, Jan Østergaard†, and Ram Zamir 
Tel Aviv University, †University of Newcastle  
 
2. Server Placement in Multiple-Description-Based Media Streaming. 
Satyajeet Ahuja and Marwan Krunz 
University of Arizona  
 
3. Speed-Up of Encoder Optimization Step in Multiple Description Scalar Quantizer Design 
Sorina Dumitrescu 
McMaster University  
 
4. Filter Banks for Prediction-Compensated Multiple Description Coding  
Jing Wang and Jie Liang 
Simon Fraser University  
 
5.On the Symmetric Gaussian Multiple Description Rate-Distortion Function. 
Chao Tian, Soheil Mohajer†, and Suhas Diggavi† 
AT&T Labs Research, †Swiss Federal Institute of Technology  
 
我有一位研究生研究過”Multiple Description Coding for wavelet coefficients＂的問題。 
 
SESSION 12 (最根本Lossless壓縮技術，有三篇論文與我目前執行計畫內容非常有關)
1. Guaranteed Synchronization of Huffman Codes  
Marek Tomasz Biskup 
Warsaw University 
 
2.Using Fibonacci Compression Codes as Alternatives to Dense Codes. 
Shmuel T. Klein and Miri Kopel Ben-Nissan 
Bar Ilan University 
 
3.A Simple Algorithm for Computing the Lempel–Ziv Factorization  
Maxime Crochemore†, Lucian Ilie‡, W. F. Smyth♦  
†King's College London and Université Paris-Est, ‡University of Western Ontario, 
♦ McMaster University and Curtin University of Technology 
 
4. A Lower Bound on the Redundancy of Arithmetic-Type Delay Constrained Coding 
Eado Meron, Ofer Shayevitz, Meir Feder, and Ram Zamir 
Tel Aviv University 
 
 
 
 
                                                            
Trellis-Based Joint Huffman and Convolutional Soft-Decision Priority-First Decoding
Yuh-Ming Huang1 and Yunghsiang S. Han2
1. Department of Computer Science and Information Engineering, National Chi Nan University, Puli, Taiwan
2. Graduate Institute of Communication Engineering, National Taipei University, Taipei County, Taiwan
(e-mail:ymhuang@csie.ncnu.edu.tw yshan@mail.ntpu.edu.tw)
Let A = {a1, a2, . . . , a26} be a set of 26 English alphabets with probabilities P = {p1, p2, . . . , p26} and
C be the corresponding Huffman code that has 26 codewords {c1, c2, . . . , c26} with average codeword
length 4.15573. The respective lengths of the codewords are given by {`1, `2, . . . , `26}. According to P ,
a concatenation of 1000 symbols randomly generated from A is Huffman encoded into a bitstream x of
length M and x is further encoded into a bitstream y of length N by a binary (2,1,6) convolutional code
with octal generator sequence 554 and 744. Then, y is BPSK modulated and sent over an AWGN channel.
Let r = (r1, r2, . . . , rN) denote the received bitstream. This work assumes that no bits are deleted by the
channel, and that the side information N is known at the receiver.
The transmitted bitstream y or its corresponding bitstream x can be represented as a path in a symbol-
level trellis. For each node (l,s) in the trellis, l denotes a position (level) in the bitstream x following a valid
codeword [1] and s denotes the current register state of the binary convolutional encoder. The codeword,
that presents a symbol, or its convolutionally encoded bitstream labels each branch in the trellis. Let SN
denote the set of all valid bitstreams of length N formed by the outputs of the convolutional encoder for
sequences of codewords in C. For maximum a posteriori (MAP) decoding, a bitstream yˆ ∈ SN needs to
be selected such that
Pr(r|yˆ) Pr(yˆ) ≥ Pr(r|y) Pr(y)⇔
N∑
j=1
(hj ⊕ yˆj)|φj| − ln Pr(yˆ) ≤
N∑
j=1
(hj ⊕ yj)|φj| − ln Pr(y) (1)
for all y ∈ SN , where hj 4=
{
1, if φj < 0
0, otherwise
and φj
4
= ln
Pr(rj |0)
Pr(rj |1) . Under the memoryless source and
channel assumptions, for branch labeled by yil =
(
y
(i1)
l , y
(i2)
l , . . . , y
(i2`i)
l
)
between level l − `i and level l
in a trellis, the new branch metric associated with it is defined as
M
(
yil
) 4
=
2`i∑
j=1
(h2l−2`i+j ⊕ y(ij)l )|φ2l−2`i+j| − ln Pr(yil). (2)
Equipped with equation (2), based on a code trellis rather than on a code tree, we can modified the
algorithm given in [2] to obtain a joint Huffman and convolutional priority-first decoding algorithm
(PFDA). In order to lower the decoding complexity, one heuristic policy was adopted on PFDA to ensure
that the level value of the ending node in the next searched path was within 10 to that of the ending node in
the farthest visited path. Simulation results indicate that the PFDA provides nearly the same performance
as that in [1] while exhibiting a significantly lower complexity (average (ave) and maximum (max) number
of branch metric computations) as shown in the following table (SNRb denotes the signal-to-noise ratio
per information bit).
SNRb 2 dB 3 dB 4 dB 5 dB 6 dB 7 dB 8 dB
method ave max ave max ave max average max ave max ave max ave max
[2] 5599109 5668494 5599109 5668494 5599109 5668494 5599109 5668494 5599109 5668494 5599109 5668494 5599109 5668494
proposed 1123514 1327974 356028 434876 113470 133648 50308 58203 32652 34610 27662 28420 26343 26735
REFERENCES
[1] K. Lakovic, J.Villasenor, and R. Wesel, “Robust joint huffman and convolutional decoding,” in Proc. of the IEEE VTC, Sep. 1999, pp.
2551–2555.
[2] Y. S. Han, P.-N. Chen, and H.-B. Wu, “A maximum-likelihood soft-decision sequential decoding algorithm for binary convolutional
codes,” IEEE Trans. Commun., vol. 50, no. 2, pp. 173–178, Feb. 2002.
Data Compression Conference
1068-0314/08 $25.00 © 2008 IEEE
DOI 10.1109/DCC.2008.40
521
Authorized licensed use limited to: National Chi-Nan University Library. Downloaded on December 28, 2008 at 22:55 from IEEE Xplore.  Restrictions apply.
表 Y04 
 
 
(A) Coding and Modulation 
 
1. A Simplified Addition Operation Log-SPA LDPC Decoder  
Po-Hui Yang (National Yunlin University of Science and Technology, Taiwan); 
Jung-Chieh Chen (National Kaohsiung Normal University, Taiwan)  
2. Shuffled BP Decoding for Punctured LDPC Codes  
Sangjoon Park (Yonsei University, Korea); SunYoung Lee (Yonsei University, Korea); 
Keum-Chan Whang (Yonsei University, Korea)  
3. An Efficient BF LDPC Decoding Algorithm Based on A Novel Syndrome Vote 
Scheme  
Jui-Hui Hung (National Chiao Tung University, Taiwan)  
4. On Decoding of the (89, 45, 17) Quadratic Residue Code  
Wen-Ku Su (I-Shou University, Taiwan); Pei-Yu Shih (I-Shou University, Taiwan); 
Tsung-Ching Lin (I-Shou University, Taiwan); Trieu-Kien Truong (I-Shou University, 
Taiwan)  
5. Constructive Algorithms for Determining Inverses and Syndrome Matrices of 
Multidimensional Convolutional Encoders Using Groebner Basis Approach  
Chalie Charoenlarpnopparut (Sirindhorn International Institute of Technology, 
Thailand); Pramote Jangisarakul (Sirindhorn International Institute of Technology, 
Thailand) 
6. A Decoding Method for Binary Quadratic Residue Codes  
Chong-Dao Lee (I-Shou University, Taiwan); Yan-Haw Chen (I-Shou University, 
Taiwan)  
 
 
大部份是在探討LDPC碼的解碼演算法，可以看出LDPC碼是工業產品：消費性通訊裝置
的核心技術。 
 
 
Proceedings of APCC2008 copyright (c) 2008 IEICE 08 SB 0083
Bit- and Trellis- Based
Soft-Decision Sequential Decoding for
Variable-Length Error-Correcting Codes
Yuh-Ming Huang and Chien-Feng Lo
Dept. of Computer Science and Information Engineering,
National Chi Nan University
Puli, Taiwan, R.O.C.
Email:ymhuang@csie.ncnu.edu.tw
Yunghsiang S. Han
Graduate Institute of Communication Engineering,
National Taipei University
Taipei County, Taiwan, R.O.C.
Email: yshan@mail.ntpu.edu.tw
Abstract—Variable-length error-correcting codes
(VLECCs) have recently received extensive attention
because they can provide both compression and error-
correction capabilities simultaneously. The larger free
distance a VLECC has, the more redundancy the VLECC
suffers from. The redundancy can be used to combat
the channel noise effectively by using the technique of
joint source-channel decoding (JSCD). However, for larger
VLECCs, the high computational decoding complexity has
prevented these codes from implementation in practice.
In this work, a new bit metric with low computational
complexity is derived first, then based on a code trellis
rather than on a code tree, we proposed a maximum a
posteriori (MAP) bit-level soft-decision sequential decoding
algorithm and its two approximations. Simulation results
indicate that both approximations can provide nearly the
same performance as the MAP scheme while exhibiting a
significantly lower complexity.
I. INTRODUCTION
Source and channel coding can be implemented sepa-
rately without asymptotical performance loss according to
the separate theory of Shannon [1]. However, the separate
theory does hold only when both source code and channel
code are optimal, where the source coder removes all
redundancy and the channel coder corrects all errors. In
practical system, there is often residual redundancy in the
source encoder’s output due to constraints on complexity
and delay that may limit compression performance. Thus,
this separate strategy does not necessary lead to a feasible
solution with the best performance. Usually, the decoder
might use the redundancy to protect the transmitted se-
quence over a noisy channel by acting as a statistical
estimator of the transmitted sequence. Hence, joint source-
channel coding (JSCC) has received a lot of attention in
the literature recently.
Recent research in JSCC can be divided into two
directions. One is to redesign the variable length codes
(VLCs) [2]–[6], called the variable-length error-correcting
codes (VLECCs), to make them more error-resilient, but
increase compression loss. Such approaches indicate using
VLECC alone can simultaneously provide the compres-
sion and error-correction capabilities. The other is to
derive efficient decoding algorithms (regarded as one joint
source/channel decoder) [2], [3], [6], [7] for the system
formed by a VLECC alone. In this work, we focus on the
latter.
Buttigieg and Farrell [2], Bystrom et al. [3] [5], Bau
and Hagenauer [7] all performed the trellis-based MAP
techniques in joint source/channel decoding. Based on a
modified form of Viterbi [8] algorithm, Buttigieg and
Farrell [2], Bystrom et al. [3] [5] adopted symbol-level
trellis structures for MAP decoding on VLECCs. Using the
BCJR [9] algorithm, Bauer and Hagenauer [7] presented a
bit-level soft-in/soft-out decoder for VLECCs based on a
bit-level trellis structure. For long source sequence, while
all possible source information (for example, Markov
source model) and side information (for example, the
number of totally transmitted symbols) are take into con-
sideration for the construction of the corresponding trellis,
all above approaches have a common serious drawback
that the decoding complexity will become quite expensive
due to the enormous number of the trellis states.
In order to reduce the decoding complexity, low-
complexity but sub-optimal symbol-level and tree-based
sequential decoding algorithms were proposed in [6] [3].
The former is based on a ZJ (Stack) [10] [11] algorithm,
whereas the latter is Fano [12] based. Recently, Huang
et al. [13] have proposed symbol-level and trellis-based
soft-decision priority-first decoding algorithms which out-
perform the existing methods [3] [6] for VLECCs.
In this work, based on the ideas of [13] and [14],
we continue to present a bit-level and trellis-based MAP
soft-decision sequential decoding algorithm (denoted as
MAPSDA) and its two approximations. Simulation results
show that the decoding complexity of our previously pro-
posed symbol-level based decoding algorithms [13] can be
further reduced a lot with no degradation on performance
in terms of symbol error probability.
II. BIT- AND TRELLIS- BASED SOFT-DECISION
SEQUENTIAL DECODING
Let S = {s1, s2, . . . , sK} be a set of source symbols
and C denote the corresponding binary VLC that has K
codewords {c1, c2, . . . , cK} with respective probabilities
{Pr(c1),Pr(c2), . . . ,Pr(ck)}. The respective lengths of
the codewords are given by {`1, `2, . . . , `K}. Let ci =
c1i c
2
i . . . c
`i
i , 1 ≤ i ≤ K. C can be represented in the
form of a tree structure. An example is given in Fig. 1,
where Ni, 0 ≤ i ≤ 2, denotes the internal nodes and Ej ,
1 ≤ j ≤ 4, denotes the external nodes. The bit sequence of
Proceedings of APCC2008 copyright (c) 2008 IEICE 08 SB 0083
the same as the transmitted bitstream x. Moreover, since
L is unknown to the decoder, even both bitstreams x and
vˆ which respectively owns different number of codewords
is possible.
Suppose v = (cτ(1), cτ(2), . . . , cτ(M)), i.e., a con-
catenation of M codewords indexed by τ and N =∑M
m=1 `τ(m). Hence, under the assumption of independent
source symbol, we have
− ln Pr(v) =
M∑
m=1
− ln Pr(cτ(m)). (8)
Combined with equations (1) and (8), − ln Pr(v) can be
further rewritten as
− ln Pr(v) =
M∑
m=1
[
− ln Pr(c1τ(m))+
`τ(m)∑
n=2
− ln Pr(cnτ(m)|c1τ(m), c2τ(m), . . . , cn−1τ(m))
 . (9)
Thus, according to the right side of equation (7) and
equation (9), the bit metric for each bit branch of the path
associated with v in a trellis can be easily obtained. For
example, the first bit metric is (h1⊕v1)|φ1|−ln Pr(c1τ(1)).
Owing to the non-negativity of each bit metric, the
metric value of the partial path is non-decreasing along
any path in a trellis . Accordingly, the MAPSDA can be
made to operate on a trellis, instead of on a code tree, as
with the traditional stack algorithm. This is achieved by
introducing a node table to record all nodes in the trellis
that has been expanded, i.e., whose children have been
visited. Based on the above definitions and notations, the
MAPSDA can be presented.
〈The bit- and trellis- based MAPSDA for VLECCs 〉
Step 1. The Stack initially has only one original node
(0,0) whose metric is assigned zero.
Step 2. If the top path in the Stack ends at the terminal
node (N ,0) in the trellis, then the algorithm
stops.
Step 3. Delete the top path from the Stack, and put the
ending node of this top path into the node table.
Calculate the path metrics of the successors of
the top path in the Stack.
Step 4. If any of the new paths ends at a node already in
the node table, then discard the new path.
Step 5. If any of the new paths merges with a path
already in the Stack, then remove the one with
higher path metric value.
Step 6. Insert the remaining new paths into the stack
and reorder the Stack according to ascending
metric values. Go to Step 2.
As indicated in the previous algorithm, the Stack con-
tains all paths explored by the MAPSDA, which are not
the prefix of all other paths in the Stack. The Stack
appears to function similarly to the stack in the traditional
sequential decoding algorithm. The node table records the
information of the ending nodes of the paths that had
previously been the top paths of the Stack. The optimality
of the MAPSDA can be proved by a similar argument
given in [15].
TABLE I
HUFFMAN CODE C2 AND VLECC C3 RESPECTIVELY GIVEN IN
TABLE II AND TABLE III OF [6] FOR THE 26-SYMBOL ENGLISH
ALPHABET
Symbol Probability C2 C3
E 0.14878570 001 0111
T 0.09354149 110 10110
A 0.08833733 0000 11101
O 0.07245769 0100 01000
R 0.06872164 0110 110101
N 0.06498532 1000 001001
H 0.05831331 1010 000100
I 0.05644515 1110 0010100
S 0.05537763 0101 0001111
D 0.04376834 00010 1101100
L 0.04123298 10110 1000001
U 0.02762209 10010 10011011
P 0.02575393 11110 00001010
F 0.02455297 01111 10011100
M 0.02361889 10111 10000101
C 0.02081665 11111 100011110
W 0.01868161 000111 100010000
G 0.01521216 011100 1000100110
Y 0.01521216 100110 1000111010
B 0.01267680 011101 0000110100
V 0.01160928 100111 00001100010
K 0.00867360 0001100 00001100101
X 0.00146784 00011011 000011011100
J 0.00080064 000110101 00001101111100
Q 0.00080064 0001101001 0000110111111100
Z 0.00053416 0001101000 00001101111111110
FD 1 3
ACL 4.15572 6.269
In order to further lower the decoding complexity of
MAPSDA, the effect of the source priori probability can
be disregarded with almost no performance degradation,
that is, the term −lnPr(v) in (7) was not included. This
approximate solution is denoted as AMAPSDA. More-
over, one heuristic policy was adopted on MAPSDA and
AMAPSDA to ensure that the ending node of the next
searched path was within a threshold to the ending node
of the farthest visited path. The resultant algorithms are
respectively denoted as MAPSDA@ and AMAPSDA@
depending on the selected threshold value @. Even though
this policy slightly degrades the error rate performance of
the proposed algorithms, it reduces the decoding complex-
ity drastically. The larger threshold value we select, the
less degradation in performance the algorithms will have.
III. SIMULATION RESULTS OVER AWGN CHANNEL
This section examines the computational effort and the
performance of the MAPSDA and its approximations by
simulations over the AWGN channel. The binary code-
word is assumed to be antipodally transmitted. Hence, for
the AWGN channel, the received vector is given by
rj = (−1)vj
√
E + λj ,
for 0 ≤ j ≤ N − 1, where E denotes the signal energy
per channel bit, and {λj}N−1j=0 denote independent noise
samples of a white Gaussian process with single-sided
noise power per hertz N0. The signal-to-noise ratio (SNR)
for the channel is therefore SNR
4
= E/N0.
For the AWGN channel, since φj = 4
√E
N0
rj , hj can be
further simplified as
hj
4
=
{
1, if rj < 0;
0, otherwise.
