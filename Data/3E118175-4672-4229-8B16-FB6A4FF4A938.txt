Language Processing. 
英文關鍵詞： retrieval and summarization, risk minimization, 
decision-making, loss functions, spoken document 
 
A spoken sentence to be selected as part of a summary may be 
considered from the following three factors (although one can still 
tackle the extractive summarization problem from a different point 
of view): 1) salience－ the importance of the sentence itself, which 
is usually evident by its structure, location, prosodic or word-usage 
information, and many more; 2) relevance－ the more relevant a 
sentence to the whole document or the other sentences in the 
document, the more likely it should be included in the summary; 
and 3) redundancy－ the information carried by the sentence and 
that of the already selected summary sentences should cover 
different topics or concepts of the document. Quite a few studies 
with either supervised or unsupervised machine-learning methods 
have been designed to address the above three factors to a certain 
extent. For the salience factor, a typical example is to estimate the 
salience of each spoken sentence with supervised machine-learning 
techniques. It can be thought of as a two-class (i.e., summary and 
non-summary) sentence-classification problem [10]: A sentence 
with a set of indicative features is fed to the classifier (or 
summarizer) and a classification result is then output from it in 
view of these features. Summary sentences are subsequently 
ranked and compiled according to those classification results. 
Although such supervised summarizers are effective, most of them 
usually explicitly assume that sentences are independent of each 
other and each sentence is classified individually without allowing 
for the relationship among the sentences (the so-called “bag-of-
sentences” assumption) [11]. The other potential shortcoming is 
that a set of handcrafted document-reference summary exemplars 
are required for training the summarizers; however, such 
summarizers tend to limit their generalization capability and might 
not be readily applicable for new tasks or domains. 
There is another school of thought that attempts to conduct 
document summarization using unsupervised machine-learning 
approaches, getting around the need for manual annotation of 
training data. The common basic idea behind these summarizers is 
typically based on the conception of the relevance (or similarity) of 
a sentence to other sentences [12]. Put simply, sentences bearing 
more similarity to the document itself (or the other sentences in the 
document) are deemed more relevant to the main theme of the 
document; such sentences thus will be selected as part of the 
summary. Moreover, unsupervised summarizers are usually 
constructed only on the basis of the lexical information without 
considering other sources of information, whereas imperfect 
speech recognition often leads to degraded performance when 
using the lexical information solely. On the other hand, for the last 
factor, redundancy, maximum marginal relevance (MMR) [13] is 
usually considered to be a good remedy. MMR performs sentence 
selection iteratively by striking the balance between topic 
relevance and coverage. 
We have recently introduced a new perspective on the problem 
of speech summarization, saying that it can be approached with a 
modeling framework built on the notion of risk minimization [14-
15], which shows good promise to inherit the merits of most 
existing summarization methods, as well as to provide a general 
and flexible way to allow for the aforementioned three factors. Our 
work in this research continues this general framework of research 
in several significant aspects: 1) we investigate leveraging several 
selection strategies and modeling paradigms to construct the 
component models involved in such a framework; 2) we explore 
various ways to devise the loss functions that can effectively 
render the dependence relationship among the sentences of a 
spoken document to be summarized, 3) more extra information 
cues are incorporated into the summarization framework that can 
further enhance the summarization performance, 4) we also 
provide extensive analysis and a series of experiments, showing 
that the methods deduced from such a risk-aware modeling 
framework are indeed very competitive with the existing speech 
summarization methods, and 5) we again confirm the added benefit 
of using of non-lexical features for speech summarization. 
The remainder of this report is structured as follows. We begin 
by giving a brief review of the related work on extractive 
summarization in Section 2, with a focus on supervised and 
unsupervised machine-learning methods. In Section 3, we describe 
how to cast extractive speech summarization as a risk minimization 
problem, followed by a detailed elucidation of the proposed 
methods in Section 4. After that, the experimental setup and 
several sets of experiments and associated discussions are 
presented in Sections 5 and 6, respectively. Finally, Section 7 
concludes our presentation and suggests avenues for future work. 
2. RELATED WORK 
Speech summarization can be conducted using either supervised or 
unsupervised machine-learning methods. In the following, we 
briefly review a few celebrated machine-learning methods that 
have been applied to speech summarization with varying degrees 
of success, as well as some other considerations pertaining to 
spoken documents. 
2. 1 Supervised Summarizers 
The supervised machine-learning strategies usually treat speech 
summarization as a two-class (summary and non-summary) 
sentence-classification problem: A spoken sentence iS  is 
characterized by a set of indicative features, such as lexical 
features [16], structural features [17], acoustic features [16], 
discourse features [18], relevance features [19], etc. Then, the 
corresponding feature vector iX  of iS  is taken as the input to the 
classifier. If the output (classification) score belongs to the positive 
class, iS  will be selected as part of the summary; otherwise, it will 
be excluded [10]. Specifically, the problem can be formulated as 
follows: Construct a sentence ranking model that assigns a 
classification score (or a posterior probability) of being in the 
summary class to each sentence; important sentences are 
subsequently ranked and selected according to these scores. To this 
end, several popular machine-learning methods could be utilized to 
serve the purpose, like Bayesian classifier (BC) [10], Gaussian 
mixture model (GMM) [20], hidden Markov model (HMM) [21], 
support vector machine (SVM) [22], maximum entropy (ME) [23], 
conditional random field (CRF) [11, 24], to name a few. 
In general, these methods require a training set comprised of 
several documents and their corresponding handcrafted summaries 
to train the classifiers (summarizers). However, manual annotation 
is often expensive in terms of time and personnel. Moreover, such 
summarizers tend to limit their generalization capability and might 
not be readily applicable for new tasks or domains. Another major 
shortcoming of these summarizers is that most of them usually 
implicitly assume that sentences are independent of each other (or 
the so-called “bag-of-sentences” assumption) and classify each 
sentence individually without leveraging the dependence 
language processing tasks, such as automatic speech recognition 
(ASR) [32], machine translation (MT) [33] and information 
retrieval (IR) [34]. However, as far as we are aware, this notion 
has never been extensively explored for either text or speech 
summarization.  
Along this same vein, in this research we formulate extractive 
speech summarization as a Bayes risk minimization problem. 
Without loss of generality, let us denote Π  as one of possible 
selection strategies which comprises a set of indicators used to 
address the importance of each sentence iS  in a document D  to 
be summarized. For notational convenience, we refer to the k -th 
action ka  as choosing the k -th selection strategy k , and the 
observation O  as the document D  to be summarized. The 
expected risk of a certain selection strategy k  is given by 
      .|,|   dDpLDR kk    (3) 
Consequently, the ultimate goal of extractive summarization could 
be stated as the search of the best selection strategy *  from the 
space of all possible selection strategies that minimizes the 
expected risk defined as follows: 
 
    .|,minarg      
|minarg*




dDpL
DR
k
k
k
k


   (4) 
As can be seen in (4), the realization of the Bayes decision theory 
for extractive speech summarization requires: 1) a practical 
definition of the selection strategy  , 2) an efficient and accurate 
way to estimate the probability of choosing a particular selection 
strategy   given D  (i.e.,  Dp | ), and 3) an effective 
mechanism to measure the loss function between any two selection 
strategies (i.e.,   ,kL ). In what follows, we will shed light on 
each of these three ingredients from various points of view.  
3.1 Selection Strategy 
A feasible selection strategy can be fairly arbitrary according to the 
underlying principle. For example, it could be a set of binary 
indicators denoting whether a sentence should be selected as part 
of summary or not. In addition, it may also be a ranked list used to 
address the importance degree of each individual sentence. Here, 
we present two different instantiations of it where the selection 
strategy can be either “sentence-wise” or “list-wise.” 
3.1.1 Sentence-wise Selection Strategy 
For the sentence-wise selection strategy, we assume that 
summary sentences can be iteratively chosen (i.e., one at each 
iteration) from the original document until the aggregated 
summary reaches a predefined target summarization ratio. More 
concretely, the selection strategy is represented by a binary 
decision vector, of which each element corresponds to a specific 
sentence iS  in the document D  and designates whether it should 
be selected as part of the summary or not. It turns out that the 
binary vector for each possible action will have just one element 
equal to 1 and all the others equal to zero (or the so-called “one-
of-n” coding). For ease of notation, we denote the binary vector 
by iS  when the i -th element has a value of 1. Therefore, (4) can 
be reduced to 
 
   ,~|,minarg      
~|minarg
~~
~
*





DjS
jji
DiS
i
DiS
DSPSSL
DSRS
  (5) 
where D~  denotes the remaining sentences that have not been 
selected into the summary yet (i.e., the “residual” document);  DSP j ~|  reflects the importance degree of a sentence jS  given 
the residual document D~ . 
3.1.1 List-wise Selection Strategy 
The iterative (or greedy) selection procedure described above 
may sometimes result in a suboptimal selection. For example, the 
information carried by a verbose sentence would be succinctly 
depicted by one or more other concise (short) sentences which 
cover more topics of interest. To address this potential 
shortcoming, one may formulate the extractive summarization as 
a maximum convergence problem under a summary length 
constraint and to solve the problem by exploiting some global 
inference algorithms, such as the integer linear programming 
(ILP) [35-36] or graph-based submodular selection [37] methods. 
We, however, present here an alternative remedy to address the 
issue by exploring the so-called list-wise selection strategy under 
the risk minimization framework. Specifically, we contemplate 
every possible combination (or subset) of sentences in a spoken 
document as a candidate summary   and then the best summary 
can be constructed through the following equation 
   ,|,minarg 


Dj
jji
Di
DPLSummary
ΨΨ 
   (6) 
where DΨ  denotes all possible combinations of sentences in a 
spoken document D  (i.e., the set of all possible candidate 
summaries);  DP j |  is the probability of j  being the 
summary given the document D . 
For practical implementation, it would be impossible to 
enumerate all possible combinations of summary sentences for 
forming the summary of a spoken document, due to the reason 
that the number of possible combinations would grow 
exponentially as the number of sentences in a document increases. 
To reduce the computational overhead, we can first use some 
prior knowledge, for example, the sentence-wise selection 
strategy, to select a set of possible summary sentences as the 
candidates for being considered to be included in the summary, 
and then enumerate all possible combinations (or samplings) of 
these sentences under a specific constraint of the length of the 
target summary. 
 
 
 
empirical success, to predict the generative probability  |DP , 
as shown in (7). In the LM approach, each selection strategy   
(virtually,   may correspond to a sentence for the sentence-wise 
selection strategy, or a subset of possible summary sentences for 
the list-wise selection strategy) can be simply regarded as a 
probabilistic model for predicting the document. If we further 
assume that words are conditionally independent given   and 
their order is no importance (i.e., the so-called “bag-of-words” 
assumption), then  |DP  can be decomposed as a product of 
unigram probabilities of words w  generated by  : 
     , ,Dwc
Dw
wPDP 

     (12) 
where  Dwc ,  is the number of times that index term (or word) 
w  occurs in D , reflecting that w  will contribute more in the 
calculation of   |DP  if it occurs more frequently in D . The 
simplest way is to estimate the probabilistic model  wP  on the 
basis of the frequency of word w  occurring in  , with the 
maximum likelihood estimation (MLE): 
    ,w,cw|P 
      (13) 
where  w,c  is the number of times that word w  occurs in   
and   is the number of words in  . In a sense, (12) belongs to 
a kind of literal term matching strategy and may suffer the 
problem of unreliable model estimation owing particularly to 
only a few sampled words present in   [39]. To mitigate this 
potential problem, a unigram probability (or background model)  BGwP  estimated from a general collection, which models the 
generic characteristics of words in the target language, is often 
used to smooth the generative model: 
       BGwPwPwP   1 ˆ    (14) 
where   is a weighting parameter. Interested readers may also 
refer to [39] an in-depth treatment of more elaborate ways to 
construct the generative model. 
As an illustration, consider the sentence-wise selection strategy 
where the calculation of the probability  |DP  is equivalent to 
the calculation of sentence generative probability  jSDP |  if   
corresponds to any arbitrary sentence jS . The probability  jSDP |  can be interpreted as the likelihood of the (residual) 
document D  being generated by jS . If jS  generate D  with a 
higher likelihood, it would be more likely to be a summary 
sentence. Phrased another way,  jSDP |  captures the degree of 
relevance of jS  to D . Following the same spirit, we can also use  |DP  to measure the similarity of a candidate summary 
(namely, a subset of possible summary sentences)   to D  for the 
list-wise selection strategy.  
4.1.2 Prior Probability 
The prior probability  P , as shown in (7), can be regarded as 
the likelihood of a selection strategy   being important without 
seeing the whole document. It could be assumed uniformly 
distributed or estimated from a wide variety of factors, such as 
the positional information, the lexical information, the structural 
information or the inherent prosodic properties embedded in a 
sentence (or a subset of sentences) of the spoken document to be 
summarized.  
Taking the sentence-wise selection strategy as an example, a 
straightforward way is to assume that the sentence prior 
probability  jSP  is set in proportion to the posterior probability 
of a sentence jS  being included in the summary class when 
observing a set of indicative features jX  of jS  derived from its 
structure, location, prosodic and word-usage information, or other 
sentence importance measures [10]. These features can be 
integrated in a systematic way into the proposed framework by 
taking the advantage of the learning capability of the supervised 
machine-learning methods. Specifically, the prior probability  jSP  can be approximated by: 
             ,|| | SSSS SS PXPPXP PXpSP jj jj    (15) 
where  S|jXP  and  S|jXP  are the likelihoods that a sentence 
jS  with features jX  are generated by the summary class S  and 
the non-summary class S , respectively; the prior probability  SP  
and  SP  are set to be equal in this research. To estimate  S|jXP  and  S|jXP , several popular supervised classifiers (or 
summarizers), like BC, can be employed for this purpose.  
On the other hand, the prior probability of each candidate 
summary  P  in the list-wise selection strategy can be estimated 
in a similar way as the sentence-wise selection strategy, or, 
alternatively, by considering the informativeness, clarity or 
redundancy of the constituent elements in the candidate summary 
(i.e., the subset of possible summary sentences). However, since in 
this research, the list-wise selection strategy is implemented by a 
two-stage selection procedure by first using the sentence-wise 
selection strategy to select a set of summary sentences to form the 
combinations of sentences as the possible candidate summaries, 
each candidate summary  , to a certain degree, is presumably 
representative enough. Thus, we might simply assume that the 
prior probability of each candidate summary  P  is uniformly 
distributed. 
4.2 Direct Modeling 
To accomplish direct modeling of the posterior probability DP | , in this study, we employ the global conditional log-
linear model (GCLM) [40] to fulfill this goal. In GCLM, the 
posterior probability of an output T  given an observation (or input) 
R  is represented by 
      ,,exp,
1;| ααα  RTRZRTP    (16) 
where  RT ,  is a feature vector used to characterize the 
relationship between T  and R ; α  is the corresponding parameter 
vector;   α RT ,  is the dot product of  RT ,  and α ; and       T RTRZ αα ,exp,  is a normalization factor that 
depends on R  and α . In the context of speech summarization, for 
a spoken document D  and a given selection strategy  (i.e.,   is 
a possible summary sentence for the sentence-wise selection 
strategy, or a subset of possible summary sentences for the list-
5.2 Features for Supervised Summarizers 
Several features have been designed and widely-used in speech 
summarization, especially with the supervised machine-learning 
approaches [10, 19]. In this research, we take BC as the 
representative supervised summarizer and use a set of 28 indicative 
features, as outlined in Table 3, to characterize a spoken sentence, 
including the structural features, the lexical features, the acoustic 
features and the relevance feature. Interested readers may refer to 
[19] for detailed accounts on the characteristics of these features, 
and comparisons among them. Also noteworthy is that, for each 
kind of acoustic features, the minimum, maximum, mean, 
difference value and mean difference value of a spoken sentence 
are extracted. The difference value is defined as the difference 
between the minimum and maximum values of the spoken 
sentence, while the mean difference value is defined as the mean 
difference between a sentence and its previous sentence. All the 28 
features are further normalized to zero mean and unit variance: 
,ˆ
m
mm
m
xx 
      (19) 
where m  and m  are, respectively, the mean and standard 
deviation of a feature mx  estimated from the training set (cf. 
Section 5.1). 
6. EXPERIMENTAL RESULTS 
6.1 Baseline Experiments 
At the outset, we evaluate the performance of a special case of the 
risk-aware summarization framework when conducting speech 
summarization with both the sentence-wise selection strategy and 
the generative-modeling paradigm, but using either the sentence 
generative model (denoted by the LM summarizer) or the sentence 
prior model (denoted by the BC summarizer), exclusively (cf. 
Section 4.1). Here the loss function is simply set to the 0-1 loss 
function. The corresponding results are detailed in Table 4, where 
the values in the parentheses are the associated 95% confidence 
intervals. It is also worth mentioning that TD denotes the 
summarization results obtained based on the manual transcripts of 
spoken documents while SD denotes the results using the speech 
recognition transcripts which may contain speech recognition 
errors and sentence boundary detection errors. In this research, 
sentence boundaries were determined by speech pauses [19]. For 
the TD case, the acoustic features were obtained by aligning the 
manual transcripts to their spoken documents counterpart by 
performing word-level forced alignment.  
Furthermore, the ROUGE measures, in essence, are evaluated 
by counting the number of overlapping units between the 
automatic summary and the reference summary; the corresponding 
evaluation results, therefore, would be severely affected by speech 
recognition errors when applying the various ROUGE measures to 
quantify the performance of speech summarization. In order to get 
rid of the confounding effect of this factor, it is assumed that the 
selected summary sentences can also be presented in speech form 
(besides text form) such that users can directly listen to the audio 
segments of the summary sentences to bypass the problem caused 
by speech recognition errors. Consequently, we can align the 
speech recognition transcripts of the summary sentences to their 
respective audio segments to obtain the correct (manual) 
transcripts for the summarization performance evaluation (i.e., for 
the SD case). On the other hand, the results obtained directly 
evaluating the automatic summary based on its associated speech 
recognition transcripts also are shown in the brackets of Table 4 for 
comparison. 
We may observe two phenomena from Table 4. One is that there 
are significant performance gaps between conducting 
summarization based on the manual transcripts and the erroneous 
speech recognition transcripts. The relative performance 
degradations are about 15%, 34% and 23%, respectively, for 
ROUGE-1, ROUGE-2 and ROUGE-L measures. One possible 
explanation is that the erroneous speech recognition transcripts of 
spoken sentences would probably carry wrong information and 
thus deviate somewhat from representing the true theme of the 
spoken document. The other is that the supervised summarizer (i.e., 
BC) outperforms the unsupervised summarizer (i.e., LM). The 
better performance of BC can be further explained by two reasons. 
One is that BC is trained with the handcrafted document-summary 
sentence labels in the training set, while LM is instead conducted 
in a purely unsupervised manner. Another is that BC utilizes a rich 
set of lexical and non-lexical features to characterize a given 
spoken sentence, while LM is constructed solely on the basis of the 
lexical (unigram) information. 
Table 1: The statistical information of the broadcast news documents used 
for the summarization. 
 Training Set Evaluation Set 
Recording Period Nov. 07, 2001 – Jan. 22, 2002 
Jan. 24, 2002 – 
Aug. 20, 2002 
Number of Documents 100 20 
Average Duration per 
Document (in sec.) 129.4 141.28 
Avg. Number of words 
per Document 326 290.3 
Avg. Number of 
Sentences per Document 20 23.25 
Avg. Character Error Rate 34.4% 36.15% 
 
Table 2: The agreement among the subjects for important sentence ranking 
for the evaluation set. 
Kappa ROUGE-1 ROUGE-2 ROUGE-L 
0.400 0.600 0.532 0.527 
 
Table 3: Basic sentence features used by supervised summarizers. 
Structural features
1.Position of the current sentence 
2.Duration of the current sentence 
3.Length of the current sentence 
Lexical 
Features 
1.Number of named entities 
2.Number of stop words 
3.Bigram language model scores 
4.Normalized bigram scores 
Acoustic 
Features 
1.The 1st formant 
2.The 2nd formant 
3.The pitch value 
4.The peak normalized cross-correlation of pitch 
Relevance Feature 1.VSM score 
 
modeling paradigm (cf. (17)) and the corresponding results are 
shown in Table 7. It is worth mentioning that we take the scores 
obtained by LM as an additional feature to augment the basic 
feature set (cf., Table 3) for a fair comparison with the generative-
modeling paradigm whose results are shown in Table 5. Two 
observations can be made from Table 7. First, when a 0-1 loss 
function is being used, the summary sentences are selected solely 
based on the posterior probability of each sentence (cf. (17)). As 
compared to the results shown in the first row of Table 5, we can 
find that the direct-modeling paradigm seems to perform slightly 
better than the generative-modeling paradigm for all cases. Second, 
as can be seen from Table 5, the use of the other loss functions, 
rather than the 0-1 loss function, also provides moderate but 
consistent improvements. However, such improvements are not as 
apparent as those gains achieved by the sentence-wise selection 
strategy conducted in conjunction with the generative-modeling 
paradigm (cf. Table 5). We speculate one possible reason is that 
the posterior probability estimated by the direct-modeling 
paradigm is already good enough, which seems to overwhelm the 
added merit of using the various loss functions. However, the exact 
reason is still worthy of further investigation. 
To go a step further, we evaluate the utility of the list-wise 
selection strategy conducted in conjunction with the generative-
modeling paradigm, and the corresponding results are shown in 
Table 8. As can be seen, the list-wise selection strategy 
consistently outperforms the sentence-wise selection strategy (cf. 
Table 5) even under the assumption of uniformly distributed priors  P . In the case of the 0-1 loss function, the selection of 
summary sentences relies solely on the list generative probability. 
It can be also seen that the 0-1 loss function performs on par with 
SIM (and even better than KL) in the TD case, and the 
performance gaps between the 0-1 loss function and SIM (and 
between the 0-1 loss function and KL as well) are reduced to a 
certain extent in the SD case as compared to that of the sentence-
wise counterparts shown in Table 5. One reason for this may be 
that speech summarization using the list generative probability 
alone is quite good enough for the list-wise selection strategy, 
leading to that the contributions made by further incorporating the 
various loss functions (viz. SIM and KL) are less pronounced. 
The above results seem to indicate that the list-wise selection 
strategy can overcome the problem of suboptimal performance 
faced by most of the current commonly-used sentence-wise 
selection strategies for extractive summarization. To better 
understand why it outperforms the sentence-wise selection strategy, 
we further analyze the average number of sentences respectively 
selected by these two strategies subject to the same length 
constraint. We observed the list-wise selection strategy selects 
about 5.05 sentences on average while the sentence-wise selection 
strategy selects about 4.1 sentences into the summary under the 
same word length constraint (i.e., 10% summarization ratio). In 
other words, these statistics might reveal that the list-wise selection 
strategy can, to some extent, avoid selecting verbose sentences into 
the summary. 
6.3 Comparison with Conventional Summarization Methods 
Furthermore, we compare our proposed summarization methods 
with a few existing summarization methods that have been well-
practiced in various summarization tasks, including LEAD, VSM 
[12], LexRank [25], ILP [35], SVM and CRF [11]; the 
corresponding results for the SD case are shown in Table 9. It 
should be noted that the LEAD-based method simply extracts the 
first few sentences from a document as the summary. For ILP 
method, we follow [35] to define the associated cost function and 
constraints and use “lpsolve” [45] to find the optimal solution. 
From Table 9, we observe the following remarks. First, to our 
surprise, CRF does not provide superior results as compared to the 
other summarization methods. One possible explanation is that the 
structural evidence of the spoken documents in the test set is not 
strong enough for CRF to show its advantage of modeling the local 
structural information among sentences. Second, LexRank gives a 
very promising performance in spite that it only utilizes lexical 
information in an unsupervised manner. This somewhat reflects the 
importance of capturing the global relationship for the sentences in 
the spoken document to be summarized. Third, ILP performs better 
than VSM. The results confirm the utility of the global inference 
algorithm for extractive summarization. By and large, the evidence 
Table 6: The results achieved by several methods derived from the sentence-wise selection strategy conducted in conjunction with the generative-modeling 
paradigm and with uniform prior probability. 
 Text Documents (TD) Spoken Documents (SD) 
Loss ROUGE-1 ROUGE-2 ROUGE-L ROUGE-1 ROUGE-2 ROUGE-L 
0-1 0.387 0.264 0.334 0.319 0.164 0.253 
SIM 0.405 0.281 0.348 0.365 0.209 0.305 
KL 0.424 0.303 0.368 0.364 0.209 0.301 
MMR 0.417 0.282 0.359 0.391 0.236 0.338 
 
Table 7: The results achieved by several methods derived from the sentence-wise selection strategy conducted in conjunction with the direct- modeling 
paradigm. 
 Text Documents (TD) Spoken Documents (SD) 
Loss ROUGE-1 ROUGE-2 ROUGE-L ROUGE-1 ROUGE-2 ROUGE-L 
0-1 0.512 0.415 0.463 0.423 0.294 0.360 
SIM 0.513 0.417 0.470 0.430 0.300 0.371 
KL 0.513 0.413 0.469 0.430 0.300 0.366 
MMR 0.515 0.418 0.476 0.430 0.300 0.371 
 
Table 8: The results achieved by several methods derived from the list-wise selection strategy conducted in conjunction with the generative-modeling paradigm.
 Text Documents (TD) Spoken Documents (SD) 
Loss ROUGE-1 ROUGE-2 ROUGE-L ROUGE-1 ROUGE-2 ROUGE-L 
0-1 0.544 0.448 0.505 0.466 0.336 0.409 
SIM 0.544 0.448 0.505 0.482 0.359 0.435 
KL 0.527 0.427 0.486 0.486 0.364 0.436 
summarization using either the manual transcripts or the speech 
recognition transcripts of spoken documents. How to more 
efficiently implement the list-wise selection strategy would be 
worthy of future investigation. We list below some other possible 
future extensions: 1) exploring more extra information cues and 
sophisticated modeling paradigms for this framework, 2) 
investigating various discriminative training criteria for training the 
component models of this framework, 3) extending and applying 
the proposed framework to multi-document summarization tasks, 
and 4) incorporating the summarization results into audio indexing 
for better retrieval and browsing of spoken documents. 
8. REFERENCES 
[1] M. Ostendorf, “Speech technology and information access,” 
IEEE Signal Processing Magazine, Vol. 25, No. 3, pp. 150 - 
152, 2008. 
[2] I. Mani and M. T. Maybury, Advances in automatic text 
summarization. Cambridge: MIT Press, 1999. 
[3] S. Furui, T. Kikuchi, Y. Shinnaka, and C. Hori, “Speech-to-text 
and speech-to-speech summarization of spontaneous speech,” 
IEEE Transactions on Speech and Audio Processing, vol. 12, 
no. 4, pp. 401 - 408, 2004. 
[4] K. McKeown, J. Hirschberg, M. Galley, and S. Maskey, “From 
text to speech summarization,” in IEEE International 
Conference on Acoustics, Speech, and Signal Processing, pp. 
997 - 1000, 2005. 
[5] H. Christensen, Y. Gotoh and S. Renals, “A cascaded broadcast 
news highlighter,” IEEE Transactions on Audio, Speech and 
Language Processing, vol. 16, no. 1, pp. 151 - 161, 2008. 
[6] G. Penn and X. Zhu, “A critical reassessment of evaluation 
baselines for speech summarization,” in Annual Meeting of the 
Association for Computational Linguistics, pp. 470 - 478, 2008. 
[7] S. Xie and Y. Liu, “Improving supervised learning for meeting 
summarization using sampling and Regression,” Computer 
Speech and Language, vol. 24, pp. 495 - 514, 2010. 
[8] J. J. Zhang, R. H. Y. Chan, and P. Fung, “Extractive speech 
summarization using shallow rhetorical structure modeling,” 
IEEE Transactions on Audio, Speech and Language Processing, 
vol. 18, no. 6, pp. 1147 - 1157, 2010. 
[9] J. Zhang and P. Fung, “Speech summarization without lexical 
features for Mandarin broadcast news,” in Human Language 
Technology Conference and the North American Chapter of the 
Association for Computational Linguistics Annual Meeting, 
2007. 
[10] J. Kupiec, J. Pedersen, and F. Chen, “A trainable document 
summarizer,” in Annual International ACM SIGIR Conference 
on Research and Development in Information Retrieval, pp. 68 
- 73, 1999. 
[11] D. Shen, J. T. Sun, H. Li, Q. Yang, and Z. Chen, “Document 
summarization using conditional random fields,” in 
International Joint Conference on Artificial Intelligence, pp. 
2862 - 2867, 2007. 
[12] Y. Gong and X. Liu, “Generic text summarization using 
relevance measure and latent semantic analysis,” in Annual 
International ACM SIGIR Conference on Research and 
Development in Information Retrieval, pp. 19 - 25, 2001. 
[13] J. Carbonell and J. Goldstein, “The use of MMR, diversity-
based reranking for reordering documents and producing 
summaries,” in Annual International ACM SIGIR Conference 
on Research and Development in Information Retrieval, pp. 
335 - 336, 1998. 
[14] S.-H. Lin and B. Chen, “A risk minimization framework for 
extractive speech summarization,” in the Annual Meeting of the 
Association for Computational Linguistics, pp. 79 - 87, 2010. 
[15] S.-H. Lin, Y.-M. Yeh, and B. Chen, “Extractive speech 
summarization － From the view of decision theory,” in the 
Annual Conference of the International Speech Communication 
Association, pp. 1684 - 1687, 2010. 
[16] K. Koumpis and S. Renals, “Automatic summarization of 
voicemail messages using lexical and prosodic features,” ACM 
Transactions on Speech Language Processing, vol. 2, no. 1, pp. 
1 - 24, 2005. 
[17] S. Maskey and J. Hirschberg, “Automatic summarization of 
broadcast news using structural features,” in Annual 
Conference of the International Speech Communication 
Association,  pp. 1147 - 1157, 2003. 
[18] J. Zhang, H. Y. Chan, P. Fung, and L. Cuo, “A comparative 
study on speech summarization of broadcast news and lecture 
speech,” in Annual Conference of the International Speech 
Communication Association, pp. 2781 - 2784, 2007. 
[19] S.-H. Lin, B. Chen, H.-M. Wang, “A comparative study of 
probabilistic ranking models for Chinese spoken document 
summarization,” ACM Transactions on Asian Language 
Information Processing, vol. 8, no. 1,  pp. 3:1 - 3:23, 2009. 
[20] M. A. Fattah and F. Ren, “GA, MR, FFNN, PNN and GMM 
based models for automatic text summarization,” Computer 
Speech and Language, vol. 23, no. 1, pp. 126 - 144, 2009. 
[21] J. M. Conroy and D. P. O'leary, “Text summarization via 
hidden Markov models,” in Annual International ACM SIGIR 
Conference on Research and Development in Information 
Retrieval, pp. 406 - 407, 2001. 
[22] A. Kolcz, V. Prabakarmurthi, and J. Kalita, “Summarization 
as feature selection for text categorization,” in Conference on 
Information and Knowledge Management, pp. 365 - 370, 2001. 
[23] L. Ferrier, A maximum entropy approach to text 
summarization. School of Artificial Intelligence, University of 
Edinburgh, 2001. 
[24] M. Galley, “A skip-chain conditional random field for ranking 
meeting utterances by importance,” in Conference on Empirical 
Methods in Natural Language Processing, pp. 364 - 372, 2006. 
[25] G. Erkan and D. R. Radev, “LexRank: graph-based lexical 
centrality as salience in text summarization,” Journal or 
Artificial Intelligence Research, vol. 22, pp. 457 - 479, 2004. 
[26] D. R. Radev, H. Jing, M. Stys, and D. Ta, “Centroid-based 
summarization of multiple documents,” Information Processing 
and Management, vol. 40, pp. 919 - 938, 2004. 
[27] R. Mihalcea and P. Tarau, “TextRank: bringing order into 
texts,” in Conference on Empirical Methods in Natural 
Language Processing, pp. 404 - 411, 2005. 
[28] S.-H. Lin and B. Chen, “Improved speech summarization with 
multiple-hypothesis representations and Kullback-Leibler 
divergence measures,” in Annual Conference of the 
International Speech Communication Association, pp. 1847 - 
1850, 2009. 
[29] Y. Liu, S. Xie, and F. Liu, “Using N-best recognition output 
for extractive summarization and keyword extraction in 
meeting speech,” in IEEE International Conference on 
Acoustics, Speech, and Signal Processing, 2010. 
[30] S. Maskey and J. Hirschberg, “Comparing lexical, 
acoustic/prosodic, structural and discourse features for speech 
[5] Yueng-Tien Lo, Shih-Hsiang Lin, Berlin Chen, "Constructing 
effective ranking models for speech summarization." the 37th 
IEEE International Conference on Acoustics, Speech, and 
Signal Processing (ICASSP 2012), Kyoto, Japan, March 25 - 
30, 2012. (EI) 
[6] Berlin Chen, Pei-Ning Chen, Kuan-Yu Chen, "Query modeling 
for spoken document retrieval," IEEE workshop on 
Automatic Speech Recognition and Understanding (ASRU 
2011), pp. 389-394, Hawaii, USA, December 11-15, 2011. 
(EI) 
[7] Ea-Ee Jan, Niyu Ge, Shih-Hsiang Lin and Berlin Chen, "An 
effective and robust framework for transliteration 
exploration," the 5th International Joint Conference on 
Natural Language Processing (IJCNLP 2011), pp. 1332-1340, 
Chiang Mai, Thailand, November 8-13, 2011. 
[8] Wen-Yi Chu, Jeih-weih Hung and Berlin Chen, "Modulation 
spectrum factorization for robust speech recognition," 2011 
APSIPA Annual Summit and Conference (APSIPA ASC 
2011), Xian, China, October 18-21, 2011. (EI) 
[9] Pei-Ning Chen, Kuan-Yu Chen, Berlin Chen, "Leveraging 
relevance cues for improved spoken document retrieval," the 
12th Annual Conference of the International Speech 
Communication Association (Interspeech 2011), pp. 929-932, 
Florence, Italy, August 28-31, 2011. (EI) 
[10] Berlin Chen, Jia-Wen Liu, "Discriminative language 
modeling for speech recognition with relevance information," 
IEEE International Conference on Multimedia & Expo 
(ICME 2011), Barcelona, Spain, July 11-15, 2011. (EI) 
[11] Kuan-Yu Chen, Berlin Chen, "Relevance language modeling 
for speech recognition," the 36th IEEE International 
Conference on Acoustics, Speech, and Signal Processing 
(ICASSP 2011), pp. 5568-5571, Prague, Czech Republic, 
May 22-27, 2011. (EI) 
[12] Shih-Hsiang Lin, Ea-Ee Jan, Berlin Chen, "Handling verbose 
queries for spoken document retrieval," the 36th IEEE 
International Conference on Acoustics, Speech, and Signal 
Processing (ICASSP 2011), pp. 5552-5555, Prague, Czech 
Republic, May 22-27, 2011. (EI) 
[13] Kuan-Yu Chen, Berlin Chen, "A study of topic modeling 
techniques for spoken document retrieval," 2010 APSIPA 
Annual Summit and Conference (APSIPA ASC 2010), pp. 
237-242, Biopolis, Singapore, December 14-17, 2010.  
[14] Ea-Ee Jan, Shih-Hsiang Lin, Berlin Chen, "Transliteration 
retrieval model for cross lingual information retrieval," the 
6th Asia Information Retrieval Societies Conference (AIRS 
2010), pp. 183-192, Taipei, Taiwan, December 1-3, 2010.  
[15] Shih-Hsiang Lin, Berlin Chen, Ea-Ee Jan, "Improving the 
informativeness of verbose queries using summarization 
techniques for spoken document retrieval," the 7th 
International Symposium on Chinese Spoken Language 
Processing (ISCSLP 2010), pp. 75-79, Tainan, Taiwan, 
November 29 - December 3, 2010. (EI) 
[16] Shih-Hsiang Lin, Yao-Ming Yeh, Berlin Chen, “Extractive 
speech summarization － From the view of decision theory,” 
the 11th Annual Conference of the International Speech 
Communication Association (Interspeech 2010), pp. 1684-
1687, Makuhari, Japan, September 26-30, 2010. 
[17] Hung-Shin Lee, Hsin-Min Wang, Berlin Chen, “A 
discriminative and heteroscedastic linear feature 
transformation for multiclass classification,” the 20th 
International Conference on Pattern Recognition (ICPR 2010), 
Istanbul, Turkey, August 23-26, 2010. (EI) 
[18] Shih-Hsiang Lin, Berlin Chen, “A risk minimization 
framework for extractive speech summarization,” the 48th 
Annual Meeting of the Association for Computational 
Linguistics (ACL 2010), pp.79-87, Uppsala, Sweden, July 
11–16, 2010. 
[19] Kuan-Yu Chen, Hsuan-Sheng Chiu, Berlin Chen, “Latent 
topic modeling of word vicinity information for speech 
recognition,” the 35th IEEE International Conference on 
Acoustics, Speech, and Signal Processing (ICASSP 2010), pp. 
5394-5397, Dallas, Texas, USA, March 14-19, 2010. (EI) 
[20] Shih-Hsiang Lin, Yu-Mei Chang, Jia-Wen Liu, Berlin Chen, 
“Leveraging evaluation metric-related training criteria for 
speech summarization,” the 35th IEEE International 
Conference on Acoustics, Speech, and Signal Processing 
(ICASSP 2010), pp. 5314-5317, Dallas, Texas, USA, March 
14-19, 2010. (EI) 
[21] Hung-Shin Lee, Berlin Chen, “Generalized likelihood ratio 
discriminant analysis,” IEEE workshop on Automatic Speech 
Recognition and Understanding (ASRU 2009), pp. 185-163, 
Merano, Italy, December 13-17, 2009. (EI) 
[22] Shih-Hsiang Lin, Berlin Chen, “Topic modeling for spoken 
document retrieval using word- and syllable-level 
information,” the 3rd workshop on Searching Spontaneous 
Conversational Speech (SSCS 2009) (in conjunction with 
ACM Multimedia 2009), pp. 3-10, Beijing, China, October 23, 
2009. 
[23] Hsin-Min Wang, Berlin Chen, “Mandarin Chinese broadcast 
news retrieval and summarization using probabilistic 
generative models,” 2009 APSIPA Annual Summit and 
Conference (APSIPA ASC 2009), Sapporo, Japan, October 4-
7, 2009.  
[24] Shih-Hsiang Lin, Berlin Chen, “Improved speech 
summarization with multiple-hypothesis representations and 
Kullback-Leibler divergence measures,” the 10th Annual 
Conference of the International Speech Communication 
Association (Interspeech 2009), pp. 1847-1850, Brighton, 
U.K., September 6-10, 2009. 
[25] Shih-Hsiang Lin, Yueng-Tien Lo, Yao-Ming Yeh, Berlin 
Chen, "Hybrids of supervised and unsupervised models for 
extractive speech summarization," the 10th Annual 
Conference of the International Speech Communication 
Association (Interspeech 2009), pp. 1507-1510, Brighton, 
U.K., September 6-10, 2009.  
 
國內會議論文 
[1] Bang-Xuan Huang, Hank Hao, Kuan-Yu Chen, Berlin Chen, 
"Recurrent Neural Network-based Language Modeling with 
Relevance Information," ROCLING XXIV: Conference on 
Computational Linguistics and Speech Processing (ROCLING 
2012), September 21 - 22, 2012. (in Chinese) (Best Paper 
Award) 
國科會補助計畫衍生研發成果推廣資料表
日期:2012/11/07
國科會補助計畫
計畫名稱: 語音搜尋與摘要方法之進一步研究
計畫主持人: 陳柏琳
計畫編號: 98-2221-E-003-011-MY3 學門領域: 自然語言處理與語音處理 
研發成果名稱
(中文) 語音摘要架構與模型
(英文) Speech summarization framework and modeling techniques
成果歸屬機構
國立臺灣師範大學 發明人
(創作人)
陳柏琳,林士翔
技術說明
(中文) 我們發展出基於風險最小化的語音摘要架構，將重要語句選取過程視為一種決策
問題。在本研究，許多選取策略與模型化範式被提出來巧妙地結合監督式與非監
督式摘要模型，除了能繼承各自模型的優勢外，亦能藉由結合來克服各自模型本
身的缺陷。同時，所發展出的摘要方法，能透過適當的減損函數設計來有系統地
描述語句與被摘要語音文件、以及語句與語句間的關係。從一系列的廣播新聞摘
要實驗顯示，我們所發展出的語音摘要方法能較現有方法有相當不錯的效能提升。
(英文) we adapt the notion of risk minimization for extractive speech summarization by 
formulating the selection of summary sentences as a decision-making problem. To this 
end, we have developed several selection strategies and modeling paradigms that can 
leverage supervised and unsupervised summarization models to inherit their individual 
merits as well as to overcome their inherent limitations. On top of that, various 
component models are introduced, providing a principled way to render the redundancy 
and coherence relationships among sentences and between sentences and the whole 
document, respectively.
產業別 其他專業、科學及技術服務業
技術/產品應用範圍 多媒體(語音文件)之瀏覽、摘要與檢索
技術移轉可行性及
預期效益
提升多媒體(語音文件)處理之功效
註：本項研發成果若尚未申請專利，請勿揭露可申請專利之主要內容。
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
