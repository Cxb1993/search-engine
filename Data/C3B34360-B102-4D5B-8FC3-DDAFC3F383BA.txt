 ii 
目錄 
第一章 序論 .............................................................................................................................. 1 
1.1 研究計畫背景 .............................................................................................................. 1 
1.2 研究計畫目的 .............................................................................................................. 2 
第二章 相關研究 ...................................................................................................................... 3 
2.1 入侵偵測系統概觀 ...................................................................................................... 3 
2.1.1 網路型入侵偵測系統 .............................................................................................. 3 
2.1.2 主機型入侵偵測系統 .............................................................................................. 3 
2.1.3 誤用型入侵偵測系統 .............................................................................................. 4 
2.1.4 異常型入侵偵測系統 .............................................................................................. 5 
2.1.5 混合型入侵偵測系統 .............................................................................................. 6 
2.2 異常行為的定義 .......................................................................................................... 6 
2.3 異常偵測技術 .............................................................................................................. 7 
2.3.1 Learning Rules Anomaly Detector (LERAD) [32] .................................................. 7 
2.3.2 Network Traffic Anomaly Detector (NETAD) [29] ................................................. 8 
2.4 分類技術 ...................................................................................................................... 8 
2.4.1 Repeated Incremental Pruning to Produce Error Reduction (RIPPER)................... 9 
2.4.2 Simple Learner with Iterative Pruning of Produce Error Reduction (SLIPPER) .. 10 
2.5 支持向量機 ................................................................................................................ 12 
2.6 關聯警訊 .................................................................................................................... 13 
2.6.1 關聯警訊的分類 .................................................................................................... 15 
2.6.2 關聯警訊的方法 .................................................................................................... 15 
2.7 預測攻擊 .................................................................................................................... 18 
2.8 網路資料收集平台 – TESTBED@TWISC [41].......................................................... 19 
第三章 具規則回饋之入侵偵測系統 .................................................................................... 21 
3.1 基於規則回饋之整合型入侵偵測系統 .................................................................... 21 
3.1.1 系統架構 ................................................................................................................ 21 
3.1.2 資料分析 ................................................................................................................ 22 
3.1.3 入侵偵測、特性萃取與分類 ................................................................................ 22 
3.1.4 規則回饋 ................................................................................................................ 23 
3.1.5 偵測演算法 ............................................................................................................ 24 
3.2 實驗與分析 ................................................................................................................ 25 
3.2.1 實驗環境與方法 .................................................................................................... 25 
3.2.2 SNORT 在 DARPA 1999 上之偵測效能分析 ...................................................... 26 
3.2.3 純資料分析結果 .................................................................................................... 27 
3.2.4 混合資料分析 ........................................................................................................ 31 
 iv 
圖目錄 
圖 2.1 網路型入侵偵測系統之佈署 .......................................................................................... 3 
圖 2.2 主機型入侵偵測系統之佈署 .......................................................................................... 4 
圖 2.3 IREP、RIPPER2 以及 C4.5RULES 之分類效率比較（WEATHER 資料集） ........... 9 
圖 2.4 BOOSTING 為利用 VOTING 的方式來選出最佳分類子的方法 .............................. 10 
圖 2.5 SLIPPER 與其他分類演算法在不同資料集下的錯誤率比較 .................................... 11 
圖 2.6 SVM 的二維分類範例 ................................................................................................... 12 
圖 2.7 決策函數之線性分類 .................................................................................................... 13 
圖 2.8 多步驟攻擊示意圖 ........................................................................................................ 14 
圖 2.9 攻擊者入侵手法之演進(圖片來源:[CERT 2003])....................................................... 14 
圖 2.10 從警訊關聯矩陣中取出的攻擊圖 .............................................................................. 17 
圖 2.11 利用 APRIORI 演算法找出的警訊序列建立攻擊樹 ................................................ 18 
圖 2.12 TESTBED@TWISC 系統概觀 [60]............................................................................ 20 
圖 3.1 基於規則回饋之整合型入侵偵測系統架構圖 ............................................................ 22 
圖 3.2 規則回饋示意圖 ............................................................................................................ 24 
圖 3.3 實驗流程 ........................................................................................................................ 25 
圖 3.4  MIT LL DARPA 1999 資料集之逐日攻擊分布 ......................................................... 27 
圖 3.5 利用 SLIPPER 演算法分類後得到的「異常」封包規則（純資料） ...................... 28 
圖 3.6 SLIPPER 規則轉換成 SNORT 格式之規則（純資料） ............................................. 29 
圖 3.7 不同訓練資料的 AIDS、規則回饋前的 SNORT (SNORT)以及規則回饋後的 SNORT 
(SNORT*) 以誤報容忍個數為基礎之偵測數比較（全 201 種攻擊案例） ........................ 30 
圖 3.8 不同訓練資料的 AIDS、規則回饋前的 SNORT (SNORT)以及規則回饋後的 SNORT 
(SNORT*) 以誤報容忍率為基礎之偵測數比較（全 201 種攻擊案例） ............................ 30 
圖 3.9 整合型 IDS 與其他實驗之偵測率比較 ....................................................................... 31 
圖 3.10 利用 SLIPPER 演算法分類後得到的「異常」封包規則（混合資料） ................ 32 
圖 3.11 SLIPPER 規則轉換成 SNORT 格式之規則（混合資料）........................................ 32 
圖 3.12 基於誤報容忍數並利用混合資料的偵測比較 .......................................................... 33 
圖 3.13 基於誤報容忍率並利用混合資料的偵測比較 .......................................................... 33 
圖 3.14 分析混合資料並以攻擊種類為基礎之偵測結果 ...................................................... 34 
 vi 
表目錄 
表 3.1 不同訓練資料對於 AIDS 在不同誤報容忍率下其偵測率之影響，並與 SNORT 比較
.................................................................................................................................................... 28 
表 3.2  SNORT*的偵測評估，並與 NETAD 和 CIDS 做比較............................................. 31 
表 3.3 本系統所擷取之特徵資訊 .......................................................................................... 41 
表 3.4 TCP/IP 中各特徵資料的異常值 ................................................................................. 42 
表 3.5 經特徵選取後所採用的特徵資訊 .............................................................................. 43 
表 3.6 正常與異常的資料格式 .............................................................................................. 44 
表 3.7 NETAD 使用的訓練資料集(資料型態皆為 NORMAL)........................................... 49 
表 3.8 SVM 使用的訓練資料集 ............................................................................................ 49 
表 3.9 NETAD 使用的測試資料集(資料型態含正常以及四大類攻擊) ............................. 50 
表 3.10 SVM 使用的測試資料集 .......................................................................................... 51 
表 3.11 純資料實驗各攻擊種類詳細之偵測率 .................................................................... 52 
表 3.12 混合正常行為資料實驗各攻擊種類詳細之偵測率 ................................................ 55 
表 3.13 測試混合異常行為實驗用之資料數量 .................................................................... 56 
表 3.14 混合異常行為資料實驗各攻擊種類詳細之偵測率 ................................................ 57 
表 4.1 各特徵値之權重表 ........................................................................................................ 64 
表 4.2 事先建立的規則資料庫 ................................................................................................ 67 
 2 
習方法相信能夠得到不一樣的偵測效果。 
1.2 研究計畫目的 
今日的網路具有越來越多的多變性，且透過系統弱點入侵的惡意行為也日益猖獗，
因此藉由使用一套能夠自動學習與偵測的入侵偵測系統來保護電腦系統是必要的。本計
劃的目的再發展一個具有規則回饋(Rule Feedback)及攻擊預測(Attack Prediction)的整合
是入侵偵測系統，並透過加入真實網路資料的分析，使得系統更能在實際的網路下發揮
效果。本計劃所提出之系統具有以下之特性及優點： 
(1)真實網路資料分析：DARPA 資料應用於異常偵測系統(Anomaly-Based IDS)具有其
潛在的問題，因此透過這樣的資料所訓練出來的正常行為模組，通常與實際網路的需求
差異甚大。有鑑與此，本計畫擬在 DARPA 資料及之外，混合加入真實網路資料以強化
模組之訓練。 
(2)規則回饋：如前述，我們希望加入真實網路的資料。且所有訓練所需的資料都希
望是無攻擊(Attack Free)的資料，使得所訓練的模組能夠完全代表「正常行為」。在本計
劃中，我們擬採用誤用偵測系統 Snort 來過濾真實網路的封包，由於誤用型偵測系統並非
能百分之百偵測出攻擊，因此在本計劃中擬透過規則回饋的機制，讓後端的異常偵測模
組所偵測出可能異常的行為，經由分類器(Classifier)分類並產生其規則，如此可增加前端
誤用偵測系統之強韌度。 
(3)攻擊預測；入侵偵測系統會在攻擊入侵事件發生的同時，發出一個警訊(Alert)通
知系統管理者。網路攻擊大多屬於多步驟的攻擊行為。隨著多步驟攻擊行為的產生，入
侵偵測系統也會產生多個相對應的警訊通知系統管理者。許多攻擊行為若能早期預測其
可能之行為模式，便能做最好的預防與反制。 
整合誤用偵測與異常偵測系統並進一步採用規則回饋機制已有論文進行研究，如
[21][40][46]。在[21]中，作者建立一個整合 MIDS 與 AIDS 協力運作之系統，命名為
CAIDS(Cooperative Anomaly and Intrusion Detection System)，其優點為可同時偵測已知攻
擊(Known Attacks)及網路異常(Network Anomalies)。該系統首先由 MIDS 偵測已知的攻
擊，然後將未偵測到攻擊的封包傳給AIDS。最後再由AIDS產生異常特徵值回饋給MIDS。 
在過去許多專家學者們有部份針對上述議題發表論文及相關研究，我們希望綜合這
些方法的優點並針對其缺點加以改善。今日的誤用型入侵偵測系統，無法偵測新的攻擊
行為（Novel Attacks），而在一個整合式的入侵偵測系統之角度，我們將嘗試利用這種入
侵偵測系統的特性，來讓誤用型入侵偵測系統能夠有學習的功能，而不僅僅使用那些固
定的規則資料庫，而且也能透過跟入侵偵測系統研發商的聯接進行規則的更新。除了誤
用型入侵偵測系統有學習新攻擊的功能外，在關聯警訊的部份，針對誤用型入侵偵測系
統所產生之警訊，比對原有警訊規則資料庫建立警訊關聯圖之外，還能針對新的未知的
新攻擊步驟產生新的警訊關聯及增加警訊規則。因此本研究將提出一個具規則回饋的整
合型入侵測測系統架構來改善整體的偵測效率自動學習新的攻擊並提供更準確的攻擊預
測。實驗資料集的部份除了採用常見的 DARPA 資料集之外並混合真實網路環境及模擬
環境的網路封包，提供更全面性的資料。 
 4 
 
圖 2.2 主機型入侵偵測系統之佈署 
2.1.3 誤用型入侵偵測系統 
誤用型入侵偵測系統(Misuse Intrusion Detection System, MIDS)，分析方式屬於「誤用
偵測(Misuse detection)」，是時下入侵偵測系統最常使用的分析方式，通常此類的偵測系
統會預先建立有關攻擊行為的參考樣本(Patterns)，進而建立龐大的樣本資料庫(Patterns 
Database)，利用預先建立好的樣本資料庫，來比對輸入資料是否有符合資料庫中的數值，
若符合便能判斷攻擊行為，反之則視為正常行為。過去在誤用偵測的方法中，主要可分
為兩大類：一類即是規則基底(Rule-based)，另一類則是以狀態轉換來判斷(State-based)。
近年來有其他相關之分析方式[5]，可另外透過模組化、專家系統以及鍵盤輸入監聽來加
強誤用型入侵測的能力，此五種方法主要概念如下： 
(1)  以規則為基底(Rule-based)：系統本身會預先建立參考樣本資料庫，其中參考樣本所
紀錄的資訊皆為攻擊行為，當有資料接收時會跟樣本資料庫進行比對，以此方式來
判斷是否為攻擊，此乃誤用偵測最常使用的方式。 
(2)  以狀態轉換為基底(State-based)：作業系統執行程序時會產生系統呼叫序列(System 
call sequence)，透過此序列來判斷是否屬於攻擊行為，此類的方式亦會事先建立有關
攻擊行為的序列，藉以此來比對。 
(3)  以模組為基底(Model-based)：類似於前兩者之概念，除了事先建立攻擊行為的資訊
外，還會針對各攻擊行為建立個別的審核資料，以透過更詳盡的比對來判斷攻擊與否。 
(4)  專家系統(Expert system)：透過專家來針對系統本身做滲透偵測，並為系統所存在的
漏洞與弱點，建立相對應的偵測規則。 
(5)  鍵盤輸入監聽(Keystroke monitoring)：主要是監聽使用者在輸入鍵盤的情況，透過這
樣的方式來判斷使用者是否有出現不正常的情況發生，此法的應用層面較偏向監聽
而非偵測。 
誤用型入侵偵測系統的最大缺點就是樣本資料庫的更新將影響整個系統的偵測能
 6 
2.1.5 混合型入侵偵測系統 
混合型入侵偵測系統(Hybrid Intrusion Detection System, HIDS)，此類的入侵偵測系統
主要是為了整合誤用偵測與異常偵測兩大偵測的優點，以彌補其缺點，透過誤用偵測在
判斷上得比對樣本資料庫之優勢，以及異常偵測在針對新型態之攻擊的判斷，使傳統型
單一分析方式的入侵偵測系統能發揮其優勢，達到整合後更進一步提高系統的偵測率，
並期望降低誤報率。 
此配置方式針對各系統的需求而有所差異，一般而言，針對網路型態的資料分析，
較常將誤用偵測放在網路最前端做為第一道防線，而異常偵測則放在後端做輔助偵測，
此法之重點在於，誤用偵測能夠即早偵測到現有的異常行為，即便有新型態之攻擊無法
辨識，也能透過第二道異常偵測來加以分析並判斷，有效減低誤報的情況發生，近年來
已有不少文獻針對此系統進行研究[13][21]。 
2.2 異常行為的定義 
異常型入侵偵測系統在目前研究遇到的瓶頸，除了前述所提到的定義正常行為的困
難與偵測率偏低之外，相對地，並不是所有的異常行為都一定含有攻擊的意圖[15]，包含
了網路本身的異常問題，以及使用者自身的行為異常，並不代表有他人正在嘗試入侵系
統的意圖，這些的影響要素，將會增加異常偵測系統在判斷「異常」與「攻擊」兩者之
間的困難度。 
根據 Mahoney 學者之研究指出，「異常行為」(Anomalous behaviors)，主要可分成五
種類型[29]： 
(1)  使用者行為：非法授權的使用者想透過網路掃描的方式，來探測主機目前所提供的服
務，一般的動作諸如透過 port scan 或 ip sweep 的方式，有可能是攻擊者的事前準備。 
(2)  系統漏洞：作業系統本身所存在的漏洞，使用者若不常更新作業系統的漏洞修補方
案，可能會導致攻擊者利用系統漏洞來達到入侵的目的，常見的攻擊諸如緩衝區溢
位(Buffer overflow)，其所產生的異常行為會根據系統漏洞的種類不同而有所差異。 
(3)  系統回應異常：此類的異常行為可能是由於攻擊者的攻擊行為成立，而使的受害者
主機本身的系統呼叫(System Call)產生異常，使攻擊者能夠接收受害者主機所回應的
訊息，與正常使用者在執行系統程序時產生的回應有所差異。 
(4)  攻擊行為本身之異常：攻擊者在進行攻擊時，可能由於本身對受害者主機所掌握的
資訊不足而出現的問題，有時候也許是攻擊者為了方便，會在一般網路協定下使用
簡單的指令，例如文字協定在 FTP、HTTP 時，攻擊者為了方便而使用小寫字體輸入，
但一般使用者常用的是大寫字體輸入，導致攻擊行為的異常情況。 
(5)  試圖躲避偵測系統之異常：攻擊者在進行攻擊時會加入惡意碼來掩飾真正的攻擊意
圖，通常這類的攻擊會變動封包欄位的資料，諸如錯誤的效驗碼、變動 TTL 值…等
等，用此方式來干擾入侵偵測系統在分析與偵測的準確性。 
然而對於異常偵測的運作，收集大量且完整的正常行為資料並不是那麼容易，尤其
是網路流量的資料非常龐大，且含許多雜訊，這些雜訊都有可能會對異常偵測在訓練偵
測模組時產生問題，因此我們可以透過合併分類工具的方法，如 SVM，來進一步改善異
常偵測所面臨的問題。 
 8 
2.3.2 Network Traffic Anomaly Detector (NETAD) [29] 
本模組延續之前的 LERAD 模組，利用動態建立規則的方式來訓練模組，然而本模
組並非取封包的欄位當成 model 目標，而是以 IP 封包標頭前 48 bytes 的資料，逐 byte 來
做模組的訓練；此外，此模組針對了前三個模組的異常分數計算方式進行改善的動作。 
在前述之 PHAD、ALAD 以及 LERAD 三模組中，主要的差別在於偵測的範圍以及
規則建立的方式，而異常值的計算方式大同小異，在 NETAD 之異常偵測模組中，基於
前三個異常偵測模組尚有部份考量點上的不足，針對了 PPMC 法的異常分數計算方式做
了以下的改善，分成了以兩個主要的子模組： 
(1) 因為訓練的過程中是沒有攻擊事件的，因此 n 值應為 0，並以 na來表示前次
發生新值至訓練過程結束為止分析到的封包數，而 t 為封包數而不為實際的時間。 
(2) 當 r 值接近 255 時（一個位元組能出現的可能值從 0~255 共 28 種），正象徵
著該欄位的狀態幾近均勻分配，因此，需要視 r 值減少產生規則之權重（Weight），如
下列 (2-4) 表示 NETAD 的第一個子模組： 
t * na (1 – r / 256 ) / r 
(3) 令某值 i 的位元組發生的頻率為 fi，ti 為該值 i 第一次出現回溯至上次出現新
值所歷經的封包數，因此第二個子模組為 (2-5)： 
ti / (fi + r / 256) 
綜合兩個子模組(2-4)以及(2-5)，能夠得到 NETAD 模組中單一封包的異常值 ANETAD，
如方程式 (2-6) 所示： 
ANETAD = Σ [t * na (1 – r / 256 ) / r + ti / (fi + r / 256)] 
在 1999 DARPA 的偵測率上，185 種可能偵測的攻擊行為，在 training 過程中 100 false 
alarms 的標準下（每日至多 10 個 false alarms），能夠偵測到其中 132 種，具有更高的偵
測率。 
在研究中，我們將以前述各異常偵測模組之封包分析觀念，對於封包資料中的每一
個 byte 進行分析並計算其異常值，以非固定式模組及隨機建立規則為基礎，進行入侵偵
測的實驗工作。 
2.4 分類技術 
「分類」（Classification）是一個應用在許多方面的方法，凡是遭遇到許多不同性質
的事物時，我們總是會想將之歸類並定義出每一個類別所具有的特徵；因此，在「資料
探勘」（Data mining）的領域中，「分類」是一個能夠說明資料特徵的方法，如 C4.5 rules、
C5.0 rules、關聯法則（Association rules）以及 Apriori 演算法等。 
「資料探勘」中的分類法，可藉由許多種的方式來實作，如：決策樹（Decision tree）
[2][3][4][5][6][7][9][10][11][17][42]、類神經網路（Neural Network）、關聯法則（Association 
rule）[26]等，另外，研川幸雄等學者以貝氏網路（Baysian network）來偵測主機型 IDS
的異常行為並區分出可能的阻斷式服務攻擊行為 [54] ；其中，我們將採用決策樹的方
法，來對資料集進行分類，並建立出分類的規則；這些分類的規則中，具有預測能力，
能夠根據訓練妥當的資料所產生的規則，對資料進行分類。入侵偵測方面的應用，如
Hussian 等人即利用分類法對阻斷服務式攻擊進行分類 [20]，以及 Cohen 等人以 RIPPER
(2-4) 
(2-5) 
(2-6) 
 10 
多，但是比 C4.5rules 少（圖 2.3）；錯誤率方面，RIPPER 則比 I-REP 低。 
2.4.2Simple Learner with Iterative Pruning of Produce Error Reduction (SLIPPER) [11] 
傳統的規則學習器，儘管有好的學習結果，但是卻有複雜、不易實作以及不易為研
究者瞭解等缺點，W.W. Cohen 有鑑於此，在 1999 年提出了 SLIPPER 之分類演算法[11]，
以 confidence-based boosting 的方式來取代傳統的 set-covering 規則學習方式，能夠處理大
量的資料並且具有好的學習結果，對於 n 筆既有的資料，SLIPPER 之時間複雜度將不大
於 Ο(nlogn)，複雜度上勝過 REP 以及 I-REP 和 RIPPER 等分類演算法。 
Boosting 是一個資料探勘中，處理分類器的方法，其涵義在於給予給一筆資料權重，
並產生多個不同的「分類子」（Classifier），每個「分類子」（意義近似「規則」）均能夠
將資料分成兩類，對於 T 個分類子，我們須從這些分類子 C1, C2, …, CT 中選出一個最能
夠適當地將資料分成兩類的分類子，因此每一個分類子均會進行「投票」（voting）的動
作，最後整合投票結果來決定最好的分類子，這樣的動作能夠提升資料分類的正確性。 
關於 boosting，舉例來說，假定你今天生了病，有 S1、以 S2 及 S3 三種症狀，為了確
定自己到底是什麼病，跑去問 7 位醫生 D1, D2, …, D7，每一位醫生根據經驗來做出診斷
並個別給予處方 R1, R2, …, R7，有三種可能的疾病被醫生們判斷出，因此我們得到以下這
些診斷： 
C1: A2, C2: A1, C3: A2, C4: A3, C5: A3, C6: A2, C7: A2 
因此我們從中得知了，有 1 位醫生認為你是 A1 疾病、4 位醫生認為你是 A2 疾病、2
位醫生認為你是 A3 疾病，由於 A2 被認為的次數最多，我們將給予之最多的「權重」
（weight），因此挑選了 A2 作為了你最可能罹患的疾病。切換至 boosting 的觀點，「醫生
們」便為訓練的實例（training instance）；「症狀」為項目集（Itemset），如同規則中的「條
件」（Condition）；「處方」即為規則（Rules）；「疾病」即為類別（Class）；而「你」則是
經過訓練後的一個新的分類目標 instance。 
Boosting 即利用這樣 voting 的方式，來選出最佳的分類子。關於 boosting 的觀念，
如圖 2.4 所示。 
 
圖 2.4 Boosting 為利用 voting 的方式來選出最佳分類子的方法 
C1 
C2 
CT 
Data 
Combine 
Votes 
New Data 
Sample 
Class 
Prediction 
 12 
2.5 支持向量機 
支持向量機(Support Vector Machine, SVM)是一種機器學習的方法，由 Vapnik 等學者
於 1992 年提出 [6]，屬於監督式學習的一種，主要常被用於統計分類以及回歸分析中，
SVM 是一個基於線性分類方法而衍生的多維分類器，可作為多分類用(Multi-Class 
Classification)，它可以找出最大間隔線(Hyperplane)來分類樣本資料，而沿著這條最大間
隔線的資料便稱之為支持向量(Support vector，亦稱為 Hypothesis)，如圖 2.6 所示。 
 
圖 2.6 SVM 的二維分類範例 
SVM 顧名思義，支持向量機，其作法就是將向量映射到一個多維度的空間，亦稱之
為超平面空間，在這樣一個超平面空間中，我們可以找到一條區分這些資料的最大間隔
線，假設間隔線的間隔距離越大，代表我們可以分類的資料越準確，訓練出來的 SVM 模
組也相對地提高分類的正確率，而影響這個間隔距離的最大因素是在於樣本資料集，若
資料集的內容是混雜的，或者是含有太多的雜訊，找到的間隔線可能無法將資料做正確
的分類，則 SVM 所訓練出來的模組其正確率就會受到影響，所以對於我們給 SVM 訓練
的樣本資料集，必須是完整的資料，這樣訓練出來的模組才會正確。 
SVM 的資料分類有幾項基本定義如下： 
(1)  Xi：是一個向量資料集，如(X1, y1), (X2, y2), …, (Xi, yi)，Xi = {x1, x2, …, xd} ∈  Rd，其
中 x 表示此向量中的各個屬性值，i = 1, …, l 
(2)  yi：表示向量的類別的標籤(Label)，通常以+1 或-1 表示，yi ∈  {+1, -1}，i = 1, …, l 
(3)  d：表示向量資料集中所有屬性的數量，又可代表 Xi 的維度大小，為 Xi 的集合。 
(4)  l：表示向量資料集的數量，為 yi 的集合。 
(5)  f：決策函數，此函數將資料依據類別標籤分類。 
向量資料集本身須有明確標記屬於那一類別的標籤，以此標籤才能判斷資料是屬於
+1 或-1，決策函數會針對此資料找出最大間隔線 f：x．w + b，若 f(x) > 0，則表示為+1，
反之表示為-1，如圖 2.7 所示。 
 
hypothesis 
hyperplane 
hypothesis 
(+1, positive) 
(-1, negative) 
 14 
採用防火牆已顯不足，因此紛紛加入入侵偵測系統以彌補防火牆的不足之處。 
當我們利用入侵偵測系統來偵測攻擊者的入侵行為時，發現到這些入侵者的
攻擊行為發生時，會產生相對應的警訊(Alert)，這些警訊都是須要系統管理員去
分析的。但這些大量且單一的警訊，只單靠系統管理員逐一去分析是相當耗時耗
力的。所以在這種環境下只有單純的入侵偵測系統是不夠的，所以必須採用關聯
警訊的技術幫助系統管理員進一步分析這些大量且單一的警訊，已顯不足。 
在現實環境中入侵偵測系統會產生大量的警訊(Alert)。許多網路攻擊都是多
步驟的攻擊行為，如圖 2.8 所示。這種單一步驟的攻擊行為混雜著大量的警訊時，
我們要如何去發現這一個警訊是屬於某一攻擊者多步驟攻擊行為的其中一個步
驟呢？利用人力去分析這些警訊是一件耗時、耗力的工作。所以警訊關聯(Alert 
Correlation)是管理入侵偵測系統所產生大量警訊的一項重要的技術。 
 
圖 2.8 多步驟攻擊示意圖 
很多企業都會建立 SOC(Security Operation Center) - 資訊安全防護營運中
心，其中 SOC 也建置了防火牆及入侵偵測系統等設備，來防止外部的網路攻擊。
但如圖 2.9 所示，網路攻擊的手法越來越複雜，且大部份網路攻擊多屬於多步驟
的攻擊行為，隨著多步驟攻擊行為的產生，入侵偵測系統也會產生多個相對應的
警訊通知系統管理者，那也意味這些經由入侵偵測系統所產生大量的低階警訊
中，也有著多步驟的關連性。事實上我們實際去觀察這些警訊也是如此。如果單
單只靠系統管理員，要如何去發現這一個警訊是屬於某一攻擊者多步驟攻擊行為
的其中一個步驟呢？利用人力去分析這些警訊是一件耗時、耗力的工作。所以關
聯警訊是管理入侵偵測系統所產生大量警訊的一項重要的技術。 
 
圖 2.9 攻擊者入侵手法之演進(圖片來源:[CERT 2003]) 
關聯警訊的目地除了在大量的低階警訊中找出有關聯的警訊，辨別出高階的
 16 
紹一下相關的論文研究。 
1. 利用事先建立警訊的必要(Prerequisite)及後果(Consequence)關係： 
在 Peng Ning[39]的研究中，它是屬於定義分類中的第一類，事先建立大量
的警訊規則。因為在多步驟攻擊中，每一個警訊都是高階攻擊行為的其中一個步
驟。所以必須大量警訊中先找出是否有符合規則的警訊，如果有符合再進一步查
看警訊間的資訊是否相符。 
由這個觀念延伸作者提出了一個 Hyper-Alert Type 的架構，將每個警訊定義
成三個部份，分別是(fact, prerequisite, consequence)，fact 則是對應到警訊特徵
值，prerequisite 則是對應到攻擊的必要條件，而 consequence 則是對應到攻擊產
生的後果條件。當警訊產生時，比對警訊兩兩間的必要及後果條件，再進一步依
照警訊的不同，比對警訊間的特徵值，如：來源及目的地位址、來源及目的地埠
等是否完全相符的，且必要警訊發生的時間必需較早，後果警訊發生時間較晚，
才是視為是彼此有關聯。 
但此方法有些缺陷存在，沒有相似特徵值(Feature Similarity)的概念，當有攻
擊者同時利用多台電腦攻擊網路內多部電腦，欲發起分散式阻斷攻擊(DDoS)
時，在攻擊初期發生時可能會被視為是多個獨立無關聯的攻擊行為。 
2. 利用事先建立已知的攻擊情境(Scenario)： 
在 Lingyu Wang[47]研究中，利用 Nessus、Nmap 等此類的弱點掃描軟體，
針對入侵偵測系統所管理的電腦進行掃描的動作，找出各電腦存在的弱點，針對
這些弱點，繪製出所有攻擊者所有可能的攻擊的手法，事先建立網路攻擊圖
(Attack Graph)。並將此網路攻擊圖轉成佇列圖(Queue Graph)，再利用此佇列圖來
關聯入侵偵測系統所產生的警訊。 
在官炳宏及陳亦明的研究中，則是利用彩色派翠網(Colored Petri Net)來替代
某一攻擊行為。因為彩色派翠網有著顯而易懂的圖形介面，且有輔助的推論機
制，方便在大量警訊中找出有關聯性的警訊，進而找出攻擊者的高階攻擊行為。 
3. 不事先建立警訊關係： 
在這方法中，因為不建立警訊間之必要後果條件，也不建立攻擊情境及攻擊
圖，所以這類的方法重點大多針對警訊間特徵值的計算，以及如何找出多步驟攻
擊的方法在研究。 
在 2005 年，S.Lee 等學者提出了一個方法[24]，在每一個預先定義的時間間
格內，先把對應到相同攻擊類別(Attack Calss)且目的地位址相同的警訊先做一個
合併的動作。經由合併過後的警訊再經由計算警訊間的特徵相似值，聚集彼此間
相似的警訊，先減少降低大量低階的警訊。這些特徵值的計算包含了：來源位址、
來源埠、目的地位址、目的地埠、攻擊類別以及時間等的相似程度，先個別的計
算每一特徵值的相似程度，計算後再依其個別權重計算出最後的聚集值。 
如果計算出來的特徵值大於某一事先定義的聚集門檻值，再將這些警訊做一
個聚集的動作。在做完聚集這步驟時，再將這些聚集後警訊依上述列的所列的特
徵值再做一次計算，算出最後的警訊關聯值。 
 18 
訊資料中，先利用時間滑動視窗的概念將警訊切成一段一段，再利用類似 Apriori
的演算法，找出較常一起出現的警訊序列。再將此警訊序列以資料結構中樹的概
念，以樹根為主，找出相同子序列的警訊序列，組成一顆樹，建構好的樹即代表
著多步驟的攻擊行為。當警訊發生時可以跟事先建立好的樹比對是否跟其它警訊
有關聯，如圖 2.11。 
 
圖 2.11 利用 Apriori 演算法找出的警訊序列建立攻擊樹 
2.7 預測攻擊 
關聯警訊的目的，除了在入侵偵測系統所產生的大量警訊中，找出攻擊者的
多步驟攻擊行為，希望能經由低階的警訊得知高階的攻擊意圖外。更希望能在經
由關聯警訊的過程中，進而去預測接下來最有可能的攻擊行為。所以今年來許多
關聯警訊的論文都有提到如果預測攻擊的部份。在這邊針對幾篇論文提出來分
享： 
在 2005 年官炳宏及陳奕明等學者發表一篇文章[51]，提出一個方法利用彩
色派翠網(Colored Petri Net,CPN)事先建立單一多步驟攻擊行為(ex:DDoS、FTP 
Bounce)。此彩色派翠網可以用來代表攻擊者在多步驟攻擊背後的意圖，再利用
隱藏式馬可夫模型(hidden markov model,HMM)，觀察訊此序列由哪個隱藏式馬
 20 
 
圖 2.12 Testbed@TWISC 系統概觀 [60]
 22 
 
圖 3.1 基於規則回饋之整合型入侵偵測系統架構圖 
3.1.2 資料分析 
由 MIT Lincoln Laboratory 所製作的 DARPA 1999 網路資料集，具有多種類
型的檔案，而我們採用其中的 in-spec 類型進行入侵偵測的實驗。 
在進行入侵偵測實驗之前，我們解析了其資料的格式，根據 Forouzan[21]以
及楊豐瑞[52] 等人所述，現行的網路封包的標頭，依序以乙太網路層（Ethernet 
layer）標頭、網路層（Network layer）標頭、傳輸層（Transport layer）標頭以及
封包負載（Payload）方式堆積，並且依照各通訊協定所定義的封包欄位進行欄
位資料的儲存與記載。DARPA 1999 網路資料集以 TCPDump 之二進制（binary）
格式來儲存，其中便依循了網路各階層及其所屬通訊協定，進行欄位資料的排列。 
透過封包資料格式的分析，我們將能對於本資料進行進一步的入侵偵測實驗
與分析。 
3.1.3 入侵偵測、特性萃取與分類 
在處裡完成相關網路資料後，便是進入入侵偵測的測試階段。在 NETAD 之
異常偵測模組中，針對入侵檢測的工作，秉持著以下原則： 
(1) 只檢查流入的封包。 
(2)  將封包 IP 層起始的 48 位元組進行逐 byte 之切割，並非考慮單一之封包欄
位。 
(3)  以通訊協定而言，分成九個子模組，個別對應至常用之通訊協定，且一個封
包可能同時具有多種類型，對於所屬的類型各別計算其異常值並加總，成為封包
的異常值： 
  所有 IP 封包：包含 TCP、UDP 以及 ICMP 等通訊協定。 
Internet 
SNORT 
Rules 
DARPA 
3rd Week 
Traffic 
DARPA 
4~5th Week 
Traffic 
Normal 
Profile 
Detect 
Alarm 
Generator Log 
Real Packets Real Packets 
Real Packets Real Packets 
Simulated 
Packets 
Normal 
NETAD 
Rules 
Anomalous Alarms 
Training Phase Detecting Phase 
Signature 
Generator 
Features 
SNORT 
Rules 
Training Data Testing Data 
Simulated 
Packets 
Mixed 
Training 
Data 
Mixed 
Testing 
Data 
Mixed Packets Mixed Packets 
NETAD 
Model 
Packets 
 24 
並且經由分類器以異常特性為 positive class 進行分類，最後將規則轉換成 MIDS
格式並存入規則集中。 
 
圖 3.2 規則回饋示意圖 
本研究中，規則轉換的方式係以人工分析的方式進行，由於 SNORT 所提出
的攻擊名稱與 IDEVAL 所定義的攻擊名稱不盡相同，且 SNORT 的規則選項部分
對於封包標頭欄位已有格式化的定義範圍，再加上經由 SLIPPER 所建立出的規
則量很少，因此轉換的過程則根據 SNORT 撰寫規則的方式，以人工分析的方式
來進行。 
3.1.5 偵測演算法 
根據前述所討論到的各種方法，茲將之彙整為下一節的主要實驗演算法，我
們分成數個子演算法來說明： 
(1)  資料蒐集與過濾：在 traffic filter 的部份，我們將從網路上所搜集到的
資料，依據我們建立的過慮原則來將符合條件的封包資料記錄到指定的目的檔
案，以供異常偵測系統之使用；時間複雜度為Ο(PacketNo)，其中 PacketNo 為封
包的數量，係因為封包之過濾處理為逐一進行之緣故。 
(2)  異常偵測與特性萃取：在AIDS phase部份之演算法，我們則利用NETAD
之異常偵測演算法來作為 AIDS 子系統；時 間 複 雜 度 為 Ο
(PacketNo+AttrNo)，其中 AttrNo 為特性萃取時所記錄的屬性量，如 NETAD 中利
用 48 個為元組資料來分析，而實際屬性量則根據狀況來調整，由於在進行異常
偵測的訓練與測試等階段時，分別會記錄正常特性與異常特性等資料，因此時間
上與封包數、萃取屬性數有關。 
(3)  分類與規則回饋：在分類上我們利用 SLIPPER 之演算法來進行，其時
間複雜度為Ο(ExampleNo*log ExampleNo)，其中 ExampleNo 為特性資料的筆
數，由於 SLIPPER 為 post pruning之規則修剪機制，因此會將所有 training example
包含後才開始修剪，由於每次包含特性資料時會將之 push 至系統的狀態堆疊
Normal 
Features 
Signatures 
Anomalous 
Features 
Classifier 
Rule 
Transformation 
MIDS AIDS 
From AIDS 
From AIDS Testing 
 26 
進行異常偵測分析與規則回饋，AIDS  phase 所使用到的訓練資料將以三
種資料來做比較，分別是第一週（共五個檔案）、第三週（共七個檔案）以
及第一＆三週（共十二個檔案）等，而測試資料我們以第四～五週（共九個
檔案）的資料為主，規則轉換與回饋之方式則採用前一章所討論到的方法，
利用 SLIPPER 分類器將網路封包特性資料分類，並轉換成 SNORT 格式，進
而更新 SNORT 的 rule set。 
(2)  混合資料（Mixed data）：這部份的實驗所秉持的原則大致上與純資料實驗相
仿，其不同點主要在於我們將利用自行在任意主機上所蒐集到的網路封包，
將之儲存成 TCPDump 格式，並且與 MIT LL DARPA 1999 的訓練資料，藉由
Mahoney 所提出的封包混合方式[30][57]，進行真實與模擬資料的混合；在
挑選欲混合的模擬資料方面，我們將以在純資料實驗中偵測率表現最佳者作
為與真實網路資料合併的對象。本實驗的主要的用意在於測試在理想環境資
料中添加富含雜訊的資料，對於整體偵測效能的影響。 
在實驗的程式設計部分，我們以 Borland C++ Builder 6.0 為主要開發工具，實
作的功能包含了： 
(1)  網路資料過濾器：此為進行異常偵測以及資料混合前所必須使用的工具，能
夠將不需要的資訊過濾並留下需要的網路封包資料。 
(2)  異常偵測器：實作 Mahoney 之 NETAD 異常偵測演算法。 
(3)  特性萃取器：隨著 AIDS 的訓練以及偵測時，會同時截取相關的封包特性，
作為特性分類的 input 資訊。萃取特性時，我們以「隨機」的方式，分別將
正常與異常的特性資料以 2:1 之比例存入分類器所需要的訓練以及測試檔
案，並且會產生相關的屬性定義檔案。 
(4)  偵測率評估器：根據 MIT Lincoln Laboratory 所提出的 IDEVAL，其中記載了
相關的偵測評估原則，此偵測率評估器將實作其評估原則，針對入侵偵測系
統所發出的特定格式警報檔案（*.sim）進行評估，並會顯示誤報率與偵測率
之分析結果，作為偵測率與誤報率的判斷準則。 
(5)  資料混合器：實作 Mahoney 所提出之 SAD 模組中，所使用到的網路封
包混合演算法。 
在實驗上我們所偵測的對象為 MIT LL DARPA 1999 dataset 之網路資料集，
因此偵測的攻擊包含 Probe、DoS、R2L、U2R 以及 Data 等五大類，其中 Data
類別之攻擊可能同時屬於 R2L 或是 U2R 類型；全資料集共包含 201 個攻擊案例，
而在 in-spec 共包含 189 個攻擊案例。 
3.2.2 SNORT 在 DARPA 1999 上之偵測效能分析 
MIT Lincoln Laboratory DARPA 1999 之網路資料集，其攻擊分布如圖 3.4 所
示（此為 in-spec 之資料集，此資料集在第四週第二天沒有資料，因此無攻擊存
在）；從圖中我們能觀察出每一個類別的攻擊在此資料集中，均幾乎存在於每一
天的資料中；經觀察與分析，本資料集在第四週的攻擊行為，多為小流量的攻擊
（Stealthy attacks），而在第五週的攻擊行為，則多為大流量的攻擊（Massive 
 28 
表 3.1 不同訓練資料對於 AIDS 在不同誤報容忍率下其偵測率之影響，並與
SNORT 比較 
 
我們有討論到，SNORT 與 Hwang 等人的偵測結果[21]相近，對於 MIT LL 
DARPA 1999 dataset 之網路資料集僅有約 24%的偵測率，在 100%的誤報容忍度
下僅偵測到 48 種攻擊；而 NETAD 的偵測結果可以到 78%以上的偵測率，其中
原作者 Mahoney 等人的實驗[29]是使用第三週的資料做為訓練資料，我們本著嘗
試的精神，以第一週以及一、三兩週混合的資料做為訓練資料，發現其中以第一
週的資料來做為訓練資料，能夠偵測到的攻擊種類比第三週的更佳，顯示出了
AIDS 對於訓練資料的變異性是相當敏感的，而用一、三週混合的訓練資料，得
到的偵測結果反而不如單獨用第一或第三週的資料，驗證了 Matt Mahoney 曾經
討論到的，訓練時間不宜過長或過短，訓練時間過短可能造成訓練不足而使得
normal profile 不完整，如果過長則會造成過度訓練，對於正常行為定義的完整度
沒有幫助，且使得 normal profile 的儲存資訊過多而影響異常偵測的效率。 
異常偵測的工作完成之後，會得到正常與異常的封包特性資料，因此我們接
著進行分類的工作。我們利用W.W. Cohen所提出的SLIPPER分類演算法 [11] 來
處理這些封包特性資料，由於 NETAD 之模組以 48 bytes 為分析範圍，因此我們
的分類屬性總共有 48 個，分類後得到 positive class 的規則，如圖 3.5 所示。 
圖 3.5 中，類別名稱與條件之間的兩個數字分別為 W+與 W- [11]，係正類別
與負類別案例數所佔之權重比例，因此在 boosting 後 W+將遠高於 W-，W-甚至
可能趨近於 0，表示該規則完全不包含屬於負類別的案例，為較完美之規則；而
error rate 為所產生之規則與 test 檔案中之案例比對後，其不符合規則所佔之案例
比例，突顯出 SLIPPER 在分類後可以得到良好的分類結果，但是耗費的時間則
相對較長。 
 
圖 3.5 利用 SLIPPER 演算法分類後得到的「異常」封包規則（純資料） 
圖 3.5 中我們得到了 6 個異常規則，隨即進行規則轉換，成為 SNORT 之規
則格式，轉換過後的結果如圖 3.6。 
 30 
 
 
圖 3.7 不同訓練資料的 AIDS、規則回饋前的 SNORT (SNORT)以及規則回饋後
的 SNORT (SNORT*) 以誤報容忍個數為基礎之偵測數比較（全 201 種攻擊案
例） 
 
圖 3.8 不同訓練資料的 AIDS、規則回饋前的 SNORT (SNORT)以及規則回饋後
的 SNORT (SNORT*) 以誤報容忍率為基礎之偵測數比較（全 201 種攻擊案例） 
從圖 3.7 以及圖 3.8 中明顯可見，規則回饋後之 SNORT（SNORT*），其對
於 DARPA 1999 之偵測率有顯著的提升，表示從 AIDS phase 所發出的異常中擷
取特性並進行分類，回饋規則給 SNORT 之同時，SNORT 對於多數在先前無法
偵測到的攻擊，於規則回饋後能夠偵測到。 
我們得知了規則回饋後的 SNORT*其偵測率有所改善，接著我們進行混合偵
測，以 MIDS 以及 AIDS 來混合評估（Collaborative IDS; 以 CIDS 表示），其偵
測率與其他實驗的比較如圖 3.9，我們從圖中發現了 CIDS 在約 8%的誤報容忍度
以上時，其偵測率比 AIDS 還要好，其原因在於 SNORT 本身能夠偵測到部份為
NETAD 所無法偵測到的攻擊種類，因此會有這樣的結果。 
 32 
 
圖 3.10 利用 SLIPPER 演算法分類後得到的「異常」封包規則（混合資料） 
由於混合了自行蒐集的資料，因此特性擷取後所包含的資料與 3.3.3 的實驗
中不相同，因此會影響到分類後的結果。仍然是一樣的步驟，我們進行規則轉換，
其結果如圖 3.11 所示。 
 
圖 3.11 SLIPPER 規則轉換成 SNORT 格式之規則（混合資料） 
規則回饋後我們評估整體系統的偵測率與誤報率，在 MIT LL DARPA 1999
的網路資料及中含有 201 個攻擊案例，我們針對誤報容忍度（圖 3.12）以及誤報
容忍率（圖 3.13），比較純資料的異常偵測（1+45；表示用第一週訓練、第四～
五週測試）、混合資料的異常偵測（m1+m45；混合入真實網路的資料）以及具
規則回饋功能之整合型入侵偵測系統（mCIDS）等。 
 34 
0
20
40
60
80
100
Detection Rate
(%)
Probe DoS R2L U2R Data Total
Attack Category
mMIDS mAIDS mCIDS
 
圖 3.14 分析混合資料並以攻擊種類為基礎之偵測結果 
在這部份的實驗中，我們發現了透過混合模擬與真實的網路資料，將使得整
體的偵測率出現下降的情形，其相關的分析，我們將於 3.2.5 中做進一步的討論。 
3.2.5 比較與分析 
我們利用了第三節所提出的方法，在 3.2.3 以及 3.2.4 兩小節進行了實驗，首
先我們先以圖 3.15 做為分析工作的開端。 
在圖 3.15 中，我們能發現利用混合資料進行規則回饋入侵偵測實驗的
mCIDS，比利用純模擬資料來偵測的 CIDS 還略為下降，讓我們回溯至 3.2.4 小
節的圖 3.12 以及圖 3.13 中，偵測率會略為下降，其可能的原因，在於真實網路
的資料是混雜的，具有許多對於異常偵測系統的訓練上沒有幫助的資料，加上
SNORT 本身對於 DARPA 的低偵測率，雖然在初步過濾了可能含有攻擊的資料，
但是仍然可能使得部份的攻擊通過因而添加至訓練資料中，造成偵測率的下降。 
0
20
40
60
80
100
2 4 6 8 10 12
False Alarm Rate (%)
De
te
ct
ion
 R
at
e (
%)
mAIDS mSNORT mSNORT* mCIDS CIDS
 
圖 3.15 混合後的各大模組與純資料下的整合型 IDS 之偵測率比較 
但是儘管如此，對於 SNORT 而言，即使是在富含雜訊的網路環境下，透過
規則回饋後的 mSNORT*，其偵測率仍比原來未經規則回饋的 mSNORT 高出許
多，突顯了規則回饋這動作對於 MIDS 之偵測率的提升是有幫助的。 
 36 
3.3 基於支持向量機之雙層式網路流量異常偵測系統 
大部分的異常偵測系統在訓練階段與測試階段都有其運作特色，基於統計分
類或機器學習的理論，訓練出完整的異常偵測模組，但針對其採用的資料集，隨
著本身的資料屬性散佈，使得正常與異常行為之間的差異性變動不大，這將導致
異常偵測系統在分析測試資料時容易發生誤報之情形，因此除了系統本身的分析
方式，透過加入更精準的分類技術與特徵選取的動作，可以有效改善異常偵測系
統進行判斷的準確性。 
3.3.1 網路流量異常偵測模組的問題 
由於 NETAD 本身是透過計算異常值的方式來建立異常偵測模組，本研究分
析 NETAD 在判斷異常行為的能力後發現，NETAD 整體的偵測率雖然比之前的
異常偵測系統來的高，但是仍擺脫不了誤報率相對高的問題，由於 NETAD 在進
行異常偵測模組的訓練時只能採用完全無攻擊的資料，導致測試階段在判斷其他
數量較少的攻擊資料時，如：DoS 及 U2R 兩大類 [29]，發生誤報的機率相當高，
茲分析造成此原因的問題可能是以下幾點： 
(1)  DARPA 1999 Dataset 乃人工製造之資料，其正常行為的資料雖然近似於
真實網路環境下的資料，但是仍有差異，如 TTL 值的數量以及 Type of Service
只固定四種協定…等等，造成其訓練出來的異常偵測模組在判斷上有所差異。 
(2)  由於 DARPA 1999 Dataset 中，正常行為的網路資料內容與攻擊行為的
網路資料往往是一連續型的內容(如 Source Port)，大部分的數值僅在 0～255 之
間變動，使得其兩者之間的差異幅度不大，因此要偵測出兩者之間的差異更是困
難。  
(3)  除了正常行為的數量遠遠大於 DoS 與 U2R 的數量外，DARPA 1999 
Dataset 中，其來源端與本機端的 IP 位址變動也不大，在訓練偵測模組的時候，
對於 IP 欄位的異常值計算值幅度也跟著縮小，而要偵測 DoS 與 U2R 這兩類攻擊
時，明顯是不容易的。 
有鑑於以上幾點因素，將導致 NETAD 在偵測結果方面，必須在很高的誤報
率下才有可能找出所有的攻擊(每日可容忍誤報約 5000 筆左右) [29]，因此本研究
提出一個新的架構，加入 SVM 幫助資料進行分類，有效改善 NETAD 對於異常
資料判別能力的不足；並針對上述問題點(3)，提出利用特徵選取(Feature selection)
的方式，去除掉多餘的封包欄位資訊，於實驗結果表示此方法的確能有效提昇整
體的偵測率。 
3.3.2 系統架構 
為解決 3.3.1 節所提出之問題，我們提出透過雙層解析的概念，利用 SVM 來
改善網路流量異常偵測模組的能力，其架構如下頁圖 3.17 所示。 
 38 
的特徵資料，有效判斷異常與正常行為之差異，達到提昇整體系統偵測率的效果。 
3.3.3 資料分析 
在進入異常偵測模組前，我們必須針對網路資料進行分析，才能擷取實驗所
需的資料，由於 DARPA 1999 資料集之格式採用 Tcpdump 工具收集而成，屬於
二進制(Binary)的網路封包資料，根據 TCP/IP 協定標準 [16]，現今有線網路環境
下的封包格式，依序應包含 14 個位元組的乙太網路層標頭(Ethernet layer)、20
個位元組的網路層標頭(Network layer)、20 個位元組的傳輸層標頭(Transport layer)
以及不定長度的封包內容(Payload)，按封包編號堆積而成，其所對應的各個協定
不同，所儲存的欄位資料也不相同。 
 
 
 
 
00000000h: A1 B2 C3 D4 00 02 00 04 00 00 00 00 00 00 00 00 
00000010h: 00 01 01 D0 00 00 00 01 46 F0 EE 57 00 07 9B 84 
00000020h: 00 00 00 4A 00 00 00 4A 00 10 83 FD E2 7B 00 18 
00000030h: F3 08 7A F9 08 00 45 00 00 3C 04 33 00 00 80 11 
00000040h: BE F7 8C 82 AF 80 8C 82 AF 01 04 50 00 35 00 28 
00000050h: D5 A9 1F 41 01 00 00 01 00 00 00 00 00 00 03 77 
00000060h: 77 77 06 67 6F 6F 67 6C 65 03 63 6F 6D 00 00 01 
00000070h: 00 01 46 F0 EE 57 00 07 AE EA 00 00 00 3C 00 00 
00000080h: 00 3C FF FF FF FF FF FF 00 10 83 FD E2 7B 08 06 
00000090h: 00 01 08 00 06 04 00 01 00 10 83 FD E2 7B 8C 82 
000000a0h: AF 01 00 00 00 00 00 00 8C 82 AF 80 00 00 00 00 
000000b0h: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 46 F0 
圖 3.18 DARPA 1999 資料集格式 
在圖 3.18 中，紅色網底部份為 Tcpdump 本身的檔案格式標頭，隨後接續的
8 個位元組為「時間戳記(Timestamp)」，而接下來的 8 個位元組(深色網底)，則表
示第一筆封包的原始長度與紀錄長度，根據此欄位記載之數值「00 00 00 4A」表
示此封包長度共有 74 個位元組，因此後續的 74 個位元組包含著 IP 層以及 TCP
層的資訊，最後連接的內容為封包本身的資料，依此規則循序堆積往後的封包資
訊。 
透過資料分析，接下來我們便能擷取出所需要的封包資訊，來進行異常偵測
與特性分類。 
3.3.4 真實網路與模擬網路資料之混合 
本系統除了採用 DARPA 1999 網路資料集外，另外還進行了與真實網路資料
混合的動作，其原因亦根據 3.3.1 節，我們所探討 DARPA 1999 網路資料集在人
Tcpdump format 
Packet length 
 40 
00000000h: A1 B2 C3 D4 00 02 00 04 00 00 00 00 00 00 00 00 
00000010h: 00 01 01 D0 00 00 00 01 46 F0 EE 57 00 07 9B 84 
00000020h: 00 00 00 4A 00 00 00 4A 00 10 83 FD E2 7B 00 18 
00000030h: F3 08 7A F9 08 00 45 00 00 3C 04 33 00 00 80 11 
00000040h: BE F7 8C 82 AF 80 8C 82 AF 01 04 50 00 35 00 28 
00000050h: D5 A9 1F 41 01 00 00 01 00 00 00 00 00 00 03 77 
00000060h: 77 77 06 67 6F 6F 67 6C 65 03 63 6F 6D 00 00 01 
00000070h: 00 01 46 F0 EE 57 00 07 AE EA 00 00 00 3C 00 00 
00000080h: 00 3C FF FF FF FF FF FF 00 10 83 FD E2 7B 08 06 
00000090h: 00 01 08 00 06 04 00 01 00 10 83 FD E2 7B 8C 82 
000000a0h: AF 01 00 00 00 00 00 00 8C 82 AF 80 00 00 00 00 
000000b0h: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 46 F0 
圖 3.20 NETAD 所擷取之範圍 
(1)  訓練階段：異常偵測演算法在訓練階段時，必須定義出正常封包所代表
的特徵，進而建立異常偵測模組，此部份的資料必須是完全無攻擊的資料，因此，
我們採用的是 DARPA 1999 資料集第一週以及第三週的訓練資料；NETAD 在分
析此資料前會先根據其過濾方式，將資料中不必要的封包先行過濾，此步驟可以
有效減少之後在進行模組的訓練與測試所花費的時間。由於此資料是 Tcpdump
格式的網路封包，因此 NETAD 會對此格式的內容進行資料擷取，取出 IP 標頭
起始的 48 位元組欄位資料供訓練與測試，如圖 3.4 深色網底區域。 
(2)  測試階段：建立好異常偵測模組後，會產生完整的正常資料(normal 
profile)，透過此偵測模組來分析輸入的資料，並判斷出現異常的封包，此部份我
們採用的測試資料為 DARPA 1999 資料集第四週與第五週的資料進行測試。異
常偵測模組在分析測試資料集的同時會產生一個警報檔，由於此警報檔的內容並
不完全是真正的攻擊，還必須透過其評估程式才能判斷真正的攻擊為何，所以我
們只會將評估後判定成真正是攻擊行為的資料取出，以供接下來進行特徵選取的
動作並提供第二層的 SVM 模組使用。 
在進行異常模組訓練的階段，我們會同時擷取出封包欄位的特徵資料，這些
特徵資料將會另外儲存成一個正常資料集；而在測試階段，當 NETAD 發出警訊
時，我們只擷取產生正確警報的封包特徵資料，並將其儲存成異常資料集，此兩
類資料集為接下來的特徵選取與 SVM 分類用。 
3.3.6 特徵選取 
經過第一層 NETAD 分析後的資料，我們已將其 Tcpdump 格式的型態，轉換
成一般數值型態，且依 NETAD 本身擷取的 48 位元組 IP 標頭欄位，總共有 32
欄的特徵資訊，大致上各欄位代表的特徵資訊如表 3.3 所示，其中 C0 至 C7 乃表
示部份 Payload 資訊。 
由於接下來必須透過第二層 SVM 進行分類，而分類的方式必須利用特徵資
 42 
表 3.4 TCP/IP 中各特徵資料的異常值 
索引標號 特徵資料 異常值 特徵型態 
01 Version 0 靜態資料 
02 Header length 0 個別資料 
03 Type of service 0 靜態資料 
04 Total length 0 個別資料 
05 Identification 2 動態資料 
06 Flags 5 動態資料 
07 Fragment offset 5 動態資料 
08 Time to live 1 動態資料 
09 Protocol 1 靜態資料 
10 Header checksum 0 個別資料 
11 Source address 2 靜態資料 
12 Destination address 1 靜態資料 
13 Options 1 靜態資料 
14 Source port 1 靜態資料 
15 Destination port 1 靜態資料 
16 Sequence number 2 動態資料 
17 Ack. number 2 動態資料 
18 Offset 1 動態資料 
19 Reserved 1 靜態資料 
20 Flags 2 動態資料 
21 Window 0 靜態資料 
22 Checksum 0 個別資料 
23 Urgent pointer 1 靜態資料 
24 Options 1 靜態資料 
參照表 3.4 中的內容，我們再進一步分析 NETAD 所擷取之特徵資料後，發
現在此 32 欄位的特徵中，多數的來源端與本機端之 IP 位址變動量不大而影響異
常偵測模組的準確性，因此，接下來我們將正常與異常的資料集，利用特徵選取
的方式，將多餘的資料特徵移除，此部份的動作我們將去除掉有關 IP 位址的特
徵資訊共 8 欄(剩餘 24 欄)，剩餘欄位如表 3.5 所示。 
經過特徵選取之後的特徵資訊，我們才會提供給第二層的 SVM 分類器來進行資
料的分類與測試。
 44 
表 3.6 正常與異常的資料格式 
Label Features (total 24) 
+1 1:-1 2:-1 3:-0.603175 4:-1 5:-1 6:1 15:-0.984314 … 
+1 1:-1 2:-1 3:0.119048 4:-1 5:-1 6:1 15:-1 … 
+1 1:-0.846154 2:-1 3:-0.666667 4:-1 5:-1 6:-0.375 15:-0.968627 … 
-1 1:0.846154 2:-1 3:-0.174603 4:-1 5:-1 6:-1 15:-0.976471 … 
-1 1:-1 2:-1 3:-0.698413 4:1 5:-1 6:-0.375 15:-0.309804 … 
 …  … 
3.3.8 雙層式異常偵測演算法 
此節乃根據本章 3.3.1 至 3.3.7 中所討論的各元件分工，用以分析本系統在運
作上的效率與時間，我們將整體系統分成以下幾個子演算法來探討，演算法如下
頁圖 3.20 所示： 
(1)  網路資料前置處理：首先在網路資料過濾的部份，我們是以 DARPA 
1999 資料集中五週的數量為分析對象，另外加上我們自行收集的兩週正常資
料，根據我們在 3.3.4 小節中所提出的過濾與混合原則，將網路資料一一轉成新
的檔案來交給 NETAD 使用，因此我們需花費的時間複雜度依附在處理的網路封
包數量，即 O(NumofPackets)，其中 NumofPackets 表示封包的數量。 
(2)  NETAD 偵測演算法與特徵擷取：接下來我們將資料交給第一層的
NETAD 異常偵測演算法，由於 NETAD 需萃取每個封包中前 48 位元組的資料當
成分析的屬性，因此在時間複雜度需加上每個封包各屬性欄位的資料數量，表示
此階段的分析與封包數量以及封包的特性數量有關，因此導出 O(NumofPackets + 
NumofFeature)，由於在這階段我們會同時將特徵擷取儲存成另外的格式，因此
在時間複雜度上的分析是沒有衝突的。 
(3)  特徵選取與 SVM 分類器：在進入第二層的 SVM 分類器之前，系統必
須先經過特徵選取的動作，而特徵選取所使用的資料為經過 NETAD 分析後擷取
的正常與異常的特徵資料數量，因此我們需要將兩種資料合併分析，時間複雜度
應為 O(Numof Normalfea + NumofAbnormalfea)，其中 NumofNormalfea 表示為正
常特徵資料的數量，而 NumofAbnormalfea 為異常特徵資料數量；而 SVM 在進
行分類時，必須依據訓練與測試的資料量來進行分析與判斷，因此我們需要將訓
練與測試的時間綜合，來表示 SVM 整體的時間複雜度，因此我們可以導出
O(NumofFeature * (NumofTrain + NumofTest))，其中 NumofFeature 表示特徵的維
度數量，而 NumofTrain 以及 NumofTest 個別表示訓練與測試的資料筆數。 
 46 
3.4 實驗與分析 
3.4.1 實驗設定 
本實驗所用的作業系統環境為 Windows XP SP2，硬體設備為 Intel Core 2 
Duo 搭配 2GB 的記憶體，而實驗用的資料為 DARPA 1999 Dataset，其中 NETAD
使用的訓練資料以第三週之資料為主，測試資料則以第四、五週之資料為主；而
SVM 使用的資料則是先經過 NETAD 過濾，並將擷取的正常與異常特徵資料進
行混合後為主。 
 
圖 3.21 實驗流程 
上圖 3.21 為本研究主要的實驗流程，我們首先以 DARPA 1999 資料集為主
要輸入資料，另一方面為了加入真實網路環境資料，我們會另行收集，並分成純
資料與混合資料兩個實驗，收集完實驗資料後，由第一層的異常偵測系統 NETAD
針對實驗資料進行訓練與測試，此時 NETAD 會發出警報資訊，透過與 DARPA 
1999 資料集網頁所記載的案例個數，以 IDEVAL 評估後之結果，我們會將屬於
真正警報的封包內容取出，同時產生正常與異常兩大資料的特徵資訊；接著，將
這兩類資料依 3.3.7 節所敘述之步驟，合併為 SVM 的輸入資料，並利用第二層
SVM 的分類技術來做異常偵測，對測試資料進行評估與判斷。 
Initialization 
1st AIDS 
NETAD 
Dataset 
collecting 
2nd AIDS 
SVM 
IDEVAL 
Output 
result 
Input data 
Original/Mixed data 
Output alarm 
Output normal/abnormal feature 
Classification 
 48 
 
圖 3.22 網路拓樸與攻擊示意圖 
由於本系統主要的研究目的在於探討 AIDS 的偵測能力，因此 Snort 本身的
偵測能力不在本系統之考量，所以接下來我們會將自行收集的真實網路正常與異
常資料，分別建立訓練資料集與測試資料集。 
3.4.2.2  訓練資料集 
本研究同時採用了 NETAD 與 SVM 為異常偵測系統，皆必須經過訓練與測
試的階段，由於 NETAD 在訓練過程必須只能使用正常的資料為主，因此必須以
DARPA 1999 資料集中的第三週資料為主；而 SVM 因為可作多元分類，因此 SVM
採用的訓練資料集，可以將正常與異常行為合併，一同給 SVM 使用。有關 NETAD
使用的訓練資料集如表 3.7；SVM 使用的訓練資料集為表 3.8，以下將詳細說明
純資料實驗與混合資料實驗兩系統採用的訓練資料集內容： 
(1)  純資料實驗用：NETAD 使用的為 DARPA 1999 資料集的第三週資料，
資料型態僅有正常資料；SVM 使用的為經 NETAD 過濾後，正常與異常混合的
資料，資料型態有五大類。 
(2)  混合正常資料實驗用：NETAD 使用的為 DARPA 1999 資料集中第三週
與本研究自行收集之第一週網路資料合併，資料型態僅有正常資料；SVM 使用
的為經 NETAD 過濾後，正常與異常混合的資料，資料型態有五大類。
 50 
以下將詳細說明純資料實驗與混合資料實驗兩系統採用的測試資料集內容： 
(1)  純資料實驗用：NETAD 使用 DARPA 1999 第四週及第五週的測試資
料，資料型態內含四大類的攻擊行為；SVM 使用的資料為經 NETAD 過濾後，
重新擷取出的正常與異常混合資料，此為過濾資料，因此數量較少，其中資料型
態一樣有五大類。 
(2)  混合正常資料實驗用：NETAD 除了使用 DARPA 1999 第四、五週資料
外，還必須與本研究自行收集之第二個禮拜的封包內容作為合併；SVM 使用的
資料仍以 NETAD 過濾後重新擷取出的正常與異常混合資料為主。 
表 3.9 NETAD 使用的測試資料集(資料型態含正常以及四大類攻擊) 
測試資料 週數 數量 總計數量 
DARPA 1999 Week 
4 
440,621 
純資料實驗用 
DARPA 1999 Week 
5 
298,098 
738,719 
DARPA 1999 Week 
4 
440,621 
DARPA 1999 Week 
5 
298,098 
混合正常資料實
驗用 
自行收集 Week 2 31,500 
770,219 
 52 
0
10
20
30
40
50
60
70
80
90
100
D
et
ec
tio
n
 
ra
te
 
(%
)
Probe DoS R2L U2R Total
Attack categories
N
S
N + S
N + S + F
圖 3.23 純資料實驗各攻擊種類之偵測率比較 
表 3.11 純資料實驗各攻擊種類詳細之偵測率 
方法 攻擊種類 偵測率 ％ 整體偵測率 ％ 
Probe 88% 
DoS 76% 
R2L 78% 
NETAD 
U2R 70% 
78% 
Probe 97% 
DoS 99% 
R2L 68% 
SVM 
U2R 74% 
85% 
Probe 98% 
DoS 99% 
R2L 78% 
NETAD + SVM 
U2R 80% 
89% 
Probe 99% 
DoS 99% 
R2L 82% 
NETAD + SVM + 
Feature selection 
U2R 90% 
93% 
根據 3.4.3 節我們所提出的評估方式，針對純資料實驗的結果，有關此四種
入侵偵測系統的誤報率與偵測率之關係如下所示。 
 54 
小節列表，其餘步驟與純資料實驗皆相同，因此我們直接來看實驗結果。 
0
20
40
60
80
100
120
140
160
180
200
0 200 400 600 800 1000 1200 1400 1600 1800 2000
Number of false alarms
N
u
m
be
r 
o
f d
et
ec
te
d 
at
ta
ck
s
N
S
N + S
N + S + F
 
圖 3.26 混合正常行為資料實驗針對可容忍誤報數之偵測攻擊數比較 
0
20
40
60
80
100
120
140
160
180
200
0 10 20 30 40 50 60 70 80 90 100False alarm rate (%)
N
u
m
be
r 
o
f d
et
ec
te
d 
at
ta
ck
s
N
S
N + S
N + S + F
圖 3.27 混合正常行為資料實驗針對誤報率之偵測攻擊數比較 
在圖 3.26 與圖 3.27 中我們可看出，在混合資真實網路資料後，對於原始
NETAD 的偵測率有大幅的影響，而經由本系統提出的雙層解析方式，透過 SVM
分類器的幫助，可以有效改善 NETAD 的偵測結果，顯然 SVM 受到的影響比
NETAD 較小，代表真實網路資料對於 SVM 在進行資料分類時，不容易受到干
擾，甚至在經由特徵選取之後的結果，我們可以看出，本系統所偵測到的攻擊數
量能與純資料之偵測結果相仿，而未完全受到真實網路資料的「雜訊」干擾，證
明本系統，對於真實網路環境下的資料，具有適應性的可能。而圖 3.28 為混合
資料的情況下，對於各攻擊的偵測率比較。 
 56 
之網路資料，對於 NETAD 本身的偵測能力確實有非常大的影響。 
3.4.4.2 混合異常行為之網路資料 
此部份的實驗主要目的是要驗證本系統在真實網路環境下，對於網路攻擊的
偵測能力，其攻擊情境我們已於 3.4.2.1 小節探討，根據我們所收集的異常行為
資料，可分為 DoS 與 Probe 兩大類，其中 DoS 的封包數量共 20,321 筆，而 Probe
的封包總數為 33,141 筆，我們在不更動訓練資料集的情況下，將這些收集到的
真實異常行為封包，與測試資料進行合併，有關混合的動作於 3.4 小節介紹，因
此，NETAD 採用的測試資料與 SVM 是相同的，表 3.13 為各攻擊種類封包數量
的詳細列表，由於我們只收集 Probe 與 DoS 兩類型的攻擊，因此 R2L 與 U2R 的
數量仍與原始資料相同，且由於 NETAD 已能偵測出部份 DARPA 1999 資料集中
的攻擊案例，我們便不再使用誤報容忍數與偵測案例的方式分析，而是以針對各
攻擊封包數量的偵測能力來探討。 
表 3.13 測試混合異常行為實驗用之資料數量 
資料型態 數量 總計數量 
Normal 69,839 
Probe 39,997 
DoS 35,088 
R2L 120 
U2R 105 
145,149 
 
0
10
20
30
40
50
60
70
80
90
100
D
et
ec
tio
n
 
ra
te
 
(%
)
Probe DoS R2L U2R Total
Attack categories
N
S
N + S
N + S + F
圖 3.29 混合異常行為資料實驗各攻擊種類之偵測率比較 
 58 
3.4.5 實驗分析 
茲分析本系統架構以 SVM 置於 NETAD 後方的特色，可避免 NETAD 判斷
網路資料發生的誤報問題，我們將 NETAD 過濾後的資料，萃取出正常與異常的
特徵並混合，提供 SVM 進行訓練與測試，能使其發揮多分類的能力，進一步偵
測到被 NETAD 誤報的異常行為。然而資料本身的散佈也會影響分類的效果，透
過適當地特徵選取的動作，去除影響 SVM 分類的雜訊內容，能更有效提昇異常
偵測系統的偵測率，以驗證雙層式異常偵測系統之優點。 
0
10
20
30
40
50
60
70
80
90
100
0 2 4 6 8 10 12False alarm rate (%)
D
et
ec
tio
n
 
ra
te
 
(%
)
N
S
N + S + F
N + S + F*
圖 3.30 混合後各偵測模組與純資料偵測模組之評估結果 
最後，我們分析純資料以及混合資料之實驗結果，針對本研究所提出的系統
做一個比較，如圖 3.30 所示，其中 N 為混合後之 NETAD 異常偵測系統，S 為混
合後之 SVM 異常偵測模組，N+S+F 表示本系統採用混合資料實驗之結果，而
N+S+F*則是使用 DARPA 1999 純資料之結果，發現本系統不管在混合資料或是
純資料的情況下，都能在誤報率約 8%時達到 90%的偵測效果，證實本系統具有
適用於真實網路環境下的可行性。
 60 
 
4.2 整合式關聯警訊與攻擊預測改進之系統流程 
此架構結合前述第一類利用事先建立警訊的必要及後果關係和第三類的做
法利用警訊的特徵相似值計算。結合兩個方法的目的是希望能結合兩個方法各有
的優點，互補彼此的缺點，以符合現今真實環境所需。針對知識背景內已知的攻
擊行為，透過第一類方法事先建立規則。但在方法中並不實際去建立警訊的必要
及後果條件，而是直接將原本已知有關聯的警訊直接建立成一條條的規則。而未
知的攻擊則是採用第三類的方法，利用警訊的特徵值，計算警訊間彼此的相似
值。而此方法的流程與步驟將以圖 4.2 及文字描述解說如下： 
 62 
在本文方法架構中，當入侵偵測系統產生一個新警訊時，會將此新警訊逐一
與先前較早產生的警訊進行比對的動作。 
步驟 1： 
查看此新警訊是否存在關聯資料庫內的關聯資料表(Correlation Table)中。如
果關聯資料表存在著，就代表是，意味著此警訊為相同的重覆攻擊步驟。由於為
了將來網路攻擊圖方便管理者判讀，所以重覆相同的警訊不會再出現，因此跳至
步驟 9，結束此流程。如果是否，警訊不存在關聯資料表的話則進行下一步驟 2。 
步驟 2： 
每當進行至此步驟，將從警訊資料庫逐一取出較舊之前一警訊。計算新警訊
與舊警訊兩個警訊間的時間差。在這邊為了顧及整個系統的效能，避免計算比對
無效的警訊，我們會定義一個時間視窗(Time Window)計算兩個警訊產生的時間
間隔。如果時間差小於設定的時間視窗則繼續進行下一步驟 3，大於設定的時間
視窗則跳至步驟 8。如果舊警訊皆已比對完或大於設定的時間視窗，結束此流
程，跳至步驟 8。 
步驟 3： 
查看此舊警訊是否存在候選列中。是的話則一樣代表為重覆的攻擊步驟，回
到步驟 2，繼續將此新警訊與此舊警訊之前一警訊比對。否的話則代表未重覆的
警訊故，所以進行下一步驟 4 透過關聯引擎的計算比對此警訊對。 
步驟 4： 
在規則資料庫查看此新警訊與舊警訊是否為事先定義的攻擊行為。是的話則
有著規則定義，進行步驟 5.1，否的話進行步驟 5.2。 
步驟 5.1： 
利用資料庫的規則比對兩警訊之特定特徵，參照 4.3 節。 
步驟 5.2： 
計算兩警訊之特徵相似值，參照 4.4 節。 
步驟 6： 
初步判斷兩警訊是否有關聯。如果是步驟 5.1 利用資料庫規則進行比對的話
則需完全符合規則，如果是步驟 5.2 計算警訊關聯值，其值結果算出來必需大於
設定的警訊關聯門檻值(Correlation Threshold)則先將警訊儲存至警訊候選列。判
斷結果是是的話進行步驟 7，否的話回到步驟 2，繼續與前一警訊比對。 
步驟 7： 
先將此警訊存至候選列，跳回步驟 2。 
步驟 8: 
從警訊候選列中針對計算特徵相似值的警訊，挑出警訊間網路位址相似性最
高的警訊及規則比對結果符合警訊規則庫定義之警訊對視為關聯。並將此資訊更
新至關聯資料表與關聯立方體(Correlation Cube)。在警訊候選列中所儲存的警訊
相似值均大於事先設定的關聯門檻值，但因在同一網段下的網路位址相似性都很
高。如果將警訊候選列中所有警訊皆視為關聯，會導致過多錯誤關聯的情況發
 64 
為 1，其餘為 0。其範例如下： 
 
 
 
 
目的地埠與來源端埠則是完全相同給 1，否則為 0。時間的計算則是設定一
個時間視窗，兩個警訊時間差小於時間視窗的警訊才比對。並計算兩個警訊的時
間差與時間視窗之比值，做為此特徵之相似值。時間視窗大小的選定關係著警訊
關聯圖的完整與否，如果攻擊者兩個步驟間格時間大於設定時間視窗則會使得原
本有關聯的警訊失去關聯。所以時間視窗盡可能越大越好，但如果時間視窗設得
太大，也會造成系統效能低落。在本文的實驗中則是將時間視窗設定為四小時。 
表 4.1 各特徵値之權重表 
 
 
 
 
 
 
 
 
IP similarity = max {A,B,C}*0.4 
關聯權重值(Correlation Weight)則是代表兩個警訊間彼此的關聯性，其值是
利用紀錄在關聯立方體內的累計關聯值(Accumulate Correlation Value)所計算
的。此方法則是延伸 Zhu 及  Ghorbani 學者 [50]提出警訊關聯矩陣 (Alert 
Correlation Matrix)的做法。建立三維的關聯立方體，在原本的二維空間中儲存警
訊間的特徵值，但並非所有計算完的警訊特徵值都會儲存，只存有意義的警訊特
徵值。警訊關聯值的計算依各特徵之權重來看，IP 及 Correlation Weight 所佔比
例較重，也左右著關聯值高低的結果。所以再進一步將關聯值計算分析成： 
1.有關聯(>Correlation Threshold) 
a. IP 相似值高，Correlation Weight 高(有意義) 
2.無關聯(<Correlation Threshold) 
b. IP 相似值高，Correlation Weight 低(有意義，>Meaningful Threshold) 
c. IP 相似值低，Correlation Weight 高(無意義，<Meaningful Threshold) 
d. IP 相似值低，Correlation Weight 低(無意義，<Meaningful Threshold) 
有意義的關聯警訊情況初期會因 Correlation Weight 較低而無關聯性，如情
況 b。但會隨著發生多次 IP 相似值高 Correlation Weight 低的情況發生。Correlation 
 S_IP D_ IP S_ Port D_Port Time Correlation_ 
Weight 
S_IP A 0 0 0 0 0 
D_IP B C 0 0 0 0 
S_Port 0 0 0.1 0 0 0 
D_Port 0 0 0 0.1 0 0 
Time 0 0 0 0 0.05 0 
Correlation 
Weight 
0 0 0 0 0 0.35 
( 1, 2) /32
ip1=192.168.0.001=110000001010100000000000
ip2=192.168.0.201=110000001010100000000000
24, ( 1, 2) 24/32 0.75
sim ip ip n
n sim ip ip
=
= = =
00000001
11001001
 66 
在 Zhu[50]學者的文章中只採用左邊二唯空間的資訊，只考慮現在的單一警訊，
而去預測接下來可能發生的警訊是 4、5 皆有可能發生。但本文除了參考原本的
二維空間外，更參考第三維度的空間幫助我們能準確預測最有可能發生的警訊。
警訊 3 之前一警訊為警訊 1，在第三維空間經由查表(3,4)、(3,5)可知之前關聯的
資訊，因此我們預測所產生警訊 5 的機會較警訊 4 的機會大。 
 
 
圖 4.4 當警訊 3 產生時，預測接來可能的攻擊行為 
5
HHLLL3
1
531 2 4
2
4
15
04
03
52
01
1 3 ?− > − >
(3, 4)
05
14
03
02
51
(3, 5)
The first two dimensions of Cube The third dimension of Cube
times timesSID SID
 
圖 4.5 透過第三維空間預測接下來最有可能的攻擊行為 
4.6 實驗與分析 
實驗的資料集是採用 DARPA 2000 LLDOS inside1.0 與 2.0.2 的資料集，並利
用入侵偵測系統 RealSecure6.0 所產生的警訊檔為依據。規則資料庫建立的部份
是利用 Ning 等學者[45]的實驗結果為依據，將不論是正確關聯或錯誤關聯之警
訊建立規則，並將其中部份正確規則刪除，使得原本攻擊圖一分為二，測試實驗
完成時是否能將缺少規則警訊關聯找出，產生一個完整的 DDoS 攻擊圖。下列表
4.2 即為實驗 DARPA 2000 LLDOS inside 1.0 資料集所建立的規則資料。
1 
4 
3 
5 
? 
? 
 68 
 
圖 4.7 DARPA 2000 LLDOS inside 1.0 第二部份實驗結果之警訊關聯圖 
圖 4.8 為 DARPA 2000 LLDOS inside 2.0.2 資料集的第一部份實驗，事先將
Ning 的實驗結果建立規則資料庫進行實驗。實驗結果雖不如 Ning[39]學者的實
驗結果能將攻擊情境合而為一，其原因在於雖然一樣是先將警訊資料搜集後再進
行分析，但本文實驗採取的是 on-line 即時的做法，將警訊流水號由小至大，逐
一比對流水號較小之警訊，所以才使得攻擊警訊圖一分為二。並非先將警訊完整
搜集後才關聯警訊。 
 
圖 4.8 DARPA 2000 LLDOS inside 2.0.2 第一部份實驗結果之警訊關聯圖 
除了採用 DARPA 2000 此資料集之外，還建立一個封閉的測試平台，並在此
平台下模擬一個駭客針對網頁伺服器進行攻擊，一開始駭客經由掃瞄探測網頁伺
服器，以及找出伺服器所存在的弱點，並選定其中一個弱點進行攻擊，隨後並置
換網頁讓無知的瀏覽者下載惡意程式執行，試圖癱瘓網頁伺服器主機的網路頻
寬。在這過程中我們利用入侵偵測系統 Snort 搜集了過程中所有的警訊，並將其
建立警訊關聯圖，如圖 4.9。 
 70 
第五章 結論 
本計劃在兩年內自我評估的結果執行結果良好，原計畫書中的目標如： 
1. 真實網路分析 
2. 規則回饋 
3. 攻擊預測 
皆已完成。計畫中原擬採用陷阱誘捕系統來蒐集資料。而綜合考慮結果，我
們的部分實驗架構於 Testbed@TWISC（國立成功大學 TWISC@NCYU 的測試主
機）來實驗，不但能快速架構環境而夠得到相關結果，也可以訓練學生使用
Testbed ，得到相關的經驗。 
 
本研究的成果亦獲得肯定，發表於國內重要的會議上，以下列出相關論文。 
 
1. 王智弘、郭力瑋。一個基於混合式網路流量分析之新的異常偵測模型。九十
四年全國計算機會議，NCS, 2005，崑山科技大學，2005 年 12 月。 
2. 王智弘、楊博仁。基於支持向量機之雙層式網路流量異常偵測系統。九十七
年資訊安全會議，CISC, 2008，國立東華大學，2008 年，5 月。 
3. 王智弘、游柏銓。整合式具攻擊預測改善之關聯警訊架構研究。九十七年民
生電子研討會，WCE, 2008，景文科技大學，2008 年 12 月。 
 
本研究尚有可繼續延伸的主題，非常值得繼續投入與實驗。目前我們正發展
無線隨意網路 (Wireless Ad Hoc Network) 的入侵偵測問題，未來應可將本研究
成果繼續往無線網路方面來發展。 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 72 
[18] M. Gangadharan and K. Hwang, “Intranet Security with Micro-Firewalls and 
Mobile Agents for Proactive Intrusion Response,” IEEE International Conference 
on Computer Networks and Mobile Computing, October 2001. 
[19] F. GAO, J. Sun and Z. Wei, “The Prediction Role of Hidden Markov Model in 
Intrusion Detection,” CCECE 2003. 
[20] A. Hussian, J. Hiedmann, C. Papadopoulos, “A Framework of Classifying Denial 
of Service Attacks,” Proceedings of the SIGCOMM, Karlsrune, Germany, 2003. 
[21] K. Hwang, Y. Chen and H. Liu, “Defending Distributed Systems Against 
Malicious Intrusions and Network Anomalies,” Proceedings of the 19th IEEE 
Parallel and Distributed Processing Symposium, 2005. 
[22] M. A. Hearst, S. T. Dumais, E. Osman, J. Platt and B. Scholkopf, “Support 
Vector Machines,” IEEE Intelligent Systems, Vol. 13, No. 4, pp. 18-28, 1998. 
[23] Y. J. Lee and O. L. Mangasarian, “SSVM: Smooth Support Vector Machine for 
 Classification,” Computational Optimization and Application, Vol.20, No. 1, pp. 
5-22, October, 2001. 
[24] S. Lee, B. Chung, H. Kim, Y. Lee, “Real-time analysis of intrusion detection 
alerts via correlation,” Journal of Computers & Security, Vol. 25, pp. 169-183, 
May 2006. 
[25] W. Lee and S. Stolfo, “A Framework for Constructing Features and Models for 
Intrusion Detection Systems,” ACM Transactions on Information and System 
Security (TISSec), 2000. 
[26] T.-R. Li and W.-M. Pan, “Intrusion Detection System Based on New Association 
Rule Mining Model,” Granular Computing, 2005 IEEE International Conference 
on Volume 2, 25-27, pp. 512 – 515, 2005. 
[27] Wang Li, Li Zhi-tang, Li Dong, Lei Jie, “Attack scenario construction with a new 
sequential mining technique”, 8th ACIS International Conference on Software 
Engineering, Artificial Intelligence, Networking, and Parallel/Distributed 
Computing, pp. 872-877, July 2007. 
[28] R. Lippmann, J. W. Haines, D. J. Fried, J. Korba and K. Das, “The 1999 DARPA 
Off-Line Intrusion Detection Evaluation,” Draft of paper submitted to Computer 
 Networks, In Press, 2000. 
[29] M. V. Mahoney, “Network Traffic Anomaly Detection Based on Packet Bytes,” 
Proceedings of the 18th ACM Symposium on Applied Computing, Melbourne, FL, 
USA, pp. 346-350, 2003. 
[30] M. V. Mahoney and P.K. Chan, “An Analysis of the 1999 DARPA/Lincoln 
Laboratory Evaluation Data for Network Anomaly Detection,” Computer Science 
Department, Florida Institute of Technology Technical Report CD-2003-02, 2003. 
[31] M. V. Mahoney and P.K. Chan, “Learning Nonstationary Models of Normal 
Network Traffic for Detecting Novel Attacks,” Proceedings of the 8th 
International Conference on Knowledge Discovery and Data Mining, pp. 376-385, 
2002. 
[32] M. V. Mahoney and P. K. Chan, “Learning Rules for Anomaly Detection of 
Hostile Network Traffic,” Proceedings of the 3rd IEEE International Conference 
on Data Mining, 2003. 
[33] M. V. Mahoney and P. K. Chan, “PHAD: Packet Header Anomaly Detection for 
Identifying Hostile Network Traffic,” Florida Institute of Technology Technical 
Report CS-2001-4, 2004. 
[34] H. Mannila and H. Toivonen, “Discovering Generalized Episodes Using Minimal 
Occurrences,” Proceedings of the Second Int'l Conference on Knowledge 
Discovery and Data Mining (KDD'96), pp. 146 – 151, 1996. 
 74 
[53] 平松 尚利, “未知の攻撃を検知するための通常ネットワークトラヒックの
非静的学習モデル,” B4 根元研究室, 2003. 
[54] 研川 幸雄, アントニ ローレンス, ラシキア ジョージ, “単純ベイズを
用いたホストベース異常検出セキュリティシステム,” 第 14 回データ工学
ワークショッププログラム (DEWS2003) 5-P-02, 2003. 
[55] DARPA 1999 dataset. Available: http://www.ll.mit.edu/IST/ideval/index.html. 
[56] KDDCUP' 99 dataset. Available:  
 http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html. 
[57] Matt Mahoney, Available: http://www.cs.fit.edu/~mmahoney/. 
[58] SPADE, Silicon Defense. Available: 
http://www.silicondefense.com/software/spice/. 
[59] Tcpdump tool. Available: http://www.tcpdump.org/. 
[60] Testbed@TWISC - Network Emulation Testbed Home. Available:  
 http://testbed.ncku.edu.tw/. 
[61] W. W. Cohen, Available: http://www.cs.cmu.edu/~wcohen/ 
 76 
在本程式中，有下列幾項功能：  
(1) 網路資料合併：此為混合資料實驗所必須用到之功能，
在 Merge Process 中，透過選擇 Select  File 來選擇兩個需要合併
的 TCPDump 格式檔案，然後選擇 Merge 來進行網路資料合併的
工作，因為封包時間的不連續，因此每個混合區段間將會有「縫
隙」（ gap）產生，所有的區段將在混合工作完成後顯示在 Info.
欄位，並會產生 tm.out 的檔案，記錄著混合的網路資料，如圖
A.2。  
 
圖 A.2 網路資料混合之輸出結果 
(2) 過濾器：在 Filter & Combination 區塊中，透過 Select File
選擇檔案，其中一個檔案為起始檔案另一個為最末檔案，因此檔
案名稱必須是為數字結尾，系統將自動判斷所包含的檔案數量並
進行過濾的工作，過濾前後的封包數將被記錄在 Info.欄位中，
如圖 A.3，並且會將過濾後的資料記錄在 t f .out 檔案中。
 
圖 A.3 網路資料過濾結果  
(3) 異常偵測器：在 Anomaly Detection 區域中，一樣透過
Select  File 選擇 t raining 與 testing 的檔案，選擇 NETAD 則會進
行異常偵測，將會在 Info.欄位顯示偵測出的異常量，其輸出結
果如圖 A.4，所有的異常紀錄將會記錄在 netad.sim 檔案中。  
 
圖 A.4 異常偵測結果  
(4) 評估程式：透過選擇 Anomaly Detection 區域的
Evaluation 按鈕，會開啟如圖 A.5 的視窗，我們可以將 *.sim 類
型的異常記錄檔案作為 input，在 Maximum False Alarm 設定最
大的錯報容忍個數，並選擇 Evaluate 後即可進行異常偵測性評
估，結果會顯示在下方的欄位中，每一行為依照攻擊種類分類的
偵測結果，每一列為 DARPA 1999 中各種不同資料集的偵測結
果，由於我們是以 MIT LL DARPA 1999 的第四與第五洲的檔案
作為評估目標，因此在我們的實驗中將以第一列的評估結果為
 78 
 
圖 A.6 檔案檢視器  
 80 
 
圖 B.2 Event_Table 儲存入侵偵測系統所產生的警訊 
 
圖 B.3 Pre_Table 儲存已知的警訊規則 
 
圖 B.4 Correlated_table 儲存 Event_Table 中有關聯的警訊 
 
圖 B.5 Correlated_Table 中的結果以視覺化輸出 
除了可見的操作介面外，尚需一套資料庫系統負責儲存所有的資料表。資料庫我
們是採用微軟公司所推出的 SQL Server，如圖 B.6。上、中、下三個資料表分別
對應到操作介面的 Event_Table、Pre_Table、Correlated_Table。 
行政院國家科學委員會補助學者出席國際學術會議報告 
（請於出席會議後填寫）                                      填表日期：97 年 7 月 18 日 
報告人姓名 王智弘 服務單位 國立嘉義大學 
資訊工程系 
計畫名稱 NSC95-2221-E-415-010-MY2（第二年） 
具規則回饋及攻擊預測模式並適用於網路真實資料分析之入侵
偵測系統 
會議時間  2008/7/10 – 11 地    點 韓國首爾 
中文：第三屆聯合資訊安全研討會 
會議名稱 
英文：The 3rd Joint Workshop on Information Security (JWIS2008) 
中文：一個可驗證加密盲簽章機制以及其在具公平交換電子現
金系統之應用 發表論文題目 
英文：A Verifiable Encrypted Blind Signature Scheme and Its 
Application in E-cash System with Fair Exchange 
 
一、參加會議經過 
  
JWIS 2008 會議是由台灣、韓國、日本在資訊安全研究交流的一個平台，本次
第三屆會議由韓國舉辦。會議時程總共兩天，包含 6 場 invited talk 以及 12 場 
session 。收錄論文有 46 篇。會議的主題包含網路安全、應用安全、 RFID/Sensor 
network 安全、安全管理、密碼技術、應用密碼技術以及系統安全等，議題包羅萬象，
涵蓋各類的安全議題。 
 
本次會議有 6 場 invited talk，演講的內容十分精彩。第一場演講由 Prof. 
Kadobayashi 演講關於 Communications Traceability 最近的發展。第二場演講由中研
院資科所李德財所長演講關於 iCAST 的簡介與展示。第三場演講是由 Prof. Xiao 演
講關於 Internet Worm Threat 及 Defending Mechanism，第四場演講是由 Prof. Song 
演講關於  WiBro Security。第五場演講由成功大學賴溪松教授演講關於  Web 
Application Security 在台灣的趨勢。而最後一場則是由 Prof. Arimura 演講在日本的 
Cyber Clean Center。總括來說，演講的內容豐富，台上台下的互動也非常好，許多問
題的發問與釐清讓演講的氣氛更為熱絡。因此，本次會議在 invited talk 的部分為我
個人收穫最多的部分。 
 
會議在第一天 (7/10) 晚上有一場晚宴。台日韓研究資訊安全的學者專家齊聚，
互動交流熱絡，彼此認識，分享研究經驗與學術交流。此次台灣學者參與佔全部的 
1/3。日本學者較少，韓國學者最多，因此在晚宴中也認識許多來自韓日等國的朋友。 
 
本次會議中，台灣爭取明年 JWIS 2009 的主辦，最後決定在南台灣的中山大學
舉辦。在最後會議結束前由高雄師範大學楊中皇教授來介紹明年會議的地點，並邀請
與會的專家學者一同參與。 
 二、與會心得 
 
本次會議個人兩天全程參加，除了與參加會議之專家學者充分溝通交流之外，也
聆聽許多場重要的演講及論文發表。此外，本次會議本人亦擔任一場論文發表之議程
主席（session chair）: Session 8: Cryptography。在這個場次中，發表的論文與密碼技
術相關，論文內容均深入且有應用價值。第一篇論文由 Prof. Kuwakado 所發表：
Analysis of Password-Verification Functions，內容談及過去使用 hash based 的通行碼
技術會發生雜湊值相等的情形，因此本篇論文提出新的 Random Injective Function 來
解決這問題。第二篇論文由中山大學官大智教授發表：Efficient Algorithms for 
Computing Modular Exponentiation  mod xa n。此論文提出 Block Method 的演算法來
提升效率與降低儲存量，有十分不錯的貢獻。第三篇論文由 Ozasa 等學者提出 Fast 
Multiplication Algorithm over GF(2
m
) Using Look-UP Two Dimension Table。此論文提出
一個提升在 GF(2m) 下乘法演算法的方式，雖然在儲存量上表現稍差，但卻能有效加
快乘法的速度。本場次的最後一篇論文由  Li 及  Prof. Kim 所發表之  Fuzzy 
Identity-Based Key-Insulated Cryptosystem。論文演說精彩，也提出嚴謹的安全分析與
證明。整個場次歷經 80 分鐘的討論，與會人士均獲得相當多的收穫。 
 
此外，本人在會議中亦發表一篇論文：A Verifiable Encrypted Blind Signature 
Scheme and Its Application in E-cash System with Fair Exchange。場次在第二天 Session 
10: Applied Cryptography。該場次的論文均與密碼學應用相關，包括 Proxy Signature、
Blind Signature 及 E-cash 等。而本人所發表的論文主要描述在電子現金與公平交換
結合的一種線上付款機制，兼具匿名性與公平性。論文發表後也與其他的專家學者交
換論文相關意見，對於未來這方面的研究有相當多的助益。 
 
由於本次會議的主題包含了網路安全、系統安全、 RFID 及密碼學與應用等，
因此在資訊安全的領域上可說十分的多元化。我此行也不僅認識在密碼技術上的專家
學者，也對於網路安全、系統安全的學者、企業內的專家們有所接觸，因此能夠擴展
國際間的友誼。而此次會議另一項重要的成果是台灣爭取到明年 2009 JWIS 的主辦
權，此次爭取由中華名國資訊安全學會主導，理事長吳宗成教授以及副理事長雷欽隆
教授均與會，展現舉辦下年度會議的極大誠意。相信這樣的努力，對於未來台灣在資
訊安全研究領域上的國際關係、能見度以及合作交流上均有很大的幫助。此次台灣方
面有兩位學者：李德財所長及賴溪松教授獲邀專題演講，他們透過演講形式將台灣最
近在資安領域上的研究向其他各國來展示與說明，的確對我們國家的資通安全發展一
個非常好的宣傳，這點是我們這次台灣的學者與會的一項很大的進展。 
 
會議兩天的行程緊湊，但主辦單位做了很好的時間控管。在服務上也做得很好。
有飯店代訂，以及地鐵路線圖說明等，因此若與會人士非常方面就能找到相關的位
置。而會議地點設備良好，晚宴亦有十分融洽的氣氛，除對全體會議舉辦的人員介紹
之外，亦頒發最佳論文獎，以鼓勵有更多好的論文能夠在會議上發表，提升整體的會
議論文品質。 
 
 
  
 
 
附件： 
 
附件一  會議議程表 
附件二  發表之論文 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Chun-Li Lin, Li-Chi Chang  Assessment" 
Kunwoo Kim, Woogyu Kim  
"An Energy-Efficient Secure Routing for Wireless Sensor 
Networks" 
Hung-Min Sun, Chih-Chien Chu, King-Hang Wang  
"An Integrated Security Incident Response Framework for a 
Hierarchical Security Infrastructure" 
Kimoon Jeong, Junhyung Park, Minsoo Kim, Bongnam Noh  
"On the Security of Vyas et al.'s RFID Authentication Protocol" 
Hung-Min Sun, Bing-Zhe He, King-Hang Wang  
"CORAS for Research of Considering the Integration Risk 
Management with ISO/IEC 27005" 
Ya-Ping Fu, Kwo-Jean Farn, Chung-Huang Yang  
12:00  
- 
13:10 
Lunch 
13:10  
- 
14:30 
Invited Talks 1, 2  
(1) "Recent Developments in Communications Traceability", Youki Kadobayashi 
(2) "iCAST, International Collaboration for Advancing Security Technology", Der-Tsai Lee 
14:30  
- 
14:50 
Coffee Break 
Session 5 etwork Security 2 
(Chair: Jungduk Kim, Chung-Ang University, Korea) 
Session 6 Application Security 2 
(Chair: Chin-Laung Lei, National Taiwan University, Taiwan) 
"Survey of Traceback techniques and Requirements on 
Traceback in the NGN Environment" 
Jung-Hwa Han, Rack-Hyun Kim, Heung-Youl Youm, Jae-Cheol 
Ryou  
"SNR Scalable Access Control for H.264/AVC Coded Video 
using Data Partition" 
Deepak Kafle, Kyung Hyune Rhee  
"Cryptanalysis on some Deniable Authentication Protocols 
based on ElGamal Cryptography" 
Meng-Hui Lim,Sanggon Lee, Sangjae Moon  
"Trackback Spam Distinction Using Similarity of Contents" 
Kohta Fujimura, Yoshiaki Hori, Kouichi Sakurai  
"Research on a Taxonomy of Web Attacks" 
Jung-Ying Lai, Jain-Shing Wu, Shih-Jen Chen, Chia-Huan Wu, 
Chung-Huang Yang  
"Watermarking for Enhancing Security in Biometric Data 
Exchange" 
S. Azhaguvel  
14:50  
- 
16:10 
"Improved Strong ID-Based Key Distribution" 
Wen-Chung Kuo, Bae-Ling Chen, Lih-Chyau Wuu  
 
16:10  
- 
Coffee Break 
10:20  
- 
10:40 
Coffee Break 
Session 9 RFID/Sensor etwork Security 2 
(Chair: Dah Jyh Guan, National Sun Yat-sen University, Taiwan) 
Session 10 Applied Cryptography 
(Chair: Hidenori Kuwakado, Kobe University, Japan) 
"Analysis of Location-Based Compromise-Tolerant Security 
Mechanisms for Wireless Sensor Networks" 
Han-Yu Lin, Ting-Yu Huang, Tzong-Sun Wu, Tzong-Chen Wu  
"A New Provably Secure Proxy Signature Scheme Based on 
Factoring" 
Bing-Chang Chen, Hung-Min Sun  
"Lightweight Broadcast Authentication for Multiple Senders in 
Sensor Networks" 
Yu-Shian Chen, I-Lun Lin, Chin-Laung Lei,Yen-Hua Liao  
"A practical anonymous proxy signature scheme with trusted 
alias issuing authority", 
Shin-Jia Hwang, Pi-Hung Hsu  
"Refinement of the Blaβ-Zitterbart Key Establishment Scheme for 
Secure Aggregating Sensor Networks" 
Yukie Unno, Masahiro Mambo, Eiji Okamoto  
"A Verifiable Encrypted Blind Signature Scheme and Its 
Application in E-cash System with Fair Exchange" 
Chih-Hung Wang, Yan-Sheng Kuo  
10:40  
- 
12:00 
"RFID Authentication Protocol in Supply Chains" 
Chun-I Fan, Shi-Yuan Huang  
"Efficient Date-Attachment Scheme for Secure Electronic 
Cash Payment System" 
Liang-Peng Chang, Tzong-Chen Wu, Chien-Lung Hsu  
12:00  
- 
13:10 
Lunch 
Session 11 etwork Security 4 
(Chair:Masahiro Mambo, University of Tsukuba, Japan) 
Session 12 System Security 
(Chair: Gwangsoo Rhee, Sookmyung Women's University, 
Korea) 
"Synchronized P2P query traffic generation for tracing information 
leaks on virtualized L2 datalink" 
Ruo Ando, Youki Kadobayashi, Yoichi Shinoda  
"EBSM: E-BLP Based Security Module for Trusted 
Embedded Linux Systems" 
JungMin Kang, DoHoon Lee, EungKi Park  
"Development and Operation of Testbed@TWISC" 
Chi-Sung Laih, Jung-Shian Li, Mao-Jie Lin, ShRiau-Han Chang, 
Li-Da Chen, Shih-Hsien Tseng, Michael Chang  
"Malware Sandbox Analysis for Extracting Exploit Codes" 
Katsunari Yoshioka, Daisuke Inoue, Masashi Eto, Yuji 
Hoshizawa, Hiroki Nogawa, Koji Nakao  
13:10  
- 
14:10 
"Undeniable Signature with a Reusable Subliminal Channel" 
Narn-Yih Lee, Pei-Hsiu Ho, Dai-Rui Lin  
"New Authenticated Encryption Scheme for Multilevel 
Security" 
Liang-Peng Chang, Tzong-Chen Wu  
14:10  Coffee Break 
A Verifiable Encrypted Blind Signature Scheme and Its 
Application in E-cash System with Fair Exchange 
Chih-Hung Wang and Yan-Sheng Kuo 
 
Department of Computer Science and Information Engineering, 
National Chiayi University, Chiayi, Taiwan, R.O.C. 
wangch@mail.ncyu.edu.tw        yskuo@mail.csie.ncyu.edu.tw 
Abstract. In e-commerce environment, the e-cash system is an important 
payment tool with privacy protection. Although e-cash system can achieve 
many security requirements, e.g. unreusability, untraceability, unforgeability, 
unstealability etc, it is impractical if the e-cash system lacks of fairness property. 
The customer may worry that he cannot obtain the desired goods after he sends 
out the money, and the merchant may also need to watch out for the customer’s 
cheating. This paper proposes a new building block, namely verifiable 
encrypted blind signature, for the e-cash system to seamlessly include the fair 
exchange process during the payment stage. The demonstration of a novel type 
of e-cash system which has privacy as well as fairness properties is also 
presented. 
Keywords: Blind Signature, Verifiable Encrypted Blind Signature, E-cash 
System, Fair Exchange 
1   Introduction 
The e-cash system, a privacy protected network payment tool, plays an important role 
in the e-commerce/e-business environment. Most of the previous e-cash systems 
provided the security requirements such as unreusability, untraceability, 
unforgeability, unstealability, etc.; however, without fairness property, the e-cash 
payment performed in Internet will suffer some serious problems. For example, the 
customer may worry that he cannot receive the desired goods after sending his e-cash 
transcripts; similarly, if the merchant sends out the goods first, it also may worry that 
the customer is unwilling to pay the bill. Hence, the fair exchange, which is defined 
that none of the two exchanged parties can gain an advantage over the other, can be 
used in the e-cash scheme to solve the above kind of problem. 
The previous works of fair exchange usually involves a trusted third party (TTP) to 
intervene in a dispute. A straight approach is using an online TTP [7, 8, 12]. In each 
transaction, the online TTP takes part in the exchange process so that it becomes a 
communication and computation bottleneck. For efficiency, the offline TTP, which 
mediate in the dispute between the two parties only when a malicious or abnormal 
situation occurs, was proposed in the recent literature [1, 2, 4, 6, 9, 13]. There are 
many variant fair exchange protocols with special features. Franklin and Reiter [8] 
附件二  發表之論文 
 
2 A New Blind Signature Scheme 
There are two parties in our blind signature scheme: the requester and the signer. In 
the blind signature scheme, the requester randomly selects a blind factor and puts it 
into the original message, and then sends the mixed message to the signer. The signer 
signs the mixed message and sends the result back to the requester. After the requester 
received the signed message from the signer, he takes off the blind factor from the 
signed message. Hence, the requester can obtain a signature but the signer learns 
nothing about the message he signed and the resulting signature. In this section, we 
present a new blind signature scheme in detail. The scheme consists of four 
procedures: Setup, Extraction, BSGen and Verification. 
Setup. The trusted key generation center TKGC chooses three groups G1, G2, and Ge 
with the same prime order p, two generators g1 of G1 and g2 of G2 , a bilinear pairing 
1 2: ee G G G× → , a computable isomorphism 2 1: G Gψ →  with 2 1( )g gψ = , and a 
cryptographic one-way hash functions 1:{0,1}H G∗ → . Then TKGC publishes the 
parameters params={G1, G2, Ge, e, ψ , p, g1, g2, H}. 
Extraction. The entity i chooses a random number i px Z∈  as his private key, and 
computes 2 2i
x
iv g G= ∈  as his public key. 
BSGen. Given a message m, the requester request the signer to blindly sign the 
message m. Assume that the key pair of the signer is (xs,vs). This procedure is show as 
follows. 
(1) (Blinding) The requester randomly selects pr Z ∗∈ , sets 1( )h H m G= ∈ , and 
computes 1 1
rc g h G= ⋅ ∈ . Then the requester sends c to the signer. 
(2) (Signing) The signer computes sxcα =  and sends back α  to the requester. 
(3) (Unblinding) The requester computes 1( )r
s
vσ α ψ −= ⋅ . 
 
Finally, the blind signature of the message m is σ . The blind signature generation 
is shown in Fig. 1. 
 
3.1 Aggregate blind signature 
Aggregate blind signature creation. There are n signers 1 2{ , ,..., }nu u u  with the 
private/public key pairs 2( , )s ixsi six v g= , and n distinct original messages 
1 2{ , ,..., }nm m m . Assuming that the requester already has the blind signature iσ  
signed by iu , the aggregate blind signature is represented as 1
n
ii
σ σ
=
= ∏ .  
Aggregate blind signature verification. Anyone who receives the aggregate blind 
signature can compute 
  
( )i ih H m= , for i=1,2,…,n, and accept the signature if and 
only if 2 1( , ) ( , )
n
i sii
e g e h vσ
=
= ∏ . 
3.2 Verifiable encrypted blind signature 
There are three parties in our verifiable encrypted blind signature scheme: the 
requester, the receiver and the adjudicator. The key pair of the adjudicator is (xadj,vadj). 
Verifiable encrypted blind signature creation. Assuming that the requester has a 
blind signature σ  of message m signed by the signer, the requester performs the 
following. 
(1) Choose a random number pu Z ∗∈  
(2) Compute 2 1( )ug Gµ ψ= ∈  
(3) Compute 1( )uadj adjv Gσ ψ= ∈  
(4) Set 1adj Gω σσ= ∈ . 
The verifiable encrypted blind signature of message m is ( , )ω µ . 
Verifiable encrypted blind signature confirmation. The receiver performs the 
following to confirm the verifiable encrypted blind signature.  
(1) Compute ( )h H m= . 
(2) Accept the signature if and only if 2( , ) ( , ) ( , )s adje g e h v e vω µ= ⋅ . 
Now we show the correctness of the protocol. 
2 2 2 2 2
2 2 2
( , ) ( , ) ( , ) ( , ) ( ( ) , )
             ( , ) ( ( ) , ) ( , ) ( , )
s
adjs
x u
t adj
xx u
s adj
e g e g e g e h g e v g
e h g e g g e h v e v
ω σ σ ψ
ψ µ
= ⋅ = ⋅
= ⋅ = ⋅
 
 Notably, if the signer of the blind signature is also the adjudicator, the following 
equation of blind signature confirmation would hold true (see the e-cash scheme 
described in Section 4; the bank is the signer and also plays the role of adjudicator). 
       2( , ) ( , ) ( , ) ( , ) ( , ) ( , )s adj adj adj adje g e h v e v e h v e v e h vω µ µ µ= ⋅ = ⋅ = ⋅  
 Fig. 2. The Registration Phase of E-Cash System 
 
Withdrawal. In this phase, the bank blindly signs the customer’s coin. The proposed 
new blind signature scheme is utilized here. 
(1) The customer generates a coin c, randomly selects pu Z ∗∈ , sets 
1( || )psH c Q Gδ = ∈ , and blinds δ  as 1 1' ug Gδ δ= ⋅ ∈  Then sends 'δ  to the 
bank via a secure channel. 
(2) The bank signs 'δ  as 1' ' bxb Gσ δ= ∈  and sends 'bσ  back to the customer. 
(3) The customer unblinds 'bσ  as 1' ( ) bxub b bvσ σ ψ δ−= ⋅ = . 
 
The customer then obtains a signature bσ  of his coin c signed by the bank, but the 
bank cannot link the resulting signature bσ  to the message he signed ( 'δ ). The 
withdrawal phase is shown in Fig. 3. 
 
Customer Trustee 
2
2
 
 
( || )
 
( , ) ( ( ), )
ps
u
ps p
x
ps
x
u u ps
t ps t
select x Z
compute Q g
H id Q
verify
e g e H Q v
σ
σ
∗∈
=
=
=
 
( , , )
u u psid Qσ  
2
 
( , ) ( ( || ), )
 ,
( ) t
u u ps u
x
t ps
verify
e g e H id Q v
If correct
H Q
σ
σ
=
=
 
tσ  
There may be happen two illegal situations in this phase. The first case is that the 
merchant does not receive bσ  from the customer in step (4) or the bσ  is invalid in 
step (5). The second case is that the merchant brings a malicious action. After 
receiving the customer’s ( , , , , ( ), )ps t b cc Q Eµ σ σ σ  in step (2), the merchant asks the 
bank to release the bσ  without sending the goods to the customer. The following 
phase could solve these disputes. 
Payment (dispute case). This phase is carried out as follows. Note that here the bank 
plays the role of the adjudicator. 
(1) The merchant sends ( , , , , ( ), , , )ps t b cc Q E msg goodsµ σ σ σ  to the bank. 
(2) The bank verifies the validity of , ( )t bEσ σ  and cσ  by checking whether 
2( , ) ( ( ), )t ps te g e H Q vσ = , 2( ( ), ) ( ( || ) , )b ps be E g e H c Q vσ µ= ⋅  and 
2( , ) ( ( || || || ), )c m ps pse g e H c id msg Q Qσ =  hold. If , ( )t bEσ σ  and cσ  are all 
correct, the bank computes ( ) / bxb bEσ σ µ= , then sends the goods to the 
customer as well as sends bσ  to the merchant. 
At the end of the protocol, the customer and the merchant both obtain what they 
should get in the transaction. Fig. 5 shows the dispute case of the payment phase. 
 
Fig. 4. The Normal Case of Payment Phase 
Customer Merchant 
2
 
( )
( )
( )
( || || || ) ps
p
v
v
um b
b b um
x
c m ps
select v Z
g
v
E
H c id msg Q
µ ψ
σ ψ
σ σ σ
σ
∗∈
=
=
=
=
 
( , , , , ( ), )ps t b cc Q Eµ σ σ σ  
2
2
2
 
( , ) ( ( ), )
( ( ), ) ( ( || ) , )
( , ) ( ( || || || ), )
t ps t
b ps b
c m ps ps
verify
e g e H Q v
e E g e H c Q v
e g e H c id msg Q Q
σ
σ µ
σ
=
= ⋅
=
 
goods  
2
 
( , ) ( ( || ), )b ps b
verify
e g e H c Q vσ =  
( || || )
m desmsg H id time good=  
bσ  
(1) The bank finds out the transaction records ( , , , , , )ps m t b cc Q id σ σ σ  and 
( , , , , , ')ps m t b cc Q id σ σ σ  of the double spending coin, and sends them to the 
trustee. 
(2) The trustee verifies all signatures, and then retrieves the double spender’s 
,ps uQ id  and uσ  from the database. The trustee then sends , ,ps u uQ id σ  to the 
bank. 
(3) The bank adds the double spender’s identity to the black list. 
5 Performance Analysis 
The computational costs of the proposed blind signature scheme, verifiable encrypted 
blind signature scheme and aggregate blind signature scheme are listed in Table 1 and 
Table 2.  
The notations in Table 1 and Table 2 are described as follows. po denotes the cost 
of executing a pairing operation, iso denotes the cost of executing an isomorphism 
function, hash denotes the cost of executing a hash function, exp(G1) denotes the cost 
of executing an exponentiation in G1, mul(G1) denotes the cost of executing a 
multiplication in G1, and inv( qZ ∗ ) denotes the cost of executing an inversion in G1. 
In Table 1, we particularize the computational costs of the proposed blind signature 
scheme and its variants. We find that the computational cost of the verifiable 
encrypted blind signature scheme is a little more than the original blind signature 
scheme. Only need to pay a little more computations, we can gain better security and 
fairness. 
Table 1. The Computational Cost of our Blind Signature Scheme. 
 Signing Verification 
Blind signature 
1 hash 
1 iso 
3 exp(G1) 
2 mul(G1) 
1 inv(G1) 
1 hash 
2 po 
Verifiable Encrypted 
Blind signature 
1 hash 
2 iso 
5 exp(G1) 
3 mul(G1) 
1 inv(G1) 
1 hash 
1 mul(G1) 
2 po 
Aggregate Blind signature 
(n messages, n signers) 
n hash 
n iso 
3n exp(G1) 
3 n-1 mul(G1) 
n inv(G1) 
n hash 
n-1 mul(Ge) 
n+1 po 
Blindness. In the blinding phase of our blind signature scheme, the requester 
randomly selects pr Z
∗∈  and computes 1 ( )rc g H m= ⋅ , the number r is only known 
by the requester. Even the signer can compute 1 / ( )rg c H m= , he still cannot know r, 
since solving the discrete logarithm problem in G1 is assumed to be infeasible. Hence 
our blind signature has the blindness property. 
Unforgeability. The verification equations of the proposed blind signature are similar 
to those of Boneh et al.’s signature scheme [3]. If an attacker can forge our blind 
signature of a given message m successfully, then the attacker can also forge a valid 
signature of Boneh et al.’s scheme on message m. However, Boneh et al.’s signature 
is proven to be unforgeable under the chosen message attack (see [3]). 
6.2 Aggregate blind signature and verifiable encrypted blind signature 
Similar to the discussion above, the security level of our aggregate blind signature 
scheme is also equivalent to Boneh et al’s aggregate scheme. 
A secure verifiable encrypted blind signature should not only satisfy the security of 
blind signature but also have two more properties: validity and opacity. The two 
security properties were detailed described in Boneh et al.’s scheme. Since the 
formulation of our verifiable encrypted blind signature is similar to Boneh et al.’s 
verifiable encrypted signature, our scheme also has the properties of validity and 
opacity. Hence our verifiable encrypted signature scheme is concluded to be secure. 
6.3 E-cash system with fair exchange 
Double spending. If the customer doubly spends his coin, the bank and trustee can 
cooperate to find out the customer’s identity and the bank adds the customer’s identity 
to the black list. 
Untraceable. The coin in our e-cash system is not traceable. In withdrawal phase, the 
bank blindly signs customer’s coin, he cannot link the resulting signature with the 
message he signed. Hence, the withdrawn coin cannot be traced. 
Unstealable. If a thief stole a customer’s ( , , , )b t psc Qσ σ , he cannot spend the coin. 
Although the thief can compute ,
um
µ σ  and )( bE σ , but he cannot sign a valid cσ  
in the payment phase. This is because he does not know the customer’s secret key 
psx . If the thief replaces psQ  by 'psQ  which is the public key corresponding to his 
private key 'psx , he can sign a valid 'cσ  with his private key 'psx  and then sends  
)',)'(,',',',( cbtps EQc σσσµ to a merchant. However, while the merchant verifies  
)'(, bt E σσ  and 'cσ , he can find that )'( bE σ  is not valid. Since bσ  signed by the 
bank is the signature of || psc Q  instead of  || 'psc Q , )'( bE σ  cannot pass the 
verification equation ),)||((),)'(( 2 bpsb vQcHegEe µσ ⋅= . Hence, even if the coin 
was stolen, the thief cannot spend it. 
