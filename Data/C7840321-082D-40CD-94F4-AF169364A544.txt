2 
行政院國家科學委員會專題研究計畫成果報告 
應用於遠距協同作業之多模態人機智慧型互動關鍵技術研
究－子計畫一：協同作業環境下結合語音與視覺事件偵測
之先進議程紀錄與後製系統(I) 
Audiovisual event detection towards advanced meeting recording and 
post-production system:Application to tele-collaboration 
計畫編號：NSC99-2219-E-155-002 
執行期限：99/08/01~100/07/31 
主持人：洪維廷 元智大學 通訊工程學系 助理教授 
 
一、中文摘要 
 
  在壅塞網路環境下進行遠距協同作業多方
通訊時，會因封包遺失或延遲等網路問題造成
之即時之通訊影音品質不良。然而當多方通訊
結束後，要產生記錄時，即時通訊當時所產生
的影音因品質不佳可能無法使用。因此本計劃
的目標是在一個無法提供高頻寬傳輸且保證
網路品質的網路環境中，針對具有多方通話能
力的遠距協同作業平台，提供高品質的多媒體
影音議程記錄，建立多媒體資料存檔備查系
統，參與人員隨時可以利用索引查詢到所需的
資訊。本計劃第一年的主要目的為建立一個
VOIP 環境下，能在低品質語音訊號(例如雜訊
干擾與封包遺失)運作的強健式語者識別系
統。此語者識別的輸出資訊將用於第二年研究
計畫中，有關後製處理技術研究之語音分段、
語者分段、語音段校準及重組和語者角色估
測。本計畫提出調適型 HCRF-UBM 演算法，
經由三種 HCRF-UBM 調適架構以及兩種
GPD(Generalized Probability Descent)訓練產
生調適型 HCRF 語者模型之實驗驗證，錯誤率
方 面 比 起 調 適 型 HMM(Adapted Hidden 
Markov Model) 、 GMM(Adapted Gaussian 
Mixture Model) 語者模型低。在資源受限之強
健性方面 HCRF 架構比 HMM 及 GMM 較佳。 
 
 關鍵詞：隱藏式條件隨機域、自動語音辨認 
 
  Many interferences (e.g. noise, packet loss 
and packet delay) corrupt the received signals in 
a tele-collaboration over a low-bandwidth 
congested network. Therefore signals used in 
real-time communication are not suitable for 
creation of high-quality audiovisual content. The 
object of our plan is to provide a collaborative 
platform for multi-party tele-education over a 
network communication environment without 
QoS guarantee. That is, we want to create 
high-quality multimedia recording of the 
conversation and save the records in a 
multimedia information retrieval system in 
which participators could retrieve important 
information. The main research topic in the first 
year is to build a robust speaker recognizer 
which can work for low-quality speech signal 
(e.g., speech signals corrupted by noise and 
packet-loss). This report of the first year presents 
the techniques of speaker identification using 
discriminative adapted hidden conditional 
4 
驗結論為測試語料加入靜音段較為符合正常
語音狀態轉移的邏輯，而提出的 HCRF 對
GMM 的錯誤改善率比 HMM 對 GMM 的錯誤
改善率高，在訓練句數為 20 句、10 句、7 句
及 5 句情況下，HCRF 對 GMM 的錯誤改善率
分別為 22.6%、16.9%、45%及 50.2%。 
   類神經方面結合了 GMM 系統與 ANN 系
統 [17]，將訓練後語者 GMM 經過 ANN 提取
語者資訊後進行辨識，語料使用 MATLAB。
GMM/ANN 辨識率為 93.04%高於MLP、GMM
的 69.82%、90.91%。在特徵參數方面提出更
準確執行語者辨別及語者驗證的方法，使用
Mel-frequency cepstrum [18]特徵以及 pitch 資
訊的擷取  [19]，而此 pitch 偵測方式使用
HPS(Harmonic Product Spectrum algorithm) 
[20]，語料使用 English Marathi Hindi 不同語
言系語料，經測試後混合 Mel-frequency 
cepstrum 及 pitch 資訊的辨識率約(81%-87%)
高於只使用 pitch 資訊的(60%-70%)。通常擷
取特徵都使用 MFCC 的方式，往往都忽略了
phase 的資訊，因此提出合併 MFCC 和 phase
方法用於語者辨識 [21]，此實驗使用 NTT 語
料共 35 個語者，HMM 及 GMM 使用 MFCC
合併 phase 方法得到的辨識率為 99.1%、98.5%
高於只使用 MFCC 的 98.5%、97.5%。雖然
MFCC 特徵對於語者辨識的效能很好，但
MFCC 在高頻的部分辨識率較低因此提出了
IMFCC 的特徵 [22]，IMFCC 可彌補 MFCC
在高頻辨識率不足的部分，並且混合 MFCC
以及 IMFCC 兩種特徵參數進行實驗。此實驗
語料以飛行員通訊對話的語音為主，最後綜合
兩種特徵參數的辨識率為 90%高於 MFCC、
IMFCC 的 86.67%、83.33%。在語者辨識抗雜
訊方面提出 MFT(Missing Feature Theory) [23]
濾除一些不關鍵的頻率特徵，而後提出改善後
的 EMFT(Extended Missing Feature theory)、
AMFT(Advanced Missing Feature Theory)以及
F-AMFT(Fast-advanced Missing Feature Theory)
比較 [24]，並且證明 F-AMFT 計算複雜度最
少而且抗雜訊的能力最強。 
本計劃中，我們使用 HCRF 下建構語者模型與
UBM 模型，並使用模型調適的技術，降低所
需的註冊語料。我們提出的系統，經由一連串
實驗驗證，在中文普通話的架構下，HCRF 比
傳統 HMM 與 GMM 模型效能較有優勢。 
   近年來由於網際網路的盛行，使得資訊生
活快速提升，資料、語音和視訊等多媒體資訊
皆可整合並透過  IP 技術於網際網路上傳
輸。其中網際網路協定語音傳輸 （Voice over 
Internet Protocol，VoIP）[25]服務，或簡稱為
網路電話，即是透過 IP 封包傳送語音，如此
一來，電話業務不再為電信公司所壟斷。另外 
VoIP 網路電話也與無線網路技術整合，讓 
VoIP 網路電話也跟無線電話或手機一樣具有
移動能力，讓 VoIP 的前景更為亮眼。 
  雖然透過 Internet 傳送 VoIP 封包進行通
訊可以大幅地降低通話費用，然而因為 
Internet 還有其他各式各樣傳輸資料服務，例
如影片下載、線上遊戲、社群網站服務等，因
此網路壅塞的情況非常地普遍。尤其根據
Cisco 的統計，Internet 流量每年的成長速度將
近 50％，如下圖 2.1 所示[26]，巨大的 IP 封
包流量正吞噬著來不及更新的網路設備與網
路服務。這樣激增的網路流量，造成了封包的
遺失（Packet Loss）、延遲（Delay）與抖動
（Jitter），影響網路電話的服務品質（Quality of 
Service，QoS）。 
   
圖 2.1 全球網路流量預測表[26] 
 
6 
       
     
1
1
, , , , , ,
          =
t
T
t
T
t q
t
f t
f
 

 

    



 
  
 
 
 
 
 
 
q o q o
o
(3.3) 
 
to 為時間 t 的觀測值，q 為現在的狀態， 'q  為
前一個時間的狀態。以下為本計畫使用之四個
HCRF 特徵函數: 
( )
, 1
1
( )
1
( 1)
1
( 2) 2
1
( , , ) ( ) ( ) ,
( , , ) ( )
( , , ) ( )
)  ( , , ( )
T
Tr
q q t t
t
T
Occ
t
t
T
M
t t
t
T
M
ts t
s
s
t
f w q q q q q q
f w q q q
f w q q o q
f w q q o q
 



 




    
  
  
  




q o
q o
q o
q o
(3.4) 
( )Trf 為狀態 'q 轉移到狀態 q  的轉移特徵函
數， ( )Occf 為該狀態出現時的特徵函  
1M
f 、
 2M
f 與觀測序列有關的第一動差及第二動差
特徵函數。 
  HCRF初始語者模型可由HMM語者模型參
數轉換得到，以下為轉換公式: 
 
( )
, ,
2
( ) 2
2
( 1)
2
( 2)
2
log ,
1
(log 2 )
2
1
2
Tr
q q q q
qOcc
q q
q
qM
q
q
M
q
q
a q q
q
q
q


 






  
   
 
  
(3.5) 
 
,q qa 為狀態 'q 轉移到狀態 q 的機率， q  為狀
態 q 中高斯函數的平均值，
q  為標準差。 
3.2  最大相似度估測法則 
尋求模型最大相似度的方法基本上模型而有
不同的演算法。以 HMM 為例，訓練方法以最
大 相 似 度 估 測 法 則 (Maximum likelihood 
estimation, 簡稱 MLE) 結合期望值最大化
(Expectation Maximization，簡稱 EM)演算法進
行模型的估測及更新。HCRF 則使用 MLE 準
則搭配隨機坡升法(Stochastic Gradient Ascent,
簡稱 SGA)演算法。EM 演算法經過反覆估測
及訓練資料其模型參數相似度會逐漸增加，雖
然 EM 演算法對於 HMM 的訓練成效不錯，而
HCRF選擇使用 SGA及MLE演算法的原因在
於 HCRF 使用 EM 演算法時計算較複雜，因此
考慮計算量及複雜程度改用 SGA 演算法取
代。SGA 演算法結合 MLE 演算法用於
HCRF-UBM 訓練推導如下: 
首先定義條件對數相似度函數  L  如式
(3.6)，其u 代表 UBM， 為模型參數，觀測
序列為 1 2 3{ , , , }To o o oo : 
 
   log | ;L p u  o                 (3.6) 
 
搭配最大相似度估測法訓練模型，此模型的更
新函式如式(3.7)。其中 n 為遞迴次數， 為模
型特徵參數，q代表隱藏狀態序列，q 代表隱
藏狀態: 
   
   
, 1 ,
, , ,
,
log | ;
n n n
u q u q n
u q
p u
 

   

 
 

o (3.7) 
將條件對數相似度函數偏微分如式(3.8): 
 
8 
   * *,
( ) ( ; ) max ( ; )
        , ; , , ;
i i i
j i
j j i i
d g g 
     


  
 
o o o
q o q o
 (3.17) 
能量函數 的求取，如下式: 
 
      
, , ,
1 22
, ,
1 1
, , , (3.18)
t d t d t d
T D
M MOcc
q t d q t d q
t d
o o     
 
  q o
 
定義損失函數(Empirical Loss Function)為雙彎
曲函數(Sigmoid Function)，參數   通常設為 
0 以及 1   。 
 
      
1
( )
1 exp( ( ) )
i
i
l
d 

  
o
o
    (3.19) 
對損失函數式(3.19)偏微分，可以看成兩個式
子個別偏微分: 
   
( ; ) ( )
( ; ) | .       
( )q
i i
i
i q
l d
l
d
 



 
 
 
o o
o
o
   (3.20) 
 
       
 
     
   
 
* *
,
1
1
, ; , , ;
 
, , ,
, , 1, 2
t
i
j j i i
T
t q
tq
T
i
t
d
f o
f t
Tr Occ M M
 
 



     
 






 
    
   
   
   
  
 

 

q q
o
q o q o
q o
(3.21) 
經過損失函數偏微分後訓練新的模型參數，模
型參數更新式， n 為遞迴次數: 
  
   
 ,
,
, 1 ,
, , ( ; ) | n
q
n n n
q q il 

 
   
   


   o   (3.22) 
損失函數偏微分後式帶入更新式(3.22)可寫成
式(3.23): 
 
   
      
   
   
      
   
 
, 1 ,
, ,
1
, 1 ,
, ,
1
1
  , , ,
1
 , , ,
, , 1, 2
i i
j j
n n n
q q
i i i i
T
i
t
n n n
q q
i i i i
T
j
t
l d l d
f t
l d l d
f t
Tr Occ M M
 
 

 
 

  


  







 
    
  
 
 
    
 
 



o o
q o
o o
q o
 (3.23) 
3.4  語者模型產生方法  
  於實際語者辨識系統中，可能會發生收集語
者註冊語料不足的狀況，進而使用調適通用背
景模型的方式達到加強語者資訊的效果，此種
調適方法參考 [4]。通用背景模型的形成必須
事先收集大量的語者語料，使其訓練出包含大
部分語者資訊的模型參數，藉由少量特定語者
的語料(或稱註冊語者語料)調適背景模型產
生特定語者模型。此調適法採用貝式調適法或
稱最大機率估測法，此演算法將欲調適語者特
徵值進行模型參數求取如附錄甲式(甲.1)-附
錄甲式(甲.3)，並且設定調適參數如附錄甲式
(甲.4)依照比例求取調適後語者模型。 
  圖(3.1)為 GMM 中單一狀態單一混合數的
調適示意圖，註冊語者語料調適背景模型會形
成一個新的特定語者模型。註冊語者 speaker 1 
將其語料區分為語音與非語音段，語音段部分
因含有語者資訊將匯集成一組序列 x 對圖中
UBM 進行語者調適如附錄甲式(甲.1)-附錄甲
式(甲.5)，調適出 speaker 1 語者特定模型，最
後 陸續有註冊語者 y、z 經過調適後產生出
speaker 2、 speaker 3。非語音段部分則與 
其他語者非語音段一起匯集起來形成一個靜
音模型。 
10 
產生 HCRF 語者模型，其模型補償的方法有四
個只挑選只其中一種進行實驗其堆導如下。使
用其中固定 ( 1)M
q 、
( 2)M
q 之 HCRF 模型補償: 
 
2
( ) 2
2
( 1)
2
( 2)
2
1
log 2
2
1
2
qOcc
q q
q
M s
q
q
M
q
q

 






 
    
 

 
        (3.24) 
假設 ( 1)Mq 與
( 2)M
q 沒有受雜訊干擾的情況，變
異數 2q 可用
( 2)M
q 取代為式(3.25)： 
 
2
( 2)
1
2
q M
q


                       (3.25) 
假設 ( )Occq 受雜訊干擾下，則
( 1)M
q 與式(3.25)
代入 ( )Occq 等式右側，如式(3.26)： 
 
2
( ) 2
2
( 1)
( 2)
1
log 2
2
1 1
log 2
2 2
qOcc
q q
q
M
q qM
q

 

  

 
    
 
  
      
   

(3.26) 
由式(3.25)可以推導更新後的 q ， q  可用
( 1)M
q 、
( 2)M
q 、
( )Occ
q 取代為式(3.27)： 
( )
( 2)
( 1)
2 logOccq M
q
q M
q





  
    
           (3.27) 
根據式(3.27)平均參數值可以由偏差值與雜訊
來補償後為 ，代入式(3.28)可得到補償後的 ： 
2
( ) 2
2
ˆ1ˆ log 2
2
Occ s
s s
s

 

 
   
 
        (3.28) 
HCRF-UBM 模型補償流程圖如圖(3.5)，經由
HMM-UBM 模型參數轉換獲得 HCRF-UBM
模型參數，在此需要進行模型參數平均值的估
測，利用 HCRF-UBM 模型參數在模型補償推
導中求取平均值式(3.27)，接著才能與語者註
冊語料進行 MAP 調適，將 HCRF-UBM 模型
轉換成 HCRF 語者模型。 
 
圖 3.5: HCRF-UBM 語者模型補償 
 
四、實驗結果與分析 
   
  在這一章中我們將會說明 ns-2 實驗的網路
架構、參數的選擇及實驗的結果。進行的實驗
分為三個部分，將呈現各種網路環境下，以接
收端收到語音封包進行語者辨識可得到的辨
識率。 
4.1  實驗網路架構與參數設定 
  我們在 ns-2 上設計如圖 4.1 的網路架構環
境，除了進行語音通訊的兩端傳送 VoIP 封包
外（只討論單向終端 A 到終端 B 的封包流
向），不同終端也會送出不同流量的封包，影
響網路的運作情形，造出我們想要的封包遺失
率。當網路的負載（Payload）增加時，路由
器（Router）的緩衝器（Buffer）會暫存等待
處理的封包。一旦緩衝器填滿了等待資料，接
著想要進入緩衝器的封包就會被丟棄，就是所
謂的封包遺失的狀況發生。所以藉由控制其他
終端送出的封包流量，就可以達到不同封包遺
失率的目的。請注意從終端 A 送到終端 B 的
12 
 
表 4.2 Mat 2000 的五個子資料庫內容 
子資料庫 內容 
MATDB-1 回答短句 
MATDB-2 數字串 
MATDB-3 單音節 
MATDB-4 2-4 字詞 
MATDB-5 語音平衡句 
 
 
圖 4.2 在 iLBC 介面輸入相關檔案名稱 
Frame size 和 channel 檔案 
 
表 4.3 語音訊號的基本條件 
Bits per sample 16 
取樣率 8000 sample/sec 
聲音訊框長度 20ms 
Encoding type 16-bit linear PCM 
iLBC 的選擇 
  透過 iLBC 編解碼器，輸入相關音檔、Frame 
size 的選擇、和網路狀況資料，就可得到所需
要且不同的 Packet Lose 的音檔。之後再靠辨
識程式算出在不同 Packet Lose 下的辨識錯誤
率。 
  iLBC 編解碼器程式來源是從中原大學的王
佳盈老師提供，並已依個人需要做過介面參數
修改可輸入所需的實驗參數。 
 
語者辨識的選擇 
  語者辨識程式是由洪維廷老師提供，並依辨
識需要改變不同的語者模型。表 4.4 是語者辨
識模型實驗相關設定表。 
 
表 4.4 語者辨識模型實驗相關設定表 
音框重疊 10 ms 
混合數 32 mixture 
維度 26 
狀態數 6 (Initial 2、Final 4) 
靜音狀態數 1 (Silence 1) 
 
實驗流程圖 
  圖 4.3 是實驗流程圖。先使用 ns-2 建立所
需要的網路架構，並設定有線網路及無線網路
的各種環境參數，得到 0 與 1 的串列，0 代
表遺失而 1 代表正確地傳送。再將此串列送
入 iLBC，就可當作 iLBC 的相關輸入參數。
連同Mat2000中做為註冊語料300人的音檔一
起輸入，便可得到有資料遺失的音檔，最後再
用資料遺失的音檔與辨識模型做辨認語者的
工作。 
開始
在ns2建立的模擬環境並設
定所要的機率(得到Bit 
stream)
從ns2得到的通道狀況輸入
iLBC介面
語者辨認(HMM、HCRF、
HMM-UBM、HCRF-UBM)
結束
Mat2000 300人語音資料
輸入
 
圖 4.3 實驗流程圖 
 
4.2 實驗一：不同 Packet Loss 環境的測試 
 
  我們使用 ns-2 設計的網路環境，分別讓 A
傳送至 B 的 VoIP 封包串流產生 1%、5%、
10%、20% 及 30%的封包遺失率。 
  接著再透過 iLBC 編解碼器，輸入相關音
檔、Frame size 的選擇、和網路狀況資料，就
可得到所需要且不同的 Packet Lose 的音檔。
之後，再靠辨識程式算出在不同 Packet Lose
14 
升時，各種語者辨識方法的錯誤率均有攀升的
趨勢，用折線圖來看各種不同 Packet Loss 下
的變化率可發現其趨勢及差異。圖 4.4 說明，
當網路環境壅塞使封包遺失率為 30%時，使用
HMM model 辨識錯誤率高達 23.6%，使用 
HMM-UBM 則有較低的錯誤率為 11.4%。圖
4.6 說明當封包遺失率為 30%時，使用 HCRF 
錯誤率為 23.4%，HCRF-UBM 表現最佳，錯
誤率最低 11.1%。圖 4.5 與 4.7 是相同實驗但
在調適語句減少為每人 5 句話的狀況下進
行。當封包遺失率為 30%時，HMM 及 HCRF
的錯誤率將會到達一半以上的 57.1%，使用
HMM-UBM或HCRF-UBM則會分別有 21.8%
和 21.7%的錯誤率。整體觀之，不管是否有封
包遺失，HCRF-UBM 都有最佳的效能。 
  在調適語句為每人 20 句話的四種辨識模型
下，錯誤率都有類似的上升趨勢：Packet Loss
從 0%變成 1%時，四種辨識模型的錯誤率都
是緩步上升（變化率相對較小）。Packet Loss
從 0%變成 1%時，HMM 從 7.9%增為 8.8%成
長 1.11 倍、HMM-UBM 增長 1.02 倍、HCRF
增長 1.01 倍、HCRF-UBM 增長 1.10 倍。然而
當封包遺失率繼續增加時，錯誤率均開始以較
快 的 速 度 上 升 。 另 外 HMM-UBM 和
HCRF-UBM 在剛開始時錯誤率略顯上升，當
封包遺失率在 5%後到 10%這段區間上升幅度
略大，之後的錯誤率以近似於等比例的方式上
升，不像 HMM 與 HCRF 當封包遺失率大於
5%後，上升幅度都差不多。 
  在調適語句為每人 5 句話的四種辨識模型
下，錯誤率都有相同的上升趨勢：封包遺失率
從 0%變成 1%時，錯誤率變化最大。HMM 從
28.9%增為 39.1%成長 1.35 倍、HMM-UBM 增
長 1.34 倍、HCRF 增長 1.35 倍、HCRF-UBM
增長 1.39 倍。 
  封包遺失率從 0%變 5%時，調適語句為每
人 20 句話與 5 句話的錯誤率變化見表格 
5-5。整體而言，使用較多的調適語句進行語
者辦識，較能對抗封包遺失造成的損害。 
 
表4.5 調適語句為每人 20句話與 5句話在
四種辨識模型下的錯誤率變化 
 HMM HMM- 
UBM 
HCRF HCRF-
UBM 
調適語
句 20 句 
1.56 倍 1.23 倍 1.56 倍 1.29 倍 
調適語
句 5 句 
1.44 倍 1.44 倍 1.44 倍 1.47 倍 
 
4.3 實驗二：因 Delay 對封包造成的影響測試 
  在此實驗中，我們希望得到封包延遲對於語
者辨識的影響。基本上網路上封包延遲與封包
遺失有著一定的交互影響，然而我們希望此實
驗中能盡可能去除封包遺失此一變因。為此我
們在設定網路環境時，將路由器的緩衝器提高
至可以容納所有等待的封包（換言之，無限大
的緩衝器），不讓路由器發生封包遺失的狀
況；另外無線網路 802.11g 也是設定在一個十
分乾淨其他干擾源的環境下，使它盡可能不遺
失封包。 
  語音本身對傳輸延遲非常敏感，因此 ITU-T 
G.114 所規定電話服務必須遵循來回傳輸時
間（Round-trip delay time）小於 300ms 的要
求，當壅塞的網路狀況使得來回傳輸時間大於
300ms，便會使得聽者難以忍受。下面的實驗
設定不同的臨界值（Threshold），只要實驗中
發現資料從 A 傳送到 B 的單程傳輸時間
（Single-trip delay time）大於設定的臨界值，
我們便將其視為過時的資料，無須再進行處
理。這個設定的臨界值，我們將其稱為最大延
遲 容 忍 臨 界 值 （ Max Delay Tolerance 
Threshold）。實驗過程中，便是把單程傳輸時
間大於設定的臨界值的封包，當作遺失來處
理。我們希望能去評估在不同的系統要求下，
傳輸延遲對語者辨識率所造成的影響。由於
ITU-T G.114 所規定的來回傳輸時間要小於
16 
 
圖 4.10 HCRF 和 HCRF-UBM 在不同最大延遲
容忍臨界值的錯誤率（調適語句為每人 20 句
話） 
 
 
圖 4-11 HCRF和 HCRF-UBM在不同最大延遲
容忍臨界值的錯誤率（調適語句為每人 5 句
話） 
 
 
 
4.4 實驗三：受雜訊干擾的語音訊號在不同
Packet Loss 環境的測試 
  測試語句是選取受到雜訊干擾（ babble 
24dB）的語料，50 人每人 8 句共 400 句。語
者辨識同樣採用了 HMM、HMM-UBM、HCRF 
與 HCRF-UBM 四種方法進行測試，圖 5-12 
與圖 4.13 是 HMM 和 HMM-UBM 分別在每人
20 句與 5 句調適語句的情況下，語者辨識錯
誤率與封包遺失率的關係圖；圖 4.14 與 4.15
則是 HCRF 和 HCRF-UBM 分別在每人 20 句
與 5 句調適語句的情況下，語者辨識錯誤率與
封包遺失率的關係圖。 
 
圖 4-12 HMM 和 HMM-UBM 在不同 Packet 
Loss 的狀況下的錯誤率（調適語句為每人 20
句話） 
 
圖 4.13 HMM 和 HMM-UBM 在不同 Packet 
Loss 的狀況下的錯誤率（調適語句為每人 5
句話） 
 
18 
 
 
圖 4-16 HMM-UBM 和 HCRF-UBM 在不同
Packet Loss 的狀況下的錯誤率（調適語句為每
人 20 句話） 
 
 
圖 4-17 HMM-UBM 和 HCRF-UBM 在不同
Packet Loss 的狀況下的錯誤率（調適語句為每
人 5 句話） 
 
 
 
圖 4-18 HMM 和 HCRF 在不同 Packet Loss 的
狀況下的錯誤率（調適語句為每人 20 句話） 
 
 
 
圖 4-19HMM 和 HCRF 在不同 Packet Loss 的
狀況下的錯誤率（調適語句為每人 5 句話） 
 
 
表 4.6 HMM-UBM 與 HCRF-UBM 錯誤率下降比 
Packet Loss 比例 0% 1% 5% 10% 20% 30% 
錯誤率下降比例(調適語句每人 20 句) 14.56% 11.93% 8.13% 11.84% 11.85% 9.47% 
錯誤率下降比例(調適語句每人 5 句) 8.43% 6.94% 8.97% 6.42% 8.90% 7.43% 
表 4.7 HMM 與 HCRF 錯誤率下降比 
Packet Loss 比例 0% 1% 5% 10% 20% 30% 
錯誤率下降比例(調適語句每人 20 句) 16.16% 15.87% 11.38% 9.43% 9.52% 7.19% 
錯誤率下降比例(調適語句每人 5 句) 5.57% 4.61% 4.02% 3.91% 3.13% 2.90% 
20 
recognition systems,” in Proceedings IEEE 
International Conference on Acoustics, Speech 
and Signal Processing, pp. 257–260, 2007. 
[6] M. F. R. Chowdhury, S. A. Selouani, and D. 
O’Shaughnessy, “Distributed automatic 
text-independent speaker identification using 
gmm-ubm speaker models,” in Proceedings 
IEEE Canadian Conference on Electrical and 
Computer Engineering, pp. 372–375, 2009. 
[7] European Telecommunications Standards 
Institute, Speech Processing, Transmission and 
Quality Aspects (STQ); Distributed speech 
recognition; Advanced feature extraction 
algorithm, 2002. ETSI Standard ES 202 050, 
Ver. 1.1.1. 
[8] 范世明, “高斯混合模型在語者辨識與國語
語音辨認之應用,” Master’s thesis,國立交通大
學電信工程系, 民國 90 年. 
[9] J.Lafferty, A.McCallum, and F.Pereira, 
“Conditional random fields probabilistic models 
for segmenting and labeling sequence data,” in 
Proceedings ICML34 Proceedings of the 
Eighteenth International Conference on 
Machine Learning, pp. 282–289, 2001. 
[10] 李信廷, “改善最小錯誤鑑別式之語者辨
認方法,” Master’s thesis, 民國 95 年. 
[11] B.-H. Juang and S. Katagirl, 
“Discriminative learning for minimum error 
classification,” IEEE Transactions on Signal 
Processing, vol. 40, pp. 3043–3054, 1992. 
[12] W.Chou, B.-H. Juang, and C.-H. Lee, 
“Segmental gpd training of hmm-based speech 
recognizer,” in Proceedings ICASSP 
International Conference on Acoustics, Speech 
and Signal Processing, vol. 1, pp. 473–476, 
1992. 
[13] H. C.Wang, F. Seide, C. Y. Tseng, and L.-S. 
Lee, “Mat-2000–design, collection, and 
validation of a mandarin 2000-speaker telephone 
speech database,” ICSLP, vol. 46, pp. 460–463, 
2000. 
[14] 游鈞顯, “應用於語音辨認之隱藏式條件
隨機域聲學模型研究,” Master’s thesis, 私立
元智大學通訊工程學系, 民國 97 年. 
[15] A.Gunawardana, M.Mahajan, A.Acero, and 
J. C. Platt, “Hidden conditional random fields 
for phone classification,” in Proceedings ISCA 
International Speech Communication 
Association, pp. 1117–1120, 2005. 
[16] 邢凱婷, “基於隱藏式條件隨機域語者模
型之語者識別演算法,” Master’s thesis, 民國
97 年. 
[17] S. fen Liang, “Gmm and ann hybrid model 
and its application in speaker identification,” in 
Proceedings ICNC Fifth International 
Conference on Natural Computation, pp. 
159–163, 2009. 
[18] 王小川, 語音訊號處理. 全華科技出版
社. 
[19] S. Chougule and P. P. Rege., “Language 
independent speaker identification,” in 
Proceedings ICNC International Conference on 
Industrial Technology, pp. 364–368, 2006. 35 
[20] A. Savard, “Overview of homophonic pitch 
detection algorithms,” Schulich School of Music, 
McGill University, 2001. 
[21] L. Wang, S. Ohtsuka, and S. Nakagawa, 
“High improvement of speaker identification 
and verification by combining mfcc and phase 
information,” in Proceedings ICASSP 
International Conference on Acoustics, Speech 
and Signal Processing, pp. 4529–4532, 2009. 
[22] Z. Qian, L. yan Liu, and X. yao Li, 
“Speaker identification based on mfcc and 
imfcc,” in Proceedings ICNC International 
Conference on Information Science and 
Engineering, pp. 5416–5419, 2009. 
[23] D. Pullella, M. Juhne, and R. Togneri, 
22 
 
圖甲.1:混合高斯語音框間的關係 
 
  首先計算背景模型中混合高斯對於註冊語
料音框的機率值如式(甲.1)，圖(甲.1)為混合高
斯語音框間的關係： 
 
 
 
1
Pr |
i i t
t M
j j t
j
w p x
i x
w p x



             (甲.1) 
 
接著累加混合高斯對於註冊語料的機率值如
式(甲.2)： 
 
1
Pr |
T
i t
t
n i x

                    (甲.2) 
 
求取一階動差  iE x ，也代表著模型平均值的
意義。 
   
1
1
Pr |
T
i t t
ti
E i x x
n 
 x             (甲.3) 
 
特定語者模型經由註冊語者與背景語者兩者
模型依照調適參數進行調適， i 代表背景模
型而  iE x 代表註冊語料模型: 
   1i i iE     x              (甲.4) 
i
i
i
n
n r
 

                        (甲.5) 
 
0  時模型會完全趨向背景模型， 1   
時模型會完全趨向註冊語者模型。其中調適參
數 r 參考資料建議使用 8 至 20，本論此參數設
定為 8。以上為 GMM 的調適過程，而 HMM
相同過程只是比起 GMM 多出狀態轉移的概
念，HCRF 的調適必需求取過平均值參數後，
也是使用相同的步驟進行調適。 
99 年度專題研究計畫研究成果彙整表 
計畫主持人：洪維廷 計畫編號：99-2219-E-155-002- 
計畫名稱：應用於遠距協同作業之多模態人機智慧型互動關鍵技術研究--子計畫一：協同作業環境下
結合語音與視覺事件偵測之先進議程紀錄與後製系統(I) 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 1 100% 
該論文審稿修訂
中。 
 
研究報告/技術報告 0 0 100%  
研討會論文 1 1 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 3 3 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 1 1 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
國科會補助專題研究計畫成果報告自評表 
請就研究內容與原計畫相符程度、達成預期目標情況、研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）、是否適
合在學術期刊發表或申請專利、主要發現或其他有關價值等，作一綜合評估。
1. 請就研究內容與原計畫相符程度、達成預期目標情況作一綜合評估 
■達成目標 
□未達成目標（請說明，以 100 字為限） 
□實驗失敗 
□因故實驗中斷 
□其他原因 
說明： 
2. 研究成果在學術期刊發表或申請專利等情形： 
論文：■已發表 □未發表之文稿 □撰寫中 □無 
專利：□已獲得 □申請中 ■無 
技轉：□已技轉 □洽談中 ■無 
其他：（以 100 字為限） 
無。 
3. 請依學術成就、技術創新、社會影響等方面，評估研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）（以
500 字為限） 
由於協同作業名列近年來最熱門商用軟體之一，可見協同作業未來的重要性。然而目 
前最受重視的產品大都是國外廠商所製造，願意投資相關產業的國內廠商屈指可數。雖然
本計畫是針對遠距教學設計相關工作平台，研究如何建立應用於遠距教學之多媒體資料存
檔備查系統，但相關的研究成果也可以應用於其他如視訊會議等其他作業。我們會推廣本
計畫的研究成果，從事論文的發表，並申請專利。因此本計畫的研究對於國內在推廣協同
作業、建立自己的技術應有相當的助益。本計畫探討遠距教學或視訊會議等協同作業的場
景，因其即時的特性與網際網路缺乏服務品質保證的狀況下，造成即時傳送之影音不佳，
如何在後處理階段利用其他子計畫標記出之高雜訊多媒體視訊與語音，以原始多媒體視訊
與語音取代之，建立高品質多媒體紀錄。除設計協同工作平台外，研究重點在於對每一語
音段之起點與終止點的偵測，與估計每一筆錄音或錄影間時間誤差，幫助對音訊與視訊資
料的處理。 
 
我們已建立基本實驗平台，利用 NS2 模擬各種網路狀況下封包遺失的狀況，以此收集到的
數據資料當作 iLBC encode/decode 的輸入通道的狀況，模擬出 iLBC 聲音串流經過 Packet 
Loss 與 Delay 後的聲音檔案。再將這些聲音檔案匯入各種語者模型進行語者辨認，最後進
行數據分析。在第一年的計畫中，我們提出一項關鍵技術:採用隱藏式條件隨機域(Hidden 
Conditional Random Field, 簡稱 HCRF)於語者辨識之聲學模型，並與傳統之隱藏式馬可
