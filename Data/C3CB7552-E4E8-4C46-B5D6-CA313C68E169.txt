using the economical strokes which positions are less 
constrained and which sizes are reduced. In the 
second system [2], the initial strokes are extended 
to most areas of the image. The proposed stroke-
extending is based on the smoothest-first strategy, 
which ensures that the geometric characteristics of 
gray levels of an object are sufficiently explored, 
and the extended strokes approximately fit the real 
shapes of objects. Then, a conventional colorization 
algorithm providing good color transition between 
objects can be used to complete the colorization. Our 
system can achieve very good colorization with much 
reduced run time. 
英文關鍵詞： colorization, color blending, weight diffusion, 
stroke extending 
 
blending of colours of the nearest several strokes, where some
sorts of distance were used to decide the nearest strokes [3,
8, 29]. As a third approach, Heu et al. [13] propagated
chrominance values from strokes to other pixels based on the
priority determined by the grey-level differences between
pixels. Smaller differences meant smoother pixels and hence
had higher priority to be coloured. A coloured pixel was
called a source. Starting from the neighbours of the strokes,
the non-source pixel that connected to the sources and had
highest priority was coloured by setting its chrominance
value as the blending of the chrominance values of the
sources around the pixel. The newly generated source again
had non-source neighbours that entered the sequence of
pixels waiting for colourisation. The process of ﬁnding the
highest priority and colouring was continuously repeated
until all the pixels were all sources. This priority-based
approach has two beneﬁcial features. First, the surfaces of
objects in the image are sufﬁciently explored by the smooth-
ﬁrst diffusion, and naturally an object touches others at
the sites with relatively large image differences. The sites are
often the real object boundaries. Second, because the
sufﬁcient exploration of smooth areas is guaranteed before
reaching image boundaries, the colourisation results are
insensitive to the locations and sizes of strokes, and hence
the manual work can be reduced. With this feature, the
priority-based approach is free from the problems of
conventional methods based on optimisation or distance.
One problem of conventional optimisation-based approach
[5] is the possible fading of colour after a long-distance
propagation. Attention should be paid to the positions of
strokes to avoid the colour fading. In conventional distance-
based approach [3], the colourisation results are sensitive to
the positions of strokes, because the distances are measured
from the strokes. These problems are avoided in the
propagation of [13]. However, the propagation [13] still has
two limitations. First, it uses the exponential function to
transform a grey-level difference into a quantity proportional
to the priority of propagation. As a result, there is a tendency
for it to propagate greedily to the pixels of smooth grey
levels. Then, excessive propagation is likely to occur in the
object juncture where the edges are not clear, resulting in
wrong object boundaries. Second, since the chrominance
values are directly blended and diffused in the propagation,
if some simple operations viewed from the users, for
example, changing the colour of a stroke, deleting a stroke or
adding a stroke, are demanded, the whole image must be
re-propagated.
In this paper, we focus on the priority-based approach and
improve the propagation [13] by solving its two limitations.
We propose to use the reciprocal function for measuring
image smoothness, which is more moderate for deciding
the priority, and hence can avoid wrong boundaries resulted
from the excessive propagation. Also, we adopt the
blending-weight diffusion, instead of the direct blending of
chrominance, to fulﬁl the colourisation. By doing so, our
method can respond quickly to the user demand for
stroke editing. The concept of generating blending weights
for colourisation was also used in [3, 30]. They have
demonstrated very good colourisation results and shown that
it was easy to change colours, extract objects for partial
colourisation etc., by virtue of the blending weights.
Nevertheless, both the two techniques did not address the
stroke editing such as adding or deleting a stroke. Also, they
all have their own limitations that our method does not have.
The technique [3] is distance based and has the limitation as
mentioned above. In [30], the blending weights were
modelled as Markov random ﬁelds and found by optimising
an objective function. The optimisation is time-consuming.
In addition, the objective function needs histogram
information on the grey levels representative of the objects to
be coloured. The information must be gathered from strokes,
which are therefore necessary to be across intentionally
chosen regions (position sensitive) and of the large size
(size sensitive) much exceeding the requirement to indicate
an object. Our method is not only free of the above
limitations of [3, 30], but also capable of fast re-colouring
adapting to adding or deleting a stroke.
The rest of this paper is organised as follows. In Section 2,
we introduce the proposed diffusion of blending weights
for colourisation. Section 3 discusses the main differences
between the propagation of [13] and our diffusion. The
experimental results are given in Section 4 to show the good
performance of our diffusion. Finally, Section 4 concludes
the paper.
2 Colourisation based on weight diffusion
Assume X is a grey-level image to be coloured, and the user
has drawn some strokes on X, each stroke indicating the
approximate position of an object and the colour to be
presented by the object. In this paper, the YUV colour space
is used to describe the colour image, where Y is the
luminance signal, and U and V represent the chrominance
signal. We note that other spaces, such as YCbCr and YIQ,
can be used for colourisation as well. If a different
chrominance coordinate system is used, it sufﬁces to change
the U and V in the following derivation into the
corresponding chrominance coordinates. Let X(s) be the grey
level at the site s, s [ V, where V is the lattice system on
which the image is deﬁned, Y (s) the luminance, and U(s)
and V (s) the chrominance values at the same site. To keep
the luminance of the coloured image the same as that of the
original grey-level image, set Y ¼ X directly. The U and V
values need to be determined from the chrominance of
strokes given by the user.
2.1 Blending-weight diffusion
For given K strokes, K . 0 and each stroke specifying a
colour, we create a vector a(s) at site s, s [ V
a(s) = [a1(s), a2(s), a3(s), . . . , aK (s)] (1)
where ak(s), k ¼ 1, 2, . . ., K, is the weight on the chrominance
of the kth stroke to take part in the blending of chrominance
at site s. We call ak(s) the blending weight of the kth stroke
at site s, and a(s) the blending vector at site s. The weight
ak(s) meets 0 ≤ ak(s) ≤ 1 and
∑K
k=1
ak (s) = 1 (2)
We note that ak(s) ¼ 0 means the chrominance at site s
does not contain the chrominance of the kth stroke. If
0 , ak(s) , 1, then the chrominance at site s contains the
chrominance of the kth stroke, and there must be other
strokes that take part in the blending. If ak(s) ¼ 1, then
the chrominance at site s is exclusively formed by the
chrominance of the kth stroke; the chrominance of other
strokes does not participated in the blending, that is,
aj=k(s) ¼ 0. In this case, the blending vector a(s) is an
IET Image Process., 2012, Vol. 6, Iss. 6, pp. 786–794 787
doi: 10.1049/iet-ipr.2011.0184 & The Institution of Engineering and Technology 2012
www.ietdl.org
2.3 Adding/deleting strokes
Suppose that the coloured image is not so satisfactory and
the user wants to add or delete some strokes. The image
needs to be re-coloured to adapt to the variation of strokes.
Since in the diffusion the order where the object regions
grow outwards is determined from the structure of local
smoothness of the grey-level image, the adding or deleting
of strokes affects only the regions covering the local
structure to which the added/deleted strokes belong. We
only need to check which regions the added/deleted strokes
are in and re-colour the regions. We consider here the user
adds/deletes a stroke. Adding/deleting multiple strokes can
be processed similarly. For adding a stroke, we execute the
following four steps.
Step A1: Collect the blending vectors at those sites comprising
the new stroke. Let a be the sum of these vectors. Note that
the ith element of a indicates whether or not the region
growing from the ith stroke is involved by the new stroke.
If the ith element is non-zero, then the ith stroke is
involved; otherwise, not involved.
Step A2: Check every element of a to see if any element is
not zero. As soon as a non-zero, say ak , is found, clear the
blending vectors which kth element is non-zero, that is, for
any s [ V, a(s) ¼ 0 if ak(s)= 0. For every non-zero
element, the blending vectors corresponding to it are
cleared. Let VA be the area consisting of the sites on which
the blending vectors are cleared, that is, VA ¼ {s|a(s) ¼ 0}.
The area VA is the region to be re-coloured.
Step A3: Append the new stroke to the original stroke
set. That is, each blending vector a(s), s [ V, is appended
by one element, which is exactly the blending weight of
the new stroke at site s.
Step A4: Use the new stroke, which must be in VA, and
the original strokes in VA as the initial strokes. Namely,
the blending vectors corresponding to these strokes are set
to be impulses. Let V\A be the complement of VA, that is,
V\A ¼ {s|s [ V, s  VA}. Use as sources the pixels of
the initial strokes and the pixels within V\A that neighbour
the pixels in VA. Then, perform the diffusion of (1)–(9)
over the region VA.
The steps for deleting a stroke, which principle is similar to
those for adding a stroke, are as follows.
Step D1: Assume the deleted stroke is the kth stroke in
the original stroke set. Clear the blending vectors which
kth element is non-zero, that is, for any s [ V, a(s) ¼ 0
if ak(s)= 0. Let VD be the area consisting of the sites
on which the blending vectors are cleared, that is,
VD ¼ {s|a(s) ¼ 0}. The area VD is the region growing
from the deleted stroke and needs to be re-coloured.
Step D2: Remove the deleted stroke from the original
stroke set. That is, the kth element of each blending vector
a(s), s [ V, is removed. The removed element is exactly
the blending weight of the deleted stroke. After the
removal, the dimension of a blending vector is decreased by
one.
Step D3: Let V\D be the complement of VD, that is,
V\D ¼ {s|s [ V, s  VD}. Use as sources the pixels within
V\D that neighbour the pixels in VD, and perform the
diffusion of (1)–(9) over the region VD.
We note that both adding (Steps A1–A4) and deleting
(Steps D1–D3) strokes require only local computation,
without recalculation of the whole image
3 Differences between the colour
propagation in [13] and our diffusion
Using this paper’s notation, we can state the kernel of the
propagation [13] as follows. The priority of a non-source at
site s is deﬁned by
P(s) =
∑
t[Ns
t is a source
s(s, t) (10)
where
s(s, t) = e−|Y (s)−Y (t)| (11)
is the smoothness measurement. The non-source (say, at site
s) with the highest priority is coloured and its chrominance
is given by
U (s) = ∑
t[Ns
t is a source
vstU (t)
V (s) = ∑
t[Ns
t is a source
vstV (t)
⎧⎪⎪⎪⎨
⎪⎪⎪⎩
(12)
where vst is as deﬁned in (8). From the comparison of (10)–
(12) with our method’s equations (3), (4) and (7), we can see
two major differences, discussed in the following.
Firstly, our diffusion uses the reciprocal function in (4)
instead of the exponential one in (11) to measure the
smoothness of grey levels. The negative-power exponential
function in (11) is actually the reciprocal of the exponential
function of grey-level difference. The measurement of (11)
can be viewed as the exponential transformation exp(.)
followed by the reciprocal measurement of (4). Since the
transformation exp(.) pre-ampliﬁes considerably the ‘large’
differences, the measurement (11), compared with (4),
reduces considerably the effect of large differences on the
priority. The priority of (10) is then excessively dominated
by the neighbouring sources that have the most similar grey
levels with the central non-source. That is, the propagation
of [13] tends to propagate towards the most similar
neighbours excessively. This behaviour may be called a
trend towards being greedy for smooth pixels. As a result,
in the propagation of [13], the region belonging to an object
usually expands far in some directions, leaves many small
cavities, and then returns back to ﬁll up the cavities, so that
there are many small holes inside, and the border of
intermediate regions is relatively uneven (see Fig. 1a). If
such greedy propagation is performed around the object
juncture that joins the grey levels without signiﬁcant
difference, it is likely to step over the real object border,
resulting in wrong boundary. Fig. 2 shows the 256 × 256
peppers image coloured using the propagation of [13]. As
seen in Fig. 2b, the region marked by the blue rectangle
contains the object juncture that joins the grey levels
without signiﬁcant difference, so the propagation around the
juncture is excessive and results in the wrong boundaries,
which are not consistent with the actual object boundaries
(see the region marked by the black rectangles in Fig. 2a).
In contrast, our diffusion employs the priority of (3),
IET Image Process., 2012, Vol. 6, Iss. 6, pp. 786–794 789
doi: 10.1049/iet-ipr.2011.0184 & The Institution of Engineering and Technology 2012
www.ietdl.org
Fig. 3 Comparison of different colourisation methods
a Stroked grey-level images
b–e Results of using [13], the proposed method, [3] and [30]
Blue frames in (b) mark some example areas of excessive propagation of chrominance
Fig. 4 Results of adding extra strokes to improve Fig. 3e1
a Image formed by adding many extra strokes to Fig. 3a1
b Result of performing our method on a
c Result of carrying out [30] on a
IET Image Process., 2012, Vol. 6, Iss. 6, pp. 786–794 791
doi: 10.1049/iet-ipr.2011.0184 & The Institution of Engineering and Technology 2012
www.ietdl.org
was slightly slower by 0.3280% than the propagation [13],
because of accessing the large number of K-dimensional
blending vectors, where K ¼ 19. However, the former was
faster by 85.92% than the latter for adding a stroke, and
faster by 98.60% for deleting a stroke. Our method
shortened the processing time greatly.
5 Conclusions
In this paper, we propose to use reciprocal function for
smoothness measurement to determine the priority order
of colour diffusion in image colourisation. The proposed
method can improve the exponential-measurement-based
propagation [13], which has a trend towards being greedy
for smooth pixels, and is likely to cause wrong boundaries
nearby the object juncture joining the grey levels without
signiﬁcant difference. Therefore during our colourisation,
the colours can be more precisely ﬁlled in the positions
representing real object surfaces. In addition, our method
uses the blending-weight diffusion instead of the direct
propagation of chrominance values. Although the weight
diffusion needs additional memory to store the blending
vectors, only parts of the vectors require to be recalculated
for adding or deleting strokes. Even no blending vectors
needs to be recomputed for changing the colours of strokes.
Hence, our method can respond quickly to the user demand
for stroke editing. In case the memory is limited, the
chrominance can be blended directly, as in [13], without
storing the weights. In this limited case, our colourisation
results will be better than those of [13] in that the object
boundaries in our results will be more accurate, with the
same processing speed. Furthermore, compared with two
conventional techniques which also implement blending
weights, our method can provide the blending weights for
acceptable colourisation by using the economical strokes
which positions are less constrained and which sizes are
reduced. In the future, we will investigate how to accelerate
the diffusion process, so as to speed up the colourisation.
6 Acknowledgments
The authors are grateful to the anonymous reviewers for their
valuable comments that greatly helped them to improve
the readability and clarify the presentation of the paper.
They would also like to acknowledge ﬁnancial supports
from the National Science Council of Taiwan. This work
was supported in part by the National Science Council,
Taiwan, under grant NSC100-2221-E239-026.
7 References
1 Cheng, J., Cao, M.-Y., Teng, S.-H.: ‘A double-matched method for color
recovery’. Proc. First Int. Congress on Image and Signal Processing,
Sanya, Hainan, China, May 2008, vol. 2, pp. 237–241
2 Sykora, D., Burianek, J., Zara, J.: ‘Colorization of black-and-white
cartoons’, Image Vis. Comput., 2005, 23, (9), pp. 767–782
3 Yatziv, L., Sapiro, G.: ‘Fast image and video colorization using
chrominance blending’, IEEE Trans. Image Process., 2006, 15, (5),
pp. 1120–1129
4 Horiuchi, T.: ‘Colorization algorithm using probabilistic relaxation’,
Image Vis. Comput., 2004, 22, (3), pp. 197–202
5 Levin, A., Lischinski, D., Weiss, Y.: ‘Colorization using optimization’.
Proc. ACM SIGGRAPH, 2004, vol. 23, pp. 689–694
6 Kang, S.H., March, R.: ‘Variational models for image colorization via
chromaticity and brightness decomposition’, IEEE Trans. Image
Process., 2007, 16, (9), pp. 2251–2261
7 Vieira, L.F.M., Nascimento, E.R.d., Fernandes, Jr. F.A., Carceroni, R.L.,
Vilela, R.D., Araujo, A.d.A.: ‘Fully automatic coloring of grayscale
images’, Image Vis. Comput., 2007, 25, (1), pp. 50–60
8 Noda, H., Niimi, M.: ‘Colorization in YCbCr color space and its
application to JPEG images’, Pattern Recognit., 2007, 40, (12),
pp. 3714–3720
9 Nie, D., Ma, Q., Ma, L., Xiao, S.: ‘Optimization based grayscale
image colorization’, Pattern Recognit. Lett., 2007, 28, (12),
pp. 1445–1451
10 Abadpour, A., Kasaei, S.: ‘An efﬁcient PCA-based color transfer
method’, J. Vis. Commun. Image Represent., 2007, 18, (1), pp. 15–34
11 Liu, X., Wan, L., Qu, Y., et al.: ‘Intrinsic colorization’, ACM Trans.
Graph., 2008, 27, (5), pp. 152:1–152:10
12 Yang, C.-K., Peng, L.-K.: ‘Automatic mood-transferring between color
images’, IEEE Comput. Graph. Appl., 2008, 28, (2), pp. 52–61
13 Heu, J.-H., Hyun, D.-Y., Kim, C.-S., Lee, S.-U.: ‘Image and video
colorization based on prioritized source propagation’. Proc. IEEE Int.
Conf. Image Processing, 2009, pp. 465–468
14 Kim, T.H., Lee, K.M., Lee, S.U.: ‘Edge-preserving colorization using
data-driven random walks with restart’. Proc. IEEE Int. Conf. Image
Processing, 2009, pp. 1661–1664
15 Liu, B.-B., Lu, Z.-M.: ‘Image colourisation using graph-based semi-
supervised learning’, IET Image Process., 2009, 3, (3), pp. 115–120
16 Xiang, Y., Zou, B., Li, H.: ‘Selective color transfer with multi-source
images’, Pattern Recognit. Lett., 2009, 30, (7), pp. 682–689
17 Quang, M.H., Kang, S.H., Le, T.M.: ‘Image and video colorization
using vector-valued reproducing kernel hilbert spaces’, J. Math.
Imaging Vis., 2010, 37, pp. 49–65
18 Yu, F.-X., Liu, B.-B., Lu, Z.-M.: ‘Fast image colourisation based on
twin-codebook vector quantisation’, Electron. Lett., 2010, 46, (2),
pp. 132–134
19 Pouli, T., Reinhard, E.: ‘Progressive color transfer for images of
arbitrary dynamic range’, Comput. Graph., 2011, 35, (1), pp. 67–80
20 Zhao, Y., Wang, L., Jin, W., Shi, S.: ‘Colorizing biomedical images
based on color transfer’. Proc. Int. Conf. on Complex Medical
Engineering, Beijing, China, May 2007, pp. 820–823
21 Toet, A.: ‘Colorizing single band intensiﬁed nightvision images’,
Displays, 2005, 26, (1), pp. 15–21
22 Zheng, Y., Essock, E.A.: ‘A local-coloring method for night-vision
colorization utilizing image analysis and fusion’, Inf. Fusion, 2008, 9,
(2), pp. 186–199
23 Li, Z., Jing, Z., Yang, X., Sun, S.: ‘Color transfer based remote sensing
image fusion using non-separable wavelet frame transform’, Pattern
Recognit. Lett., 2005, 26, (13), pp. 2006–2014
24 Lipowezky, U.: ‘Grayscale aerial and space image colorization using
texture classiﬁcation’, Pattern Recognit. Lett., 2006, 27, (4),
pp. 275–286
25 Tsagaris, V., Anastassopoulos, V.: ‘Fusion of visible and infrared
imagery for night color vision’, Displays, 2005, 26, pp. 191–196
26 Welsh, T., Ashikhmin, M., Mueller, K.: ‘Transferring color to greyscale
images’. Proc. ACM SIGGRAPH, United States, July 2002, vol. 21,
pp. 277–280
27 Li, F., Bao, Z., Liu, R., Zhang, G.: ‘Fast image inpainting and
colorization by Chambolle’s dual method’, J. Vis. Commun. Image
Represent., 2011, 22, pp. 529–542
28 Sheng, B., Sun, H., Chen, S., Liu, X., Wu, E.: ‘Colorization using the
rotation-invariant feature space’, IEEE Comput. Graph. Appl., 2011,
31, pp. 24–35
29 Lagodzinski, P., Smolka, B.: ‘Interactive colorization based on hybrid
distance transform’. Proc. 2011 IEEE Int. Conf. on Computer Science
and Automation Engineering, Shanghai, China, 10–12 June 2011,
vol. 3, pp. 538–543
30 Dalmau-Cedeno, O., Rivera, M., Mayorga, P.P.: ‘Computing the
a-channel with probabilistic segmentation for image colorization’.
Proc. IEEE 11th Int. Conf. Computer Vision, 2007, pp. 1–7
31 http://www.eecs.berkeley.edu/Research/Projects/CS/vision/bsds/,
accessed January 2011
Table 1 Comparison of colouring time for adding and deleting a
stroke (unit: second)
First
calculation
Adding a
stroke
Deleting a
stroke
the propagation of [13] 53.899139 53.317196 53.515136
the proposed method 54.075931 7.504542 0.747455
time saving percentage
((2nd row2 3rd row/2nd
row) × 100%)
20.3280% 85.92% 98.60%
IET Image Process., 2012, Vol. 6, Iss. 6, pp. 786–794 793
doi: 10.1049/iet-ipr.2011.0184 & The Institution of Engineering and Technology 2012
www.ietdl.org
 1
國科會補助專題研究計畫項下出席國際學術會議心得報告 
                                     日期：101 年 10 月 19 日 
一、參加會議經過 
5/20 抵達首爾已是當地時間 18:45，匆忙間從首爾機場入關，搭巴士抵達首爾市中心，走
進巷弄中的小商旅飯店，已近晚間 21:00。5/21 參加 Live demo，看到各種有趣的最新電路
與系統的應用專題，例如自動倒車系統、可重新裝配的虛擬硬體電路、迷你機器人用高解析
距離偵測系統等。5/22 參加各場論文會議 sessions，包括影像分析與影像處理、視覺信號
處理與強化、視覺信號編碼等。晚間參加大會晚宴。5/23 發表論文，然後參加各場論文會議
sessions，包括影像分析與影像處理、視覺信號重建與編碼等；並且參加 Farewell Party，
因班機關係 5/24 賦歸。圖一~圖四為論文發表會場上部分照片。 
 
二、與會心得 
非常感謝國科會補助，才能順利完成此次出國參加研討會並發表論文的任務。能夠與來自
各國的學者討論最新的各領域的主題，感到非常興奮與榮譽感。不但增廣自己的見聞，認識
一些國際上的朋友，所見內容也對自己未來研究的內容與方向有很有幫助。 
隔了幾年的時間再度參加 IEEE 國際電路與系統研討會，發現台灣來的學生少了很多，中
華人民共和國的學生增加非常多，可以說看到黑頭髮黃皮膚的學生，超過 90%都是對岸來的。
國科會每年特別獎助台灣學者參與並增進國際影響力的措施，似乎未發揮多大的效果？如何
提升台灣學術在國際的能見度與影響力，的確是緊急而艱困的任務，值得所有台灣學術界共
同思考與努力。 
計畫編號 NSC 100－2221－E－239－026－ 
計畫名稱 利用對速略筆畫的位置與尺寸不敏感的色彩融合來作影像彩色化 
出國人員
姓名 何肯忠 
服務機構
及職稱 國立聯合大學 電子系副教授 
會議時間 101 年 5 月 20 日至101 年 5 月 23 日 會議地點 南韓首爾 
會議名稱 
(中文)2012 電機電子工程師協會國際電路與系統研討會 
(英文)2012IEEE International Symposium on Circuits and Systems 
發表論文
題目 
(中文)從半色調點的平均值估計抖色處理臨界值 
(英文) Estimating Dither Thresholds from the Average of Halftone Dots 
ISCAS 2012 Decision Notification - Paper 1249 
1 封郵件 
Ken-Chung Ho <kchoatg@gmail.com> 
iscas@epapers.org <iscas@epapers.org> 2012年1月7日上午12:15
收件者: kcho@nuu.edu.tw 
副本: iscas@epapers.org 
Dear Ken-Chung Ho, 
 
Congratulations ! 
 
Your paper number 1249 entitled "Estimating Dither Thresholds from the Average of Halftone Dots", has been accepted 
for presentation at the 2012 IEEE International Symposium on Circuits & Systems, to be held in Seoul, Korea from 20-23 
May 2012. We look forward to your participation and presentation at ISCAS 2012. 
 
Your paper has been assigned to Digital Signal Processing Poster session C5P-T. The full Conference schedule will be 
available on the ISCAS 2012 web site very soon. Be sure to check the conference web site (http://www.iscas2012.org/) 
often as important information is posted regularly on this site. If there are additional co-authors for this paper, please make 
sure to inform them of this decision. 
 
Remember that you must adhere to the following requirements: 
1. In order to guarantee inclusion in the conference program one author must be registered by Feb 10, 2012 23:59 (GMT -
0700), the pre-registration deadline. 
2. Your completed IEEE copyright form must be received by Feb 10, 2012 23:59 (GMT -0700). The form and instructions 
can be found at http://iscas2012.e-papers.org/ESR/copyright.php 
3. Your full paper in PDF format must be submitted no later than Feb 10, 2012 23:59 (GMT -0700) at this web site: 
http://iscas2012.e-papers.org/. Your paper must comply with the specifications outlined on the web site. Due to publication 
deadlines, no time extensions will be granted. 
4. Your username to log into your author account is: kcho. 
5. If you have forgotten your password, click on the “Forgot your Password?＂ link located in the log-in box of the 
submission web site (http://iscas2012.e-papers.org/). 
 
IMPORTANT PROCEDURE: It is REQUIRED that all PDF submissions be IEEE Xplore compliant. If your file does not 
meet Xplore compliance, it will NOT be published and will be removed from the ISCAS 2012 Proceedings CDROM and 
the IEEE Xplore system. To help you meet these new requirements, you must FIRST check to ensure that your PDF file is 
compliant by using the IEEE PDF eXpress system BEFORE you submit your paper to the conference final submission 
web site. 
 
1. Go to the IEEE PDF eXpress web site: http://www.pdf-express.org/ 
2. Use this conference ID:  iscas12x 
3. Use PDF eXpress to check or create your PDF file 
4. Once you have a GOOD PDF file, return to the ISCAS 2012 final submission web site (http://iscas2012.e-papers.org/) 
and upload your final submission. 
 
Please keep in mind that checking your PDF file for compliance and submitting your final paper for publication are 2 
separate procedures. After you have finished using the IEEE PDF eXpress system to either check your file for compliance 
or to generate a compliant file, MAKE SURE to return to the ISCAS 2012 final submission web site (http://iscas2012.e-
papers.org/) and upload your compliant final submission. 
 
Please accept our thanks for submitting your paper to the Conference. We look forward to seeing you in Seoul, for an 
interesting and exciting Conference. 
 
Sincerely, 
 
Young Hwan Kim, Liang-Gee Chen & Wouter A. Serdijn 
Technical Program Co-Chairs 
2012 IEEE International Symposium on Circuits & Systems 
 
 
**************************************** 
Reviewer #1 Comments 
**************************************** 
No comments provided. 
 
Page 1 of 2Gmail - ISCAS 2012 Decision Notification - Paper 1249
2012/6/10mhtml:file://D:\Ho\Publish\Conferences\2012 ISCAS\Reviewer's Comments - Paper 1249.mht
國科會補助計畫衍生研發成果推廣資料表
日期:2012/10/13
國科會補助計畫
計畫名稱: 利用對速略筆畫的位置與尺寸不敏感的色彩融合來作影像彩色化
計畫主持人: 何肯忠
計畫編號: 100-2221-E-239-026- 學門領域: 訊號處理
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
