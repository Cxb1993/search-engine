2行政院國家科學委員會補助專題研究計畫
■ 成 果 報 告
□期中進度報告
以 FRGC 人臉資料庫發展自動化三維人臉辨識系統之研究
計畫類別：■ 個別型計畫 □ 整合型計畫
計畫編號：NSC95－2218－E－194－015－
執行期間：95 年 11 月 01 日至 96 年 07 月 31 日
計畫主持人： 林維暘
共同主持人：
計畫參與人員：邱彥霖，陳明暘
成果報告類型(依經費核定清單規定繳交)：■精簡報告  □完整報告
本成果報告包括以下應繳交之附件：
□赴國外出差或研習心得報告一份
□赴大陸地區出差或研習心得報告一份
■出席國際學術會議心得報告及發表之論文各一份
□國際合作研究計畫國外研究報告書一份
處理方式：除產學合作研究計畫、提升產業技術及人才培育研究計畫、列
管計畫及下列情形者外，得立即公開查詢
■涉及專利或其他智慧財產權，■一年□二年後可公開查詢
執行單位：國立中正大學資訊工程學系
中 華 民 國 九 十 六 年 十 月 二 十 三 日
4目錄
中文摘要 .................................................................................................................................... 3
Abstract ..................................................................................................................................... 3
1. 前言 .................................................................................................................................... 5
2. 系統架構 ............................................................................................................................ 6
2.1 前處理 .................................................................................................................... 6
2.2 不變量特徵（Invariant Feature） ..................................................................... 7
2.3 多重臉部區域的人臉辨識方法 ............................................................................ 9
3. 實驗環境與人臉資料庫 .................................................................................................... 9
4. 實驗結果 .......................................................................................................................... 11
5. 結論與未來方向 .............................................................................................................. 11
6. 計畫成果自評 .................................................................................................................. 11
7. 參考文獻 .......................................................................................................................... 11
6所能達到的辨識率反而會低於用整個人臉來做辨
識。所以，我們提出的方法可以有效地結合多重臉
部區域，使得人臉辨識的效能比較不會受到表情變
化的影響，同時，在沒有表情變化的情況下，多重
區域系統的辨識效能也不會低於整個人臉所得到
的結果。此外，目前的人臉辨識技術在實際應用上
仍面臨許多其他問題，對於目前人臉辨識技術的主
要問題，我們認為無法克服這些問題的原因在於缺
乏有效的不變量特徵 (invariant feature)。對於人臉
辨識，理想的不變量特徵應在照明、姿勢、時間、
距離，甚至表情有變化的情況下仍維持不變。以目
前的技術而言，要達到這樣的目標仍有許多困難。
但是，近年來在不變量理論 (invariant theory) 的進
展已經使研究人員有機會去突破目前技術上的瓶
頸；基於這樣的觀察，我們提出了一個創新的人臉
辨識技術，其獨特之處在於結合了數學上不變量理
論的最新進展、資訊融合 (information fusion) 方法
與三維的人臉影像資料。
本論文的架構如下：在第二節，我們介紹所使
用的測試環境與人臉資料庫；在第三節，說明了我
們所提出的人臉辨識方法的重點；接著，我們將在
第四節展示我們的實驗結果；最後，我們對目前的
研究成果作一個總結，並提出一些未來的研究方
向。
2. 系統架構
我們的系統會先將三維影像經過前處理，並取
出三個不同的區域，再對每個區域分別計算其不變
量特徵，再以 Mahalanobis cosine 作為計算相似度
的方式，最後將三個區域的相似度做融合，即得到
最後的比對結果。整個系統的流程圖如圖一，以下
我們對細節部分做進一步的說明：
圖一 ：系統架構流程圖
2.1 前處理
前處理的目的在於對人臉的位置及姿勢做正規
化(normalization)。首先，我們會找出鼻尖所在的位
置，通常鼻尖會位於 z 值最大的地方；另外，還需
要偵測附近的點是否為有效點，以避免取到影像的
雜訊。
接下來，我們以 nosetip 當球心，八公分為半徑，取
出在此球內的所有點，此區域即為我們希望拿來做
辨識的人臉區域，這樣做的目的在於去除頭髮和
8們用 ),( nn yx 來表示該曲線上的第 n 個點。該曲線
的 summation invariants 可表示成以下的形式：



N
n
i
n
i
nji yx
1
,
其中 i,j 為整數，其值為使用者所決定， x , y 表示
原始的 x , y 座標經過了一個 moving frame[8]的轉
換，N 表示該曲線上取樣點的總數。 jik  代表
該不變量特徵的階數 (order)。目前[9]我們已經推導
出一階和二階的 summation invariants，包括 1,0 ，
0,1 ， 0,2 ， 1,1 ， 2,0 。在 FRGC version 1.0 的實
驗中，這些不變量特徵所達到的辨識率有顯著的差
異，其中辨識效能最高者為 1,1 ，其數學式如下：
2 2
1,1 1,1 1 1
3 2
1,0 1 1 1
2 2 2 2
1 1 1 N 1 N N 1
3 2
0,1 1 1 1
2 2 2 2
1 1 1 1 1
0,2 2,0 1 N 1 N
(( ) ( ) )
+P ( 2 2 )
+x y 2y y +y y x y )
P ( 2 2
+y 2 )
+(P P )(x x )(y y )
N N
N N N
N N N
N N N
P x x y y
y x x y y x
x y y x x y
x x x x x y x
    
 
 
  
  
  
N 1 1 N
1 N 1 1 N 1
+N(x y x y )
(x (x x )+y (y y ))

 
在此
,
1
N
i j
i j n n
n
P x y


以下，我們用一個簡單的例子來說明 1,1 的幾
何意義；在圖三中有兩組曲線，凹型的曲線和
圖三 ： 1,1 的值和曲線以下的面積成反比。
凸型的曲線。對於凹型的曲線，其 1,1 的值為正數
對於凸型的曲線，其 1,1 的值為負數。當一個曲線
的變曲程度越大， 1,1 的絕對值就越大。此外， 1,1
的計算結果完全不受座標系統改變的影響，因此可
以作為不同姿勢下人臉的不變量特徵。在以下實驗
中，我們將以人臉表面上的不變量特徵 1,1 ，作為
身份辨識的依據。對於人臉表面的一個點，我們用
一個水平的 window（尺寸為 1L ）來設定其鄰近
區域（neighborhood region），從鄰近區域的三維資
料就可以計算出該點的不變量特徵 1,1 。人臉表面
的每一個點，我們都會算出該點的不變量特徵
1,1 。同樣地，我們也可以用一個垂直的 window（尺
寸為 L1 ）來計算 1,1 。因此，對於每一個點，我
們會計算該點的不變量特徵兩次，一次是
10
(A) (B) (C)
圖五 ：三個人臉區域：(A)眼睛 (B)鼻子 (C)中間區塊
在 FAR=0.1%的辨識率
區域選擇的數量
ROC I ROC II ROC III
鼻子 + 中間區塊 + 眼睛 82.97% 82.79% 82.58%
中間區塊 65.36% 64.93% 64.39%
鼻子 76.94% 76.48% 75.96%
眼睛 58.61% 58.41% 58.20%
FRGC baseline 演算法 (取整個人臉) 56.22% 49.55% 42.78%
表一：融合前後的辨識率
影像拍攝所需時間約１秒鐘。三維影像中的每
一個像素包含兩部份，一部分是色彩 (RGB 值，
稱之為 texture channel) 及該點在空間中位置
(XYZ 座標值，稱之為 shape channel)。
關於 FRGC 的影像資料，是從 University of
Notre Dame 蒐集而來。一個 subject session 是去拍
攝一個人的人臉影像；FRGC 資料中的每一個
subject session 是由 4 張受控制的靜態影像，2 張未
受控制的靜態影像，和一張三維影像所組成。一張
受控制的影像表示是在照相館的環境背景裡拍攝
的，前面臉部影像的照明環境是用兩組燈光 (兩種
或三種攝影的燈光) 和兩種臉部表情 (微笑或一
般正常的表情) ；而未受控制的影像，是在不同明
亮度的環境下所拍攝的 (像是在走廊，中庭，戶
外) ，也包含了兩種表情 (微笑或一般正常的表
情)。 由於這些照片有表情與光源的變化，較符合
實際情況，因此非常適合用來做為人臉辨識的影像
資料庫。
FRGC 實驗的資料分為 training partition 和
validation partition；其中 training partition 是在
2002-2003 學年度所拍攝，其包含了兩個 training
sets。第一個大型 training set，是被用來訓練二維
臉部辨識演算法，它包含了 222 位受測者，共有
12,776 張二維影像，6,388 張是受控制的二維影
像，6,388 張是未受控制的二維影像；每一位受測
者有9到16次 subject sessions。第二個大型 training
set，共有 943個 subject sessions，每次 subject session
包含了 3D 掃描，受控制的和未受控制的二維影
像，其中 3D 資料被用來訓練三維人臉辨識方法。
3D 臉部掃描是在 2002-2003 學年度被蒐集。而
validation partition 的影像在 2003-2004 學年間被蒐
集而來，它包含了 466 個位受測者，共有 4,007 次
subject sessions，每一位受測者有 1 到 22 次不等的
subject sessions。
FRGC 提供了目前資料量最大的三維人臉資料
庫，藉由使用 FRGC 資料庫與遵守其評估協定
(evaluation protocol)，所得到的實驗結果可以直接
與其他研究團隊的實驗結果做比較。其有效地協助
我們驗證與測試所發展的三維人臉辨識系統。
12
on, vol. 14, pp. 239-256, 1992.
[2] K. I. Chang, K. W. Bowyer, and P. J. Flynn,
"Multiple Nose Region Matching for 3D Face
Recognition under Varying Facial Expression,"
Pattern Analysis and Machine Intelligence,
IEEE Transactions on, vol. 28, pp. 1695-1700,
2006.
[3] M. Ajmal, B. Mohammed, and O. Robyn, "An
Efficient Multimodal 2D-3D Hybrid Approach
to Automatic Face Recognition," 2007.
[4] X. Lu and A. K. Jain, "Deformation Modeling
for Robust 3D Face Matching," Proceedings of
the 2006 IEEE Computer Society Conference
on Computer Vision and Pattern
Recognition-Volume 2, pp. 1377-1383, 2006.
[5] G. Passalis, G. Toderici, M. N. Murtuza, Y. Lu,
N. Karampatziakis, and T. Theoharis,
"Three-Dimensional Face Recognition in the
Presence of Facial Expressions: An Annotated
Deformable Model Approach," IEEE
Transactions on Pattern Analysis and Machine
Intelligence, vol. 29, pp. 640-649, 2007.
[6] G. Passalis and T. Theoharis, "Intraclass
Retrieval of Nonrigid 3D Objects: Application
to Face Recognition," IEEE Transactions on
Pattern Analysis and Machine Intelligence, vol.
29, pp. 218-229, 2007.
[7] A. M. Bronstein, M. M. Bronstein, and R.
Kimmel, "Expression-invariant 3D face
recognition," Proc. Audio and Video-based
Biometric Person Authentication, pp. 62–69,
2003.
[8] M. Fels and P. J. Olver, “Moving coframes: I. a
practical algorithm,” Acta Applicandae
Mathematicae, vol. 51, no 2 pp. 161 – 213,
1998.
[9] W. Y. Lin, K. C. Wong, N. Boston, and Y. H.
Hu, "Fusion of Summation Invariants in 3D
Human Face Recognition," Proceedings of the
2006 IEEE Computer Society Conference on
Computer Vision and Pattern
Recognition-Volume 2, pp. 1369-1376, 2006.
[10] W.-Y. Lin, M.-Y. Chen, K. R. Widder, Y. H. Hu,
and N. Boston, "Fusion of Multiple Facial
Regions for Expression-Invariant Face
Recognition," IEEE International Workshop on
Multimedia Signal Processing, 2007.
[11] W.-Y. Lin, K.-C. Wong, N. Boston, and Y. H.
Hu, "3D Face Recognition Under Expression
Variations Using Similarity Metrics
Fusion," IEEE International Conference on
Multimedia & Expo, pp. 727-730, 2007.
[12] K.-C. Wong, W.-Y. Lin, Y. H. Hu, N. Boston,
and X. Zhang, "Optimal Linear Combination of
Facial Regions for Improving Identification
Performance," IEEE Trans. Systems, Man, and
Cybernetics, Part B: Cybernetics, vol. 37, no. 5,
pp. 1138-1148, 2007.
