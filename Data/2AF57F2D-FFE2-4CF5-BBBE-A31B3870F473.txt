 串連式訊源/通道編碼系統其植基於格狀結構之 
整合式訊源/通道軟性決定循序解碼演算法 
Trellis-Based Joint Source-Channel  
Soft-Decision Sequential Decoding Algorithms  
for Serially Concatenated Source-Channel Coding Systems 
計畫編號：NSC 97-2221-E-260 -014 
執行期限：97 年 8 月 1 日至 98 年 7 月 31 日 
計畫主持人：黃育銘   國立暨南國際大學資訊工程學系助理教授 
Email : ymhuang@csie.ncnu.edu.tw
摘要 
資料通常會藉由變動長度碼、可逆式變動長度碼、變動長度錯誤更正碼、或算術碼進
行訊源編碼（source coding）以降低其龐大資料量。接者，對於壓縮過的資料可以再加入
一些多餘訊息，即所謂通道編碼（channel coding），藉以更進一步保護壓縮過的資料。
文獻上之整合式訊源/通道解碼(Joint Source-Channel Decoding, JSCD)技術可歸納成下
列三類。 
第一類為在訊源解碼步驟裏，直接利用訊源編碼後所殘留之剩餘資訊
（residualredundancy），不需額外通道編碼，對於這類解碼器來說，這些剩餘資訊宛如
一弱通道碼，因此可同時擁有解壓縮及部份錯誤更正能力。格狀結構之Vitervi 方法為一
最佳解，而樹狀結構之循序演算法僅是次佳解，但解碼複雜度低許多。第二類為在通道解
碼步驟裏，對於串連式訊源/通道編碼系統執行整合式訊源/通道解碼。Murad 及Fuja 利用
訊源端各種資訊及格狀結構之Vitervi 演算法進行精確MAP 解碼，但是當資料很多時，其
解碼複雜度會變得相當高，而讓這個方法顯得不實用。不像第一類解碼技巧，其可視作僅
有單一解碼器，也就是訊源解碼器及通道解碼器整合在一起。 
第三類利用Turbo 原理，在兩個解碼器間遞迴地進行交替解碼以達到最低解碼錯誤率，
但是解碼複雜度高許多。。 
本計畫裏，擬植基於我們最近所提出之整合式訊源/通道軟性決定循序解碼演算法 (其
為格狀結構下之循序演算法，為一最佳解)，其屬於第一類解碼技術，繼續延伸至第二類之
串連式訊源/通道編碼系統，並考量訊源端及通道之各種可用資訊，針對串連式訊源/通道
編碼系統，進行最佳之整合式訊源/通道解碼。 
 
關鍵詞：變動長度碼、可逆式變動長度碼、變動長度錯誤更正碼、算術碼、整合式訊源/通
道解碼 
 
一、 計畫緣由與目的 
 
霍夫曼碼（Huffman code）及算術碼（Arithmetic code）是兩種廣範地被採用之訊息編
碼（Entropy coding）技術。 
z 霍夫曼碼：許多圖像或視訊壓縮標準，例如：JPEG、 MPEG-1、MPEG-2、H.263++ 等，
都採用這類變動長度碼（ Variable Length Code，VLC）技術。 
z 算術碼：JPEG2000 及 MPEG4 壓縮標準採用。 
然而無論採用霍夫曼碼或算術碼編碼後之位元串流（bit-stream），當傳輸通道有雜訊
時，相當不具有抗錯（error-resilient）能力，也就是說，在傳送的位元串流中，僅僅只有一
個位元發生錯誤，對解碼器來說，就足以造成一連串的解碼錯誤，此現象即所謂錯誤蔓延
（error-propagation）。 
接者，為解決這個問題，通常對於壓縮過的資料會反過來加入一些多餘訊息
（redundancy），即所謂通道編碼（channel coding），藉以保護壓縮過的資料。 
上述作法，通常採用 Shannon [1] 的分離理論（separate theory）方式，也就是訊源編
碼與通道編碼獨自設計，理論上整體系統效能不減，不過，這只適用於訊源編碼及通道編
碼都是最佳時方成立(也就是訊源編碼能除去訊源之所有 redundancy 作最佳壓縮，而通道編
碼能更正所有通道錯誤)。但是，資料的特性往往相當複雜，redundancy 不容易地被單一壓
縮技術就能完全消除，往往仍保有一些資料彼此相關的訊息，且對各種通道，有不同的通
道特性，因此要找出最佳的通道編碼方式也實屬不易。所以，訊源編碼與通道編碼獨自設
計，其整體系統複雜度不見得比較低且效能也未必佳[2]，因此，存在訊源間彼此的相關性
在未被壓縮技術完全消除情況下，如何整合訊源及通道編碼這兩種技術將是一個非常具有
挑戰性及相當豐富的研究題材。 
Guillemot and Christ [3] 在他們的文章(Joint source-channel coding as an element of QoS 
framework for ‘4G’ wireless multimedia)裏，詳細指出整合訊源 / 通道編碼（ Joint 
Source/Channel Coding (JSCC)） 技術為未來在 4G 無線通道裏傳送多煤體資訊，例如：
MPEG4 視訊等，其重要核心技術之一。 
 (soft-decision sequential decoding)演算法，實驗數據顯示，增加維度後，效能確實提
升，而且複雜度也比沒有增加維度使用 VA 的還要低。 
 
三、 計畫成果自評 
本計畫相關研究成果如下： 
1. 吳威怡,” Bit- and Trellis- Based Joint Huffman and Convolutional Sequential Decoding 
Algorithms,” 暨大資工所碩士論文, Jul. 2008. 
2. 蔡承廷,＂Trellis-Based Iterative Sequential Decoding of Error-Correcting Binary Arithmetic 
Codes,” 暨大資工所碩士論文, Jul. 2009. 
3. 陳漢隆,＂ A Study of Low-complexity Tree-Based Sequential Decoding of Error-Correcting 
Binary Arithmetic Codes,” 暨大資工所碩士論文, Jul. 2009. 
4. Yuh-Ming Huang and Yunghsiang S. Han, “Trellis-Based Joint Huffman and Convolutional 
Soft-Decision Priority-First Decoding,” in Proc. IEEE Data Compression Conference, 
Snowbird, UT USA, Mar. 25-27, 2008. 
5. Yuh-Ming Huang, Yunghsiang S. Han, and Ting-Yi Wu, “Soft-Decision Priority-First 
Decoding Algorithms for Variable-Length Error-Correcting Codes,” IEEE Communications 
Letters, vol. 12, no. 8, pp. 572-574, Aug. 2008. 
6. Yuh-Ming Huang, Yunghsiang S. Han, and Chien-Feng Lo, “Bit- and Trellis- Based 
Soft-Decision Sequential Decoding for Variable-Length Error-Correcting Codes,” in Proc. 
IEEE Asia-Pacific Conference on Communications, Akihabara, Tokyo Japan , Oct. 14-16, 
2008.  
7. Yuh-Ming Huang, Ting-Yi Wu, and Yunghsiang S. Han, “An A*-based Algorithms for 
Constructing Reversible Variable Length Codes with Minimum Average Codeword Length,” 
IEEE Trans. on Communication, in revision, 2009. 
 
四、 參考文獻 
[1] J C.E. Shannon, “A mathematical theory of communication,” Bell Syst. Tech. J., vol. 27, pt. I, pp. 379-423, 
1948; pt. II, pp. 623-656, 1948. 
[2] J. L. Massey, “Joint source and channel coding,” in Communication System and Random Process Theory, 
NATO Advanced Studies Institutes Series E25, pp. 279-293. Sijthoff & Noordhoff, Alphen aan den Rijn, The 
Netherlands, 1978. 
[3] J. C. Guillemot and P. Christ, “Joint source-channel coding as an element of QoS framework for ｀4G＇
wireless multimedia,＂Computer Communication, vol. 27, pp. 762-779, 2004. 
[4] H. W. Tseng and C. C. Chang, “A branch-and-bound algorithm for construction of reversible variable length 
codes, ”Computer Journal, vol. 47, no. 6, pp. 701-707, 2004. 
[5] C.-W. Lin, J.-L. Wu, and Y.-J. Chuang, “Two algorithms for constructing efficient huffman-code based 
reversible variablelength codes,” IEEE Trans. Commun., vol. 56, no. 1, pp. 81–89, Jan. 2008. 
[6] V. Buttigieg and R. Deguara, “Using variable-length error-correcting codes in MPEG-4 video,” Proc. 
International Symposium on Information Theory, pp. 2379–2383, Sep. 2005. 
[7] K. Lakovic and J. Villasenor, “On design of error-correcting reversible variable length codes,” IEEE Commun. 
Letters, vol. 6, no. 8, pp. 337–339, Jan. 2002. 
[8] M. Bystrom and A. Kopansky, “Soft source decoding with applications,” IEEE Trans. on Citcuits and Systems 
for Video Technology, vol. 11, pp. 1108–1120, Oct. 2001. 
[9] Y.-M. Huang, Y. S. Han, and T.-Y. Wu, “Soft-decision priority-first decoding algorithms for variable-length 
error-correctingcodes,” IEEE Communications Letters, pp. 572–574, Aug. 2008. 
[10] S. Ben-Jamaa, C. Weidmann, and M. Kieffer, “Analytical Tools for Optimizing the Error Correction 
Performance of Arithmetic Codes,” IEEE Trans. Comm. Vol. 56, no. 9, Sep. 2008. 
2be used by the decoder to provide the error correction
capability of the RVLC.
An RVLC is an affix-free code where no codeword in
it is a prefix or a suffix of any other codeword. Hence,
an RVLC encoded bitstream can be instantaneously
decoded no matter in forward or backward direction.
RVLCs can be divided into two categories: symmetric
and asymmetric. A symmetrical RVLC has an additional
constraint that both bitstreams respectively obtained by
parsing a codeword in forward and backward directions
are the same. In contrast, an asymmetrical RVLC doesn’t
have such property. Due to this constraint, it is easier to
construct a symmetrical RVLC rather than an asymmetri-
cal RVLC. As expected, an asymmetrical RVLC always
provides better coding efficiency than the symmetrical
one does since codeword selection can be more flexible
in the process of constructing an asymmetrical RVLC.
The design of construction algorithms for RVLCs
usually follows two methodologies. One aims at con-
structing a RVLC with its average codeword length as
close to that of the Huffman code (with the best coding
efficiency) as possible. Another is to decrease the size
of a search tree for easily locating a solution.1
Based on a given Huffman code and its codeword
length distribution, Takishima et al. [1] first specified
how to construct both asymmetrical and symmetrical
RVLCs. Later, Tsai et al. [2], [3] improved the meth-
ods given in [1] by using heuristic codeword selection
mechanisms. In [4], [5], and [6], further improvement
were proposed. Basically, there is a tradeoff between the
coding efficiency and the time-complexity of the above
algorithms [3] [4] [6]. Among them, the search tree in [4]
is the largest. In fact, one can easily see that the search
1In Section II, we’ll convert the problem of constructing a RVLC
into a tree-searching problem.
trees in [3] and [6] are subsets of that in [4] if each of
the above algorithms is illustrated by its corresponding
search tree. Hence, the search results given in [4] will
always be the best since it has the largest search space.
As for both search trees in [3] and [6], since each one
is not contained in the other, the search results given
in [6] are not always better while compared with those
given in [3]. For a given source, the codeword length
distribution of an optimal RVLC is unknown and the
codeword length distributions of all Huffman-equivalent
codes may not be all the same. Hence, the search results
of construction algorithms based on a fixed codeword
length distribution are always sub-optimal.
Instead of utilizing the fixed codeword length distribu-
tion of a given Huffman code, Tseng et al. [7] proposed
a new approach for constructing symmetrical RVLCs
by employing backtracking technique. Later, Lin et
al. [8] proposed two backtracking-based construction
algorithms for asymmetrical RVLCs, which improved
the results of [3] with either smaller average codeword
lengths or shorter maximum codeword lengths. In 2004,
Tseng et al. [9] again modified their proposed algorithm
in [7] to construct asymmetrical RVLCs with better
coding efficiency. However, some constructed codes
in [9] were still worse than those of the Huffman-
code-based algorithm [5] on coding efficiency. Based on
convex function, Jeong et al. [10] constructed RVLCs
with better coding efficiency compared with those given
in [8] and [5]; however, some asymmetrical RVLCs
constructed had larger average codeword length than
those in [9]. All of the above algorithms have a serious
drawback that different initial values must be assigned
heuristically according to the source statistics. Moreover,
none of the aforementioned methods is superior to others
in all search results.
We observed that none of the existing construction
October 31, 2009 DRAFT
4codeword “1” is selected. Once the binary tree T is
constructed, to find the desired Cˆ becomes a path-search
problem in T .
A∗ algorithm [15] is a very famous search algorithm
on a graph in artificial intelligence. In the graph, a cost
is associated with each branch and the algorithm finds a
shortest path from the starting node to a goal node with
minimum path cost, which is the accumulated branch
costs along the path. A heuristic function is imposed to
the cost of each path in the graph to reduce the search
space. The better heuristic function is used, the faster
the search performs. The cost of each path, also the cost
of each node in a tree, is composed with two parts: the
accumulated cost from the starting node to the ending
node of the path and the heuristic function that estimates
the cost from the ending node of the path to a goal node.
In Section III, an A∗ based algorithm for constructing
optimal RVLCs will be presented after the cost of each
node is specified. It will be proved that the proposed
algorithm always finds an optimal RVLC as the shortest
path has been found by A∗ algorithm.
Without loss of generality, the relationship between a
parent node and its two children nodes in T is illustrated
in Fig. 2, where the costs of nodes W , X and Y are
specified.2 Since our goal is to find an optimal RVLC
we need to specify the cost of each node in the binary
tree according to (1). By the construction of T , it is
easy to see that the branch cost assigned to each branch
should be pi × l(ci), if ci is selected in this branch, or
be 0, if no codeword is selected. Let m(W ) denote the
2Since we deal with a tree in our work, the ending node is used to
represent a path. Hence, the cost associated with the path is the same
as that with its ending node.
cost of node W and it can be defined as
m(W ) =
t∑
i=1
pi × l(ci)︸ ︷︷ ︸
g(W )
+
N∑
i=t+1
pi × l(αi−t)︸ ︷︷ ︸
h(W )
, (2)
where g(W ) denotes the accumulated branch cost from
the root of T (the starting node) to node W (i.e., the ac-
cumulated average codeword length over the codewords
ci’s with respect to their occurrence probabilities pi’s,
1 ≤ i ≤ t), and h(W ) denotes an estimate on the cost
of the path from node W to any goal (leaf) node. Note
that we design h(W ) as the average codeword length
over the N − t shortest codewords among all remaining
codewords which can be legally selected while traversing
any path starting from node W . Let h∗(W ) denote the
minimum cost among all possible paths from node W
to a goal node. It can be easily observed that
h(W ) ≤ h∗(W )
and
g(W ) + h(W ) ≤ g(W ) + h∗(W ). (3)
As shown in Fig. 2, node W is associated with two
lists, CW and AW . The children node X at left hand
side adds the first codeword α1 in AW into CW . Thus,
the codeword list is now
CX = CW ∪ {α1}
= {c1, c2, · · · , ct, α1}. (4)
Next, the candidate list AW is updated as
AX = {αˆ1, αˆ2, αˆ3, · · · } (5)
by removing all non affix-free codewords in AW with
October 31, 2009 DRAFT
6the algorithm stops and reports an optimal RVLC has
found. From the definition of the cost for a node, m(W )
is not only the cost of node W but also the average
codeword length of this RVLC. Since the costs of other
nodes are not less than m(W ) and, by Lemma 1, costs of
their successors are also no less than m(W ). Hence, any
further search in the tree will not result in a RVLC with
less minimum average codeword length. This concludes
that the proposed algorithm always finds an optimal
RVLC.
Next we present some properties of the proposed
algorithm that can be used to speed up the search
procedure. By Lemma 1, the cost along any path is
non-decreasing. Then any average codeword length of
an existing RVLC can be an upper bound on the cost
of an optimal path in the binary tree. This upper bound
can be used to reduce the size of stack since any newly
generated node with cost no less than this upper bound
can be eliminated from the stack.
A complement of a code (a set) is the code that
contains complements of all elements of this code (set).
It is easy to show that the complement of an RVLC is
still an RVLC with the same average codeword length.
Therefore, for each newly generated node X , one can
examine all nodes in the stack, which have the same cost
of X , to locate the node associated with X’s complement
code. If it does exist, X can be discarded since the
node associated with X’s complement code will generate
all complements of codes constructed after traversing
all paths starting from X . This will help to reduce
the size of the stack. Before we present next speed-up
technology we first give an example to demonstrate the
search procedure.
Example 1: Consider a set of four independent source
symbols {s1, s2, s3, s4} with respective occurrence prob-
abilities {p1, p2, p3, p4} = {0.68, 0.13, 0.11, 0.08}. The
search tree and the stack contents in Example 1 are re-
spectively shown in Fig. 3 and Fig. 4. Initially, the stack
has only one node 0 with cost m(0) = 1.19 (g(0) = 0
and h(0) = 0.68× 1+0.13× 1+0.11× 2+0.08× 2 =
1.19). In round 1, we pop out node 0 from the stack.
Two children nodes (node 1 and node 2) of node 0 are
generated with m(1) = 1.27 (g(1) = 0.68 × 1 = 0.68,
h(1) = 0.13 × 1 + 0.11 × 2 + 0.08 × 3 = 0.59) and
m(2) = 1.32 (g(2) = 0, h(2) = 0.68 × 1 + 0.13 × 2 +
0.11× 2 + 0.08× 2 = 1.32). They then are pushed into
the stack in the order of ascending cost values. In round
2, node 1 is popped out from the stack and only its child
at right hand side (node 4) with m(4) = 1.51 (g(4) =
0.68× 1, h(4) = 0.13× 2+0.11× 3+0.08× 3 = 0.83)
is generated and inserted into the stack. Since the size of
C3 is less than 4 and the list A3 becomes empty, so we
discard node 3. In round 3, node 2 is popped out from
the stack and only its child at right hand side (node 6)
with m(6) = 2 (g(6) = 0, h(6) = 0.68 × 2 + 0.13 ×
2 + 0.11 × 2 + 0.08× 2 = 2) is generated and inserted
into the stack. Since C5(= {1}) is complemented with
the list C4(= {0}) kept by node 4 in the current stack,3
we discard node 5. In round 4, we pop out node 4 from
the stack, and then generate its two children (node 7 and
node 8) with m(7) = 1.59 (g(7) = 0.68 × 1 + 0.13 ×
2 = 0.94, h(7) = 0.11 × 3 + 0.08 × 4 = 0.65) and
m(8) = 1.72 (g(8) = 0.68 × 1 = 0.68, h(8) = 0.13 ×
3+0.11×3+0.08×4 = 1.04). Since C7∪{101, 1001} is a
valid RVLC, an RVLC {0, 11, 101, 1001} with minimum
average codeword length is obtained immediately after
3Suppose node V is the first node visited such that CV is comple-
mented with CX during the searching process. Since m(X)=m(V )
and m(W ) ≤ m(X) (by Lemma 1), we have m(W ) ≤ m(V ).
Therefore, the right child of node V with its codeword list comple-
mented with CX must be still in the current stack before popping node
W .
October 31, 2009 DRAFT
8in the corresponding search tree are far closer to each
other than those in constructing a symmetrical RVLC.
Hence, for a given source, it is harder to find an optimal
asymmetrical RVLC than finding an optimal symmetrical
RVLC because the number of searches performed by
our proposed algorithm increases drastically when N is
large.
The codewords and the average codeword lengths of
asymmetrical RVLCs for the English alphabet found
by the algorithm of Tseng et al. [9] and our proposed
algorithm are given in Table ??. Table ?? shows that
our algorithm can find an optimal asymmetrical RVLC
with minimum average codeword length but the algo-
rithm of [9] did not. Note that the average codeword
length of the asymmetrical RVLC found by our proposed
algorithm is very close to that of the Huffman code.
The number of codewords and the average codeword
lengths of asymmetrical RVLCs for the Canterbury Cor-
pus file set found by the algorithm of Tseng et al. [9]
and our proposed algorithm are given in Table V. We
also add the results found in [5] since there is a better
code found by the algorithm of [5] than that by the
algorithm of [9]. As given in Table V, all asymmetrical
RVLCs constructed by our proposed algorithm are better
than those constructed by the algorithms of [9] and [5].
Since algorithms of [9] and [5] are suboptimal, they
failed to find optimal asymmetrical RVLCs for all test
files. Unlike in constructing the symmetrical RVLCs, our
proposed algorithm has great achievement in lowering
the average codeword length for asymmetrical RVLCs.
Moreover, we can find the optimal asymmetrical RVLC
for the “ptt5” file in a limited time, whereas it needs
about 1018 years to even just find out a sub-optimal
asymmetrical RVLC by using the algorithm of [4]. This
analysis was shown in the Table III of [6]. Table VI lists
the codeword length vectors and the maximum codeword
lengths of the Huffman code and the symmetrical RVLCs
constructed by the proposed algorithm and that of [9]. It
can be observed that the asymmetrical RVLCs found by
our proposed algorithm have different codeword length
vectors from those found in [9] since our proposed
algorithm has found optimal asymmetrical RVLCs but
that of [9] did not.
Our proposed algorithm has not been able to find
optimal asymmetrical RVLCs for “cp.html”, “field.c”,
“sum”, and “kennedy.xls.” Since the probability distribu-
tion of codewords in each file is peculiar, the correspond-
ing optimal asymmetrical RVLCS can not be obtained
successfully in a limited time.
V. CONCLUSIONS AND FUTURE WORK
Based on the concepts of A∗ algorithm, an unified
approach for constructing the symmetrical RVLCs and
the asymmetrical RVLCs with minimum average code-
word length is presented. Optimal asymmetrical RVLCs,
which could not be found in the past, are constructed
systematically in a limited time. The construction of
an optimal RVLC is still an open issue since there
is no available polynomial-time algorithm for it [18].
Even though our proposed algorithm is still exponential
in worse case, it has been successfully found optimal
asymmetrical RVLCs for all benchmarks except for four
test files. How to further improve the search speed of our
proposed algorithm is certainly one of our future work.
There are still many interesting researches about
RVLCs, such as balance of 0/1 bits [19], free dis-
tance [11], error detection/synchronization [20], and er-
ror resiliency measure [21]. Therefore, instead of only
considering coding efficiency, in the future, we expect
to find more efficient RVLCs in regard to possessing
additional features of higher balance in 0/1 bits, larger
free distance, or stronger synchronization capability.
October 31, 2009 DRAFT
10
Fig. 1. The binary tree T to represent all asymmetrical RVLCs for
N = 3. ¥ presents a leaf in T .
Fig. 2. The relationship between one parent node and its two children
nodes in T .
TABLE I
HUFFMAN CODE AND SYMMETRICAL RVLCS CONSTRUCTED BY
THE PROPOSED ALGORITHM AND THAT OF [7] FOR THE ENGLISH
ALPHABET.
Alphabet Probability Huffman [17] Tseng et al. [7] Ours
E 0.14878570 001 000 000
T 0.09354149 110 010 010
A 0.08833733 0000 101 101
O 0.07245769 0100 111 111
R 0.06872164 0110 0110 0110
N 0.06498532 1000 1001 1001
H 0.05831331 1010 00100 00100
I 0.05644515 1110 01110 01110
S 0.05537763 0101 10001 10001
D 0.04376834 00010 11011 11011
L 0.04123298 10110 001100 001100
U 0.02762209 10010 011110 011110
P 0.02575393 11110 100001 100001
F 0.02455297 01111 110011 110011
M 0.02361889 10111 0010100 0010100
C 0.02081665 11111 0011100 0011100
W 0.01868161 000111 0111110 0111110
G 0.01521216 011100 1000001 1000001
Y 0.01521216 100110 1100011 1100011
B 0.01267680 011101 1101011 1101011
V 0.01160928 100111 00111100 00111100
K 0.00867360 0001100 01111110 01111110
X 0.00146784 00011011 10000001 10000001
J 0.00080064 000110101 11000011 11000011
Q 0.00080064 0001101001 011111110 001010100
Z 0.00053376 0001101000 100000001 001101100
Average codeword length 4.15572284 4.46463681 4.46463681
October 31, 2009 DRAFT
12
TABLE II
HUFFMAN CODE AND SYMMETRICAL RVLCS CONSTRUCTED BY THE PROPOSED ALGORITHM AND THAT OF [7] FOR THE CANTERBURY
CORPUS FILE SET.
Huffman [17] Tseng et al. [7] Ours
File Number of codewords Average codeword length
asyoulik.txt 68 4.84464646 5.21025119 5.21025119
alice29.txt 74 4.61244402 4.93155363 4.93155363
xargs.l 74 4.92382304 5.33995697 5.33995697
grammar.lsp 76 4.66433754 5.01773571 5.01773571
plrabn12.txt 81 4.57524019 4.89526695 4.89526695
lcet10.txt 84 4.6971159 5.01682473 5.01682473
cp.html 86 5.26716254 5.81172993 5.81172993
fields.c 90 5.04089686 5.46331826 5.46331826
ptt5 159 1.66091275 1.75991768 1.75991768
sum 255 5.36503661 6.03917365 6.03917365
kennedy.xls 256 3.59337466 4.27209103 4.21507667
TABLE III
THE MAXIMUM CODEWORD LENGTHS (MAX.) AND THE CODEWORD LENGTH VECTORS OF HUFFMAN CODE AND THE SYMMETRICAL
RVLCS CONSTRUCTED BY THE PROPOSED ALGORITHM AND THAT OF [7] FOR THE CANTERBURY CORPUS FILE SET.
File Algorithm Max. Codeword length vector
asyoulik.txt Huffman [17] 15 (0,0,1,6,8,7,11,8,5,11,5,1,0,3,2)
(68 codewords) Tseng et al. [7] 12 (0,0,3,2,5,5,7,6,10,9,16,5)
Ours 12 (0,0,3,2,5,5,7,6,10,9,16,5)
alice29.txt Huffman [17] 16 (0,1,0,4,9,8,6,5,4,13,12,3,0,1,4,4)
(74 codewords) Tseng et al. [7] 12 (0,0,3,2,5,5,7,6,10,9,16,11)
Ours 12 (0,0,3,2,5,5,7,6,10,9,16,11)
xargs.l Huffman [17] 12 (0,0,1,6,9,6,8,9,6,8,11,10)
(74 codewords) Tseng et al. [7] 12 (0,0,3,2,5,5,7,6,10,9,16,11)
Ours 12 (0,0,3,2,5,5,7,6,10,9,16,11)
grammar.lsp Huffman [17] 12 (0,1,0,4,8,8,8,8,5,15,9,10)
(76 codewords) Tseng et al. [7] 12 (0,1,1,2,5,5,6,7,9,10,15,15)
Ours 12 (0,1,1,2,5,5,6,7,9,10,15,15)
plrabn12.txt Huffman [17] 19 (0,0,2,7,3,9,4,4,7,14,5,2,6,1,1,7,4,3,2)
(81 codewords) Tseng et al. [7] 14 (0,0,4,2,4,4,6,4,8,6,12,8,18,5)
Ours 14 (0,0,4,2,4,4,6,4,8,6,12,8,18,5)
lcet10.txt Huffman [17] 16 (0,0,1,8,4,9,5,7,12,13,10,6,2,3,0,4)
(84 codewords) Tseng et al. [7] 13 (0,0,3,3,4,4,7,5,10,8,15,11,14)
Ours 13 (0,0,3,3,4,4,7,5,10,8,15,11,14)
cp.html Huffman [17] 14 (0,0,0,6,12,8,5,11,13,13,6,5,5,2)
(86 codewords) Tseng et al. [7] 12 (0,0,2,2,6,6,8,8,12,12,20,10)
Ours 12 (0,0,2,2,6,6,8,8,12,12,20,10)
fields.c Huffman [17] 13 (0,1,0,3,7,11,7,17,16,17,3,4,4)
(90 codewords) Tseng et al. [7] 12 (0,0,2,2,6,6,8,8,12,12,20,14)
Ours 12 (0,0,2,2,6,6,8,8,12,12,20,14)
ptt5 Huffman [17] 17 (1,0,0,1,2,14,11,9,9,7,10,9,13,20,16,11,26)
(159 codewords) Tseng et al. [7] 16 (1,0,0,2,3,3,5,5,8,8,13,12,22,23,41,13)
Ours 16 (1,0,0,2,3,3,5,5,8,8,13,12,22,23,41,13)
sum Huffman [17] 14 (0,1,0,0,3,20,16,24,25,45,30,56,29,6)
(255 codewords) Tseng et al. [7] 15 (0,1,0,1,5,5,9,10,15,14,26,24,44,43,58)
Ours 15 (0,1,0,1,5,5,9,10,15,14,26,24,44,43,58)
kennedy.xls Huffman [17] 12 (1,0,1,3,1,0,0,1,1,74,146,28)
(256 codewords) Tseng et al. [7] 17 (1,0,1,0,3,1,1,4,8,8,17,16,31,29,59,56,21)
Ours 17 (1,0,1,2,1,1,1,3,7,7,13,13,23,22,43,41,77)
October 31, 2009 DRAFT
表 Y04 
行政院國家科學委員會補助國內專家學者出席國際學術會議報告 
                                                          98 年  10 月 31 日 
報告人姓名  黃育銘 
 
服務機構
及職稱 
 
暨南國暨大學資訊工程學系 
 
     時間 
會議     
地點 
 98.6.28 – 98.7.3 
韓國首爾 
本會核定
補助文號
 
計畫編號: NSC 97-2221-E-260 -014 
會議 
名稱 
 (中文)  
 (英文) International Symposium on Information Theory (ISIT2009) 
 
發表 
論文 
題目 
 (中文)  
 (英文)  
表 Y04 
舉凡資訊科學、物理、及數學上的一些現象均可用 Entropy function 來描述。其研
究領域含括： 
z Probability theory 
z Network Coding 
z Combinatorics、 
z Group theory、 
z Kolmogorov complexity、 
z Matrix theory、 
z Quantum mechanics。 
    演講者對 Entropy function 的性質作了精闢的解說。 
 
以下列出我所聆聽之論文主題： 
 
Ｍonday, June 29 
 
SESSION MA1-4 ：Combinatorial Properties of LDPC Codes I 
SESSION MA2-4 ：Combinatorial Properties of LDPC Codes II 
SESSION MP1-4 ：LDPC Decoding I 
SESSION MP2-4 ：Analysis of LDPC Codes I 
 
Tuesday, June 30 
 
SESSION TA1-3 ：Universal Compression 
SESSION TA2-4 ：Turbo Codes 
SESSION TP1-3 ：Coding with Side Information 
SESSION TP2-3 ：Distributed Source Coding 
 
Wednesday, July 1 
 
SESSION WA1-4 ：Sequential Methods 
SESSION WA2-3 ：Losy Distributed Source Coding 
 
Thursday, July 2 
 
SESSION RA1-4 ：LDPC Decoding II 
SESSION RA2-4 ：Analysis of LDPC Codes II 
SESSION RP1-4 ：LDPC Code Design 
SESSION RP2-3 ：Source-Channel Coding 
 
 
 
 
 
 
 
 
 
 
 
 
 
                                                            
