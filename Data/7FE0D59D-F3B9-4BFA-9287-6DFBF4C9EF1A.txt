2perspective photo mapping
procedure is taken to map
corresponding pixel to the 3D
mesh。
The results of this research
show success in automating the
texturing procedures of a fine
detail mesh model. High degree of
texturing precision on the model
has been observed. This research
directly reduce human interaction
and increase the productivity of
digital recovery effort。 Not only
does it increase the value of
digital reconstruction industry,
but also prove the effectiveness of
iterative least square fit theory
on texture mapping。
Keywords: 3D object reconstruction,
perspective photo mapping, 3D mesh,
collinear texture mapping, texture,
least square fit, texture
calibration
前言
快速和正確的重建3D人造物體或
3D 立體城市的技術對於許多使用者和
供應商是很重要的，包括都市的規劃
者、建築師、媒體傳播者和環境工程
師。重建全彩模型在虛擬應用上更是
重要，像是虛擬博物館，電玩的發展
等。
對於3D立體物的全彩未知模型的
重建一般採用兩種工作流程。 第一種
是使用非接觸式或接觸式之距離感測
器如 CMM 三度座標量床(針對小型物
體)，及雷射雷達(LIDAR)(針對大型物
體)長程雷射掃描器來獲得 3D 立體尺
寸範圍資料。這些點雲資料再經由整
合程式轉換成一連續之三維網格體
[1~6,9]。接下來程序是將被掃描過的
3D 立體網格模型置入表面材質。一般
於這個階段採用間接 uv 人工對映程
序。另一種工作流程為照相測量
(photogrammetry)塑模程序。若要使
這些細節出現，需要針對目的特徵
區，進行費時費力的取景及標記處
理。所以 photogrammetry 並不適合將
模型細部自動上色敷貼。但從另一角
度看，此一軟體提供了利用控制點進
行將相片對位之方法。只要將重覆出
現在兩張以上相片之控制點加以對
應，即可求出該相片之外方位。此一
特性正好是自動上色敷貼所需。本研
究提出以線性映射方式將任一給定以
三角網格呈現之 CAD 模型加以校正，
使其與適當角度拍攝之相片共屬同一
座標系，進而可以將相素之資訊正確
且自動的應對至模型表面。最後使模
型之細節也可有全彩之呈現。
實驗研究方法
此研究並提出地面光達與數位影像資
料的結合方式，根據物空間與影像空
間座標系統轉換關係，結合兩種不同
類型儀器所取得的資料，以 Pixel－
Based 方式進行場景材質敷貼，並配合
點雲資料結合成果，完成成功大學總
圖書館的場景建置。
雖然此研究對點雲資料進行了高
精度之結合與分析，與數位影像資料
的結合，例如影像上之控制點點選卻
還是以人工的方式進行，如此應會造
成外方位計算誤差，最後影響線性對
應品質。此一色差的現象在物體邊界
上尤為明顯。雷射點雲掃瞄之另一缺
4對應關係，以利下一步驟建立轉換矩
陣之用。在此使用 ICP[10]或最小平方
差(least mean square fit)合併 1.2
座標。求取影像之外方位轉換矩陣，
可選擇將影像空間轉至實物空間，或
將實物空間轉至影像空間。此一轉換
關係為基本之齊次矩陣，現解釋如下:




10
TR
H 式(1)
T =










z
y
x
t
t
t
式(2)
R(  ,, )= 


 
zyx nnn ,, 式(3)
 Txn  sincossincoscos 

式(4)
 Tyn  sincoscoscossinsinsincossinsinsincos 

 Txn  coscossincoscossinsinsinsincossincos 

Plocal=HPworld;
式(5)
P(Xw，Yw，Zw)為空間中一點，現有
一區域座標(local coordinate
system)其原點設於 O，其區域座標軸
為 Xlocal，Ylocal及 Zlocal，此一區域座標系
統可用一轉換矩陣來描述，即 o之平
行移動(tx，ty，tz)，及 Zlocal相對於原
座標 Z軸之旋轉角(α，β，γ)，以
此 6個變量可形成一線合旋轉及平移
矩陣 H，如式一所示。式二為平行移動
矩陣， 式三為旋轉矩陣，利用此一綜
合矩陣可將全域座標轉成區域座標，
如式五所示。ICP 法為針對此 6個變量
使用非線性最佳化，找出一組合，使
得 Plocal與 Pworld之多點平方差之和為最
小，另一最小平方差法計算至少九個
對應點對間之距離最小平方差之合，
以最小二乘理論求解此九參數之轉換
矩陣，如式 6.

























11
w
w
w
z
y
x
H
z
y
x
;



































nnnnnn zwywxw
zwywxw
zwywxw
aaa
aaa
aaa
zyx
zyx
zyx
...
987
654
321
...
222
111
222
111
;
A =












nnn zyx
zyx
zyx
...
222
111
; X=










987
654
321
aaa
aaa
aaa
;
W=












nnn zwywxw
zwywxw
zwywxw
...
222
111
n 為控制點個數。
X即為外方位轉換矩陣可以最小平方
6結果與討論
本研究目的為將一給定之三維網
格模形，自動敷貼實物之影像材質。
第一先將實物進行初步雛形拍攝，建
立一影像座標系統，此一影像座標系
統主要是涵蓋實物上預選之控制點，
結合photogrammetry中之自動建立三
維影像座標系之能力(stereo vision)
建立這些控制點之三維座標。Fig. 1
右圖為經由Photomodeler建立之雛形
建築物模型。
第二為實物控制點三維座標（使
用雷射或 CAD 模型座標）與影像控制
點對應關係建立。Fig.1 顯示此一二
維影像控制點與三維實物控制點對應
關係建立之圖形介面。Fig.1 之左圖為
二維影像，右圖為三維實物雛形建築
物模型。Fig.1 之左圖中之紅點即為使
用者點選之平面控制點。Fig.1 之右圖
中之白點即為對應之三維控制點。
3.合併 1.2 座標。求取相機之外方位
轉換矩陣。Fig.1 之右圖中之相機圖示
即為經計算外方位轉換矩陣後之實際
相機外方位呈現。1,2,3 皆以
Photomodeler 軟體之圖形介面設計。
4.給定一 CAD 三維網格模型，利用共
線原理求取網格對映像素資料。此一
步驟首先需淬取平面控制點及三維控
制點座標以進行式(7)之計算。Fig.2
為一以 Matlab 設計之圖形介面，以
DDE(Dynamic Data Exchange)與
Photomodeler 進行溝通，自動截取所
需之平面控制點及三維控制點座標及
相機之外方位。Fig.3 為一使用相差雷
射密集掃描部分建物之三維網格模
型。Fig.4 為將此模型與 Fig.1 右圖之
三維實物雛形建築物模型進行整合比
對後之成果。從此圖可見二模型座標
系統完全密合。在步驟 3所計算之相
機外方位因此可用來利用共線原理計
算求取雷射細部網格對映像素資料。
Fig.5為將Fig.3之三維網格模型利用
步驟 3之原理將三維網格模型先轉換
為像片座標，接著以步驟 4之原理轉
換為以 pixel 為單位之二維影像座
標。從此圖可看見二維網格與對應之
影像密合之程度。在影像上各大構面
之邊界可完全觀察到與二維網格吻合
程度。根據此對應關係，毎一細小網
格端點皆可有一相對之 pixel 位置。
接著將此 pixel 位置進行正規化
(normalize)，轉換成材質座標。即可
以一般之3D圖學引擎進行呈現三維實
物自動敷貼之影像。Fig. 6、7 即為以
DirectX9.0実作此細部三維實物自動
敷貼之成果。從此圖可看出敷貼之正
確性。每一 pixel 皆已被敷貼至適當
之位置。同時可跟隨三維模型由使用
者進行任意之旋轉展示。
結論
本研究成功將模型之細部進行自
動敷貼。減少大量人工。及可產生相
當近似實物之三維模型。而不須使用
繁複之Photogrammetry 人工程序操
作以描述細部色彩資訊。即可將模型
表面材質自動還原。採用此一技術之
另一優點為可以人為控制細化程度。
只要將需要之細化程度由CAD軟體控
制。產生相對應之三角網格。即可將
三維模型實物化。這些研究成果可以
直接減少人力參與數位重建的程度，
對提昇生產力及仿真的程度有直接的
衝擊，不只具有提昇數位產業產值之
潛力，有市場之價值，同時在學理上
亦可驗證迭代式最小均方差理論對色
8Fig.2 線性投影轉換矩陣程式介面
Fig.4 雛型與細部模型座標系統
整合
Fig. 5 細部模型網格線性投影與原影
像整合成果
Fig.1 互動式三維點選系統建構
Fig.3 細部雷射網格
