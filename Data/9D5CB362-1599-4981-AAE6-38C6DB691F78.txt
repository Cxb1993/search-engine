 1
Abstract 
In this project, we bring up an important issue that has not been discussed at 
present and should be solved in a Chinese to Taiwanese TTS system. There is no 
related research about the issue under our survey. Such important issue is the 
problems of multi-pronunciations and polysemy of a word in Taiwanese. That is to 
say, there will be more than one pronunciations and meanings of a word in 
Taiwanese. Such words includes “我們” (we), “你” (you), “我” (I), “他” (he) and 
“不” (NO or NOT). We think that to identify the correct pronunciations and 
meanings of such words is very important in a Chinese to Taiwanese TTS system. 
Thus, the comprehensibility and fluency of a Chinese to Taiwanese TTS system will 
be higher. 
We use language models (WU and WLDB) and confidence measure to solve the 
polysemy problem in Taiwanese. The experimental results show that our approaches 
are practicable. The results in these words, “我們” (we), “你” (you), “我” (I), “他” 
(he) and “不” (NO or NOT), are very well. 
 
Keywords: Chinese to Taiwanese TTS system, polysemy, language models and  
confidence measure. 
 3
驗與成果外，我們也將運用這個計畫提供之研究助理，針對台語一詞多音的語料
進行大量的標註工作，如此可以讓我們的實驗結果更精確。在本計畫中，我們也
將開發一套具親和力的台語一詞多音的標音工具，讓標音的工作更加順暢。 
 
 
3. 文獻探討及問題描述 
目前並無正式文獻提及有關台語一詞多音問題，對於台語一詞多音的解決
方 法 也 沒 有 相 關 探 討 。 我 們 可 以 將 這 個 問 題 看 成 是 word sense 
disambiguation(WSD)的問題，在解決 WSD 的問題上，已有諸多的文獻資料加以
探討，而其中又以1977年由 Yarowsky所提出的decision list classifier(DLC)
方法，在解決 WSD 問題上獲得最好的結果。我們可以將台語的一詞多音視為一個
WSD 問題，並利用 Yarowsky 提出之 DLC 來解決台語一詞多音，並看看 DLC 應用
於這個問題上的成效。 
Yarowsky 提出之 DLC 主要是由一些 evidences 來判斷多種 senses 的模型，
在 DLC 中，我們會先建立一些判斷的規則(稱為 rules 或 evidences)，如表一所
示。表一是一個判斷英文中 bass 這個詞意義的規則，在英文中 bass 這個詞代表
著二個意義，分別是一種魚類或是一種樂器，我們希望藉由透過 DLC 中的規則判
斷文句中 bass 所代表的含意。另外在表一中的 bass1即表示 bass 是一種魚類，
而bass2表示 bass是樂器；表中的logL即表示每個規則的log-likelihood，logL
越大則表示該規則越重要，越有決定性。而 logL 的計算公式如式(1)。 
)1))...(
)|(
)|(
((
2
1
i
i
evSP
evSPLogAbs  
    式(1)中的 evi為第 i 個規則，S1 和 S2 分別代表不同的二種 senses。 
表一、bass 在 decision list 的規則及意義 
logL evidences sense 
10.98 1. fish within window bass1 
10.92 2. striped bass bass1 
9.07 3. guitar within window bass2 
9.20 4. bass player bass2 
9.10 5. piano with window bass2 
    Yarowsky 的文獻提及最佳觀測的視窗(window)為前後 20 個詞，以(EX1)為
例，句中的 bass 可以套用第 1 條、第 4 條及第 5 條規則，然而因為第 1 條規則
的 logL 最大，所以 bass 在此會被視為一種魚類，但其實際意義應該為樂器。 
(Ex1) “The fish, eaten by the piano player and bass player, is from New Zealand.” 
 
相較於 WSD 和中文的多音字(破音字)，台語的一詞多音現象較多也較複雜，
同一個詞的不同發音也意謂著該詞在不同場合所代表的不同意義。我們發現在一
篇文章中，『我們』可能會代表二種意義，一個是文章中的『我們』包含了語者
和聽者;一個是文章中的『我們』不包含聽者。而前者的『我們』在台語中的唸
 5
『不』這個字在中文中的發音除了古文會發成『ㄈㄡˇ』外，其餘的發音不
外乎變調發音，如『不/ㄅㄨˋ/行』、『不/ㄅㄨˊ/要』等。但在台語上，『不』
的發音種類不僅較多且複雜，如(Ex6)~(Ex9)所示：  
 
(Ex6)『但是社會上的一般人並不/bo/容易看出它的重要性。』 
(Ex7)『不/m/知浪費了多少國家資源。』 
(Ex8)『讓人一時聯想不/mei/到他與機械的關係。』 
(Ex9)『華航使用之航空站交通已不/pu/如從前方便。』 
 
4. 研究方法 
4.1 標音工具的建立 
 
為了能加速實驗之進行及實驗之正確性，我們開發了一個中文轉台文一詞
多音的標音系統，這個標音系統可以將特定的詞進行台語發音的標記，並將結果
輸出到特定的資料庫中。圖一是我們的標音系統畫面圖。 
在標音系統中，我們除了將文章中需要被標注音處(系統畫面右上方)外，
也將目前標音情形作一及時更新的統計結果(系統畫面右下方)。 
 
圖一、中文轉台語一詞多音標音系統 
 
4.2 實驗語料的蒐集及建置 
 
我們使用中央研究院平衡語料庫 3.0(ASBC 3.0)為實驗的語料，ASBC 3.0
內的文句包含了斷詞的結果，是一個國內公認最完整的中文語料庫。我們將所有
含『我』、『你』、『他』、『不』等單字詞的所有文句抽出，利用 4.1 的標音工具以
人工方式將正確的台語發音標記出來，這些標記好的語料即是我們的實驗的測試
及訓練語料。而我們使用的訓練語料和測試語料的比例為 9：1。 
 7
International News 2242 326 14.5% 
Journey News 9273 181 1.9% 
Local News 6066 95 1.5% 
Entertainment News 3231 408 12.6% 
Scientific News 3520 100 2.8% 
Social News 4936 160 3.2% 
Sport News 2811 193 6.9% 
Stock News 8066 83 1.0% 
Total Number of 
News 
40145 1546
3.9% 
 
表八、『我們』一詞的測試語料和訓練語料 
 Frequency of  “ 我
們 ” with 
pronuncia-tion /lan/ 
Frequency of  “我
們 ” with 
pronuncia-tion 
/ghun/ 
Frequency of  “我
們 ” with 
pronuncia-tion /lan/ 
& /ghun/ 
Training data 640 1,916 2,556 
Testing data 160 479 639 
Token frequen-cy 
of  “我們” 
800 2,395 3,195 
 
4.3 WU 語言模型 
 
我們利用了語言模型的方法，來找出影響一詞多音詞的發音，透過了(2)及
(3)，我們從訓練語料中得到利用 UG 方法統計之關鍵詞及相關之出現機率資料
庫。 
)2(
)&(
)&(
)&(
)&(
)( L∑ ∑ ∑
∑
=
k
j
i
ij
kj
i
i
k
u
WpC
wpC
WpC
wpC
pS
L
)3(
)&(
)&(
)&(
)&(
)( L∑ ∑ ∑
∑
=
k
j
i
ij
kj
i
i
k
u
WpC
wpC
WpC
wpC
pS
R
 
在(1)中 )( pS
Lu
為某一輸入文句中被判斷一詞多音詞的左邊k個詞對於發音
為 p的總分數；(2)中 )( pS
Ru
為某一輸入文句中被判斷一詞多音詞的右邊 k個詞
對於發音為 p的總分數。Pj 為該詞共有 j種不同發音情形；∑
i
ij WpC )&( 為在發
音為 Pj 的所有詞 Wi 的出現總次數。我們透過了(1)和(2)去計算輸入中文文句中
要被判斷正確發音的詞的總分數( )( pS
Lu
+ )( pS
Ru
)，並以分數最高分之發音為預
測之發音。 
 
 9
確率提高，我們利用了 confidence measure 方式讓系統可以自動選取不同輸入
時應該以何種(WU 或 WLDB)方法之預測結果為最佳之結果。Confidence measure
如 Algorithm 1 和 Algorithm 2 所示： 
 
Algorithm 1: Find the confidence curve of using WU. 
Input:  The score of pronunciation of each training sample, named as Sui(/lan/) and Sui(/ghun/), 
where i=1,2,3, …, n, and n is the number of training samples.  
Output:  A function standing for confidence curve for the given Sui(/lan/) and Sui(/ghun/), 
i=1,2,3, …, n. 
Algorithm: 
    Step 1: Normalize Sui(/lan/) and Sui(/ghun/) for each training sample i by using the following 
formula:  
NSui(/lan/)=Sui(/lan/)/(Total number of words in training sample i) 
NSui(/ghun/)=Sui(/ghun/)/(Total number of words in training sample i) 
    Step 2: Let di=| NSui(/ghun/)- NSui(/lan/)| and let  D={d1, d2,…,dn}. Find the accuracy rate 
for each different interval using the following formula: 
PRk= Ck/Nk,  k=1, 2, …, 18. 
Here Ck is the number of correct conjecture of training sample i with (k-1)/18 ≦ di < 
(k+1)/18, and Nk is the number of training sample i with (k-1)/18 ≦ d i< (k+1)/18. 
Step 3:  Find a regression curve for PR1, PR2, …, PR18. Output the function of the 
regression curve. 
 
Algorithm 2: Find the confidence curve of using WLDB. 
Input: The score of pronunciation of each training sample, named as Sbi(/lan/) and Sbi(/ghun/), 
where i=1, 2, 3, …, n, and n is the number of training samples.  
Output: A function standing for the confidence curve for the given Sbi(/lan/) and Sbi(/ghun/), i=1, 
2, 3, …, n. 
Algorithm: 
    Step 1: Normalize Sbi(/lan/) and Sbi(/ghun/) for each training sample i by using the following 
formula.  
NSbi(/lan/)=Sbi(/lan/)/(Total number of words in training sample i)2 
NSbi(/ghun/)=Sbi(/ghun/)/(Total number of words in training sample i)2 
    Step 2: Let di=| NSbi(/ghun/)- NSbi(/lan/)| and let D={d1, d2,…,dn}. Find the accuracy rate for 
each different interval using the following formula: 
PRk= Ck/Nk, k=1, 2, …, 13. 
where Ck is the number of correct conjecture of training samples i with (k-1)/13 
≦di<(k+1)/13, and Nk is the number of training samples i with 
(k-1)/13≦di<(k+1)/13. 
 11
總計 2693/3893 69.18% 
 
  5.3 預測『我們』一詞多音的實驗結果 
我們使用了 4.2 提及的網路電子報當預測『我們』一詞多音的實驗語料，
也利用了 4.3 和 4.4 提及的 WU 和 WLDB 二種方法來預測『我們』的一詞多音，實
驗結果如表十三所示，從表十三的第二欄中，我們發現 WU 方法對於判斷/ghun/
非常有效，但判斷/lan/卻不是很好；反之，如表十三的第三欄所示，使用 WLDB
時，我們發現 WLDB 對於判斷/lan/的結果非常好，但判斷/ghun/卻沒有很好的正
確率。於是我們利用了 4.5 的信心度測量，將 WU 和 WLDB 二者方法合併，得到了
很好的預測結果(如表十三的第四欄所示)。 
 
表十三、預測『我們』的台語一詞多音之外部測試結果 
 Accuracy using WU Accuracy using WLDB Accuracy combing the two 
models 
/ghun/ 94.36% 69.5% 95% 
/lan/ 48.68% 93.31% 93.1% 
Total 81.69% 81.4% 93.6% 
 
  5.4 實驗比較 
我們使用了 Yarowsky 提出之 DLC 來預測台語的一詞多音，方法如 2.所描
述。實驗結果證實本計畫提出的方法預測結果比 DLC 來得好(參考表十四及表十
五)。 
表十四、實驗結果比較(一) 
一詞多音詞 UG 的正確
率 
比
較 
DLC 的正確
率 
不 69.18% > 55.80% 
我 90.04% > 78.11% 
你 92.79% > 75.23% 
他 91.89% > 82.70% 
表十五、實驗結果比較(二) 
 WU WLDB Decision list 
classifier 
Combined 
approach 
