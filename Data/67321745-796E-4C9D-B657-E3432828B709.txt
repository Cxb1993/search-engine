中 華 民 國 95 年 7 月 31  日 
virtual container-3 (VC-3) in order to further 
reduce bandwidth waste of transporting multiple 
groups of client signals. Finally, we devise a new 
transmission method that doesn’t disassemble an 
intact packet among diverse routes. Thus, large 
memory for differential delay compensation can 
be eliminated in the receiving end for UDP 
applications. 
 
二、 計畫的緣由與目的 
 
In this section, we first introduce the 
technology evolution regarding the convergence 
of telecommunication networks and data 
networks. Then, we evaluate competitive data 
transportation schemes against 
Ethernet-over-SOENT (EoS) and conclude the 
reasons why EoS is the most promising and 
cost-efficient technology for Ethernet to access 
optical fibers. In addition, we sketch in two 
gate-opening technologies for EoS, virtual 
concatenation (VCAT) and link capacity 
adjustment scheme (LCAS), by describing the 
problems they aim at and their methodologies 
employed in short. Finally, we would summarize 
pertinent works of the EoS mapper design in 
academia and industry in order to motivate our 
architecture. 
 
2.1 Why EoS? 
 
Ethernet has dominated local area networks 
during the past decade for the reasons of the 
simplicity to use, inexpensive equipments, and 
rapid rate migration from 10,100 to 1000 Mbps.  
Not only almost every home and small enterprise 
network adopt Ethernet architecture, this popular 
LAN technology has evolved to the point where 
services providers start to deploy Ethernet-based 
services in metropolitan area networks and wide 
area networks. Due to the emergence of gigabit 
optical fiber interface, lots of variants [14] 
offered by the Institute of Electrical and 
Electronics Engineers (IEEE) 802.3 committees 
supports plentiful applications in all segments of 
networks. For example, gigabit Ethernet mode 
1000BASE-LH can transport traffic on a single 
mode fiber up to 100 km distance enough to 
cover a metropolis. Therefore, no surprise that 
personal applications, such as email, ftp, web 
surfing, instant message, online gaming, etc; and 
enterprise applications like virtual private 
network (VPN), storage area network (SAN), 
online transaction hosting, video conferencing, 
etc, would all drive service providers and carrier 
operators to research and develop the optimal 
transport of packet-based Ethernet networks. 
 
As Ethernet moves toward MAN and WAN 
environments, the issues network operators face 
are the inherent shortcomings of Ethernet: (1) 
lacking of Operations Administration and 
Maintenance (OAM) mechanism, (2) slow 
restoration and (3) distance limitation. First, The 
group of OAM functions that provides network 
fault indication, performance information, and 
data and diagnosis functions are the key how 
carrier operators meet service level agreement 
(SLA) contracted with customer with various 
needs and then charge them accordingly. Second, 
restoration of Ethernet takes long convergence 
time, usually seconds, to rebuild new spanning 
tree for partly damaged network. Hence, from 
the viewpoint of resiliency, Ethernet is not yet 
qualified as a telecom-grade network technology 
which requires protection done within 50ms. 
Union (ITU-T), generic framing procedure (GFP) 
[24], virtual concatenation and link capacity 
adjustment scheme, bring about the efficient 
manner of Ethernet transportation. GFP is a 
versatile encapsulation method that facilitates 
more economical transport of more client signals. 
By reusing many aspects of encapsulation 
methods in ATM, GFP has the ability to 
transport both packet-oriented data and 
streaming data. The other techniques: VCAT 
solves bandwidth mismatch problem between 
Ethernet and SONET/SDH; LCAS adjusts 
SONET/SDH bandwidth allocated to fluctuating 
Ethernet traffic for higher utilization.  
Therefore, the advent of VCAT and LCAS 
would enable carriers the deployment of new 
Ethernet-based services, such as private leased 
line and virtual leased line [23]. For example, as 
depicted in Fig 2, this long-haul trunking service 
helps large enterprises to administrate branch 
offices around the world. The synergy of EoS 
mapper and Ethernet switch constructs a secure 
and fast communication channel with low coast, 
thereby enables worldwide employees at 
headquarter and local firms to collaborate and 
exchange proprietary data. 
 
 
Figure 2.  EoS scenario  
 
Although rival technology, Resilient Packet 
Ring (RPR) [10], claims spatial reuse that 
utilizes backup protection path in EoS as another 
working ring, its traffic latency and reliability 
are sacrificed for gained capacity [11]. Because 
traffic over RPR is examined node by node 
rather than passed over an end-to-end dedicated 
link in EoS, latency-sensitive traffic, such as 
video streaming, online gaming, and 
voice-over-IP, would still favors EoS 
environments. Besides, link failure of RPR 
would definitely incur interruption of the service. 
Therefore, service provider adopting PRP may 
not able to meet customer’s service level 
agreements. Moreover, because most operating 
support systems of current service providers are 
based on point-to-point circuits, evolution to 
RPR requires enhancements to support shared 
multi-point environment like RPR [12].  
 
2.2 Virtual Concatenation 
 
The aboriginal issue of mapping between 
Ethernet and SONET/SDH is the bandwidth 
matching problem. Specifically, due to the rigid 
SONET/SDH rate hierarchy shown in Table 1, a 
Gigabit Ethernet signal has to be born on an 
OC-48 (2.488Gbps) connection, using miserably 
inefficient 40 percent of payload. Contiguous 
Concatenation (CCAT) technique, therefore, 
comes into existence. It allows for non-standard 
multiplexing in order to provide client signals 
the right-sized transport pipes. For instance, 
VC-4-7c for gigabit Ethernet applications would 
introduce only 8.14% bandwidth waste. 
However, contiguous concatenation requires all 
intermediate nodes in SOENT/SDH network to 
be able to process this size-customized payload. 
In order to lift the constraint of contiguous 
concatenation, VCAT standard permits the 
combination of autonomous element in 
group 
　EOS: member has highest sequence number 
in group. 
　NORM: member is part of group 
 
Return direction, sink to source, 
•Member Status (MST) field feedback 
network link conditions 
•Re-Sequence Acknowledge (RS-Ack) bit 
confirms source side is aware of sequence 
number change due to bandwidth adjustment 
 
 
Figure 4.  LCAS signaling 
 
2.4 Related Works 
 
This section summarizes papers relating to 
EoS mapper design so as to show the reasons 
why we interested in issues, like LCAS 
performance (flexibility and quickness), 
bandwidth efficiency, and differential delay 
compensation, which could have the possibility 
of being more refined than in previous works.  
 
In the work [6], an architecture that maps 
two gigabit Ethernet over one OC-48 SONET 
connection was proposed. However, applications 
of nowadays, such as the case shown in Fig 2, 
usually require more than 2 Ethernet ports. Thus, 
we try to exploit UTOPIA interface to aggregate 
scores of Ethernet ports in order to keep up with 
the trend. Besides, this work chose VC-4 
(155.52Mbps) as the size of transport container, 
resulting in an 87.5% low bandwidth efficiency. 
This also stimulates us to design the VCAT 
scheme with VC-3 granularity for higher 
utilization of bandwidth.  
 
In the work [7], authors realized the 
transport of 4 ports Ethernet over VC-4 using 
VC-12 (2.176Mbps) as minimal transport size. 
Though port number has doubled comparing to 
[6], these four groups of traffic are handled by 
independent LCAS modules. Hence, egress 
bandwidth is not exchangeable among 4 Ethernet 
ports in case of network link failure. Thus, we 
intend to develop precross-connect functionality 
to make the EoS mapper more flexible.  
 
Side effect of virtual concatenation is the 
troublesome differential delay compensation 
problem due to diverse routing. Previous publish 
paper [6, 7, 13, 27] and commercial product [8, 
28] all employed similar methodology for 
compensation: buffer all payload till the slowest 
byte arrives. Large memory dedicated for high 
speed traffic buffering severely deteriorates the 
scalability of the EoS mapper. Work [9] 
considered this issue from another aspect. It 
distributes smaller buffer among intermediate 
network nodes along routing path to compensate 
differential delay. However, this would wipe off 
the fundamental advantage gained from virtual 
concatenation. Therefore, we also work toward 
eliminating the need of buffer in the direction of 
transmission scheme modification. 
 
One contributory factor to delay of LCAS 
service is the manner of how source exams and 
sink generates necessary monitor information. 
Notification time of standard LCAS transmission 
1 2 3 5 6 7 8 
1 0 0 0 MST 
1 0 0 1 
0 0 0 RS_ACK 1 0 1 0 
Reserved 1 0 1 1 
Reserved 1 1 0 0 
Reserved 1 1 0 1 
SQ MSB 1 1 1 0 
SQ LSB 1 1 1 1 
MFI-2 MSB 0 0 0 0 
MFI-2 LSB 0 0 0 1 
CTRL 0 0 1 0 
Reserved 0 0 1 1 
0 0 0 GID 0 1 0 0 
Reserved 0 1 0 1 
CRC MSB 0 1 1 0 
CRC LSB 0 1 1 1 
Table 2.  LCAS header 
 
To overcome drawback of current standard, 
two previous works addressed this problem [3] 
[4], but the response time was still proportional 
to the member count. Although [4] only regards 
low order (LO) concatenation, the concept can 
be applied here by making use of 8 more 
reserved bits as extended MST field in VLI 
header to doubles the information exchanged 
between source and sink so as to cut half the 
LRT time to 32ms. Similarly, [3] shortens the 
refresh cycle proportional to the number of 
provisioned members instead of the number of 
maximal members by taking advantage of 5 bits 
of reserved bit as new index for MST. Because 
extra bits are not for frame alignment like MFI-2, 
sequential increment from 0 to 31 isn’t necessary. 
LCAS module, therefore, could not generate 
MST values for members from 0 to 255 but 
break redundant repetition at the number of 
member provisioned since the extra 5 bits can 
promptly inform the source side which members 
the MST stands for. 
 
Our approach adopts similar method 
described in [3] to shorten refresh cycle. 
Besides, we evenly distribute all active 
member statuses over themselves by make 
use of sequence number (SQ) in the 
protocol header as a supplementary index to 
assemble and disassemble MST. 
Specifically, the modified MST field carries 
statuses of members ranging from  
  
to 
 
, where  is the number of active members at 
source side. As an illustration, if there are 16 
active members in a VCG, their MST values are 
summarized in Table 3. It’s obvious that every 
member can retrieve its feedback information in 
1 multi-frame by sharing MST among members. 
And this modification requires only additional 
shifters and multiplexers in MST assemble and 
disassemble modules. Moreover, originally 
designed resiliency provided by redundant MST 
byte is preserved since there are 8 copies of all 
member status in any cases. 
 
implementation, manufacturing technology 
process constraint on operating frequency of the 
standard cell library is the burden of designing a 
2.5G EoS system in byte-wide datapath. 
However, architecture of multiple parallel bytes 
reduces flexibility of LCAS member assignment 
and lowers the efficiency of VCAT bandwidth 
matching. This scheme can trunk 24 Ethernet 
traffic sources over one OC-48 optical fiber with 
2.488Gbps data rate without those drawbacks. 
Furthermore, we choose VC-3 (48.384Mbps) as 
the unit of bandwidth allocation to achieve 
higher rate matching with the moderate area cost 
of 48 LCAS member. Besides, the multiplexing 
structure of VC-3 enables further saving 
bandwidth of mapping multi-groups of signals 
by interleaving the column of VC-3 payload. 
UT is a universal PHY interface utilizing a 
cross-connect buffer to aggregate 24 variable 
Ethernet traffics to N channels of aggregated 
traffics (AT). Here we use N=4 such that OC-48 
traffic can also adopt the popular OC-12 date 
rate. The advantage of aggregation, as shown in 
Fig 6, is the cutback of worst bandwidth waste 
from 24 VC-3s to 4 VC-3s, that is, 8.3% of 
OC-48 data rate. 
  
 
Figure 6.  UT aggregates 24 Ethernet into 4 
channels of traffic 
 
With the option of reconfiguring output 
ports as 4 OC-12s, a switch block is used to 
cross-connect 4 logical channels with 4 physical 
ones in order to assign LCAS member with more 
elasticity. As shown in Fig 7, LCAS module 
pops octets from UT block at assigned time slots 
for respective logical data channel. Each octet on 
different time slot and different channel can be 
perceived as a LCAS member that may travel 
distinct route to the destination. Since VC-3 is 
the member size, there are 12 members over 
each channel and 48 members in total. Moreover, 
because UT evenly aggregate 1 GbE and 5 FEs 
to an AT port, we can assume each port needs 1 
~ 12 VC-3 members to accommodate the 
aggregated traffic. Obviously, data over a logical 
channel can be transmitted over a single OC-12 
physical channel after being handled by 
overhead processing block (OP). But if path of a 
physical member fails, SW can remap 
on-bearing logical member to other health links. 
In other words, SW increases link resiliency by 
freely mapping any 48 logical members to any 
48 physical one. As illustrated in Fig 7, for 
example, physical channel 0 is down and logical 
channel B stays idle, meanwhile SW can relocate 
traffic of logical channel A to physical channel 1. 
Worth-noting that SW can not only reallocate 
entire channel but tiny members over a channel. 
Besides, in extreme case, a logical channel might 
possess all 4 physical channels in some period of 
time, thus, SW have to buffer data of 12 LCAS 
member over a logical channel during each 
allocation repetition in order to satisfy the 
fourfold output rate. 
  
 
Figure 7.  Example of bandwidth sharing 
NORM, EOS, DNU, ADD, and REMOVE, 3 
bits for handshaking control messages which are 
IDLE, ADD, DNU, EOS, and NORM, 2 bits for 
VCG identification, and log2N bits for sequence 
number to identify the command subject among 
N members. For instance, VC-2 (6.784Mbps) is 
a smaller standard virtual container size, scheme 
of member size VC-2 would take at least 7.3K 
bits only to keep information around 350 LCAS 
source members, not to mention the exploded 
logic area of inter member message exchange. 
Therefore, considering to bandwidth efficiency 
and implementation cost, nonstandard one-third 
of VC-3 is more preferable to VC-2. And its 
mapping scheme is shown in 9. We further 
divide 86 columns of VC-3 payload into 3 
interleaved parts, and each part can be assigned 
to any client signal.  Fig 8 shows one third of 
VC-3 is allocated to gigabit Ethernet #2, 
avoiding occupying entire VC-3. Therefore, this 
scheme can utilize 97.22% bandwidth in the 
scenario of 4 virtual concatenation groups. 
Besides, due to SONET frame transmission 
order, these 3 parts are abutted in time domain. 
The switch block needs no extra buffer and no 
faster clock for re-sequencing 144 logic 
members to 144 physical ones. As for LCAS 
header of proliferous members that will flood 
original H4 byte, we use first byte of payload 
column 3 and 4 for 2nd and 3rd member in a 
VC-3. 
 
 
 
Figure 8.  Example of VC-3/3 bandwidth 
allocation 
 
 
 
Figure 9.  Column-interleaved mapping of 
VC-3 / 3 
 
 
3.4 Differential Delay Memory Minimization 
 
In this section, we propose a new transport 
scheme for UDP applications. Major advantage 
of this scheme is sink side needs no memory to 
compensate differential delay. While 
constructing an EoS system that supports virtual 
concatenation, differential delay is an important 
design issue because compensation memory can 
dramatically impact the receiver design. Virtual 
concatenation transmits a high order signal over 
a number of low order tributaries that need not to 
be transported as a whole. Besides, 
SONET/SDH uses byte-interleaved transmission 
for all tributaries and all tributaries may not 
arrive at receiver at the same time. Fig 10 
illustrates the differential delay. 
 
 
 
Figure 11.  Functional block diagram of 
packet-per-member (PPM) scheme 
 
The functional block diagram of PPM 
scheme is shown in Fig 11. An extra scheduler is 
inserted between traditional mapper and UT 
interface in order to distribute packets among 
members. It acquires quota information of each 
logical channel, XAT1~XAT4, from LCAS 
module. On the other side, the scheduler is 
informed by UT the status of every FIFO in 
polling groups and stores them in internal 24bits 
status table. A FIFO becomes a candidate and 
changes its status if an Ethernet port at input of 
UT successfully polls this FIFO within certain 
polling group and reaches a sufficient high 
watermark of the FIFO. 
 
Based on these information sources, 
scheduler, then, grants transmission of picked 
FIFO by ‘pop’ and ‘addr’ signals in a round 
robin fashion. In this architecture, internal ‘addr’ 
buffer array stores addresses of picked FIFOs. 
When LCAS module starts popping octet from 
UT, addr buffers are read one by one to specify 
the source FIFO. However, packets transported 
by PPM might not arrive at the destination in the 
same sequence of transmission, thus, only 
UDP/IP applications, such as some P2P and 
long-haul large-volume data exchange, can take 
advantage of this scheme without the cost of 
expensive memory. Furthermore, for 
applications like video on demand (VOD), 
service hosts could make use of the static latency 
information of transport network provided by 
EoS mapper to transmit service content in an 
order that packet over distinct tributaries can 
arrive simultaneously. Therefore, differential 
delay could be compensated by the original 
server who essentially possesses an entire copy 
of the source information. 
 
  
 
四、 結論與討論 
In this thesis, we design and implement a 
flexible transport scheme for 4 groups of 
Ethernet traffic over SONET by embedding a 
local cross-connect along with link capacity 
adjustment scheme module to provide free 
mapping between LCAS member and physical 
transmission timeslot. Since LCAS members 
would travel distinct routes that might fail, free 
mapping allow carrier operators to manage a 
more resilient system by skipping any defective 
transmission slot. This design fits in applications 
such as next generation SONET/SDH metro 
Ethernet system, already shown in Figure 2. 
Although VCAT and LCAS mechanism are 
standardized, we propose a new multiplexing 
approach, VC-3/3, to further economize 
bandwidth usage in multiple groups of client 
traffics, which is ambiguous in recommendations. 
As a result, VC-3/3 boosts the bandwidth 
efficiency from 91% to 97% in a 4 VCGs 
scenario. Besides, this column-interleaved 
multiplexing structure can also collaborate with 
our local cross-connect achieve higher flexibility. 
Next, we revise LCAS protocol header to 
