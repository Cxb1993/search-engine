2 
 
 
中文摘要 
所謂的可逆資訊隱藏技術，就是在承載媒體內藏入重要資料後變成藏有重
要資料的藏密媒體，日後從藏密媒體取出重要資料的同時，除了要能完整的取
出重要資料之外，還要能回復承載媒體的原來樣子，這樣的技術適用於保護數
位化藝術創作，醫學影像應用，程式原始碼驗證等領域。 
本計畫成功的設計適用於各種靜態灰階影像之可逆資訊隱藏技術，第一套
技術是以一般未經任何處理的原始影像為承載媒體，發展可逆的資訊隱藏技
術，第二套技術是針對各種影像失真壓縮技術進行分析，研究在原始影像經過
失真壓縮的過程中同時藏匿重要資訊，日後在取出重要資訊並解壓縮影像後，
與原始影像經失真壓縮之後再解壓縮的影像效果一致。 
 
關鍵詞: 可逆資訊隱藏;差值擴展;失真影像壓縮 
 
Abstract 
Reversible information hiding technique hides secret data in a digital cover 
media in a reversible way. In the extraction phase, the hidden secret data can be 
extracted and the embedded media can be restored to the original cover media. This 
technology can be used to protect digital art works, to authenticate medical images 
and source codes. 
In this project, we developed various reversible information hiding technique 
that can apply to digital cover image. The cover media of the first reversible 
information hiding scheme that we developed is raw image. The second part of our 
project studies the characteristic of various lossy data compression methods. We 
embed secret data in the process of lossy data compression. When the secret data 
are extracted, the embedded image is also restored to the image that the lossy data 
compression algorithm applied to the original image directly. 
 
Keywords: Reversible information hiding;  Difference expansion; Lossy 
image compression 
4 
 
用差值及平均值便可預先判斷該pair 未來是否可用來藏資料，可以藏資料的
pair 有兩類，第一類是可以用差值擴展法藏資料的，那就將差值乘上兩倍之後
加上一個位元的重要資料之後形成新差值，然後調整原來的倆個像素值，使其
調整後的像素值的平均值與原來兩個像素值的平均值一樣，但差值為新差值，
運用平均數在cover image 和embedded image 都不會改變的特性，在取出重要
資訊時能完全地回復原來的影像，第二類是無法用差值擴展法藏資料的，那就
將一個位元的重要資料藏在差值的最後一個位元，將原差值的最後一個位元另
外紀錄，由於此類型pair 不多，所以額外紀錄的資訊並不會太多，Tian 的方
法還要紀錄一個location map 以辨識一個pair 到底是沒藏資料或是上述第二
類可藏資料的par，以便取出資料時能正確判斷無誤，最後Tain將location map 
壓縮之後再和第二類pair 所產生的差值的最後一個位元所形成的位元串及真
正重要資料位元串串接起來，之後藏入上述所列第一、二類pair 之中，由以上
敘述可知Tain 的方法每個像素至多藏0.5 個重要資料位元。 
Alattar [1] 改良Tian 的以差值擴展為基礎的可逆資訊隱藏方法,並可適用
於彩色影像,Alattar 以長度大於2 的向量取代Tain 的pair 做差值擴展的處裡
對象,長度為k的向量可以藏k-1 個位元資料,所以其藏量最高可以非常接近
k-1/k bits/pixel,藉此提升藏量,並利用generalized integer transform 將原本向量
做適度轉換於處裡過程中降低產生的差值藉此提升影像品質,其方法於向量長
度為4 時整體表現最好。 
Chang et al.[8] 也是改良Tian 的以差值擴展為基礎的可逆資訊隱藏方法,
他們利用其鄰近k 個像素值為基礎去計算一個在藏入及取出階段都一樣的預
估值,並以此預估值與真正像素值的差值做資料位元藏入的依據,所以其藏量最
高可以非常接近1 bits/pixel,而且於低中藏量時有非常不錯的影像品質。 
Thodi and Rodriguzer [20,21] 也是以Tian 的差值擴展為基礎的可逆資訊
隱藏方法,他們利用一個全新的prediction-free 的參考值計算方法,可以估算一
個非常接近真正pixel 值的預估值,如此可以有效降低其嵌入重要資料位元時
產生的差值,不過其方法最精彩之處是用到了difference shifting 的觀念以提昇
影像品質,主要觀念為當某一個像素經檢驗是可以藏入資料,但藏入一個位元的
資料之後會將此像素值調整的離原像素值很大的距離,所以為了藏一個位元卻
6 
 
Chang et al.[11]在2006 年改進了之前由Jo and Kim 及Chang and Wu 所提
出的資訊隱藏方法，提出一個關於影像透過SMVQ 編碼做資訊隱藏並能夠成
功還原的方法，在影像品質及壓縮率方面都有不錯的成果改善;他們的方法透
過預先將隱藏的資料位元加密，透過改變SMVQ 編碼的方式，在影像還原的
部分有相當不錯的成果,經由取出資料位元後，能重建成原始影像經失真壓縮
時未隱藏資料位元的影像圖,而且不用參考原始影像，也不需複雜的計算。 
Chang and Lin[6] 為了更進一步提升藏量，提出了一個新的狀態編碼簿分
群的方法。它將影像中利用SMVQ 編碼區塊的索引值分成可以改變跟不可改
變的,然後將狀態邊碼簿中第一個和最後一個編碼字放再同一群，用來當不可
改變索引值的指標，接著在將剩下的編碼字分成兩群用來藏入資料,它的方法
還可延伸在每個索引值中藏入多個位元，解決了每個索引值只能藏入一個位元
資料的限制，大幅地提升整張影像的藏量。 
Chang and Lin[7] 提出一個利用狀態編碼簿重新配置(Relocation)的方法來
開發一個新的可逆資訊隱藏方法。首先統計原始VQ 編碼簿中每個編碼字被使
用到的機率。它主要將編碼簿分成三小群，第一群為用來藏入資料，大小則為
狀態編碼簿的大小，其他兩群則用來回復用,原始的VQ 編碼簿透過 LBG 演
算法計算後會分成很多小群，接著在第一群中的每個編碼字開始去它在VQ 編
碼簿分群結果中所屬的那群，找尋跟它最相近的編碼字，如果分群結果中只有
一個編碼字，則找到的結果設為空的，如此產生第二群的編碼簿。接著在第二
群中，去原始VQ 編碼簿中沒有被用來編碼的編碼字裡，找尋跟每個編碼字所
對應最近的一個，來建立第三群編碼簿。完成了整個編碼簿的重新配置後，檢
查影像是否利用第一群的編碼簿來編碼的便可藏入資料,這個方法可以簡單的
還原原來壓縮的影像，並兼顧藏入資料後的影像品質。 
Chang et al.[5] 以declustering 為主要技術開發一個新的可逆資訊隱藏方
法,它將編碼簿中索引值分成可以改變跟不可改變的。接著將邊碼簿中第一個
和最後一個編碼字放再同一群，用來當不可改變索引值的指標；剩下的編碼字
則結合minimum-spanning-tree algorithm 來分群，為了每一群的個數平均並更
進一步提升藏量，再利用short-spanning-path 演算法來分群。藏入的步驟中，
會先判斷影像每個區塊編碼的索引值是屬於可以改變和不可改變的。接著依照
8 
 
Within Digital Data. U.S. Patent 5 646 997. 
[3]  Celik, M.U., Sharma, G., Tekalp, A.M., Saber, E., 2002. Reversible data hiding. Proceedings 
of IEEE International Conference on Image Processing vol. II, 157-160. 
[4]  Celik, M.U., Sharma, G., Tekalp, A.M., Saber, E., 2005. Lossless Generalized-LSB data 
embedding. IEEE Transactions on Image Processing 14(2), 253-266. 
[5]  Chang, C. C., Hsieh, Y. P., Lin, C.Y., 2007. Lossless data embedding with high embedding 
capacity based on declustering for VQ-compressed codes. IEEE Transactions on information 
forensics and security 2(3), 341-349. 
[6 ]  Chang, C. C., Lin, C. Y., 2006. Reversible steganographic method using SMVQ approach 
based on declustering. Information Sciences 177(8), 1796-1805. 
[7]  Chang, C. C., Lin, C. Y., 2006. Reversible Steganography for VQ-Compressed Images 
Using Side Matching and Relocation. IEEE Transactions on Information Forensics and Security 
1(4), 493-501.  
[8]  Chang, C.C., Lu, T.C., 2006. A difference expansion oriented data hiding scheme for 
restoring the original host images. The Journal of Systems and Software Vol. 79, 1754-1766. 
[9]  Chang, C. C., Lu, T. C., 2006. Reversible index-domain information hiding scheme based 
on side-match vector quantization. The Journal of Systems and Software 79(8), 1120-1129. 
[10]  Chang, C. C., Tai, W. L., Lin, M. H., 2005. A Reversible Data Hiding Scheme with 
Modified Side Match Vector Quantization. Proceedings of the 19th International Conference on 
Advanced Information Networking and Applications, Vol 1, 947-952. 
 [11]  Chang, C. C., Tai, W. L., Lin, C. C., 2006. A Reversible Data Hiding Scheme Based on 
Side Match Vector Quantization. IEEE Transactions on Circuits and Systems for Video 
Technology 16(10), 1301–1308. 
[12]  Chang, C. C., Wu, W. C., Hu, Y. C., 2007. Lossless recovery of a VQ index table with 
embedded secret data. Journal of Visual Communication and Image Representation, 18(3), 
207-216. 
[13]  De Vleeschouwer, C., Delaigle, J. F., Macq, B., 2003. Circular interpretation of bijective 
transformation in lossless watermarking for media asset management. IEEE Transactions on 
Multimedia Vol.5, 97-105. 
[14]  Fridrich J., Goljan M., Du R., 2002. Lossless data embedding-new paradigm in digital 
watermarking. EURASIP J. Appl. Signal Processing 2002(2), 185-196. 
[15]  Henk, H., Lute, K., 2003. Reversible Data Embedding Based on the Haar Wavelet 
Decomposition. VIIth Digital Image Computing: Techniques and Applications , Sun, C., Talbot, 
H., Ourselin, S., Adriaansen, T. (Eds.), Sydney. 
[16]  Jo, M., Kim, H.D., 2002. A digital image watermarking scheme based on vector 
quantization. ICICE Trans. Information and Systems, E85-D. 
[17]  Kamstra, L., Heijmans, Henk J. A. M., 2005. Reversible Data Embedding Into Images 
Using Wavelet Techniques and Sorting. IEEE Transactions on Image Processing 14(12), 
2082-2090. 
[18 ]  Macq B., 2000. Lossless multiresolution transform for image authenticating watermarking. 
Proceeding of EUSIPCO, Vol. 2000, 533-536. 
10 
 
附錄三:  
出席SIGMAP 2009國際學術會議心得報告 
 
embedded data is called the reversible information
hiding technique.
Recently, more and more reversible information
hiding methods in application to the VQ-compressed
images have been proposed. In 2005, Chang et al.11
adapted the side match vector quantization (SMVQ)
scheme to design a reversible information hiding
method. The data bits are embedded into the indices
by changing the indices of the state codebook. The
data bits are extracted using the modular operation.
Besides, the original VQ-compressed index of each
block is recovered by referring to the characteristic of
its upper and left blocks.
Chang and Lu12 referred to Jo and Kim’s method9
and proposed a reversible information hiding method
based on the SMVQ scheme. The state codebook
clustering scheme is used to conceal the data bits on
the indices of the SMVQ-compressed indices.
Chang et al.13 proposed a reversible information
hiding scheme for SMVQ-compressed images. For
visual quality, the size of the secret data, and the
compression rate, the performance of this scheme is
superior to the previous reversible information hiding
schemes for VQ-compressed and SMVQ-compressed
images.
To heighten hidden capacity and efficiency, Chang
and Lin14 proposed a reversible information hiding
method for VQ-compressed images based on the
concept of declustering. Declustering is the opposite
of clustering. Its aim is to link dissimilar codewords.
Their approach significantly reduces the embedding
time and does not need a location map.
In improving the embedding capacity and the
quality of the compressed image, Chang and Lin15
proposed another reversible embedding scheme for
VQ-compressed images. In their method, the code-
book is partitioned into several clusters before
embedding. A side-match prediction and relocation
method makes the method reversible without requir-
ing a location map. Their method provides higher
embedding capacity and image quality than other
methods without increasing the size of the cover
carrier.
In 2007, Chang et al.16 proposed a reversible data
embedding method for VQ-compressed images. It
was based on the declustering strategy and the
similarity property of bordering areas in a natural
image. The minimum-spanning-tree and the short-
spanning-path algorithms are used to decluster the
codebook, respectively. The declustering methods
make the process of data hiding very efficient and
possess higher embedding capacity compared with
other schemes.
From the above literatures review, we find some
reversible data embedding methods in the VQ-
compressed domain11–13,15 embed data bits without
file size extension problem but with limited embed-
ding capacity. Other methods14,15,17 increase embed-
ding capacity but extend the file size. However, none
are flexible enough to embed various amounts of data
bits in the VQ-compressed image. In this paper, we
propose an adaptive and simple reversible informa-
tion hiding method which is based on the search-
order coding (SOC) algorithm18 applied to VQ-
compressed images. The VQ-compressed image is
also called the index table in this manuscript. The
data bits and one judge bit are embedded into each
index in the index table during the SOC stage. Our
method can be used to hide any amount of data bits.
Our method outperforms other methods in embed-
ding capacity and compression ratio. Also, our
method’s degradation in the compression rate of the
embedded image is smoother and slower than other
methods.
The rest of this paper is organized as follows. In
Section 2, VQ, the SOC algorithm and Chang
et al.’s17 reversible information hiding method are
briefly reviewed. Our reversible information hiding
method is presented in Section 3. Some experimental
results are shown in the next section, followed by
conclusions in Section 5.
2 RELATEDWORKS
2.1 Vector quantization
Vector quantization is an efficient lossy compression
technique. The host image to be encoded is first
decomposed into several non-overlapping blocks of
the same size. Each block can be represented as a
k-dimensional vector. A codebook which contains
many representative k-dimensional vectors is used to
encode each block in the host image. In the encoding
phase, the input block will find the closest codeword
in the codebook and record the index value of this
closest codeword in the codebook. The index value
stands for the input block in the VQ-compressed
image. Each individual block is processed sequen-
tially. After encoding, the VQ-compressed image
becomes an index table with many indices. In the
38 J-Y HSIAO, J-F CHEN AND J M CHANG
The Imaging Science Journal Vol 57 IMAG mp181 # RPS 2009
Third, the sorted codebook is further partitioned
into 2B2163 clusters of the same size tN{2
B{1
2B{1|3
s where
B stands for the number of data bits to be hidden in
each VQ index and N denotes the number of
codewords in the sorted codebook. There are only
tN{2B{1
2B{1|3
s62B2163 codewords to be used in the
upcoming process.
We explain Chang et al.’s one bit reversible
information hiding method with the example shown
in Fig. 2. Let B1, N516 and the data bit string be
(100111)2. Then 2
B{1|3~21{1|3~3 clusters each
with tN{2
B{1
2B{1|3
s~t16{2
1{1
21{1|3
s~5 codewords are generated
before embedding. According to the referring num-
ber, the first five codewords are put in cluster1, the
next five codewords are put in cluster2 , and the
remaining five codewords are put in cluster3. The last
codeword in the original codebook is not used. The
three clusters are shown in Fig. 2.
In Chang et al.’s method, data bits only embed into
the indices in cluster1. If the current index is in
cluster1 and the data bit is ‘1’(‘0’), the embedding
process changes the current index to the correspond-
ing index in cluster3 (cluster2 ). For example, the first
index value in the index table is 4 and the data bit is 1.
Because 4 belongs to cluster1, it can embed one bit
data. Since the data bit is ‘1’, the embedded index
value becomes 14 which is in cluster3. The third index
value in the index table is 5 and the data bit is 0.
Because 5 belongs to cluster1, it can embed one bit
data. Since the data bit is ‘0’, the embedded index
value becomes 10 which is in cluster2.
Although no data bit embedded, the indices not in
cluster1 also have to be processed in the embedding
phase for the sake of extracting the data bit without
confusion. If the current index is in cluster2 , the
embedding process changes the current index to the
corresponding index in cluster1. If the current index
is in cluster3, the embedding process changes the
current index to the corresponding index in cluster1
and puts the unused index value in the front. For
example, the second index value in the index table is
8. Because 8 belongs to cluster2, it cannot embed any
data bit. The current index value is changed to 3
which is in cluster1. The fourth index value in the
index table is 13. Because 13 belongs to cluster3, it
cannot embed any data bit. The embedding process
changes the current index value to 0||3. In this
example, we let index value 0 be the unused index
value and it does not belong to any cluster.
The result of the embedding process is shown in
Fig. 2. At the embedded index table, the underlined
indices have no data bit embedded in them. The
coloured indices mean there is a flag index ‘0’ in front
of the changed index. It is easy to see the file size
expansion after embedding is caused by this kind of
index change.
In the extraction phase, when we process an
embedded index belonging to cluster2 (cluster3), we
know that the embedded data bit is ‘0’(‘1’) and the
original index is the corresponding index in cluster1.
If the current embedded index belongs to cluster1, we
know no data bit embeds in this index and the
original index is the corresponding index in cluster2.
If the current embedded index is 0 following another
index belonging to cluster1, we know no data bit
embeds in this index and the original index is the
corresponding index in cluster3. For example, the
fourth embedded index value is 0||3. The flag index 0
is the head followed by the embedded index value ‘3’
that will correspond to the index value 13 rather than
the default value 8 to 3 in this case.
Chang et al.’s two bits reversible information hiding
method are demonstrated with the example shown in
Fig. 3. Let B52, N532 and the data string is
(1000110101)2. The codewords in cluster
1 and cluster2
are used to embed data, the codewords in other clusters
are used to restore original indices. The first index value
in the index table is 7 and the data bits are ‘10’. Because
7 belongs to cluster2, it can embed two bits data. Since
the data bits are ‘10’, the embedded index value
becomes 17 which is in cluster4. The second index value
in the index table is 5 and the data bits are ‘00’. Because
5 belongs to cluster1, it can embed two bits data. Since
the data bit are ‘00’, the embedded index value becomes
15 which is in cluster3.
The fifth index value in the index table is 4 and the
data bits are ‘11’. Because 4 belongs to cluster1, it can
3 An example of hiding two-bit secret data in Chang’s
method
40 J-Y HSIAO, J-F CHEN AND J M CHANG
The Imaging Science Journal Vol 57 IMAG mp181 # RPS 2009
into each index. For example, if the size of the index
table is 1286128. If the length of the data string is
21384, we derive each index embeds 2 bit secret data
in the front 5000 indices and embeds 1 bit secret data
in the other 11384 indices. Thus our method can
embed arbitrary length data into an index table.
For improving the security of the hidden data, the data
string can be encrypted19,20 before embedding. We can
use the pseudo-random number generator to randomly
assign the meaning of the judge bit. This means the same
judge bit value may represent totally different meaning in
different places. Thus, if the extractor does not get the
right key and seed of the pseudo-random number
generator, the extraction will fail.
In the next section, the experimental results will show
our method is not only flexible in embedding various
lengths of data but also performs well in the compres-
sion effect when the embedding capacity increased.
4 EXPERIMENTAL RESULTS
Four 5126512 sizes grey-level standard images:
Lena, Airplane, Boat and Toys are used to produce
VQ codebooks with sizes of 256 and 512 codewords
using the LBG21 algorithm. Each codeword is a 16-
dimensional vector. In Fig. 4, we show the five
standard 5126512 sizes grey-level test images:
Lena, Airplane, Boat, Toys and Pepper. After VQ
compression, there are 1286128 indices in the index
table of each test image. We first make a comparison
between our method and Chang et al.’s17 method. In
the following experiments, the codebook size is 256
and the SOC bit length is 2.
It is obvious our method provides reversible
embedding. We do not discuss the quality of the
embedded image here, but mainly focus on the
embedding capacity and the embedded file size.
The bit rate is also called bit per pixel (bpp). This
stands for how many bits are used in the compressed
image to represent an original image pixel. Bit rate is
used to indicate the compression effect in the
following experiments. The lower the bit rate, the
better the compression effect.
In Table 1, the results of embedding one, two and
two and half data bits into each index in the index table
are listed. The experimental results reveal there is only
a slight increase in the length of the embedded code.
4 Host images with 5126 512 pixels
42 J-Y HSIAO, J-F CHEN AND J M CHANG
The Imaging Science Journal Vol 57 IMAG mp181 # RPS 2009
The experimental results are shown in Table 6. The
embedded code size of our method is lower than
Chang and Lin’s method at all different embedding
capacities on the test image Lena. But Chang and
Lin’s method outperforms our method for the first
two lower embedding capacities on the test image
Baboon. This is because the Baboon is a very
complicated image. Thus, the SOC algorithm cannot
effectively reduce the embedded code size. However,
when the embedding capacity is increased, the
embedded code size increases more obviously in
Chang and Lin’s method than in our method.
Therefore, we still have lower embedded code size
than Chang and Lin’s method for the last two
embedding capacities.
In conclusion, our reversible information hiding
method embeds any length data string to an index
table. The embedded image compression ratio
increased more smoothly than the previous method.
Our method clearly increases the embedding capacity
and decreases the embedded code size. With the
security technique mentioned earlier, the proposed
method becomes an information hiding method with
the characteristics of reversibility and security.
5 CONCLUSIONS
In this paper, we proposed an adaptive and simple
reversible information hiding method applied to VQ-
compressed images. The proposed method easily and
correctly extracts secret data and recovers the
embedded image to the original one. Our method
embeds any length of data bits into the VQ-
compressed image and still has a good compression
effect while the embedding capacity increased. For
increasing the security of the embedded data, the data
encryption and random mapping techniques can be
easily integrated with our methods. The experiment
results show that our method outperforms other
methods in the embedding capacity and the compres-
sion ratio. Additionally, our method’s degradation in
the compression rate of the embedded image is
smoother and slower than other methods.
REFERENCES
1 Pennebaker, W. B. and Mitchell, J. L. JPEG: still image
compression standard. Comput. Stand. Interf., 1993, 15,
(4), 365–366.
2 Rao, K. R. and Huh, Y. JPEG 2000, Proc. 2001 Int.
Symp. on Intelligent multimedia, video and speech
processing, Hong Kong, China, May 2001, IEEE Hong
Kong Chapter of Signal Processing and the Centre for
Multimedia Signal Processing of the Department of
Electronic and Information Engineering, The Hong
Kong Polytechnic University, pp. 20–23.
3 Linde, Y., Buzo, A. and Grey, R. M. An algorithm for
vector quantizer design. IEEE Trans. Commun., 1980,
28, (1), 84–95.
4 Artz, D. Digital steganography: hiding data within
data. IEEE Internet Comput., 2001, 5, (3), 75–80.
5 Derrick, G. Data watermarking: steganography and
watermarking of digital data. Comput. Law Secur.
Rep., 2001, 17, (2), 101–104.
6 Wang, S. J. Steganography of capacity required using
modulo operator for embedding secret image. Math.
Comput., 2005, 164, (1), 99–116.
7 Chang, C. C. and Wu, W. C. A steganographic method
for hiding secret data using side match vector quantiza-
tion. IEICE Trans. Inform. Syst., 2005, 88–D, 2159–
2167.
8 Chang, C. C. and Tseng, H. W. A steganographic
method for digital images using side match. Patt.
Recogn. Lett., 2004, 25, (12), 1431–1437.
Table 5 The comparison of our method with Chang
et al.’s16 method under the constrain of same
embedding capacity
Image
Method
Embedding
capacity (bits)
Embedded code size (bits)
Our Chang et al.
Lena 36 288 142 483 157 230
Baboon 31 272 180 713 191 439
Pepper 36 414 144 513 156 294
Barbara 33 222 150 925 178 317
Boat 35 482 137 477 163 188
Tiffany 36 390 122 635 151 164
Table 6 The comparison of our method with Chang and
Lin’s14 method under the constrain of same
embedding capacity
Method
Image
Embedding
capacity (bits)
Embedded code size (bits)
Our Chang and Lin
Baboon 16 129 166 130 151 578
29 198 179 199 172 989
36 609 186 610 199 008
39 014 189 015 222 579
Lena 16 129 120 175 148 707
31 510 135 556 153 720
45 075 149 121 161 982
55 186 159 232 174 330
44 J-Y HSIAO, J-F CHEN AND J M CHANG
The Imaging Science Journal Vol 57 IMAG mp181 # RPS 2009
This article appeared in a journal published by Elsevier. The attached
copy is furnished to the author for internal non-commercial research
and education use, including for instruction at the authors institution
and sharing with colleagues.
Other uses, including reproduction and distribution, or selling or
licensing copies, or posting to personal, institutional or third party
websites are prohibited.
In most cases authors are permitted to post their version of the
article (e.g. in Word or Tex form) to their personal website or
institutional repository. Authors requiring further information
regarding Elsevier’s archiving and manuscript policies are
encouraged to visit:
http://www.elsevier.com/copyright
Author's personal copy
was the ﬁrst researcher who researched the reversible
data embedding problem. Macq [8] solved it using an
extension to the patchwork algorithm. Fridrich and others
[6] losslessly compressed the least signiﬁcant bit (LSB)
of a cover image and embedded message on bits in the
status of a group of pixels. Their methods conspicuously
improved the embedding capacity. Celik and others [3]
improved Fridrich and others’ method and derived a high
capacity, low distortion reversible data embedding algo-
rithm. De Vleeschouwer and others [5] proposed a
reversible data embedding algorithm based on the circular
interpretation of bijective transformations.
Tian [12] developed a high-capacity and low-distortion
reversible data embedding scheme based on the differ-
ence expansion transform of a pair of pixels. His algorithm
divides the image into pairs of pixels. Those pairs not
expected to cause an overﬂow or underﬂow are embedded
one bit into the difference of the pixels of each pair. The
location map indicating which pairs are embedded data, is
compressed and included in the payload. In a single pass,
Tian’s algorithm can embed 0.5 bits/pixel at most. Chang
and Lu [4] improved Tian’s method by considering the
correlation between the target pixel and its surrounding
pixels to determine the degree of the difference expansion
for message data embedding. Their method strengthened
the embedding ability and improved the computation
efﬁciency. In a single pass, Chang and Lu’s method can
embed 1 bit/pixel at most.
Of special interest to this paper is the work done by
Alattar [1]. Alattar extended Tian’s method using a
difference expansion of vectors, instead of pairs, to
increase the hiding ability of their method. Alattar also
used the generalized integer transform of vectors to
improve the embedded image quality. In Alattar’s method,
k pixels can embed k1 bits. However, like Tian’s method,
the location map and other extra information are needed
to restore the original cover image, so the embedding
ability of their method is as high as (k1)/k bits/pixel.
Thodi and Rodriguez [10] proposed a new difference
expansion scheme termed the prediction-error expansion.
The correlation inherent in the surrounding of a pixel is
better exploited in prediction-error expansion than Tian’s
difference expansion scheme. Thodi and Rodriguez [11]
combined the histogram-shifting technique and the
prediction-error expansion technique to solve the pro-
blems existing in Tian’s method. Those are the capacity
control problem and the undesirable distortion at low
embedding capacities problem.
Ni and others [9] proposed a reversible data embed-
ding method different from the difference expansion-
based scheme. Their method utilized the zero or the
minimum points of the histogram of an image and slightly
modiﬁed the pixel grayscale values to embed data into
the image. This method can produce at least a 48dB
embedded image but the embedding capacity is limited.
Increasing the embedding capacity, maintaining the
reversible characteristic and simultaneously decreasing
the destruction of the original image are the technical
challenges of the reversible data embedding problem. In
this paper, a block-based reversible data embedding
method is proposed. The image is ﬁrst divided into two
areas: data embedding area and auxiliary information
embedding area. The data embedding area is further
partitioned into 3*3 blocks. When embedding, all the
blocks are divided into three categories: smooth, normal
or complex. To derive a higher peak signal-to-noise ratio
(PSNR) embedded image, the complex blocks will not
embed any data. To increase the embedding capacity, a
smooth block will embed twice the data of a normal block.
Each block is divided into disjoint vectors with the
same trend. The vector trend used to embed data bits in
different blocks may differ. The vector trends of the
surrounding blocks are used to determine the vector trend
of the target block. Then Alattar’s difference expansion of
a generalized integer transform method is exploited to
embed data into each vector in the block.
Our method not only improves the embedded image
quality but also provides higher payload capacity than
Alattar’s method. For some smoother images, the pro-
posed method embeds more than one bit in each pixel in a
single pass and also derives high embedded image quality
(PSNR430). In our understanding, the proposed method
is the ﬁrst to do this.
The rest of this paper is organized as follows: In Section 2,
we brieﬂy review Tian’s difference expansion concept
and Alattar’s difference expansion of a generalized integer
transform method. Section 3 presents the proposed
method in detail. Section 4 shows and discusses the
experimental results. Finally, our conclusions are sum-
marized in Section 5.
2. Related works
Tian [12] proposed a reversible data embedding
method based on the difference expansion transform of
a pair of pixels. In this section, we brieﬂy introduce Tian’s
difference expansion concept in Section 2.1. In Section 2.2,
Alattar’s [1] reversible data embedding method based on
the difference expansion of vectors, instead of pairs, is
described. Instead of processing a vector directly, Alattar
used the generalized integer transform of vector to reduce
the difference values. A modiﬁed version of Alattar’s
method which embeds twice the data in a single vector is
presented in Section 2.3.
2.1. Tian’s difference expansion concept
In Tian’s method, two neighboring pixels are used
to embed one data bit. In the embedding phase, the
difference of a pixel pair is calculated ﬁrst. Then the data
bit is carried in the LSB of the expanded difference. For
example, let x ¼ 106 and y ¼ 101 be two neighboring
pixels. Let b ¼ 1 be a data bit. First, the difference h and
the average l of x and y are calculated:
h ¼ 106 101 ¼ 5
l ¼ 106þ 101
2
 
¼ 103
ARTICLE IN PRESS
J.-Y. Hsiao et al. / Signal Processing 89 (2009) 556–569 557
Author's personal copy
to note this kind of embedding can only be applied to a
smooth vector. A smooth vector means the variance of it is
very small. If this kind of embedding is applied to a non-
smooth vector, severe destruction may occur in the
embedded pixels. The severe destruction is because of
the quad times difference expansion.
For example, let u ¼ ðu1;u2;u3Þ be a smooth vector
with three pixels and b ¼ (b1b2b3b4)2 be the data bits
stream to be embedded. Assume u ¼ (94,92,93) and
b ¼ (1011)2. The same as Alattar’s method, the weighted
average d1 and the differences d2, d3 are calculated by
Eq. (1):
d1 ¼
a1u1 þ a2u2 þ a3u3
a1 þ a2 þ a3
 
¼ 94þ 92þ 93
3
 
¼ 93
d2 ¼ u2  u1 ¼ 92 94 ¼ 2
d3 ¼ u3  u1 ¼ 93 94 ¼ 1
Then the differences are quad times expanded and the
data bits are embedded into the new differences:
d˜1 ¼ d1 ¼ 93
d˜2 ¼ 4 d2 þ b1b2 ¼ 4 ð2Þ þ ð10Þ2 ¼ 8þ 2 ¼ 6
d˜3 ¼ 4 d3 þ b3b4 ¼ 4 ð1Þ þ ð11Þ2 ¼ 4þ 3 ¼ 1 (8)
Finally, we have to ﬁnd a vector u0 ¼ ðu01;u02;u03Þ whose
weighted average ða1  u01 þ a2  u02 þ a3  u03=a1 þ a2 þ
a3Þ ¼ d˜1 ¼ 93 and differences u02  u01 ¼ d˜2 ¼ 6, u03
u01 ¼ d˜3 ¼ 1. The vector ðu01;u02;u03Þ which is the ﬁnal
embedded pixel value is calculated by Eq. (3):
u01 ¼ d1 
a2  d˜2 þ a3  d˜3
a1 þ a2 þ a3
 
¼ 93 6 1
3
 
¼ 93þ 3 ¼ 96
u02 ¼ d˜2 þ d1 
a2  d˜2 þ a3  d˜3
a1 þ a2 þ a3
 
¼ 6þ 96 ¼ 90
u03 ¼ d˜3 þ d1 
a2  d˜2 þ a3  d˜3
a1 þ a2 þ a3
 
¼ 1þ 96 ¼ 95
In the extraction phase, the weighted average d˜1 and the
differences d˜2 and d˜3 are calculated by Eq. (4):
d˜1 ¼
a1  u01 þ a2  u02 þ a3  u03
a1 þ a2 þ a3
 
¼ 96þ 90þ 95
3
 
¼ 93
d˜2 ¼ u02  u01 ¼ 90 96 ¼ 6
d˜3 ¼ u03  u01 ¼ 95 96 ¼ 1
The data bits are obtained by the following formulas:
ðb1b2Þ2 ¼ d˜2  4
d˜2
4
 
¼ 6 4 6
4
 
¼ 2 ¼ ð10Þ2
ðb3b4Þ2 ¼ d˜3  4
d˜3
4
 
¼ 1 4 1
4
 
¼ 3 ¼ ð11Þ2
(9)
The original weighted average d1 and the differences d2, d3
are calculated by
d1 ¼ d˜1 ¼ 93
d2 ¼
d˜2
4
 
¼ 6
4
 
¼ 2
d3 ¼
d˜3
4
 
¼ 1
4
 
¼ 1 (10)
Finally, the original pixel values are recovered by Eq. (7):
u1 ¼ d1 
a2  d2 þ a3  d3
a1 þ a2 þ a3
 
¼ 93 2 1
3
 
¼ 93þ 1 ¼ 94
u2 ¼ d2 þ u1 ¼ 2þ 94 ¼ 92
u3 ¼ d3 þ u1 ¼ 1þ 94 ¼ 93
That is a simpliﬁed version of Alattar’s quad times
difference expansion of a generalized integer transform
method.
3. The proposed method
The non-overlap vectors used in Alattar’s embedding
method are in the same shape. For example, it can be 1*3
or 3*1 vectors. This restriction may cause the following
problem: if the horizontal vector is used in an image with
more vertical edges, more large differences are generated
in the vectors. Thus, the embedded image quality
decreased. The 512*512 sized Lena image is adopted to
show this concept. If the vector shape of Alattar’s
embedding method is 1*3, the embedding capacity is
169818 bits and the PSNR of the embedded image is
31.4254dB. If the vector shape is 3*1, the embedding
capacity is 170254 bits and the PSNR becomes
33.3562dB. We get more higher PSNR values embedded
images by partitioning the cover image into blocks and
using the suitable vector shape to embed data in each
block.
As we know, Alattar’s method embeds k1 bits in
every vector with k pixels. He did not consider the content
of the vector. Although only the predeﬁned number of bits
is embedded in a complex area vector, it may cause
serious destruction of the pixels. On the other hand, if
twice the predeﬁned number of bits is embedded in a
smooth area vector, the difference between the original
pixel value and the embedded pixel value may be still
tolerable.
The above phenomena motivate us to develop a block-
based reversible data embedding method which embeds
different amounts of data in each block using different
vector shapes. In Section 3.1, we describe our embedding
phase. The extraction phase is presented in Section 3.2.
3.1. The embedding phase
The outline of our embedding procedure is described in
this subsection. The cover image is ﬁrst divided into two
areas: data embedding area and auxiliary information
embedding area. The data bits are embedded in the data
embedding area shown in Fig. 1. The data embedding area
ARTICLE IN PRESS
J.-Y. Hsiao et al. / Signal Processing 89 (2009) 556–569 559
Author's personal copy
(c) If the four variances are all smaller than TH2, Block0 is
predicted to be a smooth block. A modiﬁed version of
Alattar’s method mentioned in Section 2.3 is used to
embed data. The embedding capacity is twice the
original embedding capacity.
We then describe in detail about how to determine
Block0’s edge direction (or vector shape). We use the edge
directions of the surrounding blocks to predict the edge
direction of Block0. Each block has four kinds of division.
Consider the block content in Fig. 5. The ﬁrst kind is
horizontal division. After partition, the three horizontal
vectors are h1 ¼ (x1,x2,x3), h2 ¼ (x4,x5,x6) and h3 ¼
(x7,x8,x9). The second kind has vertical division. After
partition, the three vertical vectors are v1 ¼ (x1,x4,x7),
v2 ¼ (x2,x5,x8) and v3 ¼ (x3,x6,x9). The third kind has 451
division. After partition, the three vectors of 451 are
p1 ¼ (x1,x2,x4), p2 ¼ (x3,x5,x7) and p3 ¼ (x6,x8,x9). The last
kind has 451 division. After partition, the three vectors of
451 are n1 ¼ (x2,x3,x6), n2 ¼ (x1,x5,x9) and n3 ¼ (x4,x7,x8).
We calculate the variances of all the above vectors. For
the horizontal vectors, we can get three variances, var_h1,
var_h2 and var_h3. Then, we calculate the average of these
three horizontal variances var_avg_h ¼ ðvar_h1 þ var_
h2 þ var_h3Þ=3. Similarly, the average of the other three
kinds of vector directions, var_avg_v, var_avg_p and
var_avg_n can be calculated. The vector direction with
the smallest average variance among the four average
variances is regarded as the edge direction of this block.
For example, if var_avg_v ¼ minfvar_avg_h; var_avg_v;
var_avg_p; var_avg_ng, the edge direction of the block is
regarded as vertical.
Normally, edge direction consistency will be present
within a small area of an image. Therefore, we use the
edge directions from the surrounding blocks to predict the
edge direction of the target block. We count the number
of various edge directions when the edge directions of
the surrounding blocks are determined. The majority is
predicted to be the edge direction for Block0. If there is no
majority, the edge direction that has higher priority
is predicted as the edge direction of Block0. The priority
order is vertical4horizontal44514451. For example, if
two vertical edges and two 451 edges appear in the four
surrounding blocks, the edge direction of Block0 is
predicted to be vertical.
After the edge direction is decided, Block0 is parti-
tioned into three vectors. If the edge direction of Block0 is
horizontal, the three horizontal vectors h1, h2 and h3 are
used to embed data. Alattar’s integer transformation
method shown in Section 2.2 or 2.3 is applied to embed
data in these chosen vectors. The other three cases can be
processed similarly.
As with Alattar’s original method, in our method some
embedded pixel values can be out-of-range [0,255]. So,
the vector cannot embed any data. We maintain a location
map to record whether the vectors embed data. If a vector
is embedded with data, we record 1 in the location map.
Otherwise we record 0. Generally, the ratio of a vector
which cannot embed data is very low. Thus, the location
map can be losslessly compressed with a very high
compression rate. To extract embedded data and restore
the original cover image correctly, the location map needs
to be embedded into the cover image. In the next
subsection we describe the details of how to embed the
location map and other auxiliary information in the ﬁrst
few rows and columns of the cover image.
3.1.2. Location map and other auxiliary information
embedding
After the data bits are embedded into the data
embedding area, we have a location map and a temporary
embedded image. To extract the data bits and restore the
cover image correctly in the extraction phase, the location
map and some auxiliary information also need to be
embedded in the cover image. We propose a novel method
based on LSB substitution to embed these data in the
auxiliary information embedding area. In the following,
we describe the method in detail.
First, we divide the pixels in the auxiliary data
embedding area into pairs. Within each pair we only
select those pairs in which the smaller number of the pair
is even. Pairs with two odd numbers or those in which the
even number is larger than the odd number are not used.
The selected pairs form a set U. We only embed auxiliary
data bits into the pairs in U. The reason we only select
such kind of pair to embed data will be explained later.
The difference of each pair in U is calculated. The auxiliary
data bits are embedded into the LSB of those differences.
Assume we want to embed a data bit b, bA{0,1} into a
pixel pair (x,y). The difference d between x, y is calculated
d ¼ |xy|. The new difference d0 is calculated by d0 ¼
2 bd=2c þ b. The pair after embedded data bit is
calculated by the following:
ðx0; y0Þ ¼ ðx; xþ d
0Þ if xpy
ðyþ d0; yÞ otherwise
(
(11)
ARTICLE IN PRESS
Block 1 Block 2 Block 3
Block 4
Block0
(Target Block)
Fig. 4. Referring blocks.
x1 x2 x3
x4 x5 x6
x7 x8 x9
Fig. 5. A block.
J.-Y. Hsiao et al. / Signal Processing 89 (2009) 556–569 561
Author's personal copy
bits is reduced, the number of normal blocks that can
embed six data bits is increased. Therefore, the embed-
ding capacity is increased but the embedded image
quality is decreased.
The other case is that if we ﬁx TH1 and increase TH2,
the number of smooth blocks will be increased. Because
the number of smooth blocks that can embed 12 data bits
is increased, the number of normal blocks that can embed
six data bits is decreased. Thus, the embedding capacity is
increased but the embedded image quality is decreased.
If we let TH1 ¼N and TH2 ¼ 0, all of the blocks will be
classiﬁed as normal blocks and at most six data bits can
be embedded in each block. If we let TH1 ¼ TH2, all of the
blocks will be classiﬁed as smooth or complex blocks. If it
is a smooth block, no data bits can be embedded in it. If it
is a complex block, at most 12 data bits can be embedded
in it. Thus, we can adapt the embedding capacity by
controlling the values for TH1 and TH2.
In general, reducing the TH1 and TH2 values will
improve the embedded image quality but decrease the
embedding capacity. Conversely, increasing the TH1 and
TH2 values will increase the embedding capacity but
decrease the embedded image quality. However, different
images have different TH1 and TH2 values providing an
optimal trade-off for the embedding capacity and em-
bedded image quality. This is because the block variance
distribution is different for different images. How embed-
ding capacity and embedded image quality could be
traded-off by adjusting the TH1 and TH2 values is an
important issue. In Section 4, we will use various
experimental results to address this issue.
3.2. The extraction phase
In the extraction phase, we ﬁrst extract the 16 bits
compressed auxiliary information length from the aux-
iliary information embedding area in the embedded
image. According to the length information, the com-
pressed auxiliary information can be extracted from the
LSBs of the differences derived from the usable pixel pairs.
After the compressed auxiliary information is decom-
pressed, we get TH1, TH2, the location map and the LSBs
stream. The pixel values in the auxiliary information
embedding area can be completely restored using the
LSBs stream.
The data is extracted from the data embedding area in
the embedded image. The scanning order of the data
extraction is the opposite of the embedding order. That is
a raster-scan from left to right and from top to bottom. For
each block, we ﬁrst check if it is a smooth, normal or
complex block. If it is a complex block, we skip it. If it is
not a complex block, the location map is used to indicate
whether we should extract data from it. When data
extraction is needed, the vector direction is determined
according to the surrounding blocks’ edge directions. After
that, Alattar’s method is used to extract the data and
restore a normal block. The modiﬁed version of Alattar’s
method is used to extract the data and restore a smooth
block. The block diagram of extraction process is shown in
Fig. 6.
4. Experimental results
Ten 512*512 sized cover images are used in the
following experiments. As shown in Fig. 7, those are Lena,
F16, Baboon, Barb, Pepper, Boat, Girl, Gold, Tiffany and
Toys.
We used C language to implement various methods.
The experiments were performed by embedding and
extracting randomly generated bitstreams. The PSNR is
used to measure the embedded image quality.
Some notations adapted here are deﬁned in the
following:
N The total number of blocks in the data embedding area.
Vmax The maximum variance among all block variances.
Vmin The minimum variance among all block variances.
Vmed The median variance among all block variances.
V(x) Among all block variances, V(x) represents a variance which has x
percent of variances less than or equal to it.
ARTICLE IN PRESS
Cover
image
Extract the length of
compressed auxiliary information 
Restore temporary
embedded image
Extract data and
restore cover image
Data
Embedded
image
TH1, TH2, Location map
Embedded_1
Extract compressed
auxiliary information 
Decompress compressed
Auxiliary informationLSBs stream
Fig. 6. The block diagram of extraction process.
J.-Y. Hsiao et al. / Signal Processing 89 (2009) 556–569 563
Author's personal copy
totally different among these images. This implies we
cannot use the same TH1 and TH2 values to produce the
results we wanted for all the images. The block variances
distribution must be considered in determining the TH1
and TH2 values.
For the sake of easy understanding, let us ﬁrst ﬁx TH2
and discuss the properties of TH1. Let us ﬁrst consider the
following special problem which is called a special-1
problem. Let TH2 ¼ 0 and ﬁnd a TH1 value so the
embedding capacity is maximized and the embedded
image quality is also acceptable. The physical meaning of
the above constraint is the same as each block embeds 0
or 6 bits. For an image, when the solution of the special-1
problem is derived, we get an approximate TH1-upper-
bound of the original problem. The reason is if the TH1 is
over the TH1-upper-bound that will cause more blocks
embedded data. Thus, the embedded image quality
declined and the PSNR value will be less than 30. The
experimental results of the special-1 problem are listed in
Table 3. We can see most of the TH1-upper-bounds are
Vmax except for the twomore complex images, Baboon and
Barb.
Another special problem which is called a special-2
problem is as follows: Let TH2 ¼ TH1 and ﬁnd a threshold
so the embedding capacity is maximized and the
embedded image quality is also acceptable. The physical
meaning of the above constraint is the same as each block
embeds 0 or 12 bits. For an image, when the solution of
the special-2 problem is derived, we get an approximate
TH2-upper-bound of the original problem. The reason is if
the TH2 is over the TH2-upper-bound, it will cause more
blocks using the quad difference expansion method to
embed data. Thus, the embedded image quality declines
and the PSNR value will be less than 30. The experimental
results of the special-2 problem are listed in Table 4. We
can see most of the TH2-upper-bounds larger than V(65)
except the more complex image, Baboon.
For each image, we can easily gain the TH1-upper-
bound and TH2-upper-bound by solving the special-1 and
special-2 problems. Then, we can solve the special-3
problem which is TH1 ¼ TH1-upper-bound and TH2 ¼
TH2-upper-bound. The experimental results of special-3
problem are listed in Table 5. The PSNR values in Table 5
are all less than 30. This phenomenon can be easily
explained by the deﬁnition of TH1-upper-bound and TH2-
upper-bound.
To raise the PSNR value to more than 30, we must
reduce the TH1 and/or TH2 values. The experimental
results of maximizing embedding capacity under the
constraints of PSNRX30, TH1pTH1-upper-bound and
TH2pTH2-upper-bound are listed in Table 6. Another
experimental result of maximizing embedding capacity
with the only constraint of PSNRX30 are listed in Table 7.
By comparing Tables 6 and 7, we know there are ﬁve cover
ARTICLE IN PRESS
Table 2
The 3 *3 block variances distribution.
V(x) Image
Tiffany F16 Baboon Barb Pepper
V(0) ¼ Vmin 0 0 0.6666 0.2222 0.09876
V(5) 0.91358 0.39506 8.3950 2 1.3580
V(10) 1.55556 0.6666 13.6543 2.8888 2
V(15) 2 0.8888 19.5556 3.8765 2.6172
V(20) 2.44444 1.2098 26.4691 5.0617 3.1358
V(25) 2.91358 1.5555 35.8765 6.6913 3.8024
V(30) 3.4321 1.9506 47.8025 9.1111 4.5432
V(35) 4 2.4444 64.3951 12.7654 5.3333
V(40) 4.69136 3.1111 86.1728 19.1111 6.2469
V(45) 5.65432 3.8765 115.506 30.1728 7.3333
V(50) ¼ Vmed 6.83951 4.8888 152.889 49.5062 8.6666
V(55) 8.54321 6.3950 196.988 77.2099 10.3951
V(60) 10.8395 8.6913 249.333 110.889 12.5432
V(65) 14.2222 13.1111 312.222 157.111 15.5555
V(70) 19.1111 20.4444 388.247 221.284 19.6543
V(75) 26.3951 33.8765 477.284 314.617 26.2469
V(80) 38.2469 58.5432 589.358 443.062 38.4444
V(85) 58 111.358 737.556 612.321 64.6667
V(90) 101.136 256.099 945.432 825.111 130.889
V(95) 210.667 628.444 1321.14 1072.62 349.802
V(100) ¼ Vmax 10497.1 3244.77 5506.54 5678.54 6286.62
Table 3
TH1-upper-bound ﬁnding (TH2 ¼ 0 & PSNRX30).
Image Measurement
TH1 TH2 Capacity PSNR
Lena Vmax 0 170292 34.5375
F16 Vmax 0 170264 31.9911
Baboon 184.7654 0 125100 30.0036
Barb 559.4320 0 158916 30.003
Pepper Vmax 0 169502 35.0588
Girl Vmax 0 170328 35.0852
Gold Vmax 0 170344 33.2221
Tiffany Vmax 0 169898 36.4506
Boat Vmax 0 170122 31.9648
Toys Vmax 0 169584 34.3960
J.-Y. Hsiao et al. / Signal Processing 89 (2009) 556–569 565
Author's personal copy
over 1 bit/pixel in a single pass and also with PSNR higher
than 30. The experimental results of this kind of image are
given in Table 8. To the best of our knowledge, this
proposed method is the ﬁrst to do that.
In Fig. 10 (Fig. 11), the Lena image (Pepper image) is
used to demonstrate the variation between the embed-
ding capacity and the PSNR value. The experimental
results show for any amount of data bits, our method
derives higher PSNR than Alattar’s method after embed-
ding the same amount of data bits.
In the following experiment, we show the relative
fraction of the beneﬁt brought by the changeable vector
shape, adaptive data bits embedded in various blocks and
the novel auxiliary information embedding method. In the
ﬁrst two rows of Table 9, we show the experimental
results from Alattar’s method with ﬁxed horizontal and
vertical vector directions.
We implement our method with the following condi-
tions to gain the beneﬁt of changeable vector shapes. We
let TH1 ¼N and TH2 ¼ 0 such that all of the blocks are
classiﬁed as normal blocks. Thus, we have no smooth or
complex blocks. We also use Alattar’s auxiliary data
embedding method to replace our auxiliary information
embedding method in this experiment. From the experi-
mental results of Lena image, even though the embedding
capacity is almost the same, we can obtain 1.0806dB
improvement in the embedded image quality when
ARTICLE IN PRESS
0
20000
40000
60000
80000
100000
120000
140000
160000
180000
200000
220000
240000
260000
280000
Le
na F1
6
B
ab
oo
n
B
ar
b
Pe
pp
er
B
oa
t
G
irl
G
ol
d
Ti
ffa
n
y
To
ys
Image
Ca
pa
ci
ty
 (b
its
)
0
10
20
30
40
50
60
PS
N
R
PSNR (Alattar) PSNR (Threshold B)
Capacity (Alattar) Capacity (Threshold B)
Fig. 9. Comparison of Alattar’s method and our method with type B threshold.
Table 8
Embed over 1 bit/pixel in a single pass and PSNRX30.
Image Measurement
TH1 TH2 Capacity Bits/pixel PSNR
Lena 297.580 198.889 303700 1.1585 30.0000
F16 126.321 98.9136 286 488 1.0928 30.0013
Pepper 336.247 173.778 303736 1.1586 30.0012
Girl 483.333 94.1728 278638 1.0629 30.0004
Tiffany 10161.6 203.951 318288 1.2141 30.0061
Boat 133.210 115.556 266724 1.0174 30.0006
Toys 568.469 405.111 305808 1.1665 30.0003 0
20000
40000
60000
80000
100000
120000
140000
160000
180000
30 35 40 45 50 55
PSNR
Ca
pa
ci
ty
 (b
its
)
Alattar Threshold A
Fig. 10. The variation between embedding capacity and PSNR using Lena
image.
0
20000
40000
60000
80000
100000
120000
140000
160000
180000
30 35 40 45 50 55
PSNR
Ca
pa
ci
ty
 (b
its
)
Alattar Threshold A
Fig. 11. The variation between embedding capacity and PSNR using
Pepper image.
J.-Y. Hsiao et al. / Signal Processing 89 (2009) 556–569 567
Author's personal copy
[8] B. Macq, Lossless multiresolution transform for image authenticat-
ing watermarking, in: Proceeding of EUSIPCO, vol. 2000, Tempere,
Finland, September 2000, pp. 533–536.
[9] Z. Ni, Y.Q. Shi, N. Ansari, W. Su, Reversible data hiding, IEEE Trans.
Circuits Systems Video Technol. 16 (3) (March 2006) 354–362.
[10] D.M. Thodi, J.J. Rodriguez, Prediction error-based reversible water-
marking, in: Proceedings of the International Conference on Image
Processing (ICIP’04), vol. 3, Singapore, 24–27 October 2004,
pp. 1549–1552.
[11] D.M. Thodi, J.J. Rodriguez, Expansion embedding techniques for
reversible watermarking, IEEE Trans. Image Process. 16 (3) (March
2007) 721–730.
[12] J. Tian, Reversible data embedding using a difference expansion,
IEEE Trans. Circuits Systems Video Technol. 13 (8) (August 2003)
890–896.
[13] J.H. Witten, M. Radford, J.G. Cleary, Arithmetic coding for data
compression, Comm. ACM 30 (6) (June 1987) 520–540.
ARTICLE IN PRESS
J.-Y. Hsiao et al. / Signal Processing 89 (2009) 556–569 569
2 
 
 
心得報告 
個人是第一次前往歐洲開國際會議，此次會議所發表的論文名稱全銜是 
 
Ju-Yuan Hsiao and Zhi-Yu Xu, A Lossless Image Compression Method with the 
Reversible Data Embedding Capacity, Proceedings of the International Conference 
on Signal Processing and Multimedia Applications (SIGMAP 2009), Milan Italy, 
July 7-10 2009, pp. 27-32  (詳細內容詳如附件一) 
 
本篇論文也是本計劃的產出論文之一，主要內容是提出一個可以適用於無失真
壓縮方法的可回復資訊隱藏方法。 
SIGMAP 2009 會議是在歐洲舉行的訊號處理及多媒體資訊處理及運用的重要
學術會議，來自世界各國的影像及訊號處理專家學者齊聚一堂，交換研究心得
並了解最新的影像及訊號處理技術的最新發展趨勢，參與此次會議讓我更了解
影像及訊號處理領域的研究現況，也讓我的研究觸角可以伸的更廣，實用性也
更加強了。 
 
附件一: Ju-Yuan Hsiao and Zhi-Yu Xu, A Lossless Image Compression Method 
with the Reversible Data Embedding Capacity, Proceedings of the International 
Conference on Signal Processing and Multimedia Applications (SIGMAP 2009), 
Milan Italy, July 7-10 2009, pp. 27-32  全文 
proposed by Chuang and Lin for grayscale images is 
simply illustrated. First, the original grayscale image 
is divided into n×n blocks of which each is treated 
by the lossless compression from left to right and up 
to down individually. Since Chuang and Lin have 
proved that the 3×3 block leads to the optimal 
compression effect, the illustration of 3×3 block is as 
below. The individual 3×3 block is treated by the 
following steps. 
Given a 3×3 block as the subimage A of which 9 
pixel values are 810 ,...,, ggg , see Figure 1. 
0g  1g  2g  
3g  4g  5g  
6g  7g  8g  
Figure 1: Block A. 
Find the minimum i8i0 gm ≤≤=min  and the base 
1ggb i8i0i8i0 +−= ≤≤≤≤ )minmax(  in the block. 
Then compute 80,1,2,...,,' =−= imgg ii . Let 
A′ denote )',...,','( 810 ggg .We obtain 
1max0min −==
≤≤≤≤
bg',g' i8i0i8i0 , so nine-dimensional vector 
)',...,','( 810 ggg  can be treated as a nine-digit 
number bggg )'...''( 810 in the base-b number system. 
For convenience, let 33×V be the collection of all 3×3 
subimage A′ , and the base-set B = {1, 2, 3,…, 
256}. Afterwards, define a function 
BVf ×= ×33 →{non-negative integers} 
),'( bAf = the decimal integer equivalent to the 
base-b number bggg )'...''( 810 ∑
=
×=
8
0
'
i
i
i bg
 
0678 '...))')''((...( gbbgbgbg +×+×+×+×=
⎡ ⎤9log2 bbZ =  represents the number of bits required 
by the binary transformation of ),A'( bf . 
As to achieve the optimal compression effect, 
according to the b-value, there are 3 encoding cases: 
Case (1): 1≦b≦11, the encoding as: 
[ c=0 (1 bit) , b (7 bits) , m (8 bits) , f (Zb bits) ] 
Case (2): 12≦b≦127, the encoding as : 
[ c =0 (1 bit), b (7 bits), m (8 bits), P(min,max) 
(7 bits), f (Zb bits)] 
P(min,max) is used to record the locations of 
minimum (min) and maximum (max) values of A'; 
therefore, there are 9×8=72 combinations. We need 
7 bits to record all situations. The computation of 
P(min, max) is as follows : 
Case 1 : if max<min then 
 P(min,max)=min*8+max+1    (1) 
Case 2 : if max>min then 
 P(min,max)=min*8+max      (2) 
Since the minimum and the maximum of A'  is 0 
and b-1, recording P(min,max) equals to record 2 
pixel values of A' . Therefore, when computing 
),'( bAf , we only need record the residual 7 pixel 
values. Consequently, in this case, it is 
⎡ ⎤7log2 bbZ =  bits rather than ⎡ ⎤9log2 bbZ = . 
Case (3): 128≦b≦256, the encoding as:  
[ c =1(1 bit), the 9 pixel values of the original 
block (9×8 bits) ] 
Following the preceding techniques, the first bit 
value (c) of the compression codes of each block 
indicates that the following bits are either the 
original 9 pixel values or the compression codes. 
     The lossless compression technique proposed 
by Chuang and Lin employs the relation between c 
and b values to neglect c and further compress the 
remaining information. However, this paper employs 
merely the individual block compression technique 
of Chuang and Lin and introduces the reversible data 
embedding technique; therefore, the further 
compression part of Chuang and Lin’s method is 
excluded here. Please see (Chuang & Lin, 1998) for 
the further detail inofrmation. 
2.2 Decompression 
In the decoding procedures, first check the first bit c. 
Suppose c=1, then take the next 72 bits to derive the 
original 9 pixel values in the block; suppose c=0, 
then take the next 7 bits to obtain the b value. There 
are 2 cases under the b values. 
Case 1: 1≦b≦11 
We obtain the values of m and f by taking the 
next 8 and ⎡ ⎤9b2logbZ =  bits, respectively. Then 
represent the decimal integer f as a nine-digit base-b 
number bggg )'...''( 810 . According to 
8
0}'{ =iig  and 
m values, we can derive the original 9 pixel values in 
the block. 
Case 2: 12≦b≦127 
We obtain the values of m, P(min,max) and f by 
taking the next 8, 7 and ⎡ ⎤7b2logbZ =  bits 
respectively. Through the value of P(min,max) and 
Eq.s (1) and (2) we know the positions of the 
minimum and maximum in the block with the values 
0 and b-1. Then represent the decimal integer f as a 
SIGMAP 2009 - International Conference on Signal Processing and Multimedia Applications
28
take the following 72 bits to XOR with X0 and X1 to 
obtain 2 compression codes to be tested. Afterwards, 
we obtain the accurate length of the test codes and 
judge which is the true original codes in accordance 
with the verification conditions prescribed in Section 
3.1. Since we have confirmed that the accuracy of 
the retrieved original codes in the process of 
retrieving data as embedding data, we can obtain the 
original compression code and get the embedded 
data without any problem. As we verify the 
embedded data as 0 or 1, we can obtain the original 
9 pixel values by decoding the original codes with 
the decoding method proposed by Chuang and Lin. 
3.3 XOR Patterns Design 
In the proposed technique, XOR patterns X0 and X1 
are used to be the media of data embedding. 
Apparently, the design of XOR patterns impacts the 
information quantity embedded in the image. A 
good designed XOR pattern decreases the 
opportunity of data cannot be embedded in blocks 
and advanced the whole information embedding 
capacity accordingly. 
Through the experiments, we obtain the 
regularity of the XOR patterns design. The designed 
XOR patterns are able to reduce the opportunity of 
misjudgment during the retrieval of embedded data, 
which leads to the reduced inapplicability of data 
embedding. The longest length of codes is 72 bits, so 
the length of XOR patterns is all 72 bits.  
If there is 1 data bit embedded in a block, it 
demands only 2 XOR patterns X0 and X1. The 
design manner is the different 8th bit and all other 
bits are 0 in X0 and X1. See Figure 3. Such a design 
results from that the 8th bit of X0 or X1 indicates the 
first bit of m part of the compressed codes; 
accordingly, in the reversing process of original 
pixel values of the block, the difference between the 
pixel values of the true original block and the other 
block at the relative position is 128. At this rate, the 
pixel values of the other block may not be within 
0-255. Even though aforesaid values are within 
0-255, there is a huge difference between the 
aforesaid block and its adjacent block, leading to the 
judgment of non-original block. Consequently, most 
blocks are verified to be applicable to data 
embedding in the data embedding stage as to 
increase the embedding capacity.  
If there are 2 data bits to be embedded in each 
block, it demands 4 XOR patterns as X0, X1, X2 and 
X3 . We let the 8th and 9th bits differ of 30 X,...,X  
with the values of 00, 01, 10 and 11. If there are 3 
data bits to be embedded in each block, it demands 8 
XOR patterns as X0,…,X7. At this time, in addition 
to the different 8th and 9th bits, we employ the 
alteration of the first bit because it is the first bit 
responding to part b of the compressed codes. For 
this reason, there is a difference of 64 of the base 
values in the process of retrieving data and reversing 
the original values of the block, leading to the values 
out of 0-255. Even though the values are within 
0-255, there is a huge difference between the 
aforesaid block and its adjacent block, leading to the 
judgment of non-original block.  
If there are 4 data bits to be embedded in each 
block, the XOR patterns are similar to those 
embedding 3 data bits. The alteration of the 1st, 2nd, 
8th and 9th bits is used to construct X0,…,X15. If there 
are 5 data bits to be embedded in each block, it 
demands the alteration of the 1st, 2nd, 8th, 9th and 16th 
bits to construct X0,…,X31. If there are 6 data bits or 
more to be embedded in each block, it extends the 
case of 5 data bits embedding. That is, the alteration 
of the 1st, 2nd, 8th, 9th and 16th bits plus 17th and 18th 
bits to construct the required XOR patterns.  
Figure 3: XOR patterns design schematic. 
3.4 Multi-bits Embedding and 
Extracting 
In this Section, we describe how to extend the 
technique of embedding and extracting 1 data bit in 
a block prescribed in Subsections 3.1 and 3.2 to the 
multi-bits embedding and extracting. 
If there are multi-bits to be embedded in a block, 
the modification of Step 2 of the embedding method 
mentioned in Subsection 3.1 is needed. The steps of 
embedding n data bits in a block are as follows.  
Step 1. If the value c of the block′s compressed code 
to be treated is 1, there is no data 
embedding; if c is 0, then the residual codes 
(b + m+ f or b +m +P(min,max)+ f) are 
processed by Step 2. 
Step 2. If the decimal value of the n-digit to be 
embedded is i,0≤i≤2n-1, the designed Xi is 
  selected to XOR the residual code. 
The result of the XOR operation is the data 
embedded block′s final compression code.  
Step 3. Verify whether the embedded data can be 
retrieved accurately in the process of 
extraction. If it succeeds, we accomplish 
the data embedding process; if it fails, we  
 b(7 bits ) m(8 bits) P(min,max) + Zb or Zb (57 bits ) 
1 X0 0000000 00000000 0000…0000  X1 10000000 
SIGMAP 2009 - International Conference on Signal Processing and Multimedia Applications
30
main reason is Baboon is a complex image. 
Therefore, there are more blocks unable to be 
encoded by the lossless compression (blocks in Case 
3) . Thus, we can not embed data therein. Likewise, 
even the block can be compressed, there are more 
blocks where the data unable to be retrieved 
successfully so that we fail to embed data therein. 
As a result, the entire embedding quantity is 
relatively less. 
As for the performance of the compression ratio, 
when there is only 1 data bit embedded in each 
block, except for the slight advancement of Baboon 
and Pepper, the compression ratio of other images 
are identical with that of the original compression 
ratios. That is, the codes remain the same after we 
embed data. As the embedding capacity increases, 
the codes expand slowly as well. However, the 
speed of the expansibility of the codes is much 
slower than that of the increased data embedding 
quantity. Except for the case that there are 7 data bits 
embedded in the blocks of Baboon. What is 
worthwhile mention is that the compression ratio of 
other images before and after data embedding differs 
within 1% except for that of Baboon when there are 
less than 5 data bits embedded in each block. Based 
on the result, it proves that the designed XOR 
patterns perform well on the advanced embedding 
capacity. 
To sum up, we successfully propose a new 
technique adding the reversible data embedding to 
the lossless compression. The proposed technique 
performs well in the smooth images whereas it fails 
to function well on the complex images concerning 
the information embedding quantity and the 
expansibility of compression codes. 
5 CONCLUSIONS 
This paper employs the simplified Chuang and Lin′s 
method to develop a reversible data embedding 
technique applicable to the lossless compression 
technique. According to the experimental results, 
such a technique performs well on the information 
embedding quantity and expansibility of 
compression codes. As far as we know, this is the 
unprecedented paper that employs the reversible 
data embedding technique to the lossless 
compression. We will dedicate ourselves to the 
reduced compression ratio and the advanced 
embedded information quantity and the further 
research of other reversible data embedding 
techniques of lossless compression techniques. 
ACKNOWLEDGEMENTS 
This work was supported in part by National Science 
Council of Taiwan, R.O.C. under Grant no. NSC 
97-2221-E-018-023. 
REFERENCES 
Alattar, A.M., 2004. Reversible watermark using the 
difference expansion of a generalized integer 
transform. IEEE Transactions on Image Processing 
13(8), pp.1147-1156. 
Celik, M.U., Sharma, G., Tekalp, A.M., Saber, E., 2005. 
Lossless Generalized-LSB data embedding. IEEE 
Transactions on Image Processing 14(2), pp.253-266. 
Chang, C.C., Hsieh, Y.P., Lin, C.Y., 2007. Lossless data 
embedding with high embedding capacity based on 
declustering for VQ-compressed codes, IEEE 
Transactions on information forensics and security, 
2(3), pp.341-349. 
Chang, C.C., Lin, C.Y., 2006. Reversible Steganography 
for VQ-Compressed Images Using Side Matching and 
Relocation, IEEE Transactions on Information 
Forensics and Security, 1(4), pp.493-501. 
Chang, C.C., Lin, C.Y., 2007. Reversible steganographic 
method using SMVQ approach based on declustering, 
Information Sciences, 177(8), pp.1796-1805. 
Chang, C.C., Lu, T.C., 2006A. A difference expansion 
oriented data hiding scheme for restoring the original 
host images. The Journal of Systems and Software 
Vol. 79, pp.1754-1766. 
Chang, C.C., Lu, T.C., 2006B. Reversible index-domain 
information hiding scheme based on side-match vector 
quantization, The Journal of Systems and Software, 
79(8), pp.1120-1129.  
Chang, C.C., Wu, W.C., Hu, Y.C., 2007. Lossless 
recovery of a VQ index table with embedded secret 
data’, Journal of Visual Communication and Image 
Representation, 18(3), pp.207-216. 
Chuang, T.J., Lin, J.C., 1998. A New Algorithm For 
Lossless Still Image compression, Pattern 
Recognition, 31(9), pp.1343-1352. 
Ni, Z., Shi,Y.Q., Ansari, N., Su, W., 2006. Reversible 
Data Hiding. IEEE Transactions on Circuits and 
systems for video technology 16(3), pp.354-362. 
Thodi, D.M., Rodriguez, J.J., 2007. Expansion embedding 
techniques for reversible watermarking. IEEE 
Transactions on Image Processing 16(3), 721-730. 
Tian, J., 2003. Reversible data embedding using a  
difference expansion, IEEE Transactions on Circuits 
and Systems for Video Technology 13(8), pp.890-896. 
SIGMAP 2009 - International Conference on Signal Processing and Multimedia Applications
32
2 
 
 
心得報告 
個人是第一次前往歐洲開國際會議，此次會議所發表的論文名稱全銜是 
 
Ju-Yuan Hsiao and Zhi-Yu Xu, A Lossless Image Compression Method with the 
Reversible Data Embedding Capacity, Proceedings of the International Conference 
on Signal Processing and Multimedia Applications (SIGMAP 2009), Milan Italy, 
July 7-10 2009, pp. 27-32  (詳細內容詳如附件一) 
 
本篇論文也是本計劃的產出論文之一，主要內容是提出一個可以適用於無失真
壓縮方法的可回復資訊隱藏方法。 
SIGMAP 2009 會議是在歐洲舉行的訊號處理及多媒體資訊處理及運用的重要
學術會議，來自世界各國的影像及訊號處理專家學者齊聚一堂，交換研究心得
並了解最新的影像及訊號處理技術的最新發展趨勢，參與此次會議讓我更了解
影像及訊號處理領域的研究現況，也讓我的研究觸角可以伸的更廣，實用性也
更加強了。 
 
附件一: Ju-Yuan Hsiao and Zhi-Yu Xu, A Lossless Image Compression Method 
with the Reversible Data Embedding Capacity, Proceedings of the International 
Conference on Signal Processing and Multimedia Applications (SIGMAP 2009), 
Milan Italy, July 7-10 2009, pp. 27-32  全文 
proposed by Chuang and Lin for grayscale images is 
simply illustrated. First, the original grayscale image 
is divided into n×n blocks of which each is treated 
by the lossless compression from left to right and up 
to down individually. Since Chuang and Lin have 
proved that the 3×3 block leads to the optimal 
compression effect, the illustration of 3×3 block is as 
below. The individual 3×3 block is treated by the 
following steps. 
Given a 3×3 block as the subimage A of which 9 
pixel values are 810 ,...,, ggg , see Figure 1. 
0g  1g  2g  
3g  4g  5g  
6g  7g  8g  
Figure 1: Block A. 
Find the minimum i8i0 gm ≤≤=min  and the base 
1ggb i8i0i8i0 +−= ≤≤≤≤ )minmax(  in the block. 
Then compute 80,1,2,...,,' =−= imgg ii . Let 
A′ denote )',...,','( 810 ggg .We obtain 
1max0min −==
≤≤≤≤
bg',g' i8i0i8i0 , so nine-dimensional vector 
)',...,','( 810 ggg  can be treated as a nine-digit 
number bggg )'...''( 810 in the base-b number system. 
For convenience, let 33×V be the collection of all 3×3 
subimage A′ , and the base-set B = {1, 2, 3,…, 
256}. Afterwards, define a function 
BVf ×= ×33 →{non-negative integers} 
),'( bAf = the decimal integer equivalent to the 
base-b number bggg )'...''( 810 ∑
=
×=
8
0
'
i
i
i bg
 
0678 '...))')''((...( gbbgbgbg +×+×+×+×=
⎡ ⎤9log2 bbZ =  represents the number of bits required 
by the binary transformation of ),A'( bf . 
As to achieve the optimal compression effect, 
according to the b-value, there are 3 encoding cases: 
Case (1): 1≦b≦11, the encoding as: 
[ c=0 (1 bit) , b (7 bits) , m (8 bits) , f (Zb bits) ] 
Case (2): 12≦b≦127, the encoding as : 
[ c =0 (1 bit), b (7 bits), m (8 bits), P(min,max) 
(7 bits), f (Zb bits)] 
P(min,max) is used to record the locations of 
minimum (min) and maximum (max) values of A'; 
therefore, there are 9×8=72 combinations. We need 
7 bits to record all situations. The computation of 
P(min, max) is as follows : 
Case 1 : if max<min then 
 P(min,max)=min*8+max+1    (1) 
Case 2 : if max>min then 
 P(min,max)=min*8+max      (2) 
Since the minimum and the maximum of A'  is 0 
and b-1, recording P(min,max) equals to record 2 
pixel values of A' . Therefore, when computing 
),'( bAf , we only need record the residual 7 pixel 
values. Consequently, in this case, it is 
⎡ ⎤7log2 bbZ =  bits rather than ⎡ ⎤9log2 bbZ = . 
Case (3): 128≦b≦256, the encoding as:  
[ c =1(1 bit), the 9 pixel values of the original 
block (9×8 bits) ] 
Following the preceding techniques, the first bit 
value (c) of the compression codes of each block 
indicates that the following bits are either the 
original 9 pixel values or the compression codes. 
     The lossless compression technique proposed 
by Chuang and Lin employs the relation between c 
and b values to neglect c and further compress the 
remaining information. However, this paper employs 
merely the individual block compression technique 
of Chuang and Lin and introduces the reversible data 
embedding technique; therefore, the further 
compression part of Chuang and Lin’s method is 
excluded here. Please see (Chuang & Lin, 1998) for 
the further detail inofrmation. 
2.2 Decompression 
In the decoding procedures, first check the first bit c. 
Suppose c=1, then take the next 72 bits to derive the 
original 9 pixel values in the block; suppose c=0, 
then take the next 7 bits to obtain the b value. There 
are 2 cases under the b values. 
Case 1: 1≦b≦11 
We obtain the values of m and f by taking the 
next 8 and ⎡ ⎤9b2logbZ =  bits, respectively. Then 
represent the decimal integer f as a nine-digit base-b 
number bggg )'...''( 810 . According to 
8
0}'{ =iig  and 
m values, we can derive the original 9 pixel values in 
the block. 
Case 2: 12≦b≦127 
We obtain the values of m, P(min,max) and f by 
taking the next 8, 7 and ⎡ ⎤7b2logbZ =  bits 
respectively. Through the value of P(min,max) and 
Eq.s (1) and (2) we know the positions of the 
minimum and maximum in the block with the values 
0 and b-1. Then represent the decimal integer f as a 
SIGMAP 2009 - International Conference on Signal Processing and Multimedia Applications
28
take the following 72 bits to XOR with X0 and X1 to 
obtain 2 compression codes to be tested. Afterwards, 
we obtain the accurate length of the test codes and 
judge which is the true original codes in accordance 
with the verification conditions prescribed in Section 
3.1. Since we have confirmed that the accuracy of 
the retrieved original codes in the process of 
retrieving data as embedding data, we can obtain the 
original compression code and get the embedded 
data without any problem. As we verify the 
embedded data as 0 or 1, we can obtain the original 
9 pixel values by decoding the original codes with 
the decoding method proposed by Chuang and Lin. 
3.3 XOR Patterns Design 
In the proposed technique, XOR patterns X0 and X1 
are used to be the media of data embedding. 
Apparently, the design of XOR patterns impacts the 
information quantity embedded in the image. A 
good designed XOR pattern decreases the 
opportunity of data cannot be embedded in blocks 
and advanced the whole information embedding 
capacity accordingly. 
Through the experiments, we obtain the 
regularity of the XOR patterns design. The designed 
XOR patterns are able to reduce the opportunity of 
misjudgment during the retrieval of embedded data, 
which leads to the reduced inapplicability of data 
embedding. The longest length of codes is 72 bits, so 
the length of XOR patterns is all 72 bits.  
If there is 1 data bit embedded in a block, it 
demands only 2 XOR patterns X0 and X1. The 
design manner is the different 8th bit and all other 
bits are 0 in X0 and X1. See Figure 3. Such a design 
results from that the 8th bit of X0 or X1 indicates the 
first bit of m part of the compressed codes; 
accordingly, in the reversing process of original 
pixel values of the block, the difference between the 
pixel values of the true original block and the other 
block at the relative position is 128. At this rate, the 
pixel values of the other block may not be within 
0-255. Even though aforesaid values are within 
0-255, there is a huge difference between the 
aforesaid block and its adjacent block, leading to the 
judgment of non-original block. Consequently, most 
blocks are verified to be applicable to data 
embedding in the data embedding stage as to 
increase the embedding capacity.  
If there are 2 data bits to be embedded in each 
block, it demands 4 XOR patterns as X0, X1, X2 and 
X3 . We let the 8th and 9th bits differ of 30 X,...,X  
with the values of 00, 01, 10 and 11. If there are 3 
data bits to be embedded in each block, it demands 8 
XOR patterns as X0,…,X7. At this time, in addition 
to the different 8th and 9th bits, we employ the 
alteration of the first bit because it is the first bit 
responding to part b of the compressed codes. For 
this reason, there is a difference of 64 of the base 
values in the process of retrieving data and reversing 
the original values of the block, leading to the values 
out of 0-255. Even though the values are within 
0-255, there is a huge difference between the 
aforesaid block and its adjacent block, leading to the 
judgment of non-original block.  
If there are 4 data bits to be embedded in each 
block, the XOR patterns are similar to those 
embedding 3 data bits. The alteration of the 1st, 2nd, 
8th and 9th bits is used to construct X0,…,X15. If there 
are 5 data bits to be embedded in each block, it 
demands the alteration of the 1st, 2nd, 8th, 9th and 16th 
bits to construct X0,…,X31. If there are 6 data bits or 
more to be embedded in each block, it extends the 
case of 5 data bits embedding. That is, the alteration 
of the 1st, 2nd, 8th, 9th and 16th bits plus 17th and 18th 
bits to construct the required XOR patterns.  
Figure 3: XOR patterns design schematic. 
3.4 Multi-bits Embedding and 
Extracting 
In this Section, we describe how to extend the 
technique of embedding and extracting 1 data bit in 
a block prescribed in Subsections 3.1 and 3.2 to the 
multi-bits embedding and extracting. 
If there are multi-bits to be embedded in a block, 
the modification of Step 2 of the embedding method 
mentioned in Subsection 3.1 is needed. The steps of 
embedding n data bits in a block are as follows.  
Step 1. If the value c of the block′s compressed code 
to be treated is 1, there is no data 
embedding; if c is 0, then the residual codes 
(b + m+ f or b +m +P(min,max)+ f) are 
processed by Step 2. 
Step 2. If the decimal value of the n-digit to be 
embedded is i,0≤i≤2n-1, the designed Xi is 
  selected to XOR the residual code. 
The result of the XOR operation is the data 
embedded block′s final compression code.  
Step 3. Verify whether the embedded data can be 
retrieved accurately in the process of 
extraction. If it succeeds, we accomplish 
the data embedding process; if it fails, we  
 b(7 bits ) m(8 bits) P(min,max) + Zb or Zb (57 bits ) 
1 X0 0000000 00000000 0000…0000  X1 10000000 
SIGMAP 2009 - International Conference on Signal Processing and Multimedia Applications
30
