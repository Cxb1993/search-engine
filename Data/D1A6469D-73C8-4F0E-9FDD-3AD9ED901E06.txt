具有膚色適應性的動態手勢辨識系統之 SoC 設計
“SoC Design for Dynamical Gesture Recognition System with Skin Color Adaptability”
計畫編號：NSC96-2221-E-224-084-
執行期間：96 年 8 月 1 日 至 97 年 7 月 31 日
主持人：國立雲林科技大學 電子工程所 許明華教授
一、中文摘要
在第一年計畫中，主要提出可供各種人種
膚色皆能適用的手勢切割系統，本系統以動態
膚色資訊做為使用者膚色取樣與手勢定位的
基礎，並使用高斯分佈模型與最小平方近似解
得到使用者每張 frame 下的手勢膚色分佈空
間，利用該空間做為每張 frame 手勢切割的依
據。因此該手勢膚色分佈空間亦即為目前使用
者的手勢膚色分佈情形，並且可以根據不同的
環境做適應性的調整，所以可改善複雜背景以
及膚色呈現反光或陰影時造成切割破碎的問
題。最後本系統將手勢定位區域之手勢切割結
果與RGB Normalized Color Coordinates (NCC)
與 YCbCr 色彩空間之手勢切割結果做切割品
質比較。而本系統之手勢切割品質皆比 NCC
與 YCbCr 色彩空間之切割品質較佳。
In this projet, we develop a prototyping SoC to
automatically segment the image object of
human hand and analyze the gesture behavior,
which can be operated in real-time for different
color skins. The theoretical study is based on
gesture skin color space that is performed by the
least squares approximations solution and
Gaussian distributed model. In addition, we can
also improve gesture segmentation defacement,
which is caused by a complex background,
shadow effect and light-reflection effect.
Compared with NCC and YCbCr, our proposed
method can achieve more accurate motion
gesture segmentation quality of an image.
二、計畫的緣由與目的
手勢本來就是相當原始且自然的示意方
式，縱然是在語言無法溝通的情況下，藉由手
勢可以表達出許多簡易的訊息。因此有越來越
多以電腦視覺為基礎之手勢辨識系統應用於
人機介面、機器視覺和虛擬實境等方面，進一
步拉近了人類與機器之間的互動與溝通，藉此
將手勢辨識系統應用於教育、醫療、工業、交
通…等方面。在手勢辨識系統中，如何在複雜
背景中仍然能有好的手勢切割品質是一項熱
門的研究議題[1]。除此之外，光線造成膚色呈
現反光或陰影亦是影響手勢切割品質的因素
[2,3,4]。由於手勢切割的品質會直接影響到手
勢辨識的辨識率，所以學者們已提出許多電腦
視覺為基礎（Computer Vision-Based Methods）
方法來改善手勢切割品質。
因此本計畫第一年的目標為提出一種可
適應各人種膚色的動態手勢切割技術，不需透
過手套並在複雜背景環境下，不必人工加以訓
練的方式，系統能自動取得使用者膚色取樣
後，再使用高斯分佈模型(Gauss Distribution
Model) 與 最 小 平 方 近 似 解 (Least square
approximation solution)，模擬出使用者的手勢
膚色空間。如此即可得到適應性膚色空間，能
夠避免手勢呈現反光、陰影以及複雜背景的情
況下所造成的手勢切割破碎。
三、研究方法及成果
無論是NCC或是YCbCr色彩空間，都是學
者預先取得大量各式人種的膚色樣本，將全部
的膚色樣本轉換到該空間上之後，發覺人類的
膚色會集中於某個區域，接著才用方程式將該
區域定義出來。雖然這種膚色偵測能夠廣範的
當偵測出手勢的出現後，要對手勢加以定
位，圖6雖然為破碎的手勢，但是意味著完整
的手勢，會出現在其附近之區域，因此利用
gesture mask與motion skin( MOS )完成手勢定
位。如圖7為手勢定位流程圖。motion skin去除
雜訊再dilation後，就會如下圖8一樣，整張影
像僅會剩下完整的手勢與臉部資訊，只要再
labeling後即會得到一張如下圖9的 ),( yxLa 影
像，在這裡我們使用顏色來代替號碼，在此黃
色部份即為手勢區域。
圖 7 手勢定位流程圖
圖 8 手勢與臉部資訊 圖 9 labeling
接下來再將圖9與gesture mask(圖6)執行
AND運算，即可得知手勢號碼(gn)，如同圖10
所示之黃色區域，在這裡我們用黃色來代表手
勢號碼(gn)，利用 (8)式即可將手勢從圖9萃取
出來，其萃取手勢區域如下圖11黃色部份。最
終的彩色資訊之手勢定位結果如圖12所示。


 
otherwise
gnyxLaifyxI
yxGL
,0
),(),,(
),( (8)
圖 10 取得手勢號碼 圖 11 手勢域區
圖 12 手勢定位結果
取得手勢定位後，只要針對定位區域做手
勢切割即可，不須整張影像進行手勢切割，以
降低運算量。而手勢定位區域可能會包含一部
分背景資訊，為了將手勢與背景分離，我們透
過適應性膚色空間將手勢與背景分離，而手勢
切割的演算法如圖13所示。為了得知當前使用
者的手勢膚色空間，首先必須取得使用者的手
勢膚色取樣，進而利用該膚色取樣模擬出使用
者的膚色，而膚色取樣可以從動態膚色中取
得，因此只要將圖5與圖12做AND運算後，即
可得到圖 14中的使用者之手勢膚色取樣
( SKP )，其數學式如下(9)式，同時我們可以將
圖 14中的每一個pixel對應至RGB色彩空間
中，其所對應的結果如下圖 15 所示。
),(&),(),( yxMOSyxGLyxSKP ero (9)











),(
),(
),(
yxSKP
yxSKP
yxSKP
B
G
R
圖 13 適應性手勢切割流程圖
圖 14 手勢膚色取樣 圖 15 RGB 色彩空間
pixels大致是沿著 L 分佈，越接近 L 的區域其
pixel分佈越密集，反之亦然，而且其分佈範圍
介於 1y 與 2y 之間。所以可將此分佈視同高斯分
佈，如圖22所示，L 就是落於高斯分佈中的平
均值(μ)之處，因此只要再找出兩條與L 平行
的直線 ( 1y 與 2y )即可模擬使用者的膚色空
間，這兩條平行線，即位於高斯分佈的三倍標
準差(3σ)之處。我們已經利用Least squares
approximations solution求得 baxL  ，接下來
只要將 1y 與 2y 求出來，即可得知該 iC 區間的
使用者手勢膚色空間( S )。由於 1y 與 2y 皆平行
於 L，所以 1y 與 2y 之直線方程式僅在常數項與
L 之直線方程式有所不同而已。
因此我們只要計算出 1y 與 2y 之常數項即
可得到手勢膚色空間。首先我們計算上半平面
所有pixels與 L 的平均距離( 1d )，根據高斯分佈
定理，其左半面與平均值(μ)之平均距離會恰
巧等於0.68σ。同理，上半平面所有pixels與 L 的
平均距離( 1d )會等於0.68σ，所以將0.68σ乘上
四倍即是2.72σ，會近似於3σ，如此即可得到
上平行線之方程式 11 4dbaxy  。同時，我
們可以根據高斯分佈模型的對襯性原理，將 1d
供 給 另 一 條 平 行 線 使 用 ， 所 以
12 4dbaxy  ，計算後得到的 L、 1y 與 2y ，
如圖23所示。當我們取得 1y 與 2y 之方程式後，
亦即得到GB平面pixels分佈的上下邊界，至於
左右邊界則是直接使用G值的三倍標準差(3σ)
即可，此即是該G B平面skin pixels分佈範圍，
令其手勢膚色空間之名稱為 jSPD ~1 。經由上述
的方法，可求出 nCC ~1 區間的pixel分佈範圍，
即完成模擬使用者手勢膚色空間，由於篇幅的
因素僅列舉部份區間之膚色空間( SPD )，下圖
24與25為部份區間之 SPD，亦即為粉紅色範圍
所示。其該frame之完整的使用者手勢膚色空
間( S )以(12)式表示：
},,,{ 21 nSPDSPDSPDS  (12)
μ σ 2σ 3σσ2σ3σ
圖22 高斯分佈模型
μ σ 2σ 3σσ2σ3σ
68.042  baxy68.041  baxy
baxL 
圖23 1y 與 2y 在高斯分佈模型之相對位置
+3
σ-3σ
L
圖24 1SPD 圖25 2SPD
當模擬完成手勢膚色空間後，即可使用該
模擬空間( S )做為手勢判斷的依據。因此我們
將圖12的手勢定位圖中的所有pixels皆判斷是
否會符合該模擬空間中，判斷是否符合模擬膚
色空間( S )如(13)式，圖12的手勢定位後之手勢
切割結果，如下圖26所示：


 
otherwise
SzyxGLif
Segment
,0
),,(,1 (13)
圖26 手勢切割結果
四、結論與討論
(一)軟體模擬驗證
最後呈現手勢切割結果，並與NCC、YCbCr
之膚色偵測結果比較其切割品質，由下圖27、
28、29可以看到，手勢會因角度與光線的因
利用該空間做為手勢切割的依據，以完成手勢
切割，同時在操作手勢時，會因為光線而產生
膚色反光與陰影的問題皆能獲得改善，而
YCbCr與NCC色彩空間都無法改善膚色反
光、陰影以及複雜背景的問題，因此本計畫所
發展之手勢切割演算法為一新穎且效果不錯
之演算法。
本研究群的相關研究結果， 97 年發表國
際會議論文 1 篇[9]，96 年發表國際期刊論文 1
篇[10]國內會議論文 1 篇[11]。專利申請中 1
件及國際期刊論文 1 篇等待審核中。
參考文獻
[1] Quan Huynh-Thu; Meguro, M.; Kaneko, M.,
“ Skin-color extraction in images with complex
background and varying illumination,” Sixth IEEE
Workshop on Applications of Computer Vision,
pp.280 – 285, 3-4 Dec. 2002
[2] Moritz Storring, Hans J. Andersen, and Erik Granum,
“Skin colour detection under changing lighting
conditions,” 7th symposium on Intelligent Robotics
System, Coimbra Portugal, 20-23 July 1999
[3] Maricor Soriano, Birgitta Martinkauppi, Sami
Huovinen, ”Skin detection in video under changing
illumination conditions,” International Conference on
Pattern Recognition, vol.1, pp:839 – 842, Sept. 2000
[4] M Soriano, B Martinkauppi, S Huovinen, M
Laaksonen, ” Using the skin locus to cope with
changing illumination conditions in color based face
tracking,” Proc. IEEE Nordic Signal Processing
Symposium(NORSIG), pp.383-386, June 2000
[5] Junwei Han, G.M. Award, A. Sutherland, Hai
Wu, ”Automatic Skin Segmentation for Gesture
Recognition Combining Region and Support Vector
Machine Active Learning” Automatic Face and
Gesture Recognition, pp.237 – 242, April 2006.
[6] L. Gupta, S. Ma, “Gesture-based interaction and
communication: automated classification of hand
gesture contours,” Man and Cybernetics, Part C,
IEEE Transactions on Systems, vol.31, pp. 114-120,
Feb. 2001
[7] N Tanibata, N Shimada, Y Shirai, ” Extraction of Hand
Features for Recognition of Sign Language Words”
The 15th International Conference on Vision Interface,
May, 2002
[8] Berbar, M.A.; Kelash, H.M.; Kandeel, A.A; “Faces and
Facial Features Detection in Color Images” Geometric
Modeling and Imaging--New Trends, pp.209 - 214,
05-06 July 2006
論文發表:
[9] Wen-kai Tsai, Chung-chi Lin, Shyue-wen Yang,
Ming-hwa Sheu, Ching-Lung Su; “Adaptive Motion
Gesture Segmentation” submitted to 2008
International Systems on Embedded Software and
Systems.(accepted)
[10] C.C. Lin, M.H. Sheu, H.K. Chiang, C.J. Wei and C.
Liaw, “A High-performance Architecture of Motion
Adaptive De-interlacing,” IEICE Transactions on
Fundamentals of Electronics, Communications and
Computer Sciences, vol. E90-A, no. 11, pp.
2575-2583, Nov. 2007. (SCI)
[11]朱元昌，陳嘉宏，陳思穎，蔡文凱，許明華，“適
應性動態手勢切割 ”，全國計算機會議，vol.3，
pp.53-62，12月，2007.
