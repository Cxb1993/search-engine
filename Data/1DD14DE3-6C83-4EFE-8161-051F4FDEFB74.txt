 2
knowledge base automatically and find new 
information embedded in documents (Craven 
and Kumlien, 1999). The sources used in the 
study are MEDLINE, UMLS, and DO. They 
are introduced as follows. 
One of the most comprehensive textual 
sources of biomedical information is 
MEDLINE. It contains nearly 16 million 
citations from more than 7300 different 
publications dating from 1950. Biological 
researchers often access MEDLINE abstracts 
or free full-text articles through the PubMed 
database (http://www.pubmed.gov) or the 
information retrieval (IR) system. These 
systems only return documents satisfying 
users’ information needs. It is valuable for the 
biologists to mine information from the 
returned documents. 
Unified Medical Language System 
(UMLS) (Humphreys et al., 1998) provides 
the lexical information needed for processing 
natural language in the biomedical domain. 
There are three UMLS knowledge sources: 
Metathesaurus, Semantic Network and 
SPECIALIST lexicon. From the integrated 
knowledge-based information, we can use it 
to analyze the biomedical documents. 
Disease Ontology (DO) provides a 
controlled medical vocabulary to map human 
disease knowledge between datasets such as 
patient records and large scale genome 
(http://diseaseontology.sourceforge.net). The 
DO has a hierarchical structure and it contains 
12,564 DO terms. DO offers context-free 
concept identifiers to facilitate mapping to 
medical billing codes and is useful for 
extracting relationships between human genes 
and diseases. 
Based on the large-scale biomedical 
corpora, the flowchart of extracting 
gene-relevant knowledge from biological 
literature is shown in Figure 1. 
To attribute the extracted information 
more widely and more exactly, it is useful to 
map the information to the existing databases. 
Consequently, for the given biomedical 
documents, it is fundamental to classify the 
documents into curatable and less interested 
categories for the curators of the databases. 
From these documents, text-mining 
techniques are applied to capture the specific 
relation. For the purpose of linking such 
extracted relations to databases so that they 
can keep up with the fast-growing literature, 
we map these extracted information to the 
standard vocabularies used in databases in the 
last phase, and thus the integration is built. 
We classify the biomedical documents 
automatically first. Then, to achieve the 
objective of extracting gene-relevant 
knowledge from the curatable documents, we 
develop techniques for generating gene 
functions and relating human genes with DO 
terms. The methods are explained in the 
following Method Section. 
 
二、研究方法 
As mentioned in Background and Goal 
Section, given biological documents, we first 
classify them into curatable documents and 
then extract gene-relevant knowledge. We 
divide these research works in three main 
parts; i.e., (1) classification for biological 
documents, (2) extraction for gene functions, 
and (3) annotation for Disease Ontology. 
2.1 Classification System for Biological 
Documents 
In the beginning, we focus on the task of 
classifying documents for GO annotation 
because it is the first step to retrieve curatable 
documents for the biological database 
Biomedical  
Documents 
Classifying as 
Curatable 
Documents 
Data Mining for 
Gene-Relevant 
Knowledge 
Gene Function 
Generation 
Gene-Disease 
Relationship 
Extraction
Integration with 
Biological 
Databases 
Figure 1. The Flowchart of Extracting 
Gene-Relevant Knowldege from Biomedical 
Literature. 
 4
chi-square test of independence. Postulating 
the ranking perfectly reflects the effectiveness 
of the tokens in classification, we then decide 
the number of tokens to be used in SVM 
classification by 4-fold cross-validation. In 
cross-validation, we use the TF*IDF 
weighting scheme. Each feature vector is then 
normalized to a unit vector. We set C+ to ur* 
C- because of the relatively small number of 
positive examples, where C+ and C- are. Then 
we have to find the optimal number of tokens 
and the corresponding SVM parameters C-, 
the penalty constants on negative examples in 
SVMs and gamma, a parameter in the radial 
basis kernel. In the following, "Abstract30" 
denotes the "Abstract" representation with 
top-30 tokens, "CaptionSEM10" denotes 
"CaptionSEM" with top-10 tokens, and so on. 
After feature selection is done for each 
representation, we try to find the best 
combination by the following algorithm. 
Given the candidate representations with 
selected features, we start with an initial 
set containing some or zero representation. 
For each iteration, we add one 
representation to the set by picking the 
one that enhances the cross-validation 
performance the most. The iteration stops 
when we have exhausted all the 
representations or adding more 
representation to the set doesn’t improve 
the cross-validation performance. 
For classifying the documents with 
better features, we run the algorithm twice. 
We first start with an empty set and obtain the 
best combination of the basic three 
representations, e.g., "Abstract10", 
"MeSH30" and "Caption10". Then, starting 
with this combination, we attempt to 
incorporate the three semantic representations, 
e.g., "AbstractSEM30", "MeSHSEM30" and 
"CaptionSEM10", and obtain the final 
combination. 
2.2. System for Gene Function Extraction 
At the previous stage, relevant documents are 
retrieved for database curators. Consequently, 
extracting the useful information from 
documents is a lot of helpful and worthy of 
investigation. As we know, information 
explosion in molecular biology and 
biomedicine is evolving rapidly, and becomes 
one of challenging problems in the new 
information era. How to obtain relevant 
information, for example, gene/protein 
functions, from a large amount of data 
collection is indispensable for bioinformatics 
researchers and experts. 
The overall architecture is shown in 
Figure 3. First, we construct a training corpus 
in such a way that GeneRIFs are collected 
from the Entrez Gene Database and the 
corresponding abstracts are retrieved from 
MEDLINE. "GRIF words" and their weights 
are derived from the training corpus. In the 
project, Support Vector Machines are trained 
using the derived corpus. Given a new 
abstract, a sentence is selected from the 
abstract to be the candidate GeneRIF. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
2.2.1 GRIF Words Extraction and 
Weighting Scheme 
GRIF words represent the favorite vocabulary 
that human experts use to describe gene 
functions. After stop words removal and 
stemming operation, we can retrieve some 
GRIF words. 
As shown in Figure 3, we first generate 
the weight for each GRIF word. Given an 
abstract, the score of each sentence is the sum 
of weights of all the GRIF words in this 
sentence. Finally, the sentence with the 
highest score is selected as the candidate 
GeneRIF. This method is denoted as OUR 
weighting scheme, and several heuristic 
Figure 3. Architecture of Extracting Candidate 
GeneRIF.
Training 
SVMs 
Existing 
GeneRIF in 
Entrez Gene
GRIF words 
Extractor 
Weighting 
Schemes 
Generating 
Training Data 
for SVM 
GeneRIF 
Sentence 
Locator 
Candidate 
GeneRIF 
Corresponding 
MEDLINE 
abstracts 
A New 
Abstract 
 6
(http://www.tartarus.org/~martin/PorterStem
mer/). When tagging DO terms, we treat each 
paragraph of an article as an independent unit 
because different paragraphs usually focus on 
different DO terms. For each paragraph, we 
go through the list of the processed DO terms 
to check whether the paragraph contains any 
DO term. If the paragraph does, we consider 
the paragraph to contain an instance of that 
particular DO term. We label all the 
appearances of DO-terms in the paragraph 
with the DO term’s DO ID. 
2.3.3 DO to Gene Association 
Figure 5 presents the basic concept of our 
DO-to-Gene association algorithm. In Figure 
5, it illustrates one paragraph where there are 
two genes and four DO-term appearances. 
Two genes, g1 and g2, and four DO-terms may 
be the same or different in a paragraph. 
Without loss of generality, we assume there is 
only one DO term in this paragraph, and there 
is a link between each gene and each 
DO-term. We then calculate the scores 
between them. The gene closest to the DO 
term should be associated with the DO term. 
In other words, the shorter the distance 
between a gene and a DO-term is, the higher 
the score. More important DO-terms have 
higher scores. This model is similar to a 
density model where the gene with the highest 
density (i.e., most tightly surrounded by 
DO-terms) will be selected. 
 
 
 
 
 
 
 
 
 
Figure 5. Word Density Relationship between 
Genes and DO-Terms. 
 
Furthermore, we examine DO annotation 
from the perspectives of physics. Shi et al. 
(2005) proposed a gravitation-based model 
for information retrieval (IR). They mapped 
IR concepts to physics concepts (mass, 
distance, radius, etc). We design experiments 
such as gravitation models to study the effects 
based on the gravitation. 
2.3.4 Density Model 
We associate one gene with every DO term 
appearing in a paragraph. We use tf-idf (term 
frequency and inverse document frequency) 
values in IR to represent the importance of a 
DO-term. The DO-to-Gene association 
algorithm is stated informally as follows. 
For each occurrence of a gene in a 
paragraph, we compute the distance 
between the gene occurrence and 
DO-term, and determine the weight of DO 
terms. The shorter the distance is, the 
higher the score, and the higher the tf-idf 
is, the higher the score, too. We then 
average the scores of the gene and each 
DO-term. Finally, we average all gene 
occurrence scores. The gene with the 
highest score is associated with the DO 
term. 
--Δ-------------------------------------------------------
----------------●--------------Δ-------------------------
-----------Δ----------------------------------------------
--------------------------------------------------------○-
--------------------------------------------Δ-------------
 Δ: a DO term     ●: a gene, g1     ○: a gene, g2 
Text Articles 
Gene Name 
Recognition 
Genia 
Tagger 
Stop-word Removal 
Morphological 
Normalization Porter’s 
Stemmer 
DO Term Tagging 
Disease 
Ontology 
Corpus Preprocessing 
Tagged Articles 
DO-Gene Association 
Algorithm 
Report <PMID, DO ID, GENE> 
Figure 4. System Architecture of DO Annotation 
by DO-Gene Association Algorithm. 
Stop word 
List 
 8
Table 5. Comparison of performances on the 139 abstracts 
  CD MUD MBD MBDP 
1 Jelier (Sentence-wise bag of words + Naïve Bayes) 57.83% 59.63% 46.75% 49.11% 
2 Sentence-wise bag of words + SVMs 58.92% 61.46% 47.86% 50.84% 
3 OUR Weighting scheme 50.18% 46.71% 33.47% 38.83% 
4 OUR Weighting scheme + SVMs 56.86% 58.81% 45.08% 48.10% 
5 Combined 59.51% 62.16% 48.17% 51.25%
6 Combined + gene/protein names 57.59% 59.95% 46.69% 49.68% 
7 Combined + BWRatio feature selection 57.59% 59.90% 47.11% 50.08% 
8 Combined + Graphical feature selection 58.81% 61.09% 47.98% 50.92% 
9 Optimal Classifier 67.60% 70.74% 59.28% 62.09% 
10 Baseline 50.47% 52.60% 34.82% 37.91% 
this table, "M30" is the abbreviation for 
"MeSH30", "CS10" is for "CaptionSEM10", 
and so on. 
 
Table 3. Evaluation Results of GO Categorization. 
NU Recall Precision F-score Combination 
0.5332 0.8803 0.1873 0.3089 M10+C10+MS10
 
The result illustrates that adding other 
inferior representations to the best one 
enhances the performance, which implies that 
the inferior ones may contain important 
exclusive information. The cross-validation 
performance fairly predicts the performance 
on the test data. 
To compare with our performance, we 
list the best and median results on the 
genomics classification task of TREC 2005 in 
Table 4. Comparing to Tables 3 and 4, it 
shows our results have overall high 
performance. 
 
Table 4. Best and Median Results for GO Subtask 
on TREC 2005 (Hersh et al., 2005). 
 NU Recall Precision F-score
Best 0.5870 0.8861 0.2122 0.3424
Median 0.4575 0.5656 0.3223 0.4107
 
3.2. System for Gene Function Extraction 
The performance measures are based on Dice 
coefficient, which calculates the overlap 
between the candidate GeneRIF and actual 
GeneRIF. Classic Dice (CD) is the classic 
Dice formula using a common stop word list 
and the Porter stemming algorithm. Due to 
lack of space, we refer you to the Genomics 
track overview for the other three 
modifications of CD (Hersh and Bhupatiraju, 
2003). 
The evaluation results are shown in 
Table 5. The 1st row shows the official run of 
Jelier’s team, the first place in the official 
runs. The 2nd row shows the performance 
when the Naïve Bayes classifier adopted by 
Jelier is replaced with SVMs. The 3rd row is 
the performance of our weighting scheme 
without a classifier. The 4th row then lists the 
performance when our weighting scheme is 
combined with SVMs. The 5th row is the 
result when our weighting scheme and the 
sentence-wise bag of words model are 
combined together. The 6th row is the result 
when two gene/protein name detectors are 
incorporated into the combined model. The 
next two rows were obtained after two feature 
selection methods were applied. The 9th row 
shows the performance when the classifier 
always proposes a sentence most similar to 
the actual GeneRIF. The last row lists the 
baseline, i.e., a title is always picked. 
A comparative study on text 
categorization (Joachims, 1998) shows that 
SVMs outperform other classification 
methods, such as Naïve Bayes, C4.5, and 
k-NN. The reasons would be that SVMs are 
capable of handling large feature space, text 
categorization has few irrelevant features, and 
document vectors are sparse. The comparison 
between SVMs and the Naïve Bayes classifier 
again demonstrates the superiority of SVMs 
in text categorization (rows 1, 2). 
The performance greatly improves after 
introducing position information (rows 3, 4), 
showing the sentence position plays an 
important role in locating the GeneRIF 
sentence. The 2% difference between rows 2 
and 4 indicates that the features under 
sentence-wise bag of words model are more 
informative than those under our weighting 
scheme. However, with only 9 features, our 
weighting scheme with SVMs performs fairly 
well. Comparing the performance before and 
 10
representations and train an SVM classifier 
out of this combination. Evaluation results 
show overall high performance in the project. 
For the gene function extraction, the 
project proposes an automatic approach to 
locate the GeneRIF sentence in an abstract 
with the assistance of SVMs, reducing the 
human effort in updating and maintaining the 
GeneRIF field in the Entrez Gene database. 
The syntactic information is worth 
exploring, since the sentences describing gene 
functions may share some common structural 
patterns. Moreover, how the weighting 
scheme affects the performance is also very 
interesting. We are currently trying to obtain a 
weighting scheme that can best distinguish 
GeneRIF sentence from non-GeneRIF 
sentence without classifiers. 
For the DO annotation, the project uses 
word density and gravitation relationships 
between genes and DO terms to perform DO 
annotation. We propose an automatic way to 
assign a DO term to a gene. We also build 
gravitation models to explore the influence of 
the gravitational force between genes and DO 
terms. The evaluation method will be 
explored in the future. 
 
四、計畫成果自評 
In this project, the explored problems are the 
fundamental and the important issues in the 
biological research domain. Some 
experimental results will be submitted to the 
conferences and journals. They are helpful in 
the biological and the natural language 
processing domains. 
 
五、參考文獻 
Chang, Y.C.I., Hsu, H. and Chou, L.Y. (2002) 
Graphical Features Selection Method, Intelligent 
Data Engineering and Automated Learning, 
Edited by Yin, H., Allinson, N., Freeman, R., 
Keane, J. and S. Hubband, 2002. 
Chang, J.T. and Altman, R.B. (2004) Extracting and 
Characterizing Gene-Drug Relationships from the 
Literature, Pharmacognetics, 14, pp. 577-586, 
2004. 
Craven, M. and Kumlien, J. (1999) Constructing 
Biological Knowledge Bases by Extracting 
Information from Text Sources, Proceedings of 7th 
International Conference on Intelligent Systems 
for Molecular Biology, pp. 77-86, 1999. 
Dayanik, A., Fradkin, D., Genkin, A., Kantor, P., Lewis, 
D.D., Madigan, D. and Menkov, V. (2004) 
DIMACS at the TREC 2004 Genomics Track, 
Proceedings of the Thirteenth Text Retrieval 
Conference, 2004. 
Dutoit, S., Yang, Y.H,. Callow, M.J. and Speed. T.P. 
(2002) Statistical methods for identifying 
differentially expressed genes in replicated cDNA 
microarray experiments, J. Amer. Statis. Assoc. 97, 
pp. 77-86, 2002. 
Fujita, S. (2004) Revisiting Again Document Length 
Hypotheses TREC-2004 Genomics Track 
Experiments at Patolis, Proceedings of the 
Thirteenth Text Retrieval Conference, 2004. 
Hersh, W. and Bhupatiraju, R.T. (2003) TREC 
Genomics Track Overview, Proceedings of the 
Twelfth Text Retrieval Conference, NIST Special 
Publication: SP 500-255, pp. 14-23, 2003. 
Hersh, W., Cohen, A., Yang, J., Bhuptiraju, R.T., 
Toberts, P. and Hearst, M. (2005) TREC 2005 
Genomics Track Overview, Proceedings of the 
Fourteenth Text Retrieval Conference, NIST 
Special Publication: SP 500-266, 2005. 
Hirschman, L., Park, J., Tsujii, J., Wong, L. and Wu, 
C.H. (2002) Accomplishments and Challenges in 
Literature Data Mining for Biology, 
Bioinformatics, 18(12), pp. 1553-1561, 2002. 
Humphreys, B.L., Lindberg, D.A., Schoolman H.M. 
and Barnett G..O. (1998) The Unified Medical 
Language System: an Informatics Research 
Collaboration, Journal of American Medical 
Information Association, 5, pp.1-11, 1998. 
Jelier, R., Schuemie, M., Eijk, C.V.E., Weeber, M., 
Mulligen, E.V., Schijvenaars, B., Mons B. and 
Kors, J (2003) Searching for geneRIFs: 
concept-based query expansion and Bayes 
classification, Proceedings of the Twelfth Text 
Retrieval Conference, NIST Special Publication: 
SP 500-255, pp. 167-174, 2003. 
Joachims, T. (1998) Text Categorization with Support 
Vector Machines: Learning with Many Relevant 
Features, Proceedings of ECML-98, pp. 137-142, 
1998. 
Olsson, F., Eriksson, G., Franzen, K., Asker, L. and 
Liden, P. (2002) Notions of Correctness when 
Evaluating Protein Name Taggers, Proceedings of 
the 19th International Conference on 
Computational Linguistics, pp. 765-771, 2002. 
Shi, S., Wen, J.R., Yu, Q., Song, R. and Ma, W.Y. (2005) 
Gravitation-Based Model for Information 
Retrieval, Proceedings of the 28th Annual 
International ACM SIGIR Conference, pp. 
488-495, 2005. 
Wen-Juan Hou, Jia-Hao Tsao, Li Chen and Sheng-Yang 
Li (2010). Automatic Assessment of Students' 
Free-text Answers with Support Vector Machines, 
Trends in Applied Intelligent Systems: Proceedings 
23rd International Conference on Industrial, 
Engineering & Other Applications of Applied 
Intelligent Systems, IEA/AIE 2010, Córdoba, Spain, 
June 1-4, 2010, Proceedings, Part I. Nicolás 
García-Pedrajas, Francisco Herrera, Colin Fyfe, 
José Manuel Benítez, and Moonis Ali (Eds.), 
LNAI 6096, pp. 235-243, Springer-Verlag Berlin 
Hbeidelberg 2010. 
98年度專題研究計畫研究成果彙整表 
計畫主持人：侯文娟 計畫編號：98-2221-E-003-021- 
計畫名稱：生醫文件中基因與疾病資訊擷取之研究 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 2 0 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 2 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
 
