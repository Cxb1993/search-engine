two-class service differentiation that address the above three challenges. The adaptive 
diffusion is a data-centric path finding (routing) mechanism, which prefers the 
selection of stable and energy-abundant routes. The fast forwarding algorithm handles, 
in low space and time complexity, the content-based table lookup problem. The 
service differentiation enables mission-critical data to be sent in high priority and 
redundancy. Our objectives in this project are to systematically evaluate, validate, 
implement, and integrate the sensor network to the overall home care system – iCare.  
We expect, as a result, to lead the world in the research and development of sensor 
network based intelligent home care system. The expertise built up by the project will 
put Taiwan at a vintage point in the R&D of sensor networks in consumer electronics. 
This will also pave a brand new avenue for System on Chip (SOC) design and inspire 
a new generation of consumer demands for ubiquitous intelligent applications.  
 
 
 
Figure 1. The communication system architecture for home care sensor networks. 
Application-dependent services: urgent and non-urgent Data Dissemination  
Data-centric core: broadcast/adaptive manycast; regular and priority forwarding 
 
 
The task breakdown and project timeline is illustrated in Table 1.  What highlighted 
are tasks completed so far.  We have completed what have been planned for the 
first two years.  In particular, for the service differentiation parts, we are ahead of the 
schedule. 
 
Timeline Tasks Work 
Flow  Adaptive 
Diffusion  Fast Forwarding 
Service 
Differentiation  
Lit. Review  Data-centric delivery  
String search 
algorithm  
Sensor network 
QoS  
 
 
 
1st Year 
Design  Bandwidth 
usage and delay 
analysis 
Protocol 
Specification  
Complexity 
analysis Pseudo 
code  
Data 
prioritization 
for desired QoS 
Mechanism  
Evaluation  ns-2-based simulation  
Implementation 
on Linux-based 
embedded 
systems 
ns-2-based 
simulation  
 
 
 
2nd Year 
Validation  Implementation 
and APIs on 
sensor notes  
Implementation 
and APIs on 
sensor nodes 
Implementation 
and APIs on 
networked 
embedded 
Linux devices  
3rd Year Deployment  Integration and porting of the adaptive diffusion, fast 
forwarding, and service differentiation mechanisms 
to the actual devices  
 
Table 1. Task Breakdown  
 
 
Knowing that the quality of sensor data delivery is not an issue that can be solved 
solely by a well-designed communication protocol suite, our aim in the follow-up 
project is to investigate in depth the environmental, protocol design, and 
deployment factors to the quality of data dissemination in sensor networks.  Our 
premise is to develop, in a three year timeframe, a practical indoor sensor network 
deployment scheme, which may include a set of assistive software/hardware tools.  
The deployment scheme will enable easy deployment of quasi-reliable sensor 
networks in heterogeneous indoor environment.  Our ultimate goal is to complete 
progressively a series of study towards effective sensor network deployment scheme 
for heterogeneous indoor environment: (1) to come to a fundamental understanding of 
the link quality distribution, (2) to perform a network- and MAC-layer protocol 
co-analysis, and (3) to design an effective sensor network deployment mechanism.  
 
[1] Hsing-Jung Huang; Ting-Hao Chang; Shu-Yu Hu; Polly Huang, Magnetic 
Diffusion: Disseminating Mission-Critical Data for Dynamic Sensor 
Networks, In the proceedings of the 8th ACM/IEEE International 
Symposium on Modeling, Analysis and Simulation of Wireless and Mobile 
Systems (MSWiM 2005), Montreal, Qc. Canada, October 10-13, 2005 
[2] Hsing-Jung Huang; Ting-Hao Chang; Shu-Yu Hu; Polly Huang, Magnetic 
Diffusion: Scalability, Reliability, and QoS of Data Dissemination 
Mechanisms for Wireless Sensor Networks, Computer Communications, 
Vol. 29, No. 13,, pp. 2482-2493, Aug. 2006  
[3] Jui-Chieh Wu, Suffix Tree for Fast Sensor Data Forwarding, Master 
Thesis, National Taiwan University, June 2006. 
[4] Jui-Chieh Wu, Hsueh-I Lu, Polly Huang, Suffix Tree for Fast Sensor Data 
Forwarding, Under submission. 
[5] Seng-Yong Lau, Ting-Hao Chang, Shu-Yu Hu, Hsing-Jung Huang, Lung-de 
Shyu, Chui-Ming Chiu, Polly Huang, “Sensor Networks for Everyday Use: 
The BL-Live Experience,” IEEE International Conference on Sensor 
Networks, Ubiquitous, and Trustworthy Computing (SUTC 2006), Industrial 
Program, Taichung Taiwan, Jun. 2006. 
[6] Ting-Hao Chang, Reliable Data Dissemination in Practical Sensor 
Networks, Master Thesis, National Taiwan University, June 2006.  
[7] Tsung-Han Lin, Polly Huang, Hao-Hua Chu, Hsing-Hau Chen, Ju-Peng 
Chen, Enabling Energy-Efficient and Quality Localization Services, In 
the proceedings of the 4th IEEE International Conference on Pervasive 
Computing and Communications (PerCom 2006), Work in Progress Session, 
Pisa Italy, March 2006 
[8] Tsung-Han Lin, Chuang-Wen Yu, Polly Huang, Hao-hua Chu, 
Energy-efficient Boundary Detection for RF-Based Localization 
Systems, In revision to IEEE Transaction on Mobile Computing (November 
2006 submitted, September 2007 revision requested, December 2007 
revision submitted)  
[9] Chuang-wen You, Yi-Chao Chen, Hao-hua Chu, Polly Huang, Ji-Rung 
Chiang, Seng-Yong Lau, Sensor-Enhanced Mobility Prediction for 
Energy-Efficient Localization, In the proceedings of the 3rd Annual IEEE 
Communications Society Conference on Sensor, Mesh and Ad Hoc 
Communications and Networks (SECON 2006), Reston VA, USA, 
September 2006 
 
四、分析與討論之一 — Magnetic Diffusion for Disseminating Mission-Critical 
Data for Sensor Networks 
 
4.1. Introduction 
The technological advances have enlightened a future of intelligent and pervasive 
computing and communication. In that, miniature and robust sensor nodes would be 
able to generate, pre-process, and communicate metrics about the environment. For 
instance, auto-sensing of the room temperature allows tuning of the air conditioning 
to the level just as necessary. Auto-detection of pulse anomalies allows prevention of 
irreversible damages caused by diseases that are preceded by arrhythmia. 
 
Envisioning a new generation of sensor network applications in healthcare , we seek 
mechanisms that provide reliable and timely transmissions of mission-critical data. 
the sensor nodes are likely to run on limited battery power for the ease of deployment. 
Thus, energy efficiency remains an important design challenge. Much of the related 
work in sensor network data dissemination either emphasizes on the energy efficient 
design or the reliable data transfer. We have not yet been able to identify any 
mechanism comparable to the proposed mechanism, magnetic diffusion (MD) that 
aims at achieving timely delivery, reliability, and energy efficiency. 
 
MD is a simple data dissemination mechanism that promises all the above properties. 
The inspiration comes from the magnetic interactions in the nature. Consider the data 
sink as a magnet and the data as nails. The data will be attracted towards the sink 
according to the magnetic field just as the metallic nails being attracted towards the 
magnet. The magnetic field is established by setting up the proper magnetic charges 
on the sensor nodes within the range of data sink. The strength of the charge is 
determined by the hop distance to the sink and the level of resource available at the 
sink. The data will be propagated based on the magnetic field from low to high 
magnetically charged nodes. This way of disseminating data results in optimal delay 
multi-path forwarding. 
 
We are able to observe from the simulation results that MD does 1) perform the best 
in timely delivery of data, 2) achieve high data reliability in the presence of network 
dynamics, and yet 3) work as energy efficiently as the state of the art mechanisms. 
We thus conclude that MD is a promising data dissemination solution to the 
mission-critical applications such as home care and telemedicine. 
 
4.2. Related Works 
The hop-by-hop mechanisms implement the data recovery between two neighboring 
nodes. When a data packet is lost, the intermediate sending node retransmits. In the 
active approach category, several schemes [43][44][45] attempt to improve reliability 
by avoiding congestions. By avoiding congestions, these schemes indirectly lower the 
loss rate and improve the overall reliability. In addition, some schemes [46][47][48] 
avoid losses by selecting less lossy data paths. 
 
Our work is closely related to [49], a multi-path mechanism. This work has suggested 
that disseminating data over multiple paths improves the reliability. The number of 
paths selected in the mechanism depends on the priority of the data and the network 
situation. Our MD is similar to this mechanism in that we also disseminate data over 
multiple paths for reliability. The primary difference is in our choices of the multiple 
paths. Opting for energy efficiency and timeliness of data delivery, we scope our 
choice to all the available shortest paths. 
 
4.2.3 Directed Diffusion 
Directed diffusion [1][2] is a data-centric data dissemination protocol for wireless 
sensor networks. The mechanism achieves energy efficiency by means of selecting 
empirically good paths and in-network aggregation. There are two dissemination 
modes in directed diffusion: one-phase pull and two-phase pull.  
One-Phase Pull (OPP). In OPP, the sink periodically broadcasts an interest 
message to each of its neighbors. The interest message specifies the data the sink is 
interested. The neighboring nodes continue to broadcast the interest message to their 
own neighbors if the interest message is not a duplicate. This action will be repeated 
until all nodes have received the interest message. Then, the source with the matching 
data selects the path of shortest latency according to the interest arrival time, and 
disseminates data to the sink. The data path is periodically refreshed by interest 
messages. 
Two-Phase Pull (TPP). TPP operates in a similar way with a slight 
complication. The sink also periodically broadcasts an interest message to its 
neighbors, and the neighbors operate similarly to those in OPP. The main difference is 
at the broadcasting of exploratory data from the data source to all nodes in the sensor 
network. After the sink receives this exploratory data packet, it reinforces a good path 
back upstream by sending a reinforcement message. This reinforced path is 
determined according to metrics such as delay, loss rate, and available bandwidth. 
The node that receives the reinforcement message acts in the same way and forwards 
the reinforcement message back upstream until the source receives this reinforcement 
message. After that, the source sends data along the reinforced path. 
be re-established automatically. 
Resource Awareness. In the real world, some data sinks might be more 
resource-limited than the others. For example, there could be sink nodes supplied by 
unlimited wall-power, while others run on batteries. By assigning sink charges based 
on the amount of resource at hand, we can achieve the goal of balancing the use of 
heterogeneous re- source and potentially prolonging the network lifetime without 
human intervention. 
 
Figure 2-a. Data move toward magnet (i.e. sink). 
 
Figure 2-b. Multiple paths: multiple nodes with equal charge, s1 < s2 < s3. 
 
Figure 2-c. Load Balancing: multiple magnets attracting nearby nails. 
Figure 2. Illustration of Magnetic Diffusion 
 
In a healthcare example, a patient with chronic diseases may wear biometric sensors 
for long-term monitoring of the patient's body temperature, blood pressure, and heart 
rate. These sensor data need to be collected to a remote patient record server for 
further analysis. When the patient goes outdoors where there are no infrastructural 
sinks, the sensor data need to be transmitted to a resource-limited personal device 
such as the patient's PDA. Through a GPRS interface, the sensor data can be 
transmitted to the patient record server. When the patient comes back home, or 
node records the data type and the magnetic charge into its entry and then forwards 
the interest message to its neighbors. The decrementing magnetic charges from the 
sink to source will guide the flow of data in the reverse direction, mimicing the 
traveral of metallic nails from the low-charge to high-charge points in the magnetic 
field. 
 
If a node receives an interest message and the corresponding entry exists, it will 
compare the decremented magnetic charge of the interest with the one in the entry. If 
the magnetic charge of the interest is greater than the one in the entry, the node will 
update the value in the entry to that of the interest and forward the interests to its 
neighbors. Otherwise, the node will discard the interest knowing the interest is not 
from a node closer to the current sink. The sink node will broadcast interest messages 
periodically to re-establish proper magnetic charges in case of network dynamics. It 
provides a robust environment especially for the dynamic network. 
 
In Figure 4(a), the sink node broadcasts the interest to its neighbor nodes. In Figure 
4(b), both nodes, A and B receive the interest, create corresponding entries, set the 
data type and proper magnetic charges in the entries, and then propagate the interests 
to their neighbors. In Figure 4(c), node C, D, and E receive the interests from node A 
and B and repeat the actions taken by A and B in Figure 4(b). Each node may receive 
and discard duplicate interests or interests of weaker magnetic charges. 
 
 
Figure 4. An example of interest propagation. 
 
4.3.2 Data Propagation 
We next describe how the data is disseminated through a network. We have two 
implementation strategies for data propagation. One is gradient-based and the other is 
broadcast based. 
 
4.3.2.1 Gradient-based 
In the interest broadcast phase, when a node receives an interest from the neighboring 
gradients. The node simply compares the magnetic charges to decide whether to 
broadcast the data. The drawback is every data message will have to carry the 
magnetic charge of the sending node.  
 
Figure 6. An example of data propagation with broadcast-based mechanism. 
 
In Figure 6(a), the magnetic charge of every node is established with the sink having 
change strength 7. In Figure 6(b), when the source wants to send data to the sink, it 
will broadcast the data to its neighbor nodes. In Figure 6(c), the nodes with charge 
strength 6 broadcast the data because the magnetic charge of the nodes is greater than 
that of the data. Thus, the sink receives the data. 
 
4.3.3 Random Wait 
When the interests or data are being broadcast hop by hop through the network, the 
messages might collide to each other. To avoid collisions, the node waits a random 
period of time before sending a message. This technique might decrease the 
probability of collision and, in the meantime, increase the transmission delay. 
 
4.4. EVALUATION 
We have conducted an extensive set of simulations that examines the scalability of 
MD to the size of the network, the change of the data rate, and the level of the 
network dynamics. In this evaluation, we are particularly interested in the 
performance of MD in dynamic networks. Thus, we focus our discussion on the 
quality of data delivery and the message overhead of MD in the presence of network 
dynamics. 
Nodes  50  
Size  160 x 160  
Radio range  40 m  
Data rate  5 sec  
Periodic Interest  30 sec  
MAC  802.11  
we use MDB for the rest of the comparison. 
 
4.4.2 Impact of Dynamics 
To be realistic, we simulated two kinds of dynamics in our experiments. First of all, 
we simulated mobile environment in which nodes moved around every 120 seconds. 
It means that the first movement of each node occurs at 120 seconds. After a node 
moves to its new position, it waits another 120 seconds to move again. The amount of 
time that a node takes to move to its new position varies from node to node because of 
the random new position selection. As a result, the movement of the nodes are not 
simultaneous.  
 
Second of all, we simulated random node on and off according to the following 
probabilistic distribution. At the beginning, all nodes are in the on state for a random 
period between 5 to 65 seconds. Then each node goes into the off state for 25 to 35 
seconds, and wake up again for 55 to 65 seconds. All the on or off time durations are 
uniform randomly selected. and this process will continue until the end of the 
simulations. These sets of simulations are necessary because the two dynamics are 
common in reality. The choices of the parameters represent the extreme cases to 
highlight the distinct properties in MD to the other two mechanisms, DD (See Section 
4.2.3.) and flooding, compared. 
 
4.4.2.1 Overhead 
Figure 7 shows the amount of overhead for the static, mobile, and on-off cases. Note 
that in the static case, all nodes remain static and on for the entire duration of the 
simulations. We show the static case result here to compare to the mobile and on-off 
cases. In Figure 7(a), the interest packet overhead of TPP is slightly higher than that 
of OPP and MD in all cases. This is because TPP has to disseminate additional control 
packets such as the positive and negative reinforcement messages, whereas MD and 
OPP do not. Note that we set the interval of periodic interest to 30 seconds in all 
mechanisms. That is the reason that the interest packet overhead of MD and OPP are 
almost identical. 
Figure 7(b) shows that MD has a lower data packet overhead than that of the TPP and 
a higher data overhead over that of the OPP in all cases. OPP selects only one way to 
disseminate data, and thus has the least amount of data packet overhead. This result 
suggests that, independent of the static, mobile, or on-off case, the resulting data 
packet overhead of TPP's exploratory data is higher than that of the multi-path 
delivery in MD, and that MD is more energy efficient than TPP. It seems that MD is 
worse than OPP in terms of data packet overhead. However, the higher data overhead, 
 
Note that TPP performs worse than OPP in the mobile case. The difference lies in the 
path update frequency. OPP reconfigures data path at the time of periodic interest, but 
TPP does so at the time of periodic exploratory data. The interval of periodic 
exploratory data is twice as much as the periodic interest. Therefore, TPP results in a 
lowest reachability in this case. If we shortened the time of periodic exploratory data, 
there will be a higher reachability, but the data packet overhead will also increase. 
From this set of results, we can see the advantages of MD over OPP and TPP in terms 
of reachability in mobile sensor networks. Note that the reachability of flooding is 
close to 100%. The result suggests that if the data is absolutely critical and energy is 
not a constraint, flooding is the best choice for reliable data dissemination. Otherwise, 
MD provides as a reliable solution for environment that energy resource is limited.  
 
In the on-off case, we observe similar results. But the performance is unsatisfactory., 
Even the flooding mechanism manages only an 85% reachability. This is because of 
the potential of broken paths, or even a disconnected network, when certain 
bottleneck nodes are turned off. Such conditions result in a lower overall reachability. 
However, we think that a good deployment strategy may compensate for such 
situations. 
 
We find that OPP performs the worst in the on-off case. In some sense, the on-off 
type dynamic presents greater challenge to reliable delivery of data and OPP, or 
single-path mechanisms, is less suitable for networks with extreme dynamics. 
 
4.4.2.3 Latency 
Figure 9 shows the cumulative probability of data delivery latency for the static, 
mobile, and on-off cases. In Figure 9(a), MD has the least latency because it 
broadcasts data and bypasses the RTS/CST handshake in IEEE 802.11. This is also 
why OPP performs much worse than MD, even if it always finds the fastest path. 
Flooding is better than OPP and TPP only in the preceding 60%. We observe an 
unusual amount of traffic and collisions in the flooding set of simulations, As a result, 
some data packets get retransmitted repeatedly and routed for a long way to finally 
reach the sink. This explains why flooding has a lot of data packets with long latency. 
TPP is very close to OPP in the preceding 90%, but there is a long tail caused by the 
random wait mechanism in disseminating exploratory data in the later 10%. This plot 
shows that the broadcast-based mechanisms work better for applications with latency 
requirements. 
 
random wait will be a good option. If the latency is more critical, it is more 
appropriate to turn off the random wait mechanism. 
 
Figure 10. Reachability for static, mobile, and on-off case after adding random wait to 
MD and Flooding 
 
 
Figure 11. Latency. 
 
4.5. CONCLUSION 
Inspired by the physics of magnets and nails, we propose magnetic diffusion, a simple 
and yet efficient dissemination mechanism for mission-critical data. MD is able to 
identify all the shortest paths available from the data source to sink. By transmitting 
data over the multiple shortest paths, MD performs well in the timeliness and 
reliability of data delivery while the overhead and energy consumption of MD is kept 
low. These properties are confirmed by the simulations. Therefore, we conclude that 
MD is particularly suitable for sensor network applications in healthcare and 
workplace safety. For these applications, the timeliness and reliability of data, and the 
energy efficiency of the system are all required properties. 
match an incoming data to a particular interest ranges from 10s to 100s milliseconds. 
This processing delay is several orders of magnitudes higher than the propagation and 
transmission delay. 
 
Consider the MicaZ [53] and TinyOS [54] sensor network development platform. The 
packet size limit is 36 bytes. The wireless radio transmits at 100s kbps. The 
transmission delay is thus at the scale of 1s milliseconds. Assume 10 meter radio 
range and 2x108 m/s propagation speed The propagation delay can be found at the 
scale of 0.01s microseconds. The processing delay is evidently the bottleneck of the 
per hop forwarding delay. The interest lookup delay is contributed by 2 levels of 
matching - interest and predicate matching. Each interest may consist of multiple 
predicates. At the higher level, the system needs to identify, among various interests, 
a particular interest that matches the incoming data. At the lower level, the system 
verifies whether a predicate in an interest matches the incoming data. Illustrated in 
Figure 12 are 3 example interests composed by a number of predicates. Interest 1 is 
looking for anything related to the nslab group. Interest 2 looks for data about a 
faculty member whose name is polly, and interest 3 looks for data about all 2nd year 
and above master students. The incoming data in Figure 12 matches both interests 1 
and 2. 
 
Much of the recent work [55][56][57][58] focus on the strategies of structuring 
interests or content types to enable fast interest matching. Their objective is to reduce 
the number of predicate matching required. Our work complements these earlier 
studies in that we focus on improving the efficiency of individual predicate matching. 
 
Predicate matching involves attribute matching and value matching. Attribute 
matching is essentially an exact string matching problem. One common practice to 
speed up attribute matching is to fix the bit position of all possible attributes in the 
data packet as well as the routing table. This method, although simplifies the attribute 
matching process, will be memory and bandwidth consuming when the number of 
different data types is high. When there are different sensors to be added to the 
network, the system will not be easily extendable without changing the packet format 
and interest table data structure. Value matching is also a string matching problem, 
when the data type is string. Depending on the operator of the predicate, value 
matching may require exact or sub-string matching. In essence, the efficiency of 
predicate is determined by the efficiency of the string matching algorithm used. 
For efficient string matching, prior work [7] suggests the use of ternary search tree 
(TST). It is a string matching algorithm with O(|P|+log(N)) time complexity and O(|S|) 
In data-centric communication, digital information are disseminated based on the 
feature/attribute/content of the information itself, not the addresses of issuers or 
receivers. In the first data-centric routing mechanism for wireless sensor networks [1], 
sinks send explicit interest packets to set up routing states at the intermediate nodes. 
These interest specific routing states in turn draw in the data of interest for the sinks. 
Such dissemination scheme relies on well-defined naming system to describe data 
attributes and sink interests. The corresponding naming system and the filter-based 
forwarding mechanism are detailed in [55]. The string matching problem, although 
recognized as the performance bottleneck, is not addressed. 
 
5.2.2. Publish/Subscribe Systems 
In [7][61], the authors design a set of efficient forwarding and routing mechanisms for 
content-based data dissemination. The notion of content-based communication is 
essentially the same as data-centric communication. The mechanisms proposed, 
although descends from the literature of publish/subscribe systems, are applicable to 
sensor networks. There are two different kinds of publish/subscribe systems: 
channel-based and content-based. In both systems, multiple users may subscribe to 
the data of interest. In channel-based systems, the users subscribe to a particular 
channel and the corresponding data broker pushes particular data to the channel from 
which the subscribing users receive the data. In content-based systems, the concept of 
channel is refined as rules and interests, traveling through the intermediate nodes 
between brokers and subscribers. If the rules belonging to some subscribers are 
matched by certain data, the data will be forwarded further to the indicated output 
ports, otherwise the data will be dropped by the node. Much of the improvement in 
rule matching concentrates on the management of the subscriptions, i.e., organization 
of predicates and rules. For instance, index algorithms, used also extensively in 
database management, are adopted by [56] to manage the subscriptions and speed up 
the matching process. 
Other data structures such as button-up selection trees and binary decision diagrams 
are proposed to improve the matching performance by [57] and [58] respectively. 
Little work has addressed formally the problem of string matching. 
 
5.2.3. Ad Hoc Publish/Subscribe Systems 
The close relationship between publish/subscribe systems and data-centric sensor 
networks is first formally noted by [62]. The limited energy, computing power, and 
memory space on a typical wireless sensor node give rise to unique challenges in the 
design of data forwarding algorithms. Authors of [63] found that the interest diffusion 
mechanisms used by general publish/subscribe systems will not be suitable for 
location in the hash table. A string with hash value j will be stored in the jth slot.  
 
Multiple strings might be hashed to the same slot. A simple linked list is used to 
handle the collisions. When a new interest packet is received, the attribute or value 
string will be inserted into the linked list at the corresponding slot. Similarly, when a 
data packet is received, the hash function is applied to obtain the hash values of the 
attribute and value strings. The system then may look up the hash table to see if 
there’s a matching attribute and value, i.e., a matching predicate. 
 
5.3.2. Ternary Search Tree (TST ) 
String search using TST is similar to binary search. In TST, the data structure of a 
node contains a character and 4 pointers. The character is also known as the key for 
string comparison. Three of the pointers are used to track the decendant nodes cl, cm 
and cr, cl leads to substrings that begin with a character alphabatically smaller than 
the key. cm leads to substrings that begin with a character that equals the key. 
Likewise, cr leads to substrings that begin with a character alphabatically greater than 
the key. When a match is identified, one follows the 4th pointer to the matched entry. 
Figure 13 shows the TST after inserting five words: egg, gas, get, aids, and bad. 
Following the principle of binary search, for an incoming string ”bad”, the search path 
on the tree will 
be e → a → b → a → d.  
The TST search algorithm is detailed below in Algorithm 1. To insert a string, one 
search on the existing TST first. From the branch the search stops, the remaining 
substring is attached to extend the TST. Let gdp be a string to be inserted into the TST 
in Figure 13, for example. The search stops at the g node on the right. To this end, 
part of the incoming string, g, is already be matched. To complete the insertion, new 
nodes representing the remaining substring, dp, will be created and attached one by 
one onto the branch. 
 
suffix trie is iteratively inserting the suffixes into the trie from the longest to the 
shortest. The construction cost is O(|S|2) steps, but it is clear that any substring search 
can finish in O(|P|) steps for any input string P. 
 
ST retains this strong suit because it is essentially a compact representation of suffix 
trie. In a suffix trie, each edge carries one character. ST is more compact in that an 
edge on ST may carry a sequence of characters. A suffix trie can be transformed to an 
ST, and vice versa. Figure 14(c) is the ST of Figure 14(b). The pair-wise number on 
each edge denotes the beginning and end indices of the original string. For example 
[2,3] is to indicate the substring from the 2nd character to the 3rd, i.e., ba in the 
example. The numbers on the leaves represent the matched suffix. The curly (green) 
edges are traveled when none of the child matches. In this case, we can declare the 
exact match 
fails. 
 
As for the insertions, we adopt Ukkonen’s online construction [59]. With that, one can 
insert a new string T into ST by gradually adding characters T1, T2, ... , T|T| into the 
data structure without breaking any properties of the original tree. 
Taking advantage of the suffix edges, each insertion can be completed in O(|T|) time. 
This fast construction of ST allows us to build a suffix tree in linear time. We apply 
ST on the attribute and value matching for sensor data forwarding. To enable exact 
string matching, each suffix tree is initialized by adding a special character $, which is 
considered a character that will never appear in any input strings. At the initialization 
stage, the ST, T , begins with an empty string followed by the special character, $. In 
each insertion, an input string Ti will be extended by adding one $ at its end and 
concatenates to the ST set, T . The string Ti$ is then added to the ST structure. After k 
insertion operations, the ST set, T , equals string $T1$T2$...$Tk−1$Tk$. An exact 
search for string P can be achieved by searching the string $P$ in T . Other string 
operations such as prefix and suffix can also be achieved by using strings like $P or 
P$ as input. We apply also a memory requirement reduction technique proposed in 
[60] to improve the scalability of ST in space. 
we use two types of internal nodes, M-type and H-type internal nodes. M-type node is 
the same as internal nodes described in 6.3.3. H-type node uses another hash function 
to map its child nodes to a smaller hash table. The difference between ST and ST+ is 
that ST+ uses M-type nodes when a node is frequently traversed, such as the attribute 
strings, or when the number of its child nodes exceeds a certain threshold. Using these 
two criteria, we classify the internal nodes in ST , and then keep the mapping in the 
critical nodes direct for speed and the mapping in other nodes indirect, i.e., another 
hash table, for space efficiency. 
 
5.4. ANALYTICAL COMPARISON 
5.4.1. Definitions and Operations Description 
 
 Hash  TST  ST  ST +  
search  O(1)  O(|P | + log N )  O(|P |)  O(|P |)  
insert  O(1)  O(|P | + log N )  O(|P |)  O(|P |)  
memory  O(|S|)  O(|S|)  O(|S| + N )  O(|S| + N )  
Table 3. A comparison of theoretical attributes of matching algorithms. 
 
Table 3 provides as a concise overview of the theoretical average search time, 
insertion time and memory space requirement for the algorithms in comparison. We 
will elaborate in this subsection the results presented in the table in detail. The 
terminology in this section and the rest of the paper related to strings are listed below: 
• S: The training word set consist of N strings from S1 to SN, the total word length of 
S is represented by |S| 
• P: The test string, and the length of the string is |P| 
Meanwhile, the operations we would use for fast forwarding are defined as follows: 
• Search exact match through the data structure (exact match): For a input string P, 
search through all the strings in the training set S to see if there’s a string P* that is 
exactly the same as P; If such string exists, then return the index of the string, 
otherwise, the operation returns a search fail notice. 
• Search for prefix/suffix/substring match through the data structure: For a input string 
P, search all the strings in the training set S to see if there’s a set of string {P’} such 
that every strings in {P’} has more than one prefix/suffix/substring that exactly 
matches P. 
• Insertion: Insert a string P into the data structure. 
• Deletion: Delete a given string P from the data structure. In our implementation, the 
prefix/suffix/substring matching are both applying the algorithms listed in [52]. In 
consequences, the performance of these operations thus can analogize to exact match. 
5.5.1. Experimental Environment 
The test environment we use consists both x86 and sensor-based environments. 
1) For x86 platform, we use laptop with Intel Pentium-M 1.4G CPU, 768MB RAM. 
The operating system is Linux with kernel version 2.6.12. The test programs are 
written in C and compiled by gcc v3.4 with optimization flag ”O3”. We randomly 
pick up strings in each word set to form the training sets and test sets. To avoid the 
influence of HDD I/O, the program will load all strings into main memory before the 
insertion and searching procedures start. For time measurement, we use standard 
GNU library functions in < time.h > for general tests and < sys/time.h > for tests that 
need higher resolution data (Execution time is less than 10ms). 
2) For sensor based environment, we use Telos with MSP430 series MCU designed 
for sensor applications [70] , Its correspondent development tool, and benchmark IAR 
Workbench [71] as our test environment. The hardware simulation tool contained in 
the workbench is used to run each test and calculate the number of time cycles 
consumed by each string insertion and search for all three algorithms. The clock cycle 
of the chip is set to 2MHz, and the timer frequency is set to 3.27KHz. 
 
5.5.2. Word Sets 
In consideration of potential functions of real world sensor applications, we choose 
five different word sets in the experiments: 
1) Dictionary word set: Dictionary words that are collecting from free dictionaries and 
word lists. Totally 80000 words. 
2) Technical word set: Frequently used words from the book ”Longman Glossary of 
Scientific & Technical Terms”, totally 1500 words. 
3) Medical word set: Excerpt from the index of a medical sensor textbook, totally 340 
words. 
4) BL-Life word set: Word set which accounts for rooms (for example: office, lab621) 
and elevators’ status such as ”up”, ”down”, ”close”, or ”floor”, and people who are 
using these infrastructure (user names like ”Polly”, ”Tim”, ”Jerry”, ... etc). There are 
totally 50 attributes and values in BL-Life set. 
5) USNames word set: Excerpt the top 20 men’s and womem’s names from statistics 
of the demographic distribution of the United States from 1980 to 1990. The 
USNames word set is divided into men and women names. 
On x86 based platform, word set Dictionary, Technical, Medical and BL-Life are 
used; On sensor-based platform, we only use word set BL-Life and USNames in 
consideration of the limited resource of the system. 
 
5.5.3. Metrices 
Hash and other data structures can reach 1 second level when the number of search 
input reaches 1.5 million. However, in the Wne test, the performance of ST becomes 
better. The rank of performance from this perspective is  
ST ≥ STmemory−improve ≥ Hash ≥ TST . 
3) The search time difference between ST+ and the original ST is less than 5%. 
Experiments show that on general purpose computers, ST+ is viable. 
 
 
Figure 16. Result of exact string search over different word sets and algorithms 
 
 
5.6.2. Insert Time 
1) Insert Time on x86 Platform: The insertion time is the average time to insert one 
string in the training word set into the given data structures (including ST, TST and 
hash table). Our results in Figure 18 show that TST and hash method outperform ST 
in every word set. The memory efficient version of ST uses even more time in 
insertion due to the effort maintaining data structure and tag changes. The difference 
between each method is no more than 10−6 second hence and still tolerable when the 
processing speed of the node is fast enough and attributes do not update too often. In 
truth, each step of suffix tree insertion can be an edge traversing, a single node 
creation or even several suffix link constructions. To insert a character into the suffix 
tree consists one to several operations listed above depending on the input strings, and 
some operations can even use more time than inserting a string into Hash or TST. In 
consequences, ST may consume more time in each loop round then TST and Hash. 
 
Figure 18. Insertion time of different word set and algorithms 
 
2) Insert Time on Sensor-Based Platform: Table 5 shows the average insertion time 
cycles consumed in word set BLLife and USNames tests. The result shows that the 
performance rank of Hash, TST and ST remains the same as the rank on x86 platform. 
All BL-Life word set tests have better performance than USNames word set ones. 
 
 Hash TST ST 
BL-Life  3.25  6.95 11.76 
USNames-mem  3.85  9.45 16.80 
USNames-women 3.95  10.75 11.60 
Table 5. The insertion time of Hash, TST and ST on sensor-based platform. 
 
5.6.3. Memory Consumption 
1) Memory Consumption for x86 Platform: The memory consumption of each data set 
and hash. Unlike Hash method which can still complete search tasks fast under big 
word sets, ST tempt to consume more time on larger word sets. Algorithm of ST 
shows the linear relationship between input string length and search time. The real 
implementation confirms the difference for theory and experiments. The fact reflect 
that in real applications, hardware effect severely contributes to the performance of 
matching process. On sensor-based platforms, different word sets also have different 
search speed. For example, the search time of BL-Life word set in every mechanism 
outperforms the search time of USNames. But the size effect is not obvious. Based on 
our results, we consider that size effect in smaller word set tests are less obvious. 
 
5.7.2. Trade-off Between Memory and Time 
Based on the results, we observed some trade-offs between space and speed. Among 
three data structures, Hash method has the best performance in exact string search. 
But a simple hash table does not contain sufficient information to perform substring 
or super string match. If the given sensor data forwarding system has to process prefix 
suffix or substring matching, other mechanisms should be imported. TST performs 
averagely in the middle of the three algorithms in each test but have long search time. 
ST has long insertion time and occupies large memory space. On the other hand, it 
also has a short exact string search time and an even better search time for non-match 
cases. The weakness of ST is definitely blamed to the large memory space. For small 
word sets, ST, TST and Hash are similar in memory size, but with the word set grows, 
the space requirement of ST dramatically goes up. The memory efficient version of 
ST can reduce 20%-24% memory space and still keeps the search time in our 
experiments when the training word set contains more than 10000 strings, but the 
reduced memory size still large compared to TST and Hash. 
 
However, when we move our test environment to sensor-based platforms, the search 
time rank inverses. Due to the instruction set dependency, modular-based instructions 
takes much longer time on sensor-based platforms. To have better performance, 
hash-based matching method should carefully evaluate the properties of the given 
platform before choosing hash functions. In our experiences, rotation-based hash 
function has the least conflict in average cases, but it takes almost two times longer to 
finish a search than TST. 
 
5.8. CONCLUSION 
We study and evaluate the use of ST for efficient predicate matching for data-centric 
sensor networks. With the proposed memory optimization scheme, we are able to 
implement ST on a sensor network development platform. The experimental results 
 
六、分析與討論之三 — Sensor Network for Everyday Use: The BL-Live Testbed 
Experience  
 
6.1. Introduction 
There have been avid research activities on sensor networks worldwide. Research labs, 
such as Berkeley WEBS and UCLA CENS, have initiated research projects and 
related hardware/software platform development early in 1999-2000. NSF of the 
United States started to call for research proposals in the area of Sensors and Sensor 
Networks in 2003. Early vision on the military use of the sensor networks also 
prompted the establishment of sensor and sensor network related programs in 
DARPA.  
 
It is now 2006. After over 7 years of R&D in sensors and sensor networks, we see 
now sporadic reports of sensor networks for short-term experimental purpose 
[72][73][74]. There lacks still any long-term, everyday-use deployment. We wonder 
why. Is the deployment of sensor networks too difficult or practically impossible? 
Motivated to address this question, we deploy a 30+ node wireless sensor network in 
a university campus building, the Barry Lam (BL) Hall of Electrical Engineering at 
the National Taiwan University main campus. 
 
This project is referred to as BL-Live for that the seemingly cold concrete BL Hall is 
transformed into a lively smart office building. The main objective is to obtain 
practical experience and to discover problems that otherwise will be difficult to 
observe in small-scale test-beds or in simulations. 
 
The sensor network in the BL Hall facilitates two everyday services: 1) Elevator 
Report and 2) Smart Office. The first service reports the status of the slow-paced 
elevators located on two opposite sides of the building. This service allows the 
building residents to select an elevator that will arrive earlier at the floor they desire. 
The second service detects the presence meeting participants in an office. This allows 
automated control of the camera to broadcast publicly the progress of a meeting in the 
office whose door is better off kept closed to conserve energy in the summer. The two 
services, although casual, address real needs of the BL Hall residents. More 
importantly, the two services function as the applications that drive the use of the 
sensor network infrastructure. 
 
To support the Elevator Report and Smart Office services, there involve three major 
system and network components, hardware, sensor networking, and sensor signal 
which elevator will arrive earlier. The purpose of the Elevator Report service is to 
provide continuous status reports of the two elevators including the current level and 
the direction of moving. This will allow the residents to select an elevator that will 
arrive at the floor they desire earlier and to leave offices just in time to catch the 
arriving elevator. 
 
Figure 20. Elevator Report (Left) and Smart Office (Right) Service Web Interface 
 
One sensor node with accelerometer is deployed in each elevator. The accelerometer 
data are taken and analyzed on board. The status derived is transmitted wireless to the 
relay sensor nodes. There are 11 relay nodes deployed on the 4th to the 7th floor of 
the building. These relay nodes forms the sensor network infrastructure and runs MD 
routing to disseminate the status reports to the data sink. The data sink is connected to 
a Web server in a student laboratory on the 6th floor and the status reports are used to 
update the Elevator Report service Web page as shown in the left plot of Figure 20. 
 
6.2.2. Elevator Report 
The BL Hall is equipped with a central air conditioning unit, but it does not cover all 
offices in the building. The corridors are not air conditioned. The north side offices 
from the 6th floor and up are air conditioned by individual air conditioners per office. 
In the meantime, the university advises the meetings between the faculty member and 
students to be kept public. The dilemma is that when there are meetings, the office 
doors will need to be kept open with the air conditioning running. The purpose of the 
Smart Office service is to detect the presence of meeting participants in an office. 
This allows automated control of the in-office camera to take the progress of the 
meeting and broadcast publicly on a flat panel display outside the office. This way, 
the office door can remain closed to conserve the energy in the summer. 
 
A PC-based control center is installed in two offices. One of them is a faculty office 
(6th floor north side) and the other is a student laboratory. Connected to the control 
The most time consuming part is the purchasing step. We need to acquire all the parts 
we need. Before we know what parts to buy, we spent a significant amount of time 
studying the parts and the corresponding functionalities in the bill of materials. 
 
The datasheets are carefully examined to make sure that we order the parts with 
correct footprints. Our attempt purchasing from local suppliers is not successful for 
the reason that most of the suppliers do not take low quantity orders. We have no 
choice but to turn to Digikey , a major electronic component distributor that offers a 
breadth of product lines, provides with online catalogs and accepts low-quantity 
orders. 
 
After getting all the parts ready, the third step is to solder all the parts on the PCBs. 
The components used by Telos are very small and some have special footprints that 
are almost impossible to solder by hand. We take a stencil and toaster oven approach5. 
The idea is to use the stencil to paste the solder paste on the PCB, place the 
components on the solder paste, and melt the solder paste using a baking oven. A 
microscope is necessary to check whether the components are well aligned before 
sending the solderpaste-and-component ready PCB to the baking oven. Temperature 
control is also important. The components will malfunction if they are overheated for 
too long. 
 
Figure 22. The illustration of wireless sensor network 
 
Turn-Out Rate. We clone 50 pieces of Telos. After we produce the hardware, install 
the program, and test, only 5 of them function correctly. Thisnumber is far lower than 
what we anticipate. Hardware debugging is essentially to identify abnormal voltage 
level, resistance level and waveform using the electric multi-meter and oscilloscope. 
Once the abnormal component is identified, we use the microscope to check the 
quality of soldering. Two kinds of problems are common: (1) component placement 
and (2) soldering precision. For example, a 100 ohms resistor is soldered at places for 
Magnetic Diffusion. The ‘Source’, ‘Relay’, and ‘Sink’ nodes form a wireless sensor 
network in the building. To route data through the network, we adopt a routing 
protocol called Magnetic Diffusion. In that, the sink, functioning like the magnet, 
propagates the magnetic charge to set up the magnetic field. Under the influence of 
the magnetic field, the sensor data, functioning like the metallic nails, are attracted 
towards the sink. The magnetic field is established by setting up the proper magnetic 
charges on the sensor nodes within the range of sink. The strength of the charge is 
determined by the hop distance to the sink. In Figure 22, the sink node broadcasts 
interest periodically and then builds a magnetic field upon other source and relay 
nodes. Once the source node detects elevator door opening and has data (elevator 
status information) to send to sink, the data will travel from the low to strong charge 
relay nodes, and finally arrive at the sink which has the strongest charge. 
 
 
Figure 23. Reachability of individual nodes in wireless sensor network 
 
 
Data Reachability. For the evaluation, we deployed two sensor nodes with 
accelerometers in the two elevators and 14 Telos to build the sensor network. The 
nodes nearby the elevator send the data twice for each elevator arrival for better 
reachability. The deployment extends for 4 floors, from the fourth to the seventh. 
Figure 23 illustrates the placement of the nodes in BL Hall. The duration of 
experiment is two hours. During the time, we logged the message received by the sink 
node. 
the elevator ACCELERATING and BREAKING. In between such an up and down 
pair, the elevator is in the MOVING phase. In between the up and down pairs, the 
elevator is in the STILL phase and it stops and opens its door to let people in and out. 
 
The amount of time the elevator stays in each phase is unique for each floor 
movement. We collect the acceleration data of the elevator every 0.5s for hours, 
including periods with heavy and low elevator traffic. There are in total 500 floor 
movements in 3 hours when collecting the acceleration data. According to the time 
the elevator spends in two phases, the ACCELERATING and MOVING phases, we 
can identify well which floor the elevator goes to.  
 
We construct four tables of the maximum values and the minimum values of the 
accelerating time and the moving time for all-pair movements. When the elevator 
finishes an operation, the sensor checks these tables to tell which floor the elevator 
goes to. The system begins on the seventh floor, the initial floor, when the elevator 
stops and opens the door, the sensor would tell which floor it is and send the status out 
of the elevator to a sensor network outside the elevator. Our algorithm can identify the 
floor movement 100%. The four tables also allow us to identify the noises. We create 
90 noises by shaking and lightly jumping in the elevator. 90 noises are all detected. 
 
6.4. Experience and Lessons Learned 
The BL-Live project starts from June 2005. Cloning of the sensor nodes takes about 3 
months. Implementation of the services and sensor network protocols takes slightly 
more than a month of time. Deployment, testing and debugging are the most time 
consuming part. This takes pretty much all the rest of the 9 months. We learn a few 
lessons in manufacturing, choice of hardware, node placement, data delivery, and 
usability. Some lessons rise from the quantitative evaluations of the system 
components; others come from the experience deploying BL-Live hands on. 
Manufacturing Cost. The cost of building this 30+ node sensor network is 
approximately 250,000NTD. The material cost per unit is approximately 2000NTD 
that is lower than the catalog price from all manufactures worldwide. When there is 
demand, the sensor nodes can be mass-produced and assembled automatically. The 
price is expected to drop below 1000NT per unit. We, therefore, think cost is likely 
not the bottleneck commercializing sensornetwork- based products. 
Hardware Platform Choice. The deployment of sensor nodes in a building depends 
highly on the physical structure and material used by the builder. The deployment is 
generally easier in factory-style building where the space is more open and connected, 
as opposed to in office-style and apartment-style where floors, ceiling, walls lined up 
6.5. Summary and Outlook 
With 250,000 NTD material and equipment purchased, 9 month time elapsed, and 6 
graduate student power allocated, we present BL-Live, a 30+ node sensor network 
deployed for everyday services, Elevator Report and Smart Office. Based on our 
experience, we revisit technical issues such as manufacturing cost, deployment, 
communication, energy efficiency, and usability. While we think it is important to 
tackle these technical issues, the current bottleneck is at our ability to identify needs 
and the experience using sensors. 
Without actual deployment and experimentation, the proposed solutions might never 
be practical. Having observed the progress of sensor network R&D over the years, we 
think what lack to advance and commercialize sensor network technologies are 
actions and experience sharing. Thus, with this work, we would also like to advocate 
for more deployment work and an open forum for experience sharing. 
 
[11] Berkeley Wireless Embedded Systems (WEBS), http://webs.cs.berkeley.edu/ 
 
[12] Advanced Technologies and Applications for Next Generation Information 
Communication Network, http://www.ccrc.nthu.edu.tw/excellence/  
 
[13] S. Deering and R. Hinden. Internet Protocol, Version 6 (IPv6) Specification. RFC 
2460. December 1998 
 
[14] Google. http://www.google.com.tw/ 
 
[15] P. Mockapetris. Domain Names--Implementation and Specification. RFC 1035. 
November 1987 
 
[16] C. Cheng, R. Riley, S. Kumar, and J. Garcia-Lunes-Aceves. A Loop-Free 
Extended Bellman-Ford Routing Protocol Without Bouncing Effect. In 
Proceedings of ACM Sigcomm, pages 224--236, August 1989 
 
[17] D. Waitzman, C. Partridge, and S. Deering, "Distance vector multicast routing 
protocol (DVMRP)," Internet Engineering Task Force (IETF), RFC 1075, 
November 1988 
 
[18] L. Breslau, D. Estrin, K. Fall, S. Floyd, J. Heidemann, A. Helmy, P. Huang, S. 
McCanne, K. Varadhan, Y. Xu, H. Yu, "Advances in Network Simulation", IEEE 
Computer, vol. 33, No. 5, p. 5967, May 2000. 
http://citeseer.nj.nec.com/breslau00advances.html 
 
[19] David M. Thompson, “Electromyography (EMG)”, 
http://moon.ouhsc.edu/dthompso/pk/emg/emg.htm 
 
[20] Philip Levis, Sam Madden, David Gay, Joe Polastre, Robert Szewczyk, Alec 
Woo, Eric Brewer and David Culler, “The Emergence of Networking 
Abstractions and Techniques in TinyOS”, Proceedings of the First 
USENIX/ACM Symposium on Networked Systems Design and Implementation 
(NSDI 2004). 
 
[21] Jason Hill, Robert Szewczyk, Alec Woo, Seth Hollar, David Culler, Kristofer 
Pister, “System architecture directions for network sensors”, . ASPLOS 2000, 
Cambridge, November 2000. 
 
[30] Chalermek Intanagonwiwat, Ramesh Govindan and Deborah Estrin, “Directed 
Diffusion: A Scalable and Robust Communication Paradigm for Sensor 
Network”, in Proceedings of the Sixth Annual International Conference on 
Mobile Computing and Networking (MobiCOM '00), August 2000, Boston, 
Massachusetts 
[31] John Heidemann, Fabio Silva, and Deborah Estrin, “Matching Data 
Dissemination Algorithms to Application Requirements”, in Proceedings of the 
ACM SenSys Conference, pp. 218-229. Los Angeles, California, USA, ACM. 
November, 2003. 
 
[32] Seema Bandyopadhyay, Edward Coyle, “An Energy-Efficient Hierarchical 
Clustering Algorithm for Wireless Ad Hoc Networks”, in Proceedings of the 
22nd Annual Joint Conference of the IEEE Computer and Communications 
Societies (INFOCOM), 2003. 
 
 
[33] Ossama Younis, Sonia Fahmy, “Distributed Clustering in Ad-hoc Sensor 
Networks: A Hybrid, Energy-Efficient Approach”, in Proceedings of the 23nd 
Annual Joint Conference of the IEEE Computer and Communications Societies 
(INFOCOM), 2004. 
 
[34] David Braginsky, Deborah Estrin, “Rumor Routing Algorithm for Sensor 
Networks”, in Proc. of the 1st ACM International Workshop on Wireless Sensor 
Networks and Applications(WSNA), Atlanta, GA, September 2002. 
 
[35] Yan Yu, Ramesh Govindan, and Deborah Estrin, “Geographical and Energy 
Aware Routing: a recursive data dissemination protocol for wireless sensor 
networks”, Technical Report UCLA/CSD-TR-01-0023, UCLA Computer 
Science Dept., May 2001. 
 
[36] Ananth Rao, Christos Papadimitriou, Scott Shenker, and Ion Stoica, “Geographic 
Routing without Location Information”, in Proceedings of the 9th annual 
international conference on Mobile computing and networking, San Diego, CA, 
USA, September 14 - 19, 2003. 
 
[37] Hyung Seok Kim, Tarek F. Abdelzaher, and Wook Hyun Kwon, 
“Minimum-Energy Asynchronous Dissemination to Mobile Sinks in Wireless 
Sensor and Ad hoc Communications and Networks, SECON 2004. 
 
[46] Douglas De Couto, Daniel Aguayo, John Bicket, and Robert Morris, “A 
High-Throughput Path Metric for Multi-Hop Wireless Routing”, in Proceedings 
of the 9th annual international conference on Mobile computing and networking, 
MobiCom 2003, pp 134 - 146, September 2003. 
 
[47] Baruch Awerbuch, David Holmer, and Herbert Rubens, “High throughput route 
selection in multi-rate ad hoc wireless networks, in Proc. of the Wireless 
On-Demand Network Systems”, First IFIP TC6 Working Conference, WONS 
2004, January 21-23, 2004. 
 
[48] Medidi, S.R. Vik, K., “QoS Aware Source-Initiated Ad-hoc Routing”, in Proc. of 
the First IEEE International Conference on Sensor and Ad hoc Communications 
and Networks; Santa Clara, CA, USA; October 2004. 
 
[49] Budhaditya Deb, Sudeept Bhatnagar and Badri Nath, ReInForM: “Reliable 
Information Forwarding using Multiple Paths in Sensor Networks”, in 28th 
Annual conference on Local Computer Networks, LCN-2003.n 28th Annual 
conference on Local Computer Networks, LCN-2003. 
 
[50] M. Degermark, A. Brodnik, S. Carlsson, and S. Pink, “Small forwarding tables 
for fast routing lookups,” in Proceeings of ACM SIGCOMM Conference 
(SIGCOMM), 10 1997, pp. 3–14. 
 
[51] D. Estrin, R. Govindan, J. Heidemann, and S. Kumar, “Next century challenges: 
Scalable coordination in sensor networks,” in Proceedings of the Fifth Annual 
International Conference on Mobile Computing and Networks (MOBICOM), 
Seattle, 8, 1999. 
 
[52] R. Zhang and Y. C. Hu, “Hyper: A hybrid approach to efficient content-based 
publish/subscribe,” in ICDCS, 2005. 
 
[53] (2004) Micaz datasheet. Crossbow Technology. [Online]. Available: 
http://www.xbow.com/ 
 
[54] W. Weber, J. Rabaey, and E. Aarts, “Tinyos: An operating system for wireless 
sensor networks,” in Ambient Intelligence, 2005. [Online]. Available: 
Mobile Ad Hoc Networks.” 
 
[66] Knuth D.E., Morris Jr J.H., and Pratt V.R. Fast Pattern Matching in Strings. 
SIAM Journal on Computing 6(1):323-350 1977. 
 
[67]  K. Mehlhorn. Dynamic Binary Search. SIAM Journal on Computing 
8(2):175-198 May 1979. 
 
[68] P. Weiner. Linear Pattern Matching Algorithms. Proc. 14th IEEE Annual Symp. 
on Switching and Automata Theory, pp1-11, 1973 
 
[69] Minglu Li, Xian-He Sun, Qianni Deng, Jun Ni. Grid and Cooperative Computing. 
Second International Workshop, pp. 26 - 33. GCC 2003, Shanhai, China, 
December 7-10, 2003. 
 
[70] Joseph Polastre, Robert Szewczyk, and David Culler. Telos: Enabling Ultra-Low 
Power Wireless Research. ISPN 2005. 
 
[71] IAR Workbench, embedded Development Tools from IAR Systems 
http://www.iar.com/. 
 
[72] Gilman Tolle, Joseph Polastre, Robert Szewczyk, Neil Turner, Kevin Tu, 
Stephen Burgess, David Gay, Phil Buonadonna, Wei Hong, Todd Dawson, 
David Culler, “A Macroscope in the Redwoods,” In Proceedings of the 3rd 
international Conference on Embedded Networked Sensor Systems (SenSys 
2005), San Diego, California, USA, November, 2005. 
 
[73] Robert Adler, Phil Buonadonna, Jasmeet Chhabra, Mick Flanigan, Lakshman 
Krishnamurthy, Nandakishore Kushalnagar, Lama Nachman, Mark Yarvis, 
“Design and Deployment of Industrial Sensor Networks: Experiences from the 
North Sea and a Semiconductor Plant,” In Proceedings of the 3rd international 
Conference on Embedded Networked Sensor Systems (SenSys 2005), San Diego, 
California, USA, November, 2005. 
 
[74] Iuliu Vasilescu, Keith Kotay, Daniela Rus, Peter Corke, Matthew Dunbabin, 
“Data Collection, Storage and Retrieval with an Underwater Optical and 
Acoustical Sensor Network,” In Proceedings of the 3rd international Conference 
on Embedded Networked Sensor Systems (SenSys 2005), San Diego, California, 
Conference Trip Report 
 
Presenter:  
Prof. Polly Huang, National Taiwan University 
Conference Venue:  
Workshop of Internet Measurement Technology and its Applications to 
Building Next Generation Internet in conjunction with IEEE SAINT 2007 
Presentation Topic： 
Path Selection Criteria for Peer-to-Peer Voice 
Co-Authors: 
Cheng-Ying Ou, Chia-Li Huang, Cheng-Chun Lou, Ming-Tsang Tsai, 
Kuan-Ta Chen, Polly Huang 
 
I. Conference Attendance 
IEEE SAINT 2007 is held in Hiroshima, Japan. The conference is a collective 
sessions of special workshops ranging from QoS issues in wireless networks to 
Internet measurement studies.  The total attendance is approximately 200.  The 
attendance of the workshop we participate in is about 40-50.  There are 4 sessions in 
the workshop and in each session there is an invited speech.  Prof. Polly Huang is 
invited to talk on “Path Selection Criteria for Peer-to-Peer Voice”.  Other invited 
speakers includes Prof. Sue Moon of KAIST on “Automatic Signature and Behavior 
Capture for Accurate Traffic Classification” and Dr. Patrice Abry of Physics Lab., 
CNRS UMR 5672, Ecole Normale Supérieure de Lyon, France on “Statistical Sketch 
based Anomaly Detection and Validation using an Anomaly Database.”   
 
II. Visit to Local Institutes 
