1行政院國家科學委員會補助專題研究計畫成果報告
※※※※※※※※※※※※※※※※※※※※※※※※※※
※ ※
※ 以視覺為基礎之先進自動駕駛輔助系統 ※
※ ※
※※※※※※※※※※※※※※※※※※※※※※※※※※
計畫類別：□個別型計畫 □整合型計畫
計畫編號：NSC 96-2221-E-008-019-MY3
執行期間：96 年 8 月 1 日至 99 年 7 月 31 日
計畫主持人：范國清
共同主持人：
計畫參與人員：
本成果報告包括以下應繳交之附件：
□赴國外出差或研習心得報告一份
□赴大陸地區出差或研習心得報告一份
□出席國際學術會議心得報告及發表之論文各一份
□國際合作研究計畫國外研究報告書一份
執行單位：
中 華 民 國 99 年 8 月 31 日
3indeed be integrated to form a
practical driver assistance system.
Keywords: Driver assistance system,
driver behavior analysis,
traffic monitoring, driver
identity verification
二、緣由與目的
交通事故的發生往往帶給人類重大的
危害，例如財物的損失，身體的傷害，甚
至危及生命，同時也消耗了大量的社會資
源，例如警政與醫療等等。依據內政部警
政署之統計資料顯示，有九成以上之肇事
因素皆人為所致，其中“駕駛未保持警
覺”之原因占了最大比率，包括轉頭與鄰
座聊天、駕駛睡眠不足、使用行動電話、
翻閱地圖與抽煙…等。由於交通事故發生
率居高不下，因此研發駕駛輔助系統
(Advanced Driver Assistance System,
ADAS)之必要性與日俱增，若能事先警告駕
駛注意特殊的突發狀況，可預防意外事故
之發生，並且大量增進道路駕駛的安全性。
DAS 之使用目前多半用於高階車種，
其大致分為以下幾種系統：(1)車距分析
(car distance analysis)系統，用來提醒
駕駛保持行車安全距離；(2)道路監控
(lane deviation detection)系統，可預
先使駕駛瞭解路況變化，以作出應變措施;
(3)油門與剎車之監測系統：例如剎車使用
之頻率、車輛的加速度變化，皆用來分析
駕駛是否不專心或疲倦；(4)駕駛狀態分析
(driver status detection)系統，分析駕
駛是否有不專心或疲勞狀態，藉著提前發
出警告訊號(發出聲音或噴水至臉上)，以
減少交通事故發生。
本計劃的目標即為利用視覺的方式將
各種不同類型的駕駛與車輛之行為狀況，
擷取以上述種系統的優點，整合出一套完
整的駕駛輔助系統，以減少肇事率的發
生。本計劃為一三年期之研究計劃，在本
子計畫的第一年中，我們將透過架設在後
照鏡上的攝影機，對車內的狀況進行監
控，會對駕駛進行臉部偵測、追蹤與危險
狀態分析，以便提前發現徵兆，同時警示
不專心、疲勞等駕駛應注意的突發狀況，
預防意外發生。所以此項研究項目的重點
在於，如何準確的找出人險並判斷出其行
為，以利系統提出警告。在這方面的相關
研究包括了：
Rho 等人使用兩台攝影機擷取駕駛臉
資訊[1]，利用 2.5 維之深度資訊、整合兩
幅影像之畫面來計算瞳孔在三度空間實際
位置，藉此減少駕駛需要轉頭觀看照後鏡
之次數，減少危安行為並進行臉部追蹤。
Mabbott 等人分析駕駛之開車動作[2]，利
用架設於車窗內側之監控系統來偵測方向
盤之轉動、排檔變化、煞車之使用頻率、
加速度變化…等資訊，瞭解駕駛是否有不
專心的可能，進而降低危安事故。Qiang 等
人使用機率預測方式去分析駕駛之危險程
度[3]，藉由不形成使用者困擾、不受亮度
影響之紅外光投影於臉上，並錄製連續人
臉，藉由分析頭部移動、眼皮閉合、表情
變化…等資訊，判斷駕駛是否處於疲憊狀
態，提前發出警告訊息。
第二年的研究主要是針對車外的狀況
為主，這部份包括了車道偵測，前車距離
估算，路標偵測及障礙物偵測，在可能發
生意外的情形之下自動的提出警告。主要
是透過裝置在後照鏡上的攝影機，對車輛
前方的區域進行偵測，以提供駕駛週遭的
行車狀況，如其相關研究有: Hilario 等
人利用深度資訊以及的人的輪廓來偵測出
行人[4]，並用建立出的車輛 MODEL 來偵測
出 車 輛 [5] ， Fu 等人 [6] 利用 Hough
transform 來找出車道線，在分別利用特
徵抽取與後車燈在顏色空間分佈的特性，
分別偵測出日間與夜間的車輛，最後利用
計算出 vanish point 來估測出前車距離。
第三年的研究主要是在安全性上的考
量，如何提高安全性和增加駕駛輔助系統
的應用，在此會著重在對駕駛作人臉辨識
已確認是否為授權之駕駛，所以這方面的
相關研究有： Chien 等人 [7]是利用
waveletface 取代 eigenface，再加上
nearest feature classifiers 做辨識的
工作。Cevikalp 等人.[8]是利用 common
vectors 做辨識。Perlibakas [9]利用
Hausdorff distance 對臉部影像的邊緣資
訊(edge)做比對。Oh[10] —是利用 PCA 再
5但 是 上 述 的 方 法 容 易 受 到 光 線 等
apperance 的因素影響，為了增加系統的
穩 定 性 ， 我 們 採 用 AAM(active
appearance model)的方式將五官給定義出
來，所謂的 AAM 是指將要 training 的影
像，標出所謂的控制點，這些控制點通常
為臉的輪廓，之後經過 PCA(principal
componentanalysis)的方式將其重新表示
之後每張影像經由 WARP 到 mean shape 上
(作 shape-normalize)，即可簡化一張影像
的灰階資訊，進而得到 AAM 的表示式，圖
四為人臉五官切割的結果。之後將兩眼跟
鼻子連成三角形，我們將利用此三角形做
下一階段的駕駛行為分析。
圖四 人臉五官切割結果
2. 行為分析模組
此一模組的目的為透過前一模組所得
到三角形，在此一階段做駕駛行為分析，
目前系統暫時定義了五種行為模式，圖五
為此模組的流程圖，一旦發現駕駛處於以
下的狀態，系統將會自動發出警告。
圖五 駕駛行為分析流程圖
(1) 遮蔽類：即駕駛的臉被遮蔽，我
們在偵測遮蔽的情形上，是利用一旦發現
候選臉寬僅為臉高的一半(0.6 至 0.75
倍)，即表示部分遮蔽(partial occlusion)
可能發生，導致偵測不到鼻子，此時系統
藉偵察眼(耳)區域是否存在，作為臉部判
定的標準。
(2) 轉頭聊天類：轉頭與鄰座聊天也
是造成事故發生的原因之一，轉頭的判斷
方式與遮蔽類的判斷方式類似，因為一旦
發生轉頭聊天，則系統必定偵測不到眼(耳)
區域，為了避免系統發生誤判，我們一樣
以續連三幅畫面偵測不出眼(耳)與鼻子，
即表示駕駛處於轉頭狀態，系統將發出警
告訊息。
(3) 疲勞類：駕駛的疲勞與否，也是
一項重要的決定因素，我們判定疲勞的方
法為，偵測駕駛正面的瞳孔，一般在疲勞
狀態下，像是打瞌睡，其瞳孔必定偵測不
到，所以我們判定之方式為，相鄰之連續
三幅畫面皆為正面人臉、且偵測不到左右
瞳孔之存在，系統便判定駕駛正因疲勞而
打瞌睡。
(4) 手機類:我們用來偵測是否在使用
手機的方法為，藉由尋找左、右手之膚色
資訊來分析駕駛是否使用手機，若候選臉
之左下角或右下角連續出現兩幅不包含臉
部資訊之小膚色區塊(依照測試後，手部定
義為 0.3 倍之候選臉大小)，便判斷不當使
用手機。
(5) 低頭類：伸手取物、點煙、看地
圖⋯等等，也是發生事故之主因之一，因
為這類行使駕駛對於緊急狀況缺乏應有的
心理準備。為了減少誤判發生，我們定義
連續兩幅影像之眼睛(耳朵)位置低於畫面
下緣十分之一處，才判定為低頭類危安事
件。
在第一年的工作中，我們設計了一個
完整的安全駕駛監控系統，對小型車內的
駕駛人臉進行偵測、追蹤與各種危險行為
分析。第二年是針對車外的狀況進行監
控，這部份包括了車道偵測，路標偵測及
障礙物偵測，在可能發生意外的情形之下
將自動的提出警告。工作成果分述如下。
A. 車道偵測
本研究所提出的車道自動偵測系統，
在前處理上將運用各種影像處理技術來尋
找 車 道 線 , 如利用型態學影像處理
(Morphology operation)抽取車道特徵外，並
將提出一種群聚(clustering)搜尋的方式,以
車道角度(orientation)與單位面積的特徵密
7道部分，這裡我們可以利用馬可夫模型的
方法找出可能為車道的部分：
 
圖七展示了我們的成果,不論在各種
路面或天氣狀況下,我們的方法都有穩定
的效果。
圖七：車道線偵測成果
B. 行人偵測系統
行人偵測在許多應用中扮演著重要的
角色，尤其是自動車輛的安全駕駛輔助系
統。這是一個富有挑戰性的題目，因為人
體的動作有很大的變化性。本系統可在移
動的車子上進行行人偵測。我們只用一支
攝影機即完成整個行人偵測的過程，且準
確率高、執行速度快。系統的架構包含了
行人偵測模組和追蹤模組。在行人偵測模
組中， 我們整合了AdaBoost (Adaptive
-Boosting) 和樣板比對法。首先，我們利用
AdaBoost 方法訓練我們的行人偵測分類
器，在影片中利用此分類器挑選看起來像
人的區域。第二，針對這些區域來比對行
人的形狀驗證是否出現行人。行人偵測的
結果如圖九在追蹤模組中，我們採用
CAMSHIFT(Continuous Adaptive Mean
Shift) 追蹤演算法來追蹤行人。如圖十所
示，實驗結果顯示此系統能夠接近即時的
處理並且在複雜背景下擁有高度的準確
率。測試的影片解析度為320 x 240 每秒30
個畫面，行車平均速度每小時40 至50 公
里。由實驗可證實本系統所提出行人偵測
的方法是可行且有效的。
C. 路標偵測系統
本系統提出一個對擷取道路牌上強而
有效的新特徵，使用顏色的資訊來對高速
公路上的道路牌做定位，並結合邊的資
訊，自動偵測道路牌上的文字。主要的架
構可分為三個，第一個步驟，利用顏色和
不同物質具有不同傳導係數的特性，配合
類神經網路的訓練，將路牌和其他的物質
分開；第二個步驟，加入仿射（affine）矯
正，將照相機在不適當的拍攝角度，所拍
得的變形道路牌復原回來，使道路牌上的
文字正對著相機，增加框選文字的正確性；
第三個步驟，利用Canny 邊緣偵測來取得
邊的資訊，藉此在每一個道路牌上框出文
字的候選區。圖八展示了我們的系統成果。
1. 顏色特徵
我們從N 張的道路牌和非道路牌影像中擷
取出R、G、B 的顏色分佈，進而得到相對
應的協方差矩陣Σ。利用Karhunen-Loeve
轉換，我們得到協方差矩陣Σ的特徵值iλ
和特徵向量ei (i =1, 2, 3)。接下就可以定義
三個新的顏色特徵如下：
如 此 我 們 可 以 分 別 利 用
(0.49038,-0.156904, -0.352716) 、
(0.122318,-0.489759,0.387924) 和
(-0.339572, -0.339225, -0.321204)三個
向量將每一點像素(R,G,B)投影，來得到全
部的顏色特徵。我們提出的顏色模型
9圖十：行人追蹤結果
第三年的工作為駕駛者身份辨識與系
統整合。本計劃除了提供駕駛的輔助之
外，還必須確保車輛的安全避免其失竊，
所以我們將每隔一小段時間，便將偵測到
的駕駛者人臉影像跟資料庫中的人臉做比
對，一旦不屬於授權的使用者，將直接產
生警告訊息並觸發後續處理機制，例如自
動通知有關單位或是強制將引擎熄火，同
時也將此可疑之人臉影像保存在資料庫中
供日後的查詢使用。本工作的困難度在於
人臉的比對，在一般我們在作人臉辨識的
的情形下，取得的人臉影像都是正面的，
但是由於是在車內駕駛的情況，可能會有
臉部旋轉的問題，造成辨識上的不便。因
此，如何偵測出不同角度進行人臉方位校
正，並正確的比對人臉的影像便是這一年
度的研究重點。
我們將研究內容與成果分為三大部
分：(一)頭部與人臉偵測模組；(二)正面
人臉擷取模組；(三)人臉資料庫訓練與比
對模組。茲分述各項工作成果如下：
(一)頭部與人臉偵測模組
本系統主要分為兩個部分，整個系統
架構如圖 11 所示。
圖 11：正面臉部抽取與辨識之流程圖
第一部份為頭部的偵測及追縱系統，
根據事先所建立的背景影像，利用背景相
減法估計出前景物的位置及形狀，再根據
物體形狀判斷及膚色區域判斷出頭部的位
置。結果如圖 12：
(a) (b)
11
圖 15：(a)垂直投影直方圖;(b)人臉轉動方
向判斷
圖 16：左右轉動
圖 17：轉動加上仰俯情形
(b) 平面旋轉(rotation)：
我們利用一種稱為”放射狀樣板
(radial template)”的樣板來偵測判斷人
臉正面旋轉角度（延著中心點旋轉）。我
們先將人臉特徵資訊濾出，接著將樣板放
在人臉的中心位置，並且統計出其的直方
圖分佈圖。直方圖中 x 軸表示放射狀樣板
的區塊從 0 至 15 逆時鐘方向旋轉，y 軸
代表此區塊中所累積的特徵值點數。利用
人臉特徵套進此樣板來看，放射狀直方圖
的弧度將會行成三個相對最高峰以及三個
相對最低谷，此三個高峰即代表人臉中最
重要的三個特徵：左眼、右眼、嘴巴。當
人臉隨著順時針或逆時針的旋轉，利用放
射狀樣板所統計出來的直方圖將會隨著旋
轉角度穩定的水平左右移動，並且直方圖
的弧度依舊保留著顯現臉部特徵的特性。
圖 18 為放射性樣版與其直方圖。圖 19 為
平面旋轉之實驗結果。
圖 18：放射性樣版與其直方圖。
圖 19：平面旋轉判斷實驗結果
(c)俯仰偵測( bending & lifting )：
此部份為判斷人臉是否有過大的抬頭
仰角及低頭俯角，因為小角度的俯仰將比
較不影響人臉的識別度，故本系統將找出
異常過大的俯仰情形。先判斷出人體脖子
位置線，配合頭部及人臉特徵出現的相對
位置關係，來估計俯仰的情形是否有發生。
根據正常的俯仰角度，頸部位置線（下
圖中黑線部份）皆位於頭部方框的下部範
13
圖 24：三方向旋轉判斷流程
首先是利用「轉動」(turning)來作為
第一步的檢驗，因為此旋轉方向是為常見
的轉動，故我們利用所找出的特徵集中線
(右圖中綠線)與臉部方框的中心線差距作
為距離值(distance)，其中
旋轉率 turning rate =
距離/臉部邊界寬度(box width
而本實驗將旋轉率作為判斷門檻值，
設為 0.25，以此門檻值可先行過濾掉大部
份旋轉過大的人臉影像。
第二步利用「平面旋轉」(rotation)
偵測來找出人臉延著畫面平面旋轉的角
度，以常見的可能旋轉角度大概從 0 度至
正負 45 度，而此實驗中我們所設定的門檻
值為 22.5 度，意即超過正負 22.5 度旋轉
的影像將被此步驟所濾掉。經過前兩部份
的計算及門檻值的過濾，所留下的影像大
部份皆為偏向正面且左右較為對稱的人臉
角度，而再根據第三部份判斷人臉的「仰
俯」(Bending & Lifting)程度，而若人臉
俯仰程度過大即直接濾掉，若是些微的俯
仰角度則將該影像作標記，作為接下來處
理程序的正面評斷計分標準的依據。
根據前面的流程，可以留下幾個幾似
正面的人臉影像，為了更精準的計算出些
微的轉動差距及找出最佳正面的影像，此
節將判斷出左眼右眼所在的位置，來對人
臉影像作更進一步的計算。利用人臉五官
左右對稱特性，再根據前述所處理出的特
徵影像來看，對此影像作水平累計投影
後，在眉毛眼睛及嘴巴的位置，皆會形成
相對的最高峰。而將人臉所在之位置分為
上半部及下半部各別搜尋最高點，可以快
速的判斷出眼睛及嘴巴所在的高度(Y 軸)
資訊。而至於左右眼的 X 軸位置可以利用
垂直投影的方法，在左右臉範圍中各別搜
尋其最高點，再配合 Y 軸資訊，即為找出
眼睛位置。靠著前述的旋轉判斷，我們所
留下處理的影像皆為較偏向正面角度的人
臉影像，故此節可以很方便的利用區域位
置資訊將影像分為上下半部及左右半部個
別處理，而處理出的眼睛嘴巴位置也因此
可以快速的得到正確資訊。而有了正確的
眼睛及嘴巴位置資訊，即可將此資訊作為
接下來處理程序的正面評斷計分標準的依
據。
接下來將說明如何偵測人臉左右部份
的對稱程度，本系統將對稱度分為兩部
份，第一部份計算人臉特徵分佈的左右對
稱性，第二部份則計算人臉亮度資訊的左
右對稱性。
在第一部分，主要的目的為計算左右
臉結構性的對稱程度，例如左眼及右眼（或
嘴的左右）所產生的特徵對稱性。 輸入影
像如前述，利用膚色及邊緣資訊統計出之
影像，如圖 25。
圖 25：利用膚色及邊緣資訊統計出之影像
為了符合結構性及區域性分佈，系統
將影像分為三部份區域分別計算其個別區
15
圖 27：人臉資料庫之訓練流程
本計畫所使用之人臉辨識系統所要框
取的部份分成 5 個區域。這 5 個區域是：
第一個是左眉毛加右眉毛、第二個是左眼
睛加右眼睛、第三個是左眉毛加左眼睛、
第四個是右眉毛加右眼睛、第五個是嘴巴
部分，如圖 28 所示:
圖 28：人臉辨識區域
如圖所示，是利用眼睛加上眉毛一起
框取區域。不只取單一眼睛或眉毛部份的
原因是因為在框取好區域後，我們還要做
resize 的工作，統一 resize 成相同大小，
對於所有影像我們將其做小波轉換，並取
其 LL 的成分做為輸入。
如果只取單一眼睛或眉毛，會比較難
以表示出此特徵在臉部上的區域性(大
小、位置)，所以我們把眼睛和眉毛兩個特
徵組合在一起，利用兩個特徵相對的大
小、位置去表示特徵區域。圖 29 為眼睛與
眉毛之偵測結果。找到眼睛的位置後，再
根據眼睛的位置和兩眼之間的距離去框取
除了嘴巴以外的其他四個區域。
圖 29：眼睛與眉毛之偵測結果
嘴巴的偵測我們利用 Self Quotient
image ， 先 找 到 臉 部 區 域 ， 再 利 用
IPF(Integral projection function) 與
VPF(Variance projection function)找出
嘴巴之中心點。其結果如圖 30 所示：
圖 30：框取嘴巴之結果
在做人臉辨識時特徵的擷取是很重要
的 ，如何去在高維的資料群中做分類並擷
取特徵是一個重要的課題，在此方面有很
多方法像 Pricipal component analysis
(PCA)， Linear discriminant Analysis
(LDA)等。LDA 和 PCA 都是要去將一群高維
的資料找到一個主軸，將這群高維資料
project on 這個主軸能將此群資料分類開
來，另外這個這個主軸會是這群高維資料
空間的 subspace 也就是說當這群高維資
料 project on this subspace 時所得到的
17
分析。而後續的五種危安行為處理，除了
常見之疲勞偵測與遮蔽分析，本系統亦添
加轉頭聊天判斷、手機使用以及駕駛是否
低頭等分析。希望可以藉著本系統，在意
外發生前，可提前發現徵兆，並警示不專
心、疲勞之駕駛注意突發狀況，預防意外
發生，以降低事故發生率。當系統偵測出
目標區有人臉時，立刻做五官定位及駕駛
行為之分析，判斷駕駛目前的狀態，來達
到安全駕駛之目的。而當前的系統中可清
楚的看到，由我們提出的方法，可以正確
的偵測出人臉，定出五官的正確位置，但
是於行為分析這此部分中是以規則為基礎
(rule-based)的方式來分析，只定義出一
些常見的駕駛危險狀態，如果要加入其他
的危險行為，須再重新定義此行為模式，
透過越完善的定義模式，系統會更完整更
穩定，更能符合我們提出的駕駛安全監控
的目標。
第二年的計畫工作已經完成車道線，
路標與前車行人偵測。車道線偵測可輔助
駕駛人避免偏離車道，以免影響其他用路
人的行車安全;路標偵測則可進一步提供
駕駛人道路資訊，使駕駛人不用分心去注
意道路速限等資訊; 行人偵測可提供前方
障礙物警示之功能，避免駕駛人可能因一
時疏忽造成危險駕駛。本年度所完成之功
能皆可與第一年銜接並且整合成一有效且
安全駕駛輔助系統。
在第三年的計畫成果中，我們完成了
頭部與人臉偵測模組，可以偵測出駕駛者
的頭部轉動方向，其中包含俯仰、平面旋
轉與左右轉動。我們可以藉由偵測出之方
位，輔以亮度分析、結構性分析與人臉五
官位置關係擷取正面之人臉模組。最後我
們發展了一套基於五官特徵的人臉資料庫
訓練與比對模組，以確保駕駛者之身份正
確無誤。配合第一年與第二年所完成的項
目，三年總工作成果可以成功地整合成為
一套駕駛輔助系統，以增進行車之安全。
五、結論
由於交通事故之原因九成以上皆由人
為因素所致，為了降低肇事率並提升駕駛
的安全性，本計畫設計了一個以視覺為基
礎之駕駛輔助系統，將各種意外可能發生
的原因逐一偵測出來並提出警告。計畫中
的第一年，我們透過架設在後照鏡上的攝
影機，進行駕駛者臉部偵測，並追蹤與危
險狀態分析，並發出訊號警示各項異常行
為。第二年是針對車外的狀況進行監控，
包括車道偵測，路標偵測及障礙物偵測，
在可能發生意外的情形之下將自動的提出
警告。第三年的工作為駕駛者身份辨識與
系統整合，也就是維護車輛安全之機制，
隨時比對駕駛者之身份。由三年之研究成
果，我們可以成功地整合出一套具實用性
之駕駛輔助系統。
六、參考文獻
[1] K.H. Rho, K.H. Park, and M.H. Han,
“Automatic mirror adjustment system using a
driver's pupils,Intelligent Vehicle Symposium,
IEEE vol. 1(17-21), pp 251 –258, 2002.
[2] M. Lydon, L. Hartley, and P. Arnold,
“Procedures and devices to monitor operator
alertness whilst operating machinery in
open-cut coal mines”, ARRB Transport Res. Rep.
RC 7433, 1999.
[3] Qiang Ji, Zhiwei Zhu, and Lan Pu,
“Real-time non-intrusive monitoring and
prediction of driver fatigue”, Vehicular
Technology, IEEE Transactions, vol. 53(4), pp
1052 –1068, 2004.
[4] C. Hilario, J. M. Collado, J. Ma Armingol,
A. de la Escalera, “Pedestrian Detection for
Intelligent Vehicles based on Active Contour
Models and Stereo Vision”,Lecture Notes in
Computer Science,Vol. 3643, pp. 537-542, 2005
[5] C. Hilario, J. M. Collado, J. Ma Armingol,
A. de la Escalera,,”Model Based Vehicle
Detection for Intelligent Vehicles”,IEEE
Intelligent Vehicles Symposium, Parma, Italia,
Junio 2004.
[6] Chun-Che Wang1, Shih-Shinh Huang, and
Li-Chen Fu,Pei-Yung Hsiao,” Driver
Assistance System for Lane Detection and
Vehicle”, IEEE Intelligent Robots and
system,2005.
[7] J. T. Chien, C. C. Wu, “Discriminant
19
[28] S.-J. Tsai and T.-Y. Sun, “The Robust and
Fast Approach for Vision-based Shadowy Road
Boundary Detection,”IEEE Transaction on
Intelligent Transportation Systems, pp.
486-491, 2005.
[29] A. Broggi, “Robust real-time lane and
road detection in critical shadow
conditions,” ICCV, pp.353-358, Coral Gables,
Florida, Nov. 19–21, 1995.
[30] M. Bertozzi and A. Broggi, “GOLD: a
parallel real-time stereo vision system for
generic obstacle and lane detection,” IEEE
Transactions on Image Processing, vol. 7, no.
1, pp. 62-81, Jan. 1998.
[31] S. Nedevschi, et al., “3D Lane Detection
System Based on Stereovision,” Proceedings of
IEEE Conference on Intelligent Transportation
Systems, pp.161-166, Washington, USA, 2004.
[32] Zhu. W et al., “Lane Detection in some
complex conditions”, IEEE International
Conference on Intelligent Robots and
Systems,2006
[33] Thomas H. Cormen et al., “Introduction
to Algorithms, 2/e,” the MIT press.
[34] Canny, J., A Computational Approach To
Edge Detection, IEEE Transaction on Pattern
Analysis and Machine Intelligence, 8:679-714,
1986
[35] Z. Li, A.K. Katsaggelos and B.Gandhi,
“Fast video retrieval based on trace geometry
matching”, IEE Proc. Vision, Image and Signal
Processing, Vol. 152, No. 3, pp. 367-373, June
2005.
[36] Z. Kim, "Robust Lane Detection and
Tracking in Challenging Scenarios," IEEE
Transaction on Intelligent Transportation
Systems, vol. 9, no. 1, pp. 16-26
[37] P. Viola and M. J. Jones, "Robust
real-time face detection", in International
Journal of Computer Vision, Vol. 57, no. 2, pp.
137-154, 2004.
[38] D. M. Gavrila and V. Philomin, "Real-time
object detection for smart vehicle", in
Proceedings of IEEE International Conference
on Computer Vision and Pattern Recognition,
Vol. 1, pp. 87-93, 1999.
[39] D. M. Gavrila, "Pedestrian Detection from
a Moving Vehicle", in Proceedings of the
European Conference on Computer Vision,
pp.37-49, 2000.
[40] C. Papageorgiou and T. Poggio,"Trainable
pedestrian detection", in Proceedings of the
International Conference on ICIP, Vol. 4, pp.
35-39,1999.
[41] P. Viola, M. Jones, and D. Snow,
"Detecting Pedestrians Using Patterns of
Motion and Appearance", in International
Journal of Computer Vision, Vol. 63, no. 2, pp.
153-161, 2005.
[42] B. Leibe, E. Seemann, and B. Schiele,
"Pedestrian detection in crowded scene", in
Proceeding of IEEE International Conference on
Computer Vision and Pattern Recognition, Vol.
1, pp. 878-885,
2005.
[43] N. Dalal and B. Triggs, "Histograms of
oriented gradients for human detection", in
Proceeding of IEEE International Conference on
Computer Vision and Pattern Recognition, Vol.
1, pp. 886-893, 2005.
[44] Q. Zhu, S. Avidan, M. C. Yeh, and K. T.
Cheng, "Fast human detection using a cascade
of histograms of oriented gradients", in
Proceeding of IEEE International Conference on
Computer Vision and Pattern Recognition, Vol.2,
pp. 1491-1498, 2006.
[45] A. Cavallaro, "Tracking video objects in
cluttered background", in IEEE transactions on
Circuits and Systems for Video Technology,
Vol.15, no. 4, pp.575-584, 2005.
[46] V. Philomin, R. Duraiswami and L.Davis,
"Pedestrian tracking from a moving vehicle",
in Proceedings of the IEEE Intelligent
Vehicles Symposium, pp. 350-355, 2000.
[47] Chiunhsiun Lin, Kuo-Chin Fan
“Triangle-based approach to the detection of
human face” Pattern Recognition Vol.34 ,
pp.1271-1284 ,2001.
[48] J.Miao , B.Yin , K.Wang , L.Shen , X.Chen”
A Hierarchical Multiscale and Multiangle
System for Human Face Detection in a complex
21
日本同志社大學參訪 
 
去年八月，佛光大學藝術學所副教授潘襎以台灣英文雜誌社藝術文化基金會董事
身分，隨基金會理事長陳有仁、董事陳芳明及林惺嶽訪問日本京都與神戶。恩師
神林恆道博士的學生同時也是我們學長岡林洋教授，來電京都皇家飯店，表明希
望與佛光大學進行學術交流意願。 
 
 雙方約定於京都文化會館見面，岡林洋教授指出，日本文部省從全國數百所大
學中選出十二所大學作為「國際化據點整頓事業」大學，同志社大學（Doshisha 
Universiy）雀屏中選。隨之，我們將此一構想告知執教於國立政治大學的陳芳明
教授，共同約定推動東亞學術交流。 
 
  返國後，將此事報告佛光大學翁政義校長、范國清副校長、文學院李紀祥院長，
皆表強力支持，指示研發處與文學院辦理。隨之兩校積極設置窗口進行對話，推
動簽約事宜。 
 
許給年輕學生一個美好未來 
 
  「給年輕人一個機會，讓感動創造出充滿潛力的無限未來！」這是佛光大學
校長翁政義博士訪問千年古城京都同志社大學時，對兩校交流所提到的理想。為
了給年輕人機會，翁政義校長排除繁重的公務，今年三月廿五日率領副校長兼研
發長范國清、文學院院長李紀祥以及藝術學研究所潘襎副教授專程飛往京都，在
春暖花開的季節，與同志社大學簽訂國際學術交流。 
 
 去年十一月初擁有一百三十五年歷史的同志社大學文學院院長山田史郎、美學
系教授岡林洋、美學系主任伊達立晶，前來佛光大學訪問，受到校長翁政義的熱
情接待，簽訂學術交流草約。他們當面力邀翁校長率團訪日。雙方經歷院級以及
校級各階段協調與審議草約，終於敲定三月廿六日在同志社大學簽訂中、日、英
語正式條約，跨出交流的第一步。兩所大學同意教師、學生交流以及共同舉行研
討會、短期進修等實質性學術交流，允諾以最快速度與最大誠意實踐條約精神，
佛光大學預計將從九月開始派遣留學生，十一月共同舉行學術研討會。 
 
良心與慈悲的交流 
 
侵略，開始創設新的學術機構，將西方人文精神與技術引進國內。同志社大學的
創設正是在此一洪流與時勢中促成。 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
96年度專題研究計畫研究成果彙整表 
計畫主持人：范國清 計畫編號：96-2221-E-008-019-MY3 
計畫名稱：以視覺為基礎之先進自動駕駛輔助系統 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
 
