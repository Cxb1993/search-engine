amount of resource and achieve same QoS application level.
Resource management problems can be mapped to the well-
known Multiple-Dimension Multiple Choice Knapsack Prob-
lem (MMKP) such as [1, 9]. Khan [9] applied the concept of
aggregate resource consumption to pick a new item in a group
to solve the MMKP. Q-RAM (QoS-based Resource Allocation
Model) is a generalized approach to allocate resources when
utility functions for tasks are available [12]. However, all these
algorithms require predened numeric values to represent the
rewards for picking up each item or allocating resources for
tasks.
Distinct from the earlier works, this paper aims at propos-
ing a resource allocation framework for end-to-end real time
systems with multiple performance constraints when task se-
mantic importance are in partial order. We propose a two-
level resource allocation framework to maximize the system
QoS application level. The framework consists of two phases:
the off-line phase and the on-line phase. In the off-line phase,
an algorithm based on the dynamic programming is proposed
to compute the (sub-)optimal resource allocation for given sys-
tem workloads. Due to the limited memory space in the system,
only the resource conguration for limited number of workload
states are computed and stored. In the on-line phase, feasible
resource allocation for run-time workload state is computed
based on the stored resource congurations. In addition, we
propose an on-line protocol to rene the resource allocations to
improve the system QoS application level. The performance of
our approach is evaluated by extensive simulations.
The remainder of this paper is organized as follows: Section
2 denes the terms used in the paper and formulates the prob-
lem. Section 3 presents the framework to allocate resources
for end-to-end real-time tasks. Section 4 presents performance
evaluation. Finally, Section 5 concludes this paper.
2 Formal Model and Problem Formulation
Formal Model Thus far, and in our subsequent discussion,
we use the terms job and task as they are commonly used in
real-time system literature [5]. A job is an instance of signal
processing, or the illumination of a radar dwell, etc. A task
is a sequence of jobs that have identical or similar characteris-
tics and timing requirements. An end-to-end task is a task that
consists a set of related tasks each of which completes different
function and is called a subtask. The execution order of the sub-
tasks are predetermined and are called preceding constraint. In
this paper, we assume that there are only chain preceding con-
straints. Hence, a subtask has at most one preceding subtask
and at most one succeeding subtask. Except for where it is
stated otherwise, by a task, we mean an end-to-end task. We
call tasks T1, T2, . . . , TN , and the j-th subtask of task Ti sub-
task Ti,j . We also assume that a non-greedy synchronization
protocol [3] is used between the subtasks of a task. Thus, each
subtask is regarded as an independent task on each resource.
A subtask is characterized by its timing and resource cong-
uration parameters including period, execution time, and dead-
line. The execution time, denoted by e, is the amount of time
required to complete the execution of the job when it executes
alone and has all the resources it requires. Throughout our dis-
cussion, we assume that for the purpose of determining whether
each job can complete by its deadline, knowing its worst case
execution time (WCET) is sufcient. The term execution time
of a job means its WCET. The absolute deadline of a job is the
instant of time by which its execution is required to be com-
pleted. In many cases, it is more natural to state the timing
requirement of a job in terms of its response time. We call the
maximum allowable response time its relative deadline. Except
for where it is stated otherwise, by deadline, we mean relative
deadline and denote it by d. The period, denoted as p, is the
arrival intervals of two consecutive jobs of a task or subtask.
The instantaneous utilization (or called utilization for short) of
a task is the ratio of the execution time to the deadline of a
subtask.
A task is characterized by its timing and resource congu-
ration parameters including release time, period, QoS applica-
tion level function, resource conguration set, semantic impor-
tance, and minimal QoS application level. The release time of
a task (or subtask), denoted by r, is the time instant at which
the task becomes known to the system. In this paper, we as-
sume that the relative deadline of a task is equal to its period.
QoS application level, denoted by L, is the quality for complet-
ing a task. In MFPAR systems, the QoS application levels can
be represented by tracking errors for tracking tasks, i.e., how
close the estimated target location is to the actual target loca-
tion. In this paper, we assume that QoS application levels are
scalar numbers. We also assume that there are M distinguish
QoS application levels: L1, L2, . . . , LM , which are indexed
in a monotonically increasing order, i.e., Li < Lj for i < j.
Resource conguration for subtask Ti,j , denoted by Ri,j , is the
amount of resources required to complete subtask Ti,j . Differ-
ent subtasks may have different means to represent the amount
of resource required. For instance, resource conguration for
computational task can be represented by its instantaneous uti-
lization; Resource conguration for subtasks on radar antenna
can be represented by the amount of energy required to com-
plete the dwell transmission and receiving. Without loss of
generality, we assume that resource congurations are scalar
numbers. (Ghosh et al. [8] has shown that adding cooling time
into the dwell transmission can transform the resource required
in energy domain into time domain. Appendix A shows how
to transform the energy constraint into timing constraint.) In
addition, one task may have several resource congurations to
complete its work. We denote the k-th resource conguration
for task Ti by Rki = (Rki,1, Rki,2, . . . , Rki,n(i)), in which n(i) is
the number of subtasks for task Ti and Rki,j is the k-th resource
conguration for subtask Ti,j . Resource conguration set for
task Ti is a set of resource congurations for task Ti, denoted
by Ri = {R1i , R2i , . . . , R
m(i)
i }, where m(i) is the number of
resource congurations for task Ti. The resource congura-
tion selected to execute the task is called the selected resource
conguration for task Ti, denoted by Rˆi and Rˆi ∈ Ri. QoS ap-
plication level function for task Ti, denoted by fi, is a function
that shows the QoS application level when resource congu-
ration Rˆi is allocated for task Ti. The (semantic) importance
of task Ti, denoted by pii, is the importance level for task Ti.
The semantic importance for tasks are determined by domain
experts and may not be a totally ordered set. Minimal QoS ap-
plication level for task Ti, denoted by Li,min, is the minimal
allowable QoS application level for task Ti. When the QoS
application level for a task is less than its minimal QoS appli-
cation level, the task fails. Hence, each task Ti is dened by a
tuple Ti = (pii, ri, pi,Ri, fi, Li,min).
A task type, denoted by T, is a set of tasks which have sim-
ilar or identical timing parameters and resource conguration
parameters except for the release times for the tasks. For in-
stance, in MFPAR systems, there may be several tasks track-
ing same or similar types of targets in the surveillance space.
The tasks arrive at different time instants but have same or
similar timing and resource conguration parameters. Natu-
2
conguration assignment matrix X is 1 if the resource cong-
uration Rkj is selected for each task Ti of task type Tj . Oth-
erwise, xj,k is 0. As a result, the cross product of resource
conguration matrix X and resource conguration vector gives
a selected system resource conguration. In other words,
MULTI-CONSTRAINT END-TO-END RESOURCE MANAGE-
MENT problem can be formulated as following.
Maximize
K∑
j=1
∑
Ti∈Tj
m(i)∑
k=1
fi(R
k
i )× xj,k
subject to
K∑
j=1
∑
Ti∈Tj
m(i)∑
k=1
R
k
i,1 × xj,k ≤ U1, · · · ,
K∑
j=1
∑
Ti∈Tj
m(i)∑
k=1
R
k
i,M × xj,k ≤ UM ,
R
k
i × xi,k = R
k
j × xj,k for Ti, Tj ∈ Tm and 1 ≤ k ≤ C, (1)
m(p)∑
k=1
fp(R
k
p)× xp,k ≥
m(q)∑
k=1
fq(R
k
q )× xq,k, for pip > piq and 1 ≤ p, q ≤ W, (2)
m(i)∑
k=1
fi(R
k
i )× xj,k ≥ Li,min, ∀Ti ∈ Tj , j = 1, .., K, (3)
xj,k ∈ {0, 1}, ∀j = 1, .., K, and k = 1, . . . ,m(j), (4)
and
m(j)∑
k=1
xj,k = 1 for 1 ≤ j ≤ K. (5)
The rst M equations state the feasibility constraints for M
processors. In this paper, we assume that utilization bound ap-
proach is used to conduct schedulability analysis. When other
schedule analysis is used, the rst M equations should be re-
placed by the corresponding schedulability functions. Equation
(1) and (2) are fairness and criticality constraints, respectively.
Equation (3) represents the QoS application level constraint.
Equation (4) and (5) assure that only one resource congura-
tion is selected for each task type.
There are several challenges for solving the problem dened
in Denition 5. The rst challenge is the time complexity of
the problem. Because the problem is proved to be NP-hard,
there is no polynomial time algorithm to nd an optimal solu-
tion for each given workload state. The second challenge is the
dynamic workload of the system. In this paper, we are con-
cerned with open systems in terms of system workload. Hence,
tasks can be dynamically added into or removed from the sys-
tem during the run-time. The resource manager should adjust
the resource allocation according to the system workload state
during the run-time.
3 Two-Level Resource Allocation Framework
In distributed real-time systems, each processor in the sys-
tem may have its own local resource manager to optimize the
resource allocation or its own scheduler to schedule the sub-
tasks on the processor. To reduce the run-time overhead in such
systems, we develop a two-level resource management frame-
work. In the framework, the resources are managed in a hier-
archical manner in terms of the composition of the end-to-end
tasks. Namely, there is a task-level resource manager for the
entire system and subtask-level resource managers on each lo-
cal process for subtasks. Task-level resource manager allocates
the resources for each task without considering how subtasks
are scheduled on local processors, given the workload informa-
tion on task level; the schedulers on the subtask-level sched-
ules subtasks without considering synchronization issues be-
tween subtasks for every task. Although multi-level approaches
have been applied for different challenge problems, most of
them focus on solving the same problem on different levels.
For instance, open real-time environment [15] rst schedules
the server on higher-level and, then, schedule the tasks in the
server in turn. However, in our framework, the higher-level
determines the resource congurations on task level and the
lower-level schedules the subtasks on local processors. This
framework consists of two phases: in the off-line phase, the
algorithm computes the sub-optimal resource conguration as-
signments for few workload states by a dynamic programming
approach; in the on-line phase, the algorithm computes a fea-
sible run-time resource conguration by a greedy approach,
providing sub-optimal resource congurations computed in the
off-line phase.
For the sake of presentation, we illustrate the two-level re-
source management framework using MFPAR systems as an
example. In MFPAR systems, there are two processors: front-
end antenna and back-end signal processors. Nevertheless,
the developed framework can be easily extended into multiple-
dimension resources distributed real-time systems. In an MF-
PAR system, radar tasks search or track targets in its surveil-
lance space. To keep track of the targets, the system must meet
its timing and energy constraints. The timing constraint enables
the system to illuminate (electro-magnetic) waves on the targets
with high probabilities; the energy constraint prevents the sys-
tem from overheating damage. (Unlike timing constraint, en-
ergy constraint is not a scalar number. To apply the framework
to MFPAR systems, we have to transform the energy constraint
to be a scalar number. Appendix A shows how to transform the
energy constraint into a constraint on time domain.) The sys-
tem fails when it fails to meet any of these two constraints. A
(radar) track task is an end-to-end task [3] with three subtasks:
a control command subtask, a dwell subtask, and a signal pro-
cessing subtask [2]. When a track task starts, the control com-
mand subtask generates the commands of sending/receiving the
waves. Next, based on the generated commands, the dwell sub-
task sends and receives the waves at a scheduled time. Then,
the signal processing subtask processes the collected signal to
discover the location of the tracked target. The system uses the
result of the signal processing subtask to predict the movement
of the target in the future. The estimated location of the target
is given to the next instance of the track task and the execution
sequence of the three subtasks repeats. The track task stops
when there is no need to monitor the movement of the target.
3.1 Resource Allocation for Off-line Phase
The off-line phase consists of two steps: workload state
sampling and resource conguration determination. The rst
step determines which workload states will be considered in
the off-line phase; The second step uses a dynamic program-
ming approach to nd a sub-optimal solution for the problem
dened in Denition 5 for each sampled workload state.
3.1.1 Workload State Sampling
The goal of the off-line phase is to compute the resource con-
guration for the system. One trivial approach is to compute
the resource congurations for all workload states and store
the congurations for run-time use. However, the number of
workload state exponentially grows in terms of the number of
task types. It is not practical to do so. Considering the limited
amount of storage space, we can estimate how many resource
congurations can be pre-computed and stored a priori. Sup-
pose that S is the size of the available (memory or secondary
storage) space to store the resource congurations for on-line
use and γ is the size of memory required for storing each re-
source conguration assignment. Then, at most S/γ resource
4
The algorithm starts with the workload state that has only
one task type (i.e., h = 1) until U1 ∗ 1q > U1 and U2 ∗ 1q > U2.
When the algorithm terminates, it nds if there is a feasible
resource conguration for every sampled workload state.
Since the resource congurations used thus far are rounded-
up resource congurations, real system QoS application level
F (s,Rh) is no greater than the upper bound Z(h,U1, U2) for
any feasible rounded-up resource conguration assignment R.
To obtain the resource conguration assignment, the algorithm
needs to backtrack the built dynamic programming table via a
standard technique [6]. Then, we can convert the rounded-up
resource conguration for each task type into the original one.
Applying the dynamic programming approach allows us to
determine the resource conguration for the sampled workload
states in polynomial time. The following theorem shows that
polynomial space complexity and time complexity for dynamic
programming algorithm.
Theorem 2 The MULTI-CONSTRAINT END-TO-END RE-
SOURCE MANAGEMENT problem admits a poly-nomial-time
dynamic programming algorithm which takes O(KCU1U2q2)
time complexity and O(KU1U2q2) space complexity to com-
pute a solution for any user-specied parameter q > 0, where
C is the maximum number of resource congurations of all
tasks, i.e., C = maxKj=1 maxTi∈Tj n(i).
Proof. The dynamic programming table has KU1U2q2 el-
ements so the space complexity is O(KU1U2q2). When de-
riving the value of an element, we need to test C resource
congurations at most. As a result, the time complexity is
O(KCU1U2q
2). ¤
In Theorem 2, one can see that space and time complexity
are quadratically proportional to rounding factor q. The greater
the round factor, the greater time and space complexity. On the
other hand, the value of rounding factor also determines round-
ing error, i.e., how close the solution founded by the dynamic
programming algorithm is to the real solution. The greater the
round factor, the greater the rounding error. In other words,
rounding factor can be used as a mean to trade the run-time
complexity of the algorithm and quality of solution to the inte-
ger linear programming problem.
3.2 Resource Refinement for On-line Phase
In this section, we present the algorithm for computing fea-
sible resource conguration assignments for run-time workload
states, providing the pre-computed resource conguration as-
signments. When the system workload changes, current se-
lected resource conguration could be infeasible. The resource
manager should look for a new resource conguration. Sec-
ond, the resource conguration computed during the off-line
phase are mostly conservative. Hence, the resources may not
be fully utilized during the run-time. The resource manager
will reclaim un-used resources to improve system QoS appli-
cation level. Note that the two operations are conducted during
the run-time and should have low run-time overhead.
3.2.1 Approximating Feasible Resource Configuration
When the system workload state s(t) changes, the current re-
source conguration assignment could be infeasible to system
workload state s(t). We derive a resource conguration for cur-
rent system workload in the following steps:
Step 1: Searching a pre-computed resource configuration
assignment. As discussed earlier, the off-line phase does
not compute the resource congurations for all possible
workload states. Only the resource congurations for
sampled workload states are computed and stored. This
step nds a resource conguration which is feasible for
current system workload state and whose system QoS ap-
plication level is the maximal.
When equally sampling approach is used for selecting the
sampled workload states, we can nd the resource re-
conguration in constant time. Let αj be the minimum
number of tasks of task type Tj whose resource con-
guration is computed and stored in the off-line phase.
In other words, αj is equal to Nj − (
⌊
Nj
Oj
⌋
− 1) · Oj .
When the current workload state is s(t) = (m1, . . . ,mK),
the pre-congured workload state is (α1 +
⌈
n1−α1
O1
⌉
·
O1, . . . , αK +
⌈
nK−αK
OK
⌉
·OK). We can use the resource
conguration for the pre-congured workload state for
current workload state. When statistic-based approach is
used to select the sampled workload state, a linear search
might be needed to nd the proper workload state. To
shorten the time for searching for a proper pre-computed
resource conguration, one can also construct a hash table
for sampled workload states.
Step 2: Resource reclaiming. Because the resource cong-
uration derived in the off-line phase is conservative, it
is very likely that the processors are not fully utilized.
During the run-time, the resource manager reallocates the
un-used or over-reserved resources to improve the system
QoS application level. We propose an iterative algorithm
to do so.
Because the task groups are indexed by a non-increasing
order of semantic importance of tasks, the semantic im-
portance of each task of Gh is no less than that of each
task of Gh+1. To meet the criticality constraint, the algo-
rithm rst assigns reclaimed resources to the tasks of task
group G1. If the tasks in G1 are in different task types, we
randomly select a task type Tj . If the original selected re-
source conguration for task Ti ∈ Tj is (Rˆki,1, Rˆki,2), and
we allocate resources to increase its QoS application level
by one level. If there are enough resources, the QoS ap-
plication levels of all the tasks in G1 are increased. The
algorithm continues to do so for other task groups. The
procedures stops when all the tasks can achieve their max-
imal QoS application levels or there is no enough resource
to improve the QoS application level for all tasks of one
task group. Note that in order to meet the criticality con-
straint, the algorithm will not assign resources to any task
of task group Gh+1 if the minimal tracking quality levels
of tasks of Gh are equal to that of tasks of Gh+1. The time
complexity of the algorithm is O(KM), where K and M
are the numbers of task types and QoS application levels,
respectively.
After the two steps, the algorithm nds a resource conguration
for current system workload state.
3.2.2 Negotiation Between the Low-Level Schedulers and
the Resource Manager
Because the task-level resource manager loosely couples with
the local schedulers on the front-end and the back-end pro-
cessors, the resource manager may not have sufcient run-
time information, e.g., the system residual energy level of the
front-end processor during the run time. The resource manager
should rene the resource conguration during the run-time to
enhance the system QoS application level. During the run-time,
6
Target Type Region Resource Configurations
(Time-to-Intercept) Level 1 Level 2 Level 3
Critical (7.6, 0.04 ) (8.5, 0.026 ) (10.2, 0.02) (8.7, 0.0458) (9.7, 0.0297) (11.3, 0.0222) (9.9, 0.0521) (11, 0.0336) (13, 0.0255)
Hostile Target Tracking (4.5, 0.0137) (5.1, 0.0077) (6.7, 0.0046) (6, 0.0183) (7.1, 0.0107) (8.3, 0.0057) (7, 0.0213) (8.6, 0.0131) (11, 0.0075)
Non-critical (3.4, 0.008) (4, 0.0038) (5.7, 0.0019) (4.3, 0.0101) (5.7, 0.0055) (7.2, 0.0024) (6, 0.0141) (7.5, 0.0072) (9.4, 0.0032)
Critical (3, 0.096) (4, 0.0048) (5, 0.0024) (4.5, 0.0144) (5.7, 0.0068) (6.2, 0.003) (6, 0.0192) (8, 0.096) (9, 0.0043)
Friendly Target Tracking (2, 0.0032) (3, 0.0009) (4, 0.0003) (3, 0.003) (4, 0.0012) (5, 0.0004) (4.5, 0.0045) (6, 0.0018) (7, 0.0006)
Non-critical (1.5, 0.0091) (2.1, 0.0048) (3, 0.0016) (2.6, 0.0158) (3.8, 0.0087) (4.6, 0.0024) (3.7, 0.0226) (5, 0.0114) (6, 0.0032)
Guided Missile (4.5, 0.0012) (5.1, 0.0007) (6.7, 0.0004) (6, 0.0016) (7.1, 0.0009) (8.3, 0.0005) (7, 0.0019) (8.6, 0.0011) (11, 0.0007)
Table 2. Resource Congurations for Tasks.
Target Type Region 1→ Region 2 Probability
Hostile Target Stay in the Non-surveillance Space 30%
Non-surveillance Space→ Non-critical Region 70%
Stay in the Non-critical Region 20%
Non-critical Region→ Tracking Region 50%
Non-critical Region→ Non-surveillance Space 30%
Stay in Tracking Region 30%
Tracking Region→ Critical Region 30%
Tracking Region→ Non-critical Region 40%
Stay in the Critical Region 50%
Critical Region→ Tracking Region 50%
Friendly Target Stay in the Non-surveillance Space 50%
Non-surveillance Space→ Non-critical Region 50%
Stay in the Non-critical Region 10%
Non-critical Region→ Tracking Region 40%
Non-critical Region→ Non-surveillance Space 50%
Stay in the Tracking Region 30%
Tracking Region→ Critical Region 30%
Tracking Region→ Non-critical Region 40%
Stay in the Critical Region 70%
Critical Region→ Tracking Region 30%
Guided Missile Stay in Non-surveillance Space 60%
Non-surveillance Space→ Surveillance Space 40%
Surveillance Space→ Non-surveillance Space 80%
Non-surveillance Space→ Non-surveillance Space 20%
Table 3. The Probabilities of Targets and Mis-
siles Moving between Regions.
move from one region to another region. For example, a hostile
target might move from tracking region to critical region with
30% of chance, where it has 40% of chance moving from track-
ing region to non-critical region. In other words, a hostile target
has 30% of chance in staying in tracking region. The rationale
behind the probabilities is to simulate the case that targets have
a decreasing chance of entering a more critical region and a
decreasing chance in leaving a more critical region. The dura-
tion for each target or missile in staying in one region are ran-
domly distributed in the range of [3000ms, 6000ms]. Since the
performance of DPBRA-q depends on the number of resource
congurations derived in the off-line phase, parameter work-
load offset O which is the difference of task numbers between
two consecutive resource congurations for each task type is
used as a parameter in the performance evaluation. DPBRA-
q-O was used to denote DPBRA-q when the offset is equal to
O. For the on-line phase, we evaluate the performance for the
cases that workload offset are 2, 3, and 4.
The performance metrics for simulations in the off-line
phase are system QoS application level and schedulability. The
schedulability is the ratio of Num(K) to Num(OPT ), where
Num(K) is the number of task sets that have feasible resource
congurations derived by the algorithm K (that could be ID-
BRA or DPBRA), and Num(OPT ) is that derived by the ex-
haustive search method. The performance metrics for the on-
line phase are the system tracking quality level and the mean
dropping rate. Mean dropping rate is the number of tasks
dropped by the system for every 1000ms.
4.2 Evaluation Results
Figure 1(a) and (b) show the system QoS application level
and schedulability for different algorithms, when the workload
probability is (0.4, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1). DPBRA was de-
noted as DPBRA-1/q when the rounding factor q are set as
1/0.002, 1/0.006, and 1/0.01. The DPBRA algorithm for
these rounding factors are referred to DPBRA-0.002, DPBRA-
0.006, and DPBRA-0.01. The results for other workload prob-
abilities are similar to the ones shown here and are not shown.
The results in Figure 1(a) show that, in general, system QoS ap-
plication level increases as the number of track tasks increases.
However, when the number of track tasks is more than a cer-
tain value, the system QoS application level decreases. Such
results are caused by the fairness constraint. When there are
not enough resources for all the tasks, the resource manager
has to downgrade the QoS application level for the tasks of one
task type or drop the tasks of one task type. Among all al-
gorithms, the IDBRA algorithm has the worst performance in
general. For DPBRA algorithm, as the value of rounding factor
increases, the rounding error becomes smaller and the system
QoS application level for DPBRA-q algorithms are closer to
that for optimal algorithm.
Figure 1(b) shows the schedulability for different algo-
rithms. In the gure, only the cases that there is any feasible
resource conguration are considered. Hence, the schedulabil-
ity for exhaustive search algorithm is 100% and its results are
not shown. The results in the gure show that DPBRA algo-
rithm outpeforms IDBRA algorithm except when the round-
ing factor is 1/0.01. Again, in the gure, the rounding factor
plays an important role for the performance. When the value
of rounding factor increases, the schedulability increases. Al-
though optimal algorithm could derive better resource cong-
urations whenever possible, the computation time required for
optimal algorithm is very signicant. The IDBRA algorithm
requires the minimum computation time but has the worst sys-
tem QoS application level. The DPBRA algorithm, on the other
hand, provided rounding factor q to control the quality of the
results in the system QoS application level and schedulability
ratio. The computation time required for DPBRA is propor-
tional to the square of rounding factor q.
Figure 2(a) shows the system tracking quality levels of tasks
during the run-time. The results show that the DPBRA al-
gorithms outperform the IDBRA algorithm for all the cases.
Among the DPBRA algorithms, the performance are better for
greater rounding factor and less workload offset. Such results
show that the steps for nding a resource conguration in the
on-line phase do improve the performance of the DPBRA al-
gorithm. Figure 2(b) shows the total utilization for front-end
antenna during the run-time. The results show that greater
rounding factor (i.e., less rounding error) allows the system
to achieve higher utilization. The results in the gures show
that although the dynamic programming approach introduces
rounding error for converting the original problem denition,
it does compute sub-optimal solutions in polynomial time. In
addition, it is very effective to adjust the optimality of the algo-
rithm using rounding factor q. The greater the rounding factor,
the greater the optimality of the algorithm.
5 Summary
In this paper, we are concerned with the resource alloca-
tion problem for distributed real-time systems in which there
are no totally ordered importance or numeric utility values for
tasks. We develop a two-level resource allocation framework.
This approach consists of two phases: in the off-line phase, the
algorithm computes the sub-optimal resource congurations
for a limited number of workload states by the dynamic pro-
gramming approach; in the on-line phase, the algorithm com-
putes resource congurations by a greedy approach, provided
8
