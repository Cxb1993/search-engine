 2
[11] A. K. Jain and R. C. Dubes, Algorithms for Clustering Data. Prentice Hall, Englewood Cliffs, 1988.  
[12] J. T. Jrgensena, “Pharmacodiagnostics and targeted therapies: A rational approach for individualizing 
medical anticancer therapy in breast cancer,” Oncologist, vol. 12, 2007, pp. 397–405.  
[13] M. Lacroix-Triki, S. Mathoulin-Pelissier, J. Ghnassia, G. Macgrogan, A. Vincent-Salomon, V. Brouste, 
M. Mathieu, P. Roger, F. Bibeau, J. Jacquemier, “High inter-observer agreement in 
immunohistochemical evaluation of HER-2/neu expression in breast cancer: a multicentre GEFPICS 
study,” EJC, vol. 42, 2006, pp. 2946–2953. 
[14] S. Lloyd, “Least squares quantization in PCM,” IEEE Trans. Information Theory, vol. 28, 1982, pp. 
129–137. 
[15] J. B. MacQueen, “Some methods for classification and analysis of multivariate observations,” Proc. 5th 
Berkeley Symposium on Mathematical Statistics and Probability, vol. 1, 1967, pp. 281–297. 
[16] N. Otsu, “A threshold selection method from gray-level histograms,” IEEE Trans.  Systems, Man, and 
Cybernetics, vol. 9, 1979, pp. 62-66. 
[17] A. C. Ruifrok and D. A. Johnston, “Quantification of histochemical staining by color deconvolution,” 
Anal. Quant. Cytol. Histol. Vol. 23, 2001, pp. 291–299. 
[18] Z. Theodosiou, I. Kasampalidis, G. Livanos, M. Zervakis, I. Pitas, and K. Lyroudia, “Automated analysis 
of FISH and immunohistochemistry images: A review,” Cytometry, Part A, vol. 71, 2007, pp. 439-450.  
[19] C. J. van Rijsbergen, Information Retrieval. Butterworth, London, 1979. 
[20] V. Vapnik, Statistical Learning Theory. Wiley-Interscience, New York, 1998.  
[21] S. Veerla, Cancer-Related Gene Regulation Mechanisms: Cancer Genetics, Transcription Factors, Gene 
Regulation Mechanisms, Bioinformatics. VDM Verlag, 2009.  
[22] J. A. Warrington, R. Todd, and D. Wong, Microarrays and Cancer Research. Eaton Publishing Company, 
2002. 
[23] D. Crookes, P. J. Morrow, and P. J. McParland, “IAL: a parallel image processing programming 
language,” Communications, Speech and Vision, IEE Proceedings I, vol. 137, no. 3, pp. 176-182, 1990. 
[24] J. Sérot, G. Quénot, and B. Zavidovique, “Functional programming on a dataflow architecture: 
applications in real-time image processing,” Machine Vision and Applications, vol. 7, pp. 44-56, 1993. 
[25] C. Lejdfors and L. Ohlsson, “PyGPU: A high-level language for high-speed image processing,” IADIS 
International Journal on Computer Science and Information Systems, vol. 2, no. 1, pp. 66-81, 2006. 
[26] Python Programming Language, http://www.python.org/ 
[27] P. Banerjee, N. Shenoy, A. Choudhary, S. Hauck, C. Bachmann, M. Haldar, P. Joisha, A. Jones, A. 
Kanhare, A. Nayak, S. Periyacheri, M. Walkden, D. Zaretsky, “A MATLAB compiler for distributed, 
heterogeneous, reconfigurable computing systems,” 2000 IEEE Symposium on Field-Programmable 
Custom Computing Machines, pp.39-48, 2000. 
[28] W. Najjar, B. Draper, A. P. W. Bohm, and R. Beveridge, “The Cameron project: high-level programming 
of image processing applications on reconfigurable computing machines,” Proc. 7th Intl. Conf. Parallel 
Architectures and Compilation Techniques - Workshop Reconfigurable Computing, 1998. 
[29] R. W. Sebesta, Concepts of Programming Languages, 6th ed., Addison Wesley, 2003. 
[30] Chasan's Place - Backus Naur Form (BNF) of Pascal Language, 
http://www.chasanc.com/index.php/Compiler/Backus-Naur-Form-BNF-of-Pascal-Language.html. 
 4
A Computer-aided System for Discriminating Normal from Cancerous Areas in IHC 
Liver Cancer Tissue Images Using K-means Clustering 
 
R. M. Chen*, Y. J. Wu†, S. R. Jhuang†, M. H. 
Hsieh†, C. L. Kuo†, and Y. L. Ma† 
Department of Computer Science and Information 
Engineering 
National University of Tainan 
Tainan, Taiwan 
*e-mail: rmchen@mail.nutn.edu.tw 
†All the authors contributed equally to this work. 
 
R. M. Hu1 and Jeffrey J. P. Tsai2 
1Department of Biotechnology, Asia University and 
School of Chinese Medicine, China Medical University 
Taichung, Taiwan  
2Department of Bioinformatics, Asia University 
Taichung, Taiwan and Department of Computer 
Science, University of Illinois,  Chicago, USA 
e-mail: rmhu@asia.edu.tw, jjptsai@gmail.com 
 
 
 
Abstract—Immunohistochemistry (IHC) is a well established 
imaging technique that can be exploited to detect whether the 
target antigen exists in tissue sections or not in order to 
discriminate between the cancerous and normal areas in a 
cancer tissue specimen. The intensity of immuno-stained 
protein in normal and cancerous areas can be compared to 
detect the gene status in sample tissues. In this paper, we 
address the problem of identifying the differential expression 
of marker protein on cancerous and normal areas in an IHC 
liver cancer tissue image. We present an improved IHC image 
processing procedure based on nucleus density, intensity of 
stained protein, and k-means clustering algorithm to develop 
an automated system for analyzing an IHC image. The 
proposed system can discriminate between normal and 
cancerous areas in an IHC image more effectively and display 
them visually. Furthermore, this system can automatically 
evaluate the stained protein expressions in the two areas which 
can help the pathologist to analyze the differential expressions 
of a marker protein in IHC images. Finally, we tested the 
proposed system on 150 real IHC liver cancer tissue images 
and compared the results with a previous work where the 
average of density of nuclei is used as the threshold to 
discriminate cancerous from normal areas. 
Keywords-Immunohistochemistry (IHC); Tissue Image; 
Nuclei Segmentation; K-means Clustering; Image Analysis  
I.  INTRODUCTION  
It was generally believed that the formation of cancer is 
due to activation of oncogenes or in activation of tumor 
suppressor genes. Many studies of genes associated with 
cancer have been conducted over the years, expected to find 
genes that cause cancer and genes that can inhibit cancer [21]. 
Several approaches have been developed to help diagnose 
cancer in the past. These approaches may include the use of 
ultrasound, magnetic resonance, and computerized 
topography scan, etc. However, the diagnosis of cancer 
should eventually be confirmed subject to the biopsy.  
With the advances of microarray technology, microarray 
technology can be used to determine molecular markers and 
the type of cancer [22]. However, microarray gene 
expressions are usually only able to provide early stage 
information of gene expressions. The differential gene 
expressions are still needed to be validated by quantified 
polymerase chain reaction (PCR). A complementary imaging 
technique to quantify protein activity is based on 
immunohistochemistry (IHC) images [1]-[2], [4]-[6], [12], 
[17]. While a number of automated or semi-automated 
techniques are increasing in popularity, manual intervention 
is still necessary in order to resolve particularly challenging 
or ambiguous cases. This calls for new computer-aided tools 
to assist the pathologist in the examinations of their work. 
For this, an extensive review for automated analysis of IHC 
images has been made by Theodosiou et al. [18]. IHC can be 
used to detect whether the target antigen exists in tissue 
sections or not in order to discriminate between the 
cancerous and normal areas in a cancer tissue specimen. It 
can help us to recognize the location and distribution of 
marker proteins in different areas of the specimen. However, 
if the boundaries of normal and cancerous areas are not clear, 
the analysis results will be extremely affected by inter-
observer variability [13]. Moreover, it is time-consuming to 
extract information from very large datasets by manual 
analysis.  
Fig. 1 shows an example of IHC image of liver cancer 
tissue. This kind of images will be taken as the target image 
to be considered in this paper. The dark blue parts of the 
image are nuclei. The density of nuclei can be used to 
distinguish between normal and cancerous areas in the tissue. 
The area with a higher density of nuclei will be recognized 
as cancerous tissue and the area with a lower density of 
nuclei will be recognized as normal tissue. However, 
because tissues may have some deformation when 
embedding and cells are not neatly arranged in the same 
plane, many nuclei may be seen to be connected visually 
from the biopsy. Besides, since the composition of human 
liver cell is a cell with multiple nuclei, it does not necessarily 
have a nuclear membrane between nuclei. Hence, counting 
the number of nuclei per unit area is not an effective way to 
find the density of nuclei. One way to deal with this problem 
is to discriminate nuclei region from non-nuclei region based 
on the color information of nucleus before calculating the 
density of nuclei [10]. Another factor that will affect the 
 6
where Ci is the number of pixels of nucleus areas at segment 
i of the image, Ai is the number of pixels of segment i, and 
block_number is the number of segments of the image. The 
average nucleus density at each segment is selected as the 
discriminant feature. After evaluating the average nucleus 
density of all segments, we apply the k-means clustering to 
separate the cancerous from normal image areas based on 
the discriminant feature. In statistics and machine learning, 
k-means clustering is an approach of cluster analysis which 
aims to separate observations into k clusters such that each 
observation is assigned to the cluster with the nearest mean; 
it is also referred to as Lloyd's algorithm [8] , [14]-[15]. 
Since the k-means clustering is a heuristic algorithm, 
there is no guarantee that it will converge to the global 
optimum, and the result may depend on the initial data. 
Usually, the initial data are specified at random or by some 
heuristic data. In the proposed system, we will sort the 
nucleus density of all segments at first, and then the 
maximum density and minimum density are assigned to the 
initial data. This setting makes the clustering result more 
accurate in our analysis. Another problem with using k-
means clustering algorithm is to determine the number of 
clusters, an inappropriate choice of k may yield poor results. 
The number of k clusters is set to 2 since only two classes, 
normal and cancerous tissue areas, are to be separated in this 
analysis.  
C. Computing the Intensity of Stained Protein in 
Cancerous and Normal Areas 
After discriminating cancerous from normal areas in an 
IHC tissue image, the third step is to compare the intensity of 
stained protein in both areas in order to detect the gene status 
in sample tissues. We first map the regions of stained protein 
obtained in Section 2.1 onto cancerous and normal areas of 
the IHC image. The average intensity of stained protein in 
cancerous area, denoted by DP_CR, is then evaluated by the 
following formula: 
 
( )∑
∑ ∑
=
= ∈
−
= crnum
j
jj
crnum
j CAyx
CA
yxf
CRDP j_
1
_
1 ),(
),(
_
 (3) 
where num_cr is the number of segments in cancerous area, 
Aj is the number of pixels of jth segment in cancerous area, 
Cj is the number of pixels of nucleus region in jth segment of 
cancerous area, f(x, y) is the gray-level intensity at 
coordinate (x, y), and CAj is the set of coordinates in jth 
segment of cancerous area. Note that the average intensity 
of stained protein is calculated by excluding the area of 
nuclei in each segment. Similarly, the average intensity of 
stained protein in normal area, denoted by DP_NR, can be 
evaluated by the following formula:  
 
( )∑
∑ ∑
=
= ∈
−
= nrnum
j
jj
nrnum
j NAyx
NB
yxf
NRDP j_
1
_
1 ),(
),(
_
 (4) 
where num_nr is the number of segments in cancerous area, 
Bj is the number of pixels of jth segment in normal area, Nj is 
the number of pixels of nucleus region in jth segment of 
normal area, f(x, y) is the gray-level intensity at coordinate 
(x, y), and NAj is the set of coordinates in jth segment of 
normal area.  
D. Detecting the Gene Status in Sample Tissues 
The final step of the proposed system is to detect the 
gene status in sample tissues based on the comparison of 
average intensity of stained protein in cancerous and normal 
areas obtained in Section 2.3. There are three gene statuses 
for the detection. If the average intensity of stained protein in 
cancerous area is greater than the one in normal area, the 
gene status will be recognized as "overexpression". If the 
average intensity of stained protein in cancerous area is less 
than the one in normal area, the gene status will be 
recognized as "underexpression". Otherwise, the gene status 
will be recognized as "no significant difference" which may 
imply the target marker protein should have no relationship 
with the target disease. In the case of "no significant 
difference", the proposed system also provides a user-
defined threshold for distinguishing the average intensity of 
stained protein between cancerous and normal areas.  
III. PERFORMANCE MEASURE 
In this section, we introduce the performance measure 
used to evaluate the success of the proposed method.  
The success of a test lies in its ability to retrieving correct 
results for a given task. In statistics, the F-score (also F-
measure) is a measure for evaluating the performance of a 
test [19]. It considers both the precision p and recall r of the 
test to compute the score. The precision is defined as the 
fraction of tested results that are correct. The recall is defined 
as the fraction of correct results that are tested. In these terms, 
F-score is defined as the weighted harmonic mean of recall 
and precision. The formula used to compute the F-score here 
is as follows: 
 
pr
rpF +=
2  (5) 
In the following section, we will use the F-score to 
evaluate the detecting performance of the proposed method 
and the method of previous work in [10]. 
IV. EXPERIMENTAL RESULTS AND DISCUSSION 
The proposed system was implemented in Borland® C++ 
Builder, a well-known C++ development environment. We 
tested the proposed system with k-means clustering 
 8
[21] S. Veerla, Cancer-Related Gene Regulation Mechanisms: Cancer 
Genetics, Transcription Factors, Gene Regulation Mechanisms, 
Bioinformatics. VDM Verlag, 2009.  
[22] J. A. Warrington, R. Todd, and D. Wong, Microarrays and Cancer 
Research. Eaton Publishing Company, 2002.  
 
 
 
 
 
Figure 3. The graphical user interface (GUI) of the proposed system. 
 
 
 
 
 
Figure 4. Experimental results obtained with Method 1 on one of the tested IHC images. 
 
 
 
 
 
 
 
 10
Object Relational Programming of Biomedical Images 
Han C.W. Hsiao1*, Rouh-Mei Hu2, Wei-Liang Tai1, Rong-Ming Chen3, Jeffrey J.P. Tsai1,4 
1. Department of Biomedical Informatics, Asia University, Taiwan 
2. Department of Biotechnology, Asia University, Taiwan 
3. Department of Computer Science and Information Engineering, National University of Tainan, Taiwan  
4. Department of Computer Science, University of Illinois at Chicago, USA 
*Email: hwhsiao@asia.edu.tw 
 
 
Abstract—Biomedical imaging is an important technique for 
preclinical diagnosis, medical research and biological studies. 
Nowadays, the development of different tools for acquiring 
images yields an explosion in the amount of images, which are 
difficult to be analyzed in detail. There is hence an increasing 
necessity to develop new tools for processing, analyzing and 
utilizing medical and biological images. In this paper, a high-
level programming framework for biomedical image analysis is 
proposed. Example scenarios are provided to demonstrate its 
usefulness. 
Keywords-high-level programming; image analysis 
I. INTRODUCTION 
Biomedical imaging is an important tool for preclinical 
diagnosis, medical research and biological studies. Several 
modalities acquire biological images in the levels of whole-
body, organ, tissue, cellular, or molecular, which provide 
information to help physicians, medical laboratory scientist 
and biologists to make better diagnosis and more accurate 
surgical treatment, as well as to get or analyze data for their 
researches. 
In general, radiography, ultrasonography, thermography, 
and magnetic resonance imaging (MRI) are important types 
of medical images in the whole-body or organ levels. Many 
different types of microscope systems and staining/labeling 
methods have been developed to capture histological section 
images or to identify a specific protein within a tissue or cell. 
Electrophoresis and blotting methods reveal the distribution 
pattern of macromolecules isolated from a living organism or 
cultivated tissues/cells, and create images for identification, 
purification, quantification, and comparison. 
Microscopic images are usually used in clinical diagnosis 
and biomedical researches. A pathologist may scrutinize the 
histological image of a biopsy segregated from a suspected 
cancer patient to identify the cancerous tissues, or may also 
observe the biopsy from the brain of a patient suffering from 
Alzheimer’s disease to characterize the extracellular protein 
aggregation, amyloid. Since most of the biological tissues are 
colorless, Hemalum and Eosin Y (H&E) stain is a generally-
used coloring technique in histology. Hemalum binds to the 
highly basic components and stains nuclei of cell blue. Eosin 
Y stains other eosinophilic regions like cytoplasm into colors 
ranging from light pink to dark red. An amyloid aggregate in 
the brain tissue of an Alzheimer's patient can be observed as 
an eosinophilic mass on H&E. 
Immunohistochemistry or IHC is an advanced analysis 
process to detect a target protein on a histological slide using 
highly specific antibodies raised against this target protein. 
An enzyme-conjugated second antibody tracks the first one 
which has been fixed on the tissue. Brown color is developed 
by a color-forming reaction that is carried out by peroxidase 
conjugated to the second antibody. IHC images can provide 
information of quantity, distribution and location of a target 
protein in a cell, and can help to understand its differential 
expression in different parts, such as cancerous and normal 
regions, of a biological tissue. 
Computer added methodologies have been implicated in 
the biomedical imaging acquisition and analysis for a long 
time. A computed tomography (CT) is a reconstructed 3D-
image from a serious of radiographies. Program associated 
with a confocal microscope scans fluorescent micrographs 
and rebuilds them into 3D images or movies (3D + time). In 
a molecular biology laboratory, programs assist biologists to 
compare and find differentially expressed spots (genes) from 
2D electrophoresis gels. The development of different image 
acquisition tools now yields an explosion of images that are 
difficult to be analyzed in detail. Development of new tools 
for processing, analyzing and utilizing biological as well as 
medical images has increasing necessity.  
In this paper, a high-level programming framework based 
on object relational algebra [13] is proposed to facilitate such 
tasks for researchers and potential users. Some example 
scenarios are provided also to demonstrate its usefulness. 
II. BACKGROUND 
The foremost benefit of using a high-level programming 
language for writing software is gaining rapid development 
of the software. However, this is almost always accompanied 
by lower run-time performance. Some studies have dedicated 
to high-level programming of image processing applications 
in the past. Most of them focused on increasing the run-time 
performance of the high-level language. Crookes et al. [1] 
have developed a high-level programming language, called 
IAL (Image Algebra Language), for image processing. IAL 
provided a standard mathematical notation for low-level 
image processing development work and had the advantage 
of being able to implement on a parallel transputer networks. 
Based on dataflow architecture, Sérot et al. [2] presented a 
 12
objects of E according to the set of attributes specified in 
S (in the form: attribute, attribute, ….), and for each 
group applying the aggregation function f to the set of 
objects corresponding to attribute A to obtain a value, a 
set of values, an object or a set of objects. The possible 
aggregate functions include primitive functions such as 
min, max, mean, variance, avg, sum, count that can be 
applied to a group of primitive values. The aggregate 
functions can also include functions defined by users to 
a group of non-primitive objects. For example, a user 
can define a best image function to process a collection 
of visual image files and return as output one or more 
visual image files with the best signal-to-noise ratio. 
IV. BASIC FUNCTIONS FOR IHC IMAGE ANALYSIS 
We have implemented an automated procedure based on 
image morphology for diagnosis of cancerous tissue in IHC 
images. Different image processing algorithms are utilized to 
extract cell compartments and fluorescence intensities in 
individual cells. For simplicity, it is assumed that the pixel 
intensity is linearly related to the amount of proteins, and 
therefore the average intensity within a cell can be 
interpreted as a relative protein concentration. To improve 
the subjectivity and long time-consumption of manual 
analysis, the technique does not require any manual 
intervention by the operator. 
The images considered in this paper are characterized by 
blue stain (Haematoxylin and Eosin, H&E) for highlighting 
the tissue structure, which represents the background. Brown 
stain (Diaminobenzidine, DAB) shows protein activity. Note 
that accurate tracking of nuclear membranes is fundamental 
in IHC analysis. Nuclear segmentation is in general the first 
step for segmentation and quantification of protein activity of 
the other cellular compartments. Thus, a lack of accuracy of 
this step may alter the result of IHC analysis in a substantial 
way. The main steps of the procedure are the following. 
A. Color Deconvolution 
The goal of differential staining is to provide indicators 
of the distribution of the substance or structures to which the 
stain is specifically attached. The amount of stain attached or 
deposited will determine the optical density at stain-specific 
wavelengths in accordance with the Lambert-Beer law, with 
optical density being proportional to stain concentration. To 
solve the problem of separating contributions from multiple 
stains, a specific color deconvolution algorithm [9] is used to 
deconvolve color information acquired by RGB cameras and 
to calculate the contribution of each of the applied stains on 
the basis of the stain-specific RGB absorption. The original 
color image is separated into two monochromatic ones that 
contain respectively the contribution of the blue stain (H&E) 
and of the brown stain (DAB), as shown in Fig. 1. 
B. Cell Extraction 
Nuclei are separated from background through automated 
thresholding of the monochromatic images generating from 
separation of stains. A typical problem is that intensity level 
may vary among different regions of the sample because of 
inhomogeneous illumination and inconsistent staining. The 
local adaptive threshold [10] dependent on local distribution 
of the intensities is applied, which leads to a better accuracy 
than traditional global thresholding. The procedure is hence 
customized through a statistical analysis of the local intensity 
distribution. This analysis intends to minimize the effects of 
unrepresentative pixel values due to noise. Only contribution 
of the blue stain is considered to distinguish nuclei from the 
background. An example of the intermediate results after cell 
extraction is shown in Fig. 2. 
 
(a) 
 
(b) 
 
(c) 
 14
Output: IHC image labeled with the cancerous and normal 
regions 
 
1. RF = color-deconvolute(A, ‘White’)  //Identify the non-
stained region from IHC image A as region fat (RF) 
2. BlueA = color-deconvolute(A, ‘Blue’) 
3. BrownA = color-deconvolute(A, ‘Brown’) 
4. CEA = cell-extract(A) 
5. RC = identify-cancer-region(difference(CEA, RF))  
//Identify region from CEA-RF as cancerous region (RC) 
6. RN = identify-normal-region(difference(CEA, RF))  
//Identify region from CEA-RF as normal region (RN) 
7. C = super-impose(A, RC, RN)  //Define IHC image 
labeled with RC and RN as image C 
 
Question 2 
Is the target protein over-expressed or under-expressed in 
the cancerous tissue? 
Input: one IHC Image 
Output: over-expressed or under-expressed 
 
1. RF = color-deconvolute(A, ‘White’)  //Identify the non-
stained region from IHC image A as region fat (RF) 
2. BlueA = color-deconvolute(A, ‘Blue’) 
3. BrownA = color-deconvolute(A, ‘Brown’) 
4. CEA = cell-extract(A) 
5. RC = identify-cancer-region(difference(CEA, RF))  
//Identify region from CEA-RF as cancerous region (RC) 
6. RN = identify-normal-region(difference(CEA, RF))  
//Identify region from CEA-RF as normal region (RN) 
7. IAC =intensity(BrownA, RC)  //Quantify the brown stain 
intensity on RC, define the value as IAC 
8. IAN =intensity(BrownA, RN)  //Quantify the brown stain 
intensity on RN, define the value as IAN 
9. O = compare(IAC, IAN)  //Compare IAC with IAN, 
define O as the result of over-expressed if IAC > IAN, or 
under-expressed if IAC < IAN 
Question 3 
Compare two IHC images. Which one has a higher 
expression level of the target protein? 
Input: Images A and B 
Output: A or B? 
 
1. BrownA = color-deconvolute(A, ‘Brown’) 
2. BrownB = color-deconvolute(B, ‘Brown’) 
3. EA =intensity(BrownA, A)  //Quantify the brown stain 
intensity on A, define the value as EA 
4. EB =intensity(BrownB, B)  //Quantify the brown stain 
intensity on B, define the value as EA 
5. O = compare(EA, EB)  //Compare EA with EB, define O 
as the result of higher expression level if EA > EB, or 
lower expression level if EA < EB 
Question 4 
Select patients who over-expressed the target protein and 
are HBV positive. 
Input: a set of IHC images A1, A2, … An and medical 
record 
Output: Patient ID(s) 
 
1. SIHC = set(A1, A2, … An) 
2. SRF = color-deconvolute(SIHC, ‘White’)  //Identify the 
non-stained region from IHC image set SIHC as region 
fat set SRF = {RF1, RF2, …, RFn} 
3. SBlue = color-deconvolute(SIHC, ‘Blue’) 
4. SBrown = color-deconvolute(SIHC, ‘Brown’) 
5. SCEA = cell-extract(SIHC, ‘Blue’) 
6. SRC = identify-cancer-region(difference(SCEA, SRF))  
//Identify region from SCEA-SRF as cancerous region 
(SRC) 
7. SRN =identify-normal-region(difference(SCEA, SRF))  
//Identify region from SCEA-SRF as normal region (SRN) 
8. SIAC = intensity(SBrown, SRC)  //Quantify the brown stain 
intensity on SRC, define the value as SIAC 
9. SIAN = intensity(SBrown, SRN)  //Quantify the brown stain 
intensity on SRN, define the value as SIAN 
10. SO = compare(SIAC, SIAN)  //Compare SIAC with SIAN, 
define SO as the result of over-expressed if SIAC > SIAN, 
or under-expressed if SIAC < SIAN 
11. Output patient ID i if Oi ∈ SO is over-expressed 
VI. CONCLUSION 
This paper has pointed out the necessity of developing a 
useful tool for biologists and medical researchers to perform 
image analysis of biomedical applications. Ideally, user can 
operate such tool at his/her will to analyze images without 
any knowledge of programming; meanwhile, this tool should 
be flexible enough to execute workflow assigned by user. 
High-level programming designed especially for image 
analysis is thus one solution to the need. 
Similar to other high-level programming languages, the 
proposed one also adds the feature of enumeration operation 
borrowed from the concept of database. Besides, the function 
set is able to expand its size incrementally. The future work 
is to integrate the high-level programming and function set 
with a user-friendly interface. 
ACKNOWLEDGMENT 
This work is supported in part under grant numbers NSC 
99-2221-E-468-007, NSC 99-2221-E-024-010, NSC 99-
2221-E-468 -021 and NSC 99-2632-E-468-001-MY3 from 
the National Science Council, Taiwan, and Asia University. 
The views, opinions and/or findings contained in this report 
are those of the authors and should not be construed as an 
official National Science Council position, policy or 
decision unless so designated by other documentation. 
 
REFERENCES 
國科會補助計畫衍生研發成果推廣資料表
日期:2011/10/10
國科會補助計畫
計畫名稱: 研發語意生醫線上分析處理服務技術
計畫主持人: 陳榮銘
計畫編號: 99-2221-E-024-010- 學門領域: 人工智慧
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
1.獎項榮譽 
獲得獎項: 本計畫部份成果獲得教育部建國百年開放軟體創作競賽智慧感知與
辨識組銅牌 
作品名稱: 智慧型電腦輔助免疫組織化學染色影像癌症相關基因檢測系統之研
發 
參與學生: 吳宜臻、莊淑茹 
頒獎日期: 2011 年 5 月 18 日 
 
2.辦理學術活動 
計畫主持人參與主辦生物資訊相關之國際研討會: 
研討會名稱: 第 11 屆 IEEE 國際生物資訊暨生物工程研討會 
11th IEEE International Conference on Bioinformatics and Bioengineering 
(BIBE 2011) 
主辦單位: 
IEEE Computer Society, Biological &amp； AI Society (USA) 
Asia University, National University of Tainan (Taiwan) 
National Science Council, Ministry of Education (Taiwan) 
網址: http://bibe2011.asia.edu.tw/ 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
