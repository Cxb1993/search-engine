2攝影機與立體視覺進行即時特定成員追蹤與辨
識，並可藉由頭部擺動方向判定使用者指令。而
Mitsutoshi Yoshizaki等人[5]同時使用語音與機器視
覺設計一具搬運機器人，使用者可以用語音命令機
器人搬運東西，再藉由機器視覺找到欲搬運物體以
執行使用者命令。Dong Sun 等人[6]設計一具機器
視覺的高樓玻璃清潔機器人，利用雙 CCD 與雷射
二極體算出機器人本身在高樓玻璃上的幾何位
置，再使用機器視覺做骯髒區域搜尋並進行打掃。
Grzegorz Cielniak 等人[7]以雷射與攝影機作成員偵
測與辨識，先以雷射偵測附近週遭是否有人，再以
偵測物的顏色資訊作成員辨識，其中還使用 Kalman
Filter 進行偵測物追蹤。Tomoki Kobayashi 等人[8]
提出一套模仿幼兒表情學習方法的寵物型機器
人，利用觸碰開關與 Webcam等感測器，紀錄並學
習各種情緒的表情，同時也可以透過人工眼睛與嘴
巴組出三種心情的表達。Kai-Tai Song等人[9]研發
一個可以利用 PDA 進行遠端監控，以及具人臉辨
識與追蹤等保全功能的機器人，並且可根據感測器
與模糊控制器作行為分類模式。Taigun Lee 等人[10]
建立一套有效率的臉部特徵萃取方法，主要為結合
方向性像素強度樣板與臉部特徵樣板比對來快速
完成人臉偵測，並應用於室內機器人之系統介面
上。
為因應現在的大廈公寓居住習慣，同時增加整
合型智慧機器人服務範圍與能力，本實驗室設計讓
機器人具有自行上下樓梯的功能，並搭配路徑規劃
功能與辨識功能，可以完成整棟樓層的服務。
三、系統簡介
3.1系統架構
自搭電梯智慧型家用機器人的全系統功能架
構圖與硬體設備如圖 1與圖 2所示。
全系統功能可分為運動控制部份、感測系統部
份、自搭電梯系統與保全巡邏系統，並整合完成本
研究計畫的所有功能。
在硬體架構上，自搭電梯智慧型家用機器人具
備 2條 3軸伺服馬達機械手臂來執行按鍵動作或其
它工作，頭部則以步進馬達轉動 WebCam旋轉平
台，而機器人是以 2顆直流馬達差速帶動履帶產生
行進運動。以上整個控制核心為 DSP2407 控制器，
其中還包括感測避障、PID馬達控制及與主電腦溝
通等部份。在感測模組上，本機器人使用碰撞感測
器、紅外線感測器和 CMOS WebCam作為系統對外部
環境資訊的擷取工具。另外，本系統使用介面則設
立於機器人上的主電腦，主要負責路徑規劃運算及
影像偵測與辨識處理，並且進一步與 DSP2407 進
行溝通。
圖 1. 全系統功能架構圖
(a)
(b)
圖 2. 全系統硬體設備圖
(a) 家用機器人概念圖  (b) 家用機器人實體圖
4









2222 )()(
,
)()( rgrg
rg
rgrg
rg
yyxx
yy
yyxx
xx
G











2222 )()(
,
)()( oror
or
oror
or
yyxx
yy
yyxx
xxP

(3.4)
圖 3. 人工位能場示意圖
3.3.2 模糊控制之路徑規畫
機器人依照各方位的感測器所得到的障礙物距
離與個數,使用障礙物狀況為模糊輸入 ,再以圖 4 的
歸屬函數和規則表作模糊推導 ,最後用重心法解模
糊。
(a)
(b)
圖 4.  (a) 歸屬函數 (b) 規則表
3.4成員辨識
本系統於成員辨識部分使用 LDA (Linear
Discriminate Analysis)分類器，以完成保全巡邏功
能。因 PCA 分類器所得到的特徵參數僅能區別出
各張不同的影像，而要辨識出不同類別的人臉之鑑
別能力較差。LDA分類器最主要的是能將不同類別
樣本之間的中心點拉開，並將屬於同一類別之間的
影像分散程度縮小。
同一類別內原始參數之間的散佈程度，也就是原始
參數與該類別中心點的距離，可以用類別內散佈矩
陣（Within-Class Scatter Matrix）來表示：
   
1 1
x
C M T
c c c c
W m m
c m
x x x x
 
    
其中
cx 表示第 c類中所有原始參數的平均值。
而不同類別間的散佈程度，也就是不同類別中心點
之間的距離，則可用類別間散佈矩陣
（Between-Class Scatter Matrix）來表示：
   
1
x
C T
c c
B
c
x x x x

   
其中 x表示所有原始特徵參數的平均值。
LDA 轉換的目的，就是要找出一個轉換矩陣W ，
來縮小轉換後同一類別內特徵參數與該類別中心
點的距離，並且拉大不同類別間中心點的差距。
  1 ][
x xW B
rEigenvectoW (3.5)
四、實驗結果與討論
在電梯面板偵測與辨識實作中，分別對電梯內
外進行處理，如圖 5、6、7所示，受到光源變化影
響會造成影像中雜訊過多而偵測錯誤，訓練資料數
目多寡直接影響到後續辨識結果的精準度。所幸，
在經過影像白平衡和形態學開運算後可有效降低
小塊白色區塊雜訊產生；另外，增加訓練樣本後，
電梯面板按鍵辨識結果也大為改善。
(a)   (b)
6在成員辨識實驗中，經使用 ORL Face database
作鑑別率測試，在資料庫內取 5個成員，每個成員
取 10張訓練樣本作 PCA鑑別率測試下，在 8個成
員共 320 個測試樣本內仍可達到 93%的鑑別率與
2.5%的錯誤拒絕率。實驗結果如上表 1所示。而在
即時動態辨識方面，在輸入影像解析度為 320x240
pixels，訓練人臉資料庫為成大工科系統整合實驗
室成員資料庫，共 8個成員 8張訓練樣本，經小波
轉換後每秒可處理 9 至 10 張影片，實際測試結果
如下圖 9所示，系統速度可達到即時且動態辨識率
良好。
圖 9.  The result of real-time dynamic recognition
五、成果自評
本研究計畫針對現代居住習慣，設計機器人自
搭電梯能力，同時提供自動巡邏與保全監視的功
能。系統藉由影像處理可以成功即時偵測與辨識出
電梯場景及家庭成員。而機器人搭配感測器與路徑
規劃演算法，能夠在未知的動態環境下安全地完成
巡視內巡邏的工作。
六、參考文獻
[1] George. A. Bekey, “Autonomous Robots From
Biological Inspiration to Implementation and
Control ,” The MIT Press Cambridge, London,
England.
[2] Daniel Ichbiah, “ROBOT From Science Fiction to
Technological Revolution,” Harry N. Abrams, lnc.,
Publishers.
[3] Tomono, M. and Yuta, S. , “Mobile robot
navigation in indoor environments using object and
character recognition,” Robotics and Automation,
2000. Proceedings. ICRA '00. IEEE International
Conference on Volume 1, 24 -28 April 2000
Page(s):313 - 320.
[4] Doi, M., Nakakita, M., Aoki, Y., and Hashimoto,
S., “Real-time vision system for autonomous mobile
robot,” Robot and Human Interactive Communication,
2001. Proceedings. 10th IEEE International Workshop
on 18-21 Sept. 2001 Page(s):442 - 4490.
[5] Yoshizaki, M., Nakamura, A. and Kuno, Y.,
“Mutual assistance between speech and vision for
human-robot interface,” Intelligent Robots and System,
2002. IEEE/RSJ International Conference onVolume 2,
30 Sept.-5 Oct. 2002 Page(s):1308 - 1313 vol.2.
[6] Zhu, Jian, Sun, Dong, and Tso, Shiu -Kit,
“Application of a service  climbing robot with motion
planning and visual sensing,” Journal of Robotic
Systems, v 20, n 4, April, 2003, p 189 -199.
[7] Cielniak, G. and Duckett, T., “Person
identification by mobile robots in indoor
environments,” Robotic Sensing, 2003. ROSE' 03. 1s t
International Workshop on 5 -6 June 2003 Page(s):5
pp..
[8] Kobayashi, T., Ogawa, Y., Kato, K., and
Yamamoto, K., “Learning system of human facial
expression for a family robot,” Automatic Face and
Gesture Recognition, 2004. Proceedings. Sixth IEEE
International Conference on 17 -19 May 2004
Page(s):481 - 486.
[9]  Chia-How Lin, Andrian, H. ,Yao -Qing Wang,
and Kai-Tai Song, “Personal assistant robot,”
Mechatronics, 2005. ICM '05. IEEE International
Conference on 10-12 July 2005 Page(s):434 – 438.
[10] Taigun Lee, Sung-Kee Park, and Mignon Park,
“A New Facial Features and Face Detection Method
for Human-Robot Interaction,” Robotics and
Automation, 2005. ICRA 2005. Proceedings of the
2005 IEEE International Conference on 18 -22 April
2005 Page(s):2063 - 2068.
