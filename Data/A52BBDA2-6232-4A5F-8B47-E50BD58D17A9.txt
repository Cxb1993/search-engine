 
Figure 1:  Video Content Management System 
Architecture 
In this paper, we proposed a video content 
management system, that integrated three main 
components: Shot Ontology Definition, Feature Extraction, 
and Video Indexing component. In shot ontology 
component, we gathered statistics in basketball sport video 
and then to derive the temporal descriptors in event 
occasions: shot change, shot sequence, court color, and 
shot type. With comparing the features in different shots, 
we used the histogram to calculate several shots which 
segmented to different shot from one video film[2][3][9].  
In the final film indexing step, we marked the shot 
content and the event time on the time axis after the  
characteristics of the film was grabbed occasionally. 
Afterwards, the scoring events, the long shot and the 
close-up shot would be gragged with the Film Event Index 
System which was developed by our system. The 
contributions of this paper was summarized as followings: 
 
z The system would be provided with extensibility by 
the description of shot ontology. 
z A new shot method of shot-classification was 
suitable for the basketball sport film without any 
neural training or other cutting frame of ROI. 
z It provided a direct indexing for the scoring events in 
the basketball sport film. It assisted a great for saving 
time and man power respectably. 
z A convienience index software was developed for 
the user to process the behavior of event indexing, 
especially for the content index of baseketball sport 
film. 
 
Paper Structure 
The correlated research work would be explained 
and defined on chapter 2, including the introduction of the 
video file format, the definition of the ontology, and the 
related analysis of the video film. The chapter 3 would 
introduce the definition of the shot ontology in this paper. 
The chapter 4 would illustrate the system implementation 
and the collection method for each characteristic values. 
The chapter 5 explained and estimated the implementation 
and the experiment results. And the chapter 6 came out a 
conclusion with the future research eventually, 
 
2 The Video Indexing 
 
 
 
Figure 2. Abbreviation in basketball event 
 
The attribute table of  the shot ontology was the 
basic intension of the ontology. According to the attribute 
of  that table, we could establish an shot ontology for the 
basketball sprot (refer to Figure 2 and 3).   
 
 
Figure 3. Shot Ontology 
 
2.1 Shot Ontology 
The major different between the sports program 
and the regular TV program was the scriptwriter,  the 
process of a game and its result was unpredictable and 
unexpecdictable. That was the reason why the sports game 
was so attractive to all kinds of the sport fans. When it 
comes to ‘game’, meaning competiting, there must be 
certain rules for game, and also there was necessary to 
have some buzzword to assist the definition while it 
occurred in a game course. Such as the essential of scoring 
was to throw the basketball into the basket frame in other 
court in a game, and the accumulation of the points in a 
whole game was the key factor to decide the winner 
eventually. We could classify the ‘points’ in the followins:  
2-points, 3-points, free thows, and so on. Therefore, we 
could conduct a possible sequent order of a game with the 
varied buzzwords, and the process could be in a 
continuous series of dribbling, passing, three-pointing and 
goaling finally (refer to Fig. 4).  
Shot 
Content-Ch Motion Shot 
Type 
Temporal 
{Yes, No} {Low, High} 
{Long, Close Up} 
Goal Event With 
{Meets, Before, 
Completes, Starts 
…..} … 
 
Shot Boundary 
Detection 
Shot 
 Classification 
Play/Break 
 Detection 
Slow-Motion Replay 
Detection 
Automatic 
Color Modeling 
Moving Object 
Segmentation and 
Tracking 
Video Semantic 
Analysis 
Low level Feature Extraction 
●Close Shot: This should not contain any court color or 
skin color was greater than the court color. It would be 
the Close Up Shot if the absolute value was greater than 
∂  and the ratio of skin color was greater than σ . 
The valur of  ∂ and σ were the experience value 
which could be adjusted by the accuracy. In this study, we 
got a best classication result by the setting of ∂ =25 amd σ =10. And the algorithm of the classification was 
descripted as following: 
 
 
Since the classification was decided by the ratio of the skin 
color and the court color, we could define the descriptors 
for the shot ontology certainly(refer to Figure 7). 
 
Figure 7.  Descriptors of Shot classification 
 
●Score Board 
There were two type of the text format in a multimedia 
film: Contain Text and Caption Text. The Contain Text 
was existed on the picture frames, such as the player 
number on the shirt. And the Caption Text was the word 
effect on the screen by the man-made, such as the subtitles 
for the drama program of TV. It aslo provided the 
information durning the broadcasting of a sport program, 
such as the team names on the game, the periods of the 
game, the time remained, ans the current scoring result 
(refer to Figure 8). In our study, we had a summary that the 
scoring event would be identified easily and clearly be the 
Score Board changing directly. Therefore, we would 
utilize this characteristic for the event detection. 
 
Figiure 8. The text shown on the picture frame 
 
●Temporal Relation 
After the compiling statistics result of four games, we got a 
event sequence list for the Long Shot and Close Up Shot 
whcih shown as Figure 9. 
 
 
Fig. 3-7 The sequence of Shot types and events 
 
For example on the sequence S1 and S2: the S1 
was defined as a Long Shot. When a foul(ful) occurred, the 
indifferent(ind) event raised accordingly. And a serial of 
field goal or some indiffenent event would be followed 
consequently. We could simplify the similar type of shot 
as followings: 
Step 1: It could be simplified to the same one sequence if 
the status of current shot was same as next shot. 
But the event of current shot should be retained. 
Step 2: Repeated the previous step 1 until all sequences 
were simplifed completedly. 
Step 3: Expanded the simplification to two sequences for 
one sequent unit . It could be simplified to one 
sequent unit if the status of current sequence was 
same as next sequence. 
Step 4: Repeated the previous step 3 until all sequent 
units were simplifed completedly. 
For example, it could be simplified to same 
sequence if a Close Shot occurred after a previous Close 
Shot (refer to Figure 10). 
Contain Text 
Caption Text
S4/cmeOS1/cmeL S2/cmeO
ful/ind
S3/cmeO 
ind/ft 
ft/ft
ft/Gol 
S5/cmeL S6/cmeO
Gol/ind
S7/cmeL 
ind/Gol 
S8/cmeO
Gol/ind
S9/cmeL
os/ful 
S10/cmeO
ful/ind
S11/cmeL 
ind/ful 
…… 
Shot Descriptors 
Skin 
Color 
Court 
 Color ∂ &σ
 end        
1;nt2(j)TmpVoteCount2(j)TmpVoteCou            
sity;pos1insten)TmpVote2(j            
1;jj            
else        
1;tensity)nt2(pos2inTmpVoteCoutensity)nt2(pos2inTmpVoteCou              
   0itypos2intens if        
sity);pos1instente2find(TmpVoitypos2intens        
column);row,intensity(itypos1intens        
end        
1;nt(j)TmpVoteCount(j)TmpVoteCou            
pos1Hue;TmpVote(j)            
1;jj            
else        
1;)nt(pos2HueTmpVoteCou)nt(pos2HueTmpVoteCou            
   0pos2Hue if        
pos1Hue);tefind(TmpVopos2Hue        
column);Hue(row,pos1Hue        
lengthcolumn  :1columnfor     
length row :1rowfor 
+=
=
+=
+=
>
===
=
+=
=
+=
+=
>
===
=
=
=
 
3. We could get the value of court color through the Court 
Color Sample. This value would be used to decide the 
shot type from the proportion of skin color for each 
shot. And we took the first frame of each shot for the 
identified terms of shot type. Then we could update 
the table of shot detection after the shot type was 
collected continuously. 
 
●Transformed RGB value to IReBy 
(log-opponent)： 
1)log10(x*105)(as defined isoperation  L(x)
2/)]()([)(
)()(
)(
+=
+−=
−=
=
xL
RLGLBLBy
GLRLRg
GLI
 
 
●We had set the window size of 8 and filtered out the 
noisy signals of I, and made a absolute value of the 
subtraction with the original I and filtered I. Afterward, we 
could get the most appropriate texture of skin. Finally, we 
could detect a suitable skin texture in our experiment when 
the value of I was greater or equal to 5 effectively 
The transformation from IrgBy to HSV, we could 
capture the color range of skin with Hue and Saturation in 
our study. And the equation of transformation shown as 
folloings: 
 )By+ sqrt(Rg= saturation
By))(Rg,t(arctangen = hue
22
2
 
skin map corresponds to a pixel  
110<=hue<=180 and 0<=saturation<=130  
 
        
(a)Original Frame        (b) Skin Color Extraction  
 
●Next, the detection of score borard was the check point 
for a time period of scoring event. As we mentioned 
previously that the scoring event probably was not an 
impressive segments in a game. Since the event was 
impressive or not would be a subjective issue from  
●We grabbed the frmae Fl  from the Long Shot, then 
calculated the edge portion of that frame, and named it as 
El (refer to Figure 4-7). 
 
Figure 4-7  Grabbed a frmae from the Long Shot,  
and calculated the edge portion. 
 
●We grabbed the frmae Fc  from the Close Up Shot, 
then calculated the edge portion of that frame, and named 
it as Ec  (refer to Figure 4-8). 
 
Figure 4-8  Grabbed a frmae from the Close Up Shot,  
and calculated the edge portion. 
 
Expand the El 、 Ec  from the morphological theory 
 
●We compared every pixel with El and Ec , it would be 
the Caption Text pixel if the pixel of El was existed at the 
Ec in the same time. And we also set the pixel=0 if it was 
not existed(refer to Figure 4-9). 
●Filtered out the noisy signal be the median filter (refer to 
Figure 4-10). 
 
Figure 4-9   Figure 4-10 
the Caption Text pixel The result after filtered 
 
●The last step was the variation of the momentum, this 
could distinguish the shot of field goals and the shot of free 
throws by the attributes of the shot ontology. Basically, 
this step should be combine with shot detection, which was 
detected by the color statistic of Color Histogram. We 
collected the momentum from the discrepancy between 
previous frame and next frame. Thus, the accumulation of 
momentum of each shot could be recorded in a data list by 
Multimedia, boston, MA, pp.87~98, November. 1996 
[8] Blobworld, http://elib.cs.berkeley.edu/ 
photos/blobworld/ 
 
 
[9] J. M. Corridoni, A Del Bimbo, “Structured 
representation and automatic indexing of movie 
information content”, Pattern Recognition, Vol.31, 
No.12, pp.2027-2045, 1998 
