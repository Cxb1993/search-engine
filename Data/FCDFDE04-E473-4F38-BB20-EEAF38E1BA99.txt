 2
目錄 
(一) 研究計畫之目的 
-----------------------------------------------------------------------------------------page 3; 
(二) 計畫執行研究成果展 
-------------------------------------------------------------------------------------page 3-47; 
( 1 ) 研究方法之背景與動機、進行步驟含成果、及執行進度 
--------------------------------------------------------------------------------page 3-14； 
( 2 ) 相關計畫碩士論文一：透過強韌性多邊形逼近、適應與修正之處理，來
完成吻合度改良之蛇狀形變套索 
-------------------------------------------------------------------------------page 15-22; 
( 3 ) 發表論文成果: 
1. Din-Yuen Chan, Roy C. Hsu, Jia-Ci Jhuo, Bin-Wen Kao, and Cheng-Tin 
Liu, “Polygon Approximation for Snake Initialization In Noisy Image”, 
International Workshop on Computer Vision and Its Application to Image 
Media Processing, Japan, Jan. 2009. 
-----------------------------------------------------------------------------page 23-28； 
2.Din-Yuen Chan, and Roy Chaoming Hsu, “Robust Shape-Preserving 
Contour Tracing with Synchronous Redundancy Pruning,” Pattern 
Recognition Letters, Vol. 29,   Issue 5, pp. 569-579, Apr. 2008. 
-----------------------------------------------------------------------------page 29-39； 
3. R.C Hsu, D.Y. Chan, J.C Jhuo, B.W. Kao ”A Robust Object Contour 
Extraction Using Polygon Approximation and Localized Edge Linking,” 
22th IPPR Conference on Computer  Vision, Graphics and Image 
Processing, CVGIP 2009.  
-----------------------------------------------------------------------------page 40-47; 
(三) 參考文獻
-----------------------------------------------------------------------------------------page 48-49； 
(四) 計畫成果自評
----------------------------------------------------------------------------------------------page 50;
 4
下，自動適應所切割影像特性及 evolution 目前位置作有效作調整，進一步，把
影像當“動態環境＂來看，考慮如何修正補償蛇形套索系統之不佳收斂結果，我
們以一有效低判斷錯誤之紋路對比方式，從第一次收斂完 snake contour 中找到失
敗 Snaxels，再啟動補償方向性 evolution，去修正它們，讓它們有效逼近原來很
難貼近之物件上較尖銳突出的尖角輪廓和深凹輪廓；簡言之，本研究計劃第一部
份企圖去從基本解決研究計畫背景中所提及四個的問題，而本研究計畫作改良蛇
狀形變套索模型時，都是將儘量考慮壓低所需額外計算複雜度下來發展，以期望
其更有機會被應用於計算量大的視訊處理中之影像物件切割。 
II.相關本計畫第二部份而言 
因第一部份計畫中需檢測第一次收斂完snake contour中失敗Snaxels，相對就
是也同時檢測出其他已很貼近物件輪廓所謂成功之Snaxels ，將第一次收斂完
snake contour，等分六段，經紋路對比(texture contrast)，每段選取紋路對比較“清
楚＂Snaxels-相對上較成功之SCSs(successfully converged Snaxel: SCS, i.e., hit 
Snaxel)，當Affine transform之錨點(seeds)，以六個錨點為中心之六個block對下一
張畫面上做block-based ME搜尋，找到移動向量後，用其來求出Affine transform
之矩陣，以鎖定物件之移動，完成框住移動之物件，再啟動content-triggered 
adaptive snake model (CTASM)作少量evolution steps就可很快修正貼近包住移動
物件之輪廓，來完成智慧型監視系統前端，因我們提出之適應性蛇形形變套索
Snaxels收斂好壞之判斷，可以直接提供良好Affine transform之seeds之選擇，提供
良 好 連 續 畫 面 snake model 對 同 一 物 件 的 快 速 連 續 切 割 、 移 動 掌 握
(object-exploration, shape-recovery)，對監視視訊之應用有很好，所以本計畫第二
部份，物件移動較慢時，採Affine transform繼而再CTASM，其Affine transform須
設定六個錨點(seed)，以六個錨點做類似motion estimation (ME)之移動搜尋，找到
移動位置後，用其來求出Affine transform之矩陣，以此矩陣搬其他sanxels至video
下一張畫面上當initial snake contour，然後做CTASM；當物件移動很快時，必須
擴大ME移動搜尋範圍，再做搜尋一次，為計算複雜度之consistence/uniform，可
能必須犧牲物件形變之詳細掌握（輪廓精準切割），所以不做Affine transform，
直接將六個seeds找出之六個移動向量(motion vectors: MVs)，依其他sanxels相對
此六個seeds之位置，經線性內插得它們之MVs，搬那些sanxels至video下一張畫
面當initial snake contour。另一種special case則是物件相對監視器monitor2-D座標
移動距離雖小，但事實上因物件動作快造成形變大，例如本計畫作模擬的熱帶魚
游動序列中，游魚瞬間轉身片段，此時六個seeds以block matching將找不到六個
移動向量，我們就以找到之少於六個移動向量做平均，將上一張畫面中收斂好之
snake contour直接以此平均向量平移至下一張畫面中，線性擴大後當下一張畫面
作CTASM之初始snake contour，作較多移動Snaxels次數之CTASM evolution。 無
論如何，此計畫第二部份所須六個seeds與第一部份很直接相關，即第一部份對
第二部份幫助很大，簡言之，第二部份表現之好壞與計畫第一部份相依性很高。 
 6
 
圖一.  CTASM 系統圖 
A.CTASM 係數調整方式之簡介： 
a.彈力及張力權重因數的適應調整方式 
 根據適應適性濾波器(adaptive filter)的重要精神：濾波器模型係數之權重改
變的傾向(增或減)，是基於訊號特性之局部變動，濾波器係數(濾波權重因數)之
增或減對輸出是否為“正向＂影響或“負向＂影響而定。 
b.內部與外部力量之適應性正規化 
數值上，Snake 收斂之效果是與如何將內部與外部力量之正規化後再相加為
Snake 合力，有著密切關係。當在有邊雜訊(edged noise)影像中操作蛇狀形變套索
模型，蛇狀形變套索的起始輪廓距離目標物件邊界較遠時，它或許會無法去靠近
目標物件邊界，達可接受之能量最小化。而如只試圖去加強內部力量來解決這個
問題，將可能引起更多的 Snaxels 去淹沒了目標物件的邊緣，收斂在目標物件的
內部。 
c.阻尼因數的之適應性修正 
 當一個 Snaxel 靠近到目標物件邊緣，而它的 evolution 移動表現像鐘擺來來
回回，這可能暗示作用於此 Snaxel 各種力量形成一個拉距的狀態，致使其
evolution 路徑為沿目標物件邊緣之鋸齒狀態，此狀態除了讓 snake 收斂減慢外，
可能正是預言著這個 Snaxel 將錯過(越過)一個實際的物件邊界。因此，為了減少
 8
seeds，做 ME 之移動搜尋，在 video 下一張畫面上找到移動後對應位置，用移動
向量來求出 Affine transform 之矩陣，以 Affine transform 矩陣，來搬剩下其他
sanxels 至下一張畫面上當 initial snake contour，然後執行 CTASM 作很少次數之
evolution movements；當物件移動很快時即大多數 SCSs 錨點之 MV 在剛好無論
是對 x 軸或 y 軸就是為最大移動向量，則擴大 ME 移動搜尋範圍一次，再延伸距
離搜尋做 ME 一次，為讓在每張畫面計算複雜度較一致（consistence），可能必須
先不去計較物件之詳細形變，所以不做 Affine transform，而直接將六個 seeds 找
出之六個移動向量(MVs)，依其他 sanxels 相對此六個 seeds 之位置，作線性內插
得那些 sanxels 之估計 MVs，來搬它們至 video 下一張畫面當 initial snake contour，
然後，還是要執行 CTASM 作很少次數之 evolution movements。 
(二-1-3)執行計劃之實驗成果 
I.計畫第一部份之實驗結果 
在我們實驗，所用前處理已完成有蛇狀形變套索初始化之選距目標物件不遠
之 initial Snaxels(請參閱發表論文成果 1)，如圖八以 initial Snaxels 連結多邊形，
由結果可見即使有雜訊或不單調之背景，切割成果就已很近目標物件之外型，我
們所提方案已大致完成良好強韌之蛇狀形變套索初始化。 
此計畫將進一步讓 CTASM 能自動決定是向內收縮或向外擴充，來切割在
snake 內或外之目標物件輪廓，當然，如果是向外擴充則只要程式中部分反轉以
上描述力量方向即可。以下的圖表皆為實驗數據以及成果圖。 
 
表 1 Comparison of contour BMAD values 
Traditional active contour model 
shown in Figure 3(b) 
 CTASM shown in Figure 
3(c) Test object 
3.336 1.247 
 
表 2  Comparison of contour BMAD values 
Traditional active contour 
model shown in Figure 4(a)
CTASM in Figure 4(b) 
3.583 1.247 
Traditional active contour 
model shown in Figure 5(a)
 CTASM in Figure 5(b) 
Medical image with 
artificial regular 
texture 
3.508 1.074 
 
 10
 
圖四 Converged snake contours obtained by (a) the traditional active contour model 
(b) CTASM in medical image with edged background. 
 
圖五  Converged snake contours obtained by (a) the traditional active contour model 
(b)  CTASM in medical image in medical image with edged background. 
 
圖六(a). Test image with hoofed object and two artifact noise peaks added in 
background 
 
圖六(b). Arrowed lines representing the vector flow forces generated by the GVF 
model in a test image shown in Fig.6 (a). 
 12
擇一個呈現最明顯內外紋路差異之 Snaxel 作 Affine Transform 之 seed；以面積等
份分六段方式，其分法較吻合人類視物件為 pixels 2-D 集合之直覺，因以 snake
等點數 sanxels 作六區段分割，可能曲率變化大不規則處分到區段表示物件範圍
相對太小，造成幾個 seeds 擠在一小區域，如此作出之 Affine Transform 矩陣，
來移動 snake contour，失真可能性就可能很大。 
此我們挑選熱帶魚轉身之連續三張畫面 frame #119-121 做初步模擬和說明： 
前兩張frame #119-120為正常利用Affine Transform 和CTASM方法，以圖8-1到圖
8-8表示其過程。再來兩張frame #120-121，所以直接以少於六個運動向量之平均
向量，將frame#120中收斂好之snake contour平移至frame #121中線性擴大後當下
一張畫面作CTASM之初始snake contour，作較多移動Snaxels次數CTASM之 
evolution，完成frame #121中轉身後熱帶魚之輪廓segmentation，以圖9-9到圖9-12
表示其過程。 
 
 
 
圖 9-1:起始輪廓(Frame 119) 圖 9-2: SNAKE 收斂結果(Frame 119) 
 
圖 9-3:六等分中找出六個 seeds(Frame 
119) 
圖 9-4: ME 移動追蹤(Frame 120) 
 
 
 
 
 14
圖9-11: 外擴後成此Frame之起始輪廓
(Frame 121) 
圖 9-12:SNAKE 收斂結果(Frame 121) 
 
 
 16
Hence, the BBS method is firstly to rapidly estimate some positions emerging likely 
boundary gradient magnitudes on selective scanning lines, by definition, then sets the 
initial Snaxels to their proximities. Its implementation comes from some concise 
postulates: For a line scanning through the object, the variation of average gradient 
magnitude across the object border (a boundary between two heterogeneous regions. 
e.g., target object and background) shall be relatively distinguishable than that across 
the inner of same region. And, the gradient magnitude of object border pixel is larger 
relative to that of its neighboring pixels or the pixel of similar property observed. The 
BBS process is stated as the following two parts. The first part is to find the reference 
(or anchor) of initial Snaxel position.  
Step 1: Equalize the initial user-defined rectangular into four quadrants. 
Step 2: Individually scan each quadrant with horizontal and vertical scan lines of even 
distance gaps. The edges of grids generated by those mutually orthogonal lines on a 
scanning line are defined as the units of this scanning line.  
Step 3: On each scan-line unit, find a unit-representative pixel with the maximal 
gradient magnitude (MGM) and compute the subtraction-value of this MGM minus 
the gradient-magnitude mean (GMM) in scan-line unit. 
Step 4: Among the unit-representative pixels of one scanning line, look for a 
line-representative pixel having the largest gradient magnitude and its “backup”, 
which possesses the second largest gradient magnitude. Again, search another 
line-representative pixel having the largest gradient-magnitude subtraction-value and 
its “backup” having the second largest subtraction-value. 
Step 5: From the at most four line-representative pixels on every scanning line, select 
the pixel of maximum absolute x (or y) coordinate value for the horizontal (or vertical) 
scan line as the first-priority line-representative pixel. Then, set its backup (the 
second-priority line-representative pixel) as one of the remained line-representative 
pixels, which has the largest combination-value of gradient magnitude plus 
gradient-magnitude subtraction-value. 
Step 6: For one scanning line, examine if the first-priority line-representative pixel is 
located “exactly” or not on an edge, not a line or a gray-level peak. If it does, it is 
treated as an anchor node of initial Snaxel position. Or else, the same test is operated 
on its backup as well. When the test is passed, the backup will substitute as the anchor 
node of initial Snaxel position. Otherwise, the scanning line is considered not able to 
offer any information about the initial snake-contour position. 
3 實驗結果 
 For a manually-drawn object with a large concavity and artifact line noises, as 
Fig3.1 shown, we can see better concavity fitness resulted from FIA evolution-snake 
 18
 
Fig.3.3 Converged snake contours obtained by (a) the traditional active contour 
model (b) FIA-snake in medical image with edged background. 
 
 
Fig.3.4 Converged snake contours obtained by (a) the traditional active contour model 
(b) FIA-snake in medical image in medical image with edged background. 
Table 1 Comparison of contour BMAD values 
Traditional active contour model 
shown in Figure 3.2(b) 
FIA-snake shown in Figure 
3.2(c)  Test object  
3.336  1.247 
Table 1 Comparison of contour BMAD values 
Traditional active contour 
model shown in Figure 3.3(a) 
FIA-snake in Figure 3.3(b) 
3.583  1.247  
Traditional active contour 
model shown in Figure 3.4(a) 
FIA-snake in Figure 3.4(b) 
Medical image with 
artificial regular 
texture  
3.508  1.074  
 
 20
Table2 
 True 
edges
Total 
edges
accuracy
Execution 
time (sec.) 
Stage 1 of our 
method 
34 40 0.85 0.313 
Yuen’s method 23 32 0.71 0.367 
Stage 2 of our 
method 
310 320 0.96 0.653 
With snake 220 550 0.4 0.849 
 
  
(a) (b) 
  
(c) (d) 
Fig. 3-7: (a) Initialization of the proposed method of Step 1 (b) Initialization of Yuen’s 
method. (c) Result of the proposed method after applying stage 2 of edge-linking, and 
(d) Result of Yuen’s method with snake 
 22
     
Fig. 3-9: Polygonal shape approximation by performing BBS in nature images for 
semantic objects with heavy non-regular texture background 
4.結論 
In this study, FIA-snake is addressed to resolve the substantial problems in the 
classification snake model by three stages: effective snake initialization, FIA 
evolution, and converged contour refinement. All the three stages of FIA-snake 
depend on the processed image characteristics that the core of FIA-snake, i.e., FIA 
evolution, can on-time locally learn the current geometrical characteristic encountered 
by Snaxels and then adapt its own property (model coefficients).. With the integrity of 
coordinating these three stages, FIA-snake can achieve complete-profile object 
segmentations in the noisy image without too noticeable noises. Hence, it can also be 
applied to the unsupervised semantic object extractions rather than limited to 
domain-specified image segmentations requiring priori a knowledge. Observing the 
experimental results, FIA-snake can achieve the better fitness to the object profile 
over GVF approach in segmenting the noisy images.
 24
 26
 28
 30
 32
 34
 36
 38
 40
3. A Robust Object Contour Extraction Using Polygon Approximation and 
Localized Edge Linking 
 42
 44
 46
 48
(三) 參考文獻 
[1] M. Kass, A. Witkin and D. Terzopoulos, “Snakes: Active Contour Models,” 
International Journal of Computer Vision, VOL. 1, pp. 321-331, 1987. 
[2] H. Gao, W. C. Siu and C. H. Hou, “Improved Techniques for Automatic Image 
Segmentation,” IEEE Transactions on Circuits and Systems for Video Technology, 
VOL. 11, NO. 12, pp. 1273-1280, DECEMBER 2001. 
[3] J. Liu, Y. H. Yang, “Multiresolution Color Image Segmentation,” IEEE 
Transactions on Pattern Analysis Machine Intelligence, VOL. 16, NO. 7, pp. 
689-700, JULY 1994. 
[4] T. Uchiyama, M. A. Arbib, “Color Image Segmentation Using Competitive 
Learning,” IEEE Transactions on Pattern Analysis Machine Intelligence, VOL. 16, 
NO. 12, pp. 1197-1206, DECEMBER 1994. 
[5] R. H. Davies, C. J. Twining, T. F. Cootes, J. C. Waterton and C. J. Taylor, “A 
Minimum Description Length Approach to Statistical Shape Modeling,” IEEE 
Transactions on Medical Imaging, VOL. 21, NO. 5, pp. 525-537, MAY 2002. 
[6] A. Neumann, “Graphical Gaussian Shape Models and Their Application to Image 
Segmentation,” IEEE Transactions on Pattern Analysis Machine Intelligence, 
VOL. 25, NO. 3, pp. 316-329, MARCH 2003. 
[7] D. Murray, A. Basu, “Motion Tracking with an Active Camera,” IEEE 
Transactions on Pattern Analysis Machine Intelligence, VOL. 16, NO. 5, pp. 
449-459, MAY 1994. 
[8] J. B. Xu, L. M. Po and C. K. Cheung, “Adaptive Motion Tracking Block Matching 
Algorithm for Video Coding,” IEEE Transactions on Circuits and Systems for 
Video Technology, VOL. 9, NO. 7, pp. 1025-1029, OCTOBER 1999. 
[9] S. Y. Chien, Y. W. Huang, B. Y. Hsieh, S. Y. Ma and L. G. Chen, “Fast Video 
Segmentation Algorithm With Shadow Cancellation, Global Motion 
Compensation, and Adaptive Threshold Techniques,” IEEE Transactions on 
Multimedia, VOL. 6, NO. 5, pp. 732-748, OCTOBER 2004. 
[10] P. L. Correia, F. Pereira, “Objective Evaluation of Video Segmentation Quality,” 
IEEE Transactions on Image Processing, VOL. 12, NO. 2, pp. 186-200, 
FEBRUARY 2003. 
[11] L. D. Cohen, “On Active Contour Models and Balloons,” In CVGIP: Image 
 50
(四) 計畫成果自評 
執行完本計畫研究成果，為一碩士論文，一篇 SCI(此 PR Letters 期刊為計畫
前期作業就已送審通過，為發表論文成果之 2)，兩篇會議論文；及後續合作國科
會一件計畫通過為共同主持人。因為敝人為電機系籌備、與創立主任，兩年多來
由籌備、規劃、建立、開創、由無到有各種資源爭取，完成本校電機系所有主要
事務、絕大多部份皆獨力進行；電機系現已進入第二年，兩年多來相當耗時勞神，
敝人為求研究時效及後續衍生效益，將此計畫後續研究與系上徐超明副教授繼續
執行通過國科會一件計畫，亦已執行結束，並已撰寫新 SCI 論文，剛 Submit 至
SCI 期刊送審中，總之，計畫主持人執行本計畫已努力地善盡完成計畫之責任、
來盡力達一定成果。 
