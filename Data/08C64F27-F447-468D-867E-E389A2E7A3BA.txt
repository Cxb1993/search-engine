目錄 
計畫精簡報告內容 .................................................................................................................... 附錄 1 
已發表於下列期刊及會議論文 
1. K. C. Liu, "Color image compression with image dependent quantization," Journal of Information 
and Computational Science, vol. 8, no. 2, pp.223-229, Feb. 2011. (EI) 
2. K. C. Liu, "Prediction Error Preprocessing for Color Image Compression," in Proc. European Sig-
nal Processing Conference, 2011, pp. 579-583. 
 
計畫自評 .................................................................................................................................... 附錄 2 
 
where dO,D(, , i, j) is the luminance-adapted base detection 
threshold and aO(, , i, j) is the visual masking adjustment.  
Luminance-adapted Base Detection Threshold, dO,D(, , 
i, j): The threshold is measured for signals presented against 
a specified uniform luminance background.  The intensity-
based contrast sensitivity model proposed in [1], [3] is adopt-
ed here.  The mathematical model used to measure the base 
detection threshold for each subband (,  ) in O color com-
ponent can be found in [2].  The contrast sensitivity is meas-
ured while a however uniform background intensity level is 
fixed.  The base detection threshold for each subband of four-
level 9/7 DWT can be found.  It is easily found that the base 
sensitivity threshold is lowest for the lowest frequency band 
while higher frequency bands have higher thresholds.  In fact, 
the detection threshold actually varies with the background 
intensity.  This is so-called luminance adaptation.  It denotes 
the variations in the sensitivity depend on the local mean of 
luminance component in color images.  That is, the variations 
in local mean luminance within the color image will result in 
substantial variations in wavelet thresholds.  In this paper, the 
luminance adaptation factor is given by the power function 
proposed in [13]. 
Visual Masking Adjustment, aO (, , i, j): This adjust-
ment is a measure used to increase the detection threshold 
while taking visual masking effects into account.  For lumi-
nance component, the contrast masking effect means that the 
visual sensitivity of stimuli is reduced by the increasing spa-
tial non-uniformity of the background luminance.  For chro-
minance components, the masking also affects the sensitivity 
to the chrominance components of a target color pixel.  We 
apply the idea proposed in [2] to chrominance components of 
color images to simplify the estimation of the chromatic JND 
that is related to the complex features of the HVS.  In this 
paper, the visual masking adjustments proposed in [14] are 
adopted.  The adjustments that have been successfully ap-
plied to the watermarking scheme are adopted.  The visual 
masking adjustment for chrominance components is there-
fore defined by computing a measure of variance within the 
local region of a target coefficient that is scaled by the visi-
bility of the coefficient. 
3. PERCEPTUAL COLOR IMAGE 
COMPRESSION SCHEME 
The functional block diagram of the proposed perceptual 
compression scheme for color images in the wavelet domain 
is given in Fig. 1, where zO(, , i, j), ),,,(~ jizO  , eO(, , 
i, j), ),,,(~ jieO  , and dO(, , i, j), respectively, denote the 
original current wavelet coefficient, the predicted coefficient, 
the prediction error before the preprocessing, the prediction 
error after the preprocessing, and the JND value for the coef-
ficient located at (i, j) of the (, ) subband in the O color 
component of the color image.  The subband JND profiles of 
the input color image obtained by using the JND estimator 
presented in Section II are incorporated into the proposed 
prediction error preprocessor to shape the prediction error 
and decide the reconstruction level for achieving the in-
creased performance in terms of bit rate at a specified visual 
quality. 
As shown in Fig. 1, the prediction error is obtained by 
the difference between the current signal and its predicted 
signal and is given as 
 eO(, , i, j)= zO(, , i, j)- ),,,(~ jizO   
 for O = Y, Cb, Cr (2) 
 reconstructed 
 signal 
Wavelet 
transform quantizer 
Inverse 
quantizer 
Entropy 
coding 
Predictors 
Compressed 
subband image 
+ 
- 
+ 
+ 
predicted 
signal 
Color components 
of the input image 
Y Cb Cr 
JND 
estimator 
),,,( jidO 
),,,(~ jieO ),,,( jieO 
),,,(~ jizO 
),,,( jizO 
Prediction error 
preprocesssor 
Modified JND 
estimator 
),,,(
~
jid O 
 
Fig. 1 Block diagram of the proposed perceptual compression scheme. 
 








otherwise),,,,(
),,,(),,,(  if else),,,,(),,,(
),,,(),,,(  if),,,,(),,,(
),,,(~
jie
jidjiejidjie
jidjiejidjie
jie
O
OOOOOO
OOOOOO
O



  (3) 
threshold for each subband (,  ) in O color component and 
is utilized to design a simple perceptually lossless quantiza-
tion matrix for compressing color images .  Table I lists the 
overall entropy comparison of the color images under test, 
between the Watson’s method and the proposed compression 
scheme.  It can be seen that entropies are improved with the 
proposed scheme.    
5. CONCLUSIONS 
A prediction error preprocessor is presented with the goal to 
reduce the dynamic range of the prediction error signals of 
the color image to be compressed.  The lower bit rate of the 
reconstructed image can be obtained by using the preproces-
sor while reaching high visual quality.  For this purpose, a 
color JND estimator that takes into account various masking 
effects of human visual perception is proposed and incorpo-
rated into the preprocessor for the design of the perceptual 
color image compression scheme using the DPCM technique.  
The proposed compression scheme with the preprocessor 
generates consistent quality images at a lower entropy when 
comparing with that without prediction error preprocessor 
and the existing compression method.  In the future work, the 
preprocessor will be compliantly applied to the JPEG and 
JPEG2000 coders in order to achieve higher performance in 
terms of bit rate at the same visual quality. 
ACKNOWLEDGEMENT 
The work was supported by the National Science Council, 
R.O.C., under contract NSC99-2221-E-278-001.  
REFERENCES 
[1] R. J. Safranek and J. D. Johnston, “A perceptually 
tuned subband image coder with image dependent 
quantization and post-quantization data compression,” 
in Proc. IEEE Int. Conf. Acoust., Speech, Signal Pro-
cessing, vol. 3, May 1989, pp. 1945-1948. 
[2] A. B. Watson, G. Yang, J. A. Solomon, and J. Vil-
lasenor, “Visibility of wavelet quantization noise,” 
IEEE Trans. Image Processing, vol. 6, no. 8, pp. 1164-
1175, Aug. 1997. 
[3] I. Höntsch and L. J. Karam, “Locally adaptive percep-
tual image coding,” IEEE Trans. Image Processing, vol. 
9, no. 9, pp. 1472-1483, Sep. 2000. 
[4] X. K. Yang, W. S. Lin, Z. Lu, E. P. Ong, and S. Yao, 
“Motion-compensated residue preprocessing in video 
coding based on just-noticeable-distortion profile,” 
IEEE Trans Circuits and Systems for Video Tech. vol. 
15, no. 6, pp. 742-752, June 2005 
[5] C. W. Tang, “Spatiotemporal visual considerations for 
video coding,” IEEE Trans. Multimedia, vol. 9, no. 2, 
pp. 231-238, Feb. 2007. 
[6] A. Al-Fayadh, A. J. Hussain, P. Lisboa, and D. Al-
Jumeily, “An adaptive hybrid classified vector quanti-
sation and its application to image compression,” in 
Proc. European Symp. Computer Modeling and Simu-
lation, Sep. 2008, pp. 253-256. 
[7] M. J. Nadenau, J. Reichel, and M. Kunt, “Wavelet-
based color image compression: exploiting the contrast 
sensitivity function,” IEEE Trans. Image Processing, 
vol. 12, no. 1, pp. 58-70, Jan. 2003. 
[8] C. H. Chou and K. C. Liu, “Colour image compression 
based on the measure of just noticeable colour differ-
ence,” IET Image Processing, vol. 2, no. 6, pp.304-322, 
Dec. 2008. 
[9] A.B. Watson, "Perceptual optimization of DCT color 
quantization matrices," in Proc. IEEE Int. Conf. Image 
Processing, 1994, pp. 100-1044. 
[10] P. Le Callet, A. Saadane, and D. Barba, “Interactions of 
chromatic components on the perceptual quantization 
of the achromatic component,” in Proc. SPIE Human 
Vision and Electronic Imaging, vol. 3644, 1999, pp. 
121–128. 
[11] Y. Meng and L. Guo, "Color image coding by utilizing 
the crossed masking," in Proc. IEEE Int. Conf. Acoust., 
Speech, Signal Processing, 2005, pp. 389-392. 
[12] F. H. Imai, N. Tsumura, and Y. Miyake, “Perceptual 
color difference metric for complex images based on 
Mahalanobis distance,” J. Electron. Imaging, vol. 10, 
no. 2, pp. 385-393, April 2001. 
[13] A. B. Watson, “DCT quantization matrices visually 
optimized for individual images,” in Proc. SPIE Int. 
Table I Entropies of the proposed compression scheme with preprocessor, without preprocessor and the Watson’s 
compression method at nearly a perceptually lossless quality of the reconstructed color images. (G1: gain of the pro-
posed scheme with O=0, O=1.0; G2: gain of the proposed scheme with O=0.4, O=0.5) 
 Entropy Gain 
Image Watson’s 
method 
Proposed scheme 
(O=0, O=1.0) 
Proposed scheme 
(O=0.4, O=0.5) 
G1 G2 
Baboon 1.296 1.089 1.035 15.98% 20.09% 
Barbara 0.697 0.637 0.621 8.65% 10.99% 
Goldhill 0.775 0.752 0.738 3.05% 4.77% 
Leaf 0.575 0.491 0.465 14.55% 19.13% 
Lena 0.542 0.510 0.495 5.90% 8.79% 
Monarch 0.565 0.512 0.489 9.49% 13.44% 
Sail 0.863 0.739 0.717 14.36% 16.91% 
 
 
計畫自評 
在本計畫中，我們在彩色影像壓縮中提出一個以臨界可視失真(just noticeable distortion; JND)
為基礎的彩色影像前置處理器，以便獲得更好的編碼效益。因為人類視覺對彩色訊號的敏感度
有限，任何訊號上的改變，只要低於臨界可視失真門檻值，都無法被眼睛察覺。同時，在影像
編碼中，影像訊號的變異量(variance)愈小，重建訊號的主觀失真量在特定位元率條件下也會愈
小;重建訊號的位元率在相同視覺品質條件下也會愈小。因此，適當地使用彩色影像的臨界可視
失真面將有助於增加彩色影像編碼的效能。在本計畫中，我們提出兩種可應用於彩色影像編碼
上的彩色臨界可視失真估測器，一種用於小波領域及一種用於 DCT 領域。這個彩色臨界可視失
真估測器利用視覺遮罩(visual masking)及亮度(luminance)及彩度(chrominance)間的交互作用，並
且直接實現於上述兩個頻率領域。然後整合運用於彩色影像每一色頻的訊號前置處理器，彩色
影像每一色頻上的頻帶係數的變異量將被降低，進而提升編碼效能。在給定位元率的條件下，
我們提出的編碼器將獲得更高的視覺品質。在此計畫中， 我們還提出一個方法可以動態調整彩
色影像前置處理器的參數，使得前置處理器能在壓縮不同種類彩色影像時，能得到最好的視覺
品質。對於目前的彩色影像編碼標準 JPEG2000，我們所提出的技術將用在輸入影像訊號的前置
處理的測試上，使得處理後的訊號有較小的變異量，有助於重建影像視覺上失真的降低。實驗
結果顯示，視覺實驗測試確認我們所提出的方式在視覺品質的確獲得改善。同時，在相同的視
覺品質的條件下，整合前置處理器的彩色影像編碼器所需的位元率低於無前置處理器的彩色影
像編碼器所需的位元率。而計畫的執行已有論文發表於 EUROPEAN ASSOCIATION FOR 
SIGNAL PROCESSING (EURASIP)所主辦的 2011 年第 19屆歐洲訊號處理研討會(2011 19th Euro-
pean Signal Processing Conference; EUSIPCO-2011) 。未來的計畫，我們將考慮視訊之時域遮罩
(temporal masking) ，以延伸領域的彩色臨界可視失真估測器，評估視訊前置處理器應用在 H.264
視訊壓縮標準上的可行性。 
申請人於觀光背景為主的學校任教資訊相關課程，影像處理之軟硬體資源較不充裕及碩士班
研究助理難覓為遭遇之主要問題，由於國科會計畫上的經費補助，使可能遭遇之困難及重要儀
器配合使用的問題獲得解決。透過本計畫邀請的共同主持人國立東華大學資工所林信鋒教授，
計畫內設計之進階實驗於林信鋒教授所主持之影像與視訊處理實驗室進行，同時將聘任該實驗
室部分研究生及學士班大四生為兼任研究助理，定期交流與討論，在有效的學術合作模式下，
使補助的經費發揮最大的效益，同時讓學生有機會接觸彩色影像處理及人類視覺兩個有趣領
域；其它初階實驗及視覺測試作業，透過本計畫編列經費，採購較高解析度液晶顯示器，同時
購置可攜帶作業系統、高容量隨身硬碟及雷射印表機，方便進行簡報、實驗影像比對及程式報
告撰寫等工作。不論是計畫的執行、軟硬體的配合及人力的控管，自評本計畫的執行皆已達預
期成效。 
附錄 2 
 2
8/30 
IVP-L1: Image and video coding 
IVP-P1: Image segmentation  
IVP-L2: Stereoscopic and 3D processing 
8/31 
IVP-L3: Object detection 
IVP-P4: Pattern recognition in images and videos 
IVP-L4: Biomedical image processing 
9/1 
IVP-L5: Image and video coding II 
SS-09: Special Session on "2D and 3D image analysis of paintings" 
SPA-P2: Biomedical signal processing II 
SS-12: Special Session on "Processing and recovery using analysis and synthesis sparse mod-
els" 
9/2 
SS-14: Special Session on "Image and signal processing for 3DTV" 
IVP-L7: Human face analysis 
IVP-P7: Video coding 
SPT-L4: Signal and system modeling and representation 
 
本次會議筆者所發表之論文題目為「Prediction Error Preprocessing for Color Image Com-
pression」，重點在探討彩色影像壓縮時誤差訊號的前置處理方式，此方式是以人類視覺可是
失真為基礎發展建置，透過我們所提出誤差訊號的前置處理方式，重建彩色影像在相同視覺
品質下，可以得到較好的壓縮率。實驗同時與學者Watson發展出的視覺模型相比較，結果顯
示我們的所提出的方式有較好的表現。 
 
六、加泰隆尼亞理工大學及加泰隆尼亞電信技術中心參訪 
在本次會議結束後，安排幾天行程參訪此次會議主辦的單位Centre Tecnològic de Tele-
comunicacions de Catalunya (CTTC) and the Universitat Politècnica de Catalunya (UPC)。其中，加
泰隆尼亞理工大學（UPC）是西班牙一所著名的公立高等學府，建築和理工科等多個專業更
處于世界頂尖水準。該校集教學與科研為一體，人才的培養和科技的普及和推展是其辦學的
宗旨。UPC堅持用長遠的眼光為學生們提供最優秀、最全面的教育和培養訓練。依據 “歐洲
高等教育區”（European Highter Education Area）的標準，該校不斷提升教學水準、提升教育
質量。緊跟時代的脈搏，在培養道統型人才的同時，更為新興行業輸送具有最新理念和知識
的精英人才，比如太空飛行航空學、光子學、超級計算機學、生物工程學、水學、能源學等
等。 
作為西班牙科技發展的重要智庫，該校高尖端科技的研發工作始終處于世界科研的最前
沿。此外，他們也致力于在加泰羅尼亞地區、西班牙、乃至整個歐洲地區傳播普及我們的知
識和科研成果。UPC是一所自治大學，自行管理，按自身的要求決定學校的教學內容和模式，
同時擁有對科研教學管理的自主決定權。此外，UPC還負責管理運作起下屬中心以及服務機
 4
 
七、研討會照片： 
 
會議地點 Palau de Congressos de Catalunya EUSIPCO-2010 Aalborg 報到 
報到會場 
 
茶敘時間 
口頭論文發表 
 
海報論文發表 
 
海報論文發表  
 
 
 6
We are looking forward to seeing you in Barcelona in August. 
 
Best regards, 
Xavier Mestre, Javier Hernando, and Montse Pardàs, Technical Chairs. 
 
where dO,D(, , i, j) is the luminance-adapted base detection 
threshold and aO(, , i, j) is the visual masking adjustment.  
Luminance-adapted Base Detection Threshold, dO,D(, , 
i, j): The threshold is measured for signals presented against 
a specified uniform luminance background.  The intensity-
based contrast sensitivity model proposed in [1], [3] is adopt-
ed here.  The mathematical model used to measure the base 
detection threshold for each subband (,  ) in O color com-
ponent can be found in [2].  The contrast sensitivity is meas-
ured while a however uniform background intensity level is 
fixed.  The base detection threshold for each subband of four-
level 9/7 DWT can be found.  It is easily found that the base 
sensitivity threshold is lowest for the lowest frequency band 
while higher frequency bands have higher thresholds.  In fact, 
the detection threshold actually varies with the background 
intensity.  This is so-called luminance adaptation.  It denotes 
the variations in the sensitivity depend on the local mean of 
luminance component in color images.  That is, the variations 
in local mean luminance within the color image will result in 
substantial variations in wavelet thresholds.  In this paper, the 
luminance adaptation factor is given by the power function 
proposed in [13]. 
Visual Masking Adjustment, aO (, , i, j): This adjust-
ment is a measure used to increase the detection threshold 
while taking visual masking effects into account.  For lumi-
nance component, the contrast masking effect means that the 
visual sensitivity of stimuli is reduced by the increasing spa-
tial non-uniformity of the background luminance.  For chro-
minance components, the masking also affects the sensitivity 
to the chrominance components of a target color pixel.  We 
apply the idea proposed in [2] to chrominance components of 
color images to simplify the estimation of the chromatic JND 
that is related to the complex features of the HVS.  In this 
paper, the visual masking adjustments proposed in [14] are 
adopted.  The adjustments that have been successfully ap-
plied to the watermarking scheme are adopted.  The visual 
masking adjustment for chrominance components is there-
fore defined by computing a measure of variance within the 
local region of a target coefficient that is scaled by the visi-
bility of the coefficient. 
3. PERCEPTUAL COLOR IMAGE 
COMPRESSION SCHEME 
The functional block diagram of the proposed perceptual 
compression scheme for color images in the wavelet domain 
is given in Fig. 1, where zO(, , i, j), ),,,(~ jizO  , eO(, , 
i, j), ),,,(~ jieO  , and dO(, , i, j), respectively, denote the 
original current wavelet coefficient, the predicted coefficient, 
the prediction error before the preprocessing, the prediction 
error after the preprocessing, and the JND value for the coef-
ficient located at (i, j) of the (, ) subband in the O color 
component of the color image.  The subband JND profiles of 
the input color image obtained by using the JND estimator 
presented in Section II are incorporated into the proposed 
prediction error preprocessor to shape the prediction error 
and decide the reconstruction level for achieving the in-
creased performance in terms of bit rate at a specified visual 
quality. 
As shown in Fig. 1, the prediction error is obtained by 
the difference between the current signal and its predicted 
signal and is given as 
 eO(, , i, j)= zO(, , i, j)- ),,,(~ jizO   
 for O = Y, Cb, Cr (2) 
 reconstructed 
 signal 
Wavelet 
transform quantizer 
Inverse 
quantizer 
Entropy 
coding 
Predictors 
Compressed 
subband image 
+ 
- 
+ 
+ 
predicted 
signal 
Color components 
of the input image 
Y Cb Cr 
JND 
estimator 
),,,( jidO 
),,,(~ jieO ),,,( jieO 
),,,(~ jizO 
),,,( jizO 
Prediction error 
preprocesssor 
Modified JND 
estimator 
),,,(
~
jid O 
 
Fig. 1 Block diagram of the proposed perceptual compression scheme. 
 








otherwise),,,,(
),,,(),,,(  if else),,,,(),,,(
),,,(),,,(  if),,,,(),,,(
),,,(~
jie
jidjiejidjie
jidjiejidjie
jie
O
OOOOOO
OOOOOO
O



  (3) 580
threshold for each subband (,  ) in O color component and 
is utilized to design a simple perceptually lossless quantiza-
tion matrix for compressing color images .  Table I lists the 
overall entropy comparison of the color images under test, 
between the Watson’s method and the proposed compression 
scheme.  It can be seen that entropies are improved with the 
proposed scheme.    
5. CONCLUSIONS 
A prediction error preprocessor is presented with the goal to 
reduce the dynamic range of the prediction error signals of 
the color image to be compressed.  The lower bit rate of the 
reconstructed image can be obtained by using the preproces-
sor while reaching high visual quality.  For this purpose, a 
color JND estimator that takes into account various masking 
effects of human visual perception is proposed and incorpo-
rated into the preprocessor for the design of the perceptual 
color image compression scheme using the DPCM technique.  
The proposed compression scheme with the preprocessor 
generates consistent quality images at a lower entropy when 
comparing with that without prediction error preprocessor 
and the existing compression method.  In the future work, the 
preprocessor will be compliantly applied to the JPEG and 
JPEG2000 coders in order to achieve higher performance in 
terms of bit rate at the same visual quality. 
ACKNOWLEDGEMENT 
The work was supported by the National Science Council, 
R.O.C., under contract NSC99-2221-E-278-001.  
REFERENCES 
[1] R. J. Safranek and J. D. Johnston, “A perceptually 
tuned subband image coder with image dependent 
quantization and post-quantization data compression,” 
in Proc. IEEE Int. Conf. Acoust., Speech, Signal Pro-
cessing, vol. 3, May 1989, pp. 1945-1948. 
[2] A. B. Watson, G. Yang, J. A. Solomon, and J. Vil-
lasenor, “Visibility of wavelet quantization noise,” 
IEEE Trans. Image Processing, vol. 6, no. 8, pp. 1164-
1175, Aug. 1997. 
[3] I. Höntsch and L. J. Karam, “Locally adaptive percep-
tual image coding,” IEEE Trans. Image Processing, vol. 
9, no. 9, pp. 1472-1483, Sep. 2000. 
[4] X. K. Yang, W. S. Lin, Z. Lu, E. P. Ong, and S. Yao, 
“Motion-compensated residue preprocessing in video 
coding based on just-noticeable-distortion profile,” 
IEEE Trans Circuits and Systems for Video Tech. vol. 
15, no. 6, pp. 742-752, June 2005 
[5] C. W. Tang, “Spatiotemporal visual considerations for 
video coding,” IEEE Trans. Multimedia, vol. 9, no. 2, 
pp. 231-238, Feb. 2007. 
[6] A. Al-Fayadh, A. J. Hussain, P. Lisboa, and D. Al-
Jumeily, “An adaptive hybrid classified vector quanti-
sation and its application to image compression,” in 
Proc. European Symp. Computer Modeling and Simu-
lation, Sep. 2008, pp. 253-256. 
[7] M. J. Nadenau, J. Reichel, and M. Kunt, “Wavelet-
based color image compression: exploiting the contrast 
sensitivity function,” IEEE Trans. Image Processing, 
vol. 12, no. 1, pp. 58-70, Jan. 2003. 
[8] C. H. Chou and K. C. Liu, “Colour image compression 
based on the measure of just noticeable colour differ-
ence,” IET Image Processing, vol. 2, no. 6, pp.304-322, 
Dec. 2008. 
[9] A.B. Watson, "Perceptual optimization of DCT color 
quantization matrices," in Proc. IEEE Int. Conf. Image 
Processing, 1994, pp. 100-1044. 
[10] P. Le Callet, A. Saadane, and D. Barba, “Interactions of 
chromatic components on the perceptual quantization 
of the achromatic component,” in Proc. SPIE Human 
Vision and Electronic Imaging, vol. 3644, 1999, pp. 
121–128. 
[11] Y. Meng and L. Guo, "Color image coding by utilizing 
the crossed masking," in Proc. IEEE Int. Conf. Acoust., 
Speech, Signal Processing, 2005, pp. 389-392. 
[12] F. H. Imai, N. Tsumura, and Y. Miyake, “Perceptual 
color difference metric for complex images based on 
Mahalanobis distance,” J. Electron. Imaging, vol. 10, 
no. 2, pp. 385-393, April 2001. 
[13] A. B. Watson, “DCT quantization matrices visually 
optimized for individual images,” in Proc. SPIE Int. 
Table I Entropies of the proposed compression scheme with preprocessor, without preprocessor and the Watson’s 
compression method at nearly a perceptually lossless quality of the reconstructed color images. (G1: gain of the pro-
posed scheme with O=0, O=1.0; G2: gain of the proposed scheme with O=0.4, O=0.5) 
 Entropy Gain 
Image Watson’s 
method 
Proposed scheme 
(O=0, O=1.0) 
Proposed scheme 
(O=0.4, O=0.5) 
G1 G2 
Baboon 1.296 1.089 1.035 15.98% 20.09% 
Barbara 0.697 0.637 0.621 8.65% 10.99% 
Goldhill 0.775 0.752 0.738 3.05% 4.77% 
Leaf 0.575 0.491 0.465 14.55% 19.13% 
Lena 0.542 0.510 0.495 5.90% 8.79% 
Monarch 0.565 0.512 0.489 9.49% 13.44% 
Sail 0.863 0.739 0.717 14.36% 16.91% 
 582
國科會補助計畫衍生研發成果推廣資料表
日期:2011/10/01
國科會補助計畫
計畫名稱: 彩色影像視覺前置處理器之研究與在JPEG及JPEG2000之應用
計畫主持人: 劉國成
計畫編號: 99-2221-E-278-001- 學門領域: 影像處理
無研發成果推廣資料
博士後研究員 0 0 100%  
專任助理 0 0 100%  
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
