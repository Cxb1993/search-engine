IEEE COMMUNICATIONS LETTERS, VOL. 12, NO. 12, DECEMBER 2008 883
Low-Complexity ML Decoding for Convolutional Tail-Biting Codes
Hung-Ta Pai, Member, IEEE, Yunghsiang S. Han, Senior Member, IEEE, Ting-Yi Wu,
Po-Ning Chen, Senior Member, IEEE, and Shin-Lin Shieh
Abstract—Recently, a maximum-likelihood (ML) decoding al-
gorithm with two phases has been proposed for convolutional tail-
biting codes [1]. The first phase applies the Viterbi algorithm to
obtain the trellis information, and then the second phase employs
the algorithm A* to find the ML solution. In this work, we
improve the complexity of the algorithm A* by using a new
evaluation function. Simulations showed that the improved A*
algorithm has over 5 times less average decoding complexity in
the second phase when Eb/N0≥ 4 dB.
Index Terms—Viterbi algorithm, maximum-likelihood, tail-
biting codes, algorithm A*.
I. INTRODUCTION
CONVOLUTIONAL Tail-Biting Codes (CTBC) can over-come the loss on the code rate, and induces less per-
formance degradation [2], [3]. In the trellis of CTBC, there
is a one-to-one correspondence between a codeword and a
path with the same initial and final state, which is called a
tail-biting path.1 If the number of initial states (equivalently,
final states) of the convolutional tail-biting code is Ns, the
trellis is composed of Ns subtrellises with the same initial and
final state. These subtrellises are called tail-biting subtrellises,
or simply subtrellises, and will be denoted by Ti for the ith
subtrellis.
Several suboptimal decoding algorithms for the CTBC
have been proposed [2], [4]. Among them, the wrap-around
Viterbi algorithm (WAVA) is the one with the least decoding
complexity [2].
A straightforward optimal decoding algorithm for the CTBC
codes is to perform the Viterbi algorithm on all of the tail-
biting subtrellises; however, such approach may be impractical
due to its high computational complexity. Recently, an ML
decoding algorithm of practical decoding complexity has been
proposed [1]. This scheme has two phases. In the first phase,
the Viterbi algorithm (VA) is applied to the trellis of the
convolutional tail-biting code to obtain the trellis information.
Based upon the trellis information, the algorithm A* is then
performed on all subtrellises in the second phase to yield the
Manuscript received December 27, 2007. The associate editor coordinating
the review of this letter and approving it for publication was R. Nabar. This
work was supported by the National Science Council, Taiwan, R.O.C., under
the project No. NSC 96-2628-E-305-001 and NSC 96-2221-E-305-003.
H.-T. Pai, Y. S. Han, and T.-Y. Wu are with the Graduate Institute
of Communication Engineering, National Taipei University (e-mail: {htpai,
yshan}@mail.tnpu.edu.tw, mavericktywu@gmail.com).
P.-N. Chen is with the Dept. of Communications Engineering, National
Chiao Tung University (e-mail: qponing@mail.nctu.edu.tw).
S.-L. Shieh is with Sunplus mMobile Inc., Hsinchu 300, Taiwan, R.O.C.,
and also the Dept. of Communications Engineering, National Chiao Tung
University (e-mail: shinlinshieh@yahoo.com.tw).
Digital Object Identifier 10.1109/LCOMM.2008.072181.
1Hence, “tail-biting paths” and “codewords” are interchangeably used in
this work.
ML decision. It has been shown that the decoding complexity
can be reduced from Ns VA trials to equivalently 1.3 VA trials
without sacrificing the optimality in performance.
In this work, an improved algorithm A* with a new
evaluation function is presented. Simulations showed that the
complexity in the second phase can be further reduced down
to 1/5 of the original scheme at medium-to-high signal to noise
ratio (SNR).
II. MAXIMUM-LIKELIHOOD DECODING OF THE CTBC
USING IMPROVED ALGORITHM A*
Let C∼ be an (n, 1,m) convolutional tail-biting code of L
information bits, where n is the number of output bits per
information bit, and m is the memory order. Hence, the trellis
of C∼ has Ns = 2m states at each level, and is of L + 1
levels. As aforementioned, the corresponding tail-biting paths
for codewords of C∼ should constrain on the same initial and
final state. By relaxing such constraint, we denote the super
code of C∼, which consists of all paths that may end at a final
state different from the initial state, by C∼s.
Denote by v  (v0, v1, . . . , vN−1) ∈ {0, 1}N the binary
codeword of C∼, where N = nL. Define the hard-decision
sequence y = (y0, y1, . . ., yN−1) corresponding to the received
vector r = (r0, r1, . . ., rN−1) as
yj 
{
1, if φj < 0;
0, otherwise,
where φj  ln[Pr(rj |0)/Pr(rj |1)]. Then, it can be derived by
the Wagner rule that the ML decoding output v∗ for received
vector r satisfies
N−1∑
j=0
(v∗j ⊕ yj)|φj | ≤
N−1∑
j=0
(vj ⊕ yj)|φj | for all v ∈ C∼,
where “⊕” is the exclusive-or operation. We thereby define a
new metric for the path in a subtrellis as follows.
Definition 1: For a path with zero-one labels x(i)(n−1) =
(x(i)0 , x
(i)
1 , . . . , x
(i)
n−1), which ends at level  in subtrellis Ti,
define the metric associated with it as
M
(
x
(i)
(n−1)
)

n−1∑
j=0
M(x(i)j ),
where M(x(i)j )  (yj ⊕ x(i)j )|φj | is the bit metric.
The metrics for those paths not belonging to any subtrellis
Ti, where 1 ≤ i ≤ Ns, can be similarly defined.
In the first phase, the VA is applied using the metric just
defined. Then, we will have a set of Ns survivors ending at
the final states after phase one. Notably, these survivor paths
correspond to codewords in C∼s, but not necessarily codewords
1089-7798/08$25.00 c© 2008 IEEE
Authorized licensed use limited to: National Taipei University. Downloaded on December 25, 2008 at 22:56 from IEEE Xplore.  Restrictions apply.
PAI et al.: LOW-COMPLEXITY ML DECODING FOR CONVOLUTIONAL TAIL-BITING CODES 885
1 1.5 2 2.5 3 3.5 4 4.5 5
10
−5
10
−4
10
−3
10
−2
10
−1
10
0
E
b
/N
0
 (dB)
W
or
d 
E
rr
or
 R
at
e 
(W
E
R
)
 
 
WAVA
IA*(A*)
Fig. 1. The word error rates (WERs) of IA*, A*, and WAVA.
TABLE I
COMPARISON OF AVERAGE (AVE) AND MAXIMUM (MAX) NUMBERS OF
BRANCH METRIC COMPUTATIONS IN PHASE TWO
Eb/N0 3 dB 4 dB 5 dB
algorithm ave max ave max ave max
WAVA 3072 3072 3072 3072 3072 3072
A* 335 29313 221 11930 165 11010
IA* 94 11045 42 3427 27 780
decoders, it is reasonable that they yield the same WER. Also
noted from Figure 1 is that the WAVA provides near-optimal
WER performance, and is only slightly inferior to the optimal
performance when Eb/N0 is between 1 dB and 4.5 dB.2
2Eb/N0 denotes the signal-to-noise ratio per information bit.
In Table I, we compare the average and maximum compu-
tational efforts of the IA* with those of the A* and the WAVA
in phase two. For a fair comparison, only the computations of
branch metrics, i.e., the second term in (1), are considered.3
Since the WAVA searches the entire trellis in phase two, its
number of branch metrics computed is the same for all SNRs.
By the simulation results, the IA* has a much smaller average
and maximum computational complexity than the A* for all
SNRs. For example, the average computational effort of the
IA* is about 7 times and 70 times less than that of the A*
and the WAVA, respectively, when Eb/N0 ≥ 4 dB as shown
in Table I.
REFERENCES
[1] P. Shankar, P. N. A. Kumar, K. Sasidharan, B. S. Rajan, and A. S.
Madhu, “Efficient convergent maximum likelihood decoding on tail-
biting,” available at http://arxiv.org/abs/cs.IT/0601023.
[2] R. Y. Shao, S. Lin, and M. P. C. Fossorier, “Two decoding algorithm
for tailbiting codes,” IEEE Trans. Commun., vol. COM-51, no. 10, pp.
1658–1665, Oct. 2003.
[3] Q. Wang and V. K. Bhargava, “An efficient maximum likelihood decoding
algorithm for generalized tail biting,” IEEE Trans. Commun., vol. COM-
37, no. 8, pp. 875–879, 1989.
[4] R. V. Cox and C. E. W. Sundberg, “An efficient adaptive circular viterbi
algorithm for decoding generalized tailbiting convolutional codes,” IEEE
Trans. Veh. Technol., vol. 43, no. 11, pp. 57–68, Feb. 1994.
3The proposed recursive implementation of the Algorithm A* in [1] has
a merit that no branch metric computation is required when the successor
path has the same f -function value as its predecessor. By this reason, the
complexities of the IA* in Table I also excludes the computations of those
branch metrics that equate the f -function values of the successor and its
immediate predecessor.
Authorized licensed use limited to: National Taipei University. Downloaded on December 25, 2008 at 22:56 from IEEE Xplore.  Restrictions apply.
International Symposium on Information Theory and its Applications, ISITA2008
Auckland, New Zealand, 7-10, December, 2008
Priority-First Search Decoding for Convolutional Tail-biting Codes
Yunghsiang S. Han†, Ting-Yi Wu†, Hung-Ta Pai†, Po-Ning Chen‡, and Shin-Lin Shieh‡††
† Graduate Institute of
Communication Engineering
National Taipei University
Taipei, Taiwan, R.O.C.
E-mail: yshan@mail.ntpu.edu.tw
‡ Dept. of Communications Engineering
National Chiao-Tung University
Hsin Chu City, Taiwan 30056, R.O.C.
†† Sunplus mMobile Inc.
HsinChu Science Park
Taiwan 300, R.O.C.
Abstract
Due to rapid interest on the applications of convo-
lutional tail-biting to communication systems, several
suboptimal algorithms have been proposed to achieve
near-optimal Word error rate (WER) performances
with circular Viterbi decoding approach. Among them,
the wrap-around Viterbi algorithm (WAVA) proposed
in [1] is the one with least decoding complexity. Very
recently, a maximum likelihood (ML) decoding algo-
rithm has been proposed in [2]. The scheme has two
phases. The Viterbi algorithm is applied to the trellis
of the convolutional tail-biting code and the informa-
tion obtained in the first phase is used by algorithm
A*, which is performed to all subtrellises, in the sec-
ond phase. In this work, a new two-phase ML decod-
ing algorithm is proposed. From the simulation re-
sults for the (2, 1, 12) convolutional tail-biting code, the
proposed algorithm has 16 times less average decoding
complexity in the second phase when compared to the
one using algorithm A* and 15123 times less than that
of the WAVA, respectively, when SNRb = 4 dB.
1. Introduction
Convolutional codes have been widely used to pro-
vide effective error control capability in digital com-
munications. Usually, in a convolutional encoder, ze-
ros are appended to the sequence of information bits
to clear the contents of shift register. These extra zero
tail-bits can also enhance the error protection capabil-
ity of the codewords. For sufficiently long information
This work was supported by the National Science Council of
Taiwan, R.O.C., under the projects of NSC 96-2628-E-305-001
and Aiming for the Top University and Elite Research Center
Development Plan.
sequence, the loss in code rates due to these zero tail-
bits is negligible. However, when the information se-
quence is short, evident code rate loss may be induced
by adding these extra zero tail-bits.
Several methods have been proposed to resolve the
code rate lose of the aforementioned convolutional zero-
tail codes, such as Direct Truncation, Puncturing [3],
and Tail-biting [1, 4]. In particular, the convolutional
tail-biting codes can directly overcome the loss on the
code rate, and induce less performance degradation. In
comparison, the convolutional zero-tail encoder always
starts from and ends at the same all-zero state, while
the convolutional tail-biting one only ensures that the
initial state and the final state are the same but may
vary with the status of the input data. As a result that
all possible states can be the initial state for the con-
volutional tail-biting codes, the decoding complexity
drastically increases.
The decoding of a convolutional tail-biting code is
performed on its trellis, over which a path always ends
at the same state as the initial one, and is called a tail-
biting path. There is a one-to-one correspondence be-
tween a tail-biting path and a codeword. For this rea-
son, “tail-biting paths” and “codewords” will be used
interchangeably in this work.
If the number of initial states (equivalently, final
states) of the convolutional tail-biting code is Ns, the
trellis is composed of Ns subtrellises with the same ini-
tial and final state. By following similar naming con-
vention, these subtrellises are called the tail-biting sub-
trellises, or simply subtrellises, and will be denoted by
Ti for the ith subtrellis.
In literature, several suboptimal decoding algo-
rithms for the convolutional tail-biting codes have been
proposed [1, 4–6]. Among them, the wrap-around
adding the bit metrics of the branch1 enter-
ing that state to the metric of the connect-
ing survivor at level ℓ+ 1. For each state sℓ
at level ℓ, keep the entering path with the
least metric, and delete the remaining, and
let c(sℓ) equal the least metric.
Step 3. If ℓ = 0, the algorithm stops; otherwise, go
to Step 2.
In the second phase, instead of operating on the
entire trellis with respect to the super code C∼s, the
decoding of the priority-first search decoding only op-
erates on tail-biting subtrellises. Thus, the output of
the second phase will always be a codeword in C∼. In ad-
dition, the priority-first search is applied forwardly as
in [2].2 For each path with zero-one labels x
(i)
(ℓn−1) over
subtrellis Ti, a new evaluation function f is associated
with it as follows:
f(x
(i)
(ℓn−1)) = g(x
(i)
(ℓn−1)) + h(x
(i)
(ℓn−1)), (1)
where
g(x
(i)
(ℓn−1)) = g(x
(i)
((ℓ−1)n−1)) +
ℓn−1∑
j=(ℓ−1)n
M(x
(i)
j ) (2)
with initial value g(x
(i)
(−1)) = 0,
h(x
(i)
(ℓn−1)) = c(sℓ)
and sℓ is the state that path x
(i)
(ℓn−1) ends at.
It is easy to see that f(x
(i)
N−1) = g(x
(i)
N−1) since
h(x
(i)
N−1) = c(sL) = 0, where sL is the state that path
x
(i)
(N−1) ends at. Hence, the tail-biting path with the
minimum f -function value is exactly the one with the
minimum ML metric.
Then, equipped with an Open Stack for paths vis-
ited thus far by the priority-first search algorithm, and
a Close Table for starting and ending states and end-
ing level of the paths that have ever been on top of
the Open Stack, we summarize the priority-first search
algorithm on subtrellises in the following.
〈Phase Two: The Priority-First Search Algorithm〉3
Step 1. Sort all survivors obtained after phase one
according to ascending order of their met-
rics. If the survivor with the least metric is
1Each branch metric is the sum of n bit metrics (cf. (2)).
2Our decoding algorithm can also employ the conventional
forward VA in the first phase, and perform the priority-first
search backwardly in the second phase.
3There is an index for each path what subtrellis it belongs to.
also a tail-biting path (that starts and ends
at the same state), then output it as the final
ML decision, and the algorithm stops.
Step 2. Set ρ equal to the least metric among all
survivors that are also tail-biting paths, if
such exists; otherwise, set ρ =∞. Delete all
survivors whose metrics are no less than ρ.
Step 3. Load into the Open Stack every zero-length
path whose initial state s0 at level 0 coin-
cides with any of the ending states of the
remaining survivors. Sort these zero-length
paths in the Open Stack according to as-
cending order of their f -function values.
Step 4. If the Open Stack is empty, output the sur-
vivor with metric ρ as the final ML decision,
and the algorithm stops.
Step 5. If the top path in the Open Stack reaches
level L in its subtrellis, output the path as
the final ML decision, and the algorithm
stops.
Step 6. If the information of the starting and end-
ing states and ending level of the top path
has been recorded in the Close Table, dis-
card the top path from the Open Stack, and
go to Step 4; otherwise, record the paired in-
formation of the starting and ending states
and ending level of the top path in the Close
Table.
Step 7. Compute the f -function values of the suc-
cessors of the top path, and delete the top
path from the Open Stack. If the f -function
value of any successor is equal to or greater
than ρ, just delete it.
Step 8. Insert the remaining successor paths into
the Open Stack, and re-order the Open Stack
according to ascending f -function values.
Go to Step 4.
3. Optimality of the Priority-First Search Al-
gorithm Guided by f in (1)
In this section, we provide the proof that the
priority-first search algorithm proposed in the previ-
ous section is optimal. We begin with the lemma that
will be essential in the proof of the main result.
Lemma 1 f is a non-decreasing function along any
tail-biting path on each subtrellis, that is,
f
(
x
(i)
(ℓn−1)
)
≤ f
(
x
(i)
((ℓ+1)n−1)
)
,
Table 1: Comparison of average (ave) and maximum (max) numbers of branch metric computations in the second
phase
SNRb 1 dB 2 dB 3 dB 4 dB
algorithm ave max ave max ave max ave max
WAVA 196608 196608 196608 196608 196608 196608 196608 196608
A* 40441 2338532 8513 1871687 931 1301153 211 371576
PFSA(12) 5853 393021 1228 257729 114 245329 13 57262
Table 2: Comparison of average (ave) and maximum (max) numbers of memory required in the second phase
SNRb 1 dB 2 dB 3 dB 4 dB
algorithm ave max ave max ave max ave max
WAVA 4096 4096 4096 4096 4096 4096 4096 4096
A* 19994 1864371 4842 1641087 1357 1138133 879 339133
PFSA(12) 4350 339807 1830 237298 946 223638 598 20735
 1e-006
 1e-005
 0.0001
 0.001
 0.01
 0.1
 1
 1  1.5  2  2.5  3  3.5  4
W
or
d 
Er
ro
r R
at
e
Signal to Noise Ratio (SNR) Eb/N0 dB
PFSA(12) (A*)
WAVA
Figure 1: The word error rates (WERs) of PFSA(12),
A*, and WAVA.
for 0 ≤ j ≤ N − 1, where E is the signal energy per
channel bit, and {λj}N−1j=0 are independent noise sam-
ples of a white Gaussian process with single-sided noise
power per hertz N0. The signal-to-noise ratio (SNR)
for the channel is therefore SNR , E/N0. In order
to account for the code redundancy for different code
rates, we will use the SNR per information bit, i.e.,
SNRb =
NE/L
N0
= n
( E
N0
)
,
in the following discussions.
We now turn to the empirical examination of the av-
erage decoding complexity. The (2, 1, 12) binary con-
volutional tail-biting code with generator 5135, 14477
(octal) is considered. The length of the information
bits used in our simulations is 48. For ease of referring
them, we will respectively abbreviate the proposed al-
gorithm in phase two with λ = 12 and the scheme given
in [2] as the PFSA(12) and the A* in the sequel. For all
simulations, at least 30 word errors have been reported
to ensure that there is no bias on the simulation results.
In Figure 1, we compare the WERs of the PFSA(12)
with those obtained by the A*, as well as the WAVA
given in [1] with two iterations. Since both the
PFSA(12) and the A* are ML decoders, it is reason-
able that they yield the same WER. Also noted from
Figure 1 is that the WAVA has about 0.2 dB coding
gain loss on WER performance.
In Table 1, we compare the average and maximum
computational efforts of the PFSA(12) with those of
the A* and the WAVA in the second phase. For a fair
comparison, we count only the samples for which the
computations of branch metrics, i.e., the second term
in (2), are necessary.4 Since the WAVA searches for the
entire trellis in phase two, its number of branch metrics
computed is a constant for all SNRb. It can then be
noted that when SNRb = 4 dB, the maximum number
of computations that the PFSA(12) requires is 2/7 of
that of the WAVA. Much more saving (about 15000
times less) can be observed when the average number
of computations is concerned.
Likewise, the PFSA(12) has much smaller average
and maximum computational complexities than the A*
for all SNRb. For example, the average and maximum
numbers of computational efforts of the PFSA(12) are
respectively 16 times and 6 times less than those of the
A* at SNRb = 4 dB. A more striking result is that
4The proposed recursive implementation of the Algorithm A*
in [2] has a merit that no branch metric computation is required
when the successor path has the same f -function value as its
predecessor. By this reason, the complexities of the PFSA(12)
in Table 1 also excludes the computations of those branch met-
rics that equate the f -function values of the successor and its
immediate predecessor.
The Modified Wrap-Around Viterbi Algorithm
for Convolutional Tail-Biting Codes∗
Yunghsiang S. Han
Department of Electrical Engineering
National Taiwan University of Science and Technology
Taipei, 106 Taiwan
yshan@mail.ntust.edu.tw
Ting-Yi Wu
Department of Electrical Engineering
National Chiao Tung University
Hsinchu, 300 Taiwan
mavericktywu@gmail.com
Hung-Ta Pai
Graduate Institute of Communication Engineering
National Taipei University
Sanhsia, Taipei County, 237 Taiwan
htpai@mail.ntpu.edu.tw
Po-Ning Chen
Department of Electrical Engineering
National Chiao Tung University
Hsinchu, 300 Taiwan
poning@faculty.nctu.edu.tw
∗This work was supported by the National Science Council of Taiwan, R.O.C., under
In the literature, several suboptimal decoding algorithms for the CTBC
have been proposed [1, 3, 5]. Among them, the wrap-around Viterbi algo-
rithm (WAVA) [5] and the approximate linear time ML decoding algorithm
(ALTMLA) [3] are the two that can achieve the least decoding complex-
ity. In comparison with the WAVA, the ALTMLA has slightly better WER
performance but requires more memory storage.
In this work, we prove that even though the WAVA looks different from
the ALTMLA, it can be made completely equivalent to the ALTMLA by
a proper modification. The modified WAVA (which will be termed the
MWAVA in the sequel) and the ALTMLA give exactly the same survivor
path at each state in the trellis, and hence have equally good error perfor-
mance. One can consequently adopt the MWAVA to alleviate the extra stor-
age of the ALTMLA with no sacrifice in performance.
2 Background and Refinement of the WAVA
Denote by C∼ the (n, 1,m) CTBC with information bits of length L,
where n is the number of output bits per information bit, andm is the mem-
ory order. The trellis of C∼ then has 2m states at each level, and is of L + 1
levels. As mentioned in the previous section, the corresponding tail-biting
paths for the codewords in C∼ should constrain on the same initial and final
state. For convenience in later discussion, we denote by C∼ s the super code
of C∼ , which additionally takes in all paths that end at a final state different
from the initial state.
Let v , (v0, v1, . . . , vN−1) be a binary codeword of C∼ , where N = nL
and each vj ∈ {0, 1}. It can be verified [2] that the ML decoding output v∗
for the received vector r satisfies
N−1∑
j=0
(
φj − (−1)v∗j
)2 ≤ N−1∑
j=0
(φj − (−1)vj)2 for all v ∈ C∼ ,
where φj , ln[Pr(rj|0)/Pr(rj|1)] and Pr(·|·) is the channel transition
3
Iter1-Step 2. Apply the VA using M -metric with initial metric pi. At the
end of the first iteration, if the best survivor path is also a tail-
biting path, output it as the decoding result, and stop the algo-
rithm; otherwise, proceed with the next iteration.
The second iteration (I2)
Iter2-Step 1. Initialize every zero-length path containing only the initial
state at level 0 with the metric of the first-iteration survivor path
ending at the same state at levelL. Record pi(i) as the initial metric
associated with state i at level 0.
Iter2-Step 2. Apply the VA again using M -metric with initial metric pi.
At the end of the 2nd iteration, output the best tail-biting path if it
exists; otherwise, output the best survivor path ending at level L
(in which case a WER event may occur).
In the above algorithm, a set of 2m survivors is resulted after the comple-
tion of the first iteration. Notably, these survivor paths do not necessarily
correspond to codewords in C∼ , and they may end at some final states dif-
ferent from the ones from which they start. In such case, the algorithm
proceeds with the next iteration. However, if none of the survivor paths are
tail-biting paths after two iterations of the VA, the algorithm simply outputs
the best survivor path (which is of course not a codeword) and may admit a
failure in error correcting.
Another suboptimal algorithm, named approximate linear time ML de-
coding algorithm (ALTMLA), was proposed recently [3]. The ALTMLA
needs to record the metric of every intermediate survivor ever explored dur-
ing the execution of the first iteration. These recorded metrics will then be
incorporated into the new metric used in the second VA iteration, which is
defined below.
5
metric at state i at level L. Output the best tail-biting path if it
exists; otherwise, output the best survivor path ending at level L
(in which case a WER event may occur).
Since the ALTMLA and the MWAVA employ the same metric in their
first VA iteration, their equivalence can be sufficiently substantiated by
showing that both algorithms yield the same survivor path at each state at
their second iterations. It can be proved by induction on levels of the trellis.
When ℓ = 0, it is clear from Definition 2 that
M
(
x
(i,i)
(−1)
)
, M
(
x
(i,i)
(−1)
)
− c0(i) = M
(
x
(i,i)
(−1)
)
= 0
since c0(i) = 0. The equivalence of the two algorithms at the first level are
thus confirmed.
Suppose that the ALTMLA and the MWAVA have the same survivor path
at each state at level (k − 1). Assume that the two paths that enter state s
at level k are respectively labeled with x(i1,s)(kn−1) and x
(i2,s)
(kn−1), where i1 and
i2 are respectively the initial states of the two entering paths. Then, for the
MWAVA, the accumulated metrics of the two entering paths are respectively
pi(i1) +M
(
x
(i1,s)
(kn−1)
)
and pi(i2) +M
(
x
(i2,s)
(kn−1)
)
.
By the assumption that the ALTMLA and the MWAVA have the same sur-
vivor path at each state up to level (k − 1), the entering paths into state s at
level k for the ALTMLA should be the same, and their ALTMLA metrics
are respectively
M
(
x
(i1,s)
(kn−1)
)
= pi(i1) +M
(
x
(i1,s)
(kn−1)
)
− ck(s)
and
M
(
x
(i2,s)
(kn−1)
)
= pi(i2) +M
(
x
(i2,s)
(kn−1)
)
− ck(s).
Therefore, both algorithms have the same survivor at state s at level k be-
cause subtraction of the same quantity ck(s) does not alter the comparison
result between the two.
7
1 1.5 2 2.5 3 3.5 4 4.5
10−6
10−5
10−4
10−3
10−2
10−1
100
Signal to Noise Ratio (SNR) Eb/N0 dB
W
or
d 
Er
ro
r R
at
e
 
 
WAVA(2)
MWAVA(2)
ML
Figure 1. The word error rates of the two-iteration WAVA (WAVA(2)),
the two-iteration MWAVA (MWAVA(2)) and the maximum-likelihood
(ML) decoders for the (2, 1, 8) CTBC with generator 515, 677.
for different code rates, we will use the SNR per information bit as:
SNRb =
Eb
N0
=
NE/L
N0
= n
(
E
N0
)
in the sequel.
We first consider the (2, 1, 8) binary CTBC with generator 515, 677 (oc-
tal). The length of the information bits used in our simulations is L = 48.
For all simulations, at least 30 word errors have been reported to ensure that
there is no bias on the simulation results.
In Fig. 1, we compare theWERs of the two-iterationWAVAwith the two-
iteration MWAVA for the (2, 1, 8) CTBC. As expected, the two-iteration
MWAVA (equivalently, the ALTMLA) has slightly better performance than
the two-iteration WAVA. Also noted from Fig. 1 is that the two-iteration
WAVA and the two-iteration MWAVA are only slightly inferior to the op-
9
1 1.5 2 2.5 3 3.5 4
10−6
10−5
10−4
10−3
10−2
10−1
100
Signal to Noise Ratio (SNR) Eb/N0 dB
W
or
d 
Er
ro
r R
at
e
 
 
WAVA(2)
MWAVA(2)
ML
Figure 3. The word error rates of the two-iteration WAVA (WAVA(2)),
the two-iteration MWAVA (MWAVA(2)) and the maximum-likelihood
(ML) decoders for the (2, 1, 12) code with generator 5135, 14477.
(2, 1, 12)CTBC, theWERs of the two-iterationWAVA and the two-iteration
MWAVA are not as close to the ML performance as those for the (2, 1, 8)
CTBC.
In Fig. 4, we again investigate the effect of iterations on the MWAVA
(equivalently, the ALTMLA) for the (2, 1, 12) CTBC code. Analogously,
we observe from Fig. 4 that the second iteration produces the largest gain on
WER performance. However, a comparable performance to theML decoder
is not achieved by multiple iterations for the (2, 1, 12) code.
4 Conclusions
Even though the ALTMLA proposed in [3] is seemingly different from
the WAVA given in [5], we have proved that the latter can be made equiv-
alent in performance to the former with a proper modification. As a con-
11
Theory, pages 2245 – 2249, Seatle. USA, 2006.
4. P. Shankar, P. N. A. Kumar, K. Sasidharan, B. S. Rajan, and A. S.
Madhu. Efficient convergent maximum likelihood decoding on tail-
biting. available at http://arxiv.org/abs/cs.IT/0601023.
5. R. Y. Shao, S. Lin, and M. P. C. Fossorier. Two decoding algorithm
for tailbiting codes. IEEE Trans. Commun., COM-51(10):1658 – 1665,
October 2003.
6. Q. Wang and V. K. Bhargava. An efficient maximum likelihood de-
coding algorithm for generalized tail biting. IEEE Trans. Commun.,
COM-37(8):875 – 879, 1989.
13
96年度專題研究計畫研究成果彙整表 
計畫主持人：韓永祥 計畫編號：96-2628-E-305-001-MY3 
計畫名稱：去尾迴旋碼之軟性決定解碼之研究 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 1 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 2 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 2 0 100% 
人次 
 
期刊論文 1 2 100%  
研究報告/技術報告 0 0 100%  
研討會論文 1 1 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
 
