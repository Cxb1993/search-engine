   
  
自動辨識安全系統之開發研究 
Development and Construction of Automatic  
Recognition Security System 
 
計畫編號：NSC94-2213-E-014-002 
執行期限：94 年 08 月 01 日至 95 年 07 月 31 日 
計畫主持人: 郝樹聲 副教授 
計畫參與人員：胡榮富、許世賢 
計畫執行單位: 中正理學院電機工程學系 
桃園大溪鎮 335 員樹林三元一街 190 號 
電話：03-3800301 分機 371，傳真：03-3801407 
 
E-mail: haoshu@ccit.edu.tw 
摘要—近年來，人物的各種生物特徵都已經被採用來做為安全查核系統的重要比對依
據，或者是用於資料庫的管理與查詢的依據，在這些特徵中，以臉部的資訊最容易取得，
因為它並不需要被查核者的身體接觸測量儀表，而目前一般安全監視系統之攝影機絕大部
份只有監視錄影的能力，未能充分發揮先期辨識驗證的進一步功能，隨著恐怖活動與犯罪
行為的增加與技術的精進，監控系統具有此一功能的迫切性與必要性愈來愈加顯著。因此
本計劃的目的就是研發建立一套利用影像視訊資訊，來從事自動辨識的安全管制系統。本
計劃目前所建構完成的系統模組計有，取像感應模組、入侵偵測模組、辨認核心軟體模組(含
特徵擷取與辨認)、資料庫模組以及相關的統計辨識理論分析與程式之撰寫。這些模組化的
分系統設計未來可以很容易的在個別的模組中從事各種偵錯、修改、組合與升級。本計劃
目前完成的幾個主要相關技術為人物特徵的描述與比對、辨識錯誤率的分析、人物特徵資
訊的正確擷取標記、資料庫的建立與特徵比對演算法之研究等幾個主要部份，本計畫之成
果並且分別發表在二篇國際與國內之研討會論文中。 
 
 
 
 
Abstract—Recently, many applications take the human features as the main clues of the 
biometrics information in the security system. Among these features, facial features are the 
easiest to obtain without requiring the cooperation of the tester. Most of the cameras have only 
record function in lots of the security systems. We are attempting to construct an automatic 
recognition security system with the help of the video camera in this project. We have finished 
the database construction. The intrusion alert algorithm has been developed. We also developed 
the statistical face recognition algorithms and features extraction algorithms. The module 
designed concept is suitable for future debugging, updating and modifying. The key technologies 
are feature extraction and identification, human feature indexing, database construction, and 
related statistical algorithms. The results have been published in two conferences. 
 
 
關鍵詞：臉部辨識、特徵擷取、生物測量學、安全系統、自動偵測、錯誤分析 
 
Keywords: Face Recognition, Feature Extraction, Biometrics, Security System, Automatic 
Detection, Error Analysis 
   
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
圖三、像差法動作偵測一 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
圖四、像差法動作偵測二 
 
 
 
 
 
 
 
 
 
圖五、利用 MontiVision 以光流法從事入侵
偵測之系統方塊圖 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
圖六、光流法動作偵測一 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
圖七、光流法動作偵測二 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
圖八、利用 MATLAB 從事動作偵測 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
圖九、利用 MATLAB 從事動作偵測之程式 
 
以上所述乃是利用兩種不同軟體來設計一
套入侵偵測的模組。其中的取像攝影機乃是
市面上可容易購得的Logitech QuickCam”快
看溝通版”，或者採用其他的網路應用攝影
機都同樣可以達到一樣的效果。 
 
 
1 
   
四、    結果與討論 
 
 總結本年度研究計畫所獲致的研究成
果如下，一、是對於入侵偵測獲致一初步的
成果，可以利用現成的軟體來幫助我們從事
研 究 ， 我 們 分 別 利 用 MontiVision 與
MATLAB 兩種軟體來從事發展，都獲得入
侵偵測的初步成果，其中若是能夠加入
MATLAB 之 Video and Image Acquisition 
Blockset 的話，更可以結合 Simulink 從事
即時的介面控制模擬，此一部份將在往後的
年度中繼續採購相關的軟硬體從事研究發
展。 
二、是資料庫的建立，我們已經可利
用初步的場景規劃得到受均勻與不均勻光
照的臉部影像從事研究，此資料庫部份未來
將繼續的探討如何更精準的控制拍攝環
境，以及朝全自動的資料庫建立來發展。 
三、是特徵的擷取與比對技巧方面，
我 們 目 前 先 利 用 小 波 轉 換 (Wavelet 
Transform) 、 力 矩 不 變 性 (Moment 
Invariants) 、 以 及 主 值 轉 換 法 (Principle 
Component Transformation)，來從事影像特
徵值的建立與比對之研究，未來我們除了改
善現有之方法之外，也將繼續研究其他的特
徵值比對方法。 
四、是採用二維 PCA(2DPCA)，來從
事影像的搜尋，在這個方法中我們利用奇異
值分解(Singular Value Decomposition, SVD)
之方法與傳統的 PCA 方法做比較，實驗結
果顯示 2DPCA 在比對的正確率上優於
1DPCA，實驗過程中我們採用不同的測量指
標，例如：City Block、Euclidean Distance、
Covariance 、 Mahalanobis Distance 、
Correlation 等來判斷比對的正確性，由這幾
種方法中我們可以知道每次運算的乘法與
加法數目，對於未來實際硬體的設計有其貢
獻。 
 
計畫成果自評 
 
 本計畫＂自動辨識安全系統之開發研
究,＂執行完畢之後獲致了以下幾項之重要
成果。(1)完成入侵偵測的初步模組與其原
理之探討，(2)建立臉部資料庫拍攝之場
景，依照此一場景建立自己實驗室的臉部資
料庫，(3)指導學生完成相關的畢業論文，
(4) 完成辨識理論之研究與推導(5) 完成
特徵擷取演算法之研究(6) 應用程式之撰
寫與整合(7)投稿到在美國夏威夷舉行的
ICIS-COMSAR 2006 國際會議並且發表研
究成果。(8) 投稿到在桃園大溪舉行的第
19 屆電腦視覺、圖學暨影像處理研討會
(CVGIP 2006) 並且發表研究成果 
 本計畫執行完畢後已達成計畫書所列
舉的各項預計達成目標，所核定下來的各項
經費，除了出席國際會議之經費，因主持人
參加會議時間與學校學術委員會撞期，因此
自費註冊發表論文並未出席該研討會只有
刊登論文，本項出席國際會議核定經費新台
幣五萬元整，依照程序繳回國科會，其餘款
項已經依程序全部支用與結報完畢。 
 後續的研究主題將以本計畫之研發成
果 為 基 礎 繼 續 朝 下 年 度 計 畫 NSC 
95-2221-E-014-015＂應用於監控系統之特
徵擷取與辨識演算法之開發＂的計畫目標
上繼續改進。 
 
參考文獻 
 
[1]Rahul Sukthankar, “Argus: The Digital 
Doorman,” IEEE Intelligent Systems, 
March/April 2001, pp. 14-19. 
[2] Anil K. Jain, Arun Ross and Salil 
Prabhakar,” An Introduction to Biometric 
Recognition”, IEEE transactions on Circuits 
and Systems for Video Technology, vol. 14, no. 
1, January 2004, pp. 4-20. 
[3] Shu-Sheng Hao and Meng-Syuan Ye, 
“Facial Features Detection on Uneven 
Illumination Images,” has been submitted to 
2005 IEEE-EURASIP Workshop on Nonlinear 
Signal and Image Processing, May 18-20, 
2005, Sapporo, Japan 
[4]R. F. Hwu, ， M. S. Ye ， S. S. 
Hao, ”Automatic Facial Feature Detection 
on Security System” ， National Defense 
Conference (ND-14)，Nov 24-25, 2005, Acer 
Aspire Park, Lung-Tang, TaoYuan, Taiwan 
[5]J. C. Goswami and A. K. Chan, 
Fundamentals of Wavelets,Theory, Algorithms, 
and Applications, John-Wiley & Sons, Inc., 
1999. 
[6]J. F. Yang S. S. Hao and P. C. Chung,” 
Color Object segmentation using Fuzzy 
C-Means with Eigen-subspace Projections”, 
vol. 82, pp.461-472, Signal Processing, 2002. 
[7] M. K. Hu,”Visual “Pattern Recognition 
by Moment Invariants,” IRE Transactions 
on Information Theory, pp.179-187,1962. 
[8]Shu-Sheng Hao,”Image Features 
Extraction for Multimedia Database 
Content Description,” Proceedings of the 5th 
IEEE/ACIS International Conference on 
Computer and Information Science 
(ICIS-COMSAR’06), Honolulu, Hawaii 10-12 
July 2006 pp.327 – 332. 
[9]Rong-Fuh Hwu and Shu-Sheng Hao,”The 
Performance Evaluation of Various 
Classifiers with PCA and 2DPCA in Face 
Recognition,” 19th Computer Vision, 
Graphics and Image Processing (CVGIP 
2006), TaShim TaoYuan, 13-15 August 2006, 
Session D3-5, pp-562-565. 
DataBase
Images
Query
Image Image
Normalization
Principle
Component
Transformation
Wavelet
Decomposition
Moment
Invariants
wp
wv
wm
6
Search
Result
condition. In this paper, we use previous 
developed algorithm to locate the face region and 
refine the search. Most standard compresses image 
such as JEPG can be used to simulate in our 
proposed algorithms. Without influencing by the 
uneven lighting or occultation, the proposed 
algorithm can effectively extract the distinguishing 
image features. First, we will describe the system 
function block. Three feature extraction methods: 
Moment Invariants (MI), Principle Component 
Transformation (PCA) and Wavelet 
Decomposition (WD) will be described 
accordingly. Next, we propose a simple weighting 
method to combine the different coefficients from 
three algorithms. Following, we will refine our 
search by focusing on the facial region to obtain 
better results. Finally, we will show the simulation 
results and make a conclusion. 
2. System Function Block Diagram 
IQ
ID
Query
Image 
Features
Database
Image 
Features
(Bicubic Interpolation)
x y
System function block diagram is shown in 
Figure 1. The query image IQ can be any standard 
compressed image format such as JPEG, TIFF, 
BMP and GIF etc. The input query image can be 
arbitrary size. We use a normalization procedure to 
resize IQ into a fixed size image. 
Figure 1. Function Block Diagram 
We propose three image feature extraction 
methods to extract the feature coefficients from 
the query image. Three proposed algorithms are (1) 
Moment Invariants (MI) (2) Principle Component 
Analysis (PCA), and (3) Wavelet Decomposition
(WD). After the related features have been 
extracted, we will multiply different weights to 
these feature coefficients to obtain a judge factor. 
The judge factor taken as the query index is 
inputted to the database for comparison. A 
threshold is set according to all the judge factors. 
Image with judge factor below the query threshold 
are extracted. 
3. Moment Invariants  
How to efficiently generate and correctly match 
the features between the search item and database 
has gain lots of interests by many researchers. 
There are different features such as (1) curve 
features (2) region features, and (3) transform 
domain features can be used to identify the pattern 
[5]. They all have different advantages and 
limitations. In this paper we first choose the 
moment invariants methods based on region 
features proposed by Hu [6] to generate the 
features and search the closest object in the 
database. There are totally seven moments need to 
generate. The two dimensional moment of order 
p+q of a (N x M) discretized image I(x,y) is 
defined as follows: 
 
1 1
0 0
,
M N
p q
pq
y x
m x y I
 
  
 ¦¦ (1) 
With 0p q  , we can define the zeroth order 
moment which represents the mass as follows: 
 
1 1
00
0 0
,
M N
y x
m I
 
  
 ¦¦ x y (2) 
The center of the mass  ,x y  can be obtained 
from two first order moments m10 and m01. The 
coordinates of the center of mass are shown as 
follows: 
10 01
00 00
,m mx y
m m
   (3) 
If the object is coincident with the origin of the 
field of view 0x  and 0y   then the 
moments are referred to as central moments 
designed as pqP . The central moments of order 
three  3p q   which are invariant to rotation, 
translation and scale are given by 
M1 20 0P 2P 
 2 24M
(4a) 
2 20 02 11P P P  
   2 2033 3M P P P P   
   2 24 30 12 21 03M P P P P   
 (4b) 
3 30 12 21  (4c) 
 (4d) 
Proceedings of the 5th IEEE/ACIS International Conference on Computer and Information Science and 1st IEEE/ACIS  
International Workshop on Component-Based Software Engineering, Software Architecture and Reuse (ICIS-COMSAR’06) 
0-7695-2613-6/06 $20.00 © 2006 IEEE 
32 2
1
ˆ ˆD Q D QP i
i
iF E v
 
ª º   « »¬ ¼ ¦x x v

 (11) 
The vector composes the three 
eigenvectors of database image 
and
 1 2 3, ,D D D Di v v v v
 1 2 3, ,Q Q QQi v v v v  composes the three 
eigenvectors of query image. The factor 
PF represents the PCA comparison result.  
5. Wavelet Decomposition 
Wavelet transform is a multiresolution 
analysis method in transform domain [9]. The 
original signal feeds through the lowpass and 
highpass filter and downsamples to obtain the 
approximate and detail coefficients. Different level 
of details can be repeated with the same way 
through the highpass route. The decomposition 
process is shown in Figure 2. In this figure, Fi and 
Gi, represents the outputs of lowpass 
and highpass filter respectively. After 
downsampling with F
1i  "N
i and Gi, we will obtain the 
detail and approximation coefficients at level i. We 
can divide the original signal into N details 
1 2 and one approximation 
signals .
, , , ND D D"
NA
p2
p2 p2
p2
S
D1
A1 D2
A2
High Pass
Filter
Low Pass
Filter
High Pass
Filter
Low Pass
Filter
F1
G1 F2
G2
Approximation
Coefficients
Detail
Coefficients
Signal
S
D1A1
A2
AN
D2
DN
Approximation
Coefficients
Detail
Coefficients
Figure 2. Wavelet Decomposition
In our simulation, we take the Daubechies 
wavelet for the scaling function ,D MI [9]. For
m=2 case, the Daubechies wavelet can be 
described as in (12)-(14). 
      20 1 ,
2
m jz
G z S z z e
Z
   (12) 
If , then  2m  
   1 2 3
1 3
S z z  
 
(13) 
 0
2 3
1 3 1 3
1 4 4
2 1 3 1 3
4 4
z
G z
z z
 

 
 
 
§ ·
¨ ¸
¨
¨ ¸¨ ¸© ¹
¸  (14) 
Inspecting the simulation results, we find that 
the detail coefficients of the image can do a great 
help on querying the candidate images. We define 
the approximate coefficients as andQiA
D
iA for 
the query and database image. The different level 
of detail coefficients can be defined as 
andQkiD
D
kiD  where k is the decomposition detail 
level and i is the coefficient number. The 
approximation factor wA  and detail factor
can be defined as follows: 
F wDF
1
M
Q
wA i i
i
F
 
 ¦ A AD  (15) 
1
,   at level 
M
Q D
wD ki ki
i
F k
 
 ¦ D D  (16) 
where M is the coefficient number.  
6. Query Image Based on Feature 
Weightings 
The four feature coefficients are 
, , ,P wA wDF F F F' related to the MI, PCA and WD 
methods. First, we perform the coefficient 
normalization to restrict the coefficients in a small 
dynamic range. We take the query image 
coefficients , , ,Q Q Q Qp wA wDF F F F' as the denominators 
to normalize the coefficients , , ,D D D Dp wA wDF F F F'  of 
the database images. The process can be described 
as follows: 
, , ,
D DD D
wA wDP
P wA wDQ Q Q Q
P wA wD
F FF FF F F F
F F F
'
'
'
c c c c    
F
(17) 
Then, we multiply all the coefficients with 
different weights . The final 
image features can be represented as follows: 
, , ,m p vA vDw w w w
D
j m p P vA wA vDW w F w F w F w F' wDc c c    c (18) 
where DjW is the jth image judge factor. In order to 
compare the factor between the query image IQ
Proceedings of the 5th IEEE/ACIS International Conference on Computer and Information Science and 1st IEEE/ACIS  
International Workshop on Component-Based Software Engineering, Software Architecture and Reuse (ICIS-COMSAR’06) 
0-7695-2613-6/06 $20.00 © 2006 IEEE 
The extracted facial regions are shown in Figure 8. 
The extracted images below the threshold are 
shown in Figure 9. It is shown that the images in 
Figure 8(1,2) are closest matched with the query 
image.  
Head-and-
Shoulder
RGB Images Color Model 
Transformation
Principal Component 
Analysis (PCA)
YUV Color 
Image
Select candidate 
pixels from  skin 
area randomly
Edge 
Detection
Noise and 
Signal Planes
Hough
Transform (HT)
Binary
Image
Morphological 
Image Processing 
Binary Image 
dilated
Define Search 
Region
Circle Center 
and Radius
Threshold on
YUV planes 
Skin Region 
EigenVectors
Formation
Candidate Facial Region
Figure 7. Facial region extraction block diagram 
(1) (2) (3) (4)
(5) (6) (7) (8)
(9) (12)(11)(10)
Query
Image
Figure 8. Extracted facial regions 
Image Number
Feature Judge Factor
Figure 9. The search results 
8. Conclusions 
We propose an algorithm composed of MI, PCA 
and WD to search the correlated images in 
database. The related feature coefficients are 
combined with different weights. We use the judge 
factor as an index to select the similar image. We 
can further refine the search results with the help 
of the extracted facial region. The facial region 
can be defined by our previous research 
algorithms. There are two critical settings in our 
simulation. One is threshold level and the other is 
weightings of the extraction coefficients. Different 
threshold level is related to how strictly the search 
results will be obtained. Different weightings can 
be used to emphasis on some particular extraction 
results. We are devising an automatic threshold 
and weights setting method now. Inspecting the 
final simulation results, we have proved the 
effectiveness of our proposed algorithms. 
References: 
[1] A. K. Jain, A. Ross and S. Prabhaker, ”An 
Introduction to Biometric Recognition” IEEE 
transactions on circuits and systems for video 
technology, vol. 14, no. 1, pp. 4-20, January 2004. 
[2] R. Sukthankar and R. Stockton,”Argus: The 
Digital Doorman,” IEEE intelligent system, 
pp.14-19, March/April 2001. 
[3] S. S. Hao and M. S. Ye, “Facial Features 
Detection on Uneven Illumination Images”, 
International Workshop on Nonlinear Signal and 
Image Processing 2005 (NSIP 2005) 19PM2A-01, 
May18-20, 2005, Sapporo, Japan 
[4] R. F. Hwu,ǴM. S. YeǴS. S. Hao, ”Automatic 
Facial Feature Detection on Security System”Ǵ
National Defense Conference (ND-14)ǴNov 24-25, 
2005, Acer Aspire Park, Lung-Tang, TaoYuan, 
Taiwan 
[5] B. M. Mehtre, M. S. Kankanhalli and W.F. Lee, 
“Shape Measures for Content Based Image 
Retrival: A Comparison,” Information Processing 
and Management, Vol. 33, No. 3, pp. 319-337, 
1997 
[6] M. K. Hu,”Visual Pattern Recognition by 
Moment Invariants,” IRE Transactions on 
Information Theory, pp.179-187,1962 
[7] S. Theodoridis and K. Koutroumbas, Pattern 
Recognition, Academic Press, 2003 
[8] J. F. Yang S. S. Hao and P. C. Chung,” Color 
Object segmentation using Fuzzy C-Means with 
Eigen-subspace Projections”, vol. 82, pp.461-472, 
Signal Processing, 2002 
[9] J. C. Goswami and A. K. Chan, Fundamentals 
of Wavelets,Theory, Algorithms, and Applications,
John-Wiley & Sons, Inc., 1999. 
Proceedings of the 5th IEEE/ACIS International Conference on Computer and Information Science and 1st IEEE/ACIS  
International Workshop on Component-Based Software Engineering, Software Architecture and Reuse (ICIS-COMSAR’06) 
0-7695-2613-6/06 $20.00 © 2006 IEEE 
data, The equation for singular value decomposition of 
X is as follows:  
 
X=USVT                                                                                        (1) 
where U is an n x m matrix, S is an m x m diagonal 
matrix, and VT is also an m x m matrix. The columns of 
U are called the left singular vectors which are 
eigenvectors for face recognition. The vectors set {uk}, 
form an orthonormal basis for assay expression profiles. 
The rows of VT contain the elements of the right 
singular vectors. The vectors set {vk} form an 
orthonormal basis for the gene transcriptional responses. 
The matrix S has only nonzero elements called the 
singular values appeared on the diagonal, S = 
diag(s1,...,sn). Furthermore, sk > 0 for 1 ≤ k ≤ r, and sk = 
0 for (r+1) ≤ k ≤ n. The ordering of the singular vectors 
is determined by high-to-low sorting of singular values. 
The highest singular values are in the upper left of the S 
matrix. For a square, symmetric matrix X, singular 
value decomposition is equivalent to diagonalization or 
eigenvalue solution problem. With matrix U, we obtain 
new projected feature vector Y=UTX, which is an m x m 
dimension matrix. The form of Y=UTX is described as 
follows: 
 
⎥⎥
⎥
⎦
⎤
⎢⎢
⎢
⎣
⎡
⎥⎥
⎥
⎦
⎤
⎢⎢
⎢
⎣
⎡
⎥⎥
⎥
⎦
⎤
⎢⎢
⎢
⎣
⎡
•
⎥⎥
⎥
⎦
⎤
⎢⎢
⎢
⎣
⎡
=
⎥⎥
⎥
⎦
⎤
⎢⎢
⎢
⎣
⎡
⎥⎥
⎥
⎦
⎤
⎢⎢
⎢
⎣
⎡
⎥⎥
⎥
⎦
⎤
⎢⎢
⎢
⎣
⎡
nm
m
n
T
nmn
m
mm
m
m x
x
x
x
uu
uu
y
y
y
y
,
1,
,1
1,1
,,1
1,1,1
,
1,
,1
1,1
#"#
"
#%#
"
#"#   (2)               
 
3. METHOD OF 2DPCA 
 
If we obtain an m by n random image matrix A and let 
X nxdR∈   be a matrix with orthonormal columns, where 
n≧d. Projecting A onto X yields an m by d matrix Y = 
AX. In 2DPCA, the total scatter of the projected 
samples was used to determine a good projection matrix 
X to obtain optimal matrix Xopt. We adopt the following 
criterion: 
 
J(X) = trace{E[(Y-EY)(Y-EY)T]} 
= trace{E[(AX-E(AX))(AX-E(AX))T]} 
= trace{XTE[(A-EA)T(A-EA)] X}               (3) 
 
Defining the image covariance matrix G= E[(A-
EA)T(A-EA)], which is an n by n nonnegative definite 
matrix. Suppose that there are M training face images, 
denoted by m by n matrices Ak (k=1,2,…,M), and 
express the average image as  
∑=
k
kM
AA 1                                                         (4) 
Then G can be calculated by 
∑
=
−−= M
k
kkM 1
T )()(1 AAAAG                              (5) 
It has been proven that the optimal value for the 
projection matrix Xopt is composed by the orthonormal 
eigenvectors X1,…,Xd of G corresponding to the d 
largest eigenvalues, i.e. Xopt =[ X1,…,Xd]. 
 
Fig.1. Diagram of 2DPCA 
 
Because the size of G is only n by n, it is very efficient 
to compute its eigenvectors.  
The process of 2DPCA is shown in Fig 1, every 
image covariance matrix Gk (k=1,…,M) represents 
individual element of (5). The sum of all Gk produced 
the global image covariance matrix G to form the 
optimal eigenvectors Xopt. 
The optimal projection vectors of 2DPCA, 
X1,…,Xd  are used for feature extraction. For a given 
image represented by A. Let us define  
 
Yk=AXk, k=1,2,…,d.                                            (6) 
 
Then, we obtain a family of projected feature vectors, 
Y1,…,Yd, which are called the principal component 
(vectors) of the sample image A. It should be noted that 
each principal component of 2DPCA is a vector, 
whereas the principal component of PCA is a scalar. 
The obtained principal component vectors are used to 
form an n x d matrix B=[Y1,…,Yd], which is called the 
feature matrix or feature image of the image A. 
 
4. METRICS OF CLASSIFICATION 
 
In this paper, we use five classification metrics [6] to 
evaluate the performance of face recognition for PCA 
and 2DPCA. The performances of face recognition can 
be evaluated by recognition rate and speed. These five 
recognition metrics have two forms. One form is 
distance which measures the separate between feature 
vectors and another form is a similarity measure. We 
will describe five metrics in the following sections. 
 
4.1. City block 
 
The city block is a distance measure, also called L1 
norm. It sums up the absolute difference between 
feature vectors. The L1 norm of an image A and image 
B is defined as follows: 
 
∑
=
−= N iiL
1i
1 )( BABA,                                         (7) 
G1 
GM 
Xopt G z  z  
z  
z  
z  
z  
563
