 1 
專題研究計畫成果報告 
此次報告內容是以介紹研究成果，以以下三篇 IEEE TVCG 期刊論文以及一篇
ACM TOG期刊論文為主要內容。依照國科會專題研究計畫成果報告撰寫格式規定，
本計畫已有論文發表者，得作為成果報告內容或附錄，並請註明發表刊物名稱、
卷期及出版日期。論文資訊如下，並從下頁起附加論文內容為成果報告內容。 
(2008) Chih-Yuan Yao and Tong-Yee Lee, “Adaptive Geometry Image,” IEEE Transactions on 
Visualization and Computer Graphics, VOL. 14, NO. 4, July/August 2008, pp. 948-959 (SCI/EI, ISI ranking: 
8/86 = 9%@2008, 11/84=13%@2007). 
(2009) Chih-Yuan Yao, Hung-Kuo Chu, Tao Ju, Tong-Yee Lee, “Compatible Quadrangulation by 
Sketching ” Computer Animation and Virtual Worlds Journal Vol. 20, No. 2-3, 2009 , pp. 101-109(9) (a 
special issue of 22nd Annual Conference on Computer Animation and Social Agents, 2009 in "Het 
Trippenhuis", Amsterdam, the Netherlands) (SCI/EI) 
(2008) Yu-Shuen Wang and Tong-Yee Lee, “Curve-Skeleton Extraction Using Iterative Least Squares 
Optimization,” IEEE Transactions on Visualization and Computer Graphics, VOL. 14, NO. 4, July / 
August 2008, pp. 926-936 (SCI/EI, ISI ranking: 8/86 = 9%@2008, 11/84=13%@2007).  
(2010) Hung-Kuo Chu, Niloy J. Mitra, Daniel Cohen-Or, Tien-Tsin Wong and Tong-Yee Lee, 
“CAMOUFLAGE IMAGES, ”ACM Transaction on Graphics (also in Proceedings of SIGGRAPH 2010), 
Vol. 29, No.3, Article: 51, July. 2010. (SCI/EI, ISI ranking: 3/86 = 3%@2008,1/84=1%@2007) 
 
that the AGIM can be partially accelerated by the GPU to
achieve real-time rendering performance.
2 RELATED WORK
There have been several schemes such as [8] and [21]
proposed for converting irregular meshes into semiregular
remeshes. GIM [12] is a completely regular structure for
representing an arbitrary surface. The major limitation of
GIMs is its distortion problem. To parameterize an entire
mesh into a single regular chart easily leads to greater
distortion and less uniform surface sampling than can be
achieved with irregular multicharts (MCGIM) [34]. The
MCGIM achieves very high PSNR reconstruction quality
but still has some problems, as mentioned in Section 1.
Recently, the rectangularMCGIM [3] (RMCGIM)was used to
exploit rectangular patches onto tile surfaces, guaranteeing a
one-to-one pixel correspondence across chart boundaries.
However, it is difficult to guarantee each tiled patch with a
rectangular shape. The RMCGIM still has higher distortion
thanMCGIM, and its packing efficiency is not too high (about
80 percent). In contrast to multichart methods, several single
chart methods such as spherical parameterization [31] and
smooth GIMs [26] can reduce undersampling or distortion
problem in GIMs. Although the spherical parameterization
[31] only supports genus-0 meshes, this drawback is over-
come by toroidal domain tessellation [35]. In addition,
Peyre´ andMallat [30] attempted to improve the compression
ratio of GIMs using wavelet techniques. Herna´ndez and
Rudomin [14] and Ji et al. [17] proposed dynamic LOD of
GIMs on GPU. To remove T-vertices, Ji et al. used a restricted
quadtree triangulation (RQT) method [15]. With RQT, the
levels of adjacent quadtree nodes differ by, at most, one.
Like GIMs, the terrain data is always represented with a
regular grid structure. Recently, Pajarola and Gobbetti [29]
present a very thorough survey on semiregular multi-
resolution representation for interactive terrain rendering.
The adaptive terrain rendering algorithm can dynamically
generate adaptive meshes. The T-vertices may appear when
two neighboring meshes are tessellated at different rates. A
mesh with T-vertices easily creates cracks. Many techniques
[4], [20], [25] have been proposed to optimize adaptive
terrain mesh without generating T-vertices. However,
many high-valence vertices are always generated to remove
T-vertices. To avoid these types of vertices, most previous
methods require that the levels of adjacent mesh tessella-
tions differ by at most one or two [29]. Alternatively,
Lossasso et al. [7] do not remove T-vertices and propose to
use Fragment shader to blend rendering artifacts caused by
T-vertices. This approach can work well in terrain render-
ing. However, it is not suitable for geometry processing
such as mesh editing and deformation. The quaddominant
mesh [6], [13], [36], [38] is also a very popular model
representation with a regular data structure. The same
problem will be encountered as the adaptive mechanism is
applied to quadsurface [1], [27], [33]. Like MCGIMs, a
zippering algorithm can be used to remove T-vertices.
Surface parameterization research has been very active
in computer graphics. However, a detailed surface para-
meterization technique survey is beyond the scope of this
paper. A nice survey of parameterization methods can be
found in [10] or refer to the literature. In our setting, the
parameterization results from previous approaches can be
viewed as inputs to the proposed AGIM method. Our
method converts their results into a single AGIM image
with lower geometric reconstruction error and more uni-
form sampling than that which can be achieved with a GIM.
3 APPROACH OVERVIEW AND DEFINITIONS
In Fig. 1, given a surface mesh M and its surface
parameterization , our goal is to convert  into an AGIM.
To achieve this goal, we borrow parameterization results in
[31] as the input to the proposed method. The parameteriza-
tion data fromother techniques globally parameterizing a 3D
surface onto a rectangular domain can also be used. From ,
we initially create a low resolution ð2i þ 1Þ  ð2i þ 1Þ GIM
denoted as Gi at tessellation rate i. In our setting, this Gi is
treated as a virtual GIM, and each gridðx; yÞ is viewed as a
control vertex. In Fig. 2, each control vertex is illustrated by a
black dot. The surface parameterization  is also displayed
for easy explanation of our idea. For each gridðx; yÞ, our
method adaptively determines a local ð2i0 þ 1Þ  ð2i0 þ 1Þ
GIM centralized at ðx; yÞ, denoted as gi0;x;y. Therefore, the
neighbor of gi0;x;y can be tessellated at different rates, thus
creating T-vertices. Section 4 will present more details to
generate the AGIM. The zippering algorithm will be
introduced to remove T-vertices at rendering time in
Section 5.
YAO AND LEE: ADAPTIVE GEOMETRY IMAGE 949
Fig. 1. Overview of AGIM.
Our zippering algorithm consists of three major steps
(Fig. 5): 1) generating triangulation vertices on each zipper
block, 2) triangulating all edge and corner blocks, indepen-
dently, and 3) stitching each pair of adjacent triangulations.
5.2 Generating Triangulation Vertices
5.2.1 Up-Sampling a Zipper Block
Once each 2  2 edge block of gi0
1
;x1;y1 is detected, we first
sample it up to the same tessellation rate with its adjacent
block within gi0
2
;x2;y2 . After up-sampling each edge block, we
build a treelike triangulation  within it to stitch gi01;x1;y1 and
gi0
2
;x2;y2 (Section 5.2.2). To smooth the zippering triangula-
tion, we achieve this up-sampling using [3]. A corner block
must have two adjacent blocks tessellated at k1 and k2 times
with k1  k2. There will be two treelike triangulations called
k1 and k2 (Section 5.2.3) built within each corner block.
First, we tessellate it at k1 times to build a k1 . To build a k2 ,
it is not necessary to tessellate it again, since all
ð2k2 þ 1Þ  ð2k2 þ 1Þ samples  ð2k1 þ 1Þ  ð2k1 þ 1Þ samples.
5.2.2 Generating Triangulation Vertices in an Edge Block
Not all samples are used to build a triangulation within
an edge block. A good  should be a triangulation
reminiscent of a balanced tree. After up-sampling, each
edge block is tessellated into a ð2k þ 1Þ  ð2k þ 1Þ block. See
several examples in Fig. 6. Its border adjacent to gi0
2
;x2;y2 is
called the bottom border, and the opposite border is called
the top border. We define a local frame to easily address
each sample at gridðx; yÞ by orienting each block (Fig. 6)
such that its bottom border is aligned with the positive
x-axis pointing right and the positive y-axis pointing up
(from the bottom border to the top border). The origin (0, 0)
is set at its left-bottom corner. Each vertex of  is denoted
as L
ð‘;iÞ
ðx;yÞ, where iði  1Þ indicates the ith vertex on the
‘thð‘  0Þ level of a treelike , and this vertex is selected
from the sample at grid ðx; yÞ of this block. There are
ð2k þ 1Þ vertices on the 0th level of , and these vertices
are selected from ð2k þ 1Þ samples on the bottom border.
The number, N‘, of vertices on the ‘thð0  ‘  kÞ level of
YAO AND LEE: ADAPTIVE GEOMETRY IMAGE 951
Fig. 5. Overview of our zippering algorithm.
Fig. 4. Illustration of AGIM packing algorithm. (a) queueði0 Þ. (b) An image container. (c) AGIM consists of many containers. (d) AGIM.
and g denote samples located on the upper right and upper
left corners of a zipper block.
5.3.1 Triangulating an Edge Block
We have obtained all  triangulation vertices in Section 5.2.2.
If N‘ 2 odd, each vertex on the ð‘þ 1Þth level corresponds to
three vertices on the ‘th level. We can use either a set of
triangle strips or fans for generating triangulation between
these two levels (Fig. 9a). For fast rendering, we adopt [9] to
build a triangle strip with repeated vertices between these
two levels in the following pseudocode. Although repeated
vertices result in degenerated triangles (i.e., zero area), this
approach generates the same rendering appearance as that
by either a set of triangle strips or fans.
Begin(triangle strip){
L
ð‘;N‘1Þ
 , L
ð‘;N‘Þ
 , L
ð‘;N‘1Þ
 , L
ð‘þ1;ðN‘1Þ=2Þ
 ;
/* L
ð‘;N‘1Þ
 is a repeated vertex */.
ifðN‘ ¼¼ 3Þ Lð‘;N‘2Þ
forði ¼ ðN‘  2Þ; i > 1; i ¼ i 2Þ {
L
ð‘;iÞ
 , L
ð‘þ1;ði1Þ=2Þ
 , L
ð‘;i1Þ
 ;
ifðði 2Þ > 1Þ
L
ð‘þ1;ði1Þ=2Þ
 ;
/* L
ð‘þ1;ði1Þ=2Þ
 is a repeated vertex*/
else
L
ð‘;i2Þ
 ;
}
}end(triangle strip);
If N‘ 2 even, each vertex on the ð‘þ 1Þth level corre-
sponds to two vertices on the ‘th level. The following is
the pseudocode to build a triangle strip between these
two levels (Fig. 9b):
Begin(triangle strip){
forði ¼ N‘; i > 0; iÞ {
L
ð‘;iÞ
 ;
ifði > 1ÞLð‘þ1;i1Þ ;
}
}end(triangle strip);
Finally, an extra triangle will be formed by (L
ð‘¼k;1Þ
ðx;yÞ , s, g) to
stitch an adjacent 2 2 block on the top border. Fig. 10 shows
several examples of triangulating edge blockswith 1  k  3.
5.3.2 Triangulating a Corner Block
We have obtained all vertices of triangulations k1 and k2 in
Section 5.2.3. In Fig. 11a, we build k1 and k2 independently
using the same method for triangulating an edge block. Then,
we stitch k1 and k2 within a corner block in two steps. First,
we build two red triangles (Fig. 11b) using two vertex-tuples
(L
ð0;1Þ
k1
, L
ð1;1Þ
k1
, L
ð1;2k21Þ
k2
) and (L
ðk1;1Þ
k1
, s, L
ðk2;1Þ
k2
). Second, we
triangulate the blue area (Fig. 11b) using one of the following
four possible configurations, as illustrated in Fig. 12:
1. k1 ¼ k2 ¼ 1. This is a special case, since Lð1;1Þk1 ¼ L
ð1;1Þ
k2
.
In this case, we build triangle strips by traveling
vertices in the following order: g, L
ð1;1Þ
k2
, s, L
ð0;3Þ
k1
.
2. k1 ¼ k2 þ 1. The blue area becomes a trapezoidlike
shape. Some vertices of k1 are on its lower base
including L
ð‘;1Þ
k1
with 1  ‘  k1. Similarly, some
vertices of k2 are on its upper base, including
L
ð‘;N‘Þ
k2
with 1  ‘  k2, where N‘ is the number of
vertices on the ‘th level of k2 . Since k1 ¼ k2 þ 1, we
build triangle strips to triangulate this trapezoid by
traveling vertices in the following order (i.e., similar
to that in Fig. 9b and please refer to its pseudocode):
L
ðk1;1Þ
k1
L
ðk2;Nk2 Þ
k2
L
ðk11;1Þ
k1
L
ðk21;Nk2 Þ
k2
; . . . ; L
ð1;Nk2 Þ
k2
L
ð1;1Þ
k1
.
3. k1 ¼ k2 6¼ 1. The blue area becomes a rectanglelike
shape. Since k1 ¼ k2 6¼ 1, we build triangle strips to
triangulate this rectangle by traveling vertices in the
following order:
L
ðk1;1Þ
k1
L
ðk2;Nk2 Þ
k2
; L
ðk11;1Þ
k1
L
ðk21;Nk2 Þ
k2
; . . . ; L
ð1;1Þ
k1
; L
ð1;Nk2 Þ
k2
:
YAO AND LEE: ADAPTIVE GEOMETRY IMAGE 953
Fig. 9. Triangle strips between levels ‘ and ‘þ 1. Arrow heads
indicate triangle orientations in generated triangle strips. (a) N‘ 2 odd.
(b) N‘ 2 even.
Fig. 10. Triangulations of edge blocks with 1  k  3. Both samples s
and g are illustrated as green points. (a) k ¼ 1. (b) k ¼ 2. (c) k ¼ 3.
Fig. 11. (a) Build k1 and k2 independently. (b) Generate triangles to
stitch k1 and k2 .
surprising to expect that the MCGIM can achieve better
results than AGIM in this respect. Even if we increase the
sampling rates of AGIMs to those of MCGIM, our
resampled regular AGIMs have lower PSNR than MCGIMs
or at most have comparable PSNR to that of MCGIMs. The
gain of PSNR is bounded by the quality of input
parameterization. However, the AGIM still shows some
potential advantages over MCGIM as follows: First, the
AGIM retain more advantages of the original GIM than
MCGIM, as discussed in Section 1. Table 2 shows another
advantage than [34] regarding the packing efficiency. The
AGIM shows much higher packing efficiency than [34]. Our
results are even better than those of a recent work called
RMCGIM [3] (about 80 percent was achieved at this work).
For example, the packing efficiency for horse and gargoyle
is 75.6 percent and 72.7 percent using MCGIM and is
81.7 percent and 83.6 percent using RMCGIM, respectively.
Fig. 15 shows another interesting comparison between two
methods regarding the valences of vertices. In this figure,
we directly excerpt the bunny example in their paper [34] to
compare with our results. There are many high-valence
vertices (more than eight) observed in their zippered
regions. In our case, we create the worst case on purpose
to the bunny example. However, using Fig. 12, the AGIM, at
most, creates 8-valence vertices for this worst case.
The AGIM is suitable for global parameterization techni-
ques based on quadrilateral complexes. In this paper, we first
manually built PolyCube-based [37] quadrilateral complexes
and then used the PolyCube method to parameterize the
surface onto the quadrilateral complexes. Fig. 19 shows
severalmodels and their quadrilateral complexes. Finally, for
each quad of a quadrilateral complex, we used an adaptive
resolution of GIMs to approximate surface parameterized on
thisquad.Tostitch adjacentGIMswithvaryingsizes,weused
the proposed zippering algorithm. Fig. 19 also shows the
YAO AND LEE: ADAPTIVE GEOMETRY IMAGE 955
TABLE 1
Reconstruction Error (PSNR) and the Number of Samples Using Different Reconstruction Methods
Fig. 14. A close look at reconstructed models comparing AGIM and Spherical Parameterization and Remeshing [31].
Fig. 15. A close look at reconstructed models comparing AGIM and
Sander et al. [34].
TABLE 2
AGIM Packing Efficiency
YAO AND LEE: ADAPTIVE GEOMETRY IMAGE 957
Fig. 18. Results for horse, gargoyle, and dinosaur examples using AGIM.
Fig. 19. Results for feline, dragon, horse, and gargoyle using PolyCube [37] with AGIM.
disadvantage may potentially hinder the scalability of our
method, since the CPU must be bothered to send ad hoc
geometry and connectivity for the zippering part, which is
different every time as the used resolution changes. Further
work with this approach will be explored in the near future.
First, we will apply AGIM to other global parameterization
methods such as [18] and [19]. We also like to investigate
the possibility of new global parameterization method
specialized to the need of AGIM or to dynamically modify
the input parameterizations to obtain better PSNR. In
addition, some further processing on AGIM such as mesh
optimization [16] can improve reconstructed quality. How-
ever, this is computationally expensive. In this paper, we
adaptively refine the quality of AGIM using only Hausdorff
distance. In the future, other metrics such as the normal
deviations can be used. In particular, for the rendering
purposes, normal accuracy will become important. Finally,
we will explore other possible AGIM applications such as
3D morphing [22], [24] or constrained texture mapping [23].
ACKNOWLEDGMENTS
The authors would like to thank Praun and Hoppe [31] for
providing their open parameterization data for helping with
our experiment. They also thank the anonymous reviewers
for helping them to improve this paper. This work was
supported by the Landmark Program of the NCKU Top
University Project under Contract B0008 and was supported
inpart by theNational ScienceCouncil underContractsNSC-
95-2221-E-006-193-MY2 and NSC-96-2628-E-006-200-MY3.
REFERENCES
[1] P. Alliez, D. Cohen-Steiner, O. Devillers, B. Le´vy, and M. Desbrun,
“Anisotropic Polygonal Remeshing,” ACM Trans. Graphics, vol. 22,
no. 3, pp. 485-493, 2003.
[2] N.A. Carr and J.C. Hart, “Meshed Atlases for Real-Time
Procedural Solid Texturing,” ACM Trans. Graphics, vol. 21, no. 2,
pp. 106-131, 2002.
[3] N.A. Carr, J. Hoberock, K. Crane, and J.C. Hart, “Rectangular
Multi-Chart Geometry Images,” Proc. Fourth Eurographics Symp.
Geometry Processing (SGP ’06), pp. 181-190, 2006.
[4] P. Cignoni, F. Ganovelli, E. Gobbetti, F. Marton, F. Ponchio,
and R. Scopigno, “Planet-Sized Batched Dynamic Adaptive
Meshes (P-BDAM),” Proc. IEEE Visualization ’03, pp. 147-155,
Oct. 2003.
[5] P. Cignoni, C. Rocchini, and R. Scopigno, “Metro: Measuring
Error on Simplified Surfaces,” Computer Graphics Forum, vol. 17,
no. 2, pp. 167-174, 1998.
[6] S. Dong, P.-T. Bremer, M. Garland, V. Pascucci, and J.C. Hart,
“Spectral Surface Quadrangulation,” ACM Trans. Graphics, vol. 25,
no. 3, pp. 1057-1066, 2006.
[7] M.A. Duchaineau, M. Wolinsky, D.E. Sigeti, M.C. Miller,
C. Aldrich, and M.B. Mineev-Weinstein, “Roaming Terrain:
Real-Time Optimally Adapting Meshes,” IEEE Visualization,
pp. 81-88, 1997.
[8] M. Eck, T. DeRose, T. Duchamp, H. Hoppe, M. Lounsbery,
and W. Stuetzle, “Multiresolution Analysis of Arbitrary
Meshes,” Proc. ACM SIGGRAPH ’95, pp. 173-182, 1995.
[9] F. Evans, S.S. Skiena, and A. Varshney, “Optimizing Triangle
Strips for Fast Rendering,” Proc. IEEE Conf. Visualization, pp. 319-
326, R. Yagel and G.M. Nielson, eds., http://www.cs.sunysb.edu/
stripe/, 1996.
[10] M.S Floater and K. Hormann, Surface Parameterization: A Tutorial
and Survey, 2005.
[11] C. Gotsman, X. Gu, and A. Sheffer, “Fundamentals of Spherical
Parameterization for 3D Meshes,” ACM Trans. Graphics, vol. 22,
no. 3, pp. 358-363, 2003.
[12] X. Gu, S.J. Gortler, and H. Hoppe, “Geometry Images,” Proc. ACM
SIGGRAPH ’02, pp. 355-361, 2002.
[13] X. Gu and S.-T. Yau, “Global Conformal Surface Parameter-
ization,” Proc. Eurographics/ACM SIGGRAPH Symp. Geometry
Processing (SGP ’03), pp. 127-137, 2003.
[14] B. Herna´ndez and I. Rudomin, “Simple Dynamic LOD for
Geometry Images,” Proc. Fourth Int’l Conf. Computer Graphics
and Interactive Techniques in Australasia and Southeast Asia
(GRAPHITE ’06), pp. 157-163, 2006.
[15] B.V. Herzen and A.H. Barr, “Accurate Triangulations of
Deformed, Intersecting Surfaces,” Proc. ACM SIGGRAPH ’87,
pp. 103-110, 1987.
[16] H. Hoppe, T. DeRose, T. Duchamp, J. McDonald, and W. Stuetzle,
“Mesh Optimization,” Proc. ACM SIGGRAPH ’93, pp. 19-26, 1993.
[17] J. Ji, E. Wu, S. Li, and X. Liu, “Dynamic LOD on GPU,” Proc.
Computer Graphics Int’l (CGI ’05), pp. 108-114, 2005.
[18] M. Jin, J. Kim, and X.D. Gu, “Discrete Surface Ricci Flow: Theory
and Applications,” Proc. IMA Conf. Math. of Surfaces, pp. 209-232,
2007.
[19] M. Jin, F. Luo, and X. Gu, “Computing Surface Hyperbolic
Structure and Real Projective Structure,” Proc. ACM Symp. Solid
and Physical Modeling (SPM ’06), pp. 105-116, 2006.
[20] B.D. Larsen and N.J. Christensen, “Real-Time Terrain Rendering
Using Smooth Hardware Optimized Level of Detail,” J. Winter
School on Computer Graphics, Proc. 11th Int’l Conf. Central Europe
on Computer Graphics, Visualization and Digital Interactive
Media (WSCG ’03), vol. 11, no. 2, pp. 282-289, Feb. 2003.
[21] A.W.F. Lee, W. Sweldens, P. Schro¨der, L. Cowsar, and D. Dobkin,
“Maps: Multiresolution Adaptive Parameterization of Surfaces,”
Proc. ACM SIGGRAPH ’98, pp. 95-104, 1998.
[22] T.-Y. Lee and P.-H. Huang, “Fast and Intuitive Metamorphosis of
3D Polyhedral Models Using SMCC Mesh Merging Scheme,”
IEEE Trans. Visualization and Computer Graphics, vol. 9, no. 1,
pp. 85-98, Jan.-Mar. 2003.
[23] T.-Y. Lee, S.-W. Yen, and I.-C. Yeh, “Texture Mapping with Hard
Constraints Using Warping Scheme,” IEEE Trans. Visualization and
Computer Graphics, vol. 14, no. 2, pp. 382-395, Mar./Apr. 2008.
[24] C.-H. Lin and T.-Y. Lee, “Metamorphosis of 3D Polyhedral
Models Using Progressive Connectivity Transformations,” IEEE
Trans. Visualization and Computer Graphics, vol. 11, no. 1, pp. 2-12,
Jan./Feb. 2005.
[25] F. Losasso and H. Hoppe, “Geometry Clipmaps: Terrain Render-
ing Using Nested Regular Grids,” Proc. ACM SIGGRAPH ’04,
pp. 769-776, 2004.
[26] F. Losasso, H. Hoppe, S. Schaefer, and J. Warren, “Smooth
Geometry Images,” Proc. Eurographics/ACM SIGGRAPH Symp.
Geometry Processing (SGP ’03), pp. 138-145, 2003.
[27] M. Marinov and L. Kobbelt, “Direct Anisotropic Quad-Dominant
Remeshing,” Proc. 12th Pacific Conf. Computer Graphics and
Applications (PG ’04), pp. 207-216, 2004.
[28] What’s New in OpenGL 2.1, OpenGL.org.
[29] R. Pajarola and E. Gobbetti, “Survey of Semi-Regular Multi-
resolution Models for Interactive Terrain Rendering,” Visual
Computer, vol. 23, no. 8, pp. 583-605, 2007.
[30] G. Peyre´ and S. Mallat, “Surface Compression with Geometric
Bandelets,” ACM Trans. Graphics, vol. 24, no. 3, pp. 601-608, 2005.
[31] E. Praun and H. Hoppe, “Spherical Parametrization and
Remeshing,” ACM Trans. Graphics, vol. 22, no. 3, pp. 340-349,
2003.
[32] B. Purnomo, J.D. Cohen, and S. Kumar, “Seamless Texture
Atlases,” Proc. Eurographics/ACM SIGGRAPH Symp. Geometry
Processing (SGP ’04), pp. 65-74, 2004.
[33] N. Ray, W.C. Li, B. Le´vy, A. Sheffer, and P. Alliez, “Periodic
Global Parameterization,” ACM Trans. Graphics, vol. 25, no. 4,
pp. 1460-1485, 2006.
[34] P.V. Sander, Z.J. Wood, S.J. Gortler, J. Snyder, and H. Hoppe,
“Multi-Chart Geometry Images,” Proc. Symp. Geometry Processing,
pp. 146-155, 2003.
[35] J. Schreiner, A. Asirvatham, E. Praun, and H. Hoppe, “Inter-
Surface Mapping,” Proc. ACM SIGGRAPH ’04, pp. 870-877, 2004.
[36] D. Steiner and A. Fischer, “Planar Parameterization for Closed
Manifold Genus-G Meshes Using Any Type of Positive Weights,”
J. Computing and Information Science in Eng., vol. 5, no. 2, June 2005.
[37] M. Tarini, K. Hormann, P. Cignoni, and C. Montani, “Polycube-
Maps,” Proc. ACM SIGGRAPH ’04, pp. 853-860, 2004.
[38] Y. Tong, P. Alliez, D. Cohen-Steiner, and M. Desbrun, Designing
Quadrangulations with Discrete Harmonic Forms, 2006.
YAO AND LEE: ADAPTIVE GEOMETRY IMAGE 959
COMPUTER ANIMATION AND VIRTUAL WORLDS
Comp. Anim. Virtual Worlds (2009)
Published online in Wiley InterScience
(www.interscience.wiley.com) DOI: 10.1002/cav.313...........................................................................................
Compatible quadrangulation by
sketching
By Chih-Yuan Yao, Hung-Kuo Chu, Tao Ju and Tong-Yee Lee*
..........................................................................
Mesh quadrangulation has received increasing attention in the past decade. While previous
works have mostly focused on producing a high quality quad mesh of a single model, the
connectivity of the quadrangulation is typically difﬁcult to control and varies among
models even with similar shapes. In this paper, we propose a novel interactive framework
for quadrangulating a set of models collectively with compatible connectivity. Furthermore,
we demonstrate its application to 3D mesh morphing. In our approach, the user
interactively sketches a skeleton within each model, and our method automatically
computes compatible base domains for all models from these skeletons, on which the
models are parameterized. With this novel parameterization, it is very easy to generate a
pleasing and smooth 3D morphing sequence among these compatible models. The method
yields quadrangulation with comparable quality to existing approaches, but greatly
simpliﬁes compatible re-meshing among a group of topologically equivalent models, in
particular characters and animals models, with direct applications in shape blending and
morphing. Copyright © 2009 John Wiley & Sons, Ltd.
Received: 24 March 2009; Accepted: 25 March 2009
KEY WORDS: quadrangulation; morphing; compatible; shape blending
Introduction
Mesh parameterization and remeshing are fundamental
problems in digital geometry processing and have been
extensively studied. In particular,mesh quadrangulation
has attracted rising attentiondue to itsmanyapplications
such as texture mapping, texture synthesis, CAD design,
and ﬂuid ﬂow simulation, where a quadrilateral mesh is
preferred over a triangular one.
Existing approaches have focused primarily on
producing quality quad mesh of a single model. A
number of methods create the quadrangulation by
integrating two orthogonal directions derived from
speciﬁc ﬁeld functions on the surface such as the
curvature tensor ﬁeld1,2 and harmonic function.3,4 A
different approach taken by other researchers is the
use of a base complex as the parameterization domain.
Guskov5 proposes to setupaquadbasedomainmanually
*Correspondence to: T-Y Lee, National Cheng-KungUniversity,
Tainan, Taiwan, ROC. E-mail: tonylee@mail.ncku.edu.tw
followed by reﬁnements to approximate the original
surface. To simplify the manual process, Tarini6 uses
a collection of tightly stacked cubes (called Poly-
cubes) to serve as the base domain. More recently,
Dong7 uses the Morse–Smale complex as the base
domain and parameterize the mesh by solving a global
system.
In applications such as morphing,8–10 a prerequisite is
that a correspondence needs to be established between
the mesh elements in two or more models. In this
scenario, it is ideal to represent models by meshes with a
common connectivity that encodes the correspondence.
Unfortunately, the above-mentioned methods either do
not allow direct control over the connectivity of the
resulting quadrangulation, or require non-trivial effort in
manually settingupacommonbasedomain consistingof
quadrilaterals.11 While anumberof techniqueshavebeen
proposed for compatible triangulations12–14 that allow a
user to specify patch layout or feature correspondences
directly on the mesh surface, extending these techniques
formorphing is non-trivial. In addition, it is less intuitive
for a user to specify corresponding feature “points” on
............................................................................................
Copyright © 2009 John Wiley & Sons, Ltd.
COMPATIBLE QUADRANGULATION BY SKETCHING
...........................................................................................
Figure 2. Constructing a poly-pipe (d) from a skeleton (a) by
inﬂating high-valence nodes into hinges (b) and the rest of the
skeleton into pipes (c). In the sketched skeleton, nodes with
valence 1, 2 and more are colored in green, blue, and red,
respectively, and the arcs deﬁning the axis at each node are
colored red.
node. Third, to ensure a closed base domain (see next),
the system will automatically add a new node between
two valence-3 nodes sharing a common arc by splitting
the arc from themiddle. Lastly, given anumber ofmodels
that the user wishes to compatibly quadrangulate, the
skeleton of each model must have the same edge-arc
connectivity.
Poly-pipe Construction
The poly-pipe is constructed by building a system of
pipes along the skeleton arcs, or intuitively, inﬂating the
thin skeleton into a “fat” body. For the parameterization
purpose, the poly-pipe needs to preserve the topology
of the skeleton (and hence the topology of the model)
while consisting of only quad faces. To simultaneously
fulﬁll these requirements, we adopt a divide-and-
conquer approach, where pieces of the poly-pipe will be
constructed separately based on the skeleton structure
and connected together afterwards. In particular, we
will construct one pipe for each path of skeleton arcs
bounded between two nodes of valence 1 or 2, and one
hinge for each node of valence 3 or more. A neighboring
pipe and hinge will share a common quad face at
one end of the pipe. As such, all pipes and hinges
will connect seamlessly into a complex with only quad
faces and has the same topology of the skeleton (see
Figure 2b–d).
Below, we detail the construction of these two sub-
complexes, pipes and hinges. There are two main
challenges that have to be resolved. Topologically, while
it is trivial to construct apipewithquad cross-section, it is
more difﬁcult to construct a quad-only hinge polyhedron
at a skeleton node with possibly many outgoing arcs. In
addition, geometrically, the faces of the pipes and hinges
need to have relatively lowdistortion to serve as the base
domain for parameterization.
Pipe Construction
As deﬁned above, each pipe is constructed from a path
of skeleton arcs ended at two nodes with valence 1 or 2.
The pipe can be built by connecting a unit square located
at each node whose normal is aligned with the tangent
direction of the incident arcs. To compute the rotation of
the square around its normal while minimizing twisting
of the pipe, we adopt a similar idea to the sweeping
surface16,17 method, where the rotation of the squares
in the interior of the pipe is propagated from those at
the ends of the pipe. Note that if one (or both) end of
the skeleton path is adjacent to a node with valence 3
or more, the square face at that end of the pipe will be
replaced by the square located at the connecting quad
face of the hinge. Hence we have two cases to consider,
when either one or both ends of the pipe have given
square rotations. If neither end has a ﬁxed rotation,
we arbitrarily pick one end and ﬁx the rotation of that
square.
If one end face of the pipe has a ﬁxed orientation,
we denote the two axes of that square face as u0, v0
and its normal as t0 (see Figure 3b). To compute the
axes of the square cross-section as the next node with
tangent direction t1, we rotate u0, v0 around the vector
t0 × t1 by the angle between t0 and t1. The orientation can
thus be propagated throughout the pipe. An example
is shown in Figure 3(b) and compared to an otherwise
twisted conﬁguration in (a). If both ends of the pipe have
ﬁxedorientations,wewill propagate theorientation from
each end and obtain the ﬁnal orientation of the cross-
section square at a node as aweighted combination of the
orientation computed from both ends, where the weight
is proportional to the distance from the node to that end.
An example is shown in Figure 3(c).
Finally, to conform to the geometry of the mesh, we
project each vertex of the square cross-sections radially
from the square centers onto the model surface.
............................................................................................
Copyright © 2009 John Wiley & Sons, Ltd. Comp. Anim. Virtual Worlds (2009)
DOI: 10.1002/cav
COMPATIBLE QUADRANGULATION BY SKETCHING
...........................................................................................
the principle direction of variation of the projected arcs
using PCA (Figure 4b). The cuboid is rotated so that one
of itsprojecteddiagonal axis is alignedwith thatprinciple
direction (Figure 4b,c).
Quintic Subdivision. Oneach faceof the initial cuboid
where there are more than one skeleton arc intersecting
(Figure 4d), the face is subdivided. To reduce the number
of subdivisions that have to be performed, we prefer
a way of subdividing the face so that the intersections
with the skeletal arcs are uniformly distributed, that is,
when themaximumnumberof intersectingpointswithin
each subdivided face is minimized. To do so, in the
quintic subdivision shown in Figure 4(e), we place the
four vertices of the interior quad at proportion h ∈ (0, 1)
along the line connecting the centroid of the face to
the vertices of the original quad. To ﬁnd the optimal
choice of h, it sufﬁces to check for those h that yield
different distributions of the number of intersections on
the subdivided faces.
Subdivision is performed repeatedly to any quad
face that have more than one intersections with the
outgoing skeleton arcs. To show that such subdivision
always terminates, we observe that the the total number
of intersections on a quad face is reduced by at
least half after each subdivision following the above
procedure.
To adjust the hinge shape to the actual geometry, as
in pipe construction, we project the hinge vertices to
the actual geometry. For the initial cuboid, we project
the two end faces (situated at two neighboring nodes)
radially from their centers. For vertices created during
subdivision, they are ﬁrst placed at the corners of a unit
square situated at the nodes along the intersecting arcs,
and projected radially from their centers. An example
result is shown in Figure 4(f).
Compatible Hinge Construction. Note that the
face structure of the hinge produced by quintic
subdivision depends not only on the number of arcs
at a skeleton node but also the direction of those arcs.
To ensure that the face structure is the same among
the poly-pipes constructed for a group of models with
different shapes, we simply ask the user to select one
of the models as a reference model and adopt the face
structure of the hinges on the reference poly-pipe for
all their poly-pipes (assuming the skeletons have the
same connectivity and the correspondence between the
edges and arcs in different skeletons are provided by the
sketching interface).
Parameterization and
Quadrangulation
Once a poly-pipe has been constructed, we partition the
surface into quad patches by tracing boundaries12–14 of
the patches based on the connectivity of poly-pipe. To
parameterize the surface over the patches, one can either
solve a global linear system19 or employ an iterative
local parameterization method.13,14 In our method, we
adopt the latter approach to obtain a smooth andbijective
parameterization. To obtain a semi-regular quadrilateral
mesh, we uniformly sample each quad patch in its
parametric 2D domain.
Results
We ﬁrst demonstrate our method in quadrangulating a
single model. The use of a user-provided sketchmakes it
easy to create base domains that may have a non-trivial
shape or topology, as shown in Figure 5(a). The quality
of quadrangulation is reported in Table 1 using the L2
stretch metric.20 The ideal L2 value is equal to 1. The
literature typically achieve L2 values on similar models
in the range of 1.2–0.7. We compare our method with
the recently developed method by Reference [2] using
the three models shown in Figure 5(b), and the result is
reported in Table 2.We observe that ourmethod achieves
comparable quality in quadrangulation.
The primary beneﬁt of our method is that a user
can easily create compatible quad re-meshing of a
Figure 5. (a) Constructed poly-pipes and semi-regular
quadrilateral meshes of four models with non-zero genus. (b)
Models used in comparison with Ray et al. [2].
............................................................................................
Copyright © 2009 John Wiley & Sons, Ltd. Comp. Anim. Virtual Worlds (2009)
DOI: 10.1002/cav
COMPATIBLE QUADRANGULATION BY SKETCHING
...........................................................................................
Figure 8. Linearly Blended shape between pig and wolf before
(a) and after (b) adjusting a poly-pipe vertex (red sphere).
correspondence, as seen in Figure 8(a) middle. We
demonstrate more linear morphing results in Figure 1
and in the accompanied video.
Conclusion and Discussions
We presented a novel interactive method for quadran-
gulating 3D models. The method utilizes a convenient
and intuitive form of user input—sketching—to easily
produce high quality, compatible quadrangulation
among multiple models. The key component of
our method is a novel algorithm that constructs a
quadrilateral base domain automatically from a user-
provided curve skeleton.
The current method has a number of limitations that
we seek to address in the future. First, the quality of
parameterization relies on the quality of the poly-pipe,
which in turn depends on the user-provided skeleton.
Although we found it is easy to create a skeleton that
would yield a satisfactory quadrangulation, poor result
may be generated from an incomplete skeleton. For
example, Figure 9 compares the result without (a) and
with (b) a tail segment in the skeleton of a dinosaur, and
observe that the former results inaparameterizationwith
large distortion at the tail. One possible way to ensure a
complete skeleton is to use an automatically generated
skeleton by recent methods such as References [21–23],
anduse this as a guideduringuser sketching. Second, the
poly-pipe structure is designed for curve skeletons and
suitable for quadrangulating shapes consisting ofmostly
tube-like parts, such as characters. For models with a
plate-like geometry, such as the hand in Figure 9(c),
Figure 9. (a) Skeletonwithmissing tail partwill produce poor-
shaped poly-pipe and re-meshing, (b) which can be resolved
by adding the tail segment. (c) A hand model with plate-like
geometry (the palm) cannot be well parameterized using our
curve-skeleton-based poly-pipes.
poly-pipewouldyield less satisfactoryparameterization.
To this end, we would like to investigate more general
ways to construct base complexes from not only skeleton
curves but also surfaces.
ACKNOWLEDGEMENT
We thank anonymous reviewers’ helpful comments to improve
this paper. This work is supported in part by the Landmark
Program of the NCKU Top University Project (Contract B0008),
the National Science Council (Contracts NSC-97-2628-E-006-
125-MY3 and NSC-96-2628-E-006-200-MY3), Taiwan, Republic
of China. This work is supported in part by NSF grant CCF-
0702662.
References
1. Ka¨lberer F, Nieser M, Polthier K. Quadcover—surface
parameterization using branched coverings. Computer
Graphics Forum 2007; 26(3): 375–384.
2. Ray N, Li WC, Le´vy B, Sheffer A, Alliez P. Periodic global
parameterization.ACM Transactions on Graphics 2006; 25(4):
1460–1485.
............................................................................................
Copyright © 2009 John Wiley & Sons, Ltd. Comp. Anim. Virtual Worlds (2009)
DOI: 10.1002/cav
COMPATIBLE QUADRANGULATION BY SKETCHING
...........................................................................................
Tong-Yee Lee received the PhD degree in computer
engineering fromWashington State University, Pullman,
in May 1995. He is currently a Distinguished Professor
in the Department of Computer Science and Information
Engineering, National Cheng-Kung University, Tainan,
Taiwan, ROC. He leads the Computer Graphics
Group, Visual System Laboratory, National Cheng-
Kung University (http://graphics.csie.ncku.edu.tw/).
His current research interests include computer graphics,
non-photorealistic rendering, image- based rendering,
visualization, virtual reality, surgical simulation,medical
visualization and medical system, and distributed and
collaborative virtual environments.
............................................................................................
Copyright © 2009 John Wiley & Sons, Ltd. Comp. Anim. Virtual Worlds (2009)
DOI: 10.1002/cav
and are sensitive to surface perturbation. Distance field
algorithms can also efficiently extract skeletons. They first
determine the distance for each voxel to its nearest boundary
and then obtain the skeleton from those ridges. With results
similar to thinning methods, the extracted skeletons are not
always smooth and are also sensitive to noise.
In order to compute smooth skeletons from various
models, some researchers propose potential field algorithms,
whichalsocomputeavalue foreachvoxel.Whendetermining
the field, they consider larger boundary areas, rather than just
the closest boundary voxel. This strategy avoids tiny differ-
ences on the model’s surface, and therefore, the extracted
skeletons are smooth and insensitive to noise. However, the
algorithms suffer fromheavy computation since determining
the field of an interior voxel takes into account many
boundary voxels, which may result in an Oðn2Þ computation
cost, where n represents the number of voxels.
Some methods extract skeletons by computing the
medial axis. However, there is a common problem with
these algorithms. They do not directly extract thin skeletons
from 3D models because a large portion of the medial
surface has the same distance to the boundary. Therefore,
the postprocessing methods are needed. For instance, [14]
computes the medial geodesic function when defining the
center of a medial surface and erodes the faces to obtain a
thin skeleton. Their method extracts very good skeletons
from polyhedral models. However, the method suffers from
heavy computation since the shortest paths algorithm is
used to determine the geodesic distance.
In this paper, a volumetricmodel is considered as a graph.
There is also a connected edge between each 6-adjacent voxel
pair. By minimizing our proposed energy function, we
transform the graph into a thinner version, which briefly
represents the model’s shape. By applying the thinning
algorithm, the voxels on the shrunk model are then system-
atically removed to extract a 1D skeleton. Our algorithm
costs low computation because solving the objective function
and iteratively removing the boundary voxels are both
efficient. We utilize the efficiency and homotopy properties
of the thinning method but enhance its robustness against
noise and the smoothness of the extracted skeletons by using
this shrinking algorithm.
3 ALGORITHM
3.1 Overview
Our algorithm computes the skeletons from volumetric
models. The polyhedral models used in this paper are
first voxelized by using [16]. In addition, we consider the
two voxels connected if they share the same face (i.e.,
6-adjacency). In other words, the volumetric model is
represented as a graph, G ¼ fV;Eg, with nodes V and
edges E, whereV ¼ ½vT1 ;vT2 ; . . . ;vTk  and vi 2 <3 denotes the
position of the voxel center (Fig. 1). We classify the voxels
into two groups, one of which consists of the boundary
voxels @V and the other consisting of interior voxels
V @V. The interior voxels are inside the model, which
have six neighbors, while the boundary voxels are located
on the model’s surface. Initially, the edge lengths connecting
the neighboring voxels are the same (Fig. 2a). To transform
the original modelG to the shrunk modelG0, our algorithm
shortens the connected edges, as well as more closely retains
the boundary voxels @V to their original positions (Fig. 2b).
To implement this idea, we formulate the shrinking process
as an objective function and iteratively update voxel
positions. Thereafter, the thinning algorithm [32] is applied
to remove the boundary voxels of G0; the 1D skeleton
Sk  G0 is then obtained. In contrast to the skeleton
computed by directly thinning, our extracted skeleton is
smoother and closer to the model’s center (Fig. 2d).
3.2 Shrinking
Obviously, a skeleton is a 1D representation containing
zero volume. Based on this criterion, our goal is to extract
the model’s skeleton by reducing its volume. Our method
shrinks a model by contracting the edges between adjacent
voxels. However, homogeneously shortening edge lengths
results in only a smaller version of the original model and
repeating the same method merely contracts the model into
a point. To preserve the model’s geometry, we add forces
that pull the boundary voxels back to their original
positions, denoted as boundary constraints. These forces
can reduce the movement of boundary voxels and therefore
preserve the model’s features. Specifically, we illustrate this
idea in Fig. 3c. The shrunk model is represented in green,
and the forces that constrain the boundary voxels are
represented with blue lines. In this example, it is clear to see
that most of the forces pull the boundary voxels upward or
WANG AND LEE: CURVE-SKELETON EXTRACTION USING ITERATIVE LEAST SQUARES OPTIMIZATION 927
Fig. 1. The volumetric model is considered as a graph, and the
6-adjacency relationship is determined.
Fig. 2. System overview. (a) The original volumetric model. (b) The
shrunk model transformed by our algorithm. (c) By applying the thinning
method to the original model, the extracted skeleton is jagged and
deviates from the model’s center. (d) By applying the thinning method to
our shrunk model, a smooth and centered skeleton is obtained.
positions Vt and the contraction ratio ptij iteratively. Note
that the model’s (i.e., G) structure remains unchanged
during minimization. Therefore, it is not necessary to
factorize the constant matrix A in each iteration. Applying
backsubstitution to iteratively update the voxel positions
is very efficient. We demonstrate the timing statistics in
Table 1.
For the implementation detail, the shrinking process
starts by precomputing the Cholesky factorization of the
matrix ATA and then applying a back substitution to
solve V1 (i.e., V0 ¼ V is the voxel set of the original
model). In the beginning, we consider p0ij ¼ 0; our system
computes the new voxel set V1 according to this given
information. Further computations are performed by
recomputing the contraction ratios ptij and using them to
solve Vtþ1. This iterative solver shrinks the model to
achieve zero volume. We terminate the iteration when the
model is thin enough.
3.2.4 Stop Conditions
An iterative solver always needs a stop condition to
terminate the repeated process. Our shrinking method
stops when the shrinkage is close to zero. Therefore, we
define the degree of shrinkage by computing the edge
lengths before and after each step:
SðVtÞ ¼
P
fi;jg2E v
t
i  vtj


P
fi;jg2E v
0
i  v0j


v 2 V: ð6Þ
Obviously, the degree of shrinkage SðVtÞ decays when we
shrink the model. Furthermore, the first derivative of SðVtÞ
also decays at the same time, and the value close to 0
suggests that the model is thin enough and is difficult to
further shrink. We stop the shrinking process in this
situation. In this paper, the process is terminated when
@SðVtÞ is lower than  ( ¼ 0:01 in all of our experimental
results).
3.3 Iterative Thinning
We apply [32] when simplifying the shrunk model to a
1D skeleton. This method repeatedly removes boundary
voxels by using its 26-adjacent connectivity. We record
this connectivity before applying the shrinking algo-
rithm. Since only the voxel positions are moved during
the shrinking process, the connectivity of G and G0 are
the same. By applying the thinning algorithm on the
two models, we can obtain skeletons with the same
structures; only their appearances are different. Although
applying the thinning algorithm to simplify the original
model would result in jagged and unsmooth skeleton,
applying the same method to our shrunk model would
not have this problem. This is because the voxels are
transferred to better positions. As for preserving the
model’s topology, Pala´gyi and Kuba have developed
14 masks and 12 directions to test if the boundary voxel
can be removed or not. Our iterative thinning also
enjoys this advantage due to their contributions. In this
paper, the voxels remaining after the thinning algorithm
are considered skeleton nodes.
The positions of the skeleton nodes change during the
shrinking algorithm. Thus, we must connect nodes via their
edges. Otherwise, they are only meaningless points
(Fig. 4a). However, we cannot simply assume that the two
skeleton nodes are connected if there exists a 26-adjacency
between them; otherwise, the incorrect tiny loop with three
edges would be potentially created after the edge connec-
tion (Fig. 4b). This mistake results from the ambiguous
relationship of the thinned skeleton. For instance, in Fig. 5,
the connectivity represented by red dotted lines produces a
tiny three-edge loop, and the edges should not be all
connected, although the nodes are adjacent. In this paper,
we remove the loops with only three edges to overcome this
problem.1 We test if this connection causes a 3-edge cycle
before it is added to the skeleton. The test is quite simple
WANG AND LEE: CURVE-SKELETON EXTRACTION USING ITERATIVE LEAST SQUARES OPTIMIZATION 929
TABLE 1
Parameters, Model Information, and Timing Statistics (Seconds)
1. It is possible to remove some very small and important loops. We can
choose a smaller voxel size to avoid this problem. In this manner, any legal
loop is represented in more detail with more edges and thus would not be
deleted.
test the robustness of our method, we also add 20 percent
noise to each model and compare the results with the
skeletons extracted from the original model. We compute
the Peak Signal to Noise Ratio (PSNR) to determine the
similarity of the skeletons of the model and the correspond-
ing model with noise. For example, in the triceratops model,
the PSNR value of its two skeletons is 64.62. In our
experiments, the value of PSNR is between 50 and 60 since
the skeletons are extracted from different models. In
addition to noise, we also apply our algorithm to different
poses of the same model. For example, in Fig. 10, we
determine the curve skeletons of the kicking dinosaur and
then obtain similar skeletons. This property will be useful in
3D model retrieval applications and will potentially allow
for the retrieval of similar models with different poses
based on the skeletons extracted using our algorithm. Our
algorithm can also deal with the thin plate and degenerated
models. Results are shown in Fig. 8.
We have implemented our algorithm in C and have run it
on a Pentium 4 3.4-GHz PC.We solve the linear system using
theCholeskey solver providedby theTaucs library [38]. Since
factorizing the ATA matrix can be precomputed, each
shrinking iteration needs only a back substitution. Thus, the
total runtime in each of our experimental result takes only a
few seconds. The factorization step takes the most computa-
tion time in our algorithm, which depends on the number of
voxels andconnectededges. Inourexperiment, it takesnearly
50 percent of the total runtime. We show the model
information, as well as their detailed timing statistics, in
Table 1.
4.2 Parameters
There are two major parameters required in our algo-
rithm, including 1) the weighting factor ! used in (3), and
2) the stop condition  that terminates the shrinking
process. Both parameters vary between 1.0 and 0.0. In
general, the larger ! enhances the system when shrinking
the model in the correct direction and more closely
preserves the skeleton to the model’s center. However,
in this manner, the speed of shrinkage becomes slower
with the completion of each step, and the iterative solver
requires more iterations to shrink the object. The stop
condition  determines how thin the shrunk model can
be; the thinner model enhances the smoothness of the
extracted skeleton. Similar to !, the lower  demonstrates
the better results but increases computations. Fig. 11
shows the influence of different ! and  when obtaining
results. Obviously, the extracted skeletons are similar,
although different parameters are given. In our experi-
ment, we found that ! ¼ 0:3 and  ¼ 0:01 can adequately
balance the quality, as well as the computation cost. We
use these two values in most of our experimental results.
4.3 Properties
The skeletons extracted using our algorithm are thin and
connected. Our algorithm enjoys the same advantages as the
thinning method, since we apply the method to remove
boundary voxels. In addition, the skeletons are smooth,
although we still apply the thinning algorithm. This is
because the energy function EQ shortens the edge lengths
and straightens each part of the skeleton. Therefore, the
skeleton extends without unnecessary turns and becomes
smoother. In this paper, we consider a curve smooth if the
curvature of each interval is similar. To evaluate the
smoothness of our skeleton, a measure function is proposed.
We accumulate the magnitude of curvature variations
between each pair of adjacent nodes, and use the value to
indicate if the curve is smooth or not. In addition, we
normalize this value so as to make the measurement
independent of the model size. Obviously, the smaller value
means smaller variations and, therefore, a smoother curve.
To implement this idea, we introduce the following formula:
Smoothness ¼ 1
L
X
fi;jg2H
jki  kjj;
where ki ¼
X
j2MðiÞ
ni  nj
jni  njj ; n 2 N;
ð7Þ
WANG AND LEE: CURVE-SKELETON EXTRACTION USING ITERATIVE LEAST SQUARES OPTIMIZATION 931
Fig. 8. The skeletons extracted from the thin plate and sphere models.
Fig. 7. The skeleton looks clean since the redundant branches are much shorter than before. However, we still have to prune the unnecessary
branches to obtain a good structure. (a) The tiny branches on the tap. (b) The redundant branches are pruned by our algorithm.
computing potential fields can extract clean and smooth
skeletons. However, the computational complexity of
these methods are Oðn2Þ, where n is the number of
voxels that need more time to extract skeletons from
larger models. In addition, they miss the brontosaur’s tail
and have many branches located at the rabbit’s ear. As for
the thinning method, although the algorithm is very
efficient, the extracted skeletons are not smooth enough,
since the algorithm is sensitive to noise. In addition, the
skeleton found by the distance field method contains
WANG AND LEE: CURVE-SKELETON EXTRACTION USING ITERATIVE LEAST SQUARES OPTIMIZATION 933
Fig. 12. We compare our algorithm with the algorithm presented in [14]. Although both methods extract good skeletons, [14] is sensitive to the input
parameter. In contrast to that in Fig. 11, our algorithm is much more stable since the different parameters have far less influence on the results.
Fig. 11. This figure shows the results with different ! and . Obviously, the extracted skeletons are similar in appearance. The results are insensitive
to input parameters.
REFERENCES
[1] N. Amenta, S. Choi, and R.K. Kolluri, “The Power Crust,” Proc.
Sixth ACMSymp. SolidModeling and Applications (SMA ’01), pp. 249-
266, 2001.
[2] G. Aujay, F. Hetroy, F. Lazarus, and C. Depraz, “Harmonic
Skeleton for Realistic Character Animation,” Proc. ACM SIG-
GRAPH/Eurographics Symp. Computer Animation (SCA ’07), pp. 151-
160, 2007.
[3] S.R. Aylward and E. Bullitt, “Initialization, Noise, Singularities
and Scale in Height Ridge Traversal for Tubular Object Centerline
Extraction,” IEEE Trans. Medical Imaging, vol. 21, no. 2, pp. 61-75,
2002.
[4] S.R. Aylward, J. Jomier, S. Weeks, and E. Bullitt, “Registration
and Analysis of Vascular Images,” Int’l J. Computer Vision, vol. 55,
no. 2-3, pp. 123-138, 2003.
[5] G. Bertrand and Z. Aktouf, “A 3D Thinning Algorithm Using
Subfields,” Vision Geometry. SPIE, pp. 113-124, 1994.
[6] J. Bloomenthal, “Medial-Based Vertex Deformation,” Proc. ACM
SIGGRAPH/Eurographics Symp. Computer Animation (SCA ’02),
pp. 147-151, 2002.
[7] S. Bouix and K. Siddiqi, “Divergence-Based Medial Surfaces,”
Proc. Sixth European Conf. Computer Vision (ECCV ’00), pp. 603-618,
2000.
[8] J.W. Brandt and V.R. Algazi, “Continuous Skeleton Computation
by Voronoi Diagram,” CVGIP: Image Understanding, vol. 55, no. 3,
pp. 329-338, 1992.
[9] A. Brennecke and T. Isenberg, “3D Shape Matching Using
Skeleton Graphs,” Proc. Simulation and Visualization Conf.
(SimVis ’04), pp. 299-310, 2004.
[10] J.-H. Chuang, C.-H. Tsai, and M.-C. Ko, “Skeletonization of
Three-Dimensional Object Using Generalized Potential Field,”
IEEE Trans. Pattern Analysis and Machine Intelligence, vol. 22,
no. 11, pp. 1241-1251, Nov. 2000.
[11] N.D. Cornea and P. Min, “Curve-Skeleton Properties, Applica-
tions, and Algorithms,” IEEE Trans. Visualization and Computer
Graphics, vol. 13, no. 3, pp. 530-548, May/June 2007.
[12] N.D. Cornea, D. Silver, and P. Min, “Curve-Skeleton Applica-
tions,” Proc. IEEE Visualization Conf. (VIS ’05), p. 13, 2005.
[13] N.D. Cornea, D. Silver, X. Yuan, and R. Balasubramanian,
“Computing Hierarchical Curve-Skeletons of 3D Objects,” The
Visual Computer, vol. 21, no. 11, pp. 945-955, 2005.
[14] T.K. Dey and J. Sun, “Defining and Computing Curve-Skeletons
with Medial Geodesic Function,” Proc. Symp. Geometry Processing,
pp. 143-152, 2006.
[15] H. Edelsbrunner, D. Letscher, and A. Zomorodian, “Topological
Persistence and Simplification,” Proc. 41st Ann. Symp. Foundations
of Computer Science (FOCS ’00), p. 454, 2000.
[16] S. Fang and H. Chen, “Hardware Accelerated Voxelization,”
Computers and Graphics, vol. 24, no. 3, pp. 433-442, 2000.
[17] N. Gagvani and D. Silver, “Parameter-Controlled Volume Thin-
ning,” CVGIP: Graphical Models and Image Processing, vol. 61, no. 3,
pp. 149-164, 1999.
[18] N. Gagvani and D. Silver, “Animating Volumetric Models,”
Graphical Models, vol. 63, no. 6, pp. 443-458, 2001.
[19] T. He, L. Hong, D. Chen, and Z. Liang, “Reliable Path for
Virtual Endoscopy: Ensuring Complete Examination of Human
Organs,” IEEE Trans. Visualization and Computer Graphics, vol. 7,
no. 4, pp. 333-342, Oct.-Dec. 2001.
[20] L. Hong, S. Muraki, A. Kaufman, D. Bartz, and T. He, “Virtual
Voyage: Interactive Navigation in the Human Colon,” Proc.
SIGGRAPH ’97, pp. 27-34, 1997.
[21] A. Kanitsar, D. Fleischmann, R. Wegenkittl, P. Felkel, and
M.E. GrLoller, “CPR: Curved Planar Reformation,” Proc. IEEE
Visualization Conf. (VIS ’02), pp. 37-44, 2002.
[22] A. Kanitsar, R. Wegenkittl, D. Fleischmann, and M.E. GrLoller,
“Advanced Curved Planar Reformation: Flattening of Vascular
Structures,” Proc. IEEE Visualization Conf. (VIS ’03), pp. 43-50,
Oct. 2003.
[23] S. Katz and A. Tal, “Hierarchical Mesh Decomposition Using
Fuzzy Clustering and Cuts,” Proc. SIGGRAPH ’03, pp. 954-961,
2003.
[24] F. Lazarus and A. Verroust, “Level Set Diagrams of Polyhedral
Objects,” Proc. Fifth ACM Symp. Solid Modeling and Applications
(SMA ’99), pp. 130-140, 1999.
[25] T.-Y. Lee, C.-H. Lin, H.-K. Chu, Y.-S. Wang, S.-W. Yen, and
C.-R. Tsai, “Mesh Pose-Editing Using Examples,” Computer
Animation Virtual Worlds (COMPUTER ANIMATION and SOCIAL
AGENTS ’07), vol. 18, nos. 4-5, pp. 235-245, 2007.
[26] T.-Y. Lee, Y.-S. Wang, and T.-G. Chen, “Segmenting a Deforming
Mesh into Near-Rigid Components,” The Visual Computer, Proc.
Pacific Conf. Computer Graphics and Applications (Pacific
Graphics ’06), vol. 22, no. 9, pp. 729-739, 2006.
[27] F.F. Leymarie, “Three-Dimensional Shape Representation via
Shock Flows,” PhD dissertation, Division of Eng., Brown Univ.,
May 2003.
[28] X. Li, T.W. Toon, and Z. Huang, “Decomposing Polygon Meshes
for Interactive Applications,” Proc. Symp. Interactive 3D Graphics
(I3D ’01), pp. 35-42, 2001.
[29] C.-H. Lin and T.-Y. Lee, “Metamorphosis of 3D Polyhedral
Models Using Progressive Connectivity Transformations,” IEEE
Trans. Visualization and Computer Graphics, vol. 11, no. 1, pp. 2-12,
Jan./Feb. 2005.
[30] P.-C. Liu, F.-C. Wu, W.-C. Ma, R.-H. Liang, and M. Ouhyoung,
“Automatic Animation Skeleton Construction Using Repulsive
Force Field,” Proc. 11th Pacific Conf. Computer Graphics and
Applications (PG ’03), p. 409, 2003.
[31] C.M. Ma and M. Sonka, “A Fully Parallel 3D Thinning Algorithm
and Its Applications,” Computer Vision and Image Understanding,
vol. 64, no. 3, pp. 420-433, 1996.
WANG AND LEE: CURVE-SKELETON EXTRACTION USING ITERATIVE LEAST SQUARES OPTIMIZATION 935
Fig. 16. In this figure, there are two volumetric models with different voxel sizes. (a) The distances between the fingers are smaller than the voxel
size; the represented fingers are all connected together, and thus, only one branch is extracted from the four fingers. (b) The voxel size is small
enough to separate the fingers; thus, the finger branches can be extracted. (a) Voxel size ¼ 0:05. (b) Voxel size ¼ 0:005.
ACM Reference Format
Chu, H., Hsu, W., Mitra, N., Cohen-Or, D., Wong, T., Lee, T. 2010. Camoufl age Images. 
ACM Trans. Graph. 29, 4, Article 51 (July 2010), 8 pages. DOI = 10.1145/1778765.1778788 
http://doi.acm.org/10.1145/1778765.1778788.
Copyright Notice
Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted 
without fee provided that copies are not made or distributed for profi t or direct commercial advantage 
and that copies show this notice on the fi rst page or initial screen of a display along with the full citation. 
Copyrights for components of this work owned by others than ACM must be honored. Abstracting with 
credit is permitted. To copy otherwise, to republish, to post on servers, to redistribute to lists, or to use any 
component of this work in other works requires prior specifi c permission and/or a fee. Permissions may be 
requested from Publications Dept., ACM, Inc., 2 Penn Plaza, Suite 701, New York, NY 10121-0701, fax +1 
(212) 869-0481, or permissions@acm.org.
© 2010 ACM 0730-0301/2010/07-ART51 $10.00 DOI 10.1145/1778765.1778788 
http://doi.acm.org/10.1145/1778765.1778788
Camouflage Images
Hung-Kuo Chu† Wei-Hsin Hsu† Niloy J. Mitra? Daniel Cohen-Or§ Tien-Tsin Wong‡ Tong-Yee Lee†
†National Cheng Kung Univ., Taiwan ?IIT Delhi §Tel Aviv Univ. ‡The Chinese Univ. of Hong Kong
Figure 1: Two camouflage images produced by our technique. The left and right images have seven and four camouflaged objects, respectively,
at various levels of difficulty. By removing distinguishable elements from the camouflaged objects we make feature search difficult, forcing the
viewers to use conjunction search, a serial and delayed procedure. (Please zoom in for a better effect. Answer keys are on the last page.)
Abstract
Camouflage images contain one or more hidden figures that remain
imperceptible or unnoticed for a while. In one possible explanation,
the ability to delay the perception of the hidden figures is attributed
to the theory that human perception works in two main phases: fea-
ture search and conjunction search. Effective camouflage images
make feature based recognition difficult, and thus force the recog-
nition process to employ conjunction search, which takes consid-
erable effort and time. In this paper, we present a technique for
creating camouflage images. To foil the feature search, we remove
the original subtle texture details of the hidden figures and replace
them by that of the surrounding apparent image. To leave an ap-
propriate degree of clues for the conjunction search, we compute
and assign new tones to regions in the embedded figures by per-
forming an optimization between two conflicting terms, which we
call immersion and standout, corresponding to hiding and leaving
clues, respectively. We show a large number of camouflage images
generated by our technique, with or without user guidance. We have
tested the quality of the images in an extensive user study, showing
a good control of the difficulty levels.
1 Introduction
Camouflage image, also referred to as hidden image, is an instance
of recreational art. Such an image contains one or more hidden
figures, or foregrounds, that are typically embedded into a busy ap-
parent image, or background, and remain imperceptible for a while.
It takes targeted effort and conscious focus from the viewer to detect
the hidden figures. Figure 1 shows two camouflage images gener-
ated using our algorithm.
The ability of hiding is closely related to how human perception
works. A possible explanation is the feature integration theory, orig-
inally proposed by Anne Treisman [1980]. It suggests that human
vision and perception work in two main phases: feature search and
conjunction search [Treisman 1988; Wolfe 1994]. Feature search,
a largely parallel phase, looks out for characteristic entities like
color, edge, texture for quick and instantaneous characterization of
figures. In contrast, conjunction search is a serial and slow process,
and is responsible for recognition and classification by integrating
(scattered) clues from multiple features.
In other words, camouflage images intelligently foil our feature
Figure 2: Artist created camouflage images: (left) 15 eagles, and
(right) 14 wolves ( c© 2010 Steven Michael Gardner. All rights re-
served, http://gardnergallery.com/).
ACM Transactions on Graphics, Vol. 29, No. 4, Article 51, Publication date: July 2010.
quantization,
segmentation
quantization,
segmentation
luminance
assignment
texture
synthesis
database
generation
refinement
Figure 4: System overview.
a texture painting system to combine strokes of texture and pro-
duce natural-looking boundary effects. Although texture synthesis
techniques provide simple means to immerse and hide figures, they
cannot easily control the recognition difficulty. Naïve application
of texture synthesis results in obvious-to-recognize camouflage im-
ages as demonstrated in Figure 3.
3 Overview
The main task in generating a camouflage image is hiding a fore-
ground figure, while maintaining some degree of its recognition.
Our approach is to remove features that allow fast recognition (fea-
ture search) and retain other features for slow recognition (con-
junction search). Figure 4 overviews the workflow and main com-
ponents of our camouflage image synthesis. It involves two major
goals, leaving clues for conjunction search while foiling the feature
search (from left to right).
Any texture distinction between the foreground and background
supports fast recognition. Thus, to foil the feature search, we take
away the original texture details from the embedded foreground
and replace them with the texture details from the background im-
age. To this end, texture synthesis is adopted, however, care must
be taken to preserve the features that are essential to conjunc-
tion search. We propose a tailor-made two-stage texture synthesis
scheme for subtle modifications of edge features. First, to help in
preserving the essential edge features, we build a scaffold along the
major edge structure of the embedded figure, by copying texture
samples with similar edge statistics from the background. Then, we
fill in the interior regions using standard texture synthesis.
Palmer [1999] reported that (partial) information carried by only
the luminance channel provides sufficient visual cues for a range of
recognition tasks. This is also evidenced by our ability to identify
objects in grayscale cartoons. The rough luminance distribution is
obtained by quantizing and segmenting the grayscale foreground
into multiple segments. To introduce control over the recognition
difficulty, we assign new tones to these segments by optimizing
an objective function of two terms, immersion and standout. The
former immerses the foreground into the background by choosing
luminance values that are close to the luminance distribution of
background. The latter distinguishes the foreground by preserving
the original luminance distribution of foreground. We formulate this
tone assignment as a multi-label graph cut on a graph constructed
from the images.
4 Algorithm
Given a background image IB and a foreground object image IF with
its desired position and orientation in IB, our algorithm embeds and
camouflages IF into IB at a controllable level of recognition diffi-
culty. Here, we describe the key steps of our algorithm in detail
(see Figure 4).
Luminance assignment. We retain the rough luminance distri-
bution of foreground as the clue for conjunction search. The lu-
minance distribution is obtained by grayscale-conversion, quanti-
zation, and segmentation of the foreground. This gives us a set of
segments of different luminance values. Similarly, we obtain the lu-
minance distribution of the background image. With these segments
as containers and luminance values as the intensity guide, we can
already dress up the foreground segments by the texture details of
background segments using standard texture synthesis. However,
the foreground and the background may have substantially differ-
ent luminance distributions, that lead to trivial recognition. To re-
move this distinction, we can re-color the foreground segment map
with the luminance distribution from the background (immersion).
A naïve replacement of luminance distribution, on the other hand,
can completely hide the foreground, and make it unrecognizable. In
other words, we need to make the foreground standout by preserv-
ing its original luminance distribution (standout). Hence we aim for
a balance between two conflicting factors: immersion, which mea-
sures the similarity of luminance distribution between IF and IB, and
standout, which measures the deviation from the original luminance
distribution of foreground IF . We optimize an objective function of
these two terms on a graph constructed from the foreground and
background segment maps.
Quantization and segmentation: The images are quantized based
on their luminance values, and segmented into connected seg-
ments using a simple flood-fill algorithm. The background seg-
ments are cropped by foreground in overlapped regions. We de-
note the resulting segmented foreground and background images as
QF = {qFi |i = 1, . . . n} and QB = {qBi |i = 1, . . .m}, where qFi and
qBi represent connected segments in IF and IB, respectively. Notation
qi is used to denote a segment, in general. Let LF = {lFi |i = 1, . . . n}
and LB = {lBi |i = 1, . . .m} be the luminance values of the corre-
sponding segments.
Graph construction: Next, we construct a graph G = (V,E) where
the nodes V correspond to the segments in QF ∪ QB. Two nodes qi
and q j are connected by an edge ei j ∈ E, if either of the follow-
ing is true: (1) both qi, q j ∈ QF and they share a partial boundary,
or (2) qi ∈ QF , q j ∈ QB and q j ∈ N(qi) where N(qi) represents
k-nearest neighbors∗ of qi (in all our experiments, we set k = 6).
The edges ei j are respectively called standout edges and immersion
edges. The luminance values li are kept in the corresponding nodes.
Values lBi of nodes corresponding to segments QB are known. To
camouflage the foreground into background, our goal is to assign
∗ The k-nearest neighbors are computed based on the closest Euclidian
distance between two segments in a camouflage image.
Camouflage Images       •       51:3
ACM Transactions on Graphics, Vol. 29, No. 4, Article 51, Publication date: July 2010.
optimize
optimize
Figure 7: Effect of adding distracting background segments posterior to luminance optimization. (Top row, Left to right) Segment map LF ,
optimized segment map L′F , distracting background segments DB, superimposed image S using L
′
F and DB, and camouflage synthesis result
using S. (Bottom row, Left to right) Segment map, distracting background segments, superimposed image, luminance optimized segment and
resultant camouflage synthesis result.
progressively fill in texture patches along the boundary, subsequent
foreground query patches have a higher chance of non-emptiness.
To handle empty query patches, we set α = 1.0 when tFq is empty;
otherwise α = 0.7, i.e., when the query lacks any texture informa-
tion, only the segment map distance is considered. In our imple-
mentation, we realize the function D using the sum of normalized
squared distances (SSD) between two patches (full region for si and
partial region for ti). The texture distance is evaluated in the CIELab
color space.
Synthesizing segment interiors: After building the scaffold along
segment boundaries, we progressively fill up the interior. Using
the luminance information from the optimized foreground segment
map, we fill the foreground interior by growing texture from the tex-
tured boundary. We copy texture samples from the background us-
ing texture-by-numbers techniques [Hertzmann et al. 2001]. Over-
lapping textures are seamlessly combined by finding an optimized
cut path [Kwatra et al. 2003].
Both stages of synthesis require working with large collections of
patches in the database, typically 30K-300K. In our experiments,
we use patches of size 7 × 7 leading to large set of vectors of 49
dimensions. A naïve search is slow for interactive applications. To
speed up, we reduce the search vector dimensionality by a princi-
pal component analysis (PCA) based subspace learning, retain the
eigen coefficients with top 80% energy, and use them to k-mean
cluster the database into around 1,000 clusters. This leads to about
5-10 times of speedup without any noticeable visual artifact in the
synthesized results. Alternatively, it is possible to speed up with
GPU-accelerated Gaussian KD-trees [Adams et al. 2009].
5 Enhancements and User Control
We now present additional controls to improve the results using
subtle modifications, and also help the user to better explore, com-
pose, and create camouflage images.
Adding distracting segments. We increase the difficulty level
of the generated hidden figures by adding additional segments to
the luminance-optimized segment map of foreground. Specifically,
before the synthesis phase, we add some distracting segments by
randomly copying background segments that are either completely
or partially overlapped with the foreground and pasting them to
the luminance-optimized segment map. These segments help to
break the original boundary of foreground segments, making fea-
ture search harder. As an undesirable side effect, this random copy-
and-paste approach may also disturb critical features such as the
eyes and nose of the foreground figure. To prevent this problem,
we provide the user a brush tool to indicate critical foreground
regions. Subsequently, the system avoids pasting over the marked
critical segments. In Figure 7, we used the brush tool in regions
around lion’s eye. We added distracting segments to most of our re-
sults using the same default setting. Specifically, we added filtered
segments in ratios 0.5, 0.8, 1.0 for easy, medium, hard difficulty
levels, respectively. For any hidden figure in a scene, distractors for
easy (setting) are a subset of those of medium, which in turn are a
subset of those of hard. Although the distractors can be embedded
prior to luminance optimization, as a design choice we decoupled
the two stages making the system to be interactive, allowing fine
tuning the amount of distractors. In our experiments we observed
that for fixed margin of distractors, prior and posterior optimization
produce comparable results since the long and thin segments do not
significantly influence the optimization(see Figure 7). However, at
difficult setting, noticeable difference starts appearing due to the
larger-area segments.
Background warping. When the user places the foreground fig-
ure near the boundary of the background object, e.g. the contour
of mountain, parts of the foreground may protrude out unnaturally,
revealing the hidden object. We automatically detect such contour
segments with high curvature variation, and then blend them in by
warping the background border to fit the figure contour using subtle
modifications as proposed by Schaefer et al. [2006] (see Figure 9).
Embedding location search. In our system, we leave the user the
final control of positioning the foreground figure. However, to aid
the process, we provide two simple search mechanisms for local
and global placement of the object. In the local mode, we refine
the initial user-specified position by determining the translation and
rotation that minimizes the energy function in Equation 3. In our
implementation, we constrain the translation to ±1% of the image
diagonal length along x and y directions, while the angle is con-
Camouflage Images       •       51:5
ACM Transactions on Graphics, Vol. 29, No. 4, Article 51, Publication date: July 2010.
Figure 11: Comparison of synthesized results (right) with artist
generated ones (left) (top: c© 2010 Steven Michael Gardner; middle
and bottom: c© 2010 John Van Straalen. All rights reserved.).
reduce fatigue after 4 scenes the users were given a short break. The
recognition times were recorded counting from when the image is
shown until the time when the user started typing what they saw.
Figure 10 shows the average recognition times and success rate
against difficulty levels. When the participant successfully identi-
fied an image, we assume that he/she would have also identified the
easier versions. If the user instead of asking for another chance gave
a wrong answer, we assume that he/she would have also failed with
the easier versions (in absence of a better way to guess, we take
a conservative option). We hypothesize that our method can effec-
tively control the difficulty level of produced camouflage images.
Using a single factor ANOVA analysis with α = 0.05, we obtain
p-values as 3e−5 and 0.0028 for recognition time and success rate,
respectively, thus verifying our hypothesis.
User study II: comparison with camouflage artwork. In order
to get some feedback about the quality of the generated camou-
flages images, we showed a set of 30 participants 10 camouflage
images, 5 of ours and 5 from artists, in random order. Users had no
prior knowledge about the source of the images and were asked to
rate each image, on a scale of 1 to 5, depending on how natural,
seamless, and engaging they found the hidden objects to be. It is
very encouraging that our computer-generated camouflage images
received an average score of 4.23 comparable to artists’ 4.21 among
all participants, i.e., comparable within error margins. Figure 11
shows some images used in this user study. This study indicates that
our algorithm consistently provides reasonable to good camouflage
images starting from user provided foreground-background image
image res. # fig. optimize PCA,k-mean synthesis
2 dogs, 2 cats 383 x 383 4 0.47 5.85 3.05
2 lions 921 x 949 2 1.46 27.3 110
4 eagles 371 x 371 4 0.21 4.36 1.61
Africa wild life 561 x 561 4 0.65 10.07 6.1
2 eagles 531 x 531 2 0.54 13.8 11.3
1 deer, 3 goats 467 x 497 4 0.62 6.06 8.13
Table 1: Timing of generating camouflage images in Figure 8. The
timings, in seconds, are averaged over all hidden figures.
pairs. The system is easy to use, and suitable for amateurs.
Limitations. A main component of our algorithm is based on
the optimized luminance assignment. It may fail to hide the fore-
ground when the luminance contrast of foreground is fairly low.
The foreground may be re-colored with very similar luminance val-
ues and hence similar textures from background, resulting in either
complete immersion or complete standout (see Figure 12). Inter-
estingly, we found that artists rarely embed low-contrast figures
in their camouflage pieces. Another restriction is that embedded
figures produce unsatisfactory results across regions with distinc-
tive texture and orientations, e.g. across mountains and sky since
the boundary often becomes obvious. In cases when embedded fig-
ures are placed slightly across two very different regions, we use
background warping to reduce this problem. Finally, our synthesis
algorithm cannot guarantee the physical correctness of illumina-
tion in the synthetic foreground, which may lead to inconsistency
between the foreground and background, specially in presence of
strong shadows.
7 Conclusion and Future Work
Camouflage images can be fascinating and entertaining as they
challenge viewers to consciously focus to detect the hidden fig-
ures. We presented a novel approach to synthesize such images
at controllable levels of difficulty. Our user study indicates that
the approach can consistently produce results at a level where the
viewer can locate embedded figures with focused attention, but not
immediately. Although we can create many promising results, our
approach is not positioned as a substitute for artists, whose cre-
ativity and imagination is invaluable, and unlikely to be replaced
computationally. However, we believe that it can be an effective
tool for amateurs to create camouflage images as well as for skillful
artists for initial design of their artpieces, thereby reducing their
production time.
Interesting future work waits to be explored. For example, some
artists explore shadows to foil our feature search mechanism. We
plan to investigate shape from shading algorithms for obtaining
2.5D information of foreground and background images, leading
to shadow based camouflage effects. Recently, Mitra et al. [2009]
Figure 12: Limitation: Low contrast foreground image. Left-top:
original image. Left-bottom: optimized segment map. Right: the re-
sultant image.
Camouflage Images       •       51:7
ACM Transactions on Graphics, Vol. 29, No. 4, Article 51, Publication date: July 2010.
 
中 華 民 國 98 年 09 月 01 日 
 
 
報告人姓名  李同益 服務機構 
及職稱 
成功大學資訊系 
時間 
訪問 
地點 
98. 08/27 
~08/30 
香港  
The Chinese 
University of 
Hong Kong 
 
Hong Kong 
University of 
Science & 
Technology 
 
City 
University of 
Hong Kong), 
 
本會核定 
補助文號 
 
國科會計劃 
 
97-2628-E-006-125-
MY3  
 97年度: 國外差
旅費 
 
 
 
 
 
 1
 3
 2009/08/30  結束訪問行程，午後返抵台灣。 
 
三、參訪心得與建議事項 
本人(計畫主持人)與黃田津教授、戴秋蘭教授與傅紅波教授近兩年已
在國際頂級期刊(ACM TOG 、IEEE TVCG)與頂尖指標性國際研討會
(ACM SIGGRAPH ACM 、SIGGRAPH ASIA 與 IEEE Visualization 有
合作並共同發表論文的表現，質與量皆有不錯成績，加上實驗室間互
訪頻繁，值得我們繼續再深耕彼此合作，並藉由此管道與大陸名校接
觸與合作。此外，與區華明教授討論有關 Visualization Research 
TOPIC，區教授與本人皆為 IEEE 2008~ 2009 Visualization Technical 
Program Committee ，彼此非常熟識。 
 
此次參訪最大目標即與這幾位教授在 Computer graphics 資訊科技方
面的最近技術進行交流與合作， 期待未來能繼續與他(她)們進行合
作研究進行跨國際合作創新領域計畫，提昇我 Lab. Students’圖學領域
research 之國際觀與研究能量。與黃田津教授合作部分，已有較具體
討論項目與規劃，未來幾月內將以 Texture Synthesis 與 NPR 為 
topics 準備 SIGGRAPH 2010 paper submission。希望此項合作順利，
有不錯成績表現。 
 2 
APSIPA 2009 國際訊號資訊處理年會 
 (Asia-Pacific Signal and Information Processing Association 
2009 Annual Summit and Conference) 
 
一、 目的 
APSIPA 2009 是由 Asia-Pacific Signal and Information Processing 
Association委員會所主辦的首屆國際研討會，今年是第一屆標榜創新，
區域性與協助亞太弱勢國家的訊號資訊處理國際研討會。因為是首度
舉行，很多熟知知名學者參與如 :  IEEE Signal Processing 
President-Elected Prof. K. J. Ray Liu ，Tokyo Institute of Technology Prof. 
Sadaoki Furui與USC Prof. C.-C. Jay Kuo。參加本次會議目的主要1)了解
並加入Asia-Pacific Signal and Information Processing此主組織，2) 主持
人為一sub-track: computer graphics and visualization chair，必須與會與  
該sub-track論文發表者交流，由於不少國內學者參與此盛會，趁此機會
與他們進行學術交流。 
 
二、 過程 
本次會議從 2009/10/04 至 2009/10/07，本次大會，會場是座落在日本
北海道札幌市中心 Convention Center。本人(計畫主持人)從 2008/12/09
高雄小港機場搭長榮航空飛機，轉桃園中正國際機場，再轉北海道札
 4 
committee(TPC)，本人很 lucky 藉由廖弘源教授推薦因此有機會參與未
來 TPC 。此會議預料將由 Asia--Pacific 研究學者主導，在很多方面皆
有 EURASIP 影子只是規模較小。第一次舉辦缺點還不少: 如沒有提供
便利 shuttle bus 與場地不在同一地方，參與者必須數日跑不同地方，值
得下次改善。此次 technical paper 發表是最重要一項活動，今年來自不
少臺灣學者文章，真是少見。因此在休息時間，也能趁此機會經驗交
流，獲益良多。此外透過他們的介紹認識不少學者，有助於主持人加
強建構國際化學術交流與提升本實驗室競爭力。 
 
 
附錄 
最後，筆者參加此次會議，帶回了論文集 Abstract 一冊，由衷感謝補
助筆者參加 APSIPA 2009。 
 
22010國際繪圖研討會
(Computer Graphics International 2010)
一、 目的
Computer Graphics International (CGI) 2010是由Computer Graphics
Society (CGS)委員會所主辦的大型國際研討會，今年是第31屆，
Computer Graphics Society是電腦圖學領域少數歷史悠久國際研討會，
為水平不錯之國際電腦圖學研討會。參加本次會議目的主要是發表1篇
regular technical papers (oral presentation)，並訪問與本實驗室友好新加
坡大學學者Prof. .Tiow Seng Tan and Prof. Low Kok Lim，並參觀其實驗
室與進行學術交流。由於不少學者參與此盛會，趁此機會與他們進行
學術交流，並尋求合作機會。
二、 過程
本次會議從 2010/06/08 至 2010/06/11，本次大會，會場是座落在新加
坡 Nanyang Executive Centre (NEC) at the Nanyang Technological
University。本人(計畫主持人)與 1 名博士班研究生從 2010/06/08 高雄
小港機場搭華航飛機，直飛新加坡與會，本人並於 2010/06/12 深夜回
4approaches including blind, semi-blind, and non-blind detection schemes
cannot withstand the attack of pose editing, which is a very common
routine in 3D animation. In addition, the watermarked models can be
semi-reversed (i.e., the peak signal-to-noise ratio (PSNR) of the recovered
models is greater than 90dB in all experiments) in semi-blind detection
scheme. Experimental results show that this novel approach has many
significant advantages in terms of robustness and invisibility over other
state-of-the-art approaches
Fig. 1 The workflow of the proposed watermark embedding. (a) The
original model; (b) the significant patches (visualized by yellow); (c) the
sorting result of significant patches (the order is visualized by color starting
from red to yellow); (d) the watermarking result.
Technical full paper 發表是此次與會最重要一項活動，今年帶了 1 個博
士班學生與會，並由該生負責論文口頭發表，過程還順利。此外聽到
不少有趣 topics 並在會場與學者互相討論，使得這次的行程收穫更為
豐富，也對學生視野有所增廣。本次與會有不少大陸筆者認識學者參
加，在休息時間，也能趁此機會經驗交流，獲益良多。對岸學者當面
6行政院國家科學委員會補助國內研究生出席國際學術會議報
告
2010
年 8 月 2 日
報告人姓名 葉智國 就讀校院
（科系所）
■博士班研究生
國立成功大學 資訊所
□碩士班研究生
時間
會議
地點
2010/07/25~2010/07/29
美國 洛杉磯
本會核定
補助文號
NSC97-2628-E-006-125-MY3
會議
名稱
(中文) ACM SIGGRAPH 2010
(英文) ACM SIGGRAPH 2010
發表
論文
題目
無
8二、與會心得
這次為期七天的行程，雖然時間緊湊，還得來回調整時差，但透過這個機會，我還是很高興能夠
認識美洲地區，以及中國大陸地區許多優秀研究人員，尤其來自美國的優秀學者，藉此屆討論會
的機會，我與美國的優秀學者做實質討論。每一次出國參與會議，都可以讓我獲得不少新知，當
然這次也不例外。因為在會議裡可以和許多來自各地的學者交換意見，並且從中學習他們的研究
精神與態度。與會報告的論文，可以讓我在短時間內學習到很多不同的研究內容與方法，此次討
論會有來自世界各地的優秀研究人員，並且全程以英文來演說，獲益非淺。由衷感謝我有這麼一
個出國的機會。
三、考察參觀活動(無是項活動者省略)
無
四、建議
首先感謝國科會的補助，讓我在無經費顧慮下順利完成此次參與學術交流，藉此見識到國外專家
學者的研究。計算機圖學涵蓋資料視覺化包括網路流量、地理資訊系統、生物資訊、醫學影像、
流體等等，應用範圍相當廣。不過，在台灣很少人研究這個領域，如果台灣在這方面也能夠投入，
並將其技術引入各行各業裡，其實是個不錯的願景。希望國科會往後能提供更高額的補助獎金、
多鼓勵博士班與碩士班學生多參與重要國際會議，並多訓練英文能力，如此將吸引台灣有更多的
學者投入，並且在讓這個領域有更好的發展與應用。
五、攜回資料名稱及內容
無
六、其他
無
 2
 
2010 第十八屆太平洋電腦圖學會議 
 
 (Pacific Graphics 2010) 
 
一、 目的 
Pacific Graphics (PG) 2010是泛太平洋地區最重要的電腦圖學國際會
議，也是全球三大電腦圖學國際會議之一，此會議是與國際重要圖學
組織Eurographics合辦。參加本次會議主要目的是 (1)主持1 regular 
technical paper oral presentation section，(2)訪問浙江大學電腦輔助設計
與圖形學國家重點實驗室與進行學術交流，(3)討論Pacific Graphics (PG) 
2011由本人在臺灣主辦事宜。由於不少學者參與此盛會，趁此機會與
他們進行學術交流。 
 
二、 過程 
本次會議從 2010/09/25 至 2010/09/27，本次大會，會場是座落在大陸
杭州市浙江大學國際會議廳。本人(計畫主持人)從 2010/06/08 高雄小
港機場搭華信飛機，直飛杭州市與會，本人並於 2010/09/28 回國。此
次會議，有來自全世界，約 200 人來參加，學者有來自美國，歐洲，
亞洲大陸， 日本， 韓國，香港與台灣。來自臺灣學者除筆者外，還
 4
z 籌備委員會 
General Chair： 
國立成功大學     孫永年 教授 
Conference Co-chairs： 
University of Toronto       Prof. Eugene Fiume 
國立台灣大學             歐陽明教授 
Program Co-chairs：    
HTUniversity of North Carolina TH      Prof. Ming C. Lin 
University College London       Prof. Jan Kautz 
國立成功大學                李同益教授 
z PG 2011 會議預計收錄三十五篇的regular papers與 30 篇的poster 
papers，regular papers將刊登於 HJohn Wiley & Sons, Inc. H,所出版的
Computer Graphics Forum期刊（SCI, IF= 1.681）。 
 
附錄 
最後，筆者參加此次會議，帶回了論文集一冊，由衷感謝補助筆者參
加 PG2010 
 2 
 
2010 ACM國際繪圖亞洲年會 
 (2010 ACM SIGGRAPH Asia Annual Conference Series) 
 
一、 目的 
ACM SIGGRAPH Asia 2010是由ACM SIGGRAPH Committee委員會所
主辦的大型國際研討會，今年是第三屆，ACM SIGGRAPH Asia標榜與
在美國本土ACM SIGGRAPH一樣高水準的國際電腦圖學研討會。參加
本次會議目的主要是發表1篇regular technical paper (oral presentation)，
與本實驗合作學者為Prof. TT Wong。由於不少學者參與此盛會，趁此
機會與他們進行學術交流，並尋求合作機會。 
 
二、 過程 
本次會議從 2010/12/15 至 2010/12/18，本次大會，會場是座落在韓國  
首爾市中心 Convention Center。本人(計畫主持人)從 2010/12/15高雄小
港機場搭機，直飛韓國首爾市與會，本人並於 2010/12/18 回國。此次
會議，有來自全世界，約 4000 人來參加。此外扣除發表 paper 學者，
歐美人數並不多。 
 
如 ACM SIGGRAPH一樣大會有提供相關 CG產品之 Exhibition，相較
 4 
demonstrate how to reduce the artifact. To achieve practical resizing 
applications for general images, we developed a fast symmetry 
detection method that can detect multiple disjoint symmetry regions, 
even when the lattices are curved and perspectively viewed. 
Comparisons to state-of-the-art resizing techniques and a user study 
were conducted to validate the proposed method. Convincing visual 
results are shown to demonstrate its effectiveness. 
 
 
 
 
本次與會有些香港, 大陸筆者認識學者參加，在休息時間，也能趁此機
會經驗交流。此外透過他們的介紹認識不少學者，有助於主持人加強
建構國際化學術交流與提升本實驗室競爭力。。 
 
 
附錄 
最後，筆者參加此次會議，帶回了論文集一冊，由衷感謝補助筆者參
加 SIGGRAPH Asia 2010 
 
 2 
第八屆中國電腦圖形學大會(Chinagraph’2010) 
一、 目的 
本年Chinagraph’2010於10月13日至15日在南京大學舉行，此次會議由
中國電腦學會與南京大學電腦軟體新技術國家重點實驗室和南京大學
電腦科學與技術系承辦。Chinagraph是大陸最大Computer Graphics會
議。參加本次會議主要目的是受邀擔任作開幕特邀speaker，並趁此機
會與大陸學者與學生進行學術交流。此外會後於10月17日至20日至上
海參加Microsoft Faculty Summit 2010。 
 
二、 過程 
本次會議從 10 月 13 日至 15 日在南京大學舉行，本次大會，會場是座
落在南京大學國際會議室。本人(計畫主持人)從 2010/10/12 高雄小港
機場搭港龍航空飛機，轉香港國際機場，再轉南京市與會，本人會後
於 10 月 17 日至 20日至上海參加 Microsoft Faculty Summit 2010 並於
10/20回國。 
 
會議共有 6 場 paper sections 和 2 場 Poster session，包括：圖形基礎演
算法和繪製(rendering)、幾何處理和動畫、視覺化(visualization)、電腦
視覺與影像處理。並召開了兩場專題討論會以及 1 場為期一天的圖形
學學科發展前沿研討會，此外，有一場專為研究生之 Siggraph 之夜，
 4 
此次會議人員，大致上來自大陸主要大學，約 300~350 人來參加，國
內學者包括計畫主持人與台大資訊系歐陽明教授。本人觀察到大陸從
事 Computer Graphics 及相關領域研究的研究機構和人員不斷增加，研
究方向逐漸與世界接軌，有計畫性不斷拓展，研究水準亦在逐年提高，
值得我們學習與警惕！ 
 
 
附錄 
最後，筆者參加此次會議，帶回了論文集 Abstract 一冊，由衷感謝補
助筆者參加 Chinagraph 2010，此次來回機票由 Chinagraph2010 支付。 
 
97 年度專題研究計畫研究成果彙整表 
計畫主持人：李同益 計畫編號：97-2628-E-006-125-MY3 
計畫名稱：電腦繪圖三維網格參數化, 動態幾何圖, 貼圖技術與應用之研究 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 6 6 70% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 7 7 100%  
博士生 4 4 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 9 9 70%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
