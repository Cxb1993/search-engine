 2 
行政院國家科學委員會專題研究計畫成果報告 
以影像辨識導引 UAV 飛行之研究 
The Study of UAV Guidance using Image Recognition 
計畫編號：NSC 95-2221-E-006-180 
執行期限：85 年 8 月 1 日至 86 年 10 月 31 日 
主持人：陳世雄                國立成功大學航空太空工程研究所 
計畫參與人員：容丕達﹑楊一信   國立成功大學航空太空工程研究所 
 
一、中文摘要 
 
全球定位系統及慣性導航系統是最常用於作為無人飛行載具上之感測器，但它們
都依賴事先得知之任務目標座標資訊。本研究計畫目標為發展無人飛行載具所使用之影
像辨識系統，導引無人飛行載具自動飛行。 
     影像辨識系統是設計為尋找一個已知顏色及形狀的任務目標。當影像被攝影機拍
下來後會先以顏色來進行影像分割，將可能之目標與背景分離出來。接著各可能之目標
的不變矩會被計算，並與已知任務目標之不變矩作比較，決定影像中真正之任務目標之
所在。當任務目標被識別後，相關影像資訊可用於估測無人飛行載具與目標間之相對位
置及飛行姿態，並導引無人飛行載具作自動飛行。 
 
關鍵詞：無人飛行載具、影像辨識 
 
Abstract 
 
Global positioning system (GPS) and inertial navigation system (INS) are two of the 
mostly used sensors for automatic flight control of unmanned aerial vehicle (UAV). They 
both rely on pre-determined target coordinate information. In this research project an image 
recognition system for guiding an UAV is developed for terminal guidance. 
The image recognition system is designed to search and identify a mission target with 
known color and shape. The image captured by the camera is first segmented by color to 
isolate potential target candidates from background. Moment invariants of each target 
candidate are calculated later. These moment invariants are compared with those of 
predetermined target’s for identifying the target. Once the target is identified the image data 
will be used to estimate the relative position and then guide the UAV. 
 
Keywords: UAV, image recognition 
 
二、研究目的 
 
人類自發明飛行器開始，視覺就一直是飛行員駕駛飛行器時所最依賴的感官。飛行
員可以通過以肉眼尋找目標物而得知飛行器與目標物的相對位置，又可以通過以肉眼觀
察地平線而得知飛行器的姿態。人類在航空史上的多種航空儀器，其中大部份可以視為
飛行員視覺的延伸，例如無線電導航可以讓飛行員得知飛行器與視距外目標物的相對位
置，人工地平儀可以讓飛行員在無法目視地平線時得知地平線的狀態。 
     無人飛行載具與有人飛行載具相比較，具有體積較小、重量較輕、成本較低等特
點，此外由於沒有飛行員在載具上，所以適合執行高風險任務。無人飛行載具的操作一
 4 
三、影像辨認系統 
 
    影像辨認系統在應用上主要針對建築物或車輛等結構性目標，當攝影機由空中往下
拍攝時，無人機由不同方向接近目標物會在影像平面形成不同之二維投影，另外在不同
照明環境下，目標物或其他外界物件之陰影可能投射至目標物上，以上這兩項因素使偵
測物件邊緣後再確定其形狀的辨認方法困難度大增，因此本研究選用不變矩作為判別物
件形狀的特徵，而自背景中分離可能目標物候選人之方法則採用顏色作為判別的特徵。 
    本研究所使用之攝影機所拍得之影像為 320×240 解析度, 24 位元之 RGB 彩色影像，
由於 RGB 色彩空間無法直接與人類平常描述顏色之方式連結，因此先轉換成 HSV 色彩空
間，HSV 色彩空間以色相(Hue)、飽和度(Saturation)及明度(Value)描述顏色，再由影
像辨認系統對所拍得之影像之所有像素與已知目標顏色的色相、飽和度及明度範圍比
較，過濾掉顏色不符合的像素。在 HSV 色彩空間中心軸及圓錐尖端的位置為飽和度及明
度較低的位置，此一區塊不容易判別像素顏色，因此在過濾過程中會把處於此一區塊的
像素一併過濾。 
    當符合目標物顏色的像素被分離出來後，需先通過連接物件標記法(Connected 
Component Labeling)將互相連結的獨立像素標記為同一物件。本研究測試了
Haralick[19]所提出之交替式連接物件標記法及 Rosenfeld 與 Pfaltz[20]所提出之兩
次掃描連接物件標記法，測試場景包括圖 1 中的兩個場景，每一個場景分別用兩種標記
法進行 250 次計算，其運算時間之比較如表 1 所示，交替式連接物件標記法雖然掃瞄次
數容易隨物件複雜度提高而增加，運算時間較不穩定，但在測試結果中可見其運算時間
與兩次掃瞄連接物件標記法接近，這是由於經顏色過濾後之連接物件數量已大量減少且
預期目標物件大多為封閉圖形，交替式連接物件標記法的掃描次數才會與兩次掃描連接
物件標記法的掃描次數相近，由於演算法較簡單的交替式連接物件標記法比較不易在程
式撰寫上出現未預期之錯誤，因此選用交替式連接物件標記法。 
 
 
圖 1 連接物件標記法之測試場景 
 
    當各連接物件標記後，就可以計算其不變矩(Moment Invariant)，不變矩是由 Hu[21]
所提出，用以描述物體形狀，不受影像縮放、平移及旋轉所影響，不變矩共有七個，本
研究採用前四個用以描述目標物之形狀，其定義如下： 
 6 
 
圖 2 影像辨識系統程式介面 
 
 
圖 3 空中測試實驗器材配置 
 
    地上實驗及空中實驗所採用之目標物為 1.8 公尺×5.4 公尺大小之布旗，其上印有紅
色十字(圖 4)，測試方法為以影像系統於不同位置拍攝目標物之各畫面，然後記錄色相、
飽和度及不變矩之值，並比較在實際操作環境受雜訊及照明等變動因素影響下，320 組
影像中各值之變動性(表 2)，由表 2 可見各值在不同環境下其變動並不大，適合作為目
標辨識使用。影像辨識系統運算時間及各影像處理步驟運算時間可見圖 5，由圖中可見
影像處理計算部份平均每次需要 0.4 秒。 
 
 平均值 標準差 
Φ1 -0.32813 0.054374 
Φ2 -0.73112 0.126957 
Φ3 -3.00292 0.695183 
