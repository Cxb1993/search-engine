 3
中文摘要 
 
 積體電路製程精密度隨著時代演進而更加地複雜且新製程推出的速度越來越快，主要是因應市場
對高科技產品之強烈需求，如此一來也導致新製程的生命週期縮短！半導體生產屬於資本密集型產業
並藉由昂貴的設備進行冗長且複雜的反覆加工流程，各企業均致力於減短生產週期、生產高品質的產
品、準時達交、成本持續的降低和生產效率的改善以維持競爭優勢。本計畫以多年期的計劃，逐步建
立以國內高科技產業如半導體業、TFT-LCD 業的營運決策分析模式，以垂直整合製造策略、需求預測、
產能規劃與配置、生產力與效益分析的完整決策過程，將工業工程的分析方法和管理模式，由作業階
層往上整合至企業規劃與決策層，以創造新的工業工程典範和增加工業工程在企業中的價值。第一階
段將先以半導體產業為例，發展「製造策略」、「需求預測與規劃」、「產能規劃與配置」、「工廠營運績
效分析」，即生產力與效益分析、「公司營運決策分析（Corporate Operation Decision Analysis，CODA）
整合模式及其決策支援系統」五個模組。不確定性更明顯地導致製造與生產上的困難提高，而需求變
異擴大將進一步使得廠商必須承擔更高的庫存或資本投資料風險。因此本計畫成果可以在不確定性的
環境下掌握更多更準確的資訊或建構更穩健的策略模式，將可使公司在市場中保有堅強的持續競爭優
勢。 
 
關鍵字：策略性決策分析、營運決策、製造策略、需求預測、產能規劃與投資、半導體經濟、科技管
理、高科技產業、供應鏈 
 5
1. Introduction 
 Semiconductor manufacturing is an industry becoming more dynamic and changing faster in consumer 
era. Time to market and wafer fabrication cycle time are critical for maintaining competitive advantage for 
semiconductor manufacturing company. Therefore, time-to-market and cycle time reduction have become 
increasingly critical issues for both research and practice. According to Little’s Law, while maintaining the 
throughput level of individual tool sets in wafer fabrication facilities (fab), reducing the Work-in-Process 
(WIP) levels will result in cycle time reduction. However, there is a gap to effectively determine appropriate 
WIP levels for various tool sets in a fab in light of dynamic nature of wafer fabrication and complicated 
product mix on line.  
Indeed, a number of queueing and simulation models have been developed in predicting the WIP or the cycle 
time of tool sets in a fab, but many limitations for both of two models in practice also have been proven. Most 
of the studies applying queueing models have limitations in real settings due to the requisite assumptions to 
which few real-world systems conform (Uzsoy et al., 1992; Chambers and Mount-Campbell, 2002). 
Alternatively, simulation has been applied for production planning and control in semiconductor wafer 
fabrication, and it can be used to analyze operation dynamics in details. However, the construction and 
implementation of a simulation requires significant effort and lengthy computer time (Connors et al, 1996). 
Consequently, most of the existing studies are limited to specific tool sets or an ideal mini-fab that have 
limitations to be implemented for all tool sets in a real fab. Furthermore, since the modeling of a simulation is 
based on a specific system, it can hardly serve as a generic solution (Lin and Lee, 2001). 
Tool dedication and waiting time constraint are becoming critical in modern wafer fabrication, and several 
researches have addressed this issue from different viewpoints. For example, Chien and Chen (2007) 
developed a genetic algorithm for batch sequencing combined with a novel timetabling algorithm to solve the 
scheduling problem arising from oxide-nitride-oxide stacked film fabrication that is characterized by waiting 
time constraints, frequency-based setups, and capacity preoccupation; Chien et al. (2004) employed Self 
Organization Map (SOM) and decision tree for mining semiconductor production data to derive patterns 
among the critical indexes including WIP and cycle time for supporting production management decisions. 
The above studies have modeled the WIP levels of tools either with tool dedication or waiting time constraint. 
Few studies have addressed both the two constraints. 
Besides, in the recent years, the market value of LCD has been grown rapidly with the increasing demands of 
medium and small size because of the applications of high-level mobile phone and digital camera. Because of 
over-devoted investment, shorter product life cycle, quick advancement of production technology and recent 
 7
2. Manufacturing Intelligence Approach for WIP level and Cycle Time 
This study develops a manufacturing intelligence approach to extract potentially useful patterns from 
manufacturing data including production data and tool data. In particular, NNs are applied to analyze the 
relationships between related input factors and WIP of individual tool set. The model can help manufacturing 
department to improve related factors and thus to reduce the corresponding WIP levels. In particular, single 
processing and batch processing tool sets are analyzed.  
2.1 Input factors determination 
In this study, the input factors stem from queueing models. For single processing tools, we refer to the 
approximation for G/G/C model for single processing tools proposed by Hopp and Spearman (2001), as 
shown in Eq. (1).  
ρρ
ρ mccL
m
ea +⎟⎟⎠
⎞
⎜⎜⎝
⎛
−⎟⎟⎠
⎞
⎜⎜⎝
⎛ +=
+
12
)1(222
 (1) 
where  
L average WIP level tool set; 
m number of tools of the tool set; 
ρ utilization 
ca CV of inter-arrival times; 
ce CV of effective process times. 
To address the constraint of tool dedication, we propose the factor of mean ratio of usable tools (u) that 
measures the mean percentage of usable tools out of the total number of tools for all arrived lots in the 
duration. Utilization in Eq. (1) is derived from four parameters: 1) mean arrival rate; 2) mean process time; 3) 
mean number of tools; and 4) mean available rate. To investigate the effect of individual factors on WIP, the 
four factors are used as individual inputs rather than using only the utilization. Furthermore, we use the 
standard deviation of the available rate per hour (Dυ) to substitute cr in Eq. (1) because it is easier to be 
collected than cr in a typical fab. Finally, besides downtime, tools are subject to detractors such as setup 
(Hopp and Spearman, 2001). However, setup is not covered in Eq. (1). In a real fab, the setup time may vary 
as the lot size (the number of wafers contained in a lot) is changed. Therefore, we incorporate two factors into 
the inputs of the NNs: 1) the mean lot size and 2) the standard deviation of lot size. To discriminate the effect 
of lot size from process recipe on process time, the mean and coefficient of variation (CV) of process time are 
calculated based on lots with full lot size, i.e., 25 pieces of wafer.  
To identify the input factors for batch processing tools, this study refers to the approximation for G/G/C 
model with batch processing proposed by Fowler et al. (2002), as shown in Eq. (2). Due that lot size does not 
affect the process time of a batch processing tool, the mean and standard deviation of lot size are excluded in 
the inputs. The factors of mean number of recipes and mean batch size are included. Furthermore, the batch 
size may affect the process time because a larger batch size will result in a longer setup time. Therefore, the 
standard deviation of batch size is incorporated into the inputs. To discriminate the effect of batch size from 
process recipe on process time, the mean and CV of process times for batch processing tools are calculated 
 9
Dl Standard deviation of lot size ˇ  
b Mean batch size  ˇ 
Db Standard deviation of batch size  ˇ 
r Number of recipes  ˇ 
rw Mean ratio of lots with waiting time constraint ˇ ˇ 
tw Mean waiting time limit for lots with waiting time constraint ˇ ˇ 
 
2.2 NNs Evaluation 
To validate the effectiveness of NNs and to investigate which NN is suitable for predicting the WIP of a 
tool set, a simulation model is built to mimic the affects of input factors on WIP. The simulation model is built 
by the discrete event simulation packages of eM-Plant 7 to generate training and testing datasets for NNs. 
80% of data samples are randomly extracted as training data, while the remaining samples are used for testing. 
We conduct the random extraction process for five times and hence we have five datasets. The output is 
defined as WIP, and the inputs are mean inter-arrival time, standard deviation of inter-arrival time, mean 
process time, standard deviation of process time, number of tools, and mean tool available rate. For each NN, 
different combinations of network architecture, learning algorithm and parameters were experimented. The 
optimal model for each NN is evaluated with the least mean square error (MSE) and the least mean absolute 
percent error (MAPE) for testing data.  
We used the package of NeuroSolutions 5 to develop the models of BPNN, RNN and RBFNN. The 
package of STATISTICA 7 was applied for SVR. Through a number of experiments, the optimal NNs models 
can be obtained. Table 2 illustrates the MSE and MAPE of the four NNs with the optimal architecture, 
learning algorithm and parameters. It shows that BPNN significantly outperforms other models in terms of 
both MSE and MAPE. Therefore, the BPNN using LM learning algorithm with one hidden layer was chosen 
for practical application to a real fab. The number of hidden neurons needs further experiments according to 
the actual number of input factors of individual tool sets in the fab.  
 
Table 2 Comparison of MSE and MAPE for different NNs 
Dataset Item BPNN RNN RBFNN SVR 
MSE 0.284 0.579 3.323 0.463  1 MAPE 2.55% 3.56% 16.09% 5.05% 
MSE 0.460 1.859 2.372 0.747  2 MAPE 3.20% 5.03% 13.45% 4.78% 
MSE 0.384 0.362 2.967 0.741  3 MAPE 2.54% 3.04% 12.79% 5.17% 
MSE 0.202 0.397 4.182 0.733  4 MAPE 2.28% 4.70% 19.12% 6.46% 
MSE 0.363 0.538 2.789 0.444  5 MAPE 2.83% 3.90% 16.20% 4.75% 
MSE 0.338 0.747 3.126 0.625 Average MAPE 2.68% 4.05% 15.53% 5.24% 
 
 11
 
Table 4 Relationship between WIP and input factor, and implications 
Factor Relation with WIP 
% of tool sets conform 
to the relation 
Sensi-tivity 
ratio Managerial implications 
m － 92% 0.83 -- 
u － 93% 0.28 To relax tool dedication for non-critical products 
λ ＋ 95% 1.06 -- 
Ca ＋ 87% 0.38 To smooth hour-to-hour lot arrivals 
v － 94% 1.37 To improve tool availability 
Dv ＋ 73% 0.28 To balance non-available tool events among hours 
s0 ＋ 86% 0.77 To shorten process time 
Cs0 ＋ 79% 0.18 To evaluate effect of merging similar recipes on WIP 
l ＋ 81% 0.44 
Dl ＋ 88% 0.24 
To merge or split lots until the mean lot 
size approach the optimal level 
b －→＋ 83% 0.72 
Db ＋ 76% 0.37 
To develop model to determine the 
optimal batch size by recipes 
r ＋ 75% 0.46 To simplify number of recipes 
rw － 82% 0.22 To eliminate unnecessary waiting time constrains 
tw － 88% 0.56 To relax the specification for waiting time constraint 
“＋” : positively related 
’－“ : negatively related  
 
Table 4 also lists the managerial implications for improving individual factors. The case fab has taken 
many actions to improve related factors based on the priorities and resulting managerial implications we 
suggested.  
1) Level Tool Availability: Given that unscheduled down time (DOWN) is quite random, when partial PM1 
are transferred from day shift to night shift, the variation of available rate is significantly reduced. 
Thus, the average Dυ of all tool sets has been reduced by 27% and the action contributed 7.6% to the 
reduction of the fab WIP, i.e., the same reduction percentage for the fab cycle time. 
2) Contradictory Factors: The second example addresses the contradictory factors. Results of sensitivity 
analysis indicate that both mean and standard deviation of lot size are positively correlated to WIP. 
However, these two factors are negatively correlated, taking a tool set for example. Sensitivity analysis 
was conducted to simulate the compound effect of the two contradictory factors on the WIP of the tool 
set. It indicates that the optimal lot size for the tool set is 24.12, whereas the actual lot size is 23.68. 
Hence, it was suggested to merge lots of same products with smaller lot size until the mean lot size 
reaches the optimal level. As a result, the action contributed 5.3% to the reduction of the fab cycle time. 
Another example regards to a tool set for photoresist strip process. It is expected that merging some 
recipes with shorter process time to a recipe with longer process time might reduce the variation of 
process time while lengthen the mean process time. Yet, these two factors are contradictory. Sensitivity 
analysis can be employed to support the decision making. Table 5 illustrates that merging recipe B into 
 13
3. Data Mining for the Cause of Low Yield in TFT-LCD manufacturing  
3.1 Method 
This study proposes a data mining framework to explore the process data and inspection data for 
identifying the cause of TFT-LCD manufacturing defect that result in low yield. In particular, RST and DT are 
both applied to capture the cause of low yield. The proposed framework consists of problem definition and 
structuring, data preparation, model construction, and results evaluation and interpretation. 
3.1.1 Problem definition and structuring 
At the end of cell process, the panel surface defects inspection are performed for ensuring the panel 
quality. Different kinds of electronic tests, such as electronic capacity, resistance, and voltage, will be tested. 
In particular, the defective transistor could be occurred unpredictable signal and result in various defects. 
There are three typical types of LCD panel defects: (1) visual appearance defects, (2) electricity induced 
defects, (3) Mura defects (Jiang et al., 2005). The visual appearance defects are mainly caused by the unusual 
particles, uneven space between the upper and lower glass panels, and poor back light panel quality. The 
electricity induced defects are mainly caused by poor electrical transmission. These defects appear as lines or 
points as shown in Figure 1 (a) and (b). The Mura defects appear as a non-uniform area that the color is grayer 
or brighter than the other areas on a panel as shown in Figure 1 (c). A number of Mura defects which are 
caused from various processes are difficult to completely eliminate their root causes based only on knowledge 
or experience. This study aims to identify the abnormal process step and diagnose some specific panel defect 
in TFT-LCD manufacturing. Through collecting and exploring the related data including the process stations, 
operation machines and operation time, the root causes of defect failure could be identified by applying data 
mining methodologies. Furthermore, the results also can be accumulated and embedded in an IT-enabled 
knowledge-based system for supporting intelligent manufacturing and business decisions in high-tech 
industry. 
3.1.2 Data preparation 
During the TFT-LCD fabrication process, a large amount of process data will be automatically or 
semi-automatically recorded and accumulated in the engineering database. However, the collected data often 
includes noisy, missing and inconsistent data. Data preparation can not only improve the quality of the data 
but also make mining result efficiency. First, data has to be inspected to find data problem. Next, different 
kinds of problem were treated by corresponding method. Data integration merges data from multiple sources 
into a coherent data store. Data cleaning is applied to remove noisy data, identify outliers, fill in missing data, 
and correct inconsistencies. Data transformation is to transform or consolidate the data in a form appropriate 
for mining. Data reduction is to reduce the data dimension to improve the analysis efficiency, but the original 
data information is still obtained(Han and Kamber, 2006). Before model construction, the analysis dataset can 
be partition into k% training dataset and 1－k% testing dataset. Training data is used to derive the rules and 
testing data is used to estimate the validity of derived rules. 
3.1.3 Model construction 
 15
Step 6: Generate rules from the tree structure into candidate rules pool. 
Step 7: Extract meaningful rules from operation process information associated with suffered lots of minority 
class which is often set as interested class. 
 
Rules validation 
 
Two indices of confidence and lift are used to validate the appropriateness of derived rules from RST 
approach and DT approach and provide the decision maker quantitative understanding of the rules. In 
particular, confidence denotes the prediction accuracy that a subset can be classified into a specific class. Lift 
is a ratio that indicates the change in concentration of a specific class when the rule is used to select a subset 
from the general population and thus the lift should be greater than one.  
=)Rule(Confidence iH  
)Rulebyselecteddatasubset|classtarget ( iHP (23) 
)population|classtarget(
)subset|classtarget()Rule(Lift
HP
iHPiH =  (24) 
Furthermore, testing data is used to estimate the validity of the candidate rules derived from training data 
as follows.  
Step 0: Determine the thresholds of confidence and thresholds of lift for the validation rules. 
Step 1: Set 1=k  
Step 2: Summarize the object l in the testing data, set 1=l , 0=m , and 0=n . 
If the object l matches the condition part of the rule k, then 1+= mm .  
If the object l matches both the condition and decision part of the rule k, then 1+= nn . 
Step 3: If l< the total numbers of objects in the training data set, then 1+= ll  and go to step 2. 
Step 4: Calculate the kconfidence  and klift , in which mnconfidencek = ;  
=klift  /kconfidence the proportion of interested class.  
Step 5: If ≥kconfidence thresholds of confidence and ≥klift thresholds of lift, then select candidate rule k into 
validation rules pool. 
Step 6: If k< total number of the generated rules, then 1+= kk  and go to step 1. 
Step 7: Confirm all validation rules into final decision rules and discuss with domain experts domain experts 
for evaluating the meaningfulness of mined rules. 
3.1.4 Results evaluation and interpretation 
By the causal relationship derived from RST analysis and DT analysis, engineers can identify possible 
abnormal process station and machine accompanying with their domain knowledge. The useful information or 
patterns that associated with operation process information and low yield can be extracted to engineers for 
diagnosing fault quickly.  
Data mining process should iteratively extract valid inference, previously unknown information from 
data, and revise the empirical models in a feedback mode. The meaningful patterns and root causes cannot be 
easily identified with one shot. Thus, we should discuss with domain experts again to verify the data quality 
and perform data preparation to enhance the accuracy and effectiveness of mining results. All the results 
should be clarified by discussing with domain engineers and data experts. Furthermore, the mining results 
 17
Table 7 Some candidate rules about lot yield 
IF (process station) 
Item 
A B C D E F G H I J K 
THEN 
(lot yield) 
Support 
1 3 x x x x x x 3 x x x Low 10 
2 x 4 x x x x x 2 x x x High 10 
3 x x x x x x x x 1 x x Low 14  
 
3.2.3 Model Construction 
RST-based approach for low yield data 
To screen unqualified candidate rules, threshold of confidence level was set to be 70% and lift should be 
greater than 1. In particular, the decision rules about low yield were mainly considered. Some validation 
results of the candidate rules were shown as Table 6. Following the result of first time cross-validation as 
illustration example, Rule 1 in Table 6 would be accepted because it confidence level is 100% (>70%) and the 
lift is 1.75 (>1). However, Rule 2 in Table 6would be rejected because it confidence level is 50% (<70%) even 
if the lift is 1.16 (>1). Furthermore, similar rule-validation procedures were iterated until all candidate rules 
have been evaluated with all samples in the testing data, and thus 13 rules were extracted.  
After five times cross-validation and integrating the extracted rules, 18 rules were listed specific rules 
associated with the corresponding confidence level and lift as shown in Table 7. The extracted rules passed 
screening criteria could provide sufficient evidence for engineer to identify the root-cause of low yield. As 
shown in Figure 3, the machine occurred frequently in the validation rules could be inspected first, such as 
H03 in layer 3 etching process. 
 19
 
Fig. 2 Occurrence frequency of process and machine in validation rules  
 
Fig. 3 DT-based approach for diagnosing low yield 
Table 9 Validation of candidate rules for low yield by RST-based approach 
Item Rules (frequency) Confidence Lift 
1 
IF a plate lot passed machine A03 on layer 1 thin film, 
and machine H03 on layer 3 etching,  
THEN the plate lot is inferred as low yield. (5/5) 
87.00% 2.25
2 
IF a plate lot passed machine B02 on layer 1 etching, 
and machine H03 on layer 3 etching,  
THEN the plate lot is inferred as low yield. (4/5) 
96.00% 2.56
3 
IF a plate lot passed machine B02 on layer 1 etching, 
machine H03 on layer 3 etching, and machine J02 
on layer 4 thin film, 
THEN the plate lot is inferred as low yield. (5/5) 
91.50% 2.47
 
 
Similarly, the same testing data and evaluation criteria of confidence and lift were used to validate the 
candidate rules as calculated in Table 8. For example, Rule 1 in Table 8 which means “IF a plate lot passed 
machine H01 H02 on layer 3 etching process, THEN the plate lot is inferred as high yield,” would be accepted 
because confidence level is 100% (>70%) and the lift is 2.33 (>1). However, Rule 2 in Table 8 which means 
“IF a plate lot passed machine E02, E03 on layer 2 etching process, machine H03 on layer 3 etching process, 
and machine J02, J04 on layer 4 thin film process, THEN the plate lot is inferred as low yield,” would be 
rejected because it confidence level is 25% (<70%) and the lift is 0.58 (<1). After five times cross-validation, 
 21
3.2.4 Evaluation and Interpretation 
According to the analysis results and discussion with domain engineers, as shown in Figure 5, H03 was 
the abnormal machine on layer 3 etching process causing yield loss during 9/13~9/14. In particular, the defect 
of cloud Mura is mainly caused from the incomplete cleaning process of subtracts. And then the uniformity of 
threshold voltage was affected and resulted in that the electric shock is not uniform during the etching process 
as shown in Figure 6. However, it could be only inspected via the visual phenomenon of inconsistent color 
after the threshold voltage is transmitted. In addition to the bad uniformity of threshold voltage, there are 
several reasons could result in cloud Mura defect such as the roughness of etch stage. With the information of 
possible roots causes, the engineers can quickly check the machine behavior and fine tune the recipes.  
Fig. 4. Line plot of lot yield for layer 3 
etching process 
 
3.2.5 Results comparison of RST and DT 
To compare with other classification methods such as neural network and support vector machine, both 
RST and DT can provide better capacities for exploring data and extract the latent information into a series of 
simple and useful decision rules. Both can identify the causal relationships involving the complex process, 
machine and their interactions to detect the root cause. Indeed, the extracted decision rules can provide 
sufficient information or evidence for trouble-shooting based on the screening criteria.  
 
 
Fig. 5 Illustration of TFT construction 
 
Table 12. Comparison of cross-validation results for RST-based and DT-based approach 
Cross-validation 
Approach Index 
1 2 3 4 5 
Average 
 23
develop better analytical methodologies that can improve both the efficiency and effectiveness of yield 
enhancement. In addition, future studies of data mining can be done on other TFT-LCD related problems such 
as fault detection and classification (FDC), and advanced process control/advanced equipment control 
(APC/AEC). 
5. References 
Berry, M. and G. Linoff, Data Mining Techniques for Marketing, Sales and Customer Support, 2nd ed., John 
Wiley and Sons, New York (2004). 
Braha, D. and A. Shmilovici, “Data mining for improving a cleaning process in the semiconductor industry,” 
IEEE Transactions on Semiconductor Manufacturing, 15(1), 91-101 (2002) 
Breiman, L., J. H. Friedman, R. J. Olshen and C. J. Stone, Classification and Regression Trees, Belmont, 
CA:Wadsworth, (1984). 
Çakanyildirim, M. and R. Roundy, “SeDFAM: semiconductor demand forecast accuracy model,” IIE 
Transactions, 34(5), 449-465 (2002). 
Chien, C., A. Hsiao and I. Wang, “Constructing semiconductor manufacturing performance indexes and 
applying data mining for manufacturing data analysis,” Journal of the Chinese Institute of Industrial 
Engineers, 21(4), 313-327 (2004).  
Chien, C. and C. Chen, “Using genetic algorithm (GA) and a coloured timed Petri net (CPTN) for modeling 
the optimization-based schedule generator of a generic production scheduling system,” International Journal 
of Production Research, 45(8), 1763-1789 (2007). 
Chien, C., and C. Hsu, “A novel method for determining machine subgroups and backups with an empirical 
study for semiconductor manufacturing,” Journal of Intelligent Manufacturing, 17(4), 429-440 (2006). 
Chien, C., D. Lin, C. Peng and S. Hsu, “Developing Data Mining Framework and Methods for Diagnosing 
Semiconductor Manufacturing Defects and An Empirical Study of Wafer Acceptance Test Data in A Wafer 
Fab,” Journal of the Chinese Institute of Industrial Engineers, 18(4), 37-48 (2001). 
Chien, C. and L. Chen, “Using Rough Set Theory to Recruit and Retain High-Potential Talents for 
Semiconductor Manufacturing,” IEEE Transactions on Semiconductor Manufacturing, 20(4), 528-541 (2007). 
Chien, C. and L. Chen, “Data mining to improve personnel selection and enhance human capital: A case study 
in high-technology industry,” Expert Systems with Applications, 34(1), 280-290 (2008). 
Chien, C., W. Wang and J. Cheng, “Data mining for yield enhancement in semiconductor manufacturing and 
an empirical study,” Expert Systems with Applications, 33(1), 192-198 (2007). 
Dimitras, A. I., R. Slowinski, R. Susmaga and C. Zopounidia, “Business failure prediction using rough sets,” 
Europe Journal of Operation Research, 114(2), 263-280 (1999). 
Han, J. and M. Kamber, Data Mining: Concepts and Techniques, 2nd ed., Morgan Kaufmann Publishers 
(2006). 
Hsu, S. and C. Chien, “Hybrid data mining approach for pattern extraction from wafer bin map to improve 
yield in semiconductor manufacturing,” International Journal of Production Economics, 107(1), 88-103 
(2007). 
Jiang, B. C., C. Wang and H. Liu, “Liquid crystal display surface uniformity defect inspection using analysis 
of variance and exponentially weighted moving average techniques,” International Journal of Production 
Research, 43(1), 67-80, (2005). 
Kass, G. V., “An exploratory technique for investigating large quantities of categorical data,” Applied 
Statistics, 29(2), 119-127 (1980). 
Kusiak, A., J. A. Kern, K. H. Kernstine and B. Tseng, “Autonomous decision-making: a data mining 
approach,” IEEE Transactions on Information Technology in Biomedicine, 4(4), 274-284 (2000). 
 25
 
國科會補助專題研究計畫成果報告自評表 
請就研究內容與原計畫相符程度、達成預期目標情況、研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）、是否適
合在學術期刊發表或申請專利、主要發現或其他有關價值等，作一綜合評估。
1. 請就研究內容與原計畫相符程度、達成預期目標情況作一綜合評估 
■  達成目標 
□ 未達成目標（請說明，以 100 字為限） 
□ 實驗失敗 
□ 因故實驗中斷 
□ 其他原因 
說明： 
  本計畫第一年針對製造策略，特別是需求預測的研究方法。高科技產業製造
策略的核心決策是產能規劃與設置，隨著需求量而做動態調整，當晶圓需求變
多，且產能不足時，則需進行產能擴充。若需求預測之準確度高，不僅可協助公
司制定市場行銷計畫以及良好的產能策略，更能提昇公司整體獲利；倘若需求預
測結果誤差過大，會因為產能水準制定不足而導致顧客流失、商譽受損，或因為
產能過剩而增加公司成本負擔。 
本計畫第二年建立不確定下的產能規劃決策模式，包括實質選擇權在產能決策
的應用與晶圓廠建廠、擴廠與廠間分配之規劃，以建立一個穩健的模型，可以保
證在各種情境下的表現不會太差，追求合理的報酬跟風險的平衡點。在考慮需求
不確定性的情況下，從決策分析的角度建立穩健的產能計劃，並且建立出一個決
策分析工具。 
本計畫第三年發展「全面資源管理」(Total Resource Management)架構，建
構有系統的管理循環進行營運資源的目標規劃、管控、績效考核與回饋改善，以
持續提升營運績效。企業無不積極進行技術的研發、人員的訓練、產品良率的改
善、設備產出效率的提升等活動，以期能不斷提升公司的獲利能力及市場競爭
力，而其主要的關鍵乃在於企業能否有效對營運資源進行有效的管理。資源為企
業營運能夠持續運作的必備條件，透過資源的結合與運用才能順利產出產品和服
務，由此可知若能對資源有效的規劃與應用，將有助於公司生產力之提升。 
附件二 
 27
3. 請依學術成就、技術創新、社會影響等方面，評估研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）（以
500 字為限） 
 
本三年計畫以多年期的計劃，逐步建立以國內高科技產業如半導體業、
TFT-LCD 業的營運決策分析模式，以垂直整合製造策略、需求預測、產能規
劃與配置、生產力與效益分析的完整決策過程，將工業工程的分析方法和管
理模式，由作業階層往上整合至企業規劃與決策層，以創造新的工業工程典
範和增加工業工程在企業中的價值。 
透過國科會補助計畫以及與友達光電、茂迪的產學合作研究計畫，本研究團
隊已成功將過去在半導體產業之資料挖礦研究成果轉換至 TFT-LCD 與太陽
能產業領域，並針對該產業之特性發展研究方法、資料挖礦工具和決策支援
系統。針對 TFT-LCD，未來正逐步發展先進製程控制模式，以提升 TFT-LCD
陣列製程之良率。本計畫所發展的研究方法，整合資料挖礦、先進製程管制、
事故診斷與分類以提供 TFT-LCD 產業製造管理與良率提昇的決策依據，對
TFT-LCD 產業將有創新的貢獻。而針對太陽能產業發展之多市場產能分配策
略將在 100%的總產能利用率假設前提下，協助茂迪產生每個月每張訂單相
對應訂單市場「產能分配支援需求」的建議，以產生兼顧營收、獲利與毛利
率等三個根本目標的最適產能分配模式以達到「全面資源管理」的最佳化，
提供茂迪長期策略佈局在營運執行面上的兵棋推演基礎，更能提供符合企業
決策所需之參考資訊。 
 
IML2009  
 
 
 
Professor Chien, Chen-Fu 
Prof, National Tsing Hua University, Taiwan 
cfchien@mx.nthu.edu.tw 
 
 
Chairman Chan, Chien-Lung 
Prof, Yuan Ze University, Taiwan 
clchan@saturn.yzu.edu.tw  
 
 
Professor Huang, Yi-Chao 
Prof, Ping Tung University of Science and Technology, Taiwan 
tyh1332@mail.npust.edu.tw  
 
 
Kuo, Ren-Tsun 
Ph.D. Candidate, National Tsing Hua University, Taiwan 
rtkuo@tsmc.com  
 
 
Zheng, Jia-Nian 
Ph.D. Candidate, National Tsing Hua University, Taiwan 
d9534504@oz.nthu.edu.tw  
 
司，該公司主要是生產衛浴產品，在台灣也算是相當有名的品牌，整個活動到這天中午算
是結束。 
 
二、與會心得 
該會議大部分是在解決製造業的實務問題，討論到很多模型、求解演算法與系統，無論是
哪個產業一樣有求解精緻度跟模型複雜度的權衡問題，可以做為本計畫的一些參考。並且
教授們多半都有實務經驗，甚至本身就是在業界的，討論起來可以很具體或是很快進入核
心問題。與會者多半都是指導教授帶著自己的學生來發表，口頭報告後的討論比較接近是
建議或是相關研究學者的討論，另外因為指導教授簡禎富教授與主辦人玄光男教授認識很
久，晚上比較熟的教授級就一起出去，而玄光男教授則交代他學生招待這些教授的同行
人，所以晚上就在跟學生們吃飯聊天，也交換了一些名片與連絡方式，這種方式也不錯，
雖然跟著教授們聊天可以學到很多，但這種方式可以讓我們認識很多同輩的學者，而且都
是博士生的話，之後走研究的機會很高，可以先建立一些人脈關係。 
 
三、建議 
1、雖然本研討會列出的主題很多，但都是工業工程或是資訊管理相關的領域，所以參與
的人員多半都熟悉彼此做的研究，討論上也可以更熱絡；並且與會者多半都有實務經驗，
可以較具體的描述問題。 
2、與國內的研討會相比，IML 同一時間的議程並不會很多，可以增加各議程裡的人數促進
討論，國內研討會可以參考這種模式，不一定要在一天內結束。 
3、若不是只有一天的話，也可以在其中加入參觀，介紹自己國內的公司或是地方文化，
例如一天半的議程，半天的活動。在參觀活動時也較自由，可以找相關研究的學者討論，
或是認識同領域的學者。 
 
四、攜回資料名稱及內容 
帶回來的資料有智慧型製造與邏輯系統國際研討會議程本與光碟，共有 57 組口頭報告與 14
組海報；本次研討會與另一個研討會合辦，所以議程本印在一起，共 65 頁。光碟中則有
各論文的全文電子檔。 
 
 
96年度專題研究計畫研究成果彙整表 
計畫主持人：簡禎富 計畫編號：96-2628-E-007-035-MY3 
計畫名稱：建構高科技產業供應鏈之策略性營運決策分析模式及其決策支援平台 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 1 1 100%  
研究報告/技術報告 0 0 100%  
研討會論文 3 3 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 10 10 100%  
博士生 3 3 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 4 4 100%  
研究報告/技術報告 0 0 100%  
研討會論文 5 5 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
 
