2 
 
project proposes an algorithm to adaptively 
choose GOP(Group of Picture) size according to 
video variation. We calculate the gradient values 
by visual rhythm, and then determine suitable 
GOP size automatically. The experimental results 
show that the proposed algorithm provides good 
video performance and less bit-rate. 
Keywords: Scalable Video Coding, Video Coding 
Standard, MCTF, Hierarchical B picture, Visual 
Rhythm 
 
二、緣起與目的 
過去這些年來，多媒體的應用已經非常廣
泛地被應用在消費性電子產品上，舉凡數位相
機、MP3 隨身聽、行動電話等等都跟多媒體應
用脫離不了關係。多媒體是包含語音(Speech)、
音訊(Audio)、影像(Image)及視訊影像(Video)，
而這些多媒體資訊表示方式的資料量都是非常
龐大的，其中又以視訊影像的資料更為多，舉
例來說，如果以每秒三十張畫面的視訊影像，
其解析度為 800X600 Pixels，色彩空間為 RGB
的話，則這一秒鐘的視訊影像所需的資料量為 
30(Frames)*(800X600)(Pixels)*3(RGB)=41Mbyt
es。如果以一小時的電影而言，這樣的資料量不
論對於視訊資料的傳輸及儲存都是相當困難
的。而視訊資料透過不同的網路傳輸環境來做
傳輸應用是未來非常重要的一項技術發展，隨
著無線網路及行動裝置的技術發展，多媒體應
用已經漸漸的受到行動應用的重視，多媒體資
訊將被儲存或者傳輸於不同裝置及網路上。為
了要讓視訊資料能夠符合不同的應用發展，許
多學者及廠商在過去這二十年來都開始為視訊
編碼貢獻心力。為了讓不同視訊產品製造商所
編碼出來的視訊資料能夠跟不同的機器相容，
有兩個國際組織分別是 International Standard 
Organization (ISO) 以 及 International 
Telecommunication Union (ITU)訂定了許多針對
於視訊編碼的國際標準。 
對於不同的應用而言有不同的視訊標準可
以被使用，例如 H.261 [1] 以及 H.263[2]這一系
列的視訊編碼標準是由 ITU 所提出來應用於低
位元率的視訊電話系統，而 MPEG-1 [3]、
MPEG-2 [4]以及MPEG-4 [5]這一系列的視訊編
碼標準則是由 ISO 所提出來應用於比較高位元
率的多媒體儲存方面。而最新的視訊編碼標準
稱為 MPEG-4 Part-10 H.264/AVC [6-8]則是由
Joint Video Team (JVT: The jointed team of ISO 
and ITU)所提出來，H.264最主要的目的是為了
針對於不同位元率的應用，其應用範圍則是包
含不同的傳輸網路如有線及無線以及不同的儲
存設備。隨著視訊編碼技術的發展使得視訊影
像的資料可以很有效的被壓縮，也因為如此使
得視訊影像的應用變得愈來愈普及。 
上述所提到之所有的視訊編碼標準都是以
混合式(hybrid coding)架構為基礎來做不用的應
用。圖一所示即為混合式視訊編碼的架構，由
圖一可得知混合式的編碼架構包含的功能有移
動 估 計 / 移 動 補 償 (Motion Estimation: 
ME)/(Motion Compensation: MC)、畫面內編碼
(Intra Coding)、轉換編碼(Transform Coding)、量
化(Quantization)、去區塊效應濾波器(Deblocking 
Filter)以及可變長度的熵編碼(Variable Length 
Entropy Coding: VLC)。移動估計/移動補償之功
能最主要的是執行移動估計以及移動補償的動
作，此功能模組可以用來消除視訊影像中時間
域的資料累贅(Temporal Redundancy)、轉換編碼
則是將空間域(Spatial Domain)的資料做數學轉
換以方便後續的編碼處理，常見應用於視訊編
碼中的轉換編碼有離散餘弦轉換 (Discrete 
Cosine Transform: DCT)、整數轉換 (Integer 
Transform)以及離散小波轉換(Discrete Wavelet 
Transform: DWT)，量化的功能主要是將頻率域
的資訊給予量化，此量化最大目的即是用來消
除對於人眼比較不敏感的影像資訊、去方塊效
應濾波器用於去除影像小方塊的邊緣效應，因
為此混合型視訊編碼的架構都是以巨區塊
(Macroblock)為最小的處理單位 (一般都是
16x16)，所以經過量化之後每一個巨區塊之間會
造成不連續性，所以就會有區塊效應的產生。
4 
 
Motion Compensated Temporal Filtering 
(MCTF)的原理 
從圖二中我們可以發現到 MCTF 此技術是被廣
泛採用的一種時間可階性的視訊編碼技術，其
主要是架構在 lifting [13] 的基礎上。Lifting這
個方法可以保證當輸入訊號經過分解以及在沒
有量化的情況下能夠完整的將原始的輸入訊號
給予重建回來，一般的 lifting 方法通常由三個
運算來達成分別是 : 多相分解 (polyphase 
decomposition) 、 預 測 (prediction) 以 及更 新
(update)。在大部份的情況下，MCTF 都是由一
個預測及更新所成對出現。圖三所示即是由一
組 analysis-synthesis filter bank所形成的 lifting
表示方法示意圖。 
 
 
          (a)                 (b) 
(a) Lifting Scheme (Analysis Filterbank) 
(b) Inverse Lifting Scheme (Synthesis Filterbank) 
圖三、 分析－合成濾波組的 Lifting 表示方式. 
 
    對於分析端(a)而言，給予一個訊號 s，其奇
數的樣本(sample) s[2k+1]會透過一個預測運算
器 P(s[2k])對於偶數樣本 s[2k]做一線性組合來
得到預測訊號。至於高通訊號 h[k]則是由預測
的殘餘訊號所組合而成的，而其對應的低通訊
號 l[k]則是將預測後殘值做線性組合所得到
的。h[k]是透過一個更新的運算器 U(h[k])加到
原始訊號 s中的偶數樣本 s[2k]所得到的。關於
如何去求解 MCTF 中高通 h[k]及低通訊號 l[k]
可由公式(1)及(2)表示之。 
     
∑ )](2[])2[(
i
i ikspksPwith
P(s[2k])-1]+s[2k=h[k]
+=           (1) 
 
∑ ][])[(
i
i ikhukhUwith
U(h[k])s[2k]=l[k]
+=
+
             (2) 
 
    因為預測及更新的步驟都是可逆的，所以
其所對應的資訊都可以完整的被重建回來。至
於合成端的部份(圖三(b))，因為其所組成的元素
只是分析端(圖三(a))的反方向，所以所有的資訊
皆可被完整的重建回來。 
  令 s[x,k]為一個視訊影像資料位於空間坐標
x=(x,y)T以及時間坐標 k上，當使用 Haar小波的
lifting 表示方式來對於視訊資料做時間域分
析，其預測及更新的運算器可以以公式(3)來表
示 
     
]k,x[h
2
1
])k,x[h(U
]k2,x[s])k2,x[s(P
Haar
Haar
=
=
                (3) 
 
如果使用 5/3轉換，其預測及更新的運算器則是
定義如公式(4) 
 
])1-k,x[h]k,x[h(
4
1
])k,x[h(U
])2k2,x[s]k2,x[s(
2
1
])k2,x[s(P
3/5
3/5
+=
++=
  (4) 
 
接下來如果欲將上述的公式延伸至 motion 
compensated temporal filtering，則是將預測及更
新運算器修改如下公式(5)所示: 
 
]),[
],[(
4
1]),[(
])222,[
]2,[(
2
1])2,[(
],[
2
1]),[(
1
003/5
11
3/5
00
U1U
UU
PP
P0Po
UUHaar
PoPoHaar
r-1-kmxh
rkmxhkxhU
rkmxs
2r-km+xskxsP
rkmxhkxhU
]2r-,2km+s[x=(s[x,2k])P
++
++=
++++
=
++=
    (5) 
6 
 
雙向預測畫面 (B frame)，且編碼順序是在
GOP(Group Of Picture)中先按照階層，在按照播
放順序。圖六為以GOP大小為8來做說明。 
 
 
圖六、Hierarchical B Picture結構 
 
首先說明編碼順序，藍色數字為編碼順序
一開始編碼為第0張的I畫面或P畫面，若GOP大
小為8，則接下來編碼的為第8張，再接下來編
碼的為第4張，接下來依序為第2、6、1、3、5、
7張，可以看出編碼順序為有規則的階層式編
碼。不同顏色的弧線表示不同的時間域階層，
若GOP大小為8時，則有4個時間階層，最粗糙
的時間層為 [0,8]，再來是 [0,4,8]，然後是
[0,2,4,6,8] ， 最 精 緻 的 時 間 層 為
[0,1,2,3,4,5,6,7,8]；而下一個GOP是將上一個
GOP的P畫面當作第0張繼續編碼。簡單的說，
Hierarchical B Picture以調整運動估計/補償的順
序，即達到時間可調的特性，其複雜度遠比
MCTF來的低，且擁有更好的畫質表現，也能與
H.264/AVC的語法相容。 
 
三、所提出的適應性畫面群組大小調整
演算法 
此計劃中我們提出一個適應性畫面群組大
小調整(Adaptive GOP Size)的演算法，主要是針
對 Hierarchical B Picture設定 GOP大小時的問
題加以改善。從實驗得知，不同特性的評估視
訊，在不同的 GOP大小會有不盡相同的表現，
甚至量化參數(Quantization Parameter, QP)都有
可能會影響影像品質。過去在 MCTF 也有適應
性調整 GOP結構(Adaptive GOP Structure, AGS)
的功能，但隨著時間域編碼結構改為
Hierarchical B Picture，AGS在 JSVM5.1開始已
無作用，於是 JSVM6.1 將 AGS 移除。至目前
JSVM並無針對Hierarchical B Picture的AGS演
算法。本計劃提出之適應性 GOP大小演算法，
其目的與MCTF的 AGS相同，但是簡化判斷過
程，降低計算複雜度，達到快速但能有效偵測
畫面變化，進而調整 GOP 大小使單一 GOP 內
的場景盡量相似，提升壓縮效率與影像品質。
圖七表示在最大 GOP為 16的各種 GOP大小的
組合。 
 
8 8
16
4 4 4 4
2 2 2 2 2 2 2 2
4 48
8 2 2 2 2
2 28 4
4 4 2 24
2 248
44 8
82222
22 84
22 4 8
4 4 2 2 4
4422 4
44224
22 4422
2 2 2 2 2 24
2 24 4 2 2
224 422
2222 224
224 422
2 2 44 2 2
224422
222222 4
2 2 2 22 2 4
2
4
2
4
8 8
16
4 4
2 2 2 2 2 2
 
圖七、各種 GOP組合 
 
    本計畫提出之判斷畫面變動的準則採用視
覺韻律 (Visual Rhythm)[14][15]，並做了些改
變。過去視覺韻律僅取對角線的像素資訊，但
是單一方向的資訊對於某些方向的變動可能過
於敏感或不敏感。於是在視覺韻律方面加入反
對角線、水平及垂直方向的像素資訊，將四個
方向所得到的資訊加總，如圖八、圖九。實驗
結果顯示可有效偵測場景轉換(Scene Change)和
視訊影像的變動情形。 
 
 
圖八、視覺韻律的像素資訊擷取方式。 (Table 
Tennis視訊) 
8 
 
最大時間階層數為 5，也就是以 Hierarchical B 
Picture結構編碼的最大 GOP為 32。GOP的詳
細設定方法列於表一。 
表一、GOP詳細判斷準則 
GOP
大小 判斷準則 
2 gradientt>50 
4 ∑
=
≥
3
0
40
t
tgradient 或∑
=
≥
7
4
40
t
tgradient  
8 ∑
=
<
3
0
40
t
tgradient 且∑
=
<
7
4
40
t
tgradient  
16 
滿 足 GOP=8 的 條 件 ， 及
∑
=
<
11
8
40
t
tgradient 且∑
=
<
15
12
40
t
tgradient  
32 
滿 足 GOP=16 的 條 件 ， 及
∑
=
<
19
16
40
t
tgradient 、 ∑
=
<
23
20
40
t
tgradient 、
∑
=
<
27
24
40
t
tgradient 且∑
=
<
31
28
40
t
tgradient 。
四、結果與討論 
測試編碼共執行「Table Tennis」、「News」
與「Foreman」三種影像序列，每個影像序列皆
編碼 289張畫面，量化參數為 26。除了第一張
為 I畫面，其餘 288張畫面為 P畫面或 B畫面。
為使每一個 GOP設定皆能完整執行實驗，所以
設定為 32的倍數，288可以完整執行 9個 GOP
大小為 32 的編碼。其餘 GOP 大小設定也能完
整執行，不會有不完整的 GOP。以 Table Tennis
為例，當中包含一次場景切換與鏡頭拉遠，畫
面變化是比較大的。GOP選擇 2次 GOP=2，42
次 GOP=4，14 次 GOP=8，沒有選擇 GOP=16
或 GOP=32。從表二(a)可以看出，僅與畫質最
佳的 GOP=4差 0.05dB，但是位元率下降 17.64K 
bits/sec; News 則與畫質最高的 GOP=4 僅相差
0.03dB，位元率下降 3.87K bits/sec; Foreman與
最高畫質 GOP=2 僅相差 0.02dB，位元率下降
1.85K bits/sec，圖十一為 Foreman的主觀品質比
較。從實驗結果可以看出，計畫所提的方法能
夠通常能夠維持影像畫質在不錯的水準。因為
大量的 B畫面與階層式編碼結構使得最佳 GOP 
大小並不容易預測，但是本計劃所提方法大多
都能選擇到最佳畫質與次佳畫質的GOP大小之
間，而且所花費計算量非常小。目前演算法僅
將所獲得的 Visual Rhythm的像素資訊做加法、
減法及絕對值的計算，並未使用乘法，所以可
以達到快速判斷的效果，  
表二、所提出的計畫方法與固定 GOP大小的畫
質與位元率比較 
(a) Table Tennis 
GOP size PSNR 
(dB) 
Bit Rate 
(Kbits/sec) 
IPPP… 38.25 468.74 
2 38.34 314.48 
4 38.36 215.59 
8 38.19 174.94 
16 38.07 154,81 
32 37.90 148.43 
Proposed 38.31 197.95 
(b)News 
GOP size PSNR 
(dB) 
Bit Rate 
(Kbits/sec) 
IPPP… 38.73 104.45 
2 38.83 96.95 
4 38.92 97.28 
8 38.85 91.11 
16 38.74 87.67 
32 38.64 89.19 
Proposed 38.89 93.41 
(c)Foreman 
GOP size PSNR 
(dB) 
Bit Rate 
(Kbits/sec) 
IPPP… 37.71 213.97 
2 37.77 183.04 
4 37.74 181.23 
8 37.57 170.48 
16 37.50 163.93 
32 37.34 165.50 
Proposed 37.75 181.19 
10 
 
coding for generic audiovisual services.” 
[7] Jorn Ostermann, Matthias Narroschke, Thomas 
Wedi, Thomas Stockhammer, Jan Bormans, 
Fernando Pereira, Peter List and Detlev Marpe, 
“Video coding with H.264/AVC: tools, 
Performance and Complexity,” IEEE Circuits 
and Systems Magazine, Vol.4, No.1, pp. 7-28, 
First Quarter 2004. 
[8] Joint Video Team software. 
http://bs.hhi.de/~suehring/tml/download/ 
[9] Julien Reichel, Heiko Schwarz and Mathias 
Wien, “Joint Scalable Video Model (JSVM) 
1.0 Reference Encoding Algorithm 
Description,” Joint Video Team, doc. 
JVT-N023, Hong Kong, China, January 2005. 
[10] Joint Video Team, Joint Scalable Video 
Model JSVM 1, January. 2005, http:// 
ftp3.itu.int/av-arch/jvt-site/200501HongKong/
JVT-N024.zip. 
[11] Julien Reichel, Heiko Schwarz and Mathias 
Wien, “Joint Scalable Video Model (JSVM) 
2.0 Reference Encoding Algorithm 
Description,” Joint Video Team, doc. 
JVT-O074, Busan, Korea, April 2005. 
[12] Joint Video Team, Joint Scalable Video 
Model JSVM 2, April. 2005, 
http://ftp3.itu.int/av-arch/jvt-site/2005_04_Bus
an/JVT-O203.zip 
[13] Wim Sweldens, “A custom-design 
construction of biorthogonal wavelets,” 
Applied and Computational Harmonic 
Analysis, 3(2), pp.186-200, 1996. 
[14] M. G. Chung et al. Automatic video 
segmentation based on spatio-temporal 
features. Korea Telecom Journal, 4(1):4-14, 
1999. 
[15] Silvio Jamil Ferzol Guimaraes, Michel 
Couprie, Neucimar Jeronimo Leite and 
Arnaldo De Albuquerque Araujo, “A method 
for cut detection based on visual rhythm,” 
Proceedings of XIV Brazilian Symposium on  
Computer Graphics and Image Processing, pp. 
297-304, Oct 2001. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
