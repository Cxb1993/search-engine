II 
 
Abstract 
Although many algorithms have been proposed over the past few decades, it is still very 
important for solving an NP-Complete problem. Due to the complexity of the problem, many 
algorithms including (Monte Carlo ， MC) 、 (Simulated Annealing ， SA) 、 (Particle Swarm 
Optimization，PSO）and（Genetic Algorithm，GA）have been proposed for searching good solutions 
in reasonable computation times.The aim of this research is to make a study and an analysis of the 
above optimal algorithms in order to find the advantage and processing of their approaches which 
were summarized and extracted the characteristics and essence of the various algorithms. Then to 
integrate and reconstruct a new algorithm framework which is the combination of these advantages 
of these algorithm characteristics. From the analysis of relevant literature and discussion, We found 
that the advantages of these algorithms can be expressed in two properties of the handling 
characteristics of these algorithms. The first is the neighborhood search processing, and second, 
moving the processing solution. Therefore, if we could make deconstruction analysis and extraction 
for the best of these algorithms in these two properties, and then be integrated into an advantage in 
these two properties make parametric algorithm modulation framework. With the adjustment of 
parameters that will enable our algorithm framework to transfer between the above-mentioned four 
kinds of algorithms smoothly, in order to solve problem with both intensification and 
diversification of the searching convergence. Therefore, the performance of our new algorithm 
framework could be able to greatly enhance. Most previous studies made a hybrid algorithm from 
these algorithms mentioned above, to make up the shortcomings of a single algorithm for each 
other. However, this improvement method only for a specific problem solving, it is to improve the 
solution process and the limitations of solution searching. 
The present study attempted to integrate and reconstruct a new algorithm framework which is 
with the advantages of the integration of reconstruction algorithms characteristics to break through 
this limitation and improve the solving efficiency. Believe that such a new algorithm framework 
not only can enhance the performance of algorithms but also help to cope with the diversity and 
complexity of problem solving. And to provide related researchers a different contemplation of the 
algorithm study. 
 
Keywords：Neighborhood, Hybrid, Monte Carlo, Simulated Annealing, Particle Swarm 
Optimization 
  
IV 
 
圖目錄 
FIG. 1.蒙地卡羅模擬法流程圖	  .................................................................................................	  3	  
FIG. 2. 模擬退火法流程圖	  .......................................................................................................	  3	  
FIG. 3.鄰域集合 )(SN 迭代演進圖	  ...........................................................................................	  4	  
FIG. 4. PSO 粒子位置、速度與 PBEST, GBEST 之搜尋示意圖	  ...................................................	  4	  
FIG. 5.當 dgbest 、 idpbset 分別位於 ubx 與 lbx 時之鄰域集合空間	  ...........................................	  5	  
FIG. 6.新架構混合式最佳化演算法系統架構	  .........................................................................	  6	  
FIG. 7. SPHERE 函數之各搜尋次數所得結果平均值	  ................................................................	  8	  
FIG. 8. SPHERE 函數所得結果細部	  ............................................................................................	  8	  
FIG. 9. ROSEN BROCK 函數之各搜尋次數所得結果平均值	  ......................................................	  8	  
FIG. 10.  ROSEN BROCK 函數所得結果細部	  ..............................................................................	  8	  
FIG. 11. GRIEWANK 函數之各搜尋次數所得結果平均值	  .........................................................	  9	  
FIG. 12. GRIEWANK 函數所得結果細部	  .....................................................................................	  9	  
FIG. 13. RASTRIGRIN 函數之各搜尋次數所得結果平均值	  ........................................................	  9	  
 
  
1 
 
  研究目的與文獻探討 
本研究提出使用鄰域概念為架構的混合式演算法，結合 MC、SA 及 PSO 三種臨域最佳
化演算法之特性，藉由鄰域架構及各粒子且依照不同需求適時調整參數，使粒子具有三個
最佳化演算法之特性。透過這三種演算法之特性研究將其各項特質予以分析和解構，並在
鄰域搜尋法的架構下做建構一混合式演算法，可經由調整參數改變特性，如由 MC 調整成
SA；SA 調整成 PSO…等，以達成演算法之融合與漸進可適。本研究探討 MC、SA、PSO 三
個最佳化演算法之特性分析，以及混合式演算法相關特性之關連的研究與架構設計，並完
成混合式最佳化演算法之設計、驗證，期望結合優點改善缺點以面對各種問題，提升演算
效能，並驗證此架構之可行性。 
蒙地卡羅模擬法是一種數值方法，利用亂數取樣 (Random Sampling) 模擬來解決數學
問題[1]。在數學上所謂產生亂數，就是從一開始給定的數集合中選出來的數，若從集合中
不按順序隨機選取其中數，稱為亂數，若是被選到的機率相同時，稱為均勻亂數。蒙地卡
羅模擬法是基於大數法則的實證方法，當實驗的次數越多，期平均值也就會越趨近於理論
值。模擬退火演算法主要的概念是把研究的問題看作成一個統計系統，而統計系統中的某
一個溫度的狀態分佈是滿足一個波茲曼(Boltzmann)分佈函數。因此在問題中尋找最佳化解
時，就是利用這個分佈函數來選取答案。Kirkpatrick 等人在 1983 年提出模擬退火法，並應
用在最佳化問題中，屬於蒙地卡羅演算法的推廣 [2-9] 。PSO 是一個以族群概念為基礎的
群域最佳解搜尋演算法。並且有著演化式計算概念 中常見的特性，如「適應度」(fitness)
的評估。而粒子移動時會往個體最佳經驗(PBEST)或是群體最佳經驗(GBEST)的方向改變。
而粒子在決定移動方向時也加入了「隨機」(randomness)的概念，讓粒子的移動有機會跳脫
目前的趨勢，以免陷入「區域最佳解」(local optimum)。此外，PSO 中的粒子，也就是每個
可能的潛在解，是擁有速度並在整個搜尋空間中「飛行」的， 另外在 PSO 架構下粒子跟
粒子群都有記憶能力。PSO 的另一個重要特點是，只需要簡單的數學運算，並且可以用少
量的程式碼就能在電腦上實作。由於 PSO 運算成本的低廉並且採用了社會行為的模型，許
多實際的應用都已經使用這個技術，多數應用都已被提出並在文獻中展現它是成功的
[10-12]。 
傳統鄰近搜尋法為區域搜尋法（local search），常容易面臨陷入「局部最佳解（Local 
Optimum）」的困境，以致無法搜尋到更好的近似解。為克服此一缺點，1980 年代開始，新
的啟發式解題概念逐漸形成，並造成一股新興的研究風潮。此等新近啟發式方法的主要求解
策略皆為在可行解區域中一步步移動以逐步改善目標函數值，並使演算法具有從局部最佳解
脫離的能力，同時又能向最佳解逼近。 
Hybrid 混合演算法即是結合兩種以上的演算法，結合全域搜尋演算法和鄰域搜尋(local 
search)演算法，一種方法是直接將鄰域搜尋演算法中的 local improvement operator 直接加入全域
搜尋演算法中，使全域搜尋演算法和 local search 演算法結合在一起，在混合式的演算法裡，
鄰域搜尋演算法可以增進得到全域/區域最佳解的效果。目前混合演算法以粒子聚集法(PSO)結
合模擬退火法(SA)[13]與遺傳演算法(GA)結合模擬退火法(SA)[14-17]為較常見，PSO-SA 混合搜
尋法是以搜尋鄰近較佳解的概念，將 SA 的跳躍機制特性引入 PSO 演算法中，所提出混合搜
尋法。而 GA-SA 模擬退火演算法在搜尋全域最佳解的過程中往往需要花費很長的時間。除此
之外，模擬退火演算法只著眼於單一的問題解，因此不易平行化。於是，結合遺傳演算法與
模擬退火演算法的優點，發展出混合式演化演算法以處理最佳化問題的求解便成為一種極具
吸引力的策略。 
 
  
3 
 
蒙地卡羅模擬法之鄰域解集合可表示為：   𝑁!" = {𝑋!!!|𝑋!!! = 𝑠 ∙ 𝑟𝑎𝑛𝑑 1 }  (2) 
開始
初始化 生成初始解 產生新解
是是否達成
結束條件
否
是
是否接受
新解為目前
最佳解
更新目前
最佳解
結束
否
 
Fig. 1.蒙地卡羅模擬法流程圖 
B.  模擬退火法(Simulated Annealing) 
 Kirkpatrick 等人在 1983 年則將蒙地卡羅演算法延伸推廣出模擬退火法，並成功應用於最
佳化問題。不僅可以接受較佳解，也具有一定的機率判斷是否接受一個較差解，因而具有跳
脫出區域最佳解的能力。 
此外模擬退火採用 Metroplis 接受法則，用來決定是否接受一個能量變動的改變。計算目
前解的能量E，以目前解為中心隨機產生新的鄰近解並計算能量 E ʹ′ ， EEE −ʹ′=Δ 為兩個解
之間的能量差，根據下列的機率公式來決定是否接受鄰近解取代目前解： 
𝑃 = 1                , 𝑖𝑓  ∆𝐸 ≤ 0𝑒!∆!!   , 𝑖𝑓  ∆𝐸 > 0 (3) 
退火模擬法在搜尋過程中，經由降溫的程序，其搜尋範圍會逐漸收斂至全域最佳解所在的區
域，進而找出全域最佳解；但若在較低的溫度起始控制下，則需要較多次的迭代才能達到系
統平衡，因為其系統在接受爬昇的機率相對變低，所以需要較多次的跳域才能脫離局部最佳
解的陷阱。由此可得知，較高的起始溫度有較高的遷移率以跳脫出局部最佳解，同時只要降
溫的程序夠慢並有足夠的迭代次數，則可達到熱動平衡。 
否
開始
初始化 生成初始解 產生鄰近解 是否達成結束條件是否降溫
是
是否接受
鄰近解為目前
最佳解
更新目前
溫度
更新目前
最佳解
否
是
是
結束
否
 
Fig. 2. 模擬退火法流程圖 
模擬退火法之主要流程如下： 
1. 針對問題選定目標函數作為能量函數 )(xEX = ，其中的 x便是問題解中所需參數之集
合。 
2. 決定初始參數起始溫度T 、終止溫度、冷卻率(或冷卻值)α ，單一溫度迭代次數。 
3. 設定起始迭代次數 0=t ，產生初始目前解 X 。 
4. 以目前 tx 為中心與擾動範圍 ts ,隨機產生新的鄰近解 X ʹ′。 
)( 1+=ʹ′ txEX  (4) 
其中 )1()
2
(1 rands
sxx t
t
tt ⋅+−=+ ， )1(rand 為一[0,1]隨機所產生的亂數，而 s的初始擾動範
圍為整個結構空間，並同時計算其能量函數值 )( 1+txE 。 
5. 採用 Metroplis 接受法則，使用公式(3)用來決定是否接受鄰近解為目前解。若接受則
5 
 
粒子群聚演算法之鄰域值集合： 
由前文所述，粒子群聚最佳化演算法新的鄰域值𝑥!"!!!是以前一點𝑥!"! 為起點與速度v!"!!!相
加所產生。速度𝑣!"!!!代表搜尋的步幅大小，這個速度由各體本身經驗與同伴飛行經驗𝑔𝑏𝑒𝑠𝑡!"，
藉由亂數𝑟!!與𝑟!!及加速係數𝑐!與𝑐!進行動態調整。 
各粒子移動步幅範圍(速度的上限與下限)則可以下式表示： X!" = max v!"!!! = max w!v!"! + c!r!! pbest!" − x!"! + c!r!! gbest!" − x!"!   X!" = min v!"!!! = min w!v!"! + c!r!! pbest!" − x!"! + c!r!! gbest!" − x!"!  (8) (9) 
由於 PSO 中的粒子是追隨𝑝𝑏𝑒𝑠𝑡!"及x!"! 兩個極值來更新下一步搜尋之速度及位置，故在考慮
兩極值對 PSO 演算法佔有極大的影響力下，分別根據兩極值提出兩種混合策略，鄰域集合
範圍由𝑝𝑏𝑒𝑠𝑡!"及x!"! 之差所控制，當x!"! 越接近𝑝𝑏𝑒𝑠𝑡!"及x!"! 時，則鄰域集合範圍越小。 
研究方法及最佳化演算法架構 
本研究將以鄰域概念整合蒙地卡羅演算法(MC)、模擬退火演算法(SA)與粒子群聚最佳化
演算法(PSO)三個演算法，並融合特性。解構蒙地卡羅演算法(MC)、模擬退火演算法(SA)與粒
子群聚最佳化演算法(PSO)對鄰域集合空間的範圍，可以歸納如下： 𝑁!" = 𝑥!!! 𝑥!!! = 𝑠 ∙ 𝑟𝑎𝑛𝑑 1   𝑁!" = 𝑥!!! 𝑥!!! = 𝑥! − !!! + 𝑠! ∙ 𝑟𝑎𝑛𝑑 1 , 𝑠!!! = 𝑠 ∙ 𝛽! ,𝛽 ∈ 0,1   𝑁!"# = {𝑥!!!! |𝑥!"!!! = 𝑥!"! + 𝑣!"!!!, 𝑣!"!!!𝑤!𝑣!   ! + 𝑐!𝑟!! 𝑝𝑏𝑒𝑠𝑡!" − 𝑥!"! + 𝑐!𝑟!! 𝑔𝑏𝑒𝑠𝑡!" − 𝑥!"!   
其中𝑁!"、𝑁!"、𝑁!"!依序為解構蒙地卡羅演算法(MC)、模擬退火演算法(SA)與粒子群聚
最佳化演算法(PSO)對鄰域集合空間的範圍。 
由𝑁!" = 𝑥!!! 𝑥!!! = 𝑥! − !!! + 𝑠! ∙ 𝑟𝑎𝑛𝑑 1 , 𝑠!!! = 𝑠 ∙ 𝛽! ,𝛽 ∈ 0,1 ，演化公式成為： 
    𝑥!!! = 𝜓! 𝑥! − !!! + 𝑠! ∙ 𝑟𝑎𝑛𝑑 1 , 𝑠!!! = 𝑠 ∙ 𝛽! ,𝛽 ∈ 0,1   
當𝜓! = 0,𝛽 = 1時 
    𝑠!!! = 𝑠 ∙ 1! = 𝑠  
    𝑥!!! = 0 ∙ 𝑥! − !!! + 𝑠! ∙ 𝑟𝑎𝑛𝑑 1   
        = 𝑠 ∙ 𝑟𝑎𝑛𝑑 1   
與蒙地卡羅演算法之鄰域解相同，故可整合蒙地卡羅演算法與模擬退火演算法之鄰域為： 𝑁!"#$% =   {𝑥!!!|𝑥!!! = 𝜓! 𝑥! − !!! + 𝑠! ∙ 𝑟𝑎𝑛𝑑 1 ,𝜓! = 0,1 , 𝑠!!! = 𝑠 ∙ 𝛽! ,𝛽 ∈ 0,1 }  (10) 
 
Fig. 5.當 dgbest 、 idpbset 分別位於 ubx 與 lbx 時之鄰域集合空間  
 
由 Fig. 5 中可以發現，粒子群最佳化演算法之鄰域集合空間，當 dgbest 、 idpbset 分別位於
ubx 與 lbx 時，其鄰域集合空間與模擬退火演算法之鄰域集合空間相似，故推導其公式如下： 𝑥!"!!! = 𝑥!"! + 𝑣!"!!! 𝑣!"!!! = 𝑤!𝑣!"! + 𝑐!𝑟!! 𝑝𝑏𝑒𝑠𝑡!" − 𝑥!"! + 𝑐!𝑟!! 𝑔𝑏𝑒𝑠𝑡!" − 𝑥!"!                      = 𝑤!𝑣!"! + 𝑐!𝑟!! 𝑥!" − 𝑥!"! + 𝑐!𝑟!! 𝑥!" − 𝑥!"!  
(11) 
 
(12) 
設𝑤! = 0, 𝑐! = 𝑐! = 1 
7 
 
2. 深化策略：當 11 =ψ 時，增加粒子區域搜尋的能力，再藉由全體與個體暫時最佳解
( dub gbestx = , idlb pbsetx = )，改變各粒子搜尋的方向，使粒子能追隨暫時最佳經驗的導引，
提升區域搜尋的效果。 
III.  鄰近解更新策略 
鄰近解更新策略是依照選定鄰域(Neighborhood)區域，各粒子將藉由亂數產生新的粒子位
置並移動(Move)至新解位置求得適應值，並依據接受法則(Acceptance Rule)針對適應值不佳者
於以拒絕或針對適應值不佳者根據機率判斷是否接受，產生新的鄰域解，一直迭代至滿足終
止條件為止。 
成果及驗證 
本研究初期選擇經常使用的四個 Benchmark 函數問題進行數值實驗，並根據函數性質分
為具有單一極小點（單模態）和多個局部極小點（多模態）兩大類，每類兩個函數，如 Table 
1 所示。 
Table 1. Benchmark Function 
Function Name Dim Search Space 
Min/Best 
posi t ion 
∑
=
=
n
i
ixf
2
2
1  Sphere 30 (-100,100)
N 0 / (0,…0) 
∑
=
+ −+−=
n
i
iii xxxf
1
222
12 ))1()(100(  Rosen Brock 30 (-50,50)
N 0 / (1,…1) 
1cos
4000
1
1 1
2
3 +⎟⎟
⎠
⎞
⎜⎜
⎝
⎛
−= ∑ ∏
= =
n
i
n
i
i
i
i
x
xf  Griewank 30 (-300,300)N 0 / (0,…0) 
∑
=
=+−=
n
i
ii AAxAxf
1
2
4 10),)2cos(( π  Rastrigrin 30 (-5.12,5.12)
N 0 / (0,…0) 
Table 1 中，函數 21 ~ ff 是單極值函數， 43 ~ ff 則為多極值函數。函數 43 ~ ff 是典型的非
線性多模態函數。它們具有廣泛的搜索空間、大量的區域極小點和高大的障礙物，通常被認
為優化算法很難處理的複雜多模態問題。本研究採用上面四個測試函數，在統一的標準下，
藉由相同的代數（時間）來測試所提出的密度導向粒子群演算法與以前所提出的粒子群演算
法相比，測試是否有在相同代數下，有更佳的解（最小值）。 
I.  驗證結果 
 我們使用了上述之四個驗證函數來驗證新式混合演算法，以每次搜尋 10 、100 、500 、
1000 次搜尋為限， 取其各次最佳值之平均，以圖表表示其搜尋解收斂走向，Table 3、4、5、
6 及 Fig. 7、9、11、13 依序為使用 Sphere、Rosen Brock、Griewank、Rastrigrin 驗證函數所得之
數據。 
如 Table 2 數據所示，因 PSO 在各搜尋次數之收斂速度在三個演算法之中皆最快，而混合
演算法之優勢來自三個演算法之特性，所以 Hybrid 之數據趨近於 PSO。  
  Table 2. Sphere 函數之各搜尋次數所得結果平均值 
 
MC SA PSO Hybrid 
10 次 6.1698 7.8873 0.5026 0.5003 
100 次 0.7289 0.0002 0 0 
500 次 0.0833 0 0 0 
1000 次 0.0117 0 0 0 
9 
 
由 Table 3 之數據在初始時 PSO 收斂速度最佳，但由 100 次之數據發現中段時收斂速度為
SA 較佳，所以我們將混合演算法之初始階段設定為 PSO，中段接 SA 快速收斂，最後再轉回
PSO 做深度搜尋。 
Table 4. Griewank 函數之各搜尋次數所得結果平均值 
 
MC SA PSO Hybrid 
10 次 0.19979 0.38486 0.11044 0.11606 
100 次 0.02298 0.03177 0.00347 0.0034 
500 次 0.00195 0.00193 0.00094 0.00079 
1000 次 0.00016 0.00162 0.00055 0.00006 
 
Fig. 11. Griewank 函數之各搜尋次數所得結果平均值 
 
Fig. 12. Griewank 函數所得結果細部 
Table 5. Rastrigrin 函數之各搜尋次數所得結果平均值 
 
MC SA PSO Hybrid 
10 次 1.28469 1.94598 0.36256 0.36373 
100 次 0.35315 0.10758 0 0 
500 次 0.03692 0.002 0 0 
1000 次 0.00246 0.00099 0 0 
 
Fig. 13. Rastrigrin 函數之各搜尋次數所得結果平均值 
0	  
0.05	  
0.1	  
0.15	  
0.2	  
0.25	  
0.3	  
0.35	  
0.4	  
0.45	  
10次	   100次	   500次	   1000次	  
最
佳
解
平
均
值
搜尋次數
Griewank函數各搜尋次數所得最佳解之平均值
MC	  
SA	  
PSO	  
Hybrid	  
0	  
0.0002	  
0.0004	  
0.0006	  
0.0008	  
0.001	  
10	   100	   500	   1000	  
最
佳
解
平
均
值
搜尋次數
Griewank函數各搜尋次數所得最佳解之平均值
MC	  
SA	  
PSO	  
Hybrid	  
0	  
0.5	  
1	  
1.5	  
2	  
10次	   100次	   500次	   1000次	  
最
佳
解
平
均
值
搜尋次數
Rastrigrin函數各搜尋次數所得最佳解之平均值
MC	  
SA	  
PSO	  
Hybrid	  
A Low-Complexity And High-Performance Hybrid 
Problem Solving Method  
Besed On Neighborhood Search Algorithms 
Chih-ming Kung, Guan-Zhou Chen 
Dept. of Information Technology & Communication,  
Shih Chien University, Taiwan. 
alex@mail.kh.usc.edu.tw, alex@cvig.org 
Shu-Tsung Chao, Wei-Sheng Yang, Li-Min Chuang  
Graduate School of Business and Operations Management, 
Chang Jung Christian University, Taiwan. 
{james, weiboy}@cvig.org, liming@mail.cjcu.edu.tw 
Abstract— Despite many algorithms have been proposed over 
the past few decades, it still play a very important role for 
various types of improved hybrid algorithm. Due to the 
complexity of the problem, many algorithms including 
Simulated Annealing, Partical Swarm Optimization, and 
Monte Carlo have been proposed for searching better solution 
of NP-complete problem in reasonable computation time. The 
aim of this research is to make a study and an analysis of the 
above optimal algorithms in order to find out the advantage 
and processing features of these approaches which were 
summarized and extracted the characteristics and essence of 
the various algorithms. Then to integrate and reconstruct a 
new algorithm framework which is the combination of the 
processing solution of neighborhood search and moving. 
Therefore, the performance of our new algorithm framework 
could be able to greatly enhance. Believe that such a new 
algorithm framework not only can enhance the performance of 
algorithms but also help to cope with the diversity and 
complexity of problem solving.  
Keywords- Neighborhood, Hybrid, MC, SA, PSO  
I.  INTRODUCTION  
From the analysis of relevant literature, many algorithms 
have been proposed over the past few decades. It can be 
found that most previous studies made a hybrid algorithm 
from these algorithms mentioned above, to make up the 
shortcomings of a single algorithm for each other, such as 
Simulated Annealing (SA) with the Genetic Algorithm (GA) 
or Partical Swarm Optimization (PSO) with GA. The aim of 
this study is to improve the specially weakness of the 
algorithm by the advantage of another algorithm. 
This research is to make a study and analysis of these 
algorithms including PSO, SA, GA, and MC in order to find 
the advantage and processing of their approaches which were 
summarized and extracted the characteristics and essence of 
the various algorithms. Then to integrate and reconstruct an 
adaptability and robustness of new algorithm framework 
which is the combination of the processing solution of 
neighborhood search and moving. The present study 
integrates the neighborhood characteristics and reconstructs 
the neighborhood architecture of these algorithms to break 
through this limitation and improve the solving efficiency. 
According to the period of PSO, MC, SA, the parameters 
will be converted. By adjusting the parameters, the algorithm 
can be adaptive for searching better solution of NP-complete 
problem in reasonable computation time. 
II. REVIEW OF THE LITERATURE AND DISCUSSION 
A. Monte Carlo Algorithm 
The Monte Carlo method was invented by scientists 
working on the atomic bomb in the 1940s, who named it for 
the city in Monaco famed for its casinos and games of 
chance.  Its core idea is to use random samples of 
parameters or inputs to explore the behavior of a complex 
system or process.  The scientists faced physics problems, 
such as models of neutron diffusion that were too complex 
for an analytical solution, so they had to be evaluated 
numerically.  They had access to one of the earliest 
computers but their models involved so many dimensions 
that exhaustive numerical evaluation was prohibitively 
slow.  Monte Carlo simulation has been proved to be 
surprisingly effective at finding solutions to these 
problems.  Since that time, the Monte Carlo method has 
been applied to an incredibly diverse range of problems in 
science, engineering, finance, and business applications in 
virtually every industry. 
In 1949, the term of “Monte Carlo method” was 
proposed by J. Neyman and S. Ulamʳ[1]. In 1953, Metropol˼s 
proposed Monte Carlo algorithm [2]. Monte Carlo method is 
used to solve the mathematical problem by random sampling. 
B. Simulated Annealing 
The Metropolis Monte Carlo integration algorithm 
(Metropolis et al, 1953) was generalized. Simulated 
Annealing (SA) [3-6] is extended from the Monte Carlo 
algorithm. In 1983, Simulated Annealing is proposed by 
Kirkpartrick [7]. Simulated annealing is an optimization 
technique that simulates the physical annealing process in the 
field of combinatorial optimization. Annealing is the 
physical process of heating up a solid until it melts, followed 
by slow cooling it down by decreasing the temperature of the 
environment in steps. At each step, the temperature is 
maintained constant for a period of time sufficient for the 
solid to reach thermal equilibrium. 
A standard SA procedure begins by generating an initial 
2011 International Conference on Fuzzy Systems and Neural Computing 
978-1-4244-9216-9/11/$26.00 ©2011 IEEE                                                          FSNC 2011 
 
282
Boltzmann's probability distribution, to calculating the 
energy of the current solution E. The current solution 
randomly generated for the center “nearby” solution and 
calculates the energy E c , EEE c '  is the energy 
difference between the two solutions, according to the 
following formula to decide whether to accept the probability 
of nearby solution to replace the current solution:  
°¯
°®
­
!'
d'
 '
0 ,
0 ,1
Eife
Eif
P
T
E  (3)
If the center is tx with the range of disturbance randomly 
bring X c of  neighborhood  solution. 
 
)(' 1 txEX  (4) 
where Xt+1= (
2
t
t
sx  )+St Σrand(1), rand (1) is the only 
[0,1] random number, while the s range of the initial 
disturbance is the structural space, and calculated the value 
of energy function values E( 1tx ). 
By (2), the new neighborhood xt+1 of SA is randomly 
generated for the center tx  and the range of disturbance St. 
)()1()
2
(1 SNrands
sxx tttt    (5) 
where ttt SSS EE u u 1 , ]0,1[E , we may choose the 
neighborhood 1tx . 
The two basic equations which govern the working of 
PSO are that of velocity vector and position vector given by: 
)()( 2211
1 k
idd
dk
idid
dk
idi
k
id xgbestrcxpbsetrcvwv   (6)
k
id
k
id
k
id vxx  1 (7)
where k is the sub-algebra, d is the dimensional space, 
idpbset represent to the best location of the particle j at the 
time t, and dgbset represent to the best location of entire 
particle swarm in the time t. c1 and c2 represent the 
individuality and sociality coefficient, dr1 and
dr2  represent 
the random numbers, iw is the inertia weight. 
 
Figure 2.  PSO diagram 
According to Eq. (2), the new neighborhood value of 
PSO, kidv  represent the scope of search domain, it can be 
revision by pbestid, gbestd, c1, c2, dr1 and
dr2 .  
This study integrate the concept of MC, SA and PSO 
characteristics of algorithm, that spatial range of 
neighborhood set can be summarized as follows:  
)}1(|{ 11 randsxxN ttmc     ʻ8ʼ 
]}1,0[,
),1()
2
(|{ 111
u 
  
EE t
tt
t
tttsa
s
srandssxxxN
 
ʻ9ʼ 
)()(
,|{
2211
111
1
k
idd
dk
idid
dk
idi
k
id
k
id
k
id
k
id
d
tpso
xgbestrcxpbsetrcvw
vvxxxN
 
  
 
ʻ10ʼ 
where Nmc, Nsa, Npso are the neighborhood domain of Monte 
Carlo, Simulated Annealing, Particle Swarm Optimization. It 
can be integrated the neighborhood of PSO, SA and MC: 
1
1
1  u kidkidkid vxx \  ʻ11ʼ
)()(                   
))(
2
1(
2211
11
k
idub
dk
idlb
d
lbub
k
idi
k
id
xxrcxxrc
xxvwv

  \
 
ʻ12ʼ
From research results we have inferred as follows: 
1) MC is exceptional performance for SA, SA has 
convergence of neighborhood. If SA has no convergence 
and no change of searching scope, the neighborhood of 
MC will be the same. 
2) Using the concept of neighborhood re-deconstruct which 
MC, SA and PSO of algorithm, and combined with three 
kinds of algorithms to construct a new architecture such 
as the Eq. (11) and Eq.(12). 
3) Where the pbest, gbest of PSO extreme each other with 
the current solution( kidx - idpbset = dgbset -
k
idx ). The 
neighborhood set is the same as PSO and SA, it can be as 
the special case of  PSO‘s neighborhood set. 
 
The new system architecture of algorithm is different 
from local search. Where the neighborhood optimum is 
worse than local optimum in searching, the neighborhood 
optimum will be the new solution. Therefore, it will have the 
chance to search the global optimum. The elements of search 
include three sections: 
1) Initial solution : Set the initial solution to theinitial value. 
2) Neighborhood solution : According to the definition of 
neighborhood solution, the neighborhood solution set 
will be generated by present solution. 
3) Move and update : Choose the best solution to move and 
update in all of neighborhood solution. 
 
Figure 3.  New system architecture of hybrid algorithm 
284
A Hybrid Algorithms of Low-Complexity And High-Performance  
Besed On Neighborhood Search Method 
Chih-ming Kung  
Dept. of Information Technology & Communication /Shih Chien University 
Tainan City 
alex@mail.kh.usc.edu.tw 
Wei-sheng Yang 
Dept. of Information Management/Chang Jung Christian University 
Tainan Country
 
Abstract—Despite many algorithms have been proposed over 
the past few decades, it still play a very important role for 
various types of improved hybrid algorithm. Due to the 
complexity of the problem, many algorithms including 
Simulated Annealing, Partical Swarm Optimization, and 
Monte Carlo have been proposed for searching better solution 
of NP-complete problem in reasonable computation time. The 
aim of this research is to make a study and an analysis of the 
above optimal algorithms in order to find out the advantage 
and processing features of these approaches which were 
summarized and extracted the characteristics and essence of 
the various algorithms. Then to integrate and reconstruct a 
new algorithm framework which is the combination of the 
processing solution of neighborhood search and moving. 
Therefore, the performance of our new algorithm framework 
could be able to greatly enhance. Believe that such a new 
algorithm framework not only can enhance the performance of 
algorithms but also help to cope with the diversity and 
complexity of problem solving. 
Keywords- Neighborhood, Hybrid, MC, SA, PSO  
I.  INTRODUCTION  
From the analysis of relevant literature, many algorithms 
have been proposed over the past few decades. It can be 
found that most previous studies made a hybrid algorithm 
from these algorithms mentioned above, to make up the 
shortcomings of a single algorithm for each other, such as 
Simulated Annealing (SA) with the Genetic Algorithm (GA) 
or Partical Swarm Optimization (PSO) with GA. The aim of 
this study is to improve the specially weakness of the 
algorithm by the advantage of another algorithm. 
This research is to make a study and analysis of these 
algorithms including PSO, SA, GA, and MC in order to find 
the advantage and processing of their approaches which were 
summarized and extracted the characteristics and essence of 
the various algorithms. Then to integrate and reconstruct an 
adaptability and robustness of new algorithm framework 
which is the combination of the processing solution of 
neighborhood search and moving. The present study 
integrates the neighborhood characteristics and reconstructs 
the neighborhood architecture of these algorithms to break 
through this limitation and improve the solving efficiency. 
According to the period of PSO, MC, SA, the parameters 
will be converted. By adjusting the parameters, the algorithm 
can be adaptive for searching better solution of NP-complete 
problem in reasonable computation time. 
II. REVIEW OF THE LITERATURE AND DISCUSSION 
A. Metropolis Monte Carlo Algorithm 
The Monte Carlo method was invented by scientists 
working on the atomic bomb in the 1940s, who named it for 
the city in Monaco famed for its casinos and games of 
chance.  Its core idea is to use random samples of 
parameters or inputs to explore the behavior of a complex 
system or process.  The scientists faced physics problems, 
such as models of neutron diffusion that were too complex 
for an analytical solution, so they had to be evaluated 
numerically.  They had access to one of the earliest 
computers but their models involved so many dimensions 
that exhaustive numerical evaluation was prohibitively slow.  
Monte Carlo simulation has been proved to be surprisingly 
effective at finding solutions to these problems.  Since that 
time, the Monte Carlo method has been applied to an 
incredibly diverse range of problems in science, engineering, 
finance, and business applications in virtually every industry. 
In 1949, the term of “Monte Carlo method” was 
proposed by J. Neyman and S. Ulam [1]. In 1953, 
Metropolis proposed Monte Carlo algorithm [2]. Monte 
Carlo method is used to solve the mathematical problem by 
random sampling. 
B. Simulated Annealing 
The Metropolis Monte Carlo integration algorithm 
(Metropolis et al, 1953) was generalized. Simulated 
Annealing (SA) [3-6] is extended from the Monte Carlo 
algorithm. In 1983, Simulated Annealing is proposed by 
Kirkpartrick [7]. Simulated annealing is an optimization 
technique that simulates the physical annealing process in the 
field of combinatorial optimization. Annealing is the 
physical process of heating up a solid until it melts, followed 
by slow cooling it down by decreasing the temperature of the 
environment in steps. At each step, the temperature is 
using until now [12-14]. But the Meta-heuristics take the 
traditional heuristic method as the core architecture, 
combined with high search strategy, let algorithm can jump 
out local optimum [15]. Table I is the comparison of the 
optimal algorithm.  
III. RESEARCH METHODS 
This study is focus on two issues, first is how quickly and 
widely to search in any solution domain, and find out the 
approximate optimal solution in the son of the solution 
domain. Second, how quickly and widely to solve in solution 
domain and avoid getting a trouble in local optimum.  The 
new algorithm keeps on quality and speed.  
In this study, from neighborhood features to integrate 
ideas, developed into a Neighborhood Architecture of the 
hybrid optimization algorithm, and for the proposed 
algorithm to study and discuss, than compare with traditional 
algorithm, from comparing the test function to find the 
algorithmic parameter settings. Neighborhood definitions 
can be expressed as follows: 
EFmELet 2},,...2,1{ ⊆= and ℜ→FfLet :   
Combinatorial optimization problem (COP) 
Minimize }:)({ FSSf ∈   
EFN 2: →  (1) 
Where E2 is the subset of all E’s sets, F is a feasible 
solution, f is the objective function, S is feasible set, N is a 
neighborhood function, for each FS ∈ , N(S) is a subset of  
E, N(S) become feasible solution S of neighborhood. 
MC often used in optimization of various fields. This 
method is mainly based on the Boltzmann’s probability 
distribution function to help select the best solution. It’s the 
neighboring solutions can be expressed as: 
)}1(|{ 11 randsxxN ttmc ⋅== ++  (2) 
 
 
Figure 2.   SA Flow diagram 
SA is different from other algorithms; it has probability 
to judge the solution which is poor or optimal, and leave out 
the local optimal to global optimal. SA only deal with non-
contain restrained conditions of optimization algorithms, so 
it need for an infinitely long time to stabilize find the global 
optimum, Aarts [16] in 1989 proposed parallel computation 
to speed up search of SA. 
 
Metropolis criterion is used to decide whether to accept a 
change in the energy changes. At a particular temperature T, 
each specifically atomic probability of existence that show 
Boltzmann's probability distribution, to calculating the 
energy of the current solution E. The current solution 
randomly generated for the center “nearby” solution and 
calculates the energy E ′ , EEE −′=Δ  is the energy 
difference between the two solutions, according to the 
following formula to decide whether to accept the probability 
of nearby solution to replace the current solution:  
⎪⎩
⎪⎨
⎧
>Δ
≤Δ= Δ−
0 ,
0 ,1
Eife
Eif
P
T
E  (3) 
SA method is simple and operation is as follows: 
1) Chose the objective function for the problem, X=E (x). 
2) Let the initial paramete: temperature T, end 
temperature, cooling rate α , single-temperature 
iteration. 
3) Set the initial iteration t = 0, generate an initial 
current solution X . 
4) as the center tx with the range of disturbance randomly 
bring X ′ of  neghborhood  solution. 
)( 1+=′ txEX    (4) 
Where Xt+1= (
2
t
t
s
x − )+St ∙rand(1), rand (1) is the 
only [0,1] random number, while the s range of the 
initial disturbance is the structural space, and calculated 
the value of energy function values E( 1+tx ). 
5) With Metropolis Acceptance Rule, and use (1) to 
determine whether accept the neghborhood solution to 
be the current solution. If it accept X=X', t = t +1. 
6) Determine whether reache to the iterations, if yes , 
reduce temperature t = 0. There two ways of reduce 
temperature methods, one is T = ×α T, ]0,1[∈α , 
another is T = T α− , <α 0. 
7) Reduce the range of disturbanc St+1=St β×  , ]0,1[∈β . 
8) Determine temperature whether be terminated, 
otherwise return to Step 4and re-run. 
9) The final solution X. 
By (2), the new neighborhood 1+tx of SA is randomly 
generated for the center tx  and the range of disturbance St. 
)()1()
2
(1 SNrands
sxx tttt ∈⋅+−=+  (5) 
Where ttt SSS ββ ×=×=+1 , ]0,1[∈β , we may choose 
the neighborhood 1+tx . Figure 3 is neighborhood 1+tx . 
4) Untill meet the rule of the end, ended PSO. 
5) Using equation (6) and (7) to update each particle's 
velocity and position. Back to step 2. 
According to Eq. (7), the new neighborhood value of 
PSO, kidv  represent the scope of search domain, it can be 
revision by  pbestid , gbestd, ,c1, c2, dr1 and
dr2 .  Fig. 6 is 
neighborhood set. Which kidx is closed to pbestid and gbestd, 
the range of neighborhood set is smaller, as Fig. 7(B). 
1
)96,112(),80,64(
),32,16(),0,0(
211 ===
==
==
ccw
gbestpbset
vx
did
k
id
k
id
 1
)96,112(),80,64(
),0,16-(),128,64(
211 ===
==
==
ccw
gbestpbset
vx
did
k
id
k
id
(A) (B) 
Figure 7.  Neighborhood set 
This study integrate the concept of MC, SA and PSO 
characteristics of algorithm, that spatial range of 
neighborhood set can be summarized as follows:  
)}1(|{ 11 randsxxN ttmc ⋅== ++  (8) 
]}1,0[,
),1()
2
(|{ 111
∈×=
⋅+−== +++
ββ t
tt
t
tttsa
s
srands
s
xxxN
 
(9) 
)()(
,|{
2211
111
1
k
idd
dk
idid
dk
idi
k
id
k
id
k
id
k
id
d
tpso
xgbestrcxpbsetrcvw
vvxxxN
−+−+=
+== ++++
 
(10) 
Where Nmc, Nsa, Npso are the neighborhood domain of 
Monte Carlo, is Simulated Annealing, is Particle Swarm 
Optimization. Eq.(9)  extend  as follows: 
)1()
2
(11 rands
s
xx t
t
tt ⋅+−=+ ψ , ]1,0[,1 ∈×=+ ββ tt ss  
If 01 =ψ , 1=β  
)1()1()
2
(0
1
1
1
randsrands
s
xx
sss
t
t
tt
t
t
⋅=⋅+−×=
=×=
+
+
 
As the same of MC’s neighboring solutions, it can be 
integrated SA and MC neighborhood of algorithm. 
]}1,0[,},1,0{
),1()
2
(|{
11
111temp1
∈×==
⋅+−==
+
++
ββψ
ψ
t
t
t
t
ttt
ss
rands
s
xxxN
(11)
 
 
Figure 8.  When dgbset , idpbset are located in ubx and lbx ,the scope 
of neighborhood set 
As Fig. 8, PSO’s scope of the neighborhood set can be 
found, when the dgbset and idpbset  are located in ubx and lbx . 
The scope of neighborhood set is similar with SA, so 
derivation of the formula as follows:  
11 ++ += kidkidkid vxx  (12)
)()(
)()(
2211
2211
1
k
idub
dk
idlb
dk
idi
k
idd
dk
idid
dk
idi
k
id
xxrcxxrcvw
xgbestrcxpbsetrcvwv
−+−+=
−+−+=+
(13)
Set iw =0, 1c = 2c =1 
 
)()(
)()(0
)(1)(10
21
21
21
1
k
idub
dk
idlb
d
k
idub
dk
idlb
d
k
idub
dk
idlb
dk
id
k
id
xxrxxr
xxrxxr
xxrxxrvv
−+−×=
−+−×+=
−×+−×+×=+
(14)
ub
d
lb
dk
id
dk
id
dk
id
k
idub
dk
idlb
dk
id
k
id
xrxrxrxrx
xxrxxrxx
×+×+×−×−=
−×+−×+=+
2121
21
1 )()(
 
(15)
For the scope of SA’s neighborhood set, s= ubx lbx− , 
ubx =
k
idx + 2
s , lbx =
k
idx - 2
s  
xub 
xlb 
xlb 
xub 
 
According to the chosen of neighborhood domain, the 
neighborhood solution will be update. The particles move 
position by the new particles of randomly generated, and get 
fitness value by the new position of solution. According to 
Acceptance Rule, the fitness value will reject or accept the 
poor fitness value by probability. Figure.9 is the new system 
architecture of hybrid algorithm. 
B. Generated strategies of neighborhood sets  
Search method can be improved performance by the 
strategy of intensification and diversification.  Intensification 
is enhanced the search method in previous results. Different 
from the intensification, diversification is widely search in 
the region of less searching. Therefore, two kinds of 
strategies may have search more good solutions in a range of 
a new region. Eq.(17) and Eq. (18) are the generated strategy 
of neighborhood sets. The main purpose is providing of the 
directional guidance in PSO searched, and solved by iterative 
process has become highlighted condition, in order to 
provide the particles to conduct the next time searching 
direction. r It mainly consists of global search and local 
search in updating parameter. There are two parts steageies. 
1) Diversification  strategy:  
Where 01 =ψ , 1=β , 0=iw , 121 == cc , 
2
,
2
, sxxsxxxxs kidlb
k
idublbub −=+=−=  
Increasing the algorithm capability of full search to 
avoid to quickly convergence of the particle swarm 
search in the local optimum. 
2) Intensification Strategy : Where 11 =ψ   , increasing 
the capability of particle region Search to  change the 
direction of particle search by the best solution of 
global and personal ( , ),the particles can follow the 
experience of being the best guide to improve local 
search results. 
 
This study selected four frequently Benchmark to run 
numerical experiments for algorithm validation and 
performance assessment. According to characteristic of 
function be divided into with a single minimum point (single 
mode) and a number of local minimum points (multi-modal) 
two categories, each category of two functions, as shown in 
Table II.  
TABLE II.  BENCHMARK FUNCTION 
Function Name Dim 
Search 
Space 
Min/Best 
position 
∑
=
=
n
i
ixf
2
2
1
 
Sphere 30 (-100,100) 0 /(0,…0) 
∑
=
−+−+=
n
i
ixixixf
1
)2)1(2)21(100(2
 
Rosen Brock 30 (-50,50)N 0 /(1,…1) 
1cos
4000
1
1 1
2
3 +⎟⎟⎠
⎞⎜⎜⎝
⎛−= ∑ ∏
= =
n
i
n
i
i
i i
x
xf
 
Griewank 30 (-300,300) 0 /(0,…0) 
10,
))2cos((
1
2
4
=
+−=∑
=
A
AxAxf
n
i
ii π  Rastrigrin 30 (-5.12,5.12) 0 /(0,…0) 
In this study, this test functions in a unified standard, 
through the same algebra (time) to test the proposed hybrid 
optimization algorithm, compared with traditional types of 
algorithms, that to test whether is under the same of algebra 
has a better solution (minimum). 
 
IV. EXPERIMENTAL RESULTS 
In this study, we use PSO, SA, MC, Hybrid algorithms 
to search the best solution in Benchmark Function.  Shown 
as Figure 10, the purple line - All represent the experiment 
results of our Hybrid algorithm, we can find out that our 
hybrid algorithm obtain better results than the other 
algorithms on four benchmark functions. According to the 
experimental results shown in Figure 10, which shows that 
our Hybrid algorithm could improve the search result very 
well.We have the conclusion. If we don’t consider the 
solution at present, MC is exceptional performance for SA. 
If SA has no convergence and no change of searching scope, 
the neighborhood of MC will be the same. By the concept of 
neighborhood, to re-deconstruct which MC, SA and PSO of 
algorithm, and combine with three kinds of algorithms to 
construct a new algorithm.                                                                            
In this study, we know that many algorithms have been 
proposed about PSO, MC, SA over the past few decades. 
And it can be found that most previous studies made up the 
shortcomings of a single algorithm for each other. The aim 
of this study is to improve the specially weakness of the 
algorithm by the advantage of another algorithm, and 
propose the new system architecture of algorithm for PSO, 
MC, SA. It integrates the algorithms about MC, SA, PSO 
and reconstructs a new algorithm framework which is the 
combination of the processing solution of neighborhood 
search and moving. The study integrates the neighborhood 
characteristics and reconstructs the neighborhood 
architecture of these algorithms to break through this 
limitation and improve the solving efficiency. The new 
algorithm framework not only can enhance the performance 
of algorithms but also help to cope with the diversity and 
complexity of problem solving. 
V. REFERENCES 
[1] N. Metropolis and S. Ulam,”The Monte Carlo Method,”Journal of the 
American Statistical Association,Vol.44,No.247,pp.335-341,Sep.1949. 
[2] N. Metropolis A. W. Rosenbluth, M. N. Rosenbluth,A. 
H. Teller, “Equations of state  calculations by fast 
compuing machines,”Jourmal of Chamical 
Physics,Vol.21pp.1087-1092,1953 
[3] Yao, Xin, "New simulated annealing algorithm," 
International Journal of Computer Mathematics, Vol.56, 
No.3-4, pp.161-168, 1995. 
[4] V. Fabian, "Simulated annealing simulated," Computers 
& Mathematics with Applications, Vol. 33, No.1-2, pp. 
81-94, 1997. 
[5] J. Haddock, and J. Mittenthal, "Simulation optimization 
using simulated annealing", Computers & Industrial 
Engineering, Vol. 22, No.4, pp. 387-395, Oct, 1992. 
[6] F. Yang, Z. Zhuang, Y. Dai, "Using simulated 
annealing," Proceedings of the International Conference 
 
 
國科會補助專題研究計畫項下出席國際學術會議心得報告 
                                    日期：100 年 7 月 1 日 
                                 
一、參加會議經過 
    2011 神經網路與模糊系統國際學術會議 (FSNC 2011)與 2011 第二屆高性能網
路、計算與通訊系統暨計算機科學理論及數學基礎國際研討會(ICHCC-ICTMF 2011)
分別於 2 月 20-21 日在中國香港與五月 5-6 日在新加坡召開。會議分別由國際智能
信息技術應用學會（IITA）、IEEE 、 Springer 合作主辦。會議論文集將分別由 IEEE
出版社與 Springer 出版集團出版，所有錄取的論文將被 EI 和 ISTP 檢索。優秀論文
計畫編號	 NSC99-2221-E-158-007	 
計畫名稱	 鄰域搜尋架構整合最佳化演算法	 
出國人員姓名	 龔志銘	 
服務機構及
職稱	 
實踐大學	 資訊科技與通訊學系	 
助理教授	 
會議時間	 
100 年 2 月 20 日
至	 
100 年 2 月 21 日	 
會議地點	 香港	 
會議名稱	 
2011	 International	 Conference	 on	 Fuzzy	 Systems	 and	 Neural	 Computing	 
(FSNC	 2011)	 
發表論文題目	 
A	 Low-Complexity	 And	 High-Performance	 Hybrid	 Problem	 Solving	 
Method	 Based	 On	 Neighborhood	 Search	 Algorithms	 
會議時間	 
100 年 5 月 5 日	 
至	 
100 年 5 月 6 日	 
會議地點	 新加坡	 
會議名稱	 
2011	 International	 Conference	 on	 Theoretical	 and	 Mathematical	 
Foundations	 of	 Computer	 Science	 (ICHCC-ICTMF	 2011)	 
發表論文題目	 
Image	 Enhancement	 using	 the	 Multi-scale	 Filter	 :	 Application	 of	 	 the	 
bilateral	 filtering	 scheme	 and	 PSO	 algorithm	 
附件五 
二、與會心得 
首先感謝國科會計畫對於這次國際會議研究計畫的經費補助和支持，除了吸收
世界各地優秀學者所提供的研究資訊之外，對於這種直接面對面交流與觀摩的機會，
與會者提出的最新成果和交流思想對提升新技術的研究開發和應用都能促進更多技
術的提升也更能夠提升國內的研究水準，並提高台灣在國際學術研究上的能見度。 
   此次學術會議的與會人士眾多，多為人工智慧與資訊領域專長的專家與學者。
藉由會議第一天的餐敘並針對於學術上的研究作交流互動，瞭解許多專家學者於學
術上的研究領域。而透過第二天的專題講座與論文發表，獲取目前學術的研究動向。 
三、考察參觀活動(無是項活動者略) 
四、建議 
    在會議中發表自己的研究成果，並與與會人士相互討論是非常難得的經驗，也
提供了一些不同的思考模式，對於日後的研究方向有很大的幫助，且會議內容大部
分都是尚未發表的研究成果，可以從中了解目前最新人工智慧與資訊工程的發展趨
勢，啟發了我未來研究的靈感。另外，因為聆聽了來自各國一些專業學者的研究報
告，包括歐亞洲各國等學者、博士生與研究員，發現在與個人研究領域相類似的主
題探討上，還有更多不同的研究方法與討論觀點，將可獲致更多的精湛結果。 
五、攜回資料名稱及內容 
1. Program and Book of Abstracts: 內容為會議議程與投稿者之論文摘要。 
2. 大會附贈環保袋一只 
3. 大會紀念品 (原子筆、 CD)一份 
11/10/26 上午8:05實踐大學高雄校區數位電視與多媒體實驗室 郵件 - FSNC 2011 Acceptance Letter
頁面 1∕1https://mail.google.com/mail/u/0/?ui=2&ik=66f8830b49&view=pt&q=FSNC&qs=true&search=query&msg=12e029f63ffce866
Alex Kung <alex@itc.kh.usc.edu.tw>
FSNC 2011 Acceptance Letter
FSNC2010 <fsnc2011reg@163.com> 2011288:15
: Alex Kung <alex@itc.kh.usc.edu.tw>
Thank you for your submission to FSNC 2011. We are pleased to inform you that, according to the reports from anonymous reviewers, the
following distinguished work from you has been accepted for FSNC 2011, with the publisher of IEEE, which will be indexed by EI
Compendex and ISTP. 
You are kindly reminded with the following important notes:
1. Open the link and find a lot of information of paper submission and registration. 
http://www.iita-association.org/fsnc2011/ei/ieeeregistration.htm
2. In order to make high quality of Proceedings, the camera-ready version should follow format. Kindly download from here
http://www.iita-association.org/fsnc2011/ei/ieeeregistration.htm
3. After Finish the final Paper, you can prepare a Copyright Release Form. The copyright should download, print, write author names,
paper title, sign a name and date, and scanned it to PDF format 
http://www.iita-association.org/fsnc2011/ei/IEEE%20COPYRIGHT%20FORM.doc
4. Kindly download the registration form and pay for it,
http://www.iita-association.org/fsnc2011/ei/ieeeregistration.htm
 
and send both registration form and a scanned receipt from your bank to above Email  FSNC2011REG@163.com before Feb 8, 2011. If
you have not paid for your paper in that time, your paper will not be published. 
5. The e-copy official acceptance Letter could be download though
http://www.iita-association.org/fsnc2011/ei/Acceptance_and_invited_letter_ei.doc
 
Write you write author names, paper title and print it 
Kindly send Final paper (doc format), copyright, registration form and a scanned receipt to 
FSNC2011REG@163.com before Feb 8, 2011
Sincerely,
Program Committee of FSNC2011
E-mail: FSNC2011REG@163.com
URL: http://www.iita-association.org/fsnc2011/index.htm
 
 
paper ID 523
 
solution at random. At initial stages, a small random change is 
made in the current solution. Then the objective function value 
of new solution is calculated and compared with that of current 
solution. A move is made to the new solution if it has better 
value or if the probability function implemented in SA has a 
higher value than a randomly generated number. Otherwise a 
new solution generated and evaluated. 
 
Figure 1.   SA Flow diagram 
C. Particle Swarm Optimization 
Reynolds [8] observed flight behavior of the bird, he 
found that the individual behavior of each group can be 
modular by   individual, objective and group center of three 
vectors, and generate complex group behavior. The behavior 
model of bird flying is the basis of PSO. In 1995, PSO is 
proposed by the Eberhart and Kennedy [9-10], which is a 
kind of Evolutionary Computation. Every bird can be as a 
particle. Each particle keeps track of its coordinates in 
hyperspace which are associated with the best solution 
(fitness). The value of that fitness is also stored. This value 
is called pbest. Another “best” value is also tracked. The 
“global” version of the particle swarm optimizer keeps track 
of the overall best value, and its location, obtained thus far 
by any particle in the population; this is called gbest. The 
particle swarm optimization concept consists of, at each 
time step, changing the velocity each particle toward its 
pbest and gbest (global version). Acceleration is weighted 
by a random term, with separate random numbers being 
generated for acceleration toward pbest and gbest. 
TABLE I.  COMPARISON OF THE OPTIMAL ALGORITHMS 
Items of 
comparison 
Algorithms 
MC SA PSO 
Selection method of 
neighborhood Random 
Temperature of 
probability function 
Speed and move 
Of itself with several 
groups 
Selection region of 
neighborhood Global 
Current point of 
neighborhood 
Integrate region of 
itself and group 
vector 
The number of 
particle 
Times a 
particle 
A particle or more 
particles at once 
More particles 
At once 
Convergence data  Annealing temperature Fitness 
The way of escape 
local  Probability Global optimum 
Exchange 
information of 
generation 
No No Yes 
Algorithm type  Evolutionary & Probabilistic 
Evolutionary & 
Global 
D. Neighborhood  search and the Hybrid algorithm 
Traditional Neighborhood search is also known as local 
search; usually gets a trouble in local optimum. In 1980s, the 
new concept of heuristics is evolved for solving problem. 
These new heuristics are all the main strategies for solving 
feasible solution in the region move step by step to gradually 
improve the objective function value, and make the best 
algorithm with partial relief from the ability to leave, while 
approximating the optimum. 
The hybrid algorithm is combining two or more over 
algorithms. Combining with global and local search, a 
method is doing the local improvement operator of local 
search into the global search. In the hybrid algorithm, local 
search can obtain a global / local optimum solution.  
Since Glover proposed "Meta-heuristics" in his article, 
that the "Meta-heuristics" get most scholars agreement and 
using until now [11-13]. But the Meta-heuristics take the 
traditional heuristic method as the core architecture, 
combined with high search strategy, let algorithm can jump 
out local optimum [14]. Table I is the comparison of the 
optimal algorithm.  
III. RESEARCH METHODS 
This study is focus on two issues, first is how quickly and 
widely to search in any solution domain, and find out the 
approximate optimal solution in the son of the solution 
domain. Second, is how quickly and widely to solve in 
solution domain and avoid getting a trouble in local optimum.  
The new algorithm keeps on quality and speed.  
In this study, we integrate with the hybrid algorithm to 
develop into a Neighborhood Architecture and proposed a 
new algorithm to compare with traditional algorithms and 
find the algorithmic parameter settings by the neighborhood 
features. The neighborhood definitions can be expressed as 
follows: 
EFmELet 2},,...2,1{  and oFfLet :  
Combinatorial optimization problem (COP) 
Minimize }:)({ FSSf    
EFN 2: o  Ҟ(1) 
where E2 is the subset of all E’s sets, ˙ʳ is a feasible solution, 
f is the objective function, S is feasible set, N is a 
neighborhood function, for each FS  , N(S) is a subset of  E, 
N(S) become feasible solution S of neighborhood. 
MC often used in optimization of various fields. This 
method is mainly based on the Boltzmann’s probability 
distribution function to help to get the best solution. And the 
neighboring solutions can be expressed as: 
)}1(|{ 11 randsxxN ttmc     Ҟ(2) 
Metropolis criterion is used to decide whether to accept a 
change in the energy changes. At a particular temperature T, 
each specifically atomic probability of existence that show 
283
The new system architecture includes the strategies of 
initial solution generated, neighborhood set generated, and 
neighborhood solutions updated. Where the neighborhood 
set is generated by the parameter of neighborhood. 
According to the chosen of neighborhood domain, the 
neighborhood solution will be update. The particles move 
position by the new particles of randomly generated, and get 
fitness value by the new position of solution. According to 
Acceptance Rule, the fitness value will reject or accept the 
poor fitness value by probability. Figure. 3 is the new system 
architecture of hybrid algorithm. 
This study selected four frequently Benchmark to run 
numerical experiments for algorithm validation and 
performance assessment. According to characteristic of 
function be divided into with a single minimum point 
(single mode) and a number of local minimum points 
(multi-modal) two categories, each category of two 
functions, as shown in Table II. 
TABLE II.  BENCHMARK FUNCTION 
Function Name Dim Search Space 
Min/Best 
position 
¦
 
 
n
i
ixf
2
2
1
 
Sphere 30 (-100,100) 0 /(0,…0) 
¦
 
 
n
i
ixixixf
1
)2)1(2)21(100(2
 
Rosen 
Brock 30 (-50,50)
N 0 /(1,…1) 
1cos
4000
1
1 1
2
3 ¸¸¹
·
¨¨©
§ ¦ 
  
n
i
n
i
i
i i
x
xf
 
Griewank 30 (-300,300) 0 /(0,…0) 
10,
)2cos((
1
2
4
 
 ¦
 
A
AxAxf
n
i
ii S
 
Rastrigrin 30 (-5.12,5.12) 0 /(0,…0) 
In this study, this test functions in a unified standard, 
through the same algebra (time) to test the proposed hybrid 
optimization algorithm, compared with traditional types of 
algorithms, that to test whether is under the same of algebra 
has a better solution (minimum). 
TABLE III.  PSO, SA, MC, HYBRID  SEARCH THE BEST VALUE IN 
BENCHMARK FUNCTION 
 
(a) Sphere Function (b) Rosen Brock Function 
 
(c) Girewank Function (d) Rastrigrin Function 
IV. EXPERIMENTAL RESULTS 
In this study, we use PSO, SA, MC, Hybrid algorithms to 
search the best solution in Benchmark Function.  Shown as 
table III, the purple line - All represent the experiment results 
of our Hybrid algorithm, we can find out that our hybrid 
algorithm obtain better results than the other algorithms on 
four benchmark functions. According to the experimental 
results shown in table III, which shows that our Hybrid 
algorithm could improve the search result very well. 
ACKNOWLEDGMENT 
This work is supported by National Science Council of 
Taiwan grants: NSC 99-2221-E-158-007 
V. REFERENCES 
[1] N. Metropolis and S. Ulam, ”The Monte Carlo 
Method,” Journal of the American Statistical 
Association, vol.44, No.247, pp.335-341,Sep.1949. 
[2] N. Metropolis, A. W. Rosenbluth, M. N. Rosenbluth, 
and A. H. Teller, “Equations of state  calculations by 
fast compuing machines,” Jourmal of Chamical 
Physics,vol.21, pp.1087-1092,1953 
[3] Yao, Xin, "New simulated annealing algorithm," 
International Journal of Computer Mathematics, Vol.56, 
No.3-4, pp.161-168, 1995. 
[4] V. Fabian, "Simulated annealing simulated," Computers 
& Mathematics with Applications, vol. 33, No.1-2, pp. 
81-94, 1997. 
[5] J. Haddock, and J. Mittenthal, "Simulation optimization 
using simulated annealing", Computers & Industrial 
Engineering, vol. 22, No.4, pp. 387-395, Oct, 1992. 
[6] F. Yang, Z. Zhuang, Y. Dai, "Using simulated 
annealing," Proceedings of the International 
Conference on Circuits and Systems, Nanjing, China, 
pp.175, July, 1989. 
[7] S. Kirkpatrick, C. D. Gelatt, and M. P. Vecchi, 
"Optimization by simulated annealing," Science, Vol. 
220, pp. 671-680, 1983. 
[8] C. W. Reynolds, ”Flocks, herds and schools: a 
distributed behavioral model,” Computer Graphics,vol. 
21, No.4, pp.25-34, 1987. 
[9] J. Kennedy, R. C. Eberhart, “Particle swarm 
optimization,” in: Proc. IEEE Int. Conf, on Neural 
Networks, Perth, Australia, vol.4, pp.1942-1948,1995. 
[10] R. C. Eberhart, J. Kennedy, “A new optimizer using 
particle swarm theory,” in: Proc. IEEE Int. Symposium 
on Micro Machine and Human Science, Nagoya, 
Japan,pp.39-43,1995. 
[11] F. Glover, and M. Laguna, “Tabu search,” Kluwer 
Academic Publishers," Massachusetts, 1997.  
[12] F. Glover, "Tabu Search, Part I," ORSA Journal on 
Computing, Vol. 1, No. 3, pp.190-206, 1989.  
[13] F. Glover, "Tabu Search- Part II," ORSA Journal on 
Computing, Vol. 2, No. 1, pp. 4-32, 1990. 
[14] I. H. Osman, and J. P. Kelly, "Meta-Heuristics: An 
overview," Meta-Heuristics: Theory & Applications, 
Kluwer Academic Publishers, Boston, London, 
Dordrecht, pp. 1-21, 1996 
285
11/10/26 上午8:01實踐大學高雄校區數位電視與多媒體實驗室 郵件 - Acceptance Notification and Inviting Letter for ICHCC 2011 Paper 253 (论文录用通知）
頁面 2∕2https://mail.google.com/mail/u/0/?ui=2&ik=66f8830b49&view=pt&q=accept&qs=true&search=query&th=12ea0c9d72fcfc9f
Description, originality of the own contribution: 4
Presentation of the results: 5
Conclusions and future work: 5
Readability, quality of the English: 4
Quality of the figures: 4
Quality of format: 5
Overall Paper Recommendation (1-7, 1 strong reject, 7 strong accept) accepted as regular paper: 5
Please modify it according to ICHCC-ICTMF 2011 Format strictly. Otherwise, we will not publish your paper in the
proceedings. If you are not a native speaker (not familiar with in English environment), please check your
sentences and/or English one more time to improve the quality of the final camera-ready paper.
        
improving the visual identification, and provides the automatic image processing 
procedure in the future (e.g. analyze, detection, division, and identify). Most methods 
are proposed about image enhancement. [1-3], these methods mostly modify the value 
of histogram, the other methods is analyzing the edge and adjusting contrast or 
transforming the global entropy. 
2.1 Bilateral Filter 
Bilateral filter is a technology to smooth images. It is a non-linear filter. It is 
proposed for smoothing the noise and preserving edges in the image processing. It 
starts with standard Gaussian filtering in both spatial and intensity domains.  
It has been used in various contexts such as denoising, texture editing and 
relighting, tone management, demosaicking, stylization, and optical-flow estimation. 
The bilateral filter has several qualities that explain its success: 
1. Its formulation is simple: each pixel is replaced by a weighted average of its 
neighbors. This aspect is important because it makes it easy to acquire 
intuition about its behavior, to adapt it to application-specific requirements, 
and to implement it. 
2. It depends only on two parameters that indicate the size and contrast of the 
features to preserve. 
3. It can be used in a non-iterative manner. This makes the parameters easy to 
set since their effect is not cumulative over several iterations. 
Fig.1 is the bilateral filter deal with the High dynamic range image. The output 
image of the bilateral filter is become very well, the edge is obviously. 
 
 
(a) the high dynamic range image (b) output of  the bilateral filter 
Figure 1. Image processing use the bilateral filter 
 
The bilateral filtering is defined as follows: 
∑∑
∑∑
−= −=
−= −=
++
= a
ai
b
bj
a
ai
b
bj
jiW
iyixfjiW
yxg
),(
),(),(
),(  (1) 
Where f(x, y) is the original signal, g(x, y) is the smoothed signal by the bilateral 
filtering, )12()12( +×+ ba  is the length of bilateral filter. W(i, j) is the kernel of  
bilateral filter: 
),(),(),( jiWjiWjiW Is ×=  (2) 
  Ws is the Gaussian filter on the spatial domains, is defined by : 
        
where *jx  (PBEST) denotes the best position of jth particle up to time t-1 and x
# 
(GBEST) denotes the best position of the whole swarm up to time t-1, φ1 and φ2 are 
random numbers, and c1 and c2 represent the individuality and sociality coefficients, 
respectively. 
The population size is first determined, and the position and velocity of each 
particle are initialized. Each particle moves according to (5) and (6), and the fitness is 
then calculated. Meanwhile, the best positions of each particle and the swarm are 
recorded. Finally, as the stopping criterion is satisfied, the best position of the swarm 
is the final solution. The block diagram of PSO is displayed in Fig. 3 and the main 
steps are given as follows: 
1. Set the swarm size. Initialize the position and the velocity of each particle 
randomly. 
2. For each j, evaluate the fitness value of jx and update the individual best 
position *jx  if better fitness is found. 
3. Find the new best position of the whole swarm. Update the swarm best 
position #x  if the fitness of the new best position is better than that of the 
previous swarm. 
4. If the stopping criterion is satisfied, then stop. 
5. For each particle, update the velocity and the position according (5) and (6). 
Go to step 2. 
3 Experimental methods  
The study focuses on the image enhancement by Bilateral filter with Particle 
Swarm Optimization Alogrithm. And we use the SSIM index [6-15]to assess the image 
quailty. According to the quailty, the image process will finish or again.  
In this study, we use this two parts to set a system to achive the image enhancement 
about adaptive video enhancement filters. The system diagram is given in Fig. 9. 
Bilateral filtei nput
Coarse 
image
residual 
image
SSI M
PSO
out putI mage 
Synt hesi s
 
Figure 3. The system diagram 
4.1 Bilateral filter with PSO 
As discussed in Section 2, we know the bilateral filter is a neighborhood filter by 
Gaussian filter. The bilateral filter has three parameters: |Nx| is the neighborhood size, 
σs  is the distance variance of Gaussian distribution function , σi is the gray value 
difference of Gaussian distribution function.  
We encode the particle as xj =(|Nx|, σs, σi), which is the position of the domain 
block. The steps of encoding a range block using PSO are summarized as follows: 
1. Initialize the parameters of PSO. 
        
6 Acknowledgment 
This work is supported by National Science Council of Taiwan grants: NSC 98-
2815-C-158-003-E, NSC 98-2221-E-158-005 
7 References 
1. Rosenfeld and A.C.Kak, Digital Picture Processing. New York: Academic, 
Vol.1(1982). 
2. Jain, Fundamentals of Digital Image Processing. Englewood Cliffs, NJ: Prentice-Hall 
(1989). 
3. T.L.Ji, M.K. Sundareshan, and H. Roefrig, “Adaptive image contrast enhancement 
based on human visual properties,” IEEE Trans. Med. Img., vol. 13, pp. 573-586, Dec. 
1994. 
4. J. Kennedy, R. C. Eberhart, “Particle swarm optimization,” in: Proc. IEEE Int. Conf, 
on Neural Networks, vol.4, pp.1942-1948, Perth,Australia (1995). 
5. R. C. Eberhart, J. Kennedy, “A new optimizer using particle swarm theory,”in: 
Proc.IEEE Int.Symposium on Micro Machine and Human Science, pp.39-43, 
Nagoya,Japan (1995). 
6. W.S.McCulloch,and W.Pitts,”A logical calculus of ideas immanent in nervo-Us 
activity,”Bulletin of Mayhematical Biophysics, vol. 5,pp.115-133 (1943). 
7. D. O. Hebb, The Organization of Behavior:A Neuropsychological Theory, Wiley, New 
York (1949). 
8. F.Rosenblatt,”The perceptron : A probabilistic model for information Storage and 
organization in the brain,”Psychological Review,vol.65,pp.386-408 (1958). 
9. Z. Wang, A. C. Bovik, H. R. Sheikh and E. P. Simoncelli, "Image quality assessment: 
From error visibility to structural similarity," IEEE Transactions on Image Processing, 
vol. 13, no. 4, pp. 600-612, Apr. (2004). 
10. Z. Wang and Q. Li, "Video quality assessment using a statistical model of human 
visual speed perception," Journal of the Optical Society of America A, Dec. (2007). 
11. Z. Wang and X. Shang, “Spatial pooling strategies for perceptual image quality 
assessment,” IEEE International Conference on Image Processing, Atlanta, GA, Oct. 
8-11,(2006). 
12. Z. Wang and E. P. Simoncelli, “Translation insensitive image similarity in complex 
wavelet domain,” IEEE International Conference on Acoustics, Speech and Signal 
Processing, vol. II, pp. 573-576, Philadelphia, PA, Mar.( 2005). 
13. Z. Wang, L. Lu, and A. C. Bovik, “Video quality assessment based on structural 
distortion measurement,” Signal Processing: Image Communication, special issue on 
“Objective video quality metrics”, vol. 19, no. 2, pp. 121-132, Feb. (2004). 
14. Z. Wang, E. P. Simoncelli and A. C. Bovik, “Multi-scale structural similarity for 
image quality assessment,” Invited Paper, IEEE Asilomar Conference on Signals, 
Systems and Computers, Nov. (2003) 
15. Chih-hsien Kung, Wei-sheng Yang, Chun-yuan Huang, Chih-ming Kung, 
“Investigation of the Image Quality Assessment using Neural Networks and Structure 
Similarty”, The Third International Symposium Computer Science and Computational 
Technology(ISCSCT 2010),pp. 219-222,  Jiaozuo, China ,Aug.14-15(2010) 
 
99 年度專題研究計畫研究成果彙整表 
計畫主持人：龔志銘 計畫編號：99-2221-E-158-007- 
計畫名稱：鄰域搜尋架構整合最佳化演算法 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 0%  
研究報告/技術報告 0 0 0%  
研討會論文 0 0 0% 
篇 
 
論文著作 
專書 0 0 0%   
申請中件數 0 0 0%  專利 已獲得件數 0 0 0% 件  
件數 0 0 0% 件  
技術移轉 
權利金 0 0 0% 千元  
碩士生 1 1 100%  
博士生 1 1 100%  
博士後研究員 0 0 0%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 0% 
人次 
 
期刊論文 1 1 100%  
研究報告/技術報告 0 0 0%  
研討會論文 1 1 100% 
篇 
 
論文著作 
專書 0 0 0% 章/本  
申請中件數 0 0 0%  專利 已獲得件數 0 0 0% 件  
件數 0 0 0% 件  
技術移轉 
權利金 0 0 0% 千元  
碩士生 0 0 0%  
博士生 0 0 0%  
博士後研究員 0 0 0%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 0% 
人次 
 
