1 
 
中文摘要 
本計畫原規劃為三年期計畫，為『遠距醫療輔助用之影像智慧型自動導引機器手臂』，
但是只過第一年，因此研究主題集中於為『光學影像之肺部聽診位置建立』。 
由於台灣資源分配不均，為了配合居家照護和偏遠地區病患，利用 CCD 攝影機攝取病
患肺部影像，經過影像辨識，決定出胸部輪廓，進而以醫師經驗法則，決定肺部聽診的六
個位置點，此時即可得到空間中相對的平面位置，當以機器手臂聽診時，再以手臂前端的
機器手臂得到相對的縱軸距離，即可得到聽診位置的立體空間座標，進而控制機器手臂進
行聽診行為。計畫中同時推導機器手臂的動態方程式，決動其移動模式，以作為後續控制
器發展以及虛擬實境遠距醫療介面的設計。 
計畫中透過實驗手臂的建立，與 CCD 裝置擷取影像進行辨識，可以獲得初步的聽診位
置辨識結果，其正確率約可達到八成，預計將於以後延續發展，並結合遠距醫療發揮其最
大功效。 
 
ABSTRACT 
 
The research topic is focused on “Photo-Image Based Lung Auscultation Position 
Detecting”.The resource allocation of Taiwan is uneven. For cooperating with looking after at 
home and patient from far-off regions, the CCD camera is used to grab the patient's lung image. 
Distinguishing through the image, the chest outline will appear. According to the doctor's 
experience, six seats of lung auscultation will be decided. The flat relative coordinate in the space 
will be obtained. By the camera installed in the end-point of the robot, the vertical distance will 
be decided. Hence, the 3D relative co-ordinate will be found out. At the same time, the Dynamics 
and Kinematics of the robot will be driven, too. 
In this project, the locations of lung auscultation can be automatically found by CCD. The 
accuracy in the experimental results is approximated to 80%. It will be very helpful for 
remote-diagnostics. 
3 
 
 
圖二、達文西機器手臂手術[10] 
這些手術機器手臂一般皆具有精密的運動控制，而且具有前端的影像傳送，以及在另
一端的操控(Tele-operation)，綜合以上所述種種，在楊竹星教授指導的整合計畫：『應用於
呼吸治療中心之智慧型行動照護機器人系統』之中，本子計畫將製作『遠距醫療輔助用之
智慧型影像自動導引機器手臂』，配合整合計畫之總體目標，製作具有影像辨識，在照護機
器人上面會自動辨識呼吸照護病患肺部聽診位置，透過兩層式灰模糊控制器控制機器手臂
自動進行聽診位置聽診，再以手臂前端之鏡頭迴授，做近接位置偵測，以避免深度撞擊病
患胸部，同時可以透過網路遠端，進行遠端操控聽診，作為遠距診療之輔助工具。 
計畫中創新點在於聽診器聽診是對於呼吸疾病病患最重要的一項診察動作，傳統上以
人進行聽診動作，則是端視於醫師的經驗法則，以經驗目視判斷聽診的位置，位置的誤差
可以由人為隨時修正，但是在遠端遙控時，則並不是如此容易進行，一旦誤差過大，對疾
病的診斷也會有所誤差，因此在本計畫中創新的以胸部輪廓影像，經過影像辨識運算智慧
型辨識出前胸與後胸的各六個聽診點，如圖三所示，可以提供輔助機器手臂進行最正確的
診察動作。當決定出聽診位置之後，此時所得到的資訊為二維的幾何位置，透過手臂前端
的鏡頭迴授，可以計算出手臂與病患胸部聽診位置的直線距離，透過兩個鏡頭的整合，即
可得到三維的立體空間幾何座標，據此將可經過幾何座標轉換，得到機器手臂各個關節相
對的運動命令座標，而進行精確的定位控制。 
 
圖三、前胸與後胸的聽診點圖 
 
第二章 文獻探討 
本計劃是以影像辨識醫療診斷位置，並獲得空間座標，再控制機器手臂完成精密聽診
控制，。因此整個研究可以概分為四個部分，第一部份就是輔助醫療機器手臂相關研究，
第二部份為影像伺服研究。各個部分的國內外相關研究情形則概述如下： 
2-1 輔助醫療機器手臂相關研究 
A. 2004 年 Dr. Tsai 和 Dr. Hsu [11] 發表以平行架構之機器手臂進行骨頭神經外科手
術，平行的機器手臂結構，有助於手臂的伸縮行進，但是對於精密手術，角度變
5 
 
第三章 研究方法 
研究流程圖如圖四所示。 
後端CCD影像擷取
胸部輪廓搜尋
肺部影像匹配
相對位置計算
相關資料收集
與分析
六軸機器手臂
Dynamic分析
六軸機器手臂
Kinematics分析
六軸機器手臂各軸
相對座標轉換推導
6個聽診位置定位
醫生聽診測試
手臂前端CCD影像擷取
不佳
景深/垂直距離計算
平面座標 +立體相對座標
以Simulink中
SimMechatronics模擬
模擬測試
不佳
1. 建立智慧型影像辨識聽診位置系統
2. 以雙CCD鏡頭計算目標位置與手臂端點相對空間座標
3. 完成機器手臂之影像伺服系統模擬
佳
垂直座標
 
圖四、研究流程圖 
 
計畫研究重點在『光學影像之肺部聽診位置建立』，因此研究方法與步驟主要有：CCD
影像擷取、胸部聽診點識別兩個部分。 
A、CCD 影像擷取 
以 CCD 擷取影像訊號做為伺服回授，在機台的設計上面非常簡單，只要裝上 CCD 與
影像擷取卡即可，但是影響到影像品質的就是光源的問題，一旦光源不足，所取得的影像
過暗，便不容易檢出裡面物體的位置，同樣的若是光源過亮，甚至安裝位置不當，產生『光
暈』的現象，將會使得畫面過量，所有影像模糊，導致無法識別，而在本計畫中之應用，
機器手臂前端 CCD 鏡頭將隨著手臂前進至病患胸部聽診，因此光源的變化將隨著胸部的接
近越趨明顯，因此在此研究步驟必須考慮輔助光源的安裝，使影像得以清晰易於辨認。 
市面上常見的有直接照射式的環型 LED 如圖五所示，左圖為產品外觀，右圖為工作原
理，安裝位置必須低於 CCD 鏡頭，光源集中，適合用於較小固定物件的檢測使用。 
7 
 
法。比較新的樣式識別法則有圖像幾何模型化、圖像非均勻取樣法和旋轉獨立和比例獨立
的資訊萃取法三種，此三種方法都可以有效的改善傳統匹配的速度，在本研究計畫中將以
此三種方法分析圖像作位置檢出動作，分析樣式識別法的優缺點。 
顏色位置搜尋法則是建構在彩色頻譜分析上面，所以一般的圖像是以 RGB 三原色資訊
儲存，必須先轉換成 HSL 資訊，其關係圖則如圖八所示。 
 
圖八、HSL 與 RGB 關係圖 
顏色位置搜尋包含兩個步驟，第一個就是顏色樣式學習，第二個就是在圖像中搜尋這
個樣式，整個過程是在顏色頻譜中完成，因此對於圖像的旋轉與型變，只要顏色位有重大
改變，一般都還可以辨認出來，另外當外部光源有所改變，相對的顏色仍然可以搜尋出相
對位置，是一個比較可以實際應用的方式，一般的做法是在檢測端點標示一鮮明的顏色以
作識別。 
本研究計畫中將比較樣式識別與顏色位置搜尋等方法，以找尋一適合作為胸部輪廓檢
出的快速法則，一旦得到胸部外部輪廓之後，便可以比例方式獲得肺部聽診位置，如圖九
所示。 
邊緣檢測 胸部輪廓 比例計算獲得
6點聽診位置
 
圖九、聽診位置檢出圖 
9 
 
1
7
2
3
4
5
6
1 52 3 4
 
圖十一、聽診位置辨識圖 
 
第五章 結論 
本計劃中原規劃三年，由於只通過第一年計畫，因此於計畫中首先完成聽診位置的影
像辨識，在實驗過程中，共計擷取 23 人的影像做辨識，由於聽診位置可容許誤差範圍較大，
肺音仍可正常分析，因此在共同主持人義大醫院胸腔外科主任鄭裕仁醫師驗證下，只有 5
人無法正常或的聽診位置，其他皆可成功辨識，因此辨識成功率高達八成以上。 
後續計畫中，預計將以獲得的辨識位置，驅動機器手臂帶動聽診器，直接接近患者肺
部聽診，以達到遠距診療的應用。 
 
參考文獻 
[1] Y. Shirai and H. Inoue, "Guiding a robot by visual feedback in assembling tasks," Pattern Recognit., pp.99-108, 
1973. 
[2] S. Hutchinson, G.D. Hager and P.I. Corke, "A tutorial on visual servo control," IEEE Trans. On Robotics and 
Automation, pp.651-670, 1996. 
[3] P.I. Corke, "Visual control of robotics: high-performance visual servoing," Research Studies Press Ltd., 1996. 
[4] M.E. Stieber, M. McKay, G. Vukovich and E. Petriu, "Vision-based sensing and control for space robotics 
applications," IEEE Trans. On Instrumentation and Measurement, pp.807-812, 1999. 
[5] P. Abolmaesumi, S.E. Salcudean, W.H. Zhu, M.R. Sirouspour and S.P. DiMaio, "Image-guided control of a 
robot for medical ultrasound," IEEE Trans. On Robotics and Automation, pp.11-23, 2002. 
[6] S. Saripalli, J.F. Montgomery and G.S. Sukhatme, "Vision-based autonomous landing of a unmanned aerial 
vehicle," IEEE International Conference on Robotics and Automation, 2002. 
[7] T.S. Chen and R.C. Luo, "Mobile target tracking using hierarchical grey-fuzzy motion decision-making 
method," IEEE International Conference on Robotics and Automation, pp.2118-2123, 2002. 
[8] S.J. Ralis, B. Vikramaditya and B.J. Nelson, "Micropositioning of a weakly calibrated microassembly system 
using coarse-to-fine visual servoing strategies," IEEE Trans. On Electronics Packing Manufacturing, 
