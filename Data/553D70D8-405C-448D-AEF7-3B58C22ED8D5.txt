2call stay on macrocell layer to long so that effect the whole
system utilization, then the slow call must back microcell layer
as soon as possible.
The rest of this project is organized as follows. Section
II describes traffic and system models. As for the proposed
algorithm, the partial overflow call admission control scheme,
the dynamic priority of Access macrocell channel (DP-AMC)
scheme and the double bucket channel repacking algorithm,
are depicted in Section III and Section IV. Section V gives the
performance of proposed algorithm. In Section VI, numerical
experiments are conducted. Finally, Section VII gives the self-
evaluation for this project.
II. SYSTEM MODEL
In the first year of this project, we consider that a two tier
cellular network, hierarchical cellular network, which cover a
particular area and the mobiles move with different velocities
under this coverage. Every N microcells are covered by a
macrocell. Each macrocell and microcell is assigned CM
and Cm channels, respectively. The associate concepts of
the system under study is shown in Fig. 1. According to
mobile users moving velocity, we consider two types of calls
in the first year of this project, that is, slow call and fast
call. In order to avoid the call handoff frequency, we assume
that the macrocell layer channel resource almost is provided
for the fast call and the microcell layer channel resource is
allocated for the slow call. All new fast calls and new slow
calls are uniformly generated in each macrocell and microcell
according to a Poisson arrival process with mean rate λsn
and λfn. Although, a fast call trends to access the macrocell
layer channels and a slow call trends to use the microcell
layer channels. Whereas, this channel resource allocation is
not a routine. Some exceptions are taken into account. For
examples, 1). When a slow call is generated in a microcell, but
there is no available in this moment, then the new slow call
can partially overflow to the macrocell layer to temporarily
use the macrocell layer channels. 2). The overflowed slow
call is not permanent borrowed the macrocell channel, at the
appropriate opportunity, it must return the macrocell channel
and take-back the suitable microcell. 3). Also, when a fast call
is generated in a macrocell and there is no available channel
for its request, then it also can underflow to the corresponding
microcell to temporarily use the microcell layer channels, and
4). for the sake of reducing the handoff cost, the underflowed
fast call must take-back to macrocell from the microcell to
the macrocell layer as soon as possible. The associated traffic
flow under study is shown in Fig. 2
III. THE PARTIAL OVERFLOW CALL ADMISSION
CONTROL SCHEME
In the literature, these channel resource management prob-
lems in hierarchical cellular network environment, almost
papers, such as [4], [25], [26], adopt the all overflow scheme.
That is, when a slow call has no available channel in microcell
layer, then all the slow call can be overflow up to the macrocell
layer to use the macrocell resource. Although the strategy
can temporarily help the slow call to get channels, yet it
 
(a) The hierarchical cellular network (HCN)
concept.
 
Macrocell Base Station
(b) A macrocell layer cell.
 
Microcell Base Station
Microcell Base Station
Microcell Base Station
Microcell Base Station
Microcell Base Station
Microcell Base Station
Microcell Base Station
(c) A microcell layer cell.
Fig. 1. The architecture of hierarchical cellular network (HCN), macrocell,
and microcell .
will increase the overhead of the macrocell layer. Therefore,
we think that the strategy is not a good policy. All overflow
scheme maybe not get the expect QoS, but also damage the
QoS guarantee which belong to the fast call in the macrocell
layer. Thus, we propose a partial overflow call admission
control ideal for this problem. The detailed description are
as follows:
4Q
fh
Time out
Fast Handoff Call
Q
sh
Time out
Slow Handoff Call
Q
fn
Time out
Fast New Call
Q
sn
Time out
Slow New Call
DP-AMC
C
fh
C
fn
C
sh
C
sn
Fig. 3. Dynamic Priority of Access Macrocell Channel (DP-AMC).
time and has more opportunity to access macrocell channel
in next time. Therefore, the two important QoS measures of
system, resource utilization and call dropped probability, are
taken care simultaneously.
IV. THE DOUBLE BUCKET CHANNEL REPACKING
ALGORITHM
A. The Token Bucket-Leaky Bucket Channel Repacking (DBR)
Scheme
Base on the partial overflow scheme and the dynamic
priority of access macrocell channel scheme, when a slow call
has no available channel for using, then it can be overflowed
to the macrocell layer temporarily to use the macrocell layer
channel resource. However, what is the most suitable time or
opportunity for a overflowed slow call to take-back a microcell
layer? That is to say, when the system need to repack channel
resource so that the fast call use the macrocell channel and
the slow call use the microcell channel as far as possible?
Because the overflowed slow call can not occupy permanently
the macrocell layer channel which is original assigned for
fast call. Therefore, the token bucket-leaky bucket channel
repacking scheme want to be timely and accurately to execute
the repacking channel action. How to decide the channel
repacking time or epoch after all ? We think that the channel
repacking action had better according the rhythm of fast call
generation event and slow call overflowed frequency to repack
all system channel resource. Because the two epochs are just
the time of the macrocell layer resource change. The relative
detailed operations and main components of this scheme are
described as follows:
1) Token Bucket: When a fast call is generated, regard-
less of it is a fast new call or a fast handoff call,
and a slow call is overflowed to macrocell layer, then
the token-bucket mechanism, shown in Fig. 4, will be
trigged and start. At this moment, the token bucket-
leaky bucket channel repacking (DBR) scheme generates
a fast call token (or a overflowed token) follow this
fast call generating event or the slow call overflowing
event, respectively so the token counter of token-bucket
mechanism will increase one. The system as soon as
will find whether exist any overflowed slow call from
Leaky Bucket
Slow Call Candidate ueue
Overflowed 
Slow Call 
Macro-to-Micro 
Channel 
Repacking 
Event
Fast New Call 
Macro-to-Micro
Channel
Repacking
Event
Fast Call
Token
Overflow 
Token
Microcell
Selection
Rules
Sifter
Modulator
Fast Call 
Events
Overflow 
Events
Fast New Call / 
Fast Handoff Call
Micro-to-Macro
Channel
Repacking
Event
Check Fast Handoff 
Call or Fast New Call?
Overflow
Token
8c8b 8a
1
2
3
4
5
6
7
Token Bucket
Fast New Call
Token
Fig. 4. The Token Bucket-Leaky Bucket Channel Repacking (DBR) Scheme.
the slow call candidate queue can be taken-back to
microcell. If there is a overflowed slow call which still
stay in the macrocell layer, then this slow call be token-
back to a suitable microcell from the macrocell. That
is, a token of the token-bucket mechanism will trig a
channel repacking event from the macrocell layer to the
microcell layer.
2) Leaky Bucket: Besides, we attach another control
component in channel repacking scheme, that is, the
leaky bucket. When the fast call generation or slow
call overflow phenomena is heavy, the macrocell layer
will congregate many fast calls and overflowed slow
call. Therefore, the token generating rate in macrocell
is much grater than that slow take-back from macrocell
layer to microcell layer. The suddenly increasing token
will over the capacity of token bucket threshold. Thus
the excess will be shift from the token bucket to the
second bucket, named leaky bucket. The token pass
through the leaky bucket according to a certain rate.
To integrate such two repacking control mechanism,
the token bucket and the leaky bucket, we call the
double bucket channel repacking (DBR) algorithm for
maintaining the system channel resource.
3) Fast Call-Token: A token which generates follow a fast
call generating event. It is shown as the brown token in
Fig. 4.
4) Overflowed Call-Token: A token which generates fol-
low a overflowed slow call generating event. It is shown
as the green token in Fig. 4.
5) Microcell Selection Rules: Generally speaking, a hand-
off call will be provided the priority than a new call in
personal communication system. Therefore, in order to
exactly select and find out the most urgent microcell
which is the most necessary of channel repacking in
all microcells covered by a macrocell, the system will
calculate three indices for each microcell. The three
indices are the existing ratio of handoff call (HR), the
existing ratio of new call (NR) and the empty channel
ratio (ER) in each covered microcell. And the system
will according to the following priority rules to select
6time is quite short, maybe the take-backed fast call
still has no available channel. Therefore, we design the
underflowed fast call is not immediately take-back to
macrocell layer. Contrarily, we have the underflowed
accept service in microcell till it is complete or maintain
the underflowed fast call cross the macrocell border .
11) Some Special Cases: Although the DBR scheme ex-
pects to timely adjust the all channels usage, but there
are some exceptions for special cases.
a) Slow call can execute many times channel
repacking events from the macrocell layer to the
microcell layer: In the macrocell, if the average
idle channel ratio of the corresponding microcell
for a overflowed slow call is larger than that of
the locating microcell, then the system will have
many times channel repacking of slow call until
the average idle ratio of microcell equals to the
average idle ratio of microcell.
b) Slow call do not execute channel repacking
from the macrocell layer to the microcell layer:
In the macrocell, if the average idle channel ratio
of the corresponding microcell for a overflowed
slow call is much less than that of the locating
microcell, then the system will not execute any
channel repacking event of slow call until the
average idle ratio of microcell equals to the average
idle ratio of microcell. Because the corresponding
microcell almost no channel available, there is no
use of a routinely channel repacking. It is just waste
the channel switch cost.
B. Strengths and Weaknesses Analysis:
The purpose of such designs is that all channel resource
can be timely adjusted and repacked for a yearned channel
resource call. The occupied channel of the overflowed slow
call must return to fast call as soon as possible by executing
channel repacking events. Of course, if the call dropping
probability and the call blocked probability want to be under-
controlled a certain QoS guarantee, the cost of crossing layer
handoff must be number will be victims which cause from
the channel repacking actions. The detailed discussions will
appear in Section. VI.
V. PERFORMANCE EVALUATION
In the following, we apply the results of the partial
overflow scheme, the dynamic priority of access macrocell
channel schemeand the double bucket channel repacking al-
gorithm to calculate the related QoS measures, including
performance measures of slow/fast new call blocking prob-
ability, slow/fast handoff call dropping probability, microcell-
to-microcell handoff number, microcell-to-macrocell handoff
number, macrocell-to-microcell handoff number, macrocell-
to-macrocell handoff number and total channel repacking
number. By the catched simulation output measure, we can
calculate related QoS measures.
A. Performance Measures
• Psnb: the probability that a slow new call is blocked.
For a slow new call, if it neither get a available channel
from a microcell nor a macrocell, then this slow new
call will be blocked. Let Nsn denote the total slow new
call arrivals during the simulation time and Nsnb be the
total blocked slow new call arrivals and the slow new call
blocking probability, Psnb, is given by.
Psnb =
Nsnb
Nsn
(3)
• Pshd: the probability that a slow handoff call is dropped.
When an incoming handoff call request to a macrocell
or microcell, after the channel repacking algorithm ad-
justments, it still can not get available channel under the
following situations: 1) the handoff queue is already full
or 2) it has depart from the cell. Let Nsh denote the total
slow handoff calls during the simulation time and Nshd
be the total dropped slow handoff calls. The slow handoff
call dropping probability, Pshd, is given by.
Pshd =
Nshd
Nsh
(4)
• Pfnb: the probability that a fast new call is blocked.
With the same philosophy, we also calculate the blocking
probability of another type, fast new call. Let Nfn denote
the total fast new call arrivals during the simulation time
and Nfnb be the total blocked fast new call arrivals. The
fast new call blocking probability, Pfnb, is given by
Pfnb =
Nfnb
Nfn
(5)
• Pfhd: the probability that a fast handoff call is dropped.
Also the fast handoff call dropping probability, Pfhd can
be calculated by Eq.(6). Where Nsh denote the total fast
handoff calls during the simulation time and Nshd be the
total dropped fast handoff calls.
Pfhd =
Nfhd
Nfh
(6)
In order to realize how many handoff processes of the
proposed channel repacking algorithm will increase
and how to reflect on others system performance, we
also statistic some handoff quantities. For examples,
1). Hm−m: the handoff number from microcell layer
to microcell layer. 2). Hm−M : the handoff number
from microcell layer to macrocell layer. 3). HM−m:The
handoff number from macrocell layer to microcell layer.
4). HM−M : the handoff number from macrocell layer to
macrocell layer.
• Hrep: The total repacking number occurred during a call.
Due to apply the double bucket repacking channel algo-
rithm, the overflowed slow/fast calls will take-back from
the macrocell/microcell layer to the microcell/macrocell
layer. The handoff number will increase between the
microcell and macrocell because of channel repacking.
Therefore, we catch this statistic.
8[27] P. Vidales, G. Mapp, F. Stajano, and J. Crowcroft, ”A practical approach
for 4G systems- deployment of overlay networks,” in Proc. IEEE TRI-
DENTCON’05, 2005, pp.172–181.
[28] Z. Wang, P. T. Mathiopoulos, and R. Schober, ”Performance Analysis
and Improvement Methods for Channel Resource Management Strategies
of LEOVMSS With Multiparty Traffic,” IEEE Trans. Vehicular Tech.,
vol. 57, no. 6, pp. 3832–3842, 2008.
[29] C. H. Wu, H. P. Lin, and L. S. Lan, ”A new analytic framework for
dynamic mobility management of PCS networks,” IEEE Trans. Mobile
Computing, vol. 1, no. 3, pp. 208–220, 2002.
[30] W. Ying, W. Weidong, and Z. Ping, ”Admission control for multimedia
traffic in CDMA wireless networks,” in Proc. Commun. Technology’03,
2003, pp.799–802.
[31] O. Zhang, E. Saric, and A. Li, ”Fairly adjusted multimode dynamic
guard bandwidth admission control over CDMA system,” IEEE J. Select.
Areas Commun., vol. 24, no.3, pp. 579–592, 2006.
2and movement-based ones. The distance-based approach was
proposed by Bar-Noy et al. [6]. It works as follows. When an
MT moves out a cell, it will calculate the distance from that
cell to the cell performing the latest location update. If this
distance exceeds a predefined distance threshold, a location
update is then performed. Note that the scope of paging is
then limited to a virtual circle centered at the cell performing
the latest location update with the radius equal to the distance
threshold. As for the time-based approach, it was proposed
by Rose [19] with the following working mechanism. An MT
starts a count-down timer with a preset time threshold. Once
the timer expires, a location update is then performed and the
timer is reset. In [1], Akyildiz et al. proposed the movement-
based approach. For the movement-based approach, an MT
starts a counter which is increased by one if the MT moves
out a cell. Once a predefined movement threshold is reached,
a location update is then performed and the counter is reset.
Based on the aforementioned three approaches, many new
designs were proposed in the literature with a general goal
of cost reduction, e.g., [13], [17], [21], [22], [29]. In [13],
Masajedian and Khoshbin combined the time-based approach
and the ad hoc network so that the mobility information of
a user can be stored in the device of the ad hoc network to
reduce the paging cost. In [17], Ng and Chan proposed an
enhanced distance-based location management strategy which
can reduce the location management signaling traffic via
adjusting the size and shape of LAs based on the moving
speed and direction. Sricharan and Vaidehi [21] analyzed the
mobility profile of users to dynamically select a proper dis-
tance threshold to reduce the location update cost, while Tung
and Jamalipour [22] selected an optimal distance threshold
according to a defined transitional directivity index. In [29],
Zhu and Leung derived a joint probability density function
of the number of cell boundary crossings and the number
of location updates under the movement-based approach to
keep the number of location updates to a reasonable range via
bounding the movement threshold.
Different from the previous designs based on the afore-
mentioned three approaches, there are other designs of the
dynamic location management in the literature, e.g., [5], [8],
[12], [14], [15], [18], [20], [23]. Assouma et al. [5] added a
location register and internetworking gateway (LR-ING) be-
tween two adjacent home location registers (HLRs) to manage
the roaming information of users moving between different
subsystems to achieve reduction of the signaling cost generated
by databases and the inter-system paging delay. In [8], George
and Kumar integrated the cellular network and the ad hoc
network to form a multi-hop network with a goal to make
location management of users more easier. Taking mobility
patterns of users at different time instants into account in the
user profile, Ma et al. [12] enabled the determination of which
cell to be paged according to the movement state and time to
reduce the location update signaling traffic and paging delay.
In [14], Modares et al. utilized user profiles, including the LA
residence probability, cell residence probability, number of LA
crossings, and call arrival rate to determine the location update
and paging areas to reduce the total signal transactions in the
network. In [15], Morris and Aghvami proposed a scheme used
for the integrated UMTS and digital video broadcast (DVB)
system to cut the location management cost down. In [18], a
sector-based location management scheme was proposed by
Qin et al. In [20], Shah et al. used the ad hoc network in the
cellular network to collect location information of neighbors
when a location update is ready to perform for an MT to
effectively make the energy consumption and location update
cost lower. In [23], Wang and Zhang proposed a speed-
adaptive scheme using an enhanced look-up table storing
the distance and time so that when to perform a location
update can be determined with the aid of this table. Moreover,
an angular paging scheme is further incorporated in [23] to
achieve the paging cost reduction.
To take the advantages of the DB scheme, whose superior
performance has been proven in the literature, and the ad
hoc network, a distance-based location management scheme
cooperated with the ad hoc network, i.e., DBCAN, is proposed
in the second year of this project. In DBCAN, specific storage
devices put near cell boundaries, which are totally controlled
by the system only to ensure the user information secure,
are added and work with the ad hoc network to improve
the location management cost when the moving speed of an
MT is low. Because of the intrinsic nature of DB, the paging
delay in DBCAN can be properly controlled. To avoid the
extra cost caused by using the ad hoc network, a method
to determine when to use the ad hoc network is further
incorporated to DBCAN. Noting that [13] is the closest work
in the literature to our proposed scheme, let us now have some
brief comparisons between them. Although the scheme in [13]
results in fewer cells to be paged in the system, it does not
consider the extra cost caused by periodical location updates
when the moving speed of an MT is low and the overhead
caused by using the ad hoc network when the moving speed
of an MT is high. Furthermore, no restriction on the paging
delay is done for the scheme in [13] so that an extremely high
paging delay is observed when the moving speed of an MT
is high. Certainly, a security problem exists when using the
scheme in [13]. Of course, these drawbacks for the scheme
in [13] do not appear in DBCAN to be explained in detail in
Section II.
The rest of the report is organized as follows. In Section
II, the details of the proposed location management scheme
are described, including how to determine when the ad hoc
network should be used, location update strategy, and paging
strategy. In Section III, we get numerical results via simulation
and provide detailed discussions. Finally, Section IV gives the
self evaluation on this project.
II. THE PROPOSED LOCATION MANAGEMENT SCHEME
In [13], a location management scheme combining the
time-based approach and the ad hoc network was proposed
by Masajedian and Khoshbin for the fourth generation (4G)
cellular network. With the scheme in [13], an MT being
crossing the cell boundary will search a possible neighbor in
the ad hoc network through a designed algorithm and pass
the information of the next serving base station (BS) ID and
the remaining time to the time threshold, which is used to set
4TABLE I
AN EXAMPLE OF THE INFORMATION PROVIDED BY AN ARS
Base Station ID ARS ID
A,B 1
TABLE II
AN EXAMPLE OF HISTORIC RECORDS OF ARSS FOR AN MT
Base Station ID ARS ID
A,B 1
B,C 2
C,D 3
D,E 4
information of the ARS should be recorded: The ARS
should respond and provide the MT the information
about which BSs that the ARS currently belongs to so
that a list like Table I can be built to track this ARS.
Table I says that ARS 1 is covered by BSs A and B.
2) The old mobility information can be cleared by employ-
ing the following way with an extra cost when an MT
performs a location update: Aggregating all information
responded by ARSs, an MT can have a full list like Table
II to track all ARSs keeping the mobility information
for it. With Table II, it is possible for an MT to notify
all ARSs via BSs which can reach these ARSs to clear
the old mobility information when an MT performs a
location update. To make the procedure of old mobility
information removal efficient and cost-effective, a new
table with a reduced minimum set of BSs for which
broadcast messages are about to be sent to reach all
ARSs for information removal can be got (e.g., Table
III derived from Table II) to cut the cost down.
Second, the extra cost caused by using the ad hoc network
increases dramatically if the moving speed of the MT is quite
high, resulting in a high frequency of location update and
old mobility information removal for ARSs. This problem has
been previously found in the scheme proposed in [13]. To
avoid such a problem, a method used to determine whether to
use the ad hoc network or not is designed later for DBCAN.
This method is able to make a decision to use the ad hoc
network or not given a moving speed of an MT depending on
feasibility of location management cost reduction. Let us now
describe the idea behind this method.
When a call initiates, the extra cost (per call) required for
DBCAN Cadd, the paging cost (per call) for DBCAN Cp, and
the paging cost (per call) for DB without using the ad hoc
network CDBp need to be estimated. Only when (1) holds,
the ad hoc network then gets involved when the MT crosses
the cell boundary before the next call, or the ad hoc network
TABLE III
REDUCED MINIMUM HISTORIC RECORDS OF ARSS
Base Station ID ARS ID
B 1,2
D 3,4
should be avoided for preventing the extra cost.
Cadd + Cp < CDBp . (1)
(1) explicitly indicates that the sum of the estimated extra cost
and paging cost for DBCAN is still less than the estimated
paging cost for DB without using the ad hoc network. Under
this condition, assisting the location management by the ad
hoc network will be cost-effective.
However, how to get Cadd, Cp, and CDBp is still needed
to be done. Therefore, let us elaborate on the estimation of
these costs. First, the estimation of Cadd is shown as follows.
One may first note that possible extra costs for DBCAN
include the cost to use the ad hoc network and the cost
for the old information removal at ARSs when a location
update is performed. Furthermore, these two costs are pertinent
to the number of location updates and the number of cells
crossed between two consecutive location updates. With the
aforementioned knowledge, we can derive Cadd as follows:
Cadd = Nu(Nm(Ca + αCb) + Cu) +NrCa, (2)
where Nu is the estimated number of location updates, Ca de-
notes the cost to use the ad hoc network, Cb stands for the cost
to inform ARSs by BSs for old mobility information removal,
Cu is the cost for carrying the extra information when perform-
ing a location update, Nm indicates the estimated number of
movements between two consecutive location updates, and Nr
represents the estimated number of the remaining movements
after the last location update. Note that 1) NmCa indicates
the estimated extra cost for an MT to use the ad hoc network
between two consecutive location updates; 2) NrCa denotes
the estimated extra cost for an MT to use the ad hoc network
after the last location update; 3) αNmCb is the estimated extra
cost required for informing ARSs by a BS to remove the old
mobility information when an MT performs a location update.
Since the historic records of ARSs are suitably aggregated in
DBCAN to get a reduced minimum set of BSs to broadcast
messages to ARSs for mobility information removal, hence,
α is a minification multiplier caused by the aforementioned
reduction effect. Noticing that an MT enters/leaves a cell will
ask an ARS to keep its mobility information, an BS can
cover at least two ARSs, implying α ≤ 0.5. In our numerical
examples, 0.5 is set to α (i.e., the worst case is considered).
One can see that Nu can be figured out by
Nu = bNavg
Nm
c, (3)
where Navg is the estimated number of movements (propor-
tional to the moving speed) for the MT before the next call
and obtained using the sample mean shown as follows:
Navg =
n∑
i=1
Mi
n
, (4)
where Mi is the number of movements since the end of the (i−
1)-th call to the beginning of the i-th call and n is the number
of calls sampled. As for Nm, it is mobility model dependent.
Therefore, we need to check different mobility models. Let
us first derive the result for the independent and identically
6Move to the next cell.
        +         <         ?
Is there any ARS to access?
Pass the user's mobility information to
the ARS and record the ARS's
information.
No
No
Yes
Yes
addC pC
DB
pC
Do nothing
Fig. 4. Flowchart to determine when to use the ad hoc network in DBCAN.
B. Location Update Strategy for DBCAN
Since DBCAN is mainly designed based on the distance-
based scheme, a preset distance threshold is given when an
MT is at ring 0. When an MT moves into a new cell, it will
examine whether the distance from this cell to ring 0 exceeds
the distance threshold or not. If yes, then a location update
is performed. Unlike the location update in DB, information
about the historic records of ARSs associated with this MT as
described in the previous section (if any) should be appended
to the packet sent for the location update. Therefore, two types
of location update are necessary in DBCAN: 1) If no historic
records of ARSs associated with this MT exist (i.e., the ad
hoc network is not used), the conventional procedure of the
location update in DB is performed. In this procedure, the
location update packet will be first sent by the BS to the
visitor location register (VLR) located at the mobile switching
center (MSC) for registration. Via this VLR, the HLR located
at another MSC of this MT is then informed for the location
update. 2) If some historic records of ARSs associated with
this MT exist, not only actions in the conventional procedure
of the location update in DB should be taken, but also the
record of associated ARSs should be extracted from the
packet sent. With this record, a list of MSCs containing the
BSs which are able to reach the associated ARSs can be
determined first. Then, pass this record to these MSCs. For
each MSC, it informs the associated BSs for broadcasting
over the control channel to inform the associated ARSs to
delete the old mobility information kept for that MT. Note
that this broadcast may be done like paging via the paging
channel (PCH). Unlike actions taken by the conventional
paging, actions for this broadcasting (paging) are taken for
the old mobility information removal. Therefore, some suitable
control codes, e.g., delete, should be appended to the paging
packet along with the target paging IDs of ARSs. Once ARSs
located near the cell boundary receive this packet, the old
mobility information associated with some specific MT is able
to be removed accordingly. Finally, Fig. 5 shows the flowchart
of location updating in DBCAN.
Dose the distance from the last cell
performing update to the current
cell exceed D?
Dose the user have the historic
records of ARSs?
Location update for the current cell : pass
the merged historic records of ARSs to the
MSC to inform the BS to delete the old
mobility information of users.
Location update for the current cell based
on the original DB scheme.
Yes
Yes
No
No
Move to the next cell ?
Start
Yes
No
Fig. 5. Flowchart of location updating in DBCAN.
C. Paging Strategy for DBCAN
Referring to [13] leads to the paging strategy used in
DBCAN called mixed paging which is to be described as
follows. When there is a call to connect to a user (an MT), the
system will page the cell in which the latest location update
was performed by that MT. If a response is got from that
MT, then the call can be established. If no response, then any
ARS located near this cell boundary can respond by passing
the mobility information of that MT to the system if this ARS
has this information. Therefore, the system is able to page next
cell according to the mobility information got from the ARS,
resulting in the cell-by-cell paging. Such a procedure continues
until no response from any ARS. For this situation, the cell-
by-cell paging is switched to the sequential paging. Again, it
is switched to the cell-by-cell paging if any response from
the ARS is got. Once the response from the MT is got, the
whole paging procedure is terminated and the call is connected
accordingly. Shown in Fig. 6 is an example of this mixed
paging. In this example, a mobile user is assumed to move
from cell A to cell E via cells B, C, and D. Also, the mobility
information is not successfully passed to an ARS when leaving
cell C. Hence, one can see the cell-by-cell paging is started
from cell A and ended at cell C. Then, the sequential paging
follows. Within cell D, the cell-by-cell paging is switched back
since a response is got from an ARS. This cell-by-cell paging
8(0,2)
(-1,1)
(0,1)
(1,2)
(-1,0)
(0,0)
(1,1)
(-1,-1)
(0,-1)
(1,0)
(2,2)
(2,1)
(2,0)
(1,-1)
(0,-2)
(-1,-2)
(-2,-2)
(-2,-1)
(-2,0)
Y
X
Fig. 8. The coordinate system for the cell ID assignment.
0D
1D
2D
3D
4D
5D
Fig. 9. Six possible directions.
directional mobility models based on the hexagonal cell
are employed in the second year of this project. In these
two mobility models, six moving directions, i.e., D0,. . . ,D5,
in Fig. 9 are possible with (D0, D1, D2, D3, D4, D5) =
((1, 1), (0, 1), (−1, 0), (−1,−1), (0,−1), (1, 0)). Denoting
Dk and Ck as the moving direction at the kth move and the
coordinate reached by the kth move with Ck = Ck−1 +Dk
and letting γi,j denote the state transition probability from
moving direction Di at the k-th move to moving direction Dj
at the (k+1)-th move, i.e., γi,j = P (Dk+1 = Dj |Dk = Di),
the state transition matrix Γ is then given by Γ = [γi,j ],
i, j ∈ Z6, where Z6 = {0, 1, ..., 5}. Shown in [26], the state
transition matrix can be simply constructed by the row vector
γ0 = (γ0,0, γ0,1, γ0,2, γ0,3, γ0,4, γ0,5) through right cyclic
shifting with the first row vector equal to γ0. Furthermore, γ0
for the IID and directional mobility models can be specified as
follows [26]: γ0 = (1/6, 1/6, 1/6, 1/6, 1/6, 1/6) for the IID
mobility model and γ0 = (0.8, 0.025, 0.025, 0.1, 0.025, 0.025)
for the directional mobility model.
Next, let us specify the (parameters) setting for the ad hoc
network and the other models/parameters. Referring to [27],
an ARS can be placed at the center of the cell boundary with a
fixed transmission range to store mobility information of MTs.
Moreover, the probability to successfully deliver the mobility
information to an ARS falls within the range [0.5, 1]. As for
the cell residence time of an MT, it follows an exponential
distribution with the mean dwelling time λ−1m . Like most of
papers in the literature, call arrivals are modeled by a Poisson
Process with the mean arrival rate λc. As for the choice of the
distance threshold, 3 is used for the IID mobility model and
4 is employed by the directional mobility model according to
the observation in [22] that the minimum location management
cost can be reached by such a choice (actually, we also reach
the same observation using our simulation results (omitted for
brevity)). Varying the call to mobility ratio (CMR) from 1 to
10 or from 0.1 to 0.9, the location management cost, paging
delay, and ratio of using the ad hoc network are observed
under different moving speeds and mobility models. In the
following, let us further elaborate on the setting of different
unit costs. In the literature, many papers, e.g., [4], [10], and
[11], set the unit cost of location update Cup and the unit
cost of paging (paging a cell) Ccp to 10 (units) and 1 (unit),
respectively. In the second year of this project, we adhere to
these two settings as well. As for the unit cost of putting some
extra information Cu when performing a location update, it is
set to 1 (unit) since just a little information is required. About
the unit cost of using the ad hoc network Ca, it should be
lower than the unit cost of location update and the unit cost
of paging since the ad hoc network works in the unlicensed
spectrum band, i.e., Ca < Ccp. Hence, Ca is set to 0.5 (units)
in the following numerical examples. As for the unit cost of
clearing old mobility information by ARSs via a BS Cb, it
is set to 1 (unit) since it works analogously to paging. About
the detailed simulation parameters, one can refer to Table IV.
Finally, we pay attention to the movement of an MT in our
simulations since the location management cost gets involved
with the movement of an MT.
As for different costs, paging delay, and ratio of using the ad
hoc network, they can be measured via the following equations
based on the aforementioned unit costs:
TCu =
(Cup + Cu)TNu
TNcall
+ TCb, (15)
TCp =
CcpTNp
TNcall
, (16)
TCa =
CaTNa
TNcall
, (17)
TCb =
CbTNb
TNcall
, (18)
TC = TCu + TCp + TCa + TCb, (19)
Dp =
TNd
TNcall
, (20)
Ra =
TNa
TNm
, (21)
where TCu is the (total) location update cost per call, TCp is
the (total) paging cost per call, TCa is the (total) cost of using
the ad hoc network per call, TCb is the (total) cost for clearing
old mobility information by ARSs per call (it is absorbed into
TCu since clearing old mobility information by ARSs is done
when a location update is performed), TNu is the total number
of location updates, TNcall is the total number of calls, TNp
10
1 2 3 4 5 6 7 8 9 10
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
CMR
Lo
ca
tio
n 
up
da
te
 c
os
t p
er
 c
al
l
 
 
DB
DBCAN
DBACAN
(a) Location update cost per call.
1 2 3 4 5 6 7 8 9 10
0
1
2
3
4
5
6
CMR
Pa
gi
ng
 c
os
t p
er
 c
al
l
 
 
DB
DBCAN
DBACAN
(b) Paging cost per call.
1 2 3 4 5 6 7 8 9 10
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
CMR
Co
st
 o
f u
sin
g 
th
e 
ad
 h
oc
 n
et
wo
rk
 p
er
 c
al
l
 
 
DBCAN
DBACAN
(c) Cost of using the ad hoc network per call.
Fig. 10. Individual costs for CMR = 1 to CMR = 10 under the IID mobility model.
1 2 3 4 5 6 7 8 9 10
0
1
2
3
4
5
6
CMR
To
ta
l c
os
t p
er
 c
al
l
 
 
DB
DBCAN
DBACAN
(a) Total cost per call.
1 2 3 4 5 6 7 8 9 10
0
0.5
1
1.5
2
2.5
CMR
Pa
gi
ng
 d
el
ay
 p
er
 c
al
l
 
 
DB
DBCAN
DBACAN
(b) Paging delay per call.
1 2 3 4 5 6 7 8 9 10
0
0.2
0.4
0.6
0.8
1
1.2
1.4
1.6
1.8
2
CMR
R
at
io
 o
f u
sin
g 
th
e 
ad
 h
oc
 n
et
wo
rk
 
 
DBCAN
(c) Ratio of using the ad hoc network.
Fig. 11. Performance comparison for CMR = 1 to CMR = 10 under the IID mobility model.
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
0
2
4
6
8
10
12
14
16
CMR
Lo
ca
tio
n 
up
da
te
 c
os
t p
er
 c
al
l
 
 
DB
DBCAN
DBACAN
(a) Location update cost per call.
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
0
2
4
6
8
10
12
CMR
Pa
gi
ng
 c
os
t p
er
 c
al
l
 
 
DB
DBCAN
DBACAN
(b) Paging cost per call.
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
0
0.5
1
1.5
2
2.5
3
3.5
4
4.5
5
CMR
Co
st
 o
f u
sin
g 
th
e 
ad
 h
oc
 n
et
wo
rk
 p
er
 c
al
l
 
 
DBCAN
DBACAN
(c) Cost of using the ad hoc network per call.
Fig. 12. Individual costs for CMR = 0.1 to CMR = 0.9 under the IID mobility model.
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
0
5
10
15
20
25
CMR
To
ta
l c
os
t p
er
 c
al
l
 
 
DB
DBCAN
DBACAN
(a) Total cost per call.
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
0
0.5
1
1.5
2
2.5
3
3.5
CMR
Pa
gi
ng
 d
el
ay
 p
er
 c
al
l
 
 
DB
DBCAN
DBACAN
(b) Paging delay per call.
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
CMR
R
at
io
 o
f u
sin
g 
th
e 
ad
 h
oc
 n
et
wo
rk
 
 
DBCAN
(c) Ratio of using the ad hoc network.
Fig. 13. Performance comparison for CMR = 0.1 to CMR = 0.9 under the IID mobility model.
12
1 2 3 4 5 6 7 8 9 10
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
CMR
Lo
ca
tio
n 
up
da
te
 c
os
t p
er
 c
al
l
 
 
DB
DBCAN
DBACAN
(a) Location update cost per call.
1 2 3 4 5 6 7 8 9 10
0
1
2
3
4
5
6
7
8
CMR
Pa
gi
ng
 c
os
t p
er
 c
al
l
 
 
DB
DBCAN
DBACAN
(b) Paging cost per call.
1 2 3 4 5 6 7 8 9 10
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
CMR
Co
st
 o
f u
sin
g 
th
e 
ad
 h
oc
 n
et
wo
rk
 p
er
 c
al
l
 
 
DBCAN
DBACAN
(c) Cost of using the ad hoc network per call.
Fig. 14. Individual costs for CMR = 1 to CMR = 10 under the directional mobility model.
1 2 3 4 5 6 7 8 9 10
0
1
2
3
4
5
6
7
8
9
CMR
To
ta
l c
os
t p
er
 c
al
l
 
 
DB
DBCAN
DBACAN
(a) Total cost per call.
1 2 3 4 5 6 7 8 9 10
0
0.5
1
1.5
2
2.5
CMR
Pa
gi
ng
 d
el
ay
 p
er
 c
al
l
 
 
DB
DBCAN
DBACAN
(b) Paging delay per call.
1 2 3 4 5 6 7 8 9 10
0
0.2
0.4
0.6
0.8
1
1.2
1.4
1.6
1.8
2
CMR
R
at
io
 o
f u
sin
g 
th
e 
ad
 h
oc
 n
et
wo
rk
 
 
DBCAN
(c) Ratio of using the ad hoc network.
Fig. 15. Performance comparison for CMR = 1 to CMR = 10 under the directional mobility model.
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
0
5
10
15
20
25
30
35
40
45
CMR
Lo
ca
tio
n 
up
da
te
 c
os
t p
er
 c
al
l
 
 
DB
DBCAN
DBACAN
(a) Location update cost per call.
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
0
2
4
6
8
10
12
14
16
18
20
CMR
Pa
gi
ng
 c
os
t p
er
 c
al
l
 
 
DB
DBCAN
DBACAN
(b) Paging cost per call.
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
0
1
2
3
4
5
6
7
8
9
10
CMR
Co
st
 o
f u
sin
g 
th
e 
ad
 h
oc
 n
et
wo
rk
 p
er
 c
al
l
 
 
DBCAN
DBACAN
(c) Cost of using the ad hoc network per call.
Fig. 16. Individual costs for CMR = 0.05 to CMR = 0.9 under the directional mobility model.
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
0
10
20
30
40
50
60
CMR
To
ta
l c
os
t p
er
 c
al
l
 
 
DB
DBCAN
DBACAN
(a) Total cost per call.
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
0
0.5
1
1.5
2
2.5
3
3.5
CMR
Pa
gi
ng
 d
el
ay
 p
er
 c
al
l
 
 
DB
DBCAN
DBACAN
(b) Paging delay per call.
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
CMR
R
at
io
 o
f u
sin
g 
th
e 
ad
 h
oc
 n
et
wo
rk
 
 
DBCAN
(c) Ratio of using the ad hoc network.
Fig. 17. Performance comparison for CMR = 0.05 to CMR = 0.9 under the directional mobility model.
14
[3] I. F. Akyildiz, J. McNair, J. S. M. Ho, H. Uzunalioglu, and W.
Wang, “Mobility management in next-generation wireless systems,”
Proceedings of the IEEE, vol. 87, no. 8, pp. 1347–1384, Aug. 1999.
[4] I. F. Akyildiz and W. Wang, “A dynamic location management scheme
for next-generation multitier PCS systems,” IEEE Trans. Wireless Com-
mun., vol. 1, no. 1. pp. 178–189, Jan. 2002.
[5] A. D. Assouma, R. Beaubrun, and S. Pierre, “Mobility management in
heterogeneous wireless networks,” IEEE J. Sel. Areas Commun., vol. 24,
no. 3, pp. 638–648, Mar. 2006.
[6] A. Bar-Noy, I. Kessler, and M. Sidi, “Mobile users: To update or not to
update?” in Proc. IEEE INFOCOM ’94, 1994, pp. 570–576.
[7] G. Fleming, A. El Hoiydi, J. D. Vriendt, G. Nikolaidis, F. Piolini, and
M. Maraki, “A flexible network architecture for UMTS,” IEEE Personal
Commun. Mag., vol. 5, no. 2, pp. 8–15, Apr. 1998.
[8] A. George and A. Kumar, “MHN: An adaptive protocol for mobility
management in multi-hop heterogeneous networks,” in Proc. IEEE ISCC
’05, 2005, pp. 321–326.
[9] IEEE 802.11 WG, “IEEE Standard for Information Technology -
Telecommunications and Information Exchange between Systems -
Local and Metropolitan Area Networks - Specific Requirements - Part
11: Wireless LAN Medium Access Control (MAC) and Physical Layer
(PHY) Specifications,” 2007.
[10] D. J. Lee and D. H. Cho, “On optimum timer value of area and timer-
based location registration scheme,” IEEE Commun. Lett., vol. 5, no. 4,
pp. 148–150, Apr. 2001.
[11] J. Li, H. Kameda, and K. Li, “Optimal dynamic mobility management
for PCS networks,” IEEE/ACM Trans. Networking, vol. 8, no. 3, pp.
319–327, Jun. 2000.
[12] W. Ma, Y. Fang, and P. Lin, “Mobility management strategy based on
user mobility patterns in wireless networks,” IEEE Trans. Vehicular
Technology, vol. 56, no. 1, pp. 322–330, Jan. 2007.
[13] S. M. S. Masajedian and H. Khoshbin, “Cooperative location manage-
ment method in next generation cellular networks,” in Proc. IEEE ISCC
’04, 2004, pp. 525–530.
[14] J. Modares, F. Hendessi, and A. Montazeri, “A profile-based scheme for
location updating and paging in wireless systems,” in Proc. EUROCON
’07, 2007, pp. 1116–1123.
[15] D. Morris and A. H. Aghvami, “A novel location management scheme
for cellular overlay network,” IEEE Trans. Broadcasting, vol. 52, no. 1,
pp. 108–315, Mar. 2006.
[16] M. Mouly and M. B. Pautet, The GSM System for Mobile Communica-
tions. Telecom Publishing, Jun. 1992.
[17] C. K. Ng and H. W. Chan, “Enhanced distance-based location man-
agement of mobile communication systems using a cell coordinates
approach,” IEEE Trans. Mobile Computing, vol. 4. no.1, pp. 41–55,
Jan. 2005.
[18] T. Qin, P. Chang, and X. Li, “A sector-based location management
scheme for PCS networks,” in Proc. IEEE WICOM ’07, 2007, pp. 6468–
6471.
[19] C. Rose, “Minimizing the average cost of paging and registration: A
timer-based methods,” Wireless Networks, vol. 2, no. 2, pp. 109–116,
Jun. 1996.
[20] S. K. Shah, S. Tekinay, and C. Saraydar, “Co-operative location update
algorithm for mobiles in next generation cellular networks,” in Proc.
IEEE HPSR ’04, 2004, pp. 331–336.
[21] M. S. Sricharan and V. Vaidehi, “A dynamic distance based location
management strategy utilizing user profiles for next generation wireless
networks,” in Proc. IEEE ICIIS ’06, 2006, pp. 388–392.
[22] T. Tung and A. Jamalipour, “Adaptive location management strategy to
the distance-based location update techique for cellular networks,” in
Proc. IEEE WCNC ’04, 2004, pp. 172–176.
[23] Z. Wang and J. Zhang, “A speed-adaptive strategy for location manage-
ment cost reduction in cellular networks,” Wireless Networks, vol. 12,
no. 6, pp. 759–769, Nov. 2006.
[24] D. Wisely, H. Aghvami, S. L. Gwyn, T. Zahariadis, J. Manner, V. Gazis,
N. Houssos, and N. Alonistioti, “Transparent IP radio access for next-
generation mobile networks,” IEEE Wireless Commun. Mag., vol. 10,
no. 4, pp. 26–35, Aug. 2003.
[25] V. W. S. Wong and V. C. M. Leung, “An adaptive distance-based location
update algorithm for next-generation PCS networks,” IEEE J. Sel. Areas
Commun., vol. 19, no. 10, pp. 1942–1952, Oct. 2001.
[26] C. H. Wu, H. P. Lin, and L. S. Lan, “A new analytic framework for
dynamic mobility management of PCS networks,” IEEE Trans. Mobile
Computing, vol. 1, no. 3, pp. 208–220, Jul.–Sep. 2002.
[27] H. Wu, C. Qiao, S. De, and O. Tonguz, “Integrated cellular and ad hoc
relaying systems: iCAR,” IEEE J. Sel. Areas Commun., vol. 19, no. 10,
pp. 2105–2115, Oct. 2001.
[28] J. Zhang, “A cell ID assignment scheme and its applications,” in Proc.
IEEE ICPPW ’00, 2000, pp. 507–512.
[29] Y. Zhu and V. C. M. Leung, “Joint distribution of numbers of location
updates and cell boundary crossings in movement-based location man-
agement schemes,” IEEE Commun. Lett., vol. 11, no. 12, pp. 943–945,
Dec. 2007.
2the outermost corona because of its greater sensing range.
Thus, the total number of sensor nodes used, which can be
determined by the number of sensor nodes in the outermost
corona, is reduced. In the following, we shall simply call
the scheme in [28] Wu’s scheme. For Strategy II, it achieves
the longest network lifetime through the EPND and a simple
sensing/non-sensing switch scheduling. It is able to use as
few sensor nodes as possible with the help of the simple
switch scheduling. Therefore, only active sensor nodes need
to sense their surrounding area (and forward data, if any)
to allow inactive sensor nodes to remain idle to conserve
energy if they are not chosen to relay data. This enables a
longer network lifetime with fewer sensor nodes as compared
to Wu’s scheme although unbalanced energy consumption is
still possible. Moreover, the total number of sensor nodes
used by Wu’s scheme increases exponentially as the network
radius goes. However, a linear trend in terms of the network
radius is exhibited by Strategy II. Like Strategy I, fewer sensor
nodes in the outermost corona are required for Strategy III as
compared to Wu’s scheme and Strategy II. Similar to Strategy
II, energy conservation makes fewer sensor nodes required in
the other coronas. Therefore, Strategy III requires the fewest
sensor nodes among the three proposed strategies.
The rest of this paper is organized as follows: Section II
reviews the related work and Section III gives corona models
and some definitions to be used later. In Section IV, the
analyses for corona models, GND, and EPND are carried out.
Based on the analyses, we then propose three non-uniform
node distribution strategies in Section V. Section VI shows
the analytical results and the comparison with the other two
strategies in the literature along with detailed discussions
under an ideal scenario. In Section VII, ns-2 simulation
results under more realistic scenarios are provided to show the
impacts caused by some factors of routing and medium access
control (MAC) protocols. Finally, Section VIII concludes this
paper.
II. RELATED WORK
In the past, Esseghir et al. [8] and Lian et al. [16] focused on
the non-uniform initial energy distribution. The fundamental
idea behind this topic is to differentiate sensor nodes with
different initial levels of energy according to the workload.
The higher the workload is, the higher the initial level of
energy will be set. Although such a strategy seems to be
promising, its application is difficult since it will be very
inconvenient in production and deployment of sensor nodes
[4], [28]. In [1], [18], [27], sink mobility was introduced to
avoid the formation of energy holes. Bi et al. [1] proposed
an autonomous movement strategy called half-quadrant-based
moving strategy (HUMS) to let mobile sinks move pro-actively
towards half-quadrant zones with abundant energy. Similarly,
Marta and Cardei [18] showed that the network lifetime
improvement by using mobile sinks can reach 3.48 times
at most (when the mobile sink moves around a hexagonal
network perimeter and stops at the six corners) as compared
to the case with static sinks. Furthermore, a distributed and
localized mobile sink movement algorithm was also designed
by Marta and Cardei to let mobile sinks be always connected
to each other so that the network lifetime can be prolonged.
Since the gain of sink mobility can be offset by broadcasting
the new location of the sink to every node in the network, Wu
and Chen [27] tried to incorporate both a static sink and a
mobile sink in designing a WSN by putting the static sink at
the center of the monitored area and allowing the mobile sink
to move around the network perimeter. Every time the mobile
sink stops at a new location, it only broadcasts location update
messages to a subset of sensor nodes near the mobile sink.
Although mobile sinks bring some advantages to WSNs,
some new issues are also introduced to routing protocols.
Hence, many researchers focused on energy-aware routing
protocol as well for WSNs in recent years [10], [12], [20].
In [10], Gatzianas and Georgiadis presented a distributed
algorithm to select routing paths for data to be delivered
to the mobile sink to maximize the network lifetime in a
WSN with a mobile sink. Heo et al. [12] proposed an energy-
aware routing protocol for wireless industrial sensor networks
(WISNs) providing real-time and reliable communications by
selecting a path randomly according to a probability. Their
routing protocol exhibits better performance than existing
quality of service (QoS) routing protocols in terms of packet
loss and delay. Since the WSN coverage is also important,
Perillo and Heinzelman [20] proposed an integrated routing
and sensor selection protocol called distributed activation
with predetermined routes (DAPR) to avoid a path selected
from a subset of the region with sparsely distributed sensor
nodes. Besides coverage consideration, their protocol can also
improve the network lifetime.
In the literature, energy-aware node distribution was pro-
posed to alleviate the energy hole problem in WSNs, too, for
example [3], [4], [13], and [28]. In [3], Chang and Chang
proposed an efficient node placement, topology control, and a
scheduling protocol for the MAC layer to prolong the network
lifetime, to balance power consumption among sensor nodes,
and to avoid transmission collision in a grid-based WSN.
Cheng et al. [4] formulated a constrained multi-variable non-
linear programming problem to determine both locations of
sensor nodes and data transmission patterns so that the network
lifetime is maximized and the application-specific total cost
is minimized given the number of sensor nodes. Hou et al.
[13] considered a two-tiered WSN, namely, a WSN with a
sink, cluster head sensors to forward data to the sink, and
low-cost sensors to sense the surrounding area. They tried to
solve simultaneously the energy provisioning and relay node
placement problems using a heuristic approach by transform-
ing a mixed-integer non-linear programming problem into a
linear programming problem. To the best of our knowledge,
one of novel node distribution approaches was proposed by
Wu et al. in [28]. They analyzed the theoretical aspects of
mitigating the energy hole problem in a corona-based WSN
with the aid of a non-uniform node distribution strategy. They
claimed that balanced energy depletion among sensor nodes
is impossible due to the traffic pattern of WSNs, while sub-
balanced energy depletion in the network is still achievable.
In fact, their proposed strategy will be the stepping stone for
Strategy I in the third year of this project. Nevertheless, we can
4In corona model I, the sensor node sensing and transmission
ranges are su and du, respectively, where the subscript u is
used to explicitly denote the uniform corona width and the
width of each corona is set to the node sensing range. In
corona model II, the sensor nodes in the innermost corona
through the corona right next to the outermost corona have
the sensing and transmission ranges of s and d, respectively.
However, the sensor nodes in the outermost corona have longer
sensing and transmission ranges of so and do, respectively,
where the subscript o denotes the outermost corona. Therefore,
we have so > s and do > d. If the network radius R and the
number of coronas k are fixed for both models, we have the
following property: s < su < so. In general, the sensing range
of a sensor node is shorter than or equal to its transmission
range, i.e., s ≤ d, su ≤ du, so ≤ do. Since it is reasonable to
set the transmission range in proportion to the sensing range,
i.e., d = ηs, du = ηsu, do = ηso (η is a constant and η ≥ 1),
we have d < du < do accordingly given fixed R and k for both
models. Finally, let Ci (i = 1, . . . , k) denote the ith corona.
As far as energy consumption is concerned, a common
energy model for receiving and transmitting data used in [1],
[19], [27], [28] is employed in the third year of this project
as well. We assume that a sensor node consumes energy of
Eelec + ² · distα and Eelec, respectively, to transmit (over dist
distance) and receive 1 bit of data. Here, Eelec and ² are
device parameters and α is the path loss attenuation factor
depending on the system environment. According to [11],
the typical values for these parameters are Eelec = 50 nJ/bit,
² = 0.0013 pJ/bit/m4, and α = 4. As for the sensing/idel
energy consumption, it is actually ignored for simplicity in
the theoretical energy depletion analysis. However, a constant
sensing/idle energy consumption is considered in our ns-2
simulations (see the simulation setting later) to make the
simulation scenario realistic.
B. Definitions
In the following, three definitions to be used throughout this
paper are given:
Definition 3.1: The corona lifetime (measured in unit time
(or rounds)) in corona Ci is defined as the ratio of the
total initial energy in corona Ci and the energy consumption
per unit time in corona Ci. Denoting the initial energy of
each sensor node and the total number of sensor nodes in
corona Ci by ε and Ni, respectively, the total initial energy in
corona Ci is then εNi. Further letting Ei stand for the energy
consumption per unit time in corona Ci, the corona lifetime
in corona Ci is εNiEi .
Definition 3.2: The network lifetime (measured in unit time
(or rounds)) is defined as the time interval from the very
beginning of the network operation until the instant at which
the first sensor node depletes its energy. Alternatively, the
network lifetime is the shortest lifetime of a sensor node. If
the energy consumption of each sensor node within corona Ci,
∀i, is uniform/identical (i.e., the energy consumption of each
sensor node within corona Ci, ∀i, is the same), the energy
consumption per unit time of each sensor node in corona Ci
is then Ei/Ni. For such a case, the lifetime of any sensor
node in corona Ci is εEi/Ni =
εNi
Ei
which is the same as the
corresponding corona lifetime defined previously. Therefore,
the network lifetime can then be determined by the shortest
corona lifetime and is expressed as min∀i{ εNiEi }.
Although the network lifetime from the beginning until the
instant at which the last node dies is analytically tractable, it
not meaningful since the connectivity cannot be guaranteed
during this network lifetime. As for the network lifetime
from the beginning until the instant at which the network
gets partitioned, it totally makes sense. However, it is not
analytically tractable. To have meaningful and analytically
tractable network lifetime, we consider the network lifetime
defined above only. In fact, this definition of network lifetime
was widely employed in the literature as well.
Definition 3.3: Balanced energy depletion means that all
sensor nodes in the network deplete their energy simulta-
neously, namely, the lifetimes of all sensor nodes are the
same and identical to the corresponding network lifetime. If
the uniform energy consumption of each sensor node within
the same corona is achievable, then the balanced energy
depletion is achieved if εNiEi =
εNj
Ej
, ∀i, j, i 6= j. The reason
is illustrated as follows. By Definitions 3.2, the network
lifetime is min∀i{ εNiEi }. Because of εNiEi =
εNj
Ej
, ∀i, j, i 6= j,
min∀i{ εNiEi } = εNiEi =
εNj
Ej
, ∀i, j, i 6= j. Therefore, εEi/Ni =
ε
Ej/Nj
= min∀i{ εNiEi }, ∀i, j, i 6= j, which says that the
lifetimes of all sensor nodes are the same and identical to
the network lifetime, i.e., balanced energy depletion.
IV. ANALYSIS ON THE CORONA MODEL
Based on the optimal sensor node placement to be derived,
the minimum number of sensor nodes necessary to meet
the coverage requirement of each corona is then derived.
Afterwards, energy depletion analyses are given. Finally, we
prove that balanced energy depletion is analytically achievable
for two primitive node distributions.
A. Optimal Sensor Node Placement
In the following theorem, the optimal position of a sensor
node within a corona is given.
Theorem 4.1: Assume a corona model
(k,w1, . . . , wi, . . . , wk) with si, i = 1, . . . , k, denoting
the sensing range of the sensor node in corona Ci and
wi
2 ≤ si ≤
√
2
(∑i
j=1 wj
)
. The optimal position of a sensor
node within corona Ci can be determined so that the maximum
corona coverage is reached. Let this optimal position be
located at the position with distance bopti measured from the
center of the corona, then bopti , i = 1, 2, . . . , k, should satisfy
the following conditions:
bopt1 =
{ √
w21−s21
3 ,√
s21 − w21,
for w12 ≤ s1 ≤ w1,
for w1 < s1 ≤
√
2w1,
(1)
bopti =
√
(∑i−1j=1 wj)2+(∑ij=1 wj)2−2s2i
2 , i = 2, . . . , k.
(2)
Proof: Without loss of generality, we assume that the
sensor node within corona Ci is deployed at (0, bi), bi ≥ 0.
This theorem is then proven through the following two cases:
6iC  
opt
i
b  is  
i
θ  
(a)
 
 
 
 
 
 
1
i
jj
w
=
∑  
i
s  
2iθ  
opt
i
b  
(b)
Fig. 2. Sensor nodes deployed in corona Ci with optimal positions. (a) The
maximum angle of two adjacent sensor nodes in order to cover the corona.
(b) The representative triangle taken from Fig. 2(a).
Note that the third equality holds because
fi(y2(bi)− bi) = fCi(y2(bi)) = x2(bi) and
fi(y1(bi)− bi) = fCi−1(y1(bi)) = x1(bi) (see Fig. 1(b)).
Certainly, g′(bopti ) = 0 which gives
bopti =
√√√√(∑i−1j=1 wj)2 + (∑ij=1 wj)2 − 2s2i
2
.
Again, one can easily check that g′′(bopti ) > 0 so that g(b
opt
i ) is
minimized to reach the maximum coverage. The above result
then proves the second part of this theorem. Finally, combining
the two parts completes the proof of this theorem.
B. Lower Bounds on Sensor Nodes Deployed in Coronas
Based on Theorem 4.1, the minimum number of sensor
nodes that should be deployed in each corona is determined
by the following corollary.
Corollary 4.1: The minimum number of sensor nodes that
should be deployed in corona Ci in order to fully cover this
corona is
Nmini =
 360
◦
2 cos−1
(
(bopt
i
)2+(∑ij=1 wj)2−s2i
2bopt
i (
∑i
j=1 wj)
)
 ,
for i = 1, . . . , k.
(3)
Proof: Two adjacent sensor nodes placed according to
Fig. 2(a) can cover corona Ci with the largest coverage without
any gap between them. Using the cosine law, the maximum
half angle θi/2 of the two adjacent sensor nodes deployed in
corona Ci as shown in Fig. 2(b) can be derived as follows:
s2i = (b
opt
i )
2 +
 i∑
j=1
wj
2 − 2bopti
 i∑
j=1
wj
 cos ( θi2 ) ,
leading to
θi = 2 cos−1
 (bopti )2 +
(∑i
j=1 wj
)2
− s2i
2bopti
(∑i
j=1 wj
)
 .
Since the full angle of each corona is 360 ◦, the minimum
number of sensor nodes that should be deployed in corona Ci
in order to fully cover this corona is given by
Nmini =
 360
◦
2 cos−1
(
(bopt
i
)2+(∑ij=1 wj)2−s2i
2bopt
i (
∑i
j=1 wj)
)
 ,
for i = 1, . . . , k.
C. Energy Depletion Analysis
Basically, sensor nodes in the outermost corona only need
to transmit their own data, while sensor nodes in the other
coronas not only transmit their own data but also relay data
from outer coronas. Now, let us analyze the energy depletion.
Denoting Ni, Nai , Ei, and di as the number of sensor nodes,
number of active sensor nodes, energy consumed per unit time,
and transmission distance of sensor nodes, respectively, in
corona Ci, the energy consumption per unit time in corona Ci
is calculated as follows according to our energy consumption
model:
Ei =

L[Nai (Eelec + ²d
α
i )
+
∑k
j=i+1N
a
j (2Eelec + ²d
α
i )], 1 ≤ i ≤ k − 1,
NakL (Eelec + ²d
α
k ) , i = k.
(4)
Under the basic operation mode, all sensor nodes are active
with the following corresponding energy consumption per unit
time denoted by EBi .
EBi =

L[Ni (Eelec + ²dαi )
+
∑k
j=i+1Nj(2Eelec + ²d
α
i )], 1 ≤ i ≤ k − 1,
NkL (Eelec + ²dαk ) , i = k,
(5)
where the superscript B is used to explicitly denote the basic
operation mode. Note that the main task of an active sensor
node is either sensing its surrounding area and transmitting
data to its child node or relaying data from its parent node if
it is chosen as the relay node. If a sensor node does nothing
at all, it will remain idle to save energy. Hence, the energy
consumption per unit time with a minimum number of active
sensor nodes Nmini in corona Ci derived from Corollary 4.1
denoted by EMi (here, the superscript
M is used to explicitly
denote the minimum active sensor nodes getting involved) is
EMi =

L[Nmini (Eelec + ²d
α
i )
+
∑k
j=i+1N
min
j (2Eelec + ²d
α
i )], 1 ≤ i ≤ k − 1,
Nmink L (Eelec + ²d
α
k ) , i = k.
(6)
D. Balanced Energy Depletion Analysis for Two Primitive
Node Distributions
In the following, the feasibility of balanced energy depletion
using two primitive node distributions, i.e., GND specifically
designed for corona model II and EPND, is examined.
8Relating d and do, respectively, to w and wo via d = c1w
and do = c2wo, where c1 and c2 are positive multipliers of
corona widths in the relationship between the sensor node
transmission range and the corona width, d and do can then
be determined by using (8). Note that c1 ≥ 1 and c2 ≥ 1 so
that at least one of sensor nodes in the neighboring corona can
be reached by a specific sensor node. Then, the connectivity
between any sensor node and the sink node can be ensured.
With such setting for c1 and c2, the problem of connectivity
is then avoided. Of course, the larger c1 and c2 are, the more
sensor nodes in the neighboring corona can be reached. In
the following, we only show the result when c1 = c2 for ease
of calculation. For simplicity, we introduce c (≥ 1) to serve
as the common multiplier, i.e., c = c1 = c2. Now, (8) can be
rewritten as
(k − 1)d+ do = cR. (9)
Applying Theorem 4.2, we have
(k − 1)d+
[
2Eelec + q²dα
(q − 1)²
] 1
α
− cR = 0. (10)
(10) in terms of d can be solved numerically, for example,
by the Bisection method (see [21] for details). Once the value
of d is determined, the transmission range of sensor nodes
in a different corona is then totally determined according to
Theorem 4.2 via
di =
{
d, for i = 1, 2, . . . , k − 1,
do, for i = k.
(11)
Similarly, the width of each corona, i.e., w and wo, can be
calculated (i.e., w = d/c and wo = do/c) accordingly once d
and do are fixed.
2) Sensor node arrangement and deployment: As for the
number of sensor nodes deployed in a corona, it follows the
GND to have
Ni =
 qNi+1, i = 1, 2, . . . , k − 2,(q − 1)Nk, i = k − 1,
Nmink , i = k,
(12)
where q ∈ N − {1} is the common ratio of the geometric
progression. Note that Ni (i = 1, 2, . . . , k) implicitly depend
on d and do. Let us further consider the deployment of sensor
nodes. Taking a closer look at Theorem 4.1 for the innermost
corona, one can see that the positions of sensor nodes are
identical to that of the sink. Such deployment is impractical.
Therefore, we suggest deploying sensor nodes at the middle
of the corona width in the innermost corona. As for the
other coronas, Theorem 4.1 is applicable for deployment of
sensor nodes to reach optimal positions of sensor nodes in the
coronas.
3) Routing protocol: Because of the corona arrangement
and the geometric progression on the number of sensor nodes
deployed in a corona, the q-switch routing proposed in [28]
and described in Section II is still applicable to Strategy I for
data routing. Therefore, the routing protocol associated with
Strategy I in the third year of this project is set to this q-switch
routing.
With the aforementioned design, one can clearly see that
Strategy I differs from Wu’s scheme [28] in the following
aspects. i) Strategy I is designed based on corona model II,
while Wu’s scheme is designed based on corona model I. ii)
Using Strategy I, completely balanced energy depletion can be
reached. However, Wu’s scheme claimed that it is impossible
to achieve completely balanced energy depletion. Therefore,
Wu’s scheme simply reaches sub-balanced energy depletion.
iii) The optimal sensor placement is touched in the third year
of this project and utilized by Strategy I. Since the optimal
sensor node placement is not touched in [28], Wu’s scheme
does not employ the optimal sensor node placement.
B. Strategy II (Designed for Corona Model I)
Strategy II consists of a constraint on the number of sensor
nodes that should be deployed based on the EPND, a simple
switch scheduling, and a q-switch-like routing protocol under
corona model I. Now, these are explained in detail as follows.
1) Sensor node arrangement and deployment: In order to
achieve better efficiency on sensor node arrangement in each
corona, each sensor node is assumed to be either in the
sensing or the non-sensing state. With the same reasoning for
the deployment of sensor nodes in Strategy I, a deployment
scheme based on Theorem 4.1 except for the innermost corona
in which we suggest deploying sensor nodes at the middle of
the corona width is employed for Strategy II in the following.
As for the number of sensor nodes to be deployed, it follows
the EPND to form the following constrained EPND (CEPND):
Ni =
{ ⌈⌈
EMi
EMk
Nmink
⌉
/Nmini
⌉
Nmini , for i = 1, . . . k − 1,
Nmink , for i = k,
(13)
Note that EMi , i = 1, 2, . . . , k − 1, are still applicable here
since the switch scheduling can control the energy consump-
tion to EMi for corona Ci. In the previous calculation, the
following operations are required. i) The inner ceil function
d·e is employed in order to have an integer number of sensor
nodes if E
M
i
EMk
Nmink is not an integer. ii) The outer ceil function
d·e is used to ensure that the number of sensor nodes in corona
Ci, i.e., Ni, to be a multiple of the minimum number of sensor
nodes Nmini . Note that the requirement that Ni is a multiple
of the minimum number of sensor nodes Nmini is tailored for
the switch scheduling with consideration of coverage. With
these extra operations, energy depletion is perhaps not com-
pletely balanced among sensor nodes. However, Strategy II is
expected to give the best performance in the network lifetime
and efficiency on sensor node arrangement as compared to
Wu’s scheme and Strategy I to be shown in the next section.
2) Switch scheduling: A simple switch scheduling in a turn-
based manner utilizing counters determines whether a sensor
node needs to sense its surrounding area or not. Shown in
Fig. 3 is the pseudocode for our designed switch scheduling
in corona Ci. Sensor nodes not chosen to sense its surrounding
area will remain idle or relay the data received from its upper
sensor node in the outer corona. Of course, sensor nodes
chosen to sense its surrounding area need to perform this task
solely or along with some extra task, i.e., data relay, if any.
10
However, the three components should be designed based on
corona model II like Strategy I. Since the three components
for Strategy III can be easily obtained from the corresponding
three components of Strategy II, they will not be further
elaborated for making this paper concise and compact.
VI. ANALYTICAL RESULTS UNDER AN IDEAL SCENARIO
AND DISCUSSIONS
Now, analytical performance metrics of the three proposed
strategies are examined under an ideal scenario, including
• total number of sensor nodes required for the network
operation,
• network lifetime (defined according to Definition 3.2),
and
• residual energy of each sensor node when the network
operation is terminated.
Here, the ideal scenario only considers an ideal MAC layer and
does not consider the energy consumption in sensing and idle
states. The three proposed strategies are also compared with
the following two different node distribution strategies: Wu’s
scheme [28] and uniform node distribution (simply called
uniform scheme) which is a typical sensor node distribution
strategy with uniformly distributed sensor nodes in the net-
work.
Referring to (12) and (13), the total numbers of sensor nodes
required can be determined accordingly for the three proposed
strategies as well as Wu’s scheme. As for the uniform scheme,
it can be counted easily because of its fixed grid length. Let
us now further derive the network lifetime and residual energy
as follows. By Definition 3.2, the network lifetime T is
T = min{T1, T2, . . . , Tk}. (14)
For Wu’s scheme, the network lifetime TW can be determined
analytically in terms of any of T1, . . . , Tk−1 because T1 =
T2 = . . . = Tk−1 < Tk (see [28]), i.e.,
TW = T1 = . . . = Tk−1. (15)
Because Strategy I balances energy depletion among sensor
nodes, the network lifetime TS1 can be analytically expressed
in terms of any of T1, . . . , Tk, i.e.,
TS1 = T1 = . . . = Tk. (16)
For Strategies II and III,
Ti =
εNi
EMi
=
ε
⌈⌈
EMi
EMk
Nmink
⌉
/Nmini
⌉
Nmini
EMi
≥
ε((E
M
i
EMk
Nmink )/N
min
i )N
min
i
EMi
=
εNk
EMk
= Tk, i = 1, 2, . . . , k − 1.
Therefore, their corresponding network lifetimes TS2 and TS3
can be expressed by
TS2 = TS3 = Tk. (17)
Finally, it is easily understood that T1 ≤ T2 ≤ . . . ≤ Tk for
the uniform scheme. Accordingly, its network lifetime TU is
TU = T1. (18)
As for the residual energy of the ith corona ERi (i =
1, 2, . . . , k), it can be calculated via
ERi =
 εNi − TEi, Wu’s Scheme, Strategy I,and Uniform Scheme,
εNi − TEMi , Strategies I and II,
(19)
where the network lifetime T for a different strategy should
follow the calculation in (15)–(18).
In this section, network lifetime and residual energy are
also validated by simulations written in the C# programming
language. Before the discussions on the analytical results, let
us further elaborate on the calculation/simulation arrangement
first.
A. Calculation/Simulation Arrangement
In our calculation/simulation, each sensor node has a uni-
form initial amount of energy ε = 0.5 J with Eelec = 50 nJ/bit,
² = 0.0013 pJ/bit/m4, α = 4, and η = 1 (the sensing range is
the same as the transmission range). In the uniform scheme,
Wu’s scheme, and Strategy I, each sensor node generates 400
bits of data each round with duration of 1 ms, while only the
sensor nodes staying in the sensing state for Strategy II/III
generate 400 bits of data. In Strategy I/III, c = 1, i.e., the
transmission range of each sensor node is equal to the corona
width. For a given network radius R, the number of coronas
k is obtained via k = R/du for all strategies considered.
Therefore, the corona width is fixed for Wu’s scheme, Strategy
II, and the uniform scheme. To have a different network radius,
a different number of coronas is arranged accordingly. For
Strategies I and III, the number of coronas is determined
like Strategy II once a network radius is given. However, d
and do need to be recalculated based on (9) using the given
network radius. Consider an example of the 5-corona network
arrangement with network radius of 500 m. For Strategy I/III,
we have d = 94.0904 m, do = 123.6383 m, and Nmin5 = 15.
For Wu’s scheme and Strategy II, uniform corona width
du = 100 m and Nmin5 = 19 are set. Noting that sensor nodes
are deployed at corners of grids with grid length of 50 m for
the uniform scheme, we have uniform corona width du = 100
m, N1 = 12, N2 = 36, N3 = 64, N4 = 84, and N5 = 120. In
Table I, all corresponding parameters are listed.
B. Analytical Results and Discussions
1) Total number of sensor nodes: Shown in Fig. 4(a) are
the analytical results on the total number of sensor nodes
used in the network for the five strategies under various
network radii ranging from 300 to 1000 m. Obviously, the
total numbers of sensor nodes in Wu’s scheme and Strategy I
increase exponentially, while the total numbers of sensor nodes
in Strategy II, Strategy III, and the uniform scheme almost
increase linearly. For Strategy I, fewer sensor nodes are used
in the network as compared to Wu’s scheme. The difference is
magnified as the network radius increases due to the fact that
12
outer coronas, more energy consumption is required when the
network radius gets larger due to a higher amount of data to
relay per round. Therefore, the network lifetime of the uniform
scheme as shown in Fig. 5(a) has a decreasing trend as the
network radius increases. In fact, the uniform node distribution
makes N1 for the uniform scheme the smallest as compared
to those of the other four strategies. Explicitly, the uniform
scheme gives the worst performance among the five strategies.
Different from the uniform scheme, Wu’s scheme, and
Strategy I which let all sensor nodes sense the surrounding
area per round, Strategy II/III only sets a minimum number of
sensor nodes determined by Nmini in corona Ci to sense the
surrounding area per round. Besides, Strategy III sets the same
number of sensor nodes with same energy dissipation for the
outermost corona as Strategy I, while Strategy II sets more
sensor nodes with less energy dissipation for the outermost
corona than Strategy I. Noting that the corona lifetime of
the outermost corona Tk determines the network lifetime for
Strategy II from (17) and Tk = εNkEk =
εNk
Nk(Eelec+²dαk )
=
ε
(Eelec+²dαu)
for Strategy II is a constant, its network lifetime is
a constant. This explains why a constant behavior of network
lifetime for Strategy II as shown in Fig. 5(a) is observed.
(17) also shows that the network lifetime of Strategy III is
determined by the corona lifetime of the outermost corona Tk.
With the same corona model and the same number of sensor
nodes with same energy dissipation in the outermost corona
as Strategy I, the network lifetime of Strategy III is identical
to that of Strategy I (see (16) and (17)). This explains why the
network lifetimes of Strategies I and III coincide in Fig. 5(a).
Since more sensor nodes with less energy dissipation in the
outermost corona for Strategy II as compared to Strategy I,
Strategy II has a longer network lifetime than Strategy I as
well as Strategy III (see (16) and (17)).
The above observations clearly illustrate that the best strat-
egy to the worst strategy in terms of network lifetime are
Strategy II, Strategy I as well as Strategy III, Wu’s scheme,
and the uniform scheme. Since the uniform scheme performs
worst, we only show the improvement ratios for Strategies
I–III over Wu’s scheme in Fig. 5(b). This figure shows that
Strategy II gains 128% of improvement over Wu’s scheme
regardless of network radii. At the network radius of 300 m
(1000 m), Strategies I and III can get 28% (8%) of improve-
ment over Wu’s scheme. This clearly reveals the superiority
of Strategy II over the other strategies in terms of network
lifetime.
3) Residual energy of each sensor node: In this part, the
residual energy for the five strategies under a 5-corona model
is evaluated. Note that sensor nodes are assigned IDs starting
from the outermost corona to the innermost corona.
Shown in Fig. 6 is the residual energy of each node (or
called the residual nodal energy later) for the five strategies.
Explicitly, one can witness that the analytical and simulation
results match well. From Fig. 6(e), one can easily see that the
uniform scheme leaves an abundant amount of nodal energy
as expected, especially for the sensor nodes in the outermost
corona Approximately, 96% of the initial nodal energy is left
there. Fig. 6(a) shows that Wu’s scheme leaves a considerable
amount of remaining nodal energy (56% or so of the initial
50 100 150 200 250 300
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
0.45
0.5
Node ID
R
es
id
ua
l e
ne
rg
y 
(in
 jo
ule
)
 
 
Simulation
Analysis
(a)
50 100 150 200
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
0.45
0.5
Node ID
R
es
id
ua
l e
ne
rg
y 
(in
 jo
ule
)
 
 
Simulation
Analysis
(b)
50 100 150 200 250
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
0.45
0.5
Node ID
R
es
id
ua
l e
ne
rg
y 
(in
 jo
ule
)
 
 
Simulation
Analysis
(c)
20 40 60 80 100
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
0.45
0.5
Node ID
R
es
id
ua
l e
ne
rg
y 
(in
 jo
ule
)
 
 
Simulation
Analysis
(d)
50 100 150 200 250 300
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
0.45
0.5
Node ID
R
es
id
ua
l e
ne
rg
y 
(in
 jo
ule
)
 
 
Simulation
Analysis
(e)
Fig. 6. Residual energy of each sensor node under an ideal scenario. (a)
Wu’s scheme. (b) Strategy I. (c) Strategy II. (d) Strategy III. (e) Uniform
scheme.
nodal energy) in the outermost corona when the network
operation is terminated. For Strategy I, almost all sensor nodes
exhaust energy when the network operation is terminated as
shown in Fig. 6(b). In fact, the residual nodal energy for
most of sensor nodes is below 5 × 10−4 J when applying
Strategy I. As shown in Fig. 6(c), Strategy II still gives quite
good performance in the residual nodal energy although not
all sensor nodes completely exhaust energy. The remaining
nodal energy is at most 13% of the initial nodal energy (in
the 4th corona) only. Similar to Strategy II, Strategy III gives
quite good performance in the residual nodal energy as well.
As shown in Fig. 6(d), only 16% at most of the initial nodal
energy is left among sensor nodes (in the 2nd corona).
To have a comparison on the degree of energy depletion
as compared to the ideal case with complete energy depletion
(zero energy left), one can use the following two ways to
gauge this degree. The first one is the total residual energy
in the network and the second one is dνe =
∑
∀j(E
R,j)ν/nt.
Here, dνe is the defined degree of energy depletion as compared
to the ideal case, ER,j denotes the residual energy of the
senor node with ID j, ν ≥ 1 serves as a given amplifying
factor used to amplify the difference of the residual nodal
energy to zero, and nt is the number of total sensor nodes
deployed. Note that d1e (when ν = 1) is simply the mean
residual nodal energy, while d2e (when ν = 2) represents the
14
300 400 500 600 700 800 900 1000
0
1000
2000
3000
4000
5000
6000
7000
8000
Network radius (in meters)
N
et
w
or
k 
life
tim
e 
(in
 ro
un
ds
)
 
 
Wu scheme (Ideal)
Wu scheme (Realistic I)
Strategy I (Ideal)
Strategy I (Realistic I)
Strategy II (Ideal)
Strategy II (Realistic I)
Strategy III (Ideal)
Strategy III (Realistic I)
Uniform (Ideal)
Uniform (Realistic I)
(a)
300 400 500 600 700 800 900 1000
0
1000
2000
3000
4000
5000
6000
7000
8000
Network radius (in meters)
N
et
w
or
k 
life
tim
e 
(in
 ro
un
ds
)
 
 
Wu scheme (Ideal)
Wu scheme (Realistic II)
Strategy I (Ideal)
Strategy I (Realistic II)
Strategy II (Ideal)
Strategy II (Realistic II)
Strategy III (Ideal)
Strategy III (Realistic II)
Uniform (Ideal)
Uniform (Realistic II)
(b)
300 400 500 600 700 800 900 1000
0
20
40
60
80
100
120
Network radius (in meters)
Im
pr
ov
em
en
t r
at
io
 (in
 pe
rce
nt)
 
 
Strategy I
Strategy II
Strategy III
(c)
300 400 500 600 700 800 900 1000
0
10
20
30
40
50
60
70
80
90
100
Network radius (in meters)
Im
pr
ov
em
en
t r
at
io
 (in
 pe
rce
nt)
 
 
Strategy I
Strategy II
Strategy III
(d)
Fig. 7. Network lifetime and improvement ratio. (a) Network lifetime (Realistic I). (b) Network lifetime (Realistic II). (c) Improvement ratio over Wu’s
scheme (Realistic I). (d) Improvement ratio over Wu’s scheme (Realistic II).
TABLE II
TOTAL RESIDUAL ENERGY IN THE NETWORK AND d2e FOR THE FIVE STRATEGIES UNDER DIFFERENT SCENARIOS
Scenario Wu’s Scheme Strategy I Strategy II Strategy III Uniform Scheme
Ideal 5.41 J, 4.9× 10−3 0.07 J, 9.2× 10−8 7.12 J, 1.3× 10−3 3.09 J, 1.9× 10−3 136.3 J, 0.195
Realistic I 5.21 J, 3.9× 10−3 0.47 J, 4.4× 10−6 5.88 J, 8.4× 10−4 2.72 J, 1.5× 10−3 135.2 J, 0.192
Realistic II 4.92 J, 3.7× 10−3 1.37 J, 3.6× 10−5 6.99 J, 1.0× 10−3 3.56 J, 1.9× 10−3 134.9 J, 0.191
50 100 150 200 250 300
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
0.45
0.5
Node ID
R
es
id
ua
l e
ne
rg
y 
(in
 jo
ule
)
 
 
Ideal
Realistic I
Realistic II
(a)
50 100 150 200
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
0.45
0.5
Node ID
R
es
id
ua
l e
ne
rg
y 
(in
 jo
ule
)
 
 
Ideal
Realistic I
Realistic II
(b)
50 100 150 200 250
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
0.45
0.5
Node ID
R
es
id
ua
l e
ne
rg
y 
(in
 jo
ule
)
 
 
Ideal
Realistic I
Realistic II
(c)
20 40 60 80 100
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
0.45
0.5
Node ID
R
es
id
ua
l e
ne
rg
y 
(in
 jo
ule
)
 
 
Ideal
Realistic I
Realistic II
(d)
50 100 150 200 250 300
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
0.45
0.5
Node ID
R
es
id
ua
l e
ne
rg
y 
(in
 jo
ule
)
 
 
Ideal
Realistic I
Realistic II
(e)
Fig. 8. Residual energy of each sensor node under ideal and realistic
scenarios. (a) Wu’s scheme. (b) Strategy I. (c) Strategy II. (d) Strategy III.
(e) Uniform scheme.
VIII. SELF EVALUATION
Three novel node distribution strategies designed for a
corona-based WSN are proposed in the third year of this
project to mitigate the energy hole problem. Analyzing the
corona-based WSN, we get the optimal positions of sensor
nodes, lower bounds on sensor nodes to be deployed within
a corona, and proposals of GND as well as EPND. These
results enable the three proposed strategies to give full WSN
coverage while providing a long network lifetime. In fact,
one of our proposed strategies, i.e., Strategy I, has succeeded
in solving one of the most difficult tasks in WSNs, namely,
balancing energy depletion among sensor nodes. Incorporating
switch scheduling, Strategy II provides the longest network
lifetime, full WSN coverage, and high efficiency in using
sensor nodes. Similar to Strategy II, Strategy III incorporates
switch scheduling and reaches the best efficiency in using
sensor nodes, full WSN coverage, and a durable network
lifetime. Via both analytical and simulation observations, we
can show the superiority of the three strategies over the other
two most related strategies, i.e., Wu’s scheme and the uniform
scheme. We have successfully demonstrated that Strategies I–
III are highly recommended for use in a small-area WSN,
while Strategies II–III are still highly recommended for a
large-area WSN to achieve a long network lifetime, full WSN
coverage, and efficient usage of sensor nodes.
Note that the current results obtained in this project have
been published in the IEEE Transactions on Mobile Com-
puting, vol. 10, no. 9, September, 2011. Besides, one journal
paper different from the above content has been published in
ACM/Springer Wireless Networks, vol. 19, no. 5, July 2011,
one journal paper different from the above content has been
accepted on December 14, 2010 by the IEEE Transactions on
Parallel and Distributed Systems, and one journal paper dif-
ferent from the above content has been accepted on February
14, 2011 by Springer Wireless Personal Communications as
well under the financial support of this project. No doubt, the
outcome in the third year of this project is fruitful. Finally,
we need to mention that we changed the research topic in the
third year of this project from the original plan to the study
on the WSN.
REFERENCES
[1] Y. Z. Bi, L. M. Sun, J. Ma, N. Li, I. A. Khan, and C. F. Chen, “HUMS:
An autonomous moving strategy for mobile sinks in data-gathering
Design of Fair Scheduling Schemes for
the QoS-Oriented Wireless LAN
Huei-Wen Ferng, Member, IEEE, and Han-Yu Liau
Abstract—How to simultaneously achieve fairness and quality-of-service (QoS) guarantee in QoS-oriented wireless local area networks
(LANs) is an important and challenging issue. Targeting at this goal and jointly taking priority setting, fairness, and cross-layer design into
account, four scheduling schemes designed for the QoS-oriented wireless LANmainly based on concepts of deficit count and allowance
are proposed in this paper to provide better QoS and fairness. Usingmultiple deficit count to interframe space (IFS) and allowance to IFS
mappings for different priorities, enhanced distributed deficit round robin (EDDRR) and enhanced distributed elastic round robin
(EDERR) schemes are designed to reduce (or even eliminate) possible collisions, while EDDRR with backoff interval and EDERR with
backoff interval schemes still keep the backoff procedure but dynamically adjust backoff intervals for nonfailure events (the events
excluding collisions and failed transmissions) depending on the priority setting and deficit count or allowance with a cross-layer design.
Through extensive numerical examples, we show that the proposed schemes outperform the closest scheduling schemes in the
literature and exhibit much better QoS as well as station-level and flow-level fairness.
Index Terms—Wireless LAN, quality of service, scheduling, fairness.
Ç
1 INTRODUCTION
WITH the rapid technological development of wirelesslocal area networks (LANs) and the popularization of
various kinds of mobile devices, we have witnessed
that intensive wireless LANs have been deployed in
metropolitan areas to facilitate wireless access in many
famous cities, including Philadelphia, Cleveland, and
Taipei. Pervasion of wireless LANs stimulates diverse and
multimedia applications, e.g., voice over IP (VoIP) [4], [13]
and video on demand (VoD) [12] run over wireless LANs
due to users’ needs. To support multimedia applications
over wireless LANs, bandwidth has been expanded from 2
Mbps (defined in the IEEE 802.11 standard [14]) to 54 Mbps
(defined in the IEEE 802.11a/g standard [15], [17]). Except
the fundamental bandwidth requirement to support multi-
media applications, how to achieve quality-of-service (QoS)
requirements requested by voice, video, and data, respec-
tively, in wireless (multimedia) networks is a challenging
issue and has drawn much researchers’ attention in the
past, e.g., [1], [6], [13], [35], and [36]. Unfortunately, QoS is
not well taken care and defined in IEEE 802.11 [14], 802.11a
[15], and 802.11b [16] standards. Hence, IEEE 802.11 task
group E (TGe) then modified the distributed coordination
function (DCF) previously defined in the medium access
control (MAC) layer of the IEEE 802.11 standard to form the
so-called enhanced DCF (EDCF) or enhanced distributed
channel access (EDCA) (see Fig. 1) defined in the hybrid
coordination function (HCF) of IEEE 802.11e [18] so that
multimedia transmission in IEEE 802.11 wireless LANs can
be supported. EDCA is able to strengthen some functions of
DCF, for example, multiple queues of different priorities for
fulfillment of QoS guarantee are defined (see Fig. 2). In the
literature, some papers, e.g., [9], [10], [13], [19], [23], [24],
[28], [31], [35], and [36], further addressed the QoS-related
issue in the IEEE 802.11e-based network. In [9] and [10],
Gannoune and Robert proposed the dynamic tuning
method on the maximum and minimum contention
windows to enhance performance of high-priority services
in the ad hoc mode. To support VoIP, a framework was
proposed by Hwang and Cho [13] for the IEEE 802.11e
network. Iera et al. [19] enhanced QoS of multimedia flows
by dynamically adjusting transmission rates for multimedia
flows. In [23], Kim and Cho estimated the status of
contention using the virtual group (VG) scheme to reduce
collision rates. Lan et al. [24] proposed a contention
adaption (CA) scheme to reduce collision rates and shorten
delay time. In [28], a priority-based scheme for bandwidth
assignment depending on different traffic categories was
proposed by Mangold. In [31], a dynamic adjustment
method of the minimum contention window based on the
network status and needs of applications was proposed by
Romdhani et al. to achieve reduction of the collision rate
and increase of the medium utilization. Vinnakote et al. [35]
shortened delay time by adjusting the size of the contention
window and the length of the arbitration interframe space
(AIFS). In [36], Wong and Donaldson proposed an
age-dependent backoff (ADB) scheme for adjusting the
contention window according to the time spent in queue of
real-time services to shorten the delay of real-time services.
For QoS-oriented wireless LANs, e.g., the IEEE 802.11e-
based wireless LAN, QoS guarantee is definitely an issue of
extreme importance. Except QoS guarantee, how to fairly
allocate resources of networks to different services is an
extremely important issue deserving to be addressed as
well. Hence, a fair scheme, for example, a fair scheduling
scheme, to guarantee fair resource sharing among services
880 IEEE TRANSACTIONS ON MOBILE COMPUTING, VOL. 8, NO. 7, JULY 2009
. The authors are with the Department of Computer Science and Information
Engineering, National Taiwan University of Science and Technology,
43 Keelung Road, Section 4, Taipei 106, Taiwan, ROC.
E-mail: {hwferng, M9315006}@mail.ntust.edu.tw.
Manuscript received 28 July 2007; revised 27 Apr. 2008; accepted 21 Oct.
2008; published online 5 Nov. 2008.
For information on obtaining reprints of this article, please send e-mail to:
tmc@computer.org, and reference IEEECS Log Number TMC-2007-07-0222.
Digital Object Identifier no. 10.1109/TMC.2008.156.
1536-1233/09/$25.00  2009 IEEE Published by the IEEE CS, CASS, ComSoc, IES, & SPS
Authorized licensed use limited to: National Taiwan Univ of Science and Technology. Downloaded on May 27, 2009 at 01:52 from IEEE Xplore.  Restrictions apply.
2 THE PROPOSED SCHEMES
In this section, four fair scheduling schemes mainly
designed for the IEEE 802.11e wireless LAN are proposed.
These four schemes can be categorized into schemes with
backoff intervals and schemes without backoff intervals.
Among the four proposed schemes, two of them are
designed based on the concept of deficit counts and the
remaining two are designed based on the concept of
allowances. Let us now elaborate on these four schemes in
the following four sections, respectively.
2.1 Enhanced Distributed Deficit Round Robin with
Backoff Interval (EDDRR-BI)
The deficit count (deficit counter) previously employed by
DDRR [30] plays an important role in scheduling for
EDDRR-BI (so does EDDRR described in the next section)
in which three types of deficit count rather than a single
type of deficit count as in DDRR are defined for access
categories of audio, video, and data (the access category of
background is not considered in this paper). Note that the
deficit count here is used to record the transmission deficit
from the viewpoint of a flow. For convenience, we shall use
the dummy variable l to denote the type of access category
(service class), e.g., l ¼ a is used to denote the access
category of audio, l ¼ v is used to denote the access category
of video, and l ¼ d is used to denote the access category of
data. In the following,DCjl;iðtÞ is nonnegative and is defined
to denote the deficit count at time t of the ith flow of access
category l in station j. DCjl;iðtÞ will accumulate according to
(1) when no data is transmitted since the transmission
deficit for this case is simply the product of the desired
throughput and an elapsed time period plus the previous
transmission deficit (see the linearly incremental segments
in Fig. 3):
DCjl;iðtÞ ¼ DCjl;iðt0Þ þKjl;i  ðt t0Þ; l ¼ a; v; d; ð1Þ
where DCjl;ið0Þ ¼ 0, t0 denotes a reference time instant
within the range of ðts; t with ts denoting the latest
transmission time instant or the starting time instant if no
transmission before t, and Kjl;i stands for the desired
throughput of the ith flow of access category l in station j
(we assume that the desired throughput can be properly
determined via a suitable negotiation process done by a
coordinator). Hence, the definition of deficit counts in (1)
explicitly shows the following two aspects: 1) deficit counts
accumulate linearly as time goes within each segment and
2) deficit counts are proportional to the desired throughput
within each segment. Note that only the desired through-
put Kjl;i is used in this paper for the definition of deficit
counts, while a fixed quantum Q and a variable time
interval T are required for the definition of the deficit
count in [30]. Hence, our definition of deficit counts eases
parameter setting. For the situation when a frame of the
ith flow of access category l in station j is transmitted at
time t under the condition DCjl;iðtÞ  Fls, the frame size
represents the completion amount of transmission and
should be deducted from the corresponding deficit count
right after the transmission (see the vertical segments in
Fig. 3), namely,
DCjl;iðtþÞ ¼ DCjl;iðtÞ  Fls; l ¼ a; v; d; ð2Þ
where DCjl;iðtþÞ ¼ limx>t;x!tDCjl;iðxÞ, and Fls is the frame
size corresponding to access category l. The deficit counts
governed by (1) and (2) can be used to well handle the fair
scheduling issue because of their linear accumulation with
respect to time, their proportional property with respect to
the desired throughput, and their faithful reflection on
transmission.
To incorporate the aforementioned idea of fair schedul-
ing into the IEEE 802.11e wireless LAN, deficit counts here
are related to backoff intervals for nonfailure events which
are events excluding collisions and failed transmissions, i.e.,
events of a busy medium and a successful transmission.
Note that a state variable CW ½l corresponding to access
category l should be maintained in EDCA so that it can be
used to determine the backoff interval when invoking the
backoff procedure. CW ½l can be dynamically adjusted for
different events, e.g., failure events, including collisions and
failed transmissions, and events triggered by successful
transmissions and should fall within ½CWlmin; CWlmax,
where CWlmin and CW
l
max denote the minimum and
maximum contention windows. With CW ½l, the backoff
interval is set randomly using a uniform distribution with
values taken from the range ½0; CW ½l for EDCA. For
EDDRR-BI, a connection between the deficit count and the
backoff interval is directly built for nonfailure events
through the temporary backoff interval at time t of the
ith flow of access category l in station j, i.e., TBID;jl;i ðtÞ
ðl ¼ a; v; dÞ, defined as follows:
TBID;jl;i ðtÞ ¼ CWlmax  Dl DCjl;iðtÞ; l ¼ a; v; d; ð3Þ
where the superscript D is used to explicitly denote
EDDRR-BI, and Dl is a selected constant used to make
the resultant TBID;jl;i ðtÞ fall within the IEEE 802.11e
specification on the backoff interval. To have more direct
results for Dl , l ¼ a; v; d, the following remark is given.
Remark 1. For EDDRR-BI, TBID;jl;i ðtÞ should fall within
½0; CWlmax, l ¼ a; v; d, i.e.,
0  TBID;jl;i ðtÞ  CWlmax; l ¼ a; v; d;
which yield
0  Dl DCjl;iðtÞ  CWlmax; l ¼ a; v; d:
Therefore,
0  Dl 
CWlmax
MDl
; l ¼ a; v; d;
882 IEEE TRANSACTIONS ON MOBILE COMPUTING, VOL. 8, NO. 7, JULY 2009
Fig. 3. Illustration of deficit count ðDCjl;iðtÞÞ versus time ðtÞ.
Authorized licensed use limited to: National Taiwan Univ of Science and Technology. Downloaded on May 27, 2009 at 01:52 from IEEE Xplore.  Restrictions apply.
it is easy to fix the value for D by selecting a number
within ð1;1Þ. With a fixed D and (5)-(7), we have
IFSD;ja;i ðtÞ 
SIFSþ PIFS
2
 Da MDa D;
IFSD;ja;i ðtÞ 
SIFSþ PIFS
2
 Da mDa 
SIFSþ PIFS
2
;
IFSD;jv;i ðtÞ PIFS Dv MDv D;
IFSD;jv;i ðtÞ PIFS Dv mDv  PIFS;
IFSD;jd;i ðtÞ DIFS Dd MDd D;
IFSD;jd;i ðtÞ DIFS Dd mDd  DIFS;
where mDl ¼ mini;j;tDCjl;iðtÞ ð 0Þ, l ¼ a; v; d. Combining
the prespecified ranges for IFSD;jl;i ðtÞ, l ¼ a; v; d, i.e.,
SIFS  IFSD;ja;i ðtÞ 
SIFSþ PIFS
2
;
SIFSþ PIFS
2
 IFSD;jv;i ðtÞ  PIFS;
PIFS  IFSD;jd;i ðtÞ  DIFS;
we can obtain the following limitations for Dl , l ¼ a; v; d:
SIFSþ PIFS
2
 Da MDa D SIFS;
PIFS Dv MDv D 
SIFSþ PIFS
2
;
DIFS Dd MDd D PIFS;
which provide
Da 
PIFS SIFS
2MDa D
;
Dv 
PIFS SIFS
2MDv D
;
Dd 
DIFS PIFS
MDd D
:
Since Dl , l ¼ a; v; d, are positive, their values can be
picked up from ranges ð0; ðPIFS SIFSÞ=ð2MDa DÞ,
ð0; ðPIFS SIFSÞ=ð2MDv DÞ, a n d ð0; ðDIFS PIFSÞ=
ðMDd DÞ, respectively.
With fixed D and 
D
l , l ¼ a; v; d, using Remark 3, the
feasible ranges of DCjl;iðtÞ, l ¼ a; v; d, for EDDRR are given
in the following remark.
Remark 4. Since SIFS  IFSD;ja;i ðtÞ  ðSIFSþ PIFSÞ=2,
ðSIFS þ PIFSÞ=2  IFSD;jv;i ðtÞ ; PIFS, a n d PIFS 
IFSD;jd;i ðtÞ  DIFS, the feasible ranges of DCjl;iðtÞ,
l ¼ a; v; d, for EDDRR are ½0; U^Dl  once all parameters
have been set, where
U^Da ¼
PIFS SIFS
2Da D
;
U^Dv ¼
PIFS SIFS
2Dv D
;
U^Dd ¼
DIFS PIFS
Dd D
:
Again, (1) can be changed to
DCjl;iðtÞ ¼ min DCjl;iðt0Þ þKjl;i  ðt t0Þ; U^Dl
 
; l ¼ a; v; d;
to explicitly incorporate these limitations on DCjl;iðtÞ,
l ¼ a; v; d.
Therefore, the above design allows EDDRR to guarantee
QoS of different access categories, to avoid starvation so
that fairness can be taken care, and to circumvent backoff if
perfect discrimination on values of the IFS can be achieved.
At least, fewer collisions occur for EDDRR as compared to
EDCA if no perfect discrimination on values of the IFS is
assumed. Note that these possible collisions can still invoke
the backoff procedure specified in the IEEE 802.11e
standard. Without declaration of the backoff procedure,
EDDRR here merely employs the backoff procedure
specified in the IEEE 802.11e standard for possible collisions
if no perfect discrimination on values of the IFS is assumed.
2.3 Enhanced Distributed Elastic Round Robin with
Backoff Interval (EDERR-BI)
Instead of using deficit counts, some elastic and adjustable
amounts of traffic data allowed for transmission called
allowances [8] are adopted in EDERR-BI to govern the kernel
of scheduling. Note that only one single type of allowance is
defined in [8] using the concept of excess amount and a
variable time interval T . Once an allowance is set, the traffic
data associated with that allowance can be consecutively
transmitted until the amount of the traffic data is a bit more
than the allowance. More specifically, three types of
allowance are defined in EDERR-BI for access categories
of audio, video, and data. The definitions of these
allowances at time t of the ith flow of access category l in
station j denoted by Ajl;iðtÞ are given as follows (also refer to
the linearly incremental segments in Fig. 4a):
Ajl;iðtÞ ¼ Kjl;i  ðt t0Þ  Ejl;iðt0Þ; l ¼ a; v; d; ð8Þ
where Ejl;iðt0Þ is the excess amount (see Fig. 4b) at a reference
time instant t0 (t0  t and t0 denotes specifically the latest
transmission time instant or the starting time instant if no
transmission before t) of the ith flow of access category l in
station j, which can be expressed in terms of allowance at
time t0 and the total amount of traffic data transmitted at
884 IEEE TRANSACTIONS ON MOBILE COMPUTING, VOL. 8, NO. 7, JULY 2009
Fig. 4. Illustration of allowance ðAjl;iðtÞÞ versus time ðtÞ and excess
amount ðEjl;iðtÞÞ versus time ðtÞ. (a) Allowance. (b) Excess amount.
Authorized licensed use limited to: National Taiwan Univ of Science and Technology. Downloaded on May 27, 2009 at 01:52 from IEEE Xplore.  Restrictions apply.
0 <Ea 
PIFS SIFS
2MEa E
;
0 <Ev 
PIFS SIFS
2MEv E
;
0 <Ed 
DIFS PIFS
MEd E
:
Therefore, El , l ¼ a; v; d, can be picked up from ranges
ð0; ðPIFSSIFSÞ=ð2MEa EÞ, ð0; ðPIFSSIFSÞ=ð2MEv EÞ,
and ð0; ðDIFS PIFSÞ=ðMEd EÞ, respectively.
Once E and 
E
l , l ¼ a; v; d, are fixed by using Remark 7, the
upper bounds of Ajl;iðtÞ, l ¼ a; v; d, for EDERR can be
obtained in the following remark:
Remark 8. Due to the fact that SIFS  IFSE;ja;i ðtÞ 
ðSIFSþ PIFSÞ=2, ðSIFSþ PIFSÞ=2  IFSE;jv;i ðtÞ  PIFS,
and PIFS  IFSE;jd;i ðtÞ  DIFS, the upper bounds of
Ajl;iðtÞ, l ¼ a; v; d, for EDERR are U^El once all parameters
have been set, where
U^Ea ¼
PIFS SIFS
2Ea E
;
U^Ev ¼
PIFS SIFS
2Ev E
;
U^Ed ¼
DIFS PIFS
Ed E
:
Specifically speaking, the feasible ranges of Ajl;iðtÞ,
l ¼ a; v; d, are ðFls; U^El . Now, (8) can be written as
Ajl;iðtÞ ¼ min Kjl;i  ðt t0Þ  Ejl;iðt0Þ; U^El
 
; l ¼ a; v; d;
to explicitly incorporate the upper bounds of Ajl;iðtÞ,
l ¼ a; v; d.
Note that the ideas behind (12)-(14) are 1) QoS guarantee:
setting a shorter IFS for a higher priority enables service
differentiation and QoS guarantee, 2) fair scheduling: no
starvation exists since a shorter IFS may be set for a larger
amount of allowance so that getting the medium becomes
easier, and 3) collision reduction/elimination: different
values of the IFS are set for the same allowance with the
aid of random number randð1; EÞ. Compared to EDCA,
this definitely reduces collisions or even eliminates colli-
sions if discrimination on values of the IFS is totally viable.
Of course, the backoff procedure specified by IEEE 802.11e
for collisions is still employed in our numerical examples
for EDERR if collisions occur for simplicity.
3 DEFINITIONS OF WEIGHTS
For EDDRR-BI, EDERR-BI, EDDRR, and EDERR, proper
definitions of weights are necessary so that measure of
fairness can be defined based on weights. In the following,
weights for flows within the same access category
denoted by w
½s;j
l;i associated with the ith flow of access
category l in station j (here, the superscript ½s is used to
denote the same access category), weights for flows across
different access categories denoted by w
½d;j
l;i associated with
the ith flow of access category l in station j (here, the
superscript ½d is used to stand for different access
categories), and weights for different stations denoted by
wj associated with station j are defined to make definitions
of flow-level and station-level fairness feasible. These three
types of weight are now defined as follows:
w
½s;j
l;i ¼
Kjl;iP
j
P
i K
j
l;i
; ð15Þ
w
½d;j
l;i ¼
Kjl;iP
l
P
j
P
i K
j
l;i
; ð16Þ
wj ¼
P
l
P
i K
j
l;iP
l
P
j
P
i K
j
l;i
: ð17Þ
Note that one may use the reciprocal of the standard
deviation for throughput-to-weight ratios to represent the
degree of fairness (see [8]). Hence, weights should be
proportional to the (desired) throughput. This gives the
reason why values of the desired throughput are used to
define weights in (15)-(17). Further note that no direct and
reasonable definitions of weights are given in [25] as
compared to definitions of weights here; hence, no
station-level fairness was associated with EEDCF [25].
Following the aforementioned definitions of weights,
weights for all schemes in the following simulation
experiments are defined accordingly, even for EEDCF.
One should note that weights defined above are only
necessary for performance evaluation. Therefore, weights
are not involved in the proposed schemes. For performance
evaluation, an evaluator should be in charge of the
computation of weights. Let us now sketch how an
evaluator can calculate the aforementioned weights from
the information ðKjl;iÞ distributed over the wireless LAN.
No doubt, a suitable information ðKjl;iÞ sharing mechanism
should be proposed and established first. Through the
information sharing mechanism, each station is asked to
periodically (the period should be further carefully
determined) send information ðKjl;iÞ update to the evalua-
tor. Once all necessary information ðKjl;iÞ for all flows/
stations has been collected by the evaluator, weights are
then ready to be computed. With weights and other
performance measures, the system performance evaluation
can be performed by the evaluator accordingly.
4 NUMERICAL RESULTS AND DISCUSSIONS
In this section, we study performance (including through-
put, delay, and collision rate) and fairness for the four
proposed scheduling schemes, EDCA, EEDCF1 [25], and
DERR [8] through a simulation approach which is done by
ns-2 [37] alongwith somemodifications provided in [27]. Let
us first elaborate on arrangement of simulation experiments
and define related performance metrics. Then, extensive
simulation results are shown along with discussions.
4.1 Arrangement of Simulation Experiments
The simulation programs of this paper are built upon the
well-known network simulator ns-2 [37]. Fig. 5 shows the
886 IEEE TRANSACTIONS ON MOBILE COMPUTING, VOL. 8, NO. 7, JULY 2009
1. No special backoff interval adjustment is employed except that
defined in IEEE 802.11e.
Authorized licensed use limited to: National Taiwan Univ of Science and Technology. Downloaded on May 27, 2009 at 01:52 from IEEE Xplore.  Restrictions apply.
complexity/overhead to implement EDERR (EDDRR) is
higher mainly due to the fact that perfect IFS discrimination
is not really easy.
Throughput. Let us first examine individual throughput
(per access category) given in Figs. 6a and 7a. First, one can
see that constant throughput is kept for the access category of
audio (hence, the curves in Figs. 6a and 7a for this access
category coincide) because it has the highest priority but the
lowest rate for all schemes (note that the total rate requested
by audio of 18 stations is only 1.152 Mbps ( 36 Mbps)).
Second, throughput for the access category of video slightly
decreases when the number of stations is beyond 9
(corresponding to 9.792 Mbps requested by both audio and
video), 12 (corresponding to 13.056 Mbps requested by both
audio and video), and 15 (corresponding to 16.32 Mbps
requested by both audio and video) for DERR, EDCA, and
EEDCF because of the priority of this access category lower
than the access category of audio but higher than the access
category of data and the access nature of these three schemes,
while the same level (128 Kbytes/s) is kept for EDDRR-BI,
EDERR-BI, EDDRR, and EDERR (note that the curves of this
access category coincide for EDDRR-BI and EDERR-BI
(EDDRR and EDERR) in Fig. 6a (Fig. 7a)). Considering the
results at 18 stations, we note that 8 percent (10 Kbytes/s),
1.6 percent (2 Kbytes/s), and 12 percent (14 Kbytes/s) of
improvement for EDDRR-BI, EDERR-BI, EDDRR, and
EDERR as compared to EDCA, EEDCF, and DERR, respec-
tively, can be observed. Third, a noticeable decreasing trend
in throughput for the access category of data is observed for
all schemes when the number of stations is over 9
(corresponding to 18.432 Mbps requested by audio, video,
and data). The noticeable decreasing trend in throughput for
the access category of data ismainly due to its lowest priority
among the three access categories considered. Fixing the
number of stations at 18, we have 14 percent (3 Kbytes/s),
28 percent (6 Kbytes/s), 38 percent (8 Kbytes/s), and
47 percent (10 Kbytes/s) of improvement for EDDRR-BI,
EDERR-BI, EDDRR, and EDERR as compared to EDCA; we
have 41 percent (7 Kbytes/s) and 58 percent (10 Kbytes/s) of
improvement for EDDRR-BI and EDERR-BI as compared to
EEDCF; we have 7 percent (2 Kbytes/s) and 14 percent
(4 Kbytes/s) of improvement for EDDRR and EDERR as
compared to DERR. Regarding throughput for the access
category of data, EEDCF even performs worse than EDCA,
while DERR performs much better than EDCA. Moreover,
EDERR performs best, and EDDRR, DERR, EDERR-BI, and
EDDRR-BI follow successively. From the above observa-
tions, we see that EDERR and EDDRR can provide better
throughput for all access categories among schemes without
backoff intervals, while EDERR-BI and EDDRR-BI can
provide better throughput for all access categories among
schemes with backoff intervals. Noting that DERR only
provides a single type allowance defined indirectly by the
excess amount and a time interval, DERR indeed cannot
properly handle the QoS issue. This intuitive reason explains
why EDERR and EDDRR can outperform DERR in terms of
throughput. Because of the indirect definition for the
allowance like DERR, EEDCF performs worse than
EDERR-BI and EDDRR-BI in terms of throughput. Further-
more, the fact that the allowances defined by (8) by which
consecutive transmissions are enabled make system opera-
tions more efficient than the deficit counts defined by (1)
clearly explains why EDERR (EDERR-BI) can outperform
EDDRR (EDDRR-BI). Along with the observation at the
beginning of this section, EDERR explicitly outperforms the
other schemes in terms of throughput. As for total
throughput, one may see Figs. 6b and 7b for details. We
note that comparable throughput is observed for all schemes
when the number of stations is less than or equal to 9
(corresponding to 18.432 Mbps requested by audio, video,
and data, which is about the medium load (18.432 Mbps/
36Mbps) for the system) because the system load is less than
the medium load. Over nine stations, the best to the worst
schemes are EDERR, EDDRR, EDERR-BI, EDDRR-BI, and
EDCA, respectively. As for DERR and EEDCF, they perform
worse than EDCA within the interval [9, 13] but better than
EDCA when the number of stations reaches 14 and beyond.
Finally, throughput dropsmuch for all schemes as compared
to the maximum throughput at 12 stations (corresponding to
24.576 Mbps requested by audio, video, and data, which is a
moderate high load (24.576 Mbps/36 Mbps) for the system)
when the number of stations reaches 18 stations (corre-
sponding to 36.864 Mbps requested by audio, video, and
data, which is heavily loaded (36.864Mbps/36Mbps) for the
system). No doubt, throughput gets even worse if the load
gets extremely high, say, 40 stations, further. However,
EDERR and EDDRR (EDERR-BI and EDDRR-BI) still per-
form better than DERR/EDCA (EEDCF/EDCA).
Delay. With the highest priority, all mean delays of all
considered schemes for the access category of audio are
(almost) zero as shown in Figs. 8a and 8b (therefore, the
curves of this access category coincide for EDCA, EEDCF,
EDERR-BI, and EDDRR-BI in Fig. 8a and for EDCA, DERR,
EDERR, and EDDRR in Fig. 8b). For the access category of
video, an approximately linear trend is observed (see
888 IEEE TRANSACTIONS ON MOBILE COMPUTING, VOL. 8, NO. 7, JULY 2009
Fig. 6. Throughput comparison among EDCA, EEDCF, EDDRR-BI, and
EDERR-BI. (a) Individual throughput. (b) Total throughput.
Fig. 7. Throughput comparison among EDCA, DERR, EDDRR, and
EDERR. (a) Individual throughput. (b) Total throughput.
Authorized licensed use limited to: National Taiwan Univ of Science and Technology. Downloaded on May 27, 2009 at 01:52 from IEEE Xplore.  Restrictions apply.
i.e., 1=0:0071 ¼: 141 for EDDRR-BI, 1=0:0067 ¼: 149 for
EDERR-BI, 1=0:0069 ¼: 145 for EDDRR, 1=0:0051 ¼: 196 for
EDERR, 1=0:0077 ¼: 130 for EEDCF, 1=0:011 ¼: 91 for DERR,
and 1=0:0084 ¼: 119 for EDCA, respectively, revealing the
following comparison results according to dIF : 1) 18 percent,
25 percent, 22 percent, and 65 percent of improvement are
achieved by EDDRR-BI, EDERR-BI, EDDRR, and EDERR,
respectively, as compared to EDCA, 2) 8 percent and
15 percent of improvement are achieved by EDDRR-BI
and EDERR-BI, respectively, as compared to EEDCF, and
3) 59 percent and 115 percent of improvement are achieved
by EDDRR and EDERR, respectively, as compared to
DERR. In Fig. 12, throughput-to-weight ratios among flows
within the access category of data are given with values of
the standard deviation 0.0133, 0.011, 0.0115, 0.00865, 0.0137,
0.017, and 0.025 for EDDRR-BI, EDERR-BI, EDDRR,
EDERR, EEDCF, DERR, and EDCA, respectively. Again,
these values enable us to have the following comparison
results based on the type-I degree of fairness for each
scheme, i.e., 1=0:0133 ¼: 75, 1=0:011 ¼: 91, 1=0:0115 ¼: 87,
1=0:00865 ¼: 116, 1=0:0137 ¼: 73, 1=0:017 ¼: 59, and 1=0:025 ¼
40 for EDDRR-BI, EDERR-BI, EDDRR, EDERR, EEDCF,
DERR, and EDCA, respectively: 1) 88 percent, 127 percent,
117 percent, and 189 percent of improvement are achieved
by EDDRR-BI, EDERR-BI, EDDRR, and EDERR, respec-
tively, as compared to EDCA, 2) 3 percent and 25 percent of
improvement are achieved by EDDRR-BI and EDERR-BI,
respectively, as compared to EEDCF, and 3) 48 percent and
97 percent of improvement are achieved by EDDRR and
EDERR, respectively, as compared to DERR. Alternatively,
we may observe the degree of fairness via the type-II degree
of fairness ðdIIF Þ. Figs. 13a and 13d illustrate perfect fairness
ðdIIF ¼ 1Þ for all schemes when concerning the access
category of audio. From Figs. 13b and 13e, we have the
type-II degree of fairness concerning the access category of
video 1=ð10:953Þ ¼: 21 for EDDRR-BI, 1=ð10:9545Þ ¼: 22
890 IEEE TRANSACTIONS ON MOBILE COMPUTING, VOL. 8, NO. 7, JULY 2009
Fig. 10. Throughput-to-weight ratios among flows within the access
category of audio. (a) EDDRR-BI. (b) EDERR-BI. (c) EEDCF.
(d) EDDRR. (e) EDERR. (f) DERR. (g) EDCA.
Fig. 11. Throughput-to-weight ratios among flows within the access
category of video. (a) EDDRR-BI. (b) EDERR-BI. (c) EEDCF.
(d) EDDRR. (e) EDERR. (f) DERR. (g) EDCA.
Authorized licensed use limited to: National Taiwan Univ of Science and Technology. Downloaded on May 27, 2009 at 01:52 from IEEE Xplore.  Restrictions apply.
type-II degree of fairness for different schemes as follows:
1=ð1 0:918Þ ¼: 12 for EDCA, 1=ð10:942Þ ¼: 17 for EEDCF,
1=ð10:945Þ ¼: 18 for EDDRR-BI, 1=ð1 0:958Þ ¼: 24 for
EDERR-BI, 1=ð1 0:94Þ ¼: 17 for DERR, 1=ð1 0:963Þ ¼: 27
for EDDRR, and 1=ð1 0:972Þ ¼: 36 for EDERR. These values
give the following comparison results: 1) 50 percent and
6 percent of improvement for EDDRR-BI and 100 percent and
41 percent of improvement for EDERR-BI as compared to
EDCA and EEDCF, respectively, are obtained and 2) 125 per-
cent and 59 percent of improvement for EDDRR and
200 percent and 111 percent of improvement for EDERR as
compared to EDCA and DERR, respectively, are obtained.
Finally, we discuss fairness among stations. Using
throughput-to-weight ratios among stations for different
schemes as shown in Fig. 16 to obtain the type-I degree of
fairness, we have 97 percent, 230 percent, 265 percent,
and 341 percent of improvement gained by EDDRR-BI,
EDERR-BI, EDDRR, and EDERR, respectively, as compared
to EDCA, 19 percent and 98 percent of improvement gained
by EDDRR-BI and EDERR-BI, respectively, as compared to
EEDCF, and 78 percent and 114 percent of improvement
gained by EDDRR and EDERR, respectively, as compared
to DERR. Fig. 17 shows alternatively differences of fairness
indices with respect to the ideal case for stations and
eases the calculation of the type-II degree of fairness,
892 IEEE TRANSACTIONS ON MOBILE COMPUTING, VOL. 8, NO. 7, JULY 2009
Fig. 14. Throughput-to-weight ratios among flows across different
access categories. (a) EDDRR-BI. (b) EDERR-BI. (c) EEDCF.
(d) EDDRR. (e) EDERR. (f) DERR. (g) EDCA.
Fig. 15. Differences of fairness indices for flows across different access
categories.
Fig. 16. Throughput-to-weight ratios among stations. (a) EDDRR-BI.
(b) EDERR-BI. (c) EEDCF. (d) EDDRR. (e) EDERR. (f) EDCA. (g) DERR.
Authorized licensed use limited to: National Taiwan Univ of Science and Technology. Downloaded on May 27, 2009 at 01:52 from IEEE Xplore.  Restrictions apply.
[18] IEEE 802.11 WG, IEEE Standard for Information Technology—
Telecommunications and Information Exchange between Systems—
Local and Metropolitan Area Networks—Specific Requirements—Part
11: Wireless LAN Medium Access Control (MAC) and Physical Layer
(PHY) Specifications. Amendment 8: Medium Access Control (MAC)
Quality of Service Enhancements, IEEE, 2005.
[19] A. Iera, A. Molonaro, G. Ruggeri, and D. Tripodi, “Dynamic
Prioritization of Multimedia Flows for Improving QoS and
Throughput in IEEE 802.11e WLANs,” Proc. IEEE Int’l Conf.
Comm. (ICC ’05), pp. 1184-1189, 2005.
[20] I. Inan, F. Keceli, and E. Ayanoglu, “An Adaptive Multimedia QoS
Scheduler for 802.11e Wireless LANs,” Proc. IEEE Int’l Conf.
Comm. (ICC ’06), pp. 5263-5270, 2006.
[21] S.S. Kanhere, H. Sethu, and A.B. Parekh, “Fair and Efficient Packet
Scheduling Using Elastic Round Robin,” IEEE Trans. Parallel and
Distributed Systems, vol. 13, no. 3, pp. 324-336, Mar. 2002.
[22] M. Katevenis, S. Sidiropoulos, and C. Courcoubetis, “Weighted
Round-Robin Cell Multiplexing in a General-Purpose ATM
Switch Chip,” IEEE J. Selected Areas in Comm., vol. 9, no. 8,
pp. 1265-1279, Oct. 1991.
[23] S.M. Kim and Y.J. Cho, “QoS Enhancement Scheme of EDCF in
IEEE 802.11 Wireless LANs,” IEE Electronics Letters, vol. 40, no. 17,
pp. 1091-1092, Aug. 2004.
[24] Y.W. Lan, J.H. Yeh, J.C. Chen, and Z.T. Chou, “Performance
Enhancement of IEEE 802.11e EDCA by Contention Adaption,”
Proc. IEEE Vehicular Technology Conf. (VTC ’05), pp. 2096-2100,
2005.
[25] C.F. Lee, “Fair and Efficient Scheduling Mechanisms for IEEE
802.11 Wireless LANs,” master’s thesis, Nat’l Taiwan Univ. of
Science and Technology, June 2004.
[26] J.F. Lee, W. Liao, and M.C. Chen, “A Per-Class QoS Service Model
in IEEE 802.11e WLANs,” Proc. Second Int’l Conf. Quality of Service
in Heterogeneous Wired/Wireless Networks (QShine ’05), 2005.
[27] M. Malli, Q. Ni, T. Turletti, and C. Barakat, “Adaptive Fair
Channel Allocation for QoS Enhancement in IEEE 802.11 Wireless
LANs,” Proc. IEEE Int’l Conf. Comm. (ICC ’04), pp. 3470-3475, 2004.
[28] S. Mangold, “IEEE 802.11e—Coexistence of Overlapping Basic
Service Sets,” Proc. Mobile Venue, pp. 131-135, 2002.
[29] E.C. Park, D.Y. Kim, C.H. Choi, and J. So, “Improving Quality of
Service and Assuring Fairness in WLAN Access Networks,” IEEE
Trans. Mobile Computing, vol. 6, no. 4, pp. 337-350, Apr. 2007.
[30] W. Pattara-Atikom, S. Banerjee, and P. Krishnamurthy, “Starva-
tion Prevention and Quality of Service in Wireless LANs,”
Proc. IEEE Wireless Personal Multimedia Comm. (WPMC ’02),
pp. 1078-1082, 2002.
[31] L. Romdhani, Q. Ni, and T. Turletti, “Adaptive EDCF: Enhanced
Service Differentiation for IEEE 802.11 Wireless Ad-Hoc Net-
works,” Proc. IEEE Wireless Comm. and Networking (WCNC ’03),
pp. 1373-1378, 2003.
[32] D. Skyrianoglou, N. Passas, and A.K. Salkintzis, “ARROW: An
Efficient Traffic Scheduling Algorithm for IEEE 802.11e HCCA,”
IEEE Trans. Wireless Comm., vol. 5, no. 12, pp. 3558-3567, Dec. 2006.
[33] A. Soomro, S. Shankar, J.D. Prado, Y. Ohtani, J. Kowalski,
F. Simpson, and I.L.W. Lih, TGe Scheduler—Minimum Performance
Requirements, IEEE 802.11-02/709r0, Nov. 2002.
[34] N.H. Vaidya, P. Bahl, and S. Gupta, “Distributed Fair Scheduling
in a Wireless LAN,” Proc. ACM MobiCom, pp. 167-178, 2000.
[35] S. Vinnakote, N. Svs, S. Pasupuleti, and D. Das, “New-MAC
Protocol for Enhancement of QoS Performance in Wireless
LAN,” Proc. IFIP Wireless and Optical Comm. Networks
(WOCN ’06), pp. 1-5, 2006.
[36] G.W. Wong and R.W. Donaldson, “Improving the QoS Perfor-
mance of EDCF in IEEE 802.11e Wireless LANs,” Proc. IEEE Pacific
Rim Conf. Comm., Computers and Signal Processing (PACRIM ’03),
pp. 392-396, 2003.
[37] The Network Simulator—ns-2, http://www.isi.edu/nsnam/ns,
2009.
Huei-Wen Ferng received the BS degree in
electrical engineering from the National Tsing
Hwa University, Hsinchu, Taiwan, in 1993 and
the PhD degree in electrical engineering from
the National Taiwan University, Taipei, in 2000.
He joined the Department of Computer Science
and Information Engineering, National Taiwan
University of Science and Technology, Taipei,
as an assistant professor in August 2001. Since
February 2005, he has been an associate
professor. Funded by the Pan Wen-Yuan Foundation, Taiwan, he spent
the summer of 2003 visiting the Department of Electrical Engineering
and Computer Science, University of Michigan, Ann Arbor. His research
interests include wireless networks, mobile computing, high-speed
networks, design of fair scheduling, teletraffic modeling, queuing theory,
and performance analysis. He was a recipient of the research award for
young researchers from the Pan Wen-Yuan Foundation, Taiwan, in
2003 and was a recipient of the Outstanding Young Electrical Engineer
Award from the Chinese Institute of Electrical Engineering (CIEE),
Taiwan, in 2008. He is a member of the IEEE.
Han-Yu Liau received the MS degree in
computer science and information engineering
from the National Taiwan University of Science
and Technology, Taipei, in 2007. He is currently
with the Department of Computer Science and
Information Engineering, National Taiwan Uni-
versity of Science and Technology. His research
interests include wireless LANs, design of fair
scheduling, and performance analysis.
. For more information on this or any other computing topic,
please visit our Digital Library at www.computer.org/publications/dlib.
894 IEEE TRANSACTIONS ON MOBILE COMPUTING, VOL. 8, NO. 7, JULY 2009
Authorized licensed use limited to: National Taiwan Univ of Science and Technology. Downloaded on May 27, 2009 at 01:52 from IEEE Xplore.  Restrictions apply.
LEONOVICH and FERNG: A TIME SLOTS COORDINATION MECHANISM FOR IEEE 802.11 WLANS 361
Svoice
Voice Interval Data Interval Dlim
DL   UL
TSCM
Sdata
DCF
TSCM cycle TSCM cycle
1 2 Kdata
flow 1 flow 2 flow 1 flow 2
Fig. 1. Time structure of TSCM.
this time allocation is to give a higher priority to the voice
traffic. With the fact that the time to generate one packet for
the vast majority of voice codecs is much longer than the
time to transmit it, a long period of packet generation is left
to poll data flows. To keep the delay and jitter of voice frames
low, the length of the Data Interval is confined to 𝐷𝑙𝑖𝑚 chosen
based on the voice packet generation time. This time structure
implicitly sets a higher (lower) priority to voice (data) traffic.
Following the aforementioned time structure, the TS coor-
dinator assigns time slots to STAs to access the medium. To
do so, it first needs to calculate the length of the time slot
based on measurements during the CP, including data rate of
data traffic 𝑅𝑑𝑎𝑡𝑎 and average payload sizes of data and voice
traffic denoted by 𝐿𝑑𝑎𝑡𝑎 and 𝐿𝑣𝑜𝑖𝑐𝑒, respectively. Considering
the time characteristics of Voice and Data intervals, it is
reasonable to assume that only one voice frame arrives during
one TSCM cycle for each voice flow in both uplink and
downlink. Furthermore, a longer Data Interval allows to set a
long enough time slot for each data flow to send multiple data
frames. This increases data traffic throughput without harmful
effects on the QoS of voice since the Data Interval is limited
by 𝐷𝑙𝑖𝑚. Therefore, the length of the time slot for data traffic
is chosen to be a submultiple of 𝐷𝑙𝑖𝑚. However, it still should
be long enough to transmit at least one frame, giving a lower
bound 𝑆𝑚𝑖𝑛 which is the time to transmit one frame with the
maximum size defined by the standard as follows:
𝑆𝑚𝑖𝑛 = 𝑇𝑚𝑎𝑥 + 2SIFS + 𝑇𝑎𝑐𝑘, (2)
where 𝑇𝑚𝑎𝑥 is the time to transmit a frame with the maximum
size, SIFS is the short inter frame space, and 𝑇𝑎𝑐𝑘 is the
time to transmit an ACK frame. With the knowledge of traffic
parameters, the average number of packets in the data queue
after 𝐷𝑙𝑖𝑚 (denoted by 𝐾𝑑𝑎𝑡𝑎) can be found via
𝐾𝑑𝑎𝑡𝑎 =
⌈
𝑅𝑑𝑎𝑡𝑎 ⋅𝐷𝑙𝑖𝑚
𝐿𝑑𝑎𝑡𝑎
⌉
. (3)
Combining the above two equations leads to the setting of a
time slot for the data traffic 𝑆𝑑𝑎𝑡𝑎 as follows:
𝑆𝑑𝑎𝑡𝑎 = max [𝐾𝑑𝑎𝑡𝑎(𝑇𝑑𝑎𝑡𝑎 + 2SIFS + 𝑇𝑎𝑐𝑘), 𝑆𝑚𝑖𝑛] , (4)
where 𝑇𝑑𝑎𝑡𝑎 is the time to transmit a frame with the payload
size 𝐿𝑑𝑎𝑡𝑎. As for the voice traffic, the length of the time slot
𝑆𝑣𝑜𝑖𝑐𝑒 is set to the time to transmit two frames (one uplink
frame and one downlink frame) with the size of 𝐿𝑣𝑜𝑖𝑐𝑒, i.e.,
𝑆𝑣𝑜𝑖𝑐𝑒 = 2𝑇𝑣𝑜𝑖𝑐𝑒 + 2SIFS, (5)
where 𝑇𝑣𝑜𝑖𝑐𝑒 is the time to transmit a frame with the payload
size 𝐿𝑣𝑜𝑖𝑐𝑒 under the piggybacked acknowledgment.
III. COMPLEXITY ANALYSIS
In this section, both time complexity and space complexity
for introducing TSCM are examined. For acquiring the time
complexity, we introduce the following notations: 𝑇1 is the
time to measure 𝑁𝑑𝑎𝑡𝑎, 𝑁𝑎𝑐𝑘, 𝑁𝑟𝑡𝑠, or 𝑁𝑐𝑡𝑠, 𝑇2 is the time to
measure 𝑅𝑑𝑎𝑡𝑎, 𝐿𝑑𝑎𝑡𝑎, or 𝐿𝑣𝑜𝑖𝑐𝑒, 𝑇3 is the time to calculate
𝜀, 𝑇4 is the time to compare 𝜀 with 𝜀𝑡ℎ, and 𝑇5 (𝑇6) is
the time to calculate a time slot of voice (data). Letting 𝑛
denote the number of beacon intervals observed in the DCF
mode (therefore, 𝑛 network/traffic parameter observations
exist in the DCF mode), let us examine the time complexity
for introducing TSCM under the following two cases: light
network load, i.e., 𝜀 < 𝜀𝑡ℎ, and heavy network load, i.e.,
𝜀 ≥ 𝜀𝑡ℎ. The time complexity 𝑓(𝑛) for the first case can
be expressed as 𝑓(𝑛) = (4𝑇1 + 3𝑇2 + 𝑇3 + 𝑇4)𝑛 ∈ 𝑂(𝑛),
while 𝑓(𝑛) ≤ (4𝑇1 + 3𝑇2 + 𝑇3 + 𝑇4)𝑛 + (4𝑇1 + 3𝑇2 +
𝑇3 + 𝑇4 + 𝑇5 + 𝑇6)𝑁𝑐𝑦𝑐𝑙𝑒𝑛𝑇 ∈ 𝑂(𝑛) for the second case,
where 𝑛𝑇 is the number of the TSCM mode activations with
𝑛𝑇 ≤ 𝑛. The results for the two cases enable us to conclude
that the time complexity is 𝑂(𝑛). Next, let us further examine
the space complexity for introducing TSCM. Since only fixed
memory storages are necessary for the TS coordinator, the
space complexity is 𝑂(1). Because TSCM uses the same MAC
functions as DCF does and only performs a rearrangement
of the medium access time of STAs by the software module
according to characteristics of traffic flows, the implementation
of TSCM is in deed simple as illustrated by the time and
space complexity analysis. On the contrary, the other reference
schemes need hardware changes of the IEEE 802.11 MAC
layer: a new set of MAC functions is required for EDCA
and HCCA; Blackburst requires the ability of jamming on
the medium by the AP and synchronization among STAs.
Definitely, simpler implementation and structural simplicity
make TSCM more preferable among these schemes.
IV. PERFORMANCE EVALUATION AND CONCLUDING
REMARKS
Using the network simulator ns-2 [5], EDCA, HCCA,
Blackburst (denoted by Bburst), and TSCM are evaluated in
terms of end-to-end frame delay, number of supported voice
sessions, normalized throughput, and fairness index [6]. Here,
we consider an infrastructure-based system containing one
AP and various numbers of STAs under the IEEE 802.11b
physical layer with 209-𝜇s beacon intervals. Each STA is
only associated with one traffic source. To increase the system
load, we gradually increase the number of voice STAs but fix
the number of data STAs at 5. For the voice source, it is a
bidirectional 64-kbps voice over IP (VoIP) traffic source with
the 160-byte payload per 20 ms, while an FTP flow with the
1460-byte payload generated at the AP is used to model the
data source. Additionally, the low-priority (data) contention
window (CW) size is set to 63 with AIFS = 90𝜇𝑠 and the
high-priority (voice) CW size is set to 31 with AIFS = 50𝜇𝑠
for EDCA; the HCCA transmission unit (TU) is set to 1024 𝜇s
with a superframe of 500*TU and a contention-free period
(CFP) of 100*TU; and the Blackburst slot is set to 20 𝜇s with
the slack time of 5 ms.
Let us further elaborate on the choice of the parameters for
TSCM. First, 𝐷𝑙𝑖𝑚 is set to 15 ms to conform with the packet
Authorized licensed use limited to: National Taiwan Univ of Science and Technology. Downloaded on April 12,2010 at 06:37:24 UTC from IEEE Xplore.  Restrictions apply. 
1 23
Wireless Networks
The Journal of Mobile
Communication, Computation
and Information
 
ISSN 1022-0038
Volume 17
Number 5
 
Wireless Netw (2011)
17:1259-1271
DOI 10.1007/
s11276-011-0347-6
Fair round robin binary countdown to
achieve QoS guarantee and fairness in
WLANs
Huei-Wen Ferng, Chandra Setiadji &
Alexander Leonovich
Fair round robin binary countdown to achieve QoS guarantee
and fairness in WLANs
Huei-Wen Ferng • Chandra Setiadji •
Alexander Leonovich
Published online: 15 May 2011
 Springer Science+Business Media, LLC 2011
Abstract How to guarantee both quality of service (QoS)
and fairness in wireless local area networks (WLANs) is a
challenging issue. To touch this issue, a fair medium access
control (MAC) scheme called fair round robin binary
countdown (FRRBC) adopting the eminent concepts of
allowance and binary countdown is proposed in this paper.
FRRBC can guarantee QoS for both audio and video with
the aid of adaptive adjustment on system parameters and
some extra rules designed according to delay bounds. Using
multiple mapping functions from allowances to fixed-bit
binary numbers to indicate different priorities, FRRBC not
only provides guaranteed system performance but also
achieves good fairness. Finally, we demonstrate that
FRRBC can significantly outperform the enhanced distrib-
uted channel access (EDCA) (IEEE 802.11 WG in IEEE
Standard for Information technology—Telecommunica-
tions and information exchange between systems—Local
and metropolitan area networks—Specific requirements—
Part 11: Wireless LAN Medium Access Control (MAC)
and Physical Layer (PHY) Specifications. Amendment 8:
Medium Access Control (MAC) Quality of Service
Enhancements, 2005) and the synchronized medium access
control (SYN-MAC) (Wu HY et al. in Mobile Netw Appl
11:627–637, 2005) because of its superiority to offer
guaranteed QoS for both audio and video, low delay jitter,
low blocking ratio, and good fairness. Of course, FRRBC
can be illustrated to be a better choice than the enhanced
distributed elastic round robin (EDERR) (Ferng HW, Liau
HY in IEEE Trans Mobile Comput 8(7):880–894, 2009).
Keywords Wireless local area network 
Quality of service  Fairness
1 Introduction
With the ability to enable people or devices to communi-
cate with each other without the pre-installed wired
communication, the WLAN becomes one of essential
technologies in many fields, e.g., industrial, scientific, and
medical ones. Because WLANs are pervasive in urban
areas, more sophisticated services, including multimedia
services, are highly demanded. However, the legacy MAC
functions of IEEE 802.11, i.e., distributed coordination
function (DCF) and point coordination function (PCF),
were developed to support the basic data communication
only [11–13]. That is the reason why the original WLAN is
not able to meet QoS requirements of multimedia appli-
cations, e.g., voice over IP (VoIP) [1] and video on demand
(VoD) [9], etc. In order to solve this problem, EDCA [14]
was proposed by IEEE 802.11 task group E (TGe) to
support QoS in WLANs.
Even though DCF and EDCA have been standardized,
the issue of QoS guarantee is still not well handled by them
[2, 3, 8]. Therefore, many researchers, for example, those
in [1, 4–7, 10, 15–20, 22–25], tried to propose new MAC
protocols to achieve QoS guarantee and performance
enhancement. Considering a fixed contention time sched-
uling scheme, Wu et al. [23] proposed a novel MAC
scheme based on the binary countdown approach, i.e.,
SYN-MAC, to highly utilize the channel while keeping a
low collision rate. You et al. [24] proposed a collision-free
H.-W. Ferng (&)  C. Setiadji  A. Leonovich
Department of Computer Science and Information Engineering,
National Taiwan University of Science and Technology,
Taipei 106, Taiwan
e-mail: hwferng@mail.ntust.edu.tw
123
Wireless Netw (2011) 17:1259–1271
DOI 10.1007/s11276-011-0347-6
Author's personal copy
KA,i
l,j changes values at the latest transmission instant or the
latest burst arrival instant ts
0
. Explicitly, KA,i
l,j can be com-
puted via
Kl;jA;i ¼
maxðQ
l;j
i ðt
0
sÞAl;ji ðt
0
sÞ
tnl;ji t0s
; Kl;ji Þ; l ¼ AU; VI;
minðmaxðQ
l;j
i ðt
0
sÞAl;ji ðt
0
sÞ
tnl;ji t0s
; Kl;ji Þ; MBS
l
Il;j
Þ; l ¼ BE;
8
><
>:
ð1Þ
where Ai
,j(t
0
s) (in bits) is the allowance at time ts
0
of the jth
flow of access category l at station i to be defined later, Ki
l,j
is the given static desired throughput for the jth flow of
access category l at station i (which is a negotiable
parameter and can be enforced by a traffic policing
mechanism, e.g., leaky bucket or token bucket), Qi
l,j(t’s) (in
bits) is the queue length at time ts
0
of the jth flow of access
category l at station i, Il,j stands for the mean inter-burst
arrival time, and tni
l,j is initially set to the starting time of
the corresponding flow and then increases with a step of Il,j
such that tni
l,j - Il,j B ts
’ B tnl,ji, MBS
l (in bits) is the
maximum burst size of access category l (MBSl is an
agreeable parameter about how many bits can be contigu-
ously transmitted for each AC at most). With the dynamic/
adaptive adjustment on the desired throughput, the allow-
ance in FRRBC will increase faster than the given Ki
l,j
when
Ql;ji ðt
0
sÞAl;ji ðt
0
sÞ
tnl;ji t0s
[ Kl;ji to catch up the queue length in the
time period [ts
’, tni
l,j] to avoid imbalance between the
allowance and the queue length. To ensure that a higher
priority is set to the real-time traffic (l = AU or VI), an
extra limit is posed on KA,i
l,j for the best effort traffic
(l = BE). Of course, some parameters used to set priorities
in the phase of the binary countdown MAC protocol will be
further introduced later. Therefore, high priority traffic is
definitely favored as compared to low priority traffic under
our QoS-aware scheme. On the contrary, one can see that
(a)
(b)
Fig. 1 Illustration of allowance
(Al,ji(t)) or queue length (Q
l,j
i(t))
versus time (t) for a EDERR
and b FRRBC
Wireless Netw (2011) 17:1259–1271 1261
123
Author's personal copy
must give up immediately. For FRRBC, each contention slot
consists of an EDCA time slot and a short jamming period to
send a very short frame, while each contention slot in SYN-
MAC [23] consists of the receiving and transmitting turn-
around (RxTxTurnarround) time and the time to transmit the
physical layer convergence protocol header (PLCPHeader)
and a 48-bit receiver address, making one contention slot in
SYN-MAC much longer than that in FRRBC. Definitely, the
new design of a contention slot in FRRBC greatly reduces the
overhead. If station i can survive at the end of the contention
period, then station i can start to exchange the binary request
to send (BRTS) and the binary clear to send (BCTS) mes-
sages with the receiver. The BRTS message contains the
PLCPHeader, a 48-bit receiver address, and the value of
BNi ðtÞ; while the BCTS message contains the PLCPHeader
and the value of BNi ðtÞ from the BRTS message. At the end
of this phase, station i can activate data transmission if it
receives an uncorrupted BCTS message. In the data trans-
mission period, a station can send multiple frames as long as
the amount of accumulated data frames sent is lower than or
equal to Ai
l,j(t). Finally, this data transmission period ends
with an ACK transmission and the same procedure is
repeatedly performed.
From the previous explanation on the binary countdown
scheme employed by FRRBC, we know that a station must
go through the contention period before transmitting
frames. Because the effect caused by contention is traffic
load dependent, one can easily reach the following obser-
vations. When the traffic load is low, the effect caused by
contention seems to be fine since the total throughput gets
little affected. However, this effect results in the reduction
in total throughput when the traffic load is high. To miti-
gate the effect caused by contention, some extra rules can
be added. To facilitate the discussion on these rules, the
following auxiliary variables are defined: Di
l,j denotes the
delay bound associated with the jth flow of access category
l at station i, it stands for the idle threshold used to indicate
a high traffic load or not, rdi
l,j(t) represents the delay
received at time t by the frame at the head of the queue for
the jth flow of access category l at station i, nai
l,j = tni
l,j - t
(where t is the current time and t 2 ðtnl;ji  Il;j; tnl;ji Þ), and
AT denotes the average idle time of the wireless medium.
Note that it is a pre-specified parameter and should be
greater than DIFS and a station judges that the traffic load
is high via AT \ it. Explicitly, the larger it is, the sooner a
station will judge that the traffic load is high. Now, the
relevant rules are depicted as follows:
(R1) Because of no delay bound specified for the best
effort traffic, I
BE;jMBSBE
FBEs
(the longest time needed for
Ai
BE,j(t) to achieve MBSBE) is set to Di
BE,j. For the
access categories of AU and VI, the agreed delay
bounds are associated accordingly.
(R2) If AT \ it, the jth flow of access category l at
station i is allowed to go through the contention
period by computing its BNi
l,j(t) using (4) only when
rdi
l,j(t) ? nai
l,j C Dl,ji and Ai
l,j(t) C Fs
l .
(R3) If AT \ it, the jth flow of access category l at
station i is still allowed to go through the contention
period by first computing its BNi
l,j(t) using (4) when
Ai
l,j(t) = MBSl even if rdi
l,j(t) ? nai
l,j \ Di
l,j.
Since (R1) is self-explained, no further explanation is
given. As for the main ideas behind (R2) and (R3), let us
explain as follows. For both (R2) and (R3), they are applied
only when the traffic load is high, i.e., AT \ it. Under the
precondition of a high traffic load, fewer contending flows
bring a lower impact on the contention. Towards this
direction, (R2) keeps the contending right of the flow
whose delay bound is almost up (indicated by rdi
l,j(t) ?
nai
l,j C Di
l,j) but suspends the contending right of the flow
whose delay bound is far from up (revealed by rdi
l,j(t) ?
nai
l,j \ Di
l,j). By doing so, (R2) not only alleviates the
potential contention, but also reduces the possible overhead
caused by carrying real-time frames generated under the
condition Ai
l,j(t) C Fs
l only (see Fig. 3(a)) in the normal
contention operation by forcing real-time traffic (l = AU or
VI) to await more frame arrivals until rdi
l,j(t) ? nai
l,j C Di
l,j
is further reached. Under a high traffic load, it is crystal
clear that the video traffic has more frames in queue
because of its high transmission rate and the best effort
traffic normally has a lot of frames in queue because of its
low priority. With the aforementioned contention suppres-
sion for AU or VI, video or best effort is then given a
chance to send multiple frames once rdi
l,j(t) ? nai
l,j C Di
l,j
and Ai
l,j(t) [ Fs
l (l = VI or BE) are true (see Fig. 3(b) for
the case when l = BE for the above conditions). As for the
idea behind (R3), it allows the flow to enter the contention
period directly if its allowance has already reached the
maximum limit without waiting for another frame anymore
since the flow has been waiting for a long time previously
Fig. 2 MAC mechanism of
FRRBC
Wireless Netw (2011) 17:1259–1271 1263
123
Author's personal copy
fair scheduling scheme. Of course, they may be empirically
adjusted, if necessary. As for the values of FRRBC-des-
ignated parameters, e.g., al and bl, the values are simply
chosen to fulfill the corresponding functionality.
With the similar reasoning employed by [5], all schemes
considered here only focus on audio, video, and best effort
with related traffic parameters given in Table 1. About the
setting of the initially given desired throughput, we set it to
8 KB/s (0.064 Mbps), 128 KB/s (1.024 Mbps), 120 KB/s
(0.96 Mbps) for audio, video, and best effort, respectively.
Furthermore, IEEE 802.11a is assumed with the following
main parameters: transmission rate of 36 Mbps, time slot of
9 ls, SIFS of 16 ls, PIFS of 25 ls, DIFS of 34 ls, prop-
agation delay of 1 ls, and 240-bit ACK. As for some
specific MAC parameters for EDERR, EDCA, FRRBC,
and SYN-MAC, they are given as follows. For EDERR,
parameters bE, MAU
E , MVI
E , MBE
E , aAU
E , aVI
E , and aBE
E are set
to 1.9, 640 (bytes), 5,120 (bytes), 7,500 (bytes), 0.003 (ls/
byte), 0.00035 (ls/byte), and 0.00055 (ls/byte), respec-
tively, where Ml
E (l = AU, VI, BE) are the maximum
allowances for access category l chosen to determine the
possible range of al
E (see [5] for details). For EDCA,
CWmin
AU , CWmax
AU , CWmin
VI , CWmax
VI , CWmin
BE , and CWmax
BE are set
to 8 (slots), 16 (slots), 16 (slots), 32 (slots), 32 (slots),
and 1,024 (slots), respectively, where CWmin
l and
CWmax
l (l = AU, VI, BE) denote the minimum and maxi-
mum contention window sizes of access category l.
For FRRBC, parameters MBSAU, MBSVI, MBSBE, IAU,j,
IVI,j, IBE,j, Di
AU,j,Di
VI,j, it, a, and n are set to 640 (bytes),
5,120 (bytes), 6,000 (bytes), 20 (ms), 10 (ms), 12.5 (ms),
30 (ms), 40 (ms), 180 (ms), 0.2, and 11, respectively. As
for the setting of al and bl, they are given as follows:
aAU = 0.75, bAU = 0.25, aVI = 0.5, bVI = 0.5, aBE = 0,
and bBE = 0.88. For SYN-MAC, the parameter n is set to
11 and the frame size is set to 2,342 bytes. In all schemes,
each station has three traffic flows (access categories), i.e.,
audio, video, and best effort. To acquire performance
metrics under different traffic loads, the number of stations
is increased from 1 to 18 in each simulation. For measuring
fairness indices, three stations are grouped into one group
in which three videos (best effort) have different initially
given desired throughput, while the same initially given
desired throughput (8 KB/s) is set to all audios. Finally,
each simulation is run for 180 seconds.
3.2 Simulation results
We now provide the performance metrics and fairness
index for all schemes. Before the following discussion, let
us give the definition of delay jitter J(i) associated with
packet as follows [21]:
JðiÞ ¼ jðTRi  TSi Þ  ðTRi1  TSi1Þj; ð8Þ
where Ti
S denotes the time instant to send the ith packet and
Ti
R stands for the time instant to receive the ith packet.
Based on (8), the mean delay jitter J can be easily derived
via J ¼Pnpi¼1 JðiÞ=np; where np is the total number of
packets collected for the delay jitter calculation.
3.2.1 Delay
Shown in Fig. 4 are mean delays for different schemes and
access categories under various numbers of stations. First,
one may note that the mean delays of audio for all schemes
(see Fig. 4(a)) fall below 22 ms (\30 ms which is the delay
bound of audio set here) even though the mean delay of
audio for FRRBC is the highest one caused by the intro-
duction of the extra rules in Section 2. This shows that the
delay bound of audio is guaranteed for all schemes because
of its highest priority. Second, only FRRBC can guarantee
the delay bound of video (40 ms) among the four schemes
(see Fig. 4(b)) mainly thanks to the introduction of the
extra rules in Sect. 2. When the number of stations is 18
(corresponding to 36.864 Mbps requested by audio, video
and best effort), the mean delay of video in FRRBC is
much lower than (approximately 4% or less of) those in
EDERR, EDCA, and SYN-MAC. Of course, this great
improvement mainly comes from the introduction of the
aforementioned extra rules. Third, FRRBC has much lower
delays of best effort (see Fig. 4(c)) than EDERR when the
number of stations is lower than 10 (corresponding to 20.48
Mbps requested by audio, video and best effort) although
Fig. 4(c) does not explicitly illustrate this. Fourth, FRRBC
gains 44% of decline as compared to EDERR, while EDCA
and SYN-MAC get 51 and 62%, respectively, of decline as
compared to FRRBC as far as the access category of best
effort is concerned when the number of stations is 18.
There are two main reasons why the delay of best effort in
FRRCC is higher than that in EDERR when much more
Table 1 Trafic parameters of
audio, video, and best effort
Access category AU VI BE
Frame size 160 bytes 1,280 bytes 1,500 bytes
Inter-arrival time 20 ms (constant) 10 ms (constant) 12.5 ms (exponential)
Mean rate 8 KBps 128 KBps 120 KBps
Peak rate – 640 KBps –
Buffer size 25 Kb 1 Mb Infinity
Wireless Netw (2011) 17:1259–1271 1265
123
Author's personal copy
can be reached by both EDERR and FRRBC. Second,
smooth and comparable mean delay jitters are exhibited by
EDERR and FRRBC. However, the mean delay jitter is
kept at a very low level when the number of stations is
lower than or equal to 12 (corresponding to 24.576 Mbps
requested by audio, video and best effort) but increases
drastically beyond that point for SYN-MAC. As for the
mean delay jitters of video for different schemes, one can
refer to Fig. 5(b). Likewise, one can easily obtain some
salient observations from this figure as follows. First,
similar to the phenomenon concerning audio transmission,
EDERR and FRRBC have comparable and low mean delay
jitters. Further examining the mean delay jitters for these
two schemes in detail, one can find that the maximum
observable mean delay delays are 9 ms and 18 ms (100%
more than the corresponding mean delay jitter of FRRBC,
i.e., 9 ms) for FRRBC and EDERR, respectively. More-
over, the mean delay jitter of FRRBC can be lower than
that of EDERR more frequently (more than 80%). There-
fore, FRRBC performs better than EDERR in terms of
delay jitter concerning video transmission. Second, com-
pared to FRRBC and EDERR, the mean delay jitters for the
other two schemes, i.e., EDCA and SYN-MAC, are rela-
tively high and may increase as the number of stations
increases. At the point of 18 stations, the mean delay jitters
reach 345 ms and 130 ms for EDCA and SYN-MAC,
respectively.
3.2.3 Collision rate and blocking ratio
Figure 6(a) gives the collision rate vs. the number of sta-
tions and reveals that FRRBC, EDERR, and SYN-MAC
perform much better than EDCA in terms of collision rate.
When the number of stations is 18, 60% of collision rate
reduction is achieved by FRRBC as compared to SYN-
MAC, while EDERR with zero collision rate performs best
with the aid of the perfect IFS discrimination assumption.
Rather than employing a perfect assumption like EDERR,
FRRBC proposes the modified and feasible binary count-
down scheme to practically solve the problem of conten-
tion resolution. Although it cannot achieve the perfect
collision rate, the collision rate can be kept to a quite low
level (lower than 15 (frames per second)).
As for the blocking ratio as shown in Fig. 6(b), the
following observations at the point of 18 stations can be
made: (1) The adaptive desired throughput and better
arrangement for the binary countdown scheme make
FRRBC have the best performance (with EDERR) and
reach a quite low blocking ratio of 0.008. (2) Both FRRBC
and EDERR perform much better than EDCA and SYN-
MAC. Note that the percentage of improvement in block-
ing ratio gained by FRRBC as compared to the other
schemes (including EDERR) becomes much higher if the
difference between the mean data rate and the peak data
rate of video is larger (observed by simulations but not
shown for brevity).
3.2.4 Throughput
The individual throughput is given in Figs. 7(a)–(c), while
the total throughput is given in Fig. 7(d).
Let us first discuss the individual throughput. First of all,
one can see that throughput of audio is fixed at 8 KBps
(KB/s) for all schemes except EDCA. Because the ranges
of CWmin
l and CWmax
l for l = AU and VI in EDCA are
small, the collision rate gets high when the number of
stations increases, resulting in the throughput decrease of
audio. As for the throughput of video, it starts to decrease
when the number of stations is beyond 9 (corresponding to
18.432 Mbps requested by audio, video and best effort) for
EDCA and 13 (corresponding to 26.624 Mbps requested by
audio, video and best effort) for SYN-MAC. A similar
2 4 6 8 10 12 14 16 18
0
10
20
30
40
50
60
70
80
90
100
Co
llis
io
n 
ra
te
 (fr
am
es
 pe
r s
ec
on
d)
Number of stations
EDCA
EDERR
SYN−MAC
FRRBC
(a)
2 4 6 8 10 12 14 16 18
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
Bl
oc
ki
ng
 ra
tio
Number of stations
EDCA
EDERR
SYN−MAC
FRRBC
(b)
Fig. 6 a Collision rate and b blocking ratio for FRRBC, EDERR,
EDCA, and SYN-MAC
Wireless Netw (2011) 17:1259–1271 1267
123
Author's personal copy
Mbps requested by audio, video and best effort). Consider-
ing the results at 18 stations, we have 47 and 66% of
improvement for FRRBC as compared to EDCA and SYN-
MAC, respectively. Right because of the inevitable colli-
sions, FRRBC still performs second to EDERR. However,
only 8% of decline as compared EDERR is reported for
FRRBC when there are 18 stations in the system.
3.2.5 Fairness
In the following, only fairness indices among flows across
different access categories are shown (note that comparable
results can be observed for EDERR and FRRBC for the
other two types of fairness index but they are omitted here
for space saving). From Fig. 8, one can see that SYN-MAC
has the lowest fairness index (the most unfair scheme),
while EDERR has the highest fairness index (the fairest
scheme) among the four schemes. If the number of stations
is below 12, almost identical fairness index like EDERR
can be observed for FRRBC. However, a gap between the
fairness index of EDERR and that of FRRBC exists when
the number of stations increases. At the point of 18 sta-
tions, the fairness indices are 0.78 for FRRBC, 0.893 for
EDERR, 0.652 for SYN-MAC, and 0.678 for EDCA,
revealing that FRRBC gains 20% and 15% of improvement
as compared to SYN-MAC and EDCA, respectively, and
gets 13% of decline as compared to EDERR.
3.2.6 Summary on comparison
Undoubtedly, FRRBC significantly outperforms EDCA
and SYN-MAC as revealed by the previous simulation
results. As for the comparison between FRRBC and
EDERR, let us further detail as follows. First of all,
EDERR heavily relies on the perfect IFS discrimination
assumption that may make EDERR hard to implement or
perhaps infeasible. This is the main drawback of EDERR
in implementation. However, FRRBC employs realistic
assumptions to make its implementation feasible and
practical. Second, FRRBC can successfully guarantee the
delay bound for real-time traffic (both audio and video)
with a bit higher delay for non-real-time traffic (best effort)
as compared to EDERR when the traffic load gets high. For
EDERR, it fails to guarantee the delay bound of video
although it does guarantee the delay bound of audio. This is
the main drawback of EDERR in QoS guarantee for real-
time traffic. Third, FRRBC shows much better performance
of delay jitter than EDERR in video transmission, while
EDERR performs a bit better than FRRBC in delay jitter
concerning audio transmission. Fourth, without any perfect
assumption, FRRBC still keeps a quite low collision rate
(lower than 15 (frames per second)) although it cannot
achieve the perfect collision rate like EDERR. Fifth,
FRRBC and EDERR have comparably low blocking ratios
and high throughput for real-time traffic. Sixth, FRRBC
inevitably performs worse than EDERR when the system
load gets high as far as the throughput of non-real-time
traffic (best effort) is concerned because of the binary-
countdown-based scheme rather than a perfect assumption
employed by EDERR. Seventh, FRRBC improves the
degree of fairness as far as the binary countdown related
schemes, i.e., SYN-MAC and FRRBC, are concerned.
Although EDERR performs better than FRRBC in fairness,
the difference between the two schemes is small. Hence, an
acceptable degree of fairness is exhibited by FRRBC. From
the aforementioned discussions on the comparison between
FRRBC and EDERR, we believe that FRRBC is a better
choice than EDERR mainly because of ease in imple-
mentation, delay bound guarantee for both audio and video,
and ability to reach/maintain comparable performance
between the two schemes.
4 Conclusions
A fixed-contention-time-based scheme, i.e., FRRBC,
combining the distributed elastic round robin scheme and
the binary countdown scheme has been proposed in this
paper. The adaptive desired throughput setting and some
extra rules make FRRBC successfully have guaranteed
performance for both audio and video in terms of
throughput and delay with a bit sacrifice in fairness as well
as throughput and delay for the best effort. Although
FRRBC can not achieve zero collision rate, the collision
rate is kept to a much low level without any extra
assumption like that employed by EDERR, making
FRRBC feasible and easy to implement. Finally, quite low
blocking ratios and delay jitters (for both audio and video)
2 4 6 8 10 12 14 16 18
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
1.1
Fa
irn
es
s 
in
de
x
Number of stations
EDCA
EDERR
SYN−MAC
FRRBC
Fig. 8 Fairness indices across different access categories
Wireless Netw (2011) 17:1259–1271 1269
123
Author's personal copy
wireless networks, mobile computing, high-speed networks, design of
fair scheduling, teletraffic modeling, queuing theory, and performance
analysis. He was a recipient of the research award for young
researchers from the Pan Wen-Yuan Foundation, Taiwan, in 2003 and
was a recipient of the Outstanding Young Electrical Engineer Award
from the Chinese Institute of Electrical Engineering (CIEE), Taiwan,
in 2008. He is a member of the IEEE.
Chandra Setiadji received the
M.S. degree in computer sci-
ence and information engineer-
ing from the National Taiwan
University of Science and
Technology, Taipei, Taiwan, in
2009. His research interests
include wireless local area net-
works and design of fair
scheduling.
Alexander Leonovich is cur-
rently a Ph.D. candidate at the
Department of Computer Sci-
ence and Information Engineer-
ing of the National Taiwan
University of Science and
Technology, Taipei, Taiwan.
His research interests include
wireless local area networks and
design of fair scheduling.
Wireless Netw (2011) 17:1259–1271 1271
123
Author's personal copy
sensor nodes used by Wu’s scheme increases exponentially
as the network radius goes. However, a linear trend in
terms of the network radius is exhibited by Strategy II. Like
Strategy I, fewer sensor nodes in the outermost corona are
required for Strategy III as compared to Wu’s scheme and
Strategy II. Similar to Strategy II, energy conservation
makes fewer sensor nodes required in the other coronas.
Therefore, Strategy III requires the fewest sensor nodes
among the three proposed strategies.
The rest of this paper is organized as follows: Section 2
reviews the related work and Section 3 gives corona models
and some definitions to be used later. In Section 4, the
analyses for corona models, GND, and EPND are carried
out. Based on the analyses, we then propose three nonuni-
form node distribution strategies in Section 5. Section 6
shows the analytical results and the comparison with the
other two strategies in the literature along with detailed
discussions under an ideal scenario. In Section 7, ns-2
simulation results under more realistic scenarios are
provided to show the impacts caused by some factors of
routing and medium access control (MAC) protocols.
Finally, Section 8 concludes this paper.
2 RELATED WORK
In the past, Esseghir et al. [8] and Lian et al. [16] focused on
the nonuniform initial energy distribution. The fundamental
idea behind this topic is to differentiate sensor nodes with
different initial levels of energy according to the workload.
The higher the workload is, the higher the initial level of
energy will be set. Although such a strategy seems to be
promising, its application is difficult since it will be very
inconvenient in production and deployment of sensor nodes
[4], [28]. In [1], [18], and [27], sinkmobility was introduced to
avoid the formation of energy holes. Bi et al. [1] proposed an
autonomous movement strategy called half-quadrant-based
moving strategy (HUMS) to let mobile sinks move proac-
tively toward half-quadrant zones with abundant energy.
Similarly, Marta and Cardei [18] showed that the network
lifetime improvement by using mobile sinks can reach
3.48 times at most (when the mobile sink moves around a
hexagonal network perimeter and stops at the six corners) as
compared to the case with static sinks. Furthermore, a
distributed and localized mobile sink movement algorithm
was also designed by Marta and Cardei to let mobile sinks
be always connected to each other so that the network
lifetime can be prolonged. Since the gain of sink mobility can
be offset by broadcasting the new location of the sink to
every node in the network, Wu and Chen [27] tried to
incorporate both a static sink and a mobile sink in designing
a WSN by putting the static sink at the center of the
monitored area and allowing the mobile sink to move
around the network perimeter. Every time the mobile sink
stops at a new location, it only broadcasts location update
messages to a subset of sensor nodes near the mobile sink.
Although mobile sinks bring some advantages to WSNs,
some new issues are also introduced to routing protocols.
Hence, many researchers focused on energy-aware routing
protocol as well for WSNs in recent years [10], [12], [20]. In
[10], Gatzianas and Georgiadis presented a distributed
algorithm to select routing paths for data to be delivered to
the mobile sink to maximize the network lifetime in a WSN
with a mobile sink. Heo et al. [12] proposed an energy-aware
routing protocol for wireless industrial sensor networks
(WISNs) providing real-time and reliable communications
by selecting a path randomly according to a probability.
Their routing protocol exhibits better performance than
existing quality of service (QoS) routing protocols in terms of
packet loss and delay. Since the WSN coverage is also
important, Perillo and Heinzelman [20] proposed an inte-
grated routing and sensor selection protocol called distrib-
uted activationwith predetermined routes (DAPR) to avoid a
path selected from a subset of the region with sparsely
distributed sensor nodes. Besides coverage consideration,
their protocol can also improve the network lifetime.
In the literature, energy-aware node distribution was
proposed to alleviate the energy hole problem in WSNs, too,
for example, [3], [4], [13], and [28]. In [3], Chang and Chang
proposed an efficient node placement, topology control, and
a scheduling protocol for the MAC layer to prolong the
network lifetime, to balance power consumption among
sensor nodes, and to avoid transmission collision in a grid-
based WSN. Cheng et al. [4] formulated a constrained
multivariable nonlinear programming problem to determine
both locations of sensor nodes and data transmission
patterns so that the network lifetime is maximized and the
application-specific total cost is minimized given the
number of sensor nodes. Hou et al. [13] considered a two-
tiered WSN, namely, a WSN with a sink, cluster head
sensors to forward data to the sink, and low-cost sensors to
sense the surrounding area. They tried to solve simulta-
neously the energy provisioning and relay node placement
problems using a heuristic approach by transforming a
mixed-integer nonlinear programming problem into a linear
programming problem. To the best of our knowledge, one of
novel node distribution approaches was proposed by Wu et
al. in [28]. They analyzed the theoretical aspects of mitigating
the energy hole problem in a corona-basedWSNwith the aid
of a nonuniform node distribution strategy. They claimed
that balanced energy depletion among sensor nodes is
impossible due to the traffic pattern of WSNs, while
subbalanced energy depletion in the network is still
achievable. In fact, their proposed strategy will be the
stepping stone for Strategy I in this paper. Nevertheless, we
can prove in this paper that completely balanced energy
depletion is achievable with the additional help of node
transmission range arrangement. Adjusting transmission
ranges of sensor nodes has also been discussed by Cardei et
al. in [2] to give a significant impact on the network lifetime.
Besides the aforementioned approaches, some researches
devoted to design a long-lived WSN via exploring transmis-
sion schemes [17] and managing the status operation of each
sensor during the active/inactive period of a sensor or the
selection mechanism of cluster heads [9].
Since Wu’s scheme [28] is one of the most related
schemes to ours in the literature, let us further take a closer
look at it. In [28], Wu et al. first claimed that balanced energy
depletion among sensor nodes in a uniform-width corona
model (see the next section) is impossible. Then, they
proposed their nonuniform node distribution strategy, i.e.,
the so-called Wu’s scheme in this paper, based on the
uniform-width corona model and a routing protocol called
q-switch routing specifically designed for the corona-based
1298 IEEE TRANSACTIONS ON MOBILE COMPUTING, VOL. 10, NO. 9, SEPTEMBER 2011
depending on the system environment. According to [11],
the typical values for these parameters are Eelec ¼ 50 nJ/bit,
 ¼ 0:0013 pJ/bit/m4, and  ¼ 4. As for the sensing/idel
energy consumption, it is actually ignored for simplicity in
the theoretical energy depletion analysis. However, a
constant sensing/idle energy consumption is considered
in our ns-2 simulations (see the simulation setting later) to
make the simulation scenario realistic.
3.2 Definitions
In the following, three definitions to be used throughout
this paper are given:
Definition 3.1. The corona lifetime (measured in unit time (or
rounds)) in corona Ci is defined as the ratio of the total initial
energy in corona Ci and the energy consumption per unit time
in corona Ci. Denoting the initial energy of each sensor node
and the total number of sensor nodes in corona Ci by " and Ni,
respectively, the total initial energy in corona Ci is then "Ni.
Further letting Ei stand for the energy consumption per unit
time in corona Ci, the corona lifetime in corona Ci is
"Ni
Ei
.
Definition 3.2. The network lifetime (measured in unit time (or
rounds)) is defined as the time interval from the very
beginning of the network operation until the instant at which
the first sensor node depletes its energy. Alternatively, the
network lifetime is the shortest lifetime of a sensor node. If the
energy consumption of each sensor node within corona Ci, 8i,
is uniform/identical (i.e., the energy consumption of each
sensor node within corona Ci, 8i, is the same), the energy
consumption per unit time of each sensor node in corona Ci is
then Ei=Ni. For such a case, the lifetime of any sensor node in
corona Ci is
"
Ei=Ni
¼ "NiEi which is the same as the corresponding
corona lifetime defined previously. Therefore, the network
lifetime can then be determined by the shortest corona lifetime
and is expressed as min8if"NiEi g.
Although the network lifetime from the beginning until
the instant at which the last node dies is analytically
tractable, it is not meaningful since the connectivity cannot
be guaranteed during this network lifetime. As for the
network lifetime from the beginning until the instant at
which the network gets partitioned, it totally makes sense.
However, it is not analytically tractable. To have mean-
ingful and analytically tractable network lifetime, we
consider the network lifetime defined above only. In fact,
this definition of network lifetime was widely employed in
the literature as well.
Definition 3.3. Balanced energy depletion means that all sensor
nodes in the network deplete their energy simultaneously,
namely, the lifetimes of all sensor nodes are the same and
identical to the corresponding network lifetime. If the uniform
energy consumption of each sensor node within the same corona
is achievable, then the balanced energy depletion is achieved if
"Ni
Ei
¼ "NjEj ; 8i; j; i 6¼ j. The reason is illustrated as follows: By
Definitions 3.2, the network lifetime is min8if"NiEi g. Because of
"Ni
Ei
¼ "Nj
Ej
; 8i; j; i 6¼ j;
min8i
"Ni
Ei
 
¼ "Ni
Ei
¼ "Nj
Ej
; 8i; j; i 6¼ j:
Therefore, "Ei=Ni ¼ "Ej=Nj ¼ min8if
"Ni
Ei
g; 8i; j; i 6¼ j, which says
that the lifetimes of all sensor nodes are the same and identical
to the network lifetime, i.e., balanced energy depletion.
4 ANALYSIS ON THE CORONA MODEL
Based on the optimal sensor node placement to be derived,
the minimum number of sensor nodes necessary to meet the
coverage requirement of each corona is then derived.
Afterwards, energy depletion analyses are given. Finally,
we prove that balanced energy depletion is analytically
achievable for two primitive node distributions.
4.1 Optimal Sensor Node Placement
In the following theorem, the optimal position of a sensor
node within a corona is given.
Theorem 4.1. Assume a corona model ðk; w1; . . . ; wi; . . . ; wkÞ
with si; i ¼ 1; . . . ; k, denoting the sensing range of the sensor
node in corona Ci and
wi
2  si 
ﬃﬃﬃ
2
p ðPij¼1 wjÞ. The optimal
position of a sensor node within corona Ci can be determined so
that the maximum corona coverage is reached. Let this optimal
position be located at the position with distance bopti measured
from the center of the corona, then bopti ; i ¼ 1; 2; . . . ; k, should
satisfy the following conditions:
bopt1 ¼
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
w2
1
s2
1
3
q
; for w12  s1  w1;ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
s21  w21
p
; for w1 < s1 
ﬃﬃﬃ
2
p
w1;
(
ð1Þ
bopti ¼
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃPi1
j¼1 wj
 2
þ Pij¼1 wj 2 2s2i
2
vuut
; i ¼ 2; . . . ; k: ð2Þ
Proof.Without loss of generality, we assume that the sensor
node within corona Ci is deployed at ð0; biÞ; bi  0. This
theorem is then proven through the following two cases:
case of the innermost corona and case of corona Ci; i  2,
as shown in Fig. 1. With the help of the symmetric
property regarding y-axis, the first part of this theorem,
i.e., (1), is proven by finding the optimal value of b1 such
that the shaded area (half of the corona coverage) shown
in Fig. 1a is maximized. The second part of this theorem,
i.e., (2), is proven by finding the optimal value of bi to
1300 IEEE TRANSACTIONS ON MOBILE COMPUTING, VOL. 10, NO. 9, SEPTEMBER 2011
Fig. 1. Auxiliary figures for deriving the optimal position of a sensor node
within corona Ci. (a) Case of the innermost corona. (b) Case of corona
Ci; i  2.
4.2 Lower Bounds on Sensor Nodes Deployed in
Coronas
Based on Theorem 4.1, the minimum number of sensor
nodes that should be deployed in each corona is determined
by the following corollary.
Corollary 4.1. The minimum number of sensor nodes that
should be deployed in corona Ci in order to fully cover this
corona is
Nmini ¼
360
2 cos1
	
bopti

2
þ
Pi
j¼1 wj
 2
s2i
2bopti
Pi
j¼1 wj
 
0
@
1
A
2
6666666666
3
7777777777
;
for i ¼ 1; . . . ; k:
ð3Þ
Proof. Two adjacent sensor nodes placed according to
Fig. 2a can cover corona Ci with the largest coverage
without any gap between them. Using the cosine law,
the maximum half angle i=2 of the two adjacent sensor
nodes deployed in corona Ci as shown in Fig. 2b can be
derived as follows:
s2i ¼
	
bopti

2 þ Xi
j¼1
wj
 !2
2bopti
Xi
j¼1
wj
 !
cos
i
2
 
;
leading to
i ¼ 2 cos1
	
bopti

2 þ Pij¼1 wj 2s2i
2bopti
Pi
j¼1 wj
 
0
B@
1
CA:
Since the full angle of each corona is 360 degree, the
minimum number of sensor nodes that should be
deployed in corona Ci in order to fully cover this corona
is given by
Nmini ¼
360
2 cos1
	
bopti

2
þ
Pi
j¼1 wj
 2
s2i
2bopti
Pi
j¼1 wj
 
0
@
1
A
2
6666666666
3
7777777777
;
for i ¼ 1; . . . ; k:
ut
4.3 Energy Depletion Analysis
Basically, sensor nodes in the outermost corona only need
to transmit their own data, while sensor nodes in the other
coronas not only transmit their own data but also relay data
from outer coronas. Now, let us analyze the energy
depletion. Denoting Ni, N
a
i , Ei, and di as the number of
sensor nodes, number of active sensor nodes, energy
consumed per unit time, and transmission distance of
sensor nodes, respectively, in corona Ci, the energy
consumption per unit time in corona Ci is calculated as
follows according to our energy consumption model:
Ei ¼
L

Nai
	
Eelec þ di


þPkj¼iþ1Naj 	2Eelec þ di 
; 1  i  k 1;
NakL
	
Eelec þ dk


; i ¼ k:
8><
>: ð4Þ
Under the basic operation mode, all sensor nodes are active
with the following corresponding energy consumption per
unit time denoted by EBi :
EBi ¼
L

Ni
	
Eelec þ di


þPkj¼iþ1Nj	2Eelec þ di 
; 1  i  k 1;
NkL
	
Eelec þ dk


; i ¼ k;
8><
>: ð5Þ
where the superscript B is used to explicitly denote the basic
operation mode. Note that the main task of an active sensor
node is either sensing its surrounding area and transmitting
data to its child node or relaying data from its parent node
if it is chosen as the relay node. If a sensor node does
nothing at all, it will remain idle to save energy. Hence, the
energy consumption per unit time with a minimum number
of active sensor nodes Nmini in corona Ci derived from
Corollary 4.1 denoted by EMi (here, the superscript
M is
used to explicitly denote the minimum active sensor nodes
getting involved) is
EMi ¼
L

Nmini
	
Eelec þ di


þPkj¼iþ1Nminj 	2Eelec þ di 
; 1  i  k 1;
Nmink L
	
Eelec þ dk


; i ¼ k:
8><
>: ð6Þ
4.4 Balanced Energy Depletion Analysis for Two
Primitive Node Distributions
In the following, the feasibility of balanced energy depletion
using two primitive node distributions, i.e., GND specifi-
cally designed for corona model II and EPND, is examined.
4.4.1 GND Specifically Designed for Corona Model II
In [28], Wu et al. have claimed that their GND under corona
model I merely achieves the subbalanced energy depletion,
i.e., balanced energy depletion among all coronas except for
the outermost one. This motivates us to consider the GND
designed for corona model II rather than corona model I. To
achieve balanced energy depletion among all coronas, the
transmission distance in the outermost corona do should
be properly adjusted so that Tk1 ¼ Tk, i.e., "Nk1EB
k1
¼ "Nk
EB
k
by
Definition 3.1. This condition and (5) lead to
1302 IEEE TRANSACTIONS ON MOBILE COMPUTING, VOL. 10, NO. 9, SEPTEMBER 2011
Fig. 2. Sensor nodes deployed in corona Ci with optimal positions.
(a) The maximum angle of two adjacent sensor nodes in order to cover
the corona. (b) The representative triangle taken from (a).
corona can be reached by a specific sensor node. Then, the
connectivity between any sensor node and the sink node
can be ensured. With such setting for c1 and c2, the problem
of connectivity is then avoided. Of course, the larger c1 and
c2 are, the more sensor nodes in the neighboring corona can
be reached. In the following, we only show the result when
c1 ¼ c2 for ease of calculation. For simplicity, we introduce c
ð1Þ to serve as the common multiplier, i.e., c ¼ c1 ¼ c2.
Now, (8) can be rewritten as
ðk 1Þdþ do ¼ cR: ð9Þ
Applying Theorem 4.2, we have
ðk 1Þdþ 2Eelec þ qd

ðq  1Þ
 1

cR ¼ 0: ð10Þ
Equation (10) in terms of d can be solved numerically, for
example, by the Bisection method (see [21] for details). Once
the value of d is determined, the transmission range of
sensor nodes in a different corona is then totally determined
according to Theorem 4.2 via
di ¼ d; for i ¼ 1; 2; . . . ; k 1;do; for i ¼ k:

ð11Þ
Similarly, the width of each corona, i.e., w and wo, can be
calculated (i.e., w ¼ d=c and wo ¼ do=cÞ accordingly once d
and do are fixed.
5.1.2 Sensor Node Arrangement and Deployment
As for the number of sensor nodes deployed in a corona, it
follows the GND to have
Ni ¼
qNiþ1; i ¼ 1; 2; . . . ; k 2;
ðq  1ÞNk; i ¼ k 1;
Nmink ; i ¼ k;
8<
: ð12Þ
where q 2 IN f1g is the common ratio of the geometric
progression. Note that Ni (i ¼ 1; 2; . . . ; k) implicitly depend
on d and do. Let us further consider the deployment of
sensor nodes. Taking a closer look at Theorem 4.1 for the
innermost corona, one can see that the positions of sensor
nodes are identical to that of the sink. Such deployment is
impractical. Therefore, we suggest deploying sensor nodes
at the middle of the corona width in the innermost corona.
As for the other coronas, Theorem 4.1 is applicable for
deployment of sensor nodes to reach optimal positions of
sensor nodes in the coronas.
5.1.3 Routing Protocol
Because of the corona arrangement and the geometric
progression on the number of sensor nodes deployed in a
corona, the q-switch routing proposed in [28] and described
in Section 2 is still applicable to Strategy I for data routing.
Therefore, the routing protocol associated with Strategy I in
this paper is set to this q-switch routing.
With the aforementioned design, one can clearly see that
Strategy I differs from Wu’s scheme [28] in the following
aspects: 1) Strategy I is designed based on corona model II,
while Wu’s scheme is designed based on corona model I,
2) Using Strategy I, completely balanced energy depletion
can be reached. However, Wu’s scheme claimed that it is
impossible to achieve completely balanced energy deple-
tion. Therefore, Wu’s scheme simply reaches subbalanced
energy depletion, and 3) The optimal sensor placement is
touched in this paper and utilized by Strategy I. Since the
optimal sensor node placement is not touched in [28], Wu’s
scheme does not employ the optimal sensor node placement.
5.2 Strategy II (Designed for Corona Model I)
Strategy II consists of a constraint on the number of sensor
nodes that should be deployed based on the EPND, a
simple switch scheduling, and a q-switch-like routing
protocol under corona model I. Now, these are explained
in detail as follows:
5.2.1 Sensor Node Arrangement and Deployment
In order to achieve better efficiency on sensor node
arrangement in each corona, each sensor node is assumed
to be either in the sensing or the nonsensing state. With the
same reasoning for the deployment of sensor nodes in
Strategy I, a deployment scheme based on Theorem 4.1
except for the innermost corona in which we suggest
deploying sensor nodes at the middle of the corona width is
employed for Strategy II in the following. As for the number
of sensor nodes to be deployed, it follows the EPND to form
the following constrained EPND (CEPND):
Ni ¼
EMi
EM
k
Nmink
l m.
Nmini
l m
Nmini ; for i ¼ 1; . . . k 1;
Nmink ; for i ¼ k:
(
ð13Þ
Note that EMi ; i ¼ 1; 2; . . . ; k 1, are still applicable here
since the switch scheduling can control the energy
consumption to EMi for corona Ci. In the previous
calculation, the following operations are required. 1) The
inner ceil function de is employed in order to have an
integer number of sensor nodes if
EMi
EM
k
Nmink is not an integer
and 2) The outer ceil function de is used to ensure that the
number of sensor nodes in corona Ci, i.e., Ni, to be a
multiple of the minimum number of sensor nodes Nmini .
Note that the requirement that Ni is a multiple of the
minimum number of sensor nodes Nmini is tailored for the
switch scheduling with consideration of coverage. With
these extra operations, energy depletion is perhaps not
completely balanced among sensor nodes. However,
Strategy II is expected to give the best performance in the
network lifetime and efficiency on sensor node arrangement
as compared to Wu’s scheme and Strategy I to be shown in
the next section.
5.2.2 Switch Scheduling
A simple switch scheduling in a turn-basedmanner utilizing
counters determineswhether a sensor node needs to sense its
surrounding area or not. Shown in Fig. 3 is the pseudocode
for our designed switch scheduling in corona Ci. Sensor
nodes not chosen to sense its surrounding area will remain
idle or relay the data received from its upper sensor node in
the outer corona. Of course, sensor nodes chosen to sense its
surrounding area need to perform this task solely or along
with some extra task, i.e., data relay, if any.
1304 IEEE TRANSACTIONS ON MOBILE COMPUTING, VOL. 10, NO. 9, SEPTEMBER 2011
constraint on the number of sensor nodes that should be
deployed (based on (13)), a simple node switch scheduling,
and a q-switch-like routing protocol. However, the three
components should be designed based on corona model II
like Strategy I. Since the three components for Strategy III can
be easily obtained from the corresponding three components
of Strategy II, they will not be further elaborated for making
this paper concise and compact.
6 ANALYTICAL RESULTS uNDER AN IDEAL
SCENARIO AND DISCUSSIONS
Now, analytical performance metrics of the three proposed
strategies are examined under an ideal scenario, including
. total number of sensor nodes required for the
network operation,
. network lifetime (defined according toDefinition 3.2),
and
. residual energy of each sensor node when the
network operation is terminated.
Here, the ideal scenario only considers an ideal MAC layer
and does not consider the energy consumption in sensing
and idle states. The three proposed strategies are also
compared with the following two different node distribu-
tion strategies: Wu’s scheme [28] and uniform node distribu-
tion (simply called uniform scheme) which is a typical
sensor node distribution strategy with uniformly distrib-
uted sensor nodes in the network.
Referring to (12) and (13), the total numbers of sensor
nodes required can be determined accordingly for the three
proposed strategies as well as Wu’s scheme. As for the
uniform scheme, it can be counted easily because of its fixed
grid length. Let us now further derive the network lifetime
and residual energy as follows. By Definition 3.2, the
network lifetime T is
T ¼ minfT1; T2; . . . ; Tkg: ð14Þ
For Wu’s scheme, the network lifetime TW can be
determined analytically in terms of any of T1; . . . ; Tk1
because T1 ¼ T2 ¼    ¼ Tk1 < Tk (see [28]), i.e.,
TW ¼ T1 ¼    ¼ Tk1: ð15Þ
Because Strategy I balances energy depletion among
sensor nodes, the network lifetime TS1 can be analytically
expressed in terms of any of T1; . . . ; Tk, i.e.,
TS1 ¼ T1 ¼    ¼ Tk: ð16Þ
For Strategies II and III,
Ti ¼ "Ni
EMi
¼
"
EMi
EM
k
Nmink
l m.
Nmini
l m
Nmini
EMi

"
EMi
EM
k
Nmink
 .
Nmini
 
Nmini
EMi
¼ "Nk
EMk
¼ Tk; i ¼ 1; 2; . . . ; k 1:
Therefore, their corresponding network lifetimes TS2 and
TS3 can be expressed by
TS2 ¼ TS3 ¼ Tk: ð17Þ
Finally, it is easily understood that T1  T2  . . .  Tk for
the uniform scheme. Accordingly, its network lifetime TU is
TU ¼ T1: ð18Þ
As for the residual energy of the ith corona ERi
ði ¼ 1; 2; . . . ; kÞ, it can be calculated via
ERi ¼
"Ni  TEi; Wu0s Scheme; Strategy I;
and Uniform Scheme;
"Ni  TEMi ; Strategies I and II;
8<
: ð19Þ
where the network lifetime T for a different strategy should
follow the calculation in (15)-(18).
In this section, network lifetime and residual energy are
also validated by simulations written in the C# program-
ming language. Before the discussions on the analytical
results, let us further elaborate on the calculation/simula-
tion arrangement first.
6.1 Calculation/Simulation Arrangement
In our calculation/simulation, each sensor node has
a uniform initial amount of energy " ¼ 0:5 J with
Eelec ¼ 50 nJ/bit,  ¼ 0:0013 pJ/bit/m4,  ¼ 4, and  ¼ 1
(the sensing range is the same as the transmission range). In
the uniform scheme, Wu’s scheme, and Strategy I, each
sensor node generates 400 bits of data each round with
duration of 1 ms, while only the sensor nodes staying in the
sensing state for Strategy II/III generate 400 bits of data. In
Strategy I/III, c ¼ 1, i.e., the transmission range of each
sensor node is equal to the corona width. For a given
network radius R, the number of coronas k is obtained via
k ¼ R=du for all strategies considered. Therefore, the corona
width is fixed for Wu’s scheme, Strategy II, and the uniform
scheme. To have a different network radius, a different
number of coronas is arranged accordingly. For Strategies I
and III, the number of coronas is determined like Strategy II
once a network radius is given. However, d and do need to
be recalculated based on (9) using the given network radius.
Consider an example of the 5-corona network arrangement
with network radius of 500 m. For Strategy I/III, we have
d ¼ 94:0904 m, do ¼ 123:6383 m, and Nmin5 ¼ 15. For Wu’s
scheme and Strategy II, uniform corona width du ¼ 100 m
and Nmin5 ¼ 19 are set. Noting that sensor nodes are
deployed at corners of grids with grid length of 50 m for
the uniform scheme, we have uniform corona width du ¼
100m, N1 ¼ 12; N2 ¼ 36; N3 ¼ 64; N4 ¼ 84, and N5 ¼ 120. In
Table 1, all corresponding parameters are listed.
6.2 Analytical Results and Discussions
6.2.1 Total Number of Sensor Nodes
Shown in Fig. 4a are the analytical results on the total
number of sensor nodes used in the network for the five
strategies under various network radii ranging from 300 to
1,000 m. Obviously, the total numbers of sensor nodes in
Wu’s scheme and Strategy I increase exponentially, while
the total numbers of sensor nodes in Strategy II, Strategy III,
and the uniform scheme almost increase linearly. For
1306 IEEE TRANSACTIONS ON MOBILE COMPUTING, VOL. 10, NO. 9, SEPTEMBER 2011
the sensor nodes in the innermost corona need to relay the
data from the outer coronas, more energy consumption is
requiredwhen the network radius gets larger due to a higher
amount of data to relay per round. Therefore, the network
lifetime of the uniform scheme as shown in Fig. 5a has a
decreasing trend as the network radius increases. In fact, the
uniform node distribution makesN1 for the uniform scheme
the smallest as compared to those of the other four strategies.
Explicitly, the uniform scheme gives the worst performance
among the five strategies.
Different from the uniform scheme, Wu’s scheme, and
Strategy I which let all sensor nodes sense the surrounding
area per round, Strategy II/III only sets a minimum number
of sensor nodes determined by Nmini in corona Ci to sense
the surrounding area per round. Besides, Strategy III sets the
same number of sensor nodes with same energy dissipation
for the outermost corona as Strategy I, while Strategy II sets
more sensor nodes with less energy dissipation for the
outermost corona than Strategy I. Noting that the corona
lifetime of the outermost corona Tk determines the network
lifetime for Strategy II from (17) and
Tk ¼ "Nk
Ek
¼ "Nk
Nk
	
Eelec þ dk

 ¼ "	
Eelec þ du


for Strategy II is a constant, its network lifetime is a constant.
This explains why a constant behavior of network lifetime
for Strategy II as shown in Fig. 5a is observed. Equation (17)
also shows that the network lifetime of Strategy III is
determined by the corona lifetime of the outermost corona
Tk. With the same corona model and the same number of
sensor nodes with same energy dissipation in the outermost
corona as Strategy I, the network lifetime of Strategy III is
identical to that of Strategy I (see (16) and (17)). This explains
why the network lifetimes of Strategies I and III coincide in
Fig. 5a. Since more sensor nodes with less energy dissipation
in the outermost corona for Strategy II as compared to
Strategy I, Strategy II has a longer network lifetime than
Strategy I as well as Strategy III (see (16) and (17)).
The above observations clearly illustrate that the best
strategy to the worst strategy in terms of network lifetime
are Strategy II, Strategy I as well as Strategy III, Wu’s
scheme, and the uniform scheme. Since the uniform scheme
performs worst, we only show the improvement ratios for
Strategies I-III over Wu’s scheme in Fig. 5b. This figure
shows that Strategy II gains 128 percent of improvement
over Wu’s scheme regardless of network radii. At the
network radius of 300 m (1,000 m), Strategies I and III can
get 28 percent (8 percent) of improvement over Wu’s
scheme. This clearly reveals the superiority of Strategy II
over the other strategies in terms of network lifetime.
6.2.3 Residual Energy of Each Sensor Node
In this part, the residual energy for the five strategies under
a 5-corona model is evaluated. Note that sensor nodes are
assigned IDs starting from the outermost corona to the
innermost corona.
Shown in Fig. 6 is the residual energy of each node (or
called the residual nodal energy later) for the five strategies.
Explicitly, one can witness that the analytical and simulation
results match well. From Fig. 6e, one can easily see that the
uniform scheme leaves an abundant amount of nodal energy
as expected, especially for the sensor nodes in the outermost
corona Approximately, 96 percent of the initial nodal energy
is left there. Fig. 6a shows that Wu’s scheme leaves a
considerable amount of remaining nodal energy (56 percent
or so of the initial nodal energy) in the outermost corona
when the network operation is terminated. For Strategy I,
almost all sensor nodes exhaust energy when the network
operation is terminated as shown in Fig. 6b. In fact, the
residual nodal energy for most of sensor nodes is below
5 104 J when applying Strategy I. As shown in Fig. 6c,
Strategy II still gives quite good performance in the residual
nodal energy although not all sensor nodes completely
exhaust energy. The remaining nodal energy is at most
13 percent of the initial nodal energy (in the fourth corona)
only. Similar to Strategy II, Strategy III gives quite good
performance in the residual nodal energy as well. As shown
in Fig. 6d, only 16 percent at most of the initial nodal energy
is left among sensor nodes (in the second corona).
To have a comparison on the degree of energy depletion as
compared to the ideal case with complete energy depletion
(zero energy left), one can use the following two ways to
gauge this degree. The first one is the total residual energy in
the network and the second one is de ¼
P
8jðER;jÞ=nt. Here,
de is the defined degree of energy depletion as compared to
the ideal case, ER;j denotes the residual energy of the senor
nodewith ID j,   1 serves as a given amplifying factor used
to amplify the difference of the residual nodal energy to zero,
1308 IEEE TRANSACTIONS ON MOBILE COMPUTING, VOL. 10, NO. 9, SEPTEMBER 2011
Fig. 6. Residual energy of each sensor node under an ideal scenario.
(a) Wu’s scheme. (b) Strategy I. (c) Strategy II. (d) Strategy III.
(e) Uniform scheme.
percentages of improvement as compared to Wu’s scheme.
However, the percentages of improvement drop as com-
pared to those under the ideal scenario. For Strategy II, the
percentage of improvement is around 97-106 percent under
scenario Realistic I and 87-97 percent under scenario
Realistic II. As for Strategies I and III, the percentage of
improvement is around 5-25 percent under scenario
Realistic I and 4-22 percent under scenario Realistic II.
7.2 Residual Energy of Each Sensor Node
Based on a 5-corona model, Fig. 8 shows the residual energy
of each node for the five strategies under scenarios Realistic I
and II as well as the ideal scenario. This figure clearly
illustrates that almost the same distribution of the residual
energy is observed for the three scenarios as far as a specific
strategy is concerned, in particular, the uniform scheme. To
examine the degree of energy depletion, Table 2 lists the
total residual energy in the network and d2e for the five
strategies under the ideal scenario and scenarios Realistic I
and II. Compared to the ideal scenario, only Strategy I shows
remarkable impacts caused by scenarios Realistic I and II.
However, Strategy I still possesses its superiority in energy
depletion over the other four strategies. Likewise, Wu’s
scheme and Strategies II and III almost have comparable
performance in energy depletion, while the uniform scheme
performs worst.
8 CONCLUSIONS
Three novel node distribution strategies designed for a
corona-basedWSN are proposed in this paper tomitigate the
energy hole problem. Analyzing the corona-based WSN, we
get the optimal positions of sensor nodes, lower bounds on
sensor nodes to be deployed within a corona, and proposals
of GND as well as EPND. These results enable the three
proposed strategies to give full WSN coverage while
providing a long network lifetime. In fact, one of our
proposed strategies, i.e., Strategy I, has succeeded in solving
one of the most difficult tasks in WSNs, namely, balancing
energy depletion among sensor nodes. Incorporating switch
scheduling, Strategy II provides the longest network lifetime,
full WSN coverage, and high efficiency in using sensor
nodes. Similar to Strategy II, Strategy III incorporates switch
scheduling and reaches the best efficiency in using sensor
nodes, full WSN coverage, and a durable network lifetime.
Via both analytical and simulation observations, we can
show the superiority of the three strategies over the other two
most related strategies, i.e., Wu’s scheme and the uniform
scheme. We have successfully demonstrated that Strategies
I-III are highly recommended for use in a small-area WSN,
while Strategies II-III are still highly recommended for a
large-areaWSN to achieve a long network lifetime, full WSN
coverage, and efficient usage of sensor nodes.
ACKNOWLEDGMENTS
The work was supported by the National Science Council
(NSC), Taiwan, under Contracts NSC 96-2221-E-011-020-
MY3 and NSC 97-2221-E-011-045-MY3.
REFERENCES
[1] Y.Z. Bi, L.M. Sun, J. Ma, N. Li, I.A. Khan, and C.F. Chen, “HUMS:
An Autonomous Moving Strategy for Mobile Sinks in Data-
Gathering Sensor Networks,” EURASIP J. Wireless Comm. and
Networking, pp. 1-15, 2007.
[2] M. Cardei, J. Wu, M. Lu, and M.O. Pervaiz, “Maximum
Network Lifetime in Wireless Sensor Networks with Adjus-
table Sensing Ranges,” Proc. IEEE Int’l Conf. Wireless and Mobile
Computing, Networking and Comm. (WiMob ’05), pp. 438-445,
Aug. 2005.
[3] C.Y. Chang and H.R. Chang, “Energy-Aware Node Placement,
Topology Control and MAC Scheduling for Wireless Sensor
Networks,” Computer Networks, vol. 52, no. 11, pp. 2189-2204,
2008.
1310 IEEE TRANSACTIONS ON MOBILE COMPUTING, VOL. 10, NO. 9, SEPTEMBER 2011
Fig. 8. Residual energy of each sensor node under ideal and realistic
scenarios. (a) Wu’s scheme. (b) Strategy I. (c) Strategy II. (d) Strategy III.
(e) Uniform scheme.
TABLE 2
Total Residual Energy in the Network and d2e for the Five Strategies under Different Scenarios
A Globally Overlaid Hierarchical P2P-SIP
Architecture with Route Optimization
Huei-Wen Ferng, Member, IEEE, and Iwan Christanto
Abstract—In this paper, a three-level P2P-SIP architecture employing SIP servers is proposed for the overlay network. The proposed
architecture achieves global overlay and has the capability of solving the triangular routing problem for the domain-based P2P-SIP
architecture to reach route optimization. Demonstrated by our numerical results, the proposed architecture can exhibit its superiorities
over the closest-related architectures in the literature in terms of message rate, latency, and physical hops count.
Index Terms—Peer-to-peer, session initiation protocol, global overlay, overlay network.
Ç
1 INTRODUCTION
THEpeer-to-peer (P2P) systemhas beenpopular because ofdistributed operations and low deployment costs. It has
two types: structured one and unstructured one. The
structured P2P system uses a distributed hash table (DHT),
e.g., Bamboo [12] and Chord [17], to construct the overlay
network. On the other hand, the unstructured P2P system
randomly constructs the overlay network. To achieve a good
trade-off between search performance and cost in unstruc-
turedP2Pnetworks, an algorithmcalleddynamic search (DS)
was proposed by Lin et al. [8]. Unlike most P2P lookup
schemes, a lookup scheme maintaining the full system
membership called OneHop was proposed by Fonseca et al.
[4] to achieve single-hop routing when the information is up
to date or routing with a few hops otherwise.
Besides the P2P system, the session initiation protocol
(SIP) [13], [20] based voice over IP (VoIP) utilizing the client-
server paradigm in which SIP servers and user agents (UAs)
work together also gains popularity. Of course, some
researchers tried to touch the issue of combining VoIP and
P2P in thepast aswell, e.g., Skype andpeerTalk [6].However,
proprietary protocols for VoIP signaling are used by Skype
and peerTalk. Since SIP is an important protocol employed in
the next-generation telecommunication system, introducing
the P2P model to it is certainly an interesting topic. This
stimulates researchers to propose the P2P system using SIP,
i.e., P2P-SIP for brevity, e.g., [1], [3], [7], [9], [15]. SIPPeer [15]
wasdevelopedby theColumbiaUniversityusing theSIPover
P2Pmechanism. SOSIMPLE [1]usesP2Pover SIPwith all P2P
communications being replacedby SIPmessages.Ma et al. [9]
modified the ChordDHT tomap the physical topology to the
logical topology and divided the overlay network into a
subnet which consists of ordinary nodes and a main net
consisting of super nodes. The transit-stub (TS) [7] architec-
ture separates the overlay network into the stub overlay
network consisting of common P2P nodes and the transit
overlay network which consists of P2P-SIP routers. In [3],
Cheng et al. proposed the unstructured P2P-SIP calledUP2P-
SIP. Besides these projects, several IETF drafts of the P2P-SIP
architecture were also reported. In [14], a fixed hierarchical
DHT-based P2P-SIP architecture using the SIP over P2P
mechanism was proposed by Shi et al. In [10], a P2P-SIP
architecture with login and bootstrap servers to authenticate
joiningP2PnodeswasproposedbyNarayananandDaley.As
stated in [2] and [16], the aforementioned projects or drafts
still cannot provide secure authentication and global overlay.
Unlike the aforementioned P2P-SIP proposals, this paper
proposes a three-level architecture with consideration of
global overlay and SIP servers authenticating and main-
taining UAs. The first to the third levels are the global, local,
and user ones to maintain the overlay network based on
country IDs, domain names, and SIP uniform resource
identifiers (SIP-URIs), respectively. Furthermore, the pro-
posed architecture can solve the triangular routing problem
for the domain-based P2P-SIP architecture to reach route
optimization.
In the literature, the proposal in [7] is the most similar one
to our proposed architecture. In [7], Li et al. proposed a pure
overlay-based two-level hierarchical transit-stub architec-
ture with the Bamboo DHT algorithm by separating the
overlay into distributed stub overlays and a transit overlay
and newly introducing P2P-SIP routers residing in P2P
nodes for exchanging SIP routing information or routing
interoverlay SIP messages. Via the transit overlay, the
traditional SIP domains are allowed to interwork with
distributed stub overlays. Unlike the transit-stub architec-
ture, our proposed architecture is designed directly based on
SIP servers and P2P overlays to form a hybrid three-level
hierarchical architecture with the Chord DHT algorithm
using searching keys of SIP-URI/password, domain name,
and country ID to achieve global overlay. Moreover, route
optimization can be achieved with our specially designed
solution. Therefore, our proposed architecture differs from
the transit-stub architecture in many aspects to get perfor-
mance improvement. Further comparing our proposed
architecture with the transit-stub architecture in detail, our
IEEE TRANSACTIONS ON PARALLEL AND DISTRIBUTED SYSTEMS, VOL. 22, NO. X, XXX 2011 1
. The authors are with the Department of Computer Science and Information
Engineering, National Taiwan University of Science and Technology, 43
Keelung Road, Section 4, Taipei 106, Taiwan.
E-mail: hwferng@mail.ntust.edu.tw, i_0n3_ch@yahoo.com.
Manuscript received 4 Feb. 2009; revised 11 Nov. 2009; accepted 14 Dec.2010;
published online 10 Mar. 2011.
Recommended for acceptance by Y. Liu.
For information on obtaining reprints of this article, please send E-mail to:
tpds@computer.org, and reference IEEECS Log Number TPDS-2009-02-0054.
Digital Object Identifier no. 10.1109/TPDS.2011.81.
1045-9219/11/$26.00  2011 IEEE Published by the IEEE Computer Society
maintenance cost for the P2P overlay is inevitable in the
P2P architecture (so does our proposed architecture), the
candidate list of gateways can then be easily main-
tained/updated in the normally maintained P2P overlay.
This implies that the maintenance cost required by the
proposed gateway election mechanism should not be
high as compared to the normal maintenance cost for the
P2P overlay. Furthermore, a suitable/best candidate can
be chosen from the periodically updated list. Therefore,
one can believe that the performance for such a gateway
election mechanism should be satisfactory. No doubt,
this gateway election mechanism alleviates the problem
of single point of failure among gateway nodes.
2.4 Solution to the Triangular Routing Problem
Caused by User Mobility
Due to the domain-based nature, a triangular routing
problem occurs in the proposed architecture, causing extra
hops between two UAs when establishing a connection. In
the past, researchers focused on the triangular routing
problem in mobile IP networks and many solutions have
been proposed accordingly. However, this paper focuses on
the triangular routing problem in the overlay network
employing our domain-based P2P-SIP architecture. This
indicates that the solution for the traditional triangular
routing problem in mobile IP networks is not applicable to
the triangular routing problem in the overlay network
employing our domain-based P2P-SIP architecture. There-
fore, a new solution is specifically designed for the
triangular routing problem in the overlay network employ-
ing our domain-based P2P-SIP architecture. Suppose there
are two UAs, say, A belonging to the overlay network in
Taiwan (TW) and B belonging to the overlay network in the
United Kingdom. For some reason, A may move to the
United Kingdom so that A and B are physically close, but
overlaidly far. If A joins the home overlay network in TW
and actively maintains this overlay network, A is overlaidly
close to, but physically far from the home overlay network.
This causes a longer latency for every lookup process.
Moreover, both of them need to route and trace back the SIP
messages through the upper level for establishing a
connection between them. Possibly, A and B are in the
same country or even in the same domain so that routing
and tracing back through the upper level can be totally
avoided. Therefore, several new mechanisms are proposed
in the following to solve such problems by allowing mobile
UAs to register in both home and foreign overlay networks
and sending a SIP message to show the status of mobile
UAs to reach the goal of route optimization.1 To make the
related mechanisms work, new SIP messages, including
REGISTER, ACK, and 302 MOVED TEMPORARILY with
extra information for the home and foreign servers at the
local and global levels, are employed.
2.4.1 User Registration Mechanism for Mobile UAs
To have mobile UAs registered in both home and foreign
overlay networks, the user registration mechanism with
authentication having five steps as shown in Fig. 2a is
proposed. First, a joining node needs to find the address of
the foreign server using well-known multicast “All SIP
servers,” i.e., sip.mcast.net (224.0.1.75) [15] or using a
service location protocol (SLP) [18]. Once it finds the
address of the foreign server, it sends a REGISTER
message to its home server and the foreign server in
Step 1. Note that the address of the home server is a
preconfigured address and the REGISTER message sent to
the home (foreign) server includes an extra “Local-ID”
field and an extra “Global-ID” field to denote the domain
name and the country ID of the foreign (home) server. The
home server then sends a 200 OK message to the foreign
server through the lookup process of the hierarchical
overlay network (Step 2). This 200 OK message includes
“To,” “From,” and “Contact” fields with the SIP-URIs of
the foreign server, joining node, and home server,
respectively. Noting that the foreign server receives the
REGISTER message sent by the joining node containing
the information of the home server and the 200 OK
message sent by the home server, it is able to authenticate
the joining node through the two SIP messages. Afterward,
the foreign server replies the joining node with a 200 OK
message in Step 3 with some extra information of the
successor and predecessor similar to the join mechanism in
Appendix A, which can be found on the Computer Society
Digital Library at http://doi.ieeecomputersociety.org/
10.1109/TPDS.2011.81. The joining node then joins the
foreign overlay network and registers to the home overlay
network in Step 4. As explained in Remark 3, the foreign
local/global gateway can know the status of the mobile UA
using a signaling procedure. Therefore, the foreign server
sends a REGISTER message to its global gateway to
distribute the status of the mobile UA in Step 5. Step 6
performs the DHT stabilization.
Remark 3. Referring to Fig. 2a and the aforementioned
description, one can know that a mobile UA will register
to the home and foreign local gateways by sending
REGISTER messages when it moves to the other
FERNG AND CHRISTANTO: A GLOBALLY OVERLAID HIERARCHICAL P2P-SIP ARCHITECTURE WITH ROUTE OPTIMIZATION 3
Fig. 2. User registration and leave mechanisms for a mobile UA. (a) User
registration mechanism. (b) Leave mechanism.
1. Here the term route optimization is similar to that used in Mobile IP
networks [11].
callee in Step 3. Once the caller’s local gateway receives this
302 MOVED TEMPORARILY message, it knows that the
new location of the callee is located in a different domain of
the same country. As for Steps 4-6, they are similar to the
local-level call establishment mechanism. Note that the
“normal” mechanism is applied for the other cases. For the
comparison purpose, the unnumbered lines indicating the
other steps required in the normal mechanism are also
shown in Fig. 3.
3 PERFORMANCE ANALYSIS
In this section, the message rate, mean number of hops, and
latency are analyzed for the proposed architecture, while
those for the other two architectures are given inAppendix B,
which can be found on the Computer Society Digital Library
at http://doi.ieeecomputersociety.org/10.1109/TPDS.
2011.81. The message rate is the sum of messages generated
by all mechanisms per second per node in the overlay
network. Themean number of hops is the average number of
hops count of a connection. As for latency, it is the average
time to set up a connection.
In fact, the message rate Mprop can be easily obtained by
summing message rates of all levels, i.e.,
Mprop ¼Mu þMl þMg; ð1Þ
where Mu;Ml, and Mg are the message rates for the user,
local, and global levels, respectively. For ease of derivation,
a function hðn;N; pÞ rendered from [5] is given as follows:
hðn;N; pÞ ¼ 1þ pjnhðn 1; N; pÞ þ ð1 pÞ

Xjn
i¼1
pjnih n 2
i
2m=N
 
; N; p
 
;
ð2Þ
where jn ¼ maxfj : 2j  2mnN g; n is the number of hops, N is
the number of UAs/local gateways/global gateways join-
ing the overlay network, and p is a probability of the node
failure with the m-bit Chord ID.
Based on the message rate of [15] (which conducted the
analytical results for the flat architecture only) with a few
modifications, including 1) the number of keys stored k ¼ nN
is fixed at 1 since all UAs join the overlay network; 2) the
number of hops required for the INVITE rate for the call
establishment cu (calls per second per node), REGISTER
refresh rate for the finger table rf (times per second per
node), REGISTER refresh interval for the user maintenance
ur (seconds per node), and REGISTER rate for node join and
leave  (nodes per second) need to be derived using the
expected lookup number of hops E½Hu ¼ 1Nu
PNu1
n¼0 hðn;
Nu; puÞ [5] given the probability of the node failure pu and
the number of UAs Nu at the user level, Mu can be
expressed as
Mu ¼ rs þ rf logðNuÞE½Hu þ cuE½Hu
þ k
ur
E½Hu þ  logðNuÞE½Hu
Nu
;
ð3Þ
where rs (times per second per node) is the REGISTER
refresh rate for the Chord ring. Similarly, the message rate
of the local (global) level Ml (Mg) can be derived based on
[15] with the following modifications: 1) the REGISTER
refresh interval for the user maintenance and the REGISTER
rate for node join and leave vanish since SIP servers are
employed; 2) the expected lookup number of hops at the
local (global) level E½Hl ¼ 1Nl
PNl1
n¼0 hðn;Nl; plÞ ðE½Hg ¼
1
Ng
PNg1
n¼0 hðn;Ng; pgÞÞ under the probability of the node
failure pl ðpgÞ and the number of local (global) gateways Nl
(Ng) is used for the INVITE rate for the call establishment at
the local (global) level cl (cg) as well as the REGISTER
refresh rate for the finger table rf , namely,
Ml ¼ rs þ rf logðNlÞE½Hl þ clE½Hl; ð4Þ
Mg ¼ rs þ rf logðNgÞE½Hg þ cgE½Hg: ð5Þ
In the following remark, let us further discuss the extra
message rates caused by the signaling procedure triggered
by the user mobility, i.e., Algorithms 1 and 2.
Remark 4. Let us first introduce msl (m
s
g) to denote the
mobility rate in times per second per node to a different
domain of the same (different) country. The extra
message rate at the local level caused by the signaling
procedure is msl ð2þ E½HlÞ with probability msl =ðmsl þ
msgÞ if a different domain of the same country is reached.
If a different domain of a different country is reached, the
extra message rate at the local (global) level caused by the
signaling procedure is msgð3þ E½HlÞ (msgð1þE½HgÞ)
with probability msg=ðmsl þmsgÞ. Reflecting these extra
message rates, the extra message rate on average at the
local (global) level is f½ðmsl Þ2 þ ðmsgÞ2ð2þ E½HlÞ þ
ðmsgÞ2g=ðmsl þmsgÞðfðmsgÞ2ð1þ E½HgÞg=ðmsl þmsgÞÞ. Nor-
mally, msl  cl and msg  cg since the mobility rate is
quite low as compared to the call establishment rate.
Therefore, these extra message rates can be ignored
accordingly. This says that the impact caused by the
signaling procedure triggered by the user mobility is low.
As for the mean number of hops Hprop and latency Lprop,
they can be derived like those in [7] by considering one
more hierarchical level and involvement of the expected
lookup number of hops and shown as follows:
Hprop ¼ hcðE½Hu þ PE½Hl þ PE½HgÞ; ð6Þ
Lprop ¼ hcðtuE½Hu þ tlPE½Hl þ tgPE½HgÞ; ð7Þ
where tu; tl, and tg denote the session setup latencies for the
user, local, and global levels, respectively, P represents the
probability of cache miss, and hc is the average DHT lookup
hops count.
4 NUMERICAL RESULTS AND DISCUSSIONS
Because an enormous amount of nodes (up to 224 ¼
16;777;216) gets involved in the overlay network, neither
the simulation approach nor the real testing approach is
employed in this paper. For brevity, the setting of
parameters is given in Appendix C, which can be found
on the Computer Society Digital Library at http://doi.
ieeecomputersociety.org/10.1109/TPDS.2011.81.
FERNG AND CHRISTANTO: A GLOBALLY OVERLAID HIERARCHICAL P2P-SIP ARCHITECTURE WITH ROUTE OPTIMIZATION 5
flat architecture and the TS architectures with N256 static
routers in the transit overlay, respectively, at 0 (0.8) of the
probability of the node failure.
The mean latency of the TS architecture in Fig. 6 is lower
than that of the flat architecture since the TS architecture
consists of stub and transit overlay networks with fewer
number of nodes in the overlay network. As for the mean
latency of the proposed architecture is concerned, it gains
77 percent (62 percent) and 25 percent (22 percent) of
improvement as compared to the flat architecture (k ¼ 5)
and the TS architecture with N256 static routers in the transit
overlay, respectively, when observing the mean latency
versus probability of cache miss in Fig. 6a at 0 (0.5) of the
probability of cache miss. Observing the improvement
about the mean latency versus total number of nodes in
Fig. 6b, we have 64 percent of improvement as compared to
the flat architecture (k ¼ 5), 11 percent of improvement as
compared to the TS architecture with N256 dynamic routers in
the transit overlay, and 15 percent, 4 percent, and 5 percent
of decline as compared to the TS architectures with N1024 and
N
256 static routers in the transit overlay and the TS
architecture with N1024 dynamic routers in the transit overlay,
respectively, when the total number of nodes is 214 (because
the local and global levels of the proposed architecture must
employ dedicated SIP servers, resulting in more nodes in
the overlay network for initialization). However, the mean
latency of the proposed architecture outperforms that of the
TS architecture if the total number of nodes is 217 or more.
We have 62 percent and 22 percent of improvement as
compared to the flat architecture (k ¼ 5) and the TS
architectures with N256 static routers in the transit overlay,
respectively, when the total number of nodes is 224.
Checking the mean latency versus probability of the node
failure in Fig. 6c at 0 (0.8) of the probability of the node
failure, we have 50 percent (75 percent) and 21 percent
(27 percent) of improvement as compared to the flat
architecture (k ¼ 5) and the TS architectures with N256 static
routers in the transit overlay, respectively.
Again, the proposed architecture provides lower mean
number of hops and latency in general and reveals its
efficiency and robustness to the node failure over the other
two architectures.
5 CONCLUSIONS
A hybrid hierarchical P2P-SIP architecture is proposed in
this paper by employing SIP servers to easily solve the
unauthorized access from unauthenticated nodes and to
provide the global overlay. Because each domain in the
proposed architecture only sets up its SIP server to join the
overlay network, UAs are allowed to establish a multi-
media connection at a very low extra deployment cost. In
addition, the triangular routing problem caused by user
mobility is also addressed and solved to reach route
optimization. Illustrated by the analytical results, the
proposed architecture can provide the lowest message rate
as compared to the flat and TS architectures. Moreover, the
mean number of hops and latency of the proposed
architecture are in general the lowest ones as well. With
the properties of the global overlay, better efficiency in
terms of message rate, mean number of hops, and latency,
robustness to the node failure, and route optimization, the
proposed architecture is highly recommended for use in the
P2P system to significantly enhance scalability, efficiency,
and robustness.
ACKNOWLEDGMENTS
The work was supported by the National Science Council
(NSC), Taiwan under Contracts NSC 96-2221-E-011-020-
MY3 and NSC 97-2221-E-011-045-MY3.
REFERENCES
[1] D. Bryan, B. Lowekamp, and C. Jennings, “SOSIMPLE: A
Serverless, Standards-Based, P2P SIP Communication System,”
Proc. IEEE First Int’l Workshop Advanced Architectures and Algo-
rithms for Internet Delivery and Applications (AAA-IDEA ’05), Mar.
2005.
[2] D. Bryan, P. Matthews, E. Shim, D. Willis, and S. Dawkins,
“Concepts and Terminology for Peer to Peer SIP,” Internet Draft,
Internet Eng. Task Force, July 2008.
[3] C.M. Cheng, S.L. Tsao, and J.C. Chou, “Unstructured Peer-to-
Peer Session Initiation Protocol for Mobile Environment,” Proc.
IEEE 18th Int’l Symp. Personal, Indoor and Mobile Radio Comm.
(PIMRC ’07), 2007.
[4] P. Fonseca, R. Rodrigues, A. Gupta, and B. Liskov, “Full-
Information Lookups for Peer-to-Peer Overlays,” IEEE Trans.
Parallel and Distributed Systems, vol. 20, no. 9, pp. 1339-1351, Sept.
2009.
FERNG AND CHRISTANTO: A GLOBALLY OVERLAID HIERARCHICAL P2P-SIP ARCHITECTURE WITH ROUTE OPTIMIZATION 7
Fig. 6. Mean latencies for different architectures. (a) Under various
probabilities of cache miss. (b) Under various total numbers of nodes.
(c) Under various probabilities of the node failure.
Wireless Pers Commun
DOI 10.1007/s11277-011-0260-4
Energy-Efficient Routing Protocol for Wireless Sensor
Networks with Static Clustering and Dynamic Structure
Huei-Wen Ferng · Robby Tendean · Arief Kurniawan
© Springer Science+Business Media, LLC. 2011
Abstract Due to limited energy of sensor nodes in a wireless sensor network, an energy-
efficient routing protocol with static clustering and dynamic structure (ERP-SCDS) is pro-
posed in this paper. Utilizing virtual points in a corona-based wireless sensor network, static
clusters with dynamic structures are formed in ERP-SCDS. Moreover, next-round cluster
heads are selected in advance to avoid a deadlock when the old cluster heads die. Finally,
a simple relay node selection mechanism instead of a complicated multi-hop route discov-
ery algorithm is further designed for ERP-SCDS. Integrating these mechanisms enables
ERP-SCDS to form balanced cluster sizes to prolong the network lifetime. Via simulations,
we demonstrate that ERP-SCDS significantly outperforms LEACH, HEED, and Hausdorff
previously proposed in the literature.
Keywords Wireless sensor network · Static clustering · Energy efficiency ·
Dynamic structure · Routing · Network lifetime
1 Introduction
Wireless sensor networks (WSNs) formed by a group of sensor nodes in an area of interest
with the short-range wireless communication have become one of popular networks. In a
WSN, sensor nodes gather information and send it to the data processing center called base
station or sink. This task-oriented feature makes WSNs well suit the application in environ-
ment monitoring, for example, alarming the forest guard when the forest is on fire or alarming
the local guard if a dangerous volcanic activity is detected. WSNs also find some applications
in the surveillance system to detect intruders in a secret military facility or detect smugglers
around the country border. The latest application for WSNs is ubiquitous computing. In this
field of applications, WSNs may be used for checking the temperature inside the house. When
H.-W. Ferng (B) · R. Tendean · A. Kurniawan
Department of Computer Science and Information Engineering,
National Taiwan University of Science and Technology, Taipei 106, Taiwan
e-mail: hwferng@mail.ntust.edu.tw
123
Energy-Efficient Routing Protocol for Wireless Sensor Networks
approach is concerned, it can be further classified into static and dynamic ones. Clusters in
static clustering are formed in the beginning, while cluster heads are selected in each round.
Static clustering avoids energy dissipation caused by the re-clustering process, if any, in each
round. However, balanced cluster sizes are desired to prolong the network lifetime. On the
other hand, dynamic clustering constructs new clusters every round, resulting in much energy
wastage. Moreover, cluster sizes still affect the network lifetime.
In the literature, many clustering protocols have been proposed for WSNs, e.g., [2,5–11,
14,15,18,21–23,26,27,29,31–34,36]. In [2], Al-Karaki et al. introduced the optimal aggre-
gation points to improve effectiveness of data aggregation. Boukerche et al. [5] proposed a
clustering routing protocol using the nearest neighbor approach, alternation of nodes respon-
sible for the inter-cluster communication, and alternation of possible routes to the sink. In [6],
the maximum energy cluster head (MECH) protocol was proposed by Chang and Kuo. For
MECH, cluster head selection is done based on a pre-specified cluster member threshold to
form a balanced cluster. Chen et al. [7] proposed a hierarchical energy-efficient protocol for
aggregator selection (EPAS) with a general compression model for data aggregation. Cui et
al. [8] improved LEACH [13] by considering balance of the network load, multi-hop routing,
and remaining energy of nodes. Another improvement on LEACH was developed by Fan
and Yu [9] via further considering the remaining energy of nodes in the cluster head selec-
tion. In [10], a robust clustering with cooperative transmission (RCCT) for energy-efficient
WSNs to distribute energy loads was proposed by Ghelichi et al. with energy consideration
in selecting cluster members. In [11], the geographical-based multi-hop clustering algorithm
(GBMCA) was proposed by Hao et al. to divide the network area into small regions by adopt-
ing multi-hop links for the inter-cluster communication. In [14], Hong and Liang proposed
an access-based energy-efficient (ABEE) clustering protocol by using a request-response
message mechanism with the first-come-first-serve policy and the assistance of the GPS
system to get node positions. Huang et al. [15] introduced a low-energy static clustering
scheme (LESCS) for WSNs to prolong the network lifetime through solving the hot-spot
problem with static clustering and equal energy consumption throughout the network. In
[18], a distributed position-based network protocol called minimum energy communication
network (MECN) with the aid of GPS receivers to have node positions was proposed by Li
and Halpern. Manjeshwar et al. [21] designed a threshold-sensitive energy-efficient sensor
network (TEEN) protocol to increase network coverage by employing a hierarchical cluster-
ing approach. Furthermore, the adaptive periodic threshold-sensitive energy-efficient sensor
network (APTEEN) [22] protocol was also proposed by Manjeshwar et al. to improve TEEN
by using some extra methods for retrieving information from sensor nodes. Nam et al. [23]
developed an adaptive cluster head selection by considering positions of cluster heads and
cluster members. In [26], Rhazi and Pierre modeled clustering as hyper-graph partitioning
and offered a heuristic solution based on a tabu-search. On the other hand, Su and Zhang
[27] introduced clustering with an optimal number of clusters based on an energy thresh-
old. Wang et al. [29] proposed a dynamic optimal number of clusters based on the current
number of nodes in the network. In [31], Xu et al. developed an adaptive clustering proto-
col for medium-scale wireless sensor networks (ACPM) using an adaptive backoff scheme
to select cluster heads with the highest remaining energy. Ye et al. [32] introduced a two-
tier data dissemination model for large-scale wireless sensor networks to provide scalable
and efficient data delivery to multiple mobile sinks with the assumption that each node is
aware of its location through receiving GPS signals. In the hybrid energy-efficient distrib-
uted (HEED) clustering protocol introduced by Younis and Fahmi [33], minimum degree
nodes, maximum degree nodes, or average minimum reachability power (AMRP) can be
chosen to form a cluster. In [34], Zhang et al. extended the network lifetime by modifying
123
Energy-Efficient Routing Protocol for Wireless Sensor Networks
2 Network and Energy Dissipation Models
2.1 Network Model
The corona-based network model widely used in the literature, e.g., [24,28], and [30], is
employed in this paper. As shown in Fig. 1, the sink is located at the center of the area
and the network coverage is divided into k coronas denoted by C1, C2, . . . , Ck , respectively.
Denoting the radius of the outer concentric circle associated with corona Ci by ri , we assume
ri − ri−1 = r (i ≥ 2) and r1 = r , i.e., equal width of coronas. Furthermore, virtual points
are deployed on these concentric circles. As for data transmission, a low-power broadcast
range R1 and a high-power broadcast range R2 are used for intra-cluster communication and
inter-cluster communication, respectively, in the network. The low-power broadcast range
is obtained via multiplying the farthest distance between a sensor node and the nearest vir-
tual point by two to ensure connectivity inside the cluster. As for the high-power broadcast
range, it is calculated by R2 = max (4R1, R), where R denotes the radius of the area. Note
that 4R1 is needed to ensure the network connectivity between clusters, while R acts as
a threshold to limit the high-power broadcast range since the sink is located at the cen-
ter of the network. For the data communication before the steady-state phase, the medium
access control (MAC) protocol of carrier-sense multiple access with collision avoidance and
acknowledgement (CSMA/CA with ACK) [1] is used. As for the intra-cluster communica-
tion, the use of the TDMA schedule definitely avoids collisions. In this paper, all nodes are
assumed to be time-synchronized by letting the sink broadcast synchronization pulses to all
nodes (see [13] for details). Because the direct sequence spread spectrum (DSSS) can be
used to reduce the inter-cluster interference, no collisions in the inter-cluster communication
are assumed as well. Therefore, we assume that there is no collision and packet loss for
simplicity. Besides, sensor nodes are assumed to always have data to be sent during their
TDMA time slot. Because a wireless sensor network, which usually employs static sensor
nodes as those assumptions made by many papers in the literature, is assumed in this paper,
the impact caused by mobility of sensor nodes will not be studied in this paper. Finally,
sensor nodes are equipped with low-power GPS devices to acquire their positions and sense
continuously as the assumption made in [14,16,18,32,36]. Let us explain this assumption
as follows. First, many sensor nodes with GPS have been already in the market. Second, the
issue of sensor node localization is not the point of the paper. These enable us to pose such
an assumption although it might bring the deployment cost up but might not be unrealistic at
all. Of course, such an assumption can be totally replaced by any possible solution on sensor
node localization reported in the literature for sure.
2.2 Energy Dissipation Model
Like [13], an adaptive energy model is employed in this paper. Therefore, the energy expen-
diture for transmitting an l-bit message from node i to node j denoted by ET x (i, j) can be
calculated via
ET x (i, j) =
{
lEelec + lεfsd2i j , di j < d0,
lEelec + lεmpd4i j , di j ≥ d0,
(1)
where Eelec is the electronic energy consumed per bit for coding, modulation, filtering, and
spreading, d0 is the distance threshold, di j is the distance from node i to node j, εfs is the
amplifier energy for a free space (fs) model when the transmission distance is shorter than
123
Energy-Efficient Routing Protocol for Wireless Sensor Networks
1. Initialization of static clusters:
2. Sensor nodes send their coordinates to the sink. 
3. The sink calculates the number of concentric circles k and virtual point coordinates. 
4. The sink broadcasts virtual point IDs and coordinates. 
5. Each sensor node keeps the nearest virtual point ID and coordinate. 
6. While (all nodes are alive) do
7. Cluster formation:
8. If  (IsFirstRound) then
9. Perform cluster head selection. 
10. Else
11. Nodes whose next-round cluster head flag is set update their status to the cluster head. 
12. End if
13. Each cluster head broadcasts an ADV message. 
14. Nodes with the same virtual point ID reply with a JOIN message. 
15. Each cluster head creates and broadcasts the TDMA schedule. 
16. Next-round cluster head selection:
17. Each cluster head calculates the weighted average wi for its members. 
18. Each cluster head selects and tells the member with the largest wi that “it is the next-round cluster head”. 
19. The member with the largest wi sets its next-round cluster head flag. 
20. Route discovery and relay node tables:
21. Each cluster head broadcasts a candidate relay node message. 
22. Each receiving cluster head checks: 
23. If (d(sender, receiver) < d(receiver, sink)) then
24. If (d(sender, sink) < d(receiver, sink)) then
25. Calculates and inserts the weighted average ciw and ID of the sender to the relay node table. 
26. End if
27. End if
28. The candidate relay node with the largest weighted average ciw is then selected as the relay node. 
29. Steady state:
30. Cluster members send the data to the cluster head. 
31. Each cluster head aggregates and sends the data to the sink via multi-hop routing with relay nodes. 
32. End while
Fig. 2 Pseudocode of ERP-SCDS
Time 
1 2 3 4 • • •
Round Steady-state phase 
2 3 4 2 3 4 
Frame 
1. Initialization of static clusters 
2. Cluster formation 
3. Next-round cluster head selection 
4. Route discovery and relay node tables 
Fig. 3 Time diagram of ERP-SCDS
can reduce transmission energy in a large network. As for the last phase of ERP-SCDS, it is
the steady-state phase in which sensor nodes send information directly to their cluster heads
and the information is then forwarded to the sink by relay nodes through multi-hop routing
or via direct transmission. In Fig. 3, the time diagram of ERP-SCDS is shown. Initialization
of static clusters is done in the beginning. Then, each round consists of the cluster formation,
next-round cluster head selection, route discovery and relay node tables, and steady-state
phase.
3.1 Initialization of Static Clusters
In ERP-SCDS, static clusters are formed using virtual points whose locations are determined
by the sink. First of all, all sensor nodes check their locations using the low-power GPS
device. Then, they send their coordinates to the sink. Upon receiving, the sink calculates
123
Energy-Efficient Routing Protocol for Wireless Sensor Networks
Sink
Virtual Point
(a)
Sink
Virtual Point
(b)
Virtual Point
Sink
(c)
Fig. 5 Distribution of virtual points. a Before improvement. b The first improvement. c The second
improvement
distribution of virtual points can be done by giving extra initial angles to rotate the
virtual points on the concentric circles of coronas C2, C3, . . . , Ck−1 (see Fig. 5c). As for
the initial angle, it can be set to half of the angle between two consecutive virtual points
on the inner concentric circle right next to the current one. Once the coordinates of vir-
tual points have been determined, the sink broadcasts virtual point IDs and coordinates to
all sensor nodes in the network. Finally, each sensor node selects and keeps the nearest
virtual point ID and coordinate. As shown in Fig. 4b, this virtual point selection mech-
anism lets sensor nodes with the same virtual point ID form a cluster with an irregular
shape/structure.
3.2 Cluster Formation
In the beginning, cluster heads are selected using a mechanism assisted by backoff timers.
Each node initially starts a backoff timer according to its distance to the nearest virtual point.
For the i th node, the backoff timer is set to ti via
ti = di2r × TCHS, (7)
where di is the distance from the i th node to the nearest virtual point and TCHS is the time
allocated for the first-round cluster head selection. Note that a distance (di ) is used here to
ensure that the cluster head is the nearest node to the center of the cluster, i.e., the virtual
point, so that balanced energy for data transmission from cluster members to the cluster head
can be assured to prolong the network lifetime. As for 2r , it is used to make the ratio di2r fall
within (0, 1) because di < 2r,∀i under our corona-based model and the way to place virtual
points. With a backoff timer, each node can declare itself a cluster head independently. Once
the backoff timer expires, the node associated with this timer broadcasts an advertisement
(or ADV) message to claim that it is the cluster head to its neighboring nodes with low
power. The first node broadcasting the ADV message then becomes the cluster head. Any
node receiving this ADV message then suppresses its own ADV message to be sent. In the
following remark, let us discuss the case that two/multiple nodes have the same distance to
a virtual point.
Remark 1 In fact, the probability that two/multiple nodes have the same distance to a virtual
point is quite low (almost impossible). However, if this case happens, the following two situ-
ations may happen. First, the two/multiple nodes posses the shortest backoff timer. Because
of the same shortest backoff timer, the two/multiple ADV messages sent by the two/multiple
123
Energy-Efficient Routing Protocol for Wireless Sensor Networks
Sink
Candidate
(a)
Sink
Yes
Yes
No
Candidate
(b)
Sink
Yes
No
No
Candidate
(c)
Fig. 6 Relay node selection. a Broadcast of a relay node candidate message. b First condition. c Second
condition
cluster head is the node closest to the center of the cluster. The current cluster head will
inform the node with the largest weighted average value of “it is the next-round cluster head”
using a next-round cluster head message. Upon receiving this message, this node sets its
next-round cluster head flag. Right before the next round, each node checks its next-round
cluster head flag. If its flag is set, it will automatically become the cluster head in the next
round and perform the cluster formation.
3.4 Route Discovery and Relay Node Tables
At the beginning of this phase, each cluster head broadcasts a candidate relay node message
containing the source node ID, source node coordinate, and source node remaining energy to
its neighboring cluster heads with high power to tell them that “it is a candidate relay node”
(see Fig. 6a). Upon receiving this message, the neighboring cluster head checks whether its
distance to the sending cluster head is shorter than its distance to the sink to ensure that
sending the data to the relay node is nearer than sending it directly to the sink (see Fig. 6b). If
yes, it further checks whether the distance from the sending cluster head to the sink is shorter
than the distance from it to the sink to ensure the right direction/path to the sink (see Fig. 6c).
If yes again, it will insert the sending cluster head ID and the sending cluster head weighted
average value into its relay node table. Here, the weighted average value wci of the i th cluster
head can be obtained via
wci = β1
Ecrem
Ec0
+ β2
(
1 − d
c
i
R
)
, (9)
where β1 and β2 are weighting factors, Ecrem is the remaining energy of the cluster head, Ec0
is the initial energy of the cluster head, and dci is the distance from the i th cluster head to the
sink. As for R, it is used to let dci /R fall within (0, 1) because the distance between a cluster
head and the sink is shorter than the area radius. Finally, the cluster head with the largest
weighted average value listed in the relay node table of the current cluster head is selected
as the relay node for data forwarding of the current cluster head.
3.5 Steady-State Phase
Once the TDMA schedule has been broadcasted to cluster members and the relay nodes
have been selected, intra-cluster and inter-cluster data transmissions can be then started.
For the intra-cluster data transmission, each cluster member sends the sensed data to its
123
Energy-Efficient Routing Protocol for Wireless Sensor Networks
2600
2650
2700
2750
2800
2850
300 350 400 450 500 550 600 650 700
Number of nodes
N
et
w
or
k 
life
tim
e 
(ro
un
ds
)
14
15
16
17
18
(a)
0
100
200
300
400
500
600
700
800
300 350 400 450 500 550 600 650 700
Number of nodes
N
et
w
or
k 
life
tim
e 
(ro
un
ds
)
20
25
30
35
40
(b)
Fig. 7 Network lifetime for different number of clusters under different numbers of nodes. a Case of the
small-area network. b Case of the medium-area network
4.1 Detailed Simulation Arrangement
4.1.1 Small-area Network
For the small-area network, 300–700 sensor nodes are randomly deployed in an area of 100
m × 100 m with a sink at the center. Each sensor node is initially given 2-joule energy and
there are 5 TDMA frames in each round. As for the packet size, it is set to 100 bytes. For
LEACH, the optimal number of clusters copt is set to 11 [13]. For HEED, the cluster radius
is set to 25 m as suggested by [33]. As for Hausdorff, the low-power broadcast range R1 is
set to 30 m [36]. For ERP-SCDS, copt is set to 17 according to the simulation result to be
given later. In WSNs, energy is an important factor. Therefore, we set α1 = β1 = 0.8 and
α2 = β2 = 0.2.
4.1.2 Medium-area Network
In the medium-area network, 300–700 nodes are randomly distributed in an area of 350 m
× 350 m with a sink at the center. For this scenario, 5 joule of the initial energy is given to
each node and each round consists of 10 TDMA frames. As for the packet size, it is set to
500 bytes. For LEACH, copt is set to 7. As for the cluster radius of HEED, it is set to 30 m.
For Hausdorff, the low-power broadcast range is set to 50–75 m. For ERP-SCDS, copt is set
to 30 according to the simulation result to be given later. Like the reasoning and setting in
the small-area network, α1 = β1 = 0.8 and α2 = β2 = 0.2.
4.1.3 Determination of the Number of Clusters for ERP-SCDS
In the following simulations, the optimal numbers of clusters for the small-area network and
medium-area network are investigated in a sense of the longest network lifetime. Consid-
ering different numbers of clusters, we observe the network lifetime vs. number of nodes.
In Fig. 7a, b, the longest network lifetime for the small-area (medium-area) network can be
reached when the number of clusters is 17 (30). Therefore, 17 and 30 are chosen for copt in
the remaining small-area and medium-area network simulations.
123
Energy-Efficient Routing Protocol for Wireless Sensor Networks
Fig. 9 Coefficients of variation
of cluster size for different
protocols
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
300 350 400 450 500 550 600 650 700
Number of nodes
Co
ef
fic
ie
nt
 o
f v
ar
ia
tio
n
 
o
f c
lu
st
er
 s
ize
LEACH
HEED
Hausdorff
ERP-SCDS
this figure, ERP-SCDS has the lowest coefficient of variation of cluster size as compared to
LEACH, HEED, and Hausdorff because of the fact that the balanced distribution of virtual
points makes more balanced distribution of cluster members. Compared to LEACH, ERP-
SCDS has about 34% of decrease in this performance metric since advertisement messages
in LEACH are broadcasted to the entire network and the cluster head selection is done based
on the probability, giving the possibility to form unbalanced clusters. Compared to HEED,
ERP-SCDS gains 36% or so of decrease in this performance metric because there is possi-
bility in HEED to construct unbalanced clusters with a similar reasoning like that given for
the ratio of single-node clusters. As for Hausdorff, it performs worst since a sensor node in
Hausdorff is perhaps rejected by clusters around it, forcing it to declare itself as a cluster
head.
4.2.3 Clustering Energy Dissipation Per Round
Energy used for clustering can be used to illustrate the efficiency of the clustering mechanism
used in WSN routing protocols. Note that the simulation scenario used for this purpose is
the small-area network. As shown in Table 2, HEED shows the worst performance in terms
of clustering energy dissipation per round because of the re-clustering mechanism and ERP-
SCDS outperforms the other protocols because of the nature of static clustering. Compared
to HEED, about 96% lower clustering energy dissipation per round is gained by ERP-SCDS.
As mentioned previously, HEED consumes much more energy in the re-clustering process
Table 2 Clustering energy
dissipation (J) per round # Of nodes LEACH HEED Hausdorff ERP-SCDS
300 0.05 0.22 0.028 0.013
350 0.06 0.29 0.032 0.015
400 0.07 0.37 0.035 0.017
450 0.08 0.46 0.044 0.020
500 0.09 0.57 0.044 0.022
550 0.10 0.68 0.047 0.025
600 0.11 0.81 0.057 0.027
650 0.12 0.94 0.058 0.029
700 0.13 1.09 0.060 0.031
123
Energy-Efficient Routing Protocol for Wireless Sensor Networks
Fig. 10 Number of hops in
inter-cluster routing
0
500
1000
1500
2000
2500
3000
3500
4000
4500
5000
300 350 400 450 500 550 600 650 700
Number of nodes
Av
er
ag
e 
nu
m
be
r o
f h
op
s
HEED
Hausdorff
ERP-SCDS
complicated and high energy-consumed route discovery algorithm. Although the distributed
Dijkstra algorithm with estimated energy consumption and remaining energy parameters for
route discovery is employed by Hausdorff, it still consumes more energy than ERP-SCDS
whose route discovery energy dissipation per round is about 77% lower than that of Haus-
dorff. For HEED, the highest route discovery energy dissipation per round is observed among
the three protocols because it executes the route discovery mechanism for each cluster head
to the sink. Moreover, the route discovery algorithm DSR used by HEED is mainly designed
for the ad hoc network without energy and cost consideration [17].
4.2.5 Number of Hops in Inter-Cluster Routing
The number of hops in inter-cluster routing can be used to examine the efficiency of multi-hop
routing in the WSN routing protocol as well. Similarly, only HEED, Hausdorff, and ERP-
SCDS are considered because LEACH uses direct transmission for routing from cluster heads
to the sink. To get this performance metric, the medium-area network scenario is employed.
Illustrated by Fig. 10, ERP-SCDS shows the lowest number of hops in inter-cluster rout-
ing since it employs two conditions in selecting relay nodes to ensure the optimal distance
and right direction to the sink, causing the lowest number of hops needed to reach the sink.
ERP-SCDS has about 78% fewer hops than HEED since no distance consideration is taken
by HEED in the route discovery algorithm. For Hausdorff, a bit more hops are required as
compared to ERP-SCDS since Hausdorff considers power consumption in its route discovery
algorithm.
4.2.6 Network Lifetime
The network lifetime reflects the energy efficiency of a routing protocol. As one can see
from Fig. 11a, ERP-SCDS outperforms the other protocols under the small-area network
scenario. In a small-area network, multi-hop routing seems to be unnecessary since the
distance between the cluster head and the sink is shorter than the distance threshold d0.
Hence, the free space energy model is used for data transmission, leading to lower energy
dissipation and a long network lifetime. One can note that HEED and Hausdorff gain a
shorter network lifetime as compared to those of ERP-SCDS and LEACH. More specif-
ically, ERP-SCDS can outperform HEED and Hausdorff by 153 and 28%, respectively.
Compared to LEACH, ERP-SCDS still shows 16% or so of improvement in the network
lifetime since more balanced clusters are formed in ERP-SCDS. In Fig. 11b, ERP-SCDS
123
Energy-Efficient Routing Protocol for Wireless Sensor Networks
goes up, the percentages of improvement in network lifetime gained by ERP-SCDS over
LEACH, Hausdorff, and HEED fall within [12%, 165%], [84%, 406%], [124%, 479%],
respectively.
5 Conclusions
An energy-efficient routing protocol, i.e., ERP-SCDS, has been proposed in this paper
by adopting the architecture of static clusters but dynamic structures. Introducing well-
distributed virtual points to the network, evenly distributed clusters can be expected, reaching
balanced cluster sizes. Besides, a cluster head selection mechanism with energy and distance
consideration in ERP-SCDS ensures that sensor nodes with higher remaining energy and
nearer the center of the cluster are selected to prolong the network lifetime. Moreover, a
simple and energy-efficient relay node selection mechanism instead of a complicated and
energy-wasted route discovery algorithm is employed in ERP-SCDS. With these design
ideas, ERP-SCDS significantly outperforms LEACH, HEED, and Hausdorff in terms of
balanced cluster size, clustering energy dissipation (per round), route discovery energy dis-
sipation (per round), and network lifetime. With the superiority of ERP-SCDS over the other
three closest protocols in the literature, ERP-SCDS is highly recommended for use in WSNs
for sure.
In fact, considering the impact caused by sensor node mobility may form another issue.
Therefore, it serves as a possible future direction of this paper.
Acknowledgements This work was supported by the National Science Council (NSC), Taiwan under
Contracts NSC 96-2221-E-011-020-MY3 and NSC 97-2221-E-011-045-MY3.
References
1. Agrawal, D. P., & Zeng, Q. A. (2006). Introduction to wireless and mobile systems (2nd ed.). UK:
Thomson.
2. Al-Karaki, J. N., Ul-Mustafa, R., & Kamal A. E. (2004). Data aggregation in wireless sensor
networks—Exact and approximate algorithms. In Proceedings of IEEE HPSR’04, Aug 2004.
3. Alazzawi, L. K., Elkateeb, A. M., & Ramesh, A. (2008). Scalability analysis for wireless sensor
networks routing protocols. In Proceedings of IEEE AINAW’08, Apr. 2008.
4. Block, F. J., & Baum, C. W. (2002). An energy-efficient routing protocol for wireless sensor networks
with battery level uncertainty. In Proceedings of IEEE MILCOM’02, Oct 2002.
5. Boukerche, A., Martirosyan, A., & Pazzi, R. (2008). An inter-cluster communication based energy
aware and fault tolerant protocol for wireless sensor networks. ACM Transaction on Mobile Network
Application, 13(6), 614–626.
6. Chang, R. S., & Kuo, C. J. (2006). An energy efficient routing mechanism for wireless sensor
networks. In Proceedings of IEEE AINA’06, April 2006.
7. Chen, Y. P., Liestman, A. L., & Liu, J. C. (2006). A hierarchical energy-efficient framework for data
aggregation in wireless sensor networks. IEEE Transactions on Vehicular Technology, 55(3), 789–796.
8. Cui, X. Y. (2007). Research and improvement of LEACH protocol in wireless sensor networks. In
Proceedings of IEEE MAPE’07, Aug 2007.
9. Fan, Y. M., & Yu, J. J. (2007). The communication protocol for wireless sensor network about
LEACH. In Proceedings of IEEE CISW’07, Dec 2007.
10. Ghelichi, M., Jahanbakhsh, S. K., & Sanaei, E. (2008). RCCT: Robust clustering with cooperative
transmission for energy efficient wireless sensor networks. In Proceedings of IEEE ITNG’08, Feb
2008.
11. Hao, X. H., Yi, K., & Wang Y. H. (2008). Geographical-based multihop clustering algorithm for
distributed wireless sensor network. In Proceedings of IEEE WCICA’08, June 2008.
123
Energy-Efficient Routing Protocol for Wireless Sensor Networks
Author Biographies
Huei-Wen Ferng received the B.S. degree in electrical engineering
from the National Tsing Hwa University, Hsinchu, Taiwan, in 1993
and the Ph.D. degree in electrical engineering from the National
Taiwan University, Taipei, in 2000. He joined the Department of Com-
puter Science and Information Engineering, National Taiwan Univer-
sity of Science and Technology, Taipei, as an assistant professor in
August 2001. Since February 2005, he has been an associate profes-
sor. Funded by the Pan Wen-Yuan Foundation, Taiwan, he spent the
summer of 2003 visiting the Department of Electrical Engineering and
Computer Science, University of Michigan, Ann Arbor. His research
interests include wireless networks, mobile computing, high-speed net-
works, design of fair scheduling, teletraffic modeling, queuing theory,
and performance analysis. He was a recipient of the research award
for young researchers from the Pan Wen-Yuan Foundation, Taiwan, in
2003 and was a recipient of the Outstanding Young Electrical Engineer
Award from the Chinese Institute of Electrical Engineering (CIEE),
Taiwan, in 2008. He is a member of the IEEE.
Robby Tendean received his B.S. degree in information engineer-
ing from the Surabaya Institute of Technology and Applied Science,
Indonesia, in 2006 and M.S. degree in computer science and infor-
mation engineering from the National Taiwan University of Science
and Technology, Taipei, Taiwan, in 2009. His research interests include
wireless sensor networks and performance analysis.
Arief Kurniawan received his B.S. and M.S. degrees in electrical
engineering from the Institut Teknologi Sepuluh Nopember, Surabaya,
Indonesia, in 1998 and 2006, respectively. Since 2009, he has been
pursuing his Ph.D. degree in computer science and information engi-
neering at the National Taiwan University of Science and Technology,
Taipei, Taiwan, where he is currently a Ph.D. candidate. His research
interests include wireless sensor networks and protocol design.
123
表 Y04 
 
二、與會心得 
 
我們此次論文所安排的 Session 提供了豐富的論文討論，其中在我們論文所屬
的 Session 中，我與 Session Chair 討論了一些問題，也相談甚歡！ 
 
而在大會 Keynote Speech 及 Tea Break 中，我是遇到來自國內台灣科技大學資
工系之陳錫明教授、台灣科技大學電子系之陳省隆教授、台灣科技大學自控系之蔡
明忠教授等等，足顯國內研究在國際會議論文的參與相當踴躍。此外，我也新結識
幾位香港、巴基斯坦以及中國之學者或教授。因此，此次 ICMCL 國際會議場合上，
我是有機會與相關研究人員交流，增進彼此的通聯及合作的機會，這是我參與國際
會議感到收穫最大之處。 
 
三、攜回資料名稱及內容 
 
本次會議攜回 ICMCL 2011 Proceedings 光碟片一片。 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 438
Proceedings of the 2011 International Conference on Machine Learning and Cybernetics, Guilin, 10-13 July, 2011
 440
Proceedings of the 2011 International Conference on Machine Learning and Cybernetics, Guilin, 10-13 July, 2011
 442
Proceedings of the 2011 International Conference on Machine Learning and Cybernetics, Guilin, 10-13 July, 2011
97 年度專題研究計畫研究成果彙整表 
計畫主持人：馮輝文 計畫編號：97-2221-E-011-045-MY3 
計畫名稱：第四代行動通訊網路之研究 - 溢流控制與頻道重整指配機制、位置管理機制以及網路選擇
機制之設計與整合 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 3 3 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 12 12 100%  
博士生 3 3 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 6 6 100%  
研究報告/技術報告 0 0 100%  
研討會論文 1 1 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
 
