the experiments, we found that these four provided 
almost the same discrimination capability. Therefore, 
the only way to further improve the search speed is 
by using additional features, not derived based on 
the spectral characteristics, which is the basis of 
the audio signature descriptors. The features we 
propose to use are based on the time differences 
between peaks in waveforms in multiple channels 
(currently two channels). Using the additional 
features, verified by our experiments, can reduce the 
search time by 45 % while slightly improve the 
discrimination capability of the reduced-dimensional 
audio signature features. 
To find a suitable threshold value to exclude audio 
clips not contained in the database, we tried four 
different strategies. Among the strategies, one of 
them provided very good results. We were able to 
obtain a false-accept rate of 0.2 %, a false 
rejection rate of less than 0.55 %, and an accuracy 
of higher than 99.8 %. 
Overall speaking, we believe that the approaches 
developed during the conducting of the project 
provide some useful results in the area of 
constructing a music database based on MPEG-7 audio 
signature descriptors. 
 
英文關鍵詞： MPEG-7, audio signature descriptor, music content 
search, multi-channel audio 
 
Abstract 
This project investigated some problems associated with the music identification 
technique based on MPEG-7 audio signature descriptors. The music identification technique 
can be used in various applications, such as music query by recorded PCM and copyright 
control. With the MPEG-7 audio signature descriptors, a music identification technique can 
be constructed. However, there are still some problems to be solved. The first problem is to 
increase the search speed. The second one is to find a suitable threshold for correctly 
exclude any query actually not within the database.  
To address the first problem, we may adopt the well-known multi-resolution search. In 
this case, we need to figure out how to produce low-dimensional features based on the 
MPEG-7 audio signature descriptors. Among the four different approaches we tried during 
the experiments, we found that these four provided almost the same discrimination 
capability. Therefore, the only way to further improve the search speed is by using 
additional features, not derived based on the spectral characteristics, which is the basis of 
the audio signature descriptors. The features we propose to use are based on the time 
differences between peaks in waveforms in multiple channels (currently two channels). 
Using the additional features, verified by our experiments, can reduce the search time by 45 
% while slightly improve the discrimination capability of the reduced-dimensional audio 
signature features. 
To find a suitable threshold value to exclude audio clips not contained in the database, 
we tried four different strategies. Among the strategies, one of them provided very good 
results. We were able to obtain a false-accept rate of 0.2 %, a false rejection rate of less than 
0.55 %, and an accuracy of higher than 99.8 %. 
Overall speaking, we believe that the approaches developed during the conducting of 
the project provide some useful results in the area of constructing a music database based on 
MPEG-7 audio signature descriptors.  
 
Key word: MPEG-7, audio signature descriptor, music content search, multi-channel audio 
 ii
一、 前言 
過去人們搜尋資料的方式，是以文字當成輸入，在資料庫中尋找合適的資料。然
而，隨著科技的進步，多媒體資料日益增多時，利用文字當輸入的搜尋方式，顯然不
盡理想。舉例而言，早期的音樂資料庫的設計，為將音樂資料依作曲者與音樂形式等
項目分門別類，存於資料庫中，供讀者以文字的形式查詢，並取得相關資訊。當使用
者知道作曲者或音樂形式等知識時，使用資料庫固然可以找到資料，但是假如我們僅
能取得音樂的片段旋律，卻不知曲名或作曲家為何時，便無法以這些書目資料，查得
音樂本身的內容。再者，如欲判斷目前聆聽到之歌曲是否係由某明星所唱，或是沒沒
無聞者所翻唱，也無法以書目性資料庫之方式加以查詢。因此，以內涵做為查尋基礎
的多媒體資料庫，在此便有其不可取代的便利性，而這也是目前多媒體資料查詢的趨
勢。 
在以音樂內容為主的檢索方面，我們最常使用到的方式包含：（1）哼唱一段旋律
來當作檢索依據（Query by Humming）[1] 的哼唱識別；（2）利用歌曲片段為檢索依
據[2-8]的原曲識別。在 Query by Humming 的部份，使用者可自行哼唱一段旋律，利
用此旋律來當檢索依據，來搜尋資料庫中的歌曲。而在利用歌曲片斷為主之檢索方式，
主要是判別某歌曲片段（可能是 PCM 或 MP-3 格式），是否存在於資料庫中。因此，
雖然有兩個人唱相同的歌曲，仍會被判定為兩首不同的歌曲。由此可知，此檢索方法
與使用哼唱的檢索方法，大為不同。 
利用歌曲片段為檢索依據，事實上有許多應用價值。以下我們簡單列舉數種可能
之應用層面[2]： 
z 歌曲資訊詢問系統：當我們聽到某歌曲（可能是從收音機）時，想知道歌曲
的作者，甚至購買這首歌曲之電子檔時，我們也許可以利用手機將音樂片段
錄下來，並傳送到某資料提供者(Content provider)，以得到這首歌完整資訊。
此時，我們期望得到的，並非沒沒無聞者所翻唱之歌曲，而是原唱者之音樂。
因此我們不能利用 Query by Humming 之方法，而必須以音樂片段為比較基
準。 
z 廣播監督系統：唱片公司可將電台播放的音樂，利用歌曲片段為檢索依據，
來計算該電台播了幾首自己公司的音樂，並以之收費。與此概念類似的想法，
則是假設收音機以轉接卡的形式構成，連接至個人電腦中，則可藉由此資料
庫系統之協助，幫助使用者自動選取其所喜歡聆聽之音樂。當然上述之音樂，
也可以是由網路音樂電台取得。 
z 版權控制：類似前面的概念，唱片公司可將網路上流傳之音樂，利用其中片
段為檢索依據，用於發現及限制非法版權音樂的傳遞及分享。與此類似的概
念，也可應用在 peer-to-peer 的平台上。舉例來說：若干年前，美國的 Napster
公司，被（法院）要求，不可以讓使用者流通唱片公司（有版權）的音樂，
但使用者自行提供的音樂，則可以互相交換分享。類似 Napster 公司這種需
 1
 ⎪⎪
⎪
⎭
⎪⎪
⎪
⎬
⎫
⎪⎪
⎪
⎩
⎪⎪
⎪
⎨
⎧
AAAA
A
AA
AAA
24,3123,312,311,31
24,28
2,21,2
24,12,11,1
...
............
...............
.........
......
 
Frequency 
Time
圖一：  MPEG-7 聲音簽章特徵值之資料示意圖 
 
雖然，利用聲音簽章特徵值可以降低資料量；然而，比對的計算量仍然相當龐大。
假設資料庫中之歌曲數為 1000 首歌，每首歌曲長度為 30 秒，如果要判斷未知的 15
秒的音樂，是否在資料庫中，則需將未知的音樂，與資料庫中的音樂一一比較。此
外，由於未知的音樂片段，可能為於此某首歌曲的中間，因此，資料庫中 30 秒的 1488
點的（平均值）資料，必須與未知音樂的 744 點的資料，以 24 點為一步(這是特徵值
的時間解析度)，加以比較，如圖二所示。因此，每一首未知的歌曲，必須與資料庫
的一首歌，比較 32 次。故總比較之片段數為 32 × 1000 = 32,000 段。當資料庫中之
歌曲長度變長，或歌曲數目變多時，比較之片段數還會成比例增加。如果片段的比
較是使用距離為判斷基準，且只使用平均數特徵值，則片段與片段之比較，需要 744
次減法。因此，完整比較一段 15 秒的未知音樂，需要 744 × 32,000 =23,808,000 次
減法，由此我們可以看出其計算量仍然太大。因此，如何進一步降低其計算量，為
相當有實用價值之課題。一般來說，加快搜尋速度最基本的方法是使用
multi-resolution 的方式，利用低維度特徵值選取的若干可能之候選歌曲，再以最高維
度之特徵值判斷哪一首歌才是最有可能的結果，如此便能大幅加快搜尋速度。此外，
在低解析度搜尋資料的過程中，如能使用 k-d tree [21]的架構，便能更進一步降低搜
尋複雜度。 
 3
因此，我們考慮以國際標準為主，自行研發的特徵值為輔，建構我們的系統。 
在 MPEG-7 之音訊部份，其正式的國際標準，列在[11]，其參考程式則在[12]。有
關 MPEG-7 之一般性介紹文章，則可參考[13 -16]。針對音訊部份之介紹，則有[17]可
以參閱。因為 MPEG-7 音訊包含低階及高階特徵值，此外利用高階特徵值可以達成許
多不同之功能，故相關之論文相當多。文獻[3-5]主要是比較低階特徵之效果，至於這
些低階特徵值與音訊簽章特徵值比較，則在[6-8]。這些文獻的結論顯示，以鑑別率而
言，音訊簽章特徵值比低階特徵值鑑別率高。這也就是為何我們的研究要使用此特徵
值的部份原因。在運用高階特徵值方面，除了取得特徵值外，還可運用於音樂型態
(genre)的判別及語音識別等，參見[9, 22]。 
 在資料降維方面，我們研究了四種方法：區塊平均 (Block Average) 法[19, 20]、
主成份分析法(Principal Component Analysis) [23, 24]、獨立成份分析法(Independent 
Component Analysis)[25, 26]、以及因子分析法(Factor Analysis) [26, 27]。其中區塊平均
法係計劃主持人所提出，發表於[20]及學生李瑞育之論文中[19]。我們最初直接使用主
成份分析法時，發現效果不佳。然而經由區塊的切割，此方法之效果可大幅改進，並
呈現在陳威華的論文[24]中。獨立成份之技巧最初是使用於盲目訊源分離之用途[25]，
經計劃主持人之改變，以之運用於資料降維，並呈現於洪名人之論文中[26]。此外，
洪名人之論文也比較了運用因子分析法[27]的降維技巧之優劣。 
由於 MPEG-7 之音訊簽章特徵值係以頻譜為基礎，故有其極限。因此，計劃主持
人構思運用時域之訊號，以便得到額外的特徵值。因為目前所流通的音樂絕大多數有
兩個聲道，因此我們將這樣的概念加以運用，並由學生以實驗確認其效果，呈現於論
文中[28]。 
四、 研究方法 
針對高鑑別率的低維度特徵值之取得之問題，我們研究以下之降維方式：區塊平
均 (Block Average) 法[19, 20]、主成份分析法(Principal Component Analysis) [23, 24]、
獨立成份分析法(Independent Component Analysis) [25, 26]、以及因子分析法(Factor 
Analysis) [26, 27]。我們會針對這些方法，用無失真、低失真(192 kbps MP-3)、及高失
真(96 kbps MP-3)音樂產生降維特徵值後，以降維後之特徵值之正確性相互比較。至於
具體的降維方式，請參考[19, 24, 26]。 
針對設定適當的臨界值，以判斷歌曲是否在資料庫內的問題，我們比較四種臨界
值的設定計巧，並以資料庫內之歌曲進行模擬實驗[24]。在這四種方式中，我們使用
兩種不同的距離計算方法，以之計算第一距離(First Distance)與第二距離(Second 
Distance)；然後用兩種不同的方法，決定臨界值。在決定第一距離與第二距離的方法
一，為直接利用原始的查詢結果當作參考值，如圖三所示，稱距離計算法一。方法二
則將將原始查詢結果的最小距離與第二小到第十小距離的平均做相除當作第一距離；
將原始查詢結果的最二小距離與第三小到第十一小距離的平均做相除當作第二距離，
如圖四所示，稱距離計算法二。 
 5
z 方法一：距離計算法一 加 公式 (1) 
z 方法二：距離計算法二 加 公式 (1) 
z 方法三：距離計算法一 加 公式 (2) 
z 方法四：距離計算法二 加 公式 (2) 
這四種方法的優劣，將在下小節呈現。 
 在多聲道的音樂訊號特徵值的擷取及使用方面，我們研究下列課題：一、特徵值
擷取；二、搭配 MPEG-7 音訊簽章特徵值與多聲道特徵值之效果，以下分別簡單敘述
之，完整的計算細節及實驗數據，請參閱[28]。 
有關多聲道特徵值的擷取，其計算之流程如圖五所示。首先，立體音樂的兩個聲
道，分別進入子頻帶(subband)分析器，以取得我們所需的子頻帶。這些子頻帶取樣點
再經過包絡檢知器（envelope detector）取得包絡。有了包絡後，我們可以利用偵測包
絡的峰值，以取得峰值之時間點。最後，利用同聲道及異聲道間之峰值時間點，計算
特徵值。 
 在我們的設計中，子頻帶分析器是使用與 MP-3 相同構造的濾波器，只差沒有降
頻。在取得包絡方面，我們使用下式的計算 
[ ] [ ] [ ]( )max , 1 α=e n x n e n − ×         (3)            
公式中 e[n]表示包絡，x[n]代表子頻帶取樣點，α設定為 0.9995。然後，原計算之包絡
必須要加以平滑化，平滑化之公式如下： 
∑
=
+=
46079
0
][
46080
1][
i
inens         (4) 
Stereo 
Audio 
Data
Subband
extraction
Envelope 
Detection
Peak 
detection
Parameter 
extraction
 
圖五：多聲道特徵值的擷取示意圖，取材自[28] 
 要計算峰值必須先找出上升訊號，然後上升訊號之頂點便是峰值。我們簡單定義
 7
五、 結果與討論 
針對低維度特徵值之取得之問題，我們經由模擬，得到以下之結果[26]：在無失
真或低失真(192 kbps MP-3, stereo)條件下，區塊平均法或主成份分析法之效果較佳，
然而在高失真(96 kbps MP-3, stereo)之條件下，則獨立成份分析法及因子分析法較佳。
當我們要使用多重解析度的方式來加快搜尋速度時，我們並不要求最短距離者便是正
確歌曲；事實上只要正確得歌曲在前十或前十五名便可，其後我們可以使用高解析度
的特徵值再檢驗這些可能的候選歌曲便可。以此角度觀之，這四種方法，其實效益差
異不大。在我們後續的實驗中，我們使用主成份分析法來降低資料之維度。 
 
圖七：四種降維方法在無失真音樂之前 i 首以內之正確率，取材自[26] 
 
圖八：四種降維方法在低失真音樂(192 kbps MP-3)之前 i 首以內之正確率，取
材自[26] 
 9
表三： 方法四加上去除高頻後之正確率，取材自[24] 
 無失真 低失真 高失真 
錯誤接受 0.2 % 0.2 % 0.2 % 
錯誤拒絕 0.4 % 0.4 % 0.55 % 
正確率 99.7 % 99.7 % 99.7 % 
 
由表三可知，利用方法四，可達到相當高的鑑別率。 
 在多聲道特徵值的擷取方面，我們比較多聲道特徵值與 MPEG-7 音訊簽章特
徵值之相對效能，結論如下：對比多聲道特徵值與主成份分析法，在計算複雜度幾乎
相等的條件下，多聲道特徵值在無失真表現較佳；但在高失真條件下較差。 
因為多聲道特徵值與 MPEG-7 音訊簽章特徵值是使用不同的策略得到的，故可以
合併使用，即此二者並不一定是處於競爭的地位。當我們合併此二者後，我們可以加
快資料庫的搜尋，並可增加正確性。我們的概念是：每首歌曲都有其自己的峰值，每
首歌的峰值數目也就都不相同，所以峰值數目可以簡單的用來分類歌曲。具體來說，
當聲音簽章特徵值在搜尋比對 15 秒(嚴格來說是 14.04 秒，因為 MP-3 編碼器一開始會
產生一段靜音的關係)音樂時，會將資料庫的每首歌曲切割成 34 個段落，如歌曲有 750
首，則會有 34×750 = 25500 個段落，而搜尋歌曲會與這 25500 個段落搜尋比對，找出
其中最相似的段落。為了減少搜尋比對的段落，我們將資料庫中的 25500 段落，其所
擁有的峰值數目，加以分群，共分 33 群，每一群所擁有的片段數如下圖。 
 
圖十：不同峰值群所擁有的片段數，取材自[28] 
假設輸入片段擁有 n 個峰值，我們只需搜尋(n-3) ~ (n+3)這些峰值群便可。以效
益來說，可以加快搜尋速度約 45 %。在正確率方面，利用這樣的安排，其實可以小
幅增加正確性，如表四所示。 
 
 11
Identification of audio material using MPEG-7 low level description.” Available at  
http://ismir2001.ismir.net/pdf/allamanche.pdf . 
[4] J. Luksiak, D. Stirling, M. A. Jackson, N. Harders, ”An examination of practical 
information manipulation using the MPEG-7 low level Audio Descriptors.” Available at 
http://www.elec.uow.edu.au/staff/wysocki/WITSP_02_PDF/Lukasik.pdf 
[5] J. Lukasiak, D. Stirling, N. Harders, S. Perrow, “Performance of MPEG-7 low level 
audio descriptors with compressed data,” Proceedings of IEEE Multimedia and Expo, 
vol. 3, pp. III-237-6, July 2003. 
[6] O. Hellmuth, E. Allamance, M. Cremer, H. Grossmann, J. Herre, T. Kastner, “Using 
MPEG-7 audio fingerprinting in real-world application,” Convention Paper 5961 in 
115th AES Convention, October 2003. 
[7] H. Crysandt, “Music identification with MPEG-7,” Convention Paper 5967 in 115th AES 
Convention, October 2003. 
[8] J. Herre, O. Hellmuth, M. Cremer, ”Scalable robust audio fingerprinting using MPEG-7 
content description,” Proceedings of IEEE Workshop on Multimedia Signal Processing, 
pp. 165-168, Dec. 2002. 
[9] M. A. Casey, “MPEG-7 sound recognition tools,” IEEE Trans. Circuits and Systems for 
Video Tech, vol. 11, no. 6, pp. 737-747, June, 2001. 
[10] T. Kitahara, et al., “Musical instrument recognizer ‘Instrogram’ and its application to 
music retrieval based on instrumentation similarity,” Proc. IEEE Int’l Symposium on 
Multimedia, 2006. 
[11] ISO/IEC, Information technology – multimedia content description interface, 
Information Standard 15938, part 4, Audio, 2002. 
[12] ISO/IEC, Information technology – multimedia content description interface, 
Information Standard 15938, part 6, Reference Software, 2003. 
[13] ISO/IEC JTC1/SC29/WG11 N5525, Overview of the MPEG-7 standard (version 9), 
International Organization for Standardization, March 2003. 
[14] F. Nack, A. T. Lindsay, ”Everything you wanted to know about MPEG-7 part 1,” IEEE 
Multimedia Magazine, vol. 6, no. 3, pp.65 – 77, July-Sept. 1999.  
[15] F. Nack, A. T. Lindsay, ”Everything you wanted to know about MPEG-7 part 2,” IEEE 
Multimedia Magazine, vol. 6, no. 4, pp.64 – 73, Oct.-Dec. 1999.  
 13
 
國科會補助專題研究計畫出席國際學術會議心得報告 
                                     日期：100 年10月28日 
計畫編號 NSC 99 － 2221 － E － 027 － 097 － 
計畫名稱 利用 MPEG-7 音訊特徵值之原曲識別研究 
出國人員
姓名 尤信程 
服務機構
及職稱 台北科技大學資工系 
會議時間 
100 年 10 月 20 日
至 
100 年 10 月 22 日 
會議地點 韓國首爾 
會議名稱 
(中文) 國際電腦整合會議 
(英文) International Conference on Computer Convergence Technology 
(ICCCT 2011) 
發表題目 
(中文) 決定 MPEG-4 HE AAC 中 SBR 模組之起始頻率之方法 
(英文)  On the Determination of Start Band Frequency of Spectral Band 
Replication in MPEG-4 High Efficiency Advanced Audio Coding 
一、參加會議經過 
今年本人有幸能獲得國科會補助，參加 2011 年國際電腦整合會議(ICCCT  2011) ，
並發表論文。國際電腦整合會議今年第一次舉辦，地點在韓國首爾。由於會場的所
在地「蠶室的樂天世界旅館」，我今年七月底時曾造訪過，因此少了一分的不確定感。
這個會議雖然是第一次辦，但還是吸引了超過三百篇的投稿，最後只接受了五十篇，
錄取率只有 15 %，算是我曾投稿過的會議中錄取率最低的一次。之前我投過錄取率
只有 34%的會議，已經覺得很困難了，沒想到這次更低。 
所謂的電腦整合會議，其基本概念是希望能達成多種不同技術之匯流(convergence)，
 1
 3
而言，經由此演講，我才知道原來 forensics 也是一個研究領域，值得深入探討。 
 
大會安排的另一位 keynote speaker，是臨時代打上場的，因為原先規劃的人選，沒有
辦法來參加。話雖如此，但也不能小看演講者的功力。這位演講者 Dr. Park 是在韓國
的 Electronics and Telecommunications Research Institute 任職(類似台灣的工研院，但
似乎更研究導向一點)，曾參與多項國際標準的制定，他的題目是”Introduction of 
Korean SmartWork”。他一開始就提到全球暖化，交通工具製造汙染等問題，然後點
出減輕全球暖化的方法之一，就是 SmartWork: work anywhere, anytime, using any 
devices for higher flexibility. 他並說，這是韓國規劃的 Telework/Telecommunity 的專
案。我猜大概算是韓國的科技研發重點發展項目吧。不管這個項目的名稱，我覺得
韓國用這種類似「專案」的方式，以一些特定的願景方向來推動學術的研究，以尋
求某些領域的研究突破，是值得參考的。根據 Dr. Park 的說法，美國在 2016 年時，
將會有 43%的工作人員是用 Video conference (視訊會議)的方式上班，但是韓國在
2008 年時比率只有 0.6%。韓國政府規劃在 2015 年這個比率要提高到 30%，並且要
開設 500 個以上的 smartwork center，這是非常大的成長，難怪 ETRI 要投入相關的
研究。我最開始心想，teleconference 不是老掉牙的題目嗎，有什麼好討論的？然而，
其實不然，因為這牽涉到：e-mail, VoIP, file sharing, audio/video conference, digital 
approval, voice mail 等。此外，在視訊會議中要讓開會的人員覺得像是面對面的交談，
還需要有許多的配合，例如網路的延遲時間要短、鏡頭中眼神的接觸，超高解析度
的 3-D 視訊、浸入式音訊(immersive audio)等。最後在 cyber vs physical interaction (電
腦世界與實體世界的互動)中，需要考慮的因素包括：智慧型人機介面、手勢辨識、
 5
觀。例如，中國教授拿到三年一百萬人民幣的計畫的難度不高，韓國教授有十萬美
元級計畫者，所在多有。但台灣一般的教授，卻連一個國科會計畫都未必有把握，
有也是一年期居多，金額五十萬上下，真是差很多。 
 
在本次會議中，我也發現許多外國籍(非韓國籍)的研究生就讀韓國的研究所，我曾與
其中一位來自尼泊爾的博班生聊天，問他是否曾考慮申請台灣的研究所，他說他曾
了解過，但覺得太麻煩，就放棄了。原來韓國有約三十所學校，其研究所可以收外
籍學生，而且是用英語授課，當教授決定收這位外籍學生，並向學校呈報後，韓國
政府就會給學生獎學金(類似台灣獎學金)，因此學生有單一窗口的申請管道；不像台
灣，申請台灣獎學金是一回事，申請入學許可又是一回事，兩者時程又不一定能配
合，確實是有一點麻煩。他說，他們研究所裡面韓國學生是少數民族，令人驚訝，
韓國連學術國際化的企圖心都這麼強烈。 
 
我在首爾期間，由於大會中午就結束的關係，得以抽空觀察首爾市。整體來說，首
爾跟台北有一點像，車子很多，交通混亂，常常動不動就塞車，而且車也不太禮讓
行人，另外坐公車或捷運爭先恐後是一定要的。因為首爾市人口比台北多，感覺到
處都是人，像是週末晚上的明洞，只能用塞滿人的夜市(或是農曆新年的九份)來形
容。首爾的地鐵感覺比台北慢，有時候還要在某一些站等一兩分鐘，以之拉開與前
一班次地鐵的距離，實在有一點怪。以建築來說，首爾的高樓非常的多，在蠶室附
近多的是三四十樓的大樓，有的甚至七、八棟聚集在一起，不知道他們是否有實施
容積率。不過一般而言，這些大樓的外觀都還保持的相當的好，鮮少有任意加裝鐵
窗或將窗戶外推(二次施工)的現象，就這點而言，首爾人還是比台北人好一些。此外，
 7
灣，申請台灣獎學金是一回事，申請入學許可又是一回事，兩者時程又不一定能配
合，確實是有一點麻煩。 
 
五、攜回資料名稱及內容 
Proceeding 一本。 
 
六、其他 
無 
國科會補助計畫衍生研發成果推廣資料表
日期:2012/10/26
國科會補助計畫
計畫名稱: 利用MPEG-7音訊特徵值之原曲識別研究
計畫主持人: 尤信程
計畫編號: 99-2221-E-027-097- 學門領域: 自然語言處理與語音處理
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
期刊論文撰寫中 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
