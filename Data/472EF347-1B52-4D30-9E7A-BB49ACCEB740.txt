ii 
 
摘要 
  本計畫包含兩部分，第一部分為整合式快速編碼模式估測，第二部分為基於感知之視
訊壓縮系統，研究成果報告分成如下三個部分:  
 1. 整合式快速編碼模式估測 [P3] 
 我們探索了 H.264 模式決策階層結構，配合此階層結構提出了模式決策的方法。更
具體地說，我們提出了基於變異數的區塊大小模式決策、改良的預測模式決策，以
及利用了 R-D 特性與最佳模式關係的的禎內模式決策。實驗結果說明了我們所提出
的決策方法相較於前人之方法的改善效果。 
 2. 基於感知之視訊壓縮系統 [P2] 
我們在 R-D 優化架構中使用了結構相似性指標作為品質衡量標準，提出了一個預測
性的拉格朗日乘數決定方法來解決基於感知之 R-D 優化伴隨的雞生蛋、蛋生雞問
題。我們將所提出的基於感知之 R-D 優化架構用於 H.264 的模式決策。在同樣的感
知品質下相較於 JM 參考軟體，最多可以減少 20%的位元率。主觀的衡量進一步確
認了在同樣的位元率底下，相較於傳統的 R-D 優化架構，所提出的架構保留了更多
的影像細節和免去了區塊痕跡。 
 3. 基於結構相似性指標的人眼感知性位元率控制應用於視訊編碼 [P1] 
      我們在建構 R-D 模組時使用了結構相似性指標當作誤差衡量標準，並且針對視訊編
碼提出了一個最佳位元分配與位元率控制系統。此系統相較於 JM 參考軟體，最多
可以減少 25%的位元率。在 R-D 優化架構下，我們所提出的系統可以簡單的和基於
感知之編碼模式估測系統相結合，此時整體的系統相較於 JM 參考軟體，最多可以
減少 32%的位元率。 
   此項計畫之論文產出包括 3 篇 IEEE TCSVT 國際期刊論文[P1]-[P3]及 7 篇國際研討會論
文[P4]-[P10]。同時我們也申請了兩項專利。 
關鍵詞：H.264/AVC，禎內預測，R-D 優化，結構相似性指標，感知品質，拉格朗日乘數。 
 
Abstract 
 Our accomplishments of this project consist of three parts: 1) integrated fast mode decision, 
2) perceptual-based video coding system, and 3) SSIM-based perceptual rate control for video 
coding, summarized as follows: 
 
1. Integrated fast mode decision [P3] 
 
We explore the hierarchy of H.264 mode decision process in this project and adopt an 
approach that is in synchrony with the mode decision hierarchy. In particular, we propose 
a variance-based algorithm for block size decision, an improved filter-based algorithm for 
prediction mode decision using contextual information, and a selection algorithm for intra 
block decision that exploits the relation between the rate-distortion characteristic and the 
best coding type. Performance comparison is provided to show the improvement of the 
proposed algorithms over previous methods. 
 
2. Perceptual-based video coding system [P2] 
 
We incorporate the structural similarity index as the quality metric in the RDO framework. 
A predictive Lagrange multiplier selection method is developed to resolve the 
chicken-and-egg dilemma of perceptual-based RDO. The resulting perceptual-based RDO 
1 
INDEX 
 
PART I: INTEGRATED FAST MODE DECISION ................................................................... 3 
1  INTRODUCTION .................................................................................................................... 3 
2  INTRA PREDICTION AND MODE DECISION OF H.264 ................................................... 4 
2.1  Intra Prediction ............................................................................................................. 4 
2.2  Mode Decision ............................................................................................................. 4 
2.3  Related Work on Fast Prediction Mode Decision ........................................................ 5 
2.4  Related Work on Fast Inter/Intra Block Decision ........................................................ 6 
3  PROPOSED ALGORITHM ..................................................................................................... 6 
3.1  Variance-Based Block Size Decision ........................................................................... 6 
3.2  Improved Prediction Mode Decision ........................................................................... 8 
3.3  Two-Stage Approach to Intra-frame Coding .............................................................. 10 
3.4  Selective Intra Block Decision ................................................................................... 11 
3.5  Three-Stage Approach to Inter-frame Coding ............................................................ 12 
4  EXPERIMENTAL RESULTS ................................................................................................ 13 
4.1  Variance-Based Block Size Decision ......................................................................... 13 
4.2  Improved Prediction Mode Decision ......................................................................... 14 
4.3  Two-Stage Approach to Intra-frame Coding .............................................................. 15 
4.4  Selective Intra Block Decision ................................................................................... 16 
4.5  Three-Stage Approach to Inter-frame Coding ............................................................ 19 
5  CONCLUSION ....................................................................................................................... 19 
PART II: PERCEPTUAL-BASED VIDEO CODING SYSTEM ............................................ 20 
6  INTRODUCTION .................................................................................................................. 20 
7  PERCEPTUAL RATE-DISTORTION OPTIMIZATION ...................................................... 20 
7.1  H.264 Mode Decision ................................................................................................ 20 
7.2  Perceptual-Based RDO .............................................................................................. 21 
7.3  Predictive Lagrange Multiplier Selection Method ..................................................... 21 
7.4  Perceptual-Based RDO Framework ........................................................................... 22 
8  EXPERIMENTAL RESULTS ................................................................................................ 23 
8.1  Experimental Settings ................................................................................................ 24 
8.2  Evaluation of R-D Performance ................................................................................. 26 
8.3  Evaluation of the Estimated λ .................................................................................... 26 
8.4  Subjective Evaluation ................................................................................................. 28 
8.5  Computational Overhead ........................................................................................... 28 
9  CONCLUSION ....................................................................................................................... 28 
PART III: SSIM-BASED PERCEPTUAL RATE CONTROL FOR VIDEO CODING ....... 29 
10  INTRODUCTION .................................................................................................................. 29 
11  Structural Similarity Index and Perceptual-Based Rate-Distortion Optimization .................. 30 
11.1  Structural Similarity Index ......................................................................................... 30 
11.2  Perceptual-Based Rate-Distortion Optimization ........................................................ 31 
3 
PART I: INTEGRATED FAST MODE DECISION 
 
1 INTRODUCTION 
The H.264/ AVC video coding standard [1] achieves better performance than the previous 
video coding standards and has become a key technology for multimedia communications and 
consumer electronics. The high performance of this standard is achieved by the adoption of 
advanced coding tools such as spatial-domain intra prediction, variable block-size motion 
estimation, multiple reference frames, and rate-distortion (R-D) optimization [2], [3]. In 
particular, the H.264 High Profile is further developed for applications such as professional film 
production, digital video broadcasting and high-definition TV and video disc [4]. One notable 
difference of this new profile is that it adopts the 8×8 intra prediction as a new coding tool to 
improve the R-D performance. However, like the other advanced coding tools adopted earlier, it 
also introduces significant computational overhead to the encoder. 
Specifically, since a variety of coding modes are supported, the mode decision of H.264 is 
more complicated and time-consuming than that of previous coding standards. In fact, it is the 
most computationally intensive component of an H.264 encoder, more so for the High Profile. 
Therefore, fast algorithms for mode decision are needed. 
As shown in Fig. 1, the mode decision process of an H.264 compliant encoder entails a 
three-stage hierarchy of operations: inter/intra block decision, block size decision, and prediction 
mode decision. There are two important implications of this hierarchical structure of mode 
decision.  First, because of the hierarchy, the quality of a decision in the early stage of mode 
decision process impacts the overall R-D performance of the encoder more than that of a decision 
in a later stage. Therefore, it is important to ensure the correctness of decisions particularly at the 
upper layer of the hierarchy.  Second, because the mode decision process can be terminated 
based on the characteristic of the content and because the effect of a decision propagates down 
the hierarchy, it is important that the early termination is executed accurately and as early as 
possible in the mode decision hierarchy. 
Most fast mode decision algorithms developed so far, however, only deal with a single stage of 
the mode decision hierarchy [5]-[19] and fail to achieve the best possible complexity reduction. 
To address this issue, we adopt an approach that is in line with the multi-stage structure of H.264 
mode decision. In particular, we focus on the left branch of the mode decision hierarchy shown in 
Fig. 1, namely the intra/inter block decision of inter frames, the block size decision of intra 
blocks, and the prediction mode decision of intra blocks. The right branch of the hierarchy, which 
is for inter blocks and independent of the left branch, is discussed in a separate paper.  
The techniques employed in our algorithms are inspired by several factual observations. For 
block size decision, it is known that the block size of the best coding mode is highly correlated 
with texture complexity [19]. In addition, the variance of an MB in the spatial domain, equivalent 
 
Fig. 1 Mode decision hierarchy of an H.264 compliant encoder. 
5 
For intra frames, the best prediction mode of a block is defined as the mode that, among all 
prediction modes of the block, gives rise to the minimum R-D cost. The R-D cost of an MB mode 
is the sum of the minimum R-D cost of each individual block.  
 
For inter frames, besides the three intra MB modes, H.264 defines seven additional MB modes 
corresponding to different partition sizes for motion estimation [1] as inter MB modes.  Like the 
intra MB mode, the R-D cost of an inter MB mode is the sum of the R-D cost of each individual 
block, and the best MB mode is the one that, among all possible inter and intra MB modes, gives 
rise to the minimum R-D cost.  
The R-D cost, denoted by Jmode, of an MB mode is defined as follows: 
( , , ) ( ) ( , )modeJ mode QP SSD mode R mode QP= +λ λ ,         (1) 
where mode ∈  {InterModes, I4MB, I8MB, I16MB}, QP is the quantization parameter, λ is a 
Lagrange multiplier, SSD(‧) denotes the sum of squared difference, and R(‧) denotes the total 
bits used for coding the selected mode, the macroblock header, and the residual information. 
2.3 Related Work on Fast Prediction Mode Decision 
Many algorithms for fast prediction mode decision have been reported in the literature [5]-[12] 
and can be classified into two categories: non-filter-based and filter-based. 
Non-filter-based algorithms attempt to reduce the computation of the R-D cost and improve the 
R-D performance by modifying the matching criterion.  Most such algorithms are developed to 
deal with the low complexity mode, for which the RDO is turned off.  For example, Huang et al. 
proposed a context-based algorithm that incorporates a sub-sampled matching criterion to remove 
unlikely candidate modes [5], and Tseng et al. developed an enhanced rate-distortion function 
that uses the sum of absolute integer-transformed differences as distortion and a rate predictor to 
obtain the rate [7]. Our primary concern in this report, however, is the high complexity mode. 
On the other hand, because the best prediction mode of a block is highly correlated with its 
dominant edge direction [5]-[12], filter-based algorithms determine the dominant edge direction 
of each block and then select the associated prediction mode, the neighboring two prediction 
modes, and the DC mode as candidate modes. These algorithms always include the DC mode as a 
candidate mode to maintain its performance when the block to be coded contains homogeneous 
texture. Algorithms of this category exploit various edge detection methods. Pan et al. [6] applied 
Sobel filter to obtain the local edge information of each block and then constructed an edge 
direction histogram to determine the dominant edge direction. Wang et al. [8] incorporated 
MPEG-7 edge descriptors [20] into a sub-sample technique to find the dominant edge. Tsai et al. 
[9] calculated the gradient of four selected pixels of a block to extract the orientation of the block. 
An improved version is described in [11]. Li et al. [10] detected the edge by using the difference 
property of non-normalized Haar transform (NHT). Bharanitharan et al. [12] proposed a mode 
 
Fig. 3. Percentage of the best intra MB mode. 
7 
 
[ ]
2
15 15 15 15
2
0 0 0 0
1variance ( , ) ( , )
256i j i j
Y i j Y i j
= = = =
⎡ ⎤= − ⎢ ⎥⎣ ⎦∑∑ ∑∑ ,           (2) 
where ( , )Y i j  is the luminance value of the pixel at ( , )i j . The texture complexity of an MB is 
classified according to its variance as follows: 
1high,     if variance > complexity =                                                (3)
low,      otherwise.
T⎧⎨⎩
 
where T1 is a threshold, which is set to 92735 in this work. The determination of this value can be 
found in [19]. 
The percentage of the best intra MB mode for various sequences is shown in Fig. 3. We can see 
the tendency that I4MB is the majority mode when the image resolution is low. As the resolution 
increases (so does the homogeneity of the texture of an MB), I8MB becomes the majority mode. 
This empirical finding is critical to the design of fast mode decision. More specifically, it is 
important to decide when we can skip the computationally expensive I4MB mode during the 
coding of high-resolution sequences. We have also found that the inclusion of the I8MB as a 
candidate mode yields less R-D performance degradation since the inclusion of the I8MB as an 
 
Fig. 7. Five filters of various directions. 
       
(a)       (b)      (c) 
Fig. 6. Formation of the subsampled block for a block of (a) I4MB, (b) I8MB, and (c) I16MB. 
 
Fig. 5. Hit rate of the variance-based block size decision method using various thresholds. 
9 
directions are considered, and the mode along the detected edge and the DC mode are considered 
the candidate modes. The prediction mode decision for 8×8 luma block is not considered in [8]. 
However, the prediction accuracy of the above algorithm is hampered by the limitation that the 
algorithm only considers the edge information of the current block and does not take the 
correlation between blocks into account. We address this issue by adding the most probable mode 
(MPM) to the baseline algorithm. The MPM, which takes advantage of the spatial correlation of 
the prediction modes between the neighboring blocks and the current block for coding, is defined 
as the prediction mode of the left or the upper neighbor, whichever has the smaller prediction 
mode number. If either of these two neighbors is unavailable, a default DC mode is considered. 
Since only one bit is needed to signal the MPM, the other eight modes can be effectively coded 
with three bits [1], keeping the total number of bits required for representing the prediction mode 
of the current block to four. Fig. 8 shows a comparison of the prediction mode selection between 
the MPM mode and the DC mode by exhaustive search. The result clearly indicates that the 
MPM is selected as the best mode much more frequently than the DC mode. Thus, including the 
MPM rather than the DC mode as one of the candidate modes is expected to increase the 
prediction accuracy of the fast algorithm. 
The block diagram of the improved algorithm for prediction mode decision is shown in Fig. 9. 
For 4×4 luma block, three intra prediction modes along the direction of the detected edge and its 
adjacent directions are chosen as candidate modes. Since the MPM is more likely than the DC 
mode to be the best mode, we always include the MPM as the candidate mode. If the MPM is the 
same as any of the other three candidate modes, we replace it by the DC mode to increase the 
pool of candidate modes for the current block without increasing the computational complexity 
since still four prediction modes are examined (see Fig. 10). For 8×8 luma block, the candidate 
mode selection scheme is the same as that for 4×4 luma block. An input 8×8 luma block is first 
transformed to a 2×2 subsampled block. The edge is then determined by processing the 
subsampled block with the aforementioned five filters. The prediction modes whose predicting 
direction is along and adjacent to the direction of the detected edge are chosen as the candidate 
modes. For 16×16 luma block, since the MPM is not defined for such block size, the prediction 
mode decision remains unchanged. 
 
 
Fig. 9. Prediction mode decision. 
 
Fig. 10.  Candidate prediction modes corresponding to various edge directions. 
11 
 
3.4 Selective Intra Block Decision 
Intra block decision, which is performed for inter frames, occupies a considerable percentage of 
the total computations of inter-frame coding. Fig. 12 shows the percentage of computation time 
of the three intra MB modes for four test sequences. It can be seen that I16MB takes much less 
computation time than the other modes. We exploit this characteristic in our algorithm. 
In addition, it has been found that the R-D cost of I16MB is close to that of I4MB [13].  
Therefore, it is less probable for I4MB to be the best mode if the R-D cost of I16MB is much 
larger than that of the best inter MB mode.  We also exploit this characteristic to improve the 
computational efficiency of intra block decision.  
Let us define the scaled R-D cost modeJˆ  as 
ˆ mode
mode
JJ λ= .         (4) 
The advantage of using the scaled R-D cost is that it lies in the same range under different QPs, 
which makes the analysis simpler and, most importantly, a universal threshold can be used. Fig. 
13 shows the histogram of the scaled R-D cost differences between I16MB and the inter MB 
mode for the Foreman sequence.  The histograms of other sequences are similar.  As we can 
see, the histograms are centered at a lower R-D cost (that is, biased toward left) for inter coded 
blocks and at a relatively higher R-D cost for intra coded blocks.  Since an MB is very likely to 
be inter-coded when the R-D cost of the best inter mode is much lower than that of the I16MB, 
the histogram of the R-D cost difference for inter-coded MB is biased toward left. On the other 
hand, the intra modes would be selected as the best mode when the R-D cost of the best inter 
mode is higher than or close to the R-D cost of I16MB. 
Therefore, we can predict that an MB is less probable to be intra coded if the R-D cost 
difference is small. Denoting the scaled R-D cost differences between I16MB and the inter MB 
mode by ˆdJ , based on the above observation, we skip both I4MB and I8MB if ˆdJ  is small. 
 
(a)  
 
 
(b) 
 
Fig. 13. Histogram of the normalized R-D cost differences between the best inter mode and the I16MB mode 
of Foreman (QCIF) for (a) inter coded MBs and (b) intra coded MBs. 
13 
algorithm because of the superior performance of our block size decision and prediction mode 
decision algorithms applied in the later stage of the mode decision process.  
4 EXPERIMENTAL RESULTS 
In this section, we evaluate the performance of the algorithms in terms of bit-rate increase, 
PSNR drop [23], and complexity reduction. All algorithms to be compared are implemented 
using the JM reference software version 13.2 [24], and the performance gain or loss is measured 
with respect to the JM reference software. The conditions of the experiments are as follows: 
• Run on a PC with Intel 2.13 GHz Pentium processor and 1.99 GB RAM. 
• Set the QP value to 16, 20, 24, and 28. 
• Enable the R-D optimization. 
• Choose CABAC as the entropy coding method. 
• Set the intra period to 1 for intra-frame coding and 15 for inter-frame coding.  
The experimental results are discussed separately for each proposed algorithm. 
 
4.1 Variance-Based Block Size Decision 
As shown in Table II, the variance-based block size decision achieves on the average 30.5% 
TABLE II 
PERFORMANCE COMPARISON FOR INTRA-FRAME CODING 
 
Sequence     Variance-Based Block Size 
Decision 
Prediction Mode Decision [8] Improved Prediction Mode 
Decision 
Two-Stage Approach 
PSNR 
(dB) 
BR 
(%) 
Time 
(%) 
PSNR 
(dB) 
BR 
(%) 
Time 
(%) 
PSNR 
(dB) 
BR 
(%) 
Time 
(%) 
PSNR 
(dB) 
BR 
(%) 
Time 
(%) 
Container(QCIF) -0.099 0.49 -23.7 -0.186 0.95 -31.0 -0.092 0.47 -31.0 -0.191 0.97 -48.5 
Foreman(QCIF) -0.051 0.27 -11.5 -0.181 1.01 -28.6 -0.118 0.65 -29.1 -0.161 0.90 -36.7 
Hall(CIF) -0.054 0.43 -24.2 -0.203 1.60 -32.0 -0.091 0.70 -32.4 -0.145 1.12 -52.6 
Mobile(CIF) -0.019 0.07 -7.41 -0.174 0.64 -25.4 -0.136 0.50 -25.9 -0.154 0.57 -35.5 
Container (CIF) -0.045 0.26 -25.4 -0.150 0.83 -29.1 -0.075 0.41 -29.1 -0.123 0.68 -50.5 
Crew(D1) -0.039 0.30 -41.9 -0.109 0.89 -31.0 -0.064 0.51 -31.5 -0.103 0.83 -59.5 
Football(D1) -0.016 0.15 -42.5 -0.131 1.31 -35.9 -0.057 0.56 -36.7 -0.073 0.72 -62.0 
Mobile (D1) -0.054 0.21 -9.9 -0.153 0.62 -26.5 -0.123 0.50 -26.5 -0.172 0.70 -35.5 
Crew(720p) -0.013 0.10 -48.2 -0.089 0.87 -30.1 -0.055 0.52 -30.6 -0.062 0.59 -62.1 
Parkrun(720p) -0.023 0.08 -17.4 -0.154 0.65 -28.1 -0.129 0.54 -28.1 -0.147 0.61 -40.8 
Shields(720p) -0.005 0.28 -23.1 -0.121 0.75 -28.6 -0.094 0.57 -29.1 -0.137 0.83 -44.8 
Pedastrian(1080) -0.042 0.48 -48.5 -0.117 1.47 -33.8 -0.046 0.58 -34.6 -0.089 1.10 -64.7 
Station2(1080) -0.029 0.27 -53.5 -0.113 1.24 -30.6 -0.070 0.78 -31.0 -0.097 1.04 -65.6 
Sunflower(1080) -0.008 0.09 -49.8 -0.088 1.34 -36.7 -0.066 1.01 -37.5 -0.077 1.16 -66.0 
average -0.035 0.25 -30.5 -0.141 1.01 -30.5 -0.087 0.59 -30.9 -0.123 0.84 -51.8 
 
15 
time reduction for these algorithms is about 44%. In Table II, the time reduction of Wang’s and 
our algorithms is 30% because these two algorithms still have to check all modes when necessary, 
as described in Section III.B.  
In addition, we compare our algorithm against another two filter-based prediction mode 
decision algorithms [9], [12]. As shown in Table III, our algorithm achieves better R-D 
performance at the same time reduction. It can be seen that our method can be incorporated into 
existing filter-based fast algorithms to improve the R-D performance.  
4.3 Two-Stage Approach to Intra-frame Coding 
The last column of Table II shows the performance of the two-stage approach described in 
Section III.C. We can see that up to 66.0% complexity reduction over the JM reference software 
is achieved, and both the PSNR drop and the bit-rate increase are very small. For easy 
TABLE IV 
PERFORMANCE COMPARISON FOR INTRA BLOCK DECISION ALGORITHM 
Sequence Method IPPP IBBP 
BDPSNR 
(dB) 
BDBR 
(%) 
Time 
(%) 
BDPSNR 
(dB) 
BDBR 
(%) 
Time 
(%) 
Coastguard 
(QCIF) 
Choi et al. [13] 0.000 0.00 -27.5 -0.005 0.02 -21.0 
Proposed 0.000 0.00 -47.1 -0.003 0.02 -33.3 
Foreman 
(QCIF) 
Choi et al. [13] -0.010 0.10 -33.3 -0.030 0.26 -25.8 
Proposed -0.013 0.11 -46.0 -0.005 0.04 -33.7 
Mobile 
(CIF) 
Choi et al. [13] -0.008 0.04 -32.9 -0.006 0.04 -24.6 
Proposed -0.001 0.00 -48.7 -0.001 0.00 -37.5 
Stefan 
(CIF) 
Choi et al. [13] -0.042 0.32 -38.0 -0.042 0.30 -26.0 
Proposed 0.000 0.00 -41.0 -0.012 0.09 -29.3 
Tempete 
(CIF) 
Choi et al. [13] -0.016 0.10 -33.9 -0.007 0.05 -24.5 
Proposed -0.002 0.02 -45.7 -0.001 0.01 -34.8 
Football 
(D1) 
Choi et al. [13] -0.204 2.19 -23.7 -0.249 2.64 -14.2 
Proposed -0.026 0.29 -9.1 -0.013 0.14 -5.2 
Mobile 
(D1) 
Choi et al. [13] -0.025 0.14 -27.1 -0.015 0.09 -19.4 
Proposed 0.000 0.00 -41.8 -0.002 0.01 -32.9 
average 
Choi et al. [13] -0.044 0.41 -30.9 -0.051 0.41 -22.2 
Proposed -0.007 0.06 -39.9 -0.005 0.04 -29.5 
 
TABLE III 
PERFORMANCE IMPROVEMENT BY INCORPORATING THE MPM INTO PREDICTION MODE DECISION 
Prediction 
Mode 
Decision 
Original Incorporating the MPM 
PSNR 
(dB) 
BR 
(%) 
Time 
(%) 
PSNR 
(dB) 
BR 
(%) 
Time 
(%) 
[9] -0.102 0.82 -32.68 -0.084 0.66 -32.69 
[12] -0.505 3.71 -28.40 -0.279 1.97 -28.24 
 
17 
 
We first compare our method with the method described in [13], which is a state-of-the-art 
approach to intra block decision recommended by JVT.  Since the competing method does not 
support it, we exclude the I8MB mode in this experiment. However, both methods are 
implemented in compliance with the Main Profile. The performance comparison is given in 
TABLE IV. It can be seen that our algorithm has much better and more consistent R-D 
performance than the competing method. Furthermore, our algorithm achieves higher time saving 
since it is able to accurately skip the intra modes. Note that both algorithms are less efficient for 
the IBBP coding structure than for the IPPP coding structure, because the former demands more 
ME and introduces more computational overhead.  
Table V shows the percentage of intra coded MBs.  We can see that the competing method 
always generates fewer intra coded MBs and hence a larger R-D loss for sequences that have 
more intra coded MBs (see again the result for the Football sequence in TABLE IV as an 
example of this behavior).  On the contrary, the percentage of intra coded MBs obtained by our 
algorithm is very close to the ground truth generated by the JM reference software. This shows 
that our algorithm has an edge on prediction accuracy over the competing method.  
Our algorithm is also tested for the High Profile. Since most previous methods do not support 
I8MB, we can only measure the performance gain against the JM reference software. The results 
for sequences of various resolutions are tabulated in the “Selective Intra Block Decision” column 
of Table VI. It can be seen that the average time saving over the JM reference software is 33.4%, 
with almost zero R-D performance loss. The great time saving verifies that it is indeed 
computationally advantageous in our approach to use I16MB as an anchor for the intra/inter 
 
(a) 
 
 
(b) 
 
Fig. 16. Complexity reduction of (a) low-resolution sequences and (b) high-resolution sequences. 
19 
competing method (Choi et al. [13]). It can be seen that our algorithm has much less 
computational overhead than the competing method. 
4.5 Three-Stage Approach to Inter-frame Coding 
The performance comparison between the intra block decision algorithm described in Section 
III.D and the three-stage approach described in Section III.E for inter-frame coding is given in 
Table VI.  The purpose of this comparison is to highlight the advantage of the multi-stage 
approach over the single-stage approach. The results are also shown in the form of bar chart in 
Fig. 16 for easy comparison.  It can be seen that both algorithms have similar complexity 
reduction for low-resolution sequences, indicating that intra block decision is the dominant 
operation of fast mode decision for low-resolution sequences. For high-resolution sequences, 
however, the spatial correlation is relatively stronger, resulting in a much higher percentage of 
intra blocks.  Hence the complexity reduction of the single-stage approach to intra block 
decision is limited.  On the other hand, the three-stage approach is able to achieve computational 
efficiency as high as possible, especially for high-resolution sequences.  The R-D performance 
comparison is shown in Fig. 17. The results show that the R-D performance degradation of the 
three-stage approach is negligible. Overall, the three-stage approach is clearly better than the 
single-stage approach. The number of operations per MB for each stage is also provided in Table  
5 CONCLUSION 
The mode decision in H.264 encoder is a computationally expensive operation. In the report, 
we have described how to achieve fast decision of block size, prediction mode, and intra block 
for H.264 intra prediction.  The proposed algorithms provide significant improvement of 
computational efficiency over previous methods without noticeable R-D performance loss. The 
efficiency gain of these algorithms is attributed to the fact that the design of these algorithms is 
fully in line with the hierarchical structure of the mode decision process. Under this design 
principle, these algorithms can work independently or together.  Working together, they 
constitute an integral approach to intra-frame coding and inter-frame coding, for which high 
accuracy of mode prediction is achieved without complex operations. 
TABLE VII 
COMPARISON OF THE NUMBER OF OPERATIONS PER MB  
 Add/Sub Comparison Multiplication Shift 
Variance-Based 511 1 257 2 
Wang et al. [8] 483 0 84 168 
Improved Pred. 483 1 84 168 
Selective Intra 1 1 0 0 
Choi et al. [13] 64 1 0 0 
 
21 
 
 
( 12)/32 QPλ c −= × ,            (6) 
where c is a constant equal to 0.85 [29]. However, if the high-rate assumption is not true, this 
method may fail. In addition, this method is not content-adaptive because λ is a function of QP 
only.  
7.2 Perceptual-Based RDO 
In the perceptual-based RDO framework, we use the SSIM index instead of the traditional SSD 
to measure distortion between reconstructed image and original image. The new distortion metric 
DSSIM is defined by 
( , , | ) 1 ( , ).SSIMD s c mode QP SSIM s c= −                 (7) 
Then the cost function in the RDO framework becomes 
( , , | ) ( , , | ) ( , , | ).SSIM SSIMJ s c mode QP D s c mode QP λ R s c mode QP= +    (8) 
This new cost function is adopted in the MB and the prediction mode decisions. However, 
because the SSIM index cannot be related to the quantization parameter in a closed form, the R-D 
model cannot be determined analytically. A new method for solving the Lagrange multiplier λSSIM 
is needed.  
7.3 Predictive Lagrange Multiplier Selection Method 
Mai et al. used the SSIM index as distortion metric for motion estimation and intra mode 
decision [28], [29]. However, the relation between the Lagrange multiplier λSSIM and the 
quantization parameter QP is determined empirically as in [35]. Because λSSIM is a function of QP 
independent of the video content, this method is not content-adaptive. 
For simplicity, let D and λ denote DSSIM and λSSIM, respectively, from now on unless it is 
otherwise stated. The predictive Lagrange multiplier selection method we have developed is 
motivated by three observations. The first observation is made on the R-D performance 
improvement. We apply the perceptual-based RDO described in Section II.B to the mode decision 
process of H.264. The Lagrange multiplier λ is exhaustively searched to find the one that leads to 
the best R-D performance. The results show that the perceptual-based RDO performs 
significantly better than the traditional MSE-based RDO. The second observation is related to the 
characteristics of R-D curve. In [36], a linear function is used to describe the relation between the 
rate and the SSIM index. However, we find that the relation can be better described by a power 
function of the following form: 
 
Fig. 18. Illustration of the slope of the tangent line and its approximation. 
23 
However, if the R-D characteristics of the current frame and its reference key frame are very 
different, poor approximation may result. To address this issue, we can apply scene change 
detection to the video sequence because an abrupt change of R-D characteristics between frames 
is often due to scene change or high motion in the sequence.  
However, the complexity of scene change detection [38]-[40] is relatively high. In the proposed 
framework, we provide a simple but efficient method to detect the abrupt change in R-D 
characteristics. Let λt be the weighted average λ of the first five frames after the key frame. If the 
relative change of λ to λt is larger than the threshold T, we set this frame as key frame. Here, we 
leave T as a user-defined parameter. 
8 EXPERIMENTAL RESULTS 
In this section, the experimental results of the proposed method are described. We evaluate the 
performance of the proposed method in four aspects: bit-rate reduction over the JM reference 
software, quality of the estimated perceptual-based Lagrange multiplier, subjective improvement, 
and the complexity comparison between these two frameworks. 
 
(a) 
 
(b) 
 
(c) 
 
Fig. 20. R-D curves of (a) Paris, (b) Container, (c) Weather sequences when T=0.5 under setting A. 
25 
 
 
 
 
TABLE IX 
BIT-RATE REDUCTION OF THE PROPOSED FRAMEWORK  
UNDER SETTING B 
Sequence (CIF)  
Bit-rate reduction (%) 
QP=16−28 QP=24−36 
Stefan 14.60 11.13 
Flower 12.45 17.18 
Akiyo 18.19 12.95 
Mobile 6.15 14.76 
Weather 13.57 13.06 
Bridge-Close 16.26 17.99 
Bus 6.49 12.28 
Coastguard 1.23 4.46 
Container 21.19 28.62 
Hall_Monitor 24.81 27.69 
MadCyclistL 1.91 8.95 
Mother_Daughter 2.91 6.00 
Paris 10.55 12.65 
Silent 5.06 6.13 
Table 8.54 6.38 
Tempete 4.34 11.23 
average  10.52 13.22 
 
TABLE VIII 
BIT-RATE REDUCTION OF THE PROPOSED FRAMEWORK  
UNDER SETTING A 
Sequence Bit-rate Reduction (%) QP=16−28 QP=24−36 
Stefan (CIF) 12.93 10.90 
Flower (CIF) 11.85 15.01 
Akiyo (CIF) 20.33 14.74 
Mobile (CIF) 4.10 14.86 
Weather (CIF) 15.90 13.21 
Bridge-Close (CIF) 17.40 19.59 
Bus (CIF) 6.86 11.21 
Coastguard (CIF) 2.26 5.49 
Container (CIF) 23.59 29.51 
Hall_Monitor (CIF) 26.46 21.12 
MadCyclistL (CIF) 1.00 7.08 
Mother_Daughter (CIF) 2.72 2.94 
Paris (CIF) 11.30 13.13 
Silent (CIF) 4.79 5.52 
Table (CIF) 7.48 5.89 
Tempete (CIF) 4.21 9.88 
Bus (D1) 3.21 11.12 
Character (D1) 3.82 2.84 
Mobile (D1) 6.20 16.60 
720p_Mobcal_450 (720) 13.91 13.38 
720p_Shields_450 (720) 11.50 7.01 
Jets (720) 12.48 3.38 
Panslow (720) 16.92 16.41 
Spincalendar (720) 12.82 12.76 
average  10.59 11.82 
 
27 
proposed method is more adaptive to content than the existing methods that determine λ 
according to QP only.  
A closer look at Fig. 22 reveals that at the same QP, a smaller λ is selected for video sequences 
that require more bits to encode since the quality of these sequences can be improved with 
relatively small bit-rate increase. A better R-D performance is thus resulted. On the other hand, a 
larger λ is chosen for video sequences that are easy to encode so that a higher percentage of bits 
can be saved at the cost of a relatively small increase of distortion. A similar conclusion was also 
made in [29]. Note that the diversity of the estimated λs for various sequences becomes less and 
less apparent as the QP decreases. This is consistent with the prior finding that the Lagrange 
multiplier can be a function of QP under the high rate assumption [29]. 
Fig. 23 shows the estimated Lagrange multiplier λ for three different sequences encoding under 
Setting A. It can be seen that the estimated λ varies within a small range. The stability of the 
estimate is attributed to the effectiveness of the key frame determination component (shaded 
region in Fig. 19) of the coding system. 
 
 
 
(a)      (b) 
 
Fig. 25. The cropped image of the 36th frame of the Hall_monitor sequence  encoded under setting A with
QP=36 and T=0.5 by using (a) the MSE-based RDO framework and (b) the perceptual-based RDO framework.
 
 
(a)      (b) 
 
Fig. 24. The cropped image of the 41st frame of Bus sequence encoded under setting A with QP=36 and 
T=0.5 by using (a) the MSE-based RDO framework and (b) the perceptual-based RDO framework. 
29 
PART III: SSIM-BASED PERCEPTUAL RATE CONTROL FOR VIDEO 
CODING 
10 INTRODUCTION 
Rate control is indispensable for practical applications and has been an active research topic in 
video coding. A review of recent advances of rate control for video coding based on MPEG-2 
[46], H.263 [47], MPEG-4 [48], or H.264 [49] algorithm can be found in [50]. 
The goal of rate control is to regulate the encoded bit stream such that the best video quality is 
achieved without violating the constraints imposed by the encoder/decoder buffer size and the 
available channel bandwidth. Among various coding parameters, the quantization parameter (QP) 
is related to the quality of the compressed video. Therefore, the main task of rate control is to 
determine the value of QP according to the channel and buffer conditions. Given a target bit rate, 
a rate-quantization (R-Q) model that characterizes the relationship between rate and QP [51]-[59] 
is used to determine the QP value of, for example, each block of the video data. Furthermore, to 
achieve the optimal rate-distortion tradeoff, an additional distortion-quantization (D-Q) model, 
which describes the relationship between distortion and QP, is used to optimally divide the bit 
budget between the image blocks. The rate-distortion optimized rate control is achieved by jointly 
using the R-Q and D-Q models [56]-[59]. 
While the rate-distortion optimization (RDO) framework employed in H.264 allows a better 
tradeoff between rate and distortion, it complicates the rate control mechanism. The RDO cannot 
proceed without the QP; the R-Q and D-Q models cannot work without the coding statistics, such 
as the mean absolution difference (MAD) between the original and the predicted signal, that can 
only be obtained from the RDO. Therefore, a causality dilemma is resulted [60]. To resolve the 
dilemma, a linear prediction model for the MAD was employed [60]. Based on the model, a rate 
control scheme was developed and adopted in the JM reference software of H.264 [61]. The 
scheme is further improved by using enhanced rate and distortion models [53]-[57], R-D 
optimized bit allocation [56]-[58], or context-adaptive model parameter prediction [62]. 
However, these schemes use conventional objective distortion metrics such as mean squared error 
(MSE) and the like that are not well correlated with human perception. Since the video quality is 
ultimately judged by the human eye, it is desirable to incorporate the characteristics of human 
visual system (HVS) into rate control. 
A number of approaches to perceptual-based bit allocation and rate control have been reported 
in the literature. The basic idea of them is to determine the region of interest (ROI) based on the 
characteristics of HVS and allocate bits accordingly. For conversational video communication, 
some assumptions of the video content can be made. For example, human face occupies a large 
portion of a video frame, the central region of a video frame is more important than the marginal 
region, and background is static [63]-[65]. Yang et al. [63] considered luminance adaptation, 
texture masking, and skin tone to determine the perceptual sensitivity weight for each macroblock 
(MB) of a video frame. Liu et al. [64] used frame difference and skin-tone information to 
determine the weight for each MB. The resulting weights are used to guide the determination of 
QP for each MB. In addition to the ones specifically designed for conversational video 
communication, bit allocation approaches for a broader variety of videos have been developed 
[66]-[73]. Tang et al. [66] proposed a visual distortion sensitivity model to indicate the regions 
where the distortions are less perceptible. Bit saving is made by allocating fewer bits to such 
regions. The work can be extended to include more spatial and temporal cues [67]. However, due 
to the lack of a unified model, the QP is heuristically determined without rate-distortion 
optimization. 
The foveation characteristic of HVS has also been exploited for video compression. The fovea 
is the part of the retina that has the highest density of photoreceptors. The density of 
photoreceptors away from the fovea rapidly decreases. As a result, the visual acuity is 
space-variant. The visual quality can be improved by allocating more bits to the possible fixation 
points in the scene [71]-[73]. Lee et al. [72] proposed a visual quality metric called foveal 
31 
cross covariance between x and y, and C1, C2, and C3 are three constants introduced to avoid 
unstable behavior in the regions of low luminance or low contrast [26]. The block size is typically 
8×8, and the final SSIM value is the averaged SSIM of all blocks. 
The more similar two images are, the higher the SSIM index is. The maximum SSIM index is 
1, which occurs when the two images are identical. The SSIM index marks itself a 
perceptual-based image quality assessment metric because it takes into account properties of 
HVS such as luminance adaptation and textural masking [25]. 
11.2 Perceptual-Based Rate-Distortion Optimization 
An H.264 video encoder employs the RDO framework in the mode decision process to strike a 
tradeoff between rate R and distortion D. The best coding mode is the one that minimizes the 
Lagrangian cost function J defined by 
J D λR= + ,         (15) 
where λ is the so-called Lagrange multiplier, which controls the tradeoff between rate and 
distortion. The distortion metric used in the RDO process has a profound impact on video coding. 
The SSIM index is incorporated into the RDO framework as a quality metric [37], where the 
distortion metric DSSIM is defined by 
1 .SSIMD SSIM= −                (16) 
The corresponding Lagrange multiplier is determined by using the R-DSSIM curve obtained 
from the MSE-based RDO and represented by a power function 
( ) ,SSIMD R R
βα ′′=                  (17) 
where α′ and β′ are content-dependent parameters [37]. With α′, β′, and the R-D point p of the 
previous encoded frame as a prediction of the R-D point of the current frame, the Lagrange 
multiplier is determined by 
v h
SSIM
v h
D D
R R
λ −= − − ,              (18) 
where (Rh, Dh) and (Rv, Dv) are two R-D points projected from p horizontally and vertically, 
respectively, to the R-D curve defined by (17). 
12 RATE-DISTORTION MODELING AND OPTIMUM BIT ALLOCATION USING 
SSIM AS QUALITY METRIC 
In this section, we describe the proposed R-D model, which measures the distortion by the 
SSIM index, and the optimum bit allocation mechanism, which is the key component of our rate 
control scheme. 
12.1 Rate-Distortion Modeling Using SSIM as Quality Metric 
We first need a model that describes the relationship between rate and distortion so that the bit 
budget can be optimally allocated under the rate-distortion framework using the SSIM index as 
the quality metric. However, unlike the MSE-based approach, for which an analytic derivation of 
the R-D model can be found, we obtain our R-D model by curve fitting because the rate cannot 
be directly related to the SSIM-based distortion. We begin by observing the R-D statistics of a 
basic unit (BU) [49], which can be a frame, a slice, or an MB. BU is the smallest unit for most 
rate control schemes, and all MBs in a BU have the same QP. The SSIM value of a BU is the 
averaged SSIM between the original and the encoded signals of all 8×8 blocks in the BU, and 
DSSIM is obtained from Eq. (16). 
For simplicity, let D denote DSSIM from now on unless it is otherwise stated. In addition, a 
specific frame of a sequence under consideration is called a test frame. To obtain the R-D 
statistics of a test frame, we successively encode it with QPs ranging from 21 to 27, at an 
increment of 1. To ensure that identical reconstructed frames are used for the inter prediction of a 
test frame as it goes through the encoding process with various QPs, a fixed QP (24) is used for 
all the frames preceding the test frame. The R-D points shown in Fig. 26 are generated this way       
33 
 
 
points of each BU are stored and fitted by the proposed R-D model, and the average R2 value of 
all BUs of a test frame is calculated. Fig. 27 shows the average R2 values of Canoa and Mobile 
sequences. We can see that the R2 values are close to 1. Table I shows the average R2 values of all 
test frames. We can see that the proposed R-D model works well for sequences of various 
resolutions no matter whether the rate consists of texture and header bits or simply texture bits. 
12.2 Optimum Bit Allocation Using SSIM as Quality Metric 
The R-D characteristic of a BU can be estimated by using the R-D model described above. 
Given the target bit T0 of a frame and the R-D characteristics of all BUs in the frame, the purpose 
of optimum bit allocation is to determine the bit budget for each BU such that the overall 
distortion D of the frame is minimized. The optimum bit allocation problem is formulated as 
 
Fig. 28. Flowchart of the proposed rate control scheme integrated with the perceptual-based RDO. 
 
(a) 
 
(b) 
Fig. 27. The R2 statistics of the proposed R-D model for the first 150 frames of (a) Canoa and (b) Mobile sequences. 
35 
encoded. By doing so, the optimum bit allocation expressed in (21) is solved only once per frame. 
Experimental results show that such simplification results in negligible R-D performance 
degradation. 
The purpose of the upper and lower bounds in (21) is to avoid allocating unachievable bit 
budget. In our scheme, the upper bound of the bit budget is set to the maximum number of bits 
consumed by a BU in the previous frame. The lower bound of the bit budget is set to 
i
b
cL a
fN
=
, for i=1,…, Nb                 (23) 
where c is the channel rate, f is the frame rate, and a is a parameter empirically set to 0.5 in our 
current implementation. 
13.3 QP Determination 
After the target bit budget for a BU is determined, we need to compute the value of QP to meet 
the target. The bits for one BU are used for coding texture and overhead (which includes the MB 
modes, the motion vectors, and the QP value). Denote Hi and Hiprev as the number of the header 
bits for the ith BU in the current and the previous frames, respectively. It has been shown that Hi 
and Hiprev are highly correlated [56]. Hence, we take Hiprev as a predictor of Hi. Subtracting the 
predicted header bits from the target bit budget yields the target bit budget for texture coding. An 
R-Q model is needed in this process. For simplicity, we adopt the quadratic R-Q model employed 
in the JM reference software of H.264:  
1 2 2
step step
prev MAD MAD
i i Q Q
t H b b+− = ,                 (24) 
where b1 and b2 are model parameters and Qstep is the quantization step size, which has a 
one-to-one mapping relationship with QP. The QP for the ith BU is obtained by solving for Qstep 
in (24). For the smoothness of quality, the value of QP for each BU is confined to a range, 
avgQP QP δ− ≤ ,          (25) 
where δ is the variation range of QP allowed for each BU, which is set to 3 in our 
implementation. This QP is used to encode the current BU, and the resulting R-D data are stored 
to update the R-D model. 
13.4 Model Update 
The R-D, R-Q, and MAD models need to be continually updated during the encoding process 
so as to adapt to the characteristics of the content. For this purpose, a regression method is 
applied, and the selection of data points is based on the spatial and temporal correlations of a 
sequence. 
For each BU, the parameters of the R-D model in the current frame have to be updated before 
the optimum bit allocation process starts. Since the optimum bit allocation process runs before 
the encoding process of the current frame, the available data points are only those obtained in the 
previous encoded frames. Therefore, in our scheme, the data points used to update the R-D model 
of a BU in the current frame consist of 1) two R-D points of the collocated BU in the key frame 
and 2) w R-D points of the BUs collocated in the previous frames chosen by a sliding window 
technique [52], where w is the window size that is empirically set to 6. Let r and d , respectively, 
denote the encoded bits and the distortion of a previously encoded BU, and S the set of data 
points for the R-D model update. The updated model parameters α* and β* are obtained by 
minimizing 
2
1
ln ln( )k k
S
k
k
dd α βr
=
− +∑   ,             (26) 
where ( , )k kr d S∈  and |S| is the number of data points in S. Taking the gradient of (26) and 
setting it to zero, we have 
37 
 
z Fast motion estimation EPZS is turned on 
z CABAC is used 
z GOP structure is IPPP 
z 11 MBs per BU for CIF sequences and 15 for D1 sequences 
z Key frame is selected every 30 frames 
Each sequence is encoded with QP equal to 24, 28, 32, and 36, without rate control. The 
resulting bit rate is taken as the target bit rate for each sequence in the experiments and the 
corresponding QP is taken as the initial QP for the first I frame and the first P frame. 
14.2 Evaluation of R-D Performance 
The R-D performance of the proposed rate control scheme is compared against that of the JM 
reference software. To make a thorough evaluation, the proposed rate control scheme is applied to 
two H.264 compliant encoders, one with the MSE-based RDO adopted in the JM reference 
software and the other with the perceptual-based RDO described in Section 11.2. The two 
encoders are then compared against the encoder implemented in the JM reference software (with 
the native rate control on). Fig. 29 shows the SSIM values for various test sequences. It can be  
(a)          (b) 
(c)          (d) 
Fig. 29. Performance comparison of the proposed rate control scheme and that of JM 15.1 for (a) Bus (CIF), (b) Flower (CIF), (c) Paris (CIF), and (d) 
Mobile (D1) sequences. Initial QP is 32 for all tests. 
39 
 
 
TABLE XIII 
PERFORMANCE IMPROVEMENT OF THE PROPOSED RATE CONTROL SCHEME OVER THE JM REFERENCE SOFTWARE 
Sequences 
Perceptual RC Perceptual RC integrated with perceptual RDO 
PSNR variation 
(dB) SSIM gain 
Bitrate 
reduction(%) 
PSNR variation 
(dB) SSIM gain 
Bitrate reduction 
(%) 
Bus (CIF) +0.08 +0.016 25.99 -0.64 +0.020 32.37 
Canoa (CIF) +0.15 +0.012 15.54 -0.24 +0.013 16.59 
Coastguard (CIF) -0.12 +0.012 15.67 -1.51 +0.015 19.23 
Flower (CIF) -0.22 +0.006 17.38 -0.45 +0.009 23.37 
Football (CIF) -0.19 +0.005 5.27 -0.97 +0.008 9.67 
Mobile (CIF) -0.15 +0.004 10.77 -0.49 +0.008 21.86 
Paris (CIF) +0.42 +0.007 14.20 -0.58 +0.011 24.80 
Stefan (CIF) -0.20 +0.005 19.74 -0.59 +0.006 24.23 
Table (CIF) +0.02 +0.006 8.72 -1.54 +0.012 16.68 
Tempete (CIF) -0.02 +0.004 9.93 -0.42 +0.007 18.64 
Bus (D1) -0.19 +0.015 20.95 -1.43 +0.017 24.90 
Mobile (D1) -0.24 +0.005 11.70 -0.67 +0.010 23.89 
Night (D1) -0.25 +0.004 7.63 -1.40 +0.008 18.60 
average -0.07 +0.008 14.11 -0.84 +0.011 21.14 
(a)           (b) 
(c)           (d) 
Fig. 30. R-D performance of the perceptual-based rate control and the integration with the perceptual-based RDO for (a) Bus (CIF) (b) Paris (CIF) (c) Stefan
(CIF) (d) Mobile (D1). 
41 
 
perceptual-based RDO is negative for all sequences. This result, which is consistent with that in 
[37], is expected because the latter encoder does not optimize its mode decision against PSNR. 
The three encoders have the same level of bitrate error because the same R-Q model and MAD 
predictor are used. 
Fig. 30 shows the R-D curves for various sequences obtained by the three encoders. The two 
H.264 compliant encoders with our rate control scheme achieve better R-D performance than the 
JM reference software for all sequences at all bitrates. Again, between the two better ones, the 
R-D performance the one with perceptual-based RDO is even higher. Table XIII shows the 
average SSIM improvement, PSNR variation, and bit-rate reduction [23]. For sequences in which 
the BUs of the same frame have very different R-D characteristics, such as the Bus and the Paris 
sequences, our rate control scheme achieves significant R-D performance improvement. At the 
same SSIM index, the encoder with MSE-based RDO achieves up to 25% (average 14%) bit-rate 
reduction, whereas the encoder with perceptual-based RDO achieves up to 32% (average 21%) 
bit-rate reduction. 
14.3 Computational Overhead 
The computational overhead of the proposed rate control scheme mainly comes from the 
additional encoding passes for the key frames, the R-D model update, and the calculation of the 
optimum bit allocation (a GP problem). Table XIV shows the encoding time ratio between the 
two JM reference software encoders, one with our rate control scheme and the other with the 
native rate control, for various sequences and QPs. About 12% more encoding time is needed for 
the encoder with our rate control scheme. 
14.4 Subjective Inspection 
The subjective quality of the reconstructed frames is examined. We find that the proposed 
scheme indeed preserves structural information better than the JM reference software, because 
our scheme optimally allocates the bit budget based on the structural similarity. For illustration, 
an encoded frame of each of the Bus, Paris and Stefan sequences is shown in Figs. 31-33. Our 
scheme generates better results in the grass, the fence, and the trees in the Bus sequence, the 
texture of the wood table and the small white dots on the necktie in the Paris sequence, and the 
 
          
(a)                              (b) 
 
  
(c) 
Fig. 33. The 71st frame of Paris sequence (CIF) encoded by (a) the JM reference software, (b) the perceptual rate control scheme, and (c) the 
perceptual rate control scheme integrated with perceptual RDO with initial QP=32. 
43 
REFERENCES 
[1] Draft ITU-T Recommendation and Final Draft International Standard of Joint Video 
Specification (ITU-T Rec. H.264 | ISO/IEC 14496-10 AVC), 2003. 
[2] T. Wiegand, G. J. Sullivan, G. Bjontegaard, and A. Luthra, “Overview of H.264 video 
coding standard,” IEEE Trans. Circuits Syst. Video Technol., vol. 13, no. 7, pp. 560-576, 
Jul. 2003. 
[3] G. J. Sullivan and T. Wiegand, “Rate-distortion optimization for video compression,” IEEE 
Signal Processing Magazine, pp. 74-90, Nov. 1998. 
[4] D. Marpe, T. Wiegand, and S. Gordon, “H.264/MPEG4-AVC fidelity range extensions: 
tools, profiles, performance, and application areas,” IEEE Int. Conf. on Image Processing, 
vol.1, pp. 593-596, Sept. 2005. 
[5] Y. Huang et al., “Analysis, fast algorithm, and VLSI architecture design for H.264/AVC 
intra frame coder,” IEEE Trans. Circuits Syst. Video Technol., vol. 15, no. 3, pp. 378-401, 
Mar. 2005. 
[6] F. Pan et al., “Fast mode decision algorithm for intra prediction in H.264/AVC video 
coding,” IEEE Trans. Circuits Syst. Video Technol., vol. 15, no. 7, pp. 813-822, Jul. 2005. 
[7] C. Tseng, H. Wang, and J. Yang, “Enhanced intra-4x4 mode decision for H.264/AVC 
coder,” IEEE Trans. Circuits Syst. Video Technol., vol. 16, no. 8, pp. 1027-1032, Aug. 
2006. 
[8] J. Wang et al., “A fast mode decision algorithm and its VLSI design for H.264/AVC 
intra-prediction,” IEEE Trans. Circuits Syst. Video Technol., vol. 17, no. 10, pp. 
1414-1422, Oct. 2007. 
[9] A. Tsai et al., “Intensity gradient technique for efficient intra-prediction in H.264/AVC,” 
IEEE Trans. Circuits Syst. Video Technol., vol. 18, no. 5, pp. 694-698, May 2008. 
[10] H. Li, K. Ngan, and Z. Wei, “Fast and efficient method for block edge classification and its 
application in H.264/AVC video coding,” IEEE Trans. Circuits Syst. Video Technol., vol. 
18, no. 6, pp. 756-768, Jun. 2008. 
[11] A. Tsai et al., “Effective subblock-based and pixel-based fast direction detections for H.264 
intra prediction,” IEEE Trans. Circuits Syst. Video Technol., vol. 18, no. 7, pp. 975-982, 
Jul. 2008. 
[12] K. Bharanitharan et al., “A low complexity detection of discrete cross differences for fast 
H.264/AVC intra prediction,” IEEE Trans. Multimedia, vol. 10, no. 7, pp. 1250-1260, Nov. 
2008. 
[13] I. Choi, J. Lee, and B. Jeon, “Fast coding mode selection with rate-distortion optimization 
for MPEG-4 part-10 AVC/H.264,” IEEE Trans. Circuits Syst. Video Technol., vol. 16, no. 
12, pp. 1557-1561, Dec. 2006. 
[14] C. Kim, and C. Jay Kuo, “Feature-based intra-/inter coding mode selection for 
H.264/AVC,” IEEE Trans. Circuits Syst. Video Technol., vol. 17, no. 4, pp. 441-453, Apr. 
2007. 
[15] B. Kim, “Fast selective intra-mode search algorithm based on adaptive thresholding scheme 
for H.264/AVC encoding,” IEEE Trans. Circuits Syst. Video Technol., vol. 18, no. 1, pp. 
127-133, Jan. 2008. 
[16] Y. Su, M. Sun, and K. Lin, “Encoder optimization for H.264/AVC fidelity range 
extensions,” Proc. SPIE Vis. Comm. and Image Processing, vol. 5960, pp. 2067-2075 Jul. 
2005. 
[17] Y. Yu and L. Wang, “A fast mode selection method for H.264 high profile,” Proc. IEEE Int. 
Conf. on Acoustics, Speech, and Signal Processing, pp. 681-684, Apr. 2008. 
[18] Y.-C. Lin T. Fink and E. Bellers, “Fast mode decision for H.264 based on rate-distortion 
cost estimation,” Proc. IEEE Int. Conf. on Acoustics, Speech, and Signal Processing, pp. 
1137-1140, Apr. 2007.  
[19] A. Yu, G. Martin, and H. Park, “Fast inter-mode selection in the H.264/AVC standard 
using a hierarchical decision process,” IEEE Trans. Circuits Syst. Video Technol., vol. 18, 
no. 2, pp. 186-195, Feb. 2008. 
45 
[42] D. M. Chandler and S. S. Hemami, “VSNR: a wavelet-based visual signal-to-noise ratio for 
natural images,” IEEE Trans. Image Process., vol.16, no.9, pp.2284-2298, Sept. 2007. 
[43] H. R. Sheikh and A. C. Bovik, “Image information and visual quality,” IEEE Trans. Image 
Process., vol.15, no.2, pp.430-444, Feb. 2006. 
[44] Z. Wang, L. Lu, and A. C. Bovik, “Video quality assessment based on structural distortion 
measurement,” Signal Processing: Image Communication, special issue on “Objective 
video quality metrics”, vol. 19, no. 2, pp. 121-132, Feb. 2004. 
[45] T.-S. Ou, Y.-H. Huang, and H. H. Chen, “A perceptual-based approach to bit allocation for 
H.264 encoder,” in Proc. Visual Communications and Image Processing, Jul. 2010. 
[46] MPEG-2 Test Model 5, Doc. ISO/IEC JTC1/SC29/WG11/93-400, Sydney, Australia, Apr.  
1993. 
[47] Video Coding for Low Bit Rate Communication, ITU-T Rec. H.263, Nov. 1995. 
[48] MPEG-4 Video Verification Model v8.0, ISO/IEC JTC1/SC29/WG11 Coding of Moving   
Pictures and Associated Audio MPEG97/N1796, Stockholm, Sweden, Jul. 1997. 
[49] Z. G. Li, F. Pan, K. P. Lim, G. N. Feng, X. Lin, and S. Rahardaj, Adaptive basic unit layer   
rate control for JVT, Joint Video Team of ISO/IEC JTC1/SC29/WG11 and ITU-T 
SG16/Q.6 Doc. JVT-G012, Pattaya, Thailand, Mar. 2003. 
[50] Z. Chen and K. N. Ngan, “Recent advances in rate control for video coding,” Signal  
Process.: Image Commun., vol. 22, no. 1, pp. 19–38, Jan. 2007. 
[51] T. Chiang and Y.-Q. Zhang, “A new rate control scheme using quadratic rate distortion  
model,” IEEE Trans. Circuits Syst. Video Technol., vol. 7, no. 1, pp. 246–250, Feb. 1997. 
[52] H.-J. Lee, T. Chiang, and Y.-Q. Zhang, “Scalable rate control for MPEG-4 video,” IEEE  
Trans. Circuits Syst. Video Technol., vol. 10, no. 6, pp. 878–894, Sept. 2000. 
[53] N. Kamaci, Y. Altunbasak, and R. M. Mersereau, “Frame bit allocation for the H.264/AVC  
video coder via Cauchy-density-based rate and distortion models,” IEEE Trans. Circuits  
Syst. Video Technol., vol. 15, no. 8, pp. 994–1006, Aug. 2005. 
[54] S. Ma, W. Gao, and Y. Lu, “Rate-distortion analysis for H.264/AVC video coding and its 
application to rate control,” IEEE Trans. Circuits Syst. Video Technol., vol. 15, no. 12, pp. 
1533–1544, Dec. 2005. 
[55] Z. He, Y.-K. Kim, and S. K. Mitra, “Low-delay rate control for DCT video coding via 
ρ-domain source modeling,” IEEE Trans. Circuits Syst. Video Technol., vol. 11, no. 8, pp. 
928–940, Aug. 2001. 
[56] W. Yuan, S. Lin, Y. Zhang, W. Yuan, and H. Luo, “Optimum bit allocation and rate control 
for H.264/AVC,” IEEE Trans. Circuits Syst. Video Technol., vol. 16, no. 6, pp. 705–715, Jun. 
2006. 
[57] D.-K. Kwon, M.-Y. Shen, and C.-C. Jay Kuo, “Rate control for H.264 video with enhanced 
rate and distortion models,” IEEE Trans. Circuits Syst. Video Technol., vol. 17, no. 5, pp. 
517–529, May 2007. 
[58] C. An and T. Q. Nguyen, “Iterative rate-distortion optimization of H.264 with constant bit 
rate constraint,” IEEE Trans. Image Process., vol. 17, no. 9, pp.1605–1615, Sept. 2008. 
[59] Z. He and S. K. Mitra, “Optimum bit allocation and accurate rate control for video coding 
via ρ-domain source modeling,” IEEE Trans. Circuits Syst. Video Technol., vol. 12, no. 10, 
pp. 840–849, Oct. 2002. 
[60] Z. G. Li, F. Pan, K. P. Lim, and S. Rahardja, “Adaptive rate control for H.264,” in Proc. 
IEEE Int. Conf. Image Process., pp. 745–748, Oct. 2004. 
[61] JVT reference software [Online]. Available: http://bs.hhi.de/~suehring/ tml/download/. 
[62] J. Dong and N. Ling, “A context-adaptive prediction scheme for parameter estimation in 
H.264/AVC macroblock layer rate control,” IEEE Trans. Circuits Syst. Video Technol., vol. 
19, no. 8, pp. 1108–1117, Aug. 2009. 
[63] X. Yang, W. Lin, Z. Lu, X. Lin, S. Rahardja, E. Ong, and S. Yao, “Rate control for 
videophone using local perceptual cues,” IEEE Trans. Circuits Syst. Video Technol., vol. 15, 
no. 4, pp. 496–507, Apr. 2005. 
Trip Report 
 
The IEEE International Symposium on Circuits and Systems (ISCAS) is one of the world’s 
premier forum on circuits and systems. It was held in Paris from May 30 to June 2, 2010, 
and brought leading engineers and scientists from around the world. It turned out that 
Taiwan has the largest group of Asian people attending this conference.  My lab has two 
papers (see the references) presented at this conference.  The first paper is about a system 
for removing the shadow from the image of a natural scene, and the second paper is about a 
perceptual-based method for coding mode decision.  Both papers were well received. 
Besides the presentation of papers, I also attended the Editorial Board meeting of IEEE 
Transactions on Circuits and Systems for Video Technology.  Things discussed in the 
meeting include the handling of paper submissions and the special issue proposals. I also 
chaired a session on multimedia analysis in the conference. 
[1] Y.-F Su and H. H. Chen, “Shadow removal from natural images,” IEEE Int. Symp. 
on Circuits and Syst., 3369-3372, May 2010  
[2] Y.-H. Huang, T.-S. Ou, and H. H. Chen, “Perceptual-based coding mode decision,” 
IEEE Int. Symp. Circuits and Systems, 393-396, May 2010  
98 年度專題研究計畫研究成果彙整表 
計畫主持人：陳宏銘 計畫編號：98-2221-E-002-078-MY2 
計畫名稱：整合式快速編碼模式估測及基於感知之視訊壓縮研究 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 3 3 100%  
研究報告/技術報告 0 0 100%  
研討會論文 7 7 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 2 2 100%  專利 已獲得件數 0 2 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 7 7 100%  
博士生 2 2 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
 
