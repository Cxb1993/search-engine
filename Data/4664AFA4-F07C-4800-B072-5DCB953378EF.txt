 II
一、 中文摘要 
資料串流的探勘，是近年來熱門的研究議題。所謂資料串流，是一種持續不斷產生的
有序資料，其來臨往往相當快速、無法預測、大量、隨時間改變且沒有限制。依據資料的
處理模式，可以分成標界模式、時間衰減模式、與滑動窗模式。資料串流的探勘或者回覆
資料串流系統的查詢相當複雜，超越傳統關聯式查詢以及固定資料集合的勘測。由於串流
資料的特性與限制，我們必須設計在有限的資源下、單次掃瞄資料的有效率探勘方法。 
目前所提出來的資料串流頻繁樣式探勘方法，不論其資料處理模式是什麼模式，所考
慮的情形，大都是在一個固定的最小支持度下，找出所有的頻繁樣式或封閉樣式等。實務
上，因為資料串流是變動的，使用者很可能因現階段資料的特性，互動地變更最小支持度，
或者指定不同的時間區間，以觀察串流資料中頻繁樣式的改變。由於資料串流並無法保留
全部的歷史資料，資料多數也僅能掃瞄一次。因此，如何在有限的記憶體、單次的掃瞄、
甚至有限的運算時間限制下，仍可以互動式探勘出有興趣的頻繁樣式，是一個相當困難的
問題。 
互動式探勘在傳統資料庫中，我們可以指定任意的時間或項目屬性條件，掃瞄資料庫
後以擷取之資料集作為探勘的來源資料。如果使用者改變時間等條件，只要對資料庫重新
掃瞄，再以重新擷取之資料集作為探勘的來源資料即可。然而，串流資料無法保存所有的
歷史資料，多數的探勘方法因此僅保留現有的頻繁項目集持續更新，至多留存部分的串流
資料再探勘。因此，使用者改變所欲探勘的時間範圍導致資料集合不同時，現有的資料串
流探勘方法多不敷使用。FP-stream 演算法提供多時間精細度的頻繁項目集資料串流探
勘，可以改變所欲探勘的時間範圍。但是，使用者並無法變更最小支持度，一旦使用者互
動地降低最小支持度，其方法即不適用。 
我們計畫的目標是設計一個高效能、互動式探勘資料串流頻繁樣式的方法，支援可改
變支持度、可探勘任意時間區間的資料串流頻繁項目集探勘。我們規劃了一個位元序列的
方式記錄串流資料的摘要結構，可以有效減少記憶體的消耗，並利用快速的位元運算，改
善任意時間區間、可改變支持度資料串流頻繁項目集探勘的速度。實驗證實，我們的方法
可以達成高效能、互動式資料串流頻繁樣式的探勘。 
 
 IV
目錄 
 
一、 中文摘要……………………………………………………………………II 
二、 英文摘要…………………………………………………………………...III 
三、 報告內容…………………………………………………………………...1 
I. 前言………………………………………………………………………..1 
II. 研究目的 ………………………………………………………………..1 
III. 文獻探討…………………………………………………………………2 
IV. 研究方法………………………………………………………………….4 
V. 結果與討論………………………………………………………………5 
四、 參考文獻……………………………………………………………………8 
五、 計畫成果自評………………………………………………………………10
 2
stream of transactions is proposed. The VIFI algorithm uses a compact structure to store the 
summary information of stream transactions across time so that time-interval queries can be 
answered. The summary structure, called weighted bit vector, is an effective bit-sequence 
representation [ 2] to approximate past transactions with a flexible interval. The comprehensive 
experiments conducted show that VIFI is highly efficient and linearly scalable. 
III. 文獻探討 
The Buffer-Trie-SetGen is a Lossy Counting based algorithm for computing frequent counts 
over streams that consist of sets of items. This algorithm adopts the batch processing to mining 
stream data. It parts the stream data into several batches and loads these batches into the main 
memory. The size of the batches is specified by the users so that suitable batch size can be set to 
maximize the adaptive utilization of main memory. 
The objective of FP-stream is to find the complete set of frequent patterns in a data stream, 
assuming that one can only see the set of transactions in a limited size window at any moment. 
The FP-stream algorithm supports computing and maintenance of all the frequent patterns (in a 
data stream) and dynamically updates them with the incoming data. The method extended the 
FP-growth framework to mine time-sensitive patterns with approximate support guarantee. The 
authors incrementally maintain tilted-time windows for each pattern at multiple time granularities. 
The FP-stream is described briefly in following. 
An FP-stream structure consists of an in-memory frequent pattern-tree to capture the 
frequent and sub-frequent itemset information, and a tilted-time window table for each frequent 
pattern. The FP-stream algorithm processes the first batch differently from the rest as an 
initialization step. As the transactions in the first batch B1 arrive, the frequencies for all items are 
computed, and the transactions are stored in main memory. An ordered list, f_list, is created in 
which items are ordered by decreasing frequencies. Once all the transactions in B1 have arrived 
and stored, the batch is scanned by creating an FP-tree with items of frequency less than ε|B1| 
pruned. Finally, an FP-stream structure is created by mining all ε-frequent itemsets from the 
FP-tree. 
The DSM-FI algorithm adopts the landmark window model. The DSM-FI uses the 
IsFI-forest (Item-suffix Frequent Itemset forest) structure, which is consist of CFI-tree (Candidate 
Frequent Itemset trees of item-suffixes) and DHT (Dynamic Header Table). The DSM-FI 
algorithm is briefly described in the following. At first, the data stream is partitioned into blocks. 
DSM-FI will process these blocks one by one. Each transaction in a block performs the 
Item-suffix projection ( IsProjection(T) ). The projected transactions are maintained in CFI-tree 
and DHT. The prune operation is called after a block is processed. If the node representing a 
subtree of CFI-tree has a support less than ms (minimum support)*CL (current length), the 
subtree is pruned. Finally, the generation of frequent itemsets is accomplished by finding those 
itemsets whose true support ( Tsup(X) ) is large or equal to ms*CL from IsFI-forest. 
The FIDS Algorithm is to mine all maximal frequent itemsets over an arbitrary time interval 
of the stream. This algorithm adopts the batch processing to mining stream data. However, 
maintaining all the data streams in the main memory requires too much space. The FIDS is to 
 4
VSMDS will use the SYV to re-build PFI-tree for the mining of these itemsets at this moment. An 
algorithm called GruFI (Grouped Synopsis Vectors for Frequent Itemsets Mining), was presented 
in for variable support mining of frequent itemsets in a data stream. The GruFI algorithm is 
proposed to improve VSMDS algorithm in both updating and compression of the synopsis vectors. 
The framework of GruFI and the synopsis vectors are similar to VSMDS. 
An algorithm called VSMTP (Variable Support Mining for Time-Sensitive Patterns over 
Data Stream) was proposed in for variable support mining of time-sensitive frequent patterns in a 
data stream. In order to provide the patterns corresponding to user-specified interval, a new 
mechanism must be designed to effectively keep the summary information. Since the patterns are 
meaningful with respect to certain time interval. VSMTP extended the framework of VSMDS to 
mine time-sensitive patterns with approximate support guarantee when user decreased the 
minimum support. A tilted synopsis vector is constructed for maintaining statistics and tilted-time 
tables of past transactions and is invoked only when necessary. 
IV. 研究方法 
Fig. 1 presents an overview of the proposed VIFI algorithm. VIFI comprised two phases (a) 
transaction insertion phase and (b) interactive mining phase. In (a) Transaction insertion phase, 
the bit-vector is our efficient representation for transaction items. Nevertheless, such an allocation 
would consume the available memory very fast. The new structure should confine its space 
allocation to deal with the unbounded nature of data stream transactions. Therefore, we propose a 
weighted bit vector (abbreviated as WB) to maintain an itemtable for each approximated 
transaction. In addition, the WB keeps the summary transactions in data stream, in a logarithmic 
way. WB is compose of bit-vector of all items including BS(α), BS(α2), …, BS(αn). The process 
consists of three steps: (I) Bit-sequence transformation (II) Bit-sequence appending (III) 
Bit-sequence compression. On seeing a new transaction ti, VIFI transforms ti into the bit-sequence 
representation. Then, VIFI checks whether WB is full or not. VIFI appends ti into WB directly; 
otherwise compress WB. In, (b) Interactive mining phase, the extraction of all frequent itemsets 
output on user demand. In the interactive mining phase when a user asks the support of an itemset 
e in period τs to τe sup(e)τs:τe, time τs and τe  are mapped to the corresponding interval WB. The 
mining algorithm used bit-vector “and” operation for the weighted support computation. 
Consequently, the frequent itemsets in any periods, with respect to any support value, can be 
discovered. 
In this step, the bit-vector of items is used to compress w bits to w/2 bits. Four compression 
methods are described as follows: If the first even bit tn is 1, we set the first bit to be 1; otherwise, 
it is set to be 0. And then we check then next even bit until checking all even bits. If the first odd 
bit tn-1 is 1, we set the first bit to be 1; otherwise, it is set to be 0. And then we check then next odd 
bit until checking all odd bits. We use AND operation to first bit tn-1 and second bit tn and set the ti 
bit to its result. We use AND operation to first bit tn-1 and second bit tn and set the ti bit to its result. 
For example, we assume w is 4 and the bit-vector of item a, BS(a), is 1010. Now we compress 
BS(a) to be 0000, because both the first even bit and the second even bit are 0. Similarly, BS(b) is 
1100, BS(c) is 1000, and BS(d) is 1100. The second half w/2 bits are meaningless and is conserved 
 6
the synthetic datasets were generated using the well-known IBM dataset generator. Dataset 
T10I4D200k in the following context means that the data stream has 200,000 transactions (D200K) 
of average size 10 (T10), and the average size of maximally frequent itemsets is 4 (I4). We 
evaluated the efficiency of VIFI and NewMoment* algorithms on memory usage and total 
execution time. The mining with respect to various time intervals is explored. The scalability of the 
VIFI algorithm is also analyzed. 
 
Figure 2. Total Execution Time for mining T10I4D200K 
 
Figure 3. Memory Usage for mining T10I4D200K 
Table 1. Precision and Recall for T10I4D200K 
Minsup (%) 1.0 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1 Average
Precision (%) 97.3 97.27 96.81 98.36 98.14 96.98 96.76 92.16 76.83 69.35 92.00
Recall (%) 98.37 97.03 97.03 97.16 97.41 96.49 97.62 95.1 88.41 78.24 94.29
F-Measure (%) 97.83  97.15  96.92 97.76 97.77 96.74 97.19 93.61 82.22  73.53  93.13 
 Table 2. Precision and Recall for various WB size 
 
 
In this experiment, we investigate total execution time, memory usage, and precision and 
recall of T10I4D200K. The mining interval is the entire history of the stream. The minimum 
support threshold is varied from 1.0% to 0.1%. In Fig. 2, VIFI runs slower than NewMoment* 
because of VIFI using extra compression time. Fig. 3 shows the memory usage wit MB units. 
The memory usage of VIFI is about 10MB but NewMoment* is more than 25MB. Because VIFI 
used fixed memory (64kbit×1000items=8MB) to record Weighted Bit Vector (VIFI-WB) and 
little memory for mining. In Table 2, VIFI has high accuracy and average precision and recall is 
WB Size per item 8KB 16KB 32KB
Precision (%) 69.35 87.37 100 
Recall (%) 78.24 84.98 100 
 8
四、參考文獻 
(I) 計畫相關之著作 
1. Ming-Yen Lin, Sue-Chen Hsueh, Chih-Chin Chan, "Incremental Discovery of 
Sequential Patterns Using a Backward Mining Approach," 12th IEEE International 
Conference on Computational Science and Engineering , 2009. Vancouver, Canada. 
(EI) 
2. Sue-Chen Hsueh, Ming-Yen Lin, and Chien-Liang Chen, "Mining Negative 
Sequential Patterns for E-Commerce Recommendations," 2008 International 
Workshop on E-Commerce Services and Applications , Vol. 1, pp. 1213-1218, 2008. 
Yilan. (EI) 
3. Ming-Yen Lin, Sue-Chen Hsueh, and Sheng-Kun Hwang "Interactive Discovery of 
Frequent Patterns Using Synopsis Vectors in a Data Stream of Landmark Model," 
Submitted to Knowledge and Information Systems (Paper no.: KAIS-2215), (SCI) 
4. Sue-Chen Hsueh, Wei Sheng Wang, Shao-Wei Chen, Ming-Yen Lin, "Integrating 
Mobile Payments with Stored Value Cards: Securing the User Identities and 
Merchant Authentications," International Conference on Business and Information, 
2009. Malaysia. 
5. Sue-Chen Hsueh, Shao-Wei Chen,Wei-Sheng Wang, Ming-Yen Lin, "A Secure and 
Lightweight Mobile Coupon System using QR Code for Mobile 
Tagging," International Business and Information, 2009. Malaysia. 
(II) 學生畢業論文 
1. 董建翔，Interactive Mining of Maximal Frequent Itemsets in Data Streams，碩士論
文，98年。 
2. 李萬朝，Interactive Mining of Frequent Closed Itemsets in a Data Stream，碩士論
文，98年。 
3. 詹志勤，Incremental Discovery of Sequential Patterns Using Backward Mining 
Approaches，碩士論文，98 年。 
(III) 計畫參考文獻 
1. Agrawal, R. and Srikant, R., “Fast Algorithm for Mining Association Rules,” 
Proceedings of the 20th International Conference on Very Large Databases 
(VLDB’94), pages 487-499, 1994. 
2. Ayres, J., Gehrke, J., Yiu, T., and Flannick, J., “Sequential Pattern Mining using A 
Bitmap Representation,” Proceedings of the 8th ACM International Conference on 
Knowledge Discovery and Data Mining (KDD), pages 429-435, July 2002. 
3. Chang, J. H. and Lee, W. S., “Decaying Obsolete Information in Finding Recent 
Frequent Itemsets over Data Stream,” IEICE Transaction on Information and 
Systems, Volume E87-D, Number 6, June 2004. 
4. Chang, J. H. and Lee, W. S., “estWin: Online data stream mining of recent frequent 
itemsets by sliding window method,” Journal of Information Science, Volume 31, 
Issue 2, pages 76-90, April 2005. 
 10
18. Jia, L., Wang, Z., Lu, N., Xu, X., Zhou, D., Wang, Y., “RFIMiner: A 
regression-based algorithm for recently frequent patterns in multiple time granularity 
data streams,” Applied Mathematics and Computation, Volume 185, Number 2, pages 
769-783, February 2007. 
19. Jiang, N., Gruenwald, L., “CFI-Stream: mining closed frequent itemsets in data 
streams,” Proceedings of the 12th ACM SIGKDD International Conference on 
Knowledge Discovery and Data Mining, pages 592-597, August 2006. 
20. Manku, G. S., Motwani, R., “Approximate Frequency Counts over Data Streams,” 
Proceedings of the 28th VLDB Conference, pages 346-357, Hong Kong, China, 
August 2002. 
21. Raïssi, C., Poncelet, P., Teisseire, M., “Towards a new approach for mining frequent 
itemsets on data stream,” Journal of Intelligent Information Systems stream, Volume 
28, Issue 1, pages 23-36, February 2007. 
22. Wang, C. Y., Enhanced Variable Support Mining for Frequent Itemsets over Data 
Streams, Master Thesis, Feng Chia University, 2007. 
23. Wong, C. W. and Fu, W. C., “Mining top-K frequent itemsets from data streams,” 
Data Mining and Knowledge Discovery, Volume 13, Number 2, pages 193-217, 
September 2006. 
24. Yu, X., Chong, Z., Lu, H., Zhang, Z., and Zhou A., “A false negative approach to 
mining frequent itemsets from high speed transactional data streams,” Information 
Sciences, Volume 176, Number 14, pages 1984-2015, July 2006. 
 
 
 12
可供推廣之研發成果資料表 
□ 可申請專利  ▓ 可技術移轉                                     日期：98 年 12 月 28 日 
國科會補助計畫 
計畫名稱：互動式資料串流頻繁樣式探勘技術之研發 
計畫主持人：林明言         
計畫編號：NSC-97-2221-E-035-064 學門領域：資訊 
技術/創作名稱 互動式資料串流頻繁樣式探勘 
發明人/創作人 林明言、劉吉評、董建翔 
中文： 
目前所提出來的資料串流頻繁樣式探勘方法，大都是在一個固定的
最小支持度下，找出所有的頻繁樣式或封閉樣式等。 
我們設計了一個高效能、互動式探勘資料串流頻繁樣式的方法，支
援可改變支持度、可探勘任意時間區間的資料串流頻繁項目集探
勘。可以支援實務應用。 
 
技術說明 英文：Current methods for frequent pattern mining in a data stream, 
despite the data processing models, are restricted because a fixed 
minimum support must be pre-specified before mining. The minimum 
support should be changeable in practice since the stream data change 
distributions dynamically. We have devised an efficient algorithm for 
interactive mining of frequent itemsets in a data stream, featuring in 
interactive discovery of changeable supports and any time period. The 
method can be used in real-world applications. 
可利用之產業 
及 
可開發之產品 
資料庫、資料工程 
Interactive data stream mining software 
技術特點 
Interactive mining 
data stream 
changeable support 
changeable mining period 
推廣及運用的價值 
The method can be used to mine stream data. For example, the method 
can be used in chain-store transactions and flexiblely discover 
interesting patterns for further real-time reactions. 
※ 1.每項研發成果請填寫一式二份，一份隨成果報告送繳本會，一份送 貴單位
研發成果推廣單位（如技術移轉中心）。 
※ 2.本項研發成果若尚未申請專利，請勿揭露可申請專利之主要內容。 
※ 3.本表若不敷使用，請自行影印使用。 
表 Y04 
感謝國科會核准經費贊助，以及逢甲大學資訊電機學院的贊助，使本人能夠順利
前往加拿大參與國際會議討論，並發表研究論文。 
 
 
employed as a prefix and one item after the pattern is added 
(or projected), such as <a b c>, to be tested. In contrast, the 
candidate pattern <c b a> is mined after <b a> is discovered 
in backward mining. Let k-pattern be a sequential pattern 
with k items. A discovered k-pattern is used as a postfix, and 
one potential item is added before the k-pattern to form the 
candidate (k+1)-pattern in our backward mining approach.  
Backward mining is more efficient than forward mining 
for incremental sequence discovery. One complicated 
operation in incremental sequence mining is that newly 
appended items will change the previous sequence into a 
new sequence due to merging. Many new sub-sequences are 
generated but only the supports of those sub-sequences not 
existing in the previous data sequence should be increased. 
The merge step may introduce redundant counting 
operations without systematic checking. For example, a data 
sequence <(a)(b)(c)> appended item b to become 
<(a)(b)(c)(b)> so that the boxed nodes in Fig. 1 will be 
affected. Using backward mining, we may easily skip the 
checking required in forward mining, i.e. those nodes 
prefixed by items a and c in Fig. 1(a). In addition, the anti-
monotone property still holds for backward mining. Thus, if 
<(c)(b)> is infrequent, <(a)(c)(b)>, <(b)(c)(b)>, 
<(a)(b)(c)(b)>, and so on can be eliminated since they 
cannot be frequent.  
Incremental mining [3, 4, 5, 6, 7, 12] needs to be based 
on traditional sequential pattern mining [1, 2, 9, 10, 14, 15]. 
For example, the ISM algorithm [13] is based on SPADE 
[18]. IncSpan [4] uses PrefixSpan [14] and the semi-
frequent to incremental mining. IncSP [8] extends the GSP 
algorithm [15] to merge newly appended item candidates 
and previously sequential patterns to new candidates. 
CISpan [17] uses CloSpan [16] as the base mining 
algorithm and handles the newly appended items by deleting 
old sequences and adding new ones. Nevertheless, these 
approaches use the forward mining methodology.  
In this paper, we propose the BSPinc (Backward SPAM 
for incremental mining) algorithm, which utilizes the SPAM 
algorithm [2] and incrementally mines sequential patterns 
using the backward mining strategy. The experiments 
indicate that BSPinc is efficient and outperforms the well-
known IncSpan algorithm.  
The rest of the paper is organized as follows. The 
preliminary concept is introduced in Section 2. Section 3 
presents the BSPinc algorithm. The experimental evaluation 
is described in Section 4. Section 5 concludes the study. 
II. PRELIMINARIES 
Let Ψ = {α1, α2, …, αr} be a set of literals, called items. 
An itemset I = (β1, β2, …, βq) is a nonempty set of q items 
such that I ⊆ Ψ. A sequence s, denoted by <ewew-1… e2e1>, 
is an ordered list of w elements where each element ei is an 
itemset. Without loss of generality, we assume the items in  
<a>
<a b> <a c>
<a c b><a b b> <a b c>
<a b c b>
<b>
<b b> <b c>
<b c b>
<c>
<c b>
(a) forward mining (b) backward mining 
<a b>
<b>
<c b><b b>
<a b b> <a c b> <b c b>
<a b c b>
<a> <c>
<a c> <b c>
<a b c>
 
Fig. 1 Various flows of sequence mining (parentheses are 
omitted without ambiguity) 
an element are in reverse lexicographic order. The size of a 
sequence s, written as |s|, is the total number of items in all 
the elements in s. Sequence s is a k-sequence if |s| = k. A 
sequence s = <ewew-1… e2e1> is a subsequence of another 
sequence s' = <em'em-1'…e2'e1'> if there exist 1 ≤ iw< iw-1 
< …< i1 ≤ m such that e1 ⊆e i1', e2 ⊆e i2', …, and en ⊆e in'. 
Sequence s' contains sequence s if s is a subsequence of s'. 
Note that the parentheses for an itemset are omitted 
whenever there is no ambiguity. For example, <(a)(d,b)(c)> 
is a 4-sequence, which can be represented as <a(d,b)c>, and 
it contains a 3-sequence <abc>. 
Note that we define the items in an element and the 
elements in a sequence reversely; the formation of a 
sequence is also extended backward. Thus, a sequence -
extension with item x to a sequence s = <ewew-1… e2e1> 
forms s’ = <(x)ewew-1… e2e1>. An itemset-extension with 
item x to a sequence s = <ewew-1… e2e1> forms s’ = <{x}∪ew 
ew-1… e2e1>. Sequence s’ is an extension of s, and s is called 
the postfix of s’. For example, we extend sequence <ab> 
with an itemset <c> to form the sequence <cab>; we extend 
sequence <ab> with item c to the itemset (a) in <ab> to 
form the sequence <(c,a)b>.  
The sequence database DB contains |DB| data sequences, 
where each data sequence ds is a sequence with a unique 
identifier sid. The support count of sequence s, denoted by 
s.count, is the number of data sequences containing s. The 
support of sequence s, denoted by s.sup, is s.count divided 
by |DB|. The minsup is the user specified minimum support 
threshold. A sequence s is a frequent sequence, or called 
sequential pattern, if s.sup ≥ minsup. A sequential pattern s 
having |s| = k is referred to as a k-pattern. 
Given the minsup and the sequence database DB, the 
problem of sequential pattern mining is to discover the set of 
all sequential patterns, denoted by PDB. In practice, the 
sequence database will be updated with new transactions 
after the mining process. Possible updating includes 
appending transactions, insertions, deletions, and 
modifications of data sequences. With respect to the same 
minsup, the incremental mining problem aims to find out the 
65
In BSPinc, we mine the super-sequences of 1-patterns in 
lexicographic order. However, both sequence-extensions 
and itemset-extensions in candidate generation are 
conducted in a backward manner, as described in Section 2. 
Fig. 3 shows an example of candidate generation using 
items a and b, up to the candidate 3-sequences. 
The most time-consuming step in sequential pattern 
mining is the support counting step, which needs to scan the 
entire UD several times. Our backward mining can skip the 
support counting step of stable sequences because the 
support count of a stable sequence in UD is the same as that 
in DB. Such a technique is referred to as stable sequence 
pruning. Moreover, a unique property is introduced by 
backward mining: any extension of a stable sequence must 
be stable. Thus, once a stable sequence s is discovered, the 
support counting step of all extensions of s can be skipped. 
The stable sequence pruning can significantly speed up the 
incremental mining process. To determine whether a stable 
sequential pattern s is still frequent after updating, we can 
simply check its support count, which is available without 
any computations, against the new minimum support count 
in UD, i.e. minsup*|UD|. 
To determine whether 1-sequence s is stable, the 
increment-union of UD is used. If an item x is not in the 
increment-union, clearly, x appears in DB but not in db. In 
other words, the increment of any data sequence in <(x)>-pj 
does not contain <(x)>-end, which is {x}. Thus, <(x)> is a 
stable sequence. The increment-union of UD is obtained 
after the first scanning of UD. All the extensions of <(x)>, 
where x is not in the union, are free from support counting.  
In determining whether a candidate sequence s of size 
larger than one is frequent, its end-projection is checked. If 
s-end-pj is an empty set, s is stable so that s and all its 
extensions are eliminated from counting. Furthermore, the 
whole UD is not required for such end-projection 
validations. If s’ is an extension of s, then s’-pj is a subset of 
s-pj and s’-end-pj is a subset of s-end-pj. Therefore, the 
search space is shrunk iteratively during mining. We may 
skip the checking of the extensions of s once s-end-pj is an 
empty set. For example in Fig. 2, we only need to scan 
<d>-end-pj, {DS6, DS7, DS8,} to get <ad>-end-pj, which is 
∅. Thus, <ad> and all its extensions are stable so that 
further counting for these sequences are not required. 
The BSPinc algorithm is outlined in Fig. 4. BSPinc first 
scans UD to get all 1-patterns, their end-projections, and 
their DB-projections. The increment-union of UD is 
obtained in the same time. All the 1-patterns that do not 
appear in the increment-union are stable sequences. Except 
the stable sequences, the 1-patterns are to be backward 
extended, by the proposed sequence-extensions and itemset-
extensions, and recursively mined to determine whether the 
extensions are frequent in UD. 
 
<a a a> <b a a> <(b,a) a> <a b a> <b b a> <a (b,a)> <b (b,a)> <a a b> <b a b> <(b,a) b> <a b b> <b b b>
<a  a> <b a> <(b,a)> <a b> <b b>
<a> <b>
 
Fig. 3. Backward candidate generation: using items a and 
b for example 
Subroutine SS_pruning, abbreviated from stable sequence 
pruning, is used to verify whether a candidate sequence is 
stable first. If a candidate is found to be stable, its support 
count can be obtained from PDB without further support 
counting in UD. Moreover, any super sequence of the 
candidate is stable so that we may determine whether its 
super sequence is frequent immediately from PDB. We check 
the end-projection of a candidate sequence s’: if s’-end-pj = 
∅ then s’ is stable. The s’-end-pj can be obtained from 
scanning s-end-pj, where s is the postfix of s’. The support 
count of an unstable sequence is obtained from scanning its 
DB-projection. 
Note that the minimal support count changes because 
|UD| changes. Although the support count of a stable 
sequence is the same, the pattern has to be validated against 
the new minimum count. We generate the DB-projection for 
the un-stable sequence to get its support count. The final 
support count of an unstable sequence s is the sum of |s-end-
pj| and |s-DB-pj|. The candidate generation-and-test, 
improved with our backward mining and stable sequence 
pruning, is performed until no more candidates are 
generated. Figure 4 presents the BSPinc algorithm. 
B. Illustrating example of BSPinc 
Example: Given Ψ = {a, b, c, d, e, f}, minsup = 33%, DB, 
db, and UD in Fig. 2. The sequential patterns in DB is PDB = 
{<a>:5, <b>:3, <c>:3, <d>:3, <f>:3, <e>:3, 
<fa>:3 ,<(a,b)>:2, <ad>:3, <fad>:3, <fd>:3, <af>:2, <bb>: 2, 
<ca>:2}, where <ca>:2 means that the support count of 
<ca> is 2. Thus, the minimum support count in UD is 3. 
BSPinc mines sequential patterns in UD incrementally by 
the following steps. Table 1 lists several end-projections 
and DB-projections for references. 
Step 1: Scan UD once, we have the set of 1-patterns {<a>:5, 
<b>:7, <c>:3, <d>:6, <e>:5, <f>:5} and the increment-union 
{b, d, e, f}. Thus, sequences <a> and <c> are stable. We 
may directly determine whether the extensions of the two 
sequences are frequent by validating their support counts in 
PDB. Sequence <ca> (also <(b,a)>) is no longer frequent in 
UD since its support count is 2. <a>, <fa>, and <c> remain 
frequent in UD. We also know that <b>, <d>, <e>, and <f> 
are not stable. Therefore, the following steps are performed 
on 1-patterns <b>, <d>, <e>, and <f> subsequently. BSPinc 
calls SS_Pruning(<b>, {a, b, c, d, e, f}, {c, d, e, f}), 
SS_Pruning(<c>, {a, b, c, d, e, f}, {d, e, f}),  
67
two for the candidate to be frequent. Because the DB-
projections of both candidates <db> and <(f,b)> are of size 
one, they cannot be frequent and are pruned before counting.  
 
Step 2.3: The DB-projection of a candidate sequence, 
extending from <b>, can be obtained from <b>-DB-pj. The 
<ab>-DB-pj = {DS3}, <bb>-DB-pj = {DS3}, <cb>-DB-pj = 
{}, <eb>-DB-pj = {}, <fb>-DB-pj = {DS3}, <(d,b)>-DB-pj = 
{DS3}. Therefore, we have <ab>.count = 2+1=3, 
<bb>.count = 3+1=4, <cb>.count = 2, <eb>.count = 3, 
<fb>.count = 3, and <(d,b)>.count = 4.  
 
Step 2.4: Sequential patterns <ab>, <bb>, <eb>, <fb>, 
<(d,b)> will perform recursive extensions by calling 
SS_pruning each. Take <ab> for instance, SS_pruning(<ab>, 
{a,b,e,f}, {b,e,f}) is called. Sequences <aab>, <(e,a)b>, and 
<(f,a)b> are determined to be stable after we have validated 
their end-projections as empty. Sequences <aab>, <bab>, 
<eab>, <fab>, and <(b,a)b> are pruned before counting 
since their DB-projections’ sizes are smaller than two, 
whose value is the minimal support count minus |<ab>-DB-
pj|. The five candidates are prune because they are extended 
from <ab> so none can have a DB-projection of size larger 
than |<ab>-DB-pj|. The recursive call SS-pruning on <ab> 
returns without producing any sequential pattern. Similarly, 
we perform SS_pruning(<bb>, {a,b,e,f}, {e,f}), then 
SS_pruning(<eb>, {a,b,e,f}, {f}), SS_pruning(<fb>, 
{a,b,e,f}, {}), and finally SS_pruning(<(d,b)>, {a,b,e,f}, 
{e,f}). No sequential patterns are generated from these 
extensions. Consequently, the sequential patterns generated 
by SS_Pruning(<b>, {a, b, c, d, e, f}, {c, d, e, f}) are 
{<ab>:3, <bb>:4, <eb>:3, <fb>:3, <(b,d)>:4}. 
 
The SS-pruning, similar to the recursive invocations of 
steps 2.1 to 2.4, is then performed on <d>, <e>, and <f>, 
respectively. Finally, we have the sequential patterns in UD 
PUD = {<a>:5, <b>:7, <c>:3, <d>:6, <e>:5, <f>:5, <fa>:3, 
<ab>:3, <bb>:4, <eb>:3, <fb>: 3, <ad>: 3,<fd>:4, <fad>:3, 
<(d,b)>:4, <fd>:4 }. 
IV. EXPERIMENTAL RESULTS 
To assess the performance of the BSPinc algorithm, we 
conducted experiments using a 2G MHz AMD Sempron PC 
with 1024 MB memory. Synthetic dataset C10-T2.5-S4-
I1.25, generated by the IBM data generator [1], was used in 
the experiments. The dataset has 10,000 customers and N = 
10000. We used the open source IncSpan implementation [4] 
to cut data sequences to simulate the incremental mining 
environment. The modification ratio is the percentage of 
data sequences in UD that will be modified (to form DB and 
db). The SPAM used in our experiment was implementation 
without memory optimization. And the running time in low 
minsup is less efficient than PrefixSpan, obtained from 
IlliMine (http://illimine.cs.uiuc.edu). To mine the dataset 
C10-T2.5-S4-I1.25 with minsup 0.001, our SPAM took 
20.39 seconds while PrefixSpan only took 16.1 seconds. 
However, BSPinc outperforms IncSpan in the experiments 
of incremental sequence mining. 
We first compared the efficiency and memory use of 
incremental mining with different modification ratios. 
BSPinc worked an average of 2.5 times faster than IncSpan 
for every modification ratio, as shown in Fig. 5. When the 
modification ratio increases, the number of stable sequences 
decreases so that the total execution time increases. 
However, both SPAM and BSPinc may consume a 
considerable amount of memory. The amount depends on 
the total number of data sequences, the total number of 
items, and the lengths of data sequences. Given 10000 
customers, 10000 items, and sequence lengths 32, it may 
use up to 10000*10000*32*4=400 Mbytes. The peak 
memory used by SPAM was 458 MB for dataset C10-T2.5-
S4-I1.25 with minsup 0.001. When the modification ratio 
was 10%, the peak memory used by BSPinc was 459 MB. 
The stable sequence property presented in this paper 
greatly eliminated many candidates for support counting. 
The total number of candidate sequences in SPAM for 
dataset C10-T2.5-S4-I1.25 and minsup 0.001 are 25800K. 
As shown in Fig. 6, the number of candidate sequences to 
be tested in SPAM was reduced over 10 million. When the 
modification ratio is 0.5%, 25 million nodes were pruned. 
Figure 7 depicts the improvements of incremental mining 
over re-mining. It shows that incremental mining for both 
IncSpan and BSPinc are better than re-mining, while BSPinc 
improves more from backward mining. The total execution 
time over various minsups is shown in Fig. 8, which shows 
that BSPinc consistently outperforms IncSpan with respect 
to different minimum supports.  
V. CONCLUSION  
We have proposed a novel incremental mining 
methodology, backward mining, for incremental discovery 
of sequential patterns and presented the BSPinc algorithm. A 
unique characteristic in incremental pattern maintenance is 
the merging of data sequences in the updated database. Many 
patterns, whose support counts are not changed after 
updating, still have to be mined in traditional forward mining 
framework. The BSPinc algorithm enhanced SPAM and 
utilizes the stable sequence property to systematically prune 
a large number of candidates. The experimental results show 
that BSPinc outperforms the well-known IncSpan algorithm. 
We are currently applying the methodology for large 
sequence databases and stream sequence mining.  
ACKNOWLEDGMENT 
This research was supported partially by the National 
Science Council, Taiwan, under grant NSC-97-2221-E-035-
064. 
 
69
