 1
行政院國家科學委員會補助專題研究計畫成果報告 
適用於超大型資料集的異質分類模型評估、選取與集成之多項新方法及其於
具高分類效能的共同基金自動評選與推薦系統之應用 
Novel Methods of Heterogeneous Classification Model Evaluation, Selection 
and Ensemble and Their Applications to Automatic Mutual Fund Evaluation 
and Recommendation 
計畫編號： NSC 97-2221-E-022-012 
執行期限： 97 年 8 月 1 日至 98 年 10 月 31 日 
主持人：黃淇竣副教授  國立高雄海洋科技大學資訊管理系 
計畫參與人員：蔡瑞鴻  國立高雄海洋科技大學資訊管理系 
謝銘凱  國立高雄海洋科技大學資訊管理系 
王思健  國立高雄海洋科技大學資訊管理系 
張峻豪  國立高雄海洋科技大學資訊管理系 
楊順仁  國立高雄海洋科技大學資訊管理系 
 
一、中文摘要 
 
本研究旨在提出適用於超大型資料集
的 異 質 分 類 模 型 (Heterogeneous 
Classification Models)評估、選取及集成之
多項新方法，及其在共同基金自動評選與
推薦系統的應用。本研究所研究發展的異
質分類模型之評估、選取及集成多項新方
法具備數項優點，包括可在進行多個異質
分類模型的集成學習之前，先評估單一或
個別異質分類模型的分類正確率或分類效
能 (針對具超大型資料集的樣本分類問
題，則以估計單一或個別異質分類模型的
分類正確率或分類效能為主)，作為後續進
行分類模型選取以供異質分類模型集成系
統之用的依據；此外，結合田口式方法
(Taguchi Methods)可大幅減少異質分類模
型決策組合之評估實驗次數的優點，並以
訊號雜訊比為基礎，融入有效的異質分類
模型集成機制，同時考量多個異質分類模
型之間的分類模型多樣性 (Classification 
Model Diversity)概念，進而得以有效提升
或改善整體分類效能。本計畫之相關研究
成果已發表於國際知名期刊與學術研討
會，包括[34-36]等。 
 
關鍵詞：超大型資料集、異質分類模型評
估與選取、異質分類模型集成、共同基金
自動評選與推薦系統、田口式方法 
 
Abstract 
 
In recent years, methods of combining 
heterogeneous classification models have 
gained great popularity in machine learning 
and pattern recognition.  The outputs of 
heterogeneous classification models are 
combined to deal with the problem that each 
individual classification model might be 
suitable only for some specific real-world 
classification problems.  As a result, the 
overall performance (i.e., classification 
accuracy) can be improved by considering 
different classification behaviors of multiple 
heterogeneous classification models.   
In this research project, novel methods 
of heterogeneous classification model 
evaluation, selection and ensemble are 
proposed and investigated.  The 
classification performance of each individual 
heterogeneous classification model is 
evaluated.  Taguchi methods are then 
employed for heterogeneous classification 
model selection and ensemble.  Accordingly, 
a novel instance-selection based method is 
proposed to estimate the classification 
performance of each individual 
heterogeneous classification model precisely. 
Also, better heterogeneous classification 
models are selected for decision combination.  
Then, another novel feature-selection based 
 3
異質分類模型的評估、選取與集成學
習方法其主要精神為，事先評估或估計單
一或個別異質分類模型的分類正確率或分
類效能，以作為後續選取分類模型的依
據，接著將一組被選取的不同或異質分類
模型其分類決策判斷加以合併，形成集成
式或整體的分類決策，藉此提升或改善整
體分類效能(即提升整體分類正確率)。 
組合異質分類模型或預測模型主要的
動機在於突顯特定單一或個別分類模型在
特定分類問題領域的優越分類效能表現，
同時改善單一分類模型的分類或預測正確
率。另一個原因則是讓分類模型或預測模
型可擴展適用規模(Scaling)以處理超大型
資料集或超大型資料庫。在處理超大型資
料集或資料庫時，多數的分類模型或預測
模 型 都 會 由 於 計 算 上 的 複 雜
(Computationally Complex)因素而面臨記憶
體問題(Memory Problems)[8]。解決該問題
的作法之一則是將該資料集或資料庫分割
成多個子集合或子資料集，每個子集合則
用於訓練一個異質的分類或預測模型，最
後將多個異質分類或預測模型組合，以供
新樣本的分類或預測決策判斷之用。另
外，由於隱私權或資料集大小等因素，真
實世界中許多分散的資料集 (Physically 
Distributed Datasets)往往無法統整成單一
一個資料集合，同樣地，前述異質分類模
型或預測模型集成概念亦可適用，換言
之，在分散式環境下，每個不同的資料集
可用於訓練一個對應的分類模型或預測模
型，最後將多個異質的分類模型或預測模
型加以集成，供作整體分類或預測決策判
斷的依據。 
總結來說，異質分類模型的集成或組
合其定義即是在相同或不同的資料集上執
行不同的學習演算法，並將個別分類模型
的決策判斷結果加以集成，供作新樣本分
類之用。組合多個異質分類模型的基本概
念在於沒有任何一個單一或個別的分類模
型可對所有的分類問題皆產生最佳的
(Optimal)的分類效能[9]。 
由上得知，異質分類模型的評估、選
取與集成方法的有效與否，取決於以下幾
個重要的設計議題： 
(1) 事先評估或估計在分類模型集成
系統中各個單一或個別異質分類模型的分
類正確率或分類效能。在此，所有異質分
類模型的分類正確率被期望為越高越好。 
(2) 依據前述分類效能評估或估計結
果，從不同或異質的分類模型或學習機器
集合中挑選一個最佳或幾個較佳的分類模
型，供作建立異質分類模型集成系統之用。 
(3) 考量所有異質分類模型其分類錯
誤之間的關係或關聯性，換言之，即各個
異質分類模型之間的多樣性。在分類模型
集成系統中，所有單一或個別異質分類模
型被期望會產生不同或多樣化的分類錯
誤，以提高各個異質分類模型之間的多樣
性[10]。 
(4) 採用快速、有效的異質分類模型
之分類決策判斷合併機制，形成集成式或
整體的分類決策，以提升或改善整體分類
效能。 
如前所述，各個異質分類模型之間的
分類錯誤較好的情況為呈現不相關聯，也
就是說，每個異質分類模型皆是獨立的。
若各個異質分類模型之間的分類錯誤呈現
相關聯，則較不易確保最終的異質分類模
型集成系統能得到較好的分類效能。然
而，在很多情況下，每個異質分類模型之
間的分類錯誤會呈現不定程度的相依性，
相對地也就增加了建立有效的異質分類模
型集成系統之困難度。  
Evaluation and Selection 或
SelectBest[11]可謂是非常簡單但有效的分
類模型評估與選取方法。此方法首先評估
每一個異質分類模型在資料集或訓練集上
的分類效能表現，接著挑選分類效能表現
最佳的分類模型供作新樣本分類之用。
Dzeroski與Zenko等人[12]則主張此方法應
作為比較各種異質分類模型的基線或底線
(Baseline)。然而，Evaluation and Selection
或 SelectBest 方法無法保證可挑選到分類
正確率最高的分類模型[11]。 
另一種選取異質學習或分類模型的作
法則是考慮這些不同或異質的分類模型在
相近分類問題領域上的分類效能表現。此
類選取方法專注於各類分類問題領域的具
體特性描述，陸續被提出者包括一般以統
計 為 基 礎 (Statistical) 的
Information-theoretic Measures[13] ，
 5
統時，所得到的分類效能。 
 
三、研究方法 
 
本研究其研究方法詳細列述如下： 
在有關單一或個別異質分類模型分類
正確率的研究子議題方面，本研究擬將原
始訓練集合 T 隨機分割(Random Partition)
為 兩 大 小 相 等 的 樣 本 子 集 合 Tα 與
Tβ(Instance Subset)(此作法可視為 2-fold 
Cross-Validation[21]的一種變型)。其中一
個樣本子集合 Tα作為建立各異質分類模型
之用，而另一個樣本子集合 Tβ則作為評估
以訓練樣本集合 Tβ產生的單一或個別異質
分類模型其分類效能(即分類正確率)。相對
地，亦可將 Tβ作為建立各異質分類模型之
用，而 Tα 則作為評估以訓練樣本集合 Tβ
產生的單一或個別異質分類模型其分類效
能(即分類正確率)。 
假設利用樣本子集合Tα與Tβ可產生一
單一或個別的異質分類模型 CLi，則我們將
可計算 CLi 個別的分類效能，記為
Accuracy(CLi, Tβ)(或 Accuracy(CLi, Tα))，也
就是說，運用各樣本的類別已知之樣本子
集合 Tα與 Tβ驗證或評估異質分類模型 CLi
的分類效能。 
如前所述，在異質分類模型集成系統
中所有單一或個別分類模型之分類正確率
被期望為越高越好[22]。因此，本研究擬考
量將 Accuracy(CLi, Tβ)較高的分類模型 CLi
納入異質分類模型集成系統中，其比較高
低的基準可使用原始訓練集合 T 搭配每次
只剔除一個樣本的交互驗證方式( [23]，所
得到對應的分類正確率記為 Accuracy(CL, 
T)，其中 CL 代表利用原始訓練集合 T 所產
生的單一或個別分類模型。 
在前述隨機分割(Random Partition)原
始訓練集合 T 以進行單一或個別異質分類
模型的評估研究子議題方面，除了上述
2-fold Cross-Validation[23]之外，針對一特
定 的 分 類 問 題 (Specific Classification 
Problem)，本研究亦將考慮採用 10-fold 
cross-validation 交 互 驗 證 法 或 k-fold 
cross-validation 交互驗證法，評估每一個異
質分類模型在資料集(Data Set)或訓練集
(Training Set)上的分類效能表現。此作法是
一非常簡單且易於實現的異質分類模型分
類效能評估(Classification Model Evaluation)
方法。該方法將可作為比較各種異質分類
模型的基線或底線(Baseline) [24]。由於此
作法將無偏差地(Unbiased)檢視整個分類
問題的資料集(Data Set)或訓練集(Training 
Set)，所得到的異質分類模型分類效能評估
數值，將會相近或等同於該分類模型實際
進行新樣本分類所得到的分類效能。 
如前所述，本研究擬提出的不同於現
有方法、新穎的異質分類模型選取方法及
決策合併機制，以有效融合多個異質分類
模型的分類效能或表現，提升整體分類正
確率。該異質分類模型選取方法及決策合
併機制係以田口式方法(Taguchi Methods)
的相關概念為基礎： 
在 穩 健 式 實 驗 設 計 方 法 (Robust 
Experimental Design)[25]中，流程或產品可
藉由變動若干個相關的設計因子(Design 
Factor)而加以分析或改善。而田口式方法
(Taguchi Method)則為一著名的穩健式實
驗設計方法，它透過直交表 (Orthogonal 
Array)及訊號雜訊比(Signal-to-Noise Ratio 
(SNR))等機制，達到分析或改善的目的。
假設一個特定的標的(如流程或產品)有 d
個相關而不同的設計因子，則在完全因子
實 驗 設 計 (Full Factorial Experimental 
Design) 中 ， 將 有 2d 種 可 能 的 實 驗
(Experimental Trails)需要被考慮。 
直交表(Orthogonal Array)主要用來減
少 d 個相關設計因子所需要的實驗次數或
耗費，它可被視為是一個部分因子實驗設
計矩陣 (Fractional Factorial Experimental 
Design Matrix)，除了可提供所有設計因子
之間互動關係(Interactions)的完整分析之
外，同時包括每個設計因子在不同選擇情
形(Levels or Options)下公正、具平衡性及
系 統 性 的 比 較 (Fair, Balanced and 
Systematic Comparisons of Different Levels 
(or Options)) 。 在 此 二 維 矩 陣
(Two-Dimensional Array)中，每一行代表一
個特定的設計因子，而每一列則代表一個
特定的實驗，該實驗由所有設計因子在特
定的選擇情形(Levels or Options)下組合而
成。 
一個標準的二階直交表 (Two-level 
 7
進行後續分析。 
如前所述，在田口式方法 (Taguchi 
Method)中，訊號雜訊比 (Signal-to-Noise 
Ratio (SNR))主要用來決定每個設計因子
所有選擇情形的穩健性(Robustness)。本研
究針對每個異質分類模型，可藉由挑選
SNR值較高的選擇情形(即Level 1或Level 
0)，獲得高品質(High Quality)的特定標的
(在此即優越的整體分類效能)，以供異質分
類模型集成系統之用。 
最後，挑選所有 Level 1 的 SNR 值優
於 Level 0 的 SNR 值的異質分類模型，形
成最終的異質分類模型集成系統，供新樣
本分類決策判斷之用。以田口式方法
(Taguchi Method)相關概念為基礎，該最終
形成的異質分類模型集成系統預期將比單
一的異質分類模型，有更優越的整體分類
效能。 
綜 括 而 言 ， 田 口 式 方 法 (Taguchi 
Methods)(即穩健式實驗設計方法)針對本
研究擬提出的異質分類模型選取與集成方
法提供多項優點。舉例而言，假設有 r 個
異質分類模型，則可能會有 2r 種不同的決
策組合可供選取，這些多個決策組合也加
深了建立一具高分類效能的異質分類模型
集成系統的難度；然而，透過田口式方法
將可快速、有效地解決此一異質分類模型
決策合併的困難。另外，透過二階直交表
(Orthogonal Array)的使用，將可減少 r 個異
質分類模型所需要的實驗次數或耗費(即
實驗或測試 r 個異質分類模型決策合併成
效的次數)，二階直交表是一個部分因子實
驗 設 計 矩 陣 (Fractional Factorial 
Experimental Design Matrix)，除了可提供所
有異質分類模型之間互動關係(Interactions)
的完整分析之外，同時包括每個異質分類
模型在不同選擇情形(Levels or Options)下
公正、具平衡性及系統性的比較 (Fair, 
Balanced and Systematic Comparisons of 
Different Levels (or Options))。此外，在田
口式方法中的實驗次數(即計算決策合併
組合分類正確率 ACC(SEj, M)的次數)遠少
於進行完全因子實驗設計 (Full Factorial 
Experimental Design)所需要的實驗次數。
最後，在異質分類模型集成系統中，每個
異質分類模型的重要性(Significance)可明
確地透過 SNR 加以區分。此外，以田口式
方法(Taguchi Method)相關概念為基礎所
形成的異質分類模型集成系統預期將比單
一的異質分類模型，有更優越的整體分類
效能。 
以上各項優點也是本研究之所以採用
田口式方法作為進行異質分類模型的選取
(Selection) 及 決 策 合 併 (Decision 
Combination) 或 決 策 集 成 (Decision 
Ensemble)機制的主要原因。 
另外，本研究分別採用幾種不同的多
樣性測量方法，以考量所有單一分類器其
分類錯誤之間的關係或關聯性：(1)Q 統計
量 (The Q statistic)(2) 相 關 係 數 ρ
(Correlation Coefficient ρ)(3)雙誤測量法
(The Double-fault Measure)(4)不一致測量
法(Disagreement Measure)(5)廣義的多樣性
(Generalized Diversity)[28](6)Coincident 
Failure Diversity(CFD)[28](7) 熵 測 量 法
(Entropy Measure)E(8)Kohavi-Wolpert 變異
(Kohavi-WolpertVariance)[27]。 
在產生多個分類效能較佳的單一的分
類器之後，即需將各分類器的分類決策判
斷合併，以作成最後的分類決策。本研究
所採用與研究分析比較的決策合併方法包
括：(1)簡單投票法(Simple Voting)、(2)加
權投票法(Weighted Voting)、(3)加權投票
(Weighted Voting)後再進行動態的權重調
整(Dynamic Weight Adjustment)機制 
 
四、結果與討論 
 
針對本研究所提出適用於超大型資料
集的異質分類模型評估、選取及集成之多
項新方法，主要在進行多個異質分類模型
的集成學習之前，先評估單一或個別異質
分類模型的分類正確率或分類效能 (針對
具超大型資料集的樣本分類問題，則以估
計(Estimate)單一或個別異質分類模型的分
類正確率或分類效能為主)，作為後續進行
分類模型選取以供異質分類模型集成系統
之用的依據；此外，結合田口式方法
(Taguchi Methods)可大幅減少異質分類模
型決策組合之評估實驗次數的優點，並以
訊號雜訊比為基礎，融入有效的異質分類
模型集成機制，同時考量多個異質分類模
 9
Characterization[33]及 Stacking 法[29]等等
進行分類正確率、異質分類模型集成理
論、及整體複雜度等的各項比較分析，以
驗證本研究所提方法及其各項效能。各項
實驗結果已相繼發表於[34-36]。 
在此，由嚴謹的理論探討至完整的實
驗設計過程，本計畫亦遭遇了一些困難，
包括相關理論之實現、異質分類模型評
估、選取及集成相關演算法的實作與除
錯、以及與其他方法的比較等等課題。在
有效地掌握整個專案計畫的執行進度下，
方得以一一解決這些困難，順利完成本計
畫。 
 
五、成果自評 
 
根據本研究計畫內容，依序執行已完
成進度如下： 
 
(1) 已完成蒐集相關文獻、確定研究方
向、擬定研究目的、方法與步驟。 
(2) 有關理論分析與文獻探討部份，已完
成蒐集異質分類模型評估、選取與集
成方法及相關理論基礎、集成學習、
機器學習理論、資料探勘理論、圖樣
識別、統計學習(Statistical Learning) 
理論、異質分類模型設計、複雜度分
析(Complexity Analysis)與分類效能
之理論分析、田口式方法、直交表
(Orthogonal Array)、訊號雜訊比、最
近鄰居分類方法(或以樣本為基礎的
學習法則)、Bagging 法、Stacking 法、
及 Boosting 法 、 分 類 效 能 評 估
(Performance Evaluation)、異質分類模
型選取 (Heterogeneous Classification 
Model Selection)機制、異質分類模型
合併機制、Cross-Validation 以及各項
理 論 之 分 類 問 題 領 域 (Problem 
Domain)實務應用等相關重要文獻，
以作為本研究的理論基礎，與建構異
質分類模型評估、選取與集成新方法
研究及設計之參考。 
(3) 已完成建立所提異質分類模型評
估、選取與集成新方法的相關實驗環
境，以作為後續相關實驗及與其他現
有異質分類模型集成方法進行分析
比較的基礎。 
(4) 已完成研究、分析與設計異質分類模
型 的 分 類 效 能 評 估 (Performance 
Evaluation)、以田口式方法為基礎的
異質分類模型選取與集成方法，同時
亦研究分析有效的異質分類模型合
併機制，以及與所提新方法相關各項
測試(Test)與驗證。此外，並完成蒐集
整理不同應用領域之分類問題的樣
本集合，將本研究所提異質分類模型
評估、選取與集成方法所得到的分類
結果與人工處理所得到的結果、單一
或個別分類模型所得到的結果，以及
其他異質分類模型集成方法進行各
項比較與分析(包括理論分析、分類效
能分析及複雜度分析等)，評估分類正
確率及各項指標。 
(5) 完成發展本研究所提方法在各項重
要問題領域的可能應用，並驗證其分
類正確率及效能(包括與其他相關方
法的詳細比較與分析)。 
(6) 已將研究心得歸納結論，並提出未來
研究方向及建議。 
(7) 完成撰寫研究報告，並以「適用於超
大型資料集的異質分類模型評估、選
取與集成之多項新方法及其於具高
分類效能的共同基金自動評選與推
薦系統之應用」為研究主軸，將相關
研究結果發表在國際著名人工智慧
與機器學習領域 SCI 學術期刊。本計
畫之相關研究成果已發表於國際知
名期刊與學術研討會，包括[34-36]
等。 
 
本研究之具體成果如下： 
 
(1) 已完成蒐集相關文獻、確定研究方
向、擬定研究目的、方法與步驟。 
(2) 有關理論分析與文獻探討部份，已蒐
集相關重要文獻，以作為本研究的理
論基礎，與建構異質分類模型評估、
選取與集成新方法研究及設計之參
考。 
(3) 已完成建構所提新方法的相關實驗
環境 
(4) 已完成研究、分析與設計本研究所提
 11
[26] Y. Wu, A. Wu, and G. Taguchi, Taguchi 
Methods for Robust Design. New York: ASME, 
2000. 
[27] L. I. Kuncheva and C. J. Whitaker, “Ten 
measures of diversity in classifier ensembles: 
limits for two classifiers,” in Proc. of IEE 
Workshop on Intelligent Sensor Processing, pp. 
1-10, 2001. 
[28] L.I. Kuncheva and C.J. Whitaker, “Measures of 
diversity in classifier ensembles,” Machine 
Learning, 51, pp. 181-207, 2003. 
[29] D. H. Wolpert, “Stacked generalization,” 
Neural Networks, vol. 5, pp. 241-259, 1992. 
[30] P. Brazdil, C. Soares and J. P. Da Costa, 
“Ranking Learning Algorithms: Using IBL and 
Meta-Learning on Accuracy and Time Results,” 
Machine Learning, vol. 50(3), pp. 251-277, 
2003. 
[31] B. Pfahringer, H. Bensusan, and C. 
Giraud-Carrier, “Meta-Learning by 
Landmarking Various Learning Algorithms,” 
Proc. of ICML, pp. 743-750, 2000. 
[32] A. Kalousis and T. Theoharis, “NOEMON: 
Design, implementation and performance 
results of an intelligent assistant for classifier 
selection,” Intell. Data Anal, vol. 3(5), pp. 
319-337, 1999. 
[33] H. Bensusan, C. Giraud-Carrier and C. 
Kennedy, “A Higher-order Approach to 
Meta-learning,” in Proc. of the ECML'2000 
workshop on Meta-Learning: Building 
Automatic Advice Strategies for Model 
Selection and Method Combination, pp. 
109-117, 2000. 
[34] Chi-Chun Huang, Hsin-Yun Chang and 
Cheng-Hong Yang, “A Novel Grey-Based 
Feature Ranking Method for Feature Subset 
Selection,” Journal of the Chinese Institute of 
Engineers (JCIE)  
[35] 黃淇竣, 蔡瑞鴻, 吳家豪, 陳鴻瑞, 李健豪, 
“以貝氏分類器及 LOOCV 為基礎的特徵選
取方法＂, 第十三屆人工智慧與應用研討會
論文集, 台灣宜蘭, 2008.  
[36] Chi-Chun Huang and Hsin-Yun Chang, “An 
Experimental Comparison of Two Enterprise 
Voluntary Turnover Prediction Methods ＂ , 
WSEAS Transactions on Information Science 
and Applications.  
未來研究發展趨向。報告人在此會議中發表了一篇有關智慧型資料工程與自動學習
(Intelligent Data Engineering and Automated Learning)研究領域的文章，於 11 月 4
日的議程場次中發表，題目為一個以基因演算法及田口方法為基礎的特徵選取新方法(A 
Novel GA-Taguchi-based Feature Selection Method)。此篇文章主要目的為提出一個以田
口方法為主的智慧型資料工程與自動學習方法，可作為延伸本年度國科會研究計畫之重要基
礎。 
除此之外，報告人亦在數天的密集議程中，參與聆聽多個場次的論文發表。在各個場次
中，議程主持人皆具備了高度的專業能力及背景知識，有助於各發問者相關問題的釐清與議
題討論。在諸多的經驗分享與意見交換中，各項問題也得以深入的剖析並讓與會者獲得理
解。在演講主題部份，報告人主要對於來自南韓主講  “Toward Human-like Cognitive 
Systems” 的 Prof. Minho Lee 及主講 “Challenges of Gene-Gene Interaction Analysis in 
Whole Genomewide Association Studies” 的 Prof. Taesung Park 其十分精闢的見解留下
相當深刻的印象。 
總括來說，此行除了吸取新知外，更有助於進一步拓展研究視野，瞭解智慧型資料工程
與自動學習(Intelligent Data Engineering and Automated Learning)學術研究領域的研
究現況，同時也裨益於此次所發表論文的後續研究與修改，實獲益頗多。會議之中與會議後
與諸多學者廣泛討論與互相交換意見，亦是令人印象相當深刻的經驗。 
 
三、建議 
 
此次非常感謝國科會於專題研究計畫 NSC 97-2221-E-022-012 中補助報告人參與 2008
年智慧型資料工程與自動學習(Intelligent Data Engineering and Automated Learning)
國際學術會議的相關費用，除發表相關研究成果外，更有助於研究視野的拓展，收穫甚多。
另外，亦非常期盼國內相關學術機構或單位能承接此類大型國際學術會議的舉辦，積極
策劃邀請國外相關領域專家學者參與，除提供學術研究成果分享與意見交流的平台外，更得
以與國際接軌，提昇台灣相關學術研究在國際間的能見度。 
 
四、攜回資料名稱及內容 
 
1. 9th International Conference on Intelligent Data Engineering and Automated 
Learning - IDEAL 2008 會議議程表  
2. 9th International Conference on Intelligent Data Engineering and Automated 
Learning - IDEAL 2008 光碟版會議論文集一冊, 2008/11/2-2008/11/5 
3. 大會註冊單  
 
 
 
 
 
 
 
 
 
 
 
1   Introduction 
Over the past decade, different pattern classification approaches have been applied to 
classify new, unseen instances.  In a pattern classification framework [8], a set of 
training instances or examples, denoted as training set TS, is given.  Each instance or 
example consists of n features and a class label.  All features of each instance are 
generally considered during the classification process.  Various real-world pattern 
classification problems, however, involve unimportant or irrelevant features that 
typically have a marked effect on overall classification accuracy.  To improve 
classification performance, many feature selection and feature subset selection 
methods have been investigated [2][6][7][10][12][13][14][15][16][17].  These 
approaches focus on selecting important and relevant features from an original feature 
set and reducing the dimensionality in a particular pattern classification problem. 
Feature subset selection can be considered a search problem [12].  Each search 
state in the search space defines a possible feature subset.  If each instance in a 
specific classification problem has n attributes, the search space is formed by 2n 
possible or candidate feature subsets.  Clearly, an exhaustive search of the entire 
search space (i.e., 2n possible feature subsets) has a very high computational cost and, 
thus, is generally unfeasible in practice, even for a medium-sized p [17].  
Consequently, selecting a best feature subset for pattern classification from the entire 
search space is very difficult, in particular with regard to the tradeoff between high 
classification accuracy and small number of selected features. 
This paper presents novel hybrid GA-Taguchi-based feature selection method.  
Genetic Algorithms [9][18] are utilized with randomness for “global search” of the 
entire search space (i.e., 2n possible feature subsets).  Various genetic operations, 
including crossover, mutation, selection and replacement are performed to assist the 
search procedure in escaping from sub-optimal solutions [17].  In each iteration in 
the proposed nature-inspired method, the Taguchi methods [20][21] are utilized to 
help explore better feature subsets (or solutions), which are somewhat different from 
those in candidate feature subsets, for the next iteration.  In other words, the Taguchi 
methods are employed for “local search” of the entire search space (i.e., 2n possible 
feature subsets).  Consider that two feature subsets or solutions, b1 and b2, which are 
selected from a set of candidate feature subsets, have w different bits ( nw ≤ ).  The 
two-level orthogonal array, a central concept of the Taguchi method, is utilized in the 
proposed scheme for a well-organized and balanced comparison of two levels for the 
w features—a feature is or is not selected for pattern classification—and interactions 
among all features in a specific classification problem.  The signal-to-noise ratio 
(SNR) is then employed to determine the robustness of the w features.  Consequently, 
a superior candidate feature subset, which has high classification performance for the 
classification task, can be obtained by considering each feature with a specific level 
having a high signal-to-noise ratio (SNR).  If a particular target (e.g. process or 
product) has d different design factors, 2d possible experimental trials will need to be 
considered in full factorial experimental design.  Orthogonal arrays are principally 
utilized to decrease experimental efforts associated with these d design parameters.  
Finally, prior to the classification process, feature subset evaluation efforts can be 
significantly reduced based on the two-dimensional, fractional factorial experimental 
In robust experimental design [20][21], processes or products can be analyzed and 
improved by altering relative design factors.  As a commonly-used robust design 
approach, the Taguchi method [20][21] provides two mechanisms, an orthogonal 
array and signal-to-noise ratio (SNR), for analysis and improvement.  If a particular 
target (e.g. process or product) has d different design factors, 2d possible experimental 
trials will need to be considered in full factorial experimental design.  Orthogonal 
arrays are principally utilized to decrease experimental efforts associated with these d 
design parameters.  An orthogonal array can be considered a fractional factorial 
experimental design matrix that provides a comprehensive analysis of interactions 
among all design factors and fair, balanced and systematic comparisons of different 
levels (or options) of each design factor.  In this two-dimensional array, each column 
indicates a specific design parameter and each row represents an experimental trial 
with a particular combination of different levels (or options) for all design factors.  
The proposed scheme uses the commonly-used two-level orthogonal array for 
selecting representative features from the original feature set.  A general two-level 
orthogonal array can be defined as 
Lh(2d), (1) 
where d is the number of columns (i.e., number of design parameters) in the 
orthogonal matrix, kh 2=  ( dh > , )(2log dk >  and k is an integer) denotes the 
number of experimental trials, base 2 denotes the number of levels (or options) of 
each design parameter (i.e., levels 0 and 1). 
For instance, for a particular target that has 15 design parameters with two levels 
(i.e., levels 0 and 1), an two-level orthogonal array L16(215) can be generated (as 
shown in Table 1).  In this two-level orthogonal array, only 16 experimental trials 
are required for evaluation, analysis and improvement.  Conversely, all possible 
combinations of 15 design factors (i.e., 215=32768) should be considered in the full 
factorial experimental design, which is frequently inapplicable in practice. 
Once an orthogonal array is generated, an observation or objective function of each 
experimental trial can be determined.  The signal-to-noise ratio (SNR) is then 
utilized to analyze and optimize design parameters for the particular target.  
Generally, two signal-to-noise ratio (SNR) types, the smaller-the-better and larger-
the-better types [21], are typically utilized.  The signal-to-noise ratio (SNR) is 
utilized to determine the robustness of all levels of each design parameter.  That is, 
“high quality” of a particular target can be achieved by specifying each design 
parameter with a specific level having a high signal-to-noise ratio (SNR).   
3   A Novel GA-Taguchi-based Feature Selection Method 
In this section, a novel GA-Taguchi-based feature selection method is presented.  
Consider that a specific classification problem involves a set of m labeled training 
examples, defined by T= {t1, t2, …, tm}.  Each example has n features, defined by F 
= {f1, f2, …, fn}.  As mentioned, the search space S is composed of 2n candidate 
feature subsets.  In the proposed method for feature subset selection, each specific 
feature subset (i.e., a possible solution in S) is encoded as a string of n binary digits 
(or bits).  Each feature is represented by a binary digit (bit) with values 1 and 0, 
as those of b1 and b2.   
Step10. Repeat Steps 5-9 until a set of ⎣ ⎦4/* pcps  better solutions (i.e., 
⎣ ⎦4/* pcps  different t_bests), denoted as BS3, is obtained.   
Step11. Update CS by using better candidate feature subsets (i.e., solutions) in BS2 
and BS3.   
Step12. Repeat Steps 2-11 until a certain number of iterations have been completed.  
Consequently, the best feature subset, denoted as g_best in CS is utilized as 
the final feature subset for pattern classification.   
As mentioned, in the proposed method, genetic algorithms are employed with 
randomness for “global search” of the entire search space (i.e., 2n possible feature 
subsets).  Various genetic operations, including crossover (Steps 2-3), mutation 
(Step 4), selection and replacement (Step 11) are performed to assist the search 
procedure in escaping from sub-optimal solutions [17]. 
Notably, the goodness of each feature set or solution in the above-mentioned 
procedures (including Steps 7, 11 and Roulette Wheel selection method [18] in Step 2) 
is evaluated using the nearest-neighbor classification rule [4][5] with the leave-one-
out (LOO) cross-validation technique [3][19].  That is, classification accuracy with 
respect to training set T and a particular feature set or solution PS, denoted as ACC(T, 
PS), can be determined.  Leave-one-out cross-validation indicates that each instance 
in T is a test instance once and the other instances in T are considered corresponding 
training instances.  Thus, the nearest-neighbor classification rule is applied m times 
according to m instances and n features in V.  Next, average classification accuracy 
is calculated as a fitness evaluation function for analyzing the classification 
performance or goodness of the corresponding feature set PS. 
During each iteration in the proposed approach, a set CS of candidate feature 
subsets is obtained.  The Taguchi methods (Steps 5-10) can then help explore better 
feature subsets (or solutions), which are somewhat different from those in CS, for the 
next iteration.  Conversely, the Taguchi methods are employed for “local search” of 
the entire search space (i.e., 2n possible feature subsets).  As stated, consider that two 
solutions, b1 and b2, which are selected from BS2 (a set of ps perturbed offspring 
solutions), have w different bits ( nw ≤ ).  The two-level orthogonal array is utilized 
for a fair, balanced and well-organized comparison of two levels for the w features 
(two levels indicate that the feature is selected or not selected for pattern classification) 
and interactions among features in a specific classification problem.  The signal-to-
noise ratio (SNR) is then employed to determine the robustness of the w features.  
Consequently, a superior candidate feature subset, which has high classification 
performance for the classification task, can be obtained by considering each feature 
with a specific level having a high SNR.  Here, the larger-the-better characteristic is 
selected for calculating SNR as maximal classification accuracy is preferred in pattern 
classification.  Here, feature i with an SNR for level 1 greater than that for level 0 
indicates that the feature is will be selected in the candidate feature subset for pattern 
classification.  Conversely, feature i is removed from the candidate feature subset 
when the corresponding SNR for level 0 is greater than that for level 1.  As 
mentioned, if a particular target (e.g. process or product) has d different design factors, 
2d possible experimental trials will need to be considered in full factorial experimental 
design.  Orthogonal arrays are principally utilized to decrease experimental efforts 
