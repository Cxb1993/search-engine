一、前言 
光線的變化對於影像顏色(或影像灰階值)會造成非常大的影響，因此在不同的光
線照明下物體的外觀也會有相當程度的變化，心理物理學實驗結果亦顯示出當同一
人臉的影像受到不同的光線照明影響後，人類視覺系統很難分辨出該群影像是否屬
於同一人臉，同樣地如果沒有對學習和測試的人臉影像進行有效的光線補償過程，
電腦視覺系統將很難成功地辨識出真正的結果。 
二、研究目的 
本計畫發展適用於達到光線補償之裝置。更特定的說，係可用在處理數位影像照
片之光線補償裝置。光線補償前處理系統已經能克服不同的光線照明下物體的外觀
的顯示差異，近來多數的光線補償方法都是針對整張影像或大略取橢圓形的區域中
所有的灰階值進行處理，但是當強烈的光線照射頭髮或眉毛、背景光線的干擾以及
嚴重的陰影等情況發生時，這些方法的處理效果都不理想。 
三、文獻探討 
過去的十幾年至今中陸續有一些研究成果出現，我們先以 Adini 等人在 1997 年
所提出的人臉辨識研究成果舉例說明，他們提到光線的強弱程度(illumination)與光線
照射的方向(view direction)，對不同張人臉影像所造成的影響遠大於其中真正人臉特
徵的差異性。既然要控制光線的變化，基本的想法就是由推測光線的來源方向開始，
一般都利用 Lambertian 模型建構出影像的 3D光線照度空間。另外值得一提是上述
的光線照射模型並沒有考量陰影(shadow)的因素，由 Belhumeur等人所提出的研究成
果加強對陰影落在人臉上的因素進行處理，將原先的 3D 光線照度空間擴展為更詳
細也更複雜的模型，稱之為光線照射角錐(illumination convex cone)。Ishiyama 和
Sakamoto 等學者提出另一種 3D 光線照度空間基底稱為 geodesic illumination basis 
model，該方法建構出和頭部姿勢無關的 3D光線照度空間基底，因為以經建構出人
臉的 3D 資訊，在應用的時候，只要將該基底套用到人臉或是物體的視角上，便可
以有效地將光線照度推估出來，達到更佳的電腦視覺效果。Batur和 Hayes等學者則
發展出將線性空間模型切割的方法，他們將影像上的曲面法向量(例如圖三所示)接近
者群聚起來成為一個個區塊，利用 PCA 的方法取出重要的部分疊合原來的線性空
間，得到比較精確的 3D光線照度模型。 
四、研究方法 
我們提出的第一個構想是朝向人臉影像進行測試，由於背景和前景影像如果交錯在一
起會大大地影響光線校正方法的效能，故我們將先針對人臉區域的擷取下手，然後推導出
單獨架構於人臉區域的光線校正方法。我們採用影像處理技巧中的影像強化處理方法
（Enhancement）及形態學處理方法（Morphology），在輸入影像中找出所有可能是眼睛區
域的像素點，由於在影像中近似眼睛的部份並不會太多，如此一來便可以省下後續大量樣
本比對的運算時間，同時此前處理所需的時間也會小於節省下來的樣本比對運算時間。 
影像強化處理部分我們使用 3×3的二維遮罩（Mask），對輸入影像進行前處理，假設（x, 
y）是目前處理的中心點位置，x表示橫軸座標，y表示縱軸座標，w5 表示（x, y）對應的
遮罩係數，w1、w2、w3、w4、w6、w7、w8、w9 分別表示（x, y）的八個鄰近像素點的遮
罩係數，該運算法則如下： 
大小或旋轉角度為何，透過我們的偵測方法，真正的人臉區域皆可以正確而且迅速地被標
示出來。 
本計畫預集 3000 張人臉影像和 6000 張非人臉影像，為了配合前一個部分之人臉區域
產生的方式，我們以人工方式點選人臉影像的眼睛中心點位置，然後依照前一個部分的相
同做法產生相對應的人臉區域，再將其旋轉為正面影像並正規化成 19×19 大小的影像。這
些影像將被當作訓練 SVM人臉驗證器（Face Verifier）的正向資料庫，完成單張影像的
人臉區域擷取工作。 
本計畫是有關以人臉影像進行光線補償方法與系統，本演算法可以應用在人臉偵測系
統、人臉追蹤系統、人臉辨識系統、視訊監控系統、以物件為主的視訊編碼系統、人機互
動系統或其他型式之影像處理系統，作為前處理步驟或處理運算的一般模組，程式部分可
具體化成為電腦或其他系統可以執行的程式碼或韌體。如果為了達到快速的目的將可以改
採下列彩色空間下的做法。 
第一個步驟為輸入影像，該影像可由電腦的硬體裝置、記憶體、網路伺服器或其他可
能存放影像的地方取得，進一步地影像可以直接或透過網路從攝影機或視訊播放機即時地
傳送到電腦的主記憶體裏；接著決定人臉區域，就如之前所述近來多數的光線補償方法都
是針對整張影像或大略取橢圓形的區域中所有的灰階值進行處理，比較好的作法是先行找
出人臉區域，只利用人臉區域內的像點灰階值進行光線補償過程，人臉區域外的像點灰階
值則捨棄不用。在決定人臉區域之前先將每一個像點由原來的 RGB彩色空間轉換到 YCbCr
彩色空間，轉換法則如下列式子： 
0.299*R + 0.587*G + 0.114*BY =  
0.564 * (B - Y) bC =  
0.713 * (R - Y) rC =  
其中 Y表示色飽和度、Cb 和 Cr 表示色差或色度，R、G和 B分別表示紅、藍和綠色
的灰階值。 接下來檢測每一個像點的顏色是否為人的膚色，如果是則該像點就被判定為人
臉區域的一部分，下列式子是利用 Y值產生的判斷式及配合 Cb 和 Cr進行的膚色判斷的方
程式。 
使用線性模型來模擬影像上的光線變化時只能處理好光線變化的分佈亦是線性的情況，不
過使用線性模型有參數的個數較少及求取近似曲面所需時間較短的優點；上述的模型可一
般化成為(ax+by+c)n=G(x, y) 或甚至為 F(x, y)=G(x, y)型式來模擬影像上的光線變化，其中
n是近似曲面的空間維度，F(x, y)為一般化的近似曲面方程式表示法。 
 
),(),(
)(),(
yxFyxG
cbyaxyxG n
−
++− 或
GA
c
b
a
G
c
b
a
A
1−=
⎥⎥
⎥
⎦
⎤
⎢⎢
⎢
⎣
⎡
=
⎥⎥
⎥
⎦
⎤
⎢⎢
⎢
⎣
⎡
•
五、結果與討論 
在本研究中我們發展適用於達到光線補償之裝置，經由實驗結果顯示，使用一般的
類神經網路訓練的人臉辨識系統，在我們所收集的人臉資料庫以及網路上經常使用來驗證
效能的人臉資料庫中，可以有效地將辨識率由原先的 75.45%提升至 85.79%，接下來我們將
驗證更多類型的人臉辨識系統，以獲得更一般化的結論。 
由於整個計畫執行時間短，我們已經完成初步之核心技術，但尚未有足夠的時間開發
相關完整的雛形系統，希望未來後續研究能完成。不過，我們所開發之核心技術具有相當
學術價值，我們將規劃投稿到國際期刊。 
 
參考文獻 
 
[1] Y. Adini, Y. Moses, S. Ullman, Face recognition: the problem of compensating for 
changes in illumination direction, IEEE Trans. Pattern Anal. Mach. Intell. 19 (7) (1997) 
721–732. 
[2] P.W. Hallinan, A low-dimensional representation of human faces for arbitrarylighting 
conditions, in: Proceedings of the IEEE Conference on CVPR, Seattle, 1994, pp. 995–
999. 
[3] M. Bichsel, Illumination invariant object recognition, Proceedings of the International 
Conference on Image Processing, vol. 3, Washington, 1995, pp. 620–623. 
[4] P.N. Belhumeur, J.P. Hespanha, D.J. Kriegman, Eigenfaces vs. Fisherfaces: recognition 
using class speci.c linear projection, IEEE Trans. Pattern Anal. Mach. Intell. 19 (7) 
(1997) 711–720. 
[5] P.N. Belhumeur, D.J. Kriegman, What is the set of images of an object under all 
possible lighting conditions?, in Proceedings of the IEEE Conference on CVPR, San 
Francisco, 1996, pp. 270–277. 
[6] A.S. Georghiades, D.J. Kriegman, P.N. Belhumeur, Illumination cones for recognition 
under variable lighting faces, in: Proceedings of the IEEE Conference on CVPR, Santa 
Barbara, 1998, pp. 52–58. 
[7] A.S. Georghiades, P.N. Belhumeur, D.J. Kriegman, From few to many: generative 
models for recognition under variable pose and illumination, in Proceedings of the IEEE 
Conference on Face and Guesture Recognition, Grenoble, 2000, pp. 277–284. 
[8] R. Ishiyama, S. Sakamoto, Geodesic illumination basis: compensating for illumination 
variations in anypose for face recognition, Proceedings of the 16th International 
Conference on Pattern Recognition, vol. 4, Quebec, 2002, pp. 297–301. 
[9] A.U. Batur, M.H.I Hayes, Linear subspaces for illumination robust face recognition, 
Proceedings of the IEEE Conference on CVPR, vol. 2, Hawaii, 2001, pp. 296–301. 
[10] A.Z. Kouzani, F. He, K. Sammut, A. Bouzerdoum, Illumination invariant face 
recognition, IEEE International Conference on Systems, Man, and Cybernetics, vol. 5, 
San Diego, 1998, pp. 4240–4245. 
[11] W. Zhao, R. Chellappa, Illumination-insensitive face recognition using symmetric 
shape-from-shading, in Proceedings of the IEEE Conference on CVPR, Hilton Head, 
