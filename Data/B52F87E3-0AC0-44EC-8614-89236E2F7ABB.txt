2Complex-valued Neural Networks for Image Recognition under High
Noise Environment
Abstract－In this report, new design methods for the complex-valued multistate Hopfield
associative memories (CVHAMs) are presented. We show that the well known projection rule
proposed by Personnaz et al. can be generalized to complex domain such that the weight
matrix of the CVHAM can be designed by using a simple and effective method. The stability
of the proposed CVHAM is analyzed by using energy function approach which shows that in
synchronous update mode the proposed model is guaranteed to converge to a fixed point from
any given initial state. Moreover, the projection geometry of the generalized projection rule is
discussed. In order to enhance the recall capability, a strategy of eliminating the spurious
memories is also reported. The validity and the performance of the proposed methods are
investigated by computer simulation.
Index Terms－Complex-valued Hopfield associative memory, generalized projection rule,
spurious memory.
I. INTRODUCTION
Conventional neural networks are usually based on two-state neurons. Although binary
representations are widely used in engineering applications for their simplicity, multivalued
representation [4] is a much relevant and direct approximation to real world data. In [5] the
authors proposed a complex-valued multistate Hopfield associative memory (CVHAM) that
is capable of storing and recalling gray-scale images. It can be referred to as a modified
Hopfield network [1] having complex-signum activation functions and complex weighting
connections. The CVHAM is an auto-associative memory that stores complex-valued
prototype vectors mkX k ,...,1,  where m is the number of the prototype vectors and
Tk
N
kkk xxxX )( 21  . The components sxki are all quantization values which are defined by
  NiKvjx Kvki ,...,1/2exp 10   . (1)
The resolution factor K divides the complex unit circle into K quantization values so that
kix ki ,1 . In the original model [5] the m prototype vectors are stored in the connection
weights according to the generalized Hebb rule,
4render each prototype vector as a strict local minimum of a quadratic energy landscape.
However, as the dimension N increases, these methods become time and memory consuming
when compared to the generalized Hebb rule [6]. Moreover, in simulation (see later) we find
that the recall capability of CVHAM by using the above energy design method (EDM for
short hereafter) is effective only when the resolution factor K is small. If K is large, then the
recall capability will fall sharply. In the following section we generalize the projection rule
proposed in [2] and show that the generalized projection rule (GPR) can be used to improve
the recall capability of the CVHAM.
II. A GENERALIZED PROJECTION RULE (GPR) FOR CVHAMs
If we can find a matrix S such that
mkXSX kk ,...,1,  (6)
then each of the prototype vectors will be a fixed point defined in (5). Hereinafter let V
be a pointwise function that operates on each component of V as in (4). The condition (6) is
more conservative than
  mkSXX kk ,...,1,  (7)
since the transformation between prototype vectors is strictly linear in the former case.
Let )( 21 mXXX  , then (6) yields the matrix equation
.S (8)
One solution of this set of Nm linear equations is given by
,IS  (9)
where I denotes the pseudoinverse [2],[9] of . Let us assume that mXXX 21 are linearly
independent so that  has full column rank, i.e., (  ) is invertable (  denotes the
conjugate transposition of  ). Then, I can be computed by using a simple matrix
equation:
.)( 1  I (10)
In this case,
  1)(S (11)
will be a Hermitian and nonnegative definite matrix. Note that S in (11) is constructed by
using simple pseudoinverse technique. The matrix S can be computed by an iterative
6that E is bounded from below as long as ijs is bounded for all i and j. Therefore, in
synchronous mode and starting with any initial vector, the CVHAM always converges to a
fixed point. The proof is thus complete.
Theorem 2: Global energy minima are formed at the prototype states for the GPR.
Proof: The energy of a prototype vector kX and its negative kX is given by
2
)(
2
1
)()(
N
SXXXEXE kkkk   . (13)
Let N be the set of vectors whose components sxi satisfy
  10/2exp  Kvi Kvjx  (14)
Each vector in N is located on a complex discrete hyper-sphere surface since its Euclidean
distance to the origin is N . Moreover, let SL be the subspace spanned by the prototype
vectors mXXX ,,, 21  . Since S is an orthogonal projection matrix that projects any vector
onto SL , SLVSX  . For any NX  , we can represent it in the form 0XVX  where 0X
is a vector in the subspace orthogonal to SL . Then its energy is given by
 
2
2
1
2
1
2
1
)(
2
1
)(
2
2
0
N
X
V
VXV
SXXXE







Above inequality follows from the Pythagorean theorem [10] that
2
0
22
XVX  . (15)
The proof is thus complete.
In our experiment we find that the proposed GPR shows better performance than the EDM
does not only in the computation efficiency but also in the recall capability. Figs. 1 and 2 give
a comparison of recall capability by training CVHAMs of fixed size N=30. For a fixed K, the
components of the prototype vectors are generated from random complex random values
chosen from the K quantization values in (14) with equal probabilities. The sizes of the
training set being studied are m=5 and 10, respectively. After training was carried out for a set
of training vectors, the CVHAM is tested with a test set which contains 10m noisy versions of
the prototype vectors (ten for each prototype vector). Each noisy version of a specific
prototype vector is generated by replacing n components of the original prototype vector by
some random complex values chosen from the other K-1 quantization values. For each
8the recall capability can be improved by the following two-phase projection rule as follows.
In phase I, projection dynamic (12) is performed until a fixed state fX is reached. In phase
II, )( ff SXV  is checked. If ,NfV  then a new initial state Xˆ is assigned where
NX ˆ is the hyper-sphere surface point close to fV . Above two phases iterate alternatively
until .NfV 
The main idea in phase II involves moving a spurious memory fX to a nearby state Xˆ .
This remedy provides a trapped spurious memory another chance to project into SL . In other
words, it is desirable that all final states satisfy )( NSff LVX  . Moreover, the movement
from fX to Xˆ should be kept minimal so that a correct recall would not be disturbed. In
the absence of available analytical methods to find the best Xˆ , we propose choosing Xˆ from
the 1-neighborhood [6] of fX . That is, Xˆ can be obtained by randomly choosing one
component of fX , then increasing or decreasing its phase angle by K/2 .
The proposed modified projection rule (MPR) is summarized as follows:
Step 1: Given an initial state X.
Step 2: Perform the projection dynamic (12) until the fixed state }{ ff VX  is reached.
Step 3: If NfV  , then stop. Otherwise, obtain a new initial state Xˆ by randomly choosing
one component of fX , increasing or decreasing its phase angle by K/2 . Then,
assign the new initial state X= Xˆ and go to Step 2.
IV. COMPUTER SIMULATION
A. Recall Capability Test
Recall capabilities of CVHAM with the GPR and the MPR are both investigated. The
network size is fixed at N=50. For a fixed K, the components of the prototype vectors are
assigned to complex random values from the K quantization values in (14) with equal
probabilities. The sizes of the training set being studied are m=15, 21, and 25, respectively.
Each point in these figures is obtained by using the same procedure as in Section. II. As seen
from Figs. 4~6, the recall capability degenerates as K increases. However, the MPR yields an
improvement over the GPR. For example, when m=15 and K=4 the GPR has over 98% of
success if the number of corrupted components 7n . It can be improved to 9n by using
10
V. CONCLUSION AND SELF-EVALUATION
The generalized projection rule for the complex-valued multistate Hopfield associative
memory (CVHAM) has been proposed. We have shown that the well known projection rule
can be generalized to complex domain such that the weight matrix of the CVHAM can be
designed by using a simple and effective method. The stability property of the CVHAM
under synchronous mode is discussed by using the energy function approach which shows
that the CVHAM is guaranteed to converge to a fixed point from any initial state. We also
analyzed the projection geometry of the GPR. Since the projection dynamic sometimes
converges to a spurious memory that does not belong to the subspace spanned by the
prototype vectors, a strategy (MPR) to eliminate such spurious memories is also reported.
Computer simulation shows that the recall capability of the CVHAM is improved markedly
by using the proposed methods. Comparing with the existing methods [4],[6],[11]-[13] for
storing and recalling gray-scale images, the proposed method has the following features:
 Learning is simple and fast.
 No complicated transformation or extra coding process is required.
 Number of required connection weights is small.
Table III summarizes the number of required connections for different methods. It is obvious
that the proposed method needs a less number of connection weights. Therefore, the GPR and
MPR are good methods for storing gray-scale images by neural networks.
Results of this project have been published in the following journal
D. L. Lee, “Improvement of Complex-valued Hopfield Associative Memory by
usingGeneralized Projection Rules,” IEEE Trans. on Neural Networks, Vol 17, No. 5, 2006,
pp. 1341-1347, Sept. 2006. ( SCI, EI)
REFERENCES
[1] J. J. Hopfield, ''Neurons with graded response have collective computational properties
like those of two-state neurons,'' in Proc. Nat. Acad. Sci. USA, vol. 81, pp. 3088-3092,
1984.
[2] L. Personnaz, I Guyon, and G. Dreyfus, “Colective computational properties of neural 
networks: new learning mechanisms,” Phys. Rev. vol. A34, pp. 4217-4228, 1986.
[3] L. Personnaz, I Guyon, G. Dreyfus, and G. Toulouse,“A biologically constrained learning
mechanism in networks of formal neurons,”J. Statistical Phys., vol. 43, pp. 411-422,
May 1986.
12
Fig.3 Geometrical representation of the
spurious memory of type (ii)
Fig. 4. Recall capability when K=4 (+: GPR,
o:MPR)
Fig. 5. Recall capability when K=8 (+:GPR,
o: MPR)
Fig. 6. Recall capability when K=12(+:GPR,
o:MPR)
Fig. 7. Vector length trajectories of the GPR
Fig. 8. Vector length trajectories of the MPR
