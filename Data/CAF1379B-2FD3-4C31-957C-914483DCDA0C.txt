- 2 -
本計畫已開發出四種新型的機器學習方法：
1)任意森林基因選擇技術 (random forest gene selection,RFGS)
2)支持向量樣本技術(support vector sampling technique,SVST)
3)基因演算法基因選擇技術 (Genetic Algorithm Gene Selection, GAGS)
4)多工支持向量樣本技術(multi-task support vector sample learning,
MTSVSL)
本計畫所開發的技術已成功應用在白血病(leukemia)和前列腺癌(prostate
cancer)上，未來也將進一步應用在其他癌症上。
本計畫的年度執行成果相當傑出、目前已有 8篇相關論文發表 (3 篇 SCI、
4 篇 EI、1 篇 Journal)
關鍵字：醫學資訊、資料探勘、機器學習、基因篩選、基因表現、癌症診斷、
癌症分類、智慧系統、白血病、前列腺癌
Novel Approaches for the Prediction of Cancer Classification
Abstract
In the past decade, DNA microarray technologies have had a great impact on
cancer genome research; this technology has been viewed as a promising approach in
predicting cancer classes and prognosis outcomes. In this paper, we proposed two
systematic methods which can predict cancer classification. By applying the genetic
algorithm gene selection (GAGS) method in order to find an optimal information gene
subset, we avoid the over-fitting problem caused by attempting to apply a large
number of genes to a small number of samples. By extracting significant samples
(which we refer to as support vector samples because they are located only on support
vectors), we allow the back propagation neural network (BPNN) to learn more tasks.
We call this approach the multi-task support vector sample learning (MTSVSL)
technique. We demonstrate experimentally that the GAGS and MTSVSL methods
yield superior classification performance with application to leukemia and prostate
cancer gene expression datasets. Our proposed GAGS and MTSVSL methods are
novel approaches which are expedient and perform exceptionally well in cancer
diagnosis and clinical outcome prediction.
Keywords: cancer classification, multi task learning, support vectors, back
propagation neural networking, gene expression profiling, genetic algorithm gene
selection
1. Background
DNA microarray technologies, which measure the expression level for thousands of gene
expressions simultaneously, have had a great impact on cancer genome research over the past few
years. Currently, microarray-based gene expression profiling has been viewed as a promising approach
in predicting cancer classes and prognosis outcomes [1]. In most cases, cancer diagnosis depends on
the use of a complex combination of clinical and histopathological data. However, it is often difficult
- 4 -
0< i<C, where C > 0 is the penalty parameter of the error term, the Lagrange problem DL is subject
to



j
i
iiY
1
0
Therefore, iDL  , and under this circumstance, imeans that the ith data has a degree of influence
to the hyperplane. When i = C, the Lagrange problem DL is subject to
i
j
mi
mimimi XXYY  
1,2
1
DL is negative, and therefore, imeans the ith data is incorrectly classified by the hyperplane.
Each i determines how much each training example influences the SVM function. Because the
majority of the training examples do not affect the SVM function, most of the iare 0. We can then
infer that these support vectors should contain the desired strong classification information. By
extracting only the samples located on the hyper plane, we can run a gene selection algorithm that
better identifies biologically relevant genes.
We subsequently applied our method to two microarray datasets of leukemia and
prostate cancers. We found 32 support vector samples in 72 leukemia samples and 44
support vector samples in 102 prostate cancer samples. After reducing the original
samples by almost 55%, we used these samples to find the most informative genes
through gene selection algorithms.
2.2. Signal-to-noise (SNR) gene selection method
Gene selection is widely used to select target genes in the diagnosis of cancer. One of the prime
goals of gene selection is to avoid the over-fitting problems caused by the high dimensions and
relatively small number of samples of microarray data. Theoretically, in cancer classification, only
informative genes which are highly related to particular classes (or subtypes) should be selected. In this
study, we use signal-to-noise ratio (SNR) as our gene selection method [16, 17]. For each gene, we
normalized the gene expression data by subtracting the mean and then dividing by the standard
deviation of the expression value. Every sample is labeled with {+1,-1} as either a normal or a cancer
sample. We use the formula (3) to calculate each gene’s F score.
)()(
|)()(|
)( 11
11
ii
ii
i gg
gg
gF 





(3)
The and  are the mean and standard deviation of the samples in each class
(either +1or -1) individually. We rank these genes with an F score and then select the
top 25, 50, 100, and 150 gene set as the features.
2.3. Genetic algorithm gene selection (GAGS) method
In additional to statistic methods, searching algorithms are another way to discern the informative
genes from large gene datasets. The Brute force search method maybe the most basic type among
searching algorithms; it enumerates all possible solutions and then checks whether each solution
satisfied the problem's statement (e.g. high accuracy for a specific classifier). This algorithm may find
the optimal informative gene subset, but the cost in terms of time is too high. The genetic algorithm
should provide a better solution [20].
The genetic algorithm is an effective algorithm in searching complex high-dimensional space and in
finding the optimal solution. In this proposal, we develop a genetic algorithm gene selection method
that can find the most informative gene set (see Figure 1). The genetic algorithm is a type of
evolutionary computing method widely used in simulating the process of natural selection. The basic
concept behind the genetic algorithm is consisted of four steps: population, reproduction, crossover and
mutation. Before beginning the genetic algorithm, we randomly separate the gene expression data into
- 6 -
where ATR is the predictive accuracy of the training dataset using the support vector machine and
where ATV is the predictive accuracy of the validation dataset. We allow only the chromosomes which
possess a high fitness score to progress to the reproductive phase. The reproduction rate may influence
the variety of chromosomes. If the variety of chromosomes is low, the genetic algorithm may catch a
local optimum solution instead of a global optimum solution. To avoid this situation we set the
reproduction rate at 40% in the primary stage and at 20% in last stage.
Crossover: After the reproduction phase, offsprings are created by crossing over the parent
chromosomes at the cross point. The single –point crossover approach was used in this paper. The
crossover point is randomly generated and two chromosomes are randomly selected to do so at this
point (see Figure 3).
Figure 3. The illustration of the crossover step
Mutation: To increase the possibility of finding the optimal solution, a mutation phase is applied.
We will set P and p as the mutation possibility of each chromosome and each gene respectively. In our
genetic algorithm, every chromosome may generate a random number R, and if R > P then this
chromosome will be added to the mutation pool. Every gene in these chromosomes may also generate a
random number r, where if r > p then the gene will be replaced with another randomly selected gene
from the F-gene pool. The F-gene pool contains the top 20% of F-value genes. Using this approach we
have a higher chance to obtain not only better classification accuracy but also a significant informative
gene set. We set a high mutation possibility in the primary stage and low mutation possibility in the last
stage (Figure 4).
Figure 4. The illustration of the mutation step
The Figure 5 shows a broken-line graph of mean fitness scores. The x-axis represents the training
stage and the y-axis represents the fitness score. In the primer stage, we can see that the line of fitness
drastically increases before the fifth stage. The mean fitness score of the initial chromosomes is less
- 8 -
Figure 6. Three back-propagation network structures for learning
The support vector sample’s feature is mentioned in section 2.1. Most classifier just learned the
main task; however in our experiment, we find that the bias which is generated by learning the second
task can improve the classifier performance. The ratio of these two biases is set as
biasondbiasmain _sec*1.0_*9.0  .
The ratio of the second bias cannot be set too high since it may harm the performance of the main
task.
Table 1. The Pseudo Code of MTSVSL
2.5. Cross validation method
As Ambroise and McLachlan pointed out that the performance of classification maybe
overestimated by using Leave-out-out method, therefore, we verify our experiment using random
average 3-fold method. This random average 3-fold method randomly separates dataset into 3-fold and
repeat validation 100 times in order to get the impartial performance results for our model.
3. Results and Discussions
In this section, we compare the results from MTSVSL with the results from the basic BPNN. To
demonstrate the benefits of the MTSVSL method, we experiment it for leukemia and prostate cancer
gene expression datasets. We applied random average 3-fold cross validation method to get the
Input: Training
data RXYgGsSYxX SSSG  },1,1{,...1,...1},,{
s=number of samples, g= number of genes, base learner= BP network
Output: predict result and performance metrics
1. begin
2. for i = 1 to S
3. do normalize X
4. end
5. Set K = linear function
6. do train )),(( SS YXKSVM
7. sv = extract support vectors from training SVM
8. for i = 1 to S
9. svs = extract support vector samples by sv from all samples
10. end
11. divide the X to be support vector samples and non support vector
samples
12. set two learning tasks that {svs or non-svs} and {normal or abnormal}
13. use MTL approach to learn the two tasks by base learner
14. estimate the predict accuracy on test data
15. end
- 10 -
150 76.58 79.71 80.59 80.77 85.22 82.06
When GAGS method is used (see Table 5), traditional BPNN method has an average accuracy of
84% in all the range of gene number. Our MTSVSL generates a much better accuracy with an 88%
average that is above 4% better. Our proposed MTSVSL method again improves all classification
performance (sensitivity, specificity, and accuracy) in all the range of gene numbers selected.
Table 5. Comparison of prostate cancer classification performance between BPNN and
MTSVSL using GAGS method
Number
of top
genes
GAGS+BPNN GAGS+MTSVSL
sensitivity specificityaccuracy sensitivity specificityaccuracy
25 81.48 92.86 85.36 84.00 87.50 85.36
50 80.77 86.67 82.92 90.91 84.21 87.80
100 86.36 78.95 82.92 88.00 93.75 90.24
150 90.91 84.21 87.80 88.00 93.75 90.24
4. Conclusions
In the past decade, DNA microarray technologies have had a great impact on cancer genome
research; this technology has been viewed as a promising approach in predicting cancer classes and
prognosis outcomes. In this paper, we proposed two systematic methods which can predict cancer
classification. By applying the genetic algorithm gene selection (GAGS) method in order to find an
optimal information gene subset, we avoid the over-fitting problem caused by attempting to apply a
large number of genes to a small number of samples. By extracting significant samples (which we refer
to as support vector samples because they are located only on support vectors), we allow the back
propagation neural network (BPNN) to learn more than one task and then regulate these learning errors
to improve the performance of the basic BPNN. We call this approach the multi-task support vector
sample learning (MTSVSL) technique.
We demonstrate experimentally that the GAGS and MTSVSL methods yield superior classification
performance with application to leukemia and prostate cancer gene expression datasets. Our proposed
GAGS and MTSVSL methods are novel approaches which are expedient and perform exceptionally
well in cancer diagnosis and clinical outcome prediction.
5. Acknowledgment
The authors thank the National Science Council for its financial support for project NSC 99-2221-
E-320-002 and Tzu Chi University for its financial support for project TCRPP99018.
6. References
[1] Statnikov A, Aliferis CF, Tsamardinos I, Hardin D, Levy S, “A comprehensive evaluation of
multicategory classification methods for microarray gene expression cancer diagnosis,” 
Bioinformatics , 2005, vol. 21, pp. 631–643
[2] Ramaswamy S. et al., “Multiclass cancer diagnosis using tumour gene expression signatures,” 
Proc. Natl Acad. Sci. USA 98, 2001, pp. 15149–15154.
[3] Tamayo P, Slonim D, Mesirov J, Zhu Q, Kitareewan S, Dmitrovsky E, et al., “Interpreting paterns 
of gene expression with self-organizing maps,” Proc. Natl. Acad. Sci. USA,  2000, vol. 96, pp. 
2907–2912.
[4] Xu S, "Data Mining Using Higher Order Neural Network Models With Adaptive Neuron
Activation Functions", IJACT : International Journal of Advancements in Computing Technology,
2010, Vol. 2, No. 4, pp. 168-177
[5] Li L, Weinberg R C, Darden T A, Pedersen L G, “Gene selection for sample classification based
on gene expression data: study of sensitivity to choice of parameters of the GA-KNN method,” 
Bioinformatics, 2001, vol. 17, pp. 1131-1142.
[6] Berthold F, Schwab M, Antonescu CR, Peterson C, and Meltzer PS, “Classification and diagnostic
prediction of cancers using gene expression profiling and artificial neural networks,” Nature 
Medicine , 2001, vol. 7, pp. 673-679.
表 Y04
行政院國家科學委員會補助國內專家學者出席國際學術會議報告
100 年 7 月 30 日
報告人姓名 陳信志 Austin H. Chen 服務機構
及職稱
慈濟大學 醫學資訊系(所)
助理教授
時間
會議
地點
會議自100年5月27日起至
100年5月29日止，合計3天
[台灣時間], 地點在Xi’an
Hotel, Xi’an, China
本次會議帶二位研究生參加
並以英文演講
本會核定
補助文號
NSC 99-2221-E-320-002
會議
名稱
2011 3rd International Conference on Computer Design and Applications
(ICCDA 2011)
發表
論文
題目
1篇英文論文發表(口頭) “Genetic algorithm for optimizing SVM parameters in
the improvement of breast cancer prognosis accuracy”
附
件
三
國科會補助計畫衍生研發成果推廣資料表
日期:2011/10/03
國科會補助計畫
計畫名稱: 子計畫三: 開發以臨床生醫檢測資訊及基因表現分佈為基礎之癌病評估分析
系統
計畫主持人: 陳信志
計畫編號: 99-2221-E-320-002- 學門領域: 醫學資訊
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
應邀擔任各種期刊及國際會議的 Keynote speakers, Editors, Board members, 
or Reviewers. 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
