2行政院國家科學委員會專題研究計畫成果報告
智慧型動態與複雜背景之物體與人臉偵測的安全監視系統(I)
Intelligent Surveillance System of Motion and Face Detections
in Complex and Dynamic Backgrounds (I)
計 畫 編 號：NSC96-2221-E-211-020
執 行 期 限：96 年 08 月 01 日至 97 年 07 月 31 日
主 持 人：陳佑冠 華梵大學電子系
計畫參與人員：高國智 華梵大學電子系
一、摘要
一般的智慧型影像監控系統，通常僅能
運用在靜態背景的環境下，也就是監視影像的
背景是固定不動的，若所監視的環境背景是波
動的海浪，或是隨風晃動的花草樹葉，傳統影
像的處理方式，往往無法達到預期的效果。本
研究計畫利用熵值的理論，結合高效率 Σ–Δ
濾波器之入侵物體偵測演算法，提出一個新
的動態背景入侵物體偵測演算法。再利用移動
平均線的理論，設計一個移動平均門檻值來求
得發佈警報的序列。經由實驗證明，本研究計
畫所提出之方法確實可以在靜態與變動背景
的環境下，精確的偵測到移動物體的入侵而發
出警報。所以所提出之演算法比其它方法少錯
誤的警報，因此其可以被廣泛的應用在山防、
海防或空防的警戒系統裡，以減少因誤報所浪
費之社會資源。
關鍵詞：安全監視系統，入侵物體偵測，熵，
警報發佈，影像處理，電腦視覺
Abstract
The traditional automatic smart image
surveillance system can usually be used in the
environment with still background. That is, the
background image must not contain the moving
objects. If there is waving ocean, waving tree,
floating cloud, or raining in the background
image, the traditional methods do not work well.
In order to improve this problem, this project
will develop a new motion detection method
based on the theory of entropy and combined a
multi-periods Σ–Δ background estimation
algorithm. Based on the theory of moving
average, a moving thresholding method is
designed in this project to obtain a sequence of
alarm announcements. Evaluation results show
the proposed algorithm succeeds in motion
detection with dynamic or still background from
the surveillance video. The algorithm also
reduces error alarms much more than other
schemes, which makes it better suited for real
surveillance system and avoids wasting
resources of society.
Keywords: surveillance system, motion
detection, entropy, alarm announcement,
image processing, computer vision
二、報告內容
1. 簡介
隨著影像監視設備的進步，以及各種影像
處理方法的提出，使得智慧型影像監控系統的
應用越來越廣泛。而入侵物體偵測的警報是智
慧型監控系統最重要的功能，因為正確之入侵
物體偵測的警報，可避免因為誤報所造成之人
力與社會資源的浪費。所以為達到準確對對移
動物體做追蹤、辨識…等功能，依賴正確的入
侵物體偵測之警報是任何智慧型影像監控系
統所必備的。
當所監視之每一個畫面所計算出的移動
物體像素超過一門檻值時，智慧型影像監控系
統便發佈警報。所以，移動物體像素偵測的正
確率是智慧型影像監控系統發佈警報的基礎
4在一個很小的範圍內變化。如果有移動物體入
侵時，所計算出之 H 便會有明顯變化。在靜
態背景的監視影片裡，影像熵值 H 也有同樣
的變化之特性，因此，不論是靜態或動態背景
的監視影片，皆可藉由影像熵值的變化來判斷
是否有移動物體的入侵而發出警報。經由實驗
結果得知，利用差值影像 ),( yxf 所求得之影
像熵值的變化量較單純用輸入影像 ),( yxI f 所
求得之影像熵值的變化量為大，因此，本研究
計畫就採用差值影像所求得之影像熵值的變
化來判定是否有移動物體的入侵。
先以 Manzanera 的倍數取樣的 Σ–Δ背景
演算法[10]求出目前的背景影像 ),( yxM f ，再求
出目前輸入影像 ),( yxI f 與目前背景影像
),( yxM f 之差值的絕對值，即為差值影像
),( yxf ，其可表示為:
),(),(),( yxMyxIyx fff 
得到目前差值影像 ),( yxf 後，應用方程式(1)
即可得到每一影像畫面之熵值 fH ，依據 fH 的
變化即可判定移動物體之入侵。
令 )sgn(a 為一符號函數，K 為不同取樣間隔的
數目， ),( yxm jf 為第 f 畫面之第 j 種取樣間隔
的背景影像， j為第 j種取樣間隔，其中 j = 1,
2, ..., K， ),( yxjf 代表輸入影像 ),( yxI f 與第 j
取樣間隔所得之背景影像 ),( yxm jf 的絕對差值
影像，E 為絕對差值影像的放大倍率，設定範
圍為 1 至 4 的整數值， ),( yxv jf 為第 j 取樣間隔
下的變異數，則本研究計畫所提出之動態背景
之差值影像的熵值偵測演算法可表示成：
Entropy-ΔAlgorithm
For each frame f
),(0 yxm f ← ),( yxI f
for each j, ],,2,1[ Kj 
if 1f
for each pixel ),( yx :
),( yxm jf ← ),(1 yxI
else
if f is a multiple of j
for each pixel ),( yx :
),( yxm jf ← ),(1 yxm
j
f +
 ),(),(sgn 111 yxmyxm jfjf  
else
for each pixel ),( yx :
),( yxm jf ← ),(1 yxm
j
f
for each pixel ),( yx :
),( yxjf ← ),(),( yxmyxI
j
ff 
if 0),( yxjf
),( yxv jf ← ),(1 yxv
j
f +
 ),(),(sgn 1 yxvyxE jfjf 
For each frame f
for each pixel ),( yx
),( yxM f ←




K
j
j
f
j
K
j
j
f
j
fj
yxv
yxv
yxm
1
1
),(
),(
),(


),( yxf ← ),(),( yxMyxI ff 
Calculate the fH for ),( yxf
每秒取 1 張畫面，每個畫面之影像解析度
為 480640 ，圖 1 為海邊沙灘的一段 5 分鐘
監視影片，所以 f = 1, 2, 3, … , 300，即
 yxI ,1 至  yxI ,300 。此監視影片的背景為波動
的海浪。此段影片起始期間的前 76 個畫面
內，沒有人員出現在監視影像畫面內，如圖 1
的  yxI ,1 至  yxI ,76 ，且此段監視影片的海浪變
化很大，背景變動的程度很高，如圖 1 之  yxI ,1
及  yxI ,3 畫面。在第 77 至 79、170 至 172 與
236 至 238 畫面有一個人進入監視影片。
 yxI ,1  yxI ,3  yxI ,77  yxI ,80
 yxI ,171  yxI ,235  yxI ,238  yxI ,300
圖 1：海邊沙灘之監視影片 ),( yxI f
令 E = 4，K = 3， 1= 1， 2 = 8，
3=16，圖 2 是所建立之海邊沙灘背景影片
 yxM f , 。由第前面的畫面可明顯看出岸邊的
6hf 和 Hf 之關係曲線圖的範例，藍色粗實線為熵
值 fH 的變化曲線，紅色細實線為參考的差值
影像熵值 fh 的變化曲線，綠色虛線則為其移動
平均門檻值 fT 的變化曲線。於畫面 f 小於 50
與大於 100 之區間的 fh 曲線，因熵值 fH 小於
移動平均門檻值 fT ，所以在此區間之參考的差
值影像熵值 fh 等於熵值 fH 。當 f 介於 51 至 100
區間，因熵值 fH 大於移動平均門檻值 fT ，所
以 fh 一直維持著 1fh 的值，因此移動平均門檻
值 fT 呈現為水平的直線。依據參考的差值影像
熵值 fh 與套用方程式(2)，綠色虛線的移動平
均門檻值 fT 曲線即可求得。
圖 6：移動平均門檻值 Tf、hf和 Hf之關係曲線圖
為警報的輸出，於此我們設計了一個警報
輸出陣列 A(f)，當第 f 畫面所求出之熵值 fH 大
於門檻值 fT 時，則警報陣列值 A(f)記錄為 1，
否則記錄為 0，令 Q 為移動平均門檻值之區
間，G 為放大的倍率之常數，則在動態背景影
像下之移動物體入侵偵測警報輸出演算法可
表示成：
Motion Detection Alarm Algorithm
For each frame f
if
1 ff TH then fh ← fH
else fh ← 1fh
if Qf  then fT ← 

f
j
jhf
G
1
else fT ← 

f
Qfj
jhQ
G
1
if
ff TH  then )( fA ←1
else )( fA ←0
由圖 6 的範例，其 f=50 至 99 為發
警報的狀態，所以 A(50)至 A(99)的警報
陣列被設為 1 其他則為 0。若令放大倍率
G = 1.1，移動平均門檻值之區間 Q = 150，將
圖 4 的海邊沙灘影片之差值影像的熵值曲線
fH 圖代入方程式(2)，即可求得移動平均門檻
值 fT ，如圖 4之綠色虛線。可以看出在沒有人
員走進沙灘的區間，差值影像熵值 fH 變動幅
度均在一定的小範圍內，當有人員走進偵測區
域時，差值影像熵值 fH 則有明顯增大的現
象，且高於移動平均門檻值 fT 曲線。因此由熵
值曲線圖可明顯看出，波幅大小的改變，確實
可做為入侵物體偵測的依據。
以畫面數 f 為橫座標，輸出警報 A(f)為縱
座標，圖 7(a)為海邊沙灘監視影片之目視警報
輸出圖，其發生警報的區間分別為第 77 至
79、170 至 172 及 236 至 238 畫面。圖 7(b)為
本研究技畫所提出之演算法的警報輸出圖，其
發生警報的區間為第 78、171、172、224 畫面。
圖 7：海邊沙灘影片之(a)目視(b)所提演算法的警
報輸出圖
4. 實驗結果
圖 8(a), 8(b), 8(c)分別為一段山路、漁港
航道、與機場航道的 5 分鐘監視影片，同樣以
每秒取 1 張畫面，總共擷取到 300 個畫面。圖
8(a)之山路監視影片，其動態的背景為受風吹
而晃動的樹葉及棉棉的細雨，其中於第 102
至 305、201 至 203 及 240 至 242 個畫面，均
有一人進入影像監視影像畫面，以及於 288
畫面時閃過一輛計程車。圖 8(b)之漁港航道監
視影片，其動態的背景為航道上波動的海浪，
其中於第 47 至 58 個畫面，有一艘漁船進入監
視影像畫面，之後就不再有船隻通過此航道。
圖 8(c)之機場航道監視影片，其背景為藍天，
由於天空晴朗所以背景相當單純，可以當作靜
態背景之範例，其中於第 27 及 28 畫面有一台
預警機出現於監視影像畫面。
8McFarlane 演算法 (c) Shoushtarian 演算法 (d)
Manzanera 演算法的熵值曲線圖
(a) (b)
(c) (d)
圖 12：機場航道監視影片之(a)所提出演算法(b)
McFarlane 演算法 (c) Shoushtarian 演算法 (d)
Manzanera 演算法的熵值曲線圖
藉由與目視結果必比較，將各種演算法錯
誤警報的次數整理成表 1。由表 1 可以看出本
研究計畫提出之演算法的錯誤警報次數最
少，例如在機場航道監視影片裡，本研究計畫
所提出演算法完全無誤報之情況產生，而其他
比較演算法的錯誤警報次數則相當多，在漁港
航道監視影片裡，所提出演算法僅產生 3 次的
錯誤警報，相對於 McFarlane’s Algorithm [6]
產生 41 次的誤報情況，足足相差將近 12 倍的
誤報率，而 Shoushtarian’s Algorithm [8]及
Manzanera’sAlgorithm [10]的誤報狀況，亦不
少於 10 次以上，由此實驗結果可證明，本研
究計畫提出之演算法，不管是應用於靜態或動
態背景環境，皆可到相當精確警報輸出的結
果。
表 1: 各種方法錯誤警報次數比較表
Method
Video
所提出
演算法 [6] [8] [10]
海邊沙灘 7 41 17 43
山路 6 20 6 5
漁港航道 3 41 12 22
機場航道 0 14 2 73
5. 結論
由於錯誤警報的發生，會使警戒人員或救
災人員疲於奔命而徒勞無功，浪費大量之人力
及物力而耗費大量的社會成本，因此，正確的
安全監視之警報系統有其必要性。因為在動態
背景環境下的監視影片裡，在沒有移動物體入
侵時，其影像的熵值只會在一定的小範圍內變
化，當移動物體進入偵測畫面時，其影像熵值
即會增大。利用影像熵值的理論與移動平均門
檻值的設計，本研究計畫提出一個可以在動態
背景環境下之智慧型影像監視警報偵測演算
法，經過實驗證明，的確可以達到非常理想的
偵測效果。如此一來便可節省大量人力或物力
來處理此警報訊號。但如果入侵物體太小或顏
色形狀等接近變動背景時，仍會發生誤報情
形，此為未來努力改善研究的目標，以達到更
廣泛的應用目標。
三、參考文獻
[1] A. Anzalone and A. Machi, “Video-based
Management of Traffic Light at Pedestrian Road
Crossing,” Advanced Video-based Surveillance
Syatem, Kluwer Academic Publishers, 1999.
[2] E. Stringa and C. S. Regazzoni, “Real-Time
Video-Shot Detection for Scene Surveillance
Application,” IEEE Transactions on Image
Processing, vol. 9, no. 1, January 2000.
[3] W. L. Hsu, H. Y. Mark Liao, B. S. Jeng, and K. C.
Fan, “Real-time Traffic Parameter Extraction using
Entropy,”IEE Proceedings Vision, Image and Signal
Processing, vol. 151, pp. 194-202, 2004.
[4] J. A. Freer, B. J. Beggs, H. L. Fernandez-Canque, F.
Chevrier and A. Goryashko, “Automatic Recognition
of Suspicious Activity for Camera Based Security
Systems,” Proceedings of the IEE European
Convention on Security and Detection, no.408, pp.
54-58, 1995.
[5] W. L. Hsu, H. R. Tyan, Y. M. Liang, B. S. Jeng, and
K. C. Fan, “Real-time Vehicle Tracking on a
Highway,” Journal of Information Science and
Engineering, vol. 21, pp. 733-752, 2005.
[6] N. McFarlane and C. Schofield, ‘‘Segmentation and
Tracking of Piglets in Images,’ Machine Vision
Applications, vol. 8, pp. 187-193, 1995.
[7] Y. Sato, S. Kaneko, and S. Igarashi, “Robust Object
Detection and Segmentation by Peripheral Increment
Sign Correlation Image,”Transactions of the IEICE,
vol. J48-D-II, pp. 2585-2594, 2001.
[8] B. Shoushtarian and N. Ghasem-aghaee, ‘‘A
Practical Approach to Real-time Dynamic
Background Generation Based on a Temporal Median
Filter,’’Journal of Sciences, vol. 14, no. 4, pp.
351-362, 2003.
[9] S. Fukui, Y. Iwahori, H. Itoh, H. Kawanaka, and R. J.
Woodham, “Robust Background Subtraction for
Quick Illumination Changes,” Lecture Notes in
Computer Science, vol. 4319, pp. 1244-1253, 2006.
出席國際學術會議心得報告
計畫編號 NSC 96-2221-E-211-020-
計畫名稱 智慧型動態與複雜背景之物體與人臉偵測的安全監視系統(I)
出國人員姓名
服務機關及職稱
陳佑冠, 華梵大學電子系, 副教授
會議時間地點 27 to 30 May 2008 in Sanya, Hainan, China
會議名稱 2008 International Congress  on Image and Signal Processing (CISP2008)
發表論文題目 Classification of a Text and a Graphics Images with Asymmetrical Filters
一、參加會議經過
本年度的 CISP2008國際會議在中國的三亞召開，主辦單位為 IEEE Computer
Society，主編為Prof. Dongguang Li和 Prof. Guang Deng，本年度的CISP2008國
際會議共收到 1833篇的投稿論，只有723篇論文被接受而發表在此 CISP2008國際會
議，論文的接受率僅有 39%。與會的學者來自世界約 30個國家。被接受的論文登在 IEEE
Computer Society的會議論文集裡，而且此一會議論文集是 indexed in both EI and
ISTP。而這次會議中除了聽取一些專家學者的報告之外,最大的收獲為認識了一些學
者，如Virginia Commonwealth University之medical Center的Ping Xu, Ph.D.、
The University of Oklaboma的 Dr. Samuel Cheng、Medical university of South
Carolina的 XingHua Lu, M.D., Ph.D.等之國外學者，還認識了一些中國大陸的學者，
如上海交通大學的電子信息與電氣工程學院的陶衛教授、武漢理工大學能源與動力工
程學院的高嵐教授等等之學者。
二、與會心得
一位英國學者所著的論文：K.Harmer, G.Howells, W.Sheng, M.Fairhurst, &
F.Deravi所著的A Peak-Trough Detection Algorithm Based on Momentum，其利用
momentum來偵測訊號的波峰點之方法應可應用在本人目前的國科會之研究計畫上，利
用momrntum來偵測安全系統之警報的起點與結束。M.A. Drouim和G. Godin所著的
Effective Moving Objects Detection Based on Clustering Background Mosdel for
Video Surveillance；J. Zhang所著的A New method of Image Restoration Based on
Least Square；S. Jin, H. Lee, & J. Jeong所著的Hadamard transform Based Fast
Partial Distortion Elimination Algorithm for Lossless and Lossy Motion
Estimation；T. Liu, W. Liang, X. Wu, & L. Chen所著的Tracking Articulated Hand
Underlying Graphical Model with Depth Cue；B. Li, Z. Tang, B. Yuan, & Z. Miao
所著的 Segmentation of Moving Foreground Objects using Codebook and Local
 Classification of a Text and a Graphics Images with Asymmetrical Filters 
 
 
Yu-Kumg Chen and Kai-Ti Hu 
Department of Electronic Engineering, Huafan University,  
No. 1, Huafan Rd., Shihding Township, Taipei County, Taiwan 223, R.O.C. 
ykchen@huafan.hfu.edu.tw 
 
 
Abstract 
 
Classification from text/graphics images is an 
important procedure for automatic d igi t izat ion of  
documents.  Based on the shapes in the basis image, 
the asymmetrical filters are developed in this paper. By 
filtering with the asymmetrical filters, the horizontal, 
vertical, and inclined edges’ information are fetched 
from the input image. With applying a classified 
algorithm, the input image can be classified as a text 
image or a graphics image. Experiments are carried 
out for some samples to demonstrate the computational 
advantage of the proposed method.   
 
Keywords: asymmetrical filter, text/graphics images, 
image processing, classification. 
 
1. Introduction 
 
The optical character recognition (OCR) devices 
allow written and printed documents to be converted 
into an electronic form without going through the 
process of having a human key in the words or data. 
When the input data are not hand written or printed 
documents from some other medium, like a newspaper, 
the OCR devices will make mistakes. In order to make 
the OCR devices working well, classification from 
text/graphics images is an important procedure for 
automatic digitization of documents. 
There are a lot of methods to solve the problem of 
classification from text/graphics images.  These 
methods can be classified as two categories, that is, 
methods of time and frequency domains. The methods 
in time domain is also divided into two categories, that 
is, methods with gray-level histograms [1-3] and 
methods of connected component [4-7]. The methods1  
 
                                                          
This work was supported by the National Science Council under the 
project NSC 96-2221-E-211-020. 
in frequency domain are found in [8-11]. 
The shapes of images contained characters, numbers, 
fingerprints, or the license plates, etc. are all geometric. 
Based on the shapes in the basis image, the 
asymmetrical filters are developed in this paper. The 
asymmetrical filters designed in this paper are 
horizontal asymmetrical filter, vertical asymmetrical 
filter and inclined edge asymmetrical filter, which can 
be used to fetch the messages of horizontal edge, 
vertical edge, inclined edge in images. With applying 
these asymmetrical filters, a classified algorithm is 
developed to solve the problem of classification from 
text/graphics images. Experimental results show that the 
proposed algorithm can get the nice successful 
percentage over than that of the previous works, such as 
Qiao’s algorithm [10] and Lee’s algorithm [11]. 
In next section, we develop asymmetrical filters for 
proposed algorithm. Detail classification algorithm is 
given in Section 3. Experimental results are shown in 
Section 4. Concluding remarks and potential 
applications are provided in the last section of this paper. 
 
2. Asymmetrical filters 
 
Based on the shapes in the basis image [12], 
asymmetrical filters are proposed in this paper. Figure 1 
shows a 64 by 64 basis image with 8 by 8 pixels in each 
block. Normally, the basis image can be divided into 
three regions, that is, low frequency, intermediate 
frequency, and high frequency, as shown in Figure 2(a). 
Since the lower frequency of a frequency image 
contains the color information of an image and the 
higher frequency of a frequency image contains a lot of 
noises of an image, these two areas are removed in the 
designed asymmetrical filters. From Figure 1, since 
there are horizontal strips at the left bottom of the basis 
image, we have the area of horizontal edge information, 
as shown in Figure 2(b). On the other hand, there are 
vertical strips at the up right of the basis image, we have 
the area of vertical edge information, as shown in Figure 
2008 Congress on Image and Signal Processing
978-0-7695-3119-9/08 $25.00 © 2008 IEEE
DOI 10.1109/CISP.2008.503
476
  
Therefore, we use the variables 
xp , yp , and  zp  to 
represent the probabilities of the horizontal edge 
information, vertical edge information, and inclined 
edge information, respectively. The mean value   of 
xp , 
yp ,  and  zp  is 
3
zyx ppp ++
=µ .  (3)  
 
(a) 
 
(c) 
 
(b) 
 
(d) 
Figure 5 .  Edge informational images of (a) an original 
image named English document: (b) vertical edge 
informational image, (c) horizontal edge informational 
image, and (d) inclined edge informational image.  
 
From Figure 5(c), 5(b), and 5(d), we have 
xp = 
7.10%, yp =13.22%, and zp = 8.61%, respectively. 
Thus, the mean value µ  for the English document is 
9.64%. Since the example of a document image is 
presented in Figure 5, we provide another image that 
does not contain document in Figure 6. The original 
image of Lina is shown in Figure 6(a). Figures 6(b), 6(c), 
and 6(d) show the edge informational images of vertical 
edge informational image, horizontal edge informational 
image, and inclined edge informational image, 
respectively. Table 1 lists the probabilities of edge 
information for these two images with different types. 
The mean value µ  for Lina is 0.21%, which is less than 
that of the English document. 
According to the experimental results, we have the 
threshold value 2% for µ . When µ  is greater than the 
threshold value 2%, the input image is classified as a 
document image. Otherwise, the input image is 
classified as an image which does not contain document 
in this input image. Figure 7 shows the flowchart of 
classification in the proposed paper. 
 
 
(a )  
 
(c )  
 
(b )  
 
(d )  
Figure 6 .  Edge informational images of (a) an original 
image named Lena: (b) vertical edge informational image, 
(c) horizontal edge informational image, and (d) inclined 
edge informational image. 
 
Table 1. Probabilities of edge information. 
Sample xp  yp  zp  µ  
English 
document 7.10 % 13.22 % 8.61 % 9.64 % 
Lena 0.08 % 0.33 % 0.23 % 0.21 % 
 
The text/graphics images classification methods of 
Qiao’s algorithm [10], Lee’s algorithm [11], and our 
proposed algorithm are tested and run on a personal 
computer with the operating system of Microsoft 
Windows XP. The original images used in this paper are 
of size 256×256. Figure 8 lists testing text/graphics 
images with different types.  Examples of text images 
are shown in Figures 8(a) through 8(e). Figures 8(a), 
8(b), and 8(c) are three printed text images named 
newspaper, big word journal, and small word journal, 
respectively. Figures 8(d) and 8(e) are two hand writing 
text images named handwriting-1 and handwriting-2, 
respectively. Examples of graphics images are shown in 
Figures 8(f) through 8(i). Figure 8(f) is baboon image 
that contain a lot of hairs in its face. Figures 8(g), 8(h), 
and 8(i) are scenic images named mountain, airplane, 
and racing car. 
478
