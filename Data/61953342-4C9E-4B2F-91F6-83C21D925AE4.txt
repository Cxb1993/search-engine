                                                                             
中文摘要 
 
由於電腦技術上的提昇，不管在醫學掃描、科學計算或科學模擬的領域上，都能夠產生
出更高精確性、龐大的容積資料。而為了處理這些資料，我們在硬體上也需要較好的支援，
例如：CPU 與 GPU 處理速度、記憶體與硬體容量、I/O 頻寬…等等。基於這些硬體上的限制
無法突破，我們不能直接將容積資料精細的一次繪製，因此必須導入多層次精細度的觀念。 
 
以果蠅腦部資料為例，其精細度為 1890 X 1033 X 120，又為了能夠觀察果蠅腦中不同
神經結構之間的連結關係，每組不同的神經結構都以一組容積資料表示，因此需要處理的是
多組疊合在一起的大型容積資料。我們提出了處理疊合多組大型容積資料的視覺化架構，系
統還包括縮減取樣式多層次精細度架構、記憶體管理、時間控制機制及容積資料繪製法。 
 
另外在科學計算與模擬上，產生出來的資料通常帶有時間演進，因此對於這些會隨著時
間變動的容積資料，我們也加以研究並處理。我們主要是提出結合多層次精細度階層表示法
與影片式壓縮的新架構，來管理並繪製大型時變容積資料。相較於傳統使用階層式小波轉換
的方法，類似視訊壓縮技術的影片式處理，使得我們在時間軸上的解壓縮還原更有效率。此
系統提供使用者控制空間興趣區域來調整空間上多層精細度，並提供時間興趣區域來選擇部
份更新區域，在合適的興趣區域控制上，我們能夠讓使用者互動的觀察大型時變容積在時間
上的動態變化。 
 
以下我們分別以兩篇發表之論文(NCS2007, CGW2007)作為研究內容詳述。另外，
CGW2007 那篇經過修正後也已經被 Pacific Vis 2008 接受。
                                                                             
Visualization of the Fruit Fly’s Brain using Multi-resolution Volume 
Rendering Technique 
Horng-Shyang LiaoPPP*,+P Kuang-Wei FuP* P Ching-Yao LinP+P 
hsliao@nchc.org.tw kwfu@cs.nctu.edu.tw chingyao@nchc.org.tw 
   
Tsai-Pei WangP* P Jung-Hong ChuangP* P  
wangts@cs.nctu.edu.tw jhchuang@cs.nctu.edu.tw  
P
*
PDepartment of Computer Science, National Chiao Tung University 
P
+
P National Center for High-performance Computing 
Abstract 
In this paper, we propose a rendering 
pipeline to visualize the large datasets of the 
fruit fly’s brain.  According to the nature of 
these datasets, we have to handle large and 
multiple volume datasets and obtain an 
interactive rendering frame rate.  The system 
applies out-of-core data management, timing 
control mechanism, multi-resolution, and 
volume rendering techniques to render the 
target datasets efficiently. 
Keywords: Scientific Visualization, Volume 
Rendering, Level-Of-Detail 
1. Introduction 
During recent years, data-acquisition 
methods and simulation technologies have 
been continued improving, so they result in 
producing a lot higher resolution volume 
datasets.  This situation causes challenge 
problems for data analysis and visualization.  
In order to process such huge datasets, we 
need more CPU computation power, as well 
as GPU computation, memory capacity, disk 
storage, I/O bandwidth, and other computing 
related resources.  Based on the limitation 
from the current computer hardware, it is 
hard to render these datasets efficiently by 
direct rendering. 
 
In this time, the target is the datasets 
of the fruit fly’s brain.  The dimensions of 
each dataset are 1890 X 1033 X 120, and we 
resize every one to 2048 X 1024 X 128 for 
convenient processing.  Each dataset is 
captured from a fruit fly by confocal 
microscopy and only highlight on a single 
neuron, in order to observe their co-relations 
of different neurons, we have to render 
multiple volume datasets together.  
Therefore, we need to render them 
efficiently; moreover, in order to help 
biologists examine their data, we have to 
provide some useful tools, such as transfer 
function adjustment, region of interesting 
(ROI), and clipping plane to assist the 
observation. 
This work is extended from our 
previous work, 3D VR Engine [11], Image 
processing toolkit (IMT) [16], and volume 
rendering platform [10].  In this paper, our 
contributions are as follows. 
1. We design the procedures to process 
and to visualize the fruit fly’s brain 
datasets. Although the pre-processing 
stage will cost a period of reasonable 
processing time, we can build an 
interactive rendering system, 
Appealed in NCS2007 
                                                                             
     LaMar et al. [8] proposed the first octree-
based multi-resolution method to manage 
very large volume dataset and render these 
data by texture-based volume rendering.  
Boada et al. [1] proposed a similar approach 
with nearly homogeneous regions for their 
hierarchical representation.  Weiler et al. [20] 
addressed the problem of discontinuous 
artifacts between the blocks with different 
resolution, and they proposed a consistent 
interpolation method to solve it.  Plate et al. 
[14] proposed an out-of-core hierarchical 
paging method to handle very large volume 
dataset up to 16GB.  Guthe et al. [7] applied 
wavelet transform to compress data and 
decompress data into hierarchical 
representation at run-time.  Based on their 
report, they can achieve interactive 
navigation on a conventional PC.  Gao et al. 
[6] use parallelized technique to extend 
current multi-resolution volume rendering 
algorithm.  This method could achieve a 
well-balanced workload and process even 
larger volume data. 
     When we apply multi-resolution method 
to render large volume datasets, the key 
point to control rendering quality and speed 
is Level-Of-Detail (LOD) selection to 
display properly chosen blocks from 
different levels.  That is, the LOD selection 
is to choose the rendering nodes from multi-
resolution hierarchy by some criteria.  
LarMa et al. [8] and Guthe et al. [7] 
proposed view-dependent LOD selection 
method.  Pinskey et al. [13] and Plate et al. 
[14] used region of interesting to choose 
blocks.  Shen et al. [15] and Wang and Shen 
[18] used the varying of data error metrics to 
select blocks.  Ljung et al. [12], Wang and 
Shen [19], and Wang et al. [17] used image-
based quality metrics.  Image-based error 
metrics measure the final rendering results, 
so this method has the best rendering quality, 
but it needs some extra costs for LOD 
selection.  Li and Shen [9] addressed time-
critical issue from the performance direction, 
so they proposed a dynamic LOD selection 
method to achieve user’s desired frame rate. 
3. Visualization Pipeline 
     In this section, we will discuss the 
visualization pipeline of our system, 
including preprocessing, out-of-core data 
management, LOD selection, and rendering. 
3.1 Data Structure and Pre-processing 
     Before we discuss the pre-processing 
method, we want to describe the framework 
of our method.  First, we construct an octree 
for each volume.  That is, when we render 
all datasets, there is a forest of octrees and 
we will select rendering nodes from each 
octree at run-time by our LOD selection 
scheme.  We also use standard OpenGL 
texture border to fill the boundary between 
rendering blocks.  Finally, we will render 
these chosen blocks and their borders by 
texture-based volume rendering in back-to-
front order. 
     Based on the previous description, the 
preprocessing program has to process each 
original dataset to generate a set of octree 
style data.  We build this kind of octree style 
data by the order from leaf nodes to root 
node.  The processing can be briefly 
described in five steps. 
1. Resize: We resize original data into the 
nearest suitable size with power of two.  
Therefore, for each volume of the fruit 
fly’s brain, we convert its size from 
1890 X 1033 X 120 to 2048 X 1024 X 
128. 
2. Split: We choose the size of 128 X 64 
X 8 for each block (brick) and split the 
input volume into bricks.  We also add 
boundary from neighborhood blocks.  
Finally, each block’s size is 130 X 66 X 
10. 
3. Down-sampling: We down-sample the 
volume data by factor of 2 for each 
dimension; therefore, after the down 
               
 of our LOD selection. 
 
Figure 2: View dependent LOD selection.
3. The size of total chosen blocks should 
not exceed graphics memory, and the 
chosen blocks and cached blocks 
cannot overstep the limitation of main 
memory.  The data management part 
will be taken care of by our-of-core 
data manager automatically.  For LOD 
selection, we only add a criterion to 
prevent the total size of chosen blocks 
from exceeding the graphics memory. 
4. If the current checking node is a leaf 
node, we will choose it immediately 
and ignore other criteria. 
5. We only add new 8 nodes at each time 
frame to shorten the response time.  If 
more than 8 nodes need to be added, 
we will postpone them until next frame.  
Therefore, the LOD selected result will 
be refined adaptively. 
6. We build an octree structure for each 
dataset, and traverse a forest from each 
tree’s root concurrently.  After the 
proxy polygons for volume rendering 
are generated, we will sort them and 
render them by back-to-front order. 
Figure 3 show the overall workflow of 
above six concepts.  We use a list to 
maintain all candidate and chosen blocks 
(bricks).  Concepts 1 and 2 are realized in 
step 7, as well as concept 3 is step 6, and 
concept 4 is step 5.  Concept 5 is cooperated Figure 3: Workflow                                                              
                                                                             
   
(a) Overview of testing datasets.              (b) Near blocks are the most detail data. 
   
(c) Another view of testing datasets.           (d) Blocks’ boundary of (c). 
Figure 8: Rendering results. 
     Our preprocessing program will resize 
the brain and neuron into size 2048 X 1024 
X 128 and the mushroom body into size 
1024 X 512 X 128.  The chosen block size is 
130 X 66 X 10 with border, so we have 5 
levels for the brain and neuron and 4 levels 
for the mushroom body.  The preprocessing 
time is 144 seconds for the brain and neuron, 
plus 23 seconds for the mushroom body. 
     Figure 8 is the rendering results.  The 
resolution of our rendering frame buffer is 
1280 X 1024.  Figure 8(a) shows the overall 
datasets.  Figure 8(b) has a close view and 
the near blocks use the most detail data.  The 
rendering performance of figure 8(b) is 1.3 
frames per second (FPS).  Figure 8(c) and 
8(d) present the rendering result and its 
LOD selection. 
5. Conclusions 
The proposed rendering pipeline is 
targeted for the problems of visualizing the 
volume datasets of the fruit fly’s brain.  This 
method handles the issues of large dataset, 
multiple volumes, and interactive frame rate.  
In the paper, we have reasonable speed for 
pre-processing and run-time system.  For the 
interactive system, the proposed multi-
resolution texture-based volume rendering is 
supported by out-of-core data management 
                                                                             
[12]  P. Ljung, C. Lundstrom, A. Ynnerman, 
and K. Museth, "Transfer function 
based adaptive decompression for 
volume rendering of large medical data 
sets," In Proceedings of IEEE 
Symposium on Volume Visualization and 
Graphics’04, pp. 25-32, 2004. 
[13]  D. Pinskiy, E. Brugger, H. Childs, and B. 
Hamann, "An octree-based 
multiresolution approach supporting 
interactive rendering of very large 
volume data sets,” In Proceedings of the 
International Conference on Imaging 
Science, Systems, and Technology’01, 
pp. 16-22, 2001. 
[14]  J. Plate, M. Tirtasana, R. Carmona, and 
B. Fröhlich, "Octreemizer: a 
hierarchical approach for interactive 
roaming through very large volumes," 
In Proceedings of the Symposium on 
Data Visualization 2002, Barcelona, 
Spain, May 27-29, 2002. 
[15]  H.-W. Shen, L. J. Chiang, and K.-L. Ma, 
"A fast volume rendering algorithm for 
time-varying fields using a time-space 
partitioning (TSP) tree," In Proceedings 
of IEEE Visualization’99, IEEE 
Computer Society Press, pp. 371-377, 
1999. 
[16]  C.-Y. Sun, P.-Y. Li, K.-L. Tsai, and C.-W. 
Ku, "IMT: image processing toolkit", In 
Proceedings of 19Pth P Computer Vision, 
Graphics, and Image Processing 
(CVGIP2006), Tauyuan, Taiwan, 
August 13-15, 2006. 
[17]  C. Wang, A. Garcia, and H. W. Shen, 
"Interactive level-of-detail selection 
using image-based quality metric for 
large volume visualization," In IEEE 
Transactions on Visualization and 
Computer Graphics, pp. 122-134, 2007. 
[18]  C. Wang and H.-W. Shen, "A 
framework for rendering large time-
varying data using wavelet-based time-
space partitioning (WTSP) tree," Tech. 
Rep. OSU-CISRC-1/04-TR05, 
Department of Computer and 
Information Science, The Ohio State 
University, January 2004. 
[19]  C. Wang and H.-W. Shen. LOD Map - A 
Visual Interface for Navigating 
Multiresolution Volume Visualization. 
In IEEE Transactions on Visualization 
and Computer Graphics, pp. 1029-1036, 
2006. 
[20]  M. Weiler, R. Westermann, C. Hansen, 
K. Zimmerman, T. Ertl, "Level-of-detail 
volume rendering via 3d textures," In 
Proceedings of the 2000 IEEE 
symposium on Volume Visualization, 
2000.
                                                                             
point for rendering quality.  Many methods have been also 
proposed to obtain a good trade-off between the quality and speed.  
LarMar et al. [11] and Guthe et al. [6] used view-dependent 
criteria.  Pinskiy et al. [13] and Plate et al. [14] used ROI.  Shen et 
al. [17] and Wand and Shen [19] used data error metrics.  Ljung et 
al. [10], Wang and Shen [20], and Wang et al. [21] used image-
based quality metrics. 
For time-varying volume data, Guche and StraBer [7] 
introduced an algorithm that uses the 3D wavelet transform to 
encode each individual volume, and then applies a motion-
compensation-based prediction between adjacent time steps.  
Sohn et al. [16] proposed a volumetric video system that borrows 
the idea of MPEG compression to efficiently exploit the spatial 
and temporal coherence.  However, their algorithm is not focused 
on large data set.  In our algorithm, we extend the above methods 
to large time-varying data set by adding LOD, caching, and pre-
loading into consideration. 
For large tim-varying volume data, Linsen et al. [9] proposed a 
four-dimensional multi-resolution approach for time-varying 
volume data.  Their scheme treats temporal and spatial dimensions 
equally in a single hierarchical framework.  The hierarchical data 
organization is based on a subdivision scheme that only doubles 
the overall number of grid points in each subdivision step.  This 
fact leads to fine granularity and high adaptivity.  Shen et al. [17] 
proposed the time space partitioning (TSP) tree that captures both 
the spatial and temporal coherence of the underlying data.  It 
allows the user to request spatial and temporal data resolutions 
independently with separate error tolerances.  Ellsworth et al. [4] 
later provided a hardware volume rendering method using the TSP 
tree.  They also proposed color-based error metrics to improve the 
selection of data blocks to be loaded into texture memory.  Wang 
and Shen further applied wavelet transform to the TSP tree and 
proposed the wavelet-based time-space partitioning (WTSP) tree 
method [19].  They first built a wavelet tree hierarchical 
representation [6] for each individual time step, and then for the 
high-pass filtered coefficients from the corresponding spatial node 
along the time axis, they applied 1D wavelet transform to form a 
binary tree.  Although WTSP tree method supports flexible 
spatial-temporal multi-resolution data browsing, their hierarchical 
1D wavelet compression of the spatial node along the time axis is 
not suitable for interactive playback. 
3 SYSTEM OVERVIEW 
Our algorithm consists of a preprocessing stage and a run-time 
rendering stage.  In the preprocessing stage, each time step (frame) 
of the data set is classified as either an intra-coded frame (I-frame) 
or a predictive frame (P-frame).  This is similar to the group-of-
group structure used in the MPEG video coding schemes.  For 
each I-frame, we apply the hierarchical wavelet transform to 
construct a multi-resolution hierarchical wavelet representation.  
The high-pass filtered coefficients are then encoded and stored in 
the disk.  For each P-frame, we first use the hierarchical wavelet 
transform to construct a multi-resolution hierarchical 
representation and then apply motion-compensation-based 
prediction to the low-pass filtered data.  The resulting difference 
data and motion vectors are encoded and stored. 
In the rendering stage, the data are decompressed on-the-fly and 
rendered using hardware 3D texture mapping.  The system 
provides the user with a spatial ROI for supporting spatial LOD 
selection, and the selection of a temporal ROI to choose only a 
sub-region for frequent update during playback.  We also propose 
caching and pre-loading mechanisms.  Caching is applied to I-
frames so that previously reconstructed data blocks can be reused 
when the LOD selection is changed. Pre-loading is applied to P-
frames in order to distribute the workload of each frame more 
evenly. 
4 COMPRESSION SCHEME 
In this session we describe our preprocessing stage.  The input 
is a time-varying volume data set, V = {VB1B, VB2B,…, VBTB}, where T is 
the number of time frames.  In this stage, we first construct a 
multi-resolution data hierarchy for each time frame, and then 
apply our compression scheme on each hierarchy.  Each time 
frame is classified as either an I-frame or a P-frame.  The 
compression of an I-frame is independent of the other frames 
while the compression of a P-frame is dependent on its previous 
frames. 
Figure 1 illustrates the whole compression process.  The 
compression scheme consists of the following three steps: 
1. Subdivide the volume data of each time frame into a 
sequence of blocks. 
2. For each volume data, recursively apply the 3D wavelet 
transform to all blocks and construct a hierarchical wavelet 
representation. 
3.  
a. For an I-frame volume, store the high-pass filtered 
coefficients and the low-pass filtered root block. 
The high-pass filtered coefficients are encoded 
before they are stored. 
b. For a P-frame volume, apply motion-
compensation-based prediction to each node in the 
hierarchy with respect to its spatially 
corresponding node in the previous frame. The 
resulting difference data and motion vectors are 
then encoded and stored. 
In the following subsections, we will describe in detail how we 
compress I-frame data and P-frame data.  
Figure 1: The compression process.
4.1 I-frame Compression 
We compress an I-frame using the wavelet-tree method [6].  
First, we divide the volume data of this frame into a sequence of 
blocks.  Let’s assume that each block has N voxels with the 
dimension being nBxB× nByB× nBz B, where nBxB, nByB, and nBz B are all integers 
of powers of 2.  We apply 3D wavelet transform to each block, 
resulting in N/8 low-pass filtered coefficients and 7N/8 high-pass 
filtered coefficients.  The low-pass filtered coefficients from eight 
adjacent blocks are collected and grouped into a new block of size 
N, as shown in Figure 2.  Then we repeat the wavelet transform 
and low-pass coefficients grouping process recursively until only 
one single block is left.  The procedures above produce an octree.  
Each node of the octree corresponds to a data block of N voxels 
and contains a set of high frequency coefficients that can be used 
                                                                             
temporal ROI is another 3D bounding box that can be controlled 
in the spatial space by the user.  When the temporal ROI is 
enabled, the system first decides the spatial LOD, and then only 
the data blocks that are selected by the temporal ROI will be 
updated at every time step.  Blocks that are outside the temporal 
ROI are only updated at every I-frame 
5.1.1 Spatial LOD Selection 
The spatial LOD selection chooses a list of blocks from the 
octree hierarchy for rendering.  In order to avoid texture 
swapping-in and swapping-out in a single rendering pass, the total 
size of the selected blocks should not exceed the capacity of 
texture memory in the graphics hardware.  Usually the user may 
want to set a maximum total block size MBLODB for this spatial LOD 
selection.  We provide a scalar factor s such that 
M BLODB =sMBTEXB,                                        (1) 
where MBTEXB is the maximum available texture memory of the 
graphics hardware and the value of s is between 0.0 and 1.0.  
Higher values of s give better rendering quality, while lower 
values of s allow faster rendering or playback.  Users can change 
the value of s at run-time. 
The spatial LOD selection algorithm is achieved by traversing 
the octree with a priority queue.  Each node i of the octree 
hierarchy has a priority value PBLODB(i).  The priority value is given 
by considering the ROI and the distance to the viewer position.  
More specifically, we have 
P BLODB(i)=C B1BP BROIB(i)+CB2BP BVIEWB(i),                          (2) 
where CB1B and CB2B are weighting coefficients, PBROIB(i) is a priority 
value of ROI, and PBVIEWB(i) is a priority value of viewing.  We set 
P BROIB(i) to 1 for blocks inside the ROI and 
P BROIB(i)=1/(1+DBROIB(i))                                    (3) 
for block outside of the ROI, where DBROIB(i) is the distance 
between the ROI and block i.  We also define 
P BVIEWB(i)=1/(1+DBVIEWERB(i)),                                (4) 
where DBVIEWERB(i) is the distance between view point and block i. 
In the beginning of the LOD selection, we create an empty 
priority queue and insert the root node r of the octree into the 
queue with priority PBLODB(r).  Then we successively fetch the node 
with the highest priority from the queue, and insert its eight child 
nodes into the queue.  If a leaf node is reached, we remove this 
leaf node from the priority queue and put it into another queue 
which stores the nodes to be rendered.  This procedure stops when 
the total block size of the priority queue and rendering queue 
reaches the maximum size M BLODB.  Then we move all the nodes in 
the priority queue into the rendering queue.  All the nodes in the 
rendering queue will be used for rendering. 
5.1.2 Temporal ROI 
Because rendering performance will go down if too many data 
need to be updated for every time step, we provide another 
temporal ROI.  The blocks inside the temporal ROI will be 
updated every time step, while the others will be updated only at 
every I-frame.  End user can change the range of the temporal 
ROI arbitrarily at run-time. 
5.2 Decompression 
For an I-frame, after we have decided the nodes to be rendered 
according to the spatial LOD selection, we use 3D wavelet 
decompression method to restore the original data of each chosen 
node from disk.  Our decompression procedure starts from the 
root and end in target nodes.  For a P-frame, we keep the same 
spatial LOD selection as the last I-frame and construct each P-
frame from its previous frame by motion-compensation.  That is, 
we only need to load the difference values of each node from disk 
and then add them to the already decompressed node of the 
previous frame to obtain that node of the current frame. 
5.3 Rendering of Blocks 
To render the selected blocks, we use texture-based volume 
rendering.  We draw all the blocks in a back-to-front order.  The 
order can be established by enforcing a back-to-front traversal 
order of the octree.  For each block, a 3D texture is created and 
loaded into the texture memory.  We place view-aligned slices into 
the block (see Figure 6 for an example) and render these slices in 
a back-to-front order.  Alpha blending delivers the volume 
integrals along viewing rays for all the pixels on the screen. 
To obtain a higher rendering quality, we provide pre-integrated 
volume rendering [5].  The pre-integrated volume rendering 
requires more texture fetching to render the slices, hence it will 
consume more time for rendering.  End user can enable or disable 
this feature. 
5.4 Caching and Pre-Loading 
The while 
transm hance 
perfor ading 
mech using 
previo ion is 
chang e the 
workl fined 
amou ching 
and p
5.4.1
In I g box 
to adj at are 
curren e the 
time f he all 
the d rame.  
We gi
short 
P BDEL B(
where
L(i), C
1. 
2.  
Figure 6: Rendering with view-aligned slices. 
 most time-consuming part of our system occurs 
itting and reconstructing data blocks.  To further en
mance, we propose using caching and pre-lo
anisms. Caching is applied to I-frames to help re
usly reconstructed data blocks when the LOD select
ed.  Pre-loading is applied to P-frames to distribut
oad of each frame more evenly.  We allocate a pre-de
nt of extra main memory and texture memory for ca
re-loading. 
 Caching 
-frame, user may often change the spatial ROI boundin
ust spatial LOD selection.  Some of the data blocks th
tly useless may become useful in the future.  To sav
or loading and reconstructing these data blocks, we cac
ecompressed data blocks in main memory during I-f
ve each cached block i a deleting priority P BDEL B(i).  If we run 
of memory, we delete the data blocks that have the highest 
i).  We define the deleting priority PBDEL B(i) for each block i as: 
P BDEL B(i)=W B1BL(i)+WB2BC(i)+WB3BF(i),                      (5) 
 WB1B, W B2B, and W B3B are weighting coefficients.  We now define 
(i), and F(i) as follow: 
L(i): This function considers the likelihood of a block 
node being visited.  A block node will be visited for 
decompressing child nodes more often when it is closer 
to the root of the octree hierarchy.  Thus, we define L(i) 
of block node i as their depth in the octree.  The root 
node is at depth zero. 
C(i): This function is defined using a least recently used 
(LRU) scheduling scheme.  We give each decompressed 
block in memory a counter C(i) that is initially set to zero.  
                                                                             
 
Table 3: Rendering speed of Jet-large with different LOD selections.
 s=0.152 s=0.073 s=0.033 
No. of total blocks 43 15 8 
No. of non-uniform blocks 41 13 6 
Size of non-uniform blocks 82MB 26MB 12MB 
Rendering frame rate 30.04 42.76 47.72 
Rendering frame rate 
(pre-integrated) 
0.45 2.51 5.16 
methods.  We assume that we don’t have additional memory space 
to cache intermediate nodes in the binary time tree of WTSP tree 
method, so we also disable the caching and pre-loading 
mechanism in our system. 
From the comparison results shown in Figure 8 and 9 we can 
see that the decompression of our system is obviously faster than 
that of the WTSP tree method, mainly due to the fact that WTSP 
tree requires a lot of extra overhead to traverse the binary time 
tree.  This problem is worse when there are more time steps.  In 
our algorithm, even without additional memory space, we can still 
decompress the data blocks efficiently, and the performance is 
i
s
t
6
s
also show the result images in Figure 10. 
From the above testing results, we observe that the value of s 
can be decreased in the run-time to trade rendering quality for 
rendering speed.  Users can roughly browse the data set with 
smaller s in the beginning to find out suitable camera parameters, 
and then reveal more detail using higher s. 
6.3.3 Temporal ROI and Interactive Playback 
In Table 4, we demonstrate how to improve the playback speed 
in our system.  We display the selected blocks of temporal ROI 
with yellow bounding boxes in Figure 11.  The size of the 
temporal ROI is 1/8 of the whole volume.  Decreasing the value 
of   s and using temporal ROI helps to enhance the playback 
frame rate.  Here we demonstrate that with the flexible spatial and 
temporal LOD selection mechanism, users can easily see the 
results in an interactive playback. 
6.4 Discussion 
In this subsection, we explain two unmentioned features from 
the testing results. 
1. We choose block size among 0.5~2MB.  If the block size 
is too small, many data transfers are needed when we 
want to load large data.  If we choose a too large block 
size, there would be a waste while only small parts of 
data are needed.  Therefore, this is a trade-off choice 
depends on types of data and experiences. 
2. The main drawback of our algorithm is the slowing down 
by the random access of an arbitrary frame.  However, in 
our opinion, the random access happens infrequently, and 
end users usually can accept a little latency when they 
perform this kind of actions. 
7 CONCLUSION 
We have introduced a new framework that combines the multi-
resolution hierarchical representation with video-based 
compression to manage and render large scale time-varying data.  
We demonstrated how this new structure can perform more 
efficient reconstruction in time axis compared to the WTSP tree  
(a) The comparison of decompression time. 
 
(b) The corresponding size of disk loading. 
Figure 8: Results of testing with a set of blocks of
size 10~20MB. 
 
 
(a) The comparison of decompression time. ndependent of the number of time steps.  For the testing result 
hown in Figure 8, the playback frame rate is 0.85 fps for WTSP 
ree method and 5.1 fps for the proposed method. 
.3.2 LOD and Rendering Speed 
In Table 3, we list the rendering speed with three different 
calar factors s for the first time step of the Jet-large data set.  We 
                                                                             
(a) s=0. 033, with temporal ROI. 
(b) s=0.07261, with temporal ROI. 
(c) s=0.1518, with temporal ROI. 
Figure 11: The temporal ROI selection.
 
(a)  s=0.033. 
 
(b)  s=0.0726. 
 
(c)  s=0.1518 
         
(d)  LOD selection of (a).        (e)  LOD selection of (b) 
 
(f)  LOD selection of (c). 
Figure 10: Rendering results of three different scalar factors. 
[20] C. Wang and H. W. Shen. LOD Map - A Visual Interface for 
Navigating Multiresolution Volume Visualization. In IEEE 
Transactions on Visualization and Computer Graphics, 1029-1036, 
2006. 
[21] C. Wang, A. Garcia, and H. W. Shen. Interactive level-of-detail 
selection using image-based quality metric for large volume 
visualization. In IEEE Transactions on Visualization and Computer 
Graphics, 122-134, 2007. 
[22] M. Weiler, R. Westermann, C. Hansen, K. Zimmerman, T. Ertl. 
Level-of-detail volume rendering via 3d textures. In Proceedings of 
the 2000 IEEE symposium on Volume Visualization, 2000. 
[23] R. Westermann and T. Ertl. Efficiently using graphics hardware in 
volume rendering applications. In Proceedings of SIGGRAPH’98, 
1998. 
 
 
1、目的
在 Scientific visualization及 information visualization 領域裡，IEEE Visualization 和
IEEE InfoVis 是最主要的兩個 conference。不管是政府單位、學術界、或業界，都有研究人員
及相關從業人員來參加。一起交換在 Visualization方的的新知識、新科技或新工具。本年度
兩個 conference 又合併舉辦，讓不同領域的人，可以一起分享彼此的認知。
參加 IEEE Visualization，可以接觸到最新的科技，並且能了解 Visualization未來發展的
方向。對於中心未來在 Visualization的研究發展方面，可以提供一個指引，讓我們在視算方
面的研發，能夠配合世界潮流。並且認識不同地方的相關從業或研究人員，為將來進一步的
合作，增加了可能性。
entry-points等來達成他們的目標。在上述的工作項目裡，Visualization也是主要工作項目之
一。所以 Visualization，在美國似乎又成為一個重點的研究目標。
2.2.發展方向
2.2.1 平行/分散式的處理
Visualization依賴於 Data。沒有 Data，Visualization就找不到生根之處。過去的 Data產
出量並不是那麼的大，透過單一 PC或Workstation就有辦法處理及顯示。但現在 Data生成的
速度及量，和過去相比起來，進展的程度，相當驚人；各種不同 Information的累積速度，也
遠遠超過過去的想像。要能處理及顯示那麼大量的資料，分散或平行處理方式已是必要。
這次在 Visualization Conference裡，所得到的一個感想是，利用 Parallel Visualization 和
Parallel Rendering來顯示 data，對於處理大量資料的研究/計算中心來說，已經是基本功能。
因為 data的量，已經到了單一電腦無法處理的地步了。在大型的平行計算程式裡，研究學者
為了能表現或偵測運算中途時段的一些現象，也在程式加入部份視覺化程式，使得在不影響
overall的計算效率下（在 visualization 方面所佔的 CPU時間 < 5%），能夠有基本的部份成
果顯現。這有助於觀察科學模擬的中間步驟過桯。不過要讓模擬的科學家同意在他們的模擬
程式裡加入可以協助顯示的程式，是需要一番討論與溝通。
本次 paper的一個 Section，是討論有關於 Tiled-Display Wall。經由更高解析度來把 data
做更精細的表示，也是未來趨勢之一。已有研究報告指出，透過高解析度的呈現，可以幫助
研究學者了解資料。現在高解析度投影機的價錢仍相當昂貴，Tiled-Display 相對而言，仍是
一個經濟的解決方式。Tiled-Display 也是運用到 Parallel及 Distributed computation技術。
2.2.2 了解科學家的需求
Visualization的目的，是要幫科學家 "Get the insight of data"。但是，在很多時候，做
visualization的研究人員，並不完全了解科學家的需求，所以有時雖然花很多時間人力去做，
以非專業人士來看，顯示的效果可能是相當漂亮可觀；但卻無法符合專業科學家們的需求。
本次的 IEEE Visualization，有舉辦一個 panel，"Meet the Scientists"，是由 UC Davis 的馬匡六
教授所主持。他安排五個不同領域的專家學者，包含天文學家、物理學家等，他們都運用超
級電腦來做模擬；這個 panel安排他們來分別簡介他們的專業領域，他們在做什麼；並進而
討論，從他們產生的 Data裡，他們想看到什麼，Visualization 能對他們有何貢獻。這是一個
很難得的機會，可以聽到不同領域對 Visualization的看法。
