functions using integrated clinical and microarray 
data. Our model produces results more accurately than 
the average 70% predictive accuracy of other machine 
learning methods. The results indicate that the GASVM 
model has the potential to better assist physicians 
in the prognosis of breast cancer through the use of 
both clinical and microarray data. 
英文關鍵詞： Breast Cancer Prognosis； Genetic Algorithm； Support 
Vector Machine； Gene Selection； Cancer 
Classification； Gene Expression； Clinical Data 
 
 - 2 - 
learning methods. The results indicate that the GASVM model has the potential to better assist 
physicians in the prognosis of breast cancer through the use of both clinical and microarray data. 
 
Keywords: Breast Cancer Prognosis; Genetic Algorithm; Support Vector Machine; Gene Selection; 
Cancer Classification; Gene Expression; Clinical Data 
1. Introduction  
Prior to the advent of microarray analysis, methods of cancer diagnosis in most cases 
depended on a combination of clinical and pathological data; clinical data such as patient history, 
laboratory analysis, and ultrasound parameters formed the basis of research and guided the clinical 
management of cancer. However, it was often difficult or impossible for physicians using these 
methods to recognize tumor types in atypical instances (Ramaswamy S, Tamayo P, Rifkin R, 
Mukherjee S, Yeang CH, Angelo M, et al. ,2001 ).  The development of techniques based on 
microarray technology has given cancer diagnosis an additional avenue of diagnosis and cancer 
management. In the past decade, DNA microarray technologies have had a significant impact on cancer 
genome research; for example, the technology has become a powerful tool in the study of functional 
genomes (Chen JJ, Peck K, Hong TM, Yang SC, Sher YP, Shih JY. et. Al  ,2001; Morley M, Molony 
CM, Weber TM, Devlin JL, Ewens KG, Spielman RS, et al. ,2004 ) due to advancements which allow 
for the measurement of millions of gene expressions simultaneously (Friedman N, Linial M, Nachman 
I & Pe'er D. ,2000). Large scale profiling of gene expression and genomic alternations using DNA 
microarrays can reveal not only the differences between normal and malignant cells, but also genetic 
and cellular changes at each stage of tumor progression and metastasis as well as illuminate differences 
among cancers of different origins. Cancer classification is quickly becoming the critical basis for 
patient therapy. 
There are several machine learning techniques such as correlation (van de Vijver MJ, He YD, 
van't Veer LJ, Dai H, Hart AA, Voskuil DW. et al.,2002), regression (van 't Veer LJ, Dai H, van de 
Vijver MJ, He YD, Hart AA, Mao M, et al.,2002), Hierarchical clustering (Sotiriou C, Neo SY, 
McShane LM, Korn EL, Long PM, Jazaeri A, et al. ,2003), k-nearest neighbors, back-propagation, 
probabilistic neural network (Greer BT & Khan J,2004; Li L, Weinberg CR, Darden TA, Pedersen 
LG.,2001; Khan J, Wei JS, Ringnér M, Saal LH, Ladanyi M, Westermann F, et al. ,2001), Bayesian 
network (Chen T, He HL, Church GM.,1999; Friedman N, Linial M, Nachman I, Pe'er D. ,2000; 
Helman P, Veroff R, Atlas SR, Willman C.,2004), and the module-network (Savoie CJ, Aburatani S, 
Watanabe S, Eguchi Y, Muta S, Imoto S et al. ,2003; Segal E, Friedman N, Koller D, Regev A.,2004) 
that have been applied in cancer classification or clustering. Most of these classification algorithms 
suffer from a high dimensional input space issue due to the large amount of DNA gene expression data 
available. Reducing the number of genes needed for analysis while maintaining a consistently high 
accuracy is a method of addressing this problem. Among these techniques, support vector machine 
(SVM) is touted as one of the most powerful tools in the classification of cancer. Nevertheless, the use 
of SVM involves tackling three considerable challenges, including: how to select the optimal kernel 
function type, how to select the optimal parameter values for the kernel function, and how to select the 
best feature subset for SVM training and testing (Huang, C. & Wang, C. ,2006). Overcoming these 
challenges is critical.  One of our major goals in this study, therefore, is to develop a new selection 
method for the optimization of kernel function types, kernel function parameters, and SVM feature 
subsets. Another issue in this study centers on the characteristics of the data itself. Although research 
into the use microarray techniques in cancer diagnosis has flourished over the past few years, clinical 
data appears to be underused whereas microarray data is comparatively overweighed. Utilizing 
integrated data, as opposed to using only clinical or only microarray data, is another major step toward 
improving cancer prognosis accuracy. 
In this paper, we will focus as an example on the prognosis prediction of lymph node-negative 
breast cancer. We define the outcome as a variable which includes two classes: a good prognosis or a 
poor prognosis. A good prognosis corresponds to a disease-free state for a minimum of 5 years, while a 
poor prognosis corresponds to disease recurrence within 5 years after diagnosis (van 't Veer LJ, Dai H, 
van de Vijver MJ, He YD, Hart AA, Mao M, et al.,2002). If we can classify the patients correctly, we 
can better treat other patients by reducing the risk of over- or under-treatment. Thus, the main goal of 
this study is to develop a better method that can classify patients accurately using combined microarray 
and clinical data. 
In order to significantly improve predictive accuracy, we developed a new GASVM classifier 
model by combining a Genetic Algorithm and a Support Vector Machine. The benefits of our GASVM 
model were tested via the following steps. First, we selected genes using four methods (i.e. all genes, 
70 correlation-selected genes, 15 medical-literature selected genes, and 50 T-test-selected genes) and 
 - 4 - 
P.Dardenne,2004; Cristianini, N. & Shawe-Taylor, J. ,2000; Kecman, V. ,2001; Scho l¨kopf, B., Guyon, 
I., Weston, J. ,2000).  
2.3. Genetic Algorithm 
Genetic algorithm theory was introduced by John Holland in 1975. It is an optimized search 
technique based on natural selection, a genetic algorithm which represents a type of evolutionary 
computing. The evolutionary process results in the fittest solution for a given genetic algorithm. In such 
an algorithm, the user provides the environment (function) in which the population is to evolve. 
The main concept of a genetic algorithm is the transformation of all parameters into a binary string, 
referred to as a “chromosome”. Chromosomes represent a set of solutions to a specific problem. The 
first generation of chromosomes is the parent generation. The parents produce a new, second 
generation (offspring) who, through evolutionary selection, possess characteristics better suited to the 
environment. The three stages in a genetic algorithm are “Reproduction”, “Crossover”, and “Mutation”. 
The Reproduction stage determines the number of chromosomes in the next generation 
according to the adaptation status of each chromosome. Highly adaptive chromosomes will be 
produced via a large number of replications in each generation, and less adaptive chromosomes will be 
eliminated. 
The Crossover stage involves the random selection of two chromosomes from the population 
of highly adaptive chromosomes. The selected chromosomes exchange one section between one 
another in order to produce two new offspring. 
The Mutation operation randomly mutates one segment (one bit) in a chromosome from each 
generation to generate a new chromosome. 
Figure 2 illustrates the procedure of the genetic algorithm. The first step is to generate the initial 
population which contains N chromosomes, where each chromosome stands for one solution. The 
second step is to define a fitness function. The function is used to calculate the fitness score for each 
chromosome. The third step is to generate a new population of chromosomes based on “Reproduction”, 
“Crossover”, and “Mutation”. The more suitable the fitness value of a chromosome, the greater its 
chance of reproducing. This iterative process is repeated until predetermined conditions such as 
population number or improvement rate are satisfied. 
Genetic algorithm theory differs from traditional searching methods. It utilizes many 
chromosomes simultaneously to develop an optimal solution, and so it avoids sticking in a local 
optimal solution. Rapid Reproduction and Crossover illuminates the optimal solution more quickly, 
and the Mutation operation allows the optimal solution to traverse the bounds of a local optimum. 
2.4. Our Proposed Genetic Algorithm–Support Vector Machine (GASVM) Classifier 
Our proposed GASVM algorithm is a genetic algorithm based the SVM classification 
technique. This approach is used to determine the optimal parameters for a traditional SVM classifier. 
A detailed overview is described in the following sections. 
 
2.4.1. Chromosome: A chromosome of GASVM is a string representing kernel function parameters 
and the C penalty parameter. In this study, each chromosome of GASVM consists of 18 bits divided 
into 6 segments. The value of polynomial kernel parameter “degree” is represented by 3 bits (1st 
segment). The value of polynomial, radial basis and sigmoid kernel parameter “gamma” is represented 
by 4 bits (2
nd
 segment). The value of polynomial and sigmoid kernel parameter “coef0” is represented 
by 4 bits (3
rd
 segment). The value of the C parameter is represented by 3 bits (4
th
 segment). The value 
which indicates whether to use shrinking heuristics is represented by 1 bit (5
th
 segment). The value of 
the C parameter weight is represented by 3 bits (6
th
 segment). The combination of these segments 
constitutes the GASVM chromosome. 
The GASVM training model flowchart is illustrated in Figure 3. The algorithm is executed in 
the following steps. Step 1: Randomly generate an initial population of 30 chromosomes. Step 2: 
Define the fitness function and generate the fitness score ranking table. If the population passes the 
termination condition, then record the best chromosome and quit the process. Step 3: Separate the 
chromosome population by fitness score into a good population and a bad population. Step 4: Advance 
the good population to the reproduction and crossover stages, and advance the bad population to the 
mutation stage. Step 5: Generate a new population and iterate to step 2. 
 
2.4.2. Initial population: The initial population of the GASVM training set consists of 30 randomly-
generated chromosomes consisting of 6 segments each. The first segment of a chromosome (bits 1-3) 
represents the “degree” value in the polynomial kernel function and lies between 0 and 7. The second 
segment (bits 4-7) represents the “gamma” value in the polynomial, radial basis, and sigmoid kernel 
 - 6 - 
literature to select 15 breast cancer-relevant genes. The fourth method uses a T-test technique to select 
50 genes. 
 
2.5.3. Application to Combined Microarray and Clinical Data 
The second dataset used to demonstrate the benefits of our GASVM model is the integrated 
dataset. By combining microarray and clinical data, we further improve the classification accuracy of 
our GASVM model. Figure 7 illustrates via flowchart the experimental design with integrated data. 
The 78 patients’ integrated data serves as a training set in either the SVM or the GASVM classifier 
models, and the same four gene selection methods (all 24,881 genes, 70 correlation-selected genes, 15 
medical literature-selected 15 genes, and 50 T-test-selected genes) are used in this experiment. The 
extra 19 patients’ integrated data are used for testing. The classification performance of the SVM is 
then compared to the results from the GASVM. 
3. Results and Discussion  
3.1. Application to Microarray Data  
Table 3 shows the predictive accuracy results of the traditional SVM model with default 
parameter values using four methods of gene selection based on microarray data. 50 T-test-selected 
genes do demonstrate better accuracy (approximately 68%); however, this figure is far from 
satisfactory. This poor accuracy serves as an incentive to develop our proposed GASVM model. The 
classification accuracies of the GASVM model using four gene selection methods based on microarray 
data are shown in Table 4.  In this table, four kernel functions are presented: Linear kernel function 
(Linear), Polynomial kernel function (Polynomial), Radial basis kernel function (RBF), and Sigmoid 
kernel function (Sigmoid). Our proposed GASVM model can significantly raise the prediction 
accuracy rate to near 90% using any of the following methods: 70 correlation-selected genes, 15 
medical literature-selected genes, or 50 T-test-selected genes.   
Figure 8 shows the comparison of predictive accuracy between the SVM and GASVM models 
using genes selected via the four methods. The y-axis represents the prediction accuracy rate while the 
x-axis represents the selected genes. In this figure, Linear kernel function (Lin) is color-coded blue, 
Polynomial kernel function (Poly) is color-coded purple, Radial basis kernel function (RBF) is color-
coded yellow, and Sigmoid kernel function (Sig) is color-coded green. On the left half of Figure 8 we 
see the results of the SVM presented as SVM-All, SVM-C70, SVM-R15, and SVM-T50. On the right 
half of Figure 8, we see the results of the GASVM presented as GASVM-All, GASVM-C70, GASVM-
R15, and GASVM-T50. The results illustrate the benefits of our proposed GASVM model; no matter 
which kernel function is used, the GASVM model has significantly higher predictive accuracy. The 
most significant improvement is seen in the linear and polynomial kernel functions, where the accuracy 
rate increases from approximately 40% to near 90%.  
Note that the accuracy of the GASVM model using microarray data reaches as high an 
accuracy as that generated using clinical data. This raises an interesting question: Can we further 
improve the prediction accuracy rate of our proposed GASVM if we combine the microarray and 
clinical data together? 
3.2. Application to Combined Microarray and Clinical Data  
Table 5 illustrates the prediction accuracy rate of the SVM model using four gene selection 
methods based on microarray data. The default parameter values of the traditional SVM model still do 
not generate a high accuracy rate compared to the results generated by clinical data. Although the 50 T-
test-selected genes demonstrate a higher accuracy (approximately 78%), this is insufficient. To further 
improve the prediction accuracy rate, another model is needed. 
Figure 9 compares the accuracy rates of the SVM model when either microarray data or 
integrated data (microarray and clinical data) is used.  The y-axis represents the predictive accuracy 
rate while the x-axis represents genes selected using four methods: All genes (ALL), 70 correlation-
selected genes (C70), 15 medical literature-selected genes (R15), and 50 T-test-selected genes (T50). 
The left half of Figure 9 shows the results of the SVM with four kernel functions using only microarray 
data and is presented as All, C70, R15, and T50. The right half of Figure 9 shows the results of the 
SVM with four kernel functions using integrated data and is presented as All+8, C70+8, R15+8, and 
T50+8, where 8 refers to the 8 clinical features. 
The results show the benefits of using integrated data. No matter which kernel function is 
selected, the use of integrated data significantly improves the predictive accuracy rate as opposed to 
using microarray data alone. Although the degree of improvement is significant, the highest accuracy 
rate still only reaches 79%. We require a better method to attain better accuracy rates.  
 - 8 - 
In conclusion, the average accuracy rate of the GASVM model with optimized parameter 
values approaches 95% for T50 and 90% for C70 or R15 in all four kernel functions using integrated 
clinical and microarray data. Our model produces results more accurately than the average 60% 
predictive accuracy of a traditional SVM model set with default parameter values. The results show 
that the proposed GASVM model has the potential to assist physicians in the early prognosis of breast 
cancer using integrated clinical and microarray data. 
References 
1. Ahmed M & Rahman N(2006) ATM and breast cancer susceptibility. Oncogene 25, 5906–
5911 
2. Aik Choon Tan & David Gilbert (2003):Ensemble machine learning on gene expression data 
for cancer classification, Bioinformatics:2(3 Suppl) S75–S83 
3. Alexe G, Alexe S, Axelrod DE, Bonates TO, Lozina II, Reiss M, et al. (2006). Breast cancer 
prognosis by combinatorial analysis of gene expression data, Breast Cancer Research, 8:R41 
4. Anne Lise Borresen Dale (2003). TP53 and Breast Cancer. HUMAN MUTATION, 21:292^300. 
5. Bertucci F, Borie N, Ginestier C, Groulet A, Charafe-Jauffret E, Adélaïde J, et al. (2004). 
Identification and validation of an ERBB2 gene expression signature in breast cancers. 
Oncogene, 23, 2564–2575. 
6. Boulesteix AL, Porzelius C, Daumer M.(2008). Microarray-based classiﬁcation and clinical 
predictors: on combined classiﬁers and additional predictive value, BIOINFORMATICS Vol. 
24 no. 15 , pages 1698–1706 
7. Caldeira JR, Prando EC, Quevedo FC, Neto FA, Rainho CA, Rogatto SR. (2006). CDH1 
promoter hypermethylation and E-cadherin protein expression in infiltrating breast cancer. 
BMC Cancer, 6:48. 
8. Chang CC & Lin CJ. (2005): LIBSVM -- A Library for Support Vector Machines. 
http://www.csie.ntu.edu.tw/~cjlin/libsvm/index.html 
9. Chen JJ, Peck K, Hong TM, Yang SC, Sher YP, Shih JY. et. Al  (2001). Global analysis of 
gene expression in invasion by a lung cancer model. Cancer Research 61, 5223-5230, July 1 
10. Chen T, He HL, Church GM.(1999). Modeling Gene Expression with Differential Equations. 
Proc. of Pacific Symposium on Biocomputing, pp. 29-40. 
11. Cristianini, N. & Shawe-Taylor, J. (2000) An introduction to support vector machines. 
Cambridge: Cambridge University Press. 
12. Forcet C, Etienne-Manneville S, Gaude H, Fournier L, Debilly S, Salmi M, et al.(2005) 
Functional analysis of Peutz–Jeghers mutations reveals that the LKB1 C-terminal region 
exerts a crucial role in regulating both the AMPK pathway and the cell polarity. Hum. Mol. 
Genet. 14 (10): 1283 
13. Frank B, Hemminki K, Meindl A, Wappenschmidt B, Sutter C, Kiechle M et al.(2007) BRIP1 
(BACH1) variants and familial breast cancer risk: a case-control study. BMC Cancer, 7:83 
14. Friedman N, Linial M, Nachman I & Pe'er D. (2000) Using Bayesian networks to analyze 
expression data. Journal of Computational Biology, 7(3-4), 601-620, 
15. Greer BT & Khan J(2004): Diagnostic classification of cancer using DNA microarrays and 
artificial intelligence. Ann N Y Acad Sci, 1020:49-66. 
16. Gunn, SR. (2004): Support Vector Machines for Classification and Regression. 
Technicalreport, Image speechandintelligent systems research group, University of 
Southampton, UK,. Available on http://www.ecs.soton.ac.uk/srg/publications/pdf/SVM.pdf 
17. Heikkinen K, Karppinen SM, Soini Y, Mäkinen M, Winqvist R. (2003).Mutation screening of 
Mre11 complex genes: indication of RAD50 involvement in breast and ovarian cancer 
susceptibility. Journal of Medical Genetics;40:e131. 
18. Heikkinen K, Rapakko K, Karppinen SM, Erkko H, Knuutila S, Lundán T, et al.:(2006). 
RAD50 and NBS1 are breast cancer susceptibility genes associated with genomic instability. 
Carcinogenesis, 27(8):1593-1599.  
19. Helman P, Veroff R, Atlas SR, Willman C.(2004). A Bayesian network classification 
methodology for gene expression data.  J. Comput. Biol, 11, 581–615 
20. Herman GE, Butter E, Enrile B, Pastore M, Prior TW, Sommer A. (2007) Increasing 
Knowledge of PTEN Germline Mutations; Two Additional Patients With Autism and 
Macrocephaly. American Journal of Medical Genetics Part A 143A:589–593. 
21. Huang, C. & Wang, C. (2006) A GA-based feature selection and parameters optimization for 
support vector machines, Expert Systems with Applications, Volume 31, Issue 2, Pages 231- 
240. 
 - 10 - 
44. van de Vijver MJ, He YD, van't Veer LJ, Dai H, Hart AA, Voskuil DW. et al.(2002) A Gene-
expression signature as a predictor of survival in breast cancer. N Engl J Med, Vol. 347, No. 
25, December 19  
45. Walsh T, Casadei S, Coats KH, Swisher E, Stray SM, Higgins J et al. (2006) Spectrum of 
Mutations in BRCA1, BRCA2, CHEK2, and TP53 in Families at High Risk of Breast 
Cancer. JAMA; 295:1379-1388. 
46. Yang C, Ionescu-Tiba V, Burns K, Gadd M, Zukerberg L, Louis DN, et al. (2004). The Role 
of the Cyclin D1-Dependent Kinases in ErbB2-Mediated Breast Cancer. American Journal 
of Pathology; 164:1031-1038. 
 - 12 - 
Figure 3: The GASVM training model flowchart 
 
 - 14 - 
Figure 6: Experimental design of SVM or GASVM models using microarray data 
 
Figure 7: Experimental design of GASVM model using integrated microarray and 
clinical data 
 
 - 16 - 
Figure 10: Comparison of the classification accuracy for the GASVM model using 
microarray data versus integrated data 
 
Figure 11: Comparison of the predictive accuracy for the SVM and GASVM models 
using combined microarray and clinical data 
 
 
 - 18 - 
Lymphocytic Infiltrate Presence of Lymphocytic Infiltrate 
 
Table 3: Classification accuracies of the SVM model using four gene selection methods 
based on microarray data 
 
 All genes 
70 correlation-
selected genes 
15 medical literature–
selected genes 
50 T-test-selected  
genes 
Linear 36.84% 63.15% 42.1% 63.15% 
Polynomial 36.84% 36.84% 36.84% 68.42% 
RBF 36.84% 36.84% 36.84% 68.42% 
Sigmoid 36.84% 36.84% 36.84% 63.15% 
 
Table 4: Classification accuracy of the GASVM model using four gene selection 
methods based on microarray data 
 
 All genes 
70 correlation-
selected genes 
15 medical literature–
selected genes 
50 T-test-selected  
genes 
Linear 84.21% 89.47% 89.47% 89.47% 
Polynomial 36.84% 89.47% 89.47% 89.47% 
RBF 63.15% 42.10% 57.89% 78.94% 
Sigmoid 36.84% 36.84% 42.10% 68.42% 
 
 
Table 5: Classification accuracy of the SVM model using four gene selection methods 
based on combined microarray and clinical data 
 
 
All genes + 
Clinical 
70 correlation-
selected genes + 
Clinical 
15 medical literature-
selected genes + Clinical 
50 T-test-selected  
Genes + Clinical 
Linear 68.42% 73.68% 52.63% 78.94% 
Polynomial 63.15% 63.15% 57.89% 68.42% 
Radio 63.15% 42.10% 36.84% 78.94% 
Sigmoid 52.63% 68.42% 36.84% 68.42% 
 
Table 6: Classification accuracy of the GASVM model using four gene selection 
methods based on combined microarray and clinical data 
 
表 Y04 
行政院國家科學委員會補助國內專家學者出席國際學術會議報告 
                                                             101年 7 月 30日 
報告人姓名 陳信志 Austin H. Chen 
 
服務機構 
及職稱 
慈濟大學 醫學資訊系(所) 
助理教授 
     時間 
會議 
     地點 
會議自 100 年 9 月 18 日起至 
100 年 9 月 21 日止，合計 4
天 [台灣時間], 地點在杭州  
浙江賓館 
本次會議帶四位學生參加 
本會核定 
補助文號 
NSC100-2221-E-320-001 
會議 
名稱 
38th Annual Scientific Conference of Computing in Cardiology (CinC2011) 
發表 
論文 
題目 
1 篇英文論文發表 “HDPS: Heart Disease Prediction System” 
告內容應包括下列各項： 
一、參加會議經過 
Computing in Cardiology (formerly Computers in Cardiology) is an international scientific 
conference that has been held annually since 1974. CinC provides a forum for scientists and 
professionals from the fields of medicine, physics, engineering and computer science to 
discuss their current research in topics pertaining to computing in clinical cardiology and 
cardiovascular physiology. 此次會議為心臟疾病研究的大型國際會議，本次會議接觸到來
自全世界的心臟疾病專家學者,可以替台灣及慈濟醫資系(所)擴大交流, 此篇論文已發表
在 EI Indexed 的 Computing in Cardiology 上 
 
二、與會心得與建議 
參與此次國際會議的最大心得，就是有機會和來自世界各地的學者專家交流，深感獲益良多，
一些小小的建議如下： 
 參與國際會議對老師的研究水準、國際觀，有非常大的幫助，國科會及學校方面應
大力鼓勵(包括經費實質補助)老師參與國際活動，對於國家及學校的知名度一定會提
升，以這次會議為例，來自世界各地 20 多國的專家學者經由交流、演講對台灣學術
界多少有些了解。 
 最大的感觸是現在在海外接觸到的華人學者專家，絕大多數是從中國大陸出來的，
這和在十幾年前我所參加的國際會議幾乎都是台灣出去的完全相反。如果歷史是借
鏡的話，台灣的經濟奇蹟恐怕很難再現，學校方面應大力鼓勵本校學生在畢業後儘
可能出國進修，目前在我的實驗室已在大力倡導讓學生了解接觸世界的重要性。 
  
三、攜回資料名稱及內容 
 Conference Program, 38th Annual Scientific Conference of Computing in Cardiology 
(CinC2011) 
 論文發表 PDF 檔案 Austin H Chen, S Y Huang, P S Hong, C H Cheng, E J Lin, 
“HDPS: Heart Disease Prediction System”, Computing in Cardiology, Vol 38, pp 
557-560, 2011 (EI). 
 
附
件
三 
表 Y04 
HDPS: Heart Disease Prediction System 
Austin H Chen, S Y Huang, P S Hong, C H Cheng, E J Lin 
Department of Medical Informatics, Tzu Chi University, Hualien City, Taiwan 
 
 
Abstract 
The diagnosis of heart disease in most cases depends on a complex combination of clinical and pathological data. 
Because of this complexity, there exists a significant amount of interest among clinical professionals and researchers 
regarding the efficient and accurate prediction of heart disease. 
In this paper, we develop a heart disease predict system that can assist medical professionals in predicting heart 
disease status based on the clinical data of patients. Our approaches include three steps. Firstly, we select 13 important 
clinical features, i.e., age, sex, chest pain type, trestbps, cholesterol, fasting blood sugar, resting ecg, max heart rate, 
exercise induced angina, old peak, slope, number of vessels colored, and thal. Secondly, we develop an artificial neural 
network algorithm for classifying heart disease based on these clinical features. The accuracy of prediction is near 80%. 
Finally, we develop a user-friendly heart disease predict system (HDPS). 
The HDPS system will be consisted of multiple features, including input clinical data section, ROC curve display 
section, and prediction performance display section (execute time, accuracy, sensitivity, specificity, and predict result).  
Our approaches are effective in predicting the heart disease of a patient. The HDPS system developed in this study is 
a novel approach that can be used in the classification of heart disease. 
  
1. Introduction 
The diagnosis of heart disease in most cases depends on a complex combination of clinical and 
pathological data; this complexity leads to the excessive medical costs affecting the quality of the 
medical care [1]. According to the statistic data from WHO, one third population worldwide died 
from heart disease; heart disease is found to be the leading cause of death in developing countries 
by 2010. It shows one third American adult have one or more types of heart diseases based on 
American Heart Association report. Computational biology is often applied in the process of 
translating biological knowledge into clinical practice, as well as in the understanding of biological 
phenomena from the clinical data. The discovery of biomarkers in heart disease is one of the key 
contributions using computational biology.  This process involves the development of a predictive 
model and the integration of different types of data and knowledge for diagnostic purposes. 
Furthermore, this process requires the design and combination of different methodologies from 
statistical analysis and data mining [2,3]. 
In the past decades, data mining have played an important role in heart disease research. To find the 
表 Y04 
defect; 7 = reversible 
defect 
Num Diagnosis of heart 
disease 
      
In Table 1, there are 14 attributes used in this system, including 8 symbolic and 6 numeric:  age 
(age in years), sex (male, female), Chest pain type (typical angina, atypical angina, non-angina pain, 
asymptomatic), Trestbps (resting blood pressure in mm Hg), cholesterol (serum cholesterol in 
mg/dl), fasting blood sugar < 120 mg/dl (true or false), resting electrocardiographic results (normal, 
having ST-T wave abnormality, showing probable or definite left ventricular hypertrophy by Estes' 
criteria), max heart rate, exercise induced angina (true or false), oldpeak (ST depression induced by 
exercise relative to rest), slope (up, flat, down), number of vessels colored by fluoroscopy (0-3), thal 
(normal, fixed defect, reversible defect), and class (healthy, with heart-disease). 
  
2.3. Artificial Neural Network 
In this paper, we use C as a tool to implement heart disease classification and prediction trained 
via ANN.   Learning Vector Quantization (LVQ), a prototype-based supervised classification 
algorithm, is used in this study. LVQ can be understood as a special case of an artificial neural 
network. One benefit of LVQ is that it creates prototypes that are easy to interpret for experts in the 
respective application domain. LVQ applies a winner-take-all Hebbian learning approach that is a 
precursor to k-Nearest neighbor algorithm (KNN) and Self-organizing maps (SOM).
  
An LVQ system is represented by prototypes W=(w(i),...,w(n)) which are defined in the feature 
space of observed data. In winner-take-all training algorithms one determines, for each data point, 
the prototype which is closest to the input according to a given distance measure. The position of 
this so-called winner prototype is then adapted, i.e. the winner is moved closer if it correctly 
classifies the data point or moved away if it classifies the data point incorrectly. A key issue in LVQ 
is the choice of an appropriate measure of distance or similarity for training and classification. 
The network contains three layers: the input layer, the hidden layer and the output layer, having 
13 neurons, 6 neurons and 2 neurons respectively.  Figure 1 displays the framework of the model. 
  
 
  
表 Y04 
 
       
Figure 3. The design flowchart of the HDPS: It starts with 13 input clinical data and proceeds to 
develop ANN algorithm. After training model, it can generate the prediction results 
   
3.2.  The Interface of the HDPS 
The main functions of the HDPS interface shown as Figure 4 include: 
(1) Input clinical data section: users input 13 pieces of clinical data. 
(2) ROC curve display section: it displays the ROC curve  
of the HDPS. 
(3) Prediction performance display section: it displays the HDPS prediction performance including 
accuracy, sensitivity, specificity and prediction result. 
(4) Predict button: users click the button to get the result. 
(5) Clear button: users click the button to clear the previous input  
(6) Quit button: users click the button to leave this interface 
(7) Prediction result: this text box shows the prediction result of the provided clinical data.  
  
 
 
Figure 4. The HDPS interface: The HDPS interface consists of three panels: the Data input panel for the patient’s 
clinical data, ROC curve display section, and prediction performance display section (execute time, accuracy, 
sensitivity, specificity, and predict result). 
表 Y04 
[3] Asha Rajkumar, G.Sophia Reena. Diagnosis Of Heart Disease Using Datamining Algorithm. 
Global Journal of Computer Science and Technology 2010;10:38-43. 
[4] M. Anbarasi, E. Anupriya, N.CH.S.N.Iyengar. Enhanced Prediction of Heart Disease with 
Feature Subset Selection using Genetic Algorithm. International Journal of Engineering Science 
and Technology 2010;2: 5370-76. 
[5] Sellappan Palaniappan, Rafiah Awang. Intelligent Heart Disease Prediction System Using Data 
Mining Techniques. International Journal of Computer Science and Network Security 
2008;8:343-50. 
[6] W.G Baxt. Application of artificial neural networks to clinical medicine. The Lancet 
1995;346:1135-38. 
[7]   http://archive.ics.uci.edu/ml/datasets/Heart+Disease 
  
Address for correspondence. 
 
Austin H Chen  
Department of Medical Informatics, Tzu Chi University, No. 701, Sec. 3, Jhongyang Rd. Hualien 
City, Hualien County 97004, Taiwan 
achen@mail.tcu.edu.tw 
 
100年度專題研究計畫研究成果彙整表 
計畫主持人：陳信志 計畫編號：100-2221-E-320-001- 
計畫名稱：從微型核糖核酸及基因表現分佈探討乳癌,心臟疾病,及帕金森疾病的生物標誌 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 5 2 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
