  
search algorithm for optimization problems [3]. 
However, ACO may still suffer from inefficiency in 
various applications. Because HNN has random initial 
problem, it may influence search efficiency. Thus, in 
this study, we also propose GAHNNACO not only to 
improve HNN initial problem but also to enhance total 
search efficiency. 
Genetic algorithms (GAs) can handle any kind of 
objective functions without much mathematical 
requirements about the optimization problems. GAs 
use a population of solutions, from which, using 
crossover, mutation and selection strategies, better and 
better solutions can be produced. Various GAs have 
been proposed in the literature and shown superior 
performances. Because HNN can be found that the 
selection of initial solutions has a great influence on 
the search performance. In our paper, we propose to 
use Genetic algorithms to provide feasible solutions 
for HNN.  
2. Formulation of HNN for TSP 
First, we need to define a representation scheme 
for the tour, or more specifically, the tour has to be 
encoded by the states of a set of neurons. Hopfield and 
Tank [3] used a scheme in which N2 neurons are 
needed for a N-city problem. The tour can be 
conveniently represented by a N×N matrix. If element 
ij is equal to one, then city i has the jth position in the 
tour. Secondly, a Hopfield energy function and the 
corresponding weights have to be defined. The 
following energy function is proposed in [4]: 
1 2
2
3 4
, 1 , 1
2 2
   ( ),
2 2
xi xj xi yi
x i j i i x y x
xi xy xi y i y i
x i x y x i
W WE s s s s
W Ws N d s s s
≠ ≠
+ −
≠
= +
 + − + +  
∑∑∑ ∑∑∑
∑∑ ∑∑∑
  (1)                                                            
where W1, W2, W3 and W4 are positive coefficients and 
all indices in Eq. (1) are defined in modulo N. For 
convenience double-indices are used. For instance, sxi 
denotes the output of the neuron corresponding to city 
x and tour position i. The distance between cities x and 
y is indicated by dxy. The first three terms of the 
energy function correspond to the constraints of TSPs 
and measure the degree of whether the solution is a 
valid path. Assume that the Hopfield net reaches a 
steady state with outputs only either ‘0’ or ‘1’. The 
first term is only zero if and only if each row has not 
more than one ‘1’, which is the constraint that each 
city is allowed to be visited only once. The second 
term is zero if and only if each column has not more 
than one ‘1’, which corresponds to the constraint that 
each position of the tour can only be occupied by one 
city. The third term is to meet the constraint that 
exactly N cities are visited on the tour. The final term 
penalizes tours with long distances. This term is 
directly proportional to the length of the tour. Hence, 
the state with the lowest energy should correspond to 
the optimal tour. Now define 
, 1 2
3 4 , 1 , 1
(1 ) (1 )
        ( ),
xi yj xy ij ij xy
xy j i j i
w W W
W W d
δ δ δ δ
δ δ+ −
= − − − −
− − +      (2)  
where ijδ  is 1 (i=j) or 0 (otherwise). Then, the 
energy function in Equation (1) can be rewritten as 
            
, ,
2
1
2
   .
2
xi yj xi yj xi
x y i j x i
E w s C Ns
C N
= − −
+
∑∑∑∑ ∑∑
 (3)  
It can be shown that this is a Lyapunov equation [4]. 
This energy function can easily be implemented as a 
Hopfield net. 
3. Basics of GAs and ACO 
Genetic algorithms start with a set of randomly 
selected chromosomes as the initial population that 
encodes a set of possible solutions. In GAs variables 
of a problem are represented as genes in a 
chromosome, and the chromosomes are evaluated 
according to their costs using some measures of profit 
or utility that we want to optimize. The recombination 
typically involves two genetic operators: crossover 
and mutation. The genetic operators alter the 
composition of genes to create new chromosomes 
called offspring. In crossover operator, it generates 
offspring that inherits genes from both parents with a 
crossover probability Pc. In mutation operator, it 
inverts randomly chosen genes in a chromosome with 
a mutation probability Pm. The selection operator is an 
artificial version of natural selection, a Darwinian 
survival of the fittest among population, and 
chromosomes with better cost have higher 
probabilities of being selected in the next generation. 
After several generations, GA can converge to the best 
solution.  
When implementing the ACO algorithm for TSPs, 
agent starts from a random city and successively visits 
another city until all cities are visited. In the process of 
Agents_generation_and_activity, the agent- decision 
table for agent k assigning agent i to city j is governed 
by 
0( )
arg{ max [ ( ) ]} ( )
( ) k
ij iji allowed t
t when q q
j
S otherwise
βτ ηπ = ⋅ ≤= 
(4) 
where ηij is the heuristic information and is set as the 
inverse of the distance, β is a parameter representing 
the importance of heuristic information, q is a random 
number uniformly distributed in [0,1], q0 is a 
pre-specified parameter (0≤ q0≤1), allowedk(t) is the 
set of feasible cities currently not visited by agent k at 
time t, and S is an index of a city selected from 
allowedk(t) according to the probability distribution 
given by 
