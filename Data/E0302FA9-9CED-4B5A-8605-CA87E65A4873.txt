 1
整合不同攝影機之街道監控系統 
Video Surveillance System in Street Environment Using Heterogeneous Cameras 
 
國科會補助專題研究計畫 
計畫編號：NSC 97-2221-E-147-005- 
計劃執行：97 年 08 月 01 日 至 98 年 07 月 31 日 
計畫主持人：江政杰 德明財經科技大學 資訊科技系 助理教授 
 
中文摘要 
 
本計畫的主要目標在於整合街道上不同之攝影機，對應至單一街道地圖上之監控系統環
境。首先，本計畫將會以一個地圖系統為主軸，對各攝影機進行相機校正，以取得各攝影
機之內部參數；同時我們會設計一套兩階段的計算方法，來計算街道地圖與攝影機影像之
間的座標轉換。透過一些特徵點的訓練資料，我們設計一套疊代式的演算法，計算出攝影
機在街道地圖上的位置與仰角等相機外部參數；然後，我們設計出街道地圖上的 3D 座標
與攝影機影像上的 2D 座標之間的轉換。各攝影機的畫面均可藉由此程序對應至街道地圖
上，我們就可以將各攝影機的拍攝內容整合到地圖上展示。除此之外，我們同時設計一套
影片之前景移動物之偵測與追蹤，將移動物之位置對應到街道地圖上，可以完成監控系統
環境的運作。 
 
英文摘要 
 
This project aims to integrate heterogeneous cameras in streets to build a video surveillance 
system based on a unified city map. We first perform the task of camera calibration for each 
camera in the city map to get its interior parameter. Therefore, we propose a two-phase approach 
to determine the correspondence mappings between the positions in the city map and the camera 
views. By collecting several correspondence points of the city map and an image plane, our 
approach can interactively estimate the position of the corresponding cameras in the city map. 
Next, the transformation between 2D coordinates in the image and 3D coordinates in the city map 
can be computed based on the estimated position of the camera. Moreover, we also design an 
approach for moving object detection and tracking in a video sequence.  
 
 
 
 3
依據各攝影機的影像內容，計算出監控目標在街道地圖上的位置，進而達到大範圍區域之
監控目的。 
我們以圖一來說明本計畫主要的工作。圖一的(a)是一個街道上的地圖，而(b)則是此地
圖中某一場景的攝影機所拍攝到的畫面，圖片上的紅色標記代表這兩個視角上相同的點。
簡單來說，在地圖上各個角落會有為數不等的攝影機，各攝影機所拍攝到的場景位置都可
以對應到地圖上的某一點。雖然不見得所有攝影機的畫面可以涵蓋街道地圖的全部範圍，
但是將這些攝影機整合起來已經是最經濟但最有效的作法。因此我們的想法是針對每一個
別的攝影機畫面，計算出與街道地圖的座標轉換，如此在各攝影機所看到的畫面，可以對
應到單一的地圖上，進而整合各攝影機的拍攝成果，同時亦不會影響到攝影機原先之運作。 
 
 
(a). 在街道地圖上的座標點 
 
(b). 在攝影機影像上的座標點 
圖一、街道地圖與攝影機影像座標之轉換 
 
本計畫設計一個兩階段的計算方法，來計算街道地圖與攝影機影像之間的座標轉換。
首先，透過一些特徵點的訓練資料如圖一的紅色標註點，以及已知的相機內部參數，我們
設計一套疊代式的演算法，可以計算出攝影機在街道地圖上的位置與仰角等相機外部參
數；藉由計算出的相機資訊，我們設計出街道地圖上的 3D 座標與攝影機影像上的 2D 座標
之間的轉換。由於此程序只需要知道相機內部參數與事前取出對應之特徵點，也就是說要
整合的攝影機只需要經過相同的程序，均可以把影像上的座標位置對應到相同的街道地圖
上，取得一個整體的座標資訊。 
整合攝影機影像畫面後，另一個問題是偵測視訊內的前景物並加以追蹤。針對影片內
容判斷前景與背景[6][12]，以及對移動物體的追蹤[13][15]，都是電腦視覺的熱門研究主題，
也都有許多研究者投入。考量到未來攝影機整合後資料量的龐大，本計畫採用較簡單的模
式處理這兩個問題。首先得考量在影片中何為前景，最簡單的想法就是在同一座標點上橫
跨時間軸來觀察，在一段時間內某一座標點的像素值並沒有劇烈的改變，那麼這一點是背
景的可能性就會提高。因此我們對影片內容在時間軸上執行中 median filtering，先判斷出背
景的資訊，剩下的就是影片中的前景移動物；而連續的移動物偵測其實就組成了追蹤的效
果。 
本報告的章節組織如下。第 2 節將描述相機的內部、外部參數資訊，第 3 節介紹街道
地圖與攝影機畫面之對應，包括了先找出街道地圖上的相機定位，然後建立街道地圖上的
 5
 
圖三、相機校正所使用的 pattern 
 
3. 街道地圖與攝影機畫面之對應 
 
3.1. 街道地圖上的相機定位 
 
取得相機的內部參數 K 之後，下一步驟計算出相機的外部參數，包含旋轉矩陣 R 與
位移向量 T，其中向量 T 必須是以地圖之全域的座標系(global coordinate system)表示。假
設如圖一我們針對某一攝影機畫面與街道地圖取得一組對應點，令 X 是對應點中地圖上的
3D 座標，而 x 是對應點中的相機影像 2D 座標。我們設計一套操作介面協助使用者設定二
者之對應點，但是在地圖上的座標點是一定會有誤差，這是因為地圖本身就會具有誤差，
同時人工在地圖上點某一位置時也不可能絕對正確；在影像上的 2D 點則是為準確的，我
們以 ixˆ 表示。下面我們將描述相機定位的演算法。 
 
Camera Localization Algorithm 
Initialize R = I and C = 0. 
1. Compute 3D points in camera coordinate 
)(' CR −= ii XX  (3)
2. Compute project lines 
ii xˆ
1−= KP  (4)
3. Compute ideal position iQ  of 
'
iX  
iiiQ Pρ= , then 'iii X=Pρ , 
ii
ii
i PP
XP
T
'T
=ρ  (5)
4. Compute best-fit camera rotation matrix R 
QQXX iiii −=−= '      rr  
 MMUrrM T
3
1
T'       ==∑
=i
i  
 ∑
=
− ==
3
1
T2/1 1      
i
j
j
j
vvλUMUR  
where λ and vi are eigenvalues and eigenvectors of U, respectively. 
(6)
5. Compute camera center C 
)(1 QX −= − RRC  (7)
6. repeat steps 1-5 until convergence 
 
 7
 
(a). 街道地圖與對應點 (b). 攝影機畫面與對應點 (c). 以(b)的影像畫面計算得
出之攝影機位置(+)與對應點
圖四、在街道地圖上的攝影機位置定位 
 
藉由圖四(a)與(b)所算出的相機位置後，我們在街道地圖上給予若干 3D 點，計算出對
應於相機影像上的座標位置。圖五顯示三組各 5 個在街道地圖上的 3D 點，雖然可以看的
出一些誤差，但是各點之間的相對位置仍能完整呈現，也代表著地圖上適當的區域可以對
應到攝影機畫面的座標系統上。 
 
 
圖五、由街道地圖的座標點轉換至影像平面座標 (3D to 2D) 
 
同樣的，我們在攝影機畫面上給予若干 2D 點，計算出對應於街道地圖上的座標位置。
圖六顯示三組各 5 個在攝影機畫面上的 2D 點，顯示在街道地圖上的座標範圍，可以看出
此攝影機所拍攝範圍在地圖上的對應區域。結合各攝影機個別對應到街道地圖後，就可以
正確的整合各獨立的攝影機畫面。 
 
 9
 
圖七、在時間為 t 時的影片中(x, y)座標點判斷是否為前景移動物 
 
圖七描述我們判斷影片內前景移動物的方法。針對影片中任何一座標點(x, y)而言，於
時間為 t 時是否為前景或背景，我們將前後一段時間的相同座標點集合起來：(x, y, t-h), ..., (x, 
y, t+h)，將這些點的像素值取 median filtering，取出的中間值如果與(x, y, t)的像素值一樣或
者是非常接近，這樣我們可以知道(x, y, t)的值在前後時間內並沒有什麼變化，因此我們就
定義(x, y, t)為背景；反過來說，如果(x, y, t)的像素值與中間值有明顯的差異，這個點就是
前景的一部分。 
這樣的定義會對光影的變化非常敏感，例如影子或是有雲飄過去，光線的改變就會被
判斷成前景的一部分。因此針對影片中被判斷成前景的各像素點，我們先取 erosion 再取
dilation 將雜訊去除，然後進行 8-connected-component，如此移動之前景物就可以被獨立並
且加以定位。詳細的演算法如下所述。 
 
Foreground Detection Algorithm 
Input: a video V 
1. for each pixel p(x, y, t) in video V 
m = median(p(x, y, t-h), ..., p(x, y, t), ..., p(x, y, t+h)) 
if |m-p(x, y, t)| > threshold 
then p(x, y, t) is in foreground  // else in background 
end for 
2. for each frame of V, make a binary image by labeling foreground pixels 
3. for each binary frame of V 
erosion 
dilation 
8-connected-component 
end for 
4. allocate and mark moving objects in the videos 
 
圖八展示監視系統的影片中所進行的前景移動物之偵測與追蹤，由連續四秒(t=55 至
58 秒)的畫面切割中，我們可以觀察移動物追蹤之效果。圖八的上方是原始影像，偵測到的
移動物體我們以紅色矩形框起來；而中間是對應的移動物區域，我們以灰色區塊來展示所
偵測到的非背景區域。由這個例子可以看到，在攝影機的畫面中，我們可以將前景與背景
 11
 
6. 參考文獻 
 
本計畫發表之論文 
 
[1] Wee Kheng Leow, Cheng-Chieh Chiang, and Yi-Ping Hung, "Localization and Mapping of 
Surveillance Cameras in City Map", in Proceedings of ACM International Conference on 
Multimedia, ACMMM, Vancouver, Canada, 2008. 
[2] Yi-Chia Chan, Cheng-Chieh Chiang, Kai-Ming Wang, and Greg C. Lee, "Video-Based Face 
Recognition Using A Probabilistic Graphical Model", in Proceedings of the 11th IAPR 
Conference on Machine Vision Applications, MVA, Japan, 2009. 
[3] Cheng-Chieh Chiang, Kai-Ming Wang, and Greg C. Lee, "Multi-pose Face Tracking and 
Detection Using Condensation and Checklist", in Proceedings of IPPR Conference on 
Computer Vision, Graphics and Image Processing, CVGIP, Taiwan, 2009. 
 
其他參考文獻 
 
[4] A. Basu and D. Southwell, “Omni-directional sensors for pipe inspection”, in Proc. IEEE 
Int. Conf. Systems, Man and Cybernetics, vol. 4, 1995, pp. 3107–3112. 
[5] Camera Calibration Toolbox for Matlab, http://www.vision.caltech.edu/bouguetj/calib_doc/ 
[6] Y.-T. Chen, C.-S. Chen, C.-R. Huang and Y.-P. Hung, “Efficient Hierarchical Method for 
Background Subtraction”, Pattern Recognition, vol. 40(10), pages 2706-2715, October 
2007. 
[7] R. T. Collins, A. J. Lipton, T. Kanade, H. Fujiyoshi, D. Duggins, Y. Tsin, D. Tolliver, N. 
Enomoto, O. Hasegawa, P. Burt, and L.Wixson, “A system for video surveillance and 
monitoring”, Carnegie Mellon Univ., Pittsburgh, PA, Tech. Rep., CMU-RI-TR-00-12, 2000. 
[8] R. Collins, A. Lipton, H. Fujiyoshi, and T. Kanade, “Algorithmsfor cooperative multisensor 
surveillance”, in Proceedings of the IEEE, vol. 89(10), pages 1456-1477, Oct. 2001. 
[9] T. Gandhi and M. M. Trivedi, “Calibration of a Reconfigurable Array of Omnidirectional 
Cameras Using a Moving Person”, in Proc. 2nd ACM International Workshop on Video 
Surveillance and Sensor Networks, pages 12–19, New York, NY, 2004. 
[10] I. Haritaoglu, D. Harwood, and L. S. Davis, “W4 : Real-time surveillance of people and 
their activities”, IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 22, 
pages 809–830, Aug. 2000. 
[11] R. I. Hartley and A. Zisserman, “Multiple View Geometry in Computer Vision”, Cambridge 
University Press, 2004. Second Edition. 
[12] M, Heikkila and M. Pietikainen, “A texture-based method for modeling the background and 
detecting moving objects,” IEEE Transactions on Pattern Analysis and Machine Intelligence, 
vol. 28(4), pages 657-662, 2006. 
行政院國家科學委員會補助國內專家學者出席國際學術會議報告 
                                               98年 6月 1日 
報告人姓名 江 政 杰 服務機構 德明財經科技大學 資訊科技系 職稱 助理教授 
中文： 
會議正式名稱 
英文：11th IAPR Conference on Machine Vision Applications, 2009 (MVA 2009) 
會 議 時 間       自 98 年 5 月 20 日 至 98 年 5 月 22 日 地點（國、州、城市） 
日本、橫濱 
Yokohama, Japan 
報告內容應包括下列各項： 
 
一、 參加會議經過 
 
11th IAPR Conference on Machine Vision Applications (MVA 2009)是日本機器視覺與應用組
織(Machine Vision and Application Organization)所籌劃，每隔兩年在日本各地舉辦一次的
國際學術研討會，會議的主軸是電腦視覺與其相關應用之研究，在電腦視覺的研究領域
上還頗有名氣。本人於去年底投稿論文於此研討會，承蒙接受刊登於是在今年五月前往
參與。 
 
本屆研討會的舉辦地點在日本橫濱的慶應大學日吉校區所舉辦，雖然是固定由日本舉辦
的學術研討會，但是歐美參與的學者非常多；相對而言，台灣出席的學者數量並不多。
此會議於 5 月 20 日開始共三天，每日依據論文的主題分類，由與會者進行論文發表簡報，
並穿插論文 poster 展示，讓與會者可以自由在會場交談討論；主辦單位同時邀請數位知
名學者發表演講，分享他們在各研究主題上之心得。本次會議我有兩篇論文刊登發表，
兩篇都是 poster 展示，時間分別是 5/20 與 5/22 頭尾兩天。與上台演講發表不同，poster
展示必須對每位有興趣的觀眾講解，並且在互動的狀況下回答各種問題，可以針對自己
的研究主題進行最直接的交流。 
 
參與國際學術研討會時，除了可以針對自己研究主題聽取別人的意見外，也可以看看別
人的研究主題與進度，直接與作者面對面溝通，互相交換對問題的見解，這是非常棒的
感覺。很多的研究主題非常有趣，讓我在參與的過程中，充分感覺到不同的研究題目所
給予的刺激，對於未來的研究能量擴展有非常大的助益。 
 
 
 
 
