 2
前言 
In a variety of multimedia applications, the storage 
and transmission of image and video always deeply 
attract the users. However, since the data 
transmission has to meet the constraint of channels 
with time-varying bandwidth, a flexible and 
adaptive rate control mechanism is needed to 
handle with the corresponding parameters in the 
encoder and maintain the limited bandwidth during 
transmission. In low bitrate video transmission for 
mobile devices, the region-of-interest (ROI) video 
coding based on the rate control mechanism 
provides a solution to enhance the visual quality in 
the region-of-interest area. 
 
研究目的 
In this project, an ROI determination is first 
proposed to fast and efficient select the ROI area. 
And then, the region-of-interest video coding 
algorithm based on H.264 video coding standard [1] 
is further proposed to enhance the visual quality in 
the ROI area through the rate control mechanisms. 
 
文獻探討 
ROI determination 
For video encoding and surveillance, the moving 
objects will catch users’ focus points as ROIs in 
consecutive frames. Several hybrid algorithms have 
been proposed to determine ROIs with human 
attention information. Itti et al. [2] integrated 
several spatial visual features into a single saliency 
map for representing local conspicuousness in 
images. Agarwal et al. [3] used edge, motion and 
spatial frequency content of a video frame as the 
parameters for perceptually identifying important 
regions in compressed video data. The intensity, 
color, texture and motion information are employed 
in [4] to capture users’ focus points. Furthermore, 
camera motion is taken into consideration in [5] to 
determine ROIs. Ma et al. [6] combined many 
processes to analyze video content and obtain visual 
attention models. Liu et al. [7] detected the ROI 
mask by the minimum absolute difference (MAD) 
information. Motion-based methods [4]-[7] 
employed motion information obtained by the 
statistics of pixel variation, such as motion vector, 
motion magnitude and MAD values. However, 
motion estimation process is computational 
intensive and a scene change will significantly 
cause errors. Although some of the above methods 
can obtain satisfactory results in determining the 
ROIs in video data, they are time consuming and 
unfavorable to the real-time applications. Lee et al. 
[8] proposed an ROI based image segmentation 
method to select salient regions by using scale 
salient information of features, including the 
intensity, the edge and the color variation. Zhang et 
al. [9] first classified images into two groups 
according to their complexity, and then they 
extracted ROIs based on the sharp edges and color 
differences. Although the algorithms proposed in [8] 
and [9] can obtain the contour of ROIs, they are still 
too time consuming to be applied in the real-time 
applications. 
ROI video coding 
Although the ROI has higher quality, it may discard 
some background information to improve the 
encoding speed [10]. For example, Chai et al. 
proposed maximum bit transfer (MBT) [11] that 
force the coarsest quantization level the background 
in order to enhance the foreground. For sign 
language transmissions, grounding the area 
where the sign language is performed, the 
algorithm in [12] provides the high temporal 
resolution and better compression in the area of 
hands and arms for the limited bandwidth. 
Wang et al. [13] dynamically determined the 
background skip mode based on the current content 
information. A region-based blurring algorithm 
decreases the high frequency information on the 
background to reduce bit-rate at very low bit-rate 
video coding [14]. However, the information, such 
as motion vector and DCT coefficients, are totally 
lost if a skip mode is applied to the macroblock in 
the background. In [15], Chai et al. proposed a 
simple two-level quantization scheme which 
assigns a finer quantizer to the foreground and a 
coarser quantizer to the background. Some research 
works on the region/content-based rate-control 
proposed in [16]-[18] adopted a heuristic approach 
to decide the QPs for different regions in a frame. 
However, these factors are heuristically set to 
constants, and the contents of regions are not taken 
into consideration. The concept of the QP 
adjustments indeed exists in these algorithms; 
however, they lack an adaptive mechanism to 
perform bit allocation among different regions. It 
may result in improper QPs, unreasonable bits used 
for different regions, and the sub-optimal perceptual 
quality, which is crucial in the low-bit rate video 
coding. In most ROI video coding algorithms, they 
only consider the spatial information such as 
content complexity of a macroblock without the 
temporal characteristics such as the encoded 
information of the previous frames, and most of the 
previous works lack the adaptation of bits allocation 
mechanism when the ROI macroblocks change 
frame by frame. 
 4
and morphological merging, are employed to 
determine the ROI. 
2.1 Diagonal and Anti-Diagonal Visual Rhythms 
As mentioned above, four samplings lines such as 
diagonal, anti-diagonal, vertical and horizontal lines 
can obtain the efficient attention model to 
characterize the event of a video and avoid false 
alarm. Grounding the basic assumption of the 
concept of human visual system (HVS), Lee et al. 
mentioned that humans always pay more attention 
on the center of a frame [19]. Therefore, in our 
framework, the diagonal and anti-diagonal sampling 
lines are first utilized to analyze the attention model 
of the current frame, and then the vertical and 
horizontal sampling lines are integrated to derive 
the final user attention model to obtain ROI. 
2.1.1 Visual Rhythm Creation and the Difference 
Information 
Through Eq. (1) and Eq. (4), the pixel values on the 
diagonal and anti-diagonal sampling lines will be 
collected, respectively. In order to show the 
behavior of each processing step, the 2D visual 
rhythm images are demonstrated. Fig. 3 (a) is a 
frame of the Salesman sequence, and Fig. 3 (b) and 
(c) show the 2D visual rhythm images obtained by 
diagonal and anti-diagonal sampling lines, 
respectively. It is obvious that different choices of 
the sampling lines result in different visual rhythms. 
Subjectively, the visual rhythm images illustrate 
that video data is captured in the steady background 
and may belong to the horizontal or vertical 
attention model. However, from these two visual 
rhythm images, we can easily observe that the user 
attention region may locate on the center of the 
consecutive frames. 
 
(a) Salesman sequence 
 
(b) Diagonal (c) Anti-diagonal 
Fig. 3 Visual rhythms of diagonal and anti-diagonal 
sampling lines obtained from Salesman sequence. 
Here, ξ defined in Eq. (5) represents the visual 
rhythm information in the four 2D images, 
including ࣞ, ࣛ, ࣰ and ࣢. Except ࣞ and ࣛ as 
mentioned above, ࣰ and ࣢ represent the visual 
rhythms obtained from vertical and horizontal 
sampling lines, respectively. In Eq. (5), the notation, 
ξ௜ୢሺݖሻ, denotes the images that consist of absolute 
difference values acquired from ξ௜ሺݖሻ and ξ௜ିଵሺݖሻ, 
where ݖ א ሾ0, ݊ െ 1ሿ  in ࣞ , ࣛ  and ࣰ  and 
ݖ א ሾ0, ݉ െ 1ሿ in ࣢. Fig. 4 is the diagonal and 
anti-diagonal difference images in grayscale values. 
Obviously, the variation of the visual rhythms 
embeds significant information about object 
moving shown in Fig. 3. 
ξ௜ୢሺݖሻ ൌ |ξ௜ሺݖሻ െ ξ௜ିଵሺݖሻ|, where ξ ൌ ࣞ, ࣛ, ࣰ, ࣢ (5)
 
(a) Diagonal (b) Anti-diagonal 
Fig. 4 Visual rhythm difference images acquired from 
Fig. 3. 
2.1.2 Visual Rhythm History 
Since the white region in Fig. 4 is broken and 
fragile, the attention model is tough to be analyzed. 
Therefore, the aim of this step is to collect the 
temporal information of each pixel location during 
a period of time according to the history concept. 
The notation, ξ௜୦ሺݖሻ, represents the visual rhythm 
historical 2D image. Initially, in the first frame, the 
values in ξ଴୦ሺݖሻ  are all set to 128 as default. 
Afterward, each value in ξ௜୦ሺݖሻ will be updated 
frame by frame with Eq. (6) according to the 
variation of the visual rhythm. 
ξ௜୦ሺݖሻ ൌ ቊ
ξ௜ିଵ୦ ሺݖሻ ൅ ܿଵ,    
ξ௜ିଵ୦ ሺݖሻ െ ܿଶ,
if ξ௜ୢሺݖሻ ൐ ݐ
otherwise
 (6)
where t is a predefined threshold and determined 
experimentally. This threshold is used to divide the 
absolute difference values into two categories. The 
constants c1 and c2 represent the cost of insertion 
and deletion in the historical calculation, 
respectively. The definitions of the constants are 
determined depending on various kinds of 
applications. In the experiments, we empirically set 
t = 3, c1 = 8 and c2 = 2 for real video sequences. Fig. 
5 shows the historical images, and it is much clearer 
than Fig. 4 in distinguishing the trend of the white 
region. 
 6
Although the results got from morphological 
merging can acquire the contour of moving object, 
the scope of the object suffers the influence of its 
moving up and down. To solve this problem, a 
refinement is used to obtain the final scope of the 
object, ξ௜UA୰ሺݖሻ . If ξ௜ିଵUA୰ሺݖሻ  and ξ௜UAሺݖሻ  overlap, 
ξ௜UA୰ሺݖሻ  will be bounded between Rs  and Re , 
whose definitions are shown in Eq. (11). Otherwise, 
ξ௜UA୰ሺݖሻ is exactly equal to ξ௜UAሺݖሻ. In Eq. (11), 
ξ௜ିଵUA୬  is the number of 1s of ξ௜ିଵUA୰ሺݖሻ. After the 
refinement, Fig. 10 shows the final results of the 
scopes of the moving object with the diagonal and 
anti-diagonal sampling lines, and the scope is used 
to set the center point for the vertical and horizontal 
sampling lines. 
ቊ
Rs ൌ ξ௜ିଵUAୱ െ ሺξ௜ିଵUA୬ ب 2ሻ  
Re ൌ ξ௜UAୣ ൅ ሺξ௜ିଵUA୬ ب 2ሻ  
,  (11)
where Rs, Re א ሾ0, ݊ െ 1ሿ. 
 
(a) Diagonal (b) Anti-diagonal 
Fig. 10 Result images of the scopes of user attention in 
the diagonal and anti-diagonal visual rhythms. 
2.2 Vertical and Horizontal Visual Rhythms 
By referencing the diagonal and anti-diagonal 
visual rhythms, the vertical and horizontal visual 
rhythms are acquired and used to draw the scopes in 
these two aspects. Finally, the ROI can be 
accurately determined according to the scopes of 
the four visual rhythms. 
2.2.1 Center of Visual Rhythm 
By the results of ξ௜UA୰ሺݖሻ in Fig. 11, the scopes of 
ࣞ௜UA୰ሺݖሻ and ࣛ௜UA୰ሺݖሻ are decided and drawn in 
Fig. 11(a). The center position UA௜ሺx௨௔, y௨௔ሻ, as 
shown in Eq. (12), is used to define the position of 
the sampling lines for the acquirement of vertical 
and horizontal visual rhythms. As can be seen in 
Fig. 11(b), ࣞ௜UAୱ and ࣞ௜UAୣ denote the start and 
end positions of ࣞ௜UA୰ሺݖሻ, respectively. Similarly, 
ࣛ௜UAୱ  and ࣛ௜UAୣ  denote the start and end 
positions of ࣛ௜UA୰ሺݖሻ , respectively. Then, the 
vertical and horizontal visual rhythms, ௜ࣰ and ࣢௜, 
are defined in Eqs. (13) and (14), respectively. 
ە
ۖ
۔
ۖ
ۓx௨௔ ൌ ቈ
min൫ࣞ௜UAୱ, ݊ െ ࣛ௜UAୣ൯ ൅ max൫ ࣞ௜UAୣ, ݊ െ ࣛ௜UAୱ൯
2
቉
y௨௔ ൌ ቈ
min൫ࣞ௜UAୱ, ࣛ௜UAୱ൯ ൅ max൫ࣞ௜UAୣ, ࣛ௜UAୣ൯
2
቉            
 (12)
௜ࣰ ൌ
ۏ
ێ
ێ
ێ
ۍ ௜࣪
ሺ0, y௨௔ሻ
௜࣪ሺ1, y௨௔ሻ
ڭ
௜࣪ሺ݊ െ 2, y௨௔ሻ
௜࣪ሺ݊ െ 1, y௨௔ሻے
ۑ
ۑ
ۑ
ې
 (13)
࣢௜ ൌ
ۏ
ێ
ێ
ێ
ۍ ௜࣪
ሺx௨௔, 0ሻ
௜࣪ሺx௨௔, 1ሻ
ڭ
௜࣪ሺx௨௔, ݉ െ 2ሻ
௜࣪ሺx௨௔, ݉ െ 1ሻے
ۑ
ۑ
ۑ
ې
்
 (14)
 
(a) Diagonal (b) Anti-diagonal 
Fig. 11 Result images of the scopes of user attention in 
the diagonal and anti-diagonal visual rhythms. 
2.2.2 Scope Determination by Vertical and 
Horizontal Visual Rhythms 
Since the center position UA௜ሺx௨௔, y௨௔ሻ  is not 
always at the same position in the consecutive 
frames, it is necessary to store the previous frames 
in a storage buffer for repeating the steps of Sec. 2.1 
to find the scopes of the user attention in the 
vertical and horizontal sampling lines. Fig. 12 
shows the results performed by the vertical and 
horizontal visual rhythms. The discontinuity of the 
two visual rhythms causes by the different center 
positions of the diagonal and anti-diagonal visual 
rhythms. Up to present, the scopes of the user 
attention region with the four sampling lines are 
well defined and illustrated in Fig. 13(a). Finally, 
the ROI is determined by the rectangular involved 
all the scopes of all attention models through four 
visual rhythms as shown in Fig. 13(b). 
(a) Vertical (b) Horizontal 
Fig. 12 Final results of the scopes of user attention 
model in the vertical and horizontal visual rhythms. 
(a) The scope of user 
attention models 
(b) The final result of ROI
Fig. 13 The final results. 
 8
The following steps detail the procedures to 
achieve the scoreboard and separate the MBs into 
different slices. The importance of each MB is 
indicated by a scoreboard that includes ROI, 
extended-ROI and non-ROI regions when obtained 
by the ROI determination scheme. In H.264/AVC 
reference software JM 13.2 [22], the FMO 
functionality supports eight slice ordering numbers, 
from 0 to 7, with 0 as its first priority. Thus, the 
ROI determination, which is followed by the FMO 
technique in H.264/AVC, classifies the MBs into 
three slices from 0 to 2. 
3.1 Skin color extraction and visual rhythm ROI 
determination 
The ROI determination based on visual rhythm [20] 
can acquire the ROI area where the objects with 
high motion activity. On the other hand, since 
human faces are usually the loci of attention in 
conversations, human faces should be regarded as 
the ROI regions in the implementation. Here, both 
skin color extraction and visual rhythm ROI 
determination schemes can detect ROI areas, with 
the former through the spatial and the latter, 
temporal information. Fig. 18 shows the results of 
each step in the proposed FMO-aware ROI 
determination. 
In this project, the skin color detection [21] is 
used to decide whether a macroblock belongs to a 
skin region. In Fig. 18(b) and (d), the skin color 
pixels are extracted and then categorized into a 
macroblock-based image, respectively. Except skin 
color information in the spatial domain, the visual 
rhythm ROI determination is employed to 
determine a ROI region in the temporal domain. As 
can be seen in Fig. 18(c), the results of the four 
sub-sampling lines are first obtained through visual 
rhythm analysis. And then, Fig. 18(e) sketches the 
contour of the user attention region from the result 
of Fig. 18(c). Fig. 18(d) and (e) illustrate the 
individual ROI results in terms of white and black 
macroblocks, and white macroblocks represent the 
ROI region. Furthermore, two ROI determinations 
in spatial and temporal aspects are both fast and 
efficient, and they can also obtain satisfactory 
results with negligible computational overhead. 
3.2 Extended ROI macroblocks 
In implementations, the variation of generated bits 
will be raised when a macroblock changes its 
situation from a non-ROI region in the previous 
frame to a ROI region in the current frame. 
Moreover, the visual quality suffers obvious artifact 
in the boundary between ROI macroblocks and 
non-ROI ones. However, it is observed in articles 
[21] that an extended region around ROI regions is 
beneficial to reduce the artifact while ensuring 
regions with targets are not missed. Therefore, the 
extended ROI macroblocks have ROI regions 
obtained above as its center in this work. Fig. 18(f) 
and (g) illustrate the extended ROI regions marked 
by gray color, obtained from Fig. 18(d) and (e), 
respectively. It is obvious that some macroblocks 
are defined as ROI ones in both methods and some 
are in neither ROI regions nor extended ROI 
regions. Therefore, an ROI scoreboard is built to 
categorize the macroblocks. 
3.3 ROI scoreboard for FMO 
In Table 1, points are given to classify the category 
of each macroblock. If a macroblock belongs to an 
extended region either in spatial or temporal 
domains, it gets 1 point. Otherwise, a macroblock 
obtain 0 point when it belongs to the ROI region. 
Then, the scores in the spatial and temporal 
domains are summed to represent the importance of 
a macroblock. A macroblock gets 0 point if it is not 
only in the skin color region but also belongs to a 
moving object. Oppositely, a macroblock stands for 
background when it obtains 4 points. As shown in 
Fig. 18(i), each macroblock has its own score, and 
then it is arranged into five distinct ordered slices. 
Fig. 18(b) shows the original frame with the result 
of ROI scoreboard in Fig. 18(i) to demonstrate the 
location of the corresponding slices in a frame. 
Table 1 The corresponding score lookup table (points) 
 Skin color MB (0) 
Extended skin 
color MB (1) 
Background 
MB (2) 
Moving object 
MB (0) 0 1 2 
Extended 
moving object 
MB (1) 
1 2 3 
Background 
MB (2) 2 3 4 
3.4 Bit allocation for ROI video coding 
In this section, the proposed FMO-aware ROI video 
coding is implemented on H.264 JM 13.2 [22].The 
ROI determination based on visual rhythm and the 
skin color extraction [21] are combined to build a 
ROI scoreboard for FMO, a tool that performs ROI 
video coding. The Carphone, Claire, Foreman and 
Salesman sequences are used to do extensive 
experiments, evaluating the ROI video coding 
scheme. Each test video sequence contains 100 
frames with the structure of one I-frame and the 
following consecutive P-frames, and the initial QP 
for I frame is set to 35. To achieve ROI video 
coding, a strategy based on a mathematic model is 
proposed. First, Eq. (15) shows that a factor is 
 10
 
(a) ROI scoreboard (b) The result of (a)
 
(c) PSNR of slice 0 is 
26.55 dB in RC 
(d) PSNR of slice 0 is 
33.17 dB in FMO
Fig. 19 Results of ROI video coding for frame #72 in 
Foreman sequence on H.264 at 32Kbps. 
 
(a) ROI scoreboard (b) The result of (a)
 
(c) PSNR of slice 0 is 
31.20 dB in RC 
(d) PSNR of slice 0 is 
33.72 dB in FMO
Fig. 20 Results of ROI video coding for frame #70 in 
Carphone sequence on H.264 at 32Kbps. 
 
(a) ROI scoreboard (b) The result of (a)
 
(c) PSNR of slice 0 is 
31.20 dB in RC 
(d) PSNR of slice 0 is 
33.72 dB in FMO
Fig. 21 Results of ROI video coding for frame #93 in 
Claire sequence on H.264 at 32Kbps. 
結果與討論 
This project presents a robust ROI determination 
method based on user attention models through 
visual rhythm analysis and an efficient ROI video 
coding scheme. The main contribution of this work 
is the investigation of the visual rhythm concept for 
analyzing video content to facilitate the ROI 
determination. Through visual rhythm, the proposed 
algorithm can determine the highest potential ROI 
area in a fast, simple and robust way. Experimental 
results show that the proposed framework can 
obtain the ROI effectively and efficiently. This 
work is very useful for a pre-processing step of 
video coding and video content analysis for 
multimedia applications. Furthermore, an 
FMO-aware ROI video coding for H.264/AVC is 
proposed to enhance the quality of ROI regions. An 
exponential model is used to estimate an 
appropriate QP for each FMO slice. By the concept 
proposed in this project, potential developments of 
integrated applications are found when the proposed 
scheme is combined with chrominance information 
analysis. 
The ROI determination algorithm and its 
simulation results resulted from the FMO-aware 
ROI video coding have been accepted in TCSVT 
[24]. Based on the concept of the proposed ROI 
video coding, potential developments of integrated 
applications are found when it is implemented on 
mobile devices. 
 
參考文獻 
[1] ITU-T Recommendation H.264 & ISO/IEC 
14496-10 (MPEG-4) AVC. 
[2] L. Itti, C. Koch and E. Niebur, “A model of 
saliency-based visual attention for rapid scene 
analysis,” IEEE Transactions on Pattern 
Analysis and Machine Intelligence, vol. 20, no. 
11, pp. 1254-1259, November 1998. 
[3] G. Agarwal, A. Anbu and A. Sinha, “A fast 
algorithm to find the region-of-interest in the 
compressed MPEG domain,” in Proceedings of 
IEEE Conference on Multimedia & Expo, vol. 2, 
pp. 133-136, July 2003. 
[4] C.-C. Ho, W.-H. Cheng, T.-J. Pan and J.-L. Wu, 
“A user-attention based focus detection 
framework and its applications,” in 
Proceedings of IEEE International Conference 
on Pacific-Rim Conference on Multimedia, vol. 
3, pp. 1315-1319, December 2003. 
[5] W.-H. Cheng, W.-T. Chu, J.-H. Kuo and J.-L. 
Wu, “Automatic video region-of-interest 
determination based on user attention model,” 
 12
可供推廣之研發成果資料表 
5可申請專利  5 可技術移轉                                      日期：97年 7月 31日 
國科會補助計畫 
計畫名稱：應用於行動裝置之 H.264視訊編解碼研究(3/3) 
計畫主持人：陳美娟         
計畫編號：NSC 96-2221-E-259-011 學門領域：電信學門 
技術/創作名稱 感興趣區域決定法則、感興趣區域視訊編碼 
發明人/創作人 陳美娟、紀明傑 
技術說明 
中文： 
在本計劃當中首先提出感興趣區域決定法則，根據視覺韻律的觀念提出
六個使用者關注模型，基於這六個關注模型定義四條視覺韻律之取樣
線，由這四條取樣線所發展的感興趣區域決定法則可有效地擷取人眼感
興趣區域；而在感興趣區域視訊編碼演算法方面，根據 H.264 所提供錯
誤回復之彈性巨方塊排列機制，綜合考慮膚色偵測與感興趣決定法則之
結果，分配各巨方塊至不同片段，使各片段能以優先權順序進行編碼，
藉由位元分配而提高感興趣區域之視訊品質。 
 
英文： 
In this project, an ROI determination is first proposed based on the concept of 
visual rhythm. According to visual rhythm, six user attention models are 
presented. And then, four sampling lines in a frame are introduced to select 
the area where users pay more attention to. And then, a H.264 tool, flexible 
macroblock ordering (FMO) is leveraged to enhance ROI regions through the 
slice priority. Based on the ROI determination through visual rhythm and a 
skin color extraction, an FMO-aware scoreboard is built to separate the 
macroblocks into different slices. And then, each slice can be encoded by its 
priority through the proposed bit allocation. Therefore, FMO-aware ROI 
determination with a bit allocation method is proposed for H.264 video 
coding to enhance the quality of ROI regions.  
 
可利用之產業 
及 
可開發之產品 
1. 行動通訊產品 
2. 視訊會議系統 
3. 門禁保全系統 
技術特點 
本技術之特點為提出一快速擷取演算法，其使用視覺韻律當作關注模
型，利用視訊畫面中的四條取樣線，取得感興趣區域；而在感興趣區域
視訊編碼方面，由兩種感興趣區域偵測演算法所得到之結果，進而利用
彈性巨方塊排列機制進行畫面內片段的分配，使其可達成感興趣區域視
訊編碼效果，有效提升感興趣區域之視訊品質。 
推廣及運用的價值 本技術可以應用於行動通訊產品、高品質的視訊會議系統和門禁相關等相關通訊系統當中。 
(1) 1.每項研發成果請填寫一式二份，一份隨成果報告送繳本會，一份送 貴單位研發成果
推廣單位（如技術移轉中心）。 
(2) 2.本項研發成果若尚未申請專利，請勿揭露可申請專利之主要內容。 
(3) 3.本表若不敷使用，請自行影印使用。 
 
Network )之分支會議。該會議當中除了我們所參加的多媒體分析與處理國際研討會之外，尚
有 International Workshop on Performance Modeling and Evaluation in Computer and 
Telecommunication Networks、 International Workshop on Distributed Sensor  Networks 、
International Workshop on Wireless Mesh and Ad Hoc Networks (WiMAN) 、The First 
International Workshop on Distributed Sensor Systems 以及 Workshop on Advanced Networking 
and Communications 等會議同時舉行。本會議中總共接收了 32 個國家，超過 550 篇論文，平
均接受率大約是 29%，意即大約接受 160 篇論文。 
會議舉辦於烏龜灣渡假中心( Turtle Bay Resort )，其為於歐胡島北邊的海濱，離市中心較遠。
歐胡島為夏威夷群島裡面最大的島，將近八成的人口居住在此，主要生活區域在南部的威基
基( Wakiki )地區，其主要地形為火山地形，群島中的所有島嶼均為火山島，由於四面環海及
穩定優良的氣候，觀光收入為其主要來源。筆者搭機到達之日，南邊的大島正受颶風侵襲， 所
幸歐胡島未受影響。 
 
會議當天早上 8:30，主辦單位舉辦一場專題演講，講者為 Cheng-Zhong Xu 博士，講題為
「Quality Assurance and adaption: A Key to Stress-Resilient Internet Service」，其主要內容探討在
網頁服務下的自治性品質控制架構。緊接著有三場 Session 進行，分別為「視訊編碼與分析
( Video Coding and Analysis )」、「多媒體品質評估( Multimedia Quality Evaluation )」及「智慧
型視訊監控媒體處理( Media Processing for Intelligent Video Surveillance )」。 
 
筆者在此次會議當中發表「基於使用者專注模型之強健型感興趣區域決策法則--使用視覺韻
律分析」論文，其屬於視訊編碼與分析( Video Coding and Analysis )之領域，於 8 月 16 日上午
發表口頭報告。由於數位相機的普及，使得數位照片或視訊之分享蔚為風尚，因此所伴隨的
相關應用也愈形重要；其中，動態物件偵測或是感興趣區域選擇是熱門的研究主題。因此，
我們對於感興趣區域的選擇提出演算法，以實現將動態物件選擇為感興趣區域，其中藉由視
覺韻律(visual rhythm)分析可有效率獲得動態之感興趣區域，其極低之計算量符合即時性的視
訊應用，其成果更可用在序列視訊內容分析與視訊監控等系統。論文發表後，有與會的教授
提出建議，主持人任職於美國 Qualcomm 公司的 Gokce Dane 博士對於我們所提出的演算法與
出席國際學術會議心得報告 
                                                             
計畫編號 NSC 96-2221-E-259-011 
計畫名稱 應用於行動裝置之 H.264 視訊編解碼研究(3/3) 
出國人員姓名 
服務機關及職稱 
徐敬亭 
國立東華大學電機工程系  博士班研究生 
會議時間地點 97 年 5 月 19 日至 5 月 21 日  美國 西雅圖 
會議名稱 
(中文) 2008 國際電子電機學會電路與系統國際研討會 
(英文) 2008 IEEE International Symposium on Circuits and Systems 
發表論文題目  
 
一、參加會議經過 
 
筆者於民國 97 年 5 月 18 日出發，前往美國‧華聖頓州‧西雅圖 (Seattle, Washington, USA )
參加由電機電子工程師學會( Institute of Electrical and Electronics Engineers )主辦，「信號與系
統組織 ( Circuits and System Society ) 」支援之 2008 年國際電子電機學會電路與系統國際研
討會 ( 2008 First International Workshop on Multimedia Analysis and Processing )。 
此會議集合了世界頂尖的研究學者與業界共同分享其在電路與系統領域當中的研究，設計經
驗與實作成果，依其研究屬性，可分為 17 個不同的主題： 
1. 類比信號處理 
2. 生物醫藥的電路與系統 
3. 儀錶信號處理 
4. 細胞格網路與矩陣運算 
5. 通訊電路與系統 
6. 電腦輔助網路設計 
7. 數位信號處理 
8. 圖形理論與運算 
9. 生命科學系統與應用 
