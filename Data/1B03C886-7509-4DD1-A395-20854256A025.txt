可供推廣之研發成果資料表 
□ 可申請專利  █ 可技術移轉                                  日期：2009 年 10 月 20 日 
國科會補助計畫 
計畫名稱：汽車電子與汽車應用技術研究--子計畫二：先進安全駕駛輔
助系統研究 
計畫主持人： 謝君偉        
計畫編號：97-2221-E-155-036  學門領域：控制 
技術/創作名稱 即時車道偏移偵測技術 
發明人/創作人 謝君偉 
中文：此技術使用「正負」邊緣方法來做車道線偵測，然後再利用相機
幾何特性去估算出影像中車道線的大概寬度，利用此寬度資訊，我們可
以過濾些不可能的區塊，然後再利用高斯混合模型去建立車道線的顏色
資訊模型，根據顏色資訊和線段方程式，可即時找出車道線的位置，並
判斷車輛是否有偏移之現象，一旦車輛有所偏移，就會送警告訊息給駕
駛者。 
技術說明 
英文： A novel edge labeling technique is proposed for detecting lane
departure from videos in real time.  Firstly, pairs of edge pixels with 
different edge types are grouped using the labeling technique.   Then, 
different lane hypotheses can be generated for lane modeling.  Then, a lane 
geometrical constraint is derived from the pinhole camera geometry for 
filtering out impossible lane hypotheses. After filtering, a kernel-based 
modeling technique is then proposed for modeling different lane properties. 
With the modeling, different lanes can be effectively detected and tracked 
even though they are fragmented into pieces of segments or occluded by 
shadows.  With the lane information, different dangerous driving behaviors 
like lane departure can be directly analyzed from road scenes. 
可利用之產業 
及 
可開發之產品 
可應用產業為汽車電子、智慧型運輸系統、先進安全車輛，可開發產
品為車道偏移警示系統 
技術特點 
此技術特點使用「正負」邊緣方法來做車道線偵測，一旦車輛有所偏移，
就會送警告訊息給駕駛者，可即時找出車道線的位置，偵測速度達 58fps。
推廣及運用的價值 
可應用汽車電子、智慧型運輸系統等產業，適時地提醒駕駛者於第
一時間將車輛拉回既定路線，避免因注意力不集中所發生的危險。
※ 1.每項研發成果請填寫一式二份，一份隨成果報告送繳本會，一份送 貴單位
研發成果推廣單位（如技術移轉中心）。 
※ 2.本項研發成果若尚未申請專利，請勿揭露可申請專利之主要內容。 
※ 3.本表若不敷使用，請自行影印使用。 
附件二 
Kreucher and Lakshmanan proposed a LANA 
to extract different edge features for lane 
detection from frequency domain.  In 
addition to edge, texture is also another 
important feature for lane detection in 
unstructured images.  In [7], Rasmussen used 
a set of multi-scale Gabor wavelets filters to 
detect road directions from an ill-structure 
image.  In [9], Jeong and Nedevschi 
combined edge and texture features to form a 
classifier for segmenting lane regions from the 
background.  Usually, multiple features will 
perform better than single one.  Thus, in [1], 
McCall and Trivedi incorporated lane 
markings, lane texture, and vehicle state 
information to generate robust estimates of 
lane curvature.   
    In addition to the feature-based scheme, 
the model-based scheme performs more 
robustly in lane detection when different lane 
patterns, occlusions or shadows are handled.  
For example, Kluge et al.[10], proposed a 
deformable template to model and detect 
different lane types (including straight line or 
curve).  Furthermore, in [5], Wang et al. used 
B-snake to model curve and straight lanes 
from their edge features so that poorly-painted 
lanes were extracted from videos.  In [11], 
Tsai proposed a fuzzy inference system to 
model lane properties for overcoming the 
existence of shadow.   To more robustly 
detect lanes, many advantages can be 
benefited from 3D data or stereo vision.  In 
[12], Bertozzi and Broggi proposed a GOLD 
system which uses an inverse perspective 
mapping to removing perspective effects and 
then detect lane markings and obstacles using 
stereo vision.  In addition, in [13], Nedevschi 
et al. proposed a 3D lane detection method for 
lane detection, pitch angle analysis, and roll 
angle estimation from videos. Although 3D 
information can significantly reduce the 
perspective effects for lane and obstacle 
detections, the inherent correspondence 
problem makes it unfeasible for real-time 
applications. 
This paper presents a novel edge labeling 
scheme to detect lanes from videos in real 
time.  Even though the analyzed videos 
contain various occlusions, shadows, or lane 
patterns, the proposed method still performs 
very well to detect each desired lane.  Fig. 1 
shows the flowchart of our system. First of all, 
different edge points are extracted using 
Gaussian differential operators.  Then, an 
edge labeling technique is proposed for 
finding all pairs of edge points as lane 
candidates.  After that, a lane geometrical 
constraint is derived for filtering out 
impossible lane candidates.  Due to the 
filtering, only few lane hypotheses should be 
generated and verified.  With the set of lane 
hypotheses, a kernel-based modeling scheme 
is then proposed for finding all missed lane 
segments.  Based on this lane model, 
different lanes can be detected and tracked 
even though the analyzed road scene includes 
different shadows, occlusions, and light 
changes.  Experimental results have proved 
the superiority of the proposed method in lane 
detection. 
 
Fig. 1   Flow-Chart of the proposed system 
四、研究方法 
To detect lanes from the front view of a 
moving vehicle, the most challenging task to 
be overcome is lighting change.  In the past, 
most approaches use color features to detect 
lane lines from videos.  However, color will 
change under different lighting conditions.  
Compared with color, edge is a most stable 
feature for lane detection.  Thereby, an edge 
labeling technique is proposed for detecting 
lanes more robustly. 
4.1 Edge Labeling  
Let ( , )I x y  denote the input image.  This 
paper uses the Gaussian derivative filter 
( , , )xG x y σ  for extracting vertical edge points 
from the convolution of ( , )I x y  with 
( , , )xG x y σ  by the form ( , , )xI x y σ =  
( , , )xG x y σ * ( , ),I x y where ∗  is the 
convolution operation.  Then, given a point 
p(x,y) in I , it is classified as “positive” or 
“negative” according to the following rule:  
 
+,    ( ) ;
( ) ,    ( ) ;
0,            otherwise.
x edge
x edge
if I p T
map p if I p T
>⎧⎪= − < −⎨⎪⎩
 (1) 
After edge labeling, we can horizontally scan 
each pixel in I line by line to find any pair of 
pixels p+  and p−  which satisfy the 
following rules:    
(a). p+  is at the left side of p− ; 
(b). p+  is “positive” and p−  is “negative; 
(c).  Only “0” pixels appear between p+  
and p− .     
 
 ( ) 2, ,
1
, ( )
N
i i i k i i i k
k
E b m y b m x
=
= − −∑ .                 (5) 
After line fitting, a re-projection technique 
will be used for finding all isolated points 
which locate in il . Given a point p, the 
distance between p and il  can be defined as 
follows:  
 
2
| |
( , )
1
p i p i
i
i
y m x b
d p l
m
− −= + . (6) 
For each point in il , if it does not satisfy the 
following condition: 
 ( , ) 5id p l < , (7) 
it will be filter out. Fig. 5 shows the result of 
line fitting and re-projection. 
  
   (a)                  (b) 
Fig. 5  Result after line fitting. 
4.4 Lane Detection Using Edges and Colors 
In addition to edge, color is another feature 
for lane detection.  Therefore, this section 
uses a kernel-based method for modeling 
different lanes. 
4.4.1 Lane Modeling 
When a vehicle moves along a lane, the 
pixels on this lane will have similar colors.  
For the ith lane il , we use ( , , )R G Bμ μ μ  and 
( , , )R G Bρ ρ ρ  to denote the color means and 
variances of all pixels in il  in the (R, G, B) 
channels, respectively. In addition, dρ  is 
used to denote the variance of distances 
( , )id p l  (see Eq.(7)) for all pixels p in il .  
Then, the Gaussian model to model the lane 
il  is defined by: 
2 2 2 2
2 2 2 2
( ) ( ) ( ) ( , )( ) exp( )exp( ).
i
p R p G p B i
l
R G B d
R G B d p lG p
μ μ μ
ρ ρ ρ ρ
− − −= − − − −  
Then, we can judge whether a point p locates 
on this lane if 
 ( ) 0.75
il
G p < . (8) 
4.4.2 Lane Tracking 
In practice, a lane will not always be clear 
and keep continuous on each video frame.  
To tackle the above problem, a lane tracking 
technique should be proposed for robustly 
detecting lane positions.  The tracking 
technique takes advantages of Eq.(8) to find 
out all the missed lane points.  When a lane 
disappears on the current frame tI , we will 
search each pixel p in tI  whether it satisfies 
Eq.(8).  If the answer is yes, p will be 
collected to be a lane candidate appearing in 
il .  After the scanning, even though il  is 
missed in the current frame, it still will be well 
recovered.  
4.4.3 Lane Change Detection 
When the driver drives his car across the 
lane line, the lane poison will change along 
the horizontal direction.  The case “lane 
change” can be considered as an unusual 
event.  This unusual event can be easily 
detected if the lane moves across the center of 
bottom line of the observed frame. 
五、結果與討論 
  
Fig. 6: Detection result of lanes with 
different types. 
  
Fig. 7: Detection result of lanes with 
different colors. 
  
Fig. 8: Results of lane detection at night 
time.  
  
Fig. 9  Results of lane detection when 
cars moved on the road.   
  
Fig. 10  Lane departure detection.  
To examine the performance of our 
proposed to detect lane lines, different videos 
captured under different lighting conditions, 
表 Y04 
行政院國家科學委員會補助國內專家學者出席國際學術會議報告 
                                                          97 年  9 月 10  日 
報告人姓名  謝君偉 
 
服務機構 
及職稱 
 
 元智大學 電機系 
 副教授 
     時間 
會議 
     地點 
 2008 年 8 月 15 日至 8月 17 日
 哈爾濱  
本會核定 
補助文號 
 NSC97-2221-E-155-036 
會議 
名稱 
 (中文) 2008 年第四屆智慧型資訊隱藏與多媒體訊號處理國際會議 
 (英文) The Fourth International Conference on Intelligent Information Hiding 
and Multimedia Signal Processing 
發表 
論文 
題目 
 (中文) 使用星狀特徵與三角化技術作人類動作分析 
 (英文) Human Action Recognition Using Star Templates and Delaunay 
Triangulation 
報告內容應包括下列各項： 
一、參加會議經過 
 
本次研討會在中國的黑龍江省哈爾濱市舉行，由於此研討會主要是從事資料隱藏與多媒
體訊號處理學者務必參加的盛會，因此匯集了全世界的知名研究學者，剛好本人有作一
些多媒體訊號處理的相關研究，故投稿至此。為了討論目前資料隱藏與多媒體訊號處理
最熱門的問題與應用，此大會主要討論題目共有 31 個，分別為 
1. Digital Crime and Forensics 
2. Ubiquitous Multimedia Services and Applications for Residential Users 
3. Information Retrieval  
4. Wired and Wireless Multimedia Networking and Applications 
5. Techniques and Algorithms for Multimedia Security 
6. Event Analysis in Videos 
7. Fingerprinting 
8. Data Hiding and Steganography  
9. Cryptography 
10. Pattern Recognition 
11. Image and Speech Processing 
12. Video Signal Processing  
13. Watermarking Applications  
14. Networking Applications 
表 Y04 
二、與會心得 
 
圖一、參加 IIHMSP 2008 台灣來的教授與學生們 
 
   本人參加此次的資料隱藏與多媒體訊號處理國際會議，會中本人發表一篇利用骨幹
的方法，來快速辨識人的肢體動作，進而分析人的正常與異常行為，發表後獲得許多人
的興趣與討論，許多人並詢問相關執行速度、辨識率如何？是否有實驗的視訊資料，可
以做實驗。除了宣讀論文之外，我並與參加此次會議的各種 oral 與 poster 的議程，並與
各國學者或研究員彼此互相討論，除可得知這方面最新技術的研發與進展，並可了解目
前各國在多媒體與訊號處理技術上的研發情況與進展，因這會議是在大陸黑龍江省舉辦
的，大部分的學者來自亞洲與美洲國家，特別是印度的學者也來了不少，亞洲的學者也
不少，例如台灣、韓國、日本等等，只要是多媒體（包含視訊監控）與網路盛行的國家，
參加的人就不少。在研討會中與這些學者討論與交換意見，深深的覺得在資料隱藏與多
媒體訊號處理（視訊監控）這個領域，研究重點越來越偏向安全性、穩定度與正確性的
要求，因為網路很多資料是重要的，因此，如何讓資料安全到達是很重要的，除此之外，
這次會議的另一個重點多媒體訊號處理，今年很多研究都在探討利用統計的方式來做視
訊應用的分析與辨識，不過台灣的學生似乎在統計上面的訓練不大夠，這是台灣學者需
要重視的。在此會議碰到許多大陸學生與香港的學生與學者，出來的人數與論文發表數
已超過台灣了，這是過去沒見到過的，質方面也有相當不錯的進步，相對而言台灣的論
文數就少了許多。 
 
三、建議 
 
    此會議主要探討在資料隱藏與多媒體訊號處理等方面課題，只要用心參與都能吸收
表 Y04 
行政院國家科學委員會補助國內專家學者出席國際學術會議報告 
                                                          97 年  10 月 20  日 
報告人姓名  謝君偉 
 
服務機構
及職稱 
 
 元智大學 電機系 
 副教授 
     時間 
會議 
     地點 
2008 年 10 月 12 日至 10 月 15 日  
美國 San Diego 
本會核定
補助文號
 NSC97-2221-E-155-036 
會議 
名稱 
 (中文) 2008 國際影像處理會議 
 (英文) 2008 International Conference on Image Processing 
發表 
論文 
題目 
 (中文) 使用圓心取樣特徵與拖拉技巧作快速影像比對 
 (英文) Efficient Image Matching Using Concentric Sampling Features and 
Boosting Process 
 
報告內容應包括下列各項： 
 
四、參加會議經過 
 
本次研討會在美國的 San Diego 舉行，安排了六個 special sections 包括:  
1. 3D Graphics Compression and Streaming: Theory, Standardization and Applications  
2. Connectivity and Connected Filters  
3. Recent Advances in Super-resolution Imaging  
4. Landmark Shape Sequence Analysis for Video and Volume Image Sequence Processing 
5. Privacy Protection of Visual Information  
6. Image Aesthetics, Mood and Emotion 
 
分別針對最近影像處理最熱門的問題與應用，作深入的討論。由於此研討會主要是從事
影像處理研究學者務必參加的盛會，因此匯集了全世界的知名研究學者，例如 Rama 
Chellapa、Tomas Huang 等人，藉此盛會交換意見與心得，除此之外大會並提供五個短期
課程 (tutorials)，包括： 
1.  Microscopic Image Processing and analysis techniques  
2.  Accelerated Image Processing with FPGAs and GPUs  
3.  The Color Imaging Pipeline A Compressed Tutorial on Rapid MRI: from Basic 
Principles to Parallel Imaging and Compressed Sensing for Digital Still and Video 
表 Y04 
 
   本人參加此次的國際影像處理研討會，會中本人發表一篇有關利用快速圖形比對的
技術，可從視訊影像中快速地找到想要偵測的物件，發表後獲得許多人的興趣與討論，
許多人並詢問有否 source code 來做測試，並作實驗比較。除了宣讀論文之外，我並與參
加此次會議的各種 oral 與 poster 的議程，並與各國學者或研究員彼此互相討論，除可得
知這方面最新技術的研發與進展，並可了解目前各國在影像處理技術上的研發情況與進
展，因這會議是在美國舉辦的，大部分的學者來自美國，歐洲國家的學者也來了不少、
例如英國、法國、德國、義大利、比利時等國家，亞洲的學者也不少，例如大陸、日本
等等，台灣參加的學者也很多，例如台大的貝蘇章教授，交大的杭學鳴教授、中央的張
寶基教授，中研院的黃文良博士與呂俊賢博士等等。在研討會中與這些學者討論與交換
意見，深深的覺得在影像處理這個領域，研究重點越來越偏向 video coding、視訊監控
與多媒體分析，包括 H.264 codec 的探討、浮水印(watermarking)、視訊壓縮、物件偵測
與追蹤、多媒體檢索等等，而且今年很多研究都在探討利用統計的方式來做影像分析，
例如 HMM 來做行為分析，不過台灣的學生似乎在統計上面的訓練不大夠，這是台灣學
者需要重視的。在此會議碰到許多大陸學生與香港的學生與學者，出來的人數與論文發
表數已超過台灣了，這是過去沒見到過的，質方面也有相當不錯的進步，因為今年是美
國主辦的，所以有一大部分的論文是美國出來的研究論文，相對而言台灣的論文數就少
了許多，台灣不再加以努力，影像處理的研究將會慢慢地被其他國家超越過去。另外值
得一提的事情是今年得獎的論文幾乎都是亞洲人拿到，可見亞洲人的聰明智慧與創意，
不見得會輸給歐美等國家。 
 
六、建議 
 
由參加這次會議，發覺許多優秀與有深度的論文都會用到許多的統計數學，但對
於統計或數學的駕馭力，多數的台灣研究生似乎都很欠缺，尤其是現補習教育的盛行，
許多研究生能考上好學校，是因從大二或大三就開始補習，對同樣的習題與科目一直磨
練，雖然研究所考試能獲得高分，但不代表真的有對應的能力來解決問題，只能說當時
的運氣及記憶力比較好，創造能力並無跟著增長，有點令人感嘆，希望國內教育能多加
強數學與統計知訓練。 
另一方面，目前台灣學生，由於有國防役與股票可以領，越來越少人願意留學，
這以後可能造成台灣人才的斷層，反之隔岸的大陸，留學幾乎是大陸學子的第一優先選
擇，因此，在可預見的將來，有很大的可能在影像處理這個領域，越來越多的大陸的學
