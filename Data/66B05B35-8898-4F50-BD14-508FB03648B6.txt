 
2 
Contents 
 
中文摘要………………………………………………………………………3 
 
英文摘要………………………………………………………………………3 
 
一、前言………………………………………………………………………3 
 
二、新型演化式模糊聚類演算法及其於影像分割之研究…………………4 
2.1 研究背景與動機……………………………………………………….4 
2.2 演化競爭式聚類演算法………………………………………………..5 
2.3 聚類有效性指標及演算法設計………………………………………..6 
2.4 基於雜湊映射之樣本集簡化技術……………………………………..7 
2.5 實驗結果與討論………………………………………………………..7 
2.6 結論與成果自評………………………………………………………..8 
 
三、移動物影像偵測與追蹤系統設計………………………………………9 
3.1 研究背景與動機………………………………………………………..9 
3.2 運動目標偵測…………………………………………………………..9 
3.3 多目標影像追蹤………………………………………………………11 
3.4 實驗結果與討論………………………………………………………12 
3.5 結論與成果自評………………………………………………………14 
 
四、智慧型即時影像監測系統於居家環境跌倒事件偵測之應用………..15 
4.1 研究背景與動機………………………………………………………15 
4.2 改良式碼書背景模型…………………………………………………15 
4.3 跌倒事件偵測…………………………………………………………18 
4.4 系統實現……………………………………………………………....19 
4.5 實驗結果與討論………………………………………………………19 
4.6 結論與成果自評………………………………………………………19 
 
參考文獻……………………………………………………………………..21 
 
 
4 
置，此特點使其適用於實際之影像分割問題上；階段
2 建構之運動目標影像偵測與追蹤模組除了能將畫面
中目標物前景與一般背景分離之外，其還可不受目標
物間相互阻擋之影響同時追蹤多個目標物之動態。階
段 3 與 4 則是在現有之研究基礎上，發展並實現一跌
倒偵測系統，用以監控接受居家照護服務之對象於家
庭環境內之日常活動，並藉此提昇其健康自主管理之
安全性。 
以下各節分別就 IVAS 系統之發展過程中，各研究
階段所涉及之研究背景、理論基礎、技術創新以及實
驗結果與討論等項目進行較深入之說明與分析。 
 
二、新型演化式模糊聚類演算法及其於影
像分割之研究 
本計畫首先提出一可應用於自動影像分割之創新
方法―演化競爭式聚類 (Evolutionary Competitive 
Clustering, ECC)演算法做為電腦視覺研究之基礎技
術。ECC 本質上為一有效性導向之聚類演算法，其利
用模糊 c 均值(Fuzzy C-Means, FCM)與模擬退火
(Simulated Annealing, SA)之間的互補特性來對一新
的聚類準則目標函數進行最小化。ECC 一方面利用
SA 來克服聚類尋解過程可能遭遇的區域極小問題，
另一方面利用 SA 與 FCM 之競爭來加速聚類工作之
進行。因此，ECC 不僅可有效解決 FCM 面對不同群
聚尺寸及不同初始群聚中心所可能衍生之聚類問
題，更可明顯改善演化式聚類普遍面臨之搜尋速度過
慢及計算量龐大之缺點。為驗證 ECC 演算法之有效
性，本計畫將其運用於二類難以成功聚類之資料集
上，包括：二維人造資料與四維衛星影像。由實驗結
果證實，ECC 不管在群聚數目或群聚分割上其表現皆
明顯優於目前最廣為採用之 FCM 演算法。 
 
2.1 研究背景與動機 
聚類(clustering)技術在影像處理領域上常被用來
執行影像分割 (image segmentation) 、邊緣偵測
(boundary detection)以及表面近似(surface approxima-
tion)等任務[9]，而這些工作在機器人視覺伺服控制
(visual servoing)中往往占有極重要的地位[10,11]。本
計畫今年提出一創新之聚類方法―演化競爭式聚類
(evolutionary competitive clustering, ECC)演算法，以
做為本計畫未來於機器人視覺伺服控制研究上相關
技術之基礎。 
聚類本質上為非監督式學習(unsupervised learn-
ing)之一種，其目的是針對一組未標記(unlabeled)之樣
本集合，根據樣本間呈現之相似與相異特性，自動將
類似樣本歸類為至同一群聚(cluster)，而相異樣本則
分配到不同群聚。一般而言，吾人常以分割矩陣U  
(partition matrix)來表達聚類結果。當某一聚類演算法
所產生之U 矩陣元素具{0,1}二值特性時，則吾人稱
此為明確(crisp)分割；反之，若U 之元素為介於 [0,1]  
間之任意實數，則稱為模糊(fuzzy)分割。由於模糊分
割較能如實反應樣本間之物理特性(如：過渡性與不
明確性)，故近年來已獲得極為廣泛之運用。 
模糊 c 均值(fuzzy c-means, FCM)為一典型之模糊
聚類演算法 [12]，因其較不易受初始群聚中心
(center/prototype)位置影響而使聚類過程陷於目標函
數之區域極值，故其相關之衍生方法目前已成功應用
於許多領域，如：影像分割[13-15]、訊號分析[16-18]、
系統建模[19-21]…等。然而，FCM 常受下列三項問
題影響而降低其實用性 [22,23]： (1)其聚類準則
(clustering criterion)所定義之目標函數常無法有效代
表良好之資料分割結果，亦即，最小化該函數並無法
保證吾人可得到令人滿意之聚類結果；(2)相較於明確
聚類(如：k-means)而言，FCM 雖然較不易受其目標
函數影響而落入區域極值，然而，該函數基本上仍然
屬於一多極值函數(multimodal function)，且當樣本空
間維度或群聚數目增加時，此現象將更加明顯。換言
之，FCM 仍無法擺脫目標函數多極值特性之影響，
其區域極小值常造成聚類過程提早中止而使聚類效
果不佳；(3)在使用 FCM 前須預先指定群聚數目才可
開始聚類，然而，對於未標記資料集而言，群聚數目
常無法事先得知。換言之，若吾人無法正確預知樣本
資料集之群聚數目，則 FCM 聚類結果必無法確實反
應資料集潛在之群聚特徵。 
為解決上述問題，目前已有許多相關因應對策被
提出，其中，針對問題(3)所造成的困難，許多研究各
自提出不同的群聚有效性指標(cluster validity index)
來估測 FCM 演算法之群聚數目[22,24-26]。當樣本集
之群聚特性良好時(如：群聚數目適中、樣本空間維
度低、各群聚大小及密度類似)，這些指標普遍可有
效估測出實際之群聚數。然而，由於大多數樣本集並
不符合上述特性，使得此類以最小化 FCM 目標函數
為基礎之有效性指標無法準確估算出正確的群聚數
目。對此，目前已有若干研究提出以直接最佳化有效
性指標來取代最小化 FCM 目標函數之聚類演算法
[23,27,28]，以克服上述三項問題。其中，Bensaid 等
人提出一有效性導向之聚類方法[23]，此法可在群聚
數目已知的情況下同時解決問題(1)與(2)；Maulik 與
Bandyopadhyay 等人則分別提出以染色體長度可變之
基因演算法(genetic algorithm, GA)以及模擬退火演算
法(simulated annealing, SA)來最佳化 XB 指標[25]，以
同時解決上述三項問題[27,28]。然而，綜觀上述方法
可發現，其個別均存在若干問題尚待解決，例如：
Bensaid 所提方法僅適用於群聚數目已知之應用場
合，而 Maulik 與 Bandyopadhyay 等人的方法則因採
用演化(evolutionary)策略來最佳化 XB 指標，故常面
臨因演化時間過長而導致計算量過大的缺點。 
對此，本計畫提出一可有效利用演化策略與 FCM
互補特性之演化競爭式聚類演算法 (evolutionary 
competitive clustering, ECC)，以同時解決上述問題。
ECC 之整體運作架構主要係由三部份組成：(1)一個
以有效性指標為基礎之聚類準則目標函數；(2)SA 與
FCM 競爭聚類演算法；(3)以模糊群聚間之交聯集特
性為基礎之有效性指標。其中值得注意的是，該目標
函數之用途是為 ECC 提供一良好之資料集分割敘
 
6 
( , )FCM FCMV U¢ ¢ 與( , )SA SAV U¢ ¢ ，此二解分別對應之目標函
數值為 FCME 及 SAE 。ECC 使用基因演算法中常見之
輪盤式(roulette wheel scheme)挑選機制來決定獲勝解
(winner solution)，因 ECC 之目的是最小化目標函數
E，故 ( , )FCM FCMV U¢ ¢ 與 ( , )SA SAV U¢ ¢ 被挑選中之機率分別
為 
SA
FCM
FCM SA
E
P
E E
= +   and  
FCM
SA
FCM SA
E
P
E E
= +  
即函數值較低者被選中的機率較高。此機制可提昇
ECC 對於解空間探索之廣度。 
此處假設由輪盤挑選出之優勝解定義為 ( , )V U¢ ¢
且目前解為( ( ), ( ))V t U t ，ECC 利用 SA 演算法中常見
之 Metropolis 準則來決定此優勝解被接受之機率 AP  
(acceptance probability)。當 ( , ) ( ( ), ( ))E V U E V t U t¢ ¢ £
時， ( , ) 1AP V U¢ ¢ = ；否則 
( ( ), ( )) ( , )
( , ) exp
( )
A
E V t U t E V U
P V U
T t
æ ö¢ ¢- ÷ç¢ ¢ ÷= ç ÷ç ÷çè ø  (2.10) 
其中 ( )T t 為目前溫度，其冷卻時程(cooling schedule)
定義為 
( 1) ( )T t T ta+ = ⋅          (2.11) 
其中 (0,1)a Î 為冷卻率(cooling rate)。換言之，當溫
度愈低時 ECC 對於較差的解之接受機率將愈低，因
此可保證 ECC 之尋解(聚類)過程將隨著溫度的冷卻
而逐漸收斂。 
圖 2.1 所示即為本計畫所提之演化式模糊聚類演
算法之整體運作流程，此處僅就流程中各步聚之運作
重點概要說明如下： 
1. 已知一未標記資料集X 。令離散時間指標 0t = ，
初始溫度 0( )T t T= ，停止溫度 minT ，冷卻率a，群
聚數c。 
2. 在樣本空間中隨機決定初始 ( )V t ，以(2.2)式計算此
時之 ( )U t ，並令目前最佳解( , ) ( ( ), ( ))V U V t U t* * = 。 
3. 依據( ( ), ( ))V t U t 分別以式(2.3)與(2.2)計算 FCM 產
生之候選解 ( , )FCM FCMV U¢ ¢ 。利用式(2.4)至(2.7)選擇
欲擾動之群聚中心，並以式(2.9)及式(2.2)計算 SA
產生之候選解( , )SA SAV U¢ ¢ 。分別計算二者對應之聚類
目標函數值 FCME 及 SAE 。 
4. 根據 FCME 及 SAE ，使用輪盤法從 ( , )FCM FCMV U¢ ¢ 與
( , )SA SAV U¢ ¢ 兩候選解當中選取一獲勝者，並令其為
( , )V U¢ ¢ 。 
5. 若 ( , ) ( ( ), ( ))E V U E V t U t¢ ¢ £ ， 則 更 新 ( ( 1),V t +  
( 1)) ( , )U t V U¢ ¢+ = ；否則跳至步驟 7。 
6. 若 ( , ) ( , )E V U E V U* *¢ ¢ < ，則更新目前最佳解為
( , ) ( , )V U V U* * ¢ ¢= 。跳至步驟 8。 
7. 以式(2.10)計算( , )V U¢ ¢ 之接受機率 ( , )AP V U¢ ¢ ，並產
生 一 均 勻 隨 機 數 [0,1]u Î 。 若 AP u> 則 令
( 1)V t V ¢+ = 且 ( 1)U t U ¢+ = ；反之令 ( 1)V t + =  
( )V t 且 ( 1) ( )U t U t+ = 。 
8. 使用式(2.11)進行冷卻。若 min( 1)T t T+ > ，則令
1t t= + ，並跳至步驟 3；否則 ECC 演算法結束，
並輸出最佳解( , )V U* * 。 
( , ) min 1,exp tA
t
E EP V U
T
           
[0,1)r
 
圖 2.1  ECC 演算法流程 
 
2.3 聚類有效性指標及演算法設計 
本計畫採用[21]所提之有效性指標以做為 ECC 估
測樣本集內正確群聚數之用。此指標利用模糊邏輯
(fuzzy logic)中常使用之交、聯集截斷算子(truncation 
operator)來量測各群聚內部及群聚之間的緊湊性與分
離性，其定義為 
1
1
1
1 1 1
1
( ) max{ }
2 1
min{ , }
( 1)
n
ik
i c
k
c c n
ik jk
i j i k
F U u
n
u u
c c n
£ £=
-
= = + =
=
æ ö÷ç ÷- ç ÷ç ÷ç- è ø
å
å å å
 (2.12) 
其中第一項量測各樣本於所屬群聚內之緊湊性，其值
愈大表示各群聚愈緊密；第二項量測群聚之間之分離
性，其值愈小表示各群聚間之分離性愈佳。因此，F(U)
值愈大表示聚類效果愈好，故 ECC 在估測群聚數過
程中之任務其以最大化 F(U)為目標。茲就本計畫所提
之聚類有效性演算法使用流程說明如下： 
1. 已知一未標記資料集X 。令初始群聚數 2c = ，最
大群聚數限制 maxc n= ，最佳有效性指標值
F * = -¥。 
2. 令離散時間指標 0t = ，初始溫度 0( )T t T= ，停止
 
8 
其可清楚界定大部份流域(黑)與森林(灰)位置，但其將
基隆河上方耕地、中山高及右下方住宅區誤分為水體
為其主要缺點。相較之下，如圖2.5(c)所示ECC 將影
像分為5類，因其增加了開闊地之類別且不再單以緊密
性為唯一之聚類準則，故可有效消除FCM之誤分類現
象。整體而言，由上述結果證實，ECC之目標函數及
演化式聚類方式確實可有效解決FCM難以克服之聚
類問題。 
 
2.6 結論與成果自評 
本計畫提出一創新之演化競爭式聚類演算法
(ECC)，以做為未來在發展機器人視覺伺服控制上所
需影像處理技術之基礎。ECC演算法不僅可有效克服
因群聚大小、密度差異及群聚數目未知所造成之聚類
問題，其更可有效改善聚類目標函數之區域極值所衍
生之聚類成效不彰之現象。由一系列模擬與實驗結果
證實，ECC演算法確實可成功處理各種難以應付之聚
類問題。此外，由衛星影像分割結果可得知，ECC在
影像處理等相關技術上確實具有相當大的應用潛力。 
d
c
d
d
c
d
c
d
d
d
c
c
d
d
d
c
c
d
c
c
d
c
c
b
d
c
b
b
b
b
c
b
b
b
b
b
b
b
b
b
a
a
a
Crisp Clustering Result and Membership Contour
20 30 40 50 60 70 80 90 100
30
35
40
45
50
55
60
65
70
 
e
e
e
e
e
e
a
c
a
a
c
a
c
a
a
a
c
a
c
c
a
a
c
c
a
c
a
c
c
a
a
c
d
d
d
d
c
d
d
d
d
d
d
d
d
d
b
b
b
Crisp Clustering Result and Membership Contour
0 20 40 60 80 100 120
30
35
40
45
50
55
60
65
70
 
(a) FCM聚類 
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
b
b
b
b
b
b
b
b
b
b
b
b
b
b
b
b
b
Crisp Clustering Result and Membership Contour
20 30 40 50 60 70 80 90 100
30
35
40
45
50
55
60
65
70
 
b
b
b
b
b
b
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
c
c
c
c
c
c
c
c
c
c
c
c
c
c
c
c
Crisp Clustering Result and Membership Contour
0 20 40 60 80 100 120
30
35
40
45
50
55
60
65
70
 
(b) FCM聚類(令c*已知) 
b
b
b
b
b
b
b
b
b
b
b
b
b
b
b
b
b
b
b
b
b
b
b
b
b
b
b
b
b
b
b
b
b
b
b
b
b
b
b
b
a
a
a
Crisp Clustering Result and Membership Contour
20 30 40 50 60 70 80 90 100
30
35
40
45
50
55
60
65
70
 
b
b
b
b
b
b
c
c
c
c
c
c
c
c
c
c
c
c
c
c
c
c
c
c
c
c
c
c
c
c
c
c
c
c
c
c
c
c
c
c
c
c
c
c
c
c
a
a
a
Crisp Clustering Result and Membership Contour
0 20 40 60 80 100 120
30
35
40
45
50
55
60
65
70
 
(c) ECC聚類 
圖2.3  Bensaid資料集及其聚類結果 
-4 -3 -2 -1 0 1 2 3 4
-4
-3
-2
-1
0
1
2
3
4
 
d d
d
d
d
d
d
d
d
d
d
d
d
cdd
d
d
d
d
d
d
d
c
d
d
d
d
d
d
d
d
d
d
d
d
d
a
d
d
d
d
d
d
d
d
dd
d
d
d
d
d
d
d
d
d
d d
d
d
d
d
d
d
d
d
d
d
d
d
d
d
d
dd
d
d
d
d
d
d
d
d
d
d
dd
d
a
c
c
e
c
c
c
c
c
c c
c
c
c
d
c
c
c
c
c
cc c
d
c
c
c
c cc
c
c b
c
bc c
c
c
c
c c
cc
c
c
c c c
c
c
c
c
cc
c
c
c
c
c
e
c
c
c
c
c
c
c
b
c cc
c
c
c
c
ccd
c
c
c
d
c
c
c
c
c
c
c
c
c
cc
c
b
b
b
bb
b
b
b
b
b
b
b
b
b
b
b b
b b
b
b
bb bb
b
b
b b
b
c
b
b
b
b
b
b
b
bb
b
bb
b
b
b
b
b
b
b
b
b
b
b
b
b
b
b b
bb
b
c
b
b
b
b b
b
bb
b
bb
b
b
bc
b
b
b
b
b
b
b
b
aa
a
a
a
aaa
a a
a
a
a
a
a
a
a
a
a
a
e
a
a
a
a
a
aa a
a a e
aa
a
a a
e
e
a
a
a
a
a
a
a aa
aa
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a a
a
a
i
a
a
a
a
a ea
a
a
a a
a
a
a
a
a
a
d
a
a
a
a
e
e
e
e
f
ee
e
e e
e
e
e
a
e
e
e
e
e e
e
ee
a
e
ee
e
e
g
e
e
e
a
e
e
c
e
ee
ee
e
e
e
e
e
e
h
e
e
e
e
e
e
e
e
e
e
e
e
e
c
e
e
e
e
e
e
e
e
e e
e
e
a
e
e
e
e
e
e
e
a
e
e
e
e
e
e ee f
f
ff
f
ff
f
f
ff
f
f
f
f
f
f
f
f
f
f
ff
ff
f
f
f
f
f
f
f
f
f f
f
f
f
f
f
f
f
f
f
f
f
f
f
ff
f
f
f
f
ff
f
f f
ff
f f
f f
f
g
f
g
f
f f
f
f
f
f
b
f
f
f
f
ff
ff
f
f
f f
f
ff
f
f
f
f
f
i
i
i
i
i
i i
i
h
i
i
i i
i
ii
i
i
i
ii
i
i
i
i
i
iii
i
h
i
i
i h
i
i
h
i i
i
i
i
i
ii
i
i
i
i
i
h
hi
i
i
i
i
i
i
i
ii i
i
i
i
i
i
i
i
ii
i
i
i
i
i
i
i
ii i
h
i
i
i
i
i ii
i
ii
i
i
h
i
h h
e
hh
hh
h
h
h
h
h
h
h
h
h
e
h
h
h h
h
h
h
h
h
e
h
h
h
hhh
h
h
h
g
h
h
hh
h
h
h
h
h
h
h
h
h
h
h
h
h
h
h h
i
h
g
hh
h
h
h
h
h
e
h
h
h
h
h
e
h h
h
h h
h
h
h
h
hh
h
h
h
h
h
h
h
g
g
g
f
g g
gg
g
g
g
g
g
g
g
g g
f
g
g
g
g
g
gg
g
g gg
g
g
g
g
g
h
h g g
g
g
gg
gg
g
g
gg
g
g
g
g
g
g
g
g g
g
g
g
g
gg
gg
g
g
g
g
g
g
g
g g
g
g
g
g
g
g
g
g
g
g
h
g
g
gg g
Crisp Clustering Result and Membership Contour
-3 -2 -1 0 1 2 3
-3
-2
-1
0
1
2
3
 
圖 2.4  Bandyopadhyay 資料集及 ECC 之聚類結果 
 
 
(a) 淡水河出海口全彩衛星影像 
 
(b) FCM聚類( 4c* = ) 
 
(c) ECC聚類( 5c* = ) 
圖 2.5  衛星影像分割結果 
 
 
10 
IOM 則可根據BI 由畫面差異遮罩FDM 與背景差
遮罩BDM 產生 
1k k kBD I BG -= -                   (3.6) 
1,   if  ( , )
( , )
0,   otherwise
k
k
BD x y Th
BDM x y
ìï ³ï= íïïïî
      (3.7) 
( , ),   if  ( , ) 1
( , )
( , ),   otherwise
k k
k
k
BDM x y BI x y
IOM x y
FDM x y
ìï =ï= íïïïî
(3.8) 
雖然經由適當之閥值Th選擇配合上述目標物遮罩產
生方式可去除大部份靜止背景，但此時 IOM 仍常有
些許微小區塊雜訊存在，且遮罩內外亦可能存在若干
空洞或鋸齒狀邊緣。為使遮罩效果更加的貼近現實目
標，吾人須對 IOM 進行必要之後處理工作，例如：
可用相連成份法(connected component)標記所有相連
的像素，並將相連像素個數過少的區域刪除；另外，
以二值型態處理(morphological operations)為基礎之
各種方法，例如：空洞填補(hole filling)、間隙封閉
(closing)或細連結處斷開(opening)…等步驟皆可用以
提昇目標物遮罩之品質。 
此處須特別留意的是，空洞一般之產生因素有：
1)目標物所阻擋之背景亮度接近於目標物本身；2)目
標物本身之相同亮度區域(如：同色系衣物)；3)目標
物姿態之封閉(如：四肢之屈伸所形成之閉合區域)。
其中因素 1)與 2)產生之空洞因為實際仍屬於前景部
份，故才是真正須被填滿之對象；而因素 3)所生之空
洞本身為背景，若一味將其填滿將可能造成所得之
IOM 無法完如實反應目標物之狀態。因此，本研究
使用一簡單之經驗法則進行選擇性之空洞填滿[33]：
若空洞所在之畫面像素亮度與同位置所註冊之背景
像素亮度差值高於某閥值(設定為 7)時，則表示該空
洞實際屬於前景之一部份，故須被填滿；反之，若亮
度差小於該值，則其極可能為背景之一部份，吾人將
令其維持原狀。 
 
3.2.2 適應性閥值快速遞迴演算法 
由於攝影系統常因本身之硬體設計或環境因素而
產生雜訊干擾畫面品質，並使畫面差FD與背景差
BD 影像無法有效描述運動物體之形態。因此如何利
用差異影像之資訊選擇適當之閥值Th，藉以濾除雜
訊干擾並突顯運動物體之真實狀態便成為以背景相
減法為基礎之運動物偵測技術首先須解決之重要課
題。本計畫改良 Habili 等人[30]所提方法於每次獲得
FD後計算一最佳之適應性Th，以便賦予系統克服各
種不同程度干擾之能力。以下概述Th之快速計算方
式。 
假設攝影系統可提供具有L階亮度變化之畫面，
則FD為目前畫面 kI 與前一畫面 1kI - 經型態梯度濾波
後之亮度差異影像 
1( , ) ( , ) ( , )k k kFD x y I x y I x y-= - ,        (3.9) 
where 1,...,x R= , and 1,...,y C=  
此處 R 與C 分別表示畫面之高與寬所含之像素個
數。若將FD之亮度差機率分佈表示為 
( ) #{( , ) | ( , ) }h d x y FD x y d= = , ( )( ) h dP d
RC
= (3.10) 
其中 { ( 1),..., 0,...,( 1)}d L LÎ - - - 表示亮度差，且
#{}⋅ 表示計算集合內所有成員之個數。由於一般雜訊
所造成之畫面亮度差異變化本身具有零平均值(zero 
mean)特徵，而因物體運動而產生之亮度差則經常呈
現正/負偏態(positive/negative skewness)特性。因此，
使用三模(trimodal)高斯函數：包含左、右與中間模
式，即可有效近似FD之亮度差機率分佈，其定義為 
( )
( )
( )
2
1 1
21 1
1
2
1
22 2
2
2
1 3
23 3
3
min2
2
max2
 ,
( ; )  ,
 ,
i
i
i
q
q
q
e d i t
f i t e t i t
e t i d
m
s
s
m
s
s p
s p
s p
-
-
-
-
-
ìïï £ <-ïïïïïï@ - £ £íïïïï < £ïïïïî
(3.11)
 定義近似準則(fitting criterion)以及可濾除最大程度雜
訊之最佳閥值為 
max
min
( ) ( ) ( ; )
d
i d
H t P i f i t
=
-å , 
0,1,.., 1
argmin ( )
t L
Th H t
= -
=  (3.12) 
亦即，最佳適應性閥值Th之選擇係以最小化 ( )H t 為
目標。根據此一原則，三模個別之參數：比例因子q、
平均數m及變異數s 可隨著 t之不同計算如下[30] 
a) 左模式(mode1) 
min
1
1( ) ( )
t
i d
q t P i
- -
=
= å ,   
min
1
1
1
1
( ) ( )
( )
t
i d
t iP i
q t
m
- -
=
= å ,  
( )
min
1 2
2
1 1
1
1
( ) ( ) ( )
( )
t
i d
t i t P i
q t
s m
- -
=
= -å .        (3.13) 
b) 中央模式(mode2) 
2( ) ( )
t
i t
q t P i
=-
= å ,   2( ) 0tm = , t" , 
2 2
2
2
1
( ) ( )
( )
t
i t
t i P i
q t
s
=-
= å .         (3.14) 
c) 右模式(mode3) 
max
3
1
( ) ( )
d
i t
q t P i
= +
= å ,   max3
13
1
( ) ( )
( )
d
i t
t iP i
q t
m
= +
= å , 
 ( )max 223 3
13
1
( ) ( ) ( )
( )
d
i t
t i t P i
q t
s m
= +
= -å .    (3.15) 
由上述公式可看出，此法對於每個強度差 t值均須重
新計算q、m與s 公式內含之總和項，這將大幅降低
其計算效率。為改善此一問題，本研究利用 Otsu 對
於雙模(bimodal)閥值選擇所發展之遞迴概念[31]，建
立三模(trimodal)閥值選擇之遞迴關係，並導出下列快
速計算公式： 
a) 左模式(mode1) 
 
12 
( , ) / (0,1]A BOAR A B S S= Î        (3.19) 
則其值愈接近1表示兩物件之尺寸相似度愈高，亦即兩
者可能代表同一目標物之機會愈高。令 pO 與 cO 分別
為前一畫面與目前畫面內之物件，則根據上述之距離-
尺寸計算方法，吾人可建立兩連續畫面內出現物件之
對應關係矩陣 
 1, if ( , )  and
( , ) ( , )
 0, otherwise
p c
p c p c
OBD O O
R O O OAR O O
h
k
ìï <ïïï= >íïïïïî
(3.20) 
其中閥值選擇為 5h = 及 0.4k = 。此矩陣通常具有下
列特性： 
1) one-to-one對應：即R之第 cO 行內僅有1個1元素，
此表示 cO 擁有與前一畫面物件 pO 之唯一對應關
係，系統賦予 cO 相同於 pO 之識別標籤。 
2) one-to-none對應：即R之第 cO 行內全為0元素，此
表示 cO 為新進入(或出現在)畫面內之物件，此時系 
統將分配其一新的識別標籤。 
3) one-to-many對應：即R之第 cO 行內有 2K ³ 個1元
素，此表示前一畫面內有K 個目標物在目前畫面中
發生阻擋，亦即 cO 實際上可被切割並還原成K個物
件。本研究採用[33]所提之物件位置與rgI 特徵分類
來解決此問題，而後系統根據分割結果分配對應之
識別標籤。 
4) none-to-one對應：即R之第 pO 列內全為0元素，此
代表前畫面物件 pO 無法在目前畫面中找到任何對
應，亦即該物件已離開(或消失)於畫面中，此時系統
將取消其標籤。 
由於本追蹤系統係將目前分割完成之物件儲存以
作為下一畫面建立關聯矩陣之比較基礎，此可有效避
免many-to-one對應(即 pO 於目前畫面中分裂成2個(含)
以上物件)之問題，故可有效降低系統複雜度。 
 
B. 分割受阻擋之目標物 
此處利用文獻[33]所提之物件位置與rgI 特徵分類
法，針對前一畫面中有2個(或以上)目標物於目前畫面
中融合(merge)成之單一物件團塊進行分割，藉以區分
各相關物件在團塊中所呈現之部份。本法利用物件像
素之位置資訊搭配各物件在未受阻擋之前之外觀模型
(appearance model)所含色彩資訊進行團塊分割。外觀
模型主要由物件像素所含之RGB強度資訊經正規化
(normalized)後所得之 r 、 g 訊號及像素亮度 I 所構
成，其中各訊號與RGB之轉換關係為 
/( )r R R G B= + + ,  
/( )g G R G B= + + ,  
0.3 0.59 0.11I R G B= + + .    (3.21) 
此處令三者介於 [0,255]。假設物件 pO , 1,2,...,p K=
於目前畫面中發生阻擋並產生 cO ，若 pO 之外觀模型
為 p =A { , 1,2,..., }i pi N=a ，其中 ( ) ( ) ( )[ , , ]r g Ii i i ia a a=a
代表像素 i之rgI 向量，且 pN 為物件 pO 於畫面中所佔
之像素個數；另外，令目前之物件團塊 cO 外觀為
{ ,c j j= =bB 1,2,..., }cN ，其中 ( ) ( ) ( )[ , , ]r g Ij j j jb b b=b 代表
像素 j之rgI 向量， cN 為 cO 之像素個數，此處使用兩
階段分類法確定 jb 屬於 pO , 1,2,...,p K= 中之何者。 
第一階段針對 cO 進行初步分割，其規則為：
j pOÎb   if 
( ) ( )
1
1,2,..., , ,
( , )
arg max
pN c c
j ii
p K c r g I p
b a
p
N
¢
¢¢=
= =
ì üï ïGï ïï ï= í ýï ï¢ï ïï ïî þ
å   (3.22) 
其中 i ¢表示僅考慮 pA 在像素 j位置附近之色彩資訊
i ¢a 與 jb 之相似性，而 pN ¢表示在此範圍內之 pA 像素
個數。此處選擇 pA 在像素 j位置之縱向 (上下)7個像
素範圍內(且包含 pA 在此範圍內之所有橫向像素)與
像素 j進行比較，此法可避免將像素 j歸類到遠處具
有類似色彩資訊之物件。此外，G為像素 rgI 相似度
測量函數，其定義為 
( ) ( )
( ) ( )  1, if | |( , )
 0, otherwise
c c
j cic c
j i
b a T
b a ¢¢
ìï - <ïG = íïïïî
  (3.23) 
其中 cT 為一閥值。當完成所有於 cB 內之 cN 個像素之
分類後，吾人計算此階段所得之K個物件個別質心之
橫向位置。 
令 ( )xpCM 表示分類為 pO 之所有 cB 像素，其質心位
於畫面內之橫向座標。第二階段利用此座標對 cO 進行
再分類。其分類規則定義為 
j pO *Îb  if 
( ) ( )
, , 1
( )( )1,2,...,
( , )/
argmax
pN c c
j pic r g I i
xxp K
p j
b a N
p
CM b
¢
¢¢= =*
=
ì üï ï¢Gï ïï ï= í ýï ï-ï ïï ïî þ
å
(3.24) 
其中 ( )xjb 代表像素 j於畫面中之橫向座標，而 i ¢與G之
定義與第一階段相同。此階段之分類目的係為促使物
件分割結果具有更佳之緊密性(compactness)。 
 
3.4 實驗結果與討論 
本研究利用Hall Monitor之CIF影像測試序列驗證
所提之運動目標偵測與追蹤系統單元之效能，其畫面
解析度為288 352´ ，且每秒畫面幅數為25fps。 
A. 運動目標偵測 
首先說明運動目標偵測系統之適應性閥值、背景
註冊與後處理技術等實驗結果。圖 3.4 所示為獲得畫
面#35目標物遮罩過程中之所有過渡狀態，其中(e)
與(f) 係表示將FD與BD 中所有具強度變化之像素
全標示為 1(反之為 0)所得之二值影像，由此二圖可看
出，雖然畫面中僅有一移動物體，但實際上因各種雜
訊干擾而造成絕大部份像素均發生強度變化，若吾人
僅就像素強度變化與否來決定遮罩，則將難以正確偵
測移動物之位置，此現象清楚說明一良好之適應性閥
值決定機制之重要性。圖(g)與(h)則表示使用快速遞
 
14 
效追蹤各目標之動態。此外值得注意的是，畫面#165
顯示系統可偵測出物品之放置，且其對於畫面#187
中因偵測方法產生之OM 瑕疵(兩目標物融合成單一
目標，可視為廣義之物件阻擋)亦可成功區分原始目
標物之相對位置。因此，綜和上述結果可證實目前所
建置之系統的確具有同時追蹤多個動態目標之能力。 
 
3.5 結論與成果自評 
本計畫改良並整合現有之影像處理技術提出一多
目標運動偵測與追蹤系統，目前已完成系統相關軟、
硬體建置之階段性工作。經實驗結果證實，本系統對
測試影像之所有畫面均可產生正確之運動目標物遮
罩，且同時亦能根據連續畫面內之遮罩資訊正確地同
時追蹤多個目標之移動軌跡。因此，目前之研究成果
確實已達成原先設定之進度與目標。 
 
16 
傳統之CBM係將場景之背景模型建立於一般RGB
色彩空間，其令畫面中每一像素擁有各自之碼書，且
每一碼書係由為數不等之碼詞(codeword)所組成，碼
詞之數目取決於其所屬像素位置之背景複雜度而定，
通常背景類型愈多樣化之像素需要愈多碼詞來完整描
述其模型。CBM以亮度邊界(brightness bounds)及色彩
偏移(color distortion)判斷目前像素是否顯示背景成
份，此將使碼書內的每一碼詞所描述之像素值群聚
(cluster)均呈現圓柱型(cylindrical)分佈，且造成各圓柱
體之軸心均通過RGB座標之原點。若吾人可由一像素
之碼書中檢索出任一碼詞其群聚圓柱體包含此像素
值，則此像素目前呈現的是背景部份，反之則為前景
(即運動目標物)部份。 
傳統之CBM利用色彩偏移量測將像素值與碼詞兩
者之亮度資訊納入比對依據，藉以降低兩者因亮度差
所造成之誤判，並避免如正規化RGB像素值等方法可
能造成之數值不穩定問題；此外，CBM並以加大碼詞
圓柱體之亮度上下界方式避免系統將背景亮部或前景
陰影誤分類為前景之一部份。CBM目前雖已被成功應
用於許多需自動化影像監控之場合中[39-43]，然而經
實驗證實，此法對前景投射於背景上之陰影抑制效果
有限，其一般而言僅對半影(penumbra)有較佳之抑制
能力，而對本影(umbra)部份則常無法有效去除。 
對此，文獻[3]提出將碼書式背景模型建立於HSV
色彩空間，並以圓錐-圓柱混合式(hybrid cone-cylinder 
codebook, HC3)背景模型改良傳統之CBM，藉以同時
克服背景上之陰影、亮部以及亮度變化對於前景分割
所造成的困難。HC3利用HSV色彩空間較接近人類視
覺感知並可較直觀且有效區分陰影[44]之特性建構
CBM，其利用圓錐-圓柱混合式群聚取代舊有的圓柱
模型，使CBM能更有效地抑制背景陰影與亮部
(highlight)。然而，由於HC3採用HSV色彩空間建構碼
書，此使其存在下述缺點：當吾人進行RGB對HSV轉
換時，所得之飽和度(saturation)S 值大小係代表在某
一亮度值時可得之最大飽和度百分比；換言之，HSV
座標內之值將與亮度值之大小相關，且當亮度值降低
時，因飽和度範圍變小將可能使得S 值呈現劇烈變化
[45-47]，此現象可由圖4.2所示之一暗紅色像素於HSV
空間之樣本分佈情形看出。圖中之RGB空間中的對角
線代表無色軸(achromatic axis)，而HSV空間之圓柱體
代表像素值之分佈邊界；為方便比較，吾人將所有座
標值正規化至 [0,1]區間。左上圖顯示該暗紅色像素值
因受到攝影系統內部雜訊之影響而產生輕微擾動，使
其群聚呈現小範圍分佈；右上圖為其RGB座標值之時
間響應圖。右下圖為HSV轉換結果，可看出該像素之S
值呈現劇烈變動，此造成其於HSV空間中之群聚呈大
範圍散佈(見左下圖)。由於此一缺陷，使得HC3在建
立碼書式背景時往往需要較多碼詞才可充份描述低亮
度背景之群聚型態，此不僅造成系統於背景建模時之
記憶體浪費，更可能拖慢碼書索引速度並降低目標物
偵測模組效能。 
 
圖4.2 暗紅色像素於RGB與HSV空間之樣本分佈 
 
 
圖4.3 暗紅色像素於IHLS空間之樣本分佈 
 
A. 改良式HLS色彩轉換 
為提昇傳統CBM之陰影抑制能力並避免因使用
HSV色彩空間建立碼詞可能造成之碼書過大問題，本
計畫利用改良式HLS色彩空間(IHLS)[45]重新建構一
改良型碼書式背景模型(improved CBM, ICBM)。IHLS
為一極座標式色彩表示法，有別於HSV，其具有圓錐
形色彩分佈邊界。因IHLS對飽和度之計算與像素亮度
無關，故可更有效地分離各種顏色中的亮度與色度
(chrominance)資訊，並使其能更直觀並有效地處理前
景所投射之陰影(moving cast shadow)。 
IHLS對RGB座標之轉換公式可表示為[46] 
2 2
max( , , )
max( , , ) min( , , )
3
,    ( )              (4.1)
2 2
   arccos( )         if 0 and 0
360 arccos( )    if 0 and 0
    undefined             if 0
L R G B
S R G B R G B
G B
cx R cy B G
cr cx cy
cx c r cr cy
H cx cr cr cy
S
=
= -
+= - = -
= +
ì ¹ £
= - ¹ >í
=

ïïïï
ïïïïî
 
其中，L表示亮度、S 表示飽和度、H 表示色調(hue)，
且當飽和度 0S = (即R G B= = )時色度H 為未定
義。此處須留意的是，為使IHLS轉換結果完全落於其
色彩圓錐體內，本計畫定義亮度為L = max( , , )R G B
此有別於IHLS原始設定之亮S 度函數。圖4.3所示為圖
4.2之暗紅色像素之IHLS轉換結果，圖中之圓錐體表示
IHLS之色彩邊界。比較圖4.2與圖4.3可看出，相較於
 
18 
c
oSh
oh
oS
S
Ht
St
St
Ht
oc
 
圖4.6 色彩平面上之陰影消除決策區域 
 
[ , , ] [ , ] [ , ]o o xo yo o o o o oL C C L L S= ºx c h  
且令該像素所對應之碼書內任一碼詞為 
1 2[ , , ] [ , ]LL C C m=v c  
當下列三條件完全符合時 
   and   o oL L L L Lg< - <      (4.5) 
0 SS S t- <   且  o HSh t- <c    (4.6) 
系統將 ox 視為碼詞 v所描述之背景受陰影投射後之
觀測值，故此時 ox 將被改分類為背景像素。圖4.6所示
之陰影區域即為上述規則於IHLS色彩(H-S)平面上所
形成之決策區域，當原前景像素值落於此類區域時，
則系統將此像素視為背景像素。 
 
4.3 跌倒事件偵測 
本計畫主要參考並改良文獻[49]所提之方法，採用
下列步驟偵測跌倒事件：1)以運動歷史圖 (motion 
history image, MHI)量化目標物主體之運動特性；2)以
影像矩量(moment)計算目標物團塊之近似楕圓；3)分
析目標物之MHI量化值及楕圓參數之變化幅度，據此
偵測並確認跌倒事件。以下概述各步驟之實現方法。 
 
A. 運動量化 (Motion Quantizer) 
由於跌倒經常伴隨著大幅度快速運動，此特性恰可
由運動歷史圖MHI之量化結果進行初步估測。首先令
目前畫面 ( , , )I x y t 與先前畫面 ( , , )I x y t t-D 之影像差
異(frame-difference image)二值化圖為 
 1    if  ( , , ) ( , , )
( , , )
 0    otherwise                         (4.7)
I x y t I x y t t Th
D x y t
ìï - -D >ï= íïïïî
 
一般令時間差 1tD = ，其值愈大通常將可由 ( , , )D x y t
看出愈明顯之動作差異；Th為一閥值(threshold)，其
值設定之優劣將直接影響 ( , , )D x y t 是否可如實反應二
影像間之差異，本計畫利用先前所提之適應性閥值快
速遞迴算法計算Th值。接著定義MHI為 
{ }
                              if   ( , , ) 1
( , , )
max 0, ( , , 1) 1   otherwise   (4.8)
T D x y t
H x y t
H x y t
ìï =ï= íï - -ïïî
其中T 表示MHI記錄運動變化之持續時間，由於跌倒
之動作多在1秒內完成，本計畫令 0.2T = 秒；在MHI
中，時間上愈近發生的動作其亮度愈高。假設團塊
(blob) ( )B t 為受測者目前所在之前景像素所成集合，
利用MHI將此目標物之動作量化為 
( , ) ( )
( , , )
( )
( )
x y B t
MHI
H x y t
C t
B t T
Î= ´
å
         (4.9) 
其中 | |⋅ 表示集合之基數(cardinality)，其計算該團塊所
包含之像素個數。明顯地 [0,1]MHIC Î ，其值越大代表
目標物本體之動作越劇烈。 
 
B. 目標形狀變化分析 (Shape Analyzer) 
然而除了跌倒之外，快步行走、突然坐下或蹲下…
等皆可能伴隨目標物之快速運動，本計畫利用影像矩
量找出目標物團塊外觀之近似楕圓，其次透過分析楕
圓參數(中心座標、長軸傾角、長-軸比)來估測目標物
外型變化，藉以由眾多快速運動中進一步篩選出真正
具危險性之跌倒動作。楕圓中心座標計算方式為 
10
00
m
x
m
= ，  01
00
m
y
m
=          (4.10) 
其中 pqm 為團塊之空間矩(spatial moments)，其定義為 
( , )   for  , 0,1,2,...pqm D x y dxdy p q
+¥ +¥
-¥ -¥
= =ò ò  
而楕圓長軸與水平軸之夾角 
11
20 02
2
arctan
mq m m
æ ö÷ç ÷= ç ÷ç ÷ç -è ø           (4.11) 
則可由中心矩(central moments)求得 
( ) ( ) ( , )p qpq x x y y D x y dxdym +¥ +¥-¥ -¥= - -ò ò  
另外，楕圓之長/短半軸可由共變異數(covariance)矩陣 
20 11
11 02
J
m m
m m
é ùê ú= ê úê úë û
              (4.12) 
之最大 maxI 與最小 minI 特徵值計算而得 
11
84 3
max
min
4 I
a
Ip
é ùæ ö÷ç ê ú÷= ç ÷ç ê ú÷çè ø ë û
，  
11
84 3
min
max
4 I
b
Ip
é ùæ ö÷ç ê ú÷= ç ÷ç ê ú÷çè ø ë û
   (4.13) 
而長-軸比定義為 /R a b= 。 
 
C. 跌倒事件定義及偵測 (Fall Recognizer) 
由於目標物外觀之近似楕圓受前景分割結果之影
響甚巨，為使楕圓參數不因前景分割缺陷(可能由目標
物受障礙物阻擋、鏡像、反光、本影過於厚重…等因
素造成)瞬間產生大幅度波動進而影響系統對跌倒偵
測之準確性，吾人以各參數於1秒內之標準差(standard 
deviation)分析其個別大小與跌倒事件間之關係。本計
畫根據實際觀察結果定義跌倒動作如下[49]： 
1) 跌倒事件必伴隨目標物主體於短時間內大幅度之
運動，即 ( )MHIC t 過大。 
2) 跌倒事件必定影響目標物之方位(orientation)或形
狀：當受測者之跌倒方向與攝影機光軸(optical axis)
垂直時，其方位(即楕圓長軸之水平夾角)將明顯變
化，而形狀則小幅改變；若跌倒方向與光軸平行
時，形狀將顯著改變而方位則幾乎相同。 
 
20 
 
200 400 600 800 1000 1200 1400 1600
0
50
100
150
200
250
m
aj
or
 a
 &
 m
in
or
 b
-50
0
50
100
150
200

200 400 600 800 1000 1200 1400 1600
0
0.5
1
1.5
C
M
H
I &
  R
# frame
0
20
40
60
 
 
圖4.8 目標物外觀及運動參數隨時間之演變 
 
   
   
   
 
22 
text-independent speaker recognition,” Pattern Recog., vol. 37, no. 
10, pp. 2095-2096, 2004. 
[19] R. Babuska, Fuzzy modeling for control, Kluwer Acade., Norwell, 
Mass., 1998. 
[20] S. Guillaume, “Designing fuzzy inference systems from data: an 
interpretability-oriented review,” IEEE Trans. on Fuzzy Syst., vol. 
9, no. 3, pp. 426-443, 2001. 
[21] M. Y. Chen and D. A. Linkens, “Rule-base self- generation and 
simplification for data-driven fuzzy models,” Fuzzy Sets and Syst., 
vol. 142, pp. 243-265, 2004. 
[22] N. R. Pal and J. C. Bezdek, “On cluster validity for the fuzzy 
c-means model,” IEEE Trans. on Fuzzy Syst., vol. 3, no. 3, pp. 
370-379, 1995. 
[23] A. M. Bensaid, L. O. Hall, J. C. Bezdek, L. P. Clarke, M. L. Sil-
biger, J. A. Arrington, and R. F. Murtagh, “Validity-guided 
(re)clustering with application to image segmentation,” IEEE 
Trans. on Fuzzy Syst., vol. 4, no. 2, pp. 112-123, 1996. 
[24] I. Gath and A. B. Geva, “Unsupervised optimal fuzzy clustering,” 
IEEE Trans. on Patt. Anal. And Mach. Intel., vol. 11, no. 7, pp. 
773-781, 1989. 
[25] X. L. Xie and G. Beni, “A validity measure for fuzzy clustering,” 
IEEE Trans. on Patt. Anal. And Mach. Intel., vol. 13, no. 8, pp. 
841-847, 1991. 
[26] W. Wang and Y. Zhang, “On fuzzy cluster validity indices,” Fuzzy 
Sets and Syst., vol. 158, pp. 2095-2117, 2007. 
[27] U. Maulik, and S. Bandyopadhyay, “Fuzzy partitioning using a 
real-coded variable-length genetic algorithm for pixel classifica-
tion,” IEEE Trans. on Geo. and Remote Sens., vol. 41, no. 5, pp. 
1075-1081, 2003. 
[28] S. Bandyopadhyay, “Simulated annealing using a reversible jump 
Markov chain Monte Carlo algorithm for fuzzy clustering,” IEEE 
Trans. on Know. and Dtat Engin., vol. 17, no. 4, pp. 479-490, 
2005. 
[29] S. Y. Chien, Y. W. Huang, B. Y. Hsieh, S. Y. Ma, and L. G. Chen, 
“Fast video segmentation algorithm with shadow cancellation, 
global motion compensation, and adaptive threshold techniques,” 
IEEE Trans. Multimedia, vol. 6, no. 5, pp. 732-748, 2004. 
[30] N. Habili, A. Moini, and N. Burgess, “Automatic thresholding for 
change detection in digital video,” in Proc. SPIE Conf., Australia, 
vol. 4067, pp. 133-142, 2000. 
[31] R. M. Haralick and L. G. Shapiro, Computer and Robot Vision, 
vol. I, Reading, MA: Addison-Wesley, 1992, pp. 20-26. 
[32] J. B. Kim and H. J. Kim, “Efficient region-based motion segmen-
tation for a video monitoring system,” Pattern Recogn. Lett., vol. 
24, pp. 113-128, 2003. 
[33] H. Wang and D. Suter, “A consensus-based method for tracking: 
modelling background scenario and foreground appearance,” 
Pattern Recogn., vol. 40, pp. 1091-1105, 2007. 
[34] K. Toyama, J. Krumm, B. Brumitt, and B. Meyers, “Wallflower: 
principles and practice of background maintenance,” in Proc. Int’l 
Conf. on Computer Vision, 1999. 
[35] A. Amer, “Voting-based simultaneous tracking of multiple video 
objects,” IEEE Trans. Circuits Syst. Video Technol., vol. 15, no. 
11, pp. 1448-1462, 2005. 
[36] K. Kim , T. H. Chalidabhongse, D. Harwood, and L. Davis, “Re-
al-time foreground-background segmentation using codebook 
model,” Real-Time Imaging, vol. 11, pp. 172-185, 2005. 
[37] C. Stauffer and W.E.L Grimson, “Adaptive background mixture 
models for real-time tracking,” in Proc. Computer Vision and 
Pattern Recognition Conf., 1999. 
[38] A. Doshi and M. Trivedi, “Hybrid cone-cylinder codebook model 
for foreground detection with shadow and highlight suppression,” 
in Proc. IEE Int’l Conf. on Advanced Video and Signal Based 
Surveillance, Nov. 2006. 
[39] W. Zhang, F. Chen, W. Xu, and E. Zhang, “Real-time video intel-
ligent surveillance system,” in Proc. IEEE Int’l Conf. on Multi-
media and Expo, pp. 1021-1024, Jul. 2006. 
[40] S. W. Joo and R. Chellappa, “A multiple-hypothesis approach for 
multiobject visual tracking,” IEEE Trans. On Image Processing, 
vol. 16, pp. 2894-2854, 2007. 
[41] A. Ilyas, M. Scuturici, and S. Miguet, “Real-time foreground- 
background segmentation using a modified codebook model,” in 
Proc. IEE Int’l Conf. on Advanced Video and Signal Based Sur-
veillance, pp. 454-459, Sep. 2009. 
[42] S. Park and M. M. Trivedi, “Understanding human interactions 
with track and body synergies (TBS) captured from multiple 
views,” Computer Vision and Image Understanding, vol. 111, pp. 
2-20, 2008. 
[43] Y. Miao, S. M. Naqvi, and J. Chambers, “Fall detection in the 
elderly by head tracking,” in Proc. IEEE Workshop on Statistical 
Signal Processing, pp. 357-360, 2009. 
[44] R. Cucchiara, C. Grana, M. Piccardi, A. Prati, and S. Sirotti, 
“Improving shadow suppression in moving object detection with 
HSV color information,” in Proc. IEEE Int’l Conf. Intelligent 
Transportation Systems, pp. 334-339, Aug. 2001. 
[45] A. Hanbury, “A 3D-Polar coordinate colour representation well 
adapted to image analysis” Scandinavian Conf. on Image Analysis, 
pp. 804-811, 2003. 
[46] M. Kampel, H. Wildenauer, P. Blauensteiner, and A. Hanbury, 
“Improved motion segmetation based on shadow detection,” 
Electronic Letters on Computer Vision and Image Analy., vo. 6, 
pp. 1-12, 2007. 
[47] A. Hanbury, “Constructing cylindrical coordinate colour spaces,” 
Pattern Recognition Letters, vol. 29, pp. 494-500, 2008. 
[48] K. V. Mardia, Statistics of Directional Data, Academic Press, 
London UK, 1972. 
[49] C. Rougier, J. Meunier, A. St-Arnaud, and J. Rousseau, “Fall 
detection from human shape and motion history using video sur-
veillance,” in Proc. IEEE Int’l Conf. Advanced Information Net-
working and Appl., pp. 875-880, 2007. 
[50] 蒲秀瑾, “老年人跌倒的流行病學和危險因子的評估和預防,” 
台灣老年醫學會會訊, vol. 51, pp. 10-14, 2003. 
[51] 陳孟儀 , “老人跌倒之照護 ,” 行政院衛生署立南投醫院 : 
http://www. nant.doh.gov.tw/. 
[52] N. Noury, A. Fleury, P. Rumeau, A.K. burke, G. Laighin, V. 
Rialle, and J.E. Lundy, “Fall detection – principles and methods,” 
in Proc. IEEE Inter’l Conf. on Engineering in Med. and Bio, pp. 
1663-1666, 2007. 
[53] R.J. Gurley N. Lum, M. Sande, B. and Lo, “Persons found in their 
homes helpless or dead,” New England Journal of Medicine, vol. 
334, pp. 1710-1716, 1996. 
[54] T. J. Petelenz, S. C. Peterson, and S. C. Jacobsen, “Elderly fall 
monitoring method and device,” U.S. Patent 6433690, Aug. 13, 
2002. 
[55] M. Popescu, Y. Li, M. Skubic, and M. Rantz, “An acoustic fall 
detector system that uses sound height information to reduce the 
false alarm rate,” in Proc. IEEE Inter’l Conf. on Engineering in 
Med. and Bio., pp. 4628-4631, 2008. 
[56] M. Lan, A. Nahapetian, A. Vahdatpour, L. Au, W. Kaiser, and M. 
Sarrafzadeh, “SmartFall：An automatic fall detection system 
based on subsequence matching for the SmartCane,” in Proc. In-
ter’l Conf. on Body Area Networks, 2009. 
[57] Y. Depeursinge, “Device for monitoring the activity of a person 
and/or detecting a fall,” U.S. Patent 6201476, Mar. 13, 2001. 
[58] T. Zhang, J. Wang, P. Liu, and J. Hou, “Fall detection by embed-
ding an accelerometer in cellphone and using KFD algorithm,” 
Inter’l Journal of Computer Sci. and Network Security, vol. 6, pp. 
277-284, 2006. 
二、 與會心得 
今年 ISSN2010 共收到 591 篇投稿論文，來自 40 個以上之國家及地
區，經審核後，共接受 170 篇論文並刊載於論文集中，論文集分成兩冊。 
PartⅠ內容含四個領域： 
(1) Neurophysiologic foundation 
(2) Theory and models 
(3) Learning and inference 
(4) Neurodynamics 
 
PartⅡ涵蓋五個領域： 
(1) SVM and Kernel methods 
(2) Vision and image 
(3) Data mining and text analysis 
(4) BCI and brain imaging 
(5) Application 
 
此次會議由上海交通大學籌備，並與香港中文大學共同主辦，協辦
單位為中國國家自然科學協會。 
 
此次參加研討會，於歷程中有如下心得： 
(一) 大陸學術研究風頗盛 
本人藉著此次機會參觀了上海復旦大學，發現復旦大學校園優雅，
教室非常整潔，且教授大都已使用數位媒體授課，學生讀書風氣頗佳，
總而言之，復旦大學具備優良之教學及研究環境。 
國科會補助計畫衍生研發成果推廣資料表
日期:2010/12/06
國科會補助計畫
計畫名稱: 子計畫四：智慧型家用機器人輔助系統之設計與研究
計畫主持人: 洪欽銘
計畫編號: 96-2628-E-003-016-MY3 學門領域: 智慧型照護系統
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
