中文摘要 
這份研究提出的一個針對錄影資料的多身體部位受照顧者追蹤系統，首先我們利用高斯背
景模型偵測受照顧者在錄影資料中的位置，接著我們用外觀當作特徵並用粒子濾波器當作
追蹤核心來追蹤受照顧者，我們採用等化的顏色分部圖作為外觀的表示方式來強化不同物
體之間的鑑別率，因為受照顧者不是剛體，他的外觀可能會因為動作而有很大的改變，我
們將其外觀分成三個部位(頭、軀幹、臀腳)並利用粒子濾波器來追蹤，為了減少動作造成
的追蹤錯誤，我們會檢查這三個部位的狀態變化的同步性，當這些狀態經過 particle 
filter 校正後，我們利用 supprot vector machie (SVM)來偵測是否有追蹤錯誤發生並檢
查是哪一個身體部位，假如偵測出來只有一個身體部位是錯誤的，我們會校正錯誤部位的
位置，並利用系統變化模型來追蹤這個錯誤的部位，假如有兩個或三個部位出錯，我們會
以預估的位置附近重新偵測並追蹤那三個身體部位，根據測試 22 段錄影資料的實驗結果顯
示，我們的三部位錯誤偵測及校正系統有約 93%的實驗資料可以持續追蹤 100 張連續影像
中的人，而考慮人體部位追蹤，我們的系統對於持續追蹤頭、軀幹、臀腳三個部位 100 張
連續影像分別有約 91%、83%、95%的正確率，相較於將人體視為一個單一區塊來追蹤，提
升了大約 10%的正確率，這個結果顯示我們的系統是相當有效的。 
 
中文關鍵詞：人體追蹤、粒子瀘波、錄影監控 
Abstract 
The study presents a multi-part care-receiver tracking system in video sequences. First, we 
detected care-receivers in a video according to a Gaussian background model. We then tracked 
the care-receivers by using their appearances as the features and using particle filters as the 
tracking kernel. To model the appearances, we adopted equalized color histograms to enhance the 
discriminability between different objects. Since a care-receiver is not a rigid object, his 
appearance might be greatly affected by his motion. We decomposed his body into three parts: 
head, torso, and hip-leg, and tracked the three parts by particle filters to reduce possible failures 
due to appearance changes by checking the consistency of states among these three parts. After 
the tracking states are corrected, we used support vector machines (SVM) to detect tracking 
failures and abnormal body parts. If a single part was abnormal, we adjusted its position and used 
the system dynamic model to track the abnormal one. If two or three parts were abnormal, we 
re-initialized the tracking process of the three parts around their predicted positions. By testing on 
22 video clips, the experimental results showed that our three-part tracking system with failure 
detection and correction can track correctly about 93% persons until the 100th frame. With 
respect to the body parts, our system has about 91%, 83%, and 95% tracking rates for head, torso, 
and hip-leg respectively until the 100th frame. The tracking rate is increased 10% comparing with 
the method that tracks the whole body. These rates show the effective of the proposed system. 
 
Keywords: Human Tracking, particle filter, video surveillance, support vector machine. 
 
figure-ground segmentation and the predicted state is calculated using the system dynamic model. 
To find the temporal correspondences, Polat et al. [17] used MHT (Multiple Hypothesis Tracker) 
to construct hypotheses representing all the predictions and measurements. The most likely 
hypothesis is chosen as the target. To combine the predictions and measurements, Kalman 
filtering is another well-known method and has already been applied in many studies [6], [18], 
[19]. The Kalman-filter-based approaches are commonly used for tracking a target whose system 
dynamic model can be represented as a linear function and the noise as a Gaussian. In non-linear 
systems, extended Kalman filters that approximate the non-linear dynamic model by Taylor 
series have been applied [20]. Recently, particle filters are proposed to construct a robust tracking 
framework that are neither limited to linear dynamic model nor Gaussian distributed noises [13], 
[21], [22]. The method represents the state of a target object by a set of samples (particles) with 
weights. The weight of a sample is calculated by the figure-ground segmentation and the samples 
are generated by the importance sampling method so that the samples can represent the 
probability distributions of the target object’s appearances. We adopt the particle filter in our 
system, since they can be applied in an appearance-based tracking system very effectively.  
A human is not a rigid object and his appearances are changed irregularly. Segmentation of 
human body parts in an image has already been proposed in several papers [23], [24], [25], [26]. 
Forsyth and Fleck [23] introduced the notion of ‘body plans’ to represent a human or an animal 
as a structured assembly of body parts learnt from images. Shashua et al. [24] divided a human 
body into nine regions, for each of which a classifier was learnt based on features of orientation 
histograms. Mikolajczyk et al. [25] divided a human body into seven parts. For each part, a 
detector was learnt by following the Viola-Jones approach applied to scale invariant 
orientation-based features. Ioffe and Forsyth [26] decomposed the human body into nine 
distinctive segments. The method finds a person by constructing assemblies of body segments. 
The segments were consistent with the constraints on the appearance of a person that result from 
kinematic properties. These body-parts-based human segmentation usually focused on detecting 
humans in a static image. Recently, body-parts-based human tracking in consecutive images has 
been proposed [10], [11], [27], [28], [29], [30]. Parts of these studies focused on precise 
decomposition of body parts for motion type or pose analysis. However, in general environments, 
it is difficult to decompose precisely body parts due to self occlusions and complex background 
scenes. The studies in [10], [30] proposed a detection-based tracking model to solve the occlusion 
problem. They detected body parts by a pretrained model, and then tried to associate the detected 
body parts to a target person by smoothing his trajectory. However, when multiple humans 
appeared in a frame, the detection model could not differentiate the body parts of the different 
persons. The spatial positions and moving speed were the only cues, which can be used to find 
the temporal correspondences of different persons. 
When a person is tracked in consecutive frames, the figure-ground segmentation may be 
failed, since the person may be occluded or other objects may have similar appearances with the 
target person. The first problem can be classified into occluded by other persons and occluded by 
background objects. To cope with the problem of inter-person occlusion, several researchers 
proposed to detect occlusion events and then used the system dynamics to estimate the position of 
the occluded person [31], [32]. Using similar methods to predict the occlusion of background 
objects, one needs to create background object models. However, it is difficult to model all 
decompose simply the body into head, torso, and hip-leg, since the three parts usually have 
different appearances and can be distinguished as shown in Fig. 1. The images show that the 
colors of the head part contain mostly skin colors and hair colors, which are usually different 
from the colors of the other two parts. The colors of the torso and hip-leg parts consist mainly of 
those of the clothes, which may be similar, as shown in the fourth and fifth images of Fig. 1. To 
separate the three parts, we have to use other features such as height ratios. 
With respect to the features used, we adopt color histograms proposed by Perez et al. [14] and 
Nummiaro et al. [13] to model the appearances of the three body parts. In the initialization phase, 
we adopt the background subtraction method to extract a human and then extract the histograms 
of the body parts from the human region. In the tracking phase, we detect the person via the 
appearance model of the body parts and update the model from recent frames. Since the 
appearance model of each person in recent frames is usually unique and temporally 
context-dependent, the model can be used to distinguish different persons and track them 
independently. However, when modeling the color histogram in the whole color space, histogram 
matching is time-consuming due to the high dimensional features used. The method proposed by 
Nummiaro et al. [13] quantized the color histogram into a 8 x 8 x 8 or 8 x 8 x 4 three-dimensional 
one. The method proposed by Perez et al. [14] modeled colors in HSV color space by two 
histograms. The intensity channel is modeled as a histogram and the other two channels as 
another two-dimensional histogram. The histograms are quantized into several bins to improve 
the speed and reduce the effect of noises. However, in these models, two objects with very few 
dissimilarities are not easily distinguished. In our research, we will equalize the color histograms 
to improve the ability of discriminating the objects with similar color distributions. 
 
For failure detection and adjustment, we will use a support vector machine (SVM) [10], [33] 
to distinguish abnormally and normally tracked body parts. In the Dockstader and Imennov’s 
method, they did not mention how to adjust the tacking failures. The position of an abnormal 
body part will be adjusted according to its relative positions with the other body parts. Next, we 
detect whether the failure is caused by occlusion or similar appearances. For the latter case, we 
will estimate the appearance model from the adjusted rectangle of the body parts; else, the 
appearance model is kept unmodified.  
The flow diagram of our tracking system is depicted in Fig. 2. It includes four major modules: 
initialization, particle-filter-based tracking, abnormal body part detection, and state correction. 
Fig. 2. The system flow diagram of the three-part human tracker. 
Gaussian vector. In this study, we define formally the matrix A and vector W as: 




















∆
∆
=
100000
010000
001000
000100
00010
00001
t
t
A , (2) 
].),0(),0(),0(),0(),0(),0([ 222222
YXHWYX
NNNNNNW && σσσσσσ=  (3) 
In the noise vector W, the function N(0,σ2) represents a zero mean Gaussian with varianceσ2. 
The variances },,,,,{ 222222
YXHWYX &&
σσσσσσ  are set to {10, 10, 2, 2, 2, 2}, according to the 
experimental results. 
2.1.2 Particle Weighting 
In the correction process, we will convert the state of each particle into feature values. Then 
the feature values will be compared with those of the target object to calculate the similarity π 
between them as the weight of the particle. The weight that a particle in state ntS  is computed 
as: 
( ),|)( ntttn SXzp =⋅=ωπ  (4) 
where zt denotes the feature vector of a target at time t, and ω a normalization factor 
( )
,
|
1
1
∑
=
=
=
N
n
n
ttt SXzp
ω  (5) 
which ensures that 1
1
)( =∑
=
N
n
nπ . 
Each particle is composed of a state vector and a weight. The set of particles is defined as: 
}....1|,{ )()( NnSS nn == π  (6) 
According to these weights }{ )(nπ , the estimated state of the target object can be determined 
from the expectation of }{ )(nS  at each time step, that is, 
.)(
1
)()(∑
=
=
N
n
nn SSE π  (7) 
In Eq. 4, the weight of each particle is calculated from the conditional probability 
)|( nttt sXzp = . Assume that the feature vector zt forms a Gaussian distribution with a fixed 
covariance matrix Σ. The 
conditional probability can be formulated as 
( ) ( ) ( ) ,
2
1
exp2)|( 12
1
2 




 −Σ−−Σ== −
−− n
tt
Tn
tt
d
n
ttt zzzzSXzp π  (8) 
where ntz  is the feature vector extracted from the observation of the particle state 
n
tS . In this 
  
To represent the color histogram in several bins, another important task is how to map from a 
range of colors in the histogram to a bin. If the range is equally quantized for each bin and the 
histogram is compact, all pixels may fall into a small number of bins. In our cases, two different 
histograms cannot easily be distinguished. Fig. 3 shows two histograms of the Cr channel in the 
face region of a person and a background region, whose histograms are very different. When the 
ranges are equally divided into eight bins as shown in Fig. 4(a), the color distributions of the two 
regions will be very similar. To cope with the problem, we first choose one histogram H as the 
reference one for histogram equalization. The equalization can be denoted as z = M(H), where 
M(.) is a function that equalizes the reference histogram H into an equalized histogram z, which is 
represented as a vector. The function M(.) is then applied to another histogram H’ to form a 
feature vector z’ = M(H’). Based on the mapping, we can prevent the pixels from falling into the 
same bins for two slightly different color distributions. Fig. 4(b) shows the quantized bins of the 
face region and background regions by selecting the face region as a reference one. In the figure, 
we can easily find that the two quantized histograms are different, especially in the third bin. 
 
2.3 Feature Updating 
Since the target object is moving, its appearance may change gradually. To adapt to the 
changes, the feature values should be updated for each frame as defined by 
,1.09.01 ×+×= − ttt qpp  (11) 
Fig. 3. A sample image and the histogram of the Cr channel in the two rectangles (head and background). 
Fig. 4. The two histograms of the Cr channel in Fig. 3 quantized into eight bins. (a) Uniform mapping. (b) 
Equalized mapping. 
(a) (b) 
background is not always fixed, the background model needs to be updated to adapt to the 
background changes. The updating of the Gaussian model N(μt,Σt) of a pixel can be formulated 
as 
( ) ,11 ααµµ ⋅+−⋅= − ttt X  (13) 
( ) ( ) ( ),11 tt
T
tttt XX µµα −−+−⋅Σ=Σ −  (14) 
where α is used to control the updating rate. In our research, we assume that the background is 
less changed, and thus we setαas a small constant. 
Next, we extract the connected-components of foreground pixels as foreground regions. The 
connected-components smaller than a prespecified threshold are regarded as noises and removed. 
The extracted foreground regions may include shadows, other background objects being moved 
or due to illumination changes. A foreground region may also include more than one person. To 
extract the persons, we restrict the size of a human region by setting two thresholds, region size 
Tfg and width to height aspect ratio Twh. If a foreground region does not satisfy the criteria, we 
will separate the foreground region into two sub-regions by finding the lowest valley in the 
vertical projection profile. After the separation, if the aspect ratio of a sub-region is still larger 
than Twh, the separation rule will be performed recursively until all sub-regions satisfy the 
criterion of aspect ratio. Note that the region of a person may touch with small misclassified 
background regions, such as shadows. Since we do not use the whole image of the person for 
tracking, the small misclassified background region will not affect greatly the tracking 
performance. Even though a detected body part of the person belongs completely to a 
misclassified background region, the part can also be adjusted by using the other two parts during 
the process of tracking failure adjustment described in Sec 3.4. 
 
3.2 Human Part Decomposition 
Since the three body parts are used to track a person, their appearances should not be 
confused with each other. In this study, we aim to separate the three parts with a high 
distinguishability. The distinguishability can be defined as the difference between the color 
histograms of two regions. Since the difference measurement of color distributions used for our 
particle filter as depicted in Sec. 2.2 is costly, we will compute and compare the mean colors of 
the three parts instead. 
We assume that the size ratio of the three body parts of most people are similar. As shown in 
Fig. 6(a), we first locate two horizontal lines to separate the region of a person into three sections 
according to the predefined height ratio of the three parts, denote as Hh, Ht, and Hl. Then we 
move the two separation lines vertically to find the positions such that the three regions have the 
highest differences in the mean colors. The foreground human region is accordingly separated by 
the two horizontal lines into three sections Rh, Rt, and Rl. As described above, the segmented 
foreground regions may include background regions or noises. Besides, the shapes of the three 
parts for different persons and different poses are varied. To achieve a higher reliability of the 
tracked parts, we will shrink the segmented regions according to the spatial distribution of the 
pixels in the three sections. A section R is shrunk into a smaller rectangle, called inner rectangle 
hereafter, as the pixel set {(x, y) | Cx - Sx < x < Cx + Sx, Cy - Sy < y < Cy + Sy, (x, y) ∈R}, where (Cx, 
Cy) is the center of the rectangle and (Sx, Sy) the covered range of the rectangle. They are defined 
hyperplane is computed as follows: 
)),(sgn()( xgxf =  (19) 
where 
,),()(
*
1








+= ∑
=
∗ bxxKayxg
l
i
iii  (20) 
Here, we select the radial basis function as the kernel function K to map the feature vectors 
into the higher dimensional space. The class label yi∈{-1,1} denotes whether the feature vector 
∗
ix  belongs to tracking failure or not. The set {
∗
ix  | 1≤ i ≤
∗l } is a subset of the training data set, 
called support vectors. The coefficients ai and b are determined by solving a large-scale quadratic 
programming problem. 
To detect which part is failed to be tracked, we design three SVMs for detecting the tracking 
failures of the three body parts. If two or three parts are failed, the SVM failure detector for 
different body parts may become ineffective, since we cannot easily distinguish which part is 
abnormal by the relative positions. To cope with the problem, we design an additional SVM to 
determine whether the failure type is a single part failure or a multi-part failure.  
The features used in an SVM are the estimated states of the three parts in the current frame 
and the relative state changes between the current frame and a previous t frame. Here t is selected 
to make the state changes large enough (In our experiments, t=10). The feature vector is defined 
as [RSH(0), RST(0), RSL(0); RSH(0) - RSH(-t), RST(0) - RST(-t); RSL(0)-RSL(-t)]
T
 , where the vectors 
RSH(t), RST(t), and RSL(t) denote the relative state vectors of the three body parts in frame t (the 
frame zero denotes the current frame). The relative state vectors are defined as: 
( ) ( ) ( ) ( )
( )
),,,(          ,
3
,,
)(
LTHK
tS
tStRS
LTHI
I
KK =−=
∑
=
 (21) 
where SH(t), ST(t) and SL(t) are the estimated state vectors of head, torso and hip-leg parts. 
cope with the problem, we can manually label the background object that may occlude a person 
in a scene. This is reasonable for a scene monitored by a fixed sensor.  
The position of the tracking failure part can be adjusted according to the position of the other 
two parts. If the tracking failure part is the torso part as shown in Fig. 6(a), we adjust the center of 
the torso to the middle of the other two parts and the size to the average of the other parts as 
follows: 
2
},,,{},,,{
},,,{ LLLLHHHHTTTT
HWYXHWYX
HWYX
+
=  (22) 
Since the torso of a person is usually large enough, the adjusted rectangle usually lies inside the 
torso. Instead, the head of a person is usually smaller then the other two parts. Using similar 
adjustment method, its inner rectangle may contain background objects. We will use the 
background model to segment the foreground region above the torso part, and then extract the 
inner rectangle from the foreground region by the method described in Sec. 3.2. For the hip-leg 
part, its shape may have great variations. The adjustment method is similar to that of the head 
part, except that the foreground region is segmented below the torso part. 
In our tracker, the moving direction and speed of the particles will affect the predicted target 
in the next frame. If we set the same moving direction and speed to all particles, the particle filter 
may become insufficient to predict the state in the next frame. For a moving human, the moving 
direction and speed of the three body parts are assumed similar. We set the moving direction and 
moving speed as the union of the particles of other two parts. In other words, if the trackers of the 
other two parts have N1 and N2 particles, we will set the particle number of the tracking failure 
part as N1 + N2. All the particles have the same size {W, H} and position {X, Y}, but different 
moving vectors },{ YX && . The moving vectors are directly obtained from the particle of the other 
two parts. 
 
4. EXPERIMENTAL RESULTS 
The proposed approach has been implemented in a personal computer. The experiments were 
performed on 22 video clips with 72 target persons. The input images are color, whose size is 720 
x 480. The number of particles is set between 200 to 1000, which was automatically modified by 
using the entropy of particle weights. 
 
  
Figures 8(a-d) show the tracking accuracy curves of the three body parts and the whole body. 
Here we define that a correct tracking region contains less than 1/2 other objects and the target 
part can still be tracked in the following frames. The curves in the figure represent how long a 
person can be tracked continuously. In frame 105, for instance, the tracking rates with failure 
adjustment are 95%, 83%, 91%, and 95% for the three parts and the whole body respectively. 
Note that the result curves are not monotone decreasing, since the particle filter can adjust the 
target parts to the correct positions, and the numbers of frames that different persons walk in a 
scene are not the same. In our testing samples, twenty persons walk on a scene over 100 frames. 
Using our failure adjustment tracking, the whole body tracking rate until the 100th frame is 
improved about 10%. The tracking rates of head, torso, and hip-leg parts are improved about 29%, 
15%, and 31% respectively. The results show that the tracking failure adjustment can increase the 
accuracy and tracking lengths effectively. 
In our tracking system, we assume that the relative positions of body parts are fixed in a 
certain range. However, the assumption cannot be applied to track the body parts of a person 
when his posture is not trained, such as bending down. In this situation, we can still track the 
same target person, but not his body parts correctly. Since these parts belong to the same person, 
we can still track the target person when he stands up. 
In our failure adjustment, we use the background model to extract foreground regions. 
However, several false objects, such as shadow, may be regarded as foreground objects. Usually, 
the false detected foreground regions only affect the tracking results several frames. When the 
three tracked body parts are not located in the correct relative positions, the failure adjustment 
scheme will adjust the positions of the body parts. 
 
5. CONCLUSIONS 
(a) (b) 
(c) (d) 
Fig. 8. Tracking rates without and with failure detection. (a) head. (b) torso. (c) hip-leg. (d) whole body. 
[10] A. Mohan, C. Papageorgiou, T. Poggio, Example-based object detection in images by 
components, IEEE Trans. on Pattern Analysis and Machine Intelligence 23 (4) (2001) 349–361. 
[11] A. Micilotta, E. Ong, R. Bowden, Detection and tracking of humans by probabilistic body 
part assembly, in: British Machine Vision Conference, Vol. 1, Oxford, UK, 2005, pp. 14–20. 
[12] D. Comaniciu, V. Ramesh, P. Meer, Kernel-based object tracking, IEEE Trans. on Pattern 
Analysis and Machine Intelligence 25 (5) (2003) 564–577. 
[13] K. Nummiaro, E. Koller-Meier, L. V. Gool, An adaptive color-based particle filter, Image 
and Vision Computing 21 (1) (2003) 99–110. 
[14] P. Perez, C. Hue, J. Vermaak, M. Gangnet, Color-based probabilistic tracking, in: European 
Conference on Computer Vision, Vol. 1, Copenhagen, 2002, pp. 661–675. 
[15] L. Zhao, C. E. Thorpe, Stereo-and neural network-based pedestrian detection, IEEE Trans. 
on Intelligent Transportation Systems 1 (3) (2000) 148–154. 
[16] I. Haritaoglu, D. Harwood, L. S. Davis, W4: real-time surveillance of people and 
theiractivities, IEEE Trans. on Pattern Analysis and Machine Intelligence 22 (8) (2000) 809–830. 
[17] E. Polat, M. Yeasin, R. Sharma, Robust tracking of human body parts for collaborative 
human computer interaction, Computer Vision and Image Understanding 89 (1) (2003) 44–69. 
[18] C. R. Wren, A. Azarbayejani, T. Darrell, A. P. Pentland, Pfinder: real-time tracking of the 
human body, IEEE Trans. on Pattern Analysis and Machine Intelligence 19 (7) (1997) 780–785. 
[19] S. L. Dockstader, N. S. Imennov, Prediction for human motion tracking failures, IEEE Trans. 
on Image Processing 15 (2) (2006) 411–421. 
[20] Q. Zhoua, J. Aggarwal, Object tracking in an outdoor environment using fusion of features 
and cameras, Image and Vision Computing 24 (11) (2006) 1244–1255. 
[21] M. Isard, A. Blake, Condensation - conditional density propagation for visual tracking, Intl. 
Jour. of Computer Vision 29 (1) (1998) 5–28. 
[22] M. Arulampalam, S. Maskell, N. Gordon, T. Clapp, A tutorial on particle filters for online 
nonlinear/non-gaussian Bayesian tracking, IEEE Trans. on Signal Processing 50 (2) (2002) 
174–188. 
[23] D. Forsyth, M. Fleck, Body plans, in: IEEE Intl. Conf. on Computer Vision and Pattern 
Recognition, Puerto Rico, 1997, pp. 678–683. 
[24] A. Shashua, Y. Gdalyahu, G. Hayun, Pedestrian detection for driving assistance systems: 
single-frame classification and system level performance, in: Intelligent Vehicle Symposium, 
Parma, Italy, 2004, pp. 1–6. 
[25] K. Mikolajczyk, C. Schmid, A. Zisserman, Human detection based on a probabilistic 
assembly of robust part detectors, in: European Conference on Computer Vision, Prague, Czech 
Republic, 2004, pp. 69–82. 
[26] S. Ioffe, D. Forsyth, Probabilistic methods for finding people, Intl. Jour. of Computer Vision 
43 (1) (2001) 45–68. 
[27] C. Chang, R. Ansari, A. Khokhar, Efficient tracking of cyclic human motion by component 
motion, IEEE Signal Processing Letters 11 (12) (2004) 941–944. 
[28] T. Roberts, S. McKenna, I. Ricketts, Human pose estimation using learnt probabilistic region 
similarities and partial configurations, in: European Conference on Computer Vision, Prague, 
Czech Republic, 2004, pp. 291–303. 
[29] D. Ramanan, D. A. Forsyth, A. Zisserman, Strike a pose: Tracking people by finding 
