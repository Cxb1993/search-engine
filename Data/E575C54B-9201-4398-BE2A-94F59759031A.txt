motion details as well. 
The proposed representation method, through multi-
threading programming, can be applied to motion 
database segmentation and compression with high 
computational performance. When applying to real-time 
interactive applications (e.g. 3D games), the 
flexibility of memory usages can substantially 
increase. 
 
英文關鍵詞： character animation, motion capture, data 
compression, motion segmentation 
 
 2 
中文摘要 
在人物動畫合成中，動態捕捉技術已成為獲得擬真動作最直接也有效的方法。隨著與日俱增的動
作資料，如何有效的儲存與壓縮動作資料，變成了迫切需求之多媒體處理技術。目前之骨架動作壓縮
技術，雖然獲得不錯的壓縮比率。但是對於人物細微轉折等特性資料較難保存，近來提出較高壓縮倍
數的演算法，需利用到數值最佳化逼近目標函數以解碼，對於即時應用較不適用。 
本計畫在一年的時間，研發新的動作分段與壓縮技術。我們更進一步的利用動作資料中時間與空
間的相依性，並且更精準地分割重複性動作，以有效分類動作、提高壓縮率、減少近似動作造成之失
真率。並且達到超過即時運算速度需求的壓縮與解壓縮執行效率。 
除了針對單一動作資料串，本計畫並發展對於動作資料庫之壓縮技術以及利用多執行緒平行處理。
當用於即時互動應用中（如三維遊戲），可大幅增進記憶體的使用彈性，並且提升人物動作合成之擬真
與變化性。 
 
關鍵詞：人物角色動畫、動態捕捉、資料壓縮、動作分段 
 
 
 
Abstract 
In computer animation, motion capture has become the most straightforward and the most effective 
approach to acquire realistic motions. However, after more and more motion data are acquired, how to 
efficiently store or compress the motion data becomes an urgent issue. 
Recently, several compression methods are proposed for skeletal motions and are of significant 
compression ratios. Nevertheless, detailed transitions or distinct postures may not be preserved with their 
spline approximation. Besides, the methods with significantly high compression ratio use run-time 
optimization and are not adequate to current real-time applications. 
In the project, we develop a novel motion representation method in one year. We further utilize the 
spatial and temporal coherence to improve the efficiency of approximation. Besides, we also research on 
segmentation of short-term repetitive motions and motion comparisons. The proposed method automatically 
analyzes a large motion dataset to improve the compression ratios and preserve the motion details as well. 
The proposed representation method, through multi-threading programming, can be applied to motion 
database segmentation and compression with high computational performance. When applying to real-time 
interactive applications (e.g. 3D games), the flexibility of memory usages can substantially increase. 
 
Key words: character animation, motion capture, data compression, motion segmentation 
 
 
 4 
 
同年，G. Liu 與 L. McMillan 則針對個別動作資料串進行壓縮研究。相較於固定區間的小區段，Liu
等人利用 Barbic et al. 提出的 Probabilistic PCA 動作分段法[Barbic04]，將動作資料依動作型態分佈，分
為數個不定區間之區段。各個區段會先利用 PCA 降低維度，之後再找出關鍵畫格(keyframe)，並以 spline 
curves 內插取代多餘之資料。Liu 等人所的方法，對於不同動作壓縮率約在 10~60 倍左右。 
 
圖、G.Liu 等人利用 PPCA 將單一動作資料分段以進行壓縮[Liu06]. 
 
2008 年，Gu 等人則希望利用人類動作高反覆出現的特性，將人物動作分為多個區塊，並且將各區
塊類似的動作利用分群法分群。利用他們主要記錄各群組的主要動作片段，並且利用 Arithmetic coding 
的方式記錄動作片段與該群主要動作片段之間的差異。其方法壓縮倍數約在 20~50 倍之間。 
 
 
圖、Gu 等人利用多個肢體區塊與動作分群法，紀錄類似的人物動作。[Gu08] 
 
2009 年，M. Tournier 等人則更進一步，利用 Inverse Kinematics (IK)的概念，僅記錄人物動作的末
端控制點(End-effector)的動作，並且使用 Principal Geodesics Analysis (PGA)，將人物動作降至非線性的
低維度空間。為了避免與減少 IK 方法會出現的關節跳動的問題，此篇論文採用稱為 PGA-IK 的最佳化
方式，其變數為 PGA 的投影係數，目標函數包含 1.合成的動作 end-effector 必須逼近記錄的端點；2. 連
續兩個 frames 其 PGA 係數不可差距太多。利用此方法，可大幅度提高壓縮率，其提供的數據依動作
複雜度的不同為 18~182 倍，平均約 60~90 倍。 
 6 
研究方法 
The proposed motion representation can be divided into three phases: preprocessing, clip extraction, and 
clip approximation. After loading motion data files onto our system, we concatenate them as a long motion 
sequence. Character motions are composed of orientation and translation of the root and skeletal postures. For 
better analysis on repeated skeletal motion, the first step is to align the root orientation and translation. When 
aligning raw point set data, we apply Kovar and Gleicher’s method for y-orientation [Kovar 02] or B.Horn’s 
quaternion-based alignment. For hierarchical skeletal motion data, e.g. BVH (Biovision hierarchical data) 
files, we simply take the orientations and translations of the root joint. 
Our analysis showed that encoding the full root motion (Rx, Ry, Rz, Tx, Ty, Tz) sequences in PCA subspace 
is inefficient, where only one or even none of six principal components can be omitted. Since most of root 
movements result from locomotion, in most cases, we only align the major y orientation and x, y, z translation 
(Ry, Tx, Ty, Tz). For motions with large Rx, Rz variations, such as somersault and breakdance, we align all the 
six degrees of freedom. These root alignment data are separately fitted by Catmull-Rom splines. The residual 
root and joint movements can then be represented by the following clip approximation. 
As suggested in [Arikan 06], compressing joints at a Euclidean coordinate is more linear and adequate to 
PCA. We also transfer hierarchical joint angles to position space through virtual markers. As shown in the Fig. 
1, the virtual marker set of a joint in [Arikan06] are a, b, c, but the markers a, b and its child marker a’ are 
collinear along the bone vector. We can use only one additional marker c with original joint position a and a’ 
to reconstruct the joint angles. These two virtual marker configurations result in an identical PCA subspace 
when we normalize the vector aa’, but using one fewer virtual markers per joint can spare one-third of storage 
for principal component axes. For joint without sufficient bone length, we still allocate marker b. 
(a) (b) 
Fig.1 Representing joint angles through virtual markers. (a)The virtual marker set in [Arikan06]. (b)The 
compact virtual marker set. 
 
The second phase is to extract the compression unit blocks, called clips. As the conceptual diagram Fig.2, 
the aligned motion sequence is first divided into several behavior groups. For each group, we apply 
frame-based PCA to lower the dimension, e.g. from DOFs of 73 positions to 5 to 15 principal components. 
Repeated motion analysis (RMA) is then applied to these more compact data and further divides a behavior 
group into three types of clips. The first type is primary clip, including the most influential motions, and is 
referred by a set of repeated clips. The second type is repeated clip, including motions similar to those in the 
referred primary clip. The third type is unique clip where no repetition can be extracted. 
After the PCA dimensional reduction, our motion data become a set of time-varying projected 
coefficients along PC axes. Variation of each coefficient can be regarded as a coefficient trajectory. Hence, the 
 8 
 
Fig. 4. The flow charts of the proposed motion representation method. (Left) the encoding process; (right) 
the decoding process. 
 
成果與結果 
The first experiment compared the proposed method with clip PCA method [Arikan06] for a motion 
capture data set with 31 joints in 120fps. The BVH data set including sporting, dancing, walking and running 
motion, are transformed from subject no.6, 15, 16, 17, 35, 94 and 135 of CMU motion capture database. 
Compression methods are applied to data of each subject, respectively. Besides, because the compared method 
used a fixed clip length, we padded unfilled clips with their last postures.  
The original data in 32-bit floating-point numbers are about 130.9MB. We set the clip length of clip PCA 
method as 200ms and 95% of variances were covered by valid PC axes. The proposed methods with 95% 
variance and 98% variance PC subspace were also performed. The upper-bound of control point amount per 
trajectory (PC axis) in spline approximation was set identical to these methods. 
As the result shown in Table 1, the proposed method with 95% PC variance reaches a 108:1 compression 
ratio with comparable accuracy. The spare space can be used for more accurate PC space like PCA space of 
98% variance. 
 
We compare the proposed method (with major PCs of 95% variances), clip-PCA method [Arikan06] with 
the reconstructed data of PGA-IK [Tournier09]. The five original motion data are also from CMU motion 
database. As the result in Table 2, PGA-IK method get benefits from run-time optimization and can have  
TABLE 1 
THE COMPARISON OF THE PROPOSED METHOD WITH CLIP-PCA METHOD FOR A 120HZ MOCAP DATA SET 
Method 
PC  
variance 
Avg. joint 
error 
Compression 
ratio 
Encoding 
fps 
Decoding 
fps 
Avg. valid PC 
axes 
Avg. quant. bits 
(Primary/Repeat) 
Clip % 
(Pri/Uni/Rep) 
proposed 98% 1.60 cm 88.7 : 1 372.4 4286.8 12.56 6.44/ 4.89 24%/8%/68% 
proposed 95% 2.39 cm 108.4 : 1 425.1 4383.2 8.41 6.68/ 5.18 25%/8%/67% 
Clip-PCA 95% 2.32 cm 39.8 : 1 530.5 4902.3 20.33 16 ─ 
The target data set is a subset of CMU mocap database (subject: 6, 15, 16, 17, 35, 94 and 135), where 31 joints are recorded; the frame amount (with padded 
postures to fit clip length in [Arikan06]) is 341472; the original binary data in 32-bit floating point number is 130.9MB. 
 10 
compression gains with comparable accuracy. With the feature-aware motion clipping and curve fitting, the 
proposed method can grasp both intensive and gradual motions. 
We also performed experiments and user evaluation to compare the proposed method with two 
state-of-the-art methods. The results demonstrate that the proposed method can simultaneously achieve a 
significant compression ratio and high computational efficiency. Besides motion compression, the clip 
segmentation, parameters and reference indices extracted by the proposed method, inherently provide 
adequate notations for further progressive motion representation, motion data classification, retrieval or 
editing. We believe the proposed repetition analysis, and adaptive data fitting can also be applied to other 
multimedia applications. 
 2 
 Computer aided geometric design 
 Integration of CAD/CAE/CAM 
 Computer aided IC design 
 Reverse engineering 
 EDA: electronic design automation 
而除此之外，會議也邀請到了多位國際知名學者發表其於 Geometric modeling， illumination 
simulation 以及 Large-Scale Repository 等方面之研究成果，並提供和各個國家的學者交流討論的機
會。 
 
二、與會心得 
本次 CAD/Graphics 的接受論文以 Animation 和 Modeling 相關為大宗，Huajun Liu，Fazhi He 和
Xiantao Cai 等人以 window-based principal component analysis 分解並生成人體動作，可以和我們研
究相結合，Wenshan Fan，Bin Wang 等人則是引入 Parallel Spatial Hashing 的概念來處理 Collision 
Detection的問題，可以有效率的利用GPU計算節省時間。除此之外，Shengfeng He等人以及ZhaoHui 
Wu 等人也分別在煙霧及火焰的模擬中提出了新的進展。 
除此之外，由於投稿論文以學生研究為主，會議中也有許多特別有趣的論文。像是 Xinjie Zhang
和 Jinhui Yu 生成代表各種表情的中國京劇臉譜，Shiguang Liu 和 Jingting Wu 則以 patch-based 的方
式拼貼出各種不同的京劇臉譜。Ning Wang和BaoGang Hu將 3維的模型轉成 2維的鉛筆風格繪畫，
Chuan Niu，Fan Zhong 等人則是將 Panorama 技術用在隧道上，將隧道探勘的影片轉換成可自由移
動的全景影片，對於隧道維修或緊急救援等需要寬廣視野的應用時有很大的幫助。 
相較於往年，今年的 CAD/Graphics 在比重上更偏重於各種圖學相關技術和人機互動的應用，而
不僅是傳統的 CAD/CAE 相關研究，此和近年來國際各大主流期刊的論文分布相同，可見結合使用
者經驗的研究是未來幾年的趨勢。 
本人的報告被安排在會議的第一天下午第二位，台下座無虛席包含了大會 Program Chair Ralph 
Martin 教授。報告內容以本研究的子計畫 ”Lattice-based Skinning and Deformation for Real-time 
Skeleton-driven Animation” 為主。報告後也引起了台下不少的迴響，直到之後的晚宴也還陸續有大
陸學生與本人交流報告的內容，也與當日的主席討論了兩岸研究生的差別，以及中國大陸對山東
高科技園區(高新區)近年來的重點扶持。此外，由於身為全場唯一的台灣學生，用餐時間也和來自
成都青島等地的教授暢談兩岸在學術和政治上的差異。大會的最後一天有安排山東的景點參訪，
也和同行的 Ralph Martin 教授以及當地學生洽談甚歡。整體而言本人這次出席 CAD/Graphics 2011
會議相當有收穫。 
 
三、考察參觀活動(無是項活動者略) 
略。 
國科會補助計畫衍生研發成果推廣資料表
日期:2011/12/04
國科會補助計畫
計畫名稱: 電腦動畫中高效率骨架動作壓縮技術之研究
計畫主持人: 林奕成
計畫編號: 99-2221-E-009-136- 學門領域: 計算機圖學
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
