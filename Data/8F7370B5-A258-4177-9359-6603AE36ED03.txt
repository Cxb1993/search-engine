先做一體質的區分，然後針對不同體質提供需不需用藥、或用何種藥物、用多少
劑量的建議，如此將大幅降低健保體系不當的花費，當然也可將不適合治療造成
患者不當副作用的可能性降至最低。我們可以從不同的角度，看出此計劃的重要
性。 
1. 關聯性分析估計個體對病症的致病率，早期發現可以早期針對適當用
藥。我們也可以關聯性分析來做適當的治療與用藥，如此可以減少不必
要的開銷，也可以減少病人對在治療過程中的不適。這樣一來，我們可
以更有效的運用經費在適當的患者上，以達到個人化用藥、個人化醫療
的理想。 
2. 關聯性分析成功與否的關鍵在於資料维度的適當降低。自機器學習的研
究領域逐漸在近來受到重視的同時，許多與維度降低技術的理論與演算
法相對在短時間內被提出，譬如PCA，LLE等。如果能結合相關新興研
究，可以在困難的關聯性分析的工作上找到關鍵性突破的方法。進一步
來說，維度降低技術等的研究也可以嘗試拓廣在其它相關領域上。 
 
三、文獻探討 
I. 基因型的確立／SNP的檢出及相關研究 
在人類基因組（human genome）中，SNPs是研究 DNA序列變異（DNA 
sequence variation）最為充足的資料 [2][3]。而單一一個 SNP是在 DNA上的
某個位址(site)，但它會隨著不同的人而有或多或少的變化，此外也會一代傅
給一代。在最近幾年，SNPs已經達到足夠的普及而且也被做為複雜基因試驗
研究之遺傳標記(genetic marker) [4][5]。根據理論的模型，若研究一群個體的
基因型（genotype）伴隨著一共同的疾病，而有另一群並未帶有這疾病，而
某些基因型將可能與患有此病症的個體有所關聯 [5]。 
而目前檢測 SNP的方法有許多種，可是能夠有高産出（throughput）、高
效率、且低成本的方法有如下幾種方式 [6]： 
1. PCR-Free genotyping 
由於此類做法需要大量雜交的 DNA（genomic DNA），可能和高産出的
理想仍有斷差距。儘管此法方改進了 DNA的需求，它仍然可能比原本
PCR-based的方法，需要更多的 DNA. 
2. Single-step homogeneous 
此方法是擁有最高産出的方法之一。然而 multiplex assays目前是不可行
的，因為要從重疊的頻譜中區別出信號有相當的困難性。 
3. Homogeneous detection with florescence polarization 
相較於前者，此方法需要更多複雜的步驟。然而，對於實驗室的需求而
言，它仍然是合理的選擇。 
4. Pyrosequencing 
在 DNA合成（DNA synthesis）其間，Pyrosequencing [8][9] 利用一連串
且應用最小描述度（minimum description length）的概念做為判斷不
同區塊分割優劣依據。由於在不同人種所得到的 SNP或有所不同，
因此所找尋到的區塊也會不一樣。在演算的同時，應注意樣本獲取
的範圍。 
2. 連鎖組重建 
針對一區域，需要依據定序或 FP等技術得來的雙套體資料重建該
區域的單套體基因連鎖組。重要的基因連鎖組分析有以下幾種方
式：Clark提出吝嗇演算法（parsimony）[17]，此法的缺陷在於演算
法不一定可以找到開始運作的起始點，另外不同的演算法次序會得
到不同的結果，作者未提及如何在此缺陷下選取最適合的基因連鎖
組。Excoffier考慮單套體的出現頻率，利用 EM演算法計算出最大
genotype likelihood的單套體頻率，然後依照得到的單套體頻率估計
最可能的單套體給定方式（assignment）[18][19][20]。在此方法中，
單套體的頻率估計雙套體的產生機率需要 HWE（Hardy-Weinberg 
equilibrium）的假設。另外，[21] 依據貝氏理論做單套體頻率等的
相關估計來找出單套體的組合(即基因連鎖組) 
III. 關聯性分析 
目前已知人類的 DNA可能構成特定疾病，或者對藥物産生不同的反應。辨
別這些影響健康、疾病及治療的反應之遺傳因子，將是探索及研發下一代的藥物
之核心，例如：增進藥物對目標疾病的精確度及降低副作用的風險。而關聯性分
析可以提供基因變異和疾病之間的關係，不僅對於事後治療能提供有效的方式，
對於事前也能夠一定程度的預測，以早期控制預防其發生。 
關聯性分析可以分為兩大類[22]，一為以家族的方式(family-based)，另一為
以統計的方式(population based)。前者去識別親代的對偶基因(parental alleles)遺
傳給罹患疾病的子代，以及那些未遺傳給子代的。藉由這些未被遺傳的對偶基因
做為控制(control)，則可評估發生在特定對偶基因(allelic marker)的疾病之可能
性。而此方法主要是由 Falk及 Rubinstein提出[23]。而 Transmission Disequilibrium 
Tests[24][25][26]是目前最為常用的方法。此方法的缺點是捨棄了部份的基因型的
資訊，在預測真實的對偶基因關聯性(allelic association)上，造成其統計效果的喪
失。此外，此方法須要親代的基因型，然而一般致病年齡都較高，家庭成員資料
不易獲得，所以在研究上有其困難點。 
如果家族 (family-based)的方法是不可行時，選擇適當的對照 (control 
population)則變得更為重要，確使能有最佳的病例對照研究(case-control study)之
設計。理想上，此病症的對照樣本(control sample)應該能夠反應在人種及遺傳成
份上。由於此原因，用於一範圍的疾病關聯性分析之對照樣本可能變得不適當，
須要適當地與患病樣本相匹配。這樣的方式變得較難達成，且不同的對照物
(sample population)可能被用在不同的研究上。前瞻研究(prospective study)可以提
供較為強健的對照組，但要獲得足夠的樣本需要相當多的成本。另外，可以選擇
數個對照組，其反應此病症在不同結構中的結果。例如：年齡、種族等…。種族
的多樣性導致 population stratification，造成在關聯分析上有不同的表現。基因連
鎖組的演化歷史，將隨著不同的人種而有不同的變化。患病的族群，只發生在特
定的種族上，此時可能就要找尋適當的對照組來匹配。例如：肝病是影響國人建
度都比原本的空間維度來得小，而且特別的是在本質維度的空間中，資
料間的關係會比在原先的空間中彼此的關係來得更具有意義，譬如兩兩
資料間的距離，在降維後的空間中可以以簡單的歐式距離來計算，但是
在原本特徵空間中，這樣的計算卻會得到誤差。這些特性在突顯出 LLE 
和其它降維方式的不同點。另外像 PCA 等的降維方式大都基於資料可
以線性投影的假設，一般的情形，此種假設並不見得適用。在 LLE演算
法[34]，如表一。 
LLE ALGORITHM 
1. Compute the neighbors of each data point, Xi

 
2. Compute the weights Wij   that best reconstruct each data point Xi  
   from its neighbors, minimizing the cost in eq. (1) by constrained 
   linear fits. 
3. Compute the vectors Yi

 _best reconstructed by the weights Wij , 
   minimizing the quadratic form in eq. (2) by its bottom nonzero 
   eigenvectors. 
表一：LLE演算法 
 
4. ISOMAP 
於空間上，我們期許資料集會成為一個流形(manifold)，而當資料呈現在
高維空間上，我們無法直接觀察到這個流形，所以我們需要透過維度降
低的技術，將高維空間上的資料點映射到較低維度空間中，使我們能觀
察到這資料集的流形，並利用這個流形來進行各種的應用。因為流形是
最能描述資料本質的結構，故我們可以把最能表現這個流形的維度稱為
本質維度(intrinsic dimensionality)。 
ISOMAP[35]屬於流形學習(manifold learning)的一支，是一種非教導式的
學習方法，利非線性的方式對特徵集進行維度降低技術。它的目的在同
時保有局部(local)與全域(global)的不相似(dissimilar)性質下，透過MDS
（MultiDimensional Scaling）[36]將資料集投影到較低的維度空間中。於
新維度空間中，各資料點間有著如同原維度空間中的不相似性質，以及
適當地呈現資料集的本質。這樣的解說或許不太容易了解，我們舉個例
子來說。假如，今天我們想要對某個區域繪製一張地圖，這個地區中有
著許許多多的山地部落與平地村莊。不難想像這個是一個三維空間的結
構，亦為一個流形。一般我們會直接使用MDS來處理這樣的地圖繪製
問題，但倘若我們能得到的資訊，只有村民口述的各村莊部落間的步距，
而沒有任兩部落村莊間於地表線上的實際距離，那我們便無法精確的畫
出這個地圖。如此一來，ISOMAP便非常合適用來完成這個地圖。我們
將結合這個例子來輔助說明 ISOMAP，亦讓我們對 ISOMAP有更深的印
止新維度的增加。當然上述所求的 m就可以視為我們所要找的本質維度
(intrinsic dimensionality)。 
( )
2
minarg
Lyxpp
pDDEm −==          (3) 
( ) ( )( ){ }θthresholdpDDpDDpm
LyxLyx
<−−+−=
22
1min       (4) 
如地圖繪製之例，我們於第二部份得到了任兩部落村莊間的步距。接著
第三部份的目的便是把這任兩部落村莊間的步距關係真實的呈現在地圖
之上。另外，不難發現的此例的本質維度為 2。 
 
為了說明 ISOMAP的效能，我們來看圖二的例子。原本的資料分布於三
維的空間中如圖二(B)，落在如圖二(A)中的瑞士捲曲面上。如果我們在
三維的空間上去分析資料，並不能正確地描述資料集的真正性質，譬如
紅色和藍色的點應當擁有較遠的距離，但在這三維的空間中，這兩群點
集的歐式距離是很短的。如果我們能把這個瑞士捲曲面展開成一個平
面，也就是這個資料集的本質維度空間，而在這個平面上再去做類似的
分析，我們將可以判定藍色點集和紅色點集會擁有較大的（二維歐式）
距離，同時也達到降維的目的。圖二(C)為 LLE所產生的結果，此結果
達到了我們的期許，其將三維空間中曲面上的資料集展開到一個二維平
面上，並使紅色和藍色的點擁有較遠的距離。但相較於 LLE的結果，我
們更支持 ISOMAP所產出的結果，ISOMAP 的結果如圖二(D)，其不只
成功的將原三維空間中曲面上的資料集展開到一個二維平面上，並使整
個平面更適當地表達出資料集的本質。故在此我們亦將 ISOMAP視為降
維的關鍵技術，並在往後的實驗中，選出最合適的核心降維技術。 
 
圖二： (A)瑞士捲非線性的曲面，(B)假設資料集從(A)中的曲面中均勻來取樣(取
樣 1000個樣本)，(C)經 LLE處理過後的結果(k=10)，(D)經 ISOMAP處理過後的
結果(k=10)。 
特徵選取後的資料、原始資料與 ISOMAP 降維後的資料這三者之間的差異
性。 
由於資料筆數過少，並且沒有未知的資料，所以我們使用五次交互驗證
(five-fold cross-validation)來做預測。並且重複 20 次取其平均、標準差、最
佳結果來做比較(如表二)。 
由結果可以看出，重複 20次實驗下 ISOMAP 所萃取出的特徵雖比較能預測
出實驗的正確性。但也可以看出，我們的特徵選取方法可以在取少數的維度
下，在選取 30 維以上時，成效比在不降維的情形下好上許多。正確率雖然
不如 ISOMAP的結果，但以資料蒐集成本的角度來看，是值得去探討的。 
為了確認我們利用 ISOMAP 作特徵選取的方法的效果，所以將我們方法中
降維步驟中的 ISOMAP改為 PCA，利用 PCA將原始資料維度降至 10維，
再使用我們特徵選取的方法同樣取得 20、30、40、50 等維度。藉此當對照
組來說明利用 ISOMAP 作特徵選取是否恰當(如表三)。並且再與網路上的
SNPs特徵選取軟體 CHOISS做比較。 
同樣的，在選取 30維以上時，利用 ISOMAP所做的特徵選取的結果略優於
PCA的結果。 
CHOISS是個 SNPs特徵選取的軟體，我們將 26組 SNPs經過 CHOISS分別
選取 5、10、15、20等再將這些離散化資料轉為連續型，並結合年紀與性別，
所以總和共有 53、98、143、188等 attributes，最後再使用 SSVM做預測(如
表四)。由結果可以看出，利用此結果並沒有上述用 ISOMAP作特徵選取的
結果好。 
二、其他基準資料； 
我們選取名為 Ionosphere 的資料當作驗證我們方法的輔助資料。同樣的利
用 ISOMAP 將原始資料維度降維至 10 維，其中 ISOMAP 方法中的 kNN 的
k=5。再利用特徵選取分別去取 10、15、20、25。並使用十次交互驗證來做
預測，並且同樣與 PCA的特徵選取方法做比較。(如表五、表六)。 
 
根據上述實驗，我們得知此方法在特徵選取上有不錯的效果，假設我們資料
量很完整，預測的結果是可預期的。從資料蒐集成本的角度來看，也能節省不少
的成本開銷。 
表二 
Asthma 59x243 
Method Dim Training accuracy Testing accuracy 
  mean   std.   best mean   std.   best 
SSVM 242 83.31  .2017  100.0 67.64  .0390  76.36 
ISOMAP+SSVM 6 93.44  .0622  100.0 72.73  .0623  76.36 
FS+SSVM 20 76.23  .2025  100.0 65.45  .0289  72.73 
FS+SSVM 30 95.63  .0906  100.0 70.55  .0315  80.00 
FS+SSVM 40 96.48  .0860  100.0 69.46  .0293  76.36 
FS+SSVM 50 93.75  .1380  100.0 67.91  .0291  76.36 
 表六 
 
經過這些實驗，我們可以看出維度降低技術對於資料呈現及進一步資料分
類的成效。值得強調的是，關聯性分析上的表現型的標號通常來自於醫學上的相
關觀察與實驗。譬如用藥的有效與否一般或許區分為 A：有實際療效，B：無實
際療效，C：中斷實驗者等三類。但是這三類在機器學習上或許並不適當當作三
類的分類問題來處理。譬如所提 C 類的可能是諸多因素造成用藥療程的中斷。
如果是因為治療並不如預期有效，所以在早期的療程中即停止繼續用藥，如此說
來可能較類似 B 類。另一種情形也可能是因為藥物本身的價格昂貴，造成用藥
者無法負擔，如此就不能輕易的得到這些資料的類別了。這樣的資料，一般我們
傾向建議直接剔除。總結來說，依照我們非線性維度降低 ISOMAP 的技術，可
以成功找出單一核苷酸多型性和用藥性的表現型資料的關係，我們期待這樣的研
究成果可以進一步應用於其它資料的分析上，得到更一般性的結果。 
 
Ionosphere 351x34 
Method Dim Training accuracy Testing accuracy 
  mean   std.   best mean   std.   best 
FS(ISOMAP)+SSVM 
FS(PCA)+SSVM 
10 94.15  .0039  95.24 
95.74  .0026  96.12 
93.29  .0030  93.82 
93.56  .0040  94.41 
FS(ISOMAP)+SSVM 
FS(PCA)+SSVM 
15 96.37  .0127  100.0 
96.11  .0042  96.88 
94.59  .0035  95.29 
94.38  .0062  95.59 
FS(ISOMAP)+SSVM 
FS(PCA)+SSVM 
20 97.44  .0075  99.40 
97.18  .0099  99.43 
95.91  .0026  96.18 
94.50  .0043  95.29 
FS(ISOMAP)+SSVM 
FS(PCA)+SSVM 
25 98.39  .0020  98.55 
97.57  .0068  98.36 
96.15  .0049  96.77 
95.15  .0032  95.59 
 [14] Zhang, K., Calabrese, P., Nordborg, M., and Sun, F. (2002). “Haplotype block 
structure and its applications to association studies: power and study designs”, 
Am. J. Hum. Genet., 71: 1386—1394. 
 
[15] Koivisto, M., Perola, M., Varilo, T., Hennah, W., Ekelund, J., Lukk, M., Peltonen, 
L., Ukkonen, E. and Mannila, H. (2003). “An MDL method for finding 
haplotype blocks and for estimating the strength of haplotype block boundaries”, 
In Proceedings of the Pacific Symposium on Biocomputing (PSB), 8: 502—513. 
 
[16] Quinlan, J. R. (1998). “Miniboosting decision trees”, Journal of AI Research. 
 
[17] Clark, A. G. (1990). “Inference of haplotypes from PCR-amplified samples of 
diploid populations”, Mol Biol Evol, 7: 111—122. 
 
[18] Excoffier, L. and Slatkin, M. (1995). “Maximum-likelihood estimation of 
molecular haplotype frequencies in a diploid population”, Mol. Biol. Evol., 12: 
921—927. 
 
[19] Hawley, M. and Kidd, K. (1995). “HAPLO: a program using the EM algorithm 
to estimate the frequencies of multi-site haplotypes”, J. Hered, 86: 409—411. 
 
[20] Long, J. C., Williams, R. C. and Urbanek, M. (1995). “An E-M algorithm and 
testing strategy for multiple locus haplotypes”, Am. J. Hum. Genet., 56: 
799—810. 
 
[21] Stephens, M., Smith, N., and Donnelly, P. (2001). “A new statistical method for 
haplotype reconstruction from population data”, American Journal of Human 
Genetics, 68, 978–989. 
 
[22] Cardon LR, and Bell JI. (2001). ”Association Study designs for Complex 
Diseases”, Nature reviews Genetics, 2:91-99. 
 
[23] Falk, C. T. and Rubinstein, P. (1987). “Haplotype relative risks: an easy reliable 
way to construct a proper control sample for risk calculations”, Annals of human 
genetics, 51: 227–233. 
 
[24] Spielman, R. S., McGinnis, R. E. and Ewens, W. J. (1993). “Transmission test 
for linkage disequilibrium: the insulin gene region and insulin-dependent 
diabetes mellitus”, Annals of human genetics, 52: 506–516. 
 
[25] Spielman, R. S., McGinnis, R. E. and Ewens, W. J. (1994). “The 
transmission/disequilibrium test detects cosegregation and linkage”, Annals of 
human genetics, 54: 559–560. 
 
[26] Spielman, R. S. and Ewens, W. J. (1996). “The TDT and other family-basedtests 
for linkage disequilibrium and association”, Annals of human genetics, 59: 
983–989. 
 
[27] Alderborn A, Kristofferson A, and Hammerling U. (2000). “Determination of 
Review on the 14
th
 ACM SIGKDD International Conference on 
Knowledge Discovery & Data Mining 
(出席國際會議心得報告) 
 
會議地點： Las Vegas, USA 
會議日期： 2008 年 8 月 24 – 27 日 
參與人員： 台灣科技大學資工系鮑興國助理教授 
 
會議簡介 
KDD 為 data mining 和 machine learning 領域最知名的研討會之一，會議的內容主
要著重在 data mining 相關的理論與實務的最新發展，涵蓋下列幾項：data mining 
algorithms, data mining foundations, high performance and parallel/distributed data 
mining, innovative applications of data mining, data mining systems, KDD 
framework and process, mining data streams and sensor data, mining multi-media 
data, mining social networks and graph data, mining spatial and temporal data, mining 
text, Web and semi-structured data, pre-processing and post-processing in data mining, 
robust and scalable statistical methods, security, privacy, and adversarial data mining, 
visual data mining and data visualization。此次會議包含一天的 tutorial talks 和之後
兩天半的會議，一般的會議演講同時有四個同時進行的 sessions，另外每一天都
有一至兩場的 keynote speech。 
 
心得報告 
本年度計畫主題「利用維度降低技術運用於基因型表現型之關聯性分析」*，針
對關聯性分析做一維度降低技術的應用與探討。相關的研究於 data mining 和
machine learning 若干的理論與技術相關，也由於 KDD 歷來的盛名，選擇此次會
議的參與以提供相關研究第一手的資料。其中會議的 session 議題包含 topic 
modeling, data integration, social networks, text mining, statistical methods, graph 
mining, classification, rank and metric learning, clustering and distance function, 
streams and evolving data, active and semi-supervised learning, discovery and 
detection, pattern mining, feature selection, collaborative filtering and matrices, 
sequence data, prediction models, performance and scale, medical data mining, 
partially supervised learning, matrix methods, search and commerce 等幾項。本人參
加比較多及比較有趣的項目為 social networks, text mining, statistical methods, 
graph mining, rank and metric learning 等幾項。 
此外，在此次會議中認識諸位國際學者，如 CMU 的 Christos Faloutsos 和
                                                 
 
