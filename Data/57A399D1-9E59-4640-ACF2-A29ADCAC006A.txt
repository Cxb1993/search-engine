I 
目錄 
 
摘要............................................................................................................................... II 
一、前言 ......................................................................................................................1 
二、研究目的 ..............................................................................................................1 
三、文獻探討 ..............................................................................................................1 
四、研究方法 ..............................................................................................................3 
五、結果與討論 ..........................................................................................................3 
六、參考文獻 ..............................................................................................................5 
附錄 (已發表之論文，含國際期刊論文兩篇、國際會議論文三篇) .....................7 
[Journal Papers] 
1. W.-G. Teng* and W.-H. Cheng, "Exploiting Scheduling and Free-Riding for Offline 
Downloading in BitTorrent Networks," International Journal of Communication Systems, 
(In Press, Published Online: 20 February 2012, DOI: 10.1002/dac.2309). 
2. W.-G. Teng*, W.-H. Wen, and Y.-C. Liu, "From Experience to Expertise: Digesting 
Cumulative Information for Informational Web Search," Journal of Information Science and 
Engineering (Special Issue on Innovative Applications of Artificial Intelligence), 
28(1):161-176, January 2012. 
[Conference Papers] 
1. K.-L. Pang, K.-H. Chen, andW.-G. Teng, "Discovering Unusual Behavior Patterns from 
Motion Data," Proceedings of the 31st International Conference on Consumer Electronics, 
pages 244-245, Las Vegas, USA, January 11-14, 2013. 
2. K.-M. Lee, W.-G. Teng, J.-N. Wu, K.-M. Huang, Y.-H. Ko, and T.-W. Hou, "Multicast 
Deployment of Cloud Operating Systems," Proceedings of the 12th IEEE International 
Conference on Computer and Information Technology, pages 163-168, Chengdu, China, 
October 27-29, 2012. 
3. H. Wang and W.-G. Teng, "Associating and Recalling News Events with Visual 
Suggestions," Proceedings of the 7th International Conference on Digital Information 
Management, pages 196-200, Macau, China, August 22-24, 2012. 
 
1 
一、前言 
根據不同的使用者意圖，進行一次網頁
搜尋的動作可能在幾秒內便可完成亦或會持
續若干個小時，舉例來說，藉由網頁搜尋來
規劃一次自助旅行的行程便不是瞬間可完成
的事情。明確地而言，當使用者面對的是自
己所不熟悉的搜尋目標時，常常要耗費大量
的時間與精力來逐一閱覽並消化每一個搜尋
結果網頁，在此種「情報式網頁搜索」中，
我們發現到使用者是透過不斷累積片斷的資
訊線索來逐步瞭解其正在搜尋的目標。以另
一個例子而言，若使用者想瞭解「雲端運算」
的概念，他通常需要先了解「分散式計算」、
「Google App Engine」、「Amazon EC2」等詞
彙的意義，以幫助他達成目標，因此，所參
考網頁的質與量，便是讓一個使用者能否有
效率並確實瞭解所搜尋主題的重要因素。在
本研究計畫為期一年的執行時期中，我們建
構出人們在進行情報式網頁搜尋時的行為模
式，同時亦會藉由對使用者瀏覽歷程的分
析，來瞭解搜尋議題間的關聯性，最後透過
實驗研究來驗證本計畫所研發技術能夠有效
地幫助使用者來完成情報式網頁搜索。 
 
二、研究目的 
隨著近年來人機互動 (human-computer 
interaction, HCI) 技術的改進，搜尋引擎也變
得更簡單、友好，且更貼近一般人的生活，
使得找尋資料變得更加容易。從另一方面來
說，搜尋引擎透過關鍵字將資料取回，但是
理解資訊的意涵並進行判斷往往仍僅能由使
用者完成，電腦能幫助到我們的也僅是處理
大量且重複性的工作。因此，如何更有智慧
的讓搜尋引擎能取回貼近使用者想要的結
果、以及更有效率的搜尋方法，便是本研究
計畫想要探討的議題。 
本研究計畫的主要目的在於研究搜尋
引擎的發展迄今是否有不足之處，並希望能
發展新的觀念來幫助使用者更有效率的進行
網頁搜尋。具體而言，搜尋引擎最主要的用
處之一就是用以獲取相關訊息來取得對特定
知識的了解，傳統的網頁搜尋技術可於幾秒
內傳回成千上百個與搜尋關鍵字相關的頁
面，儘管如此，搜尋引擎對使用者本身卻產
生了一種矛盾，亦即在一次的搜尋過程中，
搜尋引擎可以幫助我們過濾掉 (表面上) 字
詞不相關的資訊，但卻無法根據內容語意篩
選出我們可能感興趣的資訊；因此在情報式
搜尋的情境中，由於使用者往往會進行連續
幾次相關的搜尋動作，也就意謂著使用者需
要花許多時間閱讀並理解中搜尋引擎所帶來
越來越多的資訊 [12]。舉例來說，若想要瞭
解誰是世界歷史上最具權威的帝王，當我們
使用搜尋引擎後，可能會看到我們熟悉的人
物，如漢武帝或拿破崙，但也有部分不太熟
悉的人物，如古斯塔夫二世或查理五世，想
要對這些不熟悉的人物加以了解並進行比
較，我們便需要更多次後續的搜尋動作。具
體而言，在情報式網頁搜尋的過程中，使用
者多半在一開始時對其搜尋目標不甚瞭解，
往往需要多次的搜尋才能達成原本設定的搜
尋目的，而隨著網路與文字文件不斷增長擴
張，若人們在情報檢索上必須花費越來越多
的時間，這並不符合人們對科技的期待，因
此本研究計畫期望能研發可結合或增進現有
搜尋引擎之模式，能識別使用者的搜尋意
圖，並預估在搜尋結果中個別頁面對使用者
的潛在價值，以協助使用者能更精確並省時
地閱讀關鍵的資訊。 
 
三、文獻探討 
網頁搜尋依使用者意圖可以分為三個
類 別 ： 領 航 式  (navigational) 、 事 務 式 
(transactional) 、與情報式  (informational) 
[3][5][9][15]。領航式網頁搜尋的目的是想要
經由搜尋引擎來達到使用者已知的網站，例
3 
性模式來回顧自己的瀏覽歷程。 
 
 
圖二：Pensieve 中的時間軸模式 (timeline 
mode)，可將瀏覽歷程以視覺化的方式呈現 
 
在較近期的研究中，個人化網頁搜尋 
(personalized search) 的概念也被許多學者
提出，希望能改善典型搜尋引擎的缺點。舉
例來說，如 Google 此一搜尋引擎所採用且廣
為人知的 PageRank 演算法 [13]，是建立於
隨機瀏覽模型上並利用鏈結分析  (link 
analysis) 的方法來評估每個網頁的重要
性，但使用者的意圖並未被此一方法所考
慮，因此 ClickRank [24] 提出了基於有意圖
的瀏覽模型之演算法，用以評估網頁的重要
性。整體而言，個人化網頁搜尋著重於在使
用者表達喜好或是由搜尋引擎預估使用者喜
好後，將搜尋結果重新排序或挑出部分使用
者可能較感興趣的搜尋結果予以呈現，如此
一來使用者可以將無關聯的資訊過濾掉，而
使得切中主題與自己需求的文章更加被彰
顯，但是即使如此，個人化網頁搜尋的技術
仍然並非從「理解使用者想法」此點出發，
並且僅考慮單一次搜尋期間 (search session) 
內如何將搜尋結果加以呈現的問題，因此無
法直接套用至本研究計畫之重點「情報式網
頁搜尋」上。 
 
四、研究方法 
針對本研究計畫的預期目標，為了讓使
用者能夠更快速有效率的完成情報式網頁搜
尋，我們認為應該從「理解使用者想法」做
為本研究計畫之核心，以使用者瀏覽歷程 
(browsing history) 中的蛛絲馬跡來分析使用
者的想法，進而推測並且提供使用者建議閱
讀何種文章最能幫助瞭解主題。在情報式網
頁搜尋中，使用者的行為通常可能有以下兩
種情境： 
(1) 使用者對未知目標感到興趣：舉例來
說，在某次的搜尋當中，某人在結果網頁中
看到一個並不熟稔的詞－雲端運算，並且對
其感到興趣，他可能為了瞭解這個新詞彙開
始另一次新的搜尋。 
(2) 使用者對於某些概念之間的關聯性感到
好奇：例如「雲端運算」與「資料探勘」的
關係，某個感興趣的使用者可能會進一步的
探索包含這兩個詞彙的網頁來瞭解它們之間
的關係。 
值得注意的是，隨著上述過程演進，使
用者的認知也會隨著看過的網頁累積而改
變。例如，在閱讀了一些相關的網頁後，使
用者逐漸地瞭解了「雲端運算」相關的概念，
因此原本不熟稔的詞就變得熟悉了。換句話
說，在更進一步的探索中，若某網頁的內容
是之前看過的概念，此網頁對使用者來說便
不那麼新鮮而感興趣了。在前人研究中提到
一種指標：新穎度 (novelty) [22]，是指某網
頁對使用者過去瞭解的事物相比之差異度有
多大，然而此一重要的指標在典型的搜尋引
擎中並未被考慮進去，因此我們在本研究計
畫中亦仔細考量了使用者對某一主題進行學
習認知的累進歷程。 
 
五、結果與討論 
在執行網頁搜尋的行為中，我們首先必
須對使用者如何吸收與學習網頁知識進行研
究與探討，並以此做為研究的基礎，才能進
行更深入的研究。此外，在研發適用於本研
究計畫之人機互動機制時，我們亦必須同時
5 
Interactive Interface
Data Collection POS TF-IDF
Relevance
DB
Google API Service: Web, Blogs and News
QueryQuery
1
2
3...
1
2
3...
1
2
3...
...
1
Data Mining
0
1
0
Immediacy of Interest
and Topic Map
R
E
Q
U
E
S
T
iSearch – An Informational Web Search System
Principal 
Keywords
 
圖四：本計劃所規劃之原型系統架構圖 
 
 
圖五：原型系統之展示畫面 
 
六、參考文獻 
[1] E. Agichtein, E. Brill, and S. Dumais, 
“Improving Web Search Ranking by 
Incorporating User Behavior Information,” 
Proceedings of the 29th Annual International 
ACM SIGIR Conference on Research and 
Development in Information Retrieval, pages 
19-26, August 2006. 
[2] M. Bates, “The Design of Browsing and 
Berrypicking Techniques for the Online Search 
Interface,” Online Review, 13(5):407-424, 
October 1989. 
[3] A. Broder, “A Taxonomy of Web Search,” SIGIR 
Forum, 36(2):3-10, June 2002. 
[4] Carrot2, http://search.carrot2.org/. 
[5] T.-W. Chen, P.-L. Chang, and W.-G. Teng, 
“Supporting Informational Web Search with 
Interactive Explorations,” Proceedings of the 4th 
IEEE International Conference on Signal-Image 
Technology and Internet-based Systems, pages 
153-160, November 2008. 
[6] W.-L. Chen and W.-G. Teng, “Exploiting 
Browsing History for Exploratory Search,” 
Proceedings of the 13th International Conference 
on Human-Computer Interaction, pages 355-364, 
July 2009. 
[7] S. Dziadosz and R. Chandrasekar, “Do 
Thumbnail Previews Help Users Make Better 
Relevance Decisions about Web Search 
Results?,” Proceedings of the 25th Annual 
International ACM SIGIR Conference on 
Research and Development in Information 
Retrieval, pages 365-366, August 2002. 
[8] Google AJAX APIs, 
http://code.google.com/apis/ajax/. 
[9] B. J. Jansen, D. L. Booth, and A. Spink, 
“Determining the Informational, Navigational, 
and Transactional Intent of Web Queries,” 
Information Processing and Management: an 
International Journal, 44(3):1251-1266, May 
2008. 
[10] B. J. Jansen, A. Spink, “How Are We Searching 
the World Wide Web? A Comparison of Nine 
Search Engine Transaction Logs,” Information 
Processing and Management: an International 
Journal 42(1):248–263, January 2006. 
[11] M. Levene and G. Loizou, “Web Interaction and 
the Navigation Problem in Hypertext,” 
Encyclopedia of Microcomputers, 28(7):381-398, 
January 2002. 
[12] G. Marchionini, “Exploratory Search: From 
Finding to Understanding,” Communications of 
the ACM, 49(4):41-46, April 2006. 
[13] L. Page, S. Brin, R. Motwani, and T. Winograd, 
“The PageRank Citation Ranking: Bringing 
Order to the Web,” Stanford University 
Technical Report, 1998. 
[14] P. Pirolli, “Information Foraging Theory: 
Adaptive Interaction with Information,” Oxford 
University Press, April 2007. 
[15] D. E. Rose and D. Levinson, “Understanding 
User Goals in Web Search,” Proceedings of the 
13th International Conference on World Wide 
Web, pages 13-19, May 2004. 
[16] G. Salton and C. Buckley, “Term-weighting 
Approaches in Automatic Text Retrieval,” 
INTERNATIONAL JOURNAL OF COMMUNICATION SYSTEMS
Int. J. Commun. Syst. (2012)
Published online in Wiley Online Library (wileyonlinelibrary.com). DOI: 10.1002/dac.2309
Exploiting scheduling and free-riding for offline downloading in
BitTorrent networks
Wei-Guang Teng*,† and Wei-Hao Cheng
Department of Engineering Science, National Cheng Kung University, Tainan, Taiwan
SUMMARY
Recently, the peer-to-peer (P2P) architecture has become a popular scheme for Internet users to rapidly
exchange files. As reported in previous studies, P2P traffic accounts for a significant portion of overall Inter-
net traffic. Many computing resources, for example, network bandwidth and disk space, may be consumed
by P2P clients. Accordingly, in this paper, we devise a novel scheme that integrates advantageous features
of both the conventional client–server and the P2P architectures to create an offline downloading service.
Specifically, the proposed service acts as an agent that downloads required files from the BitTorrent network
without consuming local computing resources. In other words, users can stay offline during the download
process. Because the proposed scheme aims to provide service to numerous users at the same time, a proper
scheduling technique is adopted to achieve better download performance. Moreover, a free-riding mecha-
nism is seamlessly incorporated with the proposed priority queuing to facilitate more effective bandwidth
utilization. Empirical studies show that our scheme is promising in practical applications. Copyright © 2012
John Wiley & Sons, Ltd.
Received 12 January 2011; Revised 30 September 2011; Accepted 11 December 2011
KEY WORDS: BitTorrent network; free-riding; peer-to-peer; task scheduling
1. INTRODUCTION
With the ever-increasing demand for Internet access, simple server–client architectures seem insuf-
ficient for handling unbearably limitless requests. This insufficiency is especially true for servers
that support file downloading; thus, a peer-to-peer file exchange can provide a proper alternative.
In a peer-to-peer (P2P) scheme, the end-user directly provides the information that he/she has, and
he/she receives resources from coequal peers on the network. According to a previous study [1], P2P
accounted for approximately 60% of all Internet traffic in the first half of 2004. By 2006, the propor-
tion of P2P traffic increased to 71%. This increase shows the significant potential of developments
in P2P technology.
Because sharing materials does not require a particular specification within the P2P structure,
diverse forms of content have increased substantially online. Thus, it is possible for a user to down-
load many files at the same time. Taking the well-known P2P software BitTorrent as an example,
it is reported that more than 85% of users simultaneously join multiple clusters of peers that share
various materials, and the average number of torrents that each peer joins during its lifetime is
7.514 [2, 3]. This statistic indicates the growing importance of handling several download tasks
concurrently in P2P environments.
A trivial approach for handling a number of download tasks is to work sequentially on a first-
come-first-served basis. If there are other tasks pending, or dependent tasks, they are served in the
order that the user assigns. Although this intuitive scheme operates in a straightforward fashion, it
*Correspondence to: W.-G Teng, Department of Engineering Science, National Cheng Kung University Tainan, Taiwan.
†E-mail: wgteng@mail.ncku.edu.tw
Copyright © 2012 John Wiley & Sons, Ltd.
EXPLOITING SCHEDULING AND FREE-RIDING IN BITTORRENT NETWORKS
In addition, because peers are supposed to ‘share’ what they possess, a Tit-for-Tat (TFT) policy
is employed to encourage users to upload their materials to others. With this policy adopted in the
process, a user ‘unchokes’ and transfers files preferentially to the four peers with the highest upload
rate to him, leaving others with fewer contributions with ‘chocked’ uploads. Hence, a user that
uploads data at a higher rate may be rewarded with the ability to download more requested pieces.
Nonetheless, this mechanism is somehow problematic because it would choke newcomers to the
swarm who have none of the pieces to share and naturally perform poor uploading. To compensate
for this circumstance, the optimistic unchoking (OU) policy requires that each user upload files to
one additional random peer who was originally choked.
In summary, according to the design specified above, for the singular task of downloading, a
user that uploads more and faster is likely to finish the task sooner. However, this is not the case
for a multitask process because other causes may also deteriorate the performance of a single
task regardless of how much one uploads and burden the whole process. Our aim is to prevent
these tasks from encumbering the entire process; hence, we propose a solution to this situation in
later sections.
2.2. Performance improvement in the BitTorrent network
Because BitTorrent has attracted significant research interests recently, many studies have attempted
to investigate aspects of aggregate user behavior and resource contention [6–8] in the BitTor-
rent network. Also, a number of prior works ave conducted analytical investigations to evaluate
the performance of content distribution using the BitTorrent protocol [9–11]. Furthermore, other
works focus on improving download performance by revising existing BitTorrent mechanisms or
proposing alternative ones.
In the common BitTorrent network, the allocated quotas for transferring connections for a torrent
are five per user, four statically for the TFT and one for the OU policy, as described in the preceding
subsection. Unfortunately, fixed quotas may not be satisfying to most peers in practice. The dynamic
quota-based peer selection strategy [12], which separates users into two groups by the principle of
investment return, is proposed as a solution. Upload quotas are allotted adaptively according to the
TFT and OU policies and the number of peers in each group.
The weighty piece selection strategy [13] based on local-rarest-first is also proposed. This strategy
assigns a weight to each missing fragment of a user according to the number of pieces downloaded
by neighboring peers who lack the same segment. Then, the weightiest piece would be requested
preferentially by these users. With the adoption of this strategy, those who have fewer file pieces
would tend to download more from those who have many file pieces but who lack the same pieces
and thus exchange more with them.
On the other hand, concerning the basic network structure, with a variety of Internet service
providers (ISPs) currently in the market, P2P file exchange also generates a remarkable amount
of cross-ISP traffic that usually is limited by bandwidth throttle and debases the quality of file
transfers [5]. The biased neighbor selection strategy [4] reduces such traffic. In this scheme, the user
chooses the majority of its neighbors to exchange data with from peers in the same ISP. However,
there are difficulties for this strategy to be practiced, and this strategy limits file sources.
Moreover, to ensure the availability of files to be downloaded, incentive TFT [14] prolongs the
lifetime of torrents by encouraging peers to deny requests from users near completion and exchange
data with users who have similar download progress. The strategies of quick bandwidth estimation
and pair-wise block-level TFT policy [15] are also introduced for unfairness compensation.
Aside from the leechers’ perspective, the proportional fair scheduling strategy [16] is pro-
posed for seeds to schedule file pieces to distribute on the basis of both previous scheduling
decisions and the actual distribution of content requests seen by the seed. The proportional
fair scheduling achieves fair and effective file distribution with scheduling adopted in a single
torrent session.
To summarize, the methods listed above could be readily combined with our work for better
performance because our approach helps handle multiple concurrent download tasks from a macro
aspect, without converting the policies within any single session.
Copyright © 2012 John Wiley & Sons, Ltd. Int. J. Commun. Syst. (2012)
DOI: 10.1002/dac
EXPLOITING SCHEDULING AND FREE-RIDING IN BITTORRENT NETWORKS
To summarize all of the indicators above, we formulate the following equation to measure the
importance of each task:
Priority D .S  ˛ C D  ˇ C C   C ı/  P 1! , (1)
where notations represent each criterion of the priority queue and its own weighting parameter.
These are referenced in detail in Table I. Aside from the tunable parameters, ı is a constant offset
to prevent priority from degrading to zero. Also note that privilege (P / is measured by the number
of peers requesting the same torrent. Relatively slight differences between immense numbers could
mean little whereas they could be overwhelming to other criteria with lower levels. Therefore, the
privilege is calculated exponentially, lest its difference dominate other measures in priority.
With the priority queue introduced, we further define a rescheduling period. In the P2P network,
performance of file transfer could fluctuate as a result of various causes. With periodic updates of
the priority value, the scheduler regularly rearranges tasks in the queue, suspending what performs
poorly and promoting what starves for long or what is most requested. The real-time performance
of all active tasks is reflected in the periodic reevaluation that enables the scheduler to determine
whether a task deserves a reward of activation or a penalty of suspension immediately.
3.2. Subtleties for effective bandwidth utilization
Other design details concerning circumstances that we may face in actual implementation are
described here. These details may help improve the bandwidth efficiency of our approach.
3.2.1. Elimination of duplicate tasks. With the swelling population of clients in the P2P network,
it is always possible that a single torrent is requested by an overwhelming number of online users.
In this scenario, if each request for the same materials by each user is considered an individual task,
duplicate files would be transferred. Exchanging duplicate files wastes storage and bandwidth and
slows down the overall process.
To resolve this problem, the task manager could check the logs of existing tasks dispatched when
a fresh task emerges. If the newly requested content is identical to others in existence, the agent
would be required to share the subsistent task with the requesting user, instead of creating a new
task for duplication. This requirement also helps increase the privilege of the popular task and spares
agent resources for the completion of other user tasks.
3.2.2. Attempting to free-ride. It is generally accepted that free-riders create a common problem in
a P2P network. Free-riders refer to selfish peers that download files, but are unwilling to contribute
by uploading pieces to share [17, 18]. Obviously, the phenomenon of free-riding violates the spirit
of sharing and may bring down the mechanism of P2P networks [19, 20]. Designers may determine
a way to avert this sensitive problem.
For our case of handling a large number of tasks, activating too many tasks at a time brings com-
petition between connections and results in poor upload performance of each task because upload
bandwidth is usually considerably limited for ordinary home users. On the other hand, if too many
tasks stand by, the remaining unused download bandwidth is wasted. Thus, to make the best use of
all resources, we have chosen additional tasks for those suspended in the queue to act as free-riders.
Table I. Notations and definitions in (1).
Notation Definition
S Staving time of a task (min.)
D Download rate of a task (KB/s)
C Completed ratio of a task (0100%)
P Privilege of a task (number of requests)
˛, ˇ,  , ! Weighting parameters of each indicator
 A constant offset
Copyright © 2012 John Wiley & Sons, Ltd. Int. J. Commun. Syst. (2012)
DOI: 10.1002/dac
EXPLOITING SCHEDULING AND FREE-RIDING IN BITTORRENT NETWORKS
Table II. Default values for the weighting parameters used for
task scheduling.
Parameter Corresponding indicator Value
˛ Staving time (min.) 1
ˇ Download rate (KB/s) 9
 Completed ratio (0100%) 100
! Privilege (number of requests) 3
ı A constant offset 0.01
0
2000
4000
6000
8000
Time (hours)Ac
cu
m
ul
at
ed
 D
ow
nl
oa
d 
Am
ou
nt
 (M
By
tes
)
w/o task scheduling
w/ task scheduling (4 activated tasks)
w/ task scheduling (8 activated tasks)
0
500
1000
1500
2000
2500
3000
Time (hours)A
cc
um
ul
at
ed
 U
pl
oa
d 
Am
ou
nt
 (M
By
tes
)
w/o task scheduling
w/ task scheduling (4 activated tasks)
w/ task scheduling (8 activated tasks)
0
2
4
6
8
10
0 6 12 18 24 30 36 42 48
0 6 12 18 24 30 36 42 48
0 6 12 18 24 30 36 42 48
Time (hours)
D
ow
nl
oa
d/
Up
lo
ad
 R
at
io
w/o task scheduling
w/ task scheduling (4 activated tasks)
w/ task scheduling (8 activated tasks)
(a) download
(b) upload
(c) download / upload ratio
Figure 3. Impacts of utilizing task scheduling in our approach: (a) accumulated download amount; (b)
accumulated upload amount; and (c) download / upload ratio.
Copyright © 2012 John Wiley & Sons, Ltd. Int. J. Commun. Syst. (2012)
DOI: 10.1002/dac
EXPLOITING SCHEDULING AND FREE-RIDING IN BITTORRENT NETWORKS
activated tasks executed, and four and eight additional free-riders chosen from others suspended.
As shown in Figure 4, the download amounts of free-riders grow slightly. That is, free-riders
can utilize the unused bandwidth. The theoretical analysis [24] demonstrates that a free-rider can
reach 20% of the possible maximum download rate for an activated task in current BitTorrent
networks. In practice, four free-riders offer an 18.0% increase over the original download amount
of our raw task scheduling strategy while eight free-riders offer 38.3%. These increases could
imply profound performance enhancements worthy of the additional burden of free-riders on
the agent.
5. CONCLUSIONS
In this work, we have conducted an agency service into the BitTorrent network. The agent would
evaluate the priority of each task requested by users under its service and enqueue all tasks to be
activated in descending order of priority. Furthermore, we designed the scheme to avoid transferring
duplicate files and to activate free-riders. The design is implemented with a multiagent structure to
ease the loading of agents and to provide scalability for more users.
ACKNOWLEDGEMENTS
The authors sincerely thank Kuan-Chung Chen, Wei-Lin Chen, and Yu-Cheng Chen for their help on proto-
typing and experimental studies. Also, the authors were supported in part by the National Science Council,
Project No. NSC100-2221-E-006-261-, Taiwan, R.O.C.
REFERENCES
1. Parker A. The True Picture of Peer-to-Peer File Sharing, 2004. http://www.cachelogic.com/.
2. Guo L, Chen S, Xiao Z, Tan E, Ding X, Zhang X. Measurements, analysis, and modeling of BitTorrent-like systems.
Proceedings of the 5th ACM SIGCOMM Conference on Internet Measurement, October 2005; 35–48.
3. Tian Y, Wu D, Ng KW. Analyzing multiple file downloading in BitTorrent. Proceedings of International Conference
on Parallel Processing, August 2006; 297–306.
4. Bindal R, Cao P, Chan W, Medved J, Suwala G, Bates T, Zhang A. Improving traffic locality in BitTorrent via
biased neighbor selection. Proceedings of the 26th IEEE International Conference on Distributed Computing Systems
2006:66.
5. Blond SL, Legout A, Dabbous W. Pushing BitTorrent locality to the limit. Computer Networks 2011; 55(3):541–557.
6. Andrade N, Santos-Neto E, Brasileiro F, Ripeanu M. Resource demand and supply in BitTorrent content-sharing
communities. Computer Networks 2009; 53(4):515–527.
7. Zhang C, Dhungel P, Wu D, Liu Z, Ross KW. BitTorrent darknets. Proceedings of the 29th IEEE International
Conference on Computer Communications, March 2011; 1–9.
8. Zhang C, Dhungel P, Wu D, Ross KW. Unraveling the BitTorrent ecosystem. IEEE Transactions on Parallel and
Distributed Systems 2011; 22(7):1164–1177.
9. Legout A, Liogkas N, Kohler E, Zhang L. Clustering and sharing incentives in BitTorrent systems. ACM
SIGMETRICS Performance Evaluation Review 2007; 35(1):301–312.
10. Parvez N, Williamson C, Mahanti A, Carlsson N. Analysis of BitTorrent-like protocols for on-demand stored media
streaming. ACM SIGMETRICS Performance Evaluation Review 2008; 36(1):301–312.
11. Xia RL, Muppala JK. A Survey of BitTorrent performance. IEEE Communications Surveys & Tutorials 2010;
12(2):140–158.
12. Huang K, Wang L, Zhang D, Liu Y. A dynamic quota-based peer selection strategy in BitTorrent. Proceedings of the
6th International Conference on Grid and Cooperative Computing, August 2007; 267–274.
13. Wu CJ, Li CY, Ho JM. Improving the download time of BitTorrent-like systems. Proceedings of the 2007 IEEE
International Conference on Communications, June 2007; 1125–1129.
14. Tian Y, Wu D, Ng KW. Performance analysis and improvement for BitTorrent-like file sharing systems. Concurrency
and Computation: Practice & Experience 2007; 19(13):1811–1835.
15. Bharambe AR, Herley C, Padmanabhan VN. Analyzing and improving BitTorrent performance. Technical Report
MSR-TR-2005-03, Microsoft Research, February 2005.
16. Michiardi M, Ramachandran K, Sikdar B. Modeling seed scheduling strategies in BitTorrent. Lecture Notes in
Computer Science 2007; 4479:606–616.
17. Locher T, Moor P, Schmid S, Wattenhofer R. Free riding in BitTorrent is cheap. Proceedings of the 5th Workshop on
Hot Topics in Networks, November 2006; 85–90.
18. Sirivianos M, Park JH, Chen R, Yang X. Free-riding in BitTorrent networks with the large view exploit. Proceedings
of the 6th International Workshop on Peer-to-Peer Systems, February 2007.
Copyright © 2012 John Wiley & Sons, Ltd. Int. J. Commun. Syst. (2012)
DOI: 10.1002/dac
JOURNAL OF INFORMATION SCIENCE AND ENGINEERING 28, 161-176 (2012) 
161  
From Experience to Expertise: Digesting Cumulative  
Information for Informational Web Search* 
 
WEI-GUANG TENG+, WEI-HSUN WEN AND YUE-CEN LIU 
Department of Engineering Science 
National Cheng Kung University 
Tainan, 701 Taiwan 
 
Web searching has become a necessary activity for most Internet users. People can 
reach a specific website or collect desired information by using search engines. Neverthe-
less, when a user is unfamiliar with his or her search target, e.g., learning a previously un-
known topic, browsing and understanding the web pages in the corresponding search re-
sult requires extra effort. In such an informational web search, the user accumulates infor-
mation cues by reading web pages to approach the search target. For example, a user can 
gradually understand “cloud computing” after obtaining some information about relevant 
terms, e.g., distributed computing, Google App Engine, and Amazon EC2. In this work, we 
propose an “immediacy of interest” indicator, measured in terms of information freshness, 
to evaluate the possible user interest in a web page contained in a search result. Moreover, 
to address relevance in search sessions, the topic map is also utilized in our proposed 
scheme. Empirical studies show that informational web searching tasks can be completed 
efficiently and effectively with our approach. 
 
Keywords: web search, browsing history, information cue, relevance feedback, visualiza-
tion 
 
 
1. INTRODUCTION 
 
Web searching has become one of the tasks most frequently performed by users, as 
the information gathered on the Internet increases rapidly [10]. One typical use of search 
engines is acquiring relevant information to learn or understand previously unknown topics. 
In such an informational web search, the user is usually unfamiliar with his or her search 
target. Thus, accomplishing this search task may require multiple search sessions. Never-
theless, it is a paradox that search engines help filter irrelevant information in a single 
search session, while delivering more information in successive search sessions. As sug-
gested in prior works [13], more advanced search engine designs can help users approach 
their search targets in increasingly efficient ways. 
User behavior during an informational search task can be explored in the two sce-
narios below. First, unknown targets attract the users. For example, when one does not un-
derstand the term “cloud computing” in a result page, the user may initiate a new search 
session for this unfamiliar term. Second, the user cognition changes as information cues are 
accumulated. For example, the user understands the concept of “cloud computing” after 
browsing web pages describing relevant terms such as “distributed computing” and “util-
ity computing.” Thus, originally unfamiliar terms become familiar ones. These two scenar-
 
Received February 28, 2011; revised August 27, 2011; accepted August 30, 2011.  
Communicated by Chun-Nan Hsu. 
* This work was supported in part by the National Science Council of Taiwan, Project No. NSC 100-2221-E-006- 
261-. 
+ Corresponding author. 
DIGESTING CUMULATIVE INFORMATION FOR INFORMATIONAL WEB SEARCH 
 
163 
 
more pages by following hyperlinks on the page [12]. The user can then decide whether 
the desired information can be found in this stage. If not, he or she may start over from 
the first stage by refining or redefining the query terms. 
The above process may happen within seconds or last for more than a few hours, de-
pending on the user intent. Specifically, the taxonomy of a web search can be classified 
into three categories based on user intent, i.e., navigational, transactional and informational 
searches [4, 6, 11, 15]. The goal of a navigational search is reaching a specific website, 
such as Facebook, that the user already knows. The goal of a transactional search is per-
forming some web-mediated activities, e.g., online shopping, downloading a file, or find-
ing a map. Finally, the goal of an informational search is studying or discovering informa-
tion in web pages to understand or learn some particular knowledge. In practice, the search 
process is generally very short for the first two categories, navigational and transactional, 
since their corresponding search targets are usually clear. Moreover, as reported in a pre-
vious study [23], the distribution of navigational and transactional searches is rarely af-
fected by the time period of a day, but informational searches usually happen in the day-
time. 
In this work, we discuss informational web searches in which users start with a vague 
understanding of their goal. For example, a student who lacks background knowledge 
wants to know more about “the history of classical music.” After the first attempt, some 
famous musicians’ names appear in the search results. The next search session then starts 
with the query term “Beethoven.” After reading some pages, he wants to get an idea about 
“the musical style of Beethoven.” He realizes that “the Baroque period” (1600-1750) is a 
highly important period for classical music. Similarly, this student may issue successive 
queries until he is satisfied with the obtained information on the history of classical music. 
In summary, an informational web search may lead to several instances of query refine-
ment or query re-formulation. 
An informational model of berrypicking [2] best describes the actual behavior of 
information searchers, especially the exploratory search process. Search behavior is not 
merely a single movement through which users reach the best retrieved result, but it is, 
instead, a berrypicking or evolving pattern. As shown in Fig. 1, the path of a searcher is 
usually a curve instead of a straight line. Also, searchers may iteratively change the di-
rection of their query after gaining new knowledge from retrieved documents and clari-
fying their own thoughts. 
People tend to browse web pages according to information cues obtained during the 
search session. In the simplest form, these cues can be text or images around hyperlinks. 
For example, when a user sees the alternative text “ESPN.com provides comprehensive 
sports coverage” around a banner image, the user expects that this hyperlink can lead him 
to the official ESPN website, even though he has not yet clicked the hyperlink. Further-
more, a cue can also be knowledge perceived by the user after reading some relevant web 
pages. By accumulating sufficient cues, a searcher can move to the next step. This in-
formation foraging phenomenon is then analogous to how wild animals decide which re-
source to select, keep or give up [14]. However, such a search process requires some ef-
forts, e.g., time consumption, uncertain search targets, frequent query changes, and irrele-
vant browsed pages. 
 
 
DIGESTING CUMULATIVE INFORMATION FOR INFORMATIONAL WEB SEARCH 
 
165 
 
    
(a) A clustering engine: Carrot2.                (b) Relevance mode in Pensieve. 
Fig. 2. Examples of user interfaces. 
 
(2) Visualization of Browsing History 
When users act on the web, logs are stored on different online services or in local 
browsers. These browsing logs can help users perform searches in more efficient and ef-
fective ways. For example, the Re:Search Engine [19] refers to the browsing history to 
re-rank the search results to emphasize new and possibly interesting entries for a user. 
Pensieve [7] is another work that utilizes the browsing history of a user and then 
presents it in an organized structure. Specifically, a user can review his or her browsing 
history in either timeline mode or relevance mode. The timeline mode emphasizes recent 
search sessions with finer granularities; the relevance mode, as shown in Fig. 2 (b), is 
used to represent the relationships between search sessions. 
3. REALIZING AND UTILIZING USER COGNITION IN A WEB SEARCH 
Terminology used in this work is defined in section 3.1. As a user may browse more 
than a few pages to obtain desired information, we illustrate the process of accumulating 
information cues in section 3.2. Accordingly, we propose an indicator to reflect the user 
cognition as described in section 3.3. Furthermore, we adopt the topic map in section 3.4 
to present the relevance between search sessions. Finally, the phenomenon of implicit 
relevance is illustrated in section 3.5. 
3.1 Terminology 
In an informational web search, users demand to learn a concept, e.g., recognizing a 
particular person or event or acquiring desired information. As discussed in previous sec-
tions, an informational search may contain a number of search sessions, i.e., times submit-
ting a query and browsing returned information. Each session contains some result pages 
and each page is called an entry. For each entry, there are representative keywords or 
terms regarded as features of the entry. In summary, these elements in an informational 
web search have the hierarchical relationship illustrated in Fig. 3. 
During a search session, a user may browse several entries to obtain information. In-
formation cues are gradually accumulated as one reads some relevant contents. Evaluat-
ing the usefulness of such information cues to determine their adequacy for a user’s com-
prehension of the target concept then becomes a crucial issue. 
DIGESTING CUMULATIVE INFORMATION FOR INFORMATIONAL WEB SEARCH 
 
167 
 
He may then examine every entry on the first few pages in the search results. In the 
first entry, he may be attracted by the famous name “George Bush” and feel curious to 
know why this former U.S. president is regarded as a powerful emperor. Consequently, 
he clicks the web page of the first entry and reads the contents. Afterwards, he learns that, 
to answer the question completely, more cues should be obtained by browsing more web 
pages. In other words, he may want to know about more emperors to compare their 
achievements. He may then notice the Roman Empire and its emperors in another entry. 
He may read the unfamiliar name “Gustavus Adolphus of Sweden” in yet other entries. 
Once he locates a good candidate for his presentation, he starts a new search with the 
query terms “Gustavus Adolphus” to know more about this emperor. Similarly, he may 
also start another search session after reading some stories about the Holy Roman Emperor 
“Charles V” to make further comparisons between these two emperors. This example 
clearly shows that a process of informational web searching may consist of more than a 
few successive and highly relevant search sessions. In general, information cues are ac-
cumulated as one reads more during the process. Nevertheless, more effort is required 
when one is unfamiliar with his or her search target. 
 
3.3 Reflecting the Change of User Cognition 
 
As observed from many examples, the user may understand originally unfamiliar 
terms after browsing some pages. This is intuitive: user cognition changes as one learns or 
gets familiar with something new. In addition, one may try to filter redundant entries con-
tained in the current search results because these entries are already known, not new, or 
irrelevant. We thus propose to both identify these behavior patterns as changes in user 
cognition and develop an indicator to concretely reflect this phenomenon. The change in 
user cognition is not addressed in conventional search engines, resulting in a time-con- 
suming process for users to identify and read something helpful in a large amount of search 
results. 
In this work, we seek to develop an indicator to represent the interestingness of each 
entry in the search results. With this indicator, one can simply filter the entries which are 
already known, i.e., not so fresh. This indicator can also be smoothly integrated with con-
ventional search engines. Because the user cognition evolves with time, the value of this 
indicator for a single page may also change with time. Then, the crucial issue is represent-
ing the change of user cognition through the accumulation of information cues. This indi-
cator, referred to as immediacy of interest or information freshness, can be best understood 
as the interest a user has in a result page at the present time. Specifically, an entry with a 
higher value indicates that the corresponding page contains more undiscovered informa-
tion within this session and the user is more likely to read it. This helps the user to master 
the concept he or she reads. Consequently, the value of this indicator for a specific page is 
based on the quantity of unfamiliar content included in the page. In other words, if a page 
contains many identical terms and similar paragraphs as what the user regularly reads, then 
this page is unlikely to have high information freshness. Not that a user typically needs 
to carefully examine each entry in search results when there is no such indicator. Never-
theless, as information freshness is introduced and visually represented, a user can glance 
over the whole list and read entries with higher values. 
 
DIGESTING CUMULATIVE INFORMATION FOR INFORMATIONAL WEB SEARCH 
 
169 
 
relevance may greatly interest a user who wants to know more details to connect learned 
information. The following example illustrates the usefulness of identifying implicit rele-
vance. 
Suppose a student wants to learn about the history of aircraft. He then submits “his-
tory of aircraft” to a search engine and reads some returned entries. Soon he is interested 
in an entry discussing the Wright brothers and realizes that they invented airplanes. At 
the same time, he notices the familiar name “da Vinci” in these entries. He then starts the 
next search with the query “da Vinci” to confirm the relevance of the famous Italian artist 
Leonardo da Vinci to the history of aircraft. As one may expect, the ensuing search results 
contain all art-oriented entries. This student may thus become confused as to whether this 
relevance exists. In fact, Leonardo da Vinci was also an outstanding engineer, regarded as 
a predecessor of the Wright brothers in designing a flying machine. The volume of this 
information, however, is far less than Leonardo da Vinci’s artistic achievements. 
Note that the implicit relevance tends be personal. For a person who is not interested 
in the history of aircraft at all but is a religionist, Leonardo da Vinci is mainly a painter 
who created The Last Supper, the most reproduced religious painting. In view of this, to 
help a user utilize information cues well, we propose providing suggested web pages once 
this implicit relevance occurs. If confirmed by the user, i.e., by reading several suggested 
web pages, the relevance between topics becomes explicit and is established automatically 
in the proposed topic map. 
4. EMPIRICAL STUDIES 
To realize our concepts of information freshness and a topic map for supporting in-
formational web search, we propose and implement a prototype of an appropriate scheme 
in section 4.1. Further experimental studies based on our prototype system compare the 
feasibility of using our proposed scheme to that of a conventional search engine. The cor-
responding results are presented in section 4.2. 
 
4.1 Proposed Scheme and the Prototyping 
 
To transform our proposed concepts into practical applications, we devised a system 
scheme consisting of several key components: an interactive interface, data collection, 
part-of-speech tagging (POS tagging), session characterization, relevance evaluation, sug-
gestion generation, and result visualization, as shown in Fig. 7. Moreover, a prototype of 
our scheme is implemented using the PHP script language and an ActionScript library. 
Specifically, major system components are briefly described as follows. 
• Data collection: This step forwards the query terms provided by a user to the Google 
AJAX Search API [9] to obtain corresponding search results. The results can be from 
web pages, blogs, or news. 
• POS tagging (part-of-speech tagging): This step receives the search results and extracts 
the nouns from each page to filter the redundant information, such as stop words and 
punctuation marks. Without loss of generality, we adopt the Stanford Part-Of-Speech 
Tagger [18] for tagging English articles and the SCWS (simple Chinese words segmen-
tation) [17] for segmenting and tagging Chinese articles. 
DIGESTING CUMULATIVE INFORMATION FOR INFORMATIONAL WEB SEARCH 
 
171 
 
where R(i, j) indicates the relevance strength between sessions i and j, and Si and Sj are 
the term lists in sessions i and j, respectively. R(i, j) ranges from zero to one. In our pro-
totype system, two sessions are considered as relevant when the value of R(i, j) is no less 
than a predefined threshold, e.g., 0.3. Furthermore, to address the phenomenon of im-
plicit relevance as described in section 3.5, a simple implementation is to define another 
lower threshold, e.g., 0.2. Therefore, two sessions i and j are implicitly relevant if the 
value of R(i, j) falls between these two thresholds, e.g., R(i, j) ∈ [0.2, 0.3). 
• Suggestion generation: Should there be implicit relevance between the current session 
and a previous one, this step generates suggested entries by exploiting information in 
the current session and the user’s browsing history. Intuitively, suggested entries can 
be obtained by submitting a new user query (which combines query terms in both ses-
sions) to the Google AJAX Search API. If more than a few suggested entries are read by 
the user, the term lists generated according to Eq. (2) could change and thus the rele-
vance strength may increase. 
• Result visualization: This step visualizes the two proposed items, information freshness 
and a topic map, in an interactive web interface. Specifically, the information freshness 
(or immediacy of interest) of an entry in the search result is evaluated by Eq. (4). 
1
| |
,
log ( )
i
i n
a t
t
T B
F
a c
=
−=
+∑
  (4) 
where Fi is the information freshness of entry i ranging from zero to one, Ti is the set of 
terms in entry i, B is the set of terms in the user’s browsing history, a is a constant, Ct is 
the occurrence frequency of term t in user’s browsing history, and there are n terms in 
entry i. Thus, the numerator denotes the number of terms that the user has never seen 
before; the denominator expresses the set size of all terms in entry i weighted by the term 
familiarity, Ct. The denominator reduces to the number of terms n in entry i if the user 
has not read any of the terms. 
Nevertheless, one may understand that as the user browses entries to read more terms, an 
unread entry containing several identical terms becomes less fresh. On the other hand, if 
an entry is almost composed of unseen terms, it is highly interesting, or very fresh, to 
the user. The freshness of a session, represented in colors and sizes in the topic map, is 
obtained by averaging the information freshness of all entries in the session. In addi-
tion, relevance strength between two sessions as calculated in Eq. (3) is represented by 
the link thickness. 
 
According to the system scheme above, the user interface of a prototype system is 
shown in Fig. 8. A topic map is shown over all the entries, and a visualized indicator show-
ing the information freshness value is shown to the right of each entry. A user can shift 
between topics by simply clicking on the corresponding node in the topic map. The corre-
sponding search results are presented accordingly. The concept behind such an interactive 
interface is the transformation and visual representation of the information cues accumu-
lated during the informational web search. The user can then focus on moving forward in 
the search or recalling topics explored in his or her browsing history. 
The following example based on the information in Fig. 8 illustrates this process.  
DIGESTING CUMULATIVE INFORMATION FOR INFORMATIONAL WEB SEARCH 
 
173 
 
• Question 2: Specify the differences of color tones for Nikon and Canon DSLRs (digital 
single-lens reflex cameras).  
(Answer: Nikon DSLRs have colder color tones, and Canon DSLRs have warmer color 
tones.) 
• Question 3: Specify the relationships between the following four names, Qi Bai Shi, Xu 
Bei Hong, Johann Ambrosius Bach, and Johann Christoph Bach.  
(Answer: The former two are friends and both are artists. The latter two are siblings and 
both are musicians. There is no relationship between the two pairs.) 
• Question 4: List four union stations.  
(Answer: They could be Kansas, St. Louis, Chicago, and Washington, D.C., etc.) 
• Question 5: What is independence movement? List three countries that have successfully 
achieved in independence movement.  
(Answer: Independence movement is some movement whose goals are primarily to create 
national identity and to be recognized as a sovereign state. Countries that have suc-
cessfully achieved in independence movement include India, the U.S., Ireland, etc.) 
• Question 6: List two ongoing military conflicts and corresponding belligerents.  
(Answer: They could be Mexican Drug War and War in Iraq, etc.) 
• Question 7: List four government organizations of the U.S. in Washington, D.C.  
(Answer: They could be the White House Office, Federal Bureau of Investigation, United 
States Capitol, etc.) 
7.2
8.1
6.7
3.6
8.5
6.1 5.8
9.6
10.8 11.2
8.5
13.7
6.2
9.2
0
2
4
6
8
10
12
14
16
Q1 Q2 Q3 Q4 Q5 Q6 Q7
Questions
A
ve
ra
ge
 T
im
e 
E
la
ps
ed
 (m
in
.)
Our Approach
Conventional Search Engine
 
7.1
7.8
6.2
4.6
5.8
6.8
5.6
9.4
11.4 11.8
8.5
13.8
6.5
8.9
0
2
4
6
8
10
12
14
16
Q1 Q2 Q3 Q4 Q5 Q6 Q7
Questions
Av
er
ag
e 
# 
of
 W
eb
 P
ag
es
 V
is
ite
d
Our Approach
Conventional Search Engine
 
Fig. 9. The average time required by the partici-
pants. 
Fig. 10. The average number of web pages visited 
by the participants. 
 
The required time and the number of web pages visited by the participants are shown 
in Figs. 9 and 10, respectively. Fig. 9 clearly shows that our approach is generally more 
efficient in completing a question. Moreover, as shown in Fig. 10, participants using our 
approach can obtain correct answers by reading fewer web pages. A participant can only 
read snippets to conjecture his or her next step when using a conventional search engine, 
which may result in reading redundant pages containing nothing helpful when construct-
ing answers. Also, the required time for digesting both useful and redundant information 
tends to be longer with conventional search engines. On the other hand, by utilizing our 
approach with the implemented prototype, both the required time and the number of vis-
ited web pages can be significantly reduced. 
Question 3 is a representative example to illustrate the feasibility of our approach, 
because the two pairs of names can be seen in the topic map in our approach. The partici-
DIGESTING CUMULATIVE INFORMATION FOR INFORMATIONAL WEB SEARCH 
 
175 
 
and transactional intent of web queries,” Information Processing and Management, 
Vol. 44, 2008, pp. 1251-1266. 
12. M. Levene and G. Loizou, “Web interaction and the navigation problem in hyper-
text,” Encyclopedia of Microcomputers, Vol. 28, 2001, pp. 381-398. 
13. G. Marchionini, “Exploratory search: From finding to understanding,” Communica-
tions of the ACM, Vol. 49, 2006, pp. 41-46. 
14. P. Pirolli, Information Foraging Theory: Adaptive Interaction with Information, Ox-
ford University Press, New York, 2007. 
15. D. E. Rose and D. Levinson, “Understanding user goals in web search,” in Proceed-
ings of the 13th International Conference on World Wide Web, 2004, pp. 13-19. 
16. G. Salton and C. Buckley, “Term-weighting approaches in automatic text retrieval,” 
Information Processing and Management, Vol. 24, 1988, pp. 513-523. 
17. Simple Chinese Words Segmentation (SCWS), http://www.ftphp.com/scws/index.php. 
18. Stanford POS tagger, http://nlp.stanford.edu/software/tagger.shtml. 
19. J. Teevan, “The Re:Search engine: Simultaneous support for finding and re-finding,” 
in Proceedings of the 20th Annual ACM Symposium on User Interface Software and 
Technology, 2007, pp. 23-32. 
20. J. Teevan, E. Cutrell, D. Fisher, S. M. Drucker, G. Ramos, P. André, and C. Hu, “Vis-
ual snippets: Summarizing web pages for search and revisitation,” in Proceedings of 
the 27th International Conference on Human Factors in Computing Systems, 2009, pp. 
2023-2032. 
21. M. Tomsa and M. Bieliková, “Hyperlinks visualization using social bookmarking,” 
in Proceedings of the 19th ACM Conference on Hypertext and Hypermedia, 2008, pp. 
245-246. 
22. Y. Xu and Z. Chen, “Relevance judgment: What do information users consider be-
yond topicality?” Journal of the American Society for Information Science and 
Technology, Vol. 57, 2006, pp. 961-973. 
23. Y. Zhang, B. J. Jansen, and A. Spink, “Time series analysis of a web search engine 
transaction log,” Information Processing and Management, Vol. 45, 2009, pp. 230- 
245. 
24. G. Zhu and G. Mishne, “Mining rich session context to improve web search,” in Pro-
ceedings of the 15th ACM SIGKDD International Conference on Knowledge Discov-
ery and Data Mining, 2009, pp. 1037-1046. 
 
 
Wei-Guang Teng (鄧維光) received B.S. and Ph.D. degrees 
from the Department of Electrical Engineering at the National 
Taiwan University, Taipei, Taiwan in 1998 and 2004, respectively. 
He is currently an Assistant Professor in the Department of Engi-
neering Science, National Cheng Kung University, Tainan, Taiwan. 
He was a senior researcher at Groundhog Technologies from 2004 
to 2005. His research interests include data mining, multimedia 
networking, and mobile computing. 
 
 
 
 Abstract-- As there are more and more surveillance cameras 
installed in public places, a challenging problem is to discover 
unusual behavior patterns from a huge amount of video data. 
However, this task is currently only feasible for human beings 
because both object recognition and intention detection are still 
difficult for computer vision. Recently, the development of low-
cost depth cameras significantly improves the efficiency and 
effectiveness of capturing motion data. We thus propose in this 
work an algorithmic scheme that extracts unusual behavior 
patterns from motion capture data. Specifically, feature 
extraction and data clustering techniques are applied in our 
scheme so as to detect such outlier patterns. Example applications 
of our scheme include public area surveillance and home 
healthcare. 
I. INTRODUCTION 
Research works in 3D image acquisition have proposed two 
well-known techniques, i.e., stereo vision (SV) and Time-of-
Flight (TOF), in past decades. Nevertheless, specific devices 
of high price but poor quality, e.g., laser scanners, are usually 
required to realize these techniques. In 2010, the invention of 
the low-cost Microsoft Kinect sensor, high-resolution visual 
and depth (RGB-D) sensing [3] has become available. This 
Kinect sensor also opens up new opportunities to solve 
fundamental problems in computer vision such as detecting 
and identifying objects/humans in real-world situations. 
 
 
Fig. 1. (a) An example posture; and (b) the corresponding skeleton model 
 
In general, the additional depth information is the key 
difference between video data and motion data. With depth 
cameras, motion capture denotes the process of recording 
object movements and translating the movements onto a digital 
model [4]. As shown in Fig. 1, human motion is commonly 
 
The authors are supported in part by the National Science Council, Project 
No. NSC 100-2221-E-006-261-, Taiwan, R.O.C. 
 
modeled using a kinematic chain, which may be regarded as a 
simplified copy of the human skeleton. A human skeleton 
model is composed of many major joints, i.e., elbow, knee, 
ankle and so on. Using motion capture techniques, an actor’s 
motion can be derived to be a time-dependent sequence of 3D 
joint coordinates as well as joint angles with respect to some 
fixed kinematic chain [7][8]. 
One’s usual behavior such as gait and rate of walking can be 
extracted from the history of his or her motion data. For 
thousands of years, people often use body characteristics such 
as face, height, body shape, and gait to recognize each other 
[5]. In other words, biometrics can be used to facilitate the 
purposes of user identification and unusual behavior detection 
[9]. Note that the premise of unusual behavior detection is to 
effectively conduct human motion recognition [1]. In prior 
works, there are generally two ways to recognize unusual 
human motion behavior. One approach is to build a unified 
model to represent all normal modes of human behavior in an 
observed scene [2]. In contrast, the other approach is to build a 
model which represents all abnormal modes [1]. Nevertheless, 
a common limitation of these two approaches is that all modes 
of (normal or abnormal) human behavior have to be 
predefined. This limitation may greatly reduce the feasibility 
of these approaches when applied in practical applications. 
By properly modeling the problem of behavior detection as 
an unsupervised learning problem in this work, data clustering 
techniques can then be utilized to separate unusual patterns 
from usual ones. Specifically, unusual patterns may form 
outliers that are quite different from or inconsistent with the 
remaining set of data [6]. In other words, an outlier, or 
outlying behavior pattern, is one that appears to deviate 
markedly from other observations of the sample in which it 
occurs. 
II. USAGE SCENARIOS 
In this work, we use Kinect to capture the body motion of a 
user. As shown in Fig. 2, when Kinect is installed in the 
example scenario of a train/airplane cabin, behavior patterns 
such as people sitting on their seats or walking slowly may 
occur frequently. However, patterns of running and falling 
down on the floor occur very infrequently that are considered 
as unusual behavior patterns in this case. This usage scenario 
can be also applied to other environments such as monitoring 
in a factory and healthcare in home places. In summary, a key 
observation is that usual patterns occur frequently. Thus, it is 
not necessary to define usual patterns before the identification 
process. 
 
 Discovering Unusual Behavior Patterns from Motion Data 
Kai-Lin Pang, Guan-Hong Chen, and Wei-Guang Teng*, member, IEEE 
Department of Engineering Science, National Cheng Kung University, Tainan, Taiwan 
2013 IEEE International Conference on Consumer Electronics (ICCE)978-1-4673-1363-6/13/$31.00 ©2013 IEEE 244
Multicast Deployment of Cloud Operating Systems 
 
Kuen-Min Lee1,2, Wei-Guang Teng1, Jin-Neng Wu2, Kuo-Ming Huang2, Yao-Hsing Ko2, and Ting-Wei Hou1 
1Department of Engineering Science 
National Cheng Kung University, Tainan, Taiwan 
2Cloud Service Technology Center 
Industrial Technology Research Institute, Tainan, Taiwan 
 
 
Abstract—With cloud computing’s paradigm shift for IT 
industries, the concept of thin clients has become popular again. 
There are usually numerous nodes with various functions in a 
cloud computing system. It is important to deploy different cloud 
operating systems (cloud OSs) onto different nodes. The 
conventional method of using unicast deployment to distribute a 
massive cloud OS onto thousands of nodes is time consuming and 
bandwidth-intensive. In this work, we propose a multicast 
deployment approach to significantly improve deployment 
efficiency. Furthermore, our multicast deployment approach can 
leverage existing configurations of the unicast counterpart. 
Therefore, customized deployment for different groups of nodes 
can be achieved. To evaluate the feasibility of the proposed 
approach in practical applications, our deployment approach is 
implemented using CentOS and Ubuntu on many nodes. 
Empirical studies show that the required time for the entire 
distribution process is significantly reduced, from starting 
delivery until the OS is ready. Moreover, network bandwidth 
consumption is also significantly reduced compared with the 
conventional unicast deployment. Consequently, system 
administrators must spend less effort on monitoring and 
maintenance. 
Keywords: cloud computing, deployment, multicast, preboot 
execution environment 
I.  INTRODUCTION 
Cloud computing is an emerging technology that has been 
adopted rapidly around the globe [1]. Several well-known 
corporations (e.g., Microsoft [2], IBM [3], Google [4], and HP 
[5]) have devoted their studies in this field to cultivating the 
potential market. There are also many public cloud providers, 
including Rackspace [6], GoGrid [7], and Amazon AWS [8]. In 
addition, Open Nebula [9] and Eucalyptus [10] are currently 
developing open source software. Because of frequently 
changing environments and large numbers of nodes, the 
deployment of cloud operating systems is an essential but 
labor-intensive task. Specifically, the conventional method of 
unicast deployment may result in excessive time and 
bandwidth overhead. However, the deployment time and 
required bandwidth can be greatly reduced by adopting a 
multicast approach. A major disadvantage of previous 
multicast deployment approaches is that they did not allow 
customization of cloud operating systems for different nodes; 
i.e., all nodes must have identical cloud operating systems and 
settings. 
As described in a prior study [11], a number of challenges 
exist for cloud management, including scalability, multiple 
levels of abstraction, federation, sustainability, and dynamism. 
In this work, we focus on the problem of OS deployment, 
which is primarily related to the challenge of dynamism. In 
addition, monitoring and analysis tasks must be properly 
executed to meet the dynamism challenge. Many approaches 
that use centralized [12] and distributed [13] approaches have 
been proposed to resolve the dynamism issue. One proposal to 
solve the disk-writing bottleneck was to utilize the 
methodologies of congestion control and data recovery in a 
multicast deployment method [12]. In addition, the distributed 
BitTorrent mechanism with Tracker HTTP and Peer Wire 
Protocol was also proposed as a method to install an OS [13]. 
However, the above approaches did not consider customized 
OS deployment for different groups. Additionally, the 
Hardware Deployment System (HaDeS) [14] has been 
proposed for large-scale installation. It is designed to deploy an 
OS on a large number of nodes on a massive scale with respect 
to the network topology. However, the above approach cannot 
deploy a customized OS instead of an image. Moreover, 
another OS that can treat heterogeneity has been designed on 
the client system [15]. It can determine which driver should be 
installed and which firmware should be executed on a physical 
machine. However, the OS is costly in terms of time and 
bandwidth. Another study has attempted to enhance 
deployment performance by applying a streaming server 
between the OS and the disk [16]. The authors have 
implemented this architecture in Windows and Linux. They 
show that this type of OS streaming deployment significantly 
reduces the deployment time. However, this system requires a 
streaming server and the corresponding agents. In general, a 
tradeoff of efficiency for customization (and vice versa) is 
always required when conducting OS deployment using 
previous approaches; i.e., either efficiency or flexibility must 
be sacrificed. 
In this work, we propose a time- and cost-efficient scheme 
for multicast deployment in cloud system. In addition, nodes in 
a cloud system must usually form different groups for different 
purposes. We thus address one additional advantageous feature 
of our scheme, which is that customized OSs are allowed for 
different groups. This multi-group deployment is a key feature 
of our proposed scheme. Our approach combines features and 
advantages of both unicast and multicast approaches. 
The rest of this paper is organized as follows. In Section II, 
we describe the preliminaries and related studies. In Section III, 
proposed system adds a multicast server and provides a 
multicast mechanism to enhance the system’s time and cost 
efficiency. For deployment of customized OSs, the pre-process 
that generates the multicast server environment must be 
involved. There are two deployment phases in the proposed 
system. The first phase includes UDPcast, which starts the 
PXE client to bootstrap and to execute a specified script and 
then to download the related configurations. In the second 
phase, the PXE client begins to install and downloads 
installation parameters until the deployment is finished. 
A. Multicast Server Environment Generation 
To deploy different OSs for different groups of PXE clients, 
the administrator on the server side could edit the configuration 
files and customize the parameters for specific needs. As 
shown in Fig. 3, the parameters include the group ID and the IP 
address of the clients, the ports of multicast servers, and the 
customized multicast OS. Through the environment generation 
process, the multicast server environment would be setup 
completely. Finally, the multicast server deployment process 
would be waiting for later launch. 
 
 
Figure 3.  The generation flow of the multicast server environment 
B. First Boot 
There are three main actors that participate in the first boot 
phase. They are a group of PXE clients, a multicast server, and 
a TFTP server. A PXE client is a machine that executes the 
PXE boot process. The multicast server is a server that 
launches and controls an automatic multicast deployment 
process. The TFTP server holds the initial RAM disk and the 
kernel for the client booting. These two servers are described in 
detail in Section IV. For this first boot phase, the detailed flow 
is shown in Fig. 4 and Fig. 5. The multicast server starts the 
deployment process, which includes the following five stages: 
PXE booting, pre-installation procedure planning, hard disk 
(HD) initialization, multicast OS RAM disk packaging, and 
multicast OS installation packaging. 
 
1) PXE booting: The first stage of the first boot phase is 
PXE booting. First, the multicast server runs the script and 
powers on the PXE clients remotely (steps 1 and 2). A group of 
the PXE clients request an IP address (steps 3 and 4) and then 
download a RAM disk and a kernel file from a TFTP server 
(steps 5 and 6). The RAM disk file includes the PXE client 
boot loader used in the second boot phase. After the client 
receives these files, it waits for multicast deployment (step 7). 
When the other members of the same group arrive, the 
multicast server sends the other files that are manipulated in 
steps 2 through 5. 
 
 : PXE 
Client
 : Multicast 
Server
 : HTTP 
Server
 : DHCP 
Server
 : TFTP 
Server
5: request bootstrap
6: download ramdisk and kernel of tiny os
7: request tiny.sh
8: multicast tiny.sh
10: request pre.sh
11: multicast pre.sh
9: execute tiny.sh
12: execute pre.sh
1: execute udpcast.py
2: power on
3: request IP address
4: answer IP address and address of bootstrap
 
Figure 4.  The first half of the work flow of the first boot process 
 
2) Pre-installation procedure planning: Stage 2 is the pre-
installation procedure planning stage. The multicast server 
sends the pre-installation process file, tiny.sh. The PXE client 
executes this file (steps 8 and 9) after receiving it. According 
to the pre-installation process, the multicast server sends 
related files and sets up configuration files for the boot loader 
or the master boot record. Once those files are received, the 
PXE client then executes a series of actions. 
 
3) HD initialization: The hard disk initialization stage is 
part of stage 3. The multicast server sends the hard disk 
initialization setup file, pre.sh. The PXE client then executes 
this file and starts to partition and format the hard disk (steps 
10 through 13). 
 
4) Multicast OS RAM disk packaging: In stage 4, the 
multicast server sends the destination OS initialization file to 
be used in the second boot phase, second_boot.sh (steps 11 and 
12). After executing this file, the PXE client begins to perform 
the multicast download process. After finishing the download 
process, it unzips the tar.gz file and configures it in a suitable 
place (steps 16 through 18). The tar.gz file includes the OS 
RAM disk and kernel, which are necessary for the target 
machine installation. 
Edit configuration files for 
customization (e.g., pregen.cfg) 
Customize parameters (group_id, 
member_ip, portbase, 
second_boot_os) 
Generate multicast server 
environment (e.g., pregen.sh) 
Set up multicast server environment  
the OS installation process referenced by the ks.cfg file in 
sequence. The PXE client then continued to execute the ks.cfg 
file. Finally, the PXE client executed the post.sh and subpost.sh 
scripts.  
 
/tftpboot linux-install tiny initrd_tiny_64.img
vmlinuz
pxelinux.cfg
pxelinux.0
group_x
01-00-26-2d-07-01-19
01-00-26-2d-06-ff-3d
 
Figure 7.  The directory structure of the TFTP server  
 
/var www html ks.cfg
post.shyum
glpi
sn300pub
subpost.sh
cacti  
Figure 8.  The directory structure of the HTTP server  
 
 
Figure 9.  The directory structure of the multicast server 
C. Multicast Server 
The multicast server contained the following files and 
directory structure: as shown in Fig. 9, the udpcast.py file 
defined the automatic processes of UDPcast. The pregen.sh file 
generated the execution file for the directory structure of 
group_x. The ISO files were saved in the directory structure of 
iso_file. The UDPcast tool was saved in the directory structure 
of tool. The general folder contained two subdirectories: 
first_boot and second_boot. The directory structure of 
first_boot contained template files for the multicast deployment. 
The directory structure of second_boot_x contained the 
corresponding RAM disk and kernel for the PXE clients to 
execute the second boot process. 
D. Analysis 
As shown in Fig. 10, the proposed multicast system 
consumed significantly lower network bandwidth compared 
with the conventional unicast network deployment for large 
numbers of clients. The lower bandwidth consumption is 
because our proposed system used the multicast deployment 
mechanism. When the scale of deployment is small, the one-
by-one deployment mechanism of the conventional unicast 
network deployment efficiently uses network bandwidth. As 
the number of clients becomes larger, the conventional unicast 
network deployment results in excessive network bandwidth 
overhead. Our proposed multicast system requires slightly 
more network bandwidth for groups of less than 8 machines. 
The extra bandwidth is needed because our proposed multicast 
system can deploy different OSs for different groups. The 
results demonstrated that when implementing multicast 
deployment for 5 different groups, our proposed system 
required slightly more network bandwidth than the 
conventional unicast network deployment. Therefore, from the 
experimental results, we conclude that our proposed multicast 
mechanism will waste less network bandwidth when groups 
contain more than 8 machines. In summary, the bandwidth 
consumption of our proposed mechanism will become 
significantly less than that of the unicast deployment method as 
the scale of the deployment is further increased. 
 
0
0.2
0.4
0.6
0.8
1
0 10 20 30 40 50
Number of Clients
Ac
cu
m
ul
at
io
n 
of
 N
et
w
or
k 
Ba
nd
w
id
th unicast
multicast to 1 group
multicast to 2 groups
multicast to 3 groups
multicast to 4 groups
multicast to 5 groups
 
Figure 10.  Bandwidth consumption of multicast deployment compared to that 
of unicast deployment 
The second experimental result is shown in Fig. 11. Our 
results illustrate the trend of cost per use (in terms of the 
consumption time during deployment) versus the number of 
clients. The cost per client in the conventional unicast network 
deployment does not change regardless of the number of 
clients. This is because the conventional unicast network 
deployment uses the mechanism of one-by-one deployment. 
By using the mechanism of multicast deployment, our 
proposed system can significantly decrease costs. Moreover, 
our system incurs only slightly higher costs as the number of 
clients grows Even if there is a need to support multicast 
deployment for 5 different groups, our proposed multicast 
deployment system still has lower cost per use than the 
Associating and Recalling News Events  
with Visual Suggestions 
 
Hsiang Wang and Wei-Guang Teng 
Department of Engineering Science  
National Cheng Kung University 
Tainan, Taiwan 
wgteng@mail.ncku.edu.tw 
 
 
Abstract—As more and more information including news 
articles, personal stories and so on gathered on the Internet, how 
a user perceives and memorizes every details of what he or she 
reads is of significant challenge. In view of this information 
overload problem, recent advances in the research field of 
information retrieval have resolved most difficulties when a user 
is able to provide appropriate keywords of his/her search target. 
Nevertheless, some important events which are etched deeply in 
one's memory may not be clearly defined as a few keywords or 
even easily recalled. Thus, we propose in this work to provide 
some visual suggestions to help users associate and recall their 
own stories from the memory while reading current news articles. 
In addition to the usage of fragment text, we propose to extract 
similarities from news photos. Consequently, resulting 
suggestions are effective for a user to associate current news 
event with previous ones. As such implicit relationships are 
gradually found, the topic map is then constructed to help a user 
organize relevant concepts he or she has ever known or learned. 
Index Terms—Bag-of-visual-words, content-based image 
retrieval (CBIR), query suggestion, topic map. 
I. INTRODUCTION 
With the advances in both information and communication 
technologies, more and more information has been made 
available on the Internet. The presence of too much 
information causes the difficulty of understanding and 
remembering. When users try to investigate, evaluate, compare 
and synthesize information pieces grabbed during their news 
browsing processes, they may encounter the information 
overload problem due to the limited short-term memory of 
human beings. Some news articles talking about disasters or 
big challenges of the economics may have significant influence 
in long term memory. But after a long period, users may just 
feel something familiar when they browse relevant news. 
Consequently, it is desirable for users if their browsed news 
can be properly analyzed and organized. 
Information retrieval techniques have demonstrated their 
usefulness in handling textual data. Nevertheless, the problem 
of image retrieval has attracted an increasingly growth of 
research interests recently. Specifically, common image 
retrieval techniques can be categorized into text-based and 
content-based approaches. With a text-based image retrieval 
approach, a user can search images by meta-data such as title, 
tag, and image caption affiliated with images. On the other 
hand, content-based image retrieval approaches compare 
images based on color, texture, contour, or spatial relation. 
Note that all of these features can be extracted from the image 
itself. Both text-based and content-based approaches encounter 
some challenges, including the lack of annotation data or the 
semantic difference between the visual view and actual concept 
of an image [14]. 
There are many ways for users to specify their queries 
when looking for some images, e.g., query by keywords or by 
example images. To further facilitate the image retrieval 
process, the level of human and system interaction is addressed 
in recent studies [3]. Specifically, relevance feedback (RF) is a 
query modification technique which attempts to capture the 
precise needs of a user through iterative feedback and query 
refinement. Long term relevance feedback collects user search 
behavior, or more specifically, part of the user memory, so how 
people perceive images can be simulated [5]. We thus observe 
that by understanding the long term behavior of a user, a more 
efficient and feasible retrieval algorithm can be developed. 
Different users may use different keywords to describe an 
identical image. When seeing an image, a user usually 
perceives the concept embedded in this image rather than 
counts the number of colors or extracts the shapes. It is thus 
easily understood that computer algorithms can hardly link 
low-level features and concept together. This phenomenon is 
called the semantic gap. Because of the semantic gap, it is 
almost impossible to construct a CBIR system which supports 
general categories of images [11]. In view of this, we focus on 
the processing of images embedded within news articles in this 
work. Because the main idea of a news article is usually easy to 
understood, the accompanying image of a news article is 
typically illustrative and impressive for most readers. In other 
words, news images are more closely linked with news 
concepts, resulting in a smaller semantic gap. 
In current search engines, when a user starts typing a query 
into a search box, he or she may see a dropdown list which 
offers selectable suggestions for query terms even before he or 
she may have finished typing [13]. Such query suggestions are 
usually generated by calculating the implicit relation among 
978-1-4673-2430-4/12/$31.00 ©2012 IEEE 196
quantize these features to get a better data structure as 
described in Section III.A. Second, similar news images are 
associated and gathered to form a news event, and visual 
suggestions are generated. The corresponding process is 
explored in Section III.B. 
 
 
Fig. 2.  Proposed scheme for news visual suggestion. 
A. Extracting Visual Information from News 
A simple but crucial idea of our proposed scheme is to 
deliver similar images and accompanying news articles as 
suggestions when a user is browsing some news articles. 
Therefore, each time when a user browses a news articles, the 
corresponding image and metadata (e.g., article title and url) 
are required to be stored for further analysis. Nevertheless, a 
news image is not merely stored but should be processed 
through several steps. With appropriate steps, following 
process of generating visual suggestions can thus be made 
efficient and precise. 
Usually the first step is to extract features from the image. 
Two types of feature descriptors are usually utilized. One is the 
general feature descriptors for colors, shapes, textures and so 
on, and the other is the local feature descriptors, e.g., SIFT or 
SURF. Note that local descriptors are usually robust to 
translation, rotation, or scale variations, and thus very suitable 
for object recognition [12]. In other words, local descriptors 
extract very similar features when two images containing an 
identical scene even if these two images, i.e., news photos, are 
taken from different viewpoints. With loss of generality, we 
use a local feature descriptor named opponent-SIFT to extract 
image features in this work. Specifically, SIFT descriptors are 
used to describes all of the components in the opponent color 
space that is more appropriate for human perception. With the 
opponent-SIFT descriptor, vectors of 384 dimensions are 
extracted to represent each local feature in an image. 
Features extracted from an image is like keywords 
extracted from a textual article. As indicated in the research 
works on information retrieval, synonyms (i.e., two words with 
the identical meaning) may occur frequently. As is easily 
understood, two synonyms can be used interchangeably and the 
article does not lose any information. Therefore, one keyword 
can be used as the representatives of all its synonyms. For 
image retrieval, we can similarly select representative features 
as there are usually hundreds of feature vectors in an image. 
Consequently, a data clustering technique k-means is used to 
generate such representative feature vectors, or more 
specifically, visual words [6], in the feature quantization step 
of our scheme in Fig. 2. Each local feature vector can then be 
represented by its most similar visual word. The overall 
computation overhead can also be significantly reduced 
because the number of visual words is usually limited. 
After these two necessary steps of feature extraction and 
feature quantization, an image can be represented by a list of 
visual words. Through proper normalization, the similarity of 
two images can be directly calculated by evaluating the 
difference of two corresponding lists of visual words. 
B. Associating News Events 
When a user is reading a current news article, the 
accompanying news photo, i.e., an image, is downloaded and 
analyzed through the identical steps of feature extraction and 
quantization just as mentioned. Generally speaking, if this 
image is similar to some previous ones, then visual suggestions 
can be immediately provided for this user. Such an online 
matching process is handled in the step of image associating in 
Fig. 2. He or she may decide to proceed the reading of other 
current news articles or move to suggested ones once he or she 
suddenly recalls some events in the mind. 
Note that one news event could be reported by different 
news sources with different caption, different images, and 
different contents. If two or more images from different news 
articles are very similar, we define that these images and 
corresponding news articles belong to the same news event. 
With the usage of a hierarchical data clustering technique, 
general groups of news events can be formed. A major 
advantage of our approach is that even if two news articles are 
quite dissimilar in their titles and time, they may be discovered 
to be within the same news event. 
Every news event can be considered as a topic that user 
feels interesting or not. Also, there may be a strong or weak 
relationship between two different topics. We thus incorporate 
the topic map into our proposed scheme for better illustration 
of previously read news events of a user. An example topic 
map which contains several keywords extracted from military 
news articles is shown in Fig. 3. Note that the presence of an 
edge between two keywords indicates an explicit relationship. 
Moreover, the thickness of an edge stands for the relationship 
strength. In this example topic map, we can easily find out that 
the relationship between Cheonan (i.e., the name of a Korean 
warship) and North Korean Navy is much stronger than that 
between North Korean Navy and South Korean Navy. Another 
group of military affairs between Taiwan and China can also be 
easily discovered. In summary, the usage of the topic map 
helps to better organize previously read news events of a user. 
198
 Fig. 5.  A screeshot of our prototype system. 
When the user is reading an article which contains no 
image, relevant news articles based on analyzing the textual 
information are presented. An example is shown in Fig. 6. 
 
Fig. 6.  When there is no news image, relevant news articles instead of visual 
suggestions are presented. 
Note that our prototype system also incorporates the topic 
map to present the relationships among different news events. 
As shown in Fig. 7, two representing images of respect news 
events are linked together because of the common concept 
“typhoon”. 
 
Fig. 7.  An example topic map that shows two relevant news events. 
V. CONCLUSIONS 
In this work, we have proposed to provide visual news 
suggestions for helping users to associate and recall previous 
events from their memory. Specifically, we have bridged 
currently browsed news articles and past news events in the 
memory with a properly designed scheme. In addition, the 
topic map has been incorporated into our scheme to capture the 
relevance among different news events. 
ACKNOWLEDGMENT 
The authors are supported in part by the National Science Council, 
Project No. NSC 100-2221-E-006-261-, Taiwan, R.O.C. 
REFERENCES 
[1] S. Boutemedjet and D. Ziou, “A Graphical Model for Context-
Aware Visual Content Recommendation,” IEEE Transactions on 
Multimedia, 10(1):52-62, January 2008. 
[2] S. Bowers, H. Cao, M. Schildhauer, M. Jones, B. Leinfelder, and 
M. O’Brien, “A Semantic Annotation Framework for Retrieving 
and Analyzing Observational Datasets,” Proceedings of the 
Third Workshop on Exploiting Semantic Annotations in 
Information Retrieval, pages 31-32, October 2010. 
[3] R. Datta, D. Joshi, J. Li, and J. Z. Wang, “Image Retrieval: Ideas, 
Influences, and Trends of the New Age,” ACM Computing 
Surveys, 40(2), Article No. 5, April 2008. 
[4] Google Web Search API, https://developers.google.com/web-
search/docs/. 
[5] J. Han, K. N. Ngan, M. Li, and H.-J. Zhang, “A Memory 
Learning Framework for Effective Image Retrieval,” IEEE 
Transactions on Image Processing, 14(4):511-524, April 2005. 
[6] K. Kesorn and S. Poslad, “An Enhanced Bag-of-Visual Word 
Vector Space Model to Represent Visual Content in Athletics 
Images,” IEEE Transactions on Multimedia, 14(1):211-222, 
February 2012. 
[7] L. A. Leiva, M. Villegas, and R. Paredes, “Query Refinement 
Suggestion in Multimodal Image Retrieval with Relevance 
Feedback,” Proceedings of the 11th ACM International 
Conference on Multimodal Interfaces, pages 311-314, 
November 2011. 
[8] G. Linden, B. Smith, and J. York, “Amazon.com 
Recommendations: Item-to-Item Collaborative Filtering,” IEEE 
Internet Computing Magazine, 7(1):76-80, January 2003. 
[9] Y. Liu, D. Zhang, G. Lu, and W.-Y. Ma, “A Survey of Content-
based Image Retrieval with High-level Semantics,” Pattern 
Recognition, 40(1):262-282, January 2007. 
[10] Y. Lu, L. Zhang, J. Liu, and Q. Tian, “Constructing Concept 
Lexica with Small Semantic Gaps,” IEEE Transactions 
on Multimedia, 12(4):288-299, June 2010. 
[11] T. Pavlidis, “Limitations of Content-based Image Retrieval,” 
Plenary Talk of the 19th International Conference of Pattern 
Recognition, December 2008. 
[12] K. E. A. van de Sance, T. Gevers, and C. G. M. Snoek, 
“Evaluating Color Descriptors for Object and Scene 
Recognition,” IEEE Transactions on Pattern Analysis and 
Machine Intelligence, 32(9):1582-1596, September 2010. 
[13] B. Slawski, “Predictive Search Query Suggestions,” http://www. 
seobythesea.com/2009/05/predictive-search-query-suggestions/, 
May 2009. 
[14] C. G. M. Snoek and A. W. M. Smeulders, “Visual-Concept 
Search Solved?,” Computer, 43(6):76-78, June 2010. 
[15] Y. Yang, D. Xu, F. Nie, S. Yan, and Y. Zhuang, “Image 
Clustering Using Local Discriminant Models and Global 
Integration,” IEEE Transactions on Image Processing, 
19(10):2761-2773, October 2010. 
[16] Z.-J. Zha, X.-S. Hua, T. Mei, J. Wang, G.-J. Qi, and Z. Wang, 
“Joint Multi-label Multi-instance Learning for Image 
Classification,” Proceedings of IEEE Conference on Computer 
Vision and Pattern Recognition, pages 1-8, June 2008. 
[17] Z.-J. Zha, L. Yang, Z. Wang, T.-S. Chua, and X.-S. Hua, 
“Visual Query Suggestion: Towards Capturing User Intent in 
Internet Image Search,” ACM Transactions on Multimedia 
Computing, Communications, and Applications, 6(3), Article 
No. 13, August 2010. 
200
此外，藉由聆聽大會安排的專題演講與其他論文發表的議程，我們也特別對語意網路 (semantic 
web)、影像檢索與分類、人機互動等課題的現況與發展有了更深入的瞭解，而在私下的社交場合也與
某些與會的國內外學者有良好的討論與互動。 
 
二、與會心得 
本屆會議舉行的地點 – 中國澳門雖然地方不大，但在近年來隨著其觀光與博奕業的興盛，而有
了許多新穎的建設，同時亦保有中國沿海地帶先民發展的文化遺跡，停留在此的與會期間可以發現開
拓不同的視野，更可令人更具包容不同文化的國際觀，隨行的研究生同學也獲得了除旅遊樂趣外的開
闊視野；而在論文發表方面，由於資訊領域的技術演進非常快速，所以積極地參與國際會議之重要性
應不亞於期刊論文的發表；對國內的教師或研究生而言，校內的討論環境相對來說還是較為封閉，且
在英文此一國際語言的應用上往往不若歐美國家，甚至新加坡、印度與香港等亞洲國家或地區。最後，
在會議所在地澳門大學內，我們也感受到了不同的學習風氣，而經過與參加人士的友善交流，普遍來
說更可發現國外的研究工作較為實務導向，也值得我們深思。 
 
三、考察參觀活動(無是項活動者略) 
略。 
 
四、建議 
在近年來國科會與頂尖大學計畫的支持下，國際化的程度已有攀升的趨勢，且成大在工程領域的
發展非常傑出，但除了學術發展之外，與產業界的實務面互相結合應也是研究型大學的重要任務；而
本次研討會的專題演講全由產業界的專家擔綱，演說主題實際且明確，立意良好。未來若能多在國內
舉行這樣的國際研討會，並同時安排產業界和學術界的專家學者進行交流或演講，達到產學平衡，相
信更能讓同學們有更深一層的收獲，並可更加提昇學生對研究的熱忱。 
 
五、攜回資料名稱及內容 
論文集光碟一份、近期相關領域之徵稿啟事 (call for papers) 若干份。 
 
六、其他 
search results. As an enhancement of textual query suggestions, 
recent studies have indicated that visual suggestions can be 
provided by jointing appropriate text and images [17]. Users 
can express their search intents in a more precise way by using 
image suggestions. 
The rest of this paper is organized as follows. Preliminaries 
and related works are generally reviewed in Section II. The 
proposed technique of generating visual suggestions is 
explored in Section III. Empirical studies to show the 
feasibility of our proposed scheme are conducted in Section IV. 
Finally, this paper concludes with Section V. 
II. PRELIMINARIES 
Common techniques for content-based image retrieval 
(CBIR) and their challenges are generally discussed in Section 
II.A. Moreover, the concept of visual suggestions is explored in 
Section II.B. 
A. Challenges of Current CBIR Techniques 
There are two major focuses in previous studies on CBIR, 
i.e., performance improving and retrieval supporting. 
Performance improving can be achieved by reconstructing data 
structures, changing execution priorities or algorithm 
refinement when handling huge amounts of images. On the 
other hand, the relevance feedback mechanism helps to re-rank 
retrieval results for better satisfaction. Nevertheless, in addition 
to these two focuses, recent studies have noticed a fundamental 
but crucial problem of the semantic gap [9]. 
Human beings use objects, environments, conditions, 
motions or emotions to understand the high-level concept 
delivered by an image. On the contrary, computers use low-
level features, e.g., colors, textures, shapes and spatial locations, 
extracted by several descriptors to describe an image. 
Consequently, two visually similar images may be of big 
conceptual differences, and vice versa. This phenomenon is 
called the semantic gap. Fig. 1 shows the difference, i.e., 
semantic gap, between the computational similarity and 
conceptual similarity. The left image and the middle one 
describe an identical concept of “earthquake” but they are 
computationally dissimilar. On the other hand, the middle 
image and the right one describe two different concepts, i.e., 
“earthquake” and “snake” but they are computationally similar. 
 
 
Fig. 1.  Semantic gap is resulted from the difference between how people and 
computers "define" the contents of an image. 
Image tags (e.g., labels, captions or other textual 
descriptions of an image) are a bridge to connect low-level 
features and high-level concepts. Nevertheless, the task of 
image annotation which provides image tags manually is 
generally labor-intensive. Because of the huge amount of 
images newly collected on the Internet every day, it is 
impossible to manually tag all images only by human users. 
Consequently, the focus of the image annotation problem is on 
the learning of image tags by constructing visual features and 
tags relationships [2], object recognition trying to divide an 
image into objects [16], and visual concept learning which 
consider the probability of the relationships between high-level 
concepts and low-level visual feature composition [10]. By 
using such relationships, an image retrieval system can collect 
similar images of an identical concept without the usage of 
manually defined meta-data. 
B. Providing Visual Suggestions 
According to the survey of relevant works, we conclude 
that most studies utilize visual suggestions merely for 
supporting data queries, or more specifically, image retrieval. 
When a user enters the query terms, some relevant images 
could be shown to help him or her refine the query. He or she 
can thus choose a desirable image (which matches the query 
target more) so that another set of query results can be 
generated based on the original query terms and the selected 
image [17]. Also, visual suggestions can be realized by the 
relevance feedback technique. After the query results are 
shown, a user can choose some query results which they feel 
interesting as the feedback [7]. 
For our purpose of support the news browsing process in 
this work, we propose to present visual suggestions as the 
additional information. A similar concept of helping people to 
filter out redundant information and to make proper decisions 
is the usage of recommendation systems in many e-commerce 
websites. Examples include recommending books, CDs, and 
gifts at Amazon.com [8]. Typically, user preferences can be 
estimated based on ratings provided by the users in the past. 
For our purpose of providing visual suggestions, image 
contents can also be included for estimating user preferences 
and generating recommendations [1]. 
For generating visual suggestions, techniques of calculating 
image similarities and image clustering are usually required. 
Image similarities can be calculated by measuring the 
differences of either features or tags or corresponding images. 
On the other hand, the aim of an image clustering technique is 
to partition images into groups such that images within the 
same group are similar to each other whereas images in 
different groups are dissimilar [15]. 
III. PROVIDING VISUAL SUGGESTIONS IN READING NEWS 
ARTICLES 
Fig. 2 shows the proposed scheme for generating visual 
suggestions. This scheme works when a user starts to browse 
news articles. Specifically, our approach is designated to be 
separated into two parts. First, we download images from a 
news website. Then, we extract features from news images and 
197
 
Fig. 3.  An example topic map that shows the relevance among several 
keywords. 
IV. PROTOTYPE IMPLEMENTATION AND USE CASES 
To evaluate the feasibility of the proposed scheme, a 
prototype system is developed in Section IV.A. Furthermore, 
some use cases are explored in Section IV.B. 
A. Prototype Implementation 
To conduct the search of current news articles and to record 
browsed ones by a user, we propose to develop a prototype 
system as a middleware between the user and the news sources, 
e.g., BBS News and CNN.com. Also, our prototype system is 
web-based for users to easily interact with. For simple 
implementation, we use the Google Web Search API [4] to 
search for news articles as required by a user. Also, to present 
the visual suggestions, we use both the PHP and JavaScript 
languages and MySQL databases to implement the user 
interface and required functionalities. 
Our experimental process is depicted in Fig. 4. The upper 
part indicates the analyzing steps when a user browses some 
news articles. As mentioned in Section III, feature vectors are 
firstly extracted from an accompanying image of a news article. 
Then, visual words are formed after the step of feature 
quantization. Finally, groups of news events are constructed 
after the images are clustered. 
The lower part of Fig. 4 indicates the online analyzing steps 
when a user is currently reading a news article. Note that these 
analyzing steps are identical to the ones shown in the upper 
part of Fig. 4. After the image of the current article is 
transformed into a list of visual words, the matching process 
starts to calculate the similarities between this image and 
previous ones. If any matched news events are found, they are 
presented to be the suggestions for this user. Otherwise, if there 
is no similar news event in the database, currently relevant 
news are listed instead. Note that in such cases, the relevance is 
calculated through the similarity of text segments or indicated 
by the search engine. 
B. Use Cases 
As shown in Fig. 5, there are four frames in the user 
interface of our prototype system. The lower left frame is to 
present search results after a user enters some keywords. In 
other words, our prototype system redirects the query request 
to the search engine, i.e., Google, through the use of its API, 
and delivers search results, i.e., news articles matching the 
specified keywords, to the user. Once the user clicks on a news 
article, the full contents are then shown in the upper right frame 
for him or her to read. The lower right frame is to present 
suggestions if some previously read articles are found to be 
similar with the current one. 
The example scenario shown in Fig. 5 is that a user is 
reading several news articles on a typhoon. Some articles are 
reporting the damage and death toll. Some others are reporting 
the latest weather forecasts. Some more others are reporting 
school and work suspensions. Note that a suggestion which 
shows an image of disaster recovery scene is shown in the 
lower part of Fig. 5 for further reading. The user may thus 
recall and associate a previous event that is happened in several 
years ago. 
 
 
 
Fig. 4.  Our experimental process with an illustrative example. 
199
國科會補助計畫衍生研發成果推廣資料表
日期:2013/01/31
國科會補助計畫
計畫名稱: 建構情報式網頁搜尋之使用者行為模式與探索歷程
計畫主持人: 鄧維光
計畫編號: 100-2221-E-006-261- 學門領域: 資料庫系統及資料探勘
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
