 I
一、 中文摘要 
 
資料庫技術的廣泛運用與經年累月的資料紀錄，形成許多資料庫也具有序列的型式。
不論是銷售交易序列、基因序列資料庫等，序列本身多數也帶有「類別」的標籤。過去的
序列探勘，多數忽略類別標籤以簡化探勘的複難度。但在各個類別中的序列其特性並不相
同，使用單一的最小支持度並無法找到類別資訊。因此，對於帶有類別標籤的序列型態資
料，必須設計新的探勘方法，作進一步的分析處理。傳統的分類技術主要著重於從不同類
別的資料挑選出具有代表性的特徵，作為分類的基礎。即便是近年的關聯式分類器，因為
不考慮前後的順序關係，對於序列資料來說還是不能夠很有效的分類。要改善序列型態資
料的分類準確度，序列的分類必須要考慮序列型態資料中，具頻繁序列這種共通特性的資
訊。針對大型、具有順序關係或時間關係、帶有類別標籤的序列型態資料庫，目前並未有
系統化、考慮項目集先後關係的有效序列分類技術。因此，如何設計出一個大型序列資料
的分類與發展相關的序列預測技術，就變得很重要。本計畫對於具類別標籤、序列型態資
料庫，以找出的頻繁序列為基礎並，建構一個高效能的序列分類器。為了讓最小支持度門
檻值能夠符合不同的資料特性，我們設計一個自動判斷最小支持度門檻值的方法，並移除
衝突的規則，再從中挑選出有用的規則並利用不同的策略來預測未知類別的序列資料。實
驗結果顯示，我們的方法對分類大型序列資料可以達到良好的效果。在本計畫研發過程中，
對於同樣具有序列型態的資料串流，同時開發出各種高頻串流樣式探勘方法。 
關鍵詞：資料探勘、循序樣式、序列分類、序列預測、大型序列型態資料 
 III
目錄 
一、 中文摘要……………………………………………………………………I 
二、 英文摘要…………………………………………………………………...II 
三、 報告內容…………………………………………………………………...1 
I. 前言…………………………………………………………………………………..1 
II. 研究目的 …………………………………………………………………………..2 
III. 文獻探討……………………………………………………………………………3 
IV. 研究方法…………………………………………………………………………….4.  
V. 結果與討論…………………………………………………………………………7 
四、 參考文獻……………………………………………………………………13 
五、 計畫成果自評………………………………………………………………18 
六、 附錄…………………………………………………………………………19 
 
 2
II. 研究目的  
The objective of the research is to have an accurate classifier for a large scale of 
sequence data. In order to increase the accuracy of the prediction, the frequent patterns in the 
sequence data are mined for the construction of the classifier. The minimum support 
thresholds used to discover the patterns are automatically determined by the data 
distributions of the sets of classes.  
The training set contains many data sequences; each data sequence is an order sequence 
of item-sets associated with a class label. The sequence classifier will resolve the conflicts 
among matched rules and predict the class labels of the data sequences in the test set, or in 
the future data set.  
The objective is to have a sequence classifier of high quality, i.e. high prediction 
accuracy. In addition, the time for classifying data (predicting the label) must be acceptable 
by the user, even for a large volume of the sequence data. In addition, various strategies 
should be incorporated for the requirements of high accuracy. 
 
III. 文獻探討 
Algorithms for classifications can be generally categorized into methods using decision 
trees, support vectors machine (SVM), bayesian networks, neural networks, and those based 
on discovered frequent patterns. Several association-based classifiers, which use frequent 
patterns as the classification basis, have been presented. Theses classifier first mine a set of 
high-confidence rules satisfying a user-specified minimum support and confidence threshold, 
and then use various sequential-covering-based schemes to select a set of high-quality rules 
as the associative classifiers. Many studies show that associative classifiers generally have 
higher accuracy than the other methods. Classifiers that based on frequent patterns are 
discussed in detail in the following.  
In general, the frequent patterns can be specified as frequent items or itemsets. Four 
classification algorithms, including CBA, CMAR, CPAR and MTNT are characterized in the 
use of frequent itemsets for the classifiers. The four typical associative classifiers are briefly 
reviewed.  
CBA was the first algorithm that used association-rules for classification. CBA uses 
Apriori-like association rules mining approach to generate association rules for classification. 
Usually, a large number of frequent itemsets is generated and then the rules are generated. 
The efficiency of CBA heavily relies on the process of generating frequent itemsets. Like 
conventional association rules, classification rules are generated based on all the frequent 
itemsets generated. Then these rules are sorted according to a filtering measure of certain 
precedence priorities. 
CMAR algorithm extends an efficient frequent pattern mining method, FP-growth, 
construct a class distribution-associated FP-tree. CMAR mines class-association rules by 
finding the frequent itemset and construct an FP-tree first. Based on F-list, the set of 
class-association rules can be divided into subsets without overlap. CMAR find the subset of 
rules having node, and all nodes are merged into their parent nodes. The class label as well as 
 4
IV. 研究方法 
We propose a algorithm that uses frequent sequences for the construction of the 
high-accurate sequence classifier. The construction of the classifier can be described by two 
phases, the discovery of sequential patterns and the removal of conflict rules having the 
same patterns. The proposed algorithm is named SPACL (Sequential PAttern based 
CLassifier). In the first phase, METISP is used to mine all the sequential patterns from the 
training data. The mining is applied to data sets of different classes, respectively. Then, a 
preliminary rule set for individual class is generated by collecting the discovered patterns in 
the set of data sequences. The rule in the preliminary rule set for class labeled C can be 
represented by s Æ C, where s is a sequential pattern and C is the class label. The sequential 
patterns are those sequences having support at least the minimum support threshold in that 
class. In the second phase, the conflict rules from the preliminary rule sets are removed. The 
resulting set of collected rules is used in the prediction afterward. 
The problem of building a sequence classifier is to construct a classification model, 
using the data sequences with class labels. The classification model contains many sequence 
rules. A sequence rule, abbreviated as SR, is the form of s Æ C, where s is a sequential 
pattern and C is a class label. The class label of a data sequence can be predicted by the 
sequence classifier. However, the labels of some instances (data sequences) may not be 
decidable if their characteristics are not captured in the classifier. In this case, the instance is 
un-classified. Sometimes, the unclassified instances are categorized as misclassification 
(wrong classification). If the data sequence with a class label is predicted to be the same 
class label, the classification is correct. The number of correct classifications divided by the 
total number of instances is defined the accuracy of the classifier. The coverage of a 
classifier refers to the fraction of the number of classified instances (either correct or 
incorrect) to the total number of instances. The objective is to build a classifier with high 
accuracy, and use the classifier for predicting the class labels of unknown data sequences. 
The sequential patterns discovered in different sets of classes are collected to construct the 
set of predicting rules. The training data, which contain class labels, is first mined to discover 
the sequential patterns. Each data-set of a class is mined with an automatically- determined 
support threshold. The mechanism of automatic support determination is described later. The 
sequence rules are collected from each set and the conflict sequence rules are pruned. The 
useful sequence rules, i.e. rules that are really applied to the classification of the training data, 
are selected to form the basis of the classifier. The training data is classified using this 
classifier and the coverage of the classifier is computed. If the coverage is over a 
pre-determined fraction, or the coverage is a ‘locally maximum’ value, the classifier is 
constructed. Otherwise, the minimum supports are adjusted, and then the mining of patterns, 
pruning of conflict rules, selection of useful rules, and the coverage computation are 
re-applied. Such a process is iterated until the coverage reaches a ‘local maximal’. The 
adjustment of support threshold is systematically conducted, rather than a random testing of 
all possible values. Thus, the resulting coverage is a local maximum value, not necessary a 
global maxima. Figure 1 shows an overview of the proposed algorithm. 
 6
class label and treat as a set of rule and use them to classification sequence data. 
In order to solve the problem that any two conflicting rules may lead to 
mis-classification of a single object, conflicting rules are resolved by comparing their 
support count and retrained rule which has the maximal value. 
A training data set often generates a huge set of rules. It is challenging to store, retrieve, 
prune, and sort a large number of rules efficiently for classification. In order to got more 
useful rules for classification, in this section we propose two strategies of select rules, 
P-rules only and both P-rules and N-rules. So, we can choose representative rules of each 
sequence for classification and reduce the rule space. But we don’t know which ones rule 
are useful. In the mining sequential patterns domain, the more length of sequential patterns 
and the less frequency they are. So, the more length of sequential patterns can represent 
some data. Before selecting rule, we sort the rule decently based on their length. In order to 
selecting useful sequence rules which represented the training data. For each sequence of 
training data, found the containing longest sequence rules. The containing count used to 
record the sequence rule cover count. When the class label of sequence is equal to sequence 
rule, the cover count added by one. On the contrary, when the class label of sequence is 
different to sequence rule, the containing count decreased by one. If the value of cover count 
is more than zero, the sequence rule is P-rule. It means that the sequence rule has correct 
classify times more than incorrect times. On the contrary, if the value of cover count is 
smaller than zero, the sequence rule is N-rule. It means that the sequence rule has correct 
classify times less than incorrect times. In the selecting useful domain, we proposed two 
strategies, P-rule only and both positive and N-rules. 
After a set of sequence rules is selected for classification, SPACL ready classify new 
objects. Given a new sequence data object, SPACL collects the subset of sequence rule 
contained by the new object for classification. If S is the new sequence data without class 
label, SRi are the set of sequence rule , C is the class label set (i.e. c1, c2, c3...etc.), i=n, …, 
1, |SRn|> |SRn-1|> …|SR1| and SRn is the longest sequence rule, the score of the C with S 
denoted by CSC(S, C)= ∑SC(S, SRi) 
Trivially, if a sequence rule contained by the new sequence data, and they have the same 
length, SPACL just simply assigns that sequence rule’s label to the new sequence data. If we 
can not find a sequence rule consistent with the new sequence data, SPACL presents two 
methods to determine the class label of the new sequence data. We may use top three rules 
or the top one rule as reference in the prediction strategy. Thus, four strategies are formed 
used in the prediction of class labels. the score function in TOP3 is CSC(S, C)= ∑SC(S, 
SRi), i=n, n-1, n-2, and we compared the scores of class label 1(C1) and class label 2(C2). 
The score function in TOP 1 is CSC(S, C)= ∑SC(S, SRi), i=n. 
Summarizing the predicting strategies, four strategies top-3+P-rule (T3P), top-1+P-rule 
(T1P), top-3+ P-rule and N-rule (T3PN) and top-1+ P-rule and N-rule (T1PN) are formed. 
In order to obtain the frequent sequences in the database for the construction of the 
sequence classifier, the minimum support must be specified effectively. If a fixed threshold 
is used for every dataset, the frequent patterns discovered may not be able to capture the 
 8
not. The Viewed Brand is used as the class label. The Viewed Brand includes 
“AmericanEssentials”, “DonnaKaran”, “Hanes” and “Others”. The data set was first 
partitioned into two class labels, “others” and “Has-brand: Any sequence having the Viewed 
Brand“. For classifications with multiple class labels, partition the click data into sixteen 
class labels based on the three brands such as AmericanEssentials, DonnaKaran, Hanes and 
Others. We use the experimental results to determine what product the customer bought after 
he viewed some websites. 
Table 1: Parameters used in the experiment 
Parameter Description 
|DB| Number of data sequences in database DB 
|C| Average number of transaction per data-sequence 
|T| Average number of items per transaction 
|S| Average size of potentially sequential patterns 
|I| Average size of potentially frequent itemsets 
NS Number of maximal potentially sequential patterns 
NI Number of maximal potentially frequent itemsets 
N Number of items 
 
Table 2: Parameters setting of various databases 
Database |C| |T| |S| |I| N |DB| 
DB1 10 2.5 4 1.25 10k 
DB2 1
5 
2.5 4 1.25 10k 
DB3 10 5 4 1.25 10k 
DB4 10 2.5 8 1.25 10k 
DB5 10 2.5 4 2.
5 
10k 
 
 
100k 
 
The request time is transformed into appropriate form for mining. The Table 3 gives the 
detail information of the Gazelle data. Additionally, the maximum sequence length and 
maximum session size are 628 and 267, respectively. The maximal session number in a data 
sequence is 140. 
For SPACL, we set coverage threshold form 80% to 99%. All reports of the best 
coverage threshold, runtime and accuracy include five datasets. Table 4 shows that, the 
accuracy, the best coverage threshold which got the highest accuracy and the average 
classifying time of one sequence data on different five datasets. The T3PN can get the 
highest accuracy of the others methods, but it takes more time. 
The results of changing minimum support and coverage are shown in Figure 2 and 
Figure 3. It shows that T3PN, T3P, T1PN and T1P. T3PN can gain the best accuracy, 
because it considered rules more than the others methods. 
 
 10
 
Figure 2: Accuracy of varying minimum support on C10T2.5S4I1.25D100K 
 
Figure 3: Accuracy of varying minimum support on C15T2.5S4I1.25D100K  
Table 5: Comparison of accuracy, coverage threshold and runtime on different datasets 
based on T3PN 
 
The scalability of SPACL for synthetic data C10T2.5S4I1.25 from D100K to D200K is 
verified. Figure 4 shows that the accuracy is stable as the number of data sequences increase. 
 12
dataset. After the collection of patterns, an efficient conflict rule resolution and selection 
mechanism altogether constructs the rule bases for the classifier. The performance of the 
sequence classifier is evaluation with both synthetic and real data sequences. The SPACL can 
handle sequence data having two or more class labels. In average, the accuracy of the 
classification may reach 62%. The proposed method can be used to predict the class labels of 
large scale sequence data.
 14
Patterns with Time Constraints in a Mobile Commerce Environment," 2006 INFORMS 
International Conference, Hong Kong, Jun. 2006. [NSC94-2213-E-035-012] 
(II) 學生畢業論文 
1. 陳明宏，Classification Algorithms of Large Scale Sequence Data Based on 
Sequential Patterns，碩士論文，96 年。[NSC95-2221-E-035-114] 
2. 王重義，Enhanced Variable Support Mining for Frequent Itemsets over Data 
Streams，碩士論文，96 年。[NSC95-2221-E-035-114] 
3. 黃聖坤，Efficient Mining of Frequent Patterns in Data Streams with Variable Support 
Thresholds，碩士論文，95 年。[NSC94-2213-E-035-012] 
4. 張家汶，Efficient Algorithms for Mining Sequential Patterns with Time 
Constraints，碩士論文，95 年。[NSC94-2213-E-035-012] 
 
(III) 計畫參考文獻 
[1]  R. Agrawal, R. Srikant, “Mining Sequential Patterns,” Proceedings of International 
Conference on Data Engineering, 1995, pp. 3-14. 
[2]  M.-L. Antonie, O. R. Zaïane, “An associative classifier based on positive and negative 
rules,” Proceedings of the 9th ACM SIGMOD Workshop on Research Issues in Data Mining 
and Knowledge Discovery 2004, pp. 64-69. 
[3]  C. M. Andorf, D. Dobbs, V. Honavar, “Discovering Protein Function Classification 
Rules from Reduced Alphabet Representations of Protein Sequences,” Proceedings of the 
6th Joint Conference on Information Science, pp. 1200-1206. 
[4]  J. Ayres, J. Flannick, J. Gehrke, and T. Yiu, “Sequential PAttern mining using a bitmap 
representation,” Proceedings of the ACM SIGKDD International Conference on knowledge 
discovery and Data Mining 2002, pp. 429-435. 
[5]  E. Baralis, S. Chiusano, P. Garza, “On support thresholds in associative classification,” 
Proceedings of the 2004 ACM Symposium on Applied Computing, pp. 553-558. 
[6]  J. B. D. Cabrera, L. M. Lewis, R. K. Mehra, “Detection and Classification of Intrusions 
and Faults using Sequences of System Calls,” SIGMOD Record 30(4), pp. 25-34 (2001). 
[7]  Y.-L. Chen, S.-S. Chen, P.-Y. Hsu, “Mining hybrid sequential patterns and sequential 
rules,” Information Systems 27(5), pp. 345-362 (2002). 
[8]  Y. L. Chen, , M. C. Chiang and M.T. Kao, “Discovering time-interval sequential 
patterns in sequence databases,” Expert Systems with Applications, Volume 25, Issue 3, 
October 2003, Pages 343-354. 
[9]  N. A. Chuzhanova, A. J. Jones, S. Margetts, “Feature selection for genetic sequence 
classification,” Bioinformatics 14(2), pp. 139-143 (1998). 
[10]  K. Crosby, P. Gabbert, “BioSPRINT: Classification of Intron and Exon Sequences 
Using the SPRINT Algorithm,” 3rd International IEEE Computer Society Computational 
 16
Advances in Knowledge Discovery and Data Mining 2002, pp. 198-209. 
[26]  A. H. Liu, A. Califano, “Functional classification of proteins by pattern discovery and 
top-down clustering of primary sequences,” IBM Systems Journal 40(2), pp. 379-393 
(2001). 
[27]  Y. Lu, C. I. Ezeife, “Position Coded Pre-order Linked WAP-Tree for Web Log 
Sequential Pattern Mining,” Pacific-Asia Conference on Advances in Knowledge Discovery 
and Data Mining 2003, pp. 337-349. 
[28]  Q. Ma, J. T.-L. Wang, “Application of Bayesian Neural Networks to Protein Sequence 
Classification,” Proceedings of the International Conference on Artificial Intelligence 1999, 
pp. 530-536. 
[29]  B. Mobasher, H. Dai, T. Luo, M. Nakagawa, “Using Sequential and Non-Sequential 
Patterns in Predictive Web Usage Mining Tasks,” Proceedings of the IEEE International 
Conference on Data Mining 2002, pp. 669-672. 
[30]  B. Olsson, K. Laurio, “Towards a comprehensive collection of diagnostic patterns for 
protein sequence classification,” Information Sciences. 143(1-4), pp. 1-11 (2002). 
[31]  J. Pei, J. Han, B. Mortazavi-Asl, J. Wang, H. Pinto, Q. Chen, U. Dayal, M.-C. Hsu, 
“Mining Sequential Patterns by Pattern-Growth: The PrefixSpan Approach,” IEEE 
Transactions on Knowledge and Data Engineering 16(11), pp. 1424-1440 (2004). 
[32]  J. Pei, J. Han, B. Mortazavi-Asl, H. Pinto, Q. Chen, U. Dayal, M. Hsu, “PrefixSpan: 
Mining Sequential Patterns by Prefix-Projected Growth,” Proceedings of International 
Conference on Data Engineering, 2001, pp. 215-224. 
[33]  J. Pei, J. Han, W. Wang, “Mining sequential patterns with constraints in large 
databases,” Proceedings of the ACM CIKM International Conference on Information and 
Knowledge Management 2002, pp. 18-25. 
[34]  H. Pinto, J. Han, J. Pei, K. Wang, Q. Chen, U. Dayal, “Multi-Dimensional Sequential 
Pattern Mining,” Proceedings of the ACM CIKM International Conference on Information 
and Knowledge Management, pp. 81-88. 
[35]  W. Pijls and R. Potharst, “Classification based upon Frequent Patterns,” Advances in 
Artificial Intelligence, PRICAI-2000, LNAI 2112, pp. 72-79, 2001. 
[36]  S. R. Ray, W. H. Hsu, “Self-Organized-Expert Modular Network for Classification of 
Spatiotemporal Sequences,” Intelligent Data Analysis 2(1-4), pp. 287-301 (1998). 
[37]  S.-J. Song, Z. Huang, H. Hu, S.-Y. Jin, “A Sequential Pattern Mining Algorithm for 
Misuse Intrusion Detection,” International Workshops on Grid and Cooperative Computing 
2004, pp. 458-465. 
[38]  R. Srikant, R. Agrawal, “Mining Sequential Patterns: Generalizations and Performance 
Improvements,” 5th International Conference on Extending Database Technology, pp. 3-17. 
[39]  F. A. Thabtah, P. I. Cowling, Y. Peng, “MMAC: A New Multi-Class, Multi-Label 
Associative Classification Approach,” Proceedings of the 4th IEEE International 
Conference on Data Mining 2004, pp. 217-224. 
[40]  P. A. Vijaya, M. N. Murty, D. K. Subramanian, “An Efficient Technique for Protein 
Sequence Clustering and Classification,” International Conference on Pattern Recognition 
 18
五、 計畫成果自評  
 
本計畫的預期目標是研發具類別標籤、序列型態資料庫探勘技術，並以找出的頻繁序
列為基礎，整合設計序列分類器，建構應用於交易資料庫序列等真實序列型態資料的序列
預測系統。 
經深入探討與設計後，我們提出具有高效能的循序樣式探勘與分類方法，適合於探勘
大型的具有類別標籤的序列型態資料庫，也建構出序列類別的預測方法，透過對於模擬資
料的大型實驗，以及真實的網頁點選序列資料庫類別預測實驗，驗證所研發之技術與方法。
本計畫的研究內容與原計畫目標完全相符，也達成計畫所預期之目標。同時，參與計畫的
多位研究生也獲得許多設計與研究的經驗。此外，我們也在研究序列分類方法的過程中，
完成在資料串流環境下（序列型態）高頻樣式可以變動支持度的探勘方法、可以用在行動
環境下分析使用者序列服務行為樣式、廣義關聯規則以及序列規則的探勘等等。 
本計畫之研究成果，除了 4 位碩士生的畢業論文外，另有已發表之會議與期刊論文共
7 篇，其中 3 篇為 SCI/EI 索引論文、1 篇為 EI 索引論文。本研究成果完整之內容與理論
的推演證明部分也正在補足，待補足後，也將會投稿至知名國際期刊。 
本研究不僅具有學術價值，也能應用至實務面。綜合而言，本研究成果與計畫目標高
度契合。 
 
JOURNAL OF INFORMATION SCIENCE AND ENGINEERING XX, 1-xxx (xxxx) 
1 
Mining Closed Sequential Patterns with Time Constraints 
 
MING-YEN LIN, SUE-CHEN HSUEH+, AND CHIA-WEN CHANG 
Department of Information Engineering and Computer Science 
Feng Chia University 
Taichung 40724 Taiwan 
+Department of Information Management 
Chaoyang University of Technology 
Taichung 41349 Taiwan 
 
 
The mining of closed sequential patterns has attracted researchers for its capability 
of using compact results to preserving the same expressive power as traditional mining. 
Many studies have shown that constraints are essential for applications of sequential pat-
terns. However, time constraints have not been incorporated into closed sequence mining 
yet. Therefore, we propose an algorithm called CTSP for closed sequential pattern min-
ing with time constraints. CTSP loads the database into memory and constructs 
time-indexes to facilitate both pattern mining and closure checking, within the pat-
tern-growth framework. The index sets are utilized to efficiently mine the patterns with-
out generating any candidate or sub-database. The bidirectional closure checking strategy 
further speeds up the mining. The comprehensive experiments with both synthetic and 
real datasets show that CTSP efficiently mines closed sequential patterns satisfying the 
time constraints, and has good linear scalability with respect to the database size. 
 
Keywords: sequential pattern, closed sequential pattern, time constraint, memory index, 
sequence mining 
 
 
1. INTRODUCTION 
 
Sequential pattern mining [1, 2, 5, 14], which discovers frequent sub-sequences in 
a sequence database, is becoming an active research topic for its wide applications in-
cluding customer behavior analysis [8, 9], web usage mining [6], DNA sequence analy-
sis, etc. The discovered sequential patterns disclose not only the frequent items or events 
occurred together, but also the sequences of frequently appeared item-sets or events. 
Many studies have shown that specifying constraints may increase the accuracy of 
mining results in practice. Various constraints, such as item, length, super-pattern, dura-
tion, and gap, can be specified to find more desirable patterns. Some constraints can be 
handled by a post-processing on the result of mining without constraints. However, time 
constraints affect the support computation of patterns so that they cannot be handled 
without adapting time attributes into the mining algorithms.  
The issue of mining sequential patterns with time constraints was first addressed in 
[15]. Three time constraints including minimum gap, maximum gap and sliding 
time-window are specified to enhance the semantics of sequence discovery. For example, 
in a retail application, a discovered sequential pattern may be <(TV)(Audio, Jukebox)> 
 
* This paper was supported by the National Science Council of the Republic of China under research grant 
NSC95-2221-E-035-114. 
CLOSED SEQUENTIAL PATTERNS WITH TIME CONSTRAINTS 
 
3 
 
2. PROBLEM STATEMENT 
Let Ψ = {α1, α2, …, αr} be a set of literals, called items. An itemset I = (β1, β2, …, 
βq) is a nonempty set of q items such that I ⊆ Ψ. A sequence s, denoted by <e1e2…ew>, is 
an ordered list of w elements where each element ei is an itemset. Without loss of gener-
ality, we assume the items in an element are in lexicographic order. The length of a se-
quence s, written as |s|, is the total number of items in all the elements in s. Sequence s is 
a k-sequence if |s| = k. The sequence database DB contains |DB| data sequences. A data 
sequence ds has a unique identifier sid and is represented by <t1e1’ t2e2’ … tnen’>, where 
element ei’ occurred at time ti , t1 < t2 < ...< tn.  
A sequence s in the sequence database DB is a time-constrained sequential pattern 
(abbreviated as time-pattern) if s.sup ≥ minsup, where s.sup is the support of the se-
quence s and minsup is the user specified minimum support threshold. The support of 
sequence s is the number of data sequences containing s divided by |DB|. Note that the 
support calculation has to satisfy three time-constraints maxgap (maximum gap), mingap 
(minimum gap), and swin (sliding window). A data sequence ds = < t1e1’ t2e2’ … tnen’> 
contains a sequence s = <e1e2…ew> if there exist integers l1, u1, l2, u2, …, lw, uw and 1 
≤ l1 ≤ u1 < l2 ≤ u2 < …< lw ≤ uw ≤ n such that the four conditions hold: (1) ei ⊆(eli’
∪…∪eui’), 1 ≤ i ≤ w (2) tui - tli ≤ swin, 1 ≤ i ≤ w (3) tui - tli-1 ≤ maxgap, 2 ≤ i ≤ w (4) tli - 
tui-1 ≥ mingap, 2 ≤ i ≤ w. Assume that tj, mingap, maxgap, swin are all positive integers, 
maxgap ≥ mingap ≥ 1. Data sequence ds is a supersequence of sequence s (s is a subse-
quence of ds) if ds contains s. When mingap is the same as maxgap, the time constraint 
is additionally called exact gap. Common sequential pattern mining without time con-
straints is a special case by setting mingap = 1, maxgap = ∞, swin = 0.  
A sequence s is closed if no contiguous supersequence ssup with the same support 
exists. Given a sequence s = <e1e2…ew> and a subsequence ssub of s, ssub is a contiguous 
subsequence of s if ssub can be obtained by any one of following ways: (1) dropping an 
item from either e1 or ew (2) dropping an item from element ei (1 ≤ i ≤ w) which has at 
least two items (3) ssub is a contiguous subsequence of ssub’, and ssub’ is a contiguous sub-
sequence of s. Additionally, s is called a contiguous supersequence of ssub. A sequence s 
is a closed time-constrained sequential pattern, abbreviated as closed time-pattern, if it is 
a time-pattern and is closed. The mining aims to discover the set of all closed 
time-patterns. 
For example, given a sequence database DB of four data sequences with their sids 
in Table 1, the rightmost column shows the closed time-patterns for constraints mingap = 
3, maxgap = 15, swin = 2, and minsup = 50%. In Table 1, data sequence C4 
<5(a)10(d)21(c, d)> has three itemsets occurring at time 5, 10, 21, respectively. The third 
itemset of C4 has two items c and d. Sequences <(a,c)(b)> and <(b)(e)(d)> are both 
3-sequences. The sequence <(a,c)(b)> is contained in data sequences C1 <3(c)5(a, 
f)18(b)31(a)45(f)> because element (a,c) can be contained in the transaction combining 3(c) 
and 5(a, f) for 5-3≤ 2 (swin). Meanwhile, the mingap and maxgap constraints are satis-
fied for 18-5 ≥ 3 and 18-3 ≤ 15. Similarly, <(a,c)(b)> is contained in C2. The support of 
<(a,c)(b)> is 2/4 and it is a time-pattern for minsup = 50%. <(a,c)(b)> is also a closed 
time-pattern since it has no contiguous supersequence with the same support. <(c)(b)> is 
a time-pattern for <(c)(b)>.sup = 2/4 but not closed for its contiguous supersequence 
<(a,c)(b)> having the same support. 
CLOSED SEQUENTIAL PATTERNS WITH TIME CONSTRAINTS 
 
5 
 
 
mingap
ds
FEP
lsti leti
(1) type-1 pattern
maxgap
lsti leti swin
FEP
ds
(2) type-2 pattern
swin
Definition 3: (last-start time, last-end time, time-index) Let the last element of a fre-
quent pattern P be LE. If ds contains P by having LE ⊆eγ ∪eγ+1∪ …∪eω, where eγ,…, eω 
are elements in ds, the occurring time tγ and tω for itemsets eγ and eω are named, respec-
tively, last-start time (abbreviated as lst) and last-end time (abbreviated as let) of P in ds. 
Every occurrence of the lst:let pair is collected altogether as [lst1:let1, lst2:let2,…, lstk:letk], 
lsti ≤ leti for 1≤i≤k. Such a timestamp lists is called the time-index of P in ds. 
In addition to stems, items in the backward direction of a frequent pattern P, i.e. 
occurring before P, may be used to form P’ and speed up the mining process. For exam-
ple, P = <(a)(b)> is contained in s = <2(e)6(a, c)10(b, d)18(a)> with time-index [6:10]. 
Stem (a) (timestamp 18) may extend P to a type-1 pattern <(a)(b)(a)> and stem (d) (time-
stamp 10) may extend P to a type-2 pattern <(a)(b, d)> in the forward direction. Consid-
ering the (a) in P, item (e) (timestamp 2) and item (c) (timestamp 6) can be used to form 
contiguous supersequences <(a, c)(b)> and <(e)(a)(b)>, respectively. The two non-stem 
items are found in the backward direction of P. Thus, we have the following definition. 
Definition 4: (extension item, extension period) Given a frequent pattern P contained 
in ds, a non-stem item α in ds is called an extension item (abbreviated as EI) if it can be 
used in extending P to form a contiguous supersequence P’ satisfying the time con-
straints. The time periods within which α exists is called extension period (abbreviated 
as EP). The time period is referred to as backward extension period (abbreviated as BEP) 
and the item is called backward extension item (abbreviated as BEI). For convenience, 
we refer to the time period within which stems exist as forward extension period (abbre-
viated as FEP). 
Lemma 1: Given a time-index of frequent pattern P in ds [lst1:let1, lst2:let2,…, lstk:letk], 
the FEP satisfies either one of the following conditions: (1) ∃ i, 1 ≤ i ≤ k, leti+mingap ≤ 
FEP ≤ lsti+maxgap (2) ∃ i, 1 ≤ i ≤ k, leti-swin ≤ FEP ≤ lsti+swin. Fig. 1 illustrates 
Lemma 1. 
Fig. 1. The forward extension period for (a) type-1 pattern and (b) type-2 pattern. 
 
Fig. 2. The timelines of <(a)(d)(e)> in <5(b)9(a)13(d)14(c)16(e)19(e)>. 
 
Definition 5: (timeline) Given a frequent pattern P = <e1…er…ew> in ds. If e1 ⊆ 
est1∪…∪eet1, …, er ⊆ estr∪…∪eetr, …, and ew ⊆ estw∪…∪eetw, where est1, …, estw, eet1, …, 
eetw are elements in ds, the list of timestamps [st1:et1, …, str:etr, …, stw:etw] where str ≤ 
etr for 1 ≤ r ≤ w is called the timeline of P in ds. 
[9:9] [13:13]
[19:19]
[16:16]
(a) (d) (e)
(e)
CLOSED SEQUENTIAL PATTERNS WITH TIME CONSTRAINTS 
 
7 
 
time-pattern. Recursively, for a newly formed type-1 pattern or type-2 pattern P’, its 
time-index set P’-Tidx is constructed and CMine(P’, P’-Tidx) is invoked. By pushing 
time attributes deeply into the mining process, CTSP efficiently discovers the desired 
patterns. 
 If the database is too large to fit into memory, a projected scheme is applied. The da-
tabase will be projected to small sub-databases, based on the frequent 1-sequences. Each 
sub-database then can be mined by the CTSP. A similar technique has been adopted in 
the Par-CSP algorithm [4]. Therefore, CTSP can mine databases, even when the size of 
the database is larger than that of main memory. 
 
Algorithm: CTSP 
Input: DB (a sequence database), minsup (minimum support), mingap (minimum gap), 
maxgap (maximum gap), swin (sliding time-window). 
Output: the set of all closed time-constrained sequential patterns 
1.  load DB into memory (as MDB) and scan MDB once to find all frequent items. 
2. for each frequent item x,  
(1) form the sequential pattern P = <(x)> 
(2) scan MDB once to construct P-Tidx, time-index set of x 
(3) call CMine(P, P-Tidx) to mine the closed time patterns. 
Subroutine: CMine (P, P-Tidx)  
Parameter: P = prefix with support count, P-Tidx=time-index set for P 
1. for each data sequence ds in the P-DB, // P-DB: sequences indicated in P-Tidx  
  (1) use Lemma 1 to collect the FEPs of type-1 and type-2 patterns, respectively. 
(2) for each item in the FEPs of type-1 and type-2 patterns, add one to its support 
count, respectively. 
2. if any support count of a stem is equal to the support count of P, then P is not closed. 
Otherwise output P if Backward(P, P-Tidx) return “closed”. //Backward checking 
valid 
3. for each item x’ found in the FEPs of type-1 pattern and <(x)>.sup ≥ minsup, 
(1) form the type-1 pattern P’ by extending stem x’. 
(2) use Lemma 1 and the FEPs of each ds in P-DB to construct P’-Tidx, time-index set 
of x’. 
(3) call CMine(P’, P’-Tidx);    
4. for each item x’ found in the FEPs of type-2 pattern and <(x)>.sup ≥ minsup, 
(1) form the type-2 pattern P’ by appending stem x’. 
(2) use Lemma 2 and the FEPs of each ds in P-DB to construct P’-Tidx, time-index set 
of x’. 
(3) call CMine(P’, P’-Tidx); 
Subroutine: Backward (P, P-Tidx) 
Parameter: prefix P = <e1…er…ew>, P-Tidx = time-index set 
1. for each element ej in P  
(1) for each data sequence ds in the P-DB, // P-DB: sequences indicated in P-Tidx 
1.1 find the BEPs of ej in ds 
1.2 add one to the support count of the BEIs  
(2) if any support count of a BEI is equal to the support count of P, return “not closed” 
2. return “closed” 
CLOSED SEQUENTIAL PATTERNS WITH TIME CONSTRAINTS 
 
9 
 
 
Fig. 6. Results of varying maximum gap. 
 
Fig. 7. Results of varying sliding window. 
 
Fig. 8. Results of varying minimum support. 
DB100C10T2.5S4I1.25N10k, Mingap=1, Maxgap=∞, Swin=0
0
300
600
900
1200
0.35% 0.40% 0.45% 0.50% 0.75% 1.00%
Minsup
To
tal
 ex
ec
uti
on
 tim
e (
se
co
nd
s) GSP
DELISP
CTSP
DB100KC10T2.5S4I1.25N10, Minsup=0.5%
0
400
800
1200
1600
1 2 3 4
Swin
To
tal
 ex
ec
uti
on
 tim
e (
se
co
nd
s)
GSP
DELISP
CTSP
DB100kC10T2.5S4I1.25N10k, Minsup=0.5%
0
200
400
600
800
1000
2 4 6 8 10 12
Maxgap
To
tal
 ex
ec
uti
on
 tim
e (
se
co
nd
s)
GSP
DELISP
CTSP
Mingap=1, Swin=0
CLOSED SEQUENTIAL PATTERNS WITH TIME CONSTRAINTS 
 
11 
 
   
Fig. 11. Results of varying minsup with real-dataset Gazelle database with constraints. 
 
Fig. 12. Distributions of the discovered patterns with time constraints. 
Table 2. Total number of discovered patterns. 
minsup(%) 0.04 0.045 0.05 0.055 0.06 
Time-patterns 515497 153212 101222 53164 40571 
Closed Time-patterns 154724 87095 66960 41855 33898 
 
5. CONCLUSION 
 In this paper, we have presented an efficient algorithm called CTSP for mining 
closed sequential patterns with minimum/maximum gap and sliding window constraints. 
The contributions of the proposed algorithm are as follows. First, we define the closure 
of closed time-patterns. Many algorithms were proposed to discover closed patterns but 
their definitions of closure are no longer suitable for the time-constrained patterns. Our 
definition of closure is based on the contiguous supersequence so that the accuracy and 
completeness of closed time-constrained sequential patterns can be ensured. Second, to 
the best of our knowledge, no algorithm has been proposed for mining closed sequential 
Database Gazelle, Mingap=3, Maxgap=15, Swin=1
1
10
100
1000
10000
100000
1 2 3 4 5 6 7 8 9 10 11 12 13 14
Length of closed patterns
Nu
mb
er 
of
 cl
os
ed
 Pa
tte
rn
s
Minsup=0.04%
Minsup=0.045%
Minsup=0.05%
Minsup=0.055%
Minsup=0.06%
Database Gazelle
0
400
800
1200
1600
0.040% 0.045% 0.050% 0.055% 0.060%
Minsup
To
tal
 ex
ec
uti
on
 tim
e (
se
co
nd
s) GSP
DELISP
CTSP
Mingap=3
Maxgap=15
Swin=1
CLOSED SEQUENTIAL PATTERNS WITH TIME CONSTRAINTS 
 
13 
 
Vol. 21, No. 1, Jan. 2005, pp. 109-128. 
8. M. Y. Lin and S. Y. Lee, “Efficient Mining of Sequential Patterns with Time Con-
straints by Delimited Pattern-Growth,” Knowledge and Information Systems, Vol. 7, 
Issue 4, May 2005, pp. 499-514. 
9. F. Masseglia, P. Poncelet, and M. Teisseire, “Pre-Processing Time Constraints for Ef-
ficiently Mining Generalized Sequential Patterns,” Proceedings of the 11th Interna-
tional Symposium on Temporal Representation and Reasoning, France, 2004, pp. 
87-495. 
10. S. Orlando, R. Perego, and C. Silvestri, “A new algorithm for gap constrained se-
quence mining,” Proceedings of the 2004 ACM symposium on Applied computing, 
Nicosia, Cyprus, 2004, pp. 540-547. 
11. J. Pei, J. Han, B. Moryazavi-Asl, H. Pinto, Q. Chen, U. Dayal, and M.-C. Hsu, “Pre-
fixSpan: Mining Sequential Patterns Efficiently by Prefix-Projected Pattern Growth,”  
Proceedings of the 17th International Conference on Data Engineering, Heidelberg, 
Germany, April 2001, pp. 215-224. 
12. J. Pei, J. Han, J. and W. Wang, “Mining sequential patterns with constraints in large 
databases,” Proceedings of the 11th International Conference on Information and 
Knowledge Management, 2002, pp. 18-25.   
13. T. Petre, X. Yan, and J. Han, “TSP: Mining top-k closed sequential patterns,” 
Knowledge and Information Systems, Vol. 7, Issue 4, May 2005, pp. 438-457. 
14. M. Seno and G. Karypis, “SLPMiner: An Algorithm for Finding Frequent Sequen-
tial patterns Using Length-Decreasing Support Constraint,” Proceedings of the 2002 
IEEE International Conference on Data Mining, 2002, pp. 418-425. 
15. R. Srikant, and R. Agrawal, “Mining Sequential Patterns: Generalizations and Per-
formance Improvements,” Proceedings of the 5th International Conference on Ex-
tending Database Technology, Avignon, France, 1996, pp. 3-17. (An extended ver-
sion is the IBM research report RJ 9994) 
16. J. Wang, and J. Han, “BIDE: Efficient Mining of Frequent Closed Sequences,” Pro-
ceedings of the 20th International Conference on Data Engineering, Boston, March 
2004, pp. 79-90. 
17. X. Yan, J. Han, and R. Afshar, “CloSpan: Mining Closed Sequential Patterns in 
Large Databases,” Proceedings of the Third SIAM International Conference on Data 
Mining, San Francisco USA, May 1-3, 2003. 
18. M. J. Zaki, “SPADE: An Efficient Algorithm for Mining Frequent Sequences,” 
Machine Learning Journal, Vol. 42, Jan.-Feb. 2001, pp. 31-60. 
19. M. J. Zaki, “Sequence Mining in Categorical Domains: Incorporating Constraints,” 
Proceedings of the 9th International Conference on Information and Knowledge 
Management, Washington DC, Nov. 2000, pp. 422-429. 
 
  
 
 
 
 
 
 
X. Li, O.R. Zaiane, and Z. Li (Eds.): ADMA 2006, LNAI 4093, pp. 693 – 701, 2006. 
© Springer-Verlag Berlin Heidelberg 2006 
Fast Discovery of Time-Constrained Sequential  
Patterns Using Time-Indexes 
Ming-Yen Lin1, Sue-Chen Hsueh2, and Chia-Wen Chang1 
1
 Department of Information Engineering and Computer Science,  
Feng-Chia University, Taiwan 
linmy@fcu.edu.tw, m9318119@fcu.edu.tw 
2
 Department of Information Management,  
Chaoyang University of Technology, Taiwan 
schsueh@mail.cyut.edu.tw 
Abstract. Sequential pattern mining is to find out all the frequent sub-
sequences in a sequence database. In order to have more accurate results, con-
straints in addition to the support threshold need to be specified in the mining. 
Time-constraints cannot be managed by retrieving patterns because the support 
computation of patterns must validate the time attributes for every data se-
quence in the mining process. In this paper, we propose a memory time-
indexing approach (called METISP) to discover sequential patterns with time 
constraints including minimum/maximum/exact gaps, sliding window, and du-
ration. METISP scans the database into memory and constructs time-index sets 
for effective processing. Utilizing the index sets and the pattern-growth strat-
egy, METISP efficiently mines the desired patterns without generating any can-
didate or sub-database. The comprehensive experiments show that METISP 
outperforms GSP and DELISP in the discovery of time-constrained sequential 
patterns, even with low support thresholds and very large databases. 
1   Introduction 
The problem of mining sequential patterns is becoming an active research topic. A 
typical example is to find all the frequent sub-sequences in a retail database of cus-
tomer purchasing sequences. The mining results disclose not only the frequent items 
bought together, but also the sequences of frequently appeared item-sets.  
Improving the efficiency of sequence mining algorithms has been the focus of 
many studies [4, 6, 8, 10] while increasing the accuracy of mining results tends to be 
more desirable in practice. Various constraints, such as item, length, super-pattern, 
duration, and gaps, can be specified to find the interesting patterns. Many constraints 
can be handled by a post-processing on the result of sequential pattern mining without 
constraints. Nevertheless, time constraints affect the support computation of patterns 
so that they cannot be handled without modifying the mining algorithms for the con-
sideration of time attributes. 
The issue of mining sequential patterns with time constraints was first addressed 
in [3]. Three time constraints including minimum gap (abbreviated as mingap), 
maximum gap (abbreviated as maxgap) and sliding time-window (abbreviated as 
 Fast Discovery of Time-Constrained Sequential Patterns Using Time-Indexes 695 
The rest of the paper is organized as follows. The problem is formulated in Section 2. 
Section 3 presents the METISP algorithm. The experimental evaluation is described in 
Section 4. Section 5 concludes our study. 
2   Problem Statement 
Let Ψ = {α1, α2, …, αr} be a set of literals, called items. An itemset I = (β1, β2, …, βq ) 
is a nonempty set of q items such that I ⊆ Ψ. A sequence s, denoted by <e1e2…ew>, is 
an ordered list of w elements where each element ei is an itemset. Without loss of 
generality, we assume the items in an element are in lexicographic order. The length 
of a sequence s, written as |s|, is the total number of items in all the elements in s. 
Sequence s is a k-sequence if |s| = k. The sequence database DB contains |DB| data 
sequences. A data sequence ds has a unique identifier sid and is represented by <t1e1’ 
t2
e2’ … t
n
en’>, where element ei’ occurred at time ti , t1 < t2 < ...< tn. 
A user gives a parameter minsup (minimum support) and four time-constraints 
maxgap (maximum gap), mingap (minimum gap), swin (sliding window) and dura-
tion to discover the set of all time-constrained sequential patterns. A sequence s is a 
time-constrained sequential pattern if s.sup ≥ minsup, where s.sup is the support of 
the sequence s and minsup is the user specified minimum support threshold. The sup-
port of s is the number of data sequences containing s divided by |DB|. A data se-
quence ds = <t1e1’ t2e2’… tnen’> contains a sequence s = <e1e2…ew> if there exist inte-
gers l1, u1, l2, u2, …, lw, uw and 1 ≤ l1 ≤ u1 < l2 ≤ u2 < …< lw ≤ uw ≤ n such that the five 
conditions hold: (1) ei ⊆ (eli’∪…∪eui’), 1 ≤ i ≤ w (2) tui - tli ≤ swin, 1 ≤ i ≤ w (3) tui - 
tli-1
 ≤ maxgap, 2 ≤ i ≤ w (4) tli - tui-1 ≥ mingap, 2 ≤ i ≤ w (5) tuw – tl1 ≤ duration. As-
sume that tj, mingap, maxgap, swin, and duration are all positive integers, maxgap ≥ 
mingap ≥ 1. When mingap is the same as maxgap, the time gap is called exact gap. 
Table 1. Example sequences database (DB) and the time-constrained sequential patterns 
Sid Sequence Time-constrained sequential pattern (minsup=50%, 
mingap=3, maxgap=15, swin=2, duration=25) 
C1 <3(c)5(a, f)18(b)31(a)45(f)> 
C2 <6(a, c)10(b)17(e)18(a)24(c, d)> 
C3 <1(b)20(b, g)27(e)34(d, g)35(g)> 
C4 <5(a)10(d)21(c, d)26(e)> 
<(a)>, <(a)(b)>, <(a)(d)>, <(a, c)>,  
<(a, c)(b)>, <(b)>, <(b)(a)>, <(b)(d)>, <(b)(e)>, 
(b)(e)(d)>, <(c)>, <(c)(b)>, <(c)(e)>, <(c, d)>, 
<(d)>, <(e)>, <(e)(d)> 
For example, given a sequence DB in Table 1, the mingap=3, maxgap=15, swin=2 
and duration=25. The sequence <(a, c)(b)> is contained in data sequences C1 <3(c)5(a, 
f)18(b)31(a)45(f)> because element (a, c) can be contained in the transaction combining 
3(c) and 5(a, f) for 5-3≦2 (swin). Meanwhile, the other constraints can be satisfied for 
18-5≧3 (mingap), 18-3≦15(maxgap) and total time span 18-3≦25 (duration). Simi-
larly, considering sequence <(a)(b)(a)>, it can be contained in C1 for the other con-
 Fast Discovery of Time-Constrained Sequential Patterns Using Time-Indexes 697 
 
 
Input: DB (a sequence database), minsup (minimum support), mingap (mini-
mum gap), maxgap (maximum gap), swin (sliding time-window), duration 
(duration) 
Output: the set of all time-constrained sequential patterns 
1. Load DB into memory (as MDB) and scan MDB once to find all frequent 
items. 
2. for each frequent item x,  
(1) form the sequential pattern P = <(x)> and output P. 
(2) scan MDB once to construct P-Tidx, time index set of x. 
(3) call MineType1(P, P-TIdx)  
(4) call MineType2(P, P-TIdx) 
Subroutine: MineType1(P, P-TIdx) 
Parameter: P = prefix pattern, P-Tidx = time index set  
1. for each data sequence ds in the P-DB, // P-DB: sequences indicated 
in P-TIdx  
  (1) use the corresponding time index to collect the type-1 VTPs satis-
fying 
leti+mingap≤VTP≤min{lsti+maxgap, iti+duration}, 1≤i≤k 
  (2) for each item in the VTPs, add one to its support count.  
2. for each item x’ that has support greater than or equal to minsup, 
  (1) form the type-1 pattern P’ by extending stem x’ and output P’. 
  (2) scan the VTP of each ds in P-DB to construct P’-Tidx, time index 
set of x’. 
  (3) call MineType1(P,’ P’-TIdx).    
  (4) call MineType2(P’, P’-TIdx). 
Subroutine: MineType2 (P, P-TIdx) 
Parameter: P = prefix pattern, P-Tidx = time index set  
1. for each data sequence ds in the P-DB, // P-DB: sequences indicated 
in P-TIdx 
  (1) use the corresponding time index to collect the type-2 VTPs satis-
fying   
leti-swin≤VTP≤min{lsti+swin, iti+duration}, 1≤i≤ k 
(2) for each item in the VTPs, add one to its support count.  
2. for each item x’ that has support greater than or equal to minsup, 
  (1) form the type-2 pattern P’ by appending stem x’ and output P’. 
  (2) scan the VTP of each ds in P-DB to construct P’-Tidx, time index 
set of x’.  
  (3) call MineType1(P,’ P’-TIdx).    
(4) call MineType2(P’, P’-TIdx). 
 
Fig. 1. Algorithm METISP 
3.2   METISP Algorithm 
Fig. 1 outlines the METISP Algorithm. METISP mines patterns within the pattern-
growth framework similar to the pseudo projection version [10] of Prefixspan algo-
rithm, while it can handle constraints minimum/maximum gaps, duration and sliding 
time-window. Assume that the DB can fit into the main memory; METISP first loads 
DB into memory (as MDB) and scans MDB once to find all frequent items. With 
respect to each frequent item, METISP then constructs a time index-set for the 1-
sequence item and recursively forms time-constrained sequential patterns of longer 
length. The time index-set is a set of (data-sequence pointer, time index) pairs. Only 
those data sequences containing that item would be included.  
In Fig. 1, MineType1(P, P-TIdx) mines type-1 patterns having prefix P by effec-
tively locating VTPs using Lemma 1. Likewise, MineType2(P, P-TIdx) discovers  
 
 Fast Discovery of Time-Constrained Sequential Patterns Using Time-Indexes 699 
˖ ˄ ˃ ˀ˧ ˅ ˁˈ ˀ˦ ˇ ˀ ˜˄ ˁ˅ ˈ ʿ ʳ ̏˗ ˕ ̏ː˄ ˃ ˃ ˾ ʿ ʳˡ ː˄ ˃ ˃ ˃ ʿʳ̀ ˼́ ̆̈ ̃ ː˃ ˁˆ ˈʸ
˃
˅ ˃ ˃
ˇ ˃ ˃
ˉ ˃ ˃
ˋ ˃ ˃
˄ ˅ ˇ ˉ ˋ ˄ ˅
ˠ ˼́ ˼̀ ̈̀ ʳ˺ ˴ ̃
˧̂
̇˴
˿ʳ˸
̋˸
˶̈
̇˼̂
́ʳ
̇˼̀
˸ʻ
̆˸
˶ˁ
ʼ
˚ ˦ ˣ
˗ ˘˟ ˜˦ˣ
ˠ ˘˧ ˜˦ˣ
˖ ˄ ˃ ˀ˧ ˅ ˁˈ ˀ˦ˇ ˀ˜˄ ˁ˅ ˈ ʿ ʳ ̏˗ ˕ ̏ː˄ ˃ ˃ ˾ ʿʳˡ ː˄ ˃ ˃ ˃ ʿʳ̀ ˼́ ˺ ˴ ̃ ː˅ ʿ ʳ̀ ˴ ̋ ˺ ˴ ̃ ːˋ ʿ
̆̊ ˼́ ː˄
˃
˄ ˃ ˃
˅ ˃ ˃
ˆ ˃ ˃
ˇ ˃ ˃
ˈ ˃ ˃
1 / 4 6 & 1 / 6 1 & 1 / 8 6 & 2 & 2 / 6 1 & 3 &
ˠ ˼́ ˼̀ ̈̀ ʳ̆̈ ̃ ̃ ̂ ̅̇
˧̂
̇˴
˿ʳ˸
̋˸
˶̈
̇˼̂
́ʳ
̇˼̀
˸ʳ
ʻ̆
˸˶
ˁʼ
˚ ˦ˣ
˗ ˘˟ ˜˦ˣ
ˠ ˘˧ ˜˦ˣ
 
    Fig. 2. Effects of varying minimum support     Fig. 3. Effects of varying minimum gap 
˖ ˄ ˃ ˀ˧ ˅ ˁˈ ˀ˦ ˇ ˀ ˜˄ ˁ˅ ˈ ʿʳ ̏˗ ˕ ̏ː˄ ˃ ˃ ˾ ʿ ʳˡ ː˄ ˃ ˃ ˃ ʿ ʳ̀ ˼́ ̆̈ ̃ ː˃ ˁˆ ˈʸ
˃
ˇ ˃ ˃
ˋ ˃ ˃
˄ ˅ ˃ ˃
˄ ˉ ˃ ˃
˅ ˃ ˃ ˃
˄ ˅ ˆ ˇ
˦ ˿˼˷ ˼́ ˺ ʳ̊ ˼́ ˷ ̂ ̊
˧̂
̇˴
˿ʳ˸
̋˸
˶̈
̇˼̂
́ʳ
̇˼̀
˸ʻ
̆˸
˶ˁ
ʼ
˚ ˦ ˣ
˗ ˘˟ ˜˦ˣ
ˠ ˘ ˧ ˜˦ˣ
˖ ˄ ˃ ˀ˧ ˅ ˁˈ ˀ˦ˇ ˀ˜˄ ˁ˅ ˈ ʿ ʳ̏˗ ˕ ̏ː ˄ ˃ ˃ ˾ ʿ ʳˡ ː˄ ˃ ˃ ˃ ʿ ʳ̀ ˼́ ̆̈ ̃ ː˃ ˁˆ ˈʸ
˃
˅˃ ˃
ˇ˃ ˃
ˉ˃ ˃
ˋ˃ ˃
˅ ˇ ˉ ˋ ˄ ˅
ˠ ˴ ̋ ˼̀ ̈̀ ʳ˺ ˴ ̃
˧̂
̇˴
˿ʳ˸
̋˸
˶̈
̇˼̂
́ʳ
̇˼̀
˸ʻ
̆˸
˶ˁ
ʼ
˚ ˦ˣ
˗ ˘˟ ˜˦ˣ
ˠ ˘˧ ˜˦ˣ
 
        Fig. 4. Effects of varying maximum gap                Fig. 5. Effects of varying swin 
˖ ˄ ˃ ˀ˧ ˅ ˁˈ ˀ˦ˇ ˀ˜˄ ˁ˅ ˈ ʿ ʳ̏˗ ˕ ̏ː˄ ˃ ˃ ˾ ʿ ʳˡ ː˄ ˃ ˃ ˃
ˇ˃
ˈ˃
ˉ˃
ˊ˃
ˋ˃
ˌ˃
˄˃˃
˅ ˇ ˉ ˋ ˄˅
˗ ̈ ̅˴ ̇˼̂ ́
˧̂
̇˴
˿ʳ˸
̋˸
˶̈
̇˼̂
́ʳ
̇˼̀
˸ʻ
̆˸
˶ˁ
ʼ ˃ ˁˆ ˈ ʸ˃ ˁˈ ˃ʸ
˃ ˁˊ ˈʸ
˃ ˁ˄ ˃ʸ
˖ ˄ ˃ ˀ˧ ˅ ˁˈ ˀ˦ˇ ˀ˜˄ ˁ˅ ˈ ʿ ʳ ̏˗ ˕ ̏ː˄ ˃ ˃ ˾ ʿʳˡ ː˄ ˃ ˃ ˃
ˇ ˃
ˇ ˇ
ˇ ˋ
ˈ ˅
ˈ ˉ
ˉ ˃
˄ ˅ ˆ ˇ ˈ ˉ
˘ ̋ ˴ ˶ ̇ʳ˺ ˴ ̃
˧̂
̇˴
˿ʳ˸
̋˸
˶̈
̇˼̂
́ʳ
̇˼̀
˸ʻ
̆˸
˶ˁ
ʼ
˃ ˁˆ ˈ ʸ ˃ ˁˈ ˃ ʸ
˃ ˁˊ ˈ ʸ ˄ ʸ
 
           Fig. 6. Effects of varying exact gap                 Fig. 7. Effects of varying duration 
(a) |DB|:100k~1000k (b) |DB|:1000k~10000k
 
Fig. 8. Linear scalability of the database size 
 
 Fast Discovery of Time-Constrained Sequential Patterns Using Time-Indexes 701 
11. Pei, J., Han, J., and Wang, W. Mining sequential patterns with constraints in large data-
bases. Proceedings of the Eleventh International Conference on Information and Knowl-
edge Management, 2002, 18-25.   
12. Zaki, M. J. SPADE: An Efficient Algorithm for Mining Frequent Sequences. Machine 
Learning Journal, Volume 42, Jan.-Feb. 2001, 31-60. 
13. Zaki, M. J. Sequence Mining in Categorical Domains: Incorporating Constraints. Proceed-
ings of the 9th International Conference on Information and Knowledge Management, 
Washington, DC, Nov. 2000, 422-429. 
is very high so that most approaches confine the 
discovery to certain forms.  
In this paper, we propose an algorithm to mine the 
generalized association rules. The rules can be formed 
by combinations of both positive and negative items. 
The minimum support, the minimum confidence, and 
the minimum interest are specified by the user to find 
the most interesting rules. The algorithm is based on 
the pattern-growth framework for mining frequent 
(positive) itemsets. By virtually appending negative 
items of high support, the algorithm efficiently mines 
the generalized association rules. As shown in the 
experimental results, the proposed algorithm 
outperforms the Apriori-like algorithm and has linear 
scalability with the database size. 
The rest of the paper is organized as follows. The 
problem of mining generalized association rules is 
formulated in Section 2. The proposed GENAR 
algorithm is described in detail in Section 3. The 
results of experimental evaluations are presented in 
Section 4. Section 5 concludes our study. 
 
2. Problem definition 
 
Let Ψ = {α1, α2, …, αr} be a set of literals, called 
(positive) items. An itemset e having k items, 
represented by (β1, β2, …, βk), is called a k-itemset. 
The length of a k-itemset e, written as |e|, is k. Without 
loss of generality, the items in an itemset are assumed 
to be in lexicographic order. The set of negative items 
¬Ψ = {¬α1, ¬α2, …, ¬αr}. The database D contains 
the set of transactions; each transaction is an itemset 
T⊆Ψ and an associated transaction identifier. The 
support of itemset e, denoted by sup(e), is the fraction 
of the number of transactions to the total number of 
transactions in D. The support of a negative itemset ¬e 
is defined as 1-sup(e). Itemset e is a frequent itemset if 
sup(e) ≥ min_sup, where min_sup is the user-specified 
minimum support threshold.  
A generalized association rule is the form of 
R:X→Y, where X ⊂ (Ψ∪¬Ψ), Y ⊂ (Ψ∪¬Ψ), 
(X∩Ψ)∩(Y∩Ψ)=∅ and (X∩¬Ψ)∩(Y∩¬Ψ)=∅. That 
is, X and Y can be formed by both positive and 
negative items, and items (either positive or negative) 
can appear either in X or Y but not both. X is called 
the antecedent (abbreviated as Ant) and Y the 
consequent (abbreviated as Con) of rule R.  For 
example, R:¬a∧b∧d→e∧¬f is a rule with antecedent 
item not a, item b, and item d. The support of rule R, 
written as sup(R) = sup(X∪Y). The confidence of rule 
R, written as conf(X→Y) = sup(X→Y)/sup(X). The 
discovered generalized association rules is the set of 
rules having conf(R) ≥ min_conf, where min_conf is 
the user-specified minimum confidence threshold. To 
focus on interesting rules from the potentially large 
number of rules, the interestingness is further defined 
as interest(X→Y) = sup(X→Y)-sup(X)*sup(Y). Only 
interesting rules having interestingness over the 
min_interest (minimum interest threshold) are returned. 
The purpose is to discover the set of interesting rules, 
given the min_sup, min_conf, min_interest, and the 
database D. 
 
3. The proposed algorithm: GENAR 
 
We propose an algorithm called GENAR 
(generalized association rules), based on the pattern-
growth framework [4], to solve the problem. The 
GENAR algorithm is similar to the FP-growth 
algorithm [4]. However, FP-growth mines only 
positive association rules. An overview of the GENAR 
algorithm is outlined in Figure 1. 
The database is scanned once to find the frequent 
(positive) items. The negative items of interest, i.e., 
negative items having support at least min_sup, can 
then be found.  Each transaction can be viewed as 
being appended with the negative items. For example, 
a transaction of {a, d} can be viewed as a new 
transaction {a, d, ¬c, ¬e} if the set of negative items is 
{¬c, ¬d, ¬e}. Then, each transaction will be used to 
construct the FP-tree for mining the frequent itemsets 
comprising both positive and negative items. The items 
in a virtually appended transaction is sorted by the 
support-decreasing order and then added to the FP-tree. 
The rest of the mining simply uses the FP-growth 
framework to complete the discovery. Finally, each 
rule will be verified whether its interestingness and 
confidence pass both thresholds before returning as a 
resulting rule. 
The GENAR algorithm is illustrated with the 
following example. The database D = {(a, d), (a, d, e), 
(a, e), (a, c, d, e), (c, d,  e), (b, d), (a), (a, c), (a, d, e), (a, 
c, d)}, and min_sup = 0.3. Thus, item b cannot be a 
frequent item and is pruned. Frequent items now 
include positive items a:0.8, c:0.4, d:0.7, e:0.5, and 
negative items ¬c:0.6, ¬d:0.3, ¬e:0.5. The fraction 
after the item is its support. The database, which is not 
generated in fact, used to construct the FP-tree in 
GENAR can be realized by the virtual appending of 
the frequent negative items and listed in support-
descending order. Thus, {( a, d, ¬c, ¬e), (a, d, ¬c, e), (a, 
¬c, e, ¬d), (a, d, e, c), (d, e, c), (d, ¬c, ¬e), (a, ¬c, ¬e, 
¬d), (a, ¬e, c, ¬d), (a, d, ¬c, e), (a, d, ¬e, c)} will be 
used to create the FP-tree. Figure 2 shows the 
corresponding frequent pattern tree of the database 
having negative items considered. 
T10I5R50D10k
0
20
40
60
80
100
3 5 7 9 11 13
MinSup (%)
N
um
be
r o
f L
ar
ge
 1
 it
em
s
 
Figure 4. Number of frequent 1-itemsets w.r.t. min_sup. 
T5I2.5R100D10k
0
200
400
600
800
1000
3 4 5 6 7 8
MinSup (%)
E
xe
cu
tio
n 
Ti
m
e 
(s
ec
.)
GENAR Apriori-based
 
Figure 5. Varying supports for dataset 
T5I2.5R100D10K.  
T10I5R50 MinSup=7%
0
200
400
600
800
1000
10k 20k 30k 40k 50k 60k 100k
Number of Transactions
Ex
ec
ut
io
n 
Ti
m
e 
(s
ec
.)
GENAR Apriori-based
 
Figure 6. Varying the number of transactions. 
 
5. Conclusion 
 
In this paper, the algorithm GENAR based on the 
FP-growth approach is proposed to mine the 
generalized negative association rules for service 
recommendations for digital home applications. 
Extending the mining to negative association rules can 
assist the recommendations more accurately. Although 
the mining complexity is increased, the experiments 
showed that GENAR can be applied to discover the 
patterns of both dense and spare datasets. The 
algorithm also has linear scalability with the number of 
transactions. 
 
 
Acknowledgement 
 
This work was supported partially by the National 
Science Council of the Republic of China, under grant 
NSC95-2221-E-035-114. 
 
References 
 
[1] R. Agrawal and R. Srikant, “Fast Algorithms for 
Mining Association Rules,” Proceedings of the 20th 
International Conference on Very Large Data Bases, 
pp. 487-499, 1994. 
[2] M. Antonie and O. Zaïane , “An Associative 
Classifier Based on Positive and Negative Rules,” 
Proceedings of the 9th ACM SIGMOD workshop on 
Research issues in data mining and knowledge 
discovery, pp. 64-69, 2004.  
[3] M. Gan, M.-Y. Zhang and S.-W. Wang, “One 
Extended Form for Negative Association Rules and the 
Corresponding Mining Algorithm” Proceedings of the 
4th International Conference on Machine Learning 
and Cybernetics, Vol. 3, pp.1716-1721, 2005.  
[4] J. Han, J. Pei and Y. Yin, “Mining Frequent 
Patterns without Candidate Generation,” Proceedings 
of the 2000 ACM SIGMOD International Conference 
on Management of Data, pp. 1-12, 2000.  
[5] F. Hussain, H. Liu, E. Suzuki and H. Liu, 
“Exception Rule Mining with a Relative 
Interestingness Measure,” Proceedings of the 3rd 
Pacific Asia Conference on Knowledge Discovery and 
Data Mining, Kyoto, Japan, pp.86-97, 2000.  
[6] A. Savasere, E. Omiecinski and S. Navathe, 
“Mining for Strong Negative Associations in a Large 
Database of Customer Transactions,” Proceedings of 
the 1998 International Conference on Data 
Engineering, pp. 494-502, 1998.  
[7] W.-G. Teng, M. -J. Hsieh and M. -S. Chen, “On the 
Mining of Substitution Rules for Statistically 
Dependent Items,” Proceedings of the IEEE 
International Conference on Data Mining, pp. 442-449, 
Washington, D.C., USA, 2002.  
[8] X. Wu, C. Zhang and S. Zhang, “Efficient Mining 
of Positive and Negative Association Rules,” ACM 
Transactions on Information System, Vol. 22, No. 3, 
pp. 381-405, 2004.  
[9] X. Yuan, B. Buckles, Z.-S. Yuan and J. Zhang, 
“Mining Negative Association Rules,” Proceedings of 
the 7th International Symposium on Computers and 
Communications, pp. 623-628, 2002. 
 
successfully mines closed sequential patterns. However, 
the time constraint is yet to be incorporated. To the best 
of our knowledge, no algorithm has been presented to 
solve the problem of mining closed sequential patterns 
with time constraints. Therefore, we propose an 
algorithm called CTSP (Closed Time-constrained 
Sequential Pattern mining) for mining closed sequential 
patterns with minimum gap, maximum gap, and sliding 
window constraints. Moreover, we define the closure of 
time-constrained patterns by contiguous 
sub/supersequences so that true time-constrained 
patterns with correct supports can be derived. CTSP 
utilizes the memory for efficient mining. Time-indexes 
are constructed in CTSP to facilitate both pattern mining 
and closure checking, within the pattern-growth 
framework. The closure checking is performed 
bi-directionally to speed up the mining. The extensive 
and comprehensive experiments with both synthetic and 
real datasets show that CTSP efficiently mines closed 
sequential patterns satisfying the time constraints, and 
has good linear scalability with respect to the database 
size. 
 
2: Problem Statement 
 
Let Ψ = {α1, α2, …, αr} be a set of literals, called items. 
An itemset I = (β1, β2, …, βq) is a nonempty set of q 
items such that I ⊆ Ψ. A sequence s, denoted by 
<e1e2…ew>, is an ordered list of w elements where each 
element ei is an itemset. Without loss of generality, we 
assume the items in an element are in lexicographic 
order. The length of a sequence s, written as |s|, is the 
total number of items in all the elements in s. Sequence 
s is a k-sequence if |s| = k. The sequence database DB 
contains |DB| data sequences. A data sequence ds has a 
unique identifier sid and is represented by <t1e1’ t2e2’ … 
tn
en’>, where element ei’ occurred at time ti , t1 < t2 
< ...< tn.  
A sequence s in the sequence database DB is a 
time-constrained sequential pattern (abbreviated as 
time-pattern) if s.sup ≥ minsup, where s.sup is the 
support of the sequence s and minsup is the user 
specified minimum support threshold. The support of 
sequence s is the number of data sequences containing s 
divided by |DB|. Note that the support calculation has to 
satisfy three time-constraints maxgap (maximum gap), 
mingap (minimum gap), and swin (sliding window). A 
data sequence ds = <t1e1’ t2e2’… tnen’> contains a 
sequence s = <e1e2…ew> if there exist integers l1, u1, l2, 
u2, …, lw, uw and 1 ≤ l1 ≤ u1 < l2 ≤ u2 < …< lw ≤ uw ≤ n 
such that the four conditions hold: (1) ei ⊆(eli
’∪…∪
eui
’), 1 ≤ i ≤ w (2) tui - tli ≤ swin, 1 ≤ i ≤ w (3) tui - tli-1 ≤ 
maxgap, 2 ≤ i ≤ w (4) tli - tui-1 ≥ mingap, 2 ≤ i ≤ w. 
Assume that tj, mingap, maxgap, swin are all positive 
integers, maxgap ≥ mingap ≥ 1. When mingap is the 
same as maxgap, the time constraint is additionally 
called exact gap. Common sequential pattern mining 
without time constraints is a special case by setting 
mingap = 1, maxgap = ∞, swin = 0.  
A sequence s is closed if no contiguous supersequence 
ssup with the same support exists. Given a sequence s = 
<e1e2…ew> and a subsequence ssub of s, ssub is a 
contiguous subsequence of s if ssub can be obtained by 
any one of following ways: (1) dropping an item from 
either e1 or ew (2) dropping an item from element ei (1 ≤ 
i ≤ w) which has least two items (3) ssub is a contiguous 
subsequence of ssub’, and ssub’ is a contiguous 
subsequence of s. Additionally, s is called a contiguous 
supersequence of ssub. A sequence s is a closed 
time-constrained sequential pattern, abbreviated as 
closed time-pattern, if it is a time-pattern and is closed. 
The mining aims to discover the set of all closed 
time-patterns. 
For example, given a sequence DB of four data 
sequences with their sids in Table 1, the rightmost 
column shows the closed time-patterns for constraints 
mingap = 3, maxgap = 15, swin = 2, and minsup = 50%. 
In Table 1, data sequence C4 <5(a)10(d)21(c, d)> has 
three itemsets occurring at time 5, 10, 21, respectively. 
The third itemset of C4 has two items c and d. 
Sequences <(a,c)(b)> and <(b)(e)(d)> are both 
3-sequences. The sequence <(a,c)(b)> is contained in 
data sequences C1 <3(c)5(a, f)18(b)31(a)45(f)> because 
element (a,c) can be contained in the transaction 
combining 3(c) and 5(a, f) for 5-3≤ 2 (swin). Meanwhile, 
the mingap and maxgap constraints are satisfied for 
18-5 ≥ 3 and 18-3 ≤ 15. Similarly, <(a,c)(b)> is 
contained in C2. The support of <(a,c)(b)> is 2/4 and it 
is a time-pattern for minsup = 50%. <(a,c)(b)> is also a 
closed time-pattern since it has no contiguous 
supersequence with the same support. <(c)(b)> is a 
time-pattern for <(c)(b)>.sup = 2/4 but not closed for its 
contiguous supersequence <(a,c)(b)> having the same 
support. 
The notion of contiguous subsequence 
(supersequence) is introduced to guarantee the 
correctness and completeness of closed time-patterns. 
The subsequence of a (closed) time-pattern is not 
necessary a (closed) time-pattern if the contiguous 
relationship is not hold. For example, though <(b)(d)> is 
the subsequence of <(b)(e)(d)>, time-pattern <(b)(e)(d)> 
does not imply that <(b)(d)> is also a time-pattern since 
<(b)(d)> fails the maxgap constraint in C3. However, 
<(b)(e)(d)> of support 2/4 ensures that its contiguous 
subsequences, such as <(b)(e)> and <(e)(d)>, are also 
time-patterns with support 2/4. Such a definition enables 
the close time-patterns to have the same expressive 
power with more compact patterns. 
 
3: CTSP: Closed Time-constrained 
Sequential Pattern mining 
 
The algorithm we proposed for mining closed 
time-patterns is called CTSP. CTSP uses the 
pattern-growth methodology [8, 12, 13] to discover the 
desired patterns and the bi-directional strategy, similar to 
BEIs are handled by forward closure checking and 
backward closure checking, respectively. If neither stem 
nor BEI has the same support as P, then P is a desired 
closed time-pattern. Recursively, for a newly formed 
type-1 pattern or type-2 pattern P’, its time-index set 
P’-Tidx is constructed and CMine(P’, P’-Tidx) is 
invoked. By pushing time attributes deeply into the 
mining process, CTSP efficiently discovers the desired 
patterns. 
If the database is too large to fit into memory, a 
projected scheme is applied. The database will be 
projected to small sub-databases, based on the frequent 
1-sequences. Each sub-database then can be mined by 
the CTSP. A similar technique has been adopted in the 
Par-CSP algorithm [5]. Therefore, CTSP can mine 
databases, even when the size of the database is larger 
than that of main memory. 
 
4: Experimental Results 
 
Extensive experiments were performed on both 
synthetic and real datasets to assess the performance of 
the CTSP algorithm. Algorithm GSP, which mines all 
time-constrained sequential patterns without closure 
checking, was used to compare with CTSP. All 
experiments were performed on an AMD 2800+ PC 
with 1GB memory running the Windows XP. Here, we 
describe the result of dataset C10-T2.5-S4-I1.25 having 
100000 data sequences (|DB| = 100k), with Ns=5000, 
NI=25000 and N=10000. The detailed parameters are 
addressed in [1]. The results of varying |C|, |T|, |S|, and 
|I| were consistent. CTSP outperforms GSP in all the 
experiments. 
Figures 5, 6 and 7 show the results of varying 
mingap, maxgap and sliding window constraints, 
respectively. The number of closed patterns decreases as 
mingap increases or maxgap decreases. The gap 
constraints restrict more patterns so that the running 
time is decreased. The swin relaxes the constraint and 
allows more patterns to appear so that total execution 
time is increased. The result of varying minsup is shown 
in Fig. 8. 
The results of mining real dataset Gazelle (from KDD 
Cup 2000 [7]) are displayed in Fig. 9. The mingap, 
maxgap and sliding window are set as 3, 15 and 1, 
respectively. The Gazelle dataset has 29369 data 
sequences and 386 distinct items. The maximum 
sequence length and maximum session size are 628 and 
267, respectively. CTSP is about 5 times faster than GSP 
for minsup = 0.06%. The result of scaling up the database 
size, from 100k to 1000k, in Fig. 10 indicates that CTSP 
has good linear scalability. 
 
5: Conclusion 
 
In this paper, we have presented an efficient algorithm 
called CTSP for mining closed sequential patterns with 
minimum/maximum gap and sliding window constraints.  
CTSP uses memory-indexes and the time constraints to 
shrinks the search-space effectively within the 
pattern-growth framework. The closure checking is 
bi-directionally performed. The experimental results 
show that CTSP has good performance with gap 
constraints, both for synthetic and real datasets. 
 
Table 1. Example sequence database (DB) and the closed time-constrained sequential patterns  
Sid Sequence Closed time-constrained sequential patterns 
(minsup=50%, mingap=3, maxgap=15, swin=2)
C1 <3(c)5(a, f)18(b)31(a)45(f)> 
C2 <6(a, c)10(b)17(e)24(c, d)> 
C3 <1(b)20(b, g)27(e)36(d)> 
C4 <5(a)10(d)21(c, d)> 
<(a)>:3, <(a, c)(b)>:2, <(b)>:3, <(b)(e)(d)>:2, 
<(c)>:3, <(c, d)>:2, <(d)>:3  
mingap
ds
FEP
lsti leti
(1) type-1 pattern
maxgap
lsti leti swin
FEP
ds
(2) type-2 pattern
swin
 
Fig. 1: The forward extension period for (a) type-1 pattern and (b) type-2 pattern  
[9:9] [13:13]
[19:19]
[16:16]
(a) (d) (e)
(e)
 
Fig. 2: The timelines of <(a)(d)(e)> in <5(b)9(a)13(d)14(c)16(e)19(e)> 
               
Fig. 7: Results of varying swin        Fig. 8: Results of varying minsup        
                 
Fig. 9: Gazelle dataset (a) execution          Fig. 10: Linear scalability of the database size 
References 
1. Agrawal, R., and Srikant, R. Mining Sequential Patterns. 
Proceedings of the 11th International Conference on Data 
Engineering, Taipei, Taiwan, 1995, 3-14. 
2. Agrawal, R., and Srikant, R. Mining Sequential Patterns: 
Generalizations and Performance Improvements. 
Proceedings of the 5th International Conference on   
Extending Database Technology, Avignon, France, 1996, 
3-17. 
3. Ayres, J., Flannick, J., Gehrke, J., and Yiu, T. Sequential 
PAttern Mining using A Bitmap Representation. 
Proceedings of the 8th International Conference on 
Knowledge Discovery and Data Mining, 2002, 429-435. 
4. Chiu, D. Y., Wu, Y. H., and Chen, A. L. P. An Efficient 
Algorithm for Mining Frequent Sequences by a New 
Strategy without Support Counting. Proceedings of the 20th 
International Conference on Data Engineering, 2004, 
375-386. 
5. Cong, S., Han, J., and Padua, D. A. Parallel mining of 
closed sequential patterns. Proceeding of the eleventh ACM 
SIGKDD International Conference on Knowledge 
Discovery in Databases, Chicago, Illinois, USA, August 
2005, 562-567. 
6. Garofalakis, M. N., Rastogi, R., and Shim, K. SPIRIT: 
Sequential Pattern Mining with Regular Expression 
Constraints. Proceedings of the 25th International 
Conference on Very Large Data Bases, Edinburgh, 
Scotland, Sep. 1999, 223-234. 
7. Kohavi, R., Brodley, C., Frasca, B., Mason, L., and 
Zheng. Z. KDD-Cup 2000 organizers' report: Peeling the 
onion. SIGKDD Explorations, 2:86-98, 2000. 
8. Lin, M. Y., and Lee, S. Y. Fast Discovery of Sequential 
Patterns through Memory Indexing and Database 
Partitioning. Journal of Information Science and 
Engineering. Volume 21, No. 1, Jan. 2005, 109-128. 
9. Lin, M. Y., and Lee, S. Y. Efficient Mining of Sequential 
Patterns with Time Constraints by Delimited 
Pattern-Growth. Knowledge and Information Systems. 
Volume 7, Issue 4, May 2005, 499-514. 
10. Masseglia, F., Poncelet, P., and Teisseire, M. 
Pre-Processing Time Constraints for Efficiently Mining 
Generalized Sequential Patterns. Proceedings of the 11th 
International Symposium on Temporal Representation and 
Reasoning, France, 2004, 87-495. 
11. Orlando, S., Perego, R., and Silvestri, C. A new algorithm 
for gap constrained sequence mining. Proceedings of the 
2004 ACM symposium on Applied computing, Nicosia, 
Cyprus, 2004, 540-547. 
12. Pei, J., Han, J., Moryazavi-Asl, B., Pinto, H., Chen, Q., 
Dayal, U., and Hsu, M.-C. PrefixSpan: Mining Sequential 
Patterns Efficiently by Prefix-Projected Pattern Growth. 
Proceedings of the 17th International Conference on Data 
Engineering, Heidelberg, Germany, April 2001, 215-224. 
13. Pei, J., Han, J., and Wang, W. Mining sequential patterns 
with constraints in large databases. Proceedings of the 
Eleventh International Conference on Information and 
Knowledge Management, 2002, 18-25.   
14. Petre, T., Yan, Xifeng., and Han, J. TSP: Mining top-k 
closed sequential patterns. Knowledge and Information 
Systems, Volume 7, Issue 4, pp. 438-457, May 2005. 
15. Seno, M., and Karypis, G. SLPMiner: An Algorithm for 
Finding Frequent Sequential patterns Using 
Length-Decreasing Support Constraint. Proceedings of the 
2002 IEEE International Conference on Data Mining, 2002, 
418-425. 
16. Wang, J. and Han, J. BIDE: Efficient Mining of Frequent 
Closed Sequences. Proceedings of the 20th International 
Conference on Data Engineering, Boston, March 2004, 
79-90. 
17. Yan, Xifeng., Han, J., and Afshar, R. CloSpan: Mining 
Closed Sequential Patterns in Large Databases. 
Proceedings of the Third SIAM International Conference 
on Data Mining, San Francisco, CA, USA, May 1-3, 2003. 
18. Zaki, M. J. SPADE: An Efficient Algorithm for Mining 
Frequent Sequences. Machine Learning Journal, Volume 
42, Jan.-Feb. 2001, 31-60. 
19. Zaki, M. J. Sequence Mining in Categorical Domains: 
Incorporating Constraints. Proceedings of the 9th 
International Conference on Information and Knowledge 
Management, Washington DC, Nov. 2000, 422-429. 
 
C10T2.5S4I1.25N10k, Mingap=2, Maxgap=8, Swin=1, Minsup=0.5%
0
100
200
300
400
500
600
700
100k 200k 400k 600k 800k 1000k
Number of data sequences (|DB|)
To
tal
 ex
ec
uti
on
 tim
e (
se
co
nd
s) CTSP
DB100C10T2.5S4I1.25N10k, Mingap=1, Maxgap=∞, Swin=0
0
200
400
600
800
1000
1200
0.35% 0.40% 0.45% 0.50% 0.75% 1.00%
Minsup
To
tal
 ex
ec
uti
on
 tim
e (
se
co
nd
s)
GSP
CTSP 
DB100KC10T2.5S4I1.25N10, Minsup=0.5%
0
400
800
1200
1600
1 2 3 4
Swin
Ex
ec
uti
on
 to
tal
 tim
e (
se
co
nd
s)
GSP
CTSPMaxgap=∞, Mingap=1
Database Gazelle, MinGap=3, MaxGap=15, Swin=1
0
400
800
1200
1600
0.040% 0.045% 0.050% 0.055% 0.060%
Minsup
To
tal
 ex
ec
uti
on
 tim
e (
se
co
nd
s)
GSP
CTSP
  
Mining Fuzzy Sequential Rules of One-Day Trippers for Automatic 
Tourism Recommendations 
Sue-Chen Hsueh1 Ming-Yen Lin2 Hui-Lin Wong1 
1Department of Information Management, Chaoyang University of Technology, Taiwan  
2Department of Information Engineering and Computer Science, Feng Chia University, Taiwan  
E-mail:schsueh@cyut.edu.tw, linmy@fcu.edu.tw, s9414601@cyut.edu.tw 
Abstract 
The competition for travelers is becoming fierce among tour operators in the 
service-oriented business. Predicting potential activities and providing associative 
services for the travelers, at the right place at the right time, thus is essential for the 
tourism to win the customers. In this paper, we propose an approach to automatically 
and systematically discover the subsequent traveling activities and tourist spots 
to-visit for one-day trippers. The scenic spots of the one-day trippers are clustered 
first, using a fuzzy c-means clustering algorithm, to find out representative traveling 
groups. Based on the durations of stay and the time intervals between subsequent 
spots, distinct membership functions are employed to transform the quantitative 
values into semantically meaningful actions. The moving paths and the durations of 
stay then can be used to mine the sequential patterns and form the sequential rules. A 
sequential rule indicates the possible subsequent movements, together with the 
activities and durations, after certain spot-related activities. Therefore, the tour 
operators may use these fuzzy sequential rules of traveling spots to dynamically 
provide frequent traveling schedules or plans of serial activities for the one-day 
trippers.  
  
2. Method 
2.1 Fuzzy clustering algorithm 
Bezdek firstly proposed the fuzzy clustering algorithm[1], in which the fuzzy 
membership function is integrated with c-mean algorithm, and divide the data into 
some groups. In this paper, we use the fuzzy clustering algorithm to decide for the 
better clustering center, and further discriminate travelers’ the spot area efficiently. 
The formulas of fuzzy clustering algorithm is shown in the Table 1. 
 
Notion Explain 
C  The amount of clustering 
u  The degree of membership  
V  The sets of clustering center 
v  Clustering center 
P  The data set of fuzzy partition 
 
The smallest goal equation: 
( ) ( )( )∑ ∑
= ∈
−=
k
i Xx
ik
m
kCm
k
i
vxxVPJ
1
2, μ  
 
Where  
( )
∑
=
−
−
−
=
k
j
m
j
i
C
vx
vx
x
i
1
1
1
2
2
1μ             , Xxki ∈≤≤ ,1  
 
( )( )
( )( )∑
∑
∈
∈
×
= n
Xx
m
C
Xx
m
C
i
x
xx
v
i
i
μ
μ
                  , ki ≤≤1  
2.2 Fuzzy data mining algorithm 
The fuzzy data mining algorithm was first proposed by Hong et al. [3]. In order 
continue the next step of mining process and extract important information, the main 
concept of this algorithm is to transform quantitative values into linguistic terms by 
using membership functions. Therefore, in this paper, we still adopt the fuzzy theory 
concept, and separately design the membership ship functions of the travelers’ 
durations and time intervals in spot position for transforming the quantitative values 
in transactions into linguistic terms, and then construct fuzzy sequential association 
Table 1. The notion of  FCM 
  
∑
=
=
n
i
i
jkjk fcount
1
)(  
 
Step 3：Find maxcount j = )count(MAX
||
1 jk
A
k
j
= , for mj   to1= , where jA  is the number 
of fuzzy regions for jA . Let 
max
jR  be the region with 
maxcount j  for attribute jA .  
Step 4：Check whether the maxcount j of each maxjR , mj   to1= , is larger than or equal 
to the predefined min-sup value α . 
Step 5: Use Apriori algorithm theory to generate the candidate itemset 1+rc  , and 
calculate the fuzzy value of each transaction data )(id , as 
)()()()(
121
... is
i
s
i
s
i
s r
ffff +∧∧∧= , where )(is jf  is the membership value of )(id  in region 
js . The minimum operator as follows: 
)(
1
1
)( i
s
r
j
i
s j
fMinf
+
=
=  
Step6: calculate the scalar cardinality of s  in the transaction data as:  
∑== ni iss fcount 1 )(  
Step 7: if 1+rl  is not null, set 1+= rr  and repeat Step 5-7, otherwise, do the next 
step.  
Step 8: find the association rule is equal than or larger than the predefined min-con 
value β , then output the final fuzzy association rules, and get the information. 
 
2.3 Sequential patterns 
    Sequential pattern mining has attracted a significant amount of research recently. 
As point the out by [2], the problem of sequential pattern mining is that checking the 
count values of frequent sequences is larger than or equal to the predefined minimum 
support. The problem of sequential pattern mining can be defined as follows: a 
sequence as <S1, S2,…,Sn>, and Si is an itemset in it. If two sequences <A1, A2,…,An) 
and <B1, B2,….,Bm> have an order interger i1<i2<…<in, 1≦ik≦m, and make A1 ⊆ 
Bi1,…, An ⊆ Bin, then we called sequence <B1, B2,….,Bm> include sequence <A1, 
A2,…,An), and at the same time, <A1, A2,…,An) is <B1, B2,….,Bm> and the length of 
it is subsequence of n. If the count values of a sequence is equal than or larger than 
the minimal support, then we call this sequence is frequent sequences, otherwise, it is 
called non-frequent sequence.   
 
3 Research flow 
The research flow is shown in the Figure 1 which is divide into three major parts: 
1). data preprocessing 2). fuzzy design processing 3). sequential fuzzy rules mining. 
In data preprocessing, the travelers’ data are sorted by encoded ID and then by time 
intervals. Time durations of each travelers in scenic spot area is then calculated. In 
fuzzy design processing, we use FCM to divide the travelers’ X, Y-coordinate into 
  
3. An example 
Table 3 shows the travelers’ X, Y-coordinate, durations and time intervals data in each 
spot position. Because these attributes belong to the different data type, it’s unable to 
directly mine the frequent moving scenic spot path, durations, and time intervals. 
Hence, it would be separately use FCM and membership functions to preprocess, and 
then further mine fuzzy sequential association rules. The example of mining fuzzy 
sequential association rules is as follow:   
 
 
ID traveler X Y Duration Time intervals 
001 1 0.1 0.5 328 minutes 08:10 
002 1 1.6 1.9 180 minutes 13:38 
003 1 2.2 2.5 66 minutes 16:38 
004 1 2.5 2.9 334 minutes 17:44 
005 2 0.75 0.65 148 minutes 10:02 
006 2 2.1 2.3 107 minutes 12:30 
007 2 3 2.5 324 minutes 14:17 
008 3 0.1 0.5 342 minutes 10:16 
009 3 2 2.5 100 minutes 15:58 
010 3 2.8 2.9 319 minutes 17:38 
011 4 2.1 2.2 148 minutes 10:49 
012 4 1.6 1.8 200 minutes 13:17 
013 5 1.6 1.9 118 minutes 08:05 
014 5 0.56 0.9 175 minutes 09:53 
015 5 2.45 2.5 112 minutes 12:48 
 
Step 1: according to the X,Y-coordinate of travelers 1, 2, 3, 4, 5, use FCM to find the 
five clustering center of them, it is X1(0.051695,0.50097), X2(1.6041,1.8702), 
X3(2.1395,2.3947), X4(0.6569,0.77352), X5(2.7514,2.766), and then divides into A, B, 
C, D, and the E these five scenic spot areas, as shown in Table 4: 
 
 
ID Traveler Spot area ID Traveler Spot area ID Traveler Spot area
001 1 A 006 2 D 011 4 D 
002 1 C 007 2 E 012 4 C 
003 1 D 008 3 A 013 5 C 
004 1 E 009 3 D 014 5 B 
005 2 B 010 3 E 015 5 D 
Table 3. Traveling data
Table 4. The traveling data after using FCM 
  
 
Traveler Sequences 
1 
(A, 0.2/Middle+0.8/Long, 1.0/Morning) ,(C, 1.0/Middle, 
1.0/Midday and Meridiem) ,(D, 1.0/Short, 0.7/ Midday and 
Meridiem +0.3/Night) ,(E, 0.1/Middle+0.9/Long, 0.3/ Midday 
and Meridiem +0.7/Night) 
2 
(B, 0.2/Short+0.8/Middle, 1.0/Morning) ,(D, 
0.9/Short+0.1/Middle, 1.0/ Midday and Meridiem) ,(E, 
0.3/Middle+0.7/Long, 1.0/ Midday and Meridiem) 
3 
(A, 1.0/Long, 0.9/Morning+0.1/ Midday and Meridiem) ,(D, 
1.0/Short, 1.0/ Midday and Meridiem) ,(E, 
0.3/Middle+0.7/Long, 0.3/ Midday and Meridiem +0.7/Night) 
4 
(D, 0.2/Short+0.8/Middle, 0.6/Morning+0.4/ Midday and 
Meridiem) (C, 1.0/Middle, 1.0/ Midday and Meridiem,)  
5 
(C, 0.7/Short+0.3/Middle, 1.0/Morning) , (B, 1.0/Middle, 
1.0/Morning) ,(D, 0.8/Short+0.2/Middle, 1.0/ Midday and 
Meridiem) 
 
 
Large-1 sequences Sup 
(A, Long, Morning) (1.8, 1.9) 
(B, Middle, Morning) (1.8, 2.0) 
(C, Middle, Midday and Meridiem) ( 2.0, 2.0) 
(D, Short, Midday and Meridiem) ( 3.9, 4.1) 
(E, Long, Midday and Meridiem) ( 2.3, 1.6) 
 
Step 6: The candidate-2 sequences is generated from Large-1 sequences as follows: 
((A, Long, Morning), (B, Middle, Morning)), ((B, Middle, Morning) , (A, Long, 
Morning)), ((A, Long, Morning), (C, Middle, Midday and Meridiem)), ((C, Middle, 
Midday and Meridiem) , (A, Long, Morning)),…,((D, Short, Midday and Meridiem), 
(E, Long, Midday and Meridiem)), ((E, Long, Midday and Meridiem), (D, Short, 
Midday and Meridiem)) 
Step 7: The fuzzy membership value of each candidate-2 sequence is calculated. Here, 
the minimum operator is used for the intersection. Take the sequence ((A, Long, 
Morning), (D, Short, Midday and Meridiem)) as an example. Its membership function 
value is calculated as: [min(0.8, 1.0)+min(1.0, 1.0), min(1.0, 0.7)+min(0.9, 
Table 5. Transform traveling data of travelers into itemsets 
Table 6. Large-1 sequences 
  
 
Large-2 sequences Sup 
((A, Long, Morning), (D, Short, Midday and 
Meridiem), (E, Long, Midday and Meridiem)) 
(1.5, 0.6) 
 
4. Experimental results 
    We first generate the 2,000 records dataset, but after data preprocessing and 
pruning, the remaining datasets are 1,948 records. We use FCM to divide the 
travelers’ X, Y-coordinate in scenic spot position into ten groups. The clustering 
results are shown the table 10. Afterwards, we use membership functions to transform 
durations, time intervals into linguistic terms, and further mine the frequent moving 
path, durations, and time intervals out. The mining results as shown in Table 11. 
 
 
 
      Region         Cluster center        The total number of people 
        A          (30.621, 53.143)                 119 
        B          (21.89, 69.683)                  628 
        C          (55.59, 12.317)                   12 
        D          (12.934, 20.625)                 738 
            E          (62.808, 6.3993)                 638 
        F          (64.29, 76.193 )                 2002 
 G          (23.066, 52.499)                  642 
           H          (48.447, 82.967)                  861 
         I            (30.307, 91.606)                       341   
        J             (17.868, 54.173)                  628 
 
 
 
       Large itemset    (support,confidence )   The number of fuzzy rules 
L1         both the highest 20 %            9 
           L2         both the highest 20 %           40 
           L3         both the highest 20 %            4 
 
5. Conclusion 
In this paper, we have separately used FCM and membership functions to mine 
three-dimensional data for transforming travelers’ traveling data into sequences, and 
constructed fuzzy sequential association rules to find the travelers’ frequent moving 
Table 9. Large-3 sequences 
Table 10. after using FCM to divide travelers into ten 
groups results 
Table 11. The mining results 
