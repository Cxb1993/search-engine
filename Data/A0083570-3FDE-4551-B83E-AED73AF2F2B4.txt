生物序列特徵向量之設計 
Design of feature vector for biological sequence 
計畫主持人：郭煌政 
兼任研究助理：李宗龍、曾宇正、周培元、賴弘忠、蔡佩成 
國立嘉義大學資訊工程學系 
摘要 
先前研究成果： 
在近十年來，對於生物序列的相似搜尋受到相當大的注意，尤其是人類基因體計畫完成之
後，由於序列資料庫的快速成長，如何做到快速的相似搜尋便成為日益重要的一個議題。
除了直接對原始子序列建立索引的方法外，先將子序列轉換成數字向量，在這我們稱之為
序列描述子，然後再將之置入多維索引結構似乎也是一個可行的方法。當我們要進行相似
序列的搜尋時，我們將對於查詢序列具有較相似的序列描述子的原始序列過濾出來，然後
再進行更精確的排比動作，藉由對原始序列轉換成數字向量的縝密定義，我們預期能達到
相對於查詢序列具有較相似的序列描述子的序列也會具有較高的序列相似度。 
我們先前提出所提出的序列轉換方法，它是使用原始序列的多重特徵，包含記數，相
對位置分散度和絕對位置分散度，來描述原始序列，相對於 q-gram 轉換方法我們可以避免
向量大小呈指數型成長的問題。另外我們也提出了一個分段轉換法，它是先將原始序列遞
迴地分割成等長的子序列，在將它們各別轉換為數字向量之後直接連結起來。 
本計畫研究成果： 
本計畫內容分兩部分： 
1. 調適式：我們特徵向量中有三組特徵，為了使兩序列特徵向量間之相似度更能
精準的反應出原始序列間之相似度，在計算相似度時，我們以 DNA 序列中各
鹼基的出現頻率，賦予特徵向量各組特徵不同的權重。 
2. 基因演算法之應用：利用基因演算法訓練各組特徵之權重，使權重之分配最佳
化，得到最佳之篩選效果。 
 
Abstract 
Previous study result: 
Study on biological sequence database similarity searching has received substantial attention 
in the past decade, especially after human genome project completed. Because the sizes of the 
databases are getting larger and larger, fast similarity search is becoming an important issue. In 
addition to indexing on subsequences, transforming sequences into numerical vectors, called 
sequence descriptors, for storing in a multidimensional data structure is a promising method for 
indexing bio-sequences. 
Previously, we presented an effective sequence transformation method, called SD (Sequence 
Descriptor), which uses multiple features of a sequence including Count, RPD (Relative Position 
Dispersion) and APD (Absolute Position Dispersion) to represent the original sequence data. In 
  
ADAPTIVE WEIGHTING DISTANCE FOR FEATURE VECTORS OF 
BIOLOGICAL SEQUENCES 
HUANG-CHENG KUO1, PEI-YUAN JOU 1, JEN-PEN HUANG 2 
1 Department of Computer Science and Information Engineering, National Chiayi University, Chiayi City 600, Taiwan 
2 Department of Information Management, Southern Taiwan University, Tainan 710, Taiwan 
E-MAIL: {hckuo, s0940317}@mail.ncyu.edu.tw, jehuang@mail.stut.edu.tw 
Abstract: 
Similarity search in biology sequences has attention in the 
recent studies. Sequence alignment is the essential task for 
similar sequence search in bioinformatics. The biological 
sequence databases have getting larger in past decade, finding 
sequences similar to the query sequence is a time consuming 
task. By transforming sequences into numeric feature vectors, 
we can quickly filter out sequences whose feature vectors are 
distant to the feature vector of the query sequence.  
We proposed an adaptive weighting distance which is 
based on feature vector that contains three groups of features: 
Count, Extended Relative Position Dispersion (XRPD), and 
Extended Absolute Position Dispersion (XAPD) of a DNA 
sequence [5]. Each group has four dimensions for A, C, T, G. 
When computing distance between two feature vectors, 
Euclidean distance and L1 distance are commonly used.  
In this paper, we use weighted L1 distance for computing 
the distance between two feature vectors. We derive weights 
for the four nucleotides from the Count group, and apply the 
weights to both XRPD and XAPD. In other words, if a certain 
kind of nucleotide appears much frequent than the other kinds 
of nucleotides, the weight for the kind of nucleotide should 
also be large in XRPD and XAPD groups. Experiments show 
that such distance of feature vectors helps reflect the distance 
between sequences. 
Keywords: 
DNA Sequence, Weight Assignment, Feature Vector. 
1. Introduction 
In biological sequence databases, searching for 
sequences having high alignment scores with the query 
sequence is an essential task. Similar bio-sequences of 
different species usually imply the relationship of function 
and evolution etc. Moreover, there is implicit structural 
information for protein data. For instance, sequence 
similarity analysis has assisted the detection of certain 
strains of Escherichia coli (E. coli) bacteria, often 
responsible for infant diarrhea and gastroenteritis [16]. 
Study on biological sequence database similarity 
searching has received substantial attention in the past 
decade, especially after the sequencing of the human 
genome. As a result, with larger and larger increases in 
database sizes, fast similarity search is becoming an 
important issue. 
Dynamic programming (DP) alignment algorithm, 
such as Smith-Waterman Method [14], was adopted to 
solve the problem of sequence similarity search. Although 
the traditional DP alignment algorithm guarantees the 
optimal alignment result, it is impractical because it 
requires O(mn) (m and n are the lengths of the two input 
sequences) in both time and space. Therefore, several 
heuristics have been developed, such as BLAST [2], [3], 
Pattern Hunter [6], [8], and FASTA [7], [11], [12], etc.  
The common main idea of these heuristic methods is 
that similar sequences must have similar subsequences. 
These methods not only provide good accuracy, but also 
execute efficiently. 
Particularly, BLAST is the most popular method 
because of its excellent accuracy and speed. However, a 
study of the performance of BLAST shows that BLAST is 
becoming 64% slower each year because of the 
exponentially growth of biological databases [4]. 
As the biological databases become larger and larger, 
even the heuristics are no longer feasible. Therefore, a new 
method of filtration has been developed. Researchers 
transform original sequence data into numerical vector 
space [13], and filter out the distant potential dataset via 
distance calculations. 
After the filtration phase, DP or another heuristic 
algorithm is used to align the small number of selected 
sequences with the query sequence. 
Transforming bio-sequence data into a frequency 
domain is a general method for designing feature vector, 
also denoted as sequence descriptor. Some variants of it are 
still constructed on frequency domains. Q-gram frequency 
transformation [10] is the most general one. For instance, a 
DNA sequence S = “ACGGTCAGAA” can be transformed 
  
For example, the DNA sequence S is 
“ACGGTCAGAA” and the Count(S) is [4/n, 2/n, 1/n, 3/n] 
= [0.4, 0.2, 0.1, 0.3]. 
XRPD indicates the degree of relative dispersion of 
symbol α୧. Below illustrates the definition: 
Definition 2 (Extended Relative Position Dispersion, 
XRPD):  
The extended relative position dispersion of S, called 
XRPD(S) is defined as: XRPD(S) = ൣ౨భR ,
౨మ
R , … ,
౨౫
R ൧, where R 
is the sum of r. The ݈ ୧,୨ is a difference value between the 
j-th position and the ሺ݆ ൅ ߜሻ -th position of symbol α 
(ߜ ߳ Ժାሻ. The quantity ࣢୧ which is the volume of those 
difference positions equal to |α୧| െ ߜ. The value of r୧ is 0 
when ࣢୧ ൑ 0; the value of r୧ is 
∑ ቆ భ೗౟,ౠ
ቇ࣢భౠసభ
࣢భ
 when ࣢୧ > 0. 
In the above DNA sequence S is “ACGGTCAGGAA”, 
for instance, the XRPD(S) is [ ଽ
మାସమ
ሺସିଶሻൈR
, 0, 0, ହ
మାହమ
ሺସିଶሻൈR
] = 
[0.6599, 0, 0, 0.3401] when ߜ is 2. 
Definition 3 (Extended Absolute Position Dispersion, 
XAPD): 
Extends Absolute Position Dispersion of S, denoted 
XAPD(S) is defined as: XAPDሺSሻ ൌ ൣ౪భT ,
౪మ
T , … ,
౪౫
T ൧, where T 
is the sum of t. The symbols ݌୧ denote the positions of α୧ 
in order. A group ԋ୧=ሼF୧,ଵ, ԋ୧,ଶ, … , ԋ୧,୩౟ሽ, that be satisfied of 
four conditions: i) ݇௜ א Ժା, k୧ ൑ c୧, and ൛ԋ୧,୷ ് ሼ׎ሽ ห y ൑
k୧ሽ; ii)ሼሺ݌୧,୶ א ԋ୧,୫ሻ ת ሺ݌୧,୶ ב ԋ୧,୬ሻ | x ൑ c୧, y ൑ k, and m ്
nሽ; iii) ሼ݌α౟,୥ ൏ ݌α౟,୦ | ݌α౟,୥ א Gα౟,୷ and ݌α౟,୦ א Gα౟,୷ାଵሽ; and 
iv) ∑ ห݌α౟,୶ െ ݌α౟,୶ାଵ െ 1ห୴אGα౟,౯ ൑ μ  where μ א Գ . The 
value of t୧ is ∑ ቀ∑ ݌୧,୴୴஫ԋ౟,ౘ ቁ
ଶ
/c୧
୩
ୠୀଵ . 
The above DNA sequence S is “ACGGTCAGGAA”. 
For example, the four symbol group are ԋA ൌ ሼԋA,ଵ, ԋA,ଵሽ, 
ԋC ൌ ሼԋC,ଵ, ԋC,ଶሽ , ԋT ൌ ሼԋT,ଵሽ , and ԋG ൌ ሼԋG,ଵ, ԋG,ଶሽ , 
where are ԋA,ଵ ൌ ሼ1ሽ  , ԋA,ଶ ൌ ሼ7, 10, 11ሽ , ԋC,ଵ ൌ ሼ2ሽ , 
ԋC,ଶ ൌ ሼ6ሽ , ԋT,ଵ ൌ ሼ5ሽ , ԋG,ଵ ൌ ሼ3, 4ሽ , and ԋG,ଶ ൌ ሼ8, 9ሽ 
when μ ൌ 2. The XAPD(S) = [ଵ
మାሺ଻ାଵ଴ାଵଵሻమ
ସൈT
, ଶ
మା଺మ
ଶൈT
, ହ
మ
ଵൈT
,
ሺଷାସሻమାሺ଼ାଽሻమ
ସൈT
] = [0.6608, 0.0337, 0.0210, 0.2845]. 
The feature vector of above DNA sequence S in XSD 
is [0.4, 0.2, 0.1, 0.3, 0.6599, 0, 0, 0.3401, 0.6608, 0.0337, 
0.0210, 0.2845]. 
4. Adaptive Weighting 
Let a sequence be a skewed sequence if the number of 
residues of a certain symbol in the sequence is much more 
than the numbers of other symbols. When we align two 
sequences, there are two possibilities to make them similar. 
First, two skewed sequences are very likely to have a very 
high DP score, if their dominant residues are same. If their 
dominant residues are different, they will have a very low 
DP score. Second, if a certain symbol is dominant in Count, 
the symbol will be more representative in XPRD and 
XAPD in terms of computing similarity between two 
sequences. 
Therefore, we design an adaptive weight mechanism 
to weight the distance between two feature vectors in the 
light of these two possibilities. For assigning weights to the 
symbols of Count, we could adapt the entropy to increase 
the weight of partial group of XSD. Entropy could measure 
disorder of a set of objects. The value of entropy be smaller, 
the objects is much more disorder; the objects is nearly the 
same on the contrary. Theoretically, the average value of 
two feature vectors is in the range between 0 and 2. 
Actually, we have found the value of entropy is in the range 
from 1.06 to 2. Therefore, according to the value of entropy, 
we could adaptive weighting on neither of three groups. 
First, we obtain the entropy from the Count group. For 
example, given Count(S) = [0.4, 0.2, 0.1, 0.3], the entropy 
value is 1.8464. We could get two entropy values between 
two sub-sequences. Then, the average entropy Eୟ୴୥ is a 
value which average two values of entropy. We also acquire 
the maximal entropy E୫ୟ୶  that obtains from 
sub-sequences of well-known sequences. Last, According 
to formula (1) with the above entropies, the value of 
weighted AW we obtain. And then by formula (2) and (3), 
we gain the primary weighted W୮ with the weighted AW 
and the secondary also do. The master weighted is multiple 
on the distance between the Count group of two feature 
vectors. And the secondary weighted is multiple on the 
distance between the XRPD and XAPD groups of two 
feature vectors. 
AW ൌ  cosሺω ൅ ಘమ ൈ
E౗౬ౝ
Eౣ౗౮
ሻ            (1) 
W୮ ൌ AW ൈ β ൅ γ                  (2) 
Wୱ ൌ ሺ1 െ W୮ሻ/2                  (3) 
For example, the parameters are ߜ ൌ 1 , μ ൌ 2 , 
ω ൌ െ0.4 , β ൌ 0.9 , and γ ൌ 0.1 . The sequence SQ  is 
“GTTAAAATGAACAACA” and the sequence SDB  is 
“AGAGTGGGAGAAAATA”. The feature vector XSD of 
query is [0.5625, 0.1250, 0.1875, 0.1250, 0.3829, 0.0000, 
0.6171, 0.0000, 0.4857, 0.4308, 0.0351, 0.0485] and the 
feature vector XSD of database is [0.5000, 0.0000, 0.1250, 
0.3750, 0.7524, 0.0000, 0.0000, 0.2476, 0.7282, 0.0000, 
0.1291, 0.1427]. The value of entropy of sequence SQ is 
1.6697; the value of entropy of sequence SDB is 1.4056. 
The value of the average entropy Eୟ୴୥ is (1.6697 + 1.4056) 
/ 2 = 1.5377. The weighted AW is 0.3894; the master 
weighted is 0.4505, and the secondary weighted is 0.2748. 
  
Acknowledgements 
This work was partially supported by grant NSC 
95-2221-E-415-013- from National Science Council, 
Taiwan. 
References 
[1] S. Alireza Aghili, Divyakant Agrawal and Amr El 
Abbadi. “Filtration of string proximity search via 
transformation,” IEEE International Symposium on 
Bioinformatics and Bio-engineering, 2003, pp. 
149-157. 
[2] S. F. Altschul, W. Gish, W. Miller, E. W. Myers and 
D. J. Lipman. “Basic local alignment search tool,” J. 
Mol. Biol., 1990, pp. 403-410. 
[3] S. F. Altschul, T. L. Madden, A. A. Schaffer, J Zhang, 
Z Zhang, W Miller and D. J. Lip-man. “Gapped 
BLAST and PSI-BLAST: a new generation of protein 
database search programs,” Nucleic Acids Res, 1997, 
pp. 3389-3402. 
[4] Michael Cameron, Hugh E. Williams and Adam 
Cannane, "Improved gapped alignment in BLAST," 
IEEE/ACM Transactions on Computational Biology 
and Bioinformatics (TCBB) archive Vol. 1, No. 3, 
2004, pp. 116-129. 
[5] Te-Wen Hsieh, Huang-Cheng Kuo and Jen-Peng 
Huang. “Filtering bio-sequence based on sequence 
descriptor,” Workshop on Data Mining for 
Biomedical Applications, 2006, pp. 14-23. 
[6] M. Li, B. Ma, D. Kisman and J. Tromp. “Pattern 
hunter II: highly sensitive and fast homology search,” 
J. Bioinformatics and Computational Biology, Vol. 2, 
No. 3, 2004, pp. 417-439. 
[7] D. J. Lipman and W. R. Pearson. “Rapid and 
sensitive protein similarity searches,” Science 227, 
1985, pp. 1435-1441. 
[8] B. Ma, J. Tromp and M. Li. “Pattern hunter: faster 
and more sensitive homology search,” Bioinformatics, 
Vol. 18, No. 3, 2002, pp. 440-445. 
[9] S. B. Needleman and C. D. Wunsch. “A general 
method applicable to the search for similarities in the 
amino acid sequences of two proteins,” J. Mol. Biol. 
48, 1970, pp. 443-453. 
[10] O. Ozturk and H. Ferhatosmanoglu. “Effective 
indexing and filtering for similarity search in large 
biosequence databases,” IEEE International 
Symposium on Bioinformatics and Bioengineering, 
2003, pp. 359-366. 
[11] W. R. Pearson. “Flexible sequence similarity 
searching with the FASTA3 program package,” 
Methods Mol Biol. 132, 1999, pp. 185-219. 
[12] W. R. Pearson and D. J. Lipman. “Improved tools for 
biological sequence analysis,” Natl. Acad. Sci, 85, 
1988, pp. 2444-2448. 
[13] Kim R. Rasmussen, Jens Stoye, Eugene W. Myers. 
“Efficient q-gram filters for finding all 
epsilon-matches over a given length,” International 
Conference on Research in Computational Molecular 
Biology, 2005, pp. 189-203. 
[14] T. F. Smith and M. S.Waterman. “Identification of 
common molecular subsequences,” J. Mol. Biol. 147, 
1981, pp. 195-197. 
[15] J. Zhang and T. L. Madden. “PowerBLAST: a new 
network BLAST application for interactive or 
automated sequence analysis and annotation,” 
Genome Research, Vol. 7, No. 6, 1997, pp. 649-656. 
[16] About - E. coli, http://www.about-ecoli.com/. 
[17] National Center for Biotechnology Information 
(NCBI), http://www.ncbi.nlm.nih.gov/. 
and G are nearly equal. In order to improve accuracy, the
weight for Count group is decreased when A, C, T, G oc-
cur almost the same times, whereas the weight is increased
when one of two of A, C, T, and G occur much more then
the others. In the distance function of two feature vectors,
the weights for the three groups of features are adaptive to
the Count feature.
2. Related Work
In a typical sequence similarity search application, there
are two commonly used query types: (i) k-Nearest Neighbor
(k-NN), which asks for the most similar k sequences to the
query sequence; and the (ii) -range query, which asks for
sequences sufficiently similar to the query sequence.
Sequence alignments are classified into two categories:
i) global alignment: When the two aligned sequences are
known and have almost the same length, we can predict
that they are just a little different and use global align-
ment to compute the degree of similarity between them;
ii) local alignment: When we want to search the similar-
ity between an unknown sequence and a known sequence
database or between a short sequence segment and a very
long sequence, we can use local alignment to compute the
degree of similarity between them.
Mutations occur not only due to the change of single
residue, but also due to the insertions and deletions of
residues. Therefore gaps are added in sequence alignments
in order to simulate this situation. There are some com-
monly used alignment tools such as Needleman-Wunsch al-
gorithm [11], Smith-Waterman algorithm [16], FASTA, and
BLAST and its variants Gapped BLAST, PSI-BLAST and
Power BLAST [4, 17].
In [12], frequency transformation of a biosequence S into
N-gram, FT#N(S) is defined as a vector of frequencies of
N-grams. FT1(S) has 4 dimensions and FT2(S) has 16 di-
mensions. Because there is more information about the po-
sitions of the characters relative to other characters stored
as N grows, the feature vector distance will be more re-
lated to the DP score. N-gram Frequency Wavelet Trans-
formation, denoted as WT#N(S), combines FT#N(S) and
Wavelet Transformation. After dividing the sequence S into
Sα and Sβ , WT#N(S) computes the transformations Vα
=FT#N(Sα) and Vβ =FT#N(Sβ). Then it concatenates the
addition and subtraction of those two vectors, i.e., [Vα+Vβ ,
Vα − Vβ]. Q-gram frequency transformation can also be
combined with Fourier Transformation [1].
3. Sequence Feature Vector
SD is comprised of three features from a biosequence
including Count, Relative Position Dispersion (RPD) and
Absolute Position Dispersion (APD). Their definitions are
as follows:
Definition 1 (Count):
Let S = < s1, s2, . . . , sn > be a sequence over the al-
phabet Σu = {α1, α2, . . . , αu}, then the Count of S, called
C(S), is defined as: C(S) = [C1, C2, . . . , Cu], where Ci
(≥ 0) corresponds to the total number of αi in S, and∑u
i=1 Ci = |S| = n.
Definition 2 (Relative Position Dispersion, RPD):
Let S = < s1, s2, . . . , sn > be a sequence over the al-
phabet Σu = {α1, α2, . . . αu}, and Ni be the number of αi
in S. For symbol αi in S, let lαi,j be the difference of posi-
tions of the jth αi and (j + 1)th αi. So, there are Nαi − 1
values of position differences for symbol αi. Relative Posi-
tion Dispersion of S, called RPD(S), is defined as: RPD(S)
= [
(lα1,1)
2+...+(lα1,Nα1−1)
2
Nα1−1 , . . . ,
(lαu,1)
2+...+(lαu,Nαu−1)
2
Nαu−1 ].
RPD indicates the degree of relative dispersion of each
kind of base in a biosequence.
Definition 3 (Absolute Position Dispersion, APD):
Let S = < s1, s2, . . . , sn > be a sequence over
the alphabet Σu = {α1, α2, . . . αu}, and Ni be the
number of αi in S. Let the positions of αi in S
be pαi,1, pαi,2, . . . , pαi,Nαi . Absolute Position Disper-
sion of S, called APD(S), is defined as: APD(S) =
[
(pα1,1)
2+...+(pα1,Nα1−1)
2
Nα1
, . . . ,
(pαu,1)
2+...+(pαu,Nαu−1)
2
Nαu
].
APD indicates the degree of absolute dispersion of each
base in a biosequence.
4. Adaptive Weighting Distance
A sequence is skewed if the number of residues of a cer-
tain symbol in the sequence is much more than the numbers
of other symbols. When we align two sequences, there are
two possibilities to make them similar. First, two skewed se-
quences are very likely to have a very high DP score, if their
dominant residues are the same. If their dominant residues
are different, they will have a very low DP score. Second, if
the number of four symbles of Count are the same, the sym-
bol will be more representative in RPD and APD in terms
of computing similarity between two sequences.
4.1. Adaptive Weighting Distance Mecha-
nism
We design an adaptive weighting distance to compute the
distance between two feature vectors in the light of these
two possibilities. First of all, we compute the average en-
tropy of Count of query feature vector and database’s fea-
ture vectors. Entropy indicates the distribution of a set of
objects. The value of entropy small, the objects is much
more disorder. For this reason, we use entropy to compute
Figure 1. True Positives for k-NN of FW#2, SD
and AW-SD
Figure 2. True Positives for k-NN of SSD and
AW-SSD
[2] R. Agrawal, C. Faloutsos, and A. Swami Efficient simi-
larity search in sequence databases, Proceedings of the
4th International Conference on Foundations of Data
Organization and Algorithms, pp. 69-84, 1993.
[3] S. F. Altschul, W. Gish, W. Miller, E. W. Myers and D.
J. Lipman. Basic local alignment search tool, J. Mol.
Biol., 1990, pp. 403-410.
[4] S. F. Altschul, T. L. Madden, A. A. Schaffer, J Zhang,
Z Zhang, W Miller and D. J. Lip-man. Gapped BLAST
and PSI-BLAST: a new generation of protein database
search programs, Nucleic Acids Res, 1997, pp. 3389-
3402.
[5] Te-Wen Hsieh, Huang-Cheng Kuo and Jen-Peng
Huang. Filtering bio-sequence based on sequence de-
scriptor, Workshop on Data Mining for Biomedical
Applications, 2006, pp. 14-23.
[6] Bi Jin and Gang Rong BTS: a Fast Approach for Simi-
larity Search in Sequences, World Congress on Intelli-
gent Control and Automation, 2006, pp. 5933- 5937.
[7] M. Li, B. Ma, D. Kisman and J. Tromp. Patternhunter
II: highly sensitive and fast homology search, J. Bioin-
formatics and Computational Biology, Vol. 2, No. 3,
2004, pp. 417-439.
[8] D. J. Lipman and W. R. Pearson. Rapid and sensi-
tive protein similarity searches, Science 227, 1985, pp.
1435-1441.
[9] Zbigniew Michalewicz. Genetic Algorithms + Data
Structures = Evolution Programs, Springer-Verlag,
third edition, 1999.
[10] B. Ma, J. Tromp and M. Li. Patternhunter: faster and
more sensitive homology search, Bioinformatics, Vol.
18, No. 3, 2002, pp. 440-445.
[11] S. B. Needleman and C. D.Wunsch. A general method
applicable to the search for similarities in the amino
acid sequences of two proteins, J. Mol. Biol. 48, 1970,
pp. 443-453.
[12] O. Ozturk and H. Ferhatosmanoglu. Effective indexing
and filtering for similarity search in large biosequence
databases, IEEE International Symposium on Bioin-
formatics and Bioengineering, 2003, pp. 359-366.
[13] W. R. Pearson. Flexible sequence similarity searching
with the FASTA3 program package, Methods Mol Biol.
132, 1999, pp. 185-219.
[14] W. R. Pearson and D. J. Lipman. Improved tools for
biological sequence analysis, Natl. Acad. Sci, 85, 1988,
pp. 2444-2448.
[15] Kim R. Rasmussen, Jens Stoye, Eugene W. Myers.
Efficient q-gram filters for finding all epsilon-matches
over a given length, International Conference on Re-
search in Computational Molecular Biology, 2005, pp.
189-203.
[16] T. F. Smith andM. S.Waterman. Identification of com-
mon molecular subsequences, J. Mol. Biol. 147, 1981,
pp. 195-197.
[17] J. Zhang and T. L. Madden. PowerBLAST: a new net-
work BLAST application for interactive or automated
sequence analysis and annotation, Genome Research,
Vol. 7, No. 6, 1997, pp. 649-656.
[18] About - E. coli, http://www.about-ecoli.com/.
[19] National Center for Biotechnology Information
(NCBI), http://www.ncbi.nlm.nih.gov/.
A Gradational Reduction Approach for Mining
Sequential Patterns
Jen-Peng Huang1, Guo-Cheng Lan1, and Huang-Cheng Kuo2,
1 Department of Information Management
Southern Taiwan University of Technology
jehuang@mail.stut.edu.tw
2 Department of Computer Science and Information Engineering
National Chiayi University
hckuo@mail.ncyu.edu.tw
Abstract. The technology of data mining is more important in recent
years, and it is generally applied to commercial forecast and decision
supports. Sequential pattern mining algorithms in the ﬁeld of data min-
ing play one of the important roles. Many of sequential pattern mining
algorithms were proposed to improve the eﬃciency of data mining or
save the utility rate of memory. So, our major study tries to improve the
eﬃciency of sequential pattern mining algorithms.
We propose a new algorithm - GRS (A Gradational Reduction Ap-
proach for Mining Sequential Patterns) which is an eﬃcient algorithm of
mining sequential patterns. GRS algorithm uses gradational reduction
mechanism to reduce the length of transactions and uses GraDec func-
tion to avoid generating large number of infrequent sequential patterns;
and it is very suitable to mine the transactions of databases whose record
lengths are very long. The GRS algorithm only generates some sequences
which are very possible to be frequent. So, the GRS algorithm can de-
crease a large number of infrequent sequences and increase the utility
rate of memory.
Keywords: data mining, sequential patterns, algorithm.
1 Introduction
Recent developments in computing technologies have resulted in computerizing
enterprises which were recorded by hand. For example, customers’ records in
enterprises, patients’ records in hospitals, transaction records in sales . . . etc.,
those data are transferred and stored in ﬁles or database format which make
the maintenance easier, more convenient and more eﬃcient than before by using
sorting, indexing and relationship between tables.
As people use computer to deal with diﬀerent kinds of aﬀairs, the amount of
data are stored and accumulated in surprising speed. Those large amounts of
data need new technologies and tools to analyze and extract useful information
 Corresponding author.
H.G. Okuno and M. Ali (Eds.): IEA/AIE 2007, LNAI 4570, pp. 562–571, 2007.
c© Springer-Verlag Berlin Heidelberg 2007
564 J.-P. Huang, G.-C. Lan, and H.-C. Kuo
element of the sequence. We denote an element of a sequence by (x1, x2, . . . , xm),
where xj is an item. An item can occur only once in an element of a sequence,
but can occur multiple times in diﬀerent elements. An itemset is considered to
be a sequence with a single element.
A sequence < a1a2 . . . an > is a sub-sequence of another sequence b1b2 . . . bm if
there exist integers i1 < i2 < . . . < in such that a1 ⊂ bi1, a2 ⊂ bi2, . . . , an ⊂ bin.
For example, the sequence < (3), (4, 5), (8) > is a sub-sequence of <(7), (3, 8),
(9), (4, 5, 6), (8)>, since (3) ⊂ (3, 8), (4, 5) ⊂ (4, 5, 6), and (8) ⊂ (8). However,
the sequence < (3), (5) > is not a sub-sequence of < (3, 5) >. The problem of
mining sequential patterns is to ﬁnd all sequences whose support is greater than
the user-speciﬁed minimum support. Each such sequence represents a sequential
pattern, also called a frequent sequence.
The AprioriAll[2] algorithm is a level-wise technique. In the mining sequen-
tial patterns, AprioriAll must repeatedly scan the database and generate the
candidate sets until there are no frequent sequences to be found.
The GSP[6] (Generalized Sequential Pattern) algorithm eﬀectively reduces the
number of candidate sets, and modiﬁes the join phase of candidate generation in
the mining sequential patterns. However, because the GSP algorithm will spend
a great deal of time to perform the processes of candidate sets reducing, and
GSP also needs to scan the database repeatedly, the performance of GSP is not
good.
FreeSpan[8] (Frequent pattern-Projected Sequential Pattern Mining) uses the
frequent items to project many small projected databases from original database.
Next, FreeSpan only scans and decomposes the small projected databases, and
then discover the sequential patterns. Because FreeSpan does not scan the orig-
inal database repeatedly, the mining eﬃciency is better than the Apriori-based
algorithms. However, FreeSpan may suﬀer from the following two nontrivial costs
under some conditions: (a) FreeSpan will waste unnecessary memory to build
these projected databases. (b) FreeSpan will generate many unnecessary candi-
date sets.
To improve the defects of FreeSpan[8], PreﬁxSpan[9] (Preﬁx-projected Sequen-
tial Pattern Mining) recursively uses divide-and-conquer and projected-based to
discover the sequential patterns, the performance of PreﬁxSpan is better than
the Apriori-based algorithms when patterns are long. However, PreﬁcSpan must
set up many large projected databases when the items are distributed equally
in the database. Thus it easily causes insuﬃcient memory problems.
3 Gradational Reduction Approach for Mining Sequential
Patterns, GRS
When the lengths of sequence records are long or the minimum supports are
low, the past algorithms [2][10][8][9] need to spend a great deal of time to dis-
cover the frequent sequences. Therefore, to improve the mining eﬃciency, we
propose a new algorithm GRS (Gradational Reduction Approaches for Mining
Sequential Patterns). GRS is a level-wise technique, and the algorithm uses the
566 J.-P. Huang, G.-C. Lan, and H.-C. Kuo
subset “A(BC)” is a frequent sequence, the function GraDec generates all of the
4-sequences of “A(BC)DE” which contain “A(BC)”. Thus the function GraDec
returns “A(BC)D” and “A(BC)E”. Fig. 1(a) shows the processes of infrequent
sequences ﬁltering.
Next, the function GraDec sets the mask value to “11011”. The subset which
consists of the preceding 3 items of “A(BC)DE” with the mask value “11011”
is “ABD”. In the same way, the function GraDec needs to determine whether
“ABD” is a frequent 3-sequence in L3. Because the subset “ABD” is not a
frequent 3-sequence in L3, the function GraDec directly sets the mask value
to “10111”. Fig. 1(b) shows the processes. The subset which consists of the
preceding 3 items of “A(BC)DE” with the mask value “10111” is “ACD”. The
function GraDec needs to determine whether “ACD” is a frequent 3-sequence in
L3. Because the subset “ACD” is not a frequent 3-sequence in L3, the function
GraDec directly sets the mask value to “01111”. Fig. 1(c) shows the processes.
The subset which consists of the preceding 3 items of “A(BC)DE” with the mask
value “01111” is “(BC)D”. The function GraDec needs to determine whether
“(BC)D” is a frequent 3-sequence in L3. Because the subset “(BC)D” is not a
frequent 3-sequence in L3, we stop the processes of sequences generating. Fig.
1(d) shows the processes.
Fig. 1. GraDec function on A(BC)DE
In Fig 1(e) we can discover that GRS only generates sequences which are
very possible to be frequent via the mechanism of infrequent sequences ﬁltering
in tempST. Thus GRS can eﬀectively increase the eﬃciency and the utility rate
of memory.
3.2 Process of Gradational Reduction Mechanism
Although the function GraDec can generate all of the possible frequent sequences
of speciﬁed length, in order to reduce the lengths of transactions in every phase,
568 J.-P. Huang, G.-C. Lan, and H.-C. Kuo
The function GraDec continues to generate all of the possible frequent 3-
sequences and use user-speciﬁed minimum supports to ﬁnd all of the frequent
3-sequences from temp DB and save in FST[2]. After ﬁnding the frequent 3-
sequences, we save all of the items of FST[2] into tempFST. The items which
are saved in tempFST are possible elements of frequent sequences which will be
found in next phase. Next, we delete the items of temp DB which are not in
tempFST, and then accumulate and save the rest in temp DB. Fig. 2(c) shows
the processes and result.
We perform the above processes repeatedly. There are no frequent 4-sequences
in FST[3], the process of ﬁnding frequent sequences stops. Fig. 2(d) shows the
processes of the ﬁltration mechanism.
4 Experimental Results
4.1 Experiment Environment
All the experiments are performed on the following environment: ¡br¿ Intel Pen-
tium IV 2.8GHz CPU, 512MB DDR RAM, Windows 2000 Server, IBM Data
Generator[6], J2SDK 1.4.2 Programming Language.
The experiments are pursued on synthetic data sets which are generated by
IBM Data Generator[6] with the following factors. S: Average transactions per
customer. T: Average items per transactions. II : Average length of maximal
pattern. IT : Average length of maximal pattern. N: Total number of diﬀerent
items. D: Total number of transactions.
4.2 Comparison Algorithms
Our proposed algorithms are to discover the sequential patterns, so our ex-
periment includes the famous algorithms such as AprioriAll[2] and PreﬁxS-
pan[9]. In addition, we also consider the version based on pseudo-projection
name PreﬁxSpan-2 in the experiment. The PreﬁxSpan-2 algorithm uses a struc-
ture to link all of the customer sequences in a projection database. This mecha-
nism can reduce the costs on projecting databases when the projected database
can be built in the main memory. Besides, to avoid external factors causing the
diﬀerence of performances, each algorithm is written in Java2 SDK 1.4.2 and
performed on the same environments.
To be the fairness of the performance, we need to show the performances of our
implemented algorithm PreﬁxSpan is not worse than the original one. Because
the AprioriAll algorithm is not our main competitive algorithm, we omit the
performance ﬁgure comparison. We use the performance ﬁgure of study which
is proposed by Pei[9] et al., to compare the performance with our implemented
algorithms.
In Fig. 3 they use dataset S8T8I8N1KD10K and the diﬀerent minimum
supports to test the performance of PreﬁxSpan. Because we do not have original
PreﬁxSpan[9], we try our best to implement PreﬁxSpan. The result of execution
on dataset S8T8I8N1KD10K within min sup range between 0.5% and 3% are
570 J.-P. Huang, G.-C. Lan, and H.-C. Kuo
database. Thus the performance of AprioriAll is the worst algorithm among algo-
rithms. The performance of GRS is better than others. Because it can eﬀectively
ﬁlter infrequent sequences via their own ﬁltration mechanisms. In addition, be-
cause PreﬁxSpan-1 and PreﬁxSpan-2 use the projection techniques to discover the
frequent sequences, the algorithms need to spend a great deal of memory building
the projections. Therefore their performances are not good.
Comparison of utility rate of memory in diﬀerent parameters S. In
this experiment, we use dataset N10K-D100K-T2.5-IS4-IT1.25 and min sup 0.5%
within S range between S3 and S11 to evaluate the utility rate of memory of algo-
rithms in diﬀerent number of transactions per sequence (S). We observe that the
memory usage is increasing when the S is increasing. Because both PreﬁxSpan-1
and PreﬁxSpan-2 use projection techniques to discover the frequent sequences,
the algorithms spend more memory building these projection databases when
S is increasing. Thus the utility rates of memory are not better than others.
Because AprioriAll is a level-wise method, AprioriAll can release unnecessary
memory space in each phase. Thus the utility rate of memory is very good. Be-
cause GRS can eﬀectively reduce the number of infrequent sequences via the
ﬁltration mechanisms, the algorithm can save a good deal of memory to increase
memory utility rates.
Comparison of the algorithms in diﬀerent parameters D. In this ex-
periment, we use dataset S10-N10K-T2.5-IS4-IT1.25 and min sup 0.75% within
D range between 100K and 500K to evaluate the performance of algorithms in
diﬀerent sizes of datasets (D). We discover that the execution time is increas-
ing when D is increasing. The execution time of AprioriAll is rapidly increasing
when D is increasing. The reason is that AprioriAll spends more time counting
supports of candidate sets when D is increasing. Besides, when D is greater than
500K, the execution of AprioriAll is very long. Therefore, we remove AprioriAll
from algorithms and continue to compare the performance with others.
5 Conclusion
One of the characters of GRS algorithm is the gradational reduction mechanisms.
The main mining method of GRS algorithm is similar to Apriori-like algorithm
which is level by level, but the GRS algorithm does not need to generate can-
didate sequential patterns during the mining processes. At the same time, it
can shorten the length of sequences and compress the size of database in every
phase so it can reduce a great number of infrequent sequences eﬀectively, and
then increase the eﬃciency and the utility rate of memory substantially.
The advantages of GRS algorithm are as follows:
1. Because the GRS algorithm will release the memory of storing infrequent
sequences and the shortening length and the size compressing of database in
every phase, it only generates the sequences that are the most possible to be
frequent sequences. Therefore, the GRS algorithm can increase the utility
rate of memory eﬀectively.
