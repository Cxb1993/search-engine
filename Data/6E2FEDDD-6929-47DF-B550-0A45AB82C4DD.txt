 2
行政院國家科學委員會專題研究計畫成果報告 
數位音樂的演奏表現力自動分析與演奏風格之資料探勘研究 
Automatic Analysis of Music Performance and  
Style Data Mining of Digital Music 
 
計畫編號：NSC 97-2221-E-216 -032 
執行期限：97 年 08 月 01 日 至 98 年 07 月 31 日 
主持人：劉志俊   中華大學資訊工程學系 
計畫參與人員：王鴻文、江俊賢、蔡咏昇、沈瑞祥、曾柏嘉、張俊堂、 
鄭中皓、余俊賢、張誼賢、陳奕安、鄭聿哲、黃志銘 
中華大學資訊工程學系 
 
一、中文摘要 
本計畫中，我們針對 MP3 與 AAC 數
位音樂，試著探討音樂給人的感知的高階
情緒特性，據此提出一個音樂情緒模型。
我們計畫先從壓縮領域中擷取出其 MDCT
特徵值係數，再進一步計算其 MPEG-7 與
MFCC 等音效低階特徵值作為分析其音樂
內涵的來源。接著對重要的音樂特性，如
起音點、基頻、泛音、和弦、調性、拍子、
力度、節奏、速度、音色等，我們經由樣
型分類技術與各音樂特性的樂理法則為基
礎來自動進行計算。我們針對力度、節奏、
音色等重要影響音樂演奏表現力因素提出
自動分析的技術。 
關鍵詞：human perception, music emotion 
model,  
 
二、緣由與目的 
隨著網路的快速發展以及多媒體壓縮
技術的進步，目前有大量的多媒體資料在
網際網路上快速的傳播，所以對於多媒體
資料的分類與查詢，顯得日益重要。因此，
有關多媒體資料內涵式分析的相關研究，
越來越受到學術界的重視。 
音樂是最主要的多媒體資料之一。早期的
音樂內涵分析，主要是由音樂理論學者與
心理學家，透過人工的方式來進行音樂作
品的分析探討。近年來以訊號處理的方式
來對音樂內涵進行分析，成為多媒體訊號
處理方面的主要研究焦點之一。目前的主
要研究方式是透過擷取音樂低階特徵值，
對主要的音樂特性如旋律、節奏、調性、
速度等，在偵測、比對、分析、分類、索
引等自動技術進行探討。近年來，隨著研
究的快速進展，低階特徵已逐漸無法滿足
對音樂內涵分析的高階需求，因此分析人
類感知、情緒等高階特徵，乃至於對音樂
家演奏風格詮釋的量化分析與探勘，已成
為目音樂內涵分析領域的研究挑戰之一。 
 
三、研究成果 
(一) 音樂感知情緒模型 
Hevner 設計了一系列音樂引發情緒的
實驗，請聽者寫下當演奏不同類型音樂
時，情緒有何反應錯誤! 找不到參照來
源。。透過此實驗來瞭解音樂的聲音和聽
者的情緒反應間的關係，並提出八組情緒
相關的形容詞組(adjective group)，每一組
代表性的形容詞分別為高貴的(dignified)、
傷心的 (sad)、悅耳的 (dreamy)、平靜的
(serene)、優美的(graceful)、快樂的(happy)、
使 人 興 奮 的 (exciting) 、 強 而 有 力 的
(vigorous)，此模型為針對音樂引發情緒，
最早提出的模型。 
我們以 Hevner 模型為基礎，並加入
Thayer 的二維模型以及 Juslin 的模型中區
分四種情緒的概念，依照音樂的調性、音
樂的速度、音樂的力度三種音樂表情因素
的組合，歸納出三個音樂表情影響因素與
Hevner 的八個情緒的對應關係，如圖 1 所
示。據此，我們提出之音樂感知情緒自動
分類系統整體架構如圖 2 所示。首先我們
從MP3音樂檔案中取出每一小節的音樂片
段，接著透過兩種方法分析影響音樂表情
