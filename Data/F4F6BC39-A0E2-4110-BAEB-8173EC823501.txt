II 
一、 中文摘要 
 
許多新的應用環境中持續不斷的快速產生大量有序的資料稱為資料串流。依據其特
性，串流資料分成線上串流與離線串流，其資料的處理模式，則可以分成標界模式、時間
衰減模式、與滑動窗模式。資料串流的探勘相當複雜，超越傳統關聯式查詢以及固定資料
集合的勘測，我們必須設計能盡量滿足有限記憶體需求下、單次掃瞄資料的有效率探勘方
法。目前所提出來的資料串流關聯規則探勘方法，不論其資料處理模式是什麼模式，所考
慮到的情形，都是在一個固定的最小支持度下，找出所有的頻繁樣式、封閉樣式、或最大
樣式。實務上，最小支持度是變動的。對於探勘過程中，無法改變最小支持度、相當不符
實務應用。變動支持度探勘或互動式探勘可以任意改變最小支持度探勘頻繁樣式，在串流
環境中是一大挑戰。 我們設計了兩個支援可變動支持度的高效能、高精準度、高召回率資
料串流頻繁項目集探勘方法。我們提出一個摘要結構以符合探勘所需。所設計的方法，除
了減少記憶體的需求外，也提高精確度及召回率。利用摘要向量的分組與簡化比對搜尋範
圍，大量改善可變動探勘條件之資料串流頻繁樣式探勘的效能。實驗證明，本方法相當具
有高效能與精準度，也具有可擴充性。。 
關鍵詞：資料串流、串流探勘、頻繁樣式探勘、變動支持度探勘 
IV 
目 錄 
 
一、 中文摘要……………………………………………………………………II 
二、 英文摘要…………………………………………………………………...III 
三、 報告內容…………………………………………………………………...1 
I. 前言…………………………………………………………………………………..1 
II. 研究目的 …………………………………………………………………………..1 
III. 文獻探討……………………………………………………………………………2 
IV. 研究方法…………………………………………………………………………….2.  
V. 結果與討論…………………………………………………………………………4 
四、 參考文獻……………………………………………………………………6 
五、 計畫成果自評………………………………………………………………10 
2 
issues in data streams will demand a synopsis structure for maintaining necessary 
information for re-mining purpose. 
Although VSMDS builds the synopsis vectors for the interactive mining, the precision is 
not good at all times. In addition, the compression phase of VSMDS searches a full range of 
delegates so that the efficiency is yet to be improved. Therefore, we aim to propose an 
algorithm that may support interactive mining of stream transactions for frequent itemsets 
with a high precision and better efficiency. 
 
III. 文獻探討 
Two typical algorithms, the Apriori algorithm and the FP-growth algorithm are 
generally referred in the mining of frequent itemsets in traditional databases. The 
Buffer-Trie-SetGen, FP-stream, and DSM-FI Algorithms are three algorithms which support 
the mining frequent itemsets in data streams. The Moment and estWin algorithms are aim to 
mine closed and recently frequent itemsets in a data stream, respectively. VSMDS algorithm 
is an algorithm that is most closed to our work. Thus, we briefly reviewed VSMDS algorithm 
here.  
VSMDS (Variable Support Mining for Data Streams) uses the synopsis vector 
(abbreviated as SYV) to approximate the discarded transactions and the PFI-tree (Potential 
Frequent Itemsets tree) to record the support counts of potentially frequent itemsets. Every 
time a new batch of transactions arrives, the PFI-tree is updated and the batch of transactions 
is inserted into the SYV with approximations. Hence, the PFI-tree keeps all the itemsets 
having supports above certain threshold (let it be msPFI), considering up to the last batch of 
transactions. If the newly specified minimum support (msi) is greater than msPFI, the user is 
querying frequent itemsets that have higher supports, which itemsets can be retrived from the 
PFI-tree. VSMDS replies to the user without the participation of the SYV. If msi < msPFI, 
those itemsets having supports between msi and msPFI, which itemsets are not in PFI-tree, 
become frequent. Hence, VSMDS will use the SYV to re-build PFI-tree for the mining of 
these itemsets at this moment. 
 
IV. 研究方法 
An overview of the GruFI algorithm is depicted below. A batch of transactions is 
processed together in the GruFI algorithm. That is, transactions are handled in a 
bucket-by-bucket basis. Each bucket is associated with a minimum support, which value is 
either newly specified or the same as the previous value. The arrival of a new bucket will 
trigger two operations, updating of the potentially frequent itemsets (PFI) and insertion of the 
transactions to a summary structure (called grouped synopsis vector, abbreviated as GSYV), 
and then be discarded. The frequent itemsets are retrieved from the PFI. The summary 
structure GSYV is composed of delegates and their cardinalities, in which the delegates are 
organized, based on the length, into groups. When a newly specified minimum support is less 
than the threshold used in the PFI, the GSYV is used to re-build a new PFI for mining the 
frequent patterns. The GSYV is compressed when the allocated space is over certain 
4 
created and appended to the corresponding group in GSVY. The very first GSYV, the GSYV1, 
is created by inserting transactions, one by one, to an empty summary structure. The dh is 
zero in the beginning. Recall that GSYV (l) is the group of delegates of length l in GSYV.  
Transaction t cannot be approximated by a delegate dg unless t = dg when dh = 0, since 
the approximate-difference is zero. A delegate whose length differs from |t| will have a 
nonzero approximate-difference. Thus, groups whose length is not |t| can be eliminated from 
searching. In addition, the delegates to be verified with a transaction t must have the same 
value of the signature computed with t when dh = 0.if t = {α1, α2, …, α|t|} is to be 
approximated by dg = {α1’, α2’, …, α|t|’} when dh = 0, then α1= α1’, α2= α2’, …, α|t|= 
α1|t|’. Thus, sig(t) = sig(dg). 
In short, GruFI shrinks the space of delegates to groups of delegates having length 
within range |t|-　to |t|+　 to approximate a transaction t. The delegates in group GSYV(|t|) 
is searched first. If a delegate dg in group GSYV(|t|) with sig(dg) = sig(t), dg is immediately 
verified whether it is the same as t. If dg = t then the best delegate is found and the search 
stops. Therefore, the use of signature speeds up the approximation. 
The summary structure GSYV grows as more and more transactions are approximated. 
The GSYV will reach the bound of the available memory space for the GSYV after certain 
time. Either the user may choose to write out the GSYV to reclaim the memory space for 
future transactions, or the GSYV need to be re-organized, i.e. compressed, to prepare space 
for transactions to come. The compression is dynamically invoked as necessary. 
 To reduce the space required by GSYV, the compression indeed increases the difference 
threshold, which is zero initially, to allow a delegate to approximate more itemsets. Each 
delegate existing in the GSYV is approximated using the other delegates satisfying the 
distance threshold. To prevent a delegate from being approximated more than once during 
compression, the compression of the GSV is performed from the groups having the longest 
length to the shortest one, named backward compression. We give an example of 
compression without backward compression as follows. Assume that dh is increased from 
zero to one. Delegate {a, b, c} will be approximated by {a, b, c, d} when we compress the 
GSYV(3). Next, delegate {a, b, c, d} will be approximated by {a, b, c, d, e}, which means 
the {a, b, c} is approximated by {a, b, c, d, e} with approximate-difference 2, instead of 1. 
Concisely, GruFI compresses GSYV in a length decreasing order. When GSYV(l) is 
approximated (compressed), the processed GSYV(l+1) to GSYV(l+dh) are considered. 
Besides, the consideration order is from groups of longer length to shorter length, named 
backward approximation. 
 
VI. 結果與討論 
Extensive experiments have been conducted to assess the performance of the GruFI 
algorithm. The VSMDS algorithm is used in the comparisons in the experiments because it 
allows the support to be changed for mining frequent itemsets in the data stream. Other 
algorithms for mining stream data assume a fixed support and are not used in the 
comparisons. The first version of the VSMDS algorithm postpones the searching and directly 
6 
the influence of re-compress methodology for re-mining, the support sequences are designed 
to four types for different re-mining time. Four support sequences are provided to experiment 
the influence on different re-mining time. Support sequences A, B, and C perform re-mining 
on final, middle, and initial respectively, support sequence D perform re-mining at fourth 
bucket, seventh bucket.  Support sequence A is {0.3%, 0.3%, 0.3%, 0.3%, 0.3%, 0.3%, 
0.3%, 0.3%, 0.3%, 0.1%}, sequence B is {0.3%, 0.3%, 0.3%, 0.3%, 0.3%, 0.1%, 0.1%, 0.1%, 
0.1%, 0.1%}, sequence C is {0.3%, 0.1%, 0.1%, 0.1%, 0.1%, 0.1%, 0.1%, 0.1%, 0.1%, 
0.1%}, and sequence D is {0.3%, 0.3%, 0.3%, 0.2%, 0.2%, 0.2%, 0.1%, 0.1%, 0.1%, 0.1%}. 
For the sequence A, the re-mining performs after the re-compress procedure. The 
experimental result show that GruFI and GruFI-II decreases the precision a little, but 
outperforms over the recall. Sequence B, C and D re-mining before re-compress procedure 
be performed, so the results are almost the same. The results of mining the real world data 
stream were similar. It shows that GruFI performs very well in the interactive mining of 
frequent itemsets for a data stream. 
We have proposed the GruFI algorithm for interactive mining of frequent itemsets in a 
data stream with changeable support thresholds. GruFI utilizes the lexicographically 
structured PFI-tree for fast updating and mining of patterns. A grouped synopsis vector is 
effectively used for maintaining statistics of past incoming transactions. The additions of the 
length index and the signature further speed up the searching of the delegates for 
approximations. The search space shrinks to smaller groups of delegates while inserting a 
new transaction to the synopsis vector. Several groups are skipped due to the length analysis 
with respect to the distance thresholds. Thus, the compression, when the available memory is 
not available, is accelerated. The comprehensive experiments show that GruFI outperforms 
VSMDS on both synthetic and real datasets, and has linear scalability. In addition, the recall 
is raised with a little drop on the precision. The proposed GruFI algorithm is efficient for the 
variable support mining in data streams. 
 
四、參考文獻 
 
(I) 計畫相關之著作  
1. Ming-Yen Lin, Sue-Chen Hsueh, and Chia-Wen Chang, “Fast discovery of sequential 
patterns in large databases using effective time-indexing,” Information Sciences: An 
International Journal, Vol. 178, Issue 22, pp. 4228-4245, Nov. 2008. (SCI, EI) (Impact 
factor:2.147, JECR 2007) 
2. Ming-Yen Lin, Sue-Chen Hsueh, and Sheng-Kun Hwang, “Interactive Mining of 
Frequent Itemsets over Arbitrary Time Intervals in a Data Stream,” Database 
Technologies 2008, Fekete, A. and Lin, X., Eds., CPRIT Vol. 75, pp. 15-21, Jan. 2008. 
8 
5. Cheng, J., Ke, Y., and Ng, W., “Maintaining Frequent Itemsets over High-Speed Data 
Streams,” In Proceedings of Pacific-Asia Conference on Knowledge Discovery and Data 
Mining (PAKDD2006), pages 462-467, 2006. 
6. Chi, Y., Wang, H., Yu, P. S., “Catch the Moment: Maintaining Closed Frequent Itemsets 
over a Data Stream Sliding Window,” Knowledge and Information Systems, Vol. 10, No. 3, 
pages 265-294, 2006. 
7. . Giannella, G., Han, J., Pei, J, Yan, X., and Yu, P. S., “Mining Frequent Patterns in Data 
Streams at Multiple Time Granularities,” In Proceedings of the NSF Workshop on Next 
Generation Data Mining, 2002. 
8. Han, J., Pei, J. and Yin, Y., “Mining Frequent Patterns without Candidate Generation,” In 
Proceedings of the ACM SIGMOD International Conference on Management of Data, Vol. 
9, Issue 2, pages 1-12, 1999. 
9. Hidber, C., “Online Association Rule Mining,” In Proceedings of the 1999 ACM 
SIGMOD International Conference on Management of Data, pages 145-156, 1999. 
10.  Hwang S. K, Efficient Mining of Frequent Patterns in Data Streams with Variable 
Support Thresholds, Master Thesis, Feng Chia University, Taiwan, 2006. 
11. Jiang, N., and Gruenwald, L., “Research Issues in Data Stream Association Rule Mining,” 
SIGMOD Record, Vol. 35, No. 1, pages 14-19, Mar. 2006. 
12. Koyuturk, M., Grama, A., and Ramakrishnan, N., “Compression, Clustering and Pattern 
Discovery in Very High Dimensional Discrete-attribute Datasets,” IEEE Transactions on 
Knowledge and Data Engineering, Vol. 17, no. 5, pages 446-461, 2005. 
13. Leung, C. K., Khan, Q. I, “DSTree: A Tree Structure for the Mining of Frequent Sets from 
Data Streams,” In Proceedings of the 6th IEEE International Conference on Data Mining 
(ICDM2006), pages 928-932, 2006. 
14. Li, H. F., Lee, S. Y., and Shan, M. K., “An Efficient Algorithm for Mining Frequent 
Itemsets over the Entire History of Data Streams,” In Proceedings of the First 
International Workshop on Knowledge Discovery in Data Streams, pages 20-24, 2004. 
15. Li, H. F., Lee, S. Y., and Shan, M. K., “DSM-PLW: Single-Pass Mining of Path Traversal 
10 
五、 計畫成果自評  
 
本計畫的預期目標是研發目標是設計一個支援可變動支持度的高效能、高精準度、高
召回率資料串流頻繁項目集探勘方法。 
經深入探討與設計後，我們提出具有高效能的互動式資料串流頻繁項目集探勘方法，
適合於探勘資料串流頻繁項目集，也建構出資料串流的互動式探勘方法，透過對於模擬資
料的大型實驗，以及真實的銷售點資料串流實驗，驗證所研發之技術與方法。本計畫的研
究內容與原計畫目標完全相符，也達成計畫所預期之目標。同時，參與計畫的多位研究生
也獲得許多設計與研究的經驗。此外，我們也在研究高頻樣式可以變動支持度的探勘方法
的過程中，再度深入序列資料的探勘研究等。 
本計畫之研究成果，除了 2 位碩士生的畢業論文外，另有已發表之會議、期刊與專書
論文共 4 篇，其中 1 篇為 SCI/EI 索引論文、1 篇為 EI 索引論文、1 篇為知名會議（328
個 CS 會議排名 48）論文以及一篇專書論文。本研究成果完整之內容與理論的推演證明部
分也正在補足，待補足後，也將會投稿至知名國際期刊。 
本研究不僅具有學術價值，也能應用至實務面。綜合而言，本研究成果與計畫目標高
度契合。 
 
 
 
  
