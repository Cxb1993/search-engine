1. Introduction
MRI segmentation provides important information for detecting a variety of tumors,
lesions, and abnormalities in clinical diagnosis. The segmentation can be described as
the definition of clusters whose points are associated to similar sets of intensity values in
the different images. An efficient analysis of dual echo medical imaging volumes can be
derived from a set of different diagnostic volumes carrying complementary information
provided by medical imaging technology. The extraction of such volumes from imaging
data is said to be segmentation and it is usually performed, in the image space, defining
sets of vowels with similar features within a whole dual echo volume.
In general, medical images are obtained using different acquisition methods, including
x-ray computer tomography (CT), single photon emission tomography (SPET), positron
emission tomography (PET), ultra-sound (US), magnetic resonance image (MRI) and
magnetic resonance angiographies (MRA), etc. MRI systems are important in medical
image analysis. MRI has the multidimensional nature of data provided from either one
of two different pulse sequences. MRI segmentation is an important step in any image
analysis system. Various segmentation methods for MRI have been used to differentiate
abnormal and normal tissues (see [4], [7], [13], [14], [21]).
Cluster analysis is a method of grouping data with similar characteristics into larger
units of analysis. Image segmentation is a way to partition image pixels into similar
regions. Thus, a clustering algorithm would naturally be applied in image segmentation.
Since Zadeh [27] first articulated fuzzy set theory which gave rise to the concept of
partial membership, based on a membership function, fuzziness has received increasing
attention. Fuzzy clustering, which produces overlapping cluster partitions, has been
widely studied and applied in various areas [2]. In fuzzy clustering, the fuzzy c-means
(FCM) clustering algorithm is the best known and most powerful methods used in cluster
analysis ([1]).
2
as clustering X into c clusters X1, · · · , Xc by a hard c-partition {u1, · · · , uc}. A fuzzy
extension allows ui(x) to take on values in the interval [0, 1] such that
∑c
i=1 ui(x) = 1
for all x in X. In this case, {u1, · · · , uc} is called a fuzzy c-partition of X ([15]). Thus,
the FCM objective function JFCM is defined as ([1])
JFCM(u, a) =
n∑
j=1
c∑
i=1
umij ||xj − ai||2
where u = {u1, · · · , uc} is a fuzzy c-partition with uij = ui(xj) being the membership of
the data point xj in cluster i, a = {a1, · · · , ac} is the cluster centers, and the notation
||xj−ai|| denotes the Euclidean distance between the data point xj and the cluster center
ai. The parameter m is a weighting exponent on each membership and determine the
amount of fuzziness of the resulting classification. Thus, the FCM clustering algorithm
is an iteration through the necessary conditions for minimizing JFCM with the following
update equations:
ai =
∑n
j=1 u
m
ijxj∑n
j=1 u
m
ij
, and uij =
||xj − ai||−2/(m−1)∑c
k=1 ||xj − ak||−2/(m−1)
.
The FCM algorithm is a well-known and powerful method in clustering analysis. One
of important parameters in the FCM is the weighting exponent m. When m is close
to one, the FCM approaches the hard c-means algorithm. When m approaches infinity,
the only solution of the FCM will be the mass center of the data set. Therefore, the
weighting exponent m plays an important role in the FCM algorithm. Recently, Yu et
al. [24] provided the theoretical analysis to selecting the weighting exponent m in the
FCM.
The mixture maximum likelihood approach to clustering is a remarkable model-based
clustering method. Scott and Symons [16] proposed the so-called classification maximum
likelihood (CML) procedure, named first in Bryant and Williamson [3], that many of
the commonly used clustering procedures correspond to applications of the maximum
likelihood approach for normal groups with various restrictions on the covariance matri-
ces and with the indicator classification variables of group membership associated with
4
where β ≥ 0. The update equations for a minimizer of JPIM(u, a) are
ai =
∑n
j=1 u
m
ijxj∑n
j=1 u
m
ij
, µij =

(||xj−ai||2−β)−1/(m−1)∑c
k=1
(||xj−ak||2−β)−1/(m−1) if ||xj − ai||
2 > β,
1 if ||xj − ai||2 ≤ β.
The PIM objective function can be thought of a generalization of FCM objective function
by adding to the penalty term (−β∑nj=1∑ci=1 umij ). To implement PIM algorithm, we
need to determine the value of β that controls the amount of penalization. O¨zdemir and
Akarun [12] suggested that β = δmini6=j{||ai − aj||2}, where 0 ≤ δ < 0.5.
In JPFCM , we choose αi = 1/c, ∀i. Then
JPFCM(u, a) = JFCM(u, a) + w ln c
n∑
j=1
c∑
i=1
umij
= JFCM(u, a)− β
n∑
j=1
c∑
i=1
umij ,
where β = −w ln c ≤ 0. It means that the PIM algorithm is still meaningful when β ≤ 0
and it is a special case of PFCM proposed by Yang ([20]).
By minimizing the FCM objective function and simultaneously maximizing the inter-
cluster separation (ICS) measure, O¨zdemir and Akarun [11] proposed the ICS clustering
algorithm with the objective function
JICS(u, a) =
1
n
n∑
j=1
c∑
i=1
(
µmij ||xj − ai||2 −
γ
c
c∑
t=1
||ai − at||2
)
, (1)
where the parameter γ ≥ 0. Yu and Yang [26] pointed out that the original update
equations for the ICS algorithm in [11] were partially incorrect. The update equations
for the ICS algorithm originally in [11] were corrected as follows (see [26]).
ai =
1
n
∑n
j=1 µ
m
ijxj − 2γc
∑c
t=1 at
1
n
∑n
j=1 µ
m
ij − 2γ
, µij =
||xj − ai||−2/(m−1)∑c
k=1 ||xj − ak||−2/(m−1)
. (2)
It was shown by Yang [20] and Yang and Su [22] that the PFCM algorithm is more
accurate than the FCM method. It means that the penalty term can improve the
performance of FCM. To improve the performance of ICS, we consider adding a penalty
term to ICS. Because PFCM is a model-based approach and performs better than PIM
6
a partition matrix where
Mfcn = {u = [uij]c×n| ∀i, ∀j, uij ≥ 0,
c∑
i=1
uij = 1, 0 <
n∑
j=1
uij < n}.
Let G be a function with
G : u = [uij]c×n ∈Mfcn 7→ a = (a1, · · · , ac)T ∈ Rcs
where ai =
∑n
j=1 u
m
ijxj/
∑n
j=1 u
m
ij . Let F be a function with
F : a = (a1, · · · , ac)T ∈ Rcs 7→ u = [uij]c×n ∈Mfcn
where uij = ||xj − ai||−2/(m−1)/∑ck=1 ||xj − ak||−2/(m−1), i = 1, · · · , c; j = 1, · · · , n, i.e.,
F (a) = u. We then have a mapping Tm with Tm(u, a) = (uˆ, aˆ), where uˆ = F (a),
aˆ = G(uˆ). Thus, if (u(`), a(`)) = Tm(u
(`−1), a(`−1)), ∀` ≥ 2, then (u(`), a(`)), ` = 1, 2, · · ·
are called iteration sequences of the FCM algorithm, where (u(`), a(`)) is an element of
Mfcn×Rcs. Let ΩFCM denote the solution set of the FCM objective function JFCM(u, a)
with
ΩFCM = {(u∗, a∗) ∈Mfcn ×Rcs| JFCM(u∗, a∗) ≤ JFCM(u, a∗), ∀u ∈Mfcn, u 6= u∗,
JFCM(u∗, a∗) < JFCM(u∗, a), ∀a ∈ Rcs, a 6= a∗}.
It is known that the point (u∗, a∗) ∈ ΩFCM if and only if (u∗, a∗) is an FCM fixed point.
In other words, (u∗, a∗) ∈ ΩFCM if and only if u∗ = F (a∗) and a∗ = G(u∗). Selim and
Ismail [17] then gave the Hessian matrix HFCMu of ψm(u) = mina∈Rcs J
FCM(u, a).
Clearly, JFCM(u,G(u)) = ψm(u) and ψm(u) is convex at u if and only if H
FCM
u is
positive semi-definite. Selim and Ismail [17] showed that this is a sufficient condition
for a local minimum of JFCM(u, a). Based on the Hessian matrix HFCMu , Yu et al. [24]
showed the following theorem for the FCM weighting exponent m.
Theorem 1. (Yu et al. [24]) Let U∗ = [1/c]c×n and λmax(FU∗) be the maximum
eigenvalue of the matrix FU∗ . If λmax(FU∗) < 0.5 and m > 1/(1 − 2λmax(FU∗)), then
8
Based on the discussion of Section 2, we consider β 6= 0 in PIM algorithm. Then,
according to analysis of [19], the reduced objective function of PIM with respect to the
cluster centers {a1, · · · , ac} is calculated as follows:
JPIM(F (a), a) =
n∑
j=1
( c∑
i=1
(||xj − ai||2 + β)
−1
m−1
)1−m
.
Let ΩPIM denote the solution set of the PIM objective function JPIM(u, a) with
ΩPIM = {(u∗, a∗) ∈Mfcn ×Rcs| JPIM(u∗, a∗) ≤ JPIM(u, a∗), ∀u ∈Mfcn, u 6= u∗,
JPIM(u∗, a∗) < JPIM(u∗, a), ∀a ∈ Rcs, a 6= a∗}.
However, the point in ΩPIM may be a saddle point of JPIM(u, a). To get the Hessian
matrix of JPIM(F (a), a) is enough to determine whether or not a point in ΩPIM is a
saddle point. We set
tj(a) =
c∑
i=1
(||xj − ai||2+ β)
−1
m−1 , uij =
(||xj − ai||2 + β)
−1
m−1
tj(a)
, and hij = u
m
ij (xj − ai),∀i, j.
Thus, similar to Theorem 2, we can derive the following theorem for PIM.
Theorem 3.
(1)
∂JPIM(F (a), a)
∂ai
= −2
n∑
j=1
umij (xj − ai),
(2) if i 6= `, ∂
2JPIM(F (a), a)
∂ai∂a`
=
4m
m− 1
n∑
j=1
(tj(a))
m−1hij(h`j)T ,
(3)
∂2JPIM(F (a), a)
∂ai∂ai
=
4m
m− 1
n∑
j=1
(tj(a))
m−1hij(h`j)T + 2
( n∑
j=1
umij
)
× Is×s −
4m
m− 1
n∑
j=1
(||xj − ai||2 + β)−1hij(xj − ai)T .
Therefore, the Hessian matrix HPIMa of J
PIM(F (a), a) can be decomposed to HPIMa =
A+B where A = diag(A1, · · · , Ac), B = [Bi`]c×c, and
Bi` =
4m
m− 1
n∑
j=1
(tj(a))
m−1hij(h`j)T ,
Ai = 2
( n∑
j=1
umij
)
× Is×s − 4m
m− 1
n∑
j=1
(||xj − ai||2 + β)−1hij(xj − ai)T .
10
If 1 ≤ m ≤ s/(s − 2Fβ) where β > −min1≤j≤n{||xj − x¯||2}, then x¯ will not be a
stable fixed point. It is obviously that Fβ is a monotonically decreasing function of β
if β > −min1≤j≤n{||xj − x¯||2}. If β is large enough then x¯ is a stable fixed point for
almost any m > 1. Similarly, if β < 0 and |β| is large enough, then λmax(Cβ) is negative.
In this case, x¯ is also a stable fixed point. Hence, the selection of β is important for
the PIM algorithm. O¨zdemir and Akarun [12] suggested that β should be a fraction of
the distance between the closed two quantization centers, i.e., β = δmini6=j{||ai−aj||2},
where 0 ≤ δ < 0.5. Since β is always nonnegative in PFCM, the Hessian matrix in
PFCM is the same as that in PIM at the point x¯. Thus, the above analysis for PFCM
is also valid. Similar discussion was also in Yu and Yang [25]
In ICS algorithm, the determination of the parameter is essential issue. Next, we
give a theoretical explanation for this. We know that if
1− 2γ(c+ 1)cm−1 − 2m
m− 1λmax(C0) > 0,
then the point x¯ is a stable fixed point. If γ or c is large, then not only is 1 − 2γ(c +
1)cm−1− 2m
m−1λmax(C0) negative, but the Hessian matrix of ICS algorithm is not positive
semi-definite. If the Hessian matrix of ICS is not semi-definite, then the ICS algorithm
is meaningless because it cannot produce any local minimum. More details can be
founded in Yu and Yang [26]. Thus, when c increases, γ should decrease dynamically
and become very small positive. O¨zdemir and Akarun [11] experimented on 16-level
quantization with γ = 0.0005 and 8-level quantization with γ = 0.003 with good results
for most images. This is completely consistent with our theoretical analysis. However,
γ is negative, when c increases, the point x¯ is always a stable fixed point in ICS. This is
not expected and should be avoided in clustering. Therefore, it is reasonable that γ > 0.
Combining the theoretical results of PIM, PFCM and ICS, we have that x¯ is a stable
PICS fixed point if
1− 2γ(c+ 1)cm−1 − 2m
m− 1λmax(Cβ) > 0 and λmax(Cβ) < 0.5.
12
MSE is calculated by
1
2N
N∑
k=1
2∑
i=1
||aˆ(k)i − ai||2
where aˆ
(k)
i is the estimated mean vector for the kth trial and ai is the true mean vector.
First, we consider which value of m is suitable when implementing FCM. According
to the theoretical analysis in Section 3, we must compute λmax(C0). Because MSE is
evaluated by all trails, we also compute λ(k)max(C0) for the kth trial. Then, we use the
mean and standard deviation of λ(1)max(C0), · · · , λ(500)max (C0), to choose m. That is,
λ¯max =
N∑
k=1
λ(k)max(C0), SD =
1
499
N∑
k=1
(λ(k)max(C0)− λ¯max)2.
We work out that: (i) λ¯max = 0.55, SD = 0.02 in Test A1; (ii) λ¯max = 0.55, SD = 0.03
in Test A2; (iii) λ¯max = 0.55, SD = 0.03 in Test A3 and (iv) λ¯max = 0.70, SD = 0.03
in Test A4. These results illustrate the values of λmax(C0) are stable in each trail.
Since these mean values are greater than 0.5, there is no theoretically invalid weighting
exponent of the FCM for Tests A1-A4. In this case, how to select m depends on the
user. Because most researchers have proposed m = 2, we also choose m = 2 in this
section. Next, we choose w = 0.5, 1 and 2 in PFCM, δ = 0.01, 0.449 in PIM and
γ = 0.003, 0.0005 in ICS based on the results of Section 3. Furthermore, we compute
the mean and standard value of λmax(Cβ) in PIM when δ = 0.01. We obtain that: (i)
λ¯max = 0.48, SD = 0.02 in Test A1; (ii) λ¯max = 0.49, SD = 0.02 in Test A2; (iii)
λ¯max = 0.49, SD = 0.03 in Test A3 and (iv) λ¯max = 0.67, SD = 0.03 in Test A4. These
results illustrate the values of λmax(Cβ) are stable in each trail. According the analysis
of Section 3, we find that m = 2 is suitable for each test.
The numerical results are shown in Table 2. Compared PFCM with FCM, we see
that PFCM with w = 1.0 can lead to a MSE reduction of 27.6% in Test A1, 44.0% in
Test A2, 49.4% in Test A3 and 4.9% in Test A4, respectively. But PIM can not reduce
MSE. These results illustrate the penalty term (−w∑nj=1∑ci=1 umij lnαi) to the FCM
objective function can improve the accuracy of FCM, but PIM fails. This is why we
14
5. Application to ophthalmological MRI segmentation
In this section we use PICS (γ = 0.003, 0.0005 and w = 1.0) in a real case study
of MRI segmentation to differentiate between normal and abnormal tissues in ophthal-
mology. The MRI data sets are from a 2-yr old female patient that had been analyzed
by Yang et al. [21]. She was diagnosed with retinoblastoma of her left eye, an inborn
malignant neoplasm of the retina with frequent metastasis beyond the lacrimal cribrosa.
The MRI images showed an intra-muscle cone tumor mass with high T1-weight signal
images and low T2-weight signal images in the left eyeball. The tumor measured 20 mm
in diameter and occupied nearly the entire vitreous cavity. There was a shady signal
abnormality all along the optic nerve reaching as far as the optic chiasma near the brain.
Here we analyzed two MRI data sets. The first MRI data set is illustrated in Figs. 1
& 2. The second MRI data set is shown in Fig. 3. We first attempt to cluster the full
size images (Figs. 1 & 2) into the same five clusters as used by Yang et al. [21]. The
categories are as follows: Muscle tissue, connective tissue, nervous tissue, the lens, and
tumor tissue. According to Yang et al. [21], a window segmentation (Fig. 3 for the
second MRI data set) can be used to enhance areas of the tumor to better detect small
tumors. We also apply PICS (γ = 0.003, 0.0005 and w = 1.0) to a window segmentation
illustrated in Fig. 3. The lens and muscle tissue are excluded from the window so that
the original five categories are reduced to three; connective tissue, nervous tissue and
tumor tissue. A gray scale histogram comparison shows that there are actually three
peaks appearing in the segmentation window image.
The two pictures (Figs. 1 & 2) were processed at 400× 286 pixels. The pictures are
clustered into four tissue classes and one tumor class. From the red circle on the full
size two dimensional MRI in Fig. 1, we can clearly detect white tumor tissue at the
chiasma. PICS with γ = 0.003, w = 1.0 (see Fig. 1.2) and γ = 0.0005, w = 1.0 (see Fig.
1.3) are able to distinguish the tumor from the healthy tissue using five clusters. MRI
16
(cf. [10], [28]) for each algorithm is defined as
S =
|A ∩ Aref |
|A ∪ Aref |
where A represents the set of pixels belonging to the tumor tissue found by the ith
algorithm and Aref represents the set of pixels belonging to the tumor tissue in the
reference segmented image.
Because our criterion for performance evaluation is whether the segmentation method
can indicate the tumor tissue in the segmented image, a natural way for satisfying this
purpose is to describe the degree of similarity where it is not directly in terms of the
sets A and Aref but rather in terms of some swap-invariant combinations of A and
Aref . The two natural set-operations with union A∪Aref and intersection A∩Aref are
swap-invariant. Therefore, it is reasonable to describe the degree of similarity in terms
of union and intersection. From a general point of view, the defined score S is quite
reasonable for performance evaluation because, as one can easily see, the intersection
is always a subset of the union, and both of them are equal if and only if the original
sets A and Aref are equal. In other words, when intersection and union coincide, the
sets A and Aref also coincide. Intuitively, the closer between intersection and union is,
the more similar of A and Aref is. Moreover, adopting the similar idea of false negative
and false positive from Ferna´ndez-Garc´ia et al. [6], we may also define the following two
error types based on A and Aref :
False Negative (FN) =
|Aref ∩ Ac|
|Aref | , False Positive (FP) =
|Acref ∩ A|
|Acref |
,
where Aref ∩ Ac represents the set of pixels in Aref has not been detected to be tu-
mor tissue by the ith algorithm and Acref ∩ A represents the set of pixels in Acref has
been detected to be tumor tissue by the ith algorithm and Ac and Acref represent the
complements of A and Aref , respectively.
The values of S, FN and FP corresponding to Fig. 1.2 to Fig. 3.2 are shown in Tables
6-8. Since A ⊂ Aref in Figs. 5.2, 5.3 and 5.5, the values of FP are zero for these Figures.
18
applications in cluster analysis try the proposed PICS algorithm.
References
[1] J.C. Bezdek, Pattern Recognition with Fuzzy Objective Function Algorithms,
Plenum Press, New York, 1981.
[2] J.C. Bezdek, J.M. Keller, R. Krishnapuram and N.R. Pal, Fuzzy Models and Al-
gorithms for Pattern Recognition and Image Processing, Kluwer Academic Pub-
lishers, Boston, 1999.
[3] P.G. Bryant and J.A. Williamson, Maximum likelihood and classification: a
comparison of three approaches, in: W. Gaul and M. Schader, Eds., Classification
as a Tool of Research, North-Holland, Amsterdam, 1986, pp. 35-45.
[4] L.P. Clarke, R.P. Velthuizen, M.A. Camacho, J.J. Heine, M. Vaidyanathan, L.O.
Hall, R.W. Thatcher and M.L. Silbiger, MRI segmentation: methods and appli-
cations, Magnetic Resonance Imaging, vol. 13, pp. 343-368, 1995.
[5] R.O. Duda and P.E. Hart, Pattern Classification and Scene Analysis, Wiley, New
York, 1973.
[6] N.L. Ferna´ndez-Garc´ia, R. Medina-Carnicer, A. Carmona-Poyato, F.J. Madrid-
Cuevas and M. Prieto-Villegas, 2004, Characterization of empirical discrepancy
evaluation measures, Pattern Recognition Letters, vol. 25, pp. 35-47, 2004.
[7] R.C. Gonzalez and R.E., Woods, Digital Image Processing, Massachusetts:
Addison-Wesley, 1992.
[8] J.S. Lin, K.S. Cheng and C.W. Mao, Segmentation of multispectral megnetic
resonance image using penalized fuzzy competitive learning network, Computers
and Biomedical Research, vol. 29, pp. 314-326, 1996.
20
[18] J., Suckling, T., Sigmundsson, K., Greenwood and E.T., Bullmore, A modified
fuzzy clustering algorithm for operator independent brain tissue classification
of dual echo MR images. Magnetic Resonance Imaging, vol. 17, pp. 1065-1076,
1999.
[19] W. Wei and J.M. Mendel, Optimality tests for the fuzzy c-means algorithms.
Pattern Recognition, vol. 27, pp. 1567-1573, 1994.
[20] M.S. Yang, On a class of fuzzy classification maximum likelihood prosedures,
Fuzzy Sets and Systems, vol. 57, pp. 365-375, 1993.
[21] M.S., Yang, Y.J., Hu, K.C.R., Lin and C.C.L., Lin, Segmentation techniques for
tissue differentiation in MRI of Ophthalmology using fuzzy clustering algorithms,
Magnetic Resonance Imaging, vol. 20, pp. 173-179, 2002.
[22] M.S. Yang and C.F. Su, On parameter estimation for normal mixtures based on
fuzzy clustering algorithms, Fuzzy Sets and Systems, vol. 68, pp. 13-28, 1994.
[23] M.S. Yang and N.Y. Yu, Estimation of paramrters in latent calss models using
fuzzy clustering algorithms, European Journal of Operational Research, vol. 160,
pp. 515-531, 2005.
[24] J. Yu, Q.S. Cheng and H.K. Huang, Analysis of the weighting exponent in the
FCM, IEEE Trans. Syst. Man, Cybern., vol. 34, pp. 634-639, 2004.
[25] J. Yu and M.S. Yang, Optimality test for generalized FCM and its application
to parameter selection, IEEE Trans. Fuzzy Systems, 2004 (Accepted).
[26] J. Yu and M.S. Yang, A note on the ICS algorithm with correction and theoretical
analysis, IEEE Trans. Image Processing, 2004 (Accepted).
[27] L.A. Zadeh, Fuzzy sets, Inform. Control, vol. 8, pp. 338-353, 1965.
22
  
Fig.1 Original MR image 
Fig. 1.1 Segmentation results 
of PICS(γ=0.003,w=1.0) 
Fig. 1.2 Segmentation results 
of PICS (γ=0.0005,w=1.0) 
 
 
 
 
