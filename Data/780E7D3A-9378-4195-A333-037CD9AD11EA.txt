1行政院國家科學委員會專題研究計畫成果報告
帕金森大白鼠於沈浸式虛擬實境中光流資訊與空間漫遊之研究
計畫編號：NSC－95－2221－E－269－003
執行期間： 95 年 8 月 1 日至 96 年 7 月 31 日
計畫主持人：李筱瑜 執行單位：遠東技術學院資訊管理學系
中文摘要
近來，許多虛擬實境技術已臻成熟，已
成為未來的趨勢，其中的成功例子之一為產
生虛擬透視的方格，用於輔助於帕金森症者
克服步態初始及行動困難等問題。研究相信
這些成效是利用視覺輔助提供額外的移動對
視覺資訊。但目前研究較少探討在帕金森氏
症的患者主要是由於光流資訊的缺乏，因而
造成患者喪失在空間漫遊之能力的較深入之
研究。本研究亦利用沉浸式虛擬實境開發出
一監控分析系統，並在限制環境內對實驗動
物進行刺激反應測量。我們針對帕金森氏症
鼠與正常大鼠在跑步機上的頭部活動情況以
及行進間的步態做比較，結果呈現出帕金森
氏鼠在腳步擺盪、著地停留時間均較短。藉
由本研究所開發之分析系統，未來得以作為
驗證視覺互動對於動物行為的依據。
關鍵字：虛擬實境、帕金森氏症、步態分析、
動物行為
Abstract
The utilization of integrated virtual reality
(VR) environment for clinical training and
applications has become a promising trend.
Among them, virtual cue for providing grids on
the floor has helped the Parkinson’s Disease 
(PD) patients to overcome the gait impairment.
It is believed that the gait improvement is
facilitated by the perception of motion generated
by moving visual cues. However, fewer studies
have been focused the underlying mechanism of
optic flow deficiencies as a cause of problems of
spatial navigation in PD. In this research, we
developed an animal behavior test environment
with immersive virtual reality which allowed us
to measure and interact with the animal
responses to the stimuli in a limited space. We
compared gait patterns and head mobility in
normal and PD rats while performing a treadmill
locomotion task. The PD rats resulted in an
impairment of treadmill walking manifested by
a decrease in swing and stance time of both
forelimbs. The validation tests of animal
behaviors on the developed VR system were
performed based on the visual interaction to the
PD animal behavioral studies.
Keywords: Virtual environment, Parkinson’s 
Disease, gait analysis, Animal Behavioral.
一、背景與目的
帕金森氏症是一種相當常見的神經系統
退化性疾病，好發於大於65歲老年人。致病
原因是患者腦部中產生的神經傳導物質多巴
胺(Dopamine)不足所致，而多巴胺分泌不足則
與黑質(Substantia nigra)細胞退化有關。最主
要的症狀包括動作遲緩(Bradykinesia)、 靜止
性顫抖(Resting tremor)、僵硬(Rigidity)、以及
平衡失調 (Posture instability) 等動作困難
(dyskinesia)的問題，明顯影響日常生活的品
質。雖然在臨床上左多巴(levodopa (L-dopa))
常用於直接補充多巴胺的數量，對帕金森氏
症的症狀有全面的改進 [1]。然而，服用左多
巴常出現如暈眩、口乾、姿態性低血壓、便
祕、情緒不穩等副作用，對帕金森氏症患者
又是另一項挑戰。在行動障礙上，帕金森氏
症 患 者 除 了 不 易 完 成 步 態 初 始 (gait
initialization)外，也有所謂unilateral onset 的
問題，造成帕金森氏症患行動時轉彎遲緩或
轉彎困難等情形。先前研究顯示這些是帕金
3式克服了雙側注射術後大白鼠照護的困難是
目前研究常採用的方式[10,11]。其動物模型實
驗過程如圖一所示:
圖一：慢性帕金森氏症大鼠之模型建立
(B) 步態的引導與紀錄
圖二：大鼠跑步機設計(A)與大鼠透過跑步機
上透明隔間的引導直線前進，並且由側方及
後方攝影機做紀錄(B)。
帕金森氏症的大鼠最常見的症狀為肢體
僵硬，動作緩慢，顫抖及步伐不穩與步態初
使困難等。因此可藉由一跑步機來紀錄老鼠
在跑步機上行走時，搭配高速攝影機紀錄老
鼠踏在跑步機上之步態[12]。由以上這些裝置
可紀錄並計算出老鼠的擺盪(swing)與著地
(stance)時間與步頻(stride frequency)等資訊。
因此需要使用跑步機引導及訓練大鼠步
行。本研究觀察訓練前及訓練後大鼠步態活
動情況，並且與正常大鼠步態相互比較，作
為實驗之依據。大鼠於跑步機上的步態活
動，透過高速攝影機監測和記錄其步行情況
(如圖二)。
(C) 頭部活動情況之偵測
本研究所設計的動物行為偵測系統，其
主要的功能是測量實驗動物頭部之活動狀
況。偵測系統是透過安置在大鼠頭部之加速
規，以及大鼠背部之接受器的相互比對而
成。大鼠之活動情況利用背部接收器感測頭
部加速規之變化，從數據中得以了解為大鼠
頭部與身體是否維持在同一水平，且可以得
知大鼠在靜態或動態時的頭部活動表現，並
將測量到的數據利用藍芽傳輸傳送至遠端電
腦。(如圖三)
圖三：動物頭部行為偵測系統架構圖
(C)改良式先前設計之動物行為實驗箱
本研究運用電腦聲光、影像技術去營造
出一個具有擬真(realistic)效果的虛擬環境，並
且投影至改良式動物行為實驗箱，將大鼠放
置在最佳位置(sweet pot)，不須配戴立體眼鏡
所觀看的影像即具有前後互動的沉浸式效
果，使大鼠有如身歷其境般的沈浸(Immersive)
於整個虛擬場景之中，如下圖四。
A
B
5S w in g t im e
T re a d m ill s p e e d (c m /s )
6 c m /s 1 0 c m /s 1 4 c m /s
T
im
e
(s
ec
)
0 .0 0
0 .0 5
0 .1 0
0 .1 5
0 .2 0
0 .2 5
N o rm a l ra t
P D ra t
S ta n c e tim e
T re a d m ill s p e e d (c m /s )
6 c m /s 1 0 c m /s 1 4 c m /s
T
im
e
(s
ec
)
0 .0
0 .5
1 .0
1 .5
2 .0
2 .5
N o rm a l ra t
P D ra t
圖五：正常大鼠與帕金森是大鼠在步行時之
擺盪期與著地期之差異。
(C) 動物行為偵測系統
透過偵測系統發現，相較於一般大鼠，
帕金森氏症之大鼠易呈現出頭部偏移、以及
歪斜等症狀，因此偵測系統頭過加速規將實
驗動物的頭部位置等參數經轉換後，利用藍
芽傳輸至電腦系統處理，可以了解大鼠在光
流資訊引導下的頭部活動情況，並配合互動
給予引導之資訊，達到引導與互動的一致性
(如圖六)。
圖六：透過偵測系統偵測大鼠頭部活動情況
(D)改良式動物行為實驗箱
改良後的動物行為實驗箱，使動物在虛
擬環境中可達到更具彈性的活動空間，並且
可利用加速規的角度測量取代先前半懸吊式
機械手臂，在這樣的環境下，使得帕金森式
症大鼠的步態以及頭部活動測量變的更為精
確(圖七)。
圖七：虛擬實境動物實驗箱搭配步態分析系
統。
四、計畫成果自評
我們研究採用半球形虛擬環境(domical
virtual environment)來做為動物虛擬實境顯像
的設備。此虛擬實境環境系統可分為兩部
分：分別為沈浸式虛擬實境場景及動物行為
偵測裝置。沈浸式虛擬實境場景可以涵蓋於
動物的整個視野，而實驗用動物置於一跑歨
機上，將動物限制於虛擬實境場景的中心，
由懸掛設施及我們所設計的行為偵測裝置，
使得動物視覺及動作能直接與虛擬實境的場
景及環境的互動，可訓練實驗白鼠的空間觀
視覺刺激(visual response)。此一場景可以依實
驗者的需求設計不同複雜程度及大小的場
景。而這一切都可以在一個比動物實驗籠稍
大的空間中進行，更重要的特色為所有的動
物行為發生在一既定的空間，其行為皆可輕
易的紀錄，這些功能都是神經科學及認知科
學等期望已久的實驗模式，但是現有動物行
為觀測系統所無法提供的功能。此一成果已
發表於 JMBE [14]。
此外，此研究已整合此一虛擬實境系統
與帕金森氏症大鼠動物模型，進行在視覺光
流資訊刺激下動作偵測分析，視需要給於機
B
行政院國家科學委員會補助國內專家學者出席國際學術會議報告 
                                                     95 年  9 月 10 日 
報告人姓名 李筱瑜 
 
 
服務機構 
及職稱 
遠東技術學院 
副教授 
 
     時間 
會議 
     地點 
2006年 8月 26日至 8月 30日
紐西蘭皇后鎮 
本會核定 
補助文號 
NSC 94-2213-E-269-005- 
會議 
名稱 
(中文) 第二十四屆紐澳亞太腦科學會議 
(英文) 24th Australasian Winter Conference on Brain Research (AWCBR 2006) 
發表 
論文 
題目 
(中文) 應用神經工程技術於帕金森症大白鼠的評估與治療研究 
(英文) Development of Virtual Reality Environment for Behavioral Study of Rats
報告內容應包括下列各項： 
一、會議經過： 
此次大會是第二十四屆國際澳亞冬季腦神經科學研討會（Australasian 
Winter Conference on Brain Research(AWCBR)）每年一次的國際會議，本會議
強調研究與實作的人員共同參與，特別是在學術研究與實作上觀念的交換、
研究方向及雛形的建立，本次會議是於 2006 年 8 月 28 日至 8 月 30 日在紐西
蘭皇后鎮(Queenstown)的Copthorne Hotel舉行。計有三百餘位醫學、生化、電
子等學者的會議，因本會議包含理論及各種實務應用之不同專業領域，規模
上應屬中型會議，紐澳、歐洲及美洲等各國專業研究人員齊聚於一堂。 
本人於七月二十三日上午由高雄出發，由香港轉機至奧克蘭 入境紐西蘭，再
轉機至南島的但尼丁市，在當地時間五日晚間抵達但尼丁市。抵達後首先前
往位於但尼丁市的奧塔哥大學以自費方式進行一個月的學術交流訪問。從八
月二十六日至八月三十日之間參加研討會，與國際學者交換研究心得。 
AWCBR 開會經過 : 開會前一天由但尼丁租車開至開會地點皇后鎮
(Queenstown)，與會者大都開車前往，費時約 4 個小時，沿途風光旖麗，車子稀
少，因皇后鎮機場小班次少，與會者大都由但尼丁或 Christchurch 開車前往。 
二、與會心得 
今年會議安排每天早上 8 點至 9 點半、下午 4 點至 6 點以及傍晚 8 點至 10
點三段式會議，每階段各有多場論文報告，此次會議主辦地是在紐西蘭皇后鎮。
紐西蘭位於南半球此時正值冬季，皇后鎮是一觀光旅遊發達的城市。本次會議方
式以壁報發表 (Poster Sessions) 為主，約近 100 篇論文發表。 
 
此次壁報發表之論文為“Development of Virtual Reality Environment for 
Behavioral Study of Rats” H. Y. Lee, M. D. Kuo, Y. S. Ou-Yang, J. J. J. Chen 
 
 
(3) Rewarding 與 Addition:  本會程主要探討 rewarding 跟 addition 的
相似機制，尤其是 Dr. Reynolds 提出 Cholinergic interneurons 於帕金
森症大白鼠的 rewarding 的獨特見解。相同的裡論也適用於注意力缺失過
動症(Attention deficit hyperactivity disorder，ADHD) 的關係，ADHD
為具有行為問題的學齡兒童常見的診斷，導致注意力缺失過動症的原因至今
仍然沒有定論，但每一百個兒童中約會出現三個到五個，可見其盛行率之
高。這類兒童的學校活動執行技巧，包括基本認知能力之學習、閱讀技巧與
策略及精細動作能力，均較一般兒童落後，使其遭受學習挫折機率相當高，
以致學習困難，逃避學習過程，間接形成學習障礙之問題。這類兒童的主要
症狀為注意力程度不恰當、容易分心、活動度過高、及過於衝動無法控制，
而導致社會功能上的障礙，即在家庭、學校與其同儕相處出現困難，同時亦
影響其後續學業學習、就業過程及情緒發展上的表現，帶給其主要照顧者無
形的壓力，並且進而成為社會之龐大問題及負擔。除了過高的活動量、易衝
動及注意力上的問題外，這類兒童常伴隨有平衡感、動作協調、視覺動作技
巧及動作計劃的問題。 
 
(4) 虛擬實境與視覺誘發電位(VEP)之研究: 虛擬實境也逐漸廣泛應用於神
經心理學臨床上，對於認知障礙的治療包括注意力(attention and 
concentration)、空間定向感(spatial orientation)、非語言記憶力
(nonverbal memory)、推理（reasoning）、類化（generation）、組織
（organization）、抽象層次（level of abstraction）、安全性判斷力
（judgment of safety）、語言記憶力（verbal memory）及解決問題（problem 
solving）能力的介入，先前的臨床應用大部分是利用圖卡和積木空間位置
的改變進行治療。這樣的訓練或治療方式對於孩童在二維及三維空間對所呈
現的圖像和立體圖像進行反應及辨認上是有幫助的。近幾年來，無論國內外
的認知治療或教育機構以電腦這項科技性的工具提供一個虛擬的治療性環
境將這些治療的方式加以應用，利用虛擬實境系統提供各式場景，給予受測
者各種不同模擬情境的認知活動；患童可以利用虛擬實境系統之週邊感知介
面，如頭盔顯示器或回饋手套等與環境進行互動。 
 
虛擬實境系統之建立不但可整合 VEP 訊號與 MRI 影像，，所建構的模型結構
與顯示法也可應用於腦部的手術模擬，兼具臨床與實用的價值。視覺誘發電
位(VEP)為臨床常用之誘發電位檢查之一。主要用途在於偵測視覺路徑上可
能之病灶。通常臨床上只注意記錄到的訊號延遲(delay)是否正常以及波形
是否正常，對於訊號出現的位置則無法精確的定位，因此只能粗略的知道視
覺路徑有病灶。假如能夠精確的定位，則對於疾病的症狀能有更準確的掌
握。Single Trial 的 VEP 訊號即時擷取在近年來已是相當熱門的研究課題，
而結合生醫訊號與醫學影像的構想目前才方興未艾。尤其是包含時空訊息的
VEP 訊號更是迫切需要視覺化的顯示。利用虛擬實境顯示系統的建立多種類
物體彩色透明化的顯示，本會議提出了許多新的構想，對應法以完成不同色
Development of Virtual Reality Environment for Behavioral 
Study of Rats 
 
H. Y. Lee1, M. D. Kuo1, Y. S. Ou-Yang 2, J. J. J. Chen2
 
1Department of Management Information Science, Far East University, Tainan County  
 
2Institute of Biomedical Engineering, National Cheng Kung University, Tainan, 
Taiwan, ROC 
Abstract 
Recent developments in information technology have facilitated the use of virtual 
reality (VR) techniques for simulation surgery, rehabilitation training, and cognitive 
neuroscience studies. Several VR studies have demonstrated that it is feasible for 
animals to interact with VR by using rewarding scheme and visual cues for attention 
processes, spatial memory, and executive functions. This study aims to develop an 
animal behavior testing environment with immersive VR which allowed us to interact 
with the animal responses to the stimulations in a limited space. We integrated the 
dome screen for displaying visual stimuli and a motion detection subsystem for 
sensing the animal’s intention. In our self-design animal cage, the front hemisphere 
screen connected the outer cage in one-degree-of-freedom for pitch rotating which 
ensures the animal is constrained at optimal view point during the experiment. The 
intentions of animal were detected by body position sensing device, which sent 
rotation and yaw angles via TCP/IP transmission to alter VR generation. A camera 
was mounted behind and slightly above the animal which allowed experimenter to 
observe the locomotion of rat and to synchronize the recording of brain activity. 
Validation tests of animal behaviors on the developed VR system were performed 
based on the visual interaction to the animal behavioral studies. 
 
Keywords: Immersive Virtual Reality, Animal Behavioral Study  
single recaptured males [4]. In contrast, investigations of the navigational abilities of 
rats have long been restricted by the limited space of laboratory and the number of 
landmarks that can be changed quickly and accurately without disturbing the animal 
[5]. Attempts have been made to construct a virtual environment (VE) that could be 
used to investigate the spatial navigation abilities of rodents. In one of such set-ups, 
animals were trained in a Y-maze made of six monitor screens, and the scenes on the 
two monitors that constitute a particular arm. However, the experimental results 
suggested that the animals did not treat the presentation of scenes as VE in which to 
navigate, but rather as objects within the real laboratory environment [6, 7, 8]. 
VR technology is increasingly being recognized as a useful tool for the 
assessment and rehabilitation of cognitive processes and functional abilities. Much 
like an aircraft simulator serves to test and train piloting ability, virtual environments 
can be developed to present simulations which target human cognition and behavior. 
In addition, virtual environments immerse subjects in worlds that appear physically 
real, but where conditions can be controlled. The capacity of VR to create dynamic 
3D stimulation environments, in which all behavioral responding can be recorded, 
offers assessment and rehabilitation options that are not available using traditional 
neuropsychological methods. In recent years, developments of information and 
multimedia technology have facilitated the applications of VR for industry, commerce, 
medical science. In medical science, VR systems have been extensively applied to 
simulation surgery [9, 10], rehabilitation training [11, 12] and human behavioral study 
[13]. Several studies utilized VR techniques to develop and test components of 
cognitive processes including attention processes [14], spatial abilities [15, 16], 
memory [17] and executive functions [18]. 
Research has found that non-human primates were able to navigate in 2-D 
projections as virtual environment for studying spatial learning [19]. For insects, the 
virtual environments pass through LCD projector, which were projected onto a 
rear-projection dome screen (66 cm diameter) and occupied 250 degree of the moth’s 
field of view. The position of the abdomen was monitored by an optical sensor that 
fed into PC for controlling the virtual scenes. The wind source produced pheromone, 
was placed in front of the head of the moth. An infrared video camera was placed 
above and slightly behind the moth to record abdominal ruddering and wing 
kinematics during tethered flight. The results indicated that the insect was able to 
of animal was monitored by body position detection and fed to PC that controls the 
generation of the virtual environments. Validation tests of animal behaviors on the 
developed VR system were performed which served as the initial step for future study 
of the brain correlation of spatial learning and behavioral activities in a novel 
experiment environment.  
rat is half-suspended on the treadmill close to the focus center of the dome. These VR 
environments were projected onto a dome-shaped rear projection screen at 640 × 480 
pixels and image reversed to correct for visual stimuli at the low light levels of 30-84 
lux for rats [26, 27]. 
 
 
Figure 2. Immersive VR systems for behavioral studies of rats 
Three-dimensional simulated environments were created using the Virtools 
software of Virtools web player. Virtools allows the creation of various scenes 
operating in a real-time interactive scheme. The interactive rendering ability of the 3D 
scenes produces several visual stimulation patterns including alternating 
checkerboards, optical flow fields and other patterns for validation purposes. The 
optical flow consisted of a square tunnel with vertically alternate black and white 
rectangular, as shown in Figure 3. The front exit of tunnel was a gray square so that a 
distinct exit was visible. 
Simulated environments were generated on a laptop Pentium M platform using 
an ATI Mobility Radeon X600 chip. This configuration produced interactive 
environments at a rendering rate of 60 frames per second, which is above the flicker 
fusion frequency of the eye of rat. These 3D scenes were projected onto the 
rear-projection dome screen to interact with the sensing positions of rat.  
sufficient for behavior studies of animals. The treadmill was able to appropriately 
provide the rat for one direction forward without a large space. 
Body position sensing device consists of a load cell and a rotation sensor for 
detecting the postural variation of rat’s body while walking on the treadmill. The 
animal is haltered by a soft harness attached to small aluminum sheet which links the 
load cell and allows the rat to lift and lower its body. The animal is constrained at the 
optimal view point and partially sustained its body weight during treadmill activity. 
The load cell (MLP-10, Temecula, California) could tolerate maximum weight of 10 
lb, which could measure the shift of animal weight in up or down direction. The 
analogue output of load cell is amplified and filtered before sending to analogue to 
digital converter (ADC). The amplification circuit includes instrumentation amplifier, 
DC offset adjustment and low-pass filter. The low-noise instrumentation amplifiers, 
INA118, with high common mode rejected ratios (CMRR) (>110 dB at gain = 1000) 
was used to perform an initial amplification of the recorded signal of load cell. After 
adjusting the DC baseline offset, the signal was low-pass filtered (cut-off frequency = 
16 Hz) to reduce the 60-Hz power line interference and high frequency noise. 
The yaw angle of the animal was detected by the rotary position sensor (CP-3UY, 
MIDORI, TOKYO, JAPAN) permitting the range of yaw angle from -125 to 125 
degree. In our design, we constrained the yaw angle to -40 to 40 degree to the front 
view of rat’s visual field using a mechanical limiter. The output of rotary position 
sensor was amplified (gain = 10) (IA TL074) and low-pass filtered (cut-off frequency 
= 16 Hz) for rotary position sensing. 
The signals from load cell and rotary position sensor were sent to PCI-6143 
DAQ card (National Instruments) for continuous data acquisition and storage for 
off-line analysis. Meanwhile, the behavior of the animal during an experiment was 
monitored by a Marlin F-033C video camera (Allied Vision Technologies Inc., Marlin, 
Germany) operating at 30 frames per second (a shutter speed of 33ms). The camera 
was mounted behind and slightly above the animal which allowed experimenter to 
observe the locomotion of rat without any interference to rat’s visual field. 
 
(D) Transmission between immersive VR and body position sensing 
The body position sensing data was displayed on a GUI programmed in 
LabVIEW software. The rotary and elevation angles were translated into the strings 
 
Figure 4. Design of an animal cage for behavior study in VR system 
To represent various events in the behavior studies, corded voltage was utilized 
as synchronization pulses. The synchronization pulses from the DIO were sent to 8 
LEDs individually for triggering the optical outputs as wellas passed through the 
amplified voltage output to ADC. The voltage output is the summation of DIO PO.0 
through 7 coded in 2n  ratio to represent at most of 8 events and their combinations. 
The video camera grabs the images continuously that include rat’s behavior, 
simulated virtual environment and LED outputs. The video of animal motion were 
recorded on an AVI (Audio Video Interleave) file by using LabVIEW program in PC. 
Therefore, the integration of the recorded video and data sensing were programmed in 
Matlab software for off-line analysis. This configuration allowed for off-line 
synchronization of the video of the simulated environment, behavioral video and 
physiological data. 
    In our system, the lag time occurred between the start of body movement to 
initiation of a change in VR scenes. This experiment aimed to quantify the delay time 
in order to verify the feasibility of the integrated VR system for animal study. In this 
experiment, we swing the rigid links which connect with the rotary position sensor to 
alter the yaw angles. The yaw angles were changed within -20 to 20 degree or -40 to 
40 degree cases The swing frequency for rat was appropriately between 0.5 and 1 Hz. 
Thus, the simulation swing frequency were set at 0.5 and 1 Hz by using computer 
metronome during this experiment. The VR scenes was the optic flow pattern after 
adding a feature of “A” in the center for accurately localizing the center position of 
scene. The video and data sensing from VR scenes and the shift of the yaw angle were 
and weight meters, the string of body position sensing. For TCP/IP server function, 
TCP/IP address and port setting can be selected from the GUI. For digital I/O function, 
this parameter includes digital output setting.  
The body position sensing signals were displayed in waveform chart, which were 
translated into weight and angle values in real time. These signals also were translated 
into the strings which were transported to immersive VR system using TCP/IP 
transmission for controlling the VR scenes at 30 fps (frames per second). In addition, 
the synchronization pulse from digital output was sent to DAQ card for displaying in 
waveform chart and storage.  
The behavior of the animal during an experiment was monitored by the Marlin 
F-033C video camera transmitter via IEEE 1394 digital interface. The GUI written in 
LabVIEW program is used to grab the video for monitoring the locomotion of rat. The 
video camera operated at 30 frames per second with a shutter speed of 33ms. The 
pixel depth was set to be 8-bit gray level at 640 × 480 pixels of image size. 
 
(B) Example of animal position sensing data 
The testing animal was constrained on the treadmill at optimal view point in the 
immersive environments during treadmill activity. The VR environments were 
simulated the optic flow stimulation. In this condition, turning direction was presented 
as rotation of the yaw angle either clockwise (left turn) or counterclockwise (right 
turn). Upward and downward turns of rat and rotations were represented as negative 
or positive DC offset, which were digitized and recorded on a continuously sampled 
channel along with the time stamps of synchronization pulses. The movements of the 
rat’s body drove changes in the heading and rotation of simulated environment. Figure 
5 are sample data showing that the movement of the rat produced turns in the optic 
flow environment. Data from this example were from an experiment designed to test 
the effects of reversing the polarity of the body position feedback. Thus, movements 
of the rat’s trunk to the right produced a left turn in VR environment. In addition, the 
sensing data were translated into frequency domain to observe the rhythmic 
movement of rat, as shown in Figure 6, which indicated the swing frequency for rat 
was appropriately 1 Hz. Nevertheless, these data clearly demonstrate the ability of the 
rat to walk in VR system. 
 
Figure 6. The frequency distribution of (a) rotation and (b) weight sensing data when 
rat walked on a treadmill. 
 
Figure 7. Matlab GUI for observing the sensing data and video of synchronization, the 
video image corresponds to the middle of sensing data, and the display of data is 
within 10 seconds. 
Integration of video and position sensing data are in Matlab GUI for off-line 
analysis, as shown in Figure 7. The parameters include data sampling rate and view 
alternating display has been established. During the initial animal behavior trial, the 
rats exhibited characteristic turning pattern in response to imposed rotations of the 
visual environment (Fig. 3.8). The locomotion of the rats produced specific pattern 
during treadmill walking. Our results indicated that the locomotion pattern changes in 
yaw angles between -20 to 20 degree at a frequency between 0.5 to 1 Hz. Therefore, 
this kinematic range was adopted in our validation tests for evaluating the lag time 
between the positioning data and those acquired from video display which might be 
caused by LabVIEW acquisition software and TCP/IP transmission. The lag time was 
around 180-270 ms which should be taken into consideration during future design of 
using VR as a visual stimulation for rats. 
During VR displaying, our system did not address the exact relationship between 
body ruddering and turning in the real world acquired from position sensing device 
and the visual scenes from VR display. Our approach was based on constraints 
determined by the maximum excursion of the body during tethered ruddering as well 
as the maximum rotational visual flow (clockwise or counterclockwise) produced by 
the software. Although it is possible for our system to match the visual adaptability to 
variable coupling constants by adjusting the sensitivity in the Virtools softwarem the 
exact relation might be difficult to evaluate from varied position of rats. Our current 
design presents the rat with video images rendered at 30 frames/s, which, given the 
flicker fusion frequency of the rat’s eye at the light levels we used 30-84 lux is 
sufficient to produce a smooth visual flow for this particular preparation [26, 27]. 
In comparison with our system to roaming global approach designed by Hölscher 
et al.’s device [21], our current configuration does not allow the rat to change its x 
axis. Our approach utilized the treadmill which required less space and achieved an 
immersive environment by using only a single LCD projector to project onto dome 
screen. However, the treadmill produces constant forward movements without 
feedback. The movement of the rat could be alleviated by feedback control of 
treadmill speed from the intention of rat forward movement. However, the inclusion 
of motor-driven treadmill might cause magnetic interference to the recording of brain 
activity during animal behavior studies which was the primary research goal of this 
study. Thus, appropriate design of speed-controlled treadmill placed outside the cage 
to reduce the potential interference to the brain information recording would be highly 
desirable.  
3-6, 1997. 
[10] B. Barnes, A. S. Menon, R. Mills, C. D. Bruyns, A. Twombly, J. Smith, K. 
Montgomery, and R. Boyle, “Virtual reality extensions into surgical training and 
teleportation Information Technology Applications in Biomedicine,” 2003. 4th 
International IEEE EMBS Special Topic Conference on 24-26 April 2003 
Page(s):142 – 145. 
[11] N. G. Kim, C. K. Yoo, and J. J. Im, “A New Rehabilitation Training System for 
Postural Balance Control Using Virtual Reality Technology,” IEEE Transactions 
on Rehabilitation Engineering, 7, No. 4, 482-485, 1999. 
[12] C. G. Song, J. Y. Kim, and N. G. Kim, “A New Postural Balance Control System 
for Rehabilitation Training Based on Virtual Cycling, IEEE Transactions on 
Information Technology in Biomedicine, 8, No. 2, 200-207, 2004. 
[13] N. Burgess, E. A. Maguire, and J. O'Keefe, “The human hippocampus and spatial 
and episodic memory,” Neuron. 35, 625-41, 2002. 
[14] J. P. Wann, S. K. Rushton, M. Smyth, and D. Jones, “Virtual environments for 
the rehabilitation of disorders of attention and movement. In G. Riva, (Ed.), 
Virtual Reality in Neuropsycho-physiology: Cognitive, Clinical, and 
Methodological Issues in Assessment and Rehabilitation Amsterdam: IOS Press, 
157-164, 1997. 
[15] R. S. Astur, L. M. Ortiz, and R. J. Sutherland, “A characterization of 
performance by men and women in a virtual Morris water task: A large and 
reliable sex difference,” Behavioural Brain Research, 93, 185-90, 1998. 
[16] J. McComas, J. Pivik, and M. Laflamme, “Childrenís transfer of spatial learning 
from virtual reality to real environments,” CyberPsychology and Behavior, 1(2), 
121-128, 1998. 
[17] D. A. Johnson, F. D. Rose, S. K. Rushton, B. Pentland, and E. A. Attree,” Virtual 
reality: A new prosthesis for brain injury rehabilitation,” Scottish Medical 
Journal, 43, 81-83, 1998. 
[18] L. Pugnetti, L. Mendozzi, E. A. Attree, E. Barbieri, B. M. Brooks, C. L. Cazzullo, 
A. Motta, and F. D. Rose, “Probing memory and executive functions with virtual 
reality: Past and present studies,” CyberPsychology and Behavior, 1(2), 151-162, 
1998. 
[19] N. Sato, H. Sakata, Y. Tanaka, and M. Taira, “Navigation in virtual environment 
