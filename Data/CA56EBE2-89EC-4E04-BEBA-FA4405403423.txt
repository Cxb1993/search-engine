行政院國家科學委員會補助專題研究計畫成果報告 
應用複合式資料探勘技術於人工生殖懷孕率預測之研究 
 
 
計畫類別：■個別型計畫  □整合型計畫 
計畫編號：NSC100－2221－E－027－018－ 
執行期間：100 年 8 月 1 日 至 101 年 7 月 31 日 
 
 
計畫主持人：陳凱瀛 
共同主持人： 
計畫參與人員：陳詩旻、陳柏嘉、蘇芳亭、黃依璇、陳力禎、
林修毅、鄭尹超、吳雅娟、羅詮余 
 
執行單位：國立台北科技大學 
 
中  華  民  國 1 0 1 年 7 月 3 1 日
3 
classification method to predict the pregnancy rate of IVF treatment. The results of this study show 
that higher prediction accuracy rate obtained by using a single classification (Back - propagation 
Network), followed hybrid classification model in principal component analysis combined back 
propagation network.
Keywords: Artificial Reproduction Technology, Data mining, Feature selection, 
Classification 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
5 
2. 研究目的 
人工生殖醫療診斷的歷史資料中隱含許多有用的資訊，但其數量龐大且複
雜，然而，透過資料探勘技術我們得以從這些粗糙且未經整理過的資料中挖掘出
潛藏的知識。而這些特徵屬性複雜的資料必需透過前置處理才能進行有效的分
類，一般而言，特徵愈多，應能提供愈多的區別力，但過多的特徵易造成學習績
效不佳，分類模式過度適配(Over Fitting)的問題，因此，前置處理步驟當中的特
徵選取就顯得格外重要，它能從一個數量龐大的特徵集合當中挑選出有助於辨識
的特徵子集合，並過濾含有不恰當、多餘或是被認為是雜訊的資料，以減少分類
時所花費的運算時間，更能改善分類問題的正確率。 
特徵選取可依特徵子集合產生方式不同而有不同架構，可分為 Filter 模式及
Wrappers 模式。Filters 方法是指特徵選擇的學習方式通常是由專家方法或統計方
法，最常見的方法有主成份分析(Principal Component Analysis, PCA)、卡方檢定
(Chi-square Test)、線性區別分析(Linear Discriminant Analysis, LDA)等，計算效率
較高且較為簡單。但是，這種方法的缺點是在特徵空間被選擇的變數，統計上較
有不客觀的考量，易造成不適當的訓練，使分類結果可能較差。Wrappers 特徵選
取的方法是藉由最佳化演算法來產生高正確率的特徵選入特徵子集合，常見的方
法有基因演算法 (Genetic Algorithm ,GA)及粒子群演算法 (Particle Swarm 
Optimization, PSO)等，此模式通常需要的計算量較大，所耗費的運算時間也較長。 
綜合過去文獻整理後發現，在人工生殖懷孕率預測方面，透過不同的特徵選
取模式對分類結果有顯著的差異，因此本研究將發展出複合分類模型，並以 Filter 
方法進行特徵選取，採用過去相關文獻中較少被使用到的主成份分析法與線性區
別分析法及決策樹分析法來選取特徵子集後進行分類及預測。 
承上所述，本研究主要目的可歸納如下： 
1. 為考量到單一分類方法所造成的缺撼，本論文預期運用不同分類方法，
如人工類神經網路搭配不同特徵選取技術，如 Filters 架構下的主成份分析法
7 
3. 文獻探討 
近年來，運用資料探勘於人工生殖懷孕率預測方面的研究已發展出許多不同
模式， Kaufmann (S.J.Kaufmann et al., 1997)等人嘗試應用類神經網路來預測接受
試管嬰兒(In-vitro Fertilization, I. V. F.)診療患者的懷孕結果。他們從過去與臨床診
斷預測相關的文獻發現，使用類神經網路進行預測要比傳統使用統計模型的預測
結果來的佳，傳統的統計模型仍需要進一步發展出消除驗證比較時的偏見，然
而，類神經網路不但有較佳的模式識別(Pattern Recognition)能力，從某些案例也
能發現到類神經網路在識別相關性(Associations)上能提供更廣的範圍，而這主要
的原因在於類神經網路較其它的統計技術在識別高度非線性相關性(Highly 
Non-linear Associations)上有較佳的能力。 
而在實驗當中，他們使用了聖詹姆斯大學醫院人工受孕單位 (Assisted 
Conception Unit and Department of Medical Physics, St James’s University Hospital)
所提供的資料，一開始資料集為 455 筆，利用卡方檢定( 評估輸入類
神經網路的變數，並使用 t 檢定(t-test)進行檢驗。接著，將資料集區分為 164 筆
的訓練子集(Training data set)，其中懷孕與未懷孕的資料各為 82 筆；與 291 筆測
試子集(Testing data set)，懷孕的筆數為 82 筆，未懷孕則為 209 筆來進行實驗。
類神經網路輸出結果為 0(未懷孕)與 1(懷孕)，閾值(Threshold)0.46，網路架構為
四個輸入(Input)、一個隱藏層(Hidden layer)、四個節點(Node)、一個輸出(Output)。
實驗結果指出，在正確預測方面，懷孕的資料在 54.9~79.3%，未懷孕則在
40.7~56.5%，而整體最佳成果為輸入三個神經元數時，懷孕且預測正確為 68.3%，
未懷孕且預測正確為 55%，總正確率為 58.8%。而從實驗來看，這次的實驗結果
在預測成功的結果方面多過於預測失敗。 
另外，Jurisica 等人(Igor Jurisica et. al., 1998)則為試管嬰兒之預測與知識挖掘
(knowledge mining)上發展出一個基於案例式推理法(Case-based Reasoning, CBR)
的決策支援系統(Decision Support System, DSS)，名為 。他們發現一般醫
9 
筆診療記錄，因實驗僅考量進行至最後週期的診療記錄，所以資料筆術刪減至
483 筆，每筆資料有 100 個自變數，例如病患年齡、BMI 等，但剔除懷孕後才量
測出的新自變數後則為 53 個，應變數為二元變數(Dichotomous)，例如 1(懷孕)、
0(未懷孕)。在特徵選取部份，作者使用三階段方法進行變數刪減，第一階段透
過概似比統計法(Likelihood Ratio Statistics, LRS)檢驗應變數與自變數之間的相
關性後留下 24 個與懷孕結果具顯著相關的自變數做進一步實驗，同時從資料集
中刪除具遺漏值(Missing Value)的資料，僅留下 402(懷孕：203/未懷孕：199)筆記
錄。第二階段則將 24 個自變數中的 11 個連續變數(Continuous Variables)進行主
成份分析後將變數合成為 4 個連續變數。第三階段則使用赤池資訊準則(Akaike’s 
Information Criterion, AIC)及史瓦茲貝氏準則(Schwarz’s Bayesian Criterion, SBC)
將 17 個變數(13 個類別變數與 4 個連續變數)刪至 6 個變數做為最終簡化的複邏
輯斯迴歸模型(Multiple Logistic Regression Model)，另外，再透過相關係數與多
變量分析此 6 個變數後可得知影響懷孕結果的關鍵變數依序為病患最後注射的
卵巢濾泡刺激素劑量(final fsh dose)、懷孕時所造成的創傷(trauma)、植入胚胎數
(number of transfers)、年齡(age)、BMI 指數(bmi)和胚胎移植技術人員(embryo 
transfer technician)。最後從評估預測能力的一致性比率(Percent Concordance)來
看，飽合邏輯斯迴歸模型(17 個變數)的 79.9%高於與簡化邏輯斯迴歸模型(6 個變
數)的 75.5%，此結果顯示出使用較多特徵屬性進行預測的結果應較佳。另一方
面，雖然此方法並非分類模型，但簡化變數卻可提供預測資料時的可視性及了解
其變數的重要性，並做為之後決策樹分類模型的基礎。最後使用 C5.0 決策樹進
行分類，並將 402 筆診療記錄刪至 325 筆，由於仍有 77 筆資料中特徵變數未被
納入統計模型中，因此視為遺漏值，最後以 10-fold 交叉驗證法(10-fold Cross 
Validation)進行資料驗證。 
首先在未考慮任何特徵選取技術下進行分類，輸入特徵變數為 53 個，正確
率為 67.4%；接著則使用 C5.0 演算法本身所擁有的屬性排除法進行特徵選取，
此法會在模型建立前檢驗預測變數的有用性，若發現與分析無關或被認為有損於
11 
值中，挑出 39 個有可能影響 IVF 結果的特徵值。特徵分為兩大類，連續型和間
斷型，由於造成不孕的原因每位病患不盡相同，因此將部份間斷特徵值進行擴
充，以利分析，所以這些特徵值被擴充為 18 種獨立的特徵值且皆具有邏輯的二
元值(t: true; f: false)。經過擴充後，此資料庫總共有 69 個特徵值，然後再經過資
料淨化處理(Data Cleaning)的程序，在遺漏值(Missing)的資料欄位填入「99」，得
到 70 個特徵欄位。為了求得更好的準確度，首先以類神經網路、支援向量機、
貝氏網路來進行變數篩選，再將篩選後的變數進行決策樹準確度的預測。實驗結
果指出類神經網路結合決策樹有 81.78%的準確度、支援向量機結合決策樹有
83.92%的準確度、貝式網路節結合決策樹有 82.48%的準確度(蕭昌軒、顧瑞祥，
民國 98 年)。 
而同一學者(蕭昌軒，民國 98 年)使用同樣的題目，在改變特徵選取變數及
決策樹演算法後得其結果為類神經網路結合 C5.0 決策樹有 87.11%的準確度、支
援向量機結合 C5.0 決策樹有 85.21%的準確度、CART 結合 C5.0 決策樹有 81.61%
的準確度。 
Davis (Joseph Davis et. al., 2005)等人同樣是應用資料探勘技術於輔助人工生
殖技術(Assisted Reproductive Technology, ART) 臨床診斷時的離散型資料進行分
析。他們從過去文獻中發現資訊模糊網路(Info-fuzzy Network, IFN）能藉由其在
統計控制(Statistical Manipulation)上的能力來探討特徵屬性的意義與特定目標屬
性之間的關係，但多半用於商業，因此他們對此演算法進行改善並用於臨床醫
學，另名為臨床修正資訊模糊神經網路演算法（Clinically Modified Info-fuzzy 
Network, CMIFN），以便針對臨床問題與假設上能更靈活地對其資料集進行探
索。另外，也針對關聯法則(Association Rule, AR)提出新的改進方法，另名為修
正複合式關聯法則(Modified Composite Association Rule, MCAR)演算法，使它能
更靈活選擇組成“if”節點(“if” Node)的變數並對所有相關的特徵屬性進行遞迴
(recursively)。 
實驗資料集由韋斯特米德醫院的生育門診 (Westmead Fertility Clinic, 
13 
表 1 應用於人工生殖技術之預測、分類相關文獻整理 
 
 
 
 
 
 
 
 
 
 
 
 
 
年份 作者 資料
數 
特徵選取方法 分類方法 正確率 
1997 
Kaufmann et 
al. 
455 ANN 58.8% 
1998 Jurisica et. al 788 CBR 60.6% 
2003 Passmore et. al. 
402 
402 
325 
325 
325 
325 
(1).LRS+PCA 
(2).(1)+AIC+SBC 
(3).無 
(4).(2)+DT 
(5).(2)+Greedy 
algorithm 
(6).同(2) 
MLR 
MLR 
C5.0DT 
C5.0DT 
Greedy algorithm 
Statistic 
79.9% 
75.5% 
67.4% 
69.5% 
63.1% 
66.5% 
2003 Passmore et. al. 380 
C5.0DT(僅考慮 1 個變數) 
C5.0DT(選擇 8 個與問題較相關的變數) 
MLR(將變數增至 12 個) 
56% 
75% 
74% 
2009 
蕭昌軒 
顧瑞祥 5275 
ANN 
SVM 
BN 
DT 
81.78% 
83.92% 
82.48% 
2009 蕭昌軒 5275 
ANN 
SVM 
CART 
C5.0DT 
87.11% 
85.21% 
81.61% 
2005 Davis et. al. 
DI 615 
OI 762 
CMIFN 
MCAR 
DI78%, OI86%
DI88%, OI92%
15 
懷孕)，54 個獨立變數，而獨立變數中包含了 38 個連續變數(Cont.)及 16 個類別
變數(Cate.)，當資料蒐集完後必須進行變數統計及數值區域轉換，將資料重新分
配在一個較小且特定的範圍內，這個步驟對於後續特徵變數篩選與各種分類模型
建構具有關鍵影響 (Hand et. al., 2001)。本研究使用極值正規化 (Min-max 
Normalization)法，將所有屬性值轉換到 1 到 0 之間，如下所示： 
                                          (1) 
其中 v＇代表經過轉換的資料 max、min 分別代表各資料範圍之上界(Upperbound)
與下界(Low bound)。 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
17 
                                                 
5 Fertil. number(F/T)(total)與 Fertil. number(F/M)(mature)合成為一個變數，另名為 No. of 2PN 
6 Fertil. number(F/T)(total)-ICSI 與 Fertil. number(F/M)(mature)-ICSI 合成為一個變數，另名為 No. 
of 2PN-ICSI 
7 Day0 E2 與 No check E2 合成為 Day0 E2 一個變數 
8 Day0 progesterone 與 No check progesterone 合成為 Day0 progesterone 一個變數 
9 Day0 AMH 與 No check AMH 合成為 Day0 AMH 一個變數 
卵子分析   
Asp. ova total              
Asp. mature  
Asp. date  
取卵總數 
卵子成熟數 
取卵日 
Cont.
Cont. 
Cont.
培養液類型  
HTF 
Medi-cult 
Microdrop 
Co-culture 
cult_medi_type 
Cate.
Cate.
Cate.
Cate.
Txt. 
胚胎取/受精狀況  
ICSI 
Assisted hatching 
MESA 
TESE 
Other Culture medium 
Fertil. number(F/T)(total)5 
Fertil. number(F/M)(mature) 
No. of 3PN 
No. of 1PN 
Fertil. number(F/T)(total)-ICSI6  
Fertil. number(F/M)(mature)-ICSI 
No. of 3PN-ICSI 
No. of 1PN-ICSI 
卵細胞質內單一精蟲顯微注射術 
協助性孵化 
副睪丸取精 
睪丸取精 
其它方法 
2PN/Total(正常受精/胚胎數) 
2PN/Mature(正常受精/成熟胚胎數) 
多核性受精(一個卵子有兩個精子) 
單核性受精 
2PN/Total-ICSI 治療法 
2PN/Mature-ICSI 治療法 
多核性受精-ICSI 治療法 
單核性受精-ICSI 治療法 
Cate.
Cate.
Cate.
Cate.
Txt. 
Cont.
Cont.
Cont.
Cont.
Cont.
Cont.
Cont.
Cont.
病患身體檢驗-女性   
Day0 E27 
Day0 progesterone8 
Day0 AMH9 
No check E2 
No check progesterone 
No check AMH 
(抽血檢驗)動情激素 
(抽血檢驗)黃體素(助孕激素) 
(抽血檢驗)抗穆勒氏管荷爾蒙 
(未檢驗/檢驗無結果)動情激素 
(未檢驗/檢驗無結果)黃體素 
(未檢驗/檢驗無結果)抗穆勒氏管荷爾蒙 
Cont.
Cont.
Cont.
Cate.
Cate.
Cate.
19 
第二階段為特徵選取，利用不同的特徵選取技術篩選出有意義的屬性，本研
究運用 Filter 架構下的主成份分析法及線性區別分析法來探討不同架構下的特徵
選取方法所篩選出的特徵子集是否會影響分類模型的結果。 
第三階段為分類模型建構，此階段運用監督式學習法中的類神經網路之倒傳
遞類網路做為分類模型的建構，接著再透過第二階段各特徵選取技術所選出的特
徵子集(Feature Set)輸入監督式學習網路中進行學習，最後經過反覆的學習與修
正後提出分類結果並加以做簡單評述及比較。 
第四階段為分類模式結果及討論，將上述經過三種特徵屬性選取技術後結合
三種分類方法所形成的複合分類模型所得結果之正確率(Accuracy Rate)進行比
較。 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
21 
4.1 主成份分析法 
主成份分析目的在解釋大量高維度、多相關的資料轉換成少數個別獨立的基
本變數，以達到原始資料的維度縮減。其基本的假設是指高維度資料中每二個變
數之間都為獨立變數，整個高維度資料呈現著高斯分配(Gauss Distribution)，並
經過原有變數的線性組合而得的新成份必須能保存著原有變數最多的資訊，亦即
第一主成份會顯示出最大的變異數。主成份分析的「資料轉換」關鍵即為「變異
數」問題，指的是利用求特徵值（Eigenvalue）及特徵向量（Eigenvector）之方
法，過濾出佔最大變異數的型態，找出線性組合的公式。換句話說，特徵值空間
FS 擁有 M 筆特徵值向量，每一個特徵值向量是由 N 個特徵變數所構成，則特徵
值空間可以寫成：            (2) 
而特徵值空間 FS 的共變異矩陣（Covariance matrix）以符號 Σ表示，共變異矩陣
Σ 可由下式求得：                              (3) 
其中 x 為矩陣 A 中列向量的轉置向量(xi1, xi2, …, xj,…, xiN-1, xiN)T，μ表示為向量 x
中每一成份的平均值所組成的向量。共變異矩陣 Σ的特徵值 λ 及特徵向量 ν 可由
解下列式子所得：                 Σ ν = λ ν                           (4) 
每一個非零的特徵值都會對應到一個特徵向量，將全部的特徵值從大到小排
序，分別為λ 1、λ 2、…、λ N，所對應的特徵向量分別為ν 1、ν 2、…、ν N，其中<ν 
i· ν j>= δ ij。令U表示ν1、ν 2、…、ν N所組成的矩陣，該矩陣必使得下式成立： 
UΣUT = diag (λ 1、λ2、…、λN)                  (5) 
前面所求得特徵向量 ν 1 就是第一主成份，ν 2 為第二主成份，依此類推。越前面
的成份，越能代表特徵值空間的資訊訊息。假設最多只取 Q 個成份，則居前 Q
個主成份將代替原有特徵值空間的 N 個變數。這 Q 個主成份所能代表變異程度
的百分比則可由下式計算而得：               (6) 
23 
資料特性共變數矩陣可能不一致的問題。 
4.3 決策樹 
自 Quinlan 在 1986 年所提出的 ID3 演算法後，因其無法處理連續屬性的問
題且不適用在處理大資料集，因此發展了現在較為人常使用的 C5.0 決策樹演算
法，同時因其採用 Boosting 方式來提高模型準確率，且佔用系統資源與記憶體
較少，所以計算速度較快。C5.0 是屬於監督式學習的演算法之一，亦可稱為規
則推理模型，其主要能力是能夠是對連續型變數及類別型變數作解析，它能依運
算結果產生決策樹(Decision tree)及規則集(Rule sets)兩種模型，其演算流程如圖 4
所示。 
在決策樹模型產生的過程中能自動依最大資訊增益(Information Gain)的欄
位來進行遞迴切割樣本，決策樹中每個葉子節點表示一個特定的訓練子集
(Training set)，訓練子集中的每個樣本只屬於一個葉子節點。也就是說，任何一
個給定的樣本通過決策樹只能得到一個預測結果，所以如果決策樹過於瑣碎，該
模型容易發生過度配適(Over fitting)的情形，因此當樣本子集已切割至最低層的
樣本子集，即樣本子集已無法再分割時，必須再對樣本子集重新檢查，以去掉那
些貢獻不大的分支(又稱剪枝)後得到最終的模型(Berry and Linoff, 1997)，如圖 3
所示。而判斷決策樹分類完成，即所有節點皆為樹葉節點的依據有下列三點： 
1. 該群資料的每一筆資料都已經歸類到同一類別。 
2. 該群資料已經沒有辦法再找到新的屬性來進行節點分割。 
3. 該群資料已經沒有任何尚未處理的資料。 
而規則集模型則是一個用於預測樣本的規則集合，實際上是將決策樹中所發
現的資訊提取出來的，且保留了決策樹大部分的重要資訊，但結構更加簡單。與
決策樹模型最大的區別在於使用規則子集建模時，當一個樣本有多個規則可循
時，則這些規則會根據信賴度被給予不同的權重；若樣本子集內一個規則也沒
有，那就給予預設的預測結果。 
25 
集合的實例數。而 Entropy 的數值越小，表示其子集合的純度越高。對於所區分
的子集合 S j 而言，其期望資訊可表示為： 
                             (11)               
 表示 S j 集合中的樣本屬於 Ci 類別的機率，若以該屬性為分支依據，
所獲資訊增益，亦即不純度 (Impurity) 減少量為： 
                  Gain(A)=I(s1,s2,…,sn) - E(A)                          (12) 
最後從內部節點(Non-leaf node)選擇分支(Branches)屬性的準則是以找出能獲得
最大資訊增益（Information gain）之屬性來做節點分割（Splitting Node） (廖述
賢、溫志皓, 民國 97 年)。 
 
  
圖 4 決策樹演算流程圖
Root 
node 
資料輸入樹根
並區分為訓練
及測試子集 
訓練子集 測試子集 
節點分割 
產生樹葉節點 
節點是否為
樹葉節點  
是 
否
最大資訊增益 
(Information Gain) 修剪節點
Leaf 
node 
Non-leaf 
node 
Branches 
Leaf 
node 
Branches 
Non-leaf 
node 
27 
 (邵奕誠, 民國 97 年) 
由於本研究主要針對高維度式分類問題之預測，綜合文獻探討所述之結果將
採用監督式學習網路中的倒傳遞神經網路(Back Propagation Network, BPN)進行
研究。倒傳遞神經網路是一種多層式的類神經網路架構，屬於前饋式監督式學習
演算法的其中一種，其架構由許多單層網路所連結，而每一層的網路，則由數個
神經元（Neuron），或稱節點（Node）所組成，而每一個神經元的輸出，都乘上
其相對應的加權連結值（Weights）再加總，再透過激發函數（Activation function）
的計算產生輸出訊號，而倒傳遞網路所使用的激發函數通常為 S 型函數(Sigmoid 
function)或雙曲線正切函數(Hyperbolic tangent function )，並以「最陡坡降法」
(Gradient Decent Method)使誤差函數達到最小化。一般來說，倒傳遞網路分為三
層架構，分別是輸入層、隱藏層、輸出層，其演算流程如下： 
步驟 1：設定轉換函數與網路參數。假設學習速率 η、動量系數 α。 
步驟 2：以隨機亂數來設定輸入層與隱藏層之間的加權值為 Wih 及隱藏層與
輸出層之間的加權值為 Whj，和隱藏層閥值向量 θh 及輸出層閥值向量 θj 的初
始值。 
步驟 3：輸入訓練樣本 Xi，與目的向量，即目標輸出值 Tj。 
步驟 4：推算網路輸出向量，即輸出層輸出值 Yj。假設 Xi為輸入層第 i 個神
經元輸出值，則隱藏層加權乘積和 neth，隱藏層第 h 個神經元輸出值為 Hh，
則計算公式如下： 
                    (13) 
                      (14) 
接著依上式推算輸出層第 j 個神經元輸出值 Yj，與輸出層加權乘積和 netj 
                    (15) 
                   (16) 
步驟 5：計算輸出層與隱藏層的差距量。設 Tj為輸出層目標之輸出值，則輸
出層差距量 δj可由下式所得：δj = Yj (1–Yj) (Tj–Yj)                   (17)
並由上式推算隱藏層差距量：                (18) 
29 
 
 
 
 
 
 
 
 
 
 
 
 
圖 6 倒傳遞網路演算法演算流程 
 
而在參數設定的部分，透過人為設定的參數分別有隱藏層層數、隱藏層單元
數、學習率和慣性因子，透過這些參數的不斷調整讓神經網路收斂快速並且可以
達到最小誤差值(葉怡成，民國 92 年)。但由於類神網路的建構存在太多不確定
因素，許多學者都認為試誤法是一個適合的方式，不過仍有學者提出決定參數的
規則，下列分別為些參數的調整方式： 
1. 隱藏層層數：通常倒傳遞網路有一層或一層以上的隱藏層，有學者指出，在
一般情況下，一層隱藏層已可解決大部份的問題(Berry and Linoff 1997; L 
Moutinho; P.A. Phillips 2002; D.Mitchell and R.Pavur 2002.)，而多於兩層的隱藏層
是不必要的(Davies and Brozovsky 1995)，因為太多隱藏層將使網路訓練時間增
設定網路訓練參數 
隨機亂數產生初始加權值 W
與閥值 θ 
輸入訓練樣本及目標出輸值 
計算輸出向量 
收斂效果是否良好 調整加權值與閥值 
是 
計算網路各層間差距量 δ 
計算加權值及閥值修正量 
更新各層間加權值及閥值 
停止網路訓練
否 
31 
(2)誤判率(Error rate) 
誤判率適用於分類型問題，對於簡單分類問題，誤判率較有意義。計算誤判率方
式如下式： 
                 (29) 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
33 
預測結果也有懷孕的筆數。另外 通常稱為敏感性(Sensitivity)，在此指預測 
模型能正確預測未懷孕的比例；而 則稱為特異性(Specificity)，指預測模型 
能正確預測有懷孕的比例， 為正確率(Accuracy rate)。 
接受者操作特徵(Receiver operating characteristic curve, ROC curve)源自於訊
號偵測理論（Signal Detection Theory），它是用來呈現一個充滿雜訊的頻道中命
中率（Hit rates）跟誤警率（False alarm rates）之間的關係，目前已被廣泛地應
用在醫學診斷及研究 (Spackman, 1989)，主要透過 ROC 曲線下的面積（Area 
Under the ROC Curve, AUC）來評估分類預測模型之區別效果。若涵蓋的面積為
100%，表示模型的分類效果最佳；如果是 70%~90%，則表示該模型有一定準確
性；而在 50%~70%時，則表示該模型有較低的準確性；低於 50%則表示該模型
沒有任何的分類能力(Hand, 2001)。 
該圖係以敏感性(Sensitivity)為縱座標，以 1-特異性(Specificity)為橫座標， 敏
感性與特異性的值皆介於 0 到 1 之間。如圖 7 所示， ROCm 與 ROCn 分別表
示模型 M 與 N 所產生的 ROC 曲線，表示模型 M 比模型 N 有較佳之分類能力。 
 
 
 
 
 
 
 
 
 
圖 7 ROC Curve 示意圖 
35 
子集依最大資訊增益法進行節點分割，並透過測試子集來進行修剪，屬於事後修剪法(Post 
pruning)的一種，此法首先建立一個完整的樹，再將其分支錯誤率(Error Rate)移除， 最末端
未被移除的分支節點就變成樹葉(Berry and Linoff, 1997)。 
學習率一般設為 0.1，雖然學習率提高可使網路收斂速度增加，學習效果也較佳，但學習
率過高則可能會因錯誤率增加造成所挑選出的變數不良，但實驗設計相關參數如表 6 所示： 
表 6 決策樹 C5.0 參數設定 
Variables 
Dependent：1(preg.) 
Independent：54(Cate.:38 ; Cout.:16) 
Learning rate 0.1 
Train set 50% 
Test set 30% 
Validation set 20% 
Minimum n child 1 
Maximum n nodes 3 
 
倒傳遞神經網路在本實驗當中，將以進行前處理後的 54 個變數作為輸入層，其中含有
16 個連續變數與 38 個類別變數，此 38 個類別變數皆為二元變數(TRUE/FALSE)，因此輸入
層共有 70 個神經元，而在隱藏層的部份，由於本研究輸出層為簡單二元分類(0：未懷孕；1：
懷孕)，複雜度僅需採用一層隱藏層，以避免誤差函數陷入局部極小值而無法收斂，而其神經
元數則參考學者葉怡成所提出的在一般問題之下，隱藏層單元數=( 輸入單元數＋ 輸出單元
數) /2。另外，隱藏層及輸出層的激發函數則皆使用 S 型函數(Sigmoid function) ，最後以「最
陡坡降法」(Gradient Decent Method)使誤差函數達到最小化，相關參數如表 7 所示。 
表 7 倒傳遞網路參數設定 
Input neuron numbers Cate. 16×2+Cout. 38=70 
layer neuron numbers (70+2)/2=36 
Hidden layer numbers Hidden 1 
Target 2 
Activation function 
 
Learning rate 0.1 
Momentum 0.3 
Train set 80% 
37 
而在複合式分類模型部份皆為結合倒傳遞網路進行實驗，因此主要參數皆以 5.1 所述模
型相同，僅在輸入層及隱藏層神經單元數目依不同特徵選取方法而有所差異，相關參數如表
9 所示： 
表 9 複合式分類模型參數設定 
 PCA+ANN LDA+ANN DT C5.0+ANN
Input neuron numbers 13×2+21=47 1×2+8=10 5×2+28=38 
Hidden layer neuron numbers (47+2)/2≒25 (10+2)=6 (38+2)/2=20 
Hidden layer numbers 1 
Target 2 
Activation function 
Learning rate 0.1 
Momentum 0.3 
Train set 80% 
Test set 20% 
 
5.2.1 主成份分析法結合倒傳遞網路 
透過主成份分析法所挑出的特徵變數中包含 13 個類別變數及 21 個連續變數，依此所設
計的倒傳遞網路模型為 47-25-2，由表 10 混淆矩陣中可看出在群 1 中(G_1:0，未懷孕)，從 248
筆未懷孕的資料中正確判斷為未懷孕有 228 筆，正確率為 91.94%，而群 2 中(G_2:1，懷孕)，
從 231 筆懷孕的資料中正確判斷為懷孕則有 208 筆，正確率 90.04%，平均正確率為 91.02%。 
表 10 主成份分析法結合倒傳遞網路之混淆矩陣 
Group 
Percent 
Correct 
G_1:0 G_2:1 Total 
G_1:0 82.66129 205 43 248 
G_2:1 82.68398 40 191 231 
Total 82.67223 245 234 479 
 
依主成份分析法結合倒傳遞分類模型所繪出的 ROC 曲線圖經計算後得知曲線下面積為
0.868943，表涵蓋面積為 86.89%，介於 70%~90%之間，指該模型具有一定準確性。 
39 
 
 
 
 
 
 
 
 
 
 
 
 
 
圖 10 線性區別分析法結合倒傳遞網路之 ROC Curve 
 
5.2.3 決策樹結合倒傳遞網路 
透過決策樹 C5.0 法所挑出的特徵變數中包含 5 個類別變數及 28 個連續變數，依此所設
計的倒傳遞網路模型為 38-20-2，由表 12 混淆矩陣中可看出在群 1 中(G_1:0，未懷孕)，從 248
筆未懷孕的資料中正確判斷為未懷孕有 155 筆，正確率為 62.50%，而群 2 中(G_2:1，懷孕)，
從 231 筆懷孕的資料中正確判斷為懷孕則有 192 筆，正確率 83.12%，平均正確率為 72.44%。 
表 12 決策樹 C5.0 結合倒傳遞網路之混淆矩陣 
 
 
 
 
 
 
依決策樹分析法結合倒傳遞分類模型所繪出的 ROC 曲線圖經計算後得知曲線下面積為
0.776882，表涵蓋面積為 77.69%，介於 70%~90%之間，指該模型具有一定準確性。 
  
Group 
Percent 
Correct 
G_1:0 G_2:1 Total 
G_1:0 62.50000 155 93 248 
G_2:1 83.11688 39 192 231 
Total 72.44258 194 285 479 
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
Se
ns
iti
vi
ty
1-Specificity
41 
5.3  建議及未來研究 
本研究仍有未盡完美之處，因此針對研究中所遇的問題提出建議，作為續 
研究之參考。 
一、採用不同架構下的特徵選取方法：本研究僅探討 Filters 架構下的特徵選取來結合倒
傳遞網路所組成的複合式分類模型的可行性，但尚有 Wrappers 架構下的特徵選取技術未進行
實驗，因此在後續研究可針對不同架構間的複合式分類模型之分類績效進行分析比較，以找
出最適宜於懷孕結果預測的分類模型。 
二、依照特徵屬性選取機制結合最佳化分類方法，找出最佳分類模型：例如使用不同的
啟發式演算法，如蟻群最佳化法(Ant Colony Optimization, ACO) 、粒子群最佳化法 (Particle 
Swarm optimization, PSO)與模擬退火法(Simulated Annealing, SA)等用於分類方法，可以結合
特徵選取方法來探討之間的顯著差異，看看能否提高分類的正確率。 
三、分類模型參數設定的改變：本研究之複合式分類型中的倒傳遞網路皆採用相同的參
數設定，然而，不同的參數設定可能會產生不同的結果，後續研究可以針對這些參數做改變
來得到最佳的模型。 
四、採用最新資料進行研究：由於本實驗所使用資料集為 2007 至 2009 年的診斷資料，
但生殖醫學日新月益，新型的藥物及治療方式不斷地開發，而診療時所記錄的方式也會因而
有所改變，未來在導入為該醫院所開發的人工生殖系統後所得的資料會更加完善，更有助於
日後預測準確率的提高，若能以這些資料資料來進行資料探勘，獲得的研究結果則更能符合
目前台灣民眾，從而了解影響懷孕結果的主要因素，並提供給第一線的人工生殖醫療人員參
考。 
 
 
 
 
 
 
43 
assisted reproductive technology,” 16th Australasian Conference on Information Systems, 
Sydney. 
[14]  Jolliffe, I. (1986). Principal Component Analysis. Springer-Verlag. 
[15]  Desaiet, V. S., Crook, J. N. and Overstreet, G. A. (1996). A comparison of neural networks and 
linear scoring models in the credit union environment. European Journal of Operational 
Research, 95(1), pp. 24-37. 
[16]  West, D. (2000). Neural network credit scoring models. Computers and Operations Research, 
27(11-12), pp. 1131-1152. 
[17]  Baesens, B., Van Gestel, T., Viaene, S., Stepanova, M., Suykens, J. and Vanthienen, J. (2003). 
Benchmarking state-of-the-art classification algorithms for credit scoring. Journal of the 
Operational Research Society, 54(6), pp. 627-635. 
[18]  Quinlan, J. R. (1986). Induction of Decision Tree. Machine Learning. 1, pp. 81-106. 
[19]  Kohavi, R. and Provost, F. (1998). Glossary of Terms. Machine Learning(30), pp. 271-274. 
[20]  Spackman, K. A. (1989). Signal detection theory: Valuable tools for evaluating inductive 
learning. Proceedings of the Sixth International Workshop on Machine Learning, pp. 160-163. 
[21]  Hand, D. T. (2001). A simple generalization of the area under the ROC curve to multiple class 
classification problems. . Machine Learning(45), pp. 171-186. 
 
表 Y04 
一、參加會議經過 
 
1. 本次會議為第六十二屆工業及系統工程研究會議(2012 The Industrial and Systems 
Engineering Research Conference, ISERC 2012)，於 5 月 19 日至 5 月 23 日在美
國佛羅里達州奧蘭多市的希爾頓飯店舉行 (Hilton Bonnet Creek in Orlando, Fla.)。
據IIE官方統計，此次與會人數高達1600人以上，包含世界各地工業工程學界的學
者、學生及業界相關研究人員一同分享彼此的研究及新的應用。 
2. 於2012年5月19日早上8:30報到，並領取相關資料。在為期五天的時間內，多達28種
主題，750場學術會議，內容包括電腦與資訊系統、工作研究、能源工程、工程管
理、工廠物流、企業資源規劃與決策支援系統、醫療保健系統、國土安全、人因素
工程等，提供與會人士與各界研究人員交流機會。除此之外，還可現場聆聽由頂尖
產業領袖的主題演講，了解產業動態與專家見解。 
3. 賓州州立大學(The Mary Jean and Frank P. Smeal College of Business Administration at 
Pennsylvania State University) Russell Barton教授應大會之邀進行專題演說，他特別
點出未來最具國際利益的工業工程應用為「永續製造(sustainable manufacturing)」
及供應鏈(supply chain)，但在醫學進步，人口趨於老化的現代，也必須特別注意健
康照護系統工程(healthcare systems engineering)，最後也以盲人摸象的例子提醒在
座的聽眾，做研究時如同盲人般，雖然我們從每一個角度來看是有效的，但卻不完
整的。 
4. 下一屆第六十三屆工業及系統工程研究會議 (2013 The Industrial and Systems 
Engineering Research Conference, ISERC 2012)，於 5 月 18 日至 5 月 22 日在波
多黎各聖磺島(San Juan Island, Puerto Rico)舉行。 
 
二、與會心得 
 
1. 此次報告的論文主題是探討資料探勘(data mining)在醫學研究的應用，因此也特別注
意與自身研究較相關的主題，來自奧克拉荷馬州立大學的兩名學者便是運用資料探勘
來探討髖部骨折(Hip fracture)的主要原因，所用的技術包括邏輯斯迴歸模型(logistic 
regression model)，決策樹(decision tree)及類神經網絡（artificial neural network），其
中以決策樹進行分類預測的效果最為良好。而此二名學者的研究主題雖與我們團隊不
盡相同，然而結果非常類似，未來我們也希望能更進一步了解決策樹此類資料探勘工
具應用在其它醫學領域之可行性。 
 
Proceedings of the 2012 Industrial and Systems Engineering Research Conference 
G. Lim and J.W. Herrmann, eds. 
 
 
Development of a Decision Support System for Assisted 
Reproductive Technology 
 
Abstract ID:  559 
 
Shih-Min Chen, Kai-Ying Chen, and Chui-Yu Chiu 
Department of Industrial Engineering and Management, National Taipei University of 
Technology 
 Taipei, Taiwan, R.O.C. 
 
Yuh-Ming Hwu 
Mackay Memorial Hospital  
Taipei, Taiwan, R.O.C. 
 
Abstract 
 
In recent years, more and more couples have been using in-vitro-fertilization (IVF) to treat infertility, but a 60% 
failure rate and high treatment costs often drive away many patients with infertility. Many parameters, such as age 
and stimulating hormone (FSH) levels are known to affect IVF outcome. The entire IVF treatment process is 
complicated, and every single segment will affect the final treatment outcome. For the reason given above, 
determining how to explore the main factors that affect IVF outcome and how to predict the possible IVF pregnancy 
rate have become important research topics. This study presents two methods: linear discriminant analysis (LDA) 
and decision tree method (DT) for data mining of an Asian-based IVF medical database that can not only use the 
feature selection method to find key factors that affect IVF outcomes but also use the classification method to 
predict the pregnancy rate of IVF treatment. The results of this study show that ‘Age’, ‘Original sperm 
concentration’, ‘Ovum maturity’, ‘Number of 3PN after using ICSI therapy’, ‘Estradiol’, ‘Number of implanted 
grade first embryo’ and ‘Uterine factors’ were chosen simultaneously by the two feature selection methods 
employed here. The resulting predictive accuracy was at an acceptable level. 
 
Keywords 
In-vitro-fertilization, feature selection, classification 
 
1. Introduction 
With the changing times, more and more people suffer from infertility caused by late marriages and stress. 
According to the statistics of the Bureau of Health, Executive Yuan in Taiwan in 2008 [1], about 7,000 people each 
year in Taiwan use In-Vitro-Fertilization (IVF) technology to treat infertility, more than 2,000 ‘test-tube babies’ 
were born and the pregnancy rate was 36.5%. Since 1985, when Taiwan successfully bred the first ‘test-tube baby’ 
in Taipei Veterans General Hospital, a rash of medical breakthroughs and innovations in the domain of artificial 
reproduction technology, such as ovum freezing technology which is unique in the world, have brought new hope 
for infertility couples. 
 
Despite the advances in artificial reproduction technology increasing infertility couples’ willingness to accept IVF 
treatment, the successful pregnancy rate of IVF technology still cannot be guaranteed. As far as most clinic 
physicians are concerned, the key question is “What is the key factor that will affect IVF outcome?” As we know, in 
the cycle of IVF treatment, pregnancy rates may depend on age, BMI (Body Mass Index), stimulating hormone 
(FSH) levels, sperm quality, embryo quality, the patient's psychological and mental state, etc. [2]. While there is a 
strong assumption of a links among all of the abovementioned factors and infertility, little empirical evidence has 
been found to establish direct relationships among those variables. Without certain evidence, the clinic physicians 
have to rely on their professional knowledge and rules of thumb to make their diagnoses; however, the clinical 
Chen, Chen, Hwu and Chiu 
go through the data selection and removal stage. After all of these processes are finished, the high-quality data can 
give us high-performance computing. 
 
The data for this research were collected from the IVF clinic cases of an IVF Laboratory in a hospital in Taiwan 
during the period from January 2007 to December 2009. Based on privacy and data security issues, these data do not 
contain patient names, addresses, birth dates and other basic information; their medical record number is 
also changed to a meaningless value. The initial database contains 1249 IVF clinic cases. After removing errors and 
missing data, there were 479 records (N = 479) that include 231 pregnant records and 248 non-pregnant records. 
These data records consist of 93 attributes. Through discussions with domain experts after that, only 58 attributes 
were retained after removing attributes without relevance on pregnancy outcome. The attributes can be grouped into 
two categories, including 57 independent variables (19 discrete attributes and 38 continuous attributes) and an 
additional dependent variable (i.e., the attribute of “preg.” means T: successful pregnancy or F: unsuccessful 
pregnancy). In this study, these attributes will be divided into eight parts to explain: “The factor of  infertility", 
"Treatment", "Conditions of semen collection",  "The surgical of transvaginal oocyte aspiration", "The status of 
Embryo culture", "The surgical technique", "The status of embryo culture" and "The number of embryo”, 
respectively, as shown in Table 1. 
 
Table 1: IVF attributes used in this study. 
Variables Description Attribute type 
Attribute  
value 
The factor of infertility 
Age 
Tubal factor  
Male factor  
ASAb 
Endometriosis  
Ut. factor   
Ov. factor  
Un. factor  
The age of female patient 
Abnormal tubal factor 
Abnormal sperm factor 
Anti-sperm Antibodies 
Endometriosis 
Abnormal uterus factor 
Ovulatory dysfunction factor 
Unknown factor 
Numeric 
Text 
Text 
Text 
Text 
Text 
Text 
Text 
 
T/F 
T/F 
T/F 
T/F 
T/F 
T/F 
T/F 
Treatment 
GnRHa 
GnRHant 
Short 
Modify 
HMG  
FSH  
Clomiphene  
Nature 
Gonadotropin releasing hormone analogues 
Gonadotropin releasing hormone antagonist 
Subcutaneous injection at menstrual cycle 
Subcutaneous injection before menstrual cycle 
Human Menopausal Gonadotropin 
Follicle Stimulating Hormone 
The oral medication that to stimulate ovulation 
Ovulation time 
Text 
Text 
Text 
Text 
Text 
Text 
Text 
Text 
T/F 
T/F 
T/F 
T/F 
T/F 
T/F 
T/F 
T/F 
Conditions of semen collection 
Sperm morphology 
Original volume 
Original conc. 
Original M 
Washed volume 
Washed conc. 
Washed M 
Sperm morphology 
Original volume of sperm collection 
Original sperm concentration 
Original sperm motility 
Sperm volume after purification wash 
Sperm concentration after purification wash 
Sperm motility after purification wash 
Numeric 
Numeric 
Numeric 
Numeric 
Numeric 
Numeric 
Numeric 
 
The surgical of transvaginal oocyte aspiration   
Asp. ova total 
Asp. mature                   
number of total ovum 
number of mature ovum 
Numeric 
Numeric  
The surgical technique   
ICSI 
Assisted hatching 
MESA 
TESE 
Intra-cytoplasmic Sperm Injection  
Assisted embryo hatching  
Microsurgical Epididymal Sperm Aspiration 
Testicular Sperm Extraction 
Text 
Text 
Text 
Text 
T/F 
T/F 
T/F 
T/F 
The status of embryo culture   
Chen, Chen, Hwu and Chiu 
 
Figure 1: The research process 
 
3.1 Linear Discriminant Analysis  
Linear discriminant analysis (LDA), proposed by Fisher in 1936 [20], is used to distinguish between two species of 
iris flowers: setosa and versicolor. Reichert et al. [21] were the first to use the linear discriminant 
analysis method for a classification model in 1983. Currently, it remains a popular method for extracting features 
which preserve class separability. The main goal of this method is to explain the differences between groups and 
classifying data based on various characteristics of the response variable. The choice of method for classifying the 
observation depends on the nature of the data. If the data are multivariate normal and the covariance matrices are not 
too far apart, then the linear discriminant function approach can be used [22]. Zafeiriou (2008) [23] showed how to 
use LDA for two class problems, in great detail.  
 
3.2 Decision Tree 
The decision tree ID3 algorithm was introduced by Quinlan in 1986 [24]; it cannot process the problem of 
continuous attribute and deal with large data set. Over the past few years, several new algorithms have been devoted 
to the study of decision tree algorithms, such as C4.5, CART, CHAID and C5.0. In this study, the emphasis is on the 
C5.0 algorithm. C5.0 builds decision trees from a set of training data in the same way that C4.5 does, using the 
concept of information entropy. Quinlan went on to create C5.0; C5.0 offers a number of improvements on C4.5: the 
computing speed of C5.0 is significantly faster than that of C4.5 and gets similar results to C4.5 with considerably 
smaller decision trees. Another advantage is the improved accuracy rate based on boosting. The Boosting method, 
Data collection
Data cleaning and 
standardization 
Linear Discriminant 
Analysis 
Decision Tree C5.0 
Algorithm 
LDA Data Subset C5.0 Data Subset
Decision Tree C5.0 
Algorithm 
Supervised learning
Adjust the 
parameters 
Accuracy Rate 
Analyze and 
compare the results 
Fitting 
Un-Fitting
Chen, Chen, Hwu and Chiu 
approaches are not necessarily in conflict. There are eight variables: ‘Age’ (age), ‘Original sperm concentration’ 
(original conc.), ‘Ovum maturity’ (Asp. Mature), ‘Number of 3PN after using ICSI therapy’ (No. of 3PN-ICSI), 
‘Estradiol’ (Day 0 E2), ‘Number of implanted grade first embryos’ (implant Grade 1), ‘Uterine factors’ (Ut. Factor) 
and, ‘Sperm volume after purification wash’ (washed volume), which are repeated in two feature selection 
approaches; these eight variables have the potential to significantly affect the IVF treatment outcome. 
 
Table 2: The features importance rank that found by C5.0 method. 
Variables Importance 
Day0 E2* 
Day0 progesterone 
embryo Grade 1 
Day0 AMH 
original M 
Asp. ova total 
sperm morphology 
Day 0 endometrium thickness 
age* 
washed conc. 
implant total 
No. of 2PN 
original conc.* 
original volume 
No. of 2PN-ICSI 
Asp. mature* 
embryo total 
implant Grade 1* 
implant Grade 3 
embryo Grade 2 
washed volume* 
embryo Grade 5 
Ut. factor* 
No. of 3PN 
implant Grade 5 
implant Grade 4 
No. of 3PN-ICSI* 
cryo Grade 4 
embryo Grade 3 
Tubal factor 
short 
un. factor 
ov. factor 
1 
0.776981 
0.742521 
0.716651 
0.709675 
0.674333 
0.661453 
0.638172 
0.626921 
0.621874 
0.611461 
0.610323 
0.599096 
0.582145 
0.562907 
0.556394 
0.556263 
0.55489 
0.541731 
0.523374 
0.514262 
0.507579 
0.480927 
0.439676 
0.387594 
0.348042 
0.334869 
0.326857 
0.27201 
0.269924 
0.226324 
0.181761 
0.136131
 
The second research purpose of our study was to compare the performance of feature selection approaches in 
classification. Here we also used the decision tree C5.0 to construct the classification model and parameter 
settings the same as the feature selection step in the decision tree. In order to develop a decision tree classification 
model required two different datasets. The ‘training set’ was used by the learning algorithm to establish an 
appropriate set of model weights which accurately represented associations between input and output; the ‘test set’ 
provides an objective analysis of model performance [7]. The results are reflected in Tables 3, 4 and 5. Table 3 
indicates the prediction results of the DT C5.0 only on the testing dataset which did not taken into consideration the 
method of feature selection: the sensitivity is 63%, the specificity is 67.90% and the accuracy rate is 65.19%. Table 
4 indicates the prediction results of the DT C5.0 on the testing dataset that IVF attributes found by the LDA 
methods: the sensitivity is 65%, the specificity is 70.37% and the accuracy rate is 67.40%. Table 5 indicates the 
prediction results of the DT C5.0 on the testing dataset that IVF attributes found by the DT C5.0 method: the 
sensitivity is 65%, the specificity is 75.31% and the accuracy rate is 69.61%. All of these results can explain the 
beneficial effect of feature selection in the classification model. 
 
Chen, Chen, Hwu and Chiu 
6. Stolba N. and Tjoa A., 2006, “The Relevance of Data Warehousing and Data Mining in the Field of 
Evidence-Based Medicine to Support Healthcare Decision Making,” Computer Science, 11, ISBN: 975-
00803-0-0, 12-17. 
7. Kaufmann, S. J., Eastaugh , J. L., Snowden, S., Smye S.W. and Sharma, V., 1997, “The application of 
neural networks in predicting the outcome of in-vitro fertilization,” Human Reproduction, 12(7), 1454-
1457. 
8. Jurisica, I., Mylopoulos, J., Glasgow, J., Shapiro, H., and Casper, R. F., 1998, “Case-based reasoning in 
IVF: Prediction and knowledge mining,” Artificial Intelligence in Medicine, 12(1), 1-24. 
9. Passmore, L., Goodside, J., Hamel, L., Gonzalez, L., Silberstein, T. and Trimarchi, J., 2003, “ASSESSING 
DECISION TREE MODELS FOR CLINICAL IN−VITRO FERTILIZATION DATA,” Dept. of Computer 
Science and Statistics University of Rhode Island, Technical Report TR03−296. 
10. Trimarchi, J.R., Goodside, J., Passmore, L., Silberstein, T., Hamel, L., Gonzalez, L., “Comparing data 
mining and logistic regression for predicting IVF outcome,” Fertil. Steril, 80, 100-100. 
11. Davis, J., Illingworth, P. and Salam, A., 2005, “Applications of data mining techniques in assisted 
reproductive technology,” 16th Australasian Conference on Information Systems, Sydney. 
12. Saith, R., Srinivasan, A., Michie, D. and Sargent, I., 1998, “Relationships between the developmental 
potential of human in-vitro fertilization embryos and features describing the embryo, oocyte and follicle,” 
Human Reprod. Update, 4, 121-134. 
13. Guh, R. S., Wu, T. C. J., Weng, S. P., 2011, "Integrating genetic algorithm and decision tree learning for 
assistance in predicting in vitro fertilization outcomes," Expert System, 4437-4449. 
14. Kim, I. C., and Jung, Y. G., 2003, “Using bayesian networks to analyze medical data,” Lecture Notes in 
Computer Science, 2734, 317-327. 
15. Moralesa, D. A., Bengoetxea, E., Larranaga,P., Garcia, M., Franco,Y., Fresnada, M. and Merinod, M., 2008, 
“Bayesian classification for the selection of in vitro human embryos using morphological and clinical 
data,” Computer Methods and Programs in Biomedicine archive, 90(2), 104-116. 
16. Hughes, G. F., 1968, “On the mean accuracy of statistical pattern recognizers,” IEEE: Transactions on 
Information Theory, 14, 55-63. 
17. Fukunaga, K., 1990, “Introduction to Statistical Pattern Recognition,” San Diego: Academic Press Inc. 
18. Kim, Y., Street, W. N. and Menczer, F., 2002, “Feature selection in data mining ,“ Hershey, PA: Idea 
Group Publishing. 20-105. 
19. Frawley, W., Piatetsky-Shapiro, G. and Matheus, C., 1992, “Knowledge Discovery in Databases: An 
Overview,” AI Magazine, 213-228. 
20. Fisher, R. A., 1936, “The Use of Multiple Measurements in Taxonomic Problems,” Annals of Eugenics, 7, 
179-188. 
21. Reichert, A.K., Cho, C.C. and Wagner, G.M, 1983, “An examination of the conceptual issues involved in 
developing credit-scoring models,” Journal of Business and Economic Statistics, 1(2), 101–114. 
22. Jain, S. and Jain, R. K., 1994, “Discriminant Analysis and its Application to Medical Data,” Biometrical 
Journal, 36 (2), 147-151. 
23. Zafeiriou, S., Tefas, A., Pitas, I., 2005, “Linear Discriminant Feature Selection Techniques in Elastic Graph 
Matching,” EURASIP European Signal Processing Conference, Antalya, Turkey. 
24. Quinlan, J. R., 1986, “Induction of Decision Tree,” Machine Learning, 1, 81-106. 
25. Berry, M. J. and Linoff, G., 1997, “Data Mining Techniques: for marketing, sales, and customer support,” 
John Wiley & Sons, New York. 
26. Kohavi, R. and Provost, F., 1998, “Glossary of Terms,” Machine Learning, 30, 271-274. 
27. Chen, S. Y., 2005, “Multivariate analysis (Fourth edition),” Hwa-tai Culture published, Taiwan, ROC. 
28. Nakai, K., Kanehisa, M., 1992, “A knowledge base for predicting protein localization sites in eukaryotic 
cells,” Genomics, 14(4), 897-911 
  
100年度專題研究計畫研究成果彙整表 
計畫主持人：陳凱瀛 計畫編號：100-2221-E-027-018- 
計畫名稱：應用複合式資料探勘技術於人工生殖懷孕率預測之研究 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 7 3 100%  
博士生 2 1 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 1 1 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
