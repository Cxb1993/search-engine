 2
in this layer. For external input jx , a local membership 
function is used, and the following isosceles triangular 
function is adopted, 
(2)
(2)
(2) (2) (2) (1)
(2)
0
| |
1  and   
0
j ij ij
j ij
i ij ij j ij ij j j
ij
j ij ij
u m
u m
O m u m u O
u m
σ
σ σσ
σ
⎧ ≤ −⎪ −⎪= − − ≤ ≤ + =⎨⎪⎪ ≥ +⎩
   (1) 
where ijm and ijσ  are, respectively, the center and the 
width of the triangle membership function of the i th 
term of the j th input variable jx .  For internal 
variable ih , a global membership is used, and the 
following piece-wise linear function is adopted 
(2)
(2)
(2) (2) (2)
(2)
1 2.8125
2.8125 2.8125 2.8125
5.625
0 2.8125
i
i
i i i i
i
u
uO u and u h
u
⎧ ≥⎪ +⎪= − ≤ ≤ =⎨⎪ ≤ −⎪⎩
           (2) 
where the parameters 2.8125 and 5.625 are chosen for 
easy digital implementation. Links in layer 2 are all set to 
unity. 
 Layer 3: The output of each node in this layer is 
determined by fuzzy AND operation.  Here, the 
minimum operation is utilized to determine the firing 
strength of each rule.  The function of each rule is 
1
(3) (2)
1
{ }min
n
i j
j
O O
+
=
=           (3) 
The link weights are all set to unity. 
Layer 4: Nodes in this layer perform a linear 
summation.  The mathematical function of each node i  
is 
1
(4) (4)
1
0 1
n n
i ij j io ij j in i
j j
O a u a a x a h
+
+
= =
= = + +∑ ∑      (4) 
Links from this layer to layer 6 are all equal to unity. 
 Layer 5: The context node functions as a defuzzifier 
for the fuzzy rules with inference output h . The simple 
weighted sum is calculated in each node,  
(5) (3)
1
r
i i j ij
j
h O O w
=
= =∑             (5) 
Each rule has a corresponding internal variable h  and 
is used to decide the influence degree of temporal history 
to the current rule. 
Layer 6:  The node in this layer computes the output 
signal y of the TRFN-H.  The output node together with 
links connected to it act as a defuzzifier.  The 
mathematical function is 
(3) (4)
1(6)
(3)
1
r
j jj
r
jj
O O
y O
O
=
=
= = ∑∑
             (6) 
3. TRFN-H design by multi-group genetic 
algorithm and particle swarm optimization  
 
In TRFN-H, the number of fuzzy set on each input 
variable is equal to the number of fuzzy rules. Thus, once 
the number of rules is determined, the whole TRFN-H 
structure is constructed. To use R-MGAPSO, the free 
parameters in TRFN-H should be first encoded. Here, a 
floating point coding scheme is adopted.  The length of 
each individual depends on the number of rules encoded 
in it. Suppose that there are r  rules, n  input variables 
and a single output in TRFN, then the length of each 
individual is )23( rnr ++ . The parameters representing 
spatial relation, i.e. am  and , ,σ , are encoded first 
followed by the parameters representing temporal 
relation., i.e. w . The order of parameters encoded into the 
individuals is as follows: 
11 11 1 1 10 1 1 1 0
11 1
| | | | | | | | | | | | | | | |
| | | | | |
n n n r r rn r rn
r rr
m m a a m a a
w w w
σ σ σ σ" " "" " "
" "
 Let the search range of the rule number be ] [ maxmin, rr , 
where minr  and maxr denote the minimum and 
maximum number of rules, respectively. Initially, SP  
individuals with rule number randomly selected from the 
rule search range are randomly generated, where 
individuals of equal length are considered to belonging to 
the same group. Flowchart of individuals’ evolution is 
shown in Fig. 2, where the evolution include elite strategy, 
elites enhancement, variable-length crossover, and 
mutation, each of which is introduced as follows.  
In elite strategy, the population is first sorted 
according to the fitness value of each individual. The 
top-half best performing individuals in the whole 
population are regarded as elites. These elites are then 
enhanced by PSO. Here, an elite is regarded as a particle 
in PSO. The position vector and velocity vector of 
particle i  are denoted by ix
K
 and iv
K
, respectively. The 
dimension of vectors ix
K
 and iv
K
 is the same as the 
length of elite i . The fitness value of elite i  is used 
directly as the quality measure of particle ix
K
. Each 
particle keeps track of its own best position in a 
vector ip
K
, which is associated with the best fitness it has 
achieved so far in a vector ip
K
. On generation t , by using 
the velocity updating equation, we have  
*
1 1 2 2( 1) ( ( ) ( ( ) ( )) ( ( ) ( )))i i i i iv t v t c p t x t c p t x tχ φ φ+ = + − + −K K K K K K
               (7) 
 4
design of TRFN by neural learning based on direct 
inverse control configuration proposed in [3] is simulated. 
The number of rules is also set to six and the training data 
is the same as that used in [3]. After training, RMSE of 
the control result for the test trajectory is 0.1722, which is 
larger than that achieved by R-MGAPSO.  
For comparison, TRFN designs by Elite GA (EGA) 
and Traditional GA (TGA) with variable- length 
individuals are also simulated. For fair comparison, in 
these two algorithms, the population, number of 
generations, total runs, and mutation probability are all 
the same as those used in R-MGAPSO.  In EGA, the 
top-half best-performing individuals are regarded as elites, 
and they are reproduced directly to the next generation. 
The other half population is constituted by offspring 
produced by crossover and mutation operations. The 
parent selection scheme, crossover operation, and 
mutation probability in EGA are the same as those in 
R-MGAPSO. In TGA, parents are also selected by 
tournament selection scheme, but they are selected from 
the whole population instead of only the elites. Offsprings 
are generated by two-point crossover operation with a 
crossover probability of 0.6. This probability is the best 
one via simulations on different crossover probabilities. 
To keep a non-decreasing fitness value, the best 
performing individual is reproduced to the next 
generation in TGA. For both EGA and TGA, the 
population size and initialization of variable-length 
individuals are the same as those used in R-MGAPSO. 
For these two approaches, the averaged best-so-far fitness 
values of each generation are shown in Fig. 3.  From 
comparisons, we see that R-MGAPSO achieves the 
smallest average RMSEs. 
 
Example 2. Water bath temperature control experiment  
The experiment is performed on a real water bath 
temperature control system. A schematic diagram of the 
experimental setup is shown in Fig. 5. The device of the 
FPGA is Altera FLEX EPF10K50EQC240-1which 
contains 50,000 typical gates (logic and RAM), 2,880 
logic elements. The AD converter we used is AD1674. It 
is a 12-bit analog-to-digital converter. The DA converter 
is DAC0808, which is an 8-bit monolithic 
digital-to-analog converter.  We use 12-bit AD converter 
for higher measurement accuracy. For the temperature 
measurement, a PT100 sensor is used. The max power of 
the heater is 1000W. For a discrete-time control system, it 
is necessary to decide the sampling period. Here, we first 
chose 30=ST  seconds as the sampling period.  
The TRFN-H based direct inverse control 
configuration is shown in Fig. 6. The plant considered 
here is a temperature control system. Owing to the 
recurrent property of TRFN-H, only the current 
temperature ( )Py t  and reference temperature 
( 1)refy t +  are fed as inputs during control. This is in 
contrast to the feedforward network controller, where the 
controller input variables vary with the plant order. We 
may add more past process outputs, e.g. ( 1)Py t − , 
( 2)Py t − , etc. as inputs, but this will increase network 
size. In addition, the exact order of the plant is unknown 
in advance. Since the process of controller input variable 
determination is avoided, this obviously eases the 
controller design approach. For off-line training, in order 
to get the training samples from the plant, a sequence of 
random input signals ( )u t  under the magnitude limit of 
the plant input are injected directly into the plant, and 
then an open-loop input-output characteristic of the plant 
is obtained. According to the input-output characteristic 
of the plant, proper training patterns are selected to cover 
the entire reference output space. Using the collected 
training patterns with the values of ( )Py t  and 
( 1)Py t + as the input patterns and the corresponding 
control signal ( )u t as the target pattern, the TRFN-H is 
deigned to minimize a Root-Mean-Squared-Error (RMSE) 
defined by 2 0.5
1
ˆ( [ ( ) ( )] / )
nK
n
t
RMSE u t u t K
=
= −∑ , where 
nK is the number of training patterns, and ˆ( )u t is the 
actual output of RFC. For temperature control problem, a 
large change in control input ( )u t  will usually result in 
a small change in temperature. So in the collected training 
data, for close input training temperature values ( )Py t  
and ( 1)Py t + , the desired output ( )u t is a sequence of 
random variables changing abruptly. This is not an easy 
learning problem, and learning involving gradient descent 
algorithms will lead to a poor performance. For this 
reason, design using R-MGAPSO is proposed.  
TRFN-H design by R-MGAPSO is performed, 
where the number of rules after learning is three. The 
designed TRFN-H is hardware implemented by FPGA. 
The control performance by the designed TRFN-H chip is 
shown in Fig. 7.   
 
6. Conclusions 
Contributions of the project are twofold: 1) 
Recurrent fuzzy network design by the hybrid of two 
evolutionary learning algorithms, multi-group GA and 
PSO, is proposed in this paper. 2) The TRFN-H is 
implemented by hardware. The results have been 
accepted to be published in two journal papers [1, 2] 
.  
7. REFERENCES 
[1] C. F. Juang and J. S. Chen, “Water bath temperature 
control by a recurrent fuzzy controller and its FPGA 
implementation,” IEEE Trans. Industrial Electronics, 
vol. 53, no. 3, pp. 941-949, June 2006. (SCI, EI) 
[2] C. F. Juang and I. F. Chung, “Recurrent fuzzy 
network design using hybrid evolutionary learning 
algorithms,” accepted to be published in 
