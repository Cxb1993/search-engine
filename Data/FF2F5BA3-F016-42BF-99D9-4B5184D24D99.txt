計、語音識別分析與合成及發展濾除語音干擾快速演算法(子
計畫四、五、六)。即使用擴充式卡爾曼濾波器融合多感測器
包括雷射掃瞄器與定位儀、超音波或紅外線感測、馬達轉軸
編碼器、陀螺儀等技術，提升點餐服務機器人的定位精確度
與可靠性。並利用無線電麥克風及商用語音辨識軟體(子計畫
四、五、六)、觸控螢幕、LED 按鈕輸入鍵盤，完成語音輸入
人機介面，發展濾除語音干擾快速演算法，探討其他追蹤控
制演算法在行動服務機器人路徑規劃與追蹤控制上的可行
性。此外，本研究子計畫為了安全因素，使用無線電網路透
過遠端電腦來加以監控機器人的運作狀態。 
本研究計畫分三年完成，第一年研究目標為移動式機器人室
內定位與導航技術的發展。 第二年旨在將此機器人以點餐服
務機器人為設計與製作展示平台，達到戶外定位與導航功
能，並以語音方式建立與機器人溝通的管道，及利用語音點
餐。第三年則著重在雙手臂配合雙眼視覺辨識系統端取餐
盤，送至顧客餐桌上。以上功能就工程技術而言，將發展行
動機器人室內與戶外定位導航與路徑規劃演算法，單眼視覺
辨識人臉及追蹤法則，至雙眼物件判別及定位演算法，再配
合雙機械手臂，以最佳化路徑取物，達到最短時間並避開空
間障礙物之取物目的。發展雙機械手臂相互協調動作正向逆
向運動學，座標轉換…等演算法。在語音部分，由原先較少
組的簡單辨識，發展到較多組的語音辨識，提高語音辨識的
速度與成功率。並往語音合成之高智慧的溝通技巧發展。以
上說明為本專題研究三年所得，並將成果發表在國內國際研
討會及期刊上，同時也陸續申請並獲得多項發明及新型專
利，未來將往和產業界技術移轉的方向邁進，達到科技實用
化的效果。 
中文關鍵詞： 點餐服務機器人、雷射定位技術、全球衛星定位系統、自適
應性模糊 PID 控制器、影像辨識與追蹤、語音合成與識別、
擴充式卡爾曼濾波器、訊息濾波器、KGPS、雷射定位導航、
最佳路徑規劃、F-VFH 演算法、梅爾倒頻譜係數、隱藏式馬
可夫模型、雙機械手臂、正向逆向運動學、末端效應器、雙
視覺辨識系統、影像前處理的測邊 
英 文 摘 要 ： The main purpose of this sub-project is to achieve 
the project ’Design and Implementation of Agile 
Human Symbiotic Service Robots with Semi-Humanoid 
Appearances,’ where it should be used the advanced 
technology of localization and navigation. The arms 
of this sub-project is to fuse the advanced 
technology of localization and navigation indoors and 
outdoors, apply it to the meal service robots to 
行政院國家科學委員會補助專題計畫研究
■ 成 果 報 告
□期中進度報告
智慧半人型與人共生服務機器人之研製-子計畫三：
先進定位導航技術
計畫類別：□ 個別型計畫 ■ 整合型計畫
計畫編號：NSC 97-2221-E-167-018- MY3
執行期間：97 年 08 月 01 日至 100 年 7 月 31 日
計畫主持人：黃國興
計畫參與人員：蕭順徽、陳柏承、朱銘傑、高劭銓、周冠榮、葉文揚、
賴昱辰
成果報告類型(依經費核定清單規定繳交)：□精簡報告 ▓完整報告
本成果報告包括以下應繳交之附件：
□赴國外出差或研習心得報告一份
□赴大陸地區出差或研習心得報告一份
□出席國際學術會議心得報告及發表之計畫各一份
□國際合作研究研究國外計畫報告書一份
處理方式：除產學合作研究計畫、提升產業技術及人才培育研究計畫、
列管計畫及下列情形者外，得立即公開查詢
□涉及專利或其他智慧財產權，■一年□二年後可公開查詢
執行單位：國立勤益科技大學 電子工程系
中 華 民 國 100 年 8 月 31 日
間座標，成為偵測物體空間位置的良好「感
測器」，這是雙眼視覺的最大特點。
本成果報告架構如下，第一節為前
言，說明研究本計畫的目的、動機及目前
國內外有關這方面的研究技術，及本計畫
機器人系統所採用的研究方法作簡要敘
述；第二節的部份為機器人數學模型及系
統架構；第三節為機器人的路徑規劃法
則，主要利用模糊控制器為主要演算法的
機器人定位導航系統；第四節則介紹
KGPS定位系統應用在移動式機器人上，
執行戶外導航功能；第五節為語音辨識技
術的介紹；第六節主要說明雙視覺影像辨
識與定位技術；而第七節則介紹六軸機器
手臂機構功能與系統設計；第八節為實際
測試結果，並展示出我們所開發出來的各
種演算法，應用於機器人整體導航上的成
效；第九節則作個結論，於此章節針對本
文所提出的演算法其成效做一個總體的分
析說明以及未來會繼續進行的相關工作。
二、機器人數學模型及系統架構
2.1 機器人數學模型
本文所提出的自主式載具，基本上以
雙輪式平台為主，如圖 2.1 所示。將載具
之輪軸半徑、兩輪間距、載具平均速度、
載具角速度考慮至整體系統中，如算式
(2.1)至(2.4)所示：
( ) / 2avg L Rv v v  (2.1)
其中， avgv 表示載具前進時的線速
度， Lv 及 Rv 分別代表的是載具左輪與右輪
的轉速。
( ) / ( )L R L Rv v v v   (2.2)
其中，表示載具於旋轉時的控制因
數，我們將會利用此控制因數對載具的左
右輪進行轉速的控制。
/r w w avgr d v   (2.3)
其中， r表示載具於旋轉時的角速
度， wr 代表載具兩輪的輪軸半徑， wd 代表
載具兩輪間的間距。
結合公式(2.1)與(2.3)我們可經由推導
獲得最終載具運動方程式，
cos cos
2 2
sin sin
2 2
1 1
t t
x
Lt t
y
R
r
w w
v
v
R v
v
d d
 
 

 
 
                    
(2.4)
其中，R代表自主式載具的運動方程式， xv
表示載具相對於座標系統中水平分量的速
度， yv 表示載具相對於座標系統中水平分
量的速度， t表示載具至目標點的航向。
圖 2.1 機器人運動模型
2.2 機器人軟硬體架構
圖 2.2 機器人硬體架構圖
本節將就所採用之主要系統架構及功
能軟體架構依序加以詳述。
本研究以嵌入式電腦作為主要控制
器，使用 SICK NAV200，作為定位用的設
備，並利用 SICK LMS291 雷射測距儀，
作為環境認知的主要感測器，主要通訊協
定為 RS-232。機器人硬體架構圖如圖 2.2
所示，系統架構圖如圖 2.3 所示，而機器
人實際圖如圖 2.4 所示。
圖 3.1 載具工作區間示意圖
在 F-VFH 演算法中，我們所採用的演算
法概念也是架構於原始的 VFH 避障演算
法上，但資料的處理技術共分成四個階
層，步驟如下所示：
(a) 描述載具於當前環境的詳細狀態。利
用雷射測距儀推算出載具與當前環境
的相對關係，並以二維的笛卡兒直方圖
座標來表示。
(b) 加權值設定。在載具前方 180°的地方
建立一個一維的極座標直方圖(Polar
Histogram)HP ，而 HP 是由 n 個角度為
α的連續扇形所組成，透過工作視窗
(Work Window)映射到 HP，利用模糊控
制演算法則，來調整障礙物加權函式的
參數值。
(c) 加權地圖。透過上步驟所獲得的加權
值，對加權地圖進行更新，並將其融入
到全域地圖中，使整體路徑規劃能夠更
加準確。
(d) F-VFH演算法的輸出。將 F-VFH 演算
法所獲得的參數透過轉換器送到行走
系統上，藉此控制載具的速度及方向。
3.2 環境狀態描述
於本研究中，我們利用每個方格解析
度為10㎝×10㎝的二維笛卡兒座標系統作
為經由雷射測距儀所掃描到的環境資訊地
圖。透過公式(3.1)，我們可以將雷射測距
儀所掃描到的資訊映射到世界座標系統
中，如圖 3.2 所示。
 
 
cos
sin
obs vcp xy vcp obs
obs vcp xy vcp obs
x x d
y y d
 
 
    
   
(3.1)
其中，障礙物的座標為(xobs, yobs)，載
具的座標點為(xvcp,yvcp)，θvcp 為載具的目前
的航向，θobs 為障礙物與載具之間的夾角。
圖 3.2 環境狀態描述示意圖
3.3 加權值的設定
與原來演算法有所不同的地方是，原
來的演算法是以連續掃瞄的方式來更新障
礙物存在的可信度，藉由各個不相同顆的
感測器所掃描的次數，來增減可信度的數
值，由於我們可獲得障礙物的確定位置，
所以不需要以可信度的方式來告知機器人
障礙物存在的可能性。因此，取而代之的
是，將此可信度改成障礙物對載具再行進
路徑上可能造成威脅的機會，當所獲得的
權重值越大時，表示此障礙物對載具的威
脅程度越大。
圖 3.3 掃描扇形區間示意圖
如圖 3.3 所示，我們會先規劃出一個
半徑為 d 的工作區，並利用公式(3.2)將掃
描扇形所掃描的區間範圍推算出來，
deg *
k i
i k
S d
 
  (3.2)
x
y
(xobs, yobs)
(xvcp, yvcp)
dxy
Obstacle
Vehicle
θobs
10㎝×10㎝ Per Grid
O
θvcp
VCP
Scan Sector Region
Work Window
Weight Value
5
dmax
3000mm
3000mm
Laser Scanner
Robot
Work Window
Partition Region × 9 [ 20°/Region]
0k k OD
k k k OD
OD if OD
OD OD if OD


 
  
(3.8)
圖 3.4 障礙物佔據程度直方圖
圖 3.5 佔據程度直方圖過濾
接下來的步驟，將針對通過初步濾波
的掃描區間範圍進行其權重值的分析，我
們把掃描扇形區間 2、5、6、7 做展開的動
作，將區間內各個角度對其區間佔用的程
度以直方圖來表示，如圖 3.5 所示。
圖 3.6 直方圖等化分析
接著再利用條件式(3.9)來進行第二次
的濾波工作，臨界值的範圍為 0.1~1.0，將
臨界值τw 設成 0.3，以此為分水嶺，當此
角度權重值大於 0.3 時，就將其權重值設
為 1，小於 0.3 時，則將權重值設為 0，結
果如圖 3.6 所示。
1
0 <
xy xy w
xy xy w
w if w
w if w


 
 
(3.9)
圖 3.7 二值化極直方圖
在圖 3.7 中，藍色方框代表的是
各掃描扇形區間，紅色線條代表受阻方
向，綠色方格框代表可行走的候選方向。
3.5 候選航向的決策(Candidate Heading)
透過二值化極直方圖座標，我們可以
很明顯的看出機器人可行走的候選方向以
及不可通過的受阻方向，由此獲得 CD1、
CD2、CD3 三個候選方向，再來的步驟就
是如何從這三個候選方向中選出一個合適
的來當作載具下一步航向。
候選方向的出現是由一連串極小的扇
形所組成，判斷合適的候選方向我們遵循
幾個原則，第一個為此後選方向的缺口寬
度是否大於載具的最大寬度，假如此候選
方向於所有候選方向中距離目標點是最近
的，但缺口寬度小於載具寬度，則我們就
不可以選擇此候選航向為最佳航向，而缺
口寬度大小的設定，我們利用公式(3.10)
作為主要判斷式。
     2 2 2 cos 3.10k kr l kr kr r lWidth k k     
其中，kr 為候選航向第一個扇形區間
邊界的角度，kl 為候選航向最末端邊界的
角度，dmax 為工作區半徑。當 Width 大於
載具寬度時，代表此候選航向是能夠使載
具通行的航向，選定候選航向以後，再利
用公式(3.11)求出此候選航向的中心方向
θc，如下所示。
2
r l
c
k k  (3.11)
第二個選擇原則，為此後選航向距離
目標點的遠近，如果所有候選航向的缺口
1.0
0.3
Degree
wxy
τw
20-40 80-100 100-120 120-140
CD1 CD2 CD3
1.0
0.3
7 6
Degree
wxy
2
τw
5
20-40 80-100 100-120 120-140
1.0
0.65
981 43
7
6
5
0° 20° 60° 100°
140° 180°
Degree
ODk
2
τOD
1.0
0.65
9
81
43
7
6
5
0° 20° 60° 100°
140° 180°
τOD
Degree
ODk
2
And Angl_Mdf is S then g2=1×Δ(θc,θtar)+
0.4×Δ(θc,θv)+ 0.1×Δ(θc,θc,t-1)
R3 :
If Angl_Tar is NS And Angl_Obs is NS
And Angl_Mdf is ZE then g3=1×Δ(θc,θtar)+
0.2×Δ(θc,θv)+ 0.1×Δ(θc,θc,t-1)
.
.
.
Rn :
If Angl_Tar is PB And Angl_Obs is PB
And Angl_Mdf is PB then gn=1×Δ(θc,θtar)+
0.7×Δ(θc,θv)+ 0.1×Δ(θc,θc,t-1)
四、室外 KGPS導航系統
而在室外導航定位方面，我們所採用
的定位方式為利用全球衛星定位系統
(Global Positioning System, GPS)作為主要
定位裝置。一般而言，GPS 所提供的標準
定位服務 (Standard Positioning Service ,
SPS)之精度約為水平方向 100 公尺，垂直
方向 156 公尺；就算關閉選擇可用性
(Selective Availability, SA)效應後，其精度
大約為水平方向 25 公尺，垂直方向 43 公
尺左右，這種精度對於智慧型服務機器人
而言是不夠的，因為服務型機器人所工作
的地方大部分是在人群眾多或者是環境中
有許多不確定因素的場所，因此，若要利
用 GPS 作為智慧服務機器人的室外定位
裝置，勢必需要大幅度的提升其精度。
本篇論文所研究之機器人 GPS 戶外導
航定位所採用的精度修正方式以動態
GPS(Kinematic GPS, KGPS)為主要的精度
修正技術，其所採用的修正方式係將基站
將所觀測到的 GPS 即時訊號傳送給機器
人，接著再利用機器人本身的處理器來進
行載波相位(Carrier Phase)週波未定值以
及基線向量值的解算，進而獲得即時且精
度在公分級的路徑點(Waypoint)。而 KGPS
其硬體系統架構的設置方式基本上也與
DGPS 一樣，圖 4.1 則為本研究之室外導
航系統硬體系統之配置。
圖 4.1 KGPS 室外導航架構.
五、語音辨識系統
圖 5.1 語音辨識信號處理流程圖
語音辨識在業界與學術界已經是常見
的技術，但是到目前為止卻沒有任何一種
語音辨識模組能夠完全適用於機器人上。
本研究計畫中我們使用 Spce3200 嵌入式
系統為主要控制模組。如圖 5.1 為語音辨
識信號處理流程圖，語音訊號由麥克風輸
入經過類比數位取樣，進行預強調之步
驟，聲音從人類嘴唇發出後，經由麥克風
輸入至處理系統時，聲音高頻的部分會被
衰減掉，所以本論文在框與窗的切割及處
理前，需要做高頻的補償，這個方法就是
讓信號通過一個高通濾波器。
S(n)' = S(n)- a* S(n -1) (5.1)
( )S n 為原始信號， ( ) 'S n 為預強調後的信
號，的值可由 0.9~0.99 之間，最佳值於
0.94~0.95。例如圖 5.2 為原始訊號，圖 5.3
為預強調之後的信號，可以很明顯的觀察
出兩者之間的差別，信號明顯平穩許多，
部分的背景雜音也被去除，高頻部份也被
補償回來。
圖 5.6 漢明窗
快速傅立葉轉換是離散傅立葉轉換的
快速算法，一般的語音信號在時域時資料
量非常龐大，所以我們將這些資料經由快
速傅立葉轉換至頻域方便作分析及計算。
1
0
0
0
, 2( ) ( ) ( )
F
jn t
F
F m Ts
p n w n e   



  
(5.4)
特徵值求取是語音辨識最為重要的部
份，本研究是使用梅爾倒頻譜係數(MFCC)
來求取特徵參數，如公式 (5.5)所示。
log( [ ])S k 是將能量進行對數轉換。 [ ]S n
代表音框內第 n 階之 MFCC 參數。最後是
藉由隱藏式馬可夫模型(HMM)[25]，但在
這之前要先經過模型訓練的過程，而辨識
模組的比對是使用動態時間校準演算法
(DTW)[25]來進行模組評分的動作。
1
[ ] log( [ ]) cos[ ( 0.5) ]
M
k
S n S k n k
M


    
(5.5)
六、雙影像視覺系統
6.1 雙影像視覺原理概述
本研究是使用兩台攝影機的方式，也
就 是 雙 眼 視 覺 系 統 (Binocular Stereo
Vision)，實驗環境是在立體空間進行的，
環境內有一個餐盤，我們利用雙眼視覺系
統去偵測餐盤並且計算他的三維座標，而
這些三維的資訊主要是給智慧型點餐服務
機器人作為使用，所以計算出來的三維資
訊要準確，智慧型點餐服務機器人才會拿
的到餐盤。
圖6.1 雙眼視覺的影像呈現之示意圖
而使用雙眼視覺的方式可以解決投影
點問題，如圖6.1所示，M'與N都會投影在
右影像的nR點，M與N'也都會投影在右影
像上的mR點，M與M'都會投影在左影像的
mL點，N與N'也都會投影在左影像上的nL
點，而用立體視覺能夠從左影像上的mL
點，對應右影像上的mR點，找到M點，也
能夠從左影像上的nL點，對應右影像上的
nR點，找到N點，如此一來，可知道影像
上的點對應到空間中的對應位置，即可求
出景深。
目前常見的立體對應(Stereo Matching)
[16], [17], [18]研究方式主要利用不對稱的
原理，近年來有使用影像比對的方法
(Image Matching) [16]。利用不同立體對應
方式，找出立體影像上的對應點或區塊，
求得景深資訊，將架設的系統直接用來作
影像辨識、影像重建等，或著與其他的系
統結合，裝在機器人、自走車或是其他裝
置，應用在避障、導航、運動路徑規劃等
功能上，或者輔助機器人控制機械手臂、
影像偵測與辨識等。
雙眼視覺在攝影機擺放的方式有許多
種，主要以光軸（Optical Axes）來區分，
最普遍使用的方法為光軸平行擺放，跟人
類視覺類似，也是本論文所採取的方法。
根據實驗需求我們的校正方式比較簡單，
採用影像校正的方式，主要是針對兩台攝
影機的影像中心點作校正，其中影像中心
其中：
f：鏡頭焦距
Z：目標物景深
dY ：目標物與光軸之垂直實際距離
dy ：目標物與光軸之垂直影像距離
dY Z
dy f

(6.9)
dy Z
dY
f

(6.10)
6.2 餐盤辨識系統
形狀偵測對於電腦視覺及影像處理來
說，是一個重要的課題，過去有許多學者
提出不同的形狀偵測方法，但是大部分以
偵測直線、矩形或圓形等較為簡單的形狀
為主，對於橢圓這種需要五個點才可以決
定一個橢圓的問題，則討論的較少 [19]。
使用傳統的霍式轉換雖然可以偵測橢圓，
但因為參數空間提升到五維空間後，連帶
增加了相當大量的計算時間，進行投票所
需要的記憶體量也隨之上升，造成偵測橢
圓的效率大減。採用最小平方法雖然速度
比傳統的霍式轉換快上許多，但因為一次
只能偵測一個橢圓，若影像內含多個橢圓
在內時，則必須將邊線點事先分類才能偵
測多個橢圓。橢圓偵測架構圖如圖6.4所
示。
在本研究中利用Halíř的最小平方法將
邊線點所對應的橢圓找出，這個方法與
Fitzgibbon的方法一樣具有很好的效率，並
且可以相當容易的實作出來，比起
Fitzgibbon的方法又可以避免因奇異矩陣
的影響，導致在計算特徵向量時出錯。
圖6.4 垂直方向之二維的影像投射面差以
及三角比例關係示意圖
使用最小平方法時最少需要五個點才
能找出近似的橢圓。若挑選的點過於集
中，會使近似的結果與實際的橢圓差異過
大。除此之外，若其中的幾點共線或是取
點太過密集，則近似出來的結果將與實際
的橢圓相去甚遠。同時當影像中不只存在
一個橢圓時候，也需要確定挑選的點都要
在同一個橢圓上。若橢圓重疊、有缺口或
橢圓是由虛線構成時，這都將使得要判斷
選出的點都在同一個橢圓時發生困難，如
圖6.5所示。因此若挑選出的點若能平均分
佈在橢圓上，則近似出來的橢圓便能更逼
近實際的物體。在此，我們為了判別挑選
出的點是否共線，使用了凸邊形的方式將
從影像中挑選出的點找出其凸邊形，再判
斷找出的凸邊形頂點數是否與挑選的點數
相同，若凸邊形的頂點數量與挑選的點數
相同，代表挑選出的點沒有發生共線，可
以找出與實際橢圓相近的近似橢圓；若凸
邊形的頂點數量與挑選的點數相異，表示
有些點發生了共線的情形，這將使得近似
出的橢圓與實際橢圓差異過大，這時我們
將重新挑選點，再判斷其是否能找出頂點
數量與挑選點數量相同的凸邊形，再利用
最小平方法找出近似橢圓。
圖6.5 邊線點太過密集
凸邊形計算的基本原理是建構在數學
與計算幾何（Computational Geometry）之
上。過去有許多學者提出求得凸邊形的演
算法，如： Graham's Scan[20] 、 Jarvis
March[21]、QuickHull[22], [23], [24], [25],
的逆運動學方程式，與基因演算法及模糊
演算法配合之下，使機器手臂能夠自我修
正且能針對不同事件的強健性，最後雙手
機器手臂能夠確實且穩定替客人上菜服
務。
機械手臂具有工作效率高，動作反覆
精準，承載能力佳等優點，因而被廣泛應
用在生產加工，產品運輸，家庭服務等各
領域。但固定在平台上的機械手臂，工作
空間十分有限，近年來各國專家學者和研
究人員，致力於研究將機械手臂安裝在移
動機器人身上，使機械手臂有更大的工作
空間。而機械手臂的定位系統中，本身的
位置控制、速度控制、扭力控制、結構的
設計，會直接地影響機械手臂的移動路徑
精準度，以及機器人是否能夠執行操作者
所賦予的功能。再加上雙手機械手臂路徑
移動，使得逆運動學分析複雜度更高，這
些問題得到機器人領域許多專家的關注。
在為了使機械手臂的末端能更精確至目標
物，因此先進行，因此，針對具有冗餘自
由度的機械手臂，先提出逆運動學求解策
略[19][20]。
Fuzzy-GA-Based Trajectory Planner
(FuGABTP)是Emmanuel A. Merchán-Cruz
and Alan S. Morris於2006年所提出來的雙
手機械手臂路徑規劃方法[21]，主要是用
來實現適用多軸的雙手臂在共同工作區避
免碰撞及預測情形[22]-[23]，例如手臂自
由度的增加，使移動路徑不易規劃，且可
能會破壞手臂結構的情形發生[24]；機械
手臂抓取目標物或是閃避障礙物，若缺乏
預測功能，未對不同事件處理的強健性，
其末端若偏離目標物，與目標物或是另一
手臂產生碰撞…等事件發生。
描述機械手臂的動作，必須明確定義
出機械手臂與各物體之間的相對位置，使
控制器能根據這些資料進行適當的計算與
座標轉換，進而接近目標物執行預先設定
之動作。一般機械手臂是由一連串的連桿
與馬達驅動的軸關節組合而成，用運動學
表示法來定義座標及連桿的關係，其中並
不考慮力與力矩的問題。因此機械手臂的
運動學中，包含了正向運動學與逆向運動
學，其正向運動學是給予各軸關節的角度
位置，使求得機械手臂的末端效應器
(End-effector)的位置與方向；反之，逆向
運動學是給予機械手臂的末端效應器
(End-effector)的位置與方向，求得各軸關
節的角度如圖 3.1 所示。
圖7.1 運動學的對應關係方塊圖
圖7.1 機械手臂模型6-DOF
7.1 機械手臂正向運動學分析
本研究有兩種系統分別為AI-Robot
Arm實驗系統與DC-Robot Arm研究系
統，其目的驗證兩系統的機械手臂運動學
分析。首先定義各系統的關節編號如圖3.4
所示，根據 D-H 方法定義出機械手臂各
關節的座標系統，此時兩系統定義的座標
與方向相同，因此把兩系統合成一個機械
手臂之共同座標系統；依照圖7.2所定義的
座標系統，將 D-H表整理如表7.1所示。
     1 2 3 4 5 3 5 2 4 5 1 3 4 5 3 5 .
(7.8)
yn s c c c c s s s s c c s c c c s       
   2 3 4 5 3 5 2 4 5
(7.9)
zn s c c c s s c s c     
     1 2 3 4 5 3 5 2 4 5 1 3 4 5 3 5
(7.10)
xo c c c c s s c s s s s s c s c c        
     1 2 3 4 5 3 5 2 4 5 1 3 4 5 3 5
(7.11)
yo s c c c s s c s s s c s c s c c        
   2 3 4 5 3 5 2 4 5
(7.12)
zo s c c s s c c s s     
    1 2 3 4 2 4 1 3 4
(7.13)
xa c c c s s c s s s    
     1 2 3 4 2 4 1 3 4
(7.14)
ya s c c s s c c s s    
   2 3 4 2 4
(7.15)
za s c s c c   
     1 2 3 4 5 2 4 5 3 1 3 4 5
(7.16)
xp c c c s d s c d d s s s d     
     1 2 3 4 5 2 4 5 3 1 3 4 5
(7.17)
yp s c c s d s c d d c s s d     
   2 3 4 5 2 4 5 3
(7.18)
zp s c s d c c d d    
由上式(7.16)，(7.17)，(7.18)可知末端效應
器之座標 , ,x y zp p p 。
7.2 機械手臂逆向運動學分析
從正向運動學求出 , ,x y zp p p 末端效
應器之座標，即可用來反推算逆向運動
學，所謂的逆向運動學是指利用已知各連
桿於絕對座標系中的位置，反求各軸關節
之對應轉動角度。
求解逆向運動學的技巧可使用反矩陣
比較法，再根據三角函數的觀念求出各軸
關節角度解。首先從(7.6)子中，將任一連
桿的狀態都可由先相關的矩陣相乘得知，
因此藉由 0 0 1 2 3 45 1 2 3 4 5T T T T T T 在等號兩旁同
乘上 0 1T 反矩陣運算得(7.19)，(7.20)式，再
比較左右兩矩陣中各元素來推導逆向運動
學。
        10 0 1 2 3 41 1 5 2 2 3 3 4 4 5 5
(7.19)
T T T T T T       
1 1
1 1
5
1 1
0 0
0 0 1
(7.20)
0 0
0 0 0 1 0 0 0 1
x x x x
y y y y
z z z z
c s n o a p
d n o a p
T
s c n o a p
  
      
  
  
如果令式(7.20)等號左邊的兩矩陣相乘的
元素[1,4]、[2,4]與[3,4]分別相等得
1 1
1 1 (7.21)
x y x
z y
x y z
c p s p p
p p
s p c p p
 
 
  
其中 1 5
0 0 0 1
x x x x
y y y y
z z z z
n o a p
n o a p
T
n o a p
 
 
  
   
等式，將式(7.21)平
方相加，整理後可得
2 2 2 2 2
3 5
4
3 5
(7.22)
2
x y zp p p d dc
d d
    
   
再根據 D-H 表角度限制範圍內，從
 4 180 ~ 70   範圍，可得 4
 24 4 4tan 2 1 cos , cos (7.23)A   
其中 tan 2A 是四象限反正切函數。
接下來的運算根據旋轉矩陣的正交性，矩
陣內的元素式(7.6)滿足以下等式
1
0 (7.24)
n n o o a a
n a n o o a
  
  
重新整理式 (7.6) ，等號兩邊同乘上
  13 4 4T    和  
14
5 5T 
  如下式
        1 10 4 3 0 1 25 5 5 4 4 1 1 2 2 3 3
(7.25)
T T T T T T          
即
4 5 4 5 5
4 5 4 5 5 0
3
4 4 5
0
0
(7.26)
0
0 0 0 1 0 0 0 1
x x x x
y y y y
z z z z
n o a p c c s c s
n o a p c s s s c
T
n o a p s c d
  
        
      
讓元素[1,4]、[2,4]與[3,4]在式(7.26)等號分
別相等
5 3 1 2
5 3 1 2
5 3 2
(7.27)
x x
y y
z z
a d p d c s
a d p d s s
a d p d c
  
  
  
其中式(7.27)令 Q，N 和 M，如下式
圖 8.2 為有障礙物時的實驗結果，圖 8.2(a)
為載具偵測到障礙物時的情況，圖 8.2(b)
為障礙物對掃描扇形區間的佔據程度，圖
8.2(c)為權重值直方圖，圖 8.2(d)為最後的
二值化極直方圖，綠色方框為候選航向，
其行走結果如圖 8.2(e)所示，圖中綠色的
軌跡為載具行走軌跡，較密的部分為規避
障礙物時載具修正航向的軌跡。圖 8.3 為
機器人實際避障測試結果。
(a)
(b)
圖 8.1 無障礙物. (a) 障礙物直方圖. (b)
程度直方圖.
(a)
(b)
(c)
(d)
(e)
圖 8.2 機器人障礙物閃避模擬圖(a) 障礙
物直方圖. (b) 程度直方圖. (c) 權重值方
圖. (d) 二值化直方圖 (e) 機器人軌跡.
圖 8.7 多路徑點導航實際與預期路徑比較
如圖 8.6 以及 8.7 所示，此為我們利用
KGPS 所執行的移動式機器人導航的實際
測試結果，而圖 8.7 為其行走路徑比較圖，
藍色實線代表的是我們所預期的路徑，紅
色三角形所代表的是機器人利用 KGPS 執
行定位導航所實際行走的路徑。
而表 8.1 為我們於實驗中所設定的精
確點位以及利用 KGPS 進行導航所做的比
較，我們將由衛星所接收到的經緯度利用
我們所開發的軟體轉換成 ECEF 的 XYZ
座標格式，接著再將此座標格式轉換成機
器人的座標系統格式。
表 8.1 精確座標點及 KGPS 座標點之比較
而圖 8.8 為此實驗的誤差曲線圖，藍色粗
實線為 x 軸之誤差值，紅色實線為 y 軸誤
差值。
圖 8.8 KGPS 誤差曲線圖
8.3 語音辨識系統實驗結果
本研究將 20 組中文餐點語音加入訓練，取
樣頻率採用 16kHz，實驗於三種不同的環
境下，每個環境下測試每組個語音資料 50
次(32050)，總共有 3000 筆的資料。第
一個測試場地約 10m10m 的開放空曠場
地。場地二測試大約在 10m8m 封閉空
間。場地三測試於封閉狹窄的 8m2m 小
空間。最後加入預錄的聲音做整合的測試
結果，一樣在三個不同的環境中每次測試
50 次，並計算平均的辨識率，統整所有菜
單的訓練次數。錯誤! 找不到參照來源。9
為第一個測試的場地辨識率，第一個測試
的場地辨識率為 70.3%，由於在戶外測試
的環境因素影響較多，經常會造成雜訊干
擾以，同時也能明顯觀察到辨識率較低的
問題，錯誤! 找不到參照來源。為第二個
測試場地的辨識率，第二個測試場地的辨
識率為 76.3%，在室內環境中相對較安
靜，但仍然有回音的干擾，導致無法識別，
但相較於室外環境的辨識成功率卻有大幅
的提升。錯誤! 找不到參照來源。11 為第
三個測試場地的辨識率，第三個測試場地
的辨識率為 82.6%，場地三於封閉的小房
間中，無噪音以及回聲的干擾，與先前的
兩個場地相比平均辨識率高了許多。最後
是語音特徵值的收斂範圍，如圖 8.12 為語
音特偵值收斂範圍，設定的門檻誤差值大
約在 10%左右，紅色點為中心值，黑色點
為誤差範圍內的特徵值，綠色點為訓練失
敗或散落的特徵點，而門檻值設定在 10%
的意義在於能夠較快速的完成特徵值統整
及訓練，同時也可對這些散落的特徵值做
類聚的方法，並給定不同的字碼。
(a) (b)
圖8.14 圓型偵測結果 (a)輸入影像，(b)輸
出影像
(a) (b)
圖8.15 圓型餐盤偵測結果 (a)輸入影像，
(b)輸出影像
(a) (b)
圖8.16 橢圓餐盤偵測結果 (a)輸入影像，
(b)輸出影像
(a) (b)
圖8.17 雙視覺影像校正 (a)左邊視覺，
(b)右邊視覺
(a) (b)
圖8.18 雙視覺橢圓餐盤實際偵測結果
(a) 左邊視覺，(b)右邊視覺
圖8.19 雙視覺橢圓餐盤影像處理結果
(a)左邊視覺，(b)右邊視覺
圖8.20 雙視覺橢圓餐盤影像辨識結果
(a)左邊視覺，(b)右邊視覺
表 8.1 特徵點之影像座標
左攝影機 右攝影機
特偵
點
左邊
(pixels)
右邊
(pixels)
左邊
(pixels)
右邊
(pixels)
托盤 (71,160) (310,161) (5,161) (244,160)
碟子 (142,186) (249,186) (70,184) (178,184)
表 8.2 相機座標
托盤 碟子單位
(mm) 左邊點 右邊點 左邊點 右邊點
X 軸 281.1 -145.8 155.4 -32.6
Y 軸 -62.2 -62.2 -106.1 -106.1
Z 軸 533 533 526 526
表 8.3 雙眼視覺測距結果
實際距離
(mm)
估測距離
(mm)
距離誤差
(mm)
托盤 545 533 2.2
碟子 531 526 0.9
實際長度
(mm)
估測長度
(mm)
長度誤差
(mm)
托盤 390 427 -9.4
碟子 203 188 7.3
8.5 機械手臂系統實驗結果
與第二次的特徵值也絕對不一樣，所以必
須要蒐集大量的聲音以便提高辨識率。本
系統使用預錄聲音的方式進行輸出，並且
整合多單詞的測試，在室內的最高平均辨
識率可達到82.6%，其成功率相當高。本
系統能夠為使用者提供一個操作簡單、快
速、低耗能的環境，而我們將此系統應用
於點餐服務機器人上，具有非常好的結
果，同時它也能夠很容易的移植到其他機
器人語音辨識的工作。
而於影像系統部分本研究發展目的是
建構一套即時的雙眼視覺之餐盤偵測系
統，並實現應用於智慧型點餐服務機器人
上，用來偵測餐盤與計算其三維座標，達
到定位效果，並將位置資訊傳送給驅動機
械手臂的電腦。餐盤辨識系統我們結合了
Halíř的直接最小平方法，而由實驗結果可
以知道，本系統可以不需要事先將邊線點
分類，便能將影像中不定數量的橢圓近似
物體偵測出來，並且偵測的速度也比使用
霍氏轉換來的快。同時本系統對雜訊也有
一定的抵抗能力，少許的雜訊干擾不會對
系統偵測的結果造成影響，藉由雙眼影像
視覺系統，使用10×7的黑白棋格校正板，
成功取得攝影機參數，以基礎矩陣找尋對
應點，如此加強了特徵點的精確度，並大
大的提升三維重建時座標資訊的正確率，
最後求出目標物的相機座標，提供機械手
臂控制系統，完成取物動作。機器人視覺
系統可應用的範圍很廣，在影像辨識方
面，利用立體感知來建立特徵條件並且判
斷的方法，已有許多相關的研究，像是手
勢辨識、人臉辨識等，未來可以改良我們
系統的基礎架構，並結合影像辨識與自我
學習的方法，讓系統更精確、更強健。
最後，在雙機械手臂部分，完成逆向
運動學之推導，求得末端效應器座標與角
度的關係式，使用順序控制方式控制雙機
械手臂運動軌跡，得到雙眼視覺系統目標
物之座標結果，進行抓取目標物的行為控
制。
由以上各次系統說明，我們可將以上
三年的研究目標，分五大部分簡要說明做
個結論。 1. 移動式機器人室內定位技術
及避障功能。 2. 戶外定位導航技術及演
算法發展，最佳路徑規劃。3. 語音辨識與
合成技術，信號處理方法，硬體功能的提
升與軟體演算法的開發。 4. 單眼視覺人
臉辨識及追蹤至物件的辨識，最後發展雙
眼視覺辨識系統，達到物件便是與定位功
能，提供雙機械手臂取物之目標。5. 雙機
械手臂設計及製作，推導正向及逆向運動
學，發展最佳化路徑演算法。配合雙眼視
覺辨識系統執行精確地夾取瓶子或端取餐
盤的目的，快速送達至顧客的餐桌上。得
到完整的研究目標，在未來可就這些發展
的現況，再繼續深入研究，提出更精闢的
研究成果，貢獻社會。
參考文獻
[1] X. Yang and M. Moalem, “A Layered 
Goal-Oriented Fuzzy Motion Planning
Strategy for Mobile Robot Navigation”, 
Systems, Man, and Cybernetics, Part B,
IEEE Transactions on Vol. 35, Issue 6,
pp. 1214 - 1224, Dec. 2005.
[2] J. Borenstein and Y. Koren, “The 
Vector Field Histogram –Fast Obstacle
Avoidance for Mobile Robots”, 
Robotics and Automation, IEEE
Transactions on Vol. 7, Issue 3, pp.
278 - 288, June 1991.
[3] I. Ulrich and J. Borenstein, “VFH+: 
Reliable Obstacle Avoidance for Fast
Mobile Robots”, Robotics and 
Automation, 1998. Proceedings. 1998
IEEE International Conference on Vol.
2, pp.1572–1577, May 1998.
[4] I. Ulrich and J. Borenstein, “VFH*: 
Local Obstacle Avoidance with
Look-Ahead Verification”, Robotics 
and Automation, 2000. Proceedings.
ICRA '00. IEEE International
Conference on Vol. 3, pp.2505–2511,
April 2000.
Vision Computing, Vol. 22, No. 12, pp.
983-1005, 2004.
[17] H. Jahn, “Paralel Epipolar Stereo 
Matching”, Proceedings of
International Conference on Pattern
Recognition, Vol. 15, No. 1, pp.
402-405, 2000.
[18] D. Mar and T. Poggio, “Cooperative 
Computation of Stereo Disparity”,
Science, Vol. 194, pp. 283-287, 1976.
[19] H. Kawasaki, and T. Mouri, “Design
and Control of Five-Fingered Haptic
Interface Opposite to Human Hand”,
IEEE Trans. Robotics, Vol. 23, pp.
909–918, 2007.
[20] Deok Hui Song, and Seul Jung,
“Geometrical Analysis of Inverse
Kinematics Solutions and Fuzzy
Control of Humanoid Robot Arm under
Kinematics Constraints”, ICMA 2007.
Int. Conf. Mechatronics and
Automation, pp.1178 - 1183, 2007.
[21] Ma Bojun, Fang Yongchun, and Zhang
Xuebo, “Inverse Kinematics Analysis
for a Mobile Manipulator with
Redundant DOFs”, CCC 2007. Control
Conf. Chinese, pp.118–122, 2007.
[22] E.A. Merchan-Cruz, and A.S. Morris,
“Fuzzy-GA-Based Trajectory Planner
for Robot Manipulators Sharing a
Common Workspace”, Int. J. Robot.
Res., vol. 5, pp. 90–98, 2006
[23] R. Sharma, and M. Gopal, “A Markov
Game-Adaptive Fuzzy Controller for
Robot Manipulators”, IEEE Trans.
Fuzzy Systems, Vol. 16, pp. 171–186,
2008.
[24] M.O. Efe, “Fractional Fuzzy Adaptive
Sliding-Mode Control of a 2-DOF
Direct-Drive Robot Arm”, Part B:
Cybernetics, IEEE Trans. Systems,
Man, and Cybernetics, Vol. 38, pp.
1561–1570, 2008.
[25] H. Lee, S. Chang , D. Yook and Y. Kim
“A Voice Trigger System Using
Keyword and Spraker Recognition for
Mobile Devices”, IEEE Transactions
on Consumer electronics, Vol. 55, pp.
2377-2384, 2010.
[9] Hsiung-Cheng Lin, Chao-Hung Chen, Guo-Shing Huang, Ying-Chu Liu, and Wei-Chung Hsu,
“Development of Humanoid Robot Action Control System Using Independent Microprocessors,” 
IEEE International Symposium on Industrial Electronics (ISIE 2009), pp.1773-1778, Seoul Olympic
Parktel, Seoul, Korea, July 5-8, 2009. (EI)
[10] Guo-Shing Huang, Hsiung-Cheng Lin, and Yu-Long Shen, “Study of the Monitor and Control
System on Meal Service Robot Using a Real-Time Image Detection,” International Conference on 
Service and Interactive Robotics, SIRCon 2009, pp. 1-5, Taipei, Taiwan, August 6-7, 2009.
[11] Guo-Shing Haung, Hsiung-Cheng Lin, and Yi-Hong Chung, “The Navigation of Mobile Robot
Using Fuzzy-Based Vector Field Histogram Method,” International Conference on Service and 
Interactive Robotics, SIRCon 2009, pp. 1-7, Taipei, Taiwan, August 6-7, 2009.
[12] Hsiung-Cheng Lin, Guo-Shing Huang, Chao-Hung Chen, Ying-Chu Liu, Wei-Chung Hsu,
“Development of Simple Microprocessor-based Approach for Humanoid Robot Action Control,” 
International Conference on Service and Interactive Robotics, SIRCon 2009, pp. 1-6, Taipei, Taiwan,
August 6-7, 2009.
[13] Guo-Shing Haung, Jie-Cong Ciou, and Hsiung-Cheng Lin, “Applications of Highly Accurate 
Localization and Navigation to Mobile Robot,” Proceedings of the 2009 IEEE International
Conference on Systems, Man, and Cybernetics, pp.4903-4908, San Antonio, TX, USA, October
11-14, 2009. (EI)
[14] Hsiung-Cheng Lin, Guo-Shing Huang, Ying-Chu Liu, and Wei-Chung Hsu, “Design of
Communication Interface for Intelligent Humanoid Robot,” WCE2009, Proceedings of the 2009
Workshop on Consumer Electronics, II-8-5, pp.599-604, National Chin-Yi University of Technology,
Taiping, Taichung, Taiwan, November 6, 2009.
[15] Guo-Shing Haung, Hsiung-Cheng Lin, and Yi-Hong Chung, “Development of Mobile Robot
Navigation Using Fuzzy-based Vector Field Histogram Method,” Proceedings of 2009
CACS International Automatic Control Conference, SaA04, 00366, pp.1-7, National Taipei
University of Technology, Taipei, Taiwan, Nov. 27-29, 2009.
[16] Guo-Shing Haung, Hsiung-Cheng Lin, and Yu-Long Shen, “Development of a Real-Time
Two- Eye Vision System for Meal Service Robot,” Proceedings of 2009 CACS International
Automatic Control Conference, SaA04, 00370, pp.1-5, National Taipei University of
Technology, Taipei, Taiwan, Nov. 27-29, 2009.
[17] Guo-Shing Haung, Sheng-Jr Yang, Ming-Jie Ju, and Shih-Hung Kao, “Lawn Mower Driving System
Using Microcontroller-based Wheeled Mobile Robot,” ILT 2010, Proceedings of the 5th Intelligent
Living Technology Conference, pp.36-41, Institute of Electronic Engineering, National Chin-Yi
University of Technology, Taiping, Taichung, Taiwan, June 4, 2010. (Accepted the Best Paper
Award)
[18] Hsiung-Cheng Lin, Guo-Shing Huang, C. K. Tung, C. H. Chen, and L. Y. Liu, “Design of
Microprocessor-based Communication Interface and Local-loop Control System for Intelligent
Humanoid Robot,”2010 SICE Annual Conference, pp.3529-3535, The Grand Hotel, Taipei, Taiwan,
August 18-21, 2010. (EI)
[19] Guo-Shing Haung, Hsiung-Cheng Lin, Keng-Chih Lin, and Shih-Hung Kao, “Intelligent
Auto-Saving Energy Robotic Lawn Mower,” 2010 IEEE International Conference on Systems, Man,
and Cybernetics, (SMC 2010), pp.4130-4136, Istanbul, Turkey, October 10-13, 2010. (EI)
[32] Hsiung-Cheng Lin, Vincent C. S. Lee, and Guo-Shing Huang, “DFT-based Recursive Minizing
Algorithm for Power Interharmonics Analysis,”The 37th Annual Conference of the IEEE Industrial
Electronics Society, IECON 2011, pp.1241-1246, Crown Conference Centre, Melbourne, Australia,
7-10 November 2011.
[33] Chung-Liang Chang and Guo-Shing Huang, “A Compressive Sampling Approach to Narrowband
Interference Elimination for GNSS,”Incorporating the International Symposium on GPS & GNSS,
IGNSS 2011, University of New South Wales, Sydney, Australia, 15-17 November 2011.
[34] Guo-Shing Huang, Vincent C. S. Lee, and Yu-Chern Lai, “Motion Control System of Dual Robotic
Arms to Pick up Object for Meal Service Robot,”Proceedings of 2011 International Conference on
Service and Interactive Robots, SIRCon 2011, National Chung Hsing University, Taichung, Taiwan,
November 25-27, 2011.
[35] Guo-Shing Huang, Hsiung-Cheng Lin, and Wen-Yang Yeh, “Integration Technique of Motion and
Navigation Systems for Autonomous Mobile Robot,”Proceedings of 2011 International Conference
on Service and Interactive Robots, SIRCon 2011, National Chung Hsing University, Taichung,
Taiwan, November 25-27, 2011.
[36] Guo-Shing Huang, and Jie-Cong Ciou, 2009 02, “Optimal Route Planning Algorithm of Mobile
Robot,”Far East Journal of Experimental and Theoretical Artificial Intelligence, Vol. 3, Number 1,
pp.39-52, February 2009.
[37] Hsiung-Cheng Lin, Chao-Hung Chen, Guo-Shing Huang, Ying-Chu Liu, and Wei-Chung Hsu
“Design of Communication Interface and Control System for Inteligent Humanoid Robot,”has been
published in Journal of Computer Applications in Engineering Education, pp.1-14, 2010. (SCI)
達到高精準度的機器人導航定位，對於國內外相關的研究有相當大的幫助。本研究計畫
部分成果已發表在中國工程師學刊Journal of The Chinese Institute of Engineers,及各國內
及國際研討會上，並將會把完整成果投至國際期刊(SCI)。本子研究在技術創新上是利
用模糊控制器，發展一套新的機器人避障演算法，且利用高木-管野模糊控制結合等校
直方圖障礙物閃避的觀念，提供可移動式智慧型機器人(本子計畫之展示平台即為點餐
服務機器人，而總計劃之展示平台則為智慧半人型與人共生服務機器人)在定位導航的
應用，提高系統的速度和可靠度。本計畫每年訓練參與之碩士三至四名與大學部專題生
若干名，俾使其分別獲得定位導航機電整合、感測器融合、系統控制、機械機構設計與
控制、語音辨識與回應以及影像辨識及定位等技術之數學分析方法學與單晶片、嵌入式
系統與PC軟硬體等技術之實作經驗，對國內電控技術人才的培育與訓練有相當裨益，
這些人才對提升國家競爭力將有顯著貢獻，所研究產生的國際國內研討會論文及獲得的
專利列於後。
(3) 主要發現及其他相關價值：本計畫所開發的關鍵技術可提昇智慧型機器人系統的定位導
航精度及其智慧，所研發的系統軟硬體建置與相關實務技術，不但有助於現今可移動
式智慧型機器人的定位導航，同時可推廣應用於其他的家庭、教育、旅館服務、戶外
室內娛樂休閒、博物館、甚至市場行銷等領域之服務機器人研發。根據時代雜誌等多
項市場調查顯示可移動式服務機器人產業將會像汽車、個人電腦、手機等產品一樣，
成為個人化產品，也可能是未來機器人的系統IC晶片需求來源。而參與此計畫的同學
們，俾使其分別獲得定位導航機電整合(包括雷射定位導航、雷射環境認知、KGPS定
位導航、超音波避障)、感測器融合、系統控制(各種控制演算法推導及軟體設計)、機
械機構設計與研發製改良、語音辨識與回應(至語音融合)以及影像辨識追蹤及定位和系
統晶片等技術之數學分析方法學與系統晶片、單晶片DSP與PC軟硬體等技術之實作經
驗，對國內電控技術人才的培育與訓練有相當裨益，這些人才對提升國家競爭力將有
顯著貢獻。
報告內容應包括下列各項：
（一）前言 每年由IEEE Systems, Man and Cybernetics學會(SMC)舉辦的2010 IEEE SMC 研討
會是全球各主要國家在系統、人與人工電腦學領域的年度盛會。本次研討會 IEEE SMC 2010
選在土耳其(Turkey)伊斯坦堡(Istanbul) 軍事博物館(Military Museum)舉行，會期由10月10日
至10月13日共四天。此次研討會最後接受投稿之刊登論文共733篇。此次，有來自54個國家
的近千位的學者、專家、工程師與研究生共聚一堂，互相切磋最近發展的系統、人與人工電
腦學理論等領域之嶄新內容，與會者皆受益良多。由於技術會議的場次達110之多(含107場
Technical sessions 與3 poster sessions)，與會者皆無法全程參加所有的小組技術會議，僅能選
取有興趣的會議參加。
（二）會議籌備
2010 IEEE SMC 研討會是由大會主席 (General Chair)-Bogazici University, Dr. Okyay
Kaynak, 議程主席-Dr. Georgi M. Dimirovski，並結合相當多的國際顧問團，獎勵委員會，國
際議程專家學者以及與工作委員以一年的時間籌辦而成的國際性學術會議。參與本次會議的
專題論文之領域計有系統科學與工程、人機系統與仿生科技理論等學術與工業應用領域，共
有約1000篇論文投稿,必須在今年1, 2月間送至大會評審；3~4月份，大會通知各作者論文評審
結果，僅有733篇論文接受推薦入選，且完成註冊。入選者需於今年4~5月間前將所需的最後
文稿以及摘要送至編輯委員會，以利完成e-proceeding論文集與摘要論文集的印刷。接著就是
大會秘書處提供與會者住、宿等相關網路資訊的服務。主辦單位的大會工作也陸續展開，會
期由10月10日至10月13日共 4天。
（三）與會經過
此次出席國際性研討會，能與來自54個國家的學者專家共同系統科學與工程、人機系統
與人工電腦學理論與其應用領域的有關技術，研討現在及未來的技術發展趨勢，對本團團員
之未來研究有直接的助益。以下簡述相關心得。今年大會特別在研討會開始安排一個整天的
Workshops on Monday, October 11, 10:50~15:30.及半天的技術研習會(tutorials)Sunday, October
10, 2010, 14:00~17:00，由10位專家學者教授講習，內容涵蓋Multi-media security systems,
Brain-Machine Interfaces, Challenges in Network Visualization, Simulation-based engineering of
complex systems, Requirements engineering of complex systems, new trend in safety engineering,
risk-based design and evaluation of green hybrid energy supply chains, frequency-time discrete
transforms and their applications in image processing, model a discourse and transform it to your
user interface, combining requirements and interaction design through usage, soft computing for
biometrics applications; a comprehensive overview, new global optimization techniques based on
computational intelligence, intelligent pattern recognition and applications on biometrics in
interactive learning environment, role-based collaboration等研習課題, 提供有興趣於鑽研諸專
題的學者專家相當程度入門基礎及應用背景知識。
研討會在 10 月 11 日上午 8:30 正式登場。本次大會的會議分有 2 個 Plenary Session
9:10~10:30 分別由 3位教授當 Plenary Speakers(包括“Neural Networks: From Toys to Cars to the
Mind”by Dr. Paul J. Werbos, “The Cyborg Experiments”by Dr. Kevin Warwick, “Learning to
Behave in a natural Environment”by Dr. Edgar Koerner)，107 場次發表技術會議（Technical
Sessions）以及 3 場次海報發表會議（Poster Sessions）。
Picture with Dr. Philip Chen in IEEE SMC 2010
IEEE SMC 2010
IEEE SMC 2010
Intelligent Auto-Saving Energy Robotic Lawn
Mower
Guo-Shing Huang Hsiung-Cheng Lin Keng-Chih Lin Shih-Hung Kao＊
Institute of Electronic Engineering, ＊Institute of Mechanical Engineering, National Chin-Yi University of Technology
Taiping, Taichung, Taiwan. 411, R.O.C
hgs@ncut.edu.tw hclin@ncut.edu.tw kenkchih@ms48.hinet.net ＊ kaosihon@gmail.com
表 Y04 8
commercial human-push electric mower. That traction
driven mechanisms are used of the original front-end
configuration that could be linked to pre-mower body
also installed L-bearing plate through the drive modules
linked by the horizontal central axis. Like the tow trailer
movement and activities will not affect the choice of the
original mower height adjustment. The split shift
assembly can easily restore the original hand-push
mower model. To compare before with after
improvements, there are shown in Fig. 2 and Fig. 3.
Fig.2 The Original Lawn Mower.
Fig.3 Initial framework for Intelligent Automatic Energy-Saving
Robotic Lawn Mower.
IV. DRIVE MODULE
Two sets of DC motor with reduced speed
gearbox were mounted on a posed drive
system. Those are two separated motors to
be controlled respectively in order to
achieve the function of turn. 3D Sketch of
basic drive system module is shown in Fig.
4.
Fig.4 3D Sketch of Basic Drive System Module.
The motion model of lawn mower (wheel type robot)
is shown in Fig. 5. We suppose the detecting device
works under an ideal case. Namely the hay mower can
measure the pose information of one's own and goal and
barrier. We make hay mower be just in the front 180°
several amounts of ultrasonic wave detecting devices are
installed in this area. On the examined distance, the
ultrasonic wave detects Ar distance of security collision
as the hay mower. The coordinates of hay mower and
impact point are ),( RR yx and ),( GG yx . The angle
is R and G . The contained angle and the distance
express respectively in RG and GD . In Eq. (1) and Eq.
(2), the included angle RG and distance GD can be
calculated as follows.
RG
RG
RG xx
yy

 1tan (1)
   22 RGRGG yyxxD  (2)
The nearest distance and included angle between the
hay mower and obstacle are OD and RO , respectively.
Similarly, they can be obtained using Eq. (1) and Eq. (2).
The controlled parameters in the model are the speed of
hay mower motion S and the rotating angle θ, where
S(0, 1.0) m/s and θ(-30°, 30°). θis positive when
hay mower turns right, otherwiseθ is negative.
表 Y04 10
Some ultrasonic sensors are installed to detect the
obstacles covering 180-degree range in the front of
mobile robot. The included angle between the obstacle
edge and nearest distance to the hay mower is defined as
3e . It can express as Eq. (5). [1]
O
O
RROe y
x1
3 tan
  (5)
The 3e and OD variables are the input of FLC2.
The output ( LV and RV ) of FLC2 is the speed of left
wheel and right wheel, respectively.
VI. ARM9 CONTROL SYSTEM MODULE
S3C2450 is a 32/16-bit RISC processor with a low
power consumption, and high-performance
characteristics. The main application is addressed in
those areas such as GPS positioning, intelligent guidance
and control applications to provide a common solution.
The most notable features include: update to the
ARM926EJ core, 2D graphics speed-up, the increasing
in low-power mode, the built-in ROM / RAM for
security guidance, and boot low-power audio decoding.
In addition, in order to promote the performance and
adaptability, the characteristics of the surrounding
interfaces have been updated. Such as updating the
Camera I / F, USB Device 2.0 HS, MC / HS-MMC / SD /
SDHC ports, HS-SPI ports and updating the memory, for
example, increasing support DDR2 interface. It is indeed
that S3C2450XH53 is a high performance chip and a
microprocessor of built-in all new solution. This paper is
based on the DMATEK Company ARM9 DMA-2450,
the developed host computer is the main control system
for R & D modules [9] as shown in Fig. 9 and Fig. 10. To
combine the TCM2 electronic compass, the directional
guidance and control functions are performed for the
path planning [10-14]. Fig. 11 shows the system control
flow chart.
TCM2 is built-in three-axis magnetic field sensor
and dual-axis tilt sensor. The output is a compass point
north, and south axis in the horizontal plane of projection
and magnetic north lines is on the ground projection
angle. Due to TCM2 has tilt and pitch angle
compensation, under the tilt or pitch condition the
compass point to projection line is a little change. That
compass pointing is a little effect by the tilt and pitch
[15]. There are the benchmark reference point of heading
and the perspective of the system.
Fig.9 ARM9 - Master Control Development System Module.
Fig.10 Embedded System Block Diagram.
The RS-232 is TCM2 output interface, the output
mode is "19200, n, 8, 1". Data format is $ + C + point +
P + point + R + point + X + field + Y + field + Z +
magnetic + T + temperature + Checksum.
For example:
表 Y04 12
1200 rpm, 30:1 gearbox and the diameter of the driving
wheel is 20 cm. Through the measurement, we can
obtain that the actual moving speed of hay mower is 0 ~
20.9 cm/s. We perform the tests under the barrier free
and obstacles environment respectively.
The robot path with an obstacle is shown in Fig.15.
When the mowing robot detected the obstacle at point a,
it immediately changed the way toward the point b to
avoid the collision. When the Ultrasonic A detected the
closer obstacle at point a, the robot then changed its
direction from point c to e, for details shown in Fig.16.
The point c was the initial moving time and heading
direction of mowing robot. The point d was the starting
action time and heading direction for the obstacle
avoidance. The point e was the operation time and
heading direction for completing obstacle avoidance. For
the actual test, the robot starting point is shown in Fig.17,
corresponding to Fig.156 at the point c with the direction
as 83.5 . The robot path at the actual test without
obstacle is shown in Fig. 18.
The robot path with obstacle avoidance is shown in
Fig.19, corresponding to the point d as 85.4to the point
e as 181.2shown in Fig. 16. The experimental results
are listed in Table 1, Table 2 and shown in Fig. 20.
Fig. 15 Variety of Ultrasonic A with an Obstacle from Points a to b
Fig. 16 Variety of Robot Direction with an Obstacle from Points
c to e
Fig. 17 Actual Test at Starting Location
Fig. 18 The Robot Path without Obstacle at the Actual Test
表 Y04 14
VIII. CONCLUSIONS
Due to the intelligent robots have been set the
user-centered need in daily life, it should be generated
instant interaction between the robot and users. To set up
the computing systems in space can be measured that the
users exist space in all possible circumstances and
respond to user needed.
In this paper an intelligent robot platform has been
guided into the general daily life. In electronics,
mechanical, electrical, communications, automatic
control equipments and other related technology has
been gradually mature and with a highly competitive
advantage. But using energy and resources efficiently
under this principle, also earn the development of the
earth forever and consider the human health. Therefore,
how to integrate the intelligent related industrial
technologies including devices, technique, and system
equipment… etc. in order to promote the utility
efficiency. To establish a set of the mechanism which
consists of healthy, comfortable, and energy-saving, that
can be used to carry out the evaluation and verification.
The performance exhibition of the intelligent living
environment is indeed to establish a basis for intelligent
living environment.
The intelligent auto-saving robotic lawn mower in
the future may be extended to the family and gardening.
The perfect function obtained of product is indeed for
everyone in a perfect life. It will be a challenge to
research and develop a novel product in the future.
ACKNOWLEDGMENT
This research was supported by San Fung Spring Co.,
LTD under the contract No. CY08TCL012 and the
National Science Council of Taiwan, R.O.C under grant
NSC 97-2221-E-167 -018-MY3.
REFERENCES
[1] E. Menegatti, A. Pretto, A. Scarpa, E. Pagello “Omnidirectional
Vision Scan Matching for Robot Localization in Dynamic
Environments,” IEEE Transactions on
Robotics ISSN 1552-3098 Vol. 22, Issue 3, June 2006, Page(s):
523–535.
[2] Ye Cang, “Navigating a Mobile Robot by a Traversability Field
Histogram,” IEEE Transactions on Systems, Man, and Cybernetics,
Part B, Vol. 37, Issue 2, April 2007, Page(s): 361–372.
[3] Ouadah Noureddine, Ourak Lamine, Hamerlain Mustapha and
Boudjema Fares, “Implementation of an Oriented Positioning on a
Car-Like Mobile Robot by Fuzzy Control,”IEEE 32nd Annual
Conference on Industrial Electronics, IECON 2006, November 2006,
Page(s): 4076–4081.
[4] Guo-Shing Huang, Jie-Cong Ciou, “Optimal Route Planning
Algorithm of Mobile Robot,” National Symposium on System 
Science and Engineering, June 2008.
[5] C. C. Chang and K. T. Song, “Environment Prediction for a Mobile
Robot in a Dynamic Environment,” IEEE Transactions on Robot
Automation, Vol. 13, pp. 862–872, Dec. 1997.
[6] Xiaoyu Yang, M. Moallem, R.V. Patel, “A Layered Goal-Oriented
Fuzzy Motion Planning Strategy for Mobile Robot Navigation,” 
IEEE Transactions on Systems, Man, and Cybernetics, Part B,
Volume 35, Issue 6, Dec. 2005 Page(s): 1214-1224.
[7] Ti-Chung Lee, Chi-Yi Tsai, Kai-Tai Song, “Fast Parking Control of 
Mobile Robots: A Motion Planning Approach With Experimental
Validation,” IEEE Transactions on Control Systems Technology, Vol.
12, Issue 5, Sept. 2004, Page(s): 661–676.
[8] Guo-Shing Huang, Shuo-Cheng Lee, and Meng-Wei Huang, 2007
11, “A Study of Fuzzy Speed Control in BLDC Motor,” 2007 CACS 
International Automatic Control Conference, pp.562-566, National
Chung Hsing University, Nov. 9-11, 2007.
[9] Xingwu Chen, Xinhua Jiang, Lei Wang, “Development on ARM9
System-on-chip Embedded Sensor Node for Urban Intelligent
Transportation System” Industrial Electronics, 2006 IEEE
International Symposium on, Volume 4, 9-13 July 2006 Page(s):
3270 - 3275 Digital Object Identifier 10.1109/ISIE.2006.296141
[10] Ming-Yuan Shieh, Wei-De Wu, “The Design and Implement of
the Robot with the Self-Protection Function,” Southern Taiwan 
University of Technology, Department of Electrical Engineering,
Tainan, Taiwan, November 2005.
[11] T. Fraichard, P. Garnier, “Fuzzy Control to Drive Carlike
Vehicles,” Robotics and Autonomous Systems, Vol. 34, No. 1, pp.
1-22, 2001.
[12] A. Scheuer, Th. Fraichard, “Planning Continuous Curvature Paths 
for Car-Like Robots,” In Proceedings of the 1996 International
Conference on Intelligent Robots and Systems, Vol. 3, pp.
1304-1311, Osaka, Japan.
[13] T.H. Li, S.J. Chang, and Y.X. Chen, “Implementation of
Human-like Driving Skills by Autonomous Fuzzy Behavior Control
on an FPGA-based Car-Like Mobile Robot,” IEEE Transactions on
Industrial Electronics, Vol. 50, No. 5, pp. 867-880, October 2005.
[14] W. Gueaieb, S. Miah, “An Inteligent Mobile Robot Navigation 
Technique Using RFID Technology,” Instrumentation and 
Measurement, IEEE Transactions on Vol. 57, Issue 9, Sept. 2008
Page(s): 1908–1917.
[15] Jiancheng Yu, Aiqun Zhang, and Xiaohui Wang, “Design of
Integrated Navigation System for Autonomous Underwater Robotic”
Intelligent Control and Automation, 2004. WCICA 2004. Fifth
World Congress on, Volume 6, 15-19 June 2004 Page(s): 4917 -
4921 Vol.6, Digital Object Identifier 10.1109/WCICA.2004.1343647
97 年度專題研究計畫研究成果彙整表 
計畫主持人：黃國興 計畫編號：97-2221-E-167-018-MY3 
計畫名稱：智慧半人型與人共生服務機器人之研製--子計畫三：先進定位導航技術 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 0%  
研究報告/技術報告 3 3 100%  
研討會論文 13 13 100% 
篇 
 
論文著作 
專書 0 1 50%  編寫中 
申請中件數 4 4 100%  專利 已獲得件數 10 10 100% 件  
件數 0 0 0% 件  
技術移轉 
權利金 0 0 0% 千元  
碩士生 12 8 100%  
博士生 0 0 0%  
博士後研究員 0 0 0%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 0% 
人次 
 
期刊論文 2 4 50% 2 篇國際期刊論文投稿審查中 
研究報告/技術報告 0 0 0%  
研討會論文 22 22 100% 
篇 
 
論文著作 
專書 0 0 0% 章/本  
申請中件數 0 0 0%  專利 已獲得件數 0 0 0% 件  
件數 0 0 0% 件  
技術移轉 
權利金 0 0 0% 千元  
碩士生 0 0 100%  
博士生 0 0 0%  
博士後研究員 0 0 0%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 0% 
人次 
 
國科會補助專題研究計畫成果報告自評表 
請就研究內容與原計畫相符程度、達成預期目標情況、研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）、是否適
合在學術期刊發表或申請專利、主要發現或其他有關價值等，作一綜合評估。
1. 請就研究內容與原計畫相符程度、達成預期目標情況作一綜合評估 
■達成目標 
□未達成目標（請說明，以 100 字為限） 
□實驗失敗 
□因故實驗中斷 
□其他原因 
說明： 
2. 研究成果在學術期刊發表或申請專利等情形： 
論文：■已發表 □未發表之文稿 □撰寫中 □無 
專利：□已獲得 ■申請中 □無 
技轉：□已技轉 ■洽談中 □無 
其他：（以 100 字為限） 
第一年研究計畫主要目的是利用現有已開發的即時動態差分式全球定位系統安置於可移
動式智慧型機器人上。第二年計劃主要建立一新型障礙物規避演算法即 F-VFH(Fuzzy based 
Vector Field Histogram Method)，即點餐服務機器人機構的設計與研製，並著重於機器人
於規避障礙物時的效率。第三年研究計畫主要目的是研製各具五個自由度的雙機械手臂，結
合了以雙眼之影像視覺系統的餐盤辨識系統，夾取瓶子或端取餐盤，送菜為顧客服務。目前
有發表國際研討會論文及期刊論文，並申請發明專利中。 
3. 請依學術成就、技術創新、社會影響等方面，評估研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）（以
500 字為限） 
由於可移動式智慧型機器人之應用範圍相當廣泛，且這些機器人大部分都需要有定位導航
的功能，由於 KGPS 在許多工程測量，地理資訊系統及近域差分精確導航等方面有廣泛的
應用最主要的理由是其定位精度達到公分級。目前將 GPS 導航定位系統安置在機器人上作
精確定位，國內外論文不多，最主要的原因是機器人的定位精確度一般要在公分級，而 GPS
定位多在幾公尺至十幾公尺，很難應用在機器人上執行高精密定位，因此這方面的研究，
發表的論文就相對地少，而本研究計畫是將以上所述的載具，即可移動式智慧型機器人，
當他走到戶外時，就直接由 KGPS 系統執行高精確度公分級的定位導航計算，利用現有的
KGPS 基站設備，兩套載波相位 GPS 接收器，兩套無線發射接收機(Modem)，DSP 微計算機
就可以解算出高精確度的定位功能。目前尚未有使用 KGPS 定位技術應用在可移動式智慧
型機器人作高精確定位導航的範例因此本計畫第一年的研究主題的最後實驗結果是值得
鼓舞的。換言之，本計畫就針對高精密公分級定位的 GPS 載波相位量測應用在此可移動式
智慧型機器人，當他走出室外時切換成 KGPS 導航，使機器人無論是在室內或戶外，均能
得到高精度定位導航。這套已發展好的導航定位系統，接下來研究應用於各種室內/戶外
