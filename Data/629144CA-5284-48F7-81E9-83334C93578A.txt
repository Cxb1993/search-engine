false failure (i.e., x is within the specification 
limits and y is outside the specification 
limits).  The β  risk is the probability of 
passing an out-of-specification item, which is 
also called a missed fault (i.e., x is outside 
the specification limits and y is within the 
specification limits). The magnitude of these 
risks helps determine the impact of the 
measurement error and whether or not the 
measurement system requires capability 
upgrade. Easterling et al.  provide an 
in-depth discussion of risks associated with 
misclassifying items due to measurement 
variability. Doganaksoy  presents a case 
study to assess the risks associated with 
misclassifying items due to measurement 
variability to the case of multiple sources of 
product variability. 
4
5
The relatively high values of the α  
and β  risks associated with measurement 
error might suggest that measurement 
capability needs to be further improved (i.e., 
reduce the variance of measurement error). A 
common approach to control the α  and β  
risks is to set test limits that are different 
from specification limits (i.e., an item failing 
to meet the test limits is rejected even if it 
meets the specification limits). Such test 
limits are known as guard bands.  
Engineers are often interested in 
constructing a confidence interval of theα  
and β  risks to provide a range for the 
measurement system error. The accuracy of 
the confidence intervals using the Bootstrap 
method is studied by using simulation 
experiments. In section 2, different methods 
of computing the α  and β  risks are 
described. The strategy of implementing a 
simulation study is presented in section 3, 
and the simulation results are demonstrated 
in section 4. The application of the proposed 
method to a wafer by an atomic force 
microscope is provided in section 5. Finally, 
the conclusion of this study is given in 
section 6. 
TYPE- I and TYPE- II ERRORS 
Let us suppose that we have a random 
variable X that represents the true (unknown) 
value for some test parameter of a part or 
unit of product. Suppose that we have a 
random variable Y that represents the 
measured value for the same test parameter. 
Then, we define the measured value of the 
parameter to the true value for the parameter 
as MXY += . We can assume that X and M 
are normally distributed and independent to 
each other. That is, we have ( )2,~ xNX σμ  
and ( )2,0~ MNM σ . This implies that ( )22,~ MxNY σσμ + . If we suppose that the 
two random variables X and Y are 
independent, then we have  α [ ]USLXLSLwhenUSLYorLSLYP ≤≤><= ,
 
[ ] [ ]{ } dxxfUSLYPLSLYPUSL
LSL
>+<= ∫ ( )  
( )∫ ⎭⎬
⎫
⎩⎨
⎧
⎥⎦
⎤⎢⎣
⎡ −>+⎥⎦
⎤⎢⎣
⎡ −<=
USL
LSL MM
dxxfxUSLZPxLSLZP σσ
 
( )∫ ⎭⎬
⎫
⎩⎨
⎧
⎥⎦
⎤⎢⎣
⎡ −Φ−+⎥⎦
⎤⎢⎣
⎡ −Φ=
USL
LSL MM
dxxfxUSLxLSL σσ 1  
( ) ( )∫ ∫ ⎥⎥⎦
⎤
⎢⎢⎣
⎡
⎭⎬
⎫
⎩⎨
⎧
⎥⎦
⎤⎢⎣
⎡ −Φ−⎥⎦
⎤⎢⎣
⎡ −Φ−=
USL
LSL
USL
LSL MM
dxxfxLSLxUSLdxxf σσ
 
and 
β [ ]USLXorLSLXwhenUSLYLSLP ><≤≤= ,
( )dxxfxUSLZxLSLPLSL
MM
∫
∞− ⎭⎬
⎫
⎩⎨
⎧
⎥⎦
⎤⎢⎣
⎡ −≤≤−= σσ
( )dxxfxUSLZxLSLP
USL MM
∫∞ ⎭⎬
⎫
⎩⎨
⎧
⎥⎦
⎤⎢⎣
⎡ −≤≤−+ σσ  
( )dxxfxLSLxUSLLSL
MM
∫
∞− ⎭⎬
⎫
⎩⎨
⎧
⎥⎦
⎤⎢⎣
⎡ −Φ−⎥⎦
⎤⎢⎣
⎡ −Φ= σσ
( )dxxfxLSLxUSL
USL MM
∫∞ ⎭⎬
⎫
⎩⎨
⎧
⎥⎦
⎤⎢⎣
⎡ −Φ−⎥⎦
⎤⎢⎣
⎡ −Φ+ σσ  
However, the random variables Y and X are 
jointly distributed as bivariate normal with 
 2
The above two approaches are based on 
the approximation formula. In fact, many 
softwares, such as SAS and IMSL, can be 
used to obtain the integral equation. A simple 
program using IMSL subroutine  was 
written to obtain the type I and type II errors. 
Two examples are used to compare the 
difference using dissimilar methods to obtain 
the values of the type-I and type-II errors. 
10
Example 1: Consider the data from 
Engel and De Vries .  The specification 
limits are USL=4400 and LSL=3600, the 
process mean isμ=3760, and the process 
deviation is 
7
pσ =100. Suppose the standard 
deviation of the gauge is gaugeσ =50, and the 
correlation coefficient is ρ =0.8945。Table 1 
shows the values of the type-I and type-II 
errors by the Engel and De Vries method, the 
Mee and Owen method, and IMSL 
subroutine. 
***Put Table 1 about here*** 
Example 2: Consider the data from 
Mader et al. 9 .  The specification limits are 
USL=42 and LSL=30, the process mean isμ
=35.2, and the process deviation is pσ =4.1. 
Suppose the standard deviation of the gauge 
is gaugeσ =0.7746, and the correlation 
coefficient is ρ =0.9826。Table 2 shows the 
values of the type-I and type-II errors by the 
Engel and DeVries method, the Mee and 
Owen’s method, and IMSL subroutine. 
***Put Table 2 about here*** 
 From the above results of the two 
examples, we found that the values of the 
type-I and type-II errors by Engel and 
DeVries’s method were underestimated. On 
the other hand, Mee and Owen’s method was 
overestimated. Since the results by the IMSL 
subroutine are more accurate, we recommend 
that this as the best approach to obtain the 
values of the type-I and type-II errors. 
BOOTSTRAP APPROACH 
 Efron introduced the Bootstrap 
approach in 1979 as a computer-based 
method for estimating the standard error of a 
summary statistic. The Bootstrap estimate of 
standard error requires no theoretical 
calculations and is available no matter how 
mathematically complicated the summary 
statistic may be. The standard method and 
the percentile method are introduced in 
Efron . Efron  introduced the 
biased-corrected percentile method in 1981. 
There are many different techniques for 
constructing confidence intervals using 
Bootstrap. An overview of this topic in 
Bootstrap confidence intervals can be found 
in Efron and Tibshirani . A Bootstrap 
sample  is obtained 
by a random sampling of n times, with 
replacement, from the original data point 
. Let 
11 12
13
),,,((*) **2
*
1 nyyyY K=
nyyy ,,, 21 K )(iYμ  and  be the 
mean and standard deviation of the 
)(iYS
BiiY ,,2,1),( K= , where  is the ith 
Bootstrap sample data set and B is the 
number of Bootstrap samples. Then, we have 
)(iY
,1
)(
B
B
i
iY
bootstrap
∑
==
μ
μ  and 
( )
1
)(
1
2
−
−
=
∑
=
B
iY
S
B
i
bootstrap
bootstrap
μ
. Therefore, 
an approximate (1- α )100% confidence 
interval for Yμ  by the standard method is 
bootstrapbootstrap S2/αμ Ζ±  
where 2/αΖ  is the upper 2/α  quantile of 
the standard normal distribution. 
Efron  provides an accelerated 
bias-corrected percentile ( ) method to 
improve the bias-corrected percentile method. 
The first two steps are the same as the 
bias-corrected percentile method. In the third 
step, accelerated corrected percentile 
endpoints of the standard normal distribution 
are computed as 
14
aBC
 4
and type-II errors, the average of the 
lower bound and the upper bound of the 
confidence intervals, the average width of 
the intervals, and the coverage 
proportion. 
From the above simulation study, we also 
consider the effect of the measurement error 
such as  and 
, the effect of the 
process mean such as 
)625,0(~ 2 =grrN σε
)10000,0(~ 2 =grrN σε
3710=pμ  and 
3810=pμ , and the effect of the process 
deviation such as  and 
. The simulation programs were 
implemented by C++ on a PC. The frequency 
of coverage for the limit is a binomial 
random variable with p=0.95 and N=1000. 
Thus a 95% confidence interval for the 
coverage proportion is 
25002 =pσ
400002 =pσ
1000/05.0*95.096.195.0 ± . Hence, the 
limits from 0.9365 to 0.9635 are the critical 
values for a statistical test at the 95% 
confidence level of the hypothesis that 
p-value=0.95. 
THE ANALYSIS OF SIMULATION 
RESULTS 
 From the procedures in the previous 
section, we selected three sample sizes (20, 
50 and 100), 1000 as the number of 
replications, and 95% as the confidence 
coefficient.  Bootstrap confidence intervals 
were constructed from the 2,000 Bootstrap 
resample data per each original sample. 
Confidence coefficients of 90% and 99% 
were also investigated. However, the results 
for these were similar to the results for 95% 
and are not reported here. The simulation 
results for all scenarios (confidence level 
=95%) are shown on Tables 3-6.  
 For the type-I error, we can find the 
following conclusions: 
(1) The sample size has an influence in the 
simulation. The simulated confidence 
coefficient is close to the nominal 
confidence coefficient for the sample size 
(=100). When the sample size is greater 
than 50, the coverage proportions for all 
scenarios are within the confidence 
interval at 95% confidence level. Also, 
the estimated αˆ  is close to the true 
value when the sample is increasing. 
(2) The true value of .the type-I error is 
increasing when the measurement error is 
increasing. The average width of the 
confidence interval is affected by the 
measurement error.  
(3) Under the same measurement error, the 
average width of the confidence interval 
is decreasing when the sample size is 
increasing. 
(4) The process mean and the process 
deviation have an influence on the type-I 
error and the average width of the 
confidence interval. 
For the type-II error, the simulation 
results are similar to the results of the type-I 
error. If we consider the simulated 
confidence coefficient, the Bootstrap method 
has a good simulated confidence coefficient 
in this study. Also, the values of the type-I 
and type-II errors are affected by the 
measurement error, the process mean, and 
the process deviation. Thus, the Bootstrap 
method is a valuable approach in 
constructing the confidence interval for the 
type-I and type-II errors. 
CASE STUDIES 
 In order to demonstrate the application 
of the proposed methodology, let use 
consider two cases that are collected by the 
Atomic Force Microscope (AFM) 
measurement equipment. Figure 1 depicts the 
measurement process to obtain the line width 
of the testing product that is a wafer. Each 
wafer is measured by nine different positions 
with three replications. The two datasets are 
shown in Table 7. Using the 
Anderson-Darling test statistics, we have the 
p-values as 0.407 and 0.554. That is, these 
two datasets are normal distributions. Then, 
using the Bootstrap method with 2000 
replications, the 95% confidence interval of 
the type-I and type-II errors can be 
determined. Table 8 shows the estimated 
 6
