 1
行政院國家科學委員會專題研究計畫成果報告 
題目：基於支撐向量機之細胞神經網路強韌樣板參數設計 
以實踐任一給定之布林函數 
SVM-based Robust CNN Templates Design Implementing 
 an Arbitrary Boolean Function 
計畫編號：94-2213-E-110-036- 
執行期限：94 年 8 月 1 日至 95 年 7 月 31 日 
主持人：謝哲光   國立中山大學電機工程學系 
計畫參與人員：吳旭焜、陳保戎、徐志廷、招沛宏 
 
一、前言 
Cellular neural networks (CNNs), first introduced by 
Chua and Yang [1]-[2], are large scale nonlinear circuits 
composed of locally connected cells.  CNN has a 
tremendous variety of applications in the fields of 
dynamic systems and signal processing.  Among the 
applications, image processing is of great interest since 
the structures of template operation of CNN are 
intimately related.  Examples of CNN image processing 
are edge detection, mathematical morphology, and noise 
filtering [3]-[5].  Advanced applications for image 
processing using CNN are medical image processing and 
digital content analysis [6]-[7]. 
 
The class of CNNs without feedback interconnections 
from neighboring cells, namely the uncoupled CNNs, 
plays an important role in the analysis of the dynamic 
behavior.  Furthermore, the simplicity of the uncoupled 
CNN circuits renders it attractive in VLSI 
implementation.  The binary steady state output in 
terms of the binary input of the uncoupled CNN can be 
represented by a linearly separable Boolean function.  
Most of the elementary applications can be derived and 
analyzed via Boolean functions [8]-[10], which is 
directly related to the CNN template parameters.  More 
complicated tasks can be accomplished by a sequence of 
uncoupled CNN operations.  The architecture of CNN 
provides both parallel analog processing and local 
interactions between cells characterizing cellular 
automata which is intrinsically suitable for VLSI 
implementations.  A typical implementation is the 
realization of “analogic” programs in the CNN universal 
machine (CNN-UM) framework [11], so that a fully 
parallel and high speed device of evolutional 
computation can be developed [11]-[12]. 
 
One of the crucial issues of VLSI CNN chip design is 
the robustness of a template set for CNN [13].  Analog 
VLSI implementations of CNN have numerous 
limitations that need to be taken into account in the 
theory of CNN in order to guarantee correct and efficient 
operations.  Template parameters can only be realized 
with a precision of typically 5~10% of the nominal 
values and usually only a discrete set of possible values 
is available [14]. 
 
The problem of template design or template learning is 
a key topic in CNN research.  The methods investigated 
since the inception of the CNN may be classified as 
analytical methods, local learning algorithms, and global 
learning algorithms [15]-[17].  But these algorithms 
were not studied concentrating the importance of 
robustness of the CNN template.  It is interesting to find 
that the geometric margin of a linear classifier with 
respect to a training data set, a notion borrowed from the 
machine learning theory, can conveniently be used to 
define the robustness of an uncoupled CNN 
implementing a linearly separable Boolean function.  
Consequently, the so-called maximal margin classifiers 
can be devised via support vector machines (SVMs) to 
provide the most robust template design for uncoupled 
CNNs implementing linearly separable Boolean 
functions. 
 
SVM is a learning system which was first introduced 
by Vapnik and coworkers in 1992 [18].  A unique 
feature of the SVM is that the final discriminant function 
for classification problem or the predictive function for 
regression problem can be expanded on a small subset of 
training data, which is referred to as support vectors 
[19]-[20].  In the meanwhile, the maximum margin of 
the optimal separating hyperplane to the nearest vertices 
can be computed directly by a neat formula.  The 
training algorithm of the SVM to obtain maximal margin 
design for uncoupled CNN template design can be 
implemented via sequential minimal optimization (SMO) 
algorithm [21] with some modification, which provides 
analytical formulae and efficient convergence [22].   
 
For an arbitrarily given Boolean function, the CFC 
decomposition method proposed by Crounse, Fung, and 
Chua [23], can be used to find a sequence of uncoupled 
CNNs implementing the given Boolean function.  In 
CFC method, the entries of the control templates of the 
required uncoupled CNNs are restricted to the set of 
small magnitude, and the thresholds are some integers.  
The conjunctions of the sequence of CNNs are 
traditional logic operators.  The method is a brute force 
one, yet it is simple and is easy to be implemented.  In 
our view, the most important thing in the CFC approach 
is that the uncoupled CNNs they considered are all 
robust in the sense of geometric margins, though this has 
 3
2. Linear classification 
Let nX ℜ⊆  and { }1,1: −=Y .  Suppose we are given 
the training set 
( ){ } YXyxS liii ×⊆= =1,: . (5) 
Note again that ix  in (5) is different from the CNN state 
ijx .  The training set S is said to be linearly separable if 
there is a hyperplane of the form 
( ) 0,:, =+= bxwxf bw , nw ℜ∈ , ℜ∈b , 
that correctly classifies the training data.  By treating 
the truth table of a given Boolean function as the training 
dataset with 512=l  training data, this training set must 
be linearly separable in order for the Boolean function to 
be realizable by an uncoupled CNN.  
 
For a given ( )bw, , where nw ℜ∈  and ℜ∈b , define 
( ) bxwxf bw += ,:, ,  
( ) ( ) bwxwwxfwxg bwbw 11,1, ,: −−− +== , nx ℜ∈ . 
Note that the distance of a given point nx ℜ∈'  to the 
hyperplane defined by ( ) 0, =xf bw , or equivalently 
( ) 0, =xg bw , is given by ( )', xg bw .  The following 
definitions are quoted from [20].  
 
The functional margin ( )bwS ,µ  and the geometric 
margin ( )bwS ,η  of ( )bw,  with respect to the training 
set S are defined by, respectively,  
( ) [ ] ( )ibwiliiiliS xfybxwybw ,11 min,min:, ⋅=+⋅= ==µ ,  
( ) ⎥⎦⎤⎢⎣⎡ +⋅= −−= bwxwwybw ii
l
iS
11
1
,min:,η  
( )ibwili xgy ,1min ⋅= = . 
The margin Sγ  of a training set S is defined to be the 
maximum geometric margin over all hyperplanes, i.e., 
( )[ ]ibwilibwS xgy ,1, minmax: ⋅= =γ  
⎥⎦
⎤⎢⎣
⎡ ⎟⎠
⎞⎜⎝
⎛ +⋅= −−= bwxwwy ii
l
ibw
11
1,
,minmax . 
A hyperplane realizing this maximum is called a 
maximal margin hyperplane or optimal hyperplane.  
Note that the margin of a linearly separable training set is 
positive. 
 
Note that in our template design if we choose 100 <a , 
in order for correct binary output, the gray-scale output 
values must be avoided.  This implies that the designed 
linear classifier must have a functional margin greater 
than or equal to 001 a− .  This can easily be solved by 
scaling the weight vector and the bias by the same 
constant, which results in the decision hyperplane and 
the margin unaltered. 
 
3. SVM for optimal CNN template design 
Given a Boolean function of nine variables, we have 
512=l  training data for a binary separation problem.  
To be realizable by an uncoupled CNN, the training set 
must be linearly separable.  To obtain the maximum 
robustness for the input template design, we seek the 
maximum margin for the training data.   
 
Define 
{ }1:: =∈=+ iS yliI , { }1:: −=∈=− jS yljI . 
It is fairly easy to prove the following fact.  Suppose we 
are given a non-trivial linearly separable training set S.  
Then the following statements are equivalent: 
(a) The margin of S is Sγ . 
(b) There exist nw ℜ∈* , 1* =w , ℜ∈*b , and 
0>Sγ  such that [ ] 0**, >≥+⋅ Sii bxwy γ  for all li∈ , 
Si bxw γ=+ **, *  for some +∈ SIi , 
Sj bxw γ−=+ **, *  for some −∈ SIj . 
(c) There exist nw ℜ∈0  and ℜ∈0b , with 
0: 10 >= −wSγ , such that [ ] 01, 00 >≥+⋅ bxwy ii  for all li∈ , 
1, 0
*
0 =+ bxw i  for some +∈ SIi , 
1, 0
*
0 −=+ bxw j  for some −∈ SIj . 
The functional margin of hyperplane in (c) with respect 
to the training set S becomes 1.  Such a hyperplane is 
called a canonical hyperplane. 
 
From the preceding fact, for a given non-trivial 
linearly separable training set S, maximization of the 
margin of S is equivalent to minimizing the Euclidean 
norms of the weight vector w of canonical hyperplenes.  
Thus consider the following primal optimization 
problem: 
(P)  minimize wwT12−  
subject to [ ] 1, ≥+⋅ bxwy ii  for all li∈ . 
Note that the problem (P) is a standard quadratic convex 
program. 
 
Suppose ( )**,bw  solves the (primal) optimization 
problem (P).  Then the maximal margin hyperplane is 
given by ( ) 0**,* =+= bxwxf  with margin 
1* −= wSγ . 
 
The Lagrangian of problem (P) is given by 
( ) ( )∑
=
− −+−=
l
i
ii
T
ii
T byxwyzwwzbwL
1
1 12:,, , 
where [ ] lTlzzz ℜ∈= L1:  is the vector of Lagrange 
multipliers.  Maximization of the Lagrangian leads to 
the following dual optimization problem: 
(D)  maximize ∑∑∑
= =
−
=
−
l
i
l
j
jijiji
l
i
i xxyyzzz
1 1
1
1
,2  
subject to 0
1
=∑
=
l
i
ii yz  and 0≥iz  for all li∈ . 
Note that the problem (D) is a standard quadratic 
concave program. 
 
 5
 Step 3: If Ff k =)( , then stop, else jump to Step 2. 
 
Fig. 1. Flow chart for modified algorithm. 
 
四、文獻探討 
The literature survey has been done in section 1 and 
will be not be repeated here. 
 
五、結果與討論 
In this section, two illustrative examples are provided. 
One is the famous example of “Game of Life”, and the 
other is a Boolean function generated by an ugly 
uncoupled CNN. We wish to point out that when we 
search in the Ω  and L, there may be more than one 
solution matching the algorithm. When this situation 
happens, we choose the solution we first meet. The 
program is implemented using Visual C++ 6.0 running 
on Microsoft Windows XP, Pentium IV 2.8 GHz 
platform. In our simulations, one needs about 5 seconds 
to find the first ballterm and 22 seconds for each 
consecutive ballterm. 
 
Example 1: Game of life 
The Boolean function, which is not linearly separable, 
is generated from the following local rules: 
(a) If there are two neighbors whose state values are 1, 
then set the state value to 1. 
(b) If there are three neighbors whose state values are 1, 
then retain the state value. 
(c) For situations apart from (a) and (b), set the state 
value to -1. 
The algorithm in Fig. 1 results in just two terms 
1),1,1,1,1,0,1,1,1,1()0( −−−−−−−−−= bb , dist = 46; 
4),1,1,1,1,1,1,1,1,1()1( −−−−−−−−−−= bb , 2)1( SN=Θ , dist=0. 
 
Example 2: 
The Boolean function is generated by the following 
uncoupled CNN: 
000
010
000
=A , 
26209
25824
231930
=B , 37=z . 
The results are shown as follows: 
2),1,1,0,1,0,1,1,1,1()0( ++++++++= bb ,dist = 29; 
3),1,1,1,1,1,1,1,0,1()1( −−−−−−−−−= bb , 2)1( SN=Θ ,dist=18; 
3),1,0,1,1,1,1,1,1,1()2( −−−−−−−−−= bb , 2)2( SN=Θ ,dist=14; 
3),1,0,1,1,0,1,1,0,1()3( −−−−−−−= bb , 2)3( SN=Θ ,dist=11; 
5),0,1,1,0,1,0,1,1,1()4( +−++++−= bb , 11)4( SN=Θ ,dist= 9; 
3),1,0,0,1,1,1,1,0,1()5( −−−−−−−= bb , 2)5( SN=Θ ,dist =7; 
2),1,1,1,0,0,0,0,1,1()6( +−−−−−= bb , 11)6( SN=Θ ,dist = 5; 
4),1,1,1,1,1,0,0,1,1()7( −−−−−−−−= bb , 2)7( SN=Θ ,dist=4; 
3),0,1,0,0,1,0,0,1,1()8( +−−−−= bb , 11)8( SN=Θ , dist=3; 
1),1,0,0,1,0,0,0,1,1()9( +−−−−= bb , 11)9( SN=Θ , dist=2; 
5),0,1,1,0,1,1,1,0,1()10( −−−−−−−= bb , 2)10( SN=Θ ,dist=1; 
2),0,0,0,0,0,1,1,0,1()11( +−−−= bb , 11)11( SN=Θ ,dist=0. 
 
In this project, we have proposed a modified algorithm 
to find a sequence of robust uncoupled CNNs 
implementing the given Boolean functions.  In a 
continuing research [24], the template values are not 
restricted to { }0,1± , but can be any values in 
{ }0,1,2 ±±  or { }0,1,2,3 ±±± . 
 
參考文獻 
[1] L. O. Chua and L. Yang, “Cellular neural networks: 
theory,” IEEE Transactions on Circuits and Systems, 
vol. 35, pp. 1257-1272, Oct. 1988. 
[2] L. O. Chua and L. Yang, “Cellular neural networks: 
applications,” IEEE Transactions on Circuits and 
Systems, vol. 35, pp. 1273-1290, Oct. 1988. 
[3] I. N. Aizenberg, N. N. Aizenberg, and J. Vandewalle, 
“Precise edge detection: representation by boolean 
functions, implementations on the CNN,” in Proc. 
IEEE International Workshop on Cellular Neural 
Networks and Their Applications, London, 1998, pp. 
301-306. 
[4] I. Szatmári, A. Schultz, C. Rekeczky, T. Kozek, T. 
Roska, and L. O. Chua, “Morphology and autowave 
metric on CNN applied to bubble-debris 
classification,” IEEE Transactions on Neural 
Networks, vol. 11, no. 6, pp. 1385-1393, Nov. 2000. 
[5] I. N. Aizenberg, “Processing of noisy and 
small-detailed gray-scale images using cellular 
neural networks,” Journal of Electronic Imaging, 
vol. 6, no. 3, pp. 272-285, July 1997. 
[6] G. Liszka, T. Roska, Á. Zarándy, J. Hegyesi, L. Kék, 
and C. Rekeczky, “Mammogram analysis using 
CNN algorithms,” in Proc. SPIE Medical Imaging, 
San Diego, 1995, vol. 2434, pp. 461-470. 
[7] L. Czúni and T. Szirányi, “Motion segmentation and 
tracking optimization with edge relaxation in the 
cellular nonlinear network architecture,” in Proc. 
