2 
行政院國家科學委員會專題研究計畫成果報告 
建立以動作為基礎的人與家用機器人互動系統(II)  
Action-Based Human-Robot Interaction System (II) 
計 畫 編 號：NSC 98-2221-E-025 -001 - 
執 行 期 限：98 年 08 月 01 日 至 99 年 07 月 31 日 
主 持 人：游曉貞   國立臺中技術學院多媒體設計系 
共同主持人：鄧怡莘   國立交通大學 應用藝術研究 
計畫參與人員：陳佳吟、程玉美、羅慧如、施成憲、陳怡勳  
 國立臺中技術學院多媒體設計系 
一、中文摘要 
隨著機器人開發技術的日趨完善與普及，
機器人產品開發目標已逐漸從國防與產業應
用，朝向居家服務的方向邁進。隨著坊間強調
「體感」與「動作指令」的產品備受歡迎，本
研究認為「肢體動作」不僅可以有效地作為機
器人人機互動 (HRI)的溝通方式，更能將人際
溝通的脈絡擴展至機器人產品的互動介面之
上。因此，本研究接續第一年動作與指令間的
語意關連之研究，著重於解析機器人動作、及
動作元素與語意(指令)關連性的探索，主要利
用拉邦動作分析(LMA)理論與感性工學為基礎，
透過動作相關的語彙搜集、群聚分析、實驗設
計、並將實驗結果進行分析等，來解析使用者
在一般的居家情境下與機器人互動時，運用動
作與智慧型系統互動時，使用者對其肢體動作
感受到的語意或感性訊息之關連性。並提出運
用此一「動作-語意」關係模式的未來 HRI 設
計的動作建議。 
 
關鍵詞：家用機器人，互動設計，肢體動作，
感性工學，肢拉邦動作分析 
Abstract 
Statics indicate that domestic robots for 
household chores, entertainment, or other social 
purposes will become a common scene in our 
future life. To cope with the challenge of robot 
invasion, this study proposes a systematic 
approach to develop an Action-based 
Human-Robot Interaction (HRI) System for a 
more intuitive and socially acceptable way of 
human-robot communication. The study focuses 
on the construction of a theoretical framework for 
using visible body movements as intentional 
commands for future HRI. The study consists of 
three stages: first, to collect and sort movement 
samples, commands for HRI in daily setting, and 
emotional adjectives for Kansei approach by KJ 
method and cluster analysis; secondly, to obtain 
users’ semantic and affective responses of these 
gestural HRI commands through experimental 
design; thirdly, through Quantification theory type 
I and factor analysis to establish relation between 
users’ responses and the attributes in bodily 
command. To conclude this study, guidelines for 
bodily movement design or gestural commands 
are proposed for future domestic robotic systems. 
The results reveal the importance of 
well-coordinated behaviors and suggest a new 
approach to HRI for users to better communicate 
with robots in daily life. 
Keywords: Domestic Robot, Interaction Design,, 
Body Movement, Kansei Engineering, Laban 
Movement Analysis (LMA) 
二、緣由與目的 
隨著機器人開發技術的日趨完善與普及應
用，具備智能與行動能力的智慧型機器人開始
出現於今日的現實生活當中，Brooks (2003)從機
器人製作的發展歷程與人類演化來看待人機之
間的差異，他指出機器人和人類之間的界線越
4 
LMA)是一種為了觀察、描述、以符號表示解釋
人類動作的方法，其目的是為了改善對不受拘
束的動作之認知效率與加強在每一天的溝通與
表達，著重於分析動作品質(阮逸誠，2004)；拉
邦的分析理論最初被應用在舞蹈動作的分析，
隨著後來學者的補充與延伸，現今被廣泛運用
表演、心理學、臨床醫學、多媒體動畫…等動
作相關領域上。拉邦動作分析中的「勁」(Effort)
為記錄動作質地而設立的座標系統，勁包涵四
種動作元素：時間(Time)、空間(Space)、與力度
(Weight)、順暢狀態(Flow)，時間是指動作時間
長短構成的節奏，動作急緩的程度，分為持續
(Sustain)與突然(Sudden)。空間是指動作者對於
環境的專注力，主要於動作執行時空間感上的
凝聚與渙散，分為直接(Direct)與間接(Indirect)。
力度是指一個動作的衝擊或壓力感受，重心的
下沉或上升為這類動作的主要指標，而重心的
下沉或上升與每個人的重心呼應地心引力的反
應有關，分為重(Strong) 與輕(Light)。順暢是指
肢體運動的順暢程度，分為拘束(Bound)與流暢
(Free) (江映碧，2001；黃彥慈、陳五洲，2007；
謝杰樺、王雲幼，2009)。在拉邦動作分析中，
肢體動作產生的過程中涉及到時間、空間、與
力度三元素，利用此三元素的不同搭配可產生
八類常見的日常動作，包括：漂浮(Float)、重擊 
(Punch)、滑行(Glide)、鞭甩(Slash)、扭絞(Wring)、
輕拍(Dab)、撥(Flick)與擠壓(Press)這八種類型動
作(江映碧，2001)，足以代表人類生活當中的動
作表現。Loke, Larssen, 與 Robertson(2003)將三
個元素組合成立體座標空間呈現如圖 4 所示。 
 
圖 3 設計者模型、系統意象和使用者模型 
圖 4 動作元素組合 
Moen(2007)把人類動覺感官作為感覺和體
驗自身動作一項重要的能力，尋找出「動覺運
動互動(Kinesthetic Movement Interaction，KMI)」，
希望能透過全身去體驗互動過程，推斷出以「現
代舞蹈」作為一個「以人的動作作為溝通和互
動形式」知識來源，使我們能夠建立一個提供
互動經驗具體化的基礎。肢體表演動作，各部
位動作所具有的涵意，而手的動作最重要的是
自然、有目的，不可不自然而難看，手是我們
身體上最富於動作的部位，例如：「手平而手掌
朝上」代表「請求、質問、舉起、支撐」；「手
豎起，手掌朝內」代表「招致、進來，歡迎」…
等等(詹竹莘，1997)，而手勢、姿勢和身體動作
是情緒表達的其中一個管道，Saffer(2008)依動
作發生的身體部位分為：頭部、軀幹、腳、手
臂、臉與手六大類型中，找出常用於介面案例
設計的人類肢體 103 個動作清單，如用手去指，
表示選擇、觸發、輕點、按壓按鈕、強調、盤
旋、點選；手左右揮動，表示啟動、左右移動
捲軸等等。 
林靜(2006)研究家庭影音系統控制為目標，
從手語的角度，為手勢互動發展進行設計與評
估，蒐集認知與視覺符號等文獻，透過使用性
問卷調查篩選出可發展手勢符號之語彙指令，
並結合視覺符號法則與手語產生手勢符號，分
為肖像型、指示型與象徵型三種手勢符號，經
由學習性、主觀評量、數量化Ⅰ類等分析方法
與因子間的相互關係進行實驗評估，驗證出適
合一般使用者操作之手勢符號。而手語是一種
不使用語音，使用手勢、身體動作、臉部表情
表達意思的語言，充滿了豐富的表情和動作，
6 
連調查結果，平均受測者的感受度，使用數量
化Ⅰ類和因素分析來分析；並設計動作規則，
讓受測者使用動作模擬操作 HRI 人機互動流程，
進行「動作指令之使用性評估」(第三次實驗)。 
五、研究成果 
本研究專注在人與機器人系統之間的動作
之指令研究，由於今日多種智慧家電、互動展
示裝置、甚至多媒體娛樂系統也有錄影資料播
放與聲音控制之功能與動作控制，所以不僅限
於機器人產品，也包括相關之智慧系統之指令
樣本收集，透過網站、媒體報導、使用手冊、
型錄..等功能蒐集後，篩選出目前常見的基本功
能指令，共 13 種指令，依照其目的概分為選擇、
音量、開關三類控制功能，整理成如下： 
功能 指令 
選擇控制 播放、暫停、停止、往前、往後、上一
筆資料、下一筆資料、重複 
音量控制 靜音、加大音量、減低音量 
電源控制 啟動影像資料播放、關閉影像資料播放
根據Saffer(2008)所列出的人類肢體103個
動作清單，取出上肢動作之動作清單；加上從
手語中與多媒體播放指令有相關意義的動作(丸
山浩路，1996a，1996b；教育部手語研究小組，
2002a，2002b)，以及實際運用在以動作做為操
縱的產品功能的動作指令，尋找帶有「動態知
覺」的合理動作形式，進行動作樣本過濾，並
依據動作之時間、空間與力度組合進行可作為
訊息傳遞的動作的分類，將動作分類進八種動
作類型裡，因每種類型裡的動作多寡不一，需
要先除去同類型中相似的動作，讓每個類型的
動作數目保持3~10個，因而篩選出適用於人機
互動的動作樣本共41個。 
 
圖5 KJ法分類過程 
圖6 情緒形容詞與動作關連之受測過程 
從不同的文獻(詹竹莘，1997；Shaver et al., 
1987) 與雜誌《PAR表演藝術》中，找出描述"
動作"的形容詞，篩除掉重複的詞，共計483個。
再透過KJ法 (圖5)，過濾掉相似的形容詞，留下
235個，收斂出40組形容詞，分別為：寂寞的、
沮喪的、溫柔的、激昂的、逗趣的、可愛的、
快樂的…等。實驗之初先透過動作與情緒形容
詞之間相互的感受程度，做一份「情緒形容詞
與動作之關連問卷調查表」，再次收斂形容詞數
量。首先從41個動作樣本中，挑選出動作執行
方式差異較大的5個動作，錄製成3～8秒的5個
動作樣本影片，隨機挑選10位受測者，觀看動
作樣本影片並模仿執行(圖6)，體驗做動作時會
產生何種情緒，依據自身動作的感受填答。 
 
圖7 群集分析之結果 
從「情緒形容詞與動作之關連調查」將受
測者對於 40 組形容詞的感受度，透過群集分析，
可區分出 7 組類群之關鍵性形容詞，如圖 7 所
8 
主觀感受，並邀請有使用過任何影像資料控制
經驗者，進行一份「動作指令於機器人影像資
料控制之評量問卷」的填寫，包含基本資料及
使用性。本研究採用 Brooke(1996)時所提出的系
統使用性尺度量表，使用性問卷設計共十題，
為五等尺度量表形式之問卷，一分代表非常不
同意；五分代表非常同意，採正反面交叉詢問
方式，最後利用公式將受測者所選擇之尺度轉
換 為 量 化 資 料 。 其 計 算 公 式 為 ：
{[(S1+S3+S5+S7+S9)-5]+[25-(S2+S4+S6+S8+S1
0)]}*2.5。本研究的受測流程為先請受測者學習
一組動作規則後，再讓受測者用身體動作進行
本研究建議之機器人影像資料控制之互動設計
流程，調查這組動作設計的使用性評估與口頭
訪談，完成一組調查；然後中間間隔一段時間，
再學習下一組動作。實驗資料共完成 14 份問卷，
其中男 6 位，女 8 位，年齡為 21~29 歲，教育
程度研究所或以上，皆有使用過肢體動作操作
智慧產品的經驗。 
比較三組規則的受測結果和訪問情形，多數
受測者認為動作規則一的動作簡單、順暢，動
作認知跟指令相近，直覺不需多思考，好學、
好記、易懂、辨識度高，動作方向有所對應、
較無挫折，可享受互動過程；對於規則一的總
評價，14 位受測者中有 13 位認為動作規則一是
三組裡面最好使用的，而 14 位受測者都覺得在
操作過程中情緒感受是正向的。動作規則二的
動作，大部分好記，但若動作相似會混淆指令，
有些動作跟指令沒聯想性、不直覺，例如上/下
一曲動作沒相互對應且沒方向性；對於規則二
的總評價，14 位受測者中有 5 位認為規則二是
三組裡面最不好使用的，在操作過程中規則二
的動作，受測者做不出來的次數是最多的，受
測者表示雖然有挫折，也因動作較大，情緒反
而高昂，有 10 位受測者情緒感受是正向的。而
動作規則三的動作跟指令不像，且動作對稱少，
使得動作不協調，操作時有困惑感、需要思索、
較難記，但動作本身是容易做出來的，且有類
似實際播放器圖示的動作會好聯想；對於規則
三的總評價，14 位受測者中有 9 位認為規則三
是三組裡面最不好使用的，但有 8 位受測者覺
得在操作過程中情緒感受是正向的。 
由三組使用性尺度量表之總分比較，動作規
則一得 77.68 分，動作規則二得 50.36 分，動作
規則三得 44.64 分，可得知動作規則一之設計具
有一定的使用性，動作規則三之設計被認為是
最不好使用的，但從與受測者的訪談中，動作
規則二、三之設計中還是有讓受測者滿意的部
分，動作規則二、三之優點可以作為規則一改
進之參考。從使用者主觀感受中歸納出下列幾
項動作規則設計之要點： 
(1) 使用者共同感受較高的動作，較受使用
者喜愛，因動作認知跟指令相近，直覺不需多
思考，可享受互動過程。 
(2) 動作與指令方向要有所對應，才不會讓
使用者混淆、減少困惑感。 
(3) 動作與指令有聯想性，會提升辨識度，
例如可用實際播放器上的圖示，引導使用者模
仿出相似的動作；手往外展開，有加大的感覺；
手往內壓縮，有減小的感覺等等。 
(4) 兩個相互相反的指令，動作也能設計成
相反對應比較好；若其中一個動作對於使用者
而言共同感受度本身不高，但可以透過感受度
高的相反動作，去提升感受度不高的動作之辨
識性。 
(5) 從帶有正向情緒之動作去挑選動作，多
少會提升使用者的正向情緒，但情緒正向的主
要原因還是來自於動作本身的使用性。 
(6) 為了減少混淆而從意義較少的肢體動
作來挑動作，動作與指令的關連性要高，才會
顯出動作的辨識，若不高，反而會對動作有陌
生感，因此即使是一個動作可以表達出多種指
令意思，但只要配合情境做出與指令有關連性
的動作，使用者還是可以認同動作所代表的意
涵。 
因此，根據歸納出的動作規則設計之要點，
為從使用者的角度設計出適用於未來動作設計
之參考，本研究重新整理出一組動作挑選方式
如下： 
(1) 從受測者共同感受最強的開始挑起(分數：5
10 
product development, International Journal of 
Industrial Ergonomics, 15, 3-11. 
Norman, D. A. (2010). Natural User Interfaces Are 
Not Natural. Interactions, 17(3), 6-10.  
Norman, D. A., & Draper, S. W. (1986). User 
Centered System Design: New perspectives 
onhuman computer interaction. Hillsdale, NJ: 
Lawrence Erlbaum Associates. 
Norman, D.A., (2007). The Design of Future Things, 
New York: Basic Books. 
Saffer, D. (2008) Designing Gestural Interfaces: 
Touchscreens and Interactive Devices, O'Reilly 
Media, Inc 
Shaver, P., Schwartz, J., Kirson, D., & O’Connor, C. 
(1987). Emotion Knowledge: Further Exploration of 
a Propotype Approach. Journal of Personality and 
Social Psychology, 52(6), 1061-1086. 
丸山浩路(1996a)。最新實用手語(二)。(吳耀德譯)。
台北：昭文社。 
丸山浩路(1996b)。最新實用手語(三)。(吳耀德譯)。
台北：昭文社。 
江映碧(2001)。動作分析與記錄之研究。台北：中
國文化大學出版部。 
阮逸誠(2004)。基於拉邦動作分析之動作風格合成
法。國立清華大學資訊工程研究所碩士論文。 
周君瑞、陳國祥(2003)。感性化產品造形之塑造－
以造形特徵為基礎。設計學報，8(2)，77-88。 
周君瑞、陳鴻源、劉家成、陳國祥、管倖生、鄧
怡莘、張育銘(2000)。電動刮鬍刀產品造形與感性
之關連性研究。工業設計，28(2)，142-147。 
林靜(2009)。家庭影音多媒體系統操作之手勢符號
認知設計。國立成功大學工業設計研究所碩士論
文。 
教育部手語研究小組(2002a)。常用詞彙手語畫冊 
第一輯。台北市：教育部。 
教育部手語研究小組(2002b)。常用詞彙手語畫冊 
第二輯。台北市：教育部。 
游曉貞、陳佳吟、程玉美、羅慧如、鄧怡莘(2010)。
服務型機器人的指令與使用者動作之關連探索。
第十三屆電子商務研討會。國立台北護理學院。 
游曉貞、鄧怡莘、陳佳吟、程玉美、戴秀穎、余
育婷 (2009)。建立以動作為基礎的人與家用機器
人互動系統(I)，行政院國家科學委員會專題研究
計畫成果報告，計劃編號：NSC 
97-2221-E-025-002。 
詹竹莘(1997)。表演藝術與表演教程。台北：書林。 
  
12 
27 2.300  2.400  1.933  2.433  2.133  1.867  2.433  2.167  1.733  2.467  2.300  2.233  1.967  
28 2.033  2.333  2.700  2.633  1.500  1.933  1.800  1.767  1.967  2.367  1.633  2.233  2.000  
29 1.500  2.000  2.400  1.733  2.300  1.767  2.033  1.767  1.700  1.600  2.333  1.600  2.267  
30 1.533  2.467  2.833  1.600  1.500  1.633  2.367  1.500  2.667  1.400  3.767  1.633  2.467  
31 1.567  2.500  2.700  1.600  1.600  1.733  1.700  1.733  2.433  1.733  2.267  1.800  2.400  
32 3.267  1.533  1.500  2.200  1.733  2.033  2.033  2.067  1.533  2.600  1.767  3.533  1.567  
33 3.200  2.033  1.900  2.100  1.700  1.733  2.267  1.967  1.600  2.100  1.833  3.400  2.100  
34 1.700  2.033  2.233  2.467  2.300  1.933  2.567  1.700  1.733  2.133  1.700  2.400  1.767  
35 1.733  2.100  2.367  2.033  2.367  2.633  2.100  1.967  1.833  1.600  2.033  1.867  2.700  
36 1.833  1.567  1.633  2.500  2.300  1.900  2.133  2.100  1.633  2.700  2.167  1.800  1.767  
37 2.400  1.933  1.800  2.567  2.167  1.900  2.267  2.267  1.767  2.567  1.867  2.400  1.833  
38 1.833  1.933  1.833  2.533  2.067  2.233  2.067  2.267  1.733  1.900  2.100  2.133  2.033  
39 2.533  1.567  1.700  3.033  2.300  1.967  2.233  3.367  1.667  2.667  1.767  2.800  1.967  
40 2.667  1.633  1.700  2.967  2.433  2.033  2.500  1.933  1.800  3.533  1.933  3.133  2.067  
41 2.100  1.733  1.733  2.400  2.067  1.767  2.133  2.567  1.800  2.233  1.867  1.967  2.167  
 
表 3 動作與自身情緒感受之平均數 
動作 no. 寂寞的 勇敢的 快樂的 激昂的 不安的 悲傷的 不愉快的 
1 2.600  2.233  2.367  2.067  2.233  2.300  2.300  
2 1.967  3.200  2.600  2.800  1.933  1.833  1.967  
3 2.167  2.167  2.067  2.267  2.367  2.033  2.000  
4 2.000  2.733  2.467  2.500  2.067  1.800  2.000  
5 2.433  2.300  2.167  2.467  2.533  2.167  2.333  
6 2.633  2.100  2.067  2.000  2.733  2.500  2.400  
7 1.933  2.633  2.967  3.067  1.833  1.700  1.733  
8 2.033  2.367  2.000  2.633  2.467  2.233  2.567  
9 2.100  2.000  2.167  2.400  2.167  1.867  1.800  
10 1.833  2.600  3.267  3.333  2.033  1.667  1.800  
11 2.000  2.433  2.700  3.033  2.067  1.700  1.833  
12 2.833  2.200  2.500  2.467  2.667  2.500  2.800  
13 2.233  2.433  2.600  2.467  2.100  2.000  2.000  
14 1.933  3.400  3.233  3.567  1.967  1.733  1.767  
15 2.433  2.100  2.433  2.267  3.233  1.933  2.167  
16 1.733  2.833  4.100  4.000  1.833  1.733  1.700  
17 1.600  2.433  1.767  4.200  2.233  2.133  3.867  
18 2.133  2.633  1.967  3.500  2.100  2.200  3.033  
19 1.933  2.833  1.900  3.600  2.067  1.933  3.067  
20 1.767  2.400  1.767  3.367  2.100  2.100  3.033  
21 1.900  3.533  2.400  3.333  2.100  2.100  2.633  
22 2.600  1.900  1.833  2.133  2.900  2.733  2.867  
23 1.667  2.833  2.667  2.833  1.800  1.667  1.800  
24 2.267  2.533  1.933  2.933  2.300  1.900  2.700  
25 2.233  2.300  2.333  2.567  2.533  2.233  2.600  
26 2.167  2.167  1.933  2.667  2.700  2.167  2.900  
27 1.967  2.567  2.167  3.267  2.433  2.067  2.367  
28 1.933  2.867  2.167  2.533  2.133  1.933  2.300  
29 2.367  2.700  2.100  2.400  2.233  2.200  2.167  
30 2.600  2.033  2.000  2.033  2.167  2.333  2.333  
31 2.100  3.200  2.067  2.467  2.033  1.833  2.133  
32 1.767  2.567  3.100  2.633  1.767  1.667  1.600  
33 1.767  2.267  2.767  2.567  1.933  1.667  1.667  
34 2.167  2.133  2.100  2.333  2.233  1.800  2.133  
35 2.133  2.400  2.067  2.467  2.200  1.933  2.103  
36 1.967  2.133  2.433  2.567  2.600  2.033  2.600  
37 2.100  2.500  2.300  3.133  3.067  1.967  2.233  
38 2.333  2.100  2.133  2.400  2.533  2.200  2.400  
39 2.200  2.200  2.300  2.267  2.333  2.133  2.167  
40 2.100  2.367  2.167  2.167  2.300  2.033  1.900  
41 2.100  2.100  2.000  1.933  2.300  1.933  1.867  
 
表 4 三組動作設計規則說明 
動作設計規則一 動作設計規則二 動作設計規則三 
功能指令 執行動作 功能指令 執行動作 功能指令 執行動作 
播放 32. 手高舉打勾動作 播放 16.拍手 播放 32. 手高舉打勾動作 
暫停 24. 右手從上方，朝掌心向上的左手砍下 暫停 21. 用拳猛擊 暫停 3. 手臂前伸 
停止 2.垂直往上移動至某一位置 停止 2.垂直往上移動至某一位置 停止 22.手臂放下 
往前 10. 手順時鐘轉小圈 往前 10. 手順時鐘轉小圈 往前 23. 手置於右上方，迅速往下方降 
往後 11. 手逆時鐘轉小圈 往後 11. 手逆時鐘轉小圈 往後 11. 手逆時鐘轉小圈 
上一筆 35. 將手臂往身體的左側輕點。 上一筆 19. 以手刀做劈砍的動作(垂直) 上一筆 35. 將手臂往身體的左側輕點。 
下一筆 34. 將手臂往身體的右側輕點。 下一筆 23. 手置於右上方，迅速往下方降 下一筆 1. 用手去指 
重複 39. 握拳、伸手於前，攪拌狀運動 重複 7. 手畫大 O 重複 15. 右手掌在左手掌上反覆翻轉。 
靜音 12. 左右揮手 靜音 4.手臂向外側伸展 靜音 12. 左右揮手 
加大音量 13. 手勢緩慢地向左右慢打開 加大音量 14. 手掌朝外，左右兩手各向兩上方張
開 
加大音量 13. 手勢緩慢地向左右慢打開 
減低音量 6. 手勢迅速地向中央拉近 減低音量 31. 雙手向下移動，做落幕狀 減低音量 6. 手勢迅速地向中央拉近 
啟動播放 1. 用手去指 啟動播放 32. 手高舉打勾動作 啟動播放 14. 手掌朝外，左右兩手各向兩上方張開 
關閉播放 20. 以手刀做劈砍的動作(斜角) 關閉播放 33. 手高舉往下輕點 關閉播放 18. 以手刀做劈砍的動作(水平) 
 
表 Y04 
二、與會心得 
研討會共為期五天，三場主題演講之外，尚有五十多篇來自各個領域的研究發表，綜
合了工程、管理、製造、以及感性設計等議題，在參與本次研討會的過程中，有相當
多的機會與不同國家的學者進行交流與討論，發現即便所屬學門、國別的不同，大家
對於科技發展與產品研發的人性化(或使用者中心)的專注儼然形成共識。此外，於會場
也遇到來自台灣的清華大學、交通大學、成功大學…等單位之學者與研究生，知道國
內不同學門領域所關注的核心議題以及科技發展面向，與不同領域現階段的技術與產
品研發理念，相信對於日後在學術思考的廣度與視野必有相當之助益。 
 
此外，本大會特別強調對年輕研究者的提攜，在不同的論文發表場次，可以感受到同
步工程前輩們，針對於發表者的研究方法、過程內容，提出適當的建議與鼓勵，而不
是嚴厲地指責年輕學者考量不周延之處，我想這種提攜後輩與鼓勵再接再勵的態度，
是所有參與研討會的年輕學人希望獲得正面學術活動經驗分享，也是我覺得此類活動
最有價值的地方。 
 
三、建議 
在此研討會中巧遇來自於台灣等不同學術背景之學者專家，新加坡南洋理工大學的陳
俊賢教授，也是本次會議中負責 Human-Centric Product Design and Development 特別研
究議題的召集人，本身也是出身於台灣的學者，此次的會議提供了同樣來自台灣而平
日並無機會互動的研究人員能有一實質意見交流之機會。相對於我國學術研討活動，
經常僅是應付教育部大學評鑑的手段，不但沒有實質的學術交流，往往還必須動員學
生出席去聆聽演講，以充場面。如何回歸學術研討活動之本質，敦促跨領域學者進行
交流，更是未來台灣各研究機構舉辦學術研討會必須認真考慮之問題。 
 
綜觀此研討會，來自於不同國家、學術領域的與會學者眾多，的確提供各國研究人員
一個良好的機會去理解和認識不同國家對類似亦題的研究方法和思潮。更重要的是，
它提供了各國學者對於波蘭的文化古都克拉科夫的認識，不但對於國際城市的行銷與
波蘭的研究實力的展現，也是一個很好的機會。對於我國外交處處受阻的情況，藉由
學術活動來展現我國的實力，也是一個值得學習的做法。  
 
四、攜回資料名稱及內容 
1. 研討會之論文集一冊 
2. 論文光碟 (但是光碟燒錄有問題，僅有兩篇論文在內)。 
 
五、出席研討會之照片記錄 
   
9/6 報到 9/7 與國內他校學者於會議所在克拉科夫大學入口合影 
 
 User’s Subjective Interpretation of Bodily Movements 
as Gestural Commands to Robot Companions 
Hsiao-Chen Youa,1  and Yi-Shin Dengb 
a Assistant Professor, Dept. of Multimedia Design, NTIT, Taiwan 
b Associate Professor, Institute of Applied Arts, NCTU, Taiwan 
Abstract. Statistics show that domestic service robots for household chores, entertainment, 
or other social purposes will become a common scene in our future life. However, many of 
the human-robot-interactions still behave and feel like robots belong in laboratory or factory, 
and are not well-suited toward the wide variety of home users. Researchers have 
consequently called for better interaction design of robot companions to engage users in a 
more socially meaningful style. In order to cope with the challenge of HRI, understanding 
how people interpret their own gestures will aid design of effective HRI. This study 
explored how users subjectively assessed their bodily movments in terms of gestural 
command in HRI. Literature survey, analysis of current related intelligent products, and in-
depth interview with experts were adopted to identify the feasible gesture samples and 
commands used in nowaday robot-related products. An experiment was conducted to ask 
participants to view and experience each gesture sample, then make their subjective 
assessments of each sample in reference to a set of commands by a three-point scale. The 
results obtained are discussed in terms of implied guidelines for designing a natural and 
intuitive gestural interaction for companion robots and other intellectual appliances targeting 
non-expert users. 
Keywords. Robot Companion, Human-Robot Interaction, Gestures 
1 Introduction 
Statistics indicate that domestic robots for household chores, entertainment, or 
other social purposes will become a common scene in our future life. For instance, 
3.4 million personal service robots were in use worldwide in domestic settings in 
2007, and the number is expected to increase to 4.6 million robots by 2012, 
according to the Statistical Department of the International Federation of Robotics 
[7]. The Ministry of Information and Communication in South Korea expects to 
have a robot in every family by 2013. And the Japanese Robot Association predicts 
                                                          
1  Assistant Professor, Dept. of Multimedia Design, National Taichung Institute of 
Technology, 129, San Min Road Section 3, Taichung 404, Taiwan; Tel: +886 (4) 22196802; 
Fax: +886 (4) 2219 6231; Email: hcyous@gmail.com 
 
 User’s Subjective Interpretation of Gestures as Commands for HRI 3 
evaluated people’s understanding of those gestures. Nakata, Mori, and Sato [10] 
claim proper use of robot’s body movement can convey certain emotional 
impression to users, and a framework for body expression is proposed to facilitate 
evaluation and forecast of users’ impression onto robot’s movement. However, 
approaches to study gesture in HRI have mainly focused on the development of 
understandable robots movement [8, 10] and better gesture recognition technology 
[15-17]. Few are concerning what these gestures make sense to users: Do gestures 
convey the same message to the recipients as well as to the actors themselves, the 
human users in HRI? What are the user’s subjective interpretations or feeling about 
his/her own movement in the gestural interaction? Are they aware of any 
randomness or inconsistency between their bodily feelings of the actions and the 
intended commands assigned by HRI designer? Hence instead of focusing on the 
design of comprehensible gestures of robots, this study aims to investigate the 
actor’s subjective interpretations of his/her gestural actions as commands to 
communicate with a robot companion. 
3 Methods 
The study reported in this paper is part of a larger study to explore a more intuitive 
and pleasant use of bodily movement in HRI. The focus of this paper is to 
understand how people perceive their own bodily movement in terms of gestural 
commands for HRI. An experiment was conducted to collect participants’ 
subjective assessments on what various gestures meant to themselves while they 
were using these gestures to interact with a social robot. An association rating sheet 
was developed to help participants to rate how their gestures are correlate to some 
general commands in HRI by a three-point scale. 
In order to determine a corpus of gesture examples and commands for the 
experiment, the palette of human gestures and movements proposed by Saffer [13] 
was used as the potential gesture examples from the outset. There were 103 
gestures in total, consisting six types of bodily movements, head movement, torso 
movement, leg movement, arm movement, hands movement, and face movement. 
Through an in-depth discussion with HCI experts, 41 apparently infeasible 
movements for HRI were eliminated; the total number of user gestures was 
reduced from 103 to 62. The 62 gesture samples included  “head tilt forth”, “head 
tilt back”, “head tilt right” , “head turn left”, “head nod”, “head shake no”, “finger 
point”, “hand wave”, “hand clap/applause”, “fist”, “thumbs up/down”, “okay 
gesture”, and etc.. All of these 62 gesture examples were performed by our 
research assistants and video-recorded, as shown in Figure 1.  
In the mean time, brochures and user manuals of current robot companions and 
related intelligent products were collected and analyzed, and a set of commonly 
used commands were carefully selected as the reference of subjective messages in 
the experiment. There were 22 commands included “turn on”, “turn off”, “go/turn 
left”, “go/turn right”, “go forth”, “go back”, “stop”, “yes/confirm”, “no/deny”, 
“cancel”, “repeat”, “increase volume”, “decrease volume”, “walk around”, 
“approach”, “recharge”, “follow me”, “move up”, “encourage (enjoy)”, “forbid 
 User’s Subjective Interpretation of Gestures as Commands for HRI 5 
4 Results and Discussion  
To get an overview of how participants perceive their own bodily movement in 
terms of HRI commands in the experiment, 40 association rating sheets was first 
collected and all the ratings for a particular gesture-command pair were added 
together. The sum of all participants’ ratings of the association strength between 
each gesture and command could range from -40 to 40. The larger the number 
meant more participants considering the gesture-command pair correlate, and vice 
versa.  
There were 30 gesture samples (e.g., “push”, “pull”, “finger crossed”, “pinch”, 
“cup palm”) that their sums of ratings in reference to the 22 HRI commands were 
all below 0, which meant most of participants considered they were not related to 
any of the 22 commands. Furthermore, there were 3 HRI commands (i.e., “power 
on”, “power off”, and “move down”) that their sums of ratings in reference to the 
62 gestures were all below 0, which meant most of participants considered they 
were not related to any of the 62 movements.  
Then, we removed those gestures and commands that most participants 
subjectively judged as unrelated, the sum ratings on the association of remaining 
gestures and commands were listed in Table 2. In order to visualize the association 
strength of each gesture-command pair, the numbers were replaced by symbols, 
“－”, “”,  “”, “”, and “”. 
While this research is a first step in investigating users’ subjective experience 
on their own gestures as controlling command in HRI and should be seen as 
exploratory, four tentative design guidelines are inferred. First, 32 out of 62 gesture 
samples in this study are found associated with some HRI commands, which 
means some gestures can elicit users’ subjective responses corresponding to certain 
commands in HRI. Such users’ bodily experience and subjective feelings of their 
movement should be taken into account in creating more intuitive and self-evident 
gestural interactions. Second, there is a gap existing between users’ subjective 
experiences of their own movements and others’ (not the actors themselves) 
interpretations. Some gestures make sense through looking and thinking, but not 
through acting. For instance, “hand wave” (an open hand is moved left/right) is 
suggested to be used for activating, scrolling left/right in HCI literature [13], which 
makes sense to authors in this study. However, the results shown in Table 2 
indicate that participants feel this movement is more about sending greetings to a 
robot or denying/cancelling an option. Third, users tend to employ interpersonal 
gestures to express social behavior and emotion (e.g., “hand wave” as greetings, 
“hand clap” and “thumbs up” for enjoyment and encouragement) while they are 
communicating with robot companions, as if they were alive.  Hence, if gestures 
commonly used in daily interpersonal communication are applied in the interaction 
design for robot companion, designers should follow the convention and do not 
randomly assign new meaning to them to avoid conflict. Finally, some of gesture 
samples are ambiguous to the participants. For instance, the gesture “head tilt 
forth” can be interpreted as “go forth” or “yes/confirm”, and the gesture “come 
here” as “go forth”, “approach to me”, or “follow me”. When ambiguity happens, 
gestures alone are not sufficient to convey meanings, even to the actor his/herself. 
 User’s Subjective Interpretation of Gestures as Commands for HRI 7 
5 Conclusion 
In this study, a collection of human daily gestures were carefully selected, then 
participants were asked to perform each of them, experience it , and subjectively 
rate its association of different commands in HRI. Base on results of the 
experiment conducted, some gestures do elicit participants’ subjective responses 
corresponding to certain commands in HRI, which makes the gestural interaction 
self-apparent and intuitive. However, there are some iconic gestures that make 
sense to designers or audience, but participants (actors) just don’t feel the same 
way. Hence, we argue that what users consider natural and intuitive gestures during 
their interacting with robot companion can be different from what others expect. 
Furthermore, when we discuss about using gestural commands in HRI, how user’s 
gesture is detected by intelligent devices, or what message a gesture leaves the 
majority of the audience with might be important, but in order to design an 
intuitive and communicative interaction between a user and his/her own personal 
robot companion, what user’s action mean to his/herself is important too. It is 
recommended that future HRI research take into account users’ bodily experience 
in creating socially meaningful interaction. 
In addition, the same gesture can sometimes elicit more than one subjective 
interpretation. We suspect the ambiguity is due to lack of situational context in the 
experiment. Research has suggested that both in interpersonal communication and 
HRI the perceived meaning of a gesture depends on its social context [3, 9]. The 
issue of gesture’s situational context will be considered in our forthcoming study. 
The focus of this research is to investigate user’s interpretation of his/her bodily 
movement in term of commands for HRI, and to understand how these gestures are 
relevant to some commonly used commands. Hopefully, findings in this research 
can serve as reference for the design of gestural interaction for companion robots 
and other intellectual appliances targeting non-expert users in domestic settings. 
Acknowledgments 
Authors thank Chia-Yin Chen, Yu-Mei Cheng, and Hui-Ju Lo for all their help. 
This research was in part funded by the National Science Council of Taiwan grant 
NSC 98-2221-E-025 -001to first author. 
References 
[1] Breazeal C. Toward sociable robots. Robotics and Autonomous Systems 2003;42:167–
75. 
[2] Dautenhahn K. A paradigm shift in artificial intelligence: why social intelligence 
matters in the design and development of robots with human-like intelligence. In: 
Lungarella M, Iida F, Bongard J, Pfeifer R (eds) 50 years of artificial intelligence. 
Springer, Berlin Heidelberg New York, 2007; 288~302. 
國科會補助計畫衍生研發成果推廣資料表
日期:2011/01/26
國科會補助計畫
計畫名稱: 建立以動作為基礎的人與家用機器人互動系統(II)
計畫主持人: 游曉貞
計畫編號: 98-2221-E-025-001- 學門領域: 人因工程與工業設計
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
本研究計畫之目標主要在執行機器人互動系統的設計與檢測：藉由機器人互動
雛形系統的建構，並將 HRI 雛形以真實日常生活之智慧系統功能以動作指令進
行實驗，並將訊息傳達結果與使用性/使用感受資料進行分析。除檢驗動作式互
動中動作與指令之間的關係，並提出未來藉由動作與智慧型機器人（或產品）
可能互動形式的發展方向及設計建議。 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
