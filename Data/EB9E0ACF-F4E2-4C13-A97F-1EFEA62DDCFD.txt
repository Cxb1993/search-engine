徵點，透過 SVM 分類器[2]來解決多分類
問題之結果，檢索出最適當之影像，並用
最相似影像（the best match unit, BMU）與
SOM[3]快速有效的檢索出最相似之影像
物件樣式。 
 
三、研究方法及成果  
 
1. 研究方法 
(a) 影像檢索特徵萃取方法 
 影像特徵值擷取的方法有許多種，在
過去的研究成果也相當豐富，包含：傅立
葉描述子（Fourier Descriptor）、Moment 
Invariants、以及我們曾經提出的相似形狀
特徵值[4]等等。在傅立葉描述子方面我們
採用了 Centroid 及 Complex 兩種方式
[5]，在 Moment Invariants 方面我們採用了
Chen’s Moments [6]。我們首先取得圖形輪
廓上的像素點座標，並同時計算出圖形重
心的座標位置。取得了圖形輪廓上每一個
像素點的座標位置與重心座標之後，再以
三種不同的特徵點擷取方式 Centroid 
Fourier Descriptor 、 Complex Fourier 
Descriptor 與 Moment Invariants、我們所研
發的 Similarity Measure 來擷取影像圖形
之特徵點。 
 
(b) 分類方法 
 在圖形識別的領域上，分類是相當重
要的一個步驟，將影像進行分類之後，可
以減少檢索的範圍，加快檢索的速度與有
效性。現行研究的分類方法相當的多，每
一個都有其不同的特性，但什麼樣類型的
資料適合用哪一個分類方法，到目前並未
有一定的答案。我們採用近年來受囑目的
SVM 分類技術，並選用台大林智仁博士
之 LIBSVM[7]作為多類別分類器。 
 
(c) 輔助檢索方法 
當樣本經過 SVM 訓練後，會產生一
model 供分類用，雖然 SVM 會提供每一
測試樣本一個預測之類別，但若類別中的
原始影像資料過多時，需要一一與測試樣
本比對亦屬耗時，故此我們預先對每一類
別使用 SOM 產生一個同類別的原始影像
鄰近地圖供快速檢索用，當一個測試樣本
經過分類得出預測類別後，我們對該類的
每一個原始影像的傳立葉描述子數值求
出與樣本之相對數值的最小差異的原始
影像，爾後當使用者需要檢索更多之原始
影像時，我們則從 SOM 地圖直接獲得，
以加快檢索速度。 
 
2. 成果 
(a) 實驗流程設計 
2D 影像資料研究如圖一實驗流程圖
來進行實驗，其各階段分別簡述如下： 
(i) 特徵擷取階段： 
將所有的 2Ｄ影像資料經由 CeFD 的
轉換取得影像特徵值。並分別將每個影像
類別之資料各別分成兩個部份－20%作為
測試資料和 80%作為訓練資料。 
(ii) 學習階段： 
在此階段中，我們主要先分別將 20%
測試資料和 80%訓練資料進行正規化
（normalization）的動作，將所有特徵值
之範圍正規化於+1~-1 區間。正規化資料
的主要目的希望能減少計算上的複雜度。 
經由正規化後，並依據交叉驗證之實驗得
出之最佳參數值後，將 80%的訓練資料透
過 SVM 分類器進行訓練，並獲得訓練後
之學習模組（learning model）。 
(iii) 影像檢索階段： 
SVM 檢索部份，此階段主要將測試資
料依據 SVM 學習階段所產生的學習模組
來進行預測的動作，並將預測所得之結果
類別資訊記錄於資料庫中，以方便日後檢
索。SOM 檢索部份，首先我們選擇最佳
檢索之影像類別，並於檢索類別中套用最
小平方差測量方式產生 SOM 地圖表，方
便了解其檢索所對應之相似影像。 
 
3D 影像資料研究如圖二驗流程圖來
進行實驗，其各階段分別簡述如下： 
(i) 前置處理： 
取得以視覺為基礎的影像，我們依立
體空間投影 3D 影像物件產生之 2D 影像
投影，依此原理，我們使用 Cyr 和 Kimia
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
圖二 SVM 應用於 3D 影像物件檢索實驗流程圖 
 
(b) 實驗結果 
2D 影像資料實驗過程與結果簡述如
下： 
依 實 驗 之 經 驗 法 則 ， 我 們 採 用
LIBSVM 工具，並使用 RBF 函數，因為
它在於解決多重分類的效能方面有較佳
的表現。經由交叉驗證，我們訂定了相關
的 參 數 範 圍 { }1.0,5.0,1,2,52 ∈δ 和
{ } 1 ,10 ,50 ,100 ,500 ,1000 ∈C 來 進 行 實
驗，結果如表一和表二所示。 
為了確保實驗的公正性，我們將資料
拆成五等份並以循環方式去做測試，並和
Sebastian＇s 與 Chen＇s 的方法做比較，
經由結果得知，如表三與表四，我們所使
用的方法和 Sebastian＇s 的差不多；而與
Chen＇s 方法比較，則在辨識率上皆有較
佳之表現。 
在 SOM 方面，我們對同一類別影像
物件中使用 LMSED 方法來分別找出每個
影像之最相似影像（the best match unit, 
BMU），LMSED 對每個影像 Q 的計算方
法如以下公式所示，m 為傅立葉之特徵值
數；M 為同一類別中之另一影像物件。 
 
( )∑
=
−=
m
i
MiQiQ CeFDCeFDMinLMSED
1
2(  
對於訓練資料而言，針對我們調整參
數讓每個影像之 BMU 皆於在 5×5 之 SOM
鄰近格中，並將此結果存於資料庫，方便
表三 不同方法之預測結果 
Database 99 shapes 216 shapes 1045 shapes 
Ours 90.0 96.7 84.1 
*Sebastian’s 97.0 96.0 -- 第一次比對 (%) 
Chen’s 77.8 77.8  67.8 
Ours 96.7 98.9 94.2 
*Sebastian’s -- -- -- 第二次比對 (%) 
Chen’s 77.8 83.3 81.0 
Ours 96.7 100 96.3 
*Sebastian’s 100 100 -- 第三次比對 (%) 
Chen’s 77.8 91.7 83.9 
註：Sebastian’s 的方法於第二次檢索比較與 1045 影像並無相關資料紀錄 
 
表四 五次循環之預測與測試結果 
第一次比對 (%) 第二次比對 (%) 第三次比對 (%) 
Database 循環 
Train Test Train Test Train Test 
Round1 100 94.44 100 94.44 100 94.44 
Round2 100 83.33 100 88.89 100 88.89 
Round3 100 94.44 100 100 100 100 
Round4 100 83.33 100 100 100 100 
Round5 100 94.44 100 100 100 100 
99 shapes 
Average 100 90.00 100 96.67 100 96.67 
Round1 100 100 100 100 100 100 
Round2 100 97.22 100 100 100 100 
Round3 100 97.22 100 100 100 100 
Round4 100 94.44 100 97.22 100 100 
Round5 100 94.44 100 97.22 100 100 
216 shapes 
Average 100 96.66 100 98.89 100 100.00 
Round1 96.28 84.91 99.76 93.87 100 95.75 
Round2 96.88 83.49 99.88 94.34 100 96.70 
Round3 96.88 83.49 99.88 94.34 100 96.70 
Round4 96.28 84.91 99.76 93.87 100 95.75 
Round5 96.88 83.49 99.88 94.34 100 96.70 
1045 
shapes 
Average 96.64 84.06 99.83 94.15 100 96.32 
 
 
3D 影像資料實驗過程與結果簡述如
下： 
本實驗 3D 影像檢索主要是使用 Cyr
和 Kimia 所提供之 3D 影像資料庫，此 3D
資料集主要是以視覺為基礎依立體空間
投影 3D 影像物件產生之 2D 影像，以水
平角度每隔五度做為一空間區段進行投
影而成，如圖四，影像立體物件 kangaroo
以每 5 度為一單位，進而投影產生 2D 影
像。故一個完整的 3D 影像物件可拍攝出
72 張 2D 影像。此影像資料庫總共包含了
六十四個影像物件。實驗使用 LIBSVM，
主要核心函數為 RBF，因為此函數能針對
多重類別資料分類獲得較好的結果。我們
透過 ten-fold 的交叉驗證，依所訂定相關
的參數範圍 和 來針對不同的影像特徵
擷取方法進行實驗，以取得其最佳參數與
辨識率，如圖五所示。在數種影像特徵方
法辨識率之比較圖，可輕易看出 Complex 
FD (no-scale) 於 64 個物件類別獲得較高
之辨識率，因此，本研究採用 Complex FD
特徵擷取方法來做為實驗依據。 
為確保實驗的公正性，我們分別以五
次的循環方式，分別由 0 個物件類別增加
至 64 個物件類別進行檢索預測與測試，
並獲得平均高達 98%檢索辨識之辨識
率。其結果如圖六所示。 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
圖四 3D 影像物件之 2D 影像投影 
 
