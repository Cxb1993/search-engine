 1 
行政院國家科學委員會專題研究計畫成果報告 
智慧型擴增實境技術與平台建置之研究 
A Study of Intelligent Augmented Reality Techniques and 
Platform Development 
 
計畫編號: NSC99-2220-E-327-001 
執行期限:99 年 8 月 1 日至 100 年 7 月 31 日 
計畫主持人:李嘉紘 副教授 國立高雄第一科技大學 資訊管理系 
 
 
一、中文摘要 
  擴 增 實 境 技 術 ， Augmented 
Reality(AR)，是一個結合真實、創意與媒
體世界的新科技，它能將虛擬出來的影片
圖像即時進行傳輸，簡單來說，這項技術
就是將現實世界與虛擬世界即時結合起來。
近年來，這項技術逐漸受到重視，連熱門
手機iphone都配備簡易版的AR功能，它的
應用範圍非常廣泛，例如電影製作的虛擬
場景，或者是歷史古蹟的虛擬重建等。 
在2009年MIT所出版的技術報告雜誌
上，將AR技術列為未來10年內影響人類
生活最大的十項科技之ㄧ，3D電影阿凡達
在世界各地所引發的3D視覺娛樂以及AR
技術話題，說明此一技術的重要性。目前
台灣正積極推廣六大新興產業，其中數位
內容若能結合AR的技術來顯示，更能提
高相關的附加價值。然而截至目前為止，
全世界用來開發AR產品的主要工具都掌
握在外國軟體公司手中，目前在台灣所代
理的AR軟體主要來自國外五家廠商：法
國Total Immersion (用於大型劇場，如電影
阿凡達電腦特效製作)、德國Metaio(用於
製造業)、加拿大 Vizard(用於飛行模擬器)、
義大利 AR Media( 用於 CAD 模擬，與
Google 合作)以及義大利Eligo(用於建築業，
裝潢模擬)。上述這些公司軟體規劃的主
要功能與應用的領域都有所不同，絕大部
分公司都是原先即涉獵虛擬實境的公司，
其中義大利Eligo在台灣的總代理為鼎達興
業 有 限 公 司 ( 整 個 亞 洲 代 理 為 韓 國
HanullneoTech公司)，與我們配合廠商加
碩欣業有限公司有合作關係，國內業者希
望國內尤其是南部大專院校也可以合作開
發國內自己的AR技術，並釋放出來給大
家共享，以增強台灣這方面的軟實力，不
必樣樣受限於國外廠商。另外目前業者所
提供的AR應用軟體，大部分仍受限於必
須配合使用較大尺寸的標記(Marker)使用
才能提高穩定的標記辨識，主要的原因是
環境光源的改變，往往造成標記辨識出現
錯誤；再則一般AR標記外觀並不好看，
不容易融入一般教材中， 
本研究將利用影像處理技術改進光源
影響的問題並利用半色調影像技術發展出
客製化的AR標記，再配合半色調影像資
料隱藏技術研究相關標記認證的安全議題，
最後將研發的技術投入設計行動擴增實境
的應用平台，以提供一般民間業者的使用。 
 
關鍵字：擴增實境(AR), 行動擴增實境, 
擴增實境標記, 半色調影像, 數位浮水印
技術、可調適性光線平衡 
 
二、本計畫之研究問題與研究成果 
－研究方向與目的 
本研究以自由軟體開發的架構，針對擴增
實境技術以及平台開發之應用，提出相對
的解決方法，期待能對目前行動擴增實境
核心技術、方法開發以及實際應用上，有
一個全面性的探討與實現。針對下列三個
主要的問題提出相對應的解決方案。 
(一)發展抗光線變化的標記(Marker) 辨識
 3 
AR combine function 去會辨識 AR marker，
此執行程式將會從 Model & Music Data-
Base 去讀取所相對應的檔案，並從螢幕顯
示出 3D model 和音效；User 可從英文學
習平台中下載安裝檔，並以作業系統為
XP 或 Vista 來區分系統需求、英文學習圖
卡和 AR marker，以及管理者 (Manager)
可以上傳或更改 3D model 和音效檔。 
  在 AR 技術上，由 webcam 取得影像
之後，進行影像的前處理，這個程序主要
是利用取門檻 (Thresholding)、連通成分
(Connected Component) 、 角 落 偵 測 
(Corner Detection) 等演算法來進行影像中
標記的所在位置與所在區塊的影像擷取；
然後進行標記的追蹤程序，因為所取得的
標記影像，通常因為相機角度的關係，所
拍出的標記形狀會變形，因此必須先進行
形狀的校正，然後計算轉換矩陣，將變形
的標記還原回接近標準的形狀後，再解讀
出標記的內容資料；接著根據資料，進入
英文學習資料庫，讀出相關的聲音或是動
畫，並配合轉換矩陣，聲音或動畫轉換為
與相機取像時的相同座標，最後經由視訊
混合程序，將相機的影像與聲音或動畫做
結合，經過位置校正後，將聲音或動畫疊
合到相機目前影像上，完成擴增實境的目
的。 
 
單字卡 
  
 
圖 2、所開發之單字卡，A-Z 共 26 張圖卡 
 
圖 3、單字卡實際操作情形 
 
實體書 
  為了讓使用者 (幼兒) 更加認識每個
英文字母，我們除了卡片上的單字外，還
加了許多不同的單字。因此透過實體書可
以學習到更多更豐富的英文單字。書上也
有兩句以此單字為例的句子、代表單字的
圖案、以及 AR marker。另外學習要是能
搭配實體的物品，效果會更好。除了單字
卡上平面的圖，我們也尋找並製作跟單字
有關的 3D 的人物與物品，利用擴增實境
的技術呈現，生動活潑的學習，也增加了
使用者學習英文的興趣。 
 
 (a) 
 
(b) 
圖 4、(a)實體書與(b)實際操作情形 
 
 5 
偵測角度而調整並將其分離成許多區塊。
捨棄掉文字的區塊後，圖片區塊的邊緣將
被取出，成為霍夫轉換的輸入來源。最後，
利用霍夫轉換得到的各條直線進行四邊形
偵測，而最佳的四邊形構成即代表圖片於
影像中的範圍。實驗結果證明所提出方透
過角度進行文件切割與霍夫轉換的四邊形
偵測能有效找出文件影像中圖片的所在位
置。 
 
 
圖 9、 所提方法之流程圖 
 
圖 10為報紙文件影像經由 CRLA進行角度
偵測的結果，雖然藉由角度的調整，已經
使圖片區域由文件影像中獨立，然而光照
與顏色的影響仍可能會造成提取出的圖片
區域殘缺，如圖 11 中的圖片區塊所示，
圖 11(b)與圖 11(c)為圖 11(a)中左下與右
上位置擷取的圖片區域，左下方的圖由於
其上方雲的部份與背景顏色差異過小，因
此在二值化時形成缺一角的情形；而右上
方的圖片其左半部份也有此問題。 
 
圖 10、 (a)二值化影像 (b)CRLA 頁面分
割後的結果 
 
 
圖 11 (a)報紙影像，包含垂直文字與兩張
圖片 (b)左下方的圖片區塊 (c) 右上方的
圖片區塊 
上述問題使鏈碼(chain code)或是區域
成長(region growth)等方法的效果差強人意，
為了克服此問題，霍夫轉換的樣式偵測於
是被應用到本研究中。C.R.Jung 在其研究
中提到，若以一矩形之中心點為霍夫空間
座標軸心，則構成矩形的四條邊線在霍夫
 7 
上述矩形樣式的放寬，將有助於我們
找到如梯形等非矩形的四邊形樣式。然而
由於邊線與中心點距離的條件由原本的對
稱關係簡化為距離差不多即可，因此可能
會使兩條距離很近且角度差不多的線，被
視為一組同方向的對線。為了解決此問題，
使偵測出的四邊行能準確包圍文件中的圖
片，在接下來的兩組平行線配對處理上，
將利用四邊形的周長與所含像素進行評估。 
 並非所有在霍夫轉換中偵測到的線都
會被用來檢測，我們只利用最好的 N條線 
來做配對，在取線的數量設置上不宜過少，
因物件在二值化時可能會受到光照影響而
遺失掉細節，物件的邊緣也就可能顯得支
離破碎，進而影響直線偵測準確性，此時
若使用的線數量過少，恐怕會因此遺失掉
最好的四邊形構成。在本研究中我們使用
霍夫轉換偵測中最強的 20 條線來作四邊
形檢測。 
 設 ),( mmmH  為第 m 條由霍夫轉換
中取得的線在霍夫空間中所對應的位置。
若有兩條線符合上一節中定義的樣式(1)、
(2)，則兩條線在霍夫空間中的位置
),(),,( iiiiii HH   必須符合下列條
件： 
.||||
,||




T
T
ji
ji


 (1) 
兩條線的角度門檻值 T 限制了四邊形偵測
範圍。若 T 越小，則兩條線必須越平行，
也代表偵測出的圖形越接近矩形。另外門
檻值 T 則限制了兩條線對稱於物件中心點
的距離差。本研究為了因應攝影機角度下
圖形呈現歪斜的狀況，因此將門檻值設為
25T 用以偵測歪斜的四邊形(梯形)。 
另外，四邊形可能的組合，也必須符
合條件 (3)的定義。兩組方向的對線
nmji HHHH ,,, 在霍夫空間中的 軸差距
必須小於門檻值 T 。 
.|90|)
2
()
2
(|| 

 Tnm
ji




  (2) 
最後，在物件構成的所有直線中，所
有可能產生的四邊形組合已全部找到，然
而我們只需要最符合物件外型的四邊形組
合，因此必須對所有的四邊形進行測量，
找出最合適的組合。而所有四邊形 iQ 的周
長與其邊線的像素總數量，將給予權重進
行平估計算，評估數值最大的將被保留，
視為物件的最佳外框。 
).()()( iii QPixelsQPerimeterQE  
 (3) 
其中 、  為周長與像素總數量的權重，
考慮到物體可能因為光照或顏色的影響，
造成邊緣斷裂或缺邊等情況，因此在權重
調配上，  設置應相對較低。 
 
實驗結果 
本研究之測試圖片皆為任意取得的文
件影像，攝影設備採用 HTC Hero 智慧型
手機，影像解析度為 512768 像素，影像
內容包含文字與圖片部分。在拍攝角度上，
由於本研究預想一般人在拍照時，並不會
刻意以大角度方式拍攝，因此在圖片的拍
攝角度上，僅以些微角度拍攝圖片。在頁
面切割門檻值的設定上，考慮到一般報章
雜誌在圖片旁邊可能會有文字描述，因此
置 換 的 數 目 不 宜 過 大 ， 30horC 、
30Cver  、 5Csm  為本研究之配置；而四
邊形偵測方面，對於距離與角度的門檻值
設置，將依據能容忍的歪斜程度做調整，
本研究使用 25T 、 30T 。最後在最
佳四邊形的挑選上，考慮到光照變化或圖
片部分顏色與背景相似等情形，可能造成
圖片邊緣破裂或缺一塊等情形，故四邊形
周長的權值較重， 6.0 ；而四邊形的像
素總數權重應該相對較小， 4.0 。 
 
 9 
   
(D) Baboon 
 
(E) Girl 
 
(F) Jet 
圖18、6張測試影像特徵點與所計算出的
特徵直方圖。利用最小距離公式，求得距
離如下表所示，很明顯的可以看出，圖A、
圖B、圖C為較相近的影像。 
 
表一、不同影像的特徵距離(歐式距離) 
 A B C D E F 
A 0 4.34 4.59 11.56 7.12 6.20 
B 4.34 0 1.37 11.20 6.42 6.64 
C 4.59 1.37 0 11.21 6.07 6.92 
D 11.56 11.20 11.21 0 9.29 9.53 
E 7.12 6.42 6.07 9.29 0 6.35 
F 6.20 6.64 6.92 9.53 6.35 0 
 
 
 
最後，我們完成所提出的AR動新聞系統，
如下圖所示，利用本系統webcam拍到圖(a)
影像時，系統會自動切出照片部分圖(b)，
然後經過正規化後，計算其特徵值，再與
系統資料庫特徵比對，找出對應的視訊檔
案(如圖(c))，最後在相對應位置上，播放
視訊出來，再播放前必須將視訊影格經過
四角轉換後在浮貼到對應位置上如圖(d)所
示。 
 
 
 
(a)                          (b) 
 
 
(c)                          (d) 
 
圖19、AR動新聞實例。 
 
 
 
 
 
0 
500 
1000 
1 3 5 7 9 11 13 15 
0 
200 
400 
1 3 5 7 9 11 13 15 
0 
500 
1 3 5 7 9 11 13 15 
出席國際學術會議心得報告 
計畫編號  NSC 99-2220-E-327-001 
計畫名稱  (中文) 智慧型擴增實境技術與平台建置之研究 
(英文) A Study of Intel ligent Augmented Reality 
Techniques and Platform Development  
 
出國人員姓名  
服務機關及職稱  
李嘉紘    
國立高雄第一科技大學 資訊管理系 副教授 
會議時間地點  2011年七月六日到八日, 英國倫敦  
6
th 
~ 8
th
, July, 2011 London, U.K.  
會議名稱  (中文)世界工程年會-2011訊號與影像工程國際研討會 
(英文) World Congress on Engineering 2011(WCE 2011)  
The 2011 International Conference of Signal and Image 
Engineering 
發表論文題目  (中文) 利用影像切割與擴增實境技術之視訊新聞系統 
(英文) A Framework of Video News System Using Image 
Segmentation and Augmented Reality 
 
一、參加會議經過  
 
  本次出國主要的目的是去參加世界工程年會WCE 2011並報告論文  - A 
Framework of Video News System Using Image Segmentation and Augmented Reality，
藉由報告論文的空檔，觀摩國際間在訊號處理以及多媒體應用領域上的發展趨勢、
方法、以及目前的現況。  
  WCE 2011是 International Association of Engineers (IAENG)協會聯合舉辦的國際
工程年會，在英國倫敦舉行，共有十四個重要的研討會議，其領域涵蓋了人工智慧、
生物資訊、電腦科學、資料探勘等，我們投稿至其中的訊號與影像工程國際研討會。
整個年會有來自50多個不同國家超過一千三百篇的投稿，顯示有相當多的研究者投
入這次的研討會。 
  本人參加報告的Session屬於訊號以及影像工程，是在第一天下午的二點開始，順
位是第二個。會場有許多此一領域的學者參與，也與本人做簡短的討論交流。 
這篇論文主要是結合傾斜角度掃描與霍夫轉換提出一個能在任意來源的文件影像中，
正確地擷取圖片在文件影像中的範圍。首先，文件在影像中的放置角度會被偵測，
接著文件分割程序會依據偵測角度而調整並將其分離成許多區塊。捨棄掉文字的區
塊後，圖片區塊的邊緣將被取出，成為霍夫轉換的輸入來源。最後，利用霍夫轉換
得到的各條直線進行四邊形偵測，而最佳的四邊形構成即代表圖片於影像中的範圍。
實驗結果證明所提出方透過角度進行文件切割與霍夫轉換的四邊形偵測能有效找出
 
Abstract—In this paper, we propose a framework of video 
news system using image segmentation and augmented reality 
scheme. The goal of proposed system is to provide users with 
realistic audio-visual contents when they are interested in 
reading some topics on newspapers. In our approach, pictures 
on the newspapers were used as markers of augmented reality. 
Users can pick up these pictures to watch the corresponding 
video news to obtain more information.  The proposed system 
consists of image segmentation, image recognition and 
augmented reality engine with audio-visual contents. In image 
segmentation, skew angle detection and Hough transform 
techniques are applied to extract pictures on newspapers. In 
image recognition, image calibration using four-point mapping 
and Harris corner detection are proposed to identify different 
pictures on the newspapers. In augmented reality, four-point 
transformation is reused to add video image frame on the 
captured image by camera. We expect that the proposed system 
is popular and can be applied as a kind of advertisement of 
products in business applications. 
    
 
Index Terms— augmented reality, Hough Transform, 
document image, image segmentation. 
 
I. INTRODUCTION 
ANY studies were proposed into developing 
Augmented Reality technologies for entertainment, 
education and advertisement. These applications allow 
the user to view and manipulate images or virtual 3D objects 
in a real-world environment. There are two major approaches 
in camera tracking augmented reality, marker and 
marker-less methods. Camera tracking systems based on 
placing markers in the scene have been highly 
successful[1][2]. Markers are constructed so that they are 
easily detected in each image frame and given some a priori 
information about the shapes or positions of the markers, the 
relative pose of the camera can be easily determined. 
However, these markers traditionally consist of a set of small 
white and black squares and are not good looking.  In 
addition, camera tracking can be easily lost as it is only based 
 
Manuscript received March 19, 2011; revised April 15, 2011. This work was 
supported in part by National Science Council, R.O.C., under grant NCS 
99-2220-E-327-001.  
Jia-Hong Lee. Author is with Information Management Department, the 
National Kaohsiung First University of Science and Technology, 2 Jhuoyue 
Rd., Nanzih, Kaohsiung City, 811, Taiwan (corresponding author, phone: 
886-7-6011000; fax: 886-7-6011069; e-mail: jhlee@ nkfust.edu.tw).  
Mei-Yi Wu. Author is with General Education Center, National 
Kaohsiung University of Hospitality and Tourism. No.1, Songhe Rd., 
Xiaogang Dist., Kaohsiung City 81271, Taiwan (e-mail:barbara 
@mail.nkuht.edu.tw) 
Tzu-Hao Tseng. Author is with Information Management Department, 
the National Kaohsiung First University of Science and Technology. 
. 
on a few features and there is a limited range of camera 
viewpoints from which the markers are visible. In 
comparison, systems based on natural features, e.g., corner 
points in the scene extend the tracking range and are typically 
more stable as there are more features available to track the 
camera pose from. But it costs much time in computing the 
large features.  
 
 
 
Fig. 1. An example of animated newspapers in Harry Potter 
films. 
 
In this work, we have developed a framework of video 
news system based on augmented reality techniques. The 
system can play video films like the animated newspapers in 
Harry Potter films. Figure 1 shows the example in Harry 
Potter films. The pictures on newspapers were regarded as 
augmented reality markers and we can continuously add a 
video image frame using image segmentation and augmented 
reality techniques. Image segmentation operations include 
thresholding, distorted angle detection and window Hough 
transform are applied to figure out the shapes and positions of 
pictures. We divided the picture with many sub-blocks of the 
same size and compute the image features in each block to 
form a feature histogram. The frequencies of corner points 
appeared in different regions in pictures are used as features 
to identify different pictures. Then an efficient corner 
tracking with HMMD descriptor is performed to dynamically 
figure out the position of the distorted picture and add the 
video news image frame on the captured image by camera on 
real time.  
The overall structure of the proposed system including 
skew angle detection of newspapers, corner detection, 
four-point mapping, image recognition and picture tracking 
is described in Section 2. The related experiments are shown 
in Section 3. Section 4 shows the conclusion of the proposed 
system. 
 
 
 
A Framework of Video News System Using 
Image Segmentation and Augmented Reality 
Jia-Hong Lee, Mei-Yi Wu and Tzu-Hao Tseng 
M 
Video play 
region 
Proceedings of the World Congress on Engineering 2011 Vol II 
WCE 2011, July 6 - 8, 2011, London, U.K.
ISBN: 978-988-19251-4-5 
ISSN: 2078-0958 (Print); ISSN: 2078-0966 (Online)
WCE 2011
 with length b. Also, let us assume that the origin of the 
coordinate system is located in the center of the rectangle, as 
shown in Figure 4(a). The corresponding result after Hough 
Transform is shown in Figure 4(b). 
   
(a)                                         (b) 
 
Fig. 4.  An example of windowed Hough Transform.  
 
It can be observed that these four peaks satisfy the 
following geometric relations: 
1. They appear in pairs: the first one is formed by peaks L1 
and L2, at θ = α1; the second one is formed by peaks L3 
and L4, at θ = α0. 
2. Two peaks belonging to the same pair are symmetric with 
respect to the θ axis, i.e., ρ1 + ρ2 = 0 and ρ3 +ρ4 = 0.  
3. The two pairs are separated by Δθ = 90◦ in the θ axis, i.e., 
|α1 − α0| = 90◦. 
4. The heights of two peaks within the same pair are exactly 
the same, and represent the length of the respective line 
segment, i.e., C(ρ1, θ1) = C(ρ2, θ2) = b and C(ρ3, θ3) = 
C(ρ4, θ4) = a.  
5. The vertical distances (ρ axis) between peaks within each 
pair are exactly the sides of the rectangle, i.e., ρ1 − ρ2 = w 
and ρ3 − ρ4 =h.  
 
However, in our application, a picture shape in the captured 
image frame by the camera will become a distorted rectangle. 
To solve this situation, we modified the above geometric 
relations as |α1 − α0| = 90◦ + Tθ,  ρ1 − ρ2 = w ± Tw  and ρ3 − 
ρ4 =h ± Th, where Tθ, Tw and Th are threshold values for 
distortion tolerance. Finally, we can decide the four corner 
points from the obtained four lines of a distorted rectangle. 
Figure 5 is an example of A distorted rectangle and the result 
after Hough Transform. 
   
 
 
Fig. 5.  A distorted rectangle and the result after Hough 
Transform. 
 
D. Four-point transformation 
The quality of the calibration step has a significant 
influence on the image overlay of   video news. In order to 
achieve the augmented reality goal to show the video news 
pasted on the captured distorted picture of a camera, a 
four-point transformation[5] to convert a video image frame 
to fit the shape of distorted picture is performed using the 
following equations. 
To map from an arbitrary sequence of four 2D points 
(x1,y1), (x2,y2), (x3,y3),(x4,y4) to a set of corresponding 
points(x1’,y1’), (x2’,y2’), (x3’,y3’), (x4’,y4’), the transformation 
requires eight degrees of freedom. The projective 
transformation can be expressed as a linear mapping in 
homogeneous coordinates: 
 
  
  
  
   
    
    
  
   
         
         
       
  
 
 
 
                            (1) 
We can find the eight unknown transformation parameters 
a11,…,a32 by solving a system of linear equation. 
,
,
3231232221
3231131211
iiiiiii
iiiiiii
yyayxaayaxay
xyaxxaayaxax


                             (2)                                     
An alternative method for finding the eight parameters for a 
given set of image points is to use a two-stage mapping 
through the unit square, which can avoid iteratively solving a 
system of equations.  
        
             
            
           
                  
  
          
  
      
  
                
  
  
                
  
  
                    
        
  
  
                    
        
                                        
  
                
  
  
                
                                                  (3) 
 
The set of equations has the following solution for the eight 
unknown transformation parameters: 
    
   
    
    
    
      
    
      
    
    
    
      
    
  
   
    
      
    
      
    
      
    
  
) 
    
   
    
    
    
      
    
      
    
    
    
      
    
  
   
    
      
    
      
    
      
    
  
 
      
    
        
   
      
    
        
  
        
    
      
    
        
   
      
    
        
  
      
                                                                          (4)       
 
Figure 6 shows an example to convert a distorted image into a 
square shape image using the above four-point mapping.  
 
 
 
                     (a)                                     (b) 
 
Fig. 6.  An example of four-point transformation. (a) the 
image taken by a webcam (b) the calibrated image using the 
four-point transform. 
Proceedings of the World Congress on Engineering 2011 Vol II 
WCE 2011, July 6 - 8, 2011, London, U.K.
ISBN: 978-988-19251-4-5 
ISSN: 2078-0958 (Print); ISSN: 2078-0966 (Online)
WCE 2011
  
  
(A) Original image 
 
   
(B) Blur image by Gaussian filter (σ=3) 
 
   
(C) Calibrated image by four-point mapping 
 
   
(D) Baboon 
 
 
(E) Girl 
 
(F) Jet 
Fig. 8.  Test images and their corresponding Harris corner 
point histograms using the proposed method.  
 
 
 
 
 
 
TABLE I 
 THE DISTANCES BETWEEN DIFFERENT IMAGES 
 
 A B C D E F 
A 0 4.34 4.59 11.56 7.12 6.20 
B 4.34 0 1.37 11.20 6.42 6.64 
C 4.59 1.37 0 11.21 6.07 6.92 
D 11.56 11.20 11.21 0 9.29 9.53 
E 7.12 6.42 6.07 9.29 0 6.35 
F 6.20 6.64 6.92 9.53 6.35 0 
 
The histogram of Baboon seems to be very different to 
other histograms. Figure 9 shows the locations of Harris 
corner points which are divided into 16 blocks. The 
distribution of corners are not uniform, most corner points 
appeared at the upside of image. If we order these blocks in 
horizontal scan from up to down, most points are located in 
the first and fourth blocks and just few points are located in 
the fifth and sixth blocks.  
 
 
Fig. 9. The locations of Harris corner points for image 
Baboon. 
 
C. Augmented reality video news 
Once the picture is identified, the system will track the four 
corner points of this picture to add the corresponding video 
image frame on it. Figure 10 is an example to display the AR 
video news using the proposed system. Figure 10(b) shows 
the picture extraction using the proposed image segmentation 
method. Figure 10(c) is the calibrated image converted from 
the distorted image of Figure 10(b) using four-point mapping. 
Figure 10(d) is the Harris corner point histogram of the 
gray-level image in Figure 10(c). Figure 10(e) is the video 
image frame and the image is converted into distorted form 
after inverse four-point mapping and add to the original 
captured picture. The result of augmented reality is shown in 
Figure 10(f). 
 
0
100
200
300
400
1 3 5 7 9 11 13 15
0
100
200
300
400
1 3 5 7 9 11 13 15
0
100
200
300
1 3 5 7 9 11 13 15
0
200
400
600
800
1 3 5 7 9 11 13 15
0
100
200
300
400
1 3 5 7 9 11 13 15
0
100
200
300
1 3 5 7 9 11 13 15
Proceedings of the World Congress on Engineering 2011 Vol II 
WCE 2011, July 6 - 8, 2011, London, U.K.
ISBN: 978-988-19251-4-5 
ISSN: 2078-0958 (Print); ISSN: 2078-0966 (Online)
WCE 2011
國科會補助計畫衍生研發成果推廣資料表
日期:2011/10/31
國科會補助計畫
計畫名稱: 智慧型擴增實境技術與平台建置之研究
計畫主持人: 李嘉紘
計畫編號: 99-2220-E-327-001- 學門領域: 自由軟體暨嵌入式系統
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
1.合著論文 Inverse Halftoning Method Using Pattern Substitution Based 
Data Hiding Scheme， 
  獲得 WCE 2011, London UK,  Certificate of Merit 的論文獎 
 
2. 指導學生參加專題競賽獲 
   育秀盃軟體應用 PC 組佳作 
 
3. 指導學生參加專題競賽獲 
   南區技專院校實務專題競賽  文化創意組  第一名 
 
 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
