be both objectionable and benign depending on their context (e.g., wren tits, wood screws, breast cancer).
Third, many objectionable sites (e.g., pornography sites) embed words in images to elude text-based analysis.
1.1 MORF Architecture
To overcome the shortcomings of the traditional URL- and text-based approaches while maintaining high
filtering efficiency (the filtering activities should not significantly affect network access time and throughput),
MORF employs classifiers of multiple layers and of multiple modalities. Figure 1 presentsMORF ’s functional
units including the access point unit, filtering engine, site cache, classifier (the focus of this proposal), update
unit, user interface, and the report generator. The access point unit receives incoming requests to MORF .
A received request is forwarded to the filtering engine, which decides whether the request should be granted
or denied by first consulting the site cache (i.e., the URL cache). If the requested site does not appear in the
URL cache, the filtering engine 1) queries the classifier to classify the site, 2) updates the site cache, and 3)
returns the permit/deny decision. The update unit of MORF multicasts and synchronizes new URL entries
to and from the other MORF systems. The user interface allows users to provide feedback for personalizing
the filtering criteria. Finally, the report generator compiles traffic statistics.
The core of MORF is the classifier, which consists of three layers: a confidence-based classifier, a
Cross-bagging ensemble scheme, and a multimodal integrator. The confidence-based classifier outputs a
class prediction, together with the classifier’s confidence in that prediction. Both prediction and confidence
level are then fed into the Cross-bagging scheme, which organizes training data into multiple bags and
distributes training data judiciously into these bags. The design goal of Cross-bagging is to make mutually
exclusive errors among bags, if a prediction error does occur. Cross-bagging needs just a small number of
confidence-based classifiers to achieve a high prediction accuracy. Finally, a multimodal integrator aggregates
predictions from the image ensemble and text ensemble to make the final class prediction at the Web-site
level. Figure 2 shows the layered component diagram of MORF .
2 Performance Report
Our empirical study is designed to answer the following questions:
1. How many bags should be used and what sampling strategy works the best for Bagging?
2. Can a Cross-bagging ensemble scheme outperform the traditional Bagging scheme in classification
accuracy and training time?
3. Can the confidence factor (CF) help to reduce prediction errors?
4. Can a multimodal classifier perform better than a single-modal classifier in filtering objectionable
websites?
A set of images are obtained by crawling the Internet, and their classes (objectionable/benign) are then
manually assigned. For our image dataset, we randomly select 20, 000 objectionable images to be positive
examples, and 20, 000 benign images to be negative examples. We further pick 10% (4000 images) of the
2
image dataset to form our cross-validation test set while the remaining 36, 000 images form the training set.
For characterizing an image, we extract a set of features. These features include color histograms, color
means, color variances, color spreadness, color-blob elongation, and texture features in three orientations
(vertical, horizontal, and diagonal) and three resolutions (coarse, medium, and fine) [LCL01, TC01]. Previous
works on pornographic image detection can be found in [FF99, WWF97].
2.1 Results of Traditional Bagging with Different Sampling Criteria
We first examine the optimal number of bags and the sampling strategy for Bagging, which we will use for
Cross-bagging. Figure 3(a) shows the accuracy of Bagging using the sampling-with-replacement policy, and
Figure 3(b) is for the sampling-without-replacement policy. The x-axis shows the number of bags used (from
one to five) while the y-axis shows the rate of prediction error. We plot the curves for various sampling
percentages ranging from 10% to 80%. Figure 3 shows that generally the error decreases with an increase in
the number of bags, or in the sampling percentage. In addition, sampling without replacement consistently
produces fewer prediction errors than sampling with replacement.
The change in sampling percentages affects the two policies differently. In Figure 3(a), we see that as the
sampling percentage increases, the error rate drops. For sampling percentages greater than 20%, the drop is
more gradual, implying that the error rate does not reduce in proportion to the increase in training samples.
However, in Figure 3(b), while a higher sampling percentage tends to have lower error rates (compare 40%
with 20%), the reduction is not consistent as the sampling percentage is further increased. For example,
when only two bags are used, 60% sampling gives the lowest error rate (∼ 8.6%), whereas 40% sampling
gives the lower error rate (∼7.4%) for three bags.
To observe the effects of sampling rates on error rates more clearly, we plot the prediction error against
the sampling rate (Figure 4). Similar to the observation made above, Figure 4(a) shows that the error
rate consistently decreases as the sampling rate is increased, whereas Figure 4(b) shows that increasing the
sampling rate does not always lead to a lower error rate (lowest error rate occurs when sampling rate is
40% for three or more bags). This observation reinforces a recent finding [FH99] which shows that a policy
of half-sampling without replacement is equivalent to conventional bootstrapping. In our case, bagging
benefited from the sampling without replacement policy by requiring fewer training samples (40% sampling
rate).
2.2 Results of the Cross-bagging Ensemble
Scheme
Figure 5 shows the prediction performance of our Cross-bagging ensemble scheme. The x-axis shows the
number of iterations Cross-bagging is performed, and the y-axis shows the error rate for each round. We
sample one 10% set and another 40% set from the training population to form two starting training sets.
Each training set consists of three bags of classifiers. The bags of classifiers are then used to form predictions
for our testing set. We then apply Cross-bagging for five iterations on both training samples. We plot the
error rates for both the training samples and the test set.
We observe that the training error rate for both sampling rates decreases logarithmically. The testing
4
77.5
8
8.5
9
9.5
10
10.5
11
11.5
12
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8
Cl
as
sif
ica
tio
n 
Er
ro
r (
%)
sampling rate
1 bags
2 bags
3 bags
4 bags
5 bags
(a) sampling with replacement
7
7.5
8
8.5
9
9.5
10
10.5
11
11.5
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8
Cl
as
sif
ica
tio
n 
Er
ro
r (
%)
sampling rate
1 bags
2 bags
3 bags
4 bags
5 bags
(b) sampling without replacement
Figure 4: Prediction Error vs. Sampling Rate for Traditional Bagging.
2.3 The Advantage of Multimodality Design
We can increase filtering effectiveness by using an image classifier as a lexical disambiguator. By employing a
multimodal analysis and a good classifier (such as the Cross-bagging scheme), our information filtering system
MORF is able to perform accurate classifications. Our next experiment compares the filtering accuracy of
various filtering techniques using a 30-day web access log from MORF testing sites in the United States and
Asia. The log contains a history of 103.2 million web access requests to 25,371 different websites, of which
1,266 sites were considered pornographic.
Due to legality issues, we are forbidden to present comparison of our results to those of commercial
filtering systems in this paper. We compare the filtering accuracy of our proposed multimodality techniques
to that of URL-based, keyword-based, and image-based techniques. The result in Figure 8 shows that using
the URL-blocking list alone (using an unnamed commercial filtering software) produces the highest filtering
error (greater than 50%). The reason for this high error rate is that the URL-based technique relies on a URL-
block list which is often obsolete. In contrast, the keyword-based technique produces a 33.4% filtering error.
In this case the high error rate can be attributed to the absence of keywords on many of the objectionable
sites. Another reason is that many of the objectionable sites used in this experiment are written in languages
other than English. Nonetheless, the low accuracy of the keyword-based technique strongly suggests the need
to use information other than text content for filtering purposes. The image-based filtering technique uses
6
