 2
omni-directional and PTZ cameras, the objective of 
this project is to achieve the human detection as well 
as activity recognition.  
As for human detection, this work presents a 
semantic-driven human detection algorithm, which 
integrates global template and local features built of 
Histogram of Oriented Gradients (HOGs).  Firstly 
we use distance transform to analyze distances 
between training samples and human appearance 
contour template, in order to obtain a classifier 
based on human outline features. At the training 
stage, the global outline feature will be coordinated 
into the Adaboost framework with the HOGs-based 
local features. We make a novel human classifier by 
dynamic tuning the hyper-plane of the support 
vector machine to combine both global and local 
features. Meanwhile, we effectively solve problems 
from complex backgrounds or occlusion-related 
phenomena. The experiment shows that the 
presented framework can improve the HOGs-based 
algorithm to a high degree. 
For activity recognition, this work proposes a 
frame work that combines mid-level shape and 
motion features to overcome the scaling, 
illumination variation, occlusion and action diversity. 
The figure-centric images are extracted from the 
input frames by template matching method. In our 
approach the SAD (Sum of Absolutely Differences) 
is used to represent the object’s motion, and the 
shape is represented by the HOG (Histogram of 
Gradients). We promote the low-level shape feature 
to the mid-level one in order to encode more 
semantic information. The AdaBoost algorithm is 
employed in learning the discriminative features for 
the shape and motion classifiers. The combination of 
the shape and motion classifiers is achieved by using 
support vector machine. We perform the 
experiments on KTH dataset, and experiment results 
show that our proposed framework can achieve the 
higher accuracy rate. 
二、研究動機 
 人類活動感知(Human Activity Perception)為
目前影像監控系統中(Surveillance System) 重要
核心技術之一，主要目的在辨識環境中之人類活
動類別，以作為系統提供後續服務或啟動相關機
制之重要決策依據。智慧型環境應用(Intelligent 
Space)主要藉由感知居住者活動狀態，自動調整環
境狀態以符合使用者需求，例如:啟動空調、撥放
音樂或開啟電視，使居住者感受到舒適與放鬆；
老人健康照護應用中(Health Care)，藉由辨識老年
人活動狀態，當不尋常行為(Abnormality)發生時，
例如：跌倒或日常生活習慣改變，系統可連繫醫
護人員以迅速提供相關醫療服務與諮詢。 
    應用電腦影像處理技術於多攝影機系統進行
無間隙人類活動感知技術已成為當前潮流。於此
研究計畫中，基於下列三項假設:(1)所有相機皆固
定不動 (Static) ； (2) 影像皆可同步擷取影像
(Synchronized)。(3)相機網路系統其視野涵蓋所欲
監控之範圍，進行人類活動感知辨識。延續去年
整合全景攝影機資訊與PTZ攝影機所獲得之前景
影像(Foreground Object)，進行人形偵測(Human 
Detection)以及活動辨識(Activity Recognition)。 
三、語意驅動式 HOG 行人偵測 
行人偵測於文獻上仍一個深具挑戰的研究主題，
其主要原因約略可區分為： (1)多變的姿態與外觀
(2)複雜的背景(3)遮蔽效應(4)攝影機狀態。而依據
所選用之特徵差異，人形偵測演算法大致上可三
類：全域特徵(Global)、區域特徵(Local)與結合全
域與區域特徵(Hybrid)。區域特徵是從影像中小區
塊的特徵點提取而來，再由機器學習的演算法結
合，因為每個分類器評估的範圍很小，所以容易
受雜訊影響；全域特徵在實質上能夠對應到人體
部位，具有語意上的意義，因為一次評估較大的
範圍，所以不易受雜訊影響，但卻需要足夠的資
訊才能進行判斷，容易受部分遮蔽影響。如何整
合全域與區域特徵，補足兩者優缺點，是本研究
主要探討的議題。 
 近年來結合機器學習法的區域特徵逐漸成為
人形偵測的主流 [1] ，在區域特徵方面， P. 
 4
3.2 全域分類器 
    使用行人全身外觀輪廓作為全域特徵，並採
用距離樣板比對(DT-Based Template Matching)[5]
作為輪廓相似程度的衡量方法。而用來做為全域
偵測器的判斷準則是從實驗中獲得，首先以樣板
比對計算訓練樣本的比對分數，統計正樣本與負
樣本的分數分布，最後決定出全域分類器之門檻
值。樣版產生流程如圖二所示。首先從資料庫中
選取四百張行人影像，並把每張影像轉換成梯度
(Gradient) 影 像 ， 再 計 算 各 自 的 梯 度 大 小
(Magnitude)，最後將所有影像加總後平均後得到
的行人平均梯度大小影像(Average magnitude)。所
建構之人形輪廓樣版，影像中亮度較高之區域代
表人行邊緣輪廓存在機率較高，可以區分出人類
的頭肩、雙手與雙腳。最後透過反向二值化處理，
做為所產生之行人樣板(Template)，如方程式(1)
所示，當平均梯度影像 大於門檻值時輸出 0，代
表特徵點；反之則輸出 255，代表背景。 
0,  if  
( )
255,              
AverageMag
Mag
I Threshold
T I
otherwise
 
 (1) 
CBCL images
Gradient Magnitude Summation
Average Threshold
TemplateAverage 
Magnitude  
圖二、樣板產生流程 
    基於上述之人形樣板，樣板比對流程如圖三
所示，首先將測試影像經過邊緣提取與二值化處
理後，轉換為距離影像，再與全身行人樣板做比
對，比對分數估算方式如(2)所示，其中T 為訓練
所得之人形樣板影像； I 為經過邊緣提取與距離
轉換後得到距離影像；t 則是樣板影像中之像素點。
接著取 CBCL 行人資料庫的行人影像 462 張與
INIRA[31]資料庫的背景影像 1000 張進行樣板比
對實驗。並統計人形影像與非人形影像比對分數
分佈圖(如圖四所示)。最後找到一個門檻值，使其
分類誤差最小，作為全域分類器之門檻值，本研
究中其值為 1,400，而全域分類器之判斷方程式如
(3)所示。 
( , ) ( )chamfer I
t T
D T I d t

  (2) 
,  if ( , ) 1400
GlobalResult
- ,   
chamfer globalHuman D T I T
Non Human otherwise
 
 (3) 
T
Iorigin Edge I
Matching 
Score
Mapping Summation
 
圖三、樣板比對流程圖 
 
圖四、樣板比對分數分佈圖 
3.3 語意驅動式 HOG 訓練階段 
    基於 Adaboost 演算法的機器學習應用於行人
偵測，先準備兩組分別標明屬性的訓練樣本
(Positive Samples and Negative Samples)，使用
HOG 特徵區塊對不同位置的影像資料做取樣，分
別用 SVM 產生弱分類器。當前置步驟完成後便進
入 Adaboost 程序，賦予所有訓練樣本各自一個樣
本權重，這個權重代表著分類的難易度，權重越
大則越難分類。接下來進入弱分類器挑選流程，
將結合人形輪廓全域特徵與 HOG 區域特徵，首先
用所有的弱分類器去測試包含正負樣本的訓練樣
本集(Training Sample Set)，若是分類錯誤則累加
樣本所擁有的樣本權重，累加結果在此定義為錯
誤率(Error Rate)，所有的弱分類器都得到一個專
屬的錯誤率後，從中挑選出擁有最小錯誤率的弱
分類器作為本回合的最佳弱分類器。 
 接著進入弱分類器調整階段，首先使用全域
0
10
20
30
40
50
60
70
80
1 3 5 7 9 11 13 15 17 19 21 23 25 27 29
Nu
m 
of 
im
ag
es
Matching score
Pos Neg
 6
測試，其詳細規格如表二所示。CBCL 資料庫人
形影像姿態較為單純，僅包含正面與背面姿態，
且沒有提供非人行樣本；INIRA 資料庫提供 1126
張單一人形影像，288 張原始比例之複數行人影
像，212 張非人形訓練影像與 453 張非人形測試
影像。由於樣本解析度為 70x134，與其它資料庫
合併實驗時會正規化至至解析度 64x128；CVC 資
料庫正樣本集提供較多側面站姿之人形影像，且
每張圖片有對應水平翻轉圖，及上下位移圖與翻
轉之位移影像，負樣本集提供解析度 640x480 之
2048 張無人街道背景圖。 
表二、人形影像資料庫 
 Pos Neg 
資料庫 張數 解析度 姿態 張數 解析度 
CBCL 924 64x128 正/背 無 無 
INIRA 1126/288 70x134/原
比例 
正/背/側 212/453 原比例 
CVC 3356 48x96 正/背/側 2048 原比例 
    為驗證所提出之 SemanticHOG演算法之可靠
度，於此研究中設計兩大組實驗，詳細資料分別
如表三與表四，訓練樣本統一採用 462 張 MIT 行
人影像作為正訓練樣本，訓練負樣本使用 1000 張
INIRA 隨機挑選影像，HOG 特徵區塊大小為
16x16 單一比例，SVM 的逞罰常數(Cost)設為 1，
並且預設 40 個回合的 Adaboost 訓練。 
 效能分析部分主要採用 ROC Curve 來觀察偵
測率與誤判率之間的關係。圖六使用 HOG 與我們
的方法對 C1 到 C3 進行實驗，圖七則是對 C4 到
C6 進行實驗。強分類器由 40 個弱分類器組成，
並且 Cost 設定為 1，每次調整 Adaboost 的最終決
策門檻值，從-40 到+40，橫軸為誤判率或 False 
Positive，縱軸則是偵測率或 True Positive，曲線
會呈現嚴格遞增，越往左上角彎曲代表低誤判率
的情況下有高偵測率，因此效能越好。C1 與 C4
是接近完美的曲線，這是由於使用來訓練與測試
的樣本集組成相同；C2 與 C3 使用較困難的樣本
集，因此曲線離左上角較遠；另外 C4、C5 與 C6
是經過全域特徵挑選，較具有行人輪廓特徵，較
容易辨識，離左上角較近。 
 
表三、實驗組合 C1~C3 
 Train Test 
Pos Neg Pos Neg 
C1  
MIT 462 
 
INIRA 1000 
MIT 462 INIRA 1359 
C2 CVC 3356 CVC 2048 
C3 INIRA 1126 INIRA 1359 
表四、實驗組合 C4~C6 
 Train Test 
Pos Neg Pos Neg 
C4 
MIT 462 INIRA 1000 
MIT 316 INIRA 1359 
C5 CVC 571 CVC 2048 
C6 INIRA 182 INIRA 1359 
 
圖六、ROC Curve C1~C3 
圖七、ROC Curve C4~C6 
 
0.5
0.55
0.6
0.65
0.7
0.75
0.8
0.85
0.9
0.95
1
0 0.2 0.4 0.6 0.8
HOG C1
HOG C2
HOG C3
Our C1
Our C2
Our C3
0.5
0.55
0.6
0.65
0.7
0.75
0.8
0.85
0.9
0.95
1
0 0.2 0.4 0.6 0.8
HOG C4
HOG C5
HOG C6
Our C4
Our C5
Our C6
 8
0
90
180
270
1 122 
1.0
2.0
1
1
2
k
0
90
180
270
0
90
180
270
0
90
180
270
 
圖九、系統訓練流程圖 
4.2 特徵擷取與表示 
    為有效區分各類動作，需選取有效之特徵表
示出各種動作的差異性，在[19]、[22-23]中皆以光
流偵測為運動特徵，但由於光流偵測計算量龐大，
且易受到雜訊影響，造成其值有所誤差。故本研
究在運動特徵部份採用於 H.264(JPEG)動態估測
中 廣 範 使 用 之 特 徵 SAD(Sum of Absolute 
Difference)，在 JPEG 應用中絕對誤差和是用來計
算兩張影格中最相似之區塊，減少壓縮量；於本
研究中 SAD 影像為藉由相鄰影格相減所得之影
像，此方法相較於光流偵測之主要優點為實作容
易且可有效描述兩張影像運動特徵。當計算得出
置中影像後，將相鄰影格之置中影像做 SAD 之運
算， 藉由 SAD 和影像表示出兩張影像具變化之
位置及其變化之大小。首先以 代表影像置中陣列
中的時間 t 之影像，以 代表時間 t-1 影像，對兩
張影像每個像素點做相減對其差值取絕對值，如
方程式(4)所示： 
(4)     ),(),(),( 1 
x y
tt yxIyxIyxD
   
    由於一般動作有其連續性，因此若僅以兩影
格相減取得之 SAD 影像作為運動特徵，並無法完
整有效描述動作之運動特徵，故本研究中主要描
述方式為將十張SAD影像乘上高斯權重後加總，
加強運動特徵之時間關聯性，意即將 10 個影格
之 SAD 影像依據時間之排序乘上高斯分佈加總
後產生時間關聯性更強之 SAD 影像。 
   相較於其他人形外觀特徵，分析結果為 HOG
較能克服行人外觀之變化及光影變化，並能夠有
效描述人形形狀。HOGs 計算方式為估算其梯度
強度及方向： 
),1(),1(),( yxIyxIyxd x        (5) 
)1,()1,(),(  yxIyxIyxd y       (6) 
22 ),(),(),( yxdyxdyxm yx       (7) 
),(
),(
tan),( 1
yxd
yxd
yx
x
y
            (8) 
接著將每個區塊分為四單元(Cell)(如圖十左圖所
示)，於每一單元中，我們統計其梯度強度在不同
九個方向之長條圖(Histogram)，每 40 度為一個方
向。換言之，一個 9 維向量 },....,,{ 921 vvv 可表示一
個單完的外觀；一個36維向量 },...,,....,,{ 36921 vvvv (分
別對應至四個單元如圖十右圖所示)可用來表示
一個區塊的外觀，此表示法稱為 HOGs。 
 
圖十、HOGs 特徵表示過程 
4.2 分類器學習與動作辨識 
進階HOG特徵生成器訓練流程將其正規化為
置中影像以密集表示法切割為 k 個相同大小之矩
形區塊，以 i 表示置中影像中第 i 個區塊， 
},...2,1{, kiWi  ，對區塊 i 以HOG特徵表示，
每 個 區 塊 內 HOG 底 層 特 徵 (Low-level HOG 
Feature)表示如等式 (9)所示，底層形狀特徵
(Low-level Shape Feature) )( jfi ，其表示為 i 之第
j維形狀特徵即HOG之統計區間，假設其最大維度
為m。 
(9)    }},...,2,1{},,...,2,1{:)({ mjkijfF i   
    進階特徵 HOG 建構概念為將區塊 i 內之
 10
之外，拍手、拳擊、走以及慢跑之辨識正確率皆
較其餘兩分類器高，且走路此動作類別之辨識率
更是達到百分之九十一，就整體之辨識率而言，
其辨識結果獲得有效提升。 
 
圖十二、人類活動辨識結果 
五、參考文獻 
[1] D. Geronimo, A.M. Lopez, A.D. Sappa, T. Graf, “Survey 
of Pedestrian Detection for Advanced Driver Assistance 
Systems,” IEEE Trans. on Pattern Analysis and Machine 
Intelligence, Vol. 32, Issue 7, pp. 1239-1258, July 2010. 
[2] P. Sabzmeydani, G. Mori, “Detecting Pedestrians by 
Learning Shapelet Features,” IEEE Conf. on Computer 
Vision and Pattern Recognition, pp. 1-8, June 2007. 
[3] S. Belongie, J. Malik, “Matching with Shape Contexts,” 
IEEE Workshop on Content-based Access of Image and 
Video Libraries, pp. 20-26, 2000. 
[4] P. Viola, M. Jones, “Rapid object detection using a 
boosted cascade of simple features,” IEEE Computer 
Society Conf. on Computer Vision and Pattern 
Recognition, Vol. 1, pp. 511-518, 2001. 
[5] N. Dalal, B. Triggs, “Histograms of Oriented Gradients for 
Human Detection,” IEEE Computer Society Conf. on 
Computer Vision and Pattern Recognition, Vol. 1, pp. 
886-893, June 2005. 
[6] Qiang Zhu, Mei-Chen Yeh, Kwang-Ting Cheng, S. 
Avidan, “Fast Human Detection Using a Cascade of 
Histograms of Oriented Gradients,” IEEE Computer 
Society Conf. on Computer Vision and Pattern 
Recognition, Vol. 2, pp. 1491-1498, 2006. 
[7] Qing Jun Wang, Ru Bo Zhang, “LPP-HOG: A New Local 
Image Descriptor for Fast Human Detection,” IEEE Int. 
Symposium on Knowledge Acquisition and Modeling 
Workshop, pp. 640-643, Dec. 2008. 
[8] D.M. Gavrila, “A Bayesian, Exemplar-Based Approach to 
Hierarchical Shape Matching,” IEEE Trans. on Pattern 
Analysis and Machine Intelligence, Vol. 29, Issue 8, pp. 
1408-1421, Aug. 2007. 
[9]  Duc Thanh Nguyen, Wanqing Li, Philip Ogunbona, “A 
part-based template matching method for multi-view 
human detection,” Int. Conf. on Image and Vision 
Computing, New Zealand, pp. 357-362, Nov. 2009. 
[10] Thanh Nguyen Duc, P. Ogunbona, Wanqing Li, “Human 
detection based on weighted template matching,”IEEE Int. 
Conf. on Multimedia and Expo, pp. 634-637, June 2009. 
[11] 蔡欣明，「結合形狀特徵之增強型方向梯度直方圖行人
偵測，」國立高雄第一科技大學電腦與通訊工程系，台
灣，2009 
[12] Zhihui Hao, Bo Wang, Juyuan Teng, “Fast Pedestrian 
Detection Based on Adaboost and Probability Template 
Matching,” Int. Conf. on Advanced Computer Control, Vol. 
2, pp. 390-394, Mar. 2010. 
[13] D.M. Gavrila, V. Philomin, “Real-time object detection for 
“smart” vehicles,” IEEE Int. Conf. on Computer Vision, 
Vol. 1, pp. 87-93, 1999. 
[14] INRIA Person Dataset, http://lear.inrialpes.fr/data 
[15] Weinland D., and Boyer, E.,” Action Recognition using 
Exemplar-based Embedding”,IEEE Conference on 
Computer Vision and Recognition, pp.1-7,2008 
[16] Shechtman, E.,and Irani, M.,”Space-Time Behavior Based 
Correlation”, IEEE Conference on Computer Vision and 
Recognition, vol. 1, pp.405-412, 2005 
[17] Xinghua Sun, Mingyu Chen, and  Hauptmann, A.,” 
Action Recognition via Local Descriptors and Holistic 
Features”, IEEE Conference on Computer Vision and 
Recognition, pp.58-65,2009 
[18] Tae-Kyun Kim, Shu-Fai Wong, and Cipolla, R.,” Tensor 
Canonical Correlation Analysis for Action Classification”,  
IEEE Conference on Computer Vision and Recognition, pp. 
1-8, 2007 
[19] Fathi, A., and Mori, G., “Action recognition by learning 
mid-level motion features “ IEEE Conference on 
Computer Vision and Recognition, pp. 1-8, 2008 
[20] Mikolajczyk, K., and Uemura, H., “Action recognition 
with motion-appearance vocabulary forest”, IEEE 
Conference on Computer Vision and Recognition, pp. 1-8, 
2008 
[21] Ali, S.,and Shah, M., “Human Action Recognition in 
Videos Using Kinematic Features and Multiple Instance 
Learning “, IEEE Conference on Pattern Anylasis and 
Machine Intelligence, vol. 32, pp. 288-303, 2010 
[22] Ikizler, N., Cinbis, R.G., and Duygulu, P., “Human action 
recognition with line and flow histograms”, IEEE 
Conference on Pattern Recognition, pp. 1-4, 2008  
[23] Yan Ke, Sukthankar, R.,and Hebert, M., “Spatio-temporal 
Shape and Flow Correlation for Action Recognition”, 
IEEE Conference on Computer Vision and Recognition, 
pp1-8, 2007 
 
0
0.2
0.4
0.6
0.8
1
Shape
Motion
Action
均有助益於研究上能夠更加精進。此外，在北京開會期間，也著實感受到中國對此相關領
域之企圖心，相對激發追求研究上之卓越與進步。 
 
三、考察參觀活動(無是項活動者略) 
略 
四、建議 
 參加國際研討會可使人開拓國際視野，在與專家學者交流過程中，更可有效驅使對自
我研究之檢討與調整，此亦為提升國內研究能量之重要方式。因此，教育部或國科會鼓勵
與補助國內學者，早日參與國際學術會議，開拓其國際視野並邁向國際。 
 
五、攜回資料名稱及內容 
1.會議手冊 
2.會議論文集光碟片 
99 年度專題研究計畫研究成果彙整表 
計畫主持人：黃世勳 計畫編號：99-2221-E-327-002- 
計畫名稱：基於多相機系統之無間隙人類活動感知技術(II) 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 1 1 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 1 1 100%  
研究報告/技術報告 0 0 100%  
研討會論文 1 1 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
