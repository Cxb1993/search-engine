 I 
中文摘要 
在電腦動畫的合成中，時常需要針對外在環境的改變、或人物之間的互動，來產生不
同的人物肢體動作。若要以動態捕捉技術產生相對應的動作，則需要表演者針對需求改變
而重新拍攝。此外，許多動作受限於捕捉儀器或是難度太高有危險性，無法以動態捕捉直
接獲得。為了克服這些問題，在此子計畫中，我們利用動態捕捉技術的優點，將擷取之動
作資料加以分析，產生動作向量空間，針對不同條件的改變產生出新的擬真肢體動作。 
 本報告的主旨在說明國科會專題研究計畫—「子計畫一：人物角色動作與臉部表情合
成技術之研究」的執行成果。本子計畫以三年的時間針對這個主題進行深入的研究，並發
展雛形系統： 
在人物角色動作方面，第一年我們提出了動作向量空間與動作轉移的方法，讓虛擬人
物可以自由地做出滿足不同條件限制的動作，並在兩種不同動作之間流暢地切換。而第二
年我們則是藉由整合反向關節力學Inverse Kinematics(IK)的技術進入我們的參數化合成之
中，來減少預先計算之動作數量並提高參數化的準確性。不僅如此，為了連貫所產生出來
的動作，對於無法串接的資料，我們提出以範例為基礎的貝茲內插，讓整個動作看起來更
為平順自然。至於第三年我們則是把目標放在如何自由地操控虛擬角色，藉由訓練樣本的
方式，分析人物角速度與動作的關係，當使用者揮動類似Wii的手把，即可透過內部陀螺儀
所給予的資訊，來重建出對應的動作。 
至於在臉部表情方面，由於目前的臉部動態捕捉技術僅能追蹤臉部特徵點，並無法捕
捉 細 微 的 皺 褶 變 化 ， 因 此 我 們 第 一 年 使 用 真 實 影 像 ， 在 高 維 空 間 中 利 用
shape-from-shading(SFS)的技術達成三維深度值之重建。我們提出利用時間與空間的關聯性
去計算連續圖像深度資料。為了解決SFS中固有不利條件的問題，我們使用Phong model來
表示物體表面的光源反射現象並以數值最佳化技術來逼近。當推算出特徵點與細微皺褶變
化的對應關係，我們即可產生由特徵點控制之具有細部表情之人臉動畫模型，以彌補現有
臉部動態捕捉資料之不足。第二年我們則是實作了Blend Shape的技術，來混合樣版資料，
合成出各種表情，但這種方式容易造成高頻資料的遺失。所以我們透過利用分群分層的樣
版資料，大幅度地減少所需的樣版資料數，並且保持高頻的細微資料，來讓臉部的特徵更
為明顯。至於在第三年的時候，我們則是進一步研究人臉影像中老化的變化機制，來創造
出更多樣性與可控制的臉部面孔。 
 
關鍵詞：人物動作合成、人臉動畫、動態捕捉技術、三維電腦動畫  
 III 
目錄 
報告內容 
摘要 ........................................................................ I 
Abstract ..................................................................... II 
目錄 .......................................................................IV 
一、前言 .................................................................... 1 
二、研究目的 ................................................................ 2 
三、文獻探討 ................................................................ 3 
四、研究方法 ................................................................ 11 
五、研究成果展示 ........................................................... 26 
六、結論 ................................................................... 32 
七、參考文獻 ............................................................... 33 
八、計畫成果自評 ............................................................35 
 
 2 
二、 研究目的 
本子計畫擬完成兩項主要目標，第一為角色動作的合成，第二為臉部表情的合成，且
分成三年將其逐步完成之，分年度簡述如下： 
第一年包含了動作混合、動作轉移與皺紋推估等三項研究，動作混合是為了讓玩家能
夠下達一些簡單的限制，讓虛擬角色可以滿足其要求，主要應用是在同一類動作上，使其
能夠合成出有多樣變化的同類動作出來；至於動作轉移則是為了讓兩種不同動作之間能夠
轉換得很平順，並且藉由既有資料庫來建立快速的查詢機制，以便套用在即時的遊戲上。
而皺紋的推估則是利用影像的光影變化，利用最佳化的方式來求得深度值，進而套用在臉
部的皺紋上，增加表情的細膩程度。 
第二年的研究目標則是提昇動作混合的精確度並讓動作轉移能夠即時變換。由於混合
出來的動作不見得能百分百滿足要求，於是我們使用反向關節力學來改變動作。此外，我
們希望發展出一套快速轉移機制，能夠讓虛擬角色在最短時間內就能夠變換成新的動作。
至於在臉部動畫方面則是希望表情合成能夠藉由拆解出高頻的資訊來保留細紋的變化，不
要因為使用混合的方式而讓細部的紋路被平均掉。 
第三年的目標則是希望嘗詴不同的操控人物方式，藉由結合綁定幾個 Wii 動作控制器
在手腳上，得到上面的角速度資料，能夠只靠這些資訊便反推出全身的姿勢。而對於同一
個角色的人臉動畫合成，除了表情的變化之外，另外就是歲月的摧殘會導致相貌有很大的
差異，因此我們希望能夠進行人臉的老化分析，讓一個人的各年齡的容貌都能被推估出來。 
 
 4 
則是將一組樣本動作所可以合成出來的參數空間當成是圖上的一個節點，然後利用取樣的
方式建立連結，便可將混合與轉接技術整合起來。 
上述的技術可以使得動態捕捉資料在相同環境限制下進行重組，對於在與不同環境的
互動這方面，Yamane[Yamane04]透過物體的路徑規劃(path planner)及限制性的反向關節運
動估計(constraint-based inverse kinematics)，合成出不同於原本資料庫的搬運動畫。路徑規
劃主要在規劃物體移動的位置及方向，然後再利用規劃後的物體資訊來尋找相對應的動
作。之後，他們使用反向關節運動作一些微調，以滿足使用者所設定的限制，並且同時保
持動作的自然。 
 
圖 3、Synthesized animations of manipulation tasks. [Yamane04]。 
而韓國的 Lee[Lee04]經由事先的計算，定義出人物角色所有可能的狀態以及該狀態可
以執行的動作，然後使用 dynamic programming 的方法建立一個查詢表格（look-up table），
當使用者給定了一些狀態後，系統便能有效率地利用查表的方式來找到其對應的動作。 
 
圖 4、從上而下分別為動作捕捉，學習擊打目標以及對打的動畫[Lee04]。 
Kovar 和 Gleicher [Kovar04]將大量的動態捕捉資料參數化並取樣(sampling)產生動作
 6 
根據建立的模型來幫動畫師做出動畫。 
 
圖 7、左邊為所編輯的動作，另兩個角色便跟著轉身。[Ikemoto09] 
3.2 重建 3D shape 
有關於重建 3Dshape 的論文方面，傳統的 photometric stereo 是在同一個表面上，利用
不同光源的亮度去計算表面的法向量。若單純只以三個不同光源的亮度去計算其法向量
時，結果將會相當不準確。因此 Weyrich 等人[Weyrich05]利用一個類似地球儀的裝置，它
具有 16 個數位相機，150 盞光源以及一個商業化的 3D 掃描系統，平均每秒可以拍出近百
張不同亮度的圖像出來，因此所做出來的結果相當不錯。但是 Weyrich 所提出的方法最大
的缺點便是實驗裝置太昂貴的問題，並非每一個人都可以做出如此的效果。Seitz 等人
[Seitz05] 提出 example-based photometric stereo 的方式去重建 3D 資訊。它利用
orientation-consistency 的觀念，也就是若兩個表面所具有的朝向是相同的話，那這兩個表面
必具有相似的法向量值。因此利用一個參考物體(例如:球)去找出相對應在目標物體(例如:
瓶子)上相同的朝向，便可以得到目標物體的法向量。雖然 Seitz 所提出的方法相當容易實
做，但是具有一些缺點，譬如目標和參考物體的材質必頇一致且它並不能處理自我陰影的
問題。 
我們所提出的方法是利用 Shape-from-shading(SFS)的技術來重建 3D 物體。SFS 可以避
免所謂像素對應的問題而且並不像傳統的 photometric stereo 的方式必頇利用多張不同亮
度，只需單一光源就可達到其不錯的效果出來。在相關性的論文方面，Fang 等人[Fang04]
提出一個使用簡化的 Lambertain 模型來計算出真實影像上的法向量，其主要論點是材質上
的合成，因此它所要求的法向量並不需要太準確，而且在計算法向量時需有人為的介入來
調整，才可以得到不錯的效果。Shape-from-shading(SFS)在對於真實影像的重建有一定的困
難存在，因為只根據單一光源且假設為 Lambertian 模型，所以算出的結果並不盡理想。為
了解決這個問題，Zeng 等人[Zeng05]利用人為的調整去指定法向量出來，然後使用 Fast 
Marching Methos(FMM)方式去加快 SFS 技術，並且根據這些輸入的法向量得到一個全域的
解。 
3.3 臉部表情合成 
 8 
其效果相當逼真，幾乎與真人無異，屬於發展較成熟的技術。但所產生出的動畫無法變更
光源環境、其視角亦受限制、難以與三維圖學場景結合。 
 
Q. Zhang 等人 [Zhang 2006]利用最佳化找出blend shape 中各prototype 的權重，我們的方
法也類似採用最佳化權重但是可以將高頻之細微掌握。 
相較於前者，以三維模型為基礎之人臉動畫則克服以上的缺點，可調整改變光源環境、
視角可自由控制並可直接融入三維圖形場景，因此廣泛地應用於電玩遊戲、電影特效與三
維動畫電影之中。在早期，K.Waters 與 D. Terzopoulos 等人提出了以內部肌肉模型驅動三
維人臉表面的方法[Waters 87][Terzopoulos90]，Wu 等人則提出了利用多層次表皮模擬皺紋
的產生方式[Wu99]。其概念上模仿人臉實際運動情況，然而，此方法在物理模擬上過於簡
略，且不易控制。之後，人臉動畫合成的趨勢逐漸改直接由實際的表演者臉上獲取三維資
料。 
近年來，國外最著名利用到追蹤技術合成人臉動畫的研究為 Microsoft Research 與 Univ. 
of Washington B.Guenter 等人做的"Making Faces" [Guenter98]。 他們在受測者的臉上貼上
182 個螢光標記點，利用六個不同角度之影像計算出標記點的運動軌跡。其研究中，他們
將所拍攝獲得的影像中的標記點去除，將所獲得的影像序列直接作為三維模型的動態紋理
(dynamic textures)，因此不需額外處理臉部細紋的部分。 
然而，此方法所獲得的細部表情影像是針對該受測者的，並不能應用在其他人臉模型
上(retargetting)。此外，這些細紋影像並沒有三維的法向量資訊，所產生的三維人臉動畫不
能改變光源的位置與強度。 
   
圖 10、 "Making Faces" by B. Guenter et al [GUEN 98]. 
在我們之前的研究中，我們提出了一套新的動態捕捉技術可以準確且平價地由鏡射多
 10 
重建後的三維模型套上特別的臉部表情，再重新繪製成影像。[BLAN 03] 
在 V. Blanz 等人的研究中，由於是採用雷射掃描器的關係，其方法只能擷取靜態表情
下的臉部深度資料，而沒有辦法捕捉在動態情況下的臉部皺紋變化。 
2004 年時，華盛頓大學的 L. Zhang 等人則提出一個能夠擷取三維動態細部表情變化的
方法[Zhang 04]。此方法利用了四部彩色攝影機及兩部黑白高速攝影機進行影像擷取，同時
使用了電腦視覺中結構光的技術 (structured-light reconstruction)，以兩部投影機在人臉上打
出不同粗細的光柵。他們根據光柵在不同深度的物體上會產生的不同的變形之特性，由多
視角拍攝到影像中條紋的形變，求出連續動作中臉部皺紋的細微變化。同時，由於連續影
像中的動作在極短時間中的一致性，由此項技術獲得的連續深度資料可以有不錯的準確
性。此研究亦由大量的動態人臉深度資料中學習，發展由控制點編輯臉部表情的 Face 
IK(inverse kinematics)技術。 
 
圖 13、在人臉上打上結構光以用來計算深度[Zhang04] 
(a) (b) 
圖 14、臉部深度資料(a)原始影像 (b)將擷取到的深度資訊去除雜訊後，套用到人臉模型上
[Zhang04] 
 12 



N
k
jikjkji qq
1
,,,, *
………………………………………………………….(1) 
其中 q 為關節點的朝向，以 Quaternion 來表示，i 代表第幾個畫格，j 代表第幾個關節，k
則代表第幾個樣本片段，N 為該類樣本片段的總數，α則是代表權重。 
4.1.2 動作轉移(Motion Transition) 
當動作混合的結果合成出來，或者是需要播放其他的動作時，我們便需要進行動作轉
移，才能夠很平順地從原本的動作切換到新的動作。這部分的技術一樣分為前處理與即時
合成兩大部分 
首先，在前處理的部分，我們拿出動作資料庫所有的動作，以單一畫格為單位，逐一
進行簡單的分群步驟，把相似的動作歸類在同一群。接著，我們紀錄屬於相同動作但是不
同組分群的動作順序，並且用此順序來當作增加連結邊(link edge)的參考資訊。 
然後，我們利用 dynamic programming 的方法，分別列出狀態轉換圖中任一節點到另一
節點所有可能的路徑，在求得所有的路徑之後，我們將結果按照成本進行排序，並且只取
前五條成本皆小於門檻值的最短路徑，以便之後的即時查詢能夠在最短時間內便找到最佳
結果。 
 
圖 16、動作轉移 
當需要動作轉換時，我們取出當前動作的最後一個姿勢，與目標動作的第一個姿勢(如
上圖)，分別找出兩者所隸屬的分群，然後經由查表來找出可能的路徑，然後利用這條路徑
的節點轉換順序，分別找出相對應的轉換動作，使其能夠平順地轉換。 
如果找不到任何路徑，代表動作資料庫中可能無合適的資料，或是該資料參雜過多無
謂的動作，此時我們使用一種改良過的貝茲曲線內插方式，它會參考我們所建立的狀態轉
換圖上節點的空間分布，然後找出一組控制點，將前後兩個動作平順地接合起來。 
若以下圖作為範例，如果要從最接近群組 A 的姿勢轉接到最接近群組 H 的姿勢，而它
們之間的距離為 D。於是以端點(群)為單位，從資料庫中一個一個端點去搜尋，希望能夠找
到一個端點，它的分群中心姿勢會盡可能地接近 A 的分群中心姿勢，同時它與 H 的分群中
心姿勢的距離會小於原本的 D。如同在前述擴展連結路徑中所提到，我們會事先把各端點
之間的差異程度(距離)事先計算並儲存好，以節省寶貴的時間。在下圖中，C 雖然最接近 A，
 14 
可以讓虛擬角色從前一個動作平順地轉換到下一個動作，除了可以讓使用者在不同組動作
混合中隨意切換，亦可銜接到一般的動作資料，讓角色有更豐富的動作與控制。 
為了達到這個目的，我們將當前動作的末 10 個畫格與目標動作的前 25 個畫格分別取
出，然後根據兩兩姿勢的差異程度來計算出距離矩陣（distance matrix），並找出其中的最小
值，而所對應到兩段動作的時間點就應該是最佳的接合點。然後，將前段動作後面超過最
佳接合點的動作資料與後段動作前面未及最佳接合點的動作資料全部捨棄，以達到更完美
的接合。 
 
圖 19、最佳接合點與最快速接合點 
雖然最佳接合點提供誤差最小的接合方式，但卻可能產生緩慢的動作轉換，為了同時
兼顧誤差與轉換速度，我們改找一個最快速接合點，離最佳接合點越遠越好，但與最佳接
合點的誤差必頇小於門檻值。若是遇上中間夾雜幾乎靜止的動作時，選用最快速接合點可
以直接跳過那些發呆的時段，結果將會比使用最佳接合點來得自然。 
4.1.4 精準動作混合 
不僅如此，我們也對動作混合技術提出了改良的方式。由於動作混合技術主要是利用不
同混合權重來達成參數化的機制，取樣的間隔會主宰樣本數的多寡，大量的樣本雖然可以
擁有高精確度，但卻耗費龐大的儲存空間；少量的樣本卻會導致精確度不足，以下面左圖
的拳擊來說，最後會有一點誤差。為了清除中間的誤差，我們最後使用反向關節運動力學
(Inverse Kinematics，IK)來調整動作，讓擊打的位置能夠完全吻合目標點。我們參考多種 IK 
的解法，最後決定使用 Selectively Damped Least Square 的方式來求得 IK 的解，它的優點
是能夠在很快的時間內收斂，並且在完全不可能達成碰觸點要求的情況下亦能夠盡量去逼
近目標。 
 16 
面對更為複雜的動作，一次項的變化性就比較缺乏，這點就十分明顯。 
因此我們將其換成使用二次多項式，以讓我們的結果能趨近實際數值。 
 
 
 
同時在使用的計算方法上也予以修正，改採用非線性最小平方法(Nonlinear least squares 
methods)及高斯牛頓法(Gauss-Newton methods) 
  
 
 
 
 
 
 
 
 
 
而後利用 MATLAB 處理矩陣運算後，算出的各項參數代回原多項式，再以五個主要紀
錄點的位置資訊為輸入，可以還原出其餘的非主要紀錄點，並發現如此推算出來的模擬動
作和原始動作十分相像。由此我們確定可以的確可以用多項式參數來反推出其餘各紀錄點
和全身動作。 
cXbXXa
i
ii
i
j
ij
iij 
  11
X 為主要紀錄點的三軸角速度值 
a 為二次項的參數 
b 為一次項的參數 
c 為常數項 
 
 18 
4.2.1 皺紋推估 
為了能夠解決 SFS 固有 ill-condition 的問題，我們利用最佳化的方式，去得到一個不錯
的結果出來。因此我們定義一個成本(cost)函數，為真實影像 I 與合成影像 S 平方差的和: 
 
2)(),( SIRVC
 
其中 V 為空間上的參數集合，為了能夠降低維度以及最佳化的效率，我們只調整 z 值
當作我們的空間參數。而 R 所表示的為 reflectance model 上的參數集合，在之後會再詳細
討論。因此我們希望能夠找出最佳的 V 和 R 的解去降低成本函數的值。 
)},(min{ arg**, RVCRV 
 
我們的成本函數具有兩個參數集合，V 以及 R。如果同時最佳化兩個參數集合的話，
必頇先猜測一個適合的初始條件，才能避免一些算出來的值無法收歛的問題。因此我們採
用的方式，是先將 R 參數固定去最佳化 V 參數的值之後，再利用最佳化 V 所得到的結果去
更新 R 參數的值，整個過程如下圖表示: 
3D shape 
parameters V
Reflectance model 
parameters R
Initial shape 
< V , R >
Initial reflectance parameters
 
圖 22、SFS 的過程 
我們使用 Phong model 為物體的 reflectance model，是因為在電腦圖學方面它是最廣泛
使用的光學模型，並且它所具有的參數並不會太多，因此可以提高最佳化的效率。因此給
予一個光源 L 以及表面法向量 N， Phong model 可以表示如下: 
))()((||),( reKNLKLRVS sd   
其中 Kd 和 Ks 分別表示 diffuse 以及 specular 的係數，而 為 specular 的指數參數，因
此                ，而 V 參數集合會更新表面法向量的值。 
因為我們使用 Phong model 當作物體的 reflectance model，因此整個最佳化過程為一個
非線性的最佳化問題，所以必頇使用數值方法中的 conjugate gradient 方式來解決。依據
conjugate gradient 的方式，必頇對每一個要最佳化的參數做一個微分的動作，因此若需對空
間參數做最佳化調整的時候，微分結果如下: 
},,{ sd KKR 
 20 
變化的平均，Sx和Sy為標準差。 
我們利用兩兩區塊彼此間的相關係數作為 normalized cut 分群的依據，因此我們使用區
塊彼此間的相關係數來定義區塊 X 和區塊 Y 是否為同一群的權重（式 2）。 
 
Weight越大，區塊X和區塊Y越容易分在同一個群集。 
定義好每個區塊彼此間是否屬於同一群集的權重，透過使用normalized cut，我們可以將人
的臉部區域分成以下七群（圖23），其中，同顏色的區塊表同一群集： 
 
圖 23、Normalized cut 對人臉分群之結果。 
在將人臉進行分群之後，我們使用 steerable pyramid 的概念，將所有 prototype 影像進
行高低頻以及各 subband 不同方向成分的拆解，如（圖 24）的 make pyramid 流程，其中
Hi,Vi, Ri, Li 分別代表使用水平、垂直、右斜、左斜方向 filter 所產生之不同方向影像，i 為
影像拆解的 level 數。Down sampling 所產生之 low band 可以再次重複此 make pyramid 的
過程，來產成不同 level 之不同方向的影像。 
 22 
資料數量會過於龐大，而實際存在的資料會顯得相當不足。所以我們假設人在一段時間內
的臉型變化不會太大，而重新將資料庫分為 15 組年齡層，如此一來，即可降低不存在的資
料量大小。重新以此年齡層區分出來的 Aging Pattern 如圖 25 所示。在圖 25 中每張照片所
屬的年齡層標示在該照片的左上角，如果該年齡層的照片是不存在資料庫中，則在 Aging 
Pattern 中會以―m‖表示。 
 
圖 25 Aging Pattern 
 
PCA with missing data 
這裡採用一個相當廣泛受到應用的方法：主成分分析(principal components analysis 
(PCA))來建立子空間。而投影至子空間計算如公式(1)所示： 
,     (2) 
其中μ是指 x 的平均向量，W 為 x 的共變異數矩陣(covariance matrix)的正交特徵向量
(orthogonal eigenvectors)，y 則是 x 投影的子空間(subspace)。但由於 aging patterns 的資料是
相當不完整的，於是 Xin Geng [GZS06]等人便提出 EM-like(Expectation Maximization-Like)
的演算法來計算具有代表性的子空間。 
假設要訓練的資料集合有 N 筆 aging pattern 向量 。每一筆可以被寫
成 ， 是 pattern 中存在可用的資料，而 是不存在 pattern 中的資料，再
使用轉換矩陣 W 與公式(2)，可計算出 投影出的子空間 ，而如果要使用 來重建 可
使用公式(3)： 
,     (3) 
也可表是為 , 其中  與  是  重建後的結果。一般來說，
標準的 PCA 可使用子空間中的資料集合 D 的最小化平均重建誤差推導出來[JOL02]。所以
如果要找出不存在的資料 ，則目標就會變成最小化存在資料的平均重建誤差對應的 W 如
 24 
圖 26、使用 PCA 填滿不存在資料庫的年齡層照片， 
圖中虛線外框的照片是原本不存在的照片 
圖 27 為本演算法的虛擬碼片段。我們的方法是利用 PCA 根據 EM-like 演算法去重建
各個年齡層的照片。而圖 28 是 FG-NET 資料庫中一些範例照片。 
 
圖 27、PCA EM-like 的演算法 
 
 
圖 28、FG-NET 中四組不同年齡層的序列範例 
 
臉部材質合成 
在我們所使用的資料庫 FG-NET 中，存在著許多較暗的照片，而這些照片是無法拿來
當作臉部材質合成所使用，因此我們會先除去這些無用的照片。接著，因為每張臉的姿勢
與方向皆不相同，所以我們針對剩餘可用的照片使用 wrapping method[BN92]做正規化。然
而，有陰影存在的照片經過正規化處理後，會出現許多黑洞，我們同樣將這些照片給移除，
留下適合用來臉部材質合成樣本照片，這些經過正規化後的圖片稱之為材質原型(Texture 
Prototypes)。圖 29 為各張照片正規化後的結果。 
 26 
五、 研究成果展示 
5.1.1 動作混合與動作移轉 
在動作混合這部份，使用者可以任意地指定希望虛擬角色擊打的三度空間位置，系統
會反查出對應的權重組合，來混合樣本動作，產生最後的結果動作。下圖 30 紅點代表的
是虛擬人物可以擊打到的位置，也就是樣本動作所能混合出來的範圍。如果玩家指定的不
在這個範圍內，那麼系統便只能找到最接近的點，因此，這個方法並不會突破動作原有的
限制，只會增加多樣性而已。 
 
圖 30、擊打範圍 
若將移動搭配上攻擊，兩者都使用動作混合的技術，之間以動作移轉來銜接，則虛擬
角色便會緩緩移動至目標附近，然後平順地轉換成攻擊的動作，並正確擊打到目標點，如
下圖 31 所示。 
 
圖 31、成功攻擊目標 
下圖 32則是使用反向關節力學(IK)來提昇準確度的例子，左下圖是沒套用IK的情況，
結果可以看到沒打到想要的位置；而右下圖則是有套用IK的情況，結果則是準確許多，手
就有碰到目標點。但如果混合出來最接近的結果離正確結果有很大的差距時，就不建議使
用這項技術，因為反而會使得合成出來的動作不自然，這是因為動作本身先天條件限制的
關係而無法達到使用者的需求，因此強求反而不好。 
 28 
  
原始人體骨架 移動右手 
  
移動右腳 移動左手 
圖 35、動作編輯 
5.2.1 皺紋推估 
下圖為 SFS 最佳化的過程，為了避免在第一次最佳化時因為維度太高而造成解的錯誤，因
此在第一次最佳化時，我們只根據 diffuse 做最佳化過程來得到一個比較好的初始形體，在
第2次之後才加入 specualr，可以明顯的看出來在之後的結果中其柔化的效果已經顯現出來。 
 
圖 36、(左) input image (右)處理法令紋的 3D 重建過程 
下圖 37 則為其他部位的結果，分別為抬頭紋以及眉毛間的皺紋。我們並與 [Fang 04]所提
出的 SFS 方法，在不經由任何人為調整下的結果比較，可以明顯發現我們的結果其雜質明
顯減少且在皺紋方面也較明顯。 
 30 
 
(a)                       (b)                      (c) 
圖 39、(a)眉毛間的皺紋 (b) 法令紋 (c)抬頭紋 
5.2.2 表情合成 
下面左邊那張圖為 blend shape 所產生之正規化影像，而右邊那張圖則是我們合成出的
成果材質，經反正規化後，可形成動作表情。兩者比較起來可以發現 blend shape 的細部資
訊消失很多。 
 
圖 40、blend shape 與我們方式的比較 
5.2.3 臉部老化 
下圖 41 與圖 42 共有八列，表示總共有八組實驗結果，每列上方說明該次實驗為輸入
某歲的年齡與希望預測出特定歲數的資訊，例如 3y to 16y 表示輸入的圖片為 3 歲的影像，
結果為預測合成 16 歲的影像。 
第一行圖為輸入較小年齡的影像，第二行為只使用 EM-like 演算法與 PCA 合成出的老
化效果，第三行圖則是使用我們提出的方法，也就是使用 EM-like 演算法與 PCA 合成後，
再加上臉部材質合成的技術，第四行為資料庫中實際存在的預測年齡之影像以提供比較。 
由下圖可以得知，由於我們的方法是從資料庫中找尋接近年齡與膚質的皮膚加以合
 32 
六、 結論 
在這次三年期的子計畫中，我們針對人物角色的動作與表情容貌提出了多種合成技術。 
在第一年之計畫中，我們完成了動作混合的合成技術，讓同一類動作可以有更多樣性
的變化，並且可以藉此產生滿足使用者限制條件的動作。除此之外，動作移轉的合成技術
可以讓角色可以自由切換不同動作。皺紋推估技術則是可以合成出各式臉部細紋，提昇角
色的細膩程度。 
在第二年之計畫中，我們提昇了動作混合的精確度，藉由反向關節運動力學的輔助，
我們能夠更貼近使用者的需求，這樣只需用少數樣本動作來進行混合即可，可大幅減少所
需資料量。除此之外，我們提出了即時的動作移轉機制，讓角色可以隨時立即切換動作，
而不用等待前面的動作做完。而利用 blade shape 的臉部表情合成技術則是成功地保留住臉
上細部紋路的資訊，並未因為混合的關係而被淡化處理。 
而在第三年的全身動作反推中，我們發現二次多項式比較適合描述各記錄點的線性關
係，也成功地只利用幾個動作控制器來還原出近似的整體動作；可提高遊戲中互動控制在
呈現動作方面的多樣性，遊戲本體無需紀錄大量的動作模型，只需記錄還原回動作模型所
使用的多項式之參數以及主要紀錄點的角速度值資料，配合適當的容錯機制，遊戲便能讓
使用者看到更加真實且多元的動作。至於人臉老化的合成技術，則是可以幫忙推測出一個
人在不同歲數時的模樣，使得臉部影像可提高控制性與變化性。 
 
 34 
21(3): pp 473-482 , 2002. 
[Kovar04] L. Kovar and M. Gleicher, ―Automated Extraction and Parameterization of 
Motions in Large Data Sets‖, ACM Trans. Graph. 23(3): pp 559-568 , 2004. 
[Lee02] J. Lee, J. Chai, P. Reitsma, J. Hodgins, and N. Pollard, ―Interactive Control of Avatars 
Animated with Human Motion Data‖, ACM Trans. Graph. 21(3): pp 491-500 , 2002. 
[Peng07] Jen-Yu Peng, I-Chen Lin, Jui-Shiang Chao,Yan-Ju Chen, Gwo-Hao Juang, 
"Interactive and Flexible Motion Transition" Computer Animation and Virtual Worlds, 
18(4-5): 549-558, Sept, 2007 . 
[Sch‖odl00] A. Sch‖odl , R. Szeliski, D. Salesin and I. Essa. Video textures. In Proceedings 
of ACM SIGGRAPH 2000, Annual Conference Series, ACM SIGGRAPH, pages 
489-498, 2000. 
[WZW77] A.P. Dempster, N.M. Laird, D.B. Rubin, Harvard University and Educational 
Testing service, "Maximum Likelihood from Incomplete Data via the EM Algorithm". 
Journal of the Royal Statistical Society, Series B (Methodological), Vol. 39, No. 1, 
1977  http://www.jstor.org/stable/2984875 
[Zhang06] Qingshan Zhang, Zicheng Liu, Baining Guo, Demetri Terzopoulos, 
Heung-Yeung Shum: Geometry-Driven Photorealistic Facial Expression Synthesis. 
IEEE Trans. Vis. Comput. Graph. 12(1): 48-60 (2006). 
[Weyrich06] T. Weyrich, W. Matusik, H. Pfister, Analysis of human faces using a 
measurement-based skin reflectance model. ACM Trans. Graphics 2006; 25(3): 
1013–1024. 
[Seitz05] A. Hertzmann and S.M. Seitz, Example-based photometric stereo: shape reconstruc- 
tion with general, varying brdfs, Pattern Analysis and Machine Intelligence, Vol. (27), 
No. 8, August 2005, pp. 1254-1264. 
[Fang04] H. Fang, J.C. Hart. Textureshop: texture synthesis as a photograph editing tool. ACM 
Trans. Graphics 2004; 23(3): 354–359. 
[Zeng05] G. Zeng, Y. Matsushita, L. Quan, H.-Y. Shum, "Interactive Shape from Shading," 
IEEE CVPR, vol. 1, pp.343-350, 2005.
 36 
Stereo Positions and Reflectance Properties for 3D Surface Reconstruction", Proc. Intl. 
Workshop on Advanced Image Technology (IWAIT'08), Hsinchu, Taiwan, Jan. 2008. 
 Chii-Yuan Chuang, I-Chen Lin, Yung-Sheng Lo, Chao-Chih Lin, "Feature-point Driven 3D 
Expression Editing", Proc. Intl. Conf. on Computer Graphics Theory and Applications 
(GRAPP' 07), short paper, pp.165-170, Barcelona, Spain, March, 2007. 
表 Y04 
第四日（8/6）－論文 session：「Character Animation I」、「Rendering Methods and Systems」、
「Interacting With Hands, Eyes, and Images」、「Visual, Cut, Paste, and Search」、「Modeling and 
Rendering of Dynamic Shapes」、「Shape Analysis」。 
第五日（8/7）－論文 session：「Meshing」、「Character Animation II」、「Vector Graphics and Point 
Distributions」、「Physically Based Modeling: From Contact to Capture」、「Rendering and 
Visibility」、「Computational Cameras」。 
 
二、與會心得 
本年度的 SIGGRAPH會議依舊維持一貫優良傳統，所收錄的論文絕大部分均為最頂尖之
研究成果，在論文的發表上也均精心設計。相較於往年不同處，為此次會議舉辦地 New Orleans
歷經風災重建，雖市區已恢復原貌，整體遠不如以往繁榮，參與會議人數幾乎為近年來最少之
一次。 
本人主要的研究在 computer animation以及 image-based data acquisition and synthesis。這兩
方面研究，亦為今年度的研究主流。在人物動作合成的趨勢方面，利用 physics-based controller
的動作反應在以往是較不擬真的，但是能反映環境外力的影響，今年有數篇論文結果已逼近動
態捕捉之水準，在速度上亦有大幅改進，值得深入研究。在 image editing方面，如同這兩三年
的發展，有大量與 computer vision結合的技術應用於此方面，除了二維影像外，perspective-based
的相關技術亦開始被應用。此外，有幾篇論文題目與本實驗室的研究動作分析與臉部細節頗為
有關，往後若欲擠身此一流會議需更加快研究腳步。 
另外，相關的研究越來越多採用高價設備作為資料擷取儀器，相較於國內學者所能獲得的
研究經費與儀器水準上有差距。本次會議中，我們也利用機會與國外學者有意見交流，訂定可
能的合作方向，希望可以加速研究進展，往更尖端研究邁進。 
 
三、考察參觀活動(無是項活動者省略) 
