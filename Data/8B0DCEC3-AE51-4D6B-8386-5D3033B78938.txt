 
中 文 摘 要 ： 本計畫深入討論與研究影像壓縮系列中最佳的小波轉換係
數、量化與編碼等相關主題，並且已有實質的研究成果。 
 
第一年提出一個利用雙線性內插法與離散餘弦轉換之適應性
組合以達到基於像素尺寸之二維影像快速及超大尺度放大/縮
小，並且增進放大/縮小的速度與品質。利用雙線性內插法與
離散餘弦轉換針對各區塊不同的特性，適應性地進行超大尺
度的放大/縮小。與雙線性內插法作比較，離散餘弦轉換在邊
界區塊上產生較佳品質的高階近似方法，但執行時間較長。
然而，雙線性內插法是個在平滑區塊產生不錯品質的低階近
似方法，並且只需較短時間執行。此外，如果品質為主要考
量，進化規劃演算法被利用來調整縮小影像之頻率係數矩陣
中的元素以進一步提升縮小的品質。最後，本計畫也提出一
個新的演算法以處理任意像素尺寸之放大/縮小。所提方法可
延伸至三維的影像放大，詳見作者過去所發表的研究成果，
因此，在視訊方面可有效地提升視訊壓縮品質。 
 
第二年提出一種基於升級機制的嶄新 5/3 和 9/7 小波轉換影
像插值法以達到高品質的影像壓縮目的，並且針對個別影像
提出進化規劃演算法做最佳化處理以進一步提升影像壓縮的
品質。基於小波轉換後的低頻係數，本計畫提出預測型演算
法以預測將原始影像作小波轉換後的高頻係數，所以使用本
文所提的預測型演算法得以將小波轉換後的低頻影像重建為
原始影像，以達到影像壓縮的目的。由於奇數長度的小波濾
波器其正中心係數主宰了小波轉換與反轉換的性能，所以對
濾波後的小波係數做奇數或偶數的降階取樣會影響到原始影
像的重建品質。因此，本計畫在建構升級機制的奇數長度小
波濾波器的低頻係數中，分別對原始影像的奇數和偶數像素
做小波轉換。接著，在兩者之中選擇較好的那一個以匹配奇
數小波濾波器(5/3 和 9/7)和原始影像的特性，以達到高品質
的影像壓縮。為了更進一步改進原始影像的重建品質和驗證
上述所提的演算法的最佳化程度，本計畫同時提出了基於進
化規劃演算法的影像插值法。經由實驗結果顯示，本計畫提
出的使用或不使用進化規劃的預測型演算法表現得比其他文
獻所呈現的標準方法好，而且在不使用進化規劃的預測型演
算法其時間複雜度也在可以接受的範圍內。 
 
第三年提出一個可以節省時間且增進壓縮率的醫學影像壓縮
方法。離散小波轉換是一種常見的轉換方法，但是它所花費
的時間複雜度很高。為了改善時間複雜度，我們使用低複雜
度的離散餘弦轉換取代小波轉換，並且重新排列離散餘弦轉
 
During the third year, for the efficiency of 
compressing medical images, we propose a compression 
algorithm based on DCT with set partitioning in 
hierarchical trees (SPIHT). To decrease the 
computational complexity of discrete wavelet 
transform (DWT), we use the DCT instead of DWT. The 
DCT coefficients are reordered to follow the feature 
of spatial orientation tree by the proposed method. 
Simulation results reveal that the proposed method 
improves the quality of the reconstructed medical 
images and directional natural images over the 
conventional SPIHT. The DCT is also faster than DWT 
in different types of medical images. 
 
英文關鍵詞： Enlargement, reduction, pixel-size-based zooming, 
bilinear interpolation, discrete cosine transform, 
evolutionary programming, image resolution 
enhancement, image interpolation, wavelet transform, 
medical image, Image compression, set partitioning in 
hierarchical tree 
 
II 
 
中文摘要 
本計畫深入討論與研究影像壓縮系列中最佳的小波轉換係數、量化與編碼等相關主題，並且已有實質
的研究成果。 
 
第一年提出一個利用雙線性內插法與離散餘弦轉換之適應性組合以達到基於像素尺寸之二維影像快
速及超大尺度放大/縮小，並且增進放大/縮小的速度與品質。利用雙線性內插法與離散餘弦轉換針對
各區塊不同的特性，適應性地進行超大尺度的放大/縮小。與雙線性內插法作比較，離散餘弦轉換在
邊界區塊上產生較佳品質的高階近似方法，但執行時間較長。然而，雙線性內插法是個在平滑區塊產
生不錯品質的低階近似方法，並且只需較短時間執行。此外，如果品質為主要考量，進化規劃演算法
被利用來調整縮小影像之頻率係數矩陣中的元素以進一步提升縮小的品質。最後，本計畫也提出一個
新的演算法以處理任意像素尺寸之放大/縮小。所提方法可延伸至三維的影像放大，詳見作者過去所
發表的研究成果，因此，在視訊方面可有效地提升視訊壓縮品質。 
 
第二年提出一種基於升級機制的嶄新 5/3和 9/7小波轉換影像插值法以達到高品質的影像壓縮目的，
並且針對個別影像提出進化規劃演算法做最佳化處理以進一步提升影像壓縮的品質。基於小波轉換後
的低頻係數，本計畫提出預測型演算法以預測將原始影像作小波轉換後的高頻係數，所以使用本文所
提的預測型演算法得以將小波轉換後的低頻影像重建為原始影像，以達到影像壓縮的目的。由於奇數
長度的小波濾波器其正中心係數主宰了小波轉換與反轉換的性能，所以對濾波後的小波係數做奇數或
偶數的降階取樣會影響到原始影像的重建品質。因此，本計畫在建構升級機制的奇數長度小波濾波器
的低頻係數中，分別對原始影像的奇數和偶數像素做小波轉換。接著，在兩者之中選擇較好的那一個
以匹配奇數小波濾波器(5/3和 9/7)和原始影像的特性，以達到高品質的影像壓縮。為了更進一步改進
原始影像的重建品質和驗證上述所提的演算法的最佳化程度，本計畫同時提出了基於進化規劃演算法
的影像插值法。經由實驗結果顯示，本計畫提出的使用或不使用進化規劃的預測型演算法表現得比其
他文獻所呈現的標準方法好，而且在不使用進化規劃的預測型演算法其時間複雜度也在可以接受的範
圍內。 
 
第三年提出一個可以節省時間且增進壓縮率的醫學影像壓縮方法。離散小波轉換是一種常見的轉換方
法，但是它所花費的時間複雜度很高。為了改善時間複雜度，我們使用低複雜度的離散餘弦轉換取代
小波轉換，並且重新排列離散餘弦轉換後的係數來達到空間導向的樹狀結構。由於和小波轉換一樣擁
有空間的對應關係，我們可以把它應用在以小波為基礎的壓縮演算法上，如 SPIHT。我們使用不同
大小的離散餘弦轉換區塊來找出最好的結果。實驗結果顯示，在相同的壓縮率下，本計畫提出的演算
法在較大的區塊上有比較好的重建影像視覺效果。在時間方面，不管是何種醫學影像，離散餘弦轉換
都比離散小波轉換來的快速。 
 
1 
 
1. 報告內容 
 
1.1. 前言 
 
影像放大的研究在影像領域是不可或缺的。影像放大可以應用在衛星影像、網頁圖片瀏覽、醫療影像、
以及影像處理軟體上。近年來，除了常用的雙線性內插及雙立方內插以外，利用多項式轉換的放大方
法[1.1, 1.2]也被提出。 
 
對數位影像而言, 內插是當在一個影像裝置上改變數位影像大小的必要方法，而且也被用來作為影像
編碼的有效方法[1.3]。內插也可以是一種在影像中取平均值的運算[1.4]，好的內插點需要符合及接近
原始連續資料的模型。在理想且靜態的線性系統中，最佳的近似方法為 sinc函數，sinc函數可將有限
頻帶下的訊號進行正確的重建。由於 sinc 函數在現實中難以被實現，所以各種不同的近似方法就被
提出[1.4]。所有的內插法則是以訂出影像各個像素的比重係數來決定內插點的像素值。以鄰近內插法
(Nearest Neighbor interpolation)為例，鄰近內插法的內插函數為 0次多項式，相當簡單但將會造成區塊
現象。比鄰近內插法效果更好一些是雙線性內插法(Bilinear Interpolation)[1.5]，內插模型為一次函數，
或者雙立方線性法(Bicubic Interpolation)[1.6]以及更高次的內插法。為了得到更好的效果，[1.1]提出離
散餘弦轉換的放大方法，因為經過離散餘弦轉換放大後會有區塊以及波紋效應，所以[1.1]又提出有效
的解決方法。其效果會比 B-spline，雙立方內插法更好。 
 
[1.1, 1.2]所提到的離散餘弦轉換之影像放大，應用在非整數倍放大有個缺陷，因為藉由使用者輸入放
大倍數後，得到的像素並不會完全符合放大的倍率，所以本計畫提出改良的非整數放大方法，以準確
無誤的顯示出正確大小的放大效果。 
 
因為離散餘弦轉換為偶函數轉換，所以有著內插所需的對稱性，其他的內插法[1.3-1.6]的函數圖形並
沒有對稱性。若函數沒有對稱性，在高倍數放大時，影像會產生不對稱的情形。離散餘弦轉換由於近
似的函數階數較高，運算量將會提高，本計畫結合利用雙線性內插法與離散餘弦轉換法，以達到節省
時間而不失其放大的品質。 
 
小波轉換近年來在壓縮上有不錯的成效，原因是因為小波轉換在邊界的保存部份比離散餘弦轉換更好，
而近年來在影像放大上的應用[1.7-1.9]，也有不錯的效果。近年來的小波影像放大的過程為影像經由
小波分解後產生四個大小相同 LL、LH、HL 和 HH 的頻帶，每個頻帶的大小是原始影像的 1/2 倍，
其中 LL頻帶裡的係數為原始影像的近似。假設放大 2倍後的影像經由小波分解後的 LL頻帶為原始
影像，其餘三個頻帶分別表示水平、垂直、對角細節，針對這三個頻帶的係數，使用估測的方法得到，
估測的方法有兩種，一種為對不同角度的邊界進行小波分解得到的高頻係數，其重要係數及周圍的係
數與像素之間的斜率有著固定倍數的關係。另外一種是針對原圖作若干階小波分解，將每一階分解位
3 
 
 
隨技術之演進，網際網路愈加強大，以其影像壓縮亦帶來不少好處。諸如，漸進式傳輸的實現，抗雜
訊及恢復力之可靠性，區域的取樣強化，以及壓縮率的提升。因此，影像壓縮日益廣用於各領域。  
 
混沌系統是在非線性及複雜的動態系統中一個普遍性的現象，具統計中類似隨機過程的歷態平穩性 
(ergodic) 以及其他特別的特性。在最佳化中，歷態平穩的特性就如同一基本的動力機械裝置，可幫
助系統運行的軌跡遠離局部的最佳化。在參數變動的範圍內，混沌運動盡可能一次又一次的跑到每一
個可能的狀態，有其運作規律又無周期性的規則。因此這樣的演化方式可被看成是具隨機化以及迴授。
許多研究者把混沌系統應用至自然現象模型、類神經網路、非線性迴路。因此結合混沌以及進化規劃
演算法的混沌進化規劃演算法，應用此法可以更快速的求解大範圍且具限制條件的最佳化問題並且能
收斂至更精確的最佳解。 
 
將 CEP應用於 9/7 過濾器係數之最佳化以達成對多重目標的影像壓縮。此方法可以在實際的實現上
達到整體最佳化並對於具混合型不確定性，非線性規劃是求解各種複雜問題最有效的方法之一。因此，
這種方法受到了人們的關注，迄今為止，已經構造出許多的演算法，如梯度法、共軛梯度法等。這些
演算法容易收斂到局部最佳，卻不能保證收斂到全局最佳化。 
 
進化規劃演算法(Evolutionary-Programming, EP)是一種平行計算與最佳化的方法，源出於基因遺傳演
算法。不同於基因遺傳演算法的特徵在於進化規劃演算法的資料結構為函數形式，而基因遺傳演算法
是字串符號形式，相對來說，進化規劃演算法利用函數形式比較適合解決 9/7過濾器係數最佳化的問
題。另外進化規劃演算法亦有著與遺傳演算法一樣具有繁衍與突變的性質，並且其優點為多方向搜索、
總體的解決以及適合的函數定義。與確定性的規則比較起來較能找到整體的最佳化。 
 
遺傳演算法是建立在自然選擇和族群理論基礎上的隨機、突變和進化，具有廣泛使用的搜尋方法。雖
然遺傳演算法能以機率收斂到全局最佳解，但由於演算法結構、編碼長度和演算法複雜度的限制，其
局部搜索速度和精度並不能得到最好的保證。而混沌最佳化演算法是一種新的搜尋最佳化的演算法，
基本思想是把變量從混沌空間變換到解空間，然候利用混沌變量具有歷態平穩性、隨機性和規律性的
特點進行搜尋。修改後的混沌最佳化方法具有不對初值敏感、易跳出局部極小點、搜索速度快和全局
漸進收斂的特點。 
 
本計畫考量混沌系統的真實狀態問題，利用進化規劃法演算法為基礎，結合混沌最佳化，找出滿足問
題的最佳化參數，以達成整體的最佳化。由於計畫中考量的壓縮性能和所欲決定的參數關係乃非線性
關係，因此無法直接利用二分法的方式來進行最佳化參數，這也是選擇進化規劃法的原因。 
 
資料壓縮的目的在於除去存在資料中的冗餘(redundancy)，減少傳輸所需要的時間以及儲存所需要的
空間，改善了系統的效能 [3.1-3.3]，並且增進了網路的傳輸上的安全性 [3.4]；研究的目標在於發展
出的演算法，以達到減少表達資料的資訊以及提高壓縮的速度 [3.5-3.7]。根據這幾年來的研究，人們
發現到採用以離散小波轉換(discrete wavelet transform，DWT) [3.8-3.10]為基礎的壓縮方法，其壓縮效
率往往勝過以離散餘弦轉換(discrete cosine transform，DCT)為基礎的壓縮技術。因此近年來許多以
DWT 為基礎的壓縮技巧不斷的被提出與發表，如 JPEG2000[3.11]即是以小波轉換為基礎的一個靜態
5 
 
proposed mechanisms are particularly suitable for very large-scale zooming of an image, because these 
perform very large-scale zooming of an image at once [i.e., 2×2×2 or (1/2)×(1/2)×(1/2) zooming of an image 
is not required]. 
 
Some basic interpolations, such as zero-order interpolation [4.3] and linear interpolation, are easy to 
implement, but the reconstruction quality is worse than the high-order polynomial approximation. Some 
polynomial methods, such as cubic convolution or cubic spline, [4.3] get better quality, but zigzagging 
artifacts on edge are not avoided by using these methods. 
 
In order to reduce the zigzagging artifacts, many research efforts have been devoted to the edge-directed 
image interpolation. [4.4–4.7] The methods have detected the edge pixels and smooth pixels, and then apply 
different interpolations in different characteristic pixels. Such methods as the new edge-directed 
interpolation (NEDI)4 uses the covariance of the pixels to estimate edge location. A faster edge-directed 
method is proposed in Ref. 5. The method tolerates little quality loss and takes less time than NEDI. This 
proposal proposes a new DCT-based mechanism to classify the sharp blocks and smooth blocks of an image. 
For the sharp block (i.e., the edge block), it usually contains high-frequency property. Therefore, an edge 
block is interpolated by a high-order approximation, DCT, in order to keep more original high frequency 
property. On the basis of the same reason for a smooth block (i.e., the homogeneous block), it is interpolated 
by a low-order approximation to save some operating time and get a better quality. 
 
In recent years, some edge-preserving interpolation methods, such as in Ref. 8, are proposed. A novel 
soft-decision approach is proposed8 for adaptive image interpolation. When coupled with piecewise 
autoregressive image model, the soft decision approach estimates a block of missing pixels jointly by 
imposing an adaptively learn spatial sample relation not only between known pixels and missing pixels but 
also between missing pixels themselves. This new image interpolation technique outperforms in both peak 
signal-to-noise ratios (PSNRs) measure and subjective visual quality over a wide range of scenes by 
preserving the spatial coherence of the reconstructed high-resolution (HR) image on features of large- and 
small-scale alike. Although the proposed algorithm is presented to double the horizontal and vertical 
resolutions, the scaling factor S = 2
z
 with z being a positive integer. One need to apply the proposed 
algorithm z times to scale the input image by S times. For an arbitrary scaling factor scaling factor S (not an 
integer power of 2), the interpolation can be done by first using the algorithm to expand the input image by 
2
z
 times such that 2
z
 < S < 2
z+1
, and then apply a conventional image interpolation algorithm, such as bicubic 
or bilinear interpolation, to scale up the output image of the new method by s times such that 2
zs
 = S. 
However, the above mechanism, utilized for quite lots of approaches, is not the good one for a fast 
pixel-size-based very large-scale zooming of an image. 
 
The arbitrary scale (such as r = M/N = 539/512 times) image enlargement [4.9, 4.10] was proposed to 
enlarge a noninteger multiple (r) enlargement, which is completed through an integer multiple (M) 
enlargement and then an integer multiple (N) reduction. When M and N are large and co-prime, it is obvious 
that this approach has the essential disadvantage for a fast pixel-size-based very large-scale enlargement. As 
7 
 
The continuing improvements in wavelet-based methodologies have led to many new and fascinating 
applications in image interpolation. 
 
Wavelet-based algorithms have been proved to be successful for image interpolation tasks. These algorithms 
predict the high-pass filtered coefficients, and the reconstructed image can be obtained by these estimated 
coefficients. Hence, the main problem of wavelet-based interpolation is how to estimate the high-pass 
coefficients correctly as possible. In [5.8], detail coefficients in the strong edge area are estimated using the 
regularity of wavelet transform in coarser subbands. However, it only estimates the coefficients on the 
region with strong edges, so that its improvement is limited. The methods based on the probability model 
usually employ the hidden Markov tree (HMT) model [5.9]. The HMT scheme can effectively capture the 
inter-scale transition characteristics and intra-scale statistics. This scheme reflects magnitudes of coefficients, 
but none of signs of coefficients is reflected. The theoretic analysis of inter-scale and intra-scale wavelet 
coefficients is briefly described in [5.10]. It provides a good analysis for modeling wavelet coefficients, and 
many compression algorithms also follow this concept. In [5.11], the wavelet decomposition signal is used 
to train the neural networks. The input signals of the neural network are the pixels in the low-resolution 
image to estimate all the wavelet sub-images of the corresponding high-resolution image. Literature [5.12] 
proposes the integer 5/3-transform-based lifting filter to predict high-frequency subbands for image 
compression. Literature [5.13] uses a method which exploits wavelet coefficient correlation in a local 
neighborhood sense and employs linear least-squares regression to estimate the unknown detail coefficients 
for image resolution enhancement. Literature [5.14] proposes an image resolution enhancement approach 
using inter-subband correlation in wavelet domain. Literature [5.15] proposes a different 
Haar-transform-based lifting filter to predict high-frequency subbands from LL-band for wavelet-based 
interpolation scheme to enhance resolution of medical images. Literature [5.16] uses the multilayer 
perceptron (MLP) neural networks to train a mapping from the coarser scale to the finer scale for each 
specified image. Literature [5.17] proposes discrete wavelet transform (DWT) using lifting scheme as an 
accurate and computationally inexpensive interpolation technique for image resizing. During the course of 
magnification, the MSE and PSNR are not better than bilinear and bicubic performance. However, the 
proposed approach in [5.17] has the advantage of much less computational load as compared to the bilinear 
and bicubic interpolation methods. 
 
Evolutionary programming (EP) [5.18, 5.19] was evolved and developed from the idea of genetic algorithms 
(GAs) [5.20] and is a parallel optimization and computational technique. As compared to GA, which uses 
symbolic strings to describe a problem, EP uses functional forms, so that it is more flexible and more 
suitable for solving complex engineering problems. EP also follows the same competition principle like GA 
to eliminate unwanted candidates while preserving good ones. GA and EP use some same operations such as 
reproduction and mutation to gradually approach the global optima. This proposal takes the advantages of 
EP for global optimization and proposes novel 5/3 and 9/7 wavelet-based image interpolations in lifting 
structures with/without involving EP for image compression. 
 
9 
 
Bilinear Interpolation 
 
Bilinear interpolation [4.3, 4.16-4.18] is clearly illustrated in this section. At present, many image 
interpolation algorithms are used to sample and resize image in the spatial domain. Among these, bilinear 
interpolation and bicubic interpolation are applied most commonly. They are different from nearest-neighbor 
interpolation because they compute the unknown pixel value by its neighbor pixels to get the optimal value. 
Bilinear interpolation is weaker than bicubic interpolation in quality, but its execution speed is faster than 
bicubic interpolation. In order to have a balance between the tradeoff speed and quality, here bilinear 
interpolation is combined with DCT. Bilinear interpolation makes use of the four neighbor pixel values to 
compute the new unknown pixel value. Fig. 4.1 depicts how bilinear interpolation algorithm works. 
 
 
 
Fig. 4.1 Illustration of bilinear interpolation 
 
In Fig. 4.1, when computing the new pixel value of ( )P x , ( )P x  is traced back from target image to 
original image and its location lies between four pixel values A、B、C、D . The distances between them 
and  are known, so it only computes the distance between   and . If the neighbor pixel is 
closer to , it has more contribution to  such that the pixel value affects ( )P x  more and vice 
versa. The following equations show how the pixel value of is generated: 
DCBAxP   )1()1()1()1()( .    (4.1) 
( )P x A ( )P x
( )P x ( )P x
( )P x
11 
 
signal, we have to use a transform method which has symmetric property. 
A discrete cosine transform (DCT) expresses a sequence of finitely many data points in terms of a sum of 
cosine functions oscillating at different frequencies. DCT can be applied in science and engineering from 
lossy compression of audio and images. Since, the frequency domain function 2
( )F u
 is neither a real 
function nor a symmetric one for the specified u. Pre-multiplying (4.4) by 
2
u
j
Ne


 yields 
2
2( ) ( )
u
j
NV u e F u



              
 
2 ( 0.5) 2 ( 0.5)1
2 2
0
( )
i u i uN j j
N N
i
f i e e
   

 
  
 

         
2 ( 0.5) 2 ( 0.5)1
2 2
0
( ) ,
i u i uN j j
N N
i
f i e e
   

 
  
 

 for 0 2 1u n   .   (4.6) 
After taking the inverse DFT, we get 2
( ) ( 0.5)v i f i 
, which is an even sequence with ( ) ( )v j v j  . The 
frequency domain sequence ( )V u  has the following properties: 
(i) Due to 
( 0.5)(2 ) ( 0.5)
cos cos
i N u i u
N N
      
    
    , one has 
(2 ) ( )V N u V u    .         (4.7) 
(ii) Due to 
 
( 0.5)
cos cos ( 0.5) 0
i N
i
N


 
   
  , one has 
( ) 0V N  .          (4.8) 
So, the equation ( )f i  can be simplified as follows: 
22 1
2
2
0
22 1
2 2
0
2 ( 0.5) 2 ( 0.5)2 1 2 1
2 2
0 1
1
( ) ( )
2
1
      ( )
2
1 1
      ( ) (2 )
2 2
iuN j
N
u
u iuN j j
N N
u
i u i uN Nj j
N N
u u N
f i F u e
N
V u e e
N
V u e V n u e
N N

 
 




  
  


  


 
      
( 0.5)
( 0.5)2 1
1
1 1
      (0) ( )( )
2 2
i u
ji uN Nj
N
u
V V u e e
N N





  
       
13 
 
where 
1
(0)
(1)
,
( 1)
N
F
F
F R
F N

 
 
  
 
 
   
1 0(0 0.5) 1 0(1 0.5) 1 0( 1 0.5)
cos cos cos
2 2 2
1(0 0.5) 1(1 0.5) 1( 1 0.5)
cos cos cos
,
1( 1)(0 0.5) ( 1) (1 0.5) ( 1) ( 1 0.5)
cos cos cos
N
N
N N N
N
C N N N
N N N N
N N N
  
  
  
       
 
 
       
 
 
 
            
 
   
and 
1
(0)
(1)
( 1)
N
f
f
f R
f N

 
 
  
 
 
  . Then, we have the inverse DCT as 
1( ) TN Nf C F C F
 
,            (4.15) 
where N
C
 is an orthogonal matrix. In order to get a set of enlarged signals 
1rN
rf R

 from the original 
frequency coefficient matrix F , where r  is an integer, an enlargement of extendible inverse DCT is 
defined as sampling rate increment from an N -point signal to an rN -point one. So, we need N  modified 
bases that are constructed from N  original bases, and still contain properties of original bases. 
To get new bases, resample the original basis 
( 0.5)
cos
u i
N
 
 as 
( 0.5)
cos
u i
rN
 
, for 0,1, , 1i rN  . If 
the original bases is composed of 1
B
, where 
1
1
(0 0.5) (1 0.5) ( 1 0.5)
[cos  cos   cos ] N
u u u N
B R
N N N
       
,   (4.17) 
then the new bases are 
1
2
(0 0.5) (1 0.5) ( 1 0.5)
[cos  cos   cos ] rN
u u u rN
B R
rN rN rN
       
.   (4.18) 
To conserve more original properties, choose another bases 
1
3
(0 0.5 ) (1 0.5 ) ( 1 0.5 )
[cos  cos   cos ] rN
u r u r u rN r
B R
rN rN rN
       
,  (4.19) 
where 1
B
 and 3
B
 has common points at index ir , for 0,1, , 1i N  . So, 3
B
 conserves more 
properties of 1
B
 than 2
B
. 
Therefore, the enlarged signal 
1Nr
rf R

 can be gotten from 
1NF R  , 
15 
 
as three cases as follows: 
Case 1: 0g   
1 ( ), 1 ( ), 1 ( ), 1 ( ),
ˆ [ (0),  (1),  ,  ( 1 )].
2
D g r D g r D g r D g r
p
f f f f Nr r  
     (4.24) 
Case 2: 1,2, , 2g m   
1 ( ), 1 ( ), 1 ( ), 1 ( ),
ˆ [ ( ),  ( 1),  ,  ( 1 )].
2 2 2
D g r D g r D g r D g r
p p p
f f r f r f Nr r   
    (4.25) 
Case 3: 1g m   
1 ( ), 1 ( ), 1 ( ), 1 ( ),
ˆ [ ( ),  ( 1),  ,  ( 1)].
2 2
D g r D g r D g r D g r
p p
f f r f r f Nr  
     (4.26) 
Compounding the above three cases, we get the complete interpolation process. 
Figure 4.2 shows the discontinuity property of the blocky effect, where the 24-point signal is divided into 
three 8-point sub-signals and interpolated into a double size one by DCT without overlapping and with 
overlapping. The circle shows the place where the blocky effect happens. 
 
 
 
Fig. 4.2 The blocky effect of 1-D interpolated signals 
 
Ripple effect elimination 
 
The DCT interpolation method is a high-order interpolation and its bases are oscillatory. Since the 
polynomials don’t guarantee the sampled points between the original grid points, the ripple effect may cause. 
In order to solve this problem, a ripple effect elimination scheme is proposed. If the scale is r , there are 
17 
 
Step 3: Compound these blocks, we will get the enlarged image. 
 
In the preceding sections, the blocky effect elimination and the ripple effect elimination scheme in 1-D 
signal is proposed. These schemes can also bring good quality to 2-D image interpolation. 
 
Image enlargement via bilinear interpolation and DCT 
 
The algorithm concludes three significant parts: (i) detect the homogeneous area, (ii) interpolate the 
homogeneous area, and (iii) interpolate the edge area. The area is homogeneous is that the variance of gray 
level of neighbor pixels is very small. In the other words, the homogeneous areas are mostly compound of 
low-frequency parts, and the others are edge areas. 
 
Detection of the homogeneous areas 
 
When the original image is transferred into frequency domain by DCT, the homogenous and edge 
sub-blocks can be recognized by frequency coefficient matrix. In order to save operating time and memory, 
the big original image is divided into some 8 8  blocks. Then, depending on the individual characteristic 
of the blocks, a corresponding interpolation is applied. In order to distinguish different blocks, one takes the 
smooth sub-blocks that the proportion of the absolute sum of the upper-left coefficient frequency matrix is 
greater than a specific threshold; otherwise they are edge blocks, i.e. 
sum
th
sum
LL
T
Total

,         (4.32) 
where 
TF CfC
,
8 8: 1,2, 8; 1,2, 8ijF F i j R
      , ij
F
 are the frequency coefficients 
corresponding to original block f , 
4 4: 1,2,3,4; 1,2,3,4LL ijF F i j R
      ,
4 4
1 1
sum ij
i j
LL F
 

, 
8 8
1 1
sum ij
i j
Total F
 

, and th
T
 is a specific threshold. Fig. 4.3 shows the edge and homogenous areas with 
the black and white blocks of Lena image, respectively, detected by the proposed method. The threshold th
T
 
is set to 0.9 for all images. 
 
19 
 
Step 2: Transfer these blocks 8 8
f   into corresponding frequency coefficient matrices 8 8
F   by (4.29). 
Step 3: Sum up the absolute value of the 4 4  upper left sub-block of the corresponding frequency 
coefficient matrix 8 8
F   as SUM
LL
. 
Step 4: Sum up the absolute value of all elements of the corresponding frequency coefficient matrix 8 8
F   as 
SUMTotal . 
Step 5: If 
SUM
SUM
LL
Total
 is larger than a preset threshold th
T
, the block is a homogeneous ones, otherwise it is 
an edge ones. 
Step 6: Enlarge the edge block by (4.29)-(4.30) with ripple elimination (DCT method), and enlarge the 
homogenous part by bilinear interpolation. 
Step 7: Compound the blocks with 4 r -pixel overlapping to get the completely enlarged image. 
 
Image reduction via DCT for edge blocks 
 
Based on the same reasons, the reduction of image can be processed by the similar method. First, an image 
is divided into several 8 8  blocks with overlapping pixels. Then, recognize blocks as homogeneous and 
edge ones by (4.32). The homogeneous blocks ( )m
f
 are reduced by bilinear method (4.1). The edge blocks 
can be reduced by modified method. For reducing an 8 8  original edge block ( )e
f
 in 4 4  size, ( )e
f
 is 
firstly transformed into a corresponding frequency coefficient matrix ( )e
F
, then divide ( )e
F
 into four 
frequency coefficient sub-matrices, ( )e LL
F
, ( )e LH
F
, ( )e HL
F
 and ( )e HH
F
, where 
  
8 8
( ) ( ) : 1,2, ,8; 1,2, ,8 ,e ij eF F i j R
               
4 4
( ) ( ) : 1,2,3,4; 1,2,3,4e LL ij eF F i j R
       ,         
4 4
( ) ( ) : 5,6,7,8; 1,2,3,4 ,e LH ij eF F i j R
               
4 4
( ) ( ) : 1,2,3,4; 5,6,7,8 ,e HL ij eF F i j R
               
4 4
( ) ( ) : 5,6,7,8; 5,6,7,8 .e HH ij eF F i j R
               
21 
 
Step 4: Sum up the absolute value of all elements of the corresponding frequency coefficient matrix F  as 
SUMTotal . 
Step 5: If 
SUM
SUM
LL
Total
 is larger than a preset threshold th
T
,  the block is a homogeneous one; otherwise, it is 
an edge one. 
Step 6: Reduce the edge block by (4.33)-(4.36), and choose the best one with the highest reconstruction 
quality in dB from the performed five combinations with ripple elimination and enlarge the 
homogenous part by bilinear interpolation. 
Step 7: Compound these blocks to get the completely reduced image. 
 
Pixel-size-based image scaling via adaptive DCT for edge blocks 
 
For some applications, the multiple of enlargement is not an integer value. For this case, some researches 
[4.1, 4.2] have been proposed. In the method [4.1, 4.2], the multiple can be written as a rational number 
M
N , 
where M  and N  are integers. In other words, the process combines with M -multiple enlargement and 
1
N -multiple reduction for the whole image. When M  and N  are large and co-prime, it’s obvious that 
this approach has high time complexity. 
Besides, some enlargement multiples will make the size of the enlarged 8 8  block to be a non-integer. For 
example, one wants to enlarge a 512 512  image to a 600 600  one. So the multiple is 75 / 64 . In other 
word, every 8 8  block has to be zoomed to 
75 75
8 8

 where 
75
8  is not an integer. In this case, we choose 
maximum integer 9 which is less than 
75
8  to be the desired enlarged block size. This causes an error 
3
8  
between 9 and 
75
8 . A counter is used to record the accumulated errors. Once the counter is larger than 1, the 
block size will be zoomed to 10. During the first year, we propose a new algorithm that enlarges the blocks 
adaptively without losing its quality. 
In order to process different multiples of blocks, the DCT enlargement (4.29)-(4.30) is divided into 
horizontal and vertical enlargement. The reason for dividing the zooming process into horizontal part and 
vertical part is that the enlarged blocks can’t be compounded when the dimensions of enlarged blocks are 
mutually different. The problem happens when compounding these zoomed blocks, because the width and 
height of the blocks is not equal. From (4.29) and (4.30), one has 
 
23 
 
for 1i   to 1H
N
 
2 2
2 2
(8 8 )h h
q q
d d
p p
 
     
  // accumulate missing pixels per block 
if 
1hd   then 
Zoom original 8 8 blocks into 
2
2
8 8
q
p
 
  
   blocks. 
// The counter is not more than 1, so the zooming processes remain invariant. 
else 
Zoom original 8 8  blocks into 
2
2
8 8 1
q
p
  
     
    blocks. 
// The counter is more than 1, so the zooming processes add one more pixel than original 
processes. 
end 
end 
end 
Step 3: Divide the 1 2
p q
horizontal zoomed image into several 8 8  sub-blocks ( , )i j
f
 for 
21,2, , Hi N  and 2
1,2, , ,Vj N  where NH2 is the number of sub-blocks of the horizontally 
divided zooming image, and NV2 is the number of sub-blocks of the vertically divided zooming 
image. 
Step 4: Perform horizontal zooming by (4.37)-(4.38) with adaptive zooming multiple. 
for 1i   to 2H
N
 
0Vd   
for 1j   to 1V
N
 
1 1
1 1
(8 8 )V V
q q
d d
p p
 
     
   
// A counter accumulates missing pixels every block. 
if 
1Vd   then 
25 
 
 
 
Fig. 4.4 The flowchart of DCT combined with EP for integer-multiple image reduction 
 
Step 1: Initial population 
In the reduction processes, the original image is divided into several 8 8  blocks f , then transfer these 
blocks into corresponding frequency coefficient matrices F  by (4.29). The frequency coefficient matrix is 
divided into four sub-matrices as follows 
8 8: 1,2, ,8; 1,2, ,8 ,ijF F i j R
              
4 4: 1,2,3,4; 1,2,3,4 ,LL ijF F i j R
       
4 4: 5,6,7,8; 1,2,3,4 ,LH ijF F i j R
              
4 4: 1,2,3,4; 5,6,7,8 ,HL ijF F i j R
      and 
4 4: 5,6,7,8; 5,6,7,8 .HH ijF F i j R
       
By backward DCT with LL
F
, LH
F
, HL
F
 and HH
F
, we get the corresponding spatial reduced images as 
( , ) ( , ) ,TLL L LL Lf i j C F i j C             (4.44) 
( , ) ( , ) ,TLH L LH Hf i j C F i j C                 (4.45) 
( , ) ( , ) ,THL H HL Lf i j C F i j C            (4.46) 
( , ) ( , ) .THH H HH Hf i j C F i j C                (4.47) 
To get a better reduced image, we calculate five combinations i
f
 of above sub-matrices as 1 LL
f f
,
2 LL LHf f f  , 3 LL HL
f f f 
, 4 LL LH HL
f f f f  
, and 4 LL LH HL HH
f f f f f   
. Then, transform the 
27 
 
 
(4.53) 
where max( )   and 
min( ) 
. The fitness function maps the ,
ˆ( )k lOF F  from 
, ,
ˆ ˆ[ ( ), ( )]k l k lOF F OF F
 
to appropriate range. 
[ , ] 
. 
Step 4: Probability function 
Calculate the probability function score by fitness function score: 
 
                                                                (4.54) 
 
 
Step 5: Mutation 
To find better individuals, we create N  individuals to compare with the original individuals. First, mutate 
each ,i j
P
, 1, ,i N  to increase the population size from N  to 1.6N , by assigning ,i j
P
 the following 
values: 
, , , , , , ,
ˆ: (1 sgn( (0,1)) (1 ( ))),  for 1,2, ,0.6 ,i j k N l i j k l k lP P N PF F k N          (4.55) 
where 
2( , )N    is the Gaussian random variable with mean   and variance 
2 .   is a weighting 
factor for variation for individuals, and sgn( ) is the standard sign function. The mutation makes the better 
individuals have smaller variations and worse individuals have higher variations. The remainder 0.4N  
individuals are produced from the best individual 
*
, ,i j lP : 
*
, ,1.6 , , , 1: (1 sgn(0,1) ) for 1,2, ,0.4 ,i j N m l i j lP P m m N             (4.56) 
where 1

 is a weighting factor. If the newly generated individuals is greater than the upper bound or less 
than lower bound, then assign upper (lower) bound to these individuals. 
Step 6: Selection 
Calculate the OF  score of each individual, and select first N  individuals to next generation. The best 
individual 
*
, ,i j lP  always survives to next generation. 
*
, ,i j lP  changes when the individual that is better than 
*
, ,i j lP  is produced. 
Step 7: Penalty 
Adjust   in the following way over generations to further avoid the search from being trapped into a local 
extreme. 
,
, ,
,1
ˆ( )ˆ ˆ( ( )) : ( ) .
ˆ( )
k l
k l k l N
k li
FF F
PF FF F PF F
FF F

 

29 
 
the low-frequency subband. The left part of Fig. 5.1 shows the forward two-dimensional wavelet transform 
and the right part is the backward wavelet transform. By assuming that the input is a low-pass filtered image 
(LL-band), the unknown high-frequency subbands can be predicted from the low-frequency subband. The 
easiest prediction algorithm shown in Fig. 5.1 is to pad zeros to high-frequency subbands as LH-band, 
HL-band, and HH-band. However, to present a better prediction algorithm for effectively predicting the 
high-frequency subbands, the image interpolation model in wavelet transform is desired. 
 
 
 
Fig. 5.1. Image interpolation model in wavelet transform 
 
Because bilinear interpolation assumes the original data is first-derivative continuous, the result is usually 
blurred when it interpolates the points at edges. Nevertheless, the wavelet-based interpolation can avoid this 
artifact by its good approximation property. 
 
Wavelet transform 
 
Wavelet transform is the most popular technique for image compression and data analysis. It provides 
efficient time-frequency localization and multiresolution analysis, so it is suitable for image interpolation. 
Wavelet transformation decomposes data into different subbands hierarchically and each high frequency 
subbands can locate the regions of edges and details in the original image. Fig. 5.2 shows the regions of 
edges and details in different high-frequency subbands by Haar wavelet transform. From top to bottom, the 
figure shows original data, high-subband data in the first level decomposition, low-subband data in the 
second level decomposition, and high-subband data in the second level decomposition, respectively. It can 
be seen in Figure 5.2, the detail information exists across different level decompositions, and this inter-scale 
correlation, for example in [5.10], provides information for estimating the unknown subbands. 
Two-dimensional wavelet transform can be implemented using a one-dimensional filter on an image once in 
each column and once in each row, which induces four subbands, i.e., LL-band, LH-band, HL-band, and 
HH-band, respectively. The LL-band is the approximation of original image, the LH-band represents vertical 
information, the HL-band represents horizontal information, and the HH-band represents diagonal 
31 
 
 
 
Fig. 5.3. Two-dimensional wavelet transform in four subbands 
 
Lifting scheme 
 
The wavelet transform conducts the convolution operation with two filters L and H. However, such 
convolution operation suffers from high computation cost and large memory space for storage. Thus, an 
improved approach called lifting scheme was developed [5.22]. The main concept of the lifting scheme is to 
decompose the original long-length wavelet filters into a sequence of short-length operators called 
“prediction and update” to perform the convolutions of the odd and even sequences of the original input 
image in a half-size computation, where data in the odd/even sequence are the data at odd/even positions in 
the original image. 
33 
 
,LL*IJHL ColRow          (5.3b) 
,LL*IJHH ColRow          (5.3c) 
where the proposed low-pass prediction filter I  and the proposed high-pass prediction filter J  are 
applied to each row and column of an image, notation   represents a convolution operator, and LL  is the 
input low-pass filtered image. 
The next subsection derives 
 53 53,I J  and  97 97,I J  according to 5/3 and 9/7 filters, respectively. 
 
5/3 filter based prediction algorithm 
 
 
 
Fig. 5.5. Lifting scheme for 5/3 filter 
 
The lifting scheme of 5/3 filter is shown in Fig. 5.5, which can be implemented by 
, ))(( 222120   iiii xxxd         (5.4a) 
, ))(( 121 iiii ddxs          (5.4b) 
where 
1
0,1,2,...,
2
M
i


 ( M  is the input data size), and 
1 ,1 ,
4
1
 ,
2
1
10 

 
. A symmetrical 
extension for the boundary conditions of an input image are given by 
, for 0i ix x i   and 
2 , for 1i M ix x i M   . Rewrite Eq. (5.4a) and Eq. (5.4b) as 
, ))(
2
1
( 22212  

 iiii xxxd
       (5.5a) 
35 
 
and 
, ~ 11012   iii sbsbx          (5.7b) 
respectively, where 210
 , , aaa
 and 10
 , bb
 have constraints 
0 1 2 1a a a            (5.8a) 
and 
. 110  bb          (5.8b) 
 
Then, replacing 2i
x
 and 2 1i
x   in Eqs. (5.6a) and (5.6b) by 2i
x
 and 2 1i
x   in Eqs. (5.7a) and (5.7b), 
respectively, yields 
2
2
1
121
10210
1
010
2
0
22110
11012110
11021120
8
)
44
3
8
(       
)
4484
3
8
()
484
3
(
8
    
))(
8
1
(         
)(
4
1
)(
4
3
         
)(
4
1
))(
8
1
(~














ii
iii
iii
iiiii
iiiiii
s
a
s
baa
s
bbaaa
s
baa
s
a
sasasa
sbsbsasasa
sbsbsasasas
  (5.9a) 
and 
0 1 1 2 1 0 1 1
0 1 1 2 2
0 0 1 1 2 2
1 0 1 1 2
1
( )( ) ( )
2
1
        ( )( )
2
    ( ) ( )  ,
2 2 2 2 2 2
i i i i i i
i i i
i i i i
d a s a s a s b s b s
a s a s a s
a a a a a a
s b s b s s
  
 
  
          
      
              
  (5.9b) 
where 
1
0,1,2,...,
2
M
i


, and the boundary conditions are 
, for 0i is s i   and 
1
1
, for 
2
i M i
M
s s i 

 
. 
By Eqs. (9a) and (9b), the prediction filters 53
I
 and 53
J
 are respectively given as 
0 0 0 0 01 1 2 1 1 2 1 2
53
3 3 3
, , , ,
8 4 8 4 8 4 8 4 4 8 4 4 8
a a b a ba a a b a a b a
I
 
             
    (5.10a) 
and 
37 
 
9/7 filter based prediction algorithm 
 
 
 
Fig. 5.7. Lifting scheme for 9/7 filter 
 
Similarly, the lifting scheme of 9/7 filter shown in Fig. 5.7 is given by [5.22] 
, )( 22212   iiii xxxd         (5.13a) 
, )( 12 iiii ddxs          (5.13b) 
, ))(( 10  iiii ssdd         (5.13c) 
, ))(( 11 iiii ddss          (5.13d) 
where 
1
0,1,2,...,
2
M
i


( M  is the input data size), 58613.1 , 05298.0 , 88291.0 , 
44350.0 , 81289.00  , and 23017.11  . A symmetrical extension for the boundary conditions is the 
same as the 5/3 filter given by 
, for 0i ix x i   and 2
, for 1i M ix x i M   . Rewrite Eq. (5.13c) and Eq. 
(5.13d) as 
42632522412322121220   iiiiiiii xhxhxhxhxhxhxhd   (5.14a) 
39 
 
448337463823527443628
133251742342618
312315074032241608
121130530221406
211032012043011002400
4433221108
33221107
3423121106
23121105
2413211204
13211203
1431221302
31221301
4132231400
)()()(       
)(       
)(       
)(       
)()()(    
)(       
)(       
)(       
)(       
)(       
)(       
)(       
)(       
)(~



























iii
i
i
i
iii
iiiii
iiii
iiiii
iiii
iiiii
iiii
iiiii
iiii
iiiiii
salsblalalsblblalalal
sblblblalalalal
sblblblblalalalalal
sblblblalalalal
sblblalalalsblalalsal
sasasasasal
sbsbsbsbl
sasasasasal
sbsbsbsbl
sasasasasal
sbsbsbsbl
sasasasasal
sbsbsbsbl
sasasasasals
 (5.17a) 
and 
, )()()(        
)(        
)(        
)()()(     
)(        
)(        
)(        
)(        
)(        
)(        
)(
~
446335443623325423426
131231540322416
21130530221406
111032012042011002300
4433221106
33221105
3423121104
23121103
2413211202
13211201
1431221300





















iii
i
i
iii
iiiii
iiii
iiiii
iiii
iiiii
iiii
iiiiii
sahsbhahahsbhbhahahah
sbhbhbhahahahah
sbhbhbhahahahah
sbhbhahahahsbhahahsah
sasasasasah
sbsbsbsbh
sasasasasah
sbsbsbsbh
sasasasasah
sbsbsbsbh
sasasasasahd
(5.17b) 
which implies the low-pass prediction filter and the high-pass prediction filter are respectively given by 
, ]),(),(          
),(          
),(          
),(          
),(),(,[
483746383527443628
33251742342618
312315074032241608
21130530221406
11032012040110020097
alblalalblblalalal
blblblalalalal
blblblblalalalalal
blblblalalalal
blblalalalblalalalI





    (5.18a) 
and 
97 0 0 2 0 0 1 1 0 4 0 2 1 0 2 3 0 1 1
6 0 4 1 2 2 0 3 5 0 3 1 1 2
6 1 4 2 2 3 0 4 5 1 3 2 1 3
6 2 4 3 2 4 5 2 3 3 6 3 4 4 5 3
[ , ( ), ( ),
          ( ),
          ( ),
          ( ), (
J h a h a h a h b h a h a h a h b h b
h a h a h a h a h b h b h b
h a h a h a h a h b h b h b
h a h a h a h b h b h a h a h b
      
     
     
      6 4), ] ,h a    (5.18b) 
41 
 
similar derivation shown in the above, one has the same filters given in Eqs. (5.18a) and (5.18b). 
 
Construction of LL-band for high performance image resolution 
enhancement 
 
In the lifting scheme, the original input data is split into even ( 2i
x
) and odd sequences ( 2 1i
x  ) 
1
for 0,1,2,...,
2
M
i


 ( M  is the input data size), one for low-pass filtered coefficients i
s
 and the other 
for high-pass filtered coefficients i
d
 
1
for 0,1,2,...,
2
M
i


. After wavelet transform, i
s
 are kept and i
d
 
are discarded for image resolution enhancement. However, some key pixels existed in 2i
x
 and 2 1i
x   
dominate the reconstruction of the original image or to predict the loss information in interpolation process. 
Therefore, this subsection discusses how to select the even sequence 2i
x
 or the odd sequence 2 1i
x   to 
determine i
s
 to have the characteristic of the original image. 
 
First, construct the low-band wavelet coefficients through the odd-length wavelet filter in lifting structures 
based on even and odd pixels of the original image are respectively performed. Then, select the better one 
which yields a high performance image resolution enhancement. Therefore, one more bit is required to 
indicate better prediction algorithm is performed based on either the even or odd prediction filter for original 
image reconstruction. For example, the original input data, the low-band coefficients, and the high-band 
coefficients of the undecimated 5/3 wavelet transform are respectively given as 
 0,0,0,0,255,0,0,0,0,0  ,
 
 0,0, 31.87,63.75,191.25,63.75, 31.87,0,0,0  , 
 
and 
 0,0,0, 127.5,255, 127.5,0,0,0,0  , 
 
for position indices 0,1,2,...,i M , where 9M  . Obviously, the even sequence 
(
 0, 31.87,191.25, 31.87,0 ,  for 0,2,4,6,8i  
) of the low-band coefficients dominates the characteristics 
43 
 
* 0 0 2 0 1 1 2 0 2 1 2 2 1 1
97
3 4 2 4 1 0 4 2 1 3 1
5 6 0 4 6 1 2 6 2 1 3 5 1
0 1 7 8 2 8 1 0 4 8
2 2( ) 2
[ , ,
2 2
2( ) (2 ) 2( )
          ,
2
2( ) (2 ) 2( )
          ,
2
2( ) ( 2
          
l l a l a l l l l a l a l b
I
l l l l a l l a l l b
l l l l l a l l a l l l b
l l l l l l a l l l
      

      
        
         2 1 3 5 7 1
3 2 8 4 2 1 6 2 2 7 5 3 1
5 4 6 4 1 8 4 2 7 5 1
7 6 8 6 1 6 2 7 1 8 8 2 8 1
) 2( )
,
2
2( ) (2 ) 2( )
          ,
2
2( ) (2 ) 2( )
          ,
2
2( ) 2 2
          , ]
2 2
a l l l l b
l l l l l a l l a l l l b
l l l l a l l a l l b
l l l l a l a l b l l a l a
    
        
      
      
   (5.24a) 
and 
* 0 0 1 0 2 1 2 0 2 1 2 2 1 1
97
3 4 2 4 1 0 4 2 1 3 1
5 6 0 4 6 1 2 6 2 1 3 5 1
1 0 6 2 0 1 4 0 2
2 2( ) 2
[ , ,
2 2
2( ) (2 ) 2( )
          ,
2
2( ) (2 ) 2( )
          ,
2
2( ) (2 ) 2(
          
h h a h a h h h h a h a h b
J
h h h h a h h a h h b
h h h h h a h h a h h h b
h h h h h a h h a h
      

      
        
       5 3 1 1
3 2 4 2 1 6 2 2 5 3 1
5 4 6 4 1 4 2 5 1 6 6 1 6 2
)
,
2
2( ) (2 ) 2( )
          ,
2
2( ) 2 2
          , ] .
2 2
h h b
h h h h a h h a h h b
h h h h a h a h b h h a h a
 
      
      
   (5.24b) 
 
Evolutionary programming algorithm 
 
Fig. 5.9 is the flowchart of EP. The input of EP are scaling ratio and the specific image or general images 
which are common used in simulation tests, such as Lena, Baboon…etc. Each individual in the population 
stands for a different prediction filter, and EP evaluates each individual performance in terms of PSNR under 
the prediction algorithm. The optimization problem concerns image quality only. The original image is 
reconstructed from the LL-band by the proposed prediction algorithms with the estimation filters produced 
from EP. The higher PSNR the estimation filter can achieve, the better the estimation filter is. 
 
45 
 
11 1 21 2 1,..., , ,..., , ,...,  .              
Then the interval matrix X  can be denoted as ( )X  . Let 1 2 2 3 3 5
( ),  ( ),  ( ),i i ii i i         and so on, to 
construct the desired initial population of size   (e.g., 30  ). 
Construct a -dimensional  initial population 1, 2, ,
, ,...,j j j jP P P P     ( ,i j
P
 denotes the ith individual in the 
jth generation) of size   ( 1   for 5/3 prediction filters and 3   for 9/7 prediction filters) based on the 
QRS. In order to speed up the searching of EP, the first individual of the initial population 1,1
P
 is replaced 
by the general parameters, i.e., 
2
1
2
a 
 for 5/3 prediction filters and 
1 2 1
1 1 1
,  ,  
4 2 2
a a b
 
   
   for 9/7 
prediction filters. The other individuals are generated by 
, ( )( ) ,i j RP i              (5.29) 
where the lower-bound 1,1 1,1
% | |P c P   
 and the upper-bound 1,1 1,1
% | |P c P   
 (e.g., c = 100) are 
selected from empirical studies. 
 
Step 2: Objective function 
After the initial populations are generated, they are passed to our enlargement framework, and the objective 
function PSNR is used to evaluate each individual. Assign each ,
,  for 1,...,i jP i  , an objective function 
(OF) score which is denoted as 
, ,( ) ( )i j i jOF P PSNR P           (5.30) 
for the specific image and OF is 
, 1 , 2 , ,( ) ( ) ( ) ( )i j i j i j N i jOF P PSNR P PSNR P PSNR P                 (5.31) 
for general images, where N is the number of input images. 
Arrange ,
,  for 1,...,i jP i  , in the descending order, starting from the one with the highest objective 
function score. 
 
Step 3: Fitness function 
Each sorted ,
,  for 1,...,i jP i  , will have a fitness function (FF) score in order to put more weights on those 
47 
 
*
1.8 , (1 ),  for 1,2,...,0.2  ,k j jP P k k              (5.37) 
where   (e.g.,  =0.1)is a weighting factor. 
 
Step 6: Selection 
Calculate the OF  score of each ,
,  1,...,2i jP i  . Arrange them in an ascending order, starting from the 
best individual in the population. The first   individuals are selected for the next generation 1j
P  , in which 
the best one of each generation, denoted as 
*
jP , always survives and is selected for the next generation. 
Whenever 
*
jP  is no longer the best individual during the evolutionary process, update it by the newly 
generated best one. 
 
Step 7: EP termination condition 
Set   to be the difference between the best individual and worst individual after the first generation is 
completed. 
1,2 ,2
 .
P P
 



        (5.38) 
Because only individuals with reasonable parameters and PSNR can survive,   will be confined to a 
reasonable search range even if one may set the initial   too large. Eq. (5.38) will set   within a 
reasonable range and the situation where 
 , ,i jP      can be avoided too. Also, adjust   in the 
following way over generations, to further avoid the search from being trapped into a local extreme. 
* *
1
* * * *
2 1
if (possible local max. ( ) ( ) ){
    1.5;
}elseif (already increase ( ) ( )  and ( ) ( ) ){
    0.5;
}else { ;}
j j
j j j j
OF P OF P
OF P OF P OF P OF P

 
  
 
 

 
  
 
    
 
  
where   is convergence tolerance (e.g.,  =0.1) in experimental results and j  is the generation index. 
Then, go to Step 2 and continue until the extreme value 
)( *jPOF  cannot be further improved and/or the 
allowable number of generations is reached. 
 
 
49 
 
where 








0,1
0,
2
1
f
f
D f
 
 
for 10  ni  and 10  mj . The first coefficient 0,0
g
 is termed the “DC coefficient”, and the 
remaining coefficients are called the “AC coefficients.” 
 
The image is broken up into blocks of n×m pixels xy
p
(with n = m = 8 typically), and Eq. (6.1) is used to 
produce a block of n× m DCT coefficients ji
g ,  for each block of pixels. The coefficients are then quantized, 
which results in lossy but highly efficient compression. The decoder reconstructs a block of quantized data 
values by computing the IDCT whose definition is 
 










 





 

1
0
1
0
, ,
2
)12(
cos
2
)12(
cos
22 n
i
m
j
jijixy
m
jy
n
ix
gDD
nm
p

   (6.2) 
where  








0,1
0,
2
1
f
f
D f
, 
for 10  ni  and 10  mj . 
The double sum of Eq. (6.1) and Eq. (6.2) can be written as the matrix product: 
TCPCG  ,             (6.3) 
CGCP T  ,             (6.4) 
where P is the k×k matrix of the pixels, and G is the k×k matrix of the DCT coefficients and C is the matrix 
defined by  












 


0,
16
)12(
cos
2
0,
1
i
ij
k
i
k
Cij

.          (6.5) 
 
51 
 
The encoder partitions all the coefficients into a set k
T
 (k = 1, 2, 3, …, N, where N is the number of sets) 
and performs the significance test 
n
ji
Tji
c
k
2,
),(
max 
  
 
on each set k
T
. The result may be either “no” (all the coefficients in k
T
 are insignificant, so k
T
 itself is 
considered insignificant) or “yes” (some coefficients in k
T
 are significant, so k
T
 itself is significant). This 
result is transmitted to the decoder. If the result is“yes”, then k
T
 is partitioned into four subsets by both 
encoder and decoder. Using the same rule, the significant test is performed on all the subsets. This 
partitioning is repeated until all of the significant sets are reduced to size 1 (i.e., they contain one coefficient 
each block, and that coefficient is significant). This is how the significant coefficients are identified by the 
sorting pass. 
 
The significance test performed on a set k
T
 can be summarized by 



 


otherwise
c
TS
n
jiTji
n
,0
2max if ,1
)(
,),(
.          (6.6) 
The result,
)(TSn , is a single bit transmitted to the decoder. The result of each significance test becomes a 
single bit written on the compressed stream, and then the number of tests can be minimized. To achieve this 
goal, the sets expected to be significant should be large and the sets expected to be insignificant should 
contain only one element. 
 
Spatial Orientation Trees 
 
The sets k
T
 are created and partitioned using a special data structure called a spatial orientation tree. This 
structure is defined in a way that exploits the spatial relationships between the wavelet coefficients in the 
different levels of the subband pyramid. Experience has shown that the subbands in each level of the 
pyramid exhibit spatial similarity. Any special features, such as a straight edge or a uniform region, are 
visible in all the levels at the same location. 
 
Each level is divided into four subbands. In general, a coefficient at location (i,j) in the image is the parent of 
53 
 
2) Sorting Pass: 
2.1) for each entry ( , )i j  in the LIP do: 
2.1.1) output 
( , )nS i j ; 
2.1.2) if 
( , ) 1nS i j   then move ( , )i j  to the LSP and output the sign of ( , )c i j ; 
2.2) for each ( , )i j  in the LIS do: 
2.2.1) if the entry is of type A  then 
  output ( ( , ))nS D i j ; 
  if ( ( , )) 1nS D i j   then 
* for each ( , ) ( , )k l O i j  do: 
- output 
( , )nS k l ; 
- if 
( , ) 1nS k l   then add ( , )k l  to the LSP and output the sign of ( , )c k l ; 
- if 
( , ) 0nS k l   then add ( , )k l  to the end of the LIP; 
* if ( , ) 0L i j   then move ( , )i j  to the end of the LIS, as an entry of type B , and 
go to Step 2.2.2); otherwise, remove entry ( , )i j  from the LIS; 
2.2.2) if the entry is of type B  then 
  output ( ( , ))nS L i j ; 
  if 
( ( , )) 1nS L i j   then 
* add each ( , ) ( , )k l O i j  to the end of the LIS as an entry of type A ; 
* remove ( , )i j  from the LIS. 
3) Refinement Pass: for each entry ( , )i j  in the LSP, except those included in the last sorting pass (i.e., 
with same n ), output the th
n
 most significant bit of 
( , )c i j
; 
4) Loop: decrement n  by 1 and go to Step 2 if needed.  
55 
 
 
 
Fig. 6.4. Flowchart of the proposed algorithm 
 
 
 
Fig. 6.5. The steps of reordering method 1 
57 
 
 
 
Fig. 6.6. The reordering method 1 
 
59 
 
 
 
Fig. 6.9. (a) Dividing the LL subband into 16×16 blocks (b) the sub-blocks which is divided from 16×16 
block numbered for 1 to 13 (c) reordering each sub-block to the corresponding position 
 
After the reordering method 2, we can treat each 16×16 block as a depth-4 spatial orientation tree. Fig. 6.10 
shows the spatial correlation between different subbands in the corresponding position. 
 
61 
 
method 2. There are 16 subbands calling HL1, LH1, HH1, HL2, LH2, HH2, HL3, LH3, HH3, HL4, LH4, HH4, 
HL5, LH5, HH5, and LL5 (see Fig. 6.11) with the depth-5 spatial orientation trees. Meanwhile, the energy is 
concentrated in LL5 subband. Consequently, it can obtain better compression ratio than the traditional 8×8 
DCT block with SPIHT algorithm. 
 
 
 
Fig. 6.11. The depth-5 spatial orientation tree 
 
The Preprocessing Method 
 
After reordering DCT coefficients, the energy is centered on LL subband (upper left subband). The 
coefficients of LL subband are very big, and the others are very small. For decreasing the difference between 
LL subband and the other subbands, we use a simple calculation for LL subband. The pseudo code of the 
preprocessing method is shown below: 
 
63 
 
enlarged images by bilinear method and bicubic method are shown in Fig. 4.6(b) and Fig. 4.6(c), 
respectively. The results from DCT arbitrary scale enlargement and the proposed pixel-size-based 
enlargement are shown in Fig. 4.6(d) and Fig. 4.6(e), respectively. Table 4.4 shows the execution times of 
the four methods.  
 
 
 
Fig. 4.6 (a) The original 48 48  image (b) Bilinear method (losing the symmetric appearance) (c) Bicubic 
method (losing the symmetric appearance) (d) DCT-based (remaining the symmetric appearance) (e) The 
proposed method (remaining the symmetric appearance) 
 
Table 4.4 Execution times of various enlargement methods for a 4848  Dollar image (the scaling factor r 
=20.4375) 
 
Methods Enlargement time (in 
second) 
Bilinear 4.4 
Bicubic 4.8 
DCT-based arbitrary scale 
enlargement 
19.4 
Proposed pixel-size-based 
enlargement 
7.84 
 
By the above results, bilinear method blurs the edges of the enlarged image acutely and bicubic method 
produces zigzagging artifact. The DCT-based arbitrary scale enlargement has good quality because it 
eliminates the blocky effect and the ripple effect and shows a good characteristic on the symmetric property. 
Table 4.4 also shows, without losing the image quality, the proposed method can save execution time 
compared with DCT-based arbitrary scale enlargement. Moreover, if the enlargement scale is not an integer, 
the desired size and the actually enlarged size are different while applying bilinear method and bicubic 
method. These methods only take the integer part of the enlargement scale as enlargement multiple. So the 
two methods will cause 
981 48 20.4375 981 48 20 21         pixels missing in height and width, 
65 
 
Proposed DCT combined 
with bilinear enlargement  
method with overlapping 4 
thT =0.9 
0.9375 3.8906 
 
Example 3:  The comparison among different scaling methods in terms of PSNR is given in Table 4.7- 
Table 4.10 where different testing images in Fig. 4.7 (a)-(d) are used. 
 
Fig. 4.7 Four testing images (a) Lena (b) Pepper (c) Text (d) Bridge 
 
 
 
Table 4.7 PSNRs (in dB) of different scaling methods (reducing the Lena 512 image by different reductions, 
and enlarging the reduced image by various methods). 
67 
 
[4.2] 
Proposed reduction th
T
=0.9 
21.1 21.61 21.107 22.03 22.045 
 
Table 4.10 PSNRs (in dB) of different scaling methods (reducing the Bridge 512 image by different 
reductions, and enlarging the reduced image by various methods). 
 
Methods 
Bilinear 
 
Bicubic 
 
Fast 
edge 
[4.5] 
DCT [4.1] 
enlargement 
overlap 4 
Proposed 
enlargement 
overlap 4 
with thT =0.9 
Haar wavelet reduction 24.74 24.908 24.43 24.97 24.951 
DCT-based reduction 
[4.2] 
26.04 26.267 25.52 26.294 26.271 
Proposed reduction thT
=0.9 
26.038 26.263 25.519 26.288 26.265 
 
To make our detection method more accurate, one can choose a larger block size such as 16 16  to include 
more high-frequency bases which present the edge information in a block. Table 4.11 shows the 
improvement after changing the block’s size. The execution time of the proposed reduction algorithm with 
16 16  block size only needs 0.1 second more than the proposed reduction algorithm with 8 8  block size 
for a 512 512  image. 
 
Table 4.11 PSNRs (in dB) of different scaling methods with different sizes of blocks (reducing the Lena 512 
image by different reductions, and enlarging the reduced image by various methods). 
 
         Enlargement 
 
 
Reduction     
 
DCT [4.1]  
enlargement 
overlap 4 
Proposed 
enlargement   
overlap 4 
with th
T
=0.9 
DCT-based reduction [4.2] 
Block size: 8 8  
34.512 34.52 
DCT-based reduction [4.2] 
Block size: 16 16  
34.605 34.631 
69 
 
 
 
 
Fig. 4.8 shows the performance improvement of EP for an illustrative block. From Table 4.12, the result 
shows the proposed DCT combined with EP reduction method is better than DCT-based reduction method. 
Although the improvement is small and the time consuming is very large, it proves the performance of our 
proposed method. 
 
1.4.2. 第二年 
 
Experiment simulation 
 
The test images are Lena, Baboon, Barbara, Boat, Peppers, Medical 1 and Medical 2, cameraman, house, 
jetplane, lake, pirate, walkbridge, woman_blonde and woman_darkhair shown in Fig. 5.10. Lena has 
various types of image components, Baboon has many detailed components, Barbara has mainly diagonal 
edges, Boat has mainly horizontal edges, Peppers has strongly vertical edges, we also use extra images 
cameraman, house, jetplane, lake, pirate, walkbridge, woman_ blonde and woman_darkhair to test our 
performance. The two medical images Medical 1 and Medical 2 are x-ray images of the breast and the tooth, 
respectively. These 512512  images (Lena, Baboon, Barbara, Boat, and Peppers) are from USC image 
database [5.24] and the 512512  images (cameraman, house, jetplane, lake, pirate, walkbridge, woman_ 
blonde and woman_darkhair) are from ImageProcessingPlace.com [5.26]. If there are color images in these 
image databases, they will be transformed to gray images by Matlab function rgb2gray.  
The EP parameters are chosen as population size 30  , EP generation 30 , weighting factors c=100 in 
Step1, 
 , [0,1000]  
 in Step 3, 0.1  in Step 5, and 0.1  in Step 7. Although the EP-based 
prediction filters have effective improvement, it consumes more time. So, the main goals of employing EP 
71 
 
Table 5.1. PSNR of zero padding method and proposed method for 5/3 filter 
 
 
zooming ratio 
1
2
 zooming ratio 
1
4
 
zero padding 
proposed method without EP 
zero padding 
proposed method without EP 
proposed method with EP proposed method with EP 
Lena 34.61 
35.28 
29.11 
29.43 
35.33 29.48 
Baboon 24.12 
24.11 
21.21 
21.13 
24.19 21.21 
Barbara 25.77 
25.53 
23.63 
23.73 
25.85 23.75 
Boat 30.29 
30.68 
25.81 
25.82 
30.73 25.90 
Peppers 30.87 
33.07 
27.76 
28.68 
33.13 28.75 
Medical 1 36.81 
37.76 
31.36 
31.61 
37.85 31.62 
Medical 2 44.61 
44.54 
42.21 
42.49 
44.64 42.53 
cameraman 37.32 
39.24 
27.96 
28.21 
39.66 28.35 
house 46.57 
48.37 
34.93 
35.88 
50.82 36.38 
jetplane 34.15 
35.25 
27.54 
27.8 
35.32 27.85 
lake 31.05 
31.71 
25.74 
25.98 
31.74 26.01 
pirate 31.39 
31.74 
27.03 
27.13 
31.84 27.18 
walkbridge 27.50 
27.77 
23.54 
23.55 
27.80 23.60 
woman_blonde 29.71 
29.92 
26.58 
26.61 
29.93 26.87 
woman_darkhair 41.52 
42.18 
36.03 
36.42 
42.24 36.47 
 
73 
 
44.75 42.67 
cameraman 39.44 
39.48 
28.42 
28.47 
40.06 28.61 
house 50.61 
48.35 
35.94 
36.09 
51.25 36.74 
jetplane 35.19 
35.5 
27.96 
28.02 
35.69 28.08 
lake 31.69 
31.88 
26.08 
26.16 
32 26.20 
pirate 31.85 
31.94 
27.28 
27.31 
32.05 27.35 
walkbridge 27.88 
27.95 
23.73 
23.72 
27.99 23.75 
woman_blonde 30.01 
30.12 
26.73 
26.73 
30.43 26.96 
woman_darkhair 42.24 
42.35 
36.53 
36.59 
42.54 36.71 
 
Similarly, the results of 9/7 wavelet filter for zooming ratios 
1
2  and 
1
4  are shown in Table 5.2. This table 
shows similar results in Table 5.1. The results with 9/7 filter have higher PSNR than that with 5/3 filter. The 
optimal parameters for zooming ratio 
1
2  are 
 1 2 10.1684, 0.7235, 0.5139a a b    and 
 1 2 10.2859, 1.4615, 0.6428a a b     in Baboon and Barbara, respectively, and the parameters for 
zooming ratio 
1
4  are 
 1 2 10.4795, 0.0628, 0.2920a a b    and  1 2 10.0953, 0.9206, 0.6126a a b    
in Baboon and Barbara, respectively. Fig. 5.11 shows the improved performance of EP in Baboon and 
Barbara with zooming ratio 
1
2 , respectively. 
 
75 
 
 
 
Fig. 5.12. PSNR values reconstructed with the total LL-band coefficients at various D5/3 prediction 
parameters: (i) 1
0.5a 
 for general images; (ii) EP-based optimal for each specific image; (iii) EP-based 
optimal 1
0.672a 
 for general images 
 
Table 5.3. PSNR comparison between fixed parameter  , EP-based parameter   for general images, and 
EP-based parameter for each specific image 
 
 fixed parameter EP-based (general) EP-based (specific) 
Lena 35.28 35.31 35.33 
Baboon 24.11 24.18 24.19 
Barbara 25.53 25.64 25.85 
Boat 30.68 30.72 30.73 
Peppers 33.07 33.13 33.13 
 
Table 5.4 and Table 5.5 show the PSNR comparison of the proposed methods and other common 
frequency-domain methods such as DCT and Haar wavelet. Here, we would like to point out that for a fair 
comparison, the starting zooming out images (i.e., reduced-size images) corresponding to various methods 
compared are constructed by their corresponding methods. As a result, no comparison with the conventional 
spatial methods is given. In Lena, our method for 5/3 filter has 0.65 higher PSNR than DCT and 0.86 higher 
PSNR than Haar. The proposed method for 9/7 filter has the highest PSNR among these methods. So, it is 
useful to process Barbara which contains many diagonal edges and local textures. However, Haar wavelet 
filter produces blocky effect because of its short filter length, and the blocky effect is obvious when using a 
77 
 
39.66 40.06 
house 46.26 45.55 
48.37 48.35 
50.82 51.25 
jetplane 33.9 33.99 
35.25 35.5 
35.32 35.69 
lake 30.96 30.91 
31.71 31.88 
31.74 32 
pirate 30.88 31.37 
31.74 31.94 
31.84 32.05 
walkbridge 27.03 27.49 
27.77 27.95 
27.80 27.99 
woman_blonde 30.21 29.82 
29.92 30.12 
29.93 30.43 
woman_darkhair 41.28 41.49 
42.18 42.35 
42.24 42.54 
 
Table 5.5. Comparison with different methods in zooming ratio 
1
4
 
 
 DCT Haar 
proposed method 
without EP (5/3) 
proposed method 
without EP (9/7) 
proposed method 
with EP (5/3) 
proposed method 
with EP (9/7) 
Lena 28.44 29.04 
29.43 29.61 
29.48 29.68 
Baboon 20.77 21.18 
21.13 21.26 
21.21 21.29 
Barbara 23.41 23.67 
23.73 23.83 
23.75 23.85 
Boat 25.11 25.73 
25.82 26.02 
25.90 26.07 
Peppers 28.02 28.00 
28.68 28.70 
28.75 28.82 
Medical 1 30.55 31.33 
31.61 31.78 
31.62 31.82 
Medical 2 41.72 42.22 
42.49 42.59 
42.53 42.67 
cameraman 27.1 27.89 
28.21 28.47 
28.35 28.61 
79 
 
 
 
 
The structural similarity (SSIM) is a method to measure the similarity between two images. The SSIM 
indices are calculated based on various windows of an image. The measure between windows x and y of size 
N×N is defined as 
  
  
1 2
2 2 2 2
1 2
2 2
SSIM( , ) ,
x y xy
x y x y
c c
x y
c c
  
   
 

   
 
where x

is the average of x, y

is the average of y, 
2
x is the variance of x, 
2
y is the variance of y, xy

is 
the covariance of x and y, c1 = (k1L)
2
, c2 = (k2L)
2
, L is typically 2
bits per pixel
 −1, k1 = 0.01 and 
k2 = 0.03 by default. The SSIM index value between −1 and 1, and value 1 is only reachable in the case of 
two identical data. 
The mean of SSIM (MSSIM) indices to evaluate the overall image quality is given by 
1
1
MSSIM( , ) ( , ),
M
j j
j
X Y SSIM x y
M 
 
 
where X and Y are the reference and the distorted images, respectively, and M is the total number of 
windows. Table 5.6 and Table 5.7 show the MSSIM comparison of the proposed methods and other methods. 
The simulation results show our method outperforms other approaches. The source code of MSSIM can be 
obtained at http://www.ece.uwaterloo.ca/~z70wang/research/ssim/ [5.25]. We use the default values in the 
source code to estimate MSSIM. 
 
81 
 
 
 DCT Haar 
proposed method 
without EP (5/3) 
proposed method 
without EP (9/7) 
proposed method 
with EP (5/3) 
proposed method 
with EP (9/7) 
Lena 0.813432 0.827969 
0.833192 0.833458 
0.836011 0.837311 
Baboon 0.443066 0.487031 
0.488135 0.492490 
0.487067 0.493488 
Barbara 0.655036 0.669564 
0.670486 0.670722 
0.674622 0.675124 
Boat 0.672892 0.704828 
0.704441 0.706245 
0.709745 0.710918 
Peppers 0.804590 0.813816 
0.813849 0.813758 
0.819842 0.816222 
Medical 1 0.950512 0.952410 
0.953163 0.953572 
0.953564 0.954048 
Medical 2 0.898256 0.885670 
0.905749 0.906558 
0.906294 0.907243 
cameraman 0.847286 0.867109 
0.867897 0.867658 
0.870640 0.869922 
house 0.924214 0.929588 
0.936255 0.936349 
0.940447 0.942211 
jetplane 0.831386 0.847034 
0.850036 0.850236 
0.853589 0.853815 
lake 0.729340 0.753595 
0.756175 0.757243 
0.759331 0.760648 
pirate 0.713884 0.740796 
0.742322 0.743726 
0.747843 0.749258 
walkbridge 0.548548 0.590808 
0.596227 0.599890 
0.596988 0.603067 
woman_blonde 0.730939 0.751379 
0.752089 0.753697 
0.757004 0.758123 
woman_darkhair 0.918599 0.923981 
0.926861 0.927253 
0.928176 0.929182 
 
Here, we would like to point out the computational complexity without EP is acceptable in the experimental 
results. 
 
83 
 
 
 
Fig. 6.13 - Different types of test images 
 
In Table 6.1, different kinds of medical images are tested. We compare the performance of different DCT 
block-sizes with 9/7 Daubechies DWT [6.20]. The speed of DCT is faster than DWT. And the speed of large 
block is faster than small one. The matrix multiplication is defined by Eq. (6.3-6.5) for different DCT blocks. 
The speed (second) of a forward DCT with 8×8 (S8) and 16×16 (S16) block is calculated by: 
(sec)106 68
S
 
and         
( s e c )1011 616
S
.                   (6.9) 
The number of the matrix multiplication with the 8×8 DCT block (N8) and the 16×16 DCT block (N16) on an 
m× n medical image is calculated by: 
88
8



nm
N
 
and         1616
16



nm
N
.                    (6.10) 
85 
 
conventional SPIHT on textural and directional images. 
 
Table 6.2 Comparison of the PSNR (dB) of different compression methods without entropy coding for 
different medical images 
 
Image 
set 
Bit-rate 
(bpp) 
SPIHT DCT-CSPIHT 
The proposed RDCT-SPIHT  
( DCT block-size ) 
8×8 16×16 32×32 
Angiogram 1 
0.1 36.83 37.06 37.07 37.74 37.99 
0.25 39.03 39.08 38.98 39.27 39.37 
0.5 40.39 40.41 40.33 40.59 40.68 
1.0 42.28 42.39 42.22 42.53 42.64 
Dental 1 
0.1 39.95 40.96 40.75 42.09 42.33 
0.25 42.98 43.15 43.04 43.40 43.50 
0.5 44.11 44.31 44.17 44.56 44.73 
1.0 46.47 46.69 46.55 46.91 46.96 
MRI 1 
0.1 32.09 32.56 31.26 33.66 34.43 
0.25 39.36 39.57 37.89 39.97 41.06 
0.5 44.11 44.17 42.56 44.40 44.99 
1.0 48.75 48.96 47.64 49.16 49.70 
US 1 
0.1 26.89 27.03 26.87 27.73 28.01 
0.25 30.44 30.87 30.26 31.16 31.44 
87 
 
0.25 32.41 31.73 31.99 31.31 
0.5 35.21 34.67 34.54 33.69 
1.0 37.42 37.12 37.09 36.66 
 
 
 
Fig. 6.14 PSNR values at various bit-rates for different medical images 
 
89 
 
( DCT block-size ) 
8×8 16×16 32×32 
 
8×8 16×16 32×32 
Dental 1 
0.1 40.57 41.17 42.24 40.75 42.09 42.33 
0.25 43.03 43.24 43.47 43.04 43.40 43.50 
0.5 44.16 44.39 44.69 44.17 44.56 44.73 
1.0 46.52 46.77 46.94 46.55 46.91 46.96 
 
Fig. 6.16 shows the reconstructed images compressed by the proposed algorithm using different DCT 
block-sizess and the other popular methods at 0.5 bpp. Fig. 6.17 shows the difference images between the 
reconstructed images and original images. Fig. 6.17 (b) ~ (f) are obtained by 255－16× abs(coefficients) for 
better visual presentation. Comparing with the original image and reconstructed image, there are more 
differences induced by the wavelet based SPIHT algorithm than the proposed algorithm (with the larger 
DCT block). 
 
91 
 
Angiogram 1 compressed by proposed algorithm at 0.5 bpp (using 32×32 DCT block). 
 
 
 
Fig. 6.17 - (a) original Angiogram 1 image, (b) the difference image between (a) and Fig. 6.16 (b), (c) the 
difference image between (a) and Fig. 6.16 (c), (d) the difference image between (a) and Fig. 6.16 (d), (e) 
the difference image between (a) and Fig. 6.16 (e), (f) the difference image between (a) and Fig. 6.16 (f). All 
of the images are obtained by 255－16× abs(coefficients) for better visual presentation. 
 
Owing to the significance of edge details on medical images, we compare the textural images with wavelet 
based compression algorithm (SPIHT) and DCT based algorithm (the proposed algorithm) for more obvious 
comparison. Fig. 6.18 and Fig. 6.19 show the proposed algorithm has better visual quality than the 
conventional SPIHT. This can explain that the proposed algorithm outperforms the wavelet based algorithm 
(SPIHT) on edge details. 
 
93 
 
 
 
Fig. 6.19 - Comparison of wavelet based compression algorithm (SPIHT) and DCT based algorithm (the 
proposed algorithm) for textural part (Barbara) at 1.0 bpp. 
 
95 
 
Conference on Acoustics, Speech, and Signal Processing, vol. 4, pp. 2047-2050, 2000.  
[3.6] H. Pan, W. C. Siu, and N. F. Law, “A fast and low memory image coding algorithm based on lifting 
wavelet transform and modified SPIHT,” Signal Processing: Image Communication, vol. 23, pp. 
146-161, March 2008.  
[3.7] Y. Cho and W. A. Pearlman, “Hierarchical dynamic range coding of wavelet subbands for fast and 
efficient image decompression,” IEEE Transactions on Image Processing, vol. 16, pp. 2005-2015, 
August 2007.  
[3.8] H. L. Li, G. H. Liu, and Z. Zhang, “Optimization of integer wavelet transforms based on difference 
correlation structures,” IEEE Transactions on Image Processing, vol. 14, pp. 1831- 1847, November 
2005. 
[3.9] M. Unser and T. Blu, “Mathematical properties of the JPEG2000 wavelet filters,” IEEE Transactions on 
Image Processing, vol. 12, pp. 1080- 1090, September 2003. 
[3.10] M. D. Adams and F. Kossentini, “Reversible integer-to-integer wavelet transforms for image 
compression: performance evaluation and analysis,” IEEE Transactions on Image Processing, vol. 9, pp. 
1010-1024, June 2000.  
[3.11] T. Acharya and P. S. Tsai, JPEG2000 Standard for Image Compression: Concepts, Algorithms and 
VLSI Architecture, John Wiley & Sons, Inc., Hoboken, New Jersey, 2004.  
[3.12] D. Taubman, “High performance scalable image compression with EBCOT,” IEEE Transactions 
on Image Processing, vol. 9, pp. 1158–1170, July 2000.  
[3.13] A. Said and W. A. Pearlman, “A new, fast, and efficient image codec based on set partitioning in 
hierarchical trees,” IEEE Transactions on Circuits and Systems for Video Technology, vol. 6, pp. 
243-250, June 1996.  
[3.14] W. A. Pearlman, A. Islam, N. Nagaraj, and A. Said, “Efficient, low-complexity image coding with 
a set-partitioning embedded block coder,” IEEE Transactions on Circuits and Systems for Video 
Technology, vol. 14, pp. 1219-1235, November 2004. 
[3.15] Bing-Bing Chai, Jozsef Vass, and Xinhua Zhuang, “Significance-Linked Connected Component 
Analysis for Wavelet Image Coding” IEEE Transactions on Image Processing, vol. 8, NO. 6, June 
1999. 
[3.16] J. M. Shapiro, “Embedded image coding using zerotrees of wavelet coefficients,” IEEE Trans. 
Signal Process., vol. 41, no. 12, pp. 3445–3462, Dec. 1993. 
[3.17] R. Sudhakar, M. R. karthiga, and S. Jayaraman, “Image compression using coding of wavelet 
coefficients – A survey,” ICGST International Journal on Graphics, Vision and Image Processing, vol. 5, 
pp. 25-38, June 2005.  
[3.18] Yushin Cho and William A. Pearlman, “Quantifying the Coding Performance of Zerotrees of 
Wavelet Coefficients: Degree-k Zerotree” IEEE Transactions on Signal Processing, vol. 55, NO. 6, 
June 2007. 
[3.19] Ki-Lyug Kim, Sung-Woong Ra, “Performance improvement of the SPIHT coder” Signal 
Processing: Image Communication, vol. 19 page 29–36 2004. 
[3.20] Tanzeem Muzaffar, Tae-Sun Choi “Linked significant tree wavelet-based image compression” 
Signal Processing vol. 88 May 2008. 
97 
 
[4.20] X. H. Ji, C. M. Zgang, J. Y. Wang and S. H. Boey, Fast 2-D 8×8 discrete cosine transform 
algorithm, Information Sciences, vol. 52, no. 2, pp. 215-225, 2009. 
[5.1] T. M. Lehmann, C. Gonner, and K. Spitzer, “Survey: interpolation methods in medical image 
processing,” IEEE Trans. on Medical Imaging, vol. 18, no. 11, pp. 1049-1075, 1999. 
[5.2] R. G. Keys, “Cubic convolution interpolation for digital image processing,” IEEE Trans. Acoust., 
Speech, Signal Processing, vol. 29, no. 6, pp. 1153-1160, 1981. 
[5.3] X. Li and M. T. Orchard, “New edge-directed interpolation,” IEEE Trans. Image Processing, vol. 10, no. 
10, pp. 1521-1527, Oct. 2001. 
[5.4] X. Zhang and X. Wu, “Image interpolation by adaptive 2-d autoregressive modeling and soft-decision 
estimation,” IEEE Trans. Image Processing, vol. 17, no. 6, pp. 887-896, Jun. 2008. 
[5.5] H. C. Chen and W. J. Wang, “Locally edge-adapted distance for image interpolation based on genetic 
fuzzy system,” Expert Systems with Applications, vol. 37, no. 1, pp. 288-297, Jan. 2010. 
[5.6] Y. S. Park and H. W. Park, “Arbitrary-ratio image resizing using fast DCT of composite length for 
DCT-based transcoder,” IEEE Trans. Image Processing, vol. 15, no. 2, pp. 494-500, Feb. 2006. 
[5.7] S. M. Guo, C. B. Li, C. W. Chen, Y. C. Liao, and J. S. H. Tsai, “Enlargement and reduction of 
image/video via discrete cosine transform pair, part 1: novel three-dimensional discrete cosine 
transform and enlargement, ” Journal of Electron Imaging, vol. 16, no. 4, 043006, pp. 1-19, 2007. 
[5.8] W. K. Carey, D. B. Chuang, and S. S. Hemami, “Regularity-preserving image interpolation,” IEEE 
Trans. Image Processing, vol. 8, no. 9, pp. 1293-1297, Sep. 1999. 
[5.9] K. Kinebuchi, D. D. Muresan, and T. W. Parks, “Image interpolation using wavelet-based hidden 
Markov trees,” Proc. ICASSP01, vol. 3, pp. 7-11, May 2001. 
[5.10] J. Liu and P. Moulin, “Information-theoretic analysis of interscale and intrascale dependencies 
between image wavelet coefficients,” IEEE Trans. Image Processing, vol. 10, no. 11, pp. 1647-1658, 
Nov. 2001. 
[5.11] Y. L. Huang, “Wavelet-based image interpolation using multilayer perceptrons,” Neural 
Computing & Applications, vol. 14, no. 1, pp. 1-10, Mar. 2005. 
[5.12] W. P. Lin, C. M. Chen, and Y. C. Chen, “Image compression with interpolation in 
wavelet-transform domain,” 2005 IEEE Int. Symposium on Circuits and Systems, pp. 2084 - 2087, 
May 2005. 
[5.13] A. Temizel and T. Vlachos, “Wavelet domain image resolution enhancement,” IEE Proc. Vis. 
Image Signal Processing, vol. 153, no. 1, pp. 25-30, Feb. 2006. 
[5.14] Y. Piao, I. H. Shin, and H. W. Park, “Image resolution enhancement using inter-subband 
correlation in wavelet domain,” Proc. ICIP, vol. 1, pp. 445-448 , 2007. 
[5.15] W. L. Lee, C. C. Yang, H. T. Wu, and M. J. Chen, “Wavelet-based interpolation scheme for 
resolution enhancement of medical images,” Journal of Signal Processing Systems, vol. 55, no. 1-3, pp. 
251-265, 2009. 
[5.16] S. S. Kim, Y. S. Kim, and I. K. Eom, “Image interpolation using MLP neural network with phase 
compensation of wavelet coefficients,” Neural Computing & Applications, vol. 18, no. 8, pp. 967-977, 
Nov. 2009. 
[5.17] S. A. Rohini, K. Bhurchandi, and A. S. Gandhi, “Successive image interpolation using lifting 
99 
 
[6.10] S. Singh, V. Kumar and H. K. Verma, “DWT–DCT hybrid scheme for medical image 
compression,” Journal of Medical Engineering & Technology, vol. 31, pp. 109-122, March/April 2007. 
[6.11] M. A. Ansari, R. S. Anand, “Context based medical image compression for ultrasound images with 
contextual set partitioning in hierarchical trees algorithm,” Advances in Engineering Software, vol. 40, 
pp. 487-496, 2009. 
[6.12] Wen Chien Yan, Yen Yu Chen and Shen Chuan Tai, “Compressing discrete cosine transform 
coefficients by modified set partitioning in hierarchical trees,” Journal of Electronic Imaging, vol. 14, 
pp. 043003, Oct 2005. 
[6.13] Han Sae Song and Nam Ik Cho, “DCT-Based Embedded Image Compression With a New 
Coefficient Sorting Method,” IEEE Signal Processing Letters, vol. 16, pp. 410-413, May 2009. 
[6.14] L. Junqiang and X. Zhuang, “Embedded image compression using DCT based subband 
decomposition and SLCCA data organization,” IEEE Workshop Multimedia Signal Processing, pp. 
81-84, 2002. 
[6.15] D. Zhao, W. Gao and Y. K. Chan, “Morphological representation of DCT coefficients for image 
compression,” IEEE Trans. Circuits Syst Video Technol., vol. 12, pp. 819-823, 2002. 
[6.16] Y. G. Wu, “GA-based DCT quantization table design procedure for medical images,” Image Signal 
Process, vol. 151, pp. 353-359, October 2004. 
[6.17] Yen Yu Chen, “Medical image compression using DCT-based subband decomposition and 
modified SPIHT data organization," International Journal of Medical Informatics, vol. 76, pp. 717-725, 
October 2007. 
[6.18] J. M. Shapiro, “Embedded image coding using zerotree of wavelet coefficients,” IEEE 
Transactions on Signal Processing, vol. 41, pp. 3445-3462, December 1993. 
[6.19] S. G. Mallat, “A wavelet tour of signal processing,” Academic Press, San Diego, 1999. 
[6.20] M. Antonini, M. Barlaud, P. Mathieu and I. Daubechies, “Image coding using wavelet transform,” 
IEEE Transactions on Image Processing, vol. 1, pp. 205-220, 1992. 
 
 
3. 計畫成果自評 
本計畫已達成預期目標，提出一些頗具學術及實用價值的方法： 
 
1. 提出利用離散餘弦轉換如何精確的進行非整數倍放大。 
2. 針對離散餘弦轉換及雙線性內插基底放大方法的優缺點，提出將上述兩種方法結合的放大方法。 
3. 延伸離散餘弦轉換至三維的影像放大，可有效地提升視訊壓縮品質。 
4. 提出小波基底的放大方法，利用小波基底的可移動性以改善放大品質，並且應用在三維影像。 
5. 以小波為基底的壓縮影像其頻帶相加方法，並且使用進化規劃演算法搜尋重要係數的最佳解，得
到高性能的二維/三維影像壓縮與最佳的還原結果。 
6. 應用改良之多重目標最佳化的混沌進化規劃演算法於小波基底的不同頻帶相加方法之重要係數
101 
 
Applications,  vol. 60, pp. 541-562. (SCI, EI) 
[10] Wei, C. L., Tsai, J. S. H., Guo, S. M., and Shieh, L. S., 2011, “Universal predictive Kalman filter-based 
fault estimator and tracker for sampled-data nonlinear time-varying systems,” IET Control Theory & 
Applications, vol. 5, no. 1, pp. 203-220. (SCI, EI) 
[11] Hu, N. T., Tsai, J. S. H., Guo, S. M., Shieh, L. S., and Chen, Y., July/August 2010 , “Low-order 
multi-rate linear time-invariant decentralized trackers using the new observer-based sub-optimal 
method for unknown sampled-data nonlinear time-delay system with closed-loop decoupling,” Optimal 
Control Applications and Methods, vol. 132, no. 4, pp. 433-475. (SCI, EI) 
[12] Tsai, J. S. H., Du, Y. Y., Zhuang, W. Z., Guo, S. M., Chen, C. W., and Shieh, L. S., Feb. 2011 , “Optimal 
anti-windup digital redesign of MIMO control systems under input constraints,” IET Control Theory & 
Applications , vol. 5, no. 3, pp. 447-464. (SCI, EI) 
[13] Guo, S. M., Tsai, T. J., Tsai, J. S. H., Lin, Y. C., and Chen, C. W., 2011, “Intelligent PID fault tolerant 
tracker for unknown nonlinear MIMO systems,” International Journal of Nonlinear Sciences and 
Numerical Simulations, vol. 11, no. 11, pp. 911-926. (SCI impact factor 8.0, EI) 
[14] Tsai, J. S. H., Duo, Y. Y., Huang, P. H., Guo, S. M., Shieh, L. S., and Chen, Y., Feb. 2011, “Iterative 
learning-based decentralized adaptive tracker for large-scale systems: A digital redesign approach,” ISA 
Transactions, vol. 50, no. 3, pp. 344-356. (SCI, EI) 
[15] Tsai, J. S. H., Huang, C. C., Guo, S. M., and Shieh, L. S., August 2011 , “Continuous to discrete model 
conversion for the system with a singular system matrix based on matrix sign function,” Applied 
Mathematical Modelling, vol. 35, no. 8, pp. 3893-3904. (SCI, EI) 
[16] Tsai, J. S. H., Chen, F. M., Yu, T. Y., Guo, S. M., and Shieh, L. S., 2012, “Efficient decentralized 
iterative learning trackers for the unknown sampled-data interconnected large-scale state-delay system 
with closed-loop decoupling property”, ISA Transactions, vol. 41, pp. 81-94, 2012 (Available online 
August 27, 2011). (SCI, EI) 
[17] Wang, J. H., Tsai, J. S. H., Huang, J. S., Guo, S. M., and Shieh, L. S., 2012, “A low-order active 
fault-tolerant state space self-tuner for the unknown sampled-data nonlinear singular system using 
OKID and modified ARMAX model-based system identification”, Applied Mathematical Modelling, 
Available online, 10 April, 2012, doi: 10.1016/j.apm. 2012.03.035. 
[18] Tsai, J. S. H., Chen, C. H., Lin, M. J., Guo, S. M., and Shieh, L. S., 2012, “Novel quadratic tracker and 
observer for the equivalent model of the sampled–data linear singular system”, Applied Mathematical 
Sciences. (Accepted for publication)  
[19] Chen, C. H., Tsai, J. S. H., Lin, M. J., Guo, S. M., and Shieh, L. S., 2012, “A novel linear quadratic 
observer and tracker for the linear sampled–data regular system with a direct feedthrough term: Digital 
redesign approach”, IMA Journal of Mathematical Control and Information, Available online, 9 Aug, 
2012, doi: 10.1093/imamci/dns015. (SCI, EI) 
[20] Wang, J. H., Tsai, J. S. H., Chen, Y. C., Guo, S. M., and Shieh, L. S., 2012, “An active low-order 
fault-tolerant state space self-tuner for the unknown sample-data linear regular system with an 
input-output direct feed-through term”, Applied Mathematical Sciences. (Accepted for publication)  
[21] Huang, C. C., Tsai, J. S. H., Guo, S. M., Sun, Y. J., and Shieh, L. S., 2012, “Solving algebraic Riccati 
equation for singular system based on matrix sign function”, International Journal of Innovative 
 1 
出席國際學術會議心得報告 
郭淑美 教授  成功大學資訊工程學系 
國科會計畫：NSC 98-2221-E-006-159-MY3 
 
 
 
 
 
 
 
1. 第七屆 IEEE 控制與自動化國際研討會 
2. 第三十屆國際科學與技術發展聯盟─模組化、辨識與控制研討會議 
(AsiaMIC 2010) 
3. 第四屆國際各學科間混沌專題研討會─混沌與複雜系統
（CCS2012） 
  
 3 
15.複雜系統、16. 線性系統 、17. 類神經模糊系統、18. 網路系統、19. 智慧控
制、20. 多代理系統、 21. PID 控制、 22. 分散式系統、23. 強健控制、24 .程
序控制、25. 生物系統、26. 智慧結構、27. 電力系統、28. 滑動控制、29. 延遲
系統、30. 信號處理、31. 自動導航、32. 燃料電池。 
 
  在會議中，多方發表了近來發展的控制論文，並在很多方面有重點性的進步
及突破。除了各種新的控制系統以及控制方法的研究，研討會特別著重在新的控
制研究領域的介紹及開發。如何將控制領域中的系統模型、輸入資料整合以及輸
出訊號的控制，應用在生物、網路、甚至是金融領域，以期讓自動控制達到更廣
泛的應用，都是未來重要的課題。 
 
在此次會議的三十二大主題中，分別介紹個各種不同的研究及突破，除了如
何達到快速、穩定及精確地控制，還提出各種實際應用的領域和可能性，值得我
們去研究和嘗試。 
 
 
(二) 筆者發表論文 
Guo, S. M., Tsai, J. S. H, Lin, Y. C., Tsai, T. J., and Chen, C. W., Dec. 9 – 11, 2009, 
“Intelligent-based PID fault tolerant tracking control for unknown nonlinear MIMO 
systems,” The 7th International Conference on Control and Automation (ICCA'09), 
Christchurch, New Zealand. 
 
摘要：本論文提出新的智慧型容錯控制架構，來解決非線性多輸入多輸出未知系
統之容錯追蹤控制問題。為了要消除錯誤對系統所引起的影響，本文利用類神經
網路模型來即時鑑別此非線性未知系統，其中網路模型的參數可經由擴展式卡門
濾波器來調整。同時，利用急劇下降法和進化規劃法則來設計適應性類神經網路
模型之比例－積分－微分(PID)控制器。而此 PID 容錯控制器不僅能達到系統追
蹤的目的，也能使系統在錯誤發生時，其穩定性能維持，並可達到預期之性能指
標。最後舉一個實際的例子來描述所提出方法之效能。 
 
 
三、專題演講 
I. REGIONAL ROBUST H  FILTERING FOR DYNAMIC SYSTEMS 
－ Carlos E. de Souza, National Laboratory for Scientific Computing 
     控制系統的基本問題是運用有效雜訊測量以估測一個動態系統狀態的變數，
 5 
物與引導，和飛機運載工具控制。 
Jie Huang 教授分別為 IFAC 與 IEEE 會士，並獲得 Croucher Senior Research
會士獎，在 2004 年獲得 Eighth International Conference on Control, Automation, 
Robotics 與 Vision 最佳論文獎。Jie Huang 教授擔任多種著名期刊主編或聯合主
編一職。 
 
 
III. HIGH-GAIN OBSERVERS IN NONLINEAR FEEDBACK CONTROL 
－ Hassan K. Khalil, Michigan State University  
 
    高增益估測的原理已發展將近 20 年。演講中簡略介紹在非線性迴路控制中
的高增益估測器，且強調在處理此系統尖峰現象與控制輸入飽和現象。除此之外，
並介紹高增益估測在雜訊測量、取樣控制，和非線性分離原理等方面的應用。 
 
Professor  Hassan K. Khalil 
    Hassan K. Khalil 教授 1975 於美國伊利諾州大學取得博士學位，現任職於
美國密西根州州立大學電子與電腦工程學系。主要研究領域為分散式控制，強健
控制，非線性控制，和適應性控制。 
    Hassan K. Khalil 教授於 1989 年榮任 IEEE 控制系統會士，2007 年榮任 IFAC
會士。Hassan K. Khalil 教授自 1984 年至 1985 年擔任 IEEE 自動控制期刊主編，
自 1999 年至 2008 年擔任非線性系統與自動控制期刊主編。 
 
 
Plenary Panel Session on Control research and Education: Challenges and 
Opportunities 
 
議會提供機會給研究生(尤其是年輕的研究生)，與國際著名的系統控制的專家互
相交流，並且可以請教他們相關領域上的意見，例如：如何作一個專業的研究生、
如何選擇一個主題、如何撰寫高品質的論文、如何回應評論…等問題。在議會期
間，各專家分享了他們的經驗。 
 
    在該主題，大會邀請了下列國際著名人士作專題演講： 
 
Professor J. Geoffrey Chase 
 J. Geoffrey Chase 教授於 1986 在西儲大學取得機械學士學位，1991-1996 在
斯坦福大學分別取得機械與土木工程碩士和博士學位，之後任職於通用汽車公司，
並進一步在矽谷擔任顧問；在 2000 年任教於目前的坎特伯雷大學。研究領域包
括自動控制、生理系統動力學、結構力學與振動、動態系統建構。J. Geoffrey Chase
 7 
第三十屆國際科學與技術發展聯盟─模組化、辨識與控制研
討會議 (AsiaMIC 2010) 
郭淑美 教授  成功大學資訊工程學系 
國科會計畫：NSC 98-2221-E-006-159-MY3 
 
一、參加會議經過 
筆者此次參與「國際科學與技術發展聯盟」(International Association of Science and 
Technology for Development, IASTED)擴大舉辦的“模組化、辨識與控制研討會議”、
“電力與能源系統會議”、“機器人學會議”與“進階管理科學與風險評估會議”，此
會議群從二○一○年十一月二十四日至二十六日，在泰國的普吉島(Phuket)舉行，
為期三天。「國際科學與技術發展聯盟」為一個非營利的組織，於 1977 年在瑞
士蘇黎世設立。「IASTED」主要是由工程、科學與教育等學術界及專業人士所
組成之多領域會議；並在工業化及開發中國家舉辦會議及研討課程。其主要目的
是，提供給國際間傑出的專業人士、研究人員以及工程師，發表及觀摩其在模組
化、辨識及控制等領域最近的研究、成果及想法。AsiaMIC 2010 的舉辦目的是
為了加強工業界、各研究實驗室及大學間相互的關係。 
 
    大會於十一月二十四日上午開幕後隨即進行專題演講與論文發表。這三天的
會議行程包含了三項專題演講與三項特別主題會議。論文發表共分為三十一個主
題，約有一百八十篇論文發表。 
 
     
二、與會心得 
 
(一) 模組化、辨識與控制論文 
  此次模組化、辨識與控制研討會議共有九個主題，分別是： 1. 模組化及模
擬，2. 預測性與適應性控制，3. 強健控制，4. 機器人學及機械學，5. 製程、能
 9 
    本文提出一種適用於具有內部狀態延遲連結之廣義未知大尺度資料取樣線
性系統，且其具有閉迴路解耦特性的分散式模型化線性觀測器與輸入飽和軌跡追
蹤器。首先，利用離線的觀測器/卡爾曼濾波器鑑別方法計算出具有內部狀態延
遲連結之廣義未知大尺度資料取樣線性系統的適當階數(或低階)的分散式線性
觀測器。然後 此觀測器可以利用具有高增益性質的數位再設計方法，進一步改
善模組的誤差。此外針對資料取樣系統，提出一個具有高增益的數位再設計觀測
型線性二次式數位軌跡追蹤器，且提供良好的軌跡追蹤效果，而系統具有閉迴路
解耦特性。最後，為了降低控制力來滿足輸入飽和限制的需要，提出修正型的線
性二次式數位軌跡追蹤器。藉此控制力可以有效的被壓縮，而且不會損失原本良
好的軌跡追蹤效果。 
 
 
論文二   適用於具有內部連結未知資料取樣大尺度線性延遲的奇異系統且具有
閉迴路解耦特性的分散式線性觀測器與軌跡追蹤器設計 
    Tsai, J. S. H., Pan, S. J., Liao, W. C., Guo, S. M., and Shieh, L. S., Nov. 24 – 26, 
2010, “Modeling of decentralized observers and trackers for large-scale singular 
system with time delay and closed-loop decoupling property,” The 30th IASTED 
International Conference on Modelling, Identification, and Control (AsiaMIC 
2010), Phuket, Thailand. 
 
本文提出一種適用於具有內部連結未知資料取樣大尺度線性延遲的奇異系
統且具有閉迴路解耦特性的分散式線性觀測器與軌跡追蹤器設計方法。透過離線
的觀測器 /卡爾曼濾波器鑑別方法計算出包含有直接傳輸項的內部連結未知資
料取樣大尺度線性延遲的奇異系統之適當階數(或低階)的分散式線性觀測器，然
後基於一個含 有直接傳輸項的對等分散式系統，以等效的系統來架構一個高增
益的類比二次式觀察器和軌跡追蹤器。然後，利用數位再設計法則以得到一個實
用的數位觀測器和軌跡追蹤器以控制資料取樣的系統。具有高增益的特性使分散
式數位軌跡追蹤器在有內部連結的閉迴路系統具有解耦的特性。最後，藉由進化
論演算法來獲得每一個適 當的分散式觀測器的權重以增進追蹤性能。 
 
 11 
和生命的創新。本演講此創新的挑戰，在許多領域的機器人技術與應用，如環境、
生物醫學機器人應用、生命支持應用程序的老齡化社會。 
 
主講人背景： 
Toshio Fukuda 教授，於 1977 年得到東京大學工程博士，目前為名古屋大學微
奈米中心主任與微奈米系統工程系教授，且涉及領域含智能機器人、機電整合系
統與微奈米機器人系統等。曾擔任 IEEE機器人與自動化學會 (IEEE Robotics and 
Automation Society)主席(1998-1999)，IEEE Division X, Systems and Control 理事
(2001-2002) 
 
 Lightning Surge Analysis By EMTP And Numerical Electromagnetic 
Analysis Method 
 --- Prof. Akibiro Ametani 
(閃電突波分析：使用 EMTP 與數值電磁分析方法) 
 
摘要 
因閃電和開關所引起的超電壓，運用於全世界已有 30 多年歷史。然而根據
電路理論的 EMTP 方法不能解決瞬間變化介入的 non-TEM 方式傳播，例如：橫
跨主傳輸線路電塔一個波前瞬間閃電。數值電磁式分析 NEA 方法可以解決大部
份困難瞬間變化的問題，並可用現有的電路理論模擬工具來達成。此時，利用
EMTP 模擬雷電沖擊，並且說明演算方式及假設條件和應用限制，最後以 EMTP
和 NEA 模擬作比較說明。  
 
主講人背景 
Akihiro Ametani 教授，於 1973 年得到英國曼徹斯特大學科學與技術學院工程
博士，1985 年於 Doshisha 大學任職教授，1988 年於 Catholic 大學任職教授，1966
至 1998 年科學工程技術部門理事，2003 年是日本 IEE 副主席。 Akihiro Ametani 
教授是 IEEE 院士、IET 院士和 CIGRE 會員(2010)。 
 
 
 13 
 Fringing Electric Field Sensors 
 --- Prof. Mamishev 
(機器人教程會議”邊緣電場感測器) 
 
摘要: 
    邊緣電場感測器被使用在許多機器人與自動控制的應用上。比較常見的是電
容式感測器測量液體體積的水平、極接近的測量、裂縫的位置和不連續性。較複
雜的電介質感測器被用來測量材料性能，厚度層，測定電氣絕緣老化狀態，並估
計水分動態。然而，更複雜的多電極系統被用來測量工業流動和人體斷層, 分佈
式傳感器陣列放置在機器人的表面肌膚功能：檢測壓力，剪應力，濕度和溫度。
本教程將包括使用邊緣電場基礎設計的感測器系統。 
 
主講人背景 
Prof. Mamishev 於麻省理工學院電機工程與計算機學系取得博士學位，目前任教
於 University of Washington。 
 
  
 15 
二、與會心得 
 
(一) 工業電子論文 
    此次工業電子國際研討會議共有八個主題，分別是：1. 控制系統及應用，
2. 感測器、致動器及系統積體，3. 電力電子，4. 電機及驅動器，5. 計算智慧型
與信號處理，6. 工業控制自動化及信息產業，7. 機器人，8. 新興技術。 
 
    在此次研討會議中，所發表的論文，其涵蓋範圍非常廣泛。諸如：1. 電動
汽車的應用，2. 滑動模式控制，3. 觸覺系統的機器人，4. 信號處理，5. 感測器、
致動器及系統積體，6. 風力發電機，7. 電流和電壓控制，8. 控制系統，9. 多感
測器和多機器人系統，10. 直流/直流轉換器，11. 傳感器控制，12. 影像處理，
13. 計算機與控制，14. 優化技術，15. 機器人驅動與控制，16. FPGA 的工業控
制系統，17. 感應電機，18. 多相驅動器，19. 分佈式發電和微電網，20. 運動控
制等；對於跨領域之整合相當有幫助。 
 
    在現今的工業上，可應用控制的領域非常的多，在很多精密產品的製造過程
中，為了要求精確而穩定品質，也使用了控制的方式來達到我們要求的規格，故
控制的領域非常的廣，也非常的重要，在這次工業電子國際研討會議中，多方發
表了最近發展的工業電子國際的論文，並在很多方面有重點性的進步及突破，並
使控制的應用更貼近真實的系統，並易於實現。 
 
    在此次會議的八個主題中，分別使用了不同的方法以及程序去達到我們的要
求，但如何有快速、穩定及精確地控制，仍然是我們重視的方針。 
 
 
 
 
 
 17 
架構。如此，網絡的確可以訓練到非常小的錯誤，但不重新訓練無法新的模式中
正確響應。在這次討論提出一個新的 NBN 學習演算法，這演算法不僅比 EBP 演
算法快 1000 倍，還可以應用在所有的類神經網路架構。更重要的是可以訓練出
更接近最佳的類神經網路。 
 
主講人背景： 
    Bogdan M. Wilamowski 教授，於 1966 年得到電腦工程碩士，1977 年得到神
經計算博士，1987 年獲得到正教授稱號；在 Gdansk 工業大學擔任過電子學會主
任(1979~1981)、固體電子學系主持人(1987-1989)，於 1989 至 2000 年懷俄明大
學任職教授，2000 至 2003 年他擔任副主任和電信研究所微電子研究在愛達荷州
大學教授。 
    他編著了 4 本書，300 多篇學術著作，並擁有 27 項專利。他的主要興趣領
域是：半導體器件和傳感器，混合信號和模擬信號處理，計算智慧型。 
 
    Wilamowski 教授是 IEEE 院士，他曾擔任 IEEE 計算智慧型協會(IEEE 
Computational Intelligence Society)副主執行長(2000-2004)、IEEE 工業電子學會 
(IEEE Industrial Electronics Society)主席(2004-2005)，IEEE 工業電子期刊主編
(IEEE Transactions on Industrial Electronics)(2007-2010) 
 
2. Real World Haptics and Telehaptics for Medical Applications 
-- Prof. Bogdan M. Wilamowski 
 
摘要： 
    針對人類的感官方面的一般常見技術主要集中在視覺和聽覺。這類技術
假設人類 “非接觸” 活動。然而，為了直接和充分實現人的 “接觸” 關鍵性
動作，所以發展有觸覺並且/或者觸覺感覺的技術是重要的。因為觸覺感覺本
質上是雙向的信息傳遞且必需合乎牛頓的作用力和反作用力定律，所以生動
 19 
班牙分會副主編，以及工業電子學會 AdCom 公司成員。並於 2004 年至 2007 年
擔任工業電子學會研討會副主編，2008 年與 2009 年為主編當選人，且自 2006
年為傑出講師。自 2007 年一直為的 IEEE 工業電子學會副主編和 2010 年工業電
子學會主編。 
 
四、特別主題 
 
1. Power Electronics and Electrical Machines 
A Modern Approach to the Analysis of PM Motors using Finite Element Method 
Nicola Bianchi and Massimo Barcaro, University of Padova, Padova (Italy) 
 
2. Power Electronics and Electrical Machines 
Integrated Circuits for Power Electronics Applications 
Dorin O. Neacsu, Consultant, USA 
 
3. Power Electronics and Electrical Machines 
Time Averaging Methods for Multilevel PWM Power Converters: Voltage 
Quality and Flying Capacitors Voltage Balancing Dynamics 
Alex Ruderman, Elmo Motion Control Ltd., Israel; Boris Reznikov, General Satellite 
Corp., Russia; Steven Thielemans, Ghent University, Belgium 
 
4. Renewable Energies  
Fundamentals of Ocean Wave Energy Conversion, Modelling, and Control 
Ted Brekken, Oregon State University, USA 
 
5. Renewable Energies  
Plug-in Hybrid Electric Vehicles - Power Electronics, Battery Management, 
Control, and V2G - 
Chris Mi, University of Michigan-Dearborn, USA  
Alain Bouscayrol, University of Lille 1; France 
 
6. Renewable Energies 
Power Electronics for PV Power Systems Integration 
Remus Teodorescu, Aalborg University; Pedro Rodriguez, UPC Barcelona; Marco 
Liserre, Politecnico di Bari; 
Alberto Pigazo, University of Cantabria 
 
 21 
第四屆國際各學科間混沌專題研討會─混沌與複雜系統
（CCS2012） 
郭淑美 教授 成功大學資訊工程學系 
國科會計畫：NSC 98-2221-E-006-159-MY3 
 
一、 參加會議經過 
 
筆者此次參與「國際各學科間混沌專題研討會」(International Interdisciplinary 
Chaos Symposium on Chaos and Complex Systems, CCS2012)舉辦的“混沌與複雜
系統”，此會議群從二○一二年四月二十九日至五月二日，在土耳其的安達利亞
市(Antalya)舉行，為期四天。其大會於四月二十九日上午開幕後隨即進行專題演
講與論文發表。這四天的會議行程包含了七個大會邀請演講，以及兩百五十八篇
論文發表。 
 
二、 與會心得 
 
(一) 混沌與複雜系統 
 
此次混沌與複雜系統研討會議，所發表的論文，主要針對混沌與複雜的系統
來探討，例如：混沌系統、非線性動力學、非線性科學與應用等。 
 
(二) 筆者發表論文 (共發表 1 篇) 
 
“適用於一類具有內部連結之未知大尺度資料取樣非線性系統之輸入限制
與致動器錯誤的容錯軌跡追蹤器” 
 23 
系。 
 
2. Simple System, Complex Networks (簡單系統、複雜網路) 
--- Prof. Fatihcan ATAY 
 
摘要： 
一個複雜的系統往往是包含了許多單純的元素，而本報告主要探討在複雜系
統中，相互影響之元素是如何去改變整個網絡行為。在本次會議中，將介紹所發
生在動態網絡系統之重要因子。 
 
主講人背景： 
Prof. Fatihcan ATAY 任職於德國國家理論科學研究中心數學組。 
 
3. Infinite Dimensional Chaotic Systems: Synchronization and Communications 
(無限域渾沌系統：同步與通訊) 
--- Prof. Santo Banerjee 
 
摘要 
物理系統以複雜和非線性的主要自然特性存在，下面的數學模型是以一組時
間延遲或偏微分方程產生無限域渾沌自然特性。此混沌系統的同步特性已經被廣
泛的應用於雷射和電漿動態、電子電路、化學、生物和生態等系統的背景上。此
同步特性也已經被廣泛的應用於保密通訊、非線性系統最佳化特性以模仿大腦活
動還有圖形辨識現象。藉由適當的系統參數選取的連續時間延遲系統和時間空間
的偏微分方程，可以表示渾沌範例。然而，由於大部分的物理系統，如半導體雷
射、磁化與非磁化電漿、生物與生態模型在偏微分方程的數學模性分類下有落差，
故偏微分方程數學模型這方面的領域沒有被廣泛的探討和引人注目。藉由調變各
 25 
考慮一複合式網路系統，藉由熱浴來模擬一外部壓力施力於系統上所發生的
情形。這包含社會不安定、經濟危機、和極端的生理條件等。使用類比網路的諧
波振盪器，此振盪器是由牛頓力學、量子力學的熱格林函數所推導出來。使用熱
格林函數來證明是有可能去定義歐幾里得度量，亦證明了任何網路可以被導入一
個給定半徑的超外接球。最後，利用真實世界網路的例子，提出證據顯示這些觀
念是有效的。 
 
主講人背景 
Prof. Ernesto Estrada 目前任教於英國史崔克萊大學數學與統計學系以及物理學
系。 
 
5. POLYNOMIOGRAPHY AND CHAOS (POLYNOMIOGRAPHY 和混沌) 
--- Prof. Bahman Kalantari 
 
摘要 
所謂的蝴蝶效應就是混沌理論中對初始狀態高度敏感之動態系統的行為。對
混沌系統而言，在初始狀態中小小的變化都會產生廣泛分歧的結果。
Polynomiography 是一種迭代系統的可視化演算法，用來計算複數多項式的根。
眾所周知，這種演算法在其複數平面上的有理函數迭代，導致混沌行為發生在
fractal Julia set 附近，例如，利用牛頓法尋找多項式 p(z)的根會被吸引至吸引子。
為了計算多項式 p(z)，其中一個方式是我們從 Basic Family 中選擇個別的成員。
Basic Family 是一個包括牛頓法的有理迭代函數的無限族。Polynomiography 是
一種不錯的方法來觀察、理解、比較迭代系統的混沌行為。其它種
Polynomiography 的迭代方式是可能的且會導致不同種類的混沌行為。其中一種
方式則是將 Basic Family 集體適用於 p(z) 且用 Voronoi cell 迭代收斂到根。的確，
在每一個 Voronoi cell 的封閉子集中 Basic Family 都均勻收斂。與使用個別迭代
 27 
Prof. Bulent Karasozen, Hamdullah Yucel 目前任教於土耳其中東技術大學，數學
與應用數學系研究所。 
 
7. CHAOTIC DESTRUCTION OF ANDERSON LOCALIZATION 
INNONLINEAR LATTICES (非線性晶格中安德森局域化之混沌破壞) 
--- Prof. A. Pikovsky 
 
摘要: 
本主題為假設呈現非線性，會發生在無序晶格裡的安德森局域化。這個情況
和晶格的耦合振盪器、在無序電位裡的玻色愛因斯坦凝聚 ( 此可以被
Gross-Pitaevsky equation 所描述)，以及和在無序非線性介質的光傳播有關。主要
的模型是擁有非線性項的離散型安德森(意即非線性的有序薛丁格晶格)。我們討
論的問題有： 
1. 初始化的局域波包如何擴散 
2. 規則波如何透過非線性無序層而被傳遞 
3. 在有限無序的晶格中熱化是如何發生的 
以上非線性情形會導致弱混沌和離域作用。 
 
主講人背景 
Prof. Pikovsky 目前任教於德國波茨坦大學物理系。 
98年度專題研究計畫研究成果彙整表 
計畫主持人：郭淑美 計畫編號：98-2221-E-006-159-MY3 
計畫名稱：有效的影像壓縮 
量化 
成果項目 
實際已達
成數（被接
受或已發
表） 
預期總達成
數(含實際
已達成數)
本計畫
實際貢
獻百分
比 
單位
備註（質化說明：如數個
計畫共同成果、成果列為
該 期 刊 之 封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報
告 0 0 100%  
研討會論文 2 2 100% 
篇 
[22] Tsai, J. S. H., Wei, C. 
L., Guo, S. M., Shieh, L. 
S., November 27–29, 
2009, ＇Fault estimator 
and control for 
sampled-data nonlinear 
time-varying sys-tem 
against actuator and state 
failures＇, the 2009 CACS 
International Automatic 
Control Conference 
(CACS/IACC'09), Taipei, 
Taiwan. 
[23] Guo, S. M., Hsu, C. Y., 
Wu, P. N., Tsai, J. S. H., 
2009, ＇A Trajectory-based 
Point Tracker Using Chaos 
Evolutionary 
Programming,＇ The 22nd 
International Conference 
on Industrial, Engineering 
& Other Applications of 
Applied Intelligent 
Systems (IEA-AIE 2009), 
Tainan, Taiwan. 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次
 
(ICCA'09), Christchurch, 
New Zealand. 
[25] Tsai, J. S. H., Wei, C. 
L., Guo, S. M., Shieh, L. 
S., July 4–7, 
2010, ＇Predictive Kalman 
filter-based fault 
estimator and control for 
sampled-data linear 
time-varying systems＇, 
IEEE International 
Symposium on Industrial 
Electronics, Bari, Italy.
[26] Du, Y. Y., Tsai, J. S. 
H., Chen, Y. H., Guo, S. M., 
and Shieh, L. S., Nov. 24 –
26, 2010, ＇Decentralized 
input-constraint trackers 
for unknown large-scale 
interconnected 
sampled-data systems with 
state delay,＇ The 30th 
IASTED International 
Conference on Modelling, 
Identification, and 
Control (AsiaMIC 2010), 
Phuket, Thailand. 
[27] Tsai, J. S. H., Pan, S. 
J., Liao, W. C., Guo, S. M., 
and Shieh, L. S., Nov. 24 –
26, 2010, ＇Modeling of 
decentralized observers 
and trackers for 
large-scale singular 
system with time delay and 
closed-loop decoupling 
property,＇ The 30th 
IASTED International 
Conference on Modelling, 
Identification, and 
Control (AsiaMIC 2010), 
Phuket, Thailand. 
[28] Shiu, Y. C., Tsai, J. 
S. H., Guo, S. M., Shieh, L. 
S., and Han, Z., April 29 –
May 02, 
2012, ＇Fault-tolerant 
tracker for interconnected 
large-scale nonlinear 
