PCA 子空間無法涵蓋新的數據，必須重新建構
PCA 子空間，本文提出將之前 PCA 子空間的分
類參數更新至新的子空間的演算法。由於傳統
EM 演算法有上述的三項缺點，本文將引用
DAEM演算法和 RMD演算法，降低局部最大值
和離群數據對於分類參數的影響，並以 BIC作為
選擇類別個數的依據。
2. 研究方法
2.1 主方向分析 (Principal Component Analysis)
主方向分析的概念是利用原始變數線性組合
出主要的變數或是內在變數(Latent Variables)表
示數據分佈的主要方向，因此當數據的分佈能夠
發現原始變數之間有線性的關係，能夠利用 PCA
的方式有效地降低變數的維度，而且不破壞原始
數據的真實性。假設有 n個變數 m筆數據，則數
據矩陣Y的大小為m n ，而且每筆數據經過重
新尺度化，使得每個變數的平均值為 0，標準差
為 1。
  1 X Y Y S (1)
Y為 m 筆數據的平均值， S為標準差的對角矩
陣，計算共變異矩陣Σ的特徵向量 P：
T1
1m


Σ XX, i i iΣp p, i=1…n (2)
將原始數據X投影到每個特徵向量的投影量，稱
之為 Score：
i it Xp ，i=1…n (3)
i為特徵向量 ip 的特徵值，並且由大至小排序，
可視為特徵向量解釋數據分佈的程度，也就是第
一個特徵向量 1p 為數據分佈最廣的方向，在 PCA
中特徵向量 ip 也稱為 Loading，所代表的意義為
變數之間的線性相關性。由上式數據矩陣X可表
示為：
T T T
T T
1 1
ˆ
1 1 2 2 K K
K K n n 
   
    
X t p t p t p
t p t p X E


(4)
Xˆ為 K項特徵向量所描述的數據矩陣，E則是誤
差矩陣。當誤差矩陣可被忽略不計時，即 ˆX X，
則這 K 項特徵向量即為數據分佈的主要方向
(Principal Components, PCs)。
應用 PCA的方法偵測工廠操作狀態，主要的
概念是利用工廠正常操作的數據，選擇適當個數
的主方向解釋正常操作數據，也就是 (4)式的
E 0。當有新的一筆數據 x 利用(4)式可計算
PCA的近似誤差，定義統計量 Q為：
   TTQ   ee x x x x  T TK K x I P P x (5)
×m K
K RP 為前 K 項的主要方向，Q 可視為利用
正常操作數據所建立的 PCA 子空間解釋新數據
的誤差，如果新的數據與之前的正常操作數據類
似，則 0Q 。如果前 K 項的主要方向無法有效
地近似新的數據，則 0Q ，表示新的數據與之
前的正常操作數據不符，可能製程的操作發生異
常，產生新的事件使得原先的主要方向(PCs)無法
有效地解釋新的數據。Q 的警戒值定義如下
(Jackson, 1991)：
  0
1
2
2 0 2 0 0
1 2
1 1
2 1
1
/ h
c h h h
Q 
     
   
(6)
1
1 2 3
n
i
i j
j K
i , ,
 
   , 1 30 2
2
2
1
3
h


為發生 Type I檢定錯誤的機率，c為常態分佈
之下(1-)積分至的數值。另一個測量 PCA 與
新數據之間的差異指標為統計量 2T ，
2 1 T T
K KT
xP Λ Px (7)
 1 2 Kdiag   Λ  為特徵值對角矩陣。
2T 則是測量新的數據投影至 PCA 的方向與之前
正常數據中心的距離，它的警戒值為：
 2
K,m-1,
K m-1
T F
m- K 
 (8)
K,m-1,F 為 F分配函數，其自由度分別為 K和 m-1。
2.2 貝式分類 (Bayesian Classification)
在 c 個類別的事前機率定義為 1jP , j ...c ，
而任一筆數據 xi出現在類別 j 的聯合機率密度函
數值為  ip , jx ，則在類別 j的條件下出現 xi的條
件機率密度函數值為：
   ii
j
p , j
p j;
P
 xx θ (9)
θ為定義條件機率密度函數的參數向量，依據總
和機率理論 xi出現在所有類別的密度函數值為：
   
1
c
i i k
k
p ; p k; P

x θ x θ ，由貝式定理可得知事
後機率  iP j ; ,x θP為：
 
 
 
1
1
1
m
k k
k
j m
k
k
F j ; t
t
F j ; t


 


x Θ x
μ
x Θ
， j=1…c (18)
 1j tΣ (19)
     
 
1
1
m T
k k j k j
k
m
k
k
F j ; t t t
F j ; t


 



x Θ x μ x μ
x Θ
   
1
1
1
m
j i
i
P t F j ; t
m 
   x Θ (20)
重複(18)式至(20)式直到   1t t  Θ Θ ，增
加並將收斂的參數設定為下一次疊代的啟始
值，直到 1 。
2.2.3 Robust Mixture Decomposition Algorithm
雖然 DAEM 演算法能夠克服區域最大值的
問題，但是當有離群數據時仍會影響 DAEM的收
斂結果，然而在工廠的操作數據中無法避免地會
有離群數據的出現。Medasani and Krishnapuram,
2001提出 RMD演算法，在疊代 EM的過程中先
將每個數據由混和模式所計算的機率由大至小排
序，也就是      1 2 mp p p  x θ xθ x θ ，如
果估算的參數θ正確，那麼離群數據的條件機率
值必然較低，因此在每次疊代過程中只選取 r 個
較大機率值的數據，就能避免離群數據對於估算
參數的影響。至於保留數據的比率(r/m)是以數據
品質估算，或是疊代過程中的調整參數，雖然愈
小的保留比率會造成低估條件機率中的共變異矩
陣，但是能使得收斂的結果較為穩定。
2.2.4 Bayesian Information Criterion
Schwarz, 1978提出以BIC判斷類別數 c是否
適當，以 EM 演算法所估算的參數 *Θ 近似
Loglikelihood函數的期望值：
  2 *c cBIC Q ln m Θ (21)
c是估算參數的個數，m是數據的筆數，最大化
Loglikeihood函數事實上就是最小化 BIC，選用過
多類別數將使得 BIC 大於適當類別數的 BIC。
McLachlan and Peel, 2000比較 BIC與 AIC的差異
(  2 2*c cAIC Q  Θ )。當  2ln m  ，也就
是數據筆數 8m 時，BIC的過多類別數懲罰項將
比 AIC顯著，因此在大量數據的系統，比較適合
以 BIC作為評估類別個數是否適當的指標。
3. 線上辨識操作狀態
本研究所提出的線上辨識操作狀態的方法是
以 PCA萃取歷史操作數據的特徵，再以貝式分類
在 PCA子空間中群聚 Score向量，得出各個不同
操作狀態的類別。這個方法的優點是經由 PCA能
減少變數的維度，明顯降低貝式分類的複雜程度
以及計算時間，能有效地增加混和模式收斂的穩
定性。然而，在即時辨識操作狀態之前必須確定
線上數據能被現有的 PCA子空間所解釋，除此之
外，在實際的應用過程中也發現線上數據屬於現
有的 PCA子空間仍有誤分類的情況，其原因在於
新數據的 Score向量在 PCA子空間中不屬於任一
既有的類別，也就被視為現有類別的離群數據，
因此在分類之前也必須檢查由混和模式所計算線
上數據的機率，應該大於 RMD 演算法被刪除離
群數據的機率。由於工廠的操作狀態隨著時間而
改變，當有新的事件發生，使得原先的 PCA子空
間無法解釋新的數據，此時必須更新 PCA 子空
間，而將新的數據在新的子空間分類。但是之前
已分類的數據無須重新分類，本研究提出類別參
數更新的方法，能將之前子空間的分類參數更新
至新的子空間。
3.1 Fault Isolation
線上數據經由尺度化後利用(5)式及(7)式分
別計算 Q 統計量及 T2 統計量，如果Q Q 或
2 2T T 表示已有新的事件產生，現有的 PCA 模
式無法解釋線上的數據，必須更新 PCA及分類模
式。如果Q Q 且 2 2T T ，必須藉由計算混和模
式的機率，檢查線上數據的 Score 是否為既有類
別的離群數據。如果確認線上數據屬於既有的
PCA子空間而且不是離群數據，經由貝式分類計
算屬於每個類別的事後機率，藉此判斷線上數據
是屬於過去已發生狀態之一。如果沒有檢查目前
的 PCA子空間是否能解釋線上數據，而貿然計算
每個類別的事後機率，容易發生誤分類的情況。
3.2 Update Mixture Model to Newer Subspace
新增數據至 m*筆數據，所有數據矩陣
*T T T
new  Y Y Y 經由
*
Y 、 *S 分別為所有數據的
平均值和標準差對角線矩陣，重新尺度化：
 ** * * 1 X Y Y S 。利用 PCA 找到 K*個主要方
向 *P ( *K K ，K 為之前 PCA 子空間的維度)和
對應的 Score 向量 *T ，由於新舊 PCA 子空間都
能解釋舊的數據，
*T * *T *   y y tP S y t P S (22)
舊數據的 Score在新的 PCA子空間能寫成：
* * 1 * t tA yS P (23)
T * 1 *A P SS P 、 *  y y y
