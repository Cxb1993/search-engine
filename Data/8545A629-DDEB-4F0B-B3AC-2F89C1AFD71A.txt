2 
高解析度視訊傳輸在無線網路上達到「高速
視訊服務」，並透過基於在應用層(Application 
Layer, APP) 、網路傳輸層 (Network and 
Transport Layer, NAT)、媒介存取控制層
(Media Access Control Layer, MAC)和實體層
(Physical Layer, PHY)特色上提出的傳輸服務
品質(QoS)跨層級(Cross-Layer)架構[1]-[6]，
傳輸高解析度視訊。本計畫中所提出的跨層
級架構依賴在應用層上資料分割(DP)技術和
一個適合在 IEEE 802.11b 上 MAC 層的 QoS
轉換。並透過使用 H.264 編碼器將壓縮過的
資料進行分割成不同重要性的分離單元，或
稱為分割(Partitions)。基於在不同分割上的
QoS 需求，明確指定在 MAC 層，連繫與 IEEE 
802.11b 增強分散式通道存取 (Enhanced 
Distributed Channel Access, EDCA)所提供的
存取類別(Access Category, AC)的每個分割
(Partitions)。 
本計畫亦以建置一種以高解析度視訊為
需求的嵌入式隨選視訊(embedded VOD)系統
為目的，並利用視訊在空間(Spatial)及時間
(Temporal)之可調性與嵌入式系統(Embedded 
System)的技術，使得在隨選視訊(VOD)系統
上傳輸的高解析度視訊更能適應，達到即時
傳輸及高品質的畫質[8][9]。同時，將採用目
前在高解析度視訊領域居領先的 SIGMA 
Designs 的 EM8623 平台，在 Linux 作業系統
上使用嵌入式中介軟體，開發高解析度的視
訊播放器，支援嵌入式隨選視訊(embedded 
VOD)系統。允許 APP 層透過它的串流需求
保護 H.264 較重要的資訊以保證 H.264 串流
被接收的最低品質，以達到隨選視訊(VOD)
系統之視訊傳輸所需求的網路服務品質。 
 
三、結合動態頻寬量測方法的跨層級架構 
通常網路發生壅塞情況不會隨著網路處
理能力的提高而完全消除，而且無線網路的
複雜性和視訊傳輸對壅塞時頻寬量測的性能
要求，使得頻寬量測方法的設計具有很高的
困難度，到目前為止，壅塞問題在無線網路
上還沒有得到很好的解決。本研究提出藉由
動態頻寬量測方式及結合無線網路傳輸時的
跨層級架構，即時調節視訊傳輸時資料的特
徵，希望能提升高解析度視訊於無線網路上
的傳輸服務品質(QoS)。經實驗証實本研究所
提出的架構的確有能力改善目前無線網路上
高解析度視訊傳輸服務品質。 
3.1 具有平均頻寬量測值的方法 
無線網路傳輸特性因具有訊號強弱、訊
號干擾、收發器的感應能力差異等，因此造
成有時頻寬使用率過低，有時頻寬使用率過
高，進而產生傳輸壅塞及封包遺失。大多數
的壅塞控制技術因為無法即時調節網路傳輸
頻寬狀態。所以，若是能獲得更準確且平均
的頻寬量測資訊，就能有效改善現有的壅塞
發生情況。進一步的提高無線網路上資料的
傳送與接收的品質[2]。 
對一個傳輸路徑而言，壅塞是發生在網
路瓶頸點，而這也常是傳輸延遲時間增長和
封包遺失的位置。本計畫所提出的平均頻寬
量測方法依據瓶頸點的狀況來動態調整傳送
的頻寬，希望能有效降低壅塞的發生並藉由
此方法達到以下目標： 
(1) 運算出準確的平均量測頻寬值，做為
調節視訊傳輸頻寬的依據； 
(2) 降低傳輸壅塞瓶頸點的發生機率； 
(3) 達到高度的頻寬使用率。 
一般而言，傳送端送出封包的時間差會
因網路瓶頸現象造成接收端收到的連續兩個
封包之時間差不同，藉由參考先前接收封包
運算出的平均量測頻寬值做為下一次量測頻
寬的依據，以此來推算傳送端與接收端之間
的網路頻寬值。由於傳送出的封包可能發生
遺失或延遲過久的現象，所以接下來的問題
在於如何求得平均量測頻寬值。我們定義欲
求得平均量測頻寬值(BWavg) 必須參考之前
取得至少 2個封包接收時間所量測的平均頻
寬(BWpre)及此次量測頻寬(BWcur)加總後的平
均值，做為調整視訊傳輸速率的依據，定義
如下[9]： 
( ) / 2avg cur preBW BW BW= +           (1) 
且 
1/( ) ,cur n n nBW P t t −= −               (2) 
1
1
2
1 /( ) .
2
n
pre i i i
i
BW P t t
n
−
−
=
= −− ∑          (3) 
其中
Pi：第 i 個封包長度 (Bytes)  
ti：接收端收到的第 i 個封包之時間
(million second) ，2 ≦ i ≦ n-1 
n：參考封包數。 
為了不增加計算平均量測頻寬值時間的
4 
適應它們的傳輸策略來符合可用的無線網路
環境和傳輸頻寬資源，授予它們能夠利用資
源和資訊交換，主動影響無線網路傳輸的活
力。對於允許競爭合作，亦提出一個結合動
態頻寬量測方法的跨層級架構，讓無線網路
視訊系統由聯合在每個 OSI 層中最佳的協定
和各層間資源交換。所提出競爭合作的目的
為公平概念的集合，對所選擇的無線傳輸策
略更有效，從而改善視訊應用的效能。 
 
圖 2：跨層級 QoS 架構各層執行程序 
 
四、無線網路傳輸之跨層級架構系統開發與
設計 
本研究計畫為提昇軟體開發設計的品
質，遵循 Light-Weight CMMI 規範撰寫各階
段報告書，並依推動小組所訂定的期限繳
交，說明如下：  
♦ 系統分析與計畫路程規劃階段 
本階段於 98 年 12 月 04 日繳交「專案執
行規劃書」(Project Execution Plan Document)
與 「 需 求 規 格 報 告 書 」 (Requirement 
Specification Document)。 
♦ 系統設計階段、系統製作階段 
本階段於 99 年 03 月 15 日繳交「系統設
計報告書」(System Design Document)。 
♦ 系統測試階段 
本階段於 99 年 06 月 14 日繳交「系統測
試報告書」(System Testing Document)。 
♦ 驗收與結案階段 
本階段繳交成果報告書，即本研究計畫成
果報告。 
 
本研究計畫建置一種以 IEEE 802.11e 無
線網路傳輸為需求的跨層級(Cross-Layer)架
構，並探討在本計畫所提出的跨層級
(Cross-Layer)架構下，進而透過無線網路
(802.11、802.11e)模擬實驗高解析度視訊
(HD-Video)傳輸效能，隨時改進傳輸功能，
完成可以支援高解析度視訊的播放功能，並
運用嵌入式系統之技術結合動態頻寬量測方
法，使得高解析度視訊傳輸更能適應在隨選
視訊系統(VOD)上，達到在無線網路上的傳
輸及高品質的視訊畫質。 
本計畫的主要功能敘述如下： 
 CROSS (Cross-Layer Architecture over 
Wireless Networks,無線網路傳輸之跨層
級架構) 
CROSS 利用視訊編碼層(Video Coding 
Layer)選擇所採用的視訊壓縮編碼方式
(MPEG-4, H.264)，利用平均頻寬量測法計算
出通道情況，建立最穩定且未大於可用頻寬
值，以利視訊串流進行傳輸播放。當發生壅
塞情況時，於 NAT 層採用 RED 壅塞控制機
制對視訊傳送做流量佇列速度管制。MAC 層
提供高達 8 個佇列存取類別，減少發生碰撞
時頻寬壅塞情形並提高傳輸封包擁有較快的
速度競爭到通道的使用權。各層級間依照壅
塞程度回傳給 APP 層最佳的傳輸參數，如
PHY 層回傳所計算的平均量測頻寬值及通道
狀態，MAC 層回傳所採用的佇列存取方式及
NAT 層使用的壅塞控制機制，以決定 APP 層
封包在不同的頻寬中傳輸。APP 層經由接收
其它層級最佳參數的回饋得到各層間傳輸需
求上的流量排程及通道情況和佇列的分派方
式，提供最佳的傳送狀況來建立連線。 
圖 3 為 CROSS 的系統架構圖，說明了
CROSS 系統透過 APP 層上資料分割(DP)技
術和一個適合在 IEEE 802.11e 上 MAC 層的
QoS 轉換，及 NAT 層與 PHY 層各層級之間
的互動關係。 
6 
UDP 的壅塞頻寬設為 0.5Mbps 與 1Mbps，
主要是觀察 MPEG-4 視訊在無線網路中利用
所提出的跨層級架構其傳輸的效能。詳細數
據將於接下來的內容做討論。 
 
5.4 實驗步驟 
圖 5 為模擬流程的示意圖，首先將原始
視訊壓縮編碼後產生不同之 MP4 視訊串流
檔，利用平均頻寬量測法計算出通道情況，
做為視訊傳輸速率的依據建立最穩定且未大
於頻寬值的通道，以利視訊串流進行傳輸播
放，這裡我們將 UDP 的壅塞頻寬分別設為
0.5Mbps 與 1Mbps，接著透過網路模擬器於
所提出的跨層級架構中進行傳送，並記錄相
關傳送資訊，如傳送時間、接收時間、封包
識別(packet id)等，另外也會產生傳送記錄
檔、接收紀錄檔和影片記錄檔以便後續的效
能評估動作。模擬結束分析相關資訊的記錄
後，可以得到視訊串流經過網路模擬環境傳
輸後的受損位元流，接著使用 MP4 的解碼器
對受損位元流解碼後，便可以得到和原本傳
送端相同的視訊格式(CIF)，比較傳送端視訊
和接收端受損視訊可計算出 PSNR 值用以觀
察視訊品質，另外利用經過模擬後的接收紀
錄檔可求得評估數據值(如：PSNR, Delay, 
Throughput 等)。 
 
 
圖 5：系統模擬架構圖 
 
5.5 實驗結果 
5.5.1 Mother-daughter 傳輸延遲分析 
由圖 6 可以看到所提出的跨層級架構在
一般的壅塞情況中(1Mbps)，當發生壅塞時傳
輸延遲(Delay)快速爬升後就不斷進行調控並
在一段區間內震盪後處於較平穩狀態。傳統
無線網路採用的一般傳輸方式使得傳輸延遲
維持在較高的時間上震盪，也由於它比較不
穩定的速度調整使得傳輸的服務品質也跟著
處於不平滑狀態。 
由於當路徑中傳輸的頻寬很小時，傳輸
延遲的情形將會提高，因此，接下來我們觀
察在較嚴重的壅塞情況中(0.5Mbps)的變化。 
由圖 7 我們發現，由於發生較嚴重的壅
塞情況，所提出的跨層級架構中的傳輸延遲
在快速爬升後立即動態的調整速度並達到穩
定；傳統的一般傳輸方式則反覆的在較高的
時間上進行大幅度的震盪行為。 
 
圖 6：UDP 資料流在壅塞頻寬(1Mbps)的傳輸延
遲變化圖 
 
 
圖 7：UDP 資料流在壅塞頻寬(0.5Mbps)的傳輸延
遲變化圖 
 
5.5.2Mother-daughter傳輸視訊品質分析 
由圖 8、圖 9 可以看出，當壅塞頻寬
(1Mbps 及 0.5Mbps)在較嚴重的情況下，一般
傳輸方式的效能表現於視訊品質上低於我們
提出的架構，因為傳輸頻寬過小，導致傳輸
延遲在快速爬升的途中容易因此產生封包遺
失，造成效能下降。傳統無線網路採用的方
式是保守但較容易實作的避免壅塞情況發
生，因此傳輸頻寬維持一定的流量時能夠有
良好的傳輸服務，而提供有著固定的傳輸效
能；但所提出之架構以動態調節壅塞頻寬為
最高目標以此保有一定的積極性，所以在突
發的壅塞情況下表現將比一般的傳輸流程出
8 
表 7：傳輸後視訊品質(壅塞頻寬為 0.5Mbps) 
 
 
六、結論 
本研究計畫利用無線區域網路標準，於
APP 層、NAT 層、MAC 層與 PHY 層之間所
溝通交換之控制訊息，建置一套以提供最佳
的視訊傳輸服務品質(QoS)為目標的架構，藉
此處理壅塞事件與無線網路傳輸情況所造成
之影響視訊傳輸效能的問題。我們於 NAT 層
使用平均量測頻寬方法建立一個穩定且未大
於可用頻寬值，利於視訊串流傳輸之通道，
使用 RED 佇列管理機制負責觀察網路層佇
列的壅塞情況適時地上報壅塞傳輸資訊，並
於 MAC 層加入了高達八個可用佇列的
802.11e MAC 架構。由模擬結果發現，提出
的跨層級傳輸架構在傳輸延遲項目中的表現
較一般方法至少降低了 1 倍，當網路競爭程
度提高時傳輸產出率則有更高的提升。 
實驗的模擬結果顯示，此方法除了可架
構於現有的無線網路標準上，平均量測頻寬
方法也沒有消耗任何網路頻寬資源，跨層級
架構亦因壅塞情況變化立即提高其動態調整
速度並達到穩定，減少不斷的封包損耗降低
傳輸品質，以取得較合理之服務品質。 
過去的相關研究多半集中於單純提出壅
塞頻寬量測方法之上，且未考慮加入實際於
視訊傳輸上的影響，因此在未來工作方面，
我們將以本研究成果為基礎，發展於適合各
種無線網路標準(如：WiMAX, Bluetooth 等)
上的傳輸機制，利用接收端所觀察到之網路
狀態動態決定最佳傳輸服務品質之機制，或
依此更改為動態調整壅塞路徑之選擇，以較
積極的作法調整所量測到之可用頻寬路徑反
映目前網路狀態做最佳路徑選擇傳輸，提升
整體效能對接收端視訊品質期待有進一步的
改善。 
 
七、計畫成果自評 
本研究計畫成果報告與原計畫之目的相
符，在本成果報告中所提出的透過跨層級架
構與嵌入式系統之技術，使得高解析度視訊
傳輸更能適應在無線區域網路上傳輸，以達
到即時傳送高品質的視訊畫質，達成了原計
畫的預期目標。同時，本計畫亦完成嵌入式
隨選視訊系統設計，以支援高解析度視訊傳
輸。 
本研究計畫之其他成果及相關探討，部
份已分別發表於國內外研討會論文(如八、參
考文獻[10]-[13])，未來將更進一步將相關研
究成果投稿至國際著名期刊論文發表。 
 
八、參考文獻 
[1] M. V. der Schaar and S. Shankar, “Cross-layer 
wireless multimedia transmission: challenges, 
principles, and new paradigms,” IEEE Wireless 
Communications, vol. 12, no. 4, pp.50-58, Aug. 
2005. 
[2] S. Milani and G. Calvagno, “A low-complexity 
cross-layer optimization algorithm for video 
communication over wireless networks,” IEEE 
Transactions on Multimedia, vol. 11, no. 5, pp. 
810-821, Aug. 2009. 
[3] Y. Chen and L. Li, “A wireless packet dropping 
algorithm considering fairness and channel 
condition,” in Proc. of the International Conference 
on Communications, Circuits and Systems, vol. 1, 
pp. 369-373, June 2004. 
[4] X. Li, X. Wu, W. Li, and X. Wang, “An adaptive 
cross-layer scheduling algorithm for multimedia 
networks,” in Proc. of the International Conference 
on Intelligent Information Hiding and Multimedia 
Signal Processing, pp. 52-55, Aug. 2008. 
[5] B. Xie, W. Zhou, and J. Zeng, “A novel cross-layer 
design with QoS guarantee for WiMAX system,” in 
Proc. of the Third International Conference on 
Pervasive Computing and Applications, vol. 2, pp. 
835-840, Oct. 2008. 
[6] K. A. Noordin and G. Markarian, “Cross-layer 
optimization architecture for WiMAX system,” in 
Proc. IEEE 18th International Symposium on 
Personal, Indoor and Mobile Radio 
Communications, pp. 1-4, Sept. 2007. 
[7] http://140.116.72.80/~smallko/ns2/Evalvid_in_NS2.
htm 
[8] 王隆仁, 吳承恩, “運用動態取樣法於可調式視訊
編碼及網路服務品質之效率分析,” ICDC 2008 
數位內容學術研討會(元智大學), Dec. 26, 2008. 
[9] 王隆仁, 吳承恩, “結合動態頻寬量測方法於無線
網路傳輸的跨層級架構,”NRT 2009 網路與 RFID
技術研討會(大葉大學), June 5, 2009. 
[10] L. J. Wang, Y. C. Huang, Y. L. Tang, “A study on 
the opportunity cost concept in non-linear image 
enhancement,＂ in Proc. of the ICDC 2009 
International Conference on Digital Content (ICDC 
出席國際學術會議心得報告 
                                                             
計畫編號 NSC 98-2220-E-251-001 
計畫名稱 
透過跨層級架構以改善基於嵌入式 VOD 之高解析度視訊在無線網路上的
傳輸 (Toward an improvement of HD-video transmission based on embedded VOD 
over wireless network through a cross-layer architecture) 
出國人員姓名 
服務機關及職稱 
王 隆 仁 
國立屏東商業技術學院/資訊工程系/副教授 
會議時間地點 2010/7/28~2010/7/30 英國(United Kingdom)利物浦(Liverpool) 
會議名稱 2nd International Conference on Computational Intelligence, Communication Systems and Networks (CICSyN2010 國際研討會議) 
發表論文題目 Non-Linear Image Enhancement Using Opportunity Costs 
 
一、出席國際研討會議經過 
這次參加的 CICSyN2010 國際研討會議在英國(United Kingdom)利物浦(Liverpool)的 Jurys 
Inn Liverpool Hotel (31 Keel Wharf, Liverpool, L3 4FN)舉辦，會議時間從 2010 年 7 月 28 日起
至 2010 年 7 月 30 日止共舉行三天，研討會網址為 http://cicsyn2010.info/，所研討的主要主題
說明如下： 
♦ Track:01-A Intelligent Systems 
♦ Track:02-B Hybrid Intelligent Systems & Hybrid Soft Computing 
♦ Track:03-C Sensor Nodes, Circuits, Devices, Wireless Sensor Networks 
♦ Track:04-D RFIDs and their Applications 
♦ Track:05-E Protocols and Standards 
♦ Track:06-F Modelling and Performance 
♦ Track:07-G Software Platforms and Middleware 
♦ Track:08-H Tools and Techniques for Design, Deployment, Testing and Evaluation 
♦ Track:09-I Security, Authentication, Wireless Security, Dependability 
♦ Track:10-J Discrete Event and Real Time Systems 
♦ Track:11-K Image, Speech and Signal Processing 
♦ Track:12-L Transport, Logistics, Harbour, Shipping and Marine 
♦ Track:13-M Virtual Reality, Visualization and Computer Games 
♦ Track:14-N Parallel and Distributed Architectures and Systems 
♦ Track:15-O Internet Modelling, Semantic Web and Ontologies 
♦ Track:16-P Mobile ad hoc Networks 
♦ Track:17-Q Vehicular Technology and Networks 
♦ Track:18-R Air Interfaces 
♦ Track:19-S QoS for Voice and Video in Wireless Networks 
♦ Track:20-U Bio-informatics and Bio-Medical Simulation 
 
這次的CICSyN2010三天研討會，再依發表論文之類別，在不同的Sessions(Tracks/Themes)
發表，Scheduled Papers 共有 44 papers、2 keynote speakers 及 1 tutorial，會議之行程說明如以
  
 
 
 
 
  
 
這次參與 CICSyN2010 國際研討會議是自行前往，也是第一次去英國(United Kingdom)，
英國是由大不列顛島(包括英格蘭、蘇格蘭、威爾斯)和北愛爾蘭構成。因為研討會的舉辦地
點在利物浦(Liverpool)的 Jurys Inn Liverpool Hotel (31 Keel Wharf, Liverpool, L3 4FN)，利物浦
(Liverpool)位於英格蘭北部，在曼徹斯特(Manchester)的西北方，並無直接的國際飛機航線，
因此往返的行程需先搭乘飛機再轉搭火車較為辛苦。本次行程先從高雄小港機場搭機(長榮航
空)至桃園機場，再從桃園機場轉機(長榮航空)至曼谷機場，再原機(長榮航空)飛抵英國希斯
洛(Heathrow)機場，再從希斯洛(Heathrow)機場轉乘地鐵(Underground)至倫敦(London)。希斯
洛(Heathrow)機場第三航站是長榮航空入境英國(United Kingdom)之處，由希斯洛(Heathrow)
機場至倫敦(London)市區的交通銜接十分順暢，有地鐵、電車、巴士、計程車等交通工具可
選擇，沿著機場內的標示指引，搭乘地鐵(Underground)至倫敦(London)Euston 車站，再從倫
敦(London)Euston 車站再搭乘快速火車，即可到達利物浦(Liverpool)Lime st.車站下車(如下
圖)。 
 
利物浦(Liverpool)Lime st.車站 利物浦(Liverpool)大學資訊館 
 
利物浦(Liverpool)是以披頭四故鄉聞名，在產業革命時代是與美國、西印度群島交易繁盛
的港都，雖然目前與過去的港都特色不同，但是依然是英國第二大貿易港口。利物浦市區的
環境非常美化舒適，觀光的景點有許多大教堂、美術館、博物館等。這次研討會的舉辦地點
Dr. Vasilis Tsoulkas 演講 我於 CICSyN2010 論文發表 
 
7 月 30 日(星期五) 09:00~10:10 在 Room A 參加 Keynote Speaker 2 由 Prof. Christopher J. 
James 主講“Detecting Behavioral Patterns From Personalized Ambient Monitoring of Psychiatric 
Patients”。 10:40~12:40 繼續在 Room A 參加 Image, Speech and Signal Processing 議程 – 此
Session 由 Richard N Zobel 主持，共有六位論文發表者。 12:40~12:45 研討會閉幕。 
 
二、與會心得 
首先非常感謝國科會的支持，提供補助出國參加本次 CICSyN2010 國際研討會的經費。 
這次的CICSyN2010國際研討會議，在英國(United Kingdom)利物浦(Liverpool)的 Jurys Inn 
Liverpool Hotel (31 Keel Wharf, Liverpool, L3 4FN)舉辦，除了在出國前自己要先準備充足的論
文發表資料(簡報 PPT 及成果展示)之外，能有機會以英文在世界各地的學者專家前，將自己
的研究成果發表及共同討論是最大的收穫。 
這次研討會的論文發表時間，前後大約有 25 分鐘，將個人的研究方法、理論、演算法及
成果向與會學者專家報告大約 20 分鐘，之後大約 5 分鐘再接受出席的學者專家所提出的問題
與建議，即時回答及討論，使我深刻的體認到事前準備的重要性，尤其在國外學者專家的提
問，也是一大挑戰，在報告與回答提問中不斷提醒自己，以英文解說要不急不徐，讓與會的
所有人都能聽清楚並瞭解，也深切體會到自己仍有許多研究與學習需要加強努力。另外，於
這次研討會中，亦使自己有機會可從與會的 Tutorial 及 Keynote Speakers 教授之演講，以及來
自其他國家的學者專家研究中，學習到許多先進的研究方向與知識，擴展自己研究的視野與
深度，藉以修正自己的研究及教學工作，深感獲益良多。 
 
三、考察參觀活動(無是項活動者省略) 
無。 
 
四、建議 
無。 
 
五、攜回資料名稱及內容 
Non-Linear Image Enhancement Using Opportunity Costs  
 
Lung-Jen Wang 
Dept. of Computer Science & Information Engineering 
National Pingtung Institute of Commerce 
Pingtung, Taiwan 
e-mail: ljwang@npic.edu.tw 
Ya-Chun Huang 
Dept. of Computer Science & Information Engineering 
National Pingtung Institute of Commerce 
Pingtung, Taiwan 
e-mail: yckiwi@gmail.com
 
 
Abstract—Image enhancement is a commonly used method for 
the improvement of the quality of blurred image. Among many 
image enhancement approaches, the nonlinear image 
enhancement method has a simple structure and can obtain a 
good processing effect. For various target images, it is difficult 
to decide the best combination of clipping and scaling 
parameters within the nonlinear image enhancement method. 
In this paper, we propose a new method involving the concept 
of opportunity cost to simulate the image enhancement, and 
identify the most suitable enhancement parameters of clipping 
and scaling.  Furthermore, a smoothing cubic B-spline filter is 
proposed for the conventional nonlinear image enhancement. 
Experimental results show that the proposed method improves 
the quality of blurred image and obtains a better subjective 
quality and objective PSNR performance than other nonlinear 
image enhancement methods. 
Keywords- nonlinear image enhancement; clipping; scaling; 
opportunity cost 
I.  INTRODUCTION  
Generally, an image leads to a blurred problem caused by 
the loss of high-frequency components [1]. To improve the 
quality of such a blurred image, the image enhancement is an 
indispensable post-processing method. The principle of 
image enhancement is to process a given blurred image so 
that it is more suitable for visual quality or image analysis 
[2]. 
Figure 1. Basic operation of NIE scheme 
The nonlinear image enhancement (NIE) scheme [4][5], 
which uses low-pass filter and non-linear operator technique 
to predict a high-frequency component, can enhance the 
visual quality of a blurred image. In addition, this NIE 
method uses the Gaussian-Pyramid [4] or filter subtract and 
decimate (FSD) - Pyramid [5] representation of an image to 
extract the high-frequency component of input (blurred) 
image shown in Fig.1. That is, a high-frequency component 
L-1 can be predicted by a nonlinear filter. The new output 
image is generated next as the sum of the given input image 
and L-1. 
It is well known that the cubic B-spline filter [3] is a very 
smoothing filter. In this paper, this cubic B-spline filter can 
be used to improve the conventional NIE method. In addition, 
it is shown in [5] that a tradeoff exists between the perceived 
ringing side-effects and the sharpness of the edges in the NIE 
scheme. Furthermore, the exact relationship between the 
clipping and scaling parameters to the blurring and ringing 
deviations is complex. 
Many researches on improving QoS for wireless network 
application concentrate on the exact methods of the 
bottleneck bandwidth measurement, which usually rely on 
some helpful tools of bandwidth measurement. The extra 
execution of the measurement tools before an application’s 
initialization, however, might heavily affect the overall 
performance of the application, and the measured results 
could also hardly be used to adjust the transmission rate 
immediately, which is more likely what more application 
users expect. 
However, it is believed that the best values of 
enhancement parameters vary with the types of images. 
Since one solution of enhancement parameters cannot fit all 
occasions, in this paper it is mainly inspired by the principles 
of opportunity cost [6], and presents a novel approach to 
improve the blurred image, which simulates the image 
enhancement for different combinations of the clipping and 
scaling parameters. Furthermore, the proposed method 
identifies the most suitable combination of clipping and 
scaling for enhancement parameters, and adopts it as the 
final solution to enhance the blurred image. Because there is 
no standard of image quality that can serve as the objective 
criterion in image enhancement. In this paper, some standard 
images are blurred to low-resolution images, and then the 
proposed method and other NIE methods are used to enhance 
these blurred images. Finally, their subjective quality and 
objective PSNR values of blurred and enhanced images can 
be compared in experimental results for the proposed method 
and other NIE method. 
2010 Second International Conference on Computational Intelligence, Communication Systems and Networks
978-0-7695-4158-7/10 $26.00 © 2010 IEEE
DOI 10.1109/CICSyN.2010.72
2576
IV. THE OPTIMAL PARAMETER COMBINATION 
ALGORITHM 
The choice and use of clipping(c) and scaling(s) 
parameters involves trade-off and opportunity cost. In this 
section, the optimal parameter combination algorithm is 
proposed to identify the c and s parameters in all the 
combinations as best as possible for a set of image 
enhancement to achieve the goal of optimization. 
For an input image, first it is blurred to low-resolution 
image, and then it is enhanced by the NIE method. The 
PSNR value is determined for different parameters c and/or 
s, e.g.: c = 0.1; s = 3; PSNR = 26.54 dB, c = 0.5; s = 4; 
PSNR = 26.76 dB. We use the optimal parameters in each 
group to identify the combination of c and s, and generate 
the corresponding opportunity costs. The c and s parameters 
in this paper are set to c = 0.1, 0.2, 0.3, …, 0.9, 1.0 and s = 1, 
2, 3, …, 9, 10, respectively. Consequently, 100 different 
combinations can be generated as shown in Fig.3. The costs 
for different combinations of c and s refer to their 
corresponding opportunity costs. That is, for one image, 
when we choose the option of the parameters c = 0.1; s = 1 
and give up the choice of the parameters, we can determine 
the opportunity cost of this option with respect to the image. 
Likewise, with the same parameters, the opportunity cost of 
each image can be determined. Then we have the sum of all 
these opportunity costs, called the total cost of the options. 
To obtain the optimal solution, we can choose the 
combination of c and s  parameters having the minimum 
total cost. 
 
Figure 3. All the generated combinations of c and s parameters 
 
Figure 4. The optimal parameter combination algorithm 
In the case of n (n is more than one) input images, 
each different combination of c and s parameters can get a 
different PSNR value of the image. We can find the optimal 
parameters of each image by these PSNR values, and there 
will be at most n set of different optimal parameters. With 
these n different combinations of parameters, we will have n 
opportunity costs for each image, and then have, after 
summation of opportunity costs with respect to each set of 
parameter, n total costs. We can obtain the optimal 
combination of parameters to minimize the total opportunity 
cost, as illustrated in Fig.4. 
 
Let i be the index of distinct combinations of c and s 
parameters, j be the number of images, and PSNR(i , j) be 
the PSNR of an images with respect to the c and s 
parameters for mi ≤≤1  and nj ≤≤1 , where i, j, m and n 
are integers. Then, the optimal combination algorithm of c 
and s parameters is summarized in the following steps: 
 
1) Calculate PSNR (i, j) of all images for all 
combinations of c and s parameters. 
2) Compute the optimal solution OP(j) for all image by 
)),(max()( jPSNRjOP ⋅=  (4)
3) Obtain the optimal PSNR of each image by 
))(max()(_ jOPjPSNROptimal =  (5)
4) Compute the opportunity cost of each image by 
|)(_)(|)( jPSNROptimaljOPjCost −= (6)
5) Compute the total opportunity cost of images by 
∑
=
=
n
j
jCosttT
1
)(cos  (7)
6) Select the minimum Tcost for optimal solution and 
corresponding set of c and s parameters. 
 
An illustrative example of the above algorithm is 
implemented first by the simplified c = 0.1, 0.2, 0.3; s = 1, 2, 
3 and three input images X1, X2, X3. Then, the total of nine 
different combinations of the c and s parameters is 
illustrated in this example. Consequently, each image 
corresponds to nine different PSNR values of images, as 
shown in Table I. 
TABLE I.  PSNR OF THREE IMAGES CORRESPONDING TO 
DIFFERENT c AND s PARAMETERS 
Parameters PSNR (dB) 
c s X1 X2 X3 
0.1 1 12 13 32 
0.1 2 14 17 35 
0.1 3 16 19 36 
0.2 1 18 21 37 
0.2 2 20 27 38 
0.2 3 22 25 31 
0.3 1 24 23 32 
0.3 2 26 21 33 
0.3 3 28 19 30 
2598
the side-effect of the blurring and ringing is minimum for the enhanced images. 
TABLE IV.  OPPORTUNITY COSTS AND TCOST FOR ALL IMAGES WITH DIFFERENT C AND S PARAMETERS 
  Parameters Opportunity Cost 
c s cost(X1) cost(X2) cost(X3) cost(X4) cost(X5) cost(X6) cost(X7) cost(X8) cost(X9) cost(X10) cost(X11) cost(X12) Tcost
0.1 10 0 1.1473 0.3716 0 0.0215 0.6609 3.1294 3.4166 0.0715 0.3557 0.0003 0 9.1748
0.1 7 0.1651 0 0.0049 0.3742 0.2809 0.0079 0.7609 0.9485 0.1182 0.0458 0.2284 0.2776 3.2124
0.1 8 0.0898 0.1973 0 0.1738 0.1557 0.0521 1.4821 1.7345 0.0155 0 0.0769 0.137 4.1147
0.1 10 0 1.1473 0.3716 0 0.0215 0.6609 3.1294 3.4166 0.0715 0.3557 0.0003 0 9.1748
0.4 10 0.0008 1.0782 0.3712 0.1306 0 0.5101 3.0806 3.2367 0.0729 0.3498 0.0068 0.0014 8.8391
0.3 7 0.1655 0.0004 0.0096 0.41680 0.2818 0 0.7578 0.8862 0.1189 0.0561 0.2314 0.2786 3.2031
0.1 5 0.3713 0.2939 0.4034 0.9553 0.6503 0.4679 0 0 0.5596 0.5784 0.7259 0.6823 5.6883
0.1 5 0.3713 0.2939 0.4034 0.9553 0.6503 0.4679 0 0 0.5596 0.5784 0.7259 0.6823 5.6883
0.1 9 0.0345 0.5967 0.1267 0.0471 0.0702 0.2791 2.2941 2.5788 0 0.1085 0 0.0436 6.1793
0.1 8 0.0898 0.1973 0 0.1738 0.1557 0.0521 1.4821 1.7345 0.0155 0 0.0769 0.137 4.1147
0.1 9 0.0345 0.5967 0.1267 0.0471 0.0702 0.2791 2.2941 2.5788 0 0.1085 0 0.0436 6.1793
0.1 10 0 1.1473 0.3716 0 0.0215 0.6609 3.1294 3.4166 0.0715 0.3557 0.0003 0 9.1748
 
V. EXPERIMENTAL RESULTS  
 
   
Aerial Barbara Boat Crowd 
   
Elaine Portofino Stonehse Wood 
Figure 6. Eight standard 512×512 Gray Images 
In this section it shows the experimental results of some 
NIE methods. Firstly, eight standard gray images (Aerial, 
Barbara, Boat, Crowd, Elaine, Portofino, Stonehse, and 
Wood) shown in Fig.6 are blurred into low-resolution ones. 
Then the proposed method with cubic B-spline filter and the 
methods in [4] and [5] are applied on these low-resolution 
blurred images, and we make a comparison on the PSNR 
generated in each method in Table V. The images are 
originally high-resolution images, and we use the Gaussian 
[4], FSD [5] and proposed methods for image enhancement. 
It follows from Table V that the PSNR values of enhanced 
images using the proposed methods are better then those of 
methods given in [4] and [5]. In Fig.7, one observes that the 
gray Aerial enhanced image processed by the proposed 
method obtains a better subjective quality and an objective 
PSNR to the blurred image. Image enhanced by the FSD and 
Gaussian methods are relatively worse in visual and PSNR 
quality. 
One more observes from Table V, for the proposed NIE 
method, the estimation parameters of c = 0.4; s = 5, the 
theoretical parameters of c = 0.45; s = 3 and the minimum 
Tcost parameters of c = 0.3; s = 7 are producing different 
results, that is, eight blurred images enhanced with the 
parameters of c = 0.3; s = 7 are better the those images 
enhanced with the parameters of c = 0.4; s = 5 and c = 0.45; s 
= 3. Therefore, the parameter values of c = 0.3; s = 7 is 
proposed to have a superior performance in the proposed 
NIE method with cubic B-spline filter. 
VI. CONCLUSIONS 
In this paper, we present that the NIE method combined 
with a simulation and identification process of clipping and 
scaling parameters can provide the optimal parameter 
combination for all the different images. The experimental 
results show that the proposed NIE method with cubic B-
spline filter and c = 0.3; s = 7 yields a better subjective 
quality and objective PSNR value than other NIE methods 
for the enhanced image. 
ACKNOWLEDGMENT 
This work was supported by the National Science 
Council, R.O.C., under Grant NSC 96-2221-E-251-004 and 
NSC 98-2220-E-251-001. The authors would also like to 
thank Mr. Ying-Lun Tang for his valuable contributions. 
REFERENCES 
[1] S. Yuan, A. Taguchit, M. Kawamata, “Arbitrary scale image 
enlargement with the prediction of high frequency components,” in 
Proc. of IEEE International Symposium on Circuits and Systems, vol. 
6, pp.6264-6267, 23-26 May 2005. 
[2] S. Mitra, T. Yu, “Transform amplitude sharpening: A new method of 
image enhancement,” Comput. Vis., Graph., Image Process., vol.40, 
pp.205-218, 1987. 
2610
無研發成果推廣資料 
權利金 0 0 100% 千元  
碩士生 4 4 100% 黃雅君、陳佳典、林俊男、薛明原。 
博士生 0 0 100%  
博士後研究員 0 0 100%  參與計畫人力 
（本國籍） 
專任助理 1 1 100% 
人次 李吉正 (2009/8/21 至
2009/10/6 共 1.5 個
月)、謝坤融(2009/10/12
至 2010/07/31 共 9.5 個
月) 
期刊論文 2 2 100% 
1.W. L. Yang, L. J. 
Wang, ＇The 
investigation of 
delay-constrained 
multicasting with 
minimum-energy 
consumption in static 
ad hoc wireless 
networks,＇ 
International Journal 
of Ad Hoc and 
Ubiquitous Computing, 
vol.4, no.3/4, 
pp.237-250, 2009. 
(SCIE) 
2.T. C. Lin, T. K. 
Truong, S. H. Chen, L. 
J. Wang, T. C. 
Cheng, ＇Simplified 
2-D cubic spline 
interpolation scheme 
using direct 
computation 
algorithm,＇ accepted 
and to appear in IEEE 
Trans. on Image 
Processing, April 
2010. (SCI, SCIE) 
國外 論文著作 
研究報告 /技術報
告 0 0 100% 
篇 
 
 
