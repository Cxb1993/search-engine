  
 行政院國家科學委員會補助專題研究計畫 
■成果報告 
□期中進度報告 
 
廣播球拍類型運動視訊分析 
 
計畫類別：■個別型計畫   □整合型計畫 
計畫編號：NSC  99 － 2221 － E － 130 － 011 － MY3 
執行期間：99 年 8 月 1日至  102 年 7 月 31 日 
 
執行機構及系所：銘傳大學 資訊傳播工程系 
 
計畫主持人：謝朝和 教授 
共同主持人：郭忠民 教授 
計畫參與人員：  
 
成果報告類型(依經費核定清單規定繳交)：□精簡報告  ■完整報告 
 
本計畫除繳交成果報告外，另須繳交以下出國心得報告： 
□赴國外出差或研習心得報告 
□赴大陸地區出差或研習心得報告 
■出席國際學術會議心得報告 
□國際合作研究計畫國外研究報告 
 
處理方式：除列管計畫及下列情形者外，得立即公開查詢 
            □涉及專利或其他智慧財產權，□一年■二年後可公開查詢 
 
 
中   華   民   國  102  年  9 月  25  日 
movement or camera view change. Another 
approach is background subtraction, which 
constructs a background model to separate players 
[26, 27, 30, 31, 32, 34]. Major background models 
include empty court image, mean of continuous 
frames, and mean of dominant color. The empty 
court image is hard to obtain because there usually 
have players in the court such that the background 
subtraction method is unrealistic. Using continuous 
frames to set up the statistic background model 
shows great performance at fixed camera view, but 
not suitable for circumstance of frequently changed 
perspectives. The dominant color method has merits 
of computation simplicity and robustness under 
different perspectives. However, dominant color 
selection and range determination are still open 
problems requiring more efforts. Furthermore, in 
player detection, the existing algorithms often 
employ a fixed search window which does not fit a 
player figure well. Although it makes no difference 
in tracking players, high level operations, like action 
recognition, still demand a best fit window and a 
complete body. In this research, we propose a novel 
method for player detection, tracking and 
segmentation, and player action recognition. The 
contribution of the research includes: 
(a) An effective approach for the 
segmentation of playfield and court line detection is 
presented which is mainly based on a novel adaptive 
thresholding scheme. The adaptive thresholding is 
robust to the change of stadiums and lighting 
conditions, as well as noise corruption. 
(b) An adaptive search window with varying 
player bounding box is designed to make the 
extraction of player body more complete and the 
tracking more efficient and reliable. 
(c) A player segmentation method which 
combines non-dominant color extraction and edge 
detection is proposed to effectively separate players 
from background.  
(d) A novel cast shadow removal scheme is 
presented to refine the player figure extraction and 
player search window. 
(e) An effective player action recognition 
employing SIFT flow is proposed. 
 
2. Proposed methods 
 
Fig. 1 shows the research subjects of this project 
in three years. In the first year, we are devoted to the 
detection (segmentation) and tracking of playfields 
as well as court lines. Next, in the second year, we 
developed detection (segmentation) and tracking 
methods for players including singles and doubles. 
Finally, we focus on player action analysis and 
recognition. 
 
 
Fig.1 The research subjects of this project 
2.1 Playfield segmentation 
We have presented a unsupervised method of 
playfield segmentation for various sport videos, as 
shown in Fig.2. The method includes three 
processes, unsupervised clustering, cluster merging 
and region fusing. The first process generates 
clusters by applying steepest-ascent hill climbing to 
the estimated probability density function of Cb-Cr 
plane. A simple and effective partition rule was 
developed to further merge the clusters into four 
color classes. Finally, a simple region fusing scheme 
is adopted to eliminate small regions. The 
experimental results indicate that the proposed 
method is general and effective for the segmentation 
of various sport videos 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
1st Year 
1. Playfield detection, segmentation and tracking 
2. Detection and tracking of court lines 
2nd Year 
 
1. Player detection and tracking for single player 
2. Player detection and tracking for double player 
      
3rd Year 
 
1. Players’ action analysis  
2. Action recognition and semantic extraction 
 
Image 
Non-parameter 
estimation 
Local maximum 
clustering 
Result 
Four-color 
cluster merging 
Small region 
fusion 
Fig. 2. Flow chart of the playfield  
segmentation method 
Calculate 3D 
histogram of 
(cb,cr) 
Fig. 6 shows the adaptive search window 
(marked in black) and player window (marked in 
red) during the tracking period. It can be seen that 
both windows are changing frame by frame, which 
is adaptive according to the deformable player. The 
adaptive window method is more suitable for high 
level automatic annotation system. 
3.3 Tracking Performance 
In this subsection, we evaluate the tracking 
performance of the proposed method, and compare 
it with the method in [40]. In [40], the authors 
presented a robust tracking algorithm in 3-D 
domain, and they also proposed an adaptive Double 
Exponential Smoothing (DES) filter to further 
smooth the tracking trajectory. 
Fig. 7 shows an example of the trajectory 
generated by the proposed method. The tracking 
results of the method in [40] without and with DES 
are demonstrated in Fig. 8(a) and Fig. 8(b), 
respectively. It is seen that the significant tracking 
errors occur in the approach without DES tracking 
filter. Meanwhile, even with DES, some significant 
errors still exist such as the area marked with the red 
rectangle. On the contrast, our approach that does 
not employ any tracking filter gives better tracking 
performance. Comparison of the proposed method 
and the method in [5] with DES for various tennis 
videos are summarized in Table 1. It indicates that 
our method achieves better performance than that of 
the method in [5]. 
3.4 Player Segmentation 
The factors affecting accuracy of player 
segmentation are player window and segmentation 
algorithm. The proposed adaptive window and 
player figure extraction algorithm are robust and 
effective for different courts and lighting conditions, 
so the method achieves excellent segmentation 
results as shown in Fig. 7. The performance of the 
player figure segmentation is essential to the higher 
level analysis such as player action recognition and 
behavior analysis. 
 
3.5 Player action recognition 
To evaluate the proposed algorithm, we tested 
on broadcast tennis videos. With regard to tennis 
videos, we extract 40 test action clips from 6 
broadcast tennis games. Each clip includes 11 
frames to produce 10 temporal SIFT vectors. The 
actions of the test clips contain 9 run-left, 7 
run-right, 11 backhand-stroke, and 16 
forehand-stroke actions. Fig. 10 to Fig.13 shows the 
SIFT vectors. The run-swing classifier is trained by 
8 samples selected from one game (4 runs, 4 
swings). Although the number of training samples is 
small, the accuracy is 92.5% (37/40). The other two 
classifiers, run and swing, are trained by 10 and 11 
samples each. Table 2 shows the confusion matrix. The 
recognition rate of the 4 actions (Run Left, Run Right, 
Forehand, Backhand) are (0.89, 0.72, 0.82, 0.94) 
individually. 
 
 
Fig. 5. Results of court line detection. 
 
 
 
Fig. 6. Experimental results of proposed adaptive search 
window (search window highlighted in black; player 
window highlighted in red). 
 
Table 2. Confusion matrix 
 
 Run Left Run Right Forehand Backhand 
Run Left 0.89 0 0 0.06 
Run Right 0 0.72 0 0 
Forehand 0 0.28 0.82 0 
Backhand 0.11 0 0.18 0.94 
 
 
 
Fig. 10. SIFT flows of player’s running left 
 
         
Fig. 11. SIFT flows of player’s running right 
 
 
Fig.12. SIFT flows of player’s backhand stroke 
 
8. C.H.Hsieh,Y.-C Jiang, C. M. Kuo, M. H. Hung, 
J. S. Pan, "Player Detection and segmentation 
for broadcast tennis videos," The 23rd IPPR 
Conference on Computer Vision, Graphics, and 
Image Processing (CVGIP2010) , pp.541-546, 
Taiwan, 2010.8. 
9. N. C Yang, C. M. Kuo, C. Y. Li, C. H. Hsieh, M. 
H. Hung, "Robust player tracking for broadcast 
tennis videos," The 23rd IPPR Conference on 
Computer Vision, Graphics, and Image 
Processing (CVGIP2010) , pp.522-528, Taiwan, 
2010.8 
 
References 
 
[1] Zhou, W., Dao, S., and Kuo, C. C. Jay 
“On-line knowledge- and rule-based video 
classification system for video indexing and 
dissemination,” Information Systems, vol. 27, 
no. 8, pp. 559-586, Dec. 2002. 
[2] Ekin, A., Tekalp, A. M., and Mehrotra, R. 
“Automatic soccer video analysis and 
summarization,” IEEE Trans. on Image 
Processing, Vol. 12, No. 7, pp. 796-806, July 
2003. 
[3] Zhang, D., and Chang, S.-F. “Real-time view 
recognition and event detection for sports 
video,” Journal of Visual Communication and 
Image Representation, vol. 15, issue 3, pp. 
330-347, Sep. 2004. 
[4] Li, B., Errico, J. H., Paoand H., and Sezan, I. 
“Bridging the semantic gap in sports video 
retrieval and summarization,” Journal of Visual 
Communication and Image Representation, 
vol. 15, issue 3, pp. 393-424, Sep. 2004. 
[5] Xie, L., Xu, P., Chang, S.-F., Divakaran, A., 
and Sun, H. “Structure analysis of soccer video 
with domain knowledge and hidden Markov 
models,” Pattern Recognition Letters, vol. 25, 
issue 7, pp. 767-775, May 2004. 
[6] Leonardi, R., Migliorati, P., and  Prandini, M. 
“Semantic indexing of soccer audio-visual 
sequences: a multimodal approach based on 
controlled Markov chains,” IEEE Trans. on 
Circuits Syst. Video Techn., vol. 14 no. 5, pp. 
634-643, May 2004. 
[7] Gong, Y., Han, M., Hua, W., and Xu, W. 
“Maximum entropy model-based baseball 
highlight detection and classification,” 
Computer Vision and Image Understanding, 
vol. 96, issue 2, pp.181-199, Nov. 2004. 
[8] Shih, H.-C., and Huang, C. L. “MSN: 
statistical understanding of broadcasted 
baseball video using multi-level semantic 
network,” IEEE Trans. on Broadcasting, vol. 
51, issue 4, pp. 449-459, Dec. 2005. 
[9] Duan, L.Y., Xu, M., Tian, Q., Xu, C., Jin, J. S. 
“A unified framework for semantic shot 
classification in sport video,” IEEE Trans. on 
Multimedia, vol. 7, issue 6, pp. 1066-1083, 
Dec. 2005. 
[10] Sadlier, D., and O’Connor, N. “Event detection 
in field sports video using audio-visual features 
and a support vector machine,” IEEE Trans. on 
Circuits Syst. Video Techn., vol. 15, no. 10, 
pp. 1125-1233, Oct. 2005. 
[11] Huang, C. L., Shih, H.-C., and Chao, C.-Y. 
“Semantic analysis of soccer video using 
dynamic Bayesian network,” IEEE Trans. on 
Multimedia, vol. 8, no. 4, pp. 749-760, Aug. 
2006. 
[12] Zhang, D., and Chang, S.-F. “Event detection 
in baseball video using superimposed caption 
recognition,” in Proceedings of the tenth ACM 
international conference on Multimedia, 
France, pp.315-318, Dec. 2002. 
[13] Liua, J., Tong, X., Lic, W., Wang, T., Zhang, 
Y., and Wang, H. “Automatic player detection, 
labeling and tracking in broadcast soccer 
video,” Pattern Recognition Letters, vol.30, 
no.2, pp.103-113, 2009. 
[14] Jian, J.-L., Hung, M.-H., Hsieh, C.-H., Chang, 
Y. “Real-Time scene classification for baseball 
videos,” in Proc. CVGIP, Taiwan, pp.115-122, 
Aug. 2005. 
[15] Su, Y.-M., and Hsieh, C.-H. “A novel caption 
extraction scheme for various sports captions,” 
ICPR 2006, Hong Kong, pp.1054-1057, Aug. 
2006. 
[16] Su, Y. M., and Hsieh, C.-H. “A novel 
model-based segmentation approach to extract 
caption contents on sports videos,” ICME 
2006, Toronto, pp.1829-1832, July 2006. 
[17] Ekin, A., and Tekalp, A. M. “Shot type 
classification by dominant color for sports 
video segmentation and summarization,” 
ICASSP 2003, Hong Kong, vol. 3, pp. 
173-176, Apr. 2003. 
[18] Pei, S.-C., and Chen, F. “Semantic scenes 
detection and classification in sports videos,” 
in Proc. CVGIP 2003, Taiwan, pp. 210-217, 
2003. 
[19] Chu, W.-T., and Wu, J.-L. “Development of 
realistic applications based on explicit event 
detection in broadcasting baseball videos,” in 
Proceedings of International Multimedia 
Modelling Conference, pp. 12-19, Jan. 2006. 
[20] Assfalg, J., and Bertini, M. “Semantic 
annotation of soccer videos: automatic 
highlights identification,” Computer Vision 
國科會補助專題研究計畫成果報告自評表 
請就研究內容與原計畫相符程度、達成預期目標情況、研究成果之學術或應用價值
（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）、是否適合在學
術期刊發表或申請專利、主要發現或其他有關價值等，作一綜合評估。 
1. 請就研究內容與原計畫相符程度、達成預期目標情況作一綜合評估 
■ 達成目標 
□ 未達成目標（請說明，以 100字為限） 
□ 實驗失敗 
□ 因故實驗中斷 
□ 其他原因 
說明： 
2. 研究成果在學術期刊發表或申請專利等情形： 
論文：已發表 □未發表之文稿 □撰寫中 □無 
專利：□已獲得 申請中 □無 
技轉：□已技轉 □洽談中 □無 
其他：（以 100字為限） 
已發表 9篇論文： 
1. K. T. Lai, C. H. Hsieh, J.D. Sun and Y. C. Jiang,” An adaptive search window algorithm for player 
tracking in broadcast tennis videos,” International Journal of Innovative Computing, Information and 
Control, vol.8, no.10, pp.6733–6745, Oct. 2012 (SCI). 
2. M.H. Hung, C.H. Hsieh, C. M. Kuo, J. S. Pan, “Generalized playfield segmentation of sport videos 
using color features,” Pattern Recognition Letters, vol. 32, pp. 987-1000, Jan, 2011 ( SCI). 
 3. C. M. Kuo, M. H. Hung, Y. K. Chang and C. H. Hsieh, “Playfield Segmentation for Baseball Videos 
Using Adaptive GMMs,” International Journal of Innovative Computing, Information and Control, 
vol.6, no.6, pp.2787–2801, Oct. 2010 (SCI). 
4. K.T Lai, M. S Chen , C. H. Hsieh , M. F. Lai ,“Orientation histogram of SIFT displacement for 
recognizing actions in broadcast videos,” 2011 3rd  European Workshop on Visual Information 
Processing (EUVIP), pp.286 - 291 , July 2011. 
5. C. H. Hsieh, P. S. Huang, and M. D. Tang, “Human Action Recognition Using Silhouette Histogram, 
“the 34th Australasian Computer Science Conference(ACSC 2011), Perth, Australia, 2011 
6. W. Y. Hwang, C. H. Hsieh, “Human action recognition using 3-D HOG and key-point 
distribution,”23th IPPR Conference on Computer Vision, Graphics and Image Processing 
(CVGIP2010), Aug.2010. 
7. K. T. Lai, C. H. Hsieh, M. F. Lai, M. S. Chen,” Human action recognition using key-point 
displacement” Int. Conf. on Signal and Image Processing, ICISP 2010, Quebec, Canada, pp.439-447, 
2010. 
8. C.H.Hsieh,Y.-C Jiang, C. M. Kuo, M. H. Hung, J. S. Pan, "Player Detection and segmentation for 
broadcast tennis videos," The 23rd IPPR Conference on Computer Vision, Graphics, and Image 
Processing (CVGIP2010) , pp.541-546, Taiwan, 2010.8. 
9. N. C Yang, C. M. Kuo, C. Y. Li, C. H. Hsieh, M. H. Hung, "Robust player tracking for broadcast 
tennis videos," The 23rd IPPR Conference on Computer Vision, Graphics, and Image Processing 
(CVGIP2010) , pp.522-528, Taiwan, 2010.8 
國科會補助專題研究計畫出席國際學術會議心得報告 
日期： 100  年 10 月 26日 
                                 
一、參加會議經過 
第一屆儀器、測量、計算機、通信和控制國際會議 (The First International Conference on 
Instrumentation, Measurement, Computer, Communication and Control (IMCCC 2011)是由中國哈爾濱
工業大學所主辦的，協辦單位有信息系統安全技術重點實驗室(National Key Laboratory of Science 
and Technology on Information System Security)、電子和電信工程師學會(IETE)哈爾濱分会、北京分
会及北京郵電大學(Beijing University of Posts and Telecommunications)等。會議舉辦時間為 10月 20
至 23日，地點在中國北京的温都水城（Hot Spring Leisure City）。 
本次會議論文著重在儀器、測量、計算機、通信和控制的發展趨勢，並提供一個給參加學者
在不同面向可以分享見解、經驗和互動的論壇，相互討論關於電腦科學、資訊技術和儀器、測量
的新興技術與專利。會議提供了最好的機會，將分別來自學術界和工業界的學生、研究人員和從
業人員匯聚一堂。會議論文將由 IEEE 出版，並為 EI資料庫收錄。此次發表一篇論文，報告時段
被安排在 10/22 的 15:30-17:10，得與許多國際學者交流。並利用會議空檔體驗一下北京之氣候、
地形與人文的差異。會議結束搭乘 10/24中午 12:45直飛桃園的班機返台。此次參加研討會，很高
興能與多位專家學者交換心得，對於未來的研究頗有助益。 
二、與會心得 
這次的 IMCC 2011會議中，大會提供了議事手冊及論文 CD 片，供與會者迅速了解論文內容
概況。在會議第二天的 conference dinner，大會選在温都水城餐廳舉辦，同時被安排與大會主席及
主講(Keynote speaker)同桌，透過互相交流，對目前相關領域的發展有更深入的了解，也度過一個
愉快而充實的夜晚。 
三、發表論文全文或摘要 
Human Action Recognition Using Histogram of Oriented Gradient of Motion History Image 
計畫編號 NSC 99－2632－E－130－001－MY3 
計畫名稱 廣播球拍類型運動視訊分析 
出國人員姓名 謝朝和 
服務機構
及職稱 
銘傳大學 資傳系 教授 
會議時間 
100年 10月 20日至 
100年 10月 23日 會議地點 中國北京 
會議名稱 
(中文)第一屆儀器、測量、計算機、通信和控制國際會議 
(英文) The First International Conference on Instrumentation, 
Measurement, Computer, Communication and Control (IMCCC 2011) 
發表題目 
(中文) 行為辨識使用運動歷史影像的方向梯度長條圖 
(英文) Human Action Recognition Using Histogram of Oriented Gradient 
of Motion History Image 
國科會補助專題研究計畫出席國際學術會議心得報告 
                                 日期： 102  年 7 月 24日 
                                 
一、 參加會議經過 
第五屆信息技術融合和服務國際會議  (International Conference on Information Technology 
Convergence and Services ( ITCS 2013 ))是由日本福崗工業大學所主辦的。會議舉辦時間為 7月 8至 10
日，地點在日本的北九州福岡市。本次會議論文著重在信息技術融合和服務的發展趨勢，並提供一
個給參加學者在不同面向可以分享見解、經驗和互動的論壇，相互討論關於電腦科學、資訊技術、
信息技術融合和服務的新興技術與專利。會議提供了最好的機會，將分別來自學術界和工業界的學
生、研究人員和從業人員匯聚一堂。在這個會議得與許多國際學者交流很高興能與多位專家學者交
換心得，對於未來的研究頗有助益。 
二、 與會心得 
這次的 ITCS 2013會議中，大會提供了議事手冊及論文 CD 片，供與會者迅速了解論文內容概
況。在會議第二天的 conference dinner，大會選在福岡火車站附近的一間飯店舉辦，同時與當地
的學生們同桌，透過互相交流，對目前相關領域的發展有更深入的了解，也度過一個愉快而充實
的夜晚。 
三、 發表論文全文或摘要 
Abstract  
    This paper presents a human action recognition algorithm using a depth image. First, 3D coordinates 
of the body’s joints of each frame are generated from the depth image. Then, the proposed method 
applies normalization and quantization processes to the body joints of all frames of the action video to 
obtain a 3D histogram. The histogram is projected onto xy, xz, and yz plans sequentially and combined 
into a one-dimensional feature vector. For dimension reduction, the principal component analysis (PCA) 
technique is applied to the feature vector to generate an action descriptor. To further improve the 
recognition performance, a decision tree method is developed to divide input actions into four main 
計畫編號 NSC 99－2632－E－130－001－MY3 
計畫名稱 廣播球拍類型運動視訊分析 
出國人員姓名 謝朝和 
服務機構
及職稱 
銘傳大學 資傳系 教授 
會議時間 
102年 7月 8日至 
102年 7月 11日 會議地點 日本福岡 
會議名稱 
(中文) 第五屆 FTRA信息技術融合和服務國際會議 
(英文) International Conference on Information Technology Convergence 
and Services 
發表題目 
(中文) 利用深度圖之人體動作辨識 
(英文) Human Action Recognition Using Depth Images 
國科會補助專題研究計畫出席國際學術會議心得報告 4/6 
日期： 100  年 10 月 26日 
                                 
一、參加會議經過 
第一屆儀器、測量、計算機、通信和控制國際會議 (The First International Conference on 
Instrumentation, Measurement, Computer, Communication and Control (IMCCC 2011)是由中國哈爾濱
工業大學所主辦的，協辦單位有信息系統安全技術重點實驗室(National Key Laboratory of Science 
and Technology on Information System Security)、電子和電信工程師學會(IETE)哈爾濱分会、北京分
会及北京郵電大學(Beijing University of Posts and Telecommunications)等。會議舉辦時間為 10月 20
至 23日，地點在中國北京的温都水城（Hot Spring Leisure City）。 
本次會議論文著重在儀器、測量、計算機、通信和控制的發展趨勢，並提供一個給參加學者
在不同面向可以分享見解、經驗和互動的論壇，相互討論關於電腦科學、資訊技術和儀器、測量
的新興技術與專利。會議提供了最好的機會，將分別來自學術界和工業界的學生、研究人員和從
業人員匯聚一堂。會議論文將由 IEEE 出版，並為 EI資料庫收錄。此次發表一篇論文，報告時段
被安排在 10/22 的 15:30-17:10，得與許多國際學者交流。並利用會議空檔體驗一下北京之氣候、
地形與人文的差異。會議結束搭乘 10/24中午 12:45直飛桃園的班機返台。此次參加研討會，很高
興能與多位專家學者交換心得，對於未來的研究頗有助益。 
二、與會心得 
這次的 IMCC 2011會議中，大會提供了議事手冊及論文 CD 片，供與會者迅速了解論文內容
概況。在會議第二天的 conference dinner，大會選在温都水城餐廳舉辦，同時被安排與大會主席及
主講(Keynote speaker)同桌，透過互相交流，對目前相關領域的發展有更深入的了解，也度過一個
愉快而充實的夜晚。 
三、發表論文全文或摘要 
Human Action Recognition Using Histogram of Oriented Gradient of Motion History Image 
計畫編號 NSC 99－2632－E－130－001－MY3 
計畫名稱 廣播球拍類型運動視訊分析 
出國人員姓名 謝朝和 
服務機構
及職稱 
銘傳大學 資傳系 教授 
會議時間 
100年 10月 20日至 
100年 10月 23日 會議地點 中國北京 
會議名稱 
(中文)第一屆儀器、測量、計算機、通信和控制國際會議 
(英文) The First International Conference on Instrumentation, 
Measurement, Computer, Communication and Control (IMCCC 2011) 
發表題目 
(中文) 行為辨識使用運動歷史影像的方向梯度長條圖 
(英文) Human Action Recognition Using Histogram of Oriented Gradient 
of Motion History Image 
 國科會補助專題研究計畫出席國際學術會議心得報告 6/6 
                                 日期： 102  年 7 月 24日 
                                 
一、 參加會議經過 
第五屆信息技術融合和服務國際會議  (International Conference on Information Technology 
Convergence and Services ( ITCS 2013 ))是由日本福崗工業大學所主辦的。會議舉辦時間為 7月 8至 10
日，地點在日本的北九州福岡市。本次會議論文著重在信息技術融合和服務的發展趨勢，並提供一
個給參加學者在不同面向可以分享見解、經驗和互動的論壇，相互討論關於電腦科學、資訊技術、
信息技術融合和服務的新興技術與專利。會議提供了最好的機會，將分別來自學術界和工業界的學
生、研究人員和從業人員匯聚一堂。在這個會議得與許多國際學者交流很高興能與多位專家學者交
換心得，對於未來的研究頗有助益。 
二、 與會心得 
這次的 ITCS 2013會議中，大會提供了議事手冊及論文 CD 片，供與會者迅速了解論文內容概
況。在會議第二天的 conference dinner，大會選在福岡火車站附近的一間飯店舉辦，同時與當地
的學生們同桌，透過互相交流，對目前相關領域的發展有更深入的了解，也度過一個愉快而充實
的夜晚。 
三、 發表論文全文或摘要 
Abstract  
    This paper presents a human action recognition algorithm using a depth image. First, 3D coordinates 
of the body’s joints of each frame are generated from the depth image. Then, the proposed method 
applies normalization and quantization processes to the body joints of all frames of the action video to 
obtain a 3D histogram. The histogram is projected onto xy, xz, and yz plans sequentially and combined 
into a one-dimensional feature vector. For dimension reduction, the principal component analysis (PCA) 
technique is applied to the feature vector to generate an action descriptor. To further improve the 
計畫編號 NSC 99－2632－E－130－001－MY3 
計畫名稱 廣播球拍類型運動視訊分析 
出國人員姓名 謝朝和 
服務機構
及職稱 
銘傳大學 資傳系 教授 
會議時間 
102年 7月 8日至 
102年 7月 11日 會議地點 日本福岡 
會議名稱 
(中文) 第五屆 FTRA信息技術融合和服務國際會議 
(英文) International Conference on Information Technology Convergence 
and Services 
發表題目 
(中文) 利用深度圖之人體動作辨識 
(英文) Human Action Recognition Using Depth Images 
國科會補助計畫衍生研發成果推廣資料表
日期:2013/10/17
國科會補助計畫
計畫名稱: 廣播球拍類型運動視訊分析
計畫主持人: 謝朝和
計畫編號: 99-2221-E-130-011-MY3 學門領域: 視訊與影像分析
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
