from a video acquired with a still camera. 
Temporally, moving objects provide occluding 
information about the scene, thus we can reconstruct 
the relative depth based on the occluding cue between 
objects. The second scheme is developed with a multi-
focused image sequence where a number of images are 
acquired with varying focussettings. Based on the 
focus measurement, we can reconstruct the 
corresponding depth image. We expect that the depth 
images wilt be useful for advanced image editing. 
英文關鍵詞： image enhancement, matting Laplacian, tone 
reproduction, 3D depth reconstruction, multi-focus 
 
settings. Based on the focus measurement, we 
can reconstruct the corresponding depth image. 
We expect that the depth images wilt be useful 
for advanced image editing. 
 
Keywords: contrast enhancement, matting 
Laplacian, tone reproduction, depth 
reconstruction, multi-focus. 
 
1. 簡介 
1.1 自動色調重建 
在一般攝影過程，曝光亮度是影響所得影像之
品質關鍵因素，過暗或是過亮的影像都會造成
影像對比及細節之損失，本研究所提出之演算
法透過區域性之 gamma 調整，改善影像亮度
偏差問題，增強色彩飽和度，同時提昇影像局
部對比及細節。 
本篇論文所提出的 gamma 調整技術主要會根
據影像本身亮度自動進行調整，其核心概念在
於將影像亮度值經過 gamma 重新調配至適當
之亮度。在[1]中，其作者提出區域性 gamma
調整增強影像對比之技術，本研究主要以其概
念為基礎發展。而當中調整之 gamma 必須符
合影像內容進行一致性的調整，否則容易出現
調整後的瑕疵問題，如對比增強常見的光暈問
題，或是高對比衰減問題。為了讓估算之
gamma 配合影像內容，我們採用 Matting 
Laplacian (ML)作為估算 gamma 的核心基礎。
ML 是由 Levin 等作者於[2]所提出解決自然影
像去背問題，當中他們建立影像像素點間的關
聯性作為前景背景資訊分離的依據，而像素的
關聯性會建立於 ML 中。 
在本研究中，由於亮度調整必須考量影像像素
之間的關聯性進行一致性調整，以避免產生調
整瑕疵問題，在此我們便以 ML 作為基礎進行
整張影像之 gamma 估算，以此所估算之
gamma 能夠密切貼合影像內容，可有效改善亮
度問題並增強影像對比，同時避免瑕疵。 
另一方面，為了提升處理效能，我們利用影像
像素點相似特質發展一套 cell-based matting 
Laplacian，事先將影像像素進行群聚分類，將
多像素點整合為 cell 之後再針對 cell 進行估
算，藉此省略大量的運算，最後只需再將像素
所對應的 gamma 值透過 cell 進行還原估算即
可獲得高解析度的調整影像。 
1.2 影像深度估算 
針對深度估算我們提出兩套系統架構，第一種
系統架構主要針對視訊影片估測場景深度，固
定攝影機拍攝一段影片之後利用影片中物體
移動後的遮蔽關係判斷影片中物體的相對深
度。此外，我們會採用 Hoiem 在[6]所提出的
單張影像深度估計演算法，與我們透過時間軸
分析遮蔽性的方法結合，提供更準確的深度估
測結果。 
另一方面，我們針對多重對焦影像發展一套深
度估測演算法，此方法利用單台相機調整不同
對焦深度，拍攝多張不同對焦影像。再透過對
焦程度分析影像中各物件聚焦對應深度，然而
由於影像內容常出現不易對焦物件表面而造
成估測上的誤判。為了克服這樣的問題，我們
提出一套全域最佳化演算法，此最佳化主要是
以事後機率最大化模型為基礎。在此機率模型
中，由於影像深度有著空間上連續的特質，因
此我們採用 ML 建立後述機率中的事前機率
模型。為了降低運算複雜度，我們也採用了
cell-based ML 估算全域最佳解，再透過內插計
算取得高解析度深度影像。 
 
2. 自動化色調調整 
( ) ( ) .11
),(
),(|
1
3∑
∈
−
⎟⎟
⎟
⎠
⎞
⎜⎜
⎜
⎝
⎛
⎟⎟⎠
⎞
⎜⎜⎝
⎛
−⎟⎟⎠
⎞
⎜⎜⎝
⎛ +Σ−+
=
kwjik
kj
k
k
T
ki
k ww
ji
µεµ IUI
A
 
(4) 
而 degree 矩陣 D 為一對角矩陣，定義如下 
∑
=
=
N
j
jiii
1
),(),( AD
 
(5) 
而式(3)後半之平滑項可進一步拆解為 
∑ −=
ji
sss
T
s jiji
,
2)()(),( YYALYY
 
(6)
當影像像素相近 A(i,j)值較大，則會抑制 Ys
之變動量，透過最小化(3)可以找到較佳之平滑
影像，其解如下所示。 
.~)( ssY YYUL λλ =+  (7)
取得 Ys 之後，我們根據此平滑亮度定義其對
應之平滑 gamma map 如下 
( )
( ) .),(log
log),( 0s yxY
Yyx
s
=γ
 
(8) 
接著我們定義用來重塑亮度影像的 gamma 
map γshaped，此 γshaped 之定義主要是將 γb
中關於影像細節的部分扣除，根據[2]所提出的
gamma map 處理發現，當扣除 gamma 中的細
節會使所轉換出的影像細節對比增強。 
( )( ),),(),(,0max ),( detailed1bshaped yxcyxyx γγγ −= (9)
).,(),(),( where sbdetailed yxyxyx γγγ −≡   
而最後調整所用之 gamma 定義如下 
),()1( ),( shaped0 yxwwyx γγγ +−=  
(10)
其中 w 為控制調整程度之參數，當 w=1 則影
像調整將會採用 γshaped 重塑影像亮度，而當
w=0 則不會進行調整，其中 γ0=1。最後我們
將輸入影像轉至 HSV 色彩空間後，將亮度值
透過 gamma 調整取得輸出影像之亮度值
Youtput  
),(),( ),( yxoutput yxYyxY
γ=  (11)
再轉回 RGB 色彩空間即可獲得輸出結果。 
 
2.3高效能運算架構 
在前一小節中，我們為了估算平滑亮度影像採
用了採用全域最佳化的方式，然而此方法是將
整張影像像素點同時考慮，運算量過高，不利
於一般應用。為了降低運算複雜度，我們提出
一套高效能運算方法，此方法主要利用影像相
鄰像素之相似性，將相似之像素點群聚成為
cell，而整個最佳化運算將從原始的像素為基
礎的計算轉化為以 cell 為基礎的計算方式。由
於 cell 的數目通常遠小於像素數目，運算量可
大幅降低。 
為了降低運算量並維持影像細節表現，我們將
影像轉至一高維度空間，此空間由影像空間域
與色彩域所構成。在此空間中，我們採用網格
進行降取樣，在同一個網格點中的像素將會共
同以 cell 表示。建立了像素轉換至 cell 之對應
關係之後，我們便可針對 cell 進行最佳化亮度
估算，如下式所示 
.)( cccYc YYΛL λλ =+  (12)
其中 Lc 為 cell 所對應的 matting Laplacian，它
是由原始像素之 ML 矩陣經過 pixel-to-cell 轉
換矩陣 m 之壓縮所得，如下所示 
.LmmL Tc =  (13)
透過式(12)所估測之 Yc 為 cell 所對應的亮度
值，我們進一步採用內插方法便可還原出高解
析度影像之平滑亮度影像。這樣的處理架構可
有效將原本最為複雜的最佳化運算以較低運
算的方式達成。 
2.4實驗結果 
我們將所提出之演算法套用至自然影像進行
調整，我們針對拍照環境亮度動態對比過高之
情況，如圖二所示，畫面同時出現過亮及過暗
之內容。我們比較現存相似演算法與我們所提
出的方法結果比較。對於過亮的部分，傳統方
所示，他們利用影像分割的邊界，再透過機器
學習判斷區塊間的前後關係，藉此建立相對深
度圖。然而單張影像估測深度的準確性與穩定
度仍然是相當困難，常會因為影像內容不同而
有可能發生誤判， 
 
因此在本計畫中，我們提出一套針對靜態攝影
機，拍攝一段累積時間的影片，透過畫面中移
動物體與場景物體互相遮蔽的現象，建立出分
割遮蔽 
物件的邊界，再與[6]的單張影像深度估測演算
法結合，提供較穩定的效果。 
 
圖四、Hoiem在[6]中所採用的多重分割。 
 
 
圖五、Hoiem在[6]中所得到的物件分割與深度
估測結果。 
本演算法採用固定攝影機拍攝一段時間，建立
場景的深度影像，我們以圖六進行說明本系統
的主要概念，圖六上列影像，中間影像出現一
車被中間的樹幹所遮蔽，而車子遮蔽後方的建
築與馬路，因此提供了樹木與後面背景的前後
資訊。圖六下列影像中，中間影像出現了一個
行人遮蔽了中間的樹幹，因此可以判斷樹幹與
行人走過路線的前後關係。我們便是利用這種
隨著物件移動產生的遮蔽特質判斷遮蔽邊
界，提供相對深度分析時所需要的資料。 
 
圖六、場景移動物件遮蔽特性說明。 
 
圖七、遮蔽物分析。 
 
針對同一場景拍攝一段時間後，我們分析隨著
時間經過的物件接地點位置統計值，當畫面中
出現遮蔽物件，如圖七中的樹幹。統計行人走
過的接地點分佈，圖七中紅點因為沒有遮蔽物
出現，因此行人的接地點位置分佈可能會出現
在馬路或是人行道上，呈現兩個可能的分佈統
計區間。相對的，圖七中的藍點落在樹幹上，
因此統計接地點只可能發生在樹幹前的行
人，而不會看到樹幹後的行人，因此分佈圖上
只有單一個分佈區間。我們藉由這樣的分佈關
係判斷出影像的遮蔽物。 
透過這樣的方式，我們可以偵測出遮蔽物件的
分佈狀況，如圖八所示，依此判斷遮蔽物件的
邊界位置，我們將此遮蔽物件的邊界與原始影
像採用硬分割的分割邊界整合，可以取得較穩
定的分割區塊。接著我們再針對這樣的分割區
塊進行深度估算。 
 
3.2.1事後機率最大化之深度重建 
在我們所提出的系統中，我們將深度重建以一
最大事後機率模型表示如下 
{ })(maxarg set* Idpd
d
=
. 
 (14)
上式中 d*為我們所希望取得的深度影像，它
是透過最大化事後機率 p(d|Iset)所取得，其中
Iset 為所拍攝的多重影像序列，d 為深度影像
值。我們會進一步將事後機率模型以貝氏定理
拆解如下 
)()()( set dpdIpIdp set∝
. 
 (15)
其中 p(d|Iset)為可能性機率模型，p(d)為事前
機率模型，我們透過可能性機率模型建立所拍
攝的多重對焦影像與深度影像之關聯性，而深
度影像本身所應有的空間連續性則會被我們
建立於 p(d)。當處理畫面中無紋理的區域時，
由於對焦難以辨別，因此系統會自動地以 p(d)
作為深度估算的考量，利用 p(d)限定深度影像
的空間連續性，有效排除誤判情況。接下來，
我們將分別介紹(15)中所建立的可能性機率模
型 p(d|Iset)與為事前機率模型 p(d)。 
建構可能性機率模型中，我們主要目的是建立
觀測影像與實際深度影像之間的相聯性，我們
首先會將此關聯性定義為觀測深度與實際深
度的關聯性，如下所示 
)~()( set qqqq pp dddI ≡ . 
 (16)
當中我們介紹了 qd
~
表示從多重對焦影像序列
所觀測的深度向量，這個深度會與真正理想的
深度有個偏差，我們將此偏差以 Gaussian 模型
建立如下 
( ) ( )
.~
~~)~(log
),,~()~(
2
1
∑
Ω∈
−
−=
−−≡−
≡
qi
iii
qqq
T
qqqq
qqqqq
dd
p
Np
λ
ddΛdddd
Λdddd
. 
(16)
(17)
(18)
其中每個像素所對應的深度值 di 都有一個自
己所對應的精準度，這樣的設計在於模擬有些
觀測深度可能與實際深度相當貼近，但有些觀
測深度可能由於缺乏表面紋理，很容易受到雜
訊干擾而偏離實際深度值。我們利用這樣的不
確定性來建立觀察值與實際深度的相似可能
性，若影像中出現難以對焦的狀況，此時實際
深度就不會被鎖定在觀察值附近，之後便可透
過實際深度的事前機率模型來估計。 
為了建立事前機率模型，我們提出一套學習機
制，透過局部的多重影像區塊學習深度影像像
素間的關聯性。這個學習主要來自於線性估
測，我們假設影像的深度可以由一些影像的特
徵向量經過線性組合而得，如下所示 
[ ] 0β+= βv Tkikid . (19) 
其中
k
id 表示在第 k 張對焦影像所推測在第 i
個像素位置的深度值，這個深度值是利用像素
本身的特徵向量
k
iv 進行線性組合而得，而β與
0β 分別為線性組合的參數。接著我們再將多
重對焦影像合併出最後的深度值 
[ ]
[ ] ,1
 1
0
0
⎥⎦
⎤⎢⎣
⎡=
⎥⎦
⎤⎢⎣
⎡=
β
β
β
x
β
Vp
i
T
iiid
. 
(20) 
 
(21) 
T
iii Vpx = where . 
(22) 
其中 pi = [
1
ip ,… , 
K
ip ]是合併多重影像的對應
機率向量，Vi=[
1
iv ,…, 
K
iv ] 是多重影像的特
維度空間我們建立網格將相似的像素點合
併，可避免單純使用降取樣可能造成影像細節
損失的問題。將影像轉為網格點之後，我們便
將問題轉化為估測網格點的深度值，而最後的
輸出深度影像，則是由像素點與網格點間的內
插運算求得，如此一來，原本最複雜的全域最
佳化深度重建會以網格點為基礎，其運算量遠
小於以像素為基礎的運算。 
 
 
圖十一、基於網格之快速深度估算架構。 
 
為了針對網格點進行深度重建，我們將事後機
率模型改為針對網格點建立如下 
)()()( set gpgIpIgp set∝
 
(33) 
其中 g 為網格點的深度值，同樣地我們分別對
於網格點的可能性機率 )( gIp
set
與事前機率
)(gp 分別建立模型。在建立可能性機率，我
們假設網格點的真實深度與觀測深度之間的
關係以 Gaussian 模型表示 
( ) ( ) ( )ggΛgg −−=− ~~)(log gTset gIp  (34) 
其中 g
~
表示由觀測多重影像所得的網格深度
估計值，此觀測值是將原本從影像的觀測值透
過像素至網格的轉換矩陣 m 所得，如下所示 
∑
∑
=
=
=
=
N
i
j
N
i
i
j
j
jimw
jim
w
1
1
).,(  where
,~),(1~ dg
 
(35) 
其中像素 i 若會被轉換至網格點 j，則 m(i,j)=1
反之 m(i,j)=0。式(34)中的 gΛ 為一對角矩陣，
其中對角元素 ),( jjgΛ 表示網格點 j 觀察深度
與真實深度的準確度，同樣此網格精準度是由
像素點的精確度經過網格轉換而得。 
).,(),(1),(
1
iijim
w
jj
N
ij
g ∑
=
= ΛΛ
 
(36) 
經由式(34)我們可以建立網格點對於觀察深度
值的可能性分佈情況。接著我們再建立網格點
互相間的事前機率模型。這個建立過程與像素
點的學習模型相同，是透過特徵向量的線性組
合預測深度值。首先對於各網格點，我們建立
它所對應的特徵向量，此特徵向量是由網格點
所對應的所有像素特徵向量整合而得 
.),(1
1
∑
=
=
N
i
i
j
j jimw
xφ
 
(37) 
取得了此特徵向量 jφ 之後，我們進一步透過
線性組合預測對應深度 
[ ] .  1
0
⎥⎦
⎤⎢⎣
⎡= β
β
φ jjg
 
(38) 
接著為了建立區塊性的深度預測，我們同樣取
畫面中的區塊進行深度估測如下所示 
⎥⎦
⎤⎢⎣
⎡=
0β
β
Φg qq
 
(38) 
當中向量
T
qwqq gg ],...,[ 1=g 表示在影像區塊 q
中的深度值組合向量，而這些區塊中的像素共
用同樣組合參數。
T
qwqq ]',...,'[ 1 φφΦ = 表示特
徵向量組合的特徵矩陣。而組合參數可透過最
小化估測誤差所得。最後我們可以得到區塊的
 
(a) Multi-focused Image 
Sequence Iset 
(b) High-dimensional 
Space 
fi = [si  xi]T 
(c) Reconstructed 
Depth Image 
(d) Grid Structure in 
High-dimensional Space 
能。這些深度重建方法有助於未來進行影像編
修時的物件分離與調整，影像編修可以透過影
像深度有更多元的處理發展可能性。 
 
 
 
 
5. References 
[1] C. Tseng, S. Wang, and Y. Chen, “Image 
enhancement based on gamma map 
processing,” Proceedings of the SPIE, vol. 
7723, pp. 77230G-77230G-10, 2010. 
[2] A. Levin , D. Lischinski , Y. Weiss, “A Closed 
Form Solution to Natural Image Matting,” Proc. 
ICCV, pp.61-68, 2006. 
[3] J. Tumblin and G. Turk, “LCIS: a boundary 
hierarchy for detail-preserving contrast 
reduction,” In Proc. ACM SIGGRAPH, p.83-90, 
July 1999. 
[4] F. Durand and J. Dorsey, “Fast bilateral 
filtering for the display of high dynamic- range 
images,” In ACM Transactions on Graphics, 
vol. 21, no. 3, pp. 257–266, 2002. 
[5] L. Tao and V. Asari, “Adaptive and integrated 
neighborhood-dependent approach for 
nonlinear enhancement of color images,” J. 
Electron. Imaging 14, 043006, 2005. 
[6] D. Hoiem, A. A. Efros, and M. Hebert. 
“Recovering surface layout from an image,” 
IJCV, vol. 75, no. 1, pp. 151-172, 2007. 
[7] S. K. Nayar and Y. Nakagawa, “Shape from 
focus,” IEEE Trans. Pattern Anal. Mach. Intell., 
vol. 16, no. 8, pp. 824–830, Aug. 1994. 
[8] N. Yokoya, T. Shakunaga, and M. Kanbara, 
“Passive range sensing techniques: Depth from 
images,” IEICE Trans. Syst. Inf. E82D, vol. 3, 
pp. 523–533, 1999. 
[9] T. Aydin and Y. Akgul, “A new adaptive focus 
measure for shape from focus,” in BMVC, 
2008. 
[10] C. Tseng, and S. Wang, “Maximum-a-posteriori 
estimation for global spatial coherence 
recovery based on matting Laplacian,” in IEEE 
International Conference on Image Processing, 
2012. 
 
 
圖十二、影像深度重建結果。 
(a) Image 1 
(b) Result by [9]  (c) Our result 
(a) Image (b) Our result 
圖十三、影像深度重建結果。 
Course 6 : Multivariate Analysis of Imaging and Sensor Data 
其中對我來說較有興趣的為Stereoscopic Display Application Issues, 內容說明3D展示提供
的好處及 3D的應用，並介紹很多 3D的基本概念，對於之後 3D的研究提供很好的方向 
 
第二天的議程中則是包含了許多的議程，例如 3D Applications，Image Classification and 
Recognition, Image Representation, Parallel Systems and Stereo Vision and Application等等，主要
是一些目前真實可以應用到生活上的技術議題，透過這些特別主題的介紹，我得以快速了解
當前業界發展的狀況。當天靠近中午的時候，我口頭報告投稿的 paper，之後的 Q&A也得到
很多寶貴的意見。接近晚餐時間大會提供 3D Theatre會議，播放 3D影片，說明大螢幕 3D的
技術 
 
第三天的議程中的主題主要鎖定在影像品質分析的議題，例如 3D Image Quality，Perceptual 
Image Quality and Image Quality and System Performance等等，都是現今影像品質分析應用中
相當熱門的研究領域。 
 
第四天，大會亦安排許多議題的討論，例如 3D Game，Autostereoscopic Displays，Stereoscpic 
Display，Depth Maps Analysis and 3D Shape Modeling等等，本天的議題偏重在 3D影像展示
與分析 
 
第五天，大會安排許多特定的討論議題，例如3D Analysis, Feature Extraction, Segmentation, 3D 
Compression, Content Understanding and Computer Vision，主要是一些影像資訊擷取的技術，
透過這些特別主題的介紹，我得以快速了解目前最新技術發展的狀況 
 
總結 
此次大會的議題大多與 3D 影像有關係，這也說明未來會有越來越多的技術朝此方向發展，
藉由這次研討會，吸收國外寶貴的知識，有助於之後 3D研究的發展 
 
二、與會心得 
    此次是我第一次到舊金山，對於當地的地理環境及文化皆不熟悉，因此，出發前收集有
關於舊金山的資訊，得知舊金山是一大都市，對於初次到國外的這一個城市，一定要好好的
看看城市的風貌，並且體驗在地的生活，包含如何搭交通，享受當地的文化與食物，感受一
下文化差異的衝擊。 
     
    主辦單位選擇的會議中心，與捷運站有一段距離，需要搭乘飯店接駁車才能到達捷運站，
而到了舊金山市區交通就很方便，四通八達的公車系統，讓我在城市中可以自由的移動，在
舊金山的前幾天雖然都在下雨，但是並不影響我在那享受國外生活的心情，舊金山路上沒有
機車，感覺非常特別，幾乎都是開車或是搭乘交通工具，市區內街道的規劃都非常的好，建
築物都很有自己的特色，讓我覺得生活在這都市裡也是一種享受，直接感受到舊金山真的是
很棒的城市。 
國科會補助計畫衍生研發成果推廣資料表
日期:2012/10/30
國科會補助計畫
計畫名稱: 視訊滌洗、偏好色調調整及場景內容分離萃取
計畫主持人: 王聖智
計畫編號: 98-2221-E-009-110-MY3 學門領域: 影像處理
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
本計畫進行過程中已開發出偏好色調調整技術, 影像色調重建技術, 影像內容
3D 深度估算技術, image matting 技術, 以及數項影像對比加強演算法. 其中
的影像內容 3D 深度估算技術以及 image matting 技術, 正與業界廠商洽談技
轉之可能性.  
 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
