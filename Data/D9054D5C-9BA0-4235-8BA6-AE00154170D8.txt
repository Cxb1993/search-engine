2 
和 ATF 分別以現有的 HRTF 和 ATF 總集用內差的方式求得。最後，在任意位置的虛擬
聆聽點和所選的空間回響環境內展示出具有３Ｄ效果的合成音訊。 
近來立體影像技術已逐漸成為多媒體領域中的研究主流，而自由視點視訊更是其
中的重要議題之一。自由視點的目的是從攝影機陣列所擷取的影像來產生可以任意選
擇虛擬視點的影像訊號。在合成自由視點視訊上主要有兩個步驟:(1)從攝影機陣列所擷
取的影像來重建三維資訊，(2)合成使用者視點所看到的虛擬視訊。現今，大部分的自
由視點視訊系統都專注於一維攝影機陣列所記錄的影像資訊，且研究內容也多以影像
為主，而非視訊。我們希望將研究成果拓展到二維攝影機陣列與影像序列(視訊)上。 
 
關鍵字:輪廓轉換，方向濾波器，平均移動，麥克風陣列，３Ｄ音訊合成，盲訊號源分
離，頭部相關轉移函數，聽覺轉移函數，虛擬聆聽點，立體影像，攝影機陣列，自由視
點，虛擬視訊。 
 
 英文摘要 
This project, Multi-view Video/Audio Representation and Synthesis, investigates the 
multi-view audio-visual data representation and synthesis and their related topics. There are 
three parts in this report: (1) the wavelet-based contourlet transform for image/video coding, 
(2) the 3D virtual listening point audio synthesis, and (3) free viewpoint video of stereo im-
age. 
Wavelet transform can represent 1-D signal well but fails to present 2-D signals well. 
Some researchers provide new transforms to provide multiresolution directional transform, 
such as wavelet-based contourlet transform, for 2-D signals. The original structure of wave-
let-based contourlet transform applies directional transform to all high-pass subbands except 
final LL (horizontal low-pass, vertical low-pass). Our experimental results show that it is not 
suitable to apply directional decomposition to all high pass subbands, some directional de-
composition has no improvement for compression. In this research plan, we propose a 
mean-shift-based decision method to decide which high-pass subband is suitable for direc-
tional decomposition. 
The 3D acoustic signal synthesis can be divided into two key steps. The first step is to 
estimate the individual source signal from the mixed, recorded signals. This step is usually 
accomplished by using the blind source separation (BSS) technique. The second step is to 
synthesize a 3D acoustic signal at a virtual listening point in a chosen reverberant room envi-
ronment. The 3D feeling of an acoustic signal can be enhanced by filtering the separated sig-
nals in step one by the head-related transfer function (HRTF) and the acoustic transfer func-
tion (ATF), which represents the room acoustic effect. We adopt the frequency domain inde-
pendent component analysis (FD-ICA) and a least-square optimization approach to separate 
the mixture signals. We investigate the effectiveness of the BSS methods by evaluating their 
4 
報告內容 
第一部份  可調整式以小波轉換為基礎的輪廓轉換的影像編碼 
A.  前言 
小波轉換(wavelet transform)對一維(one dimensional)的訊號具有良好的表示效果是
因為其所擁有的較佳的非線性表示法(non-linear approximation)特性，但是它把二維訊
號拆解成兩個一維小波轉換的張量積(tensor product)來表示，也因此會忽略了二維上的
連續性，故對二維的表現效果並不好。後來有不少研究者提出了數種多重解析度方向
性濾波器頻帶 (multiresolution directional filter bank)的轉換，如方向調整小波轉換
(direction-adaptive wavelet transform)和輪廓轉換(contourlet transform)等來提供二維訊號
多重解析度方向性表示法。輪廓轉換因為使用了拉氏金字塔(Laplacian pyramid)造成資
料量的增加，故有人改用二維小波轉換來取代拉氏金字塔，此新架構稱為以小波轉換
為基礎的輪廓轉換(wavelet-based contourlet transform，WBCT)，但因為此轉換的架構
中，除了最後的 LL(水平方向低通(horizontal low-pass)，垂直方向低通(vertical low-pass))
次頻帶(subband)外，其他的高通的次頻帶都會作方向性拆解(directional decomposi-
tion)，但我們的實驗結果發現並非每一個高通次頻帶都適合作方向性拆解，尤其是拆
解後對壓縮上並沒有幫助。本研究計畫主要是針對以小波轉換為基礎的輪廓轉換
(wavelet-based contourlet transform)設計一套以平均移動(mean shift)為基礎的判斷方法來
決定那個高通次頻帶適合作方向性拆解。 
B.  研究目的 
因為小波轉換所擁有的極佳的非線性表示的特性，故小波轉換對一維的訊號的表
示有不錯的效果，也因此很適合用在一維訊號處理上，如壓縮方面。但二維小波轉換
是採用兩個一維小波轉換相量績，也因此會忽略了二維訊號的連續性，故二維小波轉
換對二維訊號的處理並不理想。也因此尋找可以提供多重解析度的方向性轉換是個目
前，也有不少研究人員提供了新的方法。Minh N. Do[1]提出了輪廓轉換這種考慮方向
性的多重解析度表示方法來建立新的二維訊號表示方法，而且其擁有對二維訊號的較
佳的非線性表示法。但輪廓轉換使用了拉式金字塔[2]造成了資料量的增加，故後來
Eslami和Radha使用了二維小波轉換取代拉式金字塔來達成多重解析度分析，稱為以小
波轉換為基礎的輪廓轉換[4]。但其基本架構卻把所有的高通次頻帶都作了方向性的拆
解，而我們的研究結果發現，並不是所有的高通次頻帶都適合作方向性拆解的，有的
時候作了方向性的拆解在壓縮上並沒有幫助，反而變得更差，故我們決定設計一套判
斷方法來判斷高通頻帶是否適合做方向性的拆解。 
6 
D.  研究方法 
能量頻譜修正 
LL
LH
4-0
LH
4-0
LH
4-1
LH
4-1
LH
4-2
LH
4-3
LH
4-2
LH
4-3
HH
4-0
HH
4-0
HH
4-2
HH
4-2
HH
4-1
HH
4-1
HH
4-3
HH
4-3
HL
4-1
HL
4-1
HL
4-3
HL
4-3
HL
4-2
HL
4-2
HL
4-0
HL
4-0
pi/2
1 129 257 385 513
pi
0
-pi/2
-pi
-pi -pi/2 0 pi/2 pi
1
129
257
385
513
水平座標軸 x
水平頻率 Fx
垂
直
頻
率
垂
直
頻
率
垂
直
頻
率
垂
直
頻
率
Fy
垂
直
座
標
軸
垂
直
座
標
軸
垂
直
座
標
軸
垂
直
座
標
軸
y
257
1
258259 383384385
1
2
3
127
128
129
(a) (b)
4
126
260 382
低頻成份
垂
直
座
標
軸
垂
直
座
標
軸
垂
直
座
標
軸
垂
直
座
標
軸
y
水平座標軸 x
 
圖 2. .(a)以小波轉換為基礎的輪廓轉換的個各方向次頻帶(directional subband)在頻域
(frequency domain)的座標，中間的灰色部份是低頻成份。方向性次頻帶 LH 4-0 表示把
小波轉換後的 LH 次頻帶通過方向性濾波器的 4-0 次頻帶(如圖 1 所示)所得到的次頻
帶。(b)方向次頻帶 LH 4-0 的上半部的座標軸。 
把一張 512×512 的灰階(gray level)影像經過二維不連續富利葉轉換(2-D discrete 
Fourier transform)後可得到其頻譜(sprectrum)，頻譜為 512×512 個複數係數(complex 
coefficients)所組成，然後把直流部份(zero frequency)移到中間後，對每個係數取絕對值
(absolute value)並且平方後得到其能量，並把最上面一列(row)的係數複製到最下面，最
左邊一欄(column)的係數複製到最右邊，修正完成後可得到 513×513 大小的能量頻譜
(energy spectrum)，因為使用的影像在空間域(spatial domain)為實數，故此能量頻譜為
對稱(symmetric)且具週期性(periodic)。因為此能量頻譜含有許多小的能量波峰，我們
使用一個 3×3 大小，且全部系數都為 1/9 的平坦化運算子(smoothing operator)來作二維
連乘積(2-D convolution)，如此可消去許多小的能量波峰，並可使大的能量波峰更明
顯。圖 2(a)表示修正後的以小波轉換為基礎的輪廓轉換的能量頻譜的個各次頻帶的座
標軸。一般的能量波峰必須要大於某個門檻，而此門檻有兩種，一種是低頻(low fre-
quency)訊號的能量大小，另一種是個方向次頻帶內部的能量大小。 
低頻訊號部份的門檻 
我們先把所有的能量係數取 log10，然後來計算低頻部份的平均值當低頻成份的門
檻。 
129 258
1 256
( , )
_
3 129
y x
c x y
LH low = ==
×
∑ ∑
                         (1) 
258 129
256 1
( , )
_
3 129
y x
c x y
HL low = ==
×
∑ ∑
                         (2) 
其中 c(x, y)是能量系數取 log10之後的值。只要 LH_low 或 HL_low 兩個參數中，其
8 
的收斂點的位置累加 1。然後我們重覆此步驟直到所有比門檻大的能量係數都處理完
畢。 
使用式子(3)的範圍定義如下，假設現在是在尋找LH次頻帶底下的方向次頻帶，圖 
2(a)中表示的 LH 次頻帶的位置為 129≤x≤385 和 1≤y≤129，我們修改其範圍為
(129-5)≤x≤(385+5)和(1-5)≤y≤(129+5)，因為所用的影像皆為實數(real)且分離(discrete)
的，故頻域(frequency domain)的訊號為周期性(periodic)且對稱的，所以 y=1 這行(row)
的能量係數跟 y=513 這行是一樣的，故垂直座標軸的左邊分界點修正為 1-5+512。 
因為移動平均並不見得都會收斂到同一點，故計分板上的所得到的結果還要再作
修正。假設計分版上某個結果 d(x, y)≧10 且 d(x, y)是以 d(x, y)的 3×3 的視窗內最大的，
我們在此 3×3 的視窗內找出其他≧10 的係數並把它們和 d(x, y)加起來並得到 dsum(x, y)，
之後我們把 d(x, y)換成 dsum(x, y)並把其他 8 個係數都設成 0。再最後經過修正的計分板
上，只要某個 dsum(x, y)≧10 且其不在低頻成份的收斂範圍內(convergence of low fre-
quency component)內，此範圍為(254≤x≤260 和 1≤y≤129)或(1≤x≤129 和 254≤y≤260)，則
此小波轉換次頻帶判斷為適合作方向拆解。 
E.  結果與討論 
表示的是不同影像的測試結果，我們可以發現只有很少數的影像的高通次頻帶適
合作方向性拆解。我們把影像經過3次的二維小波轉換後，然後把高通次頻帶作方向性
拆解，並使用[7]的編碼來作壓縮(標示為 DT(使用放向性拆解的高頻訊號))，並和
JPEG2000 作比較。 
表 1. 不同的測試影像的判斷結果。 
LH HL HH
位置
(x, y)
計分板
最大值
方向性
拆解
位置
(x, y)
計分板
最大值
方向性
拆解
位置
(x, y)
計分板
最大值
方向性
拆解
Baboon (257,1) 1 N 0 N (44,453) 7 N
Barbara (213,126) 1 N (130,366) 102 Y (92,384) 8 N
Fingerprint (257,129) 3 N (128,200) 11 Y 0 N
Lena (154,121) 6 N (122,259) 2 N (129,390) 1 N
Pepper 0 N 0 N (32,24) 13 Y
Boat 0 N (118,259) 11 N 0 N
Bridge 0 N 0 N 0 N
Couple (236,96) 2 N (109,259) 11 N 0 N
Elaine (177,123) 88 Y (107,212) 55 Y (83,32) 160 Y
Goldhill 0 N (69,255) 9 N 0 N
Harbour (246,27) 3 N 0 N 0 N
Man (226,120) 2 N (121,255) 7 N 0 N
小波轉換
次頻帶
測試
影像
 
10 
 
圖 5. 使用不同方法壓縮 Elaine 的 PSNR。 
Original DT(HH HL LH) JPEG2000
 
圖 6. 在 0.5bpp(bit per pixel)下用不同的壓縮法重建後的 Barbara。 
從表 1 可以發現 Elaine 是全部的高通次頻帶都適合作方向性的拆解，而圖 5 所示
其 PSNR比 JPEG2000 好得多，圖 6是在 0.5bpp下的重建的結果，可以發現使用方向性
的拆解時，可以針對原本影像中，類似花紋的訊號(texture-like pattern)有很好的重建效
果。 
第二部份  虛擬聆聽點的 3D 音訊合成 
A.  前言 
本研究計畫的目標之一是為了在無原始麥克風錄音訊號的虛擬聆聽點上合成出 3D
音訊。為了達到這個目標，我們在空間中佈置麥克風陣列用以進行音源訊號的錄製工
作。３Ｄ音訊合成可分為兩個主要步驟，第一個步驟是由混合的錄製訊號去估測各個
音源訊號，此步驟通常是以盲訊號源分離 (blind source separation, BSS) 的技術來達
成。第二個步驟則是在選定的回響空間內某一個虛擬聆聽點上合成出該點的３Ｄ音
訊。此音訊的３Ｄ空間感可藉由頭部相關轉移函數 (head-related transfer function, 
HRTF) 與代表該點房間回響感覺的聽覺轉移函數 (acoustic transfer function, ATF) 對
12 
[13]，[14]，[15]，[16]，[17]，[18]，[19]，[20]，[21]，則會有不同的適應性學習規則
以及不同的特性。另外，對於高於所求型 (over-determined) 的 BSS 方法，我們通常只
會需要某一部份的子空間 (subspace)，因此可以用主要成份分析法 (principal compo-
nent analysis, PCA) [22] 或是其他的子空間方法[11]，[23]，[24]來求得我們所關注的子
空間。 
至於 3D 聽覺訊號合成的部份，ATF[25]包含了空間脈衝響應 (room impulse re-
sponse, RIR)，描繪出一個回響的空間中，聲源到麥克風的直接路徑以及各個反射所帶
來的效果，因此ATF會隨著所處的房間大小與牆壁材質一同改變。HRTF則是描述了不
同方位的聲音源到左右耳的差異[13]，[26]利用仿真人頭錄音的方式測量出每一組鉛直
方向角φ 、水平方向角θ 和距離 r 到左右耳各別的轉移函數。 
D.  研究方法 
在本計畫中，我們對麥克風陣列訊號進行 3D 音訊合成，如圖 7 與 
圖 8所示，主要分為兩個部份：盲訊號源分離與 3D 聽覺訊號合成，分別如以下所
述： 
 
圖 7. 麥克風陣列示意圖。 
 
圖 8. 3D 音訊合成示意圖。 
14 
 
圖 10. 使用分離訊號作 3D 聽覺訊號合成之演算法流程圖。 
E.  結果與討論 
表 2. 各組訊號源編號與其內容簡述。 
 
我們所使用的 5 組麥克風陣列訊號如表 2 所示，每個聲源訊號的長度約為 6.8 秒。
我們用訊號干擾比 (signal-to-interference ratio, SIR) 來評估對 BSS 的分離矩陣的效果，
SIR 的數值愈高，表示分離的效果愈好，如在無回響的條件下，不同訊號源的分離效果
比較。在有回響的條件下，不同訊號源的分離效果比較。圖 11，圖 12及圖 13所示。
對於第 i 個分離訊號的 SIR 的計算方式是以「只播放第 i 個聲源訊號時，第 i 個分離訊
號的功率大小」做為分子，而以「播放其他聲源訊號時，第 i 個分離訊號的功率大小總
和」為分母所得到的比值。 
16 
我們可以從圖 13 得知，在無回響的環境底下所得到的分離效果比有回響的情況的
SIR 數值約略高出 12 dB 左右，這個現象主要是因為回聲會擾亂聲源訊號之間彼此獨立
的特性，而造成 SIR 數值的降低。 
至於第 5 組麥克風陣列訊號「wistru」，兩個聲音源 SIR 數值是 5 組當中差距最大
的一組，如圖 11 和圖 12 所示。這主要是因為兩個聲音源的原始功率較大，因此以此
二聲源訊號錄製的麥克風陣列訊號進行分離，各別得到的 SIR 數值就會有較大的差
距，然而，在兩個聲音源的情況底下，其平均的 SIR數值與其他 4組相近，這是因為兩
個聲源訊號的功率差距會在平均 SIR 數值的計算過程當中互相抵消，也就表示說平均
SIR 的數值只會反應出分離矩陣本身的效果，而與聲源訊號的功率無關。 
(a) (b)
(c) (d)
 
圖 14. 不同條件底下的 ATF 頻率響應：(a)無回響、(b)小房間、(c)中房間、(d)大房
間。 
在不同的回響環境底下，同一組測量點所得到的 ATF 頻率響應會有明顯的差異。
如圖 14 所示，我們可以觀察得知：愈大的房間，其頻率響應的振盪就愈快速，這是因
為當多個回聲反射至虛擬麥克風時，在頻率響應上會產生振盪項，與直接路徑相比的
時間差愈長，其振盪項會愈加迅速，反應在頻譜上則是更加密集的變動，如圖 14(d) 
所示。 
經過HRTF的濾波之後，所得到左右聲道的振幅大小與時間差異會因聲源所在的方
位與距離而決定，如圖 15 所示，當聲源在左前方 45 度角的時候，左聲道的音量明顯
大於右聲道；同理可推，當聲源改為在右前方 45 度角時，右聲道的音量也會比左聲道
18 
我們的麥克風陣列錄音空間是在 NASA SLAB 的聲訊合成模擬軟體[33]上取得，其
簡易的情境描述如表 4所示，房間的形狀為矩形，6個反射面可選擇不同的材質，反射
面是只會計算第一次的反射，所以回聲不會造成再一次的反射。 
第三部份  立體影像之自由視點視訊的研究 
A.  前言 
近來立體影像技術已逐漸成為多媒體領域中的研究主流，而自由視點視訊更是其
中的重要議題之一。自由視點的目的是從攝影機陣列所擷取的影像來產生可以任意選
擇虛擬視點的影像訊號。在合成自由視點視訊上主要有兩個步驟:(1)從攝影機陣列所擷
取的影像來重建三維資訊，(2)合成使用者視點所看到的虛擬視訊。現今，大部分的自
由視點視訊系統都專注於一維攝影機陣列所記錄的影像資訊，且研究內容也多以影像
為主，而非視訊。我們希望將研究成果拓展到二維攝影機陣列與影像序列(視訊)上。 
B.  研究目的 
近年來由於硬體以及相關演算法的進步，單一視點視訊技術已達成熟；而隨著三
維顯示技術的發展，多重視點視訊已逐漸成為多媒體領域下一個階段的研究重心。
MPEG 在 2003 年 11 月的會議中，正式制定了 3DAV(3D Audio-Video)文件[34][35]，其
主要目標是擴展現有的視訊標準，其內容包含了三項多重視點視訊的主要應用：自由
視點視訊(Free Viewpoint Video)、全景視訊(Omni-directional Video)、與互動式立體視訊
(Interactive Stereo Video)，其中的自由視點視訊即為本計劃主要研究主題。自由視點視
訊的目是使用有限的影像擷取設備來精確描述三維空間中的場景資訊，並能有效地壓
縮所紀錄的資訊。當呈現時，能夠即時合成出任意視點所見的畫面。 
傳統自由視點視訊系統大多使用一維攝影機陣列來擷取影像[36]，這使得視點位置
僅能在一個平面上移動。為了將移動的範圍延伸到立體空間上，我們將一維攝影機陣
列拓展為二維攝影機陣列。自由視點視訊系統在進行影像內插時，為了增加其準確度
會搭配視差(disparity)資訊作為參考。基於二維攝影機陣列的特殊結構以及視差圖的平
移特性，我們提出一套適合二維攝影機陣列的視差估測方法。此外，我們同時也參考
了移動向量資訊來降低在視訊上進行視差估測的時間，以實現在二維攝影機陣列上的
自由視點視訊。 
C.  文獻探討 
一個典型的自由視點視訊系統包含了五種程序：影像擷取、場景成像(rendering)、
壓縮、資料傳輸、以及顯示。其中場景成像為最複雜的程序，亦是整個系統的核心。
場景成像主要分為兩類： 
(1)model-based rendering(MBR) 
MBR 主要是利用物體模型投影到成像平面上而成。理想的 MBR 可以達到完美的自
20 
考影像的位置不同，因遮蔽效而在視差圖上出現的 occlusion 區域也會跟著改變。因
此，我們採用投票的方式從四個不同方向得到的視差圖中來決定最後的結果。我們分
別測試了三種不同的投票方式:視窗和掃描線方向無關、視窗和掃描線方向相同、以及
視窗和掃描線方向垂直，而從測試結果中可以發現視窗和掃描線方向垂直的視差圖結
果最為理想，因此我們採用此種視窗作為決定單一影像視差圖的投票機制，如圖 16。
其中的數字代表視差值，X 表示該點為 occlusion；綠色虛線標記的區域為掃描線方
向，紅點為當前要決定視差值的位置，而紅色標記區域為視窗範圍。 
 
圖 17. 一維攝影機陣列虛擬視點影像合成流程。 
Synthesizing
Virtual images 
and disparity 
maps in 
horizontal 
direction
Disparity maps
Synthesizing
Virtual images in 
vertical direction
Virtual viewpoint 
image
Synthesized
source imagesSource images
Synthesized
disparity maps
 
圖 18. 二維攝影機陣列虛擬視點影像合成流程。 
然而，參考四台攝影機來決定一張視差圖會使得計算時間大量增加。在本計劃
中，我們利用了視差圖的平移特性和二維攝影機陣列的特殊結構來降低計系統的計算
22 
在自由視點視訊中，我們將重心放在如何降低估測視訊信號視差時的計算量。由
於在一串連續影像中，視差圖之間也會存在著時間上的相關性，因此我們引進了 GoP
的概念，對每個 GoP 的第一張畫面優先進行處理。而剩下的畫面，我們則是參考移動
向量來進行視差估測。對於移動向量和畫面交會的區域，其視差值可以用已知的參考
畫面視差值來進行內插，如圖 19。 
當兩張參考畫面在時間上距離太遠時，會造成移動向量準確度下降。為了提升移
動向量的精確度，在進行移動估測時我們加入了視差資料作為參考，其表示式如下。 
2
, 0 0
2
( , ) arg min [ ( , ) ( , )]
[ ( , ) ( , )]
w w
t t T
x y R k l
t t T
i j D x k y j D x i k y j k
I x k y j I x i k y j kα
+
∈
= =
+
= + + − + + + +
+ + + − + + + +
∑∑
              (4) 
其中 I 為原始影像資訊，D為視差圖資訊。由於視差圖和原始影像之間並非一對一的函
數關係，所以參數α 為一個經驗解。經由實驗測試，我們發現當α 為 0.1 時會是一個較
理想的選擇。 
E.  結果與討論 
 
圖 20. 使用棋盤式視差估測和使用完整視差估測的結果比較。 
使用棋盤視視差估測和每台攝影機都使用完整估測方式在最後虛擬視點影像的合
成結果如圖 20，其中縱軸為平均的 PSNR，橫軸為不同的測試資料，分別代表了五種不
同的物體運動行為。Monkey-Translation 為物體平移，Monkey-Rotation 為物體旋轉，
Monkey-Leaving 為物體遠離攝影機 Monkey-Approaching 是體靠近攝影機，而
Monkey-Covering 則是兩個物體互相遮蔽。我們可以發現使用棋盤式視差估測的結果比
完整視差估測的結果來得好，這和一般直觀想法剛好相反。對於這個現象，我們提出了
24 
frame 數量增加，在進行移動估測時的搜尋範圍也會變大，導致搜尋所耗的時間蓋過了
略過 frame所帶來的效益。圖 22是比較不同物體運動行為和參考影像間略過不同 frame
數對於合成結果的關係，可以看出基本上略過 frame 數量越多，起影像品質就會越差。
而對於物體靠近和遠離這兩種運動行為，基本上是不容易受到略過的 frame 數量所影
響。 
 參考文獻 
[1] M. N. Do, and M. Vetterli, “The contourlet transform: an efficient directional decompo-
sition multiresolution image represenation,” IEEE Trans. Img. Proc. vol. 14, issue 12, pp. 
2091- 2106, Dec. 2005. 
[2] P. J. Burt and E. H. Adelson. “The Laplacian pyramid as a compact image code”, IEEE 
Transactions on Communications, vol. 31:4, pp 532–540, April 1983. 
[3] S.-M. Phoong, C. W. Kim, P. P. Vaidyanathan, and R. Ansari. “A new class of 
two-channel biorthogonal filter banks and wavelet bases”, IEEE Transactions on Signal 
Processing, vol. 43:3, pp 649–665, Mar. 1995. 
[4] R. Eslami and H. Radha, “Wavelet-based contourlet transform and its application to im-
age coding,” IEEE International Conference on Image Proc. Oct. 2004. 
[5] D. Taubman, “High performance scalable image compression with EBCOT”, IEEE 
Trans. Image Processing, vol. 9:7, pp. 1158-1170, July 2000. 
[6] J. Xu, Z. Xiong, S. Li, Y, Zhang, “Three-Dimensional Embedded Subband Coding with 
Optimized Truncation (3D ESCOT)”, Applied and Computational Harmonic Analysis 10, 
290-315(2001), doi:10.1006/acha.2000.0345. 
[7] C.–H. Hung and H.–M. Hang, “Image coding using short wavelet-based contourlet 
transform,” IEEE International Conference on Image Proc.(ICIP), San Diego, CA, USA, 
Oct. 2008. 
[8] K. Fukunaga and L.D. Hostetler, “The estimation of the gradient of a density function, 
with applications in pattern recognition,” IEEE Trans. Information Theory, Vol.21, 
p.p.32-40, 1975. 
[9] Y. Cheng, “Mean Shift, Mode Seeking, and Clustering,” IEEE Transactions on Pattern 
Analysis and Machine Intelligence, vol. 17, no. 8, pp. 790–799, Aug. 1995. 
[10] R. Eslami and H. Radha, “A new family of nonredundant transformations using hybrid 
wavelets and directional filter banks,” IEEE Trans. Img. Proc., vol. 16, no. 4, Apr. 2007. 
[11] S. Choi, et al., "Blind source separation and independent component analysis: a review," 
Neural Information Processing - Letters and Reviews, vol. 6, no. 1, Jan. 2005. 
[12] F. Asano, et al., “Combined approach of array processing and independent component 
analysis for blind separation of acoustic signals,” IEEE Trans. on Speech and Audio 
Processing, vol. 11, no. 3, May 2003. 
[13] E. Binghan and A. Hyvarinen, "A fast fixed-point algorithm for independent component 
analysis of complex valued signals," International Journal of Neural Systems, vol. 10, no. 
26 
1995. 
[31] TSP design: http://tosa.mri.co.jp/sounddb/tsp/tsp_design_e.htm. 
[32] An online HRTF database: http://recherche.ircam.fr/equipes/salles/listen/index.html. 
[33] J. D. Miller, “SLAB: a software-based real-time virtual acoustic environment rendering 
system,” in Proc. of the 2001 International Conference on Auditory Display, Espoo, Fin-
land, Jul. 2001. 
[34] Applications and Requirements for 3DAV, ISO/IEC JTC1/SC29/WG11 N5877, July 
2003. 
[35] Report on 3DAV Exploration, ISO/IEC JTC1/SC29/WG11 N5878, July 2003. 
[36] M. Tanimoto, “Overview of free viewpoint television,” Signal Processing: Image Com-
munication, vol. 21, no. 6, pp.454-461, July 2006. 
[37] P. E. Debevec, C. J. Taylor, and J. Malik, “Modeling and rendering architecture from 
photographs: A hybrid geometry- and image-based approach,” in Proc. ACMAnnu. 
Computer Graphics Conf., Aug. 1996, pp. 11–20. 
[38] R. C. Bolles and H. H. Baker, “Epipolar-plane image analysis: A technique for analyzing 
motion sequences,” in Proc. IEEE 3rd Workshop Computer Vision: Representation and 
Control, Bellaire, Oct. 1985, pp. 168-178. 
[39] Baker, H. and R. Bolles, “Generalizing epipolar-plane image analysis on the spatiotem-
poral surface,” in DARPA Image Understanding Workshop, Cambridge, MA. April 6-8, 
pp. 1022-1030. 
[40] S. T. Hsu, Disparity Estimation Using Multiple Images. National Chaio Tung University, 
M.S., 2008. 
[41] T. Naemura and H. Harashima, “Real-Time Video-Based rendering for augmented spa-
tial communication,” Proc. VCIP, vol. 3653, SPIE Press, Bellingham, Wash., 1999, pp. 
620-631. 
[42] N. Grammalidis and M. G. Strintzis, “Disparity and occlusion estimation in mutiocular 
systems and their coding for the communication of multiview image sequences,” IEEE 
Trans. Circuits Syst. Video Technol., vol. 8, pp. 328–344, June 1998. 
[43] Y. Ohta and T. Kanade, “Stereo by intra- and inter-scanline search using dynamic pro-
gramming,” IEEE Trans. Pattern Analysis and Machine Intelligence, Vol. PAMI-7, No. 2, 
pp. 139-154, March, 1985. 
