1 
 
 
 
計畫編號：NSC 96-2221-E-164-011 
執行期限：96年8月1日至97年9月15日 
執行單位：修平技術學院 資訊網路技術系 
計畫主持人：鄭文昌 博士 
 
 
摘要 
智慧化居住空間為近幾年頗受注目的前瞻技術方向之一，而智慧化整合式的安全監控
系統是打造智慧化居住空間中一個重要角色。在此計畫中我們針對智慧化居住空間建置提
出一套智慧化整合式安全監控系統，不同於傳統的安全監控系統，此系統是一種被動式的
監控系統，我們賦予系統智慧化的能力，將被動變成主動角色，此系統能在第一時間主動
發現異狀時提出警告，有效完成智慧化主動式居住空間的安全監控。在此計畫中，我們完
成一套結合 RFID 與人臉辨識的門禁管理系統，對於進出人員進行身分確認工作，合法人
員能自由進出活動，而入侵者則發出警訊；其次入侵者往往不會走正常管道進入，而是透
過非允許的方式進入，例如翻牆進入或爬窗戶侵入，因此我們也完成一套入侵者偵測、追
蹤以及路徑比對系統，此系統以分析人形移動目標之行為為主，因此對於光影變化及其他
非人形移動物體影響可以降低，結合行為分析與人臉偵測、辨識與追蹤技術，作為居住空
間室內與室外之安全事件判斷依據。此外在此計畫中我們也對於多攝影機組的安全監控整
合提出解決的方法，利用相機間座標轉換方式進行相機之間位置的校正，因此系統對入侵
者進行追蹤時，當入侵者欲離開某一攝影機監控範圍時，可以透過預先校正過的轉換參數，
將座標傳遞給就近的其它攝影機進行接替追蹤的動作，如此一來可以避免跟丟的情形發生，
以完成全方位的智慧化居間空間安全監控的目的。 
 
關鍵詞：視訊監控、人臉偵測、人臉辨識、行人偵測、行人追蹤、背景重建、無線射頻辨
識系統 
 
3 
 
化居間空間安全監控的目的。 
二、 研究目的 
此計畫的目的是將針對居住空間的應用提出一套智慧化整合式視訊安全監視系統，整
合居住環境中各種攝影機所取得的視訊資料，建構一個全方位、無死角、且具主動性的安
全監控系統，此系統能夠針對入侵者進行偵測、辨識、追蹤、紀錄以及行為分析，並配合
視訊事件觸發為安全監控提供主動服務。 
三、 文獻探討 
3.1 傳統門禁系統 
一般最常使用的電子式門禁系統有磁卡、條碼和智慧卡三種，磁卡雖然成本低，但是
容易消磁不易保管，且磁卡容易被盜錄，此外磁卡遺失後，因為沒有一個確認機制，以致
無法確認磁卡使用者是否為此磁卡的合法使用者，至於條碼的門禁系統有和磁卡相同的缺
點，且更容易被拷貝，至於智慧卡[1]，雖然他的加解密可以達到很好的防拷效果，但是遺
失後還是一樣沒有確認機制可達到防止盜用的情況，其次不管是智慧卡、磁卡和條碼均屬
於被動式門禁系統，使用者需配合門禁系統讀取設備的建置位置讀取資料完成身份確認，
使用上是相當不方便，改善的方法可改採無線識別標籤(RFID)取代[2-5]。由於 RFID 是利
用無線電波的傳送與接收進行識別碼確認的動作，又分為主動式與被動式兩種電子標籤，
被動式與傳統門禁相同，而主動式 RFID 的電子標籤比起傳統門禁系統有較遠的感應距離，
使用時不需要使用者主動出示電子標籤卡片，只要使用者進入一定區域後，RFID 的讀取器
便能自動進行 RFID 的讀取與身份確認，使得使用上更加方便。至於 RFID 的缺點則是當電
子標籤遺失時，亦有被盜用之問題，因此需要再結合其他的辨識系統以進行進一步確認。 
3.2 生物辨識門禁系統 
近年來生物辨識被大量採用在門禁管理系統上[1, 6-7]，其中又以虹膜、指紋和人臉辨
識為主流，虹膜辨識與其他辨識比較起來，虹膜是最不容易被外在因素所改變的，但他的
設備價格也是三種中最高的，其次指紋辨識比較容易被拷貝複製所盜用，且指紋太淺、手
汗、受傷等，容易造成辨識率降低，人臉辨識比起其他辨識設備較平價化，辨識時主要以
光線影響最大。對於人臉辨識系統包含有三個部分，分別是人臉偵測與人臉辨識，而人臉
偵測最常用的的方法是利用膚色切割[8-10]，對於人臉辨識則需先針對人臉進行特徵抽取，
例如常用的有主軸成分分析(PCA)、線性描述分析(LDA)、獨立成分分析(ICA)以及小波轉
換(Wavelets transformation)等[12]，再利用分群方法對於特徵向量進行分群的動作，常用的
方法有類神經網路、模糊推論分類器、支持向量機器分類器以及貝氏機率分類器等[11]。 
3.3 膚色切割 
膚色切割(Skin Segmentation)技術在電腦視覺及圖形辨識領域中扮演著重要的角色，例
如人臉偵測、人臉追蹤、及手勢辨識都是常見的應用[8-11]。到目前為止已經有許多膚色切
割技術被提出，而這些技術的大部分都是使用一個分類器將影像的像素依據顏色分成膚色
(Skin)與非膚色(Non-skin)兩大群，因此隱藏在這些方法背後有一些前提假設及值得注意的
議題，首先這些方法假設人類的膚色是有別於一般其它物體的顏色且膚色有相當高程度的
一致性，因此進行膚色的切割對於上述這些應用才有意義，其次是不同色彩空間及不同分
5 
 
新方法是採用相同位置的連續幾張畫面像素數值的中值，又或者有學者提出採用連續幾張
相同位置的像素值的最大統計值作為背景影像更新，不管是採用中值或最大統計值，最大
缺點是計算耗時且須大量記憶體紀錄連續幾個畫面的資料，而優點則是效果優於盲目更新
以及選擇性更新方法，不僅考慮到背景隨時間改變光線改變的問題，同時也考慮到當前景
物體常駐後變成背景物體的情況。 
3.5 行人追蹤 
物體追蹤之問題，可視為一連串疊代求最佳解之過程，對於每一張視訊的影像，追蹤
系統需要即時的利用當下擷取的影像給定初始位置後，利用疊代的方法在鄰近區域中找尋
下一個與目標相似的區域求得一最佳解，來表示被追蹤物體目前最可能之狀態與位置。傳
統的光流估測是獲得影像中運動物體移動向量(Motion vector)的一個常見方法，但是光流估
測所需要的計算量龐大，不適合於即時系統追蹤。區塊比對法是另外一種計算運動向量的
方法[39]，此種方法將目前輸入的視訊影像以固定尺寸切割成相同大小的區塊，再將每一區
塊對應到前一張輸入的視訊影像，並且以一個特定範圍搜尋最近似區塊，最後可以決定出
每一區塊對應到前一張輸入視訊影像的移動向量，圖一為區塊比對法的示意圖，圖右為目
前輸入的視訊影像(標示為Target frame)，以2N+1像素為區塊邊長切割成(2N+1)ൈ(2N+1)像
素的區塊，假設其中某一區塊的中心座標為ቀx0, y0ቁ，圖左為前一張輸入的視訊影像(標示為
Reference frame )，以ቀx0, y0ቁ對應到前一張輸入視訊影像，以[-p, p]為搜尋範圍搜尋最近似
的區塊，如圖中標示為Matched macroblock的區塊即為最近似區塊，因此連接此最近似區塊
的中心座標與座標ቀx0, y0ቁ即為此區塊的移動向量，此方法缺點是需要相當龐大的計算量，
因此有學者提出一種類似於二元搜尋法的方法，稱為2D搜尋法，圖二為此方法的示意圖，
此方法改善循序搜尋的方法，改採類似九元搜尋的方法，當欲在前一張輸入視訊影像搜尋
最近似區塊時，我們以ቀx0, y0ቁ為中心搜尋[-p, p]像素範圍，首先搜尋圖中標示為1的區塊，
這些在圖中標示為1的區塊在x軸與y軸上分別是以與座標 ቀx0, y0ቁ間隔p/2為取樣間隔，將標
示為1的區塊與目前輸入視訊影像中以ቀx0, y0ቁ為中心區塊進行近似比對，最後可以從標示為
1的區塊中找到一個最近似的區塊，例如圖二中被標示為1且被填滿灰色的區塊，接著以此
區塊中心座標接著進行第二次九元搜尋，因此搜尋途中被標示為2的區塊，此次取樣的間隔
則以p/4像素為取樣，接著再從標示為2的區塊中找到與目前輸入視訊影像中以ቀx0, y0ቁ為中
心區塊最近似的區塊，如圖二中標示為2且填滿灰色的區塊，再接著進行第三次九元搜尋，
找到途中被標示為3且填滿灰色的區塊，以此類推，直到找尋間隔為1個像素時停止，最後
再以[-p, p]的搜尋範圍中找到與輸入影像以座標ቀx0, y0ቁ為中心區塊最近似的區塊，並決定區
塊的移動向量，如圖2中標示為MV的向量。 
7 
 
 
圖3、階層式區塊比對法示意圖 圖4. 系統流程圖 
 
四、 研究方法 
4.1. 結合 RFID 與人臉辨識門禁管理系統 
雖然RFID有許多優點，但是當RFID遺失時仍然沒有一套機制可以確認卡片的擁有者，
因此在本計畫中我們提出一套結合 RFID 身份辨識系統與人臉近似度比對的門禁管理系統，
以達到方便使用與安全性高的主動式門禁管理系統。當使用者持 RFID 的電子標籤卡經過
門禁系統(此計畫採用 13.56MHz 被動式 RFID 系統)，透過 RFID 讀取器讀取電子標籤卡中
的辨識碼與資料庫進行身份比對，接著透過架設於門禁系統上的攝影機取得即時的使用者
人臉影像，經由特徵臉(Eigenface 或 Fisherface)方法[11]的特徵抽取與資料庫中預存的使用
者人臉影像特徵進行近似度比對，避免卡片遺失後被盜用的情況發生，有效提升門禁管理
系統的安全層級。 
此系統採用兩階段身份辨識流程的優點，第一階段先執行比對使用者 ID，第二階段再
採用人臉近似度比對技術以至於能更確定其使用者身分，只要有其中一階段不符合其標準
的話，系統便不允許此持卡人進入，由此可見，就算是其 RFID 磁卡被盜用的話，此盜用
者仍然無法通過第二階段的人臉近似度比對，如此一來便大大地改善了原始人員進出管制
系統的安全性。圖 4 是整個系統的軟體運作流程圖。 
開始 
系統讀取RFID卡片 
卡片 ID 進行 
資料庫比對 
ID 是否符合 
攝影機拍下持卡人的
影像，並與資料庫進
行人臉近似分析 
Yes 第一階段 
No 
影像是否符合 
系統核准持 
卡人進入 
開門
No 
Yes 
第二階段 
9 
 
其中 ( ) ( ) μzz −Φ=Φ~ ， ( ) MM
i i∑ = Φ= 1 xμ 是在 F 空間的膚色特徵向量的平均向量，
( ) ( ) MM
i
T
ii∑= ΦΦ= 1 ~~~ xxC 則是在F空間的膚色特徵向量的共變異矩陣，此一問題可以利用核
主軸成分分析解決[23]。 
圖 5 為部分實驗影像的膚色切割結果，圖 5 中(a)欄位為原始影像，圖 5(b)欄位為片段
直線分類器的膚色切割結果，圖 5(c)欄位為單一高斯分類器膚色切割結果，圖 5(d)欄位為
我們提出具有核轉換單一高斯分類器的膚色切割結果，從圖 5 中我們發現，片段直線分類
器的結果最差，而單一高斯分類器與我們提出改良式單一高斯分類器結果近似，但是以膚
色切割完整性來說，我們的方法比單一高斯分類器更好，例如圖 5 中第一列的例子，我們
方法完整切割出影像中人像右上手臂內側，而單一高斯分類器無法完整切割，又例如圖 5
中第四個例子中，人臉膚色切割結果我們提出方法比起單一高斯分類器有較完整的切割結
果。 
 
    
(a) (b) (c) (d) 
圖 5. 部分影像膚色偵測結果的比較，(a)原始彩色影像，膚色切割結果藉由(b)片段線性方法(c)單一
11 
 
 
  
frame 1 frame 2 frame 3 frame 4 frame 5 
  
frame 6 frame 7 frame 8 frame 9 frame 10 
  
frame 11 frame 12 frame 13 frame 14 frame 15 
圖 7、圖 6 連續影像範例的移動物體偵測結果。 
  
 
 
 
 
 
 
 
圖 8、統計的背景影像更新法示意圖 
4.2.2 人形辨識 
上述步驟完成後我們可以求得視訊中前景影像，接著利用相連成分計算將移動物體從
前景影像中切割出來，在正規化尺寸及邊緣化計算後，將移動物體區塊的邊緣化影像輸入
到一預先經過 Adaboost 演算法訓練過的分類器，進行人形移動物體的分析與辨識，最後得
到移動物體是否為人形或非人形，若此移動物體非為人形，例如樹木、窗簾、或光影變化
時，則忽略此一移動物體；另一方面，若移動物體為一人形物體時，接著進行行人追蹤與
路徑比對步驟。 
 
 
h1(x) h2(x) hn(x) 
F F F 
P P P
Feature vector 
Level 
Probability 
Value
Value
Frame t 
Frame t-M+1 
Frame t-M 
13 
 
 
 
  
frame 1 frame 2 frame 3 frame 4 frame 5 
  
frame 6 frame 7 frame 8 frame 9 frame 10 
  
frame 11 frame 12 frame 13 frame 14 frame 15 
圖 11. 圖 6 視訊範例的移動物體路徑偵測結果 
 
(a) (b) 
(d) (e) 
圖 12. 其他片段視訊的移動物體路徑偵測範例，(a)由右下往左上方向走，走到一半掉頭。
(b)由左上往右下方向走，移動物體包含兩個人。(c)由右下往左上方向走，到了左上
15 
 
碩士論文。 
[6]. 菲謝蒂， “指紋辨識器”， 科學人雜誌，2003 年 4 月。 
[7]. 阿爾珀特， “資訊安全一指搞定：利用指紋感測器保衛你的電腦資料”，科學人雜誌，
2004 年 8 月。 
[8]. E. Hjelm and B. K. Low, “Face Detection: A Survey,” Computer Vision and Image 
Understanding, Vol. 83, No. 3, pp. 236-273, 2001. 
[9]. M. H. Yang, D Kriegman, and N. Ahuja, “Detecting Faces in Images: A Survey,” IEEE 
Trans. on Pattern Analysis and Machine Intelligences, Vol. 24, No. 1, pp. 34-58, 2001. 
[10]. R. L. Hsu, A. M. Mohamed, and A. K. Jain, “Face Detection in Color Images,” IEEE Trans. 
on Pattern Analysis and Machine Intelligences, Vol. 24, No. 5, pp. 696-706, 2002. 
[11]. W. Zhao, R. Chellappa, P. J. Phillips, and A. Rosenfeld, “Face recognition: A literature 
survey,” ACM Computing Surveys, Vol. 35, no. 4, pp. 399-458, 2003. 
[12]. Gonzalez, “Digital image processing 2/e,” Addison-Wesley Publishing Company, 2002. 
[13]. S.-L. Phung, A. Bouzerdoum, and D. Chai, “Skin Segmentation Using Color Pixel 
Classification: Analysis and Comparison,” IEEE Trans. on Pattern Analysis and Machine 
Intelligence, vol. 27, no. 1, Jan. 2005. 
[14]. D. Chai and K. N. Ngan, “Face Segmentation Using Skin Color Map in Videophone 
Applications,” IEEE Trans. on Circuits and Systems for Video Technology, vol. 9, no. 4, pp. 
551-564, 1999. 
[15]. C. Garcia and G. Tziritas, “ Face Detection Using Quantized Skin Color Region Merging 
and Wavelet Packet Analysis,” IEEE Trans. on Multimedia, vol. 1, no. 3, pp. 264-277, 1999. 
[16]. K. Sobottka and I. Pitas, “A Novel Method for Automatic Face Segmentation, Facial Feature 
Extraction and Tracking,” Signal Processing: Image Comm., vol. 12, no. 3, pp. 263-281, 
1998. 
[17]. R.-L. Hsu, A.-M. Mohamed and A. K. Jain, “Face Detection in Color Images,” IEEE Trans. 
on Pattern Analysis and Machine Intelligence, vol. 24, no. 5, pp. 696-706, May. 2002. 
[18]. H. Wang and S. F. Chang, “A Highly Efficient System for Automatic Face Detection in 
Mpeg Video,” IEEE Trans. on Circuits and Systems for Video Technology, vol. 7, no. 4, pp. 
615-628, 1999. 
[19]. H. Greenspan, J. Goldberger, and I. Eshet, “Mixture Model for Face Color Modeling and 
Segmentation,” Pattern Recognition Letters, vol. 22, pp. 1525-1536, Step. 2001. 
[20]. B. Menser and M. Wien, “Segmentation and Tracking of Facial Regions in Color Image 
Sequences,” SPIE Visual Comm. and Image Processing, vol. 4067, pp. 731-740, June 2000. 
[21]. M.-H. Yang and N. Ahuja, “Gaussian Mixture Model for Human Skin Color and Its 
Application in Image and Video Databases,” SPIE Storage and Retrieval for Image and 
Video Databases, vol. 3656, pp. 450-466, Jan. 1999. 
[22]. S.L. Phung, D. Chai, and A. Bouzerdoum, “A Universal and Robust Human Skin Color 
Model Using Neural Networks,” Proc. of INNS-IEEE Internal Joint Conf. Neural Networks, 
vol. 4, pp. 2844-2849, July 2001. 
[23]. András Kocsor and László Tóth, “Kernel-Based Feature Extraction with a Speech,” IEEE 
Trans. on Signal Processing, Vol. 52, No. 8, pp. 2250-2263, August 2004. 
[24]. D. M. Gavrila, J. Giebel, and S. Munder, “Vision-based Pedestrian Detection: The 
PROTECTOR System,” in Proc. IEEE Int. Conf. Intell. Veh. Symp., Jun. 2004, pp. 13–18. 
17 
 
附錄：該計畫已發表論文(並請註明發表刊物名稱、卷期及出版日期) 
 
一、期刊論文： 
[1]. 鄭文昌、林宗毅、張家銘， “結合 RFID 與人臉近似度比對之門禁管理系統,” Journal of 
Hsiuping, Vol. 15, pp. 233-244, Sept. 2007. 
 
二、研討會論文： 
[1]. Song-Shyong Chen, Yuan-Chang Chang, Jenq-Lang Wu, Wen-Chang Cheng, and 
Shun-Feng Su, “Fuzzy Control Design for Switched Nonlinear Systems,” Proceedings of 
The SICE Annual International conference 2008 on instrumentation, control and information 
technology, 8/20~8/22, 2008. 
[2]. Wen-Chang Cheng, “3D Human Face Reconstruction with Three Images Based on 
Constrained ICA,” Proceedings of the IEEE International Joint Conference on Neural 
Networks, HK, 6/1~6/5, 2008. 
[3]. 鄭文昌、林宗毅、張家銘，“基於核轉換距離測量之膚色切割方法”， 2007 National 
Computer Symposium, 12/20~12/21, 2007. 
[4]. 鄭文昌、林宗毅， “利用 RFID 與影像人臉比對之門禁管理系統”， Proceedings of the 
Conference on the Information Education and Technological Applications, 11/6, 2007. 
3D Human Face Reconstruction with Three Images Based on 
Constrained ICA 
 
Wen-Chang Cheng 
 
 
Abstract— In this paper, we propose an improved 
photometric stereo scheme based on the Lambertian 
reflectance model and the constrained independent 
component analysis (CICA) method. When we obtain the 
object’s surface normal vector on each point of an image by 
ICA model to reconstruct 3-D shape, we will find the normal 
vector’s coordinates whose x-axis, y-axis and z-axis value are 
not arranged in turn. So we use CICA method to solve the 
problem. Then we obtain correct normal vector’s sequence 
form surface, and using the enforcing integrability method to 
reconstruct 3-D object. Finally, we test our algorithm on a 
number of real images captured from the Yale Face Database 
B. The experimental results demonstrate that the proposed 
CICA method is work to find the order of normal vector. 
I. INTRODUCTION 
ne of the computer vision approaches is photometric 
stereo approach for surface reconstruction which is 
able to estimate local surface orientation by using several 
images of the same surface taken from the same viewpoint 
but under illuminations from different directions. It was 
first introduced based on the Lambertian reflectance model 
by R. J. Woodham [1]. It has received wide attention and 
several efforts have been made to improve the performance 
of recovery [2]-[18]. 
The main limitation of classical photometric stereo 
approach is that the light source positions must be 
accurately known and this necessitates a fixed, calibrated 
lighting rig. Hence, an improved photometric stereo 
method for estimating the surface normal and the surface 
reflectance of objects without a priori knowledge of the 
light source direction or the light source intensity is 
proposed by C.T. Lin etc.. They propose a 
neural-network-based adaptive hybrid reflectance model 
[6]. By neural-network’s training process, we will obtain 
surface normal vector without knowing the source 
directions in advance. Due Neural-Network’s light 
directions in the hidden level, so they are nearly approach 
the real light directions. It should affect reconstruction 
model‘s accuracy. Then they propose a novel ICA-based 
photometric stereo approach based on the non-Lambertian 
model [7]. The goal of ICA model is used to separate the 
independent component of surface normal on each point of 
an image. But the ICA model still has the novel problem 
which the separated normal vector whose x-axis, y-axis and 
z-axis value are not arranged in turn. However, in this paper, 
                                                 
W. C. Cheng is with the Department of Information Network Technology, 
Hsiuping Institute of Technology, No.11,  Gongye Rd.,  Taichung,  
412,  Taiwan(e-mail: wccheng@mail.hit.edu.tw). 
we propose a technique of the constrained independent 
components analysis (CICA) model [20]-[25]. It is a 
supervised ICA model which may make the outputs of 
normal vector’s coordinate values arranged in turn. Finally, 
the 3D surface model is reconstructed from the surface 
normal on each point of an image, obtained by the CICA 
technique, using the method of enforcing integrability [19]. 
The rest of this paper is organized as follows. Section II 
describes the Lambertian model. The details of the 
proposed CICA-based reflectance model and its derivations 
are presented in Section III. In session IV, we obtain the 
surface normal of objects by CICA model. Then we use the 
enforcing integrability approach to obtain the deeper 
information for reconstructing of the surface of an object 
by its normal vectors. Extensive experiments have been 
performed to evaluate the performance of the proposed 
approach, and parts of the results are presented in Section 
V. Conclusions are summarized in the last section. 
II. THE LAMBERTIAN MODEL 
Lambertian surface mean angle can get the same surface 
of illumination perhaps from each. The illumination of 
observing the income is only involved in direction of the 
light source. suppose that the recovering of surface shape, 
denoted by z(x, y), from shaded images depends upon the 
systematic variation of image brightness with surface 
orientation, where z is the depth field, and (x, y) form the 
2-D grid over the domain D of the image plane. Then, the 
Lambertian reflectance model used to represent a surface 
illuminated by a single point light source v is written as: ( ) ),(),(),(),(   , yxTyxyxyx LR nvn αα = , Dyx ∈∀ ) ,( ,   (1) 
where )(⋅R  is diffuse component intensity, yx,α  is diffuse 
albedo on position (x, y) of surface, v is a column vector 
indicating the direction of point light, and L is light strength. 
The surface normal on position (x, y), denoted by , 
can be represented as 
),( yxn
[ ]T
yxyx
yxyx
yx
qp
qp
1
1
2
),(
2
),(
),(),(
),( ++
−−=n ,           (2) 
where xyxzyxp ∂∂= ),(),(  and yyxzyxq ∂∂= ),(),(  are 
the surface gradients [1]. 
The Lambertian model describes a diffuse reflection 
surface. Any light shooting out and is reflected averagely 
from all directions after modulating by the surface 
reflection rate. It is a useful model in the field of computer 
vision. 
O 
( yx,n )  from which we can easily deduce from Eq. (2) the 
possibly nonintegrable partial derivatives ( )yxzx ,ˆ  and 
. These partial derivatives can also be expressed as a 
series, giving 
( yxzy ,ˆ )
)
)
( ) ( ) ( ωω
ω
 , , ˆ ,ˆ 1 yxcyxz xx φ∑
Ω∈
=         (9) 
( ) ( ) ( ωω
ω
 , , ˆ ,ˆ 2 yxcyxz yy φ∑
Ω∈
=        (10) 
This method can find the expansion coefficients ( )ωc  
for being given a possibly nonintegrable estimate of surface 
slopes  and : ( yxzx ,ˆ ) ( )yxzy ,ˆ
( ) ( ) ( ) ( ) ( )( ) ( )ωω
ωωωω
ω
yx
yx
pp
cpcp
c +
+= 21 ˆˆ , for ( ) Ω∈= vu,ω  (11) 
where  
( ) ( ) dxdyyxp xx ∫∫= 2,, ωω φ           (12) 
( ) ( ) dxdyyxp yy ∫∫= 2,, ωω φ .         (13) 
In the end, we can reconstruct the face’s surface by 
implementing the inverse 2-D DCT on the coefficient ( )ωc . 
V. EXPERIMENTAL RESULTS 
We test the algorithm on a number of real images from 
the Yale Face Database B [26] showing the variability due to 
illumination and there is varying albedo in each point of 
surface of human faces. First, we take the images of the 
same person that was photographed under three different 
light sources from these testing images arbitrarily shown in 
Fig. 2. We feed the normalized images into our algorithm. 
For the face surface reconstruction problem, the normal 
vectors of a sphere’s surface were used as the reference 
values of the CICA model due to their similar structures. 
The true depth map of the synthetic sphere object is 
generated mathematically as 
( )
⎪⎩
⎪⎨
⎧ ≤+−−=
                    otherwise   ,0
 if    ,,
222222 dyxyxdyxz    (14) 
where d = 48, , and the center is located at (x, 
y) = (51, 51). Fig. 1 shows the normal vectors of a sphere’s 
surface. 
100  ,0 ≤< yx
After updating the parameters by several iterations, we 
can get the normal vector of the surfaces of human faces 
corresponding to each pixel in an image in the output nodes. 
The results are shown in the second row in Fig. 2, which are 
the X-component, the Y-component, and the Z-component 
of the surface normal vector in order. Fig. 3 presents the 
results of 3D human face reconstruction. 
VI. CONCLUSIONS 
The application of component analysis methods such as 
ICA to surface normal vector analysis has met with 
considerable success. However, when automated analysis 
techniques are required the standard ICA algorithms prove 
to be less useful. Supervising the ICA solution by 
incorporating prior domain knowledge is logical and is in 
keeping with expert evaluation of neurophysiological 
signals, where for different evaluation purposes 
predetermined expectations of signal morphology and 
distribution are present. CICA as applied in this paper with 
temporal constraint results in a useful technique for the fast 
and efficient extraction of surface normal vector from three 
surface reflection images. An important result derived 
fromusing the constrained CICA model for solving 
photometric stereo problems does not need any desired 
output value and the smoothing conditions. It is easier to 
converge and make the system stable. 
(a) 
(b) 
(c) 
Figure 1. the normal vectors of a sphere’s surface (a) the 
X-component, (b) the Y-component, and (c) the 
Z-component of the normal vectors. 
 
(a) (b) (c) 
 
(d) (e) (f) 
Figure 2. (a)-(c) Three training images with differ light source 
positions from Yale Face Database B in frontal. (d)-(f) 
Surface normal corresponding to the three source images. 
 
Figure 3. The results of 3D model reconstruction by our proposed 
algorithm. 
