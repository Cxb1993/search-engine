 1
一個使用相關回饋的影像標註系統 
An Image Annotation Tool with Relevance Feedbacks 
 
國科會補助專題研究計畫 
計畫編號：NSC 97-2218-E-147-002- 
計劃執行：民國 97 年 01 月 01 日至民國 97 年 10 月 31 日 
計劃主持人：江政杰 德明財經科技大學 資訊科技系 助理教授 
 
一、摘要 
中文摘要 
本計畫的主軸在於處理語意隔閡的問題。人們辨認影像內容是憑藉較高階語意的認知，但
是電腦視覺在辨認影像是由分析低階的訊號資訊而來，二者之間存在的差異性，就稱之為
語意隔閡。我們首先提出一個以語意為基礎的影像特徵描述，稱之為以機率為基礎的語意
組成描述子(probabilistic semantic component descriptor, SCD)。針對一組影像，我們的做法
是分析每張影像的組成內涵，並組織成一個具代表性的影像特徵。同時，我們設計一個使
用相關回饋的影像標註系統，讓使用者可以較容易的對影像加上文字的語意資訊。我們使
用以半監督式學習的方法，並整合已標註與未標註的影像，來強化影像標註的學習機制。
藉由設計這一加入影像語意內涵的影像特徵描述，以及參照使用者相關回饋資訊的影像標
註，本計畫由這兩個方向來縮短影像辨識時的語意隔閡問題。 
 
英文摘要 
This project aims to deal with semantic gap between low-level features of images in computer 
vision and high-level concepts in human cognition. We first propose a semantic based image 
feature called probabilistic semantic component descriptor (pSCD) to extract semantic contents 
involved in an image. Given a set of images, our approach analyzes what kinds of concepts each 
of region in an image involves, and then combines all concepts of regions in the same image to 
form its pSCD. Then, we design an interactive tool of image annotation to assist users in easily 
annotating images with labels. The proposed annotation method employs a semi-supervised 
learning approach that integrates labeled and unlabeled images for training to improve the 
efficiency of recognition while the number of labeled images is small at the beginning of 
iterations. This project makes efforts to reduce the semantic gap of image understanding by 
proposing the new visual descriptor and designing the image annotation method with relevance 
feedbacks. 
 
 
 3
街道、行人等，是很困難的工作，因為這牽涉到精確的物體辨識問題。我們的想法是藉由
非監督式的方法(unsupervised method)，分析大量相關的影像資訊後，雖然不知道這些影像
內容確切是由哪些組成，但是可以分析這些組成份子中，大略可以分類成哪些群組，而用
這些群組來描述影像的內容。 
 
影像標註的主要目標是為影像加入文字主題的描述，也就是為影像加入額外的語意資
訊，以突破電腦視覺中語意隔閡的困難。試圖全自動的為影像加註文字語意，已經有許多
的研究嘗試過[9][10]，但是並無法真正的突破語意隔閡的困難。既然語意的內容終究以人
的認知為準，因此本計畫的主要想法是採用相關回饋(relevance feedback)機制，讓使用者的
語意可以直接導入影像標註之內。針對單一文字標註主題，我們設計一個半監督式的方法，
同時結合已標註與未標註之影像資訊，訓練出階層式分類器(hierarchical classifier)，來提升
訓練器的學習效能。利用我們設計的分類器，將可能符合目標文字主題的影像提供給使用
者，由使用者決定是否正確。 
 
 
三、以機率為基礎的語意組成描述子(pSCD) 
 
欲擷取可以描述一組影像的 pSCD，我們首先依照圖二的流程，將這些影像的視覺特
徵資訊轉換成一組視覺字組(visual word)。我們套用[11][12]這兩個方法，找出每張影像內的
特徵點(interest point)，並以此框出一個橢圓的影像區域，對此影像區域計算 sift descriptor 
[13]，並以 k-means clustering 將這些代表全部影像的 sift descriptors 分成 k 類，這樣就會有
k 組的視覺字組來描述全部的影像。我們對這些影像分別取出兩種不同類型的特徵點，因此
就會有兩組不同描述的視覺字組。 
 
 
圖二、擷取視覺字組的流程圖 
 
 
(a). 一張影像內組成份子之間的
機率關係 
(b). 機率上影像 d、視覺字組 w、與隱藏語意 z 之
間的計算 
圖三、影像(d)與視覺字組(w)的機率關係 
 
 5
sZ(wj)代表著在 Z 的數量值之下讓此視覺字組所得到的語意判斷成果，這個值越大，就代表
著使用 z*來描述這個視覺字組的可靠性就越高。因此我們設定一個門檻值 h，所有 sZ(wj)大
於 h 的 p(z*|wj)才保留下來，也就是說我們將利用這個門檻值，過濾掉判斷隱藏語意時不是
很有信心的視覺字組： 
⎩⎨
⎧
<
≥=
h(ws
h(ws
hw
jz
jz
j ) if ,0
) if ,1
) ,(κ  (6)
在後面的比較，我們將門檻值 h 設定成過濾掉的視覺字組比例。於是，針對某一張影像 di，
我們可以定義其 pSCD 為一 Z 維的向量 } ..., ,{ 1 Zd fff i = ： 
∑
∈
⋅⋅=
ij dw
jji wzpwzif )|()() ,(
** κδ  (7)
其中 δ是 Kronecker's delta function： 
⎭⎬
⎫
⎩⎨
⎧
≠
==
yx
yx
yx
 if ,0
 if ,1
),(δ  (8)
 
這樣的做法有一個前提：必須先確認 Z 的數量。Z 的數量代表著我們希望拿多少種語
意資訊(雖然我們沒有對這些語意命名)來描述這組影像，很明顯的不同 Z 的數量將會造成
對視覺字組不同的判斷結果。同時，我們必須決定門檻值 h 才能完成 pSCD 的擷取，而 Z
跟 h 的值對 pSCD 的效果有很大的影響。因此我們設計一個實驗，改變不同的 h 跟 Z 來觀
察 pSCD 的效果，以決定這兩個值的選擇。 
 
我們由 Caltech 101-Object [16]這個影像資料集取出四類型影像：飛機、人臉、花豹、
摩托車，每一類取 200 張圖共 800 張影像。以這組影像來分析搭配不同的 h 與 Z 值，擷取
每張影像的 pSCD，並以[17]的方法執行影像分類的比較，在表一內顯示各自的正確率。觀
察這些正確率的值，並計算不同 h 所得到的正確率平均與變異數，可以發現在 h=0.3 時不
但平均正確較高且變異數低，代表著這時的 pSCD 具有相當的穩定度。因此我們挑選 h=0.3
以及 Z=30 來產生 pSCD，代表著我們將以 30 種隱藏語意來描述這組影像，同時每次都過
濾掉視覺字組中最不可靠的 30%，來產生 pSCD。 
 
表一、不同 h 與 Z 所擷取的 pSCD 執行影像分類的正確率 
h Z = 10 20 30 40 50 avg std 
0 0.668 0.642 0. 622 0. 653 0. 706 0. 658 0. 0280 
0.1 0. 640 0. 676 0. 676 0. 639 0. 692 0. 665 0. 0214 
0.2 0. 656 0. 703 0. 736 0. 674 0. 682 0. 690 0. 0272 
0.3 0. 668 0. 689 0. 704 0. 687 0. 723 0. 694 0. 0184 
0.4 0. 634 0. 659 0. 693 0. 688 0. 650 0. 665 0. 0225 
0.5 0. 632 0. 681 0. 703 0. 691 0. 722 0. 686 0. 0300 
0.6 0. 616 0. 651 0. 685 0. 665 0. 681 0. 660 0. 0248 
0.7 0. 616 0. 617 0. 687 0. 637 0. 658 0. 643 0. 0267 
0.8 0. 588 0. 672 0. 593 0. 578 0. 616 0. 609 0. 0336 
 
 7
 
針對單一文字主題 Lk 時，我們將建立一個階層式分類器，表二顯示我們設計的分類器
Ck的遞迴訓練過程。一開始將相關影像集合 Dk、非相關影像集合 Dk'、以及未被標註的影
像 DU合在一起，形成階層式分類器 Ck的樹根節點。對每個節點所包含的影像特徵向量，
我們以 k-means clustering 分成 z 類。檢視這 z 個子集合內每個資料組成，我們希望或者是
大多是相關影像集合的成員(代表這個子集合可以代表包含文字標記 Lk)，或者大多是非相
關影像集合的成員(代表這個子集合可以代表不包含文字標記 Lk)。這個概念就像是在影像
資料上做記號，看這些資料在分類器上的行為，而估計未來測試時資料的可能分類效果。
因此我們設計一個評分的標準[3]，來判斷這個節點分成 z 類是否合適，挑選最適合的 z 值
當成是此節點往下切割子節點的依據。另外當節點內包含的資料比較”純正” (大多是相關或
非相關影像)，或者是節點內資料數量太少沒有代表性時，我們就會停止節點的切割。 
 
表二、分類器 Ck的訓練程序 
Input: unlabeled images UD , positive images kD , and negative images 'kD  
Output: a hierarchical classifier Ck for label Lk 
Initialization: root node krootN  contains 
'
kkU DDD ∪∪  
// kiN : node i for the hierarchical classifier Ck. 
// construct the tree by splitting each node kiN . 
1. for each leaf node kiN  not fitting the stopping condition  
{ 
2. for z = 2 to b  
 {  // b is the max number of the trying range 
3. node splitting method to divide kiN  into z classes. 
4.  compute score ) ,( zN ki  
// evaluate how many branches are appropriate for node kiN . 
} 
5.  ) ,(minarg zNscorez kiz
k
i =  
6.  kiN  is divided into 
k
iz  classes 
// kiN  is divided into, w.l.o.g., 
k
zi
k
i k
i
NcNc ,1,  ..., , . 
} 
 
當階層式分類器 Ck訓練完成後，針對尚未標註的影像 Inew來說，接著要計算這張影像
包含 Lk 的文字標記有多少的信賴值(confidence value)。關於信賴值的詳細計算方式請參考
[3]，這邊以圖五的範例說明。假設圖五內針對 L2 的文字標註訓練出記階層式分類器 C2，
首先將影像 Inew轉換成特徵向量，我們的目標是計算 Inew階層式分類器 C2 的相容程度如何。
由於在訓練階段 C2 是由相關與非相關影像集合的節點所建構，因此影像 Inew從 C2 的樹根出
發，計算與各子節點的中心點(mean)距離，並將這些相對距離正規化(normalize)為 0 到 1 的
標準模式。例如圖五中影像 Inew對第一層的子節點距離關係分別是 0.7、0.1、與 0.2，因為
每個節點代表著訓練資料的分布狀態，因此將距離關係遞迴的乘上各子節點對此文字主題
的代表性，累加的結果 0.15745 就是影像 Inew對此階層式分類器 C2 的相似程度，並以之代
表這張影像包含 L2 的信賴程度。 
 
基本上我們採用半監督式的分類方式，藉由未標註的影像資訊，來降低訓練分類器時
所需的已標註影像的數量，提升分類器的訓練效能。而階層式分類器在訓練時主要是採用
 9
饋的概念，以提升系統協助使用者進行影像監督的效率。這些研究工作有更進一步的成果
後，我們將會彙整成更完整的論文，投稿到國際知名的學術會議與期刊，以期本計畫的研
究工作有個完整的結束。 
 
六、參考文獻 
 
本計畫發表之論文 
 
[1] Cheng-Chieh Chiang, Yi-Ping Hung, Hsuan Yang, and Greg C. Lee, “Region-based Image 
Retrieval Using Color-Size Features of Watershed Regions”, submitted to Journal of Visual 
Communication and Image Representation, (SCI, accepted and in press)  
[2] Jia-Wei Wu, Cheng-Chieh Chiang, Greg C. Lee, “Semantic-Based Image Feature Through 
Visual Words”, in Proceedings of IPPR Conference on Computer Vision, Graphics and 
Image Processing, CVGIP, Taiwan, 2008.  
[3] Cheng-Chieh Chiang, Ming-Wei Hung, Yi-Ping Hung, and Wee Kheng Leow, “Image 
Annotation with Relevance Feedbacks Using a Seim-Supervised and Hierarchical 
Approach”, in Proceedings of 3rd International Conference on Computer Vision Theory and 
Applications, VisApp, Funchal, Madeira - Portugal, Jan., 2008. 
 
其他參考文獻 
 
[4] Datta, R., Li, J., and Wang, J. Z.: Content-Based Image Retrieval - Approaches and Trends 
of the New Age. In: Proceedings of the ACM SIGMM international workshop on MIR, 
2005. 
[5] M. S. Lew, N. Sebe, C. Djeraba, and R. Jain, “Content-based multimedia information 
retrieval: state of the art and challenges”, ACM Transactions on Multimedia Computing, 
Communications and Applications, vol. 2(1): 1–19, 2006. 
[6] X. S. Zhou, and T. S. Huang, “Relevance Feedback for Image Retrieval: A Comprehensive 
Review”, Multimedia Systems Journal, 8(6), pp. 536-544, 2003 
[7] B. S. Manjunath and W. Y. Ma, “Texture features for browsing and retrieval of image data”, 
IEEE Transactions on PAMI, pp. 837-842, Aug. 1996. 
[8] B. S. Manjunath, J. -R. Ohm, V. V. Vasudevan, and A. Yamada, “Color and texture 
descriptors”, IEEE Transactions on Circuits Systems Video Technologies (Special Issue on 
MPEG-7), 11(6), 703-715, June 2001. 
[9] S. L. Feng, R. Manmatha, and V. Lavrenko, “Multiple Bernoulli Relevance Models for 
Image and Video Annotation”, in Proceedings of CVPR, 2004. 
[10] G. Carneiro and N. Vasconcelos, “Formulating Semantic Image Annotation as a Supervised 
Learning Problem”, in Proceedings of CVPR, 2005. 
[11] J.Matas, O. Chum, M. Urban, and T. Pajdla, “Robust wide baseline stereo from maximally 
 11
 
International Conference on Computer Vision Theory and Applications 
VisApp 2008  
葡萄牙、Madeira - Funchal City, 自 97 年 1 月 22 日至 97 年 1 月 25 日 
 心得報告 江政杰 
 
一、 參加會議經過 
 
3rd International Conference on Computer Vision Theory and Applications (VISAPP 2008)是由
INSTICC (Institute for Systems and Technologies of Information, Control and Communication)
這個組織所舉辦的國際學術研討會，每年的年初固定在南歐舉辦。如同會議名稱所述，
VISAPP 著重在電腦視覺之原理與應用等相關主題上。本人於去年九月投稿論文於此研討
會，承蒙接受刊登於是在今年一月前往參與。 
 
此研討會的舉辦地點在葡萄牙的 Madeira 島上的 Funchal 市，這是接近葡萄牙本土的大西洋
小島，在歐洲算是頗負盛名的渡假區。台灣並沒有直飛葡萄牙的航空班機，所以本人由荷
蘭轉機至葡萄牙首都里斯本後，再轉機至 Fuchal 市參加會議。此會議於 1 月 22 開始，一
共四天的議程，每日依據不同的論文主題分成數個時段由與會者進行論文發表簡報，並穿
插論文 Poster 展示，讓與會者可以自由在會場交談討論；主辦單位並邀請數位知名學者發
表演講，分享他們在各研究主題上之心得。我的論文發表時程安排在第三天(1 月 24 日)下
午，演講時間約 20 分鐘。以英文簡報是很一件很令人緊張的事情，幸好最後還是順利完成。 
 
在這四天中，主要的活動有三類：聽演講與論文發表、與其他與會者討論相關研究主題、
以及自己的論文發表。看看別人的研究主題與進度，可以直接與作者面對面溝通，互相交
換對問題的見解，這是非常棒的感覺。整體來說，這四天的學術活動內容非常緊湊，收穫
豐富，讓自己的國際視野與研究觀點有很大的突破，是一個很好的學術活動經驗。 
 
二、 與會心得 
 
參與 VISAPP 對我最大的壓力在於論文發表，畢竟英文的簡報與溝通無法如同中文般的順
暢。由於台灣至葡萄牙的飛航、轉機時間很長，所以在飛機上有充分的時間準備英文講稿，
因此整個簡報還算是順利。除此之外，聽演講、與其他學者討論有趣的主題，這是參與國
際學術研討會最主要的目標，可以讓自己看到不同的世界，才不會在研究的主題上只鑽入
一個很小的角落之中；同時聽聽另一種文化思考的學者的意見，有時候可以讓自己跳出過
出席國際學術會議心得報告 
                                                             
計畫編號 NSC 97－2218－E－147－002－ 
計畫名稱 一個使用相關回饋的影像標註系統 
出國人員姓名 
服務機關及職稱 
江 政 杰 
德明財經科技大學 資訊科技系 
會議時間地點 葡萄牙、Madeira - Funchal City,  自 97年 1月 22日至 97年 1月 25 日 
會議名稱 3rd International Conference on Computer Vision Theory and Applications 
發表論文題目 Image Annotation with Relevance Feedbacks Using a Seim-Supervised and Hierarchical Approach 
 
一、參加會議經過 
3rd International Conference on Computer Vision Theory and Applications (VISAPP 
2008)是由 INSTICC (Institute for Systems and Technologies of Information, Control and 
Communication)這個組織所舉辦的國際學術研討會，每年的年初固定在南歐舉辦。如同
會議名稱所述，VISAPP著重在電腦視覺之原理與應用等相關主題上。本人於去年九月
投稿論文於此研討會，承蒙接受刊登於是在今年一月前往參與。 
 
此研討會的舉辦地點在葡萄牙的Madeira島上的 Funchal市，這是接近葡萄牙本土的
大西洋小島，在歐洲算是頗負盛名的渡假區。台灣並沒有直飛葡萄牙的航空班機，所以
本人由荷蘭轉機至葡萄牙首都里斯本後，再轉機至 Fuchal市參加會議。此會議於 1月 22
開始，一共四天的議程，每日依據不同的論文主題分成數個時段由與會者進行論文發表
簡報，並穿插論文 Poster展示，讓與會者可以自由在會場交談討論；主辦單位並邀請數
位知名學者發表演講，分享他們在各研究主題上之心得。我的論文發表時程安排在第三
天(1月 24日)下午，演講時間約 20分鐘。以英文簡報是很一件很令人緊張的事情，幸好
最後還是順利完成。 
 
在這四天中，主要的活動有三類：聽演講與論文發表、與其他與會者討論相關研究
主題、以及自己的論文發表。看看別人的研究主題與進度，可以直接與作者面對面溝通，
互相交換對問題的見解，這是非常棒的感覺。整體來說，這四天的學術活動內容非常緊
湊，收穫豐富，讓自己的國際視野與研究觀點有很大的突破，是一個很好的學術活動經
驗。 
 
 
二、與會心得 
參與 VISAPP對我最大的壓力在於論文發表，畢竟英文的簡報與溝通無法如同中文
般的順暢。由於台灣至葡萄牙的飛航、轉機時間很長，所以在飛機上有充分的時間準備
IMAGE ANNOTATION WITH RELEVANCE FEEDBACK USING 
A SEMI-SUPERVISED AND HIERARCHICAL APPROACH 
Cheng-Chieh Chiang 1, Ming-Wei Hung 2, Yi-Ping Hung 2 and Wee Kheng Leow 3
1 Department of Information Technology, Takming University of Science and Technology, Taipei, Taiwan 
kevin@cc.ntnu.edu.tw 
2 Graduate Institute of Networking and Multimedia, National Taiwan University, Taipei, Taiwan 
r94944019@csie.ntu.edu.tw; hung@csie.ntu.edu.tw 
3 Department of Computer Science, School of Computing, National University of Singapore, Singapore 
leowwk@.comp.nus.edu.sg 
Keywords: Image Annotation, Relevance Feedback, Semi-supervised Learning, Hierarchical Classifier. 
Abstract: This paper presents an approach for image annotation with relevance feedback that interactively employs a 
semi-supervised learning to build hierarchical classifiers associated with annotation labels. We construct 
individual hierarchical classifiers each corresponding to one semantic label that is used for describing the 
semantic contents of the images. We adopt hierarchical approach for classifiers to divide the whole semantic 
concept associated with a label into several parts such that the complex contents in images can be simplified. 
We also design a semi-supervised approach for learning classifiers reduces the need of training images by 
use of both labeled and unlabeled images. This proposed semi-supervised and hierarchical approach is 
involved in an interactive scheme of relevance feedbacks to assist the user in annotating images. Finally, we  
describe some experiments to show the performance of the proposed approach. 
1 INTRODUCTION 
Image understanding and retrieval (Datta et al., 2005) 
have become a very active research area since the 
1990’s due to the rapid increase in the use of digital 
images. However, the semantic gap between the 
low-level features extracted from images and the 
high-level concepts involved in human perception is 
still a challenging problem. Image annotation, which 
discovers the semantic contents from images, may 
be potential for bridging the semantic gap. The goal 
of image annotation is to annotate several labels to 
an image to describe the semantic contents of the 
image. Image annotation is helpful to many 
applications, e.g., additional metadata within images 
for retrieval, or archiving personal photos. 
Unfortunately, it is a difficult task to build a 
model that can describe the contents of images with 
semantic labels. Regarding a simple case that images 
with a single label involve the same semantic 
meaning, the contents are not often homogeneous. 
For example, Figure 1 shows the four images that 
contain the same label “sky”, but their semantic 
contents are very different – sunset, cloud or 
cloudless, blue sky, and night. Obviously, it must be 
more complex if many kinds of labels are mixed. 
That is the main reason that most of the state-of-the-
art approaches cannot annotate images well. Our 
opinion is to involve human feedbacks in image 
annotation because human should make the final 
decision for the semantic concept. Hence, we design 
a method with interactive human feedbacks to assist 
the user in annotating images in this paper. 
Figure 1: Different image contents with label “sky”. 
Image annotation is considered a supervised 
learning problem in many state-of-the-art methods 
(Carneiro and Vasconcelos, 2005). A main limit of 
the supervised learning approach for image 
annotation is that a large number of training images 
is necessary to avoid overfitting. However, it is often 
difficult to manually annotate a large set of images. 
Moreover, the number of labeled images must be 
also small at the beginning of annotating images. 
This limit motivates us to design a semi-supervised 
173
iterations in the relevance feedbacks. That will make 
the learning difficult for overfitting. Hence, we 
integrate unlabeled images into the training images 
for the classifier training to avoid this problem. Also, 
we adopt the hierarchical approach to build a 
classifier associated with each of labels. The main 
reason is that we divide the whole semantic concept 
of images with a label into several sub-concepts by 
use of the hierarchical classifier such that the 
complex contents, illustrated as Figure 1, of images 
can be simplified. Moreover, our proposed method 
by use of individual classifiers for image annotation 
makes the system flexible because it is independent 
of the number of labels. 
Figure 2: The flowchart of our approach. 
4 CLASSIFIER TRAINING 
Table 1 shows the algorithm that constructs the 
hierarchical classifier Ck for label Lk. In this 
algorithm, the root node k
rootN  of the tree Ck initially 
contains the mixture of images Dk, 'kD , and DU. In 
most cases, |||| ' kk DD !! ; hence we randomly ignore 
some of negative-labeled images such that 
|||| ' kk DD   to avoid the imbalance problem in the 
training. In the algorithm, we first decide which 
node needs to be split. If a node needs to be split, we 
go on to decide how many branches are appropriate 
to split the node. Here, K-means clustering is applied 
to divide a node into several child nodes. We try a 
range of branch number and calculate a score for 
each branch number to select the best one. Our 
proposed semi-supervised approach learns the 
classifier in the two ways: (i) evaluate the stopping 
criteria for node splitting according to the positive 
and negative images in the node and (ii) split a node 
by use of the mixture of labeled and unlabeled 
images in order to cover more information in 
learning. Finally, each leaf node in a hierarchical 
classifier represents a sub-concept for the label.  
Table 1: The algorithm of constructing the hierarchical 
classifier Ck for label Lk.
Input: unlabeled images UD , positive images kD , and 
negative images 'kD
Output: a hierarchical classifier Ck for label Lk
Initialization: root node krootN  contains 
'
kkU DDD 
// kiN : node i for the hierarchical classifier Ck.
// construct the tree by splitting each node kiN .
1. for each leaf node kiN  not fitting the stopping
condition
{
2. for z = 2 to b
 {  // b is the max number of the trying range 
3. node splitting method to divide kiN  into z
classes. 
4.  compute score ),( zN ki
// evaluate how many branches are appropriate for 
node kiN .
}
5. ),(minarg zNscorez kiz
k
i  
6. kiN  is divided into 
k
iz  classes 
// kiN  is divided into, w.l.o.g., 
k
zi
k
i k
i
NcNc ,1, ...,, .
}
In the algorithm, we need to design three tasks: (i) 
the node splitting method (line 3), (ii) the stopping 
condition (line 1) which checks whether a node 
needs to be split, and (iii) the score function (line 4) 
which evaluates how many branches for the node to 
split are appropriate. Note that we use the two 
notations given a node kiN : id  is the number of 
positive images in the node and 'id  is the number of 
negative images in the node. 
4.1 Node Splitting 
An unsupervised clustering is used to divide node 
k
iN  into several classes. Here we used K-means 
clustering. To employ it in our work, an image 
should first be converted into be a vector of image 
IMAGE ANNOTATION WITH RELEVANCE FEEDBACK USING A SEMI-SUPERVISED AND HIERARCHICAL
APPROACH
175
that means the possibility of image Inew belonging to 
node k
ijNc . The weight can be defined as the 
normalized inverse of distances from Inew to the 
mean of the cluster, denoted as kiN  in general, by 
¦
 
 J
j
k
 jparentnew
k
inew
new
k
i
NcIdist
NIdistINp
1
,
1-
-1
),(
),(
)|(
 (6) 
where J is the number of sibling nodes of kiN .
Figure 3 illustrates the computation, in equation 
(5), of the confidence values. Assume that the 
classifier is trained for label Lk, and an unlabeled 
image Inew is annotated now. In initial, 
100|||| '   kk DD , and the numbers of positive and 
negative images in nodes are shown. The red digits 
means )|( new
k
i INp  of all nodes kiN . Then, the final 
confidence value of Inew associated with label Lk is 
the sum of all values computed in the leaves, and it 
is 0.15745. 
Figure 3: Illustration of computing the confidence of an 
image Inew associated with label Lk. The total confidence 
value is the sum of all values computed in the leaves. 
6 EXPERIMENTAL RESULTS 
In our experiments, we adopted the public dataset 
(Duygulu et al., 2002) that is widely used for the 
evaluation in image annotation. This dataset includes 
a total of 5,000 images of Corel Photo, the ground 
truth of labeling (1-5 labels for each image), a set of 
region features (36D), and visual words generated 
by K-means clustering (K=500). In the dataset, some 
labels are associated with a huge number of images, 
but some labels are not. For example, there are 1,120 
images labeled by “water” but only one image 
labeled by “glacier”. Because our method is 
independent of the number of labels, we select 15 
labels, shown in Table 2, that are associated with 
images many enough. 
Table 2: The labels used in the experiments and their 
original numbers of associated images. 
Label # of images label # of images label # of images
Water 1120 sky 988 tree 948 
People 744 grass 497 buildings 462 
mountain 345 snow 298 flowers 296 
clouds 280 rocks 250 stone 232 
street 229 plane 224 bear 220 
(a). recalls for each of 15 labels. 
(b). average recalls of our methods and random choice. 
Figure 4: The recalls of our proposed method with 
different iterations. 
Figure 5: The performances of our method with different 
number of labeled images and with different number of 
unlabeled images. 
IMAGE ANNOTATION WITH RELEVANCE FEEDBACK USING A SEMI-SUPERVISED AND HIERARCHICAL
APPROACH
177
