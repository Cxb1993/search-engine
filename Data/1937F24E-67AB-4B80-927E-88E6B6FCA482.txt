次的發生；(4)Ontology-based Meeting Scheduling
Technology (Ontology-based 會議排程技術)：對於
企業內部溝通協調或導入 CMMI 應召開之重要會
議幾乎都是透過召開會議討論協商來完成，但是會
議召開前是需要許多前置作業才能有效並如期的
舉辦，因此負責規畫的人員常要花很多的時間和精
力進行溝通協調。有鑑於此，本計畫將提出一個
Ontology-based會議排程技術來降低這些不必要的
人員、時間及成本上的浪費。
2. CMMI文件摘要技術
大多數的網路線上文件都以全文格式呈現，無
可避免的會產生資訊重複、繁雜或內容冗長等現
象，使用者必須逐行逐字瀏覽觀看，無法迅速確實
地掌握文件內容，不僅浪費網路瀏覽時間，而且缺
乏效率和效果。由此可見，文件摘要技術是一個相
當重要的趨勢。人類的溝通與閱讀主要以文字、概
念為單位用以傳達訊息，而文件背後也是在表達概
念含意，摘要是指以較少或特定長度的文字來代表
原始文件所欲傳達的意涵，其目的在於能產生一簡
單明瞭的內容敘述，可讓使用者在很短的時間限制
下，有效地掌握原始文件所包含的意思。為協助使
用者能快速地瀏覽線上文件，以判斷文件是否為所
要尋找或感興趣的資訊，需要運用資訊擷取相關技
術，萃取出文章中重要內容以形成文件的摘要。本
計畫基於計畫主持人過去三年國科會計畫之研究
成果，進行更深入之研究，主要包括將 Weighted
Event Ontology(93 年 度計 畫 )延 申成 Fuzzy
Ontology及將五層平行模糊推論架構(93年度計畫)
擴展為七層平行模糊推論架構。此外，建構 CMMI
Ontology亦為本計畫之重點。
CMMI 文件摘要技術主要包括兩個處理步
驟，一個為 Fuzzy Ontology Construction，另一個
為 Summarization Generation。圖 2 為 Fuzzy
Ontology Construction處理流程，其中包括三個處
理程序（Document Processing Mechanism、Term
Classifier 及 Fuzzy Inference Mechanism ）。
Document Processing Mechanism 主要是將資料庫
中的文件進行自然語言的處理（例如：斷詞、標註
詞性及中文詞的過濾），以產生重要且有意義的中
文詞並將其傳送至下一個程序進行處理；Term
Classifier 主要是將有意義的中文詞進行特定事件
的分類處理；Fuzzy Inference Mechanism 將產生
Fuzzy Ontology 中 Fuzzy Concept 之歸屬度，即
Concept屬於特定事件的歸屬度。各處理程序說明
如下：
Domain
Expert
Document
Corpus Domain Ontology
…
Fuzzy Ontology
…
Meaningful
Terms
Concept Set
Fuzzy
Inference
Mechanism
Document
Preprocessing
Mechanism
Chinese
Dictionary
Term
Classifier
Classified
Meaningful
Term Set
圖 2 Fuzzy ontology construction處理流程
 Fuzzy Ontology
圖 3為 Fuzzy Ontology架構，其中包括Domain
Layer、Category Layer、Event Layer及 Class Layer
等四層，Domain Layer 代表一個 Ontology 的
Domain Name，它是由多個 Categories所組合而成
的；每個 Category是由多個 Events所組合而成的；
每個 Event 是由多個於 Class Layer 內的 Fuzzy
Concept所組成的。在 Class Layer中，例如：每個
Fuzzy Concept iC 包含一個 Concept Name和一組
歸 屬 程 度 };{
21 piii ECECECi
,,,C   、 一 個
Attribute 集 合 }{ 21 iiii qCCC ,A,,AA  以 及 一 個
Operation 集合 }{ 21 iiii qCCC ,O,,OO  ， ji EC 代表
iC 在 Event jE 的歸屬程度，另外 Attribute iiqCA
及 Operation
iiqC
O 各別代表 iC 的第 iq 個 Attribute
和第 iq 個 Operation。圖 3中，有 3種基本 Relations
(Generalization、Aggregation及 Association)以及 2
種 Fuzzy Relations
(LBR(Location_Broader_Relationship) 及
LNR(Location_Narrower _Relationship))。連接一個
Domain 和它所對應的 Category 是 Generalization
的關係，Generalization 它是一種”is-kind-of”的關
係；連接每個 Category 和它所對應的 Events 是
Aggregation 的 關 係 ， Aggregation 它 是 一
種”is-part-of”的關係；Association 是一個 General
的關係；另外，LBR 和 LNR 為各別為 Location
Broader和 Narrower之關係。
圖 4為本計畫建構之 CMMI Ontology範例，
本範例之 Domain Ontology 為“CMMI Level 2
v1.9”，而所包含的 Category為七個 Process Areas，
分別有需求管理(Requirement Management, RM)、
專案規劃(Project Planning, PP)、專案監控(Project
Monitoring and Control, PMC)、供應商協議管理
(Supplier Agreement Management, SAM)、度量與分
析(Measurement and Analysis, MA)、流程與產品品
質保證 (Process and Product Quality Assurance,
PPQA)及建構管理 (Configuration Management,
CM)，Class Layer中的 Concept為 CMMI Level 2
每個Process Area之一般執行方法(Genetic Practice,
GG)及特定執行方法(Specific Practice, SG)所產生
之表格。
Domain
Category 2 ……………
C : Concept
A : Attribute
O : Operation
Category 1 Category 3 Category k
Class-layer
{C1;μC1E1,μC1E2,…,μC1Ep}
AC11,AC12 ,…,AC1q1
{Cm;μCmE1,μCmE2,…,μCmEp}
ACm1,ACm2,…,ACmqm
OCm1 ,OCm1,…,OCmqm
{C2;μC2E1,μC2E2,…,μC2Ep}
AC21,AC22 ,…,AC2q2
{C3;μC3E1,μC3E2,…,μC3Ep}
AC31,AC32 ,…,AC3q3
{C4;μC4E1,μC4E2,…,μC4Ep}
AC41,AC42,…,AC4q4
OC41,OC41,…,OC4q4
{C5;μC5E1,μC5E2,…,μC5Ep}
AC51,AC52,…,AC5q5
OC51,OC51,…,OC5q5
Association
Aggregation
Generalization
Event E1 Event E2 Event E3 Event Ep
……
……
OC11 ,OC11,…,OC1q1 OC21 ,OC21 ,…,OC2q2 OC31 ,OC31 ,…,OC3q3
LBR
LNR
圖 3 Fuzzy Ontology架構
圖 6 CKIP定義之 Tagging Tree
圖 6 表示一個為 CKIP 所定義之 Tagging
Tree。本計畫將利用任兩個詞性標記節點的路徑距
離來推算兩個詞彙，即為詞組之間的 POS
Similarity，其中，詞性距離長度界定在[0, 7]之間。
例如，有兩個詞彙(“颱風(Na)”和“台灣(Nc)”)，其各
別的詞性為 Na 及 Nc，故詞性距離長度為
2(Na→N→Nc)，POS Similarity 訂有三個語意項
(Linguistic Term)，分別為 POS_High、POS_Median
以及 POS_Low。另一個定義之輸入模糊變數是詞
字相似度(TW Similarity)，本計畫利用任兩個詞彙
之間相同字個數來計算兩個詞之間的詞字相似
度，相同字個數界定在[0, 6]之間。TW Similarity
訂有三個語意項分別為 TW_High、TW_Median以
及 TW_Low。第三個變數定義為語意距離相似度
(Semantic Distance Similarity)，用以推論詞組的語
意距離關聯強度。因在 Ontology 架構中，專家將
同一階層的 Concept，以一個相同 Event 主題的
Concept為中心點，愈靠近中心點的詞彙，其詞彙
之間的語意距離關係度愈強，反之，距離中心點愈
遠的 Concept 則愈弱。由於專家建構 Domain
Ontology是以「Who」、「When」、「Where」、「What」、
「How」五個層級建構的，因此模糊變數 SD
Similarity 之計算將個別分開計算五個層級的詞彙
語意距離，距離界定在 [0, 10]之間。Semantic
Distance Similarity 訂 有三個語意項分別為
SD_High、SD_Median以及 SD_Low。
第二層的每一個模糊變數是以一個預先假設
的條件節點呈現， 每一個條件節點的輸出是連結
至第三層的模糊推論規則節點，以組成模糊規則庫
的前項假設部分。在這一層級是執行第一個推論步
驟，即計算三個輸入模糊變數的每個模糊語意項之
隸屬程度(Matching Degree)。
 Layer 3 (Rule Layer)
第三層級是規則層，每一個節點代表用以表示
一條模糊推論規則，這一層級的連結完成模糊邏輯
規則前項假設的Match，因此，規則節點必須執行
模糊 AND運算，且其輸出必須連結至第四層級的
關連語意節點。在本計畫的機制中，推論規則是預
先由領域專家所定義的，如表 1 所顯示，(Eq. 2)
表示規則節點 1所對應之Matching Degree：
)( 2 SD_Low-11
2
TW_Low-11
2
POS_Low-11
3
1 u,u,uminμ 
(Eq. 2)
表 1 Fuzzy Inference Mechanism之推論規則
Fuzzy variables
Rules
POS
Similarity
TW
Similarity
SD
Similarity TRS
1 L L L VL
2 L L M L
3 L L H L
4 L M L L
5 L M M L
6 L M H M
7 L H L L
8 L H M M
9 L H H H
10 M L L L
11 M L M L
12 M L H M
13 M M L L
14 M M M M
15 M M H L
16 M H L M
17 M H M H
18 M H H H
19 H L L L
20 H L M M
21 H L H H
22 H M L M
23 H M M H
24 H M H H
25 H H L H
26 H H M H
27 H H H VH
VL:Very Low L:Low M:Median H:High VH:Very High
 Layer 4 (Output Term Layer)
第四層的輸出節點是執行模糊 OR 運算來整
合有相同後項的模糊規則，第四層有一模糊變數語
意關聯強度(TRS)，其中 TRS有五個語意項分別為
TRS_Very_Low 、 TRS_Low 、 TRS_Median 、
TRS_High和 TRS_Very_High。假設有 r 條規則推
論到相同的結果，對應到輸出語意項為 Low, 則其
對應計算得到的重心值為 LowV , 而詞組 ijX 的第
四層輸出如下所示：




r
1p
3
p_kij
r
1p
kijLow
3
p_kij
4
kijLow_
μ
Vμ
μ
P _
(Eq. 3)
 Layer 5 (Output Linguistic Layer)
Output Linguistic Layer 主要是完成解模糊化
以取得每個詞組的 TRS 值，在本研究中採用重心
法以實行解模糊化的處理。最後，事件 1E 的詞組
ijX 之語意關聯強度(TRS)值 ijEy 1 如下所示：








r
1p
c
1q
4
pq_kij
r
1p
c
1q
pq_kij
4
pq_kij
jiE
μ
Vμ
y
1
(Eq. 4)
當 r 代表規則節點數， c 是輸出模糊變數之
語意項數，而 c 是第 q 個關連到 p 條推論規則的
重心。
 Layer 6 (Summation Layer)
Summation Layer 主要是計算特定 Concept
jC 在某事件中的 TRS值，其輸入向量如下：
)},,(,),,,(),,,{(
11111111 1221111 mnEnEmEEmEE
yyyyyy 
(Eq. 5)
ijEy 1 為第一個事件中的第 j 個 Concept 和第 i
個詞彙 iET 1 間的 TRS值，Summation處理如下：
The algorithm of Sentence Generator
Input:
A temporary fuzzy ontology TFO & a set of
sentence paths.
Output:
A set of sentences.
Method:
For i←1 to m { /* m denotes the
number of sentence paths in the sentence path set P
*/
Compute the number in of concepts in the
sentence path iP . /* iP denotes the i-th
sentence path of P */
For j←1 to in {
iw ←1. /*
iw denotes the possibility of the sentence iS */
If j =1 then { /*
iS denotes the i-th sentence */
Get all information of concept jC
from the temporary fuzzy ontology.
iw ← iw × kj EC .}
/*
kj EC
 denotes the membership degree of
j -th
concept of iP in k -th event */
Else {
Get all information of concept jC
from the temporary fuzzy ontology.
Get a relation
jj CC
R
1
between
1jC and jC from the temporary fuzzy ontology.
Use the relation
jj CC
R
1
to
connect 1jC with jC and store them into iS .
iw ← iw × kj EC .}
}
If iw of the sentence iS > threshold {
Combine the sentence iS with iw and
store them into the sentence set.}
}
End.
Sentence Generator處理結果表示如下：
Sentence Si: [Concept Name, Attribute_value,
Operation]→Relation→[Concept Name, 
Attribute_value,
Operation]→Relation→…→[Concept Name, 
Attribute_value, Operation] (Possibility iw )
B. Sentence Filter
Sentence Filter主要是過濾重複的句子，它
會產生一個簡單的句子集合且會結合相似的句
子以及轉換成一個有語意的句子。Sentence Filter
演算法如下所示：
The algorithm of Sentence Filter
Input:
A sentence set generated by Sentence Generator &
the news retrieved by the retrieval agent.
Output:
The summary results of the news.
Method:
Sort the length of each sentence of the sentence set
descending in order.
For i←1 to q { /* q
denotes the number of the sentences in the sentence
set S */
For j← 1i to q {
iA ←.
jA ←.
If iS =Null or jS =Null {
Divide iS into iA .
/* iA denotes a set with the concepts of the
sentence iS */
Divide jS into jA .
/* jA denotes a set with the concepts of the
sentence jS */
If ij AA  then {
Delete jS from S .}
}
}
}
Add the date of the retrieved news to FS .
/* FS denotes the summary results of the
news */
Add the event title of the retrieved news to FS .
For k←1 to q {
SS←. /* SS denotes
the semantic sentence */
Divide kS into kA . /* kA denotes a
set with the result of the sentence kS in the sentence
set S */
For m←1 to 
kAn { /* kAn
denotes the number of kA */
SS← mISS .} /* mI
denotes the m-th conepts or relations of kA */
Add SS to FS .
}
Compute the compression rate based on S and the
news, and add it to FS .
Compression rate =
N
SS
newsretrievedthethewordsThe
ofwordsThe
.
Store FS into the summary repository.
End.
參考文獻
[1] D. Beneventano, S. Bergamaschi, F. Guerra
and M. Vincini, “Synthesizing an Integrated 
Ontology,” IEEE Internet Computing, Vol. 7, 
No. 5, pp.42–51, Sept-Oct 2003.
[2] H. V. Halteren, “New Feature Sets for 
Summarization by Sentence Extraction,” 
IEEE Intelligent Systems, Vol. 18, No. 4,
pp.34-42, Jul-Aug 2003.
[3] A. Maedche, B. Motik, L. Stojanovic, R.
Studer, R. Volz, “Ontologies for enterprise 
knowledge management,” IEEE Inteligent
Systems, Vol. 18, No. 2, pp.26–33, Mar-Apr
2003.
[4] M. A. Rodriguez and M. J. Egenhofer,
“Determining Semantic Similarity among 
Entity Classes from Diferent Ontologies,” 
IEEE Transactions On Knowledge And Data
Engineering, Vol. 15, No. 2, pp.442-456,
Mar-Apr 2003.
[5] R. Navigli, P. Velardi and A. Gangemi,
“Ontology Learning and Its Application to 
Automated Terminology Translation,” IEEE 
Intelligent Systems, Vol. 18, No.1, pp. 22-31,
Jan.-Feb. 2003.
[6] H. Alani, S. Kim, D. E. Millard, M. J. Weal,
W. Hall, P. H. Lewis and N. R. Shadbolt,
“Automatic Ontology-Based Knowledge
Extraction from Web Documents,” IEEE 
Intelligent Systems, Vol. 18, No. 1, pp.14-21,
Jan.-Feb 2003.
[7] Chinese Knowledge Information Processing
Group, Academic sinica, Taiwan, 2003.
http://godel.iis.sinica.edu.tw/CKIP/
[8] D. L. Mcguinness, R. Fikes, J. Hendler and L.
A. Stein, “DAML+OIL: an ontology 
language for the Semantic Web,” IEEE 
Intelligent Systems, Vol. 17, No. 5, pp.72–80,
Sep-Oct 2002.
[9] A. Gomez-Perez and O. Corcho, “Ontology 
languages for the Semantic Web,” IEEE 
Intelligent Systems, Vol. 17, No. 1, pp.54-60,
Jan-Feb 2002.
[10] W. Lam and K. S. Ho, “FIDS: An Inteligent 
Financial Web News Articles Digest System”, 
IEEE Trans. on SMC-part A, Vol.31, No. 6,
pp.753-762, Nov 2001.
[11] R. E. Filman and S. Pant, “Searching the 
Internet,” IEEE Internet Computing, Vol. 2, 
No. 4, pp.21-23, 1998.
[12] V. N. Gudivada and V. V. Raghavan,
“Content-Based Image Retrieval Systems,” 
IEEE Computer, Vol. 28, No. 9, pp.18-22,
1995.
[13] N. R. Adam, “Content-Based Retrieval in
Digital Libraries,” IEEE Computer, Vol. 31, 
No. 1, 1998.
[14] B. H. Lee, “Embedded Internet Systems: 
Poised for Takeof,” IEEE Internet 
Computing, Vol. 2, No. 3, pp.24-29, 1998.
[15] M. N. Huhns and M. P. Sing, “Personal 
Agents,” IEEE Internet Computing, Vol. 2, 
No. 5, pp.90-93, 1998.
[16] R. Khare and A. Rifkin, “XML-A Door to
Automated Web Applications,” IEEE Internet 
Computing, Vol. 1, No. 4, pp.78-87, 1997.
[17] M. P. Singh, “Agent Communication 
Languages: Rethinking the Principles,” IEEE 
Computer, Vol. 31, No.12, pp. 40-48, 1998.
[18] A. Prasad and E. K. Park, “AI-based
Classification and Retrieval of Reusable
Software Components,” IEEE Software, pp. 
519-523, 1993.
[19] J. van Rijsbergen, “Information Retrieval, 
London and Tonbridge, “Butetworth & Co 
Ltd, 1975.
[20] S. Miyamoto, “Fuzzy retrieval as general
knowledge for information retrieval and
classes of relevance,” Proc. Of 2nd IFSA 
Congress,Tokyo, pp.719-722, 1987.
[21] S. Miyamoto, “Information retrieval based on 
fuzzy associations,” Fuzzy Sets and Systems, 
Vol. 38, pp.191-205, 1990.
[22] S. Miyamoto, “Two Approaches for 
Information Retrieval Through Fuzzy
Associations,” IEEE T. Systems, Man, and 
Cybernetics, Vol . 19, No. 1, pp.123-130,
1989.
[23] S. Miyamoto and K. Nakayama, “Fuzzy 
information retrieval based on a fuzzy
pseudothesaurus,” IEEE Trans. Systems Man
Cybernetics, Vol. 16, No. 2, pp.278-282,
1986.
[24] S. Miyamoto, T. Miyake and K. Nakayama,
“Generation of a Pseudothesaurus for 
information retrieval based on cooccurrences
and fuzzy set operations,” IEEE Trans. 
Systems Man Cybernetics, Vol. 13, No. 1,
pp.62-70, 1983.
[25] S. M. Chen and J. Y. Wang, “Document 
Retrieval Using Knowledge-Based Fuzzy
Information Retrieval Techniques,” IEEE T. 
Systems, Man, Cybernetics, Vol. 25, No. 5,
pp.793-803, 1995.
[26] Tahani, “A conceptual framework for fuzzy 
query processing: a step toward very
inteligent database systems,” Inform. Process. 
And Management, 13, pp.177-200, 1997.
[27] Y. C. Chou, “Inteligent information retrieval 
agent with neuro-fuzzy approach,” Thesis for 
master degree, 1998.
[28] J. T. Kim and D. I. Moldvan, “Classification
and Retrieval of Knowledge on a Parallel
Marker-Parsing Architecture,” IEEE Trans. 
On Knowledge and Data Engineering, Vol. 5,
No. 5, pp.753-761, 1993.
[29] J. T. Kim and D. I. Moldvan, “Acquisition of 
Linguistic Patterns for Knowledge-Based
Information Extraction,” IEEE Trans. On 
Knowledge and Data Engineering, Vol. 7, No.
