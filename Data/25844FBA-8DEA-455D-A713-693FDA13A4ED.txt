特定應用導向多處理器系統單晶片設計方法(I) 
“A Study of Application-Specific Instruction-set Processors for System-on-Chip” 
計畫編號：NSC 96-2221-E-035 -103 
執行期間：96 年 8 月 1 日 至 97 年 7 月 31 日 
主持人：王益文 逢甲大學資訊工程學系副教授 
 
一、 中文摘要 
本計畫藉由對特定應用程式行為的了解
和分析，使嵌入式系統設計更有機會達到依客
戶的需求“量身定做＂。由於產品上市時間的
快速加上產品生命週期的縮短，針對特定類型
應用的多樣性需求，使得我們迫切需要快速的
設計與評估，找出能夠有較好的效能、較少的
電力，及低成本的多重處理器系統單晶片架
構。 
本計畫有系統地探討設計方法論與開發
工具，提出多階層方式整合執行從應用程式的
切割分配與排程對應到不同的特定應用指令
集處理器，並同時對每一個特定應用指令集處
理器作最佳化。另外，我們也可能研究軟體在
任務階層的管線化，以期增加平行化運算的程
度與提供更好的方式來達成多重處理的概念。 
英文摘要 
Shrinking time-to-market, coupled with 
short product lifetimes create a critical need for 
rapid exploration and evaluation of candidate 
Multi-Processor System on Chip (MPSoC) 
architectures for a given set of applications to 
meet the diverse requirements, such as the better 
performance, lower power, low cost etc. 
Application-specific heterogeneous 
multiprocessors will be started from this project. 
Multilevel methodologies to perform the 
assignment and scheduling of the application 
tasks on the various ASIPs together with 
processor application-specific instruction-set 
customization in an integrated environment will 
be proposed. It is also possible to explore 
task-level software pipelining to further increase 
the parallelism in the task graph and provide 
opportunities for multiprocessing. 
 
二、 計畫的緣由與目的 
Embedded systems present a tremendous 
opportunity to customize designs by exploiting 
the application behavior. The main motivating 
factors behind investigating the methodologies 
for heterogeneous MPSoC, are the great amount 
of parallelism present in several embedded 
applications and nanometer technology trends.   
Application-Specific heterogeneous MPSoCs 
offer high levels of performance and flexibility 
and at the same time promise low-cost, reliable 
and power-efficient implementations.  
Nanometer fabrication technologies now have 
made it feasible to create MPSoCs for a wide 
range of applications. 
A primary bottleneck is the development of 
programming paradigms and tools to alleviate 
the design complexity. The design complexity of 
heterogeneous MPSoCs will be increased 
tremendously, which poses many challenges for 
mapping of an application to the heterogeneous 
MPSoC architecture. 
 
三、 研究方法及成果 
The following research activities are 
accomplished in the 1st year to achieve the 
success of this research project: 
Problem Formulations 
Micro-architecture models 
The basic instruction set of ASIPs is 
enhanced by ASIs that use special-purpose 
hardware. However, micro-architecture 
 1
Given a graph G+ and the microarchitectural 
features Nin, Nout, and F, find the cut S, which 
maximizes M(S) under the following constraints: 
1) IN(S) ≤ Nin; 
2) OUT(S) ≤ Nout; 
3) F ∩ S = ∅  ;  
4) S is convex. 
Problem 2 (Selection):  
Given the graphs G+i of all basic blocks and the 
microarchitectural features Nin, Nout, and F, find 
up to Ninstr cuts Sj which ∑j M(S)j under the same 
constraints of problem 1 for each cut Sj . 
Problem 3 (Multiple-Cut Identification):  
Given a graph G+ and the microarchitectural 
features Nin, Nout, and F, find the K disjoint cuts 
Sj which ∑j M(S)j under the following constraints 
for each cut Sj : 
1) IN(Sj) ≤ Nin; 
2) OUT(Sj) ≤ Nout; 
3) F ∩ Sj = ∅ ; and 
4) Sj is convex. 
Primitive Compilation Infrastructure 
GCC 
The GNU compiler collection [5] is a 
robust open-sourced compilation platform aimed 
to be portable to any machine with integer type. 
GCC is retargetable through the “machine 
description”, which describes instruction set 
information. A “target macro” is used to describe 
target architecture features such as register files, 
endianess, storage layout, etc. 
The figure 3 shows the overall ASIP design 
flow using GCC. The profiling data of 
application programs will be generated with the 
information about the execution count of each 
basic block. Then the application programs will 
be translated to RTL for ASI generation and ASI 
selection. The GCC MD will be modified as 
customized ASIP according to the selected ASIs 
and the GCC compiler of this customized ASIP 
will be generated. Then the application programs 
will be recompiled by the customized ASIP GCC 
compiler to generate the executable file. Finally 
the executable file will be executed on the 
simulator to analyze the experimental results. 
Trimaran 
Trimaran [6] is a compiler infrastructure for 
Instruction Level Parallel (ILP) architectures. 
The system is oriented towards EPIC (Explicitly 
Parallel Instruction Computing) architectures, 
instruction scheduling, register allocation, and 
machine-dependent optimizations. The Trimaran 
system is based on the HPL-PlayDoh 
architecture which is a parametric processor 
architecture. 
Application-specific instructions are needed 
to describe the latency of the new operation, as 
well as the resources used. It is necessary to 
define the graph for the Elcor pattern matcher as 
well as to utilize a machine description of the 
graph to find all instances that occur in the IR, 
and replaces them with the new instruction. Any 
occurrences of the graph that are found in the 
application are replaced automatically with the 
new operation. However we must still modify 
Simu, the simulator of trimaran framework, to 
recognize the new opcode. 
Multiprocessor and ASIP Simulator 
ISIS and osiris 
The osiris library is the linking library of 
ISIS multiprocessor simulation library [7] 
developing by Keio university. Figure 4 is one 
example of the simulated architecture of ISIS 
simulation library. The CPUs in figure 4 is the 
ASIPs which generated by our design flow. The 
 
Figure 3. The ASIP Design Flow 
 
Figure 4. System calls methodology of ISIS 
multiprocessor simulation library. 
 3
出席國際學術會議心得報告 
                                                             
計畫編號 NSC 96-2221-E-035-103 
計畫名稱 特定應用導向多處理器系統單晶片設計方法(I) 
出國人員姓名 
服務機關及職稱 
王  益  文 
逢甲大學  副教授 
會議時間地點 
97 年 7 月 29 日起至 97 年 7 月 31 日止 
Chengdu, Sichuan, China 
會議名稱 
The 2008 International Conference on embedded Software and Systems
(ICESS-2008 ) 
發表論文題目 Performance Improvement using Application-Specific Instructions under Hardware Constraints  
 
一、 參加會議經過 
ICESS-08 包含了一場主會議，及三場座談會。其內容不但有嵌入式系統的傳統核心
領域還有新的特殊議題，如：sensor networks, HW/SW co-design and SoC, wireless 
communications, power-aware computing, security, 以及 multimedia. 在這次研討
會中，共有三場主要演講。第一場演講是針對中國的五年國家基礎研究計畫在 Wireless 
Sensor Networks 項目中，做了一個綜合的介紹。其中對於 wireless sensor network
做一個有系統的探討，包括從 node platform development, core protocol design 以
及 system solution development 到 critical problems。第二場演講則是對於如何最
佳化應用平行度，如何減少 memory overhead，以及如何減少 power consumption 等問
題，給與會者們作了一些基本概念的說明。最後則是針對中國設計高效能
general-purpose microprocessors 方面的簡略的介紹。 
ICESS-08 在來自十個以上不同的國家或區域的 483 篇的投稿中，共有 90 篇論文被
接受，接受率為 18%。其它有 93 篇論文被選為 Poster(Symposia)。 
我們的論文被選定在 session 15, 標題為"Compilation and Application-Specific 
Instruction Set"中來發表，時間為 2008 年 7 月 30 日的下午 3點 20 分，主持人則是上
海交通大學的 Yongxin Zhu 教授。 
 
二、與會心得 
在這次的會議中，因為大部分的作者是來自中國大陸，讓我們對於現在中國的研究
情況有所了解。他們不僅著手在基礎的研究議題上，也處理實際的應用問題，對於解決
複雜研究問題的能力也在持續成長中。 
但對於大型會議的行政處理經驗還不足。主持人並沒有流暢地主持整場會議，因此
會議有被延遲的情況發生。因此在發表論文期間我們並沒有太多的時間可以跟其他作者
討論。然而，會後與其他學者專家討論一些有趣的概念，像是“Optimizing Memory Bank 
Performance Improvement using Application-Specific Instructions under 
Hardware Constraints 
 
Chijie Lin, Jiying Wu, Jerung Shiu, Desheng Chen and Yiwen Wang 
Department of Information Engineering and Computer Science, Feng Chia University  
Taichung, Taiwan 
 
 
Abstract 
 
An Application-Specific Instruction-set Processor 
(ASIP) is a technique that exploits special 
characteristics of application(s) to meet the desired 
performance, cost and power requirements. The 
generation and selection of Application-Specific 
Instructions (ASIs) dramatically affect the quality of an 
ASIP with design constraints such as number of 
register file I/Os and hardware cost. In this paper, a 
design flow is developed to automatically combine the 
disjoint operations as an ASI to enrich the selection 
varieties. The operation cover-ratio and the ASI 
latency model are used to select profitable ASIs so that 
the performance can be improved. The experimental 
results show the maximal 1.64x speed up can be 
obtained under hardware cost less than 8000 LEs in 
Altera FPGA. 
 
1. Introduction 
 
An Application Specific Instruction Processor 
(ASIP) is a processor designed for a particular 
application or for a set of applications. An ASIP 
exploits special characteristics of application(s) to meet 
the desired performance, cost and power requirements. 
ASIPs are a balance between two extremes: ASICs and 
general programmable processors. Since an ASIC is 
specially designed for one behavior, it is difficult to 
make any changes at a later stage. In such a situation, 
the ASIPs offer the required flexibility at lower cost 
than general programmable processors. 
ASIPs are often composed of a standard 
microprocessor with a simple instruction set that can 
be augmented with Application-Specific Instructions 
(ASIs) so that the critical parts of the application can 
be run in hardware, in application-specific functional 
units (AFUs). Extending a RISC kind of processor, 
imposes the following constraints. First, RISC 
processor is based on Load/Store architecture. Any 
functional unit can not directly access memory. Hence, 
an ASI should not have load/store operations that need 
to access memory. Second, in a legal subgraph S none 
of its input operand should be dependet on an output of 
the subgraph, i.e if all the operations of S are collaped 
into single operation in the basic block BB containing 
S, the resulting DFG graph of BB should not contain 
cycles. Last, In a standard RISC architecture, the inputs 
and outputs of an functional unit are communicated at 
the beginning and completion of its execution 
respectively. This implies the number of inputs and 
outputs of an AFU are constrained by the number of 
register read and write ports respectively. The 
automation offered by these processor toolchains is 
increasing, and source code analysis techniques have 
been proposed to identify the most profitable ASIs for 
a given application.  
In this paper, a design flow is presented for 
automatic Application-Specific Instructions generation 
to improve performance under constraints, such as 
number of register file I/Os and hardware cost. The 
selection of ASIs with hardware cost consideration 
affects the quality of an ASIP design. The operation 
cover-ratio and the ASI latency model are used to 
select profitable ASIs so the performance can be 
improved. 
The rest of this paper is organized as follows. 
Section 2 describes the related work. Section 3 presents 
the problem formulation and design flow overview. 
Section 4 explains our methodology of application-
specific instructions generation and selection. The 
experimental result will be shown at section 5, and 
section 6 is the conclusion. 
 
2. Related Work  
 
Customizing a processor's instruction set exploits 
the observation that recurring subgraphs frequently 
exist in the dataflow graphs (DFG) of applications. By 
implementing these frequently occurring subgraphs in 
hardware as instructions, performance improves, code 
size decreases, and energy consumption is reduced. 
Normally, the ASIP design can be divided into three 
major steps: template generation, candidate selection, 
the final DFG. Once the ASIs were selected, the 
templates in CFG were replaced to ASIs in P9. 
 
 
Figure 2. DFG generation of MachSUIF 
 
3.4 Template and candidate generation 
 
In template generation, each node (instruction) in a 
DFG is traced by top-down sequence. Then, a template 
is generated by combing the current node with its 
predecessors and all templates generated by the 
predecessors. The disjoint templates could be 
generated when combing the predecessors and the 
templates without the current node. For example in 
Figure 3, if the current node is node 5, then the 
predecessors node 1,3,2 and 4 are clustered as the 
disjoint template. In the current work, only partial 
disconnected subgraphs in a DFG which have the same 
successor are searched in order to keep data 
dependency. 
 
 
Figure 3. The disjoint template 
 
No memory-access and branch instructions are 
allowed in templates. A convex subgraph S is a subset 
of nodes, such that for every pair of nodes u, v ∈ S, 
every path from u to v in the graph consists solely of 
nodes in S. The subgraph has to be convex in order to 
keep data-dependence. Figure 4 is an example of 
convex subgraphs, if the input/output constraints are 
10/10, the T2 which contains node 1, 3 could be a 
template. The T3 which contains node 2, 4, 5 is a non-
convex graph because there is a path from node 2 to 
node 5 through node 3 which is not contained in the 
subgraph. So, T3 is not a valid template. T1 contains 
node 1-6 is the largest template, the node 2, 4, 6 are the 
critical path, so the hardware latency is 28.5 
(9.5+9.5+9.5). Node 7 will not be a template because it 
is a memory store operation. After all templates of 
each DFG are generated, the templates isomorphism 
checking is performed to produce candidates. 
 
 
Figure 4. An example of convex subgraphs 
 
The hardware library is used to estimate the 
template attributes like hardware critical path latency, 
hardware cost and software executing cycles, etc. The 
hardware cost of a template is estimated as the 
summation of all nodes in the subgraph. Table 1 is the 
example of the hardware library. 
Table 1. The Example of hardware library 
Opcode Software executing cycle 
Hardware 
latency 
Hardware 
cost 
ADD 1 0.4 1 
MUL 10 9.5 7 
STR 2 - - 
 
3.5 Candidate selection and application 
replacement 
 
Our strategy used for candidate selection is a simple 
priority based method. A merit function, equation 1, is 
used to rank all the candidates in descending order. RT 
is the reduced time after utilizing ASIs. Tsw is the 
software execution cycle count. Thw is the critical path 
latency in hardware. RrepeatingTimes is the execution 
