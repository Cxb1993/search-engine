 2
目    錄 
 
一、研究背景及動機 ...................................................................... 3 
二、文獻探討 ................................................................................. 3 
三、研究方法概述.......................................................................... 4 
四、結果與討論 ............................................................................. 5 
五、計畫成果自評........................................................................ 17 
參考文獻 ...................................................................................... 18 
 
 4
個。[4]提出一個透過限制物件為無色的並且為單純反射的，採用[3]提出的背景影像和演算
法，可以擷取動態變化物件的 matting model。 
    在 Wexler[7],提出一種不需要預先知道背景就可以計算出 matting model 的演算法，他
們透過一張固定的背景圖跟物件做不同位置的變化，採用”幾何認證”(geometric registration)
的方式找出背景圖在物件後方的相對位置以及光線折射的區域。當要去選取能容納的區域
時，將因為物件本身的形狀和物理特性和背景圖的內容和訓練的影像數量影響到建立
matting model 的困難度和合成後影像的品質。 
    在 Peers[8],採用”訊息回傳”(feedback)分析方式，使用微波圖作為分析時的背景，由最
小的水平面的微波圖開始依序秀在物件後方的螢幕上，每改變一次背景便由數位相機紀錄
顏色的變化，並去分析在這個階段的微波圖對於場景照明的影像程度，由這個階段分析的
結果來決定下一個階段的微波圖，因此事先設定允許的誤差值將直接影響到返回訊息分析
的次數，當物件的折射和反射特性越來越複雜時，需要相機記錄的資料和返回訊息分析的
次數也會隨之變多。 
    在 Zhu[9],他們將背景圖形分成 row-base 和 column-base 兩種類型，不同的類型位置給
定一個固定的頻率，因此背景上的畫素值隨不同的相機記錄時間而改變，使用相機記錄完
所有背景變化的影像後使用 DFT 轉換分析在不同頻率的影響，然後由 row-base 和
column-base 交集的矩形區域在 row-base 和 column-base 分析後的正規劃處裡交乘方式來求
得物件的 matting model。 
    在本計畫中中，我們擬採用 frequency-based 分析的方法來分析透明物體的物理模型。
因為 frequency-based 分析的方法比 space-based 分析的方法對於有雜訊的訊號有更好的處理
能力，我們延伸 Zhu[9]提出的方法，然後再採用我們所提出更精確的方法對合成影像的品
質做進一步的改善。 
 
 
三、研究方法概述 
   傳統的數位影像合成，顏色 C 產生的方式為前景的顏色 F 乘上 alpha channel α，再加上
背景顏色 B 乘上 1 減 alpha，整個方程式稱為“Matting Equation” [1] 用來對各個畫素作計算 : 
BFC ×−+×= )1( αα              (1) 
在 Matting 方程式下，一個 alpha 通道在傳統上有兩個腳色：他是同時在表現前景畫素的涵
蓋範圍和不透光的部分。在我們的應用上，因為在前景的區域是採用分析方式找出呈現面
光源影響的權重表，在不是前景的區域是將世界座標下的背景經由座標轉換到成像平面的
座標作為合成影像的背景，所以我們忽略分數的 alpha channel 值只需要考慮影藏跟沒以影
藏的前景元素。因此，若為不為前景的畫素的 alpha channel 為 0，而前景涵蓋的部分的 alpha 
channel 就為 1。 
    傳統上的數位影像組合，前景的顏色可以產生一個區塊的兩個不同組成: 
1. 由前景自己產生。 
2. 反射或是折射來自光源環境的。 
在我們的方法下，我們可以使用一個新的結構去擷取前景環境中光源的反射和折射。訂出
新的定義方式稱為“Environment Matting Equation” : 
Φ+−+= ααα gBRFC ˆ)1(           (2) 
而 C 表示為呈現面記錄的結果。F 表示為前景的 color。α  用來表示為背景是否有被前景
覆蓋，若α =0 表示為背景的位置，α =1 表示為前景物件的位置。 gBˆ  表示原來 mn ×  畫素
的背景影像 Bg 經由呈現面記錄後，因為世界座標和成像座標間的座標空間轉換將世界座標
中的 Bg 變成成像座標中的 mn ′×′  畫素的影像 gBˆ 。R  表示為光源發射位置到呈現面之間光
線衰減的比例，在顏色系統中 BGR ,, 三個 channel 分別用 RR , GR , BR 三個參數來表示。Φ表
示前景在任何環境光源下的反射或是折射所產生的影響。 
 6
 
Figure 2 FFT 後的 spectrum 
 
Figure 3～9 的(a)所示，為實際一個透明玻璃杯放在 LCD 螢幕前方，並且在 LCD 螢幕
秀十張不同的背景圖由 digital camera 紀錄下來的 image。在這邊我們先忽略影像中的 pixel
位置是否為 object area，我們單純去設定一個矩型的區域，在這個矩型區域內分別使用
without and with The Kaczmarz Method 分析每一個 pixel 的 weight tables。 
 
Figure 3 (b)~(c)所示，為 threshold 設定為 max/2 分別 with and without The Kaczmarz 
Method 的 compositing image。Figure3 (d)~(e)所示，為 threshold 設定為 max/4 分別 with and 
without The Kaczmarz Method 的 compositing image。 
Figure 3 (f)~(g)所示，為 threshold 設定為 max/8 分別 with and without The Kaczmarz Method
的 compositing image。Figure 3 (h)~(i)所示，為 threshold 設定為 max/16 分別 with and without 
The Kaczmarz Method 的 compositing image。Figure 3 (j)~(k)所示，為 threshold 設定為 max/32
分別 with and without The Kaczmarz Method 的 compositing image。Figure 3 (l)~(m)所示，為
threshold 設定為 max/64 分別 with and without The Kaczmarz Method 的 compositing image。
Figure 3 (n)~(o)所示，為 threshold設定為max/128分別with and without The Kaczmarz Method
的 compositing image。在 Figure 4 ~ 9 分別為另外六張背景影像合成的結果。 
 
比較 PSNR 時，使用實際拍攝的 image 當作參考影像，分別和 without and with The 
Kaczmarz Method 的 compositing image 計算 PSNR。Figure 3 所示，為分別使用 without and 
with The Kaczmarz Method 然後在不同 threshold 下，用十張不同新背景合成新影像後和參考
影像比較計算得到的 PNSR 值，最後取這些 PSNR 值的平均值可以得到 threshold vs. PSNR
的曲線。 
 
由 Figure 3 的結果看出 with The Kaczmarz Method 明顯可以改善合成影像的品質。在比
較高的 threshold 時（例如：max/2），因為光源貢獻位置只限制在貢獻最多的幾個位置，因
此 PNSR 直會稍微低一些。而在比較低的 threshold 時（例如：max/128），因為 LCD 螢幕
或是 digital camera 或是在電腦運算時的捨位誤差等不能抗拒因素的影響，造成在 FFT 分析
的結果會理論上不會存在的 noise 產生。如 Figure 2 中 FFT 分析的 spectrum 所示，在一些
原來沒有 contribution 的頻率產生有一些 magnitude 的存在，所以當 threshold 時設定太低時
也會造成的 PSNR 值變差。而在 with and without The Kaczmarz Method 兩種作法的 PSNR
表現，可以看出經由 with The Kaczmarz Method 可以提升合成後影像的品質。另外，我們
觀察 Figure 3～9 的(a)裡，在屬於 object 的區域內有些部分是全部黑色並不會因為背景圖改
 8
(j)  (k) 
(l)  (m) 
(m) (o) 
Figure 2 第一張背景影像 (a)新背景和 object 實際拍攝的 image. (b) ~ (o) with and without 
The Kaczmarz Method 在不同 threshold 的結果. 
 
(a) 
(b) (c) 
(d) (e) 
(f) (g) 
(h) (i) 
(j)  (k) 
 10
(n) (o) 
Figure 4 第三張背景影像 (a)新背景和 object 實際拍攝的 image. (b) ~ (o) with and without 
The Kaczmarz Method 在不同 threshold 的結果. 
 
(a) 
(b) (c) 
(d) (e) 
(f)  (g) 
(h) (i) 
(j) (k) 
(l)  (m) 
(n) (o) 
Figure 5 第四張背景影像 (a)新背景和 object 實際拍攝的 image. (b) ~ (o) with and without 
The Kaczmarz Method 在不同 threshold 的結果. 
 12
(a) 
(b) (c) 
(d) (e) 
(f) (g) 
(h) (i) 
(j)  (k) 
(l)  (m) 
(n) (o) 
Figure 7 第六張背景影像 (a)新背景和 object 實際拍攝的 image. (b) ~ (o) with and without 
The Kaczmarz Method 在不同 threshold 的結果. 
 
 14
(a) 
(b)  (c) 
(d) (e) 
(f)  (g) 
(h) (i) 
(j)  (k) 
(l)  (m) 
(n) (o) 
Figure 9 第八張背景影像 (a)新背景和 object 實際拍攝的 image. (b) ~ (o) with and without 
The Kaczmarz Method 在不同 threshold 的結果. 
 
 
 
 16
 
(e)         (f) 
 
(g)         (h) 
Figure 13 Object’s motion 
 
 
(a)         (b) 
 
(c)         (d) 
 
(e)         (f) 
Figure 14 Object’s scale 
 
 18
影像 background 區域的影像解析度。 
在未來的工作上，目前我們分析一個 object 的 model 需要用 digital camera 拍攝一千多張的
照片，如果要建立 3D 的 model 所需要拍攝的照片更是巨大，因此後續朝減少 digital camera
拍攝張數和發展更快的分析演算著手，使得使用者能夠便利的且快速的獲得想要的 object
的 model。本計畫結果已整理成論文投稿至期刊，目前正在審查中。 
 
參考文獻 
[1] Thomas Porter and Tom Duff. Compositing Digital Images. In Computer Graphics , volume 
18, number 3, pages 253-259, July 1984. 
[2] Alvy Ray Smith and James F. Blinn. Blue Screen Matting. In SIGGRAPH, volume 30, pages 
259–268, 1996. 
[3] Douglas E. Zongker, Dawn M. Werner, Brian Curless, and David H. Salesin. Environment 
matting and compositing. In Proceedings of ACM SIGGRAPH 1999, pages 205–214, 1999. 
[4] Yung-Yu Chuang, Douglas E. Zongker, Joel Hindorff, Brian Curless, David H. Salesin, and 
Richard Szeliski. Environment matting extensions: Towards higher accuracy and real-time 
capture. In Proceedings of ACM SIGGRAPH 2000, pages 121–130, July 2000. 
[5] Wojciech Matusik, Hanspeter Pfister, Remo Ziegler, Addy Ngan, and Leonard McMillan. 
Acquisition and rendering of transparent and refractive objects. In Thirteenth Eurographics 
Workshop on Rendering, pages 267–277, 2002. 
[6]Wojciech Matusik, Hanspeter Pfister, Addy Ngan, Paul Beardsley, Remo Ziegler, and Leonard 
McMillan. Image-Based 3D Photography using Opacity Hulls. In SIGGRAPH 2002, pages 
427–437, July 2002. 
[7] Yonatan Wexler, Andrew W. Fitzgibbon, and Andrew Zisserman. Image-based environment 
matting. In Proceedings of EuroGraphics Workshop on Rendering 2002, pages 289–299, June 
26–28 2002.  
[8] Pieter Peers and Philip Dutre. Wavelet environment matting. In Proceedings of Eurographics 
workshop on Rendering 2003, pages 157–166, 2003. 
[9] Jiayuan Zhu and Yee-Hong Yang. Frequency-based Environment Matting. In Proceedings of 
the 12th Pacific Conference on Computer Graphics and Applications, 2004. 
[10] Avinash C. Kak and Malcolm Slaney. Principles of Computerized Tomographic Imaging. 
IEEE Press, New York, 1988. 
[11]K. Tanabe. Projection method for solving a singular system of linear equation and 
applications. In Numerical Mathematics, volume 17, pages 203-214, 1971. 
[12] Mark A. Ruzon and Carlo Tomasi. Alpha Estimation in Natural Images. In IEEE Conference 
on Computer Vision and Pattern Recognition 2000, Volume 1, pages 18-25, June 2000. 
[13] Yung-Yu Chuang, Brian Curless, David Salesin, and Richard Szeliski. A Bayesian Approach 
to Digital Matting. In Proceedings of CVPR 2001, Volume 2, pages 264-271, 2001. 
[14]Yung-Yu CHUANG, Aseem Agarwala, Brian Curless, David H. Salesin, and Richard 
Szeliski. 2002. Video matting of complex scenes. In Proceedings 
of ACM SIGGRAPH 2002, pages 243–248, 2002. 
[15] Wojciech Matusik, Hanspeter Pfister, Addy Ngan, Paul Beardsley, Remo Ziegler, and 
Leonard McMillan. Image-Based 3D Photography using Opacity Hulls. In Proceedings of ACM 
SIGGRAPH 2002, Volume 21 , pages 427 – 437, July 2002. 
[16] Andrew Fitzgibbon, Yonatan Wexler, and Andrew Zisserman. Bayesian Video Matting Using 
Learnt Image Priors. In International Journal of Computer Vision, Volume 63, pages 141 – 151, 
July 2005.  
[17] Jian Sun, Jiaya Jia, Chi-Keung Tang, and Heung-Yeung Shum. Poisson Matting. In ACM 
Transactions on Graphics, Volume 23, pages 315 - 321, August 2004. 
 
 
圖二 會議地點 
 
 
此會議三天的會議議程如下： 
 
PROGRAM OVERVIEW 
Monday, August 18, 2008  
07:00 – Registration  
08:00 (Lobby Rotunda)  
08:00 – Welcome Address  
08:30 (Keauhou I Room)  
08:30 Tutorial Presentation -  
“Nucleotide Genomic Signal Representation and Processing”  
(Keauhou I Room)  
10:00 - Coffee Break  
10:30 (Convention Center Foyer)  
10:30 Tutorial Presentation Continued  
13:00 - Keynote Speaker – “Real-Time  
14:00 Image Processing: From Research to Reality”  
(Keauhou I Room)  
14:00 Invited Speaker – “All-Optical  
Circuits for Ultrafast Information Processing and Computing”  
(Keauhou I Room)  
15:00 – Coffee Break  
15:30 (Convention Center Foyer)  
 2
Chairs: C. Mehmet and T. Yu  
Location: Keauhou I Room  
623-142  
Spatio-Temporal Correlation based Adaptive Rood Search for Block-Matching Motion 
Estimation  
Y. Luo and M. Celenk (USA)  
623-114  
Enhanced Exemplar-based Method for Image Inpainting  
I.-C. Chang and C.-W. Hsu (Taiwan)  
623-177  
Fast Motion Estimation of H.264/AVC by Adaptive Early Termination  
M.G. Sarwer, T.M. Nguyen, and Q.M.J. Wu (Canada)  
623-179  
4 x 4 SAD and SATD based All Zero Block Detection Algorithm in H.264/AVC  
Q. Liu, Y. Huang, and T. Ikenaga (Japan)  
623-191  
VLSI Oriented Group-based Algorithm for Multiply Reference Frame Fractional Motion 
Estimation in H.264/AVC  
W. You, Y. Ma, Y. Song, Y. Zhuang, T. Ikenaga, and S. Goto (Japan)  
623-190  
Half Pixel Cost Distribution based Simplified Fractional Motion Estimation  
Y. Huang, Q. Liu, and T. Ikenaga (Japan)  
623-058  
Fast VBSME Design using Reconfigurable Hardware Architecture and Search Range Reduction  
Y. Fan, T. Ikenaga, and S. Goto (Japan)  
623-055  
A Framework for Very High Performance Compression of Table Tennis Video Clips  
T.L. Yu (USA)  
623-098  
Related Pre and Post-Processing for All-Intra and Inter-Picture Coding  
K. Sugiyama, N. Sagara, and S. Moriya (Japan)  
 
10:00 – 10:30 COFFEE BREAK  
Location: Convention Center Foyer  
10:30 SESSION 8 CONTINUED 
 4
replication, by the conversion of random molecular movements into an ordered 
gradual advance of the enzyme along the DNA strand. 
 
Paul Cristea graduated the Faculty of Electronics of the "Politehnica" University of 
Bucharest in 1962, the Faculty of Physics of the University of Bucharest in 1969, and 
defended his Ph.D. in Physics at PUB in 1970. His research and teaching activities 
have addressed a wide range of fields related to Electrical and Electronics 
Engineering, including topics such as Genomic Signals, Signal and Image processing, 
Intelligent E-Learning Systems, Circuit Theory and Design, Computer Assisted 
Medical Equipment, Advanced Electrical Batteries and other. Prof. Cristea is author or 
co-author of more then 130 published papers, 11 patents, and contributed to more then 
20 books. He gave keynote or plenary talks to many international conferences, and 
was an invited professor to several European and US universities. Prof. Cristea is a 
Corresponding Member of the Romanian Academy, the director of the Biomedical 
Engineering Center of PUB, and the director of the Romanian Bioinformatics Society. 
 
（ 二 ） “REAL-TIME IMAGE PROCESSING: FROM RESEARCH TO 
REALITY”  
Presenter: Nasser Kehtarnavaz  
Location: Keauhou I Room  
 
Out of a considerable number of image processing algorithms that are developed in 
research environments, only very few get actually used in hardware or software 
products. There are many reasons for this lack of transition. One of the main reasons 
is the fact that image processing algorithms are often developed without considering 
the real-time constraints they ought to meet if they are ever going to be deployed in 
resource limited image or video processing products. This talk provides an overview 
of the guidelines and strategies for transitioning an image or video processing 
algorithm from a research environment into a real-time constrained environment. 
More specifically, the following topics will be covered: (a) algorithmic simplification 
strategies, (b) hardware platforms for real-time implementation, and (c) software 
optimization techniques. Various examples from the literature will be presented to 
more effectively convey the real-time strategies.  
 
Nasser Kehtarnavaz received the PhD degree in Electrical and Computer 
Engineering from Rice University in 1987. He is Professor of Electrical Engineering 
and Director of the Signal and Image Processing Laboratory at the University of 
Texas at Dallas (UTD). He is currently managing a Texas Instruments sponsored 
 6
and robust waveguide and/or all-fiber optics technologies, which could be readily 
incorporated in future integrated photonic circuits. This talk will provide an overview 
of the different designs for photonics temporal differentiation and integration recently 
demonstrated by our group. The potential of these developed basic devices for 
applications in all-optical computing and information processing, ultrafast coding and 
switching will be also discussed. 
 
José Azaña received the Telecommunication Engineer degree (six years engineering 
program) and Ph.D. degree from the Universidad Politécnica de Madrid (UPM), Spain, 
in 1997 and 2001, respectively. He completed part of his Ph.D. research at the 
University of Toronto (Canada) and University of California, Davis (USA).  
From September 2001 to mid 2003 he worked as a Postdoctoral Research Fellow at 
McGill University (Montreal, Canada). In 2003, he joined the Institut National de la 
Recherche Scientifique (INRS), a graduate degree - granting research institute in 
Montreal, where he currently works as a Professor-Researcher. His research interests 
focus on fiber and integrated technologies for ultrafast optical signal processing and 
optical pulse shaping, for various applications, including fiber-optics 
telecommunications, optical computing, measurement and characterization of ultrafast 
events and photonics/optoelectronic components and devices, biomedical imaging, 
and ultra-wideband (UWB) microwave waveform generation and processing. His 
research work has resulted in more than 160 publications in top scientific and 
engineering journals and leading conferences, including about 90 publications in 
high-impact ISI journals and various (co-)invited presentations.  
 
Prof. Azaña is a member of IEEE and OSA. He has served as a Guest Editor of the 
only two monographs entirely devoted to the emerging area of Optical Signal 
Processing, published by EURASIP Journal of Applied Signal Processing (2005) and 
IEEE Journal of Lightwave Technology (2006). Prof. Azaña was awarded with the 
XXII national prize for the "best doctoral thesis in data networks" from the 
Association of Telecommunication Engineers of Spain (2002) and with the 
"extraordinary prize for the best doctoral thesis" from his former university, UPM 
(2003). He is also the recipient of the 2008 IEEE-LEOS Young Investigator Award, 
recognizing outstanding scientific contributions to the area of photonics (broadly 
defined), for "pioneer contributions on innovative ultra-fast optical pulse processing 
techniques using all-fiber grating technologies".  
 
二、與會心得 
本次參加會議，除論文發表外也和一些與會學者交換意見，認為將 image 
 8
附錄：會議報告投影片 
1
ENHANCED EXEMPLAR-BASED 
METHOD FOR IMAGE INPAINTING
I-Cheng Chang and Chia-We Shu
National Dong Hwa University, Taiwan
2
Outline 
 Introduction 
Related Works 
Review of Criminisi’s Algorithm
 Proposed Algorithm
 Experimental Results 
Conclusions
 10
5Related works
 Texture analysis 
 Bertalmio[2003]
 Xiaowei Shao[2004]
 Possion Equation  and Laplacian 
 Decompose image into structure and texture 
components
 Blur in the result image
6
Concerned Problems of Image 
Inpainting
 How to reconstruct the texture and structure
information of the removed area?
 Texture information
 Searching region
 Structure information
 Filling order 
Onion Peel
 12
9Proposed Algorithm
 Provide a more reliable Priority value
 Structure Priority Value
 Better filling order to recover the structure 
information
 Change the update rule of confidence value
 Redefine the searching region
 Reduce the computation time
 Get the better texture information
( )SP p
10
Proposed Algorithm
 Filling Order (structure priority value         )
 Edge Ratio of a patch
( )SP p
( ) ( ) ( )SP p C p ER p= ×
( ) ( )
( ) q
q I
p
C q
C p
∈Ψ −Ω= Ψ
∑ ∩
( )
( )
( )
( )
( )
p
p
q I
q I
e q
ER p
C q
∈Ψ −Ω
∈Ψ −Ω
=
∑
∑
∩
∩
1
( )
0
e q ⎧= ⎨⎩
if q edge
otherwise
∈
Notation diagram
ˆ ˆarg min ( , ) , :SSD
q
q p qd dΨ ∈Φ
Ψ = Ψ Ψ
 14
13
Proposed Algorithm (cont.)
 Edge map extraction
 Canny edge
le eρ
Sobel edge map
(lower threshold ) 
Laplacian edge map
(higher threshold ) 
Canny edge map 
(default threshold)
Original image
14
Proposed Algorithm (cont.)
 Threshold adjustment 
where       is adjusted threshold ,         is adjustment value , 
and      are the original the lower and higher threshold of Canny 
edge, respectively  
Canny edge map
(higher threshold )
Original image
'  ,  
2
h l
l l e e
e ee e ρ ρ −= + =
le
he
eρ'le
Canny edge map 
(default threshold)
 16
17
Proposed Algorithm (cont.)
 Edge ratio around the boundary 
 The edge ratio           of these patches closed to  the 
boundary is assigned to zero.
 Half of the patch size
( )ER p
18
Experimental Results
 18
21
Experimental Results
Original image Target region 
Proposed algorithm
Criminisi’s algorithm
22
Experimental Results
Original image Target region  
Proposed algorithm Criminisi’s algorithm
 20
25
Experimental Results
Proposed algorithmOriginal image
Result of Wen (1)
Result of Wen (2)
26
Experimental Results (Texture  
Synthesized)
Original image
Original image 
Result of 
proposal algorithm
Result of Xiaowei
Result of 
proposal algorithm
Result of Bornard
 22
