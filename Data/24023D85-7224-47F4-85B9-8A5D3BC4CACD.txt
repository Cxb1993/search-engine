 中文摘要 
隨著Web的快速成長和普及，使用者會利用搜尋引擎從數百億的網頁中找尋相關資訊以供決
策。以使用者想到南投旅遊為例：到 Google搜尋 “南投 旅遊” 的關鍵字，結果出現 874,000
筆。當中絕大多數網頁可能都是和使用者目的無關的資訊。使用者必須「再搜尋」或「點選
許多網頁」以蒐集並整理大量的資訊，最後完成此次的旅遊決策資訊。問題關鍵在於大多數
Web使用者所依賴的搜尋引擎 (Google)，僅限於提供「大量相關資訊」，無法『整合資訊』
成為更適合使用者的『知識』。使用者通常需要的是『跨領域知識整合需求』。以上述旅遊
領域的問題為例：使用者想要的『知識』是完整整合地圖、官方網站、旅遊網站、新聞、部
落格等資訊源『有價資訊』，並非散在大量網頁的『片段資訊』。在此論文，我們開發 Intelligent 
Internet Information System (I3S) 做為快速及有效建立領域入口的平台 (a general platform for 
Domain Portals)。利用資料探勘和序列分析等技術，發展半自動化資訊擷取系統 (I3 Metadata 
Extractor, I3ME)，並制訂人機介面流程和系統整合，盡量減少人力於建立 domain portals所花
的時間。以『旅遊』領域為研究實例，I3S以 I3ME可擷取出台灣主要旅遊網站的結構化資訊 
(metadata information)，並整合成 7,768個旅遊資訊。對照「全人工 (fully manual)」設定擷取
的結果，本系統擷取 metadata的 precision (準確率) 最高可以到 84.98%，Recall (回收率) 可
以到達 94.01%。 
關鍵字：資訊擷取、資料探勘、領域入口網站、搜尋引擎。 
Website of Travel@I3S: http://163.22.21.70/TravelI3S/Index.aspx.  
Abstract 
As the exponential growth of the Web, users rely on search engines to find information needs for 
making decisions. Using the example of searching “南投 旅遊 (Nantou Travel)” on the Web, the 
user obtained 874,000 target pages from the Google’s search results, in which only a few pages are 
valuable for the user. However, the user must perform click-and-click operations to integrate little 
information from large amounts of pages. The key problem is that the user requires not only 
“relevant pages” retrieved by search engines, but also “useful knowledge” integrated to solve some 
problems in the “travel domain”. The “knowledge” presents the complete information integrated 
from significant information of pages that are published in different domains (websites). To make 
unacceptable results. 
  
Figure 1: The search result page of the Google. 
 
Figure 2: The wait-and-wait in the Yahoo Knowledge+. 
By tracking and surveying large number of search results of “清境農場 (Cing Jing Farm)”, gUsers 
gradually realized useful pages about the query so that they become Master Users (mUsers) about 
the travel domain on the Web. They will find more related topics related to the query, such as “具特
色的民宿”, ”步道”, ”採水蜜桃”, etc. Since mUsers accumulated experiences by clicking and 
studying pages, they have rich knowledge (collecting related websites and bookmarks) and know 
which websites matching the best “cost-effective ratio” on a tour. The difference of information 
needs between gUsers and mUsers is shown in Figure 3, in which Google provided search services 
for gUsers in the beginning so that they can learn on the Web. After promoting gUsers to mUsers, 
the knowledge and experiences of mUsers will replace partial functions provided by Google. For 
instance, many domain-related websites about travel, auction, medicine, health, etc. have attracted 
stationary web users who use these websites to find domain-related information instead of Google 
or other search engines. The mUsers are familiar with using professional travel-related websites to 
plan tours including: finding maps, booking hotels and tickets, survey restaurants and news about 
travel spots, etc. However, mUsers still pay a lot of time to collected and organized tedious works 
about the travel package. Therefore, an intelligent information system that automatically collected 
and organized web pages for this purpose is very useful to serve users requirements on making 
decisions. 
 Traffic Domain Object (tDO) defines the metadata of different type of transportations that 
facilitate users to arrive at targets of the tour. In addition to categorizing tDO based on 
geographic hierarchy, tDO can be also classified by vehicles, such as planes, trains, buses, 
ferryboat, TRT (Taipei Rapid Transit), HSR (High Speed Rail), etc. 
 Accommodation Domain Object (aDO) defines the metadata of overnight accommodations 
during the tour. It can be classified by properties like: hotel, inn, guesthouse, business hotel, etc. 
 Food Domain Object (fDO) provides metadata information about foods, restaurants, specialties, 
etc. It can also be classified by styles of foods like: western, eastern, Japanese, etc. 
.  
Figure 4: The example of the travel-related page contains three DO types: sDO, aDO and tDO. 
Based on the Web infrastructure, the I3S is developed to integrate web data into the useful 
knowledge and value-added information. Through services of search engines, I3S efficiently 
gathers large amount of relevant pages. Then, the system analyzes these data to extract domain 
metadata and attribute for automatically extracting metadata for DO. Using the “mashup” concept 
of Web 2.0, we develop several Web Services components and integrate with the Google API 
service to semi-automatically integrate disordered web data into Travel@I3S. By carefully 
examining manual efforts employed in constructing the domain portal, we verify the ability of I3S 
by the effectiveness of solving the problem of web scalability: the manpower bottleneck.  
Therefore, we will record manual time cost (MTC) during constructing the domain portal to verify 
the effectiveness of the propose semi-automatic information extraction method. 
known as Metadata Block (MB). The third process is mining the template for MB of some website 
so that the system is able to precisely extract metadata from MB. Finally, metadata extraction 
methods are applied to extract structured information from MB and mashup technology is employed 
to integrate metadata into the knowledge. 
Based on the design of HTML [23], an HTML page can be expressed as a DOM [22] (Document 
Object Model) tree. A block of a page can be regarded as a sub-tree that may recursively contain 
several sub-trees as its components. Of course, each sub-tree can be also a DOM tree based on the 
definition. By top-down analyzing the DOM tree of a page, all conceptual blocks may be extracted 
precisely. Then, MB of a page can be furthermore recognized for metadata extraction according to 
metadata attributes selected by the user. The system analyze the text of domain-related pages to 
extract metadata attributes that are recommended to the user to define attributes and map those 
attributes to 15 Dublin core fields. Finally, we propose simple methods to integrate metadata 
information into useful knowledge and present the difference between the knowledge before and 
after mashup. 
We roughly define two kinds of blocks: Content Blocks (CB) and Link Blocks (LB). Basically, CB 
and LB present content and link structures of a page, respectively. Furthermore, LB can be divided 
into two types of blocks: Structure Block (SB) and Redundant Block (RB). Examples of these 
blocks are shown Figure 5. 
Content Blocks
Structure Blocks
Redundant Blocks
 
Figure 5: Examples of CB, SB and RD in a news page. 
 Content Block (CB) is the block that contains the major content (concept) of a page. For 
example, blocks that contain texts of the news article in a news page are identified as CB. 
 Structure Block (SB) is defined as the block that contributes hyperlinks to construct the website 
usually share the same attributes, such as “title” and “description” are widely used in every 
domain’s metadata fields. Therefore, we borrow the ideas of “Dublin Core Element” [13] [14] from 
the topic of digital library so that different patterns can be mapped into the same attribute and 
different domains can share the same attribute defined in 15 Dublin Core fields. Apparently, as 
digital libraries use the Dublin Core to union digital archives generated from different domains, the 
Dublin Core is also applied to integrate (mashup) metadata information extracted from different 
pages. In the travel domain, we map domain-related metadata attributes into 15 Dublin Core fields 
as followings:  
1. Title – 名稱、景點名稱 
2. Subject – 行程名稱、旅行名稱、關鍵字 
3. Description – 資訊 、指南、描述、事項、特色 
4. Type – 類別、景點類別、景點類型 
5. Date – 日期、時間 
6. Publisher – 網站名稱，旅行社 
7. Creator – 作者、製作 
8. Contributor – 電話、傳真、郵件、email 
9. Format – Photos 
10. Identifier – URL、網址  
11. Source – Object ID 
12. Language - 語言 
13. Relation - 交通，巴士、租車、費用、門票、住宿、飯店、國家 
14. Coverage - 地址、位於、路線、位置、地點 
15. Rights – 版權 
 
Several different metadata may be extracted from different websites; we therefore integrate those 
metadata to form the complete and useful knowledge for some object. In Web 2.0, the process of 
information integration is known as “mashup”. Before performing mashup process, as the example 
shown in Figure 7, the metadata information of “廬山溫泉”, with slightly different AV-pairs and 
scene photos, is spread in two websites. After performing the mashup process of the system, as the 
example of the Figure 8, both metadata information records are merged into the useful knowledge 
that consists of complete metadata, maps, related news and blogs. 
Applying Information Extraction technology to extract metadata from various websites and 
mapping the domain’s metadata attributes into the 15 Dublin Core fields as the standard to 
“mashup” useful metadata information into the useful knowledge. In Figure 9, different words are 
used to denote the same attributes in two different websites. Red and green rectangles are 
corresponding to attributes mapped to the Dublin Core (DC), dc.subject and dc.coverage, 
domain data by issuing keywords or websites and labeling important websites and pages. In the 
second phase, I3S extracts metadata information from those important domain websites labeled in 
first phase. Finally, the third phase integrates metadata information extracted from different 
websites into the complete and useful knowledge. 
Ideas Websites
Concept
Hierarchies
Pages
Keyphrases
Metadata:DC
I3MC I3SMG
I3PE
I3CF
I3SE
Indices
I3MA
I3ME
I3BE
Blocks
metadata blocks
Attribute-Values
Domain Objects
I3DOC
I3MC (MetaCrawler)
I3SMG (SiteMap Generator)
I3SE (Search Engine)
I3BE (Block Extractor)
I3PE (Phrase Extractor)
I3MA (Metadata Analyzer)
I3ME (Metadata Extractor)
I3DOC (Domain Object Classifier)
I3CF (Catalog Fuser)
1
2 3
 
Figure 10: The system design and architecture of I3S. 
4.1. Domain Data Collection (DDC) 
In this phase, ideas of Metadata Crawler and Focused Crawler are employed to efficiently and 
effectively to crawl pages as the domain-related data pool. In the case study of the travel domain, as 
shown in Figure 11, the user may issue keywords, “旅遊 (travel) or 旅行 (trip)” to the system 
(Travel@I3S). Then, Meta Crawler (I3MC) rapidly gathers large amount of pages from web search 
engines. The Parser component parses each HTML page into the DOM tree. By performing 
conventional lexical analysis and indexing methods, the Search Engine (I3SE) component builds 
tokens and indices to facilitate following analyses on pages. During these processes, important 
websites may be recommended and confirmed or selected by the user; therefore, these websites are 
applied to the SiteMap Generator (I3SMG) module for semi-automatically constructing Domain 
Concept Hierarchies (DCH). In the case study, the user intuitively employs the page of “zip code of 
Taiwan 319 countries from Taiwan POST office” to construct the DCH, as shown in Figure 12. 
 Figure 13: The system architecture of Domain Metadata Extraction 
4.3. Domain Metadata Integration (DMI) 
In the chapter 1, we introduced that general travel Domain Objects are divided into 4 
fine-granularity Domain Objects: sDO, tDo, aDo and fDo. Since metadata of the same Domain 
Object are probably extracted from different pages from different websites, the system must identify 
which DOs extracted from different pages are used to describe the same object. In this way, the 
concept of mashup is applied to integrate domain objects. 
 
Figure 14: The system architecture of Domain Integration 
In the DMI phase, using the example of sDO (廬山溫泉) as shown in Figure 14, two metadata 
described in different pages “mashup” as a complete sDO. Intuitively, the AV-pair mapped to 
“dc.title” is employed to identify the new DO the same with the old DO and merge two metadata 
into a more complete DO. Apparently, extracted metadata are very useful to be applied to search 
engines to obtain more relevant pages about news or blogs. Therefore, in the Travel@I3S case 
study, News Extractor and Blog Identifier components can be easily implemented based on I3MC 
that submits qualified metadata queries to search engines and extract high-relevant news blog pages. 
Consequently, extracted metadata information are also valuable to “mashup” more relevant 
information. 
 Figure 15: The use process of manually adding Attribute to database. 
 
Figure 16: The use process of Attribute Selector. 
 
Figure 17: Recall and precision rates of attribute evaluation. 
In Table 2, we show experiment results of two methods based on two websites: CTIN and OKGO. 
In addition to calculate the precision and recall of attributes, we also calculate the F-measure to 
estimate both recall and precision of attributes in Figure 17. It is hard to obtain all attributes about 
the travel domain from the extreme large Web; we define the desired attributes (answers) by union 
two results of manual and semi-automatically method. Of course, the precision of manual result is 
100%, but the recall is not sure perfect. Manual method spends much time (13 minutes 47 seconds 
and 22 minutes 16 seconds) in par with the semi-automatic method. The manual method gets the 
average of F-measure 80.5%. In the semi-automatic method, we just need select attributes from 
adequate to be employed in constructing the travel domain portal. 
Table 4: The result of Mashup three travel web sites 
Web site CTIN OKGO MMM Total 
Domain Scene Scene Accommodation Food  
Before Mashup 1,686 2,704 3,905 499 8794 
Title match 
 (overlap) 
1,026  
After Mashup 3,364 3,905 499 7768 
 
 
Figure 18: The use flow of Mashup. 
6. Conclusion and Future Work 
In this project, we implement the Internet Intelligent Information System (I3S) as a general platform 
for building domain portals. Using the travel domain as a case study (Travel@I3S), we efficiently 
and effectively (with little manual effort) construct an online travel domain portal as shown in 
Figure 19. 
 
Figure 19: The travel domain portal: Travel＠I3S. 
We design and implement the I3S’s Domain Data Collector (I3DDC) and Domain Metadata 
Extractor (I3DME) to semi-automatically extract metadata from several travel websites. Both 
in the Figure 21. The scenario demonstrates the ideas of integrating knowledge from various 
domains that is the main problems in the future projects. 
 
Figure 20: The web interface for planning a tour. 
 
Figure 21: The tour package recommended by Travel＠I3S. 
7. References 
[1] Altschul, S.F., Gish, W., Miller, W., Myers, E.W. and Lipman, D.J., “Basic local alignment 
search tool,” J. Mol. Biol. 215, 1990, pp. 403-410. 
[2] Baker, T. and Birlinghoven, S., “A Grammar of Dublin Core,” D-Lib Magazine, October 2000, 
Vol. 6 NO. 10, http://www.dlib.org/dlib/october00/baker/10baker.html. 
[3] S. K. Bhavnani, “The Retrieval of Highly Scattered Facts and Architectural Images: Strategies 
for Search and Design,” Automation in Construction, vol. 14, pp. 724-735, 2005. 
[4] S. K. Bhavnani, C. K. Bichakjian, T M. Johnson, R. J. Little, F. A. Peck, J. L. Schwartz, V. J. 
Strecher, “Strategy Hubs: Next-Generation Domain Portals with Search Procedures,” Proc. 
SIGCHI Conf. on Human Factors in Computing Systems 
[5] S. K. Bhavnani, C. K. Bichakjian, T M. Johnson, R. J. Little, F. A. Peck, J. L. Schwartz, V. J. 
Strecher, “Strategy Hubs: Domain Portals to Help Find Comprehensive Information,” Journal 
of the American Society for Information Science and Technology, vol. 57, no. 1, pp.4-24, 2005. 
[6] Cai, D., He, X., Wen, J.-R. and Ma, W.-Y., “Block-level Link Analysis,” In Proceedings of the 
27th Annual International ACM SIGIR Conference, Sheffield, UK, July 2004. 
[7] Cai, D., Yu, S., Wen, J.-R., Ma, W.-Y., “VIPS: a vision-based page segmentation algorithm,” 
Microsoft Technical Report, 2003 
[8] Chakrabarti, S., van den Berg, M. and Dom, B., “Focused crawling: A new approach to 
topic-specific web resource discovery,” Proceedings of the 8th World Wide Web Conference, 
