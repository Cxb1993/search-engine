行政院國家科學委員會補助專題研究計畫 
□期中進度報告 
▉期末報告 
 
植基於 Hadoop 分散式檔案系統之 Nutch 整合平台之實作與效能分析 
 
 
計畫類別：▉個別型計畫   □整合型計畫 
計畫編號：NSC 100 －2221 － E － 126 － 009 － 
執行期間：100 年 8月 1 日至 101 年 7 月 31 日 
 
執行機構及系所：靜宜大學資訊管理學系 
 
計畫主持人： 王孝熙 
共同主持人： 
計畫參與人員： 張鈞徨、傅浚庭、葉欽智 
 
 
 
 
本計畫除繳交成果報告外，另含下列出國報告，共 ___ 份： 
□移地研究心得報告 
□出席國際學術會議心得報告 
□國際合作研究計畫國外研究報告 
 
 
 
處理方式：除列管計畫及下列情形者外，得立即公開查詢 
            □涉及專利或其他智慧財產權，□一年□二年後可公開查詢 
 
中   華   民   國  101 年 10 月 12 日
 
3 
 
的發展漸趨成熟，讓雲端運算進行大型的計
算工作更輕而易舉，並且使分散式應用更加
廣泛。近十幾年以來，許多研究領域對於電
腦演算的需求需要相當的處理速度。使得電
腦的處理能力在平行運算上快速地演化，演
化過程從分散式運算演變成格網運算，到最
新趨勢的雲端運算。 
Nutch 是一種開放源的搜尋引擎，可以建
立自己的搜尋引擎。我們使用 Nutch 的原因
是因為可以減少許多廣告、不相符合的內容
以及資訊。另外，在隱密的環境下，ex:防火
牆內，想搜尋內部資料，這時也可以用 Nutch
建立一個專屬的搜尋引擎。 
虛擬化是一種很廣義的技術，本研究探
討的虛擬化為伺服器虛擬化。伺服器虛擬化
可分為三種，半虛擬化、全虛擬化、硬體輔
助虛擬化。具代表性是  VMWare、Xen 與
KVM（Kernel-based Virtual Machine）。虛擬
化運用在雲端運算，透過虛擬機器管理平
台，讓作業系統、網路及儲存都可以虛擬化。
透過虛擬化整合，可以減少成本，虛擬機器
也可以快速地遷移。虛擬化的彈性特點，可
以在系統上彈性的調配資源應用。虛擬化可
以在一台硬體上執行多個不同的應用系統的
能力，可以有效降低成本、讓使用者可以更
靈活的運用資訊系統。 
在本篇研究中，我們使用刀鋒伺服器，
建構了多重虛擬機器叢集，把 Nutch[1]以及
Hadoop[2]建置在虛擬機器的環境中，利用虛
擬機器替代實體機器。由於許多商業服務的
系統僅支援特定的作業系統，且其作業系統
又緊密的綑綁著硬體。因此，隨意地擴充系
統都必須添購新的硬體，並更動網路的設
定，導致本研究利用虛擬化所具有的彈性特
點，來解決擴充性問題。 
接下來我們在實驗環境的建置上，我們
將使用目前最常見且實際運用在大規模商業
環境上的雲端運算平台之一的Hadoop開放原
始碼作為主要的 MapReduce 運算平台。此平
台的優點是其強大而完整的基礎架構可以減
少大量的雲端架構開發的時間，大量部署時
也相當迅速。此外，我們將嘗試利用整合
Virtual Workspaces 開放原始碼系統作為主要
的虛擬機器與虛擬網路技術，透過虛擬機器
的叢集配置，分析在不同虛擬機器數量，對
於系統的效能提升，有明顯的改善，以及在
實驗環境的成本上，能有所節省。 
 
三、文獻探討 
3.1 Scale-Out System 
伺服器的硬體架構，大致上可以分成三種類
型：(1)直立式伺服器(2)機架式伺服器(3)刀鋒
伺服器。在 Scale-Out System[3]中，第一種最
為流行的形式為機架式伺服器，機架式伺服
器是一種結構最佳化的直立式伺服器，第二
種代表性的伺服器為刀鋒伺服器，刀鋒伺服
器簡單來說就是密集式的機架式伺服器，主
要結構為一個大型主體機箱，內部可插上許
多獨立的伺服器模組，每一個模組就是一個
完整的系統，因此可以運行自己的作業系統。 
 
5 
 
 
圖二、MapReduce 架構圖 
HDFS[8]類似 Google File System[9]是一
種分佈式檔案系統設計運行在通用的硬體，
它與現有的分佈式檔案系統有許多相似之
處。其不同之處 HDFS 擁有高度的容錯性
(fault-tolerant)，主要佈署再較低成本的硬體設
施上面，並且適合用於大量的資料處理
(Perabytes)，提供高吞吐、低延遲的特性，在
Hadoop 系統中資料的存放和運算所產生的暫
存檔案，都是存放在 HDFS 上面。 
HDFS 是由 Name Node(Master)以及 Data 
Node(Slave)所組成。其中 Name node(只有一
個 ) 負責管理檔案的資訊、 Metadata 與
Namespace 等、以及檔案的如何去存放。Data 
Node(可多個)則是負責儲存資料被系統切割
後的區塊(Block)，每一個區塊還會有三份的
備份(Replica)存放在不同的 Data Node，存放
的位置則記錄在 Name Node 上面。如此一來
當某一個 Data Node 故障時，系統會自動地進
行資料的搬遷和複製，以確保資料的完整性。 
 
四、研究方法與實驗建置  
在雲端運算上，資料處理量過於龐大，
為了解決實體機器的龐大成本，透過虛擬化
以節省成本的開發。在資源上，為了服務大
量且不同的需求，實體機器在處理上，會有
效能的不足，虛擬化特性，能利用彈性的調
配資源，解決此問題。在雲端運算上，虛擬
化是不可或缺的角色。 
所謂的虛擬化，其實就是把電腦的資
源，如運算能力、儲存空間以及應用程式抽
離出來，讓資源的使用方式更具效率。在作
業系統的虛擬化這個領域，有數種不同的方
法，可以依他們虛擬的層級來分類。例如:將
硬體平台完整的用軟體模擬，可以將作業系
統執行在多種不一樣的硬體設定上。半虛擬
化，並不會將所有的硬體設備虛擬化，藉由
虛擬層（Hypervisor）讓虛擬伺服器能直接取
用硬體運算資源，提供硬體直接存取的 API
給各不同的作業系統，而不是完整地模擬硬
體。在完全虛擬化(full virtualization)中，必須
藉由作業系統負責控制與分配底層硬體的資
源，虛擬機器是一個足夠強大的硬體使客戶
機作業系統獨立運行。這種方案最早在 1966
年被虛擬機家族的先鋒 IBM CP-40 與 CP-67
使用。支持完全虛擬化的虛擬機軟體包括
VirtualBox，VirtualPC，VMware Workstation， 
VMware Server …等。 
本研究為了減少成本的開發，我們利用
了虛擬化的特性，提高了整個系統的效能。
由於構建在 Hadoop 分佈式文件系統之上，使
用 MapRreduce 方法完成。 
 
 
7 
 
虛擬機器環境，在節點數增加時對於效能的
提升是否有幫助。 
0
500
1000
1500
2000
2500
3000
3500
4000
P
ro
ce
ss
 T
im
e
 (
s)
1
n
o
d
e
4
n
o
d
e
8
n
o
d
e
 我們發現，在透過 Hadoop 配置後，在時
間的改善，的確有所改進。為了能有效的儲
存資料，以及嘗試是否能對於速度效率上作
改進，我們在機器配置上，增加了節點數量。 
 由圖中我們發現，在 Process Time 顯示，
節點數量增加時，在同個資料處理的時間，
會跟著多重節點縮短，在整體效能上，是有
所提升。 
我們發現，在透過 Hadoop 配置後，時間
的改善，的確有所改進。為了能有效的儲存
資料，以及嘗試是否能對於速度效率上作改
進，我們在機器配置上，增加了節點數量。
實驗結果發現節點數目不同時，在時間上的
成長性。在得到的數據圖如下，在圖中顯示，
我們設定的 8 個節點數，在時間上來看，speed 
up 的效果最為明顯。 
  
在雲端運算漸趨成熟的環境下，工作排
程的調整，以及在雲端運算使用虛擬機器的
配置，在本研究中，都做了相關實驗。 
在實驗環境測試方面，我們使用虛擬機
器叢集架構，架設 Hadoop 的平台。研究結果
發現，節點數增加時，speed up 會近乎呈現倍
數成長，對於整體處理速度的提升，有所改
善。 
我們的實驗結果顯示，處理時間透過了
虛擬化的功能，效能會有所提升。在機器配
置使用虛擬化，可以快速配置所需要的機
器，對於使用虛擬機器叢集設定上，減少成
本的開發，也減少時間上的花費。 
 
本計畫工作目標以及研究方法： 
 
建置並且深入了解Hadoop雲端運算平台
為主，並且在平台上架構Nutch搜尋引擎，目
前Hadoop平台的相關研究大部分都是在著重
於前端的工作排程策略(MapReduce)部分，使
用兩種平台搭配，從中了解使用時會遇到什
麼問題，再逐步去改善從中使用的工作排程
策略，以改善進行Map & Reduce時在系統效
能的瓶頸，並且考量在多使用者的環境下，
如何提供相同品質的服務、改善整體系統平
台資源使用效率、達到性能最佳化。我們將
綜合上述種種影響因素，實作分析後提出改
善的工作排程策略及效能改進。 
 
本計畫各階段工作項目之進行步驟、所遇到
的困難以及解決方法如下： 
 
 
9 
 
架構之優缺點 
 
目前現有的平台架構所考慮的因素尚未完
整，只使用Nutch 本身的原理來搜尋，現在
我們要使用Hadoop 的MapReduce 在系統效
能上提升。因此，我們的平台架構把Nutch 使
用在Hadoop 下如何去提供相同品質的服
務、整體系統資源使用率、應用程序的需求
以及時間上的縮短，等等因素列入重要的考
量。 
所遇到的困難： 
目前在 Nutch 的平台架構以及Hadoop 的平
台架設，在Hadoop方面雖有較多的研究人員
及機構投入研究與探討，但是Nutch和Hadoop
互配下的資料仍然有限，在Nutch幾個步驟
下，如果加上了Hadoop，使用效能上是否能
夠有所改善。所以在資料有限的情況下，必
須去克服我們在此過程中所面臨的這些因
素。 
解決成果： 
加強相關的技術文件之閱讀，我們將詳細地
得知 Nutch 搜尋分成幾個步驟， Inject 、
generate、fetch、updateDB幾個方法，我們測
試這幾個步驟中，哪些步驟在花費的時間上
會比較費時。Nutch 搜尋引擎架構處理流程
包括抓取流程和搜尋流程， Nutch 也分為2
部分，抓取器和搜尋器。 在抓取流程中，以
廣度優先搜尋（BFS）的方式從企業內部網或
者互聯網抓取網頁。  這個過程涉及到對
CrawlDB 和LinkDB 資料庫的操作。  然後
Nutch 解析器開始解析諸如HTML、XML、
RSS、PDF等不同格式的文件。 最後Nutch 搜
尋器針對解析結果建立索引並儲存到
indexDB 和SegmentsDB 資料庫中，以供搜尋
器搜尋用。在透過Hadoop中的MapReduce架
構，將該步驟拆散成幾個機器平均運作，接
著再把目前現有的平台搭配下可能影響的因
素作彙整，盡量將可能會影響實驗結果的因
素降到最低。 
 
【3】實驗環境之建置: 
我們將利用現有的機器及再添購一定數量的
伺服器以支援完整的實驗環境，因為此實驗
將會運用到許多機器。如果實驗室內機器的
數量、種類或規格無法滿足實驗之需求，我
們將會將透過虛擬器來滿足我們操作系統的
需求環境，當然我們盡量以最客觀的操作方
式及架構，以最少的機器做出最大的測試成
果。 
所遇到的困難： 
Hadoop可以支援異質性的平台，如果每台伺
服器之間的性能差異太大，會對整體的負載
平衡能力造成影響不得而知，因此我們必須
進行分析及評估。此外，如果實驗環境使用
到虛擬機器來架設，又牽涉到我們雖然可以
有效切割每台虛擬伺服器的記憶體分配使用
量，但CPU 是原本實體機器及虛擬伺服器共
用的，無法去完全均衡地切割資源的問題。 
解決成果： 
我們使用刀鋒伺服器，建構了多重虛擬機器
 
11 
 
六、參考文獻 
[1] M. Cafarella and D. Cutting. Building Nutch: 
open source search. ACM Queue. Vol. 2, no. 
2, pp. 54-61, 2004.   
[2] ApacheHadoop                                          
http://hadoop.apache.org/ 
[3] M. Michael, J. E. Moreira, D. Shiloach, and R. 
Wisniewski. Scale-up x Scale-out: A Case 
Study using Nutch/Lucene. Third 
International Workshop on System 
Management Techniques, Processes, and 
Services (SMTPS). Held in conjunction with 
the 2007 International Parallel and 
Distributed Processing Symposium (IPDPS 
2007). Long Beach, CA, March 30th, 2007. 
[4] Lucene 
http://lucene.apache.org/java/docs/index.html 
[5] Luotuo Nutch search engine 
http://www.luotuo.net.cn/a/qitabiyesheji/2010/102
7/12405.html 
[6] Rohit Khare, Doug Cutting, Kragen Sitaker, 
Adam Rifkin:Nutch:A Flexible and Scalable 
Open-Source Web Search Engine,www 
2005,Chiba,Japan,May10-14,2005 
[7] Dean, J. and Ghemawat, S., MapReduce: 
Simplified data processing on large clusters, 
In Proceedings of Operating Systems Design 
and Implementation (OSDI), San Francisco, 
CA, pages 137-150, 2004. 
[8] HDFSArchitecture                                     
http://hadoop.apache.org/core/docs/current/hd
fs design.html. 
[9] S. Ghemawat, H. Gobioff, and S.-T. Leung., 
The google file system, SIGOPS Oper. Syst. 
Rev., 37(5):29–43, 20
 
13 
 
 
100 年度專題研究計畫研究成果彙整表 
計畫主持人：王孝熙 計畫編號：100-2221-E-126-009- 
計畫名稱：植基於 Hadoop 分散式檔案系統之 Nutch 整合平台之實作與效能分析 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 2 2 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 3 3 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
