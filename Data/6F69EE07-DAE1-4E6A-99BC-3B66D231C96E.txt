 Figure 1. Two-dimensional User Position 
 
two distances give two possible solutions because two circles intersect at two points. A third circle is 
needed to uniquely determine the user position. For similar reasons one might decide that in a 
three-dimensional case four satellites and four distances are needed. The equal-distance trace to a fixed 
point is a sphere in a three-dimensional case. Two spheres intersect to make a circle. This circle intersects 
another sphere to produce two points. In order to determine which point is the user position, one more sat-
ellite is needed. In GPS, usually the position of the satellite is known from the ephemeris data transmitted 
by the satellite. The broadcast ephemerides are based on observations at the five monitor stations of the 
GPS control segment. The most recent of these data are used to compute a reference orbit for the satellites. 
Additional tracking data are entered into a Kalman filter and the improved orbits are used for extrapola-
tion. As reported by Remondi and Hofmann-Wellenhof (1989), these orbital data could be accurate to ap-
proximately 5m based on three uploads per day; with a single daily update one might expect an accuracy 
of 10 m. To use the broadcast ephemerides, the GPS receiver needs to download the navigation message 
from the satellite. Downloading ephemeris is slow (because the data rate is only 50 bps), and requires con-
tinuous lock on the satellite. It is pretty much like downloading photographs from the internet over a 
dial-up modem. The major draw with the broadcast ephemeredes is that it is not capable of emergency 
applications such as the indoor GPS positioning. 
 
Another method is to use the precise ephemerides that are maintained by the National Geodetic Sur-
vey (NGS) of the U.S. The official precise GPS satellite orbits are produced by the Naval Surface Warfare 
Center (NSWC) of the U.S. together with the U.S. Defense Mapping Agency (DMA) and are based on 
observed data in the tracking network of the control segment. The post mission orbits are available upon 
2. THE NATIONAL GEODETIC SURVEY STANDARD GPS FORMAT SP3 
 In this section, the NGS orbital format SP3 (Standard Product #3) for GPS satellites is discussed. 
The first NGS standard GPS format is called SP1 introduced by Remondi (1985). Since then, some modi-
fications have been made. The major addition to earlier format is the satellite clock correction information 
which is computed simultaneously with orbits. The SP3 format has two types of records: the basic format 
is a position and clock record; a second, optional, record contains velocities and clock rates-of-change. 
Examples of the SP3 format are shown in Tables 1 and 2. Note that only part of the record is present. The 
Position Record Flag, P, in line one indicates that no velocities are included. The Velocity Record Flag, V,  
 
# a P 1 9 9 4  1 2  1 7   0   0   0 . 0 0 0 0 0 0 0 0       9 6      d  I T R 9 2  F I T   N G S
# #   7 7 9  5 1 8 4 0 0 . 0 0 0 0 0 0 0 0    9 0 0 . 0 0 0 0 0 0 0 0  4 9 7 0 3  0 . 0 0 0 0 0 0 0 0 0 0 0 0 0
+    2 5      1   2   4   5   6   7   9  1 2  1 4  1 5  1 6  1 7  1 8  1 9  2 0  2 1  2 2
+          2 3  2 4  2 5  2 6  2 7  2 8  2 9  3 1   0   0   0   0   0   0   0   0   0
* 
* 
% c  c c  c c  c c c  c c c  c c c c  c c c c  c c c c  c c c c  c c c c c  c c c c c  c c c c c  c c c c c
* 
* 
/* CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC
*   2 0 0 5  0 4  1 7   0   0   0 . 0 0 0 0 0 0 0 0
P   1   1 6 2 5 8 . 5 2 4 7 5 0   - 3 5 2 9 . 0 1 5 7 5 0  - 2 0 6 1 1 . 4 2 7 0 5 0     - 6 2 . 5 4 0 6 0 0
* 
* 
* 
P  2 8   1 3 2 0 4 . 9 3 7 7 5 0  - 2 0 4 8 5 . 5 3 3 4 0 0   1 0 7 9 4 . 7 8 7 0 0 0      5 5 . 2 0 0 8 0 0
P  2 9   - 1 6 3 8 . 4 3 1 0 5 0  - 2 4 3 9 1 . 4 7 9 2 0 0   1 0 4 5 5 . 3 1 2 6 5 0       3 . 6 9 0 3 0 0
P  3 1    6 2 6 5 . 2 5 5 8 0 0  - 2 5 6 8 7 . 9 8 6 9 5 0    - 7 5 3 . 3 5 9 0 0 0      7 0 . 8 3 0 8 0 0
*   1 9 9 4  1 2  1 7   0  1 5   0 . 0 0 0 0 0 0 0 0
P   1   1 5 7 1 6 . 8 2 0 1 3 5   - 1 1 6 9 . 8 5 0 4 9 0  - 2 1 2 8 1 . 5 7 8 7 6 6     - 6 2 . 5 4 2 7 4 6
P   2  - 2 2 8 1 3 . 2 6 1 0 6 5   - 9 9 2 7 . 6 1 6 8 6 4   - 9 8 1 6 . 4 9 0 1 8 9    - 1 3 1 . 3 2 8 6 8 6
Table 1. Type 1 Record of SP3 Format (“*” indicates that some lines are omitted here.) 
 
3. H∞ OPTIMALITY CRITERIA FOR BACKPROPAGATION 
 In this section, we shall investigate the H∞ optimality of the BP algorithm. Let us begin with the 
definition of the H∞ norm of a transfer operator. Let h2 denote the vector space of square-summable com-
plex-valued causal sequences {fk, 0≤k<∞}, i.e., 
  *2
=0
{set of sequences { } such that }k k
k
h f
∞
= <∑ kf f ∞
with inner product <{fk}, {gk}> = *0 k kk f g
∞
=∑ , where * denotes complex conjugate. Let T be a transfer 
operator that maps an input sequence {ui} to an output sequence {yi}. Then the H∞ norm of T is equal to 
2
2
0, 2
sup
u u h
y
T
u∞ ≠ ∈
=  
where the notation 
2
u  denotes the h2-norm of the sequence {ui}, i.e., 
 2 *
2
0
k k
k
u u
∞
=
= ∑ u
i
 
The H∞ norm may thus be regarded as the maximum energy gain from the input u to the output y. Sup-
pose that the observed sequence {di} obeys the following nonlinear model 
 
                (1) ( )i id h w v= +
 
where  is a known nonlinear function (with bounded first and second order derivatives), w is an un-
known weight vector, and {v
( )ih i
i} is an unknown disturbance sequence that includes noise and/or modeling 
errors. In a neural network context the index i in  corresponds to the nonlinear function that maps 
the weight vector, while the ith input pattern is presented, to the output. In other words, 
( )ih i
( )( )( ) ,iih w h x w= , 
where x(i) is the ith input pattern. The function  may also be interpreted as a nonlinear activation 
function. The important point to emphasize here is the nonlinearity is smooth. A commonly used form of 
the activation function is a sigmoidal nonlinearity defined by the logistic function: 
( )ih i
 
1( )
1 exp( )i
h w
w
= + − . 
The BP algorithm is well suitable for a multilayer neural network. Figure 2 shows the architectural graph 
of a multilayer perceptron with two hidden layers and an output layer. To set the stage for a description of 
the multilayer perceptron in its general form, the network shown here is fully connected. Signal through 
the network progress in a forward direction, from left to right and on a layer-by-layer basis. Figure 3 de-
picts a portion of the multilayer perceptron. In the BP algorithm, two kinds of signals are identified 
(Parker, 1987). 
 
are the only “visible” neurons for which error signals can be calculated directly. Now let T denote the 
transfer operator that maps the unknowns/disturbances { }{ }1, iw w v−−  to the prediction errors { }'ie . The 
optimal nonlinear H∞ adaptive problem can be stated as follows: Find an H∞–optimal estimation strategy 
 that minimizes 0( , , )iw d d= …F i T ∞ , and obtain the corresponding minimal system gain which is de-
fined by the following identity: 
 
2
2'
22 2
2 21, 1 2
inf inf sup .opt
w v h
e
T
w w v
γ μ∞ −∈ −
= =
− +F F
 
Here μ is a positive constant that reflects a priori knowledge of how close w is to the initial guess w-1. In 
the neural network context, μ is usually called the learning rate. The above problem formulation shows 
that H∞ optimal estimators guarantee the smallest prediction error energy over all possible disturbances of 
fixed energy. H∞ estimators are thus over conservative, which reflects in a more robust behavior to dis-
turbance variation. 
 
 Currently, there is no general solution to the above problem due to the nonlinearity of equation (1). 
Moreover, the class of nonlinear function  for which the optimal nonlinear H( )ih i ∞ adaptive problem 
has a solution is not known (Ball and Helton, 1992). However, in order to gain some insight, observe that 
by using the mean value theorem (1) may be rewritten as: 
 *1 1 1( ) ( ) ( )
T
i
i i i i i i
hd h w w w w v
w− − −
∂= + ⋅ −∂ i+           (2) 
where  is a point on the line joining w and w* 1iw − i-1. Upon applying the result of Hassibi et al.(1994) to 
the above equation shows that the recursion 
 *1 1( )( ( )ii i i i i i
hw w w d h w
w
μ− −∂= + −∂ 1 )−            (3) 
will yield γ = 1. The problem with the above algorithm is that ’s are not known. However, it can be 
shown that the γ
*
iw
opt in the above problem cannot be less than one, and indeed the BP algorithm is an ap-
proximation to (3) with  replaced by w*iw i. In the following, we shall state a result that characterizes the 
H∞ optimality of the BP algorithm with an H∞ norm that is not less than one. For a detailed treatment, 
one can consult Hassibi et al. (1994). To begin with, observe that equation (1) can be written in the fol-
lowing form by using the mean value theorem: 
result characterizes the H∞ optimality of the BP algorithm. 
 
Theorem 3 (Local H∞ Optimality, Hassibi et al., 1994) Consider the model (1) and the BP algorithm 
(5). Suppose that the 1(i i
h
w
w −
∂
∂ )  is persistently exciting, and that inequality (6) holds. Then for each ε>0, 
there exist δ1, δ2 > 0 such that for all |w-w-1|< δ1 and all v∈h2 with |vi|< δ2, we have 
 
2'
2
2 21
1 2
1
ie
w w v
εμ− −
≤ +
− +
.            (8) 
                  ■ 
 
The above theorem indicates that for w-1 sufficiently close to w, and for sufficiently small distur-
bance, the ratio in (8) can be made arbitrary close to one. In other words, locally the BP algorithm has an 
H∞ norm that cannot be less than one. Practically, it is necessary that w is close to w-1 and the disturbance 
is vi small, otherwise the BP algorithm may be stuck in a local minimum (Haykin, 1999). In this case, the 
ratio in (8) may get arbitrarily large. Note that inequality (6) also gives an upper bound on the learning rate 
μ, and indicates why BP algorithm behaves poorly if the learning rate is too large. 
 
 
4. SIMULATION RESULTS 
 In this paper, we adopt a fully-connected, two-input, and four-output neural network with two hidden 
layers. Each hidden layer has assigned 20 neurons. The network architecture is shown in Figure 4. For our 
experiment, the initial weighting w-1 is randomly set between -0.5 to 0.5 and the iteration is set to be 
300000. The input training pattern is the GPS time. The standard GPS epoch is given by the modified 
Julian date (MJD), but the time stamp for the SP3 format is given in the Coordinated Universal Time 
(UTC). The relation between MJD and UTC is summarized in the following (Xu, 2003): 
 
 
[ ] ( )365.25 30.6001 1
1 and 12  if  2,
/ 24 1720981.5,                                        
 and   if  2
2400000.5,
JD INT y INT m D
y Y m M M
UT
y Y m M M
MJD JD
= + ⎡ + ⎤ +⎣ ⎦
= − = +⎧+ + ⎨ = = >⎩
= −
≤
 
 
where JD is the Julian date, D is day, M is month, Y is year, UT is the UTC expressed in hours, and INT[x] 
means taking integer part of x. 
  
Figure 6. PRN16 GPS Satellite Orbit in the ECI Coordinate 
 
 
Figure 7. Desired Output Trajectories for the GPS Satellite Coordinate and Clock Bias 
 
 In order to verify the performance of the neural network output, we have to set up a true orbital tra-
jectory for comparison. One reasonable choice is the precise ephemeride offered by the NGS. Since the 
NGS only provides 96 points a day, which is not enough to obtain the position of the satellite at any inter-
ested epoch, a Lagrange polynomial is often used to interpolate the data at the needed epoch. The general 
Lagrange polynomial is (Moritz, 1977): 
 True Orbit 
Network Output
Figure 9. PRN16 GPS Satellite Orbit in ECI Coordinate (1000 Iterations) 
 
 
True Orbit 
Network Output
Figure 10. PRN16 GPS Satellite Orbit in ECEF Coordinate (300,000 Iterations) 
 
We also use the resulting neural network to predict the satellite orbit and the clock bias. The results are 
also shown in Table 3. In this table, the second row is the network output with the training pattern as input. 
After that, the weighting functions, when the training is complete, is then stored in the network and used 
to predict the satellite orbit and clock bias for the next consecutive six days. In Table 1, the unit of the po-
sition error is meter, and the clock bias is nanosecond. In view of the table, the prediction error is pretty 
much the same level as the broadcast GPS ephemeris. 
 
 Finally, we incorporate the neural network with a standard GPS navigation algorithm and perform a 
real-time vehicular positioning. The result is shown in Figure 12. 
 Ground Track 
Figure 12. Real-Time Positioning with the Satellite Orbits Predicted by the Proposed Neural Network.  
(The ground track of the vehicle is on the campus of the National Taiwan Ocean University) 
 
5. CONCLUSIONS 
 We have presented a neural network approach to predict the GPS satellite orbit based on the H∞ 
learning algorithm. The simulation result shows that we can use the well-trained network to predict about 
six days’ data and the orbital errors can be within meter level, which is in the same order as the broadcast 
ephemerides. We have also incorporated the neural network into a standard GPS navigation algorithm and 
performed a real-time vehicle positioning. GPS satellite orbital prediction is particular useful for the in-
door GPS application. By using the proposed method, users need not to wait for the GPS receiver to 
download the ephemeris data from the satellites which is usually a time-consuming process. We simply 
store the well-trained neural network in the receiver’s software (or firmware). Then the satellite’s orbit can 
be computed without collecting the broadcast ephemeris data. 
 
 
REFERENCES 
Ball, J. A. and Helton, J. W. (1992). Nonlinear H∞ Control Theory for Stable Plants. Math. Control Sig-
nals and Systems, 5, 233-261. 
