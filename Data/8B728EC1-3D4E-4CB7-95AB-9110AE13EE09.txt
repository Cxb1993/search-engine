2 
 
I. Introduction 
Detecting copies of digital documents, such as text, 
image, and video content, has been an active research 
area for decades. Copy detection techniques for text 
documents have been used in many applications, such as 
duplicate document detection in databases, duplicate 
web page detection in search engines, and document 
versioning and plagiarism detection in digital libraries. 
In recent years, the maturity of hardware and software 
has generated enormous amounts of image/video content, 
creating the need for copy detection techniques for mul-
timedia. Such techniques allow content owners to moni-
tor their image/video content for infringement detection 
and data mining; blog operators to identify 
near-duplicate images/videos for removal from databas-
es or for aggregating search results; and TV advertisers 
to check if their commercials are broadcast as contracted 
by TV channels. In this paper, we focus on con-
tent-based video copy detection (CBVCD). 
 
II. Related Work 
A number of feature representations have been 
proposed to resist some types of video transformation 
and editing. For example, global descriptors, such as the 
ordinal measure [1], are used to model the properties of 
an entire frame region. The merit of global descriptors is 
that their dimensions are very compact; only a 
9-dimensional ordinal measure or spatial correlation de-
scriptor is needed for a 3×3-block frame, and a 
2-dimensional color-shift/centroid-based signature is 
needed for a single frame. Although they have been 
shown to be robust against preserved-frame-region 
transformation and editing in many studies, the global 
descriptors of the modified frame might be totally dif-
ferent from those of the source frame if parts of the 
frame regions are discarded. 
Due to the limitation of global descriptors, some 
researchers have employed local descriptors, which 
capture the local region properties of the points of inter-
est in a frame. Chiu et al. [2] modeled the 
scale-invariant feature transform (SIFT) descriptor in a 
"bag-of-words" form. Local descriptors are more robust 
than global descriptors in handling dis-
carded-frame-region transformation and editing. How-
ever, the dimensionality of the local descriptor-based 
feature is usually much higher than that of the global 
descriptor-based feature. 
Some researchers have applied conventional CBVR 
methods in CBVCD to match two video sequences [3]. 
These methods usually rely on efficient indexing tech-
niques (e.g., tree and hash techniques) to maintain 
shots/trajectories/keyframes in the dataset. However, the 
indexing techniques are apt to deteriorate significantly in 
a high dimensional feature space. 
The time-series linear search (TLS) method has al-
so been widely used in CBVCD [1][2] because of its 
simple computation process. Basically, it employs a 
fixed-length sliding window to scan video streams and 
computes the similarity between the query and window 
sequences. Since TLS does not utilize indexing tech-
niques, a high dimensional feature space does not affect 
its performance significantly. However, the method 
might experience problems when handling video trans-
formation and editing events that induce the containment 
relation. By comparing the source sequence and its fast 
forward copy in the figure, it is clear that, with a 
fixed-length window, the source content and the copy 
content do not synchronize; hence, the similarity be-
tween the two sequences could be very low. Moreover, 
even though local descriptor-based features are expected 
to be robust to frame cropping, the discarded part still 
results in a decline in the similarity between the source 
sequence and its cropped copy. The above two cases can 
easily induce the increment of false negatives, i.e., real 
copies that are not detected. 
 
III. Framework Overview 
We present a novel TLS method for video copy de-
tection. Specifically, a compact signature derived based 
on the min-hash theory is used to represent a video se-
4 
 
integrates a compact signature representation of a video 
sequence based on the min-hash theory and an efficient 
signature generation process based on the heap structure 
and operations. To enhance the detection accuracy, the 
method integrates window length estimation and thre-
shold transform to deal with the containment relation 
between the source and copy sequences due to video 
transformation and editing. The proposed method is ro-
bust against various types of video transformation and 
editing, and the computational cost is low compared to 
existing methods. 
 
Reference 
[1]  C. Y. Chiu, C. S. Chen, and L. F. Chien, "A 
framework for handling spatiotemporal variations 
in video copy detection," IEEE Transactions on 
Circuits and Systems for Video Technology, Vol. 18, 
No. 3, pp. 412-417, 2008. 
[2]  C. Y. Chiu, C. C. Yang, and C. S. Chen, "Efficient 
and effective video copy detection based on spati-
otemporal analysis," In Proceedings of IEEE Inter-
national Symposium on Multimedia (ISM), pp. 
202-209, Taichung, Taiwan, Dec. 10-12, 2007. 
[3]  O. Chum, J. Philbin, M. Isard, and A. Zisserman, 
"Scalable near identical image and shot detection," 
In Proceedings of ACM International Conference 
on Image and Video Retrieval (CIVR), Amsterdam, 
The Netherlands, Jul. 9-11, 2007. 
[4]  MUSCLE-VCD-2007, 
http://www-rocq.inria.fr/imedia/civr-bench/index.ht
ml 
[5]  T. C. Hoad and J. Zobel, "Methods for identifying 
versioned and plagiarized documents," Journal of 
the American Society for Information Science and 
Technology, Vol. 54, No. 3, pp. 203-215, 2003. 
 
TABLE I 
The recall and precision rates of the six methods for eight types of transformation and editing. 
 (1) 
MH 
(2) 
MH+WE
(3) 
MH+TT
(4) 
ALL 
(5) 
HZ 
(6) 
CHUM 
Preserved-fram
e-region 
Brightness 
R 0.9459 0.9459 1.0000 1.0000 0.7742 0.8710 
P 0.9476 0.9476 0.9261 0.9394 0.7742 0.1627 
Compression 
R 0.9189 0.9189 0.9729 0.9677 0.9355 0.9032 
P 0.9460 0.9729 0.8803 0.9091 0.9355 0.1228 
Noise 
R 0.8649 0.9189 0.8649 1.0000 0.9032 0.8065 
P 0.9422 1.0000 0.8691 1.0000 0.9032 0.1042 
Resolution 
R 0.5676 0.5946 0.6756 0.8065 0.8710 0.6129 
P 0.9238 0.9271 0.9033 0.9259 0.8710 0.0465 
D
iscarded-fram
e 
-region 
Cropping 
R 0.8649 0.8648 0.9677 0.9677 0.2903 0.7742 
P 0.9162 0.9711 0.8571 0.9375 0.2903 0.1127 
Zoom-in 
R 0.8378 0.8378 0.9032 0.9355 0.8710 0.6774 
P 0.9402 0.9690 0.8750 0.9355 0.8710 0.0824 
C
hanged-fram
e  
-num
ber 
Slow motion 
R 0.8108 0.9189 0.8379 0.9355 0.0323 0.9355 
P 0.9356 1.0000 0.9379 1.0000 0.0323 0.1835 
Fast forward 
R 0.8919 0.9459 0.8919 1.0000 0.2588 0.9355 
P 0.9189 0.9476 0.7905 0.8378 0.2588 0.0755 
 
2 
 
•  (2010/09/29)第四天早上 9:00 – 10:00 是 K. J. Ray Liu 的 plenary talk，演講題目是 Multimedia 
Social Networking: A New Paradigm for Signal and Image Processing。這是個很有趣的題目，探討了
現今的社群網路行為對傳統的多媒體訊號處理帶來的新問題與新方向，並展示了劉教授運用相關
社群行為理論來對傳統的影像處理問題的新技巧。接著聆聽WA.L5: Compressive Sensing Session，
這也是與 sparse representation 相關的議題。下午則參加 WP.L1: 3D Video Quality Assessment 
Session，相關議題在這兩年的多媒體會議受到很大的重視，主要是因為社群網站要自動對大量的
上傳照片與影片進行評分排序。稍晚則搭機返國。 
 
二、與會心得 
CSIM 吸引來自中國各地之學者專家齊聚一堂共同研討，除學術與經驗之交流外，亦可藉此機會
結識華人朋友，增進彼此視野及後續之交流，實屬難得的經驗。尤其是本人所發表的論文場次，
與會者發表之論文皆充分體現科技與管理結合之用，本人獲益良多。 
 
三、考察參觀活動(無是項活動者略) 
略 
 
四、建議 
ICIP 是影像處理領域最具代表性的國際研討會，內容包含最新的理論、應用、及實務等議題，是一
個值得參與，可以廣泛吸取相關學術新知及與增進國際交流之會議，應鼓勵國內學者踴躍參加。 
 
五、攜回資料名稱及內容 
本次會議攜回一張光碟片，收錄本會出版之論文集(ISBN 978-1-4244-7994-8)。論文集名稱：
Proceedings of the International Conference on Image Processing (ICIP 2010) 
 
六、其他 
略 
 
99 年度專題研究計畫研究成果彙整表 
計畫主持人：邱志義 計畫編號：99-2221-E-415-011- 
計畫名稱：多媒體內容拷貝偵測技術之研究 II 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 2 2 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 1 1 100%  
研究報告/技術報告 0 0 100%  
研討會論文 1 1 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
