 1
行政院國家科學委員會專題研究計畫成果報告 
智慧型機器頭顱之設計與製作(I) 
Design and Fabrication of Intelligent Robot Head 
計畫編號：NSC 94-2212-E-011-032 
執行期限：94 年 8 月 1 日至 95 年 7 月 31 日 
主持人：林其禹   國立台灣科技大學機械系 
計畫參與人員：曾昌國   國立台灣科技大學機械系 
              鄭欽元   國立台灣科技大學機械系 
              邱培文   國立台灣科技大學機械系 
 
一、中文摘要 
本研究計劃之目的是以三年期間設計
並製作出一台具有人工智慧的機器頭顱，
目前第一年的工作已經大致完成，該機器
頭顱的功能為可以做出與真實人臉相同的
幾種主要表情，且機器頭顱同時具有人工
智慧可以偵測並自動模仿位於機器頭顱前
方人物之臉部表情。本研究計畫除了製作
具備上述軟體功之機器頭顱外，也發展出
可正確偵測出人物表情之電腦視覺技術，
此技術可以將演講者或說故事者之表情訊
號紀錄下來，然後由機器頭顱將所紀錄之
人臉表情播放出來。 
 
關鍵詞：機器頭顱、表情辨識 
  
Abstract 
This research aims to design and 
fabricate an intelligent robot head in three 
years. The work of the first year has already 
been finished. This robot head now can 
perform a number of major facial expressions 
of a normal human and the robot head 
installed with a brain of artificial intelligence 
can also automatically mimic the facial 
expression of a person standing in front of 
him. This research project also aims to 
develop a new technique that can record the 
facial expression signals from a person 
conducting a speech, story telling or any kind 
of verbal presentation. Then the robot head 
can reproduce the whole presentation that 
includes the reproduction (mimic) of the 
facial expressions. 
 
Keywords: Robot head, Facial expression 
recognition 
 
二、緣由與目的 
機器人之相關科技研究正如火如荼地
在日本及包含美國、英國等幾過極少數國
家進行中，台灣學界對於機器人之相關研
究尚處於嬰兒期與萌芽期交界處，平均機
器人技術水平落後上述國家一大段距離。
看到日本 Honda Asimo 跑步，Sony Qrio 
跳舞和打太極拳，及機器人相撲對打的真
實模樣，不難看出日本之「機器人技術」
將在繼「電腦」與「通訊」後之未來下一
個全球主要經濟戰場上建立主要戰功。十
年前除工業用機器人外，幾乎沒有其他機
器人市場。十年後的今天，娛樂用機器人、
商業用機器人、醫學用機器人的市場幾乎
以幾何指數方式成長。 
本計劃之目的是要設計並製作出一台
具有人工智慧的機器頭顱，機器頭顱的硬
體功能為可以做出與真實人臉相同的幾種
主要表情，且機器頭顱同時具有之人工智
慧為可以偵測出位於機器頭顱前方之人物
表情。該機器頭顱除了具備上述的軟硬體
功能外，利用發展出可正確偵測出人物表
 3
孔，再把另一線端固定在伺服機的拉桿
上。當伺服機上的拉桿轉動時，會直接拉
動固定在機械頭顱臉部皮膚的控制點，如
此就可以讓控制點產生位移動作。 
臉部表情表現的眼睛方面，各個眼睛
設計給予上下左右移動的 2 個自由度，並
加裝了 CCD 元件。圖 3為頭顱機器人眼部
CCD 與 CAD 機構圖。 
  
圖 3 頭顱機器人眼部 CCD 與 CAD 機構圖 
 
四、臉部皮膚製作 
在設計機械頭顱皮膚部份事先參考
了，以製作恐龍博物館成名的日本
kokoro-dreams 公司，開發以女性為主的人
形機器人 ACTROID，已特殊的軟質橡膠製
造外皮。另外美國得州大學達拉斯分校的
K－bot 機器人，此頭顱機器人表皮為人造
橡膠和泡沫混合物。此兩款表皮皆具有與
皮膚相似的外表與觸感，但是在材料成本
上，價格極高，且在製作的配置比例過程
需自行測試，非常耗時。在成本與時間的
考量，本機械頭顱皮膚以選用矽膠，搭配
顏色染料來達到近似臉皮的效果。 
由於人臉的面部肌肉組織為依附在顱
骨和皮膚上，而肌肉也。主要分為四大組：
口部周圍肌肉組織、眼部周圍肌肉組織、
頰部肌肉組織、顱頂淺層肌肉組織。依照
這些肌肉不同的性質，在設計製作表皮時
的厚度也必須有所改變。 
顱頂和頰部肌肉，為比較重要的視覺
效果突出的肌肉組織，是那些表面面積較
大，因此在此部份厚度上為均勻厚度；口
部周圍肌肉組織，由於需要較有彈性效
果，來表現出唇部開縮動作，所以此部份
厚度較為厚。 
在矽膠表皮的製作上，先利用人臉模
型製作出石膏母模，等石膏模完全乾燥硬
化後，利用黏土依照所定義之厚度黏在石
膏母模上，接而再來製造石膏公模，圖 4
為石膏母模與石膏公模。石膏模必須要完
全乾燥才能灌入矽膠或黏土，防止矽膠或
黏土黏上石膏，造成石膏模無法脫模的後
果。 
 
圖 4 為石膏母模與石膏公模 
  
最後調配矽膠及其顏色，均勻攪拌後
滴入凝固，均勻倒入石膏母模內，關上石
膏母模等其凝固，則可得其矽膠外皮，圖 5
為矽膠外皮。 
 
圖 5 為矽膠外皮 
 
五、人臉表情擷取軟體 
 人臉表情擷取軟體主要研究目的
為發展出能應用於機器頭顱之人臉表情與
之視覺技術，具有高偵測率與辨識率、且
速度不會太慢。圖 6為從複雜背景進行人
臉表情方法之架構圖；此人臉表情辨識策
略包含人臉偵測(Faces Detection)、特徵擷
取 (Characteristics Capture) 與 表 情 辨 識
 5
錄下來座標點，代表左眼的特徵有上下兩
個邊界座標點，以及右眼也有兩個邊界座
標點，總共找到 4 個代表眼睛上下邊界的
座標點即完成眼睛的特徵擷取。 
 
 
圖 8 眼睛特徵擷取流程圖 
 
5.3 表情辨識 
嘴巴的變動在辨識人臉表情是一個很
重要的依據，像是在開心笑的時候嘴巴的
嘴角會往上揚，且上嘴唇的邊界線會容易
成一水平直線，下嘴唇會向下移動，整個
嘴型容易成為倒三角的形狀。生氣的時候
常是緊閉的狀態，嘴唇會有擠壓的痕跡。
驚訝的時候，嘴型會微微的成 O 字型。所
以我們的目標是擷取到嘴巴的上下左右 4
點的座標。且我們分兩個部份用不同的方
式來偵測，一部分是搜尋左右嘴角的座
標，而另一部分是上下嘴唇的邊界座標。 
嘴巴的偵測原理也是利用臉部的比例
來預估嘴巴範圍後，在進行細部的搜尋工
作，不過由於在嘴型會因為情緒的差異有
很大的變動，會因為每個人的臉型長短而
造成範圍不容易確定，所以我們先搜尋鼻
孔的位置再來定義嘴巴的搜尋範圍，主要
是因為鼻孔有何瞳孔一樣的特色，和周圍
的膚色顏色差異大，且是黑色不易受到光
線的影響。定義出鼻孔位置後，再往下定
義出嘴巴的搜尋範圍，這樣也可以避免在
後面的步驟用到灰階值排序時不小心包含
到鼻孔而影響偵測的效果。偵測左右嘴角
的邊界座標流程如下圖 9所示。首先將人
臉後選區域的影像中偵測鼻子對低點的座
標，然後利用此座標在去預估嘴巴的區
域，接著分兩個步驟進行其中一個為保留
灰階值較深的資訊，另一個則為搜尋邊界
線的資訊，最後對兩個步驟的交集圖進行
嘴角特徵的搜尋，我們利用所剩嘴唇影像
中距離左右邊界角落最短距離的點來當作
左右嘴角的邊界座標點總共 2 點，就可以
完成左右嘴角特徵的擷取。 
 
 
圖 9 眼睛特徵擷取流程圖 
 
接下來則是要偵測上下嘴唇邊界的座
標，流程圖如圖 8 所示。首先將人臉區域
中嘴巴的區域給預估出來，然後分兩個步
驟進行，其中一個為利用 Cr 及 Cb 值的比
例將影像轉換後，主要是觀察嘴巴顏色的
特性。利用嘴巴部份跟人臉其他區域比起
來，紅色的成分較多，藍色的成分較少，
且 Cr 值會比 Cb 大許多，利用此特性進行
加權的方式運算，分數越高的區域越有可
能為嘴巴的所在。其轉換公式參考
Rein-Lien Hsu[3] 所提出如下式 1。Mouth 
Map 為嘴巴的搜尋區域。 
 
 7
 
圖 12 系統辨識流程圖 
 
我們所開發的自動化表情系統可以直
接對影像內的人物直接做表情辨識判斷，
並不限定在固定的環境或是光源下。所需
的條件為五官清晰眉毛必須不被頭髮遮
蔽，正面的人臉正視 CCD 即可(平面影像
無法偵測前後傾斜角度)。扣除人臉因為快
速移動而造成的的影像模糊不清，或是情
緒模擬兩可我們自己都無法以肉眼分辨的
影像之外。在此前提下由四組實驗的數據
統計顯示，如表 1，表 2，表 3，表 4所
示。笑的表情平均辨識率為 92.64%，生氣
的表情平均辨識率為 89.08%，驚訝表情平
均辨識率為 88.20%，無表情平均辨識率為
98.46%。其中以無表情及笑的表情辨識可
靠度較高，主要是因為這兩種表情在絕大
部分的人所表達的方式較相似。而生氣的
辨識率則較差，主要是因為生氣的表達方
式會因人而異而差異性較大。大部分生氣
主要比較大的臉部變動都是在於眉毛的高
低會改變，眉頭的部份會向兩眼的中心擠
過去。有時移動的變化相當的細小，連肉
眼都分不太出來，所以會造成生氣的辨識
率比其他的表情的辨識率差。 
雖然人臉表情辨識的方法目前尚無法
全部達到辨識率逾 9 成，但其平均辨識率
也具有 8 成以上。最後應用在即時辨識的
系統上，我們將影像的輸入方式直接改成
CCD 的即時輸入影像，且將連續的兩張影
像的判斷結果相同才輸出，這樣也可以避
免因為人臉快速移動被拍攝的模糊影像也
當成輸入造成的判斷錯誤，而且也在一開
始由系統自己藉由拍攝學習出該人物的中
性無表情影像當做基準，這樣便完成了一
套完全是自動化的表情辨識系統，而不需
要人為的操作，相信應用在娛樂機器人上
應該是可以接受的。如圖 13即為辨識表情
成功的範例。 
 
表 1 笑表情之辨識率 
 
人物 
辨識
正確
辨識
錯誤 辨識率 
A 40 1 97.56 %
B 62 12  83.78 %
C 57 2 96.61 %
D 45 0 100.00 %
E 40 19 67.79 %
F 48 1 97.95 %
G 57 4 93.44 %
H 53 3  94.64 %
總計 402 42  90.54 %
均辨識率為 90.54 % 
 
表 2 無表情之辨識率 
 
人物 
辨識
正確
辨識
錯誤 辨識率 
A 47 2 95.91 %
B 47 2 95.91 %
C 48 0 100.00 %
D 48 1 97.95 %
E 49 0 100.00 %
F 49 0 100.50 %
G 49 0 100.00 %
H 48 1 97.95 %
總計 385 6 98.46 %
均辨識率為 98.46 ％ 
