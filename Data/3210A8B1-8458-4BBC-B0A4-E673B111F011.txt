experimental results also show that our method can 
efficiently remove the impulse noise in various noise 
density corruption. 
英文關鍵詞： Speech enhancement, spectral subtraction, musical 
residual noise, median filter, post processing, 
impulse noise denoising. 
 
 1
行政院國家科學委員會補助專題研究計畫成果報告 
使用互補型雜訊移除演算法及聲譜濾波法於語音增強之研究 
Speech enhancement using complementary noise reduction 
algorithms and spectrogram filtering 
 
計畫編號： NSC 100 – E – 2221 – 468 - 016 
執行期限：100年 08月 01日至 101年 07月 31日 
主持人：陸清達   (亞洲大學資訊傳播學系 副教授) 
 
壹、 摘要  
一、 中文摘要 
音樂型殘留雜訊的干擾是語音增強系
統所共同面臨的主要問題，主因為該雜訊不
僅對人耳來說非常的吵雜，而且會破壞增強
語音的品質。在本研究計畫中，我們使用三
步驟語音增強系統對該受干擾語音信號從
事背景雜訊刪減之預處理；輸出的信號稱為
預處理信號，由於預處理信號依然存在許多
的音樂型單音頻譜，因此我們使用混合型中
值濾波器在二維聲譜中，大幅移除音樂型殘
留雜訊。主要的作法是在類似雜訊的頻譜區
域中，我們使用方塊中值濾波法來降低頻譜
的變化程度，使得音樂型殘留雜訊效應能有
效的抑制；相對的，在類似語音的區域中，
我們使用方向型中值濾波法，舒緩殘留雜訊
的影響，使得母音的諧波頻譜不致於遭到破
壞；實驗結果證明，本研究計畫提出的方法
可以大幅改善語音增強系統移除音樂型殘
留雜訊的效能。除此之外，在本研究計畫
中，我們也應用後處理技術於數位影像中，
移除椒鹽雜訊干擾的研究，實驗結果證明本
研究的方法也可以在各種不同雜訊密度的
干擾下，有效的除數位影像中的脈衝雜訊。 
 
關鍵詞：語音增強，頻譜刪減，音樂型殘留
雜訊、中值濾波，後處理，脈衝雜訊移除。 
 
二、 英文摘要 
Musical residual noise is a major problem for 
a speech enhancement system. This noise is 
annoying to the human ear and seriously 
deteriorates the quality of enhanced speech. In 
this project, we employ a three-step-decision 
gain factor to enhance a noisy speech, 
enabling background noise to be efficiently 
reduced. The output signal is named as 
pre-processed signal. Since plenty of musical 
tones still exist in the pre-processed signal, a 
hybrid median filter is performed in the 
spectrogram to significantly reduce a quantity 
of residual noise. In the case of a noise-like 
spectrum, block median filtering is performed 
to reduce the spectral variation. A musical 
tone is then reduced. In the case of a 
speech-like spectrum, directional median 
filtering is performed to slightly reducing the 
residual noise, while a harmonic spectrum is 
not destroyed. Experimental results show that 
the proposed approach can significantly 
improve the performance of a speech 
enhancement system by significantly reducing 
musical residual noise. In addition, we also 
apply the post-processing technique in 
denoising a pepper-and-salt noise corrupted 
image, experimental results also show that our 
method can efficiently remove the impulse 
noise in various noise density corruption. 
Keywords: Speech enhancement, spectral 
subtraction, musical residual noise, median 
filter, post processing, impulse noise 
denoising. 
 
貳、報告內容 
一、 前言 
Single channel speech enhancement is 
widely used in applications such as mobile 
 3
much more amount of residual noise, while 
speech distortion can be maintained at a low 
level in the post-processed signal.  
 
4.1. Proposed speech enhancement system 
Figure 1 shows a block diagram of the 
proposed speech enhancement system. 
Initially, noisy speech is initially framed by a 
Hanning window, and then transformed into 
the frequency domain by fast Fourier 
transform (FFT). A minimum statistics 
algorithm [21] is employed to estimate the 
noise magnitude for each subband. Hence, this 
estimated noise is employed to adapt a 
three-step-decision gain factor for speech 
enhancement [2][11], enabling the background 
noise to be efficiently removed.  
Because the musical residual noise is 
contained in the pre-processed speech, we 
propose using a hybrid median filter to 
remove this noise. A spectral bin is analyzed 
to classify whether it is vowel-like in a 
window. If the center spectrum is vowel-like, 
it is further checked the number of 
vowel-subband in a frame. When the number 
of vowel-subband is less than a given 
threshold Tv for a frame, a directional median 
filter is adopted to adjust the center spectrum. 
This yields the musical residual noise being 
slightly reduced. On the contrary, the center 
spectrum is kept unchanged when it lies in a 
vowel frame. This prevents the harmonic 
spectrum from being deteriorated.  
If the center spectrum is not vowel-like, it 
may be a residual noise. We employ a block 
median filter to adjust the center spectrum. 
This filter can reduce the spectral variation 
over the neighbor of the center spectrum, 
yielding the musical tone being removed. In 
turn, a fuzzy-switching-median (FSM) filter 
[22] is employed to modify the center 
spectrum, enabling the musical residual noise 
to be significantly reduced. Finally, the 
inverse FFT is performed to achieve enhanced 
speech. 
 
Fig. 1. Block diagram of proposed speech 
enhancement method. 
A noisy speech signal ) ,( nmy
 
can be 
modeled as the sum of clean speech ) ,( nms
 
and additive noise ) ,( nmd
 
in the frame m of 
the time domain, given as 
) ,() ,() ,( nmdnmsnmy +=
 
(1) 
The spectral estimate of speech signal 
)ω,(ˆ mS
 is obtained by multiplying a gain 
 5
is set to smaller (3 × 3), when the center 
spectrum is noise-like. The block median filter 
can be expressed by 
)},(~ ,                               
),,-(~{),(
ppmS
ppmSmedianmM
++
⋅⋅⋅−=
ω
ωω
 (9) 
where p controls the window size ( 1 or 2 in 
the experiments). 
A musical tone may exist in the 
pre-processed signal with high energy. It is 
difficult to distinguish a spectrum into speech 
or noise. Thus, a directional median filter is 
employed to adjust the center spectrum. An 
example of 5X5 widow centered at the 
subband ω  of the frame m is shown in Fig. 2.  
 
Fig. 2. Motion directions of the center 
spectrum. 
Firstly, the optimum motion direction of the 
center spectrum should be selected among 
four directions (1-4). The decision rule is to 
find the minimum spectral-distance among the 
four directions. The directional median filter 
can mitigate the fluctuation of random spectral 
peaks. Hence the magnitude of an isolated 
center spectrum is reduced. This filter can be 
computed by  
*}),(                              
),,(~{),(
im
mmSmedianmM
∈∆∆
∆+∆+=
ω
ωωω
 (10) 
where i* denotes the optimum direction. 
Moreover, the FSM filter is also utilized to 
control the weighting for attenuating the 
musical tone. The FSM filter can be expressed 
as 
),()],(F1[),(~),(F),(ˆ ωωωωω mMmmSmmS ⋅−+⋅=  (11) 
where ),( ωmM  denotes the median value 
obtained from either the block median or the 
directional median filters. ),(F ωm  represents 
the fuzzy function, it can be computed by 
 
),(  if ,                      1
),( if , ),(
),(  if ,                      0
),(F







>
<<
−
−
<
=
V
VN
NV
N
N
m
m
m
m
m
ξωξ
ξωξξξξ
ξωξ
ξωξ
ω  (12) 
where ),( ωξ m
 
is the subband SNR. Vξ  and 
Nξ
 
denote the SNR thresholds for a vowel and  
noise, which are empirically chosen to be 5 
and -10 dBs, respectively . 
If the value of a subband SNR exceeds Vξ , 
the spectrum is classified as a vowel. The 
value of fuzzy function ),(F ωm given in (12) is 
unity. Substituting this ),(F ωm
 
into (11), the 
output spectrum is equal to the pre-processed 
one. The center spectrum is kept unchanged to 
maintain speech quality. Conversely, if the 
value of a subband SNR is less than Nξ , the 
center spectrum is classified as noise. The 
corresponding value of fuzzy function ),(F ωm
 
is zero. Substituting this ),(F ωm
 
into (11), the 
center spectrum is replaced by the median 
spectrum. This results in the musical tone 
being efficiently suppressed. When the value 
of a subband SNR lies between Vξ
 
and Nξ , 
the center spectrum is filtered by the FSM 
filter, yielding the magnitude of residual noise 
being slightly reduced, while the speech 
quality is well maintained.  
 
4.2. Proposed image denoising algorithm 
The block diagram of proposed method is 
shown in Fig. 3. Initially, a noise-corrupted 
image is analyzed by a 7×7 sliding window. If 
the value of the center pixel in a local window 
is not an extreme value (0 or 255), the center 
pixel is classified to noise-free and kept 
unchanged to maintain image quality. 
Conversely, the center pixel needs to be 
further classified to which it is a noise pixel or  
 7
center pixel.  
Considering a pixel adjacent to the center 
one, the gray-level value should be close when 
they are the edge of an object or in the same 
smoothly varying area. The corresponding 
spatial distance given in (13) should be small. 
Thus the weight of the absolute difference 
between the two closest pixels has a larger 
value than that of the pixels which are not 
adjacent to the center pixel. The weights in 
(13) can be expressed by 


 ≤∆∆≤
=∆∆
 elsewhere ,  1
1  i,1- , 2
,
j
w ji  (14) 
In order to detect the edge of an object in a 
given window, we select the direction with the 
minimum absolute difference among the 
twelve directions to be the optimum direction 
for the edge1. The optimum direction can be 
achieved by 
{ }121, minarg* )(
,
≤≤= kdk kji
k
 (15) 
where *k  denotes the index of optimum 
direction in a local window. 
The value of the absolute difference on the 
optimal direction )*(
,
k
jid  is the smallest among 
the twelve directions. Hence, the value of  
)*(
,
k
jid  can be employed to detect whether the 
center pixel of a local window is either 
noise-free or noisy. When the center pixel is 
noise-free in a flat variation region or on the 
edge of an object, the value of )*(
,
k
jid  is small. 
Conversely, the value of )*(
,
k
jid  is large when 
the center pixel is impulse noise. Accordingly, 
we can detect an impulse noise pixel by the 
value of )*(
,
k
jid , given as 



 ≤
∈
otherwise ,           pixelnoisy  
  if ,   pixel free-noise *)(
,
,
Td
x
k
ji
ji  (16) 
where T is a threshold for classifying the 
center pixel to noise-free or noisy.  
If the center pixel is classified to noisy, it 
should be modified to remove the impulse 
noise. On the contrary, the center pixel has to 
be kept unchanged when it is classified to 
noise-free. 
 
4.2.2. Modified directional weighting 
median filtering 
Accordingly to (16), we can decide whether 
the center pixel of a local window is noisy. If 
the center pixel is classified to noisy, it should 
be replaced by an appropriate value to remove 
the impulse noise. Here we employ the 
switch-median (SM) filter to recover the value 
of the center pixel. The value of enhanced 
pixel can be computed by 
jijijijiji xxs ,,,,, )1(ˆ αα −+=  (17) 
where jis ,ˆ  and jix ,  denote the denoised 
pixel and the directional-weighted-median 
filtered one, respectively. ji ,α  is a noise-free 
flag which can be decided according to the 
optimum absolute difference *)(
,
k
jid , given as  



 ≤
=
otherwise,     0
,      1 *)(
,
,
Td kji
jiα  (18) 
If the value of ji ,α  is equal to unity, the 
center pixel is noise-free. Substituting ji ,α  
into (17), the restored pixel is equal to the 
input pixel without change. On the contrary, 
 9
evaluation of speech quality (PESQ) [24]-[26] 
are conducted to evaluate the performance of 
a speech enhancement system. Only the 
performance in speech-activity regions is 
evaluated. A subjective listening test 
methodology standardized by the ITU-T P.835 
[26], and spectrogram comparisons are also 
performed. In order to evaluate the 
performance of the proposed system, a 
two-step-decision-directed (TSDD) algorithm 
[6] and the Virag method [1] were 
implemented for comparisons. The proposed 
three-step gain factor is constituted by these 
two methods. 
 
5.1. Noise estimate 
Noise estimator has been a major role on 
deciding the quality of a speech enhancement 
system. If the noise estimate is too low, 
residual noise increases. Conversely, if the 
level of noise estimate is too high, enhanced 
speech sounds would be muffled and 
intelligibility would be lost. The traditional 
voice activity detectors (VADs) are difficult to 
tune in non-stationary noise corruption. In 
addition, the voice activity detector (VAD) 
application to low SNR speech results often in 
clipped speech. Thus, the VAD cannot well 
estimate the noise level in non-stationary and 
low SNR environments. 
 Martin [21] proposed the minimum 
statistics algorithm to estimate the power of 
noise for each subband. The algorithm does 
not use the VAD, instead it tracks power 
minimum in each subband to decide the noise 
estimate. The minimum statistics noise 
tracking method is based on the observation 
that even during speech activity a short-term 
power density estimate of the noisy signal 
frequently decays to values which are 
representative of the noise level. This method 
rests on the fundamental assumption that 
during speech pause or within brief periods in 
between words and syllables, the speech 
energy is close or identical to zero. Thus, by 
tracking the minimum power within a finite 
window large enough to bridge high power 
speech segments, the noise floor can be 
estimated. Detailed procedure of the minimum 
statistics noise estimation algorithm can be 
found in [21]. 
 
5.2. Segmental SNR improvement 
The amounts of noise reduction, residual 
noise and speech distortion can be measured 
by the average segmental SNR improvement 
(Avg_SegSNR_Imp). The average of 
segmental SNR (Avg_SegSNR) of a test signal 
is evaluated according to clean speech 
) ,( nms , and the enhanced signal ) ,(ˆ nms . It 
can be expressed by 
 )
|) ,(ˆ) ,(|
|) ,(|
(log10
1SegSNR _
}{  
1
0
2
1
0
2
10∑
∑
∑
∈
−
=
−
=
−
⋅
⋅=
Im
N
n
N
n
nmsnms
nms
M
Avg
 (22) 
where } {I
 
represents a set of speech-activity 
frames. M and N denote the numbers of 
speech-activity frames and of samples per 
frame, respectively. m is frame index. 
 The Avg_SegSNR_Imp is computed by 
subtracting the Avg_SegSNR of noisy speech 
from that of enhanced speech. Table 1 
presents the performance comparisons in 
terms of the Avg_SegSNR_Imp for various 
methods. All of the speech enhancement 
algorithms provide significant Avg_SNR 
improvement in low-SNR environments 
(0dB).  
Table 1 presents the performance 
comparisons in terms of the average 
segmental SNR (Avg_SegSNR) improvement. 
 11
remove more amounts of residual noise, the 
score of the PESQ can still approach that of 
the Virag method.   
 
5.4. Waveforms 
Figure 4 demonstrates an example of 
speech waveform plots. Comparing the 
waveform plots of enhanced speech shown in 
Figs. 4(c)-4(e), the proposed method 
outperforms the TSDD and the Virag methods 
in removing background noise, while the 
post-processed speech in the speech-activity 
regions does not suffer from over-attenuation. 
The major reason is that the proposed method 
employs the hybrid median filter to modify 
the pre-processed spectra, yielding most 
musical tones with high energy being 
mitigated. Consequently, the enhanced speech 
of proposed method sounds less annoying than 
that produced by the Virag and the TSDD 
methods.  
 
Fig. 4. Example of speech signal spoken in Mandarin 
by a female speaker, (a) clean speech, (b) noisy speech 
corrupted by white noise with average SegSNR = 0 dB , 
(c) enhanced speech using the TSDD method, (d) 
enhanced speech using the Virag method, (e) enhanced 
speech using the proposed method. 
 
5.5. Spectrograms 
Objective measures cannot easily 
quantify the amount of residual noise in the 
enhanced speech. Analyzing the 
time-frequency distribution of the enhanced 
speech and evaluating the structure of residual 
noise, are particularly important. The speech 
spectrograms are therefore observed, to yield 
more information about the residual noise and 
speech distortion.  
 
(a) 
 
(b) 
 
(c) 
 
(d) 
 
(e) 
Fig. 5. Spectrograms of clean speech spoken by a 
female speaker, (a) clean speech, (b) noisy speech 
(corrupted by F16-cockpit noise with average SegSNR 
= 5 dB), (c) enhanced speech using the TSDD method, 
(d) enhanced speech using the Virag method, (e) 
enhance speech using proposed method. 
 
Figure 5 shows the spectrograms of a 
speech signal which is corrupted by 
F16-cockpit noise. Observing the 
spectrograms of enhanced speech during 
speech-pause regions shown in Figs. 5(c)-5(e), 
the proposed method is better able to remove 
 13
yielding the enhanced speech of the proposed 
method sounding more comfortable than the 
other speech enhancement systems. Extended 
research also goes to image denoising. 
Modifying the proposed post-processing 
system can be applied in impulse noise 
denoising for various noise densities. The 
proposed method also outperforms the other 
state-of-the-art algorithms.  
 
七、附錄 
7.1. 本計畫所發表之論文列表 
【1】 Ching-Ta Lu and Tzu-Chun Chou, “Denoising 
of salt-and-pepper noise corrupted image using 
modified directional-weighted-median filter,” 
Pattern Recognition Letters, vol. 33, pp. 1287- 
1295, Jul. 2012.(SCI) (NSC 100-2221-E-468- 
016) 
【2】 Ching-Ta Lu, “Noise reduction using three-step 
gain factor and iterative-directional-median 
filter,” Applied Acoustics, Submitted, paper 
number:APAC-D-12-00345, 2012. (SCI) (NSC 
100-2221-E-468- 016) 
【3】 Ching-Ta Lu, Kun-Fu Tseng, Chih-Tsung Chen, 
“Reduction of musical residual noise using 
hybrid median filter,” in Proc. IEEE Spring 
World Congress on Engineering and Technology 
(SCET) , vol. 2, pp. 458-461, Xi’an, China, 2012. 
(NSC 100-2221-E-468-016)(EI) 
【4】 Ching-Ta Lu, Tzu-Chun Chou, Kun-Fu Tseng, 
Chih-Tsung Chen, Chi-Yu Chen, “Salt and 
pepper noise reduction using modified 
directional-switch-weighted-median filter,” in 
Proc. National Symposium on Telecommuni- 
cations (NST), Nov. 18-19, 2011. (NSC 100- 
2221 -E-468-016.) 
【5】 Ching-Ta Lu, Kun-Fu Tseng, Chih-Tsung Chen, 
Yu-Chung Shen, “Speech enhancement using 
three-step gain factor and fuzzy-switching- 
median filter,” in Proc. National Symposium on 
Telecommunications (NST), Nov. 18-19, 2011. 
(NSC 100-2221-E- 468-016.) 
 15
 
Yours sincerely,  
 
Jaya Pavithra  
Central Administrator  
Applied Acoustics  
 
Comments:  
 
1) Full contact addresses of three potential reviewers including their e-mail 
addresses should be provided. 
 
2) Avoid vertical lines in tables. 
 
  
 17
 
 19
 
 21
 
 23
 
 25
7.4. 本計畫發表論文[3] 
Ching-Ta Lu, Kun-Fu Tseng, Chih-Tsung Chen, “Reduction of musical residual noise using hybrid median filter,” in 
Proc. IEEE Spring World Congress on Engineering and Technology (SCET) , vol. 2, pp. 458-461, Xi’an, China, 2012. 
(NSC 100-2221-E-468-016)(EI) 
 
 27
 
 29
7.5. 本計畫發表論文[4] 
Ching-Ta Lu, Tzu-Chun Chou, Kun-Fu Tseng, Chih-Tsung Chen, Chi-Yu Chen, “Salt and pepper noise reduction 
using modified directional-switch-weighted-median filter,” in Proc. National Symposium on Telecommuni- cations 
(NST), Nov. 18-19, 2011. (NSC 100- 2221 -E-468-016.) 
 
 31
 
 33
 
 35
7.6. 本計畫發表論文[5] 
Ching-Ta Lu, Kun-Fu Tseng, Chih-Tsung Chen, Yu-Chung Shen, “Speech enhancement using three-step gain factor 
and fuzzy-switching- median filter,” in Proc. National Symposium on Telecommunications (NST), Nov. 18-19, 2011. 
(NSC 100-2221-E- 468-016.) 
 
 37
 
 39
 
 41
參考文獻 
[1] N. Virag, “Single channel speech enhancement 
based on masking properties of the human 
auditory system, “ IEEE Trans. Speech Audio 
Process., vol. 7, no. 2, 126-137, 1999. 
[2] C. -T. Lu, K. -F. Tseng, C. -T. Chen, M. -Y. Wu, K. 
-L.  Hong, T. -T. Chou, “Speech enhancement 
using three-step-decision gain factor,” in Proc. 
National Symposium on Telecommun. (NST), Dec. 
2010. 
[3] C. -T. Lu, “Enhancement of single channel speech 
using perceptual-decision-directed approach,” 
Speech Commun., vol. 53, no. 4, pp. 495-507, 
2011. 
[4] S. Jo, C. D. Yoo, “Psychoacoustically constrained 
and distortion minimized speech enhancement, 
“ IEEE Trans. Audio Speech, Language Process., 
vol. 18, no. 8, pp. 2099-2110, 2010. 
[5] H. Ding, I.Y. Soon, S. N. Koh, and C. K. Yeo, “A 
spectral filtering method based on hybrid Wiener 
filters for speech enhancement,” Speech Commun., 
vol. 51, pp. 259-267, 2009. 
[6] C. Plapous, C. Marro, and P. Scalart, “Improved 
singal-to-noise ratio estimation for speech 
enhancement,” IEEE Trans. Audio Speech 
Languge Process., vol. 14, no. 6, pp. 2098-2108, 
2006. 
[7] W. Jin, X. Liu, M.S. Scordilis, L. Han, “Speech 
enhancement using harmonic emphasis and 
adaptive comb filtering, “ IEEE Trans. Audio 
Speech, Language Process., vol. 18, no. 2, 
356-368, 2010. 
[8] C. –T. Lu, “Reduction of musical residual noise for 
speech enhancement using masking properties and 
optimal smoothing,” Pattern Recog. Lett., vol.  28, 
no. 11, pp. 1300-1306, 2007. 
[9] C. –T Lu, K. -F. Tseng, “A gain factor adapted by 
masking property and SNR variation for speech 
enhancement in colored-noise corruptions,” 
Computer Speech and Language, vol. 24, no. 4, pp. 
632-647, 2010. 
[10] C. –T. Lu, K. –F. Tseng, C. –T. Chen, “Reduction 
of residual noise using directional median filter,” 
In: Proc. IEEE Int. Conf. Computer Science and 
Automation Engineer. (CSAE), vol. 3, pp. 475-479, 
2011. (NSC 99-2221-E-468-001) 
[11] C. –T. Lu, J. –H. Shen, K. –F. Tseng, “Speech 
enhancement using three-step-decision gain factor 
with optimal smoothing,” Int. J. Electrical Eng.,  
vol. 18, no. 5, pp. 209-221, 2011. (EI) (NSC 
99-2221-E- 468-001) 
[12] B. Chen, P. C. Loizou, “A Laplacian-basedMMSE 
estimator for speech enhancement,” Speech 
Commun., vol. 49, pp. 134-143, 2007. 
[13] H. Ding, I. Y. Soon, S. N. Koh, C. K. Yeo, “A 
spectral filtering method based on hybrid Wiener 
filters for speech enhancement,” Speech Commun., 
vol. 51, pp. 259-267, 2009. 
[14] T. Esch, P. Vary, “Efficient musical noise 
suppression for speech enhancement systems,” In: 
Proc. IEEE Int. Conf. Acoust., Speech, Signal 
Process. (ICASSP), pp. 4409-4412, 2009. 
[15] T. S. Gunawan, E. Ambikairajah, J. Epps, 
“Perceptual speech enhancement exploiting 
temporal masking properties of human auditory 
system,” Speech Commun., vol. 52, pp. 381-393, 
2010. 
[16] S. Jo, C. D. Yoo, “Psychoacoustically constrained 
and distortion minimized speech enhancement,” 
IEEE Trans. Audio Speech Language Process., vol. 
18, no. 8, pp. 2099- 2110, 2010. 
[17] C. –T. Lu, H. –C. Wang, “Enhancement of single 
channel speech based on masking property and 
wavelet transform,” Speech Commun., vol. 41/2-3, 
409-427, 2003. 
[18] C. –T. Lu, H. –C. Wang, “Speech enhancement 
using perceptually-constrained gain factors in 
critical-band- wavelet-packet transform,” Electron. 
Lett., vol. 40, no. 6, pp. 394-396, 2004.  
[19] C. –T. Lu, H. –C. Wang, “ Speech enhancement 
using hybrid gain factor in critical- band-wavelet 
 1
 
國科會補助專題研究計畫項下出席國際學術會議心得報告 
                                     日期：101 年 6月 1日 
一、參加會議經過 
本次會議屬於IEEE Computer Society的國際研討會議，承辦單位為IEEE Xi’an Section，會議的地點是在
中國西安市舉行，會議場所選在西安市當地著名的建國飯店舉辦。 
    本次的研討會(IEEE Spring International Conference on Engineering and Technology (SCET), 2012)
中，包含下列15個國際研討會共同舉辦： 
2012 Spring International Conference on Applied and Engineering Mathematics(AEM-S) 
2012 Spring International Conference on Biomedical Engineering and Biotechnology (BEB-S)  
2012 Spring International Conference on Computational Biology and Bioinformatics (CBB-S) 
2012 Spring International Conference on Computer Science and 
 Engineering (CSE-S)  
2012 Spring International Conference on Chemical Engineering (CEN-S) 
2012 Spring International Conference on Control and Automation (CAA-S)  
2012 Spring International Conference on Electronics and Electrical Engineering (CEEE-S)  
2012 Spring International Conference on Engineering and Business Management (CEBM-S) 
2012 Spring International Conference on Engineering Education (CEE-S)  
2012 Spring International Conference on Environmental Protection Engineering (CEPE-S) 
計畫編號 NSC 100－2221－E－468－016 
計畫名稱 使用互補型雜訊移除演算法及聲譜濾波法於語音增強之研究 
出國人員
姓名 
陸清達 
服務機構
及職稱 
亞洲大學資訊傳播學系/副教授 
會議時間 
101年 5月 27日至 
101 年 5 月 30 日 
會議地點 中國、陝西省西安市 
會議名稱 
(中文)2012 年春季國際工程與技術研討會 
(英文) IEEE Spring World Congress on Engineering and Technology 
(SCET), 2012 
發表論文
題目 
(中文)使用混合型中值濾波器於殘留雜訊移除之研究 
(英文)  Reduction of Musical Residual Noise Using Hybrid Median Filter  
附件四 
 3
    有部分與會學者也提出疑問：偵測母音的方法僅用最低頻的32個次頻帶的頻譜自我相關性做偵
測，可能會造成母音諧波頻譜偵測不準確，在選擇使用方向中值濾波或方塊中值聲譜濾波時，會因為
語音歸類錯誤，造成語音失真過大，或者音樂型殘留雜訊移除效果不佳的問題，詢問我們是否有想過
提升母音偵測準確率，來提升整體效能的措施；我們在會場中，非常感謝與會學者的建議，也認為這
是個很好的問題與思維，同時給予說明：目前已經在研究與實現提升母音偵測法的效能，除了提升本
系統對於音樂型殘留雜訊的效能，也希望可以重建遭到第一級語音增強，或者遭到第二級後處理刪除
的母音諧波頻譜，藉以提升母音信號。在這母音重建的過程中，我們必須準確的估測基頻頻率，故也
可由分析基頻頻率變化情形，作為判斷預處理信號是否屬於母音信號的依據，達到提升母音偵測準確
率，讓預處理信號可以正確的使用方向中值濾波，或者方塊中值濾波，提升音樂型殘留雜訊移除的效
能，也避免造成過大的語音失真。這些解釋與說明，讓提問的學者感到滿意；我們也期待在重建較弱
音強的諧波頻譜之後，語音品質可以有效提升，然後從事各種主觀與客觀的語音品質量測，以及殘留
雜訊移除效率的量化與質化分析，並且加入豐富的實驗證明與結果分析之後，可以將完整的研究成果
發表在SCI期刊論文中，讓更多的研究人員能夠分享我們的研究方法與成果。 
     
三、考察參觀活動(無是項活動者略) 
無 
四、建議 
參加完本次國際會議之後，我們有下面的心得與建議： 
1. 由於SCET 2012的論文主題很多，包括應用數學、語音處理、影像處理、視訊處理、網路通訊、射
頻通訊、模糊理論應用、控制與自動化應用、行動通訊、多重輸入多重輸出應用、生醫信號處理與
相關技術、無線通訊與網路相關技術、陣列信號處理、語音與影像結合之辨識系統、自動控制、估
測與量測技術、電機與電子工程、工程教育、以及各種資訊技術等等，討論的領域很廣泛，參加這
次的研討會可以增廣自己的研究領域，學習各種信號處理、通訊、控制的相關研究方法與技術，對
於拓展研究領域範圍，融合不同領域的關鍵技術到自己目前的研究主題，助益很多；而且可以讓自
己在目前的研究主題上，產生許多新的創意。 
2.由於 SCET 2012安排每個時段有 4個議程同時舉行，我們挑選跟音訊處理、影像處理、視訊處理、
估測理論、信號處理等等的相關論文聆聽，對於激發新的靈感與規劃新的研究主題，有很大的助
益。 
五、攜回資料名稱及內容 
研討會論文集光碟一片。 
六、其他 
 5
刊登論文 
 
 7
 
國科會補助計畫衍生研發成果推廣資料表
日期:2012/10/08
國科會補助計畫
計畫名稱: 使用互補型雜訊移除演算法及聲譜濾波法於語音增強之研究
計畫主持人: 陸清達
計畫編號: 100-2221-E-468-016- 學門領域: 訊號處理
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
