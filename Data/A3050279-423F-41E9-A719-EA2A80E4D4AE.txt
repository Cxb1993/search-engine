號，進行語音驗證來取代目前的圖形驗證
機制（見圖 1）。藉由這套語音驗證機制的
確認程序，將使得網站的資料存取安全獲
得更進一步的保障。本系統主要針對數字
0～9 共 10 個符號的部分來進行發音的辨
識。 
 
2. 研究方法 
2.1 特徵值的抽取 
特徵參數的抽取主要是以處理訊號為基
礎，將所得到的原始聲音訊號經過一序列
計算，可取得代表這串語音訊號的代表特
徵參數；我們先將一連串原始語音訊號切
割成數個音框後再進行各種特徵參數的抽
取，以便應用於我們製作系統所需的特徵
參數[1,7,11]。 
 
2.1.1  能量 
能量值可說是最基本的語音訓號處理
的特徵值，常用來判斷聲音的起始及結
束，其定義如下: 
∑
−
=
+=
1
0
2 )()(
N
m
mnSnEn   （2.1） 
上式中，N 為取樣點個數，n 為此段語
音之起始點，上式可用來計算一個音框大
小的能量值，作為有效語音的端點偵測之
用。 
 
2.1.2  取音框（Taking frames） 
以 256 個取樣點為一音框長度，為避
免兩相鄰的特徵音框變化過大，因此我們
在兩相鄰音框之間取重疊區域（Overlap 
area）85 個取樣點，便可避免音框間的變
化太過劇烈。 
預強調（Pre-emphasis） 
由於語音從嘴唇發出後會有高頻的損
失，因此我們把每一個音框內的語音訊號
通過一階高通濾波器來做預強調處理： 
)1()()(
)0()0(
−⋅−=
=
nsnsns
xs
α
 
ｓ(n)：聲音訊號經過預強調處理的值，
19.0 ≤≤ α              （2.2） 
漢明窗（Hamming window） 
為了減少訊號的不連續、聽起來像是
聲音中斷或是額外聲響的現象，我們採用
「漢明窗」使聲音訊號緩慢減小，降低在
邊界上的不連續現象，其公式如下： 








−≤≤
−
−
=
　　　　　　　　　　　
　
otherwise
Nn
N
n
nw
,0
10,)
1
2
cos(*46.054.0)(
pi
 
（2.3） 
2.1.3  自相關係數（Autocorrelation 
coefficients） 
自相關係數表示在一段時間內，訊號
之間的相關性，用於偵測語音訊號的週
期，也可求得聲音的基頻，其定義如下: 
∑
−
=
+=
mN
n
mnSnSnr
1
)()()(
, .10,10 −≤≤−≤≤ NmNn  
（2.4） 
2.1.4  線性預估係數（Linear Predict 
Coding, LPC） 
線性預估係數（LPC）的基本原理是
假設目前聲音的取樣值可以由前面 p 的取
樣值線性組合來預測，其定義如下: 
∑
=
⋅+−=
p
i
i neGinsans
1
)()()(~   （2.5） 
e(n): 線性濾波器, G: 線性濾波器的振幅,  
p: LPC 為預估濾波器之階數, ai : LPC係
數.  
 
2.1.5  倒 頻 譜 係 數 （ Cepstrum 
coefficients） 
倒頻譜係數主要用在表示聲音信號中
頻譜的波峰及細部變化的特徵值，比 LPC 
係數更能表現出語音訊號的特性，因此更
適合拿來做語音辨識的特徵參數；在倒頻
譜係數的計算上，可以經由 LPC 係數以下
列方式求得： 
llc α=     （2.6） 
第一個倒頻譜係數等於第一個 LPC 係
數，至於其它的倒頻譜參數則由下式求得： 
於客戶端，錄取語音後抽取聲音特徵參
數，將特徵參數傳送至伺服端驗證，依驗
證的結果傳回客戶端網頁確認，透過腳本
撰寫將控制元件與網頁作結合[15]。 
 
3.1 ActiveX 錄音元件 
ActiveX 是由 Microsoft 所開發建立的
一種開放性標準，是由一些具有互動式功
能的技術所組成，能夠使軟體元件在網路
的環境中相互溝通，發展出功能強大的網
際網路應用程式或在網頁內容添加多媒體
效果[2,4]，如在網頁上播放影像、動畫、
錄製聲音等等特殊效果。 
為了設計具備錄音機功能的 ActiveX
錄音元件，本系統採用 Win32 Application
所 提 供 的 多 媒 體 應 用 程 式 介 面
（mmsystem）來開發此錄音機元件，由音
效卡(Sound Card)來擷取錄下在客戶端使
用者的語音。有效的語音資訊至少取樣頻
率（Sample Rate）要在 8k Hz 以上，因此
本錄音程式設定取樣頻率為 11k Hz、及
8bit 的取樣品質以錄製使用者的聲音，這
些 錄 音 規 格 的 設 定 可 以 使 用
aveFormATEX 的結構變數來設定，並傳遞
這些設定參數給開啟錄音裝置的函式
waveInOpen()使用。 
3.2 特徵值轉換 
在製作 ActiveX 控制元件的過程中，
也即時抽取了使用者的語音特徵參數，轉
換為 10 階的倒頻譜陣列係數，每次的語
音訊號抽取特徵參數後，把音框數乘上 10 
階大小的多維陣列表示，先將多維陣列轉
換成一維陣列的資料，再將此一序列的特
徵參數使用 I/O 方式串接成字串包裝方
式，透過 IUnkown 介面[4]對外公開這個
字串陣列，讓瀏覽器網頁能存取到此特徵
參數字串並結合於表單中，其轉換的過程
如圖 3 所示： 
 
(a) 
 
(b) 
c 0 1 2 ‧‧‧‧ 7 8 9 
f=1 0      
f=2 0      
f=3 0   
 
‧‧‧‧ 
   
     :                   : 
f=
82 
2      
f=
83 
2      
f=
84 
2   
 
‧‧‧‧ 
   
 
圖 3 特徵參數轉換為一個特徵值字串(a)
原始語音訊號(b)計算倒頻譜系數陣列 
 
4.實驗結果 
 
4.1 訓練語句的收集 
此語音驗證系統放置於網際網路上使
用之前，我們將先在伺服端錄製樣本語
句，對本系統進行實驗及調整再建立模
組，接下來的實驗中是由國立勤益科技大
學的 10 位男學生，於實驗室中所錄製採集
的，周圍環境相當於一般室內房間(噪音低
於 30 分貝)，透過麥克風及音效卡，以每
秒 8k Hz 的取樣頻率，抽取 10 位語者的聲
紋特徵，由於驗證核心採用固定語句的方
式，因此我們截取固定的語句作為實驗中
所 測 試 的 聲 紋 資 料 ， 每 位 語 者 錄
製”0”、”1”、”2”、”3”、”4”
、”5”、”6”、”7”、”8”以及”9”，
各錄製 10 次，計算出每個音框的倒頻譜係
數，作為語音驗證之特徵值。 
 
向，目前本系統所採用之語音驗證基本架
構是以HMM為主，需不斷擴充訓練語音資
料來提高準確率，未來可加入動態時間扭
曲(Dynamic Time Warping, DTW)技術來
減少資料量，另外對於辨識系統效能的加
強，降低模型錯誤率，從單音節模型提升
至次音節模型可使辨識更廣泛，將成為改
進本系統之首要目標。在網頁上所使用的
錄音元件是以Microsoft 開發的ActiveX 
控制元件之規格撰寫，但ActiveX 控制元
件只限於視窗作業系統的平台上使用，今
後可考慮C or Java語言跨平台的特性，發
展嵌入式的語音驗證系統於其他平台。 
 
 
參考文獻 
[1] 王小川編著，語音訊號處理，全華科
技圖書股份有限公司出版，台北。 
[2] 椰風工作室編，ActiveX即時互動網頁
設計，博碩顧問有限公司出版，台北。 
[3] 楊鎮光，快速演算法在大字彙關鍵詞
萃取上的應用，國立中央大學碩論
文，2001。 
[4] 蔡孟哲編著，COM/ActiveX完全實作
寶典，松崗電腦圖書資料股份有限公
司，台北。 
[5] A. Kolupaev and J. Ogijenko, 
“CAPTCHAs: Humans vs. Bots”, IEEE 
Security & Privacy, Vol. 6,  Issue 
1, Jan.-Feb. 2008, pp. 68–70.  
[6] A.J. Viterbi, “A personal history of the 
Viterbi algorithm”, IEEE Signal 
Processing Magazine, Vol. 23, Issue 4, 
Jul. 2006, pp. 120-142. 
[7] Acevedo, C.M.D. and Nieves, M.G., 
“Integrated System Approach for the 
Automatic Speech Recognition using 
Linear predict Coding and Neural 
Networks”, Electronics, Robotics and 
Automotive Mechanics Conference, 
25-28 Sept. 2007, pp: 207-212. 
[8] G. Mori, and J. Malik, “Recognizing 
Objects in Adversarial Clutter: 
Breaking a Visual CAPTCHA”, 
Proceedings of the International 
Conference on Computer Vision and 
Pattern Recognition, Vol. 1, Madison, 
USA, 2003, pp. 134-141. 
[9] I.F. Ince, Ilker Yengin, Y.B. Salman, 
H.G. Cho, T.C. Yang, “Designing 
CAPTCHA Algorithm: Splitting and 
Rotating the Images against OCRs”, '08 
Convergence and Hybrid Information 
Technology, Vol. 2, Nov. 2008, pp. 
596-601. 
[10] L.R. Rabiner and B.H. Juang, “An 
Introduction to the Hidden Markov 
Model”, IEEE ASSP Magazine, Jan. 
1986, pp. 4-16. 
[11] Pei-Yuan Hong, Yun-Long Lay, 
Hui-Jen Yang, “The implementation of 
graphic-displaying speech learning 
system for hearing impairments”, 2th 
Intelligent Living Technology, National 
Chin-Yi University of Technology, Jun. 
2007.  
[12] R. Cai, Lu Lie, A. Hanjalic, 
Hong-Jiang Zhang, and Lian-Hong Cai, 
“A flexible framework for key audio 
effects detection and auditory context 
inference”, IEEE Transactions on 
Audio Speech and Language 
Processing, Vol. 14, Issue 3, May. 
2006, pp. 1026–1039. 
[13] R. Datta, J. Li and Z. Wang, 
“Exploiting the Human-Machine Gap 
in Image Recognition for Designing 
CAPTCHAs”, IEEE Transactions on  
Information Forensics and Security: 
Accepted for future publication, 2009, 
pp. 1–1.  
[14] Yan, J., El Ahmad, A.S., “CAPTCHA 
Security: A Case”, IEEE Study 
Security & Privacy, Vol. 7 , Issue 4, 
July-Aug. 2009, pp. 22-28. 
[15] 吳俊德，WWW上結合聲紋確認機制
之身份驗証系統，高雄第一科技大學
碩士論文，2000。 
 
 
、 計畫成果自評 (請就研究內容與原計畫相符程度、達成預期目標情況、研究成
果之學術或應用價值、是否適合在學術期刊發表或申請專利、主要發現或其
可利用之產業 
及 
可開發之產品 
網路安全、網路驗證、人員管理系統 
技術特點 
在辨識方面，先將語音分成一個個音框(frame)，對音框的語
音取樣資料作前處理，再求出線性預估係數(Linear Predict Coding, 
LPC)、倒頻譜參數(Cepstrum coefficients)、轉移倒頻譜參數後得到
語音資料的特徵值，接著使用隱藏式馬可夫模型（Hidden Markov 
Model, HMM）來建立辨識模型作為語音識別的基準，最後使用維
特比演算法(Viterbi algorithm)計算結果的相似度來做比對。我們將
以此來分辨是否為正常的使用者，藉由這套機制與網頁做整合的
語音驗證，確實能夠達到控制網站上資源存取的目的，來防止網
站遭受有心人士利用程式來進行惡意破壞或竊取密碼、資料等不
當行為。 
推廣及運用的價值 網路安全、網路驗證、人員管理  
※ 1.每項研發成果請填寫一式二份，一份隨成果報告送繳本會，一份送 貴單
位研發成果推廣單位（如技術移轉中心）。 
 
 2 
 
 
ICMLC 2011 研討會第一埸 keynote speaker 演講結束現場 
 
此次會議發表的論文已所錄至 Engineering Village (EI)索引，文章內容如下所述。 
 
 
Face Moiré Detection and Recognition 
Yun-Long Lay 
Department of Electronic 
Engineering, National 
Chin-Yi University of 
Technology 
 
Hui-Jen Yang 
Department of MIS, 
National Chin-Yi 
University of Technology 
 
Chern-Sheng Lin 
Department of Automatic 
Control Engineering, Feng 
Chia University 
 
Wei-Yu Chen 
Department of Electronic 
Engineering, National 
Chin-Yi University of 
Technology 
 
 
Abstract—This study applies shadow moiré to get the 3D data 
of a human face with its contour profiles as recognition 
features in real time. The recognition process is from external 
fringe gradually comparing to internal fringe. Hence, from the 
outside fringe to the inside fringe, a queue of levels data 
structure is created which will speed up the searching and 
recognition of each processing object. 
Keywords—Shadow Moiré; face-shape recognition,  
contour 
 INTRODUCTION 
The advancement of optical technology and 
the continuous improvement of human feature 
recognition technology are largely applied in 
information security, communications, banking 
systems, and even the personal recognition 
systems in businesses or the government.  
However, finding a single matching target from a 
vast database of users presents a critical 
bottleneck of processing speed. Recently, most 
face recognition research has concentrated on the 
study of software feature extraction and 
recognition algorithms [1-3].  Research on 3D 
face recognition with Moiré is still limited. How 
to effectively analyze, store and compare features 
are important issues in the pattern recognition 
domain, especially for 3D objects. 
The optical measurement method uses lasers 
or light interference to measure objects [4]. There 
will be no contact stress or vibration to cause bias 
or damage of the testing object. This method is 
very suitable to measure a  
soft object. In addition, its application domains 
are wide, such as industrial model design 
processing, reverse engineering, medical 
engineering, surgery simulation, 3D animation 
and so on. 
This research applies the shadow moiré 
method to recognize a 3D face. The contour 
 4 
 
equipment to obtain images shall be the 
interception of the two gratings which form the 
moiré pattern, and can be regarded as the surface 
contour profile. The shadow moiré is not only a 
cost-saving method, but is also the easiest setup.  
In order to allow observers to intuitively 
understand the ups and downs of surface with 
contour fringes, the measurement resolution could 
be changed by setting the light angle or the 
grating pitch distance. This method is very 
suitable for measuring the external contours of 
objects. 
The image processing methods 
In the moiré image, if the reference grating 
pitch is too large then the reference grating stripes, 
which are not the required information, will be 
very obvious. The impact of stripes on the images 
is comprehensive and can be seen as a periodical 
noise in the whole image. It must be removed. 
Suppose the original matrix is f (x , y), where x 
and y are matrix elements. Through Fourier 
transformation, the output matrix is F(u ,v). 
Suppose the matrix index is M×N, with the 
x-index ranges from 0 to M-1 and the y-index 
ranges from 0 to N-1. Equations 8 and 9 are the 
two-dimensional discrete Fourier transformation 
formulas [10]: 
∑∑
−
=
−
=












+−=
1
0
1
0
2exp),(),(
M
x
N
y N
yu
M
xuiyxfvuF pi         
(8) 
The reversed transformation is 
∑∑
−
=
−
=












+=
1
0
1
0
2exp),(1),(
M
x
N
y N
yu
M
xuivuF
MN
yxf pi         
(9) 
 
     
   (a)                                                
(b) 
Figure 1.  Graph of Shadow Moiré Measurement 
 
Fig. 1 (b) is the extracted image of the Moiré 
where the pitch of reference grating is 1mm (p = 
1mm), light source is from θ1= 35 ° to project, 
and the observation angle is from θ2 = 0 ° to 
observe. Through Equation 3 calculating the 
d=0.714N(mm), there is a depth change of 1 mm 
in each pixel. The image area was cut 
appropriately and the color image was converted 
into grayscale for each pixel. RGB with Equation 
10 fills in the original pixel [11]. Equation 10 is 
described as follows. 
Gray=0.299×R + 0.587×G + 0.114×B                    
(3)  
After enhancing , a better contrast image can 
be derived.  The pixels of each horizontal line of 
the block have been analyzed to find out the 
minimum gray-scale values. This value serves as 
the image cutting threshold foundation to make a 
record of lowest image position for the curve line. 
Namely, it is the fringe of moiré. 
The easiest way to match contours is to 
compare two contour coordinates. All the pixels 
on the contour points make a sum operation and 
yield a feature. This method relies on the 
coordinates, which have a higher recognition rate 
for a fixed image profile. However, if the fringe 
has parallel movement or rotation, it will result in 
a great deal of errors. Applying Hu’s [12] 
unchanged matrix in the calculations, this method 
will generate seven geometric matrixes. These 
matrixes recognize the similar moiré fringe with 
parallel movement, rotation or mirroring as the 
same pattern [13]. The algorithm is as follows: 
 
The central matrix is defined as: 
∑∑ −−=
x y
qp
pq )y,x(f)yy()xx(µ                 
(4) 
f(x, y) is a digital image. 
 
The centroid is described as follows: 
00
01
00
10
m
m
y,
m
m
x ==  
00
01
00
10
m
m
y,
m
m
y ==                                                       
(5) 
The image matrix is as follows: 
 6 
 
[8] A. M. Siddiolo, D'Acquisto, L., “A Direction/Orientation-Based 
Method for Shape Measurement by Shadow Moiré,” Instrumentation 
and Measurement, IEEE Trans., vol. 57, no. 4, pp. 843 – 849, Mar. 
2008. 
[9] A. Glassner, “Andrew Glassner's Notebook: Recreational Computer 
Graphics,” IEEE Computer Graphics and Applications. , Morgan 
Kaufmann, Apr. 1999. 
[10] A. McAndrew, “Introduction to Digital Image Processing with 
MATLAB,” Thomdon Learning Company, Jul. 2004. 
[11] Convert RGB image or colormap to grayscale. 
http://www.mathworks.com/access/helpdesk/help/toolbox/images/rg
b2gray.html (retrieved date 07-19-2009).11 
[12] M. K. Hu, “Visual pattern recognition by moment invariants,” IRE 
Transactions, vol. 8, no. 2, pp. 179 - 187, August 1962. 
[13] J. Flusser, T. Suk, “Rotation Moment Invariants for Recognition of 
Symmetric Objects,” IEEE Trans. Image Processing, vol. 15, no. 12, 
pp. 3784 - 3790, Sep. 2006. 
[14] J. S. Noh, K. H. Rhee, “Palmprint identification algorithm using Hu 
invariant moments and Otsu binarization,” Computer and 
Information Science, Fourth Annual ACIS International Conference, 
pp. 94 - 99. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
99 年度專題研究計畫研究成果彙整表 
計畫主持人：賴雲龍 計畫編號：99-2221-E-167-002- 
計畫名稱：聽障生網路即時通信與語言學習系統研製 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 1 1 100%  
研討會論文 1 1 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 3 3 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 2 2 100%  
研究報告/技術報告 0 0 100%  
研討會論文 3 3 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
