develop an intelligent embedded robot software 
system. The system is an agent system of team robot 
that proposes a cooperative and adaptive mechanism to 
take a complex mission. 
The roadmap of this project is described as 
following. The previous two years, we already studied 
some robot systems and development platform, and 
developed an intelligent agent system that can make 
goal evolution and action learning in the RoboCup 
domain. In this year, we applied the robot learning 
platform developed in previous two years to propose a 
cooperative learning mechanism for the robot agent, 
and to develop an intelligent embedded open source 
codes. The cooperative learning process will handle 
flexibility the different service components to 
provide an adaptive intelligent software service. We 
also developed strategies learning mechanism for 
agent knowledge. Each agent has individual experience 
and knowledge, so they have evolve different 
strategies to resolve different problems. 
英文關鍵詞： Intelligent Agent, Team Strategies evolution, 
automation action plan, robot embedded system 
 
 2
中，代理人的任務協商、目標學習演化、與自我調適性是相當重要的。因為在真實環境中
存在各種不同的變動因素，代理人必須瞭解自己的目標任務，且隨外在情境的變化而更改
計畫策略。例如在足球場上，為因應環境的動態變化，如何使足球機器人能夠快速的適應
多變的競賽環境以達到得分目的並不容易，此時所有的代理人必須共同合作協商、互相學
習，以找出最佳的調適狀態。本計畫之四年開發路程(Roadmap)為：(1) 2008：研究機器人
系統平台與軟體開發環境，發展智慧型機器人目標學習演化機制；(2) 2009：發展智慧型機
器人代理軟體系統互動溝通、同化學習的架構；(3) 2010：發展智慧型機器人代理軟體系統
個人策略演化、行動規劃的架構；整個系統架構如圖1所示，機器人核心軟體由智慧型代理
人控制，機器人可以透過藍芽系統協商、溝通，以合作完成複雜的共同任務。 
 
3. 文獻探討 
在多重代理人系統中，代理人被指派較難的任務，代理人遇到困難而無法執行任務時，
代理人之間能夠以合作的方法來完成，以提升整體效能[11]。論文[12]實做多重機器人系
統，讓機器人以合作的方式執行較難的任務。將代理人分成幾個群組，當要指定任務時，
則以群組為單位，變成將任務指定給代理人群組而不是指定單一代理人來執行。當機器人
遇到新的任務需求或為了適應環境變化時，機器人會轉變現有的工作或角色交換；但是當
機器人遇到超出自已能力的任務，會尋求其他機器人幫助。 
研究[4]應用軟體行動代理人設計虛擬操作多代理人架構，智慧型代理人和機器人代理
人共同控制機器人，使其服從所指定的任務，動態執行工作並隨時可以轉而控制最初沒指
定的新任務。為了解決多代理人系統中決策問題，研究[9]提出以狀態-行為地圖的動態程序
設計的合作機器人，證明動態程序設計對機器人在自覺方法非常有用，利用八個變數延展
到制定決策的6億1千萬個狀態，實做動態程序的設計，解決機器人合作在每一個決策中創
造出向前看表格的最佳化行動。在連續狀態空間的行為中，兩個模擬合作機器人減少得分
所需步驟的次數，它們能夠交換傳球，接球。 
論文[13]利用傳遞學習的程序，從新的和更複雜的工作中重整經驗，發展一個學習架構
讓機器人傳遞早期學習的設定，應用到後來更複雜的工作設定，例如一般的開車技巧。運
用動作命令與其他感應訊號讓機器人學習夠多新的複雜的感應馬達工作技巧。研究[6]希望
足球機器人能在足球場上運用人工智慧超越人類，做法是把足球機器代理人的行為分為二
階層，一個是單純只與自己有關行為動作，例如射球傳球等，另一階層是全體機器人的合
作、或是策略行為。定義此兩種行為是為了讓足球機器人更像人類踢足球一樣。除了自我
球技，加上學會團隊合作，研究人員希望在2050年能贏過真實球員。 
研究[10]提出進階程式語言，用於自動產生函式以及挑選演算法，使的在足球機器人比
賽中得到有效率的行為。期望能藉由設定競賽環境和目標，產出高效能的機器人。目前使
用模擬器開發出一個系統，可以從XML中讀取記載機器人行為的資料。此研究著重於使用
進階程式語言產生足球機器人比賽團隊所需的多機器人系統行為。論文[8]將其自2000~2006
年間以強效式學習應用於機器人足球比賽上的方法和經驗發表。基於強效式學習，其機器
 4
 
 
時間演化，產生良好的控制規則。 
4.1.發展基因演化模糊控制方法 
基因模糊系統是以模糊控制來對被控系統做控制輸出，在模糊化策略方面，採用三角
形歸屬函數當作模糊推論引擎與環境間的介面，並能簡化模糊推論的計算複雜度。模糊規
則的前件部採用混合模糊命題，使用 t-norm 為連接詞。模糊推論的模糊關係採用 Mandani 
min implication[6]。模糊規則庫中每一條規則輸出的推論採用 s-norm 合成，模糊推論引擎
為 Mandani min-min-max 推論。推論結果採 Center average defuzzifier 轉換明確數值。基因
演化模糊系統是以基因演算法搜尋最佳模糊規則，步驟： 
(1) 族群初始化：將第一代初始族群所有個體的染色體以隨機方式產生，族群中個體的總
數與染色體位元字串的長度皆依照系統需求分別採用固定常數。 
(2) 適應性評估：對該代族群所有個體進行效能評估，將染色體解碼成模糊系統中的模糊
規則庫，對受控系統作控制輸入，再以適應性函數將所有個體區分優劣，效能表現好
的個體得到較高的適應值，反之得到較低的適應值。 
(3) 終止運作：判斷基因演算法是否符合停止條件，如果符合則終止基因演算法，反之則
繼續進行步驟 4。停止條件設定當族群演化代數上限已達一個目標或族群個體平均效能
已達系統設定目標。 
(4) 產生子代：採精英策略先從母代挑選 n 個適應值最高個體直接複製到子代。剩餘的子
代再從母世代族群中採輪盤法挑選個體進入交配池，交配運算以隨機的方式從交配池
中選出兩個個體，以交配率 pc，單點交配的方式產生兩個子代個體，直到子世代族群
數目達設定目標為止。子世代族群中每個個體的染色體以 pm機率、每位元以 pb 機率進
行突變。最後檢查這一代是否有重複染色體產生。 
(5) 基因修補策略：基因複製過程中，染色體經過交配、突變後可能產生基因無法解碼。
由於歸屬函數的基因編碼中MFC欄位必須滿足C1 C2 C3的設定，因此基因修補的動作
需將 C1、C2、C3 以小到大排序並更新染色體。 
(6) 反覆評估：基因演算法完成一個世代的演進後，回到步驟 2 進行子世代群體適應性評估。 
4.2.發展基因演化搜尋方法 
利用基因演算法校調模糊系統的參數，如何以基因位元字串編碼，使這些參數組成具
有控制特徵的基因染色體，進而控制系統是建立模糊基因系統的首要任務。在基因模糊系
統中，所有語意變數的模糊集合以三角形歸屬函數的形式呈現，μi = (Li, Ci, Ri)，其中 Li, Ci, 
Ri 分別表示三角形歸屬函數中左底部點、中心底部點及右底部點，並在論域的數值上定義
Li < Ci < Ri，且語意變數在 Ci點上有最大的歸屬值，i 則是表示一個語意變數的第 i 個歸屬
函數之標號。 
 
 
圖 2 歸屬函數的基因編碼 
1 1 0 1 0 0 1 0 0 1 1 0 00
MFN MFC
C1          C2           C3
 6
 
 
 
 
 
 
 
圖 4 帶球前進訓練場景示意圖 
表 1 系統輸入與輸出變數 
x1 敵人與前進方向的夾角 
x2 敵人的距離 輸入語意變數 
x3 敵人的速度 
y1 踢球的方向與前進方向的夾角 輸出語意變數 
y2 踢球的力量 
 
(1) 定義基因模糊系統輸入與輸出的語言變數：當球員在可踢球的狀況下，系統考慮三個環
境輸入變數及產生兩個輸出變數，如表 1 所示。 
(2) 定義各個語意變數的論域數值：由於實驗是在同一個問題領域也就是足球比賽中探討，
因此對於相同的語意變數使用相同的論域是合理的，所以本實驗的距離為 0~15M 範圍、
力量為 0~100%範圍、夾角為-90°~90°範圍、速度為在-10~10 m/s 範圍。為語意變數的歸
屬函數型態的例子，力量變數有五個語意數值，距離變數有四個語意數值，速度有三個
語意數值，夾角有五個語意數值。 
(3) 定義模糊規則庫的規則數量：設定模糊規則最大數量為 100 條，由於初始規則由亂數隨
機產生，初始族群的模糊規則約 50 條，之後將隨基因演算法調整。 
(4) 染色體的編碼與解碼：初始族群所有個體的染色體以隨機的方式產生，基因編碼
110100100011005 之模糊規則解碼：IF ( 11X = 3aμ ) and ( 12X = 3dμ ) and ( 13X = 2sμ )   THEN 
( 11Y =
0
aμ ) and ( 12Y = 3pμ )   
(5) 定義評估函數：評估函數是將族群中所有個體分出優劣的依據，要儘可能將個體的表現
級距拉開，以達汰弱留強的目的，評估函數定義 F = α(A)+ β (B)+ γ (1/C) +δ (D)，其中
α=1, β=0.5, γ=1000, δ=-100，變數 A 表示球被踢到的次數，B 表球最後被踢到的位置與
起始點的距離，C 表球最後被踢到的位置與敵方球門中心點的距離，D 表球是否由進攻
方踢出界外，若出界則值為 1 反之則為 0。不同參數的設定將影響評估結果，α設定表
示運球能力、β、γ表示攻擊能力，δ表示閃避能力。 
6. 基因演化參數設定： 
表 2 基因演算法參數設定 
群體大小 100 
演化代數 30 
每代個體評估次數 2 
選擇型態 輪盤式選擇 
訓練範圍
 
 8
1.攻擊代理人感測到敵人的速度、距離和
敵人與前進方向的夾角並產生出踢球的力
量、踢球的方向與前進方向的夾角。 
2. 紀錄球被踢到的次數、球最後被踢到的
位置與起始點的距離、球最後被踢到的位
置與敵方球門中心點的距離和球是否由進
攻方踢出界外。 
3. 計算評估函數 F = α(A)+ β (B)+ γ (1/C) 
+δ (D)，其中α=1, β=0.5, γ=1000, δ=-100 
 
Expected Result 利用評估函數以區分出個體優劣去達到汰弱留強的目的，進而演化出一套有效率的動
作決策。 
 
(4) 驗證驗證代理人可透過 RoboCup 模擬系統進行比賽。。 
Actor Actions System Responses 
1. 進攻方代理人利用基因模糊演化進行
射門。 
2. 防守方代理人攔截進攻方代理人。 
Instructions 
3. 在足球場上進行攻守比賽。  
Expected Result 將程式碼燒入真實 LEGO 模組套件進行比賽。 
 
最後利用系統中最後演進30世代完的基因，把其動作模糊規則庫轉換成JAVA程式，以便燒
入NXT機器人硬體中。NXT機器人利用模糊規則函示庫去分析環境資訊做出進攻並躲避防
守員的動作。 
 
 
 
 
 
 
 
圖 5 NXT 機器人分析環境並躲避防守員 
6. 結論 
本研究發展智慧型機器人代理軟體系統個人策略演化、行動規劃的架構；未來的研究
方向，我們將考慮發展智慧型機器人代理軟體系統策略分享學習、團隊策略學習與演化架
構。 
7. 參考文獻 
[1] E. Aatashpaz Gargari, B.N. Araabi, C. Lucas, Optimal Fuzzy Passing Strategy for Robot 
Soccer Players, IEEE International Conference on Fuzzy Systems, pp. 1576-1581, 2008. 
[2] J. Bruce, S. Zickler, M. Licitra, M. Veloso, CMDragons: Dynamic passing and strategy on a 
champion robot soccer team, IEEE International Conference on Robotics and Automation pp. 
4074-4079, 2008. 
[3] J. Hespanha, H.J. Kim, and S. Sastry. Multiple-agent probabilistic pursuit-evasion games. In 
Proceedings of 38th IEEE CDC, pp. 2432-2437, 1999. 
 1
國科會補助專題研究計畫項下出席國際學術會議心得報告 
                                   日期： 100  年 7 月 21 日 
一、參加會議經過 
The 2011 International Conference on Machine Learning and Cybernetics (ICMLC 2011)是
人工智慧、機器學習領域重要的國際研討會，會議於 2010 年 7 月 10 日至 13 日於中國廣西
壯族自治區桂林市喜來登酒店舉行，會中來自許多不同國家的學者共同參與討論，發表學
術論文包括模糊理論、類神經網路、智慧型代理人、商業智慧、資料探勘、資訊檢索等各
研究領域。 
7月 12日大會舉辦一場Keynote Speech，由 Shyi-Ming Chen教授主講「Fuzzy Forecasting 
Based on High-Order Fuzzy Time Series and Genetic Algorithms」，以及 Panel Discussion，由
Daniel Yeung、Tin Kam Ho、Hong Yan、Witold Pedrycz 與 Vladimír Mařík 等學者參與討論。
其中 Panel Discussion 的主題是「The Genesis of an Innovative Research Topic」，主要討論對
於研究者，如何挑選合適的研究題目，及如何建立創新的研究方向，會中各學者的建議讓
我獲益良多，也得到許多研究上的啟發。12 日晚間為大會晚宴，今年為 ICMLC 會議十週
年，大會舉辦慶祝儀式並頒發本年度的「Lotfi Zadeh Best Paper Award」。 
本人論文安排在 7 月 13 日上午，session 主題為「Intelligent systems and applications」，
此 session 發表之論文主題大多與 web service 技術以及 semantic web 技術相關之智慧型系
計畫編號 NSC 99-2220-E-027-009 
計畫名稱 應用智慧型代理人技術於機器人合作學習系統之開發 III 
出國人員
姓名 
郭忠義 
服務機構
及職稱 
國立臺北科技大學資訊工程系 
會議時間 
100 年 7 月 10 日至 
100 年 7 月 13 日 
會議地點 
中國廣西壯族自治區桂林市 
會議名稱 
(中文) 2011 年國際機器學習與控制研討會 
(英文) International Conference on Machine Learning and Cybernetics 
(ICMLC 2011) 
發表論文
題目 
(中文) 無 
(英文) A Hybrid Approach to Multi-agent Pursuit-Evasion Game 
國科會補助計畫衍生研發成果推廣資料表
日期:2011/12/12
國科會補助計畫
計畫名稱: 應用智慧型代理人技術於機器人合作學習系統之開發III
計畫主持人: 郭忠義
計畫編號: 99-2220-E-027-009- 學門領域: 自由軟體暨嵌入式系統
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
