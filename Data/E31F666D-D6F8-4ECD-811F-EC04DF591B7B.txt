本計劃所提出的一般性影像分割架構如圖 1 所示，此圖描述一個由
下而上的多級處理之影像分割架構，最後的輸出結果是一個分層表示的
物件區域描述圖。架構中的第一級處理是從原始影像中擷取灰階變化或
不連續處的能量，再由此能量圖偵測出各方向的局部能量最大值，稱為
邊線特徵點並依據準則將其分類為輪廓點與紋理點，在此階段，我們基
本上已解決了輪廓與紋理的區分問題。接下來的處理過程將暫時分為輪
廓處理與紋理處理。在輪廓處理程序方面，首先將第一級的輸出，即灰
階變化能量圖，輸入至第二級同方向能量截取單元，並由此單元的輸出
偵測交點與高曲率點，我們稱這些點為全方位點，簡稱為
AP( all-orientation peak ) 點。以 AP 點為起始點，並參考其轉折方向，將
離散的輪廓點連結至另一個 AP 點，此連結過程必須克服輪廓點不連續
而產生間隙的問題。 緊接著，我們利用 AP 點及轉折方向產生有效的外
差 ( extrapolated ) 延伸輪廓，這些輪廓代表無邊緣存在的遮擋輪廓與被
遮擋輪廓。所以在此階段已解決了無邊緣存在及遮擋與被遮擋的兩個問
題，最後這兩種輪廓，即實質輪廓與外差延伸輪廓共同送入區域擷取單
元，找出區域邊界。另一方面，在紋理處理流程裡，首先將每一紋理特
徵點與鄰近的紋理特徵點經非線性轉換連接在一起，在每一方向形成平
坦化的同質紋理能量圖，將它輸入到紋理邊界能量擷取單元，並偵測其
邊界點與 AP 點，而後續的程序與輪廓處理程序是相同的。以下將附上
 Separating Contours from Texture Edges in 
Natural Images 
Chengho Hsin, Shih-Chang Chen, Yi-Ku Lin, Shaw-Jyh Shin  
Department of Communications Engineering, Feng Chia University, Taichung, Taiwan, ROC 
  
Abstract—The main purpose of this paper is to develop a contour 
extraction scheme based on suppression of texture-like edges. Traditional 
edge detection methods are unable to distinguish between contours of 
objects and edges originating from textured regions. This difficulty is 
resolved by the proposed scheme. Three modules of contour attributes 
describing the independence of the detected edges are established. A 
procedure of eliminating texture-like edges by applying the contour 
attributes is performed through processes of contour decision, generation 
of model parameters, and contour integration. From experimental results, 
it has shown that the developed contour detection scheme produces 
reliable object boundaries. 
 
Index Terms—Contour detection, edge detection, image segmentation. 
I. INTRODUCTION 
any contemporary edge detection methods [1-6] failed 
to distinguish between contours of objects and edges 
originating from textured regions (so-called texture-like 
edges). This will hinder the subsequent tasks such as 
contour-based segmentation and object recognition. Natural 
images contain both textured and untextured regions. 
Traditional edge detection methods produce meaningless 
tangled and random edges in a textured region. The common 
solution for this problem in edge detection is to use a high 
threshold so as to minimize the number of edges found in the 
texture area. Obviously the extended contours of low contrast 
will be eliminated. The essential problem with simple edge 
detection models have led researchers to develop various 
methods that extract the contours of objects from textured 
backgrounds, such as the level set approach [7], active contour 
scheme [8], local cues combination methods [9,10], and 
edge-based approaches [11,12]. These methods are either very 
complex or full of ad hoc design decision. 
  
We propose a novel approach to extract salient contours by 
eliminating the texture-like edges simultaneously. The 
developed scheme deals with general images. Regions with or 
without textures are processed in the same framework. 
Contours defined by brightness edges as well as lines are 
derived in the same manner. Fig.1 shows the block diagram of 
the proposed contour detection scheme. It consists of units of 
edge detection, contour attributes, contour decision, model 
parameters, and contour integration. The remainder of the 
paper is organized as follows. Section II describes an edge 
detection model base on an adaptive local grey-level mapping. 
Three modules of contour attributes characterizing the 
independence of edges are established in Section III. A 
procedure of suppressing texture-like edges by applying the 
contour attributes is discussed in Section IV. Finally, 
simulation results and conclusion are given in Sections V and 
VI, respectively. 
 
Edge Detection
Contour 
Decision Unit
Modules of 
Contour Attributes
Contour 
Integration
Contour M odel 
Parameters
A Final Contour 
Map
An Input 
Im age
 
M Fig. 1 The block diagram of the proposed contour detection scheme. 
II. EDGE DETECTION BASED ON A LOCAL GREY-LEVEL 
MAPPING 
Most edge detection methods [1-6] failed to produce 
connected edges near and at the corners or junctions. 
Treatment of edge and line features in a unified scheme is still 
a core research problem. In addition, the issue of deriving a 
simple and efficient multi-scale edge detection structure has 
not been resolved yet. We propose an entirely new approach to 
solve these difficulties. A multi-scale and multi-orientation 
edge detection scheme based on an adaptive local grey-level 
mapping is developed. The purposes of the mapping are 
twofold: increasing the amplitudes of the weak edges with 
respect to those of the strong edges and modifying the local 
grey-level pattern to facilitate the extraction of the weak edges 
near corners and junctions. The block diagram of the proposed 
edge detection scheme is shown in Fig. 2. A normalized 
orientation channel shown in Fig. 2 is composed of three units 
which are an adaptive local grey-level mapping, the unit of 
orientation filtering and energy extraction, and the unit of local 
peak detection. A Gaussian smoothing filter is inserted in front 
of the normalized channels for both noise reduction and 
mapping enhancement. The impulse responses of the 
orientation filters are the  directional derivatives of a 
Gaussian function, which are expressed by 
th-orderp
( ) ( )( , ; , ) ( ; ) ( ; )p pg x y g x g yθ σ σ′ ′= σ                   (1) 
where the superscript indicates the order of the 
differentiation, 
p
σ  is the scale parameter, θ  is the direction 
orthogonal to the orientation, and  
 
 The continuity of an image point is measured by the total 
weighted Teager energy in the scale space that is defined by 
( )LL yx ,
( ),e ex y
( )RR yx ,
θLLine
θ
x
y
 
( )( , ; , ) ( , ; , , )
s
p s sv x y p t x y pσ
θ ε σ θ σ= ∑                (11) 
where  
Fig. 7 A line Lθ . (2 3)
( )
2
( 3 2)
p
s
p s p
πσε σ
+
= Γ +                             (12) 
( )LL yx , ( ),e ex y ( )RR yx , θLLine
( ), ; ,v x y pθ
 
is the energy weighting factor which gives higher weights to 
larger scales. Hence, the continuity of an edge point is 
evaluated by . On the other hand, the  ( , , , )e ev x y pθ
H ig h e s t
C o m p le x i ty
L o w e s t
W e a k e s t
( T a n g e n t ia l  d i r e c t io n s  o f  c o n to u r s )
S t r o n g e s tC o n t in u i ty
C o n to u r  E d g e s
T e x tu r e - l ik e  E d g e s
N
orm
al directions of 
conto
urs
 
Fig. 6 The classification of the contour edges and the texture edges in terms of 
the continuity and the complexity. 
 
complexity of an edge point is measured by 
( , ; , ) [ ( , , , )]
p
e e
C
s x y p F v x y p d
θ
θ = ∫ Aθ           (13) 
where [ ]F ⋅  denotes a functional form, the integration is 
performed along the direction θ , and pCθ  is the integration 
interval which will be defined below. An energy envelop of an 
orientation channel, ( , , ,v x y )pθ , at a given edge point 
 along a line (see Fig. 7):  )e,( e yx θL
( ) cos ( )sine ey y x x 0θ θ− − − =                 (14) 
is shown in Fig. 8. For each edge point at , define a 
local interval  along a line , such that 
),( ee yx
pCθ θL
{
}
( , ) ( , ; , ) ( , , , )
          , ,
p
e e
L R L R
C x y L u x y p u x y
x x x y y y
θ θ θ θ= ∈ ≤
≤ ≤ ≤ ≤
p
           (15) 
where ( , )L Lx y  and ( , )R Rx y  are the two nearest valley points 
of the edge point. 
Since a contour may represent the boundary of a uniform 
grey-level region or a smooth curve, it is characterized as an 
edge type, a line type, or a high curvature type. Thus, we 
propose three modules of contour attributes to label each edge 
point. These modules are derived by Eq. (13) with the 
appropriate functional forms.  
 
A. Module of Contour Attributes based on Energy Spread 
This module measures the likelihood of the edge-type 
contour points. The basic idea is to compute the area of the 
Teager energy envelop, ( , ; , )v x y pθ , in the interval pCθ  for 
each edge point. Note that the computed area indicated by the 
shaded region in Fig.9 does not include the part of the   DC
Fig. 8 An energy envelop of an orientation channel along a line Lθ . 
 
level. The discrete mathematical form of the contour energy 
spread attribute is defined by 
1 1, ; , ; ,( ) (e e e e )s x y p s x y pθ
θ= ∑                   (16) 
where 
[ ]
( )
[ ]
( )
,
,
1
,
,
( , ; , ) ( , ; , ) ( , ; , )
                         ( , ; , ) ( , ; , )
p
L
p
R
e e L L
x y C
R R
x y C
s x y p B v x y p v x y p
v x y p v x y p
θ
θ
θ θ
θ θ
∈
∈
θ= + −
−
∑
∑
+
   (17) 
1( , ; , ) [ ( , ; , ) ( , ; , )]
2e e L L R R
B v x y p v x y p v x y pθ θ= − + θ       (18) 
and the two local subintervals ,pRC θ  and ,pLC θ  are given by 
{ }, ( , ) ,pR e R ec x y L x x x y y yθ θ= ∈ < < < < R         (19) 
{ }, ( , ) ,pL L e Lc x y L x x x y y yθ θ= ∈ < < < < e         (20) 
 
 
Input Image Teager Energy Envelop
Energy Spread 
Attributes  
Fig. 9 The depiction of contour attributes based on energy spread. 
 
The energy spread attributes of the image Mandrill is shown 
in Fig. 10(a). It revealed that the weak and blurred contour 
edges were enhanced, meanwhile, the texture edges were 
greatly suppressed. 
 
B. Module of Contour Attributes based on Frequency Spread 
This module measures the likelihood of the line-type 
contour points. It is derived from the concept of the 
instantaneous bandwidth, and is defined by  
2 2, ; , ; ,( ) (e e e e )s x y p s x y pθ
θ= ∑                (21) 
where 
( )2 ,
2
( , ; , 1)
, ; ,( )
pe e x y C
dv x y p
s x y p
dxθ
θθ
∈
== ∑ ′
         (22) 
The frequency spread attributes of the image Mandrill is 
 ,,
( , ; ) , ( , )
( , ; ) ( , ; )( , ; )
0, otherwise
N e e
e e j
N e e i j e ei j e e
e x y p x y A
e x y p a x y pz x y p
⎧ ∈⎪ += ⎨⎪⎩
      (30) 
where  is a dynamic threshold function that is inversely 
related to the contour  attribute .  When the 
contour attribute is small, the threshold function will become 
large so the normalized edge response  is inhibited. 
Hence, edges with small contour attributes are likely to be 
suppressed by this mechanism. On the other hand, edges with 
large contour attributes will be retained as contours. We 
derived the dynamic threshold function as 
, ( )i ja ⋅
, ( , ; )i j e eq x y p
( , ;N e ee x y p)
,
,
,
,
(2 ( , ; ))
1 ( , ; )
( , ; )
( , ; )
i j e e
i j e e
i j e e
i j e e
q x y p
q x y p
a x y p c
q x y p
−−= ⎡ ⎤⎢ ⎥⎢ ⎥⎣ ⎦
 (31) 
where c is a constant. The decision function of each set jA is 
thresholded with the same value, which is expressed by 
j ,
,
1 , ( , ; )
( , ; )
0, otherwise
i j e e
i j e e
z x y p T
z x y p
≥⎧⎪= ⎨⎪⎩
         (32) 
where  is the threshold value. The contour map 
generated by each module is given by 
0 T≤ <1
i j
,
1
( , ; ) ( , ; ); 1, 2,3
M
i e e i j e e
j
z x y p z x y p i
=
= =∑           (33) 
 
B. Generation of Model Parameters 
The model parameters ,MAX pe , , , ,MAX i j ps , 1, 2,3i = , 
, and  were initially obtained from 
synthetic images created by ideal edge models, line models, 
and corner/junction models. Also, the parameters were 
updated with real images including pure micro-textures 
images. Fig. 12 shows 
1, 2,j M= " 1,p = 2
, , ,MAX i j ps (ordinate) of the three 
modules of the contour attributes for  case, where the 
diagrams from left to right represent the modules for i=1,2,3, 
respectively. The horizontal axis indicates the edge intensity 
index j. 
1p =
0 50 100 150 200 250 300 350
0
50
100
150
200
250
300
350
400
450
500
0 50 100 150 200 250 300 350
0
5
10
15
20
25
30
0 50 100 150 200 250 300 350
0
5
10
15
20
25
30
35
40
45
 
Fig. 12  From left to right:  , , ,MAX i j ps  for i=1,2,3, respectively. 
 
C. Integration of Contour Maps 
The binary contour maps generated by the three modules of 
the contour attributes are combined by the approach of the 
sketch. At first, the primary contours are given by the module 
based on the energy spread attributes. Then the detailed 
contours produced by the module based on the frequency 
spread attributes are added to the primary contour map. This 
adding procedure is governed by the criterion that only the 
detailed contours connected to the primary contours are kept. 
Finally, the contours given by the high curvature module are 
added directly to the previously resulted contour map. 
Continuing with the example of image Mandrill, Figs. 
13(a)-(c) shows the binary contour maps i( , ; 1)i e ez x y p =  
derived from the three contour modules, i=1,2,3, respectively. 
The final integrated contour map including 1 and 2p = cases 
is shown in Fig. 13(d), which demonstrated the effectiveness 
of our scheme in suppressing the texture-like edges. 
V. SIMULATION RESULTS 
We have run our algorithm on a variety of natural images. 
Figs. 14 and 15 show typical contour extraction results. In all 
cases, the contours are well separated from texture edges. Fig. 
14 illustrates two testing examples. The first column refers to 
the original images. The best extracted salient contours by 
directly thresholding the edge intensity maps are shown in the 
second column. The final column shows the results obtained 
by our scheme. The next experimental examples are shown in 
Fig. 15. The performance of our algorithm is compared to the 
associated ground truth contour maps specified by the human 
subjects [12] and a detector based on nonclassical receptive 
field (non-CRF) inhibition developed by Grigorescu et al. [12]. 
The first column refers to the original images. The second 
column shows the ground truth contour maps of these images. 
The third column presents the results produced by the 
non-CRF inhibition method. The final column shows the 
results obtained by our scheme. The essence of non-CRF 
inhibition mechanism is that the response of an edge detector 
in a certain point is governed by the surround inhibition to 
improve the contour detection. Based on an evaluation of 
experimental results, our contour detector outperforms 
non-CRF inhibition method, and enhances contour detection 
in cluttered visual scenes much more effectively than existing 
edge detectors. 
(a)   (b)  
(c)    (d)  
Fig. 13 (a)-(c) the contour maps i resulted from contour 
modules, i=1,2,3, respectively, (d) the final contour map. 
( , ; 1)i e ez x y p =
 
[12] C. Grigorescu, N. Petkov, and M. A. Westenberg, "Contour detection 
based on nonclassical receptive field inhibition,"  IEEE Transactions on 
Image Processing, vol. 12, no. 7, pp. 729-739, 2003. 
[13] P. Maragos, J. F. Kaiser, and T. F. Quatieri, "On amplitude and 
frequency demodulation using energy operators," IEEE Transactions on 
Signal Processing, vol. 41, no. 4,  pp.1532-1550, 1993. 
Output影像特徵 Differentiation 
module
Energy 
module
Curvature 
module
scaling sectionting normalization threshold
Suppression of 
texture
Suppression of texture
Suppression of texture
整合
描繪
 
Fig. 2 輪廓模型機制的架構圖 
 
 
(a)            (b)             (c) 
 
(d)            (e)             (f) 
Fig. 3 原始影像與經由輪廓模型獲得的離散輪廓 
 
III. Key points 
 
    本論文中的第二級曲率機制與第二級關鍵點，
其主架構都是從第二級 Teagar 能量組合所演生來
的，第二級曲率機制是由能量權重響應值送入第二
級 Teagar 能量組合，再由後置之處理所獲得，第二
級關鍵點則是由匹配權重響應值送入第二級 Teagar
能量組合再由對偶能量相乘所獲得，下圖 4 說明了
第二級 Teagar 能量組合的架構流程。 
 
能量權重響應值
或
匹配權重響應值
0度方向
高斯微分濾波器
Teagar能量組合
能量權重響應值
或
匹配權重響應值
15度方向
高斯微分濾波器
Teagar能量組合
能量權重響應值
或
匹配權重響應值
165度方向
高斯微分濾波器
Teagar能量組合
第二級Teagar
能量組合輸出
第一級Teagar能量組合
0度方向輪出
第一級Teagar能量組合
15度方向輪出
第一級Teagar能量組合
165度方向輪出
Teagar
能量組合法
 
Fig. 4 第二級 Teagar 能量組合架構圖 
 
    關鍵點是指能代表一個物體或一個物件上重要
的連結點，獲得關鍵點的方法本論文乃延用 C. Hsin 
and M. H. Yang【22】的方式，正確的關鍵點所發生
的位置幾乎都座落於影像的交點區、角點區、曲率
區，如圖 5 所示，由 A、B、C 三點構成的三角型，
其 A、B、C 這三點即本論文所指的關鍵點，而 D、
E 這二點，則稱之為冗餘關鍵點，對於冗餘關鍵點
的部份，本論文是藉由關鍵點篩選機制來刪除。 
 
A
D
E
B
C
 
Fig. 5 關鍵點與肌餘關鍵點說明 
 
獲得的關鍵點之程序流程，其過程需先分別偵測出
解析度較高的第一級關鍵點與準確度較高的第二級
的關鍵點，合併一、二級之關鍵點後再經由關鍵點
篩選機制篩選出我們最後之關鍵點。圖 6 為合併第
一級與第二級關鍵點之架構圖，其過程都需要先獲 
各自的對偶能量輸出，才能獲得第一級與第二級的
關鍵點位置。 
 
第一級Teagar能量
0度方向輸 出
第一級Teagar能量
15度 方向輸出
第一級Teagar能量
165度 方向輸出
∑ +∗ oEE 90θθ
5.1=xσ
對
偶
能
量
輸
出
匹
配
權
重
係
數
*
第一級Teagar能量
0度方向輸 出
第一級Teagar能量
15度 方向輸出
第一級Teagar能量
165度 方向輸出
∑ +∗ oEE 90θθ
6=xσ
對
偶
能
量
輸
出
匹
配
權
重
係
數
*
∑
0度方向
高斯微分濾 波器
Teagar能
量組合
∑ +∗ oEE 90θθ
對
偶
能
量
輸
出165度 方向
高斯微分濾 波器
Teagar能
量組合
15度方向
高斯微分濾 波器
Teagar能
量組合
∑
一級
關鍵點 位置
二級
關鍵點 位置
關
鍵
點
第
二
級
關
鍵
點
第
一
級
關
鍵
點
第一級Teagar能量
組合0度方向 輸出
第一級Teagar能量
組合15度方向輸 出
第一級Teagar能量
組合 165度方向輸出  
Fig. 6 合併第一級與第二級關鍵點之架構圖 
 
合併第一級與第二級關鍵點後，經由實驗觀察發現
存有一定比例的冗餘關鍵點，此部份的冗餘關鍵
點，由關鍵點篩選機制中將它刪除。關鍵點篩選機
制如圖 7 所示，主要由能量正規化法統計出的門檻
值及第二級曲率輪廓所構成，其判斷準則為關鍵經
能量正規化法後大於其統計的門檻值，並且關鍵點
的位置與第二級曲率輪廓點為 8 相鄰則定義此點為
關鍵點的生長方向： 
50 100 150 200 250
50
00
50
00
50
 
( I ). 首先以關鍵點 A、B 為出發點，沿著之前所所
偵測到的離散輪廓邊線，做同心圓擴散動作，每次
的擴散動作只向外擴散一格，所以 A 與 B 可以分別
得到暫時的終點群 A1 與 B1，如圖 13 的(a)到(b)。 
( II ). 重覆做同心圓往外擴散的動作，會發現同心圓
愈來愈大，直到 A 與 B 向外擴散生長四格時，其雙
方的終點會發生碰撞，如圖 13(c)中的 A3、B3，此
時就須停止此關鍵點終點群發生碰撞的擴散生長動
作，並由所有碰撞的終點群決定綠色的生長終點位
置，最後定義 A、B 關鍵點各自擁有往終點位置的
生長方向，如圖 13(d)所示。  Fig. 11 (續) 
 ( III ). 沒有碰撞的終點群則可繼續往外做擴散生長
動作，如圖 13(e)。 IV. Extraction of Contours 
 ( IV ). 每個關鍵點依上述( I )與( II )之動作，最終即
可獲得該各自所屬的關鍵點生長方向，如圖 13(f)所
示。 
    依據前面的章節，獲得離散輪廓點與關鍵點
後，可利用關鍵點生長的臂膀輪廓之連結，獲得影
像邊界輪廓，它是一個連續輪廓，並希望連結的封
閉輪廓能夠成為一個區域，其觀念相法如圖 12 所
示，當我們獲得該影像的關鍵點(圖 12(a))與離散輪
廓點(圖 12(b))後經由偵測關鍵點的生長方向(圖
12(c))並透過生長臂膀的輪廓連結機制而連結出可
代表原始影像的連續的輪廓(圖 12(d))。其中偵測關
鍵點的生長方向與生長臂膀的輪廓連結機制，此兩
機制的核心構有點類似，但關鍵點偵測生長方向為
同心圓範圍大小 11*11 時所決定。 
1 2 3 4 5 6 7 8 9
1
2
3
4
5
6
7
8
  
B1
1 2 3 4 5 6 7 8 9
1
2
3
4
5
6
7
8
 
1 
2 
3 
4 
5 
6 
7 
8 
9 
10   
(a)                    (b)  
   
(c)                    (d)  
Fig. 12 關鍵點、輪廓邊線、關鍵點的生長方向、與
影像封閉輪廓 
 
A B
同心圓
A B
A1 A1 B1
 C9 DC9 D
           (a)                   (b)  
B3
1 2 3 4 5 6 7 8
1
2
3
4
5
6
7
8
A B
B3A3
A3
B3
C9   
1 2 3 4 5 6 7 8
1
2
3
4
5
6
7
8
A B
終
D
發生碰撞
 C9 D
           (c)                    (d)  
1 2 3 4 5 6 7 8
1
2
3
4
5
6
7
8
A B
A4
C9   
1 2 3 4 5 6 7 8
1
2
3
4
5
6
7
8
A B
終
D
B4 終 終
C9 D終  
           (e)                    (f) 
Fig. 13 關鍵點的生長方向 
[3] C. Hsin, H. T. Wang, and S. J. Shin, "Edge 
detection based on an adaptive local grey-level 
mapping," IPPR15th IPPR Conference on Computer 
Vision, Graphics, and Image Processing, Taiwan, 
R.O.C., Aug. 2002. 
50 100 150 200 250
50
00
50
00
50  
[4] C. Hsin, S. C. Chen, Y. P. Wang and S. H. Cheng, 
"Contour detection based on suppression of 
texture-like edges," IPPR16th IPPR Conference on 
Computer Vision, Graphics, and Image Processing, 
Taiwan, R.O.C., Aug. 2003.  NSC 
91-2219-E-035-002, 2002.    (c)                  (d) 
50 100 150 200 250
50
00
50
00
50  
[5] F. Heitger, L. Rosenthaler, R. V. D. Heydt, E. 
Peterhans, and O. Kubler, “Simulation of neural 
contour mechanisms： from simple to end-stopped 
cells, ＂  Vision Research, vol. 32(5), pp.963-981, 
1992. 
[6] J. Canny, "A computational approach to edge 
detection," IEEE Transactions on Pattern Analysis and 
Machine Intelligence, vol. 8(6), pp.679-698, Nov. 
1986. 
   (e)                   (f) [7] J. H. Elder and S. W. Zucker, "Local scale 
control for edge detection and blur estimation," IEEE 
Transactions on Pattern Analysis and Machine 
Intelligence, vol. 20(7), pp.699-716, 1998. 
Fig. 16 (續) 
 
VI. CONCLUSION 
[8] K. Rangarajan, M. Shan, and D.V. Brackle, 
"Optimal corner detection," Computer Vision, 
Graphics, and Image Processing, vol. 48, pp.230-245, 
1989. 
 
本論文在獲得關鍵點位置與離散輪廓邊線後，
提供出一套經由關鍵點同步生長所偵測的關鍵點生
長方向，與第四章所提的生長臂膀的輪廓連結機
制，使原來離散的輪廓點經過簡單且有效連結過程
最終能連結成連續性的邊線或封閉輪廓，在關鍵點
的偵測方式中我們不但提高了解析度與精確度，並
藉由關鍵點篩選機制篩選出最精準的關鍵點，另
外，對於關鍵點所偵測的生長方向，除了可做為本
論文生長臂膀的輪廓連結方向之判斷，與矯正關鍵
點位置外，相信未來也是可應用於判斷所屬關鍵點
之交點、角點類型。 
[9] P. Maragos, F. Kaiser, and F. Quatieri, “On 
amplitude and frequency demodulation using energy 
operators,” IEEE Transaction on Signal Processing, vol. 
41(4), pp.3331-3340, 1993. 
[10] R. Deriche and G. Giraudon, "A computational 
approach for corner and vertex detection," Int’l J. 
Computer Vision, vol. 10(2), pp.101-124,1993. 
[11] C. Hsin and F. H. Liao, “Textural feature 
extraction and texture reconstruction based on Gabor 
filter bank,＂ 逢甲大學通訊工程學系研究所碩士論
文, 2005. 
而在影像輪封閉輪廓之擷取部份，除了原始所獲得
的先天資訊不夠足以獲得其完整的封閉輪廓結果
外，其未來的後續工作上，相信在改善關鍵點生長
臂膀的輪廓連結機制缺點後，能獲得一套更穩健的
連結方式，使任何影像都能擷取獲得其完整不斷
裂、沒有錯誤的連續而封閉輪廓邊線，讓其所擷取
的輪廓更能完整無誤的代表其原始影像所應能獲得
的完整輪廓。 
[12] C. Hsin and M. H. Yang, “Detection of image 
contours,＂ 逢甲大學通訊工程學系研究所碩士論文, 
2005. 
[13] C. Hsin and H. T. Chen, "Detection of image 
contours," 逢甲大學通訊工程學系研究所碩士論文, 
2004. 
[14] C. Hsin and H. T. Wang, "Image feature 
detection based on local gray-level modification," 逢
甲大學通訊工程學系研究所碩士論文, 2002. 
 
REFERENCES  
 [15] 張獻堂, “Nonlinear image feature extraction 
theory on edges and lines,＂ 逢甲大學電子工程研究
所碩士學位論文, 2002. 
[1] A. Alexandrov, "Corner detection overview and 
comparison," 2002. 
[2] B. Robbins and R. Owens, "2D Feature detection 
via local energy,"  Image and Vision Computing, 
vol(15), pp.353-368, 1997. 
 
3.紋理特徵擷取 其整合奇次、偶次微分函數，使用Teager 能量組 
合法【1】同時偵測邊、線。Teager 能量組合  
法，定義為： 整個紋理特徵擷取架構如圖 3 所示： 
][][ )2()()1( 2 ++ ×−= ppp ggg fffE θθθθ  
特徵響應
方向通道 Teager能量組合
區域灰度值
調整
輸入影像
圖 3 紋理特徵擷取 
其中 是輸入影像經過高斯p 次微分濾波器組所
得的響應， 即為θ角度的方向響應。  
)(pg
f
θ
θE
  
而我們在特徵擷取這個架構中所使用的方法主
要包括有區域灰度值的調整、方向通道、 Teager 
能量組合法，然後再利用這些方法將初步的特徵擷
取出來。 
4. 紋理邊界的偵測 
 
經過對影像做特徵能量的擷取【1】後，接下
來要對特徵點做全域性的非線性轉換，先拉進屬於
同性質特徵點的能量差，然後將結果送入到偏移均
値向量（Mean Shift）中分類出屬於同性質間的特
徵點，類似分群的效果，再對分群後的特徵點經由
能量的填補使其能量平坦化，而區域性非線性的轉
換機制則是強化跟減弱影像的重要特徵，類似特徵
精簡的效果，最後在經由邊界的偵測機制完成紋理
的邊界偵，以擷取出紋理的邊界。 
 
3.1 區域灰階調整 
 
    主要是要在一張影像與遮罩做運算之前，先 
將影像做灰階值調整在與遮罩做運算，其中做灰階 
值調整的動作就是當濾波器遮罩的滑動時，對於遮 
罩內所涵蓋的像素做轉換的動作，主要是為了降低 
過大的灰階值差異所導致的影響【1】，經過轉移
函數可以將邊緣與非邊緣的差距拉開。   
 4.1 全域性非線性轉換（Tanh正規化函
數） 3.2 方向通道 
  
       方向通道的擷取架構【1】來擷取影像，每個
方向通道使用不同方向的高斯濾波器，主要目的是
期望各個方向通道擷取屬於自己方向的特徵，不屬
於該通道的響應就會很低，最後在加總各個方向所
偵測的響應，即是該全部影像的特徵響應，如圖
4。 
    由於不同的紋理所擷取出來的紋理特徵能量會
有較大的差異性，所以在紋理邊界偵測架構中經過
特徵擷取後的第一個步驟是先想辦法將所屬於同一
群的特徵響應做類似平滑的動作，就是拉近彼此間
的能量差，公式如下 
( )
2 g
2 g
1g
1
i
ii
e
e
α
α
ψ
−
−
−
=
+
  
 
圖 4 方向通道擷取架構方塊圖 
在上面的式子裡，其中 為我們所要輸入的各通
道特徵響應， ，其中 為通道的數目，
而 則為可調適的參數。 
gi
n1i = " n
α
 
4.2 偏移均値向量（Mean Shift） 
 
    此架構在論文中的主要原理就是認為特徵相同
的點會聚集在一起，因而這些特徵點在某ㄧ區域內
形成密集度很高的ㄧ群，而不同高密度區域會有密
度低的過渡區域將兩不同區域給隔開來，此過渡區
便為群組區別的邊界，而區域中密度最大者為該區
域的群中心。而在此我們對 Mean-shift 的定義
【2】： 
 
3.3 Teager 能量組合 
 
    前述已經介紹濾波器如何產生，且知道奇次與 
偶次高斯微分函數對於偵測邊和線，所得到響應並 
不一樣，例如對邊作奇次微分則其特徵點位置在峰 
值點，偶次微分則其特徵點位置在過零點。現在將 
[2] Danny Barash and Dorin Comaniciu. A 
common framework for nonlinear 
diffusion,adaptive smoothing, bilateral filtering 
and mean shift. Image and Video 
Computing,22(1):73–81, 2004. 
  
 (a)合成紋理影像 (b) 原始特徵點響應 (0 度方向) 
  
(c) 經過全域性非線性
轉換 (0 度方
向) 
2.5α =
(d)為經過限制偏移均
值濾波後特徵響應 (0
度方向) 
  
(e)為經過能量填補後
響應(0 度方向) 
(f)為經過邊界偵測後
的結果 
圖 7 合成紋理影像經過本論文測試的結果 
[3] 楊敏宏, “影像輪廓偵測與分割,” 逢甲大學
通訊工程學系研究所碩士論文, 2005. 
 
[4] 張獻堂 , “影像特徵邊緣之非線性偵測理
論,” 逢甲大學電子工程研究所碩士學位論
文, 2002. 
[5] Yizong Cheng, "Mean Shift, Mode Seeking, 
and Clustering" IEEE Trans. Patt. Anal. Mach. 
Intell., vol.17. No. 8. August 1995 
 
[6] M. S. Moore, R. Bernstein, and S. K. Mitra, "A 
generalization of the Teager algorithm," 
Processing IEEE Workshop on Nonlinear 
Signal Processing, Michigan, Sep. 1997. 
 
  
 (a)合成紋理影像 (b) 原始特徵點響應  (0 度方向) 
  
(c) 經過全域性非線性
轉換 (0 度方
向) 
2.5α =
 (d)為經過限制偏移均
值濾波後特徵響應 (0
度方向) 
  
(e)為經過能量填補後
響應(0 度方向) 
(f)為經過邊界偵測後
的結果 
圖 8 合成紋理影像經過本論文測試的結果 
 
[7] P. Meer and B. Georgescu, "Edge detection 
with embedded confidence, " IEEE 
Transactions on Pattern Analysis and Machine 
Intelligence, vol. 23, pp. 1351-1365, Dec.2001. 
 
[8] J. Canny, "A computational approach to edge 
detection," IEEE Transactions on  Pattern 
Analysis and Machine Intelligence, Vol. PAMI-
8, No. 6, pp. 679-698, 1986. 
 
[9] T. Wang, and S. J. Shin, "Edge detection 
based on an adaptive local grey-level 
mapping," IPPR15th IPPR Conference on 
Computer Vision, Graphics, and Image 
Processing, Taiwan, R.O.C., Aug. 2002. 
 
  
6.參考文獻 [10] B. A. Maxwell and S. J. Brubaker. Texture 
edge detection using the compass operator. 
In Proceedings British Machine Conference 
2003, September 9-11 2003. 
 
[1] 陳世章, " 影像輪廓偵測 ,"逢甲大學通訊工程
學系研究所碩士論文，2004。 
 
 
(5) Signal and Image Processing 
(6) Embedded System and Reconfigurable Systems 
(7) Software Engineering and Data Structures 
(8) Network Protocol and Security 
(9) Wireless Networks and Sensor Networks 
(10) Power Systems and Power Electronics 
(11) Computer Systems and Architecture 
(12) Design Automation, Intelligent Systems, and Reliability 
(13) Computer Systems and Intelligent Systems 
(14) Electronic Systems, Intelligent Systems, and Automation 
(15) Communication and Signal Processing System 
另外大會還安排 5 場 keynote speeches, 講題及演講者分列如下： 
(1) Toward Human-Level Machine Intelligence, Lotfi A. Zadeh 
(2) Wavelet-Chaos-Dynamic Neural Network Models for Biomedical Applications and 
Diagnosis of Neurological Disorders, Hojjat Adeli 
(3) Electric Power System Restructuring: Will Blackouts Occur Again? Mohammad 
Shahidehpour 
(4) Convergence in the Mobile Device, Tom Walczak 
(5) Using Digital Technology, Larry Leto 
上述之講演(1)至(3)是由該領域之知名學者發表其研究心得，而講演(4)與(5)則是從產
業的角度，由業界精英闡述行動通訊與數位科技的發展趨勢，這五場演講皆非常精
采，使本人獲益良多。大會也安排了兩場要教育場次，講題分別是 “Information 
Systems Security: the Cyber-Security of Business and Business Aspects of 
Cyber-Security” 及 “3G Wireless”。同時也安排了兩場有關「領導技巧」與「專案管
理」的講習會及一場科技產品展示會。足見大會規劃與執行此次研討會議的盡心盡
力。 
     本人在 EIT2007 所發表的論文，在口頭報告結束後獲得與多位此領域的專家學
者互相交流的機會受益頗多，也巧遇參與此次會議的台灣學者，倍感親切。本次大
會個人覺得有興趣的部份略述如下：Lotfi A. Zadeh 教授的 keynote speech: Toward 
