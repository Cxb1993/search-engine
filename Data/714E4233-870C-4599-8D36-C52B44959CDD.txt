 2
目  錄 
 頁碼 
一、摘要……………………………………………………………………………3 
二、前言……………………………………………………………………………4 
三、研究目的………………………………………………………………………7 
1. 第一年……………………………………………………………………7 
2. 第二年……………………………………………………………………10 
3. 第三年……………………………………………………………………11 
四、文獻探討………………………………………………………………………11 
五、研究方法………………………………………………………………………13 
六、研究結果………………………………………………………………………18 
七、計畫成果自評…………………………………………………………………21 
八、參考文獻………………………………………………………………………22 
 4
transporting and/or streaming of the signals. Our group has enormous prior research experiences in 
Intelligent Human-Computer Interfaces, Scalable Media Streaming, Audio-visual Integration, 
Error-resilient Video Coding and Transcoding, and Audio-Visual Analysis. Based on these valuable 
experiences, we have teamed up to develop Intelligent Audio-Visual Analysis, Coding and 
Transmission schemes on a common platform over two universities. Five sub-proposals are 
integrated for three years’ research as follows: 
(1) Ultra-low-bit-rate Video Coding and Transmission 
(2) Error Resilient Image / Video Coding and Error Concealment 
(3) Content-based FGS Coding Mode Determination for Video Streaming 
(4) Audio/visual content analysis and its applications 
(5) Content-Aware QoS Control for Video Streaming over Heterogeneous Networks 
 In the first year, our focus was on algorithms development and platform establishment. To 
investigate the relationship between sub-projects and to setup the common platform are the 
purposes of this main project. In the second year of this three-year project, our focus was on the 
optimization of the algorithms and the testing of the platform’s networks. To investigate the 
relationship between sub-projects and to test the common platform networks are the purposes of this 
main project. In the last year, we focused on the integration of the system and develop software IPs. 
The proposals are well organized and closely linked together. For the promotion of this group 
research, we will organize group meetings regularly to report on individual progress, share the 
Audio/Visual Labs and need a full-time assistant to manage the system integration. 
 
二、 前言 
近年來由於多媒體應用的快速發展，電腦軟硬體性能的大量提升，有線/無線/網際網路大
量並普遍的使用，及資訊家電的快速發展及推廣，因此各種資料的流通、儲存及管理的需求
就大量的提升。一部家用電腦可以儲存非常大的資料，這些資料內容亦從過去的數字、文字
等小量資料擴張為語音、圖形、影像/視訊等多媒體資料。另外由於資訊家電的快速發展，原
來在實驗室、辦公室才能處理的多媒體處理及通訊正逐漸走入家庭及個人化環境，尤其是無
線/網際網路技術的發展和應用，更使多媒體資料進一步與家庭及個人生活緊密結合。舉例來
說，未來的 PDA 或無線手機就可以透過無線網路與外界通話、觀賞 DVD 主機正在播放的精
彩影片或觀察屋外的環境 (檢測是否有客人或闖賊)…。最近 10 年來各種語音、影像、視訊的
壓縮標準，如 JPEG、JPEG-2000、H.261、H.263、H.264、MPEG-2、MPEG-4、MPEG-7、
 6
子計畫三： 
智慧型音/視訊分析、編碼及傳輸技術之研究：視訊傳輸之
內容為導向之可伸縮性編碼的模式決策 
子計畫四： 
智慧型音/視訊分析、編碼及傳輸技術之研究：音/視訊內容
特徵分析及其應用 
子計畫五： 
智慧型音/視訊分析、編碼及傳輸技術之研究：應用於異質
網路視訊串流之內容導向 QoS 控制 
 
相關的研究範疇及分工合作架構敘述如下： 
總計畫： 
1. 整體系統之規劃，使得各子計畫能順利整合。 
2. 依據各子計畫之演算法，制訂軟體之介面標準。 
3. 建立有線與無線網路環境進行多媒體訊號之管理與傳輸。 
子計畫一： 
1. 建立超低位元率視訊編解碼架構及實驗平台。 
2. 其錯誤容忍、錯誤隱藏之設計。 
3. 系統測試、驗證。 
子計畫二： 
1. 處理 JPEG 影像的錯誤回復影像編碼之方法及錯誤隱蔽技術。 
2. 處理 JPEG-2000 影像的錯誤回復影像編碼之方法及錯誤隱蔽技術。 
3. 研發 H.263 視訊影像的錯誤回復影像編碼之方法及錯誤隱蔽技術。 
子計畫三： 
1. 根據基層編碼器資訊，描述資料特性。 
2. 建立 FGS，FGS-SE，FGST9，FGST13，FGST9-BC，FGST13-BC 六種模式。 
3. 根據資料特性與網路狀況選擇一種模式做最合適的編碼。 
子計畫四： 
1. 原始及壓縮音/視訊內容分析與 MPEG-7 相關特徵的定義與擷取。 
2. 利用所擷取內容特徵加強音/視訊編碼傳輸效能及進行音/視訊資料庫的管理應用 
(如 summary, filtering, retrieval)。 
3. 整合音/視訊內容分析的多媒體傳輸與管理應用系統。 
 8
Engines
Client Kernel
*FACE *BODY VIDEO AUDIO
TEXT*OBJ.*SCENEDATABASE
PROPERTIES
INTERFACE
PROPERTIES
INTERFACE
PROPERTIES
INTERFACE
PROPERTIES
INTERFACE
PROPERTIES
INTERFACE
PROPERTIES
INTERFACE
PROPERTIES
INTERFACE
ENGINE
LAYER
APPLICATION
LAYER
APPLICATION 1
VIRTUAL MEETING,
CLASSROOM
APPLICATION 2
AUDIO/VIDEO
STREAMING
NETW ORK
MANAGER
Mode
and
Rate
Control
Compressed
M essages
COMM .
Control
Signals
Updated
World
Description
SCENE
RENDERER
AUDIO
RENDERER
PRESENTATION  /
COM MUNICATION
LAYER
User Screen Speaker
NETW ORK
LAYER
BEHAVIOR
PROPERTIES
INTERFACE
(1) (1)(2)
(4) (4)
(3)
(4)(2)(4)
Compressed
Bit-stream
MEDIA
GATEW AY
(5)
APPLICATION 3
MULTIMEDIA
GATEW AY
 
(a) 架構圖 
 
 
(b) PC 軟體介面 
 10
 
*FAP/BAP
MANAGER
VIDEO/AUDIO
CODER AND
TRANSCODER
*SCENE
TRANSCODERRAS SERVER
SCENE
DATABASE
MEDIA
DATABASE
CLIENT
INFORMATION
*OBJ.
MANAGER
COMMUNICATOR
NETWORK
MANAGER
NETWORK
Control
Signals
Compressed
Messages
Updated
World
Description
Registration,
Administration,
Status
Messages
Compressed
Bit-stream
(1)(2)(3)(4)(5)
 
(a) 架構圖 
 
 (b) 軟體介面 
圖四：伺服器端軟體架構 
 
2. 第二年 
本整合型計畫第二年的研究以整體網路測試與最佳化為重點為主，第二年總計畫建
立了有線與無線的網路環境，在已建構好的系統網路中，進行了網路品質的測試工作，
以了解網路點對點間的傳輸品質，並進行多媒體資料之管理與傳輸技術之研究，系統網
路架構圖如下圖五所示。 
 
 12
成錯誤遞延(drifting error)，導致重建後的影像造成嚴重的品質損壞，所以在可調式編解
碼技術的設計上考量，編碼效能與錯誤遞延是一種取捨(trade-off)的協調。  
在一個三層次的影像串流服務架構裡，使用無線網路可以將現有的有線網路做延伸，提
供終端設備無線連線的便利性，三層次的影像串流服務架構主要是包括有串流伺服器、提供
轉換編碼的多媒體閘道器、及可以移動的終端設備，在這架構中的資料傳送路徑包括從串流
伺服器到多媒體閘道器間的有線網路，及從閘道器到終端設備間的無線網路，多媒體閘道器
主要是擔任代理人或調解器使用，將由串流伺服器所傳送來的多媒體內容，依據各個終端設
備的特性進行轉換編碼，所其能適合該終端設備使用，在此架構中為了達到高品質的多媒體
串流服務，提供一穩定及有效能的傳輸網路是有其必要性。 
無線網路中的視訊傳輸，常常受到訊號不穩定(signal fading)、雜訊干擾、網路擁塞和
基地台訊號交握(handoff)，這些都將造成傳輸資料的錯誤及資料封包遺失；如果造成的錯誤
超過傳輸資料錯誤更正保護碼所能修補的範圍，就連封包內只錯一個位元都有可能造成整個
封包的遺失。這類的封包遺失不但會影響現在視訊畫面的品質，藉由現有視訊技術中的動態
補償技術，也會對之後的畫面造成影響，並使得錯誤往後傳遞[2]。 
在容易產生錯誤的網路上傳輸壓縮視訊會有封包遺失的情況，為了處理這個問題，最常
使用的方法就是加上額外的資訊來保護視訊資料。經常用來做錯誤容忍的訊號源編碼和轉換
編碼的工具包含有：資料分裝、同步記號、可反轉換的可變長度編碼(reversible variable 
length codes, RVLC)、錯誤隱藏的熵數編碼(error resilient entropy coding, EREC)、多
重描述編碼(multiple-description coding, MDC)、錯誤追蹤、可調式內部重置(adaptive 
intro refresh, AIR)、等等[2][3]. MDC [2][4][5] 是一種結合了訊號源與通道的編碼方式。
它的目的是要藉由通道分散的方式，使得在通道錯誤時，仍然可以增加資料傳輸的穩定性。
MDC 刻意加入了額外的資訊，讓資料流對於傳輸時的錯誤容忍性更高。如果資料是在數個互
相獨立的通道上傳遞，這樣子可以大大地增加至少有一個通道是可以接收到正確資料的機
率，也使得在接收端可以更加輕易的重建出能令人接受的畫面品質。最近有很多 MDC 的方法
被提出來增強視訊編碼的錯誤容忍能力。[7] 中提出了一個基於多重描述數量量化
(multiple-description scalar quantization, MDSQ)和兩個獨立預測迴圈的視訊編碼方
式。基於成對關聯轉換的 MD 視訊編碼器則是在[8][9][10]內被提出。當編碼器的預測訊號不
能被解碼器接收到的時候，會造成錯誤漂移的情況，並導致嚴重的錯誤擴張。MDC 則是通常
被用來處理這個問題。錯誤漂移的問題可以用[11]中所提出來的多重描述子，或是[10]的單
一描述子來有效的緩和。[12]中則是提出一個基於小波轉換並且不會產生錯誤漂移現象的 MD
 14
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
(b) 中正大學 -> 清華大學 
圖六：網路傳輸品質測試結果 
 
我們也建構了 Wireless LAN 無線網路的共同平台，其中使用兩台支援 IEEE 802.11f 國
際標準的基地台(AP: access point)建立了一個以中控式 infrastructure mode 為基礎，可
提供漫遊(Roaming)服務功能的網路傳輸環境，其網路架構圖如下圖七所示，我們也使用了兩
台具有無線網路界面卡的電腦，以對等式 ad-hoc mode 為基礎，建立一個可同時提供兩條傳
輸路徑的網路環境，做為 Multi-channels 傳輸方式研究的實作平台。 
 
 
 
 
圖七：Multi-channels 傳輸網路無線網路架構圖 
AP1 AP2 
 16
 
 
MD-FGS 
Transcoder 
Channel 
Status 
Estimation
i
j
i
j RTTPLR ,
Media Gateway
Pre-stored   
Bitstream 
SD 
MD 
(from station i ) 
Mode Decision
 
圖九：轉換編碼所用的傳輸模式選擇機制 
 
以標準 MPEG-4 編碼器編成的預先編碼字元串將會被儲存在伺服器端。當轉換編碼器
停留在“MD”模式時，一個預先儲存的字元串將被讀進轉換編碼器，並且用 MDSQ 編碼程
序編成兩個敘述，自動的用兩個通道分別傳輸；否則，當處於“MD”模式時，轉換編碼
器將預先儲存的字元串原封不動的直接傳送給用戶端。 
 
2. Base-MDSQ 
我們提出 Base-MDSQ 編碼器，這個編碼器藉著新設計好的量化器而可以在部分視訊
資料遺失的時候達到較好的錯誤抵抗能力。而 Base-MDSQ 的部份預測功能也能減少漂移
錯誤但不會嚴重的影響編碼效率，Base-MDSQ 是修改過的 MDSQ 編碼設計，以新的方
式設計的索引指定使編碼器能夠截取出在所有描述中共同的部份。此處的描述是參考 
“base part” 的描述，用來做預測編碼。這麼一來，如果接收端收到至少一段描述，解碼
器會從收到的描述中擷取出完全相同的 “base part”，所以編碼和解碼處的預測會完全正
確，使用 “base part” 這個詞是為了避免與分層編碼的 “base layer” 混淆。圖十舉了一個
Base-MDSQ 索引指定的例子，在這例子中，我們從一些被矩形圍住的 “base part” 群中
把中央索引聚集起來，而這些矩形都有特定的 “base part” 重建值，在解碼端，當描述都
沒被收到後，中央索引可以被解碼出來，且按順序的截取出來源的中央重建。兩個描述
中的其中一個被收到之時，解碼端仍然重建 “base part” 的來源。我們定義中央重建和
“base part” 間的差距叫做編碼完成資料的Base-MDSQ的 “enhancement-part”。只用 “base 
part” 在編解碼端做預測能達到較好的漂移控制，因為解碼端至少收到一個描述的機率是
相對很高的。 
 18
},,,     ,~)( 1,1
2,
1
1,
11
bnjjj
B ii{iiXib j ⋅⋅⋅∈∀=  (3) 
},,,    ,~)( 2,2
2,
2
1,
22
bnjjj
B ii{iiXib j ⋅⋅⋅∈∀=  (4) 
只要解碼端接至少收到一個敘述，我們可以藉由接收到的敘述來投影
0 1 2( ),  ( ),   or  ( )b b b⋅ ⋅ ⋅ 精準的重建基礎部份的值。因為解碼端成功重建回來源的基礎部份的
機率非常高，於是我們可以使用基礎部份的重建來當作影像編碼以及低機率漂移的解碼
兩者預測的參考值。 
 
六、 研究結果 
1. 無線網路之視訊串流的無接縫式漫遊 
為了在實驗室的環境中建構出漫遊的環境，將基地台相隔 30 公尺遠，並將傳輸功率
降低 25%。基地台原廠設定重傳限制設定為 7，實驗中的測試影片格式為 QCIF 4:2:0，
並用使用 MPEG 4 編碼，位元率為 256kbps，畫面速率(frame rate)為 30 fps。第一張畫
面使用 I-frame 編碼，其餘的使用 P-frame 編碼。影片封包的長度為 512 bytes。我們
模擬兩基地台 S1 與 S2 的情境如下：客戶端用步行的速度從 S1 移動到 S2，在走回 S1。
圖四記錄了 S1 與 S2 頻道的PLR 和 RTT 。頻道選擇的成果是由轉碼器決定。圖十一中，
當時間在 180 單位時，頻道狀態偵測器發現到第一條路徑 S1 的PLR 和 RTT開始變差，
而第二條路徑 S2 有好的環境，所以決定使用“MD”模式，將資料同時使用兩個頻道傳給
客戶端，當時間在 210 單位時，第一條路徑的狀況便的比第二條差，所以將傳輸的路徑
完全轉移至第二條，類似的狀況也發生在 395 到 414 時間單位時，這時客戶端是由 S2 漫
遊到 S1，我們對遺失的影像採用零動差替換錯誤補償法。圖十二顯示我們提出的方法在
兩個情境的比較，在情境一，轉碼器使用了 MD 模式，將輸入的位元串流轉碼成兩個同樣
位元率(256kbps)的描述，在第二個情境，轉碼器將位元串流轉碼成無品質損失的串流，
但是位元率增加了 20%，在這個情狀之下，當發生從“Normal”模式轉換成 “MD”模式
或是相反的情況就不會發生錯誤漂流(drift)效應，如此在轉碼之後也沒也品質的損失。
圖十三顯示我們提出的多路徑 MD 模式編碼法可以減少因為漫遊位移所導致的失真，即使
在 MD 模式下仍有無效的封包落失，在頻道如圖十一的環境下，我們提出在廣域網路上漫
遊的改進方法可以在平均 PSNR 上可以改進 5.4dB，然而因為 MD 編碼模式所導致的品質
的降級在乾淨的頻道上只有大約 0.75dB。 
 
 20
Akiyo、Coastguard 等測試影像串列，我們則以 MPEG-4 編碼器[21]進行編碼，相關參數
如下：每秒 144000 位元、每秒 7.5 張畫面、影像群(GOP)的長度為 15 張畫面，但不包含
B-frame，影像封包大小則為 512 個位元組。我們採用零動差 [22]取代錯誤隱藏
(zero-motion replacement error concealment)的方法來解決隱蔽因資料遺失而造成的
錯誤。在我們的實驗中，內部直流係數(intra DC coeff.)及移動向量(M.V.)均被複製在
兩個描述之中，MDSQ 索引指示矩陣的對角線寬度為 3(換言之，k=1)。為了將實際的網路
行為特性模型化，我們參考由國際電信聯盟所製作的關於封包損失之統計特性的相關文
件[23]，再以封包損失的錯誤模式為基礎，針對各演算法以五種不同的封包遺失率(0%、
3%、5%、10%、20%)進行模擬。 
以下所呈現的是，以影像編碼中的離散餘弦轉換係數，進行基礎部分重建及中央重
建的重建品質。如表一所示，對於此兩個測試影像串列而言，基礎部分重建的最大訊雜
比僅比中央重建的最大訊雜比低 4~5dB，圖十三則分別顯示了以中央重建與基礎部分重
建利用 p-frame 重建影像的結果。  
表一：在每秒 144000 位元時，中央重建與基礎部份重建的最大訊雜比比較 
測試影像 
最大訊雜比(dB) 
(中央重建) 
最大訊雜比(dB) 
(基礎部份) 
最大訊雜比之差 
(dB) 
Foreman 31.30 26.89 4.41 
Coastguard 29.96 25.01 4.95 
 
由於剩餘值的基礎部份比加強部分能在解碼器上更可靠地被重建，在我們所提出的
Base-MDSQ 編解碼技術中，簡單地設定 B=1、E=0。圖十四則是以平均最大訊雜比，對
Base-MDSQ 編碼器與傳統的標準 MPEG-4 編碼器所作出的效能評估；其中可看出，
Base-MDSQ 編碼器顯著地減少了在中度與高度封包損失率時的失真 —因為用來估測的
基礎部份，有較高的可能性能被重新得到，雖然額外的資料會使在乾淨無錯誤通道下傳
輸減少編碼效率，但在易錯環境下的 Base-MDSQ 整體效能卻能因此得到保證。 
 
 22
在這三年計畫的進行，各子計畫如期完成預定的工作項目，重要的成果也已在國內
外發表多篇的學術論文，包括期刊論文 16 篇[24]-[39]及會議論文 55 篇[40]-[94]，其
中總計畫則有期刊論文三篇[24]-[26]及會議論文 13 篇[40]-[52]。 
 
八、 參考文獻 
[1] “Streaming video profile-- Final Draft Amendment (FDAM 4),” ISO/IEC 
JTC1/SC29/WG11/N3904, Jan. 2001. 
[2] Y. Wang and Q.-F. Zhu, “Error control and concealment for video communication: A 
review,” Proc. IEEE, vol. 86, no. 5,  pp. 974–997, May 1998. 
[3] J. Xin, C.-W. Lin, and M.-T. Sun, “Digital video transcoding,” Proc. IEEE, vol. 93, no. 1, pp. 
84–97, Jan. 2005. 
[4] V. K Goyal, “Multiple description coding: Compression meets the network,” IEEE Signal 
Processing Magazine, vol. 18, no.5, pp. 74–93, Sept. 2001. 
[5] Y. Wang, A. Reibman and S. Lin, “Multiple description coding for video delivery,” Proc. 
IEEE, vol. 93, no. 1, pp. 57–70, Jan. 2005. 
[6] A. Miu, J. G. Apostolopoulo, W.-T. Tan, and M. Trott, “Low-latency wireless video over 
802.11 networks using path diversity,” in Proc. IEEE Int. Conf. Multimedia and Expo, pp.  
441–444, Aug. 2003. 
[7] V. A. Vaishampayan, “Design of multiple description scalar quantizers,” IEEE Trans. 
Information Theory, vol. 39, no. 3, pp. 821–834, May 1993. 
[8] V. K Goyal, and J. Kovacevic, “Optimal multiple description transform coding of Gaussian 
vectors”, in Proc. IEEE Data Compression Conference, pp. 388-397, Mar. 1998. 
[9] Y. Wang, M. T. Orchard, V. A, Vaishampayan, and A. R. Reibman, “Multiple description 
coding using pairwise correlating transforms,” IEEE Trans. Image Processing, vol.10, no. 3, 
pp. 351–366, Mar. 2001. 
[10] A. R. Reibman, H. Jafarkhani, Y. Wang, M. T. Orchard, and R. Puri, “Multiple description 
coding for video using motion compensated prediction,” IEEE Trans. Circuits Systems Video 
Technol., vol. 12, no. 3, pp. 193–204, Mar. 2002. 
[11] J. Apostolopoulos, “Reliable video communication over lossy packet networks using multiple 
state encoding and path diversity,” in Proc. SPIE Conf. Visual Communications and Image 
Processing, pp. 392–409, 2001. 
[12] N. V. Boulgouris, K. E. Zachariadis, A. N. Leontaris, and M.G. Strintzis, “Drift-free multiple 
description coding of video,” in Proc. IEEE Workshop on Multimedia Signal Processing, 
pp.105–110, Oct. 2001. 
[13] Y. Wang and S. Lin, “Error resilient video coding using multiple description motion 
compensation,” IEEE Trans. Circuits Systems Video Technol., vol. 12, no. 6, pp. 438–453, 
 24
Talking Head Application”, Signal Processing: Image Communication 21 (2006), pp1-12 
[28] Hung B. F. and Huang, C. L. “Content-based FGS Coding Mode determination for Video 
Streaming over Wireless Network,” IEEE J. Selected Areas in Communication, Vol. 21, No. 
10, pp.1595-1604, 2003. 
[29] Huang C. L. and Liang, S., “Unequal error protection for MPEG-2 video transmission over 
wireless channels,” Image Communication, Vol. 19, pp.67-79, Jan 2004. 
[30] Chan H.-T., Fu Chih-Ming, and Huang C.-L., “A New Error Resilient Video Coding Using 
Matching Pursuit and Multiple Description Coding” IEEE Trans. on CAS for VT. Vol. 15, 
No.8, pp. 1047-1052, Aug. 2005. 
[31] Fu C.M., Hwang W.L. and Huang C.L., “Data-aided frame timing acquisition for fractal 
modulation in an AWGN channel” Signal Processing, vol. 86, 310-318, 2006. 
[32] Fu C.M., Hwang W.L. and Huang C.L., “A Subspace Approach to Timing Acquisition for 
Wavelet-Based Multirate Transmission,” to appear in IEEE Trans. on Communication, 2006. 
[33] Fu C.M., Hwang W.L. and Huang C.L.,, “A Joint Source and Channel Coding for 
Error-Resilient SPHIT-coded Video Stream,” to appear in Visual Communication and Image 
Representation, 2006. 
[34] J. Xin, C.-W. Lin, and M.-T. Sun, “Digital video transcoding,” Proceedings of the IEEE, vol. 
93, no. 1, pp. 84-97, Jan. 2005. 
[35] H.-J. Chiou, Y.-R. Lee, and C.-W. Lin, “Content-aware error resilient transcoding using 
prioritized intra-refresh for video streaming,” J. Visual Commun. Image Represent. (Special 
Issue on Visual Communications in the Ubiquitous Era), vol. 16, no. 4-5, pp. 563-588, 
Aug.-Oct. 2005. 
[36] W.-N. Lie, C.-I. Lin, and C.-W. Lin, “Enhancing video error resilience by using data 
embedding techniques,” IEEE Trans. Circuits Syst. Video Technol., vol. 16, no. 2, pp. 
300-308, Feb. 2006. 
[37] Y.-C. Tsai, C.-W. Lin, and C.-M. Tsai, “H.264 error resilience coding based on 
multihypothesis motion-compensated prediction,” Signal Processing: Image Communication. 
(submitted) 
[38] Y.-R. Lee and C.-W. Lin, “Visual Quality Enhancement in DCT-Domain Spatial 
Downscaling Transcoding Using Generalized DCT Decimation,” IEEE Trans. Circuits Syst. 
Video Technol., April 2006. (in revision) 
[39] C.-P. Chang, C.-W. Lin, and S.-M. Hsu, “R-D optimized quantization of H.264 SP-frames for 
bitstream switching with storage constraints,” IEEE Trans. Circuits and Systems for Video 
Technology. (submitted) 
[40] Chih-Ming Chen, Chia-Wen Lin, and Yung-Chang Chen, “Packet scheduling for video 
streaming over wireless with content-aware packet retry limit,” International Workshop on 
Multimedia Signal Processing, 3-6 Oct. 2006 
[41] Chih-Ming Chen , Chia-Wen Lin, and Yung-Chang Chen, “Unequal error protection for video 
streaming over wireless LANs using content-aware packet retry limit,” Conference on 
 26
Talking Head Application”, Proceedings of 2005 IEEE International Conference on 
Multimedia and Expo (ICME 2005), Amsterdam, Netherlands, July 6-8, 2005 
[55] Wen-Tang Chang, Chao-Kuei Hsieh, and Yung-Chang Chen, “Fast Head Pose Estimation 
under Different Lighting Conditions”, Proceedings of 2004 IEEE International Conference 
on Multimedia and Expo (ICME2004), Taipei, Taiwan, June 27-30, 2004 
[56] Chien-Hung Liu, Chao-Kuei Hsieh, Yung-Chang Chen, “MPEG-4 Facial Animation Over 
WIFI”, 二○○四數位生活與網際網路科技研討會 ( 2004 Symposium on Digital Life 
and Internet Technologies ), Workshop 3:Multimedia and Digital Contents Technologies 
[57] H. T. Chan and Huang, C. L., “Multiple description and matching pursue coding for video 
transmission over the internet,” IEEE ICASSP, 2003, Hong-Kong. 
[58] Fu C. M., Hwang W. L., and Huang, C. L., “Timing Acquisition for Wavelet-Based Multirate 
Transmissions,” Globalcom 2003, San Francisco, USA, Dec. 2003. 
[59] Fu C. M., Hwang W. L. and Huang C. L., “Timing Acquisition for Fractal Modulation In 
Gaussian White And 1/F Channels”, IEEE ICASSP 2004, Montreal Canada, May 17-21, 
2004. 
[60] Liang, C. H. and Huang, C. L., “Content-Based Adaptive Media Player For Network Video,” 
IEEE ISCAS 2004, Vancouver, Canada, May 23-26, 2004. 
[61] Fu C. M., Hwang, W. L., Huang, C. L., “Efficient Post-Compression Error-Resilent 
3D-Scalable Video Transmission for Packet Erasure Channels,” Proc. IEEE ICASSP 2005, 
Philadelphia, PA, March 18-23, 2005. 
[62] Lin T.-H., Ho M.-F., and Huang C.-L., "A Joint Source-Channel Coding Scheme for The 
Incorporated Multiple Description Coding with JPEG2000," Proc. CVGIP 2005, Taipei, 
ROC.  
[63] Chen, C.-L., Ho, M.-F, and Huang, C.-L., “Adaptive Rate Control For H.264/Avc Using 
Kalman Filter” Proc. of IEEE ISCAS 2006, Kos Island, Greece, May 21-24, 2006 
[64] Wen-Nung Lie and Chen-Kang Su, “News Video Classification Based on Multi-modal 
Information Fusion,” Proc. Of  IEEE Int’l Conf. On Image Processing, ICIP-2005, Genova, 
Italy, Sep. 2005 
[65] Wen-Nung Lie and Sheng-Hsiung Shia, “Combining Caption and Visual Features for 
Semantic Event Classification of Baseball Video,” Proc. Of IEEE Int’l Conf. On Multimedia 
and Expo, ICME-2005, Amsterdam, The Netherlands, July 2005 
[66] Wen-Nung Lie, Guo-Shiang Lin, and Sheng-Lung Cheng (Nov. 2006), “Pitching shot 
detection based on multiple feature analysis and fuzzy classification,” Proc. Of Pacific-Rim 
Conference on Multimedia, PCM-2006, Hanzhou, China 
[67] Wen-Nung Lie, Guo-Shiang Lin, and Sheng-Lung Cheng (July 2006), “Anchor shot detection 
based on spatial-temporal analysis of skin-color,” Proc. of International Technical 
Conference on Circuits/Systems, Computers and Communications, Bangkok, Thailand, 2006. 
[68] Wen-Nung Lie and Chen-Kang Su, “News Video Classification Based on Multi-modal 
Information Fusion,” Proc. Of  IEEE Int’l Conf. On Image Processing, ICIP-2005, Genova, 
