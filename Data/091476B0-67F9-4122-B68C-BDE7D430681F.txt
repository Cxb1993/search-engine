1. Introduction 
Recent advances in communication and computer technology have made increased the 
speed of transmission across the Internet. Next-generation networks will support transmission 
rates that are many orders of magnitude higher than current rates. Therefore, the explosive 
increase in commercial usage of the Internet has resulted in a rapid growth in demand for 
video deliver technologies. For instance, on-demand home entertainment gives customers the 
freedom to view movies from remote sites at any time in own homes, while distance learning 
gives opportunities for students to take courses taught at remote locations based on their 
individual needs and time constraints, and digital video library lets remote users research and 
view videos from a large video library. In such a system implemented with client-server 
architecture, viewers have the flexibility of specifying both the video they want as well as the 
time at which they wish to watch the video. 
A video-on-demand (VoD) system comprises a video server with a video archive and 
several client machines linked via a local area network. Users adopt request their desired 
videos using client software. The server delivers the requested video to the user in an 
isochronous data stream in response to a service request. Bar-Noy [1] found two major 
bottlenecks in current VoD system architecture: 
z The limited number of broadcasting channels available on the access network. 
z The number of movies that a server can send concurrently. 
Many schemes have been proposed to enhance the efficiency of the VoD system, 
including resource sharing and scheduling [2-5], admission control [6-9], disk striping 
[10,11], data replication [12-14], disk head scheduling [15] and data block allocation and 
rearrangement [16-18]. This work concentrates on resource sharing and scheduling schemes 
as described below. 
Among the resource sharing schemes represented in the literature, batching [19-24] is 
the most general policy for VoD system, since it groups users waiting for the same video data 
and serves them by a multicast channel. This batching process can occur passively while the 
users are waiting or actively by delaying the service of early-arriving users to wait for 
late-arriving users to join the batch. Since all users are placed in the same queue in batch 
mode, they have to wait to obtain the requested video service. Patching [25-26] exploits 
buffers videos using the client’s disk space, decreasing the requested waiting time. Therefore, 
patching strongly depends on client side’s disk space to be able to cache the video data. 
Piggy-backing [27-28] services a request almost immediately by varying the play-back rate 
on the client side, thus exploiting the user’s tolerance on play-back rate variation. 
Broadcasting [29-31] splits a video into several segments, and periodically broadcasts them 
 2
at the client’s site. For a new request to the same video, the server delivers only the missing 
portion of the requested video in a separate patching stream. The client downloads the data 
from the patching stream, and immediately displays the data. The client concurrently 
downloads and caches the later portion of the video from the multicast stream. When it 
finishes playing the data in the patching stream, the client switches to playing the video data 
in its local buffer. 
Piggy-backing services a request almost immediately, but alters the playback rate so that 
the request can catch up with a preceding stream, reducing the quality of the initial 
presentation. The server slows down the delivery rate of the video stream to a previous client, 
and speeds up the delivery rate of the video stream to a new client, until they share the same 
playing point in the video. The server then merges the two video streams, and utilizes only 
one channel to serve the two clients. The adjustment of the delivery rate must be kept below 
5% to preserve the display quality of the video, which restricts the number of channels that 
piggybacking can adaptively merge to save resources. 
A broadcasting scheme fragments a video into several segments, each of which is 
periodically broadcasted on a dedicated channel. A periodic broadcast system is highly 
scalable, since it can serve a very large community of users requesting the same video with 
minimal server bandwidth. The server bandwidth requirement is independent of the number 
of users that the system is designed to support. The client tunes concurrently into one or more 
channels to download the broadcast segments into its buffers, while local playback software 
renders the video data in the buffers onto the screen. 
2.2 Scheduling policies 
The performance of these resource-sharing strategies can be further enhanced if VoD 
servers can schedule the waiting requests in a suitable order. The scheduling policies differ in 
terms of which batch to serve first when a server channel becomes available. In 
first-come-first-served (FCFS), the batch holding the oldest request with the longest waiting 
time is served as soon as bandwidth becomes available. In maximum-queue-length-first 
(MQL) [34], the batch with the largest number of pending requests (i.e., longest queue) 
receives the service. FCFS offers fairness since the scheme treats each user equally, 
irrespective of the popularity of the requested video. However, FCFS yields low system 
throughput, since it may elect to serve a batch with fewer requests first while causes another 
batch with more requests to wait. To address this issue, MQL, which also maintains a 
separate waiting queue for each video, delivers the video with the longest queue first. This 
policy maximizes server throughput, but is unfair to users requesting less popular videos. 
Maximum-factored-queued-length first (MFQL) [35] tries to provide reasonable fairness and 
high server throughput. MFQL also maintains a waiting queue for each video. When a server 
 4
 Fig. 1. The architecture of the proposed hybrid VoD scheme 
Figure 2 illustrates the flow chart of the proposed hybrid VoD resource-sharing scheme. 
When a client requests a video, the video server first specifies the priority of the request. If 
the request is low-priority, and the controlled multicasting channels are not overloaded, then 
the server services the request immediately. The server places the low-priority requests into 
the scheduler when the controlled multicasting channels are overloaded. 
If the request belongs to the high-priority task group, and sufficient free controlled 
multicasting channels are available, then the server allocates a channel and serves the request 
immediately. A channel can also be allocated from any free reserved channels if no controlled 
multicasting channels are available. 
 6
3.1 Integration of controlled multicasting and channel borrowing 
A controlled multicasting [32, 33] scheme assumes that infinite server channels are 
available, and enables two clients that request the same video at different times can share a 
channel. However, the late-arriving client is permitted to use another free channel to 
download the portion of the video segment that was received by the early-arriving client. 
Unlike other batching schemes is that controlled multicasting does not delay the earlier 
request when it is still sharing a channel. 
Channel borrowing [32] has been presented to handle the temporary bandwidth crisis on 
controlled multicasting by borrowing bandwidth from other ongoing streams. As defined in 
coding standards as MPEG-2, video streams in this scheme are coded into multiple layers, 
comprising the base layer and several enhanced layers using a scalable layer video coding 
technique. Each layer corresponds to a particular QoS. During a temporary bandwidth crisis, 
some of the topmost ongoing video streams are eliminated to accommodate new streams. 
When bandwidth becomes available after a regular or patch stream is dropped, the missing 
layers of the streams are restored to reuse the free bandwidth. 
Figure 3 displays the sharing of the channels using the controlled multicasting and 
batching scheme. Clients are divided into two different priority groups ac cording to their 
certification guarantees. The clients in different classes have different QoS guarantees, only 
the high priority clients are assumed to have to pay for the requested videos. Therefore, the 
controlled multicasting scheme is dedicated to the clients in the high priority group, while the 
batching scheme serves low-priority clients who access videos for free. Each video is divided 
into several parts according to the broadcasting scheme. That is, each channel is divided into 
fixed time slots for transmitting a specific part of a video. The videos in the two priority 
groups were broadcast in turn. The controlled multicasting and batching scheme were 
integrated by changing the mode in each channel after fix time slot. High-priority clients are 
preferred to access channels in the controlled multicasting mode, while low-priority class 
clients are preferred to access channels in batching mode, as shown in Fig. 3. The low-class 
clients could access channels in controlled multicasting mode in case the current network 
loading is not heavy. Channel borrowing is utilized to enable high-priority clients to share a 
channel that is currently serving low class clients by removing the topmost layer of the 
ongoing streams that serve low-class clients in the controlled multicasting mode. The shared 
channel is adopted to catch up the missing video segment received by the early-arriving high 
priority clients. The difference between the proposed scheme and the broadcasting scheme is 
as follows. The broadcasting scheme broadcasts each video in turn. This approach is suitable 
only for popular videos, and consumes more server resources than the proposed scheme, in 
which the channel access mode can be changed. The proposed scheme is thus more flexible 
 8
where Str denotes the total number of the server streams; b is the blocking probability for 
class 1 video during the current time period; )(ˆ ⋅Hn  and )(ˆ ⋅Ln  represent the predicted 
numbers of high-priority and low-priority clients during the next time period, respectively, 
and K is a constant less than 1. Notably, the values of )(ˆ ⋅Hn  and )(ˆ ⋅Ln  are predicted by the 
weighted moving average method. 
3.2.1 Weighted moving average method 
Since  and  can both be treated as time series, this work predicts the value 
of the next time interval using a well-known time series predictor, the weighted moving 
average method [36], which has been reported to perform well on time series prediction [36]. 
Time series is a sequence of numerical values indexed by increasing time unit. The 
well-known time series prediction techniques in the literature include the ‘average’ method, 
which computes the mean of the past M measurement periods: 
)(ˆ ⋅Hn )(ˆ ⋅Ln
( )
( )
M
jt
t
M
j
∑1
0
-
1ˆ
−
===+
λ
λλ , (2) 
and the weighted moving average, which increases the weight of the last measurement 
period, 
( ) ( ) ( )tt λρλρλ ⋅+⋅−=+ 11ˆ , (3) 
where ρ =1, and λ  is the average calculated in Eq. (2). 
3.3 The Probability model-based scheduling policy 
Since the batching scheme leads to different videos waiting for service in the same 
priority class, another selecting mechanism is required to select the next video to serve in the 
same priority group. Wu et. al [37] assumed that the user can wait for infinite time. This 
assumption is impractical, because the client cannot reasonably wait for an unknown long 
time after having paid to watch a video on the Internet. This work presents a practical 
probability model-based scheduler, called the largest effective waiting time first scheduling 
policy, to user defection and unfairness. 
If the probability that a client leaves the system at t seconds is p(t), then the probability 
for the client leaving the system within t seconds is given by 
∫= t dxxptD )()( . (4) 
Now assume a client requests a video and does not cancel it within T seconds, and that 
the conditional probability for this client leaving the system after T seconds is, 
 10
and 
( ) ( ) ( ) ( ) dtdxeexdxxDxpxJ x txnnn ∫∫∫ ∞−
−−∞
∞−
−−∞
∞− ==
2
2
2
2
22
22
1 σ
μ
σ
μ
πσ  (11) 
The computation of Eq. (9) can then be further transformed into a linear matrix: 
⎥⎥
⎥⎥
⎥
⎦
⎤
⎢⎢
⎢⎢
⎢
⎣
⎡
=
⎥⎥
⎥⎥
⎦
⎤
⎢⎢
⎢⎢
⎣
⎡
3
2
1
0
6543
5432
4321
3210
J
J
J
J
IIII
IIII
IIII
IIII
e
c
b
a
, (12) 
where the values of I0, I1, I2, I3, I4, I5 and I6 can be derived by Eq. (10), and J0, J1, J2 and J3 can 
be obtained by Eq. (11). Since the coefficients of the cubic polynomial are tedious to derive 
from Eq. (12), we set z = x −μσ  and rewrite Eqs. (7) and (8) as follows to simplify the 
calculation: 
22
2
1)( /ze
π
zp = , (13) 
∫∞= z- /2' 'e2
1)(
2
dzzD zπ , (14) 
The cubic polynomial that approximates the cumulative distribution function thence 
becomes 
32)( ezczbzazg +++= , (15) 
After substituting for z in Eq. (15) using x − μσ , we obtain 
( ) 32 ⎟⎠
⎞⎜⎝
⎛+⎟⎠
⎞⎜⎝
⎛++=
σ
x-μe
σ
x-μc
σ
x-μbaxg , (16) 
and the error function becomes 
( ) ( )∫∞∞ +++= - dzzp-D(z)ezczbzaE 232 , (17) 
Since  is symmetric at( )zD )
2
1,0( , it can be shown that 
2
1=a , (18) 
 12
When n is even, In becomes a recurrence relation as follows, 
( ) nn InI 12 +=+ . (29) 
Thus, we obtain 
1531 642 ===  I;  I; I . (30) 
Next we let 
( )∫∞∞= - nn dzzpzK 2 . (31) 
It can be shown that 
nn-n KnJJ +=+ 11 , (32) 
and 
π
  J;  
π
J
4
5
2
1
31 == . (33) 
Accordingly, Eq. (24) can be expressed as 
⎥⎦
⎤⎢⎣
⎡=
⎥⎥
⎥⎥
⎦
⎤
⎢⎢
⎢⎢
⎣
⎡
=⎥⎦
⎤⎢⎣
⎡
1
15
24
1
4
1
2
1
153
31
-π
π
π
e
b
, (34) 
and the cubic polynomial as given by Eq. (16) becomes 
( ) 3
24
1
8
5
2
1 ⎟⎠
⎞⎜⎝
⎛ −−⎟⎠
⎞⎜⎝
⎛ −+=
σ
μx
πσ
μx
π
xg . (35) 
Accordingly, the tedious computation of Eq. (4) can be replaced by the simplified cubic 
polynomial form as illustrated by Eq. (35). 
The proposed VoD server selects the video to serve according to its vi value as given in 
Eq. (6). The video with the biggest vi value is served first. Figure 4 depicts the selection 
criteria for the next low-priority client under different scheduling policies. 
 14
4. Simulation 
A series of simulations were ran in this work ran to compare our proposed schemes with 
controlled multicasting, FCFS and MFQL. The parameters used in the simulations are 
summarized in Table 1. 
4.1 Performance metrics 
In the analysis of our resource sharing and scheduling policies, the following 
performance measures are used: 
z Blocking probability: This is the probability that an arriving high priority client 
leaves the system without being serviced due to the lack of server stream. 
z Defection probability: This is the probability that an arriving low priority client 
leaves the system without being served due to the waiting time exceeding the 
viewer's tolerance. Obviously, the defection probabilities may vary across different 
videos. Let ri denote the defection probability for video i, then the mean defection 
probability can be expressed by, 
 r = ∑
=
N
i
i Nr
1
. (36) 
z Meanwhile, the user defection behavior is modeled using normal distribution with a 
mean value of five minutes and standard deviation of one. 
z Average latency time: The latency of a client is the period which elapses between 
the arrival of the video request and the time when the service to the display device 
is actually initiated. Only non-defecting clients are considered in the latency time 
measure. 
z Unfairness: The unfairness is defined as follows. [35] 
)1()(
2
1
−−= ∑ = nrrunfairness ni i . (37) 
In many batching polices, the clients wait longer for the less popular, cold videos 
than for the more popular, hot videos. Higher unfairness values correspond to less 
fair policies. If all videos are treated equally, the unfairness as given by Eq. (37) 
should be small. 
 16
capacity is equal to or larger than 300 because there are more channels can be reserved or 
borrowed by high priority clients. 
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
100 200 300 400 500
Server Capacity
AHVoD1 AHVoD2 AHVoD3 CM
 
Fig. 6. Blocking probability of high priority clients for the three proposed schemes and 
controlled multicasting scheme under varied server capacity. 
The defection probability of low priority clients for the three proposed schemes and the 
representative scheduling schemes, MFQL and FIFO, is given in Figs. 7 and 8. The primitive 
hybrid scheme (AHVoD1) performs worse than MFQL scheme because the prompt service of 
high priority clients in controlled multicast operating mode deteriorates the defection 
probability of low priority clients operated in batching mode. The hybrid scheme embedded 
with channel borrowing mechanism (AHVoD2) performs slightly better than the hybrid 
system embedded with channel borrowing and reservation mechanisms (AHVoD3) because 
some channels are reserved for high priority clients in AHVoD3 and cause a moderate 
deterioration of the defection probability for the low priority clients.  
 18
44.2
4.4
4.6
4.8
5
5.2
5.4
20 30 40 50 60
Arrival Rate (requests/per minute)
AHVoD1 AHVoD2 AHVoD3 MFQL FIFO
 
Fig. 9. Service delay time of low priority clients at varied arrival rates. 
5
5.05
5.1
5.15
5.2
5.25
5.3
5.35
5.4
100 200 300 400 500
Server Capacity
AHVoD1 AHVoD2 AHVoD3 MFQL FIFO
 
Fig. 10. Service delay time of low priority clients under varied server capacity. 
Figs. 11 and 12 give the comparison of unfairness for the low priority clients in the five 
resource sharing schemes. The three proposed schemes are fairer than MFQL because the 
proposed scheduling policy schedules each video by the waiting time and leaving probability 
of each client in that video queue. It implies that the proposed scheduling policy selects the 
next video to serve based on the maximum waiting time along with the maximum leaving 
probability. Note that the hybrid system embedded with channel borrowing and reservation 
mechanisms (AHVoD3) performs better than AHVoD2 and AHVOD1 because the channel 
 20
00.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
20 30 40 50 60Arrival Rate (requests/per minute)
MFQL LETF FIFO
 
Fig. 13. Defection probability of the clients at varied arrival rates. 
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
100 200 300 400 500
Server Capacity
MFQL LETF FIFO
 
Fig. 14. Defection probability of the clients under varied server capacity. 
In order to see the effectiveness of the proposed scheduling policy, we further ran a 
series of test under batching mode wherein all the clients are treated identically. The proposed 
scheduling policy (LETF) was compared with MFQL and FIFO. Figs. 13 and 14 compare the 
defection probability of the clients under the three scheduling policies. As expected, the 
proposed scheduling policy can effectively reduce the defection probability. Since the 
proposed probability model based scheduling policy schedule the video queue by the waiting 
time and leaving probability of each client in the video queue. Thus, the proposed scheduler 
can selected the next video to serve before the client leaving the system by waiting for a long 
 22
queue and the waiting time of the incoming clients makes the proposed scheduling policy 
fairer than MFQL but slightly more unfair than FIFO. The selection criteria for the next video 
to serve in Eq. (6) shows that the queue with largest waiting time and largest leaving 
probability value will be serve at next time. It is reasonable to serve a client first who waits 
for a long time and has high possible defected by the system. 
0
0.02
0.04
0.06
0.08
0.1
0.12
0.14
20 30 40 50 60Arrival Rate (requests/per minute)
MFQL LETF FIFO
 
Fig. 17. Unfairness of the clients at varied arrival rates. 
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
100 200 300 400 500
Server Capacity
MFQL LETF FIFO
 
Fig. 18. Unfairness of the clients under varied server capacity. 
 
 24
References 
[1] A. Bar-Noy, J. A. Garay and A. Herzberg, “Sharing video on demand,” Discrete Applied 
Mathematics, 129(1), 2003, 3-30. 
[2] L. Juhn and L. Tseng, “Harmonic Broadcasting for Video-on-Demand Service,” IEEE 
Trans. on Broadcasting, 43(3), 1997, 268-271. 
[3] F. Lin, X. Wang and X. Xue, “A novel architecture for video-on-demand services,” The 
Fifth International Conference on Computer and Information Technology, 2005 , 640 – 
644. 
[4] W.-F. Poon, K.-T. Lo and J. Feng, “Scheduling policy for multicast video-on-demand 
system,” Electronics Letters, 37(2), 2001, 138 – 140. 
[5] K. O. Lee, J. B. Lee and K. W. Rim, “A dynamic scheduling algorithm for 
video-on-demand servers,” IEEE Transactions on Consumer Electronics, 50(4), 2004, 
1113 – 1118. 
[6] B. Qazzaz, J. Moreno, J. Xiao, P. Hernandez, R. Suppi and E Luque, “Admission control 
policies for video on demand brokers,” International Conference on Multimedia and Expo, 
2, 2003, 529-32. 
[7] S. E. Kim and C.R. Das, “A reliable statistical admission control strategy for interactive 
video-on-demand servers with interval caching,” International Conference on Parallel 
Processing, 2000, 135 – 142 
[8] P. Mundur, R. Simon and A.K. Sood, “End-to-end analysis of distributed 
video-on-demand systems,” IEEE Transactions on Multimedia, 6(1), 2004, 129 – 141. 
[9] P. Mundur, A. k. Sood and R. Simon, “Class-based access control for distributed 
video-on-demand systems,” IEEE Transactions on Circuits and Systems for Video 
Technology, 15(7), 2005, 844–853. 
[10] P. Sumari, M. Merabti, and R. Pereira, “Video-on-demand server: strategies for 
improving performance,” IEE Proceedings Software, 146(1), 1999, 33 – 37. 
[11] P. Sumari, A. Samsudin and H. Kamarulhaili, “Data storage and retrieval for 
video-on-demand servers,” Fourth International Symposium on Multimedia Software 
Engineering, 2002, 240 – 245. 
 26
[23] C.C.Y. Choi and M. Hamdi, “A scalable video-on-demand system using multi-batch 
buffering techniques,” IEEE Transactions on Broadcasting, 49(2), 2003, 178 – 191. 
[24] N.L.S. da Fonseca and H.K.S. Rubinsztejn, “Dimensioning the capacity of true 
video-on-demand servers,” IEEE Transactions on Multimedia, 7(5), 2005, 932 – 941. 
[25] W.-F. Poon, K.-T. Lo and J. Feng, “Determination of efficient transmission scheme for 
video-on-demand (VoD) services,” IEEE Transactions on Circuits and Systems for Video 
Technology, 13(2), 2003, 188 – 192. 
[26] D. Guan and S. Yu, “A two-level patching scheme for video-on-demand delivery,” IEEE 
Transactions on Broadcasting, 50(1), 2004, 11 – 15. 
[27] W.-F. Poon, K.-T. Lo and J. Feng, “Provision of continuous VCR functions in interactive 
broadcast VoD systems,” IEEE Transactions on Broadcasting, 51(4), 2005, 460 – 472. 
[28] W. Chien, Y. Yeh and J. Wang, “Practical Channel Transition for Near-VOD Services,” 
IEEE Transactions on Broadcasting, 51(3), 2005, 360 – 365. 
[29] J.B Kwon and H.Y. Yeom, “VCR-oriented video broadcasting for near video-on-demand 
services,” IEEE Transactions on Consumer Electronics, 49(4), 2003, 1106 – 1113. 
[30] Z. Zhang, S. Yu, J. Chen and K. Chu, “Advanced mirrored-pyramid broadcasting for 
video-on-demand,” IEEE Transactions on Consumer Electronics, 50(1), 2004, 139 – 144. 
[31] J.-F. Paris, “A simple but efficient broadcasting protocol for video-on-demand,” 
24th IEEE International Performance, Computing, and Communications Conference,  
2005, 167 – 174. 
[32] S.A. Azad, M. Murshed and L.S. Dooley, “Bandwidth borrowing schemes for 
instantaneous video-on-demand systems,” IEEE International Conference on Multimedia 
and Expo, 3, 2004, 2011 – 2014. 
[33] L. Gao and D. Twosly, “Supplying instantaneous video-on-demand services using 
controlled multicast” Proceedings of IEEE International Conf. on Multimedia Computing 
and Systems, 1999, 117-121. 
[34] A. Dan, D. Sitaram, and P. Shahabuddin, “Scheduling Policies for an On-Demand Video 
Server with Batching” Proceedings of the ACM Conf. on Multimedia,  1994, 391-398. 
[35] C. C. Aggarwal, J. L.Wolf, and P. S. Yu, “The Maximum Factor Queue Length Batching 
Scheme for Video-on-Demand Systems” IEEE Trans. on Computers, 50(2), 2001, 97-110. 
 28
計畫成果自評 
1. 研究內容與原計畫相符程度 
本研究遵循原計畫內容及概念撰寫程式並執行模擬，研究過程與原計畫相符，唯所
使用的排程演算法由原先的機器學習機制改為機率模型排程演算法，由於使用機率
模型的排程演算法比原先提出的機器學習演算法來的有效率，且模擬結果證實與目
前文獻上所提出的隨選視訊系統的排程演算法相比較，所提出的機率模型演算法有
較好的成效，證實了該演算法的有效程度。 
2. 達成預期目標情況 
本研究成果豐碩，亦與預期目標一致；而研究中所提出的混合式資源共享隨選視訊
系統與機率模型的排程演算法在模擬結果顯示能比過去單一隨選視訊系統有較好的
效能，不論是針對付費的高優先權使用者，或是免費使用的低優先權使用者。 
3. 研究成果之學術或應用價值 
本研究所提出的混合式隨選視訊系統與機率模型排成演算法，其成果顯示我們提出
的技術的確適用於隨選視訊系統上的多媒體應用，而排成演算法屬於最佳化問題的
領域，研究成果也顯示該演算法能提升系統的服務時間與公平性，因此總體下來，
不管在學術或應用方面，本研究均能提供學術界或企業界後續研發技術之參考。 
4. 是否適合在學術期刊發表或申請專利 
由於本研究所提出混合式共享資源隨選視訊系統，分別針對不同優先權使用者提出
不同的服務方式，對高優先權的使用者提出可即時服務使用者的頻寬借用與預留機
制，對低優先權使用者提出的機率模型排成演算法能有效降低使用者離開系統的機
率、服務延遲的時間與公平性，而實驗結果也證明本架構的可行性。本研究成果已
投至SCI期刊，目前正進入Revision階段。
 30
二、與會心得 
由於此次會議的論文很多，大會安排了口頭和海報論文發表二種，論文的口頭報告
方面，由於論文篇數相當多，因此大會安排了多個平行的會議場地，且限制發表的時間
為 15 分鐘，時間非常緊湊。 
智慧系統創新與應用國際研討會(2007 International Symposium on Innovations in 
Intelligent Systems and Applications)安排的研究與討論的主題包括如下所示之領域： 
z Artificial Intelligence Algorithms 
z Intelligent Approaches in Robotic and Automation 
z Artificial Neural Networks 
z Intelligent Approaches in Signal and Image Processing  
z Bioinformatics 
z Intelligent Approaches in System Identification/Modeling 
z Data Mining 
z Intelligent Control Systems 
z Evolutionary Computations 
z Intelligent Defense/Security Systems 
z Expert Systems 
z Intelligent Life 
z Fuzzy Logic 
z Machine Learning 
z Genetic Algorithms 
z Natural Language Processing 
z Hardware Implementations for Intelligent Systems 
z Partical Swarms 
z Human-Computer Interaction 
z Smart Sensors and Materials 
z Intelligent Applications in Biomedical Engineering 
z Other topics related with Intelligent Systems 
在每一個主題的會議中均有多位學者發表相關的研究成果，並和與會的專家學者進
行討論。在會議的進行過程中讓我們體會到在國際會議的場合對於研究問題與討論的深
入與嚴謹，個人除自多位學者專家得到許多珍貴的建議外，並由數篇他人發表之研究成
果啟發出相關主題進一步探討的靈感。 
 
三、建議 
出席國際性學術會議除能增廣見聞、吸收新知外，更能和研究同一領域之國內外學
者互相切磋討論，十分感謝國科會此次提供經費補助。由於此次個人發表 2 篇論文，註
冊費用較高，但因補助之經費有限，致使自行負擔之經費比例較高。希望日後於經費許
可下盡量給於與會學者補助，以提高國內學者參加類似之國際性學術會議之意願，並藉
以提昇台灣國際學術地位。 
