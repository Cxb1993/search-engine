Compression of Chinese Document Image based on Pattern Matching and Symbol Clustering
Chwan-Yi Shiah
Department of Informatics
Fo Guang University, I-Lan, Taiwan 26247
cyshiah@mail.fgu.edu.tw
ABSTRACT
In this paper, we present a general compression scheme
for the Chinese document images. The method consists
of three phases. First, the document image is segmented
into Chinese characters using connected component analy-
sis. Separated parts of a character will be merged in this
phase. Second, the spatial domain shape context feature
sets are extracted for pattern matching and clustering on the
character level. To reduce the time for symbol matching,
shape context features are degraded to include one sample
point (called centroid), and the stroke density features are
used for fast pruning of unlikely symbols. The symbol clus-
tering procedure is multistage: Initially all characters are
representative symbols, repeated symbols are grouped to-
gether based on a strict criterion. At the sebsequent stages,
less strict criterions are used to group similar clusters and
eventually a more compact set of symbols are formed to
represent all characters. We use this set to reduce symbol
redundancy in the text region and achieve high compres-
sion ratio. In the last phase, bit-based and integer-based
arithmetic coding are employed to encode the representa-
tive symbol pixels and their corresponding coordinate and
index data. In the experiment on several scanned document
images, the compression ratio of the proposed method is
better than the international standard JBIG2 algorithm on
the average and the compressed form of the document im-
age is suitable for a content-based keyword searching op-
eration, both of which are desired attributes in the digital
archive of Chinese document images.
Keywords: Document Image Compression, Shape Con-
text, Pattern Matching, Symbolic Compression, Symbol
Clustering.
1. INTRODUCTION
Document image compression has its earlier use in fax ma-
chine. The documents are textual images and black/white in
nature. Conventional approaches for document image com-
pression include several international standards: CCITT
Group3, Group4 and JBIG1 [10] (also known as ITU-T
recommendation T.82). These standards are for generic
document images and achieve various degree of compres-
sion. Among these standards, the JBIG1, which uses a
form of adaptive arithmetic coding known as Q-coder, has
1.1 to 1.5 times compression ratio better than the CCITT
Group4, which in turn outperforms the CCITT Group3.
Besides, JBIG1 supports ‘progressive’ mode of transmis-
sion and multiple bit-plane encoding, by which it can be
used for color and grayscale images. The JBIG1 standard
had been the best document image compression scheme be-
fore the JBIG2 standard emerged. Therefore, we will base
our performance comparision on the JBIG2 implementation
in [13].
The latest binary image coding methods, including
JBIG2 [11] standard and JB2 [15] (used in DjVu file for-
mat), use another form of compression scheme called ‘pat-
tern matching’. The idea of pattern matching comes from
the symbol redundancy among the text region of an image
when a human observer reads along the text line. The pat-
terns which are similar in shape usually correspond to a
symbol, a word or a character in a document, but this is not
required in JBIG2. They can occur many times through-
out the entire text. Therefore high compression ratio can be
achieved by compressing these redundancies. The JBIG2
uses a pattern matching technique— the Soft Pattern Match-
ing [14] for matching repeated symbols. During the encod-
ing phase, the representative symbol, which can be stored as
a template, will be encoded by an efficient coding scheme
and its similar patterns are stored as the index to the tem-
plate. Note that the difference between the template and its
similar images can effect the quality of the decompressed
image. If the residual images (the XOR operation of the
template image and its similar pattern) are also encoded into
the compressed data, the compression will be lossless. Oth-
erwise, the compression will be lossy.
1.1. System Overview
In this paper, we implement a lossy pattern matching com-
pression scheme on the character-level for the Chinese doc-
ument image. The method can be easily extended to do
1
as the scan line goes from a text region to a halftone region,
the cross-correlation function gradually loses its periodic-
ity. More detailed information about the layout of a docu-
ment image can be found by combining the interline cross-
correlation with other methods. For example, the boundary
of textlines can be marked by the contour following and X-
Y cut methods [18]. In the next section, a pattern matching
technique which are suitable for matching Chinese charac-
ters will be proposed. Since we are dealing with character-
level pattern matching and compression in the text region,
the halftone region’s compression will not be considered in
this paper.
Figure 1: The disjoint components (labelled by rectangles)
within a Chinese character found by connected component
analysis.
Figure 2: Diagram for testing if the two subcharacters are
close enough relative to their size.
3. PATTERN MATCHING
In this section a pattern matching technique which is based
on the shape context method [5] will be discussed. As we
mentioned in section 1.1, the large number of Chinese char-
acters and their various forms make the pattern matching
task formidable. Traditional OCR methods for recogniz-
ing Chinese characters have been developed for many years.
However, most of the proposed OCR methods require a pre-
defined character set (a dictionary) and a training phase be-
fore the recognition phase can actually start. Here we use
the modified shape context method for matching any pat-
terns appearing in a document image without the computa-
tional intensive training. The matching of similar patterns
can be even faster by including the stroke density feature
of a Chinese character. Considering the high complexity of
an image pattern, the local appearance features are incorpo-
rated into the shape context feature set so that the similarity
measure between two patterns can be calculated based on
the above mentioned features.
3.1. The Modified Shape Context
The shape context method is a spatial domain shape de-
scriptor which makes use of the local or global histogram
for representing an image pattern. For its simplest form, we
sample one point from the image where the center of grav-
ity resides, called ‘centroid’. The centroid point is unique
in each image pattern and preserves the rotational invariant
property. In some situations the image pattern is rotated by
some degrees and the centorid point remains in the same
place. Hence the shape context feature can be made rota-
tional invariant too. In Fig. 3, a Chinese character and its
centroid point are shown. The global histogram is made
by measuring the distribution of image pixels relative to the
centroid, it can be stated as follows:
hc(r, θ) = #{~v : r = ‖~v − ~c‖, θ = 6 (~v − ~c), ∀ ~v ∈ V }
(1)
where~c is the centroid point, V is the set of all image pixels,
θ is the angle of ~v − ~c relative to the positive x-axis and r
is the Euclidean distance between ~v and ~c. Since r and θ
are continuous variables, we divide them into several bins
that are equally spaced and normalize the value of r by the
height and width of image pattern so that the histogram is
independent of the size of image . In Fig. 4, the global
histogram for the centroid point in Fig. 3 is shown, darker
grids represent larger values. The number of bins for r, θ are
set to 5 and 12 respectively so that the structure of Chinese
character can be captured. The global histogram in Fig. 4 is
referred to as the shape context in [5] and it is unique and
reversible to the original image. We measure the distance
between two global histograms hc and gc as follows:
global dist =
1
2
m∑
i=1
n∑
j=1
(hc(i, j)− gc(i, j))2
hc(i, j) + gc(i, j)
(2)
where i denotes the ith bin of radius r and j denotes the
jth bin of angle θ. Furthermore, the distance measure
global dist can be restricted to [0, 1] if we normalize the
global histogram as follows:
m∑
i=1
n∑
j=1
hc(i, j) =
m∑
i=1
n∑
j=1
gc(i, j) = 1 (3)
so that a similarity measure can be made to judge if two
patterns are similar in shape. In section 3.2, the local ap-
pearance features that account for the detailed structure of a
pattern are incorporated into the distance measure.
3.2. Local Appearance
Due to the nonuniform distribution of image pixels, the
number of bins used in the radius r and angle θ in the global
3
is computed as the Euclidean distance of f1 and f2 weighted
by the weighting function w(m,n) derived from (6):
stroke dist =[∑M
m=1
∑N
n=1 w(m,n)(f1(m,n)− f2(m,n))2
]1/2
(9)
During the process of pattern matching and symbol cluster-
ing, the distance measure stroke dist is first used to filter
out unlikely patterns. For more complex characters, the dis-
tance measure in (4) is used for matching their shape con-
texts. The multistage symbol clustering will be discussed in
the next section.
Figure 7: A Chinese character divided into 4 × 4 grids (c:
corner, h: center, p: peripheral).
4. SYMBOL CLUSTERING AND CODING
The clustering of symbols (e.g. characters, punctuation,
numbers and English letters and so on) is based on the
distance measures in (9) and (4). The former measure is
a coarse selection of similar patterns based on the stroke
density function. The latter measure is more precise and
is based on the shape context method where the local his-
togram computed from the local appearance is included.
The symbol clustering proposed in here is similar to the
multistage structural clustering in [16] with the same pur-
pose that a prototype symbol library (or a template library)
is formed to replace repeated patterns in the original docu-
ment image. The procedure is stated as follows:
step 1: Initially, all symbols (segmented and merged by the
procedure described in section 2) in the document im-
age are included in the prototype symbol library, the
number of all symbols is assumed to be N .
step 2: Setup the threshold values η1, η2, τ for the stroke
density and modified shape context method, where
η1, η2 denote the upper and lower thresholds for
matching stroke density functions, τ denotes the
threshold for matching shape contexts, set flag = 0.
step 3: Take two symbols Si, Sj from the prototype sym-
bol library, where 1 ≤ i ≤ P − 1, i+ 1 ≤ j ≤ P , the
number of symbols in the prototype symbol library is
assumed to be P .
step 4: Match Si and Sj by their stroke density functions,
the distance measure stroke dist could be in one of
the following three cases:
case 1: stroke dist < η2, the match is accepted, goto
step 6 to update the prototype symbol library.
case 2: η1 ≥ stroke dist ≥ η2, the match is partially
accepted, goto step 5 for more tests.
case 3: stroke dist > η1, the match is rejected, goto
step 7 for the next symbol matching.
step 5: Match Si and Sj by shape contexts, the result could
be in one of the following two cases:
case 1: dist < τ , the match is accepted, goto step 6 to
update the prototype symbol library.
case 2: dist ≥ τ , the match is rejected, goto step 7 for
the next symbol matching.
step 6: The match is accpeted, replace the symbol Sj by
Si in the prototype symbol library, P = P − 1 and set
flag = 1.
step 7: Check if there are more prototype symbols that
need to be matched in the library, if the answer is yes,
goto step 3; otherwise goto step 8.
step 8: Check the value of flag, if flag = 1, goto step 2;
otherwise the procedure is ended.
The procedure stated above is illustrated by a flowchart
shown in Fig. 8. Initially a strict threshold value τ is used
for matching shape contexts in step 5. At the subsequent
stages, the value of τ is loosened up in step 2 to allow more
prototype symbols to substitute for their similar shapes in
step 6. High compression ratio can be gained as the num-
ber of prototype symbols keeps decreasing in the prototype
symbol library. To avoid error substitution, we use the false
acceptance test to ensure that the document image recov-
ered from the compressed data is content-lossless, which
implies that there is no visible error between the original
image and the decompressed one. The false acceptance test
is to substract the image Sj from Si (and vice versa) and
check the number of pixels in the residual image so that an
exact match can be attained:
false acceptance =( |Sj−Si|
|Sj | < γ1
)
∧
( |Si−Sj |
|Si| < γ2
) (10)
where |Si| denotes the number of black pixels in the im-
age Si, the image Si − Sj contains the pixels that are in-
cluded in Si but not included in Sj , the values of γ1 and γ2
are forced to be less than 1 to ensure an exact match. By
the definition in (10), the match is rejected if the value of
false acceptance is equal to true. The resulting prototype
symbols, their corresponding coordinate and index data are
encoded by a well-known coding scheme—the arithmetic
coding, which will be discussed in the next section.
5
5. EXPERIMENTAL RESULTS
In this section, a number of scanned document images
printed in Chinese are tested by the proposed pattern match-
ing and symbol clustering algorithm. The layout of the doc-
ument image can be horizontal or vertical to reflect the con-
vention of documents written in Chinese. The documents
were collected from various sources with different fonts,
sizes and printing quality, all of them were scanned with
varying resolutions between 150 to 300 dpi.
Initially the documents are segmented into characters
by the algorithm in section 2, followed by the multistage
symbol clustering procedure to find the prototype sym-
bol library, where the distance between different symbols
is based on the modified shape context and stroke den-
sity method. The size and positional information regarding
the prototype/non-prototype symbols are compressed by the
integer-based arithmetic coding, while the image pixels of
prototype symbols are compressed by the bit-based adaptive
arithmetic coding. The image pixels of the non-prototype
symbols are discarded and replaced by the prototype sym-
bol pixels at the reconstruction phase. The results of charac-
ter segmentation, symbol clustering and image reconstruc-
tion are shown from Fig. 10 to Fig. 13.
The original document image in Fig. 10 contains
119,472 bytes, where 345 symbols are segmented and
shown in Fig. 11. Among those symbols, 231 symbols
are prototype, 114 symbols are non-prototype and both are
shown in Fig. 12. The prototype symbols are left intact in
Fig. 12 and the non-prototype symbols are obtained by sub-
tracting the prototype symbol pixels from the non-prototype
symbols. At the encoding phase, the residual pixels from
non-prototype symbols are discarded, resulting in a lossy
compression with file size 16,547 bytes and compression
ratio 7.22 (input vs. output). Compared with the implemen-
tation of JBIG2 algorithm in [13], the compressed file with
JBIG2 has 21,373 bytes, 582 symbols and a compression ra-
tio 5.59. Table 1 and Table 2 list the results of compression
on more scanned documents printed in Chinese. The aver-
age compression ratio in Table 1 is 16.32, which is better
than the average compression ratio 11.35 in JBIG2. Based
on the experiments, we make several observations as fol-
lows:
• The method proposed in here is prone to be effected by
the quality of printing and scanning noise. As the noise
level becomes high, the number of prototype symbols
increases and the degree of compression goes down.
• The compression is in fact lossy, however, we can
make the contents lossless by including the false ac-
ceptance test so that there is no visible error between
the reconstructed image and the original one.
• The clustering of repeated symbols in here is based
on, but not limited to, the Chinese characters. In other
compression algorithms that use the pattern matching
technique, such as JBIG2, the symbol may not corre-
spond to a character and hence it may result in a dif-
ferent compression performance.
• As the number of symbols increases, we have more re-
peated symbols and hence the degree of compression
increases. This is especially true for multi-page docu-
ment images from the same source.
• The method used in here and the structure of the com-
pressed file are ready for a content-based keyword
and image searching operation, especially when some
complex symbols, such as Chinese characters, are pre-
sented in the document.
In the experiment, the number of symbols found in JBIG2
is more than the number of prototype symbols in Table 1,
which implies that more repeated symbols are found in our
symbol clustering procedure, hence we can have more sym-
bols replaced by their corresponding prototypes and achieve
higher degree of compression.
6. CONCLUSIONS
In this paper, we propose a pattern matching and symbol
clustering algorithm for the compression of scanned docu-
ment images printed in Chinese. Due to the characteristic
of Chinese characters, we design a couple of procedures for
the segmentation and merging of image components that be-
long to the same character. Also, due to the high complexity
of Chinese characters, the algorithm for matching charac-
ters is based on the modified shape context method. The
results show that it is effective in finding similar symbols in
a document image.
Before the compression can actually take place, we
group repeated symbols by using the multistage symbol
clustering algorithm so that the actual number of symbols
being compressed is reduced to the number of prototype
symbols. The binary pixels from prototype symbols and
their corresponding positional data are then compressed by
the bit-based adaptive arithmetic coding and the integer-
based arithmetic coding. Based on the experiment on a
number of document images, the compression efficiency
outperforms the international standard JBIG2 algorithm on
the average and, at the same time, the structure of the com-
pessed file is ready for a content-based keyword searching
operation. Therefore, we conclude that this study will be
a great help in the realization of massive digital archive of
Chinese documents.
7
Figure 10: The original scanned document image.
Figure 11: The document image in Fig. 10 segmented into Chi-
nese characters.
Figure 12: The prototype symbols (which are left intact in
the image) and non-prototype symbols (obtained by subtracting
prototype symbol pixels).
Figure 13: The reconstructed document image.
9
計畫成果自評：
本研究使用了圖像比對及符號叢集技術，實現了中文二元文字影像之壓縮，並與文字影像
壓縮之國際標準JBIG2進行比較，達到了較佳的壓縮效能，與原計畫之研究內容相符程度
100%，並且達成預期的研究目標。同時，在壓縮檔案的結構方面，具有快速搜尋相似影像
及內容的能力，在中文化數位典藏的領域，具有較佳的應用價值。未來將持續進行壓縮影
像內容檢索應用程式的開發，以及改進程式之執行效能，並選擇在適當的學術期刊發表。
