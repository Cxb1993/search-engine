1 
摘要 
一、 中文摘要 
隨著電腦科技的進步及網際網路的發展，越來越多的數位化音樂可透過網路傳播。但
面對如此大量且豐富的資料，如何讓需要者能快速準確的找到所要的資訊，一直都是我們
所面臨的挑戰。而到目前為止，大多數相關的研究是以哼唱系統為主，也就是查詢者演唱
一段音樂，查詢系統將其轉換為音高、音長等特徵值，然後再與預先依主旋律建置的資料
庫做比對，將比對到的資料當作答案回應出來，這類系統大都只提供單音旋律的查詢。但
事實上音樂絕大多數是以複音的形式存在。所以能適用於複音環境的查詢系統有其發展的
必要。在本論文中，我們使用複音表示音樂的特徵值，並依據音量進行的樂句分段，然後
建立適用於複音音樂之索引結構，利用容錯的近似查詢方法，能夠提供快速且符合查詢需
求的複音音樂資料庫系統。 
關鍵詞：複音音樂資料庫、音樂分類、索引結構、查詢處理 
二、 英文摘要 
Due to the great progress of computer technology and mature development, more and more 
music objects in various formats are generated and distributed through the Internet. Given a large 
amount of music objects, to provide the users a suitable and fast query tool is very important. The 
most of existing musical information retrieval (MIR) system only provide the function of query 
by humming. In these systems, the user first sings a piece of music as query. Then, music objects 
are matched with the query by the information of pitch and duration. They only consider the 
monophonic music. Indeed, most music objects are polyphonic. A system can provide query by 
any kind of music is necessarily developed. In this project, we extract the features from the 
polyphonic music, segment the music into sentences and design a novel index structure and a 
query processing for the polyphonic music. 
Keywords：Polyphonic music database, music classification, index structure, query processing 
3 
三、 文獻探討 
3.1 音樂特徵值擷取 
在傳統的音樂資料庫中，音樂的分類及查詢不外乎是基於演唱者、曲風、年代等等資
訊，而這些資訊通常都是以人工的方式取得，因此在大量的音樂資料庫中，這種方式就會
非常沒有效率。就自動化分類及內涵式查詢法而言，適當的特徵值擷取就相當的重要了。 
就音樂的表示法而言，可分為以訊號為主的資料(如WAV、MP3等)，及符號為主的資
料(如 MIDI)兩類。對於訊號而言可以直接取用相關低階參數，如(i) zero crossing rate (ii) 
MFCC coefficients等[1]，或是轉置為符號資料[2]。 
如果採用第一種方法，如何選取出具有代表性的特徵並給予適當的權重，便是十分重
要的課題，為了能夠有效率地處理大量的音樂資料以及提升分群或是查詢的準確性，相關
研究之目標都在於能夠從資料中擷取出有代表性的特徵，同時淘汰那些重複或是不重要的
特徵。在特徵選取的研究領域中，相關的研究成果有早期的 principal component analysis 
(PCA) method[3]，為了能夠有效地降低維度，將原有的特徵轉換成 principal components以
將原有資料的特徵作 summarize，但是這個方法的缺點在於其特徵轉換的過程會導致失真的
出現；之後利用統計的角度來選取特徵的方法相繼出現，其最典型的作法是利用 entropy來
找出具有意義的特徵[4]。 
如同文章一般，音樂是由一連串長短不一的句子所組成的，這些句子我們稱之為樂句。
一般人所記憶的音樂亦由樂句為基本單位，所以樂句這樣的特徵在查詢時扮演重要的角
色，但在分析大量的音樂資料時，以人工的方式取得將會是十分耗時的，因此必須要有自
動化的方式來加以處理，目前已經有一些研究[5]開始朝自動化的方式來擷取出音樂物件中
的樂句。 
3.2音樂查詢技術 
Barlow和Morganstern[6]曾針對音樂的旋律，建立常用旋律提供查詢。Hudson [7]亦以
建立線上索引的方式進行樂曲的查詢，Dowling[8]亦提出輪廓對使用者而言，是辦識旋律的
重要工具。在六０年代與七０年代間的計畫，多半著重於音符資料的儲存與表示，較少考
慮使用者的查詢與使用方式。近年來，研究者則開始朝向建立一個完整的音樂查詢系統努
力，如 Yamamoto於 1988年發展由使用者自鍵盤輸入查詢條件，其系統採完全比對方式，
進行樂曲的查詢工作。 
5 
句。為減小索引結構的複雜度。我們進行音樂樂句的分割。在音樂訊號均轉為符號資料後，
我們利用無聲的部份或是超過一個Window長度中平均音長的延長音做為分割樂句的依據。 
我們使用可由使用者自訂參數的相似度計算方法，計算法則如下： 
1. 計算使用者查詢與查詢結果之訂正距離(edit distance)。 
2. 可給予不同的訂正值比重。 
∑ ∑∑∑
∑
= =
==
= ===
128
1
128
1
128
1
2128
1
2
128
1 1)(,1)(,
)(*)(
)(*)(
),(
i i
i
i
Vi
i
U
i i
i
Vi i
i
U
i i
i
Vi
i
U vf  uf  
vfuf
vfuf
VUsim  
U, V: the vectors of events with 128 dimensions 
ui, vi: the values of dimension i in U, V vectors respectively 
fUi, fVi: the weighting functions of U, V for dimension i 
在索引結構及查詢處理，一般在字串比對所使用的索引結構多為Suffix tree或是改良自
Suffix tree的結構，但音樂的音符種類繁多，除了基本的88個樂音外，加上各個音符有不同
的長度及複音的組合，建立Suffix tree將會使得該樹的Branch factor過大，導致查詢時會與掃
描整個資料庫的時間接近，我們使用簡單的Link List結構記錄每個複音曾經出現的歌曲編號
及位置。 在查詢處理上我們直接比較各個鍵值出現的順序關係，進而找到該音樂片段的所
在位置。如下圖例，可以找到單音60之後出現 60、67，然後再出現62的音樂片段在第一首
歌的第七個位置、第二首歌的第一個位置還有第三首歌曲第九個位置開始。在整個研究中
我們測試查詢結果的正確性(effectiveness)。 
1D-List 索引結構 1D-List查詢處理 
五、 結果與討論 
就多音音樂資料的轉換，我們利用頻譜分析的方法，先將短時距的音樂訊號轉換至頻
譜，藉由樂音中基頻與泛音有比例關係，將旋律的頻率萃取出來。此方法與傳統方式相同，
但我們繼續藉由頻譜中去除已找出頻率的部份，使用其他能量較大的頻率轉換出第二及第
7 
[3] Joliffe, I. T., Principal Component Analysis, New York: Springer-Verlag, 1986. 
[4] Setiono, R. and H. Liu, “Neural network feature selector,” IEEE Trans. on Neural Networks, 
vol. 8, May 1997. 
[5] Takasu, A., T. Yanase, T. Kanazawa and J. Adachi, "Music Structure Analysis and Its 
Application to Theme Phrase Extraction ", 3rd European Conference on Digital Library, 
1999. 
[6] Barlow, H., and S. Morganstern, A Dictionary of Musical Themes, Crown Publishers, Inc., 
New York, 1948. 
[7] Hudson, B., Toward a Comprehensive French Chanson Catalog, Lincoln, 1970. 
[8] Dowling, W. J., “Scale and Contour: Two Components of a theory of memory for melodies,” 
Computers and the Humanities, 16:107-117, 1978. 
[9] Ghias, A., H. Logan, D. Chamberlin, and B. C. Smith, “Query by Humming: Musical 
Information Retrieval in an Audio Database,” in Proceedings of 3rd ACM International 
Conference on Multimedia, pp. 231-236, 1995. 
[10] Prather, R. E., “Harmonic Analysis from the Computer Representation of a Musical Score,” 
Communication of the ACM, Vol. 39, No. 12, Dec. 1996, page 119, (pages 239~255 of Virtual 
Extension Edition of CACM) 
[11] Blackburn, S. and D. DeRoure, “A Tool for Content-Based Navigation of Music,” in 
Proceedings of the 6th ACM International Multimedia Conference, pages 361~368, 1998. 
[12] Tseng, Y. H., “Content-Based Retrieval for Music Collections,” in Proceedings of 
International Conference on ACM SIGIR, 1999. 
[13] MuseData System, Stanford University, http://www.ccarh.org/musedata/. 
[14] Clausen, M., R. Engelbrecht, D. Meyer, J. Schmitz, “PROMS: A Web-based Tool for 
Searching in Polyphonic Music,” International Symposium on Music Information Retrieval, 
2000. 
[15] Wiggins, G., E. Miranda, A. Smaill, and M. Harris, “A Framework for the Evaluation of 
Music Representation Systems,” Computer Music Journal, 17(3), 1993 
[16] Dovey, M. J., “An Algorithm for Locating Polyphonic Phrases within a Polyphonic Musical 
Piece,” in Proceedings of the AISB '99 Symposium on Musical Creativity, pp 48-53, 
Edinburgh, 1999. 
[17] Lemstrom, K., String Matching Techniques for Music Retrieval, PhD thesis, Department of 
Computers Science, University of Helsinki, Finland. 
[18] McNab, R. J., L. A. Smith, D. Bainbridge, and I .H. Witten, “The New Zealand Digital 
Library: MELody inDEX,” D-Lib Magazine, 1997. 
