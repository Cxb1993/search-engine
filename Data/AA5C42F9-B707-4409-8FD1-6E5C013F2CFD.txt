 1
一､前言 
隨著第二語言學習需求的增加，電腦輔助語言學習(Computer-Assisted Language Learning, 
CALL)系統已成為不可或缺的學習工具之一，其可結合自然語言及語音處理技術提供學習者便
利的學習環境及有用的回饋資訊。目前國內外相關研究大部分著重於以英語為第二語言(English 
as a Second Language, ESL)之輔助學習，包括：分詞、介系詞及動詞時態等文法錯誤偵測與修正
[1], [2], [3], [4], [5]；國內相關研究則包括：張俊盛教授所發展的雙語辭彙索引典[6]與雙語搭配
詞查詢系統[7]，其雙語的優勢在於學習者可透過以母語查詢第二外語的方式快速掌握單字與片
語的用法甚至是使用頻率；劉吉軒教授利用資訊檢索技術自動從語料庫中推薦適當的範例句來
輔助英文寫作[8]；張俊盛、劉昭麟及高照明教授則提出電腦輔助文法、閱讀測驗、克漏字出題
[9], [10], [11]及試題翻譯等教學上之應用[12]；廖元甫教授亦針對電腦輔助語言學習系統提供詳
盡的文獻探討，尤其是在語音技術的部分[13]。 
近年來，隨著華人市場逐漸受到重視，全球正興起一股學習華語文的熱潮，加上政府亦積
極推動台灣成為華語文學習資源及數位學習重鎮，因此，以華語文為第二語言(Chinese as a 
Second Language, CSL)之相關研究也逐漸受到重視。CSL學習者在寫作過程中容易其母語影響
而產生錯誤的句子，這些錯誤通常稱之為負向的語言遷移(Language Transfer)。本計畫事先從語
言中心收集部分英中錯誤句子，觀察後歸類出CSL學習者較常產生的負向語言遷移為詞序(Word 
Order)、選詞(Lexical Choice)、冗詞(Redundancy)與漏詞(Omission)錯誤，表1顯示了這些錯誤類
型之範例句及其對應的正確句子。 
表1 錯誤類型之範例 
錯誤類型 錯誤句子 正確句子 
詞序錯誤 我睡覺十二點昨天晚上 我昨天晚上十二點睡覺 
選詞錯誤 努力學習是成功的鑰匙 努力學習是成功的關鍵 
漏詞錯誤 他是一能幹的律師 他是一位能幹的律師 
冗詞錯誤 他是很年輕 他很年輕 
在錯誤句子偵測與修正相關研究中，大部分研究對象仍著重於ESL所產生的錯誤句子，並
且不同研究所處理的錯誤類型也有所不同。在錯誤偵測研究中，Izumi等學者使用Maximum 
Entropy分類器來偵測輸入句中是否有選詞及漏詞錯誤[1]；Nagata等學者使用Decision List的方法
來處理分詞與單複數使用之錯誤偵測問題[2]；Sun等學者則將錯誤偵測視為二元分類的問題(即
有錯誤或沒有錯誤)，並使用SVM分類器進行錯誤偵測[3]。在錯誤修正研究中，Lee & Seneff學
者針對分詞、介系詞及動詞時態等文法錯誤進行修正，並提出「刪除並插入有限候選字詞法」
(Stripping and Insertion of Limited Candidates, SILC) [4]；此修正方法的程序為首先刪除掉分詞、
介係詞與助詞等特定詞類的可能錯誤字詞，接著插入這些詞類所允許的可能候選詞並且形成字
詞網格(Word Lattice)，然後使用 n-gram及 PCFG (Probabilistic Context-Free Grammar) [14]語言
模型來對網格中的各個路徑加以評分，具有最高分數之路徑即為修正句子。另一種修正方法則
是使用統計式機器翻譯系統[15], [16]，然而在[5]初步評估中，僅有與不可數名詞相關的錯誤才
被考慮進行修正。 
上述方法的限制可由以下三方面來說明。第一，上述方法僅針對英文特定詞類錯誤進行修
正，並未考慮中文學習者常發生的錯誤問題(如：詞序錯誤，請參考表3統計資料)；第二，在整
體架構上，上述方法係將錯誤句子的偵測與修正分開處理，也就是說錯誤偵測的部分並未處理
 3
2. 語言遷移錯誤語料：由於大量的錯誤語料不易取得，本計畫使用中英平行語料庫搭配一個簡
單的機器翻譯系統來模擬建立錯誤語料。錯誤語料模擬過程說明如下：首先，從這些平行語料
庫中訓練字詞及片語對應(Word and Phrase Alignment)資訊建立一個簡單的機器翻譯系統，接著
將平行語料庫的英文部分逐句翻譯成中文，可以預期的是這些機器翻譯的結果將含有許多錯
誤，稱之為模擬的錯誤語料( ERRΛ )，而平行語料庫的中文部分則稱之為參考語料( REFΛ )。這兩
部分語料可用於訓練二元分類器，以決定一個句子是否存在語言遷移錯誤，亦可提供有用的統
計資訊於錯誤修正階段使用。另外，我們從語言中心初步收集到150句CSL學習者產生的真實錯
誤語料(Real Data)做為實驗的測試資料，其錯誤類型分佈如表2所列，我們亦從模擬錯誤語料中
取等量的句子觀察其錯誤類型分佈並將結果列於表2。 
表2 模擬與真實錯誤語料之錯誤類型比例 
錯誤類型 模擬錯誤語料 真實錯誤語料 
詞序錯誤 36.2% 45.3% 
選詞錯誤 16.9% 40.0% 
漏詞錯誤 26.2% 24.7% 
冗詞錯誤 43.9% 25.3% 
錯誤偵測 (Error Detection): 
本計畫使用SVM分類器來判斷輸入句是否包含語言遷移錯誤。訓練語料即為模擬的錯誤語
料( ERRΛ )與正確的參考語料( REFΛ )，而訓練所採用的特徵包括：n-gram、PCFG、相對位置與剖
析範本，與修正模型所使用的相同(將於下節介紹)。 
錯誤修正 (Error Correction): 
錯誤句子修正的基本方法是先針對輸入句中不同錯誤類型產生可能的修正候選句，例如：
利用重新排序、重新選擇替代詞、刪除可能的冗詞及插回可能的漏詞等方法產生多個候選句，
最後進行句子流暢度評分挑選最佳候選句。因此，給定一個錯誤句E (可能含多種錯誤)，修正的
目標在獲取最佳的修正候選句，如下式所示。 
arg max ( ) arg max ( ) ( )
c c
C P C E P E C P C
∧ = =                   (1) 
其中 C 為一修正候選句；P(E|C)定義為修正模型，用以修正句中不同的錯誤類型並產生可能的
候選句；P(C)定義為語言模型，係使用大型正確中文句子語料(Λ)訓練所得，用以評估候選句C
之綜合流暢度分數，定義如下。 
1 2 3 4( ) ( ) ( ) ( ) ( )RPLM N Gram PTLM PCFGP C F C F C F C F Cλ λ λ λ−= + + +                     (2) 
其中 ( )N GramF C− 和 ( )PCFGF C 分別是由n-gram與PCFG語言模型加以計算； ( )RPLMF C  與 ( )PTLMF C
為本計畫所提之相對位置與剖析範本語言模型分數，而 iλ 為結合權重。修正模型P(E|C)是用來
修正輸入句中不同錯誤類型並產生可能的修正候選句，定義如下。 
 5
   
E   FD 
C
ROOT   
y  z x 
A B   
Domination Paths:  
x: ROOT　A　D 
 y: ROOT　B　E 
z: ROOT　B　C　F 
 
 Node Dominated By   
 A ROOT 
 B ROOT 
 C ROOT, B  
 D ROOT, A  
 E ROOT, B  
 F ROOT, B, C   
圖3、剖析樹之節點支配及其支配路徑。 
給定一個句子的剖析樹，則句中的每一個詞皆有其相對應的剖析範本，而此句的流暢度亦
可由每個詞的剖析範本在語料庫出現的機率來評估。然而，當剖析範本具有較多層的結構時，
其機率估算可能面臨資料稀疏的問題，因此，我們藉由估算其子樹(子範本)的機率來降低資料
稀疏造成的影響。因此，給定一詞 w，其對應的剖析範本 T 之機率可定義為 
1
( | )
( | )
d
i
i
p t w
p T w
d
==
∑
                                                     (6) 
其中 ti 為 T 的第 i 個子範本，而詞 w 的子範本 t 的機率可以下式加以估算 
( , )( | )
( )
count w tp t w
count w
=                                                       (7) 
其中 count(w, t) 為語料庫中 w 出現於 t 中的次數，而 count(w) 則為 w 出現於任何子範本中
的機率。因此，句子 C = w1w2…wn 的流暢度分數即可由句中所有詞所對應的剖析範本來計算，
定義如下 
1 2
1 1 1
1 1 ( | )( ) ( ) ( | )
jn n d
i i
PTLM PTLM n i i
i i j
p t wF C F w w w P T w
n n d= = =
= = =∑ ∑∑"                        (8) 
其中 Ti 為wi對應的剖析範本，而 jit  則為 Ti 的第 j 個子範本。 
2. 修正模型: P(E|C) 
(1) 詞序錯誤(Word Order) 
解決詞序錯誤的其中一種方法是為考慮句中所有可能的排序。不過這個方法在計算上並不
實用，因為一個具有 n 個字的句子就有 n! 個不同的排序，而以一個具有 10 個字的短句子來
說，就有 10! = 3,628,800 個排序，其數量過大並不實際可行。若能跟據句子結構的特性來產生
修正候選句，將可避免產生一些不合理的排序，有助於降低候選句數。因此，我們先對輸入句
進行剖析，並藉由剖析結果來產生可能的排序修正。 
剖析的結果讓我們可以使用較小的詞塊(Chunk)進行句子修正處理；修正步驟為沿著句子的
剖析樹由下而上，每一層僅對該層詞塊內的節點旋轉並產生修正候選句，並且往上一層時不同
 7
的字詞，其修正方法除了要找出最佳疑詞外，還必須重新選擇適當的候選詞替代之。 
疑詞所造成的前後文不匹配現象可由詞與詞之間的共現值(Co-occurrence)來衡量，定義如下 
1 2
1 2
1 2 1 2
( , | )( , | )
( | ) ( | ) ( , | )
count w wu w w
count w count w count w w
ΛΛ = Λ + Λ − Λ                     (10) 
其中 1 2( , | )u w w Λ 表示語料庫Λ中w1與w2的共現值； ( | )count w Λ 表示語料庫Λ中包含w的句數；
1 2( , | )count w w Λ 為語料庫Λ中w1與w2共同出現的句數。我們預期疑詞在一個正確的中文語料庫
中有較低的共現值，而在錯誤的語料庫中有較高的共現值；基於此種特性，我們可根據正確與
錯誤中文語料庫的共現值比值，做為選取候選句C = w1w2…wn中最佳疑詞 wj 的選詞/冗詞修正
模型，如式(11)所示。 
,
,
max ( , | )
( | )
max ( , | )
i j REFi j
reselect
i j ERRi j
u w w
P E C
u w w
Λ
= Λ                                          (11) 
其中 REFΛ 與 ERRΛ 分別表示一個正確與錯誤的中文句子語料庫。此式意義說明如下：對於冗
詞錯誤而言，疑詞通常發生於停用字(Stopword)，而在選詞錯誤，疑詞通常發生於內容字(Content 
Word)；因此，在選取冗詞錯誤的最佳疑詞時，我們首先計算句中每個停用字與其他字詞的共
現值，並且記錄其最大值，其中具有最小的最大共現值之停用字即為最佳疑詞(對式(11)取
argmin)，而此最佳疑詞(冗詞)將被刪除而產生一組冗詞錯誤修正候選句。圖5顯示了一個冗詞錯
誤的範例。在此句子中共有兩個停用字：”的”以及”被”。中文學習者在此例中不恰當地將所有
格分詞”的”在”然後”後面插入。在計算過上下文中這兩個停用字的最大共現值後，我們可以發
現”的”具有最小的最大共現值，因此該停用字即被選為在句子中的最佳疑詞(冗詞)。 
錯誤句子： [ 然後 的 事情 被 取消 ] 
 max u(的, w) = u(的, 事情) = 0.0012 ← best culprit: 的  
 max u(被, w) = u(被, 取消) = 0.0036  
正確句子： [ 然後 事情 被 取消 ]  
圖5、冗詞錯誤之範例句子 
同樣地，我們可依上述方法選取具有最小的最大共現值之內容字做為選詞錯誤的最佳疑
詞，接著便是重新選擇適當的候選詞來取代最佳疑詞。圖6顯示了一個含有選詞錯誤的錯誤句
子，其中”鑰匙”即為此句的最佳疑詞(正確詞應為”關鍵”)。 
錯誤句子：[努力(hard) 學習(studying) 是(is) 成功(success) 的(de) 鑰匙(key)] 。 
max u(努力, w) = u(努力, 的) = 0.0046 
max u(學習, w) = u(學習, 努力) = 0.0032 
max u(成功, w) = u(成功, 努力) = 0.0032 
max u(鑰匙, w) = u(鑰匙, 是) = 0.0001 ← best culprit: 鑰匙 
圖6、選詞錯誤之範例句子 
 9
( | , )( | )
( | , )
REF
ERR
V x Cx C
V x C
ω Λ= Λ                                                  (14) 
其中 REFΛ 與 ERRΛ 分別表示一個正確與錯誤的中文句子語料庫。此權重函數代表插入某候選停用
字，其在正確與錯誤語料庫之共現值的比值，因此，當輸入句包含漏詞錯誤時，插入較佳的停
用字將可獲得較大的權重，因為其在正確語料庫有較高的共現值，而在錯誤語料庫有較低的共
現值。結合式(12)與式(14)兩式可得選取最佳插入停用字之漏詞修正模型，定義如下。 
( | ) ( | ) ( | , )insertionP E C x C V x Cω= × Λ                                         (15) 
其中能夠最大化此修正模型之停用字即為最佳候選停用字。為了簡單起見，我們只允許插入一
個候選停用字於句子中。 
找出候選的插入字詞後，我們仍需決定其在句子中的最佳插入位置，欲達成此一目標可藉
由比較插入句中不同位置的n-gram分數來決定。給定一個候選停用字及句子C = w1w2…wn ，需
要考慮的插入位置由 0 (在 w1 前插入) 開始到 n+1 (在 wn 後插入) 為止，對於每一個插入位
置 i (也就是介於 wi 和 wi+1 間的位置)，我們考慮五個字範圍內之字串的 n-gram 值，因此最
佳的插入位置為 
1 2 1arg max ( )N Gram n
i
i F w w w− += …                                             (16) 
為了確保在句子插入停用字後能改進分數，我們也加入了下列條件：只有當插入停用字後句子
的 n-gram 分數較原句子提高的情況下，才會考慮插入此候選的修正字詞。 
三、結果與討論 
在實驗中，本計畫使用表2所列之150句真實錯誤語料(Real Data)做為測試集。在錯誤句子
偵測上，我們使用SVM分類器，所採用的特徵則為本計畫所提出以及使用的各種不同的語言模
型數值(N-gram、PTLM、RPLM)。以10-fold交互驗證法加以檢驗，所得出的錯誤偵測正確率為
96.7%。在錯誤句子修正上，我們根據先前所提出的兩種語言模型（RPLM與PTLM）理論加以
實作，並且與原有的兩種語言模型（N-gram與PCFG）進行比較。所得的比較結果如表3所示。 
表3 不同語言模型之平均最大 BLEU 數值 TOP-N 列表 
INPUT (AV.: 0.603) RPLM N-GRAM PTLM PCFG 
Top 1 0.503 0.492 0.483 0.457 
Top 5 0.680 0.703 0.653 0.680 
Top 10 0.750 0.771 0.730 0.754 
Top 20 0.802 0.828 0.783 0.813 
 
實驗結果顯示，在以字詞位置作為基礎的語言模型中，可以看出本計畫所提出的 RPLM
較 N-gram 在 Top-1 中得出較好的結果，表示 RPLM 語言模型在判斷較高名次的 Top-N 候選
句子時具有較高的鑑別度，而傳統的 N-gram 在判斷 Top-5 至 Top-20 的候選句子時也有不錯
的效果。在以句子結構作為基礎的語言模型中，可以看出 PTLM 亦較 PCFG 在 Top-1 中得
出較好的結果，表示所提出的 PTLM 語言模型在判斷較高名次的 Top-N 候選句子時也具有
 11
參考文獻 
[1] E. Izumi, K. Uchimoto, T. Saiga, T. Supnithi, and H. Isahara, "Automatic Error Detection in the 
Japanese Learners' English Spoken Data," in Proc. of ACL, pages 145-148, Sapporo, Japan, 2003. 
[2] R. Nagata, A. Kawai, K. Morihiro, and N. Isu, "A Feedback-Augmented Method for Detecting 
Errors in the Writing of Learners of English," in Proc. of COLING/ACL-06, pages 241-248, 
Sydney, Australia, 2006. 
[3] G. Sun, X. Liu, G. Cong, M. Zhou, Z. Xiong, J. Lee, and C. Y. Lin, "Detecting Erroneous Sentences 
using Automatically Mined Sequential Patterns," in Proc. of ACL-07, pages 81-88, Prague, Czech 
Republic, 2007. 
[4] J. Lee and S. Seneff, "Automatic Grammar Correction for Second-Language Learners," in Proc. of 
ICSLP, pages 1978-1981, Pittsburgh, PA, 2006. 
[5] C. Brockett, W. B. Dolan, and M. Gamon, "Correcting ESL Errors Using Phrasal SMT 
Techniques," in Proc. of COLING/ACL-06, pages 249-256, Sydney, Australia, 2006. 
[6] J. Y. Jian, Y. C. Chang, and J. S. Chang, “TANGO: Bilingual Collocational Concordancer,” in Proc.
of ACL-04, Barcelona, Spain, 2004. 
[7] J. C. Wu, K. C. Yeh, T. C. Chuang, W. C. Shei, and J. S. Chang, “TotalRecall: A Bilingual 
Concordance for Computer Assisted Translation and Language Learning,” in Proc. of ACL-03, 
pages 201-204, Sapporo, Japan, 2003. 
[8] J. S. Liu, P. C Hung, and C. Y. Lee, “Corporal Sentence Retrieval for English Writing Assistance,” 
in Proc. of ROCLING-07, pages 5-19, 2007. 
[9] 陳佳吟，柯明憲，吳紫葦，張俊盛，“FAST：電腦輔助英文文法出題系統，” in Proc. of 
ROCLING-05, 2005. 
[10] 楊媛茜，楊捷扉，張嘉銘，張俊盛，“電腦輔助閱讀測驗自動出題，” in Proc. of ROCLING-05, 
2005. 
[11] C. L. Liu, C. H. Wang, and Z. M. Gao, “Using Lexical Constraints to Enhance the Quality of 
Computer-Generated Multiple-Choice Cloze Items,” International Journal of Computational 
Linguistics and Chinese Language Processing, vol. 10, no. 3, pp. 303-328, 2005. 
[12] M. S. Lu, Y. C. Wang, J. H. Lin, C. L. Liu, Z. M. Gao, and C. Y. Chang, "Supporting the Translation 
and Authoring of Test Items with Techniques of Natural Language Processing, Journal of Advanced 
Computational Intelligence and Intelligent Informatics, vol. 12, no. 3, pp. 234–242, 2008. 
[13] 蔡明峰，廖元甫. “電腦輔助語言學習，” ACLCLP Newsletter, vol. 19, no. 1, pp. 7-16, 2008. 
[14] D. Jurafsky, J. H. Martin, A. Kehler, K. Vander Linden, and N. Ward, Speech and Language 
Processing: An Introduction to Natural Language Processing, Computational Linguistics, and 
Speech Recognition, MIT Press, 2000. 
[15] S. Corston-Oliver, M. Gamon, and C. Brockett, "A Machine Learning Approach to the Automatic 
Evaluation of Machine Translation," in Proc. of ACL-01, pages 148-155, Toulouse, France, 2001. 
[16] P. Koehn, F. J. Och, and D. Marcu, "Statistical Phrase-based Translation," in Proc. of 
NAACL-HLT-03, pages 48-54, Edmonton, Canada, 2003. 
 
表 Y04 
二、與會心得 
本次論文安排在八月四日中午 12:30~14:00 以海報形式發表。過程中主要針對本論文所提
之方法與國際學者交換心得，並獲得相當寶貴意見；另有學者詢問資料特性與實際應用等問
題，本人均已詳細解釋。透過此次交流，本人在研究方法上獲得其他學者在不同層面的看法，
可做為日後繼續從事相關研究之參考，亦可在多場演講中獲得最新研究趨勢，瞭解相關領域學
者之研究，增進研究能量。 
三、建議 
建議主管機關與學校多補助與鼓勵國內學者出席國際研討會，此外，積極爭取國際研討會
在國內舉辦亦是國際交流的重要管道之一，此舉可讓國際學者進一步瞭解國內相關研究現況，
提高國內研究之能見度，亦有助於未來深化合作關係，共同發表研究成果。 
四、攜回資料名稱及內容 
1. 論文集光碟乙片 
2. 大會手冊乙份 
無衍生研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
