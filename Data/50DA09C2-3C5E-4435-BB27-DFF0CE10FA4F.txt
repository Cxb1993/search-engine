2is 0.12 m.
Keywords: LIDAR, aerial image,
building detection, building
reconstruction, building model
二、前言與研究目的
數碼城市是都市規劃、建設及管理之
未來重要發展方向，具有虛擬但反應真
實、數位化、多維且架構於網際網路的環
境等特性。其應用層面非常廣泛。如可用
作都市規劃、區域環境規劃 [Danahy,
1999]、虛擬實境[Volz and Klinec, 1999]及
變遷偵測[Mukurami et al., 1999]等用途。
數碼城市中所需的空間資訊就靜態而言
主要在於建置立體的模型，而三維之房屋
模型是不可或缺的部分。
建物模型重建包含建物區塊偵測以
及建物模型重建兩大部分，建物模型重建
又包含建物外圍輪廓線偵測以及建物頂
結構分析兩步驟。二維向量圖具有明確建
物輪廓線，可省去建物區塊偵測及建物輪
廓線偵測之步驟，但有時會因缺漏或變遷
問題而無法使用。
本研究利用航照中之光譜資訊以及
邊緣線資訊，作為光達資料的輔助。以航
照中之光譜資訊，輔助光達資料進行房屋
區塊偵測。融合光達資料中之高程資訊及
航照影像中之邊緣線資訊，進行建物模型
重建，達到資料融合的目的。在偵測建物
外圍輪廓時，加入圓弧偵測機制，進行直
線與圓弧輪廓的建物模型重建，並且對於
屋頂為斜面的建物，也具有重建的能力，
期能提高房屋模型外型之多元性。此處所
指之輪廓為建物邊緣在水平投影方向上
之外型。測試將以可靠度及精度作為主要
考量。
三、主要研究流程
本研究流程包括三個部分，第一部分
為資料前處理，包括光達資料以及航照資
料。第二部分為建物區塊偵測，融合兩種
資料的特性，找出影像上及光達資料中，
屬於建物的部分。第三部分為建物模型重
建，在航照影像上偵測建物輪廓以
(building boundary)及階梯線(step edge)，
透過光達資料共面分析求取屋脊線(ridge
line)，最後模塑產生三維建物模型。流程
如圖 1，並詳述各步驟內容。
四、資料前處理和建物區塊偵測
在進行建物區塊偵測之前，需要將光
達點雲以及航照影像經過前處理，以得到
所需的資料。在光達資料的部分，須先將
光達資料網格化。在航照影像部分，需將
影像正射化，得到正射化影像，並計算紋
理得到紋理影像，以及分類得到分類影
像。
建物區塊偵測的目的是為了得到航
照影像以及光達資料中，屬於建物的部
分。將這四層資料套疊進行區塊分割，之
後設定條件，給予權重，利用知識庫分類
的方式，依區塊之高度資訊、光譜資訊及
紋理資訊，以區塊為單位，將區塊分類成
建物以及非建物區塊。接著將建物區塊進
行面積分析，去除面積過小的區塊，利用
形狀分析，去除過於狹長的區塊，最後運
用建築物屋頂結構多以平面組成之特
性，分析區塊表面粗糙度，去除表面過於
粗糙的區塊，最後得到建物區塊。建物區
塊偵測之研究流程如圖 2。
五、建物模型重建
建物模型重建包括外圍輪廓線偵
測、階梯線偵測及屋脊線求取，主要工作
主要有四個部分，分別為(1)建物牆面輪廓
分析、(2)建物頂共面分析、(3)求取建物結
4點資料點密度大約為 2.15 點/m2。航照影
像資料空間解析力為 50 cm。
光達原始點雲經過人工編修為地表
點及地面點，分別網格化成 0.5 m 解析之
DSM與 DTM，如圖 9(a)。航照資料部分，
利用 DSM將航照正射化為 0.5 m 解析力
之正射化影像，如圖 9(b)。在建物區塊偵
測的部分，建物總數為 23 棟，偵測所得
到之建物共有 21 棟，遺漏 2 棟，成功率
為 91%。建物區塊和二維向量圖套疊之後
如圖 9(c)。
建物模型重建的部分，將針對建物區
塊內的 21 棟建物進行建物模型重建。在
測試區中的建物，依其輪廓及屋頂形狀將
建物分類。由於此測區中，圓弧輪廓建物
皆屬於平頂屋，因此可將建物分為三類：
外圍輪廓含有圓弧輪廓之建物，共有 3
棟。而在無圓弧輪廓建物中，將建物以屋
頂形狀分類，平頂屋為一個或多個水平屋
頂之建物，共有 11 棟，山型屋為屋頂包
含斜面構造，具有屋脊線之建物，共有 7
棟。
在重建成果部分，將正確率分為三
種：正確、部分正確、以及錯誤。正確為
建物模型與建物一致，部分正確為建物輪
廓不正確或有部分遺漏，或因建物頂突出
物重建不完整者。重建失敗表示該建物無
法重建。全區建物模型重建如圖 10。將重
建成果整理如表 1。
在建物輪廓精度評估部分，針對測試
區內重建正確及部分正確之建物模型
中，以人工於空照立體對中量測且重建完
成之建物模型為地真資料，進行輪廓精度
評估。以建物模型之屋角點與地真資料之
屋角點間之平面座標差，計算均方根誤
差。其均方根誤差在 X、Y 方向分別為
0.71、0.73公尺。誤差向量圖如圖 11。
在模型精度評估部分，本研究不探討
光達取樣時之誤差，而只探討模塑出來的
模型跟光達點雲之間之差異，故以模塑誤
差(shaping error)進行精度評估。計算方法
為每屋頂面光達點雲先剔除粗差，剩餘點
雲再與產生的建物模型計算平均的垂距
殘差量，當作模塑誤差。本研究針對正確
和部份正確建物計算模塑誤差。整體模塑
誤差為 0.12m，範圍約 0.06m~0.33m，與
光達資料高程精度為 0.15m相符合。
七、結論
本研究以資訊融合為概念，提出完整
之程序，結合光達資料及單張數位航照影
像進行建物區塊偵測及直線及圓弧輪廓
建物模型重建。從研究成果觀察，本法具
有自動化之潛力。
建物區塊偵測之成果經由和一千分
之一向量圖套疊分析之後，偵測成功率約
為 91%。重建之模型成果以其輪廓及屋頂
結構進行成功率判斷，76%之建物在輪廓
以及屋頂形狀皆為正確，14%之建物在輪
廓或屋頂突出物部分與真實情況不完全
相符合，10%之建物因遭到樹木遮蔽，無
法進行重建。建物輪廓部分均方根誤差在
X方向為 0.73 m，Y方向為 0.71 m。模塑
誤差為 0.12 m。
由研究成果顯示，切片法在牆面輪廓
分析時，可以得到一封閉的概略建物輪
廓，並且能夠偵測建物建物頂階梯線的部
分，相較於以邊界偵測的方法，較不易受
屋頂雜訊所干擾。
在建物頂共面分析部分，改以三角形
重心垂距作為區塊成長時判斷的依據，相
較於以法向量夾角作為區塊成長之條件
的方法，在門檻值的設定上，對於建物頂
的雜訊干擾較不敏感。
在圓弧及直線分析部分，本研究之圓
弧偵測為二維處理，可降低複雜度並縮短
6圖 1 本研究流程圖
圖 2 建物區塊偵測流程圖
光達資料 航照資料
資料前處理
建物區塊偵測
切片法
階梯線
概略建物外圍輪廓
建立封閉多邊形
圓弧及直線偵測圓弧及直線偵測
內部階梯線輪廓
精確建物外圍輪廓
求取建物屋脊線
建物模塑
建物模型
像/物空間轉換 像/物空間轉換
階梯線
航照資料
資料前處理
影像分割
建物區塊
非建物區塊
面積分析
形狀分析
物件影像
表面粗糙度分析
建物候選區
高程資訊
光譜資訊
紋理資訊
光達資料
8圖 10 建物模型重建成果
圖 11 誤差向量圖
表 1 重建成果
重建成果 平頂屋 山型屋 圓弧輪廓建物 正確率
正確 9 5 2 76%
部分正確 2 0 1 14%
遺漏 0 2 0 10%
1出席國際學術會議心得報告
計畫編號 NSC 94-2211-E-008-028
計畫名稱
數碼城市中空間資訊獲取、分析、整合及視覺化研究--子計畫
一：整合空載多元探測技術及空間資料重建都市之人工建物及
植被覆蓋模型(I)
出國人員姓名
服務機關及職稱
陳良健 國立中央大學太空及遙測研究中心 教授
會議時間地點 2005 年 11 月 7 日至 11 月 11 日 越南河內
會議名稱 第二十六屆亞洲遙測會議
發表論文題目 Fusion of LIDAR Point Clouds and Large Scale VectorMaps for the Reconstruction of 3-D Road Models
一、背景
亞洲遙測會議(ACRS, Asian Conference on Remote Sensing)自
1980 年於曼谷舉辦首屆以來每年均舉行一次。本次會議為第二十六
屆，主辦單位為越南之大地測量，製圖及遙測學會(Vietnam Association
of Geodesy, Cartography and Remote Sensing)及亞洲遙測學會(AARS,
Asian Association on Remote Sensing)。舉行地點為河內之 Melia 飯
店，時間為本(2005)年 11 月 7 日至 11 月 11 日。開幕式由越南環境資
源部副部長 Dr. Dang Hung Vo 與亞洲遙測學會秘書長 Prof. Shunji
Murai 主持。此次會議與第二屆亞洲太空所研討會(The 2nd Asian Space
Conference)聯合舉行。
二、參加會議經過
本次會議共有 37 國家的 628 名與會者，其中越南佔 248 人。論
文總數 407 篇，安排於 49 個場次，其中口頭發表(Oral)有 46 個場次
的 245 篇論文，餘為海報(Poster)展示。論文主題包括(1)Forestry，(2)
Tsunami，(3)Remote Sensing & GIS Integration，(4)Coastal Zone，
(5)Disasters，(6)Water Resources，(7)Agriculture & Crops，(8) Land
Use/Land Cover，(9)RiceSat，(10)GIS Decision Support and Models，
(11)Strengthening International Partnership for Education ，
Fusion of LIDAR Point Clouds and Large Scale Vector Maps  
for the Reconstruction of 3-D Road Models 
 
Liang-Chien Chen1, Chao-Yuan Lo2, Yi-Chen Shao3, Tee-Ann Teo4 
Professor1, Student2, Student3, Student4 
Center for Space and Remote Sensing Research 
National Central University, Chung-Li, TAIWAN 
lcchen@csrsr.ncu.edu.tw; 93322077@cc.ncu.edu.tw; ycshao@csrsr.ncu.edu.tw; ann@csrsr.ncu.edu.tw 
 
Abstract: To describe the environment of a cyber city in detail, 3-D road models are necessary. Due to the diversity of the road types, 
traditional 2-D vector maps are insufficient to represent 3-D road models when multi-layer road systems are considered. The 
reconstruction of 3-D road models, thus, becomes an important task in the geoinformatic area. The LIDAR data contains the height 
information of the road surface. The vector maps record the accurate road boundaries. Thus, we fuse LIDAR point clouds and large 
scale vector maps to reconstruct the 3-D road models. The proposed scheme comprises two major parts: establishment of 2-D road 
networks and 3-D road modeling. In the first one, the roadsides of the vector maps are split and merged for the determination of road 
centerlines and the formation of networks. In the second one, the heights of the road centerlines are derived from LIDAR data to 
represent the road surface. The profiles of the 3-D roads are obtained by the constraints of slope and slope difference. Then, the road 
fragments are organized into road models as ribbons. The test data covers Hsin-Chu city in the north of Taiwan. The point density of 
LIDAR data is 1.78 points/m2. The scale of the vector map is 1:1,000. The experimental results show that the successful rate of the 
automatic reconstruction for 2-D road network is 81.6%. After the enhancement of the planimetric road networks by manual editing, 
the reconstructed 3-D road models reach a modeling accuracy better than 0.10m. 
Keywords: LIDAR Data, Large Scale Vector Maps, 2-D Road Network, 3-D Road Model, Reconstruction. 
 
 
1. Introduction 
 
Considering the different functionalities, road types include highways, arterial roads, local streets, etc. Traditional 2-D 
vector maps are insufficient to represent the 3-D road system when a viaduct crosses other streets. The 3-D road models 
are, thus, needed for describing the multiple layers of a road system. Hence, the reconstruction of 3-D road models 
becomes an important task in geoinformatic realm. 
 
A number of researches have been reported to reconstruct the 2-D road networks or 3-D road models [1], [2], [3], [4], 
[5]. Most of them are based on the viewpoint of data fusion of planimetric geodata, LIDAR point clouds, and remote 
sensing images. The geodata provides the planimetric geometry of roads. The LIDAR point clouds contain the 
information of elevation and intensity of roads. The high resolution imagery has its unique characteristics for roads in the 
geometry and spectrum. According to the geodata, the roads can be detected and identified from imagery for updating the 
database. Zhang [1] updates the 2-D road networks with stereo aerial images and LIDAR point clouds. It assumes that a 
road is composed of edge pairs with similar geometry. If one edge is occluded but the other isn’t, the lost one can be 
filled up by the existing one to update the road network. Hu [2] reconstructs the road networks by fusion of LIDAR point 
clouds and high resolution imagery. The road candidates are segmented by the intensity and height information from 
LIDAR point clouds. Then the points in the non-road sites are filtered out by the spectral information of the image. A 
modified Hough transform method is used to detect the roads from the segmented LIDAR data and to reconstruct the 
road networks. 
 
A number of approaches are possible to represent 3-D road models. Clode et al. [3] extracts the height information of 
road surface through the constraints of height differences and intensity of LIDAR data. Hatger et al. [4] integrates the 
centerlines from databases and the LIDAR data to extract the road sides and to build the geometry of the 3-D road 
profiles. Then the road can be represented as a parametric model. Kada et al., [5] computes the geometry of profiles from 
LIDAR point clouds along the centerlines to reconstruct the 3-D road models. 
 
This investigation integrates large scale vector maps with polylines that represent street block boundaries and LIDAR 
point clouds to reconstruct the 3-D road models. Because the large scale vector maps used in this investigation record the 
boundaries of street blocks instead of centerlines, the road centerlines need to be derived by the block boundaries. Then 
we can compute the heights of the road surface form LIDAR point clouds along those centerlines. There are three main 
steps in our investigation: (1) determination of the road centerlines, (2) extraction of the road surface points from LIDAR 
 
(a)                                       (b)                               (c) 
Fig. 2. The processes of roadside pairing (crossroads) 
(a) the raw data; (b) the split process; (c) the merged process 
 
2) Road Networking 
 
The piecewise centerlines are insufficient to describe a road network and, thus, are needed to be connected together. 
We define a road centerline with three features: (1) a centerline is composed by two points named nodes at the start and 
the end, (2) each vertex between nodes records the road width, and (3) a node is generated by the intersection of two 
centerlines for the crossroads or the sharp turns. 
 
A merging procedure forms a network with road centerlines. If the angle difference between two centerlines is less 
than an angle threshold (θ3), the centerlines are merged. An example is illustrated in figure 3a. As shown in figure 3b, if 
there is a centerline passing over another one, it is needed to be differentiated by a crossroads or an overpass. As figure 
4a shows, a crossroads in the original maps has no road boundary passing the crossroads, but a viaduct does (figure 4b). 
Then, we can confirm this site using the label. If the intersection is a crossroads, we add a node to separate those two 
centerlines to four segments (figure 3c). Notice that there will be still two centerlines without a node when a viaduct 
exists. 
 
 
(a)        (b)     (c) 
Fig. 3. The processes of road network connection (crossroads) 
(a) before linking; (b) after linking; (c) create a node at the intersection 
 
 
(a)       (b) 
Fig. 4. The intersection (a) a crossroads; (b) a viaduct 
 
 
 
 
 
θ3 
θ2 
distance 
θ1 
       
(a)                                      (b)                     (c) 
Fig. 6. The split polylines of the road boundaries 
 (a) original roadsides; (b) local streets; (c) highway 
 
After splitting polylines, the line segments are merged into the same roadsides then to determine their centerlines. The 
thresholds of the angle and the distance are 4 ∘ and 50m, respectively. The distance threshold between the pair of 
roadsides ranges from 3m to 25m. The range threshold is based on the cross section of roadway design. The centerlines 
are connected with an angle threshold of 10 ∘. Then, the polylines of streets and highway are reduced to 387 and 13 
polylines, respectively. The merged results are shown in figure 7a and 7b. 
 
    
(a)                     (b) 
Fig. 7. The merged polylines of the roadsides (a) local streets; (b) highway 
 
The results of automatic reconstruction for the 2-D road network contain some errors such as missing, broken, or 
redundant roadsides. One hundred and thirty three out of one hundred sixty three roads segments are successfully 
reconstructed. The successful rate is, thus, 81.6%. The automation of these processes is shown in figure 8a. After further 
removing the outliers through manual editing, we produce the complete set of the planimetric road networks as shown in 
figure 8b. 
 
  
(a)                            (b) 
Fig. 10. The 3-D road models (a) a perspective view; (b) a close view 
 
For the accuracy assessment of the extraction points on road surface, we filter out the non-road points manually and 
reconstruct the 3-D road models as a reference data set. The RMSE of Z component of the reconstructed road models is 
0.10m. The histogram of the discrepancies is shown in figure 11. 
 
RMSE-Z
0
0.2
0.4
0.6
0.8
1
1.2
0 100 200 300 400 500 600 700 800 900 1000 1100
Station(m)
RM
SE
(m
)
RMSE-Z
 
Fig. 11. The histogram of the estimation 
 
5. Conclusions 
 
A scheme is proposed for the formation of the 2-D road network from the large-scale line maps and the 3-D road 
model reconstruction by incorporating of LIDAR data. The successful rate of the reconstruction of road centerlines is 
81.6% for the test area. The RMSE of Z component of the extraction road points is 0.10m. The experimental results show 
the promising potential of the proposed scheme. This paper reports the preliminary results. Further investigation 
regarding the inclusion of better filtering technique and surface fitting procedure is suggested. 
 
Acknowledgement 
 
This research is funded by the NSC project 94-2212-E-008-029. And the LIDAR data and large scale vector maps are 
supported by Council of Agriculture and China Engineering Consultants, Inc., respectively. 
 
 
1出席國際學術會議心得報告
計畫編號
NSC 94-2211-E-008-028
NSC 95-2221-E-008-103-MY2
計畫名稱
數碼城市中空間資訊獲取、分析、整合及視覺化研究--子計畫
一：整合空載多元探測技術及空間資料重建都市之人工建物及
植被覆蓋模型(I)
數碼城市中空間資訊獲取、分析、整合及視覺化研究－子計畫
一：整合空載多元探測技術及空間資料重建都市之人工建物及
植被覆蓋模型
出國人員姓名
服務機關及職稱
陳良健 國立中央大學太空及遙測研究中心 教授
會議時間地點 2006 年 10 月 9 日至 10 月 13 日 蒙古-烏蘭巴托
會議名稱 第二十七屆亞洲遙測會議
發表論文題目 Building modeling by the integration of multi-sourcedata
一、背景
亞洲遙測會議(ACRS, Asian Conference on Remote Sensing)自
1980 年於曼谷舉辦首屆以來每年均舉行一次。本次會議為第二十七
屆，主辦單位為蒙古之航測及遙測學會 (The Mongolian Society for
Photogrammetry and Remote Sensing) 及亞洲遙測學會 (AARS, Asian
Association on Remote Sensing)。舉行地點為烏蘭巴托之 Chinggis 飯
店，時間為本(2006)年 10 月 9 日至 10 月 13 日。開幕式由蒙古教育
文化及科技部部長 Dr. Oe Enkhtuvshin 與亞洲遙測學會秘書長 Prof.
Shunji Murai 主持。
二、參加會議經過
本次會議共有 22 國家的 389 名與會者，其中來自台灣的成員數
為 83，僅次於日本的 90。論文總數 294 篇，安排於 40 個場次，其中
口頭發表(Oral)有 36 個場次的 168 篇論文，餘為海報(Poster)展示。
論文主題包括：(1) Agriculture，(2)Diaster，(3) GIS，(4)Forestry，
(5) Data Processing ， (6)Urban ， (7)Mapping ， (8)SAR ，
BUILDING MODELING BY THE 
INTEGRATION OF MULTI-SOURCE DATA 
 
Liang-Chien Chen1, Tang-Yu Li2, Tee-Ann Teo3 
1Professor, 2Msc Student, 3PhD Candidate 
Center for Space and Remote Sensing Research, 
National Central University, Taiwan 
E-mail: lcchen@csrsr.ncu.edu.tw; 943202068@cc.ncu.edu.tw; ann@csrsr.ncu.edu.tw 
 
 
KEY WORDS: Building Model, LIDAR Data, Aerial Images, 2-D map, Reconstruction. 
 
ABSTRACT: Due to the complexity and variety of the building types, using single data to 
automatically generate building models could yield unreliable results. Therefore the trend is to 
fuse multi-source data to achieve the automation. This research, thus, considers the integration 
of LIDAR data, aerial images, and 2-D maps to perform the modeling. The proposed scheme 
comprises three major steps: (1) data preprocessing, (2) classification of roof types, and (3) 
building modeling. In the first step, we enclose the polylines of the maps then extract the point 
clouds that belong to a building. Through the roof hypothesis by employing point clouds, the 
camber roofs are parameterized. For non-camber roofs, we determine the ridges of gable roofs 
by interesting the two inclined planes. The step-edges are obtained by combining point clouds 
and image features. Finally, we shape the models by SMS method. The result of classification 
shows that different kinds of roofs can be correctly categorized. Buildings are successfully 
reconstructed by the proposed approach. 
 
1. INTRODUCTION 
 
In response to the development of 3-D city spatial information for urban planning and 
management, the establishment of cyber city is getting important. Cyber city is an epitome of  
the real world. It stores and reconstructs the information of real world in the system. The 
information provides valuable decision support to city managers. The applications of the cyber 
city are significant, such as urban planning (Mannan and Juergen, 2004), environmental 
planning, change detection (Habib et al., 2005), and disaster risk management, etc. 
 
Building models is one of the most important parts in a cyber city. Building reconstruction could 
be accomplished by two strategies, i.e., fully automatic approach and semi-automatic approach. 
Fully automation is always an ultimate goal in building reconstruction. However, it is difficult to 
achieve fully automatic interpretation. Thus, many application projects adopt semi-automatic 
method in the model production. 
 
Building models may be reconstructed by different approaches such as using aerial photography 
which picks up the model and modulates the parameters by manual operation then shaping by 
CSG method (Tseng and Wang, 2003). It might also be restricted to the simple shape by 
polyhedral models (Taillandier, 2005). Some combined aerial images with maps to locate the 
working area and generate building hypotheses then fitting by CSG models (Suveg and 
Vosselman, 2004). Since LIDAR (light detecting and ranging) has plentiful 3-D information, it 
has demonstrated profound potentials in automatic building reconstruction. In the past 
researches, many reports used LIDAR data to reconstruct building models such as projecting 
point clouds in 2-D space to analyze the 3-D plane (Schwalbe et al., 2005). Some integrate 
cadastral data to analyze the relation between 3-D planes then reconstruct by B-rep model 
3. CLASSIFICATION OF ROOF TYPES 
 
Priori to the building shaping, we categorize the roof types by using the point clouds. Once the 
most likely roof type of a building is determined, the surface function can be assured by fitting 
the point clouds. To better represent the surface, the point clouds need to be filtered. 
 
3.1 Point Cloud Filtering 
 
Considering the possible registration errors between LIDAR data and vector maps, the point 
clouds in a building polygon would include roof and ground points. A less number of points may 
also come from building walls. To obtain the points that solely belong to the roofs, we design a 
three-step processing for the filtering of unwanted points. In the first step, a clustering technique 
is employed to exclude non-roof points. Notice that the roof points should be the majority. In the 
next step, we eliminate the points that are deviated from the distribution with two standard 
deviations. That means we consider 95% confidence interval. Finally, the points that form 
over-steep facets are excluded. This step is dedicated to the exclusion of wall points. In the 
processing, TIN (triangulated irregular networks) structure is employed. 
 
3.2 Surface Fitting 
 
The shaping of the roofs deals with the determination of surface function for each roof primitive. 
We consider three types of the roofs in this investigation, namely, camber, flat, and gable. The 
roof structures are determined by the test of the most likelihood of the surfaces. For the camber 
roofs that have been assured by employing a sphere or a cylinder equation, the model may be 
reconstructed by the feature parameters. For those that do not belong to the camber roofs will be 
tested for the flat or gable roofs. To better delineate the roof details, each building area are split 
by the consideration of shape symmetry. A rectangle, for instance, in the Fig. 2 (a) is divided by 
two parts according to the first and second axes. Thus, the two possibilities in Fig. 2 (b) and 
Fif.2 (c) are tested for the selection of the most likely one. In the determination, each part of A, 
B, C, and D is fitted with a plane. The one with the least fitting error are considered as the 
suitable roof. 
 
 
Figure 2 Splitting the building boundary 
(a) Original roof polygon, (b) Divided by axis1, (c) Divided by axis2 
 
4. BUILDING MODELING 
 
Polyhedral models or parameter ones are considered in this investigation. For camber roofs, the 
parameter models are selected. The feature parameters are determined in the point cloud fitting 
procedure. For flat and gable roofs, the interior structure lines need to be determined. We detect 
image edges within the building polygons. The polygons in the image space are projected by 
employing the building blocks estimated from the DSM. Hough transform is integrated to select 
the major structure lines. We then project the structure lines to the object space to generate three 
dimensional building edges. After a geometric regularization, the building models are generated 
by employing SMS method. The details are given in Chen et al (2006). 
(c) (b) (a) 
For the determination of building types, we test seven polygons. Notice that building A has four 
parts, namely A1, A2, A3, and A4. As shown in Fig. 3, the remaining three are given as B, C, 
and D. The fitting procedure is employed to each polygon that is divided into four parts, as 
indicated in Fig. 2. As shown in Tab.2, the fitting results indicate that parts A1, A2, A3, A4, and 
B fulfill the condition of flat roof. That means the fitting for a plane is more likely than a sphere. 
In addition, no significant difference is detected between two orthogonal directions. On the other 
hand, roof C satisfies the gable building, because two parts in one direction has better fit for a 
plane than its orthogonal counterparts. The roof D is better fitted as a sphere than a plane by the 
indication of fitting error. The results reveal the soundness of the proposed method. 
 
Table 2 Result of surface fitting            (Unit:meter) 
 Roof A1 Roof A2 
Plane 0.090  0.078  0.082  0.086  0.060  0.054  0.072  0.053  
Sphere 0.457  1.011  0.885  1.036  0.243  0.292  0.101  0.167  
  Roof A3 Roof A4 
Plane 0.070  0.032  0.040  0.073  0.233 0.147 0.055 0.194 
Sphere 0.359  0.095  0.077  0.144  0.461 0.976 1.177  0.256  
  Roof B Roof C 
Plane 0.502  0.405  0.542  0.348  0.330  0.310  0.034  0.040  
Sphere 8.014  3.189  7.005  3.104  0.197  0.256  0.127  0.273  
  Roof D     
Plane 1.333  1.261  1.208  1.221      
Sphere 0.135  0.127  0.134  0.129      
 
Fig. 5 shows the result of modeling in each roof types. In each type, the right part is building 
model. As shown in Fig. 5 (a) and Fig. 5 (b), the left parts depict the topology of the building 
boundaries superimposed with the point clouds from LIDAR. Fig. 5 (c) indicates the ridge be 
intersection of two adjacent planar faces. And Fig. 5 (d) depicts the camber roof in polyhedral 
structure. Notice that the model-based parameters have been transformed to the polyhedral ones 
for the unified presentation with others. 
 
  
(a) (b) 
  
(c) (d) 
Figure 5 Result of building models 
(a) Flat roof, (b) Flat roof with annex structure, (c) Gable roof, (d) Camber roof 
 
6. CONCLUSIONS 
 
We have presented a scheme for the roof classification and building modeling by the fusion of 
LIDAR data, aerial images and vector maps. The results from the experiment show the potential 
of the proposed method. Each building type could be classified and reconstructed successfully 
by the proposed approach.  
