is a good model, but it is not always superior to 
computer systems for all the tasks, especially for 
analyzing large amount of image data and recording 
image in high fidelity. Therefore, we will not try to 
duplicate and copy the behavior and working model of 
human vision system, but will try to integrate recent 
research technologies in computer vision, machine 
learning, data mining, and computer graphics to be a 
complement with Sub-Project 1, Silicon Brain. We 
believe the combination of these two projects would 
achieve a powerful intelligent system like the 
combination of human’s left brain and right brain. 
 
There are two main targets in this project: multi-
core stream processor for intelligent video 
processing and multi-core universal graphics 
processing unit. The first one can support the 
acceleration of recognition and data mining 
operations. The result will be useful for many 
intelligent video systems, such as video surveillance 
systems and intelligent vehicle systems. The second 
one can support the operations of image synthesis. It 
can be employed in many applications, such as gaming 
and man-machine-interface. We may also try to develop 
an integrated system with these two proposed 
processors to further support synthesis based 
video/image recognition, which will be our future 
research direction. 
 
英文關鍵詞： stream processor, reconfigurable processor, multi-
core processor, recognition, data mining, image 
synthesis, graphics processing unit, computer 
graphics, computer vision, and machine learning 
 
 2 
摘要 
 
在單晶片的電晶體的整合程度達到兆級的時候，其能支援的應用也將跨入 RMS (辨識 Recognition、資
料探勘 Mining、影像合成 Synthesis)等智慧應用的範疇，而一個有效的處理器硬體架構將會扮演一個
重要的地位。在本計畫中，以人類的視覺系統—包括從視網膜開始到大腦—為設計的藍圖，在未來兆
級的晶片中，發展智慧型的視覺運算系統。人腦的皮質構造只在某些方面具有優勢，對於較為精細且
大量的影像分析或是影像記錄的能力，則未必能超越最強大的電腦系統。在本計畫中，我們希望不全
然以人類的大腦細胞運作為藍圖，而是結合現今在電腦視覺、機器人學習、資料探勘、電腦圖學的技
術，補足人腦之不足，跟其他子計畫結果，可望收到如人腦左腦及右腦各有擅長之效果，從而能發展
出能力更強的智慧系統。我們將會發展出一個適用於智慧型視覺處理的多核心串流處理器，以及一個
多核心的通用型繪圖處理器，前者可以支援加速辨識(recognition)及資料探勘(mining)的運算，後者主
要可以用以影像合成(synthesis)的運算；我們也會嘗詴發展兩者合而為一的整合性架構。辨識
(recognition)及資料探勘(mining)的即時應用在近年來的發展愈來愈快速，而其瓶頸之一為大量的運算
量，而我們所發展的多核心串流處理器，將可以為此方面的應用提供一個有效率的解決方案；另一方
面，在影像合成(synthesis)的應用更是廣泛，三維電腦繪圖已漸漸開始被應用到遊戲及人機介面之上，
而我們將發展的多核心的通用型繪圖處理器將立即可以被應用到相關的產品上。此外，兩者合而為一
的系統，將可將系統的能力提升至另一境界，進一步支援以影像合成的運算為基礎的視覺辦識系統之
中，這一部分也是我們未來研究的方向。 
 
關鍵字：串流處理器、可重組式處理器、多核心處理器、辦識、資料探勘、影像合成、繪圖處理器元、
電腦圖學、電腦視覺、機器人學習 
 
Abstract 
 
When the integration scale in a single chip reaches tera-scale, the target applications will switch to the field 
of intelligent applications, such as RMS (Recognition, Mining, and Synthesis), where an effective processor 
hardware architecture will play an important role. In this project, based on human vision system, which 
covers the pathway from the retina to the brain, we will develop an intelligent visual computing system in 
the tera-scale integration circuits in the future. The cortex in the human brain is a good model, but it is not 
always superior to computer systems for all the tasks, especially for analyzing large amount of image data 
and recording image in high fidelity. Therefore, we will not try to duplicate and copy the behavior and 
working model of human vision system, but will try to integrate recent research technologies in computer 
vision, machine learning, data mining, and computer graphics to be a complement with Sub-Project 1, 
Silicon Brain. We believe the combination of these two projects would achieve a powerful intelligent system 
like the combination of human’s left brain and right brain. 
 
There are two main targets in this project: multi-core stream processor for intelligent video processing and 
multi-core universal graphics processing unit. The first one can support the acceleration of recognition and 
data mining operations. The result will be useful for many intelligent video systems, such as video 
surveillance systems and intelligent vehicle systems. The second one can support the operations of image 
synthesis. It can be employed in many applications, such as gaming and man-machine-interface. We may 
also try to develop an integrated system with these two proposed processors to further support synthesis 
 4 
一、前言 
 
在單晶片的電晶體的整合程度達到兆級的時候，
其 能 支 援 的 應 用 也 將 跨 入 RMS ( 辨 識
Recognition、資料探勘 Mining、影像合成 Synthesis)
等智慧應用的範疇，而一個有效的處理器硬體架
構將會扮演一個重要的地位。在本計畫中，以人
類的視覺系統—包括從視網膜開始到大腦—為設
計的藍圖，在未來兆級的晶片中，發展智慧型的
視覺運算系統。人腦的皮質構造只在某些方面具
有優勢，對於較為精細且大量的影像分析或是影
像記錄的能力，則未必能超越最強大的電腦系
統。在本計畫中，我們希望不全然以人類的大腦
細胞運作為藍圖，而是結合現今在電腦視覺、機
器人學習、資料探勘、電腦圖學的技術，補足人
腦之不足，跟其他子計畫結果，可望收到如人腦
左腦及右腦各有擅長之效果，從而能發展出能力
更強的智慧系統。我們將會發展出一個適用於智
慧型視覺處理的多核心串流處理器，以及一個多
核心的通用型繪圖處理器，前者可以支援加速辨
識(recognition)及資料探勘(mining)的運算，後者主
要可以用以影像合成(synthesis)的運算；我們也會
嘗詴發展兩者合而為一的整合性架構。辨識
(recognition)及資料探勘(mining)的即時應用在近
年來的發展愈來愈快速，而其瓶頸之一為大量的
運算量，而我們所發展的多核心串流處理器，將
可以為此方面的應用提供一個有效率的解決方
案；另一方面，在影像合成(synthesis)的應用更是
廣泛，三維電腦繪圖已漸漸開始被應用到遊戲及
人機介面之上，而我們將發展的多核心的通用型
繪圖處理器將立即可以被應用到相關的產品上。
此外，兩者合而為一的系統，將可將系統的能力
提升至另一境界，進一步支援以影像合成的運算
為基礎的視覺辦識系統之中，這一部分也是我們
未來研究的方向。在第一年中，我們的研究重點
在於設計一多核心的通用型繪圖處理器，此外我
們也發展出一有效率的材質編碼演算法，可以降
低對晶片外記憶體頻寛的需求。 
在第二年的計畫之中，延續第一年的成果，
我們把研究的重心放在資料探勘(Mining)以及辨
識(Recognition)的功能之上。作為人工智慧的其中
一個分支，機器學習提供了一系列用於資料探勘
以及辨識的演算法，如監督式學習演算法 
(supervised learning algorithms)，無監督式學習演
算法 (unsupervised learning algorithms)，強化學習
演算法等 (reinforcement learning algorithms)。這
些演算法被廣泛使用於不同的應用，例如資料探
勘(Mining)以及辨識(Recognition)的功能之上。如
多媒體內容分析，其中包含了彩色圖像分割和基
於內容之圖像檢索。機器學習演算法的計算常常
會需要對高維度的特徵向量進行大量、重複且複
雜的運算，因此對於傳統的處理器很難達到即時
運算的需求。我們在第二年度的一項重要成果，
便是研發一雙串流處理器(Dual-Steam Processor, 
DSP)，其中特別整合了一影像串流處理器(Image 
Stream Processor, ISP)和特徵串流處理器(Feature 
Stream Processor, FSP)的功能，其中的 FSP能夠支
援部分機器學習的功能。 
  另一方面，在影像合成(synthesis)的應用方面
更是廣泛。除了延續去年開發的多核心通用型繪
圖處理器，發展更加節省頻寬資源的壓縮及解壓
縮模組外，我們也將影像合成的另一個重要分支
──光線追跡(ray tracing)加入我們的研究範疇。 
  光線追跡(ray tracing)是一個在三維繪圖(3D 
graphics)中藉由計算來生成接近真實圖形的演算
法。它的好處是能夠模擬出影子(shadow)以及反射
光(reflection ray)、折射光(refraction ray)等非直射
光(indirect illumination)所造成的效果。然而這個
方法因為要算很多次的光線和三角形的相交測詴
(intersection test)，故運算量極大。雖然有很多加
速 的 方 法 可 以 另 用 特 定 的 加 速 資 料 結 構
(acceleration data structure)來加速它，要達到即時
(real-time) 運 算 還 是 很 困 難 。 此 外 互 動 式
(interactive)的應用在三維繪圖中亦是不可或缺。
如果要實現這個應用，場景在畫每一張圖的時候
都有可能會變動，而造成事先建好的資料結構跟
著改變；因此在本年度之中，我們也設計了一套
光線追跡之特定應用積體電路以解決這個問題。 
 
二、研究目的 
 
本計畫的目標，是要設計能支援智慧視訊應
 6 
一個時脈週期中完成四筆、兩個執行緒共八筆的
單精確度浮點數運算。 
    可程式化濾波器的概念是我們今年度首先提
出的，在系統中將用以取代傳統的材質處理單元
(texture unit)，其設計概念可見圖四。圖四左側是
傳統的繪圖處理器架構，其中的材質單元會透過
材質快取記憶體負責材質的存取，而材質資料在
存取的時候，通常會有一個重新取樣的動作，於
是材質快取記憶體會以多bank的模式讓材質處理
單元能一次存取多筆資料，以便其濾波後輸出給
著色器(shader)，也就是我們的串流處理單元，然
而一般的材質處理單元之中只會內建幾項簡單的
濾波器，例如bilinear interpolation，所以當我們用
繪圖處理器來執行一些影像的濾波運算時，主要
的運算還是會由串流處理單元來執行，材質單元
的角色只是負責單點的存取。圖四右側是我們提
出的新概念，我們把材質濾波器以可程式濾波器
來取代，詳細架構圖如圖五所示，而可程式濾波
器之核心運算單元如圖六所示，可程式濾波器可
執行各種FIR濾波器，還能支援非線性的形態學濾
波器(morphology filter)，如此一來，這些在影像
或是視訊處理中常見的濾波器運算，便可以由可
程式濾波器來負責，其好處是可程式濾波器對材
質快取記憶體有高度平行的存取能力，能提供更
高速的運算，另一好處是可以有效減輕串流處理
器的負擔。 
    在我們這次的通用型繪圖處理器的設計中，
我們也發展了一個新的材質壓縮演算法，稱為
Mipmapping Texture Compression (MTC)，MTC是
專門為了mipmapping材質而設計，mipmapping是
為了減少濾波產生的aliasing並考慮level-of-detail
的一種常用的材質結構，如圖七所示，MTC可以
以小波轉換的方式，一次壓縮三層的mipmapping
材質，對應的MTC材質解碼器的架構如圖八所
示，因為我們使用的是簡單的Haar小波轉換的關
係，此硬體的複雜度並不會很高，也能夠在一個
時脈週期解出一個4x4區塊中任何一點的材質資
訊。 
    相關的實驗結果如圖九到圖十一所示。在圖
九中，我們可以看出，使用MTC材質壓縮，可以
有效地節省80%的頻寬。而使用我們提出的具有
可程式濾波器的串流處理器架構之後，在執行
H.264解碼時，可以減少約28%的運算時間，如圖
十所示。而使用此串流處理器，在執行視訊切割
演算法的時候，可以減少約58%的運算時間，如
圖十一所示。 
    在圖十二中，我們展示了此晶片架構之晶片
實現成果，也展示了其規格，當運作在200MHz
時，此晶片能夠達到200M vertices/s、400M 
pixels/s、1.6G texels/s的運算能力，也可以支援
H.264的解碼以及形態學的運算，而只需37mW的
功率消耗。 
 
在第二年的計畫之中，我們的目標是開發更
多 RMS 的智慧應用及硬體實現，以下則分列三大
方向並加以簡述： 
1) 機器學習系統 
2) 光線追跡之特定應用積體電路 
3) 適用於繪圖系統之壓縮與解壓縮模組 
 
1) 機器學習系統 
圖十三顯示了我們所提出的機器學習系統單
晶片架構圖，包含了一個針對多媒體內容分析之
完整的平台。雙串流處理器的架構如圖十四所
示，在接到系統指令後，DSP 控制單元會進行指
示分析並且使用兩個處理器來處理資料。在 DSP
架構中，資料是透過連接到 32 個記憶體區塊的高
頻寬雙記憶體(HBDM)的內部媒體資料匯流排來
取得。一半大小的 HBDM 即足以儲存 160 × 120
的圖像。目的在於使用 HBDM 來存儲 ISP 和 FSP
所需要的資料，只需要花 2048 個週期即可將存在 
HBDM 的一個記憶體中的資料完全複製到其他記
憶體中。該快速資料存取可以加速多媒體內容的
計算分析和降低 RISC 與 DSP 間資料傳輸所需功
耗。 
影像串流處理器(ISP)主要是由兩個子處理
器，線性處理器以及排序處理器所構成，如圖十
五、圖十六所示。影像串流處理器使用大規模平
行處理單元來處理影像或視頻資料，影像像素輸
入頻寬從16像素/週期轉換為256像素/週期來完成
影像處理中常用到的鄰近區域運算。 
特徵串流處理器(FSP)是用於擷取多媒體資
 8 
點的包圍盒。 
    相關的實驗結果如圖二十五，採用我們所設
計之 RT-ASIC 來加速渲染結果近乎提升約 149 倍
之效能提升。另外對於動態場景的支援，這個硬
體可以直接來做重新適合這個方法。而在節點插
入的這個模式時，此硬體可以幫忙找出最適合的
插入點。整個光線追跡系統是由一顆中央處理
器，記憶體，我們特製的硬體加速器和一些周邊
元件所組成。對於一個 352 x 288 的圖片，這個
系統每秒可以計算出約三到十張圖的速度並支援
動態場景的移動。圖二十六為我們實作之晶片相
片及規格表。此晶片實作的結果中可以看出，此
晶片大小約為 3mm3mm並且可以在 125MHz的
工作頻率下提供 125M traversal/s、62.5M 
intersection/s、21.125GFLOPS 的運算能力，而只
需 111.7mW 的功率消耗。 
 
3) 適用於繪圖系統之壓縮與解壓縮模組 
行動裝置上使用的繪圖晶片比貣適用於桌機
的繪圖晶片在設計上有更多的限制，如有限的能
源及系統頻寬，也因此如何減緩系統頻寬對行動
裝置上的繪圖晶片的限制，成為迫切的問題。而
藉由對系統內的資料進行壓縮及解壓縮來達到節
省頻寬的方式，則是目前相當受歡迎的一種做
法。而其在系統間的位置可見於圖二十七。然而
目前的研究大多著重在高壓縮效率的演算法上，
卻忽略了在解壓縮過程中延遲過久的問題；我們
因此設計了一個新的通用緩衝儲存器壓縮與解壓
縮單元(Universal Buffer Compression and 
Decompression Unit)，這個模組可以同時處理色彩
(color)、深度(depth)及材質(texture)的資訊，並且
能在壓縮率及延遲時間兩者間取得較好的平衡。 
 提出的演算法是先將畫面分成 4x4 的區塊，
並可根據供用基礎點的方式，再擴展到 8x8 或更
大的區塊。接著對每個區塊以誤差訊號編碼
(Differential Pulse-code Modulation, DPCM)的架構
做壓縮及解壓縮，並根據繪圖晶片系統的特性，
對 DPCM 中的每一個步驟做調整，以達更高的壓
縮率；同時，採取並利用可平行化的演算法來減
少解壓縮的時間。整個系統的架構圖可見圖二十
八。 
以誤差訊號編碼為基礎的演算法會包含數值
轉換(color transform)、預測基礎點(spatial 
predictor)、餘數編碼(residue encoding)三個部分。
以下我們針對數值轉換及預測基礎點的部份做簡
短的介紹。 
1) 數值轉換：以色彩資訊為例，我們採取類似
YCbCr 的轉換方式，而在這樣的模式下，我們
選取Ｒ、Ｇ、Ｂ三個頻道中，數值變化頻率最
低的頻道為亮度(luminance)資訊，這樣的做法
能使預測值更為準確，進而提高壓縮率。 
 
2) 預測基礎點：由於繪圖處理器的特性，每個
4x4 的所能涵蓋的平面通常不超過兩個，而同
一平面的資訊通常較為連續，因此若能依據不
同評麵給予不同的預測基礎點，則能提高壓縮
率。我們利用圖二十九中 A、B、C 三點間，
考慮其值差異大小的方式來判斷區塊中每個
點所處的平面，圖中紅色及藍色分屬不同平
面，紫色則為待決定的位置，依據圖中各種可
能的平面組合方式決定其所屬平面之後，再為
各平面，尋找適合的預測基礎點。 
 
 這樣的處理流程除了可應用在色彩資訊的壓
縮外，深度的資訊也可用類似的方式處理。而對
於常見於處理材質資訊(texture)時所用的 DXT5
壓縮方法，我們也可以套用與色彩/深度資訊類似
的概念，在不另外增加延遲時間的前提下，增加
材質貼圖的品質。 
   圖三十為我們提出的壓縮與解壓縮演算
法於之前作品[9][10][14]的壓縮率比較，圖中可以
看出，我們能提供與現階段方法相類似或更好的
品質，然而解壓縮時所需要的時間為其他作品的
四倍。圖三十一則為晶片顯影，操作在 143MHz
的操作頻率下，功率為 158mW。 
 
在第三年的計畫之中，我們針 RMS 之中 RM
的部分進行更進一步的研發。由第二年的研究經
驗，我們認為可重組化串流處理器在這方面的應
用上相當具有效率，故我們進一步針對二類不同
的應用進行了二個可重組化多核心串流處理器的
系統整合。其一是可重組化多媒體語意分析處理
 10 
 
2) 用於智慧型攝影機之可重組化串流處理器 
 
智慧型攝影機具有相當廣泛的用途，特別是智
慧型監控系統，在第三年中，我們也以智慧型攝
影機的晶片為一發展的目標。我們同樣地利用所
發展之可重組化串流處理架構技術來設計此一晶
片，晶片的整體架構如圖四十所示。此架構具有
數個可重組化階段處理單元(Reconfigurable Stage 
Processing Element, RSPE)，這些 RSPE 都是以智
慧型攝影機為目標而設計的，而且他們以可重組
化連線單元(Reconfigurable Interconnection, RI)得
以互相連結。使用這種架構，視訊資料串流透過
RI 在不同的 RSPE 之間流動，包括資料的輸入以
及輸出，以完成目標之運算。 
以往面對這類型的應用，視覺處理器(vision 
processor)是一個常用的架構，如圖四十一(a)所
示，在這個常見的架構之下，使用單一指令多筆
資料(SIMD)的架構，以多個處理單元達至極高的
運算速度，然而為了要提供足夠的輸入資料給這
些高度平行的處理單元，往往需要在晶片上放置
一個很大的記憶體空間，而且對外也將產生極大
的記憶體頻寬，這兩個問題是視覺處理器成本及
耗電的主要來源。在我們所提出的可重組化影像
串流處理器架構(CRISPA)之中，如圖四十一(b)所
示，RSPE 以 RI 進行相連，配合特定的組態，而
能形成各種形態的管線如圖四十一(b)右圖所示，
其中每一種 RSPE 將對應於某一種類的運算，而
可以透過改變組態來改變其功能，如此一來，這
種管線式的運算將不需要如傳統做法的大記憶體
容量以及大頻寬需求，從系統匯流排輸入的資
料，將會形成串流，在不同 RSPE 之前流動，以
充分利用輸入的資料，經過多級多管線的運算之
後，最後輸出至匯流排上。 
在應用 CRISPA 架構於智慧攝影機上時，演算
法中資料形態的多樣性成為一個問題，也就是
說，在智慧型攝影機的演算法中，資料的寬度不
一，有 1-bit 的 mask 資料，也有 8-bit 的影像資料，
也有 16-bit 的標記資料。為了讓這些多樣性的資
料型態能夠在同一架構上執行，我們提出了兩項
重要技術：異質性串流處理(heterogeneous stream 
processing)及次字節平行處理(sub-word level 
parallel) 架構，如圖四十二(a)所示，這項技術可
以動態調整處理單元的字元寬度以及其和匯流排
的比例，而我們也提出了跨資料型態的串流介面
設計，如圖四十二(b)所示。 
對於智慧型攝影機的應用，在分析數種演算法
之後，我們最後設計的可重組化處理單元之種
類、功能、及數量如圖四十三所示。使用這些可
重組化處理單元，只要搭配不同的組態
(configuration, context)，此架構便能有效率地執行
對應之運算，圖四十四展示了一個例子，其中我
們在我們所提出的架構之下實現了常用的 Scale 
Invariant Feature Transform (SIFT)之特徵抽取。 
圖四十五中，我們展示了此晶片用於一些高階
應用之執行結果。在用於物件切割及追蹤時，在
使用複雜的演算法時，此系統仍可以達到 VGA 
30fps 的運算速度。在人臉偵測上，每秒可進行 150
個人臉的偵測。在物件偵測及辨識方面，則可以
達到即時 full-HD 的處理速度。 
晶片的規格如圖四十六所示，晶片照片如圖四十
七所示，在使用 TSMC 90nm 的製程之下，我們
能夠在 197mW 的功率之下，達到 1158GOPS 的
處理能力。在圖四十六中，我們可以看到，和一
些近期相關作品的比較之後，我們可以看到我們
所提出的可重組化串流處理單相當具有競爭力，
為一有效率的設計，他所需要的記憶體數量可以
大幅度地降低，而且能夠達到更好的成本效益以
及用電效率。 
 
 
四、計畫成果自評 
 
在第一年度的計畫之中，我們設計了一個多
核心的串流處理器，其為一個異質的多核心處理
器，包含了一個控制用的 RISC、雙核心的串流處
理子系統、以及可程式化的濾波單元。在此晶片
之中，我們首創了可程式化的濾波單元，用以取
代傳統的材質單元，此單元也提供了一個新的可
程式化單元的思維，我們也證明此單元的設計，
對於執行影像或是視訊系統中的濾波器運算具有
相當好的加速效果。我們也發展了一個為
 12 
[13] Matthew Eldrige, Designing Graphics Architectures 
around Scalability and Communication, Ph.D. Thesis, 
Stanford University, June 2001. 
[14] M. Ishikawa, K. Ogawa, T. Komuro, I. Ishii, “A CMOS 
vision chip with SIMD processing element array for 1 
ms image processing,” ISSCC’99, 1999. 
[15] A. Abbo, R. Kleihorst, V. Choudhary, L. Sevat, P. 
Wielage, S. Mouy, M. Heijligers, “XETAL-II: A 107 
GOPS, 600mW Massively-Parallel Processor for Video 
Scene Analysis,” ISSCC'07, Feb. 2007. 
[16] J. Montrym and H. Moreton, “The GeForce 6800,” 
IEEE Micro, vol. 25, no. 2, pp. 41--51, March-April 
2005. 
[17] C.-H. Chang, C.-Y. Lee, and S.-Y. Chien, “A 2:88mm2 
50MIntersections/s Ray-Triangle Intersection Unit for 
Interactive Ray Tracing,”in Proceeding of the 2008 
IEEE Asian Solid-State Circuits Conference, 2008. 
[18] C. Lauterbach, S.-e. Yoon, and D. Manocha, 
“RT-DEFORM: Interactive Ray Tracing of Dynamic 
Scenes using BVHs,” in Proceedings of the IEEE 
Symposium on Interactive Ray Tracing 2006, 2006, pp. 
39-45. 
[19] R. Overbeck, R, Ramamoorthi, and W. R. Mark, “Large 
Ray Packets for Real-time Whitted Ray Tracing,” in 
Proceedings of the 2008 IEEE/EG Symposium on 
Interactive Ray Tracing, 2008 
[20] S. Woop, E. Brunvand, and P. Slusallek, “Estimating 
Performance of a Ray-Tracing ASIC Design,” in 
Proceedings of IEEE Symposium on Interactive Ray 
Tracing 2006, 2006 
[21] J. Schmittler, I. Wald, and P. Slusallek, “SaarCOR – A 
Hardware Architecture For Ray Tracing,” Proceedings 
of the conference on Graphics Hardware 2002, 2002, 
pp. 27-36.multi-core stream processor for mobile 
multimedia applications,” Symposium on VLSI Circuits 
Dig. Tech. Papers, pp. 24–25, Jun. 2008. 
[22] A. Abbo, R. Kleihorst, V. Choudhary, L. Sevat, P. 
Wielage, S. Mouy, and M. Heijligers, “XETAL-II: A 
107 GOPS, 600mW massively-parallel processor for 
video scene analysis,” in Digest of Technical Papers of 
2007 IEEE International Solid-State Circuits 
Conference (ISSCC2007) , Feb. 2007, pp. 270–271. 
[23] K. Kim, S. Lee, J.-Y. Kim, M. Kim, D. Kim, J.-H. Woo, 
and H.-J. Yoo, “A 125GOPS 583mW Network-on-Chip 
based parallel processor with bio-inspired visual 
attention engine,” in Digest of Technical Papers of 2008 
IEEE International Solid-State Circuits Conference 
(ISSCC2008), Feb. 2008, pp. 308–309.  
[24] C.-C. Cheng, C.-H. Lin, C.-T. Li, S. Chang, C.-J. Hsu, 
and L.-G. Chen, “iVisual: An intelligent visual sensor 
SoC with 2790fps CMOS image sensor and 
205GOPS/W vision processor,” in Digest of Technical 
Papers of 2008 IEEE International Solid-State Circuits 
Conference (ISSCC2008), Feb. 2008, pp. 306–307. 
[25] Jim Rasmusson, Jon Hasselgren, and Tomas 
Akenine-M o¨ller, “Exact and error-bounded 
approximate color buffer compression and 
decompression,” in GH ’07: Proceedings of the 22nd 
ACM SIGGRAPH/EUROGRAPHICS symposium on 
Graphics hardware, 2007, pp. 41–48. 
[26] Jacob Str o¨m, Per Wennersten, Jim Rasmusson, Jon 
Hasselgren, Jacob Munkberg, Petrik Clarberg, and 
Tomas Akenine-M¨oller, “Floating-point buffer 
compression in a unified codec architecture,” in GH ’08: 
Proceedings of the 23rd ACM 
SIGGRAPH/EUROGRAPHICS symposium on Graphics 
hardware, 2008, pp. 75–84. 
[27] H. Malvar and G. Sullivan, “YCoCg-R: A color space 
with RGB reversibility and low dynamic range,” in 
JVTdocument JVT-I014, 2003. 
[28] Morein Stephen L.and Natale Mark A., “System, 
method, and apparatus for com pression of video data 
using offset values,” in US Patent 6762758, 2004 
[29] Tse-Wei Chen, Chi-Sun Tang, Sung-Fang Tsai, 
Chen-Han Tsai, Shao-Yi Chien, and Liang-Gee Chen, 
"Tera-scale performance machine learning SoC with 
dual stream processor architecture for multimedia 
content analysis," in Proc. Custom Integrated Circuits 
Conference (CICC), 2009. 
[30] Tse-Wei Chen, Yi-Ling Chen, Teng-Yuan Cheng, 
Chi-Sun Tang, Pei-Kuei Tsung, Tzu-Der Chuang, 
Liang-Gee Chen, and Shao-Yi Chien, "A multimedia 
 14 
AHB System Bus
Stream Data Buffer and Reference Data Buffer
External Memory Bus
Unified Stream Processing Subsystem
RISC
CPU
Power
Aware
Frequency
Scaling
Memory
Controller
(MC)
Vertex
Fetch
Unit
Universal 
Rasterizer
Rop
Unit
Stream Register File (SRF)
(Configurable Memory Array)
Stream Processing 
Unit (SPU0)
Stream Processing 
Unit (SPU1)
I$ D$
T$Programmable Filtering Unit (PFU)
 
圖一、多核心的通用型繪圖處理器之系統架構圖。 
List0
List0
Batch0
List1
RISC USPS
List0
Batch1
List0
Batch0
PFU
List0
Batch1
List1
Batch0
List1
Batch1
List0
Batch0
List0
Batch1
List0
Batch2
List0
Batch3
List2
List3
Prepare List 
Command 
Kernel 
Execution
Start
Issue Txload
Change Thread
Filter Back
Resume Thread
Change Thread
Issue Txload
Filter Back
Issue Txload
Time
MEM
Stream
Stream
Fetching
Ref.
Samples/Texture
Fetching
Ref.
Data
Samples/Texture
Fetching
Ref.
Data
Ref.
Data
Stream
Stream
Stream
Stream
Fetching
............
............
......
............
............
............
............
 
圖二、RISC、通用型串流處理單元、可程式化濾
波器單之共同運作的時序圖。 
 
Instruction Fetch
Instruction Memory
DEC
SPU
ALU
SUM
FPMUL FPADD
MODIFY
+ + + +
+ +
+
Adder Tree
Unified SOP
(EXP, LOG,
RCP, RSQ) 
Thread A EXE
ALU
SUM
FPMUL FPADD
MODIFY
+ + + +
+ +
+
Adder Tree
Unified SOP
(EXP, LOG,
RCP, RSQ) 
Thread B EXE
From
SRF
From PFU  
圖三、串流處理單元之細部架構圖。 
 
Rasterizer
Texture Unit
Programmable 
shader
Texture Cache
Datapath
TextureTexture
TextureTexture
Temp
Register
Constant
Register
Texture Cache
Texture Filtering PFU
Datapath
Temp
Register
Constant
Register
With the Traditional Texture Unit With the Proposed PFU in the Texture Unit
Texture 
Memory
TextureTexture
TextureTexture
Rasterizer
 
圖四、可程式化濾波器之設計概念圖。 
 
Footprints
Generator
Texture 
Request FIFO
Programmable
 Filtering
Kernel
Texture
Reference 
Data
Buffer
Texture Data 
Cache 
Tag Look 
Up
Filter Coefficients
Memory
Stream
Processing
Unit
Cache 
Address
Fragment 
FIFO
Texture 
Decoder
Programmable Filtering Unit
 
圖五、可程式化濾波器之細部架構圖。 
ADD/ 
MAX/MIN
X
X
X
X
X
X
X
X
X
ADD/
MAX/MIN
ADD/
MAX/MIN
ADD/
MAX/MIN
ADD/
MAX/MIN
ADD/
MAX/MIN ADD/
MAX/MIN
ADD/
MAX/MIN
ADD/MAX/MIN Operation 
Sign
1
2
32
3232
ADD/MAX/MIN
Neg
32
Thread A
Thread B
ADD/
MAX/MIN
*Support Floating point arithmetic
 
圖六、可程式化濾波器核心。 
d
u
v 64x64
32x32
16x16
8x8
4x4
2x2
1x1
Level 1
Level 0
Level 2
Level 3
Level 4
Level 5
Level 6
Decompress in one single pass
(u, v, d)
 
圖七、所提出之Mipmapping Texture Compression 
(MTC) 之演算法概念圖。 
 16 
 
圖十三、機器學習演算法之系統單晶片架構圖。 
 
 
圖十四、雙串流處理器(DSP)架構圖。 
 
 
圖十五、影像串流處理器(ISP)中之線性處理器
(linear processor)架構圖。 
 
 
圖十六、影像串流處理器(ISP)中之排序處理器
(order processor)架構圖。 
 
 
 
 
 
圖十七、用於 K-Nearest Neighbor(K-NN)之自動排
序機制架構圖。 
 
 
 
 
 
圖十八、特徵串流處理器中用於 K-Means 之可根
據頻寬調變機制之架構。 
 
 18 
 
 
圖二十五、利用此RT-ASIC之效能提升。 
 
 
 
 
圖二十六、晶片相片及規格表。 
 
 
 
 
 
 
 
圖二十七、繪圖系統與壓縮及解壓縮模組。 
 
 
 
圖二十八、適用於繪圖系統壓縮與解壓縮模組。 
 
 
圖二十九、各點所屬平面的可能組合。 
 
 
圖三十、壓縮率之比較。 
 
 
 20 
Software Algorithm Hardware Implementation
16-Bank
Slice Memory
OPU
Median
Filter
Image-Stream Processing
Image
    Stream
ISPS Bus
ISPS Bus System Bus
RISP Output
Memory
16-Bank
Slice Memory
LPU
Haar-
like
Filter
RISP Output
Memory
R
e
p
e
a
t N
 tim
e
s
 fo
r
N
 fe
a
tu
re
s
System Bus
Noise Reduction
Based on Median Filter
Feature Extraction
Haar-like Filter
Image
Sensor
RISP RISP
Captured Image
 
ISPS Bus System Bus
Mid-Level VPU
High-Level VPU
FSPS Input Vector Stream Bus
Output Vector
Memory
Input Vector Memory A
d
a
B
o
o
s
t T
ra
in
in
g
 R
e
s
u
lt
S
to
re
d
 to
 V
P
U
 M
e
m
o
ry
(O
fflin
e
)
Feature-Stream Processing
Feature Extraction
AdaBoost
Classifier
(2 Classes)
Candidate
Record
VPU
Face/Non-face
Training Data
Detection Results
Face
Non-Face
 
圖三十六、使用範例二，人臉偵測。 
 
 
 
Power
(mW)
Peak
Power
Scaling
Factor = 2
Power
(mW)
Scaling
Factor = 10
Frequency Scaling of FSPS
Application: Concept-Based
Image Retrieval (156fps)
Peak
Power
Scaling
Factor = 2
Scaling
Factor = 10
Frequency Scaling of ISPS
Application: Block-Based Image
Feature Classification (6kblock/s)
1200
400
0
800
1214mW
1200
400
0
551mW
800
428mW
-55% -65%
1214mW 1053mW 929mW
-13% -23%
 
圖三十七、使用工作頻率動態調整技術所達到之
節能效果。 
 
 
 
0.42
29.1
8.6
7.3
1.71.5
0.67
0.18
0.8
0.4
0
ISSCC
2007
ISSCC
2009
ISSCC
2008
This
Work
(SASoC)
Power
Efficiency
(TOPS/W)
0.11
0.6
0.2
32
16
0
Area Efficiency
(GOPS/mm2)
24
8
0.31
ISSCC
2008
ISSCC
2007
ISSCC
2009
ISSCC
2008
This
Work
(SASoC)
ISSCC
2008
 
圖三十八、和其他相關工作之比較。 
 
 
Process
Die Size
Power Supply
Operating Frequency
On-Chip SRAM
Total Gate Count
(2-Input NAND Gate)
TSMC 90nm IP9M CMOS
28mm2 (7mm x 4mm)
Core 1.2V, I/O 2.5V
3 Clock Domains
Maximum 200MHz for Each
Maximum
Input Data Rate
Peak Performance
Power Consumption 1214mW (Peak)
ISPS
FSPS
3.00M gates
(ISPS: 1.23M gates, FSPS: 1.76M gates)
76.8Gpixel/s
51.2Gdimension/s
149KB
(ISPS: 100KB, FSPS: 49KB)
814GOPS
(ISPS: 512GOPS, FSPS: 302GOPS)
Power Efficiency 671GOPS/W
Application Example
(160 x 120 frame)
Concept-Based Image Retrieval: 156fps
Face Detection: 294fps  
圖三十九、晶片圖及規格 
 
64-bit System Bus
AHB Master/Slave
Input 
Interface
Output 
Interface
In
p
u
t S
tre
a
m
Host Processor
O
u
tp
u
t S
tre
a
m
Reconfigurable Interconnections
Context 
Registers
Main Controller
External 
Memory
Reconfigurable Interconnections
S
e
g
m
e
n
ta
tio
n
O
b
je
c
t In
fo
P
a
z
e
n
 
D
is
ta
n
c
e
 
C
o
m
p
u
ta
tio
n
S
L
P
 W
in
d
o
w
 
R
e
g
is
te
rs
A
L
U
 
C
O
R
D
IC
M
A
C
R
e
c
o
n
fig
u
ra
b
le
 
M
e
m
o
ry
 
B
in
a
ry
 
M
o
rp
h
o
lo
g
y
Reconfigurable 
Stream 
Processing 
Elements
(RSPEs)
ReSSP
M
in
M
a
x
 
圖四十、用於智慧型攝影機之可重組化串流處理
器。 
 
 22 
Smart Camera 
Application
Supported High Level 
Algorithm Specification Hardware Speed
Video Object
Segmentation and 
Tracking
Segmentation : Multi-Layer
Background Subtraction
Tracking : Particle Filter
Segmentation : 640x480 125fps
Segmentation + tracking : 
640x480 30fps 11 Objects  
(or 33000 particles per sec) 
with object size 80x80 
ReSSP @ 132 MHz
ReSSP @ 132 MHz
ARM926EJ-S @266MHz
Face Detection , 
Scoring and Ranking
Face Detection with 
Segmentation and
Feature-based Face Scoring
150 faces per second ReSSP @ 132 MHz
ARM926EJ-S @266MHz
Object Detection and 
Recognition
Scale Invariant Feature 
Transform (SIFT)
can support 1920x1080 full HD 
object recognition in real-time
ReSSP @ 149 MHz
ARM926EJ-S @266MHz
 
(b) 
圖四十五、(a) 一些高階應用之執行結果。(b)執
行速度之分析。 
 
Work [2] [3] [4] [5] ReSSP
Process 
90nm CMOS UMC 0.18um 
2P4M CMOS 
Image Sensor 
Process
TSMC 90nm 
IP9M CMOS
0.13µm 8 metal 
CMOS 
TSMC 90nm 1P9M 
CMOS
Die Size 74mm
2
70.5 mm
2
(7.5mm x 
9.4mm)(core area)
28mm
2 
(7mm x 
4mm)(die size)
50mm
2 
(die size) 10.4mm
2 
(3.2mmx3.2mm) 
Power Supply 
LPA:0.7V - 1.2V 
/other : 0.9V-1.2V
2.1V Core 1.2V, I/O 
2.5V
0.65V-1.2V Core 1.2V, I/O 2.5V
Total Gate Count
740 kgates NA 3.00M gates 2.92M gates 0.9M Gates (2-Input 
NAND Gate, Including 
On-Chip Memory)  
On-Chip Memory (Kb)
10240 1024 1192 4896 56  (Including Context 
Registers) 
Working Frequency 84MHz 50MHz Max 200MHz
NoC: 400MHz 
Processing: Max 
200MHz
Max 149MHz 
Peak Performance 
(GOPS)
107 76.8 814 228 1157.82
Power Consumption 
600mW Vision Processor: 
374mW
1214mW (Peak) Peak :704mW
Average: 345mW
197mW (peak)
Area Efficiency 
(GOPS/mm^2)
1.500 4.357 29.100 9.120 111.329 
Power Efficiency 
(TOPS/W)
0.178 1.283 0.671 0.469 5.877 
Resolution and Spec 
for Image Analysis 
Target at 128x128 
image analysis
Target at 
160x120
Image analysis 
SIFT 640x480 30 
fps
SIFT 640x480 30fps 
and other applications 
with high spec
 
960
56
0
200
400
600
800
1000
1200
Without SLP ReSSP (With 
SLP)
On-Chip 
Memory (Kb)
94% reduction
  
10240
1024 1192
4896
56
[ 2 ] [ 3 ] [ 4 ] [ 5 ] R e S S P
On-C h i p  M e m o r y ( K b )
 
(With Technology Scaling of Area)
12.2x
3.8x
25.5x
74.2x
1.500 4.357 
29.100 
9.120 
111.329 
[2] [3] [4] [5] ReSSP
Area Efficiency (GOPS/mm^2)
Technology scaling of power
P90 = P180x(C90/C180)x(V90/V180)2= P180x0.5x(1.2/2.1)2 = P180x0.16
P90 = P130x(C90/C130)x(V90/V130)2= P130x0.69x(1.2/1.2)2 = P130x0.69  
0.178 
1.283 
0.671 0.469 
5.877 
[2] [3] [4] [5] ReSSP
Power Efficiency(TOPS/W)
33.0x
4.5x 8.7x 12.5x
  
[2] A. Abbo, et al., "XETAL-II: A 107 GOPS, 600mW Massively-Parallel Processor for Video Scene 
Analysis," ISSCC Dig. Tech. Papers, pp. 270-271, Feb. 2007. 
[3] C.-C. Cheng, et al., "iVisual: An Intelligent Visual Sensor SoC with 2790fps CMOS Image Sensor 
and 205GOPS/W Vision Processor," ISSCC Dig. Tech. Papers, pp. 306 - 615, Feb. 2008.    
[4] T.-W. Chen, et al., "A Multimedia Semantic Analysis SoC (SASoC) with Machine-Learning 
Engine," ISSCC Dig. Tech. Papers, pp. 338 - 339, Feb. 2010. 
[5] S. Lee, et al., "A 345mW Heterogeneous Many-Core Processor with an Intelligent Inference 
Engine for Robust Object Recognition," ISSCC Dig. Tech. Papers, pp. 332 -333, Feb. 2010. 
               
圖四十六、晶片規格以及和其他相關作品之比較。 
 
 
圖四十七、晶片照片。 
 
 24 
3. 請依學術成就、技術創新、社會影響等方面，評估研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）（以
500 字為限） 
 
在 Recognition、Mining、Synthesis的應用之中，在此三年計畫，我們先後
完成了二代繪圖處理器之設計，也完成一光追蹤晶片的雛型，在智慧辨識系
統方面，我們也完成了兩個和機器學習有關的晶片設計，以及一用於智慧型
攝影機之可重組化串流處理器之設計。研究成果可說相當豐富。 
在此三年之中，我們發展了許多繪圖處理器、機器學習、可重組化串流處理
器的關鍵技術，在一些整合的晶片上均能超越文獻中的其他作品，我們也在
持續推動，希望這些設計最後能夠落實在產業界，而能提昇相關產品的價值。 
 
 
 
 
 
 
 
 
 26 
國科會補助計畫衍生研發成果推廣資料表 
日期： 100 年 12月 15日 
國科會補助計畫 
計畫名稱：iChip兆級智慧矽晶片之研究：演算法，架構，與實現
技術--子計畫二：適用於智慧應用之兆級可重組化多核心串流處
理器架構之研究 
計畫主持人：簡韶逸         
計畫編號：97-2221-E-002-243-MY3   領域：微電子 
研發成果名稱 
（中文）用於智慧型攝影機之可重組化串流處理器 
（英文）Reconfigurable Smart-Camera Stream Processor 
成果歸屬機構 
國立臺灣大學 發明人 
(創作人) 
簡韶逸、詹偉凱 
技術說明 
（中文）此可重組化串流處理處理器以 90nm 的製程打造，其中我
們使用了可組化異質串流處理以及次字節平行處理的技術而能加
速智慧型攝影機的運算。 
（英文）A 5.877 TOPS/W Reconfigurable Smart-camera Stream 
Processor is implemented in 90nm CMOS technology. A 
re-configurable hardware architecture with heterogeneous stream 
processing and subword-level parallelism is implemented to accelerate 
the vision processing for smart-camera applications. The area 
efficiency reaches 111.329 GOPS/mm
2
. The power efficiency and area 
efficiency are 4.5x to 33.0x and 3.8x to 74.2x better than the 
state-of-the-art works, respectively. 
產業別 
電機電子相關產業 
技術/產品應用範圍 
各種會使用到影像辨識及電腦視覺的系統，特別是智慧型攝影機。 
技術移轉可行性及預期
效益 
本技術可以技轉於晶片設計公司，可以矽智財的方式進行整合，
或是將元件重組後整合，將可增加系統的功能 
     註：本項研發成果若尚未申請專利，請勿揭露可申請專利之主要內容。 
 28 
 
 
國科會補助專題研究計畫項下出席國際學術會議心得報告 
                                     日期：100 年 7月 15日 
                                 
一、參加會議經過 
 
IEEE International Conference on Multimedia and Expo (ICME)是由國際電子電機學會（IEEE）中的電路
與系統學會（Circuits and Systems Society）、通訊學會（Communication Society）、電腦學會（Computer 
Society）、信號處理學會（Signal Processing Society）等四大學學會共同舉辦，其原因在於多媒體的領
域其實就是多個領域的交集。每年約在七月分舉行，今年是從 7 月 11 日至 15 月 5 日共計五天，在西
計畫編號 NSC97-2221-E-002-243-MY3 
計畫名稱 iChip兆級智慧矽晶片之研究：演算法，架構，與實現技術--子計畫
二：適用於智慧應用之兆級可重組化多核心串流處理器架構之研究 
出國人員
姓名 
簡韶逸 
服務機構
及職稱 
國立臺灣大學電子所 
會議時間 
2011年 7月 11日
至 
2011年 7月 15日 
會議地點 
西班牙巴塞隆納市 
會議名稱 
(中文) 2011 IEEE 國際多媒體會議暨博覽會 
(英文) 2011 IEEE International Conference on Multimedia and Expo 
發表論文
題目 
1. Architecture design and analysis of image-based rendering 
engine 
2. Automatic object segmentation with salient color model 
3. Coarse-to-fine temporal optimization for video retargeting 
based on seam carving 
附件四 
 30 
個 MW 級的功率消耗，所以近年來有一個新的排名稱為 Green Top 500，會開始考慮功耗的部分，而通
常會使用 GPU 當作運算單元，也有一些其他的方式，例如使用 FPGA、ASIC、甚至是 ARM processor，
這些也是超級電腦發展的新趨勢。不過這個演講和多媒體的主軸似乎關係沒有很密切。在 keynote 
speech 後就開始了第一天的議程，第一天的第一場的第一篇論文就是我們的論文，由我自己上台報告，
今年 ICME 同時只有兩場平行的 session，所以來聽我的報告的人非常多，算是我在 conference 之中所
遇過數一數二多的，在 Q&A 的時候也獲得許多有用的建議，我也把這些建議記下來，帶過我們實驗室
做進一步的探討。同場也有好幾篇有趣的論文，其中一篇使用一些人臉的特徵來自動計畫出臉的美醜
程度，並使用一些女性照片的網站的網友評價做為參考，這項有趣的研究，後來也得到 Best demo 
award。今年的議程設計很特別，在我早上講完之後，下午我還必頇在 poster session 報告同一個作品一
次，雖然會增加報告者的負擔，不過可以跟聽眾更有互動，也更能夠多討論一些，算是滿不錯的一個
設計。在下午我還主持了一場 session，有關於多媒體的系統設計，其中有跟教育相關的，跟視訊傳輸
相關的，還有跟監控系統相關的論文。在第一天我馬不停蹄的參加各項活動，算是相當充實。不過很
可惜也失去了看其他論文的報告以及無法參加下午兩場精采的 Plenary 演講：Sparse and Redundant 
Representations: Theory and Applications 以及 Virtual Vision: Computer Vision in Virtual Reality，不過我
的學生也適時參加這些場次，可以另外跟我說明。在這一天的下午，我參加了這邊的 research facility 
visit，原本覺得只是看看而已，沒想到看完之後另人印象非常深刻，主辦單位號稱具有最好的 VR 開發
環境，事實上在參觀之後真的有這種感覺，最令人印象深刻的是他們連製作 3D 動畫電影所用的 body 
motion capture 系統都有，建置在一個像是攝影棚的房間之中，而學生的研究室的規劃和 MIT Media Lab
的感覺竟然非常相似！這也讓我對西班牙的科技研究的實力有了不同的看法。 
 
7/13 的議程由另外一場 keynote speech 開始，主講人是 UC Berkeley 的 Prof. Avideh Zakhor，講題是 Fast, 
Automatic, Photo-Realistic, 3D Modeling of Building Interiors。她在這場演講之中說明了他們做的一套很
有意思的系統。這個系統是從以往空照圖的概念進行延伸，由一位學生背著一台建置各種感測器的背
包，其中包括數個攝影機、雷射測距儀、陀螺儀等，這位學生之後在建築物裡行走，並上下樓梯，系
統便可以自動把相對應的三維模型建立出來。要建置這項系統需要很複雜的技術，Prof. Zakhor 都進行
了鉅細靡遺的說明，而這套系統可能的應為為 image based rendering，也有可能用於 indoor AR。不過
講者似乎講太多技術的細節，比較不像是一般的 keynote speech 的主要目標在於點出未來的技術發展方
 32 
場演講之中，他把 Kinect 發展的原因，以及一些相關的技術內容都做了詳盡的敘述，Kinect 不僅僅用
於電玩上，他也形成一種新型態的 non-touch user interface，預估將來會有越來越廣的應用。在感測端，
Kinect 依然使用了三角定位的技術來擷取深度資料，它利用了一個 infra ray emitter 以及 infra ray camera
形成一雙眼系統，再利用 structure light 以及 time of flight 的技術，便可以量到最後的深度值。在身體
姿勢的辨識方面，主要使用的技術為利用電腦繪圖的模型和真實物體的真實深度進行比較，另外就是
採用 machine learning 的方式，以 training 的方式找到最佳的辨識方法。我們的第三篇論文也在今日下
午報告。而我下午也再參加了兩場Plenary演講。第一場是由Vienna University的Prof. Werner Purgathofer
所主講之 Future Challenges in Computer Graphics，他點出了幾個未來的發展方向：scalability、semantics、
fusion、interaction、acquisition。第二場是由 University of Southern California 的 Prof. Shrikanth (Shri) 
Narayanan 所主講之 Behavioral Informatics: Challenges and Opportunities for Multimedia Signal 
Processing。 
 
7/15 的議程是另外的一些 workshop，同時也有以下兩個 tutorial，不過第一場我在其他會議已經聽過，
而第二場和我的研究領域關係較低，故我都沒有參加。 
1) Quality of Experience (QoE) in Multimedia Communications 
2) Packet Core Network Evolution in regard to Future Internet Research 
 
 
二、與會心得 
 
ICME 是以多媒體研究為主的會議，幾乎每個 session 都和我們實驗室研究的方面非常相關，在這個會
議之中也可以感受到這個領域的發展趨勢。這一次的會議對多媒體的應用系統的重視程度很高，也就
是說，論文的方向從模組邁向了系統，而網路技術、雲端運算、電腦視覺已經變成了每個系統發展的
基礎，一些先進的研究題目，例如增擬實境(Augmented Reality, AR)，還有 Kinect 的應用也成為這次會
議的亮點。這個領域的變化非常迅速，所以我們在做研究的同時，也應該要多涉獵各方面的新知，也
才能以更為整體的觀點走出正確的研究方向。 
 1 
 
國科會補助專題研究計畫項下出席國際學術會議心得報告 
                                     日期：100 年 7月 15日 
                                 
一、參加會議經過 
 
IEEE International Conference on Multimedia and Expo (ICME)是由國際電子電機學會（IEEE）中的電路
與系統學會（Circuits and Systems Society）、通訊學會（Communication Society）、電腦學會（Computer 
Society）、信號處理學會（Signal Processing Society）等四大學學會共同舉辦，其原因在於多媒體的領
域其實就是多個領域的交集。每年約在七月分舉行，今年是從 7 月 11 日至 15 月 5 日共計五天，在西
計畫編號 NSC97-2221-E-002-243-MY3 
計畫名稱 iChip兆級智慧矽晶片之研究：演算法，架構，與實現技術--子計畫
二：適用於智慧應用之兆級可重組化多核心串流處理器架構之研究 
出國人員
姓名 
簡韶逸 
服務機構
及職稱 
國立臺灣大學電子所 
會議時間 
2011年 7月 11日
至 
2011年 7月 15日 
會議地點 
西班牙巴塞隆納市 
會議名稱 
(中文) 2011 IEEE 國際多媒體會議暨博覽會 
(英文) 2011 IEEE International Conference on Multimedia and Expo 
發表論文
題目 
1. Architecture design and analysis of image-based rendering 
engine 
2. Automatic object segmentation with salient color model 
3. Coarse-to-fine temporal optimization for video retargeting 
based on seam carving 
附件四 
 3 
個 MW 級的功率消耗，所以近年來有一個新的排名稱為 Green Top 500，會開始考慮功耗的部分，而通
常會使用 GPU 當作運算單元，也有一些其他的方式，例如使用 FPGA、ASIC、甚至是 ARM processor，
這些也是超級電腦發展的新趨勢。不過這個演講和多媒體的主軸似乎關係沒有很密切。在 keynote 
speech 後就開始了第一天的議程，第一天的第一場的第一篇論文就是我們的論文，由我自己上台報告，
今年 ICME 同時只有兩場平行的 session，所以來聽我的報告的人非常多，算是我在 conference 之中所
遇過數一數二多的，在 Q&A 的時候也獲得許多有用的建議，我也把這些建議記下來，帶過我們實驗室
做進一步的探討。同場也有好幾篇有趣的論文，其中一篇使用一些人臉的特徵來自動計畫出臉的美醜
程度，並使用一些女性照片的網站的網友評價做為參考，這項有趣的研究，後來也得到 Best demo 
award。今年的議程設計很特別，在我早上講完之後，下午我還必須在 poster session 報告同一個作品一
次，雖然會增加報告者的負擔，不過可以跟聽眾更有互動，也更能夠多討論一些，算是滿不錯的一個
設計。在下午我還主持了一場 session，有關於多媒體的系統設計，其中有跟教育相關的，跟視訊傳輸
相關的，還有跟監控系統相關的論文。在第一天我馬不停蹄的參加各項活動，算是相當充實。不過很
可惜也失去了看其他論文的報告以及無法參加下午兩場精采的 Plenary 演講：Sparse and Redundant 
Representations: Theory and Applications 以及 Virtual Vision: Computer Vision in Virtual Reality，不過我
的學生也適時參加這些場次，可以另外跟我說明。在這一天的下午，我參加了這邊的 research facility 
visit，原本覺得只是看看而已，沒想到看完之後另人印象非常深刻，主辦單位號稱具有最好的 VR 開發
環境，事實上在參觀之後真的有這種感覺，最令人印象深刻的是他們連製作 3D 動畫電影所用的 body 
motion capture 系統都有，建置在一個像是攝影棚的房間之中，而學生的研究室的規劃和 MIT Media Lab
的感覺竟然非常相似！這也讓我對西班牙的科技研究的實力有了不同的看法。 
 
7/13 的議程由另外一場 keynote speech 開始，主講人是 UC Berkeley 的 Prof. Avideh Zakhor，講題是 Fast, 
Automatic, Photo-Realistic, 3D Modeling of Building Interiors。她在這場演講之中說明了他們做的一套很
有意思的系統。這個系統是從以往空照圖的概念進行延伸，由一位學生背著一台建置各種感測器的背
包，其中包括數個攝影機、雷射測距儀、陀螺儀等，這位學生之後在建築物裡行走，並上下樓梯，系
統便可以自動把相對應的三維模型建立出來。要建置這項系統需要很複雜的技術，Prof. Zakhor 都進行
了鉅細靡遺的說明，而這套系統可能的應為為 image based rendering，也有可能用於 indoor AR。不過
講者似乎講太多技術的細節，比較不像是一般的 keynote speech 的主要目標在於點出未來的技術發展方
 5 
場演講之中，他把 Kinect 發展的原因，以及一些相關的技術內容都做了詳盡的敘述，Kinect 不僅僅用
於電玩上，他也形成一種新型態的 non-touch user interface，預估將來會有越來越廣的應用。在感測端，
Kinect 依然使用了三角定位的技術來擷取深度資料，它利用了一個 infra ray emitter 以及 infra ray camera
形成一雙眼系統，再利用 structure light 以及 time of flight 的技術，便可以量到最後的深度值。在身體
姿勢的辨識方面，主要使用的技術為利用電腦繪圖的模型和真實物體的真實深度進行比較，另外就是
採用 machine learning 的方式，以 training 的方式找到最佳的辨識方法。我們的第三篇論文也在今日下
午報告。而我下午也再參加了兩場Plenary演講。第一場是由Vienna University的Prof. Werner Purgathofer
所主講之 Future Challenges in Computer Graphics，他點出了幾個未來的發展方向：scalability、semantics、
fusion、interaction、acquisition。第二場是由 University of Southern California 的 Prof. Shrikanth (Shri) 
Narayanan 所主講之 Behavioral Informatics: Challenges and Opportunities for Multimedia Signal 
Processing。 
 
7/15 的議程是另外的一些 workshop，同時也有以下兩個 tutorial，不過第一場我在其他會議已經聽過，
而第二場和我的研究領域關係較低，故我都沒有參加。 
1) Quality of Experience (QoE) in Multimedia Communications 
2) Packet Core Network Evolution in regard to Future Internet Research 
 
 
二、與會心得 
 
ICME 是以多媒體研究為主的會議，幾乎每個 session 都和我們實驗室研究的方面非常相關，在這個會
議之中也可以感受到這個領域的發展趨勢。這一次的會議對多媒體的應用系統的重視程度很高，也就
是說，論文的方向從模組邁向了系統，而網路技術、雲端運算、電腦視覺已經變成了每個系統發展的
基礎，一些先進的研究題目，例如增擬實境(Augmented Reality, AR)，還有 Kinect 的應用也成為這次會
議的亮點。這個領域的變化非常迅速，所以我們在做研究的同時，也應該要多涉獵各方面的新知，也
才能以更為整體的觀點走出正確的研究方向。 
國科會補助計畫衍生研發成果推廣資料表
日期:2010/08/27
國科會補助計畫
計畫名稱: 子計畫二：適用於智慧應用之兆級可重組化多核心串流處理器架構之研究
計畫主持人: 簡韶逸
計畫編號: 97-2221-E-002-243-MY3 學門領域: 積體電路及系統設計 
研發成果名稱
(中文) 影像語意分析單晶片系統及其方法
(英文) Image semantic analysis system-on-a-chip system architecture and algorithms
成果歸屬機構
國立臺灣大學 發明人
(創作人)
簡韶逸,陳則瑋
技術說明
(中文) 本發明有關於一種影像語意分析單晶片系統及其方法，尤指一種具有機器學習引
擎之單晶片系統及其方法，其架構包括有一影像串流處理系統及一特徵串流處理
系統，影像串流處理系統在一待測影像中擷取出至少一第一特徵量，特徵串流處
理系統為一機器學習引擎，係將第一特徵量與複數種特徵類型之訓練影像的第二
特徵量進行相似度比對，以產生至少一特徵相似值，則根據各特徵相似值語意分
析出待測影像所代表的特徵類型，藉此，不僅可對於待測影像所內涵的影像特徵
進行語意分析，進而分類待測影像，並實現一硬體化架構，以加快影像處理的速
度。
(英文) This work is about the architecture and algorithman of an image semantic analysis 
system-on-a-chip system, including a core of machine learning engine. The architecture 
of this system consists of an image stream processor and a feature stream processor. The 
image stream processor can extract several features from the input image. The feature 
stream processor is a machine engine, which acts as the classifier with the features 
extracted from the image stream processor. The associated hardware architectures and 
algorithms are proposed in this work.
產業別 電機及電子機械器材業
技術/產品應用範圍 可整合至各式影像及視訊設備之晶片之中，例如手機、網路攝影機、相機、攝影機
技術移轉可行性及
預期效益
因此系統可整合至各式影像及視訊設備之晶片之中，此技術適合移轉給影像及視訊處理
晶片設計公司
註：本項研發成果若尚未申請專利，請勿揭露可申請專利之主要內容。
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
與本計畫相關之前期繪圖晶片技術已經技轉給業界。 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
