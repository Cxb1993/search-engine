 2
 
行政院國家科學委員會專題研究計畫成果報告 
   
多種材質類型合成技術之研究 
A Study on Synthesis Techniques for Various Types of Textures 
 
計畫編號：NSC 95-2221-E-239 -031 
執行期限：95 年 08 月 01 日至 96 年 07 月 31 日 
主持人：張勤振        國立聯合大學 資訊工程學系 
計畫參與人員：徐嘉敏  國立交通大學 資訊科學與工程研究所 
王允文  國立交通大學 多媒體工程研究所 
阮喬愷  國立交通大學 多媒體工程研究所 
 
中英文摘要 
本報告提出了全新的材質合成演算法。首
先，將來源材質轉換成演化式計算演算法的
輸 入 個 體 (Individual) 。 接 著 ， 選 擇
(Selection) 對 適 應 函 數 (Fitness 
Function)來說具有優良的材質合成效果的
母代作為演化的依據。然後，選出優良母代
後該如何進行交配(Crossover)動作，將優
良的材質區塊傳遞給子代。之後，將產生出
來視覺效果較好的子代與原母代作世代交
替（Survivor Selection \ Replacement）。
最後，經過世代繁衍後，當演化的子代個體
符合我們的適應函數或是到達演化設定的
結束時間後，我們將找出一組合成效果最好
的材質圖塊，再利用改良最小誤差路徑作為
兩相鄰重疊區塊貼合的接合方法將接縫處
模糊化，得到最後的結果。 
 
關鍵詞：電腦繪圖; 材質合成; 基因演算法;
演化式計算 
 
In this report, we propose a genetic algorithm 
for texture synthesis. First, combining the idea 
of evolutionary computation, source and 
output textures are represented as two 
individuals by a sequence of patches. Then, by 
a selection between individuals using fitness 
of each individual and the operation of 
crossover and mutation, new individuals, 
called offspring, are obtained. Repeat this 
procedure until the user-specified criteria is 
reached. The individual with the lower error 
and high visual quality can be obtained, and 
then patch this individual by scan-line order 
and smooth the seams that appear between 
two continuous patches. Finally, the output 
texture is produced. Results show that our 
approach can produce good results. 
 
Keywords ： Computer Graphics; Texture 
Synthesis; Genetic Algorithm; Evolutionary 
Computation 
 
一、 前言與目的 
在電腦圖學（Computer Graphics）研究領域
中，材質（Texture）通常被廣泛地使用來呈
現不同物件表面的特徵。然而在電腦圖學
中，我們最普遍地是利用多邊形（Polygon）
來表現物體，用多少數量的多邊形來描述一
個物體可以決定這個物體呈現出來的精細
與複雜度，但是當整個場景的物體過多，多
邊形數量龐大的時候，電腦必須花費更多的
資源與時間來處理這些資料來完成描繪
（Rendering）， 所以我們利用材質貼圖技術
（Texture Mapping）來取代以往使用大量的
多邊形來描述物體，材質貼圖是利用一張
圖，通常是矩形，將此圖形的四個頂點分別
對應到三度空間場景中的座標。 
但在採用材質貼圖技術時，我們將遭遇
到 兩 個 問 題 ： 第 一 個 問 題 是 解 析 度
（Resolution），通常提供材質的解析度都很
小，若我們直接將材質貼於物體上，必然無
法將整個大型物體覆蓋，我們可以使用貼磚
（Tiling）的方式來將小張的材質反覆貼
上，但是此舉會造成物體貼圖表面連接不順
暢，造成貼圖間不可避免的縫隙，視覺效果
便大打折扣。第二個問題是，記憶體管理的
問題，為了要呈現較佳的視覺效果，我們通
常會使用多組材質組合起來，這便表示系統
整體的個體群落逐漸往問題所要求的最佳
化解答前進。然後這個函數本身不一定非要
有數值的產生，在演化式計算的彈性架構下
只要能夠找出一種評斷好與壞的方式即可
稱為適應函數，而當我們應用到材質合成的
話，我們所設計的適應函數是將兩相鄰區塊
A與B的重疊區域中每一個相對應的像素之
像素值作相減後平方的總和，也就是 
 
( )∑==
==
−
5,5
1,1
2),(),(
ji
ji
jiBjiA . 
 
我們依據此值來判斷如何從個體群中的挑
選出合成品質較優良的母代，個體具有較小
值（合成後的誤差較小）的便是較優良的母
代，而適應值（Fitness）的計算包含了每一
塊材質區塊與上方和左方的區塊所重疊的
區域，下圖(圖一)是適應函數圖解： 
 
 
(圖一) 
 
3-3. 母代選擇（Parent Selection）: 
在我們配合材質合成的概念下，我們選擇競
賽選擇作為選擇母代的方法，原因是因為競
賽選擇可以避免第一類以機率為主的選擇
法所產生的兩種風險，另外一個原因是競賽
選擇在最佳化的收斂時間較短，比起其他的
選取方式，我們能夠較快速的得到結果並且
程式實作上較彈性也簡單。 
 4
 
3-4. 交配（Crossover）: 
我們在材質合成的演算法中所選擇的交配
原則為 N-點交配，原因是因為我們的個體
基因數為 144 個，若只用 1-點交配則基因的
交換效率太過低落，可能會造成演化速度的
緩慢，使用均勻交配的話又會使得基因交換
太過頻繁，無法有效發現優良的基因區塊。 
 
3-5. 變異（Mutation) : 
在此材質合成演算過程中，我們對於變異的
設計是打算利用一個隨機變數來表示每一
個子代的每一個基因會產生變異的機率，這
個數值必須要小，否則子代變種晃動的太劇
烈，對於演化式計算這種將優良的基因傳遞
下去的概念將會被破壞，也就沒辦法順利解
出問題的最佳化解，我們將為子代中的每一
個基因變異機率設為 ，則子代變異的情
況將會是每一個個體中的基因有  的機
率會變異，變異後的基因將從材質編號區塊
中隨機選擇。 
rP
rP
NPPPP ,.....,,, 321
 
3-6. 生存者汰換（Survivor Selection \ 
Replacement）: 
在我們設計的材質合成演化演算法中，我們
將採取世代交替（Generational Model），將
整個母代全不用相同個數的子代汰換掉。這
種方式透過我們的交配、變異技巧能擁有多
樣性並且保持去蕪存菁的特性。 
 
3-7. 改良式最小誤差路徑 (Adapted 
Minimum Error Path) : 
針對利用演化式計算方法所得出來具有最
低誤差值的個體，我們將使用改良後的L2 
Norm來當作是計算最小誤差路徑的依據
值，原本的L2 Norm值是直接將兩塊相同大
小之重疊區域中位置互相對應的像素值作
相減後的平方，現在我們考量到這種作法只
是針對該點位置的顏色差異作考量，並沒有
考量該點周圍的顏色值差異程度，我們提出
了一個新的計算依據 :  
 
( ) ( ) ( 222 347 BABABA GGRRBB −×+−×+−× ) . 
 
如下圖(圖二)： 
 
 
(圖二) 
 
在重疊區塊中，黑色點是我們目前處理
的點，所以我們將 A 區塊的黑色點值減去 B
區塊的黑色點值後平方乘上較高的比例，再
加上黑色點水平與垂直方向的四周紅色點
作 A 區塊紅點減去 B 區塊紅點色值後平方
  
(圖六) 
 
參考文獻 
[1] 游麗娟（指導教授: 葉維磬），「基因演算法於
幾何形狀最佳化設計之研究」，國立中央大學機
械工程所碩士論文，2000 年。 
[2] 張任烜（指導教授: 王宗銘），「有效的材質合
成與影像轉移技術之研究」，國立中興大學資訊
科學研究所碩士論文，2002 年。 
[3] 王丁立（指導教授: 孫春在），「結合演化式策
略和完整式搜尋在 DNA 序列中尋找有意義的
基因片段」，國立交通大學資訊科學系碩士論
文，2002 年。 
[4] 許展碩（指導教授: 黃俊哲），「一個複合型的
演化式計算：基因演算法結和約略集合理論」，
暨南國際大學資訊管理學系碩士論文，2004
年。 
[5] 陳之容（指導教授: 戴文凱），「採用資料探勘
技術的材質合成」，國立東華大學資訊工程學系
碩士論文，2004 年。 
[6] M. Ashikhmin, “Synthesizing Natural Texture,” 
In ACM Symposium on  Interactive 3D 
Graphics, pp. 217-226, 2001. 
[7] Y. Chen, X. Tong, J. Wang, S. Lin, B. Guo and 
H.Y. Shum, “Shell Texture Functions,” 
SIGGRAPH 2004, 2004. 
[8] J. M. Dischler, K. Maritaud, B. Levy and D. 
Ghazanfarpour, “Texture Particles,” Computer 
Graphics Forum (Eurogrpahics 2002), Vol. 21, 
No. 3, 2002. 
[9] F. Dong, H. Lin and G. Clapworthy, “Cutting and 
Pasting Irregularly Shaped Patches for Texture 
Synthesis”, Computer Graphics Forum, Vol. 24, 
No. 1 pp. 17-26, 2005. 
 6
[10] G. Doretto and S. Soatto, “Editable Dynamic 
Textures,” ACM SIGGRAPH 2002 Sketches and 
Applications, 2002. 
[11] A.A. Efros and W. T. Freeman, "Image Quilting 
for Texture Synthesis and Transfer," In 
Proceedings of SIGGRAPH 2001, 2001. 
[12] A. A. Efros and T. K. Leung, “Texture Synthesis 
by Non-parametric Sampling,” In Proceedings of 
IEEE International Conference on Computer 
Vision, 1999. 
[13] C.W. Fu and M.K. Leung, “Texture Tiling on 
Arbitrary Topological Surfaces using Wang 
Tiles,” Eurographics Symposium on Rendering, 
2005. 
[14] M. Haindl and V. Havlicek, “A Simple 
Multispectral Multiresolution Markov Texture 
Model,” In Proceedings of the 2nd International 
Workshop on Texture Analysis and Synthesis, pp. 
63-66, 2002. 
[15] P. Harrison, “A Non-Hierarchical Procedure for 
Re-synthesis of Complex Textures,” In 
Proceedings of Winter School of Computer 
Graphics 2001 (WSCG 2001), pp. 190-197, 2001. 
[16] A. Hertzmann, C. E. Jacobs, N. Oliver, B. Curless 
and D. H. Salesin, “Image Analogies,” In 
Proceedings of SIGGRAPH 2001, pp. 327-340, 
2001. 
[17] Z. B. Joseph, R. E. Yaniv, D. Lischinski and M. 
Werman, “Texture Mixing and Texture Movie 
Synthesis Using Statistical Learning,” In 
Proceeding of SIGGRAPH 2000 Sketch, pp. 
266-266, 2000. 
[18] D. Kim and J. K. Hahn, “Projective Texture 
Mapping with Full  Panorama,” Computer 
Graphics Forum (Eurographics 2002), Vol. 21, 
No. 3, 2002. 
[19] V. Kwatra, A. Schodl, I. Essa, G. Turk and A. 
Bobick, “Graphcut Textures: Image and Video 
Synthesis Using Graph Cuts,” SIGGRAPH 2003, 
2003. 
[20] L. Liang, C. Liu, Y. Q. Xu, B. Guo and H. Y. 
Shum, “Real-Time Texture Synthesis by 
Patch-Based Sampling,” ACM Transactions on 
Graphics, Vol. 20, No.3, pp. 127-150, 2001. 
[21] A. Nealen and M. Alexa, “Hybrid Texture 
Synthesis,” In Proceedings of Eurographics 
Symposium on Rendering 2003. 
[22] E. Praun, A. Finkelstein and H. Hoppe, “Lapped 
Texture,” In Proceedings of SIGGRAPH 2000, pp. 
456-470, 2000. 
[23] P. V. Sander, J. Snyder, S. J. Gortler and H. 
Hoppe, “Texture Mapping  Progressive 
Meshes,” In Proceedings of SIGGRAPH 2001, 
pp.409-416, 2001. 
[24] S. Soatto, G. Doretto and Y. N. Wu, “Dynamic 
Textures,” In Proceedings of IEEE International 
Conference on Computer Vision 2001 (ICCV 
2001), Vol. 2, pp. 439-446, 2001. 
 
    
Keynote Speech                         Poster 
 
二、心得與建議 
 本會議主要是亞洲幾個國家輪流主辦，包括日本、韓國、台灣、新加坡、泰國等。此次會議
在泰國曼谷舉辦，當地天氣相當不錯，交通也很方面。與往年差不多，參加會議的人數還是以日
本和韓國最多，許多是整個實驗室的成員來參加此研討會，主要是他們經費充足，鼓勵學生多參
加研討會，讓學生多培養國際觀。此外，他們在技術研發方面都相當積極，所運用到整合的技術
也愈來愈多，例如影像處理、電腦視覺、電腦圖學等技術相互運用與整合，以開發更新更複雜的
技術。 
 參與此次會議，認識許多其他國家的專家學者，除了經驗交流增加相關研究能力外，對於日
後舉辦國際研討會，將有相當大的幫助。建議政府應多鼓勵研發人員參與國際研討會和國際技術
合作，如此才能提昇技術層次，增加國際競爭優勢。除了可以培養國際觀外，還可以培養與外國
人商討問題的能力等等。另外，政府應多鼓勵產學合作，讓學校與廠商能多合作，開發實用的技
術，增加相關技術的競爭力。最後，政府應多鼓勵相關技術整合的能力，例如多媒體或數位內容
方面的應用，不可能用單一技術來完成，而需要許多相關的技術如影像處理、電腦視覺、電腦圖
學等等整合在一起才能完成。 
 
三、攜回資料 
參加此會議，帶回一片 CD 會議論文集與會議的議程(含論文摘要)。 
)],(),,(),,([),( jiujiujiujiu CrCbY= ,                                                                             
 
and 
 
)],(),,(),,([),( jijijiji CrCbY σσσσ = .                                                                           
 
The absolute difference of the DC value of each I 
frame from the mean in the established background model 
can be easily obtained. Then, the moving object can be 
extracted by comparing the absolute difference against a 
threshold value determined by a scaling parameter  
multiplied by the variance. The equations for the moving 
object detection are defined as follows: 
βt
 
,foreground),(),,(),(),( ∈×>− jijitjiuji χσχ β                                                       
 
and 
 
.background),(),,(),(),( ∈×≤− jijitjiuji χσχ β                                                      
The background model is also adapted to avoid the 
noise and illumination change. The means and variance of 
the DC values are updated as follows: 
 
),()],(1[),(),(),( 1 jiujiwjijiwjiu ttt −×−+×= χ ,                                                    
 
and 
 
),()],(1[)],(),([),(),( 21
22 jijiwjiujijiwji tttt −×−+−×= σχσ , 
 
where μt (i, j) and μt-1 (i, j) are the means of the DC values 
of (i,j)-th 8x8 YCbCr DCT blocks at time t and t-1, 
respectively; ),( jitχ  is the DC value of (i,j)-th 8x8 
YCbCr DCT block at time t; σt (i, j) and σt-1 (i, j) are the 
variances of the DC values of (i,j)-th 8x8 YCbCr DCT 
blocks at time t and t-1, respectively;  is the 
blending weighting function defined as follows: 
),( jiw
 
⎩⎨
⎧
∈
∈=
  foreground ),(       
 background ),(       
),(
ji
ji
jiw
tfg
tbg
χα
χα
,    
                                                             
where bgα  is set at 0.05 and fgα  is set at 0.0125. 
 
 
 
Fig. 1 Flowchart of the proposed moving object detection 
 
 
Fig. 2 Computation of means and variances of the DC 
values of (i,j)-th 8x8 YCbCr DCT blocks over a number of 
static background I frames 
 
 
3. GAIT ANALYSIS AND 
CLASSIFICATION 
 
For gait analysis, motion vectors and velocities of human 
head and body centroids are extracted. 
Motion vectors of inter-block MBs are extracted in P 
and B frames. In a P frame, there are forward-predicted 
MBs containing forward-predicted motion vectors. In a B 
frame, there are three types of MBs: forward-predicted, 
backward-predicted, and bidirectionally-predicted. 
Forward-predicted MBs contain forward-predicted motion 
vectors, backward-predicted MBs contain 
backward-predicted motion vectors, and 
bidirectionally-predicted MBs contain both forward- and 
backward-predicted motion vectors. If MBs in a B frame 
are bidirectionally-predicted, the motion vectors are 
computed by the average of the forward- and 
backward-predicted motion vectors. 
For each 8x8 block of the human region with motion 
vectors, the human region is divided uniformly into (a) 3 
parts and (b) 9 parts. Fig. 3 shows the human region 
divided uniformly into (a) 3 parts; ( 1u , 1v ), ( 2u , 2v ) and 
( 3u , 3v ) are the centroids of the 3 parts and (b) 9 parts; 
( 1u , 1v ), ( 2u , 2v ), ( 3u , 3v ), ( 4u , 4v ), ( 5u , 5v ), ( 6u , 6v ), 
( 7u , 7v ), ( 8u , 8v ) and ( 9u , 9v ) are the centroids of the 9 
parts. 
Then, the average motion vectors ( )(Γku , )(Γkv ) of 
the human region are computed by 
 
regionhuman  in the blocks 8x8 ofnumber  
),,(
)( ∑ Γ=Γ jiuu kk ,               
 
and 
 
region human  in the blocks 8x8 ofnumber 
),,(
)( ∑ Γ=Γ jivv kk ,               
 
where ),,( Γjiuk  and are the horizontal and 
vertical components of motion vectors of k-th part of 
(i,j)-th 8x8 block of 
),,( Γjivk
Γ -th frame; 1 ≤ k ≤ 3 for the human 
