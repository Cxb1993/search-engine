 1
Abstract 
In this project, a particle swarm optimization-
based approach is proposed to determine a desired 
sampling-time range which guarantees minimum 
phase behaviour for the sampled-data system of 
an interval plant preceded by a zero-order hold 
(ZOH). Based on a worst-case analysis, the 
identification problem of the sampling-time range 
is first formulated as an optimization problem, 
which is subsequently solved under a PSO-based 
framework incorporating two particle swarm 
optimizations. The first particle swarm 
optimization searches both the uncertain plant 
parameters and sampling time to dynamically 
reduce the search range for locating the desired 
sampling-time boundaries based on verification 
results from the second particle swarm 
optimization. As a result, the desired sampling-
time range ensuring minimum phase behaviour of 
the sampled-data interval system can be 
evolutionarily obtained. Because of the time-
consuming process that particle swarm 
optimizations generally exhibit, particularly the 
problem nature which requires undertaking a large 
number of evolution cycles, parallel computation 
for the proposed particle swarm optimization is 
therefore proposed to accelerate the derivation 
process.  
 
Keywords: particle swarm optimization, 
minimum-phase, uncertain systems, interval plant, 
parallel computation, sampled-data systems, 
discretization. 
 
1. Introduction 
It is well known that stability can be preserved 
when a stable continuous-time system is sampled 
by a zero-order hold (ZOH). However, there is no 
guarantee that zeros of the sampled system will 
always remain within the unit circle in the z-plane 
(i.e. minimum phase) [1]. In the design of linear 
control systems, the existence of unstable zeros 
makes it difficult to construct some control 
procedures, such as inverse systems, model 
matching systems, and model reference adaptive 
controllers [2]. Therefore, the unstable zeros 
which limit the performance that can be achieved 
when controlling a system should be avoided. 
Unfortunately, there is no simple formula 
governing the mapping of zeros for the sampled 
system even in deterministic systems. An earlier 
discussion about zeros of sampled system [1] 
showed that if there are more than two excess 
poles in the continuous transfer function of the 
plant, the sampled system will be non-minimum 
phase (NMP) if the sampling frequency is 
sufficiently fast. Criteria which guarantee that all 
zeros of sampled transfer functions are inside the 
unit circle have been investigated [1]-[6]. They 
were all based on the observation of Nyquist plot 
of the sampled system. In [1], sufficient 
conditions for retaining stable zeros were given 
both in terms of continuous plant G(s) and in 
terms of the Nyquist curve G(jω), but they are 
quite restrictive. To determine the sampling-time 
range which ensures stable zeros, Fu et al. [4] 
provided an alternative way to obtain the critical 
sampling frequency by using a relay. This 
approach, however, is limited to cases when the 
continuous plant is a stable, minimum-phase 
system. To relieve the abovementioned 
restrictions, criteria for stability of zeros of 
sampled systems were proposed by extending the 
Nyquist method to unstable systems [5]. This 
method which graphically determines the stable 
zeros by examining the Nyquist plot, however, is 
limited to a specified sampling time T only. 
Moreover, if a low-pass plant is considered, the 
criteria which guarantee minimum-phase are 
represented by a nonlinear inequality comprising 
sampling time T and coefficients of the plant. To 
determine the sampling-time range to ensure 
minimum-phase behaviour for the sampled 
system, this method [5] has no choice but to 
eventually resort to numerical methods to solve a 
nonlinear equation of sampling time T. Based on 
symbolic manipulation, a symbolic approach [6] 
was proposed to determine the sampling-time 
range to ensure minimum phase behavior. 
Although this method provides a simpler way in 
solving the minimum phase problem with fewer 
restrictions, it is workable only for deterministic 
systems.  
As far as interval systems [17]-[19] are 
concerned, the problem of determining the 
sampling-time range to ensure minimum phase 
behaviour for the sampled system becomes 
extremely difficult because of the exponential 
nature [7] during the discretization process of the 
interval plant, where the coefficient functions of 
the sampled system involve serious and non-linear 
couplings of the sampling time T and the 
uncertain plant parameters. Due to the highly non-
linear nature, it is extremely difficult to examine 
the behaviour of zeros of the sampled system in 
Nyquist plot as sampling time varies. 
Furthermore, because of the non-convexity 
inevitably involved in the determination of the 
sampling-time range to ensure minimum phase 
behaviour for the sampled system, conventional 
methods generally fail to solve this problem, 
particularly when the interval plant is of higher 
order. Generally speaking, there is still no 
systematic method so far to determine the 
sampling-time range to guarantee minimum phase 
behavior for sampled-data interval systems. 
 3
vectors with highly nonlinear coupling of the 
uncertain interval parameters of ),,( II basGp  and 
the sampling time T. As mentioned earlier, the 
determination of the sampling-time range which 
guarantees minimum phase behaviour for the 
sampled-data interval system is extremely 
difficult because of the discretization of the 
uncertain plant. Existing methods generally fail to 
solve this problem. So far, there is no effective 
numerical method to deal with this problem. It is 
therefore the objective of this paper to propose a 
global optimization scheme based on particle 
swarm optimizations to solve this problem.  
Assume that ( )rr ba ,,sGpr  is a degenerate 
(real) model of the interval plant ),,( II basGp  as 
follows: 
),,(
),(
),(),,(
21
21
II
nr1)r-(n2r1r0r
nr1)r-(n2r1r
r
r
rr
ba
a
bba
sG
asasasasa
bsbsbsb
sD
sNsG
p
nnn
nn
pr
∈
+++++
++++=
=
−−
−−
L
L   (5) 
, where the coefficient vectors 
T
nrrr aaa ],,,[ 10 L=ra  and 
T
nrrr bbb ],,,[ 21 L=rb are consisted of 
degenerate (real) numbers, such that  
niaaaa ii
I
iir ,,2,1,0, ],[ L==∈ +−  (6) 
and  
njbbbb jj
I
jjr ,,3,2,1 , ],[ L==∈ +−  (7) 
, respectively. As a result, the sample-data system 
),,,( TzGG rrprh ba  associated with the 
degenerate plant can be easily obtained as 
follows: 
)T,,z( GG
)T,,z(D
)T,,z(N
)T,,,z(D
)T,,,z(N
c...zczc
d...zdzd
s
),,s(G
)z()T,,,z( GG
ph
H
H
rrr
rrr
nr
n
r
n
r
nr
n
r
n
r
rrpr
rrprh
II
II
II
ba
ba
ba
ba
ba
ba
ba
,
,
,
1
1
10
2
2
1
1
1
=∈
≡+++
+++=
⎥⎦
⎤⎢⎣
⎡⋅−=
−
−−
− Z
  
(8) 
Note that ),,,( TzGG rrprh ba  is said to be 
minimum phase if all its zeros, 
1,,2,1 , −= nizi L , (i.e. roots of ),,,( TzN rrr ba ) 
lie within the unit circle in the z-plane. That is, 
          1,,2,1,1 −=∀< nizi L .  (9) 
Suppose that 1,,2,1 , −= nizNHi L  denotes the 
zeros of ),,,( TzGG ph
II ba . The sampled-data 
system ),,,( TzGG ph
II ba  is said to be minimum 
phase if all zeros, 1,,2,1 , −= nizNHi L , lie inside 
the unit circle in the z-plane. In other words, all 
possible ),,,( TzGG rrprh ba  from within the 
sampled-data system ),,,( TzGG ph
II ba  needs to 
be minimum phase. That is 
II bbaa ∈∈−=∀< rrNHi niz   , ,1,,2,1,1 L    (10) 
The problem can now be re-stated as follows: 
Given the coefficient space II ba , and a pre-
specified sampling time Tc, if there exists a non-
minimum phase ),T,,,z( GG crrprh ba  
II bb ,aa ∈∈∀ rr  , then ),,,( cph TzGG dc  is 
non-minimum phase. 
Although the problem formulation is 
conceptually simple, excessively large search 
space and nonlinearities involved have created 
difficulties in obtaining a satisfactory result by 
using traditional optimization methods. Therefore, 
we need a robust search algorithm to effectively 
solve this problem. Particle swarm optimization, 
with its power as an efficient and robust 
alternative for solving complex and highly 
nonlinear optimization problems, will be used to 
identify the sampling-time range ensuring 
minimum phase behaviour for the sampled-data 
interval system. 
 
3. PSO-based approach for determining the 
sampling-time range 
The evolutionary framework of the proposed 
PSO-based approach is shown in Fig. 2, where 
two PSOs are working together to determine the 
sampling-time range which guarantees minimum 
phase behaviour for the sampled-data interval 
system. In this framework, PSO1 searches both 
the coefficient space II ba ,  and sampling time T, 
in such a way that particles resulting in minimum 
phase are passed to PSO2 for further test while 
those resulting in non-minimum phase will be 
filtered out during the evolution process. PSO2, 
on the other hand, searches only the coefficient 
space II ba ,  to verify if minimum phase condition 
has been met for a specific sampling time Tc 
passed from PSO1 for the sampled-data system 
),,,( cph TzGG
II ba . All of the sampling times in 
a population are recorded for dynamically 
adjusting the search range of sampling time T so 
as to improve the evolutionary efficiency.  
For illustration purpose, a flowchart detailing 
the proposed PSO-based approach is shown in 
Fig. 3. The rightmost block in blue dashed line in 
Fig. 3 is to ensure that at least a particle 
containing a sampling time cT  with all stable 
zeros can be found so that the flag “Verified” can 
be set to “1”. Once the condition “Verified=1” is 
satisfied, PSO1 evolves by evaluating fitness for 
 5
Care should be taken that the proposed 
approach is assumed to locate all of the unstable 
zeros at all times, which is unfortunately not 
always true. In fact, there are two further 
possibilities in Case 2. 
(a). The sampled-data system is non-
minimum phase at sampling time cT  
but PSO fails to find any zero 
residing on or outside the unit circle. 
(b). The sampled-data system at sampling 
time cT  is minimum phase, i.e. Eq.(10) 
is fully satisfied. 
 
Actually, the proposed algorithm can’t 
unambiguously distinguish between Cases (a) and 
(b). Therefore, this approach can only provide a 
necessary condition on the sampling-time range to 
ensure minimum phase for sampled-data systems. 
To improve reliability of the proposed approach, a 
positive tolerance value ε  is used as a 
measurement of the real numerical zero in 
evaluating the fitness function in Eq. (12) during 
the optimization process. A largeεresults in more 
restrictive results, while a small ε provides more 
conservative results for the problem. Another way 
to improve the reliability of the proposed 
approach is to increase the population size and 
iteration number of PSO2 at the expense of a 
longer computation time, which is not desired in 
practice. In this case, parallel processing of PSO2 
is essential to overcome this problem.  
 
C. Parallel processing of PSO2 
Due to the parallelism nature of PSO and the fact 
that the most time-consuming procedure of PSO is 
generally fitness evaluation, architecture for 
parallel processing of PSO2 is proposed in Fig. 4. 
The basic idea of the parallel computation scheme 
is that fitness evaluation in the evolution process 
can be performed in parallel to accelerate the 
computation. Note that the main process of PSO2 
is performed on the master site. According to the 
number of slave, particles in a population are 
evenly divided into sub-populations and 
dispatched to each slave to evaluate their fitness. 
Fitness of particles evaluated by the parallelized 
process on the slave site is constantly polled and 
transferred to the master site via the message 
passing system when finished. With the evolution 
process executed on multiple slaves in parallel, 
evolution efficiency of the particle swarm 
optimization can be significantly improved.  
 
PSO2
Fitness 
evaluation
Sub-population 1
Fitness 
Master Slave 1
Fitness 
evaluation
Sub-population 1
Fitness 
Slave 2
Fitness 
evaluation
Sub-population n
Fitness 
Slave n
 
Fig. 4  Architecture for parallel processing of 
PSO2. 
 
3.2 Evolutionary scheme of PSO1 
Suppose that the sampling-time range which 
guarantees minimum phase behaviour of the 
sampled-data system ),,,( TzGG ph
II ba lies 
between an upper bound Tmax and lower bound 
Tmin. That is,  
],[ ,1,,2,1,,1 maxmin TTTnizz iNHi ∈−=∀< L    (13) 
The objective of PSO1 is to search the coefficient 
space II ba , and sampling time T to evolutionarily 
determine Tmax  and Tmin. 
 
A. Particle representation 
X is a particle in PSO1, defined as: [ ]TaaabbbX nrrrnrrr  1021 LL=   (14) 
, where, njbjr ,,2,1, L=  and niair ,,2,1,0, L= , 
represent coefficients of the degenerate plant ( )rr ba ,,sGpr  in Eq.(5), which lie within the 
perturbation range in Eqs.(6-7). T is the sampling 
time from within a dynamically adjusted search 
range of [TLB, TUB] updated by PSO1 when 
evolution continues. 
 
B. Fitness evaluation 
Assume that the sampled-data system 
),,,( TzGG rrprh ba  corresponding to particle X 
has zeros 1,,2,1 , −= nizi L . Fitness function of 
PSO1 is defined as: 
⎩⎨
⎧
≥∃
∀<=
1 that such  )),(max(
,1 ,0
)(1
ii
i
zizabs
iz
XF   (15) 
The objective of PSO1 is to minimize F1(X) 
subject to Iiir aa ∈ and Ijjr bb ∈ . Note that 
particles with fitness value “0” imply that the 
corresponding sampled system is minimum phase 
only for a particular set of uncertain parameters 
and sampling time T contained in particle X, i.e. 
Eq.(9) is satisfied. However, it’s not sufficient to 
 7
[Tmin, Tmax] tested via PSO2 are demonstrated in 
Figs. 7 and 8. In Fig. 7, sampling time of T = 
0.5792 lying inside the desired range is tested in 
all 10 runs, where the fitness value of F2(X) all 
converges to 0.0002015 in a very consistent way. 
When sampling time T= 2.3999 is used for 
testing, F2(X) converges to 0.0001227 in all 10 
runs. In these two cases where the sampling times 
lie with the desired range, PSO2 can’t find any 
zero on or outside the unit circle.  
In Fig. 8, sampling times slightly outside the 
desired range are tested. When T = 0.5790, fitness 
function F2(X) converges to -0.0000677 after 23 
generations, implying that there exisits at least 
one zero ouside the unit circle. For verification 
purchase, the sampled-data system at T = 0.5790 
is listed below: 
000053.00322.04138.0837.1178.2
000027.0001107.00047.0000725.0006504.0
)(
2345
234
++−+−
++−+
=
zzzzz
zzzz
zGG ph
corresponding to a degenerate plant of: 
121351037517
6.16.29.0)( 2345
2
+++++
++=
sssss
sssGr . 
The zeros of )(zGG ph  are -1.0000677, 
0.6005518, 0.3106033, and -0.0225078, 
respectively, which apparently violate the 
minimum-phase condition.  
When T = 2.4401, fitness function F2(X) 
converges to -0.0000294 after 16 generations, 
indicating that PSO2 finds at least one zero ouside 
the unit circle as well. 
The sampled-data system for T = 2.4401 becomes: 
 
zzzzz
zzzz
zGG ph
0000005.000729.076.2465.2
0000000005.0000014.0006252.004115.004741.0
)(
2345
234
++++
++−+
=
 
corresponding to a degenerate plant of 
121331030021.7517
6.14.29.0)( 2345
2
+++++
++=
sssss
sssGr . 
The zeros of )(zGG ph  are -1.0000294, 
0.1298518, 0.0023371, and -0.0000319, 
respectively, which apparently violate the 
minimum-phase condition. 
 
 
  
 
Fig. 6  Simulation results to derive Tmax and Tmin in 10 different runs. 
 
 9
References 
[1] K.J. Astrom, P. Hagader, and J. Sternby, 
“Zeros of sampled systems,” Automatica, vol. 
20, no. 1, pp. 31-38, 1984. 
[2] Mitsuaki Ishitobi, “Conditions for Stable 
Zeros of Sampled Systems,” IEEE Trans. Auto. 
Contr., vol.37, no. 10, pp. 1558-1561, Oct. 
1992. 
[3] P. Hagander, “Comments on “Conditions for 
Stable Zeros of Sampled System”, IEEE Trans. 
Auto. Contr., vol. AC-38, no. 5, pp. 830-831, 
May, 1993. 
[4] Y. Fu and G. A. Dumont, “Choice of sampling 
to ensure minimum-phase behavior,” IEEE 
Trans. Auto. Contr., vol. AC-34, no. 5, pp. 
560-563, 1989. 
[5] M. Ishitobi, “Criteria for stability of zeros of 
sampled systems,” IEE Proc. Control Theory 
Appl., vol. 141, no. 6, pp. 396-402, 1994. 
[6] C.H. Wang, W. Y. Wang, and C. C. Hsu, 
“Minimum-Phase Criteria for Sampled 
Systems via Symbolic Approach,” IEEE Proc. 
of the 35th Conf., vol. 4, pp. 4333-4338, Dec. 
1996.  
[7] H. Hu and C. Hollot, “Robustness of sampled-
data control systems having parametric 
uncertainty: a conic sector approach,” IEEE 
Transactions on Automatic Control, Vol. 38, 
pp. 1541-1545, 1993. 
[8] Z. Michalewicz, Genetic Algorithms + Data 
Structure = Evolution Program, Springer-
Verlag, 1996. 
[9] D. Goldberg, Genetic Algorithms in Search, 
Optimisation, and Machine Learning, 
Addison-Wesley, 1989. 
[10] R. Krohling and J. Rey, “Design of optimal 
disturbance rejection PID controllers using 
genetic algorithms,” IEEE Transactions on 
Evolutionary Computation, Vol. 5, No. 1, pp. 
78-82, 2001. 
[11] Chen-Chien Hsu and Chih-Yung Yu, 
“Design of optimal controller for interval 
plant from signal energy point of view via 
evolutionary approaches,” IEEE Transactions 
on Systems, Man, and Cybernetics-Part B, 
Vol. 34, No. 3, pp. 1609-1617, 2004. 
[12] Chen-Chien Hsu and Shih-Chi Chang, 
“Tolerance Design of Robust Controllers for 
Uncertain Interval Systems based on 
Evolutionary Algorithms,” IET Control 
Theory & Applications, Vol. 1, No. 1, pp. 24-
252, Jan., 2007. 
[13] Chen-Chien Hsu, Shih-Chi Chang, and Chih-
Yung Yu, “Multiobjective Evolutionary 
Approach to the Design of Optimal 
Controllers for Interval Plants Based on 
Parallel Computation,” IEICE Transactions 
on Fundamentals of Electronics, 
Communications and Computer Sciences, 
Vol.E89-A, No.9, pp.2363-2373, Sep. 2006. 
[14] J. Renders and S. Flasse, “Hybrid methods 
using genetic algorithms for global 
optimization,” IEEE Transactions on 
Systems, Man, and Cybernetics-Part B, Vol. 
26, No. 2, pp. 243-258, 1996. 
[15] P.J. Fleming and R.C. Purshouse, 
“Evolutionary algorithms in control systems 
engineering: a survey,” Control Engineering 
Practice, Vol. 10, pp. 1223-1241, 2002. 
[16] L.R. Pujara, “On computing stabilizing 
controllers for SISO interval plants,” in Proc. 
American Control Conf., Arlington, VA, pp. 
3896–3901, 2001. 
[17] J. Ackermann, Robust Control - Systems with 
uncertain physical parameters, Springer-
Verlag, Berlin, 1993. 
[18] B. Barmish, New Tools for Robustness of 
Linear Systems, Macmillan Publihing 
Company, New York, 1994. 
[19] S.P. Bhattacharyya, H. Chapellat, and L. 
Keel, Robust Control – The Parametric 
Approach, Prentice Hall, 1995. 
[20] Fengdan Dong, Youyi Wang, and Jianying 
Zhou, “Robust ∞H  control based on model-
matching for track-following system of 
optical disk drive,” Proceedings of the 
American Control Conference, Denver, USA, 
June 2003, pp. 713-718. 
[21] Fengdan Dong, Youyi Wang, and Jianying 
Zhou, “Track following control design for 
ODDs by employing repetitive two-degree-
of-freedom control scheme,” IEEE 
Transactions on Consumer Electronics, Vol. 
49, No. 4, pp. 1186 - 1195, 2003. 
[22] Avraham Levkovich, Ezra Zeheb, and Nir 
Cohen, “Frequency response envelopes of a 
family of uncertain continuous-time systems,” 
IEEE Transactions on Circuits and Systems, 
Vol. 42, No. 3, pp. 156-165, 1995. 
[23] Leang-San Shieh, Xian Zou, and Norman P. 
Coleman, “Digital interval modeling and 
hybrid control of uncertain systems,” IEEE 
Transactions on Industrial Electronics, Vol. 
43, No. 1, pp. 173-183, 1996. 
[24] Leang-San Shieh, Xian Zou, and Jason S. H. 
Tsai, “Model conversion of continuous-time 
uncertain systems via the interval geometric-
series method,” IEEE Transactions on 
Circuits and Systems I, Vol. 43, No. 10, pp. 
851-854, 1996. 
[25] Jung-Ho Moon, Moon-Noh Lee, and Myung 
Jin Chung, “Repetitive control for the track-
following servo system of an optical disk 
drive,” IEEE Transactions on Control 
Systems Technology, Vol. 6, No 5, pp. 663-
670, 1998. 
