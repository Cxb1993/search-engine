 2 
convenience. However, some disadvantages 
of association criterion in IEEE 802.11 are 
revealed when there are more and more 
users join in the wireless network. In 
original design of IEEE 802.11, every 
station (STA) must contend for the channel 
usage if it has data to transmit. And the 
contention window would be increased by 
an exponential law if collisions continue to 
occur. Therefore, how to alleviate the 
congestion situation and distribute load 
among all APs is critical for those IEEE 
802.11 wireless network designed and 
deployed for large number of users. 
In recent years, many studies [1-3] 
focus on the number of STAs associated 
with an AP as the load index of the AP. 
Some research works also take the total 
throughput of an AP as the load index. 
However, the load indexes can not reflect 
the accurate load of an AP because of the 
fluctuating characteristic in the physical 
layer of the wireless network.  
In the project, we propose a new load 
index which takes into account of the defer 
time during the contention and the average 
transmission overhead evaluated via a 
probabilistic model. STAs are allowed to 
associate with an AP dynamically and the 
distributed load-balancing algorithm can be 
executed by all APs to reach better load 
balancing in a large and congested Wireless 
Local Area Network (WLAN) environment. 
Moreover, an adaptive rate control scheme 
using bandwidth estimation [4-9] to adjust 
the transmission rate of real-time 
multimedia applications is also presented. 
三、無線網路系統架構與負載指標 
In this section, an architecture for IEEE 
802.11 wireless local network and the 
algorithms for each component are 
presented. 
3.1 System Architecture 
The assumed system architecture is as 
shown in Fig. 1. There are three basic 
components in our wireless network, 
namely STAs, APs, and routers. A subnet 
consists of a router and APs connected with 
this router. Alternatively, we can combine 
the function of AP and router to form an 
AP-Router, or replace the AP by a wireless 
switch, and they are also functional in our 
model. Each STA can associate with one AP 
at one time. The circle centered by an AP is 
the coverage of the AP. In order to simplify 
our model, we assume the transmission 
power and the coverage of all APs are the 
same. Each AP would be connected with a 
router by wired line. The wired network can 
be 10/100 Mbps Ethernet or others, and we 
assume that the bottleneck of this network 
is located in wireless. In Fig. 1, routers 
connect to a gateway router in order to 
access the Internet. 
We assume each STA is equipped with 
an agent that scans all channels actively by 
its Network Interface Card (NIC) and 
periodically sends the Association 
Information to AP which it associated with 
at present. We call the AP as the serving_AP 
and an example of Association Information 
is shown in Table 1. All APs have the same 
capacity and are operating in infrastructure 
mode. By the reason of simplification, we 
assume that all the channels of APs are 
non-overlapped and independent, e.q. 
 4 
Fig. 3. AP’s Internal Architecture. 
In the following subsection, we describe 
the algorithms for each component. 
3.2 Definition of the Load Index 
From some header information, we 
could derive a probabilistic model to 
evaluate the transmission cycle time when a 
DATA is transmitted. We assume that there 
are x bits DATA from IP layer waiting for 
transmission. And the channel is 
time-stationary. In other words, we assume 
the Bit Error Rate (BER), p, of the channel 
is fixed. To our best knowledge, we find 
that RTS/CTS mechanism of 802.11 is 
rarely in used actually. Therefore in our 
model, we assume that RTS/CTS 
mechanism is not used. 
Let Di is the event that transmit DATA 
after i-1 times of failed retransmission and 
Ai is the event that receiver respond an ACK 
after receiving the i-th transmission DATA 
correctly. And we also let SDi be the state 
when Di has occurred and SAi be the state 
when Ai has occurred. We can illustrate the 
corresponding state transition as in Fig. 4. 
Where SD1 is initial state of transmission, 
and Success or Fail denotes as successful 
transmission state or failure transmission 
state respectively, and they are absorption 
states of transmission. And we denote the 
Data Error Rate and the ACK Error Rate as 
DER and AER respectively. Furthermore, 
we could compute the actual transmission 
time which excludes back-off and spacing 
time in IEEE 802.11 standard, for a DATA 
packet, TD.  
Fig. 4. State Transitions within a 
Transmission Cycle. 
According to Fig. 4 and derivation 
formulas above, we could compute a 
transmission cycle time, denoted as T, via a 
probabilistic model. The notation P(E ) is 
probability of the event E such as Di or Ai. 
From definition of Di, D1 is the initial event 
and P(D1) equals 1 apparently. And the 
expected transmission cycle time, E(T), can 
be compute via the following equations. 
 
 
 
 
where P( i-1 th ACK is error | Ai-1) is the 
conditional probability if (i-1)-th ACK is 
error when the (i-1)-th ACK has been 
transmitted in a transmission cycle and the 
probability is equal to AER, P(Error | Di-1) 
is equal to DER ,and similarly P(Correct | 
Di-1) is equal to 1-DER . 
DERAP −= 1)( 1
{2,3,4}i   )(*)|1(             
)(*)1 ()(
11
11
∈−+
−=
−−
−−
ii 
ii i
DPDerror th DATAiP
APerror|A th ACKiPDP
{2,3,4}i   )(*)|()( ∈= iii DPD  correct i th DATAPAP
[ ]∑
=
+++=
4
2
1 )(*)(*)(*)(
i
iAiDAD APTDPTAPTTTE
 6 
formulate the distribution as the normal 
distribution by the central limit theorem 
because of there are thousands of 
transmission. 
3.3.3 Simulation Environment and 
Queueing Model 
The targeted simulation environment is 
shown in Fig. 5. There are 100 STAs in a 
40*40 m2 room and 4 APs is located at the 
corners of the room. The STAs are located 
in the room randomly with uniform 
distribution. And the STAs would choose 
the AP to associate with, using the 
maximum RSSI criterion at the beginning. 
There is at least one AP which can be 
associated for each STA. All APs have their 
own application and all traffic would pass 
through the 4 APs by the pure IEEE 
802.11b. 
 
Fig. 5. Simulation Scenario. 
The C simulation program is based on 
a queueing model. We show our program 
architecture as Fig. 6. There is a traffic 
generator such as VoIP or Web application. 
Each one of STA has its own traffic 
generator defined by the application. And 
each STA has its queue for preserving the 
packets which is waiting for transmission. 
There are 4 APs in the program architecture 
and we can model these APs as servers. 
Each AP has its own STAs associated with 
it and the AP has to process the packets 
coming from these STAs. The service time 
in the queueing model of Fig. 6 is equal to 
the delay time described in section 3.3.2. If 
the channel is idle, the coming packet could 
be served immediately, or it would be 
blocked and wait in queue if the channel is 
busy. Once the packets can pass through the 
gateway router, the router would analyze 
the traffic and report the statistics to the APs 
periodically. 
 
Fig. 6. Program Queueing Model. 
3.4  Scenario for Web Traffic and VoIP 
Traffic with Random Waypoint 
Model [12] 
In this section, we would combine the 
Web and VoIP traffic into our simulation 
and verify the performance the DAWLOB if 
there are two types of different traffics. In 
addition, we also add a mobility model into 
VoIP traffic to better fit the practical 
situation. 
As shown as Fig. 7, we illustrate the 
number of on-going calls if DAWLOB is 
not used. From Fig. 7, we can find out the 
number of calls are totally unbalanced 
 8 
From the results of this simulation, we 
can conclude that the user-based load index 
can be used to improve the quality of VoIP 
quality and keep packet delay at a low level. 
However, when one compares these two 
algorithms, obviously DAWLOB has better 
performance than the user-based load index 
obviously shown in Fig. 10 and 11. 
Fig. 10. VoIP MOS Value v.s. Simulation 
Time when User-based Load Index is 
activated. 
Fig. 11. The Ratio of Unacceptable VoIP 
Quality (MOS<3) v.s. Simulation Time 
when User-based Load Index is activated. 
 
四、頻寬估測技術與多媒體速率控制機制 
In this section, we will discuss that 
how to implement the theoretical and 
mathematical formulas for the measurement 
techniques of estimating available 
bandwidth in wireless LAN. Next, we 
design an adaptive rate control scheme for 
real-time video transmission in wireless 
LAN. Eventually, the simulation results are 
present. 
4.1 Calculate the gaps of packet pairs for 
the Packet Pairs/Train Dispersion (PPTD) 
method [8] 
In order to correct responding the state 
of path by observing the arrival-time gaps 
of probe packet receiving in the receiver, 
the sending gaps of the probe packets 
should be as small as possible in the sender. 
When the packets are received by the 
receiver, it should record the system time of 
the packet arriving, and the sequence 
numbers of the probe packets received. If 
the sequence numbers of the probe packet 
pair received are in order, we could 
calculate the gaps between the received 
packets by using the record of each 
receiving time: 
Gapmeasure = Treceiving, i+1 – Treceiving, i                                                
The Treceiving, i and Treceiving, i+1 are the 
recorded arrival-time of the probe packets 
that the sequence numbers of them are i and 
(i +1). The Gapmeasur is the difference of 
Treceiving, i and Treceiving, i+1. 
If the sequence numbers of the probe 
packet pair received are discontinuous, we 
could know that there are packets losing on 
the wireless path. After the discriminating 
of the reason of packet losses which is 
congestion or link error, we could record 
the number of congestion-loss packets, and 
the numbers of error packets respectively. 
Then we could calculate the congestion loss 
 10
are the variant values. 
In the PPTD measuring techniques, the 
value of gap between probe packets 
received in the receiver will be affect by the 
system internal delay. Let T’receiving, i and  
T’receiving, i+1 are the system time when the 
packets which‘s sequence number are i and 
i+1 arriving at the adapter of receiver. The 
τ receiving, i and τ receiving, i+1 are the system 
internal delay arising when the packets 
forwarding from the adapter to the 
application layer respectively. Then Treceiving, 
I and Treceiving, i+1 could be rewrite as follow: 
T
 sending, i = T’receiving, i + τ receiving, I 
Tsending, i+1 = T’receiving, i+1 + τ receiving, i+1 
Fig. 12 shows the transmitting process 
of the probe packets sending from the 
sender to the receiver in PPTD measuring 
process. By discussing above, the system 
internal delays will product a variant 
redundant term in the measuring value of 
gap between arrival packets. We assume 
that the system internal delays are the 
random variables which are independent 
and identical distribution (I.I.D). The 
probability distribution of the system 
internal delays are normal distribution 
which’s mean and variance are μ andσ2. 
 
Fig. 12. the transmitting process of the 
probe packets sending from the sender to 
the receiver in PPTD measuring process. 
In the similar way, the transmitting 
process of the probe packets sending from 
the sender to the receiver in TTOP 
measuring process can also be shown in Fig. 
13.  
 
Fig. 13. the transmitting process of the 
probe packets sending from the sender to 
the receiver in TTOP measuring process. 
 
4.4 Algorithm of the adaptive rate 
control using bandwidth estimation 
 12
average puts more weight on the 
MeasureBW than on the old samples. This 
is reasonable due to the fact that the more 
recent samples better reflect the current 
available bandwidth in the network. 
 When the streaming server begins to 
transmit the streaming flow to client, the 
bandwidth estimation process will be 
continued to monitor the changes of the 
bandwidth in the wireless path. Because 
most part of available bandwidth is directly 
used to transmit the video streaming flow, 
the new measured value of available 
bandwidth, MeasureBW, now is equal to the 
difference between the available bandwidth 
and the transmission rate of video streaming. 
We use the term ReserveBW as the value 
subtracted the transmission rate of video 
streaming from available bandwidth. Fig. 
15 shows the relationship among the terms 
discussing above. When there is not cross 
traffic flow or significant new interferences 
in the air, the value of ReservedBW should 
vary only slightly, but may be frequently 
due to the properties of wireless network. 
According to the discussion above, like 
AvailableBW, we update the ReservedBW 
using following equation: 
ReservedBW = ReservedBW‧(1 - α) + 
MeasureBW‧α                   
 
 
Fig. 15. The relationship among the 
capacity, AvailableBW, and ReservedBW 
when there are the streaming flow and cross 
traffic flow in the transmission path. 
 
 Following we will describe the 
complete algorithm of the adaptive rate 
control scheme using bandwidth estimation 
in detailed. In the initial state, when the 
streaming server prepares to transmit the 
streaming traffic to the client, we first start 
the bandwidth estimation process. Using the 
values of AvailableBW in the path between 
server and client, we can select the 
appropriate transmission rate making the 
good quality of the streaming service to 
present. In order to avoid rapid change of 
the transmission rate which may degrade 
the quality of video service, the chosen 
value of the transmission rate usually is 
lower than the value of AvailableBW, and 
the value of ReservedBW can be maintained 
as the safety zone. In the algorithm of rate 
control scheme, we set the ReservedBW as β. 
When the available bandwidth varies only 
slightly, the transmission rate will not be 
affected directly by preserveing the value of 
ReservedBW, β, and then the quality of 
multimedia service will be kept in a good 
level. 
 After transmitting the streaming traffic 
to client, the bandwidth estimation process 
keeps to measure the value of MeasuredBW 
in the transmission path, and update the 
value of ReservedBW. When the value of 
ReservedBW decrease a lot and is lower 
than the lower bound of the general 
variation, we could know the available 
bandwidth in the path is reduced due to the 
competing of wireless median with the 
 14
adaptive rate control algorithm using the 
bandwidth estimation technique. 
 
4.5 Simulation Results  
4.5.1 The setup of experiment 
environment for adaptive rate control 
scheme using bandwidth estimation 
Fig. 17 shows the architecture of 
experiment environment for the adaptive 
rate control scheme. 
The experiment continuously estimates 
the available bandwidth every three seconds 
until the time reaches 180 seconds. The 
client transmits probe packets, and 
streaming server receives probe packets and 
calculates the estimating values of available 
bandwidth. After the bandwidth estimation, 
streaming server implement the rate control 
scheme using the estimating results for the 
UDP traffic transmitted from streaming 
server to client. Table 3 shows the related 
setting of the rate control scheme. Finally, 
we add the cross traffic whose rate is 
2Mbps when the experiment time is 60 
second, and transmit it continuously until 
the experiment time reaches 120 seconds. 
 
Fig. 17. The architecture of experiment 
environment for adaptive rate control 
scheme using bandwidth estimation. 
 
ReservedBW  2 
α 0.675 
μ1  1.95 
μ2  1.6 
γ 3 
Table 3. The flow chart of rate control 
scheme in our experiment.  
 
4.5.2 Experiment results of adaptive rate 
control scheme using bandwidth 
estimation 
Fig. 18 shows the experiment results of 
the rate control scheme using bandwidth 
estimation. We could observe cleanly that 
streaming server decreases the transmission 
rate of UDP traffic immediately to avoid the 
network congestion according to the 
measuring values of bandwidth estimation 
when there is cross traffic in experiment 
environment. When the transmission of 
cross traffic finishes at 120 seconds, the 
server increases the transmission rate of 
UDP traffic fast to improve the transmission 
0
1
2
3
4
5
6
7
8
0 15 30 45 60 75 90 105 120 135 150 165 180
Time (sec)
M
bp
s
Measuring Bandwidth
Available Bandwidth
Rate of Application
Cross Traffic 
 16
“Load balancing in overlapping 
wireless LAN Cells,” Communications, 
2004 IEEE International Conference, 
pp. 3833-3387 Vol. 7, June 2004. 
[4] J. Tang, et al., "RCS: A Rate Control 
Scheme for Real-time Traffic in 
Networks with High Bandwidth-Delay 
Products and High Bit Error Rates", 
Proceeding of the 20th Annual Joint 
Conference on the IEEE Computer and 
Communications Societies, INFOCOM, 
vol. 1, pp. 114-122, April. 2001. 
[5] Hoang, D. Reschke, “An adaptive 
control scheme for multimedia flows 
over wireless networks,” Proceedings 
of the 5th Biannual on World 
Automation Congress, vol. 13, pp. 
325-330, 2002. 
[6] P. van Beek, S. Deshpande, H. Pan, 
and I. Sezan, “Adaptive streaming of 
high-quality video over wireless 
LANs,” Visual Communications and 
Image Processing 2004 (VCIP 2004), 
Proc. SPIE, vol. 5308, pp. 647-660. 
[7] Tong, Gao, Huang, “A novel rate 
control scheme for video streaming 
over wireless networks,” Proceedings 
of the 3rd International Conference on 
Image and Graphics, pp. 369-372, Dec. 
2004. 
[8] Hoang, Z. Shao, M. Fujise, “A New 
solution to Estimate the available 
Bandwidth in MANETs,” Proceedings 
of IEEE 63rd Vehicular Technology 
Conference, 2006 on VTC 2006-Spring, 
vol. 2, pp. 653-657, May. 2006. 
[9] 鐘政峰 “On the Estimation Method of 
Available Bandwidth in Wireless 
Channels” Master thesis of Graduate 
Institute of Communication 
Engineering, National Taiwan 
University, June. 2002. 
[10] T. S. Rappaport, Wireless 
communications, principles and 
practice, 2nd edtion, Prentice Hall, Dec. 
31, 2001. 
[11] W. Xiuchao, “Simulate 802.11b 
Channel within NS2,” SOC, NUS. 
[12] C. Bettstetter and C. Wagner. ”The 
spatial node distribution of the random 
waypoint mobility model,” in 
Proceedings of German Workshop on 
Mobile Ad Hoc networks (WMAN), 
Ulm, Germany, March 2002. 
 
人員(如 Intel , Qualcomm) 的深度參與，也是此會議的一大特色。 
 
至於 CTIA Wireless 2009 的電信展，則以產品系列為區分標的，
包括無線網路系統 (如 WiMAX, LTE)、子系統  / 小型系統 (如
Repeater)、元件晶片組，網路服務應用套件，手機，以及網路規劃服
務等，其中最令參觀者印象深刻的是展場中設有 LTE 以及 WiMAX
專區，除展出最新之產品外，也提供 Live Demo, 頗有讓 WiMAX 及
LTE 廠商當場拼場的味道，其中我特別仔細參觀 WiMAX 專屬區，發
現台灣產品不多，且仍然是以美、韓產品為主流，且由大廠主導。另
外 Nortel 展示了 WiMAX 的高速傳輸，採用 MIMO，速率近 20Mbps
以上，令人印象不錯。LTE 展示的歐洲廠商則以 Low Latency 為號召，
方便 Mobile 使用者玩線上即時遊戲。 
 
筆者也發現兩項會議的討論議題也十分符合產業實際需求，例
如 WCNC 論壇討論題綱為： 
 
1. 語音營收下滑時，行動業者如何藉加值服務增加營收? 
(How will Mobile Operators Increase ARPU with Declining 
Voice Revenue?) 
2. WiMAX 網路中服務品質保障的相關商業機制、維運及技
術挑戰，題否已接近實際可行? ( Realizing QoS in WiMAX 
Networks：Business, Operational, and Technical Challenges 
How Close are We to Reality? )  
3. 未來行動網際網路的願景與挑戰為何? ( Future of Mobile 
Broadband Internet and Challenges) 
 
Design of a Packet Scheduling Scheme for Downlink Channel in 
IEEE 802.16 BWA Systems 
Tsung-Yu Tsai                       Zsehong Tsai 
Networks and Multimedia Institute Graduate Institute of Commun. Engineering   
Institute of Information Industry                         National Taiwan University 
            Taiwan                                           Taiwan 
         tyt@nmi.iii.org.tw                                ztsai@cc.ee.ntu.edu.tw
Abstract-  A packet scheduling scheme in the 
downlink channel for IEEE 802.16 is proposed. 
The scheme can be implemented in the base 
station and is compatible to the MAC protocol 
of IEEE 802.16. In order incorporate the 
properties of location-dependent and burst 
error of wireless channels, we design a novel 
packet scheduling algorithm named the 
Credit-Based Algorithm (CBA) to guarantee 
QoS of both real-time and non-real-time 
services. Simulation experiments are conducted 
to evaluate the performance of the proposed 
scheme. Based on the simulation results, we 
show the CBA scheme is capable of providing 
significantly improved system capacity, 
guaranteeing the packet delay for real-time 
services, and maintaining fair capacity 
allocation to non-real-time services.   
I. INTRODUCTION 
Currently, five various types of services,  
each supporting a different level of Quality of 
Service, have been defined in the latest release of 
the standard (IEEE 802.16-2005)[1] to satisfy a 
variety of applications supported in near future. 
However, the IEEE 802.16-2005 standard does not 
specify the packet-level scheduling mechanism for 
the base station. As a result, such down link packet 
scheduling scheme, one of the crucial technologies 
to provide the guarantee of QoS of the system 
level, may still be treated as an independent 
component of an 802.16 network system and is yet 
to be investigated from the system level.  
In fact, although there have been so many 
research works [4-7] in the area of packet-level 
scheduling done in the recent years, a packet 
scheduling scheme specifically completely  
designed for efficient operations within an IEEE 
802.16 MAC architecture is relatively few. 
Wongthavarawat and Ganz[3] completed an 
important reference work which provides a 
feasible solution to solve this problem. In [3], a 
classic scheduler-transmitter based two-tier 
hierarchical structure was shown to have the 
advantage of flexibility and was able to protect the 
QoS of the delay-sensitive traffic such as UGS 
connections or rtPS connections by simply 
assigning them higher priority. However, it also 
had the main drawback in the fairness between 
service types. As a result, it could sacrifice the  
QoS of the flows with lower priority when the 
flows with higher priority encountered bad 
channels. And the main cause of this draw back 
should be the lack of the cross-layer design: no 
feedback mechanism from the transmission 
operation at the physical channel to the MAC layer 
scheduling operations.    
Based the performance of [3], one can also 
argue that if a classic packet scheduler such a 
WFQ[1] is employed in other 802.16 BS, it may 
also encounter a similar drawback. Unless, the 
cross-layer design concept is employed, we 
believed the overall system performance may 
always be limited with any independently 
operating scheduler. In this paper, we thus propose 
a new QoS-based packet scheduling scheme 
specifically designed for IEEE 802.16 networks. A 
novel packet scheduling algorithm is adopted in 
our scheme to consider the bursty and 
location-dependent error information regarding the 
wireless transmissions, and to satisfy the QoS 
requirement flows with different service types 
simultaneously. 
The rest of this paper is organized as follows. In 
section II, we introduce our system model. Then 
we discuss our proposed packet scheduling 
scheme and the credit-based algorithm in deep in 
section III. In section IV, we evaluate the system 
performance by simulation experiment, the 
simulation results are shown in this section. 
Finally, we conclude this research in section V.   
II. SYSTEM MODEL 
A. Environment 
In this study, we consider an IEEE 802.16-2005 
network operating in OFDMA physical layer. The 
network architecture is PMP(point to multipoint), 
including one BS and several MSs which are in 
different locations. We address the scheduling of 
the downlink traffic. The duplex mode is TDD. 
The ratio of downlink and uplink subframes is 
assumed to be fixed and the sub-carrier 
permutation mode is kept not changed. Thus, the 
available slots for scheduling of downlink traffic 
can be regarded as constants.
B. Frame-by-frame Operation Scheme 
We assume the IEEE 802.16 operates as a 
time-slotted system. For generality, we use “slots” 
as a general resource allocation unit and “frames” 
as a general time units for description of traffic 
characteristic and system capacity in the entire 
system. In this study, we assume our system has a 
1525-3511/08/$25.00 ©2008 IEEE
This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the WCNC 2008 proceedings.
1453
Authorized licensed use limited to: Institute for Information Industry. Downloaded on February 2, 2009 at 04:15 from IEEE Xplore.  Restrictions apply.
three virtual queue (VQ) in our system with strict 
priority. They are VQ for RT retransmission 
(VQ-RTRX), VQ for NRT retransmission 
(VQ-NRTRX), and VQ for first time transmission 
(VQ-TX) from the highest priority          
Fig. 1 The system architecture of proposed packet scheduling 
scheme 
to the lowest priority. The three virtual queues are
the inputs of the credit-based scheduler in the 
second stage. The Credit-based scheduler checks 
the packets in the virtual queues sequentially from 
the highest priority to lowest priority and 
determines whether to schedule it by credit-based 
algorithm.  The packet not received successfully 
due to channel error is moved to one of the 
retransmission VQ according to its service group.
C. Credit-based scheduler 
The Credit-based scheduler determines which 
packet should be scheduled to transmit in the next 
frame. The fundamental operation of the 
credit-based scheduler is as follows.   
Assume that there are B slots available for 
downlink traffic each frame. Each flow i maintains 
a parameter credits ci . The credits of every flow i
has a fixed credit incremental rate ri (slots/frame). 
At every beginning of a frame, the credits of flow i
is increased by ri slots. When a packet is 
transmitted, it should consume corresponding 
credits. Thus, ri can be regarded as the protected 
capacity of flow i. Then, the basic principles of 
scheduling are as follows: 
1. The packet which has sufficient credits has 
the higher priority, or it is assigned a lower 
priority. 
2. For the packets with the same priority, the 
scheduling order is according to the order in 
WFQ scheduler 
Based on the principles stated above, the 
processes of the packet scheduler in each 
scheduling cycle can be divided into two phases. 
The first phase is the packet selection procedure.
The second is the debt allocation procedure. In the 
first phase, the scheduler checks the packets in 
each virtual queue. If a packet has sufficient credit, 
then it is scheduled for transmission; it will be 
skipped, otherwise. After all the packets are 
checked, if there are still available slots in the next 
frame, the scheduler enters the second phase. 
During the second phase, the scheduler checks the 
packets which are not scheduled in the first phase. 
If there are sufficient slots to transmit the checked 
packet, the packet will be scheduled, and the 
over-consumed credits are called debt. The debt is 
allocated to other RT flows in proportional to their 
weight. Here, we prefer to give RT flows more 
opportunity to increase their credits. Since if we 
clean RT packet as soon as possible, it is more 
likely to allocate remained resource to NRT flows, 
and meet the QoS requirement of both. The pseudo 
codes of the packet selection procedure and the 
debt allocation procedure are shown in Figure 2.        
Fig. 2 The pseudo code of the packet selection procedure and 
the debt allocation procedure
  The provisioning of credit incremental rate 
alters the system performance significantly. We 
suggest that ri is set toʳ Įiʽbi, where Įi is the 
protecting factor of flow i. It is a value larger than 
or equal to 1. bi is the minimum required capacity 
of flow i. It is defined as the minimum required 
capacity need to be reserved for flow i to satisfy its 
QoS requirement. For RT flows, the QoS matrix is 
the tolerable delay, and for NRT flows, the QoS 
matrix is the minimum reserved data rate. bi can be 
calculated as follows: 
...
...
),,( 111 Dλδ
),,( 222 Dλδ
),,( iii Dλδ
1iλ +
2iλ +
nλ
This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the WCNC 2008 proceedings.
1455
Authorized licensed use limited to: Institute for Information Industry. Downloaded on February 2, 2009 at 04:15 from IEEE Xplore.  Restrictions apply.
Experiment  2: Test of Voice Quality 
To further evaluate the real-time performance of 
CBA scheme, we test the quality of 35 VoIP in this 
experiment. The setting of parameters of flows and 
the tested system is shown in Table 3 and Table 4, 
respectively. Please note that the assumption of 
overhead in this experiment is larger than that of 
the previous experiment. In a network dominated 
by VoIP traffic, the number of users scheduled 
per-frame may be larger than that by other services, 
because of the small packet size and low data rate 
in VoIP flows. Thus, it may introduce more 
overhead, especially the overhead of MAP 
messages, which increases linearly as the number 
of scheduled users increases.  This system can 
provide a peak downlink rate of 4.032 Mbps. 
Besides, the channel model of each flow is the 
same as that of the previous experiment. 
  For providing a more realistic evaluation of the 
quality of voice, we adopt Mean Opinion Score 
(MOS) [8] as the performance index which is a 
widely used benchmark for evaluation of voice 
quality. MOS is a value ranging from 1.0 to 5.0. In 
general, MOS larger than 4 means excellent 
quality, 3.0-4.0 means acceptable quality, below 
3.0 means poor quality. 
Table 5 shows the average MOS of all VoIP 
flows and the ratio of the time with MOS>3, 
denoted as R(3). We can find that our proposed 
packet scheduling scheme outperforms the FIFO 
(with WFQ) design and the average MOS is 4.1 
which is an excellent level of voice quality. The 
average MOS of the FIFO system is 2.4, which is 
much lower than that of our scheme and far from 
the acceptable level. About 93% of the time, the 
voice is in acceptable quality in our scheme, and 
only 22.75% of the time, the voice is in acceptable 
quality in the system with FIFO. 
Table 3. The configuration of the flows in experiment 2 
Table 4. The system parameter used in experiment 2 
Table 5. The summary of voice quality in experiment 2 
Experiment 3: Integrated Services with RT 
services and NRT services 
In this experiment, we investigate the 
performance of a general integrated service 
network using the CBQ scheduling scheme. The 
simulation scenario is 4 FTP sessions as the 
background traffic. And we regulate the number of 
IPTV sessions from 5 to 9 to observe the effect to 
the system performance. The setting of parameters 
of flows is shown in Table 6. Other system 
parameters are the same as that in experiment 1. 
We concern two properties of the NRT services. 
One is the effective throughput which is the 
average amount of data (slots) successfully 
received by the receiver of a flow in a frame. 
Another is the Fairness Index which is defined as 
follows: 
                          
                                  (2)                    
where Si and Pi is the normalized effective 
throughput and normalized protected  capacity 
(slots/frame) of a non-real-time flow i respectively. 
The smaller the Fairness Index, the smaller the 
variation between the services received by each 
flow. In other words, smaller fairness index 
implies better fairness. 
Table 6. The configuration of the flows in experiment 3
Fig. 4 and Fig. 5 show the average packet loss rate 
of all IPTV flows and the average throughput of 
all FTP flows with different number of IPTV flows. 
The average packet loss ratio suffered in the FIFO 
system is always higher than 25%. Obviously, the 
quality of the IPTV stream is far from the 
acceptable level. Though FIFO has achieved the 
highest FTP throughput in this experiment, it 
cannot guarantee the QoS of any RT flow.  On 
the contrary, the priority queue uses all the system 
capacity to sustain real-time services. When the 
real-time traffic is heavy, the priority design uses 
most of the capacity to serve packets of real-time 
flows and it also starves the non-real-time flows. 
As a result, the average throughput is much lower 
than that of the other two, the usage of its channel 
capacity becomes inefficient, and the packet loss 
ratio of IPTV flows is also higher than that of 
CBA. Among all 3 systems, CBA is the system 
that achieves the most efficient usage of system 
capacity and successfully grants protection to 
non-real-time flows. 
  Since we are also interested in the efficiency 
of system channel capacity, we introduce a metric 
called System Utilization, for performance 
comparison. The System Utilization is defined as  
j
j
i
i
Sji P
S
P
SndexFairness I
NRT
−=
∈,
max
This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the WCNC 2008 proceedings.
1457
Authorized licensed use limited to: Institute for Information Industry. Downloaded on February 2, 2009 at 04:15 from IEEE Xplore.  Restrictions apply.
