for dealing with communication issues such as packet loss,
retransmission, and routing. Third, they revise the IA repeatedly
and have more chances to commit a programming mistake in
comparison to the IA in a computer without any network
function. For example, they may mark or comment on some
subroutines for achieving a certain network mechanism, but
forget to restore or hide the subroutines when testing other
different network mechanisms.
Accordingly, the IA developers need a mechanism to free them
from the extra burdens of achieving distributed computing in the
IA. More speciﬁcally, the IA developers: (1) do not want to learn
other knowledge unrelated to the IA design, (2) do not have to
change the programming style of the IA for networking, (3) do not
need to modify any source codes of the IA for achieving the
distributed computing, and (4) do not have to revise the IA in
order to ﬁnd the appropriate connection mechanism or topology.
Unfortunately, the IA developers currently have no available
solution to make the IA achieve distributed computing without
suffering the aforementioned negative consequences. Despite
many proposals claiming to achieve distributed computing, the
IA developers have to learn the speciﬁcations or formal languages,
change the programming style, revise the way of calling a
subroutine, use the speciﬁc programming language, or operate
the special tool to compile extra modules and link additional
components in order to use the proposals.
In this paper, the universal connection architecture (UCA) is
proposed to free IA developers from the burdens of achieving
distributed computing in the IA. The UCA makes IA developers
focus on the design of the IA without learning other unrelated
knowledge and the use of network APIs. The UCA allows IA
developers to connect the IA’s components distributed over
networks without changing the programming style or source
codes of the IA. The UCA allows IA developers to repeatedly
evaluate and dynamically extend network functions of the IA with
various modules at run time. When a network function is
evaluated, the UCA does not need IA developers to recompile
the IA or link the IA to a different module. Besides, the UCA allows
IA developers to use the distributed components written in
different languages. In other words, the UCA makes IA developers
immediately achieve distributed computing in the IA once core
functions of the IA are ﬁnished. The UCA is implemented on
multiple PCs running Windows 2000 to verify its practicability
because Windows is the most popular operating system in the
world. The UCA will go through several experiments to identify its
capability and limitations.
We construct the remaining parts of this paper as follows. We
address the related works in Section 2. We present the UCA
in Section 3. Then, we introduce the UCA implementation in
Section 4. In Section 5, we observe the UCA overhead and
performance. Finally, we conclude this paper in Section 6.
2. Related works
Since distributed computing technology emerges in the last
decade, many proposals claim to be a practicable solution to
application developers. The proposals can be classiﬁed into
several types according to what cost application developers
should pay for achieving the goal. The proposals’ types are
addressed respectively as follows.
2.1. Remote procedure proposal
Remote procedure proposals (Birrell and Nelson, 1984)
separate certain subroutines from the software main body and
deploy the subroutines in other hosts instead of the host (i.e. the
local host) in where the software main body resides. They execute
the subroutines distributed over networks in order to utilize
resources owned by other hosts. They provide application
developers with tools such as stub generators and compilers
(Gibbons, 1987; Bershad et al., 1987) to facilitate marshaling and
delivering parameters to subroutines in other hosts. They have
several typical examples in the market, e.g. sun remote procedure
call (RPC) (Bloomer, 1992) and Java remote method invocation
(RMI) (Grosso. 2001; Taboada et al., 2007).
Remote procedure proposals need IA developers to program
applications according to a speciﬁc style, e.g. no reference-type
valuable as the subroutine parameter. Besides, they need IA
developers to program applications in a speciﬁc language
compatible with source codes of the stub generated by their
tools. Accordingly, they make IA developers change the program-
ming style or source codes of application. Besides, they provide no
alternative communication mechanism for invoking remote
procedures, so IA developers have no way to decide how to
connect the distributed objects.
2.2. Distributed object environment proposal
Distributed object environment proposals (Ahmed, 1998; Thai,
1999; Blair et al., 1998) improve remote procedure proposals to
create remote objects (instance of a class at run time) capable of
supporting multiple functions. Unlike remote procedure propo-
sals that merely own temporary data during the remote
procedure execution, they can create stateful contexts in remote
objects to facilitate the development of various applications. They
deﬁne an interface to help interaction and interconnection
between distributed objects, so application developers neither
know how a distributed object is located nor have the ﬂexibility to
control the way of connecting a distributed object. They claim
that the distributed objects can be implemented with various
languages as long as the speciﬁcation of the interface is followed.
For example, Common Object Request Broker Architecture
(CORBA) (Ahmed, 1998) uses an interface deﬁnition language
(IDL) (Warren and Kickenson, 1987; Dilley, 1996) to specify the
interface that an object provides to other objects. For another
example, Distributed Component Object Model (DCOM) (Thai,
1999) requires that an object provide other objects with the
IUnknown interface to control the object lifetime or query other
available functions for further interacting.
Distributed object environment proposals need IA developers
to either implement the IA with the interface layout correspond-
ing to the speciﬁcation (Thai, 1999) or use the IDL (Warren and
Kickenson, 1987; Dilley, 1996; Ahmed, 1998) to describe the
mapping between an interface deﬁned in IDL and an implementa-
tion deﬁned in a programming language. Accordingly, they make
IA developers not only learn other knowledge unrelated to the IA
design (e.g. the use of IDL), but also change the programming style
or source codes of the IA. Meanwhile, they make the way of
locating a distributed object transparent to IA developers who
may want to evaluate and ﬁnd an appropriate connection
mechanism for the IA.
2.3. Software abstraction proposal
Software abstraction proposals (Shaw et al., 1995; Magee et al.,
1993; Callahan and Purtilo, 1991; Cao et al., 2005) try to deﬁne an
abstract framework to facilitate the interconnection between
components distributed over networks. They neither specify what
language should be used to implement the components nor
regulate what interconnection should be used to connect the
components. In order describe the abstract framework, they need
T.-C. Huang / Journal of Network and Computer Applications ] (]]]]) ]]]–]]]2
Please cite this article as: Huang T-C. Universal connection architecture for interactive applications to achieve distributed.... J Network
Comput Appl (2010), doi:10.1016/j.jnca.2010.07.013
However, cloud-based web service proposals need program-
mers to follow their programming models, e.g. the MapReduce
model (Dean and Ghemawat, 2008) or work based on certain
assumptions, e.g. initiating an update request that involves a large
number of data items with a simple update rule (Yuqing Zhu et al.,
2010). Furthermore, certain of them such as MapReduce (Dean
and Ghemawat, 2008) are designed for efﬁciently and simulta-
neously utilizing resources in a cloud rather than for easily
developing the IA. Besides, certain of them have limited functions
(Ciurana, 2009) which merely allow programmers to develop
certain applications with the available toolkits working on
speciﬁc platforms, e.g. Google’s cloud computing environment
(Dean and Ghemawat, 2008; Ciurana, 2009).
2.7. Contributions of our UCA
Although the existing proposals are designed for distributed
computing, our UCA outperforms them in many areas as follows.
The UCA does not burden IA developers with works of learning
knowledge unrelated to the IA design. The UCA does not need IA
developers to know how to program their IAs to have the
networking capability. The UCA neither requires writing the IA
in a speciﬁc programming style nor changes source codes of the IA
in order to be compatible with a speciﬁc interface or execution
environment. The UCA allows IA developers to repeatedly evaluate
and dynamically extend network functions of the IA with various
modules at run time. When a network function is evaluated, the
UCA does not need IA developers to recompile the IA or link the IA
to a different module. Moreover, the UCA allows IA developers to
use the distributed components written in different languages. The
UCA makes IA developers immediately achieve distributed
computing in the IA once core functions of the IA are ﬁnished.
3. Universal connection architecture
3.1. UCA overview
In Fig. 1, the UCA consists of multiple UCA engines distributed
over networks. The UCA uses a UCA engine to manage an IA in a
node (i.e. host) by means of handling input and output of the
IA. On the one hand, the UCA accepts commands from the IA
developer and forwards them to the target IA according to the IA
developer’s option. According to the IA developer’s option, on the
other hand, the UCA processes responses from the IA and
forwards them to the target UCA engine for displaying them to
the IA developer or delivering them to other IAs as input of other
IAs. When handling input and output of the IAs, besides, the UCA
can make the UCA engines load modules offered by IA developers
to extend network functions among the IAs. To be compatible
with various network environments, the UCA uses conventional
transport protocols to connect the UCA engines distributed over
networks.
We take a scenario of distributing the IA over ﬁve nodes in
Fig. 1 for example. Developer 1 can input a command at the UCA
engine in Node 1 and specify the IA in Node 2 as the command
target and the IA in Node 3 as the response target of the IA in
Node 2 before the response is returned to Node 1 and displayed to
Developer 1. Developer 1 can use such a sophisticated command
to form a data processing chain among the IAs for certain
applications whose necessary resources are distributed over
different nodes. Conversely, Developer 2 can input a command
at the UCA engine in Node 4 and specify both the IAs in Nodes 4
and 5 as the target in order to see responses from two nodes. With
such a sophisticated command, Developer 2 can achieve dis-
tributed parallel processing among the IAs for certain applications
that apply the identical algorithm to different data segments in
different nodes. Furthermore, Developers 1 and 2 can cooperate
with each other to perform complex applications or activities, e.g.
holding a conference or debugging the IAs.
In the UCA, IA developers can determine how many IAs are
distributed over networks in order to achieve a customized scale
of distributed computing. IA developers can control routes of
commands and responses among the distributed IAs in order to
evaluate and ﬁnd the appropriate connection mechanism. Mean-
while, IA developers can specify various modules to process input
and output of the IAs in a customized order when evaluating
connection mechanisms. While the UCA handles network func-
tions on behalf of the IA and IA developers, IA developers
concentrate on the IA design without programming any network
Network
UCA Engine
Interactive
Applciation (IA)
UCA Engine
Interactive
Applciation (IA)
UCA Engine
Interactive
Applciation (IA)
UCA Engine
Interactive
Applciation (IA)
Flow over Network
Flow over Pipeline
Developer 1
Developer 2
UCA Engine
Interactive
Applciation (IA)
Node 1
Node 2
Node 3
Node 4
Node 5
Fig. 1. UCA overview.
T.-C. Huang / Journal of Network and Computer Applications ] (]]]]) ]]]–]]]4
Please cite this article as: Huang T-C. Universal connection architecture for interactive applications to achieve distributed.... J Network
Comput Appl (2010), doi:10.1016/j.jnca.2010.07.013
(i.e. data pre-processing) but also the process of output from the
IA (i.e. data post-processing). The UCA script can decide whether
responses are displayed to the console in a UCA engine or used as
input of other IAs. The UCA script uses a ‘‘@’’ sign as the preﬁx of
the name to distinguish a UCA script from modules. Besides, the
UCA script can support module names and UCA script names in
the URI format (Lee et al., 2005) that indicates how and where to
locate the module or the UCA script. For clear explanation, the
UCA script has a layout in Fig. 3(a) without any module and UCA
script name in the URI format. Generally, the UCA script is
composed of TAGs TN (short for target node), IC (short for input
chain), and OC (short for output chain).
Tag TN indicates not only where the UCA engine is responsible
for processing the payload with the IA (speciﬁed as a parameter in
the bootstrap loader of the UCA engine) and modules speciﬁed in
Tags IC and OC, but also how to connect to the UCA engine. To this
end, Tag TN is composed of three ﬁelds separated by a comma, i.e.
the IP address of the UCA engine, the port number of the UCA
engine, and the protocol to contact the UCA engine. Tag TN is
necessary because a node may have more than one UCA engine
responsible for managing different IAs and reachable via various
protocols. In a computer for example, Tag TN can use TCP port
3233 to contact a UCA engine for an IA but UDP port 3266 to
contact a UCA engine for another IA.
Tag IC denotes a chain of modules that process input before the
IA (i.e. data pre-processing). Tag IC is composed of module names
separated by a ‘‘9’’ sign which is also used to express the command
line pipe in UNIX and Windows. Tag IC uses the following
modules to process input in a cascade style, i.e. output of Module
1 as input of Module 2 in Fig. 3(a). If being left blank, Tag IC has no
module and forwards input from the UCA Engine to the IA
directly.
Similar to Tag IC, Tag OC denotes a chain of modules that
process output of the IA. Although using the ‘‘9’’ sign to separate
the module names like Tag IC, however, Tag OC allows IA
developers to use a UCA Script name as the chain tail instead of
a module name in order to forward output to other UCA Engines,
e.g. ‘‘@UCA Script 9’’ in Fig. 3(a). Besides, Tag OC can exist in more
than one row in order to process output of the IA with different
modules in the local node or forward output of the IA to different
modules in different nodes, according to Tag TN of the UCA script
at the chain tail.
Since the UCA script supports more than one Tag OC, so IA
developers can duplicate and process output of the IA with
different module chains. Furthermore, IA developers can use the
feature to forward output of the IA to multiple distributed IAs.
Currently, IA developers can use a UCA script consisting of only
Tag TN to display output to a console of the UCA engine at a
speciﬁc node. Meanwhile, IA developers can input a command to
the console and append UCA scripts to the command as shown in
Fig. 3(b), which runs the command according to contents of ‘‘UCA
Script 1’’ and ‘‘UCA Script 2’’ respectively. With the support of
using UCA scripts in a console, IA developers can dynamically
control the command target for various applications. For example,
IA developers can evaluate different network functions or test
various distributed computing models by applying UCA scripts to
certain nodes. If IA developers give commands without any UCA
script to the console, conversely, the UCA engine forwards the
commands to the IA in the local node and displays responses on
the Console directly.
As an example composed of four UCA scripts in Fig. 4, the IA
developers can send a command with UCA script 1 to the IA at
192.168.1.1 by using ‘‘command @UCA Script 1’’ in a console. The
IA developers can expect that output of the IA will be forwarded
to the UCA engines at 192.168.1.2 and 192.168.1.3, respectively,
according to ‘‘UCA Script 2’’ and ‘‘UCA Script 3’’ speciﬁed in Tags
OC. Then, the IA developers can observe that the UCA engines at
192.168.1.2 and 192.168.1.3 will, respectively, invoke a well-
known UNIX module ‘‘grep’’ to pick out output having strings that
correspond to the addresses they are bound to. After the UCA
engines pick out the speciﬁc output and use it as input of the IAs
at 192.168.1.2 and 192.168.1.3, the IA developers can expect that
output of the two IAs will be forwarded and displayed to the
console of the UCA engine at 192.168.1.4 (because of only Tag TN
in UCA Script 4) according to ‘‘UCA Script 4’’ speciﬁed in Tag OC of
UCA Scripts 2 and 3.
3.4. UCA transmission unit
The UCA transmission unit is the unit ﬂowing among the UCA
engines. The UCA transmission unit can transport commands of IA
developers and responses of IAs no matter the responses will be
displayed to the console of a UCA engine or used as input of other
IAs. In Fig. 5, the UCA transmission unit consists of the header
part, the script part, and the payload part. The UCA transmission
unit uses the header part to indicate its script size, and payload
size. The UCA transmission unit uses the script part to carry the
UCA script dedicated to handling commands or responses in the
payload part. The UCA transmission unit uses the payload part to
carry commands of IA developers or responses of IAs. Due to no
ﬁeld available for recording a sequence number or a checksum
value, the UCA transmission unit transport the payload according
to the feature of the underlying transport protocol speciﬁed by
Tag TN in the UCA script, e.g. TCP for a reliable delivery
mechanism but UDP for an unreliable delivery mechanism.
However, the UCA transmission unit’s functions can be easily
enhanced or extended with modules speciﬁed by Tags IC and OC
in the UCA script.
TN: IP Address, Port Number, Protocol Type
IC: Module 1 | Module 2 ...
OC: Module 5 | Module 6 ... @UCA Script 9
(a) UCA Script Layout
Command @UCA Script 1 @UCA Script 2 ...
(b) Using UCA Script in Console
Fig. 3. UCA script layout and usage in console.
TN: 192.168.1.1, 1234, udp
IC:
OC: @UCA Script 2
OC: @UCA Script 3
(a) UCA Script 1
TN: 192.168.1.2, 1234, udp
IC: grep "192.168.1.2"
OC: @UCA Script 4
(b) UCA Script 2
TN: 192.168.1.3, 1234, udp
IC: grep "192.168.1.3"
OC: @UCA Script 4
(c) UCA Script 3
TN: 192.168.1.4, 1234, udp
(d) UCA Script 4
Fig. 4. UCA script example.
T.-C. Huang / Journal of Network and Computer Applications ] (]]]]) ]]]–]]]6
Please cite this article as: Huang T-C. Universal connection architecture for interactive applications to achieve distributed.... J Network
Comput Appl (2010), doi:10.1016/j.jnca.2010.07.013
5. Performance
5.1. UCA overhead breakdown
5.1.1. UCA overhead according to processing step
We observe the overhead of the UCA in the section. We divide
the processing of the UCA into several steps as follows:
ProcessingUserCommand (PUC): The user interface thread
receives a user command from the console, parses the command,
and allocates a job space for the command.
WaitinginOutgoingJobQueue (WOJQ): The user interface thread
puts a job into the outgoing job queue and delays the processing
of the job until that the communication thread is scheduled to
create the UCA transmission unit and transmit the job to the
network.
WaitinginIncomingJobQueue (WIJQ): The communication thread
receives the job from the network and puts it into the incoming
job queue.
ProcessingScript (PS): The job processing thread extracts the
payload from the UCA transmission unit and parses the UCA script
in the UCA transmission unit.
LoadingModule (LM): The job processing thread searches
memory for the IA and the wanted modules, and if they are not
in memory, loads them from disks into memory for processing the
job later.
RunningModuleinIC (RMIC): The job processing thread runs
modules in the IC (short for input chain) to process the payload.
RunningIA (RIA): The job processing thread runs the IA to
process output from modules in the IC.
RunningModuleinOC (RMOC): The job processing thread runs
modules in the OC (short for output chain) to process output from
the IA.
We observe the overhead of the UCA prototype on a Windows
2000 server running on a PC with an idle 366 MHz CPU. To
facilitate observing the performance of the UCA, we develop a
command generator capable of showing commands on the screen
in different speeds and use a pipeline to redirect the commands
from the screen to the console of the UCA (i.e. simply deploying a
‘9’ symbol between the name of the command generator and the
name of the console in the command line, Stevens, 1998). We
conﬁgure the command generator to send commands with
different payload sizes to the UCA through the console, and
destine the local UCA to the commands’ destination with a
speciﬁc script ﬁle in order to observe the optimal overhead
without any network propagation delay. Due to the use of a
loopback IP address in Tag TN in the script ﬁle, we can expect that
the local UCA will receive the jobs submitted by itself via the
network loopback interface. We conﬁgure commands to use the
script ﬁle that arranges for handling the payload with an IA
merely capable of forwarding input to output without any further
processing.
5.1.2. UCA overhead without modules in IC and OC
First, we do not use any module in the IC and OC. We get the
results in Fig. 8. We observe that when the UCA is idle, the
dominative performance factor is the WOJQ (short for
WaitinginOutgoingJobQueue) because the job has to stay in the
outgoing job queue waiting for the communication thread to
create the UCA transmission unit and transmit the job to
networks; in the experiment, the job will be destined to the
local network interface but immediately looped back to the
incoming job queue by the communication thread. Because we
design the communication thread to wait in API select until API
socket can be written, the high overhead of the WOJQ is due to the
use of API select. Conversely, we design the job processing thread
to pick a job from the incoming job queue once receiving the
event from the communication thread after the communication
thread puts a job into the incoming job queue. Accordingly, we
can see that the WIJQ (short for WaitinginIncomingJobQueue) has
a lower overhead than the WOJQ.
We note that the PUC (short for ProcessingUserCommand) and
the RIA (short for RunningIA) have overheads in proportional to
the payload size because the time increases when the payload
increases. We know that the PUC and the RIA should be
responsible for the phenomenon due to the payload copy
operation; the former transfers the command and the payload
(e.g., loading UCA scripts from disks and saving the payload in
memory) into the job data structure, while the latter forwards
the payload from input to output. We attribute the overhead
difference between the PUC and the RIA to the disk I/O. Although
we have not used any module in the IC and OC for this experiment,
. . .
. . .
Script Parser
Module
Downloader
I/O Integrator
Job Processing
Thread
Communication
Thread
Transmission Unit
Packager
User Interface
Thread
Console
IA
Windows Application Programming Interface
Incoming Job
Queue
Outgoing Job
Bootstrap Loader
Data FlowDisk Volume
Network Adapter
UCA Engine
Module
Queue TCPSocket
UDP
Socket
Fig. 7. UCA on Windows 2000.
T.-C. Huang / Journal of Network and Computer Applications ] (]]]]) ]]]–]]]8
Please cite this article as: Huang T-C. Universal connection architecture for interactive applications to achieve distributed.... J Network
Comput Appl (2010), doi:10.1016/j.jnca.2010.07.013
Fig. 9. Overhead breakdown with ICMs in UCA.
Fig. 10. Overhead breakdown with OCMs in UCA.
T.-C. Huang / Journal of Network and Computer Applications ] (]]]]) ]]]–]]]10
Please cite this article as: Huang T-C. Universal connection architecture for interactive applications to achieve distributed.... J Network
Comput Appl (2010), doi:10.1016/j.jnca.2010.07.013
most rising curves decrease at the input speeds beyond 120 TUPS
in TCP and 200 TUPS in UDP according to the number of receivers.
5.2.2.3. Multi-target communication throughout with modules in
OC. We specify multiple hosts as the targets in commands and use
modules in the OC (i.e. OCM) of the UCA script. Because the UCA
allows the IA to output data to multiple OCs (denoted by multiple
Tags OC), we also conduct the experiments with different numbers
of modules in multiple OCs. In Fig. 16, we merely show the cases of
1 and 4 receivers for observing TCP and UDP throughput in multi-
target communication with OCMs in 1 OC due to space limitation.
We note that receivers share the outgoing job queue of the UCA in
the sender (i.e. PC 1 in the experiment), so more receivers can
sustain the high workload of the sender according to the slopes of
most rising curves at the input speeds beyond 120 TUPS in TCP
and 200 TUPS in UDP. Take UDP throughput for example, we
observe that the UCA has more rising curves in 1 receiver than 4
receivers at the input speed of 240 TUPS to where the destination
receive livelock happens. Similar to the reason of the source receive
livelock in the previous experiment with TCP, we see that the UCA
cannot use 3 OCMs to efﬁciently sustain jobs with small payloads
(i.e. 64, 256, 512 bytes) in a receiver, especially in multiple
receivers which can get unstable TCP throughput.
After knowing that the number of receivers can beneﬁt
sustaining the workload of the sender at most situations, we
observe the cases that have OCMs in multiple OCs (i.e. denoted by
multiple Tags OC) because the UCA allows the IA to output data to
multiple OCs. In Fig. 17, we merely show the cases of 2 and 3 OCs
for observing TCP and UDP throughput due to space limitation.
We observe that the input speed of 120 TUPS is still the beginning
of the source receive livelock in TCP and the input speed of 200
TUPS is the beginning of the destination receive livelock in UDP, no
matter how many OCMs in OCs are indicated by the UCA Script to
process the payload. Because more OCs can incur more processing
delay in the UCA at the target host to block jobs sent by the sender
over TCP, e.g. 9 OCMs as the product of 3 OCs and 3 OCMs, we
observe that many curves in TCP are horizontal without changing
according to the input speeds. Moreover, we see that the
processing delay in the UCA at the target host can further
degrade the UDP throughput by comparing the curves in 2 OCs
and 3 OCs at the input speeds of 200, 220, and 240 TUPS.
Accordingly, we conclude that the processing delay at target hosts
is harmful to the UCA performance in multi-target communication.
5.2.3. Relay-based communication
5.2.3.1. Relay-based communication throughout without modules in
IC and OC. In the section, we observe the optimal UCA throughput
in relay-based communication without any module in IC and OC.
We use the network topology in Fig. 11 and the same equipments
as previous experiments. In order to deliver the UCA transmission
unit to a target relayed by multiple intermediary hosts, we specify
a new script ﬁle at the end of Tag OC in the script ﬁle processed by
an intermediary host and indicate the IP address of the next in-
termediary host at Tag TN in the new script ﬁle until that the UCA
transmission unit is processed by the target host. Accordingly, we
can make the UCA transmission unit traverse the intermediary
hosts before it reaches the target. We show TCP throughput in
Fig. 12. UCA TCP throughput in multi-target communication without modules.
T.-C. Huang / Journal of Network and Computer Applications ] (]]]]) ]]]–]]]12
Please cite this article as: Huang T-C. Universal connection architecture for interactive applications to achieve distributed.... J Network
Comput Appl (2010), doi:10.1016/j.jnca.2010.07.013
speed of 200 TUPS, because the 366 MHz CPU in the intermediary
host can support the jobs sent from the UCA in PC 1. Moreover, we
observe that the results correspond to the conclusion in Fig. 19
because the destination receive livelock is sensitive to the delay in
the intermediary host. When the input speed is greater than 200
TUPS, we see that the curves suddenly rise according to the
number of the ICMs and intermediary hosts. We think that using a
modern CPU with a high speed in the intermediary hosts can
overcome the situation greatly.
5.2.3.3. Relay-based communication throughout with modules in
OC. In the section, we specify a host as the target and multiple
hosts as the intermediary hosts in commands and program the
Fig. 14. UCA TCP throughput in multi-target communication with ICMs.
Fig. 15. UCA UDP throughput in multi-target communication with ICMs.
T.-C. Huang / Journal of Network and Computer Applications ] (]]]]) ]]]–]]]14
Please cite this article as: Huang T-C. Universal connection architecture for interactive applications to achieve distributed.... J Network
Comput Appl (2010), doi:10.1016/j.jnca.2010.07.013
2000)(Alparslan et al., 2006) due to the delay in intermediary
hosts still beneﬁts most cases of the UCA except the cases using 3
OCMs to process small payloads such as 64, 256, and 512 bytes,
and (3) using 3 OCMs to process small payloads in Fig. 22 seems to
make TCP throughput more unstable than using 3 ICMs to process
small payloads in Fig. 20 due to different overheads of the RMIC
and RMOC observed in Figs. 9 and 10. Besides, we observe that
UDP throughput in Fig. 23 corresponds to our expectation of
beginning to have degradation at the input speed of 200 TUPS in
where the destination receive livelock appears. Moreover, we note
that UDP throughput does not have much degradation according
to the number of intermediary hosts either, which is similar to the
observations in Fig. 21.
6. Conclusions
In this paper, the universal connection architecture (UCA) is
proposed to free interactive application (IA) developers from the
burdens of achieving distributed computing in the IA. The UCA
makes IA developers focus on the design of the IA without
learning other unrelated knowledge and the use of network APIs.
The UCA allows IA developers to connect the IA’s components
distributed over networks without changing the programming
style or source codes of the IA. The UCA allows IA developers to
repeatedly evaluate and dynamically extend network functions of
the IA with various modules at run time. When a network
function is evaluated, the UCA does not need IA developers to
recompile the IA or link the IA to a different module. Besides, the
UCA allows IA developers to use the distributed components
written in different languages. In other words, the UCA makes
IA developers immediately achieve distributed computing in the
IA once core functions of the IA are ﬁnished. The UCA is
implemented on multiple PCs running Windows 2000 to verify
its practicability.
We use low-end PCs with 366 MHz CPUs to construct the
experiment environment. In the overhead breakdown experi-
ment, we analyze the overhead of the UCA according to its
processing steps. We observe that the dominative performance
factor is the time waiting in the outgoing job queue which is
involved with overheads of network API select and the context
switch between threads in the UCA. Besides, we see that the time
of processing the command and running the IA to manipulate the
payload both increases in proportion to the payload size. We
Fig. 18. UCA TCP throughput in relay-based communication without modules.
T.-C. Huang / Journal of Network and Computer Applications ] (]]]]) ]]]–]]]16
Please cite this article as: Huang T-C. Universal connection architecture for interactive applications to achieve distributed.... J Network
Comput Appl (2010), doi:10.1016/j.jnca.2010.07.013
that the processing delay at target hosts is harmful to the UCA
performance in multi-target communication.
In relay-based communication experiments, we deliver jobs to
a target through multiple intermediary hosts. In the experiment
without any module, we observe that the delay in the inter-
mediary host degrades TCP throughput in proportion to the
number of the intermediary hosts traversed by the UCA
transmission units. Besides throughput degradation due to the
destination receive livelock, we note that UDP throughput hardly
degrades according to the number of intermediary hosts. In the
experiment with ICMs, we observe that the delay in the
intermediary hosts creates the effect of the TCP pacing to alleviate
Fig. 20. UCA TCP throughput in relay-based communication with ICMs.
Fig. 21. UCA UDP throughput in relay-based communication with ICMs.
T.-C. Huang / Journal of Network and Computer Applications ] (]]]]) ]]]–]]]18
Please cite this article as: Huang T-C. Universal connection architecture for interactive applications to achieve distributed.... J Network
Comput Appl (2010), doi:10.1016/j.jnca.2010.07.013
port the UCA to the architecture of cloud computing (Weiss, 2007)
in the future, the attractive distributed computing model in the
next generation. While the well-known areas of cloud computing
have the Software as a Service (SaaS), the Platform as a Service
(PaaS), and the Infrastructure as a Service (IaaS) (Creeger, 2009),
we believe that the SaaS and the PaaS are the appropriate
candidates that can be easily extended with the UCA to facilitate
the deployment and the development of a cloud. We believe that
the combination of the UCA and the cloud computing will be
promising in the future.
Acknowledgement
We thank the editor and reviewers for their valuable
comments. We address the achievement of the project (Project
NSC 98-2218-E-262-002) supported by the National Science
Council at Taiwan. We attribute the success of this project to
the ﬁnancial supports from the National Science Council at
Taiwan. Besides, we thank Lunghwa University of Science and
Technology at Taiwan for other supports such as the supply of
equipments and electrical power.
References
Birrell AD, Nelson BJ. Implementing remote procedure calls. ACM Transaction on
Computer System February 1984;2(1):39–59.
Gibbons PB. A stub generator for multilanguage RPC in heterogeneous environ-
ments. IEEE Transactions on Software Engineering January 1987;SE-13(1).
Bershad B, Ching D, Lazowska E, Sanislo J, Schwartz M. A remote procedure call
facility for interconnecting heterogeneous computer systems. IEEE Transac-
tions on Software Engineering August 1987;13:880–94.
Bloomer J. Power Programming with RPC, O’Reilly Media, ISBN 10: 0-937175-77-3,
February 1992.
Grosso W. Java RMI, O’Reilly Media, Beijing, China, ISBN:10: 1-56592-452-5,
October 2001.
Taboada GL, Teijeiro C, Tourino J. High performance java remote method
invocation for parallel computing on clusters. In: Proceedings of the 12th
IEEE symposium on computers and communications; July 2007. p. 233–39.
Ahmed S. CORBA programming unleashed. Sams Publishing; December 1998.
ISBN-10: 0672310260.
Thai TL. Learning DCOM, O’Reilly Media, ISBN 10: 1-56592-581-5, April 1999.
Blair G, Coulson G, Robin P, Papathomas M. An architecture for next generation
middleware. In: Proceedings of the IFIP international conference on distrib-
uted systems platforms and open distributed processing; 1998. p. 15–18.
Warren WB, Kickenson J. A tutorial introduction to using IDL. ACM SIGPLAN
Notices November 1987;22(11):18–34.
Dilley J. Using OMG IDL to write OODCE applications. In Proceedings of the IFIP/
IEEE international conference on distributed platforms: client/server and
beyond: DCE, CORBA, ODP and advanced distributed applications; March
1996. p. 386–98.
Shaw M, DeLine R, Klein DV, Ross TL, Young DM, Zelesnik G. Abstractions for
software architecture and tools to support them. IEEE Transactions on
Software Engineering April 1995;21(4):314–35.
Magee J, Dulay N, Kramer J. Structuring parallel and distributed programs. IEE
Software Engineering Journal March 1993;8(2):73–82.
Callahan JR, Purtilo JM. A packaging system for heterogeneous execution environ-
ments. IEEE Transactions on Software Engineering June 1991;17(6):626–35.
Cao F, Bryant BR, Burt CC, Raje RR, Olson AM, Auguston M. A component assembly
approach based on aspect-oriented generative domain modeling. Electronic
Notes in Theoretical Computer Science Jan. 2005;114(17):119–36.
Magee J, Kramer J. Dynamic structure in software architectures. ACM SIGSOFT
Software Engineering Notes Nov. 1996;21(6):3–14.
Waddington DG, Coulson G. A distributed multimedia component architecture. In:
Proceedings of the ﬁrst international enterprise distributed object computing
workshop; October 1997, p. 334–45.
Upadhyayaand BP, Liu Z. Formal support for development of JavaBeans component
systems. In: Proceedings of the 28th annual international computer software
and applications conference; 2004. p. 23–28.
Wang G, Ungar L, Klawitter D. A framework supporting component assembly for
distributed systems. In: Proceedings of second international enterprise
distributed object computing workshop; 1998. p. 136–46.
Pryce N, Crane S. Component interaction in distributed systems. In: Proceedings
of international conference on conﬁgurable distributed systems; 1998.
p. 71.
Magee J, Dulay N, Kramer J. Regis: a constructive development environment for
distributed programs. Distributed Systems Engineering Journal 1994;1(5):
304–12.
Magee J, Sloman M. Constructing distributed systems in conic. IEEE Transactions
on Software Engineering June 1989;15(6):663–75.
Purtilo JM. The POLYLITH software bus. ACM Transactions on Programming
Languages and Systems Jan. 1994;16(1):151–74.
Koster R, Black AP, Huang J, Walpole J, Pu C. Thread transparency in information
ﬂow middleware. Software Practice & Experience April 2003;33(4):321–49.
O’Ryan C, Kuhns F, Schmidt DC, Othman O, Parsons J. The design and performance
of a pluggable protocols framework for real-time distributed object computing
middleware. In: Proceedings of IFIP/ACM international conference on
distributed systems platforms; 2000. p. 372–95.
Hutchinson NC, Peterson LL. The x-Kernel: an architecture for implementing
network protocols. IEEE Transactions on Software Engineering Jan. 1991:
64–76.
Plagemann T, Gotti A, Plattner B. CoRA—a heuristic for protocol conﬁguration and
resource allocation. In: Proceedings of the fourth international IFIP workshop
on protocols for high speed networks; August 1994. p. 103–19.
Kramp T, Coulson G. The design of a ﬂexible communications framework for next-
generation middleware. In: Proceedings of the international symposium on
distributed objects and applications; 2000. p. 273–82.
Greenberg MS, Byington JC, Harper DG. Mobile agents and security. IEEE
Communications Magazine July 1998;36(7):76–85.
Htoon H, Thwin M.M.T. Mobile agent for distributed information retrieval system.
In: Proceedings of ﬁfth international conference on electrical engineering/
electronics, computer, telecommunications and information technology; May
2008. p. 169–72.
Tennenhouse DL, Wetherall DJ. Towards an active network architecture. ACM
SIGCOMM Computer Communication Review Oct. 2007;37(5):81–94.
Tzu-Chi Huang Ce-Kuen, Shieh Yu-Ben. Miao, bottleneck active node detouring for
capsule-based active network. Journal of Network and Computer Applications
(JNCA) January 2009;32(1):1–30.
Weiss A. Computing in the clouds. netWorker December 2007;11(4):16–25.
Creeger M. Cloud computing: an overview. ACM Queue June 2009;5(5):2.
Dean J, Ghemawat S. MapReduce: simpliﬁed data processing on large clusters.
Communications of the ACM Jan. 2008;51(1):107–13.
Zhu Yuqing, Wang Jianmin, Wang Chaokun. Ripple: a publish/subscribe service for
multidata item updates propagation in the cloud. Journal of Network and
Computer Applications 11 June 2010. /http://dx.doi.org/10.1016/j.jnca.2010.
06.002S.
Ciurana E. Developing with Google App Engine, Apress (Berkely, CA, USA), ISBN:
1430218312, 2009.
Lee TB, Fielding R, Masinter L. Uniform Resource Identiﬁer (URI): Generic Syntax.
RFC 3986, January 2005.
Kernighan BW, Ritchie DM. C programming language. Prentice Hall; April 1, 1988.
ISBN 10: 0-13110-362-8.
Stevens WR. UNIX network programming: networking APIs: sockets and XTI;
volume 1. Prentice Hall; January 15, 1998. ISBN-10: 0-13490-012-X.
Mogul JC, Ramakrishnan KK. Eliminating receive livelock in an interrupt-
driven kernel. ACM Transactions on Computer Systems (TOCS) 1997;15(3):
217–52.
Aggarwal A, Savage S, Anderson T. Understanding the performance of TCP pacing.
In: Proceeding of the IEEE INFOCOM 2000 conference on computer commu-
nications, March 2000; pp. 1157–1165.
Alparslan O, Arakawa S, Murata M, Performance of paced and non-paced
transmission control algorithms in small buffered networks. In: Proceeding
of the IEEE symposium on computers and communications; June 2006.
p. 115–122.
T.-C. Huang / Journal of Network and Computer Applications ] (]]]]) ]]]–]]]20
Please cite this article as: Huang T-C. Universal connection architecture for interactive applications to achieve distributed.... J Network
Comput Appl (2010), doi:10.1016/j.jnca.2010.07.013
