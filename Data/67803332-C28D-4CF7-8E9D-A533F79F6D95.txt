1 
行政院國家科學委員會補助專題研究計畫成果報告 
「具任意字元的近似比對問題」之索引演算法的研究 (3/3)  
A study on indexing algorithms for approximate matching 
with don't care symbols 
計畫編號：NSC－96－2221－E－007－030 
執行期限：96 年 08 月 01 日至 97 年 07 月 31 日 
主持人：王 炳 豐   國立清華大學資訊工程學系 
 
一、摘要 
 
 String matching 是計算機科學中最基
礎也最重要的研究問題之一。近年來在 
string matching 這個研究領域裡，有一類
新 的 主 題 興 起 ， 稱 為  approximate 
matching。Approximate matching 中有一類
問題稱為 approximate matching with don't 
care symbols。這一類問題允許 pattern 中
包含一些特殊字元，可以用來和任何 
symbol 或任何 string match。除了經常被
應用在  search 或  information retrieval 
上，在生物資訊上，也有許多用處。所以，
有關這類問題之 on-line algorithms 的探
討，不論就理論研究或實際應用而言，都
具有相當的重要性。這個研究計劃的主要
目的，就是去深入探討  approximate 
matching with don't care symbols 這一類問
題的 on-line algorithms。這是一個為期三
年的研究計劃，在計劃進行中，我們也會
找尋其它與  matching 或  approximate 
matching 相關的重要問題來加以研究。目
前這個研究計劃已進行完畢。除了
matching with variable-length don't cares 
這個問題外，我們也在 text fingerprinting 
problem 與 interval location 這兩個問題
的 on-line algorithms 上獲得了相當不錯
的成果。 
 
關鍵詞：演算法設計與分析、字串比對、 
字串索引、資料結構 
 
Abstract 
 
 String matching is one of the most 
important and fundamental problems in 
computer science. Recently, a lot of 
researchers have turned their attention to 
a new kind of string matching problems, 
called approximate matching with don't 
care symbols. In the problems, a pattern 
can contain some special symbols, called 
don't care symbols, which can match any 
symbol in the alphabet or even any 
substring. Efficient algorithms for this 
kind of problems have applications in 
information retrieval and molecular 
biology. Therefore, to design on-line 
algorithms for this kind of problems is 
both of theoretical interest and of 
practical importance. The goal of this 
project is to develop on-line algorithms 
for these problems. Several related 
important problems are also studied in 
this project. 
 
Keywords: algorithms, string matching, 
indexing, data structures 
 
二、緣由與目的 
 
  字串比對(string matching)是計算
機科學中最基礎也最重要的研究課題
之一。給定一個 text string S 和一個 
pattern string P，「字串比對問題」是要
去尋找出  P 在  S 中的所有出現位
置。近年來隨著網際網路的蓬勃發展，
網路上的問題，如網路傳輸協定的設
計、網路安全機制的訂定等等，吸引了
許多研究學者的注意。網際網路上的資
料內容包羅萬象，可惜資料的格式不
一，而且經常會包含有一些誤差。為了
因應網際網路上各種格式不一且包含
誤差之資料的搜尋，目前在  string 
matching 這個研究領域裡，最熱門的新
興研究方向稱為  approximate string 
matching。 
3 
|S|, m = |P|, and U is the number of 
occurrences of P in S. 
 
上述結果在 preprocessing time 與 space 
上已大幅改進前人 O(n2) 的結果 [7]。以
下，我們提出了不論是 preprocessing time 
或 space 都更好的 algorithm，而且把這
個結果更進一步的推廣到 alphabet size |∑| 
= 2O(loglog n) 的情況。另外，我們也提出了
可以處理 general alphabet 的 algorithm。 
 
Theorem A3. When |∑| = 2O(loglog n), with 
an O(nlog n/loglog n)-time preprocessing 
on a text string S using O(n) storage, 
whether a given on-line *-pattern P occurs 
in S can be determined in O(m) time, 
where n = |S| and m = |P|. 
 
Theorem A4. When |∑| = 2O(loglog n), with 
an O(nlog n/loglog n)-time preprocessing 
on a text string S using O(n) storage, all 
occurrences of a given on-line *-pattern P 
in S can be found in O(m + U) time, where 
n = |S|, m =|P|, and U is the number of 
occurrences of P in S. 
 
Theorem A5. For general alphabet ∑, 
with an O(nlog n/loglog n)-time 
preprocessing on a text string S using O(n) 
storage, whether a given on-line *-pattern 
P occurs in S can be determined in O(m + 
log |∑| + klog n/loglog n) time, where n = 
|S|, m = |P|, and k is the number of 
*-symbols in P. 
 
Theorem A6. For general alphabet ∑, with 
an O(nlog n/loglog n)-time preprocessing 
on a text string S using O(n) storage, all 
occurrences of a given on-line *-pattern P 
in S can be found in O(m + log |∑| + klog 
n/loglog n + U) time, where n = |S|, m =|P|, 
k is the number of *-symbols in P, and U is 
the number of occurrences of P in S. 
 
B. Text fingerprinting problem 
 
 Let S be a string over a finite, ordered 
alphabet Σ. For any substring S' of S, the set 
of distinct characters contained in S' is 
called its fingerprint. The text fingerprinting 
indexing problem consists of constructing a 
data structure for the string S in advance, so 
that on given any input set C ⊆ Σ of 
characters, we can answer the following 
queries efficiently:  
 
Existential query: Determine if C 
represents a fingerprint of some substrings 
in S;  
Enumerative query: Find all maximal 
substrings of S whose fingerprint is equal to 
C.  
 
The best results known so far solved 
these two queries in Θ(|Σ|) and Θ(|Σ| + K) 
time, respectively, where K is the number of 
maximal substrings. 
 
Let ℱ denote the set of all distinct 
fingerprints in S and let ℒ denote the set 
of all maximal locations of all fingerprints 
in ℱ. Our results are as follows. 
 
Theorem B1. For any string S, with a Θ(n 
+ |ℒ| log |Σ|)-time and Θ(|ℱ| log |Σ| + 
|ℒ|)-space preprocessing, existential query 
can be answered in O(min{|C| log n, |Σ|}) 
time with Θ(|ℱ| log |Σ|) space, and 
enumerative query can be answered in 
O(min{|C| log n, |Σ|} + K) time with 
Θ(|ℱ| log |Σ| + |ℒ|) space.  
 
Theorem B2. With an Θ(n + |ℒ| log 
|Σ|)-time preprocessing, existential query 
can be answered in O(|C| log (|Σ|/|C|)) 
time with Θ(|ℱ|) storage, and enumerative 
query can be answered in O(|C| log (|Σ|/|C|) 
+ K) time with Θ(|ℒ|) storage. 
 
 Both Theorems B1 and B2 answer an 
open problem proposed by Amir et al. [1]. 
Also, the results improve the previous ones 
in [8]. 
 
C. Interval location problem 
 
 Let A be a sequence of n real 
numbers, L1 and L2 be two integers such 
5 
and indexing with errors and don't 
cares," in Proceedings of the 36th 
Annual ACM Symposium on Theory 
of Computing (STOC 04), 2004, pp. 
91-100. 
[4] R. Cole and R. Hariharan, 
"Approximate string matching: a 
simpler faster algorithm," SIAM 
Journal on Computing, vol. 31, no. 
6, pp. 1761-1782, 2002. 
[5] R. Cole and R. Hariharan, 
"Verifying candidate matches in 
sparse and wildcard matching," in 
Proceedings of the 34th Annual 
ACM Symposium on Theory of 
Computing (STOC 02), 2002, pp. 
592-601. 
[6] Z. Galil and R. Giancarlo, 
"Improved string matching with k 
mismatches," SIGACT News, vol. 
17, no. 4, pp. 52-54, 1986. 
[7] S. Inenaga, M. Takeda, A. 
Shinohara, H. Hoshino, and S. 
Arikawa, "The minimum DAWG 
for all suffixes of a string and its 
applications," in Proceedings of the 
Combinatorial Pattern Matching 
(CPM 02), 2002, pp. 153-167. 
[8] R. Kolpakov and M. Raffinot, "New 
algorithms for text fingerprinting," 
Journal of Discrete Algorithms, vol. 
6, no. 2, pp. 243-255, 2008. 
[9] G. Kucherov and M. Rusinowitch, 
"Matching a set of strings with 
variable length don't cares," 
Theoretical Computer Science, vol. 
178, no. 1-2, pp. 129-154, 1997. 
[10] G. M. Landau and U. Vishkin, 
"Efficient string matching with k 
mismatches," Theoretical Computer 
Science, vol. 43, pp. 239-249, 1986. 
[11] S. Muthukrishnan, "Efficient 
algorithms for document retrieval 
problems," in Proceedings of the 
13th ACM-SIAM Symposium on 
Discrete Algorithms (SODA 02), 
2002, pp. 657-666. 
[12] R. Y. Pinter, "Efficient string 
matching with don't-cares patterns," 
Combinatorial Algorithms on Words, 
vol. 12, pp. 11-29, 1985. 
[13] S. C. Sahinalp and U. Vishkin, 
"Efficient approximate and dynamic 
matching of patterns using a 
labeling paradigm," in Proceedings 
of the 37th IEEE Symposium on 
Foundations of Computer Science 
(FOCS 96), 1996, pp. 320-328. 
Efficient Data Structure for Orthogonal y-Max
and Its Application to VLDC Indexing?
Yong-Hsiang Hsieh, Wing-Kai Hon, and Biing-Feng Wang
Department of Computer Science, National Tsing Hua University
Hsinchu, Taiwan 30043, Republic of China
{eric,wkhon,bfwang}@cs.nthu.edu.tw
Abstract. Let T be a text of length n, whose characters are drawn from an alphabet Σ.
Let ∗ be a symbol, called variable don’t care or VLDC symbol, that can match any substring
of T or an empty string. Our problem, called VLDC-indexing problem, is to construct an
index for T such that on given any input pattern P with any number of ∗, we can determine
whether P occurs in T , and also report all its occurrences, efficiently.
Inenaga et al proposed the first index that can answer if P occurs in T in O(|P | log |Σ|)
time, and the index occupies O(n2) words of space. However, they did not show how to use
their index to report the occurrences. In this paper, we improve the space to O(n) words,
and improves the search time to optimal O(|P |) when the alphabet size is small (precisely,
when |Σ| = 2O(log logn)); for general alphabet, the search time is degraded a little. Also, our
index can report all the occurrences in an additional O(occ) time, where occ denotes the
number of occurrences.
Technically speaking, our improvement comes from (i) a reduction of the pattern matching
query to a special type of orthogonal range query [3], which we call three-sided y-max query,
and (ii) a novel index for the latter query.
Key words: string matching, indexing, variable length don’t care, algorithms, data struc-
tures.
1 Introduction
The classical string matching problem is to locate all occurrences of a pattern P within a text T .
Let ∗ be a symbol, called variable length don’t care or VLDC symbol, that can match any substring
of T or an empty string. A more general problem, in which the pattern P may contain ∗, had been
widely discussed [1,2,11,16,18] recently. This problem is motivated from applications in biology and
internet search. For example, Manber and Baeza-Yates [16] reported that the DNA pattern TATA
is a common promoter that often appears after the pattern CAATCT within some distance [12]. If
a set of such general patterns are found, it is desirable to know if they appear, one after the other,
in the DNA database. For another example, the famous search engine, Google, supports keyword
searching with patterns containing ∗ symbols.
More formally, let T be a text whose characters are drawn from an alphabet Σ. We assume that
|Σ| ≤ n. Let P be a pattern containing ∗ symbols, and we call P a ∗-pattern. For string matching
with ∗-pattern, Pinter [18] mentioned that the problem can be easily solved in O(n + |P |) time
based on the KMP algorithm [10]. Bertossi and Logi [2] proposed an O(log n)-time, O(n × |P |)-
work parallel algorithm on EREW PRAM. Kucherov and Rusinowith [11] considered the case
where multiple ∗-patterns are given in a batch; they showed that we can determine if each of these
∗-patterns occurs in T in O((n+m) logm) time and O(n+m) working space, where m is the total
? This research was supported in part by the National Science Council of the Republic of China under the
Contract NSC-96-2221-E-007-030
3Table 2. Comparison of indexes for 3-sided y-max query.
Space Query time Source
O(n) O(log1+ε n) [3]
O(n) O(logn) [15]
O(n) O(logn/ log log n) this
at least a, this point is the solution to the original orthogonal y-max query. Otherwise, we can
conclude that there is no point within the range. Therefore, all results shown in Table 2 all hold
for the orthogonal y-max query.
1.2 Organization
The paper is organized as follows. In Section 2, we review some basic data structures and Pinter’s
algorithm. In Section 3, we first describe our new index for 3-sided y-max queries, and show how
to obtain an efficient VLDC-index that determines if P occurs in T . Section 4 discusses how to
further tune the VLDC-index and improve the query time to O(|P |) when the alphabet size is
small. Finally, in Section 5, we describe an auxiliary data structure for reporting occurrences.
2 Preliminaries
In this section, we review the suffix trees [13, 19], suffix arrays [17], and suffix trays [4] which
form the basis of our indexing structures. We then describe Pinter’s algorithm [18] which gives us
the basic idea of how to perform pattern matching with VLDC-pattern. Then, we show how to
transform the VLDC-indexing problem to the indexing problem for 3-sided y-max queries, and give
a straightforward result for the VLDC-indexing problem based on the existing wavelet tree [6,7,15].
In the following, we let T be a text of length n over an alphabet Σ. We assume that T is
represented by an array such that T (i) is the ith symbol in T . We further assume that T (n) = $,
where $ is a special symbol not appearing elsewhere in the text, and it is lexicographically smaller
than all characters in Σ. Also, we let T (i, j) denote the substring of T starting at position i and
ending at position j.
Definition 1. Let P be a ∗-pattern. If we can replace each ∗ in P by some substring (or empty
string) so that the resulting pattern exactly matches T (i, j), we say P occurs at position i in T .
Example: Suppose T = cabccba. Then, P = c∗c∗ba occurs at positions 1 and 4 in T .
2.1 Suffix Tree, Suffix Array, and Suffix Tray
The suffix tree, suffix array, and suffix tray are O(n)-word indexes for T that support finding all
exact matches of any input pattern P in T . For 1 ≤ i ≤ n, the substring T (i, n) is called a suffix
of T .
The suffix tree [13,19] is a compact trie of all suffixes of T . Each edge of the suffix tree is labeled
by a substring of T . For each node v in the suffix tree, the concatenation of the edge labels along
the path from the root to v is called the path label of v. The path label of each leaf is exactly a
suffix of T , so that we label a leaf by i if its path label is T (i, n). For a pattern P , the locus of P is
the node v, farthest from the root, whose path label is a prefix of P . We have the following lemma.
5One way to solve this is to first transform the n integers in SA to a set N of n points (xi, yi)
for i = 1, 2, . . . , n such that (xi, yi) = (i,SA(i)). Then, construct an index for these n points to
support the following 3-sided y-max query max(N, i, j, k): given any i, j, and k as the input, report
the highest point (a, b) in N with i ≤ a ≤ j and k ≥ b (in the boundary case where no such point
can be found, return an arbitrary answer (a, b) with b = −1).
Thus, determining whether a ∗-pattern P occurs in T can be done as follows: Set x`+1 = n+1.
For each sub-pattern pi, find the lex-start and lex-end positions of pi in SA. Then repeatedly
compute the 3-sided y-max querymax(sp(pi), ep(pi), xi+1−|pi|) to obtain a point (a, b). Set xi = b.
By maintaining the suffix tray (Lemma 3), the lex-start and lex-end positions can be obtained
in O(|pi|+ log |Σ|) time for each sub-pattern pi. It remains to find a data structure that supports
the 3-sided y-max query. Therefore, we have the following.
Lemma 4 Let N be the set of n points (i,SA(i)) for i = 1, 2, ..., n. Suppose that we have a data
structure D on N that answers the 3-sided y-max query in fD time. Then, by storing D and the
suffix tray of T , we can determine whether any input ∗-pattern P occurs in T in O(|P | + `(fD +
log |Σ|)) time, where `− 1 is the number of ∗ symbols in P . uunionsq
The wavelet tree [6,7,15] is one such data structure for the 3-sided y-max queries. It takes O(n)
words of storage and can solve the 3-side y-max query in O(log n) time. By Lemma 4, we have the
following straightforward result.
Theorem 1 We can construct an index for T that occupies O(n) words, such that on given any
∗-pattern P , we can determine whether P occurs in T in O(|P |+ ` logn) time. uunionsq
As for reporting the occurrences of P , from the previous subsection, we see that it corresponds
to finding all occurrences of p1 on or before a certain position x in T . This can be solved as a
separate problem; we defer the discussion to Section 5, where we give an efficient data structure
for that.
3 Data Structures for 3-Sided y-max Queries
In this section, we focus on a restricted form of 3-sided y-max query as follows: Let A be an integer
array of length n, such that each integer is drawn from 1 to n. We want to answer the query,
Q(A, i, j, k), that returns the largest integer in A(i), A(i + 1), . . . , A(j) which is less than k. The
indexing problem for this query is in fact equivalent to the indexing problem for 3-sided y-max
query. (We defer the proof in the full paper.) Also, for the ease of exposition, we shall consider A
to be SA in the remaining of the paper.
The general framework of our data structure is a complete
√
logn-ary ordered rooted tree
with 2 log n/ log log n levels. In the following, we first show how our data structure can answer
Q(SA, i, j, k) assuming two helper functions, namely countv and maxv, are provided in each internal
node v of the tree. Then, we show data structures for countv and maxv, so that once they receive
the input, each can compute the desired result in O(1) time. After that, we show how to further
improve the space of our data structures and obtain our main result for VLDC-indexing.
3.1 General Framework
We shall construct a data structure that supports Q(SA, i, j, k), which is the required query
for pattern matching if we apply Pinter’s algorithm in Section 2.3. We first give some neces-
sary notation. Assume that X is an array of length n. We define X(i, j) to denote the elements
X(i), X(i + 1), . . . , X(j). For each integer x in the suffix array SA, denote the log n-bit binary
7Suppose that the search continues without termination, so that we arrive at the parent of v,
compute countu2 logn/ log logn−1(j2 logn/ log logn−1, x2 log n/ log log n−1), and obtain j
′. By careful check-
ing, j′ is exactly the number of times x appears in SA(1, j).
To obtain the number of times x appears in SA(i, j), we execute the above procedure similarly
to find the number of times x appears in SA(1, i− 1). The difference between the result of the two
executions is the desired result. uunionsq
Now, we discuss how to compute Q(SA, i, j, x) using D. First, we determine whether x exists
in SA(i, j). If so, it is clear that x = Q(SA, i, j, x) and this can be found by Lemma 5. Otherwise,
we proceed with a procedure similar to that in the proof of Lemma 5. Details are as follows.
We adopt the notations defined in the proof of Lemma 5. Recall that v is the node in D asso-
ciated with the group Gx0,x1,...,x2 logn/ log logn−1 , where xi = b
−1
i+1(x). We denote the nodes along the
path from the root r to v in D by u0, u1, . . . , u2 log n/ log log n, where r = u0 and v = u2 logn/ log logn.
We also let jk be the value obtained at Round k when we search for x in SA(1, j). We now define
ik analogously to be the value obtained at Round k when we search for x in SA(1, i− 1). Then, we
perform the following:
Let k′ be the largest value of k with jk > 0. Firstly, we compute maxuk(ik, jk, xk − 1) for all
k = 0, 1, 2, . . . , k′. Let k′′ be the largest k such that maxuk(ik, jk, xk−1) 6= −1. By careful checking,
we can see that if no such k′′ exists, then, we can safely return Q(SA, i, j, x) as -1.
Otherwise, the desired value for Q(SA, i, j, x) must exist. Let w′′ be the sibling of uk′′ such
that it is the child of uk′′−1 with label L = maxuk′′ (ik′′ , jk′′ , xk′′ − 1). Again, we can see that
the desired value must occur in Dw′′ . In particular, it is the largest value z in Dw′′(i′′, j′′) where
i′′ = countuk′′−1(ik′′−1, L) + 1 and j
′′ = countuk′′−1(jk′′−1, L).
In other words, the first k′′ characteristic bytes of z is already known (their values are equal
to x1, x2, . . . , xk′′−1, L). Next, to find the actual value of z, we continue to find its remaining
characteristic bytes repeatedly. We show only two steps as the other steps are similar. First, to find
the k′′ + 1th characteristic byte, we compute L′ = maxw′′(i′′, j′′, n). By careful checking, L′ is the
value of the desired byte. Next, we compute i′′′ = countw′′(i′′− 1, L)+1 and j′′′ = countw′′(j′′, L).
Set w′′′ to be the child of w′′ with label L′. Then, the value of the k′′+2th characteristic byte will
be L′′ = maxw′′′(i′′′, j′′′, n).
In the next subsection, we show how to maintain a data structure that supports efficient queries
for each v. We shall use another name, maxv, to denote the desired query. To conclude, we have
the following.
Lemma 6 Suppose that we can compute countv and max v for each internal node v of D in constant
time. Then Q(SA, i, j, x) can be computed in O(log n/ log log n) time. uunionsq
3.2 Supporting countv and maxv Queries in O(1) time
Consider a fixed node v. Let d = n/((
√
log n)δ(v)) which is the number of integers represented
by Dv. We first show how to construct an O(d log d
√
logn)-bit data structure that can answer
the maxv query in O(1) time. We note that each input integer in Dv has the same first δ(v)
characteristic bytes. Therefore, to support maxv (or, countv later), we can assume each integer of
Dv is represented by its δ(v) + 1th characteristic byte; the latter one consists of (log log n)/2 bits
and thus is an integer ranging from 1 to
√
logn. The basic idea is to preprocess each query whose
length is a power of two. For each integer i, 1 ≤ i ≤ d, we build a summary bitmap B(i, j) to
represent the existence of the set of integers in the block starting at position i and having length
2j , 1 ≤ j ≤ log d; that is, we use a √log n-bit bitstring B(i, j) in which the w-th bit of B(i, j) is set
to 1 if w is in Dv(i, i+ 2j − 1); otherwise, it is set to 0. It is easy to see that for any interval (i, j),
1 ≤ i ≤ d, the union of the two intervals (i, i+ 2y − 1) and (j − 2y + 1, j), where y = dlog(j − i)e,
9small gropus in a large group is O(log1.5 n log log n) bits, and there are O(d log log n/ log1.5 n) large
groups. Thus, this contributes a space of O(d log log n) bits. As there are only d log log n/ log1.5 n
leaders, the space for the top-level structure is bounded by O(d log log n) bits. Thus, the total space
follows. uunionsq
Combining Lemma 9 with Lemma 6, we have:
Theorem 2 Let A be an integer array of length n, whose elements are from 1 to n. We can
construct a data structure for A taking O(n) words, such that any 3-sided y-max query Q(A, i, j, k)
can be answered in O(log n/ log log n) time. uunionsq
Based on Theorem 2, if we apply the framework discussed in Section 2.3 for pattern matching,
then we have following result for the VLDC-indexing problem.
Theorem 3 We can construct an index for T taking O(n) words, such that on given any ∗-pattern
P , we can determine whether P occurs in T in O(|P |+ `(logn/ log log n+ log |Σ|)) time, where `
denotes the number of ∗ symbols in P .
Proof. We define A such that A[i] = SA(i). Then, the query max(N, i, j, k) in Section 2.3 will be
equivalent to Q(A, i, j, k). uunionsq
4 Achieving Linear Search Time When |Σ| = 2O(log logn)
In this section, we improve the searching time further, in case the alphabet size, |Σ|, is 2O(log logn).
We first give the following result, which is obtained by a direct application of Makinen and Navarro’s
index in [15].
Theorem 4 [15] When |Σ| = 2O(log logn), we can construct an index for T taking O(n log|Σ| n)
bits; then, given any pattern P of length O(log|Σ| n), we can answer the following two queries in
O(|P |) time:
1. rankP (T, x): compute the number of occurrences of P in the substring T (1, x), and
2. selectP (T, j): find the jth occurrence of P in T ; uunionsq
When the pattern length is short (|pi| = O(log|Σ| n)), Theorem 4 is very useful to support
the required operations in applying Pinter’s algorithm (see Sections 2.2 and 2.3), as shown in the
following lemma.
Lemma 10 When |Σ| = 2O(log logn), we can construct an index for T taking O(n log|Σ| n) bits
such that for any pattern pi of length O(log|Σ| n), finding the last occurrence of pi in T before
position x can be done in O(|pi|) time.
Proof. To find the last occurrence of a given pattern pi before a given position x, we can first
compute rankpi(T, x) to obtain the number of occurrences of pi in T (1, x). Let this number obtained
be y. Then, if x is not an occurrence of pi, we select the (y)-th occurrence of pi in T , by selectpi(T, y).
Otherwise, we select the (y − 1)-th occurrence of pi in T . Obviously, this occurrence found is the
first occurrence of pi after x. uunionsq
When the pattern length is long (|pi| = Ω(log|Σ| n)), Theorem 2 becomes useful, as shown in
the following lemma.
Lemma 11 When |Σ| = 2O(log log n), we can construct an index for T taking O(n) words such that
for any pattern pi of length Ω(log|Σ| n), finding the last occurrence of pi in T before position x can
be done in O(|pi|) time.
11
children, and it requires O(occ× |Σ|) time in the worse case, where occ is the number of positions
reported. However, the term O(occ× |Σ|) is too large.
We can further reduce the time of the third part by maintaining some additional information.
For each internal node v in the suffix tree, we maintain a list Lv which is the sorted sequence of
the keys stored in those children of v. Then during the course of the breadth-first search, assuming
that the current visited node is v, we check the elements stored in Lv from the smallest to the
largest, put the nodes whose keys are in Lv and less than or equal to k into the queue, and stop
checking the list if a key encountered is larger than k. It is easy to see that the third part can be
reduced to O(occ) time, where occ is the total number of positions reported. Clearly, all additional
information requires O(n) words. Therefore, we have the following result.
Lemma 13 We can construct an O(n)-word index that reports all the occurrences of a given
pattern P before a position k in a text T in O(|P | + log |Σ| + occ) time, where occ is the total
number of occurrences. uunionsq
Now, we go back to the first step and try to reduce the required time when |Σ| = 2O(log logn).
If the pattern P is of length Ω(log |Σ|), Lemma 13 is enough for us to use. If the pattern P is of
length |P | = O(log |Σ|), |P | ≤ c log log n for some constant c. The following lemma shows how to
reduce the required time.
Lemma 14 When |Σ| = 2O(log log n), for patterns P of length |P | = O(log |Σ|), we can construct
an O(n)-word index such that we can answer the locus of each pattern in O(1) time.
Proof. Since |P | ≤ c log log n for some c, the total number of possible patterns are at most
|Σ|c log log n × c log log n. This is at most O(n).
To support O(1) query for any such pattern, we can construct a global table in advance. That
is, for each possible pattern, build a table to indicate the locus of the pattern in the suffix tree.
Since the answer to each table can be represented by O(1) word. So, the total table size is O(n)
words. uunionsq
By combining Lemmas 13 and 14, we have the following.
Lemma 15 When |Σ| = 2O(log log n), we can construct an O(n)-words index that answers all the
occurrences of a given pattern P on or before a position k in a text T in O(|P |+ occ) time, where
occ is the total number of occurrences. uunionsq
For the VLDC-indexing problem, the following results are direct from Lemmas 13 and 15 and
Theorems 3 and 5.
Theorem 6 We can construct an O(n)-words index that answers all the occurrences of a given
∗-pattern P in a text T in O(|P |+ ` log n/ log log n+ log |Σ|+ occ) time, where ` is the number of
∗ in P and occ is the total number of occurrences. uunionsq
Theorem 7 When |Σ| = 2O(log log n), we can construct an O(n)-words index that answers all the
occurrences of a given ∗-pattern P in a text T in O(|P |+ occ) time, where occ is the total number
of occurrences. uunionsq
References
1. Akutsu, T.: “Approximate string matching with don’t care characters.” Information Processing Letters
5 (1995) 235–239.
13
6 Appendix: Two Examples
In Fig. 1, assume that we want to determine whether 6 is in SA(5, 12). For each node v, we label
the b−11 (i) for the elements stored in v on the edge to its parent. At the beginning, we compute
b−11 (6) = 1, b
−1
2 (6) = 2. Thus, we first compute the new search range on v1 by using the countv
operation, and obtain (2, 3), where v1 is the root of D. Therefore, the new search range on the
2-nd child of v1, denoted by v2, is (2, 3). Again, we search for the new search range on the 3-rd
child of v2 and obtain (1, 1). Finally, we arrive the leaf which contains the single element 6 and
report that 6 exists in SA(5, 12).
In Fig. 2, let v be the bold vertex in the tree. For each node u in the tree, the Lu and Ru are
represented as the sequence with parentheses and square brackets. If we want to find all positions
stored in the subtree rooted at v less than or equal to 5, we first traverse from the root to v. Since
the key contained in the root is 1 and the leaf containing 1 is not in the subtree rooted at v, 1 is
not reported. Next, v is encountered. Since the key stored in v is 2 which is less than or equal to 5,
we report 2 as an occurrence. Then we traverse the lists stored in v. Since the first element in Lv
is 3 which is less than 5, 3 is reported and we put the node into the queue of breadth-first search.
However, the next element in Lv is 7 which is larger than 7; therefore, we stop scanning Lv. Since
Rv is not empty, we scan Rv from the smallest element to the largest one. However, since the first
element in Rv is 8 which is larger than 5, we stop scanning Rv and do not report any position.
Then we continue to execute the breadth-first search. The next node visited is the node containing
key 3. Let the node be u. Again, we scan Lu (which is empty) and Ru. Then report the positions
in Ru less than or equal to 5. Since the only element in Ru is larger than 5, no element is reported.
Finally, we have the set of positions stored in the subtree rooted at v less than or equal to 5 are 2,
3.
