 II
中文摘要 
垃圾郵件（SPAM）的處理已經成為一個全球性的重要工作。目前針對垃圾郵件的處理方
式是 white/black list 或以關鍵字來進行過濾，並假設這些特徵是固定的。使用機器學習的方
式對郵件分類問題作自動化處理，其前提是要擁有問題合適的特徵描述，並依據此特徵作
為分類的量測依據。目前的機器學習技術不足之處在於 SAPM 是「活」的，會經常改變其
特徵。此外，人類可以精確的經由內文文字意義的理解，而分辨 SPAM 與否。但如果要以
相同的技術進行內文的分析，會有特徵的選擇不易與數量龐大等問題。以傳統文字或語言
的理解的統計式或歸納式方法，需要較多的計算時間。對於即時 SPAM 的處理，較不適用。
本計畫分成三大部分，分別在計畫編號 NSC 94-2213-E-390-007、NSC 95-2221-E-390-023-、
NSC 96-2221-E-390-004 完成： 
1. 重新定義並取得 SPAM 的特徵：我們相信 SPAM 的寄送是為了達到某種寄件者的
目的，所以在寄送郵件時會有一些「行為」特徵，例如大量寄發、偽造資料、分
時寄發與多重轉寄等數種特徵，這些特徵不是直接表現在關鍵字上，但是人類卻
可以快速判斷郵件是否為 SPAM。因此，人類具有分辨 SPAM 的背景知識
(background knowledge)。如果能將此背景知識拿來作為分辨 SPAM 的「特徵」，可
以達到更好的 SPAM 過濾效果。這部分以知識工程中的知識擷取技術來進行，並
以可以邏輯化處理背景知識的歸納技術加以驗證。 
2. 發展具自我調整型的漸進增量型、高效率機器學習演算法對新特徵的SPAM進行
分類：由於目前應用在SPAM過濾的機器學習技術都是以關鍵字形式、批次化處理
訓練資料，其成效隨樣本與時間的變化而效果變差。我們預計以第一部分新定義
的SPAM特徵，發展具自我調整型(adaptive)的漸進增量型(incremental)機器學習演
算法，所使用的機器學習技術為ANN、PSO、SVM等軟性計算的方法。 
3. 針對MAIL內文使用資料探勘方式進行有效的分析：由於人類可以經由閱讀以理
解訊息內容，而分辨SPAM與否。但如果要以傳統的技術進行內文的分析，會有特
徵的選擇不易與數量龐大等問題。本階段的計畫是希望透過資料探勘知識方式，
將文字內容建立關連索引(associative index)，作為SPAM案例的分類特徵，最後才
是整合到機器學習分類技術中，進行SPAM的分類處理。 
關鍵詞：電子郵件、垃圾郵件、機器學習、人工智慧、知識工程、知識擷取、
軟性計算、支持向量機 
 IV
or unchanged words. However, SPAMs are alive and change the words used. In the 3rd 
year’s project, we employed data-mining techniques to analyze the contents of emails 
and build associative models of texts used in emails. With such text-association models, 
emails classified accordingly. Finally, we will integrate all the techniques for 
sophisticate SPAM filtering.  
 
Keywords: E-mails, SPAM, Machine Learning, Artificial Intelligence, Knowledge 
Engineering, Knowledge Acquisition, Soft-Computing, Support Vector Machine 
 
 
 
 
 2
圖表目錄 
圖表 1：過濾郵件的方法.......................................................................................................... 9 
圖表 2: 研究架構圖................................................................................................................. 11 
圖表 3：知識庫系統與知識擷取的關係................................................................................ 12 
圖表 4：個人認知時間區間.................................................................................................... 17 
圖表 5：時段計數統計圖........................................................................................................ 17 
圖表 6：區間 1 的歸屬函數.................................................................................................... 18 
圖表 7： 「郵寄時間異常」的特徵屬性梯型函數表示...................................................... 18 
圖表 8：「常發生的郵寄時間」模糊語意函數以梯型函數.................................................. 18 
圖表 9：認知領域歸屬函數表................................................................................................ 19 
圖表 10：判斷為垃圾郵件的模糊方格表(一) ....................................................................... 20 
圖表 11：判斷為垃圾郵件的模糊方格表(二) ....................................................................... 20 
圖表 12：表垃圾郵件認知的模糊方格表.............................................................................. 21 
圖表 13：模糊方格流程圖...................................................................................................... 22 
圖表 14：模糊方格表實驗流程圖.......................................................................................... 25 
圖表 15：離散型態編碼.......................................................................................................... 42 
圖表 16：位元式編碼.............................................................................................................. 42 
圖表 17: 轉換函數及學習法則交互實驗參數值設定........................................................... 43 
圖表 18:學習效能組別(由轉換函數與學習法則學習曲線判斷) .......................................... 44 
圖表 19：高網路學習效能組別(由轉換函數與學習法則C.V.MSE判斷)............................ 44 
圖表 20：高網路學習效能組別(由轉換函數與學習法則混亂矩陣判斷) ........................... 45 
圖表 21：網路學習效能組別得分表(由轉換函數與學習法則整體表現判斷) ................... 45 
圖表 22：隱藏層及處裡單元交互實驗.................................................................................. 45 
圖表 23：離散型網路結構...................................................................................................... 46 
圖表 24：位元型網路結構...................................................................................................... 46 
圖表 25：使用BPNN的實驗結果 ........................................................................................... 47 
圖表 26：對時間變化的分類效果.......................................................................................... 48 
圖表 27：與KB系統的比較 .................................................................................................... 49 
圖表 28：其他軟性計算分類技術的比較.............................................................................. 49 
圖表 29：關連規則的問題...................................................................................................... 52 
圖表 30：Not_be Covered Rule............................................................................................... 55 
圖表 31：CARC演算法主要流程 ........................................................................................... 55 
圖表 32：CARC演算法詳細流程 ........................................................................................... 56 
圖表 33：Lk流程圖 ................................................................................................................. 57 
圖表 34：訓練資料分類.......................................................................................................... 58 
圖表 35：CondensedAR .......................................................................................................... 60 
圖表 36：CARC參數設定 ....................................................................................................... 61 
圖表 37：UCI測試資料集 ....................................................................................................... 61 
 4
 
一、前言 
網際網路的普及已改變了人類的生活，例如：網路上瀏覽新聞漸漸改變訂閱報紙的習
慣；收發電子郵件已成為網路使用者日常工作的主要通訊方式；網路線上交易讓買賣雙方
多了一種購物方式。在商業交易市場上，網際網路也扮演一種新的交易管道。利用網路進
行商品行銷不但可以節省大量的成本且又快速便利。其中，利用電子郵件進行商業行銷是
一種普偏的方式。透過電子郵件的網路行銷，其優點是成本低、宣傳效果大；缺點是未經
允許的商業訊息郵件，往往會造成電子郵件的收信者很大的困擾。 
所謂垃圾郵件(Junk Mail)從廣義來探討[36][35]指的是利用大眾網路，未經允許或契約
而主動大量寄送的訊息傳遞行為。這些大量的垃圾郵件如同實體信箱所收到的廣告傳單。
在狹義的定義[29]指的是那些不請自來的商業廣告性電子郵件(Unsolicited Commercial 
Email, UCE)，或是不請自來的大量郵件(Unsolicited Bulk Email, UBE)[26]，特別是那些令人
困擾的、大量發送的郵件，人們將這二項統稱為“SPAM”。相對來說，正常的郵件稱之為
“HAM”。不管是SPAM、Junk Mail、還是UCE、UCB都代表著網路上一種干擾行動。垃圾
郵件『污染』網路世界的情況有多嚴重？根據Ferris的研究調查顯示，平均每個網路使用者
每天收到的垃圾郵件量，將從 2003 年的 5~10 封，成長到 2008 年的 30~40 封。此外根據
Gartner公司的研究報告指出，2003 年電子垃圾郵件大約占總電子郵件流量的 50%。2006
年 10 月行政院研考會在數位落差調查報告中，統計台灣總上網人口達到 1,260 萬人，對垃
圾郵件收發情形調查發現，台灣網路人口一天收到 50 封以上者佔 19.1%, 40~49 封佔 2.0%, 
30~39 封佔 5.2%, 20~29 封佔 10.4%, 10~19 封佔 17.2%, 10 封以下者佔 30.7%,0 封 3.9%,不清
楚佔 11.6%。所以，垃圾郵件的成長明顯增加，進而問題影響的範圍也擴大，產生的問題
需解決。 
垃圾郵件的大量寄發所引起的問題很多，例如：電子郵件收件者為了辨別垃圾郵件與
正常郵件，而造成個人時間成本的浪費、工作效率的降低以及生產力的低落。更有許多電
子郵件帳號被垃圾郵件業者濫用，使得正常的帳號可能會被誤列入不受歡迎的寄件者名單
而造成困擾。郵件伺服器有限的儲存空間，會被垃圾郵件塞滿，造成正常郵件無法正常寄
送。垃圾郵件占住大量的頻寬，堵塞郵件伺服器的運行，影響正常郵件寄送的速度。垃圾
郵件常常夾帶惡意攻擊的病毒程式，影響電腦正常運作。垃圾郵件也常被「網路釣客」
（phisher）所利用，騙取電子郵件使用者的機密資料，例如銀行帳戶帳號與密碼等。垃圾
 6
漸變差。 
所以以固定的 keywords 作為分類 SPAM 的機器學習演算法的 feature 並不合適。本計畫從
機器學習的角度分析 SPAM 的特性，以取出特徵並發展有效過濾方法為目的。以下分三年
的計畫結果說明本計畫的成果。 
 8
針對Classify有Richard等人[22]提出Mailcat方法與Robert[23]的Channel概念等。其次，針
對Content
一般的垃圾郵件過濾方法是從郵件訊息的內容著手，最早期是結合著寄件人白名單
(wh
另一方面，比較被廣泛應用的垃圾郵件過濾是利用關鍵字辨識以進行分類，此類過濾
方式
使用文字分類為大多數自動化郵件過濾的規則，一般是分析郵件的訊息內容特徵。
Moo
針對郵件 Content 或 Text Mining 的研究，Olivier Y. et al. [50]應用 SVM 針對 Author 來
(Genetic programming)來分類垃圾郵件，並與貝氏分類演算法的方法做比較。Boone[11]提供
Re:Agent系統來做郵件分類與擷取其相關資訊。 
或Text Mining的研究，de Vel等人[21]提出利用Author來作識別加以分析結構特性
與語意、Mobasher等人[2]提出一套通用的架構適用於個人化的郵件與Content Mining、上述
研究與工具，大部份是以用戶端為考量及利用關鍵字過濾的方法為基礎，然而重覆的垃圾
郵件會在郵件伺服器中不同帳號的mailbox出現，且關鍵字時常會變化。  
itelist)或黑名單(blacklist)進行，白名單乃指那些在收件者電腦上已設定可以接受其郵件
的寄件人名單。通常設定白名單的方法是將曾經認定為正常郵件的寄件人之電子郵件位址
列入名單中。白名單的設定方式不是很有效的，因為只設定讓白名單通行的方式可能會漏
失掉很多不在白名單內的正常郵件[47]；黑名單的涵義與白名單相反，泛指那些已設定不予
接受其郵件的寄件人名單，這類過濾方式的缺點在於垃圾郵件位址的變動相當頻繁而不易
掌握。 
通常是鎖定某些具垃圾郵件特徵的關鍵字，例如「信用貸款」、「sex」等。關於 spam
在關鍵字過濾(keyword-based filter)上的研究，部份是應用 Naïve Bayesian [55]理論，配合屬
性 words+ phrases+ non-textual 的組合來進行 [28]。Gray Boone [22]提供 Re:Agent 系統進行
郵件分類與擷取其相關資訊；Hooman [26]比較 Genetic Programming 與 Naïve Bayes 的過濾
效率；Elisabeth Crawford [16]則使用 Inductive logic programming(ILP)技術，自動由 learning 
rules 中找尋規則，歸納成一因果關係的 filtering rules，以方便郵件分類(classifying email)。
綜合上述研究，係以使用者端為考量與 email message 為研究對象，對於存有變化性的
spam，當問題的複雜程度增加時，需要不斷地修改其過濾條件，否則將無法適用，因此可
能不適合一般的收信使用者。 
ney et al. [41]提出以 naïve bayesian 演算法進行文字分類。此演算法以產生文字特徵為
基礎，它的優點是其郵件分類的能力乃超越以關鍵字規則基礎的系統[33]，而缺點在於其難
整合於郵件寄收軟體內，因為它在分類上缺乏一種規則性的表現。 
 10
將郵件
寄件人加入黑名單或安全清單中，以進行郵件過濾。另外也有將防堵垃圾郵件功能與
防毒功能結合的軟體，例如著名的諾頓網路安全大師 與國
術來建立垃圾郵件的型態，需要花費長時間讓它學習如何辨識垃圾郵件
通行。
Spamkiller [39]利用安全層級的設定來決定防堵垃圾郵件的等級，並提供
Norton Internet Security [59]
內趨勢科技所推出的 PC-Cillin 2004 [60]防毒軟體。InBoxer [2]利用語音辨識軟體的技
。SpamCatcher 
[38]是垃圾郵件的阻擋軟體，其過濾機制為建立垃圾郵件定義檔，以杜絕垃圾郵件的
 
3.2 研究方法 
知識擷取（Knowledge Acquisition）的目地是為擷取特定的問題與解決問題的方法，而
不同的知識型態就有其適用的獲取技術。知識擷取是專家與知識工程師的互動過程，從專
家中萃取、結構與組織知識，然後將所獲得的知識、解決策略與經驗法則轉換成為知識庫
或電腦數位化表達形式的一連串程序，並歸納為知識庫可以儲存格式的過程。知識的擷取
及歸納往往決定了專家系統推理的效率與準確性，良好的人機介面、有效的與專家交談，
在互動模式中取得正確而完整的知識，如下圖。 
人類專家
概念
問題
知識工程師
知識擷取 知識庫系統
知識擷取
使用者界面
知識引擎
使用者
歸
納
 
圖表 3：知識庫系統與知識擷取的關係 
目前發展方法有如卡片排序法（card sorting）、構念排序法（concept sorting）[19][24] 、協
議分析法（protocol analysis）、階梯法（the laddered grid）[24][25]、訪談法（interviewing）
[9][10][8]，和Repertory Grid 技術。 
Repertory Grid 技術是運用一種半結構性的訪談過程，以得到專家在解決問題時的內心
模式且得到專家在解決問題時的決策行為模式為目的，從資料表中找出尋相似屬性以區分
不同屬性資料的方法。它是由元素(element)、構念(construct)、連結(link)等三主要成份所組
合成的矩陣式表格。由於Repertory Grid 技術具備以下優點[17]：(1)以人類心理學為基礎。
(2)適合多種類的問題、使用簡易的格式化或詮釋問題。(3)使用清楚簡單的方法來區別在元
素和構念間的程度描述程度差異。(4)可以簡化使用者系統界面的設計、使用方簡單易學。
(5)可動態新增的模式來使用。(6)可用來分析組織與邏輯知識擷取和顯出隱藏的專家知識。
(7)可使用演算法、程式、軟體方式抽出和擷取應用在自動知識擷取。 
 12
z 郵件內容表示方式為靜態圖片顯示型態 
z 郵件內容表示方式為短篇動態影像檔顯示型態 
z 郵件內容表示方式為商業廣告型態顯示型態 
z 郵件內容表示方式為確認個人重要資料等待回覆型態 
z 郵件內容表示方式為認證通知回覆型態等的集合 
步驟二：研究範圍在受訪者人數選擇訪談對象為 M 人，且俱電子郵件使用者頻
率高的有經驗受訪者接受訪談。 
步驟三：分為 A、B 部份受測區域 
步驟 3.1：以研究中初步列出的垃圾郵件內容顯示型態分類 Ei大項，歸納為 A
部份受測區域，先進行受訪者類別圈選計數的動作。 
步驟 3.2：請受訪者除已列出的垃圾郵件內容顯示型態分類外，可再新增填入
個人認知的其他可代表列出的垃圾郵件內容顯示型態分類，歸納為 B
部份受測區域，得到的型態以 Ej 表示。 
步驟四： 
步驟 4.1：數值計數在步驟 3.1 中，A 部份受測區域，受訪者圈選次數高於 K
值的型態分類，得到的型態以 Ei 表示。 
步驟 4.2：步驟 4.1 中得到的 Ei 與 B 部份受測區域的 Ej，再一次統計次數取
得高於 K 值的型態分類。 
步驟五：完整收集 M 位受訪者的步驟三到四的實驗計數結果，整理列出經計數
結果具代表性的元素項各值，做為本研究的元素項，以θm表示。 
以符號式子表示集合： { }1,...,e e eθ = m 我們可以得到以人類認知對垃圾郵件的元素項定
義，是以電子郵件內文型態分類為主，假設從上述實驗步驟可得到具代表的類型：郵件內
容為單純文字型態、內含網頁連結型態、靜態圖片型態、商業廣告型態、確認個人重要資
料等待回覆型態、認證通知回覆型態等。 
接著引出分類元素的特徵屬性構念，主要特色是對元素間產生不同的分類區別，第三
 14
步驟四：分為 A、B 部份受測區域，數值計數 
步驟 4.1：數值計數在步驟 3.1 中，A 部份受測區域，受訪者圈選次數高於 K 值
的型態分類，得到的型態以 表示。 ic
 16
步驟 4.2：由步驟 4.1 中得到的 與 B 部份受測區域的 ，再一次統計次數擷取
得高於 K 值的型態分類。 
步驟五：完整收集 M 位受訪者的步驟三到四的實驗計數結果，整理列出經計數結果具
代表性的元素項各值，做為本研究的元素項，以
ic jc
cθ 表示。
以式子表示：
 
{ }1,...,c nc cθ = ，擷取人類對垃圾郵件中的構念可以從郵件標頭欄位、系
統記錄欄位取得構念項，例如欄位
模糊方格表中的元素和構念之間的強度關係描述，我們分為二部份討論，第一部份評
分方
從前面得到元素項 E1~E5 和特徵屬性構念 C1~C5，接著開始下列工作項目的步驟： 
步驟一，讓受訪者填入認知等級描述 
對強度程度描述的制定 。特徵屬性的描述
不同
1. 認知領域只有「是」或「否」二種，「0」表示「沒有」或「不是」而「1」
空白型態特性、亂數型態表示、主旨 Re/Fw 回覆型信件、
有時間字串特性、關鍵字出現、收件者地址人數等。 
式以五點量表等級分類，例如「欄位值亂數型態」，屬性特徵是可明確區分。第二部份
評分方式以模糊集合方式來等級分類，例如討論「收件時間異常」的模糊集合，例如描述
收件時間假設有「晚」、「太晚」等個人認知模糊集合的語意描述。實驗中選擇訪談對象為
M 個對垃圾郵件研究有一定程度了解的人，填入方格評比的等級值。 
，讓受訪者填入認知等級描述
，所以在每一個認知領域不同，如下列說明： 
表示「有」或「是」。例如「郵件位址無@符號」的特徵屬性來討論。 
2. 以數值表示構念的強度。如以「0」、「1」、「2」、「3」、「4」五點的量表法。
例如「對收件者地址人數」對郵件的判別強度分析：「1」表收件者人數
只有 1 人、「2」表收件者人數為 1~3 人、「3」表收件者人數大於 3 人 
3. 以模糊集合方式評比，例如對「垃圾郵件常發生的寄發時間」的特徵屬
半夜
a=22 b=23 d=25c=24 時間
μ
1
 
圖表 6：區間 1 的歸屬函數 
在「常發生的郵寄時間」的特徵屬性中，統整後分析受訪者認為在時間 22 點到凌晨 6 點是
屬異常時段。實驗結果可將整理時間區段的特性，分別給予不同的名詞「區間 1」、「區間 2」、
「區間 3」如表 4-3 所示。整理受訪者特徵屬性和相對應的認知領域歸屬函數，將評比方式
以下表說明，下圖將「區間 1」、「區間 2」、「區間 3」的歸屬函數以圖形表示。 
 a b c d 
區間 1 22 點 23 點 0 點 1 點 
區間 2 0 點 1 點 3 點 4 點 
區間 3 3 點 4 點 5 點 6 點 
圖表 7： 「郵寄時間異常」的特徵屬性梯型函數表示 
 
a=10
D=1
時段3
時間
μ
1
a’=03
D=2
b’= 04
D=2
c’= 05
D=2
d’= 06
D=2
時段1 時段2
b=11
D=1
c=00
D=2
d=01
D=2
 
圖表 8：「常發生的郵寄時間」模糊語意函數以梯型函數 
 18
 20
郵件位址無@符號 0 1 1 0 
郵件位址有時間
字串 
1 0 1 1 
郵件位址空白 4 3 2 0 
收件者地址人數 3 3 2 1 
郵寄時間異常 區間 1 區間 2 區間 3 區間 2 
圖表 10：判斷為垃圾郵件的模糊方格表(一) 
步驟三，重複步驟三，直到表格中是符合標準的元素、特徵屬性構念 
3.1 元素項相似度的檢查，若元素項太相近則加入構念特徵屬性區分。 
3.2 構念特徵屬性相似度的檢查，若構念特徵屬性太相近則加入元素項區
分。 
(1) 將判斷為垃圾郵件的模糊方格表認知領域歸屬函數如下表，以梯型函數表示方式列表。 
 E1 E2 E3 E4 
C1 a=b=c=d=0 a=b=c=d=1 a=b=c=d=1 a=b=c=d=0 
C2 a=b=c=d=1 a=b=c=d=0 a=b=c=d=1 a=b=c=d=1 
C3 a=b=c=d=4 a=b=c=d=3 a=b=c=d=2 a=b=c=d=0 
C4 a=b=c=d=3 a=b=c=d=3 a=b=c=d=2 a=b=c=d=1 
C5 
a=22 
b=23 
c=24 
d=01 
a=24 
b=01 
c=03 
d=04 
a=03 
b=04 
c=05 
d=06 
a=24 
b=01 
c=03 
d=04 
圖表 11：判斷為垃圾郵件的模糊方格表(二) 
(2) 步驟 3.1 依 3.3.3 節檢查元素項特徵屬性相似度 
成模糊方格表的整個流程，下圖為模糊方格表的流程圖。 
 
 
 
引出元素
引出特徵屬性構念
填入方格矩陣
評比方式：
0.1.2.3.4五點的量表法
0和1的二分法
模糊集合及歸屬函數
計算相似距離矩陣
檢查元素間
是否太相近
檢查構念間
是否太相近
完成模糊方格表
開始
結束
否
否
是
是
 
圖表 13：模糊方格流程圖 
由模糊方格表步驟中，整理產生郵件行為規則 Rj，得到如下所列的條件判斷規則： 
: IF  is  THEN  is j jR X E Y y  
0 0 1 1IF  is  and  is  ant ... and  is 
    THEN  is 
n n
j
X E X E X E
Y y
 
因此我們可以在 SPAM-FRT 裡得到規則以 表示，假設 ： SPAM SPAM
 
R R
 22
 24
關係，
第一部份：從垃圾郵件的標頭檔，標出確定性詞彙、模糊化詞彙與歸屬函數，如圖 5-1
A、 取得對電子郵件類型的分類 
1. 從標頭檔取得對電子郵件類型形容的詞彙 EA，從評選結果高於標準值 K 為
中新加形容的詞彙為 EB。 
B、 取得對郵件行為特徵形容的詞彙 
1. 從標頭檔取得對郵件行為特徵形容的詞彙 CA，從評選結果高於標準值 K 為
中新加形容的詞彙為 CB。 
為「可成立為判斷特性」、 「不可成立
者直接寫下描述認知區段，進行數量統
第二部份：將第一階段取得之受訪者填入新值帶入，再進行一次標出確定性詞彙、模
1. 將 EA2 和 EB 統整擷取高於標準值 EA3。 
 
性認知領域(是/否)；有程度的影響
 
如為垃圾郵件常發生在收件者人數「較多」的特徵，「較多」一詞無法精確表示人數
為何，但是描述人數「較多」卻和「人數個數」有比例上的密切關係，且這比例可用模糊
歸屬函數來表示。                                                        
流程所示。 
EA2。 
2. 從受訪者
CA2。 
2. 從受訪者
3. 讓受訪者評選 CA 中，適合的評選標準
為判斷特性」、「需有程度上的差異」。 
4. 針對模糊化描述詞彙取得進行，讓受訪
計保留高於標準值 K。 
糊化詞彙與歸屬函數，如圖 5-1 流程所示。 
2. 將 CA2 和 CB 統整擷取高於標準值 CA3a。
3. 配合 CA3a 屬性評選的量表如可成立為判斷特
認知領域「非常不確定」~「非常確定」有(1、2、3、4、5)等表示構念的強度。 
4. 模糊化描述詞彙，統計區段的強度，分析強度區間特性程度描述的歸屬函數區
間值為 CA3b。 
 26
形 
 副本收件人地址(Cc)有空白出現的情形、有時間字串出現的情形 
 副本收件人地址(Cc)認為是假造資料的情形，有數字、亂數、特殊符號出現的情形 
 寄件者地址(From)有空白出現的情形 
 寄件者地址(From)有時間字串出現的情形 
 寄件者地址(From)認為是假造資料的情形，有數字、亂數、特殊符號出現的情形 
 收件者地址(To)有空白出現的情形 
 收件者地址(To)有時間字串出現的情形 
 收件者地址(To)認為是假造資料的情形，有數字、亂數、特殊符號出現的情形 
 回應的郵件位址(Return-Path)和寄件者地址(From)不同地址的情況 
 和收件者地址(To) 不同地址的情況 
 郵寄信件時間(Date)內容錯誤 
特徵屬性項目屬模糊函數值(CA3b)會得到新詞彙： 
 認為垃圾郵件常發生在收件者人數(nrcps)的特徵為 
z 區段 1：10 人以下；區段 2：10-30 人；區段 3：30 人以上 
 認為垃圾郵件常發生在的郵寄信件時間(Date) 
z 時段 1：22:00-00:00；時段 2：23:00-01:00；時段 3：00:00-03:00；時段 4：
02:00-05:00 
 垃圾郵件在常發生的郵件傳送路徑長度(Received)次數 
z 區段 1：長度 4 以下；區段 2：長度 4~7；區段 3：長度 7 以上 
本節實驗得知最初從受訪者取得電子郵件顯示類別的元素項，與描述垃圾郵件行為詞
彙特徵屬性，將受訪者的認知轉換成數值化表示，再進一步分析出描述詞彙是可以分成可
明確區分值與模糊化語意描述詞彙，得到更具描述的詞彙特徵屬性，在實驗結果中有些不
屬本研究的設定範圍或描述重覆性太高…等其他不適合的因素，所以在實驗過程中低於標
準值則不討論。例如元素項「為認證通知回覆型態等的集合」結果遠低標準值，分析可能
是此元素項的特性不夠明顯，受訪者不易明確評比。 
6. 錯誤率：指未能正確分類郵件的比率。由表 5-7 (B)中可以分別計算正常郵件與垃圾郵
件的錯誤率，其計算方式如下： 
 正常郵件的錯誤率：指 False positive 的比率 + unclassified 的比率，即為
59 0 38%
155 155
+ =  
 垃圾郵件的錯誤率：指 False negative 的比率 + unclassified 的比率，即為
0 0 0%
312 312
+ =  
正常郵件/垃圾郵件的實驗數據 
 人工判斷 Classified False positive Unclassified 
正常郵件 155 96 59 0 
垃圾郵件 312 312 0 0 
分類的正確率與錯誤率 
 正確率 錯誤率 
正常郵件 62% 38% 
垃圾郵件 100% 0% 
垃圾郵件規則數使用的變異數分佈，發現在電子郵件顯示型態屬網頁連結類別（A2）
規則的符合次數相差大於其他種類，反之，在電子郵件顯示型態屬文字類別（A1）與電子
郵件顯示型態屬靜態圖片、動態影片類別（A3）所產生的規則是符合次數差異較小，在判
斷垃圾郵件的規則上出現較平均。在 A2 規則分佈從平均數與變異數的結果分析，表示這
些規則中有些不符合 A2 類別判斷垃圾郵件的特性。 
正常郵件驗證規則，發現在電子郵件顯示型態屬文字類別（A1）規則符合平均次數與
變異數的關係，得知，在 A1 的規則中得知符合的條件都明顯的與 A2A3 多，但是也發現變
異數呈規符合條件呈不平均的分佈，所以，在 A1 的規則中發現正常郵件中產生的機率也
比電子郵件顯示型態屬網頁連結類別（A2）、電子郵件顯示型態屬靜態圖片、動態影片類
別（A3）高。 
本研究中驗證判斷垃圾郵件規則的正確率達 100%，表示在對判斷為垃圾郵件的認知
下所擷取的條件是可以達高正確率的判斷結果。產生模糊方格表可得到的規則條件是可以
 28
 四、計畫第二年 
4.1 研究目的 
目前已有許多機器學習的技術被用來過濾 SPAM，如決策樹(Decision Tree)、貝式分類
器(Naïve Bayes Classifier)與案例式學習(Case-Based learning)等，這些方法大都使用關鍵字
(keyword)來萃取郵件的屬性。如同前面所述，SAPM 是「活」的，SPAM 的寄送者為了防
止郵件被過濾掉，他們會經常改變主旨和內文的用字遣詞，所以先前所使用的關鍵字可能
不會出現在新型態的 SPAM 裡，因此造成過濾 SPAM 的成效不彰。第一年的研究取得新的
SPAM 的特徵定義後，經過 ILP 的歸納，可以初步定義出具可理解（reasonable）且可閱讀
(readable)的 SPAM 分類規則。但是，ILP 雖然為 white-box reasoning，但是其效率較慢，適
合萃取可閱讀式的高階符號型態知識（high-level symbolic knowledge）。如果要進行高效率
的機器學習分類技術，勢必要進行數字型態的推理(numeric reasoning)。典型的數字型態的
分類技術為類神經網路（artificial neural network, ANN）、支持向量機（support vector machine, 
SVM）、粒子群優最佳化（particle swarm optimization, PSO） 技術等。這些方法可以處理
高維度（high dimension）特徵的問題，但是需要完整的訓練範例集（training set），才能發
揮其功效。本年度計畫目的是發展以軟性計算、機器學習技術在 SPAM 過濾與自動化處理
的研究。重點在於開發增量型(incremental)機器學習技術，使改良後的 ANN、SVM 及 PSO
等分類技術，可以以 incremental 的方式處理第一年所建立的新的 SPAM 分類 features。基
本的研究構想如下圖所示： 
具自我調整型的漸進增量型機器學習演算法
Normal/Spam 
Mails
or al/ pa  
ails
目標函數
定義
新的SPAM
特徵定義
新的SPAM特徵定義轉換成feature vector Adaptive learning
Classification 
model
lassificati  
el
Adaptive, incremental
軟性計算技術
(SPO,SVM)
a tive, i cre e tal
( , )
Incrementally updating
train
Classification
results
Feedback
 
4.2 研究方法 
 30
 32
最適化應用網路 對一問題決定其設計變數值，使其在滿足設計限制下，使
設計目標達到最佳狀態的應用。 
 
在神經元的資訊處理過程裡有兩階段，分別是學習(learning phase)階段與回想(retrieving 
phase)階段。除了最適化應用網路的運作不需使用樣本，其它的神經網路的運作，均需
經過這兩個階段。由學習過程來調整連接權值獲取最適當的權重值，網路再依回想演
算法從輸入的資料決定輸出資料。茲將學習與回想階段分述於下： 
1. 學習階段(training/learning)：類神經網路最顯著的特徵就是它們對資料的學習能
力，其從範例中學習以調整網路連結加權值（即權重），此加權值將隨新的訓
練範例而更新，通常，最佳的權重值是透過匹配的「能量函數」(Energy function)
而獲得的。能量函數是用來衡量網路的學習效果，因此網路的學習過程變成使
能量函數最小或最大化的過程。例如監督式學習演算法裡，在推論值與目標值
的演算之間即是將最小平方差(least-squares-error) 最小化。 
2. 回想階段(recall)：有許多的非線性系統被設計去回想目標範例，所得知結果可
能是已分類，也可能是再更新其回想能力，而最後的神經回想值將被輸出。 
 
 倒傳遞類神經網路：SPAM 分類屬於監督式學習。而監督式學習的模式又分為感知
機網路(perceptron)、倒傳遞類神經網路(back-propagation network, BPN)、機率神經網路
(Probabilistic Neural Network)、學習向量量化網路(learning vector quantization, LVQ)以
及反傳遞網路(counter-propagation network, CPN)。其中以倒傳遞類神經網路的精確度
最高、最廣被為使用的一種模式，而這也是本研究將使用的方法。 
 倒傳遞類神經網路為一包括輸入層(input layer)、隱藏層(hidden layer)及輸出層
(output layer)三層結構之神經網路，其中輸入層用以表現輸入變數 X ，內部單元數 i 依
問題型式而定；隱藏層 net 用以表現輸入處理單元間之交互影響，其單元數目需以試
驗方式來決定最佳數目；輸出層 Y 用以表現輸出變數，其單元數目亦依問題的型式而
定。倒傳遞網路屬於多層前向網路架構(multi-layer feed-forward network)，其基本原理
採用最陡坡降法(gradient steepest descent method)作為訓練網路的方法，方法是將誤差
函數最小化，採用非線性的轉換函數以處理輸入輸出間之非線性映射關係。 
倒傳遞類神經網路屬於監督式學習網路，其學習過程是藉由訊息正向傳播
(forward-pass)與誤差修正負向傳播(backward-pass)兩階段所組成，如下圖所示。前者在
運作時其權重是固定的，而後者運作時，其權重先是不變，待其取到誤差參數值 d 後，
再配合所選取的學習法則以調整權重。正向傳播過程中輸入訊息後從輸入層經由隱藏
層權重運算，透過轉換函數處理後，傳向輸出層運算輸出，每一層神經元的狀態僅影
響下一層神經元的狀態。若於輸出層無法得到期望的推論值，則轉入誤差修正負向傳
播，將推論值和目標值間的誤差，沿原來的連接通路返回，並利用最陡坡降法以修正
各層神經元的權重值與閥值，期能使誤差函數值達到容忍誤差範圍而停止。 
Step 7. 跳回步驟3，重複計算誤差至最小容忍誤差範圍內，或達到預設訓練次數時，
網路即停止計算。 
2. 回想過程 
Step 1. 設定網路參數，並讀入收斂後之權重值及各處理單元閥值。 
Step 2. 輸入驗證範例的輸入值。 
Step 3. 計算網路輸出的推論值。 
 
倒傳遞網路建構流程 
 支持向量機（support vector machine, SVM） 
 支持向量機基本原理 
SVM是以統計學習理論為基礎所發展而來的一種機器學習方法，其是Vapnik與他的同
事於1995年所提出。近幾年來，支持向量機被廣泛應用在許多的領域，如手寫識別、語音
識別、人臉偵測、文件分類、生物資訊等，而且都有良好的表現，因而受到許多生物資訊
研究者的矚目。接下來我們將簡要地介紹支持向量機。假設有一個學習機器來做分類的工
作，我們可以使用預期的測試誤差來衡量它的效能，在統計學習理論將之稱為期望誤差，
或稱為真正的誤差，如公式1， 
[ ] | ( ) | ( , )X YR f f x y dF x×= −∫ y  (1) 
x 是輸入的變數，y 是輸出的變數，f(x) 是學習機器輸出的類別，F(x,y) 是資料集裡 x 和 y 
的聯合分佈函數(joint distribution function)。而且假設訓練集和測試集的資料是從 F(x,y) 這
個分佈來取出，且為獨立和一致的(independently and identically, i.i.d)。但是大部分的機器學
習演算法包括類神經網路，都只考慮最小化經驗風險(Empirical Risk Minimization)這個原則
來學習並產生一個 model，如公式 2， 
 34
一個超平面來區分N+1個資料點，此時的VC dimension就為N+1。然而支持向量機的VC 
dimension是否為N+1呢？因為它有考慮到邊界(margin)，所以其VC dimension並不是N+1。
支持向量機是利用邊界來控制VC dimension，它是找出最大的邊界，而使得VC dimension
來降低，如此一來複雜度就會降低。 
 SVM中最佳超平面 
在實做支持向量機時，主要是找出一個超平面來區分資料，使之區分成兩類。當輸入
的資料點可以用一個線性的超平面來區分它時，我們稱它為線性支持向量機(Linear Support 
Vector Machine)，如下圖(a)所示，它是屬於線性的分類器，也就是決定函數(Decision Function)
是一個線性的函數。 
然而，可以將資料區分成兩類的超平面不只一個，它可能會有很多種選擇，如下圖(b)
所示。此時，就需要找出一個最佳化的超平面(Optimal Hyperplane)，來區分這些資料，使
其誤差達到最小。 
                     Hyperplane
    
 
 
依照 Vapnik的解釋為，求出最大的邊界(margin，ρ)，如下圖所示。此時的超平面為最
佳化，而這最佳化超平面可以讓誤差達到最小。當資料點 x 落在邊界上，則稱此x為支持向
量(support vectors)，如下圖(a)所示。 
當支持向量機在訓練時所找出的超平面，不是最佳化時，也就是其邊界不是最大時，
則會使得容錯率會下降，結果是訓練的誤差會很小，但是在做測試時，會因為容錯率太小，
反而使得測試集的資料點很容易被分錯邊，此時則會降低預測準確度，此種現象有類神經
網路過度學習的味道。如下圖(b)所示。 
ρ 
                最大的邊界(margin)
 
 
                    support vector 
  
預測時被分錯邊  
 
當最佳化的超平面可以正確地區分訓練集裡的資料，此時稱為線性可區分型態，也就是訓
練集裡的資料落在正確的位置。此時的邊界型態又稱為 hard margin。當訓練集的資料包含
 36
第一是此種轉換是非線性的，第二是特徵空間的維度要夠高。所以我們需將資料點從輸入
空間映射至高維度特徵空間，然後再來區分它。此時可以使用公式(5)來將這些資料從輸入
空間映射到高維度的特徵空間， 
 38
T f
0 1 n  ( )=[ ( ), ( ),..., ( )]   
nR Rϕ ϕ ϕ ϕ∈ ∈ax x x x x  (5) 
其中，x：為輸入的資料，其維度為n。ϕ(x)：將x映射到高維度的特徵空間，其維度為f，且 
f > n。ϕ：為將資料映射到特徵空間的函數，也就是將資料從  n fR Ra 。 
當我們將資料映射過去，接下來要找出最佳的線性超平面，此時所面臨的問題跟輸入
空間是一樣的，此最佳超平面是否可以正確地區分資料點。在特徵空間裡，若線性的超平
面可以正確地來區分這些資料點，則我們所要最小化的成本函數為， 
1min    ( )=
2
.    ( ( ) ) 1      for  =1,2,...,Ti is t y b i N
φ
ϕ + ≥
Tw w w
w x
 
(6) 
目標函數同上一小節的線性支持向量機，只要將x改為ϕ(x)即可，也就是這些向量是從
特徵空間裡取出，而不是原來的輸入空間， 
1 1 1
1
1max   ( ) ( ) ( )
2
.   (1)    0  (2)    0      for  1, 2,...,
N N N
T
i i j i j i
i i j
N
i i i
i
Q y y
s t y i N
α α α α α ϕ ϕ
α α
= = =
=
= −
= ≥ =
∑ ∑∑
∑
x x j
1
1
 
(7) 
當解出對偶問題中的 α1, α2,…, αN之後，接著可以再將αi代入公式(8)(9)(10)來求出w和
b。 
0 0.
1
( )
N
i i i
i
yα ϕ
=
=∑w x  
(8) 
( )
0 01 ( )   for  =
T s
ib yϕ= − +w x  (9) 
( )
0 01 ( )   for  =
T s
ib yϕ= + −w x  (10) 
則決定函數為： 
( ) = sign( ( ), +b)   , b f ϕ  x x w w 和 為已知，這就是所謂的 model。 
在測試階段，輸入測試集的資料 x，使用上述的決定函數來計算出 值，最後再決
定其類別為何。 
( ) f x
由上述可以得知，我們會先將原始問題轉換為對偶問題，而觀察對偶問題時，發現在
對偶問題中，資料的處理都是用到向量內積(inner product)，因此若要在特徵空間學習，只
要能計算出資料在特徵空間中的內積值就可以了，並不需要直接把資料映射到特徵空間。 
 核心函數 
其中，vi：是 Particle 的速度。假設一個群體有 n 個 Particle，則 i = 1, 2, 3, …, n。PSO
的概念為每個尋優的問題解都被想像成一個 Particle，我們使用向量來表示一個
Particle。假設這個問題有 d 個解，則每個 Particle 的向量將會是 d 維。每一個 Particle
的速度向量表示法為 vi =vi1, vi2, …, vid。xi：是 Particle 目前的位置。假設一個群體有 n
個 Particle，則 i = 1, 2, 3, …, n。每一個 Particle 的位置向量表示法為，xi =xi1, xi2, …, xid。
yi：每一 Particle 到目前為止，所出現的最佳位置。每一個 Particle 的最佳位置向量表
示法為，yi =yi1, yi2, …,yid。所有的 Particle 都有一個 fitness value 以判斷目前的位置之
好壞，是否要更新歷代中最佳位置，而此 fitness value 則是根據目標函數(objective 
function)計算而得到的。假設目標函數是求最小值，當 f(xi)<f(yi)時，則 yi=xi。r1 是介
於(0,1)之間的隨機數値，其呈均勻分佈(uniform distribution)。c1 介於(0,4)之間的整數，
通常設定為 2。 
 社會模式(Social-only model)： 
 40
)i2 2 ˆ=  ( -i iv c r y x  (13) 
其中，vi：是 Particle 的速度，用來決定 Particle 飛行的距離與方向。xi：是 Particle 目
前的位置。 ˆiy ：所有 Particle 到目前為止，所出現的最佳位置。 ˆiy =max{y1, y2, …,yn }。
r2 是介於(0,1)之間的隨機數値，其呈均勻分佈(uniform distribution)。c2 介於(0,4)之間的
整數，通常也設為 2。 
混合模式： 
1 1 2 2 ˆ=  ( - )+  ( - )i i i iv c r y x c r y xi  (14) 
( +1)= ( )+ ( +1)i i ix t x t v t  (15) 
其中，xi(t+1)：是 Particle 下一代的位置，其是使用下一代的速度來更新。xi(t)：是 Particle
目前這一代的位置。vi(t+1)：是 Particle 下一代的速度。 
PSO 主要原理，在於讓每一個 Particle 能夠獨立搜尋個體的最佳位置，並記錄在個體記憶
中；因此每一個 Particle 都會擁有歷代最佳位置的記憶。在認知模式中，Particle 依照歷代
最佳位置的記憶，修正下一次搜尋的速度。在社會模式中，每一個 Particle 會依照其歷代的
最佳位置，互相比較後，擇優當作群體最佳位置的代表。而真正使用時，則是結合認知模
式和社會模式而得的混合模式，如式子(14)所示；如此，能有效找尋全域最佳解。 
Particle 移動的運動速度，除了會受認知模式的自我記憶影響外，也會被社會模式的群
體力量所影響，將速度做區域和全域的考量，來修正下一次 Particle 該移動的位置，如式子
(15)。一開始 Particle 平均分佈在搜尋空間中，並各自找尋自我認知的最佳位置，執行多次
世代的移動後，Particle 會漸漸移動至全域最佳解附近，而形成粒子群，來加強全域解的快
速逼近，這也是社會模式的用意。不過還是會有部分的粒子，不在這粒子群，這是為了避
特徵編碼 
首先，我們必須先對特徵進行編碼。每一封郵件的特徵，個別出現在 HEADER 或 SYSLOG
中的，稱為 B-Feature；用來交叉比對 B-Feature 的稱為 X-Feature。本研究採用兩種編碼方
式： 
離散型態編碼：如下圖。 
 
圖表 15：離散型態編碼 
 
位元式編碼：如下圖。 
 
圖表 16：位元式編碼 
兩種編碼可以如下變化： 
 42
 44
SigmoidAxon ◎ ◎    
LinearTanhAxon  ◎    
LinearSigmoidAxon ◎ ◎  ◎  
SoftMaxAxon ◎ ◎ ◎ ◎  
BiasAxon      
LinearAxon      
Axon      
圖表 18:學習效能組別(由轉換函數與學習法則學習曲線判斷) 
2. 誤差均方值下之判斷 
  我們挑選出誤差均方值較低者(C. V. MSE<0.04)並整理出下表。在本表中，
SigmoidAxon-Step、LinearSigmoidAxon-Step 與 LinearSigmoidAxon-Quickprop 表現亦很
突出(C. V. MSE<0.03)。 
C.V.  MSE Step Momentum ConjugateGradient Quickprop DeltaBarDelta
TanhAxon 0.051325 0.055241 0.049258 0.07653 0.414589 
SigmoidAxon 0.023477 0.055241 1.120692 0.063352 0.834825 
LinearTanhAxon 0.062716 0.078056 1.560767 0.085168 1.207392 
LinearSigmoidAxon 0.029947 0.030263 0.223953 0.02923 0.03277 
SoftMaxAxon 0.042818 0.04558 0.036054 0.068567 0.111239 
BiasAxon 0.230952 0.315392 0.268944 0.296747 0.809998 
LinearAxon 0.271257 0.315392 0.269369 0.296747 0.809998 
Axon 0.271667 0.304605 0.26933 0.305149 0.809998 
圖表 19：高網路學習效能組別(由轉換函數與學習法則 C.V.MSE 判斷) 
3. 混亂矩陣下之判斷 
  另一方面，我們依然由試驗表中挑選出在混亂矩陣中表現良好
(C.M.(average)>95%)的組別。並整理出下表。在本表中，可看出有多組表現都是相同值，
比較學習效果可知，組別雖然具有相同的網路學習能力，但其在效能與效率上還是具
有不同的能力。 
C.V. C.M. %  Step Momentum ConjugateGradient Quickprop DeltaBarDelta
TanhAxon Y-Y 94.285713 94.285713 94.285713 94.285713 68.571426
 N-N 98.75 98.75 98.75 98.75 96.875
SigmoidAxon Y-Y 94.285713 94.285713 24.285715 94.285713 77.14286
 N-N 98.75 98.75 55.625 98.75 76.25
LinearTanhAxon Y-Y 94.285713 94.285713 91.428574 92.85714 47.142857
 N-N 98.75 98.75 26.25 98.75 68.125
LinearSigmoidAxon Y-Y 90 90.85714 0 90 90
 N-N 98.75 97.5 100 98.75 98.75
SoftMaxAxon Y-Y 87.14286 84.285713 82.85714 81.428574 38.57143
 N-N 94.375 94.375 98.75 95.625 100
BiasAxon Y-Y 79.136688 65.714287 74.285713 68.571426 100
 N-N 98.753891 97.5 99.375 98.125 0
LinearAxon Y-Y 75.714287 65.714287 74.285713 68.571426 100
 N-N 100 97.5 100 98.125 0
Axon Y-Y 78.571426 65.714287 74.285713 64.285713 100
圾郵寄行為的型態類型上，而類型量化後即呈現離散值，因此我們在使用倒傳遞類神經網
路演算法時，轉換函數與學習法則的決定在解題上是絕對的關鍵。本節中，我們發現適用
於離散型網路的轉換函數與學習法則的組合是 SigmoidAxon-Step，而隱藏層數與處理單元
各為 2 及 5。 
： 
： 
1
1
hnet
 
 
Spam
 
Normal
1
2
hnet
1
3
hnet
 
1
4
hnet
1
5
hnet
 
2
1
hnet
2
2
hnet
2
3
hnet
2
4
hnet
2
5
hnet
 
Spam 
 
Normal 
Input 
Layer 
Hidden 
Layer 1 
Hidden 
Layer 2 
Output 
Layer 
Desired 
Layer 
(From:) 
(To:) 
(Subject:) 
Input data 
(Typed Behaviors) 
(Bcc:) 
(Cc:) 
(Reply To:) 
(Sender:) 
(Return-Path:) 
(Date:) 
(From:)+(To:) 
(From:)+(Bcc:) 
Forward-pass 
Backward-pass 
δ 
SigmoidAxon 
Step 
SigmoidAxon 
Step 
SigmoidAxon 
Step 
Transfer 
Learning Rule 
 
圖表 23：離散型網路結構 
 
圖表 24：位元型網路結構 
 46
綜合以上數點敘述，可得以下實驗結論，依據本研究所分析的十三種型態二
十四種類型的垃圾郵件行為類型，可利用倒傳遞類神經網路進行學習，且其
效果是相當顯著地。 
對時間回想能力試驗 
 
圖表 26：對時間變化的分類效果 
 
與其他方法之比較 
我們選擇了同樣以針對郵件寄送行為過濾的方式，但不同方法的知識基
(Knowledge-based, KB)系統作比較。以 KB 方式在[61]的研究實驗裡其正確率高達 98.85%，
且在其報告中已與 SpamAssassin(SA)與 BogoFilter(BF)等產品比較並證實 KB 之正確率為最
佳。本系統 BPN 與 KB 系統之技術方式比較如下： 
y KB：收集 header＋syslog 兩種檔案，配合廿種郵寄行為規則判斷是否為垃圾或正常
郵件。 
y BPN：收集 header＋syslog 兩種檔案，根據廿種個別與四種交叉比對之郵寄行為，
分析檔案裡各欄位所屬類型，以判斷是否為垃圾或正常郵件。 
我們從相同的郵件資料庫裡隨機採取了 300 封郵件，針對兩套系統所訂定的郵件行為
規則分別進行分析與實驗，並用人為意識根據郵件之正當性判斷其郵件類型；實驗結果如
下表所示。 
 
 48
 50
五、計畫第三年 
5.1 研究目的 
結合機器學習技術與本體論應用於 SPAM 內文(context, message body)語意特徵分析，並將
之與第一、二年所發展出來的機器學習技術整合成完整的 SPAM 過濾與處理機制。以前的
技術多只是在 EMAIL 中的標頭(header)的特徵上進行處理，對於訊息內容則只作關鍵字
(keyword)的判斷而已。然而，SPAM 是「活」的，會經常改變其特徵，故即使是在訊息本
文中進行關鍵字的分析，其精確度仍然不佳。由於人類可以精確的判斷並分類 SPAM 等訊
息，並在視似而非的 SPAM 訊息中判斷其是否為 SPAM。通常這必須經由人類閱讀以理解
訊息內容才能做出正確的決定。這意味著人類可以精確的經由內文文字意義的理解，而分
辨 SPAM 與否。由於 EMAIL 由標頭與訊息兩部分構成，其中標頭是有制式的規定(protocol)
的限制，並經由 MUA 產生，屬於機器處理階段; 而 EMAIL 內文主要包含傳送端要接收端
(人類)看懂訊息意義，其內容由人為方式產生，屬人為處理階段。因此，我們有下面兩個研
究假設： 
z 標頭訊息：可以用機器學習技術進行分類處理，因為其行為「特徵」多是結構化
的(structured)，且反映在標頭的各個欄位中，可以用基本資料(raw data)型態表現
出來，只要能夠建立充足且有效的 features，便可以用高效率的機器學習技術進行
分類。這一點已經反映在第一二年的研究中。 
z 內文文字：需加入「推理」的技術以「理解」內文的意義。因為其內文意義多是
非結構化的(unstructured)，並可能以多元的方式呈現相同意義，需以文字理解
(understanding)的技術加以解決。 
經過第一二年的研究，SPAM 的處理已經可以用經過改良式的機器學習技術來分析新的特
徵行為。但如果要以相同的技術進行內文的分析，會有特徵的選擇不易與數量龐大等問題。
以傳統文字或語言的理解(natural language understanding/processing)需要以統計式或歸納式
方法，需要較多的計算時間。對於即時 SPAM 的處理，可能較不適用。因此，本階段的計
畫是希望透過知識探勘技術的使用，先分析訊息內容的關連性，並將之轉換成一致的基本
意義單元(primitive clause)，並以此為索引(index)，作為 SPAM 案例的分類特徵，最後才是
整合到機器學習分類技術中，進行 SPAM 的分類處理。 
 
過支持度門檻值，過多的候選項目集合造成程式在執行上的時間過長，因為需要
反覆搜尋資料庫求得候選項目集合的支持度值；而通過門檻值所產生的關聯規
則，也會因為門檻值太低產生許多不重要無意義的規則，過多無意義的規則被產
生亦會影響演算法的可信度。  
3. 關聯規則的緊密性是指產生的關聯規則前項和後項稠密的程度，也就是以單一規
則而言其前項和後項一起出現的機率高低，某些規則支持度可能很低，但是規則
的緊密性很高也就是說規則會集中在某一類別，如下圖所示，可觀察出項目集合
{W, Y}明顯地集中在 Class3中，規則“W, Y→Class3”緊密性很高。 
4. 預設類別:當未知類別的測試資料無法根據關聯規則所建立出的分類模型進行分
類時，則需有一預設類別能對資料進行最終分類的判斷。因此，好的預設類別演
算法也是影響分類結果的因素之一。 
 
 
圖表 29：關連規則的問題 
 
根據以上四項分析討論，為了解決基於關聯的分類所造成的問題，並將關聯規則整合應用
在分類上，因此，本論文中提出 CARC(Condensed Association Rule on Classification)演算
法，一種新的基於關聯規則的分類演算法，所產生的關聯式規則在本文中以  CAR 
(Condensed Association Rule)稱之。藉由此方法能改善因為支持度設得太高或太低所造成的
問題，產生出重要的關聯規則並提高資料分類的精確度，將測試資料正確無誤進行分類，
並能更加廣泛應用於各個領域，實際活用在郵件分類上。關連規則的緊密性中，舉例來說，
 52
  I = {I1, I2, I3...,  Im} 
  
{ }
m
IIIIILength m
=
= ,...,,,)( 321  
  例：I = {A, B, C, D}，Length(I ) = 4 
定義4 Condenseness Distance 定義兩項目集合之間的距離。I1，I2 分別為兩項目集合，其
中 I1={I11, I12, I13..., I1m}，I2={I21, I22, I23..., I2n} 
  Condenseness Distance(I1 , I2) = ⎟⎟⎠
⎞
⎜⎜⎝
⎛ ∩
⎟⎟⎠
⎞
⎜⎜⎝
⎛ ∩
)()( 2
21
1
21
ILength
II
ILength
II
 
  其中  }|{ 2121 IiIiiII ∈∧∈=∩
  例： 
  I1={A, B, C} I2={B, C, D ,E} 
  ，}{21 CBII =∩ 221 =∩ II  
  Condenseness Distance(I1 , I2) = ⎟⎠
⎞⎜⎝
⎛⎟⎠
⎞⎜⎝
⎛
4
2
3
2  = 31  
定義5 Not_be_Covered Rule 定義訓練資料中完全不被 Condensed Association Rule 所包含
的規則。 
  Not_be_Covered Rule  
  = )..(|{ classcclassrcrCrccTrrr }=∧=∩∧∈∀∧∈ φ  
  Tr：Training Data 
  Cr：Condensed Association Rule 
  r.class：r 的類別標籤 
  c.class：c 的類別標籤 
 
  例：若是訓練資料和 Condensed Association Rule 如下圖所示，在圖中以 “CAR”
表示 Condensed Association Rule。在訓練資料中有一筆為{Class1,a,b,c}，此筆資料的任一子
集並未出現在 CAR 中類別標籤同為“Class1”的規則中，因此被視 Not_be_Covered Rule；同
理，{Class2,x,y,z}的任一子集亦未出現在類別標籤為“Class2”的 CAR 中，所以，{Class2,x,y,z}
也會被加入 Not_be_Covered Rule。 
 54
 有別於一般傳統關聯式規則演算法並不考慮類別此屬性，CARC 演算法是利用規則進
行分類，因此必須考慮類別此屬性，CARC 首先須將資料庫中的訓練資料根據各自不同類
別標籤進行分類，再各自產生該類別的 Condensed Association Rule，最後，測試資料依據
所有不同類別所產生的規則進行分類的動作(如下圖所示)。演算法詳細步驟將在以下詳加介
紹。 
‧‧‧‧
‧‧‧
產生頻繁項目集
關聯式規則1
Condensed AR_1 
分類
(Classification)
測試資料
(Testing Data)
分類結果
(Result)
資料庫
(Data Base)
關聯式規則2
Condensed AR_2 
關聯式規則3
Condensed AR_3
關聯式規則n
Condensed AR_n
類別1
(Class 1)
類別2
(Class 2)
類別3
(Class 3)
類別m
(Class m)
預設類別
(Default Class)
 
圖表 32：CARC 演算法詳細流程 
 
如何利用 Condenseness 規則衡量指標和改善傳統關聯規則演算法產生 Condensed 
Association Rule，其步驟如下。 
 
步驟1 將資料庫中的訓練資料，根據類別進行分類，分類好的訓練資 料各自
進行以下步驟。 
步驟2 針對單一類別訓練資料，產生長度為 1 且 Support 值大於 MinSup 的
頻繁項目集合 L1。 
步驟3 利用 L1 組合成 C2，組合方式同 Apriori 演算法。 
 56
3EF13
3BF12
2AEF5
2BC2
3ABE9
3DEF8
1ACE16
1AC15
1BDE14
1CDE11
1ABCD10
1BCDE7
1BE6
1ABCE4
1BCE3
1ACD1
Class LabelItemsetTID
1ABCD6
1BCDE5
1BE4
1ABCE3
1BCE2
1ACD1
1ACE10
1AC9
1BDE8
1CDE7
Class LabelItemsetTID
2AEF2
2BC1
Class LabelItemsetTID
3EF4
3BF3
3ABE2
3DEF1
Class LabelItemsetTID
 
圖表 34：訓練資料分類 
 
 
步驟2 在以下步驟中將以圖3-5中，Class Label為1的資料庫為例。 
  設定MinSup = 30%，MinCond=70% 
    Sup(A) = 0.5≧MinSup 
    Sup(B) = 0.6≧MinSup  
    Sup(C) = 0.8≧MinSup 
    Sup(D) = 0.5≧MinSup 
    Sup(E) = 0.7≧MinSup 
      所以，得到L1={A,B,C,D,E} 
步驟3 L1={A,B,C,D,E}， 
  組合成C2 = {AB, AC, AD, AE, BC, BD, BE, CD, CE, DE} 
步驟4 MinSup = 30% 
  Sup(AB) = 0.2≦MinSup 
    Sup(AC) = 0.5≧MinSup 
  Sup(AD) = 0.2≧MinSup 
 58
10.4C
10.4D
10.4DE
10.4BC
10.6E
10.6B
Class LabelSupportItemset
20.3ce
20.5cd
20.4e
20.5d
20.75c
Class LabelSupportItemset
30.3d
30.1cd
30.1AB
30.2B
30.1A
30.2c
Class LabelSupportItemset
Condensed Association Rule
 
圖表 35：CondensedAR 
 
步驟1 測試資料={cde}， 測試資料所有子集且長度大於1={cd, de, ce, cde}。 
步驟2 {cd, de, ce, cde}元素皆不被包含在圖3-5 Class Label 1資料庫 內，所以，
元素Support值總和為0，SumSupport({cd, de, ce, cde},Class1) = 0 
步驟3 {cd, de, ce, cde}在圖3-5資料庫內，出現在Class Label 2中有 
    Sup(cd)=0.5 
    Sup(ce)=0.3 
    SumSupport({cd, de, ce, cde},Class2) = 0.5+0.3=0.8; 
     而出現在Class Label 3中有 
    Sup(cd)=0.1 
    SumSupport({cd, de, ce, cde},Class3) = 0.1 
    因為SumSupport({cd, de, ce, cde},Class2) =0.8值最大，因此，測試資料
={cde}，將被分類至 “類別2” 中。 
 
預設類別演算法 
步驟1 找出Not_be_Covered Rule 
 60
 
圖表 38：實驗一(a) 
 
圖表 39：實驗一(b) 
 
圖表 40：實驗一(c) 
 
 
實驗二 
 62
 
圖表 43：實驗二(c) 
 
 
實驗三 
 
在資料庫為“pima”，實驗三(如下圖實驗三(a) (c))中，可觀察出 CBA 的實驗結果不同於實
驗一和實驗三中會因為 MinSup 值設定太高精確率而有所降低，從圖中可發現 CARC 和
CBA 兩者準確率不相上下，但是依然可觀察出 CARC 有稍微較高的準確率。 
 
 
 
圖表 44：實驗三(a) 
 64
 66
如此，其正確率並不如使用 behavior-based feature 來的正確。因為，有許多 SPAM 郵件本
文中根本沒有任何文字。若將兩種 feature 合併使用，其結果如下。 
 
 
  n=2 n=3 n=4 n=5 n=6 n=7 n=8 
FP 1.15% 0.66% 0.64% 0.62% 0.60% 0.58% 0.56%
FN 3.00% 2.95% 2.90% 2.85% 2.81% 2.76% 2.71%
TP 98.85% 0.993443 0.993641 0.99384 0.994039 0.994237 0.994436
TN 97.00% 0.970485 0.97097 0.971456 0.971941 0.972427 0.972914
圖表 48：CARC+Behavior-based Features(ANN)用於 SPAM 本文分類 
 
 68
3rd International Conference on Soft Computing and Intelligent Systems and 7th 
International Symposium on advanced Intelligent Systems, Japan , Sep. 20-24, 2006. 
4. C.-Y. Yeh, S.-J. Lee, C.-H. Wu, S.-H. Doong, “A Kernel Prototype-based Clustering 
Algorithm”, The 10th WSEAS International Conference on COMPUTERS, 
Vouliagmeni, Athens , Greece , July 13-15, 2006. 
5. C.-H. Wu, H.-C. Kuo and C.-C. Lai, ;Acquisition of Knowledge for Spam Filtering by 
Rule Induction,; The 2006 IAENG International Workshop on Artificial Intelligence 
and Applications(IWAIA), Hong Kong , 20-22 June, 2006. 
6. C.-Y. Yeh, C.-H. Wu, S.-H. Doong, “Effective Spam Classification based on 
Meta-Heuristics”, 2005 IEEE International Conference on Systems, Man and 
Cybernetics, Vol. 4, pp. 3872-3877, Waikoloa, Hawaii, October 10-12, 2005. 
7. C.-H. Wu, S.-H. Doong, C.-Y. Yeh, ;Behavior Based Spam Filtering Using Support 
Vector Machine;, IEEE International Conference on System & Signals, Kaohsiung , 
Taiwan , April 28-29, 2005. 
8. C.-H. Wu, C.-H. Wun, H.-J. Chou, ;Using Association Rules for Completing Missing 
Data;, the Third International conference on Hybrid Intelligent Systems, Kitakyushu, 
Japan, 05-08 December, 2004 
9. Jung-Sheng Yang and Chih-Hung Wu, (2003, 12), ;Plagiarism Detection of Text using 
Knowledge-based Techniques;, in the Proceedings of the Third International 
conference on Hybrid Intelligent Systems (HIS'03), pp.973-982, Australia, 14-17, 
December 2003 
10. Ling-Sheng Tseng and Chih-Hung Wu, (2003, 12),;Detection of Spam E-Mails by 
Analyzing the Distributing Behaviors of E-Mail Servers;, in the Proceedings of the 
Third International conference on Hybrid Intelligent Systems (HIS'03), pp. 1024-1033, 
Austrialia, Dec. 2003 
 
專書： 
1. Lai, C.-C., Doong, S.-H., and Wu, C.-H. (April 4, 2008). Machine Learning. In Wiley 
Encyclopedia of Computer Science and Engineering (Benjamin Wah, ed.), Hoboken: 
John Wiley and Sons, Inc. doi.org/10.1002/9780470050118.ecse228 
 
協助完成碩士論文： 
1. 郭香君，應用模糊理論與凱利方格進行垃圾郵件分類的知識，樹德科技大學，2007 
2. 王靜誼，衡量分類關聯規則的新方法，國立高雄大學，2007 
3. 蔡瓊輝，使用倒傳遞類神經網路學習垃圾郵件行為的類型，樹德科技大學，2005 
4. 陳俊南，使用決策樹進行垃圾郵件行為的類型，樹德科技大學，2005 
5. 溫千慧，利用貝氏估計與關聯式法則進行資料庫遺失值的預測，樹德科技大學，
2004 
 
 
 70
categorization” ,Neural Networks, IEEE Transactions on, vol. 10, pp. 1048-1054,. 
[13] Hooman Katirai.,1999, Filtering junk E-mail: A performance comparison between genetic. 
programming and naive bayes. Available from: http://citeseer.ist.psu.edu/. 
katirai99filtering.html. 
[14] Ion Androutsopoulos, John Koutsias, Konstantinos V. Chandrinos and Constantine D. 
Spyropoulos,2000, “An Experimental Comparison of Naive Bayesian and Keyword-Based 
Anti-Spam Filtering with Personal E-mail Messages,” in Proc. of the 23rd Annual 
International ACM SIGIR Conference on Research and Development in Information 
Retrieval (SIGIR 2000), Jul. 
[15] J.J. Rocchio, 1971, “Relevance feedback in information retrieval,” ,In: G. Salton (ed.), The 
Smart retrieval system:. experiments in automatic document processing, Prentice Hall, pp. 
313-323. 
[16] Jefferson Provost.,1999, “Naive-Bayes vs. Rule-Learning in Classification of 
Email.” ,Technical Report AI-TR-99-284, The University of Texes at Austin, Artificial 
Intelligence Lab. 
[17] Jose Jesus Castro-Schez, Nicholas R. Jennings, Xudong Luo, Nigel R. ,2004, “Shadbolt: 
Acquiring domain knowledge for negotiating agents: a case of study.” Int. J. Hum.-Comput. 
Stud. 61(1): 3-31. 
[18] Kelly, G.A., 1955. The Psychology of Personal Constructs. Norton, New York. 
[19] McDonald, J., Dearholt, D., Paap, K., Schvanevedt, R., 1986. A formal interface design 
methodology based on user knowledge. CHI’86 Proceedings, pp. 285–290. 
[20] Mehran Sahami, Susan Dumais, David Heckerman, and Eric Horvitz.,1998, “ A bayesian 
approach to filtering junk E-mail.” ,In Learning for Text Categorization:Papers from the 
1998 Workshop, Madison, Wisconsin. 
[21] Vel, A. Anderson, M. Corney, and G. Mohay, 2001, “Mining e-mail content for author. 
identification forensics.” ,ACM SIGMOD Record,. vol. 30, pp. 55-64. 
[22] Richard B. Segal and Jeffrey O. Kephart.,1999, Mailcat: An Intelligent Assistant for 
Organizing E-Mail. In Proceedings of the third annual conference on Autonomous Agents, 
Seattle, Washington, United States. 
[23] Robert J. Hall. ,1996, “Channels: Avoiding Unwanted Electronic Mail.” ,In Proceedings of 
the 1996 DIMACS Symposium on Network Threats, volume 38, Piscataway, NJ, December 
4-6. 
 72
 
八、計畫成果自評 
 
1. 計畫分為三個階段進行，大致上可以完成原先之規劃。除了建立數套分類機制外，同
時完成數篇論文的發表，成果堪稱滿意。 
2. 計畫進行中最大的問題是樣本的取得。因為本計畫在第二、三年開始使用behavior-based 
features 的觀念進行分類。其中同時需要 header 與 syslog 的資料。國內外的資料庫中僅
提供 SPAM 本文+header。唯一取得 syslog 的方式是自行建立 mail server。但是在接收
SPAM 的過程中，經常被 TANET 警告流量過大，也一度被懷疑為惡意郵件散佈者，困
擾頗多，也對本校電算中心造成不小困擾。因此，應該在實驗樣本的取得更有效率。 
3. 第一年的 Repertory Grid 方式可以取得 USER 對 SPAM 的定義，但是在定義「行為」
時，有許多不同意見。例如，時間區間的訂定、大量與少量、正常與與亂數的區隔等
等。再來是參與訪談的對象中，對中文郵件較為熟悉，英文郵件大多表示不熟悉，在
進行訪談時，造成不少無效或重複樣本。本研究也發現，中文 SPAM 與英文 SPAM 在
內容與發佈行為上的確有所不同，未來可以採用區隔方式，分別研究不同語系的 SPAM
散發行為。 
4. 第二年的主要採用 ANN、SVM 作為分類器，未來可以增加更多分類技術。同時在編
碼技術上也可以使用更多元的方式進行之。除了目前使用的 HEADER 欄位外，本研究
有發現有些欄位是不固定出現的，換言之，FEATREUE 欄位本身是變動的。這對目前
機器學習演算法是一項挑戰。未來可以加入對 dynamic feature 的擷取做更多的研究。 
5. 第三年則因為 ontology 的建立成效不如預期，故改為使用 AR 技術。並發現在 NLP 領
域中常用的 n-gram 技術，可以套用在 CARC 中，並成應用在 SPAM 過濾中。同第一
年的發現，中文 SPAM 與英文 SPAM 在內容有所不同，中文 SPAM 在 n-gram 的呈現
比英文 n-gram 的敏感度不同，例如中文一個字可能在英文需要許多單字同時出現才能
判定為 SPAM，反之亦然。未來可以採用區隔方式，分別研究同語系的 SPAM 內文。 
 
 
 由於大會開始前一天台灣恰逢颱風來襲，因此原先訂位的飛機臨時取消，而致使未能
趕上大會開幕盛況，隔天則順利搭上搬機抵達香港參加第二天的會議。本次會議所投稿
之論文名稱為 A TIME-ROBUST SPAM CLASSIFIER BASED ON BACK-PROPAGATION 
NEURAL NETWORKS AND BEHAVIOR-BASED FEATURES，被安排於(MC- 2  Machine 
Learning Applications II)場次進行。本論文主要探討垃圾郵件的分類，一別以往僅用關鍵
字過濾的方式，由於關鍵字會隨時間而時常改變，進而影響過濾的效果，因此我們提出
了採用郵件寄件者的郵寄行為來進行分析，利用淬取出的郵件寄送行為模式來進行分
析，並採用倒傳遞類神經網路的機器學習方法，以進行分類預測。實驗結果顯示我們所
採用的方法有顯著的成效，並且不會因為時間的改變而讓垃圾郵件過濾的效果有降低的
情況。報告結束後，本議題受到許多學者的討論，顯示本議題在目前的重要性，並且獲
得許多意見，報告完後的休息時間，發問的學者也給予了寶貴的建議，使得後續的研究
有更多的參考。 
 
幾天的與會中，聆聽了多場精彩的報告與演講。Qing He 在 Fault Diagnosis Of 
Induction Motor Using Neural Networks 講題中提出了使用類神經網路在電動機故障的診
斷，透過關聯度分析，評估影響感應電動機溫升較大之因子作為輸入變數，來估測感應
電動機之溫升。Wan-Chen Huang 在 A Method To Combine Hmm And BPNN On Speech 
Recognition 講題中提出了利用倒傳遞類神經網路在語音辨識中的應用，建立了一套語音
辨識系統，讓使用者可在遠端直接以語音來下達指令給控制裝置，而其則以倒傳遞類神
經網路模型來作語音辨識的功能。Huai-Lin Shu 在 Simulation Study Of PID Neural 
Network Temperature Control System In Plastic Injecting-Moulding Machine 講題中提出了
調節 PID控制器之類神經網路溫度控制系統在注入的塑膠機器的模擬研究中，當感應塑
膠潮濕變化時，類神經網路能夠自動調節 PID 參數, 有效的控制溫度，不讓塑膠產生品
質變化。 
 
二、與會心得 
