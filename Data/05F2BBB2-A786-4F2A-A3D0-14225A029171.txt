 2
報告內容 
請卓參已發表之文章內容（各文章內容已詳列於本計畫之最後方），如下所示： 
1. Chi-Chang Wang, 2007, “Use of new residual correction method to calculate upper and lower 
solutions of natural convection,“ Numerical Heat Transfer Part A: Applications, Vol. 51, No. 3, 
pp. 249-265. (EI、SCI)  
2. Chi-Chang Wang, 2006,”Use residual correction method to calculate the upper and lower 
solutions of initial value problem,“ Applied Mathematics and Computation, Vol. 181, pp. 29-39. 
(EI、SCI) 
3. Chi-Chang Wang, Zong-Yi Lee and Yiyo Kuo, 2008, Application of Residual Correction 
Method in Calculating Upper and Lower Approximate Solutions of Fifth-order Boundary Value 
Problems, Applied Mathematics and Computation, Vol. 199,  pp. 677-690. (EI、SCI) 
4. Chi-Chang Wang and Hai-Ping Hu, 2008, Study on Monotonicity of Boundary Value Problems 
of Differential Equations, Applied Mathematics and Computation, Vol. 202, pp. 383-394. (EI、
SCI)  
 
計畫成果自評部份 
一、 研究內容與原計畫相符程度 
■完全相符 □大致相符 □不相符  
二、 達成預期目標情況 
■完全達成 □大致達成 □部分達成  □未達成 
項次 內容 進度與說明 
1.  收集國內外相關資料與各項準備工作。 已達成 
2.  一維殘差修正法之理論架構 已達成 
3.  二階邊界值條件最大值定理 已達成 
4.  高階邊界值條件最大值定理 已達成 
5.  一維 B 樣線函數架構 已達成 
6.  建立數值計算之電腦程式，並做基本測試。 已達成 
7.  
範例探討:強迫對流問題 
    單調性證明 
    數值測試 
已達成 
8.  
範例探討:自然對流問題（耦合方程式） 
    單調性證明 
    數值測試 
已達成 
9.  結果分析與整理，並討論如何將成果應用在未 已達成 
 4
可供推廣之研發成果資料表 
■ 可申請專利  ■ 可技術移轉                                 日期：97 年 8 月 2日 
國科會補助計畫 
計畫名稱：「殘差修正法」之理論建構及應用於求解熱對
流問題的較大與較小近似解 
計畫主持人：王啟昌         
計畫編號：96-2221-E-432-002-    學門領域：熱流
技術/創作名稱 殘差修正法求近似解的誤差分析 
發明人/創作人 王啟昌  
技術說明 
中文：求得之微分方程之近似解為正確解的較大與較小近
似解，並可據以求得平均近似解的誤差分析，避免無謂增
加離散格點或近似函數之數目來減少數值誤差。 
 
可利用之產業 
及 
可開發之產品 
數值分析領域及計算軟體之開發。 
技術特點 
該理論具備明確誤差分析的特性，將可有效的節省計算時
間、記憶空間與避免反覆的數值精度測試。 
 
推廣及運用的價值  
※ 1.每項研發成果請填寫一式二份，一份隨成果報告送繳本會，一份送 
貴單位研發成果推廣單位（如技術移轉中心）。 
※ 2.本項研發成果若尚未申請專利，請勿揭露可申請專利之主要內容。 
※ 3.本表若不敷使用，請自行影印使用。 
equations. After the monotonicity relation between the solution and the residual of a
differential equation is established, numerical calculation puts forth a new method,
the ‘‘residual correction method,’’ to overcome traditional problems in solving math-
ematical programming under inequality constraint conditions. Its idea is first to use
spline approximation to discretize the differential equation, then to use iteration
technique of residual correction to transform the once complex inequality constraint
problem into a simple problem of equation iteration.
PROBLEM FORMULATION FOR LOWER AND UPPER SOLUTIONS
Considering the problem of boundary-layer natural convection when a
Newtonian fluid passes through a flat plate, the governing equations on a dimen-
sionless flow field and temperature field [6] can be denoted as
f 000 þ 3ff 00  2f 02 þ h ¼ 0 ð1Þ
h00 þ 3 Pr f h0 ¼ 0 ð2Þ
with boundary conditions
On plate surface:
f ¼ f 0 ¼ 0; h ¼ 1 as g ¼ 0 ð3Þ
Far away from the surface:
f 0 ¼ h ¼ 0 as g!1 ð4Þ
where f ðgÞ and hðgÞ are dimensionless flow field and temperature parameters on the
g coordinate, respectively, and Pr is Prandtl number, which is assumed to be 1 in this
article.
In order to obtain the upper and lower solutions of a differential equation, in
most cases one has to rely on the maximum principle of the differential equation to
establish the solution’s monotonic relation (if any) with a residual function (also
NOMENCLATURE
Ea maximum possible error of mean
approximate solution
Emax maximum possible error of
approximate solutions
f variable
Ni serial number of maximum
grid point
Pr Prandtl number
R residual
u dimensionless velocity
g dimensionless axial
h dimensionless temperature
s virtual time
Subscripts
i serial number of calculation grid
points
Superscripts
m iteration times
n virtual time index
 average of upper and lower
approximate solutions
 approximate function
\, [ upper and lower approximate
solutionsb value of previous iteration
250 C.-C. WANG
concept of maximum principle to once nonmonotonic equations or systems of equa-
tions. The first step is to use the concept of virtual time to rewrite Eqs. (1) and (2)
into the following new differential equations:
f 0  u ¼ 0 ð13Þ
u00 þ 3f^ u0  2u^uþ h u u^
Ds
 kf ðf^
a
^f Þ ¼ 3ðf  f^ Þu0 þ 2ðu u^Þu ðh h^Þ
 u u^
Ds
 kf ðf^
a
^f Þ ð14Þ
h00 þ 3 Pr f^ h0  h h^
Ds1
 khðf^
a
^f Þ ¼ 3 Prðf  f^ Þh0  h h^
Ds1
 khðf^
a
^f Þ ð15Þ
where function u is the first differential value of f, indicating that Eqs. (13) and (14)
are the order-reduced expressions of Eq. (1). Ds denotes the positive increment of
virtual time. Superscript^ denotes the given or obtained function value in previous
time, which may be required to be either greater than or equal to, or smaller than
or equal to, the exact solution of the function, respectively, when extracting an upper
or lower approximate value. In addition, f^
a
and
^
f are the given values in previous
time that now can be determined to be smaller than or equal to, and greater than
or equal to, the exact solution. k is a variable used to complement the monotonicity
of the differential equation. In most cases, no doubt, it is impossible to obtain an
exact solution that satisfies Eqs. (13)–(15), so the relation between the approximate
function and exact solution is assumed as follows:
f ¼ ~f  d~f ð16Þ
u ¼ ~u d~u ð17Þ
h ¼ ~h d~h ð18Þ
where ~f , ~u, and ~h are the approximate solutions of exact solutions u, f, and h, respect-
ively, and d refers to the difference between the exact solutions and approximate
solutions. Putting Eqs. (16)–(18) into Eqs. (13)–(15) to obtain new residual
expressions,
R~f ðgÞ ¼ ~f
0  ~u ¼ d~f 0  d~u ¼ 0 ð19Þ
R~uðgÞ ¼ ~u00 þ 3f^ ~u0  2u^~uþ h^ ~u u^Ds  kf ðf^
a
^f Þ
¼ d~u00 þ 3f^ d~u0  2u^þ 1
Ds
 
d~u
 kf ðf^
a
^f Þ þ 3u0ðf  f^ Þ þ 1
Ds
 2u
 
ðu u^Þ þ ðh h^Þ
" #
ð20Þ
252 C.-C. WANG
time increment Ds also satisfies
1
Ds
 2~u  0 ð29Þ
then, when the following conditions hold,
R~f ðgÞ ¼ 0 ð30Þ
R~uðgÞ  0 ð31Þ
R~hðgÞ  0 ð32Þ
kf  Max ð0;3~u0Þ ð33Þ
kh  Max ð0;3 Pr ~h0Þ ð34Þ
f^
a
 f  ^f ¼ f^ u^  u h^  h ð35Þ
it can be known that the sum on the right of the equal signs of Eqs. (23) and (24) is
positive, indicating that the residual of the differential equation is greater than or
equal to zero. It can be concluded from the concept of maximum principle that
d~f , d~u, and d~h have lower solutions that are smaller than or equal to zero (as their
exact solutions are zero). Therefore, from Eqs. (9)–(12), we can know when expres-
sions (30)–(35) are satisfied, and the obtained approximate solutions ~u, ~f , and ~h are
lower approximate solutions of their exact solutions. Certainly, it can be easily
deduced that when
R~f ðgÞ ¼ 0 ð36Þ
R~uðgÞ  0 ð37Þ
R~hðgÞ  0 ð38Þ
kf  Min ð0; 3~u0Þ ð39Þ
kh  Min ð0; 3 Pr ~h0Þ ð40Þ
f^ ¼ f^
a
 f  ^f u  u^ h  h^ ð41Þ
the obtained approximate solutions are upper approximate solutions of their exact
solutions.
254 C.-C. WANG
or (46)–(48) and rewrite the inequalities into the following equations:
Rni ¼ u00nþ1i þHðxi; unþ1i ; u0nþ1i Þ ð50Þ
Rb
n
0
¼ u0nþ10 cos h unþ10 sin hþ ca ð51Þ
Rb
n
Ni
¼ u0nþ1Ni cos/ unþ1Ni sin/þ cb ð52Þ
where the superscripts m and n are iteration time and virtual time index, respectively,
subscripts i ¼ 0; 1; 2; . . . ;Ni are serial number of discretized calculation grid points,
and Rmi are residual correction values on calculation grid points, which are used to
correct the residual values on calculation grid points and ensure the residual values
of the neighboring subinterval of i grid point (xi1  x  xiþ1) are all positive or
negative. The complete process for residual correction is as follows.
1. Assume the residual on each grid point R0i ¼ 0.
2. Use Eqs. (50)–(52) to obtain new values unþ1i , u
0nþ1
i , and u
00nþ1
i .
3. Estimate Rmþ1i required for the next iteration according to the residual value of
the neighboring subinterval of grid point i (xi1  x  xiþ1). Its residual correc-
tion relations are as follows:
When extracting the lower approximate solution
Rmþ1i ¼ Rmi minRðxÞ xi1  x  xiþ1 ð53Þ
Rmþ10 ¼ Rm0 min½RðxÞ;RbðaÞ a  x  x1 ð54Þ
Rmþ1Ni ¼ RmNi min½RðxÞ;RbðbÞ xNi1  x  b ð55Þ
When extracting the upper approximate solution,
Rmþ1i ¼ Rmi maxRðxÞ xi1  x  xiþ1 ð56Þ
Rmþ10 ¼ Rm0 max½RðxÞ;RbðaÞ a  x  x1 ð57Þ
Rmþ1Ni ¼ RmNi max½RðxÞ;RbðbÞ xNi1  x  b ð58Þ
where RðxÞ is the residual function obtained by putting the function and its deri-
vatives obtained from the previous step into the differential equation.
4. Progress one m value and repeat steps 2 and 3 until Rmþ1i ¼ Rmi .
To actually use the above method to solve residual correction equations (53)–
(58), we must obtain the residuals of neighboring subregions RðxÞ. However, the
functions and derivatives obtained from traditional difference are only those on grid
points. They are not continuous on noncalculation grid points, so they are not appli-
cable to this method. For this reason, this article adopts the concept of spline
256 C.-C. WANG
According to the theory of cubic splines, any function g(g) at any point of a
subinterval can be expressed with the functions and derivatives of its two ends as
gðgÞ ¼ g00i1
ðgi  gÞ3
6Dgi
þ g00i
ðg gi1Þ3
6Dgi
þ gi1 
g00i1Dg
2
i
6
 
gi  g
Dgi
þ gi  g
00
i Dg
2
i
6
 
g gi1
Dgi
ð67Þ
where Dgi ¼ gi  gi1 is space between grid points. Therefore, in eqs. (59) and (63),
the values of function f on grid points can be accurately obtained by using
fi ¼
Z gi
0
u dg ¼
Xi
k¼1
ðuk1 þ ukÞDgk
2
 Dg
3
k
24
ðu00k1 þ u00kÞ
 
ð68Þ
In this way, the coefficients of functions and its first and second derivatives in Eqs.
(60), (61), (64), and (65) can be determined by the solutions obtained in previous vir-
tual time. For the method to obtain solutions, refer to Wang and Kahawita [7]. The
whole procedure to obtain solutions and correct residuals is as follows.
1. Set initial conditions: Set n ¼ m ¼ 0, set initial value according to Eqs. (62) and
(66), and assume the residual correction value on each grid point is zero, i.e.,
Rua
m
i
¼ Ru
m
i
¼ R
h
a
m
i
¼ Rh
m
i
¼ 0 ð69Þ
2. Calculate approximate solutions: Use the cubic spline method to calculate Eqs.
(59)–(61) and obtain approximate solutions f
nþ1
i , u
nþ1
i , and
h
nþ1
i as well as their
first- and second-order derivatives;
3. Correct residual: Put the approximate solutions obtained in step 2 into residual
expressions (20) and (21), obtain residuals RuðxÞ and RhðxÞ, then obtain new
residual corrections according to Eqs. (53)–(55).
4. Progress one m value and repeat steps 2 and 3 untill Rmþ1i ¼ Rmi . Only then are
the approximate solutions unþ1i and h
nþ1
i the real lower approximate solutions.
5. Calculate Eqs. (63)–(65) by steps similar to steps 2–4 and obtain upper approxi-
mate solutions u
anþ1
i , f
anþ1
i , and h
anþ1
i .
6. Progress one n value and repeat steps 2–5 until the following expression is
satisfied:
gnþ1i  gni
gnþ1i

  106 ð70Þ
where function g represents the upper or lower solutions of u or h.
RESULTS AND DISCUSSION
Figure 1 shows the distribution curves of the residuals obtained by putting
upper and lower approximate solutions of dimensionless velocity and temperature
258 C.-C. WANG
into differential equations (20) and (21) before and after residual correction. There
are 11 calculation grid points that are evenly collocated on the plate surface between
ðg ¼ 0Þ and g ¼ 10 (i.e., the space of grid points is 1). It can be seen from Figure 1
that although the uncorrected residuals of the differential equation of the approxi-
mate solutions are always zero on calculation grid points (g ¼ 0, 1, 2,. . ., 10), they
are greater than or equal to zero on noncalculation grid points, as the approximate
solutions fail to satisfy all the inner regions within neighboring subintervals. After
residual correction, it is found that the residuals on calculation points are not always
zero. They are corrected by the residuals in neighboring regions to ensure that the
residuals in neighboring regions are all positive or all negative. For example, when
calculating upper solutions, the residuals at g ¼ 1 in Figures 1a and 1b are corrected
to about 0.01 and 0.04, respectively, making the residuals in the neighboring
regions 0 < g < 2 all smaller than or equal to zero. Noticeably, these two correction
values coincidently make the residual at about g ¼ 0:5 zero, indicating that these
two correction values are the optimal correction values that satisfy the condition that
the residuals in neighboring regions are all smaller than zero. On the other hand,
when calculating lower approximate solutions, the residuals at g ¼ 1 in Figures 1a
and 1b are corrected to 0.1 and 0.7, respectively, making the residual at about
g ¼ 0:8 zero and in neighboring regions all greater than zero.
Figure 2 illustrates the difference of approximate solutions and their first and
second derivatives of velocity and temperature before and after residual correction.
As the approximate curves are of cubic splines, both velocity and temperature curves
as well as their first and second derivatives are continuous, and only the second deri-
vatives show linear distribution in each subinterval (which means that the third deri-
vatives are not continuous on grid points). In any case, as second order is the highest
order in the differential equations (19)–(21), it is assured that the residuals of the dif-
ferential equations are continuous. That is the exact reason why this article gives up
traditional difference and adopts spline approximation. From Figure 2, we can easily
see the impact of residual correction on functions and their derivatives. When resi-
duals are corrected to be greater than or equal to zero, the approximate solutions
are smaller than those in the curve before residual correction. On the other hand,
when residuals are corrected to be smaller than or equal to zero, the approximate
solutions are greater than the approximate solutions before residual correction.
However, the monotonicity of solutions with residuals only exists in the function
itself and cannot be guaranteed in its first and second derivatives.
Since the residual distribution in Figure 1 indicates that the residual correction
method put forth by this article can correctly satisfy expressions (30)–(35) or (36)–
(41), it can be guaranteed that the curves of approximate solutions of various grid
points after residual correction as shown in Figure 3 have the following relations
with exact solutions: The top three curves in Figure 3 are for upper approximate
solutions of exact solutions, while the three curves below them are for lower approxi-
mate solutions of exact solutions. In other words, the curves of upper and lower
approximate solutions clearly limit the exact solutions in a region between them,
and the region shrinks with the increase of grid points as shown in Figure 4. That
means that the error of solutions tends to be reduced with an increase of grid points.
As the ultimate purpose of this problem is mostly for research on fluid shear
stress and thermal conductivity on walls, in order to more accurately study how
260 C.-C. WANG
EmaxðgÞ ¼ g
a g
Minðj ga j; jgjÞ
ð72Þ
EaðgÞ ¼Maxðjg g
a j; jg gjÞ
Minðj ga j; jgjÞ
ð73Þ
Figure 3. Distribution curves of the upper and lower approximate solutions of (a) f, (b) u, and (c) h when
the number of grid points is 11, 21, and 51, respectively.
262 C.-C. WANG
possible error obtained from Eq. (72), as expected, is reduced with increase of grid
points. For instance, when the number of grid points is 200, it is confirmed that
0:56729637  h0ð0Þ  0:56701472 ð74Þ
This result indicates that it is guaranteed the maximum possible error is smaller
than 0.04964%. In comparison with Relation [6] with an error of 5%,
h0ð0Þ  0:75 Pr
1=2
ð0:609þ 1:221 Pr1=2þ1:238 PrÞ1=4
¼ 0:56781 ð75Þ
we can see that these two are rather close. Notably, the maximum possible error here
refers to the possible maximum error between the exact solution and any approxi-
mate value within the range between the upper approximate solution and the lower
approximate solution. In practical applications, the mean approximate solutions
extracted from Eq. (71) can be used as the final and better numerical approximate
solutions, in this way, the error can be remarkably improved. In this example,
although exact solution cannot be determined exactly, as long as we put the lower
and upper approximate solutions in Tables 1 and 2 into Eq. (73), the error obtained
is certainly greater than the real error.
In order to validate the error range of the mean approximate solution in this
article, we put the upper and lower approximate solutions with 200 grid points into
terms g
a
and g of Eq. (73) and put mean approximate solution obtained with different
numbers of grid points into term g of the same equation. It is found that the
maximum errors of the mean approximate solutions in the last columns of Tables
1 and 2 are much smaller than the largest possible error. For instance, when there
are only 10 grid points, the errors of differential mean values of velocity and tem-
perature are already smaller than 1.5% and 0.4%, respectively. That indicates the
upper and lower solutions obtained by using the residual correction method in this
article can be used to analyze the maximum possible error of solutions. Moreover, as
the residuals of these two approximate solutions are always distributed on two sides
of zero in a basically symmetric manner as shown in Figure 1, the errors between the
upper=lower approximate solutions extracted from Figure 3 and the exact solution
are symmetric to considerable degree, and the values of mean approximate solutions
extracted from Eq. (73) are rather close to their exact solutions even there are only a
Table 2. Approximate solutions and errors of dimensionless temperature h0ð0Þ under different numbers of
calculation grid points
Ni
h0ð0Þ
Emax EaLower solutions h
0
Average solutions h
0
Upper solutions h
a0
10  0.63473898  0.569305518  0.50387205 0.2061744 0.0040401
20  0.58404432  0.566384220  0.54872411 0.0604752 0.0016086
50  0.56959230  0.567235726  0.56487915 0.0082745 0.0003897
100  0.56774889  0.567179796  0.56661069 0.0020047 0.0002911
200  0.56729637  0.567155549  0.56701472 0.0004964 0.0002483
264 C.-C. WANG
This article was originally published in a journal published by
Elsevier, and the attached copy is provided by Elsevier for the
author’s benefit and for the benefit of the author’s institution, for
non-commercial research and educational use including without
limitation use in instruction at your institution, sending it to specific
colleagues that you know, and providing a copy to your institution’s
administrator.
All other uses, reproduction and distribution, including without
limitation commercial reprints, selling or licensing copies or access,
or posting on open internet sites, your personal or institution’s
website or repository, are prohibited. For exceptions, permission
may be sought for such use through Elsevier’s permissions site at:
http://www.elsevier.com/locate/permissionusematerial
Au
th
or
's 
  p
er
so
na
l   
co
py
problem of equation iteration. Therefore, the method can quickly solve mathematical programming problems
under inequation constraint conditions.
2. Problem formulation for lower and upper solutions
2.1. The maximum principle
In general, in order to obtain the upper and lower solutions of a diﬀerential equation, a monotonic relation
(if exist) of the residual function (also known as residual) of a diﬀerential equation with solution must be
established by using the concept of diﬀerential equation maximum principle. Therefore, before introducing
residual correction method, it is necessary to say something about maximum principle. Firstly, the maximum
value for the ﬁrst order initial value problem can be simply described as follows [2]:
Theorem 1. Let us begin by considering the scalar IVP
Rðt; u; u0Þ ¼ u0  f ðt; uÞ; tP a; ð1Þ
R0ðt ¼ aÞ ¼ u0; ð2Þ
where function R0 and R are called residuals or residual functions of the initial value condition and differential
equation, respectively. On assumption that function u(t) is the exact solution that makes the residuals of
Eqs. (1) and (2) all satisfy with zero, and the approximate functions u
_ðtÞ and u^ðtÞ have definition when tP a
and continuous till first derivatives, then, when approximate function u
_ðtÞ satisfies
Rðt; u_; u_0Þ ¼ u_0  f ðt; u_ÞP 0; ð3Þ
R0ðt; u_Þ ¼ u_0  u0 P 0; ð4Þ
u
_ðtÞ is considered an approximate solution greater than exact solution u(t), on the other hand, when u^ðtÞ satisfies
Rðt; u^; u^0Þ ¼ u^0  f ðt; u^0Þ 6 0; ð5Þ
R0ðt; u^Þ ¼ u^0  u0 6 0; ð6Þ
u
^ðtÞ is considered an approximate solution smaller than exact solution u(t).
Nomenclature
Ea error of mean approximate solutions
Emax maximum possible error of approximate solutions
R residual
Ri corrected residual value on a calculation grid point
u function
t time coordinate
Greek symbol
Dt time increment
Superscripts
m iteration times
n diﬀerential times
– mean approximate solution
_;^ upper and lower solutions
Subscript
i serial number of calculation grid points
30 C.-C. Wang / Applied Mathematics and Computation 181 (2006) 29–39
Au
th
or
's 
  p
er
so
na
l   
co
py
making the approximate function u
_ðtÞ the optimal approximate solution that is greater than or equal to exact
solution.
Although the acquisition of upper and lower approximate solutions are good for accuracy and credibility
analysis of a solution, owing to the tremendous complexity and diﬃculty in extracting optimal solution of
mathematical programming problems under such constraint conditions, the theory of such kind has stopped
at theoretic studies for quite some time and failed to solve complex problems in practical application. For this
reason, the article puts forth the concept of residual correction method by which the inequation mathematical
programming problems are simpliﬁed into equation problems that are similar to traditional diﬀerential equa-
tions. The concept is to use iteration technique to discretize expressions (15)–(17) or (18)–(20) and rewrite the
inequations into the following ﬁrst order or second order equations
Rmi ¼ u0mþ1i  f ðti; umþ1i Þ; ð21Þ
Rmi ¼ u00mþ1i þ Hðti; umþ1i ; u0mþ1i Þ; ð22Þ
where superscript m stands for iteration times, subscript i = 0,1,2, . . . are serial number of discretized calcu-
lation grid points, and Rmi is residual correction values on calculation grid points, which are used to correct the
residual values on calculation grid points and ensure the residual values within subinterval (ti1 6 t 6 ti) are all
positive or negative. The complete process for residual correction on i grid point is described as follows:
1. Set m = 0, and residual Ri = 0.
2. Use Eq. (21) or (22) to obtain new umþ1i and its ﬁrst derivative u
0mþ1
i or second derivative u
00mþ1
i , for the func-
tion and derivatives are known on i  1 grid point.
3. Use Eq. (1) or (7) to obtain the residual values R(t) within the subinterval (ti1 6 t 6 ti) and estimate Rmþ1i
required for next iteration, for the function and derivatives are known on i grid point. Its residual correc-
tion relations are as follows:When extracting lower approximate solution,
Rmþ1i ¼ Rmi max RðtÞ
ti  ti1
t  ti1
 
; ti1 6 t 6 ti. ð23Þ
When extracting upper approximate solution,
Rmþ1i ¼ Rmi min RðtÞ
ti  ti1
t  ti1
 
; ti1 6 t 6 ti. ð24Þ
4. Progress one m value and repeat steps 2 and 3 till Rmþ1i ¼ Rmi .
2.3. Spline approximation
There is still a hard nut to be cracked when applying the residual correction method put forth in this article,
that is: the residuals R(t) within the subinterval (ti1 6 t 6 ti) must be obtained before solving residual correc-
tion equations (23) and (24). However, the functions and derivatives obtained from traditional diﬀerence are
only those on grid points. They are not continuous on non-calculation grid points and not applicable to this
method as a result. For this reason, the article adopts the concept of spline approximation to discretize equa-
tions, making the functions and derivatives of various orders continuous in any area. Talking about the origin
of spline, it was often found in past researches on numerical methods that if using a single polynomial to
approximate a function, the result is usually not so good. To tackle this problem, traditional ﬁnite diﬀerence
method divides function region into a number of subregions, then approximate derivatives at the ends of each
subregion by using forward diﬀerence concept, the calculation result was markedly improved. Whereas the
shortcoming of this eﬀort is the functions and derivatives are discontinuous at the boundaries of subregions.
It undermines value accuracy. Therefore, how to solve these discontinuous points and make them, including
derivatives of various orders ‘‘continuous and smooth’’ at the boundaries of subregions has become the
research direction of spline function. To my knowledge, a good few scholars have done research into the spline
function about boundary problems [4,5], but nothing is reported on the study of initial value problem. It is
assumed in this article that the approximate solutions of Mth order initial value diﬀerential equation within
the region ti1 6 t 6 ti are composed of a M + 1th order polynomial, i.e.
32 C.-C. Wang / Applied Mathematics and Computation 181 (2006) 29–39
Au
th
or
's 
  p
er
so
na
l   
co
py
It can be seen from the maximum theory of ﬁrst order diﬀerential equation that when the approximate func-
tion u
^
satisﬁes constraint condition
Rðt; u^; u^0Þ 6 0; tP 0 ð38Þ
and objective function is
maxðu^Þ ð39Þ
the minimum value of optimal approximate solution can be extracted. On the other hand, when approximate
function u
_
satisﬁes constraint condition
Rðt; u_; u_0ÞP 0; tP 0 ð40Þ
and objective function is
minðu_Þ ð41Þ
the maximum approximate solution is u
_ðtÞ.
Therefore, in order to quickly solve the mathematical programming problems of inequations (38)–(41),
residual correction concept raised in this article is used to convert the mathematical programming problem of
an inequation into equation iterative operation as per the following steps:
1. Discretize Eq. (37) on each calculation grid point according to spline approximation relation for initial
value problems and rewrite it into the following iterative equation:
2
umþ1i  ui1
Dti
 u0i1 
ðumi Þ2
1þ ðumi Þ2
umþ1i ¼ Rmi ; ð42Þ
where Rmi is the corrected residual value of calculation grid point i. It is used to correct the residual value on
a calculation grid point and ensure the residual values within neighboring subinterval (ti1 6 t 6 ti) are all
positive or negative.
2. Make i = 0 and t = 0, and set condition for initial value as per Eq. (36).
3. Add 1 to i and t = a + Dti, set m = 0 and assume residual correction R
m
i ¼ 0.
4. Progress one m value and obtain approximate solution umþ1i from Eq. (42) and its derivatives u
0mþ1
i and u
00mþ1
i
from Eqs. (27) and (28).
5. Put Eq. (25) into residual expression (37) to obtain residual values R(t) within the interval ti1 6 t 6 ti, for
uðnÞi in the expression all are known, then get new residual correction from Eq. (23) or (24).
6. Repeat steps 4 and 5 till Rmþ1i ¼ Rmi .
7. Return to step 3 and continue calculation till the required t value.
In order to observe whether the result from residual correction method is correct, Fig. 1 illustrates the
residual distribution before and after residual correction. From Fig. 1, it can be seen that although the
uncorrected residuals of the approximate solutions of a diﬀerential equation are zero on calculation grid
points, they are not zero on non-calculation grid points as the approximate solutions fail to satisfy all the inner
regions within neighboring subintervals. Further observation reveals the uncorrected residual distribution
exactly meets the requirement that residuals shall be greater than or equal to zero in every region, indicating
residual correcting in unnecessary for extracting upper approximate solutions. Therefore, these two residual
curves in Fig. 1 overlap each other. On the other hand, when extracting lower approximate solutions, the
residuals for Eq. (37) must satisfy the distribution deﬁned by Eq. (38) (i.e. all of them are smaller than or equal
to zero), Therefore, as shown in the ﬁgure, during residual correction, condition that makes the residuals
within the subinterval of a calculation grid point all smaller than or equal to zero is eliminated. Take t = 0.9
for example, although the uncorrected residual value at 0.9 is zero, no residuals is smaller than or equal to zero
when 0.6 < t < 0.9, therefore, the residual at t = 0.9 is corrected into 0.04 as per the residual correction
method put forth by this article, making the residues within the interval 0.6 < t 6 0.9 are all smaller than or
equal to zero.
34 C.-C. Wang / Applied Mathematics and Computation 181 (2006) 29–39
Au
th
or
's 
  p
er
so
na
l   
co
py
comparing with exact solution. However, in practical application, the mean approximate solutions extracted
from Eq. (32) can be used as the ﬁnal and better numerical approximate solutions. In this example, the exact
solution is
uðtÞ ¼ 1ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
ProductLogðe2tþ1Þp . ð43Þ
Whilst the exact value at t = 3 is
uð3Þ ¼ 12:22333. ð44Þ
To put it into Eq. (34), it can be f und that the error of mean approximate solution in the last column of Table
1 is much smaller than the maximum possible error, indicating the upper and lower solutions obtained by
using residual correction met od in this article can be used to analyze the maximum possible error of a solu-
tion. Moreover, as the residuals of these two approximate solutions are always distributed on two sides of zero
in a basically symmetric manner as shown in Fig. 1, the errors between the upper/lower approximate solutions
extracted from Fig. 2 and the exact solution are symmetric to considerable degree, and the values of mean
approximate solutions extracted from Eq. (32) are rather close to their exact solutions even when time incre-
ment is very big. Therefore, it can say that the residual correction also indirectly increases the accuracy of
mean approximate solutions.
Example 2. Consider Bratu-type problem under initial value problem [7]
u00  2eu ¼ 0; ð45Þ
uð0Þ ¼ u0ð0Þ ¼ 0. ð46Þ
Fig. 3. Diﬀerence between upper and lower solutions under diﬀerent time increments.
Table 1
Approximate solutions and errors obtained in Example 1 at x = 3 under diﬀerent number of calculation grid points
Dt u Emax (%) Er (%)
Lower solutions u
^
Average values u Upper solutions u
_
0.60 11.546206 12.579525 13.612843 17.90 2.9135
0.30 12.031584 12.28668 12.541779 4.24 0.5176
0.15 12.147806 12.224545 12.301284 1.26 0.0094
0.06 12.209292 12.222479 12.235666 0.22 0.0075
0.03 12.219647 12.223031 12.226416 0.05 0.0030
36 C.-C. Wang / Applied Mathematics and Computation 181 (2006) 29–39
Au
th
or
's 
  p
er
so
na
l   
co
py
with the increase of coordinate under diﬀerent time increments, and the error analysis at t = 1.3 are drawn and
listed in Fig. 6 and Table 2, respectively. In a word, the relations between approximate/exact solution and time
increment are same as described in Example 1, indicating the residual correction put forth by this article can
also be applied to second order initial value problem. Finally, it shall be known that the exact solution of this
problem is
uðtÞ ¼ 2 lnðcosðtÞÞ. ð48Þ
Apparently, it is inﬁnite at t = p/2. If this method is used for calculation to this point, it will be found although
the lower approximate solution can be obtained, the upper approximation solution cannot obtained, for it
becomes divergent during iteration. The actual reason is that numerical method is unable to express a value
that is greater than inﬁnite, so the condition the upper approximate solutions are not constringent during cal-
culation again proves it can be assured the approximate solutions obtained in this article are greater than or
smaller than exact solution.
4. Conclusions
Through validation of two examples of this article, we can ﬁnd the residual correction method put forth by
this article can quickly correct the residuals of approximate solutions on initial value problem of a diﬀerential
equation and satisfy the condition that corrected residuals are all greater than or smaller than zero. Under the
support of monotonicity of a diﬀerential equation, the upper and lower approximation solutions of an initial
value problem can always been obtained correctly. As proved by the above two examples, the process to
obtain upper and lower approximate solutions by this method does not need extra internal memory and
Fig. 6. Diﬀerence between upper and lower approximate solutions under diﬀerent time increments.
Table 2
Approximate solutions and errors obtained in Example 2 at x = 1.3 under diﬀerent number of calculation grid points
Dt u Emax (%) Er (%)
Lower solutions u
^
Average values u Upper solutions u
_
0.260 2.5441334 2.7558282 2.9675230 16.64 4.4951
0.130 2.6079607 2.6494900 2.6910193 3.18 0.4639
0.065 2.6273601 2.6385111 2.6496622 0.85 0.0467
0.026 2.6352541 2.6372355 2.6392169 0.15 0.0017
0.013 2.6367289 2.6372457 2.6377624 0.039 0.0013
38 C.-C. Wang / Applied Mathematics and Computation 181 (2006) 29–39
This article appeared in a journal published by Elsevier. The attached
copy is furnished to the author for internal non-commercial research
and education use, including for instruction at the authors institution
and sharing with colleagues.
Other uses, including reproduction and distribution, or selling or
licensing copies, or posting to personal, institutional or third party
websites are prohibited.
In most cases authors are permitted to post their version of the
article (e.g. in Word or Tex form) to their personal website or
institutional repository. Authors requiring further information
regarding Elsevier’s archiving and manuscript policies are
encouraged to visit:
http://www.elsevier.com/copyright
Author's personal copy
concluded that the numerical values obtained through this method and their diﬀerential values below the ﬁfth-
order are both continuous and very accurate. Recently, Wazwaz [8] and Syam and Atili [9] made attempts to
solve these problems through the Adomain decomposition method together with a modiﬁed technique, and
after having compared this approach with other numerical methods, came to the conclusion that such numer-
ical method can raise computational eﬃciency eﬀectively.
When we look back to the researches conducted in the past, we may ﬁnd out that most of the numerical
methods, when used to solve higher-order boundary-value problems, always base validation of the error range
of calculation results on the known exact solutions of these problems. In practical applications, however, the
exact solutions are often unknown to us. Under such circumstances, more grid points or approximation func-
tions are requisite to determine reliability of these results and their error range roughly, which requires a lot of
time and energy from us. In light of the above-mentioned situations, this paper suggests a new method ‘‘sixth-
degree B-spline residual correction method’’ to calculate maximum and minimum approximate solutions of
ﬁfth-order boundary-value problems for diﬀerential equations. The steps are as follows: ﬁrst establish the
residual expressions of a diﬀerential equation based on the maximum principle for diﬀerential equations; then
discretize and convert the residual relation into optimized constraint problems for inequations through sixth-
degree B-spline; and ﬁnally adopt the iterative technique for residual correction and the concept of virtual time
(if necessary) to translate originally complex inequational constraint problems into simple problems involving
equational iteration. The solutions obtained in such a way cannot only be deﬁned as the upper or lower solu-
tions of the exact solution, but also the value of error between the exact solution and the upper or lower solu-
tion can be considered as the maximum possible error of these approximate solutions.
2. Problem formulation for lower and upper solutions
2.1. Residual correction method
Let us begin by considering a nonlinear ﬁfth-order boundary-value problem as shown below:
uðvÞðxÞ ¼ Hðx; uÞ; x 2 ða; bÞ: ð1Þ
The traditional way to solve such a diﬀerential equation was no more than discretization of the equation into
an algebraic equation set or use of a trial function as its approximate solution. Yet such approximation meth-
od often fails to satisfy the diﬀerential equation completely on all calculation intervals. As a result, the residual
values of the diﬀerential equation occur. In order to obtain the maximum and minimum approximate solu-
Nomenclature
B(x) B-spline function
Emax maximum possible error of an approximate solution, u
_ u^
h interval between adjacent grid points, xi  xi1
n number of grid points
R(x) residual value of the diﬀerential equation
Ri residual correction value at a calculation grid point
u function
Superscripts
m iteration time needed for residual correction
– mean approximate solution
\, [ upper and lower approximate solutions
Subscript
i serial number of a calculation grid point
678 C.-C. Wang et al. / Applied Mathematics and Computation 199 (2008) 677–690
Author's personal copy
(b) For the lower approximate solution to be calculated:
Rmþ1i ¼ Rmi maxRðxÞ;maxða; xi1Þ 6 x 6 minðb; xiþ1Þ; ð7Þ
where R(x) is a residual value function obtained from putting the function and its derivative value obtained
in the previous step into Expression (2).
4. Turn to the next value of m and repeat Steps 2 and 3, till Rmþ1i ¼ Rmi .
2.2. The sixth-degree B-spline
The residual values in the adjacent subdomains must be sought ﬁrst before the solutions of the residual cor-
rection expressions (6) and (7) may be obtained. However, the conventional ﬁnite diﬀerence method is more
often used to solve diﬀerential equations of lower order, and the functions derived through such method and
their derivatives only reﬂect the results at grid points and are not continuous at non-calculation grid points. To
address such issue, this article considers the sixth-degree B-spline as an approximation function to discretize
and convert Expression (2) into Expression (5), so as to ensure that the function itself and its derivative values
below the ﬁfth-order are not only continuous at grid points, but also continuous in any place. According to the
theory on B-spline, the relation of sth-degree B-spline may be expressed as follows [13]:
BðdÞs ðxÞ ¼
Xsþ1
j¼0
ð1Þj
ðs dÞ!
ðsþ 1Þ!
j!ðsþ 1 jÞ! Maxð0; xþ
sþ 1
2
 jÞ
 md
: ð8Þ
For the above-mentioned expression, s and d denote the greatest diﬀerentiable degrees and diﬀerentiation time
of the B-spline. Taking the sixth-degree B-spline into account, this expression can be rewritten into the follow-
ing form:
B6 x 1
2
 
¼ 1
720
ð3þ xÞ6 x 2 ½3;2
7ð2þ xÞ6þ ð3þ xÞ6 x 2 ½2;1
21ð1þ xÞ6  7ð2þ xÞ6 þ ð3þ xÞ6 x 2 ½1;0
35x6 þ 21ð1þ xÞ6  7ð2þ xÞ6 þ ð3þ xÞ6 x 2 ½0;1
35ð1þ xÞ6  35x6 þ 21ð1þ xÞ6  7ð2þ xÞ6 þ ð3þ xÞ6 x 2 ½1;2
21ð2þ xÞ6þ 35ð1þ xÞ6  35x6 þ 21ð1þ xÞ6  7ð2þ xÞ6 þ ð3þ xÞ6 x 2 ½2;3
ð4þ xÞ6 x 2 ½3;4
8>>>>>>><>>>>>>>:
9>>>>>>>=>>>>>>>;
:
ð9Þ
Apparently, the derivatives of Expression (9) below the ﬁfth-order are continuous in the x-aisle. So if the space
on [a,b] consisting of grid points X : a = x0 < x1 <    < xn = b is a uniform interval h = xi  xi1, the approx-
imation function of the diﬀerential equation can be expressed by many diﬀerent spline B6(x), enabling us to
suppose such approximation function takes the following form:
~uðxÞ ¼
Xnþ2
i¼3
ciB6
x xi
h
 1
2
 
; ð10Þ
where the unknown coeﬃcient ci is a reference value for the spline at the grid point i. After substitution of
Expression (9) into Expression (10), we can get discrete relations below the ﬁfth-order at grid points as follows:
ui ¼ 1
720
ðci3 þ 57ci2 þ 320ci1 þ 320ci þ 57ciþ1 þ ciþ2Þ; ð11Þ
u0i ¼
1
120h
ðci3  257ci2  40ci1 þ 40ci þ 25ciþ1 þ ciþ2Þ; ð12Þ
680 C.-C. Wang et al. / Applied Mathematics and Computation 199 (2008) 677–690
Author's personal copy
2. Let m = 0 and suppose that the quantity for residual correction Rmi ¼ 0.
3. Turn to the next value of m, determine the unknown coeﬃcient ci by using Expressions (24) and (25), and
then obtain the approximate solution u(x)m+1 and its derivatives below the ﬁfth-order based on Eqs. (9) and
(10).
4. Derive a new residual correction quantity Rmþ1i from Expression (6) or (7).
5. Repeat Steps 3 or 4, till Rmþ1i ¼ Rmi .
To make sure if the residual correction method really enables the constraint conditions of Expression (20)
or (22) to be met, Fig. 1 shows curve distributions of residual values of the diﬀerential equation on the x-axis
before and after residual correction is carried out. As shown in this ﬁgure, for the approximate solutions which
do not experience residual correction, although the residual values of the diﬀerential equation are equal to zero
at calculation grid points (x = 0,0.1,0.2, . . . , 1), the phenomena in which the residual values are not equal to
zero at non-calculation grid points do occur, because the approximate solution cannot satisfy all internal areas
on adjacent subintervals, leading to occurrence of the phenomena that the residual values are equal to zero at
non-calculation grid points. Through further observations, we can ﬁnd out that the residual values that do not
experience residual correction are distributed in such a way that meets the requirement for the residual values
to be smaller than or equal to zero in all areas, indicating that no residual correction is needed to obtain the
lower approximate solution. As a result, the two distribution curves of residual values overlap in the ﬁgure. On
the other hand, the residual values of Eq. (19) must satisfy the distribution of residual values for Expression
(22) (i.e. greater than or equal to zero). For this purpose, a residual value is added to each calculation grid
point in the process of residual correction to ensure that all residual values of the diﬀerential equation are
greater than or equal to zero on subintervals, as shown in the ﬁgure.
Since the residual values in Fig. 1 satisfy Expression (20) or (22), the following relationship between the
approximate solution listed in Table 1 and the exact solution can be ensured, even if the exact solution cannot
be sought: the approximate solution u
_
is the optimal upper approximate solution of the exact solution, while u
^
serves as the optimal lower approximate solution of the exact solution. In another word, residual correction
will result in such feature of the approximate solution: the upper approximate solution must be greater than
the lower approximate solution, and the exact solution must exist between the upper and lower approximate
solutions. Such feature provides the basis for determining the range of the maximum possible error of both
x
R
0 0.25 0.5 0.75 1
-0.2
-0.15
-0.1
-0.05
0
0.05
0.1
0.15
0.2
Ri=0
R(x)>0
R(x)<0
Fig. 1. Curve distribution of residual values before and after residual correction under the condition of the number of grid points n = 10.
682 C.-C. Wang et al. / Applied Mathematics and Computation 199 (2008) 677–690
Author's personal copy
and lower approximate solutions obtained following the residual correction in relation to the exact solution is
also characterized by such symmetry to some extent, thus improving the accuracy of the mean approximate
solution indirectly. Secondly, the results from comparison between the solutions obtained in this paper and
those sought by Caglar et al. [7] under the condition of the same number of grid points show that the method
suggested by this article is not only useful in determining the maximum possible error, but also the accuracy of
the mean approximate solution is improved signiﬁcantly.
Example 2. Let us consider a nonlinear BVP [7] as follows:
uðvÞðxÞ ¼ 24e5uðxÞ þ 48ð1þ xÞ5 ; 0 < x < 1; ð26Þ
uð0Þ ¼ 0; u0ð0Þ ¼ 1; u00ð0Þ ¼ 1; uð1Þ ¼ lnð2Þ; u0ð1Þ ¼ 1=2: ð27Þ
To obtain its upper and lower solutions, it is necessary to ﬁrst work out the discrete expression of its residual
equation as follows:
uðvÞi þ 24e5ui þ
48
ð1þ xiÞ5
¼ Ri: ð28Þ
We take the calculation steps as done in Example 1 and adopt the homotopy perturbation method [14] to han-
dle recursive solutions of nonlinear terms, and then we will see the residual values are distributed above or
below zero after residual correction is performed, as shown in Fig. 3, and the upper and lower approximate
solutions obtained are listed as in Table 3. In addition, the maximum error of approximate solutions is ana-
lyzed and the values of actual error are calculated under the conditions of diﬀerent number of grid points, with
the results shown in Fig. 4 and Table 4, respectively. In general, the relationship between approximate and
exact solutions and the number of grid points is similar to that in example, indicating that the residual cor-
rection method proposed in this article can also be applicable to solving nonlinear ﬁfth-order boundary-value
problems eﬀectively.
Example 3. Consider the ﬁfth-order system [15]
w000 þ 3 n
2
ww00 þ nðw0Þ2  1þ G2  sw0 ¼ 0; ð29Þ
G00 þ 3 n
2
wG0 þ ðn 1Þw0G sðG 1Þ ¼ 0: ð30Þ
With the boundary conditions
wð0Þ ¼ w0ð0Þ ¼ Gð0Þ ¼ 0; wð1Þ ¼ 0; Gð1Þ ¼ 1; ð31Þ
where n and s are given constants to solve similarity solution for rotating ﬂows in boundary-layer problem. In
order to solve the above-mentioned equation set and enhance the monotonicity properties of the subject prob-
Table 2
Comparison between the error of mean solutions and the results of Caglar et al. [7] under the condition of n = 30 for Example 1
x Analytical solutiona Errorsb (present) Errorsc ([7], B-spline)
0.1 0.09946538 1.0E8 8.0E3
0.2 0.19542444 6.0E8 1.2E3
0.3 0.28347035 1.5E7 5.0E3
0.4 0.35803793 2.7E7 3.0E3
0.5 0.41218032 3.8E7 8.0E3
0.6 0.43730851 4.3E7 6.0E3
0.7 0.42288807 3.9E7 0
0.8 0.35608655 2.7E7 9.0E3
0.9 0.22136428 1.0E7 9.0E3
a Analytical solution = x(1  x)ex.
b Error = analytical solution  average values (i.e. u ¼ ðu_þ u^Þ=2).
c Error = analytical solution  numerical solution.
684 C.-C. Wang et al. / Applied Mathematics and Computation 199 (2008) 677–690
Author's personal copy
intervals, the residual value here can be directly set as zero. According to the diﬀerential equation monotonic-
ity principle, when approximation functions w and G make the residual equations (33) and (34) meet the fol-
lowing conditions:
RuðgÞP 0; ð35Þ
RGðgÞP 0 ð36Þ
the lower approximate solutions in relation to the exact solution can be obtained. On the other hand, when
approximation function w and G make the residual equations meet the following conditions:
RuðgÞ 6 0; ð37Þ
RGðgÞ 6 0 ð38Þ
Fig. 4. Diﬀerence between upper approximate solutions and lower approximate solutions under the condition of diﬀerent number of grid
points.
Table 4
Comparison between the error of mean solutions and the results of Caglar et al. [7] under the condition of n = 30 for Example 2
x Analytical solutiona Errorsb (present) Errorsc ([7], B-spline)
0 0.00000000 0 0
0.1 0.09531018 2E8 0
0.2 0.18232156 1.2E7 0.015
0.3 0.26236426 2.8E7 0.029
0.4 0.33647224 4.5E7 0.028
0.5 0.40546511 5.6E7 0.026
0.6 0.47000363 5.8E7 0.024
0.7 0.53062825 4.8E7 0.026
0.8 0.58778666 3.0E7 0.033
0.9 0.64185389 1.0 E7 0.046
1.0 0.69314718 0 0
a Analytical solution = ln(1  x).
b Error = analytical solution  average values (i.e. u ¼ ðu_þ u^Þ=2).
c Error = analytical solution  numerical solution.
686 C.-C. Wang et al. / Applied Mathematics and Computation 199 (2008) 677–690
Author's personal copy
cannot be ensured based on the maximum principle for diﬀerential equation. However, after residual correc-
tion proposed in this article, the resulting residual values at calculation grid points, as shown in Fig. 5a and b,
are not necessarily equal to zero, instead, correction shall be carried out on residual values according to their
adjacent subintervals to ensure that every residual value is a positive or negative number on adjacent subin-
tervals of the grid point. To further conﬁrm the existence of monotonicity, Tables 5 and 6 show wall diﬀer-
ential values and error analysis of functions u and G. We can ﬁnd out from Tables that the lower
diﬀerential approximate values at wall (g = 0) of functions u and G always remain less than the corresponding
upper wall diﬀerential values. This is because the wall boundary conditions are ﬁxed (i.e. G(0) = u(0) = 0), so
the diﬀerential approximate values at wall also show the monotonicity properties similar to the inherent
monotonicity properties of the functions. Such monotonicity properties ensure the value of diﬀerence between
Table 5
Approximate values and error ranges of function u 0(0) on various maximum calculation intervals L with n = 0.1, s = 0.2 and Dg = 0.1
L u 0(0) Emax ¼ u_00  u^0 Scott and Watts [15]
Lower solutions u
^0
Average solutions u0 Upper solutions u
_0
3 0.9901858625 0.9900751327 0.9899644029 2.2146E4 0.9900771
6 0.9663747104 0.9662913761 0.9662080417 1.6666E4 0.9663039
9 0.9663823450 0.9662990149 0.9662156849 1.6666E4 0.9663115
12 0.9663823438 0.9662990327 0.9662157217 1.6662E4 0.9663115
Table 6
Approximate values and error ranges of function G 0(0) on various maximum calculation intervals L with n = 0.1, s = 0.2 and Dg = 0.1
L G 0(0) Emax ¼ G
_0
 G
^0
Scott and Watts [15]
Lower solutions G
^0
Average solutions G0 Upper solutions G
_0
3 0.6236992133 0.6237212459 0.6237432785 4.40652E05 0.6236982
6 0.6529111788 0.6529230659 0.6529349531 2.37743E05 0.6529137
9 0.6529073334 0.6529191978 0.6529310622 2.37288E05 0.6529098
12 0.6529073305 0.6529192166 0.6529311028 2.37723E05 0.6529098
Fig. 6. Distribution of w and G with n = 0.2, 0.261 and 0.3, and s = 0.05.
688 C.-C. Wang et al. / Applied Mathematics and Computation 199 (2008) 677–690
Author's personal copy
[5] A.R. Davies, A. Karageorghis, T.N. Phillips, Spectral Galerkin methods for the primary two-point boundary-value problem in
modeling viscoelastic ﬂows, Int. J. Numer. Methods. Eng. 26 (1988) 647–662.
[6] S.S. Siddiqi, E.H. Twizell, Spline solution of linear sixth-order boundary-value problems, Int. J. Comput. Math. 60 (3) (1996) 295–
304.
[7] H.N. Caglar, S.H. Caglar, E.H. Twizell, The numerical solution of ﬁfth-order boundary value problems with sixth-degree B-spline
functions, Appl. Math. Lett. 12 (1999) 25–30.
[8] A.M. Wazwaz, The numerical solution of ﬁfth-order boundary value problems by the decomposition method, J. Comput. Appl.
Math. 136 (2001) 259–270.
[9] M.I. Syam, B.S. Attili, Numerical solution of singularly perturbed ﬁfth order two point boundary value problem, Appl. Math.
Comput. 170 (2005) 1085–1094.
[10] M.H. Protter, Maximum Principles in Diﬀerential Equations, Prentice-Hall, Englewood Cliﬀs, NJ, 1967.
[11] L.E. Fraenkel, Introduction to Maximum Principles and Symmetry in Elliptic Problems, Cambridge University Press, New York,
2000.
[12] C.C. Wang, Use residual correction method to calculate the upper and lower solutions of initial value problem, Appl. Math. Comput.
181 (2006) 29–39.
[13] C. de Boor, A Practical Guide to Splines, Springer-Verlag, New York, 1978.
[14] J.H. He, Comparison of homotopy perturbation method and homotopy analysis method, Appl. Math. Comput. 156 (2004) 527–539.
[15] M.R. Scott, H.A. Watts, A systematized collection of codes for solving two-point boundary-value problems, in: L. Lapidus, W.E.
Schiesser (Eds.), Numerical Methods for Diﬀerential Systems, Academic, New York, 1976, pp. 223–225.
690 C.-C. Wang et al. / Applied Mathematics and Computation 199 (2008) 677–690
Author's personal copy
Study on monotonicity of boundary value problems
of diﬀerential equations
Chi-Chang Wang a,*, Hai-Ping Hu b
aDepartment of Technology Management, Hsing Kuo University of Management, Tainan 709, Taiwan, ROC
bDepartment of Marine Engineering, National Taiwan Ocean University, Keelung 20224, Taiwan, ROC
Abstract
This article presents two new test methods to decide monotonic increasing or decreasing properties of diﬀerential equa-
tions. For simple problems, the eigenfunction test method can be applied to obtain their exact monotonicity or their loosest
conditional expression, and can contribute to probes into accumulated eﬀect of various terms in equations on their mono-
tonicity. Secondly, the trial function test method sets relatively strict conditions for discrimination ofmonotonicity, but it can
verify complex non-linear problems in a simple and rapid way. Therefore, these two similar test methods will help to further
understand theories on monotonicity, thus making it possible to apply monotonic equations more widely to other problems.
 2008 Elsevier Inc. All rights reserved.
Keywords: Maximum principle; Monotonic equation; Upper and lower solutions; Error analysis
1. Introduction
Regarding error analysis of approximate solutions of diﬀerential equations, early in 1964, Appl and Hung
[1] began to utilize the maximum principle [3–5] to judge monotonicity of such boundary value problems and
on this basis, to obtain upper and lower approximate solutions of exact solutions of diﬀerential equations in
order to understand error range of these approximate solutions. Again in 1966, Finlayson and Scriven [2]
made the similar attempts. However, such method requires conversion into mathematical programming prob-
lems of inequalities, resulting in very complex and lengthy process of operation. In light of this, to the author’s
knowledge, some scholars have recently tried to use given trial functions in combination with genetic algo-
rithms (Lin and Chen [6] and Chang and Lee [7]) instead of traditional non-linear programming methods
to get better approximate solutions. Besides, Wang [8,9] used Spline as the basic function to discretize diﬀer-
ential equations, followed by addition of residual correction values to discretized grid points, using the ‘‘resid-
ual correction method” he proposed, to convert complex constraint mathematical programming problems of
inequalities into simpler equational iteration ones. As a result, the eﬃciency of obtaining solutions is raised
signiﬁcantly.
0096-3003/$ - see front matter  2008 Elsevier Inc. All rights reserved.
doi:10.1016/j.amc.2008.02.036
* Corresponding author.
E-mail address: ccwang123@mail.hku.edu.tw (C.-C. Wang).
Available online at www.sciencedirect.com
Applied Mathematics and Computation 202 (2008) 383–394
www.elsevier.com/locate/amc
Author's personal copy
Among eﬀorts on monotonicity analysis in the past, monotonicity of second order boundary values were
most thoroughly discussed. To describe monotonicity of such problems, let us consider the following diﬀeren-
tiation problem of non-linear boundary values:
RðuÞ ¼ u00 þ Hðx; u; u0Þ; x 2 ða; bÞ; ð10Þ
with the boundary conditions
RbðaÞ ¼ u0ðaÞ cos h uðaÞ sin hþ ca; ð11Þ
RbðbÞ ¼ u0ðbÞ cos/ uðaÞ sin/þ cb; ð12Þ
where 0 6 h 6 p/2 and 0 6 / 6 p/2, and one of them is not equal to zero at any time. Suppose that u_ðxÞ and
u
^ðxÞ are deﬁned on the interval (a, b) and have continuous derivatives till the second order, if H, oHou and oHou0 are
continuous, and
oH
ou
6 0 ð13Þ
this problem has the properties of monotonic decreasing [3].
As indicated above, Expression (13) is applied to judge existence of monotonicity in monotonicity analysis
of second order boundary value problems. Simple as this method is, it is often too strict in practice. Besides the
possibility that originally monotonic problems are decided as non-monotonic by using such method, it is not
applicable to solve high order boundary value problems. For this reason, this article presents two new discrim-
ination methods in an attempt to judge monotonicity more accurately.
2.2. The eigenfunction test method
Let us consider the boundary value problem involved in Expressions (1) and (2), if its corresponding
eigenfunctions
LðuÞ ¼ ku; 2 V ; ð14Þ
BðuÞ ¼ 0; 2 S ð15Þ
exist and have n eigenvalues {ki} (i = 1,2,3, . . . ,n), and their corresponding linearly independent eigenfunc-
tions are {ui} (i = 1,2,3, . . . ,n), the complete set of such eigenfunctions can be regarded as a group of the bases
for expression of function u(x) included in Eqs. (1) and (2), i.e.
uðxÞ ¼
Xn
i¼1
uiðxÞ: ð16Þ
So when
dRi
dui
P 0; i ¼ 1; 2; 3; . . . ; n ð17Þ
it can be concluded that monotonicity of Expressions (1) and (2) exists and is characterized by monotonic
increasing that can satisfy Expressions (5)–(7). Conversely, when
dRi
dui
6 0; i ¼ 1; 2; 3; . . . ; n ð18Þ
the monotonicity of Expressions (1) and (2) still exists and is characterized by monotonic decreasing that can
satisfy Expressions (7)–(9).
2.3. The approximate function test method
Similarly, consider the boundary value problem covered by Expressions (1) and (2), which leads to the
residual equation that can be denoted as
Rð~uÞ ¼ Lð~uÞ  f ðxÞ ¼ Lðd~uÞ; 2 V ð19Þ
C.-C. Wang, H.-P. Hu /Applied Mathematics and Computation 202 (2008) 383–394 385
Author's personal copy
k2 6 p
l
 2
ð32Þ
the contribution of various terms to monotonic quantity in this expression will always be negative values and
satisfy Expression (17) if iP 1. This indicates that Example 1 has the properties of monotonic decreasing if the
above-mentioned expression is satisﬁed.
The eigenfunction test method can be applied to obtain the simplest and correct expression for monotonic-
ity analysis; however, sometimes diﬀerential equations are so complex that their eigenfunctions cannot be
sought easily. In such cases, the test method of trial functions may be useful for monotonicity analysis of these
diﬀerential equations. As in Example 1, suppose the approximate solution that meets the boundary condition
of Expression (26) is ~u(x) and the diﬀerence between this solution and the exact solution u is d ~u = ~u  u. Put
this solution and the expression of the diﬀerence into Expression (25) and rewrite it into a residual relation, as
what is done to Expression (19), i.e.
Rð~uÞ ¼ ~u00ðxÞ þ k2~uðxÞ MðxÞ ¼ d~u00ðxÞ þ k2d~uðxÞ; x 2 ð0; lÞ ð33Þ
then the monotonicity of this problem can be determined through use of function d~uðxÞ. Since the highest or-
der diﬀerential term of this problem is of monotonic decreasing, let trial functions u
_
and u
^
be polynomials that
satisfy Expression (21) and (22), respectively,
d u
_ðxÞ ¼ xðl xÞ
Xn
i¼1
aixi; ð34Þ
d u
^ðxÞ ¼ xðl xÞ
Xn
i¼1
aixi; ð35Þ
the problem can be recognized as monotonic, if Expression (24) is satisﬁed, too. Here, let us begin by consid-
ering the simplest form, i.e. let n = 0 and put Expressions (34) and (35) into Expression (33), then the necessary
condition for existence of monotonic decreasing is
ð2þ k2xðl xÞÞP 0P 2þ k2xðl xÞ; x 2 ð0; lÞ: ð36Þ
Similarly, based on Expression (32) derived by using the eigenfunction test method, the condition for
Expression (36) at x 2 (0, l) is
k2 6 8
l2
: ð37Þ
So the approximate function test method can lead us to conclude that this example is monotonic, provided
that Expression (37) is satisﬁed. It should be noted that the condition for monotonicity analysis of the expres-
sion indicated above is much stricter than that in Expression (32). The greater the value of n in Expression (34)
and (35) is, the more chances there will be to ﬁnd more proper trail functions, thus making the generated dis-
criminant closer to the correct one obtained with the eigenfunction test method.
In order to demonstrate the applicability of monotonicity test methods proposed in this text, the upper and
lower approximate solutions obtained with the methods suggested in [7,8] are required to meet the conditions
that residual value distribution of diﬀerential equations are always smaller or greater than zero at l = 1 and
M(x) = 1, as shown in Fig. 1. And Fig. 2 shows the error of upper and lower approximate solutions varies
as k2 increases. As indicated in Fig. 2a, because k < p, the upper and lower approximate solutions of the dif-
ferential equation obtained under monotonic decreasing are always distributed at both ends of the exact solu-
tion respectively and expectedly. However, when k continues to increase till it is greater than p, the upper and
lower solutions obtained ﬁrst at k2 = 20 are not really greater or smaller than the exact solution, but on the
contrary, as shown in Fig. 1b. When k2 further increases to be at 60, it is clear that the upper and lower
approximate solutions are distributed irregularly in upper and lower sides of the exact solution, showing that
when the diﬀerential equation is not monotonic any more, it is impossible to determine the relation of approx-
imate solutions with the exact solution, or in another word, it is impossible to judge whether the approximate
solutions are larger or smaller than the exact solution.
C.-C. Wang, H.-P. Hu /Applied Mathematics and Computation 202 (2008) 383–394 387
Author's personal copy
the value of Expression (44) will be always negative regardless of the value of i, indicating that Example 2 is
monotonic if Expression (45) is satisﬁed. In this example, since r and k are unknown, it will be diﬃcult to gen-
erate a simple discriminant by using the trial function test method. For this reason, the following example is
given to demonstrate the advantages of trial function test method.
Example 3. Let us begin with the following problem
u00ðxÞ þ 5xu0ðxÞ þ 10uðxÞ ¼ 1; x 2 ð0; 1Þ; ð46Þ
uð0Þ ¼ uð1Þ ¼ 0 ð47Þ
this example can be considered as a non-monotonic problem if its ﬁrst order diﬀerential term is not taken into
account. Yet, since ﬁrst order diﬀerential terms can have impact on monotonicity as Example 2 indicates, it is
still likely that monotonicity of this problem exists. For conﬁrmation, the trial function test method is applied
to ﬁrst generate the residual relation of Expression (46) as follows:
Fig. 2. Distribution of error between approximate function and exact solution when (a) monotonicity exists (b) monotonicity does not
exist for Example 1.
C.-C. Wang, H.-P. Hu /Applied Mathematics and Computation 202 (2008) 383–394 389
Author's personal copy
Rð~uÞ ¼ 8ð3 50x2 þ 100x3  50x4 þ að9þ 45x 45x2  50x3 þ 150x4  150x5 þ 50x6ÞÞ ð55Þ
the value of the above expression will be always greater than zero in the domain of x at a = 0.3. So with the
boundary conditions in Expression (54), Expression (50) is monotonic increasing.
To further verify correctness of monotonicity test, Tables 2 and 3 show the numerical solutions obtained
under two diﬀerent boundary conditions as the value of k becomes smaller. As shown in Table 2, when k
is greater than p4, the diﬀerential equation in this example is monotonic, so if its residual values are greater
than or equal to zero, or smaller than or equal to zero, the approximate solutions will be the upper and lower
approximate solutions respectively. However, if the value of k is smaller than p4, the diﬀerential equation is
not monotonic any more, and the approximate solutions obtained under such conditions are not monotonic,
either. So we are not certain that the approximate solutions obtained under R(x)P 0 are still the upper solu-
tions. Similarly, it is not certain that the approximate solutions obtained under the condition of R(x) 6 0 are
the lower solutions any more. In addition, Table 3 shows the same results, except that its monotonicity exists
when k < 500.56 under diﬀerent boundary conditions.
Example 5. For the higher order non-linear diﬀerential equation in the following form:
uð4ÞðxÞ þ u00ðxÞ þ ðx 1
2
Þu0ðxÞ  u2ðxÞ ¼ 1; x 2 ð0; 1Þ; ð56Þ
with the boundary conditions
uð0Þ ¼ 1; uð1Þ ¼ 0; u00ð0Þ ¼ 10; u00ð1Þ ¼ 0 ð57Þ
Table 2
Variation of upper and lower approximate solutions with decreasing values of k with Expression (51) as the boundary conditions for
Example 4 (grid points is 10)
k u(0.5) Ep ¼ u
_ u^
2
R(~u) 6 0 Exact solution R(~u)P 0
500 2.076911 2.08422 2.098734 1.1E2
200 4.220199 4.23220 4.255842 1.8E2
100 6.386482 6.40019 6.427046 2.0E2
0 13.020833 13.0208 13.020833 1.2E11
30 18.769176 18.8378 18.873483 5.2E2
60 31.918130 33.9849 32.559853 3.2E1
95 399.35107 582.463 634.11934 1.2E1
p4 – – – –
100 419.15375 491.476 718.92954 150
150 23.969928 24.2615 24.841052 4.4E1
200 12.359502 12.4624 12.663905 1.5E1
Table 3
Variation of upper and lower approximate solutions with decreasing values of k with Expression (54) as the boundary conditions for
Example 4 (10 grid points)
k ~u(0.5) Ep ¼ u
_ u^
2
R(~u) 6 0 Exact values R(~u) = 0 R(~u)P 0
500 1.283533 1.28800 1.295892 6.2E3
200 1.848234 1.85207 1.858530 5.2E3
100 2.162815 2.16546 2.169862 3.5E3
0 2.604167 2.60416 2.604167 3.8E13
100 3.252163 3.26202 3.268000 7.9E3
200 4.322899 4.35778 4.378742 2.8E3
490 79.78272 124.876 188.1526 5.4E1
500.56 – – – –
510 80.33857 139.871 409.8298 1.6E2
750 5.206490 5.32383 5.528832 1.6E1
1000 2.635641 2.67649 2.744996 5.5E2
C.-C. Wang, H.-P. Hu /Applied Mathematics and Computation 202 (2008) 383–394 391
Author's personal copy
d4u
dx4
þ e du
dx
d5u
dx5
¼ c; 1=2 < x < 1=2; ð60Þ
uð1=2Þ ¼ du
dx
ð1=2Þ ¼ 0; ð61Þ
d2u
dx2
ð1=2Þ ¼ c: ð62Þ
Here, e and c are positive constants that represent the elasticity parameter and a boundary stress, respectively.
For such physical problems, the traditional approach of monotonicity analysis is no longer applicable in
deciding whether monotonicity of equations exists. So the approximate function test method suggested in
the paper is used to derive its residual relation as follows:
Rð~uÞ ¼ ~uð4Þ þ e~u0~uð5Þ ¼ d~uð4Þ þ eð~u0duð5Þ þ ~uð5Þdu0Þ; x 2 ð1=2; 1=2Þ: ð63Þ
And further suppose the test function with all boundary conditions equal to zero to be
duðxÞ ¼ 1
32
ð1 2xÞ2ð1þ 2xÞ3. By putting it into Relation (63), a residual relation will be generated to satisfy
monotonic increasing conditions, namely,
Fig. 4. Maximum possible error of approximate solutions for Example 5.
x
u(
x)
-0.5 -0.25 0 0.25 0.50
0.005
0.01
0.015
0.02
0.025
0.03
0.035
0.04
0.045
0.05
R(x)=0, exact solution
R(x)<0, lower solutions
R(x)>0, upper solutions
R(x)>0, upper solutions
R(x)<0 ,lower solutions
R=-1,-0.5,0,0.5,1
Fig. 5. Upper and lower approximate solutions for Example 6 when e = 0.1 and c = 1.
C.-C. Wang, H.-P. Hu /Applied Mathematics and Computation 202 (2008) 383–394 393
