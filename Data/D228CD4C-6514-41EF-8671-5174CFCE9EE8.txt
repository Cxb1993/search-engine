 1z−
[ ]1y n+[ ]u n
[ ]y n
 
 
ΔT 
ΔT
 
 
 
 
Fig. 2. Proposed general structure controller. 
START 
Initialize parent 
Generate offspring   
by mutation 
Evaluate fitness 
 Accept     
offspring? 
Replace parent 
Decrease Tk
1/5 successful rule 
END 
Yes
No
Yes
No
 Stop the   
algorithm? 
Fig. 3. Flowchart of the proposed learning algorithm.
and learning algorithm of ES-based control system are 
introduced. In section III, simulation examples of both 
linear and nonlinear plants are provided to demonstrate 
the performance of the proposed learning control system. 
The conclusion is presented in section IV. 
II. ES-BASED LEARNING CONTROL SYSTEM WITH GS 
The proposed learning control system adopts the GS 
as the controller which would adapt itself to the plant by 
the evolution strategies shown as Fig. 1. Both the struc-
ture and learning algorithm of the ES-based learning 
control system with GS would be introduced in the fol-
lowing subsections. 
A. Structure of Learning Control System with GS 
A general structure (GS) proposed in this study is 
used to model the discrete-time controller and similar to 
the neural networks. The GS is specified by four basic 
entities: processing elements (PEs), connections, sam-
pling time, and evolution strategies (ES) as shown in Fig. 
2. The processing elements used in this study are the 
summation and production which would result in linear 
and nonlinear combination of the inputs respectively. 
The GS is a multilayer feedforward network with an 
output delay feedback and each layer consists of nu-
merous PEs and a bias element. The PEs receive infor-
mation from the previous layer and generate output data 
through the weights to next layer. Since the GS is a dis-
crete-time model, the differential equation is converted 
to a difference equation. While the nth order differential 
equation is converted, the sampling time ΔT would be 
produced during the process. Therefore, in order to adapt 
system with different sampling time, the ΔT is consid-
ered as the bias element in the GS. The GS could be 
further expressed in terms of G(i, h(m,n), o(p,q)) where i 
is the number of inputs, h(m,n) represents the hidden 
layer contains m summation nodes and n production 
nodes and o(.) represents the output layer contains p 
summation nodes and q production nodes. 
B. ES-Based Learning Control 
The proposed ES-based learning algorithm for the GS 
controller is constructed by integrating evolution strate-
gies, 1/5 success rule, and simulated annealing shown as 
Fig. 3. Once the number of the PEs and the connection 
type are confirmed manually, the remained job of de-
signing the GS is to set the weights. In order to develop a 
systematical design approach for the GS, the learning 
algorithms are considered, such as back-propagation 
method and ES. Although the GS is similar to the neural 
networks, it could not directly employ the 
back-propagation learning algorithm to updating the 
weights for a plant of unknown model. Instead, it adopts 
the ES, which doesn’t require any gradient information 
and prior knowledge of the plant and is apposite for 
problems that derivation information is not available. In 
the following subsections, the procedure of proposed 
learning algorithm would be illustrated step by step. 
1) Fitness function: Usually, the ES is adopted to 
solve the optimization of multidimensional real-valued 
population is set to 1 per generation. The ES was run 
with 1,000 generations. The mutation step sizes of the 
weights in GS are randomly initialized by the Gaussian 
distribution N(0,1). In order to compute the probability ps 
for 1/5 success rule, the ps would be estimated from 20 
trials. The parameter c in 1/5 success rule is in the range 
 according to the suggestion of [23] and set 
to 0.817 in this study. In the selection policy, the decay 
rate for the T
0 817 1. c≤ ≤
k in SA is set as 
 
  (3-2) (1 0 95 kkT . T+ = ⋅ )k
 
The learning control system was simulated with several 
runs. Each run consists of 1,000 generations. 
 
After 5 runs with both linear and nonlinear GS con-
troller, the output responses of the system with G(2, 
h(4,0), o(1,0)) and G(2, h(2,2), o(0,1)) are shown as Fig. 
4(a). and 4(b). respectively. Although some of the re-
sponses have smaller oscillatory properties, most of them 
could achieve the goal fast and have smaller steady state 
error. Furthermore, the nonlinear GS could achieve 
smaller overshoot and oscillatory property in steady state. 
The optimal output responses with both linear and 
nonlinear GS are almost the same in Fig. 5(a), however, 
the control energies obtained from Fig. 5(b). show the 
advantage of the linear GS controller, i.e., the control 
energy is smaller. 
For nonlinear case, a simple nonlinear system is 
adopted and its transfer function is 
 
 2y y y u= + +  (3-3) 
 
The settings of the simulation for nonlinear case are 
almost the same with the linear case, expect for the ap-
plied GS controllers. The nonlinear system will be con-
trolled by two GS controllers, G(2, h(4,0), o(1,0)) and 
G(2, h(2,2), o(1,0)) where the output node function is 
summation and different from the GS in linear case. 
Fig. 4. Control performance of second-order oscillatory 
system (a) linear GS (b) nonlinear GS. 
0 0.5 1 1.5 2 2.5 3 3.5 4 4.5 5
0
0.2
0.4
0.6
0.8
1
Time (sec)
O
ut
pu
t
0 0.5 1 1.5 2 2.5 3 3.5 4 4.5 5
0
0.2
0.4
0.6
0.8
1
1.2
1.4
1.6
1.8
Time (sec)
O
ut
pu
t
Fig. 5. (a) output response (b) control signal. 
 
0
0.2
.4
0.6
0.8
1
1.2
i
O
ut
pu
t
0
0.2
0.4
0.6
1
1.2
i
O
ut
pu
t
0 1 2 3 4 5
0
0.5
1
Time (sec)
O
ut
pu
t
0 1 2 3 4 5
-10
0
10
20
Time (sec)
C
on
tr
ol
 s
ig
na
l
0 1 2 3 4 5
0
5
1
1.5
Time (sec)
O
ut
pu
t
0 1 2 3 4 5
0
10
20
30
Time (sec)
C
on
tr
ol
 s
ig
na
l
1 2 3 4 5
0
0.5
1
1 5
Time (sec)
O
ut
pu
t
0 1 2 3 4
0
10
20
30
Time (sec)
C
on
tr
ol
 s
ig
na
l
0 1 2 3 4 5
0
0.5
1
Time (sec)
O
ut
pu
t
0 1 2 3 4 5
-5
0
5
10
Time (sec)
C
on
tr
ol
 s
ig
na
l
0 1 2 3 4 5
0
0.5
1
1.5
Time (sec)
O
ut
pu
t
0 1 2 3 4 5
0
10
20
Time (sec)
C
on
tr
ol
 s
ig
na
l
1 2 3 4 5
0
0.5
1
1.5
Time (sec)
O
ut
pu
t
0 1 2 3 4
0
10
20
Time (sec)
C
on
tr
ol
 s
ig
na
l
0 0.5 1 1.5 2 2.5 3 3.5 4 4.5 5
0
0.5
1
2
O
ut
pu
t
(a)
. . . . .
0
0.5
1
1.5
2
O
ut
pu
t
sec
(b)
0 0.5 1 1.5 2 2.5 3 3.5 4 4.5 5
0
0.5
1
1.5
2
O
ut
pu
t
(a)
-300
-20
-100
0
100
200
300
(b)
sec
C
on
tr
ol
 s
ig
na
l
Linear GS 
Nonlinear GS 
 
Fig. 6. Control performance of second-order oscillatory 
system (a) linear GS (b) nonlinear GS. 
0 0.5 1 1.5 2 2.5 3 3.5 4 4.5 5
0
0.2
0.4
0.6
0.8
1
Time (sec)
O
ut
pu
t
0 0.5 1 1.5 2 2.5 3 3.5 4 4.5 5
0
0.2
0.4
0.6
0.8
1
1.2
1.4
1.6
1.8
Time (sec)
O
ut
pu
t
Fig. 7. (a) output response (b) control signal. 
0
0.2
.4
0.6
0.8
1
1.2
i
O
ut
pu
t
0
0.2
0.4
0.6
1
1.2
i
O
ut
pu
t
0 1 2 3 4 5
0
0.5
1
Time (sec)
O
ut
pu
t
0 1 2 3 4 5
-10
0
10
20
Time (sec)
C
on
tr
ol
 s
ig
na
l
0 1 2 3 4 5
0
5
1
1.5
Time (sec)
O
ut
pu
t
0 1 2 3 4 5
0
10
20
30
Time (sec)
C
on
tr
ol
 s
ig
na
l
1 2 3 4 5
0
0.5
1
1 5
Time (sec)
O
ut
pu
t
0 1 2 3 4
0
10
20
30
Time (sec)
C
on
tr
ol
 s
ig
na
l
0 1 2 3 4 5
0
0.5
1
Time (sec)
O
ut
pu
t
0 1 2 3 4 5
-5
0
5
10
Time (sec)
C
on
tr
ol
 s
ig
na
l
0 1 2 3 4 5
0
0.5
1
1.5
Time (sec)
O
ut
pu
t
0 1 2 3 4 5
0
10
20
Time (sec)
C
on
tr
ol
 s
ig
na
l
1 2 3 4 5
0
0.5
1
1.5
Time (sec)
O
ut
pu
t
0 1 2 3 4
0
10
20
Time (sec)
C
on
tr
ol
 s
ig
na
l
0 0.5 1 1.5 2 2.5 3 3.5 4 4.5 5
0
0.5
1
2
O
ut
pu
t
(a)
. . . . .
0
0.5
1
1.5
2
O
ut
pu
t
sec
(b)
O
ut
pu
t
O
ut
pu
t
0 0.5 1 1.5 2 2.5 3 3.5 4 4.5 5
0
0.5
1
1.5
2
O
ut
pu
t
(a)
0 0.5 1 1.5 2 2.5 3 3.5 4 4.5 5
-1
0
10
20
(b)
sec
C
on
tr
ol
 s
ig
na
l
Nonlinear GS 
Linear GS 
Similarly, after 5 runs with both linear and nonlinear 
GS controller, the output responses of the nonlinear 
system with G(2, h(4,0), o(1,0)) and G(2, h(2,2), o(1,0)) 
are shown as Fig. 6(a). and 6(b). respectively. Most of 
the output responses with linear GS have smaller steady 
state errors and achieve the goal fast. However, with the 
nonlinear GS, one of the output responses has large 
eyeBot II. The eyeBot I used the RC servo motors as the 
actuator and eyeBot II adopted the DC servo motors 
2224U012SR to execute the motion. The control and 
image process were both implemented in personal 
computer with 1.5 GHz CPU where control command 
was transmitted by RS232 and image signal was received 
through USB shown as Fig. 14. 
  
 
Fig. 13. (a) Robot designed with CAD (b) eyeBot I (c) 
eyeBot II. 
 
Fig. 14. Hardware structure. 
 This project would first focus on tracking skin 
color-like target. The recognition of skin color is im-
plemented as (4-1) 
( )
( )
( ) ( )
( ) ( )
2
1
2
2
2 2
1 2
1 3767 1 0743 0 1452
0 766 0 5601 0 1766
0 33 0 33
1 if ( < ) & ( ) & ( 0 00004) & ( )
0 otherwise
n n
n n n
n n n
n n
n n n n
. . .
. . .
. .
, .
,
R GR G
R G B R G B
f R R R
f R R R
w R G
G f R G f R w R G B
S
= =+ + + +
= − + +
= − + +
= − + −
⎧ > > >= ⎨⎩
>
(4-1) 
where R, G, and B means the grey level value matrix of 
red, green, and blue respectively. After the recognition, 
the position of gravity could be determined by (4-2) 
shown as: 
( )
( )
1
1
n
x
n
x
xf x
m
f x
=
=
=
∑
∑
       (4-2) 
where n means the length of image frame and m is 
the position of gravity in x-axis. This method could be 
applied to calculate the position in y-axis. The result is 
shown as Fig. 15.  
While these positions were determined by above 
procedure, the controller could control the robot to track 
the target via these feedback positions of target. The 
tracking result is shown as Fig. 16. where the height and 
length of image frame are 240 and 320 respectively. 
Furthermore, the dynamic performance of tracking has 
been recorded as the movie shown as [24]. However, 
there were some drawbacks of the skin color recognition 
and control performance. When the target moved fast, 
the recognition would fail due to the incomplete target 
image. Moreover, as there were two more targets, the 
recognition was not available since it could not distin-
guish how many objects in image frame. On the other 
hand, the controller was sometimes not reliable such that 
the robot would have unexpected behavior. In addition, 
the robot could not act as smoothly as human being, 
because the RCB-1 controller could not provide con-
tinuous variation of speed for RC servo motor. Therefore, 
this project would adopt the DC servo motor in eyeBot II 
shown as Fig. 13(c) in 2nd year. 
 
Webcam 
Motors RCB-1 
 
PC 
 
Robot 
USB 
COM Fig. 15. Skin color recognition. 
 
Fig. 16. Tracking performance. 
V. CONCLUSION 
The proposed learning control system adopts the GS 
as the controller which would adapt itself to the plant by 
the evolution strategies. The learning algorithm is con-
structed by integrating evolution strategies, 1/5 success 
rule, and simulated annealing. Most of the simulation 
results show the ability of learning algorithm which 
adapts the GS controller to unknown system. Either 
linear  or nonlinear GS could control both linear and 
nonlinear system well through evolution processes. 
However, the well-trained GS controller could not face 
the large steady state error problem when adopting in 
different sampling time system. It is worth to study and 
improve the GS to solve the problem. In addition, the 
human-like eye movement robot (eyeBot) was con-
structed with 5 degrees including eyeballs and neck. The 
developed image process and control of eyeBot have 
行政院國家科學委員會補助專題研究計畫■ 成 果 報 告      □期中進度報告 
 
仿人類眼球系統之動態影像偵測及辨識技術之開發(I) 
 
計畫類別：■ 個別型計畫  □ 整合型計畫 
計畫編號：NSC 95-2221-E-009-098- 
執行期間：   2006年08月01日至 2007年07月31日 
 
計畫主持人：陳永平 
共同主持人： 
計畫參與人員：  
 
 
成果報告類型(依經費核定清單規定繳交)：■精簡報告  □完整報告 
 
本成果報告包括以下應繳交之附件： 
□赴國外出差或研習心得報告一份 
□赴大陸地區出差或研習心得報告一份 
□出席國際學術會議心得報告及發表之論文各一份 
□國際合作研究計畫國外研究報告書一份 
 
 
處理方式：除產學合作研究計畫、提升產業技術及人才培育研究計畫、
列管計畫及下列情形者外，得立即公開查詢 
          □涉及專利或其他智慧財產權，□一年□二年後可公開查詢 
          
執行單位： 
 
中   華   民   國   96年   11月    13日 
