II 
 
摘要 
數位浮水印是一種用來保護數位資料智慧財產權的技術，作者可產生一段代表自身所
有權的訊息，藏入受保護的影像中，當有疑似盜版的情事發生時，便從受保護影像中取出
浮水印，以驗證作者的所有權。然而數位浮水印應用在共同著作權的保護時，可能會面臨
一些問題，亦即在藏入多名作者的浮水印至受保護影像中時，可能會互相破壞彼此的浮水
印。因此本研究計劃結合視覺密碼方法，提出一套應用於數位影像的共同著作權保護機
制，可以改善傳統數位浮水印的問題。 
 
關鍵詞：智慧財產權保護、離散餘弦轉換、共同著作權、數位浮水印、視覺密碼 
 
Abstract 
Digital watermarking is a technique for protecting intellectual property of digital information. A 
signature, called a watermark, is embedded into a protected image. When piracy happens, the 
author can extract the watermark to prove his ownership. However, when a work is created by 
multiple authors, digital watermarking may suffer some problems. When embedding multiple 
watermarks into the protected image, it is highly probable that the latter watermark will 
compromise the former one. In this research, we integrate visual cryptography to propose a joint 
ownership protection scheme to improve the drawbacks of digital watermarking. 
 
Keywords: intellectual property protection, discrete cosine transform, joint ownership, digital 
watermarking, visual cryptography 
1 
 
一、研究背景與目的 
自從進入數位化時代後，許多傳統的類比資訊紛紛被數位化，以便達到容易保存的目
的，而網際網路的發達，更促進了數位化資訊的流通與取得，在網際網路上流通的數位資
訊尤其以多媒體資訊為大宗。然而，由於數位化資訊具有容易被複製和散播的特性，使得
多媒體數位資訊的著作權保護變得更加困難，因此多媒體數位資訊的著作權保護是一項重
要的議題，而近年來亦有許多相關的研究陸續被提出。數位浮水印(digital watermarking)
便是一種保護智慧財產權的技術，可以應用在聲音、影像、視訊等各種類型的數位資料上。
以數位影像為例，作者可在數位影像中藏入一個稱為浮水印(Watermark)的資訊，當有疑似
侵害著作權的事件發生時，作者便可以從影像中取出浮水印，以驗證其所有權。通常我們
稱原始的影像為主影像 (Host image)，藏入浮水印後的影像則稱為被浮水印影像
(Watermarked image)，而浮水印本身可以是一段無意義的訊號，亦可為一張有意義的影像。 
Chang 等人(2002)提出一種有別於數位浮水印的著作權保護方法，他們利用視覺密碼
(visual cryptography)和離散餘弦轉換(discrete cosine transform, DCT)的技術，設計了以彩色
浮水印來保護彩色影像所有權的機制。實體上浮水印並未真正藏入受保護的影像中，而是
藉由產生 ownership share 來「虛擬地」藏入浮水印。Chang 等人的方法為共同著作權的驗
證，提出了一種可行的解決辦法，如果受保護的影像是由多名作者共同創作者，各作者分
別產生代表自身著作權浮水印，這些浮水印便可利用 Chang 等人的方法，一一「虛擬地」
藏入受保護的影像中；亦即，針對不同的浮水印分別產生各作者的 ownership share，任何
一名作者只要利用他所持有的 ownership share，便可顯示出自己的浮水印，進而驗證其著
作權。除了 Change 等人外，尚有其它研究提出相同概念的方法(Chang and Chuang 2002, 
Chang et al. 2002, Chang et al. 2000, Hwang 2000, Tu and Hsu 2004, Lou et al. 2007, Wang and 
Chen 2009)，而這些方法的差異，主要在於產生 master share 的方法的不同。除了 Chang
等人(2002)所提的方法外，其它方法皆為黑白浮水印，然而， Chang 等人的方法使用的浮
水印是 4 色影像，且在產生 ownership share 前，仍須依照事先定義好的型態，將彩色的浮
水印轉換成黑白的影像，同時也由於這道轉換的步驟，當浮水印的顏色愈多時，浮水印的
大小便受到極大的限制。 
上述所提的方法應用在共同著作權的保護時，會將每位作者視為同等重要，然而我們
知道，在多人共同創作的情況下，有可能每位作者的貢獻程度不完全相等，如果一個著作
權保護機制將所有作者的重要性皆相同看待，便無法反映出貢獻程度不一致的事實。因
此，在共同著作權保護機制的研究中，應將此一因素納入考慮。為了與將浮水印實體上藏
入受保護影像的方法有所區別，本研究將以 ownership statement 這個名詞代替「浮水印」
(watermark)這個名詞，但是其意義與浮水印相同，同樣是指代表作者自身所有權的標誌。
本研究計畫分兩年提出一套完整的共同著作權保護機制，在第一年的計畫中，本研究結合
離散餘弦轉換(discrete cosine transform, DCT)的技術，設計出一個可改善(Chang et al. 2000; 
Change et al., 2002, Hwang 2000; Chang and Chuang 2002; Tu and Hsu 2004)缺點的演算法，
本研究所設計之演算法可以黑白影像、灰階影像或彩色影像做為 ownership statement，且
ownership statement 的尺寸大小不會受限於受保護影像。在第二年的計畫中，本研究以第
一年的研究結果為基礎，並進一步結合視覺密碼的機制，使得本研究所提出的方法可以依
3 
 
要加密的機密影像像素是白點，並且隨機選取了第一項白點加密規則，則在分享影像 1 上
依序填入一黑點一白點，在分享影像 2 上依序填入一黑點一白點，當兩張分享影像疊合時
便會呈現一黑點一白點；假設要加密的機密影像像素為黑點，並且隨機選取了第二項黑點
加密規則，則在分享影像 1 上依序填入一白點一黑點，在分享影像 2 上依序填入一黑點一
白點，當兩張分享影像疊合時便會呈現兩個連續的黑點。圖 2(b)和圖 2(c)便是依照表 1 的
加密規則所分解出的兩張分享影像，從任何單一張分享影像上是無法看出有關機密影像的
訊息，當兩張分享影像疊合時，人眼便可從重疊影像(圖 2(d))上辨識出原機密影像(圖
2(a))。就安全性而言，機密影像上的像素不論是黑點或白點，在分享影像上皆被加密成一
白點和一黑點，因此無法由單一張分享影像上去猜測出原始機密影像的訊息；當兩張分享
影像疊合後，原機密影像的白點在重疊影像上會變成一白點和一黑點，而原機密影像的黑
點則是變成兩個黑點，由於在重疊影像上代表白點與黑點的像素有對比上的差異，因此人
眼便可以由重疊影像中辨識出原來的機密訊息。 
Ateniese 等人(1996)將門檻式的使用結構加以擴充為Γ=(P, F, Q)的形式，稱之為任意
使用結構(general access structure)。令 P = {1, 2, …, n}代表參與秘密分享的人(participants)
的集合，2P 代表 P 的冪集(power set)，也就是 P 的全體子集合的集合，F, Q 是 2P 的子集合，
分別代表禁止集合的集合(forbidden sets)與合格集合的集合(qualified sets)，而且 Q ∩ F  
= ∅。任何一個合格集合 Y ∈ Q 都可以還原機密影像，而任何一個禁止集合 X ∈ F 都
無法獲得一絲機密訊息。所謂的「使用結構」是指定義如何分享機密的一種規則，而(k, 
n)-threshold 便是屬於任意使用結構的一種特例。例如(2, 2)-threshold 可以表示成下列的使
用結構：Γ = (P ={1, 2}，F ={{1},{2}}，Q ={{1, 2}})。實現使用結構的視覺式秘密分享
機制，可以用兩個代表黑點與白點的 n×m 基礎矩陣來表示，方程式(1)便是可實作出(2, 
2)-threshold 使用結構的基礎矩陣： 
 
 
01
01
0 ⎥⎦
⎤⎢⎣
⎡=M
，
⎥⎦
⎤⎢⎣
⎡=
10
01
1M
 (1) 
其中 M0 (resp. M1)代表白(resp. 黑)點的基礎矩陣，矩陣中的‘1’代表黑色，‘0’代表白色。當
要加密的像素為白((resp. 黑)點時，便將 M0 ((resp. M1)做欄向量隨機重排，將重排後的矩
陣第一列的顏色填入分享影像 1，第二列的顏色填入分享影像 2，因此 m 即代表像素擴展
的倍數，亦即傳統的視覺式秘密分享機制會使還原影像擴展成原始影像的 m 倍。 
基礎矩陣的設計必須滿足視覺式秘密分享的對比條件和安全條件，令 C0 和 C1 分別代
表將基礎矩陣 M0 和 M1 做欄向量隨機重排後的所有 n × m 布林矩陣的集合，假如存在一個
值α(m)與一個門檻值集合{(X, tx)}X∈Q，則 C0 和 C1 構成一個視覺密碼方法必須滿足下列條
件(Ateniese et al. 1996)： 
(1) 任何一個合格集合 X = {i1, i2, …, ip} ∈ Q 可以藉由疊合對應於集合中的所有分享影像來
還原機密影像。也就是說，將任何一個矩陣 M ∈ C0 的第 i1, i2, …, ip列做 OR 運算所得到
的 m-向量 V，必須滿足 w(V) ≤ tX − α(m)⋅m；然而，將任何一個矩陣 M∈C１的第 i1, i2, …, 
ip 列做 OR 運算所得到的 m-向量 V，必須滿足 w(V) ≥ tX。 
(2) 任何一個禁止集合 X = {i1, i2, …, ip} ∈F 無法獲得機密影像中的任何機密訊息。也就是
說，將 Ct (t ∈ {0, 1})中所有的 n × m 矩陣限制在第 i1, i2, …, ip 列所得到的 p × m 矩陣的
集合 Dt，則在 D0 與 D1 中相同的矩陣會有相同的出現次數，因此 D0與 D1 是無法區分的
(indistinguishable)。 
5 
 
決定。事實上，在浮水印的研究中，判斷取出的浮水印與原始浮水印是否相似，除了利用
客觀的衡量指標外，人眼的主觀判斷，也是重要且常用的依據。因此，若以有意義的影像
做為浮水印，便可藉由人眼的主觀判斷，來輔助量化指標的不足之處。 
三、本研究方法 
本研究的原始影像是一張灰階影像，而浮水印則是一張黑白影像。我們會利用 DCT 從
原始影像中，抽取出原始影像的特徵，之後，我們會根據原始的影像的共同著作者不同的
所有權驗證的權利，利用視覺式秘密分享機制，配合原始影像的特徵，將 ownership statement
分解成若干張分享影像，分別交由每位作者各別持有一份。由於 ownership statement 是配
合原始影像的特徵值進行分解，因此可視為 ownership statement 被虛擬地藏入原始影像中。
本研究的方法分成兩個階段，一為所有權註冊階段，另一為所有權驗證階段。在所有權註
冊階段中，我們會根據不同作者的重要性以及代表受保護影像特徵的 feature map，利用視
覺式秘密分享機制來分解 ownership statement，每位作者各持有一份分解後的影像，我們將
分解後的影像稱為分享影像；在所有權驗證階段中，具有驗證所有權權限的作者，便可透
過手中所持有的分享影像，配合受保護影像的 feature map，還原 ownership statement 以驗
證所有權。 
3.1 所有權註冊階段 
假設共同著作者共有 n 位，首先我們定義一個使用結構Γ = (P, F, Q)，來表示這 n 位
作者不同的所有權驗證權利，其中P = {1,2,…,n}代表所有作者的集合。令2P代表P的Power 
Set，F 和 Q 則是 2P 的子集合，分別代表禁止集合的集合與合格集合的集合，也就是 F 和
Q 中每個元素皆為一個集合，且 F 和 Q 必須滿足如下的所有權驗證條件： 
1. 任何一個合格集合 Y∈Q，Y 中所有的作者皆可藉由手中持有的分享影像與 feature map
顯示出 ownership statement。 
2. 任何一個禁止集合 X∈F，X 中所有的作者無法由手中持有的分享影像顯示出浮水印，
亦無法由手中持有的影像加上 feature map 顯示出 ownership statement。 
為了能完整表達上述的兩項條件，我們令 a0 代表一個虛擬的作者，並且重新定義另一個
使用結構Γ′=(P′, F′, Q′)，其中 P′ = {a0 , a1, a2, …, an}，代表所有作者加上虛擬作者 a0 的集
合，Q′ = {X∪{ a0}︱X∈Q }，F′ = F∪{Y∪{ a0}︱Y∈F }，而受保護影像的 feature map 便
是虛擬作者 f 手中所持有的分享影像。也就是說，合格集合的作者群可配合 Feature Map
顯示 ownership statement，禁止集合的作者群即使配合 Feature Map，亦無法顯示 ownership 
statement。 
為了要能取得受保護影像的特徵值，我們會將受保護影像切割成大小為 4 × 4 的區
塊，並利用 DCT 將每個影像區塊轉換成 DCT 區塊。接著，我們選擇一個可以實現Γ′的
視覺式秘密分享機制，亦即兩個分別代表白點與黑點的(n+1) ×m 布林矩陣 M0 和 M1，在
M0 和 M1 符合 VSSS 安全性條件下，兩個矩陣同一列的｀1＇的個數皆相等。令 b 代表 M0
或 M1 第一列的｀1＇的個數。對於 ownership statement 的任何一個像素 p，我們利用一虛
擬亂數產生器，從受保護影像的DCT區塊中，隨機抽取m個區塊的DC係數，令(d1,d2,…,dm)
代表這 m 個 DC 係數的序列；接著，我們將序列中前 b 個較大的值設為‘1’，其它的值設
為‘0’，因此我們可以得到一個長度為 m 的位元串 s。根據位元串 s，我們以下列的方式將
7 
 
M0 和 M1，我們令 b 代表 M0 或 M1第一列的｀1＇的個數。我們使用虛擬亂數產生器隨機
抽取 m 個 DCT 區塊的 DC 係數，並將這 m 個 DC 係數較大的 b 個設為‘1’，其它設為‘0’，
產生一個長度為 m 的位元串。若原始 ownership statement 大小為 I × J，則重複上述的程序
I × J 次，便可產生一張大小為 I × (J × m)的 feature map。要注意的是，在隨機抽取的過程
中，虛擬亂數產生器所使用的 Seed，必須為所有權註冊階段所使用的 Seed 相同。產生了
feature map 後，便與擁有所有權驗證權利的作者所持有的影像疊合，而所謂的疊合，即指
將 feature map 與分享影像做 bit-wise OR，若能顯示 ownership statement 的圖案，便可驗證
所有權。 
 
四、實驗結果與討論 
在此節中，本研究將實作兩種情況，為說明起見，我們將第一種情況以“case 1”代表，
第二種情況以“case 2”代表。Case 1 是所有作者共同分享所有權驗證的權利，即 n 位作者必
須共同配合 feature map 來驗證所有權，小於 n 位作者便無法驗證所有權，此處我們以 n = 2
為例，亦即 3.2 節中 2 位作者的例子；case 2 則是有部份的作者可驗證所有權，而有部份作
者無法驗證所有權，在此我們以 P′ = {a0, a1, a2, a3}，F′ = {{a0 }, {a1}, {a2}, {a3},{a0, a1}, {a0, 
a2},{a0, a3},{a0, a1, a3}}，以及 Q′ = {{a0, a1, a2}, { a0, a2, a3}, { a0, a1, a2, a3}}為例，亦即作者
1 和作者 2 可共同配合 feature map 驗證所有權，或是三個作者一起共同配合 feature map 驗
證所有權，而其它作者的組合則不具驗證所有權的權利，可實作此 access structure 的基礎
矩陣如下： 
 
.
0110
1010
0110
0011
 ,
0110
0101
0110
0011
10
⎥⎥
⎥⎥
⎦
⎤
⎢⎢
⎢⎢
⎣
⎡
=
⎥⎥
⎥⎥
⎦
⎤
⎢⎢
⎢⎢
⎣
⎡
= MM
 (3) 
圖 2(a)為本實驗所使用的原始影像，大小為 512 × 512，圖 2(b)則為 case 1 的 ownership 
statement，大小為 100 × 100，圖 2(c)則為 case 2 的 ownership statement，大小為 100 × 100，
圖 3 則為本研究所模擬的各種攻擊結果，本研究以 Photoshop version 7 作為模擬各種攻擊
之工具，本研究所模擬的各種攻擊及其設定參數如表 1 所示。圖 4 為圖 2(b)利用公式(2)
加密與解密的結果，圖 6 則為圖 2(c)利用公式(3)加密與解密的結果。本研究採用
PSNR(Peak-Signal-to-Noise Ratio)做為衡量各種攻擊強度的指標，公式如下： 
 )255(log10 210 MSEPSNR =  (4) 
where 
 
2
1
,,
1
)(1 ∑∑
=
−
=
′×=
N
j
jiji
M
i
pp
NM
MSE  (5) 
PSNR 的單位為 dB，當所算出的 PSNR 之值愈小，表示受攻擊影像與原始影像間的相
似度愈低。另外，本研究採用 NC（Normalized Correlation）做為衡量取出的浮水印與原浮
9 
 
  
(a) Lightening (PSNR = 18.59) (b) Darkening (PSNR = 18.59) (c) Blurring (PSNR = 36.82) 
  
(d) Sharpening (PSNR = 28.86) (e) Noising (PSNR = 24.44) (f) Distortion (PSNR = 28.98) 
 
 
(g) Jpeg (PSNR = 39.43) (h) Cropping (PSNR = 15.58)  
圖 3 圖 2(a)的各種攻擊結果 
 
   
(a) Share 1 (b) Share 2 (c) The stacked result
圖 4 圖 2(b)的加密與解密結果 
    
(a) NC = 100.0 (b) NC = 100.0 (c) NC = 99.78 (d) NC = 99.4
    
(e) NC = 99.03 (f) NC = 99.1 (g) NC = 99.79 (h) NC =97.48
圖 5 從圖 3 的各種攻擊結果取出的 ownership statement (case 1) 
11 
 
 
五、結論 
本研究結合視覺式秘密分享機制，設計一個應用於數位影像的共同著作權保護機制。
當一張數位影像是由多位作者共同創作時，由於每位作者的貢獻度可能不同，因此對於每
位作者可驗證影像所有權的權利應有所不同，也就是說，有部份的作者可被賦予驗證所有
權的權利，有部份作者則由於貢獻度不高，則不給予驗證所有權的權利。傳統多浮水印的
方法，受保護影像在藏入多張浮水印後，可能會有影像品質不佳的問題，因此本研究將一
張代表 ownership statement 的影像，依各作者所有權驗證的規則，利用視覺式秘密分享機
制，將 ownership statement 配合受保護影像的特徵值，分解成多張分解影像，每位作者持
有一張分解影像，可驗證所有權的作者群，便可以手中的分解影像，配合待驗證影像的特
徵值，來顯現 ownership statement 以驗證所有權；反之，無驗證所有權權利的作者群，即
使有受保護影像的持徵值，亦則無法以手中持有的分解影像來驗證所有權。由第四節的實
驗結果亦可看出，本研究所設計的機制的確可成功達到共同著作權保護的目的，同時由於
視覺式秘密分享機制具有易實作與安全的優點，本研究的方法亦繼承了視覺式秘密分享機
制的這兩項優點。另外，由實驗結果的 NC 值亦可看出，本研究的方法對於一些常見的影
像攻擊，是有不錯的強靭性的。綜合言之，本研究所設計之機制不但容易實作，同時也兼
具安全性與強靭性的優點。 
六、參考文獻 
[1] Chang, C.C., Hwang, K.F., and Lin, Y. (2000) A proof of copyright ownership using 
moment-preserving. The 24th Annual International Computer Software and Application 
Conference (COMPSAC 2000), Taipei, Taiwan, 25-28 October 2000, pp. 198-203. 
[2] Chang, C.C. and Chuang, J.C. (2002) An image intellectual property protection scheme for 
gray-level images using visual secret sharing strategy. Pattern Recognition Letters 23, pp. 
931-941. 
[3] Chang, C.C., Hsiao, J.Y., and Yeh, J.C. (2002) A colour image copyright protection scheme 
based on visual cryptography and discrete cosine transform. Imaging Science Journal, 50, pp. 
133-140. 
[4] Hwang, R.J. (2000) A digital image copyright protection scheme based on visual 
cryptography. Tamkang Journal of Science and Engineering, 3(2), pp. 97-106. 
[5] Lou, D.C., Tso, H.K., and Liu, J.L. (2007) A copyright protection scheme for digital images 
using visual cryptography technique, Computer Standards & Interfaces, 29, pp.125–131 
13 
 
[22] 林憲章(2008)，以視覺式秘密分享為基礎之共同著作權保護機制，中國文化大學資訊管
理研究所碩士論文。 
[23] Tu, S. F. and Hsu, C. S. (2007, 7, 2−4). A VC-Based Copyright Protection Scheme for 
Digital Images of Multi-Authorship. Proceedings of the World Congress on Engineering 
2007 (WCE 2007), London, UK, Vol. 1, 685−689. (Best Paper Award) 
七、計畫成果自評 
在原本的計畫書中的研究目標，規劃一套共同著作權保護的可行方案，可依作者的重
要性賦予不同的所有權驗證的權限，即是要以一張有意義的黑白影像做為 ownership 
statement，同時利用視覺式秘密分享的技術，將 ownership statement 分解成 n 張分享影像，
不具有驗證所有權權限的作者，無法利用手中所持有的分享影像來還原 ownership 
statement，而只要是具有驗證所有權權限的作者，便可利用所持有的分享影像，與受保護
影像的 feature map 疊合，疊合影像便會呈現 ownership statement 的圖案。由第四節的實驗
結果可看出，本研究的確與原預期目標相符。另外，本研究之計畫內容已整理成期刊論文
投稿，目前正在接受審查中。 
 
 
2 
 
有監視器侵犯隱私的疑慮。台灣目前已慢慢走向高齡社會，老人的居家照護相信是未
來一個很重要的議題，而資訊科技在這方面該如何發揮功能，相信是資訊相關領域的
學者一個值得努力的方向。回國後，我也在參閱了一些普及運算的論文，發現這個領
域不只限於老人照護，亦有些論文是有關於特殊兒童的輔助，譬如自閉症或發展遲緩
的兒童，我認為這方面的研究是非常具有實用價值的，也能帶給特殊兒童一些實質的
幫忙。目前特殊兒童多半必須由父母帶去醫院接受職能治療，讓小朋友接受一些訓練
課程，如果能利用資訊科技，讓某些訓練課程可在家進行，相信可以省卻小朋友的父
母許多時間，因此未來我希望能朝向這方面的研究。 
這之會議舉行的地點在澳洲的昆士蘭大學，該大學在整個澳洲大學的排名來講，
應可算是前三名的大學，在當地看到許多來自日本、韓國、中國的留學生，當然也有
不少的台灣學生。參與會議的學者也十分樂意與其它學者交流，在我上台簡報完我們
所發表的論文後，便有學者主動前來表示對我們的論文很有興趣，想向我們詢問論文
的相關細節。 
在此特別感謝行政院國家科學委員會提供經費補助，使本人得以順利參加於澳洲
布里斯本舉辦的 Permedia2009 學術研討會。 
forbidden set cannot gain any information about the 
secret. For example, in a k-out-of-n , or (k, n)-
threshold, VSS scheme, the secret is visible only when 
at least k or more shares are stacked together. Hence 
VSS scheme is suitable for group secret sharing 
without the help of a computer. 
Table 1 illustrates an (2, 2)-threshold VSS scheme. 
Each pixel of the secret image is encoded separately. 
Both white and black pixels have two encryption rules, 
which specify how a secret pixel is encrypted into two 
subpixels on share 1 and share 2. Hence each pixel on 
the secret image is recovered by two subpixels on the 
stacked image. When a white (black) pixel is to be 
encoded, one of the two corresponding encryption 
rules is selected randomly. Obviously, the size of the 
recovered image is two times that of the secret image. 
To encode a gray-level or chromatic secret image, Hou 
[6] incorporated the halftoning technique and CMY 
color model to preprocess the secret image, so that the 
traditional VSS scheme can be applicable to non-
binary image easily. 
Table 1.  (2, 2)-threshold visual secret sharing scheme. 
Secret 
pixel 
Share 
1 
Share 
2 
The stacking 
result 
       
       
 
Some researchers tried to employ the concept of 
probability to solve that problem [7-10]. However, 
with instinctive nature of randomness, their methods 
can decrease the image quality of the recovered 
images. Therefore, the MPEM are proposed to cope 
with the problem of randomness. Now we describe the 
(2, 2)-threshold scheme of MPEM briefly. In the 
scheme, each time two successive pixels of the secret 
image, called an encryption sequence, are encoded. 
For a black-and-white image, there are four types of 
an encryption sequence, namely (b, b), (w, w), (b, w), 
and (w, b), where ‘b’ denotes black, and ‘w’ denotes 
white. The encryption rules of encryption sequences of 
a (b, b) and (w, w) are shown in Table 2. 
Table 2.  A part of (2, 2)-threshold scheme of the MPEM. 
Secret 
pixel 
Share 
1 
Share 
2 
The stacking 
result 
       
       
 
For the other two types of the encryption sequence, 
the following decision rule is used to decide which 
encryption rule should be used: 
if  x mod 2 = 0  then 
Randomly use one of the encryption rules of the (b, b) 
type 
else  
Randomly use one of the encryption rules of the (w, w) 
type, 
 
where x denotes the number of the encryption 
sequences of these two types that have been encoded 
until now. That is, the encryption sequences of the (b, 
w) and (w, b) types are encoded by the encryption 
rules of the (b, b) and (w, w) types in rotation. The 
security and contrast of the MPEM can be assured by 
the visual cryptography.  
Fig. 1 is the experimental result of the (2, 2)-
threshold scheme of the MPEM. Fig. 1(a), which is 
also the watermark used in section 4, is split into two 
shares (Fig. 1(b) and 1(c)) and is recovered when the 
two shares are stacked as shown in Fig. 1(d). Note that 
the “stacking” action is simulated by the logic OR 
operation. 
 
3. The Proposed scheme 
 
The proposed scheme composes of two phases: the 
watermark embedding and watermark extraction. 
During the watermark embedding phase, a 2-level 
    
(a) Watermark (b) Master share (c) Ownership share (d) Stacked result 
Fig. 1. The binary watermark and its corresponding shares and stacked result (128 × 128 pixels). 
363
If the coefficient c′ modulo R is greater than a half 
of R, the recovered pixel p′ of the master share is black; 
otherwise, it is white. By doing so, we can extract the 
embedded share and combine with the owner’s share 
to reveal the watermark. Note that R must be the same 
as we used in the watermark embedding phase. 
 
4. Experimental results 
 
In the experiment, we use PSNR (Peak Signal to 
Noise Ratios) to measure the quality of the 
watermarked image. The PSNR is computed as 
follows. 
)255(log20 10 MSEPSNR = , (1) 
where  
2
1
,,
1
)(1 ∑∑
=
−
=
′
×
=
N
j
jiji
M
i
pp
NM
MSE
. 
(2) 
 
In Eq.(2), pi,j is the pixel of the host image, and p′i,j 
is that of the watermarked image. The larger the 
PSNR is, the more similar the watermarked image is 
to the host image. Generally speaking, human eyes 
cannot perceive the difference if PSNR is greater than 
30. Fig. 4(a) is the host image, and Fig. 4(b) is the 
watermarked image. The PSNR of the watermarked 
image is 41.66, which means that human eyes almost 
cannot perceive the difference between it and the 
original image.  
We simulate JPEG attack of various quality factors 
using Adobe Photoshop version 7. The extracted 
watermark is measured by the measurement NC 
(normalized correlation) as shown in Eq.(3). 
∑∑ ⎟⎠
⎞⎜⎝
⎛
∑∑ ⎟⎠
⎞⎜⎝
⎛⎟⎠
⎞⎜⎝
⎛
∑∑
∑∑
−
′−−
×
′
=
i j ji
w
i j ji
wjiw
i j ji
w
i j ji
wjiw
NC
2
,1
,1,1
2
,
,,
, 
(3) 
 
where wi,j is the pixel of the original watermark, 
and w′i,j is that of the extracted watermark. If NC is 
close to 1, the extracted watermark is similar to the 
original watermark. The numerical data, namely the 
PSNR of the watermarked image under attacks and the 
NC of the extracted watermark, are shown in Table 3. 
The results show that our scheme is highly robust 
against the JPEG attack even the quality factor is low. 
Fig. 5 is the line chart of NC values corresponding to 
different JPEG quality factors. Observing Fig. 5, we 
can see that the quality of the extracted watermark 
does not decline sharply with the decreasing of the 
quality factors. The numerical data of other attacks are 
also listed in Table 3. Those data show that our 
scheme can resist most common attacks. 
  
(a) (b) 
Fig. 4. (a) The host image (512 × 512 pixels); (b) The 
watermarked image (PSNR = 41.66 dB). 
Table 3.  Experimental results under various attacks. 
Attacks PSNR (dB) NC (%) 
JPEG (quality = 1) 33.27 77.55 
JPEG (quality = 2) 34.77 79.45 
JPEG (quality = 3) 36.89 87.61 
JPEG (quality = 4) 37.84 91.12 
JPEG (quality = 5) 38.90 93.57 
JPEG (quality = 6) 40.47 96.69 
JPEG (quality = 7) 39.52 94.72 
JPEG (quality = 8) 41.52 98.89 
JPEG (quality = 9) 43.26 99.84 
 
Fig. 3. The extracting procedure. 
ownership 
share 
master 
share 
Extracting 
DWT 
Test image 
365
