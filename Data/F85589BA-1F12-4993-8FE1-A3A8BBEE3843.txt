一、前言 
個人隱私保護已成為資訊社會最大的挑戰之一。如何能夠在保障個人
隱私之前提下，讓資料能夠分享，以期產生最大的效用是目前研究之重
點。本計畫希望應用資訊理論來探討多方私密計算在隱私保護領域之應
用。 
二、成果 
在香港舉辦的 International Conference of Machine Learning and 
Cybernetics 2007 發表兩篇論文 
1. Information Theoretically secure number product protocol. 
2. An Aspect-Oriented Approach to Privacy-Aware Access Control 
第一篇成果是我們的研究主題，探討資訊理論架構下如何利用內績的協
定來完成其他的計算工作。論文中提出如何用 scalar product protocol
來實現 number product protocol，而 number product protocol 可以用
來計算資料探勘中的一些問題。而第二篇論文雖然不是此研究計畫之核
心主題，但是仍然與計畫的方向一致，討論的是如何利用資訊技術來完
成 尊 重 個 人 隱 私 價 值 體 現 的 系 統 。 而 所 用 的 資 訊 技 術 則 是
aspect-oriented programming。 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
DEFINITION 2.3 (Information-theoretically Secure): Let
xi be the private input of party i. Protocol pi is said to be
information-theoretically secure if the information about
xi is not leaked during an execution of pi from any other
party’s perspective, i.e., H(xi|VIEWpij ) = H(xi), for all
j 6= i.
III. SECURE MULTIPARTY NUMBER-PRODUCT
PROTOCOL
A. Problem Definition
There are n parties, each of which has an N -element data
vector denoted by X1, . . . , Xn. The number-product [12] is
defined as Fn(X1, . . . , Xn) 7→ (y1, . . . , yn) such that
N∑
i=1
 n∏
j=1
Xj [i]
 = n∑
i=1
yi.
For simplicity, we explore the problem based on the fol-
lowing assumptions: 1) Xi, for i = 1, . . . , n is an N -
dimensional vector with all elements independently drawn
from GF (p), where GF (p) is a Galois field of order p, and
p is a large enough prime number; 2) all the participants
are semi-honest and follow the protocol faithfully, but they
may deduce information from the messages received during
an execution of the protocol; 3) all the random numbers
in the protocol are independently generated from a uniform
distribution over GF (p); and 4) there exist private channels
between all parties.
B. Useful Tools
LEMMA 3.1: Let X and Y be random variables. If X is
independent of Y , then f(X) is independent of g(Y ).
Proof: From the independence between X and Y , we
know that Pr(X,Y ) = Pr(X) · Pr(Y ); therefore,
Pr(f(X) = i, g(Y ) = j)
= Pr(X ∈ {s : f(s) = i}, Y ∈ {t : g(t) = j})
= Pr(X ∈ {s : f(s) = i}) · Pr(Y ∈ {t : g(t) = j})
= Pr(f(X) = i) · Pr(g(Y ) = j).
LEMMA 3.2: Let X , Y , and Z be random variables. If Z
is independent of (X,Y ), then Z is independent of Y .
Proof: Z is independent of (X,Y ) implies, by defini-
tion, that Pr(X,Y, Z) = Pr(X,Y ) · Pr(Z); then we have
Pr(Y,Z) =
∑
kPr(X = k, Y, Z)
=
∑
kPr(X = k, Y ) · Pr(Z) = Pr(Y ) · Pr(Z).
LEMMA 3.3: Let X , Y , and Z be random variables. If Z
is independent of (X,Y ), then X and Z are conditionally
independent given Y ; i.e., Pr(X|Y, Z) = Pr(X|Y ).
Proof: From Lemma 3.2 and the independence between
Z and (X,Y ), we know that Y is independent of Z;
therefore,
Pr(X|Y, Z) = Pr(X,Y,Z)Pr(Y,Z)
= Pr(X,Y )·Pr(Z)Pr(Y )·Pr(Z) =
Pr(X,Y )
Pr(Y ) = Pr(X|Y ).
LEMMA 3.4: Let X and R be random variables defined
on GF (p). If R is uniformly distributed and independent of
X , then X +R follows a uniform distribution.
Proof: By the assumption that R is independent of X
and uniformly distributed on GF (p), we know that Pr(R =
i|X) = Pr(R = i) = 1p ,∀i ∈ GF (p); therefore,
Pr(X +R = i)
=
∑
kPr(X = k,R = i− k)
=
∑
kPr(X = k) · Pr(R = i− k|X = k)
=
∑
kPr(X = k) · Pr(R = i− k)
=
∑
kPr(X = k) · 1p = 1p .
LEMMA 3.5: Let X , Y , and R be random variables
defined on GF (p). If R is uniformly distributed and inde-
pendent of (X,Y ), then X +R will be independent of Y .
Proof: According to the assumption that R is uniformly
distributed and independent of (X,Y ), Lemma 3.2 states that
R is independent of X , and by Lemma 3.4 we know that
X +R follows a uniform distribution; therefore,
Pr(X +R = i|Y )
=
∑
kPr(X = k,R = i− k|Y )
=
∑
kPr(X = k|Y ) · Pr(R = i− k|X = k, Y )
=
∑
kPr(X = k|Y ) · Pr(R = i− k)
=
∑
kPr(X = k|Y ) · 1p = 1p
= Pr(X +R = i)
demonstrates the independence between X +R and Y .
LEMMA 3.6: Let X1, . . . , Xn, and R be random vari-
ables defined on GF (p). If R follows a uniform distri-
bution and is independent of (X1, . . . , Xn), then we have
Pr(X1|X2, . . . , Xn−1, Xn +R) = Pr(X1|X2, . . . , Xn−1).
Proof: From the assumption that R is independent of
(X1, . . . , Xn) and Lemma 3.5, we know that Xn + R is
independent of (X1, . . . , Xn−1). By combining that result
with Lemma 3.3, we prove this lemma.
THEOREM 3.7 (Masked Condition Removal): Let R, X1,
. . ., Xn be random variables defined on GF (p). If R follows
a uniform distribution and is independent of (X1, . . . , Xn),
and Y1, . . . , Ym are functions of X1, . . . , Xn, then we have
Pr(Y1|Y2, . . . , Ym−1, Ym+R) = Pr(Y1|Y2, . . . , Ym−1); i.e.,
H(Y1|Y2, . . . , Ym−1, Ym +R) = H(Y1|Y2, . . . , Ym−1).
Proof: Lemma 3.1 states that if R is independent of
(X1, . . . , Xn), then R is also independent of (Y1, . . . , Ym).
By combining that result with Lemma 3.6, we prove this
theorem.
LEMMA 3.8 (Functional Condition Removal): Let X and
Y be random variables such that H(X|Y, f(Y )) = H(X|Y ).
Proof: Trivially, H(f(Y )|X,Y ) = H(f(Y )|Y ) = 0;
therefore, we know that
H(X|Y, f(Y )) = H(X,Y, f(Y ))−H(Y, f(Y ))
= H(X,Y ) +H(f(Y )|X,Y )−H(Y )−H(f(Y )|Y )
= H(X,Y )−H(Y ) = H(X|Y ).
Because ti = xˆi · xn + rni − yni , and yni is uniformly dis-
tributed and independent of (xj , VIEW
pin−1
i , xn, si, sni , ri),
Theorem 3.7 tells us that1
H(xj |VIEWpin−1i , si, ri, xˆni , ti)
= H(xj |VIEWpin−1i , si, ri, xˆni). (13)
Similarly, by the problem assumptions, sni is independent
of (xj , VIEW
pin−1
i , xn, si, ri); therefore, Theorem 3.7 states
that
H(xj |VIEWpin−1i , si, ri, xˆni)
= H(xj |VIEWpin−1i , si, ri). (14)
Because si, ri, and (xj , VIEW
pin−1
i ) are independent, and
according to Eqn. (9) and Eqn. (11)∼(14), we have
H(xj |VIEWpini ) = H(xj |VIEWpin−1i , si, ri)
= H(xj |VIEWpin−1i ) = H(xj), (15)
for i, j < n and i 6= j.
2) H(xn|VIEWpini ), i < n: From Pi’s perspective on Pn’s
input xn, i < n, by the problem assumptions we know
that xn, si, sni , ri, yni , and VIEW
pin−1
i are independent;
moreover, si, sni , ri, and yni are uniformly distributed.
Then, by the same reasoning as Eqn. (11)∼(14), we have
H(xn|VIEWpini ) = H(xn|VIEWpin−1i ), (16)
and because xn is independent of VIEW
pin−1
i , we prove that
H(xn|VIEWpini ) = H(xn).
3) H(xi|VIEWpinn ), i < n: Finally, we consider Pn’s
perspective on Pi’s input, xi, for i < n. Based on the
problem assumptions, x1, . . ., xn, s1, . . ., sn−1, sn1 ,
. . ., snn−1 , r1, . . ., rn−1, yn1 , . . ., and ynn−1 are inde-
pendent. For simplicity, let X = (x1, . . . , xn−1), S =
(s1, . . . , sn−1), Sn = (sn1 , . . . , snn−1), R = (r1, . . . , rn−1),
Rn = (rn1 , . . . , rnn−1), Yn = (yn1 , . . . , ynn−1), and Xˆ =
(xˆ1, . . . , xˆn−1), where xˆi = zi + si and rni = si · sni − ri,
for i = 1, . . . , n − 1. Moreover, S, Sn, R, and Yn follow a
uniform distribution. Then, we have
H(xi|VIEWpinn ) = H(xi|xn, Sn, Xˆ,Rn,Yn). (17)
Because Yn is independent of (X, xn,Sn,S,R), we have
H(xi|xn, Sn, Xˆ,Rn,Yn) = H(xi|xn, Sn, Xˆ,Rn). (18)
For j, k < n, rj is uniformly distributed and independent of
(X, xn, Sn, S, (rk)j 6=k). After applying Theorem 3.7 n − 1
times, we will have
H(xi|xn, Sn, Xˆ,Rn) = H(xi|xn, Sn, Xˆ). (19)
Similarly, for j, k < n, sj is uniformly distributed and inde-
pendent of (X, xn, Sn, (sk)j 6=k). After applying Theorem 3.7
n− 1 times, we will have
H(xi|xn, Sn, Xˆ) = H(xi|xn,Sn). (20)
1Recall that zi is part of VIEW
pin−1
i , so xˆi ·xn+ rni in ti is a function
of (VIEW
pin−1
i , xn, si, sni , ri), which is independent of yni ; therefore, it
is appropriate to apply Theorem 3.7 in this case.
Then, from the independence between xi, xn, and Sn, and
according to Eqn. (17)∼(20), we conclude that
H(xi|VIEWpinn ) = H(xi).
4) Correctness: From Eqn. (10) , yi = zi · xn − yni , and
Step III in the protocol, we have∑n
i=1 yi =
∑n−1
i=1 yi + yn
=
∑n−1
i=1 (zi · xn − yni) + yn
=
(∑n−1
i=1 zi
)
· xn −
∑n−1
i=1 yni + yn
=
(∏n−1
i=1 xi
)
· xn =
∏n
i=1 xi,
which completes the proof.
LEMMA 3.11: If the commodity server is semi-honest,
which means it follows pi2 faithfully, it will not
gain any information about x1, x2, y1, and y2; i.e.,
H(x1, x2, y1, y2|VIEWpi2c ) = H(x1, x2, y1, y2), where
VIEWpi2c denotes the view of the commodity server in pi2.
Proof: Since x1, x2, and y2 are generated by P1
and P2, which are independent of the commodity server,
H(x1, x2, y2|VIEWpi2c ) = H(x1, x2, y2). Because x1 · x2 =
y1 + y2, then, by the definition of f2, y1 is determined
given x1, x2, and y2; i.e., H(y1|x1, x2, y2, VIEWpi2c ) =
H(y1|x1, x2, y2) = 0. Therefore, we conclude that
H(x1, x2, y1, y2|VIEWpi2c )
= H(x1, x2, y2|VIEWpi2c ) +H(y1|x1, x2, y2, VIEWpi2c )
= H(x1, x2, y2|VIEWpi2c ) = H(x1, x2, y2)
= H(x1, x2, y2) +H(y1|x1, x2, y2)
= H(x1, x2, y1, y2),
which implies that there is no information leakage about the
inputs and outputs from the commodity server’s perspective.
REMARK 3.12: From Lemma 3.11, we know that under
the assumption of semi-honest behavior, there is no privacy
leakage, even if one of the parties becomes the commodity
server while any two of the other parties are executing
protocol pi2.
IV. BEN-OR ET AL’S SOLUTION
Ben-Or et al. proposed an efficient protocol that is theo-
retically secure and collusion-resistant if less than half the
participants are corrupt [2]. In the protocol, computing the
multiplication of n parties’ private inputs involves three
stages:
A. Input Stage
Party i shares his input with the secret sharing procedure
proposed in [9]. More specifically, let α1, . . . , αn be n
different non-zero numbers that are publicly known, and let
party i randomly select k numbers aij , for j = 1, . . . , k,
k < n2 , to compose a k-degree polynomial
fi(t) = xi + ai1t+ · · ·+ aiktk,
which hides the secret xi as the constant coefficient. Then,
party i sends fi(αj), a share of secret xi, to party j, j =
1, . . . , n.
fairness issue when one of the parties acts as the commodity
server as well as the feasibility of a collaborative commodity
server.
REFERENCES
[1] Donald Beaver. Commodity-based cryptography (extended abstract).
In STOC ’97: Proceedings of the Twenty-ninth Annual ACM Sympo-
sium on Theory of Computing, pages 446–455, New York, NY, USA,
1997. ACM Press.
[2] Michael Ben-Or, Shafi Goldwasser, and Avi Wigderson. Completeness
theorems for non-cryptographic fault-tolerant distributed computation.
In STOC ’88: Proceedings of the Twentieth Annual ACM Symposium
on Theory of Computing, pages 1–10, New York, NY, USA, 1988.
ACM Press.
[3] Yi-Ting Chiang, Da-Wei Wang, Churn-Jung Liau, and Tsan-Sheng
Hsu. Secrecy of two-party secure computation. Lecture Notes in
Computer Science, 3654:114–123, 2005.
[4] Thomas M. Cover and Joy A. Thomas. Elements of Information
Theory. John Wiley & Sons Inc., 2nd edition, 1991.
[5] Morris H. DeGroot and Mark J. Schervish. Probability and Statistics.
Addison Wesley, 3rd edition, 2001.
[6] Wenliang Du. A Study of Several Specific Secure Two-party Compu-
tation Problems. PhD thesis, Purdue University, August 2001.
[7] Oded Goldreich. Foundations of Cryptography, Volumne II Basic
Applications. Cambridge University Press, 1st edition, 2004.
[8] Oded Goldreich, Silvio Micali, and Avi Wigderson. How to play any
mental game. In STOC ’87: Proceedings of the Nineteenth Annual
ACM Symposium on Theory of Computing, pages 218–229, New York,
NY, USA, 1987. ACM Press.
[9] Adi Shamir. How to share a secret. Commun. ACM, 22(11):612–613,
1979.
[10] Da-Wei Wang, Churn-Jung Liau, Yi-Ting Chiang, and Tsan sheng Hsu.
Information theoretical analysis of two-party secret computation. Data
and Applications Security XX, Lecture Notes in Computer Science,
4127:310–317, 2006.
[11] Andrew C. Yao. Protocols for secure computation. In Proceedings
of the 23rd Annual IEEE Symposium on Foundations of Computer
Science, 1982.
[12] Zhijun Zhan and LiWu Chang. Privacy-preserving collaborative data
mining. In Proceedings of ICDM Foundation and New Directions of
Data Mining workshop, pages 228–235, 2003.
such as EPAL [5]. 
The enforcement of these privacy policies goes beyond traditional access control and 
involves more sophisticated requirements, such as comparing the purpose of data requestors 
against the data collection purpose consented by the data subjects. As far as application 
development is concerned, it is far from easy to enforce such privacy protection requirements in a 
modular and adaptable manner. In addition to the inherently crosscutting nature, there are two 
other major difficulties. First, these privacy-aware access control requirements are extremely 
fine-grained. Each data subject may make different decisions regarding which fields of his/her 
personally identifiable information (PII) can be accessed by who under what intent. For example, 
customer A permits the employees of an online shopping company to disclose her e-mail address 
for both marketing and post-sale service purposes whereas customer B permits disclosure for 
only post-sale service purpose. In other words, the access control decision on disclosing a 
customer’s e-mail address is not only customer-specific but also depends on the intended usage 
purpose.  Such extra fine-grained requirements are simply beyond the capability of ordinary 
access control mechanisms. 
Second, it is conceivable that such privacy requirements emerged only after the access 
control system of an online application was built. In such cases, although it is possible to collect 
customers’ consent and categorize the intents of an application’s action on customers’ PII 
afterwards, it is rather difficult to enhance the working access control system with customer 
consent and action intents yet being able to accomplish it with little impact on the structure of the 
underlying application.   
Based on our prior experience, we claim that we can further leverage the aspect technology 
to develop a privacy-aware access control framework to overcome the two difficulties described 
above. In our viewpoint, the main issue here is how to modularly make a customer’s privacy 
preferences for her PII available to the aspect responsible for protecting her PII from 
unauthorized access. In aspect-oriented programming languages such as AspectJ [5], an aspect 
provides two kinds of mechanisms for modularizing crosscutting concerns, namely advice and 
inter-type declarations. The former is a piece of instrumentation code that dynamically affects 
program flow and the latter allows the programmer to modify a program's static structure, for 
example, the members of its classes and the relationship between classes. Previously, our aspect 
framework employs only advice to enforce access control policies. Now, this paper shows that we 
can utilize the inter-type declarations to associate a customer’s privacy preferences with her PII 
and make such information available to the access control aspect via another piece of advice in a 
modular manner. Consequently, the advice in charge of making access control decisions can also 
get a customer’s privacy preferences when evaluating access constraints, thus achieving 
privacy-aware access control.  
The remainder of the paper is organized as follows. Section 2 outlines the basics of AOP and 
the relevant features of AspectJ, our implementation language. Section 3 overviews the design of 
the access control aspects for enforcing privacy policies. Section 4 describes the detailed design 
of these aspects and presents an example. Section 5 discusses related work. Section 6 concludes 
and sketches future work.  
 
 
class NewClass { ... } 
aspect AddMember {  
   private Preference C1.newF; //new field 
   after (C1 co): execution (C1.new(..))  
                 && this(co) { 
      co.newF = NewFactory.getF(co);  }  
}  
abstract aspect AC { 
 abstract pointcut pc(C1 co);  
 abstract boolean constraint(Preference p); 
 void around(C1 co) : pc(co) { 
   if (constraint(co.newF))  proceed(co);   
   else forwardToExceHandler(..); //denied 
 }  // end around    
} 
aspect UpdateCond extends AC 
{ pointcut pc(C1 co): execution 
   (void C1.update(..)) && this(co); 
  boolean constraint(Preference p) {  
   ActionObj ao = Action.getAO( 
         thisJoinPoint.getSignature()); 
   if (match(p, ao)) return true; 
   else return false; 
  } 
} 
 
Here class C1 is a legacy class which includes customer data that must be protected from 
unauthorized modification based on customer’s preferences. The aspect, AddMember, employs 
inter-type declaration and after advice to add a Preference object to every instance of C1. The 
aspect AC, illustrates the generic structure of an access control aspect. It is an abstract aspect with 
a single piece of around advice and an abstract pointcut pc. The advice specifies that if the call to 
the abstract method constraint returns false, invocation of the method selected by the abstract 
pointcut pc will be aborted and an exception handler will take over. Otherwise, the intercepted 
method will be resumed by calling proceed(). The other aspect, UpdateCond, inherits AC and 
provides the missing pointcut definition, namely the update method of the C1 class, and the 
constraint we impose to protect it. Here the constraint attempts to match the new preference 
object just added to the involved C1 object against an ActionObj, ao, derived from the intercepted 
method via the thisJoinPoint mechanism of AspectJ.  
 
 
3. System Overview  
 
Our experimental platform is the popular MVC-based Apache Struts Framework for Web 
 Figure 2: Privacy-aware access control 
 
Figure 2 illustrates the main components we devised to support privacy-aware access control. 
Besides the access control aspects, there are components for supplying the required 
privacy-related decision information. The purpose associated with an action is easier to handle. 
We simply provide a global action purpose manager which keeps a hash table that maps the 
signature of an action’s join point to the action’s purpose.  Then, in an access control aspect, its 
advice can easily fetch the underlying action’s purpose via the join point API of AspectJ. 
As to the privacy preferences of a data subject, we need to use more sophisticated 
mechanisms to support it. Essentially, such privacy preferences are data subject specific. A main 
difficulty here is that our solution should not require significant changes to the underlying 
application so that we can also handle the case that these preferences are only acquired after the 
application is built and deployed. To overcome the difficulty, we separate the management of 
privacy preferences from the application and link them to the access control aspects through a 
preference factory and a preference aspect, as shown in Figure 2. 
The idea of our privacy preference management is as follows. A data subject specifies its 
privacy preferences regarding its PII in a consent form. These consent forms are collected and 
managed by the privacy preference management module, which is not shown in Figure 2. Later 
when a data subject’s data are requested for access by a data requester, the preference aspect 
invokes the preference factory to retrieve the data subject’s privacy preferences and associate 
them with the requested data. To realize this scheme, the preference aspect should perform two 
major tasks, one static and one dynamic. The static task adds a privacy preference field to any 
class which includes a data subject’s PII to protect. This is achieved through the inter-type 
declaration mechanism of AspectJ. The dynamic task is conducted by an object construction 
advice which is triggered right after any object is instantiated from those classes with PII. The 
advice will then ask the privacy factory to generate a proper privacy preference object specific to 
the requested PII object and associate the preference object with the PII object.  Consequently, 
the privacy preferences specific to a data subject will be made available to the access control 
aspect in charge of protecting the requested data. 
 
 
Data 
subject
Data  
requester 
 DB 
Preference 
Consent 
Action 
purpose 
manager 
Data with PII
Preference 
match? 
Preference 
cond? 
Access 
control 
17    // user has passed identity check? 
18    if (auth.isAuthenticated(req)) { 
19       //eval access control constraint 
20       if (constraint(request)) {  
21          //allow executing the action 
22          ActionForward forward =  
23                        proceed(...); 
24          //get cust data & preference 
25          Object data = getData(req); 
26          //filter PII according to the  
27          //cust’s privacy preference 
28          PIIfilter(data); 
29       } else // access denied 
30                return forwardToErrorPage( 
31                             req, map); 
32     } else  // login re-direction 
33         return map.findForward( 
34                     auth.forwardTo()); 
35   } //end advice 
36 } 
 
The advice (line 13~36) ensures that the three major tasks will be performed. First, it 
validates that the requesting user has passed the required authentication check (line 16~18). 
This is accomplished by looking for the authentication token, if any, kept in the user session 
object accessible through the request object. Second, it invokes the constraint(req) method 
to ensure that the user is authorized to execute the intercepted action. Finally, the 
PIIfilter(data) method is called to filter out any PII according to the privacy preference of 
the underlying data subject. 
In order for the PIIfilter method to work properly, we need to augment the data object 
with the privacy preference of its owner.  This is performed by the other aspect, 
AddPrivacyPreference. For each data class that involves customer PII, this aspect introduces 
a new member, preference, for keeping the customer’s privacy preference (line 04). Later 
when a customer data object is instantiated, this aspect will grab the data object and get its 
owner’s privacy preference from the preference factory and set it to the preference field 
(line 09~13). Listing 3 sketches the code of this aspect.  
 
Listing 3: The privacy preference aspect 
01 aspect AddPrivacyPreference { 
02 // Introduce a new member for each 
03 // class which involves customer PII  
04   Preference CustData.preference; 
05  ... 
 // Create Customer A’s preference obj  
  cp = new ContactPreference(postal,  
                          email, mobile); 
 
This scheme of representing the privacy preference of a data subject is quite concise; 
other kinds of PII data can be handled in a similar manner.   
 
Listing 4: Class for representing customers’ contact preference 
01 class ContactPreference extends 
02                         Preference { 
03  //collections of consented purposes 
04  Collection postalP; 
05  Collection emailP; 
06  Collection mobileP; 
07  //constructor called by pref factory 
08  ContactPreference(Collection c1,  
09        Collection c2, Collection c3) { 
10    postalP=c1; emailP=c2; mobileP=c3; 
11  } 
12  Collection getPostal() {  
13    return postalP;      } 
14  Collection getEmailP()  {  
15    return email;       } 
16  Collection getMobile()  {  
17      return mobileP;         } 
18 } 
 
Now we present the aspect, CampaignList, for enforcing the above rule (Listing 5). It 
inherits the PW_AccessControl aspect and provides the definition of the pointcut and other 
inherited abstract methods. The constraint method (line 06~13) restricts the underlying 
action to only staff in the marketing department. The getData method (line 15~18) retrieves 
the list of customer’s contact information from the request object. The PIIfilter method (line 
20~42) is more involved. After fetching the purpose of the action from the action purpose 
manager, it enters a loop to filter out any specific contact data from the list for each 
customer according to his/her privacy preference. Note that both the getData  and PIIfilter 
methods are executed after the CreateCompaignList action is performed by the proceed() 
call in the advice. Therefore, the list of customer contact information is available in the 
request object and each contact information object has already been extended with a proper 
contact preference object by the AddPrivacyPreference aspect.   
Listing 5: Aspect for enforcing the marketing campaign rule 
43 ) 
 
 
5. Related Work 
 
In the past few years, there have been many architectural proposals published for 
enforcing privacy in enterprise applications [9][10][11][12]. Our formulation of 
privacy-aware access control rules are inspired by the works of [5] and [9]. However, both 
of them emphasize more on the comprehensive features of the proposed architectures rather 
than practical issues of migrating existing applications to support privacy enforcement, as 
we do. Neither do they use aspect technology. 
The recent work of Berghe and Schunter [13] also proposes to use aspect technology for 
privacy enforcement. The so-called privacy injector scheme focuses on using aspects to associate 
privacy preference with personal data and monitor the input and output of PII data in an 
enterprise application. Their scheme did not include access control enforcement. By contrast, our 
aspects are more versatile. They are privacy-aware access control aspects which can be applied to 
any user actions in an enterprise application. 
 
 
6. Conclusion and Future Work 
 
Privacy enforcement is attracting more and more concerns in the development of 
enterprise applications. In this paper, we have presented a systematic approach to common 
privacy requirements; we model them as data-subject specific and fine-grained access 
control requirements. We extended our previous aspect framework for enforcing such 
requirements for Struts-based Web applications. By employing AOP and framework 
technology, we have successfully separated the access control implementation from the 
functional core and in a modular manner and obtained good balance between reuse and 
customization. Furthermore, the correspondence between privacy-aware access control rules 
and associated aspects is direct and hence easy to adapt. 
For future work, we shall investigate two directions of extensions. First, since obligations 
are also an essential part of comprehensive privacy enforcement, we shall proceed to devise 
mechanisms for managing privacy obligations in our framework. Basically, as proposed in [14], it 
will involve an implementation scheme for associating privacy obligations with personal data and 
provide an event service which periodically scans pending privacy obligations and fulfills 
qualified ones.  
Second, we plan to investigate the support of dynamic adjustment of access control rules. In 
some situations, it is likely that certain access control rules are subject to frequent changes. In our 
current approach, for those changes to be effective, we have to modify the involved access 
control aspects, re-compile them, stop the application, and re-weave the aspects into the 
application. If this kind of service interruption is not acceptable, we must provide some kind of 
dynamic adjustment mechanism which can support replacement of the enforcing code while 
allowing the application running as usual. We plan to utilize the dynamic class loading facility of 
[14] M. Casassa Mont, “Dealing with Privacy Obligations in  
Enterprises”, HP Labs Technical Report, HPL-2004-109, 2004. 
 
 
