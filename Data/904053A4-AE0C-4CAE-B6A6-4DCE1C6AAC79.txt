中文摘要：
本計畫(九十六年度) 「體積全像應用於體腔內部之三維動態形貌量測」承繼九十五年度之
國科會計畫申請案，繼續開發以繞射元件為核心，並且利用內視鏡進行動態、大深度落差
的三維形貌檢測系統。主要原理是將繞射元件產生之 diffracted sinusoidal fringe pattern 投影
在待測物體上，其條紋扭曲程度和待測物體的縱深有關，稱為「相位－縱深」關係式
(phase-to-depth relation)，找到此關係式即可進一步得到物體表面的三維座標。本計畫重點
在於設計一灰階特殊分佈之 fringe pattern，以此 pattern 作為物光，紀錄於全像元件中，再
利用雷射光源所重建出的影像，投射在體腔內部之待測物表面，其條紋扭曲程度透過內視
鏡記錄於影像擷取器中，最後再由「相位－縱深」關係式還原動態物體的三維形狀。
相較於傳統的條紋投影方式，開發本計畫的優勢在於：1. 此繞射元件的體積甚小(<500
μm3)，搭配內視鏡等小型的 image sensor 可形成一完整的微形系統，適用於生物體腔內部
之 3D 檢測；2. 相較於目前各式的形貌量測系統，包括傳統的 holographic interferometry，
此計畫的量測裝置更加輕便、簡單，而且避免了像差因素，故而降低了電腦演算及系統校
正成本；3. 由於光源的空間同調性甚佳，故投影系統有甚大的景深(depth of focus)，待測物
的縱深量測範圍亦因此增加；4. 繞射條紋以灰階編碼的方式投射在待測物表面，可進行大
深度落差的三維形貌檢測；5. 由於影像擷取系統只需要擷取一次資料，因此可進行動態物
體的三維形貌量測。
關鍵詞：條紋投影技術，弦波光柵，三維形貌量測系統，繞射元件，內視鏡
英文摘要：
A projected fringe profilometry using a diffraction element embedded into an endoscope for
finding the absolute shape of an object with large depth discontinuities is proposed. The
projection system is simplified by using a diffraction element to produce an area-encoded fringe
pattern instead of the typical fringe projection scheme. The proposed method offers following
major advantages: (1)) a very compact design for the measurement system, (2) very low fringe
distortion (even for a large field of view), (3) a large depth of focus in the projection system, (4)
reliable phase unwrapping to complex objects, especially for surfaces with large depth
discontinuities, and (5) robust performance to analyze dynamic objects.
Keywords: fringe projection, sinusoidal grating, projected fringe profilometry, diffraction
element, endoscopes
between two plane waves are inclined at a small angle to each other. The projection system is
therefore simplified by using a two-slit device. Unfortunately, it is still a challenge to analyze
surfaces with lots of discontinuities. Phase unwrapping [11-14], the inevitable procedure to
remove the phase jumps in order to recover the absolute phase, will encounter ambiguity to
distinguish the local fringe order. Two or several different projected spatial frequencies can be
used to increase the range of measured depth [15-24]. However, these systematic configurations
become complicated again and are still impractical in application to endoscopes.
In this paper, we investigate the use of a fringe pattern generated by launching a laser beam
into a diffraction grating. The projection system is simplified by using a diffraction element
instead of a projection lens or interference components. This makes it possible to perform 3D
shape measurements using endoscopes. The field of view of this measurement system can be
wider than 60°, depending on requirement of the working distance and measurement scale of the
tested object. The high spatial coherence from the diffraction grating allows it to generate a large
depth-of-focus projection. In addition, only one measurement frame is required to inspect
surfaces. Thus, it is feasible to perform a single-shot measurement of dynamic objects.
To distinguish the depth discontinuities, the diffraction grating forms an area-encoded fringe
pattern in which the sinusoidal fringes are encoded with binary stripes. The binary stripes plays a
key role to identify the local fringe order, while the sinusoidal fringes are employed to reconstruct
the 3D shape. Even though the inspected surfaces are colorful, the proposed encoding scheme can
still identify the local fringe orders. Compared with our previous work, this encoding scheme
provides a more reliable performance to identify the fringe orders since it is not sensitive to the
observed colors. The overall system is compact for specific detections in many severe
circumstances, especially for 3D inspections using an endoscope for dynamic surfaces with large
depth discontinuities.
2. Fabrication of the diffraction component for fringe projection
To perform fringe projection using a diffraction element, a standard holographic setup is
proposed, as shown in Fig. 1. The setup is mainly composed of (1) a laser with good temporal
coherence, (2) a divergent reference wave from a single-mode fiber, (3) a convergent object wave,
and (4) a hologram, which is used as a diffraction element. An objective lens forms the object
wave from an area-encoded pattern. The reference wave and the object wave interfere, resulting
in an intensity distribution in the hologram.
The projected fringes are encoded with binary stripes. The transmittance of this encoded pattern
is mathematically represented as
 2.0)]cos(4.04.0[)( 2  xxBxt d , (1)
where B(x) is the transmittance of binary stripes, and d is the period of sinusoidal fringes. Figure
2(a) and (b) show the distribution of binary stripes and sinusoidal fringes, respectively. Note that
(a) (b)
Fig. 3. Sinusoidal fringes encoded with binary stripes.
The binary stripes play a main role to identify the local fringe order. Thus, this encoding scheme
are not sensitive to noises from the color.
For a coaxial system, the imaged position di is approximately given by
oi dfd
111  , (2)
where f is the focal length of objective lens, do is the distance between the fringe pattern and the
objective lens.
As shown in Fig. 4, when a reading beam from the single-mode fiber is launched into the
hologram, a diffracted area-encoded pattern is reconstructed on which the image is formed, at
distance di away from the hologram. Since the diameter of the core of the single-mode fiber is in
micron-scale, an almost perfect point source is obtained. This also makes it possible to
reconstruct an image with a large depth of focus at distance di away from the hologram. The
diffracted fringes on the inspected object are recorded by the image acquisition system in which
consists of an endoscope and a CCD camera. Phase distribution is then analyzed to reconstruct
the 3D shape.
Fig. 4. Projected fringe profilometry using a diffracted area-encoded pattern by
launching a reading beam to the hologram. An endoscope combined with a CCD
camera is used to record the distorted fringes
with an output power of 10mW at 632.8nm was employed to be the light source. A film hologram
was used as the diffraction component. Its diffraction efficiency was measured approximately 20
%. The focal length of the objective lens used to form an image of the area-encoded pattern was
100mm. A flat plate with large depth discontinuities was selected as the testing sample. Shown in
Fig. 5 is the recorded image in which the diffracted pattern was projected on this testing object.
Figure 6 is the reconstructed shape.
5.2 Error analysis
Errors of the system, in the case of our experiment, were mainly raised from the speckle
noise of the diffraction pattern and the spatially sampling density of the fiber endoscope. A
standard flat plate with roughness of 3m and size of 20mm20mm was used to evaluate the
systematic accuracy. The reconstructed shape is shown in Fig. 7. The sampling resolution was
approximately 120m, which was limited by the pixel numbers of the endoscope. Depth accuracy
was approximately 240m.
Fig. 5. Appearance of a diffracted fringe pattern projected to the testing object which was
observed by an endoscope. A 12-bit camera with 10241024 pixels was used to record the
fringes.
Fig. 7. 3D shape sensing for a standard flat plate.
6. Conclusion
In summary, we investigated a unique projected fringe profilometry using a diffraction
element embedded into an endoscope. A method to fabricate this diffraction element has been
presented. An area-encoded projection was employed, and therefore it was robust to analyze
surfaces with discontinuities. The high spatial coherence from the diffraction grating allows it to
generate a large depth-of-focus projection. Thus, the depth’s measuring range could be very large.
The field of view of this measurement system could be wider than 60°, depending on requirement
of the working distance and measurement scale of the tested object. Since only one phase
measurement was needed for operation, it was practical for 3D measurements of dynamic objects.
The projection system was simplified by using a diffraction element instead of a projection lens
or interference components. Thus, the overall system was very compact. This makes it possible to
perform 3D shape measurements using the diffraction grating built into an endoscope for
dynamic surfaces with large depth discontinuities.
9. Reference
1. G. Indebetouw,“Profile measurement using projection of running fringes,”Appl. Opt. 17,
2930-2933 (1978).
18. H. Zhao, W. Chen, and Y. Tan, “Phase-unwrapping algorithm for the measurement of
three-dimensional object shapes,”Appl. Opt. 33, 4497-4500 (1994).
19. D. R. Burton and M. J. Lalor,“Multichannel Fourier fringe analysis as an aid to automatic
phase unwrapping,”Appl. Opt. 33, 2939-2948 (1994)
20. Y. Hao, Y. Zhao, and D. Li,“Multifrequency grating projection profilometry based on the
nonlinear excess fraction method,”Appl. Opt. 38, 4106-4110 (1999).
21. E. B. Li, X. Peng, J. Xi, J. F. Chicharo, J. Q. Yao, and D.W. Zhang,“Multi-frequency and
multiple phase-shift sinusoidal fringe projection for 3D profilometry,”Opt. Express 13,
1561-1569 (2005).
22. M. Takeda, Q. Gu, M. Kinoshita, H. Takai, and Y. Takahashi, “Frequency-multiplex
Fourier-transform profilomery: a single-shot three-dimensional shape measurement of
objects with large height discontinuities and/or surface isolations,”Appl. Opt. 36,
5347-5354 (1997).
23. J. L. Li, H. J. Su, and X. Y. Su, “Two-frequency grating used in phase-measuring
profilometry,”Appl. Opt. 36, 277-280 (1997).
24. W. H. Su and H. Liu, “Calibration-based two-frequency projected fringe profilometry: a
robust, accurate, and single-shot measurement for objects with large depth
discontinuities,” Opt. Express 14, 9178-9187 (2006).
25. Wei-Hung Su, “Color-encoded fringe projection for 3D shape measurements,” Opt.
Express 15, 13167-13181 (2007).
26. Wei-Hung Su, Wei-Chia Su, Hung-Jei Kao, and Chien-Yue Chen, “Correlator-aided
alignment of phase key in encrypted holographic storage systems,” Opt. Commun. 280,
27-32 (2007).
27. Wei-Hung Su,“Projected fringe profilometry using the area-encoded algorithm for
spatially isolated and dynamic objects,”Opt. Express 16, 2590-2596 (2008).
28. Wei-Hung Su, Cho-Yo Kuo, Chun-Chieh Wang, and Chung-Fan Tu,“Projected fringe
profilometry with multiple measurements to form an entire shape,”Opt. Express 16,
4069-4077 (2008).
29. Wei-Hung Su, Yi-Ling Hsu, Kun-Chang Yu, and Hongyu Liu,“Accurate integration of
segmented 3D profile measurements using digital 2D fringe projection,”Microwave and
Optical Technology Letters 50, 2474-2480 (2008).
30. Chao-Kuei Lee, Wei-Hung Su, and Chengwei Lee,“Speckle-reduction using the empirical
mode decomposition for fringe analysis,” submitted to Microwave and Optical
Technology Letters.
31. Wei-Hung Su, and Chi-Chang Chen, “Image formation using a supercontinum light
illumination and its application to projected fringe profilometry,”submitted to Microwave
and Optical Technology Letters.
可供推廣之研發成果資料表
可申請專利 可技術移轉 日期：96 年 10 月 27 日
國科會補助計畫
計畫名稱：體積全像應用於體腔內部之三維動態形貌量測
計畫主持人：蘇威宏
計畫編號：NSC 96－2221－E－110－056－ 學門領域：光電
技術/創作名稱 體積全像應用於體腔內部之三維動態形貌量測
發明人/創作人 蘇威宏
中文：提出一套利用全像技術所設計的條紋投影系統，來進行待測
物三維形貌的量測。此投影系統的體積甚小(<500μm3)，搭配 fiber
bundle 及小型的 image sensor 可形成一完整的光學微機電形貌量測
系統，適用於生醫檢測如內視鏡等 3D 檢測。所提出的新型投影系
統，用來進行待測物三維形貌的量測時，不僅可以克服量測大物體
時所受景深限制的影響，並且，構造簡單的投影裝置，也增加了未
來在市場上的可行性。
技術說明
英文：A projected fringe profilometry using a diffraction element for
finding the absolute shape of an object with large depth discontinuities
is proposed. The projection system is simplified by using a diffraction
element to produce an area-encoded fringe pattern instead of the
typical fringe projection scheme. The proposed method offers
following major advantages: (1) a very compact design for the
measurement system, (2) very low fringe distortion (even for a large
field of view), (3) only one phase measurement needed for operation,
(4) robust performance to analyze surfaces with lots of discontinuities,
especially for automatic phase unwrapping, and (5) a large depth of
focus in the projection system. The advantages make it possible for
measurements of dynamic objects inside a tiny body.
可利用之產業
及
可開發之產品
1. 國防工業如飛彈、魚雷、機翼與螺旋槳等形貌之鑑定，醫學工
程如生物細胞，電子產業如 PC 板面，機械製造如齒輪形狀探
測等，皆需要對待測物之三維形貌作精密的檢定;
2. 對所有以 projected fringes 為基礎的形貌量測工具都可適用。
技術特點
1. 此繞射元件的體積甚小(<500μm3)，搭配 fiber bundle 及小型的
image sensor 可形成一完整的光學微機電形貌量測系統，適用於
生醫檢測如內視鏡等 3D 檢測；
2. 相較於目前各式的形貌量測系統，包括傳統的 holographic
interferometry，此計畫的量測裝置更加輕便、簡單，而且避免
了像差因素，故而降低了電腦演算及系統校正成本；
3. 由於光源的同調性甚佳，故投影系統有甚大的景深(depth of
focus)，待測物的縱深量測範圍亦因此增加；
出席國際會議研究心得報告及發表論文
敝人於 2007年八月參加 SPIE會議（SPIE Optics and Photonics, 26 - 30 August
2007），並且發表四篇論文，過程十分順利，其中，所發表的論文“Time resolved
profile measurements for ultra-fast vibrating objects”為 invited paper。
另外，Session 7（Conference 6698, Conv. Ctr. 26B）之會議主持人 Prof. Karl M.
Reichard 無法如期參加，因此由本人代為主持。
(http://spie.org/Documents/ConferencesExhibitions/SPIE-Optics-and-Photonics-2007
-Final.pdf)
台灣學者在本會議(Conference 6698, Photorefractive Fiber and Crystal Devices)發
表的論文眾多，顯示台灣學者在此領域有佔有極高的學術地位。
發表之四篇論文如附件所示。
One of the principal trends in the development of 3D inspection is the accurate measurement of
dynamic objects. Therefore, real-time response of the image acquisition system becomes a critical issue.
A high-speed video camera built into the image acquisition system can be a selected solution. However,
it is still a challenge to analyze a tested object that moves with high speed up to 10Km/sec., or vibrates
up to 10K-Hz.
In this paper, we proposed a method to reconstruct a 3D shape from a dynamic object
using pulsed illuminations. The light source is generated by launching pulsed signals
to a white light LED. The dynamic object seems static during each illuminating pulse.
Image recorded by the sensor array illuminated by each pulsed wave is therefore not
blurred by motion. This makes it possible to inspect a dynamic object at a desired
sequence of time.
2. SYSTEM SETUP
As one can see from Fig. 1, a dynamic object moving from left to right is projected with a sinusoidal
pattern and observed by an image sensor array. The light source, which consists of a function generator
and a white light LED, provides a sequence of pulsed illuminations. The duration of each pulse can be
as low as 5ns. Thus, the dynamic object seems static during each illuminating pulse. A fringe pattern,
which is illuminated by the pulsed wave, is projected to the tested object. The field of view of the
projection system is large enough that the motion of the object can be fully inspected. It is
advantageous to illuminate a dynamic object periodically in order to trace the motion. For each pulse,
the fringe pattern distorted by the surface profile can be captured by a sensor array and stored in a
digital frame buffer for subsequent analysis by a computer.
To avoid an image blurred by uniform linear motion when recorded by the sensor array, the duration
time for each pulse should be restricted to a specific value, which can be expressed as


M
w
t  , (1)
where w is the pixel size on the detector array, M is the magnitude of the projection lens, and is the
transverse speed of the tested object.
Depending on demands of the reconstructed data, the image sensor array can be either a CCD camera
or a digital video. If a digital video is chosen as the sensor array, the frame rate of the video is generally
30Hz. Thus, for a dynamic object with moving speed up to 10km/sec., the sampling density in time
domain is too low. An alternative solution is the utilization of a CCD camera. When a CCD camera is
The one-dimensional Fourier transform of Eq. (4) with respect x-axis is realized as
    ),1(~
2
1
),
1
(
~
2
1
,},{ * y
d
fBy
d
fByfAyxI xxx  , (5)
where   ),(~},~{ yfByxb x . The fundamental component, ),1(~
2
1
y
d
fB x  , can be carried
out with a suitable band-pass filter.
The inverse Fourier transform of the fundamental component is expressed as,
     ],
2
[
2
1 ,
2
1
),(
~
2
1
)},
1
(
~
2
1
{,
yxx
d
jx
d
j
x eyxbeyxbyd
fByxs
   . (6)
Phase distribution from Eq. (6) is then given by
    



 
}{Re
}Im{
tan, 1
x,ys
x,ys
yx , (7)
where Im{} and Re{} represents the image part and real part of the complex signal.
Note that phase evaluation gives principle values ranging from–andand has
discontinuities with 2phase jumps. t needs to be unwrapped to obtain the absolute
phases xd. After a process of so-called phase unwrapping [12], the absolute
phase values can be identified as
 Unwrap . (8)
4. PHASE UNWRAPPING
A method to reconstruct a 3D shape from a complicated object using color-encoded
fringe projection is proposed. The projected pattern consists of a set of color-encoded
strips and a set of sinusoidal fringes. Phases of the projected fringes on the surface are
evaluated by Fourier transform method. Unwrapping is then performed with reference
to the color-encoded stripes. The period of the sinusoidal fringe and the width of the
color strips need not to be the same, depending on complicacy of the tested object.
Shown in Fig. 2 is an example of the encoded fringe pattern, in which the period of
the fringes is twice of the stripe width. The transmittance of the sinusoidal fringes is
represented as
 )cos(4.06.0 2 xxt d , (9)
where d is the period of the fringe. The minimum of the transmittance is set to 0.2 so that the entire
color stripes are observable and discriminable by the color CCD camera.
significant information to distinguish the fringe color. They are desirable to address the distribution of
the color-encoded fringes.
Table 2. Assigned binary values in red-green-blue model with the corresponding digital numbers
Digital number 1 2 3 4 5 6 7
Binary value in
red-green-blue
model
(1 0 0) (0 1 0) (0 0 1) (1 1 0) (1 0 1) (0 1 1) (1 1 1)
However, it is a challenge to assign a suitable threshold value to the whole image. If the threshold is set
too low, noises cannot be filtered out. If the threshold is set too high, intensity of the dark fringes,
where the transmittance of the pattern is close to the minimum, might be set to zero. Errors are
therefore introduced to distinguish the fringe color. To retrieve the lost data, one can address the
boundary of each fringe by searching for the intervals between two local minimums. The mask pattern
is then created with reference to boundaries of the fringes. Shown in Fig. 5(b), (c), and (d) are three
retrieved binary masks.
With reference to these binary masks, a stream of digital numbers for each row on the image can be
generated. The digital numbers with their corresponding binary values are illustrated in Table 2. This
stream is then evaluated with the code table. Fringe order at each row is therefore carried out.
To evaluate the phase distribution, the color-encoded fringes should be displayed in
gray intensity levels. Figure 6 illustrates the basic stages of the transform method.
Shown in Fig. 7 is the transformation of Fig. 5(a). The binary masks are employed to
weigh the intensities of the colors.
An example is given to illustrate our proposed method. A box attached to a plate was
selected as the testing object. A color-encoded pattern was projected onto this object.
The recorded image is shown in Fig. 8(a). This image was separated by the
red-green-blue color channels, as depicted in Fig. 8(b), (c), and (d). They are then
transformed to a binary intensity distribution. The corresponding mask patterns are
created, as shown in Fig. 8(e), (f), and (g). As demonstrated Table 2, these mask
patterns generate a stream of digital numbers for each row on the image to represent
the color stripes. Then the fringe order can be found out with reference to the code
table (Fig. 4(b)). Distribution of the fringe order identified by the code table is
illustrated in Fig. 8(h), in which a color bar is used to represent the order number.
The estimation of Eq. (12) can be represented as the polynomial






m
i
i
i
n
i
i
i ccz
00
)(  , (13)
where ci and c-i are coefficients of the polynomial. With a sufficient set of phase
values and corresponding depth values, the coefficients can be carried out.
6. 3D SHAPE MEASUREMENTS
As an experimental example, an onion cell attached with a vibrator with frequency
80Hz was selected as the testing sample. A fringe pattern was projected to the testing
object. A monochrome sensor array with 10241024 pixels at 12-bit pixel resolution
was selected as the image sensor array. The duration time of each pulse was 660s,
while the intervallic time between two pulses was 33ms. Shown in Fig. 11 is the
recorded image. Phase-extraction was performed by Fourier transform method.
Shown in Fig. 12 is the computed phase map. The phases have principle values
ranging from –and , and have discontinuities with 2phase jumps. A phase
unwrapping process to recover the absolute phase is employed. The reconstructed 3D
shape using Eq. (11) and (13) was retrieved, as shown in Fig. 13.
12. D. C. Ghiglia and L. A. Romero, "Robust two-dimensional weighted and unweighted phase
unwrapping that uses fast transforms and iterative methods," J. Opt. Soc. Am. A 11, 107- (1994).
Figure 3 Quantization scheme used for generating a digital sinusoidal grating from its
continuous
(a)
(b)
(c)
1 2 3 4 5 6 7 1 2 1 3 1 4 1 5 1
6 1 7 2 3 2 4 2 5 2
(a)
(b)
(c)
(d)
Figure 5 (a) Appearance of the projected pattern on a plate recorded by the color CCD camera
(b) Binary mask generated from the red channel. (c) Binary mask created from the green
channel. (d) Binary mask created from the blue channel.
Figure 6 Flow diagram of stages for color-encoded fringes transformed in gray intensity
levels.
(a)
(b) (c)
(d)
(e) (f)
(g)
(h)
Figure 8 Fringe order identification: (a) shows an observed image in which the tested object is
projected with a color-encoded fringe pattern; (b), (c), and (d) show the same image in red,
green, and blue channel, respectively; (e), (f), and (g) show the binary mask created by the red
channel, green channel, and blue channel, respectively; (h) shows the evaluated distribution of
the fringe order, with a color bar to represent the order.
Figure 10 Coordinate systems in a non-telecentric projected fringe measurement system.
Figure 11 Appearance of an onion cell projected with sinusoidal fringes.
Speckles removal from 3D images by empirical mode
decomposition
Wei-Hung Su, Guan-Long Chen, and Cho-Yo Kuo
Department of Material Science and Optoelectronic Engineering,
National Sun Yat-Sen University
Kaohsiung 804, Taiwan
ABSTRACT
3D shape reconstruction using fringe projection or interference schemes has been
extended studied. However, speckle noises could be introduced once a coherent light
source is used. In this paper, we use the empirical mode decomposition (EMD) to
remove speckles caused by such kind of coherent illumination. This makes it possible
to accurately analyze fringes in the frequency domain and to accurately reconstruct a
3D image.
Keywords: interferometry, coherent light source, empirical mode decomposition,
speckle noise, fringe projection
8. INTRODUCTION
The speckle that is formed in coherent illumination confuses efforts to record an
object’s fine details. The confusion is particularly severe in optical metrology and
microscopy. Many filter algorithms, such as Kuan Filter [1], Enhanced Frost Filter [2],
and Gamma Filter [3], have been extensively studied to remove the speckle. However,
signal might be lost or distorted while performing these algorithms. The empirical
mode decomposition (EMD), which was first introduced by Huang [4], is desirable to
analysis noise efficiently. This makes it possible to accurately analyze interference
fringes from an optical interferometry and to accurately retrieve the signal.
 )()]2cos(1[ xNx
T
AxI   , (3)
where N(x) is the random noise. In our experiment, A=1000, and T=15. Density of the noise
distribution was 27/136. The amplitude of random noise was 57. Thus, the signal-to-noise ratio was
1000/57. Shown in Fig. 1(a) is the data I(x). Figure 1(b) shows the IMF component c1. It is obvious that
with a suitable signal-to-noise ratio, the characteristics of the signals can be extracted through the EMD
and get rids of most of the noises.
First we evaluate the performance of EMD to signal extraction. The sinusoidal curve that
contains random distributed noises is used as an example again. Coefficients of the sinusoidal curve in
Eq. (1) are kept in the same values (i.e. A=1000, and T=15), while amplitude of the noises is enlarged.
It is found that the IMF component c1 cannot retrieve the signal correctly. Shown in Fig. 2(b) is the
IMF component c1, in which the noise amplitude was 58. When the signal-to-noise ratio (SNR) was
smaller than 1000/57, part of the signal cannot be retrieved. Figure 3 shows a curve which addresses
the required SNR to retrieve signals without distortion for a given noise density. Signal-to-noise ratios
below that curve cannot recover the desired signal correctly.
To investigate the feasibility for speckle removal by the EMD, a plate projected with a sinusoidal
pattern illuminated by a laser source was used as the tested object. Coherent noise is inevitably
introduced by the laser source. Appearance of the speckles on the plate is shown in Fig. 4(a). Its
intensity distribution across a line of the image is shown in Fig. 4(b). One can see that the amplitude of
the speckle noise is very large, resulting in a low signal-to-noise ratio. Thus, the EMD cannot be
applied to retrieve the signal directly. An alternated solution is to eliminate most of the speckles by a
band pass filter and then perform the EMD to retrieve the signal. The signal-to-noise ratio is therefore
enlarged after performing the band pass filter. Figure 5 shows appearance of the image after
performing the band pass filter. The intensity distribution is then evaluated by EMD. Figure 6(a)
illustrates the retrieved signal performed by the EMD. Its intensity distribution across a line of the
image is shown in Fig. 6(b).
10. 3D SHAPE RECONSTRUCTION BY FRINGE PROJECTION
PROFILOMETRY
An application of the proposed method is 3D shape reconstruction by fringe
projection profilometry. Projected fringe profilometry consists of a projection system
and an image acquisition system. The projection system generates a sinusoidal fringe
pattern from a projection lens onto the inspected surface. With proper
4. N. E. Huang, Z. Shen, R. L. Steven, M. C. Wu, H. S. Shih, Q. A. Zheng, N. C. Yen, C. C. Tung,
and H. H. Liu, “The empirical mode decomposition and Hilbert spectrum for nonlinear and
non-stationary time series analysis,” Proc. Of the Royal Society of London, Series A, 454,
903-995 (1998).
5. Takeda, “Fourier transform profilometry for the automatic measurement of 3-D object shaped,” 
Applied Optics, 22, No. 24, 3977-3982 (1983).
6. V. Srinivasan, H. C. Liu, and M. Halioua, “Automated phase-measuring profilometry of 3-D
difuse objects,” Applied Optics, 23 (18), 3105-3108 (1984).
7. Hongyu Liu, Wei-Hung Su, Karl Reichard, and Shizhuo Yin, “Calibration-based phase-shifting
projected fringe profilometry for accurate absolute 3D surface profile measurement,” Optics
Communications, 216, Issues 1-3, February 1, 2003, p.65-80.
(a)
(b)
Figure 2 (2) Simulated signal by adding random distributed noises to the sinusoidal
curve. (b) One of the IMF components, c1(x).
(b)
Figure 4 (a) Appearance of the speckles on the plate. (b) Intensity distribution across a line of the
image.
Figure 5 Intensity distribution after performing a band pass filter.
Figure 7 Appearance of a fan blade projected with a fringe pattern illuminated by a laser light.
Figure 8 Signal extraction evaluated by the EMD.
3D shape reconstruction using multiple projections: a
method to eliminate shadowing for projected fringe
profilometry
Wei-Hung Su and and Cho-Yo Kuo
Department of Material Science and Optoelectronic Engineering,
National Sun Yat-Sen University
Kaohsiung 804, Taiwan
ABSTRACT
A method using multiple fringe projections from different viewpoints for finding the
absolute shape of an object is proposed. In this method, surfaces with large depth
discontinuities can be identified without ambiguity. Shadowing caused by tilted fringe
projection can be eliminated as well. The other advantages of the proposed
measurement system are: (1) large depth-of-field in the projection system; (2) very
low fringe distortion (even for a large field of view); and (3) robust performance to
analyze dynamic objects.
Keywords: fringe projection, projected fringe profilometry, sinusoidal grating,
multiple projections
12. INTRODUCTION
In optical 3D sensing, techniques based on fringe projection methods have the
properties of nondestructive detection, high depth accuracy, fast measurement speed,
and full-field inspection. It consists of a pattern projection system and an image
acquisition system. The inspected surface is illuminated by a fringe pattern from the
projection system. Fringes distorted by the surface is recorded by the image
acquisition system at a different viewpoint. With triangulation methods or suitable
identified by a unique code and therefore the ambiguity does not occur. The encoding algorithms can
be further divided into two categories, namely temporal encoding algorithms [1-3] and spatial encoding
algorithms [4-5]. Algorithms that use temporal methods project a sequence of patterns with different
number of stripes to the inspect surface temporally. Intensity of the stripe on the image is coded in
binary or gray intensity levels. Each intensity level is assigned to a character. Thus, a code word, or a
stream of coded characters, is created by the sequent projections. Stripes are identified by the code
words if the code words are unique. Systematic accuracy can be as high as one pixel, depending on the
number of projections. Again, the measuring procedure is time consuming and impractical to on-line
inspection. In the spatial encoding algorithms, stripes are generally encoded by colors. A color CCD
camera is utilized to record the color-encoded strips. The color illumination provides additional degree
of freedom to identify the stripes. Thus, the stripe colors can be arranged in a specific order [5]. Each
stripe is then distinguishable by this order.
Approaches using color-encoded projection and those using fringe projection evaluated by Fourier
transform method are both one-shot measurements, and therefore both are desirable to inspect dynamic
objects. To analyze surfaces with large depth discontinuities, it seems that the color-encoded projection
is more practical because the unwrapping ambiguity does not occur. However, systematic precision of
the color-encoded projection is generally not high enough since the measurement accuracy is highly
related to the strip width.
In this paper, a method using multiple fringe projections from different viewpoints for finding the
absolute shape of an object is proposed. In this method, surfaces with large depth discontinuities can be
identified without ambiguity. Shadowing caused by tilted fringe projection can be eliminated as well.
The other advantages of the proposed measurement system are: (1) large depth-of-field in the
projection system; (2) very low fringe distortion (even for a large field of view); and (3) robust
performance to analyze dynamic objects.
13. PRINCIPLE OF MULTIPLE FRINGE PROJECTIONS
Shown in Fig. 1 is the Schematic diagram. The inspected object is projected with two color fringe
patterns at the same time from two different viewpoints. In our setup, a set of red fringes and a set of
green fringes were selected as the projected patterns. A color CCD camera was used to record the
projected fringes. Shown in Fig. 2 is the recorded image, in which a lid was projected with two sets of
color fringes. The recorded image was separately to three color channels: the red, green, and blue.
Figure 3(a) and (b) illustrates the images separated in the red channel and blue channel, respectively.
For surfaces with depth discontinuities, phases can be unwrapped without ambiguity by comparison of
unwrapped to obtain the absolute phases xd. The unwrapped maps are shown in Fig. 5(a) and
(b), respectively. For each color pattern, it is difficult to directly distinguish the local fringe order when
discontinuity is larger than its equivalent wavelength. Thus, as depicted in Fig. 5, the uncorrected phase
jumps occurred. The uncorrected phase jumps could be identified by comparison of the channel images.
The absolute phase map for the red channel was corrected with reference of the green channel, as
shown in Fig. 6.
15. CALIBRATION-BASED PROJECTED FRINGE PROFIOMETRY
The schematic configuration of our proposed measurement system is given in Fig. 7.
A fringe pattern that lies in the XgYg plane with fringes normal to axis Xg is projected
to the tested object. Accurate detection of the fringe deformation is obtained by the
CCD camera. The CCD sensor array is located in the coordinate system RC, Shape of
the tested object is identified in world coordinate system XYZ. The origin of the
camera coordinate system, UVW, is the nodal point of the imaging lens, while the
origin of the projection system, XgYpZp, is the nodal point of the projection lens. Axis
W and Zp coincides with the optical axis of the imaging lens and projection lens,
respectively. The calibration scheme can be divided into two parts, depth calibration
and lateral calibration. In the procedure of depth calibration, the correspondence
between the detected phase and the depth of the surface, namely phase-to-depth
conversion, is carried out. A similar procedure for lateral calibration is then performed
to find the depth-to-transverse conversion.
A standard optical flat is applied to perform phase-to-depth calibration of the optical system. The flat
surface was made from a steel block. Sufficient surface diffusivity has been achieved through chemical
etching processing. As shown in Fig. 8, a sinusoidal fringe pattern is projected onto this flat surface
perpendicular to the z direction via the projection optics, and a CCD detector obtains the image on
the flat surface. The phase measurement is repeated as the flat is successively translated to different
depth position (at plane z = zi) and stops when certain limit position is reached. Phase extraction on
the flat surface is evaluated using the Fourier Transform method, and thus the computation of the phase
by the inverse trigonometric function provides only values lie between -and . Phase unwrapping is
inevitable to eliminate these discontinuities and to produce the true phase from modulo 2data. After
this processing, a series of absolute phases and the associated depths are then obtained at each pixel
location. With the subsequent curve fitting process, phase-to-depth relation Z() at each pixel is
determined.
In the procedure of lateral calibration, two mutually orthogonal sinusoidal gratings are
unwrapped without ambiguity by comparison of the separated images, too. It requires only one
measurement frame to inspect discontinuous surfaces. This makes it possible for a single-shot
measurement of dynamic objects with discontinuities.
23. H. O. Saldner and J. M. Huntley, “Profilometry using temporal phase unwrapping and a spatial
light modulator-based fringe projector,”Opt. Eng. 36, 610-615 (1997).
24. D. R. Burton and M. J. Lalor,“Multichannel Fourier fringe analysis as an aid to automatic phase
unwrapping,”Appl. Opt. 33, 2939-2948 (1994).
25. Y. Hao, Y. Zhao, and D. Li, “Multifrequency grating projection profilometry based on the
nonlinear excess fraction method,”Appl. Opt. 38, 4106-4110 (1999).
26. E. B. Li, X. Peng, J. Xi, J. F. Chicharo, J. Q. Yao, and D.W. Zhang, “Multi-frequency and
multiple phase-shift sinusoidal fringe projection for 3D profilometry,”Opt. Express 13,
1561-1569 (2005).
27. M. Takeda, Q. Gu, M. Kinoshita, H. Takai, and Y. Takahashi, “Frequency-multiplex
Fourier-transform profilomery: a single-shot three-dimensional shape measurement of objects
with large height discontinuities and/or surface isolations,”Appl. Opt. 36, 5347-5354 (1997).
28. J. L. Li, H. J. Su, and X. Y. Su,“Two-frequency grating used in phase-measuring profilometry,”
Appl. Opt. 36, 277-280 (1997).
29. W. H. Su, and H. Liu,“Calibration-based two frequency projected fringe profilometry: a robust,
accurate, and single-shot meaurement for objects with large depth discontinuities,”Opt. Express
14, 9178-9187 (2006).
(a) (b)
Figure 3 Image separated from (a) the red channel, and (b) the green channel.
(a) (b)
Figure 5 Unwrapped phase map for (a) the red channel, and (b) the green channel.
Figure 7 Coordinate systems in a projected fringe profilometry.
1
2
3
3 2
1
Figure 9 Depth-to-transverse calibration in a projected fringe profilometry system.
1
2
Figure 11 Measured 3D surface profile reconstructed by the corrected absolute phase map.
system. The projection system generates a sinusoidal fringe pattern on the inspected
surface. Phases of the fringes recorded by the image acquisition system at a different
viewpoint can be analyzed to reconstruct the 3D shape. With proper phase-extraction
schemes [3-6] and calibrations, depth accuracy better than one part in ten thousandth
of the field of view can be achieved even with excessive image noises [8-10].
One of the major studies in the development of 3D inspection is the accurate
measurement of dynamic objects. A high-speed camera with proper a projection
system might be a selected resolution. However, it is still a challenge to observe a
dynamic object with ultra fast speed even though a high-speed video camera is
utilized. The observed image is blurred by uniform linear motion. Image processing
becomes an inevitable procedure to remove blurs in order to recover the absolute
phase.
In this paper, we propose a method to retrieve 3D shape using the projected fringe profilometry for an
image blurred by uniform linear motion.
19. PHASE EXTRACTION
The image of fringes projected to the tested surface obtained by the sensor array is
described as
       
         ],
2
[],
2
[
,
2
1
,
2
1
,
],
2
cos[,,,
yxx
d
jyxx
d
j
eyxbeyxbyxa
yxx
d
yxbyxayxI





, (4)
where a(x, y) is the background intensity, b(x, y) is the modulation amplitude, d is the
period of the projected fringes obtained by the CCD camera, andis distorted phase
of the fringes. Eq. (4) can be represented as
        xdjxdj eyxbeyxbyxayxI
 2
*
2
,
~
2
1
,
~
2
1
,,

 , (5)
where ),(),(),(~ yxjeyxbyxb  , and“*”denotes the conjugate operation.
The one-dimensional Fourier transform of Eq. (5) with respect x-axis is realized as
    ),1(~
2
1
),
1
(
~
2
1
,},{ * y
d
fBy
d
fByfAyxI xxx  , (6)
where   ),(~},~{ yfByxb x . The fundamental component, ),1(~
2
1
y
d
fB x  , can be carried
out with a suitable band-pass filter.
The inverse Fourier transform of the fundamental component is expressed as,
     ],
2
[
2
1 ,
2
1
),(
~
2
1
)},
1
(
~
2
1
{,
yxx
d
jx
d
j
x eyxbeyxbyd
fByxs
   . (7)
Phase distribution from Eq. (7) is then given by
    



 
}{Re
}Im{
tan, 1
x,ys
x,ys
yx , (8)
where Im{} and Re{} represents the image part and real part of the complex signal.
Note that phase evaluation gives principle values ranging from–andand has
discontinuities with 2phase jumps. t needs to be unwrapped to obtain the absolute
phases xd. After a process of so-called phase unwrapping [11], the absolute
phase values can be identified as
 Unwrap . (9)
22. CONCLUSION
In summary, we have demonstrated a method for finding a 3D shape from an image blurred by
uniform linear motion. It provides a robust performance to analyze dynamic objects. It requires only
one measurement frame to inspect discontinuous surfaces. This makes it possible for a single-shot
measurement of dynamic objects with discontinuities.
REFERENCE
13. G. Indebetouw, “Profile measurement using projection of running fringes,”Appl. Opt. 17,
2930-2933 (1978).
14. V. Srinivasan, H. C. Liu, and M. Halioua, “Automated phase-measuring profilometry of 3-D
difuse objects,” Appl. Opt. 23, 3105-3108 (1984).
15. M. Takeda and K. Mutoh, “Fourier transform profilometry for the automatic measurement of 3-D
object shaped,” Appl. Opt. 22, 3977-3982 (1983).
16. X. Su, and W. Chen, “Fourier transform profilometry: a review,”Opt. Lasers Eng. 35, 263-284
(2001).
17. K. G. Larkin and B. F. Oreb, “Design and assessment of symmetrical phase-shifting algorithms,”
J. Opt. Soc. Am. A 9, 1740-1748 (1992).
18. V. Y. Su, G von Baly, and D. Vukicevic, “Phase-stepping grating profilometry: utilization of
intensity modulation analysis in complex objects evaluation,”Opt. Commun. 98, 141-150 (1993).
19. Y. Surrel, “Design of algorithms for phase measurements by the use of phase stepping,”Appl.
Opt. 35, 51-60 (1996).
20. F. Chen, G. M. Brown, and M. Song, “Overview of three-dimensional shape measurement using
optical methods,” Opt. Eng. 39, 10-22 (2000).
21. W. H. Su, H. Liu, K. Reichard, S. Yin, and F. T. S. Yu, “Fabrication of digital sinusoidal gratings 
and precisely conytolled diffusive flats and their application to highly accurate projected fringe
profilometry,” Opt. Eng. 42, 1730-1740 (2003).
22. H. Liu, W. H. Su, K. R., and S. Yin, “Calibration-based phase-shifting projected fringe
profilometry for accurate absolute 3D surface profile measurement,” Opt. Commun. 216, 65-80
(2003).
23. D. C. Ghiglia and L. A. Romero, "Robust two-dimensional weighted and unweighted phase
unwrapping that uses fast transforms and iterative methods," J. Opt. Soc. Am. A 11, 107- (1994).
Figure 1 Optical geometry of the projected fringe profilometry.
Figure 2 Phase-to-depth correspondence measured from proposed calibration scheme.
Figure 5 The restored image from Fig. 4.
Figure 6 Phase extraction by Fourier transform method.
