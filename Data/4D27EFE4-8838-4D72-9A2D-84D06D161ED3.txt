 I
中文摘要 
 
在語者識別中，如何能夠訓練出強健的模型是非常重要的，因為辨識時必須決定出測
試語句最可能的語者模型為何。目前最常用來建立語者模型的方式為高斯混合模型，而標
準的最大相似度準則亦是最常用來推演模型參數的法則。最大相似度估測的方法是利用單
一語者的訓練語料去訓練出此語者之模型，跟其它語者的訓練語料並無關係，然而此方法
並未考量到訓練時模型間彼此的關係。縱然最大相似度估測在模型參數訓練完成後，使得
語音特徵向量落在對應的聲學特性上，卻無法保證在有限的訓練語料下得到最佳模型參
數，因而辨識上產生混淆。反觀鑑別式訓練的方法，其利用最小化分類錯誤為目標來取代
最大相似度，使較混淆的模型能夠更有各自的代表性。在本計劃中，我們利用三個準則改
善傳統最小錯誤鑑別式方法，不僅降低其複雜性並加快訓練的速度，亦提高了辨識率。 
 
關鍵詞：最小分類錯誤、最大相似度估測 
 
Abstract 
 
    Speaker identification is the process of finding the registered speakers from a given 
utterance. Therefore, how to train the model effectively is an important issue. The standard 
maximum-likelihood design criterion is to use a training sequence of observations to derive the 
model parameters of the Gaussian mixture model, which is the most popular method for 
text-independent speaker identification. However this method only considers the likelihood for a 
single speaker. When the training data are limited, it is very probable that it will reach a local 
optimal solution. To compare the likelihood against those of similar utterances and maximize 
their likelihood differences, the minimum classification error method provides a more 
discriminative algorithm for modeling. By the three methods proposed in this project, the 
performance of the traditional minimum classification error algorithm is improved. 
 
Keywords: Minimum Classification Error (MCE), Maximum Likelihood Estimation (MLE). 
 2
2.2 更新語者模型 
1
1 exp( )
( )
kd
l dk γ θ= + − +  
'( ) ( ) (1 ( ))k k kd d dγ= ⋅ ⋅ −A A A  
再來我們定義一個 Loss Function ( )l dk 去
描述正確語者模型與其它競爭語者模型的
關係，再對模型參數調整使得 ( )l dk 最小
化，這樣可以得到較好的語者模型。我們通
常令θ =0，γ ≥1。 
再來用下列公式可以重新去調整語者參數
模型 
1 ( ; ) | nn n n Xε+ Λ =ΛΛ = Λ − ∇ ΛA
( ; )( 1) ( )s s smd md s
md
l Xn n λμ μ ε μ
∂+ = − ∂  
( ; )s s s
s s
md s md
l X l d
d
λ
μ μ
∂ ∂ ∂=∂ ∂ ∂   
( ) (1 ( ))s s s
s
l d d
d
γ∂ = ⋅ ⋅ −∂ A A  
( ) ( )         ; 
( )
( ) ( )      ; 
( )
s s s
m m t t md
s s
t mds
s s s s
md m m t t md
s s s
t md
p b x x u s k
B xd
p b x x uW s k
B x
σ
μ
σ
⎧ −− =⎪∂ ⎪=⎨∂ −⎪ ≠⎪⎩
  
 
三、結果與討論 
 
使用傳統的最小分類錯誤方法時會難
以決定競爭語者的數目，當系統有 50 位語
者時，其競爭語者的數目可能設為 5，當系
統有 100 位語者時，其競爭語者的數目可能
設為 20，這樣依據系統人數的不同而要定
義不同的競爭語者數目實在是缺乏方便
性。在改善的最小分類錯誤中，不管系統人
數有多少，只要把門檻值設為 0.8，就可以
得到最佳的辨識結果。 
 
表一、門檻值與辨識率及辨識時間 
調 適
方法 
競爭語
者數目
調適時
間(分) 
Base 
line 
辨 識
率 
5 位 129 94.5%
10 位 215 95% 
20 位 430 96% 
傳統 
MCE 
40 位 721 95.5%
門檻值
0.9 
 
59 
 
94.5%
0.8 217 96% 
改善 
MCE 
0.7 608 
 
 
 
93% 
95.5%
 
由表一得知，當傳統的最小分類錯誤與
改善的最小分類錯誤在相同辨識率時，改善
的最小分類錯誤所花費的調適時間都比較
少。在最高辨識率 96%時，傳統的最小分類
錯誤所花費的時間為 430 分鐘，而改善的最
小分類錯誤所花費的時間卻為 217 分鐘，至
少省了一半多的時間。因為改善的最小分類
錯誤使用了最有效率的鑑別函式，所以不會
降低辨識率，還有使用門檻值去篩選競爭語
者數目，才不會在每次遞迴調整時競爭語者
數目都固定。 
 
表二、不同語料長度之辨識率 
語料庫 
語者人數
訓練/
測試
(句) 
baseline 改善
MCE 
2/1 57% 77% 
5/2 93% 96% 
MAT2000
100 人 
7/3 97.33% 98% 
TCC300 
300 人 
10/2 94.5% 95.5%
 
另外我們在不同語料庫測試改善最小
分類錯誤方法的效果，由表二可以看出當在
訓練語料句數少的時候，辨識率有高幅度的
增加，所以可證實本計畫所使用的改善最小
