摘要 
由於資訊科技的發達及網路資源的普及，人們透過網路檢索資料已是常態，而與
生命相關的健康資訊更是受到重視，不管是醫療專業人員、疾病患者或關心自我保健
的民眾，皆可透過網路瀏覽數以萬計的網頁文章，搜尋所需要的資訊，甚至藉由線上
問診，以獲得疾病初步診斷，或是就醫相關建議。在專業醫療網站上的問診服務中，
民眾可以透過症狀描述來詢問，醫師可透過症狀做初步診斷，而這些長久累積之問答
記錄，若能有效利用，將可提供民眾疾病知識，或是就醫前之參考，因此，本研究應
用知識本體、關鍵詞彙權重計算及查詢結果排名技術，建構疾病詢答系統，來幫助使
用者更有效率地進行疾病詢答。實驗結果顯示，本研究所提出之疾病症狀領域本體與
排名技術進行搜尋之方式，確實可提高搜尋資料之精確率及呈現較佳的排名效果。 
關鍵詞：知識本體、疾病詢答、資訊擷取、資訊檢索 
 
 
Abstract 
Due to the development of information technology and flood of network resources, it 
is common for people to search information in Internet. Moreover, we pay more attention 
to health information about life. No matter what we are, professional medical personnel or 
patients, we can browse tens of thousands articles through Internet and search the 
information we need. Even more we can get the diagnosis through the interrogation enquiry 
on-line, or the suggestions about taking medical treatment. Because of the interrogation 
enquiry’s service in Internet, people can get answers about some disease questions through 
the description of symptom. Doctors can also give prior diagnosis through the symptom. If 
the documents of dialogues can be used efficaciously, it would offer the knowledge of 
disease to people, or be the reference materials before taking medical treatment. Therefore, 
this study is to develop an ontology-based FAQ prototype in disease consultation. Through 
information extraction and retrieval, we hope it can help user to consult medical treatment 
on-line more effectively. Our experiments show that this ontology-based FAQ system in 
diseases consultation can truly improve the precision rate of the retrieved FAQs along with 
an effective ranking presentation. 
Keywords: Ontology, Disease Consultation, Information Extraction, Information 
Retrieval 
 2
二、 進行查詢時，使用者僅需輸入自然語言，系統即可自動分析該問句，產生合
適之關鍵詞進行查詢，使得所需資料能依其相關性做排序。 
三、 以知識本體支援進行疾病領域方面知識查詢時，所得資料之準確率能優於一
般關鍵字搜尋方式。 
四、 分析影響資料搜尋準確率與排序之因素，進而提高搜尋效果。 
 
以下各節將包括相關的文獻探討，例如本體論、資訊檢索、及 FAQ 相關系統；
接著探討疾病詢答 FAQ 系統建構，包括系統架構、資料前處理、『疾病症狀』知識
本體的架構、及查詢結果之呈現；再來就是實驗與結果分析，最後針對研究的結果進
行討論並提出建議。 
 
貳、文獻探討 
一、本體論 
 
(一) 本體論之定義 
本體論(ontology)一詞最早是屬於哲學的範疇，是研究『存有的知識（knowledge 
of being），因此本體論是論述事物與探究事物本質的學問，在真實世界的每一個領
域（domain）都會有一個被定義的本體論，這就是知識本體。而同一個語彙，在不同
的時代背景、不同的領域，其意義就有可能不一樣。本體論在電腦科學是指某一個領
域知識中相關的語彙的集合，這些專業語彙都有明確定義與描述，可以用來陳述領域
知識中的某一概念，也可以用來描述概念與概念之間的關係。以下列出學者對於本體
論的看法： 
 
1. Neches, et al. [3]：本體論提出建構領域知識的基本規則，以定義基本用語及其關
聯的方式構成目標領域的辭彙。 
2. Wielinga and Schreiber [4]：本體論是一種理論，探索何種實體能存在知識代理人
的思想中心。  
3. Gruber [5]：本體論是概念的明確描述，源自哲學，藉由定義專有名詞的集合來
描述本體。本體論也是為了塑造領域知識的模型或論述而定義的代表元素。 
 
由以上各學者的看法可知，本體論乃是針對領域知識，將其中各種組成元素
下一明確的定義，而此定義需有規格化的陳述，如此方能在不同代理人之間溝
通，並且可進行概念的共享與共創。 
 
(二) 本體論之組成 
目前不論以何種語言來描述本體，它們的結構都極為類似，多數學者均認為由本
體論以下四種元素組成：  
 
1. 實例(individual)：實例是本體論中最明確、最底層的物件，不同領域會有不同的
描述，可能包含具體的物件，如動物、植物、桌、椅等，或者是數字、文字等。  
2. 概念(concept)：或稱類別(class)，概念是由多個底層物件(實例)所組成的集合，藉
 4
    
    圖 1、本體論語言階層[8] 
      
二、資訊檢索 
 
（一） 中研院中文自動斷詞系統 
目前國內中文斷詞的研究中，中研院中文詞知識庫小組(CKIP)發展出的中文自動
斷詞系統，已能對中文作精準的斷詞[10]，該系統具備下列功能：  
 
1. 自斷詞功能。  
2. 詞類自動標記功能：該系統將中文詞性分成：形容詞(A)、連接詞(C)、副詞(D)、
名詞(N)、感歎詞(I)、介詞(P)、語助詞(T)、動詞(V)八大類，可再細分成 46類。  
3. 選擇不同的詞典，做為斷詞及詞類標記的參考。 
 
（二） 詞彙權重計算 
TF(term frequency)與IDF(inverse document frequency)，是由Salton and McGill[11]
所提出來的概念。提出該架構的理由，是因為每個文件中的詞彙佔整篇文件的重要
性，是不太相同的，因此TF和IDF的概念就由此產生了，這兩者的結合，就可以衡量
詞彙在文章中的重要性。TFIDF以詞彙出現在文件中的頻率TF，乘上詞彙出現的文件
佔所有文件中的篇數比值倒數IDF。由TF可以獲得詞彙ki在文件dj中的重要程度；IDF
則可估算ki在各文件中出現的情況，若ki出現較多文件，IDF值會很小，表示ki到處可
見，對dj的重要性似較小。計算方式如下： 
        iiji IDFTFW ×=,                             (1) 
 
      
)( ,
,
jij
ji
i freqMAX
freq
TF =                           (2) 
 
i
i df
NIDF log=                             (3) 
 
其中，Wi,j為詞彙ki在文件dj之權重，freqi,j為詞彙ki出現在文件dj的頻率，MAX(freq)為
所有在文件dj中出現的詞彙的最大頻率。N表示文件集中所有文件篇數，dfi表示文件
 6
∑∑
∑
==
=
×
×
=
•
•=
n
i
qi
n
i
ji
n
i
qiji
j
j
j
WW
WW
qd
qdqdsim
1
,
2
1
,
2
1
,,
),(
ρρ
ρρ
                   (5) 
 
三、 FAQ相關系統 
 
現今許多網站都有提供相關的 FAQ 系統讓使用者查閱，依網站的性質提供不同
的內容，如：醫療諮詢、商業客服、特定領域 FAQ查詢等，本節簡述幾個常見的 FAQ
系統。 
 
（一） 自動化 FAQ回答系統(automated FAQ answering) 
自動化 FAQ 回答系統將每個 FAQ 裡的字詞分成四類：需要關鍵字(required 
keywords)、選擇關鍵字(optional keywords)、不相關字(irrelevant words)、被禁止關鍵
字(forbidden keywords)。在尋找 FAQ時即依此來作比對，亦即可用的 FAQ的需要關
鍵字必須完全出現在使用者的問題內；選擇關鍵字則可有可無；不相關字相似於資訊
取得(information retrieval)系統中的停止字(stop words)，可以完全忽略；被禁止關鍵字
則是針對不能出現在使用者問題裡的關鍵字。使用者輸入問題後，比對 FAQ 裡的各
同分類的字詞，即可找出符合的 FAQ 提供給使用者[13]。  
 
（二） FAQ發現者系統（FAQ Finder） 
FAQ發現者系統是個以自然語言做輸入的網頁為主(web based)的查詢系統，它以
Usenet FAQ檔案內容為知識庫，透過智慧型萃取系統找出與使用者問題相關的 FAQ 
檔案，交由使用者從中選擇一個 FAQ檔案，系統接著將此 FAQ 檔案，交由第二階段
處理，找出最符合使用者問題的 FAQ。第二階段處理包含計算 4個公制(metrics)：詞
向量相似度 (term vector similarity)、覆蓋範圍 (coverage)、語意相似度 (semantic 
similarity)、問題型態相似度(question type similarity)，分別給予 0.25的權重，每個公
制值都介於 0~1之間，並依據最後線性加總值做為排名，值愈大表示愈符合使用者的
問題。其中，詞向量相似度就是使用 VSM模型，以 TFIDF計算字詞權重，用以計算
相似程度；覆蓋範圍就是使用者關鍵詞出現於 FAQ問句內次數與 FAQ問句所有關鍵
詞出現次數之百分比；語意相似度就是使用 WordNet 的語意網路知識庫為基礎，計
算查詢問題與 FAQ 問題關鍵詞間的語意相似程度；問題型態相似度以系統內設定的
相似度矩陣計算查詢與 FAQ的彼此問題型態相似程度[14]。  
 
（三） FAQ分享系統(FAQshare) 
FAQ分享系統是一個應用在教學的 FAQ系統，此系統具有四個重要的功能：1.
讓使用者提出問題；2.回答問題；3.票選問題；4.票選解答。使用者在此系統中，不
僅能提出問題，也能回答別人的問題。透過票選問題的機制，若一個問題得到較多票
數，表示此問題是大家最關心的，也就能表示這是個常見問題。若使用者認為解答的
內容是正確的，則可以投票給這個回答，系統最後就可以依據使用者最關心的問題與
解答最正確的這二個因素，將查詢結果排序後呈現予使用者[15]。 
 
 8
筆問答記錄。 
 
 
圖 3、系統架構 
（二） 斷詞處理 
由搜尋代理人取回網頁資料後，經由連線傳送本文至中研院開發之『中文斷詞系
統』(CKIP)伺服器進行斷詞及詞性標記[10]，再根據詞性標記去除停止字後統計詞彙
出現頻率。關鍵詞萃取經過斷詞後，即可將每筆 Q_A pair存到資料庫中，惟為有利
於後續之資料查詢，我們先萃取出每筆 Q_A pair的關鍵詞，並轉換為內部表示一致
關鍵詞，以作為索引。關鍵詞萃取處理包含三個步驟： 
1. 詞彙萃取：參考斷詞問句與斷詞解答，將每個斷詞後的詞彙經由領域知識本體判
斷是否屬於領域知識本體詞彙，若是則加到問句關鍵詞或解答關鍵詞中。 
2. 一致性偵測：關鍵詞如果不是系統內部一致表示的關鍵詞，即將之轉換為內部一
致表示的關鍵詞。 
3. Q_A pair轉換與儲存：針對問句總關鍵詞及解答總關鍵詞，依照斷詞處理時，所
進行的詞頻統計各別作排序。並計算問句關鍵詞與解答關鍵詞中關鍵詞個數。最
後，將每筆 Q_A pair的相關資料存到對應的資料庫表格中。 
 
三、『疾病症狀』知識本體的架構 
 
本研究根據『中央健康保險局北區分局』，網站內就醫指南的症狀分類[17]，及
使用 Protégé編輯工具，建立『疾病症狀』本體論，說明如下： 
 
 10
 
圖 4、疾病知識本體架構（中央健康保險局北區分局，2008） 
 
     
圖 5、實例與其註解關聯圖 
  
 
圖 6、疾病症狀領域本體概念關聯圖 
 12
稱為五十肩，是指盂肱關節的主動和被動動作受到限制的一種臨床症狀。因為外
傷或勞損傷而引起肩關節疼痛，導致肩關節不能主動或被動活動』，以及在
point:sameAs欄中輸入『冰凍肩、冷凍肩、粘黏性肩關節囊炎』。 
3. 將各類別之實例依上述步驟一一輸入，就可完成建構。  
圖 8為展示眼睛部位的疾病症狀知識本體及概念實例。 
 
   
 
圖 8、眼睛部位的疾病症狀知識本體與實例 
 
 
四、查詢結果之呈現 
 
為了減少搜尋的時間與提升搜尋結果的品質，我們只採用重要的關鍵詞作為找尋
解答的依據，並經由系統找出與查詢問句相似的問答記錄後，再分別計算排名指標
值，以進行排名呈現。為了找出較重的關鍵詞，我們首先計算每個查詢關鍵詞的
TF×IDF值，並據以排序，若查詢者問題有 5 個以上的關鍵詞，則取前 5 個關鍵詞做
搜尋。最後針對搜尋出來的問答記錄，依據匹配值加以排序，而匹配值的計算，如公
式(6)；本研究以實驗方式決定統計相似值(SSV, statistic similarity value)、相容值(CV, 
compatibility value)及涵蓋值(CR, coverage ratio)等三個量測值的權重，WSSV、WCV、
WCR。匹配值愈高表示此筆問答記錄與查詢的問題愈相似，系統即依計算出的匹配值
將問答記錄由大到小排序，提供給查詢者。公式(6)之SSV、CV、CR，分別在以下各
 14
本研究定義 CR 為查詢問句的關鍵詞出現在問答記錄問句關鍵詞的比率。
表示某一個查詢問句的關鍵詞集合，而{ mq qqqK ,...,, 21= } { }nf fffK ,...,, 21=  表示某一
個問答記錄問句的關鍵詞集合，則涵蓋值 CR即可依公式(8)計算。 
 
f
qf
K
KK
CR
∩=                             (8) 
     
其中， fK 為 集合中關鍵詞的數量，fK qf KK ∩ 為兩個集合中同時出現的關鍵詞數
量，當一查詢問句包含『玻璃體，視網膜，胰島素，糖尿病』四個關鍵詞，而某一問
答紀錄包含『玻璃體，胰島素，視力，血糖』四個關鍵詞，此問答紀錄與查詢問句中
同時出現『玻璃體』與『胰島素』，即此問答紀錄涵蓋了這二個查詢關鍵詞，佔此紀
錄問句關鍵詞的比率 2/4＝50%，也就是當一問答紀錄中涵蓋愈多查詢關鍵詞，且佔
此問答紀錄問句關鍵詞比率愈高，表示該問答紀錄與查詢問句愈相近。 
 
肆、實驗與結果分析 
    
本節設計一些實驗來評估本系統於搜尋解答的效能，主要目的在分析是否能夠透
過知識本體支援來提供較佳的解答品質，以及匹配值權重分配對於排名的影響。本研
究的實驗包含三部份，第一為評估知識本體支援機制在提升精確率（precision rate）
的效果，第二為探討計算匹配值時，各匹配值因素間的權重應如何分配才能獲得較佳
的排名結果，第三則為評比本系統查詢介面與 Google搜尋引擎之查詢結果之成效。 
 
一、 知識本體支援機制對精確率之影響  
本實驗將比較採用知識本體支援處理使用者查詢與未採用時兩者在精確率的異
同。實驗中從問答記錄中挑選 20筆查詢問題(牙科、眼科、骨科、家庭醫學科各 5筆)
作為測試案例，經由判斷查詢找出的問答記錄是否與使用者查詢相關，從中計算精確
率。圖 10為系統執行實驗的畫面，而表 1為本次實驗的結果，從中發現知識本體支
援的精確率高於沒有知識本體支援的精確率，而且當匹配值門檻大於 0.6，此時具知
識本體支援所萃取出的 46 篇問答記錄都是與使用者問題相關的，因此，精確率達到
100%。 
 
           
檢索所得篇數
關篇數檢索所得與主題有精確率 =                     (9) 
 
 16
∑
=
×=
n
k
kk EWSWG
1
                         (11) 
               
為了將其正規化，先計算出最佳排名得分Gmax與最差排名得分Gmin，當系統找出
的文件是以專家認為最符合使用者查詢的文件呈現在愈前面的排序方式則為最佳排
名的情況，反之為最差排名之情況。因此，正規化排序得分比Gnormal即如公式(12)，
正規化得分比越高，代表排名越接近最佳排名位置。 
 
%100
minmax
min ×−
−=
GG
GGGnormal                      (12) 
 
表 2為一個排名範例，此時系統找出 5筆問答記錄QA(QA1、QA3、QA9 、QA11 、
QA22) ，系統呈現排名的集合（S1, S2, S3…, S5）＝（1, 2, 3, 4, 5），依公式(10)此排
名集合權重為{101, 104/5, 103/5, 102/5, 101/5}，設專家排名(E1, E2, E3,…, E5)=(1, 3, 1, 2, 
3)，此排名順序集合{1, 2, 3}之排名權重為{101, 102/3, 101/3}，此時的最佳排名為QA1、
QA3、QA9 、QA11 、QA22={1, 1, 2, 3, 3}，如表 3所示；反之，最差排名＝{3, 3, 2, 
1, 1}，如表 4所示。 
 
因 此 ， 此 排 名 的 正 規 化 排 序 得 分 比 ， 依 公 式 (12) ， 可 以 得 到
%100
minmax
min ×−
−=
GG
GGGnormal =72.12%，表示此排名有 72.12%的比率接近最佳排名的情
況。 
 
三、 實驗結果   
本實驗從問答記錄中挑選 20筆查詢問題(牙科、眼科、骨科、家庭醫學科各 5筆)
作為案例，並嘗試引入不同權重來進行多組測試，將查詢後的結果，交由專家進行排
名，以專家排名後結果計算其排名得分率，得分率最高者，表示該組權重分配的效果
具有較佳的排名準確率，依此作為權重的分配。本研究認定SSV、CV、CR對排名都
應該具有特定影響力，因此，設定每個權重的最低值為 0.2。經由此次實驗結果，本
系統設定權重分配為，WSSV=0.4，WCV=0.3，WCR=0.3（編號 11），如表 5所示。 
 
   
 表 2、排名得分範例 
文件 系統呈現
排名 
系統呈現排名
權重 
專家排名 專家排名 
權重 
排名得分
QA1 1 101 1 101
QA3 2 104/5 3 101/3
QA9 3 103/5 1 101
QA11 4 102/5 2 102/3
QA22 5 101/5 3 101/3
168.478 
 18
統對於使用者搜尋疾病詢答之效益上是有所提升的。 
 
表 5、權重分配實驗 
編號 WSSV WCV WCR G normal (%) 
1 0.2 0.2 0.6 69.34 
2 0.2 0.3 0.5 66.12. 
3 0.2 0.4 0.4 67.56 
4 0.2 0.5 0.3 69.37 
5 0.2 0.6 0.2 70.74 
6 0.3 0.3 0.4 79.58 
7 0.3 0.2 0.5 82.36 
8 0.3 0.4 0.3 70.35 
9 0.6 0.2 0.2 79.45 
10 0.5 0.2 0.3 83.11 
11 0.4 0.3 0.3 85.23 
12 0.3 0.2 0.5 71.68 
13 0.3 0.5 0.2 73.12 
14 0.4 0.4 0.2 80.26 
15 0.5 0.3 0.2 83.32 
16 0.4 0.2 0.4 79.32 
     
 20
伍、結論 
 
本研究以疾病症狀知識本體為基礎，透過知識本體支援，將 Search Agent取回之疾病詢
答資料，轉換成系統內部一致表示法並儲存，以利後續使用者查詢。查詢時，使用者輸入自
然語言問句，經由中文斷詞後，交由知識本體轉換成一致化關鍵詞，交給系統查詢。首先利
用 TF×IDF，找出查詢中的重要關鍵詞，並以之進行查詢，取出相似的問答記錄，並依相容值、
統計相似值、包含值的權重對保留下來的問答記錄進行排名。 
從實驗結果中發現，經由知識本體支援，來刪除不必要的查詢關鍵詞，及關鍵詞一致表
示法，確能提升問答記錄萃取時的正確性，也同時有助於提升系統查詢時的精確值。而萃取
出的問答記錄透過匹配值計算後加以排名，更能符合正確排名的結果，使用者即可在前面查
詢結果中找到所需的資訊，減少篩選資訊的時間。總結本研究特點如下：  
 
一、 資訊經由系統前置處理程序後，有利後續查詢的一致化處理。 
二、 藉由知識本體支援，能將不必要的查詢關鍵詞去除及轉換成一致性表示法，可達到更準
確的查詢結果。 
三、 藉由匹配值的計算，讓萃取出的問答記錄排名結果更貼近使用者查詢的目標。 
四、 藉由本系統的發展，能提供使用者更有精準、正確與更佳排名結果的解答，以減少使用
者閱讀資訊的負擔及時間。且只要建構不同知識本體，即可提供各式領域的查詢之用。  
 
在學術意涵方面，本研究將知識本體方法運用於疾病詢答系統的建置上，把涉及到的相
關資源，利用知識本體之抽象概念、具像實例表達出來，並利用關係的聯結讓每個實例、每
個資源被充分的註解。透過實作，除了利用知識本體的方法將疾病症狀加以建構之外，並結
合 Search Agent之開發、CKIP斷詞系統提供之服務、TF×IDF詞彙權重計算、疾病本體的支
援、向量空間模型之相似度衡量、語意查詢服務程式及介面的開發，發展出疾病詢答系統，
以提供查詢服務。此外，透過排名機制，將搜尋結果以符合查詢問句之相似度高低加以排列，
有效提供使用者高品質的搜尋資訊。藉著本系統對於網路資源、知識本體及資訊檢索的整合，
達成了知識集中及分享的功能。它所提供的資訊，可幫助使用者在網頁上獲得醫學健康方面
諮詢，並避免相似問題重複回答，及使用者提出諮詢後，免於等待醫護人員回覆之時間，提
升使用者在網路上進行疾病詢答之效率，此為本研究之貢獻。 
 
在實務意涵方面，本研究提出一套運用在疾病詢答領域的問答記錄檢索系統，並引用知
識本體支援來幫助過濾及轉換成一致性表示的關鍵詞，能減少一般 FAQ系統萃取出不相關的
問題，提升回覆的精確值及正確性。另外，系統查詢結果呈現上，納入匹配值計算後加以排
名，能夠減少使用者篩選資訊的時間。 因此，本系統能在查詢回覆上，能提供更精準、更正
確、更佳排名呈現的查詢結果。公司的產品 FAQ或其他領域 FAQ系統也能透過本系統快速
的處理包裝，並建構屬於自己的領域知識本體，以提供更完善的查詢服務，如此將可以減少
大量客戶服務人力的支出。 
本研究建構之本體論疾病詢答系統，雖經驗證所提之方法確實可行，但仍有未及之處，
在此提出以供後續研究之參考： 
一、 使用者輸入錯誤將導致系統無法正確擷取關鍵詞，目前未進行處理，未來若能運用
模糊理論，計算其歸屬程度，更能增加系統實用性。  
22 
[14] Lytinen, S., and Tomuro, N., “The use of question types to match questions in FAQFinder,” 
2002 AAAI Spring Symposium on Mining Answers from Texts and Knowledge Bases, CA: 
Stanford, 2002. 
[15] Van, H.L., and Trentini, A., “FAQ share: a frequently asked questions voting system as a 
collaboration and evaluation tool in teaching activities,” Proceedings of the 14th international 
conference on Software engineering and knowledge engineering, Ischia, Italy, 2002. 
[16] KingNet國家網路醫院，http://hospital.kingnet.com.tw/，2008。 
[17] 中央健康保險局北區分局，http://www.nhinb.gov.tw/，2008。 
24 
二、參加會議經過 
七月二日早上 9:00 由桃園機場搭機赴直飛泰國曼谷，下飛機後即轉搭巴士到旅館。經
過休息後，於七月五日至會場報到，地點設於 Landmark 七樓，當日 8 點開始及下午均有分
組論文發表。圖 2 為本人於報到會場前留影。 
 
 
圖 2. 本人於報到會場前留影 
 
本人之論文發表乃被排在五日上午 8:20 至 10:10，屬於管理資訊系統 (Management 
Information Systems) A3 之場次第七篇，主持人為 North Dakota State University 的 Prof. Ron 
Johnson。本場次共有七篇文章，除第二篇缺席外，其餘均準時出席報告，第一篇討論供應
鍊管理之議題，第三篇討論電子商務調適問題，第四篇提供醫療機構之知識管理研究結果，
第五篇討論人力資源問題，第六篇研究辦公室資訊系統與辦公室自動化的優缺點，現場討論
熱烈，圖 3 為本人在論文發表時現場留影。 
 
A HIERARCHICAL SELF-ORGANIZING MAP NETWORK FOR MOTIF 
DISCOVERY 
 
Jinn-Yi Yeha, Tai-Hsi Wub 
aDepartment of Management Information Systems, National Chiayi University,  
580, Sinmin Road, Chiayi City, Taiwan 600 
jyeh@mail.nyu.edu.tw 
b Department of Business Administration, National Taipei University,  
151, University Road, San Shia, Taipei, Taiwan 237 
taiwu@mail.ntpu.edu.tw 
 
ABSTRACT  
The deoxyribonucleic acid (DNA) sequences have important hereditary information. They are 
composed by four different kinds of nucleotides (A, T, C, and G). The permutation and combination 
of the DNA’s base-pair are significant. The significant information is called Motif which can help 
experts to recognize the blood ties and hereditary disease in medicine. The Motif finding problem is 
to search the important fragment from the DNA sequences. These fragments are retained during the 
evolutionary process. There are more than hundred million base-pairs in the organism. Therefore, to 
find the important fragment becomes a difficult problem. This paper applies a growing hierarchical 
self-organizing map (GHSOM) network to cluster the DNA sequences. It makes the similar 
fragment together and searches the specific fragment in the sequences. Experimental results show 
that the GHSOM outperforms traditional methods such as MEME and Gibbs Sampling. 
Keyword: DNA sequences, Self-organizing map networks, Motif finding problem 
 
INTRODUCTION 
Deoxyribonucleic aid (DNA), ribonucleic acid (RNA), and proteins are important molecules 
for every living being in the world. A DNA molecule is a double-stranded polymer composed of 
four basic units called nucleotides which are adenine (A), guanine (G), cytosine (C), and thymine 
(T). The halves of the double helix structures are held together through the base-pairs: G with C, A 
with T. DNA sequence is a particular arrangement of the base-pairs in the DNA strand. The 
arrangement spells out the exact instructions required to create a particular organism with its own 
unique characteristics. The unusual double helix structure of DNA molecules gives DNA special 
properties which allow the information stored in DNA to be preserved and passed from one cell to 
another and from parents to their offspring (Lu and Han, 2003). 
A DNA motif is defined as a nucleic acid sequence pattern that has some biological 
significance such as being DNA binding sites for a regulatory protein. It is known to recur in 
different genes or several times within a gene. Motifs are fairly short (6 to 20 base-pairs long) and 
hidden amongst a great amount of genomic noise (promoter regions are typically thousands of base-
pairs long). DNA sequences could have zero, one, or multiple copies of a motif. Thus, identification 
of subtle regulatory motifs in a DNA sequence is a difficult pattern recognition problem (Das and 
Dai, 2007). 
Despite the difficulties, numerous motif finding algorithms have been proposed over the last 
few years. Many approaches are based on statistical methods such as expectation-maximization 
(Lawrence and Reilly, 1990), MEME (Craven, 2006； Bailey and Elkan, 1995), regression (Conlon 
et al., 2003), covariance model (Yao et al., 2005), BioOptimizer (Jensen and Liu, 2004), and Gibbs 
sampling (Rouchka, 1997; Casella and Edward, 1992; Liu et al., 1995, Liebert, 2002). Other 
approaches were reviewed in Das and Dai (2007) and Sandve and Drablos (2006) 
This paper applies a growing hierarchical self-organizing map (GHSOM) network to cluster 
the DNA sequences. It makes the similar fragment together and searches the specific fragment in 
the sequences. The rest of this paper is arranged as follows: Section 2 contains the detailed 
within each sequence mutually similar segments of specified width W. The algorithm maintains two 
evolving data structures. One is the pattern description, in the form of a probabilistic model of 
residue frequencies for each position i from 1 to W, and consisting of the variables qi,1, qi,2,...,qi,20, 
indexed by W positions and the 20 possible residues. This pattern description is accompanied by an 
analogous probabilistic description of the background frequencies, p1, p2,...,p20 with which residues 
occur in sites not described by the pattern. The other is a set of positions ak (k from 1 to N) 
constituting the alignment for the common pattern within the sequences. The objective will be to 
identify the best, defined as the most probable, common pattern. This pattern is obtained by locating 
the alignment that maximizes the ratio of the corresponding pattern probability to background 
probability (Liu et al., 1995). 
 
4. Self-organizing map 
The objective of unsupervised learning methods in data mining applications is to identify 
groupings in an unlabeled set of data vectors that share semantic similarities. The self-organizing 
map (SOM) is a general unsupervised tool for the ordering of high-dimensional data in such a way 
that similar items are grouped spatially close to one another (Kohonen, 1982). In this study, we only 
considered the Kohonen’s self-organizing feature maps (SOFM) that consists of a quadratic layer as 
shown in Fig. 2. The SOM network consists of an input layer and the Kohonen layer. The Kohonen 
layer is usually designed as a two-dimensional arrangement of neurons that maps n-dimensional 
input to two dimensions, preserving topological order. That is, the SOM input layer of neurons is 
fully connected to the Kohonen layer. The input neuron send the information, modified according to 
the specific synaptic weight factors, onto a two-dimensional array of neurons which are somehow 
topologically related to each other in a way that neighborhood relationships are defined. 
The whole process is driven only by repeated representations of the input vectors and the 
applied learning rule. The process begins with all network weights initialized to a small random 
value. Training proceeds by repeatedly exposing the network to the entire set of input vectors. The 
Kohonen layer computes the distances between the weight vector for each of the Kohonen neurons 
and the input pattern. The Kohonen neuron that is closest (i.e., minimum distance) is the ‘‘winner’’. 
The neuron responding maximally to a given input is allowed to adjust its weight factors such that 
its response to a repeated stimulation with the same input will be stronger. Few surrounding neurons 
are allowed to participate in this learning step; all other neurons do not adjust their synaptic weights 
during this step. Hence, the algorithm updates the ‘‘winner’’ node and those in the neighborhood 
such that their weight vectors gradually get closer to the current input vector. Thus, the network 
adjusts its internal connections via the weight factors autonomously without reference to external 
information. 
 
 
Fig. 2. Example of a two-dimensional self-organising feature map. 
 
Fig. 3. The hierarchical structure of GHSOM (Rauber et al., 2002) 
 
 The main idea of GHSOM is based on the adaptation to the training data. The adaptation 
quality is measured in terms of the deviation between a unit’s model vector and the input vectors. 
Two different criterions are used for the control of the growth process including quantization error 
(QE) and mean quantization error (MQE). The MQE of unit i is defined as follows: 
0|,|,/1 ≠=−⋅= ∑
∈
ii
Cx
jii CCncxmncMQE
ij
                   (1) 
where mi is a model vector, nc is the number of input vector xj that are elements of the set of input 
vector Ci. The MQE measures the dissimilarity of all input data mapped onto a particular unit and 
will be used to control the growth process of the neural network. Therefore, 
02 MQEMQEi ⋅< τ                            (2) 
where τ2 is a constant fraction value. Alternatively, the QE of the unit may be used instead of the 
MQE, resulting in a global termination criterion as follows: 
∑
∈
−=
ij Cx
jii xmQE                             (3) 
02 QEQEi ⋅< τ                               (4) 
The unit with the highest QE is selected and denotes as the error unit e which is determined as the 
unit with the MQE as below: 
.||||maxarg ⎟⎟⎠
⎞
⎜⎜⎝
⎛ −= ∑
∈ ij Cx
jii
xme                          (5) 
A new row or column of units is then inserted between e and its most dissimilar neighbor d which is 
defined as: ( ) eiiei Nmmmd ∈−= ,||||maxarg                       (6) 
where Ne is the set of neighboring units of e. Fig. 4 shows a graphical representation of the insertion 
process of a GHSOM with the newly inserted units being described as shaded circles. 
 
 
         (a)               (b) 
Fig. 4. Insertion of units (a) row (b) column (Rauber et al., 2002) 
    The input sequence is then sliced by giving a projected length. Fig. 6 shows an example with the 
projected length (M = 7) of motifs. All subsequences of seven connected letters are obtained using a 
sliding window from the given DNA sequences. This will form a set of input patterns. 
 
 
Original DNA sequence: GAGAATGCTATTC ...... AGTTCGATCCA 
Input pattern #1: GAGAATG 
Input pattern #2:  AGAATGC 
Input pattern #3:   GAATGCT 
Input pattern #4:    AATGCTA 
 
Fig. 6. Input patterns (M = 7) from a given DNA sequence (Liu et al., 2006) 
 
After training of GHSOM, the profile analysis is used to calculate the scores of different 
clusters. There are three steps to do the profile analysis as shown in Fig. 7: (1) Line up the patterns 
by their start indexes s = (s1, s2, …, st). (2) Construct a matrix profile with frequencies of each 
nucleotide in columns. (3) Obtain consensus nucleotide in each position which has the highest score 
in column. 
 
  ATACTAgc 
  AcACTtTT 
Alignment  ATcCTATg 
  ATACTcTc 
  ATAgTAaT 
 A 50400310 
Profile C 01140102 
 G 00010011 
 T 04005132 
Consensus  ATACTATT 
Fig. 7. Profile analysis 
     
In order to test the performance of GHSOM, a total of 6 sequence datasets (length from 100 bp 
to 600 bp) were generated. In each dataset, a true motif site was random placed in each sequence 
and the other parameters are as follows: (1) Number of test files: 10. (2) Number of sequences: 20 
sequences. (3) Length of motif: 15 bp. (4) Number of mutation: 4.  
    For each simulated dataset, GHSOM, MEME, and Gibbs Sampling were applied to find the motif 
in terms of accuracy rate. The results are shown in Fig. 8 which indicates that GHSOM outperforms 
both MEME and Gibbs Sampling, especially when the sequence length is great than 300 bp. Table 2 
lists the analysis of variance for testing the equalities of mean accuracies of GHSOM, MEME, and 
Gibbs Sampling (H0: μGHSOM=μMEME=μGibbsSampling vs. H1: μGHSOM≠μMEME≠μGibbsSampling). Because the 
value of F test (4.441) is great than F2,15,0.05 (3.68), we can not accept H0 which means that the mean 
accuracies of GHSOM, MEME, and Gibbs Sampling have significant differences. 
 
Craven, M., “Learning sequence motif models using expectation maximization (EM) and Gibbs 
Sampling,” BMI/CS, Vol. 776, 2006. 
Das, M.K. and Dai, H., “A survey of DNA motif finding algorithms,” BMC Bioinformatics, Vol. 8 
(Suppl 7): S21, 2007. 
Dellaert, F., The Expectation Maximization Algorithm, Technical Report of College of Computing, 
Georgia Institute of Technology, No. GIT-GVU-02-20, 2002. 
Jensen, S.T. and Liu, J.S., “BioOptimizer: a Bayesian scoring function approach to motif 
discovery,” Bioinformatics, Vol. 20, No. 10, pp. 1557-1564, 2004. 
Keich, U. and Pevzner, P.A., “Finding motifs in the twilight zone,” Bioinformatics, Vol. 18, No.10, 
pp. 1374-1381, 2002. 
Kohonen, T., “Self-organized formation of topologically correct feature maps,” Biological 
Cybernetics, Vol. 43, pp. 59-69, 1982. 
Lawrence, C.E. and Reilly, A.A., “An expectation maximization (EM) algorithm for the 
identification and characterization of common sites in unaligned biopolymer sequences,” 
Proteins, Vol. 7, pp. 41-51, 1990. 
Liebert, M. A., “A Gibbs sampling method to detect overrepresented motifs in the upstream regions 
of coexpressed genes,” Journal Of Computational Biology, Vol. 9, No. 2, pp. 447-464, 2002. 
Liu, J.S., Neuwald, A.F., and Lawrence, C.E., “Bayesian models for multiple local sequence 
alignment and Gibbs sampling strategies,” Journal of American Statistical Association, Vol. 
90, No. 11, pp. 1156-1170, 1995. 
Lu, Y. and Han, J., “Cancer classification using gene expression data,” Information Systems, Vol. 
28, No. 4, pp. 243-268, 2003. 
Mahony, S., Benos, P.V., Smith, T.J. and Golden, A., “Self-organizing neural networks to support 
the discovery of DNA-binding motifs,” Neural Networks, Vol. 19, No. 6-7, pp. 950-962, 
2006. 
Mount, D.W., Bioinformatics Sequence and Genome Analysis, Cold Spring Harbor Laboratory 
Press, 2004. 
Pevzner, P. and Sze, S., Combinatorial approaches to finding subtle signals in DNA sequences, In 
Proceedings of the 8th International Conference on Intelligent Systems for Molecular 
Biology (ISMB-00), pages 269–278, Menlo Park, CA, August 16–23. AAAI Press, 2000. 
Rauber, A., Merkl, D., and Dittenbach, M., “The growing hierarchical self-organizing map: 
exploratory analysis of high-dimensional data,” IEEE Transactions on Neural Networks, 
Vol. 33, No.6, pp. 1331-1341, 2002. 
Rouchka, E.C., A Brief Overview of Gibbs Sampling, Washington University Institute for 
Biomedical Computing Statistics Study Group, 1997. 
Sandve, G.K. and Dranlos, F., “A survey of motif discovery methods in an integrated framework,” 
Biology Direct, Vol. 1, No.11, 2006. 
Yao, Z. and Weinberg, Z., and Ruzzo, W.L., “CMfinder--a covariance model based RNA motif 
finding algorithm,” Bioinformatics, Vol. 22, No. 4, pp. 445-452, 2005. 
 
 
 
 
 
 
 
 
 
 
 
 
 
國科會補助計畫衍生研發成果推廣資料表
日期:2011/08/30
國科會補助計畫
計畫名稱: 應用資料探勘技術於抗核抗體免疫螢光顯影影像、血液透析病患資料、及醫
療語意網之分析研究
計畫主持人: 葉進儀
計畫編號: 97-2221-E-415-008-MY3 學門領域: 生產系統規劃與管制
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
