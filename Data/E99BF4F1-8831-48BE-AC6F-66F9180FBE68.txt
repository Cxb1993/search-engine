 2
研究計畫中英文摘要 
 
(一) 計畫中文摘要 
 
百分百網路安全是無法達到的，數位鑑識的機制可以大量降低安全風險。數位鑑識是
用來重建被攻擊時的現場，藉由分析得到的資訊將其入侵者的身份、入侵的方法和入侵的
途徑等證據能保存下來，在法律訴訟程序時，更可提供具有法律效力的證據。MSN 
Messenger是目前網路應用當紅之通訊工具，但市面上缺乏MSN網路鑑識產品。現今許多網
路鑑識工具(如擷取網路原始封包的Sniffer或只解析L3/L4的網路鑑識系統)均無法完全還原
使用者行為。因此我們提出MSN網路鑑識系統的解決方案—「MSN-Shot」。誠如「MSN-Shot」
會把MSN之各種應用與活動紀錄下來，作為往後的數位證據。此計畫將以IXP425網路處理
器實作一套MSN網路鑑識系統，直接針對MSN的資訊稽核，將網路上的行為進行嚴密行為
紀錄，以便當資訊安全事件發生時，可以提出有效的證據並且還原事件現場。  
 
關鍵詞：網路鑑識、網路安全、MSN Messenger 、網路處理器 
 
(二) 計畫英文摘要 
 
  Digital forensic is the applications of science to identify, collect, analyze and examine digital 
evidence in the manner of preserving the integrity of evidences and supports the legal system 
resolving information security questions in lawsuit trials. With the complement of existing 
security perimeter devices (such as IDSs and fire walls), digital forensic tools become more 
important to handle the subtleties of policy violations or security breaches. Digital forensic 
analysis not only plays a vital role in information security management cycle but also has become 
a preferred step for new network security legal processes. 
 
In literatures, a few network forensic tools offer MSN-messenger behavior reconstruction. 
Moreover, they do not have classification strategies at the collection stage when the system 
becomes saturated. The emphasis of this project is to address the shortcomings of the above 
situations and pose a solution to select a better classification in order to ensure the integrity of the 
evidences in the collection stage under high-traffic network environments. We believe that 
MSN-shot is able to reconstruct the MSN-messenger behaviors perfectly in the context of 
upcoming next generation network. 
 
Keywords: Digital forensic, Network Security, MSN Messenger, Network Processor 
 
 4
 
    目前在市面與網路上也有一些 Open source 或 Commercial 的網路鑑識工具，接下來簡
介一些著名的網路鑑識工具： 
 
 TCPDump：TCPDump 鑑識技術是屬於 OSI 第三層的鑑識軟體，可擷取所有線路
上的網路封包，使用者可查看任何連線之建立與結束，也可以擷取網路封包表頭
(Header)內的任何資訊，可以利用 IP、ICMP、UDP、TCP 表頭內任何一個欄位過
濾封包，配合正規字串表示式(Regular expression)與過濾器(Filter)，可以將使用者
有興趣的網路活動過濾出來，提供已知事件網路鑑識。 
 Argus：一套網路稽核紀錄系統，他是屬於 OSI 第四層鑑識軟體，具備即時流量監
視、追蹤、效能與狀態，Argus 提供每條連線報告數據計有：遺失率、延遲時間
Jitter 值與連線狀態等等。 
 NetDetector (http://www.niksun.com/)：一個屬於應用層網路鑑識軟體，其核心技
術是網路資料的即時擷取、大量資料儲存及專業的資料重組、挖掘及分析，並與
網路安全技術緊密結合。 
 NetIntercept (http://www.sandstorm.net)：NetIntercept 屬於應用層網路鑑識軟體，
提供一個完整的系統，其中包含硬體與預先搭載的軟體，NetIntercept 已經準備好
隨時可以部署在網路上。優異的性能，使 NetIntercept 有 Gigabit 等級的擷取封包
能力，網路協定引擎檢驗收集到的封包，藉由傳輸層資訊與使用者 session 資訊將
獨立的網路封包組織起來，並且顯示裝置之間的連線，也能夠精確地辨別超過 95
種網路協定。 
 
    以上鑑識工具方面有些的工具皆無支援 MSN Messenger 的分析，雖然有些有支援 MSN 
Messenger 的封包擷取軟體，也僅是把 MSN Messenger 的 協定跟 e-mail 等資訊顯示出來，
並無法針對使用者之間傳遞的訊息，狀態的改變，檔案傳輸，語音等資訊做進一步地歸類
重整，不夠完整的資訊造成無法真實呈現使用者行為與重建事件現場，同時也無法發現隱
藏在資訊安全事件後的事情真相。 
 
 
(四) 研究方法 
 
    我們提出一套 MSN-Shot 來解決 MSN 鑑識之所需，其架構主要有兩部分：MSN-Shot 
Sensor 與 Evidence Administration Server (EAS ⎯ 證據管理伺服器) ，其整體架構如圖 1
所示。各MSN-shot sensor透過安全通道(Channel)或是以獨立實體線路的方式與EAS做many 
agent-one manger 之通訊模式。其分散式 Sensor 架構可提升整個系統在大型網路中的效能，
集中式管理讓網管人員能夠輕易的對設備做設定以及監控網路狀態，直接針對 MSN 的資訊
稽核，使用者可以透過 Web 界面操控所要的功能需求，可將網路上的行為進行嚴密行為紀
錄，當資訊安全事件發生時，最後提出有效的證據並且還原事件現場。 
 6
  最後將上述的系統結構中，我們用Intel IXP425 Development Platform 系列中的ADI 
Engineering – Coyote Gateway Reference Design來開發MSN-Shot sensor，並用MontaVista 
Linux Professional Edition 3.1為作業系統，EAS則採用Linux作業系統，並以Apache 為Web 
server，後端的資料庫則是使用MySQL。開發應用軟體的部分主要是利用C與PHP來完成各
種MSN-Shot EAS的功能。 
 
 
(五) 結果與討論 
 
    由我們所提出的MSN-Shot，可以將MSN-Shot功能對於市面上Open source與商業網路鑑
識產品比較，其中TCPDump、Argus 與NetIntercept無法解析MSN其內容，只有MSN-shot
與NetDetector能解析MSN封包內的訊息，但MSN-shot能夠保證收集的證據與目前顯示給使
用者的資料是完全符合的收集到證據的第一時間，立即把證據利用MD5演算法產生雜湊
碼，然後放置安全的地方，當使用者調閱相關證據的時候，對取出的證據再做一次MD5，
並且把結果與證據收到時產生的MD5雜湊碼比對，以保證目前與最初的證據是完全相同
的，總而言之，MSN-Shot擁有可信賴的資料擷取功能、強大的資料分析能力、完整重建現
場與精確的資料解剖技巧，且證據的收集、分析、檢驗、保存與文件製作是MSN-Shot網路
鑑識系統真正價值之所在。詳細內容請參閱附件一(發表於第十八屆資訊安全會議)。 
 
    MSN messenger的功能非常多，常用的有：即時訊息交談、檔案交換甚至是進行互動遊
戲，然而MSN-shot目前尚未完全開發完成。在表 2中列舉MSN-shot目前對MSN messenger
支援的功能，在表中我們分成已經完成的功能、開發中的功能與正在設計中的功能。 
 
表 2 MSN messenger 與 MSN-shot 功能對照 
(註：○:表示開發完成;  ∆:表示目前正在開發中;  -:表示正在設計中) 
MSN messenger MSN-shot 
文字訊息 ○ 
來電震動 ○ 
檔案傳輸 ∆ 
語音對話 - 
視訊通話 - 
動畫快遞 - 
好友名單 ○ 
好友狀態 ○ 
好友暱稱 ○ 
表情圖案 - 
使用者圖案 - 
 
我們並且完成web-based 管理功能，MSN-shot管理者可透過瀏覽器連接到EAS Server，其
管理功能介面，如：設定鑑識目標(圖 3)，證據瀏覽功能(圖 4)、顯示系統狀態(圖 5)。 
 
 8
 
 
在第二年部份，除了繼續完成第一年未完成部分，我們將針對現今的高流量網路環境
之下，為了避免MSN-shot在高流量環境而影響資料的完整性，我們將進行Quality Assurance 
Evidence Collection (QAEC) 方法研究，以期在大量資料的湧入時， QAEC可以動態的控制
流量出入於MSN-shot，使得我們設計出的MSN-shot能夠更完整的重建事發現場。尤其是在
資源有限的網路環境下，如何設計一套有效率地的證據蒐集機制以適用於高負載傳輸，而
關鍵在於鑑識服務請求之合理接受率與資料擷取時發生遺失的可容忍程度。QAEC初步是
以連續時間(Continuous Time)的Markov Chain為模組化，並以flow-level與packet-level作為成
本花費的計算元件，以此模型來反映證據重建程序的變化過程。 
(0,1)
(0,n) (1,n)
(1,1)
μ
λ
μ
λ
μ
nμ
μ
(0,0) (1,0)
μ
λ
2μ
λ
2μ
λ
2μ
λ
2μ 2μ
nμ
(m,n)
(m,1)
mμ
λ
mμ
λ
λ
(m,0)
mμ
λ
μ
nμ
2μλ
λ
μ
nμ
(m-1,0)
2μ
(m-1,1)
(m-1,n)
A No Penalty Region B Drop Penalty Region C Block Penalty Region
 
圖 6  QAEC 模型的二維狀態 Markov Chain  
 
首先，在敘述研究方法之前，我們先陳述其中的前提假設，以便能清楚了解QAEC的
系統結構。假設一：網路辨識系統中典型的證據蒐集結構包含兩個主要的子系統，一是證
據捕捉系統(Evidence Capture Subsystem，ECS)，另一個是儲存系統(Storage Subsystem，SS)。
ECS負責監視與過濾網路封包資料，當其認定某些資料可為網路辨識證據時，則將那些資
料另行儲存至SS中。假設二：SS允許網路節點可長期地透過安全通道將資料存入SS中。但
因受限於通道儲存之頻寬與速率，可能會趕不上ECS系統所欲儲存之資料流量，屆時，則
形成網路鑑識程序的一個瓶頸(Bottleneck)。假設三：以QAEC證據蒐集的程度上來分類，
可分為兩類，完整蒐集(Full Collection，FC)與選擇性蒐集(Selective Collection，SC)。顧名
思義，FC-class是將有關證據資料的封包全部儲存，而SC-class則是選擇性的儲存部分資料。
而系統要選擇採用FC-class或是SC-class，則是根據下一個假設所定義的方式。假設四：利
用兩個參數(ε與Ψ)相互比較來決定系統下一階段要採用哪種程度的證據蒐集，ε表示一個
事先定義的門檻值，Ψ則表示當前ECS系統經計算後可得的一個參數值。當Ψ≦ε時，系
統對於下一個證據流量是採完整蒐集級別(FC-class)；若Ψ＞ε時，下一次的證據蒐集則是
採用選擇性蒐集(SC-class)方式。 
 10
00
1
0
, ==⋅= ∑∑
=
−
=
FC
n
oj
m
i
jiFCA iPP ττ Q  
∑−
=
=
1
1
,
n
j
jmSCB jPP τ  
⎩⎨
⎧
<≤
==
10
1
,
,
αθ
αθ
nmSC
nmFC
C P
P
P  
(5) 
基於前幾段所敘述的函式定義，我們對此系統進行Flow-level的效能分析，以下列舉說
明系統的儲存能力對於服務阻斷率(Service blocking rate)的影響，假設證據流量的密度為
80，η=0.4即為SC-class的封包阻斷率，而服務被阻斷率即為P(m,n)，實驗結果如下圖 7所示，
X軸表示儲存能力，Y軸表示服務阻斷率，圖中列出七種不同α參數值(0~1)的實驗數據，其
結果均表示當儲存能力愈大時，服務阻斷率會有下降的趨勢。同時，我們也進行了α以及
η對於服務阻斷率的影響分析，其詳細實驗內容，請參照附件一。 
 
 
圖 7  儲存能力對服務阻斷率的影響 
 
另一方面，我們分析儲存能力與系統效能(Cost(J))之間的關係，實驗環境為當α=0.5，
η=0.4，結果如下圖 8所示，X軸為儲存能力(Storage capacity)，Y軸為目標函式Cost(J)，圖
中列出三條曲線分別表示不同的變數k值(k=1~3)，該k值影響在SC-class時，封包遺棄的負面
損失。實驗數據呈現出當儲存能力極低時，目標函式Cost(J)的值會極低，這是因為當儲存
能力偏低時，同時導致系統常常處於擁塞的狀態，也對應至圖 7中極高的服務阻斷率
(Blocking rate)產生。此時，我們觀察出，當儲存能力較大時，也能有較低的服務阻斷率以
及較高的Cost(J)，然而Cost(J)愈高並不完全是好事，除了帶來了較佳效能之外，反向思考
也是需要較高的成本支出。因此，系統效能評估便是要從中取捨，最佳選擇是要以符合系
統需求為主，同時也要能達到最大效益，這就是Trade-off的精神。 
 12
Manufacturing system and Security & Assurance (IMSA) for Journal of Intelligent 
Manufacturing (SCI/EI); DOI: 10.1007/s10845-009-0241-6 
 
(六) 計畫成果自評 
 
本計畫皆能順利達到預期目標，在計畫期間(08/2007~10/2009)共計產出下列成果(計10篇期
刊論文、7篇國外學術會議論文、7篇國內學術會議論文與兩本專書) 
z 期刊論文 
1. Bo-Chao Cheng, Huan Chen, Ryh-Yuh Tseng, “Quality Assurance Evidence Collection 
Model for MSN Forensics”, Special Issue on Intelligent Manufacturing system and 
Security & Assurance (IMSA) for Journal of Intelligent Manufacturing (SCI/EI); DOI: 
10.1007/s10845-009-0241-6 [SCI,EI] (Y2008) Impact Factor: 1.018, Rank 16/38 in 
Engineering, Manufacturing 
2. Bo-Chao Cheng, Yi-An Tsai, Guo-Tan Liao and Eui-Seok Byeon, “HMM machine 
learning and inference for Activities of Daily Living recognition”, Journal of 
Supercomputing (JoS), DOI 10.1007/s11227-009-0335-0. [SCI,EI] (Y2008) Impact 
Factor: 0.615, Rank 153/229 in Engineering, Electrical & Electronic 
3. Huan Chen, Bo-Chao Cheng, Po-Kai Tseng: Cognitive Shortest Path Tree Restoration 
(CSPTR) for MANET Using Cost-Sensitivity Analysis. IEICE Transactions 92-B(3): 
717-727 (2009) 
[SCI,EI] (Y2008) Impact Factor 0.427, Rank 44/67 in Telecommunications 
4. Bo-Chao Cheng, Huan Chen, Guo-Tan Liao: FBT: an efficient traceback scheme in 
hierarchical wireless sensor network. Security and Communication Networks 2(2): 
133-144 (2009) [EI] 
5. Bo-Chao Cheng, Huan Chen and Guo-Tan Liao, “A Novel Marking Probability 
Distribution Using Probability Propagation in Hierarchical WSN”, LNCS 5487, pp. 
265-274, Springer-Verlag, April 2009. [EI] 
6. Bo-Chao Cheng, Huan Chen, Yi-Jean Li, Ryh-Yuh Tseng: A packet marking with fair 
probability distribution function for minimizing the convergence time in wireless sensor 
networks. Computer Communications 31(18): 4352-4359 (2008). [SCI,EI] (Y2008) 
Impact Factor 0.884, Rank 32/67 in Telecommunications 
7. Bo-Chao Cheng, Huan Chen, Ryh-Yuh Tseng: A Good IDS Response Protocol of 
MANET Containment Strategies. IEICE Transactions 91-B(11): 3657-3666 (2008). 
[SCI,EI] (Y2008) Impact Factor 0.427, Rank 44/67 in Telecommunications 
8. Bo-Chao Cheng, Huan Chen and Ryh-Yuh Tseng, “A Context Aware Gateway for 
SIP-based Services in Ubiquitous Smart Homes”, International Journal of Smart Home 
Vol.2 No.1 , 2008, pp.1~14 
9. Huan Chen, Hui-Kai Su and Bo-Chao Cheng, “An Objective-Oriented Service Model for 
VoIP Overlay Networks over DiffServ/MPLS Networks,” Computer Communications, 
vol. 30, no. 16, pp. 3055-3062, Nov. 2007. [SCI,EI] (Y2007) Impact Factor 0.391, Rank 
37/66 in Telecommunications 
 14
for Minimizing the Convergence Time in Hierarchical Wireless Sensor Networks＂, 
TANET 2007, No. 359_303, Oct. 22-25, 2007. 
7. 陳煥, 林承助, 鄭伯炤, “Automated Trusted Negotiation Using a Smart Trust Agent”, 
2007 年第九屆「網際空間：資安、犯罪與法律社會」 學術研討會, November 30,2007 
 
z 專書、專章 
1. SOHO網路閘道器－實作與VoIP應用，作者：林宗男、周立德、陳煥、趙涵捷、
賴文彬、陳俊良編著，黃崇明、鄭伯炤彙整，出版社：知城，出版日期：2007年
12月1日，語言：繁體中文，ISBN：9789866850554。 
2. 數位家庭網路與居家安全監視系統，作者：石維寬、梁文耀、鄭憲宗、蔡智強編
著，黃崇明、鄭伯炤彙整，出版社：知城，出版日期：2007年12月1日，語言：繁
體中文，ISBN：9789866850509。 
 
 15
 
附件一 
Bo-Chao Cheng, Huan Chen, Ryh-Yuh Tseng, “Quality Assurance Evidence Collection 
Model for MSN Forensics”, Special Issue on Intelligent Manufacturing system and Security 
& Assurance (IMSA) for Journal of Intelligent Manufacturing (SCI/EI); DOI: 
10.1007/s10845-009-0241-6 [SCI,EI] (Y2008) Impact Factor: 1.018, Rank 16/38 in 
Engineering, Manufacturing 
2 
collection technology is employed, the storage subsystem should be powerful enough (including 
sufficient storage size and a fast system bus speed) to keep up with the network wire speed (Corey 
et al. 2002). 
When the storage subsystem becomes the bottleneck, a control mechanism is needed to 
supervise the evidence collection process and accommodate new evidence collection requests in a 
high bandwidth environment. In this paper, we propose a network forensic control model, called 
the Quality Assurance Evidence Collection (QAEC) model, which can dynamically adjust the 
amount of data to be collected during evidence flow according to the current status of the storage 
subsystem. The QAEC model will firstly be modeled as a Continuous Time Markov Chain 
(CTMC) then solved by a commercial optimization tool, LINGO. The performance is evaluated by 
formulating a cost function that comprises both flow-level and packet-level components to reflect 
the efforts on the evidence reconstruction process. We have prototyped a MSN Messenger forensic 
system, called MSN-Shot, which uses QAEC selecting appropriate FC and SC margins to 
minimize data loss associated with storage subsystem saturation while preserving a reasonable 
acceptance ratio of new forensic collection requests.  
This paper is organized as follows. In section 2, we briefly review various admission control 
models. Section 3 details our proposed evidence collection model, QAEC. Section 4 illustrates the 
numerical analysis for the QAEC cost function. Section 5 presents a prototype (known as MSN-
Shot) as a MSN forensic system using the QAEC engine. Finally, section 6 concludes our paper. 
2. Background and Related Work 
Digital forensics is a scientific application able to support the legal system, which helps resolve 
information security questions which arise in legal trials. As such, digital forensics becomes an 
essential component in the information security management cycle. There are two major types of 
information forensic systems available today: computer forensics and network forensics. These 
two types are characterized by different monitoring and analysis approaches as follows: Computer 
Forensic Analysis Tools (CFATs) aim at analyzing evidence inside a compromised computer, such 
as system log files, storage status, command log, etc; on the other hand, Network Forensic 
Analysis Tools (NFATs) review network traffic and network security logs.  
For an effective NFAT, the evidence collection function must capture an acceptable amount of 
network traffic and maintain the integrity of the evidence. However, due to limited resources, 
NFAT may not be able to capture all real-time evidence simultaneously. If this occurs, preferential 
treatment has to be applied. Like the Quality of Service (QoS) guarantee mechanisms in network 
traffic engineering, NFAT should allocate more resources or give priority to important incidents. 
The difficulty here is allocating priority.  
A service request admission control mechanism might be a primitive solution for managing 
forensic evidence collection. An intuitive approach, First-In-First-Out (FIFO), serves one of the 
capture requests in the service queue when the resource becomes available. If there is no available 
resource, the requests are queued until the resource becomes available again. The FIFO scheme 
results in a large average service waiting time especially if the service time for individual service 
requests vary substantially. The basic idea behind Guard Resource (GR) based admission control 
schemes is to reserve resources known as guard resources a priori and to give preferential 
treatment to new high-priority requests. As a result, the GR scheme offers systems a better service 
rate for high-priority requests (Hong and Rapport 2002). Jamjoom and Shin (2003) proposed the 
persistent dropping approach to preserve established connection service resources and drop 
incoming requests with probability p. Using the persistent dropping technique, we are able to 
protect the established service connections and use different dropping probabilities for specified 
services. Feng and his colleagues proposed an active queue management algorithm (Feng et al. 
1999), BLUE, using packet loss and link utilization history to manage the service request rate. 
Upon detecting overflow or link idle events, BLUE changes the appropriate dropping probability 
to reflect these two extreme cases. Without early congestion detection, BLUE was obstructed 
because of slow responses and a heavy dependence on link utilization history. 
Admission control mechanisms have been proposed above, but none have been designed to 
incorporate the goals of achieving a satisfactory acceptance rate and tolerance of packet loss. We 
therefore propose a new evidence collection control model (QAEC) which will provide a certain 
level of quality assurance for network forensics. Our main focus is to optimize the trade-off cost 
between forensic service requests and data capture loss. In addition, we also implement our 
evidence collection control model as a forensic system for MSN. 
 
4 
class up to n flows. In QAEC, a SC-class service, once accepted, will never be upgraded back to 
the FC-class even if the storage capacity drops below the threshold (ε). The QAEC model can be 
modeled as a two dimensional birth-death process. Figure 1 shows the state transition diagram of 
this birth-death process based on the Continuous Time Markov Chain (CTMC).  
(0,1)
(0,n) (1,n)
(1,1)
μ
λ
μ
λ
μ
nμ
μ
(0,0) (1,0)
μ
λ
2μ
λ
2μ
λ
2μ
λ
2μ 2μ
nμ
(m,n)
(m,1)
mμ
λ
mμ
λ
λ
(m,0)
mμ
λ
μ
nμ
2μλ
λ
μ
nμ
(m-1,0)
2μ
(m-1,1)
(m-1,n)
A No Penalty Region B Drop Penalty Region C Block Penalty Region
 
Figure 1. Two-dimensional state-transition-rate diagram for the QAEC model. 
 
Observe that in Figure 1, if the ECS is monitoring the ith FC-class and the jth SC-class evidence 
flows, we say that this system is in the state of (i, j), where i and j are positive integers in the 
ranges of 0 ≤ i ≤ m and 0 ≤ j ≤ n, respectively. Let Pi,j be the stationary state probability of (i, j), 
which can be found by solving the equilibrium equations below: 
 
λP0,0   = μP0,1 + μP1,0 , if i = 0 and j = 0 
(λ + iμ)Pi,0 = λPi−1,0 
+ (i + 1)μPi+1,0 + μPi,1 
, if 1 ≤ i ≤ m− 1 and , j = 0 
(λ + mμ)Pm,0 = λPm−1,0 + μPm,,1 , if i = m and j = 0 
(λ + jμ)P0,j  = (j + 1)μP0,j+1 + μP1,j , if i = 0 and 1 ≤ j ≤ n-1 
(λ + iμ + jμ)Pi,j = (i + 1)μPi+1,j 
+ (j + 1)μ · Pi, j + 1 
+ λPi−1,j 
, if 1 ≤ i ≤ m− 1 and  
, 1 ≤ j ≤ n-1 
(λ + mμ + jμ)Pm,j  =λPm,j−1 + λPm−1,j 
+ (j + 1)μPm,j+1 
, if i = m and 1 ≤ j ≤ n-1 
(λ + nμ)P0,n  = μP1,n , if i = 0 and j = n 
(λ + iμ + nμ)Pi,n = (i + 1)μPi+1,n 
+ λPi−1,n 
, if 1 ≤ i ≤ m− 1 and j = n 
 
(mμ + nμ)Pm,n  =λPm-1,n + λPm,n-1 , if i = m and j = n 
(3)
 
The normalization equation for the above equilibrium equations can be expressed as: 
∑∑
= =
=
n
j
m
i0 0
 ji, 1 P  (4)
3.1 The QAEC Cost Function 
In the design of the ECS, QAEC plays an important role, driving the entire system to achieve its 
performance targets (such as maximizing the “profit” for the system). These goals shall be 
described quantitatively to allow QAEC to map the “goals” from the semantic domain to the 
objective domain. In this section, we propose an objective function (J) that is designed to 
maximize the acceptance ratio for new arrival requests at the flow level and minimize the penalty 
6 
⎩⎨
⎧
<≤
==
10
1
,
,
αθ
αθ
nmSC
nmFC
C P
P
P  (11)
CBCBA PPPPPP +=++=  (12)
 The cost function of the evidence collection model, J can thus be defined as: 
PRJ −=  (13)
4. Numerical Results 
This section presents numerical results for the QAEC control model. The performance metrics 
of the QAEC model include: the blocking rate of forensic services and the cost function J. The 
QAEC model can be modeled as a two-dimensional Continuous Time Markov Chain (CTMC). 
Due to its complex mathematical structure, QAEC does not have a closed-form solution. A 
sophisticated commercial optimization tool, LINGO, is applied to derive its numerical results. 
 
In particular, if the reward and penalty are equally weighted for both FC and SC class traffic, 
(i.e., γFC = γSC = θFC = θSC = ω), the cost function J defined in Eq. (13) can be simplified as follows: 
 
J  PR −=  
 
ωω ⋅⎥⎥⎦
⎤
⎢⎢⎣
⎡
+⎟⎟⎠
⎞
⎜⎜⎝
⎛
⎟⎟⎠
⎞
⎜⎜⎝
⎛−−⋅⎥⎦
⎤⎢⎣
⎡ += ∑∑∑∑∑ −
== == =
nm
n
j
jm
k
FC
SC
n
oj
m
i
ji
n
oj
m
i
ji PjPb
bjPiP ,
1
1
,
0
,
0
, 1
(14)
 
4.1 Flow-Level Performance Analysis – Service Blocking Rates  
A. The impact of provisioned storage capacity Ω on the blocking rate 
 
To evaluate the flow-level performance, the traffic intensity of the evidence flow (denoted as ρ) 
is set to 80, and the blocking rate of the forensic services is calculated based on Eq. (8). The total 
provisioned storage capacity Ω is varied from 10-units to 60-units. Figure 2 shows that the 
blocking rate decreases with the increase of the total provisioned storage capacity Ω. The blocking 
rate declines to zero when the amount Ω approaches larger units.  
 
Figure 2. The blocking rate of the QAEC model with a variable amount of Ω. 
 
For a given Ω, it is also shown that the blocking rate decreases with the decrease of α. Notice 
that the blocking rate decreases with the increase of the total possible flow number. As the value of 
8 
variable amount of Ω with α=0.5 and η=0.4. The objective for parameter k of τSC is to find the 
best fit packet loss penalty for real-life application. The Y axis denotes the cost function J and the 
X axis indicates the amount of Ω. When Ω is very small, the cost J falls to a minimum value 
regardless of k. This is because storage capacity becomes exhausted, causing a large block rate; in 
other words, the system becomes congested and rejects many requests for evidence collection. As 
Ω increases, this leads to an increase of the cost function J. Having increased the amount of Ω,  
the values of α and η can be set in such a way that, for the forensic manager, the trade-off between 
the reward for accepting new requests and the extra penalty of packet loss leads to an optimal cost 
solution. When the amount of Ω is large enough to host all of the forensic requests, the cost J of 
each of the three k values will be the same.  
 
 
Figure 4. The cost function J of the QAEC model with a variable amount of Ω. 
 
 
B. The impact of α and η on the cost function J  
 
From the above results, shown in Figure 4, QAEC can play an important role when the SS is 
almost saturated. The QAEC impact on the cost function J is minimal under very low or heavy 
load situations. Now, we will investigate the impact of α and η when the SS is almost saturated.  
 
(a) (b) 
Figure 5. The cost function J of the QAEC model with varying amounts of Ω. 
 
In this study, we assume that the amount of Ω is fixed to 50-units with η=0.4 to obtain the 
results shown in Figure 5(a) where the Y axis is the cost J and the X axis indicates α. As α=1-, the 
three curves (k=1, 2 and 3) close to a cost point, 481.622. As α is decreased, each curve will rise. 
However, when each curve rises to a peak cost point, its profit cost falls along with a continually 
decreasing α. Each curve falls tremendously when α reaches a very small value, especially for the 
k=3 curve. From Figure 5(a), each curve has a maximum value and by proper selection of the 
parameter α, the  maximum cost can be obtained.  
10 
z The Evidence Administrator Server (EAS)  
The EAS is a manager program that provides a surveillance interface that network administrators 
can use to manage, review and analyze collected evidence. The EAS is able to manage one or 
more agents running on MSN-Shot Sensors. It also provides the current system status (CPU 
utilization, memory capacity, storage capacity, bus utilization, TCP connection numbers and the 
link priority) to the ECS. We have implemented a web-based management interface for MSN-Shot 
which is shown in Figure 7. 
 
z The Storage Subsystem (SS) 
The storage subsystem is the set of components (including storage devices and communication 
channels) that let sensors permanently store evidence on the MSN-Shot system. Storage devices 
are the actual drives that host data and communication channels are used to convey information to 
and from the storage devices. To preserve evidence and ensure data integrity, the SS uses a MD5 
signature to create a checksum for each session of data exchange (including file, voice and 
message) and stores it in another text file. Then, the SS can compare the session checksums 
against the values in the text file to see whether any change has occurred. 
 
 
Figure 7. Web-based management interface for MSN-Shot. 
5.1 Information Flow 
The MSN-shot design architecture is based on the QAEC model, which is able to make 
decisions to accept either FC-class or SC-class requests (with a specified packet drop rateη) when 
resources are constrained. After the negotiation process is done with the system administrator via 
the configuration manager, the QAEC model obtains the values of (α,η), which conform to a 
quality assurance packet acquisition model. Upon receiving (α,η), the ECS is able to classify the 
packet flow and collect the packet in a smart way.  
Figure 8 depicts how the MSN-Shot application deals with the three different phases: the 
Negotiation Phase to obtain proper parameters (α,η), the INVITE Phase to deal with the incoming 
INVITE requests, and the Collection Phase to collect regular data packets. The detailed processes 
are illustrated as follows: 
12 
6. Conclusion 
Collecting all available data and preserving the integrity of evidence for IM applications is a 
challenging task, but worth the effort as evidence reconstruction can be made more efficient and 
return higher system profits. A good evidence collection mechanism is required to adapt to an 
event collections strategy based on system storage capacity in order to avoid the high penalty of 
evidence reconstruction efforts, especially in a network environment where there is heavy traffic. 
The emphasis of this paper is on the development of an evidence collection control mechanism 
that produces optimal solutions with a reasonable forensic service requests acceptance ratio along 
with tolerable data capture loss. In this paper, we have proposed an evidence collection control 
mechanism, QAEC, which can dynamically adjust the amount of data to be collected on an 
evidence flow according to the storage capacity level on the storage subsystem. In order to reflect 
the practical system reward and evidence reconstruction penalties, a cost function that comprises 
both flow-level and packet-level components was developed and used. Numerical results showed 
that QAEC can select appropriate FC and SC margins to minimize data loss associated with 
storage subsystem saturation while sustaining a reasonable acceptance ratio of new forensic 
collection requests. This study has confirmed that the QAEC model meets cost-effectiveness 
requirements and provides a practical evidence collection solution to network forensics 
applications with a high level of quality assurance. Moreover, we presented the MSN-Shot system 
prototype as a MSN forensic system which made effective use of the QAEC model. The MSN-
Shot system can successfully reconstruct MSN Messenger behaviors including user status (online, 
offline, away, etc). From the benefits and positive results shown by the QAEC engine, a forensics 
manager can be confident that their security assurance process provides a high level of security.  
Two potential researches issues can be further developed based on the contributions of this work. 
The first issue is to perform a realistic traffic estimation to get more proper parameters for the 
Poisson distribution used in the proposed model. The second issue is to integrate the Service Level 
Agreement (SLA) with the proposed QAEC model. With the SLA in place, QAEC can assure the 
delivered forensic quality between end users and their service providers, or between service 
providers.  
References 
Casey, E. (2004). Network traffic as a source of evidence: tool strengths, weaknesses, and future 
needs. Digital Investigation 1(1) 28–43 
 
Corey, V., Peterman, C., Shearin, S., Greenberg, M.S., Bokkelen, J.V. (2002). Network forensics 
analysis. IEEE Internet Computing 6(6) 60–66. 
 
Feng, W., Kandlur, D., Saha, D., Shin, K.: Blue (1999). A new class of active queue management 
algorithms. Technical report  
 
Hong, D., Rapport, S.S. (1986). Traffic model and performance analysis for cellular mobile 
radiotelephone systems with prioritized and non-prioritized handoff procedures. IEEE Trans. on 
Vehicular Technology 35 77–92. 
 
Jamjoom, H., Shin, K. (2003). Persistent dropping: An efficient control of traffic aggregates. In: 
ACM SIGCOMM.  
 
Kent, K., Chevalier, S., Grance, T., Dang, H., (2006). Guide to integrating forensic techniques into 
incident response. NIST Special Publication 800-86. August. 
http://csrc.nist.gov/publications/nistpubs/800-86/SP800-86.pdf 
 
Krasser, S., Conti, G., Grizzard, J., Gribschaw, J., Owen, H (2005).: Real-time and forensic 
network data analysis using animated and coordinated visualization. IEEE Information Assurance 
Workshop (IAW).  
 
Nisase, T., Itoh, M.(2004). Network forensic technologies utilizing communication information. 
NTT Technical Review 2(8). 
 
Sekar, V., Xie, Y., Maltz, D., Reiter, M., Zhang, H. (2004). Toward a framework for internet 
forensic analysis. In: ACM SIGCOMM Hot Topics in Networks (HotNets). 
 2 
 
 
 
 4 
 
二、 與會心得 
    第一次出國參與國際會議的心情是一種膽顫心驚的感覺，能夠親眼看
到世界各地的學生及專家於會議中演講，聆聽各種不同腔調的口音，而大
部分的論文報告者，都有穩健的台風與獨特的表現。雖然很難聽懂別人的
演講內容，但是也一度激起回國後要增強聽力訓練的想法。而且，因為參
與此次會議，也與東華大學的同學們相結識，看過東華同學的報告後，覺
得其表現優良，可為標竿，並希望自己日後能大有進步。 
    另外，看見大陸北京建設欣欣向榮，似乎已有國際化的規模，令人不
禁興起要多多努力才能有所成長。並感謝國科會計畫提供補助，才能令學
生們有出國增廣見聞的機會，能參加國際會議有助於擴展個人視野，並且
意識到國際學術交流是無遠弗屆的。若能持續補助國際學術交流活動，相
信這是非常有助於提升國際競爭力。 
 
三、 攜回資料名稱及內容 
    本次會議後攜回會議議程及會議論文集紙本(1 & 2冊，無光碟)，如下列： 
 議程Program：INSCRYPT 2008 (4th International SKLOIS Conference on 
Information Security and Cryptology) Decemeber 14-17, 2008, Beijing, China. 
 論文集紙本： Pre-proceedings ( Ⅰ & Ⅱ ) of Information Security and 
Cryptology. 
 
 
 6 
packets (by each node on the attacking path). In this paper, we propose a novel Stratified Probability Propagation 
Model (SPPM) to provide low convergence time in a hierarchical wireless sensor network (HWSN) environments. 
The rest of this paper is organized as follows: Section 2 provides background information of the hierarchical WSN 
and the impact of marking probability. Section 3 details the SPPM techniques. Simulation results are shown in 
Section 4. Finally, we give a conclusion in Section 5. 
2   Related work  
In this section, we first state preliminary background on HWSN, and then discuss the impact of 
the marking probability of PPM.  
2.1   Preliminary Background on HWSN 
A typical HWSN comprises a base station, several cluster head nodes and many regular sensor 
nodes [9]. LEACH [17], a well-known clustering algorithm, relies on localized coordination to 
achieve four advantages (reduction in energy dissipation, distribution of energy-usage, 
enhancement of network lifetime and maintaining the network coverage). However, LEACH is 
not scalable because each node transmits data straight to its cluster-head, and then the 
cluster-head forwards it to the sink directly. TEEN [5] and APTEEN [4] use the hierarchical level 
clustering technique to allow the cluster head to have indirect communications with the sink via 
other cluster heads. Lindsey et al. [13] developed a token-passing chain-based PEGASIS 
(Power-Efficient GAthering in Sensor Information Systems) that eliminates the process of 
dynamic cluster formation and uses data fusion at the designated leader to reduce the amount of 
data transmitted between sensor nodes and the BS. Please note that this paper uses the terms 
“cluster head” and “leader” almost interchangeably. A hierarchical PEGASIS, H-PEGASIS [12], 
uses 3-level chain-based scheme to improve energy and delay problem in PEGASIS. In 
Lowest-ID heuristic [3] allows regular sensor nodes working as intermediate nodes between any 
two cluster heads. 
In this paper, we study how to minimize the convergence time by PPM via a good marking 
probability assignment as well as the integration methodology of SPPM in hierarchical WSN for 
cluster formation.  
2.2   Marking Probability of PPM  
In the conventional IP network, edge sampling [14] advanced by Savage et al. is a well known 
traceback algorithm to counter DoS/DDoS attacks. However, the probability research of packet 
marking is a fly in the ointment because Savage et al. do not address how to adopt such marking 
probability (denoted as ). Packet marking probability assignment is difficult due to the potential 
for node failures and a high penalty if it does not allocate “right” probability. The good news is 
that [14] provides a good traceback model and offers the following bounded expectation about 
the number of packets, E[X], required for the victim to reconstruct a path of length d, as shown in 
Eq.(1). They assume all nodes with the same marking probability () and the farthest node with 
 8 
L
SPFA
1
][
1
  (2) 
 
We also derive the upper bond is based on i of the farthest node An where the value of |P(An, 
Co)| is the shortest distance. 
S
YS
YLS
S
S
S
YS
YS
YS
YS
YL
YL
YL
YL
LPFA





















1
)
1
1
2
......
2
1
1
()
1
1
2
......
3
2
2
1
1(][
1
    (3) 
So, SPF is better than LPF based on the following equation.  
][
11
][
11
SPF
LLYLS
YS
SYLS
YS
S
YS
YL
LPF AA  









  (4) 
Thus, we conclude that the SPF has better performance generically with lower upper bound of 
convergence time. The difference between LPF and SPF is those marking probabilities upon the 
common attack path P(N, C0). That is to say the victim C0 has a higher chance of receiving the 
packets marked by far nodes in SPF than in LPF.  
An(S)
N(Y)
A1(L)
C0
(a) LPF
(b) SPF
=
1 =
1/
2
=
1
=
1/
2
(Y)=1/(L-Y+1)
(Y)=1/(S-Y+1)
(1)=1/L
(1)=1/S
...Ai…
|P(A1, C0)| = L; |P(An, C0)| = S;
: the node N with the distance Y to C0
: the marking probability of node Z 
with the distance X to C0
)(x
)(YN
|A
n , N
|=S-Y
|A 1 
, N
|=L
-Y
|N,C|=Y
 
Fig. 1. Illustration of the (a) LPF and (b) SPF 
Based on the above discussion, SPPM will use SPF to determine the marking probability of 
each node as follows:  
1
)(
1
1


j
i
Min 
  
(5) 
Where node j is an ancestor of node i that means i is the conjunction point of many 
chains, while j directly transmits data to i 
 
The graph below shows an example that details the marking probability assignment for the 
SPPM. Fig. 2 shows a network topology with the original marking probability for each node. The 
joint node D determines its own marking probability is 1/4 because 1/3 is the minimum of its 
ancestors (C=1/3; H=1/2; F=1). With the probability propagation, L1=1/[1/Min(D =1/4, I=1) + 
1]=1/5.  
 10 
initialization process. After initialization, the nodes discover its neighbors periodically by 
“HELLO” messages and maintaining a neighbor list with a format (ID, Location) where ID 
is its neighbor node ID and Location indicates the front/back direction to the cluster head. If 
a node i is front of node j then node i is closer to cluster head than node j. Depending on the 
system implementation, either the Base Station chooses a cluster head based on the hybrid 
information of location and energy level or a sensor node nominates itself as a cluster head 
(e.g., LEACH). 
 Step 2: The cluster head sends out the “setup” message with its node ID as a cluster head to 
all cluster members for each participated group. 
 Step 3: After receiving the “setup” message at this round, the member sensor node sends 
“join” message with its packet marking probability (PMP) to its corresponding Custer head 
for committing to associate the group. There are two possible ways for intra-cluster 
communications: messages can be sent directly to its cluster head or indirectly through an 
intermediate neighboring node. In case of the indirectly communication, the sensor node 
propagates the “join” message to its one of neighbor list with a “front” location. The 
sequence of joining nodes is the transmitting path for DCM phase. If there is no “join” 
message from the “back” neighboring node within a sampling window, it would assign its 
PMP as 1. Otherwise, the “front” sensor will assign PMP based on Eq. (5). 
 Step 4: Each node sends/forwards the data to its “back” neighbor with its probability 
marking. 
4   Experiment and Evaluation  
This section presents performance evaluation obtained from simulation conducted by the QualNet (v4.0) for the 
proposed SPPM. We use two factors (JD and BL) to investigate the efficiency of SPPM compared with that of other 
approaches and LPF. As shown in Fig. 1, we assume there are the longest path (as |A1, C0|) and the shortest path (as 
|An, C0|). Let JD denote as join distance which represents the hop counts from a join point (N) to the sink (C0), i.e. 
|P(N, C0)|. We also define BL as the branch length which stands for the length of the insertion branch at N, i.e. |P(An, 
N)|. Now, we illustrate experiment results as follows: 
4.1   The Impact of JD 
In this JD impact analysis, we assume the main trunk line |P(A1, C0)| = 20 and BL = 6. Fig. 4 depicts the simulation 
results of seven kinds of probability distribution schemes. The x-axis represents the position of the joint point (as JD) 
by different schemes, and the y-axis represents the number of packets required for traceback on behalf of 
convergence time. The results reveal the following three clues: 
 
 12 
 
Fig. 5. Comparison of Marking Probability Schemes by Branch Length 
 
5   Conclusions 
Marking probability plays a very important role in PPM, especially affecting the convergence 
time of the algorithm. Having an optimal probability distribution function for hierarchical WSN 
is a hard work, but will repay the system with lower convergence time and higher system 
dependability. In this paper, we propose an efficient stratified probability propagation model 
(SPPM) based on the concept of probability propagation. SPPM assigns marking probability for 
each node in a distributed fashion by integration of the long path and cluster formation phase. 
The efficiency of SPPM is compared with that of LPF (largest-probability based function) and 
that of other fixed probability schemes, and experimental results show that SPPM has the 
superior performance for low convergence time. This study has confirmed that SPPM can provide 
an effective and practical solution to be applied in a hierarchical WSN environment.  
Reference 
1. A. C. Snoeren, C. Partridge, L.A. Sanchez, C.E. Jones, “Hash-Based IP Traceback”. Proceeding in ACM. 
SIGCOMM, Aug. 2001, pp. 3-14. 
2. A. D. Wood and J. A. Stankovic, “Denial of Service in Sensor Networks”. IEEE Computer, October. 2002, pp. 
54-62. 
3. A. Ephremides, J.E. Wieselthier and D.J. Baker, “A design concept for reliable mobile radio networks with 
frequency hoping signaling”. In proceeding of the IEEE, vol. 75, issue 1, pp. 56-73, Jan. 1987. 
4. A. Manjeshwar and D. P. Agrawal, “APTEEN: A Hybrid Protocol for Efficient Routing and Comprehensive 
Information Retrieval inWireless Sensor Networks”. 16th International Parallel and Distributed Processing 
Symposium (IPDPS), pp. 195 – 202, 2002. 
5. A. Manjeshwar and D. P. Agrawal, “TEEN: a Routing Protocol for Enhanced Efficiency in Wireless Sensor 
Networks”. In Proceeding of the IEEE 15th International Symposium on Parallel and Distributed Processing, pp. 
2009-2015, April 2001. 
