 II
一、 中文摘要 
探勘資料串流是近年來熱門的研究議題。不論是線上或離線的資料串流，其特性是快
速、大量、隨時間改變、無法預測且持續不斷產生。依據資料的處理模式，可以分成標界
模式、時間衰減模式、與滑動窗模式。資料串流的探勘因為其資料並不固定，因此比傳統
探勘難，必須設計單次掃瞄無限制資料串流的有效率探勘方法。如何改善現有方法的效率
與呈現更精確的近似結果仍然是此領域值得挑戰的議題。 
由於資料串流並無法保留全部的歷史資料，資料多數也僅能掃瞄一次。因此，如何在
有限的記憶體、單次的掃瞄、甚至有限的運算時間限制下得到所求相當困難。循序樣式探
勘的複雜度遠比高頻樣式探勘難。在資料串流中探勘，因為更動態，又必須考慮同依序列
需要合併的問題、時序的關係、以及變動的時間限制，因此問題更加複雜。 
本計畫的研究，提出一個後向式漸增探勘序列樣式的方法。此後向式合併的架構與探
勘方法，可以運用於序列樣式資料串流探勘。我們將此架構應用於類似於 Apriori 與樣式
增長的機制並發展了兩個方法。使用合成資料及實際資料實驗的結果證實，此架構與方法
不僅有效率且勝過著名的 IncSpan 演算法。此外，本架構之方法也能隨序列數量增長有線
性的擴充能力。 
 
關鍵詞: 資料串流、串流探勘、漸增序列、循序樣式、頻繁序列、後向式探勘 
 
 IV
目錄 
 
一、 中文摘要……………………………………………………………………II 
二、 英文摘要…………………………………………………………………...III 
三、 報告內容…………………………………………………………………...1 
I. 前言………………………………………………………………………..1 
II. 研究目的 ………………………………………………………………..1 
III. 文獻探討…………………………………………………………………2 
IV. 研究方法………………………………………………………………….4 
V. 結果與討論………………………………………………………………5 
四、 參考文獻……………………………………………………………………8 
五、 計畫成果自評………………………………………………………………10
 2
above approaches. In addition, previous approaches usually assume a fixed minimum support in the mining. 
The minimum support cannot be changed during the mining for these approaches. In data stream processing, 
the aged transaction is discarded and cannot be retrieved back. That is, if the minimum support is changed to a 
smaller value, these algorithms cannot obtain the statistics of the discarded transactions so that the mining 
result will be incorrect. In reality, the user may be interested in patterns across different intervals, comparisons 
of patterns of same length of interval in different time, varying the support, and specific patterns. 
II. 研究目的  
Several algorithms were introduced to deal with the problem of incremental mining of sequential patterns, 
based on common sequence mining algorithms. However, these algorithms still have some limitation on 
finding the unchanged patterns for incremental mining. Previous sequential pattern mining approaches, within 
either Apriori-based or projection-basedframework, mine patterns in a forward manner, called forward mining 
here. Let k-pattern be a sequential pattern with k items. A discovered k-pattern is used as a prefix, and one 
potential item is added after the k-pattern to form the candidate (k+1)-pattern in forward mining. For example, 
after mining pattern <(a) (b)> in forward mining, the pattern is employed as a prefix and one item after the 
pattern is added (or projected), such as <(a) (b) (c)>, to be tested.  
After an in-depth study of the incremental characteristics of sequences, we develop a novel methodology, 
called backward mining, for efficient incremental sequence discovery. In contrast to forward mining, the 
candidate pattern <(c) (b) (a)> is mined after <(b) (a)> is discovered in backward mining. A discovered 
k-pattern is used as a postfix, and one potential item is added before the k-pattern to form the candidate 
(k+1)-pattern in the proposed backward mining methodology.  
To the best of our knowledge, no algorithms with backward mining flow have been proposed for the 
mining and the maintenance of sequential patterns. In this report, we present the backward mining 
methodology and describe a unique property, called stable sequence properties, for incremental discovery of 
sequential patterns. We develop two incremental mining algorithms within different frameworks to show the 
applicability of the backward mining methodology. First, the BSPinc (Backward SPAM for incremental 
mining) algorithm utilizes the SPAM algorithm as the basis to incrementally mine the sequential patterns 
within the Apriori-like framework. Second, the BSpan (Backward Sequential PAtterN mining and updating) 
algorithm utilizes the PrefixSpan algorithm to incrementally mine and update sequential patterns within the 
pattern-growth framework. 
III. 文獻探討 
Incremental mining needs to be based on traditional sequential pattern mining. For example, the IncSpan 
algorithm is based on PrefixSpan. IncSpan uses PrefixSpan and the semi-frequent to incremental mining. 
IncSP extends the GSP algorithm to merge newly appended item candidates and previously sequential 
patterns to new candidates. CISpan uses CloSpan as the base mining algorithm and handles the newly 
appended items by deleting old sequences and adding new ones. Nevertheless, these approaches use the 
forward mining methodology. 
IncSP algorithm is an incremental mining algorithm based on GSP algorithm. The GSP algorithm makes 
multiple passes over the database and finds out frequent k-sequences at the k-th database scanning. In each 
pass, every data sequence is examined to update the support counts of the candidates contained in this 
 4
DS4, DS5}, whose increment-union is {b, e, f}. Sequence <a> is stable since {a} ⊄ {b, e, f}. Considering 
<(b,a)>, which is an extension of <a>. <(b,a)>-end is item a, <(b,a)>-pj is {DS2, DS3}, whose increment-union 
is {b, e, f}. {a} ⊄ {b, e, f} so that sequence <(b,a)> is stable. Table 1 lists some projections and 
increment-unions.  
Table 1. The endings and increments in the example database 
sid data sequence ending increment 
DS1 <fad (f,e)>   {f, e} {f, e} 
DS2 <b(e,c)(b,a) eb> {b} {e, b} 
DS3 <f(b,a)(d,b) f> {f} {f} 
DS4 <facd b> {b} {b} 
DS5 <ca> {a} ∅ 
DS6 <e(f,e,b) (d,b)> {d, b} {d, b} 
DS7 <(d,b)> {d, b} {d, b} 
DS8 <(d,b)(e)> {e} {e, d, b} 
DS9 <be(f,b)> {f, b} {f, e, b} 
A unique characteristic in the backward mining approaches is the identification of the stable sequence. 
The stable sequence owns two important properties to be used in the backward mining for the substantial 
improvements on incremental sequence mining. Two properties are fully utilized in the mining. First, the 
support of a stable sequence in UD is the same as that in DB. Second, any extensions of a stable sequence 
must be stable.  
We use SPAM as the fundamental mining framework, enhance it with backward mining, and propose the 
BSPinc (Backward SPAM for incremental mining) algorithm for incremental sequence mining. The 
bitmapped representation is also used in the BSPinc algorithm. The set of 1-patterns are obtained after 
scanning UD once. Each 1-pattern is then extended to form the candidate sequences for further testing. The 
BSPinc algorithm, like SPAM, generates candidate (k+1)-sequences from k-patterns. The candidate patterns 
are then counted to determine whether they are frequent. The order of 1-sequences used for the subsequent 
generate-and-test procedure is irrelevant to the mining result. In BSPinc, we mine the super-sequences of 
1-patterns in lexicographic order. However, both sequence-extensions and itemset-extensions in candidate 
generation are conducted in a backward manner. Fig. 1 shows an example of candidate generation using 
items a and item b, up to the candidate 3-sequences. To determine whether 1-sequence s is stable, the 
increment-union of UD is used. If an item x is not in the increment-union, clearly, x appears in DB but not in 
db. In other word, the increment of any data sequence in <(x)>-pj does not contain <(x)>-end, which is {x}. 
Thus, <(x)> is a stable sequence. The increment-union of UD is obtained after the first scanning of UD. All 
the extensions of <(x)>, where x is not in the union, are free from support counting.  
In determining whether a candidate sequence s of size larger than one is frequent, its inc-projection is 
checked. If s-inc-pj is an empty set, s is stable so that s and all its extensions are eliminated from counting. 
Furthermore, the whole UD is not required for such inc-projection validations. If s’ is an extension of s, then 
 6
execution time are the almost same for both BSpan and PrefixSpan in mining a static database. 
The definitions of basic terms in BSpan are the same as those stated above. We define the terms used 
particularly in the Bspan in the following. A sequence s = <ewew-1… e2e1>, sequence s’ =< evev-1… e2e1>(v ≤ w) 
is a postfix of s. Sequence s’’= <ewew-1…ev+1 ev> is called the prefix of s. For example, the prefix of <fad 
(f,e)> regards to postfix <d(f,e)> is <fa>; The prefix of <e(f,e,b)(d,b)> regards to postfix <b(d,b)> is <e(f,e_)>. 
The projected database of a sequence s is the set of all prefix of data sequences in UD with regards to postfix 
s, denoted by UD|s. The increment-projected database of a sequence s, denoted by s-inc-pdb, is the set of data 
sequences’ prefix which is generated form sequence’s increment. The origin-projected database of a sequence 
s, denoted by s-org-pdb, is the set-theoretic difference of all data sequence in projected database and in 
increment-projected database. For example, the projected database of <d> is {<fa>, <f(b,a)>, <fac>, e(f,e,b), 
∅, ∅} and UD|<fd> is {∅, ∅, ∅}. The increment-projected database of <d> is {<e(f,e,b)>, ∅, ∅} and 
<fd>-inc-pdb is {<e>}. The origin-projected database of <d> is {<fa>, <f(b,a)>, <fac>} and <fd>-org-pdb is 
{∅, ∅, ∅}. 
We use PrefixSpan as the fundamental mining framework, enhance it with backward mining, and 
propose the BSpan algorithm for incremental sequence mining. The method to pseudo projection is the same 
as PrefixSpan algorithm but it project with postfix instead prefix. The BSpan algorithm, like PrefixSpan, count 
(k+1)-sequences from k-patterns’ projection. And the Projected database can also be divided into 
increment-projected database and origin-projected database. If the sequence has support count in 
increment-projected database then the sequence is not stable sequence. The un-stable sequence needs to 
generate new projected database and recursively mining. If the sequence has not supported in 
increment-projected database then it is stable sequence. We can prune the new projected database generation 
and support count step with stable sequence. Fig. 3 presents the BSpan algorithm. 
 The BSpan algorithm first scans UD to get all 1-patterns, generate their projected database and detect 
new appended item in data sequences to divided projected database into two parts, increment-projected 
database and origin-projected database. The increment-union of UD is obtained in the same time. All the 
1-patterns that do not appear in the increment-union are stable sequences.  
 The most time-consuming step in sequential pattern mining is the support counting step, which needs to 
scan the projected databases several times. Our backward mining can skip the support counting step of stable 
sequences because the support count of a stable sequence in UD is the same as that in DB. Such a technique is 
referred to as stable sequence pruning. Moreover, a unique property is introduced by backward mining: any 
extension of a stable sequence must be stable. Thus, once a stable sequence s is discovered, the support 
counting step of all extensions of s can be skipped. The stable sequence pruning can significantly speed up the 
incremental mining process. For the reason we can not only skip the support count step but also the further 
step to generate new projected databases. 
To determine whether a stable sequential pattern s is still frequent after updating, we can simply check its 
support count, which is available without any computations, against the new minimum support count in UD, 
i.e. minsup*|UD|. 
 To determine whether sequence s is stable, its inc-pdb is checked. If s-inc-pdb is an empty set, s is stable 
so that s and all its extensions are eliminated from counting. Furthermore, the whole UD is not required for 
such inc-projection validations. If s’ is an extension of s, then UD|s is a subset of UD|s’ and s’-inc-pdb is a 
subset of s-inc-pdb. Therefore, the search space is shrunk iteratively during mining. We may skip the checking 
 8
of semi-frequent patterns. Two optimizations including reverse pattern matching and shard projection are 
presented in IncSpan. The shard projection technique is to project the similar projected database in the same 
time. Reverse pattern matching is totally different from our proposed backward mining. We compared the 
execution times of incremental mining using IncSpan and our approaches with respect to different 
modification ratios. BSPinc and BSpan works an average of 4 times faster than IncSpan for all the 
modification ratios on mining dataset C10-T2.5-S4-I1.25, as shown in Fig. 4. When the modification ratio 
increases, the number of stable sequences decreases so that the total execution time increases. Fig. 5 depicts 
that the improvements of incremental mining over re-mining. It shows that incremental mining algorithms 
IncSpan, BSPinc and BSpan definitely outperform their re-mining based counterparts. BSPinc and BSpan 
improve mush more from backward mining than IncSpan. The experiments of total execution times over 
various minsups show that BSPinc and BSpan consistently outperform IncSpan with respect to different 
minimum supports.  
 
Fig. 4. Effects of varying modification ratio  
 
Fig. 5. Effects of improved ratio of varying modification ratio  
Both SPAM and BSPinc may consume a considerable amount of memory. The amount depends on the 
total number of data sequences, the total number of items, and the lengths of data sequences. Given 10000 
customers, 10000 items, and sequence lengths 32, it may use up to 10000 * 10000 * 32 * 4 = 400 Mbytes. The 
peak memory used by SPAM was 458 MB for dataset C10-T2.5-S4-I1.25 with minsup 0.001. When the 
modification ratio was 10%, the peak memory used by BSPinc was 469 MB. BSPinc uses too large memory 
C10-T2.5-S4-I1.25, |UD|=10K, db=100~4k,N=10000, minsup=0.1%
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
1% 2% 5% 10% 20% 40%
Modification ratio
To
tal
 ex
ec
uti
on
 tim
e r
ati
o
T(PrefixSpan)/T(BSpan) T(SPAM)/T(BSPinc) T(PrefixSpan)/T(IncSpan)
C10-T2.5-S4-I1.25, |UD|=10K, db=50~4k,N=10000, minsup=0.1%
0
5
10
15
20
25
30
35
40
45
0.50% 1% 5% 10% 20% 40%
Modification ratio
To
tal
 ex
ec
uti
on
 tim
e (
se
c.)
BSpan BSPinc IncSpan
 10
 
Fig. 8. Effects of improved ratio of varying modification ratio 
  
Fig. 9. Effects of varying minsup 
四、參考文獻 
(I) 計畫相關之著作 
1. Ming-Yen Lin, Sue-Chen Hsueh, Chien-Hsiang Tung, "Interactive Stream Mining of Maximal 
Frequent Itemsets Allowing Flexible Time Intervals and Support Thresholds," the ACM Fourth 
International Conference on Ubiquitous Information Management and Communication, 2010-01. 
Suwon, Korea. (EI) 
2. Ming-Yen Lin, Sue-Chen Hsueh, Ming-Hong Chen, and Hong-Yang Hsu, "Mining Sequential 
Patterns for Image Classification in Ubiquitous Multimedia Systems," the IEEE Fifth 
International Conference on Intelligent Information Hiding and Multimedia Signal Processing, 
pp. 303-306, 2009, Kyoto, Japan. (EI) 
3. Ming-Yen Lin, Sheng-Kun Hwang, and Sue-Chen Hsueh, "Interactive Discovery of Frequent 
Patterns in a Data Stream of Landmark Model," Submitted to Expert System with Applications 
(Paper no.: ESWA-D-10-00831). (SCI) 
4. Ming-Yen Lin, Tzer-Fu Tu, and Sue-Chen Hsueh, "High Utility Pattern Mining using the 
Maximal Itemset Property and Lexicographic Tree Structures," Submitted to IEEE Transactions 
Gazelle, modification ratio=10%
0
5
10
15
20
25
30
35
40
0.04% 0.05% 0.06% 0.07% 0.08%
minsup
To
tal
 ex
ec
uti
on
 tim
e (
se
c)
BSpan IncSpan PrefixSpan
Real dataset Gazelle, minsup=0.04%
0
0.5
1
1.5
2
2.5
0.50% 1% 2% 5% 10% 20% 40%
Modification ratio (%)
To
tal
 ex
ec
uti
on
 tim
e r
ati
o
T(PrefixSpan)/T(BSpan) T(PrefixSpan)/T(IncSpan)
 12
Data Stream Using Synopsis Vectors,” Proceedings of Pacific-Asia Conference on Knowledge 
Discovery and Data Mining (PAKDD2006), pp. 724-728, April 2006.  
14. G. S. Manku and R. Motwani, “Approximate Frequency Counts over Data Streams,” Proceedings 
of the 28th VLDB Conference, pp. 346-357, Hong Kong, China, August 2002. 
15. S. N. Nguyen, X. Sun, and M. E. Orlowska, “Improvements of IncSpan: Incremental Mining of 
Sequential Patterns in Large Database,” Proceedings of the 9th International Conference on 
Advances in Knowledge Discovery and Data Mining, pp. 442-451, May 2005. 
16. S. Parthasarathy, M. J. Zaki, M. Ogihara, and S. Dwarkadas, “Incremental and Interactive 
Sequence Mining” Proceedings of the 1999 ACM CIKM International Conference on Information 
and Knowledge Management, pp. 251-258, November 1999. 
17. J. Pei, J. Han, H. Pinto, Q. Chen, U. Dayal, and M. C. Hsu, “Mining Sequential Patterns by 
Pattern-Growth: The PrefixSpan Approach,” IEEE Transactions on Knowledge and Data 
Engineering, Vol. 16, No. 11, pp 215-224, November 2004. 
18. J. D. Ren and X. L. Zhou, "An Efficient Algorithm for Incremental Mining of Sequential 
Patterns," Proceedings of the 4th International Conference on Advances in Machine Learning and 
Cybernetics, pp. 179-188, August 2005. 
19. R. Srikant and R. Agrawal, “Mining Sequential Patterns: Generalizations and Performance 
Improvements,” Proceedings of the 5th International Conference on Extending Database 
Technology, pp. 3-17, March 1996. 
20. D. Yuan, K. Lee, H. Cheng, G. Krishna, Z. Li, X. Ma, Y. Zhou, and J. Han, “CISpan: 
Comprehensive Incremental Mining Algorithms of Closed Sequential Patterns for 
Multi-Versional Software Mining,” Proceedings of the SIAM International Conference on Data 
Mining, pp. 84-95, April 2008. 
21. M. J. Zaki, “Efficient Enumeration of Frequent Sequences,” Proceedings of the 1998 ACM 
CIKM International Conference on Information and Knowledge Management, pp. 68-75, 
November 1998. 
 14
可供推廣之研發成果資料表 
□ 可申請專利  ▓ 可技術移轉                                     日期：99 年 10 月 31 日 
國科會補助計畫
計畫名稱：互動式資料串流頻繁樣式探勘技術之研發 
計畫主持人：林明言         
計畫編號：NSC-98-2221-E-035-069 學門領域：資訊 
技術/創作名稱 後向式頻繁序列漸增式探勘 
發明人/創作人 林明言、詹志勤 
中文： 
目前所提出來的頻繁序列漸增探勘方法，大都是以「前向式」的方
法，將新的資料合併於舊的序列。 
我們設計了一個高效能、後向式漸增探勘頻繁序列的方法，可以配
合樣式增長或候選檢視的方法架構，探勘漸增式的循序樣式，也可
以應用於串流頻繁樣式探勘及支援實務應用。 
 
技術說明 英文：Current methods for incremental sequence mining are based on 
the forward mining framework. The newly generated transactions are 
merged directly at the rear end of the same sequence. Such a naïve 
merging is ineffective for sequence mining of incremental databases or 
data streams. We have devised a new backward mining framework that 
is very efficient for incremental mining of sequential patterns. The 
framework can be used in pattern-growth or Apriori-like 
methodologies. The methods can be effectively applied to data stream 
frequent sequence mining and practical applications. 
可利用之產業 
及 
可開發之產品 
資料庫、資料工程 
Incremental data stream mining software 
技術特點 
Backward framework 
Incremental mining 
Sequence data  
Sequential patterns 
推廣及運用的價值
The method can be used to mine sequence data. For example, the 
method can be used in chain-store transactions and flexiblely discover 
interesting sequential patterns for further real-time actions. 
※ 1.每項研發成果請填寫一式二份，一份隨成果報告送繳本會，一份送 貴單位研發成果推
廣單位（如技術移轉中心）。 
※ 2.本項研發成果若尚未申請專利，請勿揭露可申請專利之主要內容。 
※ 3.本表若不敷使用，請自行影印使用。 
同的討論觀點，豐富了與會者與筆者的國際觀與研究的視野。加上這次筆者積極的參與討論、踴
躍提出問題，會議中獲得的交流並不亞於過去參加的國際會議。會議 session chair 所提可採用
之 image feature 也頗值得再研究。 
三、考察參觀活動: 略(無是項活動) 
四、建議 
 請多給予經費，以利於帶博士生參加會議，增加國際交流。 
五、攜回資料名稱及內容 
 (1) IIHMSP 2009 會議議程資料 
(2) IIHMSP 2009 CD (會議論文登錄於 IEEE Xplore) 
六、其他 
 感謝國科會核准經費，使本人能順利前往日本參與國際會議，並發表研究論文。 
 
 
 
 
III. THE PROPOSED METHOD 
Figure 1 depicts an overview of the proposed method for 
image classification. Objection segmentation and low-level 
feature extraction are applied to an image to obtain the 
sequence representation of the image, which is a sequence of 
feature-sets. The method consists of two stages. In the 
classifier construction stage, training images in each class are 
transformed into data sequences first, sequence rules are then 
mined, conflict rules having the same patterns are pruned to 
obtain a reduced set of rules, and useful rules are selected to 
form the classifier finally. In the classifier prediction stage, 
the sequence representations of test images with class labels, 
or new images without class labels, are acquired. Assisted by 
a pre-determined heuristics, the classifier predicts the class 
label of the image using the corresponding sequence 
representation. We provide four heuristics, which are T3PN, 
T3P, T1PN, and T1P, to be used with the classifier. 
image
Object segmentation Low level feature extraction
<(fi1, fi2, …, fik)(fj1, fj2, …, fjk)…(fm1, fm2, …, fmk)> 
data sequence  
mine (class 1)
sequential patterns
data sequence  mine (class 2) sequential patterns
data sequence  
mine (class n) 
sequential patterns
Sequence rules
Sequence rules
Sequence rules
remove
conflict
sequence
rules
reduced 
set 
of 
sequence 
rules
Classifier
select 
useful 
rules
prediction
heuristicsT3PN,T3P,T1PN,T1P
Test data
with label
New data
without label
Predicted
Class
label
sequence-representation of an image
a sequence of feature-sets
Training data
 
Figure 1.  Overview of the proposed method 
A. Construction of the image classifier  
The problem of building the image classifier is now 
transformed to construct a classification model using the 
labeled sequences.  
The sequence rules in a class C are obtained by mining 
all the sequential patterns in the class by specifying a 
minimum support. We use METISP [?], a memory time-
indexing approach for discovering sequential patterns with 
time constraints, to discover the sequential patterns in each 
class, specifying only the minimum support constraint. Each 
sequential pattern s forms a sequence rule s → C for the 
classifier. The sequence rules discovered from all the 
different classes are collected to construct the set of 
predicting rules. The classification model contains many 
sequence rules and some of them may be conflict. Two 
sequence rules SR1: s1 → C1 and SR2: s2 → C2 are conflict 
if s1 = s2 and C1 ≠ C2. Only the one having the largest 
support count of the conflicting sequence rules is kept in the 
classifier. 
After pruning the conflicting rules, we further select the 
useful rules to form the basis of the classifier. We classify 
the training dataset using current classifier and compute its 
coverage. The final classifier is determined if the coverage of 
present classifier is above a pre-determined threshold. 
Otherwise, minimum supports are adjusted, and then mining 
of patterns and rules, pruning of conflict rules, selection of 
useful rules, and coverage computation are re-applied until 
the final classifier is constructed. 
B. Prediction strategy  
The selection of sequence rules and the class label 
determination strategy greatly influence the prediction 
accuracy of the final classifier. A labeled sequence LS={s, C} 
is said to cover a sequence rule SR:s’ →C’ if s contains s’, 
despite that C might be different from C’. The covered count 
of SR is the number of sequences covering SR in the training 
dataset. All the sequence rules are sorted in length-
decreasing order before calculating the covered counts of 
sequence rules. The covered count of the first sequence rule 
SR covered by an LS is increased by one if the label of SR is 
the same as that of LS, and decreased by one if both labels 
are different. The covered count of each SR, initially zero, is 
calculated after checking against every labeled sequence. 
Sequence rules of zero covered count are removed from the 
classifier. We characterize rules with positive covered counts 
as P-rules, and negative covered counts as N-rules to be used 
in the prediction.  
Two strategies can be used in the prediction, using only 
P-rules or using N-rules as well. The classifier now is a mix 
with sequence rules of various class labels, listed in length-
decreasing order for fast matching for both strategies. The 
class label of a sequence is predicted using top-one rule, 
denoted by T1, or top-three rules, denoted by T3. Thus, four 
prediction heuristics named T3PN, T3P, T1PN, and T1P can 
be used for the prediction.  
In addition to the covered count, the length of a rule is 
engaged in the determination of the class label. Because it is 
more difficult to contain a longer sequence, the score is 
defined in proportion to the length of the sequence. Use 
T3PN heuristics as an example. Given a sequence s to be 
predicted, in every class, we find the top-three P-rules and 
top-three N-rules covered by s and sum up the score in each 
class. P-rules contribute positive scores while N-rules, 
representing wrong classification, contribute negative scores 
in the summation. The score is defined in proportion to the 
length of the sequence rule. The label of sequence s is 
predicted as the class having the highest score. 
IV. EXPERIMENTAL EVALUATIONS 
Extensive experiments were performed to assess the 
performance of the proposed algorithm. 
V. CONCLUSION  
In this paper, we have presented an approach for image 
classification using sequential patterns. After segmentation 
of the image and extraction of the low level features, an 
image is represented as a sequence of feature-sets. The 
kernel of the proposed approach, then, is the construction of 
the sequence-based classifier. The sequence-based classifier 
collects sequence rules from sequence mining and resolves 
conflict rules. Experimental evaluations using synthetic 
Interactive Stream Mining of Maximal Frequent Itemsets 
Allowing Flexible Time Intervals and Support Thresholds
Ming-Yen Lin 
Dept. of IECS  
Feng Chia University 
Taichung, Taiwan 
+886-4-24517250#3747 
linmy@fcu.edu.tw 
Sue-Chen Hsueh 
Dept. of IM 
Chaoyang University of 
Technology 
Taichung, Taiwan 
+886-4-23323000#4231 
schsueh@cyut.edu.tw 
Chien-Hsiang Tung 
Dept. of IECS 
Feng Chia University 
Taichung, Taiwan 
+886-4-24517250#3747 
M9622291@fcu.edu.tw 
 
 
ABSTRACT  
Stream data mining is to extract useful patterns or knowledge 
from continuous, rapid data elements in modern applications. The 
discovery of frequent patterns in data streams generally is 
constrained by the usage of bounded memory and computation 
time. Most algorithms for mining frequent itemsets in streaming 
transactions assume a fixed minimum threshold and an 
unchangeable time interval. The support threshold, however, 
should be changeable to cope with the needs of the users and the 
characteristics of the incoming data. In addition, allowing the 
specification of the interesting time period of data may enhance 
the discovered knowledge. Still, the number of frequent itemsets 
might be too large to discovering the trends or changes. Thus, 
maximal frequent itemsets (MFIs) with respect to a changeable 
support in a user specified period become a favorable objective in 
stream data mining. In this paper, we propose an algorithm named 
VIMFI for mining MFIs in a data stream, allowing an arbitrary 
time interval and support threshold. A bounded memory space is 
allocated for summarizing all the transactions. VIMFI appends 
transactions to the summary structure and compresses the 
structure when it becomes full. Corresponding transactions in the 
specified interval will be extracted and a mining will be 
performed for the desired MFIs within that interval. Experiments 
using both synthetic and real-world datasets demonstrate that 
VIMFI efficiently mines MFIs in data streams with flexible time 
intervals and changeable support thresholds. 
Categories and Subject Descriptors 
H.2.8 [Database Management]: Database Applications-Data 
Mining 
General Terms 
Algorithms, Performance 
Keywords 
Data stream, maximal frequent itemsets, interactive mining, 
variable support, variable interval. 
1. INTRODUCTION 
Database and knowledge discovery communities have conducted 
focused studies on data streams. A data stream is a real time, 
unbounded sequence of data items continuously generated at a 
high rate. There are currently many applications that generate 
large amounts of stream data in real time, such as web 
transactions, network flows, telephone records, and chain store 
transactions. In fact, more real-world data applications are now 
data stream models other than traditional static databases. 
Modeling the unbounded stream as persistent relational records is 
no longer sufficient for answering diverse queries and providing 
in-time responses. Traditional database management systems and 
data mining methods have become inadequate to support the 
functionalities of modeling this new class of data. For example, 
frequent pattern discovery such as association rule mining now 
demands new mechanisms to handle the rapid and time-changing 
data streams. 
In general, data streams have five characteristics, which pose 
some inherent challenges for the processing of data streams. First, 
data elements are continuous, unbounded, and high speed; each 
data element in the stream can be examined only once, as there is 
insufficient time to rescan the whole database. Second, the mining 
method of data streams needs to adapt to various data 
distributions in a reasonable time. Third, since a data stream is 
high-speed, processing needs to occur as quickly as possible; the 
speed of the mining algorithm should be faster than the rate of the 
incoming data, so that errors of the outputs by approximation 
techniques are as small as possible. Fourth, the mining results of 
the stream should be instantly available upon the user’s request. 
Finally, an unlimited amount of streamed data having limited 
system resources, such as in a memory space, requires a 
mechanism that adapts itself to the available resource. 
The unbounded nature of the data stream disallows the holding 
of the entire stream in memory because a data stream is an 
unbounded sequence of data elements, and often incurs a high 
call-back cost, even if past data can be stored in some external 
media. In general, an algorithm for processing streaming data 
would be restricted to scan the data items only once. In addition, 
the huge amount of streamed data requires the maintenance of a 
summary structure instead of the complete information. 
Consequently, algorithms for stream management, such as stream 
mining algorithms, present approximate rather than accurate 
results, because some data items will inevitably be discarded. 
Permission to make digital or hard copies of all or part of this work for personal or 
classroom use is granted without fee provided that copies are not made or 
distributed for profit or commercial advantage and that copies bear this notice and 
the full citation on the first page. To copy otherwise, or republish, to post on servers 
or to redistribute to lists, requires prior specific permission and/or a fee. 
/ICUIMC’//10/, January 14–15, 2010, Suwon, Korea. 
Copyright 2010 ACM 978-1-60558-893-3…$5.00. 
s to e, denoted by |DS|se, is the number of transactions 
occurring from time s to e in DS. The support of itemset e in 
[s,e], denoted by sup(e)se, is count(e)se /|DS|se. Let the first 
transaction occurring at s be tf and the last transaction occurring 
at e be tl. We may determine tf and t lll by mapping ts(tf) = s and 
ts(tl) = e, respectively. Thus, |DS|se = tid(tl) – tid(tf) + 1. 
At anytime along the coming of stream transactions, the user 
may specify a minimum support threshold ms  (0,1] and two 
times s and e, to discover the maximal frequent itemsets 
(abbreviated as MFI) in time interval [s,e] of DS. An itemset e is 
called a frequent itemset (abbreviated as FI) in [s,e] if 
sup(e)se ms. An itemset e’ is an MFI in [s,e] if e’ is a FI in 
[s,e] and there exists no e’’ such that e’  e’’. The objective is 
to determine the maximal frequent itemsets for any specified time 
period, with respect to any specified minimum support. 
4. THE PROPOSED VIMFI ALGORITHM 
In this section, we describe the proposed algorithm, called VIMFI 
(Variable Interval mining of Maximal Frequent Itemsets), for 
interactive mining of frequent itemsets with variable time 
intervals and supports in a data stream. 
PBV
Compress
PBV & append
Append ti
to PBV
full
Not-full
Interval PBV 
MFPT Tree
s e ms
Maximal
Frequent 
itemsets
Bit-sequence appendingBit-sequence Transformation
Data stream
(a) Transaction appending phase
(b) Interactive mining phase
Ti
t1 t2 t3 …
frequent
1-itemsets
Sub checking
LMFI
Superset checking 
techniques
PBV: Power Bit Vector
s: interval start
e: interval end
ms: Minimum support 
LMFI: local MFI 
MMFP
algorithm
 
Figure 1. An overall concept of the VIMFI algorithm. 
4.1 An Overview of the VIMFI Algorithm 
Figure 1 depicts an overview of the proposed VIMFI algorithm. In 
the transaction appending phase, an incoming transaction ti is 
transformed into a horizontal bit vector of 1’s and 0’s, 
representing the items in ti, and appended to an in-memory 
summary structure named PBV (Power Bit-vectors). The size of 
PBV is bounded so that VIMFI will compress PBV for future 
transactions whenever PBV is full. A counter named cp records 
the number of compressions applied on PBV. The details of PBV 
and the associated compression are described in Section 4.2. 
In the interactive mining phase, a corresponding segment of 
PBV called interval-PBV is extracted with respect to the specified 
time interval from s to e. The segment is then mined using the 
specified minimum support ms. The mining is performed in a 
depth-first manner by determining the frequent items first. The 
composition of the segment may come from an uncompressed 
PBV, a compressed PBV, or both. Hence, the support count of an 
item or an itemset is obtained by a weighted computation. The 
MMFP subroutine, which is based on the GenMax algorithm [8], 
in the VIMFI algorithm is used to find all the maximal frequent 
itemsets (MFI) in the specified interval. A depth-first strategy is 
used in MMFP to recursively find the MFIs. Whenever a potential 
MFI is discovered by MMFP, it will be placed in a pattern tree. A 
group of local MFI will be extracted to speed up the checking of a 
newly discovered MFI of potential. Accompanied with the 
superset checking and subset checking techniques, VIMFI prunes 
a large portion of non-MFIs and mines the MFIs efficiently. 
4.2 PBV and support computation 
Let the number of items be N. The Power Bit-vectors PBV is a W 
by N bits structure where W is referred to as window size. The 
PBV is also viewed vertically as N bit sequences, denoted by 
BS(), BS(), …, BS(). Additionally, a pointer named fp 
indicates the first free bit-position for appending a new bit vector. 
Thus, an incoming transaction ti will set the first free bit-position 
of BS() to 1 if  is in ti, and clear that of BS() to 0 otherwise. 
For example, let the window size be 4 and DS has four 
transactions, <t1, (abcd)>, <t2, (bcd)>, <t3, (abd)>, and <t4, (bc)>. 
The bit vector of a, BS(a), is 1010 since item a appeared in t1 and 
t4. Similarly, BS(b) is 1111, BS(c) is 1101, and BS(d) is 1110. 
Now fp points beyond the last entry of PBV, which indicates the 
PBV is full. 
The PBV will become full as we append new stream 
transactions to it. VIMFI will compress PBV whenever PBV is 
full. We have to preserve past transactions in an approximated 
form and derive some space for future transactions on 
compressing PBV. We approximate every 2 neighboring 
transactions into one vector for all the existing vectors in PBV in 
a compression. For example, the coming of transaction t5 causes a 
compression of PBV since PBV is full. Current implementation 
selects the later transaction of the two to represent the two 
transactions. Thus, the first bit of BS(d) is 1 after compression. 
Similarly, the second bit of BS(d) is 0 after compression. The fp 
indicates the third entry is the first free bit-position for appending 
a new bit vector. After one compression step, the compression 
count cp is increased by one. Then, the appending of <t5,(abc)>  
sets the third bits of BS(a), BS(b), and BS(c), and clears the third 
bit of BS(d). The fp now points to the fourth entry.  
Consequently, a half of the PBV is reserved for storing the 
transactions intact by the VIMFI algorithm. The very first 
compression approximates W transactions into the first half of 
PBV. After the second compression, the first W/2 transactions 
will be compressed and stored in the first quarter of PBV, the 
second W/2 transactions will be compressed and stored in the 
second quarter of PBV, and the latter half of PBV can be used for 
storing the un-compressed W/2 transactions to come. The cp is set 
to 2 accordingly. Current implementation of VIMFI opts to stop 
appending new transactions when cp is log2W. Consequently, 
VIMFI may handle up to 20 transactions, given W = 8. 
VIMFI extracts interval-PBV, the corresponding segment of 
PBV in [s, e], for mining in the interactive mining phase. For 
convenience, we use PBV[i] to denote the i-th row (i.e., i-th bit 
vector) of PBV. A bit-vector in PBV may represent an exact 
transaction, two approximated transactions, or 2cp approximated 
transactions. For example, when cp = 3, PBV[1] is the 
approximation of transactions t1 to t8, PBV [2] is that of 
transactions t9 to t12, PBV [4] is that of transactions t15 to t16, and 
PBV [8] is transaction t20. That is, the i-th vector in PBV 
represents a different number of transactions with respect to 
method to compress PBV is as described in Section 4.2. Then, the 
subroutine MMFP is used to find the maximal frequent itemsets if 
there is a query of mining MFIs of minimum support ms and time 
interval between s ande. The time interval i and j map to the 
corresponding start and end of the interval PBV to be mined. The 
frequent 1-itemsets are obtained first, then by recursively ANDing 
the bit sequences and applying the maximal itemsets checking 
techniques, VIMFI finds the complete set of MFIs. 
Figure 3. The VIMFI algorithm. 
5. EXPERIMENTAL RESULTS 
We have performed extensive experiments using an AMD 
Sempron 2800+ PC with 1GB memory, running the Windows XP. 
The proposed VIMFI algorithm is implemented in Visual C++. 
Both synthetic datasets and a real-world dataset were used in the 
experiments. The parameters used to generate the datasets, using 
the method described in [1], are listed in Table 1. Dataset 
T10.I4.D200k means that the data stream has 200,000 
transactions (D200K) of average size 10 (T10), and the average 
size of maximal frequent itemsets is 4 (I4). The number of distinct 
items (N) is 1000.  
Three metrics, precision, recall and F-measure, are used to 
quantify the accuracy of VIMFI algorithm. Give a set T of 
frequent patterns mined from exact stream data without any 
approximations and a set O of frequent patterns discovered by 
VIMFI. Precision is defined as |TO|/|O|, the number of truly 
frequent patterns divided by the number of frequent patterns 
discovered by VIMFI. Recall is defined as |TO|/|T|, the number 
of truly frequent patterns divided by the total number of frequent 
patterns. F-measure is the weighted harmonic mean of precision 
and recall and defined as (2precisionrecall)/(precision+recall).  
We have implemented a variation of the VIFI algorithm [18], 
called VIFI_M, for performance comparisons with VIMFI.  
VIFI_M mines MFIs by discovering the set of all frequent 
itemsets and then extracting the maximal ones. In addition, 
VIMFI_60% and VIMFI_70% denote the percentage of PBV that 
is preserved in each compression. For example, VIMFI_60% 
represents that when PBV is full, it will be compressed into 60% 
of its original size so that 40% of the original PBV can be reused 
for new transactions.  
Table 1. Parameters used in the experiments 
Parameter Description Value 
|D| Number of transactions in data stream 200K~5000K 
|T| Average size (number of 
items) per transaction 
10, 15 
|I| Average size of potential 
maximal frequent itemsets 
4, 5 
 
5.1 Efficiency on runtime and memory usage 
In the experiment, the total execution time, memory usage, and 
precision and recall of T10.I4.D200K were investigated. The 
mining interval is the entire history of the data stream and the size 
of PBV is 65536. Figure 4 shows the result of mining 
T10.I4.D200K, varying the minimum support threshold is 1.0% to 
0.1%. VIMFI runs faster than VIFI_M for all the experiments 
because VIFI_M needs to select MFIs from the set of frequent 
itemsets. 
Next, the characteristics of data streams were changed. The 
average size per transaction increases from 10 and 15, and the 
average size of potentially maximal frequent itemsets increase 
from 4 and 5. In general, this change would allow the data stream 
to have more (and longer) frequent itemsets with respect to the 
above minimum support threshold values. In Figure 5, the total 
execution time on mining the entire T10.I5.D200K is shown. 
as shown in Figure 9, since VIMFI_70% has to decompress more 
entries than the other two. The required memory space for the 
three compression ratios is nearly the same since they all used 
fixed amount of PBV size, as shown in Figure 10. Table 3 lists the 
number of discovered patterns by the three compression ratios in 
the three intervals. The true total number of patterns in interval A, 
B, and C is 11416, 8639, and 9379, respectively. The true 
maximum length of patterns is all 10 for all the three intervals.  
To summarize, when more transactions are used to approximate 
the same number of transactions, the accuracy will be higher but 
the execution time will be longer. We also observed one particular 
situation in the accuracy computation of maximal frequent 
itemsets as follows. When one MFI of length k is not discovered 
but some of its subsets of length k-1 are discovered, the F-
measure decreases quickly. For example, if itemset {a, b, c, d} is 
an MFI but itemsets {a, b, c}, {a, c, d} and {b, c, d} are mined as 
MFIs after some approximations by compressions, both the 
precision and the recall are decreased. The accuracy of 
discovering MFIs should be performed after enumerating the 
MFIs. However, the experiments of varying intervals show that 
VIMFI may discover MFIs in a data stream with respect to user-
specified intervals. 
 
Figure 7. Scale up of a data stream from 200K to 1000K. 
 
Figure 8. Scale up of a data stream from 1000K to 5000K. 
 
Figure 9. Total execution time w.r.t. various intervals. 
 
Figure 10. Required memory w.r.t. various intervals. 
6. CONCLUSIONS 
In this paper, we have proposed the VIMFI algorithm for mining 
maximal frequent itemsets over a data stream with changeable 
support threshold and time interval. VIMFI allocates a bounded 
memory called PBV for summarizing transactions, represented as 
bit sequences. VIMFI will compress the PBV to accommodate 
more incoming transactions. The corresponding segment of 
transaction sequences will be extracted and the maximal frequent 
itemsets in the interval will be mined for the specified minimum 
support. Moreover, VIMFI uses the set of local maximal frequent 
itemsets to speed up the superset checking so that the maximal 
frequent itemsets can be quickly identified. Our comprehensive 
experiments confirm that VIMFI efficiently mines maximal 
frequent patterns with respect to variable supports and flexible 
intervals, and has good linear scalability. 
7. ACKNOWLEDGMENTS 
This research was supported partially by the National Science 
Council, Taiwan, under grant NSC98-2221-E-035-069. 
8. REFERENCES 
[1] Agrawal, R. and Srikant, R. 1994. Fast algorithm for mining 
association rules. Proceedings of the 20th International 
Conference on Very Large Databases. pp. 487-499. 
[2] Ayres, J., Flannick, J., Gehrke, J., and Yiu, T. 2002. 
Sequential pattern mining using a bitmap representation. 
Proceedings of the 8th ACM International Conference on 
Knowledge Discovery and Data Mining. pp. 429-435, July. 
[3] Bayardo Jr., R. J. 1998. Efficiently mining long patterns 
from databases. Proceeding of Special Interest Group on 
Management of Data. pp. 85-93, June. 
國科會補助計畫衍生研發成果推廣資料表
日期 2010年11月01日
國科會補助計畫
研發成果名稱
發明人
(創作人)
技術說明
技術移轉可行性及
預期效益
技術/產品應用範圍
產業別
計畫名稱:
計畫主持人:
計畫編號: 學門領域:
(中文)
(英文)
成果歸屬機構
(中文)
(英文)
高效能資料串流循序樣式探勘技術之研發
林明言
98 -2221-E -035 -069 - 資料庫系統及資料工程
後向式頻繁序列漸增式探勘
Backward mining of incremental sequential patterns
逢甲大學 林明言,詹志勤
目前所提出來的頻繁序列漸增探勘方法，大都是以「前向式」的方法，
將新的資料合併於舊的序列。 由於新增的交易，在序列探勘中，如果屬於同一
顧客，需要合併舊有的序列，因此，前向式的方式，必須將所有受影響的序列
重新檢視。
不論是資料串流或者一般的漸增序列資料庫，這種方式的探勘效能都大受影響
。
我們設計了一個後向式的探勘架構，將樣式的組成與探勘，由最後的交易看起
，因此，許多資料序列或者樣式的產生，不再受序列合併舊資料影響，整題探
勘效能也因此可以大幅提昇。本研發成果中，
我們設計了一個高效能、後向式漸增探勘頻繁序列的方法，可以配合樣式增長
或候選檢視的方法架構，探勘漸增式的循序樣式，也可以應用於串流頻繁樣式
探勘及支援實務應用。
Current methods for incremental sequence mining are based on the
forward mining framework. The newly generated transactions are merged
directly at the rear end of the same sequence. Such a naïve merging
is ineffective for sequence mining of incremental databases or data
streams. We have devised a new backward mining framework that is very
efficient for incremental mining of sequential patterns. The
framework can be used in pattern-growth or Apriori-like
methodologies. The methods can be effectively applied to data stream
frequent sequence mining and practical applications.
資訊服務業
資料庫、資料工程
Incremental data stream mining software
The method can be used to mine sequence data. For example, the method can
be used in chain-store transactions and flexiblely discover interesting
sequential patterns for further real-time actions.
註：本項研發成果若尚未申請專利，請勿揭露可申請專利之主要內容。
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
