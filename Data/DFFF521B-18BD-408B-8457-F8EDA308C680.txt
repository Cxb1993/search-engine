 2
  
一、中文摘要 
提供肢體障礙者一個無障礙的生活空
間，一直是各以開發國家努力的目標。但
無障礙空間設施畢竟是屬於一項被動式輔
助設施，因此爲視障者發展一套主動式的
視障者導行系統來因應變遷環境是一個相
當重要的課題。雖然文獻中已有ㄧ些不同
導行的策略被提出，但均處於概念性階
段。從 1992 年影像資訊轉換成聲音資訊流
的導行概念以來，近十年內也陸續提出相
關的研究，並開發資料聲音化研究的新紀
元。但是以往研究文獻基於達到即時性資
訊提供的目標，始終停留在單眼攝影機二
維影像資料處理，為的就是減少系統的計
算量。這也代表了所得到的並非三維的立
體資訊，最重要的距離資訊或可稱為景物
的深度的資訊卻無法正確提供給使用者。 
本研究希望利用雙眼攝影機來建構視
覺系統，進而將雙眼之影像資訊透過計算
得到影像中三維座標的立體空間資訊。再
利用模糊分類比對方式對物件影像加以分
類，區分重要物件及背景資訊，最後透過
資料聲音化的概念，將影像資訊加以編碼
成聲音資訊流，讓視障者能夠透過此聲音
資訊流了解週遭環境的景物資訊。本計畫
之執行有助於視障者導行技術之研發，亦
可用於其他方面，如智慧型行動機器人系
統。 
 
關鍵詞：物件偵測、雙眼視覺、視障、導
行、聲音化 
  
Abstract 
   To provide barrier-free environments for 
physically handicapped people is one of the 
main issues of social welfare of developed 
countries. However, barrier-free facilities can 
only be considered as passive auxiliary 
facilities. Therefore, to develop an active 
guiding system for blinds is a very important 
topic in facing a changing living environment. 
There were different kinds of guiding 
systems in the literature. However, these 
results are still in the state of art and require 
more effort to be realized. The concept of 
using series sound information to carry 
environment data obtained by vision system 
was proposed in 1992. During this decade, 
relative researches have been proposed and 
led to a new era for data sonification 
processing. In order to provide 
environmental data in real time, only one 
camera was used, which provide 
two-dimension information instead of 
three-dimension. In those approaches, the 
computation time is minimized at the cost of 
depth information also known as distance 
accuracy.  
In the proposed research project, a 
stereo vision technique will be applied to 
determine object location in world coordinate 
using binocular camera system. Fuzzy 
classification and pattern recognition will be 
used identify important object and 
background information. Using the propose 
approach, environment information obtained 
from stereo image will be coded as sound 
series data which the blind can understand 
and been guided in an active way. The result 
of this project will be beneficial to the 
development of blind guiding system and can 
be applied to other systems such as mobile 
robots. 
 
Keywords: Object detection, binocular 
vision, visually impaired, navigtion, 
sonification 
 
二、緣由與目的 
根據 WHO 的估計，在 20 年內，全球
視障者的人數將會是現在的兩倍，約 9000
萬人。許多歐美或者是日本的先進國家，
對於創造一個無障礙空間的建設不遺餘
力，但是這些被動式的建設不僅花費昂
貴，並且在實現上也有相當的限制。因此
設計一個主動式的視障者導行系統成為一
個相當重要的課題。早在 1970 年代，就有
許多科學家用各種不同的方法來設計視障
者的導向系統，例如 Optacon (1969)使用的
是裝在手指的震動桿陣列、Sonic Guide 
(1974)利用超音波的回波定位法和 Laser 
Cane (1973)運用紅外線結合傳統手杖等
等，但在使用上都有諸多不便及限制或者
是設備的花費過於昂貴。直到資料聲音化
(Data Sonification) 概念的提出，對於視障
 4
在單一攝影機所擷取到的畫面，都會遺失
實際空間的深度的資訊。基於這個需求可
運用兩個 CCD 攝影機，擷取到兩幅同樣景
物但不同角度的畫面，藉以算出三維的空
間資訊。本研究採用合成立體校正模型(如
圖 4)，利用一個單一校正板的位移，形成
一個由多平面組成的立方體，以建構較大
的攝影機有效量測範圍。 
 
圖 4. 合成立體校正模型 
 
爲達成此目標，研究步驟包括： 
(1)改良攝影機參數校正法：以提供工作範
圍內(距 1.5m~2m 之量測精度)。 
(2)數位影像前處理：以便快速萃取必須之
物件影像點。 
(3)利用 Epipole Geometry 計算重要影像點
之世界座標值：即指定左邊影像上的一
個物件點，就可獲得右邊影像所有可能
對應該點所建構的一直線，進而找出右
影像中之對映點，如圖 5所示。再使用
u 與 u’及校正之攝影機內外部參數計算
物件點世界座標值。 
                                
( )Ty,1x,=u
( )T,1y,x ''u'=0Fu'u =T
 
圖 5. 左影像上的一點與其右影像對映的
epipolar line 
 
圖 6. 影像系統量測示意圖 
 
表 1. 三個校正面構成的空間量測 
（a）旋轉 °30 目標物的量測結果 1 
量測長度(mm) 
(-500) 量測 
距離 
(mm) 
基線
長度
(mm)
待測
長度
(mm)
1 2 3 4 5 6 7 8 
平均
(mm)
誤差
(mm)
1200-1400
(-30deg) 1090 510 9.944 10.041 9.655 9.703 8.791 8.250 9.427 9.424 9.404 -0.596 
1400-1600
(-30deg) 1090 510 7.807 7.798 9.990 10.043 7.966 8.012 9.122 9.076 8.727 -1.273 
1600-1800
(-30deg) 1090 510 9.678 9.741 8.118 8.177 10.736 10.798 6.283 6.229 8.720 -1.280 
1200-1400
(30deg) 1090 510 10.750 10.767 10.020 10.064 9.518 9.605 9.870 9.831 10.053 0.053 
1400-1600
(30deg) 1090 510 10.161 9.953 9.393 9.373 9.454 9.551 8.507 8.464 9.357 -0.643 
1600-1800
(30deg) 1090 510 9.259 9.261 7.865 7.923 6.715 6.662 10.334 10.332 8.544 -1.456 
                9.134 -0.866 
（b）旋轉 °30 目標物的量測結果 2 
量測長度(mm) 
(-500) 
量測距離
(mm) 
基線
長度
(mm)
待測
長度
(mm) 1 2 3 4 5 6 7 8 
平均
(mm)
誤差
(mm)
1200-1400
(-30deg) 1090 510 7.106 7.213 10.935 10.935 6.874 6.840 10.414 10.365 8.835 -1.165 
1400-1600
(-30deg) 1090 510 11.681 11.736 5.448 5.459 10.073 10.128 6.452 6.485 8.433 -1.567 
1600-1800
(-30deg) 1090 510 4.910 4.974 9.631 9.642 4.591 4.647 11.186 11.247 7.604 -2.397 
1200-1400
(30deg) 1090 510 9.523 9.477 10.060 10.019 10.357 10.402 10.153 10.097 10.011 0.011 
1400-1600
(30deg) 1090 510 7.922 7.982 9.363 9.414 8.192 8.150 10.219 10.211 8.932 -1.068 
1600-1800
(30deg) 1090 510 10.327 10.262 9.738 9.806 8.404 8.461 7.866 7.802 9.083 -0.917 
                8.816 -1.184 
由表一可看出藉由合成立體校正模型，可
使整個工作區間 1100mm~1800mm 的量測
誤差都在 0.5mm 以內，對於旋轉的待測物
則可以在 1.5mm 以內。而目前正在進行
2000mm 即 2m 以上距離的校正及量測實
驗。 
 
(2). 建構與測試語音播放系統 
本研究建構了以 Creative Audigy 4 音效
卡、YAMAHA PSR-275 之 MIDI 鍵盤以及
SONAR 軟體之語音播放系統(如圖 7, 8, 9, 
10)。 
 
圖 7. 數位聲音處理系統示意圖 
工作區間
1100 mm
最近的量
測距離
1800 mm
最遠的量
測距離
camera
camera
1090 m
m
0 mm
相對解析度
較好
相對解析度
較差
1600
mm
1700
mm
第一
校正面
slide slide
基線所在位置
第二
校正面
第三
校正面
鏡頭初始
對焦平面
1500
mm
 6
(1) 單一樂器，複雜音階的辨識度實驗 
(2) 以 MIDI 內建之常見樂器，測試單一樂
器彼此間的相似度，用以選出不易混淆
之樂器 
(3) 以(2)之結果，測試兩兩樂器混合之鑑別
度，用以選出混音時仍保持高鑑別度之
樂器 
(4) 以(3)之結果，測試三種樂器混合之鑑別
度，用以選出三種樂器混音時，仍可接
受且鑑別之樂器 
 
其實驗結果如下： 
(1) 單一樂器複雜音階的辨識度。 
隨機組合 1~4 個音階，共 15 組，11
個受測者寫下他們聽到的音階數目。下表 2
列出每組音答對的人數(橫軸表示對應的
音階組合的編號，縱軸表示測試中答對的
人數)。 
 
表 2. 複雜音階(1~4 個音階)鑑別度 
(a) 低音階組合測試 
 
 
 
低音
0
2
4
6
8
10
12
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15
 
 
(b) 中音階組合測試 
 
 
 
中音
0
2
4
6
8
10
12
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15
 
 
(c) 高音階組合測試 
 
 
高音
0
2
4
6
8
10
12
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15
 
 
由表 2 結果，發現人耳對於複雜音階
的鑑別度不高，除了單一音階可明顯被鑑
別出來，只要超過 2 音階混合，鑑別率會
大幅降低。本項目實驗，更針對 2 音階混
合、3音階混合之鑑別度測試，而其結果與
隨機 1~4 音階混合之結果相近，證實人耳
對於複雜音階，不論是 2音階、3音階甚至
是 4音階混合都無法清楚分辨。 
 
(2) 以 MIDI 內建之常見樂器，測試單一樂
器彼此間的相似度，用以選出不易混
淆之樂器。 
從 MIDI 內建合成樂器內，選出常見之 20
種樂器以及 4 種特效，如下表 3，再以 10
位受測者，將 24 種音色播放二次，之後任
意播放這些音色，請受測者寫下聽到的樂
器。根據實驗結果，將容易混淆的樂器刪
除，以剩下樂器再重複上述實驗。最後保
留音色鑑別度最高的樂器如下表 4。 
 
表 3. MIDI 內建常見樂器及特效 
1 鋼琴 9 大提琴 17 豎笛 
2 木琴 10 小號 18 長笛 
3 管鐘 11 大號 19 陶笛 
4 管風琴 12 中音薩克斯風 20 木魚 
5 口琴 13 低音薩克斯風 21 海浪聲
6 吉他 14 法國號 22 鳥鳴聲
7 貝斯 15 雙簧管 23 電話聲
8 小提琴 16 巴松管 24 槍聲 
 
表 4. 音色鑑別度高之樂器 
1 鋼琴 8 大號 
2 木琴 9 長笛 
3 管鐘 10 木魚 
4 管風琴 11 海浪聲 
5 貝斯 12 鳥鳴聲 
6 小提琴 13 電話聲 
7 小號 14 槍聲 
由(2)之測試，可得知表 4 之 14 種高音色鑑
 8
用 HSI 色彩模型來加以做分類，但 HSI 色
彩模型在判別灰色(及 RGB 三成份相同)時
則容易失敗，雖然 HSI 色彩模型有將灰色
(包含白色及黑色，僅是亮度的差別)定
義，但僅定義在 RGB 三成份必須完全相同
的情況下，即為純灰色；而實際上所取的
有灰色地板之照片，因為數位化、亮度及
週遭環境顏色的影響及誤差，所取得之地
板值其 RGB 三成份完全相同的情況相當少
見。因此我們藉由大量的樣本照片加以統
計平均，定義灰色地板如上式(7)。 
一般對於色彩分割(Color Segmentation)
可分為兩種，一是將 RGB 轉換至 HSI 色彩
模型，主要是利用 Hue，配合 Saturation 及
Intensity 為輔助來進行色彩分割。但只要地
板與非地板的色調稍為接近，即使是肉眼
可明顯分辨地板與非地板的情況，HSI 色
彩模型將無法有效的分割地板與非地板區
域。另一個常見判斷錯誤的情況則為同屬
於地板區域的部份，只因為亮度的不均
勻，而造成判斷錯誤。而另外一個常使用
的 色 彩 分 割 方 法 則 是 RGB Vector 
Space(RGB 向量空間)，其基本原理就是將
RGB 三個成分當作 RGB 向量空間的三
軸，因此影像上任一點之 RGB 值，可視為
該空間中的一點的座標，而其分割方法即
為計算任一點座標到基準值的距離，藉由
設定不同的距離的 threshold，可將相近的
顏色的分離出來，但此法耗費大量的計算
時間，並且對於同樣顏色但光度不均勻的
情況也將錯誤分割。 
因 此 本 研 究 提 出 RGB 正 規 化
(Normalization)的方法並以HSI色彩模型為
輔助來分割地板與非地板區域。在此我們
將 RGB Normalization 定義為在時間 t 時，
影像上任一點 f(x,y,t)的 R,G, B 值分別相對
於地板基準值 g(t)的 R, G, B 值的變化率。
在時間 t 的 RGB 變化率 V(t)可以下面的式
子表示。 
BGRjtg
tyxftV
j
j
j ,,    )(
),,()( ∈=  (10) 
經由上式，我們可以得到影像上每一點相
對於地板基準值的變化率，透過適當的門
檻值，可將色彩相近的部分分離出來。 
主要顏色(Maincolor) : 假定某一顏色
的三成份中，某一成份為主要顏色，例如
Red 為其主要成份，那麼該顏色在從亮變
化至暗時，其主要成份之變化率的增量與
減少量會明顯小於另外兩成份之變化量。
因此，在判斷影像上某一點之顏色是否與
地板相近時，我們需將地板顏色之主要成
份決定出來，在分別比較主要成份的變化
率與另外兩成份之變化率。當然我們也考
慮了三成份中有兩成份為主要成份(如 Red
與 Green 同為主要成份)的情況，因此我們
將主要成份的情況分為以下六種，R, G, B, 
RG, RB, and GB。 
 
地板偵測法則(Decision Rules) 
由於地板顏色之主要成份有六種情況，即
為R, G, B分別主要成份三種和RG, RB, GB
分別主要成份三種，而我們所設定的判斷
方法可分為只有單一主要成份以及兩種顏
色同為主要成份兩種，而前述所提的六種
情況只需將我們所設定的主要成份做替換
即可。而為了簡化偵測法則的表示法，我
們先定義以下符號： )(),,( tgtyxfI IIfg −= , 
)(),,( tgtyxfH HHfg −= , ),,( tyxff SS = 和 
)(),,( tgtyxfS SSfg −= 。 
 
彩色地板偵測法則: 
在對彩色地板偵測前，我們皆先將該影像
在亮度及色調上強化，以得到較佳的偵測
結果。 
{ }{ }321),,( CCCC CCCtyxG IU= , 
其中 { } ),,( ),,(1 tyxfHtyxC fgC θ≤= , (11) { } { }{ }),,(  02.0   2  ),,(2 tyxfSHtyxC fgfgC ≤≤<= Iθθ , (12) 
( )
( )
BGRi
tVforTKtV
tVforTKtV
tyxC
iliii
iuiii
C
,, , 
1)(       )(10
1)(       1)(0
),,(3
∈
⎭⎬
⎫
⎩⎨
⎧
≤×≤−≤
≥×≤−≤=
, (13) 
若為主要顏色時 1=iK  , 其他則 2 =iK .  
在此我們將 θ  選定為 30 度. 而第(9)式
的門檻值 )(tTu 與 )(tTl 則定義如下 
( ) BGRjandtVtV
n
tT j
n
j
uj
ju
uj
,,    1)(    , 1)(1)( ∈≥−= ∑ ,(14)
( )     ,,    1)(    , )(11)( BGRjandtVtV
n
tT j
n
j
lj
lj
lj
∈<−= ∑ ,(15) 
ujn 和 ljn  則是可能成為地板點的候選點
n(x,y,t)之數目，其限制條件如下 
 10
值及亮度(intensity)限制，可將灰色地板有
效的分離出來。由於我們將灰色地板時的
RGB Normalization 簡化成 RGB 三成份之
兩兩成份的差距，我們先定義兩兩成份差
距為 
),,(),,( tyxftyxfD GRRG −= , (29) 
),,(),,( tyxftyxfD BRRB −= , (30) 
),,(),,( tyxftyxfD GBBG −= . (31) 
灰色地板之偵測法則定義如下 
{ }{ }{ } CCCCtyxG GrGrGrGrGr 2431 ),,( UII= , (32) 
其中 { }),,(2.0 ),,(1 tyxfItyxC fgGr ≤= , (33) { }),,(01.0),,(),,(2 tyxftyxftyxC SGr ≤= , (34) { }),,(01.0),,(),,(3 tyxftyxftyxC SGr >= , (35) 
⎭⎬
⎫
⎩⎨
⎧
≠
∈≤=
ji
BGRjiTD
tyxC grayijGr    
,,,,  
),,(4 , (36) 
∑
⎟⎟
⎟⎟
⎠
⎞
⎜⎜
⎜⎜
⎝
⎛
−
+−
+−
=
n
GB
BR
GR
gray
tyxntyxn
tyxntyxn
tyxntyxn
n
T  
),,(),,(
 ),,(),,(
),,(),,(
1 . (37)
而後選點 n(x,y,t)之限制條件則如下式表示 { }),,(1.0),,(),,( tyxftyxftyxn S ≤= . (38) 
圖 13 為灰色地板偵測之範例。 
 
      
    (a)原始影像       (b)偵測結果 
圖 13.灰色地板之偵測結果 
 
點校正程序 
在經過地板偵測程序中，由於我們是對
於影像上進行每一點的檢查其對於地板之
色彩相似度，因此我們可以預測到其結果
必然會存有一些被錯誤判定的點。因此，
在本研究提出一個校正方法，利用每一點
之八鄰域的點，來判斷該點是否被判斷正
確或是應該被更正。當有一個點是判斷錯
誤時，例如在地板區域上，有一點應該被
視為地板，但卻判斷錯誤，我們可預期的
現象是該點的周圍應該都是地板值；但若
是在地板區域內的一個物件，而非單一
點，我們可以知道即使在物件與地板的邊
界點，其八鄰域點也不會全為地板值。本
研究提出下面四種應該被保留不需校正的
情況，如圖 14，f(x,y)表示待檢測點，而
Ob 表示被認定為物件(Object)的點，g 表示
被認定為地板(Ground)的點，由下面四種狀
況，我們可以知道當待測點為物件角落
時，其鄰域點為地板的個數為最多(5 個)，
且為下圖四種情況中其中一種，而只要待
測點是位於物件其他部位，其鄰域點為地
板的個數必定小於 5 個；因此若待測點之
鄰域點為地板的個數超過 5 個或是等於 5
個但不為四種模型中其中一種，我們將待
測點視為判斷錯誤，將其更正，反之亦然。 
 
g
g g
g
g
Ob Ob
Obf(x,y)
   
g
g
g
gg
Ob
Ob Ob
f(x,y)
 
        (a)               (b) 
g g g
g
gObOb
Ob f(x,y)
   
g g g
g
g Ob Ob
Obf(x,y)
 
        (c)               (d) 
圖 14.四種位於邊界不需校正之示意圖 
 
   
      (a)         (b)         (c) 
圖 15. 經過點校正之彩色、淺色及灰色地
板偵測結果 
 
地板邊緣偵測(Ground Edge Detection) 
藉由地板偵測以及點校正程序之後，我
們將非地板的區域完全塗黑，合理的忽略
掉非地板區域裡面所含的資訊，這是因為
我們的目標在於找出地板區域並建立可通
行及不可通行的部份，因此非地板區域內
所包含的物件或環境對我們而言並不重
要，因此可藉由將非地板區域完全塗黑來
 12
發出以單攝影機，透過多個獨立基礎矩陣
(Fundamental Matrix)，配合判斷法則，量
測出障礙物所在位置及其三維資訊。 
(39)式為已熟知的基礎對應矩陣中，將
wZ 假設為 0，即為平面轉換對應矩陣
(Homography Matrix)，如(40)式。 
⎥⎥
⎥
⎦
⎤
⎢⎢
⎢
⎣
⎡
⎥⎥
⎥
⎦
⎤
⎢⎢
⎢
⎣
⎡
=
⎥⎥
⎥⎥
⎦
⎤
⎢⎢
⎢⎢
⎣
⎡
⎥⎥
⎥
⎦
⎤
⎢⎢
⎢
⎣
⎡
=
⎥⎥
⎥
⎦
⎤
⎢⎢
⎢
⎣
⎡
1
        
1
0
343231
242221
141211
34333231
24232221
14131211
3
2
1
W
W
W
W
Y
X
ppp
ppp
ppp
Y
X
pppp
pppp
pppp
x
x
x
 (39) 
 
'  ,
1333231
232221
131211
3
2
1
xHx xyw
w
Y
X
hhh
hhh
hhh
x
x
x
=
⎥⎥
⎥
⎦
⎤
⎢⎢
⎢
⎣
⎡
⎥⎥
⎥
⎦
⎤
⎢⎢
⎢
⎣
⎡
=
⎥⎥
⎥
⎦
⎤
⎢⎢
⎢
⎣
⎡
 (40) 
 
除(40)式常用之平面轉換矩陣，用來求取
在某一特定深度( wZ )的物件的 wX 及 wY 之
外，本研究另假設 wY = 0，即將校正板平躺
於地面上，求得另外一組獨立的轉換矩
陣，如(41) 
'  ,
1333231
232221
131211
3
2
1
xHx xzw
w
Z
X
hhh
hhh
hhh
x
x
x
=
⎥⎥
⎥
⎦
⎤
⎢⎢
⎢
⎣
⎡
⎥⎥
⎥
⎦
⎤
⎢⎢
⎢
⎣
⎡
=
⎥⎥
⎥
⎦
⎤
⎢⎢
⎢
⎣
⎡
 (41) 
 
圖 20 為本研究所使用之校正板形式。 
 
圖 20. 校正板樣式圖 
 
本研究之攝影機所架設位置及高度，可拍
攝最近的範圍是距離攝影機 150cm 處，最
遠約至 2000cm，而本研究從 150cm 開始放
置校正板求取一組平面轉換矩陣 150xyH ，每
隔 50cm 再求取一組 200xyH 、 250xyH 、
300xyH … 650xyH 等至 650cm 處。如圖 21 所
示。 
650 cm
50 cm
18 degree
150 cm
10
3.
5 
cm
 
圖 21. 求取多重平面轉換矩陣示意圖 
 
而本研究將校正板平躺於地面上，同樣從
150cm 開始至 650cm，每隔 50cm 放置一次
校正板，但與前述求取多組平面轉換矩陣
不同的是，在此本研究對於平躺於地面不
同距離之校正板，僅求取一組整合知平面
轉換矩陣 xzH ，如圖 22 所示。 
 
650 cm
50 cm
18 degree
150 cm
10
3.
5 
cm
Z
Y
 
圖 22. 求取整合平面轉換矩陣 xzH 示意圖 
 
利用所求的之兩種平面轉換矩陣，實際量
測結果如下圖23和表9以及圖24及表10。 
 
 
圖 23. 實際量測圖(Z = 247) 
 
表 9. 待測物 : 椅子(實際高度 : 77cm) 
Z 值(cm) 
(離攝影機
距離) 
量測 
Z 值 
(cm) 
量測高度
值(cm) 
(使用 Hxy) 
量測深度
值(cm) 
(使用 Hxz)
212 206.57 75.54 626.24 
247 242.95 76.67 765.15 
299 294.03 76.51 865.74 
334 333.00 75.87 969.82 
376 374.45 77.05 1090.60 
436 431.38 76.63 1207.08 
506 502.79 74.21 1351.14 
564 563.71 76.34 1420.55 
634 630.00 77.05 1621.65 
平均誤差 -3.2033 -0.7922  
 14
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
0
500
1000
1500
2000
2500
3000
Normalized Y-coordinate of the lowest pixel
P
ix
el
s
Image size of a large obstacle located from 6.5m to 1.5m
 
 
Measured Obstacle Image Size
 
(a)大物件影像面積(6.5m-1.5m) 
 
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
0
200
400
600
800
1000
1200
Normalized Y-coordinate of the lowest pixel
P
ix
el
s
Image size of a medium obstacle located from 6.5m to 1.5m
 
 
Measured Obstacle Image Size
 
(b)中物件影像面積(6.5m-1.5m) 
 
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
0
100
200
300
400
500
600
700
Normalized Y-coordinate of the lowest pixel
P
ix
el
s
Image size of a small obstacle located from 6.5m to 1.5m
 
 
Measured Obstacle Image Size
 
(c)小物件影像面積(6.5m-1.5m) 
圖 25. 物件影像面積對應物件下緣 Y座標 
 
 
 
 
 
 
表 11. 特定物件於不同距離之影像面積與
正規化面積 
原始影像 地板偵測後 ( ), NA A  
 
(165, 1258) 
 
(400,1211) 
 
(792,1116) 
 
 
而對於將影像上資訊轉為聲音資訊的部
份，本研究在第一年已利用 SONAR 此套軟
體對於MIDI內建之常見樂器完成辨識度測
試，而留下最易被使用者辨識之樂器，而
本研究在本年度亦以 Microsoft Visual 
C++ 程式完成對於 MIDI 音樂的合成及操
作，可在程式內自行控制播放之樂器、音
調、節奏以及響度。而本研究目前以單聲
道播放方式來提供資訊，此乃因若是以雙
聲道提供資訊，會造成使用者無法接受外
界聲音資訊，造成使用上不便及困擾。而
影像資訊轉換聲音資訊規則如下: 
1. 樂器的種類 Q 影像上的各物件 
2. 播放聲音時間序列 Q 影像由左至右 
3. 音調高低 Q 影像上量測之物件尺寸 
4. 響度大小 Q 影像上量測之物件遠近 
 
第三年預期工作項目與完成進度如下 
(1) 影像系統與語音系統之整合。(達成
率 100%) 
(2) 複合式導行資料播報系統之建立。
(達成率 100%) 
(3) 導行系統之測試與使用評估。(達成
率 100%) 
在完成影像三維資訊的萃取，以及影像資
訊轉換聲音規則建立後，根據本研究所使
 16
表 12. 小物件於彩色地板之 MIDI 轉換成果 
 Original Image Hot Zone 
Obstacle 
(MI, PI ) 
(Vol, Pitch)
Wave Form 
1 
(Flute, 9) 
(2, 79) 
0 2 4 6 8 10 12
x 10
4
-0.02
0
0.02
samples
m
ag
ni
tu
de
 
55 
(Flute, 10)
(27, 77) 
0 2 4 6 8 10 12
x 10
4
-0.02
0
0.02
samples
m
ag
ni
tu
de
 
93 
(Flute, 12)
(80, 79) 
0 2 4 6 8 10 12
x 10
4
-0.1
0
0.1
samples
m
ag
ni
tu
de
 
113 
(Flute, 13)
(118, 79) 
0 2 4 6 8 10 12
x 10
4
-0.2
0
0.2
samples
m
ag
ni
tu
de
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 18
表 14. 多物件於彩色地板之 MIDI 轉換成果 
case Original Image Hot Zone 
Obstacle (MI, PI , Vol, Pitch) Wave Form 
(a) (Piano, 13, 46, 67) 
(Flute, 5, 113, 77) 
0 2 4 6 8 10 12
x 10
4
-0.2
0
0.2
samples
m
ag
ni
tu
de
(b) (Piano, 9, 9, 76) 
(Flute, 14, 19, 84) 
0 2 4 6 8 10 12
x 10
4
-0.02
0
0.02
samples
m
ag
ni
tu
de
(c) (Piano, 9, 13, 69) (Trumpet, 13, 22, 76)
(Flute, 9, 67, 79)  0 2 4 6 8 10 12
x 10
4
-0.06
0
0.06
samples
m
ag
ni
tu
de
(d) (Flute, 9, 58, 79) 
0 2 4 6 8 10 12
x 10
4
-0.06
0
0.06
samples
m
ag
ni
tu
de
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 20
表 16. 多物件於灰色地板之 MIDI 轉換成果 
case Original Image Hot Zone 
Obstacle (MI, PI , Vol, Pitch) Wave Form 
(a) (Flute, 12, 5, 79) 
(Piano, 7, 109, 62) 
0 2 4 6 8 10 12
x 10
4
-0.2
0
0.2
samples
m
ag
ni
tu
de
(b) (Bass, 11, 30, 41) 
(Flute, 3, 127, 81) 
0 2 4 6 8 10 12
x 10
4
-0.25
0
0.25
samples
m
ag
ni
tu
de
(c) (Piano, 10, 17, 60) 
0 2 4 6 8 10 12
x 10
4
-0.02
0
0.02
samples
m
ag
ni
tu
de
(d) (Piano, 12, 22, 67) 
(Flute, 12, 44 76) 
0 2 4 6 8 10 12
x 10
4
-0.02
0
0.02
samples
m
ag
ni
tu
de
 
 
 
 
 
 
 
 
 
 
 
 
 22
Experimental System for Auditory 
Image Representations”, IEEE 
Transactions on Biomedical 
Engineering, Volume: 39, Issue: 2, Feb. 
1992, pp.112 – 121. 
13. Nagarajan, R., Wong, F., and Yaacob, 
S., (2003), “Application of Stereovision 
in a Navigation Aid for Blind People”, 
2003 and the Fourth Pacific Rim 
Conference on Multimedia. 
Proceedings of the 2003 Joint 
Conference of the Fourth International 
Conference on Information, 
Communications and Signal 
Processing, Volume: 2, 15-18 Dec. 
2003, pp.734 - 737 vol.2. 
14. Nagarajan, R., Sainarayanan, G., and 
Yaacob, S., (2001), “Incorporating 
Certain Human Vision Properties in 
Vision Substitution by Stereo Acoustic 
Transform”, 2001, Sixth International, 
Symposium on Signal Processing and 
its Applications, Volume: 1, 13-16 Aug. 
2001,pp.60 - 63 vol.1. 
15. Nagarajan, R., Sainarayanan, G., and 
Yaacob, S., (2002), “Fuzzy Clustering 
in Vision Recognition Applied in 
NAVI”, Fuzzy Information Processing 
Society, 2002. Proceedings. NAFIPS. 
2002 Annual Meeting of the North 
American ,27-29 June 2002, pp.261 – 
266.  
16. Nagarajan, R., Sainarayanan, G., and 
Yaacob, S., (2003), “Role of Object 
Identification in Sonification System 
for Visually Impaired”, TENCON 2003. 
Conference on Convergent 
Technologies for Asia-Pacific 
Region, Volume: 2, 15-17 Oct. 2003, 
pp. 735 - 739 Vol.2. 
17. Smith, S., (1991), “Data Sonification: 
Issues and Challenges”, 1991. Final 
Program and Paper Summaries., 1991 
IEEE ASSP Workshop on Applications 
of Signal Processing to Audio and 
Acoustics, October 20-23, 1991 
pp.0_63 - 0_65. 
 
