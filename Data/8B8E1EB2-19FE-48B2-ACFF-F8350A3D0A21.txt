I 
 
目錄 
 
中文摘要.............................................................................................................................................................................. II 
Abstract ............................................................................................................................................................................... III 
I. INTRODUCTION ....................................................................................................................................................... 1 
II. METHOD .................................................................................................................................................................... 3 
II.A. Image preparation ................................................................................................................................................. 3 
II.B. Overview of the proposed method ..................................................................................................................... 3 
II.C. Reference model construction ............................................................................................................................ 4 
II.C.1. Architecture of the reference model............................................................................................................ 4 
II.C.2. Finger joint mechanism of the reference model ........................................................................................ 4 
II.C.3. Intensity pattern of the reference model .................................................................................................... 4 
II.D. Joint parameter initialization ................................................................................................................................ 5 
II.E. Registration-based segmentation ....................................................................................................................... 5 
II.E.1. Model-based registration .............................................................................................................................. 5 
II.E.2. Surface refinement ........................................................................................................................................ 8 
II.F. Joint parameter refinement .................................................................................................................................. 9 
II.G. Hand bone motion animation ............................................................................................................................ 10 
III. EXPERIMENTS AND DISCUSSION .............................................................................................................. 11 
III.A. Visual evaluation ................................................................................................................................................ 11 
III.B. Quantitative analysis of the segmentation results ........................................................................................ 12 
III.C. Comparative study ............................................................................................................................................. 12 
IV. CONCLUSION .................................................................................................................................................... 13 
References .......................................................................................................................................................................... 27 
計畫成果自評 .................................................................................................................................................................... 29 
國科會補助專題研究計畫成果報告自評表 .................................................................................................................... 30 
出席國際學術會議心得報告 I ........................................................................................................................................ 31 
出席國際學術會議心得報告 II ...................................................................................................................................... 33 
出席國際學術會議心得報告 III .................................................................................................................................... 35 
III 
 
Abstract 
The quantitative measurements of hand bones, including volume, surface, orientation, and position are 
essential in investigating hand kinematics. Moreover, within the measurement stage, bone segmentation is the 
most important step due to its certain influences on measuring accuracy. Since hand bones are small and 
tubular in shape, magnetic resonance MR imaging is prone to artifacts such as nonuniform intensity and fuzzy 
boundaries. Thus, greater detail is required for improving segmentation accuracy. In this project we propose 
using a novel registration-based method on an articulated hand model to segment hand bones from 
multipostural MR images. The proposed method consists of the model construction and registration-based 
segmentation stages. Given a reference postural image, the first stage requires construction of a drivable 
reference model characterized by hand bone shapes, intensity patterns, and articulated joint mechanism. By 
applying the reference model to the second stage, we initially design a model-based registration pursuant to 
intensity distribution similarity, MR bone intensity properties, and constraints of model geometry to align the 
reference model to target bone regions of the given postural image. We then refine the resulting surface to 
improve the superimposition between the registered reference model and target bone boundaries. After the 
hand bone segmentation, the hand bone motion animation can be yielded via interpolating frames between the 
segmented hand postures.  
The multipostural MR images of four subjects were included in the validation work. For each subject, given 
a reference postural image, the proposed method can automatically segment all hand bones from all other 
postural images. Compared to the ground truth from two experts, the resulting surface image had an average 
margin of error within 1 mm only. In addition, the proposed method showed good agreement on the overlap 
of bone segmentations by dice similarity coefficient and also demonstrated better segmentation results than 
conventional methods. The proposed registration-based segmentation method can successfully overcome 
drawbacks caused by inherent artifacts in MR images and obtain more accurate segmentation results 
automatically. Moreover, realistic hand motion animations can be generated based on the bone segmentation 
results. The proposed method is found helpful for understanding hand bone geometries in dynamic postures 
that can be used in simulating 3D hand motion through multipostural MR images. Other than the issue of the 
hand bone segmentation, we also adopted the concept of the registration-based segmentation to develop an 
X-ray image analysis system measuring knee parameters in the execution period of this project. 
 
Keywords: segmentation, registration, MR, hand bone, deformable model 
2 
 
each joint is with a certain degree of freedom (DoF), it has a complicated articulated structure that allows 
large movements and can generate very different postures, such as the neutral and flexion postures in Figs. 1(h) 
and 1(i). Therefore, a large movement between two sampled postures cannot be simply described by a rigid or 
affine transformation. This is the fourth difficulty (DY4) in automatic segmentation. 
In the past, deformable model-based segmentation methods
13-15
 were commonly used to extract the object 
contour from images. Two representative approaches, the 2D active contour model (ACM, snakes)
13
 and the 
active shape model (ASM),
14
 achieve segmentation by deforming a contour/surface to capture the strong 
edges of a target object. Unfortunately, strong edges do not appear consistently throughout the entire contour 
and strong image noises may exist, producing instability using traditional ACM and ASM. On the other hand, 
as the initial model in a deformable model-based segmentation is often obtainable by registration, integration 
of segmentation and registration are complementary and thus compose the registration-based segmentation as 
exemplified by Zagrodsky et al.
16
 in a proposal for a deformable model-based framework. They presented a 
registration-assisted method to segment the cardiac surface from 4D echocardiographic data and then 
visualize it at different phases of the cardiac cycle. Based on the mutual information–based registration, they 
resolved the low spatial correlation problems of adjacent image frames caused by heartbeats. Such a 
registration-based segmentation concept was also utilized in atlas-based segmentation methods,
17, 18
 which 
were designed based on the elastic (non-rigid) registration of the atlas image to the given image. Nevertheless, 
these segmentation methods based on direct image registration are unsuitable for resolving the 
aforementioned difficulties when handling hand MR images. 
Recently, some studies related to the bone segmentation for joint motion analysis were presented. Ryu et 
al.
8
 utilized a semi-automatic approach to segment hand bones from MR volumetric images of sequentially 
moving postures. In their method, the thresholds of intensity for distinguishing the bones from their adjacent 
soft tissues were manually adjusted repeatedly for different bone segments or different image slices while 
simultaneously removing non-relevant objects in a laborious process due to the lack of ideal solutions to 
DY1-DY3. Since the movement of a bone segment between two different postures can be described by using 
a rigid transformation, a registration-based segmentation scheme is supposed to be ideal for hand moving 
postural images. Kamojima et al.
19
 utilized a registration-based method to segment hand bones from images 
of sequentially moving postures based on many pre-segmented bone segment models. Liu et al.
20
 presented a 
rigid model-based segmentation method for the bones of joints, using an image sequence of joints under 
different loads. Both strategies intended to fit a segmented bone model into the best matched bone region of 
the target images by using rigid image registration. Unfortunately, the fitness measures in their registration 
strategies were not designed for accommodating image artifacts (e.g., DY1-DY2), so their methods might fail 
to handle the artifact regions of hand MR images. In addition, the articulated model was not utilized, thus the 
initial posture of each bone model had to be adjusted manually in a tedious and time-consuming endeavor. Up 
to present, an automatic registration-based segmentation method for whole hand bones is not yet available. 
Later, Martín-Fernández et al.
21
 proposed using an articulated model in the registration of hand 
radiographies while du Bois d’Aische et al.22 presented a similar registration method for neck MR images. 
The articulated model utilized a hierarchical relationship wherein the geometric transformations of bones can 
propagate from high to low layers. With far less movement in the processed images, their models did not 
provide the joint mechanism that constrains the motion of bone segments. Hence, the transformation 
correlating the hand moving postural images is still unavailable. (i.e., DY4 has not yet been overcome).  
In this paper, we propose a new registration-based method consisting of model-based registration and 
4 
 
II.C. Reference model construction 
II.C.1. Architecture of the reference model 
The reference model used to control the articulated motion of the finger bone segments plays a pivotal role 
in the proposed registration-based segmentation. The model consists of twenty pieces of bone components, 
including the capitate bone of the wrist, five metacarpals, five proximal phalanges, four medial phalanges and 
five distal phalanges. These bone components are semi-automatically extracted from the neutral postural 
image using the livewire approach.
20 
The bone surfaces of the reference model are triangulated using the 
marching cube algorithm
23
 and then smoothed to remove local fluctuations, as shown in Fig. 4(a). 
The human hand is an articulated object so it can be modeled as a hierarchical chain composed of several 
linked bone segments as shown in Fig. 4(b). In this figure gray nodes represent the bone segments and their 
anatomical names are noted on the right. Fingers 0 to 4 represent the thumb, index, middle, ring and little 
fingers, respectively. To provide the characteristics of hand motion, a hierarchy is established with layers 
descending from the capitate bone to the distal phalanges. The capitate bone is the highest layer that 
determines global hand motion while the lower layers represent movements of finger bone segments. The 
geometric transformations of bone segments propagate from the high to low layers in the hierarchy. The 
hierarchical relationship of hand bones is consequently characterized in the reference model. 
II.C.2. Finger joint mechanism of the reference model 
Generally, finger motion depends on the integrated movement of the finger bone segments constrained by 
the finger joint mechanism. Each finger joint has a certain DoF that constrains the rotation of a finger bone 
segment with respect to its proximally adjacent bone. In fingers 1 to 4, the metacarpophalangeal (MCP) joint 
(see Fig. 4(b)) is characterized with two DoFs corresponding to the flexion/extension and adduction/abduction 
motions. The proximal interphalangeal (PIP) joint, and distal interphalangeal (DIP) joint are simple hinge 
joints with only one DoF corresponding to the flexion/extension motion. On the other hand, the thumb (finger 
0), which contains the proximal interphalangeal (PIP), metacarpophalangeal (MCP) and trapeziometacarpal 
(TMC) joints, is very different from the other fingers anatomically.
24, 25
 The first is a hinge joint with one DoF, 
and the two others are modeled with 2-DoF joints, respectively.
26
 Consequently, twenty-one DoFs are 
assigned to the joints of the reference model totally.  
II.C.3. Intensity pattern of the reference model 
In addition to the finger joint mechanism, the proposed reference model is also characterized by intensity 
information of the MR image. Among the multi-postural MR images, the intensity distribution of both the 
bone and its vicinity in a postural image is related to one of the corresponding regions in the other postural 
images. In order to provide the model with MR intensity information, for each reference bone segment, we 
build an intensity pattern of the bone and its vicinity from the neutral postural image. The first step requires 
constructing an oriented bounding box with faces that are parallel to the coordinate planes of the reference 
bone segment. The intensity pattern is defined as the intensity sequence of the bone bounding box, denoted as 
a one-dimensional vector Ar,j = (I1(BBr,j(1)), I1(BBr,j(2)), …, I1(BBr,j(N1–1)), I1(BBr,j(N1)) ), where BBr,j 
represents the 3D coordinates of voxels inside the bone bounding box, N1 is the number of voxels, and I1 is 
the neutral postural image. The reference model thus contains the intensity information through reference to a 
6 
 
the reference bone segments in the proper positions in Ik, thereby facilitating the subsequent registration. 
Usually, capitate bone positions in different postural MR images are not fixed. The capitate bone of the 
reference model is manually placed in an initial position and then registered using the intensity pattern 
matching and intensity optimization steps. Since the metacarpal movements relative to the capitate bone are 
very limited in fingers 1 to 4, their initial positions can be determined by propagating the geometric 
transformation of the capitate bone to these metacarpals. Furthermore, the hand bone segment is supposed to 
be located inside the hand region regardless of the postures, so we can determine the initial position of each 
finger bone segment based on this property.  
Articulated object surface, silhouette or region information is frequently used to help estimate an object 
posture.
28, 29
 In the proposed method, an anisotropic smoothing filter is first used to remove image noises, 
followed by thresholding, morphological dilation, and then hole-filling of the filtered image. The hand region 
can be extracted and then represented by using a binary image Hk. In the processing window, Hk(x) is assigned 
with 1 in the hand region and is 0 otherwise, where x is the coordinate of a voxel. Then, the initial position of 
the bone segment can be determined by maximizing the overlapped region of the reference bone segment and 
low intensity voxels of Ik inside the processing window: 
2
,
, , , , ,
1
argmax ( ( ))(255 ( ( )))
r j
N
r j k r j r j k r j r j
i
H i I i

 
  
Θ
Θ M B M B ,
 
(1) 
where Θr, j represents the rotation angle set of the corresponding joint motion, and each element of the set is a 
rotation angle corresponding to a DoF of the joint motion. Br,j represents the 3D coordinates of voxels inside 
the reference bone segment and N2 denotes the number of voxels. Since hand anatomy restricts finger motion, 
the rotation angle of a finger bone segment is supposed to be in a certain interval
30 
and the finger cannot 
overly hyperextend. Thus, the maximization process of Eq. (1) is subject to these constraints, so that the 
estimated rotation angle set ,r jΘ  can satisfy the motion configuration of a normal hand. By using the joint 
mechanism with the estimated rotation angle set, the reference bone segment can be driven to the initial 
position as the first registration step. 
II.E.1.2. Intensity pattern matching  
After determining the initial position of the reference bone segment, we present an intensity pattern 
matching algorithm to register the reference bone segment to the corresponding region in the given postural 
image Ik. We solve registration parameters denoted as Tr,j by maximizing a fitness function that represents the 
similarity of intensity patterns between the model and the given image. The registration parameters include a 
translation vector t and a rotation matrix R with respect to the coordinate of reference bone segment. The 
fitness function is defined as 
'
, ,
,
corr( , )
( )
r j r j
intensity_pattern r j
geometry
f
C

A A
T , (2) 
where Ar,j is the intensity pattern inside the bone bounding box of the reference bone segment described in 
section II.C.3, and 
'
,r jA = (Ik(Tr,j(BBr,j(1))), Ik(Tr,j(BBr,j(2))), …, Ik(Tr,j(BBr,j(N1–1))), Ik(Tr,j (BBr,j(N1)))) 
represents the intensity sequence of Ik inside the bone bounding box after Tr,j transformation. By maximizing 
8 
 
1II.E.1.3. Intensity optimization  
After the intensity pattern matching, the reference bone segment can be closely allocated to the 
corresponding bone region in the given image Ik. Nevertheless, due to soft tissue deformation or differences in 
imaging conditions, intensity pattern matching may not necessarily achieve perfect alignment. Therefore, we 
present an intensity optimization step that minimizes the sum of bone intensity in the T2-weighted 
fat-suppressed images, in which the bone regions are supposed to be dark. If the reference bone segment is 
exactly registered to the corresponding bone region of Ik, the sum of intensity inside the bone segment should 
be minimized. The intensity optimization step is achieved by maximizing 
, ,
1
,
(255 ( ( ( ))))
( )
2N
k r j r j
i
intensity r j
geometry
I i
f
C



 T B
T .
 
(7) 
The maximization of fintensity can find a rigid transformation that maps the reference bone segment to the 
region with the minimal sum of intensity inside Ik. Consequently, we can register the reference bone segment 
to the corresponding bone region in Ik more precisely. 
II.E.2. Surface refinement 
Due to inconsistent imaging and physiological conditions, the registered image usually varies with respect 
to the acquired images of different postures. In addition, the surface-smoothing step in the model construction 
stage may also cause deviations between the bone boundaries of the reference model and the given postural 
MR images. Since the previous rigid registration step only adjusts the model posture, it cannot resolve these 
bone boundary deviations. Thus we propose a snake-based approach to refine the surfaces of bone segments. 
The surface of each bone segment of the registered reference model is refined via minimizing energy Erefine: 
3
0
( ) ( ) (1 )( ( ) ( ))
N
refine i shape i edge i region i
i
E E E E 

    v v v v ,
 
(8) 
where Eshape represents the shape energy, Eedge is the edge energy, Eregion is the region energy, α is a weighting 
value, iv  represents the coordinate of the i-th vertex and N3 is the number of vertices on the deformable 
model. The shape energy that restricts the movement of vertex on the deformable model is defined as 
( )
( ) 1
j i j i
shape i
j Nei i j i j i
E

   
   
       

v v v v
v
v v v v
, (9) 
where vi is the coordinate of the i-th vertex on the original model before deformation, and Nei(i) represents its 
neighboring vertices. By referring to the local shape features of the original model, Eshape closely maintains 
the shape of the deformable model to the original in the deformation process, to help avoid excessive 
distortions. 
The edge and region energies that measure the boundary fitness between the deformable model and the 
underlying image are designed as follows: 
( ) ( ) ( ( ))edge i k i k i iE I I  v v v n v ,
 
(10) 
10 
 
rotation matrix R =      11 21 31 12 22 32 13 23 33      
T T T
r r r r r r r r r 
   and a translation vector t =   
T
x y zt t t   . From the 
geometric transformation of this movement, we can estimate the JPs of the given subject. 
Constrained by the joint DoF, rotational motion can approximate the movement of the finger bone segment. 
In Fig. 6, bone segment b rotates around axis u located at point J, with rotation angle θ. The bone segment, 
after the rotation, is represented by 
'b . O and 
'
O  represents the CoM of b and 
'b , respectively. Given the 
rotation matrix R, rotation axis u and rotation angle θ are retrieved based on Euler’s rotation theorem31: 
32 23
13 31
21 12
1
2sin
r r
r r
r r


 

 
 
 
 
u  , 
11 22 33 1cos( )
2
r r r
arc
  
 . 
(12) 
In Fig. 6, triangle 
'
JOO  is isosceles, based on the assumption that the movement between b and 
'b  is a 
single planar rotational motion. Therefore, the rotation center J can be calculated by 
2
2
tan( )
2

 
 
   
  
 
t
' u tO+O
J
u t
, 
t = O' - O . 
(13) 
Using Eq. (12) and Eq. (13), we can estimate the JPs which are the rotation axes and rotation center for the 
movement of a finger bone segment.  
The DIP and PIP joint motions with one DoF which corresponds to the flexion/extension are constrained 
with one rotation axis by using Eq. (12) and Eq. (13). On the other hand, the MCP and TMC joints with two 
DoFs are constrained by two rotation axes. Thus, the bone posture can be obtained by adjusting the rotation 
angles, such that the simulated joint mechanism in the 2-DoF joints is less influenced by the deviations of 
bone coordinates. Adopting the definitions of rotation axes recommended by the ISB can well approximate 
the hand postures of a given subject, so we need only estimate the rotation center and adopt the ISB-defined 
rotation axes for the 2-DoF joints. As the JPs are directly estimated based on the image data, the resulting JPs 
are less sensitive to bone coordinate deviations and can better match the joint motion behaviors of the given 
subject. For each subject, the JPs are automatically determined based on two postural images at the beginning 
of the registration step. Since the joint model of each subject physically varies very little during finger motion, 
the JPs can be used to match all other images for the same subject once they are determined. In other words, 
the subject-specific reference model can be used in registering different postural images or even images from 
different acquisition of the same subject.  
II.G. Hand bone motion animation 
To provide the clinicians with the dynamic information of hand bone geometries, we generate the hand 
bone motion animations by interpolating frames between sequentially moving postures segmented from the 
12 
 
motion animations are available on our web page.
32
 
III.B. Quantitative analysis of the segmentation results 
In the quantitative analysis, the segmentation results by the proposed automatic method were compared 
against the average of manual results of two experts, which constituted the ground truth for validating the 
accuracy of the proposed method. Since manual segmentation of the whole data set (ten postural image 
volumes in this experiment) was tedious and impracticable, we chose the four bone segments (i.e., the distal, 
medial, and proximal phalanges and metacarpal) of the middle finger from each postural image volume for 
validation. For each of the four bone segments, the comparison was achieved based on three metrics, 
including the mean error (ME), the root mean square error (RMSE), and the dice similarity coefficient
33
 
(DSC): 
2
1
ME  ( )
N
i j
i
N

  a b , (15) 
2
1
RMSE  ( )
N
i j
i
N

  a b
, 
(16) 
2
DSC  



A G
A G
, 
(17) 
where ai is the i-th surface point of the automatic result, and bj is the j-th surface point of the ground truth that 
is the closest to ai, and N is the number of surface points of the automatic result. A and G are the sets of 
voxels classified as the bone segments in the automatic result and the ground truth, respectively. The ME and 
RMSE represent the surface distance deviations between the automatic result and the ground truth. The DSC 
is a measure of the spatial dependency between two segmented bone volumes, and its value ranges from zero, 
indicating no overlap, to one indicating complete overlap.  
Table I states the evaluation results, and each row of the table lists the average ME, RMSE and DSC of the 
four bone segments in the middle finger, respectively. As shown in Table I, the average MEs and RMSEs were 
less than 1 mm and the average DSCs were far above 0.8, indicating a good overlap between the automatic 
results and the ground truth.
33
 Beyond the assessment of segmentation results of the middle finger, we further 
validated the proposed method with two sets of orthogonal cross-sections to evaluate the results of different 
bone segments. The validation images included three coronal and three sagittal view images from each of the 
four postural images of subject 1, and the ground truth was given by the average of manual results by the 
same two experts. Table II and Table III state the resulting distance errors of bone contours and the overlap 
ratios of bone regions in the coronal and sagittal cross-sectional images, respectively. As shown in Table II 
and Table III, the average MEs were 0.574 0.079 mm and 0.617 0.077 mm; the average RMSEs were 
0.816 0.092 mm
 
and 0.862 0.079 mm; and the average DSCs were 0.887 0.02 and 0.875 0.02 in 
coronal and sagittal views, respectively. The resulting MEs and RMSEs were less than 1 mm, and moreover, 
all the DSC values were larger than 0.8.
 
Overall, the evaluation results are satisfactory for clinical or 
biomechanics requirements.  
III.C. Comparative study 
Image segmentation methods have been developed and are widely used in medical image analysis. 
14 
 
TABLE I. 
Means and standard deviations of accuracy measures (ME, RMSE and DSC) estimated from the proximal, 
medial, distal phalanges and metacarpal of the middle finger in the multi-postural images of four subjects. 
Subject Posture Average ME 
(mm) 
Average RMSE 
(mm) 
Average DSC 
(%) 
1 2 0.668 0.012 0.689 0.011 84.752 7.321 
 3 0.634 0.027 0.707 0.051 83.724 6.938 
 4 0.601 0.027 0.652 0.038 86.143 3.656 
 5 0.666 0.046 0.712 0.028 84.491 6.249 
2 3 0.613 0.029 0.656 0.036 84.799 7.071 
 5 0.614 0.018 0.651 0.024 85.317 4.426 
3 4 0.726 0.044 0.777 0.052 82.815 6.276 
 5 0.683 0.077 0.731 0.063 82.760 5.865 
4 4 0.560 0.064 0.629 0.066 85.068 4.416 
 5 0.500 0.044 0.588 0.063 84.348 6.330 
 
16 
 
TABLE III.  
Accuracy evaluation results in ME, RMSE and DSC estimated from the sagittal images of subject 1. 
Image no. ME (mm) RMSE (mm) DSC (%) 
posture 2    
2.1.s 0.524  0.798  90.234  
2.2.s 0.592  0.833  88.674  
2.3.s 0.601  0.886  89.031  
posture 3    
3.1.s 0.676  0.918  86.911  
3.2.s 0.742  0.997  84.906  
3.3.s 0.621  0.891  85.974  
posture 4    
4.1.s 0.712  0.892  84.591  
4.2.s 0.573  0.800  88.242  
4.3.s 0.524  0.751  88.899  
posture 5    
5.1.s 0.713  0.968  85.977  
5.2.s 0.531  0.752  90.908  
5.3.s 0.591  0.833  86.487  
Mean SD 0.617 0.077  0.862 0.079  87.569 2.055  
 
18 
 
 
 
20 
 
 
22 
 
 
24 
 
 
 
FIG. 8. Hand bone motion animation generated based on the segmented hand 
postures. The source posture (most left) moves toward the target posture (most 
right). 
 
 
 
 
 
26 
 
 
28 
 
estimation for atlas-based segmentation of pathological MR brain images,‖ Comput. Methods Programs 
Biomed. 84 (2), 66–75 (2006). 
19 S. Kamojima, N. Miyata, and J. Ota, ―Identification of position and orientation of hand bones from MR 
images by bone model registration,‖ IEEE/RSJ Int. Conf. Intell. Robots and Syst. (IROS), pp. 2021–2027 
(2004). 
20 J. Liu, J. K. Udupa, and P. K. Saha, ―Rigid model-based 3D segmentation of the bones of joints in MR 
and CT images for motion analysis,‖ Med. Phys. 35 (8), 3637–3649 (2008). 
21 M. Á . Martín-Fernández, E. Muñoz-Moreno, M. Martín-Fernández, and C. Alberola-López, ―Articulated 
registration-elastic registration based on a wire-model,‖ Proc. SPIE 5747, 182–191 (2005). 
22 A. du Bois d'Aische, M. De Craene, B. Macq, and S. K. Warfield, ―An improved articulated registration 
method for neck images,‖ 27th Annu. Int. Conf. IEEE EMBS, pp. 7668–7671 (2005). 
23 W. E. Lorensen, and H. E. Cline, ―Marching cubes: A high resolution 3-D surface construction 
algorithm,‖ Comput. Graph. (ACM) 21 (4), 163–169 (1987). 
24 W. P. Cooney, M. J. Lucca, E. Y. S. Chao, and R. L. Linscheid, ―The kinesiology of the thumb TMC 
joint,‖ J. Bone Joint Surg. Am. 63, 1371–1381 (1981). 
25 P. Cerveri, E. De Momi, N. Lopomo, G. Baud-Bovy, R. M. L. Barros, and G. Ferrigno, ―Finger kinematic 
modeling and real-time hand motion estimation,‖ Ann. Biomed. Eng. 35 (11), 1989–2002 (2007). 
26 S. Cobos, M. Ferre, and M. A. Sanchéz-Urán, ―Simplified hand configuration for object manipulation,‖ 
Lect. Notes Comput. Sci. 5024, 730–735 (2008). 
27 G. Wu, F. C. T. van der Helm, H. E. J. Veeger, M. Makhsous, P. Van Roy, C. Anglin, J. Nagels, A. R. 
Karduna, K. McQuade, X. Wang, F. W. Werner, and B. Buchholz, ―ISB recommendation on definitions of 
joint coordinate systems of various joints for the reporting of human joint motion—Part II: shoulder, elbow, 
wrist and hand,‖ J. Biomech. 38, 981–992 (2005). 
28 N. Shimada, K. Kimura, and Y. Shirai, ―Real-time 3-D hand posture estimation based on 2-D appearance 
retrieval using monocular camera,‖ Proc. IEEE/ICCV Workshop on Recognition, Analysis, and Tracking of 
Faces and Gestures in Real-time Systems, Washington, DC, USA (2001). 
29 J. Cui, and Z. Sun, ―Model-based visual hand posture tracking for guiding a dexterous robotic hand,‖ Opt. 
Commun. 235, 311–318 (2004). 
30 J. Lin, Y. Wu, and T. S. Huang, ―Modeling the constraints of human hand motion,‖ Proc. IEEE Workshop 
on Human Motion (HUMO), Los Alamitos, CA, USA, pp. 121–126 (2000). 
31 F. S. Hill, and S. M. Kelley, Computer Graphics Using OpenGL, 3rd ed. (Prentice Hall, NJ, 2007). 
32 http://image.csie.ncku.edu.tw/research/RBShand.htm  
33 K. H. Zou, S. K. Warfield, A. Bharatha, C. M. Tempany, M. R. Kaus, S. J. Haker, W. M. Wells III, F. A. 
Jolesz, and R. Kikinis, ―Statistical validation image segmentation quality based on a spatial overlap index,‖ 
Acad. Radiol. 11, 178–189 (2004). 
L. Vincent, and P. Soille, ―Watersheds in digital spaces: an efficient algorithm based on immersion 
simulations,‖ IEEE Trans. Pattern Anal. Mach. Intell. 13 (6), 583–598 (1991). 
30 
 
國科會補助專題研究計畫成果報告自評表 
請就研究內容與原計畫相符程度、達成預期目標情況、研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）、是否適
合在學術期刊發表或申請專利、主要發現或其他有關價值等，作一綜合評估。 
1. 請就研究內容與原計畫相符程度、達成預期目標情況作一綜合評估 
  達成目標 
□ 未達成目標（請說明，以 100 字為限） 
□ 實驗失敗 
□ 因故實驗中斷 
□ 其他原因 
說明： 
 
 
 
2. 研究成果在學術期刊發表或申請專利等情形： 
論文：已發表 □未發表之文稿 □撰寫中 □無 
專利：□已獲得 □申請中 □無 
技轉：□已技轉 □洽談中 □無 
其他：（以 100 字為限） 
 
 
 
3. 請依學術成就、技術創新、社會影響等方面，評估研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）（以
500 字為限） 
 
我們在本研究計畫中提出了一個新穎的對位為基礎的手骨分割技術。在影像處理的技術
面，我們的系統針對多姿勢核磁共振影像中假影造成的影響、手骨姿勢的變異等問題進行
解決，達成自動化並準確分割手骨的目標，因此具有相當的創新性與實用性。以手骨分割
的結果為基礎，我們能順利的產生逼真且平滑的手骨運動動畫。研究成果所發表的期刊
Medical Physics 屬於生醫工程相關領域重要之雜誌。而其後續應用層面包含了手骨運動
學、板機指虛擬手術訓練系統開發等手部肌肉骨骼相關的研究領域。目前，我們也以核磁
共振影像手骨分割的技術為基礎，著手進行板機指虛擬手術的研究，期望未來能提供臨床
手部疾病診療有效的電腦影像輔助工具。除了手部骨塊分割與運動動畫的研究，我們將相
似的分割技術概念應用至膝關節 X-ray 影像分析上，也得到了相當豐碩的成果。相關研究
成果發表於 Physics in Medicine and Biology。整體而言，在這個研究計畫中，我們發展出
一套對位為基礎的分割策略，它能被應用在不同醫學影像中去得到可靠的分割結果，在未
來的研究中具有相當的潛力。 
 
32 
 
並且利用投影的方式來比較我的三維模擬運動與二維真實運動的相關性。另一個問題是問如何利
用我的樣板去目標影像中比對出最契合的位置。我回答是本實驗中，利用參考模型與目標影像在
骨頭紋理灰階值分布的相關係數高低，來決定契合度，藉此找出最佳位置。 
 
二、與會心得 
這是我第一次在國際會議報告的經驗，很新鮮有趣，重要的是收穫很多。在開始準備報告的
投影片與講稿時，如何在有限的時間內，簡單明瞭地強調出自己的特色還有貢獻，是花最久時間
去揣摩的。另外，在會議會場，也有聽了其他人的報告，大家的共同點就是以‖充滿自信‖的態度來‖
分享‖所做的研究成果。我想這就是做為一個研究生該具備的態度：對自己的研究充滿熱忱。另外，
能夠參觀國外的實驗室也是很寶貴的經驗，除了觀摩國外研究生的研究成果之外，也能體會一下
在國外實驗室研究的學生，跟國內的學生到底差異在哪邊；我有跟他們分享我所做的研究，在過
程中，國外的研究生或者學者有問題就會大膽提問，有新點子或者建議，也會大方的提出來分享，
甚至是讚美也都是毫不吝嗇地提出，給予鼓勵。一個很需要學習的地方就是國外優秀的研究生，
總是在腦中充滿問號(?)與驚嘆號(!)，這對於做研究或者在面對未來工作的挑戰上會有很大的幫
助，時時刻刻找出疑問與解決方法，這也會是我需要把握與持之以恆的原則。 
  很多本身的能力需要精進之處，在出國期間讓我感受更加深刻。去到國外感受最深刻的莫過
於英文能力的不足；平常在國內，雖然常在閱讀國外雜誌，閱讀能力與文章撰寫上，並不會有太
強烈的能力不足的感受。但是到了國外，溝通靠的不是眼看與手寫，主要是依靠耳聽與口說！在
報告這一部分，我們台灣學生需要先寫稿演練多次，才能在講台上流暢的報告，這是輸給國外學
生最大的地方。國外的學生們，由於英文能力很好，能夠精準與迅速的把自己的成果描述出來，
在許多類似有學者來參觀的場合，能夠給予對方完整且明瞭的簡報，達到研究成果展示的目標。
在回答問題上，台下英文問題一出現，雖然我能夠聽懂問題，腦中也能知道想回答的答案，但是
用英文回答的時候，總是覺得還是沒有中文回答來的精確與完整。這一部分將會是我未來努力的
重點，除了多聽多看英文電影與廣播來練習聽力與發音之外，也會盡量在實驗室討論的時候利用
英文報告，將英文能力好好提升。 
 
三、考察參觀活動 
除了發表論文之外，我們也有去參觀了匹茲堡大學內的兩個實驗室，一個在腦部研究上表現
得相當優秀；另一個則是較偏向醫學工程研究中心屬性，蛋白質的基因治療、藥劑刺激組織的收
縮舒張等皆在他們的研究範圍內。參觀這些國外卓越的實驗室，在擴展視野上，有相當大的幫助。 
 
四、攜回資料名稱及內容 
會議論文摘要集一本。 
34 
 
想法很不錯，因為這樣的構想，不但利用影像處理的技術，還結合了解剖構造上的特性。而有一
位觀眾對於我的研究問了很多問題，主要是想多了解一些動態形狀模型的概念，因為他說他目前
的研究只用到灰階資訊，並未用到物體形狀的資訊，因此，他對統計性模型在掌握形狀變異的能
力很有興趣，因此跟我討論了一段時間。整體來說，在一個多小時的海報時間當中，跟不少國外
研究人員有愉快的討論並交流。 
 
二、與會心得 
首先，很高興能夠參加這個盛大會議，讓我有相當多的收穫。在會議過程中，我發現英文的
聽與說仍然是一個需要進步的地方。在聽取國外學者們報告的時候，他們大多能利用流利順暢的
英文，”精準地”提問以及回答。這是我要繼續學習的地方，未來我也將會多利用線上廣播來練
習英文的聽與說，以利於未來在國外的論文發表能夠表現得更好。而會議的過程中，發表演說或
與人討論交流時的一個重要的態度就是要有自信。有些人報告的東西的確不錯，但是在回答問題
的時候有點慌張或者猶豫，多少會把自己的研究成果光芒壓抑掉。相對地，有些人的研究沒特別
突出，但在提問及報告過程中，話語相當果斷且能侃侃而談，與台下觀眾們順暢地交換看法，反
而達到很好的交流效果。這樣的態度我想將是一個值得學習且必頇具備的態度。 
    實際上，不必擔心自己說錯話，只要平常有認真的學習，並把想法坦然與大家分享，在學術
交流上，反而容易激貣火花與新的創意。除此之外，國外學校的校園規劃也讓我有所心得與想法。
平時常聽老師們說，國外的學生不但在寫論文以及報告論文都很注重包裝，這次我參觀明尼蘇達
大學的感想是它們的學校建設也包裝的不錯，尤其是在校園的美化綠化部分，整個校園很多綠色
草皮以及綠樹，硬體部分包裝的很不錯，提升了整個學校的外觀分數，校園美化及規劃工程是在
形塑呈現一間學府的格局，校園在外觀硬體之建構是各國人士認是學校的第一媒介，雖然內在美
更為重要，但是外在的包裝也是一個值得我們學習的地方。不管是在論文發表或者工程產品開發
上應該都是一個重要的課題，值得我們重視與關注。 
 
三、考察參觀活動 
除了開會的地點之外，我還抽空到了明尼蘇達大學去參觀一番，目的就是希望能看看他們校
園的硬體以及軟體上目前的發展情況，剛好遇到他們的新生入學時間，很多新生們在學長姐帶領
下，也正在參觀學校的各項建設以及系館，這樣的一個參訪行程，對我而言，的確有達到增廣見
聞的目標。 
36 
 
11. Technology Commercialization, Industry, Education, and Society 
12. Recent Advancements in Biomedical Engineering 
 
共十二大主題。而參與本次會議的學者來自世界各地，共有近六千篇論文投稿，最後有超過兩千
篇論文，在會場以口頭報告或壁報展示兩種方式，發表各單位最新之研究成果。另外，主辦單位
也安排了許多演講會議，邀請專家學者給予精闢的演說。其中，一些主題演講 (keynote speech) 的
題目探討較新的議題，如―Toward CognitiveNeuro-Prosthesis‖，―Useful Signals from Motor Cortex‖ 利
用動物腦皮層的訊號來控制機器移動、―MR Imaging of Brain Function: Challenges, Opportunities and 
Questions‖、―Biomedical Imaging and Optical Biopsy Using Optical Coherence Tomography‖ OCT 影像
的成像技巧與新的運用、―Magnetic resonance elastography (MRE) ‖、―MolecularImaging with PET 
(Positron Emission Tomography) ‖之最新應用、…等；同時，相關業界廠商也在會場擺設攤位，推
出最新之相關科技產品，無論是硬體或軟體，工業應用或醫療用途都有。在整個會議中，不管是
口頭報告或者是壁報展示，藉由各國學者以及不同領域的研究人員之間的互相討論，使得我們可
以吸收別人之想法，也同時給自己一些正面刺激。 
 
二、與會心得 
此次研討會於 9 月 2 日開始一連舉行五天，包含口頭報告與壁報展示共分為將近兩百個議程
同時舉行。此次我們所發表兩篇文章，一篇為口頭報告，另一篇為壁報展示論文。這兩篇論文分
別為―Registration-Based Segmentation of Nerve Cells in Microscopy Images”，發表時間被安排於 6
日上午， ―Automated Segmentation for Patella from Lateral Knee X-ray Images”, 其壁報張貼時間被
安排於 4 日下午。前者屬於「Cellular and Molecular Image Processing」主題，後者屬「Biomedical 
Imaging and Image Processing」的議題。在第一場口頭論文發表中，我們報告使用以對位為基礎之
技術應用於顯微鏡影像之神經細胞分割。論文為本實驗室與神經內科林宙晴醫師及機械系朱銘祥
教授合作之成果。爲了訓練學生國際會議論文發表能力，論文由王怡穎同學做口頭報告，內容圖
文並茂。王同學之英文報告相當不錯，解答提問經驗稍微不足，但多次參加國際會議後，已漸漸
可以應付與解答問題。學者在報告完後所提問，也讓我們對未來研究的方向，有所啟發，感覺獲
益良多。此一個場次的其他報告者，也報告了與我們的研究領域相關的研究主題，一方面可以提
昇我們對新技術與趨勢的了解，另一方面也有機會與他們交換學習的心得。而另ㄧ方面，壁報論
文之主題為，由側面膝蓋 X 光影像之髕骨自動分割技術。由於 X-ray 的吸收量不一致，即使在同
一個組織中，影像灰階仍會呈現不均勻分布而且會有很多的雜訊。我們針對 X-ray 影像上的髕骨分
割，提出一個新的動態形狀模型為基礎的分割方法。對髕骨的統計性模型，設計一套基於邊緣追
蹤方法的策略去把模型自動化的擺到髕骨附近。接著利用一個雙最佳化的方法，將形狀模型形變
至符合影像上髕骨的邊緣位置。我們所提出的方法能處理不同的 X-ray 影像，而且能自動化地分割
髕骨。由於張貼發表均有一個多小時的討論時間，會場中的討論可說相當熱烈。在海報展覽期間，
有來自國外的學者或研究生對我們的研究成果提問，亦獲得許多學者從不同角度思考的意見，對
於後續的研究將有極大的助益。除發表自己研究室之研究成果外，同時參加研討會的多次主題演
講(Keynote speech)，不同場次的研究論文發表會(Session)，以及瀏覽他人之壁報研究成果發表，期
望給自己一些新的思考方向，作為日後研究之參考。在會議中，一些研究群從不同的角度切入和
我們類似的研究問題，並提出各自的解決方法。本次會議的另一特色為腦神經科學相關研究之發
表深受重視，除有許多時段(Session)以此類相關議題為主題外，壁報論文眾多，也有多次相關
Keynote speech，參展廠商也努力推廣相關儀器。當然我們最有興趣的是神經訊號與功能性腦影像
國科會補助出席國際會議報告 
 
   99 年   9 月  27  日 
報告人姓名  黃仲誼 就讀學校系所
及年級 
國立成功大學資訊工程
研究所 博士班六年級 
會議期間及地點  2010.8.27~8.28 
日本京都大學 
本會核定 
補助文號 
NSC97-2221-E-006-
158-MY2 
會議名稱 (中文) 第三屆生物工程國際會議 
(英文) The 3nd Biomedical Engineering International 
Conference 
發表論文題目 (中文) 利用標準腦影像多步驟對位進行功能評估 
( 英 文 ) FUNCTIONAL EVALUATION BY USING MULTI-STEP 
REGISTRATION WITH STANDARD MR BRAIN IMAGE  
 
參加 BMEiCon 第三屆生物工程國際研討會報告 
報告人：國立成功大學 資訊工程學研究所 黃仲誼 
 
一、 參加會議經過 
Biomedical Engineering International Conference (BMEiCon) 生物工程國際會議，是
國際上的生物工程年度會議，每年都吸引了不少國際知名的專家學者前來共襄盛舉。此次
會議舉行其間為8 月 27 日至 8月 28 日，2010年的會議地點在日本京都的京都大學。承
蒙指導教授孫永年老師的支持與國科會的補助，讓學生有機會能參加此一年一度的盛會。
本次研討會邀請生物與醫學工程領域中的專家學者，交流各領域的研究資訊；此次會議內
容包羅萬象，主要探討的議題如下： 
 
Bioinformatics, Medical Informatics  
篇文章的發表。我所報告的場次為影像(Image)的場次，報告的地點是三個演講廳中最大的
第 一 演 講 廳 。 主 辦 單 位 在 8/27 日早上 10:00~10:30 進行了與會人員的註冊
(Registration)，我所報告的場次為 8/27 日下午 1:30 分在第一演講廳的場次。在這個場
次中，其他報告者所呈現的主題與我的領域具有一定的相關性，讓我一方面可以了解最新
的技術，另一方面也有機會與他們交換學習的心得。輪到我上台報告時，透過之前指導老
師孫永年教授之前對報告投影片的修正與建議，讓我的報告流暢許多。同時，在報告完之
後，兩位學者的提問，包含論文所提方法的計算時間以及 HAMMER 對位方法是否為彈性對位
等問題，也對於我未來研究的方向有另一個層面的思考邏輯，感覺獲益良多，除了能進一
步了解目前研究的發展方向，更期許能激發自己新的思維與靈感。 
除了本場次的參與外，我另外參與了與自己研究領域相關的研究會議議程，如：醫療
影像處理，影像，生物工程介紹…等。其中包含了由大會邀請來的演講者 Dr. Kohji 
MASUDA ，Dr.Tetsuya Matsuda 以及 Dr. Somkiat Wattanasirichaigoon 所帶領的研究團
隊所投稿的文章。會議的進行採取三個場次同時進行的方式，在同時間有三個文章的報
告。且於研討會互相討論交流中獲得許多第一手的相關知識。國際間針對各種專業領域不
乏有多位知名學者。在交流的過程中，可從提問與答辯間，得到許多從未思考過的知識；
也可在私下討論時，了解每位學者間所關注的焦點，能使我們對整體研究趨勢有所了解，
助我們掌握新的研究方向。 
整體來講，最近的醫療影像發展上，透過功能性核磁共振造像(fMRI) 、單光子電腦斷
層攝影(SPECT)以及核磁共振顯像(MRI)的發展，腦部功能的研究在近年來已經有著顯著的
進展，這些腦部的成像提供了研究學者了解腦部特定區域與區域內主要功能之間的關係並
找出腦中影響該病症的區域，進而可以開發新的策略來治療腦部疾病。大腦至今仍有許多
腦部的疾病尚未有治癒的方法，例如著名的阿茲海默症 (Alzheimer's disease)，而透過
五、其    他 
會場剪影: 
  
BMEiCon 會議看板                      會議第一演講廳的準備現場  
       
京都大學鐘塔大樓                    校園留影 
 
 
 
 
 
 
 
 
 
SPECT, which has very different 
characteristics with low background activity 
and poor reference landmark. 
In the previous study, we proposed the 
sequential registration to achieve accurate 
registration along the time course of 
sequential imaging. But it is tedious and 
time-consuming and is impractical for imaging 
patients. We next proposed a two-step 
registration strategy that achieves results 
similar to those of the sequential strategy 
while greatly reducing its drawbacks [3].  
However, the individual MR images from 
volunteers were needed in the two-step 
registration method. In this paper, we propose 
to register the ADAM image to a standard MR 
brain image which is constructed by a fast and 
effective strategy. The ROIs which were 
manually drawn on the MR standard brain are 
mapped onto the registered 6-hour I-123 ADAM 
images. The functional evaluation can then be 
easily performed on the resulting AOIs. Fig .1 
shows the two-step registration procedure by 
using the standard MR brain. Comparing the 
registration results with the individual MR, 
the ICBM152 standard brain [4] and the 
proposed MRI standard brain (MRIstd) as the 
standard brain, the two-step registration 
achieves better registration results using the 
MRIstd than the ICBM152 standard brain. And the 
proposed MRIstd obtains accuracy even close to 
the one by using the individual MRI. Thus, the 
proposed method can achieve good accuracy in 
quantitative measurement and reduce the 
patient loading by eliminating the additional 
MR imaging. The examination of I-123 ADAM 
becomes less expensive and more convenient for 
clinical applications. 
2. MATERIALS 
A total of 10 healthy volunteers (male 4, 
female 6, mean age 65 years) entered this 
study. All subjects gave written informed 
consent, and ethics committee approval was 
obtained.  
 
 
  
Figure 1.  Two step registration of 6-hour I-
123 ADAM SPECT to MRIstd 
 
2.1. MRI 
T-1 weighted MRI images were obtained on the 
same day in axial planes on a Megaton 1.5 
Tesla scanner. The resolution of each MRI 
image was 256 X 256 X 140. 
 
2.2. I-123 ADAM SPECT 
Before the SPECT examination with I-123 ADAM, 
the thyroid gland was protected with 9 ml of 
Lugol's solution. For brain SPECT imaging, 
each participant was intravenously injected 
with 185 MBq (5 mCi) of I-123 ADAM. We used a 
triple-headed rotating gamma camera (Siemens 
Medical Systems, Hoffman Estates, IL, USA) 
with fan-beam collimators and an image 
resolution of approximately 8.5 mm FWHM. A 20% 
energy window was symmetrically placed at 159 
keV. The SPECT images were acquired over a 
360° rotation of 120 steps, at 50 s/step, in a 
128 X 128 X 16 matrix. The images were 
reconstructed using Butterworth and Ramp 
filters (cutoff frequency = 0.3 Nyquist; power 
factor = 7) with attenuation corrections using 
Chang's method [4]. The reconstructed 
transverse images were realigned parallel to 
the canthomeatal line. The slice thickness of 
each transverse image was 2.89 mm. 
 
2.3 ICBM 152 
International Consortium for Brain Mapping 
(ICBM) used 152 normal brain MR scans which 
were normalized to MNI305 with 9 parameter 
affine transformation to construct the ICBM152 
standard brain [6]. 
 
3. REGISTRATION METHODS 
The MRI standard brain was constructed by 
using the HAMMER registration [5]. In this 
The MRI was overlaid with the SPECT image 
to show the relation between the anatomical 
and functional areas (Fig. 4). The ADAM 
binding to SERT is a promising ligand for 
detecting SERT in the human brain, which has 
shown specific regional uptake of I-123 ADAM 
in the midbrain. This supports the hypothesis 
that the midbrain is a suitable region for I-
123 ADAM SPECT monitoring of long-term SERT 
availability changes in the human brain. 
 
 
 
Figure 4.  The first figure shows the 6-hour 
SPECT images, the second figure shows the ICBM 
152 overlaid with the 6-hour ADAM image, and 
the third figure shows the MRIstd overlaid with 
the 6-hour ADAM image. 
 
The mean counts of midbrain activity was 
significantly higher in MRIstd than in ICBM 152 
(153.9±2.99 vs 147.3±2.26, p<0.001). The M/C 
Ratios were also shown (4.235±0.17 vs 
3.577±0.14, p<0.001) significantly higher in 
MRIstd than in ICBM 152. 
In the first experiment, the activities 
mean count in the midbrain region is measured 
by using the proposed standard brain images. 
In table1, the individual MRI, ICBM, MRIstd were 
used as the reference brain. The experimental 
results show the individual MRI as the golden 
standard is the best anatomic reference for 
ADAM-MRI registration. The measured activities 
mean count in the midbrain region is better 
than the others. And registration by using the 
proposed Taiwanese MRI standard brain MRIstd 
shows better results than that by the ICBM 152 
and the resulting accuracy is closed to the 
individual MRI.  
In the second experiment, the SBR ratio 
was calculated as the ratio of the average 
intensity of the corresponding midbrain-to-
cerebellum regions (M/C Ratio) on the 
registered final time point ADAM image.  As 
shown in table2, the individual MRI shows 
better results in M/C Ratio than the other two 
methods. And the proposed Taiwanese MRI 
standard brains shows better results than ICBM 
152 and the accuracy is closed to the one of 
individual MRI. These results are consistent 
with the one of mean count in Table 1. On the 
other hand, the ICBM152 standard brain was 
constructed by using rigid registration with 
152 western brains, thus the image is blurry 
and fairly different to the oriental brains. 
It may make the registration of ICBM152 less 
favorable than the proposed one in the 
experimental results.  
Especially, for these functional 
measurements, we only have to draw the AOI on 
the MRIstd once and then apply the drawn AOI to 
ADAM images for all subjects while we have to 
draw the AOI once for each individual on the 
corresponding MR brain image when using the 
TABLE II 
The midbrain/cerebellum ratios 
 Individual MRI ICBM MRIstd 
Case 1 4.354 3.9 4.55 
Case 2 4.558 3.93 4.41 
Case 3 4.67 3.74 4.29 
Case 4 4.429 3.75 4.39 
Case 5 4.376 3.51 4.31 
Case 6 4.579 3.57 4.19 
Case 7 4.135 3.52 4.091 
Case 8 5.006 3.44 4.57 
Case 9 4.21 3.08 4.04 
Case 10 4.766 3.33 4.26 
AVG 4.5083 3.577 4.310 
AVG, AVERAGE 
TABLE I 
The mean counts of midbrain activity. 
 
 Individual MRI ICBM MRIstd 
Case 1 161 149 157 
Case 2 159 151 155 
Case 3 163 148 156 
Case 4 157 147 155 
Case 5 160 147 157 
Case 6 152 143 148 
Case 7 161 146 154 
Case 8 157 148 152 
Case 9 161 149 155 
Case 10 162 145 150 
AVG 159.3 147.3 153.9 
AVG, AVERAGE 
 
參加IEEE國際生物醫學工程研討會暨 
與匹茲堡大學學術交流報告 
 
 
報告人姓名 孫永年教授 
服務機構 
及職稱 
國立成功大學 
資訊工程學系 
會議及活動
時間地點 
1.98.09.02-06美國
-明尼亞波里斯 
2.98.09.07-09美國
-匹茲堡大學 
 
本會核定 
補助文號 
NSC97-2221-E-006-158-MY2
會議名稱 
(中文) IEEE 國際生物醫學工程研討會 
(英文) 31st Annual International Conference of IEEE Engineering 
in Medicine and Biology Society 
發表論文題
目 
中文： 
以對位為基礎於顯微影像上之神經細胞分割 
由側面膝蓋 X 光影像之髕骨自動分割 
英文： 
Registration-Based Segmentation of Nerve Cells in 
Microscopy Images 
Automated Segmentation for Patella from Lateral Knee X-ray 
Images 
 
 
 
 
 
共十二大主題。而參與本次會議的學者來自世界各地，共有近六千篇論文投稿，最
後有超過兩千篇論文，在會場以口頭報告或壁報展示兩種方式，發表各單位最新之
研究成果。 
 
另外，主辦單位也安排了許多演講會議，邀請專家學者給予精闢的演說。其中，
一些主題演講 (keynote speech) 的題目探討較新的議題，如“Toward Cognitive 
Neuro-Prosthesis”，“Useful Signals from Motor Cortex” 利用動物腦皮層的訊號來控制
機器移動、“MR Imaging of Brain Function: Challenges, Opportunities and Questions”、
“Biomedical Imaging and Optical Biopsy Using Optical Coherence Tomography” OCT影
像的成像技巧與新的運用、“Magnetic resonance elastography (MRE) ”、“Molecular 
Imaging with PET (Positron Emission Tomography) ”之最新應用、…等；同時，相關
業界廠商也在會場擺設攤位，推出最新之相關科技產品，無論是硬體或軟體，工業
應用或醫療用途都有。在整個會議中，不管是口頭報告或者是壁報展示，藉由各國
學者以及不同領域的研究人員之間的互相討論，使得我們可以吸收別人之想法，也
同時給自己一些正面刺激。 
 
 
二、與會心得與建議 
  
此次研討會於9月2日開始一連舉行五天，包含口頭報告與壁報展示共分為將近
兩百個議程同時舉行。此次我們所發表兩篇文章，一篇為口頭報告，另一篇為壁報
展示論文。這兩篇論文分別為 “Registration-Based Segmentation of Nerve Cells in 
Microscopy Images＂，發表時間被安排於6日上午， “Automated Segmentation for 
Patella from Lateral Knee X-ray Images＂, 其壁報張貼時間被安排於4日下午。前者
屬於「Cellular and Molecular Image Processing」主題，後者屬「Biomedical Imaging and 
Image Processing」的議題。 
 
 
 
 
為我們實驗的參考。而超音波影像分析，以及有關於動態模型之相關影像與訊號處
理，也是和本實驗室相關的研究主題。 
  
由於會議論文數量龐大，藉由聽取他人的簡報，除了可以讓我們了解他人的研
究思考及處理方法外，亦可以與國際相關研究學者互動，進而了解國際生物醫學工
程相關研究的趨勢走向，以及最新的研究成果。而在會議中遇到許多國外教授如哥
倫比亞大學之 Elisa E Konofagou教授，韓國光州科技大學之Heung-No Lee教授，以
及澳洲及歐洲的學者，如互相切磋討論，並邀請互訪，十分難得。尤其一些在美的
中國教授，像南加大熊克平教授，能有機會深談敘舊，可遇不可求。而國內數位教
授學者也在會場多所相聚長談，是難得的機會與收穫。 
 
 在聽過這些議程中之部分文章發表後，感覺能經常參加此類研討會，吸取新知
識與觀摩別人的作法，對我們的研究是有益的。尤其所做面對面的溝通，則是我們
在網路交流較不易達到的效果。而在醫學影像相關的發表中，有關於臨床的複雜問
題，通常親自討論可得更大益處。故十分感謝國科會對此次研討會之補助，並希望
在研究上能更努力更有收益，而再有機會參加此類國際性之討論。最後，在聽過多
場國際學生之論文發表之後，覺得我國學生的臨場經驗不足，英文提問之回答也需
加強訓練，這或許是我國高等教育國際化急待改進的一環。 
 
三、參訪匹茲堡大學醫學院與電機系相關實驗室 
 
在完成明尼亞波里斯的 EMBS 研討會之後，也接受匹茲堡大學孫明貴教授之邀
請，前往匹茲堡作三天的訪問。孫明貴(Mingui Sun)教授目前任教於美國匹茲堡大學
神經外科系(Department of Neurological Surgery, University of Pittsburgh)，主要研究領
域為生醫工程，包含生醫訊號處理、影像處理、腦機介面(Brain Computer Interface)
相關儀器之開發與應用，以及電腦輔助之神經手術與診斷系統的開發等。孫教授在
腦波(EEG)訊號處理上有豐富的研究經驗與成果。早期著重在不同睡眠時期下腦波
樣本的分析與探討，1995 年後則以癲癇相關研究，包含腦波源定位(EEG source 
 
 
 
   
           口頭報告                              壁報展示 
97年度專題研究計畫研究成果彙整表 
計畫主持人：孫永年 計畫編號：97-2221-E-006-158-MY2 
計畫名稱：由靜態三維醫學影像重構四維手部運動之研究 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 1 1 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 2 2 100%  
研究報告/技術報告 0 0 100%  
研討會論文 2 2 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
 
