1廣義型線性分式規劃–理論、演算法與應用(II)
Generalized Linear Fractional Programming - Theory, Algorithms and Applications (II)
NSC95-2221-E-239-030
國立聯合大學經營管理學系吳光耀
一、中英文摘要
廣義型線性分式規劃(GLFP)是處理多個線性函數型比值問題的最佳化模式，從中使
比值最小者能夠最大化(或最大者最小化)。此模式常見於經濟、管理科學與工程領域的
應用研究中，同時其問題特性也常被引用於廣義型凸性與廣義型單調性的理論發展中，
此趨勢使得 GLFP 在應用面與理論面皆有日益顯著的重要性。因此，本研究計畫將以三
年時間分別就理論、演算法與應用等層面，完整地探討廣義型線性分式規劃技術。
在第二年的研究中，我們處理最大分式最小化規劃的對偶問題，以及其參數化的等
價擴張模式，從中定義所謂對偶基解與參數化等式系統的關係。繼而提出單形型法來搜
尋基解，反覆找尋直到最佳解被找到。此對偶基方法可適用於處理較多比值的廣義型線
性分式規劃問題。
關鍵詞：分式規劃；多個線性函數型比值；單形型法；原始和對偶問題
Abstract
Generalized linear fractional programming (GLFP) is a ratio optimization approach to the
problems with multiple ratios of affine functions, in which the minimum (maximum) of ratios is
to be maximized (minimized). Many applications of GLFP can be found in the fields of economy,
engineering, and management science. Moreover, the GLFP problem is commonly cited in the
literature of generalized convexity and generalized monotonicity. Therefore, the development of
GLFP appears to be critical in theory and applications. The 3-year plan focuses on the
development of theory, algorithms and applications of GLFP.
In the second year, we addresses the dual problem of minimizing the maximum of a finite
number of linear ratios over a polytope as well as the parametric optimization in which a
parametric basic solution is defined by a system of parametric linear equalities. A simplex-type
algorithm is proposed for exploring basic solutions iteratively, until the optimal point is reached.
The dual approach appears to be highly adaptive to solve the primal fractional problem with a
considerable number of linear ratios.
Keywords: Fractional programming; Multiple ratios of affine functions; Simplex-type methods;
Primal and dual problems
3









0
10
lf
f
 by f0, the matrix










lf
f

1
Rlv by F, and a similar manner for g0Rl, h0Ru, GRlv and
HRuv. Here, we assume
(H1) the feasible region Y={y: Hy+h0=0, y0} is nonempty;
(H2) all denominators gky+gk0, kL, are positive on Y.
Because of (H2), Problem (P1) is equivalently written as
(P2) inf {: (FG)yg0f0, Hy=h0, y0,R }.
Theorem 1. Necessary optimality conditions (Bector, et al., 1989). Let y* be an optimal
solution of (P2) with optimal value*. Then, there exist *Rl,* beRu such that (y*,*,*,*)
satisfies
*T((F*G)y*+(f0*g0))=0,
(F*G)y*+(f0*g0)0,
Hy=h0,
*Te=1,*0.
By introducing slack sRl for which (FG)y+s=g0f0, (P2) is augmented as
(P3) inf {: 



OH
IGF 




s
y
= 





0
00
h
fg
, 



s
y 0,R }.
To arrive at the dual problem of (P3), follow the derivation of Jagannathan and Schaible (1983)
by using Farkas’lemma. For fixed, introduce the set
S= { 



s
y Rv+l: 



OH
IGF 




s
y
= 





0
00
h
fg
, 



s
y 0},
which is defined by a system of linear equalities. It can been seen that the optimal value of (P3) is
(P3)=inf{:S}. (1)
According to theorems of the alternative (see, e.g., Gale (1960), Theorem 2.6), exactly one of the
following two systems has a solution:
 System 1: Ax=b and x0 for some xRn.
 System 2: ATw0 and bTw<0 for some wRm.
Based on the above, Sif and only if the set
T={ 



μ
ω Rl+u: 




 
OI
HGF TTT 




μ
ω 0,  T0T0T0 hfg  



μ
ω
<0}
is empty. From (1), it follows (P3)=inf{:T=}. Note that T= implies T= for any,
and hence(P3)=sup{:T}. For a solution to T,0 holds, since otherwise
HT0 andh0T<0
is consistent (by theorems of the alternative, no solution for Hy=h0 and y0), which contradicts
(H1). We have arrived at the dual problem
(D1) sup {: 




 
OI
HGF TTT 




μ
ω 0,  T0T0T0 hfg  



μ
ω
<0,0,R },
5Thus, T= holds for any (D2) and hence, S for any (D2). From (1), it follows
that(P3)=(D2).
Note that i corresponds to the i-th fractional function, i to the i-th constraint, i to the i-th
variable in (P1), as shown in the following property. This property yields optimality to the
number of zero variables in solutions.
Proposition 3. Suppose that [y*T s*T] and [*T *T *T *] are optimal for (P2) and (D2),
respectively. Then it holds that yi*i*=0 for all iV and si*i*=0 for all iL.
Proof: From problems (P2) and (D2), it follows that (FG)y+s=g0f0, Hy=h0,
T(FG)+THT=0T and T(g0f0)Th00. Hence, T(FG)y+Ts=T(g0f0),
THy=Th0 and T(FG)y+THyTy=0. Thus, TsT(g0f0)=T(FG)y=
THyTy=Th0Ty. We haveTs+Ty=T(g0f0)Th00.
Note that Ts+Ty0 because of 0, 0, y0 and s0. Together with the above, we have
Ts+Ty=0. Because sii0 and yii0, sii=0 and yii=0 are necessary for the solution to
Ts+Ty=0.
Proposition 4. The optimal value of (D2) is obtained by the solution with at least l+u1 zero
--variables and at most vu+1 positive--variables.
Proof: Based on Wu and Wang (2006), the optimal value of (P2) is obtained by the solution with
vu+1 zero variables of y and s, i.e. l+u1 positive variables. Based on Proposition 3, the
property is concluded.
For fixed , Problem (D2) turns to a system with l+u+v+1 variables and v+1 linear equalities.
Based on Proposition 4, a candidate for optimality is the solution with at most v+2 positive
variables (vu+1--variables and u+1--variables). Therefore, the candidate is obtained by (i)
settling l+u1 variables to be zero, then (ii) solving a corresponding linear system with other v+2
variables. Because the corresponding system is of a null space, its solutions are in a ratio way.
According to 0, fix a-variable by a positive value, saying =1, and shift the corresponding
column vector to the right-hand-side (R.H.S.) of the equations. Hence, the other variables are
solvable via a (v+1)(v+1) linear system without a null. Using its gradient, the current can be
improved until a variable arrives at zero. Based on this observation, we have the following
property, which is a basic solution.
Proposition 5. The optimal value of (D2) is obtained by the solution with at least l+u zero
variables.
Definition 1. A solution [T T T ] in which any l+u variables are zero is called a dual basic
solution, or a basic solution in short.
In the following, a basis-based solution approach is proposed for exploring dual basic solutions
iteratively, until an optimal point is reached.
2.3 Solution Procedure
Let T={1, 2, …, l, l+u+1, l+u+2, …, l+u+v+1} be the set of indices corresponding to
nonnegative {,,}. For fixed , Problem (D2) turns to be/becomes a linear system of the null
space
={x: Ax=0, xT0, xL0},
7with the first-order derivative
 new
ip
x =
ip
x / 2)(
ip
x and new
kp
x =(
ip
x 
kp
x 
kp
x 
ip
x )/ 2)(
ip
x ,ki.
It can be seen that newPx 0 and newipx <0, and this result provides another feasible improvement.
Based on the above, the solution procedure is described below.
Algorithm 1. A dual approach for solving (D2)
Step 1. Initialization. Obtain afor which and a basic feasible solution xwith xZ=0.
Let x=1 for BL. Find a Z and settle P={}B\{} and R=Z\{}. According to
the system (3), computexP.
Step 2. Optimality check. Solve Q to the system of PA Q=

RA . If there is a pT for which
p
x =0,
p
x <0 and q0, then stop. The currentis the solution to (D2). Otherwise, go
to Step 3.
Step 3. Pivoting. Find a pair (,j) for which pT, px =0, px <0 and qj<0. Obtain both new P
and R by exchanging the leaving pand the entering rj between sets P and R.
Step 4. Improvement. Apply a gradient search method to increase the value of, until a pT for
which
p
x =0 and
p
x <0. Updateand Aassociated with xP andxP.
Based on Proposition 1, Step 1 can be initialized by a starting obtained via the linear
programming problem sup{: 



μ
T }. The remainder is to obtain a basic feasible solution
within.
To find a basic feasible solution from the current, let1=1 be the r.h.s and {,} be the v+1
basic variables (i.e. =1 and P={l+u+1,…,l+u+v+1}). Note that the current x may be unfeasible.
Using a simplex approach, the following algorithm is proposed for exploring a basic solution
xwith xZ=0.
Algorithm 2. A simplex approach for exploring a starting basic feasible solution
Step 1. Given a nonempty, let=1 and P={l+u+1, l+u+2,…l+u+v+1}
Step 2. If xi0 for all iPT, then go to Step 4. Otherwise, go to Step 3.
Step 3. Compute Q and find a pair (i,j), piT, for which
ip
x <0, qij<0. Give priority to the case of
kp
x 
ip
x qkj/qij0 for all k{1,2,…,p} \{i}.
Step 4. Identify both new P and R by exchanging pi and rj between sets P and R. Update xP and
return to Step 2.
Step 5. Apply a gradient search method to increase the value of , until a pT exists for which
p
x =0 and
p
x <0. The current x is a basic feasible solution and stop.
9Table 1. Computation results of Algorithm 2 in Example 1
 xB x2
(2)
x3
(3)
x4
()
x5
(1)
x6
(2)
x7
(3)
x8
()
x1
R.H.S.
xB
(a) Initialize a basic solution:
0.916667 x5 -0.25 1.75 -3 1 0 0 0 0.3333 -20
x6 4.75 -1.917 -4 0 1 0 0 -10 0
x7 -10.75 -9.833 -1 0 0 1 0 11.6667 -4
x8 -13.167 -6.917 12 0 0 0 1 18.4167 -19
0.916667 x5 4.087 0 -6.652 1 0.913 0 0 -5.7971 -9.1115
x3 -2.478 1 2.087 0 -0.522 0 0 5.2174 2.7221
x7 -35.120 0 19.522 0 -5.130 1 0 62.9710 12.3327
x8 -30.308 0 26.435 0 -3.609 0 1 54.5036 -67.9981
0.916667 x4 -0.614 0 1 -0.150 -0.137 0 0 0.8715 1.9403
x3 -1.196 1 0 0.314 -0.235 0 0 3.3987 -2.2760
x7 -23.126 0 0 2.935 -2.451 1 0 45.9586 -31.2382
x8 -14.067 0 0 3.974 -0.020 0 1 31.4668 -102.2090
(b) Gradient search for improving by 3 iterations:
0.605051 x4 -0.150 0 1 -0.199 -0.101 0 0 1.5855 2.8462
x3 -2.004 1 0 0.495 -0.371 0 0 2.2789 -5.6733
x7 -28.423 0 0 4.363 -3.522 1 0 32.9949 -57.9631
x8 -10.259 0 0 3.804 0.147 0 1 0 -99.0383
Table 2. Computation results of Algorithm 1 in Example 1
 xB x2
(2)
x3
(3)
x4
()
x5
(1)
x6
(2)
x7
(3)
x8
()
x1
R.H.S.
xB
(a) Initialize a basic feasible solution:
0.605051 x4 -0.150 0 1 -0.199 -0.101 0 0 1.5855 2.8462
x3 -2.004 1 0 0.495 -0.371 0 0 2.2789 -5.6733
x7 -28.423 0 0 4.363 -3.522 1 0 32.9949 -57.9631
x8 -10.259 0 0 3.804 0.147 0 1 0 -99.0383
(b) Change the current basis:
0.605051 x4 0 0 1 -0.254 -0.103 0 -0.015 1.5855 4.2905
x3 0 1 0 -0.248 -0.400 0 -0.195 2.2789 13.6742
x7 0 0 0 -6.177 -3.929 1 -2.771 32.9949 216.4267
x2 1 0 0 -0.371 -0.014 0 -0.097 0 9.6538
(c) Change the current R.H.S.:
x2 x1 x4 x5 x6 x7 x8 x3 xB
0.605051 x4 0 0 1 -0.082 0.175 0 0.121 0.6957 -2.2920
x1 0 1 0 0.109 0.176 0 0.086 0.4388 -2.6329
x7 0 0 0 -2.588 1.865 1 0.058 14.4783 8.0953
x2 1 0 0 -0.371 -0.014 0 -0.097 0 4.2361
(d) Gradient search for improving by 7 iterations:
0.199447 x4 0 0 1 0.066 -0.030 0 0.090 -0.2255 -1.1565
x1 0 1 0 0.071 0.176 0 0.030 0 -0.2473
x7 0 0 0 -0.790 1.865 1 0.558 9.1575 -14.9730
x2 1 0 0 -0.172 -0.014 0 0.024 0.1145 -1.0813
11
Table 4. Computation results of Algorithm 1 in Example 2
 xB x2
(2)
x3
(3)
x4
()
x5
(1)
x6
(2)
x7
(3)
x8
()
x1
R.H.S.
xB
(a) Initialize a basic feasible solution:
0.605051 x4 -0.150 0 1 -0.199 -0.101 0 0 1.5855 2.8462
x3 -2.004 1 0 0.495 -0.371 0 0 2.2789 -5.6733
x7 -0.150 0 0 -0.199 -0.101 1 0 1.5856 2.8462
x8 -10.259 0 0 3.804 0.147 0 1 0 -99.0383
(b) Change the current basis:
0.605051 x4 0 0 1 -0.254 -0.103 0 -0.015 1.5855 4.2905
x3 0 1 0 -0.248 -0.400 0 -0.195 2.2789 13.6742
x7 0 0 0 -0.254 -0.103 1 -0.015 1.5855 4.2905
x2 1 0 0 -0.371 -0.014 0 -0.097 0 9.6538
(c) Change the current R.H.S.:
x2 x1 x4 x5 x6 x7 x8 x3 xB
0.605051 x4 0 0 1 -0.082 0.175 0 0.121 0.6957 -2.2920
x1 0 1 0 0.109 0.176 0 0.086 0.4388 -2.6329
x7 0 0 0 -0.082 0.175 0 0.121 0.6957 -2.2920
x2 1 0 0 -0.371 -0.014 0 -0.097 0 4.2361
(d) Gradient search for improving by 7 iterations:
0.341361 x4 0 0 1 0.043 0.047 0 0.110 0 -2.0548
x1 0 1 0 0.085 0.062 0 0.042 0.0580 -0.6186
x7 0 0 0 0.043 0.047 1 0.110 0 -2.0548
x2 1 0 0 -0.222 0.187 0 0.007 0.2519 -0.7531
3.2 Discussions and Summary
Basis-based approaches to the primal GLFP and its dual problem have been proposed in the
first and the second-year study, respectively. The optimal condition for the basic solutions was
analyzed by algebra properties. Gradient search was proposed for a move from current solution
toward another better basic feasible solution.
Based on a dual space, a dual simplex-type algorithm has been proposed for GLFP in this study.
From the scale of the basis, it can be seen that dealing with the dual problem would be more
beneficial to the primal problem with a considerable number of the linear ratios (see Wu, 2006b
for numerical results). Moreover, it is less influenced by scaling when solving the dual.
Several results on theory, algorithms and applications are summarized and discussed in the
following.
 Our proposed approach is similar to the conventional simplex method for LP, and also to the
extension of the simplex algorithm for linear fractional programs. A unified simplex-type
approach for solving some optimization problems with linear constraints was established
(see Wu, 2005; Wu, 2006a). Moreover, the adaptability of the parametric model and that of
the solution procedure were discussed therein. In particular, the proposed algorithm can
prevent cycling when compared with the conventional simplex method used for solving
linear programs.
 The approach based on basis technique facilitates the development of a sensitivity analysis
scheme as well as a GLFP-aided interactive system in decision-making. The fractional
programming approach was proposed for throughput planning in a production system (Wu
13
& Management System and 2007 Chinese Institute of Industrial Engineers Conference,
Kaohsiung, Taiwan, December 9-12, 2007. (NSC95-2221-E-239 -030)
19. Wu, K.-Y. and Lai, H.-F. (2006). Application of generalized linear fractional programming to
a throughput planning problem. Proceedings of the 36th International Conference on
Computers and Industrial Engineering, June 20-23, Taipei, Taiwan. (NSC94-2213-E239-005)
20. Wu, K.-Y., Lai, H.-F. and Ho, C.-Y. (2007). Manpower allocation in an asynchronous
production line with leveled labor. IEEE International Conference on Industrial Engineering
and Engineering Management, December 2-5, 2007, Singapore. (NSC95-2221-E-239 -030)
21. Wu, K.-Y. and Wang, H.-F. (2006). A basis-based algorithm for generalized linear fractional
programming, Journal of Optimization Theory and Applications, submitted.
(NSC94-2213-E239-005)
三、計畫成果自評
本專題研究計畫以三年期分別就理論、演算法與應用等三個層面來完整地探討廣義
型線性分式規劃，以奠立該技術發展之宏規。延續第一年成果，目前第二年的具體成果
有 1 篇已發表的國內研討會論文(Wu, 2006c)、1 篇已發表的國際研討會論文(Wu, 2006b)
和 2 篇即將發表的國際研討會論文(Wu, Lai and Ho, 2007; Wu and Ho, 2007)。茲將第二年
研究成果說明如下：
(1) 利用搜尋基解為基礎的單形型(Simplex-type)方法，以及最佳解條件、對偶等特性，
發展出對偶基底式演算法(Wu, 2006b; 2006c)。待數值實驗結果整理完成後，將投稿
國際期刊。
(2) 藉由產出率最佳化在本地銅線廠的應用範例(Wu and Ho, 2007)，我們已驗證以基解性
質求得的最佳解有利於敏感度分析技術的建立，同時有助於交談式決策支援系統的
建構。延伸此應用研究，我們也建構一個人力資源限制下之產能規劃模式(Wu, Lai and
Ho, 2007)來幫助製造業面對人力短缺與流動的雙重問題。待此雛型實作完成後，可
供實務推廣。
在完成二個計畫年度後，未來將運用所奠定的理論與演算法基礎，導入到財務規劃問
題的應用。
1出席國際學術會議心得報告
計畫編號 95-221-E-239-030
計畫名稱 廣義型線性分式規劃–理論、演算法與應用(II)
出國人員姓名
服務機關及職稱
吳光耀
國立聯合大學經營管理學系副教授
會議時間地點 民國九十五年十一月五至八日，美國(匹茲堡)
會議名稱 INFORMS Annual Meeting, Pittsburgh 2006
發表論文題目 On Solving a Dual Problem in Generalized Linear Fractional Programs
一、參加會議經過
本人於匹茲堡當地時間 5日早上八點到達 Pittsburgh Convention Center會議場地，並完成
研討會註冊報到及領取資料﹙如下圖﹚，之後展開為期四天的會議參與行程，8日下午一點離
開會議返台。本人前三天主要活動是聆聽每日四個時段的學者演說，最後一天為本人的論文
發表；另於第二天晚上參加在 Carnegie Museums舉辦的歡迎晚宴，會中與幾位哈佛大學博士
生閒聊一些該校校友電子商務創業的故事，以及該校的教學特色。
INFORMS﹙Institute For Operations Research and the Management Sciences﹚出版許多知名
高水準的期刊，如Management Science、Decision Analysis、INFORMS Journal on Computing
Interfaces、Operations Research、Transportation Science等，每年舉辦的會議是作業研究與管
理科學領域的年度國際盛會，參會者眾；另設有展示場陳列各項書籍及軟體。本屆四天會議
總計有 825個論文發表場次(Session)，高達 3300篇以上論文發表，另外平行時段安排有八場
Plenary & Keynote Presentations與二十場 Tutorials。因此，這場議題豐富的知識饗宴，大抵只
能從中擇取本人有興趣或與本人研究相關的議題聆聽，並分列如下：
3二、與會心得
本次大會安排研究人員交流機會，除了發表論文並進行詢答外，每個晚上都有不同的交
誼活動。本人曾參與第二晚在卡內基博物館的歡迎晚晏，許多參與研討會的學者專家都相當
習慣這種聯誼的方式，在輕鬆的氣氛中來增進專業研究經驗交換及彼此的情誼，對於個人未
來參與國際合作的參與提供相當好的經驗。本人自1993年從講師到副教授，一直致力於教學
工作，鮮有機會參與國際性的研討會。本次幸獲國科會專題研究的補助，能參與國際盛會並
發表最近年來的研究成果，對未來將研究成果推向國際建立了相當高的自信心。
本次研討過程中，感受到美國作業研究與管理科學領域的活力，許多議題都相當實務，
尤其是頗多論文來自於學界、產業界及顧問公司聯合完成，其產學合作已經是相互融入形成
定型的互動。這也啟蒙本人在未來的研究領域方向應更要加強實務的結合，以避免落入為研
究而研究的象牙塔中。
經過此次與會，見識到研討會的環境安排、議程活動進行、會場詢問與服務都相當用心，
足可做為本人未來主辦相關研討會之參考。最後茲將四天演講聆聽到的重要議題分述如下：
(1) 有關電子商務目前仍是延續的熱門議題，尤其是拍賣的機制與模式探討。這類場次
聽眾都特別多，而且每篇報告完畢後都收到詢問和回響。
(2) 大型且係數複雜的線性規劃問題，目前在求解演算法發展上，知名的K.G. Murty教授
發展descent method有顯著的進展。
(3) Risk = Uncertainty + Cost，許多不確定性理論相繼配提出之際，知名的M.J. Greenberg
教授提倡整合的架構。
(4) 知名的P.T. Harker教授介紹服務業管理時，預估在2040年OR&MS學術論文的分布：
製造業(Manufacturing)30%、教育學習(Education)30%、健康照顧(Healthcare)40%。
開始決定參加本次會議時，尚覺得註冊費很高，但現場親身聽到這些知名教授的演講及
聽後收獲，實感值得！以自身的經驗認為這種國際性的研討會，對個人未來教學及研究方向
有相當大的啟發。
三、建議
經由本次參與研討會的心得，有下列三點建議：
(1) 國內雖已開始強調服務業的研究，惟服務產業含蓋層面眾多且異。國內未來10-20年
有那些服務產業會新興，宜未雨綢繆，至少要正視教育學習和健康照顧的後勢發展。
(2) 國際上不確定性理論發展眾多，惟國內大學似仍未廣含於教學課程中。
(3) 電子商務推動著服務業的創新，也創造許多研究議題。因此除了典型作業管理題材
外，國內作業研究領域的學者可在電子商務服務創新上耕耘。
四、攜回資料名稱及內容
本次研討會的議程與論文摘要集：Proceedings INFORMS 2006，內含3300篇以上相關的論文
摘要。
52.1. Primal problem and its dual
Consider a problem with l linearly fractional functions, u linear constraints and v (v>u) variables,
and let L={1,2,…,l}, U={1,2,…,u} and V={1,2,…,v}. The problem of GLFP is formulated as
below:
(P1) inf { 






0
0max
kk
kk
Lk g
f
yg
yf
: 0ii hyh =0,iU, y0},
where fk, gk, hi are row v-vectors, and fk0, gk0, hi0 are real value. Wu denote the column vector










0
10
lf
f

by f0, the matrix










lf
f

1
Rlv by F, and a similar manner for g0Rl, h0Ru, GRlv and HRuv. Here,
we assume
(H1) the feasible region Y={y: Hy+h0=0, y0} is nonempty;
(H2) all denominators gky+gk0, kL, are positive on Y.
Because of (H2), Problem (P1) is equivalently written as
(P2) inf {: (FG)yg0f0, Hy=h0, y0,R }.
Theorem 1.1. Necessary optimality conditions (Bector, et al., 1989). Let y* be an optimal
solution of (P2) with optimal value *. Then, there exist *Rl, * beRu such that (y*,*,*,*)
satisfies
*T((F*G)y*+(f0*g0))=0,
(F*G)y*+(f0*g0)0,
Hy=h0,
*Te=1,*0.
By introducing slack sRl for which (FG)y+s=g0f0, (P2) is augmented as
(P3) inf {: 



OH
IGF 




s
y
= 





0
00
h
fg
, 



s
y 0,R }.
To arrive at the dual problem of (P3), follow the derivation of Jagannathan and Schaible (1983)
by using Farkas’lemma. For fixed, introduce the set
S= { 



s
y Rv+l: 



OH
IGF 




s
y
= 





0
00
h
fg
, 



s
y 0},
which is defined by a system of linear equalities. It can been seen that the optimal value of (P3) is
(P3)=inf{:S}. (1)
According to theorems of the alternative (see, e.g., Gale (1960), Theorem 2.6), exactly one of the
following two systems has a solution:
72.2. Optimality in the Dual Problem
Considering the extreme case of (D1) and introducing the slack Rv and R, an augmented
problem was arranged as
(D2) sup{: 







10To
T
o
T
o
TTT
hfg
0IHFG















υ
μ
ω
=0,0,0,0,0,R }.
For fixed, introduce the set
= {













υ
μ
ω
Rl+u+v+1: 







10To
T
o
T
o
TTT
hfg
0IHFG















υ
μ
ω
=0,0,0,0,0}.
Then it can been seen that the optimal value of (D2) is
(D2)=sup{:}. (2)
Proposition 2. Both problems (P2) and (D2) are equivalent, i.e.(P3)=(D2).
Proof. (D2) is an upper bound of the solution to (D1), since  T0T0T0 hfg  



μ
ω 0 in (D2).
Thus, T=holds for any(D2) and hence, S for any(D2). From (1), it follows that
(P3)=(D2).
Note that i corresponds to the i-th fractional function, i to the i-th constraint, i to the i-th
variable in (P1), as shown in the following property. This property yields optimality to the number
of zero variables in solutions.
Proposition 3. Suppose that [y*T s*T] and [*T*T*T*] are optimal for (P2) and (D2), respectively.
Then it holds that yi*i*=0 for all iV and si*i*=0 for all iL.
Proof: From problems (P2) and (D2), it follows that (FG)y+s=g0f0, Hy=h0,
T(FG)+THT=0T and T(g0f0)Th00. Hence, T(FG)y+Ts=T(g0f0),
THy=Th0 and T(FG)y+THyTy=0. Thus, TsT(g0f0)=T(FG)y=
THyTy=Th0Ty. We haveTs+Ty=T(g0f0)Th00.
Note that Ts+Ty0 because of 0, 0, y0 and s0. Together with the above, we have
Ts+Ty=0. Because sii0 and yii0, sii=0 and yii=0 are necessary for the solution to
Ts+Ty=0.
Proposition 4. The optimal value of (D2) is obtained by the solution with at least l+u1 zero
--variables and at most vu+1 positive--variables.
Proof: Based on Wu and Wang (2006), the optimal value of (P2) is obtained by the solution with
vu+1 zero variables of y and s, i.e. l+u1 positive variables. Based on Proposition 3, the
property is concluded.
For fixed , Problem (D2) turns to a system with l+u+v+1 variables and v+1 linear equalities.
Based on Proposition 4, a candidate for optimality is the solution with at most v+2 positive
variables (vu+1 --variables and u+1 --variables). Therefore, the candidate is obtained by (1)
settling l+u1 variables to be zero, then (2) solving a corresponding linear system with other v+2
variables. Because the corresponding system is of a null space, its solutions are in a ratio way.
9between sets P and R to obtain the new basis sets Pnew and Rnew, we have the new solution of
new
ip
x =
ip
x / ijq and new
kp
x =
kp
x 
ip
x kjq /

ijq ,ki,
with the first-order derivative
 new
ip
x ()=
ip
x / ijq and new
kp
x =
kp
x 
ip
x kjq /

ijq ,ki,
where Q= 1)( PA

RA . Thus, when Proposition 6 holds, we find a j for which

jq <0 for another
improving direction. On the other hand, if there is no jq <0 , then an optimal solution is reached.
Proposition 7: If there is a pT for which px =0,  px <0 and

q 0, then the current is the
solution to (D2).
Conversely, when xi0 andxi0 for all iPT, the improvement becomes an infinite. To avoid
this trap, consider a positive vector
ip
x , piL, to be the r.h.s., in which
ip
x >0. This is done by
letting positive
ip
x leave the basis to r.h.s. (i.e. resettle
ip
x =1) and xenters the basis P at position
i. Based on the new basis Pnew, we have the new solution of
new
ip
x =1/
ip
x and new
kp
x =
kp
x /
ip
x ,ki,
with the first-order derivative
 new
ip
x =
ip
x / 2)(
ip
x and new
kp
x =(
ip
x 
kp
x 
kp
x 
ip
x )/ 2)(
ip
x ,ki.
It can be seen that newPx 0 and newipx <0, and this result provides another feasible improvement.
Based on the above, the solution procedure is described below.
Algorithm 1. A dual based approach for solving (D2)
Step 1. Initialization. Obtain afor whichand a basic feasible solution xwith xZ=0. Let
x=1 for BL. Find a Z and settle P={}B\{} and R=Z\{}. According to the
system (3), computexP.
Step 2. Optimality check. Solve Q to the system of PA Q=

RA . If there is a pT for which px =0,

p
x <0 and q0, then stop. The currentis the solution to (D2). Otherwise, go to Step 3.
Step 3. Pivoting. Find a pair (,j) for which pT, px =0,  px <0 and qj<0. Obtain both new P
and R by exchanging the leaving pand the entering rj between sets P and R.
Step 4. Improvement. Apply a gradient search method to increase the value of , until a pT for
which
p
x =0 and
p
x <0. Updateand Aassociated with xP andxP.
11
s.t.
















100012135227191
01001283848
0010413210
0001331332015




































3
2
1
3
2
1
=












0
0
0
0
,
10,20,30,10,20,30,0,0.
Letting [1,2,3]=[1,1,1],is initialized by0.916667 yielded from the following problem
max
s.t. 14311,2411, 924, 54+1211.
Now, settling 1=1 and P={5,6,7,8}, we have Table 1(a) as a basic solution. Using Algorithm 2, a
basic feasible solution is obtained. As shown in Table 1(b), the currentis improved up to0.6051
by the gradient search method. The solution is used for Algorithm 1, which computation results are
listed in Table 2. Finally, the optimal solution of =[0.0000,0.1144,1.0000]T, =-0.2255,
=[0.0000,0.0000,9.1575] T,=0 and=0.199447 is obtained in Table 2(d). Based on Proposition
3, the solution indicates that the solution to (P2) is the intersection of the three hyperplanes of y3=0,
s2=0 and s3=0 on S0.199447. The primal optimal solution is that y=[2.3922,1.2058,0.0000]T and
s=[33.6100,0.0000,0.0000]T.
Table 1. Computation results of Algorithm 2 in Example 1
 xB x2
(2)
x3
(3)
x4
()
x5
(1)
x6
(2)
x7
(3)
x8
()
x1
R.H.S.
xB
(a) Initialize a basic solution:
0.916667 x5 -0.25 1.75 -3 1 0 0 0 0.3333 -20
x6 4.75 -1.917 -4 0 1 0 0 -10 0
x7 -10.75 -9.833 -1 0 0 1 0 11.6667 -4
x8 -13.167 -6.917 12 0 0 0 1 18.4167 -19
0.916667 x5 4.087 0 -6.652 1 0.913 0 0 -5.7971 -9.1115
x3 -2.478 1 2.087 0 -0.522 0 0 5.2174 2.7221
x7 -35.120 0 19.522 0 -5.130 1 0 62.9710 12.3327
x8 -30.308 0 26.435 0 -3.609 0 1 54.5036 -67.9981
0.916667 x4 -0.614 0 1 -0.150 -0.137 0 0 0.8715 1.9403
x3 -1.196 1 0 0.314 -0.235 0 0 3.3987 -2.2760
x7 -23.126 0 0 2.935 -2.451 1 0 45.9586 -31.2382
x8 -14.067 0 0 3.974 -0.020 0 1 31.4668 -102.2090
(b) Gradient search for improving by 3 iterations:
0.605051 x4 -0.150 0 1 -0.199 -0.101 0 0 1.5855 2.8462
x3 -2.004 1 0 0.495 -0.371 0 0 2.2789 -5.6733
x7 -28.423 0 0 4.363 -3.522 1 0 32.9949 -57.9631
x8 -10.259 0 0 3.804 0.147 0 1 0 -99.0383
13
Table 3. Computation results of Algorithm 2 in Example 2
 xB x2
(2)
x3
(3)
x4
()
x5
(1)
x6
(2)
x7
(3)
x8
()
x1
R.H.S.
xB
(a) Initialize a basic solution:
0.916667 x5 -0.25 1.75 -3 1 0 0 0 0.3333 -20
x6 4.75 -1.917 -4 0 1 0 0 -10 0
x7 0 0 -1 0 0 1 0 0 0
x8 -13.167 -6.917 12 0 0 0 1 18.4167 -19
0.916667 x5 4.087 0 -6.652 1 0.913 0 0 -5.7971 -9.1115
x3 -2.478 1 2.087 0 -0.522 0 0 5.2174 2.7221
x7 0 0 -1 0 0 1 0 0 0
x8 -30.308 0 26.435 0 -3.609 0 1 54.5036 -67.9981
0.916667 x4 -0.614 0 1 -0.150 -0.137 0 0 0.8715 1.9403
x3 -1.196 1 0 0.314 -0.235 0 0 3.3987 -2.2760
x7 -0.614 0 0 -0.150 -0.137 1 0 0.8715 1.9403
x8 -14.067 0 0 3.974 -0.020 0 1 31.4668 -102.2090
(b) Gradient search for improving by 3 iterations:
0.605051 x4 -0.150 0 1 -0.199 -0.101 0 0 1.5855 2.8462
x3 -2.004 1 0 0.495 -0.371 0 0 2.2789 -5.6733
x7 -0.150 0 0 -0.199 -0.101 1 0 1.5856 2.8462
x8 -10.259 0 0 3.804 0.147 0 1 0 -99.0383
Table 4. Computation results of Algorithm 1 in Example 2
 xB x2
(2)
x3
(3)
x4
()
x5
(1)
x6
(2)
x7
(3)
x8
()
x1
R.H.S.
xB
(a) Initialize a basic feasible solution:
0.605051 x4 -0.150 0 1 -0.199 -0.101 0 0 1.5855 2.8462
x3 -2.004 1 0 0.495 -0.371 0 0 2.2789 -5.6733
x7 -0.150 0 0 -0.199 -0.101 1 0 1.5856 2.8462
x8 -10.259 0 0 3.804 0.147 0 1 0 -99.0383
(b) Change the current basis:
0.605051 x4 0 0 1 -0.254 -0.103 0 -0.015 1.5855 4.2905
x3 0 1 0 -0.248 -0.400 0 -0.195 2.2789 13.6742
x7 0 0 0 -0.254 -0.103 1 -0.015 1.5855 4.2905
x2 1 0 0 -0.371 -0.014 0 -0.097 0 9.6538
(c) Change the current R.H.S.:
x2 x1 x4 x5 x6 x7 x8 x3 xB
0.605051 x4 0 0 1 -0.082 0.175 0 0.121 0.6957 -2.2920
x1 0 1 0 0.109 0.176 0 0.086 0.4388 -2.6329
x7 0 0 0 -0.082 0.175 0 0.121 0.6957 -2.2920
x2 1 0 0 -0.371 -0.014 0 -0.097 0 4.2361
(d) Gradient search for improving by 7 iterations:
0.341361 x4 0 0 1 0.043 0.047 0 0.110 0 -2.0548
x1 0 1 0 0.085 0.062 0 0.042 0.0580 -0.6186
x7 0 0 0 0.043 0.047 1 0.110 0 -2.0548
x2 1 0 0 -0.222 0.187 0 0.007 0.2519 -0.7531
The results of applying Algorithms 2 and 1 are reported in Tables 3 and 4, respectively. As shown
in Table 4(d), the optimal solution is =[0.0580,0.2519,1.0000]T, =0, =[0,0,0] T, =0 and
