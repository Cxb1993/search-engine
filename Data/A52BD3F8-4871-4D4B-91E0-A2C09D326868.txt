 2 
行政院國家科學委員會專題研究計畫成果報告 
 
具人聲特性的噪音頻譜預估以完成即時語音增強系統之研究 
The Study on Noise Spectrum Estimation with Human Voice Properties to 
Implement a Real-Time Speech Enhancement System 
 
計畫編號：NSC 98-2221-E-158 -004 
執行期限：98 年 8 月 1 日至 99 年 7 月 31 日 
主持人：王坤卿 執行單位﹕實踐大學/資訊科技與通訊學系 
 
 
壹、 摘要 
一、 中文摘要 
本 計 畫 主 要 針 對 極 非 穩 態 (highly 
non-stationary)噪音環境下考慮人聲特性為
基礎之噪音頻譜預估以快速調整時間頻率
相關(time-frequency dependent)之小波係數
閥值(wavelet coefficient threshold)以作即時
(real-time)語音增強系統 (real-time speech 
enhancement system)。事實上，在現實生活
中的背景噪音能量程度變動地非常快速，若
無法即時更新噪音頻譜能量，其可能因閥值
運算(thresholding)後而造成殘餘性噪音的產
生，進一步地降低語音通訊的品質。為達到
快速抑制噪音及補償語音音質以實現一個
即時(real-time)語音增強的技術，計畫中提
出一個以人聲特性為基礎之子頻帶噪音頻
譜追蹤(subband noise spectral tracking)作為
快速且精準預估背景噪音程度的方法。 
首先，根據人耳感知聽覺，將頻譜熵(spectral 
entropy) 建立於 24 個巴克量度子頻帶
(bark-scale subband)上，並透過可用頻帶選
擇(useful subband selection)的觀念及人聲既
有的聲紋特性(voiceprint property)的利用以
偵測語音有效區段。其次，提出一個子頻帶
噪 音 頻 譜 追 蹤 (subband noise spectral 
tracking)方法，依照各音框的語音偵測結果
及 各 子 頻 帶 的 語 音 存 在 機 率
(speech-presence probability)，以遞迴平均的
方式更新噪音能量，使得不僅在非語音訊號 
 
區段更新噪音能量，也能在語音訊號區段作
精準地預估噪音能量。除此之外，本計畫也
將建立一個時間頻率資訊相關的小波係數
閥值，考慮各音框的語音偵測及頻帶噪音頻
譜追蹤的結果作適度性地隨時間調整各頻
帶的小波係數閥值。最後，計畫將採用感知
增益因子(perceptual gain factor)以改善最終
的感知音質(perceptual quality)。 
關鍵詞：頻譜熵、噪音頻譜預估、非穩態噪
音、語音有效偵測、語音增強 
二、 英文摘要 
This project mainly proposes a real-time 
speech enhancement system that utilizes noise 
spectrum estimation with human voice 
properties to adapt wavelet coefficient 
thresholds of the time-frequency dependent. In 
fact, the background noise level varies very 
quickly in real environment. If noise spectrum 
cannot be quickly updated, the residual noise 
may be produced. Furthermore, the quality of 
voice communication will be decreased. A 
real-time speech enhancement will be 
accomplished in order to quickly suppress 
noise and compensate speech quality. This 
project will propose a subband noise spectral 
tracking with human voice properties as a fast 
and accurate method for estimating 
background noise.  
First, the spectral entropy is defined on 24 
bark-scale subband according to the human 
 4 
5) 子頻帶噪音頻譜追蹤 (subband noise 
spectrum tracking)之建立。 
6) 時間及頻率相關性的小波係數閥值之
計算 
7) 感知增益因子(perceptual gain factor)之
推導。 
三、 文獻探討 
利用小波轉換(wavelet transform)具有極佳
的時域、頻域分析功能以及多重解析的特性
[13]，其應用在的語音增強技術的開發，近
年來已成為一個新興的研究領域[8]-[11]。其
中最受歡迎的小波閥值為基礎 (wavelet 
threshold-based)的方法，經由分解後的各子
頻帶的小波係數(wavelet coefficients)直接減
去對應的各子頻帶上的門檻值(threshold)即
可 達 到 語 音 增 強 的 效 果 。 最 早 由
Donoho[1]-[2] 等 人 首 先 針 對 高 斯 分 佈
(Guassian)特性的白色噪音(White Noise)提
出一致性(universal)小波閥值，然而，對於
實際噪音具音樂性雜訊(musical noise)，各頻
帶的噪音程度會分佈不同，因此，一致性的
小波閥值會消去其它頻帶可能存有的語音
訊號成分。為了考慮音樂性雜訊的特性，
Johnstone[3]等人採用與小波分頻層次有關
(level-dependent)的小波閥值，使各頻帶間的
小波閥值皆不同。進一步地，Vidakovic[4]
等人針對小波封包(wavelet packet)分頻的架
構，提出適用的小波閥值。由於考量背景噪
音具有非穩態特性，根據不同音框的特性適
當地調整小波閥值，其隨著時間作調整
(time-adapted) 的 方 法 近 年 來 也 被 提 出
[5]-[6]。由於小波閥值處理過程易產生無法
避免的殘餘性噪音(residual noise)，近幾年，
考慮人耳聲響模型，計算噪音遮蔽門檻
(noise masking threshold)[18]以降低殘餘性
噪音對人耳聽覺的影響。 
以目前來看，雖然國內外提出不少以小波閥
值為基礎的語音增強方法，大多以考慮人耳
聲響模型及可調式的小波係數為主，以抑制
殘餘噪音成分的對感知聽覺的影響。然而，
如何建立快速補償語音的語音增強的研究
卻是較為缺乏。小波閥值雖由各音框之各頻
率噪音程度作適當地調整，但是噪音程度的
決定在現實噪音特性下卻顯得不太適用。由
於現實生活中的背景噪音能量程度遽烈變
動時可能造成語音瞬間無法迅速補償所產
生的殘餘性噪音(musical residual noise)，這
些都會造成語音通訊上的收訊障礙。申請人
希望透過本計畫之執行，考慮以人聲特性為
基礎之噪音頻譜預估與時間頻率相關之小
波係數閥值之研究及小波閥值隨著各音框
的訊雜比值及頻率的噪音程度以完成快速
語音增強的系統。 
四、 研究方法 
本計畫執行預期可分成三大部分來進行，(1)
透過人耳感知聽覺模型(perceptual auditory 
model)作語音分析。(2)考慮人聲特性(human 
speech properties)之子頻帶噪音頻譜追蹤以
預估非穩態(non-stationary)下之噪音程度。
(3)根據各音框子頻帶預估之噪音程度進而
隨時間頻率調整小波係數閥值。圖一所示為
透過人耳感知聽覺模型(perceptual auditory 
model)作語音分析以快速調整時間頻率相
關之小波係數閥值之即時性(real-time)語音
增強之架構圖。 
 
圖一 考慮人聲特性之噪音預估以快速調整時間頻
率相關之即時(real-time)語音增強系統 
由圖一清楚地描述為匹配人耳感知聽覺模
型，將輸入之受噪音干擾的語音 (noisy 
speech) 經 由 巴 克 量 度 小 波 封 包 分 解
(Bark-scale wavelet packet decomposition, 
BSWPD)。分解出的各關鍵子頻帶(critical 
 6 
式 (4)來計算每個臨界頻帶遮蔽的偏移
(offset)： 
( ) ( ) (14.5 ) 5.5(1 ( ))O ton tonξ ξ ξ ξ= ⋅ + + −  (4) 
其中 ( )ton ξ 是用來判斷訊號是比較靠近語
音還是比較靠近噪音。 
我們利用頻譜平坦度量測(Spectral Flatness 
Measure, SFM)來決定 ( )ton ξ 的值。當頻譜比
較平坦，判斷為比較接近噪音；如果譜譜變
化比較劇烈，判斷為比較接近語音。SFM 的
定義是功率頻譜的幾何平均 (geometric 
mean)G 值與算術平均(arithmetic mean)A 值
的比值： 
( )( ) ( )
GmSFM
Am
ξξ ξ= 。  (5) 
決定 SFM 後， ton 值可由得到式(16)求
出 
max
min ,1dB
dB
SFM
ton
SFM
 
=  
 
。 (6) 
當 ton值接近 1 時，表示頻譜較不平坦，判
斷為接近語音訊號；當 ton值接近 0 時，表
示頻譜比較平坦，判斷為類似噪音的訊號。 
將激發樣型減掉偏移量後，就可以得到每個
臨界子頻帶的閥值，如式(7)所示 
( ) ( ) ( )Th B Oξ ς ξ= − 。 (7) 
最後，將經減掉偏移量，求出聽覺遮蔽閥值
的 正 規 化 ， 再 與 絕 對 聽 覺 閥 值
(absolute-hearing threshold, AHT)作比較，如
圖五及式(9)所示，取比較大的作為最後的聽
覺遮蔽閥值： 
( )( ) max ( ), ( )cb absT T f Thξ ξ= ， (8) 
20.6( 3.3)0.8 1000
3 4
( ) 3.64( ) 6.5
1000
10 ( )   (dB)
1000
f
abs
fT f e
f
− −
−
−
= −
+
，  (9) 
此 ( )cbT ξ 及 ( )absT f 為臨界頻帶的聽覺遮蔽
閥值與絕對聽覺閥值。 
 
II. 考慮人聲特性之子頻帶噪音頻譜追蹤 
此部分主要包含一個以頻譜熵為基礎的語
音段偵測及子頻帶噪音頻譜程度追蹤。本計
畫為快速作語音訊號增強，考慮人耳特性，
建立一個以頻譜熵為基礎語音偵測以精準
判斷語音/噪音為主的音框，並採用子頻帶
噪音頻譜追蹤以依據語音偵測結果作遞迴
平均方式去預估噪音頻譜。 
 語 音 活 動 偵 測 (voice-activity 
detector, VAD)  
由於一般噪音特性在無語音訊號區段及有
語音訊號區段間有所不同，因此本計劃建立
語音段偵測是除了用來區隔語音與噪音的
一種方法，也針對在無語音訊號區段估測噪
音能量外，也能在有語音訊號區段間提供噪
音特性之即時更新。 
圖三為本計畫提出的語音段偵測架構別，分
別計算經巴克量度小波封包分頻出的 24 個
巴克量度之子頻帶頻譜能量。根據不同噪音
特性對各頻帶干擾程度的不同現象，透過一
個適應頻帶選擇觀念 (adaptive frequency 
subband selection, AFSS)選擇不受噪音干擾
或干擾程度不大之可用的巴克量度子頻帶
以提供有效的語音資訊。文獻[21]表示頻譜
熵 (spectral entropy) 較頻譜能 量 (spectral 
energy)更能用語音偵測語訊號的參數，故將
頻譜熵定義在 24 個關鍵子頻帶上，並進一
步地描述語音訊號在聲譜圖(spectrogram)上
特有的聲紋(voiceprint)特徵[19]。同時，也
加入無聲語音的偵測(unvoiced decision)。 
 
 
圖三 建立在巴克標度小波封包分解並以頻譜
熵為基礎語音段偵測 
 
 8 
框的事後預估訊雜比值(posterior SNR)。 
針對第 m 音框第ξ 頻帶內之預估噪音頻譜
( , )N mξ% ，其子頻帶的事後訊雜比值可視為 
2( , )( , ) ( , )
X m
ptsnr m
N m
ξξ ξ= % .  (14) 
因此，  ( )SNR m 可由各子頻帶上的事後訊雜
比值相加計算得出 
10( ) 10log ( , )
N
SNR m ptsnr m
ξ
ξ
∈
= ∑ .  (15) 
因此，適應性頻帶選擇的機制可先透過子頻
帶噪音頻譜追蹤以預估頻帶內的噪音程
度，並依式(14)決定各頻帶內之預估訊雜比
值，經式(15)決定整個音框的訊雜比值。最
後，依照式(13)及圖六所示決定可用頻帶數
( )ubN m 。 
 
 
圖五 可用頻帶數目 與語音偵測正確準確率之關係 
 
 
 
圖六 ubN 與 SNR 的線性關係 
 
頻譜熵之計算(calculation of spectral 
entropy) 
針對各音框所分解出的24個關鍵子頻帶，由
式(11)的頻帶能量之正規化運算如下, 
1
( , ) ( , ) ( , )
N
P m E m E m
ω
ξ ξ ω
=
= ∑% % 。  (16) 
此 ( , )P mξ 為第m 音框內的第ξ 個關鍵子頻
帶之能量分佈機率，而 N 為經BSWPD分解
後的24關鍵子頻帶。 
事實上，某些頻帶會受背景噪音干擾而破壞
既有的語音能量資訊，因此在計算頻譜熵參
數時，利用式(13)~式(15)以選擇可用頻帶，
因此，式(11)可進一步更正為 
( )
1
( , ) ( , ) ( , )
ubN m
P m E m E m
ω
ξ ξ ω
=
= ∑% % ，  (17) 
此 ( )ubN m 表示第 m 音框的可用子頻帶數
目，其隨著不同音框的預估訊雜比值
 ( )SNR m 而決定。 
經上述修正後，針對第m 音框其所提出的頻
譜熵 ( )H m 計算如下 
1
( ) ( , ) log[ ( , )]
ubN
H m P m P m
ξ
ξ ξ
=
= − ⋅∑ 。  (18) 
相較於一般以頻譜能量作為語音偵測的參
數，通常假定語音能量大於噪音背景量，在
訊雜比低時就會有語音偵測錯誤的時候，尤
其在背景噪音程度突然增大情況下最常出
現錯誤偵測的結果。本計畫執行中將特別強
調人聲特性在聲譜上的聲紋現現象作為語
音偵測的依據，將採以頻譜熵參數為基礎語
音偵測方法。 
無聲語音偵測(unvoiced decision) 
在語音活動偵測方法中，由於頻譜熵僅作為
描述在聲譜圖上具聲紋現像的有聲語音
(voiced speech)，因此無法適用於無聲語音
(unvoiced speech)不具有聲紋的先天特性(。 
為有效區隔無聲語音與背景噪音訊號，通常
為高頻帶背景噪音訊號訊號能量所分佈，經
BSWPD 分頻出的19th 到 24th 關鍵子頻帶屬
 10
1.3     1
( ) 3        LF
5        MF 2
LF
MF
Fs
ξ
δ ξ ξ
ξ
≤ ≤

= ≤ ≤
 ≤ ≤
，  (26) 
式(26)所示為各頻帶比值與所對應的臨界值
作比較， 
if  ( , ) ( )
     ( , ) 1     speech-present in  subband
else
    ( , ) 0     speech-absent in  subband
end
r
th
subband
th
subband
S m
I m
I m
ξ δ ξ
ξ ξ
ξ ξ
>
=
=
  (27) 
若各頻帶的比值大於所對應的臨界值時，其
可表示為語音存在之頻率(speech-presence 
frequency)；反之，若各頻帶的比值小於所
對應的臨界值時，其可表示為噪音存在之頻
率(speech-absence frequency)。 
雖 然 是 一 個 語 音 為 主 的 音 框
(speech-dominated frame), 但其僅是表示以
整個音框或所有 24 個子頻帶來說，語音存
在的能量大於噪音的能量，但並不是所有頻
帶都表示語音訊號存在，有些頻帶仍以噪音
訊號為主，因此需以頻帶噪音程度作整體噪
音預估及更新的資訊。 
各音框在各個頻帶的語音存在之表示
(Indication of speech-present)，其表示如下 
( , ) ( ) ( , )subbandI m VAD m I mξ ξ= ⋅ ， (28) 
此式(28)表示各頻帶的語音存在性與音框的
語音偵測結果及各頻帶的語音存在機率有
關。 
由於 ( , )subbandI mξ 主要由頻譜能量為基礎的
參數所估計出，再加上有頻譜上的 ( )VAD m
補償，可避免因噪音程度突增而計為語音成
分的可能性。 
最後，各頻帶的想鄰間的語音存在機率
( , )p mξ (speech-presence probability)可透過
一階遞迴計算出 
( , ) ( , 1) (1 ) ( , )p pp m p m I mξ α ξ α ξ= ⋅ − + − ⋅ ，  (29) 
此 pα 是一個平滑的常數，式(29)也說明其語
音存在機率在相鄰音框間的關係。 
 
 
噪音頻譜能量之更新 
為準確且連續地更新噪音頻譜，使用式(29)
語音存在機率估計，我們提出一個時變且頻
率相關的平滑參數如下 
( , ) (1 ) ( , )s d dm p mα ξ α α ξ= + − ⋅ ，  (30) 
此 dα 為一個常數，而 ( , )s mα ξ 使用範圍為
( , ) 1d s mα α ξ≤ ≤ 。 
最後, 使用式(30)的時變且頻率相關的平滑
參數 ( , )s mα ξ ，其各頻帶的噪音頻譜更新如
下 
2
( , ) ( , ) ( , 1)
            (1 ( , )) ( , )
D s D
s
m m m
m Y m
σ ξ α ξ σ ξ
α ξ ξ
= ⋅ −
+ − ⋅
% %
，  (31) 
此 ( , )D mσ ξ% 為噪音頻譜能量的預估。 
因此，首先經由式(24)即時求得頻譜的局部
最小值，以快速求出 ( , )
r
S mξ 的比值。由式
(28)決定各頻帶的語音存在性，並透過式(29)
的一階遞迴更新語音存在機率，進一步地使
用式(30)計算時變且頻率相關的平滑參數。
最後，利用式(31)即時更新噪音頻譜能量的
預估。 
 
III. 可調式(adjustable)小波係數閥值 
1) 基於頻帶噪音程度以進行微調 
由於傳統的小波閥值為基礎之語音增強技
術，假設在各頻帶內的小波閥值皆相同，因
此在作閥值運算(thresholding process)時，易
產生殘餘噪音。為了進一步改良以小波閥值
為基礎的語音增強架構，我們提出一個具可
調式的小波係數閥值，其隨時間及頻率資訊
作適應性地調整，以降低音樂性殘餘噪音產
生。 
一般在各子頻帶小波係數閥值 (wavelet 
coefficient threshold)可定義如下[12]-[13]， 
2 log( )D Nλ σ= ⋅ ⋅ ，  (32) 
其中 / 0.6745D MADσ = ，表示背景噪音程
度；MAD 為平均絕對離差(mean absolute 
deviation)。因此當噪音程度大時，可得知小
波係數閥值也隨之增大。若對於一個具高斯
 12
反之，若當為無聲語音的音框時，其式(34)
的小波係數閥值可改成 
( , ),   if low-band 
'( , ) ( , ),  otherwise 
L
H
m k
m
m
β λ ξλ ξ β λ ξ
⋅ ∈
= 
⋅
(38) 
此 Lβ 及 Hβ 分別表示低頻及高頻的調整係數
( 1.2Lβ = , 0.05Hβ = )。 
通常在無聲語音音框，在高頻帶具有的重要
資訊較低頻帶多，因此，藉由調降高頻帶的
小波係數閥值達到保留高頻帶的小波係數
的效果，如式(38)調整 0.05Hβ = 。反之，在
式(38)中調整 1.2Lβ = 以調高低頻帶的小波
係數閥值，進一步抑制低頻帶的訊號。 
3) 基於感知增益因子 (perceptual gain 
factor)的微調 
為避免因過度調高小波閥值而造成殘餘噪
音的產生，我們將採用一個感知增益因子作
為改善最終的感知音質。因此，在原式(37)
及式(38)中考慮人耳感知模型下，其時間頻
率相關的小波係數閥值可進一步更改如下： 
''( , ) '( , ) ( , )
                ( , )
ptsnr
pecp
m m g m
g m
λ ξ λ ξ ξ
ξ
= ⋅
⋅
 (39) 
( , )( , ) 1 1 max 1,  0( )
D
pecp
cb
m
g m
T
σ ξξ ξ
   
= + −      
. (40) 
此 ( , )pecpg mξ 為感知增益因子[20]。 ( )cbT ξ 為
式(8)所求出的臨界頻帶的聽覺遮蔽門檻值。 
從式(40)可看出，若殘餘噪音 ( , )D mσ ξ 大於
各關鍵子頻帶上的聽覺遮蔽門檻值 ( )cbT ξ ，
將藉由降低 ( , )pecpg mξ 以避免殘餘噪音對感
官聽覺的影響。反之，若殘餘噪音 ( , )D mσ ξ
小於各關鍵子頻帶上的聽覺遮蔽門檻值
( )cbT ξ 時，因人耳感知無法察覺其殘餘噪音
的存在，因此就不用在改善最終的感知聽
覺。 
五、 結果與討論 
Due to that VAD approach is important in the 
proposed wavelet-based speech enhancement, 
a number of experiment are be evaluated. To 
set up the noisy signal for test, we add the 
prepared noise signals to the recorded speech 
signal with different SNRs range from −5 dB 
to 10 dB. Noise signals extracted from the 
Noisex-92 database [18] were artificially 
added to clean speech signals with various 
SNRs. Of the various noises available on the 
NOISEX database, white noise, factory noise 
and vehicle noise are selected as speech 
containment. 
 
5.1. The evaluation of VAD 
In order to compare with other VADs, we 
introduce three criteria: 1) the probability of 
correctly detecting speech frames cSP  is the 
ratio of the correct speech decision to the total 
number of hand-labeled speech frames. 2) the 
probability of correctly detecting noise frames 
cNP  is the ratio of the correct noise decision to 
the total number of hand-labeled noise frames. 
3) the probability of false error fP  is the 
ratio of the false speech decision or false noise 
decision to the total hand-labeled frames. The 
experimental results are summarized in Tables 
I~III. Under a variety of SNR's, the three 
criteria of proposed algorithm are compared 
with those of the VADs specified in the ITU 
standard G.729B [25], other entropy-based 
VAD proposed by Shen et al. [21] and 
HOS-based VAD [26]. It is shown that the 
proposed VAD algorithm obtains a better 
performance than those of others. The 
proposed VAD has superior performance to 
others particularly in low SNR, even though 
the result of Shen’s VAD is comparable to 
proposed VAD in high SNR. Fig. 7 shows the 
VAD result of the proposed algorithm on the 
noisy speech signal "May-I-Help-you" under 
variable-level of noise. It is founded that the 
VAS of the proposed algorithm can correctly 
extract speech segments especially for 
unvoiced segment /H/ occurred at /Help/ 
sentence in Fig. 7(b). Conversely, in Fig. 7(c) 
the VAS of standard G.729B performs fail 
during high variable-level of noise segment 
and unvoiced segment. 
 
5.2. The evaluation of speech 
enhancement 
The performance of the proposed speech 
enhancement system based on time-frequency 
adapted WCTs is evaluated in various adverse 
conditions and compared to those of the others 
[5, 6]. It has been shown by experiments that 
 14
Table I Performance comparisons of the probability of correctly 
detecting speech frames for three noise types and levels. 
 
 
Table II Performance comparisons of the probability of correctly 
detecting noise frames for three noise types and levels. 
 
 
Table III Performance comparisons of the probability of false error 
for three noise types and levels. 
 
 
Table IV MOS results of the listening test. 
 
 
 
Table V The average SegSNR results of speech enhancement under 
various noisy conditions. 
 
 
Table VI The average SegSNR results of speech enhancement under 
the variable-level of noise. 
 
 
六、 參考文獻： 
[1] D.L. Donoho, “De-Noising by 
Soft-Thresholding,” IEEE Trans. Inform. Theory, 
vol. 41, pp. 613–627, 1995. 
[2] D.L. Donoho and I.M. Johnstone, “Ideal Spatial 
Adaptation by Wavelet Shrinkage,” Biometrika, 
vol. 81, pp. 425–455, 1994. 
[3] I.M. Johnstone and B.W. Silverman, “Wavelet 
Threshold Estimators for Data with Correlated 
Noise,” J. Roy. Statist. Soc. B, vol. 59, pp. 
319–351, 1997. 
[4] B. Vidakovic, C. Lozoya, “On time-dependant 
wavelet denoising,” IEEE Trans. Signal Process. 
vol. 46, pp. 2549–2554, 1998. 
[5] S.H. Chen and J.F. Wang, “Speech 
Enhancement Using Perceptual Wavelet Packet 
Decomposition and Teager Energy Operator,” 
Journal of VLSI Signal Processing, vol. 36, pp. 
125-139, 2004. 
[6] M. Bahoura and J. Rouat, “Wavelet Speech 
Enhancement Based on the Teager Energy 
Operator,” IEEE Signal Processing Lett., vol. 8, 
pp. 10–12, 2001. 
[7] B.H. Juang, “Recent Developments in Speech 
Recognition Under Adverse Conditions,” in 
Proceedings of Int. Conf. Spoken Language 
Process ’90, pp. 1113–1116, 1990. 
[8] J.H. Chen and A. Gersho, “Adaptive 
Postfiltering for Quality Enhancement of Coded 
Speech,” IEEE Trans. Speech and Audio 
Processing, vol. 3, pp. 57–71, 1995. 
[9] P. Aarabi and G. Shi, “Phase-based 
dual-microphone robust speech enhancement,” 
IEEE Trans. Syst., Man, Cybern. B, Cybern., vol. 
34, no. 4, pp.1763-1773, 2004. 
[10] W.L.B. Jeannes, P. Scalart, G. Faucon, and C. 
Beaugeant, “Combined noise and echo reduction 
 16
Enhancement,” International Conference on 
Asian Languages Processing 2009  (IALP2009), 
pp.114-117, Dec 7-9, 2009, Singapore. 
[5] K. C. Wang, T. L. Hou, C. L. Chin, “Voice 
Activity Detection Using Spectral Entropy in 
Bark-Scale Wavelet Domain,” Proceedings of the 
21st Conference on Computational Linguistics 
and Speech Processing, pp.385-398, 1-2 
September 2009 in Taichung, Taiwan. 
[6] K. C. Wang, C. L. Chin and Y. H. Tsai,, "Voice 
Activity Detection based on Combination of 
Weighted Sub-band Features using 
Auto-Correlation, " accepted by DiSS-LPSS 2010, 
September 25-26, 2010, in Tokyo, Japan. 
[7] K. C. Wang, “Detection of Speech Presence 
Based on Combination of Multiple Features 
through Sigmoid Function (2010EDP7207),” 
submitted to IEICE Trans. on Fundamentals, Aug., 
2010.  
[8] K. C. Wang, “VAD Algorithm Using the 
Combination of Weighted Auto-Correlation 
Function in Wavelet Domain (Temporary ID: 
20100810004),” submitted to IEICE Transactions 
on Information and Systems, June, 2010. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 18
 
圖 1 研討會會場 
 
本次研討會有來至新加坡、大陸、日本、印度、韓國、馬來西亞、越南、泰國、澳洲、
德國、香港、科威特、愛爾蘭及台灣等學術單位，業界只有日本 Hitachi，可能是因為只侷
限在"亞洲地區的語言"，所以只見到一間公司的蹤影，而同樣來自台灣的有五篇，二篇是
ITRI，其餘的是來自國防大學、大同大學及成功大學。 
在研討會中許多論文都是在討論各個國家的語文(Natural Language Processing, NLP)，其
討論的題目有有建立 POS tagging、語義的分析、自動詞句及詞義的擷取、疑問句及肯定句
的分析…等等，這些題目上述參與的國家至少都有一篇在探討各自國定的語言，所以我聽
到了很多各地的語言。而其使用的方法大多是 machine learning，其技術不外乎是 HMM 
model、SVM、MLN、HNC…等。我對大同大學那篇論文蠻印象深刻的－Repetition in Mandarin 
Interaction : A case study on TV shopping Channels in Taiwan，因為當這篇報告完後的討論十分
踴躍，尤其是新加坡本地人，因為新加坡人的台語是從大陸潮州那傳過來的，所以提問者
也都會提到一些台語，就有人問到華人地區的台語－大陸、台灣、新加坡可否互相轉換，
而作者說只要把各地的拼音及字根收集整理，是可以建立一個 model 做轉換，但是否有其
必要性呢?因為，其實這些地方的台語並沒有相差太多，基本上是大家都聽得懂，所以並沒
有一定要做轉換。那我在報告時有二個人提問，有一個是問說我提到的 Low Band 及 high 
Band 的定義為何，另一個是問到說我實驗中的樣本有漢文及英文，那是否有做漢文及英文
的分類。 
 
 
 
 
 20
 
 
 
 
 
 22
 
 
 
 
 
 1 
出席國際學術會議心得報告 
計畫編號 NSC 98-2221-E-158 -004 
計畫名稱 具人聲特性的噪音頻譜預估以完成即時語音增強系統之研究 
出國人員姓名 
服務機關及職稱 王坤卿—實踐大學資訊科技與通訊學系, 助理教授 
會議時間地點 時間:  2009年 12月 7日~ 2009年 12月 9日 地點:  Holiday Inn Atrium, Singapore 
會議名稱 International Conference on Asian Language Processing (IALP 2009) 
發表論文題目 A Wavelet De-noising System Using Time-Frequency Adaptation for 
Speech Enhancement Adaptation for Speech Enhancement 
 
一、 參加會議經過 
本次參加 2009 年 12 月 7 日至 2009 年 12 月 9 日在新加坡 Holiday Inn Atrium 
Singapore 所舉行的 IALP2009 研討會，此研討會分成 11 個 sessions -Chunking, POS, SEG, 
NER、Speech Processing 1、Machine Translation & Multilingualism 1、Information Retrieval 
1 、 Machine Translation & Multilingualism 2 、 Corpus Linguistics & Computational 
Linguistics、NLP Applications、Parsing、Information Retrieval 2、Information Extraction、
Speech Processing 2。而此行主要參與的是 Speech Processing 1，並發表論文 A Wavelet 
De-noising System Using Time-Frequency Adaptation for Speech Enhancement Adaptation 
for Speech Enhancement。  
 
此研討會是由 COLIPS（Chinese and Oriental Languages Information Processing 
Society） 以及 IEEE Singapore Computer Chapter 所主辦。IALP 此研討會的主要目的
在於提供一個論壇讓研究語音技術的學者從不同語言領域來探討亞洲地區的語言。
第一屆的 IALP於 1986 年在新加坡舉行，原本研討會的名稱為" International Conference 
on Chinese Computing (ICCC)"，而在 1988 年後就更名為 IALP。根據主辦單位所提供
的資訊此次研討會共有 122 篇論文投稿，接受了 40 篇。下圖 1 為研討會會場。 
 3 
二、 與會心得 
 
事實上，此次的研討會中有許多的論文研究都是出自語文學院，或者是語文學
院加上工學院，這類的論文大多是介紹當地語文的特性，如語義預測、語法的規則、
句子的產生…等等，或是各地語文的比較等等，沒用到太多的方法或技術可言。下
列所摘錄的 paper 為個人比較有興趣的題目： 
 An Articulation Training System with Intelligent Interface and Multimode Feedbacks to 
Articulation Disorders ： 本篇論文蠻有趣的，他們提供一個 3D 發音訓練系統，
使用者說出一個字或是句子，系統可以利用臉部辨識及聲音辨識來糾正使用者
的發音，並指導嘴形等等，現場有開放 Demo，但目前只限定於輸入中文聲音。 
 Analysis and selection of prosodic features for language identification：這篇論文是將
12 種語言中的押韻利用 SVM 的方法做分類，我對如何收集 12 種語言較感興
趣，但作者似乎是誤會我的提問，反而在介紹 SVM。 
 Foxinfo1.0: A Chinese Topic-oriented Search Engine：這篇論文是建置一個 Google 
like 的中文 search engine，其搜尋方法為輸入文件的 topic（query by topic），而其
資料庫為中文文件資料庫。其實說穿了他們是用 text serach，就有人問說你們是
Google like，但為什麼實驗中沒有跟 Google 比較呢？作者回答他們主要是 focus
在中文文件資料庫，而學習的對象是 Google。現場的 demo 其搜尋的回覆時間
很快，但不知其資料庫多大…等背景資訊。 
 Automatic User Preferences Acquirement in Chinese Commercial Web Sites With NLP 
and DM Techniques：本篇論文是先在中文的商業網頁中擷取出 metadata，之後使
用 NLP（Natural Language Processing）及資料探勘（Data Mining）的方法自動的
找出使用者的需求及喜好，如此便能更精準的掌握市場脈動及顧客的愛好。 
 An Experimental Study of Vietnamese Question Answering System：這篇論文所建置
的系統為 QA system，也就是使用者輸入問題後，搜尋引擎用語音回答的方法將
結果輸出，這套系統是針對越南文所設計的，也是越南第一套自動 QA 系統，
而此類的系統 Yahoo（Yahoo Answers）、Google（Google Question，僅提供俄羅斯
文，我有提問為什麼只有俄羅斯文，但作者不很清楚）都有建置。因為是越南
文所以現場的 Demo 我也不知道回答的正不正確。 
 
綜觀本次的研討會，利用語音辨認、語義分析等相關語音技術與其它方面的結
合應用可以讓人機介面更 friendly，必然可以創造加乘的效果，許多的應用若能讓使
用者用最簡單的方式來操作就更可以讓使用者有購買的想法。 
 
 
 
 5 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 7 
 
 
 
 
 
 
 
98年度專題研究計畫研究成果彙整表 
計畫主持人：王坤卿 計畫編號：98-2221-E-158-004- 
計畫名稱：具人聲特性的噪音頻譜預估以完成即時語音增強系統之研究 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 3 2 100%  
研究報告/技術報告 0 0 100%  
研討會論文 4 4 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 1 1 100%  
博士生 1 1 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
電子報、網站 0  項 
目 計畫成果推廣之參與（閱聽）人數 0  
