1 
行政院國家科學委員會專題研究計畫成果報告 
以線掃瞄為基之光碟片自動光學檢測系統研究 
The Study of a Linescan-based Automatic Optical 
Inspection System for Optical Discs 
計 畫 編 號：NSC 95-2221-E-216-025 
執 行 期 限：95 年 08 月 01 日至 96 年 07 月 31 日 
主 持 人：邱奕契 中華大學機械工程學系 
計畫參與人員：蔡孟儒、李韋辰 中華大學機械與航太工程研究所 
 
一、中文摘要 
光碟產業使用許多價格昂貴的自動光
學檢測(Automatic Optical Inspection • AOI)
設備以確保光碟品質，然而多數 AOI 設備
都是仰賴進口。除此之外，並沒有任何一
套設備可以將瑕疵品進一步做分級的工
作。有鑑於此，本研究發展一套以線掃瞄
取像技術為基礎之光碟片瑕疵偵測與分級
系統，冀望能夠降低光碟製造業者購置
AOI 設備的成本，以提高產業的競爭力。 
為了達成上述目標，本研究分兩階段
進行。第一階段為硬體設備的規劃，其首
要目標是將出現在光碟上的所有瑕疵完整
且真實的呈現出來。本階段是本研究成敗
的關鍵，因為如果影像中所出現的瑕疵失
真或不完整，則後續的工作將變得毫無意
義可言。儘管光碟片屬於高反射體，本研
究採用亮場成像原理，同時攫取光碟片正
反兩面的影像以節省時間。本研究所建構
之硬體設備是由兩台線掃瞄攝影機、兩塊
影像攫取卡、兩台線性光纖光源、一個步
進馬達驅動之旋轉平台所組成。第二階段
是利用影像濾波、梯度分析、影像分割、
形態處理、物件分析、邊界偵測、及特徵
抽取與分析等影像處理技術，發展一套瑕
疵檢測程式，將瑕疵分割出來並予以分
類。實驗顯示，本研究所發展之系統可成
功檢查出光碟表面上的刮痕、流星、針孔、
氣泡、條紋、及沾污等瑕疵。就 P4 3.0G 之
個人電腦及 2048 pixels 解析度之線掃瞄攝
影機而言，在 29 µm 及 117 µm 空間解析度
下，檢測時間分別約需 0.765 秒及 0.172 秒。 
關鍵詞：自動光學檢測、瑕疵偵測、分類、
光碟片、亮場成像 
Abstract 
Optical disc industry uses many automatic 
optical inspection (AOI) systems to ensure their 
products defect-free. However, most of them are 
imported and expensive. Besides, none of them is 
capable of providing grading function for the 
defected discs. So the object of the research is to 
develop a flaw detection and classification 
system to reduce the cost for purchasing AOI 
equipment and increase the competitiveness.  
To achieve the above-mentioned objectives, 
a two-step approach is adopted. The first step is 
to establish an apparatus to acquire images that 
will truly show all the defects on the surface of 
optical discs. This step is crucial to the success 
of the study, because if the captured defects are 
incomplete or camera cannot perceive defects at 
all, the developed system will be useless. Despite 
the high reflecting surface of the optical discs, 
we apply bright-field technique to capture images 
of both sides simultaneously to reduce inspection 
time. The developed imaging system consists of 
two line-scan cameras, two image grabbers, two 
line-type fiber-optic light sources, and a rotation 
stage driven by a stepping motor. The second 
step is to develop a flaw-detection program using 
image-processing techniques such as filtering, 
segmentation, blob analysis, edge detection, 
feature extraction and analysis, etc. to detect and 
classify defects. The experimental results show 
that the developed AOI system is successful in 
inspecting optical discs having specular surfaces 
for defects such as scratches, comets, pinholes, 
bubbles, streaks, etc. For a P4 3.0G PC with a 
2048 pixels line-scan camera, if the desired 
spatial resolution is 29 µm, it takes 0.765 seconds 
to complete the inspection. If the desired 
resolution is 117 µm, it takes only 0.172 seconds. 
Keywords: AOI, Flaw Detection, Classification, 
Optical Disc, Bright-field Imaging 
3 
LA-150UE）進行照明。 
此外，本研究特別將攝影機放置在三
軸平移台上，以方便使用者手動進行攝影
機位置的微調。平移台之精度為 10µm，可
微調之範圍為 25 mm。 
 
3.2 照明方式 
根據光源、攝影機及待檢測物之相對
位置、以及所獲得影像為暗或亮，檢測方
式可分為亮場檢測（Bright Field Inspection）
與暗場檢測（Dark Field Inspection）兩大
類。請參考圖一(a)，暗場檢測是利用光線
反射的原理，當入射光照射在光碟片表面
時，由於光碟片具有高反射率的特性，光
線會依入射角度產生反射。如果反射光線
無法進入鏡頭，則攝影機所取得之影像將
呈現全黑的狀態，因此稱為暗場。然而當
入射光照射到瑕疵時，由於瑕疵具有不平
整的表面，將迫使光線反射路徑改變，導
致部份反射光進入攝影機鏡頭，因此在暗
影像中所呈現的亮點即為瑕疵。一般而
言，暗場檢測適用於高反射物體之檢測。 
請參考圖一(b)，亮場檢測是入射光照
射在光碟片之表面，經反射後如果反射光
直接進入攝影機之鏡頭，使得感知器接收
最大的光線，因此影像將呈現全白的狀
態，因此稱為亮場。當入射光照射到瑕疵
時，反射角度將偏離正常路徑，使得反射
光線無法順利進入攝影機之鏡頭，造成瑕
疵於影像中呈現暗點。一般而言，亮場檢
測適用於透明物體之檢測。 
前段製程之檢測物為透明體，因此對
於瑕疵的檢測方式應採用亮場檢測。反
之，後段製程之檢測物為具有高反射率之
非透明體，瑕疵檢測方式理應採用暗場檢
測。然而實驗結果顯示，對於光碟表面瑕
疵之檢測，無論是前段製程或是後段製
程，使用亮場檢測都可獲得不錯的效果。 
 
  
(a) (b) 
圖一、亮場及暗場檢測之差別：(a) 暗場檢
測示意圖；(b) 亮場檢測示意圖。 
圖二、光碟表面瑕疵檢測流程圖。 
 
圖三、參數設定對話框。 
3.3 瑕疵檢測方法與流程 
光碟表面瑕疵檢測流程如圖二所示，
包含檢測參數設定、影像攫取、瑕疵檢測、
瑕疵分類及檢測結果顯示等五個步驟。第
一步是參數設定，有鑑於客戶對品質之要
求有所不同，廠商對於瑕疵品的判斷標準
也不盡相同，因此有必要提供一個方便的
使用者介面，讓使用者可根據客戶的要求
調整瑕疵檢測參數。其次對攝影機位置進
行校正，以確定取像區域正確。完成上述
兩個步驟後即可開始進行檢測。檢測時首
先透過 RS232 通訊介面，控制旋轉機構轉
動光碟，搭配線掃瞄攝影機攫取待測光碟
影像。完成取像，接著選擇適當的演算法，
對待測影像進行瑕疵的偵測。偵測出瑕疵
後，接下來便是將瑕疵分類。瑕疵分類的
目的在於追溯瑕疵產生的源頭，以了解那
個製程出了問題。除此之外，也可根據瑕
疵的類型，將有問題的光碟進行再分級。 
 
3.3.1 參數設定與位置校正 
檢測前必須對檢測系統進行參數設定
及攝影機位置的校正。有些廠商只針對資
料讀取區進行檢測，忽略其他不影響資料
存取穩定性之印刷區，因此檢測前須先進
行相關參數設定，若檢測參數有所變更
時，操作人員可由圖三所示之參數設定對
話框輸入檢測範圍。程式中預設之檢測範
5 
 
圖七、當校正片上之圓與直線(黑色虛線)
與系統繪製之圓形及直線尺規(青色實線)
重合時，代表攝影機位置之校正已完成。 
 
3.3.2 瑕疵偵測 
瑕疵偵測的目的是要找出影像中可能
是瑕疵的區域。如前所述，本研究所採用
之亮場照明方式是將線型光源傾斜一個角
度，因此攝影機視野內的每一個點所接收
之光線並不相同。導致攫取所得之影像，
即使是同一列(row)上的點也會有不同的灰
階值。此現象使得傳統以面為基礎或一個
區域使用一個閥值的影像分割方式，並不
適合用來分割線掃瞄影像。 
線掃瞄影像上同一列的每一個像素點
雖然會有照明不均的現象，但是同一行
(column)上的每一個像素點所接受到的光
線理論上應該是相同的。本研究就是根據
此一原理，發展以閥值線為基礎的四種瑕
疵偵測法，包括平均灰階值瑕疵檢測
法、灰階標準差瑕疵檢測法、平均梯度
瑕疵檢測法、以及多閥值瑕疵檢測法。
這四種方法都是以影像中的行為處理單
元，為每一行設定一個閥值，構成所謂的
閥值線（Threshold line）。再以此閥值線對
線掃瞄影像逐列進行分割，以達到瑕疵偵
測的目的。從文獻可知[1-2]，灰階標準差
法是上述四種方法中最適合者。因此，以
下僅就這個演算法做介紹。 
一般說來，灰階異常的像素點就是瑕
疵點。所謂的“灰階異常”，指的是其灰階
值與正常灰階值的差異超出某個事先設定
的門檻值。但是，如何界定灰階值是否正
常？根據統計學上對標準差的研究發現，
若實驗數據屬於常態分佈（亦即屬於高斯
分佈），則大約會有 68%以上的數據與該
組數據的平均值的差距會在一個標準差以
內。因此，如果影像中灰階異常的區域（瑕
疵），在影像中屬於少數（32%以下），
則可藉由灰階標準差的計算，得到大部分
灰階正常像素與平均值的差異。換言之，
當灰階值與平均灰階值的差在一個標準差
以內者，可視為正常；反之，則視為異常。 
灰階標準差法首先根據統計學上標準
差的觀念，設定上控制線及下控制線。接
下來，將各像素的偏差值（deviation）與灰
階標準差（standard deviation）做比較，以
判定各像素之灰階值是否正常。令 f 代表待
測影像，以灰階標準差法檢測時首先利用 
(1)及(2)式計算各行的灰階平均值及灰階
標準差。例如，Avg(x)及 σ(x)分別代表第 x
行的平均灰階值及灰階標準差；接著利用 
(3)及(4)式建構上下控制線（閥值線）；最
後再將影像中的每一個點代入(5)式即可將
影像分割。 
∑
=
=
H
y
yxf
H
xAvg
1
),(1)(  ; for x = 1,W  (1) 
( )
H
xAvgyxf
x
H
y
∑
−
=
−
=
1
0
2)(),(
)(σ       (2) 
σσ TxxAvgxTup ++= )()()(          (3) 
σσ TxxAvgxTdw −−= )()()(        (4) 


 <>
=
otherwise
xTyxfxTif
yxI updwR
    ; 552
)(),()(    ; 0    ),(  (5) 
其中 H 為影像的高度，Tσ為閥值（預設值
為 5）。經過上述處理所得到之影像 IR 為
黑白影像，其中黑色（灰階值 0）代表背景；
白色（灰階值 255）則代表異常之像素。 
 
3.3.3 瑕疵分類與光碟分級 
在光碟的生產過程中，每道製程所可
能產生的瑕疵不同，因此若能將檢測出的
瑕疵分類，則可得知那個製程發生問題以
及出現甚麼問題。除此之外，根據瑕疵的
類別、數量及出現之位置，也可以進一步
將被判定為瑕疵品的光碟分級出售。 
經由瑕疵偵測後，可能是瑕疵的區域
已被偵測出，接下來便是將瑕疵做進一步
的分類。瑕疵分類的方法，主要是依據瑕
疵的幾何特徵、分佈位置及灰階特性來進
7 
果。首先就完成染料塗佈製程之 DVD 樣
本進行取像及檢測說明。此類樣本屬於完
成第二製程之 DVD，其結構僅包括透明基
片與染料層。一般說來，出現在此類樣本
的瑕疵包括染料塗佈異常及基片表面刮傷
等表面瑕疵。此類樣本屬於半透明物，瑕
疵可能出現在光碟片的正面或反面。為了
探討那一面比較容易檢測出瑕疵，本研究
針對染料面及資料讀取面進行檢測。結果
顯示，並非對任意一面取像都能攫取到所
有的瑕疵。例如，當瑕疵出現在染料面，
則必需對染料面取像才能看得到瑕疵；反
之，如果瑕疵出現在資料讀取面，則必需
對資料面取像才能看到瑕疵。圖十及圖十
一所示為對染料面及資料面進行取像及檢
測之結果，右圖為重組後之原始光碟影
像，左圖為瑕疵檢測之結果，其中以紅色
標示者為檢測出之瑕疵。 
對於完成 Bonding 之 DVD 樣本，由於
已完成染料塗佈、反射層濺鍍、保護膠塗
佈及 Bonding 等程序，樣本中可能出現各
式瑕疵，而且表面具有高度反射性。針對
此類樣本，本研究是以亮場照明的方式取
像。實驗結果顯示，無論是染料異常或刮
傷，在亮場照明下均無所遁形。然而，由
於此類樣本具有多層次的結構（各層具有
不同的特性），因此攫取所得之影像中有
些會出現波型紋路。圖十二及圖十三所示
為取像及檢測之結果，右圖為重組後之原
始光碟影像，左圖為瑕疵檢測之結果，其
中以紅色標示者為檢測出之瑕疵。 
 
 
圖十二、完成 Bonding DVD 樣本之取像及
檢測結果：右圖為重組後之原始光碟影
像；左圖為檢測結果，以紅色標示者為檢
測出之瑕疵。 
 
圖十三、完成 Bonding DVD 樣本之取像及
檢測結果：右圖為重組後之原始光碟影
像；左圖為檢測結果，以紅色標示者為檢
測出之瑕疵。 
 
4.2 討論 
在影像解析度方面，受限於現有之線
掃瞄攝影機其最高解析度為 2048 pixels，
因而最高解析度僅可達 29 µm/pixel。若要
攫取更細微的瑕疵影像，則必需採用更高
解析度的攝影機。在瑕疵偵測方面，為了
解決影像在水平方向照明不均的問題，本
研究提出四種以閥值線為基礎之瑕疵偵測
法，包括平均灰階法、灰階標準差法、平
均梯度法及多閥值法。經過幾項指標的評
估後，本研究採用灰階標準差法，此方法
適用於檢測完成染料塗佈之半透明膠片及
完成 Bonding 之 DVD 樣本。 
在瑕疵完整性方面，對於完成染料塗
佈之半透明樣本而言，瑕疵可能同時顯現
在染料面及資料面上。實驗顯示，有些瑕
疵從資料面取像所得到的瑕疵較完整。對
完成 Bonding 之樣本而言，刮傷與染料異
常等瑕疵均可順利的被檢測出來，然而有
些影像內會出現如圖十三右所示之波紋。
這些波紋利用瑕疵偵測法處理後在瑕疵影
像中會以雜訊般的小點出現。由於本研究
在後續之影像處理過程中，會再利用尺寸
濾波（size filtering）將面積太小的瑕疵移
除，因此並不會影響檢測結果。 
本研究所使用之「灰階標準差瑕疵檢
測法」是建構在瑕疵數量少於 1/3 的基礎
上。因此當具有瑕疵之像素點過多時，有
些瑕疵是會被忽略的（仔細觀察瑕疵檢測
結果即可發現此一問題），換言之，本研
究所使用之演算法仍有許多改善的空間。
9 
Support Vector Machines,” Journal of Food 
Engineering, Vol. 66, No. 2, pp. 137-145, 
2005. 
[7] 
 
X. Zhang, C. Krewet, and B. Kuhlenkotter, 
“Automatic Classification of Defects on the 
Product Surface in Grinding and Polishing,” 
International Journal of Machine Tools and 
Manufacture, Vol. 46, No. 1, pp. 59-69, 
2006.  
[8] 
 
莊富傑，“導線架瑕疵之偵測與分類使用類
神經網路”，碩士論文，中華大學機械與航
太工程研究所，1999。 
[9]  陳冠字，“紋理分析在彩色影像分類上之應
用”，碩士論文，中華大學機械與航太工程
研究所，2002。 
 
Selecting an Appropriate Segmentation Method
Automatically Using ANN Classiﬁer
Yih-Chih Chiou and Meng-Ru Tsai
Institute of Mechanical and Aerospace Engineering, Chung Hua University,
Hsinchu, Taiwan, 30012, R.O.C.
chiou@chu.edu.tw
Abstract. In general, we can easily determine the manufacturing step
that does not function properly by referring to the ﬂaw type. However, a
successful segmentation of ﬂaws is the prerequisite for the success of the
subsequent ﬂaw classiﬁcation. It is worth noticing that, diﬀerent segmen-
tation methods are needed for diﬀerent types of images. In the study, a
mechanism that is capable of choosing a proper segmentation method
automatically has been proposed. The mechanism employed artiﬁcial
neural networks to select a suitable segmentation method from three
methods, i.e., Otsu, HV standard deviation, and Gradient Otsu. The se-
lection is based on the four features extracted from an image including
standard deviation of background image, variance coeﬃcient, the ratio
of the width to height of both foreground and background histograms.
The results show the success of the proposed mechanism. The high seg-
mentation rate reﬂects the fact that the four carefully selected features
are adequate.
Keywords: Segmentation, Feature Extraction, Flaw Detection, Flaw
Classiﬁcation, BPN Network.
1 Introduction
Flaw detection is an important procedure in the quality assurance of products.
In general, by referring to the defect type, we can easily determine the manu-
facturing step that does not function properly. Hence, the ultimate goal of ﬂaw
classiﬁcation is to identify each ﬂaw type such that the sources of ﬂaws can
be identiﬁed and the manufacturing parameters can be adjusted accordingly.
However, a successful segmentation is the prerequisite for the success of the sub-
sequent ﬂaw detection and classiﬁcation. Segmentation is a process to separate
desired ﬂaws from background. Thresholding is the most commonly used ﬂaw
detection method [1], [2], [3], [4], [5]. Several researchers [3], [6], [7], [8], [9] have
suggested the use of image gradient to detect ﬂaws. On the other hand, a num-
ber of authors have applied standard deviation [9], [10], [11] to discover ﬂaws.
It is worth noting that most segmentation methods are sensitive to noise, illu-
mination variance, object shape and size, grayscale variance of foreground and
background, etc. In addition, diﬀerent types of ﬂaws need diﬀerent segmentation
methods.
H.G. Okuno and M. Ali (Eds.): IEA/AIE 2007, LNAI 4570, pp. 195–206, 2007.
c© Springer-Verlag Berlin Heidelberg 2007
Selecting an Appropriate Segmentation Method Automatically 197
(a) wrinkle (b) greasy stain (c) strip scratch (d) line scratch (e) dotted scratch
(f) pinhole (g) protrusion (h) dent (i) bubble (j) large stain
(k) small stain (l) glue particle (m) broken warp (n) broken woof (o) ﬁsh eye
Fig. 3. Segmentation results of the ﬁfteen types of ﬂaws as shown in Fig. 1 using HVStd
method. It is evident that HVStd is good for some ﬂaw types, but quite bad for others.
(a) wrinkle (b) greasy stain (c) strip scratch (d) line scratch (e) dotted scratch
(f) pinhole (g) protrusion (h) dent (i) bubble (j) large stain
(k) small stain (l) glue particle (m) broken warp (n) broken woof (o) ﬁsh eye
Fig. 4. Segmentation results using GradOtsu method. It is clear the method is suitable
for segmenting wrinkle and small defects. For large defects, only their proﬁles are shown.
Selecting an Appropriate Segmentation Method Automatically 199
2.1 Segmentation Methods
In this study, three segmentationmethods, includingOtsu,HVStd, andGradOtsu,
were used to segment images. Aside from Otsu method, the other two methods are
described in detail as follows:
(1) HVStd: The method ﬁrst calculates grayscale means and standard devia-
tions for each row and column and then uses the derived information to generate
a threshold value for segmentation. Let IO be an original image, IO(i,j) be the
grayscale value of the pixel located at column i and row j. The grayscale mean
for each column and row are given by
μcol(i) =
1
H
H∑
j=0
IO(i, j); for i = 1,W (1)
μrow(j) =
1
W
W∑
i=0
IO(i, j); for j = 1, H (2)
where W and H are the width and height of the image. After that, (3) and (4)
are used to calculate standard deviations for each column σcol(i) and each row
σrow(j).
σcol(i) =
√√√√ 1
H
H∑
j=0
(IO(i, j) − μcol(i)) ; for i = 1,W (3)
σrow(j) =
√√√√ 1
W
W∑
i=0
(IO(i, j) − μrow(j)); for j = 1, H (4)
Let δrow and δcol be deviations of rows and columns, respectively. We have
δcol(i, j) = |Io(i, j) − μcol(i)| ; for i = 1,W (5)
δrow(i, j) = |Io(i, j) − μrow(j)| ; for j = 1, H. (6)
Finally, we can use the following equation to derive the resulting image, IR.
IR(i, j) =
⎧
⎨
⎩
IO(i, j), if |δcol(i, j) − σcol(i)| > Tstd and
|δrow(i, j) − σrow(j)| > Tstd
0, otherwise
. (7)
The pre-selected value Tstd, is determined to be 5.0 after a rigorous test of images
at hand.
(2) GradOtsu: Diﬀerent from Otsu’s method, which segment an image directly,
the method ﬁrst calculate the image’s gradient and then uses Otsu’s method to
segment the gradient image in order to reveal ﬂaws. The method was developed
speciﬁcally for extracting defects from wrinkles corrugated type surfaces. First
of all, we use Sobel’s edge detector to derive each point’s gradient and generate
Selecting an Appropriate Segmentation Method Automatically 201
where fbg(i, j) denotes the grey level of the pixel located at column i and row j
of the background image, μbg is the grayscale mean of the background image,
Nbgis the count of background pixels. Here, StdBg was used primarily to check
the uniformity of the background image. If grayscale values of the background
pixels are all close to their grayscale mean, then the standard deviation is low.
(2) VCBg: In a statistical sense, variance coeﬃcient is deﬁned as the ratio
of standard deviation to grayscale mean. Since background image was used to
calculate grayscale mean, μbg, and standard deviation, σbg, we called the ratio
of σbg to μbg variance coeﬃcient of background (VCBg), i.e.
V CBg = σbg/μbg. (9)
Statistically speaking VCBg can be used to evaluate the degree of dispersion of
background pixels’ grayscales, too. The larger the number is, the more dispersed
the grayscale values are.
(3) HWROH: The ratio of height to width of the histogram of the original
image (HWROH ) is another useful feature. We deﬁned HWROH as
HWROH =
Hraw/Nraw
Wraw/256
, (10)
where Hraw and Wraw are the height and width of the histogram of the original
image, respectively, Nraw is the count of the pixels in the image. The height of a
histogram is deﬁned as the count of the bin with the maximum count of pixels.
As to the width of a histogram, it is deﬁned as the diﬀerence between the largest
bin number and the smallest bin number with non-zero count. This feature is
useful in measuring how complex an image is. In general, the larger the number
is; the narrower the grayscale spreads. A small value of HWROH usually implies
that there are several objects in the image.
(4) HWRBH: The ratio of height to width of the histogram of the background
image (HWRBH ) is a useful feature, too. We deﬁned HWRBH as
HWRBH =
Hbg/Nbg
Wbg/256
, (11)
where Hbg and Wbg are the height and width of the background histogram,
respectively, Nbg is the count of the background pixels. We can obtain Hbg and
Wbg in a similar manner. HWRBH is useful in knowing the grayscale distribution
of background pixels. The higher the value is, the narrower the grayscale spreads.
2.3 Flaw Segmentation Using BPN Networks
Unlike classiﬁcation tree or other statistical methods, neural network approaches
do not require exact knowledge of the statistical distribution of input items. A
BPN network is the most popular among all the known ANNs. Hence, we employ
Selecting an Appropriate Segmentation Method Automatically 203
converges quickly. The recall process shows that only 4 samples were misclassi-
ﬁed, i.e., the recall rate is 99.57%. To explore the ability of the trained network,
we presented each sample in the testing set to the network one-by-one. At the
recognition stage, the network is fed with the four features extracted from the
inputted image and a proper method is chosen. The recognition rate is 99.61%.
The high recall and recognition rates strongly imply that the selected features
are extremely appropriate for discriminating one class of image from another.
3 Results and Discussions
For comparison, the same 15 images, as shown in Fig. 1, were segmented using
the proposed mechanism and the results were shown in Fig. 8. In contrast with
the segmentation results shown in Figs. 2-4, the results are satisfactory. The
outcomes suggest that the proposed method perform well in selecting a suit-
able segmentation method automatically. In addition, the results indicate that
the four carefully selected features, i.e. StdBg, VCBg, HWROH, and HWRBH,
proved to be well suited for discriminate one group from another. To explore
the capability of the proposed mechanism further, the images in the testing set
were segmented and classiﬁed. The experimental results are listed in Table 1.
With regard to the classiﬁcation of the 15 types of ﬂaws, we made use of BPN
(a) GradOtsu (b) Otsu (c) Otsu (d) HVStd (e) HVStd
(f) Otsu (g) HVStd (h) HVStd (i) HVStd (j) HVStd
(k) HVStd (l) GradOtsu (m) GradOtsu (n) GradOtsu (o) HVStd
Fig. 8. Segmentation results of the 15 images shown in Fig. 1 using the proposed
methodology. The method below each image indicates the method automatically se-
lected.
Selecting an Appropriate Segmentation Method Automatically 205
Execution time is an important issue, too. HVStd is the default method for
segmenting an incoming image; therefore, if it is selected for the subsequence
segmentation, the image has no need to be segmented again. On the other hand,
if other methods are chosen, the image will be re-segmented. Therefore, the
run time depends on the segmentation method chosen. Besides, the run time is
related to the ﬂaw types. The average run time evaluated by a 1200MHz personal
computer can be seen in Table 1.
4 Conclusion
In this paper, we have proposed a novel methodology for segmenting a vari-
ety of images. The main advantage of the proposed thresholding scheme is its
ability to choose an appropriate method from the three segmentation methods
automatically. The proposed method does not require establishing complicated
classiﬁcation tree; we use ANN classiﬁers for both image segmentation and ﬂaw
classiﬁcation, instead. The automatic selection is according to the features ex-
tracted from the image to be segmented. The overall segmentation and classiﬁca-
tion rates of the 768 images in the test set are 99.69% and 97.66%, respectively.
The experimental results show the eﬀectiveness of the selected features for clas-
siﬁcation and the power of BPN networks.
Acknowledgements. This work was supported by National Science Council
(NSC), Taiwan, R.O.C., under Grant No. 95-2622-E-216-009-CC3.
References
1. Ng, H.F.: Automatic Thresholding for Defect Detection. In: Proc. 3rd Int. Conf.
Image and Graphics, pp. 532–535 (2004)
2. Yeh, C., Perng, D.B.: A Reference Standard of Defect Compensation for Leather
Transactions. The Int. J. of Advanced Manufacturing Technology 25(11-12), 1197–
1204 (2005)
3. Mery, D., Carrasco, M.: Automated Multiple View Inspection Based on Uncali-
brated Image Sequences. In: Kalviainen, H., Parkkinen, J., Kaarna, A. (eds.) SCIA
2005. LNCS, vol. 3540, pp. 1238–1247. Springer, Heidelberg (2005)
4. Cheriet, M., Said, J.N., Suen, C.Y.: A Recursive Thresholding Technique for Image
Segmentation. IEEE Trans. Image Processing 7(6), 918–921 (1998)
5. Chan, F.H.Y., Lam, F.K., Hui, Z.: Adaptive Thresholding by Variational Method.
IEEE Trans. Image Processing 7(3), 468–473 (1998)
6. Mery, D.: Crossing Line Proﬁle: A New Approach to Detecting Defects in Alu-
minum Die Castings. In: Bigun, J., Gustavsson, T. (eds.) SCIA 2003. LNCS,
vol. 2749, pp. 725–732. Springer, Heidelberg (2003)
7. Gao, H., Siu, W.C., Hou, C.H.: Improved Techniques for Automatic Image Seg-
mentation. IEEE Trans. Circuits Syst. Video Technol. 11(12), 1273–1280 (2001)
8. Tancharoen, D., Jitapunkul, S., Chompun, S.: Spatial Segmentation based on Mod-
iﬁed Morphological Tools. In: Proc. Int. Conf. Information Technology: Coding and
Computing, pp. 478–482 (2001)
