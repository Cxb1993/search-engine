 1 
行政院國家科學委員會補助專題研究計畫 ■成果報告   
□期中進度報告 
 
探討 nWord的斷詞效能及其應用 
Investigating the Segmentation Performance and Applications of nWords 
 
計畫類別：■個別型計畫   □整合型計畫 
計畫編號：NSC  100－2221－E－005－090 
執行期間： 100年 8月 1日 至 101年 7月 31日 
 
執行機構及系所： 國立中興大學 資訊科學與工程學系(所) 
  
計畫主持人：余明興 
共同主持人： 
計畫參與人員：劉榮現、蔡珮均、李尉綸、林尚毅、 
施善舒、林蹟旋、魏俊瑋 
 
 
成果報告類型(依經費核定清單規定繳交)：■精簡報告  □完整報告 
 
本計畫除繳交成果報告外，另須繳交以下出國心得報告： 
□赴國外出差或研習心得報告 
□赴大陸地區出差或研習心得報告 
□出席國際學術會議心得報告 
□國際合作研究計畫國外研究報告 
 
 
處理方式：除列管計畫及下列情形者外，得立即公開查詢 
    □涉及專利或其他智慧財產權，□一年□二年後可公開查詢 
 
中   華   民   國  101  年  10  月 30 日 
 
 3 
 
 
二、前言 
 
  在中文的自然語言處理中，中文斷詞(及詞性標記)是一個存在很久的基本問
題，儘管已經有許多的研究結果，仍然有研究持續在進行。  斷詞方式通常分為
三大類：(1)法則式(rule-based) [Chen and Liu 1992]、(2)統計式(statistical 
methods) [Zhang, Yasuda, and Sumita, 2008; Zhang, Yang, and Qu, 2008; 賴
亦傑 2011; 羅永聖 2008; 唐若華 2010]、(3)混合式(hybrid)及其它(others) 
[Lu 2007]。 法則式的斷詞法主要是以長詞優先的方式來斷詞，分為前向式
(forward)與後向式(backward)兩種。 一種類似但不完全相同的方式是少詞優先
[江昶毅 2010]。 
 
 
三、研究目的 
 
在此計畫中，我們用一種新提出的nWord(中文稱為 多詞)做為斷詞的單位來
做中文斷詞(Chinese Word Segmentation, 簡稱CWS)，所謂nWord即是把若干個
詞合起來當做一個語言模型中的單位，角色就像是一個詞(word)一樣。 我們認
為這個方法可以再提升CWS的正確率，並且可以產生許多有用的片語(phrases)，
這些片語在機器翻譯或其它領域會有其應用。  
 
舉例而言，”才能”這個詞在斷詞時相當難以處理，但是它在中文轉台語的
系統中相當重要，通常斷成”才能”時 讀為/zai-ling/，而斷為"才+能”時 讀
為/zia/+/e-sai/，弄錯了會影響台語的語意。 例如句中有”…才能夠實
現…”，若斷成”才 能夠 實現”就有希望讀的對，但若斷成”才能 夠 實現”
就很難讀的對。 在nWord中，我們把 才+能夠+實現 和 才能+夠+實現 都當作是
一個3Word (3個詞看成一個單位)，經統計後發現， 才+能夠+實現 出現8次，而 
才能+夠+實現 出現0次，因此若採用nWord，斷詞正確的機率可望提升。 
 
用高階N-Gram(N>2)的語言模型時，除了資料量龐大外，還有運算速率的問
題。我們的構想是把出現夠多次的若干個(n個)words合在一起，稱為一個nWord，
例如前面提過的 才+能夠+實現 出現8次，就可以稱為一個3Word。 一個nWord
在語言模型中的角色就相當於一個word的角色，許多語言模型中的做法都可以延
用。 我們估計很可能只要用2階的語言模型，即nWord的bi-gram，就有很好的效
果，這樣計算速率也不會是問題。 
 
 5 
表 1. nWords 的檔案大小(2 次以上)和若干出現次數的數據。 
 
 1Word   2Word   3Word   4Word   5Word   6Word 
檔案大小  14MB   282MB   930MB   1196MB   1072MB   1015MB 
1: 916124 22146617 120910511 252913750 339093304 379753517 
2: 260551 5477196  19795602  26162697  23258776  19498882  
3: 154783 2419561  7098303  7303501  4995821  3402319  
4: 86685 1392239  3632603  3257580  1941884  1168509  
5: 56956 907763  2174730  1769909  952153  520211  
6: 43526 650806  1463049  1129149  589752  323988  
7: 32264 487506  1041254  761553  377325  195445  
8: 25250 382440  785002  555969  274019  148167  
9: 20597 308709  607310  415365  196811  102391  
10: 17314 254715  488308  326427  156906  84242  
11: 14249 213962  397166  258055  118421  60379  
12: 12608 183818  332778  212492  98391  51990  
13: 10747 158665  280536  174032  78161  39558  
14: 9326 138751  241393  148689  66707  34221  
15: 8256 123082  208139  124940  55270  28013  
16: 7551 110215  182785  109501  50137  27029  
17: 6868 98535  162600  96861  44349  24576  
18: 6451 92234  152847  99650  55440  38149  
19: 5577 81092  129378  74998  33981  18460  
20: 5240 74924  118711  70625  34238  20657  
21: 4745 68166  104473  58550  25536  12761  
22: 4367 62563  97421  55813  26509  15778  
23: 4128 57410  85804  46793  20255  10396  
24: 3717 53568  78992  42468  18296  9491  
25: 3563 49251  72152  38106  16144  7987  
26: 3389 46196  66243  35136  14652  7373  
27: 3184 43113  61560  32011  13064  6604  
28: 2939 40340  56853  29579  12353  6118  
29: 2744 38166  52826  27394  11308  5832  
30: 2547 35502  48740  25076  10559  5342  
31: 2503 33519  45949  23194  9641  4917  
32: 2320 31674  43122  21413  9003  4708  
33: 2247 30103  40006  20068  8284  4267  
34: 2083 28514  38027  18675  7605  3955  
35: 2047 26816  35264  17510  7237  3624  
 7 
 
我們再用 nPOS的4gram模型來作詞性標記，F-Measure在內部測試是
96.50%，在外部測試是91.51%。 
 
四.七、多詞-多詞性組合的 4igram 詞性標記 
 
我們再用2Words-2POS組合的4gram模型來作詞性標記，F-Measure在內部測
試是97.42%，在外部測試是92.04%。 
 
 
五、結果與討論 
 
 本計畫探討了在中文處理使用多詞(nWord)的斷詞(word segmentation)效
能，另外也探討了多詞性(nPOS)在詞性標記(POS tagging)上的效能。 我們把這
個結果加上未知詞的偵測，做出一個效能很好的斷詞&詞性標記系統，放於我們
實驗室的線上展示，在 http://speechlab.cs.nchu.edu.tw/ 點選系統展示就可
以使用。 圖 1是我們展示系統執行的畫面。 4個文字框由上而下是輸入文句、
斷詞結果、詞性標記結果、和可能的未知詞。 斷詞結果可能有少數不理想的地
方，那就可以在斷詞結果的框加以修改，再重新斷詞。 例如有不該是同一個詞
的字被合在同一個詞，可以打入空白將其分開；又如有該是同一個詞的字被分
開，可以將其反白後按”合併”按鈕；重新斷詞以後就可得到所要的結果。 最
後，如果想要斷詞和詞性標記的結果，還可以按”儲存”按鈕存到剪貼簿，以供
後續使用。 
 9 
 
 
七、References 
  
1. K. J. Chen and S. H. Liu, “Word Identification for Mandarin Chinese 
Sentences”, Proceedings COLING '92, pp. 101-107, 1992. 
2. X. Lu, “Combining Machine Learning with Linguistic Heuristics for 
Chinese Word Segmentation”, FLAIRS Conference, 2007, pp. 241-246. 
3. H. Zhang, W. Yang, and J. Qu, “Chinese Word Segmentation Method Based 
on Dictionary and Frequency of the Word”, Microcomputer Information, 
Vol. 3, 2008. 
4. R. Zhang, K. Yasuda, and E. Sumita, “Chinese Word Segmentation and 
Statistical Machine Translation”, ACM Trans. Speech and Language 
Processing, Vol. 5, No. 2, Article 4, May 2008. 
5. 江昶毅，”應用多種特徵的中文斷詞及詞性標計方法”， 國立中興大學
資訊科學與工程研究所碩士論文，2010。 
6. 唐若華，”基於詞性之斷詞方法以改善華語語音合成系統”，國立清華大
學資訊系統與應用研究所碩士論文，2010 年 7月。 
7. 賴亦傑，”應用多詞及多詞性語言模型的中文斷詞及詞性標記方法”， 國
立中興大學資訊科學與工程研究所碩士論文，2011。 
8. 羅永聖，”結合多類型字典與條件隨機域之中文斷詞與詞性標記系統研究
作”， 國立台灣大學資訊工程學系碩士論文，2008。 
 
 
 
100年度專題研究計畫研究成果彙整表 
計畫主持人：余明興 計畫編號：100-2221-E-005-090- 
計畫名稱：探討 nWord 的斷詞效能及其應用 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 7 7 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
