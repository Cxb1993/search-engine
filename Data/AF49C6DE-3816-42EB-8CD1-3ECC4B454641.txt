中文摘要 
關鍵字：非線性遞迴關係，系統鑑別
與控制，預測，空間軌跡追蹤，高階
馬可夫隨機過程，多層波茲認知機，
遞迴類神經網路，Levenberg Marquardt
學習法則，混沌時間序列分析 
本計劃主要提出離散時間域的波茲認
知 機 遞 迴 網 路 (Recurrent Potts 
perceptrons)的模型與學習方法，解決
一維、二維及三維時間序列分析問
題。新的遞迴類神經網路是以新的波
茲認知機所組織而成的，網路輸出透
過遞迴連接轉為網路輸入。本計劃以
高階非線性差分程式具體描述相關的
非線性遞迴關係，除了證明傳統二元
態認知機遞迴網路是波茲認知機遞迴
網路的特殊架構，並以 Levenberg 
Marquardt 法則發展新的遞迴網路學習
法則，並應用在 Mackey-Glass 混沌序
列分析、手寫字辯識、Hill-Valley 圖樣
辨識、機械手臂三 D 軌跡分析及
Lorenz 3D 軌跡資料分析等問題。 
英文摘要 
Keywords: nonlinear recurrence 
relations, system identification and 
control, forecasting, spatial trajectory 
tracking, high-order Markov processes, 
multilayer Potts perceptrons, recurrent 
neural networks, Levenberg Marquardt 
method, chaotic time series analysis 
 This project mainly proposes 
recurrent neural networks of Potts 
perceptrons and explores effective 
learning methodologies for solving 
time-arrow data analysis. This work 
employs high-order nonlinear difference 
equations to characterize network 
functions of RCPotts (recurrence Potts), 
The output of an RCPotts network 
automatically feedbacks to the network 
input at upcoming time points through 
recurrent connections. This project 
explores learning an RCPotts network  
based on the Levenberg-Marquardt 
method. An RCPotts network can 
promote parameter utilization for 
representing nonlinear structures by 
simply increasing the number of states 
in Potts perceptrons. This significantly 
improves flexibility of representing 
high-order nonlinear difference 
equations using recurrent neural 
networks. Numerical results are highly 
consistent with theoretical advantages of 
Potts perceptrons against perceptrons for 
function reconstruction. The developed 
learning method of RCPotts networks 
has been extensively applied to 
Mackey-Glass series analysis, 
Hill-Valley pattern recognition, 3D robot 
arm trajectory tracking and Lorenz 3D 
series analysis. 
 
一、介紹 
1990年IEEE類神經網路雜誌創刊號首
篇 文 章 刊 登 Narendra 和
Parthasarathy[1]以遞迴類神經網路
(recurrent neural networks)在動態
系統(dynamic system)的應用研究。
文中以傳統二元態認知機[18-20]建
構遞迴類神經網路，以離散時間域
(discrete time domain)的低階差分
方程(difference equations)描述遞
迴 網 路 函 數 ， 並 以 倒 傳 遞 方 法
(back-propagation)[15-17][26] 為
基礎發展遞迴網路的學習方法。離散
2. 以RCPotts遞迴網路建構高階非
線性差分方程的另一個特色是，
設計者可根據K值提升用於線性
及非線性表示的網路參數使用比
率，根據論文[2]的推導，在
RCPotts遞迴網路中非線性表示
參數的使用比例為
12
12
++
+
Kd
K ，而
在傳統認知機遞迴網路此比例為
1
1
+d ，在建構高階非線性差分方
程時，d=m+n，如果m和n都大於
10，傳統遞迴網路的非線性參數
使用比例將低於5%，這個比例並
不會因為增加二元態傳統認知機
的個數而增加，導致傳統遞迴網
路在架構上的嚴重限制。相反，
RCPotts遞迴網路可以使用較大
的K值調高非線性表示參數的使
用比例，更能表示複雜的非線性
函數結構。 
二、方法 
本 計 畫 以 新 的 波 茲 認 知 機 建 構
RCPotts遞迴網路。首先，我們以多重
波茲認知機的加權總和來建構高階非
線性差分方程的參數化函數： 
)4(  ),;(
),,;();(
1
2
1
2T
ˋ∑
∑
=
=
=
=
M
m
mm
T
m
T
m
M
m
mmmmF
σ
σϕ
cxwgr
crwxθx
 
式中的網路參數θ包含波茲認知機的
接收場向量、節點向量、權重向量及
變異量等。參數化後的高階非線性差
分方程的計算架構預計如圖一所示，
圖中的RCPotts遞迴網路輸出透過遞
迴連接自動回饋為輸入的一部分，連
續n階的網路輸出，與m階的外部輸入
形成向量x，共同決定下一個時間點的
網路輸出y[t+1]。 
 無即時誤差回饋的RCPotts遞迴
網路應用模型：如圖二的資料流程所
示， RCPotts遞迴網路在此應用模型
下，無即時誤差回饋，在進行系統鑑
別或預測時，RCPotts遞迴網路並未接
收到實體的動態系統真實輸出，其遞
迴訊息完全來自網路本身的輸出。圖
二的e[t]代表RCPotts遞迴網路與實
體動態系統的輸出誤差。因為在應用
時無誤差回饋，所以採用離線學習模
式，應用時的平均平方誤差是測試離
線網路學習效益的主要指標。當誤差
達到最小化時，透過RCPotts遞迴網路
計算所建構的高階非線性差分方程
式，恰足以描述實體動態系統的遞迴
架構。 
 具即時誤差回饋之RCPotts遞迴
網路應用模型：圖三的RCPott網路的
遞迴訊息包含即時誤差回饋，除了離
線學習外，還可以根據回饋誤差對
RCPotts網路進行即時調變及線上學
習。 
三、數值模擬 
    本計劃應用有效的RCPotts遞迴網
路學習方法解決具時間方向性的資料
分析(time arrow data analysis)問題，發
展以LM(Levenberg-Marquardt)方法為
基礎的離線式學習與即時線上學習方
法。 
A、 Mackey-Glass 17 (MG17)混沌序列
[6]分析： 我們將研發的學習程式，應
用在分析如圖四a所示MG17混沌序
列。在無誤差回饋應用架構下(參考圖
一)，RCPotts網路的神經元個數及輸出
狀態個數分別設定為M=8、K=31。假
設n=10 ，應用序列前 1000 點訓練
RCPotts網路，得到10階的非線性差分
四、總結 
 本計劃完成的工作項目包括 
1. 離散式RCPotts遞迴網路架構。 
2. RCPotts遞迴網路應用模型設計： 
A. 無即時誤差回饋的RCPotts
遞迴網路應用模型。 
B. 具即時誤差回饋之RCPotts
遞迴網路應用模型。 
3. 針對各式RCPotts遞迴網路的應用
模型發展離線式或線上即時學習
方法。 
4. 完成RCPotts遞迴網路的LM學習方
法。 
5. 將所發展的RCPotts遞迴網路應用
在具時間方向性資料分析問題上 
A. 一維序列分析 
B. 二維軌跡分析 
C. 三維軌跡分析 
 波茲認知機的多態特性強化類神
經網路的非線性表示能力，這項優勢
已經被應用在解決函數近似問題上，
本計劃進一步拓展至離散式遞迴網路
的研究上。本研究落實離散式遞迴網
路的具體應用。在學術上，RCPotts遞
迴網路巧妙連結高階非線性差分方
程、高階馬可夫程序與微分方程等研
究方向，相關類神經組織架構在解決
具時間方向性的資料分析問題扮演關
鍵角色，本研究的完成將更加落實類
神經網路在資料分析與模型建構上的
具體應用。 
 
 
 [20] Widrow, B., Generalization and Information Storage in Networks of Adaline Neuron in 
Self-Organizing Systems, 1962, M. Yovitz, G. Jacobi, and G. Goldstein, Eds. Washington, 
DC: Spartan Books, 1962, pp.435-461. 
[21] Widrow, B., 30 Years of Adaptive Neural Networks: Perceptron, Madaline, and 
Backpropagation, Proceedings of the IEEE, Vol.78, No.9, September 1990.  
[22] Wu, J.M., Lin C.H., Learning generative models of natural images, Neural Networks, 
Vol 15, No. 3, 2002. 
[23] Jiann-Ming Wu, Fetal electrocardiogram extraction by annealed expectation 
maximization, Neurocomputing 71, pp 1500-1514, 2008(SCI) 
[24] Wu, J.M., S. J. Chiu, Independent component analysis using Potts models, IEEE Trans. 
On Neural Networks, Vol. 12, No. 2, March, 2001. 
[25] Wu, J.M. (2002), Natural discriminant analysis using interactive Potts models, NEURAL 
COMPUTATION 14 (3): 689-713 MAR 2002.  
[26] Peterson, C., and Södergerbg, B., "A new method for mapping optimization problems 
onto neural network," Int. J. Neural Syst. 1,3, 1989. 
[27] Rumelhart DE, Learning Representations by back-propagation errors, Nature 323 : 533 
1986  
[28] Hagan MT, Menhaj MB, Training feedforward networks with the Marquardt algorithm, 
IEEE Transactions on Neural Networks, 5 (6): 989-993 NOV 1994,  
[29] Barnard E, Optimization for training neural nets, IEEE Transactions on Neural Networks 
3 : 232 1992  
[30] Battiti R, 1st-order and 2nd-order methods for learning - between steepest descent and 
Newton method, Neural Computation 4 : 141 1992  
[31] Hayakawa, T., Haddad, W.M., Hovakimyan, N., Chellaboina, V. (2005), Neural network 
adaptive control for nonlinear nonnegative dynamical systems, IEEE Trans. on Neural 
Networks, Vol. 16 Issue 2, 399- 413. 
[32] M. NØrgaard, O. Ravn, N. K. Poulsen, L. K. Hansen (2000), Neural networks for 
Modelling and Control of Dynamic Systems, Springer-Verlag, London, UK, 2000.  
[33] Charalambous C, Conjugate-gradient algorithm for efficient training of artificial neural 
networks, IEE Proceedings-G Circuits Devices and Systems 139 : 301 1992 
[34] Jacobs RA, Increased rates of convergence through learning rate adaptation, NEURAL 
NETWORKS 1 : 295 1988  
[35] Kollias S, An adaptive least-squares algorithm for the efficient training of artificial 
neural networks, IEEE Transactions on Circuits and Systems 36 : 1092 1989  
[36] Bishop, C.M.(1995), Neural Networks for Pattern Recognition, Clarendon Press, 1995. 
[37] R. Fletcher, (1987), Practical Methods of Optimization, Wiley. 
[38] Ferrari, S., Stengel, R.F., (2005), Smooth function approximation using neural networks, 
IEEE Trans. on Neural Networks, Vol. 16 Issue 1, 24- 38. 
[39] L. Ljung (1987), System Identification - Theory for the User, Prentice-Hall. 
  
圖三、具即時誤差回饋之RCPotts遞迴網路應用架構 
 
 
圖四、以無誤差回饋的RCPotts遞迴網路的應用架構分析MG17混沌序列  
 
RCPotts network
Dynamic System
∑
]1[ +tu
]1[ +tyP
]1[ +ty
]1[ +te
- 
+ 
  
圖六、具時間方向性的Lorenz 3D序列軌跡分析
3
8
28
10
=
=
=
β
ρ
σ
3
8
13
10
=
=
=
β
ρ
σ
a
b
c
  
  
Abstract—This work explores blind image deconvolution by 
recursive function approximation based on supervised learning of 
neural networks, under the assumption that a degraded image is linear 
convolution of an original source image through a linear 
shift-invariant (LSI) blurring matrix. Supervised learning of neural 
networks of  radial basis functions (RBF)  is employed to construct an 
embedded recursive function within a blurring image, try to extract 
non-deterministic component of an original source image, and use 
them to estimate hyper parameters of a linear image degradation 
model. Based on the estimated blurring matrix, reconstruction of  an 
original source image from a blurred image is further resolved by an 
annealed Hopfield neural network. By numerical simulations, the 
proposed novel method is shown effective for faithful estimation of an 
unknown blurring matrix and restoration of an original source image. 
Keywords—blind image deconvolution, linear shift-invariant 
(LSI), linear image degradation model, radial basis functions (RBF), 
recursive function, annealed Hopfield neural networks.  
I. INTRODUCTION 
HE general image deconvolution is to reconstruct the 
original image from given degraded observations and a 
blurring matrix. Some authors [1] preferred to address cases for 
semi-blind deconvolution, since the blurring matrix in many 
applications was unknown or partially known. Blind 
deconvolution refers to a task that is expected to reconstruct an 
original source image from only degraded observations. 
Moreover, the degradation is generally nonlinear (due to 
saturation, quantization, etc.) and spatially varying (lens 
imperfections, nonuniform motion, etc.). However in many 
imaging applications, degraded observations could be 
estimated by a linear spatially invariant (LSI) blur, which are 
also known as the point-spread function (PSF). For medical 
imaging and astronomical imaging, the PSF could be unknown 
or partially known. Reviews on major existing approaches for 
blind and semi-blind deconvolution can be found in [2] and [3]. 
Blind deconvolution is related to blind equalization as 
applied to process single channel temporal observations for 
digital communications. The goal of blind equalization is to 
 
J.-M Wu is with the Department of Applied Mathematics, National Dong 
Hwa University, Hualien 941, Taiwan. Phone: +886-3-8633531 (e-mail: 
jmwu@mail.ndhu.edu.tw).  
H.-C Chen was with the Department of Applied Mathematics, National Dong 
Hwa University, Hualien 941, Taiwan. 
C.-C Wu  is with the Department of Applied Mathematics, National Dong 
Hwa University, Hualien 941, Taiwan (e-mail: d9611002@mail.ndhu.edu.tw). 
P.-H. Hsu is with the Department of Computer Science and Information 
Engineering, National Taiwan University, Taipei 100, Taiwan. 
 
reconstruct transmitting signals from given single-channel 
observations. The degradation is linear convolution through an 
unknown filter. Typical approaches to blind equalization are to 
develop an inverse filter. Convolving single channel 
observations through an effective inverse filter is expected to 
reconstruct transmitting signals. In [4] the RBF (radial basis 
functions) neural network was employed to emulate non-linear 
dynamics of transmitting signals. Installed at a receiver, it helps 
to predict the inverse filter output and provide targets to adapt 
an inverse filter. In [5] blind deconvolution is approached by 
supervised learning of multilayer neural networks. The authors 
applied learning multilayer neural networks to extract an 
embedded nonlinear recursive function from observations and 
employed it to estimate an unknown transmitting filter. This 
work further extends recursive function approximation for 
blind image deconvolution based on supervised learning of 
multilayer neural networks. 
 In two-dimensional cases, some existing approaches to 
blind image deconvolution consider PSF partially known. The 
method addresses on blur identification based on assumption 
that elements in a blurring matrix are sampled from a 
two-dimensional Gaussian distribution. A given degraded 
image was transformed to frequency domain and factorized by 
minimizing the Kullback-Leibler (KL) divergence [6] for blur 
identification. With partially known PSF some variational 
methodologies to solve the blind deconvolution problem in 
Bayesian formulation have been presented in [7]-[11]. 
    To estimate unknown PSF, this work explores neural 
network based methodologies for blur estimation and source 
restoration. The supervised learning of neural networks are 
applied to retrieve spatially variant nonlinear recursive 
structures from a blurred image, then employing them to 
estimate a globally invariant linear convolutive structure. At 
restoration phase, Hopfield neural networks are employed to 
restore a source image from a blurred image based on an 
estimated blurring matrix. The advantages of our approach for 
estimation of an unknown blurring matrix leaning are mainly 
oriented from powerful supervised learning of multilayer 
neural networks for recursive function approximation. Blind 
image deconvolution addressed here is without given prior 
informations about PSF. Numerical simulations show Hopfield 
neural networks are effective for restoration of binary and gray 
source images based on an estimated blurring matrix. 
Blind image deconvolution by neural  
recursive function approximation 
Jiann-Ming Wu, Hsiao-Chang Chen, Chun-Chang Wu, and Pei-Hsun Hsu 
T
  
 
Fig. 2: X is generated by linear image convolution of an 
independent source. Its deterministic component is estimated 
by recursive function approximation based on RBF learning.  
The difference between the networks output and the desired 
output approximates the independent source from which X is 
oriented. 
C. Estimation of an unknown blurring matrix 
Non-deterministic components in S  detected by [ , ]e m n  
contribute to X  through an unknown convolutive structure. 
By the argument, the unknown convolutive structure can be 
estimated by minimizing the following mean square error, 
 
( )( )
2
2( ) { [ , ]
1 1
           [ , ] [ , ]}       
M N
m n
i j
C h x m n
M N
h i j e m i n j
τ τ
τ τ
τ τ
τ τ ≥ ≥
=− =−
= −− + − +
− −
∑∑
∑∑ 
 
where [ , ]e m n  equals [ , ] [ , ].x m n x m n− Since C  
quadratically depends on elements in ,H  its derivative with 
respect to each [ , ]h i j  linearly depends on elements in .H  
Setting 
                                       0
[ , ]
dC
dh p q
=                               (5) 
 
where p  and q  run from τ−  to τ , forms a linear system 
whose solution estimates parameters of the linear image 
degradation model. The proposed novel method for 
reconstruction of the nonlinear recursion embedded within a 
given degraded image and estimation of the linear image 
degradation model is summarized by the following stepwise 
procedure. 
1.   Input { [ , ]}M NX x m n× = . 
2.   Form paired data (x[ , ], [ , ])m n x m n  for all ,m n . 
3.   Train an RBF neural network to minimize ( )E θ  subject 
to given paired data and set the obtained network 
parameter to optθ . 
4. Set [ , ] [ , ] [ , ]e m n x m n x m n= −   for all m  and ,n  
where (x )optx G θ=  . 
5. Solve the linear system defined by equation (5) to 
determine all [ , ]h i j . 
 
    With an estimated blurring matrix and a degraded image, the 
restoration of an original source image is explored in the 
upcoming sections. In above procedure, if X  is a large image, 
it can be decomposed to several sub-images. At step 3 each 
sub-image can be processed to attain its local recursive relation. 
At step 5 over the whole image all [ , ]e m n  are employed to 
estimate a global convolutive structure. 
X  is generated by linear convolution of source S  through 
blurring matrix H  and added with error .r  There are two 
cases of source .S  If the pixel of S  is independent of its 
nearby pixels, it is composed of non-deterministic components 
(NDC) only. Otherwise the pixel of S  could have 
contributions of its nearby pixels through shift invariant linear 
convolution. In the occasion, S can be decomposed into 
non-deterministic components (NDC) and deterministic 
components (DC). The linear convolutions of these two types 
of sources are respectively depicted in figures 3 and 4, where 
deterministic components are assumed as results through linear 
or nonlinear convolution structures.  The result of the process 
in fig. 2 denoted by [ , ]e m n  can be employed to approximate 
NDC in .S  
 
Fig. 3: The original source image S is composed of NDC only.  
 
 
Fig. 4: Linear convolution of an original source image S 
through a LIS blurring matrix H where S can be decomposed 
into NDC and DC. 
III. IMAGE RESTORATION BY HOPFIELD                                          
NEURAL NETWORKS 
For blind equalization, given an estimated convolutive 
structure ,A  the independent source could be retrieved from 
  
2 2
, ,[( ) ( ) ]
1 1 1 11       ( log log )
2 2 2 2
ij m i n j mn ij m i n j
m n i j i j
mn mn mn mn
m n
F H S X H S
S S S S
τ τ τ τ
τ τ τ τ
β
− − − −
=− =− =− =−
≈ − −
+ + − −− − −
∑∑ ∑ ∑ ∑ ∑
∑∑
Let hk hkV S= . The derivative of F  with respect to hkV  is 
well defined. Setting 
0
hk
F
V
∂ =∂  
leads to the following mean field equation, 
, ,
, ,
tanh( 2 [ ( )
                                           ])
h k
hk ij m i n j mn m h n k
m h n k i j
h k
h m k n m h n k hk
m h n k
V H V X H
H H V
τ τ τ τ
τ τ τ τ
τ τ
τ τ
β
+ +
− − − −
= − = − =− =−
+ +
− − − −
= − = −
= − −
−
∑ ∑ ∑ ∑
∑ ∑
 (9) 
IV. NUMERICAL SIMULATIONS 
The proposed method is tested for blur estimation and source 
restoration. Fig. 6 - 9 shows an original source image, a 
blurring matrix, a blurred image, an estimated blurring matrix 
and a restored source image. Numerical simulations are 
summarized by the following stepwise procedure. 
 
1.   Use matlab built-in function imread.m to load an original 
source image, { [ , ]}.M NS s m n× =  
2.  Ask the user to define a blurring matrix , (2 1) (2 1)H τ τ+ × +  
{ [ , ]}h i j= . 
3. Convolve S  through H  to generate a blurred image, 
{ [ , ]}M NX x m n× = . 
4.  Form paired data {(x[ , ], [ , ])}D m n x m n=   from .X  
5. Apply RBF learning to build an embedded recursive 
function within .X  
6. Calculate [ , ]x m n  for all m  and n  by (3). 
7. Set [ , ] [ , ] [ , ]e m n x m n x m n= −   for all m  and n . 
8. Solve the linear system defined by (5) to determine all 
[ , ]h i j . 
9. Execute the mean field equation (9) under an annealing 
process for source restoration. 
 
The proposed novel method is tested for case of 2τ =  and 
31K = , where K denotes the number of hidden units in an 
RBF network and (2 1) (2 1)τ τ+ × +  denotes the size of the 
blurring matrix. Fig. 7 show numerical results for this example. 
Fig. 8 shows the blurring  matrix estimated by the RBF & 
AdaBoost reg  Software [15] method. 
 
Fig. 6: (a) Original source image. (b) Blurred image is 
generated by linear image degradation model. 
 
Fig. 7: The image and 3D mesh of a blurring matrix H. 
 
Fig. 8: The image and 3D mesh of an estimated blurring 
matrix. 
 
Fig. 9: Restored source image by Hopfield neural networks. 
 
With an exact blurring matrix, source restoration by solving 
(6) is shown effective. But when a given blurring matrix is 
added with noises or slightly perturbed, the general image 
deconvolution will be not effective for restoring an original 
source image as shown in Fig. 10. Numerical simulation show 
annealed Hopfield neural networks effective for source 
  
 
TABLE I 
UNITS FOR MAGNETIC PROPERTIES 
 
Method 
Error rate of the cat 
1 [ , ] ( [ , ])
2 m n
s m n s m n
MN
λ φ= −∑∑ 
 
 
 
Recursive 
Function 
Approximation 
k-means clustering 
for σ  
0.0975 
k-means clustering 
for 
kσ  
0.1355 
RBF and 
AdaBoost-reg 
Software 
0.0974 
Levenberg-Marqu
ardt method 
0.0980 
Deblurring images using the blind 
deconvolution algorithm 
0.2031 
Error rate derived by relevant RBF learning methods for 
recursive function approximation and the matlab built-in 
function, deconvblind.m. 
 
V. CONCLUSION 
This work has shown the proposed novel method effective 
for faithful blur estimation and source reconstruction. The 
novel method applies supervised learning of RBF networks to 
construct an embedded recursive function within degraded 
observations and use them to extract the non-deterministic 
component of an original source image. The difference 
between degraded observations and the extracted deterministic 
component serves as the non- deterministic component. The 
non-deterministic component is further applied to estimate an 
unknown blur structure. Moreover, an annealed Hopfield 
neural network is applied for image deconvolution and its 
effectiveness is shown for source restoration based on a  noisy 
blurring matrix.  
APPENDIX 
The RBF network function employed in (2) is defined by 
               2
0 2
1
[ , ] (x[ , ] | )
x[ , ]
          exp( )
2
K
k
k
k k
x m n G m n
m n
w w
μ
θ
σ=
=
−= + −∑
 
             (10) 
where { } { } { }k k kwθ σ= ∪ ∪μ denotes collection of 
network parameters. 
A. K-means based RBF learning 
K-means clustering [14] aims to determine K means of given 
observations by partitioning them into non-overlapping subsets. 
Let 1{ }
n
i i=ξ denote collection of d-dimensional real vectors. 
K-means clustering aims to partition them into k subsets, each 
denoted by ,jΛ  where ,K n< so as to minimize the 
within-cluster sum of squares (WCSS), 
2*
1
arg min
i j
K
i j
j x
Λ = ∈Λ
Λ = −∑∑ ξ μ  
where jμ  is the mean of elements in .jΛ  K-means clustering 
can be employed to initialize the network parameter θ of 
equation (10). Let {( , )}i i iD= ξ y  denote paired training 
data. Two simple approaches are considered to determine 
network parameters other than determined K means, denoted 
by 1{ }
K
j j=μ . 
1.    The first situation considers kσ σ=  for all k, where σ  
is a real value. The means kμ  for all k are determined by 
k-means clustering. A common variance is employed. 
Equation (10) for each iξ  will reduce to a linear system, 
                           0
1
K
i k ik
k
y w w v
=
= +∑                             (11) 
where 
2
2exp( )2
i k
ik
k
v σ
−= − ξ μ . There are K unknowns, 
{ }k kw , and n constraints, which constitute a linear system 
well resolved by the technique of pseudo inverse. 
Substituting all determined network parameters to 
                        2
1
1 ( ( | ))
2
N
i
i
E y G
Nσ
θ
=
= −∑ ξ              (12) 
attains an error. This error is minimized by selecting the 
best common σ. 
2.   The second situation employs different variances. The 
K-means clustering method is used to determine all .kμ  
Then kσ  is determined by elements that are closest to kμ  
relative to jμ  with  j≠k. Then equation (11) is employed 
to determine all .kw  
B. Levenberg-Marquardt method 
The Levenberg-Marquardt method [16] can be considered as 
a hybrid of the gradient method and the Newton-Gauss method. 
Let iθ  denote the network parameter at the thi  iteration and 
( , ) ( | )i t it y y tε θ θ= −  denote an approximating error. The 
mean square error in (12) can be rewritten as 
                          2
1
1( ) ( , )
2
N
D i i
t
E t
N
θ ε θ
=
= ∑                   (13) 
It follows 
1
( ) 1( ) ( , ) ( , )
i
N
D
i i i
t
dE t t
d Nθ θ
θθ ε θ θθ = =
∇ = =− Ψ∑  
Where 
( [ ] | )( , ) .
i
dG x tt
d θ θ
θθ θ =Ψ = Moreover, 
                    
( ) ( )
i
D
i i
dE
d θ θ
θθ θθ =Δ ∝− =−∇            (14) 
( , )tε θ by linear expansion at iθ θ=  can be represented as 
行政院國家科學委員會補助國內研究生出席國際學術會議報告 
                                                              99 年 11 月 1  日 
報告人姓名 
吳俊樟 
就讀校院
（科系所）
                     ■博士班研究生 
國立東華大學 
應用數學研究所 
                     □碩士班研究生 
時間 
會議地點 
2010/8/25-2010/8/27 
新加坡  
本會核定
補助文號
論文指導教授吳建銘老師之國科會計畫
補助（NSC 98-2221-E-259-020） 
會議 
名稱 
 (中文) 訊號與影像處理國際會議 
 (英文) International Conference on Signal and Image Processing 
發表 
論文 
題目 
 (中文) 基於類神經遞迴函數近似的盲影像反迴旋問題 
 (英文) Blind image deconvolution by neural recursive function approximation 
    我們於四月中提交此篇論文於 World Academy of Science, Engineering and Technology
(WASET)國際學會所舉辦的會議，五月中通知接受，並且赴 8/25 至 8/27 於新加坡 River View 
Hotel 舉辦的會議參加口頭報告。此國際學會在同一地點同時進行多個會議報告，包含化學、物
理、生物、工程、電腦計算等領域，此篇論文參加的是名為訊號與影響處理的會議。 
    我的口頭報告安排於會議的第一天，於 B廳舉行。早上八點開始報到註冊，但會場安排動線
不良，近百人的會議全部擠在外面狹小的長廊報到，並且只有兩位工作人員處理報到事宜，大約
三十分鐘之後報到完成。一進會場，會議的主持人已開始介紹 WASET 學會，大約十分鐘之後，開
始進行三位邀請學者演講。三位邀請學者演講結束之後，於短暫休息之後開始進行投稿的口頭報
告。這時有兩位學會學者進來會場，講解報告事項以及安排順序。這兩位學會學者會在每位演講
者口頭報告結束之後，負責發問問題。我在口頭報告中大約花了 15 分鐘，並且展示一個利用
Matlab 所寫的 Toolbox 來模擬論文中的理論之影片。最後兩位學者發問問題，包含程式執行時
間多長，有無與其他方法做比較，為何使用 hopfield neural network 來解決我們的問題，以及如何
執行報告中所提的監督式學習(Supervise learning)。除了兩位學者提問題以外，沒有其他與會學
者提問題。 
    上段文中提起，此學會所舉辦的會議是在同一地點同時舉辦多個會議，可以參照以下網址:
http://www.waset.org/conferences.php，因此會讓人覺得有點雜亂、不專業的感覺，不過從另
一觀點來看，參加一個會議也可以聆聽不同領域的問題和知識，例如其他演講者介紹支持向量機
(Support Vector Machine)學習的相關問題，以及微陣列分析(Introduction to Micro Array 
Analysis)等不同有趣的問題。會議中包含各種領域的人，也因為如此，在我口頭報告時，除了
基本學會學者以外，很少可以互相交換意見的人。整個會議的工作人員並不多，一進會場並沒有
人招待，只有兩位工作人員負責報到事宜，會議證書和名牌放在長廊的桌上，也沒有人講解如何
進行報到，讓人有點不知所措的感覺，上述情況提供給有意參加此學會會議的人參考。 
    另外，我們的論文 Blind image deconvolution by neural recursive function approximation 有收錄
於 World Academy of Science, Engineering and Technology ISSUE 69 的刊物中。參加此次會議攜回
1.參加會議證書與名牌各一。2.一本刊物。3.收錄完整會議論文的光碟片一片。4.議會流程單。
國科會補助計畫衍生研發成果推廣資料表
日期:2010/12/21
國科會補助計畫
計畫名稱: 波茲認知機的離散式遞迴網路架構、學習與應用
計畫主持人: 吳建銘
計畫編號: 98-2221-E-259-020- 學門領域: 人工智慧
無研發成果推廣資料
碩士生 4 0 100%  
博士生 2 0 100%  
博士後研究員 0 0 100%  
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
 
 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
