行政院國家科學委員會補助專題研究計畫 成 果 報 告   □  期中進度報告 
 
 
大學雲：分散式雲端運算中介軟體－ 
子計畫三:QoS 排程與管理系統 
 
計畫類別：□ 個別型計畫   整合型計畫 
計畫編號：NSC 99-2218-E-142 -001 -  
執行期間： 99 年 8 月 1 日至 100 年 10 月 31 日 
 
計畫主持人：黃國展 
 
成果報告類型(依經費核定清單規定繳交)：■精簡報告  □完整報告 
 
本成果報告包括以下應繳交之附件： 
□赴國外出差或研習心得報告一份 
□赴大陸地區出差或研習心得報告一份 
■出席國際學術會議心得報告及發表之論文各一份 
□國際合作研究計畫國外研究報告書一份 
 
 
處理方式：除產學合作研究計畫、提升產業技術及人才培育研究計畫、
列管計畫及下列情形者外，得立即公開查詢 
          □涉及專利或其他智慧財產權，□一年□二年後可公開查詢 
          
執行單位：國立臺中教育大學資訊科學學系(所) 
 
 
 
中   華   民   國  101  年  1  月   31  日 
 2
中文摘要 
雲端計算雖然不是全新的想法，但近年來逐漸為大家所接受，日益受到重視，被認為
是最有希望的下一代計算平台。一個雲端平台多是由分散各地的計算或資料中心所組成，
而每個計算或資料中心內部通常是一組或多組的大型叢集(cluster)系統。因此，從計算機
系統架構的觀點來看，雲端計算平台的底層可視為是一個分散式的多叢集(multi-cluster)
架構。雖然之前常被提到的雲端運算平台上的應用種類，多屬於服務導向
(service-oriented)的應用系統(例如 web server, application server 等等)，但最近開
始陸續有許多探討關於 HPC(High Performance Computing)應用的雲端運算需求與服務的
聲音出現。這類型的應用常出現在科學研究(例如模擬核爆、全球氣候變遷、銀河系生成等
等)或工程設計(例如飛機設計、汽車碰撞模擬等)等領域。因此，在雲端運算平台上支援
HPC 應用勢必成為一項無可避免的需求，而所需的技術則包括了平行工作的排程與資源配
置等，也正是本子計畫的研究重點。雲端運算因為有一明確的平台提供者，而且使用者通
常需付費使用平台上的服務，因此更為著重計算資源的使用效率以及使用者對服務品質的
滿意度等議題，這兩個議題也是本子計畫的研究重點。藉由發展出更能提高計算資源使用
效率的工作排程及資源配置方法，平台提供者可以在相同的計算資源數量下，服務更多的
使用者或是增加收益。而 QoS 排程方法的發展，可以讓使用者在雲端平台上執行工作時獲
得服務品質的確保，提高其使用雲端平台的意願。上述兩個研究議題的進展以及相關排程
方法的開發，可以創造平台提供者跟使用者之間的雙贏效果。本計畫所支援的計算導向型
工作主要以批次(batch)計算為主，包括 sequential jobs, SPMD parallel jobs, DAG-based 
parallel jobs。本子計畫除開發一實際系統來支援及管理雲端運算平台中所執行的上述各
種型態的工作之外，亦針對 QoS 排程等議題進行深入研究，以發展出更有效率的排程與配
置方法。 
 
關鍵詞：雲端運算、高效能運算、工作排程、資源配置 
 4
前言 
本子計畫所屬之整合型計畫的目標在發展一套分散式雲端運算中介軟體，利用
P2P 及虛擬化技術，將地理上分散於各地的各種計算與儲存資源透過此一中介軟體整
合起來，提供一以學術單位為主所集合而成的分散式雲端運算平台，讓有意從事雲端
運算技術相關研究及應用的單位，能夠有一雲端運算實驗環境，藉此帶動台灣雲端運
算相關技術的研究與發展。本子計畫預計開發一 QoS 排程與管理系統，負責處理雲端
運算平台中計算導向型工作的管理、排程與最佳化等議題。 
一、 研究目的 
雖然目前常被提到的雲端運算平台上的應用種類，多屬於服務導向
(service-oriented)的應用系統(例如 web server, application server 等等)，但最近開始陸續
有許多探討關於 HPC(High Performance Computing)應用的雲端運算需求與服務的聲音
出現。HPC 應用指的是一些計算密集的大型平行程式，通常一次的執行就需要很多的
計算資源及很長的時間，例如用幾十顆 CPU 或是上百顆 CPU 執行幾個小時，甚至幾
天等等。這類型的應用常出現在科學研究(例如模擬核爆、全球氣候變遷、銀河系生成
等等)或工程設計(例如飛機設計、汽車碰撞模擬等)等領域，隨著各種商業活動的日漸
e 化以及電子商務的普及，許多商業系統幕後的決策或分析工作也逐漸出現大量計算的
HPC 應用需求。因此在可預見的將來 s，在雲端運算平台上支援 HPC 應用勢必成為一
項無可避免的需求。本子計畫除開發一實際系統來支援及管理雲端運算平台中所執行
的上述各種型態的工作之外，亦針對 QoS 排程等議題進行深入研究，以發展出更有效
率的排程與配置方法。 
二、 文獻探討 
Feitelson等人在[1]中曾提出一個PSCHED的工作排程環境參考架構，如圖一所示，其
中分成三個主要元件: Task Manager, Resource Manager, Scheduler，分別負責使用者提交的
工作管理、系統資源(在此即指處理器)管理、工作排程與資源配置決策，這個架構將是我
們在此子計畫中開發QoS排程與管理系統時的重要參考。 
 
 6
擎(workflow engine)，用來管理工作流程內不同工作的先後執行關係，以確保所有的資
料相依性獲得維護，並能進行適當的工作排程，以提高計算工作的執行效率。 
2. 計算工作監控及管理介面 
使用者在將計算工作交付雲端平台執行或等待執行之後，需要有一個使用者介面
能夠隨時掌握工作的最新進度或是一些異常狀況的訊息。我們開發了一個方便使用之
圖型化操作介面，供使用者瞭解工作的執行狀態並可進行相關的工作管理動作，例如
刪除、暫停等等。 
3. 工作流程排程演算法 
我們於本年度發展出一種 discontinuous gap search 之工作流程排程演算法，它首先
將一個工作流程內之所有工作依其相依屬性分成多個不同群組，然後允許將同一工作
群組內的工作分配在同一機器之不同空閒時間區間內(time gap)。這個不連續的機制經
實驗證實可比先前文獻中的排程方法更進一步提高計算資源利用率，進而達成更好的
工作流程執行效能，縮短其完工時間。 
 
本子計畫透過研發上述之元件實做了一個工作排程與管理系統。此子系統提供高
效能計算雲端服務，能將使用者提交之平行計算工作或工作流程透過高效率的工作排
程方法安排至適當之雲端計算資源上執行，以同時達成縮短使用者計算工作所需之完
成時間及提升整體雲端資源使用效率等目的。 
 
圖二、QoS 排程與管理系統架構圖 
 
四、 結果與討論 
本子計畫本年度已如期完成一工作排程與管理雛型系統，與其他相關子計畫
完成整合，並發展出一新的 discontinuous gap search 工作流程排程方法。未來
將針對 mixed-parallel 工作流程的排程議題進行研究。 
 
 
 
 8
參考文獻 
[1] Feitelson, D. G., Rudolph, L., Schweigelshohn, U., Sevcik, K., and Wong, P., “Theory and 
practice in parallel job scheduling”, In Job Scheduling Strategies for Parallel Processing D. 
G. Feitelson and L. Rudolph (Eds.), pp. 1-34, Springer-Verlag, 1997. Lecture Notes in 
Computer Science Vol. 1291.  
[2] Hamscher, V., Schwiegelshohn, U., Streit, A., and Yahyapour, R., “Evaluation of 
Job-Scheduling Strategies for Grid Computing”, Proceedings of the 7th International 
Conference on High Performance Computing, HiPC-2000, pp. 191-202, Bangalore, India, 
2000. 
[3] Ernemann, C., Hamscher, V., Yahyapour, R., and Streit, A., “Enhanced Algorithms for 
Multi-Site Scheduling”, Proceedings of 3rd International Workshop Grid 2002, in 
conjunction with Supercomputing 2002, pp. 219-231, Baltimore, MD, USA, November 
2002. 
[4] Ernemann, C., Hamscher, V., Schwiegelshohn, U., Streit, A., Yahyapour, R., “On 
Advantages of Grid Computing for Parallel Job Scheduling”, Proceedings of 2nd IEEE 
International Symposium on Cluster Computing and the Grid (CC-GRID 2002), pp. 39-46, 
Berlin, Germany, 2002. 
[5] Ernemann, C., Hamscher, V., Streit, A., Yahyapour, R., “"On Effects of Machine 
Configurations on Parallel Job Scheduling in Computational Grids", Proceedings of 
International Conference on Architecture of Computing Systems, ARCS 2002, pp. 169-179, 
2002. 
[6] Sakellariou, R. and Zhao, H., “A hybrid heuristic for DAG scheduling on heterogeneous 
systems”, Proceedings of 18th International Parallel and Distributed Processing Symposium 
(IPDPS’04), page 111. IEEE Computer Society, 2004. 
[7] Zhao, H. and Sakellarious, R., “Scheduling Multiple DAGs onto Heterogeneous Systems”. 
Proceedings of the 15th Heterogeneous Computing Workshop (HCW), Rhodes Island, Greece, 
April 2006. 
[8] N'takpe', T. and Suter, F., “Concurrent Scheduling of Parallel Task Graphs on Multi-Clusters 
Using Constrained Resource Allocations”. Rapport de recherché n° 6774, December 2008. 
[9] Yu, Z. and Shi, W., “A Planner-Guided Scheduling Strategy for Multiple Workflow 
Applications”. Proceedings of the 2008 International Conference on Parallel Processing, 
8-12 Sept. 2008. 
[10] Topcuoglu, H., Hariri, S., and Wu, M. Y., “Performance-Effective and Low-Complexity Task 
Scheduling for Heterogeneous Computing”. IEEE Transactions on Parallel and Distributed 
Systems, 2(13):260-247, 2002. 
[11] Barzegar, B., Rahmani, A. M., Zamanifar, K., Divsalar, A., “Gravitational Emulation Local 
Search Algorithm for Advanced Reservation and Scheduling in Grid Computing Systems”, 
Proceedings of the 2009 Fourth International Conference on Computer Sciences and 
Convergence Information Technology, November 2009, pp. 1240-1245. 
[12] Lee, C. Y., Lee, T. Y., Wu, H., Tsui, H. D., Huang, J. B., “A Performance Optimization of 
Job Scheduling Model Based on Grid Environment”, Proceedings of the 2009 Fourth 
International Conference on Computer Sciences and Convergence Information Technology, 
November 2009, pp. 768-773. 
[13] Nie, L., Xu, Z., “An Adaptive Scheduling Mechanism for Elastic Grid Computing”, 
Proceedings of the 2009 Fifth International Conference on Semantics, Knowledge and Grid, 
October 2009, pp. 184-191. 
[14] Rao, I. and Huh, E. N., “A Probabilistic and Adaptive Scheduling Algorithm Using 
System-Generated Predictions for Inter-Grid Resource Sharing”, The Journal of 
Supercomputing, Volume 45, Issue 2 (August 2008), pp. 185 – 204.  
[15] Fan, S., “Session Scheduling Algorithm of Grid Computing”, Proceedings of the Third 
International Conference on Knowledge Discovery and Data Mining, January 2010, pp. 3-6. 
 
2
 
 
 
 Parallel Algorithms 
 Parallel Architectures 
 Parallel and Distributed Databases 
 Parallel I/O Systems and Storage Systems 
 Parallel Programming Paradigms 
 Performance of Parallel & Distributed Computing Systems 
 Resource Management and Scheduling 
 Tools and Environments for Parallel & Distributed Software 
Development 
 Software and Hardware Reliability, Testing, Verification and 
Validation 
 Security, Privacy, and Trusted Computing 
 Self-healing, Self-protecting and Fault-tolerant Systems 
 Information Security In Internet 
 Multimedia in Parallel Computing 
 Parallel Computing in Bioinformatics 
 Dependability Issues in Computer Networks and Communications 
 Dependability Issues in Distributed and Parallel Systems 
 Dependability Issues in Embedded Parallel Systems 
 Industrial Applications 
 Scientific Applications 
 
二、與會心得 
 
本屆大會除了主會議之外，尚同時聯合舉辦了底下幾個不同主題的研討會。 
 
 2011 International Symposium on Advances of Distributed Computing and 
Networking (ADCN 2011) 
 The 4th IEEE International Workshop on Internet and Distributed Computing 
Systems (IDCS 2011) 
 The 1st IEEE International Workshop on Parallel Architectures for Bioinformatics 
Systems (HardBio 2011) 
 The III International Workshop on Multicore and Multithreaded Architectures and 
Algorithms (M2A2 2011) 
 
這幾個workshops的主題正點出了目前Parallel and Distributed Processing領域中的一
些重要研究方向，例如: multi-core、multi-threaded、網路、及與應用領域結合 (如
Bioonformatics)等等。從這次大會場次的安排跟所發表的論文內容看來，可以發現不同研
究領域間正逐漸加強彼此的交流與合作來解決一些共同的問題或是達成共同的目標，也
4
 
 
 
 
Kuo-Chan Huang & He-Jhan Jiang 
National Taichung University of Education 
Department of Computer and Information Science 
Taichung, Taiwan 
  
 
16th August 2011 
 
 
Dear Kuo-Chan & He-Jhan, 
 
We invite you to attend the 11th International Conference on Algorithms and Architectures for 
Parallel Processing (ICA3PP 11), to orally present your paper, Scheduling Concurrent Workflows 
in HPC Cloud Through Exploiting Schedule Gaps. 
 
This conference is to be held in Melbourne, AUSTRALIA, 23-26 October 2011.  
 
Please present this letter when lodging your visa application at the Australian immigration office 
overseas. 
 
Please note that in order to be granted a visa to visit Australia you must demonstrate that you meet 
all the legislative requirements for visa grant. For all questions regarding you visa please contact 
your local Australian immigration office 
 
If you have any further queries, please feel free in contacting me. 
 
We wish you all the best.  
 
Kind Regards, 
 
Professor Wanlei Zhou 
ICA3PP 11 Steering Committee Chair 
 
                          
6
 
 
 
Scheduling Concurrent Workflows in HPC Cloud Through Exploiting 
Schedule Gaps 
He-Jhan Jiang Kuo-Chan Huang Hsi-Ya Chang‡  
Di-Syuan Gu Po-Jen Shih 
 
Department of Computer and Information Science 
National Taichung University of Education 
No. 140, Min-Shen Road, Taichung, Taiwan 
mice.jiang@gmail.com; kchuang@mail.ntcu.edu.tw; ejeu67195@gmail.com; 
frontpageserver@gmail.com 
 
National Center for High-Performance Computing‡ 
National Applied Research Laboratories 
P.O. Box 19-136, Hsinchu, Taiwan 
jerry@nchc.narl.org.tw 
Abstract. Many large-scale scientific applications are usually constructed as workflows due to large amounts of 
interrelated computation and communication. Workflow scheduling has long been a research topic in parallel and 
distributed computing. However, most previous research focuses on single workflow scheduling. As cloud computing 
emerges, users can now have easy access to on-demand high performance computing resources, usually called HPC 
cloud. Since HPC cloud has to serve many users simultaneously, it is common that many workflows submitted from 
different users are running concurrently. Therefore, how to schedule concurrent workflows efficiently becomes an 
important issue in HPC cloud environments. Due to the dependency and communication costs between tasks in a 
workflow, there usually are gaps formed in the schedule of a workflow. In this paper, we propose a method which 
exploits such schedule gaps to efficiently schedule concurrent workflows in HPC cloud. The proposed scheduling 
method was evaluated with a series of simulation experiments and compared to the existing method in the literature. 
The results indicate that our method can deliver good performance and outperform the existing method significantly 
in terms of average makespan, up to 18% performance improvement. 
Keywords: HPC cloud, workflow scheduling, distributed gap search 
Introduction 
Many large-scale scientific and engineering applications are usually constructed as workflows due 
to large amounts of interrelated computation and communication. Common types of workflows can 
be represented by Directed Acyclic Graphs (DAG) for describing the inter-task precedence 
constraints [7]. Each node represents a task which executes a specific program. The number next to 
each node means the execution time of the task. The edges represent the dependence between tasks 
and the number next to an edge means the inter-task data transmission time. A job scheduler has to 
schedule and allocate each task according to the dependence specified in the workflow definition.  
Traditionally, few users have access to high performance computing platforms for executing 
8
 
 
 
grouping the tasks of heavy communication into the same labeled cluster. In general, a 
clustering-based heuristic method has two phases: clustering and merging. In the clustering phase, 
the original workflow application is partitioned into clusters, and the merging phase merges the 
clusters so that the remaining number of clusters equals to the number of resources.  
A duplication-based heuristic method [20] helps a task to transmit the data to the resource of 
succeeding task(s) through duplicating the task on the destination processor. This duplication 
arrangement can reduce the communication cost from a task to a successor in order to minimize the 
overall makespan of the entire workflow. A level-based heuristic method, e.g. LHBS (Levelized 
Heuristic Based Scheduling) [21], divides the workflow into levels of independent tasks. Within 
each level, LHBS can use the Greedy, Min-Min, Min-Max, or Sufferage [22] heuristics to map the 
tasks onto resources. 
Both the method in [1] and our method in this paper adopt a hybrid approach to workflow 
scheduling. At the first step a clustering-based scheme is used to partition a workflow into several 
task groups. Then, in the second step the list-based heuristic is applied to allocate these task groups 
onto processors.  
PCH and Gap Search 
This section introduces the Path Clustering Heuristic (PCH) approach and the gap search algorithm 
[1][4]. The entire workflow scheduling process is divided into two phases. In the first phase, PCH is 
used to cluster tasks in a workflow into different groups, and then priorities are assigned to the task 
groups based on their dependence. In the second phase, the gap search algorithm is used to allocate 
each task group onto a specific processor.  
The workflows discussed in this paper can be represented by Directed Acyclic Graphs (DAG), G (V, 
E), where: 
• V is the set of tasks, tn  V, |V| = number of tasks; 
• E is the set of directed edges, en  E, |E| = number of edges. 
Each workflow starts at one node, named the front node, and finishes at one node, named the end 
node. Each node in the workflow is a task representing a specific job or program to execute and 
each edge represents the data dependence between nodes. Each task starts its execution only after 
receiving all data from his parent nodes. 
The Path Clustering Heuristic (PCH) is a DAG scheduling heuristic which clusters the tasks into 
different groups and uses the list scheduling technique to schedule the tasks within a group onto the 
same resource. PCH focuses on reducing the communication costs between tasks and has been 
shown good performance in [1][4]. 
We first define several node attributes which will be used in the following. 
• Computation cost: 
10
 
 
 
PCH is used to cluster the tasks, resulting in four task groups for the upper DAG and three task 
groups for the second DAG. Then, the upper DAG is scheduled first with the traditional list 
scheduling heuristic. When scheduling the second DAG, we first calculate the computation cost of 
each task group, e.g. {A, B, C, and D}, through summing up the computation costs of all the tasks 
within the task group. Then, the gap search algorithm is used to check whether there is a suitable 
gap to allocate the task group. A suitable gap for a task group means a gap with a time period equal 
to or larger than the computation cost of the task group. 
 
 
Fig. 1. Example of scheduling two workflows using PCH and gap search 
To consider the issue that a gap might dynamically shrink due to the unexpected slowdown of a 
resource, the gap search algorithm adopts a security margin mechanism [4], which calculates the 
time gap by assuming a specific percentage of shrink caused by resource slowdown. In this paper, 
we assume this percentage to be 10%, which means if there is a task group of 90-second 
computation cost, we have to find a time gap larger than 100 seconds to accommodate the task 
group since 100*(100%-10%) = 90. 
Algorithm 1 in the following describes the gap search algorithm in details. For a resource with k 
tasks already scheduled on it, there are k candidate time gaps to allocate a subsequent task group. In 
Algorithm 1, Lines 1 to 9 tries to allocate the task group into the first time gap, indexed with 0. 
Lines 10 to 19 iteratively tries to allocate the task group into the remaining k-1 time gaps until a 
suitable gap is found. If no suitable gap is found after trying all k time gaps, the task group will be 
allocated to immediately follow the last task on current schedule. 
12
 
 
 
partitions the task group into two subgroups, {5, 6, 7, 8, 9} and {10}, where the first subgroup can 
fit into a gap on resource two and the second subgroup can be allocated onto another resource, in 
this case resource zero, as shown in Figure 2. This leads to a better resource utilization and 
workflow execution performance.  
 
 
Fig.2. Example of distributed gap search 
Algorithm 2 in the following describes the distributed gap search scheme in details. Lines 14 to 26 
deal with the case that a task group cannot fit into current gap. The while loop through lines 16 to 
25 performs the re-clustering, which partitions the task group into two subgroups and ensures that 
the first subgroup can fit into current gap and contains as more tasks as possible. Lines 19 and 20 
allocate the first subgroup into current gap, while line 21 recursively calls the distributed gap search 
scheme to allocate the second subgroup. 
 
 
Algorithm 2: Distributed Gap Search: DGS(grp) 
 grp: task group to be scheduled 
          G: the set of time gaps on all resources 
 Sr: current schedule of resource r  
m: number of tasks in grp; tasks are indexed from 1 to m
 
 
  1: sort the gaps in G into a list L with a non-decreasing order 
of beginning time 
2: k ←number of tasks in Sr  
3: EFT(t0,r) ← 0; 
4: foreach time gap g in L do 
5:       r ←the resource where g resides  
6:       sizegrp,r ← EFT( tgrpm,r )-EST( tgrp1,r ) 
7:       sizeg← the time duration of gap g 
14
 
 
 
search scheme delivers better performance through improving the overall resource utilization. Up to 
18% performance improvement can be obtained as shown in the above experiments. 
 
Fig. 3. Average makespan of 500 DAGs on 30 resources 
 
Fig. 4. Resource utilization of 500 DAGs on 30 resources 
Conclusions 
Concurrent workflow scheduling becomes a crucial issue in HPC cloud environments. This paper 
deals with this issue through a hybrid scheduling approach. At the first step, a clustering based PCH 
approach [1][4] is applied to cluster the tasks within a workflow into different task groups. At the 
second step, the list-based scheduling heuristic is accompanied with a gap search mechanism to 
allocate the task groups onto the resources. A distributed gap search scheme is proposed in this 
paper to further improve resource utilization and workflow completion time. The proposed scheme 
were evaluated with a series of simulation experiments on workflows of various structures and 
compared to the continuous gap search algorithm in [1][4]. The results indicate that the proposed 
distributed gap search scheme outperforms the previous continuous approach significantly in terms 
of average makespan. Up to 18% performance improvement was obtained in the experiments. 
References 
1. Bittencourt, L. F., Madeira, E. R. M.: Towards the Scheduling of Multiple Workflows on Computational Grids. 
Journal of Grid Computing. 8, 419-441 (2009). 
2. Kwok, Y. K., Ahmad, I.: Static Scheduling Algorithms for Allocating Directed Task Graphs to Multiprocessors. 
ACM Computing Surveys. vol. 31, no. 4, pp. 406–471. (1999) 
16
 
 
 
32. Kim, H., el-Khamra, Y., Jha, S., Parashar, M.: An Autonomic Approach to Integrated HPC Grid and Cloud Usage. 
In: 5th IEEE International Conference on e-Science, pp. 366-373. (2009) 
  
 
99 年度專題研究計畫研究成果彙整表 
計畫主持人：黃國展 計畫編號：99-2218-E-142-001- 
計畫名稱：大學雲：分散式雲端運算中介軟體--子計畫三:QoS 排程與管理系統 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 0%  
研究報告/技術報告 0 0 100%  
研討會論文 1 1 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 4 4 80%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 0 1 80%  
研究報告/技術報告 0 0 100%  
研討會論文 1 1 80% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
