2一、中英文摘要............................................ 1
二、報告內容.............................................. 3
1.前言.............................................................. 3
2.研究目的.......................................................... 3
3.研究方法.......................................................... 4
4.系統整合實作 ...................................................... 11
5.結果、討論與現階段潛在困難 ........................................ 11
三、計畫成果自評.......................................... 12
四、參考文獻.............................................. 13
4種不規則形狀的物件，例如：樹、車子、房子，讓機器人於虛擬環境中先
進行訓練辨識這些非目標物之物體，以避免機器人對目標物及障礙物辨識
錯誤而影響行走路線。本研究透過類神經訓練來提高更高層視覺認知的實
踐(Dror & Dascal, 1997; Dror & Thomas, 2005)，透過融合虛擬環境設計概念
(Virtual Reality)、影像處理技術 (image processing)、細胞集合技術 (Cell
Assemblies)、演算法(Algorithm)、「神經網絡」(Neural Network)技術，構成
智慧型機器人互相組合機器人智慧代理人能模擬人類的思考模式並擁有記
憶能力，達到完美的辨識能力，讓搜救行為可以更有效率並且更具安全性，
下段將對於第三年所作的方法及過程進行詳盡的解說。
3.研究方法
本研究第三年的計畫為針對前二年所進行的研究與分析結果，進行實
際環境的處理辨識與演算法改良與精進，其主要包括：於虛擬實境進行訓
練及演算法之改進，以達到避開障礙物及尋找多重目標、使系統與機器人
整合，並於實際環境測試及改良、影像處理系統增加不規則物件之辨識，
其中包括演算法之改進及撰寫。針對領域解說如下:
(1). 虛擬地震環境模型建造(3D Max + Virtools + OpenGL)
為了使機器人智慧代理人及圖形辨識系統可以獲得更精密的圖像資
料，已進行更精確的訓練及模擬，此階段與前兩年使用相同的工具(3D Max
及 Virtools)與流程(模型製作、材質貼圖、打光、算圖、虛擬實境軟體應用)，
圖二、虛擬地震環境模型圖
6這裡我們利用的是中值濾波器，影像經過中值濾波之後，較不會對整張影
像造成多大的變化。
ii、低通濾波:
低通濾波通常會產生影像模糊的效果。低通濾波器中常見的遮罩是由
9 個 1/9 的係數組成，為將遮罩中所有灰度值加總後求其平均，然後寫入
對應的點素中，如此可將雜訊去除。使用此方法的好處為計算簡單。常用
遮罩。這階段的目的為圖片經過灰階值轉換後，些微的雜訊依舊會存在，
用低通濾波將灰階圖片模糊及平滑後，能減少雜訊及細紋的影響。
iii、二值化轉換:
經模糊處理後進一步做二值化轉換，圖片將會變成純黑白圖像，此時
即可分離出背影與物件。
iv、影像測邊:
當中有各式各樣的物件，包含了許多的訊息。這個階段，我們主要是
強化邊緣的訊息，以利之後正確的做影像分割。一個影像中邊緣的變化有
對 x 與 y 方向，使用 sobel 濾波器來獲得 x 與 y 方向的分量，然後再做矩陣
相加的動作(算式 1 所示)
此演算法計算容易，在邊緣的表達又清楚，因此被廣泛應用在機械視
覺的領域中。
(c) 物件屬性模組
現實世界中，每個物件都有不同的外型、顏色。就算不同顏色，或是
缺乏一些資訊，但是人類還是能夠正確的判斷；但機器人不同於人類，
(1)
圖四、物件屬性模組處理結果
8i、圖像標籤化
此階段會先利用圖像標籤化(Connected component labeling) 將所拍
攝到的影像做分割，判斷此畫面中共有幾個物件，並求出每個物件的面積
及對應點。在此圖像標籤化是使用八方向鄰邊偵測，所謂八方向鄰邊偵測
是將一張圖由上至下，由左至右掃描其像素的八個方位：上、下、左、右、
右上，右下，左上，左下，如果某一個元素他的八方向鄰邊像素皆為 255
就自成一堆，反之則與鄰邊的數值成為一堆，由此原則將二值化後的像素
做分區以分割物件。如圖十所示
此影像處理系統其各模組以及其子系統架構圖如下:
ii、特徵抽取
1.人形辨識方法：
在此我們使用 Alan J. Lipton 的分類方法，求出其 Dispersedness 值。其
Dispersedness 原理為：各個物件經過 Sobel 濾波器之後所求得出來的輪
圖六、八向鄰邊偵測法
10
該架構圖黃色部份代表該系統已有功能，粉紅色部份代表目前進行開
(3).機器人動態決策能力系統
智慧代理人的訓練關係到機器人平台是否可以進行正確的動作。在這
個階段中，智慧代理人就像人類的大腦及觸覺感知一樣，CAs 方面則模擬
人類大腦，共有兩種模式使用，主要扮演著人類大腦下決策命令的功能，
第一，目標搜尋模式，此模式為進入 CAs 必先經歷的流程，用意在於判斷
經影像處理過後影像中物件是否為欲搜尋之目標物，若為目標物的情況
下，則記憶該目標物件所在坐標並設定前往目標坐標路徑，在移動過程中
隨時調整目標所在坐標，第二種模式為避開障礙物模式，共有兩種情況會
使 CAs 進入此模式執行，分別:為沒有目標被尋獲以及目標物件位置坐標成
功確認，抵達目標座標前，故此模式將針對障礙物進行閃避的動作，依據
所處環境不同會有不同的指令下達分別為前進、左轉、右轉等情況，執行
終止條件則為抵達目的地，此階段程式使用 Java 進行編碼，首先，讀取經
過前段所述之影像處理後所得影像資料，經過所撰寫的演算法及程式執行
圖七、系統架構圖
12
機器人之路徑規劃及其它較難於現場實際施測的場景，例如在空中、災害
現場等，可藉由 3D 虛擬實境模擬現場環境來訓練系統。
圖八：系統於虛擬實境路徑規劃執行結果
三、 計畫成果自評
本年度針對前兩年度所設計之系統進行修改並整合，成果包括：
1.建置更多種 3D 物件模組及 3D 虛擬空間設計與製作
2.修改影像處方法，使影像處理結果更佳
3.修改 CAs 演算法及參數調整，使指令更能精確下達
4.將系統應用於真實機器人上，進行實地環境測試
經過以上努力，證明機器人可以先於模擬環境中操作，再將之應用於實際環
境中，未來將秉持同樣嚴謹的研究精神持續測試、改進機器人，以期作出判斷更
國科會補助計畫衍生研發成果推廣資料表
日期:2011/04/14
國科會補助計畫
計畫名稱: 子計畫四：影像感測融合技術於機器人環境感知與活動辨識(3/3)
計畫主持人: 程于芳
計畫編號: 98-2218-E-018-001- 學門領域: 智慧型機器人
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
