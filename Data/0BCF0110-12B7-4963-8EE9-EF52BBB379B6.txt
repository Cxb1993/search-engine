information-theory feature weighting methods. Then 
the features with higher weighs are selected into the 
feature vector. However, these methods ignore some 
important information, such as term dependency and 
term correlation. Therefore, we have to analyze the 
impact of pattern dependency to solve the problem. 
The main goal of this project is to develop an 
effective feature selection method and to find an 
efficient way to evolve the patterns by analyzing the 
feature dependency. In this project, a Concept-based 
Pattern Taxonomy Model (CPTM) has been developed and 
the experimental results are compared with those of 
other methods. The results also reveal that the 
proposed model outperforms other methods and the 
effectiveness of system is significantly improved. 
英文關鍵詞： Pattern Taxonomy Model, Web Mining, Pattern 
Dependency 
 
 
 
2 
行政院國家科學委員會補助專題研究計畫成果報告 
樣式依存度問題於網頁探勘之影響研究 
Impact of Pattern Dependency on PTM-based Web Mining Models 
計畫編號：NSC 100-2221-E-468-020- 
計畫主持人：吳勝堂 
執行機構及系所：亞洲大學資訊多媒體應用學系 
 
Abstract 
Along with the fast growth of Internet, the issue of Web Mining has drawn so much attention for 
recent years. Web content mining can be viewed as a sub-field of Text Mining. There are two main 
steps used by a Pattern Taxonomy Model (PTM)-based Web Mining system. First, it uses indexing 
technique to build a feature space. Then the features are transformed into patterns by using pattern 
evolving method for the purpose of implementing classification or information filtering works. 
However, we encounter the problem of how to find a sufficient amount of useful patterns for dealing 
with document indexing. The other problem is how to generate powerful patterns from as less 
features as possible during the step of pattern evolving. The traditional way to form a feature space is 
to adopt either information-retrieval or information-theory feature weighting methods. Then the 
features with higher weighs are selected into the feature vector. However, these methods ignore some 
important information, such as term dependency and term correlation. Therefore, we have to analyze 
the impact of pattern dependency to solve the problem. The main goal of this project is to develop an 
effective feature selection method and to find an efficient way to evolve the patterns by analyzing the 
feature dependency. In this project, a Concept-based Pattern Taxonomy Model (CPTM) has been 
developed and the experimental results are compared with those of other methods. The results also 
reveal that the proposed model outperforms other methods and the effectiveness of system is 
significantly improved. 
 
摘要 
隨著網際網路的快速發展，網頁探勘(Web Mining)的議題一直受到大家的矚目，網頁內容
探勘一般可視為文字探勘(Text Mining)的子範疇，目前以樣式分類模式(Pattern Taxonomy Model)
為基礎的網頁探勘的方法主要分為兩大步驟，第一個步驟是透過文件索引(Indexing)的方式，建
立字詞特徵空間(Feature Space)；第二個步驟則是利用樣式進化 (Pattern Evolving) 技術，轉換
特徵詞成更具描述力的樣式(Pattern)，最後進行文件分類(Classification)或資訊過濾(Information 
Filtering)等相關應用的工作。然而，文件索引所遇到的困難是應如何找到適量且具重要性的特
徵字詞，而樣式進化則是遇到如何以少量字詞整合出更具效能樣式的問題。過去特徵選取的方
式是以傳統資訊檢索(Information Retrieval)或資訊理論(Information Theory)的方法計算特徵權
重，排序之後截取部分重要的字詞組成特徵向量(Feature Vector)。然而，這些方法卻忽略了字
 
 
4 
 
圖 1. 本計畫方法和其他方法的實驗結果比較圖 
 
 
 
 
 
 
II. LITERATURE REVIEW 
The World Wide Web provides rich information on an 
extremely large amount of linked Web pages. Such a 
repository contains not only text data but also multimedia 
objects, such as images, audio and video clips. Data mining 
on the World Wide Web can be referred to as Web mining 
which has gained much attention with the rapid growth in the 
amount of information available on the internet. Web mining 
is classified into several categories, including Web content 
mining, Web usage mining and Web structure mining[9]. 
Data mining is the process of pattern discovery in a 
dataset from which noise has been previously eliminated and 
which has been transformed in such a way to enable the 
pattern discovery process. Data mining techniques are 
developed to retrieve information or patterns to implement a 
wide range of knowledge discovery tasks. In recent years, 
several data mining methods are proposed, such as 
association rule mining[1], frequent itemset mining [21], 
sequential pattern mining [20], maximum pattern mining [6] 
and closed pattern mining [19]. Most of them attempt to 
develop efficient mining algorithms for the purpose of 
finding specific patterns within a reasonable period of time. 
However, how to effectively use this large amount of 
discovered patterns is still an unsolved issue. Therefore, the 
pattern taxonomy mechanism [16] is proposed to replace the 
keyword-based methods by using tree-like taxonomies as 
concept representatives.  Taxonomy is a structure that 
contains information describing the relationship between 
sequence and sub-sequence [18]. In addition, the 
performance of PTM-based models is improved by adopting 
the closed sequential patterns. The removal of non-closed 
sequential patterns also results in the increase of efficiency of 
the system due to the shrunken dimensionality. 
III. CONCEPT-BASED PTM MODEL 
Concept-based PTM (CPTM) model is developed using a 
sentence-based framework proposed to address the text 
classification problems. CPTM adopts the NLP techniques 
by parsing and tagging each word based on its POS and 
generating semantic patterns as a result [15]. Different from 
the traditional approaches, CPTM treats each sentence as a 
unit rather than entire article during the phase of semantic 
analysis. In addition, the weight of terms (words) or phrases 
is estimated according to their statistical characteristics (such 
as the number of occurrences) in the traditional methods. 
However, words may have different descriptive capabilities 
even though they own exactly the same statistic value. 
Therefore, the more effective conceptual patterns that are 
obtained, more precisely the system can determine the 
concept. 
How can we get more useful conceptual patterns by using 
NLP techniques? Below is our strategy to be described. An 
example sentence is stated as follows: 
“We have investigated that the Data Mining field, 
developed for many years, has encountered the issues of 
low frequency and high dimensionality.” 
 
In this sentence, we can first label the words based on 
their POS. The verbs, written in bold, then can be used as 
node in a specific structure to describe the semantic meaning 
of sentence. By expanding words from each verb, a structure 
called “Verb-Argument” [10] is formed, which is defined as 
a conceptual pattern in this study. The following conceptual 
patterns are obtained from the example sentence using the 
above definition: 
 
 [ARG0 We] have [TARGET investigated] [ARG1 Data 
Mining filed, developed for many years, has encountered the 
issues of low frequency and high dimensionality] 
 
 [ARG1 Data Mining filed] [TARGET developed] 
[ARGM-TMP for many years] has encountered the issues 
of low frequency and high dimensionality 
 
 [ARG1 Data Mining filed developed for many years] 
has [TARGET encountered] [ARG2 the issues of low 
frequency and high dimensionality]  
 
TARGET denotes the verb in the sentence. ARG0, 
ARG1 and ARGM-TMP are arguments appeared around 
TARGET. Therefore, a set of "Verb-Argument" can be 
discovered while applying it to a whole document. After the 
above process, our proposed CPTM can then analyze these 
conceptual patterns in the next phase. 
From the data mining point of view, the conceptual 
patterns are defined as two types: sequential pattern and non-
sequential pattern. The definition is described as follows: 
Firstly, let T = {t1, t2, ..., tk} be a set of terms, which can be 
viewed as words or keywords in a dataset. A non-sequential 
pattern is then a non-ordered list of terms, which is a subset 
of T, denoted as {s1, s2, ..., sm} (si ∈ T). A sequential pattern, 
defined as S = 〈s1, s2,...,sn 〉 (si∈T), is an ordered list of terms. 
Note that the duplication of terms is allowed in a sequence. 
This is different from the usual definition where a pattern 
consists of distinct terms. 
After mining conceptual patterns, the relationship 
between patterns has to be defined in order to establish the 
pattern taxonomies. Sub-sequence is defined as follows: if 
there exist integers 1 ≤ i1 ≤ i2 ≤ … ≤ in ≤ m, such that a1 = bi1, 
a2 = bi2,..., an = bin, then a sequence α = 〈a1, a2,...,an〉 is a sub-
sequence of another sequence β = 〈b1, b2,...,bm〉. For example, 
sequence 〈s1, s3〉 is a sub-sequence of sequence 〈s1, s2, s3〉. 
However, sequence 〈s3, s1〉 is not a sub-sequence of 〈s1, s2, s3〉  
since the order of terms is considered. In addition, we can 
also say sequence 〈s1, s2, s3〉 is a super-sequence of 〈s1, s3〉. 
The problem of mining sequential patterns is to find a 
complete set of sub-sequences from a set of sequences whose 
support is greater than a user-predefined threshold (minimum 
support). 
We can then acquire a set of frequent sequential concept- 
patterns CP for all documents d ∈ D+, such that CP = {p1, 
p2,…, pn}. The absolute support suppa(pi) for all pi ∈ CP is 
obtained as well. We firstly normalize the absolute support 
of each discovered pattern based on the following equation: 
Figure 4 indicates the primary result of pattern analysis 
using Propbank scheme. The marked terms in parentheses 
are the verbs defined by Propbank. All of the conceptual 
patterns then can be generated by adopting “Verb-
Argument” frame basis. At the next stage, IPE and DPE 
methods are used for pattern evolving. Figure 5 illustrates the 
output of pattern discovery using CPTM for example.  
 
Sentence no. 1 
[polic] [search] properti [own] marc dutroux chief [suspect] 
belgium child sex [abus] [murder] [scandal] tuesdai [found] 
decompos bodi two adolesc adult medic sourc 
Sentence no. 2 
[found] two bodi [advanc] [state] decomposit sourc told 
[condit] anonym 
: 
: 
: 
Sentence no. 7 
fate two girl [remain] mysteri 
Sentence no. 8 
belgian girl gone [miss] recent year 
 
Figure 4. The primary result of pattern analysis.    
 
 
Figure 5. The output of pattern discovery. 
 
In additional, the effect from the patterns derived from 
negative examples cannot be ignored due to their useful 
information[11]. There is no doubt that negative documents 
contain much useful information to identify ambiguous 
patterns during the concept learning. Therefore, it is 
necessary for a CPTM system to exploit these ambiguous 
patterns from the negative examples in order to reduce their 
influences. Algorithm NDP is shown as the follow. 
 
Algorithm NDP(Ω, D+, D-) 
Input: A list of deployed patterns Ω; a list of positive and 
negative documents D+ and D-. 
Output: A set of term-weight pairs d. 
Method: 
1:  d ← Ø 
2:  τ = Threshold(D+) 
3:  foreach negative document nd in D-  
4:    if Threshold({nd}) > τ 
5:    ∆p = {dp in Ω | termset(dp) ∩ nd ≠ Ø } 
6:    Weight shuffling for each P in ∆p 
7:    end if 
8:    foreach deployed pattern dp in Ω  
9:      d ← d pattern merging dp 
10:   end for 
11:  end for 
 
IV. EXPERIMENTAL RESULTS 
The effectiveness of the proposed CPTM Web mining 
model is evaluated by performing information filtering task 
with real Web dataset RCV1. The experimental results of 
CPTM are compared to those of other baselines, such as 
TFIDF, Rocchio, BM25[12] and support vector machines 
SVM[2, 7, 8], using several standard measures. These 
measures include Precision, Recall, Top-k (k = 20 in this 
study), Breakeven Point (b/e), Fβ-measure, Interpolated 
Average Precision (IAP) and Mean Average Precision 
(MAP).  
 
 
Table 1. Contingency table. 
 
The precision is the fraction of retrieved documents that 
are relevant to the topic, and the recall is the fraction of 
relevant documents that have been retrieved. For a binary 
classification problem the judgment can be defined within a 
contingency table as depicted in Table 1. According to the 
definition in this table, the measures of Precision and Recall  
are denoted as TP/(TP+FP) and TP/(TP+FN) respectively, 
where TP (True Positives) is the number of documents the 
system correctly identifies as positives; FP (False Positives) 
is the number of documents the system falsely identifies as 
positives; FN (False Negatives) is the number of relevant 
documents the system fails to identify. 
The precision of top-K returned documents refers to the 
relative value of relevant documents in the first K returned 
documents. The value of K we use in the experiments is 20, 
denoted as "t20". Breakeven point (b/e) is used to provide 
another measurement for performance evaluation. It indicates 
the point where the value of precision equals to the value of 
recall for a topic. 
Both the b/e and F1-measure are the single-valued 
measures in that they only use a figure to reflect the 
performance over all the documents. However, we need 
more figures to evaluate the system as a whole. Therefore, 
at trec," Information Processing and Management, 
vol. 36, pp. 95-108, 2000. 
[13] T. Rose, M. Stevenson, and M. Whitehead, "The 
reuters corpus volume1- from yesterday's news to 
today's language resources," in Inter. Conf. on 
Language Resources and Evaluation, 2002, pp. 29-
31. 
[14] F. Sebastiani, "Machine learning in automated text 
categorization," ACM Computing Surveys, vol. 34, 
pp. 1-47, 2002. 
[15] S. Shehata, F. Karray, and M. Kamel, "A concept-
based model for enhancing text categorization," in 
KDD, 2007, pp. 629-637. 
[16] S.-T. Wu, Y. Li, and Y. Xu, "An effective 
deploying algorithm for using pattern-taxonomy," 
in iiWAS05, 2005, pp. 1013-1022. 
[17] S.-T. Wu, Y. Li, and Y. Xu, "Deploying 
approaches for pattern refinement in text mining," 
in ICDM, 2006, pp. 1157-1161. 
[18] S.-T. Wu, Y. Li, Y. Xu, B. Pham, and P. Chen, 
"Automatic pattern-taxonomy extraction for web 
mining," in IEEE/WIC/ACM International 
Conference on Web Intelligence, 2004, pp. 242-248. 
[19] X. Yan, J. Han, and R. Afshar, "Clospan: mining 
closed sequential patterns in large datasets," in 
SIAM Int. Conf. on Data Mining (SDM03), 2003, 
pp. 166-177. 
[20] C.-C. Yu and Y.-L. Chen, "Mining sequential 
patterns from multidimensional sequence data," 
IEEE Transactions on Knowledge and Data 
Engineering, vol. 17, pp. 136-140, 2005. 
[21] S. Zhang, X. Wu, J. Zhang, and C. Zhang, "A 
decremental algorithm for maintaining frequent 
itemsets in dynamic databases," in International 
Conference on Data Warehousing and Knowledge 
Discovery (DaWaK05), 2005, pp. 305-314. 
 
 
 
 2 
本團隊此次 IC2IT 2012會議之行主要是參與其中關於Web Mining(網頁探勘)主題的研討會，近
幾年來，隨著網際網路的快速發展，網頁探勘的議題一直受到大家的矚目，其重要的關鍵在於系
統是否能夠快速地回應使用者的需求，並著重資訊擷取的精確性，避免提供使用者過多不相關的
內容。本團隊所發表的主題為「應用語意基礎的樣式分類網頁探勘模式」(Web Mining Using 
Concept-based Pattern Taxonomy Model)，其內容為發展一有效的特徵選取 (Feature Selection) 方
法，藉由分析樣式依存度 (Pattern Dependency) 的問題，建立更具效能的樣式進化 (Pattern Evolving) 
方案，最後整合於以樣式分類模型 (Pattern Taxonomy Model) 為基礎的網頁探勘 (PTM-based Web 
Mining) 系統，以解決上述的問題。其他的團隊則偏重於套用既有的方法，以不同的應用層面評估
其系統的效能。 
此次參與 IC2IT 2012會議的另一個重點，是藉機和其他團隊進行相互交流，本人也把握住這難
得的機會，就研究成果和所發現知識與他人討論，交流了目前的研究階段與方向，除此之外，也
利用了會議的餐會時間，向來自其他國家相關領域的研究先進們請教並分享彼此的研究心得，分
享了各自實驗中演算法的優弱勢，進而對於現今研究階段中的演算法有了新的啟示與方向，對於
往後的研究之路，實是受益良多。另外，本人於會議開始前一日已先行抵達泰國，故也藉此機會
造訪了曼谷一些知名景點，增進不少自我的人文素養與國際觀。 
三、建議 
銘謝 貴會提供研究經費的補助才造就此行，本人在會議的參與中，不但有了一次與其他國家
的研究先進更為深入的面對面交流機會，同時也增強了自我的國際視野與研究方向，希望往後還
繼續獲得 貴會的補助，以高水平的研究成果參與重要的國際研討會。 
四、攜回資料名稱及內容 
本次研討會攜回研討會論文集一本以及論文集光碟一片，內容為所有研究團隊的成果發表論
文。 
五、論文接受通知 
 
100年度專題研究計畫研究成果彙整表 
計畫主持人：吳勝堂 計畫編號：100-2221-E-468-020- 
計畫名稱：樣式依存度問題於網頁探勘之影響研究 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 1 1 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 1 1 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 1 1 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 1 1 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
