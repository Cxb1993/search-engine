Page 2 of 31 
以基因演算法建立高性能混凝土材料行為模式 
計劃編號：NSC-96-2221-E-216-032- 
執行期限：96/08/01~97/07/31 
主持人：葉怡成  中華大學土木工程學系 教授 
 
摘要 
迴歸分析可以建立外顯的公式來預測高性能混凝土強度，但其產生之公式精確性不
良；倒傳遞網路能夠建立相當精確的模型，但無法產生一個外顯的公式；而演化運算樹
能產生外顯的公式，其預測的準確度介於迴歸分析與倒傳遞網路之間。此外，雖然演化
運算樹能產生公式，但公式經常過於複雜，以致無法解釋其中的意義。因此，本研究發
展出一個後向刪除法，來簡化演算運算樹公式的複雜性，這個公式嘗試用「中位常數」
替代樹型枝葉端的「變數」，以簡化公式的複雜性，並維持公式的準確度。為了驗證本
法的優點，本研究以 404 筆實驗數據，比較逐步迴歸、逐步倒傳遞網路、修剪的演化運
算樹三者的模型準確度與複雜答。實證結果顯示，在修剪的演化運算樹可以產生一個簡
化但準確的高性能混凝土強度預測公式。 
 
關鍵字：倒傳遞網路、演化運算樹、高性能混凝土、向後式修剪技術、中位數。 
 
 
 
 
 
Page 4 of 31 
一、前言 
高性能混凝土[1]之主要材料組成除了傳統混凝土之水、水泥、粗骨材及細骨材基
本構材外，並添加了許多填充膠結料，例如爐石、飛灰，及其它化學摻料，例如強塑劑，
除了提升材料主要性質之高強度與工作度外，同時兼顧耐久性、安全性、工作性、經濟
性及生態性之需求[2]。傳統建立預測模型的關係式是以統計的方法，例如多變數線性
迴歸分析(Linear Regression Analysis, LRA)等，雖可產生預測之公式，唯其準確度較低，
因此將其應用在複雜的高性能混凝土非線性系統模型並不可行。 
在過去，已有相當多的研究應用倒傳遞網路[3](Back-Propagation Network, BPN)於
材料的領域，雖然文獻提出許多建構混凝土強度模型的方法[4-12]，並能準確的預測混
凝土之強度行為，但無法提出合理且讓人理解之材料行為模型公式。為解決產生明確公
式的問題，許多研究者提出了人工智慧中演化式計算的方法[4-6, 11, 12]。遺傳演算法
(Genetic Algorithms, GA)是人工智慧中演化式計算的一門分支，其依據自然演化及適者
生存的觀念衍生而成[13, 14]，模擬遺傳的選擇、交配、突變等機制。其強韌性以及平
行處理能力，能夠在各種不同的環境裡讓效率與精確率達到平衡[15]，並且適用於解答
空間大、複雜、非線性的問題。 
從過去文獻[12]的預測準確度及模型可解釋的能力可知，遺傳演算法結合運算樹
(Genetic Algorithms of Operation Tree)的演化運算樹(Genetic Operation Tree, GOT)方法確
實是一個可以產生自組織公式的方法，其產生之公式準確度低於倒傳遞網路，卻遠比迴
歸分析(Regression Analysis, RA)及其它已經發表的文獻[4-6]好。雖然演化運算樹與迴歸
分析同樣能產生模型公式，但卻有公式過度複雜的問題，使得雖然有公式但確難以解讀
其意義。 
為解決公式過度複雜的問題，本研究提出一個運算樹修剪技術(Pruning Technique, 
Page 6 of 31 
 
運算樹可用在數據的迴歸問題上，其方法是在運算樹的節點設定適當的運算子及運
算元，使此樹狀構對應的數學公式能最配適數據，即能使將數據的自變數代入公式下產
生的因變數預測值，與數據的因變數實際值之間的誤差平方和最小化。利用運算樹的結
構可以突破傳統迴歸分析的公式結構必須預設，迴歸分析只能作調整迴歸係數的工作的
瓶頸。但運算樹是一個離散資料結構，故無法像迴歸分析一樣以微積分中的極值定理導
出解迴歸係數的聯立方程式，即用運算樹來迴歸數據是一個離散最佳化問題。因此，本
研究採用具有解離散最佳化問題能力的遺傳演算法，來建構最配適數據的運算樹。 
 
2. 遺傳演算法 
遺傳演算法是近年來極具發展潛力的最佳化方法。它以獨特的搜尋方式，可跳離局
部最佳值，並趨近整體最佳值。此方法最早於1975年由Holland所發展，並出版Adaptation 
in Natural and Artificial System一書。遺傳演算法的概念源自於達爾文「物競天擇，適者
生存」的想法，即仿效自然界生物生存競爭機制，較能適應環境的個體有較高的存活機
會，這些個體透過兩兩交配的方式產生後代個體，而後代藉由組合前代個體的基因而擁
有近似但不同於前代個體的特性，此外基因突變也產生一些變異。新的一代也在生存競
爭的機制下產生下一代，如此一代接一代，個體將朝向最能適應環境的方向演化。而遺
傳演算法以「最佳化問題」為「演化問題」；以「解答」為「個體」；「解答的最佳化」
過程為「個體的演化」過程，使解答能逼近最佳解。 
遺傳演算法的要點如下[12]： 
z 染色體的編碼與解碼(encoding and decoding)：在遺傳演算法中，一個解答由許多個
染色體構成，將解答以染色體表達稱為編碼；反之，將染色體表達成解答稱為解碼。
例如，將一個數學公式以運算樹來表達可視為一種編碼法；反之，將一個運算樹表
Page 8 of 31 
保證適應度最高的個體一定能存活。此策略可確保最終世代的最佳個體是整個演化
過程所產生的所有個體中的最佳個體。一個完整的遺傳演算法程序可參考圖 3。 
 
 
圖 3  遺傳演算法流程圖 
 
3. 運算樹的修剪 
遺傳演算法產生的運算樹的末端節點為「變數」者，可考慮改用樣本變數中位數之
「常數」來替代，即修剪運算樹，以簡化公式。因此可令末端節點修剪與否為二元狀態：
維持「變數」狀態、改用樣本變數中位數之「常數」狀態，即不修剪與修剪二種狀態。
本研究提出二種修剪方式： 
(1) 窮盡式修剪法：當運算樹有N個「變數」的末端節點時，二元狀態有 N2 個組合，即
運算樹有 N2 個修剪方式。當N不是很大，例如10以下時，可以進行窮盡式的搜尋。 
(2) 後向式修剪法：當N很大時，窮盡式的搜尋不可行，此時可用類似逐步迴歸中的後
向刪除法，即先嘗試修剪一個最不會降低運算樹預測準確度的末端節點；接著在修
剪該末端節點下，再嘗試修剪第二個最會降低運算樹預測準確度的末端節點；如此
開始 
產生第一代個體族群 
計算個體適應度 
交配 
突變 
結果收斂 結束 
子代取代母代
Yes 
No 
再次演化
Page 10 of 31 
表 1  強度資料中各變數的值域及型態 
變數名稱 值域 單位 型態 
C 71.00~896.00 Kg/m3 連續 
FL 0.00~200.10 Kg/m3 連續 
SL 0.00~359.40 Kg/m3 連續 
W 118.00~314.00 Kg/m3 連續 
SP 0.00~32.20 Kg/m3 連續 
CA 595.00~1820.00 Kg/m3 連續 
FA 486.00~1300.00 Kg/m3 連續 
W/C 0.24~2.73 比例 連續 
W/B 0.24~0.90 比例 連續 
W/S 0.04~0.13 比例 連續 
TA/B 2.18~9.85 比例 連續 
自變數 
'
cf  1238.00~17691.00 psi 連續 因變數 
其中 W/C=(W+SP)/(C)、W/B=(W+SP)/(C+FL+SL)、W/S=(W+SP)/(C+FL+SL+CA+FA)、
TA/B=(CA+FA)/(C+FL+SL)。 
 
2. 運算樹規則及基因編碼方式 
本研究為產生自組織公式，採用了運算樹的公式表達方式。圖 4 為一個五層的運算
樹示意圖，而運算樹的運算子及運算元的編碼方式如表 2 及表 3 所示。其中： 
z 第一層的節點(X1)限使用運算子，因此值域為 1~6 的整數； 
z 第二、三、四層節點(X2~X15)可使用運算子或運算元，因此值域為 1~18 的整數，
其中當編碼為 18 時，代表使用常數 K，而 K 的值域限定為-100~100 的連續數值； 
z 第五層的節點(X16~X31)限使用運算元，因此值域為 7~18 的整數。 
此外，此樹狀結構遵守下列規則： 
z 當節點使用 ln 運算子時，則此運算子只對「左」節點運算。 
z 當節點使用運算元(變數或常數)時，則該節點下方的節點將被忽略。 
 
 
 
Page 12 of 31 
度值筆資料的運算樹預測強第
筆資料的實際強度值第
強度平均值所有資料的運算樹預測
均值所有資料的實際強度平
 i 
 i 
=
=
=
=
i
i
f
y
f
y
 
 
4. 適應度函數 
本研究以訓練範例的誤差均方根(Root of Mean Square, RMS)最小化作為適應度函
數，並以測試範例的誤差均方根評估產生的預測公式是否具有普遍性。RMS 公式如下： 
n
yy
RMS
n
i
ii∑
=
−
= 1
2)ˆ(
………………………………………...……………………………(4) 
其中 iyˆ 為第 i 筆資料的預測強度值； iy 為第 i 筆資料的實際強度值；n 為訓練範例或測
試範例之總筆數。 
 
5. 演算法參數設定 
文獻[16]建議的遺傳演算法參數設定為：(一)交配後產生之個體數 10~200 個；(二)
交配率設定為 0.4~0.99；(三)突變率設定為 0.0001~0.1。本研究所採用之遺傳演算法參
數設定為：(一)交配後產生之個體數設定為 100 個；(二)交配率設定為 0.9；(三)突變率
設定為 0.001。此外，使用精英策略強迫保留目前為止所搜尋到的最佳個體，並設定收
斂條件為連續 1000 個世代不再進步則停止程式。 
 
四、結果 
1. 修剪前的運算樹 
遺傳演算法的解答具有隨機性，因此本研究以不同的亂數種子執行三次，得到如圖
5~7 的演化運算樹，運算樹的相應預測公式如下。 
Page 14 of 31 
表 4  GOT 修剪前的統計數據 
組別 訓練 RMS 測試 RMS
1 1320 1561 
2 1348 1466 
3 1320 1539 
 
R2 = 0.8137
0
5000
10000
15000
20000
0 5000 10000 15000 20000
實際強度值(psi)
預
測
強
度
值
(p
si)
R2 = 0.8245
0
5000
10000
15000
20000
0 5000 10000 15000 20000
實際強度值(psi)
預
測
強
度
值
(p
si)
圖 8  第一組 GOT 訓練範例強度散佈圖 圖 9  第一組 GOT 測試範例強度散佈圖 
 
R2 = 0.8056
0
5000
10000
15000
20000
0 5000 10000 15000 20000
實際強度值(psi)
預
測
強
度
值
(p
si)
R2 = 0.848
0
5000
10000
15000
20000
0 5000 10000 15000 20000
實際強度值(psi)
預
測
強
度
值
(p
si)
圖 10 第二組 GOT 訓練範例強度散佈圖 圖 11  第二組 GOT 測試範例強度散佈圖 
 
Page 16 of 31 
BW
Cy
/
43.2)ln(84.94283.865 −×+−= ..................................................................................(9) 
 
BW
Cy
/
)ln(84.61857.1888 ×+−= ........................................................................................(10) 
 
BW
CWy
/
43.2)/ln(86.96560.272 −×−−= ....................................................................... (11) 
 
公式(9)與(10)顯示，在水膠比相同下，水泥用量越大強度越高。在公式(11)中，因水灰
比常小於 1.0，故 ln(W/C)幾乎不可能大於 2.43，故 ln(W/C)-2.43 幾乎可以肯定小於 0，
因此(11)式與(9)式、(10)式一樣，都顯示強度與水膠比成反比。將(11)式改寫成 
 
( )
BW
CWy
/
12347)/ln(86.96560.272 ×+⋅−+−= .................................................... (11) 
 
可知水灰比越小，因其 ln(W/C)為負值，故強度越大。 
Page 18 of 31 
 
 
步驟 公式二 
1. 未進行修剪之模型 
 
2. 修剪一個末端變數節點 
 
3. 修剪二個末端變數節點 
 
4. 修剪三個末端變數節點 
 
5. 修剪四個末端變數節點 
 
÷
× ㏑
C – W/B
＋ ÷
185.7 5.27 4.26 ㏑
281.4 
÷
× ㏑
C – W/B
＋ ÷
185.7 SP 4.26 ㏑
281.4 
÷
× ㏑
C – W/B
＋ ÷
W SP 4.26 ㏑
281.4 
÷
× ㏑
C – W/B
＋ ÷
W SP 4.26 ㏑
C 
÷
× ㏑
C – W/B
＋ ÷
W SP TA/B ㏑
C 
Page 20 of 31 
 
步驟 公式三 
1. 未進行修剪之模型 
 
2. 修剪一個末端變數節點 
 
3. 修剪二個末端變數節點 
 
 
圖 16  第三組 GOT 的修剪過程 
 
表 7  第三組 GOT 修剪過程的統計數據 
步
驟 公式 
訓練
2R  
測試
2R  
訓練
RMS 
測試
RMS 
1 
BW
SWCWy
/
)//ln(06.87140.263 ××−= 0.81 0.84 1320 1538 
2 
BW
CWy
/
43.2)/ln(86.96560.272 −×−−= 0.81 0.81 1339 1663 
3 
BW
y
/
29.413495.3313 +−=  0.76 0.76 1483 1880 
 
÷ 
W/B ㏑
×
0.683 0.088
÷ 
W/B ㏑
×
W/C 0.088
÷ 
W/B ㏑
×
W/C W/S
Page 22 of 31 
2. 模型的測試範例評估：在刪減變數過程中，測試範例的準確度在刪前六個變數時，
反而有遞增的趨勢，這顯示使用 11 個變數的模型有過度配適的現象，因此簡化的
模型其「普遍化」預測能力反而獲得提升。 
 
表 8  逐步迴歸之後向刪除法 
步
驟 公式 
訓練
2R
測試
2R  
訓練
RMS 
測試
RMS
丟棄
變數
1 
BTASW
BWCW0AGEFACA
SPWSLFLCfc
/69.993/70.561452
/82.7539/44.34024.3923.99
8.0673.2741336.4635.0046.1490.36390-'
−+
+−+++
−−+++=
0.82 0.68 1313 2241 None
2 
BTA
SWBWFACA
SPWSLFLCfc
/69.880
/9.555362/38.588923.7023.39
0.9473.8735335.2133.7121.1450.55143-'
−
++++
−−+++=
0.82 0.69 1314 2210 W/C
3 
BTASWAFCA
SPWSLFLCfc
/44.341/2.57914331.2384.22
50.36989.33399.3433.2009.14-36644.20'
−+++
−−+++=
0.82 0.68 1315 2233 W/B 
4 
BTASWCA
SPWSLFLCfc
/787.214/31.9199099.0
78.14323.11369.1428.1245.2109.14171'
−++
−−+++=  0.80 0.81 1374 1682 FA 
5 
BTASW
SPWSLFLCfc
/72.264/77.72477
13.14064.10459.1337.1144.20127.8631'
−+
−−+++=  0.80 0.81 1377 1711 CA 
6 
SW
SPWSLFLCfc
/32.91558
43.14835.11414.1796.1486.2346.10648'
+
−−+++=  0.80 0.81 1380 1710 TA/B
7 SPWSLFLCfc 53.10152.6638.1641.1479.2155.10386
' −−+++=  0.78 0.81 1420 1680 W/S 
8 WSLFLCfc 42.5932.1482.878.2043.9274
' −+++=  0.77 0.76 1483 1873 SP 
9 WSLCfc 11.6175.1150.1831.10871
' −++=  0.74 0.77 1559 1833 FL 
10 WCfc 89.5783.1492.12238
' −+=  0.65 0.73 1809 2005 SL 
11 Cfc 30.16752.1254
' +=  0.45 0.47 2258 2819 W 
 
4. 神經網路 
本研究以 11-11-1(11 輸入、11 節點、1 輸出)的倒傳遞網路來做為準確度的比較，
其中網路的設定值如下所示： 
z 初始權值範圍= ±0.3 
z 學習速率=1.0 
z 學習速率衰減率=0.99 
z 學習速率下限值=0.1 
z 慣性因數初始值=0.5 
z 慣性因數衰減率=0.99 
Page 24 of 31 
表 9  逐步神經網路 
步驟 訓練 2R  測試 2R 訓練 RMS 測試 RMS 丟棄變數 
1 0.85 0.88 1173 1280 None 
2 0.87 0.83 1097 1554 W/C 
3 0.87 0.87 1096 1378 W/B 
4 0.87 0.87 1105 1380 CA 
5 0.87 0.88 1117 1307 FA 
6 0.84 0.87 1133 1329 TA/B 
7 0.85 0.87 1194 1352 W/S 
8 0.81 0.79 1331 1704 SP 
9 0.77 0.82 1458 1617 FL 
10 0.69 0.76 1713 1851 SL 
11 0.5 0.5 2176 2654 W 
 
5. 各方法的比較 
表 10 及表 11 與圖 17 至圖 20 為上述方法的在模型準確度及複雜度的比較。模型的
準確度指的是對於問題的預測能力，亦即 RMS 越小則表示準確度越優；模型的複雜度
由變數數目或節點數目來表示，數目越大模型越複雜，其可理解性越低。由表及圖可知： 
z 複雜度：在節點或變數數目大於五以上，準確度由高而低是逐步神經網路、GOT、
逐步迴歸；但在節點或變數數目小於三以下時，逐步神經網路、逐步迴歸的準確度
開始劇降，而GOT的準確度並沒有發生劇降的情況，準確度由高而低變成GOT、逐
步神經網路、逐步迴歸。 
z 複雜度：上述三組GOT產生的運算樹模型所使用的變數為3~6個，其訓練範例R2平均
為0.81及RMS平均為1329。而逐步迴歸需要使用9個變數、神經網路需要使用4個變
數以上方能達到相同的準確度。顯示在相同的預測準確度下，模型複雜度由低而高
是逐步神經網路、GOT、逐步迴歸。 
因此，本研究提出的修剪法是一個可以簡化 GOT 產生的 28 天高性能混凝土強度公
式，但簡化過程不會導致準確度劇降的方法。 
 
Page 26 of 31 
0.4
0.5
0.6
0.7
0.8
0.9
1.0
01234567891011
變數或節點數
R
^2
第一組GOT測試範例 第二組GOT測試範例
第三組GOT測試範例 逐步迴歸測試範例
逐步神經網路測試範例  
圖 18  各種方法的測試範例 2R 比較折線圖 
 
表 11  各種方法的 RMS 比較 
第一組 GOT 第二組 GOT 第三組 GOT 逐步迴歸 逐步神經網路
變數或節點數 訓練
範例
測試 
範例 
訓練
範例
測試
範例
訓練
範例
測試
範例
訓練
範例
測試 
範例 
訓練 
範例 
測試
範例
11 NA NA NA NA NA NA 1313 2241 1173 1280
10 NA NA NA NA NA NA 1314 2210 1097 1554
9 NA NA NA NA NA NA 1315 2233 1096 1378
8 NA NA NA NA NA NA 1374 1682 1105 1380
7 NA NA NA NA NA NA 1377 1711 1117 1307
6 NA NA 1348 1466 NA NA 1380 1710 1133 1329
5 NA NA 1347 1467 NA NA 1420 1680 1194 1352
4 1320 1567 1347 1467 NA NA 1483 1873 1331 1704
3 1345 1623 1363 1706 1320 1538 1559 1833 1458 1617
2 1412 1848 1389 1815 1339 1663 1809 2005 1713 1851
1 1482 1880 1483 1880 1483 1880 2258 2819 2176 2654
 
Page 28 of 31 
 
五、結論及建議 
本文研究結論歸納如下： 
1. 採用本研究所提出的向後式修剪法進行演化運算樹的修剪，其最後存留的公式型態
皆相同，顯示其產生的公式具備穩定性，且皆認為預測 28 天高性能混凝土強度的最
重要的變數為水膠比(W/B)，並認為水膠比與強度成反比，這樣的結果與實務上符合。 
2. 逐步神經網路刪減變數的順序與準確度變化的歷程與逐步迴歸分析十分接近，即最
後三個被刪除的變數依序都是水飛灰用量(FL)、爐石用量(SL)、水用量(W)，最後只
剩水泥用量(C)；在刪減變數過程中，測試範例的準確度在刪前六個變數時，反而有
遞增的趨勢，這顯示使用 11 個變數的模型有過度配適的現象，因此簡化的模型其「普
遍化」預測能力反而獲得提升。 
3. 在模型準確度的比較方面，在節點或變數數目大於五以上，準確度由高而低依序是
逐步神經網路、GOT、逐步迴歸；但在節點或變數數目小於三以下時，逐步神經網
路、逐步迴歸的準確度開始劇降，而 GOT 的準確度並沒有發生劇降的情況，準確度
由高而低變成 GOT、逐步神經網路、逐步迴歸。 
4. 在模型複雜度的比較方面，GOT 產生的運算樹模型所使用的變數為 3~6 個，其訓練
範例 R2 平均為 0.81 及 RMS 平均為 1329。而逐步迴歸需要使用 9 個變數、神經網路
需要使用 4 個變數以上方能達到相同的準確度。顯示在相同的預測準確度下，模型
複雜度由小而大依序是逐步神經網路、GOT、逐步迴歸。 
綜合以上四點，可以證明本研究提出的修剪法是一個可以產生簡化，但能保持高準
確度的 HPC 強度公式的方法。 
未來研究方向包括： 
Page 30 of 31 
新竹市 (1995)。 
9. Hamid-Zadeh, N., Jamali, A., Nariman-Zadeh, N., and Akbarzadeh, H., “Prediction of 
concrete compressive strength using evolved polynomial neural networks,” WSEAS 
Transactions on Systems Vol.6, No.4, pp. 802-807 (2007). 
10. Ahmet O., Murat P., Erdogan O., Erdogan K., Naci C., and Bhatti M. A., “Predicting the 
compressive strength and slump of high strength concrete using neural network,” 
Construction and Building Materials Vol.20, pp.769-775 (2006). 
11. 連立川、葉怡成、張皓博、謝明勳，「以遺傳演算法及運算樹作高性能混凝土工作度
建模」，2005 營建技術暨管理研討會，斗六市 (2005)。 
12. 連立川、葉怡成、鄭明淵，「以遺傳演算法及運算樹作高性能混凝土強度建模」，技
術學刊，第二十一卷，第一期，第 41-54 頁 (2006)。 
13. Davis, L., Handbook of Genetic Algorithms, Van Nostrand Reinhold, NY. (1991). 
14. Holland, J. H., Adaptation in Natural and Artificial System, University of Michigan Press, 
Ann Arbor. (1975). 
15. Goldberg, D. E., Genetic Algorithms in Search Optimization and Machine Learning, 
Addison-Wesley Publishing Company. (1989). 
16. 雷英杰、張善文、李續武、周創明，MATLAB 遺傳算法工具箱及應用，西安電子科
技大學出版社 (2005)。 
