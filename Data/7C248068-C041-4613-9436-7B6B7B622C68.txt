aim of computing spatially localized bases from a face 
database by adding three constraints that modify the 
objective function in the original NMF algorithm. But 
this method has a slow speed for learning the bases. 
Then, Guillamet and Vitrià adopt one relevant metric 
called Earth Mover's Distance (EMD) [17] for parts-
based representation of NMF. However, the 
computation of EMD is too time-demanding. Recently 
Hoyer incorporated the notion of sparseness to improve 
the found decompositions, and then proposed a method 
called Non-Negative Matrix Factorization with 
Sparseness Constraints (NMFSC) [20] [21]. But its 
recognition accuracy is not better than that of PCA. 
In this paper, a novel subspace method is proposed, 
called Basis-emphasized Non-negative Matrix 
Factorization with Wavelet Transform (wBNMF), for 
learning intuitive parts-based representation of visual 
pattern with noise reduction [22] [23]. Inspired by 
previous work, our aim is to impose orthonormal 
characteristic on basis components and to make the 
representation more suitable for tasks where feature 
localization is important. This paper also investigates 
how to improve the face recognition accuracy based on 
wBNMF [24] [25] [26] [27] [28] [29]. For better 
performance, we adopt the Riemanian metric distance 
for the learned feature vectors instead of the Euclidean 
distance [18] [19]. Experiments on the widely used AR 
face database demonstrate the proposed method can 
improve recognition accuracy and even outperform 
PCA. 
 
2. FACE DATABASE 
 
2.1. CBCL face database 
 
There are 2429 faces and 4548 non-faces in the 
training set. The testing set consists of 472 faces, 23573 
non-faces. Each image is 19 ×  19 grayscale PGM 
format. Figure 1 shows some sample images from the 
database. 
 
 
 
Figure 1: Face examples from the CBCL database. 
 
2.2. ORL face database 
 
There are 400 face images of 40 persons, 10 images per 
person which are shown in Fig. 2. The original 
dimension of each image is 112 × 92. These images are 
taken at different times, slightly varying lighting, facial 
expressions (open/closed eyes, smiling/non-smiling) 
and facial details (glasses/no-glasses). All the images 
are taken against a dark homogeneous background. The 
faces are in up-right position of frontal view, with 
slight left-right out-of-plane rotation. Each image is 
linearly stretched to the full range of pixel value within 
[0, 255]. In Fig. 3, the ORL faces are re-aligned in the 
center of the original images. The redundancy region of 
each image, non-facial feature, is eliminated to avoid 
undesired noise in face image analysis. The dimension 
of the normalized ORL face image is 48 × 48. 
 
 
 
Figure 2: Face examples from the ORL database. 
 
 
 
Figure 3: Face examples from the normalized ORL 
database. 
 
2.3. AR face database 
 
The AR color face database contains images of 126 
individuals (70 males and 56 females). Original images 
are 768 × 576 pixels in size with 24-bit color resolution.  
A total of 13 photos are taken from each individual 
with each shot taken under different conditions as 
shown in Fie. 4. These same shots are taken again after 
two weeks interval in another session. For our 
experiments, only 200 face images (50 males and 50 
females) of 13 shots in both sessions of the original AR 
database were randomly extracted. In order to avoid 
external influence of background, these realigned 
images are cropped and down-sampled in such a way 
that the final image size is 120 × 120 pixels.  
 
 
 
                 
 
                 
 
                 
 
PDF created with pdfFactory Pro trial version www.pdffactory.com
Figure 7: Basis images learned from the normalized 
ORL database using NMF (a) and BNMF (b). 
 
     Since the original NMF does not impose any 
constraints on the spatial localization, minimizing the 
objective function hardly yields a factorization which 
can reveal local features in the basis images. Therefore, 
BNMF is introduced to impose more spatial constraints 
on the cost function. A new objective function is 
defined to learn intuitively parts-based components. 
Letting [ ] TijB b W W= = , BNMF can learn local 
features by imposing the following constraints on the 
bases and encodings. 
(1) Given the existing constraint 1iji w =å  for all i, 
we wish that each basis should be as orthogonal as 
possible, so as to minimize redundancy between 
different bases. The objective function can be 
imposed by minijb =å  
(2) Take advantage of essential characteristics in PCA, 
we make each basis image have constant energy. 
This can be achieved by 
2
1
ik
ik n
pkp
WW
W
=
¬
å
 
(3) To avoid the degradation of energy on coefficients, 
we renormalize each row of H to maintain constant 
energy. This can be done by 
2
1
kj
kj m
kpp
H
H
H
=
¬
å
 
The incorporation of the above constraints leads to 
the following objective function for BNMF: 
2
1 1
  ( - ( ) )n m ij ij iji jF V WH B= == +å å å  
When subject to the non-negativity for all matrix 
factors, a local solution to the minimization of such a 
constrained objective function can be found under the 
update rules: 
1 ( )
m ij
ik ik kjj
ij
V
W W H
WH=
¬ å  
1
ik
ik n
pkp
WW
W
=
¬
å
 
2
1
ik
ik n
pkp
WW
W
=
¬
å
 
1 ( )
n ij
kj kj iki
ij
V
H H W
WH=
¬ å  
2
1
kj
kj m
kpp
H
H
H
=
¬
å
 
 
3.4. Comparison of NMF-related Algorithms 
 
BNMF adds the non-negative constraint and the 
orthonormal characteristic of PCA to get intuitive 
parts-based features. Therefore, bases should be as 
orthogonal as possible so as to minimize redundancy 
between them. 
To show the advantage of BNMF, we compare it with 
other extensions of NMF. The Euclidean distance and 
the divergence distance between the original and 
reconstructed images are computed to evaluate the 
efficiency of each algorithm. The smaller distance value 
we compute, the better matrix factorization we get. 
Furthermore, the influence of various dimensions 
(number of basis components) on the result basis 
images is surveyed. 
As Fig. 7 shows, NMF and BNMF learn basis 
images which contain dark intuitive part-based facial 
features and light global facial contour. Higher contrast 
between the holistic contour and the local feature 
emerges in BNMF. Nevertheless, some of the basis 
images learned from LNMF and NMFSC in Fig. 6 are 
no more than non-meaningful fragments. In Table 1, 
we intentionally adopt two different kinds of distance 
metrics, the Euclidean distance and the divergence 
distance. So we can see more deeply that the smallest 
distance value occurs in BNMF. 
 
Table 1: Distance between the original and the 
reconstructed images under various extensions of NMF 
and NMF itself. And we set the dimension for 25 and 
the iteration time for 1000. 
 
 
 
4. WAVELET TRANSFORM 
 
4.1. Two-Dimensional Discrete Wavelet Transform 
 
Since the information the continuous wavelet transform 
(CWT) provides is highly redundant as far as the 
reconstruction of the signal is concerned, the discrete 
wavelet transform (DWT) is needed to provide 
sufficient information both for analysis and synthesis of 
the original signal, with a significant reduction in the 
computation time. DWT employs two sets of functions, 
called scaling functions and wavelet functions obtained 
by successive high pass and low pass filtering of the 
time domain signal. The equation of DWT is given: 
-
0
0
1( ( ))( , )  [ ] [ - ]m
km
W f x m n x k a n k
a
y y= å  
Where m is a scaling integer variable, n is a shifting 
integer variable, x[k] is a digital signal with sample 
index k, and y  is the mother wavelet. 
For images, two-dimensional DWT is needed to 
decompose approximation coefficients at level j-1 to 
PDF created with pdfFactory Pro trial version www.pdffactory.com
 
 
Figure 11: The error images between the original image 
and the corresponding reconstructed image in Fig. 10.  
 
 
4.3. Basis-emphasized Non-negative Matrix Factor-
ization with Wavelet Transform 
 
This section introduces a novel subspace projection 
technique via BNMF to represent human facial image 
in low frequency sub-band, which is able to realize 
through the Wavelet Transform. After wavelet 
decomposition and reconstruction, BNMF is performed 
to produce part-based representations of the images. 
The simulation results on the AR database show that 
the hybrid of BNMF and the best wavelet filter will 
yield better recognition rate and shorter training time. 
In order to achieve an excellent verification rate when 
identifying the faces, We investigate the performance 
obtained by the integration of WT and BNMF to take 
the advantages of these two methods. These results are 
compared with those learned by PCA and the original 
NMF techniques later. 
In face recognition, dimensionality reduction is 
very important to project the facial images from a high-
dimensional space onto a lower-dimensional space. 
And wavelet transform reduces the resolution of images 
and decreases the computation load of feature 
generation. With the adoption of wavelet transform, the 
training time can also be reduced significantly. In this 
paper, three level of wavelet decomposition is 
performed on face images. The reconstructed face 
image discarding the highest-frequency sub-band is 
then subjected to BNMF. The integrated framework of 
Wavelet Transform and Basis-emphasized Non-
negative Matrix Factorization is abbreviated as 
wBNMF. The flow chart of wBNMF is illustrated in 
Fig. 12. 
 
 
 
Figure 12: Flow chart of generating the wBNMF 
features. 
 
5. FACE RECOGNITION 
 
5.1. Classifier Determination 
 
In this experiment, we adopt the Riemannian distance 
metric which is more suitable than any other distance 
metric for face classification when using the nearest 
neighbor classifier. Let f1, f2 denote two facial vectors 
in the original n-dimension space, and the 
corresponding learned coefficients in lower r-
dimension space are h1, h2, respectively. To some extent, 
we can say f1 = Wh1 and f2 = Wh2 where W is the 
learned basis matrix. Then we get 
1, 2 1 2 1 2 1 2 1 2
1 2 1 2 1 2 1 2
( ) ( ) ( ) ( ) ( )
( ) ( ) ( ) ( )
T T T
T T
Rie f f f f f f h h W W h h
h h G h h h h h h
= - - = - -
= - - ¹ - -
This indicates that the Riemannian metric can preserve 
the neighborhood of the original samples for 
classification. In addition, the technique is able to 
improve recognition accuracy when a higher rank is 
used.  
 
5.2 Facial Expression 
 
In order to see how each technique can deal with 
expression, facial images in the AR face database are 
used as a testing set because they contain smile, anger 
and scream expressions. And we use the neutral facial 
expression images as the training set. NMF and 
wBNMF techniques are executed under 1000 iteration 
time.  
Given scream facial images as a testing set, it is 
noticeable that PCA produces the poorest recognition 
rate. Since PCA is based on learning holistic nature, it 
mostly extracts global features of the original images 
and cannot handle obvious distortion such as scream 
facial expressions. On the contrary, the other two parts-
based methods, NMF and wBNMF, are more suitable to 
solve such a problem, especially with the significant 
performance improvement on behalf of wBNMF under 
the lowest feature dimensional space. And wBNMF 
outperforms both PCA and NMF for smile and anger 
expressions under such feature dimensional space. 
Therefore, the small basis number is necessary for 
wBNMF to reach good recognition accuracy. The 
reason is that smaller basis number is helpful to 
PDF created with pdfFactory Pro trial version www.pdffactory.com
Since a specific pattern of interest can reside in a low 
dimensional sub-manifold of the original input data 
space which consists of an unnecessarily high 
dimensionality. One of subspace analyses, wBNMF, is 
used to reveal low dimensional structures observed in a 
high dimensional space. In fact, the essence of feature 
extraction in pattern recognition can be considered as 
discovering and computing low dimensional intrinsic 
pattern from observation. Subspace analysis has 
demonstrated its success in numerous visual 
recognition tasks such as face recognition and detection. 
 
6. REFERENCES 
 
[1] MIT Center for Biological and Computation Learning, 
“The CBCL face database,” Available at: 
http://cbcl.mit.edu/cbcl/software-databasets/FaceData2.html 
 
[2] AT & T Laboratories, Cambridge, U.K., “The ORL face 
database,” Available at: 
http://www.orl.co.uk/facedatabase.html 
 
[3] A. M. Martinez and R. Benavente, “The AR face 
database,” Technical Report 24, Computer Vision Center 
(CVC), Barcelona, Spain, June 1998. 
 
[4] M. A. Turk and A. P. Pentland, “Face recognition using 
eigenfaces,” Proceedings of IEEE Conference on Computer 
Vision and Pattern Recognition (CVPR), pp. 586-591, Hawaii, 
June 1991. 
 
[5] L. Sirovich and M. Kirby, “Low-dimensional procedure 
for the characterization of human faces,” Journal of the 
Optical Society of America, Vol. 4, No. 3, pp. 519-524, 
March 1987. 
 
[6] M. Kirby and L. Sirovich, “Application of the Karhunen-
Loeve procedure for the characterization of human faces,” 
IEEE Transactions on Pattern Analysis and Machine 
Intelligence, Vol. 12, No. 1, pp. 103-108, January 1990. 
 
[7] D. D. Lee and H. S. Seung, “Learning the parts of objects 
by non-negative matrix factorization,” Nature, vol. 401, pp. 
788-791, 1999. 
 
[8] D. D. Lee and H. S. Seung, “Algorithms for non-negative 
matrix factorization,” Advances in Neutral Information 
Processing 13 (Proc. NIPS*2000), MIP Press, 2001. 
 
[9] D. Guillamet and J. Vitrià, “Unsupervised learning of 
part-based representation,” Computer Analysis of Images and 
Patterns, W. Skarbek (Eds.) Lecture Notes in Computer 
Science 2124, Springer, pp. 700-708, 2001. 
 
[10] Wei Xu, Win Liu, and Yihong Gong, “Document 
clustering based on non-negative matrix factorization,” 
Proceedings of the 26th annual international ACM SIGIR 
conference on Research and development in information 
retrieval, July 28-August 01, 2003, Toronto, Canada. 
 
[11] Jeffrey Ho, Ming-Hsuan Yang, Jongwoo Lim, Kuang-
Chih Lee, and David Kriegman, “Clustering Appearances of 
Objects Under Varying Illumination Conditions,” 
Proceedings of IEEE Conference on Computer Vision and 
Pattern Recognition, pp. 11-18, 2003. 
 
[12] M. Juvela, K. Lehtinen, and P. Paatero, “The use of 
positive matrix factorization in the analysis of molecular line 
spectra from the thumbprint nebula,” In D. P. Clemens and R. 
Barvainis, editors, Clouds, Cores, and Low Mass Stars, ASP 
Conference Series, vol. 65, pp. 176-180, 1994. 
 
[13] M. Juvela, K. Lehtinen, and P. Paatero, “The use of 
positive matrix factorization in the analysis of molecular line 
spectra,” MNRAS, vol. 280, pp. 616-626, 1996. 
 
[14] P. Comon, “Independent component analysis -- a new 
concept?,” Signal Procesing, vol. 36, pp. 287-314, 1994. 
 
[15] Hyvärinen, J. Karhunen, and E. Oja, “Independent 
Component Analysis,” Wiley Interscience, 2001. 
 
[16] S. Z. Li, X. Hou, H. Zhang, and Q. Cheng, “Learning 
spatially localized parts-based representations,” Proceedings 
of IEEE Conference on Computer Vision and Pattern 
Recognition (CVPR), vol. I, pp. 207-212, Hawaii, USA, 2001. 
 
[17] D. Guillamet and J. Vitrià, “Evaluation of distance 
metrics for recognition based on non-negative matrix 
factorization,” Pattern Recognition Letters, vol. 24, pp. 1599-
1605, June 2003. 
 
[18] D. Guillamet and J. Vitrià, “Determining a suitable 
metric when using non-negative matrix factorization,” 
Proceedings of the 16th International Conference on Pattern 
Recognition (ICPR 2002), pp. 128-131, Quebec, 2002. 
 
[19] W. Liu and N. Zheng, “Non-negative matrix 
factorization based methods for object recognition,” Pattern 
Recognition Letters, vol. 25, no. 8, pp. 893-897, June, 2004. 
 
[20] P. O.~Hoyer, “Non-negative sparse coding,” Neural 
Networks for Signal Processing XII (Proc. IEEE Workshop 
on Neural Networks for Signal Processing), pp. 895-898, The 
MIT Press, Cambridge, Massachusetts, 1995. 
 
[21] P. O. Hoyer, “Non-negative matrix factorization with 
sparseness constraints,” Journal of Machine Learning 
Research, vol. 5, pp. 1457-1469, November 2004. 
 
[22] D. Donono and V. Stodden, “When does non-negative 
matrix factorization give a correct decomposition into parts?”  
Proceedings of NIPS workshop on ICA, 2003. 
 
[23] N. H. Foon, A. T. B. Jin, and D. N. C. Ling, “Face 
recognition using wavelet transform and non-negative matrix 
factorization.” Australian Conference on Artificial 
Intelligence, pp. 192-202, 2004. 
 
[24] D. Guillamet and J. Vitrià, “Non-negative matrix 
factorization for face recognition,” Escrig Monferrer, M. T., 
Toledo, F., Golobardes, E. (Eds.), Topics in Artificial 
Intelligence. Springer-Verlag Series: Lecture Notes in 
Artificial Intelligence, vol. 2504, pp. 336-344, Castello de la 
Plana, 2002. 
 
PDF created with pdfFactory Pro trial version www.pdffactory.com
