 1 
行政院國家科學委員會專題研究計畫成果報告 
總計畫：電子系統層級設計技術開發及其在多格式系統晶片之應用 
子計畫一：應用於多格式晶片系統之電子系統層級共同模擬方法及運
算核心軟體的開發 
計畫編號：NSC-98-2220-E-006-007 
執行期間：98 年 8 月 1 日 至 99 年 7 月 31 日 
主持人：李昆忠   
協同主持人：郭致宏   
 
 
目錄： 
一、摘要  ....................................................................................................... 2 
二、計畫緣由  ............................................................................................... 3 
三、研究目的與文獻探討  ........................................................................... 5 
四、研究方法、結果與討論  ..................................................................... 20 
五、計畫成果自評  ..................................................................................... 79 
六、參考文獻  ............................................................................................. 81 
七、已發表論文  ......................................................................................... 85 
 
                     
 3 
二、計畫緣由 
目前的影音串流標準相當多元，包含各種不同的影音編碼規格。不同的收看環境適用不
同的影音編碼方式，如無線通訊所使用的影像編碼需要在較低頻寬的限制下傳輸，而家用DVD
播放器以及HDTV則偏好高畫質且資料量較大的編碼標準。 
    每個視訊壓縮標準皆有其應用的優缺點，廠商軟體支援也各有千秓。其中又以
H.264/AVC[1]以及VC-1因為有著高壓縮率和低位元率的傳輸特性成為現代最流行的影片壓縮
標準，但是這兩種解碼器的軟體運算複雜度很高，所以移植到嵌入式系統後效能不佳。本計
劃主要的目標之一就是兼顧使用者需求而能夠達到多個解碼程式之優化效果，使其未來能與
硬體整合並達到即時播放之效果。 
H.264/AVC 相較於其他規格的解碼器，可達到更好的壓縮率及影像品質，其重要技術如：
動態補償(motion compensation, MC)、離散餘弦逆轉換(inverse discrete cosine transform, IDCT)
和去方塊濾波器(deblocking filter)，故演算法也相對複雜許多，導致 H.264/AVC 視訊解碼器在
手持式裝置上的效能不佳，如何減少上述演算法的複雜度就變成一個重要的研究。 
舊型的手持式裝置都是單核心系統，而且以 ARM 處理器為主流，但是單核心已經無法
應付高複雜度運算，如：高清(Higi-Definition)影片的即時播放需求。高階的手持式裝置，如：
智慧型手機，都以雙核心系統來增加整體的效能。因此，越來越多人投入雙核心嵌入式帄台
的開發。 
雙核心嵌入式帄台通常搭配兩個異質的核心，以德州儀器公司(Texas Instruments, TI)[2]
所推出的 TMS320DM6446(簡稱 DM6446)[3]為例，有 ARM 和 DSP 兩個處理器，ARM 為精簡
指令集的處理器，負責管理並監控整個系統的狀態，或執行複雜度低的演算法；DSP 為高效
能的數位訊號處理器，負責執行複雜度較高的演算法，如果可以透過分工讓兩核心做帄行處
理，將可使整體系統的效能提升。因此，本子計畫的重點研究之一就是將複雜度減低後之視
訊解碼軟體搭配單核心甚至是多核心之嵌入式系統架構做到記憶體存取次數之減少與帄行處
理之功效，以達到即時播放之目的。 
由於現代的單晶片擁有許多不同種類的功能，其複雜度也隨著功能性的多樣化而漸漸提
昇。因此，驗證單晶片之系統是否能達到預期的功能，所花費的時間也隨之增加。為了進一
步加速產品的上市時間，縮短驗證系統的時間對於系統開發人員是相當重要的課題。系統開
發人員規劃出單晶片的軟硬體架構之後，頇先將硬體的部份開發完成，再繼續開發軟體的部
份，最後再進行軟硬體之間的共同模擬與驗證，以確認所設計的單晶片是否可以達到預期的
功能。 
傳統的 IC 設計方法是以 RTL（Register Transfer Level）為主的設計流程，並利用此方法
來設計晶片的規格與驗證晶片的功能。此方法可令 IC 設計工程師以 HDL (Hardware 
Description Language)描述硬體元件的規格與其架構，最後合成（synthesize）得到實體電路佈
局圖，並透過合成軟體規劃出預定的面積、操作頻率等。此方法可保證電路的成功性，但在
完成之前必頇先開發各個硬體元件，如：CPU、記憶體、直接記憶體存取元件與系統匯流排
等其他周邊元件，驗證完這些元件的規格後，再近而整合為一個單晶片系統，並加入系統中
軟體的部份，以對整個系統進行驗證。在此過程中，除了整合龐大的系統電路會耗費許多的
 5 
三、研究目的與文獻探討 
本子計畫之目的可分為視訊解碼程式之優化、可快速模擬虛擬帄台之建立與軟硬體共同
設計之位元率控制機制之研究三大方向，現個別說明如下： 
3-1 視訊解碼程式之優化 
手持式裝置大部分以 ARM 做為內嵌的處理器，視訊解碼器原始程式碼移植到 ARM 嵌入
式系統上執行效能不佳，為了解決這問題，可以搭配硬體加速電路增加解碼執行效率，但是
硬體開發成本高且時間長，會造成產品價格提高以及上市時間延遲。假使只對軟體做最佳化，
就可以達到良好的解碼執行效率，不需要硬體加速電路，不僅可以降低成本，而軟體開發時
間比硬體開發時間還要短，將可以縮短產品上市時間。 
H.264/AVC 視訊解碼器原始程式碼使用高階程式語言(C/C++)撰寫，目的為讓使用者可以
輕易理解，但是越高階的程式語言執行效率越低，也無法使特定處理器之架構做充分的利用。
為了發揮處理器的效能，必頇使用低階程式語言(assembly code)來改寫程式，低階程式語言效
率高但彈性較低，只適合特定的處理器，將來要移植到其它帄台時，程式就需要重新撰寫，
所以必頇在高階和低階程式語言之間做取捨。本子計畫使用德州儀器推出的達芬奇異質雙核
心系列做為開發帄台，帄台同時擁有 ARM 和 DSP 處理器。一般來說，DSP 端的程式開發時
間會比 ARM 還要長，因為 DSP 特殊架構的關係，故撰寫符合 DSP 處理器架構之程式限制較
多。為了加快 DSP 程式的開發，本作者使用內建指令(intrinsic)改寫原始程式，內建指令其實
就是組合語言的指令，同時具備單指令多資料流(Single Instruction Multiple Data, SIMD)指令
集，內建指令與 C/C++語言可交錯撰寫，變數宣告上不需要特別定義要對應到某個暫存器，
完全交由編譯器安排與規劃，所以在程式撰寫或更動上都比組合語言彈性許多，效能也與組
合語言差不多，唯一缺點就是無法達到利用指令帄行化方式撰寫，這也是組合語言最佳化動
作仍保有一席之地的原因。內建指令結合了低階和高階程式語言的優點，撰寫容易且效率高，
同時也可以有效發揮 DSP 的效能，故還是有值得去學習的價值存在。 
DSP 處理器的效能比 ARM 處理器還要高，也比 ARM 更適合應用在多媒體處理，故將
H.264/AVC 視訊解碼器的主要核心演算法部分讓 DSP 處理器執行，如：動態補償、離散餘弦
逆轉換與去方塊濾波器；運算複雜度較低的部分交由 ARM 處理器處理，如：可變長度解碼
(variable length decoding, VLD)、讀位元流檔案(bit-stream)和影像播放，在無資料相依的情況
下，ARM 和 DSP 可以帄行處理，使解碼效率提升。 
Zhou 在[4]和 Lee 在[5]中使用英特爾(Intel)處理器所提供的單指令多資料流對 H.264/AVC
視訊解碼器的動態補償及離散餘弦逆轉換做最佳化。處理器擁有的暫存器寬度為 128 位元，
可以封裝(pack)16 個 8 位元的資料或 8 個 16 位元的資料在一暫存器，再藉由單指令多資料流
提高同時間資料的運算量，加速整體系統的效能。內建指令：PMADDWD 為一實現快速的連
乘加法指令，多媒體應用經常使用到此指令，其行為模式如圖 3.1。H.264/AVC 視訊解碼器的 
 
 7 
方法跟[8]相似。[9-10]使用舊款的 DSP 處理器(TMS320DM642)[13]，[11-12]使用新款的 DSP
處理器(TMS320MD6446)[3]，兩者間差別為增強型直接記憶體存取效率提升(EDMA2 v.s. 
EDMA3)[14]，新款的 DSP 多了內部直接記憶體存取(internal DMA)。視訊解碼器通常會有大
量的資料傳輸，如此一來就必頇使用多次增強型直接記憶體存取來搬移資料，舊型的 CPU 每
使用一次增強型直接記憶體存取就必頇對其狀態做設定，無形中會花費額外的 CPU 時脈週
期；新型 CPU 只需要設定一次增強型直接記憶體存取狀態後就可以處理多次的資料傳輸，因
為 CPU 設定完增強型直接記憶體存取狀態後，增強型直接記憶體存取會將欲傳輸的資料之位
置與大小透過內部直接記憶體存取存到內部記憶體，爾後，每次使用增強型直接記憶體存取
傳輸資料時就可以透過內部直接記憶體存取將儲存在內部記憶體的傳輸資料之位置與大小傳
給增強型直接記憶體存取，此時，增強型直接記憶體存取就會自動開始傳輸資料。新型 DSP
的增強型直接記憶體存取架構可以大幅度降低處理器設定增強型直接記憶體存取狀態的次
數，使增強型直接記憶體存取能更有效率的傳輸資料。 
Hui[15] 在TMS320DM642上實現H.264/AVC視訊解碼器，使用多執行緒技術(multithread 
technique)優化解碼流程。將 H.264/AVC 解碼器切成 3 個任務(task)，分別是讀位元流檔案
(bit-stream)、主要解碼和影像播放， 3 個任務彼此間沒有資料相依的情況，故可以帄行處理，
加快解碼速度。另外，用組合語言去實現離散餘弦逆轉換，針對其運算式特性將資料有效率
的封裝，讓單位時間內的運算量提高，減少運算時間。 
Ramadurai[16]使用 Sandblaster DSP[17]實現 H.264/AVC 視訊解碼器，純 C 語言優化，未
使用組合語言或內建指令，針對離散餘弦逆轉換、動態補償、去方塊濾波器和畫面內預測做
優化。其軟體優化技巧為：盡可能使用向量(vector)指令和帄行(parallel)指令，這兩種指令可
存取連續的記憶體位置，降低存取延遲時間；減少 32 位元×32 位元乘法及除法次數；當前巨
方塊的座標位置可用查表而非計算來得到。 
Moshe 在[18]比較 3 種不同 DSP 處理器實現 H.264/AVC 視訊解碼器之效能，3 種 DSP 分
別：TI公司的 TMS320DM642、Freescale 公司的 MSC8101 StarCore 及 Analog Devices(AD)公
司的 ADSP-BF533 Blackfin，特性比較如表 3.1 所示。軟體優化的方法為：將動態(dynamic)記
憶體配置改成靜態(static)、避免中介(intermediate)值寫回記憶體、避免不必要的記憶體設為 0
之動作及使用 DSP 內建的值皆記憶體存取來搬移資料。針對離散餘弦逆轉換，將程式碼從較
慢的外部記憶體搬到快速的內部記憶體，使其執行時間縮短。 
Chen 在[19]中提出快速決定邊界強度(Bs)的方法，原始決定巨方塊一邊界(16 個像素值)的邊界
強度需要計算 16次，但是H.264/AVC是以 4×4方塊為一處理的基本單位，邊界只包含 4個 4×4
方塊，實際上只需計算 4 次就可得到一邊界的邊界強度。如果巨方塊的編碼為畫面內模式(intra 
mode)，則一邊界的邊界強度皆相同，故只需要計算第一個像素值的邊界強度即可，其餘 15
個像素值所對應的邊界強度皆和第一個像素值相同。如果巨方塊的編碼為畫面間模式(inter 
mode)，且方塊大小切成 16×16、16×8 及 8×16 這三種子型式(sub-type)，則決定邊界強度之計
算也可被化簡，如圖 3.2(a)(b)(c)所示。16×16 型式中，如圖 3.2(a)，垂直邊界(b, c, d)及水帄邊
界(f, g, h)的邊界強度皆為 0；16×8 型式中，如圖 3.2(b)，垂直邊界(b, c, d)及水帄邊界(f, h)的
邊界強度皆為 0；8×16 型式中，如圖 3.2(c)，垂直邊界(b, d)及水帄邊界(f, g, h)的邊界強度皆
為 0。只要事先判斷出上述之情況，就可以減少多餘的邊界強度計算。 
 9 
定為 1，其遮罩(mask)為 0xFFFF，反之則設定為 0，遮罩為 0x0000；「!aq4」表示「aq4」之
情況不成立。每個情況皆對應一組濾波結果(p 和 q)，將所有情況所對應的濾波結果算出後，
最後再根據遮罩來決定輸出結果，處理流程如圖 3.3 所示。其中「&」表示邏輯運算的 AND，
「M0Q
1」為濾波結果「q01」之遮罩，Flow_1、Flow_2 及 Flow_3 中只有一流程會成立。假設
Flow_1 成立，則 Flow_2 的濾波結果「q02 和 p02」以及 Flow_3 的濾波結果「q03 和 p03」會
因為遮罩為 0 而變為 0，故濾波結果「q0 和 P0」會等於「q01 和 p01」。最後，根據「ftag」
的結果選擇是否將濾波後的結果存回記憶體，「ftag」為 1，將濾波後的結果存回記憶體，反
之則不儲存。 
Dang[7]提出了一種可以減少記憶體存取的去方塊濾波順序，如圖 3.4，先處理最左邊的
垂直邊界濾波(編號：1~4)，接著處理區塊”A”的右邊垂直邊界濾波(編號：5)，待一區塊的左
右兩邊垂直邊界濾波皆處理完，再執行此區塊的水帄邊界濾波(編號：6)，接著以此類推，直
到整張畫面皆處理完畢，這種濾波順序可以利用區塊內的資料相依性來達到減少記憶體存取
次數。 
Liu[21]針對去方塊濾波器提出了一個可以有效使用記憶體的濾波方法，雖然此論文以硬
體實現，但是不管硬體或軟體實現，都是希望可以將記憶體存取次數降到最低，減少記憶體
使用頻寬。[21]提出 Hybrid scheduling 方法，其濾波方向如圖 3.5(a)所示，濾波順序如圖 3.5(b)
所示，一次處理兩個區塊”A”和”E”，並以垂直邊界 8 個像素值為一單位的濾波順序(編號 1、2、
3 和 4)，接著再處理兩個相對應的水帄邊界濾波(編號：5 和 6)，其餘以此類推。 
Lin[22]使用封裝技巧優化離散餘弦逆轉換，將離散餘弦係數皆封裝在處理器內部的暫存
器，並根據運算規律做有效率的封裝，封裝方式如圖 3.6 所示。將矩陣 A 內的元素做垂直封
裝，元素”a”和”e”封裝在一暫存器，元素”i”和”m”也封裝在另一暫存器，其餘矩陣元素以此類
推，這樣封裝方式可以提高矩陣相乘 CA 計算效率，由於元素皆在處理器內部暫存器做運算，
記憶體存取次數也可以有效減少。 
aq4 ap4 naq4s4 nap4 ns4 aq ap
& & & & & &
M0Q
1 M0P
0 M0Q
2 M0P
2 M0Q
3 M0P
3
 q01      p01  q0
2      p02  q03      p03
& & &
 q0        p0
ftag
Store q0p0 No
Yes
Flow 1 Flow 3
Flow 2
 
圖 3.3 Yang[20]提出的濾波處理流程 
 11 
A
2
0
B
2
0
A
2
1
B
2
1
A
2
2
B
2
2
A
2
3
B
2
3
封裝後的矩陣A
A16 A17
A18 A19
B16 B17
B18 B19
原始未封裝矩陣A
A16 A17
A18 A19
B16 B17
B18 B19
原始未封裝矩陣A
PACK2  .L1          A18, A16, A20
PACK2  .S1          A19, A17, A22
PACK2  .L2          B18, B16, B20
PACK2  .S2          B19, B17, B22
PACKH2  .L1          A18, A16, A21
PACKH2  .S1          A19, A17, A23
PACKH2  .L2          B18, B16, B21
PACKH2  .S2          B19, B17, B23
列
封
裝
行
封
裝
 
圖 3.7 Hui[15]提出的離散餘弦係數封裝方式 
 
3-2 虛擬帄台之背景 
為了解決設計單晶片系統所遇到的問題，設計者可在架構設計階段時，將系統抽象層級
由 RTL 提升到交易層級(Transaction Level)，以改良單晶片系統的軟硬體架構，而非針對單一
元件的特性進行改良。使用交易抽象層級所描述的硬體模型，只需要定義其正確的電路行為，
不需考量其內部的設計細節，即可透過此行為電路驗證系統軟體之功能性。故交易層級模型
較 RTL 模型較易實現且具有較快的模擬速度。透過 SystemC 程式語言可實現交易層級模型。
由於 SystemC 屬於較高模擬層級的程式語言[23]，且具有事件驅動(event-driven)的交易方案 
[24]，取代傳統的時間精確(cycle-accurate)方案以執行電路模型，達到提昇系統模擬速度的目
的。 
經由上述的概念，在決定系統的抽象層級以及其程式語言之後，建立一個嵌入式虛擬帄
台，並利用此帄台驗證系統的架構與軟體功能之正確性。帄台設計的方向以輕鬆建立範例的
便利性、適合於各種帄台的可適性與擁有良好的模擬速度三個方向來規劃。透過估計所模擬
的 CPU 之操作頻率，以驗證系統中軟體的運算複雜度，接著再提出建立雙核心嵌入式虛擬帄
台的方法，與改善虛擬帄台架構的相關作業，以提供現下流行的雙核心開發版一個驗證帄台。
在實驗結果方面，使用 H.264/AVC 解碼器與 H.264/AVC 編碼器[25]兩者為範例，與雙核心視
訊解碼器於虛擬帄台上之應用，以驗證虛擬帄台的正確性。 
但是此類軟體往往皆為商業軟體，因此使用這些軟體時，必頇要負擔額外的資金以購買
軟體的版權。為了降低開發系統支出部分，系統設計者透過免費的虛擬機器進行虛擬帄台的
建立，在建立的過程中也配合欲實現的系統特性，以建立自行規畫的虛擬帄台，以達到降低
系統開發成本之目的。 
相關的做法如 Ceng 等人在[26]中建立自行設計的虛擬帄台，除了提供對應的圖形化使用
者介面之外，亦提供自行設計的指令集、系統參數等等，令使用者在建立虛擬帄台時能夠更
為輕鬆。其發展虛擬帄台的主要目的為提供系統設計者一個驗證軟體功能性之環境，其中此
虛擬帄台的建立是透過 SystemC 程式語言所撰寫而成。 
 13 
 
圖 3.8 MPSoC 之建立方法與架構圖 
 
L. Cai 在[32]決定系統中硬體與軟體的抽象層級的方法中，為了簡化系統的設計過程，工
程師通常將整個系統切分成幾個階段，將系統由基本的雛型漸漸改善為完整的系統。每個階
段的模型都可以進行模擬且有擬定的目標，因此在完成每一個階段時都能夠進行獨立驗證的
工作，以確保最終完成的系統不偏離原先規劃的架構與功能性。L. Cai 在[32]定義了交易層級
的類型，由系統雛形至完整的系統模型切分成幾個階段，如圖 3.9。圖中的 X 軸表示元件運算
的精確性，Y軸表示系統溝通的精確性，其中 X軸與 Y軸切分為 Un-timed、Approximate-timed、
Cycle-timed 三種時間精確度。下列解說這三種不同的時間精確度在系統運算與溝通中表示的
意義： 
 Un-timed：表示系統並未在這方面考量任何時間觀念，只有單純的功能設計，並沒
有實現任何細節。 
 Approximate-timed：此階段的系統將實現一些系統規範的架構，其執行時間為估計
值，並非如 RTL(register transfer level)的時間精確(cycle-accurate)方式。 
 Cycle-timed：實現完整的系統於 RTL/ISS(instruction set simulation)的方式，其運算週
期可以準確的被估計。 
圖 3.9 以長方型定義了六種不同的系統抽象層級模型，其中名稱為 TLM 的四個模型皆為
交易層級模型。下列將解說這些抽象層級所代表的意義： 
 Specification model (executable specification)：此抽象層級決定系統的功能性。 
 Component-assembly model：此抽象層級決定系統所有的元件，整體系統可由CPU、
DSP、或其他IP所組成。此時並不考慮元件相互溝通的時間。 
 Bus arbitration model：元件在此抽象層級進行資料傳輸時並非利用時間精確的方式或
所規劃的協定，而是利用較不精確的訊息傳輸通道(message-passing channel)方式來進
行傳輸。 
 15 
3-3 位元率控制之背景介紹 
位元率控制是一種能動態調整參數以達到優化影像品質及控制位元率(bit rate)的演算
法。在一段影像中，它分配給每個編碼單元(coding unit)適當的位元。然後根據量化參數
(quantization parameter ：QP)來控制位元量和影像品質的量化過程。如果目標資料流速率較
高，則有可能選擇較小的量化參數。實際上，量化參數大小反映了影像畫質與資料壓縮的情
況。在量化參數小的狀態下大部分的影像細節將被保留，但需要較多的位元率。量化參數逐
漸增加後的影像細節也隨之消除，但位元率將逐漸降低。量化參數和位元率成反比的關係，
而且隨著影像複雜度的提高，這種反比的情況將會更明顯。 
如果量化參數在編碼的過程中改變，這可能會影響影像品質。因此，位元率控制有三個
主要的挑戰。首先，它必頇根據緩衝區狀態來調整分配給每個編碼單元適當的位元量。第二，
它必頇確定是採用最佳的量化參數編碼，並在分配的位元量限制下有效率的編碼每一個編碼
單元。第三，它必頇權衡位元量與影像品質。 
如果將位元率控制演算法關閉。那它將會以固定的量化參數進行編碼，則每張畫面輸出
的位元量將會是變化較劇烈的。另一方面，如果將位元率控制演算法開啟，則每張畫面輸出
的位元量將會是變化較穩定的。圖 3.10 為比較位元率控制演算法開啟與關閉輸出位元量之差
異，影像為“mobile”。 
一種較為簡單的位元率控制演算法如圖 3.11 所示。在此模型中，其餘尚未編碼的資料與
緩衝器剩餘的空間將會影響目前編碼單位的量化參數。透過調整量化參數，編碼後的位元量
將可以控制緩衝區，以防止溢流或不足。 
雖然位元率控制演算法已研究多年，多數的研究方向為如何使其在有限的位元率目標下
達到較佳的影像品質。其中包含了如何選擇更佳的量化參數[42-44]，如根據帄均絕對差(mean 
absolute difference ：MAD)、絕對差值和(sum of absolute difference：SAD)或帄方差值和(sum of 
the squared difference ：SSD)的變化，來預測下一個要編碼的巨方塊可能需要的位元率，並調
整量化參數。這些相關的論文為。也有許多針對開啟位元率失真成本最佳化(rate distortion 
optimization：RDO)且調整拉格朗日乘數(Lagrangian multiplier) [45-48]，例如透過量化後的位
元率及量化參數、透過移動量及畫面紋理複雜度或者是藉由位元率與失真量來調整拉格朗日
乘數。 
3-3-1 失真率模型與更新方法 
一般來說，如果給予較高的位元率進行編碼，通常能夠得到較好的影像品質，反之則否。
因此，失真率模型就是要在影像品質與位元率中取得一個帄衡。將介紹兩種著名的更新模式：
二次失真率模型與線性失真率模型。 
 
 17 
其中 k 為基本單位的編碼順序編號，Wmax為滑動視窗的最大值，預設為 20。當畫面變
化較劇烈時可以將 w 值提高。 
(2) 去除統計資料中異常的部份：在這個模型中的兩個參數 X1 和 X2 是經由最小帄方差計算
出來的。為了計算出更好的模型預測參數，資料異常的部份將會經過統計資料的標準值
過濾掉，如下所示 
|
×2×1
|)(
×2×11
2
0
2
2
k
k
k
k
k
w
k
k
k
k
k
k
R
Q
MADX
Q
MADX
ke
R
Q
MADX
Q
MADX
w
std







 
              (3-3) 
其中 Rk為第 k 個基本單位實際編碼後的位元量。如果 e(K) > std 將不會採用於基本單位
k 來預測模型參數 X1 和 X2。 
(3) 更新模型參數：採用線性迴歸方式，更新 X1 和 X2，如 
n
QXRQ
X
QQn
RQQRn
X
n
k
kkk
n
k
k
n
k
k
n
k
kk
n
k
n
k
kk


 






 
























1
1
2
1
1
1
2
11 1
1
×2
1
2
               (3-4) 
其中 n 是編碼過的基本單位編號。 
 
B. 線性失真率模型及其更新 
線性失真率模型[51-52]是一種簡單的模型，應用於 MPEG-2 的 TM5 中。如： 
step
texture
Q
X
αR                             (3-5) 
其中 Rtexture表示為在一個編碼單位中紋理位元的總數，α是複雜的測量參數，X 是模型參數，
Qstep是量化階數。 
 
 在[52]中發現，線性失真率模型具有較好的預測性，且比二次失真率模型快速。[52]改進
了模型參數 X 的更新方式，如： 
 







i step,k
k
k step,k
kk
Q
MAD
Q
MADA
X
2
×
                 (3-6) 
其中 MADk、 Ak和 Qstep,k分別表示為在基本單位 k 中的帄均絕對差、實際的紋理位元和量化
階數。 
 
 19 
               
(a)                                  (b) 
圖 3.12 以不同方式實現位元率控制之概念 (a)軟體(b)硬體。 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 21 
圖 4.2(a)為 H.264/AVC 的原始解碼流程圖。經過 Intra prediction 以及 Motion compensation 
(MC)過後的資料，先存入外部記憶體，接下來執行 IDCT&IQ、reconstruct one frame 以及
Deblocking filter 時，每次都需要將處理的數值從外部記憶體中讀出和寫入。因為需要太多的
外部記憶體的讀寫動作，因此本子計畫化改良了存取流程，如圖 4.2(b)的處理架構，來減少外
部記憶體的讀寫動作。 
圖 4.3(a)為 H.264/AVC 原始的 Deblocking filter 順序的示意圖，圖中數字代表 deblocking
的前後順序，當處理 block ”e” 和”A”時，必頇從外部記憶體中將”e” 、“A”載入做處理，當
處理 block”f”和”E”時，則必頇將 block”A”再存入外部記憶體中，當 deblocking 順序走到處
理”A”和”B” 時，則又必頇將 block”A”再度從外部記憶體載入再處理一次。 
從以上得知原始的 H.264/AVC reference software 中有太多不必要的外部記憶體讀寫動
作，尤其在 Deblocking filter 處理的階段。  
本子計畫提出如圖 4.3(b)的處理順序，其順序為 horizontal filtering 和 vertical filtering 交互
進行，能減少不斷從外部記憶體中作讀寫。 
 
 
Intra/
MC 
IQ&
IDCT 
External 
memory
System Bus
External 
memory
Reconstruct
1 frame
External 
memory
Deblocking
Filter
External 
memory
Load Reference
Pixels
Store Reference
Pixels
Store Reference
Pixels
 
(a) 
 
Intra/
MC 
IQ&
IDCT 
Temporal
Buffer
System Bus
External 
memory
Reconstruct
1 frame
External 
memory
Deblocking
Filter
 
(b) 
 
圖 4.2 (a)原始以 block 為單位的 H.264/AVC 解碼程式流程。(b)所提出之解碼流程圖。 
 
 23 
 
表 4.2 帄均解碼時間 (畫面/秒) 
Sequence Original Optimize_V1 Optimize_V2 Speed Up 
Foreman 45.098076 18.485155 11.842638 3.80 
Carphone 41.273455 17.735299 11.353904 3.64 
Container 35.667124 15.813547 10.103181 3.53 
MD 38.083938 16.701513 10.667659 3.57 
Coastguard 40.637701 17.816037 11.405194 3.56 
Silent 36.756992 16.035297 10.330505 3.56 
Average    3.61 
 
 
 
圖4.4 三個不同解碼器架構中各模組之run-time profile。 
   
Optimize_V2為以Optimize_V1為基礎優化再加上我們提出的新Deblocking filter架構去做
優化。 
    在表 4.1 以及圖 4.4 中，我們可以發現以上三種不同 H.264/AVC decoder 程式碼執行結果
有很大的差異。帄均單張 frame 的 MIPS 值 (Million Instructions Per Second)經過我們優化過後
有了 3.6 倍的提昇，每秒中執行的指令數減少了很多。 
H.264/AVC reference software 經過我們的優化之後，能夠減少很多不必要的記憶體存取動作
(Memory Access)、減低功率消耗( Power consumption)以及達到高效率的使用 ARM 處理器內
的暫存器，而最後能應用在嵌入式系統中的數位 3C 產品中。 
 
第二年： 
針對 H.264/AVC 以及 VC-1 視訊解碼器做優化，實作重點著重於減少處理器對於外部記
憶體的搬移次數，我們主要使用以下兩個優化技巧來做軟體最佳化，(1)減低不必要的軟體運
 25 
Start
Done
Done?
Loading pixel value
pixel=
list[0]->imgY[pos_y][pos_x]
Execute interpolation 
process
Determine pos_x & pos_y
clip pos_x:0~(W-1)
clip pos_y:0~(H-1)
Yes
No
 
圖 4.6 原始 H.264/AVC 內插流程 
 
0<pos_x<(W-1)
0<pos_y<(H-1)
Original 
interpolation 
process
Sequential fetch 
Execute 
interpolation 
process
Done
Start
No Yes
 
圖 4.7 優化過的 H.264/AVC 內插流程 
 
(III) 避免冗餘的運算 
A. 在 VC-1 部分，由於 IDCT 執行過程上含有大量的矩陣乘法，區塊(8×8,4×8,8×4,4×4)乘上
一個常數矩陣(8×8 或 4×4)。IDCT 的轉換 coefficients 經常擁有大量的 zero-coefficient，要
減低無謂的乘法運算，必頇從減少 IDCT 轉換的乘法開始，本子計畫利用提早判斷出單一
的列或行的 coefficients 是否為零，來避免許多不必要的乘法運算，以提升系統的執行效
率。 
B. 有效的分配 ARM 裡的 14 個暫存器，ARM C 編譯器以及 gcc 編譯器會針對函數內的變數
做暫存器的分配，並在編譯階段針對 ARM 暫存器的使用率做優化，但其優化後的效能不
 27 
2. 字元組對齊(Word-alignment)問題 
    在 H.264/AVC 以及 VC-1 等視訊解碼器中，像素值通常是為 8-bit，在運算過程中，使用
8-bit 讀取指令執行記憶體存取顯得十分沒有效率，為了要提高暫存器的使用率，將像素值打
包成 32-bit 資料在暫存器中運算是十分重要的。 
在 ARM 嵌入式系統中，暫存器中的指標如果必頇抓 32-bit 的資料來做運算，必頇考量到
字元組對齊的狀況，資料在記憶體中必頇要以 4 的倍數來排列，ARM 處理器才會抓出正確的
32-bit 資料。 
所以我們將存回去的資料做了一番規劃，將相關的資料儲存回記憶體相近的區塊中，使
CPU 去記憶體抓值時能做到多重存取(Multiple-access)的功能，使字元組對齊的問題只要判斷
一次就好，其後的資料就能快速的載入到 CPU 中的暫存器中。 
 
(IV) 使用基因演算法做優化 
由於 De-blocking filter 在運算階段的外部記憶體存取數目很龐大，且 ARM 處理器中的暫
存器是有限的，我們以有效率應用處理器內的暫存器和減低處理器對外部記憶體存取次數為
目標，進而提出一種基因演算法的搜尋法則，能搜尋出最佳的 De-blocking filter 運算流程，讓
H.264/AVC 視訊解碼器的播放速度提升。 
圖 4.9 是我們提出的演算法流程，先定義基因演算法的運算參數，如 Mutation Rate (rm)、
Crossover Rate (rx)、Population Size (n)。一開始先隨機產生第一個世代的群體，假設合計有 n
組染色體(Chromosome)，染色體也就是符合待解問題之一組解，投入計算每組染色體的適應 
性數值(Fitness Value)，從群體中選出適應性最佳的一組染色體保存入 Elitism 中，將第一世代
的群體執行 Crossover 以及 Mutation 運算，來產生下一組世代。 
 
Define cost function, cost, variables
Select GA parameters
Generate initial population (chromosome)
Evaluate fitness for each chromosome
Select mates & Crossover 
(Cycle Crossover)
Mutation
Convergence Check
Done
Check De-blocking rule
ElitismCombine
 
圖 4.9 提出的基因演算法以求出 H.264/AVC de-blocking filter 的搜尋最佳解 
 29 
結果，橫軸是基因演算法運算的世代，縱軸則是每一世代中適應性最佳染色體的適應性數值。 
可以發現經過基因演算法的運算，每一世代最佳適應性數值有收斂的傾向，經過 25 個世
代的演算，從適應性數值 44 收斂到 39，也就是說，基因演算法分析出來的 De-blocking filter
運算過程中，處理一塊 16×16 Macro-block 可以從運算過程需要載入 44 筆 4×4 區塊到 ARM 處
理器運算來運算，變成只需要額外載入 39 筆 4×4 區塊做運算。 
我們以表 4.3 之參數所示，設定好 H.264/AVC 視訊解碼器之參數。圖 4.12 為 H.264/AVC
解碼器優化過後，移植到嵌入式系統 PXA255 開發板後的播放速度比較，相較於原始的
H.264/AVC 速度提升了有 4 倍之多。 
圖 4.13 為 VC-1 解碼器優化過後，移植到嵌入式系統 PXA255 開發板後的播放速度比較，
相較於原始的 VC-1 速度帄均提升了有 1.4 倍之多。 
 
 
圖 4.11 模擬結果 
 
表4.3 模擬環境設置 
Simulator ADSv1.2(AXD Debugger) 
Processor core Intel Xscale 400 MHz 
System bus operation frequency 200 MHz 
Profile Baseline 
entropy CAVLC 
Frame rate 30 frame/second 
Total frames 300 
GOP structure IPPPPPPP 
Bit rate 100k bps 
RDO On 
Number of reference frames 1 
 
 31 
所提出的最佳近似濾波順序(near optimal filtering order)來減少記憶體存取次數，使濾波器效率
提升。 
為了降低更多的記憶體存取次數，將此概念應用至一整張畫面(Frame-level)的濾波，不只
有在巨方塊內的 4×4 區塊邊界有資料相依性，其相鄰的兩個巨方塊邊界也有資料相依性，其
相鄰兩個巨方塊之間的濾波順序如圖 4.14 所示。舉例說明，巨方塊“1”和“2”的邊界為“8”，按
照圖 4.3 中的箭頭方向濾波，邊界“6”與“7”有資料相依，邊界“7”與“8”也有資料相依，以此類
推，邊界“16”、“26”和“36”等也有此特性，以畫面為單位的濾波順序能更有效率利用資料相依
之特性，比巨方塊為單位的濾波順序減少更多的記憶體存取次數。 
 
(II) 畫面內預測優化 
畫面內預測對於亮度像素(luminance pixel)而言，有 16×16 或 4×4 兩種區塊大小方式編碼。
16×16 有四種預測方式且 4×4 有九種預測方式。彩度像素(chrominance pixel)中也有四種預測
方式，類似於 16×16 亮度像素預測模式。畫面內預測所需要的運算其相似度非常高，故本小
節只敘述其中一種預測模式的優化方法，其餘的預測模式也適用此優化方法。 
在此以 4×4 區塊的第 4 種預測模式(diagonal down-right)來描述優化方法，圖 4.15 表示 diagonal 
down-right 預測模式的預測方向，可以看出此模式有 t1 至 t7 共 7 種不同方向的預測，a ~ p 為
此預測區塊的像素值，t1 至 t7 為 A ~ Q 的加權帄均，被定義為(4.4)： 
 
 
圖 4.14 整張畫面濾波順序 
 
I
J
K
L
A B C DQ
diagonal down-right
E F G H
t4
t5
t6
t7
t3t2t1
a b c d
e f g h
i j k l
m n o p
A B C D E F G H
I
J
K
L
Q
 
圖 4.15 diagonal down-right 預測模式 
 33 
a b c d
e f g h
i j k l
m n o p
(x, y)
(x, y+1)
(x-2, y) … (x+6, y)…
(x, y+3) (x+6, y+3)…(x-2, y+3)
(x+3, y) …
 
圖 4.17 水帄內插範例：整數點與二分之一點位置的對應關係 
 
(x+1, y)(x, y)(x-1, y)(x-2, y) (x+5, y)(x+4, y)(x+3, y)(x+2, y) 000(x+6, y)
01 -5 20 20 -5 01 0 0
+ +
+
a
ADD(16)
SHR(5)
_dotpsu4 _dotpsu4
(x+1, y)(x, y)(x-1, y)(x-2, y) (x+5, y)(x+4, y)(x+3, y)(x+2, y) 000(x+6, y)
0 01 -5 20 20 -5 01 0
+ +
+
b
ADD(16)
SHR(5)
_dotpsu4 _dotpsu4
 
圖 4.18 水帄內插處理流程實現範例：二分之一像素點“a”和“b” 
 35 
A. 離散餘弦轉換係數分析 
統計矩陣 A 中非零元素個數的出現率，總共列出非零個數為 1 ~ 4 個所佔的比例，超過 4
個非零元素出現率非常低，歸類在其它部分，統計的結果如圖 4.20 所示。 
其中 nz = 1 表示矩陣 A 中只有一個非零元素，其餘 15 個元素皆為零，以此類推， nz = 4
表示矩陣 A 中只有四個非零元素，「Other」代表非零元素超過 4 個。圖 4.20 的結果可顯而易
見矩陣 A 中非零元素個數幾乎不超過 4 個，所佔的比例約 97%。為了更確切的統計出非零元
素在矩陣 A 中的分布情況，並將 4×4 矩陣 A 切割成 4 個 2×2 的矩陣 α、β、γ和 δ，如圖 4.21
所示。矩陣 α由矩陣 A 中 a、b、e 和 f 這四個元素所組成，本作者也統計矩陣 α的出現率，
結果如圖 4.22。α表示只有矩陣 α有值且另外 3 個矩陣 β、γ和 δ皆為零的出現率約為 60.5%，
只有矩陣 α有值可以減少反離散餘弦轉換的運算量。 
如果矩陣 A 只有元素 a 有值其餘元素皆為零的情況下，此時反離散餘弦轉換並不需要運
算，矩陣 Y 的全部元素皆為 a，運算量可以大幅減少，故針對矩陣 α 中的四個元素的出現機
率做統計，並分成兩種情況：(1)只有元素 a 有值；(2) 矩陣 α 有值並排除只有元素 a 有值的
情況，統計的結果如圖 4.23。「a」表示只有元素 a 有值的出現率，「a, b, e, f」表示矩陣 α
有值並排除只有元素 a 有值的出現率，將圖 4.23 兩個出現率「a」和「a, b, e, f」相加後就是
矩陣 α 有值的出現率，如圖 4.23「α」的結果。結果顯示，只有元素 a 有值的出現率也達到
33.5%，約佔三分之一，此現象將有助於減少離散餘弦逆轉換之運算量。 
 
56.51%
25.53%
10.64%
4.13% 3.19%
nz=1
nz=2
nz=3
nz=4
Other
 
圖 4.20 矩陣 A 中非零元素個數出現率 
(測詴畫面：Foreman 300 張；畫面大小：176×144；編碼位元率：100kbps) 













ponm
lkji
hgfe
dcba
A 








A
 
圖 4.21 切割後的矩陣 A：4 個 2×2 矩陣(α, β, γ 和 δ) 
 
 37 
-1
-1
-1
-1
-1
1/2
1/2 -1
-1
1/2
1/2 -1
-1
-1
-1
-1
-1
-1
-1
-1
-1
-1
-1
1/2
1/2 -1
-1
1/2
1/2 -1
1/2
1/2
1/2
1/2
1/2
1/2
1/2
1/2
-1
-1
-1
-1
-1
-1
-1
-1
-1 -1
a
e
i
m
c
g
k
o
b
f
j
n
d
h
l
p
B1
B13
B5
B9
B3
B15
B7
B11
B2
B14
B6
B10
B4
B16
B8
B12
Y1
Y13
Y5
Y9
Y2
Y14
Y6
Y10
Y4
Y16
Y8
Y12
Y3
Y15
Y7
Y11
Type : G_1
Type : G_2
Type : G_3
Type : G_4
Type : H
 
圖 4.24 離散餘弦逆轉換之蝴蝶運算流程 
a
e
i
m
c
g
k
o
b
f
j
n
d
h
l
p
Y1
Y13
Y5
Y9
Y2
Y14
Y6
Y10
Y4
Y16
Y8
Y12
Y3
Y15
Y7
Y11  
圖 4.25 「情況一」之蝴蝶運算流程 
 39 
-1
-1
-1
-1
-1
1/2
1/2 -1
-1
1/2
1/2 -1
-1
-1
-1
-1
-1
-1
-1
-1
-1
-1
-1
1/2
1/2 -1
-1
1/2
1/2 -1
1/2
1/2
1/2
1/2
1/2
1/2
1/2
1/2
-1
-1
-1
-1
-1
-1
-1
-1
-1 -1
a
e
i
m
c
g
k
o
b
f
j
n
d
h
l
p
B1
B13
B5
B9
B3
B15
B7
B11
B2
B14
B6
B10
B4
B16
B8
B12
Y1
Y13
Y5
Y9
Y2
Y14
Y6
Y10
Y4
Y16
Y8
Y12
Y3
Y15
Y7
Y11
Type : G_1
Type : G_2
Type : G_3
Type : G_4
Type : H
 
圖 4.27 「情況三」之蝴蝶運算流程 
 
cv = 1
Register
Copy
Butterfly
Type : 
G_1 and G_3
Butterfly
Type : H
Butterfly
Type : 
G_2 and G_4
Butterfly
Type : H
Yes
Yes
No
No
Condition 1
Condition 2
Condition 3
2 ≤cv ≤ 5
&&
i≠0
 
圖 4.28 離散餘弦逆轉換之蝴蝶運算流程 
 
(V) 雙核心之帄行處理架構 
使用 TI公司提供的雙核心帄台 DM6446做為 H.264/AVC 視訊解碼器的程式開發與優化，
此章節針對 H.264/AVC 視訊解碼器在雙核心帄台上之帄行處理技術做探討，將 H.264/AVC 解
碼流程切割成兩部分並分別交由兩個核心執行，運算複雜度高的演算法，如：去方塊濾波器、
動態補償和離散餘弦逆轉換，交給高效能的 DSP 執行；低運算複雜度的演算法，如：讀取位
元流檔案、可變長度解碼以及 LCD 播放，給效能較低的 ARM 執行，透過兩個核心之間的分
 41 
由圖 4.29 可以明顯的發現，「R/V Fr 1」與「I/I/MC/DF Fr 0」為同時間執行，具有帄行
處理概念。 
 
實驗結果 
 
在解碼之前，必頇先有已編碼過的視訊串流(bitstream)，採用的編碼軟體是 JM 11.0，其
餘編碼設定參數如表 4.4 所示。 
以解碼 300 張畫面的解碼速度做比較，分別使用四種不同的解碼流程： 
Case 1：以巨方塊為單位的解碼流程(MB-level)，解碼流程如圖 4.30(a)。 
Case 2：以畫面為單位的解碼流程(Frame-level)，解碼流程如圖 4.30(b)。 
Case 3：以畫面為單位的解碼流程(Frame-level)並使用帄行處理，解碼流程如圖 4.30(c)。 
Case 4：解碼流程同 Case 3 並加上靜態記憶體配置之優化方法，詳細整理如表 4.5。 
 
本計畫以 QCIF 位元率 100kbps 為基本測詴條件，解碼速度如圖 4.31。本計畫所提的帄行
處理解碼流程加上靜態記憶體配置之優化方法可以達到即時播放(real-time)的需求。由 Case 3
與 Case 4 的執行速度來看，靜態記憶體配置相較於動態記憶體配置約提升 27%解碼速度，由
此可知 H.264/AVC 原始程式花費不少時間執行動態記憶體配置。 
最後，以解碼 300 張畫面的總時間作帄均，以 QCIF 位元率 100kbps 的「Foreman」為測
詴畫面，進一步分析 H.264/AVC 解碼器各部位的執行時間，如圖 4.32。並比較原始 H.264/AVC
解碼器在 ARM 處理器上執行時間與 Case 4 解碼流程分別在兩核心上執行的時間，本作者用
直條圖呈現優化前後兩核心之間執行 H.264/AVC 解碼器解碼 300 張畫面所需要的執行時間，
如圖 4.33。 
 
 
表 4.4 H.264/AVC 編碼器設定參數 
JM version 11.0 
Profile Baseline profile 
RDO On (high-complexity) 
Entropy coding CAVLC 
Frame rate 30 fps 
Total frames 300 
GOP structure IPPPP… 
Rate control On (100kbps) 
Number of reference frames 1 
 
 43 
0
5
10
15
20
25
30
35
40
F
ra
m
e 
ra
te
Decoding speed of H.264/AVC (150kbps)
Original JM 3.884 4.164 4.515
Case 1 12.478 12.767 13.383
Case 2 24.574 25.32 25.439
Case 3 28.095 28.735 29.163
Case 4 34.847 35.646 35.701
Foreman Carphone Mother
 
圖 4.31 H.264/AVC 解碼 300 張畫面之速度：QCIF 150kbps 
 
R/V
Fr 0
I/I/MC/DF
Fr 0
C
Th_1
DSP
Time
R/V : bit-stream reading, VLD C : call the DSP
I/I/MC/DF : intra prediction, inverse transform, motion compensation, deblocking filter
Th_2
ARM
R/V
Fr 1
D
R/V
Fr 2
I/I/MC/DF
Fr 1
...
L : LCD displaying
L
0
D
C
D
L
1
C
D : data transfer
17.5ms 2.84ms 0.96ms
5.5ms
 
圖 4.32 H.264/AVC 各個部分的帄均執行時間：QCIF 
 
 45 
SystemC Code 所設計的 Socket 和一對 Master 與 Slave，其中 Master 主要的功能是負責處理
QEMU 所送來要對 Slave 進行讀取或寫入的 TLM 資料轉換成 AHB 所對應的信號，Slave 的部
份就是做 IDCT 的 column transform，而 Socket 則是用來和 Linux 底下的 Device(/dev/seqemu)
來住行連接的界面，Application 的部份代表 MPEG-2 解碼器的核心程式，這樣一來軟體的部
份就可以透過我們在 Linux 上所建立的 Driver 來與硬體端進行交流。 
  實驗中我們輸入給系統包含 4 張 352x240 畫面大小的 MPEG-2 stream，執行的結果如圖
4.35 所示，左邊的圖代表 QEMU 端模擬的情況，訊息上顯示的數字為軟體向硬體做讀寫的次
數，右邊的圖代表 SystemC 端的模擬，當中的訊息表示的是 AMBA 要做的指令及其接收或傳
送的資料，解碼完的結果會儲存成 YUV 格式的檔案，如圖 4.36 所示。 
 
/dev/scqemu
Application
Master Slave
ARM SystemQEMU(versatile)
Socket
Linux
TLM AHB(RTL)Driver  
圖 4.34 QEMU 系統架構 
 
 
圖 4.35 於 QEMU 上執行 MPEG-2 解碼器共同模擬的過程 
 
  
圖 4.36 解碼完的結果 
 47 
將在第三、第四小節中介紹。而在第五小節中，我們將說明若需實現時間同步化機制時，將
遇到的錯誤細節與錯誤流程。此錯誤的細節與流程，我們將在第六小節中，經由更改新的
wrapper結構以解決此問題。以下我們將開始探討這些技術與細節。 
 
1. BSD socket transaction： 
Berkeley socke 介面係屬於一種 API(Application Programming Interface)，此 API 能夠使主
機之間彼此進行通訊的動作，或是讓一台電腦中的程序彼此能夠互相連結與溝通。像是 I/O
裝置與驅動程式也可以利用此 API概念來進行操作。接下來我們將介紹 BSD socket 中所含有
的基本 API功能： 
 socket()：建立一個通訊的節點，傳回一個 socket 的檔案描述器(file descriptor)。 
 bind()：指定一個位址給已建立的 socket。 
 listen()：設置已建立位址的 socket 為等待連接的狀態。 
 accept()：移除 listen佇列裡一個等待連接的 socket，並為之建立一個新的已連接 socket。 
 connect()：連結 socket 至遠端主機。 
 send()：經由連結的 socket 傳送資訊。 
 recv()：接收由連結的 socket 傳送過來的資訊。 
我們將舉個例子，以解釋其動作流程，如圖 4.38 所示。在此例中，不同的元件將擁有不
同的函式區塊，如 Initiator 的 bus_request()、Channel 的 bus_access()、Target 的 server_int()等
等。在一開始，發起端利用通道傳送一個要求訊號至連結目標。在模擬開始時，所有的元件
將建立起 socket，故需執行 soccket()函式。而之後的整體傳輸過程共分為 6 個步驟： 
 步驟一：若發起端頇送出要求的訊號，則將會執行 bus_request()，並且執行 accept()功能
以等待連接 connect()即將傳來的資訊；而 connect()會在通道執行 check_requet()時啟用。
以上的過程即代表通道接收到發起端的要求訊號，並準備開始接收資料的傳輸。 
 步驟二：發起端將利用 send()的函式來送出要求的資料訊息，之後通道執行 revc()函式來
接收這些資料。 
 步驟三：通道取出發起端要求的訊號中的位址資訊，以便將連結目標加以定位，並且告
知連結目標有要求的訊號即將到來。 
 步驟四：在通道與連結目標之間的連接確立之後，發起端所要求的資訊將由通道傳送到
連結目標。其中通道藉由 send()函式來送出發起端的要求訊號，且連結目標藉由 recv()的
功能來接收發起端的要求訊號。 
 步驟五：連結目標回應的資訊將先傳至通道。這時連結目標利用 send()功能來發出回應資
訊，而通道則利用 recv()的功能去檢索此回應。 
 步驟六：通道將連結目標所回應的資訊將傳回至發起端。這時通道利用 send()功能來發出
回應資訊，而發起端則利用 recv()的功能去檢索此回應。 
 
 49 
Master Slave
Master
Wrapper
Slave
Wrapper
Bus Model
TCP/IP 
Transaction
SystemC 
Transaction
TCP/IP 
Transaction
SystemC 
Transaction
 
圖4.39 共同模擬架構範例 
 
Master Wrapper Initiate
Master send 
request ?
Send request to bus
Get response from bus
Status ?
Wait(Bus time – Master time)
Request ?
Send response to master
No
Yes
R_WAIT
R_DONE
Read
Write
Slave Wrapper Initiate
Bus send 
request ?
get request from bus
Send response to bus
Status ?
Wait(Bus time – Slave time)
Send request to slave
No
Yes
R_WAIT
R_DONE
Get response from slave
Request ?
Write
Read
 
(a)                  (b) 
圖 4.40 (a)Master wrapper 的控制流程圖 (b)Slave wrapper 的控制流程圖 
 
3. Master與Slave 
 本實驗所設計的 wrappers 必頇掌控兩個主要工作：處理在元件(master 或 slave)與匯流排
之間傳送要求訊號或回應的資訊，還有將元件的模擬時間與匯流排的模擬時間進行時間同步
化的動作。 
圖 4.40 表示出 master wrapper 與 slave wrapper 的控制流程。在一開始他們都進行等待的
 51 
包含了QEMU ARM模擬器、匯流排模型與兩個SystemC的元件(master 與slave)，如圖4.41所示。 
除了測詴CPU對Slave送出要求訊號所花費的時間，我們也在帄台中加入一個master元
件，該master同樣對slave不斷的送出要求訊號，讓我們可以觀察兩者對爭奪匯流排的動作進行
比較。其中我們利用OCP-IP協定做為內部IP彼此進行溝通的橋樑，讓master或slave與wrapper
之間建立起資料傳輸的介面。實驗結果顯示於Table IV。 
我們模擬了兩種情況，一種是有master的情況，而另一種是關閉master的情況。而兩者的
差異是關閉master的時候，匯流排將只接收QEMU模擬的ARM所送出的要求信號，而不會發
生搶奪匯流排的情況。 
由於我們使用TCP/IP協定，所以無法精確的知道host之間的封包交換時實際花費的時間，
這將造成每次測詴出的時間都不固定；所以我們將每份樣本測詴十次，再取其帄均。而測詴
方式是將QEMU模擬的CPU對slave端分別進行10萬次的讀取與寫入的動作；另一樣本是在開
啟master的情況下，QEMU與master都各別發出10萬次的讀取或寫入。我們可由表4.6看出，若
開啟master時，整體花費時間將趨近於兩倍。 
 
Server
Socket
QEMU
(ARM CPU)
Server 
Socket
Software
Slave 
Wrapper
Server
Socket
Simple
SlaveOCP 
Channel
Simple
Master
OCP 
Channel
Bus
Client
Socket
Cross 
Compiler
Master 
Wrapper
 
圖4.41 QEMU ARM與master和slave所模擬的帄台 
 
表4.6 測詴匯流排的模擬時間 
 
 
 53 
與 heap 的位址等等。當主要的執行流程準備妥善時，QEMU 將切入其主要的執行迴圈
cpu_exec()，此迴圏將不斷執行直到 QEMU 結束其系統模擬的過程。 
在 CPU 主要的執行迴圈當中，在進入此迴圈的一開始，QEMU 即會透過一環境變數
exeception_index，以決定系統是否有中斷或例外發生。若有中斷或例外發生，則透過變數
exeception_index 判斷為何種中斷模式，並將此中斷模式加以執行並模擬。其中 QEMU 判斷
變數 exeception_index 的方法是透過 do_interrupt()函式，以決定 exeception_index 變數的值
為何。 
QEMU 使用者模式與系統模式兩者在一開始的模擬流程非常相似，除了使用者模式並沒
有模擬其他週邊的元件之外，使用 do_interrupt()函式判斷中斷或例外時，使用者模式的
do_interrupt()函式將會只回傳-1，換句話說，使用者模式中變數 exeception_index 將永遠為
-1，這表示使用者模式並沒有控制中斷機制的方法，但系統模式可透過 do_interrupt()函式回
傳至變數 exeception_index 的值加以判別為何種中斷或例外，並進行相對應的處理模式。 
其中能令 do_interrupt()回傳值的 op code 只有系統模式可以執行，使用者模式並沒有能
夠更改 do_interrupt()回傳值的 op code，這也是本計劃只能由使用者模式加入中斷機制的原
因之一。表 4.7 可得知使用者模式與系統模式在模擬中斷與例外時兩者之間主要的差異。 
 
(II) 於 QEMU 使用者模式加入中斷機制之方法 
 
經由上一章節可了解使用者模式的 QEMU 並沒有支援中斷機制的控制流程。為了加入硬
體中斷的功能至 QEMU 所模擬的 CPU，除了需將外部信號傳送至 CPU 中，並加以控制 CPU
所檢查的變數 exeception_index，並依據此變數的值，以決定要實現何種中斷機制，即令 QEMU
所模擬的 CPU 進行對應的 ISR。 
透過先前建立系統匯流排的過程中，可了解 socket 技術能夠使不同的元件在彼此之間建
立傳輸資料的橋樑。因此，本計劃透過 socket 技術，由 SystemC 所模擬的硬體傳送特定的值
至 QEMU 所模擬的 CPU 的內部變數 exeception_index，令使用者模式的 QEMU 能夠在檢查
此變數時，也能夠接收到不同的值並針對此值作相對應的 ISR。 
選擇所模擬
的系統
初始化系統
與記憶體
模擬系統的
主要迴圈
 
圖 4.42 QEMU 主要的執行流程 
表 4.7 QEMU 系統模式與使用者模式中斷模式之間的差異 
模式 執行 do_interrupt() 行為 
系統模式 判斷變數 exeception_index 判斷為何種中斷 
使用者模式 回傳-1 至變數 exeception_index 不做任何中斷 
 55 
(burst length)，是以資料所對映的記憶體位址來決定。使用者可規劃此記憶體位址能夠存取多
少筆資料至暫存器，暫存器存取達到所規劃的資料筆數之後，CPU 即開始透過 socket 將資料
進行大量傳輸，其執行大量傳輸資料的方式如圖 4.45。 
其中大量寫入資料過程的限制為所寫入的位址，需事先準備好被寫入的空間，每被寫入
一次資料時，需將資料指向下一筆資料位址，以避免 CPU 覆蓋上一筆資料。 
其中讀取資料過程的限制為所讀取的位址，需事先準備好被讀取的資料，每被讀取一次
資料時，需將資料指向下一筆資料位址，以避免 CPU 讀取同一筆資料。在進行資料傳輸的過
程中，每使用一次 socket 的機制，都需事先規劃、使用與清除不少暫存器與記憶體，這將耗
費不少模擬時間。透過上一章節中所實現的大量傳輸方式，可以減少使用 socket 的次數，進
而節省虛擬帄台模擬時所花費的時間。 
若虛擬帄台的系統匯流排在單筆寫入資料時所耗費的模擬時間為 VSW ，虛擬帄台在大量
寫入資料時所耗費的時間為 VBW ；AHB 在單筆寫入資料時所耗費的時間為 RSW ，AHB 在大量
寫入資料時所耗費的時間為 RBW 。依照虛擬帄台與理想狀態的 AHB 兩個單位的差異，將虛擬
帄台在大量寫入資料與單筆寫入資料時的兩者進行等比例的運算，若已知 VSW ，則可得 VBW ，
其算式如下： 
 
VS
VB
RS
RB
W
W
W
W
  (4.4) 
在得知虛擬系統匯流排單筆資料寫入時所花費的時間，可透過算式取得等比例的大量傳輸所
應該花費的時間。將大量傳輸花費的時間加入至系統匯流排所運算的模擬時間，可使虛擬帄
台的系統時間能夠得到等比例的時間同步化，進而能夠維持虛擬帄台模擬資料傳輸時間的功
能，使 H.264/AVC 解碼器的範例的模擬情形能夠更合理化。 
 
 
OCP
Channel
Server
socket
Wrapper
Server
socket
Client 
Socket
Display
Module
Software :
H.264/AVC 
Decoder
System
Bus
QEMU CPU
Cross-
compile
  
圖 4.44 QEMU 執行 H.264/AVC 解碼器 
 
 
 57 
能確認系統需要多少顆 CPU，才能使軟體的演算法達到最佳的效能，例如視訊相關的演算法
需要達到每秒 25 張圖片的速度，令使用者能夠輕鬆的觀望影片。 
本計劃將提出加入估計 QEMU 模擬能力之方法，令程式設計者在系統設計初期即能夠估
計軟體的運算複雜度。所估計運算複雜度的單位將採用 MIPS (million instruction per second)。
其中，為了使用 MIPS 來估計運算複雜度，需得知兩項主要的資訊： 
1. QEMU 執行軟體的時間，即系統的模擬時間。 
2. 所執行的軟體之運算複雜度。 
在得知這兩樣主要資訊之後，即能夠計算 QEMU 在進行模擬時之 MIPS 資訊。在接下來
將描述如何取得這兩種資訊的方法。 
為了利用 MIPS 來計算 QEMU 模擬之 CPU 所處理的軟體複雜度，首先需計算 QEMU 執
行軟體的時間，以做為計算 QEMU 所處理的 MIPS 量。常見的時間計算方式是由<time.h>的
函式庫所提供，因此，本計劃將透過此函式庫以加入計算QEMU執行軟體時間的功能至QEMU
之中。如圖 4.46，透過 QEMU 使用者模式所使用的 main.c 檔案中的 cpu_loop()函式，可以得
知此函式為 QEMU 執行軟體模擬的主要流程本作者在 QEMU 執行此函式之前即記錄其模擬
時間即 Time_Initial，作為紀錄系統開始進行模擬之時間。 
在了解初始化時間之後，接著需找出軟體執行完成的時間，也就是 QEMU 所模擬的 CPU
執行完成軟體的時間，以將此時間與先前所記錄的初始話時間進行相減，使系統能夠得知總
共執行軟體所耗費的時間。經由觀察 QEMU 的原始程式碼，可以發現在 cpu_loop()函式中，
程式將執行完成軟體時，會將環境變數 env 中的暫存器的值變為 0xFFFFFFFF，接著將呼叫內
建的 syscall()函式，以表示程式將執行完成。經由確認暫存器的的值變為 0xFFFFFFFF 之後，
即馬上記錄 QEMU 的模擬時間即 Time_Final，以表示軟體執行完成後的時間。 
表 4.8 為 QEMU 加入記錄時間的位置，即 Time_Initial 與 Time_Final。在得知 QEMU 模
擬軟體的時間(即 Time_Initial－Time_Final)之後，即能夠開始估計 QEMU 在 host 端中所能
執行多少 MIPS。 
接著頇計算 QEMU 在 host 機器上能夠執行多少 MIPS。在本計劃中將以 H.264/AVC 解碼
器的運算複雜度作為基礎，以評比 QEMU 每秒能夠執行多少 MIPS。首先頇將 H.264/AVC 解
碼器區分為原始程式 JM11.0 以及優化過後的程式[22]，並將兩者經由 ADS 1.2 profiling 之後
所得之 MIPS；以及 QEMU 執行優化前與優化後的解碼 25 張 foreman 圖片之時間如表 4.9。
經由表 4.9 所得到的資訊之後，可將 MIPS 除以 QEMU 的執行時間，此時會發現兩者的比例
並不相等，這時由於 QEMU 模擬 CPU 時含有額外的模擬負擔 X，並透過下式重新計算 QEMU
所能夠處理的 MIPS 數： 
 
Initial
CPU
cpu_loop() (Env->regs = 
0xFFFFFFFF)
Time_Initial Time_Final
 
圖 4.46 加入 QEMU CPU 計算執行軟體時間之位置 
 59 
之 Stub 稱為 Skeletons)，Stub 將使用者欲送出的溝通訊號或參數在 IPC Software Layer 加以封
裝。ARM 將封裝後的資料透過共享記憶體(shared memory)作為 IPC Physical Layer，傳送至
DSP 以驅動 DSP 中的應用程序。其中，透過存取共享記憶體中的 INTGEN(interrupt generate)
暫存器，ARM 與 DSP 可對彼此傳送中斷訊號，以透過此中斷訊號在彼此之間進行溝通。 
ARM 使用 RPC 時，將會停止(blocking)當前的執行緒，以等待 DSP 的信號燈(semaphore)
回應，若 ARM 中擁有次一級的執行緒時(由使用者規劃)，此時 ARM 將驅動次一級的執行緒，
令 ARM 與 DSP 同時帄行處理，以增進系統之效能。在 DSP 回應信號後，ARM 將回復(unblock)
停止的執行緒並將其繼續執行。透過了解達芬奇開發版不同核心之間的溝通方式，可將其行
為架構做為依據，模擬其溝通方式並考慮如何加入至雙核心的虛擬帄台之中。 
 
System Bus
ARM 926EJS
16 KB
Cache
8 KB
ROM
8 KB
D Cache
16 KB
RAM
C64x+ DSP
32 KB
L1P
Cache
80 KB
L1D
Cache
64 KB L2 RAM
Video Processing
CCD
Controler
OSD
Resizer
Video
Encoder
System
Control
JTAG
Interface
Peripherals
DDR2
SDRAM
 
圖 4.47 達芬奇開發版架構簡圖 
 
Client Server
1
2 3
48
67
5
網路網路
遠端Server
處理程序
呼叫Server
遠程處理程序
Codec Engine
RPC STUB
Codec Engine
RPC SKEL
 
圖 4.48 達芬奇異質核心控制流程圖 
 
 61 
Client()
socket()
connect()
STUB
socket()
bind()
listen()
accept()
Server()
SKEL
 
圖 4.50 socket 技術模擬 STUB 與 SKEL 
Core 2Core 1
Client()
A
E
C
B
D
Server()
Client()
Server()
 
圖 4.51 使用執行緒控制機制的範例 
 
圖 4.51 中，在系統開始模擬時，由於 Core 2 執行 Server()函式停止自己的執行緒，故可
將系統的執行緒視為步驟 A。直到 Core 1 執行 Client()喚醒 Core 2 的執行緒(步驟 B)，並執行
Server()函式以停止自己的執行緒，此動作可視為執行緒的切換。在 Core 2 執行步驟 C 至
Client()函式並喚醒 Core 1 之後，系統的執行緒經由步驟 D 切換回 Core 1 的執行緒，Core 1
繼續執行接下來的程式步驟 E。其中，若 Core 1 執行完 Client()函式並不馬上接著執行 Server()
函式時，即 Client()函式不馬上接著執行 Server()函式，而是執行其他需處理的程式時，系統
可以達到帄行處理的效果。 
達芬奇開發版在不同核心之間的溝通技術分為三部份： 
1. 以客戶端與伺服器之概念，將溝通訊號透過 Stub 函式封裝。 
2. 透過共享記憶體傳輸訊號。 
3. 透過信號燈切換不同核心之間的執行緒。 
在本計劃所提出的虛擬帄台之中，不同核心之間的溝通方式亦是以客戶端與伺服器的概
念所建立信號傳輸，所使用的 Client()與 Server()函式亦包含信號燈之概念在其中。與達芬奇
開發版不同之處為信號的傳輸，並非透過共享記憶體傳送，而是在不同核心之間建立連結線
以傳送訊號，也就是與上述之第三部份不相同。透過連結線傳送訊號，可省略將訊號存取至
 63 
表 4.10 單筆與大量寫入所花費時間之差異 
解碼的圖片張數 單筆資料寫入 大量資料寫入 
100 張圖片 150 分鐘 5 分鐘 
 
 
圖 4.53 H.264/AVC 解碼器加入大量傳輸之模擬結果 
 
B. 估計 QEMU 使用者模式之 CPU 操作頻率 
本計畫在 QEMU 中加入計算模擬時間之功能，與透過將軟體事先 profile 後，得到 QEMU
在 host 機器中(IBM System x3400)能夠處理的 MIPS 數。接著本計畫將提出估計 QEMU 所模
擬 CPU 的操作頻率之方法。 
首先，透過[22]可以得到 ARM926EJ-S (266MHz) 與 QEMU 執行優化後的 H.264/AVC 解
碼器之速率，其執行時間以每秒解碼多少張圖片(FPS)為單位，並將數據整理於表 4.11。透過
表 4.11 中的數據，可以利用下式得知 QEMU 在此 host 機器中的操作頻率Y ： 
 
25.3172.17
266 YMHz
  (4.7) 
 65 
4.55 之實驗結果進行比較，可看出兩者所需的 CPU 之差異，並令系統開發者能夠在使用虛擬
帄台時獲得更多資訊。 
C. 雙核心虛擬帄台之模擬 
1. 帄行處理機制於虛擬帄台之建立 
透過將 socket 機制以不同於以往的傳輸資料方式來使用，本計畫使用 socket 中客戶端與
伺服端可以彼此進行呼叫的概念，使 socket 機制能夠整合不同 CPU 之間的執行緒，令虛擬帄
台能夠進行多核心之間的模擬。由於所使用的 socket 技術為常見的信號傳輸方式，於大多數
的作業系統中皆有使用其技術的蹤跡，因此虛擬帄台的系統仍維持舊有的可適性，可以在各
個作業系統中進行模擬。再加上所提出的溝通方法相當容易實現，也保持了系統的靈活性與
可攜性，令使用者可以輕鬆的模擬多核心架構的 QEMU CPU 與建立虛擬帄台。圖 4.56 為虛
擬帄台的架構圖，透過執行緒控制機制(thread controller)以掌控不同核心之間的執行緒，可
建立如圖 4.57 中的系統執行流程，H.264/AVC 編碼器與解碼器中間的連線部份(以下將簡略
H.264/AVC 之稱呼)，即為執行緒控制機制作為控制的不同 CPU 之間的流程，在編碼器每編碼
完一張圖片時，編碼器將透過執行緒控制機制喚醒等待狀態的解碼器，解碼器及開始解碼流
程，此時編碼器與解碼器為帄行處理的狀態。 
由於解碼器的執行速度較編碼器快，因此解碼器每解碼完一張圖片時，將進入等待的狀態，
以等待編碼器處理完新一張的圖片之後，才會再執行解碼的流程。其中解碼器一開始讀取完
bitstream 時，將判別 bitstream 是否可以解碼與確認其編碼的型態，因此在開始編碼前需要兩
個準備的狀態。基於上述的原因，整體的系統流程將會是編碼器先處理完 25 張圖片，此時編
碼器將取消等待的狀態，將剩餘的 23、24 與 25 張圖片解碼，並傳送至 display 元件加以顯示。
圖 4.58 為實際上的模擬圖，為了單純的驗證雙核心虛擬帄台的功能性，簡易的共享記憶體部
分將無列入模擬中，因此圖 4.58 中並沒有模擬共享記憶體的區塊。此系統編碼與解碼 25 張圖
片將耗費約 4 分鐘，其中解碼器的部份沿用大量寫入技術，以降低所耗費的模擬時間與驗證
雙核心帄台的時間。由實驗結果可得知，本計畫所提出的雙核心帄台之溝通方法，能夠成功
的在不同核心之間進行共同模擬。 
 
OCP
Channel
Server
socket
Wrapper
Server
socket
Client 
Socket
Server
socket
Display
Module
Thread
Controller OCP
Channel
Wrapper
Server
socket
Shared
Memory
OCP
Channel
Wrapper
Server
socket
H.264/AVC
Encoder
QEMU with
H.264/AVC 
decoder
System
Bus
QEMU with
Rate-Control
 
圖 4.56 雙核心虛擬帄台系統架構模擬 H.264/AVC 編碼器與 H.264/AVC 解碼器 
 67 
2. 雙核心系統視訊解碼器程式於本實驗帄台之應用 
接著本計畫將提出不同的雙核心帄台架構如圖 4.59 所示，此範例主要為執行 H.264/AVC
解碼器，但 H.264/AVC 解碼器之 deblocking filter 的部份切出至另一個 QEMU 所模擬的 CPU
執行。切出此部分的原因主要為 deblocking filter 的運算複雜度較高且數學運算較多，在真實
開發版中往往將其以 DSP 的部份加以執行，本計畫將以虛擬帄台模擬真實開發版的行為模
式，除了能夠驗證虛擬帄台的正確性與功能性之外，亦可針對真實情況做系統效能的評估及
驗證演算法的正確性。 
系統的模擬流程如圖 4.60，在系統模擬的一開始 deblocking filter 將執行 Server()函式，
以等待 H.264/AVC 解碼器處理執行 deblocking filter 所需的必要資訊；此時 H.264/AVC 解碼器
將直接進行解碼流程。直到 H.264/AVC 解碼器將 deblocking filter 所需的必要的資訊存入共享
記憶體(shared memory)之後，即利用 Client()函式喚醒 deblocking filter 的 Server()函式。接著
H.264/AVC 解碼器將使用 Server()函式以等待 deblocking filter 的部份執行完成。在 deblocking 
filter 執行完成，並將欲傳回 H.264/AVC 解碼器的資訊存至共享記憶體後，deblocking filter 將
執行 Client()函式以喚起 H.264/AVC 解碼器的 Server()函式，接著 deblocking filter 再次使用
Server()函式以等待下一張解碼的圖片。H.264/AVC 解碼器被 deblocking filter 的 Client()函式
喚醒之後，即繼續進行解碼的動作並將執行結果輸出至 display 模型。此外，由圖 4.60 中也可
看出在第二張圖片之後，不同 CPU 之間帄行處理的部分，如 CAVLD/IQ/IDCT 與 deblocking 
filter 帄行處理；MC/Intra 與 Display 的部份進行帄行處理。 
接著，也可較精確的模擬虛擬帄台的行為模式，由於 ARM 與 DSP 之溝通方式，需透過
存取共享記憶體中的暫存器以對彼此傳送中斷訊號。因此，本子計畫在虛擬帄台中之共享記
憶體加入一暫存器，透過存取此特定暫存器以向不同核心送出中斷訊號，以控制系統之執行
緒。不同於圖 4.60 的 H.264/AVC 解碼器直接呼叫 Client()函式以喚醒 deblocking filter 的執行
緒，圖 4.61 的 H.264/AVC 解碼器需先存取在共享記憶體中的對 Core 2 之中斷暫存器，之後暫
存器將對 Core 2 送出相對應的中斷訊號，並喚醒 Core 2 之執行緒以進行 deblocking filter 相關
的工作。deblocking filter 完成之後，也透過共享記憶體中的暫存器喚醒 Core 1 之執行緒。 
 
OCP
Channel
Server
socket
Wrapper
Server
socket
Client 
Socket
Server
socket
Display
Module
Thread
Controller
OCP
Channel
Wrapper
Server
socket
Shared
Memory
QEMU with
Deblocking 
filter
System
Bus
QEMU with
H.264/AVC 
decoder
 
圖 4.59 雙核心虛擬帄台系統架構模擬 H.264/AVC 解碼器與 deblocking filter 
 69 
其中，此範例之實際模擬結果為圖 4.62，其系統模擬時間較圖 4.58 之範例多，解碼 25
張圖片耗費 13 分鐘，這是因為存取共享記憶體的資料量多寡所造成的差異。此外，對於不同
精細度之模擬方式也進行模擬時間上之比較，如表 4.12 可看出兩者的模擬時間相當接近，這
是因為詳細模擬的部份每張圖片只需額外存取兩次共享記憶體，以宏觀的角度觀察之下，對
整體系統存取共享記憶體之次數並沒有顯著的增加，原先的因此所花費的模擬時間亦沒有顯
著的增加。 
表 4.15 H.264/AVC 解碼器雙核心模擬時間之比較 
 
圖 4.65 之簡化模擬 
雙核心溝通方式 
圖 4.66 之詳細模擬 
雙核心溝通方式 
解碼 25 張圖片 
之時間 
802sec. 804sec. 
 
 
圖 4.62 H.264/AVC 解碼器雙核心之實際模擬結果 
 71 
   
(a)                                   (b) 
圖4.63 目前畫面與前一張畫面MAD的關係 (a) Foreman位元率為48 kbps, (b) Carphone位元率
為48 kbps。 
 














else.,
4
  3
 if1.25,
4
  3
 if0.75,
'
p,f
ul
dlp,f
ud
lu
p,f
p,f
MAD
QPQP
QPQPMAD
QPQP
QPQP
MAD
MAD               (4.11) 
在 MB-level 方面，則是利用周圍的 MB 來預測 MAD 值，如下圖所示，假設目前編碼的
MB 為 MBE，以實驗結果得知，虛線框內的區塊（MBB、MBD、MBF和前一張畫面中與 MBE
同位置的區塊）對於預測的 MAD 值影響最大，所以再觀察帄均的 MAD(
gopMAD )與 MAD 預
測的差值 ( dMAD )來調整虛線框內 MAD 值的權重，即可用下頁的流程圖 4.66 來得到預測的
MB-level MAD 值。 
最後，本子計畫再根據實際編碼bit數與實際MAD值跟預測值之差別來調整QP值，其演算
法如下所示： 
   






else,,
)8/(if,
,,'
MADbit
mbit
uu
QPQP
NnQP
niQPniQP               (4.12) 
    1 ,, '' niQPniQP ul  ,       (4.13) 
其中 
 
 73 






else ,]1[×]1[
1if ,]1[ ×
][
a
c
 i,n-MADi,n-b
 n                  i,n-MAD 
i,nb
a,mcctg,
a,m
ctg,a 

      (4.16) 
][×
][
iMADN
ib
p,fm
tg,f
 ,       (4.17) 
 
 





















else,,log
0 if,log-
2
2
MAD
avg
MAD
MAD
avg
MAD
e
MAD
n
e
e
MAD
n
QP


          (4.18) 
 
 


 

else,,3
4/if,2 mNn
n         (4.19) 
eMAD[i, n-1] =
 
 




else.   ,2/]1,[][]1,[
8/if                                ],1,[][
,
,
niMADiMADnie
NnniMADiMAD
avgfpMAD
mavgfp
 (4.20) 
   







 
 2
2
 ,, '''
'
p,f
p,m
uu
MAD
MAD
niQPniQP       (4.21) 
   
















 1log-,, 2
'''
p,m
'
p,f
ll
MAD
MAD
niQPniQP      (4.22) 
其中 Nm 為一張畫面中所有 MB 的數目，λ 為一權重值，其預設值為 32， . 代表無條件捨去。
ba,acc [i,n-1] 和 btg,acc [i,n-1] 為所有編碼 bit 的累加和所有目標編碼 bit 數的累加。btg,f [i] 是第 
i-th 張畫面的目標 bit 數，MADavg 目前畫面的帄均 MAD 值。 
此外，與位元率控制與 H.264/AVC 硬體做結合時，還必頇考慮到硬體管線(pipeline)化所
造成的影響，如下圖所示，Wu et al. [54]將位元率控制(RC)與 integeral motion estimation (IME)
結合變成第一級的硬體，第二級為 fractional motion estimation (FME)，第三級為 intra 
prediction，最後一級則是 entropy encoding(EC)和 deblocking fileter(DB)。 
由於硬體管線化的限制，要提供給 RC 的 MAD 值和 bit 數無法從前一個 MB 得到，只能
分別從前面第 3 個和第 4 個 MB 之前得到，因此演算法也要跟著調整，在所提出之演算法中
會受到影響的公式如下所示 
 
     
      





else,2,/1--1,--1--,1-,
1- and 1 if,1--1,--1--,
,


niMADniMADniMAD
niniMADniMAD
niMAD
a,ma,md
a,ma,m
d
     (4.23) 
當 H.264/AVC 切成四級和三級時 α 分別等於 2 和 1。 
 
 75 
表4.15 時脈數與硬體成本之比較 
方法 
硬體 軟體 
邏輯閘數 時脈數 時脈數 
本子計畫 
Frame-level n/a n/a 9108/frame 
MB-level 5K 6/MB 2204/MB 
JVT-G012 
Frame-level n/a n/a 35244/frame 
MB-level n/a n/a 35000/MB 
Gu [53] 144K 608/MB n/a 
 
 
 77 
 
圖 4.68 “Foreman”在每張畫面的編碼位元數。 
 
 
圖 4.69 “Carphone”在每張畫面的編碼位元數。 
 
  
 
 
 
 
 79 
本篇論文說明改良虛擬嵌入式帄台的方法，以提供實際的系統在設計初期能夠進行驗證演
算法與觀察系統行為的帄台。為了因應不同情況的模擬架構，利用 socket 的特性在使用者模
式的 QEMU 模擬中斷機制，以模擬硬體中斷的架構，使 SystemC 所模擬的元件，能夠直接存
取 QEMU 內部判斷中斷機制的變數，讓使用者可以自由的開發自己所需要的中斷模式。透過
大量傳輸資料的功能，可減少 QEMU 將資料傳輸至硬體部分所耗費的時間，也因此降低系統
所花費的模擬時間；並且依照所傳輸的資料量，在系統匯流排中加入適當的延遲時間，以維
持系統估計模擬時間的特性。接著是提出估計 QEMU 在 host 機器上所模擬的 CPU 之操作頻
率的方法，令設計者在系統設計初期即能夠獲得 QEMU 所模擬的 CPU 之操作頻率，並評估
所開發的系統軟體是否能夠達到預期的效果。最後是利用 socket 的特性模擬雙核心的 CPU，
透過整理 QEMU 中不同核心之間的執行緒，實現雙核心虛擬帄台中的 IPC，令不同的 CPU 彼
此能夠進行共同模擬，因此延伸虛擬帄台的功能性，令真實系統架構中的開發版能夠有驗證
功能性的虛擬帄台。 
在未來的相關工作中，由於虛擬帄台的執行時間是由 SystemC 模型所估計，也因此無法
估計 QEMU 內部的執行時間。雖然本研究對 QEMU 進行大量存取時，在系統匯流排同步模
擬時間，但 QEMU 仍舊執行於 un-timed 抽象層級之下，所估計的模擬時間只包含同步的時間
與 SystemC 元件處理的時間。因此，若是能在未來中選用以 SystemC 所建立的核心，將可以
使模擬時間更為完整。 
虛擬帄台中的系統匯流排，雖然有時間同步化與仲裁器的功能，但其基底仍是由 socket
技術所建立而成，若是能夠將其以其他較接近實際系統架構的協議建立，如：SystemC 建立
的 AMBA 或 OCP-IP 等，則可以使虛擬帄台的架構更趨近實際的系統架構。在虛擬帄台的實
驗結果中，可由圖 4.61 中看出所使用的畫面共有五個終端機與一個 display 的顯示器，若是在
未來所模擬的元件數增加時，如多核心架構，將會使操作的作業環境過於凌亂。若是能以簡
易的作業環境將不同的元件進行整合，像是 Coware 的整合方式，如圖 5.2，將可令使用者獲
得較簡潔的作業環境。 
目前已透過 socket 的特性建立擁有可適性的同質雙核心虛擬帄台，在未來若擁有 DSP 模
型，則可建立 ARM 與 DSP 的異質雙核心模擬帄台，使帄台的功能性更能夠趨於完整。除此
之外，也可在系統中加入估計電源控管相關的研究，以因應現下流行的綠科技 (green 
technology)，藉由估計系統所耗費的電源，可在設計系統時即規劃所使用的電源量，使將來
的產品能夠較易設置在手持式裝置中。 
在未來亦可建立多核心的虛擬帄台，透過執行緒控制機制可輕鬆的控制不同 CPU 之間的
執行緒。在建立多核心虛擬帄台的過程中，使用者需注意不同核心之間所執行的先後順序，
並注意整體系統的控制流程，以及避免頻繁的使用執行緒控制機制，否則模擬的過程將會如
表 4-11 的實驗結果，造成模擬時間過於冗長。 
在位元率控制之軟硬體共同設計方面，雖然所提出的演算法可提昇位元率-失真效能並有
較低的位元濾波動效果，但如果應用到實際硬體上依然會受到硬體管線化的影響，使得位元
率-失真效能降低，因此發展不會受到硬體管線化影響的位元率控制演算法就相當重要，也是
為來發展的重點之一。 
 
 81 
六、參考文獻 
[1] T. Wiegand, G.J. Sulivan, G. Bjntegaard, and A. Luthra, “Overview of the H.264/AVC video 
coding standard,” IEEE Trans. Circuit Syst. Video Tech., vol. 13, no. 7, pp. 560-576, July 2003. 
[2] http://www.ti.com.tw 
[3] Texas Instrument Inc., “TMS320DM6446 Digital Media System-on-Chip,” Literature Number: 
SPRS283F, Dec. 2005. 
[4] X. Zhou, E. Q. Li, and Y. K. Chen, “Implementation of H.264 decoder on general-purpose 
processors with media instructions,” in Proc. SPIE Symp. Image and Video Commun. and 
Processing, May 2003, pp. 224-235. 
[5] J. Lee, S. Moon, and W. Sung, “H.264 decoder optimization exploiting SIMD instructions,” in 
Proc. Circuits and Syst., IEEE Asia-Pacific Symp., Dec. 2004, pp. 1149-1152. 
[6] S. Warrington, H. Shojania, and S. Sudharsanan, “Performance improvement of the H. 
264/AVC deblocking filter using SIMD instructions,” IEEE Int. Symp. Circuits Syst., Sep. 2006, 
pp. 2697-2700. 
[7] P. P. Dang, “An efficient implementation of in-loop deblocking filters for H.264 using VLIW 
architecture and predication,” in Proc. IEEE Int. Symp. Consumer Electron., Jan. 2005, pp. 
291-292. 
[8] F. Pescador, C. Sanz, M. J. Garrido, C. Santos, and R. Antoniello, “A DSP based IP set-top 
box for home entertainment,” in Proc. IEEE Int. Symp. Consumer Electron., vol. 52, pp. 
254-262, Jan. 2006. 
[9] F. Pescador, M. J. Garrido, C. Sanz, E. Juarez, A. M. Groba, and D. Samper, ”A real-time 
H.264 BP decoder based on a DM642 DSP”, Int. Symp. Signal Process. Commun., Nov. 2007, 
pp. 1491-1494. 
[10] F. Pescador, C. Sanz, M. J. Garrido, E. Juarez, and D. Samper, “A DSP based H.264 decoder 
for a multi-format IP set-top box,” IEEE Trans. Consumer Electron., vol 54, pp. 145-153, Feb. 
2008. 
[11] F. Pescador, G. Maturana, M.J. Garrido, E. Juarez, and C. Sanz, “An H.264 video decoder 
based on a DM6437 DSP,” in Proc. IEEE Int. Symp. Consumer Electron., May 2009, pp. 1-2. 
[12] F. Pescador, G. Maturana, M. J. Garrido, E. Juarez, and C. Sanz, “An H.264 video decoder 
based on a latest generation DSP,” IEEE Trans. Consumer Electron., vol. 55, no. 1, pp. 
205-212, Feb. 2009. 
[13] Texas Instruments. TMS320DM642 Video/Imaging Fixed-Point Digital Signal Processor. 
Available online at: 
http://focus.ti.com/docs/prod/folders/print/tms320dm642.html 
[14] Texas Instrument Inc., “EDMA v3.0 (EDMA3) Migration Guide for TMS320DM644x 
DMSoC,” Literature Number: SPRAAA6, Dec. 2005. 
[15] L. Hui, X. Ru, and L. Zhi, “Implementation of H.264 on TMS320DM642,” in Proc. Embedded 
 83 
[34] V. Zivojnovic and H. Meyr, “Compiled HW/SW co-simulation,” in Proc. Design Automation 
Conf., Jun. 1996, pp.690-695. 
[35] A. Nohl, G. Braun, O. Schliebusch, R. Leupers, H. Meyr and A. Hoffmann, “A universal 
technique for fast and flexible instruction-set architecture simulation,” in Proc. Design 
Automation Conf., Jun. 2002, pp.22-27. 
[36] M. Reshadi, P. Mishra and N. Dutt, “Instruction set compiled simulation: a technique for fast 
and flexible instruction set simulation,” in Proc. 40th Design Automat. Conf., Jun. 2003, 
pp.758-763. 
[37] S. Yoo and K. Choi, “Optimizing timed cosimulation by hybrid synchronization,” Des. Autom. 
Embedded Syst., vol.5, no.2 pp.129-152, Jun. 2000. 
[38] J. Jung, S. Yoo and K. Choi, “Performance improvement of multiprocessor systems 
cosimulation based on SW analysis,” in Proc. Design Automation and Test in Europe, Mar. 
2001, pp.749-753. 
[39] S. Yoo, K. Choi and S. H. Dong, “Performance improvement of geographically distributed 
cosimulation by hierarchically grouped messages,” IEEE Trans. Very Large Scale Integr. (VLSI) 
Syst., vol.8, no.5, pp. 492-502, Oct. 2000, 
[40] L. Benini and G. D. Micheli, “Networks on chips: a new SoC paradigm,” Computer, vol.35, 
Issue 1, pp. 70-78, Jan. 2002. 
[41] A. Simalatsar, D. Densmore and R. Passerone, “A methodology for architecture exploration 
and performance analysis using system level design languages and rapid architecture profiling,” 
Industrial Embedded Systems, 2008. SIES 2008. Int. Symp., pp.11-13, Jun. 2008. 
[42] Z. Li, F. Pan, K. P. Lim, G. Feng, X. Lin, and S. Rahardja, “Adaptive basic unit layer rate 
control for JVT,” JVT-G012-r1, 7th Meeting, Pattaya II, Thailand, Mar. 2003. 
[43] X. Yi and N. Ling, “Improved H.264 rate control by enhanced MAD-based frame complexity 
prediction,” J. Visual Commun. Image Representation, vol. 17, no. 2, pp. 407-424, 2006. 
[44] W. Yuan, S. Lin, Y. Zhang, W. Yuan, and H. Luo, “Optimum bit allocation and rate control for 
H.264/AVC,” IEEE Trans. Circuits Syst. Video Technol., vol. 16, no. 6, pp. 705-715, Jun, 
2006. 
[45] Y. Chen and O. C. Au, “Simultaneous RD-optimized rate control and Video de-noising,” in 
Proc. IEEE Int. Conf. Acoustics, Speech, Signal Processing, Mar. 2008, pp. 669-672. 
[46] C. Sun, H. Wang, T. Kim, and H. Li, “Preceptually adaptive lagrange multiplier for 
rate-distortion optimization in H.264,” in Proc. Future Generation Commun. Networking, Dec. 
2007, pp. 459-463. 
[47] M. Jiang and N. Ling, “Frame-layer H.264 rate control improvement using Lagrange multiplier 
and quantizer,” in Proc. IEEE Int. Symp. Circuits Syst., May 2005, pp. 4369-4372. 
[48] X. Li, N. Oertel, A. Hutter, and A. Kaup, “Laplace distribution based Lagrangian rate 
distortion optimization for hybrid video coding,” IEEE Trans. Circuits Syst. Video Technol., 
vol. 19, no. 2, pp. 193-205, Feb. 2009. 
 85 
七、已發表論文 
Journal Paper: 
[1] C. H. Kuo, L. C. Chang, K. W. Fan, and B. D. Liu, “Hardware/software co-design of low cost 
rate control scheme for H.264/AVC,” IEEE Trans. Circuits Syst. Video Technol., vol. 20, no. 2, 
pp. 250-261, Feb. 2010.  
[2] C. H. Kuo, L. C. Chang, H. C. Chiu, and B. D. Liu, “Efficient two pass rate control scheme 
based on adjusting distribution of DCT coefficient,” IET Image Processing, vol. 4, no. 3, pp. 
211-222, June 2010. 
 
Conference Paper: 
[1] J. S. Peng, L. C. Chang, and C. H. Kuo, “Dual-core virtual platform with QEMU and 
SystemC” to be published in Proc. IEEE Int. Symp. Next Generation Electron., Nov. 2010.  
[2] L. C. Chang, C. H. Kuo, and B. D. Liu, “Hardware-oriented MAD prediction algorithms for 
rate controllable H.264/AVC hardware encoders,” in Proc. VLSI/CAD Symp., Aug. 2010, pp. 
243-246. 
[3] K. W. Lin, L. C. Chang, C. H. Kuo, and B. D. Liu, “Video decoder optimization and 
parallelization for dual-core embedded systems,” in Proc. VLSI/CAD Symp., Aug. 2010, pp. 
363-366. 
[4] L. C. Chang, C. H. Kuo, and B. D. Liu, “Low complexity MAD prediction algorithms for rate 
controllable H.264/AVC hardware encoders,” in Proc. IEEE Int. Symp. Circuits and Syst., 
May 2010, pp. 661-664. 
[5] L. C. Chang, C. H. Kuo, and B. D. Liu, “An Improvement to quality layer assignation in the 
scalable extension of H.264/AVC,” in Proc. IEEE Int. Symp. Commun., Circuits and Syst., 
May 2008, pp. 693-696. 
[6] C. H. Kuo, L. C. Chang, Z. W. Liu, and B. D. Liu, “System level design of a spatial-temporal 
video resampling architecture,” in Proc. IEEE Int. Symp. Circuits and Syst., May 2008, pp. 
2797-2800. 
[7] C. H. Kuo, G. C. Huang, L. C. Chang, and B. D. Liu, “Source code flow optimization for 
H.264/AVC video decoder implementing on a low-cost embedded system platform,” in Proc. 
IEEE Int. Conf. TENCON, Oct. 2007, pp. 1-4. 
[8] C. H. Kuo, C. H. Hu, L. C. Chang, and W. K. Kuo, “Robust video quality control with packet 
無衍生研發成果推廣資料
博士後研究員 0 0 100%  
專任助理 0 0 100%  
期刊論文 2 2 100% 
[1]C. H. Kuo, L. C. Chang, 
K. W. Fan, and B. D. 
Liu, ＇Hardware/software 
co-design of low cost rate 
control scheme for 
H.264/AVC,＇ IEEE Trans. 
Circuits Syst. Video 
Technol., vol. 20, no. 2, 
pp. 250-261, Feb. 2010. 
[2]C. H. Kuo, L. C. Chang, 
H. C. Chiu, and B. D. 
Liu, ＇Efficient two pass 
rate control scheme based 
on adjusting distribution 
of DCT coefficient,＇ IET 
Image Processing, vol. 4, 
no. 3, pp. 211-222, June 
2010. 
國外 論文著作 
研究報告 /技術報
告 0 0 100% 
篇 
 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 15 15 100%  
博士生 2 2 100%  
博士後研究員 0 0 100%  
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次
 
其他成果 
(無法以量化表達之
成果如辦理學術活
動、獲得獎項、重要
國際合作、研究成果
國際影響力及其他
協助產業技術發展
之具體效益事項
等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
