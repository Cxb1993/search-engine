 1
行政院國家科學委員會補助專題研究計畫 ■ 成 果 報 告   □ 期中進度報告 
 
省電與性能最佳化技術:從應用面至系統面之探討— 
子計畫三：考量能量之網路架構晶片軟硬體共同合成架構 
 
計畫類別：□ 個別型計畫  ■ 整合型計畫 
計畫編號：NSC  95－2221－E－002－098－MY3 
執行期間： 2006 年 08 月 01 日 至 2009 年 07 月 31 日 
 
計畫主持人：楊佳玲 
共同主持人： 
計畫參與人員： 陳依蓉，林仲祥，王柏翰，李修賢，李苡嬋，李翰林，林業峻，
楊登峰，黃教偉，黃崇智，羅健維，鄒志鴻，吳新傳，鄭湘筠，胡森博 
 
 
成果報告類型(依經費核定清單規定繳交)：□精簡報告  ■完整報告 
 
本成果報告包括以下應繳交之附件： 
□赴國外出差或研習心得報告一份 
□赴大陸地區出差或研習心得報告一份 
■出席國際學術會議心得報告及發表之論文各一份 
□國際合作研究計畫國外研究報告書一份 
 
處理方式：除產學合作研究計畫、提升產業技術及人才培育研究計畫、列管計
畫及下列情形者外，得立即公開查詢 
          ■涉及專利或其他智慧財產權，□一年■二年後可公開查詢 
          
執行單位：國立臺灣大學資訊工程學系 
中   華   民   國 98  年  10 月   30  日 
 
 3
 
英文摘要： 
Network-on-Chip (NoC) has been proposed to overcome the complex on-chip communication 
problem of SoC (System-on-Chip) design in deep submicron. The goal of this project is to 
propose a system-level hardware-software co-design framework for SoCs with NoC 
architecture. In the first year of the project, we proposed a set of Simulated-Annealing (SA) 
based hardware-software co-synthesis algorithms for NoC design. According to the 
characteristics of the target applications, the proposed algorithms decide the hardware and 
software architecture of the system that minimizes system energy consumption while meeting 
the timing constraints of the system. In the second year of the project, we built an energy model 
that considers static energy consumption in the co-synthesis framework. Moreover, we perform 
thorough comparison of the proposed SA-based co-synthesis algorithms with two categories of 
algorithm for solving combinational optimization problem, the branch-and-bound and iterative 
algorithms. We analyze the solution quality of algorithms in terms of synthesized system 
energy consumption, and execution time of each algorithm. In the third year of the project, we 
propose a Processing Elements (PEs) and memory co-synthesis (PM-COSYN) algorithm for 
NoCs. According to the computation and memory behavior of the target applications, the 
proposed PM-COSYN algorithm decides how to partition the limited resource to PE and 
memory modules such that system performance is maximized. With the system-level synthesis 
framework developed in this project, system designers can find proper hardware-software 
architecture, and PE and memory subsystem designs at early design stage.  
 
 
英文關鍵字： Network-on-Chip, Real-time system, Energy consumption, Hardware-software 
co-design, Memory subsystem 
 
 5
 
二、 報告內容： 
1. Introduction 
Platform-Based SoC (System-on-Chip) has become the main design trend for the current 
embedded systems that converges computers, communications and multimedia into consumer 
products. To cope with the complexity of SoC design in billion transistors, system architectures 
are shifting towards to a more communication-centric methodology[3]. Therefore, NoC 
(Network-on-Chip) has been proposed as a practical development platform to mitigate the 
complex on-chip communication problem by providing a more structured and modular network 
interface. The baseline NoC architecture discussed in this project is shown in Figure 1[1]. A tile is 
composed of a resource and a switch. A resource can be any other intellectual property (IP) block 
or processing element (PE), which fits into the available slot and complies with the interface of the 
NOC, such as a general-purpose CPU, digital signal processors (DSP), FPGAs 
(field-programmable gate array), memory blocks, or dedicated hardware. Each resource connects 
to its local switch through its routing network interface (rni). A switch routes and buffers 
messages between resources. The structure of a switch on a 2D mesh-based network is shown in 
Figure 1[1]. Each switch is connected to one resource and four neighboring switches, and each 
resource is connected to one switch. With this architecture, the communication among tiles is 
achieved by sending packets to one another over the network instead of routing wires.  
R30
S30
R31
S31
R32
S32
R33
S33
R20
S20
R21
S21
R22
S22
R23
S23
R10
S10
R11
S11
R12
S12
R13
S13
R00
S00
R01
S01
R02
S02
R03
S03
rni rni rni rni
rni rni rni rni
rni rni rni rni
rni rni rni rni
mux
Selection
logic
queue
m
ux
Selection
logic
queue
muxSe
le
ct
io
n
lo
gi
c
m
ux
Selection
logic
queue
m
ux
Se
lec
tio
n
log
ic
SWITCH
Selection
logic
m
ux
Se
le
ct
io
n
lo
gi
c
m
ux
 
Figure 1. Architectural overview of an NoC. 
 
The objective of this project is to develop a system-level hardware-software co-design 
framework for application-specific NOCs. In the first year of the project, we targeted at 
heterogeneous application-specific NoCs, and proposed four Simulated-Annealing-based 
(SA-based) hardware-software co-synthesis algorithms. The design target of the proposed 
algorithms is to minimize the overall system energy consumption while meeting the timing 
constraints of target applications. The details of the results achieved in the first year are presented 
in Section 2: First Year: Hardware-Software Co-Synthesis Algorithms for NoCs. In the 
 7
 
It is obvious that the solution space of the hardware software co-synthesis problem is huge, 
and it is impossible to search the design space completely. Therefore, we proposed a set of 
simulated annealing (SA) [15] based co-synthesis algorithm for heterogeneous application-specific 
NoCs. Since most embedded systems are battery-operated and have real-time requirements, the 
optimization goal of our co-synthesis algorithm is to minimize the energy consumption and meet 
the real-time constraints. The proposed co-design algorithm specifically addresses the PE 
selection problem, which is challenging in an IP-centric design with hundreds of IPss in the IP 
library, and considers the interplay between the steps in the co-design flow. To the best of our 
knowledge, the co-synthesis algorithm proposed in this project is the first hardware-software 
co-synthesis algorithm that allows fast NoC design space exploration considering both energy and 
performance factors. The details of the formal problem formulation and the proposed SA-based 
algorithms are described in the following subsections. 
 
2.1 System Specifications and Problem Formulation  
2.1.1 System Specification 
Our system consists of three main components: a real-time application, a NoC-based 
architecture and a PE library. 
Application Model 
We represent a real-time application by a task graph (TG) G =< V,E >, which is a 
directed acyclic graph, where V represents the set of tasks and E represents the set of directed 
edges between tasks. Each vertex Vvi ∈  has following properties: 
z d(vi) denotes the deadline of the node, which must be met ensure correct functionality of 
the application. 
z type(vi) denotes the type of this task node, which can be general-purpose CPU, DSP, or 
ASIC. 
z An array Ri, where the j-th element Rr ij ∈  gives the execution time of task vi if vi is 
executed on j-th PE pj in the PE library. 
z An array Si, where the j-th element Ssij ∈  gives the energy consumption of task vi if vi is 
executed on j-th PE pj in the PE library. 
Each Ee ji ∈,  represents a precedence relation (vi should be executed before vj) between vi to 
vj and is associated with a value c(ei,j) which indicates the amount of communication volume 
(bits) between vi and vj. 
 
 9
( )∑
∈∀ Vv
i
v
i
i
sω is the total energy consumption on PEs and 
( ) ( )( )( ) ( )∑
∈∀
×
Ee
ji
vv
bit
ji
ji ecI
,
,
, ωφωφ  is the total 
energy consumption on interconnections (routers and links). The P’ is the result of PE 
Selection (PS), where |P'|=|T|.  The function ψ, ω and η represent steps: Tile Mapping (TM), 
Task Allocation (TA) and Task Scheduling (TS) respectively and are defined as below: 
z Tile Mapping (TM): Map each selected PE in P' onto one of tile of the NoC. We use the 
function ψ : P' → T to represent “Tile Mapping” step. Obviously ψ is a one-to-one and 
onto function. 
z Task Allocation (TA): Assign each task node in V into one of compatible PE in P'. We use 
the function ω : V → P' to represent “Task Allocation” step. 
z Task Scheduling (TS): Determine the execution order of the tasks and communications. 
For “Task Scheduling” in our problem, the set of all possible solutions consists of all the 
possible permutations of the tasks subject to the additional precedence and exclusion 
constraints and to their deadlines. We use the function η : V → V' to represent “Task 
Scheduling” step.  
 
2.2 SA-based Co-synthesis Algorithms 
In this project, we propose a set of SA-based hardware/software co-synthesis algorithms. 
The easiest way to adopt the SA approach for the co-synthesis problem is to treat each 
co-synthesis step (i.e., PE selection, task allocation, tile mapping and task scheduling) as a 
perturbation operation. We refer to this as the baseline SA algorithm. Figure 3 shows the 
baseline SA flow. Four steps in the NoC co-design flow are treated as perturbation operations. 
We use the List scheduling [8][12] as our baseline scheduler.  
Application Specification PE Library
+
Hardware 
Architecture
Software 
Architecture
Initial solution
Is Feasible?
Yes
No
NoC Architecture
Keep the best solution 
Task Allocation
(TA)
PE Selection
(PS)
Tile Mapping
(TM)
Task Scheduling
(TS)
Perturbation
 
Figure 3. Flow of Architectural Co-Synthesis for NoC 
 11
perturbations on the new PE configuration before deciding to accept or reject the new PE 
configuration. 
2.2.2 Greedy PE Selection  
Instead of randomly choosing a PE in each SA iteration, a heuristic approach is to select 
PEs in a greedy method as illustrated in Figure 4. We first sort the PEs in a non-decreasing 
order of their energy consumption1. We then choose the first n PEs, where n is the number of 
tiles as our initial hardware configuration. Let (P’) denote the PE configuration. In the 
example shown in Figure 4, initial P’ contains p0,p1,p2 and p3 assuming a 2×2 NoC. For a 
selected PE configuration, we evaluate its feasibility with a low-temperature SA engine. If 
there exist tasks that cannot be scheduled using P’, we replace a PE by the CPU (CPUlowest) 
with the lowest energy consumption in the sorted PE library. The victim PE (Pv) is the PE with 
the maximal energy consumption in P’, and P’ = (P’ - Pv)∪ CPUlowest. If we can not find a 
feasible solution, we replace the PE with the lowest energy consumption in P’ by the PE with 
the lowest energy among all the PEs that have energy consumptions larger than that of P’ - 
CPUlowest. We repeat this process until a feasible solution is found. We then perform a normal 
SA run on the selected PEs to determine the corresponding tile mapping and software 
architecture. 
We can see that the greedy method only explores a subset of PE combinations. For 
example, the greedy method does not try the PE combination (p0, p3, p4, p5) in the example 
shown in Figure 4. To expand the solution space, we propose the Two-Stage SA algorithm 
described in the next Section. 
p1p0
PE Library
…
Low High
Energy Consumption
Initial PE configuration
p2 p3 p4 p5 p6 p7 p8 p11p10p9 p12 p99p97 p98
The first feasible configuration
 
Figure 4. Greedy Method for PE Selection 
 
2.2.3 Two-Stage SA 
The Two-Stage SA algorithm contains two stages as shown in Figure 5. First stage is the 
aforementioned greedy approach. After a feasible solution is found, all PEs with higher energy 
consumption than those in P’ (the set of PEs of the feasible solution) are not considered in the 
second stage SA. In the example shown in Figure 4, only the set of {p0, p1, ... , p10} are 
selected as candidate PEs for the second stage SA. The objective of the first stage is to prune 
the design space. The second-stage SA is the LTM-PS scheme. 
                                                 
1 We compute the average energy consumption of pk by ∑ Pi iksP1  
 13
algorithm, but SA-based algorithm is able to find solution that is closed to the optimal. Compared 
to the SA-based algorithms, the systems synthesized by the iterative algorithm have 82% more 
energy consumption on the average for a set of synthetic tasks generated by TGFF [7]. In the 
following subsections, we first present the energy model used in the co-synthesis framework, and 
the architecture co-synthesis algorithms evaluated in this project. Then, we present the analysis of 
co-synthesis algorithms. 
 
3.1 Leakage Energy Model 
In the second year of the project, we use three different energy models to evaluate the 
energy consumption of the synthesized system. The application model, NoC model and PE 
model are the same as the ones we used in the first year. The first energy model considers 
dynamic energy only. The total energy consumption of this model is calculated by the 
dynamic energy from PEs, links, and routers. The second energy model considers both 
dynamic and static energy. The static energy is calculated by: Estatic = Pstatic×T, where Pstatic is 
the static power come from PEs and routers, and T is the total execution time of the system. The 
third energy model is for system with leakage control. That is, each component is completely 
gated when it is not active. Therefore, the static energy model of each component in this case is 
Estatic = Pstatic×T’, where T’ is the total execution time of the component. 
 
3.2 Architectural Co-Synthesis Algorithms 
In this section, we present the two NoC co-synthesis algorithms for comparison, which are 
branch-and-bound algorithm and iterative algorithm.  
3.2.1 Branch-and-Bound Algorithm 
Branch-and-bound is a general algorithm for finding optimal solutions of various 
optimization problems. It consists of a systematic enumeration of all candidates solutions 
(branch method). A branch of candidates are discarded by using upper and lower estimated 
bounds of the quantity being optimized (bound method). For the NoC hardware-software 
co-synthesis problem, we use a search tree as shown in Figure 6 to enumerate all 
configurations. Each node in the tree is either a root, internal, or a leaf node. The root node 
corresponds to the initial state with empty configuration. The search tree three kinds of 
internal nodes: PE selection, task allocation, and tile mapping internal node. The leaf node 
represents one of the system configurations, including task scheduling. We can see that, the 
number of nodes in the search tree increases exponentially with the increase in the size of NoC 
template and task set. We use Depth-First-Search (DFS) to traverse the search tree. To prune 
the solution branches, we obtain upper bound by running the low-temperature baseline SA, 
 15
Application Specification PE Library
+
Hardware 
Architecture
Software 
Architecture
Initial solution
Is Better?
No
Yes
NoC Architecture
Keep the best solution 
Reallocate tasks to minimize 
the energy consumption from computation
Reallocate tasks to minimize 
the energy consumption from communication
 
Figure 7: Flow of Iterative Algorithm 
 
3.3 Analysis of Co-Synthesis Algorithms 
All the co-synthesis algorithms for analysis are implemented by C++. The synthetic task 
graphs for all algorithms are generated by TGFF [10]. We generated random task graphs g1 to 
g15 which have various graph size and in-out degree. A synthetic PE library was also generated 
for this task set, which has 78 ASICs, 117 DSPs and 48 CPUs with randomly generated 
frequency and voltage levels. Besides synthetic task graphs, we also has task graph from 
MPEG2 encoder [7]. Note that we transform the cyclic task graph into an acyclic one by 
removing the incoming edge of the node that is the entrance node of a strongly connected 
component. The traffic traces were obtained directly by executing the encoder on the 
SimpleScalar[20]. We selected 29 CPUs from ARM [4], 8 DSPs from TI [6], and 19 ASICs 
from Philips [5] for the PE library supporting MPEG2 encoder. We assume task executed on an 
ASIC for only one cycle, and with half of the CPU cycles on a DSP. The NoC architecture 
template is set to 2 × 2 tiles interconnected by a 2D mesh network. For the energy model, the 
static power is set to 10% of dynamic power.  
 
Figure 8: Comparison of energy consumption of co-synthesis algorithms with energy model considering 
dynamic energy only. 
 17
in all cases. From Figure 10, we can see that, with leakage control, the synthesis results are the 
same as the ones that consider dynamic energy only. 
Figure 11 show the normalized energy consumption of system synthesized by different 
algorithms for MPEG2 encoder. For the large solution space, the Branch and Bound Algorithm 
can not run the result of energy consumption. The energy consumption is also normalized to the 
baseline SA. The experimental results show the Greedy PE-Selection Method also performs 
worse than baseline SA. With real application, Two-Stage SA achieves 6.5% less energy 
consumption than baseline SA. However, iterative algorithm almost performs as good as 
Two-Stage SA. This is because the size of PE library is small and there are little choices for 
SA-based algorithms to trade off between performance and energy consumption.  
 
Figure 11: Comparison of energy consumption of co-synthesis algorithms applying on MPEG2 encoder. (a) with energy 
model considering dynamic energy only, (b) with energy model considering dynamic and static energy, and (c) with 
energy model that performs leakage control. 
 
Table 1 lists the running time of various schemes normalized to that of baseline SA, which 
needs about four minutes find a solution. The experimental result shows the Iterative Algorithm 
is the fastest among all the evaluated algorithms. Iterative Algorithm only explores the optimal 
solution in the subset of solution space, and this shows the Iterative Algorithm sacrifices the 
quality of solution to get high efficiency. From Table 2, we can see that Two-Stage SA derives 
better solution than LTM-PS without the cost of longer execution time. In the Two-Stage SA, 
the first stage is invoked only once. The second stage converges faster than the LTM-PS 
because the PE searching space has been reduced. The LTM-PS has longer execution time than 
the baseline SA since a low-temperature SA is performed after each PS perturbation. The 
Branch and Bound Algorithm is the slowest among all the evaluated algorithms. It is because 
the Branch and Bound Algorithm needs to exhaustively explore the design space. It needs more 
than ten hours to find the optimal solution.  
 
 
 19
remaining tiles, PM-COSYN adopts a greedy-based iterative method to refine the system 
configuration. During the refinement process, PEs are gradually replaced with memory modules to 
see if it results in better system performance.  
In the following subsections, we first present system models used by PM-COSYN and the 
formal problem formulation of the synthesis problem that PM-COSYN considers. Next, we 
present the proposed PM-COSYN algorithm and the experimental results.  
 
4.1 System Specification and Problem Formulation 
4.1.1 System Model 
As the system models used in the first two years, PM-COSYN considers a system that 
consists of an application model and an NoC architecture model. The NoC model is the same 
as the one used in the first two years. For the application model, to capture the data access 
behavior in the application model, we use a model that is different from the one used first two 
years for PM-COSYN. Here, the target application set is represented by a Control and Data 
Flow Graph (CDFG). The CDFG considered here is a directed acyclic graph in which a node 
is a task, and the directed edges represent transfers of data blocks. A data block is the 
collection of scalars or arrays which is similar to the definition used in [24]. We use G =< V,E 
> to denote a CDFG, where V represents the set of tasks and E represents the set of directed 
edges. Each vertex vi ∈ V has the following properties: 
• c(vi) denotes the number of cycles that vi used to complete on the reference PE. 
• p(vi) denotes the priority of vi. We adopt List Scheduling [8][12] as our baseline scheduler. 
In List Scheduling, tasks are scheduled according to their precedence relations and priorities. 
We assume the priorities are given by system designers in advance. 
Each ei ∈ E represents a data block transfer. Each ei is associated with d(ei), which 
denotes the ID of the data block that is transferred by ei. For each application set, there is a 
data block library D = {d1, ..., dk} to store all the data blocks touched in the application set, and 
di  indicates the i-th data block in the library. Each di is associated with size(di), which 
indicates the size of data block di (in bits).  
 
4.1.2 Problem Formulation 
The goal of PM-COSYN is to simultaneously synthesize PE and on-chip memory 
allocation for application-specific NoCs with the area constraint. Since NoCs are usually 
composed of regular tiles, in this paper, the area constraint is specified by the tile number of 
the target NoC platform. As we can see, the assignment of tasks and data blocks should be 
adjusted when the allocation of PE and on-chip memory are changed. Therefore, for a given 
 21
Victim PE Selection 
Only One PE left?
No    
Best configuration
Yes
Iterative Refinement
Initial Solution Generation
Task Set 
Specification
Yes
NoC Template
Data Block
Library
Un-Assigned Data Block
on Critical Path?
Data Block Assignment
PE & Memory
Allocation
Memory Reduction Process
Output Final 
Configuration
No
Terminate?
No    
Yes 
 
Figure 12 PM-COSYN overview. 
 
4.2.1 PE & Memory Allocation 
In this section, we present the details of Victim PE Selection and Data Block 
Assignment, which are the two major steps of PE & Memory Allocation. 
   Victim PE Selection  
The Victim PE Selection step is to decide which PE should be replaced by an on-chip 
memory, and how to reassign tasks on the victim PE to other PEs. To reassign tasks on the 
victim PE, we have to consider the control flow and the amount of shared data among tasks 
such that system performance can be maximized. For the complex interplay among tasks, we 
adopt an exhaustive search method. Victim PE Selection takes each PE Pi ∈ P on the system 
as a candidate victim PE. Pi is selected as the victim if the performance of removing Pi is the 
best among all other candidate victim PE. To reassign tasks on Pi, for each task vj on Pi, 
Victim PE Selection evaluates the system execution times of moving vj to all other PEs on the 
system. vj is moved to the PE that achieves the best system performance when Pi is selected as 
the victim PE. When more than one PE achieves the best performance with vj moved to it, the 
PE with tasks that have the most shared data with vj is selected to reduce on-chip traffic. After 
the victim PE is selected and tasks are reassigned, the tile position of the victim PE is allocated 
to a new on-chip memory. For each iteration, this step takes O((|V | · |P|) · ((|V | + |E|) + (|V | 
log |V |))) time. Evaluating system execution time needs to traverse all the nodes and edges on 
the CDFG and thus takes O(|V |+|E|) time. Moving a task to a PE needs to perform a simple 
insertion sort according to the priorities of tasks on the target PE to decide the task schedule, 
which needs about O(|V |log|V |) time. For each iteration, at most O(|V | · |P|) times of 
 23
 
4.3 Experimental Results 
In this section, we evaluate the effectiveness of PM-COSYN and discuss its experimental 
results. The experimental setup is described in Section 4.3.1. Analysis of PM-COSYN is 
performed in Section 4.3.2. We also compare the proposed PM-COSYN algorithm with a 
Simulated-Annealing optimizer, and the results are presented in Section 4.3.3. 
4.3.1 Experimental Setup  
To analyze the proposed algorithm, we apply PM-COSYN to two sets of benchmarks, 
synthetic task sets and real-world applications. The synthetic task sets are generated by the 
graph generator TGFF[10]. We generate random CDFGs and random data block libraries for 
every task set. Each of the task sets varies in its data access to task execution ratio. We use the 
average number of bits transferred per task cycle (trans_bit/task_cycle) as the measurement 
metric to quantify the data access to task execution ratio of a task set. In addition to synthetic 
task sets, we also evaluate PM-COSYN on two real-world application mixes: 
Mpeg2_Enc+Mpeg2_Dec and Consumer+Telecom. Mpeg2_Enc+Mpeg2_Dec is the mix of 
Mpeg2 encoder and Mpeg2 decode [7]. Consumer+Telecom is the mix of consumer and 
telecom benchmark suites obtained from Embedded System Synthesis Benchmark Suites (E3S) 
[27]. E3S is a collection of task graphs which are built from the Embedded Microprocessor 
Benchmark Consortium (EEMBC) benchmark suites [28]. Since existing mobile devices 
usually supports multimedia and telecommunication applications, we select the mix of 
consumer and telecom task sets for evaluation. The detailed properties of the task sets 
evaluated here are listed in Table 2.  
Table 2 Task set properties. 
 Task Set ID Parallel Degree Trans_bit/task_cycle Memory Footprint 
 (in bits) 
Initial 
PE/MEM
T0 10 10.468801 276800 9/0 
T1 10 1.20632 279100 9/0 
T2 10 0.94242 276800 9/0 
Synthetic Task 
Sets 
T3 10 0.05115 276800 9/0 
Consumer+Telecom 13 0.95139 9018000 9/0 Real-World 
Applications Mpeg2_Enc+Mpeg2_Dec 2 0.3444 5455900 2/7 
 
The configuration of NoC template we used for experiments is listed in Table 2. We use 
3 × 3 NoC for synthetic task sets and real-world application mixes. The capacity of an on-chip 
memory module is set to 32Kb, which is estimated by CACTI5.3 [29] assuming 65nm process 
and 1mm2 tile size. As described in Section 4.1, we assume each tile is either a PE or a 
memory module, and all PEs are general purpose processors with the same micro-architecture. 
 25
0
1
2
3
4
5
6
7
8
t0 t1 t2 t3
N
um
. O
n-
C
hi
p 
M
em
or
y
0
2
4
6
8
10
12
tra
ns
_b
it/
ta
sk
_c
yc
le
Num. of On-Chip Memory trans_bit/task_cycle
 
Figure 13 Number of on-chip memory allocated for highly parallel task sets with various trans_bit/task_cycle. 
 
To show the correctness of the solution synthesized by PMCOSYN, we evaluate system 
performance of NoCs with various number of on-chip memory1, and Figure 6 shows the 
results. Figure 14(a) and Figure 14(b) show the results of task set t0 and t3, respectively. In 
this set of experiments, all system execution time are normalized to that of NoC without any 
on-chip memory. As we can see from Figure 14(a), for task set t0, the NoC with 7 on-chip 
memories achieves the best performance among all other configurations. This configuration 
improves system performance by 79.14% compared the 9-PE configuration. For task set t3, as 
shown in Figure 14(b), although NoCs with 1 to 3 on-chip memories have similar performance, 
NoC with 1 on-chip memory achieves the best performance among all the configurations. 
With 1 on-chip memory, system performance is improved by 5.8% compared to the 9-PE 
configuration. Because t3 is with low trans bit/task cycle, system performance becomes worse 
when the number of on-chip memory increases. For the NoC with 8 on-chip memories, the 
system execution time is 3.1 times of the 9-PE configuration. From Figure 14, we can observe 
that the results are correspondent with the results of PM-COSYN. Therefore, we can see that 
PM-COSYN is able to correctly allocate NoC resources according to the requirements of 
target task sets.  
      (a)        (b) 
task set to
0.0
0.2
0.4
0.6
0.8
1.0
1.2
0 1 2 3 4 5 6 7 8
Number of On-Chip Memory
N
or
m
al
iz
ed
 S
ys
te
m
Ex
ec
ut
io
n 
Ti
m
e
task set t3
0.8
1.0
1.2
1.4
1.6
1.8
2.0
2.2
2.4
2.6
2.8
3.0
3.2
0 1 2 3 4 5 6 7 8
Number of On-Chip Memory
N
or
m
al
iz
ed
 S
ys
te
m
Ex
ec
ut
io
n 
Ti
m
e
 
Figure 14 Normalized system execution time of systems with various number of on-chip memories: (a) 
task set t0 and (b) task set t3 
 
For real-world applications, PM-COSYN allocates 2 on-chip memories for both 
Consumer+Telecom and Mpeg2_Enc+Mpeg2_Dec. For Mpeg2_Enc+Mpeg2_Dec, which has 
 27
PM-COSYN even achieves 19.71% better system performance than PM-SA. With real-world 
applications, PM-COSYN performs up to 15.2% better than PM-SA. From Table 4, we can see 
that PM-COSYN uses at most 0.76% of PM-SA execution time to synthesize a solution 
quality that is 18.14% better than PM-SA (task set t0). With Consumer+Telecom, 
PM-COSYN is 17640 times faster than PM-SA and achieves 15.2% better solution quality. 
Therefore, we can see that, PM-COSYN is able to achieve a good solution quality in a very 
short time.  
Table 4 Comparison of PM-COSYN and PM-SA. 
PM-COSYN PM-SA Normalized  
Task Sets System exe. 
Time (cycle) 
CPU 
Time (sec)
System exe. 
Time (cycle)
CPU Time 
(sec) 
System exe. Time 
PM-COSYN/PM-SA 
CPU Time 
PM-COSYN/PM-SA
T0 187237 2.96 228736 391.45 81.86% 0.76% 
T1 591159 3.05 726799 391.45 81.34% 0.42% 
T2 4907203 2.85 4987639 4448.06 98.38% 0.06% 
T3 8181791 2.87 10189648 6993.70 80.29% 0.04% 
Consumer+Telecom 74636117 1.17 88664777 20568.68 84.18% 0.0057% 
Mpeg2_Enc+Mpeg2_Dec 156275324 0.26 160162415 73.54 97.57% 0.35% 
 
5. Conclusion 
In this project, we proposed a system synthesis framework for application-specific NoCs. In 
the first two years of the project, we proposed a set of SA-based hardware-software co-synthesis 
algorithms for NoCs. The goal of the proposed algorithm is to minimize system energy 
consumption while meeting the timing constraint. When comparing to the branch-and-bound and 
iterative algorithm, the experimental results show that the proposed Two-Stage SA achieves the 
best balance in solution quality and CPU time. Although branch-and-bound algorithm is able to 
find the optimal solution, it also needs extremely long execution time. Iterative algorithm, on the 
other hand, has short execution time, but the synthesized solution has high system energy 
consumption. Although Two-Stage SA uses 5.91 times of iterative algorithm’s CPU time, 
Two-Stage is able to find the synthesis solution that is closed to the optimal solution. The results 
of the first two years have been published in the 2007 ACM Symposium on Applied Computing 
(SAC 2007) [19] and Journal of Systems Architecture [21].  
In the third year of the project, we proposed PE and Memory Co-Synthesis (PM-COSYN) 
algorithm, the first synthesis algorithm that simultaneously synthesize PE and on-chip memory for 
application-specific NoC with area constraints. The proposed PM-COSYN is a greedy-based 
iterative algorithm. Starting from an initial solution with all PEs and no on-chip memory, during 
each iteration, PM-COSYN replaces a PE by a memory and allocates the most critical data blocks 
 29
 
4 參考文獻： 
[1] Shashi Kumar et. al., “A network on Chip Architecture and Design Methodology,” IEEE 
Computer SoCiety Annual Symposium on VLSI, pp. 117-124, April 2002. 
[2] A. Hemani, A. Jantsch, S. Kumar, A. Postula, J. Oberg, M. Millberg, and D. Lindqvist, 
“Network On a Chip: An Architecture for Billion Transistor Era,” Proc. of the IEEE NorChip 
Conference, November 2000. 
[3] M. Srogi, et al. Addressing the System on Chip Interconnection Woe through communication 
based design, in Proc. Dac 2001. 
[4] ARM Processor cores. http://www.arm.com/products/CPUs/. 
[5] Electronics. Philips’ IP portfolio. http://www.semiconductors.philips.com. 
[6] Texas Instruments. Digital Signal Processing. 
http://focus.ti.com/dsp/docs/dsphome.tsp?sectionId=46. 
[7] Mpeg-2 video. is standard. I. D. 13818-2, 2001. 
[8] T. Adam, K. Chandy, and J. Dickson. A comparison of list schedules for parallel processing 
systems. Commun. ACM, 17(12):685–690, December 1974. 
[9] T. H. Coreman, C. E. Leiserson, R. L. Rivest, and C. Stain. Introduction to Algoirthms. 
McGraw Hill. 
[10] R. Dick, D. L. Rhodes, and W. Wolf. Tgff: Task graphs for free. March 1998. 
[11] C. J. Glass and L. M. Ni. The turn model for adaptive routing. pages 278–287, May 1992. 
[12] M. Grajcar. Strengths and weakness of genetic list scheduling for heterogeneous systems. 
pages 123–132, June 2001. 
[13] J. Hu and R. Marculescu. Energy-aware mapping for tile-based noc architectures under 
performance constraints. In Proc. ASP-DAC, January 2003. 
[14] J. Hu and R. Marculescu. Energy-aware communication and task scheduling for 
network-on-chip architecture under real-time constraints. In Proc. Design, Automation and 
Testing in Europe Conference and Exhibition (DATE), 2004. 
[15] S. Kirkpatrick, C. D. Gelatt, and M. P. Vecchi. Optimization by simulated annealing. Science, 
220(4598):671–680, May 1983. 
[16] D. Shin and J. Kim. Power-aware communication optimization for network-on-chips with 
voltage scalable links. In Proc. CODES+ISSS, September 2004. 
[17] W. Wolf. An architectural co-synthesis algorithm for distributed, embedded computing 
systems. IEEE Tran. on Very Large Scale Integration (VLSI) Systems, 5, June 1997. 
[18] T. T. Ye, L. Benini, and G. D. Micheli. Analysis of power consumption on switch fabrics in 
network routers. In Proc. Design Automation Conference (DAC), pages 524–529, June 2002. 
 31
 
5 計畫成果自評： 
The goal of this project is to propose a system synthesis framework for application-specific 
NoCs. In the first two years of the project, we proposed a set of SA-based hardware-software 
co-synthesis algorithms for NoCs. The goal of the proposed algorithm is to minimize system 
energy consumption while meeting the timing constraint. The results of the first two years have 
been published in the 2007 ACM Symposium on Applied Computing (SAC 2007) [19] and 
Journal of Systems Architecture [21]. In the third year of the project, we proposed PE and 
Memory Co-Synthesis (PM-COSYN) algorithm, the first synthesis algorithm that simultaneously 
synthesizes PE and on-chip memory for application-specific NoCs with area constraints. The 
result of the third year of the project has been submitted to 2010 Conference on Design, 
Automation and Test in Europe (DATE 2010) for publication. 
The system-level synthesis framework proposed in this project solves the two most 
challenging design issues of SoC in the multi-core ear, that is, hardware-software co-design and 
memory subsystem design. For an MPSoC with heterogeneous models and applications integrated 
on the same chip, it is challenging to find a good system design for such a complex system on chip. 
Moreover, although an MPSoC design exploits task-level parallelism to achieve high computation 
throughput, it also stresses the memory system with concurrent memory access from different PEs. 
Therefore, it is critical to incorporate memory decisions early in the design cycle, and 
concurrently with other system components in the synthesis flow as well. With the proposed 
synthesis framework, system designers can decide the hardware-software architecture, and PE and 
memory subsystem in the early design stage, thus effectively reduce the time-to-market window.  
 33
附錄 
 
1. W.-H. Hong, Y.-J. Chen, C.-L. Yang, Y.-S. Chang and Alan P. Su, “An Architectural 
Co-Synthesis Algorithm for Energy-aware Network-on-Chip Design”, SAC 2007 
2. Y.-J. Chen, C.-L. Yang and Y.-S. Chang, “An Architectural Co-Synthesis Algorithm for 
Energy-aware Network-on-Chip Design”, Vol. 55, Issue 5-6, page 299-309, May-June 2009. 
 
pose a simulated annealing (SA) [12] based co-synthesis al-
gorithm. SA is a widely used non-deterministic algorithm
for solving combinatorial optimization problem. Most em-
bedded systems are battery-operated and have real-time re-
quirements. Therefore, the optimization goal of our co-
synthesis algorithm is to minimize the energy consumption
and meet the real-time constraints. We assume a heteroge-
neous NoC architecture. We propose a Two-Stage SA algo-
rithm which first uses the Greedy PE-Selection method to
prune the PE space and then invokes an SA engine to find
both the hardware and software architectures. We show that
the Two-Stage SA algorithm reduce energy consumption by
26% on the average for a set of synthetic tasks generated by
TGFF[7], and 10% for the MPEG2 encoder, compared to
the baseline SA method that simply treats each hardware-
software co-design step as an SA perturbation.
The rest of this paper is organized as follows. We present
a concise specification of our co-synthesis models in Section
2. A formal problem definition is described in Section 3.
The architectural co-synthesis algorithm based on SA is then
proposed in Section 4. Next, we report our experimental
results in Section 5. Finally, in Section 6 we conclude by
summarizing our main contributions.
2. SYSTEM SPECIFICATIONS
Our system consists of three main components: a real-time
application, an NoC-based architecture and a PE library.
1. Application Model
We represent a real-time application by a task graph
(TG) G =< V,E >, which is a directed acyclic graph,
where V represents the set of tasks and E represents
the set of directed edges between tasks. Each vertex
vi ∈ V has following properties:
• d(vi) denotes the deadline of the node, which must
be met to ensure correct functionality of the ap-
plication.
• type(vi) denotes the type of this task node, which
can be a general-purpose CPU, DSP, or ASIC.
• An array Ri, where the j-th element rij ∈ Ri gives
the execution time of task vi if vi is executed on
j-th PE pj in the PE library.
• An array Si, where the j-th element sij ∈ Si gives
the energy consumption of task vi if vi is executed
on j-th PE pj in the PE library.
Each ei,j ∈ E represents a precedence relation (vi
should be executed before vj) between vi to vj and
is associated with a value c(ei,j) which indicates the
amount of communication volume (bits) between vi
and vj .
2. NoC Model
The NoC-based architecture under consideration is com-
posed of n× n tiles interconnected by a 2D mesh net-
work. We model such an NoC-based system with n×n
tiles as an Architecture Graph (AG) N =< T,L >,
which is a directed graph, where T = {t1, ..., tn, ..., tn2}
is the set of tiles and L is the set of links between tiles.
Each link li,j ∈ L represents a link connection between
ti and tj and is associated with b(li,j) which stands for
the bandwidth (bits/second) of li,j . We use I
ti,tj
bit to
denote the average energy consumption (in joules) of
sending one bit of data from ti to tj including energy
consumed in the links and switches. We use the energy
model in [10, 11, 15] to calculate I
ti,tj
bit . They define
I
ti,tj
bit as: I
ti,tj
bit = nhops × ESbit + (nhops − 1)× ELbit ,
where ESbit and ELbit represent the energy consumed
on the switch and on the link between tiles, respec-
tively. The nhops is the number of routers the bit
passes on its way from ti to tj .
Similar to [11], we also assume a static XY routing
scheme [8] as our underlying routing protocol. It first
routes packets along the X -axis. Once it reaches the
column where the destination tile lies in, the packet is
then routed along the Y -axis. Note that the proposed
co-synthesis can be easily modified to apply other de-
terministic routing algorithm.
3. PE Model
We denote the set of PEs as P = {p1, ..., pn}, where pi
indicates the i-th PE. We assume that the number of
PEs are at least more than the number of tiles. Each
pi is associated with a type(pi) which indicates the
compatible task type of pi. The task vi can execute
on pi if and only if type(pi) is general-purpose CPU or
type(pi) = type(vi).
3. PROBLEM FORMULATION
For a given task graph G =< V,E >, a PE Library
P = {p1, p2, ..., pn} and an NoC-based architecture N =<
T,L >, the problem we want to solve is to find both the
hardware and software architectures such that the overall
energy consumption is minimized and specified performance
constraints are met. For the overall NoC energy consump-
tion, we break down the NoC hardware into two compo-
nents: PE and interconnection. We can define the NoC
co-synthesis problem as follows.
Given G =< V,E >, P = {p1, ..., pn},
and N =< T,L >,
Find a subset P ′ of P and the function φ, ω, η
such that
{
∑
∀vi∈V
siω(vi) +
∑
∀ei,j∈E
I
φ(ω(vi)),φ(ω(vj))
bit × c(ei,j)}
is minimized
Subject to ∀ vi ∈ V, completion T ime(vi) ≤ d(vi)∑
∀vi∈V
siω(vi) is the total energy consumption on PEs and∑
∀ei,j∈E
I
φ(η(vi)),φ(η(vj))
bit × c(ei,j) is the total energy consump-
tion on interconnections (routers and links). The P ′ is the
result of PE Selection (PS), where |P ′| = |T |. The function
φ, ω, and η represent steps: Tile Mapping(TM), Task Al-
location(TA) and Task Scheduling(TS) respectively and are
defined as below:
• Tile Mapping (TM): Map each selected PE in P ′
onto one of tile of the NoC. We use the function φ :
P ′ → T to represent ”Tile Mapping” step. Obviously
φ is a one-to-one and onto function.
• Task Allocation (TA): Assign each task node in V
681
Is Feasible?
Greedy PE Selection
No
Yes
End
Stage 1
Stage 2
Sort P by energy consumption
Get initial PE configuration P’
SA Engine
(TM, TA, TS)
SA Engine
(PS,TM,TA,TA)
Set Candidate PEs P
Figure 4: Flow of Two-Stage SA Algorithm
our initial hardware configuration. Let (P ′) denote the
PE configuration. In the example shown in Figure 3, ini-
tial P ′ contains p0,p1,p2 and p3 assuming a 2 × 2 NoC.
For a selected PE configuration, we evaluate its feasibil-
ity with a low-temperature SA engine. If there exist tasks
that cannot be scheduled using P ′, we replace a PE by
the CPU (CPUlowest) with the lowest energy consumption
in the sorted PE library. The victim PE (Pv) is the PE
with the maximal energy consumption in P ′, and P ′ =
(P ′ − Pv)⋃CPUlowest. If we can not find a feasible solu-
tion, we replace the PE with the lowest energy consump-
tion in P ′ by the PE with the lowest energy among all
the PEs that have energy consumptions larger than that
of P ′ − CPUlowest. We repeat this process until a feasible
solution is found. We then perform a normal SA run on the
selected PEs to determine the corresponding tile mapping
and software architecture.
We can see that the greedy method only explores a subset
of PE combinations. For example, the greedy method does
not try the PE combination (p0, p3, p4, p5) in the example
shown in Figure 3. To expand the solution space, we propose
the Two-Stage SA algorithm described in the next Section.
4.3 The Two-Stage SA Algorithm
The Two-Stage SA algorithm contains two stages as shown
in Figure 4. First stage is the aforementioned greedy ap-
proach. After a feasible solution is found, all PEs with
higher energy consumption than those in P ′ (the set of PEs
of the feasible solution) are not considered in the second
stage SA. In the example shown in Figure 3, only the set of
{p0, p1..., p10} are selected as candidate PEs for the second
stage SA. The objective of the first stage is to prune the
design space. The second-stage SA is the LTM-PS scheme
described in Section 4.1.
5. EXPERIMENTAL RESULTS
We use the graph generator TGFF [7] to generate random
task graphs for our experiments. TGFF is a parameterizable
generator that can accept user specifications like maximum
in-degree, out-degree of the vertices. We generated random
task graphs g1 to g15 which varies in graph size and in-out
degree. A synthetic PE library was also generated for this
set of tasks. The synthetic PE library contains three types
(4)DCT Type
Estimation
(3)Predict
(2)Motion
Estimation
(5)Transform
(6)DCT (10)Inverse
DCT
(9)Inverse
Transform
(8)Inverse
Quantize
(7)Quantize
(1)Control Code
Figure 5: Task Graph of MPEG-2 Encoder
of PEs: ASIC, DSP and CPU. The frequency and voltage
of each type of PE was randomly generated, and there are
16 CPUs, 26 ASIC and 39 DSPs in this PE library.
To test the proposed co-synthesis algorithm on a real-
world application, we apply our schemes to the MPEG2 en-
coder [4]. The MPEG2 encoder is divided into 10 tasks as
shown in Figure 5. Note that we transform the cyclic task
graph into an acyclic one by removing the incoming edge of
the node that is the entrance node of a strongly connected
component [6]. Task 1 of MPEG2 encoder contains control
codes, and can only be allocated to a CPU. We compose the
PE library based on the datasheets of the IPs comprising
DSPs, CPUs, and ASICs for DCT/IDCT transform, mo-
tion estimation, prediction and quantization. We selected
29 CPUs from ARM [1], 8 DSPs from TI [3], and 19 ASICs
from Philips [2].
Figure 6 and Figure 7 show the energy consumption of the
best solutions of 100 SA runs for various schemes on syn-
thetic task sets, and the MPEG2 encoder, respectively. Note
that, in the Two-Stage SA, the first stage runs only once.
The candidate PEs are then passed to the second-stage SA
which runs 100 times to derive the best solution. The energy
consumption is normalized to the baseline SA. The experi-
mental results show that the Greedy PE-Selection method
performs even worse than the baseline SA. The Greedy PE-
Selection can be considered as an approach that a designer
would adopt without an automatic co-design environment.
The Greedy PE-Selection method can only explore a subset
of PE combination, therefore, it performs worse than the
baseline SA. This result demonstrates the importance of PE
selection. The Two-Stage SA achieves the most energy sav-
ings among the three co-synthesis schemes. The Two-Stage
SA has energy reduction of 26% on the average for synthetic
task sets, and 10% for the MPEG2 encoder, compared to the
baseline SA method.
In addition to solution quality, how fast a co-synthesis
algorithm can converge is also critical. Table 1 lists the
execution time of various schemes normalized to the base-
line SA. The experimental results show that the Two-Stage
SA derives better solutions than LTM-PS without the cost
of longer execution time. The Two-Stage SA first uses the
Greedy PE-Selection to prune down the solution space, there-
fore, it can find better solution than the LTM-PS in shorter
time. The LTM-PS has longer execution time than the base-
line SA since a low-temperature SA is performed after each
PS perturbation.
6. CONCLUSIONS
In this paper, we proposed an energy-aware architectural
683
An architectural co-synthesis algorithm for energy-aware Network-on-Chip designq
Yi-Jung Chen, Chia-Lin Yang *, Yen-Sheng Chang
Department of Computer Science and Information Engineering, National Taiwan University, No. 1, Sec. 4, Roosevelt Road, Taipei 10617, Taiwan, ROC
a r t i c l e i n f o
Article history:
Received 21 October 2008
Received in revised form 25 February 2009
Accepted 25 February 2009
Available online 13 March 2009
Keywords:
Network-on-Chip
Hardware–software co-synthesis
Energy-aware design
a b s t r a c t
Network-on-Chip (NoC) has been proposed to overcome the complex on-chip communication problem of
System-on-Chip (SoC) design in deep sub-micron. A complete NoC design contains exploration on both
hardware and software architectures. The hardware architecture includes the selection of Processing Ele-
ments (PEs) with multiple types and their topology. The software architecture contains allocating tasks to
PEs, scheduling of tasks and their communications. To ﬁnd the best hardware design for the target tasks,
both hardware and software architectures need to be considered simultaneously. Previous works on NoC
design have concentrated on solving only one or two design parameters at a time. In this paper, we pro-
pose a hardware–software co-synthesis algorithm for a heterogeneous NoC architecture. The design goal
is to minimize energy consumption while meeting the real-time requirements commonly seen in embed-
ded applications. The proposed algorithm is based on Simulated-Annealing (SA). To compare the solution
quality and efﬁciency of the proposed algorithm, we also implement the branch-and-bound and iterative
algorithm to solve the hardware–software co-synthesis problem of a heterogeneous NoC. With the given
synthetic task sets, the experimental results show that the proposed SA-based algorithm achieves near-
optimal solution in a reasonable time, while the branch-and-bound algorithm takes a very long time to
ﬁnd the optimal solution, and the iterative algorithm fails to achieve good solution quality. When apply-
ing the co-synthesis algorithms to a real-world application with PE library that has little variation in PE
performance and energy consumption, the iterative algorithm achieves solution quality comparable to
that of the proposed SA-based algorithm.
 2009 Elsevier B.V. All rights reserved.
1. Introduction
To cope with the complexity of System-on-Chip (SoC) design in
billion transistors, Network-on-Chip (NoC) has been proposed to
overcome the complex on-chip communication problem [4]. As
shown in Fig. 1(a), an NoC-based system is typically divided into
a number of regular tiles interconnected by a 2D mesh network.
A tile is composed of a processing element (PE) and a router. A PE
could be a general-purpose CPU, Digital Signal Processors (DSP),
Field-Programmable Gate Arrays (FPGAs), memory blocks, or
Application-Speciﬁc Integrated Circuits (ASICs). PEs communicate
with one another by sending packets via the mesh network instead
of routing wires. The router embedded in each tile consists of input
and output links, buffers and a crossbar switch. The abstract view
of a tile is shown in Fig. 1(b) [11].
The design ﬂow of an NoC is shown in Fig. 2. We assume an
IP-centric design where PEs are selected from the IP library
[25]. Given a set of target tasks (represented in task graph), a
set of PEs are selected from the IP library (PE Selection), and tasks
are allocated to PEs (Task Allocation). The selected PEs are
mapped to the n n tiles (Tile Mapping), and the schedule of
tasks allocated to the same PE is decided (Task Scheduling). The
communication paths among tasks allocated to different PEs are
determined through routing path allocation. From the design ﬂow
we can see that a complete NoC design contains exploration on
both hardware and software architectures. The hardware archi-
tecture includes the selection of PEs and their topology. The soft-
ware architecture contains the allocation of tasks to PEs and
scheduling of tasks and their communication. The design of the
hardware and software architecture actually interplays with each
other. For example, a good task schedule might reduce the
required PE computing capability to meet the real-time require-
ments of tasks. To ﬁnd the best hardware design for the target
tasks, both hardware and software architectures need to be
considered simultaneously.
1383-7621/$ - see front matter  2009 Elsevier B.V. All rights reserved.
doi:10.1016/j.sysarc.2009.02.002
q The preliminary version of this paper was published in SAC 2007 [10]. In this
paper, we extend our conference paper with: (1) Implementing a branch-and-
bound and an iterative algorithm to solve the NoC co-synthesis problem. (2)
Comparing the solution quality and algorithm efﬁciency achieved by the proposed
SA-based algorithms, the branch-and-bound algorithm and the iterative algorithm.
(3) In addition to the original energy model that considers dynamic energy
consumption only, we use an additional energy model that considers system
leakage when performing system synthesis. This work was supported in part by the
National Science Council of Taiwan under Grants NSC 95-2221-E-002-098-MY3 and
NSC 97-2221-E-002-242-My3, and in part by the Excellent Research Projects of
National Taiwan University 97R0062-05.
* Corresponding author.
E-mail addresses: d91015@csie.ntu.edu.tw (Y.-J. Chen), yangc@csie.ntu.edu.tw
(C.-L. Yang), r92043@csie.ntu.edu.tw (Y.-S. Chang).
URL: http://www.csie.ntu.edu.tw/~yangc (C.-L. Yang).
Journal of Systems Architecture 55 (2009) 299–309
Contents lists available at ScienceDirect
Journal of Systems Architecture
journal homepage: www.elsevier .com/ locate /sysarc
2. Related work
NoC has been proposed to mitigate on-chip interconnection
problem [2,4,9,15,26]. In [4], Dally and Towles introduce the con-
cept of on-chip networks, sketch a simple network, and discuss
some challenges in the architecture and design of these networks.
Ye et al. [26] give a detail analysis for the power consumption on
network communication. Kumar et al. [15] propose a Network-
on-Chip platform including both the architecture and the design
methodology. Based on this architecture, Millberg et al. [16] pres-
ent the Nostrum NoC supporting multiple communication services
modelled by a protocol stack. All the above papers essentially
advocate the advantages of using NoCs as effective means to design
high performance SoCs.
For NoC system design, Hu et al. [11,12] propose an energy-
aware task allocation and scheduling algorithm which schedules
both communication and computation for NoC architecture. They
also propose an energy-aware tile mapping algorithm which ex-
ploits routing ﬂexibility of regular NoC architectures. The algo-
rithms in both papers are proposed to optimize only one or two
aspects of the NoC-based design framework at one time. Shin
et al. in [20] propose a communication optimization technique
for NoC with voltage scalable links. In this work, they addressed
the importance of inter-related steps of the NoC design ﬂow and
presented a GA-based algorithm to solve link speed assignment
problem. However, it omits the PE Selection step and only focuses
on link speed assignment to minimize communication energy cost.
Murali and De Micheli propose an algorithm that maps processing
cores onto a mesh NoC architecture under bandwidth constraints
[17]. In [18], the same authors introduce SUNMAP, which automat-
ically selects the best topology for a certain application under de-
lay, area and energy constraints. In [19], a topology synthesis
process that considers the effect ﬂoorplan is proposed. Srinivasan
et al. [22,23] propose an automatic technique to generate ﬂoorplan
and route for application-speciﬁc NoC with irregular topology.
Several works [21,24,25] are proposed to solve the hardware–
software co-synthesis problem of traditional bus-based distributed
embedded systems. In [25], an architectural co-synthesis algo-
rithm that considers PE selection and task allocation simulta-
neously is proposed for distributed embedded system; however,
their algorithm omits tile mapping and routing path allocation
which are speciﬁc to the NoC-based systems.
3. System models
Our system consists of four main models: a real-time application
model, an NoC architecture model, a PE library and a system energy
model.
(1) Application Model.
We represent a real-time application by a task graph
G ¼ hV ; Ei, which is a directed acyclic graph, where V repre-
sents the set of tasks and E represents the set of directed
edges between tasks. Each vertex vi 2 V has following
properties:
 dðviÞ denotes the deadline of the node vi which must be
met to ensure correct functionality of the application.
 typeðviÞ denotes the type of this task node, which can be a
general-purpose CPU, DSP, or ASIC.
 An array Ri, where the jth element rij 2 Ri gives the execu-
tion time of task vi if vi is executed on jth PE pj in the PE
library.
 An array Si, where the jth element sij 2 Si gives the energy
consumption of task vi if vi is executed on jth PE pj in the
PE library.
Each ei;j 2 E represents a precedence relation (vi should be
executed before vj) between vi to vj and is associated with a
value cðei;jÞ which indicates the amount of communication
volume (bits) between vi and vj.
(2) NoC Model.
The NoC architecture under consideration is composed of
m n tiles interconnected by a 2D mesh network. We model
such an NoC-based systemwithm n tiles as an Architecture
Graph N ¼ hT; Li, which is a directed graph, where
T ¼ ft1; . . . ; tmng is the set of tiles and L is the set of links
between tiles. Each link li;j 2 L represents a link connection
between ti and tj and is associated with bðli;jÞ which stands
for the bandwidth (bits/second) of li;j.
Similar to [12], we also assume a static XY routing scheme [7]
as our underlying routing protocol. It ﬁrst routes packets
along the X-axis. Once it reaches the column where the des-
tination tile lies in, the packet is then routed along the Y-
axis. Note that the proposed co-synthesis can be easily mod-
iﬁed to apply other deterministic routing algorithm.
(3) PE Model.
We denote the PE library P ¼ fp1; . . . ; png, where pi indicates
the ith PE in the PE library. We assume that the number of
PEs are at least more than the number of tiles. Each pi are
associated with a typeðpiÞ which indicates the compatible
task type of pi. The task vi can execute on pi if and only if
typeðpiÞ is a general-purpose CPU or typeðpiÞ ¼ typeðviÞ.
(4) Energy Model
In this paper, we use two energy models to evaluate the
energy consumption of synthesis results. The ﬁrst energy
model considers system dynamic energy only. The dynamic
energy consumption of a system is composed of computa-
tion and communication energy consumption. According to
the application model described before, computation energy
consumption Ecomput: can be modelled as
Ecomput: ¼
XjV j
i¼1
sik; ð1Þ
where task i is mapped to the kth PE in the PE library, and sik
is the energy consumption of task i running on the kth PE. For
the energy consumption of communication, we use Iti ;tjbit to de-
note the average energy consumption (in joules) of sending
one bit of data from ti to tj, including energy consumed in
the links and switches. We use the energy model in
[11,12,26] to calculate Iti ;tjbit . They deﬁne I
ti ;tj
bit as
I
ti ;tj
bit ¼ nhops  ESbit þ ðnhops  1Þ  ELbit ; ð2Þ
where ESbit and ELbit represent the energy consumed on the
switch and on the link between tiles, respectively. The nhops
is the number of routers the bit passes on its way from ti to tj.
The second energy model used in this paper considers both
dynamic and static energy consumption in the system. The
dynamic energy consumption is modelled by Eqs. (1) and
(2). The static energy from the leakage of each component
is modelled by Eq. (3), where Pstatic is the static power of se-
lected PEs and routers, and T is the total execution time of
system. A similar leakage model is also used in [13].
Estatic ¼ Pstatic  T: ð3Þ
4. Problem formulation
For a given task graph G ¼ hV ; Ei, a PE Library P ¼ fp1; p2; . . . ; png
and an NoC architecture N ¼ hT; Li, the problem we want to solve is
to ﬁnd both the hardware and software architectures such that
the overall energy consumption is minimized and speciﬁed
Y.-J. Chen et al. / Journal of Systems Architecture 55 (2009) 299–309 301
(ii) typeðpiÞ – typeðpjÞ and typeðpjÞ – CPU: in this case,
parts of the tasks running on pi may not be able to exe-
cute on pj. To handle this case, we select a CPU from P
0
and migrate these tasks to the selected CPU. If there is
no CPU in P0, we then redo the PS perturbation.
(b) TM (Tile Mapping): TM is to pick pi; pj 2 P0 randomly,
where pi – pj; ti ¼ /ðpiÞ, and tj ¼ /ðpjÞ. Then we change
the tile mapping to: /ðpiÞ ¼ tj;/ðpjÞ ¼ ti.
(c) TA (Task Allocation): TA picks vi 2 V randomly and
selects a pi 2 P0 randomly, where vi is compatible with
pi and migrate vi into pi.
(d) TS (Task Scheduling): We adopt List Scheduling [1,8] as
our baseline scheduler. In List Scheduling, tasks are sched-
uled according to their precedence relations and priorities.
In our SA-based List scheduler, the task priorities are ﬁrst
randomly given, and then we use the TS perturbation to
change the priorities of the task set. More speciﬁcally,
the TS is to randomly select vi; vj 2 V ; vi – vj, and then
swap the priority of vi and vj. Note that communication
trafﬁc is taken into account for task scheduling.
(3) Cost function: The objective function contains two parts:
energy cost and miss deadline penalty.
U ¼ Cenergy þ Cpenalty; ð4Þ
where U is the cost of current solution. We normalized both
energy term and timing penalty term in the cost function.
The energy term (Cenergy) is the same as the objective function
in the problem formulation.
X
8vi2V
sixðviÞt þ
X
8ei;j2E
I
/ðxðviÞÞ;/ðxðvjÞÞ
bit  cðei;jÞ
8<
:
9=
;
and the Cpenalty is described as following:
(a) Cpenalty ¼ 0; if T 6 Td,
(b) Cpenalty ¼ T  Td þ ; if T > Td,
where Td is the timing constraint of the application, T is
the current completion time of the application and  is a
constant.Recall that our optimization goal is minimizing
the total energy consumption while meeting the tight per-
formance constraint. In the ﬁrst case, when the current solu-
tion satisﬁes the speciﬁed timing constraint, we concentrate
on energy consumption optimization by setting Cpenalty to
zero. In the second case, the completion time T violates the
timing constraint Td, therefore, both energy consumption
and timing factors should be considered in searching for
solutions. The Cpenalty is given more weight as the difference
between the timing constraint and the current completion
time gets larger. Note that we include  in Cpenalty to distin-
guish a feasible solution from an infeasible one. The  is an
user-deﬁned experimental parameter. A larger  indicates
that an infeasible NoC conﬁguration is less likely to be
accepted as the best conﬁguration during the execution of
SA. Since both energy term and timing penalty term in the
cost function are normalized,  should be 0 <  < 1. In this
paper, we set  to 0.25 for all experiments.
5.2. LTM-PS: low-temperature move on PS
In the SA algorithm, after a perturbation, the derived solution is
evaluated using the cost function to decide accepting or rejecting
the solution. Since a PS perturbation changes the underlying hard-
ware architecture, it implies that it might require a signiﬁcant
change in software architecture as well. For example, if the newly
selected PE has lower computing power than the replaced one, it is
very likely that the current schedule is not going to meet the tim-
ing constraints with the new set of PEs. Therefore, the new solution
will be probably rejected by the SA due to its high cost. However,
trivially rejecting this new PE conﬁguration may foreclose possibly
attracting PE conﬁgurations. In the example mentioned above, if
we re-schedule the tasks according to the new hardware conﬁgu-
ration, we might be able to ﬁnd a feasible solution. Therefore, in
the LTM-PS scheme, we try to optimize for the PE conﬁguration
by performing a low-temperature SA containing only TA, TM and
TS perturbations on the new PE conﬁguration before deciding to
accept or reject the new PE conﬁguration.
5.3. Greedy PE-selection method
Instead of randomly choosing a PE in each SA iteration, a heuris-
tic approach is to select PEs in a greedy method as illustrated in
Fig. 5. We ﬁrst sort the PEs in a non-decreasing order of their en-
ergy consumption.1 We then choose the ﬁrst n PEs where n is the
number of tiles as our initial hardware conﬁguration (P0). In the
example shown in Fig. 5, the initial hardware conﬁguration P0 con-
tainsp0, p1, p2 and p3 assuming a 2 2 NoC. For a selected PE conﬁg-
uration, we evaluate its feasibility with a low-temperature SA engine
with only the TM, TA and TS perturbations. If there exist tasks that
cannot be scheduled using P0, we replace a PE by the CPU with the
lowest energy consumption (CPUlowest) in the sorted PE library. The
victim PE (Pv) is the PE with the maximal energy consumption in
P0, and the new hardware conﬁguration is P0 ¼ ðP0  PvÞ
S
CPUlowest .
If we can not ﬁnd a feasible solution, we replace the PE with the low-
est energy consumption in P0 by the PE with the lowest energy
among all the PEs that have energy consumptions larger than that
of P0  CPUlowest . We repeat this process until a feasible solution is
found. We then perform a normal SA run on the selected PEs to
determine the corresponding tile mapping and software
architecture.
We can see that the greedy method only explores a subset of PE
combinations. For example, the greedy method does not try the PE
combination (p0; p3; p4; p5) in the example shown in Fig. 5. This lim-
itation may lead to a conﬁguration with high energy consumption.
To expand the solution space, we propose the Two-Stage SA algo-
rithm described in the next section.
5.4. The two-stage SA algorithm
The Two-Stage SA algorithm contains two stages as shown in
Fig. 6. The ﬁrst stage is the aforementioned Greedy PE-Selection.
Fig. 5. Greedy PE-Selection method.
1 We compute the average energy consumption of PE pk by 1jPj
PjPj
i s
i
k .
Y.-J. Chen et al. / Journal of Systems Architecture 55 (2009) 299–309 303
SoC. The iterative algorithm proposed in [25] consist of a step of
ﬁnding the initial solution and an iterative reﬁnement step that
is executed repeatedly. In each iteration, the iterative reﬁnement
process modiﬁes the system conﬁguration to minimize energy con-
sumption from task computation and communication, respec-
tively. We maintain the structure of the algorithm proposed in
[25], and modify the detail steps of ﬁnding the initial solution
and performing iterative reﬁnement to cope with the NoC co-syn-
thesis problem. The overview of the iterative algorithm for NoC
hardware–software co-synthesis is illustrated in Fig. 8, and the
overview of each operation is as follows.
(1) Initial solution: Initial solution generates an initial conﬁgu-
ration, including PE Selection, Tile Mapping, Task Allocation
and Task Scheduling.
(2) Iterative reﬁnement: Two steps are performed in the itera-
tive reﬁnement:
(a) Minimization of computation energy consumption: Con-
ﬁgurations of PE Selection and Task Allocation are
modiﬁed to minimize computation energy
consumption.
(b) Minimization of communication energy consumption:
Tasks are re-allocated to minimize inter-PE
communication.
To ﬁnd a feasible initial solution, the algorithm tends to select
PEs with high computation power. Although PEs with high compu-
tation power tend to have high energy consumption, these PEs can
be replaced by the ones with low energy consumption during the
iterative reﬁnement process as long as the timing constraint is
met. Therefore, for the initial solution, the algorithm selects PEs
according to the tasks with the most workload. Assume an m n
NoC, the algorithm ﬁnds the m n tasks with the most workload
among the task set. For each task, the PE compatible to the task
type and with the highest computation power is selected, and
the task is also allocated to the PE. For the tasks other than the
m n tasks, each of them is allocated to the PE with feasible type
and the highest computation power. On deciding the initial Tile
Mapping, the algorithm tends to minimize the communication cost
by allocating PEs with high communication demands as close to
one another as possible. To achieve this, the algorithm ﬁrst allo-
cates the PE with the highest communication needs in the middle
of the NoC platform. For each un-mapped tile position that is adja-
cent to a mapped one, we calculate ﬁt value FPEi ;ðx;yÞ
2 of tile position
ðx; yÞ for all PEi that is an un-allocated selected PE. FPEi ;ðx;yÞ represents
the average communication load of links between tile position ðx; yÞ
with PEi and other mapped PEs. Therefore, the algorithm tends to
map the PE with the highest ﬁt value for an un-mapped tile position.
The schedule of tasks allocated on a PE is set according to the prece-
dence constraint of the input task graph. The priorities of tasks at the
same level in the task graph are randomly decided. The ﬂow of gen-
erating initial solution is summarized in Fig. 9.
In the iterative reﬁnement process, the algorithm minimizes
system energy consumption in two directions; computation and
communication energy consumption. The computation energy con-
sumption is minimized by (1) replacing an selected PE PEi by a PE
in the PE library that is compatible to PEi and has energy consump-
tion lower than PEi, and (2) re-allocating a task originally allocated
on PEi to another selected PE, which is feasible for the task and has
energy consumption lower than PEi. The communication energy
consumption comes from the distance and communication vol-
umes between two PEs on the system. To minimize communica-
tion energy consumption, the algorithm exhaustively merge tasks
with high communication volume to the same PE as long as the
merging leads to less on-chip communication.
7. Experimental results
To evaluate the effectiveness of the proposed NoC hardware–
software co-synthesis algorithms, we implement all the proposed
SA-based algorithms and perform several experiments on syn-
thetic and real-application task sets. In Section 7.1, the solution
quality achieved by different co-synthesis algorithms are dis-
cussed. The efﬁciency of different algorithms is compared in Sec-
tion 7.2.
7.1. Comparison of synthesis results
For evaluation, we implement all the proposed SA-based co-
synthesis algorithms; baseline SA, the Greedy PE-Selection method,
Table 1
Number of conﬁgurations to be explored in the search tree.
Synthesis step Number of
conﬁgurations
Explanation on parameters
PE Selection jPj
m n
 
P: total number of PEs in the PE
library
m;n: dimension of the target
NoC
Task Allocation jAjmþn A: total number of tasks in the
task set
Tile Mapping jðm nÞj! m;n: dimension of the target
NoC
Task Scheduling jSj! S: total number of tasks
Total number of
conﬁguration
jPj
m n
 
 jAjmþn  jðm nÞj!  jSj!
Fig. 8. Overview of the iterative algorithm for NoC design.
2 FPEi ;ðx;yÞ ¼
P
8mapped PEm
CommuðPEi ;PEmÞ
linkðpositionðPEm Þ;ðx;yÞÞ, where CommuðPEi; PEmÞ denotes the
communication volume between PEi and PEm , and linkðpositionðPEmÞ; ðx; yÞÞ denotes
the Manhattan-Distance between ðx; yÞ the tile position that PEm is mapped to.
Y.-J. Chen et al. / Journal of Systems Architecture 55 (2009) 299–309 305
can always synthesize the optimal solution. When considering
dynamic energy only, branch-and-bound achieves 52.5% less en-
ergy consumption than baseline SA. However, the execution time
of the branch-and-bound algorithm is also extremely long. In this
set of experiments, when performing the branch-and-bound algo-
rithm, we can only get synthesis results of task graphs g1—g5,
which have at most 13 tasks in their task graphs. When comparing
the SA-based algorithms and the branch-and-bound algorithm, we
can observe that the solution quality of conﬁguration synthesized
by Two-Stage SA is close to that of branch-and-bound. When con-
sidering dynamic energy only, among the ﬁve task graphs that the
branch-and-bound algorithm is able to synthesize, Two-Stage SA
has at most 5.9% more energy consumption than that of the
branch-and-bound algorithm. We can also observe that the itera-
tive algorithm, which only explores a subset of feasible solutions
in each iteration, performs worse than baseline SA, LTM-PS and
the Two-Stage SA in all cases. However, the iterative algorithm per-
forms better than the Greedy PE-Selection method in some cases.
As described earlier, the Greedy PE-Selection method tends to se-
lect a set of PEs with high computation power and high energy
consumption when a task set needs PEs with high computation
power to meet its deadline. In such cases, Greedy PE-Selection
tends to perform worse than iterative algorithm.
When comparing Figs. 11 and 12, we observe that the differ-
ences between SA-based algorithms and iterative algorithm are
shortened when considering static power consumption. SA-based
methods tend to select PEs with lower voltage levels as long as
the timing constraints are met. These PEs also lead to a longer exe-
cution time and thus have more leakage energy consumption.
However, when considering static power consumption, except for
Greedy PE-Selection, the SA-based methods still perform better
than the iterative algorithm, and the Two-Stage SA still performs
the best in all cases.
Figs. 13 and 14 show the dynamic and dynamic + static energy
consumption of MPEG2 encoder system, respectively. The energy
consumption is also normalized to that of baseline SA. In this set
Fig. 11. Dynamic energy consumption of solutions synthesized by various co-synthesis algorithms.
Fig. 12. Dynamic and static energy consumption of solutions synthesized by various co-synthesis algorithms.
Fig. 13. Dynamic energy consumption of MPEG2 encoder system synthesized by
various co-synthesis algorithms.
Y.-J. Chen et al. / Journal of Systems Architecture 55 (2009) 299–309 307
[20] D. Shin, J. Kim, Power-aware communication optimization for network-on-
chips with voltage scalable links, in: Proceedings of the CODES+ISSS,
September 2004.
[21] G.C. Sih, E.A. Lee, A compile-time scheduling heuristic for interconnection-
constrained heterogeneous processor architectures, IEEE Trans Parallel
Distribut. Syst. 4 (2) (1993) 175–187.
[22] K. Srinivasan, K.S. Chatha, G. Konjevod, An automated technique for topology
and route generation of application speciﬁc on-chip interconnection netowkrs,
in: Proceedings of 2005 International Conference on Computer-Aided Design
(ICCAD’05), 2005.
[23] K. Srinivasan, K.S. Chatha, G. Konjevod, Linear-programming-based
atechniques for synthesis of network-on-chip architectures, IEEE Trans. Very
Large Scale Intergrat. (VLSI) Syst. 14 (4) (2006) 407–420.
[24] W.H. Wolf, Hardware–software codesign of embedded systems, Proc. IEEE 82
(7) (1994) 967–989.
[25] W.H. Wolf, An architectural co-synthesis algorithm for distributed, embedded
computing systems, IEEE Trans. Very Large Scale Integrat. (VLSI) Syst. 5 (June)
(1997).
[26] T.T. Ye, L. Benini, G. De Micheli, Analysis of power consumption on switch
fabrics in network routers, in: Proceedings of Design Automation Conference
(DAC), June 2002, pp. 524–529.
[27] MPEG2 video, IS standard. I.D. 13818-2, 2001.
[28] ARM Processor cores. <http://www.arm.com/products/CPUs/>.
[29] Electronics, Philips’ IP portfolio. <http://www.semiconductors.philips.com>.
[30] SimpleScalar. <http://www.simplescalar.com/>.
[31] Texas Instruments, Digital Signal Processing. <http://focus.ti.com/dsp/docs/
dsphome.tsp?sectionId=46>.
Yi-Jung Chen received the B.S. and M.S. degrees from
the Department of Computer Science and Information
Engineering at National Chi Nan University, Nantou,
Taiwan in 2000 and 2002, respectively. She is currently
working toward the Ph.D. degree in Department of
Computer Science and Information Engineering at
National Taiwan University, Taipei, Taiwan.
Her research interests include high-level synthesis,
Network-on-Chip design and memory hierarchy design.
Chia-Lin Yang received the B.S. degree from the
National Taiwan Normal University, Taiwan, ROC, in
1989, the M.S. degree from the University of Texas at
Austin in 1992, and the Ph.D. degree from the Depart-
ment of Computer Science, Duke University, Durham,
NC, in 2001.
In 1993, she joined VLSI Technology Inc. (now Philips
Semiconductors) as a Software Engineer. She is cur-
rently an Associate Professor in the Department of
Computer Science and Information Engineering,
National Taiwan University, Taipei, Taiwan. Her
research interests include energy-efﬁcient microarchi-
tectures, memory hierarchy design, and multimedia workload characterization.
She is the recipient of a 2000–2001 Intel Foundation Graduate Fellowship Award
and 2005 IBM Faculty Award.
Yen-Sheng Chang received the B.S. degree in computer
science and engineering from National Dong Hwa Uni-
versity, Hualien, Taiwan, in 2003, and the M.S. degree in
computer science and engineering from National Tai-
wan University, Taipei, Taiwan, in 2005. His research
interests include hardware–software co-design and
Network-on-Chip design.
Y.-J. Chen et al. / Journal of Systems Architecture 55 (2009) 299–309 309
industrial keynote and plenary talks。The special session on green data centers 有
4 invited talks: 
1. Cullen Bash of HP expands on sustainable data centers and IT ecosystem. 
2. John carter discusses IBM’s green data center research activities. 
3. Prof. Massoud Pedram of USC talks about minimizing data center cooling and server 
power costs. 
4. Prof. Tom Wenisch of University of Michigan focuses on system level power 
以前大家談到低功率 常專注於battery-operated embedded system, 近年來
data center, 因其龐大的耗電量 , 學界及業界開始重視  data center之
power management 及thermal control issues, 包含 core hopping, thermal 
planning, power budget allocation and main memory power management. 
Storage-class memory 也是一個未來很重要的議題。這也是我目前研究一
重要方向。 
 
三、攜回資料名稱之內容 
 
2009 ISLPED 會議論文集光碟片一片。 
 
四、結語 
 
非常感謝國科會提供補助，使得我得以成行。也使得我們有機會與國外同領域的
學者交換Low Power Architecture發展及研究的心得。 
 
 
 
 
 
 
 
 
 
 
