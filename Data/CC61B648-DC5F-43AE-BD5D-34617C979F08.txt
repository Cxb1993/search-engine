報告內容 
1 前言 
    Multiple description video coding (MDC) is one of the techniques used to reduce 
the detrimental effects caused by transmission over error-prone networks. This paper 
presents a hybrid MDC method which segments the video along spatial and temporal 
dimensions, and provides efficient estimation methods for missing description 
reconstruction. The experimental results confirm the improved error resilience 
capability achieved by the proposed hybrid MDC in lossy networks. 
 
2 研究目的 
As the Internet backbone capability increases and more and more hand-held 
devices connect to network, the Internet becomes much more heterogeneous. A video 
streaming service may serve for a variety of clients such as PDA or desk-top on 
different type of networks, such as wired or wireless network. With different types of 
networks, the bandwidth varies from Kilo-bytes to Mega-bytes. In the MDC 
architecture, if the number of descriptors increases, the quality and bit-rate thus span a 
wider range. For example, if four descriptors are generated, the low bandwidth client 
can receive only one descriptor, while clients with highest bandwidth can receive all 
four descriptors. The low bandwidth client only needs one quarter bit-rate for the 
service. 
Class B MDC architecture has the characteristic that the side decoders have fully 
mismatch control, which implies that the encoder prediction loop should take the state 
of decoder into account, and has less prediction efficiency as discussed in chapter 2. 
Thus prediction error will become larger and the total redundancy of descriptors will 
also rise. Further, class B might also need more encoding time, to be more specific, 
the motion estimation. Since the prediction for each descriptor is different, and motion 
estimation is needed for each descriptor, the motion estimation time could be linearly 
depending on the descriptor number. In other words, if more descriptors were 
generated, more motion estimation time is needed. As a result, to fast split the source 
into multiple descriptors, say four, with lower redundancy, the class A architecture 
with splitting on the prediction error approach is a good candidate, because only one 
motion estimation time is needed and the prediction efficiency could be as well as 
SDC. 
According to the two considerations mentioned above: 1) higher number of 
descriptors; 2) more efficient encoding time and redundancy; we would like to 
pixels before splitting is to take into account the estimation of lost description, which 
will be discussed later. After polyphase permuting, the splitting process is performed 
to split each 8x8 block into two 8x8 blocks, called residual 0 (R0) and residual 1 (R1), 
each carries two 4x4 blocks chosen in diagonal. For each 8x8 block, the remaining 
two 4x4 blocks with pixels all labeled with „x‟ in Fig.1 are given residual pixels all set 
to zero. The encoder has no need to encode the coefficient of these two all-zero blocks. 
Briefly, the encoding path of Hybrid MDC is split into two after temporal splitter, and 
then four after residual splitter. The resulting four descriptions are called T0R0, T0R1, 
T1R0, and T1R1, respectively. 
 
Fig. 1.  Polyphase permuting and splitting of an 8x8 residual block. 
 
 
4.2. Hybrid Decoder 
 
In Hybrid decoder, if all the four descriptions are received correctly, these 
descriptions are separately entropy decoded, dequantized, inversely transformed, and 
then a Residual Merger is applied to merge every two descriptions from the same 
prediction loops. The Residual Merger adopts residual merging and polyphase inverse 
permuting in a reversed way of Fig.1. Then, motion compensation is applied on each 
prediction loop and a Temporal Merger is used to combine even and old frames so the 
whole sequence is reconstructed. 
However, if not all the descriptions are received intactly, the decoder may apply 
spatial estimation after Residual Merger, or temporal estimation after Temporal 
Merger to reconstruct the lost descriptions. We first describe the temporal and spatial 
estimation methods in the context of the proposed Hybrid MDC, and then the criterion 
for estimation method selection is presented. 
 
4.2.1. Temporal Estimation Method: B-PMVI 
When two descriptions from the same prediction loop are lost, it will result in 
whole-frame loss. Since the Hybrid method splits consecutive frames into different 
prediction loops, the lost frame can be estimated by its previous frame and next frame 
  
   . Our spatial method uses bilinear interpolation to estimate these lost residual 
pixels, as shown in Equation (3). Since neighboring pixels have high spatial 
correlation, this method should be efficient. 
                                                  (3) 
 
Fig. 3.  Spatial estimation by bilinear interpolation. 
 
 
4.2.3. Estimation Method Selection 
The proposed Hybrid MDC segments a video sequence into four descriptions. 
There are 16 states of the four descriptions as listed in Table I, where the columns 
describe the four possible cases for the two descriptions split from prediction loop T0; 
while the rows describe those for T1. The estimation method to be applied for each 
case are also shown in this table, where „T‟ denotes the temporal estimation, „S‟ the 
spatial estimation, and „S→T‟ denotes that spatial method will be performed first and 
then temporal method.   
 
Table I. Mapping of estimation methods and description-loss cases 
 
    
To illustrate the cases that „S→T‟ will be applied, Fig. 4 depicts one of the four 
possible cases that three descriptions are lost. The descriptions marked with „(x)‟ 
mean they are lost. In Fig. 4, since    
    of T0 is received, spatial method can be 
applied to reconstruct its counterpart,   
   , as denoted by the dotted arrow labeled 
with S. Then, after merging    
    and   
   , the reconstructed frame    
 , together 
with the frame    
   , are used by temporal method B-PMVI to recover the lost 
whole frame    
   , as denoted by the dotted arrow labeled with T. The right side of 
Fig. 4 shows how the „S→T‟ is performed. 
To illustrate the cases that „T‟ will be applied, Fig.5 depicts two cases that two 
  
 
 
參考文獻 
 
[1] V.A. Vaishampayan, “Design of Multiple Description Scalar Quantizers,” IEEE 
Trans. on Info. Theory, vol. 39, 1993. 
[2] Y. Wang, A. R. Reibman, and S. Lin, “Multiple Description Coding for Video 
Delivery,” Proceeding IEEE, vol. 93, no. 1, Jan. 2005. 
[3] O. Campana, R. Contiero, “An H.264/AVC Video Coder Based on Multiple 
Description Scalar Quantizer,” IEEE Asilomar Conf. on Signals, Systems and 
Computers, 2006. 
[4] A. Reibman, H. Jafarkhani, Y. Wang, M. Orchard, “Multiple Description Video 
Using Rate-Distortion Splitting,” IEEE Intl. Conf. on Image Processing, 2001. 
[5] J. G. Apostolopoulos, “Error-Resilient Video Compression Through the Use of 
Multiple States,” IEEE Intl. Conf. on Image Processing, 2000. 
[6] S. Gao, H. Gharavi, “Multiple Description Video Coding over Multiple Path 
Routing Networks,” Intl. Conf. on Digital Communication Proceedings (ICDT), 
2006. 
[7] D. Wang, N. Canagarajah and D. Bull, “Slice Group Based Multiple Description 
Video Coding Using Motion Vector Estimation,” IEEE Intl. Conf. on Image 
Processing, 2004. 
[8] T. Tillo, M. Grangetto, and G. Olmo, “Redundant Slice Optimal Allocation for 
H.264 Multiple Description Coding,” IEEE Trans. on Circuits and Systems for 
Video Technology, vol. 18, no. 1, Jan. 2008. 
[9] R. Bemardini, M. Durigon, R. Rinaldo, L. Celetto, and A. Vitali,“Polyphase 
Spatial Subsampling Multiple Description Coding of Video Streams with H.264,” 
IEEE Intel. Conf. on Image Processing (ICIP), Oct. 2004. 
[10] H.264/AVC Software, http://iphome.hhi.de/suehring/tml/ 
 
 
 
 
 
 
 
面的分別,而我們所提出的,與一般編碼方式比較所提升的效益不會依視訊內容的不
同特性而有所區別,相同的,在我們研究結果中,不同的MDC切割法不會依據此特性而
在整體切割效益有明顯的差別,所以我們所提出的多重描述切割法是適用於各類型的
視訊資料。 
 
 完成不同 MDC切割法之 redundant bit-rate 關係的實驗與分析 
redundant bit-rate 是比較各種 MDC切割法優劣方法之一，在實驗結果中，我們發
現用於一般編碼方式的 MDC切割法 , 若是使用單一種切割法(如:時間域切割法、空
間域切割法、複製法等) ，效果有限,雖然能減少一些 redundant bit-rate,但還是
有改良的空間; 而混合式的多重描述切割法則能改善此問題，降低 redundant 
bit-rate 的比例，盡可能的達到一般 MDC較佳能用切割法的要求 。 
 
 完成各種錯誤隱藏方法在不同視訊內容特性與傳輸通道的實驗與分析  
在實驗結果中，我們所提出的空間域錯誤隱藏方法對於不同類型的視訊內容，並沒有
很明顯的差別，residual 的錯誤補償的優劣主要是取決於視訊壓縮的 QP 大小 ，而
不會因為動態、靜態或複雜的視訊內容有明顯的變動。時間域的錯誤隱藏方法則對於
靜態的視訊內容能有較好的效益，相反的動態的視訊內容因有太多大幅度的 motion 
vector ,或是 scene change的情況過多 ， 都會直接影響到時間域錯誤隱藏的效益，
所以動態的視訊內容較不適用時間域的錯誤隱藏方法。為了模擬不同的傳輸通道的情
況，我們設計了 0%~10% 的 random loss rate 來實驗，在網路傳輸條件較為可靠時，
整體效益的表現以時間域的錯誤隱藏方法為佳，但若是像無線傳輸這類型會發生較高 
loss rate,則以空間域的  錯誤隱藏效益較高。 
 
 
 
遺失所造成視訊品質下降的情形。此研究可用於一般網路上的視訊串流應用，包
括 P2P。  
 此研究主題以海報方式呈現於 Session: MP.PE: Scalable Coding and 
Multiple Description Coding 中，期間吸引一些學者的興趣並和許多學界先進
交換意見及討論，也獲得不少回饋，整理如下： 
1. 與會中很多人對於論文中所提之 spatial estimation 和  temporal 
estimation 的方法，並在不同描述檔遺失(description loss) 的情形下選
擇不同的方法很感興趣，認為是很不錯的點子。不過也有人提到如果也能根
據視訊本身的特性來選擇 estimation method 可能可以有更好的效果。 
2. 論文中的實驗結果顯示在高資料流(high bit-rate)時對所提的方法更有
利，與會中有人建議增加對較高解析度的視訊影片的實驗，應該會有不錯的
結果。  
3. 會中和多重描述編碼法有關的論文雖然不多，但有興趣且加以詢問作法的人
數還不少，顯示在多重描述編碼法上有突破的方法雖不多，但有興趣研究的
人並不少，因此，在這方面的議題還是值得深入研究的。  
4. 此次會議中，除了獲得別人對自己發表的論文的看法外，也和其它論文發表
的作者有意見交流，獲得許多在會議論文集上沒有載明的一些觀點及細節，
有助於從中引發新的研究議題，收穫不少。 
 
 
四、攜回資料名稱及內容 
 CD 一片，內容為這次於 ICIP2010 發表的所有論文集。 
 
 
98年度專題研究計畫研究成果彙整表 
計畫主持人：蔡文錦 計畫編號：98-2221-E-009-085- 
計畫名稱：適用於媒體串流之多重描述視訊編碼法 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 8 4 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 1 1 100% 
已 被 IEEE 
Transactions on 
Circuits and 
Systems for 
Video technology 
期刊接受 
研究報告/技術報告 0 0 100%  
研討會論文 1 1 100% 
篇 
已發表於 IEEE 
International 
Conference on 
Image Processing 
(ICIP2010) 國際
會議中 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
 
