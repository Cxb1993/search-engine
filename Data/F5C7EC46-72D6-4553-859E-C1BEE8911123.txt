 In second year (2010-2011), we develop the system 
such that it can support the functionality of data 
forward. In this system, the data owner can securely 
forward the stored data in the distributed storage 
system to another user. The owner does not need to 
retrieve the data back to process it for forwarding 
to another user. The owner simply sends a proxy re-
encryption key to the storage servers and the servers 
re-encrypt the data into a ciphertext that can be 
decrypted by the target user. This method reduces the 
bandwidth requirement dramatically. We have finished 
a manuscript and submitted it to an international 
journal. 
 In the third year (2011-2012), we continue to 
research on distributed storage systems. Based on the 
results of the previous two years, we consider repair 
mechanisms for our robust and secure storage system. 
We propose cooperative and non-cooperative repair 
mechanisms. The results have been published in the 
conference IEEE TrustCom-2011. The complete paper is 
submitted to a prestigious journal. 
 
英文關鍵詞： Distributed networked storage system, public key 
cryptosystem, random erasure code, data forwarding, 
repair mechanism 
 
 2 
中文摘要 
本研究計畫將研究分散式網路儲存系統的安全
儲存機制。網路儲存系統提供使用者儲存資料在
網路上的儲存系統中，再透過網路進行資料存
取。目前的分散式網路儲存系統首要注重的是效
率，其次才是安全性,我們認為在資料隱私性上
還有許多改善的空間。 
第一年度（98-99）我們發展了一個以隨機
線性編碼基礎的安全分散式網路儲存系統。在我
們的系統中，資料透過公開金鑰系統加密來達到
高度資料隱私性，隨機線性編碼方法則是提供了
儲存系統的容錯能力。整體系統的運作符合分散
式系統的環境特質,論文已在 IEEE TPDS (2010)
期刊發表。 
第二年度（99-100）我們基於去年發展的
安全儲存系統，繼續提供多樣性的功能，例如，
如 何 將 安 全 儲 存 的 資 料 送 給 第 三 者
(forwarding)，資料擁有者不需將儲存的資料取
回解密後再上傳，這樣可以減少大量的頻寬使
用。論文成果已經在 IEEE TPDS (2012)上發表。 
第三年度（100-101），我們基於先前兩年
的成果，有一個安全強固且具有資料傳送給第三
者的分散式雲端儲存系統上，提出當系統的一些
伺服器出現錯誤時可以修復的機制，成果發表在
IEEE TrustCom-2011 會議上，完整論文也已投
稿到知名期刊。 
關鍵詞: 分散式網路儲存系統，公開金鑰加密，
隨機容錯編碼，資料安全傳送，資料傳送。 
英文摘要 
In this project, we study security issues of 
distributed networked storage systems. A 
networked storage system enables users to store 
data and to access data via Internet access. 
Currently, distributed networked storage systems 
are designed for efficiency and security is a second 
issue. One of goals of this research is to improve 
the data confidentiality in distributed networked 
storage systems. 
 In the first year (2009-2010), we developed a 
random linear code-based secure distributed 
networked storage system. The system uses a 
public key encryption scheme to provide high data 
confidentiality and uses a random linear code to 
achieve the data robustness. The data storing and 
retrieval processes are fully distributed. The paper 
has been published in IEEE TPDE. 
 In second year (2010-2011), we develop the 
system such that it can support the functionality of 
data forward. In this system, the data owner can 
securely forward the stored data in the distributed 
storage system to another user. The owner does 
not need to retrieve the data back to process it for 
forwarding to another user. The owner simply 
sends a proxy re-encryption key to the storage 
servers and the servers re-encrypt the data into a 
ciphertext that can be decrypted by the target user. 
This method reduces the bandwidth requirement 
dramatically. We have finished a manuscript and 
submitted it to an international journal. 
 In the third year (2011-2012), we continue to 
research on distributed storage systems. Based on 
the results of the previous two years, we consider 
repair mechanisms for our robust and secure 
storage system. We propose cooperative and 
non-cooperative repair mechanisms. The results 
have been published in the conference IEEE 
TrustCom-2011. The complete paper is submitted 
to a prestigious journal. 
 4 
率。如何提供有效率使用安全儲存資料的方法是
研究的重點。 
當資料以分散式的方式儲存在儲存伺服器
時，可能損毀或遭到破壞，當這些錯誤發生時，
如何利用儲存在其他伺服器的資料將錯誤的伺
服器修護或對新加入的伺服器寫入一些資料，使
得整個系統還具有強固與安全的特性，是值得研
究的課題。 
二. 研究成果 
第一年度（2009-2010） 
第一年度的研究成果為提出一個安全的分
散式網路儲存系統。我們的系統有三個角色，儲
存伺服器，金鑰管理伺服器與使用者。假定系統
有 n個儲存伺服器，m個金鑰管理伺服器，使用
者要儲存 k筆資料。使用者的資料將被加密後存
入 系 統 ， 系 統 會 透 過 分 散 式 容 錯 編 碼
(decentralized erasure coding) 將資料分散
儲存在 v個儲存伺服器中，當使用者要將資料取
回時，系統中的金鑰管理伺服器會與 u個儲存伺
服器聯絡取得資料並協助使用者進行解密運
算，使用者自己再進行解碼以拿到資料。在這期
間，由於儲存伺服器與金鑰伺服器都是獨立進行
編碼與協助解密的程序，所以不需要一個中央控
制單位的協助。 
在功能性上，我們透過錯誤更正碼儲存來
因應系統中儲存伺服器可能意外地斷線或儲存
設備的毀損，使得系統在發生意外狀況時仍能夠
提供服務。在資料隱私性上，我們則是考慮一個
高度隱私性的要求，使用者的資料不僅僅是其他
系統中使用者無法接觸，負責提供服務的儲存伺
服器本身亦無法得知資料的內容。 
研究成果的主要貢獻，從學術理論上來
看，我們提供了一個結合了容錯技術與公開金鑰
加密系統的密碼學工具，這個工具能夠在一個非
集中式的儲存系統環境中被使用，使得系統同時
具有資料可信賴與高度隱私性並且兼顧了分散
式的優點，另外針對系統中資料儲存的取回正確
率上，我們亦提供了一個完整的分析方式並建議
了一組通用的系統參數。 
從儲存系統發展與應用上來看，我們強調
了資料隱私性在雲端儲存系統上的重要性與一
個強度上的分野，早期網路儲存系統的隱私性是
建立在完全信任儲存伺服器的假設下，僅對登入
的使用者進行身分認證，我們則是強調資料隱私
性的強度應該要能夠消除對儲存伺服器的信任
的假設條件。 
在容錯能力上來說，我們的系統能夠容忍
(n-k)個儲存伺服器錯誤與(m-t)個金鑰管理伺
服器錯誤。只要有 k個儲存伺服器與 t個金鑰管
理伺服器仍正常運作，則使用者可以有很高的機
率將資料取回。 
在資料隱私性方面，因為資料都是以加密
的型態被儲存，所以即使是所有的儲存伺服器都
被攻擊者控制，資料內容仍能保密。我們對於金
鑰管理伺服器則有較高的信任要求，我們假設這
些金鑰管理伺服器有較好的安全機制以保障使
用者的各個部分解密金鑰。 
第二年度（2010-2011） 
為了在分散式安全的儲存系統上達到具有 data 
forwarding 的能力，我們提出了新的門檻式的
再 加 密 協 定 (threshold re-encryption 
scheme)，然後將整合到安全的儲存系統裡。結
合的系統具有安全、容錯、data forwarding的
A Decentralized Repair Mechanism for
Decentralized Erasure Code based Storage Systems
Hsiao-Ying Lin∗, Wen-Guey Tzeng†, Bao-Shuh Lin∗
∗Intelligent Information and Communications Research Center, †Department of Computer Science
National Chiao Tung University
Hsinchu, Taiwan
hsiaoying.lin@gmail.com, wgtzeng@cs.nctu.edu.tw, bplin@mail.nctu.edu.tw
Abstract—Erasure code based distributed storage systems
provide data robustness by storing encoded-fragments over
servers. To maintain data robustness, a repair mechanism
recovers a storage system from server failures by repairing
encoded-fragments. For decentralized erasure code based stor-
age systems, we propose a decentralized repair mechanism.
Our mechanism has the following features. Firstly, an encoded-
fragment is replenished by a combination of a number u of
encoded-fragments that are randomly chosen. Secondly, the
number u depends on the number of the available encoded-
fragments and is independent of the pattern of missing
encoded-fragments. Thirdly, multiple encoded-fragments are
simultaneously replenished in parallel. We measure the com-
munication cost in terms of the number u of required network
connections for replenishing an encoded-fragment. We then
conducted a numerical analysis by using traces of real systems.
We find that our requirement on u is smaller than that from
existing methods. Both theoretical and numerical results show
that our decentralized repair mechanism outperforms existing
ones in terms of the communication cost under the same
consideration of efficiency cost for storage.
Keywords-decentralized erasure codes; regenerating codes;
network coding; distributed storage;
I. INTRODUCTION
Erasure code based distributed storage systems provide
data robustness by storing encoded-fragments over servers.
An (𝑛, 𝑘) erasure code encodes a message of 𝑘 symbols
to a codeword of 𝑛 symbols such that the message can be
decoded from any 𝑘 codeword symbols. The code tolerates
𝑛−𝑘 erasure errors. To store a message in an (𝑛, 𝑘)-erasure
code based distributed storage system with 𝑛 servers, the
message is encoded into a codeword by the erasure code
and each of its codeword symbols is stored in a different
server. A server failure corresponds to an erasure error of the
stored codeword symbol. As long as 𝑘 servers are available,
the message can be recovered. In this paper, we sometimes
refer a codeword symbol as an encoded fragment and use
them interchangeably.
A decentralized erasure code is an erasure code that inde-
pendently computes each codeword symbol for a message.
Thus, the encoding process for a message consists of 𝑛
parallel tasks of generating codeword symbols. Each server
executes one task to compute a codeword symbol. This kind
of systems is suitable for decentralized environments, where
no centralized authority coordinates the tasks, such as peer-
to-peer and ad-hoc networks. Parallel computing also speeds
up the storing process.
Maintenance of robustness in an erasure code based dis-
tributed storage system requires to replenish codeword sym-
bols when servers fail or leave the system. A straightforward
solution is to compute the original message from available
codeword symbols and then to regenerate missing codeword
symbols from the message. This approach leads to higher
communication and computation cost. Another approach
is to generate codeword symbols by directly combining 𝑢
available ones. When a new server joins the system, it
queries 𝑢 available servers to generate a codeword symbol.
The generated codeword symbol can be different from the
missing one. But, the property that any 𝑘 codeword symbols
can recover the message remains.
In previous studies, efficiency is measured by the storage
cost (the number of bits a server stores) and the repair
bandwidth (the number of bits a new server received for
replenishing a codeword symbol). However, in considering
the communication cost, the cost of establishing network
connections is significant. Establishing network connections
between servers involves authentication and negotiation
process. The entailed communication cost is significant,
especially when 𝑢 is large. For example, when 𝑢 = 𝑛 − 1,
a new server needs to connect all available servers in the
system. Thus, we measure the communication cost by the
number 𝑢 of required network connections, as well as the
repair bandwidth.
We study repair mechanisms for decentralized erasure
code based storage systems. In a decentralized erasure code
based storage system, we show that 𝑢 = 𝑘 is a sufficient
condition for a repair mechanism. Specifically, we are inter-
ested in finding out whether 𝑢 can be smaller than 𝑘.
Contributions. We propose a decentralized repair mecha-
nism for decentralized erasure code based storage systems
with the following features:
∙ A codeword symbol is replenished by a combination
of a number 𝑢 of randomly chosen codeword symbols
without recreating the original message.
2011 International Joint Conference of IEEE TrustCom-11/IEEE ICESS-11/FCST-11
978-0-7695-4600-1/11 $26.00 © 2011 IEEE
DOI 10.1109/TrustCom.2011.79
613
Figure 1. The model of decentralized erasure code based storage systems.
A. Decentralized Erasure Code based Storage System
Dimakis et al. [16] proposed a decentralized erasure code
based storage system where the encoding process is ac-
complished by decentralized servers in parallel. Afterward,
for strengthening data confidentiality, Lin and Tzeng [17],
[18] proposed secure decentralized erasure codes where data
are encoded in an encrypted form. Illustrated in Fig. 1,
a decentralized erasure code based storage systems is de-
scribed as follows. There are 𝑛 servers, SS1,SS2, . . .,
SS𝑛, and a message is represented as a vector of symbols
𝑚1,𝑚2, . . . ,𝑚𝑘 in some finite field. To store the message,
each symbol is distributed to 𝑣 randomly chosen servers.
A server SS𝑖 then picks a random coefficient 𝑔𝑖,𝑗 for a
received message symbol 𝑚𝑗 and linearly combines all
received message symbols as a codeword symbol 𝑐𝑖. If 𝑚𝑗
is not received, 𝑔𝑖,𝑗 is set to 0. Note that the combination is
operated in the finite field. Globally, all chosen coefficients
form a generator matrix 𝐺 = [𝑔𝑖,𝑗 ], 1 ≤ 𝑖 ≤ 𝑛, 1 ≤ 𝑗 ≤ 𝑘,
which encodes the vector of 𝑘 message symbols to the
vector of 𝑛 codeword symbols. To retrieve the message, a
user queries 𝑘 randomly chosen servers to get 𝑘 codeword
symbols, say 𝑐1, 𝑐2, . . . , 𝑐𝑘, and the corresponding coeffi-
cients. The coefficients form a square matrix 𝐾, which is a
submatrix of 𝐺. The user decodes the message by computing
(𝑐1, 𝑐2, . . . , 𝑐𝑘)×𝐾−1, where 𝐾−1 is the inverse matrix of
𝐾. A successful data retrieval of the system is the event that
𝐾 is invertible. The probability of a successful data retrieval
is overwhelming when 𝑣 is sufficiently large [16], [17], [18].
From the results in [16], the system parameters are
suggested as follows in order to guarantee a high probability
of a successful data retrieval. When 𝑛 = 𝑎𝑘, 𝑣 = 𝑏 ln 𝑘,
and 𝑏 > 5𝑎 with constants 𝑎 and 𝑏, the probability of a
successful data retrieval is at least 1−𝑘/𝑝−𝑜(1), where 𝑝 is
the prime order of the underlined group. Later in [18], these
parameters are generalized for 𝑛 = 𝑎𝑘𝑐 and 𝑐 ≥ 1. When
𝑛 = 𝑎𝑘𝑐, 𝑣 = 𝑏𝑘𝑐−1 ln 𝑘, 𝑏 > 5𝑎, and 𝑐 ≥ 1 with constants
𝑎 and 𝑏, the probability of a successful data retrieval is at
Figure 2. Our repair model for decentralized erasure code based storage
systems.
least 1− 𝑘/𝑝− 𝑜(1).
B. Decentralized Repair Mechanism
Let messages be stored among 𝑛 servers in a decentralized
erasure code based storage system. After a period of time,
some servers fail. Let the number of remaining servers be
𝛼𝑛, where 𝛼 < 1. By the results [16], [17], [18], any 𝑘
remaining servers can recover the message with probability
1− 𝑘/𝑝− 𝑜(1). To repair the system from (1− 𝛼)𝑛 server
failures, (1 − 𝛼)𝑛 new servers join the system. We shall
call a remaining server as an old server and a newly joining
one as a new server. A repair procedure is initiated by new
servers (see Fig. 2). After executing the repair procedure,
the storage system is recovered from server failures so that
any 𝑘 servers, no matter new or old ones, shall recover the
message with an overwhelming probability.
Repair procedure. New server SS𝑗 performs the following
steps:
1) Query 𝑢 randomly chosen old servers, SS𝑗1 ,
SS𝑗2 , . . ., SS𝑗𝑢 . A queried old server SS𝑗𝑖 re-
turns the stored codeword symbol and coefficients
(𝑐𝑗𝑖 , 𝑔𝑗𝑖,1, 𝑔𝑗𝑖,2, . . . , 𝑔𝑗𝑖,𝑘).
2) Choose a random coefficient 𝑧𝑗𝑖 for a received
(𝑐𝑗𝑖 , 𝑔𝑗𝑖,1, 𝑔𝑗𝑖,2, . . . , 𝑔𝑗𝑖,𝑘).
3) Encode all received data into a new codeword
symbol and the corresponding coefficients
( ?˜? , ?˜?,1, ?˜?,2, . . . , ?˜?,𝑘):
?˜? =
∑
1≤𝑖≤𝑢
𝑧𝑗𝑖𝑐𝑗𝑖 , ?˜?,𝑠 =
∑
1≤𝑖≤𝑢
𝑧𝑗𝑖𝑔𝑗𝑖,𝑠, 1 ≤ 𝑠 ≤ 𝑘
4) Store the resulting ( ?˜? , ?˜?,1, ?˜?,2, . . . , ?˜?,𝑘).
By considering communication cost of establishing net-
work connections between servers, we want a smaller 𝑢. A
larger 𝑢 means that the new server queries more codeword
symbols from old servers. The combination of these queried
codeword symbols contains more information about the mes-
sage. Therefore, we need to carefully select 𝑢. Apparently, if
𝑢 ≥ 𝑘, more than 𝑘 codeword symbols are queried and they
are sufficient to recover the message with an overwhelming
probability. The combination of these codeword symbols in
the new server, together with the codeword symbols from
615
When E2 happens, there is a maximal matching from 𝑆2
to 𝑉1 ∖ 𝑆1. That is, a subset 𝑆′2 ⊆ 𝑁(𝑆2) ∖ 𝑆1 exists with
∣𝑆′2∣ = 𝑛2
Let 𝐾 be the 𝑘 × 𝑘 matrix formed by coefficients from
queried servers in 𝑆1∪𝑆2. When 𝐾 is invertible, E1 happens.
Let 𝐾1 be the 𝑘× 𝑘 matrix formed by coefficients from the
servers in 𝑆1∪𝑆′2. Since 𝑆1∪𝑆′2 is a subset of 𝑘 vertices in
𝑉1, 𝐾1 is invertible with probability at least 1−𝑘/𝑝−𝑜(1).
Since the subgraph induced by 𝑆2 and 𝑆′2 has a perfect
matching, 𝐾 has full rank if 𝐾1 has full rank. Moreover,
each row in 𝐾 can be expressed as a linear combination of
rows in 𝐾1. Thus, 𝐾 can be expressed as 𝑇 ×𝐾1 for some
𝑘×𝑘 matrix 𝑇 . Entries of 𝑇 are randomly and independently
determined by new servers. To have 𝐾 invertible, 𝐾1 and
𝑇 must be invertible. When 𝐾1 is invertible, 𝑇 is invertible
with probability at least 1− 𝑘/𝑝 according to the Schwartz-
Zippel Theorem. Thus, we have
Pr[E1∣E2 ∧ (𝑛1 < 𝑘)]
= Pr[𝐾 is invertible∣E2 ∧ (𝑛1 < 𝑘)]
≥ Pr[𝐾1 is invertible ∧ 𝑇 is invertible∣E2 ∧ (𝑛1 < 𝑘)]
≥ (1− 𝑘/𝑝− 𝑜(1))× (1− 𝑘/𝑝)
≥ 1− 2𝑘/𝑝− 𝑜(1)
Lemma 2. (Hall’s Theorem) If and only of for any subset
𝐵 ⊆ 𝑆2, the number of neighbors of 𝐵 in 𝑉1 ∖ 𝑆1 is no
less than the size of 𝐵, i.e., ∣𝑁(𝐵) ∖ 𝑆1∣ ≥ ∣𝐵∣, where
𝑁(𝐵) ⊆ 𝑉1 is the set of neighbors of 𝐵, there exists a
maximal matching from 𝑆2 to 𝑉1 ∖ 𝑆1.
Lemma 3. Pr[E2∣𝑛1 < 𝑘] = 1
Proof: When 𝑢 = 𝑘, each vertex 𝑣 in 𝑆2 has 𝑘
neighbors in 𝑉1. For all possible 𝐵, where 1 ≤ ∣𝐵∣ ≤ 𝑛2,
∣𝑁(𝐵) ∖ 𝑆1∣ ≥ 𝑘 − 𝑛1 = 𝑛2 ≥ ∣𝐵∣.
Hence, Pr[E2∣𝑛1 < 𝑘] = 1.
From Equation (1), Lemma 1, and Lemma 3, we have
Pr[E1] = Pr[E1∣𝑛1 = 𝑘] Pr[𝑛1 = 𝑘] + Pr[E1∣𝑛1 < 𝑘] Pr[𝑛1 < 𝑘]
≥ Pr[E1∣𝑛1 = 𝑘] Pr[𝑛1 = 𝑘]
+ Pr[E1∣E2 ∧ (𝑛1 < 𝑘)] Pr[E2∣𝑛1 < 𝑘] Pr[𝑛1 < 𝑘]
≥ (1− 𝑘/𝑝− 𝑜(1)) Pr[𝑛1 = 𝑘]
+ (1− 2𝑘/𝑝− 𝑜(1)) Pr[𝑛1 < 𝑘]
≥ 1− 2𝑘/𝑝− 𝑜(1)
It concludes this proof.
E. Proof of Theorem 2
The proof of Theorem 2 is similar to the proof of
Theorem 1 except for the analysis of the random graph. To
ease the analysis, the original repair procedure is modified
to that a new server randomly queries an old server 𝑢
times with replacement. Thus, a new server may query
less than 𝑢 distinct old servers. The modification leads to
a different random graph. The probability of a maximum
matching from 𝑆2 to 𝑉1 ∖ 𝑆1 in the new random graph is
smaller than that in the original random graph. Hence the
probability in the original random graph is underestimated.
Let 𝔾′ = (𝑉1, 𝑉2, 𝐸′) be the random bipartite graph, where
∣𝑉1∣ = 𝛼𝑛, ∣𝑉2∣ = (1 − 𝛼)𝑛, and 𝐸′ is the edge set. Let
event E’2 is that there is a maximal matching from 𝑆2 to
𝑉1∖𝑆1. Again, we need Lemma 1 and Lemma 4 for relations
between events E1 and E’2 to complete this proof.
Lemma 4. Pr[E′2∣𝑛1 < 𝑘] ≥ 1− 𝑜(1)
Proof: We use Lemma 2 (Hall’s theorem) and Lemma 5
to bound the probability Pr[E′2∣𝑛1 < 𝑘]. Lemma 5 is a
bound for 𝐶𝑥𝑦 (Due to limited space, the proof for Lemma 5
is omitted):
Lemma 5. 𝐶𝑥𝑦 ≤
(
𝑥(𝑥−𝑦+1)
𝑦
) 𝑦
2
When there exists a subset 𝐵 ⊆ 𝑆2 where ∣𝑁(𝐵)∖𝑆1∣ <
∣𝐵∣, no maximal matching from 𝑆2 to 𝑉1 ∖ 𝑆1 exists.
We consider every possible subset 𝐵 and overestimate the
probability of the complement event of E’2 by a union
bound.
Pr[∃𝐵 ⊆ 𝑆2, ∣𝑁(𝐵) ∖ 𝑆1∣ < ∣𝐵∣]
≤ 2𝑘 ⋅ max
𝐵⊆𝑆2
{Pr [∣𝑁(𝐵) ∖ 𝑆1∣ < ∣𝐵∣]}
Let ∣𝐵∣ = 𝑡, where 1 ≤ 𝑡 ≤ 𝑛2. The event that some
subset 𝐵 exists for ∣𝑁(𝐵) ∖ 𝑆1∣ < ∣𝐵∣ is equivalent to the
event that some subset 𝐴 exists where 𝐴 ⊆ 𝑉1 ∖ 𝑆1, ∣𝐴∣ ≤
𝑡− 1, and 𝐴 ∪ 𝑆1 ⊇ 𝑁(𝐵)
Pr [∣𝑁(𝐵) ∖ 𝑆1∣ ≤ ∣𝐵∣]
= Pr[∃𝐴, ∣𝐴∣ ≤ 𝑡− 1, 𝐴 ∪ 𝑆1 ⊇ 𝑁(𝐵)]
≤ 𝐶𝛼𝑛−𝑛1𝑡−1
(
𝑘 − 1
𝛼𝑛
)𝑡𝑢
(Lemma 5)
≤
(
2(𝛼𝑛− 𝑛1)(𝛼𝑛− 𝑛1 − 𝑡+ 2)
𝑡
) 𝑡−1
2
(
𝑘
𝛼𝑛
)𝑡𝑢
Since we want Pr[∃𝐵 ⊆ 𝑆2, ∣𝑁(𝐵) ∖ 𝑆1∣ < ∣𝐵∣] < 𝑒−𝑘, it
is sufficient to have:(
2(𝛼𝑛− 𝑛1)(𝛼𝑛− 𝑛1 − 𝑡+ 2)
𝑡
) 𝑡−1
2
(
𝑘
𝛼𝑛
)𝑡𝑢
< 𝑒−2𝑘
(3)
Now we substitute 𝛼𝑛 = 𝑘𝑑 in Equation (3) and overesti-
mate the left hand side:(
2𝑘2𝑑
𝑡
) 𝑡−1
2
𝑘(1−𝑑)𝑡𝑢 < 𝑒−2𝑘 (4)
We take nature logarithm on both sides of Equation (4) and
617
Trace Microsoft PCs Gnutella Skype PlanetLab
𝑛: average number of nodes 41970 1846 710 303
𝑓 : fraction of failed node per day 0.038 0.3 0.12 0.017
Table I
STATISTICS OF SYSTEM TRACES [2].
𝑘 = 4
𝑑 2 3 4 5 6
𝑢 3 3 3 3 2
𝑘𝑑 16 64 256 1024 4096
𝑘 = 8
𝑑 2 3 4 5
𝑢 6 4 3 3
𝑘𝑑 64 512 4096 32768
𝑘 = 16
𝑑 2 3 4 5
𝑢 8 5 4 3
𝑘𝑑 256 4096 65536 1048576
Table II
NUMERICAL ANALYSIS FOR THE NUMBER 𝑢 FOR DIFFERENT 𝑘 AND 𝛼𝑛.
Trace Microsoft Gnutella Skype PlanetLab
𝑛 41970 1846 710 303
𝑓 0.038 0.3 0.12 0.017
𝑘 4 8 4 8 4 8 4 8
𝑢 3 3 3 4 3 4 3 6
𝛼𝑛 16 4096 16 512 16 512 16 64
Survival duration (days) 26 23 3 3 8 2 47 39
Table III
NUMERICAL ANALYSIS FOR SURVIVAL DURATION IN DAYS.
𝑢 server failures bandwidth storage type
MBR [2] 𝑛− 1 single (2𝑛−2)𝑙(2𝑛−𝑘−1)𝑘 (2𝑛−2)𝑙(2𝑛−𝑘−1)𝑘 symmetric
MSR [2] 𝑘 + 1 single (𝑛−1)𝑙(𝑛−𝑘)𝑘
𝑙
𝑘 symmetric
MCR [10] 𝑛− 1 multiple (𝑛−1)𝑙(𝑛−𝑘)𝑘 𝑙𝑘 symmetric
SRHC [11] < 𝑘 multiple 𝑢𝑙𝑘 𝑙𝑘 asymmetric
Our work < 𝑘 multiple 𝑢𝑙𝑘
𝑙
𝑘 symmetric
Table IV
COMPARISON OVER REPAIR MECHANISMS.
queries more than 𝑘 servers. However, they only tolerate one
server failure. MCR tolerates multiple server failures, but
the number of required connections for repairing a failure is
𝑛 − 1. In other words, a new server has to communicate
with all other servers in the storage system. SRHC is a
novel way to recover the system from multiple server failures
with 𝑢 < 𝑘. But, SRHC is not suitable for distributed or
decentralized environment because it is asymmetric.
Our mechanism outperforms existing ones in terms of
the communication cost under the same consideration of
efficiency cost for storage. A new server queries less than
𝑘 servers and the required bandwidth is less than 𝑙. At the
same time, the storage cost is as less as the cost of the MSR.
Moreover, our repair mechanism recovers a decentralized
erasure code based storage system from multiple server
failures.
The sacrifice is the probability of a successful data re-
trieval. The probabilities of a successful data retrieval in
MBR, MSR, and MCR are all 1’s. Since SRHC exactly
regenerates missing codeword symbols, the probability is
1 as well. While our mechanism has lower communica-
tion cost, the probability of a successful data retrieval is
1− 2𝑘/𝑝− 𝑜(1). However, by choosing a sufficient large 𝑝,
the probability 1−2𝑘/𝑝−𝑜(1) is overwhelming. Moreover,
the probability can be dramatically increased by letting a
user query more than 𝑘 servers for data retrieval.
V. CONCLUSION AND FUTURE WORK
We consider the measurement of communication cost in
terms of the number 𝑢 of connections that a new server
has to establish. Our repair mechanism provides flexible
adjustment between 𝑢 and the number of remaining servers.
More importantly, our results confirm that to repair a server
failure, a new server can query less than 𝑘 servers.
Our repair mechanism symmetrically repairs multiple
server failures of decentralized erasure code based storage
systems. Thus, a lazy repair strategy or a periodical repair
strategy can be taken upon our repair mechanism. It is
619
行政院國家科學委員會補助國內專家學者出席國際學術會議報告 
                                                             101 年 7 月 13 日 
報告人姓名 曾文貴 
服務機構 
及職稱 
交通大學資工系 教授 
     時間 
會議 
     地點 
101 年 6 月 20 日至  101 年 6 月 22 日 
(出國時間為 101 年 6 月 18 日至  101 年 6 月 24 日) 
    美國華盛頓特區 NIST Administrator Building 101 
會議 
名稱 
2012 IEEE International Conference on Software Security and 
Reliability （SERE 2012） 
出國目的/
發表論文題
目 
發表論文： 
論文作者於題目: Hsiao-Ying Lin, John Kubiatowicz and Wen-Guey Tzeng. 
A Secure Fine-Grained Access Control Mechanism for Networked Storage 
System. In the Sixth IEEE International Conference on Software Security and 
Reliability (IEEE SERE 2012), June 2012.  
 
內容包括下列各項： 
一、 參加會議經過(含照片) 
本人於 18日從台灣搭機，當日抵達，19日調整時差，20開始參加會議，會議舉
辦期間為 6月 20日至 6月 22日，參加完會議後，於 23日離開華盛頓 特區，24日到達
台灣。於會議舉辦期間，本人參加會議行程，詳細行程資訊按時間順序整理如下: 
 6月 20日: 
會議首日，由謝續平教授協助聯繫當地的同學來接我們一行三人抵達 NIST的 101
大樓。進入 NIST區域需要持有一份通行文件與一份含照片的個人識別證件，經
過警察核對之後才能進入，門禁相當森嚴。我們抵達會場時約為早上 9點半。
會議地點在 NIST區域的 A101大樓。 
 
 
報到時，拿到大會時程，注意到自己需要在 22日下午主持一場議程(session)。 
      
第一場 Keynote speech是由 Virgil Gligor主講。 
 
 
 
早上參加的議程為: 
 
 
下午則是參加： 
 
下午的活動含有一個自助參訪與晚宴。兩項活動都是在 NIST 101大樓內舉行，
我們在參訪活動中，找到了牛頓的蘋果樹的後代，以及參訪了 NIST的博物館
(Museum): 
 在報告之後，有一位學者提出三個問題，分別是針對取消授權，儲存成本，以
及與其他存取控制方式的比較討論。上午議程結束後，與此學者討論了在結合
應用系統與密碼學工具上的經驗。 
 
這天下午的日程如下所示，這兩個議程皆由本人擔任議程主席(Session chair): 
 
至此，會議順利進行結束。 
 
 6月 23日: 
早上 8:30 離開飯店，搭乘地鐵前往雷根機場，在機場除了到航空櫃台報到，進
行行李檢查，亦通過繁複的安全檢查，足見美國對於機場安全的謹慎。在底特
律及東京轉機後，於台灣時間 6 月 24 日晚間 7 點抵達桃園機場，結束此次行程。 
 
二、與會心得 
這次與會在研究方面有多項心得，首先研究學術議題與潮流方面，目前針對軟
體安全與系統安全的研究大都需要檢驗非常底層的東西，例如原始碼(source 
code)或執行檔(binary code)，以發掘潛在的軟體弱點或系統弱點，因此需要大量
的計算，非常適合雲端的架構來執行，另一方面，利用 Model checking 的技術來
檢驗各種系統的功能與安全性也受到重視。我們發表的文章是屬於系統權限的
存取控制，雖然較少的會議的參者熟悉，但是在進行報告之後，許多學者積極
行政院國家科學委員會補助國內專家學者出席國際學術會議報告 
                                                             101 年 7 月 13 日 
報告人姓名 曾文貴 
服務機構 
及職稱 
交通大學資工系 教授 
     時間 
會議 
     地點 
101 年 6 月 20 日至  101 年 6 月 22 日 
(出國時間為 101 年 6 月 18 日至  101 年 6 月 24 日) 
    美國華盛頓特區 NIST Administrator Building 101 
會議 
名稱 
2012 IEEE International Conference on Software Security and 
Reliability （SERE 2012） 
出國目的/
發表論文題
目 
發表論文： 
論文作者於題目: Hsiao-Ying Lin, John Kubiatowicz and Wen-Guey Tzeng. 
A Secure Fine-Grained Access Control Mechanism for Networked Storage 
System. In the Sixth IEEE International Conference on Software Security and 
Reliability (IEEE SERE 2012), June 2012.  
 
內容包括下列各項： 
一、 參加會議經過(含照片) 
本人於 18日從台灣搭機，當日抵達，19日調整時差，20開始參加會議，會議舉
辦期間為 6月 20日至 6月 22日，參加完會議後，於 23日離開華盛頓 特區，24日到達
台灣。於會議舉辦期間，本人參加會議行程，詳細行程資訊按時間順序整理如下: 
 6月 20日: 
會議首日，由謝續平教授協助聯繫當地的同學來接我們一行三人抵達 NIST的 101
大樓。進入 NIST區域需要持有一份通行文件與一份含照片的個人識別證件，經
過警察核對之後才能進入，門禁相當森嚴。我們抵達會場時約為早上 9點半。
會議地點在 NIST區域的 A101大樓。 
 
 
報到時，拿到大會時程，注意到自己需要在 22日下午主持一場議程(session)。 
      
第一場 Keynote speech是由 Virgil Gligor主講。 
 
 
 
早上參加的議程為: 
 
 
下午則是參加： 
 
下午的活動含有一個自助參訪與晚宴。兩項活動都是在 NIST 101大樓內舉行，
我們在參訪活動中，找到了牛頓的蘋果樹的後代，以及參訪了 NIST的博物館
(Museum): 
 在報告之後，有一位學者提出三個問題，分別是針對取消授權，儲存成本，以
及與其他存取控制方式的比較討論。上午議程結束後，與此學者討論了在結合
應用系統與密碼學工具上的經驗。 
 
這天下午的日程如下所示，這兩個議程皆由本人擔任議程主席(Session chair): 
 
至此，會議順利進行結束。 
 
 6月 23日: 
早上 8:30 離開飯店，搭乘地鐵前往雷根機場，在機場除了到航空櫃台報到，進
行行李檢查，亦通過繁複的安全檢查，足見美國對於機場安全的謹慎。在底特
律及東京轉機後，於台灣時間 6 月 24 日晚間 7 點抵達桃園機場，結束此次行程。 
 
二、與會心得 
這次與會在研究方面有多項心得，首先研究學術議題與潮流方面，目前針對軟
體安全與系統安全的研究大都需要檢驗非常底層的東西，例如原始碼(source 
code)或執行檔(binary code)，以發掘潛在的軟體弱點或系統弱點，因此需要大量
的計算，非常適合雲端的架構來執行，另一方面，利用 Model checking 的技術來
檢驗各種系統的功能與安全性也受到重視。我們發表的文章是屬於系統權限的
存取控制，雖然較少的會議的參者熟悉，但是在進行報告之後，許多學者積極
國科會補助計畫衍生研發成果推廣資料表
日期:2012/10/26
國科會補助計畫
計畫名稱: 分散式網路儲存系統安全傳輸問題的研究
計畫主持人: 曾文貴
計畫編號: 98-2221-E-009-068-MY3 學門領域: 資訊安全
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
