Automation 2011                  The 11th International Conference on Automation Technology, Douliou, Yunlin, Taiwan, 2011 
Paper No. A008 
II. VISUAL SERVO 
A. Introductions of Visual Servo 
In order to develop the techniques of robotic obstacle 
avoidance based on machine vision. We control our robot 
hand under visual servo structure. Visual servo is a technique 
which uses feedback information extracted from a vision 
sensor to control the motion of a robot. There are two common 
classifications of control configuration named “Position 
Based Visual Servo” and “Imaged Based Visual Servo”. 
 The differences between the two control configurations are 
the reference inputs. Prior case uses coordinate error  in 3D 
space as reference input as shown in Fig. 1, while the other 
uses error signals in 2D image plane as reference input as 
shown in Fig. 2. 
Camera
Feature
Extraction
Forward
Kinematics
Deferential
Kinematics
Joint 
Control
Robot 
Manipulator
+
-
Coordinate
Transform
 
Fig. 1.  Position based visual servo configuration. 
 
Camera
Feature
Extraction
Forward
Kinematics
Deferential
Kinematics
Joint 
Control
Robot 
Manipulator
+
-
Coordinate
Transform
 
Fig. 2.  Image based visual servo configuration. 
B. Position Based Visual Servo 
Position-based visual servo defines its reference input as 
the relative position and orientation between the object and 
the robot hand. The relative position and orientation are 
recovered from the images obtained by the fixed camera. 
Since the robot control problem itself is classical and well 
established, we adopt our system under PBVS. 
Usually, the object feature points are extracted from the 
image and feature point positions in the image plane are used 
for computing  the object  coordinates in 3D. The error signal  
between  robot hand coordinate and camera coordinate is the 
reference input of  the control loop. The feedback signal is the 
estimated hand position which is computed on the basis of 
joint angle measurement. With proper computation, robot 
hand moves to precise position when the joint controller  
receives position commands and finally reach the goal 
position. 
C. Fixed Eyes Configuration 
System based on “Eye-to-Hand” configuration locates 
camera rigidly within robot manipulator’s workspace as 
shown in Fig. 3. That is to say, camera can’t change the 
position and orientation arbitrary. Since the transformation 
matrix between the original point of robot manipulator and 
camera is fixed, it’s relatively easy to estimate the pose of 
robot manipulator. 
 
Fig. 3.  Fixed eyes configuration. 
D. System Description 
In order to apply path planning method to visual servo 
system, a simple example is given [21]. The aim of this 
simulation is to move the robot hand avoiding obstacles and to 
reach the goal position. 
The cameras are static. Assume that the optical axes of the 
cameras are parallel each other and let the direction of the 
optical axes be z . The image plane is in the x y plane and 
the robot moves in the x y plane. Let the base line between 
the cameras be b , the position of the hand and the goal in the 
left camera’s image be 
hl and gl  respectively. Also, let the 
positions of the hand and the goal in the right camera’s image 
be 
hr and gr . Suppose the joint angles are 1 2( , )   , two 
link length are 
1 2( , )a a , hand position ( , )x zh h h , goal 
position ( , )x zg g g as shown in Fig. 4. 
 
Fig. 4.  System configuration. 
III. POTENTIAL FIELD METHODS 
Path planning artificial field is proposed by O. Khatib [14] 
in 1985. Maria Isabel Ribero [22] mentioned it’s simple and 
effective  of using  potential field method to realize obstacles 
avoidance. The main idea of this method is like magnetic 
fields phenomenon; That is to say, the goal generates an 
attractive potential while the obstacle generates a repulsive 
potential. The robot finally immersed in the potential field is 
subject to the action of a force that drives it to the goal position 
while keeping it away from the obstacles as shown in Fig. 5. 
Automation 2011                  The 11th International Conference on Automation Technology, Douliou, Yunlin, Taiwan, 2011 
Paper No. A008 
position and didn’t avoid obstacle. However, robot would 
bump into the obstacle in real condition. Then we combine 
system with potential field method. Any coefficients are been 
given as the previous cases. The results are shown in Fig. 8, 
Fig. 9. Robot hand actively avoids the obstacles before it 
touch them and then approaches the goal position as shown in 
Fig. 8. The angles change with time as shown in Fig. 9. 
Finally, we concern enormous obstacles occurring in next 
condition and set all the coefficients artificially as shown in 
Table II. Robot hand effectively avoids all of the obstacles 
with the potential field methods and reach the goal position as 
shown in Fig. 10. The joint angle varying with time are shown 
in  Fig. 11. 
 
TABLE I 
COORDINATE I 
Initial Point (1.1,0) 
Obstacle Point (0.55,0.55) 
Desire Goal Point (0,1.1) 
 
 
Fig. 7.  Simulation result without potential field method. 
 
 
Fig. 8.  Simulation result with potential field method. 
 
Fig. 9.  Robot joint angle plot (with an obstacle). 
 
TABLE II 
COORDINATE II 
Initial Point (1.1,0) 
Obstacle Points (0.55,0.55)、(0.8,0.3) 
Desire Goal Point (0,1.1) 
 
 
Fig. 10.  Simulation result with multi-obstacles 
 
 
Fig. 11.  Robot joint angle plot (with multi- obstacles). 
 
  
 
 
國科會國外研討會心得報告 
IEEE ICMA 2011 conference,  
Beijing, China 
計畫名稱：NSC 99-2221-E-011-096 
補助出席國際會議經費 
撰寫人：林紀穎 
服務單位名稱：國立台灣科技大學機械工程系 
出國地點：中國北京  
出國日期：2011/8/7~2011/8/10 
且談話幽默風趣，並有獨到見解，感覺上他不只在理論上基礎紮實，實作經
驗也相當豐富，演講中他不時提到日本這個機器人大國，發明了許多全球獨
一無二的機器人技術，但在今年三月期間的福島電廠救災時卻英雄無用武之
地，他一再的強調應用研究的重要性，不能花了一大堆國家經費做出來的東
西無法應用在實際產業上。 
2. 本次會議中大會安排了一個有關救災機器人的論壇，邀請四位有名的機器人
研究學者提供其發展方向，其中 Prof. Asama 與 Prof. Kosuge 兩位說明了為何
日本所發展的機器人技術無法應用在此次地震救災任務，原因有兩個，第一
是政府所資助的研究計畫一旦結束，並沒有再規劃特定的組織與經費進行維
護動作，有做過機器人實作的人都很清楚，沒有持續維護的機器人是無法派
上用場的；第二則是政治因素，若之前日本政府同意發展核能電廠之相關機
器人救難技術，政府高層認為，其所代表的意涵即核電廠並不安全，會影響
人民對其幅射安全有更大的疑慮，所以並沒有提供經費給各大學進行這方面
的研究。但是日本高層與學術單位已紛紛開始正視這個問題，重新思考審視
如何建立一個能應用在實際情況的機器人技術發展流程。其中一個重要的觀
念是：”Integrate a robot into the society” after “Integrate technologies into a robot  
system”，並將此觀念納入審查計畫書的標準之一，到目前為止學術界大都在
專注於如何將各種技術整合在一起以應用在機器人上面，但卻甚少去思考如
何將所發展之機器人融入人群當中，所以接下來他們將更努力往這方面去執
行以解決實際問題。不過，這樣子的做法對 SCI 論文發表勢必會造成一定程
度的阻礙，不知道對年輕學者來說該如何取捨？ 
3. 在本人報告的議程中有機會認識了一位來自廣州中山大學的張雨依教授，他
的報告主題為類神經網路相關，聊過之後發現他原來是香港中文大學王鈞教
授的學生，我們在言談中分享了彼此各自在中國大陸與台灣申請經費與指導
學生的經驗。其中讓我印象深刻的是他在博士班與博士後時皆是進行較理論
模擬探討的類神經研究主題，但在大陸卻是開始投入機器人實作的研究。他
國科會補助計畫衍生研發成果推廣資料表
日期:2011/09/16
國科會補助計畫
計畫名稱: 子計畫二：仿人式視覺引導手臂全自主物件擷取技術
計畫主持人: 林紀穎
計畫編號: 99-2221-E-011-096- 學門領域: 自動化系統整合技術
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
