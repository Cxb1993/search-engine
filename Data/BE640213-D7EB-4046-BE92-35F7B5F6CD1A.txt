一、 中文摘要 
為改善傳統語音強化演算法，本計畫提出一個應用多麥克風架構及旋積未知
信號分離在語音信號增強上的研究。利用多麥克風錄音環境之架設，可以利用旋
積未知信號分離來進行語音與干擾噪音之分離，這部份我們在傳統旋積未知信號
分離架構前端加入一個稱為聽覺線性預測殘值平方的方法，這方法執行類聽覺之
頻率-時間域預白化，其由聽覺濾波組和時間-頻率線性預測殘值所組成，目的在
於移除內部取樣點頻率-時間上的相關性，之後才是透過旋積未知信號分離來減
少在各個預處理觀測值之間的干擾。經過旋積未知信號得到逆混和矩陣，再將錄
製混合信號和逆混和矩陣作旋積處理後得到分離的兩組輸出信號，一是由語者音
源為主要部份，另一則是干擾音源為主要部分。為了從兩個輸出辨識出目標語
音，我們使用時間域線性預測殘值這個方法。一般說來，任何的純語音信號的時
間預測性會不低於空間分佈的干擾源如人聲噪音的時間預測性。因此，時間域線
性預測殘值可被視為一種鑑別目標語音和干擾噪音的測量。所以藉由此信號選擇
器，我們可以達到語者音源與干擾源的分離。 
針對前階段之中所未能濾除的背景噪音，我們將進行訊號子空間語音強化來
進行噪音消除的處理。這裡訊號經由小波聽覺濾波組分成數個子頻帶訊號，各個
子頻帶則由訊號子空間語音強化來進行噪音消除的處理，而訊號子空間的拆解則
是由子空間追蹤法來完成。由子空間追蹤法所估算出來的特徵值，則用以計算各
個子頻帶訊號的增益值。語音強化的處理為將子頻帶訊號經過特徵向量投影轉換
後，由增益值來調整其訊號大小，再經過反轉換來得到強化後的語音訊號。 
 
關鍵詞：旋積未知信號分離，多麥克風語音訊號處理，語音增強 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 1
 三、 目錄 
中文摘要………………………………………………………………………………1 
英文摘要………………………………………………………………………………2 
目錄……………………………………………………………………………………3 
報告內容………………………………………………………………………………4 
前言……………………………………………………………………………4 
研究目的………………………………………………………………………5 
文獻探討………………………………………………………………………5 
研究方法………………………………………………………………………6 
結果與討論…………………………………………………………..………………15 
參考文獻…………………………………………………..…………………………21 
計畫成果自評…………………………………………………………..……………23 
附錄…………………………………………………………..………………………25 
 
 
 3
研究目的 
本畫將分兩年的時間來進行多麥克風語音信號處理上之研究，建構一套多麥
克風語音處理系統，該系統將具有高抗雜訊能力及高強健等特性，使用者可以在
任一方位、距離讓進行麥克風收訊並進行語音強化之動作。 
 
 
文獻研討 
傳統的語音強化 (speech enhancement) 方法，如: Berouti 等提出的頻譜相減
法  (spectral subtraction)，Ephraim 等提出訊號子空間強化 (signal subspace 
enhancement)等，對於白噪音都能有效的消除。但是對於顏色噪音，這幾種方法
是較無效。近來，獨立成份分析被應用在許多不同的真實資料的分析上，像是數
位影像、語音訊號、文件資料、腦電波等。而由於獨立成份分析的成效顯著，使
得其亦被大量使用於處理未知訊號分離(Blind Signal Separation)方面的問題。諸
如，分離麥克風陣列所接收到多個語音訊號源的問題、或是分離麥克風陣列接收
的語音訊號源與背景噪音(Background Noise)的問題。獨立成份分析是一種用來
找出隨機變數或訊號中隱藏因子(Hidden Factor)的統計和分析方法。在觀察的資
料中，假設模型裡的資料變數是由潛在變數(Latent Variable)以線性或非線性方式
組合而成，而組合的系統是未知的。這些潛在變數假設為非高斯分佈且互相獨
立，其亦被稱為觀察資料的獨立成份。簡言之，獨立成份分析就是欲找出這些獨
立成份，或稱為因子、來源的方法。所以，我們利用此種特性針對所架設的多麥
克風錄音環境，來進行語音與背景噪音之分離。S. Y. Low 等和 Visser 等提出結
合旋積未知信號處理和後處理器來去除雜訊。目前旋積未知信號處理已發展為兩
個領域:一個為時域，一個為頻率域，在時域中，有大量的參數需要做迴旋積的
計算，然而在頻域，大量的參數被分成數個獨立估計的問題在每個頻率帶，因此
複雜的迴旋積也被轉成簡單直接的乘法。總結的來說，一般頻域的旋積未知信號
處理有較簡單的實作和較好的收斂特性。因此我們的方法會使用 Parra 等提出在
頻域的旋積未知信號處理。此法是利用混合信號之間彼此的二階統計特性(相關
函數)來做價值函數 (Cost Function)，以此來做調適性的修正分離矩陣 W。但是
對於旋積未知信號處理如何能達到最佳收斂和求得最佳矩陣並未著墨。K. 
Kokkinakis 進一步提出基於線性預測分析的未知信號處理。這是加一個前級處
理 – 利用時域線性預測分析的前處理來白化時域上的輸入信號，去除信號的相
關性，藉此增快收斂速度和找到更好的分離矩陣 W。 
 
 
 
 
 5
…j
x …
…
……
j
1x
2
jx
17
jx
1
t jε
2
t jε
17
t jε
1
jε
2
jε
17
jε
jε
圖二 聽覺線性預測殘值平方模組 
 
A 類聽覺之頻率-時間域預白化(聽覺線性預測殘值平方, PLPP2) 
圖二顯示所提出的類聽覺之頻率-時間域預白化方法架構包含四個模組: (1) 
聽覺小波轉換(PWT); (2) 時間域線性預測殘值(TD-LPR); (3) 頻率域線性預測殘
值(FD-LPR); (4) 和逆聽覺小波轉換(IPWT)。 
 
(1) 聽覺小波轉換 (PWT) 
具聽覺感知的小波轉換(Perceptual Wavelet Transform，PWT)是改良自傳統小
波轉換，使語音信號經 PWT 分解後的各個子頻帶信號的頻寬接近人耳的聽覺響
應，描述人耳聽覺響應的參數主要有巴克頻譜 (Bark)以及關鍵頻寬(Critical 
Bandwidth)。 
由小波轉換逼近巴克頻譜及關鍵頻寬是藉由調整小波轉換的樹狀結構來達
成。依據關鍵頻寬分佈情形，適當對訊號做高低頻的分解，使得子頻帶訊號的頻
率分佈跟關鍵頻寬近似。所使用的具聽覺感知的小波轉換分解架構圖，其中輸入
訊號經五個階段，共 16 次的高低頻分解。 
此工作假設在， 是麥克風錄製到的 m 個混合信號，
則是原始的 m 個信號來源， 代表第 j 個混和信號,
而且然後小波展開係數 
1 2( ) [ ( ), ( ), ..., ( )]=x Tmt x t x t x t
1 2( ) [ ( ), ( ),..., ( )]
T
mt s t s t s t=s ( )xj t
{ }( )( )Fij nx  可由下式求得 
{ }( ) F( ) ( ( )), i =1, 2, ..., 17.=Fij jn PWT nx x             (1) 
在此iF 代表臨界頻帶的索引。 
 
 7
    ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( )
1
( ) ( ) ( ) ( ) ( ) ( ) ( ),
=
= − = − − = −∑F F F F F F F F Fqi i i i i i i i ij t j tj t j jl t j t j j t j
l
E k E k E k E k a E k l E k ka ET    (4) 
( ) ( ) ( ) ( )
1 2, ,...,⎡= ⎣F F F Fi i i ij j j jqa a aa
T⎤⎦
−
是 第 l 階 的 線 性 預 測 係 數 向 量 和
。在經過逆離散餘弦轉換
(Inverse Discrete Cosine Transform, IDCT) 得到各鄰界頻帶的頻 -時域殘值
。 
( ) ( ) ( ) ( )( ) ( 1), ( 2),..., ( )⎡ ⎤= − − −⎣ ⎦E F F F Fi i i it j t j t j t jk E k E k E k q
T
( ) ( )Fij nε
(4) 逆聽覺小波轉換 (IPWT) 
最後各個臨界頻帶的殘值藉著逆聽覺小波轉換被合成為時間域的頻-時域殘
值 。 ( )j tε
          i( )( ) ({ ( )}),= Fij jn IPWT nε ε F =1, 2, …, 17.   (5) 
 
B 旋積未知信號處理-二階去相關性法 
預處理信號，即混和信號殘值由 由 m 個殘值信號
來源 所組成。 
1 2( ) [ ( ), ( ),..., ( )]
T
mt t t t= ε ε εε
1 2( ) [ ( ), ( ),..., ( )]
T
mt u t u t u t=u
        
1
1 0
( ) ( ) ( ),
−
= =
= ∑∑m Pj ij i
i
n h u n
τ
ε τ τ                     (6) 
(·)T 是一轉置運算，hij 是一未知FIR濾波器其時間長度為P. ( ) 代表第i個殘值
來源。因為我們是在頻域下做未知信號分離，所以我們需要經過一個離散傅利葉
轉換 (Discrete Fourier Transform, DFT)，於是上式被轉為頻率域的公式，如下所
示。 
iu n
( , ) ( ) ( , ), for ,≈ n n PE H U Tω ω ω         (7) 
( )ωH 和 ( , )tU ω 分別是混合矩陣和殘值信號來源估測的轉換表示，從公式可以發
現旋積運算已在每一頻率槽被轉成乘法運算的未知信號處理問題了。接下來我們
要做的就是找到一個逆混合矩陣 從混合信號殘值W(ω) ( , )tE ω 來復原m筆原始的
殘餘來源信號估測 ˆ ( , )tU ω ，如下式 
ˆ ( , ) ( ) ( , )=nU W Eω ω ω n .                   (8) 
首先我們要設定我們的價值函數 ))(( ωWJ ，價值函數 ))(( ωWJ 被定義為測
量 1 2ˆ ˆ ˆ ˆ( , ) [ ( , ), ( , ),..., ( , )]= mn U n U n U nU Hω ω ω ω 間的獨立性，我們可以將 ))(( ωWJ 最
 9
信號的時間預測性會高於或等於空間分佈的干擾源如人聲噪音。因此 時間域線
性預測殘值可被視為一種鑑別目標語音和干擾噪音的測量。 
 
2. 信噪比知覺的子空間語音增強 
由於在環境中，充斥著各式各樣的雜訊，而語音訊號的辨識率又深受雜訊的
影響，因此，我們導入子空間語音增強，藉以減少環境中的雜訊對辨識率的影響。 
Ephraim 和 Van-Trees 推薦一個訊號子空間語音增強系統。在其所推薦的系統
當中，將錄製的訊號分解成訊號加雜訊子空間及雜訊子空間。由訊號加雜訊子空
間中扣除雜訊子空間，以估算剩餘訊號子空間中的乾淨訊號，這個分解可藉由
Karhunen-Loeve 轉換(KLT)加以完成。 
語音增強的問題可以描述為：由一個語音訊號 經由無失真的通道傳輸，也
就是他僅受環境中附加雜訊 的影響，而最後受雜訊影響的語音訊號 可表示成 
x
n y
= +y x n                            (15) 
其中  觀察周期為
M。 
語音的估算可以藉由其估算子  而得到，乾淨語音的殘值可以由ε 可表示
為 
x
ˆ
    ( - )
    n
ε
ε ε
= −
= +
= +
x x
H I x Hn
                         (16) 
ε n 表示殘餘的雜訊，而ε x表示訊號失真。訊號失真的能量可以由(17)計算而得
到 
2 { } {( ) ( )T Tx x x xtrE trε ε ε= = − −H I R H I }
}
       (17) 
相同的殘餘雜訊的能量可以由(18)計算而得到 
2 2{ } {T Tn n n ntrE e e trε σ= = HH                (18)  
最後全部的誤差能量, ε 可藉由(19)而計算 
222
nx εεε +=                             (19) 
當限制平均雜訊能量小於
2
nασ ，具最小訊號失真的時域限制估算子(Time 
Domain Constraint estimator) ，因此 
 11
 圖四 為了處理遠距離辨識收音的前處理器 
 
 
錄製六個訊號 子空間語音增強 關鍵字辨識 投票Mi>TH i=0~5
拋棄
求絕對
最大值
求臨界值
5
0
1
6 ii
M
=
∑
正規化各
通道資料
N
Y
圖五 前處理器系統流程圖 
 
3. 為了處理遠距離辨識收音的前處理器 
本計畫透過多隻麥克風並整合子空間語音增強達到遠距離辨識的功能。圖四
是為了處理遠距離辨識收音的前處理器的系統架構圖，當使用者發出含有關鍵字
命令的語音時，聲音訊號經由六隻麥克風及同軸電纜線傳送至前置放大電路，前
 13
 
圖六 工作電路 
 
 
Fig. 7. Experimental layout. 
 
五、 結果與討論 
A. Experimental Environment 
The performance of the proposed architecture was measured in a room (530 × 
330 × 280cm) with a two-element microphone array. The inter-element distance was 
14cm and the speech source was located 40 cm from the center of the array at an 
angle 60° (see Fig. 7). The settings for all the experiments were as follows: 
z sentences were input in Chinese from a male speaker; 
z 50 different sentences were input, each with about 30,000 samples; 
z babble noise in AURORA database was employed as the interference; 
 15
proposed architecture is able to perform best and reduce over half the number of 
iterations needed from the other three architectures. Table II presents the average 
SNRI values achieved in the four enhancement architectures with the kurtosis based 
signal selection. Compared to Table I, we can discover that both measurements 
achieved approximate performances in most cases. However, in the heavily noisy 
environment with very low average SNR value, the proposed TD-LPR measurement 
had better performance. 
Figures 9(a)-(f) exemplify both waveforms and spectrograms of the original, 
mixed, and enhanced signals. It is apparent to observe that only the CBSS fails to 
preserve the color of the original signal, and it is worthy to note the energy is most 
evenly distributed along the entire range of low frequencies in Figs. 9(c). On the other 
hand, the proposed architecture manages to successfully retain source spectra shown 
here in Figs. 9(f), which is most similar to the spectra of the original speech source in 
Figs. 9(a) than the other three architectures in Figs. 9(c), (d) and (e). However, the 
proposed architecture will fail to work if there are two speech sources from the array. 
When that happens, we can not ascertain which the target speech is. 
This work develops a novel architecture exploiting spectro-temporal and spatial 
information for speech enhancement. The architecture is composed of the 
auditory-like spectro-temporal pre-whitening module and the CBSS module. The 
spectro-temporal and spatial information are exploited to enhance the target speech 
and to suppress interference resulting from the use of two microphones. The proposed 
perceptual linear prediction residual squared (PLPR2), as the pre-whitening stage, 
comprises the perceptual wavelet filterbank, the subband TD-LPR, and the subband 
FD-LPR models. The PLPR2 can build the spectrogram-like signal representation for 
human auditory processing, to effectively remove the inter-symbol correlation, and 
thus ensure that the recorded source mixtures are spectrally and temporally 
independent. Successful enhancement and fast convergence are accomplished by 
cascading the PLPR2 to the CBSS module and the TD-LPR as the signal selection. 
Evaluation results show the superiority of the proposed architecture in terms of SNRI 
measure. 
 
 17
(b) 
(c) 
(d) 
(e) 
 19
Table II. Evaluation on Various Enhancement Architectures with the Kurtosis Based 
Signal Selection in Average SNRI (dB) for Sentences Corrupted by Interfering Babble 
Noise  
Average SNR measure (dB) 
Corrupted Signal  
-5.0 -3.13 -2.58 -2.54 -2.49 
Enhancement Architecture Average SNRI (dB) 
CBSS 1.67 2.01 1.20 1.54 1.19 
TD-LPR + CBSS 1.11 2.10 1.47 1.59 1.28 
FD-LPR + CBSS 1.70 2.01 1.20 1.52 1.05 
PLPR2   + CBSS 1.77 2.14 1.60 1.68 1.46 
 
 
六、 參考文獻 
[1] B. D. Van Veen and K. M. Buckley, “Beamforming: a versatile approach to spatial 
filtering,” IEEE Acoustics, Speech and Signal Processing Magazine, vol. 5, no.2, 
pp. 4–24, April 1988. 
[2] W. Kellermann, “A self-steering digital microphone array,” in Proceedings of 
IEEE International Conference on Acoustics, Speech, and Signal Processing, vol. 
5, May 1991, pp. 3581–3584. 
[3] P. Comon, “Independent component analysis: a new concept?,” Signal Processing, 
vol. 36, no. 3, pp. 287–314, 1994. 
[4] J. F. Cardoso, “Blind signal separation: statistical principles,” Proceedings of the 
IEEE, vol. 86, no. 10, pp. 2009–2025, October 1998. 
[5] A. Hyvärinen, J. Karhunen, and E. Oja, Independent Component Analysis, New 
York: Wiley, 2001. 
[6] A. Bell and T. Sejnowski, “An information-maximization approach to blind 
separation and blind deconvolution,” Neural Computation, vol. 7, no. 6, pp. 
1129–1159, November 1995. 
[7] D. Yellin and E. Weinstein, “Multichannel signal separation: methods and 
analysis,” IEEE Transactions on Signal Processing, vol. 44, no.1, pp. 106–118, 
January 1996. 
[8] K. Rahbar and J. P. Reilly, “Blind source separation algorithm for MIMO 
convolutive mixtures,” in Proceedings International Workshop on Independent 
Component Analysis and Signal Separation, December 2001, pp. 242–247. 
[9] K. Rahbar and J. P. Reilly, “A frequency domain method for blind source 
 21
Proceedings of the 2002 IEEE Signal Processing Society Workshop, pp. 515–524, 
Martigny, Switzerland, September 2002. 
[23] N. Charkani and Y. Deville, “Self-adaptive separation of convolutively mixed 
signals with a recursive structure Part II: Theoretical extensions and application 
to synthetic and real signals,” Signal Processing, vol. 75, no. 2, pp. 117–140, 
June 1999. 
[24] S. Choi, H. Hong, H. Glotin, and F. Berthommier, “Multichannel signal 
separation for cocktail party speech recognition: A dynamic recurrent network,” 
Neurocomputing, vol. 49, no. 1–4, pp. 299–314, December 2002. 
[25] X. Sun and S. C. Douglas, “A natural gradient convolutive blind source 
separation algorithm for speech mixtures,” in Proceedings of the 3rd 
International Conference on Independent Component Analysis and Blind 
Source Separation, December 2001, pp. 59–64. 
[26] K. Kokkinakis and A. K. Nandi, “Multichannel blind deconvolution for source 
separation in convolutive mixtures of speech,” IEEE Transactions on Audio, 
Speech and Language Processing, vol. 14, no. 1, pp. 200–212, January 2006. 
[27] T. Kim, H. T. Attias, S. Y. Lee, and T. W. Lee, “Blind source separation exploiting 
higher-order frequency dependencies,” IEEE Transactions on Speech and Audio 
Processing, vol. 15, no. 1, pp.70–79, January 2007. 
[28] M. Athineos, H. Hermansky and D. Ellis, “PLP : Autoregressive modeling of 
auditory-like 2-D spectro-temporal patterns
2
,” ISCA Tutorial and Research 
Workshop on Statistical and Perceptual Audio Processing SAPA-04, Jeju, Korea, 
October 2004, pp. 37–42. 
[29] S. Y. Low, S. Nordholm and R. Togneri, “Convolutive blind signal separation 
with post-processing,” IEEE Transactions on Speech and Audio Processing, vol. 
12, no. 5, pp. 539–548, September 2004.  
[30] E. Zwicker and E. Terhardt, “Analytical expressions for critical-band rate and 
critical bandwidth as a function of frequency,” Journal of the Acoustical Society of 
America, vol. 68, no. 5, pp. 1523–1525, 1980. 
[31] S. H. Chen and J. F. Wang, “Speech enhancement using perceptual wavelet 
packet decomposition and Teager energy operator,” The Journal of VLSI Signal 
Processing Systems, vol. 36, no. 2–3, pp. 125–139, February 2004. 
 
 
七、 計畫成果自評 
本計畫之研究針對語音訊號強化技術作深入探討，掌握國際上在語音技術開
發的趨勢，研究的過程中，已有若干在國際上發表的學術論文產生，並有相關發
 23
八、 附錄 
Chung-Hsien Yang, Jia-Ching Wang, Jhing-Fa Wang, Chung-Hsien Wu, and 
Kai-Hsing Chang, “Design and Implementation of Subspace-Based Speech 
Enhancement under In-Car Noisy Environments,” to be published in IEEE 
Transactions on Vehicular Technology.  
 
 
 
 25
 2
5. Circuits and Systems for Communications  
6. Computer-Aided Network Design  
7. Digital Signal Processing  
8. Graph Theory and Computing  
9. Life-Science Systems and Applications  
10. Multimedia Systems and Applications  
11. Nanoelectronics and Gigascale Systems  
12. Neural Systems and Applications  
13. Nonlinear Circuits and Systems  
14. Power Systems and Power Electronic Circuits  
15. Sensory Systems  
16. Visual Signal Processing and Communications  
17. VLSI Systems and Applications  
18. Ubiquitous Computing  
 
→本次會議之 Keynote Talk如下： 
1. Redshift - the explosion of massive scale and its implications for circuits and 
systems, Presented by: Dr. Greg Papadopoulos,Chief Technology Officer and 
Executive Vice President of Research and Development, USA 
2.  Si Technology Roadmap For Ubiquitous Computing, Sensing, and Perception, 
Presented by: Dr. Dennis Buss, Vice President of Silicon Technology 
Development,USA 
3. Emotional Intelligence Technology and the Death of Clippy,  Presented by: Dr. 
Rosalind W. Picard, Director of Affective Computing Research, Co-Director of 
Things That Think, Professor of Media Arts and Sciences, M.I.T. Media Laboratory, 
USA  
 
→本次會議之 Tutorial如下： 
1. Integrated Biosensors 
2. Satellite Navigation Receiver Design : GPS and Beyond 
3. Design of Programmable Wireless Networks aka Cognitive Radios 
4. Circuit Techniques for Operational Amplifier Speed and Accuracy Improvement : 
Analog Circuit Design with Structural Methodology 
5. Design Challenges and Solutions for Nanoscale Memories 
6. Wireless Sensor Networks: From Theory to Practice 
7. Challenges and Opportunities of Digital Design in Nanoscale CMOS 
8. Analog Circuit Design on Digital CMOS : Why it is difficult, and which ideas help? 
9. Design of Digital Filters Satisfying Prescribed Specifications 
 
 
 
五、與會心得: 
 1
出席國際會議心得報告 
International Conference on Intelligent Information Hiding and 
Multimedia Signal Processing (IIH-MSP 2006)  
 18-20 Dec. 2006  
 
一、參加會議時間：民國 95年 12月 18日至 12月 20日 
二、會 議 地 點 ：洛杉磯 Pasadena, California, U.S.A. 
三、行       程： 
12月 17日(日) 
長榮航空(BR 908) , 1640 出發：高雄(KHH) KAOHSIUNG INTL, 1730 抵達：
台北(TPE) 中正國際機場 
長榮航空(BR 12), 1840 出發：台北(TPE) 中正國際機場, 1405 抵達：洛杉磯
(LAX) LOS ANGELES INTL 
12月 19日(二) 
長榮航空(BR 11), 1535 出發：洛杉磯(LAX) LOS ANGELES INTL, 2155 抵
達：台北(TPE) 中正國際機場 
12月 20日(三) 
長榮航空(BR 909), 2250 出發：台北(TPE) 中正國際機場, 2340 抵達：高雄
(KHH) KAOHSIUNG INTL 
 
四、出席會議經過： 
95.12.17(日)從台灣高雄小港機場經台北中正機場，抵達洛杉磯，抵達飯店時
已接近晚上 6-7點。 
95.12.18(一)參加 IIH-MSP 2006，並與世界各地的專家學者互相討論交流。 
95.12.19(二)參加 IIH-MSP 2006 並演講 Intelligent Multimedia Processing for 
Human-Centric Digital Life，中午 15:35 從洛杉磯搭機返回台
灣。 
95.12.20(三)晚上 23:40從抵達台灣高雄小港機場。 
本次會議主要有下列主題： 
Track I: Information Hiding and Security 
- Watermarking: techniques, attacks, protocols, applications 
- Steganography and steganalysis: techniques, protocols, applications 
- Cryptography and cryptanalysis: techniques, protocols, applications 
