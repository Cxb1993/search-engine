2 
 
 
國科會補助專題研究計畫成果報告自評表 
請就研究內容與原計畫相符程度、達成預期目標情況、研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）、是否適
合在學術期刊發表或申請專利、主要發現或其他有關價值等，作一綜合評估。 
1. 請就研究內容與原計畫相符程度、達成預期目標情況作一綜合評估 
   ■  達成目標 
□ 未達成目標（請說明，以 100 字為限） 
□ 實驗失敗 
□ 因故實驗中斷 
□ 其他原因 
說明： 
 
2. 研究成果在學術期刊發表或申請專利等情形： 
論文：■已發表 □未發表之文稿 □撰寫中 □無 
專利：□已獲得 □申請中 □無 
技轉：□已技轉 □洽談中 □無 
其他：已發表於兩個國際研討會(獲得最佳論文獎)及一篇國際期刊。 
 
3. 請依學術成就、技術創新、社會影響等方面，評估研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）（以
500 字為限） 
本研究為探討集合值資料庫上非一般之化之新型隱匿模式及技術。文獻上尚
鮮見此方面之論文發表。目前之結果為初步之隱藏方法之設計及效率分析，
具學術探討價值。可進一步探究其實際應用層面並評估其對社會網路上資料
隱私、個資隱私之可行性應用及效益。 
 
 
 
 
附件二 
4 
 
through friendships, hobbies, professional 
association, and so on.  These user information 
and relationship can be modeled as vertices and 
edges in complex graphs and are of significant 
important in various application domains such as 
marketing, psychology, epidemiology and 
homeland security.  As a result, companies and 
institutions hosting the data are interested and 
expect to be beneficial in releasing portions of the 
graphs so that research communities can analyze 
the data.  However, these social network graphs 
may contain sensitive information.  In order to 
protect the privacy of users against different types 
of attacks, graphs should be anonymized before 
they are published. 
Some current practices to protect user privacy 
from published data include removing all 
identifiable personal information such as names 
and social security numbers, limiting access, 
“fuzzing” the data, eliminating unnecessary 
groupings, augmenting with additional data, etc.  
However, it is still easy for an attacker to identify 
the target by performing different structural and 
non-structural queries.  Let’s consider the 
following examples of re-identification attack on 
relational data, transaction data, and graph data. 
For published relational data, given a public 
voter registration data and a private microdata 
such as the de-identified (name and social security 
number removed) patient data of Massachusetts’s 
state employees, a simple “linking” attack by 
joining the two datasets can re-identify the 
identity and medical history of the state’s 
governor.  According to one study, 
approximately 87% of the population of the 
United States can be uniquely identified on the 
basis of their 5-digit zip code, sex, and date of 
birth [10, 11]. 
For published transaction data, America Online 
(AOL) released a large portion of its search 
engine query logs for research purposes in August 
2006.  The dataset contained 20 million queries 
posed by 650,000 AOL users over a 3 month 
period.  Before releasing the data, AOL replaces 
each user’s name by a random identifier.  
However, by examining unique query terms, the 
New York Times [2] demonstrated that the 
searcher No. 4417749 was traced back to Thelma 
Arnold, a 62-year-old widow who lives in Lilburn, 
Georgia.  Despite a query does not contain 
address or name, a searcher may still be 
re-identified from combination of query terms that 
are unique enough about the searcher. 
For published graph data, even when a network is 
published without any identity information, it is 
still possible to locate the target with high 
probability based on some structural information 
around the target [4, 13].  Similar to the 
quasi-identifiers in relational or set-valued data 
that can be used as background knowledge for 
re-identification, any topological structure of the 
network can be utilized to identify the target in a 
released network.  There can be four types of 
structural attacks in this environment [4, 6, 12]: 
degree-attack, subgraph attack, 1-neighborhood 
attack, and hub-fingerprint-attack.  For example, 
given a social network G in Figure 1a, and a 
corresponding naïve anonymized network G’ in 
Figure 1b, by removing all node identities, we can 
identify that David is vertex 4 in G’ if we know 
that David has four neighbors (degree attack).  It 
is also possible that an attacker can also launch a 
query based on non-structural information (such 
as vertex label) to identify the target. 
6 Frank
1 Alice
2 Bob
3 Carl 4 David
5 Ed
7 Gabe
 
(a) Original graph G 
1 
2
3 4
5
6
7
 
6 
 
To achieve such an anonymization, Motwani [8] 
proposed a skillful 2-phase technique that is based 
on suppression algorithm on relational data 
proposed by Park etc [9] and flipping.  The aim 
of the suppression algorithm is to efficiently 
obtain a partition of a dataset so that minimal 
number of suppression is required on each subset 
of the partition to achieve k-anonymity.  For 
example, in the first phase, the suppression 
algorithm will partition the dataset into two 
subsets  = {{S1, S4, S5}, {S2, S3, S6}}, where S1 = 
S4 = S5 = (1, *, 0), S2 = S3 = S6 = (*, 1, 0), * 
represents that the item value is suppressed, 1 
represents that the corresponding item is in the 
record, and 0 represents the item is not in the 
record.  In the second phase, for each subset of 
the partition, the suppressed items are flipped to 1 
or 0 depending on the minimum number of 
flipping required.  For example, for subset {S1, 
S4, S5}, there are two records S4, S5 that do not 
contain item e2 and one record S1 that contains 
item e2.  Deleting item e2 from record S1 will 
make this subset of records identical and become 
3-anonymity. 
To efficiently partition a dataset, Park etc [9] 
proposed using minimum length sum to estimate 
the number of suppression required for a given 
partition, where the size of each subset is between 
k and 2k-1.  The partition with minimum length 
sum will achieve 2(1 + ln 2k)-approximation to 
the optimal suppression of the k-anomymization 
problem.  The minimum length, a(S), for a set of 
records is defined as follows. 
Definition 3. (Minimum length of suppression 
for relational data) Let a(S) be the number of 
attributes with multiple distinct values in a table S 
and defined as follows: 
a(S) := |{i : u, v  S, u[i]  v[i]}| 
where u[i] and v[i] are the values of i-th attribute 
of the records u and v respectively. 
However, it is noticed that although minimum 
length may be a better estimate than minimum 
diameter [7] for suppressing relational data.  For 
anonymizing set-valued data, direct estimation of 
addition and deletion of items may achieve better 
partition that requires fewer operations.  In the 
next section, we will propose an effective 
algorithm to partition a dataset so that minimal 
number of items needs to be added or deleted and 
the resulting dataset is k-anonymous. 
III. PROPOSED ALGORITHM 
Given a relational dataset, k-minimum 
diameter sums [7] and k-minimum length sum [9] 
have been proposed to determine a partition with 
minimum number of suppression for achieving 
k-anonymity.  For set-valued data, we propose 
the following measure, ad(S), to effectively 
estimate the number of addition and deletion 
operations required for a given set of records.  
For a given set of records S,  



Ij
s(j)Oad(s)
1

Where OS(j) = min { number of transactions in S 
containing item j, number of transactions in S not 
containing item j}, and |I| is the total number of 
items in the dataset.  The number of operation 
required for a partition can be expressed as  



S
ad(S))ad( 
Where  is a partition of the dataset. 
Figure 3 shows two partitions of eight records 
and their minimum length sums a(S) and 
minimum operation sums ad(S).  In Figure 3a, 
the a(S) is 3 + 3 = 6 and the ad(S) is 4 + 4 = 8.  
In Figure 3b, the a(S) for this partition is 3 + 3 = 6, 
which is same as previous partition and cannot 
distinguish the difference between the two 
partitions.  The ad(S) for this partition is 3 + 3 = 
6, which is smaller than the previous partition and 
indicates this is a better partition. 
To obtain optimal partition of a given dataset, 
Myerson [7] proposed a set-cover type greedy 
approach.  Let F be the collection of all subsets 
of D with cardinality in the range of [k, 2k-1].  
Let S  F be a set in the collection.  The greedy 
approach selects the S with minimum diameter 
and includes it to the cover.  The process repeats 
8 
 
 
Figure 5  Varying k for running time 
V. CONCLUSION 
In this work, we have studied the privacy 
preserving network publishing problem in general, 
and preserve privacy against linking attack on 
set-valued node data in particular.  The problem 
of k-anonymizing relational and set-valued data 
with the minimum number of suppressed cell is 
known to be NP-hard.  Approximation 
algorithms based on set-cover greedy approach 
have been developed for relational data.  We 
extend the approach and propose an effective 
technique to minimize the number of operations to 
achieve k-anonymity.  Numerical comparison 
with previous modified suppression-based 
algorithm shows that our technique requires less 
number of operations.  In the future, we will 
consider further improving the running time of the 
proposed approach, show the complexity bound 
and combined with structural anonymization. 
ACKNOWLEDGMENT 
This work was supported in part by the 
National Science Council, Taiwan, under grant 
NSC-99-2221-E-390-033. 
 
REFERENCES 
[1] L. Backstrom, D. P. Huttenlocher, J. M. Kleinberg, and X. Lan. 
Group formation in large social networks: membership, growth, and 
evolution. In KDD, pages 44–54, 2006. 
[2] M. Barbaro and T. Z. Jr. A face is exposed for AOL searcher no. 
4417749. New York Times, Aug 2006. 
[3] J. Cheng, A. Fu, and J. Liu, K-isomorphism: privacy preserving 
network publication against structural attacks, In SIGMOD 
conference, 459-470, 2010. 
[4] M. Hay, G. Miklau, D. Jensen, D. F. Towsley, and P. Weis. Resisting 
structural re-identification in anonymized social networks. PVLDB, 
1(1):102–114, 2008. 
[5] Y. He and J.F. Naughton, Anonymization of set-valued data via 
top-down, local generalization, in VLDB 2009. 
[6] K. Liu and E. Terzi. Towards identity anonymization on graphs. In 
SIGMOD Conference, pages 93–106, 2008. 
[7] A. Meyerson and R. Williams. On the complexity of optimal 
k-anonymity. In Proc. of PODS, 2004. 
[8] R. Motwani and S.U. Nabar, Anonymizing unstructured data, arXiv: 
0810.5582v2, [cs.DB], 2008. 
[9] H. Park and K. Shim. Approximate algorithms for k-anonymity. In 
Proceedings of the 2007 ACM SIGMOD International Conference on 
Management of Data, pages 67–78, 2007. 
[10] P. Samarati and L. Sweeny. Generalizing data to provide anonymity 
when disclosing information. In Proc. of ACM Symposium on 
Principles of Database Systems, page 188, 1998. 
[11] L. Sweeny. k-anonymity: a model for protecting privacy. 
International Journal on Uncertainty, Fuzziness and 
Knowledge-based Systems, 10(5):557–570, 2002. 
[12] B. Zhou and J. Pei. Preserving privacy in social networks against 
neighborhood attacks. In ICDE, pages 506–515, 2008. 
[13] L. Zou, L. Chen, and M. T. Ozsu. K-automorphism: A general 
framework for privacy preserving network publication. In VLDB, 
2009. 
 
 
 
 
1 
 
國科會補助專題研究計畫項下出席國際學術會議心得報告 
                                 日期：100 年 7月 31日 
                                 
 
計畫編號 NSC  99－2221－E－390－033－ 
計畫名稱 集合值資料庫上非一般化方式之隱匿方法之研究 
出國人員
姓名 
王學亮 
服務機構
及職稱 
國立高雄大學資訊管理系教授 
會議時間 1. 99/12/18-99/12/20 
2. 100/6/28-100/7/1 
會議地點 
1. 中國杭州 
2. 美國紐約州雪城(Syracuse University, 
New York, USA) 
會議名稱 
1. (中文)2010第3屆電機電子工程學會/計算機器學會之數碼控制、實體、及社會計算國際研
討會  
(英文)The 3rd IEEE/ACM International Conference on Cyber, Physical and Social Computing 
2. (中文)第24屆工業、工程、及其他應用之應用智慧系統國際研討會 
(英文)The 24th International Conference on Industrial, Engineering and Other Applications of 
Applied Intelligent Systems (IEA/AIE 2011)  
發表論文
題目 
1. (中文)集合值社會資料之隱匿 (最佳論文獎) 
(英文) Anonymizing Set-Valued Social Data (Best Paper Awards) 
2. (中文)一個基於TF-IDF之經驗法則之資料清除方法 (受邀投稿APIN期刊特輯) 
(英文) A Heuristic Data-Sanitization Approach Based on TF-IDF (Invited to special issue of 
Applied Intelligence) 
3 
 
 
 
(三)攜回資料名稱及內容 
 
Proceeding of the 3rd IEEE/ACM International Conference on Cyber, Physical and Social Computing（光
碟）. 
 
 
(四)附件 
 
發表論文全文 
 
5 
 
still be re-identified from combination of query 
terms that are unique enough about the searcher. 
For published graph data, even when a network 
is published without any identity information, it is 
still possible to locate the target with high 
probability based on some structural information 
around the target [4, 13].  Similar to the 
quasi-identifiers in relational or set-valued data that 
can be used as background knowledge for 
re-identification, any topological structure of the 
network can be utilized to identify the target in a 
released network.  There can be four types of 
structural attacks in this environment [4, 6, 12]: 
degree-attack, subgraph attack, 1-neighborhood 
attack, and hub-fingerprint-attack.  For example, 
given a social network G in Figure 1a, and a 
corresponding naïve anonymized network G’ in 
Figure 1b, by removing all node identities, we can 
identify that David is vertex 4 in G’ if we know that 
David has four neighbors (degree attack).  It is also 
possible that an attacker can also launch a query 
based on non-structural information (such as vertex 
label) to identify the target. 
 
 
 
(a) Original graph G 
 
(b) Naïve anonymized graph G’ 
Figure 1  Anonymized Networks 
There are basically two types of sensitive 
information that one may want to keep private and 
may be under attack in a social network 
environment: node information and link information 
[3].  The node information is the information 
attached to a vertex.  For example, the emails sent 
by an individual, the personal information such as 
age, sex, zip code, and transaction data such as 
purchased items [5].  The link information is about 
the relationships among the individuals which may 
be considered sensitive.  To protect link 
information, there are some studies such as k-degree, 
k-automorphism, k-isomorphism privacy models 
addressing various types of structural attacks.  To 
protect node information, many generalization and 
suppression-based k-anonymity techniques for 
relational and set-valued data have been proposed.  
Since most privacy models against link information 
attacks transform the graph into various 
k-―identical‖ subgraphs and node information in 
each subgraph or between subgraphs are not 
emphasized, this work concentrates on anonymizing 
node information that contains set-valued data.  
We propose a k-anonymization-based technique 
that minimizes the number of operations on 
set-valued node data to achieve k-anonymity. 
The rest of the paper is organized as follows.  
Section 2 gives the problem description.  Section 3 
describes the proposed algorithm.  Section 4 
reports the numerical experiments.  Section 5 
concludes the paper. 
II. Problem Description 
Current studies in privacy preserving network 
publication have proposed many valuable privacy 
models and anonymization techniques.  Similar to 
studies in privacy preserving data publishing, the 
anonymization depends on what external 
information or background knowledge may be 
acquired by an adversary.  An adversary may use 
an arbitrary subgraph to locate the vertex in a graph 
that belongs to an individual for re-identification 
attacks.  Several methods [1, 3, 6, 13] proposed to 
achieve k-anonymity based only on structural 
adversary knowledge.  In this work, we assume 
that the adversary may possess both structural and 
non-structural background knowledge but will 
concentrate on anonymizing set-valued node 
information for k-anonymity. 
Let D = {T1, …, Tn} be a dataset containing n 
records that belong to n nodes in a network.  Each 
record is a set of items.  We define an anonymous 
dataset as follows [8]. 
Definition 1. (K-anonymity for set-valued data) 
We say that D is k-anonymous if every transaction 
Tj  D has at least (k-1) other identical records in 
7 
 
Figure 3 shows two partitions of eight records 
and their minimum length sums a(S) and minimum 
operation sums ad(S).  In Figure 3a, the a(S) is 3 + 
3 = 6 and the ad(S) is 4 + 4 = 8.  In Figure 3b, the 
a(S) for this partition is 3 + 3 = 6, which is same as 
previous partition and cannot distinguish the 
difference between the two partitions.  The ad(S) 
for this partition is 3 + 3 = 6, which is smaller than 
the previous partition and indicates this is a better 
partition. 
To obtain optimal partition of a given dataset, 
Myerson [7] proposed a set-cover type greedy 
approach.  Let F be the collection of all subsets of 
D with cardinality in the range of [k, 2k-1].  Let S 
 F be a set in the collection.  The greedy 
approach selects the S with minimum diameter and 
includes it to the cover.  The process repeats itself 
until all records are included to the cover.  The 
cover is then converted to a partition to ensure each 
subset is disjoint from others. 
 
 
 a1 a2 a3 
T1 1 1 1 
T2 1 1 0 
T4 0 1 1 
T5 1 0 0 
  
 a1 a2 a3 
T1 1 1 1 
T2 1 1 0 
T3 1 0 1 
T4 0 1 1 
 a1 a2 a3 
T3 1 0 1 
T6 0 1 0 
T7 0 0 1 
T8 0 0 0 
 a1 a2 a3 
T5 1 0 0 
T6 0 1 0 
T7 0 0 1 
T8 0 0 0 
(a) Arbitrary partition (b) Optimal partition 
Figure 3  Two partitions of eight records 
For a set-valued dataset, we propose a similar 
set-covered greedy algorithm.  Instead of checking 
all subsets of D in the range of [k, 2k-1], we 
propose using the sets of transactions that contain 
frequent itemsets with support count greater than or 
equal to k to be included in the collection F.  The 
greedy approach then selects the S with minimum 
operation ad(S) and includes it to the cover. The 
proposed algorithm is given as follows. 
Algorithm (Set_Anonymize) 
Input: dataset D 
Output: anonymized database D’ that satisfies 
k-anonymity 
1. Find all frequent itemsets vi from D, let FIL = { vi };  
2. For each vi, find all subsets of transactions S(vi) 
containing vi and let F = {S(vi)}; 
3. Sort S(vi) in increasing order of ad(S(vi)); 
4. While (D   and F  ) { 
5.     Remove S(vi) with the smallest ad(S(vi)) from D and 
F; 
6.     Anonymize S(vi) and add to D’; 
7.     Update vi and S(vi);} 
8. Output D’; 
IV. NUMERICAL EXPERIMENT 
To evaluate the performance of the proposed 
algorithm, we run simulations on the 
BMS-WebView-1 dataset and compare with the 
suppression-based algorithm proposed by Park etc 
[9].  The BMS-WebView-1 dataset contains 
59,602 transactions, 497 items with maximum 
transaction length 267 and average length 2.5.  
There are five implementations in [9].  The fastest 
implementation is OPT-LB, which is not algorithm 
for the k-anonymity problem, but can show the 
lower bound on the number of suppressed cells for 
the optimal solution for the k-anonymity problem.  
As a preliminary test, frequent itemsets are used 
instead of closed frequent itemsets.  We call this 
implementation modified a(S) and our approach 
ad(S). 
All experiments reported in this section were 
performed on a Pentium-4 2.3 Ghz machine with 2 
GB main memory, running Microsoft Windows 
2000 operating system.  All the methods were 
implemented using Microsoft SQL Server 2000. 
Figure 4 shows the number of addition and 
deletion operations under different privacy 
threshold k.  The tested dataset size is 10,000 
records selected from the BMS-WebView-1 dataset. 
The number of items tested is 10, which are the 
top-10 frequent items.  It can be observed that the 
proposed algorithm required less number of 
addition and deletion operations than the previously 
proposed suppression-based approach.  Figure 5 
shows that both approaches require about the same 
amount of running time to achieve k-anonymity. 
 9 
 
會議(二) The 24th International Conference on Industrial, Engineering and Other Applications of 
Applied Intelligent Systems (IEA/AIE 2011) 
 
(一)參加會議經過 
 
2011年第24屆工業、工程、及其他應用之應用智慧系統國際研討會(The 24th International 
Conference on Industrial, Engineering and Other Applications of Applied Intelligent Systems) 是由
Syracuse University雪城大學所承辦之國際性學術研討會。其主辦單位是International Society of 
Applied Intelligence, 其協辦單位有Association for the Advancement of Artificial Intelligence 
(AAAI), Association for Computing Machinery (ACM/SIGART, SIGKDD), Austrian 
Association for Artificial Intelligence (OeGAI), British Computer Society Specialist Group on 
Artificial Intelligence (BCS_SGAI), European Neural Network Society (ENNS), International 
Neural Network Society (INNS), Japanese Society for Artificial Intelligence (JSAI), Slovenian 
Artificial Intelligence Society (SLAIS), Spanish Society for Artificial Intelligence (AEPIA), 
Swiss Group for Artificial Intelligence and Cognitive Science (SGAICO),Taiwanese 
Association for Artificial Intelligence (TAAI), Taiwanese Association for Consumer 
Electronics (TACE), Texas State University-San Marcos 及Springer。其會議之宗旨是希望提供
各國學者參與共同研討應用智慧系統相關在工業、工程等領域之研究，並在美國國內及世界各
地輪流舉辦研討會。一年在美國，一年在美國以外的國家舉辦，中華民國曾於2009年承辦過此
研討會，由台南大學與高雄大學共同舉辦，相當成功。 
 
2011年之會期是從6月28日至7月1日。2011年的研討會地點為美國紐約州之雪城大學
(Syracuse University)。IEA/AIE已舉辦過24次，雖然會議排名相當不錯，名列701個電腦科學相
關國際會議之46名，且此次會期有4天之長，但是大會只邀請了3個專題演講，3個帄行場次，論
文來源涵蓋十多個國家地區，約100篇左右論文作口頭報告，其中有相當多之作者未出席報告，
筆者受邀為場次主持人，就有一半之作者未出席報告。而且其中有半天的時間是到尼加拉瀑布
旅遊，並沒有安排議程。筆者此次發表之論文是國科會計畫之部分研究成果。本人除親自參加
各場座談會外，於會議期間並與各國學者交換意見與心得，收穫甚多。 
 
(二)與會心得 
 
 本會議的議程安排相當簡單。雖然有三天半的時間但因出席人數不多，因此每天雖只有3
個場次同時進行，主要之開幕式以及茶點時間，其人數亦寥寥可數，開幕式之人數只有六、七
十人，大會老主席 Moonis Ali 一直招呼參與者進場聆聽，並且一再強調會議之重要性及未來三
年之舉辦地點，呼籲大家投稿參加。另外有一個開幕式，一個接待式，一場晚宴，及一閉幕式。 
 
與其他國際性學術研討會相比較，個人列舉三點看法: 
 11 
 
A Heuristic Data-Sanitization Approach  
Based on TF-IDF 
Tzung-Pei Hong1,4, Chun-Wei Lin1,3, Kuo-Tung Yang
1
 and Shyue-Liang Wang2 
 
1Department of Computer Science and Information Engineering 
2Department of Information Management 
3General Education Center 
National University of Kaohsiung, Kaohsiung, Taiwan 
4Department of Computer Science and Engineering 
National Sun Yat-sen University, Kaohsiung, Taiwan  
{tphong, cwlin, kdyang, slwang}@nuk.edu.tw 
Abstract. Data mining technology can help extract useful knowledge from large data sets. The process of data collection 
and data dissemination may, however, result in an inherent risk of privacy threats. In this paper, the SIF-IDF algorithm is 
proposed to modify original databases in order to hide sensitive itemsets. It is a greedy approach based on the concept of 
the Term Frequency and Inverse Document Frequency (TF-IDF) borrowed from text mining. Experimental results also 
show the performance of the proposed approach. 
Keywords: Privacy preserving, data mining, data sanitization, TF-IDF. 
1   Introduction 
In recent years, the privacy-preserving data mining (PPDM) has become an important issue due to the quick proliferation of 
electronic data in governments, corporations and non-profit organizations. Verykios et al. [10] thus proposed a data 
sanitization process to hide sensitive knowledge by item addition or deletion. Zhu et al. [11] then discussed what kind of 
public information type was suitable for not revealing sensitive data and insinuated that the k-anonymity technique might 
still have security problems. 
In text mining, the technique of term frequency–inverse document frequency (TF-IDF) [9] is usually used to evaluate how 
relevant a word in a corpus is to a document. It may be thought of as a statistical measure. In this paper, a novel 
greedy-based approach called sensitive items frequency - inverse database frequency (SIF-IDF) algorithm is thus designed 
to modify the TF-IDF [9] approach. It evaluates the degrees of transactions associated with given sensitive itemsets, 
reducing the frequencies of sensitive itemsets for data sanitization. Based on the SIF-IDF algorithm, the user-specific 
sensitive itmesets can be completely hidden with reduced side effects. Experimental results are also used to evaluate the 
performance of the proposed approach. 
2   Review of Related Works 
In this section, we respectively review data mining process and general concept of data sanitization. 
2.1   Data Mining Process 
Data mining is most commonly used in attempts to induce association rules from transaction data, such that the presence of 
certain items in a transaction will imply the presence of some other items. To achieve this purpose, Agrawal et al. proposed 
several mining algorithms based on the concept of large itemsets to find association rules in transaction data [3-4]. In the 
first phase, candidate itemsets were generated and counted by scanning the transaction data. If the count of an itemset 
appearing in the transactions was larger than a pre-defined threshold value (called the minimum support), the itemset was 
considered a large itemset. Large itemsets containing only single items were then combined to form candidate itemsets 
containing two items. This process was repeated until all large itemset had been found. In the second phase, association rules 
were induced from the large itemsets found in the first phase. All possible association combinations for each large itemset 
were formed, and those with calculated confidence values larger than a predefined threshold (called the minimum 
confidence) were output as association rules. 
 13 
 
for each transaction as follows: 
 
 










n
i
p
k kki
ij
i
MRCf
n
T
si
TIDFSIF
1 1
log)( . 
STEP 4: Find the transaction (Tb) which has the best SIF-IDF value. 
STEP 5: Process the transaction Tb to prune appropriate items by the following substeps. 
Substep 5-1: Sort the items in a descending order of their occurrence frequencies within the sensitive itemsets. 
Substrp 5-2: Find the first sensitive item (itemo) in T according to the sorted order obtained in Substep 5-1. 
Substep 5-3: Delete the item (itemo) from the transaction. 
STEP 6: Update the occurrence frequencies of the sensitive itemsets. 
STEP 7: Repeat STEPS 2 to 6 until the set of sensitive itemsets is null, which indicates that the supports of all the sensitive 
itemsets are below the user-specific minimum support threshold s. 
4   An Example 
In this section, an example is given to demonstrate the proposed sensitive items frequency - inverse database frequency 
(SIF-IDF) algorithm for privacy preserving data mining (PPDM). Assume a database shown in Table 1 is used as the 
example. It consists of 10 transactions and 9 items, denoted a to i.  
Table 1.  A database example with 10 transactions. 
TID Item 
1 a, b, c, d, f, g, h 
2 a, b, d, e 
3 b, c, d, f, g, h 
4 a, b, c, f, h 
5 c, d, e, g, i 
6 a, c, f, i 
7 b, c, d, e, f, g 
8 c, d, f, h, i 
9 a, d, e, f, i 
10 a, c, e, f, h 
Assume the set of user-specific sensitive itemsets S is {cfh, af, c}. Also assume the user-specific minimum support 
threshold is set at 40%, which indicates that the minimum count is 0.4*10, which is 4. The proposed approach proceeds as 
follows to hide the sensitive Itemsets for avoiding being mined from the database.   
STEPs 1 & 2: The transactions with sensitive itemsets in the database are found and kept. The sensitive items frequency 
(SIF) value of each sensitive itemset in each transaction is calculated. The results are shown in Table 2. 
Table 2.  The SIF values of each sensitive itemset in each transaction. 
TID Item SIFcfh SIFaf SIFc 
1 a, b, c, d, f, g, h 3/7 2/7 1/7 
2 a, b, d, e 0/4 1/4 0/4 
3 b, c, d, f, g, h 3/6 1/6 1/6 
4 a, b, c, f, h 3/5 2/5 1/5 
5 c, d, e, g, i 1/5 0/5 1/5 
6 a, c, f, i 2/4 2/4 1/4 
7 b, c, d, e, f, g 2/6 1/6 1/6 
8 c, d, f, h, i 3/5 1/5 1/5 
9 a, d, e, f, i 1/5 1/5 0/5 
10 a, c, e, f, h 3/5 2/5 1/5 
 
STEP 3: The inverse database frequency (IDF) value of each sensitive itemset in each transaction is calculated. In this 
step, the reduced count (RC) of each item for each sensitive itemset is first calculated and the maximum of the RC values of 
each item is found as the MRC value. The IDF value of each item is then calculated. The MRC and IDF values of all items 
are shown in Table 3. 
 15 
 
SIF-IDF algorithm, the relationships between the numbers of iterations and the EC values are compared to indicate the 
proposed algorithm could completely hide all user-specific sensitive itemsets. The results for BMSPOS and WebView_1 are 
shown in Figures 1 and 2, respectively.  
 
 
Fig. 1. The relationships between the EC value and the number of iterations in the BMSPOS database. 
 
Fig. 2. The relationships between the EC values and he number of iterations in the Webview_1 database. 
From Figure 1, it can be seen that the sensitive itmesets S3 and S4 were alternatively processed to be hidden. From Figure 
2, the sensitive itemsets S4, S3, S2 and S1 are sequentially processed to be hidden. The execution time to hide the four 
sensitive itemsets for two databases was also compared and shown in Figure 3. Note that the WebView_1 database required 
more execution time to hide the sensitive itemsets than the BMSPOS dataset. 
 
 
Fig. 3. The execution time to hide the four sensitive itemsets in the two databases. 
6   Conclusion 
In this paper, the SIF-IDF algorithm is proposed to evaluate the similarity between sensitive itemsets and transactions for 
minimizing the side effects, which inherits the properties from TF-IDF algorithm in information retrieval. Based on the 
user-specific sensitive itemsets in the experiments, the proposed SIF-IDF algorithm can process all defined sensitive 
國科會補助計畫衍生研發成果推廣資料表
日期:2011/10/22
國科會補助計畫
計畫名稱: 集合值資料庫上非一般化方式之隱匿方法之研究
計畫主持人: 王學亮
計畫編號: 99-2221-E-390-033- 學門領域: 資料庫系統及資料工程
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
