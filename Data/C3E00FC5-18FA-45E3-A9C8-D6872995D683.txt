areas. It can also help advance other data processing and analysis techniques, which will further 
the promotion of our information technology (IT) industry. 
 
Keywords: Data mining, Knowledge discovery, Decision support system, Association rule. 
 
三、前言 
近年來網路的普及和資訊科技的快速進步，使得資料產生的數量和累積的速度與日遽
增，然而隨著資料量的增加，它的價值與數量的比值可能是逐漸減少的。因此要如何才
能有效且快速的從資料中取得更有價值的資訊，成為作業上或決策上可用的參考，是一
個很重要的課題與挑戰。近年來有關資料庫的知識探索(Knowledge Discovery in Databases, 
KDD)就成為熱門發展的領域，尤其是運用資料挖掘(Data Mining)或探勘的技巧，可從大
量資料中發覺出潛在而有用的型樣(Patterns)或規則(Rules)等知識來提供各項作業或決策
之用。 
我們在以前的計畫中，已成功的研究和發展出各種有效的資料挖掘方法，如資料倉儲
的建置，關聯法則的挖掘，分類法，組群化，序列型樣，路徑行走型樣等初步的成果。
然而我們發現在面臨資料量變大、資料維度增加、資料屬性變複雜的情況下，資料挖掘
的演算法通常也會變的更複雜，比如說有些會透過前處理的方式來減低後續資料分析的
複雜度，有些則可能在處理資料時加了很多限制參數來控制演算法的效率，甚至也有用
平行處理的方式來加速運算。然而隨著演算法的複雜化，一般使用者如果對處理資料的
技術不瞭解，是很難有效的去設定這些參數或選擇有效的前處理法來達到演算法預期的
效果，如此一來將可能會導致處理時間變長、處理效率變差，更會造成產生的結果不是
使用者所感興趣的，甚至產生出來的結果是無意義的。更嚴重的是若是使用者本身對資
料不瞭解，其對資料處理產生的結果沒有一定的鑑別力的話，拿這些粗略結果來用時，
輕則可能導致效果不彰，重則可能造成嚴重的錯誤。 
所以當我們在做資料處理的時候，知識庫的建立與智慧型的決策機制的開發是相當重
要的。另外隨著資料的複雜化，單一演算法在處理不同性質的資料集(dataset)時，其成效
可能不會總是最好的，因此如何協助不同使用者挑選最適合其資料集的方法及依照其需
要設定相關參數將是本研究計畫的一個重點。而在所有的資料挖掘技術中，關連法則演
算法的發展可說已經有一段時間了，現階段所開發的演算法大多包含相當多複雜的機
制，所需設定的參數也比其他資料挖掘演算法來的多且敏感，因此由我們過去的成果顯
示，如何解決前述的問題實有深入探討解決的必要，特別是在關連法則的演算法方面還
有很多可改進的地方。 
 
四、研究目的 
因此本研究計畫之目的即在於協助使用者選擇最適合其資料性質的資料挖掘演算法
及依照其不同的需要去調整參數的設定，我們先針對關連法則演算法來探索知識挖掘流
程的最佳化，因為關連法則是目前應用最廣泛的一項資料挖掘技術，若能有效解決上述
的問題將能帶來莫大的利益，以後可以延伸至其它的資料挖掘方法上。本計畫第一階段
著重在研究與發展各種適合不同資料特性的關連法則演算法。本期第二階段著重於將前
一階段所開發的技術整合以及建立一資料挖掘網站，並且加入智慧型的決策機制，讓系
統可以在使用者不需瞭解演算法細節的情況下，幫助使用者選取最適當的演算法和參數
 2
在過程中不需要產生候選物項集合，並在一次的掃描資料庫即能產生高頻物項
集合。下圖(1)所示為產生高頻物項集合的概念，交易資料由物項個數最長的先
進行處理，例如：{ABCD}，{CDE}，{DF}，依物項個數大小先後處理，讀入
的交易資料內容有交易物項集合及交易發生次數，依交易次數判斷是否為高頻
物項集合，再依結果放入高頻緩衝區或非高頻緩衝區，{ABCD}的交易發生次
數小於支持度，放入非高頻緩衝區，再次讀入交易資料{CDE}，再做上述判斷，
若是非高頻物項集合再做物項個數判斷，{CDE}的物項個數小於非高頻緩衝區
的{ABCD}物項個數，需先對非高頻緩衝區的物項集合做分解子物項集合處
理，{ABCD} 做分解子集合{ABC}，{BCD}，{ACD}，{ABD}，後{CDE}再判
斷是否有相同之物項集合，非高頻緩衝區中沒有{CDE}，{CDE}再依交易次數
判斷是否為高頻物項集合，{CDE}的交易發生次數大於支持度，放入高頻緩衝
區，再繼續讀入交易資料{DF}，依前述程序處理，最後在高頻緩衝區中皆為高
頻物項集合。我們將開發一演算法跳脫 Apriori 演算法的架構，以新的思維重新
建構邏輯架構來挖掘資料，以改善原缺失，減少主記憶體的浪費，避免重覆做
I/O 處理，使執行有非常好的效率並讓執行的時間不因支持度的變化，差異過
大造成執行的時間無法掌握。 
 
圖(1)產生高頻物項集合的概念 
 
圖(2)顯示 STD演算法之特性，及與其他演算法之比較結果。 
 4
 (e)支持度提高時的變化對 STD 演算法的影響 
圖(2) STD演算法與其他演算法之比較結果 
 
2) 另外，針對大型資料庫，多數的演算法可能會無法得到預期的處理成效，面對
這樣的問題我們發展出Merging演算法[12]，先將資料作前處理去合併資料庫中
的項目集，並在這合併的項目集中挖掘關連式法則，如此的作法最後只需再掃
瞄原始資料庫一次，因此可減少了大部分磁碟輸出與輸入的負載。而當資料庫
有新增或刪除的時候，我們只需對合併的項目集進行分析，最壞情況下也只需
重新掃瞄原始資料庫一次，因此這種方式特別適合用在大型的資料庫中，尤其
是用在資料更新時對於挖掘關連式法則的處理。下圖(3)為一種資料合併方法，
我們首先將資料庫作排序，然後假設我們希望資料合併後剩 5 筆紀錄，因此將
每 4 筆紀錄合併成一筆紀錄，而最後可得新的項目集資料庫。透過控制此合併
的項目集存放於記憶體中，只需稍加修改任何己有的關連法則演算法即可用來
挖掘此合併的項目集。 
    當我們在用既有的一些關連法則演算法挖掘合併的資料集時，只需針對計
算項目出現個數的部分稍加修改即可。比如說我們要算項目集{A,G}在合併的交
易{A4,D1,F3,G2,H1,J2}的出現頻率時，我們只需取其個別出現次數的最小值即
可，以此例而言{A,G}的出現頻率就是 2。我們可以使用既有的關連法則演算法
來從合併後的資料集中找出高頻項目組來，而這些從合併後資料集所找出的高
頻項目組，會是真正高頻項目組的一個超集合，因此我們不會漏掉任何一個真
正的高頻項目組，我們只需花一次搜尋原始資料庫的時間，計算出由合併資料
集中所找出的高頻項目組在原始資料庫中真正出現的頻率即可去定哪些項目組
是真正的高頻項目組。 
 
 6
0
10
20
30
40
50
60
1M 2.5M 5M 7.5M 10M
Number of transactions
Re
lat
ive
 T
im
e (
sec
)
Merging, 0.25%
Merging, 0.75%
Merging, 2%
 
(c) 交易筆數的變化對Merging演算法的影響 
圖(4) Merging演算法與其他演算法之比較結果 
 
3) 根據過去的關連法則演算法，我們發現在資料庫的搜尋方面仍然有許多可改進
的地方。尤其是當最大高頻項目組（maximum frequent itemsets）長度太長(12 項
以上時)，使得某些演算法花費太多時間做資料庫搜尋，例如 Apriori 之類的演
算法。另外一些像 Pincer-Search 演算法的執行效率很好，可是當最大高頻項目
組長度為資料庫中最長項目組長度的一半時，這些演算法的執行效率就會變的
非常差。因此我們結合 Close演算法與 Pincer-Search 演算法的概念，利用了上
下搜尋以及 closure的概念來快速搜尋最大高頻項目組，稱為 CMFI演算法[14]，
不僅適合最大高頻項目組長度較長的時候(12 項以上)，也適合於當最大高頻項
目組的長度為短的時候(6-8)。尤其是在資料庫中當最大高頻項目組的長度為中
(8-12)或是長的(12以上)，此方法的執行效率與其它演算法(Pincer-Search、Close)
比較起來顯得非常好。在許多資料庫裡，最長項目組通常不是高頻項目組。所
以當我們使用某些只適合在資料庫中最大高頻項目組的長度較長的演算法，這
些演算法的執行效率在面對最大高頻項目組的長度是中或短的會變得非常差。
另一方面，當我們使用某些只適合在資料庫中最大高頻項目組的長度是短的演
算法，這些演算法的執行效率在面對最大高頻項目組的長度是中或長的也會變
得非常差，而此演算法能夠適當的解決這些問題，其概念如下圖(5)所示。 
          
       圖(5) 長項目集關連法則挖掘概念圖 
 
 8
T20I12
0
200000
400000
600000
800000
1000000
100K 200K 300K 500K
transactions
Ti
me
(se
c)
CMFI
Pincer-Search
 
(d) 交易筆數的變化對 CMFI及 Pincer-Search演算法的影響 
圖(6) CMFI演算法及與其他演算法之比較結果 
 
本期計畫第二階段著重於將前一階段所開發的技術整合以及建立一資料挖掘網站，
並且加入智慧型的決策機制，讓系統可以在使用者不需瞭解演算法細節的情況下，幫助
使用者選取最適當的演算法，並且協助其解決參數設定的一些問題，如支持度跟可靠度
的設定，讓使用者找出其最感興趣的規則來。以下就本階段的幾個重要環節說明我們所
採行的方法與結果。 
本資料挖掘網站系統之架構圖如圖(7)所示，共有七個階層，涵蓋三個維度。圖(8)為
每一階層的剖面圖。 
 
 
Communication   Layer 
UDDI 
Web service
WSDL 
Http 
TCP/IP 
 
Data           Layer 
Database
Unstruc- 
tured Data
XML File
 
Support         Layer 
XML 
PMML 
OLE DB
KQML 
 
Mining          Layer 
Data Agents
Mining 
Agents
Evaluation 
Agents
Visualiza- 
tion Agents
AR 
Agents
Clustering 
Agents
Feedback 
Agents
 
Knowledge      Layer 
Ontology
Knowledge 
Base
Meta    
Data
Task Log
 
Driven         Layer 
Monitor 
Agent
Inference 
Agent
Interface 
Engine
 
Applicati n      Layer 
Market 
Basket
Medical 
Service
Bio- 
Informatics
Medical 
Treatment
Medical 
Image
System 
Components 
Component 
Abstraction 
System 
Layers 
 
圖(7)系統之架構圖 
 
 
 10
 提供 Filter的機制 
(6). u
gent及 Evaluation Anent 傳來的資料，並以視覺化的方式呈
 oom out，Distortion 等 
 
(9)、(10)為系統的工作概念流程圖。 
 
Vis alization Agent 
 接受Mining A
現。如長條圖，直方圖，圓餅圖，AR Graph等 
提供與使用者 Interaction的機制，如 Zoom in，Z
圖
 
 
圖(9)系統工作概念流程圖 
Interface 
Agent 
Application 
Facilitator
Market 
Basket
Medical 
Service
Bio- 
Informatics
Medical 
Treatment
Medical 
Image
Feedback 
Agent 
Mining 
Facilitator
Data Agent Mining Agent
Evaluation 
Agent 
Visualization 
Agent
XML 
Dispatcher
Data 
Warehouse
Association 
Rule 
Clustering 
Apriori 
STD 
K-means 
Monitor 
Engine 
Knowledge 
Facilitator 
Merging 
CMFI 
Inference 
Agent 
Knowledge 
Base 
Knowledge 
Base Meta Data 
Ontology Task Log 
 12
 
圖(11)為系統的 use case diagram；圖(12)，及圖(13)為相對應的 class diagram及
sequential diagram。 
 
 
圖(11)系統的 use case diagram 
 
 
 
 
 
圖(12)系統的 class diagram 
 
 14
我們建立了一個資料挖掘的網站，透過瀏覽器的介面以提供服務，並針對不同的使
用者提供各種不同的個人化服務，依據不同領域的需求對知識探索的程序做最佳化安
排。我們首先設定幾個不同的使用者領域來規劃實驗我們的智慧化參數設定機制，比如
說以一般的超商資料而言，因為寸土寸金，使用者所感興趣的可能是高支持度跟高可信
度的規則；而以生物資訊的資料而言，因為資料量太多，使用者所感興趣的可能只是高
可信度的規則；而以醫療資料而言，因為要服務大眾，使用者所感興趣的可能只是高支
持度的規則。我們透過主動式的分群，由使用者先設定其資料是屬於何種應用
(Application)，再由被動式分群法，分析過去歷史資料挖掘中接近的資料型態格式或是使
用者屬性以找出適合的參數設定或演算法來建議給使用者。我們提供機制讓使用者能主
動的回饋對每一次設定的滿意值，並被動的監督使用者每一次設定的變化，透過時間序
列及關連法則來分析設定，找出有意義的規則，並建議給其他類似的分析使用。舉例來
說，在生物資訊領域時，如果我們發現大多數的使用者在資料的項目數在 200~400之間，
交易記錄數量在 3000以下時，當他第一次 support設定為 5%~10%時，他可能會對出來的
結果不太滿意，並且會將 support 設成 1%。因此當其他使用者有類似情況時，在其還沒
進行資料挖掘時，我們系統就可以直接建議他 support 設成 1%。又或在醫療領域下，我
們發現可能大多數的使用者在當結果的規則數在 10 條以下時，他會調低 Support 10%，
並調低 Confidence 5%，而在其他領域下則沒有此現象，因此當下次使用者(可能是其他人)
在進行資料挖掘時，若有發生此現象，則我們系統就可以建議他進行類似的參數調整，
並持續進行後續的分析。 
我們開發工具使用的是 Sun JDK Java 2 Standard Edition 1.5.0_06 with netBean 5.0 
IDE，並搭配 Apache Tomcat 5.5.9為網頁伺服器，以及MySQL 4.1.12a-nt 作為後端的資
料庫，我們系統平台是建立在Microsoft Wondows Server 2003 Standard Edition with Service 
Pack 1下，圖(14)是本資料挖掘系統網站的首頁，其中 AIWS為本計畫名稱的縮寫，點選
AIWS後即可進入本計畫成果的網頁，其畫面如圖(15)所示。 
 
 
圖(14) 本資料挖掘系統網站首頁畫面 
 
 16
 
圖(17) 資料上傳後部分的資料與統計分析畫面 
 
 
 
圖(18) 部分資料挖掘結果畫面 
 
 18
