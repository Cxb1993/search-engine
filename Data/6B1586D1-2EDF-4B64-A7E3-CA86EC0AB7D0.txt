研發語意服務合成技術 (Semantic Service Synthesis) 
 
PI: Chen-Yu (Phillip) Sheu, 許承瑜  
Currently, on-line queries of bioinformatics databases and tools consist of keyword-based queries that 
tend to be extremely limiting and result in users having to spend valuable time filtering out irrelevant 
results. Additionally many of the existing bioinformatics tools are highly heterogeneous with different 
input and out formats, data models and document structures resulting in users having to partition their jobs 
manually into several tasks and do them separately. This often causes bioinformatics tools to be 
incompatible, making it difficult for a user to design a correct workflow. 
 
This research hunts for biomedical database/web server supported by a semantic description langrage. The 
achievement of this project comprises of object relational programming and Biofactory  (Semantic 
Integration of Biomedical Data and Applications), which are briefly described as follows. 
 
RELATED PUBLICATION 
1. Charles C.N. Wang, Ka-Lok Ng, Yu-Ching Chen, Phillip C.Y. Sheu, Jeffrey J.P. Tsai, “Simulation of 
Bacterial Chemotaxis by the Random Run and Tumble Model”, The 11th International Conference on 
Bioinformatics & Bioengineering (BIBE 2011), Taichung, Taiwan, Oct. 24-26, 2011. [EI] 
2. David A. Hecht, Charles C.N. Wang, Rouh-Mei Hu, Jeffrey J.P. Tsai, “Molecular Modeling Studies 
of AmpR Mediated AmpC β-Lactamase Repression”, The 11th International Conference on 
Bioinformatics & Bioengineering (BIBE 2011), Taichung, Taiwan, Oct. 24-26, 2011. [EI] 
3. Han C. W. Hsiao, Rouh-Mei Hu, Wei-Liang Tai, Rong-Ming Chen, and Jeffrey J.P. Tsai, “Object 
Relational Programming of Biomedical Images,” The 11th International Conference on 
Bioinformatics & Bioengineering (BIBE 2011), Taichung, Taiwan, Oct. 24-26, 2011. [EI] 
4. Charles C.N. Wang, David Hecht, Jeffrey J.P. Tsai, “BioFactory – Semantic Integration of 
Biomedical Data and Applications,” 2011, (in preparation)  
 
 
 
RESULTS 
 
Object Relational Programming of Biomedical Images 
 
INTRODUCTION 
Biomedical imaging is an important tool for preclinical diagnosis, medical research and biological studies. 
Several modalities acquire biological images in the levels of whole-body, organ, tissue, cellular, or 
molecular, which provide information to help physicians, medical laboratory scientist and biologists to 
make better diagnosis and more accurate surgical treatment, as well as to get or analyze data for their 
researches. 
 
In general, radiography, ultrasonography, thermography, and magnetic resonance imaging (MRI) are 
important types of medical images in the whole-body or organ levels. Many different types of microscope 
systems and staining/labeling methods have been developed to capture histological section images or to 
identify a specific protein within a tissue or cell. Electrophoresis and blotting methods reveal the 
distribution pattern of macromolecules isolated from a living organism or cultivated tissues/cells, and create 
images for identification, purification, quantification, and comparison. 
 
Microscopic images are usually used in clinical diagnosis and biomedical researches. A pathologist may 
scrutinize the histological image of a biopsy segregated from a suspected cancer patient to identify the 
cancerous tissues, or may also observe the biopsy from the brain of a patient suffering from Alzheimer’s 
disease to characterize the extracellular protein aggregation, amyloid. Since most of the biological tissues 
are colorless, Hemalum and Eosin Y (H&E) stain is a generally-used coloring technique in histology. 
Hemalum binds to the highly basic components and stains nuclei of cell blue. Eosin Y stains other 
eosinophilic regions like cytoplasm into colors ranging from light pink to dark red. An amyloid aggregate 
in the brain tissue of an Alzheimer's patient can be observed as an eosinophilic mass on H&E. 
 
Immunohistochemistry or IHC is an advanced analysis process to detect a target protein on a histological 
slide using highly specific antibodies raised against this target protein. An enzyme-conjugated second 
 
• An expression is “type bound” if all elements of the expression have the same non-primitive type. 
• An expression is “structure type bound” if each element of the expression is a sequence of objects, 
the number of objects in each sequence is the same, and the objects in the same position belong to 
the same type (i.e., for any two elements <x1, x2,…, xn> and <y1, y2,…, yn> the types of xi and yi are 
the same.) Also some meaningful functions may be defined on each element. 
• Otherwise it is “type free”. A type free expression may be a relation such as a flat file or a set of 
records whose fields are primitive values such as integers, floating point numbers and text strings. 
 
Following is a brief summary of the operators: 
1. Select: The operator σP(E) returns as result objects in E that satisfy P. 
2. Project: The operator ΠS(E) removes those objects of E that do not satisfy the attributes specified in S 
from each object of E, and returns as result the other objects of E that satisfy the attributes specified in 
S. 
3. Function: If f is a function that returns an expression as its result, and each of its arguments is an 
object or an expression, then f(arguments) is an expression. Whether f(arguments) is type free, type 
bound or structure type bounded is determined by the semantics of f. Some special cases are: 
• Cartesian Product: If E and F are expressions then E×F is an expression. The operator (Cartesian 
Product) computes the set {(x, y) | x ∈ E, y ∈ F} which is either structure type bound (if both E and 
F are type bound or structure type bound) or type free (if both E and F are type free). 
• Union: If E and F are expressions then E ∪ F is an expression. The operator (Union) computes the 
union of the two expressions. The Union operator preserves the structure classification. 
• Difference: If E and F are expressions then E - F is an expression. The operator (Difference) 
computes the difference between the two expressions. The Difference operator preserves the 
structure classification. 
 
Considering an image to be a set of pixels, following is a list of functions that can be applied to images: 
- color-deconvolute(A, Color) that takes an image object A, a color parameter Color, and returns one 
image object resulted from staining A with color Color 
- cell-extract(A) that takes an image object A and returns another image object resulted from 
separating nuclei from background 
- cancer-cell-extract(CEA) that takes an image object CEA and returns another image object CCA 
- normal-cell-extract(CEA) that takes an image object CEA and returns another image object NCA 
- intensity(CDBrown, CCA) that takes two image objects CDBrown and CCA and returns a numeric 
set IAC 
- compare(IAC, IAN) that takes two numeric sets IAC and IAN, compares the two sets, and returns 
the result of comparison 
4. Aggregation: If E is a type bound expression then SGfA(E) is a structure type bound expression. The 
operator G (called the “Aggregate” operator) groups the objects of E according to the set of 
attributes specified in S (in the form: attribute, attribute, ….), and for each group applying the 
aggregation function f to the set of objects corresponding to attribute A to obtain a value, a set of 
values, an object or a set of objects. The possible aggregate functions include primitive functions 
such as min, max, mean, variance, avg, sum, count that can be applied to a group of primitive values. 
The aggregate functions can also include functions defined by users to a group of non-primitive 
objects. For example, a user can define a best image function to process a collection of visual image 
files and return as output one or more visual image files with the best signal-to-noise ratio. 
 
BASIC FUNCTIONS FOR IHC IMAGE ANALYSIS 
We have implemented an automated procedure based on image morphology for diagnosis of cancerous 
tissue in IHC images. Different image processing algorithms are utilized to extract cell compartments and 
fluorescence intensities in individual cells. For simplicity, it is assumed that the pixel intensity is linearly 
related to the amount of proteins, and therefore the average intensity within a cell can be interpreted as a 
relative protein concentration. To improve the subjectivity and long time-consumption of manual analysis, 
the technique does not require any manual intervention by the operator. 
 
The images considered in this paper are characterized by blue stain (Haematoxylin and Eosin, H&E) for 
highlighting the tissue structure, which represents the background. Brown stain (Diaminobenzidine, DAB) 
shows protein activity. Note that accurate tracking of nuclear membranes is fundamental in IHC analysis. 
Nuclear segmentation is in general the first step for segmentation and quantification of protein activity of 
the other cellular compartments. Thus, a lack of accuracy of this step may alter the result of IHC analysis in 
 
(c) 
Figure 1.  Separation of blue (b) and brown stain (c) as obtained through color deconvolution of original 
image (a). 
 
(a) 
 
(b) 
Figure 2.  The result of cell extraction (b) by local adaptive thresholding from the blus stain image (a). 
C. Cancer Region Identification 
To identify cancerous and normal regions, a classifier is applied employed to categorize tissue images into 
lesion and non-lesion classes. Feature extraction and selection are two key steps in cancer detection and 
classification, and texture feature is extracted to distinguish these two classes. Intensity level difference 
defined in (2) is applied to distinguish pixels inside cancerous region from those that surround cancerous 
region, i.e. 
 
 ( ) ( )∑
−
=
−=
1
0
1 N
x
xi iWN
iIV  (2) 
where Vi is local variance of pixel i, I(i) is intensity of pixel i, and Wx(i) is intensity of N nearest neighbors 
Input: one IHC Image 
Output: IHC image labeled with the cancerous and normal 
regions 
 
1. RF = color-deconvolute(A, ‘White’)  //Identify the non-stained region from IHC image A as region fat 
(RF) 
2. BlueA = color-deconvolute(A, ‘Blue’) 
3. BrownA = color-deconvolute(A, ‘Brown’) 
4. CEA = cell-extract(A) 
5. RC = identify-cancer-region(difference(CEA, RF))  //Identify region from CEA-RF as cancerous 
region (RC) 
6. RN = identify-normal-region(difference(CEA, RF))  //Identify region from CEA-RF as normal region 
(RN) 
7. C = super-impose(A, RC, RN)  //Define IHC image labeled with RC and RN as image C 
 
Question 2 
Is the target protein over-expressed or under-expressed in the cancerous tissue? 
Input: one IHC Image 
Output: over-expressed or under-expressed 
 
1. RF = color-deconvolute(A, ‘White’)  //Identify the non-stained region from IHC image A as region fat 
(RF) 
2. BlueA = color-deconvolute(A, ‘Blue’) 
3. BrownA = color-deconvolute(A, ‘Brown’) 
4. CEA = cell-extract(A) 
5. RC = identify-cancer-region(difference(CEA, RF))  //Identify region from CEA-RF as cancerous 
region (RC) 
6. RN = identify-normal-region(difference(CEA, RF))  //Identify region from CEA-RF as normal region 
(RN) 
7. IAC =intensity(BrownA, RC)  //Quantify the brown stain intensity on RC, define the value as IAC 
8. IAN =intensity(BrownA, RN)  //Quantify the brown stain intensity on RN, define the value as IAN 
9. O = compare(IAC, IAN)  //Compare IAC with IAN, define O as the result of over-expressed if IAC > 
IAN, or under-expressed if IAC < IAN 
Question 3 
Compare two IHC images. Which one has a higher expression level of the target protein? 
Input: Images A and B 
Output: A or B? 
 
1. BrownA = color-deconvolute(A, ‘Brown’) 
2. BrownB = color-deconvolute(B, ‘Brown’) 
3. EA =intensity(BrownA, A)  //Quantify the brown stain intensity on A, define the value as EA 
4. EB =intensity(BrownB, B)  //Quantify the brown stain intensity on B, define the value as EA 
5. O = compare(EA, EB)  //Compare EA with EB, define O as the result of higher expression level if EA 
> EB, or lower expression level if EA < EB 
Question 4 
Select patients who over-expressed the target protein and are HBV positive. 
Input: a set of IHC images A1, A2, … An and medical 
record 
Output: Patient ID(s) 
 
1. SIHC = set(A1, A2, … An) 
2. SRF = color-deconvolute(SIHC, ‘White’)  //Identify the non-stained region from IHC image set SIHC as 
region fat set SRF = {RF1, RF2, …, RFn} 
3. SBlue = color-deconvolute(SIHC, ‘Blue’) 
4. SBrown = color-deconvolute(SIHC, ‘Brown’) 
5. SCEA = cell-extract(SIHC, ‘Blue’) 
6. SRC = identify-cancer-region(difference(SCEA, SRF))  //Identify region from SCEA-SRF as cancerous 
region (SRC) 
7. SRN =identify-normal-region(difference(SCEA, SRF))  //Identify region from SCEA-SRF as normal region 
industry-standard technologies defined by the Web Service Interoperability organization and to provide 
tools that help developers move towards adopting these, while at the same time recognizing that a wide 
variety of other approaches exist for pragmatic or historical reasons. The registry therefore allows all 
manner of services to be added, and aims to provide documentation and support for users wishing to bring 
their services in line with standard practices. The registry thus supports WSDL/SOAP, REST and DAS 
service types, with the dual intention of lowering the barriers to adoption and actively encouraging best 
practice. The WSDL is an XML format for describing network services as a set of endpoints operating on 
messages containing either document-oriented or procedure-oriented information [8]. However, few 
studies have been done on Semantic computing. Semantic computing and in particular semantic capability 
description language (SCDL)[9] seem ideally suited to help streamline these processes by providing a 
common language and a generic format for problem formalization. 
 
In this paper, we present a Semantic Description Language (SDL) for biomedical service registery and 
search. Applications of SDL to several core processes in the biological and biomedical web service 
registry and search are presented and discussed. This paper is organized as follows. In Section2, In 
Section3 …and Section4…., discretion the SDL for web service register and web service search 
 
THE BIOFACTORY REGISTRY 
 
The BioFactory is a collection of bioinformatics web service. The ultimate goal of the BioFactory is to 
provide an integrated framework for prospective users to facilitate use of bioinformatics tools and/or 
databases, as illustrated in Figure1. Users are able to search the registry for bioinformatics services using 
SCDL and keywords. This will assist a user in finding a web service client that facilitates the use of aweb 
page client to service. The user can register the bioinformatics service using SCDL and WSDL/SOAP. 
The BioFactory will periodically monitor the status and behavior of the share service (WSDL/SOAP and 
SCDL).  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Service and database framework of the BioFactory 
 
1. NLP Uesr Infteface, that provides user with a friendly query interface through which user can pose 
query in Structured /Natural Language(SNL) 
2. VIO Natural Language Process, the translates an SNL query. 
3. SDL the matches SDL (Semantic Description Language)  to web service, SDL is a declarative 
language used by the Biofactory to describe the web service registry and web service search. 
 
Sample SDL for this class of web service registry is presented below: 
 
Example1 
Sentence :: Search best-best neighbor of the #genes with offset and limit in all #organisms. 
WS ::Sequence Similarity Database (SSDB by KEGG)  
WSF ::get_best_best_neighbors_by_gene (string:genes_id, int:offset ,int:limit) 
WSD ::form KEGG find best neighbors for (with)#geneid with #offset and #limit 
Location ::http://soap.genome.jp/KEGG.wsdl 
 
SNL User Interface 
VIO Algorithm 
Web service, tools… 
SDL 
國科會補助專題研究計畫項下赴國外(或大陸地區)出差或研習心得報告	 
	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 日期：	 99	 年	 7	 月	 25	 日	 
	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 
一、參加會議經過	 
	 
計畫編號	 NSC	 96－2221－E－468－007－MY3	 
計畫名稱	 生醫分析系統之語意計算介面	 
出國人員
姓名	 
王昭能	 
服務機
構及職
稱	 
亞洲大學	 
兼任助理	 
會議時間	 
99 年 7 月 26 日	 
至	 
99 年 7 月 31 日	 
會議地
點	 
美國	 柏克萊	 
會議名稱	 
(中文)	 IEEE	 2010	 Summer	 School	 on	 Semantic	 Computing	 
(英文)	 IEEE	 2010	 Summer	 School	 on	 Semantic	 Computing	 
國科會補助計畫衍生研發成果推廣資料表
日期:2011/10/20
國科會補助計畫
計畫名稱: 研發語意服務合成技術
計畫主持人: 許承瑜
計畫編號: 99-2221-E-468-007- 學門領域: 生物資訊
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
