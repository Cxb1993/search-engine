行政院國家科學委員會專題研究計畫期末報告 
感測網路分散式救援機器人研發－子計劃三：結合感測網
路與分散式機器人之研究 (3/3) 
計劃編號：NSC 97-2218-E-009-007 
執行期限：98/08/01~99/7/31 
主 持 人：徐保羅 國立交通大學電機與控制工程系 
 
摘要 
多機器人的應用範疇隨著時間越來越廣泛，特別是強調合作部份，不同的場合有
不一樣的合作模式和應用，以救援機器人來講，融合分散式概念於機器人系統上將可
以提升救援效率，本報告架構首先說明 ZigBee 無線定位來得到各機器人的位置資訊，
接著目標物位置資訊則透過分散式機器人上影像資訊融合的方式來精確估算，提出一
個行為模式架構和合作策略法則來完成分散式救援機器人的合作搜尋任務，最後透過
實驗來驗證本研究所提出的方法可行性。 
串結式機器人由於多自由度運動，以及易重組的特性，具備優越的克服複雜地形
能力。本研究建構了實體的串結式機器人，為了在有限的機構空間上實現電路架構，
無感測的技術便是此研究的特色。在克服蜿蜒隧道地形時，藉由多維度訊號映射所建
立之分類模型觀測履帶馬達之異常速度與扭矩，取代距離與碰撞偵測器的使用，最後
由實驗通過蜿蜒隧道印證此法之可行性。 
最後，探討自閉症孩童的模仿能力，利用結合非視覺式感測器來實現自閉症孩童與
人形機器人的互動，將先說明系統架構，也利用 ZigBee 達到無線化的效果，增加活動
性，由於三軸加速度計天生準確度缺乏，故利用演算法與三角函數作為改善。 
 
關鍵詞：合作, 定位, 救援機器人, 多重視覺, 多重訊號對應 
 
Abstract 
Multi-robot applications have been widely developed recently with a cooperative 
method adaptive to critical environments. For applications of the rescue robot, the distributed 
wireless sensor network is developed in this study and its position is determined by applying 
the Zigbee wireless localization. Then, with fusion on multiple visions, the target position can 
be thus estimated accurately. The present chain-type robots present the feature of multi-DOF 
with excellent capability of conquering the complex terrain. In order to realize the circuit 
礙物、攀爬階梯與鑽過牆上的洞等任務。Hutchison et al.[12]利用基因演算法與神經網
路，賦予串結式機器人自主學習能力，能夠克服踏板上有石頭的階梯地形。這兩篇論
文皆外加大量感測器(力感測器、距離感測器等)，但實務上，在複雜環境中，外加感測
器容易因碰撞而損壞。陳俊傑[14]利用擾動觀測器，僅需過馬達的速度與電流，就能估
測外界地形施於機器人的干擾扭矩，設計 admittance 控制器，完全不需外加任何感測
器，即能調整關節馬達轉速，克服步階、斜坡等地形。 
2. 機器人架構 
2.1 硬體架構 
合作搜尋在硬體平台上使用第二、三代機器人(圖 2-1)，兩種機器人平台各搭配其適
合的感測器，接下來將分別就硬體平台的不同，說明其系統運作。另與自閉症孩童之互
動式機器人操作模式也於下面說明。 
 
圖 2-1 硬體平台(左邊、中間:第三代機器人，右邊:第二代機器人) 
2.1.1 第二代機器人 
體積寬度足以放置筆記型電腦，攝影機透過 USB 介面連接到筆記型電腦做目標物顏
色的辨識，而雷射掃瞄器則是透過 RS232 的介面連接到筆記型電腦做環境偵測的資料收
集，透過筆記型電腦上的人機介面來做行為決策，再透過 RS232 介面與底層 DSP 控制
板來溝通，同時電子羅盤透過 SPI 介面連接到 DSP 控制板做角度的判別偵測，馬達控制
方面以電壓訊號命令來控制馬達的轉速，此外 ZigBee 模組也透過 RS232 介面連接到
DSP，系統架構如圖 2-2 所示。 
DSP 2812
SPI
USB
Camera
IBM
PC
Compass
SCI ASCI B
ZigBee
Module
GPIO
驅動電
路板
Driver
Driver
Motor 
A
Motor 
B
Encoder
Encoder
Laser
RS232
 
 圖 2-6 馬達控制電路硬體架構 
 
    機器人的致動器使用 ROBOTIS 公司出產的 AX-12 伺服機。其主要特色為半雙工
UART 數位封包通訊，與位置、速度、負載扭矩等回授資訊。由於 AX-12 伺服機的通訊
協定為半雙工通訊，因此 F2812 的 SCI 介面需經由全雙工轉半雙工電路才能與之溝通，
而馬達回傳資料的電壓位準為 5V，為了避免 DSP 燒毀，必須透過 5V 轉 3.3V 電路轉換
電壓位準。 
2.2 無線通訊架構 
2.2.1 ZigBee 網路位址分配演算法 
當網路形成時，ZigBee 的協調者(Coordinator)必須要先定義 ZigBee 路由器最多可容
許連線之裝置個數(Cm)，以及最多的子 ZigBee 路由器數量(Rm)以及網路的深度(Lm)，
ZigBee 規定 Cm  Rm，因此一 ZigBee 路由器至少可供(Cm-Rm)ZigBee 終端設備連結上
它。裝置的網路位址是由其父節點(Parent router)所給定的，對於 ZigBee 協調者，整個
網路的位址空間被劃分成 Rm+1 塊，前 Rm 塊位址空間將分配給其 Rm 個子路由器，而
最後一部份則保留給與之連線之(Cm-Rm)個 ZigBee 終端設備。ZigBee 路由器利用 Cm、
Rm、Lm 來計算一個稱為 skipC 的參數，然後再利用 skipC 來計算其子路由器以及終端
設備的網路位址，假定一路由器位於網路的第 d 層， skipC 的數值由式 2-1 可得: 
1
1 ( 1),          if Rm=1
( ) 1
,
1
Lm d
skip
Cm Lm d
C d Cm Rm Cm Rm
Otherwise
Rm
 
  

    


      (2-1) 
位址的分配是由 ZigBee 協調者開始，會先將自己的位址指定為 0，以及深度指定為
0，假設一個在深度 d 的父節點的位址以被指定為 parentA ，該父節點將指定他的第 n 個
子路由器的位址為 ( 1) ( ) 1parent skipA n C d    ，並且指定他的第 n 個子終端設備的位
址為 ( )parent skipA Rm C d n   。 
2.2.2 ZigBee 區域網路建構 
多機器人合作主要就是可以透過彼此機器人間的無線通訊做資料交換，以達到資源
分享的目的，最後提升整體的工作效率，同時為了讓傳輸端和接收端有即時的交換訊
息，所以在無線通訊上比須使用到點對點的直接通訊方式。 
在 ZigBee 的網路拓撲決定使用 Mesh 的方式，也就是全部節點都扮演 router 的角
色，在協調者(coordinator)上設定 Cm=4、Rm=4、Lm=5，可容許底下加入 4 個子節點，
後，將分別提出一套合作策略以及所相對應的行為模式架構，使多機器人可以自主性的
達到合作搜尋目標物的任務。 
3.1 已知環境合作搜尋策略 
A. 策略說明 
(1) 透過 ZigBee 無線通訊進行資訊交換，所交換的資訊包括目前各機器人本身所在的區
塊編號，以及位置座標(由馬達 Encoder 取得)。 
(2) 機器人本身具備自我決策系統，判斷其他機器人的區塊編號以及位置資訊，當機器
人本身的區塊如果有跟其他機器人的區塊重疊到時，將進行避開的動作，而如果目
前所在的區塊都沒有跟其他機器人所在區塊重疊到時，機器人下一步將會避開有機
器人在的區塊搜尋，以此機制來讓多機器人分散在環境中，如圖 3-1 所示，在此把
透過 ZigBee 無線通訊產生合作的行為歸類為群體行為。 
Target
3
5
0
350
21 3
4 5 6
7 8 9
Robot
R
o
b
o
t
Robot
R
ob
ot
Inter-robot communication
 
圖 3-1 虛擬區域劃分策略示意圖 
 
B. 場地虛擬區域劃分 
先對場地做虛擬的區域劃分，再以劃分好的區塊為判斷依據，目的使多機器人有
效的分散在環境中，至於多大範圍畫分一個區塊則視機器人的感測能力，所以在區塊
的劃分上採用以 100cm X 100 cm 為大小當成ㄧ個區塊。 
C. 個別行為設計 
個別行為在本論文中定義為自主機器人本身所具備的基本功能，所以個別行為同
樣適用在沒有合作機制下的自主搜尋，在行為的設計上以機器人所要執行的任務為參
考，以本論文的搜救機器人應用議題來說，機器人必須具備: 
(1) 有找尋目標物的能力，設計 find target 行為。 
(2) 環境中避障的能力，設計 obstacle avoidance 行為。 
(3) 環境中隨機探索的能力，設計 wander 行為。 
 find target 行為 
找尋目標物為搜尋任務的最終目的，所以首先對於目標物做定義，在本論文中目標
In
ter-ro
b
o
t co
m
m
u
n
icatio
n
inter-robot 
avoidance
robot
wander
exploring
Behavior
output
Based on
priority
 、
find target
obstacle 
avoidance
Localization
Environment
wander
Priority2
Priority5
Priority1
Priority3
Priority4
compass
laser
color-detect color-detect
ultrasonic
compass
第二代機器人 第三代機器人
Individual behavior
Group behavior
mission
Priority 1àHigh priority
Priority 5àLow priority
 
圖 3-3 基於行為模式之多機器人合作搜尋架構(虛擬區域劃分策略) 
3.2 未知環境合作搜尋策略 
A. 策略說明 
(1) 各機器人透過 ZigBee 無線通訊進行資訊交換，訊息內容為各機器人的座標(由馬達
Encoder 取得)和狀態(是否發現目標物)，然後短暫的儲存幾筆其他機器人的座標資
訊，再把座標各換算成單獨區域，相對於幾筆暫存的座標就可以顯示成一個小區域。 
(2) 各機器人透過比對此小區域是否和其他機器人有相重疊到，若有重疊到就進行避開
的動作。而座標換算成單獨區域的大小，則使用先前章節所介紹的機器人個人區域
100cm，暫存座標經過一段時間後將會更新一次。在此把透過 ZigBee 無線通訊產生
合作的行為歸類為群體行為。 
Target
Robot individual  area
Inter-robot communication
r
Robot1
R
ob
ot
2
R
obot
3
Current
(X,Y)
Previous
(X,Y)
Previous
(X,Y)
Previous
(X,Y)
Previous
(X,Y)
Current
(X,Y)
Previous
(X,Y)
Previous
(X,Y)
Current
(X,Y)
 
圖 3-4 動態區域劃分策略 
 基於無距離感測器之克服蜿蜒隧道之系統架構 
3.3 雙層式偵測碰撞結構 
 
圖 3-6 雙層式偵測碰撞結構 
 
圖 3-6 為串結機器人基於無距離感測器克服蜿蜒隧道的架構，其特色為採用第一節
機器人左右履帶的速度與扭矩資訊，偵測履帶與壁面摩擦造成的異常擾動，觀察機器人
是否產生方向，並且判斷碰撞產生之方向，再執行特定的脫逃動作。 
    在此架構中，應用了統計上的分類模型，並且透過時域上訊號分佈的特性，使機器
人產生更精準與多樣化的環境認知，最後利用此資訊達成克服蜿蜒隧道之目的，以下就
各系統區塊做說明。 
First Judgment Layer 設計 
 
圖 3-7 Chain-type 機器人左側與右側碰撞實驗 
 
本層的輸入為第一節左右兩側履帶馬達的速度與負載扭矩，一共有四個維度，第一
層判斷機制(first judgment layer)內涵預先建立之分類模型，分類模型的獲得由預先進行
機器人的左側與右側碰撞實驗(圖3-7)，是基於實驗上的統計結果。吾人利用的技巧為將
四個維度的訊號映射至二維平面作圖，再透過線性規劃的技巧分類不同碰撞的特徵圖樣
(pattern)，本層將輸出三種判斷結果，分別為Normal(無碰撞)，Right collision(左側碰撞)
與Left collision(右側碰撞)，如圖3-8所示。 
Left 
Right 
  
 圖 3-9(b) 實驗結果，採用第二種映射的分佈圖 
 
 直覺上右側碰撞時，右側履帶會因摩擦力而較左側慢，但可以發現上圖的切割線並
非完美的通過原點之 45 度直線，原因在於實際上機器人的負載並不平均，左右兩側履
帶在碰撞時所受的負載也有不同，因此要增加判斷的準確性，就必須觀察如上圖之速度
分佈來設計切割線。 
 
Second Judgment Layer 之設計 
    而第二層判斷機制(second judgment layer)擁有記憶性質，本層的重點在於解決第一
層的分類模型之缺點：(1) 第一層判斷的輸出缺乏暫態分析，需要一定的時間之後才會
收斂到正確的結果。(2) 第一層之設計只能判別時間 0n n 時的碰撞結果，無法判定機
器人是否長時間受困於地形。 
    因此本層的重點在於加入時間記憶暫存器，收集第一層過去 k 個取樣時間的結果，
進行更加準確的判斷，有助於預防因機構與地形引起之雜訊的危害，並且可以偵測機器
人是否卡住於某一區域的狀況。以下碰撞(collision)的定義為機器人與洞穴進行初次接觸
的事件，而卡住(stuck)定義為機器人長時間因地形因素無
4.1 已知環境策略模擬結果 
0 1 2 3 4 5 6
0
5
10
15
20
25
30
35
40
45
number  of  robots
s
e
a
rc
h
  
ti
m
e
 (
m
in
)
uncooperative(environment1)
cooperative(environment1)
0 1 2 3 4 5 6
0
10
20
30
40
50
number  of  robots
s
e
a
rc
h
  
ti
m
e
 (
m
in
)
uncooperative(environment2)
cooperative(environment2)
 
圖 4-2 模擬場地 A-1 之模擬結果       圖 4-3 模擬場地 A-2 之模擬結果 
0 1 2 3 4 5 6
0
5
10
15
20
25
30
35
40
45
50
number  of  robots
s
e
a
rc
h
  
ti
m
e
 (
m
in
)
uncooperative(environment3)
cooperative(environment3)
 
圖 4-4 模擬場地 A-3 之模擬結果 
 合作策略對搜尋時間的影響 
分別透過三個不一樣的場地模擬，如圖 4-2、       圖 4-3、圖 4-4 所示，當機器
人數目慢慢增多時(1~6)，在平均搜尋時間上會降低，同時是以一個趨於平緩的趨勢降
低，而有使用合作策略(虛擬區域劃分策略)時會比沒有合作策略時降低更多，同時觀察
搜尋時間的標準差，有使用合作策略時，標準差的下降還比沒有合作策略時明顯，這代
表著搜尋效率的提升，經由模擬結果，可以證實所設計的虛擬區域劃分策略的可行性。 
 
 合作策略與機器人數目的關係 
比較有、無合作策略時的模擬結果，可以觀察到當機器人數目在 2~3 時改善的幅度
比較明顯，也就是對於平均搜尋時間的降低比較多，而機器人數目多(大於 4)的時候反
而改善幅度比較小，原因為: 
(1) 當機器人數目越多，就類似採取人海戰術，越多人工作，則工作越快完成，最後相
對起來，有使用合作策略反而改善的幅度並不明顯 
(2) 機器人數目多，代表重複走過的路徑會增加，導致會花比較多時間在走同樣走過的
路徑，對於整體搜尋效率的提升比較有限。 
 經由模擬結果，當機器人數目在 2~3 時，對於本研究所設計之虛擬區域劃分策略，
比較能發揮其改善的效果，因此當成實際實驗時，選擇機器人數目的重要指標。 
4.3 已知環境策略實驗結果 
1 2 3
0
2
4
6
8
10
12
14
16
number of robot
s
e
a
rc
h
 t
im
e
(m
in
)
*uncooperative
o cooperative
1 2 3
0
1
2
3
4
5
6
7
8
9
number of robot
a
v
e
ra
g
e
 s
e
a
rc
h
 t
im
e
(m
in
)
uncooperative
cooperative
 
圖 4-8 比較時間變異量(已知環境)       圖 4-9 比較平均時間(已知環境) 
4.4 未知環境策略實驗結果 
1 2 3
0
2
4
6
8
10
12
14
16
number of robot
s
e
a
rc
h
 t
im
e
(m
in
)
* uncooperative
o cooperative
1 2 3
0
1
2
3
4
5
6
7
8
9
number of robot
a
v
e
ra
g
e
 s
e
a
rc
h
 t
im
e
(m
in
)
uncooperative
cooperative
 
圖 4-10 比較時間變異量(未知環境)       圖 4-11 比較平均時間(未知環境) 
4.5 無距離感測器通過蜿蜒隧道實驗結果 
串節機器人通過蜿蜒隧道，如圖 4-12 所示，先以逆時針通過ㄇ字形通道，最後右
轉 90 度出彎。隧道寬度 26cm，單節機器人寬度 11cm、長度 22cm，機器人總長度 53cm，
實驗結果如圖 4-12 (a)到(l)所示。 
        
           (a)            (b) 偵測到左側碰撞        (c) 機器人進行轉向 
行為，機器人自主能力產生3個個別行為，最後透過優先權比較機制，結合ZigBee無
線通訊，設計出基於行為模式之多機器人合作搜尋架構，經由實驗結果，使用此策
略，相較於沒有使用合作策略，將可以提高整體搜尋效率30%。 
 
3、串節機器人基於無距離感測器克服蜿蜒隧道 
在機器人克服蜿蜒隧道中，藉由觀測馬達之異常速度與扭矩，透過多維訊號映射建立
的分類模型，搭配擁有記憶性的判斷機制，達成機器人感測週遭環境之功能，並且藉由
動作的挑選，可以使機器人在不使用距離或碰撞感測器下走出狹窄走道地形，有助於節
省機構空間與預防感測器損壞之情形。 
 
 
Reference 
[1]  B. Kuipers and Y.-T. Byun, “A Robot Exploration and Mapping Strategy Based on a 
Semantic Hierarchy of Spatial Representations,” J. Robot. Autonomous Syst., Vol. 8, pp. 
47–63, 1991. 
[2]  S. J. Moorehead, R. Simmons, and W. L. Whittaker, "Autonomous Exploration Using 
Multiple Sources of Information," Proceedings of the 2001 IEEE International 
Conference on Robotics and Automation, Vol. 3, pp. 3098-3103, 2001. 
[3] I. Rekleitis, G. Dudek, and E. Milios. “Multi-Robot Exploration of An Unknown 
Environment, Efficiently Reducing the Odometry Error.” Proceedings of the 
International Joint Conference on Artificial Intelligence (IJCAI’97), pages 1340-1345, 
Japan, August 1997. 
[4]  I. Rekleitis, G. Dudek, and E. Milios. “Accurate Mapping of an Unknown World and 
Online Landmark Positioning.” In Proc. Vision Interface (VI), pp. 455-461, Nagoya 
Japan, 1998 
[5]  I. Rekleitis, R. Sim, G. Dudek, and E. Milios, "Collaborative Exploration for the 
Construction of Visual Maps," Proceedings of 2001 IEEE/RSJ International Conference 
on Intelligent Robots and Systems, Vol. 3, pp. 1269-1274, 2001. 
[6]  C. Chee Kong and G. Leng, "Cooperative Search Algorithm for Distributed 
Autonomous Robots," Proceedings of 2004 IEEE/RSJ International Conference on 
Intelligent Robots and Systems, Vol. 1, pp. 394-399, 2004. 
[7]  M. Anderson and N. Papanikolopoulos, "Improving Multirobot, Cooperative Search via 
Local Target Queues," Proceedings of 2007 IEEE/RSJ International Conference on 
Intelligent Robots and Systems, pp. 2590-2595, 2007. 
[8] R. Grabowski, L. Navarro-Serment, C. Paredis, and P. Khosla, "Heterogeneous Teams 
of Modular Robots for Mapping and Exploration," Autonomous Robots, vol. 8, pp. 
293-308, 2000. 
[9]  D. Jung and A. Zelinsky, "An Architecture for Distributed Cooperative Planning in A 
Behavior-Based Multi-Robot System," Robotics and Autonomous Systems, vol. 26, pp. 
149-174, 1999. 
Mechatronics 2010, June 28 – 30, Swiss Federal Institute of Technology ETH, Zurich Switzerland 1
 
Wireless Localization for Mobile Robots via Particle Filter and 
Sensor Fusion 
Cheng-Chung Hsu, Syh-Shiuh Yeh*, and Pau-Lo Hsu** 
Department of Electrical Engineering 
National Chiao-Tung University 
Hsinchu, 300 Taiwan, ROC 
E-mail: plhsu@cc.nctu.edu.tw 
** corresponding Author 
*Department of Mechanical Engineering 
National Taipei University of Technology 
Taipei, 10608 Taiwan, ROC 
E-mail: ssyeh@ntut.edu.tw 
ABSTRACT 
A built-in received signal strength indicator (RSSI) is conveniently adopted to estimate the location of a mobile 
robot by applying the trilateration algorithm. However, the estimated RSSI is seriously affected by both the 
multi-path effect and the antenna orientation of wireless sensor networks, and this generally leads to 
unreliable estimation results. This paper proposes the technique of applying  particle filter to effectively 
reduce estimation error. Experimental results indicate that the present localization accuracy significantly 
improved by 73.9% compared with those obtained by applying the Kalman filter. 
1. INTRODUCTION 
Wireless sensor network (WSN) has become popular especially in localization techniques mainly due to their 
advantages of being low in cost and power consumption. Several successful methods in determining targets in 
distance have already been proposed. They are categorized as: (i) range-based localization and (ii) range-free 
based localization. There are four general types in the range-based localization, and these are briefly described as: 
(i) TOA, which utilizes the time tag to calculate the time of fly to obtain distance; (ii) TDOA, which calculates the 
time difference between two different time tags to obtain the time of fly [1]; (iii) AoA, which sets up a set of 
antenna arrays to receive the arrival signal and calculate the target position by triangulation [2]; and (vi) RSSI, 
which transfers received signal strength to distance and calculates the target position by trilateration. Among the 
four available methods, RSSI is the simplest and most convenient method because it is easy to implement and does 
not need additional hardware [3]. However, RSSI-based localization renders unreliable results because RSSI is 
affected heavily by both the multi-path effect and antenna orientation of wireless systems [4, 5].  
In recent years, Bayesian-based localization approaches have been widely discussed for mobile robot 
localization [8-11]. The particle filter, which is based on the Bayesian recursive filtering, is also a powerful signal 
processing technique for low S/N signals. It generates a set of particles to approximate system states, from which 
the state with the highest possibility is then determined [12, 13]. This paper proposes the application and 
implementation of particle filter on mobile robots with the fusion technique to significantly reduce the effects of 
multi-path and antenna orientation and, generate reliable localization results. 
2. RSSI MODELING 
2.1. TRILATERATION LOCALIZATION 
The mobile robot used in this study was mounted on a mesh-based topology for the 802.15.4 ZigBee sensor 
network. A built-in received signal strength indicator was adopted to estimate the location of the mobile robot by 
applying the trilateration algorithm. The trilateration algorithm in general requires three reference nodes; however, 
the undesirable estimation results in the present implementation can be filtered by applying the logic judgment. 
Mechatronics 2010, June 28 – 30, Swiss Federal Institute of Technology ETH, Zurich Switzerland 3
 
where n is signal propagation constant, also named the propagation exponent; D is the distance from the sender; 
and A is the received signal strength at a distance of 1 m.  
 
Experiments to estimate RSSI were conducted in an indoor obstacle-free environment. Both the SmartRF04 
and CC2430DB sent a test package to record RSSI 10000 times with a fixed antenna orientation. The histogram 
results shown in Figure 5 indicate that almost all estimated RSSI are close to -45dbm as the distance approaches 1 
m. The parameter A was then determined as -45, and the parameter n was determined by the averaged RSSI at 
different distances. Results shown in Figure 6 indicate that with the model n=3.5, the experimental results are 
consistent with the theoretical results. 
0 5 10 15 20 25 30
-100
-90
-80
-70
-60
-50
-40
distance (m)
R
SS
I
n=3.5
measurement mean
 
Figure 6: The RSSI model with the n = 3.5 
3. THE IMPLEMENTATION OF THE PARTICLE FILTER AND SENSOR FUSION 
3.1. PRINCIPLE OF THE PARTICLE FILTER 
Both the information on electronic compass and the current state of the robot are also included with the 
RSSI-based localization; this is because the target node obtained simply from the RSSI-based localization renders 
primary and unreliable estimation results only [15].The state-space equation is given by:  
1 1( , )k k kx fx x V− −=  and (2)
( , )k k k kz h x U= . (3)
where 
xk is the state vector at time instant k ; 
zk is the observations at time instant k; 
fx is the state transition function; 
hk is the observation function; 
Vk is the process noise; 
Uk is the observation noise. 
 
The particle filter is based on the Bayesian recursive filtering which uses a set of particles to approximate the 
system state [12, 13]. Each particle expresses a possible state space, and the weight of each particle expresses the 
truest of each particle as shown in (4) and (5) as 
1 1( , )
i i
k k kx fx x V− −=  (4)
0: 1{ , }
i i N
k k ix w = , (5)
where 
0:{ , 1,..... }
i
kx i N=  is the number of particle; 
0: { , 0,....., }k jx x j k= =  is the set of state till time instant k ; and 
i
kw  is the weight of each particle.  
The posterior probability 0: 1:( | )k kp x z at time instant k can be approximated as:  
Mechatronics 2010, June 28 – 30, Swiss Federal Institute of Technology ETH, Zurich Switzerland 5
 
following formula for the weighting function is used: 
w =
1
distance .
 (13)
where the distance is the difference between the prediction position of particle and the RSSI based localization 
result. 
0 0.2 0.4 0.6 0.8 1 1.2 1.4
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
distance
M
ea
su
re
m
en
t  
lik
el
ih
oo
d 
 
Figure 9: The distance weighting function 
However, RSSI-based localization provides incorrect estimation results mainly because of the multi-path  and the 
antenna orientation effects. Three physical constraints were considered here to filter incorrect localization results, 
and the most possible particle can then be found as the maximum velocity, angular velocity, and current state of 
the robot as detailed below. 
 
a) The maximum velocity of the mobile robot. This is because localization results should fulfill the 
continuity in motion considering the maximum velocity of the mobile robot. Therefore, some 
localization results will be eliminated if the estimated motion is unreasonable. The weighting function 
is designed as the difference between the current velocity of the particle and the maximum velocity of 
the mobile robot (Figure 10) as expressed by: 
           1
Vmax-V' ,
 (14)
where Vmax and 'V represent the maximum and current velocities of the robot, respectively.  
 
b) The angular velocity of the robot. Unreasonable localization information on angle difference will be 
neglected, in consideration of the angular velocity of the robot and orientation obtained from electronic 
compass. As shown in Figure 11, the  weighting function can be determined as by: 
1( , )p k kP Pθ −= ∠            (15)
' '
1k kθ θ θ −Δ = −              (16)
1
pθ θΔ −    ,
                 (17)
where  
kP  is the current position from RSSI based localization result; 
pθ  is the difference between current localization result and previous result; 
kθ  is the orientation of each particle; and  
θΔ  is the difference between current orientation and previous orientation. 
 
c) The current state of the robot. The antenna orientation will change when the robot rotates. The 
information on the current state of the robot will then be useful in filtering out incorrect estimation 
results from RSSI in order to reduce the antenna orientation effect. Three states are described below: 
 
z Stop: Any localization error increases or position change leads to wrong RSSI estimation if the current 
state is stop. 
z Forward or backward: Localization results should not change dramatically unless RSSI results are 
unreliable when the robot moves forward or backward. 
z Rotation: When the robot rotates, the antenna orientation will also change. Otherwise, RSSI provides 
unreliable information. 
Mechatronics 2010, June 28 – 30, Swiss Federal Institute of Technology ETH, Zurich Switzerland 7
 
 
Figure 12: The experimental environment and trajectory 
Table 1: Comparison of localization error  
Error(m) uncompensated（m） Kalman Filter（m） Particle Filter (m) Improvement  (%) 
AVG. 1.5080 1.5193 0.3665 73.9443% 
 
0 0.5 1 1.5 2 2.5 3 3.5
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
error(m)
cu
m
ul
at
iv
e 
pr
ob
ab
ili
ty
Original
Kalman
Particle
 
Figure 13: Cumulative probability distribution of localization error 
-2 -1 0 1 2 3 4
0
0.5
1
1.5
2
2.5
3
3.5
4
X axis
Y
 a
xi
s
ref
wireless
 
Figure 14: The uncompensated robot trajectory 
-2 -1 0 1 2 3 4
0
0.5
1
1.5
2
2.5
3
3.5
4
X axis
Y
 a
xi
s
ref
particle
 
Figure 15: The estimated robot trajectory by applying the particle filter 
無衍生研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
以 Chain-type 機器人參與 2010 TI DSP 競賽獲得佳作獎 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
