支援 IEEE 802.11r的資料串流之順暢傳遞方法
紀光輝
國立雲林科技大學電機工程系
雲林縣斗六市大學路三段 123號
(05) 5342601分機 4245
chikh@yuntech.edu.tw
中文摘要
IEEE 802.11e為傳統的 IEEE 802.11無線區域網路提供服務品質（QoS, quality of service）保
證的增強規範。提供服務品質是目前發展無線區域網路技術最重要的議題之一；這項技術
的進展可成為 Voice-over-IP、H.264 AVC codec或整合多媒體應用的基本平台。針對即時性
的資料串流（如語音或多媒體型態資料），本研究提出一個動態分配 TXOPs (transmission
opportunities) 的方法。TXOP界定工作站可連續地發送資料訊框（data frame）的一段時期；
在這段時期當中，工作站毋須經由傳統的一一輪詢（polling）方式方能送出單一訊框。我
們依各個工作站可能的傳輸佇列長度而分配適當的 TXOP，並提出一個適應性的方法，使
得工作站能更有效率地傳送或接收資料。如何就各個工作站決定合適的 TXOP 值是我們所
關切的問題核心。因為不同的工作站有不同的工作量，若讓每個工作站皆使用相同的
TXOP，將造成工作量大的工作站無法得到需要的時間而工作量小的工作站卻得到了過長的
時間，造成浪費。
有別於絕大多數的文獻，我們所提出的方法有下列優點：
 與 IEEE 802.11e規範完全相容，毋須修改規範中已定義完備的機制、亦毋須增加額外
新的通訊流程。
 我們主要關心如何在免競爭時期（contention free period）能更有效率地提升網路的效
能。
目前文獻的作法多考慮競爭時期（contention period）的行為，主要目的係在競爭時期中降
低訊框碰撞的發生，進而提高網路傳輸的效能。唯，這些作法均須更動 IEEE 802.11e甚或
IEEE 802.11既定機制方能支援，因此並不符合標準規範。此外，使用免競爭模式來服務即
時性的資料訊框應較為宜。吾人預期將有愈來愈大量的語音或多媒體類資料透過無線區域
網路進行傳輸。我們的方法改善免競爭時期中網路運作的效能，且若免競爭時期佔整個服
務週期（superframe）較大部分比例的話，則能大幅地增進整個系統的傳輸效益。
我們的研究步驟分成數個階段。首先，我們假設在完美、無錯誤的通訊通道環境下設
計一基本工作模式。此工作模式將成為底下階段的方法設計與實驗之基礎。我們使用指數
平均（exponential average）的技巧來預估各個工作站在即將開啟的服務週期內有多少訊框
待發送，再依照此預估值分配合適的 TXOP。為使得資料傳輸有效率地進行，待傳訊框個
數的估測值會隨著交通狀況的改變而作動態調整。作動態調整的根本前提有二：不違反各
個工作站的最大、最小頻寬需求（此為 QoS參數）並可使得免競爭時期的總長度不超過整
個服務週期特定比例。此比例可由系統管理者指定，與允入控制（admission control）搭配
Provision of Streaming Services in IEEE 802.11r Networks
Kuang-Hui Chi
Department of Electrical Engineering
National Yunlin University of Science and Technology
123, University Road Section 3, Douliu, Yunlin County, Taiwan 640, ROC
Phone: (05) 5342601ext. 4245
chikh@yuntech.edu.tw
Abstract
IEEE 802.11e specifies supplementary mechanisms to IEEE 802.11 wireless Local Area
Networks for QoS (quality of service) support. Meanwhile, the emerging IEEE 802.11r is
targeted at providing fast transitions of a mobile station among access points (APs) for wireless
Voice-over-IP or other delay-sensitive applications. As IEEE 802.11r is still at its early stage of
development, we plan preliminary studies on IEEE 802.11r-centric techniques. The provision of
QoS support is one of the most important issues to be dealt with. Concerning real-time or any
delay-sensitive traffic, this project has developed a means of dynamically allocating TXOPs
(transmission opportunities) whereby stations can send or receive frames more efficiently without
violating QoS requirements, meanwhile at a lower cost of system operations. We propose an
adaptive approach to allocating TXOPs in light of the potential length of per-station transmit
queue. Our treatments are carried out in stages. First, given an error-free communication channel,
we design a base operation paradigm for subsequent development. Here an exponential averaging
technique is employed for assessing the number of uplink frames to be sent by each station. The
assessed value is then tuned in line with traffic dynamics over time, yet fulfilling the guaranteed
data rate.
Next, an unreliable channel is taken into account so as to adapt the base operation model.
For error resilience, we allot shorter TXOPs to stations with higher error rate, whereas stations
with lower error rate allow for longer TXOPs. In this manner, stations with poor communication
quality can be prevented from seizing the wireless medium for repeated ineffective
retransmissions, causing system throughput degradation.
Third, we consider schedule management during a contention free period. Under discussion
are the First-Come-First Served, Random, or Shortest-Job-First policies. The estimated amount of
jobs is taken from the foregoing stages. We elaborate on the relative effectiveness of the three
policies.
An analytical model is developed for performance evaluation as well. A performance index
is concerned with how long a packet spends on average waiting in its transmit queue. This is
addressed using an M/G/1 queue with vacations, additionally with gated system behavior. The
other performance index of interest is the packet loss rate. Extensive simulation results show that
our approach can be used to determine proper TXOPs and leads to a marked improvement of
system throughput.
第一章 導論
無線網路的蓬勃發展使得無線網路越來越受到大眾的了解以及接受。而隨著網路傳輸
上頻寬的需求逐漸改變，現今的無線網路面臨一項重要的課題，就是如何使無線網路去提
供 Quality of Service (QoS)去增強支援即時性服務的能力，而這項技術的進展更可成為
Voice-over-IP或 H.264 AVC codec等相關應用的基本平台。
傳統 IEEE 802.11 MAC層並沒有注重 QoS的問題，僅考慮兩個不同的協調功能，分散
式協調功能(distributed coordination function，簡稱 DCF)以及中樞協調功能(point coordination
function，PCF)，前者是使用 carrier sense multiple access with collision detection(CSMA/CA)
存取機制的基礎；而後者提供的是免競爭服務。雖然中樞協調的功能原本是為了要提供即
時性服務所設計，但是其功能確未完善。
為了提供無線網路使用者的服務品質保證，IEEE 802.11 Task Group E提出了新的無線
媒體存取方法(IEEE 802.11e)，其動作方式將在本文的第三章中介紹，其中 EDCF(Enhanced
Distributed Coordination Function)是針對 DCF 作改良的機制，而 HCCA(HCF controlled
Channel Access)則是取代原本的 PCF，圖 1.1為 IEEE 802.11e MAC層的架構：
而類似於 IEEE 802.11的 Point Coordinator(PC)，在 IEEE 802.11e中也有類似其功能的
Hybrid Coordinator(HC)，用以管控各個工作站的存取機制。通常HC如PC一樣建設於Access
point(AP)之中。
由於在過往的文獻當中，在 IEEE 802.11e當中針對於為了要提供更好的服務品質，幾
乎都是提出在 EDCF中去作改良。其中有調整 contention window(CW)或是 interframe space
(IFS)等，目的無非是想要減少在 EDCF中所發生的碰撞，進以提高整體的效率。諸如此類
的方法確實可以提高競爭週期中的效能，但是對於免競爭週期當中，卻少有文獻探討於此。
我們則是希望在盡可能充分發揮 HCCA的機制，使得整個網路效能得以提升。我們的方法
是去動態調地整適合的 Transmission Opportunities (TXOP)長度，使得每個工作站都能分配
到適合自己的 TXOP，避免那些擁有較高封包遺失率的工作站或是只有較少封包待傳送的
工作站分配到過長的 TXOP 長度，相反的對於封包遺失率較低的工作站或是擁有較多封包
第二章 IEEE802.11無線區域網路的基礎架構
決定無線媒介的存取是由協調功能(coordination function)所掌控。在 IEEE 802.11無線
區域網路的媒體存取控制層(MAC layer)中，提供了兩種不同功能的無線傳輸媒介的存取方
式：分散式協調功能(DCF)與中樞協調功能(PCF)，兩者分別屬於競爭傳輸免競爭傳輸，如
圖 2.1所示：
而這兩個功能將由 PC 去掌控，並且交替進行。亦即，在進行一段時間的競爭
(contention-based)傳輸之後，隨即進行一段免競爭 (contention-free)傳輸。而兩個時期交替
一次才稱為一個超級訊框(superframe)。底下我們將詳細的介紹這兩個功能。
2.1分散式協調功能
DCF是標準 CSMA/CA存取機制的基礎。在傳送資料之前，它會先檢查媒介是否處於
淨空的狀態。為了避免發生碰撞，如果當傳送者要傳送的時候發現目前頻道被佔據，則此
傳送者會隨機延後一個 backoff時間。在某些情況下，DCF也可以使用 Request to Send/Clear
to Send (CTS/RTS)的技術來減少碰撞的發生。
2.1.1載波偵測功能與網路配置向量
載波偵測 (carrier sensing)的功能主要是在判定媒介是否處於可用的狀態。IEEE 802.11
具備兩種載波偵測的功能：實體載波偵測、虛擬載波偵測。實體載波偵測主要是由實體層
提供；而虛擬載波偵測是由網路配置向量(Network Allocation Vector，簡稱 NAV)所提供。
IEEE 802.11的訊框通常會有一個 duration的欄位，來指定一段媒介的使用時間。一旦某一
個工作站開始傳輸的時候，同一網路之其他的工作站就會依據其 NAV的時間開始作倒數至
零。圖 2.2是一個說明 NAV如何保障整個程序不受干擾的示意圖。
因此 IEEE 802.11才會使用 backoff的機制來降低碰撞的機會。
2.1.3 backoff機制
在競爭週期當中，工作站想傳送訊框的時候，會先等待一段 DIFS的時間，如果此時媒
介式處於空閒的狀態，工作站即可馬上傳送。若是此時發現媒介處於忙碌的狀態，此工作
站會等待一個 DIFS再加上一段 backoff的時間，再嘗試進行重送，若是再發生媒介忙碌的
狀態，則會加長 backoff時間，再繼續一樣的動作，直至傳輸成功或訊框必須被丟棄為止，
如圖 2.3所示：
每當傳輸失敗時，便會從競爭視窗 (contention window)範圍之中隨意挑選出某個時
槽。因此每當傳送次數增加，競爭週期增長，由於每個工作站所挑選延後的時間長短不一，
因此可以避免掉許多碰撞。
競爭期間(CW)通常是 2的指數倍數減 1(例如 31、63、127、255)，每當多重傳一次，
競爭期間即移至下一個 2 的指數倍數。而競爭期間的大小事由實體層所限制，例如圖 2.3
使用唯一 direct-sequence (DS)實體層，其長度最長為 1023個時槽。
若是到達競爭期間的上限(contention window maximum，簡稱 CWmax)，則在發生碰撞
的時候還是使用此值，直到重送送次數 (retry count)超過某一上限，則此訊框將會被丟棄，
競爭期間將重置回最小競爭期間(CWmin)，並將 retry count 設為 0。
若是訊框重傳成功，則會將 CW重置回最小競爭期間(CWmin)，retry count設為 0。
2.1.4 RTS/CTS的機制
在無線區域網路之中，會有隱藏節點的問題，圖 2.4為一個隱藏節點的示意圖：
2.2中樞式協調功能
中樞協調功能提供的是免競爭服務。稱為中樞協調單元(point coordinator)的特殊工作
站，可以確保不必透過競爭即可使用媒介。中樞協調單元位於基地台，因此只有中控式型
網路才會使用 PCF。
在 PCF 之中，只有可輪詢(CF-pollable)的工作站才可以向中樞協調單元要求加入輪詢
表(polling list)之中。反之，非輪詢(Non CF-pollable)工作站在 PCF的期間之中不可進行傳
輸。通常中樞協調單元是使用 round-robin的方式，逐一要求目前在輪詢表之中的工作站進
行傳輸。若是工作站在被要求輪詢之後，傳送的訊框發生錯誤，工作站也不可以立刻進行
重送的程序，必須要等待至下一次輪詢或是競爭週期才能重送此訊框。如果可輪詢的工作
站傳送訊框的目的地是一個非輪詢工作站，則此非輪詢工作站必須等待至 DCF的期間，才
可能接收到此傳送訊框。
在 PCF的期間當中，工作站之間的訊框傳輸並不會使用 RTS/CTS的機制，因為在此期
間並不會有發生碰撞的問題。在這個期間，中樞協調單元擁有最高的控制權，所有的工作
站皆會等待中樞協調單元的輪詢之後才擁有傳送的權利。
2.2.1 PCF作業以及 Beacon訊框
在免競爭週期內，訊框的傳送由中樞協調單元控制。免競爭週期與競爭週期會交替的
出現，兩個者合稱一個超級訊框。而 PCF 起始於一個 Beacon 訊框，該 Beacon 訊框中的
CFPMaxDuration 欄位用來標明免競爭週期可以持續多久的時間。所有收到 Beacon 訊框的
工作站，都會將 NAV值設定為此時間，以確保中樞協調單元擁有足夠的掌控權。
Beacon的訊框格式如下圖所示：
Beacon訊框不只是用於 PCF起始的宣告且用於宣告某個網路的存在。定期傳送 Beacon
訊框可讓行動式工作站得知網路的存在，從而調整加入該網路的必要參數。
在 Beacon訊框當中，其MAC標頭與其他的 IEEE 802.11管理訊框並無不同。而在其
訊框主體(frame body)之中，分成強制性以及選擇性兩種：
1. 強制性：
I. Timestamp：主要是用來同步 BSS 中的工作站。BSS 的主計時器會定期目前
已作用的微秒數。
II. Beacon interval：此欄位指出多久會傳送一次 Beacon 訊框，通常設定為 100
用，因此任何管理訊框應皆可在免競爭週期中傳送。
2.2.3 PCF的傳輸程序
圖 2.7為一利用 PCF進行傳輸的範例。如上所述，免競爭週期起始於 Beacon訊框。在
範例中，基地台等候一個 SIFS的時間之後，使用一個 CF-Poll訊框去允許工作站 (工作站 1)
有一個傳送暫存訊框的能力，此工作站也隨即傳送一個Data+CF-ACK訊框，其中的CF-ACK
用以回應基地台輪詢的訊框，而資料是因為基地台給予它一個傳送的能力。
接下來等待了一個 SIFS的時間之後，工作站使用了 CF-ACK+CF-Poll的訊框。基地台
同時的輪詢了另一工作站 (工作站 2)以及回應原工作站剛剛所傳送的暫存訊框。而此時工
作站 2可能發生錯誤或是沒有收到剛剛基地台的輪詢訊框，基地台在等候一段 PIFS的時間
還沒有收到工作站 2 所傳送的暫存訊框時，基地台會直接的去輪詢下一個工作站。在等候
了 PIFS 的時間之後，基地台因為正好也有資料要傳送給工作站 4，因此基地台使用了
Data+CF-Poll的訊框。但是此時工作站 4可能正好完全沒有暫存訊框待傳送，因此工作站 4
只回應了一個 CF-ACK訊框表示有收到基地台給予它的輪詢。最後基地台以 CF-End結束
整個免競爭週期。
2.2.4 輪詢名單的建立與維護
在免競爭週期之中，中樞協調單元是依靠輪詢名單來進行輪詢。工作站在開始通訊之
前會先使用 Association來與中樞協調單元達成連結的關係。根據此訊框工作站可以得知是
否有加入輪詢的名單之中。通常如果是處於省電模式的工作站比較不願意加入名單之中，
因為若是在名單之中，一旦基地台輪詢到此工作站，就必須從省電模式醒來去回應此輪詢。
而輪詢的方式目前大多是使用 round-robin的方式，也就是基地台會依據目前所有在輪
詢名單中的工作站，按照順序一個一個去作輪詢。但是此種方法效率不好，因為雖然同樣
是處於輪詢名單的工作站，有些可能擁有較多的資料待傳送，而某些可能只有少量的資料
待傳送。因此若是此兩類的工作站被輪詢到的機會是一樣的話，可能會造成少資料量的工
圖 2.9為一說明此訊框為哪一個等級的表格，如下所示：
Control Management Data
Class1 Request to Send
(RTS)
Probe Request Any frame with ToDS
and FromDS false (0)
Class1 Clear to Send
(CTS)
Probe Response
Class1 Acknowledgment
(ACK)
Beacon
Class1 CF-End Authentication
Class1 CF-End +
CF-Ack
Deauthentication
Class1 ATIM
Class2 None Association
Request / Response
None
Class2 Reassociation
Request / Response
Class2 Disassociation
Class3 PS-Poll Deauthentication Any frame, including
those with either the
ToDS or FromDS bits
set
圖 2.9 三種等級的訊框
2.4 結論
在本章之中我們簡介了 IEEE 802.11 MAC協定。IEEE 802.11 MAC中主要是分為 DCF
與 PCF兩種機制，然而 DCF並無任何服務品質保證，而 PCF雖然原本設計是為了要解決
這個問題，但事實上仍未完善。因此為了加強原本 802.11的不足，IEEE標準組織針對服務
品質保證方面，特別提出了 IEEE 802.11e的草案，在第三章之中我們將簡單介紹這個新的
規範。
在這個欄位的 bit0至 bit3代表 TID的欄位，TID欄位用來表示：TC(traffic category)與
TS(traffic stream)。TID的值從 0到 7會對映成競爭模式中的 4個 Access categories (ACs)，
8~15 則會分別對映到 TSIDs(traffic stream Identifiers)的值 0~7，每個 TSID 再對映成
TSPEC(Traffic Specification Element)。TSPEC是用來描述 traffic stream特性的參數，後面在
介紹 HCCA時會有更詳細的介紹，TID的欄位如圖 3.2所示，而優先權與 AC 的對映表載
於表 3.2：
到所屬的 AC序列，如圖 3.4所示：
每個佇列被分類到所屬的 AC序列之後，擁有自己不同的 Arbitration interframe
space (AIFS)、CW、以及 TXOP值，如此在大部分的情況下，可以保證擁有較高優先權的
佇列其資料會比擁有低優先權佇列的資料先傳送，表 3.3 為各個 AC 所使用的 AIFS、CW
值。
IEEE 802.11e 使用 Arbitration IFS取代 DIFS。工作站中的佇列會分別獨立偵測傳輸媒
介空閒了 AIFS值之後開始作 backoff的動作，因此擁有高優先權的佇列會擁有較小的競爭
視窗值 (CWmin)與最大的競爭視窗 (CWmax)以及最小的 AIFS值，圖 3.5說明了 EDCA時
間的關係：
 Element ID：資訊元素是管理訊框的組成元件，其長度不定。element ID表示此資訊元
素識別碼，通常後面會有一個 Length的欄位代表此資訊元素的長度。
 Length：此欄位表示此資訊元素的長度。
 TSInfo：此欄位表示 traffic stream的資訊，包括所使用的存取方式、ACK等，此欄位
佔 2個 bytes。
 Nominal MSDU Size：此欄位用來指出 traffic stream 中每個MSDU的大小，佔2個bytes。
 Maximum MSDU Size：此欄位用來指出 traffic stream 中最大的MSDU大小，佔 2個
bytes。
 Minimum Service Interval：此欄位用來指出 traffic stream中相鄰的兩服務週期的最小間
隔，佔 4個 bytes。
 Maximum Service Interval：此欄位用來指出 traffic stream中相鄰的兩服務週期的最大間
隔，佔 4個 bytes。
 Inactivity Interval：此欄位用來指定一段時間，在這段時間內如果 HC沒有接收到訊框
或是沒有訊框傳送出去時，則 traffic stream將會被取消。佔 4個 bytes。
 Minimum Data Rate：此欄位用來指出 TS在傳送MSDUs時，最小的資料傳輸速率。此
值不包括MAC與 PHY的 overheads，佔 4個 bytes。
 Mean Data Rate：此欄位用來指出 TS在傳送MSDUs時，資料傳輸的平均速率。Mean
Data Rate包含在 twin token 中 second token bucket 的速率 ，佔 4個 bytes。
 Maximum Burst Size：此欄位用以表示在 TS中能以 peak rate傳送MSDUs的最大資料
量，佔 4個 bytes。
 Minimum PHY rate：此欄位用以表示在 TS中能以 peak rate傳送MSDUs的最小 PHY
rate，佔 4個 bytes。
 Peak_Data_Rate：此欄位用以表示在 TS中傳送MSDUs的最大傳送速率，佔 4個 bytes。
 Delay bound：此欄位用來表示TS在傳送一個MSDU所能允許的最大時間，佔4個bytes。
 Surplus_Bandwidth_Allowance_Factor：此欄位用以表示 TS中用以上的速率來傳送一個
MSDU時所超過分配的時間和頻寬，佔 2個 bytes。
3.3.2 HCCA的運作
在 HCF 的機制之中，HC 在任何時候都可以等待一段 PIFS 的時間後即傳送 MSDU。
因為 PIFS的長度小於 DIFS，因此 HC擁有比較高的優先權等級。圖 3.7為
3.4 結論
本章的一開始介紹了 IEEE 802.11e 比起傳統的 IEEE 802.11訊框所多出來的欄位。接
下來介紹了在 HCF中有關 DCF機制的改良(稱為 EDCF機制)。在 EDCF機制中允許一個工
作站最多同時有八個虛擬的佇列以不同的 MAC 參數來競爭無線媒介的使用權。這樣雖然
可以保證較高優先權的資料有較高的機會競爭到傳輸媒介的使用權，不過一旦 BSS內的工
作站數目便多使得傳輸媒介的競爭變得很激烈的話，資料的碰撞率就會急劇的增高。目前
已有文獻針對這一點提出改善的方法，我們將在第四章介紹這些方法。
最後本章則介紹 HCCA 的機制，包括在 Beacon 訊框中多定義出來的一些針對服務品
質保證所設定的參數，以及有別於 PCF的輪詢機制—polled TXOP。如此一來工作站接受到
輪詢以後，不再只傳送一個暫存訊框，便必須等後下一次的輪詢才能再傳送暫存訊框。工
作站可以利用 HC 所給予的 TXOP 時段任意地傳送目前所有的暫存訊框，如此一來不旦可
以使得資料傳輸的的延遲時間降低，更可以使得頻道的使用率便高。
過短的門檻值時間，容易導致較長時間無資料要傳送工作站，因為 PC 輪詢次數的頻繁而
使得浪費頻寬。反之，過長時間的門檻值時間，會導致處於 inactive工作站已有資料待傳送，
PC卻遲遲沒有輪詢到此工作站。最後此文獻是以模擬實際的語音封包來決定此門檻值。
4.1.2 Distributed Weighted Fair Queuing
此篇文獻[3]主要是針對 DCF 的模式下，針對權值(weight)公平性的去分配頻寬。文中
首先定義一個比率：Li=ri/Wi。這個比率在每個工作站必須相等，而 ri表示此工作站的輸出
量(throughput)，Wi表示此工作站的權值(weight)。若是傳統的 IEEE 802.11 的工作站其 Wi
預設值為 1，其他的工作站Wi值應大於 1。ri會隨著每個封包傳送後作改變，如 4.1式所示：
old
i
Kti
i
iKtinew
i ret
l
er // )1(   4-1
其中 li與 ti分別為傳送封包的長度以及 inter-arrival時間，K為一個常數。
每個工作站會計算自己的 Li值，並且傳送封包也會計算此值並放在目的地的封包標頭
當中。如果工作站的 Li值大於封包的 Li值的話，CW值就會稍微的作增大，反之則 CW值
會稍微的縮短，如圖 4.2的演算法所示：
在圖 4.2中，p是代表 CW 的比率，所以 p越大表示相對使用的 CW值越大且 p為一
個小於 1的值。Lown與 Lrcv分別代表工作站以及放在封包標頭的 Li值。而增加的Δ1值則如
4-2式所示：
rcvown
rcvown
LL
LL

1 (4-2)
此文獻的目的在於可以公平地的去分配頻寬，強調公平性的議題。而在此之後[14]與[42]
也是使用權重的方式針對公平性去分配適當的頻寬。
4.1.3 Support of Multimedia Services
Yeh et al. [54]介紹了四種在 PCF中不同的在 polling 方式。首先是 Round Robin的方
]*_*[
i
L
FactorScalingBi
k
i

 (4-4)
其中為介於 0.9到 1.1之間的均勻分配。若發生碰撞，發生碰撞的工作站將會選擇一
個新的均勻分配[1,2Collisioncounter-1*CollisionWindow]，其中 collisioncounter為已經發生的碰撞
次數。因此此系統會依照碰撞發生的次數以及 Scaling_Factor等去選擇適當的 BI值，而不
是像傳統 IEEE 802.11的 BI值是固定的。
4.1.5 Multipolling Mechanism
此篇文獻[36]重點在於改良 multipolling的機制。Multipolling 為一個較為特殊的輪詢方
式，其動作如圖 4-3所示：
如上圖所示，PC可以經由一個 multipoll的訊框同時要求 A,B,C,D四個工作站各傳送一
個封包。它的方式是利用一個特殊的欄位，分別對 A,B,C,D四個工作站設定不同的 backoff
時間。圖中的工作站 A設為 1個時槽、工作站 B設為 2個時槽。因此只要這四個工作站持
續監聽媒介，直至自己的 backoff時間倒數完成，則只需要一個輪詢的封包，就可以使得四
個工作站依序傳送封包。
此文獻另外也提出了一個輪詢的排程。首先先將一個 CFP 分成四個 phase，如圖 4-4
所示：
第一個 phase主要服務 downflow的封包，而它服務的單位為一個 bi(基本單位)至一個
bi+ei(最大服務單位)。至於第二的 phase為對於每一個 upflow去服務一個 bi的基本單位，
權。在少數 RRj+1>DIFSj -DIFSj+1的情況下，若封包在存取媒介的時候失敗，則會將此封包
的優先權降一等級、稍後再作傳送。
其實這個概念很類似 IEEE 802.11e 的概念，利用 DIFS 的長度來分別優先權的順序。
高優先權的工作站因為使用較小的 DIFS 值，因此可以有更大的機會在競爭週期取得使用
權。並且因為它設計高優先權的 DIFS值在加上 CWmax值也會比低優先權的 DIFS短，因
此這個方法幾乎可以保證高優先權的封包一定會先作傳送。
4.2.2 Improving the Qos Performance of EDCF
Wong et al.[51]提出了一個建立在 EDCF 且名為”ADB ( Age Dependen t Backoff)”的 排
程。每個優先權等級(Traffic Category，簡稱 TC)的佇列一旦發生碰撞，其競爭視窗會隨著
各等級的 PF(Persistence Factor)值而有不同的改變。通常而言，PF值若是越大，則再發生碰
撞的時候 CW值就會增加的越快，但是仍限制於上限 CWmax值。PF值的計算如 4-5式所
示：
2*
][
2
][  Age
TCLT
TCPF (4-5)
其中 LT[TC]為封包存活時間，Age為封包在傳送序列中的年齡。
因此若是 Age>LT 的話，PF<0，則封包將被丟棄不再使用。而且由式中可知，封包若是處
於前半個封包存活時段的話，PF值會落於 1到 2之間。若是封包處於後半個封包存活時間
的話，PF值則會落於 0到 1之間。如此一來的話，若是封包快要被丟棄的時候，其 CW值
會增加得較為緩慢，以增加其傳送的機會。
此文獻最後是以模擬的方式找出可以使即時性封包擁有最高傳送效率的 PF參數值。最
後找出了 PF在 2還有 1.5的時候可以保證即時性封包有較短的封包延遲、jitter和封包丟棄
速率，但是此時卻不利於對於 best-effort的封包傳輸。
4.2.3Adaptive EDCF
在[43]提出一機制，主要是著重於 IEEE 802.11 DCF機制的改良。它的改良重點在於工
作站能依據網路情況適應性地改變其佇列的競爭視窗值(CW)，以避免在系統負荷過重時產
生連續的碰撞而使得網路情況更為惡化。
工作站會先計算工作站內所有佇列的碰撞頻率 jcurrf ，工作站中的佇列再依據此碰撞頻
率更新其競爭週期。 jcurrf 的計算如 4-6式：
])[_(
])[(
isentdataE
icollisionsE
f
j
jj
curr  (4-6)
其中 ])[( icollisionsE j 為工作站 i在第 j個更新週期(其中每經過一個 superframe則稱為一個週
期)所產生的碰撞數目，而 ])[_( isentdataE j 為工作站 i 在第 j 個更新週期所送出的封包數。
接著，使用 exponential取平均值的方式去計算平均碰撞頻率，如 4-7式所示：
第五章 無線區域網路中適應性調配 TXOP
IEEE 802.11e 的網路環境中，為了提供更好的服務品質，許多文獻都是就 EDCF機制
作改良。不論是調整 CW 或是 IFS，就是想要在競爭時期降低碰撞的可能以及提高整體的
效能。我們主要考量則是如何在免競爭週期的期間，能更有效率地提升整體網路的效能。
一個 superframe由競爭週期(CP)加上免競爭週期(CFP)所構成，在前人的做法當中，雖
然針對 CP去改進，但是若是在整個 superframe當中，CP佔 superframe的比例比 CFP還要
小的話，無論在 CP 期間如何的去改善，所獲致的效能增益仍十分有限。針對即時性的封
包，使用免競爭的方式可以達到比較好的效能。若是我們能改善 CFP期間的效能，且若 CFP
佔整個 superframe較大部分比例的話，便可更容易的改善系統效能。
IEEE 802.11e的協定並沒有特別對 TXOP limit給定有詳加切確的值。雖然我們知道這
個值是由 HC去給定的，但是如果我們能依照各個不同工作站目前的 Transmit queue length
來動態地分配不同的 TXOP limit，我們將不旦更能夠掌控整體的交通狀況，而且也可以減
少許多不必要發送的封包，使得我們能降低系統的負擔以及提高整體的 throughput。這種分
配方式並不會違反 IEEE 802.11e的規範，因為規範中僅提供建議值，而非固定值。反觀上
章所提及的文獻當中，因為在 EDCF機制中的無論是 CW值或 IFS值，皆已有詳加切確規
範的值，因此若是選擇調整這些值的話，都必須在某種程度上的修改標準協定才能夠達成
此目的。
5.1如何去適當的分配 TXOP limit
本節將敘述於 HC如何估測各個工作站上的 transmit queue length以及如何利用估測的
值來分配給各個工作站所需要的 TXOP limit。
在 IEEE 802.11e的規範之中提到，每當 CFP開始之前，工作站一旦與 HC建立 TSPEC
之後，在這個週期內 HC 必須對所有目前已建立在輪詢名單的工作站皆輪詢過一次。因此
若是我們能依照工作站的佇列長度而分配適當的 TXOP給工作站，
則在某種程度上可達到公平性。
5.1.1傳統的 IEEE 802.11e免競爭時期
在傳統的 IEEE 802.11e協定之中，HC會處理目前在 transmit queue之中的封包。見圖
5-1與圖 5-2。我們在此先將所有的封包定義成兩大類：
1. uplink packet：代表工作站將要傳至 HC的封包。
2. downlink packet：代表 HC將要傳至工作站的封包。
HC 只能掌握 downlink packet 的數量，而對於工作站有多少封包想要在當下這個免競
爭週期傳回至 AP 則無從判斷，但藉由預測的方式可稍彌補此不足。因此如果我們能掌握
uplink packet的個數、能夠猜測的越準確的話，則我們將越可以掌握完整的交通狀況。
對於各個工作站，我們使用一個簡單的估測算式(5-1 式)去預估在此工作站的封包個
數，而式中的時間平滑因子()亦可動態去調整，使得更能符合於各個不
同的系統當中。
*11* )1(*   jcurrjcurrjcurr numUnumUnumU  (5-1)
其中 為時間遺忘因子( 10  )、
jcurrnumU *為這個 CFP中我們預估在工作站 j中的 uplink的封包總數、
1jcurrnumU 為上一個 CFP中在工作站 j中真正的 uplink的封包總數、
1jcurrnumU *為上個 CFP中我們預估在工作站 j中的 uplink的封包總數。
我們可由很簡單的數學證明得到：
numUnumU
j
jcrur  (5-2)
經由上面的 5-2式，我們可以估計出在這個 CFP中所有要服務的 uplink封包個數。同
時，因為我們可以知道各個工作站的 downlink封包個數，所以我們提出的方法是依據預估
值，去給予工作站 j能滿足基本 bj個 packets所需的 TXOP
limit，如圖 5-3和 5-4所示：
TXOP limit過長，過長所造成的影響比較不大，因為 HC隨時可以終止這個 TXOP，
取回掌控權。
其實不管上述這兩種可能性哪一個發生，只要我們去調整α值，使目前這個系統可以
更接近我們的猜測，我們應仍可達到一定滿意的效果。
5.2.3 bj值的調整
在本文中 bj值只是基本服務的單位。隨著在各個 CFP中，我們可以給予不同的 bj值，
使其能盡量符合目前的交通狀況。我們依照下面演算法去調整 bj值，使得 bj值的上限由兩
個因素決定：1.不會超過於 HC 允許工作站的最大傳輸量。2.因為過大的 bj值將導致整個
CFP過長。另外因為 HC一旦與工作站建立關係，在 TSPEC之中會指明此工作站之最大傳
輸速率(max data rate)與最小傳輸速率(min data rate)。雖然我們調整 bj值去使得 HC可以改
變原本對於工作站的 TXOP 長度，但是卻不能違反此上限以及下限所設置的原則。因此演
算法如圖 5-5所示：
// fj為 HC允許工作站的最大傳輸速率所能傳輸的最大個數的 packets數量、
bj和 ej 皆是 fj的某個百分比。
5.3考慮非完美通道
在 5.2 節之中，我們沒有考慮通道所產生的錯誤，以及傳輸封包時候所發生的封包遺
失。在本節之中，我們將考慮非完美通道所產生的錯誤，我們將利用 ASACA [12]的概念，
進而再分配給不同錯誤率的工作站有不同的 TXOP limit，使得通訊品質較為良好的工作站
擁有較多機會的傳輸時間，如此一來可避免因為一些通訊品質不好的工作站一直嘗試重傳
而導致整個系統的 throughput 下降。
5.3.1考慮各個工作站的 packet loss
若考慮到 packet loss的話，在前一節所提到的 TXOP limit必須稍作修改。如果原本假
整體而言，給予越長的 TXOP limit相當於給予越大的頻寬。因此，對於較高錯誤率的工作
站我們將給予較短的 TXOP limit，而至於較低錯誤率的工作站我們則給予較長的 TXOP
limit。
我們的作法為設定門檻值，並且區分要給予多少多大的 TXOP limit。為了公平性考量，
我們想令所有待傳的封包，至少都有一次可以傳輸的機會。因此，在最大錯誤率區段的工
作站，我們還是給予其封包有能夠至少傳輸一次機會。我們依據上個 CFP的錯誤率而將工
作站區分為四種等級，分別是：
A：0.75<Pj≤1；
B：0.5<Pj≤0.75；
C：0.25<Pj≤0.5；
D：0≤Pj≤0.25。
而我們給予 A、B、C和 D四種工作站的 transmit queue中各個封包所能傳輸的時間長
度為：
A：足夠每個封包都傳輸一次的時間；
B：足夠讓封包在錯誤的情況下能夠重傳一次的時間；
C：足夠讓封包在錯誤的情況下能夠重傳兩次的時間；
D：足夠讓封包在錯誤的情況下能夠重傳三次的時間。
因此對於這四種等級的工作站，在他們的 transmit queue中的各個封包所需傳輸時間的
機率分佈將會有如下列關係式：
A：



j
j
kj
p
p
xf
1
)( ,
的時間傳送一次但是失敗所花X
時間傳送一次就成功所花的X
kj,
kj,


(5-7)
B：






2
, )1(
1
)(
j
jj
j
kj
p
pp
p
xf
重傳一次後失敗的時間X
時間傳送兩次才成功所花的X
時間傳送一次就成功所花的X
kj,
kj,
kj,



(5-8)
C：









3
)1(
)1(
1
)(
2
,
j
jj
jj
j
kj
p
pp
pp
p
xf
重傳兩次皆失敗的時間X
時間傳送三次才成功所花的X
時間傳送兩次才成功所花的X
時間傳送一次就成功所花的X
kj,
kj,
kj,
kj,




(5-9)
D：













4
3
2
,
)1(
)1(
)1(
1
)(
j
jj
jj
jj
j
kj
p
pp
pp
pp
p
xf
重傳三次皆失敗的時間X
時間傳送四次才成功所花的X
時間傳送三次才成功所花的X
時間傳送兩次才成功所花的X
時間傳送一次就成功所花的X
kj,
kj,
kj,
kj,
kj,





(5-10)













4
3
2
,
)1(
)1(
)1(
1
)(
j
jj
jj
jj
j
kj
p
pp
pp
pp
p
xf
)(44
)(532
)(422
)(32
)(22
,
,
,
,
,
ACKpacketkj
ACKpacketkj
ACKpacketkj
ACKpacketkj
ACKpacketkj
PIFSSIFSx
PIFSSIFSx
PIFSSIFSx
PIFSSIFSx
SIFSx










(5-11)













4
3
2
*,
)1(
)1(
)1(
1
)(
j
jj
jj
jj
j
kj
p
pp
pp
pp
p
xf
packetkj
ACKpacketkj
ACKpacketkj
ACKpacketkj
ACKpacketkj
PIFSSIFSx
PIFSSIFSx
PIFSSIFSx
PIFSSIFSx
SIFSx





44
432
322
22
2
,
,
,
,
,





(5-12)
5.4.2 TXOPj的期望值和變異數
因為 TXOPj為一段時間的長短，而且對於各個工作站皆有自己的不同的 TXOPj值。由
圖 5-3 與圖 5-4 我們可得知在一個 TXOPj 之中的運作模式。因此底下我們分別對圖
5-3( numUj < numDj )與圖 5-4( numUj > numDj )所示的情形做討論。我們先在圖 5-3之中標
示出 Xj,k，如下圖：
因此， TXOPj= 

 
m
j
kjpollCF X
1
. (5-13)
= pollCF  +m*E[Xj.k]+r*E[Xj.k *] (5-16)
再來我們計算 TXOPj 的 variance。因為封包的傳送有良好的獨立特性，因此在計算
variance仍可與在計算其期望值的時候一樣、仰賴這個特性。
Case1：
V[TXOPj]= V[ 

 
m
j
kjpollCF X
1
. ]
=V[mXj.k ]=m2*V[Xj.k] (5-17)
Case2：
V[TXOPj]= V[ 

 
r
j
kj
m
j
kjpollCF XX
1
.
1
. * ]
= V[mXj.k + rXj.k *]
= m2*V[Xj.k]+2*m*r*Cov[Xj.k , Xj.k *]+r2*V[Xj.k*]
= m2*V[Xj.k] +r2*V[Xj.k*] (5-18)
5.4.3 封包等待時間(Waiting time)
關於這個部分的計算，我們是參考 [5]的M/G/1 Queue with Vacations模型。我們把各
個工作站都分開來看，因此對於那些除了屬於本身的 TXOPj以外的時間，我們把這段時間
當作它的一個 vacation time Vj，如圖 5-8所示：
將所剩餘的服務時間為直軸，時間為橫軸，可以畫出圖 5-9：
而進行傳輸， 如下列圖 5-11中所示 CAP：
為了充分反映實際網路行為，我們的做法是在 CFP結束的時刻起，HC啟動一 recoder
用記錄工作站 j 將在此 CP期間傳送封包的個數。假設記錄到的封包個數為 r j個，因此我
們把整個 superframe_period來的封包，從本來的λj*T個封包，看成λj*T - r j 個。假設λ為
已經考慮有在 CP 中傳送掉封包的影響，亦即在到達速率方面要扣掉這些傳送掉的封包再
除於整段的時間，則λ需改為：λ=(λj*T - r j) / T；
而若是假設μ*為已經考慮有在 CP中傳送掉封包的影響後的傳送速率，則
μ*=(λj*T- r j) /TXOPj：而在有考慮這個影響後的ρ則為ρ=λ/μ*。
5.5輪詢方式以及殘餘封包的考量
5.5.1 輪詢方式
在文獻[54]曾有討論到不同的輪詢方法。因此在此我們則運用三種不同的輪詢方式去做
比較：first in first serve (FIFS)、short job first (SJF)以及 random。
 FIFS的輪詢方式為優先到達佇列的工作站將先被 HC輪詢。反之，越晚到達佇列
的工作站則越晚被 HC所輪詢。
 SJF的輪詢方式為在開始服務時，擁有最少封包待傳送的工作站將先被 HC輪詢。
較高封包待傳送的工作站較晚被 HC輪詢。
 Random的輪詢方式為 HC服務工作站的順序為一隨機狀況，無論是擁有多少的封
包待傳送或是到工作站到達的順序不一，HC將所有的工作站都視為同等，以隨機
取樣的方式去輪詢。
使用此三種方式去做考量，目的是在於計算封包等待時間的時候應該會與使用何種輪
詢方式息息相關。一般而言，若是在輪詢的時候可以依照 SJF 的方式，對於整體的封包等
待時間應該可以降到最低，在下一章中我們也會對此三種輪詢方式所造就的效能做比較。
第六章 模擬結果
此章目的在於利用模擬的結果驗證本研究計畫所提出來的方法，並與舊有規範所使用
的方法作比較。並且由模擬的結果來決定上一章所定義的一些參數，探討使用不同參數的
差異性，最後我們將提出最佳的參數的使用建議。
6.1系統模型
模擬程式是以 C語言撰寫。首先使各個工作站產生自己的封包串列，封包產生的方式
是使用 M/G/1的模式，也就是對於各個工作站會有自己的封包到達速率，進而我們使用三
種不同的輪詢方式去輪詢各個工作站：First-Come-First-Serve(FIFS)、Shorest-Job-First(SJF)、
Random。再後面的章節我們也將比較此三種方法所產生的結果。
模擬中我們假設工作站為 10 個，而為了凸顯所提出方法的執行效益，模擬僅假設有
uplink的封包，並且所有的封包我們都假設語音型態的封包，因此每個封包的 delay bound
均暫設為 20ms。表 6.1左邊部份為模擬所使用的參數值。在 IEEE 802.11e 的規範裡面，已
有詳細的定義出一些參數，如表 6.1右邊部份所示。
表 6.1參數表
模擬程式使用的參數 IEEE 802.11e參數
系統模擬時間 86.4 s aSlotTime 9 μs
工作站總數 10 CF-Poll 64μs
Delay bound 20 ms CF-Ack 64μs
網路傳輸速度 54Mbps CF-Null 64μs
封包最大重傳次數 3 SIFS 16μs
單一語音封包傳送
時間
(不包含 SIFS)
29μs [21] PIFS 25μs
單一語音封包傳送
時間
(包含 SIFS)
45μs [21] SI 20 ms
6.2模擬數據
在接下來的模擬當中，我們首先假設完美通道以及一些最單純的考量，接下來我們則
考慮比較複雜的情況，例如去改變平滑因子值(α值)，或是假設工作站有自己的封包傳輸失
敗機率(packet error rate)。我們也會比較在各個工作站的 packet arrival rate差異大與差異小
所產生的結果，以及其他方向的量度。
圖 6-4至圖 6-6則是與上面使用同樣的參數，分別利用上面三種不同的輪詢方式所計算
出來的封包遺失率：
封
包
遺
失
率
(成
功
傳
送
封
包
/產
生
封
包
數
)
圖 6-4 適應性方法對於封包遺失率的影響(FIFS)
封
包
遺
失
率
(成
功
傳
送
封
包
/產
生
封
包
數
)
圖 6-4 適應性方法對於封包遺失率的影響(SJF)
封
包
遺
失
率
(成
功
傳
送
封
包
/產
生
封
包
數
)
圖 6-6 適應性方法對於封包遺失率的影響(Random)
由上面六個圖可以得知，如果使用適應性的方式去決定 TXOP 的長度，則對於語音的
封包將可以達到比較小的封包等待時間。在整個 CFP的上限佔整個 superframe的比例較低
的時候，適應性的方法因為受限於整個 CFP的時間過短，反而發揮不出使用此方法的效能。
而反觀傳統的方法因為 bj 值的固定，也就是說在每個週期中傳統的方法擁有相同大小的
封
包
等
待
時
間
(i
n
μ
se
c)
圖 6-8適應性方法對於封包等待時間的影響(SJF)
10000
11000
12000
13000
14000
15000
16000
17000
Random
0.2 0.50.3 0.4 0.6 0.7 0.8
CFP佔SI之最大比例上限
傳統方
法
適應性
方法
封
包
等
待
時
間
(i
n
μ
se
c)
圖 6-9 適應性方法對於封包等待時間的影響(Random)
封
包
遺
失
率
(成
功
傳
送
封
包
/產
生
封
包
數
)
圖 6-10 適應性方法對於封包遺失率的影響(FIFS)
此正好造成使用這兩種輪詢方式時，其實順序上是應該是相同的。為了驗證這個想法，因
此我們做了一個實驗為下：
 我們使用了兩組數據，其中一組如之前6.2.1節以及6.2.2節一致，使得 packet arrival
rate為一個遞增的方式(packet arrival rate分別為 0.00055、0.0006、0.00065、0.0007、
0.00075、0.0008、0.00085、0.0009、0.00095以及 0.001)。而另一組數據則為 packet
arrival rate並無依照一個順序(packet arrival rate分別為 0.00055、0.0008、0.00085、
0.0007、0.00075、0.0006、0.00065、0.0009、0.00095 以及 0.001)。我們使用的α
值為 0.8，bj值為 4。
圖 6-13及圖 6-46為分別使用這兩組數據下所模擬出來的封包等待時間，如下所示：
10000
11000
12000
13000
14000
15000
16000
17000
FIFS
SJF
Random
0.2 0.50.3 0.4 0.6 0.7 0.8
CFP佔SI之最大比例上限
封
包
等
待
時
間
(i
n
μ
se
c)
圖 6-13第一組數據的封包等待時間
封
包
等
待
時
間
(i
n
μ
se
c)
圖 6-14第二組數據的封包等待時間
由圖 6-13及 6-14所知，如同我們所預期，Random的輪詢方式表現最差，而若是使用
非順序的 packet arrival rate(第二組數據)時，可在圖 6-14中看到 SJF的輪詢方式果然比 FIFS
的輪詢方式表現的還要更好一點。而圖 6-15及圖 6-16則是分別使用這兩組數據下所模擬出
來的封包遺失率。
封
包
等
待
時
間
(i
n
μ
se
c)
圖 6-17 平滑因子對於封包等待時間的影響
0
0.05
0.1
0.15
0.2
0.25
0.5
0.6
0.7
0.8
CFP佔SI最大
比值
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
平滑因子值
封
包
遺
失
率
(成
功
傳
送
封
包
/產
生
封
包
數
)
圖 6-18 平滑因子對於封包遺失率的影響
我們可以由圖 6-17與圖 6-18看到，α值在大於 0.2之後，對於封包等待的時間差異性
並不大，可是在封包遺失率方面，如圖 6-18 所示，α值在 0.8 與 0.3 分別模擬出來的封包
遺失率甚至可以差異到達 56%之多，因此我們可以發現到α值對於整個系統扮演著很重要
的角色，但是若要決定各個環境中的最佳α值並不能單由上面所假設的參數值去進行模擬
所得到的結果而去決定，因此我們取了許多不同的環境參數在去做模擬，而下面是其中兩
種。
表 6.3及表 6.4跟別為圖 6-19、圖 6-20及圖 6-21、圖 6-22所使用的參數表，如下所示：
對於封包等待時間的影響似乎很小。但是對於封包遺失率方面的考量，三種模擬環境下α
值的最佳值似乎都落在不同的區間。這背後的意義也就是意味著，在不同的環境下，應該
由不同的α值去估測才比較有辦法估測到各個工作站較為準確的佇列情形，所以我們可以
得到的結論是並無法找到一個可以適合所有情況的最佳α值。
6.2.5 Packet arrival rate的影響
本節將探討封包到達速率對於系統的影響，最主要我們希望比較若是各個工作站封包
到達的速率的變異量大與變異量小時，這兩種情況將會對於傳統的方法以及適應性的方法
造成什麼樣子的影響。我們將除了封包到達速率以外的參數先固定，只改變封包到達的速
率，如表 6.5所示：
表 6.5 參數表(3)
Packet error rate
(工作站 0~工作站 9
依序所示)
0.1、01、0.1、0.1、0.1、0.05、0.05、0.05、0.05、0.05。
Packet arrival rate
(工作站 0~工作站 9
依序所示)
第一組：0.0005、0.0005、0.0005、0.0005、0.0005、0.0005、
0.0005、0.0005、0.0005、0.0005。
第二組：0.00005、0.0001、0.00015、0.0002、0.00025、
0.00075、0.0008、0.00085、0.0009、0.00095。
傳統方法假設 bj值 3
α值 0.5
我們可以計算出第一組封包到達速率的標準差為 0，而第二組的封包到達速率的標準
差為 3.7639e-004，很明顯地第二組各個工作站封包所產生的個數彼此相差很大，比較符合
實際的交通狀況，圖 6-23至圖 6-26將比較在這兩種不同的封包到達速率下所模擬的結果，
如下所示：
封
包
等
待
時
間
(i
n
μ
se
c)
圖 6-23 第一組數據下對於封包等待時間的關係圖
封
包
遺
失
率
(成
功
傳
送
封
包
/產
生
封
包
數
)
圖 6-26 第二組數據下對於封包遺失率的關係圖
圖 6-25與圖 6-26更說明適應性方法對於封包到達速率有著較為良好的表現，在變異量
小時(使用第一組數據)，除了使用 FIFS 的輪詢方式下，除非 CFP 佔 SI的最大比例可以超
過 50%，否則對於封包遺失率將比傳統的方法表現的還要差。但是若是在變異量大的時候
(使用第二組數據)，不論是使用何種的輪詢方式，CFP佔 SI的最大比例只要超過 30%時，
適應性方法將有更良好的表現。
在這節中，我們可以發現到封包到達速率對於這兩種方法的影響，無論是封包到達速
率的變異量大或是不大，適應性的方法均能對於這種環境去做調整，因此在封包等待時間
或是封包遺失率方面都將會有不錯的表現。傳統的方法因為 bj值的固定導致無法掌握各個
工作站佇列的狀況，因此在封包到達率差異大時，分配了不恰當的時間給各個工作站，是
導致其效能較為不佳的主要原因。
6.2.6 Remthreshold
在上一章曾提到有關殘餘封包考量的議題，因此在程式當中，設計了這個門檻值
(Remthreshold)，對於在免競爭週期結束之後，所有超過擁過 Remthreshold殘餘封包量的工
作站，HC將會在競爭週期中使用 CAP去服務它，而且給予的 CAP時間長度為剩餘的封包
各自擁有一次傳輸機會的時間。除此之外也計算了是否所有的 CAP 總和已經超過競爭週
期，若如此，則將剩餘量較少者優先扣減，每次扣減 1，若是扣減至小於門檻值時，則取
消此工作站之 CAP，直至確定不超過 CP的時間。
在決定這個門檻值的話，最主要的考量在於若是設計的太大，則大部分工作站所殘餘
下來的封包將無法被服務到。若是門檻值過小，則可能很容易超過 CP 的時間，最後也終
將是縮減各個工作站 CAP的時段。所以我們將由表 6.3的參數去做模擬，並且把原本預設
為 2的值從 1累加一直模擬至 4為止，如圖 6-27與 6-28所示：
TXOP 長度是一致的，因此在 bj值固定下對於免競爭週期其實為一個固定值，而我們若是
在適應性的方法之中，把 CFP佔 SI比例的上限調整至較大的比例時，則在比較上，因為適
應性方法擁有的 CFP時間比起比較的傳統方法更長，因此在對於語音的封包等待時間以及
封包遺失率上，適應性方法將會比起傳統方法有著更大的效能，因此在這節中我們將提出
一個兩種方法比較的基準點，表 6.6 為我們在計算傳統方法的 bj值之後，所佔用的時間比
上一個 SI(20ms)的比例，如下所示：
表 6.6： bj值佔 SI比例關係表
bj值 佔 SI的比例
3 24%
4 30%
5 36%
6 41%
7 47%
8 53%
9 59%
10 64%
11 70%
12 76%
因此接下來的實驗我們將把 bj值所對應到的比例，假設成適應性方法的 CFP 佔 SI 比
例的上限，兩者互相去做比較，也就是說，若是傳統方法的 bj值取 3的話，就與適應性方
法中 CFP 佔 SI 比例的上限為 24%的模擬數據做比較。如此一來至少可以使得兩者的 CFP
站在同一個基準點(時段長短一致)，達到某種程度上的公平性。圖 6-29 為使用表 6.4 的數
據下所產生的模擬結果，如下所示：
10000
11000
12000
13000
14000
15000
16000
17000
18000
3 4 5 6 7 8 9 10 11 12
傳統方法
適應性方法
a=0.6
適應性方法
a=0.1
適應性方法
a=0
適應性方法
a=0.2
適應性方法
a=0.3
適應性方法
a=0.4
適應性方法
a=0.5
適應性方法
a=0.7
適應性方法
a=0.8
適應性方法
a=0.9
封
包
等
待
時
間
(i
n
μ
se
c)
bj值
圖 6-29 在相同 CFP下傳統方法以及適應性方法的封包等待時間
圖 6-29的橫軸代表的是傳統方法所使用的 bj值,，同時也代表適應性方法所使用的 CFP
的時間。我們取 CAP 的方法是在模擬時間中數千個 SI 中，把各個 SI 中所花費掉的 CAP
時間去取平均值。我們得到，用傳統方法所平均使用的 CAP 為 9148.532μs，比較一個 SI
為 20ms，差不多佔 SI的比例為 45.7%。使用適應性方法平均所使用的 CAP為 8526.133μs，
佔 SI的比例為 42.6%。我們分別在加上兩種方法在所花掉的 CFP時間，得到傳統方法用來
服務這些語音封包所花掉的平均時間是佔 SI的 75.7%，適應性方法用來服務這些語音封包
所花掉的平均時間是則佔 SI的 62.6%。因此雖然適應性方法的封包等待時間以及封包遺失
率方面在限定 CFP 佔 SI比例上限為 20%的時候表現的比傳統方法 bj值取 4時還差，但是
傳統方法卻用了較多的時間去服務這些封包，因此這應該是會造成適應性方法效能上較為
不良的原因。
我們在比較考慮兩種方法在固定 CFP長度的時候，CAP分配的情形。我們分別取出傳
統方法 bj值為 4以及 5去與適應性方法 CFP佔 SI比例上限為 30%以及 36%去作比較，我
們測得傳統方法的平均CAP值分別為 9438.47μs以及 9103.181μs，適應性方法的平均CAP
值分別為 8582.395μ以及 8202.296μs。因此在固定 CFP佔 SI比例為 30%的時候，傳統方
法用來服務語音封包的時間差不多佔 SI的 77.2%，而適應性方法則為 72.9%。在固定 CFP
佔 SI比例為 36%的時候，傳統方法用來服務語音封包的時間差不多佔 SI的 76.67%，適應
性方法則為 72.62%。由圖 6-29與圖 6-30可知，即使在傳統方法使用較多的時間去服務這
些封包的時候，適應性的方法在大部份的情況還是表現的比傳統的方法還要好。
6.3結論
在本節中我們用了數種考量去比較傳統方法以及我們所提出的適應性方法，無論是在
完美通道、非完美通道，或是在封包到達速率或是 Remthreshold上造成的影響都在本章中
一一討論，最後我們則在公平性上對於兩種方法做比較，得到的結果為適應性方法的確在
封包等待時間上有改善，導致這些因素都是因為給定 TXOP 方法的不同而產生的，因此
TXOP 給定的方式的確會對於整體的效能有影響。下一章我們將會做本研究計畫的總結以
及未來的工作。
參考文獻
[1] I. Aad and C. Castelluccia, Differentiation mechanisms for IEEE 802.11, Proc. 20th Ann.
Joint Conf. of the IEEE Computer and Commun. Societies (INFOCOM 2001), pp.
209—218, 2001.
[2] P. Ansel, Q. Ni, and T. Turletti, A fair scheduling scheme for 802.11e WLAN, (French)
INRIA Research Report No. 4883, July 2003.
[3] F. Babich and L. Detto, Modeling and performance analysis of resource allocation
strategies for real-time service in UMTS using TIPPtool, Performance Evaluation, Vol.
50, pp. 101—128, 2002.
[4] A. Banchs and X. Perez, Distributed weighted fair queuing in 802.11 wireless LANs,
Proc.IEEE Int’l Conf. Commun., April 2002.
[5] D. Bertsekas and R. Gallager, Data Networks (2nd Ed.), Prentice Hall, 1992.
[6] L. Bononi et al., Power & QoS constrained networks: A differentiated distributed
coordination function MAC protocol for cluster-based wireless ad hoc networks, Proc.
1st ACM Int'l Wksp. Performance Evaluation of Wireless Ad Hoc, Sensor, and
Ubiquitous Networks, October 2004.
[7] P. T. Brady, A model for generating ON-OFF speech patterns in two-way conversation,
Bell Syst. Tech. Journal, Vol. 48, pp. 2445—2472, September 1969.
[8] D. Chen et al., Dependability enhancement for IEEE 802.11 wireless LAN with
redundancy techniques,” Proc. 2003 Int’l Conf. Dependable Systems and Networks, pp.
521—528, June 2003.
[9] D. Chiu and R. Jain, Analysis of the increase and decrease algorithms for congestion
avoidance in computer networks, Journal of Computer Networks and ISDN, Vol. 17, Jun
1989.
[10] S. Choi et al., IEEE 802.11e contention-based channel access (EDCF) performance
evaluation, IEEE Int'l Conf. Commun., Vol. 2, pp. 1151—1156, May 2003.
[11] J. del Prado Pavon and S. N. Shankar, Impact of frame size, number of stations and
mobility on the throughput performance of IEEE 802.11e, IEEE Wireless Commun. and
Networking Conf., Vol. 2, pp. 789—795, March 2004.
[12] S. K. Das, M. Chatterjee, and N. K. Kakani, ASACA: An adaptive service admission
control algorithm to guarantee delay constraints in integrated services packet networks,
Proc. IEEE Int’l Conf. Commun., Vol. 1, June 2001.
[13] C. Dou, Y.-J. Chen, and J.-Y. Wang, The performance study of contention-based
differentiation mechanisms in IEEE 802.11e MAC layer, 14th IEEE Proc. Personal,
Indoor and Mobile Radio Commun., Vol. 2, pp. 1415—1419, September 2003.
[14] H. Duong, A. Dadej, and S. Gordon, Proactive context transfer and forced handover in
IEEE 802.11 wireless LAN-based access networks, ACM Mobile Comput. and Commun.
Rev., 9(3):32—44, July 2005.
[15] A. Dugar, N. Vaidya, and P. Bahl, Priority and fair scheduling in a wireless LAN. Proc.
IEEE Military Commun. Conf. (MILCOM 2001), Commun. for Network-Centric
Operations: Creating the information force, Vol. 2, pp. 993—997, October 2001.
LANs supporting Voice over IP (VoIP) services, Wireless Commun. and Mobile Comp.,
December 2004.
[31] A. Ksentini et al., Routing and performance modelling: Adaptive service differentiation
for QoS provisioning in IEEE 802.11 wireless ad hoc networks. Proc. 1st ACM Int'l
Wksp. Performance Evaluation of Wireless Ad Hoc, Sensor, and Ubiquitous Networks,
October 2004.
[32] P. Kyasanur and N. Vaidya, Detection and handling of MAC layer misbehavior in
wireless networks, Proc. 2003 Int’l Conf. Dependable Syst. and Networks, pp. 173—182,
June 2003.
[33] L. Lamport, Specifying Systems: The TLA+ Language and Tools for Hardware and
Software Engineers, Addison Wesley Professional, 2002 (Available at http://
research.microsoft.com/users/lamport/tla/book-02-08-08.pdf)
[34] C.-M. Lin, Performance evaluation for IEEE 802.11e wireless Local Area Network
systems, Master thesis, National Chiao Tung University, June 2003.
[35] Y.-S. Lin, Optimization of call admission control in IEEE 802.11 WLAN
contention-free periods, Master thesis, National Taiwan University, July 2004.
[36] S.-C. Lo, G.-L. Lee, and W.-T. Chen, An efficient multipolling mechanism for IEEE
802.11 wireless LANs, IEEE Trans. Computers, 52(6):764—778, June 2003.
[37] S. Mangold et al., IEEE 802.11e - fair resource sharing between overlapping Basic
Service Sets, Proc. 13th IEEE Int'l Symp. Personal, Indoor and Mobile Radio Commun.,
Vol. 1 , pp. 166—171, September 2002.
[38] S. Mangold, IEEE 802.11e wireless LAN for quality of service, Proc. European
Wireless, Florence, Italy, February 2002.
[39] M. Muskin and I. Bar-David, Capacity and coding for the Gilbert-Elliot channels. IEEE
Trans. Information Theory, 35(6):1277—1290, November 1989.
[40] Q. Ni, L. Romdhani, T. Turletti, and I. Aad, QoS issues and enhancements for IEEE
802.11 wireless LAN, (French) INRIA Research Report No. 4612, November 2002.
[41] Q. Ni, L. Romdhani, and T. Turletti, A survey of QoS enhancements for IEEE 802.11
wireless LAN, Proc. Wireless Commun. and Mobile Comp., 2004.
[42] M. Ogawa, I. Shimojima, and T. Hattori, QoS guarantee control for wireless LAN, Proc.
IEEE 55th Vehicular Technology Conf. (VTC) 2002, pp. 50—54.
[43] L. Romdhani, Adaptive service differentiation for QoS enhancement in IEEE 802.11
wireless LANs, Ph.D Dissertation, Institut National de Recherche en Informatique et
Automatique, France, 2002.
[44] K. Sood et al., IEEE 802.11 TGr Just-In-Time Transition Acceleration Proposal
(JIT-TAP) Proposal, May 2005.
[45] TIPPtool Project, University of Erlangen-Nuremberg, Germany. (Available at http://
www7.informatik.uni-erlangen.de/tipp/)
[46] TLA+ Tools, Available at http://research.microsoft.com/users/lamport/tla/tools.html
[47] N. D. Tripathi, Generic Adaptive Handoff Algorithms Using Fuzzy Logic and Neural
Networks, Ph.D. Thesis, Department of Electrical and Computer Engineering, Virginia
Polytechnic Institute and State University, Aug 1997.
Multigroup Rekeying for a Wireless Network
Kuang-Hui Chi1, Ji-Han Jiang2, and Yu-Ching Hsu3
1 Department of Electrical Engineering, National Yunlin University of Science and
Technology, Taiwan
chikh@yuntech.edu.tw
2 Department of Computer Science and Information Engineering, National Formosa
University, Taiwan
3 Information and Communications Research Laboratories, Industrial Technology
Research Institute, Taiwan
Abstract. In the context of secure group communication, a shared se-
cret key is generated anew for data protection whenever group mem-
bership changes. This paper presents an approach to fast rekeying in
a wireless network that is subject to time-varying channel conditions.
We address a scenario where a station joins one group at a time, but
may leave multiple groups at once for abrupt link failure or cascading
application termination. In our architecture, each station is assigned a
private number and a code, so as to exploit Fermat’s Little Theorem
and an orthogonal coding methodology, respectively. The former is used
to protect the delivery of updated group keys, while the latter to en-
code keying material meant for diﬀerent sites in an aggregate form as a
payload for message distribution. Since rekeying messages are delivered
via multicast, intended stations can decode information of interest at
the same time. Therefore rekeying among multiple groups can still be
carried out timely with O(1) message complexity. Our design provides a
complementary facility to current schemes for performance improvement.
Pragmatic considerations of our approach are discussed as well.
1 Introduction
Secure group communication is generally accomplished by using a shared cryp-
tographic key for data protection. For forward and backward secrecy, however,
a rekeying process is performed whenever group membership changes. As far
as a wireless network is concerned, group membership is likely to change over
time due to link outage on account of radio signal characteristics or user’s mo-
bility. Such network dynamics may cause frequent group rekeyng, at the cost of
repeated message exchanges taking nontrivial delay. This gives rise to an out-
of-sync problem between keys and data [9] or disruptions of message delivery
among communicating parties. In addition, group keys are generally meant for
 This work was supported by the National Science Council, ROC, under grants NSC
95-2221-E-224-016-MY2 and NSC 95-2622-E-150-035-CC3, and by the Ministry of
Economics, ROC, under the grant 6301XS2430.
T. Enokido, L. Barolli, and M. Takizawa (Eds.): NBiS 2007, LNCS 4658, pp. 147–156, 2007.
c© Springer-Verlag Berlin Heidelberg 2007
Multigroup Rekeying for a Wireless Network 149
Group Key
Controller (GKC)
Station
Communication group
Point of attachment
to the network
Data traffic
Fig. 1. An architecture of n wireless stations under common management of some
GKC. Stations enclosed by dashed lines represent participants of a same group.
Group ID/Bitmap Key Material (encrypted)Flag
Fig. 2. Format of group rekeying information
are mainly concerned with regional communication activities such as in a local
area network or on a campus. The local network, however, can be part of group
communication that spans on the Internet.
2.1 Preliminaries
In our architecture, the GKC maintains a large prime pi for each station i ∈
{1, 2, · · · , n}. Such a prime is unique, i.e., pi = pj if i = j. To join a group, each
station i authenticates with the GKC for admission whereby pi can be derived
from mutual authentication methods, say, over the IEEE 802.1X Extensible Au-
thentication Protocol (see the appendix.) As can be seen shortly, pi speciﬁc to
a station i is used to compute shared secret keys for groups to which i belongs.
Besides, the GKC needs to detect departures of stations per group somehow,
probably through explicit notiﬁcations by stations or timeout of periodic reau-
thentications. Hence the GKC is assumed knowledgeable about each station in
its administrative domain involved in which group(s).
Since two or more stations can form a group, a station may participate in
multiple groups. We address a common scenario where a station joins one group
at a time, but may leave several groups at once (possibly out of abrupt link failure
or cascading application terminations.) Whenever group membership changes,
the GKC generates rekeying information as in Fig. 2 toward intended stations
via multicast or link-scoped broadcast. The ﬁrst ﬁeld (Flag) valued either 0 or 1
indicates whether to interpret the second ﬁeld as a group identity or a bitmap.
The former is used when a station joins some group, whereas the latter relates
to simultaneous departures of a station from multiple groups. A bitmap keeps
track of which groups require rekeying. Each group is indicated by a bit in the
Multigroup Rekeying for a Wireless Network 151
allows correct stations to extract K1 by using arithmetic modulo their respective
private numbers as in (1). Stations without holding correct private numbers can
hardly decrypt M because factoring a big number is hard.
As a note, the rekeying message in the join protocol can grow in proportion
to group size. For instance, for a group involving all the n stations, the length of
Key Material amounts to |p1p2 · · · pn| ≤ |p1|+ |p2|+ · · ·+ |pn|, where |pt| denotes
the number of bits in use to represent the integer pt, t = 1, 2, · · · , n. However,
as far as a local area network is concerned, its accommodated membership of a
group is generally not large. This implies that our protocol does not suﬀer such
potential limit in most cases. Alternatively, the problem can be dealt with by
selecting group keys and private numbers associated with new stations properly.
In words, when a station k is about to join the group (K0 being the original
group key), the GKC resolves a new group key K1 and a nonce r′ such that K1
is smaller than and relatively prime to both Kα0 and pk. The integer exponent α
(α > 1) is introduced here to generate a larger value Kα0 to expand the range of
choosing K1. Letting α be 2, the GKC sets M = K
1+r′(K20−1)(pk−1)
1 mod K
2
0pk
for distribution. All stations of the original group holding the key K0 will thus
be able to decrypt M to ﬁnd K1 by performing M mod K20 similarly to (1).
Meanwhile, station k performs M mod pk. In this manner, the rekeying message
carries ciphertext M encoded by the original group key and another new private
number, keeping modulo operations irrespective of group size. Therefore, even
though there are n stations to rekey, the rekeying message is restricted to an
order of 2|K0|+ |pk| in length.
2.3 Leaving Multiple Groups
When a station, say j, with membership of more than one group departs from the
system, immediate departures from multiple groups occur. Suppose that j par-
ticipated in a set Gj of groups. Upon detecting such a leave, the GKC generates
a new pair of K2 and r′′, and instructs aﬀected groups to change their secret
keys. Considering stations belonging to any group in Gj , K2 is selected to be
smaller than and relatively prime to private numbers of these stations, whereas
r′′ is not a multiple of (pj − 1). The GKC proceeds to send a rekeying message
carrying 1 in the Flag ﬁeld, a suitable Bitmap ﬁeld (see the next subsection),
and M = K1+r
′′Π(pt−1)
2 mod Πpt in the Key Material ﬁeld, where pt denotes
the private number of each station other than j participating in some group(s)
of Gj . This enables each intended station (ruling out j) to decrypt M as in (1),
and then uses the received Bitmap to locate which group(s) in its membership
requires rekeying by means of the obtained K2.
As an example shown in Fig. 3(c), let i and k be such stations involved in
diﬀerent groups of Gj . Provided a group key K1 in use by i, the station computes
its new key for that group as K1⊕K2 (exclusive OR operations of K1 with K2.)1
1 In general, a one-way hash function f can be employed that yields the new group
key as f(K1, K2). This ensures that only a member in possession of K2 can obtain
the updated group key.
Multigroup Rekeying for a Wireless Network 153
Table 1. Complexity results of selected schemes (in the case of |b| groups involved)
Communication Computational
Chang et al.’s scheme [4] O(|b| log n) O(|b| log n)
Mittra’s scheme [10] O(|b|n) O(|b|)
Wong et al.’s scheme [14] O(|b|n) O(|b|n)
Our scheme O(1) O(1)
and computational aspects. The former measurement index refers to how many
rekeying messages are generated, while the latter the number of key encryp-
tions/decryptions during transmission. Table 1 compares corresponding results
in the case of |b| groups. To gain a fairer basis for comparisons, our GKC is
likened to the group controller in Chang et al’s scheme [4], a group security
intermediary in Mittra’s scheme [10], or the key server of a star key graph in
Wong et al’s scheme under the group-oriented rekeying paradigm [14]. (Another
paradigm—a tree key graph—in Wong et al’s scheme has similar complexities to
Chang et al.’s scheme.) Note that conventional rekeying schemes operate mostly
on per-group basis, so their incurred costs can grow linearly with the involve-
ment of more groups. In contrast, the proposed scheme allows for multigroup
rekeying with O(1) message complexity, such as to complete rekeying faster.
A side eﬀect of our scheme is that a rekeying message might appear lengthy
due to carrying excess bitmaps or key material indicative of a large number of
stations to rekey. However, the side eﬀect will arguably become less prominent
if the bitmap length |b| or the number n′, 1 ≤ n′ ≤ n, of stations involved in
rekeying can be maintained. To see this, observe that our Bitmap ﬁeld contains
b1c˜1+b2c˜2+· · ·+bnc˜n = 〈
∑n
i=1 bici[1],
∑n
i=1 bici[2], · · · ,
∑n
i=1 bici[L]〉. Since each
bi ranges from 0 to 2|b|−1, every element of the L-tuple sums up to n(2|b|−1),
which can be represented using |b|+logn bits. Thus, the Bitmap ﬁeld occupies
at most L(|b|+logn) bits. Concerning the best-known counterpart scheme whose
rekeying message containing per-group identity and key material is delivered to
stations, in the event that a group identity indicates a 128-bit IPv6 address (as
deﬁned by RFC 4291), there will totally require |b|(|H |+128+|M | logn) bits in
a message, where |H | and |M | denote the number of bits in the message header
(plus message trailer) and key material M , respectively. Relating the bit count
of our rekeying message to that of the counterpart scheme, we ﬁnd that the
inequality |H |+1+L(|b|+logn) + n′|M | ≤ |b|(|H | +128+ |M | logn) holds if
|b| ≥ (|H |+1+L logn+n′|M |)/(|H |+128+|M | logn−L). The condition implies
that maintaining the bitmap length |b| or n′ can ensure our approach to incur
comparatively less message space, although our key material is n′ times the size
of key material in the counterpart scheme.
For example, given that |H | is 224 in an IEEE 802.11 network, L=n, |M |=
128, n′=n/2 on average, and n=10, we have |b|≥1.86. In other words, when a
station belonging to more than two groups departs from the system, our proposed
approach would outperform counterpart schemes in terms of communication
complexity as well. Under the prescribed parametric setting, it is further deduced
Multigroup Rekeying for a Wireless Network 155
5. Eronen, P., Hiller, T., Zorn, G. (eds.): Diameter Extensible Authentication Protocol
(EAP) application, RFC 4072, IETF Network Working Group (2005)
6. IEEE Std 802.11i, IEEE Standard for Telecommunications and Information Ex-
change between Systems—LAN/MAN Speciﬁc Requirements—Part 11: Wireless
Medium Access Control (MAC) and Physical layer (PHY) speciﬁcations. Amend-
ment 6: Medium Access Control (MAC) security enhancements (2004)
7. Kim, Y.: Group key agreement—theory and practice, Ph.D. Thesis, Department
of Computer Science, University of Southern California, USA (2002)
8. Kim, H., Hong, S.-M., Yoon, H., Cho, J.W.: Secure group communication with
multiplicative one-way functions. In: Proc. Int’l Conf. Info. Technology, pp. 685–
690 (2005)
9. Li, X.S., Yang, Y.R., Gouda, M., Lam, S.S.: Batch rekeying for secure group com-
munications. In: Proc. Int’l World Wide Web Conf. pp. 525–534 (2001)
10. Mittra, S.: Iolus: A framework for scalable secure multicasting. In: Proc. ACM
Conf. Applications, Technologies, Architectures, and Protocols for Computer Com-
mun. pp. 277–288. ACM, New York (1997)
11. Moharrum, M., Mukkamala, R., Eltoweissy, M.: Eﬃcient secure multicast with
well-populated multicast Key trees. In: Proc. 10th Int’l Conf. Parallel and Dis-
tributed Systems, pp. 215–222 (2004)
12. Rigney, C., Willens, S., Rubens, A., Simpson, W.: Remote Authentication Dial-In
User Service (RADIUS), RFC 2865, IETF Network Working Group (2000)
13. Steiner, M., Tsudik, G., Waidner, M.: CLIQUES: A new approach to group key
agreement. In: Proc. 18th Int’l Conf. Distributed Computing Syst. pp. 380–387
(1998)
14. Wong, C.K., Gouda, M., Lam, S.S.: Secure group communications using key graphs.
IEEE/ACM Trans. Networking 8, 16–30 (2000)
15. Yang, C., Li, C.: Access control in a hierarchy using one-way hash functions. Com-
puters & Security 23, 659–664 (2004)
A Appendix
As mentioned in Sect. 2, each station i shares a unique prime pi with the GKC.
This appendix exempliﬁes the provision of such primes in an IEEE 802.11i net-
work. IEEE 802.11i specifying security enhancements to an IEEE 802.11 net-
work, can be viewed to consist of two levels. On the lower level are encryption
protocols known as the temporal key integrity protocol (TKIP) and the counter
mode with CBC-MAC protocol (CCMP.) (CBC-MAC stands for cipher-block
chaining with message authentication code.) Overlying TKIP and CCMP is
IEEE 802.1X—a framework for authentication and key material distribution.
IEEE 802.1X allowing for various authentication methods over the Extensible
Authentication Protocol (EAP) [1], entails mutual authentication between a
station and a backend Authentication Server. As illustrated in Fig. 4, EAP
messages carrying upper-layer authentication information are encapsulated in
EAP over LAN (EAPOL) frames for wireless transport and in the Diameter
protocol on the wired side, respectively. Here the AP (access point) acts as
a transit entity to relay authentication messages. Diameter operates using a
general-purpose message header plus an extensible collection of Attribute Value
Pairs indicating application-speciﬁc commands. For synergy use of Diameter
