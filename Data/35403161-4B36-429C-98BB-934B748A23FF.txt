中文摘要 
 在近幾年當中，基於視覺影像與統計學習方法的人機介面 (Human-Computer 
Interfaces；HCIs )，其相關研究越來越引人注目。由於手勢是一種最直接和最方便的輸入
方式，使得它的應用範圍日益廣泛。常見的應用包括有取代傳統的鍵盤和滑鼠輸入、在虛
擬實境中作為控制輸入器、或輔助聾啞人士進行交互溝通等。 
本研究提出一基於 Gabor Filter + SVM 的方法來進行手勢識別。本研究之目的在於提
出(1)適應性膚色模型選擇方法，以解決光線變化的問題；(2)手勢角度估算與校正方法，
以解決手勢旋轉的問題；(3)手勢與手臂分割方法，以增加使用者穿著衣物(短袖或長袖)之
彈性。透過以上問題的解決，本研究確實可以提昇手勢識別之強健性。 
 採用 Gabor Feature 做為手勢特徵描述的方法，其手勢識別率遠高於僅採用原始手勢
影像之識別率，在所採用的 3 種分類器中，又以支持向量機(SVM)之手勢識別率最高。針
對靜態手勢資料庫的識別試驗中，當應用 Gabor Filter 來表示手勢時，歐氏距離的識別率
在特徵數量為 35 時可得到 93.0％，餘弦距離的識別率在特徵數量為 113 時可得到 94.0％，
但支持向量機的識別率在特徵數量為 103 時卻可得到 96.1％之水準；經比較沒有經過
Gabor Filter 變換之原始影像，歐氏距離的識別率在特徵數量 25 時僅為 80.0％，餘弦距離
的識別率在特徵數量 35 時亦為 80.0％，至於 SVM 分類器的識別率在特徵數量 29 時可得
到 86.4％；由實驗結果得知採用 Gabor Feature＋SVM 可以獲得最好的手勢識別結果。  
    在動態手勢偵測方面，本研究所發展的即時手勢偵測與識別系統亦能有效地識別出各
種旋轉角度下之正確手勢。本系統每幀影像處理時間約為250ms，大部分時間花在適應性膚
色偵測上。另外，透過一系列動態視訊影像之檢測，在動態手勢識別時，分別對穿著長袖
衣物和穿著短袖衣物進行實驗，當穿著短袖時，在270幀中成功辨識出252幀，SVM辨識率
為93.3％；當穿著長袖時，在300幀中成功辨識出282幀，SVM辨識率為94％。 
 
關鍵詞：手勢識別、Gabor Feature、主分量分析法、支持向量機 
英文摘要 
 Human-Computer Interfaces (HCIs) based on visual image and statistical learning method 
have attracted more attention in the last decade. Because of its accessibility and convenience, 
hand gestures are widely adopted in a large number of HCI’s applications. For instance, it can 
replace conventional keyboard and mouse as an input for computers, or as a controller in virtual 
reality or as an auxiliary communication way for the deaf-and-dumb community. 
 The effect of hand-pose orientation on recognition rate is greatly significant. In this study, 
we proposed a module called “hand-pose angle estimation and correction,” which can 
effectively overcome the difficulties of hand gestures with various angles. In addition, this 
module can also correct the hand gestures to an acceptable small angle. In this work, we used 
Gabor feature as a hand gesture descriptor, and then adopted PCA for feature extraction to 
reduce the dimensionality of Gabor features. Furthermore, three classifiers including Euclidean 
distance, cosine distance, and SVM are employed for hand-gesture classifications. 
 Experimental results show that the recognition rates of Gabor-filtered images are higher 
than those of raw images. Among the three classifiers, the SVM classifier achieves the highest 
recognition rate for both with and without Gabor-filtered images. For static hand gestures on our 
own database, the result reveals that the combination of Gabor-filtered image with the SVM 
因此這個方法還是會受到不同視角的影響，因此本方法在應用上還是有其侷限性。 
 Chen 等人[3,4]為了解決猜拳遊戲(剪刀、石頭與布)中多角度的手勢辨識問題，採用三
台攝影機自前方、左方與右方分別取得手勢影像，接著將所取得的影像資料用來訓練三個
支持向量機分類器，待訓練完成後，再透過資訊融合的方式，以識別出猜拳遊戲中的手勢
變化。最後實驗結果顯示：前方攝影機之辨識率為 73.3%，左方與右方攝影機則分別為
87.5%與 92.5%。此方法雖解決多重視角的問題，但由於背景單純，再加上識別的手勢僅
有 3 種，使得整個問題簡化不少，但若應用在複雜背景下，或增加更多不同的手勢時，此
方法之強健性仍有待考驗。 
 Qing Chen等人[5,6]提出Haar-Like Feature+SCFG (Stochastic Context-Free Grammar)組
合而成的二階段式即時手勢辨識系統。首先利用 Haar-Like Feature+Adaboost Algorithm 來
找出手勢位置與辨識手勢，接著利用第二階段的 Stochastic Context-Free Grammar 方式，
利用其所產生的規則，找出輸入一連串手勢後所代表的意義，雖然此方法能夠快速的偵測
出手勢的位置與其代表的意義，但是由於識別的手勢只有 4 種並且皆為單純的白色背景，
而其容忍手勢旋轉的角度只能為±15°。 
 此外由於手勢的分類是透過學習過程來完成，所以用來訓練的影像數量是相當重要
的。因此，Chen等人[7]採用2,000張影像序列，其中包含20個不同手勢與20個不同的個人，
使用隱馬可夫模型可達成90.5%的辨識率；若再搭配傅利葉描述子(Fourier Descriptor)的總體
不變性與運動特徵，辨識率可再往上提昇至93.%。 
 Amin等人[8]採用Gabor-PCA作為特徵擷取的方式，並利用Hough Transform的方式來
作為手勢旋轉校正之前處理步驟，接著利用Fuzzy C-Mean來做為分類的方法，針對America 
Sign Language(ASL)內的26個字母來進行辨識，結果平均辨識率可達93.23%，但對於相似
的字母其辨識率偏低。由於本方法手勢變化不大，同時也無法達到即時偵測與辨識的功能。 
 
(四) 研究方法 
 
 本研究主要是使用自行開發的前處理單元，其包含以下3個模組：(1)適應性膚色模型切
換方法；(2)基於Gabor Feature的手勢角度估算與校正方法，與(3)手部切割方法。由於採用
Gabor Feature來做為表示手勢的方法，所以必須結合主分量分析法來進行特徵降維，最後
再利用支持向量機來進行手勢分類(見圖一)。本文將同時比較歐式距離、餘弦距離與SVM
等分類器在手勢辨別上的優劣點。 
 
圖一、本文所提手勢識別方法流程圖 
 
    3
 圖四、適應性膚色模型選擇流程圖 
 
圖五、(a)原圖；(b)紅色框為經過適應性膚色模組選擇後之結果 
 
4.3 基於Gabor Filter之手勢角度估算與校正方法 
 
由於在一般的情形下，使用者作出的手勢，都會有不同程度的歪斜情況發生，若是直
接對這些歪斜手勢進行識別，通常錯誤率會比較大。因此，為了解決手勢歪斜導致辨識率
下降之問題，本研究提出一基於 Gabor Filter 之手勢角度估算與校正方法。其具體步驟如
下(見圖六)： 
(1) 進行影像二值化並擷取出手勢區域；緊接著，將分割出來的影像縮小至 20*20 像素，
並與 Gabor Filter 進行迴旋積，其中 Gabor Filter 設定之參數如下： 785.0=γ ，
θ ∈{0o , 90o , 72o , 45o , 36o , 72o− , 45o− , 36o− }，與 { }3,2,1=σ 。 
(2) 計 算 各 個 旋 轉 角 度 內 所 產 生 Gabor Filters 的 平 均 灰 階 值 ， 亦 即 
3
1 1 1
1 ( , )
3
w h
k
j x y
i x y
wh
γ
= = =
⎛ ⎞= ⎜ ⎟⎝ ⎠∑ ∑∑ ，其中 { }1,  2, ,  8k ∈ " ，而  w and h 分別表示影像的寬與高。 
(3) 將 { }0 ,36 ,45θ = ° ° ° ; { }36 ,45 ,72θ = ° ° ° ; { }45 ,72 ,90θ = ° ° ° ; { }0 , 36 , 45θ = ° − ° − ° ;  
    5
    7
(五) 結果與討論 
 
 首先針對靜態手勢資料庫進行本文所提方法之驗證。本實驗的訓練影像與測試影像分
別有660張，其中包含各種旋轉角度之手勢影像，且訓練與測試影像不重複。圖八表示原始
影像手勢識別率與所取特徵數之關係，由圖中可知，當所取特徵數高於15時，手勢識別率
以SVM分類器最好，其中當特徵數等於29時，其識別率達最大為86.4%。反之，當利用Gabor 
filter來表示手勢特徵時，其手勢識別率明顯高於原始圖像(見圖八)，其中當特徵數等於103
識別率可達到96.1%之水準(見圖九)。由此可知，Gabor filter具有擷取手
特徵之最大鑑別能量。 
時，SVM分類器的
勢
 
 圖八、採用原始影像之手勢識別結果     圖九、採用Gabor-filtered Image之手勢識別結果 
 
將以上結果總結於表一。由表中可知：不論採用何種分類器，利用Gabor filter來表示手
勢特徵，其識別率皆高於原始手勢影像，最大者並可高出13％左右。在使用的3種分類器中，
以SVM分類器的結果為最好。其中在採用Gabor filter的情況下，特徵數量為103時辨識率為
96.1%；而在未採用Gabor filter的情況下，當採用特徵數量為29時，其辨識率為86.4%。 
 
表一、不同分類器下 Raw image 與 Gabor-filtered image 之最高辨識率 
  Raw image 
(20×20 pixels) 
Gabor-filtered image 
(160×100 pixels) 
  辨識率(%) 特徵數量 辨識率(%) 特徵數量 
Euclidean Distance  80.0  25  93  35 
Cosine Distance  80.0  35  94  113 
SVM (C=3, γ=0.9 for Raw image) 
SVM (C=2, γ=0.125 for Gabor-filtered image)  86 29   .4  96.1  103
 
本文亦實現動態手勢識別系統，其結果如圖十
著長袖衣服與穿著短袖衣服進行試驗。在有使用手勢旋 組下：當 短袖時 0
幀中成功 分類器的辨識率為93.3％；當穿著長袖時，在300幀中成功辨
識出282幀，SVM分類器的辨識率為94.0 93.7%。當系統沒有採用手
所示。針對動態手勢識別，分別針對穿
轉模 穿著 ，在27
辨識出252幀，SVM
％，因此平均識別率為
    9
 
ds,” IEEE transactions on pattern analysis and 
Vol. 23, No. 12, pp. 1449-1453, 2001. 
[3] Y. T. . Tseng, “Multiple-angle hand gesture recognition by fusing svm 
ecognition system 
me vision-based hand gesture 
. Amin, and H. Yan, “Sign language finger alphabet recognition from gabor-pca 
 
s, and M. Strintzis, "Comparison of 2d and 3d 
Bouzerdoum, “A Bayesian approach to skin color classification in YCbCr 
t packet analysis,” IEEE Transactions on Multimedia, Vol. 1, No. 3, pp. 264-277, 
參考文獻
[1] J. Triesch and C. von der Malsburg, “Robust classification of hand postures against 
complex backgrounds,” In: Proceedings of the IEEE Int. Conf. on Automatic Face and 
Gesture Recognition, pp. 170-175, Killington, Vermont, USA, Oct. 1996. 
[2] J. Triesch and C. Von Der Malsburg, “A system for person-independent hand posture 
recognition against complex backgroun
machine intelligence, 
 Chen, and K. T
classifiers,” In: Proceedings of IEEE conference on Automation Science and Engineering, 
pp. 527-530, Scottsdale, AZ, USA, Sep. 2007. 
[4] Y. T. Chen, and K. T. Tseng, “Developing a multiple-angle hand gesture r
for human machine interactions,” In: Proceedings of the 33rd Annual Conference of the 
IEEE Industrial Electronics Society (IECON), pp. 489-492, Taipei, Taiwan, Nov. 5-8, 2007,. 
[5] Q. Chen, N. D. Georganas, and E. M. Petriu, “Real-ti
recognition using haar-like features,” In: Proceedings of IEEE Instrumentation and 
Measurement Technology Conference Proceedings, pp. 1-6, Warsaw, Poland, May 1-3, 
2007 
[6] Q. Chen, N. D. Georganas, and E. M. Petriu, “Hand gesture recognition using Haar-like 
features and a stochastic context-free grammar,” IEEE Transaction on Instrumentation and 
Measurement, Vol. 57, No. 8, Aug 2008. 
[7] F. S. Chen, C. M. Fu, and C. L. Huang, “Hand gesture recognition using a real-time 
tracking method and hidden markov models,” Image and Vision Computing, Vol. 21, No. 8, 
pp. 745-758, Aug. 2003. 
[8] M. A
represention of hand gestures,” In: Proceedings of the Sixth International Conference on
Machine Learning and Cybernetics, Hong Kong, August 19-22, 2007 
[9] A. Caplier, L. Bonnaud, S. Malassioti
analysis for automated cued speech gesture recognition," In: Proceedings of the 9th 
International Workshop on Speech and Computer (SPECOM '04), Saint-Petersburg, Russia, 
September 2004. 
[10] R. L. Hsu, M. A. Mottaleb, and A. K. Jain, “Face detection in color image,” IEEE 
Transactions on Pattern Analysis and Machine Intelligence, Vol. 24, No. 5, pp. 696-706, 
2002. 
[11] C. Garcia, and G. Tziritas, “Face detection using quantized skin color regions merging and 
wavelet packet analysis,” IEEE Transactions on Multimedia, Vol. 1, No. 3, pp. 264-277, 
1999. 
[12] D. Chai, and A. 
color space,” In: Proceedings of TENCON, Vol. 2, pp. 421-424, 2000. 
[13] C. Garcia, and G. Tziritas, “Face detection using quantized skin color regions merging and 
wavele
    11
際期刊來進行發表。本研究總計發表2篇國際研討會論文，與產
出一篇SCI等級的論文(已投稿至Expert Systems with Applications)(請參見論文發表列表)，因
此本
能有效地提昇手勢識別率。根據以上結果，本研究方法確實極具學術與應用價值，其成果
當然適合於國際研討會與國
研發成果不論在質與量都有相當長足的進步。 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Vision-based Hand Gesture Recognition Using PCA+Gabor Filters and SVM 
 
Deng-Yuan Huang1, Wu-Chih Hu2, Sung-Hsiang Chang3 
1,3Department of Electrical Engineering, Da-Yeh University 
1kevin@mail.dyu.edu.tw, 3r9603025@mail.dyu.edu.tw 
2Department of Computer Science and Information Engineering, National Penghu University 
wchu@npu.edu.tw
 
 
Abstract—In this paper we present a novel method for hand 
gesture recognition based on Gabor filters and support vector 
machine (SVM). Gabor filters are first convolved with images 
to acquire desirable hand gesture features. The principal 
components analysis (PCA) method is then used to reduce the 
dimensionality of the feature space. With the reduced Gabor 
features, SVM is trained and exploited to perform the hand 
gesture recognition tasks. To confirm the robustness of the 
proposed method, a dataset with large posed-angle (>45 deg.) 
of hand gestures is created. The experiment result shows that 
the recognition rate of 95.2% can be achieved when SVM is 
used. A real-time video system for hand gesture recognition is 
also presented with a processing rate of 0.2 s for every frame. 
This result proves the efficiency and superiority of the 
proposed Gabor-SVM method. 
Keywords-gesture recognition; Gabor wavelet; SVM; PCA 
I.  INTRODUCTION 
Hand gesture has become an important application in 
vision-based human-computer interfaces (HCIs) for the past 
decades because the traditional HCI input devices, such as 
mice and keyboard, cannot quickly respond to currently 
complicated interaction systems. For hearing impaired 
community, the development of automatic gesture translation 
based natural languages (e.g. the American Sign Language; 
ASL) is highly expected to improve their communication 
means among humans. For the recognition system of hand 
gestures based on images or videos, the posed-angle of 
gestures taking by a camera/webcam can usually be a critical 
factor in determining the effectiveness of the recognition 
systems. 
Triesch and Malsburg [1] applied the method of elastic 
bunch-graph matching (EBGM) to the classification of hand 
postures for grayscale images. For EBGM method, the jets 
are described as vectors based on a 2D Gabor-wavelet 
transform. The results showed that their system can reach 
86.2% recognition rates against complex background. This 
approach can achieve user-independent and scale-invariant 
recognition. However, this method is not view-independent 
and is computational inefficiency due to the matching 
process. 
Chen and Tseng [2] proposed a multi-angle hand gesture 
recognition system for finger guessing games. To cope with 
various angles for hand gestures, they used three webcams 
set at front, left, and right directions of hand to capture 
gesture images. Then, three SVM classifiers are trained using 
the images acquired from the three cameras. After the 
training process, the constructed classifiers were fused by 
one voting and two plans of fusion to decide the gesture. The 
recognition rates of their system for the front, left, and right 
classifiers are 73.3%, 87.5%, and 92.5%, respectively. 
However, only 3 hand gestures were used in their work. 
Amin and Yan [3] used PCA and Gabor filters to 
recognize the American Sign Language (ASL) finger 
alphabets from hand gesture images. The classification is 
then conducted with a method of fuzzy-c-mean clustering. 
The experimental results showed that the recognition rate of 
the ASL alphabets with average 93.23% accuracy can be 
achieved. However, the recognition rate of similar alphabets 
is relatively low in their approach. 
In the past decade, the Gabor features have been 
successfully used in the fields of hand gesture and face 
recognitions [3,4]. However, Gabor features employed are of 
too high dimensionality to be used effectively. We proposed 
to deal with this problem by the PCA method to reduce the 
dimensionality of the feature space. The classification of 
hand gestures is then performed by the SVM method. 
Finally, a real-time video system on hand gesture recognition 
is presented. 
The remainder of the paper is organized as follows: In 
Section 2, we describe how to construct the dataset of hand 
gestures and briefly outlines the methods of extracting the 
hand gesture features, followed by sketching the method of 
SVM. In Section 3, we present our experiment results. 
Finally, Section 4 gives a conclusion and some suggestions 
for future work. 
II. SYSTEM DESCRIPTION 
This section consists of the major components such as 
image capturing and preprocessing, feature extraction and 
classification of hand gestures. A brief description is 
provided in the subsequent sections. 
A. Image Capturing and Preprocessing 
Some critical factors such as lighting condition, posed-
angle and scale variability of hand gesture should be 
considered while collecting images for hand gesture 
recognition. The images of 11 hand gestures (see Fig. 1) for 
training and testing were collected with the same colored 
background by 10 signers, and each signer was requested to 
sign the same hand gesture 12 times; each time from a 
different angle and position. In order to verify the 
classification capability, the hand was cropped manually and 
resized to 20*20 pixels at the initial stage of the experiment. 
Fig. 2 shows that the pose of hand gestures with small angles 
2009 Fifth International Conference on Intelligent Information Hiding and Multimedia Signal Processing
978-0-7695-3762-7/09 $26.00 © 2009 IEEE
DOI 10.1109/IIH-MSP.2009.96
1
2) Principal component analysis (PCA): The method of 
PCA [7] is a popular dimensionality reduction technique 
with the goal to find a set of orthonormal vectors in the data 
space, which can maximize the data’s variance and map the 
data onto a lower dimensional subspace spanned by those 
vectors. 
Consider a dataset with M images Nix   
belonging to C subjects, and N is the number of pixels in the 
image. The total scatter matrix N NT ∈ℜ is defined as 
∈ℜ
×
( 1, ,  )i =  M
AA
S
 
 (3) ( )( )
1
M T T
T i ii
S x xμ μ
=
= − − =¦
where ȝ is the global mean image of the training set, 
and [ ]1 N MMA x xμ μ ×= − − ∈ℜ . 
A direct computation of ST is impractical due to the huge 
size of the matrix. Instead of direct finding the 
eigenvector WPCA of ST, we solve the eigenvalue 
problem, , to obtain the eigenvectors, 
N N×
PCA PCARV V= Λ
M P×∈ ℜPCAV , and the eigenvalues, [ ]1 P PPdiag λ λ ×Λ = ∈ℜ
0Pλ > iλ
(T M M
, 
with decreasing order  , where  is the 
nonzero eigenvalue of the matrix 
1λ ≥ ≥
)R A A M N×= ∈ℜ  . 
Then, the PCA subspace WPCA is formed by multiplying the 
matrix A with the eigenvectors VPCA, that is, 
N PV ×∈ℜPCA PCA  . Therefore, the feature vector y of an 
image x is acquired by projecting x into the coordinate 
system defined by the PCA subspace, that is 
W A=
 
 (4) ( )TPCAy W x μ= − ∈ Pℜ
)
C. Classification of Hand Gestures 
In principle, one SVM classifier searches for an optimal 
hyperplane that maximizes the margins of their decision 
boundaries to ensure that their worst-case generalization 
errors are minimized, which is known as “structural risk 
minimization (SRM).” 
To perform the classification between two classes, a 
nonlinear SVM classifier is applied by mapping the input 
data ( ,i ix y  into a higher dimensional feature space using a 
nonlinear operator ( )xΦ , where anddix ∈ℜ { }1, 1iy ∈ + − . 
Therefore, the optimal hyperplane can be computed as a 
decision surface 
 ( ) sgn ( , )i i i
i
f x y K x xα§= ©¨¦ b
·
+ ¹¸  (5) 
where represents the sign function, and sgn( )
 ) (i( , ) ( )
T
iK x x xΦx= Φ is the predefined kernel function 
that satisfies Mercer’s condition [8]. In this research, the 
radial basis function (RBF) is used and it is defined as 
follows 
 ( )2( , ) exp ,  0i iK x x x xγ= − − >γ  (6) 
where γ=0.25. The coefficients  and in (5) can be 
determined by the following quadratic programming (QP) 
problem 
iα b
 
,
1max ( , )
2
. . 0
0 ,  
i i j i j i
i i j
i i
i
i
y y K x x
s t y
C i
α α α
α
α
j
ª º« »−« »¬ ¼
=
< < ∀
¦ ¦
¦  (7) 
The parameter C is a penalty that represents the tradeoff 
between minimizing the training set error and maximizing 
the margin, where  is determined empirically. Since 
the SVM is a binary classifier, it should be extended for an 
m-class problem in hand gesture recognition. We used the so 
called one against one approach, which is a pairwise method 
and needs to train SVM classifiers. In addition, 
another two distance measures, i.e., Euclidean distance and 
Cosine similarity distance, are also computed to make a 
comparison with the SVM method. 
8=
( 1m m −
C
) / 2
III. RESULTS AND DISCUSSION 
The dataset of hand gesture images was classified as a 
training set and a testing set, for which data set has 
6*11*10=660 images (3 small angles and 3 large angles data 
selected randomly from each of the 10 signers for 11 hand 
gestures). The image of hand gesture was first convolved 
with Gabor filters to form a Gabor-coded image. The data of 
40 filter responses were concatenated by the rows to form a 
pattern vector with a dimensionality of 16,000, which is 
further reduced by the PCA method to construct a 
discriminating feature vector. Finally, the classification of 
hand gestures was performed by SVM (C=8 and γ=0.25), a 
Euclidean distance, and a cosine similarity distance, 
respectively. 
Fig. 5 shows the recognition rates for the three methods 
when different number of features acquired from the PCA 
method is used. The maximum recognition rates using SVM, 
the Euclidean distance, and the cosine distance are 95.2%, 
93%, and 93%, respectively, with corresponding numbers of 
features being 100, 50, and 50, respectively. This result 
confirms the outstanding performance of the proposed 
Gabor-SVM method when compared to the other two 
methods. The analysis of the confusion matrix performed by 
the SVM method with a number of features of 100 (see 
Table 1) verifies the results and reveals which gestures are 
sources of errors. 
3
Adaptive Skin Color Model Switching for Face Tracking under Varying 
Illumination 
 
Deng-Yuan Huang1, Wu-Chih Hu2, Mao-Hsiang Hsu3 
1,3Department of Electrical Engineering, Da-Yeh University 
1kevin@mail.dyu.edu.tw, 3r9703030@mail.dyu.edu.tw 
2Department of Computer Science and Information Engineering, National Penghu University 
wchu@npu.edu.tw
 
 
Abstract—In this paper, an adaptive skin color model 
switching based on AdaBoost method for face tracking is 
proposed. Possible skin clusters under illumination varying 
scenes are detected by an optimal skin color model, which is 
adaptively selected by a well-defined quality measure. The 
possible facial candidates are further validated by AdaBoost to 
determine whether human faces exist in video sequences or not. 
The tracking sequences reveal that good and robust results are 
obtained from dim- to profile- to back-light scenarios. The 
performance of the proposed method can achieve an average 
tracking time of about 145.4 ms/frame and a detection rate of 
94.4%. 
Keywords-Skin color model; AdaBoost; Face tracking 
I.  INTRODUCTION 
The most two important issues of face detection are face 
tracking and localization. Face detection are of importance 
due to a wide variety of applications such as public security, 
video surveillance, and access control. Face detection is 
often preceded by the extraction of skin-tone colors [1], since 
it is one of the most important cues of face features with 
invariance of the changes of face scales, poses, and facial 
expressions. However, the color-based approaches are quite 
difficult to robustly detect skin-tone color in the presence of 
complex background and varying illumination. 
The compact skin clusters can be formed in YCbCr color 
space under a wide range of lighting variations [2]. However, 
the skin color models using YCbCr space frequently 
misclassifies non-skin pixels at low luminance as skin-tone 
pixels, and vice versa [1] due to its nonlinear dependence on 
luma. Since skin-tone pixels have a distinct shape in the 
normalized color space (r, g), Soriano et al. [3] use (r, g) 
color space to perform face detection with high capabilities 
under daylight, incandescent lamp, fluorescent light and a 
combination of these light sources. Under certain light 
conditions, the skin color distribution can be modeled by a 
Gaussian function in (r, g) color space [4]. However, since 
single skin color model cannot deal with similar skin-tone 
pixels in background and wide ranges of lighting changes, 
Stern et al. [5] proposed an adaptive color space switching 
method to tackle such difficulties and they claimed this 
method can achieve satisfied performance on face detection 
and tracking. 
Much research for color constancy have been suggested 
but so far their performance has been inadequate. In this 
paper, we present a novel scheme based on adaptive 
switching for skin-color models (ASSM) with light 
compensation for face tracking in video sequences under 
unconstrained illumination. Extensive experiments show that 
switching between the skin color models results in better 
tracking performance when compared to using single skin 
color model throughout. 
The remainder of this paper is organized as follows. In 
Section 2, the method of adaptive switching for skin color 
models is described. Section 3 presents the results of face 
tracking in video sequences under varying illumination. 
Conclusions and a future work are given in Section 4. 
 
II. ADAPTIVE SKIN COLOR MODEL SWITCHING METHOD 
The proposed method, ASSM, is constructed by the 
possible combinations of three different skin color models, 
i.e., YCbCr model [1,2], Soriano’s model [3], and Gaussian 
mixture model [4], with three types of lighting compensation, 
i.e., reference white [1], modified reference white [6] and 
gray world [7]. A quality measure for face tracking is 
presented to adaptively select an optimal skin color model 
from the combinations. The detected skin clusters are further 
validated by performing an AdaBoost method on each 
possible face candidate in video sequences. 
A. Skin color models 
1) YCbCr Skin color model: YCbCr is a family of color 
spaces used as a part of the color image pipeline in response 
to increasing demands for digital approaches in handling 
video information, and has become a widely used model in 
digital video. In contrast to RGB, the YCbCr color space is 
luma-independent, leading to a better performance under 
varying lighting scenes. The corresponding skin cluster can 
be described as: 
  (1) 
[ ] 
( ,  ,  )      :
            60 255
           100 125
           135 170
 ,  ,  0, 255
Y Cb Cr is classified as skin pixels if
Y
Cb
Cr
where Y Cb Cr
≤ ≤
≤ ≤
< ≤
∈
2) Soriano’s skin color model: The normalized RG 
color space (r, g) is first applied, and a pair of quadratic 
functions is used to define the upper and lower bounds of 
due to its greedy characteristics. To significantly improve 
computational efficiency and also reduce false positive rate 
(FPR), a sequence of strong classifiers is concatenated as a 
so-called cascaded detector. More details of computing the 
integral image and implementing the AdaBoost algorithm 
can be found in [8]. 
D. Quality measure 
The skin clusters can be found by a 4-connected 
component labeling for skin-tone pixels greater than 50. 
Then the possible facial regions are fitted with a rectangle 
or an ellipse as shown in Fig. 2. To evaluate the 
quality of the segmented face regions for every possible 
combination of skin color models, a quality measure 
representing the skin color model is proposed and 
defined as: 
rW
kr
eW
k th
  (9) 1 1 2 2k kr rω ω= + kr
where 
 1
1 ( , )
( , ) /
C
r
N
k
r
i x y W
r p x y W
= ∈
⎛ ⎞⎜= ⎜ ⎟⎝ ⎠
∑ ∑ CN⎟
)3 / C
 (10) 
and 
  (11) (2
1
( ) /
C
e e e
N
W W Wk
e p a
i
r S S S N
=
= + +∑
where is a detected skin-tone pixel in or , ( , )p x y rW eW
1ω and 2ω are weights set to be 0.5, respectively, and  is 
the total number of all 4-connected components with skin-
tone pixels greater than 50. , 
CN
We
eS
We
pS and represent the 
sensitivity (i.e., true positive rate = TP/(TP+FN)), the 
specificity (i.e., true negative rate = TN/(TN+FP)), and the 
spatial accuracy (=1-(FP+FN)/(TP+FN)), respectively. 
These values are estimated from the elliptical regions, , 
where TP, TN, FP and FN represent the total number of true 
positive, true negative, false positive and false negative 
pixels, respectively. 
We
aS
eW
 
III. EXPERIMENTAL RESULTS 
Experiments were performed on a computer with Intel(R) 
Core(TM)2 Quad Q8200 2.33 GHz processor and 3.25GB 
RAM. The algorithm was implemented in BCB (Borland 
C++ Builder) 6.0. Fig. 3 shows the flow chart of the 
proposed method for face tracking. The video image 
(320×240 pixels) is input and first resized to 80×60 pixels, 
and then the quality measures are computed by all 
possible combinations of skin color models. With 
maximum , an optimal skin color model can be chosen. 
Afterwards, the possible facial candidates are further 
validated by the cascaded AdaBoost method. Fig. 4 shows 
the results of detected skin-tone pixels for all possible 
combinations, and an optimal combination of YCbCr + 
Modified reference white ( ) is selected here. 
kr
kr
0.612kr =
Figure 5 shows the typical results of detected skin 
clusters of which some of the most important features of 
human face, i.e., eyes, may be lost due to severe lighting 
variations (see the red box with a size of W×H). Therefore, 
to keep as myriad face features as possible, the width of red 
box is expanded by 0.5W on both either side, and the height 
of red box is increased by 0.5H only on the top side. The 
detected possible face candidates (see the yellow box) are 
formed and then fed to the cascaded AdaBoost detector to 
further validate whether the possible candidate regions are a 
human face or not. 
In order to evaluate the robustness of the proposed 
method, a tracking sequence with varying brightness of dim 
light, profile light and back light is performed as shown in 
Fig. 6. The tracking results of quality measure with adaptive 
skin color model switching in the video are shown in Fig.7. 
Note that only five models are used in this case. As revealed 
in Fig. 7, M1 and M7 are alternately used in the period of 
dim light, M7 dominates the period of profile light (scanning 
from left to right), and M5 (Gaussian model) is most 
preferred in the back light situation. Apparently, only single 
skin color model in this case cannot accommodate all the 
lighting variations from dim- to profile- to back light 
situations. 
Finally, the performance of the proposed method in face 
tracking was evaluated by a sequence of video which is 
composed of 144 frames with a size of 320×240 pixels. 
There are totally 144 faces in the tested sequence (see Fig. 6). 
The detection rate, missing rate, and false alarm rate are 
RP=94.4% (136/144), RM=4.2% (6/144), and RFA=1.4% 
(2/144), respectively. Furthermore, the average detection 
time for each frame is about 145.4 ms; this result also 
confirms the possibilities of real-time operation in face 
tracking for the proposed method. 
 
 
Figure 1.  The set of Haar-like feature for AdaBoost 
 
Figure 2.  4-connected component labeling for the estimation of quality 
measure 
行政院國家科學委員會補助國內專家學者出席國際學術會議報告 
                                                            98 年 8 月 25 日 附件三
 
報告人姓名  
黃登淵 
 
服務機構
及職稱 
 
大葉大學電機系助理教授 
 
     時間 
會議 
     地點 
2009 年 8 月 12~14 日 
中國瀋陽 
本會核定
補助文號
 
NSC 97-2221-E-212-035- 
會議 
名稱 
(中文) 
(英文) 
The Ninth IEEE International Conference on Hybrid Intelligent Systems 
發表 
論文 
題目 
(中文) 
(英文) 
Video Object Segmentation by Integrating Motion Information and Gradient 
Compensation without Background Construction 
 
98 年 08 月 14 日 
這是 HIS2009 會議的第三天，也是大會會議的最後一天。今天一整天都安排 Presentation 
Sessions and Poster Sessions，分別在早上安排九個 Sessions 與三個 Poster Sessions，下午則安
排八個 Sessions 與四個 Poster Sessions 等。早上參加的 Sessions 分別為：Session C17 – 
Innovative computing for image analysis (2)，與 Session C08 – Information management & 
knowledge management (2)。下午參加的 Sessions 是：Session C12 – Advanced data processing 
technology，與 Session C15 – Soft computing for image and signal processing。同時早上的
Session C17 也是我們論文報告的 Session，本篇論文報告期間，與會人員發問相當踴躍、討論
氣氛熱烈，由於時間限制，大家只得於會後繼續討論，彼此交換心得。 
 
98 年 08 月 15 日 
結束 HIS2009 會議行程，循原來小三通的方式回台灣。首先由瀋陽桃仙國際機場搭機至
廈門高崎國際機場，然後再坐船至金門，再轉搭飛機回高雄小港國際機場。 
 
二、與會心得 
 
此次參加 HIS2009 會議，認識了許多世界各地同樣為 Intelligent computing 領域的研究人
員，包括有馬來西亞、美國、日本、印度、英國等地的教授與博士生，當然也有接觸到中國
當地的與會人士，皆與他們相談甚歡，同時也交換了許多在研究上的意見與想法，相信對於
未來的研究會有更進一步的幫助。 
除此之外，此次的最大收穫便是聽取了許多非常有趣的演講，其中讓我印象最為深刻的
是Kyushu University副教授Hideyuki Takagi之keynote Speech - IEC Prospector's Guide: Features 
of Some Interactive EC Frameworks。本次Talk主要是講述如何利用植基於人類智識、經驗、偏
好(preference)與直覺之Interactive Evolutionary Computation (IEC)方法來最佳化目標系統。一般
說來，設計一個fitness function對大部分系統的最佳化是相當困難的，但IEC卻提供了一個解
決的方法。因此，這個方法也啟示了研究者一個最佳化目標系統的一個方向，相當值得參考。 
另一個收獲較大的是，本次有許多相關領域的台灣學者參加 HIS2009 會議，包括有雲科
大張傳育教授、伍麗樵教授、虎尾科大郭文忠教授、澎湖科大胡武誌教授、嘉義大學柯建全
教授、王智弘教授、盧天麒教授、王皓立教授、高雄大學張保榮教授、高應大王嘉男教授、
行政院國家科學委員會補助國內專家學者出席國際學術會議報告 
                                                            98 年 9 月 21 日 
報告人姓名  黃登淵 
 
服務機構
及職稱 
 
大葉大學電機系助理教授 
 
     時間 
會議 
     地點 
2009 年 9 月 12~14 日 
日本京都 
本會核定
補助文號
 
NSC 97-2221-E-212-035- 
會議 
名稱 
(中文) 
(英文) 
2009 Fifth International Conference on Intelligent Information Hiding and 
Multimedia Signal Processing (IIH-MSP2009) 
發表 
論文 
題目 
(中文) 
(英文) 
Vision-based Hand Gesture Recognition Using PCA+Gabor Filters and SVM 
附件三
 
表 Y04 
表  Y04 
Session 來參加，分別為：Session B10 - Image Processing and VLSI Implementation 與
Session B11 - Intelligent Watermarking Techniques, Image Authentication and Visual 
Cryptography (II)。 
 
98 年 09 月 14 日 
這是 IIH-MSP2009 會議的第三天，也是大會會議的最後一天。大會首先安排中國浙
江大學教授潭建榮(Jianrong Tan)進行專題演講，講題為：Multimodal Information Fusion in 
the Virtual Environment and Its Applications in Product Design。今天一整天都安排
Presentation Sessions and Poster Sessions，分別在早上安排 4 個 Sessions，下午則安排有 4
個 Sessions 與 2 個 Poster Sessions 等。早上參加的 Sessions 分別為：Session C02 –
Intelligent Video Processing。下午參加的 Sessions 有：Session C06 - Multi-dimensional 
Signal Processing, Modeling and Visualization，與 Session C07 - Multimedia Signal 
Processing for Plasma Diagnostics。同時早上的 Session C02 也是本人論文報告的 Session，
本篇論文報告期間，與會人員發問相當踴躍、討論氣氛熱烈，由於時間限制，大家只得
於會後再行討論，彼此交換研究心得，收獲頗多。 
 
二、與會心得 
 
此次參加 IIH-MSP2009 會議，認識了許多世界各地同樣為 Intelligent Information 
Hiding 與 Multimedia Signal Processing 等領域的研究人員。本次與會的學者遍佈相當廣
泛，在亞洲方面包括有日本、台灣、南韓、中國、新加波與伊朗等，在歐洲方面則有德
國、捷克、荷蘭、挪威、義大利與波蘭等，此外還有埃及與俄羅斯等國家的教授與博士
生參與。在會議期間，當然也有接觸到中國當地的與會人士，彼此也交換了許多在研究
上的意見與想法，相信對於未來的研究會有更進一步的幫助。 
除此之外，此次的最大收穫便是聽取了許多非常深入且生動的演講，其中讓我印象
最為深刻的是浙江大學潭建榮教授之專題演講 - Multimodal Information Fusion in the 
Virtual Environment and Its Applications in Product Design。本次Talk主要是講述如何利用
3D模型來建構一個更真實的虛擬實境(virtual reality)。除此之外，潭教授亦講述如何利用
這個技術來模擬一個汽車引擎的組裝過程，整個模擬過程相當真實。 
另外一個較大的收獲是，本次有許多相關領域的台灣學者參加 IIHMSP2009 會議，
包括有雲科大張傳育教授、伍麗樵教授、虎尾科大郭文忠教授、澎湖科大胡武誌教授 
 
