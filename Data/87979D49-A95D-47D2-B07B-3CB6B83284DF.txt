1行政院國家科學委員會專題研究計畫成果報告
混合式蟻群最佳化演算法於影像分割之應用
Application of Ant Colony Optimization for Multilevel
Thresholding
計 畫 編 號：NSC 97-2221-E-155-042-MY2
執 行 期 限：97 年 8 月 1 日至 99 年 7 月 31 日
主 持 人：梁韵嘉 元智大學工業工程與管理學系 副教授
計畫參與人員：尹岳川 元智大學工業工程與管理學系 博士生
羅敏華 元智大學工業工程與管理學系 博士後研究員
勞齊均 元智大學工業工程與管理學系 碩士生
1、中文摘要
本研究於計畫第二年度嘗試以 Socha
and Dorigo 於 2008 年所提出之求解連續型
問題的連續型蟻群最佳化演算法 (ACOR)，
與 期 望 值 最 大 化 演 算 法 （ Expectation
Maximization Algorithm；EM）相結合，在高
斯混合模型（Gaussian Mixture Model；GMM）
機率分配模型的假設之下，發展出一個應用
在多階影像分割問題上的快速參數估計法。
由於 EM 演算法的品質受到起始解的影響非
常大，因此，本研究應用 ACOR 演算法為 EM
演算法搜尋出品質較佳的起始解，並將 EM
演算法視為區域搜尋機制，不斷的改善搜尋
解的品質，以得到最佳的高斯配適模型。由
實驗結果顯示，本研究所提出的 ACOR-EM
演算法確實是一個非常有效率且穩健的方
法。
關鍵詞：連續型蟻群最佳化演算法; 期望值
最大化演算法; 高斯混合模型; 多階影像分
割問題
Abstract
Socha and Dorigo proposed an extension
of combinatorial ACO algorithms to continuous
domains named ACOR in 2008. In the 2nd
year of the project, we present a fast estimation
algorithm based on ACOR and the
expectation-maximization (EM) algorithm for
solving multi-level thresholding problems in
image segmentation. The distribution of
image intensity is modeled as random variables,
which are approximated by a mixture of
Gaussian distributions. The solution quality
provided by the iterative EM algorithm is
intensely affected by the initial solution fed into
the EM algorithm. Therefore, we apply the
ACOR algorithm to provide a good initial
solution for the EM algorithm. The EM
algorithm is then used as a local search
procedure to improve each new solution
generated by ACOR while fitting the mixture
Gaussian model. The experiment results
successfully show the effectiveness and
efficiency of the ACOR–EM algorithm.
Keywords: Continuous Ant Colony
Optimization, Expectation Maximization
Algorithm, Gaussian Mixture Model,
3The remainder of the report is organized as
follows: Section 3 describes the proposed
ACOR-EM algorithm and their key features in
detail. Section 4 presented the computational
results on test images. Finally, the concluding
remarks are provided in Section 5.
3. The Hybrid ACOR-EM Algorithm
In practice, the frequency data observed from
complex images intensity can be modeled as a
random variable, which could be approximated
by a mixture Gaussian model. In this project,
we hybridize ACOR with EM algorithm to
develop an efficient and effective estimation
algorithm for the multi-level thresholding
problems. Since the performance of the EM
algorithm is strongly affected by the initial
solution, the ACOR algorithm will be employed
as a global search procedure to provide a good
initial solution for the EM algorithm. The EM
algorithm is then used as a local search
procedure to improve each new solution
generated by ACOR while trying to seek the
best-practice parameter estimates of the
mixture Gaussian model. The general
description of the proposed ACOR-EM
algorithm is summarized in Fig. 1.
3.1 ACOR Algorithm
In ACO algorithms for discrete optimization
problems solutions are constructed by sampling
at each construction step a discrete probability
distribution that is derived from the pheromone
and heuristic information. The pheromone
information represents the stored search
experience of the algorithm and the heuristic
information is usually determined by some
simple rules. In contrast, ACOR utilizes a
continuous probability density function (PDF).
This density function is produced, for each
solution construction, from a population of
solutions that the algorithm maintains through
the search process. Before the algorithm
begins, the population is filled with random
solutions, and this corresponds to the
pheromone value initialization in discrete ACO
algorithms. Then, at each iteration the set of
generated solutions is added to the population
and the same number of the worst solutions is
removed from it. This action corresponds to the
pheromone update in discrete ACO (Blum,
[7]).
Figure 1: Flow chart of the ACOR-EM
algorithm.
ACOR algorithm keeps track of a number of
solutions in a solution archive T. For each
solution ls to an n-dimensional problem,
ACOR stores in T the values of its n variables
E v alu a te th e fitn ess o f
each so lu tio n in a rch iv e T
A p p ly E M alg o rith m to
u p d a te th e n ew so lu tio n
O b ta in th e o p tim a l
es tim a tess
U p d a ted
S u ccessfu lly ?
Y es
N o
G en era te A C O R
p o p u la tio n o f size k
R an k so lu tio n s
b ased o n th e fitn ess
H am m in g D is tan ce
C o n s tru c t a n ew so lu tio n
R eac h th e stopp ing
c rite r ia ?
N o
Y es
5the l*th solution multiplied by a parameter 
is selected as the standard deviation, denoted
by * ,l of the Gaussian function as follows:
*
*
1 1
i ik
e li
l
e
s s
k
 



 (4)
Parameter (0,1) which regulates the
speed of convergence, has a role similar to the
pheromone evaporation rate  in ACO for
discrete problems. The higher the value of 
is, the lower the convergence speed of the
algorithm can get, and hence the lower the
learning rate will become. Since this whole
process is done for each dimension in turn,
each time the distance is calculated only with
the use of one single dimension. This allows
the handling of problems that are scaled
differently in different directions.
3.2 The peak-selection algorithm
Through the preliminary results, it is
observed that ACOR is sensitive to the initial
archive; therefore, a procedure is designed to
generate a set of quality initial solutions for
ACOR to store in the archive.
A histogram of an image provides a global
description of the image. Usually, dominating
peaks in the histogram can represent different
regions in the image. The most important task
in a typical image segmentation approach based
on histogram analysis is the identification of
peaks (Nakib et al., [8]). First, we proposed a
fast peak-selection algorithm that was used to
identify the most significant peaks of the
histogram. A proper number of peaks are
selected from the histogram of the given image.
Step 1. Smooth the histogram a Gaussian
kernel: The Gaussian kernel originally from
Rattarangsi and Chin [9] and modified by
Chang et al. [10] with window size of four is
used to generate smoothing function. After the
smoothed histogram H~ has been obtained, the
peaks in the histogram can be determined by
the following rule: for any gray value j,
[1, ]j L , where L is the total number of gray
values, )(~ jH is a peak if )1(~)(~  jHjH and
)1(~)(~  jHjH .
Step 2. Refine the peaks. In this step, we
adopted two refined procedures presented by
Nakib et al. [8]. The first sub-step consists of
removing the small peaks. We compare all
peaks to the highest one. If the current peak is
too small, it will be removed. From the
preliminary experiments, we decided to remove
all the peaks, if its amplitude is less than 1.8%
(the amplitude of the highest peak is 1) of the
highest peak. The second sub-step, we remove
the peaks by measuring the distance on abscissa
axis (gray level axis) between peaks. If the
distance between two peaks is less than 9, we
remove the peak with the lower frequency of
occurrence.
Second, the peaks chosen are treated as the
means of the distribution of the mixture
Gaussian model. For d-level curve fitting
problem, d maximum peaks will be selected
and a gray-level value between two successive
peaks is randomly generated as the threshold to
divide the histogram into different groups.
Then, the priori probability and standard
deviation of each group can be calculated and
saved as the initial solutions in the archive T.
3.3 The Expectation-Maximization
(EM) Algorithm
The EM was first introduced by Dempster et
al. [11] as a mean of fitting incomplete data
71 2( 1)
0( 1)
1
0
L
EM l
ij i j
jl
i L
EM
ij j
j
P j n
P n







  




(11)
where N denotes the total number of the pixels
in the image, nj is the occurrence of pixels with
gray level j. According to the EM algorithm,
the final parameter estimates are obtained
staring from a set of initial values
 0 0 0 0, , ; 1, 2,...,i i i i k     and then iterating
the above equations until convergence (Bazi et
al. [14]).
4、Computational Results and
Analysis
In this section, the performance of the
proposed ACOR-EM algorithm has been
evaluated and compared with the PSO-EM
algorithm from the literature [15]. The
PSO-EM algorithm was implemented on an
Intel Celeron 2.8 GHz platform with 512 MB
DDR-RAM, and the algorithm was coded using
Matlab. The ACOR-EM algorithm was
implemented on a personal computer with
Intel® Core(TM)2 Quad CPU Q9400
@2.66GHz and 3.00GB RAM. The program
was compiled and run using Borland C++
Builder 6.0. Three images - oxidation induce
stacking fault (OISF), printed circuit board
(PCB), and random access memory (RAM) are
tested. Three test images were taken under
natural room lighting without the support of
any special light source and have been
transformed into gray-scale images of 256×256
pixels. That is these images including a
collection of pixels have been assigned values
from 0 to 255 in this study. Table 1 shows the
maximum and minimum values of gray-level in
three test images, the number of peaks and their
gray level values selected from the histogram
of the three test images, respectively.
To account for both efficiency and
effectiveness, the best parameter combination
for ACOR is set up from the preliminary
experiments as follows: q = 0.02,  = 0.67
for all the following experimental runs. The
best population size (k) of the ACOR is set at 50
and the number of ants for each iteration is set
at 5. The stopping criterion for ACOR-EM
algorithm is the maximum number of iterations
equal to 30 and for EM algorithm is the
absolute difference of the likelihood function
value over two successive iterations less than
10-6.
Table 1: Search ranges and the gray-level of peaks on three test images
Images
Gray-level of pixels
Number
of peaks Gray-level of peaksMinimum
value
Maximum
value
OISF 3 213 6 27,45,75,94,128,143
PCB 35 255 9 43,52,87,101,120,129,148,162,251
RAM 9 255 4 37,56,86,251
9thresholding. The ACOR-EM performs slightly
better with a lower Hamming distance at the
value of 1.0745E-04. When both algorithms
raise the level of thresholds up to seven and
nine, it is obvious that they both fit the
histogram nicely as shown in Fig. 4(g) and 4(h)
respectively. When considering the CPU time,
the main advantage of ACOR-EM over
PSO-EM can be recognized once again. For
example, at the level of four, PSO-EM
consumes 5.95 seconds. When the number of
levels is increased to seven, PSO-EM spends
7.54 seconds, but ACOR-EM just uses 3.70
seconds at nine-level thresholding..
Fig. 5(a) and 5(e) illustrate the original
image and the corresponding histogram of the
last test image RAM respectively. Obviously,
PSO-EM did not fit the histogram well at
four-level thresholding but the ACOR-EM
algorithm returns a much smaller Hamming
distance of 3.3240E-04 than the PSO-EM
algorithm of 1.9656e-03. Even when the level
of PSO-EM increases up to seven, the
Hamming distance 1.6471e-04 is just slightly
smaller than the four-level of ACOR-EM
algorithm. In Fig. 5(b), (c) and (d), we can find
the quality of the ACOR-EM thresholded image
is better than PSO-EM algorithm. In addition,
the CPU time of ACOR-EM is much shorter
than the ones in PSO-EM such as 29.01
seconds of PSO+EM and 70.78 seconds by
PSO+EM versus 1.94 seconds by ACOR-EM at
the case of four-level.
Table 2 summarizes the estimation results of
the three test images in the third set, including
Hamming distance and CPU time. For a fair
comparison of the computation robustness with
the PSO-EM algorithm [9], we also executed
the ACOR-EM algorithm ten independent runs
and reported the average Hamming distance
(HD) and CPU time (T) statistics on the last
two columns in Table 2. The number in the
parenthesis indicates the standard deviation of
the related statistic. In Table 2, the ACOR-EM
algorithm can return smaller mean values and
standard deviations of the Hamming distance
than the PSO-EM algorithm in almost all
comparison. This indicates that ACOR-EM has
provided a better performance with persistently
stability over the random number seed. In
considering CPU time, ACOR-EM never
exceeds 4.05 seconds in all three testing images
when PSO-EM needs much higher
computational expense (between 5 and 90+
seconds). Overall, the ACOR-EM algorithm
reveals its competitiveness in the consistency
and stability of fitting accuracy.
Based on the experimental results of the
pervious three test images, we can conclude
that the proposed initialization strategy based
on ACOR algorithm is robust and efficient
enough to compensate the drawback of the EM
algorithm. The ACOR-EM algorithm was
verified to be more efficient and effective than
the PSO-EM algorithm in multi-level
thresholding that also makes the ACOR-EM
algorithm more practical in on-line application.
11
Table 2. Experimental results via multi-level thresholding methods and its statistics
5、Conclsions
In the second year of the project, we present
a fast estimation algorithm based on the
hybridization of ACOR and the EM algorithm
for solving multi-level thresholding problems
in image segmentation. Since the initial
values of the statistical parameters of classes
strongly affect estimates obtained by the EM
algorithm at both convergence and the
thresholding results, it is important to adopt an
accurate and robust initialization procedure,
which can properly explore the space of
solutions. It is obvious that we have
successfully introduced the ACOR algorithm as
a global search procedure to provide a good
initial solution efficiently for the consecutive
EM algorithm. The EM algorithm is then used
as a local search procedure to improve the new
solutions generated by ACOR while fitting the
mixture Gaussian model. Experimental results
of the test images show that the ACOR-EM
algorithm is an efficient and effective
estimation algorithm. Comparisons between the
ACOR-EM algorithm and the PSO-EM
algorithm also verify that the ACOR-EM
algorithm not only provides competitive
thresholding results but also outperform
PSO-EM in computational expense; moreover,
the ACOR-EM algorithm can also be
considered as a promising and valuable
multi-level thresholding technique for the
on-line application in practice.
6、Reference
[1] Dorigo, M., Optimization Learning and Natural
Algorithms (in Italian), Ph.D. thesis, Dipartimento
di Elettronica, Politecnico di Milano, Italy, 1992.
[2] Dorigo, M., Di Caro, G., and Gambardella, L.M.,
Ant algorithms for discrete optimization, Artificial
Life 5(3), 137-172, 1999.
[3] Socha, K. and M. Dorigo, Ant colony optimization
for continuous domain, European Journal of
Operational Research 185, 1155-1173, 2008.
[4] Bilchev, G. and Parmee, I.C., The ant colony
metaphor for searching continuous design spaces,
Proceedings of the AISB Workshop on
Image Method # of
Levels
Hamming
distance
(HD)
CPU
time
(T)
HD statistica T statistica
OISF PSO+EM 4 1.1356e-04 3.75 1.29e-04 (3.74e-05) 6.63 (3.95)
PSO+EM 7 1.0751e-04 5.84 1.18e-04 (2.70e-05) 8.74 (5.01)
ACOR EM 6 2.0833E-05 1.70 2.17e-05 (9.80 e-07) 1.78 (0.262)
PCB PSO+EM 4 8.5164e-04 5.95 8.60e-04 (9.68e-05) 5.25 (2.24)
PSO+EM 7 2.7661e-04 7.54 2.79e-04 (3.88e-05) 12.93 (3.45)
ACOR EM 9 1.0745E-04 3.70 1.10e-04 (4.41e-06) 4.05 (0.58)
RAM PSO+EM 4 1.9656e-03 29.01 2.14e-03 (2.33e-04) 23.38 (5.17)
PSO+EM 7 1.6174e-04 70.78 1.60e-04 (2.57e-05) 90.67 (17.43)
ACOR-EM 4 3.3240E-04 1.94 3.97E-04 (5.80E-05) 1.69 (0.172)
表 Y04
（附件四）
行政院國家科學委員會補助國內專家學者出席國際學術會議報告
98 年 12 月 22 日
報告人姓名
梁韵嘉
服務機構
及職稱
元智大學工業工程與管理系
副教授
時間
會議
地點
2009/12/14-16
Kitakyushu International
Conference Center,
Kitakyushu City, Japan
本會核定
補助文號
NSC97-2221-E-155-043-MY2
會議
名稱
(中文) 第十屆亞太工業工程與管理系統研討會 (APIEMS2009)
(英文) The 10th Asia Pacific Industrial Engineering & Management Systems
Conference (APIEMS2009)
發表
論文
題目
1. Variable Neighborhood Search for Multi-Objective Resource Allocation Problems
2. An Application of Continuous Ant Colony Optimization for Multi-level Thresholding
3. Variable Neighborhood Search for Portfolio Optimization Problems
4. Virus Optimization Algorithm (VOA): A Novel Metaheuristic for Solving Continuous
Optimization Problems
無衍生研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
