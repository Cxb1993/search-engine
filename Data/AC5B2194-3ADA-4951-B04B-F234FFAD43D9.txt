of defect. The standard feature set is
reconfigurable and easy to update, thus
makes the inspection for new product easier.
The benefit of the project is fast
prototyping the required feature set for
automatic inspection in manufacturing.
The results can significantly increase the
automatic inspection capability in industry.
The major deliverables is establishing
standard feature set for defect recognition.
Keywords: Stand Feature Set、Module
Vision Inspection、Feature Fetch、
Feature Classification
二、緣由與目的
在今日工業社會中，凡事都講求效率，
如何有效的提昇生產力與產品品質之議
題，已成為各工廠所追求之目標。若要達
到一個良好的產品品質，必須靠著一個完
善的品質檢驗系統。隨著科技的發達，自
動化檢測已逐漸取代人眼目視檢測，但在
自動化檢測中，以既有的機台對多變的產
品進行檢測，無法達到正確及有效的檢測
結果且耗費人力，主要是因為大部份的研
究均針對特定產品來建立系統。所以需要
一個泛用型的檢測方法，來應用於多變的
產品中，以便能夠在既有的系統架構上不
斷的快速升級，進而適應新產品。目前機
器視覺檢測被廣泛的應用在工業生產上。
在凡事講究迅速、時效的今天來看，如果
能有一個快速檢測產品的程序，相信可大
幅度提升整個製程在檢測更新(Update)上
的速度，進而縮短製程工時，提升產業競
爭力。
雖然每個研究人員都盡力提出ㄧ套有
效的檢測流程，但是基於人力與時間下，
ㄧ定會面臨以下幾個問題：
 針對不同的產品，需要個別發展合
適的演算法。
 在實務上，無法針對產品品質的特
性，提供有效的解決方案。
 當製程加入新瑕疵的品質要求
時，無法提供有效率的方案，擴張
其能力。
 對於同性質但不同類型的瑕疵，無
法根據既有系統做出相對應的解
決方案。
由上述可以知道，目前對於視覺檢測瑕
疵和分類時，必須針對不同產品、不同瑕
疵、不同的特徵做出許多不能預期的搭
配，如此瑕疵檢測與分類上就成了視覺檢
測最無法掌握的ㄧ環，在實務應用上，造
成許多的不便，故在瑕疵偵測與分類的處
理上必須要有一套系統化的程序。
對此，本研究計畫將建立以標準特徵子
集的檢測架構。將所要檢測的物件，轉換
成特徵子集，並建立其資料庫，取代影像
資料庫。並且建立與瑕疵的關係模式。待
有新瑕疵或同性質瑕疵要建立檢測系統
時，能夠藉由本研究之標準特徵子集資料
庫快速地且有系統地建立流程。
本研究希望主導新的檢測程序，根據瑕
疵特性，建立標準特徵子集後，使用者不
必了解瑕疵特性與樣本特徵之間的關係，
一旦樣本更換或出現新種瑕疵，只需套用
平日流程一次，即可自動得到新的標準特
徵子集，並可以立刻套用到線上檢測流程
中，符合現在工業界需求。不管產品如何
更新，以此新的架構可以快速的更新檢測
機制，不需要原廠駐廠更新或是漫長的維
護程序。
本計劃第一年使用之前所取得結果圖
形與統計資料，再進行特徵分類與特徵評
估。
由計劃提出完整流程可建立一有效法
則將各單一物件找出，並萃取其特徵，第
一年之執行流程與步驟說明整理如下：
Step1.影像前處理突顯及找到目標物
後
Step2.計算所有物件並歸類特徵子集
Step3.特徵子集之極限評估
Step4.確立模組與資料庫架構
在第二年的研究計劃，主要針對標準特
徵子集作建立。
主要模組有兩個部分，分別說明如下：
標準特徵子集建立：經過第一年計畫的
執行，可以取得有系統特徵值以及各項特
徵的極限與能力資訊，而過去的處理方式
選擇影像強化的方法，此處的決策指標則
以量化的方式來呈現，可量化的參數將提
供較客觀的標準來依循；又因電子類產品
的種類繁多，若是以觀察的方式來尋找影
像間的相似指標，困難度相對提升，故將
影像予以量化後，透過特徵值的擷取來描
述影像特性，藉以區分為空間域與頻率域
影像（Step1），後續階段為建立欲使用的
影像增強技術與影像特性的關係（Step2
和 Step3），經由本研究所建立的分析決
策程序，期望可快速地將低對比影像轉換
成具有高對比值的影像。另外，本研究並
非著重於瑕疵存在與否，而是為了尋找特
徵子集，本例為找出影像整體對比的特徵
子集，故對研究中所使用的影像處理方式
皆以整張影像進行。
本研究的方法流程先以訓練影像進行
特徵值的擷取，透過分類方法將影像區分
為以空間域或頻率域之影像增強方法將影
像強化，第二及第三步驟將透過文獻中所
使用的方法，以及現有套裝軟體內建參數
進行影像強化，最後計算影像強化後成
效，以評估影像的對比度是否提升，影像
強化成效也同樣予以量化，使評估結果較
為客觀。
因影像可區分為空間域或頻率域特
徵，若對兩種不同的特徵用不適合的影像
處理技術易造成誤判或強化後的效果不
好，為避免此狀況發生，本研究於影像在
進行增強技術判定前，先對影像做初步分
類，區分為使用空間域或使用頻率域影像
增強技術。比方說對一張 LCD影像進行強
化，透過頻率域轉換後之影像其對比值皆
偏向相對小的情況，故若未予以分類，則
會使所有影像的強化方法之抉擇，皆以空
間域影像增強技術進行處理，如此結果就
稍嫌偏頗，無法適用於實際情況。故於影
像強化前，先擷取影像的特徵值，特徵值
的擷取可分為兩個主要部分，一為影像於
空間域之特徵值擷取、二為影像於頻率域
之特徵值擷取。頻率域特徵值擷取時必須
將影像以傅立葉轉換為頻率域影像，透過
功率譜擷取影像特徵值，將所擷取的特徵
值以判別分析區分出影像適用於空間域或
頻率域影像增強方法。
在訓練影像選擇以頻率域或空間域強
化技術前，本研究預先以主觀的方式將影
像予以初步分類，即文獻中大多數學者所
用之影像處理類別為依據，因此在影像分
類的問題上是屬於監督式分類，分類方法
主 要 則 是 透 過 鑑 別 函 數 分 類 法
（Discriminate Classifier）來進行。本研究
於主觀方式分類的步驟基於文獻中選擇的
影像處理技術類別是有效的假設下，根據
這種假設條件下將影像區分為頻率域與空
間域兩大類別。
本研究於決定第二及第三步驟的決策
指標進行方式，主要是將分類後的影像對
所有空間域或頻率域影像增強方法全部執
行，若影像以空間影像增強方法來強化影
像，則會得到六張強化後影像，以頻率域
增強方法來處理則會得到七張強化後影
像，計算影像強化後成效值，根據成效指
標進行分類，被歸類以相同強化技術的影
像，透過量化的參數來決定其決策指標。
本研究用於評估影像強化後成效指
標，與擷取特徵值中以灰階資訊來評估影
像的指標相同，包括影像灰階值分佈範圍
與影像各區域灰階值變異情形以及影像對
比值，使用相同的指標主要目的為評估透
過本研究方法強化後影像、原始影像以及
文獻中所使用強化技術處理後之影像之差
異。
第一階段結果：區分空間域與頻率域影
像
此階段的分類依據先以主觀方式進行
初步分類，所謂主觀方式即是文獻和前人
經驗中認為該影像適用於空間域或頻率域
影像處理，透過後續特徵值篩選與分類後
結果進行比對，是否符合本研究預估之結
果，實驗結果如下。
首先以五十三張空間域訓練影像、十三
張頻率域訓練影像作為第一階段分類的測
試。在實際計算鑑別分析係數前，為使特
徵值以最少數量達到最大分類效果，故透
過 Wilk’s 統計量來檢定這些特徵值是否
具顯著性，又因（影像灰階最大值）與（影
像灰階動態範圍）兩者具有高相關性，故
由表 4分類結果可證明，文獻中以空間
域影像增強技術處理之影像，於本研究所
提鑑別分析函數計算歸類後，被判定為適
合以空間域影像增強技術處理的正確率為
百分之百，頻率域亦然。故可判定本研究
在第一階段區分影像以空間域與頻率域影
像增強技術類別中，藉由計算影像七個特
徵參數所建構之鑑別函數，可有效地將欲
測試之影像分類。
表 4 測試影像於區分空間域與頻率域
兩類之正確率
四、參考文獻
1. Abdulhady, M., H. Abbas, and S. Nassar, “Fabric 
Fault Classification Using Neural Trees,” Systems, 
Man and Cybernetics, IEEE International
Conference on , 6, 2002.
2. Bae, S. C., K. I. So, and C. D. Yoo, “COP: A 
New Corner Detector,” Patern Recognition 
Letters, 23, 2002, 1349-1360.
3. Bhalla, K., N. G. Durdle, A. E. Peterson, J. Raso,
D. Hil, and X. Li, “Automatic feature detection 
and correspondence in a stereo-vision
application,” IEEE International Conference on 
Systems Man and Cybernetics, 4, 1995,
3537-3542, 1995, Vancouver, Canada.
4. Cao, L., Z. Shi, and E. K. W. Cheng, “Fast 
Automatic Multilevel Thresholding Method,” 
Electronics Letters, 38, 2002, 868–870.
5. Cho, K. D. and H. S. Tae, “Improvement of Low 
Gray Scale Linearity using
Multi-Luminance-Level Subfield Method in
Plasma Display Panel”, IEEE Transactions on 
Consumer Electronics, 3, 2002, 377-381.
6. Chabat, F., GZ. Yang, and D. M. Hansel, “A 
Corner Orientation Detector,” Image and Vision 
Computing, 17, 1999, 761-769.
7. Feng, J., L. Mingjing, Z. Hong-Jiang, and B.
Zhang, “Unsupervised Image Segmentation Using
Local Homogeneity Analysis,” Circuits and 
Systems, ISCAS '03. Proceedings of the 2003
International Symposium on, 2, 2003,
II-456-II-459.
8. Gallegos, J. M., J. R. Villalobos, G. Carrillo, and
S. D. Cabrera, “Reduced-dimension and wavelet
processing of SMD images for real-time
inspection,” Proceedings of the IEEE Southwest 
Symposium on Image Analysis and Interpretation,
1996, 30-36, San Antonio, TX, USA.
9. Gonzalez, R. C. and R. E. Woods, Digital Image
Processing, 2nd ed., Prentice Hall, 2002, Upper
Saddle River, New Jersey.
10.Hamed, S. H. and R. Safabakhsh, “Automatic 
Multilevel Thresholding for Image Segmentation
by the Growing Time Adaptive Self-Organizing
Map”, IEEE Transactions on Patern Analysis and 
Machine Intelligence, 10, 2002, 1388-1393.
11.Hong, J. J., H. J. Park, and K. G. Kim, “Paralel 
Processing Machine Vision System for Bare PCB
Inspection”, Proceedings of IECON, 3, 1998, 
1346-1350, Aachen, Germany.
12. Ishimaru, I.; S. Hata, and M. Hirokari,
“Color-Defect Classification for Printed-Matter
Visual Inspection System,” Inteligent Control 
and Automation, Proceedings of the 4th World
Congress on, 4, 2002, 3261–3265.
13. Jiang, T. and F. Yang, “An Evolutionary Tabu
Search for Cell Image Segmentation” , IEEE
Transactions on Systems, Man, and Cybernetics
－Part B:Cybernetics, 5, 2002, 675-678.
14. Jong, B. K., C. H. Moon, and H. J. Kim,
“Wavelet-Based Morphological Approach for
Detection of Human Face Region,” Patern 
Recognition, 1, 2002, 417–420.
15.Jong, B. K. and H. J. Kim, “A Wavelet-Based
Watershed Image Segmentation for VOP
Generation,” Patern Recognition, 3, 2002, 
505-508.
16.Khwang, T. E., and D. P. Mital, “An inteligent 
vision system for inspection of surface mounted
devices,” IEEE Region 10 International 
Conference on TENCON '92, 2, 1992, 804-808,
Melbourne, Australia.
17. Kim, S., H. B. Pyo, S. K. Lee, S. Lee, and S. H.
Park, “Digital image subtraction of temporaly 
sequential chest images by rib image elimination,” 
Proceedings of the 22nd Annual International
Conference of the IEEE Engineering in Medicine
and Biology Society, Chicago, IL, 3, 2000,
1752-1755, USA.
18. Kondo, K., M. Iguchi, H. Ishigaki, and Y. Konishi,
“ Design of complex-valued cnn filters for
medical image enhancement,” IFSA World 
Congress and 20th NAFIPS International
