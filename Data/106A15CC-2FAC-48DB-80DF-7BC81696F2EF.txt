22. Fast Revelation of the Motif Mode for a Yeast Protein Interaction Network
through Intelligent Agent-based Distributed Computing. Protein and Peptide
Letters, 17(9), 1091-1101.
另外亦有兩篇已被有條件接受（conditional accepted），目前進行第三輪審
查後的小修改，此兩篇論文如下：
1. An Adaptive GA-PSO Approach with Gene Clustering to Infer S-System
Models of Gene Regulatory Networks. The Computer Journal.
2. Combining GRN Modeling and Demonstration-Based Programming for
Robot Control. Neural Computing and Applications.
研究成果論文部份內容附加於後以為參考。
41. Introduction
Constructing gene regulatory networks (GRNs) has been identified as one of the most
important issues in systems biology research [1]. With the current experimental tools and
techniques, researchers are now able to simultaneously measure and to record the relevant
information of multiple genetic reactors and their interactions. They can gradually model the
overall systems from the experimentally measured time-series data, and then infer some
unknown interactions between the reactors accordingly. Traditionally, to reconstruct GRNs
manually takes a considerable amount of time, therefore an automated procedure (i.e.,
reverse engineering) is advocated [1][2]. This procedure involves altering the gene network
in some ways, observing the outcome, and using mathematics and logic (i.e., computational
methods) to infer the underlying principles of the network. The present work is to establish a
practical methodology for such a procedure of network inference.
In the abovementioned network reconstruction procedure, the most important steps are
selecting the network model and fiting the network’s structural parametersto the available
data. Depending on the biological level to be studied, many gene regulation models have
been proposed, and they range from very abstract (involving Boolean values only) to very
concrete (including fully biochemical interactions with stochastic kinetics). The abstract
models are mathematically tractable that provide the possibility of examining large systems,
but they are inherently static and cannot infer networks with feedback loops. In contrast, the
concrete models are more suitable in simulating the biochemical reality, but due to their
computational complexities, these models can only be applied to small systems. With a
chosen network model, several optimization techniques have been proposed to determine
network parameters and structures from the available data [3][4].
Among the many computational methods, evolutionary algorithms (EAs) have been
widely used to solve many optimization problems with good results, and can be used for the
network modeling task here. EAs are population-based approaches that evaluate many
solutions simultaneously in the search space. They are likely to find a global solution for a
given problem. However, these algorithms involve stochastic search procedures and require
many iterations to converge to a good solution. Therefore, the speed of convergence becomes
an important factor to be considered. Recently, a new population-based optimization
technique, namely particle swarm optimization (PSO, [5]), was proposed as an alternative to
6more accurately. Compared to the discrete variable models, the differential equation models
can represent the underlying physical phenomena by the virtue of their use of continuous
variables. The other commonly used type of continuous variable model is the neural
network-based model, and among which the recurrent neural network (RNN) model is the
most successful one. This model is continuous in time, and uses a transformation function to
transfer the inputs into shapes similar to those observed in natural processes. Although
continuous variable models can more accurately model the system dynamics of gene
networks, this modeling approach can only be applied to relatively small systems due to their
computational complexity.
For the above models, many computational methods have been proposed to infer the
relevant network parameters correspondingly. For example, Genetic Algorithm (GA, [11])
has been used to evolve network parameters in [12], and the back-propagation learning
method has been used to infer parameters for RNN-based gene networks in [13]. However, as
different researchers have made various assumptions and experimental conditions, it is
difficult to compare those methods in an objective way. In this work, we develop a hybrid
approach of Genetic Algorithm and PSO to derive network parameters. In general, a solution
in GA is represented as a fixed length string of genes; each of them is regarded as carrying a
genetic feature. A fitness function is defined to evaluate the solutions to determine the fitters.
GA is operated as a cyclically iterative mechanism, which includes a sequence of selecting
parents and creating children, after the initialization phase. The selection phase involves
probabilistically choosing individuals from the current population as parents to generate
offspring to form a new population, and the recreation phase is to apply genetic operators,
such as reproduction, crossover, and mutation to the selected individuals for the generation of
new ones.
PSO is also a population-based technique that shares many features with other EA
methods for solving optimization problems. It tries to mimic the goal seeking behavior of
biological swarms. The basic PSO algorithm contains a set of particles and operates in an
iterative manner. Each particle is characterized by its position and velocity, and it moves in
the solution space. The position of each particle represents a potential solution and is
evaluated by a predefined fitness function. During the iterative search process, each particle
remembers its previous best position and the best position of any particle in the swarm. Then
8interaction from gene j to i. The above set of parameters defines an S-system model. To infer
an S-system model is thus to estimate all of the 2N (N+1) parameters simultaneously.
As in a curve-fitting optimization problem, the goal here is to minimize the accumulated
discrepancy between the gene expression data recorded in the dataset (desired values) and the
values produced by the inferred model (actual values). The desired values mean the real
measurements in the laboratory experiments, while in our experiments they mean the data
generated from the collected models. Thus, the performance of a certain model m can be
defined directly as the mean squared error over the time period:

  




 
N
i
T
t
d
i
d
i
a
i
m tx
txtx
p
1 1
2
)(
)()(
in which )(txdi is the desired expression level of gene i at time t, )(tx
a
i is the actual value
obtained from the inferred model, N is the number of genes in the network, and T is the
number of time points in measuring gene expression data during the period. A small penalty
term measuring the connection between genes can be added to the fitness function to
discourage the connections (e.g., [12]), but it is not used in this work because it is not the
main focus here.
As can be observed, it is difficult to determine the large number of parameters involved
in a GRN, especially when the complexity of regulation increases along with the number of
genes involved. Although many intelligent computing techniques for parameter
approximation have been proposed to derive solutions, approaches that are more efficient are
still needed to resolve this high dimensional problem. In this work, we establish a
methodology for the construction of S-systems from two directions, bottom-up and top-down,
to deal with the scalability problem. The former is to develop an enhanced GA-PSO hybrid
approach to determine the system parameters defined above, and the latter is to tackle this
problem in a divide-and-conquer manner that involves a network decomposition procedure to
reduce the task complexity. The details are described in sections 3.2 and 3.3, respectively.
3.2 An Adaptive GA-PSO Hybrid Approach
To infer GRNs, our hybrid approach includes both GA and PSO procedures to exploit
their respective advantages. As in other evolution-based methods, the first step in inferring a
network model is to define an appropriate representation to characterize the solution. Here
10
Fig. 1. The main flow of the proposed GA-PSO hybrid.
3.2.1 The Adaptive Strategy
In our application, p is designed to have a fixed value (estimated from a preliminary
test), while r is a variable whose value changes during the run to control the population
diversity. In this work, the randomness rate r increases linearly in proportion to the
generation number to maintain population diversity. This adaptive strategy is based on the
observation that the PSO method converges very fast, but at the end of the run it tends to
perform local search, so a high rate of randomness is desired. Though more complicated
strategies (for example, a non-linear function) can be used to change the randomness rate
during the experimental run, a simple linear strategy described above is sufficient enough to
deliver superior performance in our application of network inference. The corresponding
effect will be shown in the experimental section below.
3.2.2 The PSO and GA Parts
In the PSO procedure shown in Fig. 1, particles are potential solutions flying in the
search space defined by the parameters, each of which has its position and velocity. To
enhance the individual performance, the main operator here is the velocity updating for the
particles, which combines the best position reached by the swarm of particles and the best
position reached by a certain particle during its flying history. It has the effect that particles
move towards the best position of the swarm. In this work, the velocity and the position of a
Population
ranking
Part 2 = (1-p)%Part 1 = p%
indpop_size….indk+1indk….ind1
random
r%
parent poolPSO procedure
(velocity/position update)
(1-p-r)%
Candidate List
(1-p)%p%
indpop_size….indk+1indk….ind1
GA procedure
(crossover/mutation)
Initialization:
random population
12
but accelerated away from the current directions in order to increase population diversity.
Then the commonly used non-uniform mutation procedure, as described in [11], is performed
to fine-tune the numerical values of the individuals in order to infer the network parameters.
3.2.3 Model Selection
As analyzed previously, inferring a gene network is to determine network parameters for
the chosen computational network model, and an adaptive GA-PSO method is developed to
search the space constituted by these parameters to find the appropriate solutions. However,
due to the cost consideration of laboratory experiments for data collection, in the real world
situations, the number of data points available is often smaller than that of the parameters to
be determined. That is, the network inference is in fact an under-determined problem. It is
thus possible to obtain various combinations of network parameters (i.e., solutions) with
error very close to zero. From the numerical optimization point of view, these combinations
can all be considered as feasible solutions. To infer solutions with special biological meaning,
domain knowledge must be integrated into the computational methods. A simple and efficient
way is to take the form of parameter constraint for knowledge representation. This way, a
biologist can explicitly encode his prior knowledge of the gene concentrations or the
regulation relationships between genes in the forms of numerical constraints (e.g., c1≦ npi≦
c2 or npi≦ npj, in which c1, c2 are certain constants and npi, npj are network parameters).
The constraints specified for parameters can then be used to restrain the solution search, and
only the ones meaningful to the domain experts will be derived.
3.3 Gene Clustering
For small networks, the search-based GA-PSO approach presented in the above section
can be used to infer the entire network models directly. Additionally, to solve more
complicated reconstruction task, we also develop a clustering-based method to decompose
the search space and to reduce the task complexity. Clustering is a useful exploratory
technique for the analysis of gene expression data. The hypothesis of gene clustering is that
the genes in a cluster may share some common functions or regulatory elements and can thus
be considered and modeled together. In our method, a clustering technique is first employed
to group the genes into tightly coupled small-scale networks, based on the analysis of their
corresponding expression data, and then the small networks can be decomposed again in a
14
Where x(t) is the signal to be analyzed, a and b represent the scaling factor and the translation
along the time axis, respectively (to scale the wavelet at time b with a factor of a), and the
superscript asterisk denotes the complex conjugation ofψ(t).
In the CWT form, the scaling and translation factors a and b change continuously. For
practical computation, the discrete wavelet transfer (DWT) is often used, and which can be
achieved by restricting the variation in scale and translation (usually to powers of 2). When
the scale is changed in powers of 2, that is, a = 2m and b = n2m (n, m are integers), the DWT
can thus be described as:
DWTψx(m, n) = dtnttx mm )2()(2 2/  


  
For discrete-time signals, the above wavelet computation can be performed equivalently
by simply using the filtering processes. That is, the multi-resolution analysis is carried out by
using two channel filter banks composed of a low-pass filter h and its complementary
high-pass filter g. With the specific initial condition and standard quadrature mirror filter
condition for h, a sequence of filters with increasing length can be derived. Fig. 3 illustrates
the subband decomposition of DWT implementation for a signal x. Each stage in the figure
consists of two filters and two downsamplers by 2 (denoted as ↓2). The scaling and wavelet
functions can be obtained from the filters. Then the approximation coefficient ai and detailed
coefficient di of the DWT decomposition at each resolution i can be calculated from these
functions accordingly. In this way, the original signal x can be decomposed and described as:
 li il dax 1
where l is the resolution level the signal to be analyzed. More details on the formulation can
be found in [17].
Fig. 3. The signal decomposition of DWT implementation.
As can be seen, DWT can compress an original signal consisting of many data points
into a few parameters (i.e., wavelet coefficients) that characterize the behavior of the signal.
x(n)
g(n) ↓2
h(n) ↓2
d1
a1
g(n) ↓2
h(n) ↓2
d2
a2 …
16

Then the weight vectors of the winning neuron and its neighborhood neurons are updated by
the following rules:
Wi(t +1) = Wi(t) +α(t)[X(t)－Wi(t)], if iNk(t)
Wi(t +1) = Wi(t), if iNk(t)
where α(t) and Nk(t) are the learning rate and the neighborhood function, respectively. They
have pre-specified values and gradually decrease to zero with time t. With the above
adaptation procedure, the weight vectors will converge to stable values. As a result, the SOM
network can form gene clusters of the input vectors (expression data) with similar properties
by groups of neurons with similar weights.
4. Experiments and Results
After describing the proposed methodology for network reconstruction, we present three
series of experiments for performance evaluation. The first series compares the performance
of different inference methods, in which five different datasets for small-scale networks were
used. The second series of experiments is to examine whether our method can be used to
infer robust networks. Finally, the proposed inference method was coupled with a clustering
technique to reconstruct complicated networks with more gene nodes.
4.1 Performance evaluation for inferring networks
To evaluate our hybrid GA-PSO method objectively, we collect several datasets that are
commonly used and are available from the related works, to conduct the experiments on
network reconstruction. In addition, to compare the proposed method with others, we have
implemented different methods, including the ordinary GA, PSO, and two hybrid GA-PSO
methods (which have been widely used for performance comparison [8][9]).
In the experiments, the first dataset was derived from a five node regulatory network as
reported in [18]. To collect time series data, we started the network operations and continued
the operations for 30 simulation time steps. The relationships among the nodes are described
as follows:
18
For the above datasets, the proposed hybrid GA-PSO approach has been employed to
infer the S-system network models. As described in Section 3.2, in the proposed approach a
certain amount of individuals are randomly generated to form the parent pool for the creation
of new individuals. To assess the corresponding effect, in the experiments we chose a fixed
rate of 70% (based on a preliminary test) of the individuals for PSO improvement, and
employed static strategies with different proportions of random individuals (i.e., r is set to
10%, 30%, and 50%, respectively) to infer the solutions. In addition, a dynamic strategy was
designed to adjust the random rate automatically during the evolutionary process, to reduce
the effort of selecting an appropriate randomness rate. This strategy is to linearly increase the
randomness rate (i.e., r varies from 10% to 50%) in proportion to the generation number, to
maintain population diversity.
Twenty independent runs were conducted and the population size was 400 for each run.
Figs 5-9 compare the behaviors of the original networks and the networks inferred by our
approach, in which the x-axis represents time step, and the y-axis, the concentration of
different gene components. As can be seen, all the network models can be inferred
successfully: the behaviors of the inferred networks are very similar to the original ones, in
which many of the genes generate almost identical data sequences.
As mentioned above, the other four methods were also implemented and used to
reconstruct network reversely from the same datasets. For each method, twenty independent
runs were conducted for each dataset, and the experimental settings remained the same as in
the runs by the proposed method. Tables 1-5 show the results of the five datasets,
respectively, in which the mean, standard deviation, best and worst performance of the runs
are listed for each method. From these tables, we can observe that the proposed method, with
either the fixed or the dynamic strategy, outperforms all others in inferring gene networks.
Our hybrid method also gives smaller standard deviations for all sets of experimental runs
than others. It indicates that our method is more stable than others. To observe the converged
system behaviors of different computational methods, Figs 10-14 compare the fitness curves
3187.0
2
6600.0
14
8352.0
3
2282.0
2
8782.0
13
2960.0
2
5929.0
12
2768.0
2
6345.1
1
2771.0
2
8993.0
11
3568.0
0735.05433.0
8574.13067.3
4777.01125.3
XXX
XXXX
XXX
XXXXX



 




20
0
0.4
0.8
1.2
1.6
1 4 7 10 13 16 19 22 25 28
G1 G2 G3 G4 G5
0
0.4
0.8
1.2
1.6
1 4 7 10 13 16 19 22 25 28
G1 G2 G3 G4 G5
Fig. 8. The original (left) and inferred (right) network behaviors for dataset 4.
0
20
40
60
80
100
120
140
160
1 3 5 7 9 11 13
G1 G2 G3 G4
0
20
40
60
80
100
120
140
160
1 3 5 7 9 11 13
G1 G2 G3 G4
Fig. 9. The original (left) and inferred (right) network behaviors for dataset 5.
Table 1. Results obtained by different methods for dataset 1.
GA PSO H1 [8] H2 [9] This work
r = 0.1 r = 0.3 r = 0.5 dynamic
Avg 1.3075 0.6524 0.6150 0.0487 0.0370 0.0311 0.0450 0.0271
Best 0.6498 0.4365 0.3471 0.0192 0.0083 0.0106 0.0183 0.0077
Worst 2.0916 0.9091 0.7729 0.0870 0.0521 0.0473 0.0668 0.0512
S.D 0.5107 0.1554 0.1498 0.0217 0.0170 0.0132 0.0165 0.0148
Table 2. Results obtained by different methods for dataset 2.
GA PSO H1 [8] H2 [9] This work
r = 0.1 r = 0.3 r = 0.5 dynamic
Avg 0.4210 0.4982 0.1174 0.0246 0.0242 0.0180 0.0169 0.0164
Best 0.2322 0.2370 0.0792 0.0177 0.0110 0.0091 0.0091 0.0093
Worst 0.6494 0.6603 0.1689 0.0318 0.0323 0.0265 0.0239 0.0218
S.D 0.1506 0.1564 0.0373 0.0051 0.0077 0.0067 0.0044 0.0039
22
0
1
2
3
4
1 51 101 151 201 251 301 351 401 451
generation
fi
tn
es
s
(e
rr
or
)
GA
PSO
H1
H2
This work
Fig. 11. Comparison of the fitness curves by five different methods for dataset 2.
0
8
16
24
32
40
1 201 401 601 801 1001 1201 1401 1601 1801
generation
fi
tn
es
s
(e
rr
or
)
GA
PSO
H1
H2
This work
Fig. 12. Comparison of the fitness curves by five different methods for dataset 3.
0
0.1
0.2
0.3
1 51 101 151 201 251 301 351 401 451
generation
fit
ne
ss
(e
rr
or
)
GA
PSO
H1
H2
This work
Fig. 13. Comparison of the fitness curves by five different methods for dataset 4.
24
4.2 Network Robustness
In addition to the issue of parameter fitting, network robustness is an important factor to
be considered in network modeling. In the process of inferring GRNs from the measured
gene expression dataset, the target networks may be perfectly inferred. But it should be noted
that the data samples collected at different time points from the microarray experiments are
very limited, and which often causes the over-fitting problem. That is, the models perfectly
fitting the dataset generally give poor performance in prediction. In addition, as is known,
gene expression measurements are unreliable; they always contain a certain amount of noises.
Under such circumstances, the obtained networks are not robust as expected.
To infer a robust gene network, the criterion of adding noises to the dataset for network
inference is proposed [23]. In fact, it has been shown that adding noises of small amplitude to
the dataset is equivalent to a Tikhonov regularization [24]. It is also known that the Tikhonov
regularizers are especially suitable for modeling work with insufficient sampling data.
Therefore, when a regularization term is hard to find in the modeling process, adding noises
has been advocated as a simple alternative way for regularization. In this way, the prediction
capability of the inferred network on the dataset is not perfect any more, whereas the
robustness will be optimal and the solution stable [24].
In this section, we adopt the above strategy to infer robust networks. Instead of
expanding the original measured data set with a set of noisy duplicates (to overcome the
problem of insufficient training samples, as reported in [23]), here we introduced some
random noises to the desired data to simulate the effect of data disturbance. Three sets of
experiments have been conducted for comparison, in which the original five datasets reported
Fig. 15. Solutions within the self-organizing feature map.
26
Two datasets have been used in the experiments of modeling large networks. The first
dataset is a ten nodes artificial dataset created manually by Genexp. To collect data, initial
parameters were specified for network operation and then the expression data were recorded
for 30 consecutive time points. Since it was difficult to reconstruct the entire network from
these time series data directly by the inference method, the gene clustering method described
in Section 3.3, including the procedures of wavelet transform and SOM, was used to group
the genes. Two clusters were observed, one for genes 1, 2, and 3, the other for genes 5, 6, 7, 8
and 9. Obviously, genes 4 and 10 did not belong to any of the above two clusters. After
measuring the gene distance and calculating the Pearson’s corelation coeficients between
the genes, we decided to organize the genes into four parts as shown in Fig. 16, in which
genes 4 and 10 were considered as outliers. In the experiments, the proposed GA-PSO
approach was used to infer networks for the two major clusters, and then the network
parameters obtained were used as initial settings to infer the overall network at a higher level.
The results for the two subnets are shown in Fig. 17 (a) and (b), respectively, and Fig. 18
presents the system behaviors of the original and reconstructed networks over the 10 genes. It
can be observed that the behavior of the trained network is very similar to the original one, in
which many of them have almost identical data sequences. These results evidently show the
efficiency of the proposed approach.
Fig. 16. The decomposition of the original network.
4
C1
1 2 3
C2
5 6
7 8 9
10
28
The second dataset used in this set of experiments is the real experimental dataset Rat
CNS (central nervous system), taken from [25]. This dataset includes expression data of 112
genes collected from 9 time points of different phases (embryonic, postnatal, and adult).
Again, the gene clustering method was used to group the genes. Out of the data from the 112
genes, 103 of them were categorized into 6 different clusters and 9 genes did not belong to
any cluster. One of our clusters consisting of 19 genes, is very similar to one reported in a
previous study dealing with rat CNS data [25] (containing the 17 gene cluster, in fact). To be
consistent with the previous study and to preserve the meaning of the cluster as the original
work, we decided to use the 17 gene cluster reported in [25] as the target network to be
reconstructed.
As the genes within the same cluster are closely related, it is not practical to group them
by the same clustering method again. Therefore, once the above target network had been
determined, the genes were decomposed into four sub-groups according to the mutual
information between them, in which some genes belonged to more than one sub-group. Table
6 lists the details of the decomposed results in which the four sub-groups have 8, 5, 4, and 5
nodes, respectively. Then the 4 subnets, and afterward the target network, were built. Fig. 19
(a)-(d) presents four sets of behaviors of the original and inferred sub-networks group by
group. Again, very similar behaviors between the original and inferred sub-networks can be
observed. After that, the network parameters of the inferred subnets were used as the initial
settings for the individuals in the experiments of inferring the overall network. Fig. 20 shows
the corresponding network behaviors. It indicates that the proposed gene clustering approach
can be efficiently and successfully used to model networks of relatively large size.
Table 7. The details of each sub-group
Group(#genes) Gene Names
sub-a (8) NFH, NFM, MOG, GRg1, NGF, Afgf, GFAP, cfos
sub-b (5) S100beta, mGluR1, CNTF, GFAP, cfos
sub-c (4) ChAT, NMDA2A, Bfgf, MOG
sub-d (5) mAChR4, cjun, IP3R2, GFAP, cfos
30
0
0.2
0.4
0.6
0.8
1
1.2
1 4 7 10 13 16 19 22 25 28
(a)
0
0.2
0.4
0.6
0.8
1
1.2
1 4 7 10 13 16 19 22 25 28
(b)
Fig. 20. The overall behaviors of the original (a) and inferred (b) networks.
5. Conclusions
In this work, we have emphasized the importance of inferring GRNs from gene
expression profiles, and indicated that the two most crucial steps in network inference are
selecting the network model and fitting the time series data into the network parameters.
Depending on the biological level to be studied, many models have been proposed to
simulate GRNs, and different computational methods have also been developed to
reconstruct networks accordingly. Instead of identifying which model and method are most
suitable for network reconstruction, here we have concentrated on establishing a practical
methodology that can model GRNs and is scalable for inferring large-scale networks. As
S-systems can work as dynamical systems as GRNs do, our work has adopted this model to
represent GRNs, and developed a hybrid GA-PSO method to infer network models from
expression data. The results have shown that our method can infer networks successfully and
has prominent performance. Meanwhile our work takes the form of knowledge-based
constraints to restrain the proposed search-based method and can evolve meaningful
32
[6] Angeline, P. J. (1998) Evolutionary optimization versus particle swarm optimization:
philosophy and performance difference. Proceedings of the International Conference on
Evolutionary Programming, San Diego, California, March 25–27, pp.601–610. Springer,
Berlin.
[7] Eberhart, R. C. and Shi, Y. (1998) Comparison between genetic algorithms and particle
swarm optimization. Proceedings of the International Conference on Evolutionary
Programming, San Diego, California, March 25–27, pp.611–616. Springer, Berlin.
[8] Settles, M. and Soule, T. (2005) Breeding swarms: a GA/PSO hybrid. Proceedings of
Genetic and Evolutionary Computation Conference, Washington DC, June 25–29,
pp.161–168. ACM Press, MA.
[9] Grimaccia, F., Mussetta, M. and Zich, R. (2006) Genetical swarm optimization:
self-adaptive hybrid evolutionary algorithm for electromagnetics. IEEE Trans. on
Antennas and Propagation, 55, 781–785.
[10] Elhossini, A., Areibi, S. and Dony, R. (2010) Strength pareto particle swarm
optimization and hybrid EA-PSO for multi-objective optimization. Evolutionary
Computation, 18, 127–156.
[11] Michalewicz, Z. (1999) Genetic Algorithms + Data Structures = Evolution Programs.
Springer, Berlin.
[12] Ho, S.-Y., Hsieh, C.-H., Yu, C.-F. and Huang, H.-L. (2007) An intelligent two-stage
evolutionary algorithm for dynamic pathway identification from gene expression profiles.
IEEE/ACM Trans. on Computational Biology and Bioinformatics, 4, 648–660.
[13] Lee, W.-P. and Yang, K.-C. (2008) A clustering-based approach for inferring recurrent
neural networks as gene regulatory networks. Neurocomputing, 71, 600–610.
[14] Engelbrecht, A. P. (2005) Fundamentals of Computational Swarm Intelligence. Wiley,
West Sussex.
[15] Kohonen, T. (1990) The self-organizing map. Proceedings of the IEEE, 78, 1464–1480.
[16] Mallat, S. (1989) A theory for multiresolution signal decomposition: the wavelet
representation. IEEE Trans on Pattern Analysis and Machine Intelligence, 11, 674–693.
[17] Daubechies, I. (1990) The wavelet transform, time-frequency localization and signal
analysis. IEEE Trans. on Information Theory, 36, 961–1005.
[18] Cao, H., Kang, L. and Chen, Y. (2000) Evolutionary modeling of systems of ordinary
1國科會補助專題研究計畫項下出席國際學術會議心得報告
日期： 99 年 10 月 30 日
一、參加會議經過
本人於 9月 26 日搭機前往日本東京大學（Tokyo University）參加美國電機工程學會的
機器人與生物醫學工程合辦的國際會議，會議地點在東大的 Hongo 校區工程二館，會期共四天
（9/26-9/29）。由於此會議包含不同領域主題，會議依不同類型的相關主題（生物醫學、資訊、
機電）分為數個 session 同時進行，且每天都安排有 Plenary Lecture。由於第一天到會場已
是下午且大會並未安排主要議程，因此完成報到手續後僅其中一個小型的關於修復型機器人介
紹的 workshop。會議期間參與了數場大會的應邀演說及場次報告，其中印象最深刻的主要有
日本 Keisuke Morishima 教授的演講 “Cellular Build Up Wet Robotics Toward Regenerative
Living Machine”及南韓Woo Jin Hyung教授關於目前機器人在外科手術的應用演說“Current
Status of Robotics Surgery”。會議期間大會亦有安排實驗室參觀及廠商特殊儀器展示，增
進學者交流及瞭解實務應用。
計畫編號 NSC 97－2221－E－110－063－MY2
計畫名稱 結合知識本體論及機器學習方法建構大型基因調控網路之研究
出國人員
姓名
李偉柏
服務機構
及職稱
中山大學資管系副教授
會議時間 99 年 9 月 26 日至
99 年 9 月 29 日
會議地點 日本東京
會議名稱
(中文) IEEE 生物醫學機器人及仿生機電國際研討會
(英文) IEEE/RAS-EMBS International Conference on Biomedical Robotics and
Biomechatronics
發表論文
題目
(中文) 應用智慧型計算於機器人的模仿學習
(英文) Intelligent Computing for Demonstration-Based Robot Learning
附件四
無衍生研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
