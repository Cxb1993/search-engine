 1 
Mining Top-K Frequent Closed Itemsets from Data Streams 
 
Hua-Fu Li1, Ming-Ho Hsiao2 and Hsuan-Sheng Chen2
1Department of Computer Science                 2Department of Computer Science 
     Kainan University, Taoyuan, Taiwan      National Chiao-Tung University, Taiwan 
 
 
Abstract 
 
Mining closed frequent itemsets from data streams is one of 
most important research issues of stream data mining. 
However, it is not easy for users to determine a proper 
minimum support threshold. Hence, it is more reasonable 
to ask users to set a bound on the result size. Therefore, an 
online, single-pass algorithm, called TKC-DS (Top-K 
frequent Closed itemsets of Data Streams), is proposed for 
mining top-K closed itemsets from data streams efficiently. 
A novel data structure, called CIL (Closed Itemset Lattice), 
is developed for maintaining the essential information of 
closed itemsets generated so far. Experimental results show 
that the TKC-DS algorithm is an efficient method for 
mining top-K frequent closed itemsets from data streams. 
Keywords: data mining, data streams, closed itemsets, top-
k frequent closed itemsets, incremental mining. 
 
1. Introduction 
In recent years, mining of data streams has becomes one of 
the most important research issues of data mining [3, 10, 
12]. A data stream is an unbounded sequence of data 
elements arriving at rapid speed. Data streams are found in 
a lot of applications including network monitoring and 
traffic management, sensor network monitoring, transaction 
analysis of large electronic-commerce, stock tickler 
monitoring, web click steam monitoring and mining.  
Based on the unique characteristics of data streams, there 
are three main challenges in mining data streams [3, 10, 12]: 
(1) each data element of data streams should be examined 
at once since the data is arrived at a high speed; (2) the 
memory requirement of mining data streams should be 
bounded even though new data elements are generated 
continuously; (3) the mining results are usually expected to 
be outputted in real time. Hence, new approaches are 
designed for mining useful patterns from data streams.  
Efficient stream mining methods based on a user-
specified minimum support threshold min_sup have been 
studied extensively, including frequent itemset mining [18, 
14, 13, 16], frequent closed itemset mining [7, 17], and 
maximal frequent itemset mining [15]. However, the setting 
of minimum support threshold is quite tricky and it leads to 
the following problem that may hinder its popular use. 
There are two challenges of minimum-support based stream 
data mining: (1) if the value of minimum support threshold 
is set to be too small, the pattern mining algorithm may 
lead to the generation of thousands of patterns; (2) if the 
value of minimum support constraint is set to be too big, 
the mining algorithm may often generate a few patterns or 
even no answers. As it is difficult to predict how many 
patterns will be mined with a user-defined minimum 
support threshold, the top-k pattern mining has been 
proposed [9, 22, 23, 6, 19].  
Unlike mining frequent patterns, there are not so many 
methods proposed for mining top-K frequent patterns from 
data streams. This is partly due to the complexity of the 
problem. To the best of our knowledge, the algorithm, 
called Top-K Lossy Counting or Lossy for simplicity, 
proposed Wong and Fu [24] is the first algorithm for 
mining top-K frequent itemsets from data streams. The 
algorithm is based on the well-known existing stream 
mining algorithm BTS [18]. However, there are no 
methods developed for mining top-K frequent closed 
itemsets from data streams. Hence, we proposed the first 
algorithm, called TKC-DS (Top-K frequent Closed itemsets 
of Data Streams), for interactive mining of top-K frequent 
closed itemsets from data streams in this paper. 
Our contribution can be summarized as follows. 
(1) We propose an efficient single-pass algorithm, 
called TKC-DS (Top-K frequent Closed itemsets of Data 
Streams), for mining a set of top-K closed frequent itemsets 
from data streams within a transaction-sensitive sliding 
window. 
(2) An effective data structure, called CIL (Closed 
Itemset Lattice), is developed to maintain the essential 
information about the current set of closed itemsets from 
data streams. 
(3) The experimental results show that the proposed 
TKC-DS algorithm achieves high accuracy, less memory 
usage and fast execution time. 
The remainder of this paper is organized as follows. 
Section 2 introduces the problem of mining top-K frequent 
closed itemsets over stream sliding windows and related 
work. An efficient algorithm TKC-DS and an effective data 
structure CIL are proposed in Section 3. Experimental 
results are discussed in Section 4. Finally, we conclude this 
work in Section 5. 
 
2. Problem Definition 
In this section, the research problem of mining top-k closed 
frequent itemsets over data stream within a transaction-
sensitive sliding window is defined.  
Let I = {i1, i2, …, im} be a set of literals, called items. An 
itemset is a non-empty set of items. An l-itemset is a set of 
l items and l is the size of l-itemset. A transaction T = <TID, 
(x1, x2, …., xk)> is composed of a set of items, i.e., (x1, 
x2, …., xk), and a unique transaction identifier, i.e., TID.  
A transaction data stream TDS = {T1, T2, T3, …, TN}, is 
an unbounded sequence of transactions, where N is TID of 
latest incoming transaction TN. In a transaction data stream, 
a transaction-sensitive sliding window SW = [TN－w+1, TN－
w+2, …, TN] is a window that slides forward for every 
incoming transaction, where N is TID of latest incoming 
transaction and w is the size of SW, i.e., SW consists of w 
transactions.  
The support of an itemset X, denoted as sup(X), is the 
number of transactions of SW containing X as a subset. An 
itemset X is called a closed itemset (CI) if there exists no 
itemset X’ such that (1) X’ is a proper superset of X, and (2) 
every transaction containing X also contains X’. A closed 
 3 
Recently, Metwally et al. [19] proposed a single-pass 
algorithm to mine the top-K data elements, i.e., top-K items, 
from data streams. Recently, Wong and Fu [24] studied the 
problem of mining top-K frequent itemsets from data 
streams within a sliding window and proposed a BTS-
based algorithm, called Top-K Lossy Counting, which is 
probably closest to our work here. 
3. TKC-DS Algorithm 
3.1 Bit-Vector Representation of Item 
Bit-vector representation of item is an efficient method 
used to record the complete information of sliding windows 
of data streams [16, 17]. It can be used to reduce the time 
and memory needed to slide the windows. Bit-vector 
representation of item is described as follows. 
For each unique item x of sliding window, a bit vector 
representation with w bits, denoted as Bit(x), is constructed, 
where w is the size of sliding window. Moreover, if an item 
x is in the i-th transaction of current sliding window, the i-
th bit of Bit(x) is set to be 1. Otherwise, it is set to be 0.  
For example, in Example 1, the bit vector of item a is 
10100, i.e., Bit(a) = 10100, in SW1, since item a appears in 
T1 and T3 of SW1. In SW2, Bit(a) = 01000, since item a 
appears only in T2 of SW2. 
3.2 Construction of Closed Itemset Lattice  
In this section, the proposed data structure Closed Itemset 
Lattice (CIL) is defined and the constructing process of the 
CIL is introduced as follows. 
Definition 6 Closed Itemset Lattice (CIL) is an extended 
lattice structure and defined as follows. 
(1) CIL is composed of three substructures: a list of bit-
vectors of items (BV-list), a set of closed itemset tree (CI-
tree), a list of supports of closed itemsets (S-list), and a 
hash table of closed itemsets (HTC). 
(2) BV-list consists of three parts: a list of items, i.e., e1, 
e2, …, em, a list of corresponding bit-vectors, i.e., Bit(e1), 
Bit(e2), …, Bit(em), and a list of amount of closed itemsets 
with root node ei, i.e., CI-num(e1), CI-num(e2), …, CI-
num(em). Each entry ei of BV-list is a root node of CI-tree 
and composed of three fields: item-id, bit-vector, and child-
pointer, where child-pointer points to the child nodes of 
root node item-id. 
(3) CI-tree is an extended prefix tree and its root node is 
one of the entries of BV-list. Each node of CI-tree consists 
of five fields: item-id, Bit(item-id) sup(item-id), child-
pointer and sibling-child-pointer, where sibling-child-
pointer points to the child node of sibling of item-id and 
the child node is a superset of node item-id. Moreover, 
each node nX of CI-tree is an itemset X. A child node nX’ is 
obtained by adding a new item to X.  Note that only closed 
itemsets are maintained in the set of CI-trees, not all 
itemsets. A CI-tree with a root node item-id is denoted as 
CI-tree(item-id). Furthermore, the total number of nodes of 
CI-tree(item-id) is denoted as |CI-tree(item-id)|. 
(4) HTC is a hash table and is used to check whether an 
itemset is closed or not. Moreover, HTC is used to store all 
closed itemsets with their supports as keysii. 
Constructing algorithm of the CIL is given in Figure 2. 
                                                 
ii
 Assume that there are two frequent itemsets X and Y. If sup(X) = 
sup(Y) and X  ⊆ Y, X and Y have to be recorded in the same set of 
transactions. That means the itemset X is not a frequent closed 
itemset. Hence, the support of pattern is suitable to be the key of 
the hash table. 
In the constructing algorithm CIL-build, each node nX has 
a corresponding bit-vector, Bit(nX), used to maintain the 
support information of current sliding window. Procedure 
CIL-build is a depth-first method and checks all 
itemsets of CIL in lexicographic order as follows. First of 
all, function CIL-build is performed when a new node nX is 
not a subset of any other closed itemsets by using function 
HTC-check. Function HTC-check checks nX is closed or 
not and uses the support of nX as a hash key to speed up the 
subset checking. After subset checking, all candidate 
children of nX with frequent siblings and their 
corresponding bit-vectors are generated. Note that these 
bit-vectors are generated by performing the bitwise AND 
operation on Bit(nX) and its siblings. Next, CIL-build 
recursively calls itself to check each child of nX. Finally, if 
there are no children of nX with the same support as nX, nX 
is a closed itemset. Therefore, nX is maintained in the 
proposed data structure CIL. 
The constructing steps of CIL of first sliding window 
SW1 is given in Figure 3 and described as follows. First of 
all, the proposed TKC-DS algorithm computes all bit 
vectors of each item from SW1, i.e., constructs a BV-list of 
SW1. Hence, BV-list contains four items and four bit 
vectors, i.e., BV-list = {[(a): 10100], [(b): 11111], [(c): 
11110], [(d): 01001]}. After constructing the BV-list, TKC-
DS uses the function CIL-build, as shown in Figure 2, to 
construct the CIL.  
                                                                                               
Algorithm CIL-build (Constructing method of CIL) 
Input: A BV-list with m entries, where m ≥ 1. 
Output: A Closed Itemset Lattice (CIL). 
Method:  
Begin 
foreach entry nX of BV-list do 
  if HTC-check(nX) == FALSE then 
         foreach sibling nY of nX do 
             generate a new child node nX∪Y of nX ; 
  compute the Bit(nX∪Y) by using bitwise AND 
 Bit(nX) and Bit(nY);  
endfor 
foreach child nX’ of nX do 
   perform CIL-build(); 
endfor 
compute sup(nX) by counting Bit(nX); 
foreach child nX’ of nX  do 
   compute sup(nX’) by counting Bit(nX’); 
if sup(nX’) != sup(nX) then 
   nX is a closed itemset; 
   insert sup(nX) and nX into the HTC; 
   CI-num(nX) = CI-num(nX) + 1; 
   eliminate Bit(nX) from CI-tree; 
else 
   drop nX form CIL; 
endif 
endfor 
      endif 
   endfor 
End 
Figure 2: Algorithm of constructing CIL 
 5 
items (b) and (c) of CIL. The result is shown in Figure 5(b). 
From this figure, we can find that the support of 2-itemset 
(bc) of CI-tree(b) is modified to 3, i.e., sup(bc) = 3, based 
on the dropped transaction T1. Moreover, 2-itemset (bc) is 
still a closed itemset of CI-tree(b). Note that no child nodes 
of entry (c) of BV-list are needed to be modified in this 
example. 
 
Algorithm CIL-DOT (Delete the Oldest Transaction 
from CIL) 
Input: A CIL generated so far; 
Output: A CIL after deleting the oldest transaction Td; 
Method: 
Begin 
All bit vectors of items of BV-list are left shifted one bit; 
Reconstruct the dropped transaction Td = (x1x2…xp), where p 
≥ 1, by monitoring the leftmost bits of items of BV-list; 
foreach item xi of Td do /* where i =1, 2, …, p */ 
    if CI-num(xi) ≤ CCI-boundary(xi) then  /* CCI-boundary(xi) 
=  2(p − i)−1 */ 
    foreach node nj of CI-tree(xi) do 
        if nj ⊆ Td then 
                update sup(nj); /* sup(nj) = sup(nj) -1; */ 
                if sup(nj) = 0 then 
                    delete nj from CI-tree(xi); 
                    delete nj from HTC;  
else 
                   update the key of nj of HTC; 
/*key = sup(nj);*/ 
endif      
endif 
    endfor 
else  /* if CI-num(xi) > CCI-boundary(xi) */ 
generate candidate closed itemsets with prefix xi; by 
using BU-TEN on Td; 
         foreach candidate Cj with prefix xi do  
             if Cj ⊆ CI-tree(xi) then 
                 update sup(Cj); /* sup(Cj) = sup(Cj) -1; */ 
                 if sup(Cj) = 0 then 
                      delete Cj from CI-tree(xi); 
                      delete Cj from HTC;  
                      CI-num(xi) = CI-num(xi) – 1; 
else 
                    update the key of Cj of HTC; 
/*key = sup(Cj)*/ 
endif 
              endif 
         endfor 
endif 
endfor 
End 
------------------------------------------------------------------------ 
Figure 4: Algorithm CIL-DOT 
 
 
Figure 5: Deleting dropped information of T1 from CIL 
3.4 Inserting the New Transaction into CIL 
The second step of window sliding phase of TKC-DS 
algorithm is inserting the new incoming transaction into the 
CIL. Hence, a transaction-inserting method, called CIL-
INT (Inserting the New Transaction into CIL), is 
developed for improving the efficiency of TKC-DS and 
described as follows. First, all the bit vectors of items of 
BV-list are set their right-most bit to 1 or 0 based on the 
new incoming transaction TN. If the item xi is contained in 
the TN, the rightmost bit of Bit(xi) is set to be 1. Otherwise, 
it is set to be 0. 
In the proposed CIL-INT algorithm, an extend 
transaction enumeration method, called TD-TEN (Top-
Down Transaction-ENumeration), is used to generate a set 
of candidate closed itemsets from TN  = (x1, x2, …, xm). The 
process of TD-TEN is described as follows. First, TD-TEN 
uses the m-itemset, i.e., (x1, x2, …, xm), as a candidate 
closed itemset to verify the current CIL. If the candidate is 
an existing node of CI-tree(x1), TD-TEN updates the 
support and key of the m-itemset of CIL. Otherwise, the m-
itemset is inserted into CI-tree(x1) as a left node. At this 
moment, the support information of node is represented by 
a bit vector, not a support count. Then, TD-TEN 
enumerates the m-itemset, i.e., (x1, x2, …, xm), to one 
(m−1)-itemset, i.e., (x2, x3, …, xm). After that, same process 
is used on the (m−1)-itemset until 1-itemset, i.e., (xm). The 
CIL-INT algorithm is given in Figure 6. 
Now, we use the Example 1 to demonstrate the proposed 
CIL-INT algorithm. The processing steps of CIL-INT 
algorithm for the new transaction T6 = (abcd) of SW2 of 
Example 1 is described as follows. First, CIL-INT 
generates a maximal candidate closed 4-itemset, i.e., (abcd), 
from T6 based on TD-TEN scheme. Hence, a new leaf node, 
i.e., (abcd), of CI-tree(a) with a bit vector, i.e., Bit(abcd) = 
00001, is created. Moreover, its closed subset, i.e., (abc), is 
also in a bit vector representation, i.e., Bit(abc) = 01001. 
The result is shown in Figure 7(a). After processing the 4-
itemset (abcd), CIL-INT generates a 3-itemset (bcd) based 
on TD-TEN for maintaining CI-tree(b) of current CIL. 
Because itemset (bcd) is a existing node of CI-tree(b), the 
support information of all existing nodes of CI-tree(b), i.e., 
(bc), (bd) and (bcd), are increased by one and modified to a 
bit vector format as shown in Figure 7(b).  
Next, CIL-INT algorithm generates a 2-itemset (cd) and 
uses the itemset to verify the closed property of this itemset 
(cd). Since the support of itemset (cd) is equal to the 
support of its superset (bcd), it is not a closed itemset and is 
removed from CIL. Furthermore, 1-itemset (d) is in the 
same situation of 2-itemset (cd). The result is given in 
Figure 7(c). After processing all enumerated itemsets of T6, 
the support information is modified into a support counter 
format. The final result of inserting T6 of SW2 into CIL is 
shown in Figure 7(d). After sliding the window from SW1 
to SW2, the current CIL with HTC is given in Figure 8. 
 
Algorithm CIL-INT (Inserting the New Transaction into 
CIL) 
Input: A CIL without the oldest transaction Td and a new 
incoming transaction TN = (x1, x2, …, xm), where m ≥ 1. 
Output: A Closed Itemset Lattice (CIL). 
Method:  
Begin 
   foreach item xi of TN  do /*  ∀i, i = 1, 2, 3, …, m  */ 
        perform TD-TEN on TN to generate a candidate closed 
itemset Yi with prefix xi; 
 7 
performed on a 1.3GHz Intel Celeron PC with 1GB 
memory and performed in a Windows XP system. 
The synthetic data set, T10.I6.w100K, generated by IBM 
synthetic data generator [1, 2] is used to evaluate the 
performance of the proposed algorithm, where T is the 
average item  per transaction, I is the average length of 
maximal patterns, and w is the size of sliding window. Both 
synthetic data sets are consists of 1,000 different items.  
The performance measurements consist of memory usage, 
processing time of maintaining sliding windows and mining 
time of top-K frequent closed itemsets, processing time of 
maintain sliding windows is composed of initialization time 
of first sliding window and sliding time of 10,000 
consecutive sliding windows. Note that the minimum 
support threshold used in both algorithms Moment-K and 
NewMoment-K are set to be 1/w, where w is the size of 
working sliding window. Moreover, the default value of 
frequent closed itemsets to be mined K used in following 
experiments is set to be 1,000. 
 
4.1 Effect of Number of Frequent Closed 
Itemsets to be Mined K 
Figure 10 shows the memory usage for algorithms 
Moment-K, NewMoment-K and TKC-DS under different 
number K of frequent closed itemsets to be mined for 
T10.I6.w100K. The value K is changed from 100 to 1,000. 
The memory usages of all algorithms are independent of 
the value K since all closed itemsets are maintained in the 
CET of Moment-K, NewCET of NewMoment-K and CIL 
of TKC-DS. Note that Moment-K contains not only closed 
itemsets but also the infrequent gateway modes, 
unpromising gateway nodes and intermediate nodes. Hence, 
from this figure, we can find that the memory requirement 
of Moment-K algorithm is significant larger than that of 
algorithms NewMoment-K and TKC-DS.   
Figure 11 and Figure 12 give the processing time of 
maintaining sliding windows and mining time of top-K 
frequent closed itemsets for Moment-K, NewMoment-K 
and TKC-DS, respectively, under different number K of 
frequent closed itemsets to be mined. From these figures, 
we can see that the proposed TKC-DS algorithm runs faster 
than algorithms Moment-K and NewMoment-K under 
various sizes w of sliding window. 
As shown in the experiments of Section 4.1, the 
proposed TKC-DS algorithm outperforms both algorithms 
Moment-K and NewMoment-K in all the tests conducted 
with various K values. 
 
4.2 Effect of Various Window Sizes w 
In this section, the experiments of evaluating the effect of 
different window size are performed. The size w of sliding 
window is tested form 10,000 transactions to 100,000 
transactions. Figure 13 shows the memory usage for 
Moment-K, NewMoment-K and TKC-DS under different 
window sizes. The memory usages of all algorithms 
increase when the window size increases. From this figure, 
we can find that the memory requirement of Moment-K is 
significant larger than that of NewMoment-K and TKC-DS. 
Moreover, TKC-DS takes a smaller amount of memory 
space than NewMoment-K. This is because New-Moment-
K generates more candidates than TKC-DS.  
Figure 14 and Figure 15 give the processing time of 
maintaining sliding windows and mining time of top-K 
frequent closed itemsets for Moment-K, NewMoment-K 
and TKC-DS, respectively, under different window sizes w. 
From these figures, we can see that the proposed TKC-DS 
algorithm runs faster than Moment-K and NewMoment-K 
under various sizes w of sliding window. 
 
0
100
200
300
400
500
600
100 200 300 400 500 600 700 800 900 1000
frequent closed itemsets to be mined K
M
em
o
ry
 
u
sa
ge
 
(M
B
)
Moment-K NewMoment-K TKC-DS
 
Figure 10: Memory usage under different frequent closed 
itemsets to be mined K 
0
20
40
60
80
100
120
100 200 300 400 500 600 700 800 900 1000
frequent closed itemsets to be mined K
Pr
o
ce
ss
in
g 
tim
e 
(se
co
n
ds
)
Moment-K NewMoment-K TKC-DS
 
Figure 11: Processing time of maintaining sliding windows 
under different frequent closed itemsets to be mined K 
0
1
2
3
4
5
6
7
8
100 200 300 400 500 600 700 800 900 1000
frequent closed itemsets to be mined K
M
in
in
g 
tim
e 
(se
co
n
ds
)
Moment-K NewMoment-K TKC-DS
 
Figure 12: Mining time of top-K frequent closed itemsets 
under different frequent closed itemsets to be mined K 
 
0
50
100
150
200
250
300
350
400
10K 20K 30K 40K 50K 60K 70K 80K 90K 100K
Window size w (K=1,000)
M
em
o
ry
 
u
sa
ge
 
(M
B
)
Moment-K NewMoment-K TKC-DS
 
Figure 13: Memory usage under different sizes of sliding 
windows 
 9 
出席國際學術會議心得報告 
                                                             
計畫編號 NSC 96-2218-E-424-001- 
計畫名稱 資料串流上高效能之前 k 個封閉型頻繁樣式探勘之研究 
出國人員姓名 
服務機關及職稱 
陳宣勝 (計畫兼任助理) 
國立交通大學 博士研究生 
會議時間地點 6/23/08~6/26/08 德國漢諾威 
會議名稱 2008 IEEE International Conference on Multimedia & Expo (ICME 2008) 
發表論文題目 Efficiently Mining Frequent Patterns in Recent Music Query Streams 
 
一、參加會議經過 
本人於六月二十三日至六月二十六日赴德國漢諾威市參加 ICME 2008，這是多媒
體領域中重要的國際會議。本次會議的會議主席是 Jörn Ostermann (Leibniz Universität 
Hannover, Germany)，議程主席是 Milind Naphade (IBM Research, USA) 。其議程包括 3
場專題演講、26 個 Special Session 共 392 篇 Regular Paper 以口頭或海報方式發表、1 項
系統展示；此外，還有 7 門不同主題的教學課程。在論文投稿與評審方面，本次會議
論文的評審委員由來自各大學、研究機構與產業界等合計超過 15 個不同國家所組成；
最後從 803 篇投稿論文中選出 392 篇論文(約 50%接受率)。 
我們於六月十九日早上 7:50 從台灣出發(超過十九日即為暑期旺季，機票得加
價)，經過泰國蘇汪納蓬國際機場轉機後，於德國法蘭克福當地時間六月十九日下午
6:10 左右抵達法蘭克福國際機場(FRA)。夏天的德國約晚上十點才天黑，但是路上的店
約晚上八點就關光光了，而當時明明天還很亮，這和我們台灣的夜生活實在有很大的
差異。由於時差問題，我們立刻抵達住宿地點休息。在接下來的三天，我們順著萊茵
河往北，參觀萊茵河沿岸的小鎮及科隆大教堂，於二十二日晚上抵達漢諾威的住宿地
點休息，為隔天開始的會議做準備。 
四天的會議期間，我除了報告我們自己的論文外，也參加了 3 場專題座談 (主講人
分別為: Sebastian Thrun、Tsuhan Chen 與 Frank H.P. Fitzek)、3 場論文發表會，以及和
自己同一個 poster session 的與會者相互討論。就整體印象而言，從這次會議中，我深
刻瞭解到當前多媒體的相關研究以 Semantic Understanding of Multimedia、Searching for 
Multimedia Killer Application 和 Social Network 等領域最受矚目的。 
在參與的論文發表與討論中，我都挑選與自己的研究領域(動作分析與多媒體內容
了解)相關的題目聽，期望自己能透過參考別人對相近問題的不同看法，刺激自己看會
不會有不一樣的靈感發現新的問題或解決相同問題更好的方法。在論文發表中，有不
少與會者發問的問題是我所沒想到的，有的問題值得我深思，看能不能成為目前研究
的延續，藉此有更完整的研究成果。 
最後，在每日例行的會議結束後，我們利用漢諾威市便利的地上輕軌列車到漢諾
威大學參觀，以及參觀漢諾威著名的景點，例如：市政廳、賀倫赫森公園、教堂、車
站廣場、歌劇院等。其中輕軌列車是利用電力沒有污染，並且搭乘時可以看到地面上
的風景，具有觀光價值，十分值得我們的政府效法。 
總體而言，參加這次會議，除了在專業領域方面吸取到許多新知之外，在學術交
流方面也深深領略到國外優秀學者的風範和研究精神，也意識到學術研究的良性競爭
 11 
EFFICIENTLY MINING FREQUENT PATTERNS IN RECENT MUSIC QUERY 
STREAMS 
 
Hua-Fu Li  
Department of Computer Science 
Kainan University, Taoyuan, 
Taiwan 
hfli@mail.knu.edu.tw 
 
Ming-Ho Hsiao 
Department of Computer Science 
National Chiao-Tung University, 
Taiwan 
mhhsiao@csie.nctu.edu.tw 
 
Hsuan-Sheng Chen 
Department of Computer Science 
National Chiao-Tung University, 
Taiwan 
xschen@csie.nctu.edu.tw
Abstract 
 
Mining frequent melody structures from music data is one 
of the most important issues in multimedia data mining. In 
this paper, we proposed an efficient online algorithm, 
called BVMDS (Bit-Vector based Mining of Data Streams), 
to mine all frequent temporal patterns over sliding 
windows of music melody sequence streams. An effective 
bit-sequence representation is used in BVMDS to reduce 
the time and memory needed to slide the windows. An 
effective list structure is used to overcome the performance 
bottleneck of previous work, FTP-stream. Experiments 
show that the BVMDS algorithm outperforms FTP-stream 
algorithm, and just scans the streaming data once. 
 
1. INTRODUCTION 
 
In recent years, many applications generate large 
amount of data streams in real time. For example, 
sensor data generated from sensor networks, online 
transaction flows in retail chains, streaming Web 
click-sequences and records in Web applications, 
performance measurement in network monitoring and 
traffic management, call records in 
telecommunications [4].  
Mining data streams differs from mining traditional 
static data sets in two main aspects. First, the volume 
of a continuous data stream over its lifetime could be 
huge and fast changing. Second, the queries require 
timely answers, and the response time is short. Hence, 
it is not possible to store all the streaming data in 
main memory or even in secondary storage. This 
motivates the design for in-memory summary data 
structure with small memory footprints that can 
support both one-time and continuous queries. 
Furthermore, online method of mining such data has 
to sacrifice the correctness of their analysis results by 
allowing some counting errors, i.e., it generating 
approximate results, and only have one pass over the 
data [2] [4].  
    Mining music data is one of the most important 
research issues in multimedia data mining. Although 
several techniques have been developed recently for 
discovering and analyzing the content of static music 
data [3][5][6][10][11], new approaches are needed to 
analyze and discover the content of streaming music 
data. Li et al. [7][8] proposed efficient single-pass 
algorithms to find maximal frequent melody 
structures and closed frequent melody structures over 
the entire history of continuous music query streams. 
The problem comes from the context of online music-
downloading services (such as iTunes, Kuro and 
KKBOX), where the streams in question are streams 
of queries, i.e., music-downloading requests, sent to 
the server, and we are interested in finding the useful 
music melody structures requested by most customers 
during some period of time. With the processing 
model of music query streams presented in Figure 1 
[7][8][9], the melody stream processor and the 
summary data structure are two major components in 
such a streaming environment. The user query 
processor receives user queries in the form of 
<Timestamp, Customer-ID, Music-ID>, and then 
transforms the queries into music data (i.e., melody 
sequences) in the form of <Timestamp, Customer-ID, 
Music-ID, Melody-Sequence> by querying the music 
database. Note that the component Buffer can be 
optionally set for temporary storage of recent music 
melody sequences from the music query streams 
[7][8][9]. 
Recently, Li et al. proposed the first one-pass 
algorithm FTP-streams for mining for mining 
frequent patterns over recent music data streams, i.e., 
mining music data streams within a sliding window. 
However, the FTP-stream is an Apriori-based [1] 
single-pass algorithm. Hence, FTP-stream has the 
performance bottleneck of 2-candidates generation 
[1]. Therefore, in this paper, we proposed an efficient 
online mining algorithm, called BVMDS (Bit-Vector 
based Mining of Data Streams), to find the set of 
frequent temporal patterns over music query streams 
with a sliding window. An effective list structure, 
called 2C-list (List of 2-Candidates), is used to 
overcome the bottleneck of 2-candidates generation. 
Experiments show that the proposed algorithm is an 
efficient single-pass mining method in such a 
streaming environment. 
. 
 
Figure 1: Computation model for music query streams 
 
The remainder of the paper is organized as follows. 
 13 
 
Example 3 Consider the melody sequence stream in Figure 2. The 
first sliding window SW1 contains three melody sequences: m1, m2, 
and m3. The bit-sequences of items and 2C-lists of sliding window 
SW1 in the initialization phase are shown in Figure 3. 
 
3.2.2. Window Sliding Phase 
The phase is activated after the sliding window SW becomes full. 
A new incoming melody sequence is appended to the sliding 
window, and the oldest melody sequence is removed from the 
window. In order to remove the oldest information, an efficient 
window sliding method is used in the proposed algorithm BVMDS. 
Based on the bit-vector representation, BVMDS uses the bitwise 
left shift operation to remove the aged melody sequences from the 
set of items in the current sliding window. After sliding the 
window, an effective pruning method, called Item-Prune (IP), is 
used to improve the memory usage. The pruning approach is that 
an item X in the current sliding window is dropped if and only if 
X.sup = 0. The method is also used in FTP-stream algorithm [9]. 
Example 4 Consider the melody sequence stream in Figure 2. 
Before the fourth melody sequence <m4, (be)> is processed, the 
first melody sequence m1 must be removed from the current 
window using bitwise left shift on the set of items. Hence, Bit(a) is 
modified from 101 to 010. Similarly, Bit(c) = 110, Bit(d) = 000, 
Bit(b) = 110, and Bit(e) = 110. Then, the new melody sequence 
<m4, (be)> is processed by bit-sequence transform. The result is 
shown in Figure 4. Note that item d is dropped since Bit(d) = 000, 
i.e., sup(d) = 0, based on Item-Prune method. 
 
Figure 4: Bit-sequences of items and 2C-lists after sliding window 
SW1 to window SW2 
 
3.2.3. Frequent Temporal Patterns Generation Phase 
The phase is performed only when the up-to-date set of frequent 
temporal patterns is requested. In this phase, BVMDS algorithm 
uses a level-wise method to generate the set of candidate temporal 
patterns CTPk (candidate temporal patterns with k items) from the 
pre-known frequent temporal patterns FTPk−1 (frequent temporal 
patterns with k-1 items) according to the Apriori property [1]iii, 
where k > 2. The step is called CandidateGenWithout2Candidates 
(Candidate temporal pattern Generation without 2-candidates). 
Then, the proposed algorithm uses the bitwise AND operation to 
                                                 
iii
 It is a downward closure property, i.e., if a temporal 
pattern is frequent, all of its sub-patterns will also be 
frequent. 
compute the support of these candidates in order to find the 
frequent ones FTPk. The generation-then-test process is stopped 
until no new candidates with k+1 items (CTPk+1) are generated. 
The major difference between BVMDS and FTP-stream is that 
FTP-stream generates candidates from 2-candidates to k-
candidates, but BVMDS generates candidates from 3-candidates 
to k-candidates, where k is the largest size of itemsets. It is because 
the set of frequent 2-itemsets can be determined by the 2C-lists 
and its bit-vectors. 
Example 5 Consider the bit-sequences and 2C-lists of 
SW2 in Figure 4, and let the minimum support 
threshold s be 0.6. Hence, a temporal pattern X is 
frequent if sup(X) ≥ 0.6⋅3 = 1.8. In the following, we 
discuss the frequent temporal patterns mining steps of 
SW2.  
    First, BVMDS checks each bit-vector of item to 
find the frequent 1-itemsets, (b), (c) (e). Then, 
BVMDS generates frequent 2-itemsets, (bc), (be) 
and (ce), by combining frequent 1-item (c) with item 
e where e.sup:2 in 2C-list of item e and frequent 1-
item (b) with items c and e in 2C-list of item b. After 
that we find that (ce).sup = 2, (bc).sup = 2, and 
(be).sup = 3. 
Then, BVMDS generates one candidate 3-itemset 
(bce) from 2C-list of item b according to Apriori 
property. After that BVMDS uses bitwise AND 
operation to count the sup(bce) = 2, i.e., Bit(bc) 
AND Bit(be) AND Bit(ce) = 110. Because no new 
candidates are generated, the generation-then-test 
process is stopped. Hence, there are six frequent 
temporal patterns, (b), (c), (bc), (be), (ce), (bce), 
generated by BVMDS in SW2.  
 
4. EXPERIMENTS 
 
In this section, we report the experimental results of 
the proposed algorithm BVMDS and FTP-Stream 
algorithm [9]. All the programs are implemented 
using Dec-C++ and performed on a 1.80 GHz 
Pentium(R) PC machine with 1024 MB memory 
running on Windows XP. For testing frequent 
temporal patterns mining of melody sequence streams, 
we generate melody sequence streams using IBM 
synthetic data [1]. One synthetic melody sequence 
stream, denoted by T5.I4.D100K, of size 100,000 
melody sequences each is used to evaluate the 
performance of the proposed algorithm BVMDS. 
Moreover, T5.I4.D100K, with 1,000 unique items, 
has an average melody sequence size of 5 items with 
average maximal frequent temporal pattern size of 4 
items. 
    The experiment of memory usage comparison of 
the proposed algorithm BVMDS and FTP-stream are 
given in Figure 5. The minimum support threshold s 
and the size of a window w are set to 0.001 and 
20,000, respectively. From this figure, we can find 
that the memory usage of BVMDS is less than that of 
FTP-stream. 
The experiment of mining time comparison of the 
algorithms BVMDS and FTP-stream is shown in 
出席國際學術會議心得報告 
                                                             
計畫編號 NSC 96-2218-E-424-001- 
計畫名稱 資料串流上高效能之前 k 個封閉型頻繁樣式探勘之研究 
出國人員姓名 
服務機關及職稱 
陳宣勝 (計畫兼任助理) 
國立交通大學 博士研究生 
會議時間地點 6/23/08~6/26/08 德國漢諾威 
會議名稱 2008 IEEE International Conference on Multimedia & Expo (ICME 2008) 
發表論文題目 Efficiently Mining Frequent Patterns in Recent Music Query Streams 
 
一、參加會議經過 
本人於六月二十三日至六月二十六日赴德國漢諾威市參加 ICME 2008，這是多媒體領域
中重要的國際會議。本次會議的會議主席是 Jörn Ostermann (Leibniz Universität Hannover, 
Germany)，議程主席是 Milind Naphade (IBM Research, USA) 。其議程包括 3 場專題演講、26
個 Special Session 共 392 篇 Regular Paper 以口頭或海報方式發表、1 項系統展示；此外，還
有 7 門不同主題的教學課程。在論文投稿與評審方面，本次會議論文的評審委員由來自各大
學、研究機構與產業界等合計超過 15 個不同國家所組成；最後從 803 篇投稿論文中選出 392
篇論文(約 50%接受率)。 
我們於六月十九日早上 7:50 從台灣出發(超過十九日即為暑期旺季，機票得加價)，經過
泰國蘇汪納蓬國際機場轉機後，於德國法蘭克福當地時間六月十九日下午 6:10 左右抵達法蘭
克福國際機場(FRA)。夏天的德國約晚上十點才天黑，但是路上的店約晚上八點就關光光了，
而當時明明天還很亮，這和我們台灣的夜生活實在有很大的差異。由於時差問題，我們立刻
抵達住宿地點休息。在接下來的三天，我們順著萊茵河往北，參觀萊茵河沿岸的小鎮及科隆
大教堂，於二十二日晚上抵達漢諾威的住宿地點休息，為隔天開始的會議做準備。 
四天的會議期間，我除了報告我們自己的論文外，也參加了 3 場專題座談 (主講人分別
為: Sebastian Thrun、Tsuhan Chen 與 Frank H.P. Fitzek)、3 場論文發表會，以及和自己同一個
poster session 的與會者相互討論。就整體印象而言，從這次會議中，我深刻瞭解到當前多媒
體的相關研究以 Semantic Understanding of Multimedia、Searching for Multimedia Killer 
Application 和 Social Network 等領域最受矚目的。 
在參與的論文發表與討論中，我都挑選與自己的研究領域(動作分析與多媒體內容了解)
相關的題目聽，期望自己能透過參考別人對相近問題的不同看法，刺激自己看會不會有不一
樣的靈感發現新的問題或解決相同問題更好的方法。在論文發表中，有不少與會者發問的問
題是我所沒想到的，有的問題值得我深思，看能不能成為目前研究的延續，藉此有更完整的
研究成果。 
最後，在每日例行的會議結束後，我們利用漢諾威市便利的地上輕軌列車到漢諾威大學
參觀，以及參觀漢諾威著名的景點，例如：市政廳、賀倫赫森公園、教堂、車站廣場、歌劇
院等。其中輕軌列車是利用電力沒有污染，並且搭乘時可以看到地面上的風景，具有觀光價
值，十分值得我們的政府效法。 
總體而言，參加這次會議，除了在專業領域方面吸取到許多新知之外，在學術交流方面
也深深領略到國外優秀學者的風範和研究精神，也意識到學術研究的良性競爭壓力。感謝研
發會支持本人參加這次會議，希望將來還有機會參加類似的頂尖國際會議。 
