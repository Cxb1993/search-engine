1 Introduction
With wireless networking technologies extending into every part of our working and living
environments, proper handling of intermittent wireless connectivity and network disrup-
tions is important. As the foreseeable need for data communication escalates in challenged
network environments, an increasing amount of effort is being invested in developing tech-
niques that can address these anticipated requirements. Applications of these techniques are
wide ranging. For instance, it would be quite advantageous to be able to interconnect mo-
bile search and rescue nodes in disaster areas (where communication infrastructures have
been disabled by earthquakes, hurricanes, wildfires, or flooding), allow message exchanges
in underdeveloped areas (remote towns and villages interconnected by wireless networks,
but not guaranteed an always-on Internet connection), and permit scientific monitoring of
wilderness areas (remote monitoring of various forms of wildlife).
Formally, an opportunistic network is a type of challenged network that satisfies the
following conditions: (1) network contacts (i.e., communication opportunities) are inter-
mittent, (2) an end-to-end path between the source and the destination rarely exists, (3)
disconnection and reconnection is common, and (4) link performance is highly variable or
extreme. Because of various disruptions and long delays, traditional MANET and Internet
routing techniques can not be applied directly to opportunistic networks. Meanwhile, with
the development of numerous opportunistic networking applications, such as wireless sen-
sor networks (WSN) [7, 62], underwater sensor networks (UWSN) [22], pocket switched
networks (PSN) [15, 34], people networks [57, 60], and transportation networks [6, 12],
it is both desirable and necessary to develop an effective content dissemination framework
that can better accommodate data content and the various characteristics of opportunistic
networks.
Several data forwarding schemes have been proposed for opportunistic networks [12, 30,
38, 39, 42, 58, 61, 64]. Such schemes can be divided into two main categories, replication-
based and coding-based, according to their basic technical strategies. In general, coding-
based schemes are more robust than replication-based schemes when the network connec-
tivity is extremely poor, but they result in inefficiency when the network is fairly connected
(due to the additional code blocks embedded in the data). Yet, all of the above schemes
only consider data delivery performance (in terms of delivery latency and success ratio),
and neglect the innate characteristics (e.g., content types) of applications when designing
dissemination mechanisms. With the growing diversity of opportunistic network applica-
tions, a well-designed and content-centric solution for effective data dissemination remains
highly desirable.
In this project, we propose techniques to better facilitate content dissemination based on
the characteristics of the content and network mobility. To investigate this problem from
its origins, we propose a probabilistic forwarding based routing algorithm: HEC-PF, and
the dissemination methods considered are Layered MDC-based and file-based. Using sim-
ulations as well as both synthetic and realistic network scenarios, we evaluate the proposed
schemes in terms of latency and user perceived quality. We demonstrate how the schemes
can achieve much better latency performance for file transfers. We show that our proposed
1
Group Mobility Model [31]), the overhead carried by epidemic- and/or flooding-based rout-
ing schemes can be further reduced by considering node mobility. For instance, the Proba-
bilistic Routing scheme [41] calculates the delivery predictability from a node to a particular
destination node based on the observed contact history, and forwards a message to its neigh-
boring node if and only if that neighboring node has a higher delivery predictability value.
The scheme was revised by Leguay et al. [38] by considering the mobility pattern, i.e., a
message is forwarded to a neighbor node if and only if that node has a mobility pattern more
similar to the destination node. [38, 39] show that the revised mobility pattern scheme is
more effective than previous schemes.
Another class of opportunistic network routing schemes is based on encoding tech-
niques, which transform a message into a different format prior to transmission. For in-
stance, an integration of network coding and epidemic routing techniques has been pro-
posed to reduce the required number of transmissions in a network [64], and [61] proposes
combining erasure coding and the simple replication-based routing method to improve data
delivery for the worst delay performance cases in opportunistic networks.
Following the concept of erasure coding-based data forwarding [61], an Estimation
based Erasure-Coding routing scheme (EBEC) has been proposed to adapt the delivery of
erasure coded blocks using the Average Contact Frequency (ACF) estimate [40]. More-
over, [16] proposes a hybrid scheme that combines the strength of erasure coding and the
advantages of Aggressive Forwarding, so that it not only remains robust in worst delay per-
formance cases, but also performs efficiently in very small delay performance cases.
3 HEC-PF: H-EC with Probabilistic Forwarding
In this section, we propose a message scheduling algorithm, called Probabilistic Forward-
ing, for the aggressive forwarding phase of the H-EC scheme. The resulting scheme is called
HEC-PF. Unlike the H-EC scheme [16], which tries to forward the second copy of EC coded
blocks (after sending one block of the first EC coded blocks) in sequence until the end of
the network contact period, the HEC-PF scheme does NOT enter the aggressive forwarding
phase unless a newly encountered node has a higher likelihood of successfully forwarding
the message to the destination node than the current node. We describe the HEC-PF scheme
in the following sub-sections.
3.1 H-EC: An Overview
Erasure coding is a scheme that provides better fault-tolerance by adding redundancy with-
out the overhead of strict replication of the original data [63]. Two of the most popular era-
sure coding algorithms are Reed-Solomon coding and Low-Density Parity-Check (LDPC)
based coding (e.g., Gallager codes, Tornado codes, and IRA codes) [44, 51]. These algo-
rithms differ in the degree of encoding/decoding efficiency, the replication factor, and the
minimum number of code blocks needed to reconstruct a message. The selection of an ap-
propriate erasure coding algorithm is not within the scope of this paper, since our work is
3
utilize each network contact effectively when the contact duration is slightly longer than the
time required to send the relayed data. If most network contacts are much longer than the
required time, the EC scheme tends to waste the residual contact period, which results in
ineffectiveness, as illustrated in Fig. 1.
To resolve this problem, [16] proposed an enhanced scheme called A-EC, i.e., EC with
an aggressive forwarding feature, as shown in Fig. 2. In this scheme, the source sends as
many coded blocks as possible during each contact (totally Sr
bn
blocks, i.e., Sr
n
bytes). It has
been shown that the A-EC scheme is better able to utilize network contacts; thus, it can be
expected to outperform the EC scheme for very small delay performance cases. However,
for worst delay performance cases, it has been shown that A-EC yields a poor delivery ratio
and/or a very large delivery delay when black-holes3 are present in the network [16].
Taking advantage of the strengths of the EC and A-EC schemes to achieve better mes-
sage delivery performance in both worst delay performance and very small delay perfor-
mance cases, Chen et al. proposed a hybrid scheme, called H-EC, which is illustrated in
Fig. 3.
In the H-EC scheme, two copies of EC blocks (constructed based on the erasure coding
and replication techniques described previously) are transmitted by the sender. The first
copy of EC blocks is sent in a similar way to how the original EC scheme sends blocks
(shown as white blocks in Fig. 3), while the second copy is sent using aggressive forwarding
during the residual contact time after sending the first EC block (shown as gray blocks in
Fig. 3). For general opportunistic network scenarios (i.e., without black-hole nodes), the
H-EC scheme utilizes each contact opportunity better because of the aggressive forwarding
feature; however, if black-hole nodes are present in the network, the scheme’s performance
is expected to be similar to that of the EC scheme, which achieves better forwarding in worst
delay performance cases.
The performance of the H-EC scheme depends to a large extent on the message schedul-
ing algorithm used in the aggressive forwarding phase, which is not discussed in [16]. How-
ever, in this paper, we assess the impact of probabilistic message scheduling algorithms
on the performance of H-EC routing. To this end, we propose an extension of the H-EC
scheme, called HEC-PF, in the following section.
3.2 Delivery Probability
The key issue for the HEC-PF scheme is how to estimate the likelihood of successfully
transmitting a message from a given node to the destination node. Similar to the PRoPHET
scheme [41], the HEC-PF scheme estimates the delivery probability based on the observed
contact history. However, unlike PRoPHET, the HEC-PF scheme considers the contact
frequency in the history as well as the contact volume, which represents the proportion of
time that the two nodes are in contact in the last T time units. More specifically, if there are
K nodes in the network, we denote the i-th node as Xi, the j-th node as Xj , the aggregate
3A node in a network is called a black-hole if it is either unreliable (e.g., it has very limited battery power
and/or buffer size) or it hardly moves towards the destination [16].
5
Figure 4: The flowchart of the HEC-PF scheme.
network. For simplicity, we set k to a constant value in the simulations, and defer a detailed
discussion and evaluation of this issue to a future work.
3.3 Probabilistic Forwarding
We now describe the HEC-PF scheme in detail. As mentioned earlier, the scheme incor-
porates a new Probabilistic Forwarding feature that decides whether to forward a message
to a newly encountered node based on the delivery probability estimate, rather than on a
first-come-first-served basis. The HEC-PF scheme is better able to deliver a message suc-
cessfully because it tends to utilize relay nodes that have higher delivery probabilities. Fig.
4 shows the flowchart of the HEC-PF scheme.
More precisely, suppose that node Xi holds a message from the source node XS for
transmission to the destination node XD, H denotes the maximum hop distance allowed for
message transmission in the system, and the message has not been relayed more than H
times so far. There are two cases where Xi could accidentally encounter another node Xj
(assuming Xj 6= XD) if there is time remaining after Xi sends out one block of the first copy
of the EC blocks. First, if Xi is the source node, Xi must make a decision about whether to
enter the aggressive forwarding phase by comparing the two delivery probabilities, PXi,XD
and PXj ,XD . If PXi,XD > PXj ,XD , Xi will enter the aggressive forwarding phase in the same
way as the original H-EC scheme; otherwise, it will follow the EC scheme and not enter the
aggressive forwarding phase.
In the second case (i.e., Xi is not the source node), Xi first checks whether the next-
to-be-sent block was sent by the source node during the aggressive forwarding phase (i.e.,
whether it belongs to the second copy of the EC blocks). If it was, Xi forwards the block
to Xj as long as Xj has a higher delivery probability than Xi of successfully forwarding
7
Table 1: The properties of the four network scenarios.
Trace Name Power-Law ZebraNet iMote UCSD
Device N/A N/A iMote PDA
Network Type N/A N/A Bluetooth WiFi
Duration (days) 16 16 3 77
Devices participating 34 34 274 273
Number of contacts 25,959 31,693 28,217 195,364
Avg # Contacts/pair/day 2.89205 3.53086 0.12574 0.06834
conference. For simplicity, we assume there is a network contact between two Bluetooth
devices if there exists a query-and-response interaction between them.
The UCSD trace is client-based and records the availability of WiFi-based access points
(APs) for each participating portable device (e.g., PDAs and laptops) on the UCSD cam-
pus. The network trace covers a two and half-month period, and there are 273 participating
devices. Similar to [14–16, 34], we assume that two participating devices in ad hoc mode
encounter a communication opportunity (i.e., a network contact) if and only if they are both
associated with the same AP at the same time.
Note that, the network connectivity of the UCSD scenario is deemed to be very poor
because network contacts (per source-destination pair and per day) occur much less fre-
quently than in other scenarios. Specifically, the UCSD scenario only achieves 50% of the
network connectivity of the iMote scenario, and 0.02% of the network connectivity of the
Power-Law and ZebraNet scenarios.
3.4.2 Evaluation I: Two-hop Scenario
In the first set of simulations, we evaluate the delay performance of the HEC-PF scheme
for message delivery in opportunistic networks. Four network scenarios are examined via
simulations, with H set to 2 (i.e., the conventional two-hop scenario used in [16, 61]). The
k parameter of the HEC-PF scheme is set to 2 (i.e., we consider the transitive property of
message delivery with a distance of up to two hops). Fig. 5 depicts the average delivery
latency distribution results in Complementary CDF (CCDF) curves.
From Fig. 5, we observe that the HEC-PF scheme consistently outperforms the H-EC
and EC schemes in all test scenarios. The reason is that HEC-PF employs the Probabilistic
Forwarding feature, which decides whether to forward a message to a newly encountered
node based on the delivery probability estimates, rather than on the first-come-first-served
(FCFS) basis used in the original H-EC scheme. As a result, HEC-PF is better able to make
use of nodes that are more likely to encounter the destination node, and thereby achieve
better message delivery performance.
We also observe that the completion ratio, i.e., the percentage of messages success-
fully transmitted before the end of the simulation, degrades as the network connectivity
(i.e., the average number of network contacts per node pair, per day) decreases. For ex-
ample, although the HEC-PF scheme achieves approximately 99% completion ratio in the
9
00.2
0.4
0.6
0.8
1
0 50000 100000 150000 200000
CC
DF
Latency (seconds)
HEC-PF (k=1)
HEC-PF (k=2)
HEC-PF (k=3)
HEC-PF (k=4)
(a) ZebraNet Scenario
0
0.2
0.4
0.6
0.8
1
0 1e+06 2e+06 3e+06 4e+06 5e+06 6e+06
CC
DF
Latency (seconds)
HEC-PF (k=1)
HEC-PF (k=2)
HEC-PF (k=3)
HEC-PF (k=4)
(b) UCSD Scenario
Figure 6: Distribution (CCDF) of average latency performance of the HEC-PF scheme with
various k settings (N = 16, r = 2, and H = 5).
Power-Law scenario, it can only achieve about 48% in the UCSD scenario, and 80% in the
ZebraNet and iMote scenario. The reason is that the two-hop forwarding strategy is not
sufficient to deliver all messages in the limited simulation time because the network’s con-
nectivity is poor. Another observation is that the performance gain of the HEC-PF scheme
(compared to the H-EC scheme) is not significant. This implies that the calculation of the
delivery probability (with k = 2 in this case) cannot provide sufficient information to make
a decision on whether to forward a message in the aggressive forwarding phase of the HEC-
PF scheme. The findings motivate us to investigate the impact of the HEC-PF parameters on
the performance of message delivery in opportunistic networks. We present the evaluation
in the next subsection.
3.4.3 Evaluation II: Variable k Scenarios
In the second set of evaluations, we evaluate the performance of the HEC-PF scheme in the
ZebraNet and UCSD scenarios with various k values (k = 1...4). The configurations of the
evaluation are the same as previously, except that the maximum forwarding distance H is
set to 5. Fig. 6 depicts the average delivery latency distribution results in CCDF curves.
From Fig. 6, it is evident that the CCDF curve falls as k increases, which means that,
given the same H setting, the completion ratio of message delivery increases as the hop
distance (used to estimate the delivery probability) increases; however, the transmission
overhead of the HEC-PF scheme only increases moderately (except the UCSD case) as the
value of k increases, as shown in Fig. 8. The figure also shows that the performance gain of
the completion ratio decreases as k increases, which indicates that the completion ratio tends
to converge. It is also worth noting that k must be configured less than H when estimating
the delivery probability, since it is impossible to deliver a message successfully with a hop
distance larger than the maximum forwarding distance. Based on the evaluation results, we
suggest k = H − 1 for the proposed HEC-PF scheme.
11
one-hop data forwarding is required (as shown in Fig. 9, the transmission overhead of the
HEC-PF scheme increases substantially as the value of H increases); thus, more energy will
be consumed in the network. An ideal solution for HEC-PF should adapt its H value to the
properties of the network in order to compensate for the above tradeoff, and the decision
of the optimal H value should consider various network properties (e.g., the network con-
nectivity and traffic load) and system factors (e.g., the buffer size and batter life of each
participating node). We defer a detailed discussion and evaluation of this issue to a future
work.
4 Layered Multiple Description Coding with Unequal Era-
sure Protection
In this section, we propose the use of Layered Multiple Description Coding (LMDC) with
unequal erasure protection [19] for effective data dissemination in opportunistic networks.
Layered MDC has been proposed as a means of combining Multiple Description Coding
(MDC) [28] and Layered Coding [45] for emerging multicast and peer-to-peer audio/video
streaming applications. More specifically, multiple descriptions are spread across multiple
packets (or paths) via MDC, and transmitted to a collection of clients, thereby reducing
packet loss due to network congestion or the failure of unreliable hosts. Applications of
MDC include IP-level multicast [18] and application-level multicast [47, 48]. Moreover, by
using Layered Coding, multimedia data can be encoded into different quality levels, so that
clients can play the best possible video/audio quality level according to their capabilities,
such as screen resolution and link bandwidth.
By combining MDC and Layered Coding, the Layered MDC scheme spreads the layered
data across multiple packets with multiple descriptions. Then, clients can play the layered
data as long as the required number of descriptions are received successfully. Of course,
the more descriptions a client receives, the better the reconstructed data quality will be. In
practice, the Layered MDC scheme is usually implemented in conjunction with Unequal
Erasure Protection (UEP) [19], which provides different levels of erasure protection to the
Layered MDC blocks by adding different amounts of redundancy (i.e., the more essential
the code blocks are, the more protection/redundancy is added). In this study, we propose
the use of Layered Multiple Description Coding with unequal erasure protection for video
file transfer and web surfing applications in opportunistic networks. Hereafter, we call the
resulting scheme LMDC.
4.1 LMDC for Video Transfer
Fig. 10 illustrates the LMDC scheme for video transfer applications. From the figure, we
observe that the quality of a layered video frame improves as the size of the collected video
bit stream increases. More specifically, if one of the layered video frames is S bytes in size,
one can split it into k equal-sized pieces and reconstruct it to Qi quality level by using the
13
Table 2: Layered coding for web objects
Layers MIME types
1 text/{html,css,plain,javascript,xml}; application/javascript
2 Layer 1 + image/{gif,jpeg,png,bmp,x-icon}
3 Layer 2 + application/{pdf,octet-stream,x-shockwave-flash}
4 Layer 3 + video
5 Layer 4 + others
Moreover, comparing with the Layered Coding scheme, the traffic overhead of the LMDC
scheme is
boverhead = Nbpacket − S = S
k∑
i=2
1
i
. (11)
Since k is a positive integer, one can conclude that (a) boverhead = 0 when N = k = 1 (i.e.,
no LMDC); and (b) boverhead > 0 otherwise.
4.2 LMDC for Web Surfing
In addition to video file transfer applications, we apply the LMDC scheme to web surfing
applications in opportunistic networks. More precisely, the LMDC scheme is applied to
each MHTML document [49] that is a MIME (Multipurpose Internet Mail Extensions [10])
HTML document enclosing one or more objects, such as text, images, and videos. Un-
like video transfer applications, the layered coding scheme encodes MHTML documents
by looking up a pre-determined codebook, rather than splitting messages into equal-sized
pieces. For instance, we present a codebook that is based on the MIME type of each web
object, as shown in Table 2.
In the codebook, Layer 1 web objects can be HTML documents (source codes only),
cascading style sheets (CSS), java script, or plain text. Layer 2 contains images files in
addition to Layer 1 objects. Layer 3 contains additional application objects (such as PDF
files and flash games). Layer 4 contains additional video objects. Layer 5 contains other
objects (e.g., audio and unknown objects). Note that the design of the codebook can be
customized according to an object’s size, semantics, importance, and other design choices.
The approach proposed in this paper is based on the generic LMDC concept.
Similar to video transfer applications, the LMDC scheme first encodes each MHTML
document into k quality levels using layered coding. The layered document is then split
among N packets (N ≥ k) with unequal erasure protection on each layered piece. More
precisely, the i-th layered piece contains the i-th layered document, excluding the (i− 1)th
layered piece. Unequal erasure protection is applied to each layered piece, such that the i-th
piece is erasure coded with a replication factor equal to i and split among N packets5 (i.e.,
the i-th layered document can be successfully reconstructed from any i of the N packets).
5Note that the replication factor of each layered piece should be carefully configured according to the
performance requirements of the network system.
15
Table 3: Object properties of the selected web documents.
Object types Request (%) Avg. Size (bytes)
Layer 1 27.81 9,082
Layer 2 excluding Layer 1 objects 63.11 6,974
Layer 3 excluding Layer 2 objects 8.17 66,725
Layer 4 excluding Layer 3 objects 0.15 2,028,783
Layer 5 excluding Layer 4 objects 0.76 182,289
Table 4: Distribution of the required layer numbers, which can result in full quality docu-
ment, of the selected web documents.
Layer # Number of documents % of documents
Layer 1 0 0%
Layer 2 240 48%
Layer 3 240 48%
Layer 4 15 3%
Layer 5 5 1%
Table 5: The properties of the network scenarios in this study.
Trace Name Power-Law UCSD
Device N/A WiFi-based PDA
Network Type N/A WiFi
Duration (days) 16 77
Devices participating 34 273
Number of contacts 25,959 195,364
Avg # Contacts/pair/day 2.89205 0.06834
with limited layers (i.e., a web document may achieve the best possible quality with fewer
layers if it does not contain objects located in higher layers). The average number of layers
required for the best possible quality documents in this study was 2.57. Moreover, we also
assumed that data transmission is wireless at a fixed rate of 1Mbps. The simulation results
were all obtained by taking the average performance of 200 simulation runs. In each simu-
lation run the source and the destination pair was randomly selected from all participating
nodes.
We evaluate two network scenarios. One is generated according to the power-law distri-
bution by setting both inter-contact time and contact duration of the network with power-law
distributed values of coefficient 0.6 (as reported in [34]). The scenario consists of 34 partic-
ipating nodes. The other scenario is based on realistic campus wireless network traces, i.e.,
the UCSD [5] trace, which is publicly available for research references. Table 5 outlines the
basic properties of the two network scenarios.
17
(a) 500,000 seconds
(b) 1,000,000 seconds
(c) 5,000,000 seconds
Figure 13: Comparison of average video quality (i.e., PSNR for each video frame) for the
UCSD scenario after 500,000, 1,000,000, and 5,000,000 seconds.
algorithm [61] to transfer video file directly without LMDC coding. More precisely, the
LMDC-FI scheme would performs comparatively better than the LMDC-SF scheme in the
simulation. This is because the FI-based strategy combines both aggressive forwarding and
interleaving techniques that not only make aggressive use of precious network contacts, but
also do their best to alleviate the negative effects of possible black-holes.
The performance of the LMDC scheme is only slightly better than that of the dir scheme.
This result contradicts our intuition about the LMDC scheme’s added resilience to error-
19
(a) Power-Law Scenario (b) UCSD Scenario
Figure 14: Average quality of web surfing results using the dir and LMDC-based schemes.
(N = k = 5, and the results have been normalized to the average quality of the employed
web documents, i.e., 2.57)
our evaluation (i.e., using the codebook shown in Table 2).
We evaluated the performance of web surfing in the Power-Law and UCSD scenarios,
based on the average performance results of 200 runs. In each run, we randomly selected
one node as the Internet gateway (which also served as the LMDC encoder) and one node as
the web surfer. We used 500 web documents based on the top-500 hit-count statistics of our
campus proxy server for the period Apr.’06 to Sept.’06 (the basic properties of the selected
web documents are shown in Tables 3 and 4). Fig. 14 shows the normalized average quality
of web surfing (with respect to 2.57, which is the average number of layers required for the
best possible quality documents) using different coding and data forwarding schemes.
The results in Fig. 14 clearly show that, regardless of the coding and forwarding schemes
employed, the average surfing quality improves over time, and eventually converges after
a certain period. The reason for this is very straightforward: over time, a web surfer has
more chances of making more contacts in the network; thus, he/she is more likely to receive
his/her requested web documents. The results also show that the LMDC-based schemes
consistently outperform the dir scheme in both scenarios; more specifically, the HEC-based
schemes (i.e., LMDC-FI and LMDC-SF) perform comparatively better than the non-HEC
scheme (i.e., LMDC) in all test cases. The reason, not surprisingly, is the same as for video
transfers, i.e., LMDC-based schemes spread web documents more widely over the network,
and allow the receiver to preview part of a document, even before it has been transferred
completely. Moreover, since the HEC-based schemes allow more redundancy in data for-
warding, the data forwarding performance should be better. Finally, it is worth mentioning
that LMDC-FI slightly outperforms LMDC-SF in the simulations, which confirms our pre-
vious findings in LMDC-based video transfer applications.
In addition to evaluating the average web document quality in web surfing, we compare
the surfing quality of each received web document, which is more representative of the
surfing experience of end users. Fig. 15 shows the CDF distribution of the web document
quality received by a surfer, based on different coding and data forwarding schemes, at
21
documents before they have been transferred completed.
To sum up, the evaluation results demonstrate that the LMDC scheme enhances web
document transfer in opportunistic networks by enabling surfers to preview lower quality
web documents, even though the data has only been partially transferred. Moreover, in
conjunction with the HEC data forwarding strategy, the LMDC-SF/FI schemes are able
to better cope with link outages and provide scalable web surfing in challenging network
environments.
5 Remaining Issues
So far, we have presented the basic design of the collaborative Internet access approach for
mobile opportunistic people networks. In this section, we discuss several additional research
issues that are yet required to be further investigated before the proposed system being
really deployed. The issues are (1) traffic overhead management, (2) buffer management,
(3) information security, and (4) network reliability. We present the discussion of these
issues in the followings.
5.1 Traffic Overhead Management
Though the proposed CIA scheme is promising in providing mobile Internet access appli-
cation, the main drawback of this scheme is the traffic overhead it inputs into the network,
which is considered costly when network resources are not rich (e.g., limited bandwidth
and/or buffer size). The traffic overhead can be possibly reduced by ‘healing’ the network
with receivers’ feedbacks upon successful receipt of a complete message. For instance,
[12, 30] have proposed Explicit ACKs and Passive Cure schemes to alleviate traffic over-
head carried by replication-based data forwarding schemes. However, it should also be
mentioned that, unlike the scenarios employed in [12, 30], where raw messages are inputted
into the network, the proposed schemes encodes all messages using erasure coding before
injecting them into the network. As a result, the implementation of either Explicit ACK
or Passive Cure scheme must be aware of the encoding scheme, i.e., the scheme should
acknowledge/cure N erasure coded blocks at a time once N
r
of the blocks have been suc-
cessfully delivered. In addition, the forwarding of receivers’ feedbacks also needs to be
carefully controlled. For instance, the Time-To-Live [30], Kill Time [30], or Reverse Path
Forwarding [23] like methods should be employed to reduce the traffic overhead caused by
receivers’ feedbacks.
5.2 Buffer Management
Unlike traditional Internet routing approaches that are mostly store-and-forward based, the
proposed collaborative Internet access system follows the store-carry-and-forward commu-
nication paradigm [56], i.e., it relies on the node mobility to facilitate data dissemination in
a network. As a result, it requires network participants to collaboratively cache messages
23
system, free-riders may take advantage of the system by issuing numerous requests to Inter-
net content, but refuse to help download/relay messages that are requested by other peers.
Consequently, free-riders save their storage and energy than honest peers, while the system
has to pay the cost, in terms of system throughput performance, due to the decreased level
of collaboration.
In addition, “black-hole attacks” is another type of uncooperative behavior [24] that
may significantly degrades the performance of the proposed system. General speaking,
“black-hole attacks” happens when there are a set of malicious peers in the network, and
the black-holes intentionally ‘absorb’ data (i.e., accepting relay requests) from other peers
without relaying (i.e., drop those absorbed data immediately). As a result, the proposed
system suffer a very poor delivery ratio performance, and thus unable to provide reliable
data transmission service.
Similarly, “wormhole attacks” is also caused by malicious peers in the network [32, 50,
53]. A network wormhole is composed of one black hole and one white hole. While black
holes ‘absorb’ data from other peers, while holes ‘radiate’ data as much as they could to
the network. As a result, the wormhole peer is very likely to be overloaded, and the system
may thus suffer single-point-of-failure problem. Moreover, since a wormhole is a tunnel
connecting the black hole and the white hole, the malicious peer can thus examine every
piece of data that is going through the tunnel, which may create other problems such as
security, privacy, anonymity, and etc.
6 Conclusion
There is an urgent need for an effective data dissemination scheme for opportunistic net-
works, as communication opportunities in such challenged networks are opportunistic in
nature and thus very precious. In this paper, using three types of content as examples (file,
video, and web documents), we have presented a probabilistic forwarding based data for-
warding algorithm that enhances the data delivery capabilities of the HEC scheme for file
transfers. In addition, we have proposed a content-centric framework that combines layered
coding and multiple descriptions coding to facilitate data dissemination for video transfers
and web surfing applications in opportunistic networks. The proposed schemes were evalu-
ated using simulations as well as both synthetic and realistic network scenarios. The results
show that the schemes can achieve a much better latency performance. Moreover, we have
shown that our proposed techniques enable the end user to “preview” video or web content
at a lower quality, even before the data has been completely transferred, thereby improving
the overall viewing experience. The effectiveness and robustness of our message scheduling
algorithms and their corresponding content dissemination techniques make them ideal solu-
tions that can go a long way toward effective data dissemination in opportunistic networks.
25
[16] L.-J. Chen, C.-H. Yu, T. Sun, Y.-C. Chen, and Hao-huaChu. A hybrid routing approach
for opportunistic networks. In ACM SIGCOMM Workshop on Challenged Networks,
pages 213–220, 2006.
[17] L.-J. Chen, C.-H. Yu, C.-L. Tseng, H. hua Chu, and C.-F. Chou. A content-centric
framework for effective data dissemination in opportunistic networks. IEEE Journal
of Selected Areas in Communications, 26(5):761–772, June 2008.
[18] P. A. Chou and K. Ramchandran. Clustering source/channel rate allocations for
receiver-driven multicastunder a limited number of streams. In IEEE ICME, 2000.
[19] P. A. Chou, H. J. Wang, and V. N. Padmanabhan. Layered multiple description coding.
In IEEE Packet Video Workshop, 2003.
[20] M. C. Chuah and W.-B. Ma. Integrated buffer and route management in a dtn with
message ferry. Journal of Information Science and Engineering, 23(4):1123–1139,
July 2007.
[21] C. Cocks. Identity based encryption scheme based on quadratic residues. In 8th IMA
International Conference on Cryptography and Coding, 2001.
[22] J.-H. Cui, J. Kong, M. Gerla, and S. Zhou. The challenges of building mobile underwa-
ter wireless networks for aquatic applications. IEEE Network, 20(3):12–18, May-June
2006.
[23] Y. Dalal and R. Metcalfe. Reverse path forwarding of broadcast packets. Communi-
cations of the ACM, 21:1040–1048, December 1978.
[24] H. Deng, W. Li, and D. P. Agrawal. Routing security in wireless ad hoc networks.
IEEE Communications Magazine, 40:70–75, October 2002.
[25] K. Fall. A delay-tolerant network architecture for challenged internets. In ACM SIG-
COMM, 2003.
[26] M. Feldman, C. Papadimitriou, J. Chuang, and I. Stoica. Free-riding and whitewashing
in Peer-to-Peer systems. In ACM SIGCOMM Workshop on Practice and Theory of
Incentives in Networked Systems, pages 228–236, 2004.
[27] C. Gentry and A. Silverberg. Hierarchical id-based cryptography. In International
Conference on the Theory and Application of Cryptography andInformation Security,
2002.
[28] V. K. Goyal. Multiple description coding: Compression meets the network. IEEE
Signal Processing Magazine, 18(5):74–93, September 2001.
[29] M. Grossglauser and D. Tse. Mobility increases the capacity of ad-hoc wireless net-
works. IEEE/ACM Transactions on Networking, 10(4):477–486, August 2002.
27
[43] A. Lindgren and K. S. Phanse. Evaluation of queueing policies and forwarding strate-
gies for routing inintermittently connected networks. In IEEE COMSWARE, 2006.
[44] M. G. Luby, M. Mitzenmacher, M. A. Shokrollahi, and D. Spielman. Efficient erasure
correcting codes. IEEE Transactions on Information Theory, 47(2):569–584, February
2001.
[45] S. R. McCanne. Scalable Compression and Transmission of Internet Multicast Video.
PhD thesis, University of California, Berkeley, 1996.
[46] J. Ott and D. Kutscher. Bundling the Web: HTTP over DTN. In ICST QShine Work-
shop on Networking in Public Transport, 2006.
[47] V. N. Padmanabhan, H. J. Wang, and P. A. Chou. Resilient peer-to-peer streaming. In
IEEE International Conference on Network Protocols, 2003.
[48] V. N. Padmanabhan, H. J. Wang, P. A. Chou, and KunwadeeSripanidkulchai. Dis-
tributing streaming media content using cooperative networking. In ACM NOSSDAV,
2002.
[49] J. Palme, A. Hopmann, and N. Shelness. MIME encapsulation of aggregate docu-
ments, such as HTML (MHTML). IETF RFC 2557, March 1999.
[50] P. Papadimitratos and Z. J. Haas. Secure routing for mobile ad hoc networks. In SCS
Communication Networks and Distributed Systems Modeling and SimulationConfer-
ence, 2002.
[51] J. S. Plank and M. G. Thomason. A practical analysis of low-density parity-check
erasure codes for wide-areastorage applications. In The International Conference on
Dependable Systems and Networks, 2004.
[52] L. Ramaswamy and L. Liu. Free riding: A new challenge to peer-to-peer file sharing
systems. In 36th Hawaii International conference on system sciences, 2003.
[53] K. Sanzgiri, B. Dahill, B. N. Levine, and C. S. E. M. Belding-Royer. A secure routing
protocol for ad hoc networks. In IEEE ICNP, 2002.
[54] A. Seth and S. Keshav. Practical security for disconnected nodes. In IEEE ICNP
Workshop on Secure Network Protocols, 2005.
[55] A. Shamir. Identity-based cryptosystems and signature schemes. In CRYPTO, 1984.
[56] T. Small and Z. J. Haas. Resource and performance tradeoffs in delay-tolerant wireless
networks. In ACM SIGCOMM Workshop on Delay Tolerant Networks, 2005.
[57] D. Snowdon, N. Glance, and J.-L. Meunier. Pollen: using people as a communication
medium. Elsevier Computer Networks, 35(4):429–442, February 2001.
29
2. Ling-Jyh Chen and Yun-Chih Chen. An Analytical Study of People Mobility in
Opportunistic Networks. Accepted for publication in the Journal of Information
Science and Engineering.
3. Che-Liang Chiou and Ling-Jyh Chen. An Evaluation Study of Routing Reli-
ability in Opportunistic Networks. Short Paper (Poster). The 9th ACM Inter-
national Symposium on Mobile Ad Hoc Networking and Computing (Mobi-
Hoc’08), Hong Kong, 2008.
4. Ling-Jyh Chen, Ting-Kai Huang, and Che-Liang Chiou. Scalable and Collabo-
rative Internet Access for Opportunistic People Networks. Short Paper (Poster).
The 9th ACM International Symposium on Mobile Ad Hoc Networking and
Computing (MobiHoc’08), Hong Kong, 2008.
5. Ling-Jyh Chen and Ting-Kai Huang. A Peer-to-Peer Approach for Mobile File
Transfer in Opportunistic People Networks. The 22nd IEEE International Con-
ference on Advanced Information Networking and Applications (AINA’08), Gi-
nowan, Okinawa, Japan, 2008.
6. Chien-Shiu Lin, Wei-Shyh Chang, Ling-Jyh Chen, and Cheng-Fu Chou. Perfor-
mance Study of Routing Schemes in Delay Tolerant Networks. The first Inter-
national Workshop on Opportunistic Networks (WON’08, in conjunction with
IEEE AINA’08), Ginowan, Okinawa, Japan, 2008.
7. Ling-Jyh Chen, Ting-Kai Huang, and Guang Yang. PPWeb: A Peer-to-Peer
Approach for Web Surfing On the Go. The 1st IEEE International Peer-to-Peer
for Handheld Devices (P2PHD’08, in conjunction with IEEE CCNC’08), Las
Vegas, USA, 2008.
8. Ling-Jyh Chen, Cheng-Long Tseng, and Cheng-Fu Chou. On Using Probabilis-
tic Forwarding to Improve HEC-based Data Forwarding in Opportunistic Net-
works. The 2007 IFIP International Conference on Embedded and Ubiquitous
Computing (EUC’07), Taipei, Taiwan, 2007. (also in LNCS 4808, pp. 101-112,
Springer, 2007)
• Released Source Codes
1. HEC-PF codes for DTNSIM simulator.
http://nrl.iis.sinica.edu.tw/Download/
2. LMDC codes for DTNSIM simulator.
http://nrl.iis.sinica.edu.tw/Download/
3. Analysis Tools for DTN and Opportunistic Network Traces.
http://nrl.iis.sinica.edu.tw/Download/
31
 本屆 AINA 會議在扣除合併主辦之 Workshop/Symposia 後，今年共計有
超過 469 篇的論文投稿，在區分為 16 個子領域後，由各子領域組成之
committee 經過 peer-review 階段的篩選後，最後僅錄取 145 篇論文，整體論
文之接受率僅有約 31%。此外，大會亦安排了兩場 keynote，分別由法國 IRISA
的 Dr. Michel Raynal 主講”Synchronization is Coming Back, But is it the 
Same?”，以及由日本 National Institute of Informatics 的 Dr. Shigeki Yamada
所主講的” Cyber Science Infrastructure (CSI) for Promoting Research Activities 
of Academia and Industries in Japan＂。 
 
本屆的 IEEE AINA 會議，在大會主席以及相關籌備人員的妥善規劃
下，稱的上是十分圓滿成功的。本次會議不但大幅提高了與會者彼此間的交
流，更由於本次會議的參與者來自世界各地，經由本次會議的討論、激盪、
交流，相信對所有與會者而言，皆有實質上無比的收穫，同時也更開啟了無
數未來國際學術合作的橋樑。 
 
本次參與 AINA 2008 會議之詳細行程表如下： 
 
日期 行程活動 地點 
3/24 10:55am 抵達 Okinawa, Japan Okinawa, Japan
3/25 出席 IEEE AINA 會議及其 PAEWN 研討會 Okinawa, Japan
3/26 出席 IEEE AINA 會議 Okinawa, Japan
3/27 出席 IEEE AINA 會議及其 WON 研討會 Okinawa, Japan
3/28 11:55am 啟程返臺 Okinawa, Japan
 
