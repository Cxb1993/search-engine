Design and Implementation of an Object Tracking Management in Wireless
Sensor Networks
Chih-Chieh Hung and Wen-Chih Peng∗
Department of Computer Science
National Chiao Tung University
Hsinchu, Taiwan, ROC
E-mail:{hungcc@csie.nctu.edu.tw, wcpeng@cs.nctu.edu.tw}
Abstract
One promising application of sensor networks is object
tracking. Because the movements of the tracked objects usu-
ally show repeating patterns, we propose a heterogeneous
tracking model, referred to as HTM, to efficiently mine ob-
ject moving patterns and track objects. To ensure the qual-
ity of moving patterns, we develop a storage management
to facilitate mining object moving patterns. Specifically, we
explore load-balance feature to store more moving data for
mining moving patterns. Once a storage of a cluster head is
occupied by moving data, we devise a replacement strategy
to replace the less informative patterns. Simulation results
show that HTM with storage management is able not only
to increase the accuracy of predition but also to save more
energy in tracking objects.
1 Introduction
Object tracking is one of the killer applications for wire-
less sensor networks. Various energy conservation schemes
for object tracking sensor networks have been extensively
studied in the literature [3][5]. In this paper, we concen-
trate at the prediction-based object tracking sensor network.
The prediction-based object tracking sensor networks relies
on certain prediction mechanisms to achieve energy saving.
We argue that tracked objects such as human or animals
tend to have their own moving patterns since the behaviors
of human or animals are likely to be regular [4]. Thus, ef-
ficient techniques for obtaining moving patterns of objects
are very important for energy conservation in object track-
ing sensor networks. Various data mining techniques have
been explored in the literature [1]. However, these prior
works mostly require data to be collected at one central-
ized server, leading to a significant amount of energy con-
∗The corresponding author of this paper.
sumption in data collection. Our goal is to propose an ef-
ficient data mining mechanism for deriving object moving
patterns in object tracking sensor network and utilize the
object moving patterns for energy saving prediction-based
object tracking sensor networks.
To facilitate collaborative data collection processing in
object tracking sensor networks, cluster architectures are
usually used to organize sensor nodes into clusters (with
each cluster consisting of a cluster head and sensors). Sim-
ilar to [2], we consider the sensor network which consists
of heterogeneous nodes of various functions and roles and
thus propose a heterogeneous tracking model (referred to as
HTM) in the cluster architecture, in which a large number of
inexpensive sensor nodes perform sensing operations and a
limited number of heterogeneous nodes (standing for clus-
ter heads) offer data collection and mining capabilities. For
scalability, the cluster heads recursively form a hierarchical
architecture for efficiently mining and queries. As such, the
higher-level cluster heads will maintain coarse object mov-
ing patterns and the low-level cluster heads will have more
precise object moving patterns. Based on the obtained ob-
ject moving patterns, the cluster heads predict the object
movements. If the prediction fails, a recovery procedure
will be executed by waking up sensor nodes within the cov-
erage region of the cluster head. Based on HTM, only a
bound number of sensor nodes need to participate in the re-
covery procedure.
In HTM, cluster heads should keep as many moving log
data as possible in their clusters. Note that cluster heads also
have storage constraint and the amount of data will affect
the effect of pattern mining. Notice that the conventional
hierarchy clustering architectures (i.e., the level i cluster
head is chosen among these level (i-1) cluster heads) suf-
fer from the storage load unbalance problem. Assume that
the storage space of a cluster head is S and the height of
hierarchy is k, there is always a cluster head (called heavy
node) which stores information of all level in the hierarchy
chy is four1. To avoid the heavy node problem of conven-
tional hierarchy architectures, we must consider the number
of levels of information a cluster head stores. Once a clus-
ter head stores too much information, we tend to separate
data flows to other cluster heads stored fewer information.
Based on this concept, we propose a storage load-balanced
scheme for HTM:
Given child cluster heads Ci in level i and the coordinate
of sink, the parent cluster head of Ci is assigned by the fol-
lowing rules: If there exist a cluster head v ∈ Ci such that
v stores only one level of information and v is the nearest
sink among any cluster head u∈Ci, then v is parent cluster
head of Ci. Otherwise, redirect the task to a cluster head w,
where w is the cluster heads closet to sink among all 1-hop
neighbors of Ci. The sink is assigned to be parent in highest
level
The proposed scheme can be illustrated as the following
example. An illustrative example shows in Figure 2. Every
square represents a cluster head. The square marked k is
the cluster head stores the information of level 0 and level
k. Sink is in the bottom of the network. Arrows repre-
sent the data flow from low level cluster heads to its parent.
Consider the circled level-2 cluster head, the circle level-2
cluster head in the marked region is the cluster head nearest
to sink among circled level-2 cluster heads, but it already
stores two levels of information and then redirects the task
to its right neighbor. Its right neighbor stores only level 0
information and then become the parent of circled level-2
cluster heads.
To prove our scheme is storage load-balanced, we eval-
uate the variance of storage cost. Suppose the height of the
hierarchy is k, the expected value of the storage cost for
each cluster head is EHTM = 4−4
−k
3 . Then we can evalu-
ate the variance of the storage cost as:
VHTM =
(2−EHTM )2( 4
k−1
3 )+(1−EHTM )
2( 2×4
k+1
3 )
4k
= 29 −
4−k
9 −
4−2k
9 = Θ(1)
Similarly, we can evaluate the storage cost for each clus-
ter head using conventional clustering hierarchy architec-
tures to be Θ(k2). It can be seen that VHTM grows in the
constant rate and is independent to the height. Therefore
we can conclude that the proposed scheme can satisfy the
storage load-balance and thus ensure the quality of moving
patterns for each cluster head.
3.2 Storage Replacement Strategy
Through the proposed storage scheme can ensure that a
level i (i ≥ 1) cluster head only has to maintain two lev-
els of information, with time passing by, the storage of each
cluster head will run out. Therefore, we must to discard less
1That is, every parent cluster head in hierarhcy has four children.
11211211211
23
111131111
2
11211211211
111131111
232
1121111211
11111111
2
11211211211
11111111
Figure 2. Storage load-balanced scheme for
HTM.
informative patterns to store more informative ones. Hence,
the storage replacement strategy is necessary for dealing
with this situation. When the memory space of a cluster
head is full and the count of one symbol in the table main-
tained by an emission tree node is larger than given thresh-
old min_sup, we have to decide to prune other nodes so that
the newborn node can be inserted into emission trees. We
specify a threshold  and if the prediction hit rate of the tree
to which the newborn node belongs is already larger than ,
we can ignore the insertion since this emission tree already
has higher prediction rates. Otherwise, we must select an
appropriate node to be pruned from other trees. The prun-
ing mechanism consists two steps:
1) Select the tree to be pruned. Each object usually has
its own moving behavior. An object may stay in some re-
gions more frequently than other regions. Hence, the re-
porting rates of objects in each cluster head will be differ-
ent. For tree selection, each tree maintains a counter. The
counter increases one when a tree is updated and minuses
one every T periods. Obviously, a tree with a lower counter
value means that it is not often used than other trees. Once
a newborn generated, we only select the same level tree to
the newborn node to prune. To guarantee that the accuracy
of each tree is acceptable, we specify a threshold ξ. Sup-
pose that the new node will be inserted into a level i emis-
sion tree. Among other level i trees with their prediction hit
rates ≥ ξ, the tree with the minimal counter value will be
selected. Consider an example in Figure 3, where the size
of a tree stands for the access counter value of the tree. Let
 = 0.8 and ξ = 0.6. Since the hit rate of tree T1 < 0.8, we
decide to insert the new node into T1 and prune one node in
T2~T5. T2 will not be selected since its hit rate<0.6 and T4
is next selected. Since the hit rate of T4 > 0.6, T4 is then
3
