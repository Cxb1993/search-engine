2行政院國家科學委員會專題研究計畫成果報告
使用類神經模糊演算法於小波特徵的選擇應用在語者辨識之研究
計畫編號: NSC 94－2213－E－163－004
執行期限: 94 年 8 月 1 日至 95 年 7 月 31 日
計畫主持人：龍生雲 副教授 (中國技術學院 資訊管理系)
計畫參與人員：陳駿瑋, 李冠興, 沈欣茹, 李靜玟.(中國技術學院 資訊
管理系)
一. 中文摘要
在本論文中，提出了以類神經-模糊評估
法做小波特徵的選擇，應用於不特定語句之
語者辨識系統上。 首先，採用離散小波轉
換技術做頻域上的參數萃取，然後再使用類
神經-模糊評估法做特徵的選擇。
類神經-模糊評估法是利用變動式目標
函數的觀念，應用在加權距離的評估上，使
得分類的模式更為合適。其中，以類神經參
數代表每一獨立特徵向量的重要性，而得到
一組最佳化的類神經網路加權參數，而加權
參數選擇的方法是依連結者的最短距離而
定。
在本論文中，利用類神經-模糊評估法在
不特定語句之語者辨識系統上，使每一語者
的離散小波特徵，從 32 個特徵縮減為 16 個
特徵，在特徵數目上做了縮減。
本論文之結果，將與使用小波特徵和離
散小波特徵的特徵萃取法，在辨識率上做一
比較。
關鍵詞: 小波特徵, 模糊評估法, 類神經
網路.
Abstract:
In this paper, a wavelet feature selection
derived by using neuro-fuzzy evaluation index
for speaker identification is proposed.
Feature extraction first the data in the
spectrum domain using the discrete wavelet
transform and afterwards using the
neuro-fuzzy evaluation index in feature
selection.
The neuro-fuzzy concept of a flexible
membership function incorporating weighed
distance is introduced in the evaluation index
to make the modeling of clusters more
appropriate. A set of optimal weighting
coefficients in terms of networks parameters
representing individual feature importance is
obtained through connectionist minimization.
In this paper, the author introduce the
use of a neuro-fuzzy evaluation index in the
reduction of a 32 discrete wavelet features to
16 discrete wavelet features, for each speaker
in text independent speaker identification.
Our results compare with the wavelet
features and discrete wavelet features with
respect to the percentages of recognition.
1. Introduction
One of the commonly used feature set is a
wavelet features [1], [2]. Wavelet spaces are
a series of function spaces that are highly
decorrelated from each other and are
particularly suitable for the representation of
signals and operators at different resolution
scales that exhibit speech and speaker feature
behaviors. The discrete wavelet transform
(DWT) [3] has been used with limited success
because of its left recursive nature. A more
generalized form of the standard wavelet
transform is the wavelet packet, which
decomposes both the high and low frequency
4capturing different frequency subband features
of the original signal. The two wavelet
orthogonal bases generated from a parent node
are defined as



 
n
jp
j
p
j nknhk )2(][)(
2
1  (1)




 
n
jp
j
p
j nkngk )2(][)(
12
1  (2)
where ][nh is the lowpass filter, ][ng is the
highpass filter and ][n is the wavelet
function[3]. )2( nk jpj  where j is the
depth of decomposition, p is the number of
nodes to the left of the parent node.
However, WP analysis is generally only
applicable to regularly spaced data of order
n2 and tend to be limited to the analysis data
due to the exponential growth in storage terms
with dimension.
To overcome these problems, wavelet
packet feature selection derived by using
neuro-fuzzy evaluation index for speaker
identification is described. The new
approach is a fuzzy feature evaluation index
for a set of features is defined in terms of
membership values denoting the degree of
similarity between two patterns. In the area
of speaker recognition, neuro-fuzzy
approaches have been attempted mostly for
recognition, not much for feature selection.
3. Neuro-Fuzzy (NF) Feature Selection
In this study, we will extend the proposed
methods in [8] to a neural networks feature
selection. The extension can be improved
the discriminatory power of each feature.
The network consists of an input, a hidden and
output layer (Fig. 1). The input layer
consists of a pair of nodes corresponding to
each feature, for an n dimensional feature
space. The hidden layer consists of n nodes
which compute the part in Eq.(8) for each pair
of patterns. The output layer consists of two
nodes. One of them computes o , and the
other T . The feature evaluation
index )(WE in Eq.(8) is computed from these
 values off the network. For convenience
we use the following notation to describe the
functions of the nodes in each of the three
layers.
Layer 1: The nodes of this layer directly
transmit input signals to the next layer.
When the pth and qth patterns are present to
the input layer, the activation produced by ith
input node is )0(iu , where pii xu )0( and
qini xu )0( for ni1 , the total activations
received by the ith and (i+n)th input node,
respectively.
Layer 2: The total activations received by
the jth hidden node is given by
)0()0(1 )1(1 niij uuu  for ni1
(3)
Layer 3: The node in this layer computes
the output signal of the NF model. The total
activations received by the output node which
computes the Tu values, is

j
jjT uwu
)1()2( (4)
and that received by the other node which
computes the ou values, is

j
jo uu
)1()2( (5)
6speakers includes 438 males and 192 females.
The preprocessing of the TIMIT speech data
consists of several steps. First, the speech is
downsampled from 16 to 8 KHz sampling
frequency. The speech data is processed by a
silence removing algorithm followed by the
application of a pre-emphasis filter
195.01)(  zzH . A 30ms Hamming
window is applied to the speech every 10ms.
KING DATABASE: The KING database is a
collection of conversational speech from 51
male speakers. For each speaker there are 10
section of conversational speech recorded at
different times. The first five sessions were
recorded at normal time intervals of one week
and the second five sessions at intervals of one
month. The speech signals are recorded at 8
KHz and 16 bits per sample. Free-text
utterances were used for training and testing.
A Hamming window was applied to each
frame. The signal was pre-emphasized with
a coefficient equal to 0.95.
5. Identification Decision
Gaussian Mixture Model (GMM) [11]
recently have become the dominant approach
in text independent speaker recognition. One
of the powerful attributes of GMMs is their
capability to form smooth approximations to
arbitrarily shaped densities [3]. Although for
text dependent applications, hidden Markov
models (HMMs) can have some advantages
when incorporating temporal knowledge,
GMMs still show the best performance to date
for text independence speaker recognition
with high accuracy.
As a typical model based approach, GMM
has been used to characterize speaker’s voice
in the form of probabilistic model. It has
been reported that the GMM approach
outperforms other classical methods for
text-independent speaker identification. In
this section, we briefly review the GMM
based speaker identification scheme that will
be used in our simulations.
Given }{ 21 kYYYY  , where
},,{
2211 jj TtTtTt
yyyY   is a sequence of jT
feature vectors in j th cluster jR , the
complete GMM for speaker model  is
parameterized by the mean vectors,
covariance matrices and mixture weights from
all component densities. The parameters of
the speaker model are denoted as
jtjtjtj Miup ,,2,1},{ ,,,  and
Kj ,,2,1  (10)
Then, the GMM likelihood can be written
as
)|()|()|(
1
1
1

Kt
T
t
t ypypYp  (11)
In (11), )|( 
jt
yp is the Gaussian mixture
density for j th cluster and defined by a
weighted sum of jM component densities as



j
jj
M
i
tijt ybpyp
1
, )()|(  (12)
where
()(
2
1
exp{
||)2(
1
)( 1,,
2
1
,
2
1 jtjij
T
ijtj
ij
tji uyuyyb 

 

with mean iju , and variance matrix ij , .
The mixture weights satisfy the constraint
that 
 

K
j
M
i
ij
j
p
1 1
, 1 . In here, we assume that
894-2213-E-163-004).
References
1 Shung-Yung Lung,: “Feature extracted
from wavelet eigenfunction estimation for
text independent speaker recognition”,
Pattern Recognition, Vol. 37, July 2004,
pp. 1543-1544
2 Chang, S., Kwon, Y., and Yang, S.,I.:
“Speech feature extracted from adaptive
wavelet for speech recognition”,
Electronics Letters, Vol 34, 1998, pp.
2211-2213
3 Tufekci, Z., and Gowdy, J.N.: “Feature
extraction using discrete wavelet
transform for speech recognition”,Proc.
IEEE Southeastcon 2000, USA, 2000,
pp.116-123
4 Shung-Yung Lung,: “Applied
Multi-Wavelet Feature to Text
Independent Speaker Identification”,
IEICE Trans. on Fundamentals,
Vol.E87-A,No.4, April 2004, pp. 944-945
5 Nathan, K.S.; Silverman, H.F.,
“Time-varying feature selection and
classification of unvoiced stop
consonants”, IEEE Transactions on
Speech and Audio Processing, Vol. 2 , July
1994, pp.395 - 405
6 Hyeon Ji; Bang, S.Y.,: “Feature selection
for multi-class classification using
pairwise class discriminatory measure and
covering concept”, Electronics Letters ,Vol.
36, March 2000, pp.524 - 525
7 Haydar, A.; Demirekler, M.; Yurtseven,
M.K.,:“Speaker identification through use
of features selected using genetic
algorithm”, Electronics Letters ,Vol.
34, Jan. 1998, pp.39–40
8 Shung-Yung Lung,: “Wavelet feature
selection using fuzzy approach to text
independent speaker recognition”,IEICE
Trans. on Fundamentals, Vol.E88-A, No.3,
March 2005, pp.779-781
9 Ng, S.-C.; Cheung, C.-C.; Leung, S.-H.,:
“Magnified gradient function with
deterministic weight modification in
adaptive learning”, IEEE Trans. Neural
Networks, Vol. 15, November 2004, pp.
1411- 1423
10 Gori, M.; Petrosino, A.,: “Encoding
nondeterministic fuzzy tree automata into
recursive neural networks” IEEE Trans.
Neural Networks, Vol. 15, November 2004,
pp. 1435- 1449
11 D. A. Reynolds and R. C. Rose, “Robust
text-independent speaker identification
using Gaussian mixture speaker models,”
IEEE Trans. Speech Audio Processing, Vol.
3, no. 1, Jan. 1995, pp. 72-83
10
80 85 90 95
Recognition %
16
24
32
D
im
Fig. 2 Speaker Recognition Rates (TALUNG)
WT WP NFWP
55 60 65 70 75
Recognition %
16
24
32
D
im
Fig. 3 Speaker Recognition Rates(TIMIT)
WT WP NFWP
