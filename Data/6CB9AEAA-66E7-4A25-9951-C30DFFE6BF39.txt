行政院國家科學委員會專題研究計畫成果報告 
 
計畫名稱：無拘束性環境下以會員/非會員確認為基礎之研究 
   及其在自動化保全之應用 
計畫編號：    NSC 97-2221-E-033-029 
執行期限：    97 年 08 月 01 日至 98 年 07 月 31 日 
計畫主持人：  中原大學機械系 劉益宏  副教授 
計畫參與人員： 
中文摘要 
本計劃將過去文獻中所使用的特徵抽取
方法(主成份分析、線性鑑別分析、廣義鑑別
分析)且加入了核心主成份分析運用到熱人臉
影像做統合性的比較，另外也進行固定特徵抽
取方法進行分類器的分類成效比較。本計劃加
入了支持向量機分類器與先前所使用的最近
平均分類器和 K 個最近鄰居分類器進行比
較。由特徵抽取比較實驗結果顯示，由分類成
效可知資料點先經由核函數映射至高維特徵
空間中進行特徵抽取，比直接在輸入空間中進
行特徵抽取來得好。在分類器比較方面，將支
持向量機運用在熱人臉影像辨識所得到的分
類成效均比其他的分類器好，同時也證明直接
運用熱影像的灰階值也可得到很高的分類
率。本計劃中建立了中原大學熱紅外人臉影像
資料庫，其中包含 50 個人，每個人 60 張熱影
像照片，總共包含 3000 張熱影像照片。由實
驗結果可得知對於包含人臉輪廓的資料分別
運用主成份分析、核心主成份分析、線性鑑別
分析和廣義鑑別分析分類率可高達 100%，其
中分類器為支持向量機。對於未包含人臉輪廓
的資料使用支持向量機分類器，配合廣義鑑別
分析分類率為 99.2%，而配合核心主成份分析
分類率可高達 100%。 
關鍵詞:熱人臉影像辨識、支持向量機器、核心主成份
分析、線性鑑別分析、廣義鑑別分析。 
 
Abstract 
This project uses some advanced feature 
extraction methods, including PCA, LDA, GDA, 
and Kernel PCA (KPCA), to make a comparison 
on thermal face image recognition. We also 
evaluate some classifiers, including the Support 
Vector Machine (SVM), Nearest Mean 
Classifier (NMC), and K Nearest Neighbor 
(K-NN) Classifier. This project also establishes 
a Chung Yuan Christian University thermal 
infrared (IR) face image database, which 
contains 3000 images. The results show using 
the SVM as the classifier, using any of the 
feature extraction methods can achieve 100% 
classification rate if the input thermal IR images 
contain face contours. For the images that do not 
contain the face contours, the combination of 
KPCA+SVM can achieve 100% thermal IR face 
recognition rate also. 
Keywords: IR Thermal Face Recognition, Support Vector 
Machine, Kernel Principal Component Analysis, Linear 
Discriminant Analysis, and Generalized Discriminant 
Analysis. 
一、 前言及背景介紹 
近年來，由於電荷耦合器件技術的發展使得紅外
線攝影機的費用有明顯的下降[1]，因此民間方面的應
用開始不斷地上升。Prokoski [2]提出在紅外線光頻譜中
辨識的概觀，近十年來利用紅外線頻譜的人臉辨識方
面已成為日益感興趣的領域[3,4]，特別是熱紅外線影像
感測器，其範圍為中波紅外線(Mid-Wave IR, MWIR)和
長波紅外線(Long-Wave IR, LWIR)。儘管基於可見光頻
譜的自動化人臉辨識技術已成功地應用在許多實際面
圖2.1 拍照相對位置示意圖 
  
圖 2.2 中原大學熱影像人臉資料庫部份熱人臉影像 
 
三、 實驗系統架構與流程分析 
本計劃是利用中原大學影像伺服控制研究室所建
立的熱影像人臉資料庫進行特徵抽取的方法比較和分
類器的分類率比較。以下將詳述系統架構之流程中各
個步驟的設計原理、使用的理論及功能。 
 
3.1 熱人臉影像辨識系統實驗架構與實驗理論 
 
圖 3.1 熱人臉影像辨識系統實驗架構流程示意圖 
 
由於 FLIR Photon 320 輸出的熱影像不易清楚看出人
臉的輪廓、眼睛等資訊，所以本研究中的熱影像前處
理部份就是將原本的熱影像作轉換。 
3.2 數位影像處理技術 
熱影像前處理分成兩部份，第一部分是將熱影像
正規化，第二部份則是熱人臉影像剪裁。而熱人臉影
像剪裁可細分成三階段，第一階段是有包含頭髮、脖
子、耳朵，也就是整個臉的輪廓外型，第二階段只有
包含額頭到下巴和臉頰的部份，第三階段則是將第一
階段和第二階段所產生的熱人臉影像經過影像縮放、
直方圖等化和資料排列。 
A 熱影像正規化 
 
圖 3.2 熱影像正規化流程圖 
 
對於熱影像感測器 FLIR Photon 320 所輸出的資料為
14-bit Thermal Image，其每個像素值範圍為 0~16383 之
間，將熱影像正規化到我們熟悉的 8-bit 熱影像，其每
個像素值範圍為 0~255 之間。 
  
(a)原始的熱人臉影像 (b) 經過正規化 
圖 3.3 熱影像正規化之結果 
B 熱人臉影像剪裁 
第一階段熱人臉影像剪裁 
 
圖 3.4 第一階段熱人臉影像剪裁流程圖 
Step1. 首先將經過正規化的 8-bit 熱影像做二值化處
理，因為環境背景的溫度控制在一定範圍之內，所以
可以選擇一特定閥值將背景去除，在此選擇的閥值為
125，圖 3.5(a)為尚未經過二值化的熱影像，圖 3.5(b)
為經過二值化後的熱影像。 
  
(a)尚未經過二值化 (b)經過二值化 
圖 3.5 熱影像二值化之結果 
之y座標
 
對應熱影像
個數累計量 
Histogram 
Equalization
Horizontal 
Projection
Step1
Step2
Chin
position
Morphology
Processing
Connected 
Component Labeling
Area >Threshold
Reserving 
Object
Deleting 
Object
 Thermal Facial  Image 
Binarization Processing Step3
Yes
No
Cropped 
Thermal 
Facial 
Image  I
Cropped 
Thermal 
Facial 
Image  II
Forehead 
position
Cheek 
position
 
圖 3.12 第二階段熱人臉剪裁流程圖 
 
Step1. 在此將經過第一階段熱人臉剪裁的熱影像作直
方圖等化的動作。如圖 3.13 所示。 
  
(a) 第一階段熱人臉剪裁 (b)經過直方圖等化 
圖 3.13 直方圖等化之結果 
Step2. 將經過直方圖等化的熱人臉影像經過與第一階
段熱人臉剪裁的 Step3(形態學)及 Step4(形態學熱影像
修剪)同樣的處理後，得到修剪後的形態學熱人臉影像
(此為二值化的熱影像)，對其進行掃描的動作，由左到
右，由上到下進行掃描，其掃描的範圍為影上的上半
部，紀錄最先遇到像素為 1 時的 y 座標，此為左邊臉
頰的起始位置。同理，由右到左，由上到下，再次進
行掃描的動作，其範圍與上相同，紀錄最先遇到像素
為 1 時的 y 座標，此為右臉頰的起始位置。將兩座標
相減可得到一距離，在此我們定義此距離為第二階段
熱人臉剪裁的臉寬。同時將修剪後的形態學影像進行
水平投影，由上到下對投影所得到的累計圖去尋找累
計量超過五分之二臉寬的 x 座標，在此我們定義此座
標為額頭的水平位置，如圖 3.14 所示。 
         
 
圖 3.14 第二階段熱人臉水平投影結果 
 
Step3. 將 Step2 所得到的臉頰位置和額頭的位置與第
一階段裁減所記錄的脖子位置套用在第一次裁減的影
像上面，則可得到第二次裁減的影像。如圖 3.15 所示。 
  
(a)第一階段熱人臉剪裁 (b)第二階段熱人臉剪裁 
圖 3.15 第二階段熱人臉剪裁之結果 
 
第三階段熱人臉影像處理 
這階段則是將第一階段熱人臉剪裁和第二階段熱
人臉剪裁所得到的熱人臉影像作處理，使得熱人臉影
像能夠直接運用到實驗部分的處理步驟。圖 3.16 為其
流程圖。 
Step1. 將第一階段剪裁的影像集合和第二階段剪裁的
影像集合分別作直方圖等化和影像縮小尺寸，由於熱
人臉影像經過裁減後每張大小就會有些不同，且為了
減小程式進行分類器的訓練與測試之時間，所以依序
將每張熱人臉影像縮小高度為 28 像素、寬度為 23 像
素的尺寸。  
 
圖 3.16 第三階段處理流程圖 
Step2. 資料排列：為了將每張影像經過直方圖等化及
影像縮放之後的所有灰階值當作其特徵值，於是建立
一個新的空矩陣，然後逐列掃描灰階影像的矩陣資
料，將矩陣中第 1 列的 23 個灰階值存入新矩陣的第 1
行到 23 行，將矩陣中第 2 列的 23 個灰階值接續存入
新矩陣的第 24 行到 46 行，而矩陣中第 3 列到 28 列的
基本想法利用含兩個類別的訓練資料(Training data)找
出一個分離平面(Separation hyperplane)，該平面距離兩
個類別中最近資料點的距離愈大，則對於未知的測試
集合(Test set)能夠產生愈小的分類錯誤率，故具有較好
的擴充能力(Generalization ability)。 
 
 
圖 3.17 支持向量說明圖 
 
 
圖 3.18 彈性變數與最佳分離平面的關係圖 
 
在現實世界中，通常我們想要分類的資料會有重
疊的情形(data overlapping)，因此無法使用線性分類器
對資料進行分類，所以就無法以剛性邊界限度的方式
(如(3.3.10)式)來求解，為了解決此一問題，我們使用了
柔性邊界限度(soft margin)來求解，將部份重疊的資料
點視為錯誤(error)，忽略這些錯誤後就可利用剩下的資
料點來建構 OSH。我們必須加入一個彈性變數 iξ (slack 
variables)於限制條件中，其中 iξ 可分為三種情形，如圖
3.18 所示資料點(1)、(2)、(3)分別代表第一、二、三種
情形，第一種情況代表 1≥iξ ，為分類錯誤；第二種情
況滿足 10 << iξ ，資料點落在邊界限度之內，但分類正
確；第三種情況之 0=iξ 為分類正確。此時之初始最佳
化問題為(3.4)式 
li
bwxytoSubject
CwMinimize
i
iii
l
i
i
,,1          0                   
       01),(     
2
1     
**
1
2
L=≥
≥+−+
+ ∑
=
ξ
ξ
ξ
     (3.4) 
原問題對偶形式，如(3.5)式 
liC
ytosubject
xxyyLMaximize
i
l
i
ii
l
i
l
j
jijiji
l
i
iD
,,1,0                   
0    
,
2
1)(  
1
1 11
L=≤≤
=
−=
∑
∑∑∑
=
= ==
α
α
αααα
 (3.5) 
當 Ci =α 時，若 1>iξ 則分類錯誤；若 10 << iξ 時資料
點落在邊界限度內，但分類正確；當 Ci <<α0 時
0=iξ ，資料點位於邊界平面上，分類正確，我們可利
用拉哥朗君乘子不為零之資料點來計算最佳分離平面
的權重向量 *w ，如(3.6)式， 
          Cxyw i
N
i
SV
iii
s <<=∑
=
αα 0,        
1
**              
                                           (3.6) 
 
其中 SV 代表支持向量， SN 代表支持向量的個數；而
偏移量 *b 必須利用 iξ 為零之資料點求得，如(3.7)式所
示 
 
          Cwx
yN
b i
N
i
SV
i
is
s <<⎟⎟⎠
⎞
⎜⎜⎝
⎛ −= ∑
=
α0      ,,11
1
*       
                                (3.7) 
 
故對於測試資料點 x 而言，便可利用決策函數進行分
類，如(3.8)式所示 
         
),()( *
1
* bxxysignxf
sN
i
SV
iii += ∑
=
α
    (3.8) 
 
上述的核心函數 K 有不同種類，常用的核心函數如表
3-1 中所示，當使用多項式函數時，我們可以調整其次
方項P ；當使用幅射基底函數時，可調整其高斯寬度
σ 。 
表 3.1 常用的核心函數表 
多項式函數 (Polynomial) pzxzxK )1,(),( +=  
幅射基底函數   
(Radial Basic Function，
RBF) 
⎟⎟⎠
⎞
⎜⎜⎝
⎛ −−= 2
2
2
exp),( σ
zx
zxK
四、實驗結果 
4.1 比較特徵抽取的方法之辨識結果 
本研究中先運用最為廣泛使用的分類器- K-NN，
當 K=1 時，也稱為最近距離分類器(NN)，其中測距方
法為歐式距離。然後運用 PCA、LDA、KPCA、GDA
4.3 圖樣經過 PCA 特徵抽取的分類器比較與討論 
將原本維度大小為 500*644 的 IR_1 和 IR_2 分別
進行 PCA 特徵抽取。原本每張影像維度為 644，分別
進行抽取 50、100、200、300、400 個最大特徵值所對
應的特徵向量，由最近距離分類器(NN)找尋最佳的特
徵抽取筆數 t。由表 4.1 可知對於 IR_1 而言，經過 PCA
特徵抽取最佳筆數 t 為 100，IR_1 維度大小變為
500*100。對於 IR_2 而言，經過 PCA 特徵抽取最佳筆
數 t 為 100，IR_2 維度大小變為 500*100。 
 
表4.3 IR_1&IR_2經過PCA特徵抽取實驗結果
(Classification Rate：%) 
Classifier IR_1 IR_2 
ED MD MA ED MD MA
NMC 
96.8 99.4 99.6 88.4 91 92.8
Type ED MD MA ED MD MA
K=1 99.6 99 98.6 98.2 90.4 92 
K=3 95.8 95.2 94.2 83.8 77.8 83.8
K-NN 
K=5 94.8 92.6 94.2 80.4 68.6 81.8
SVM 100 99.3 
 
將 NMC 與 K-NN 兩種分類器中的最佳分類率的
測距方式與 SVM 做比較。對於經過 PCA 特徵抽取的
IR_1 而言，當σ =400、C=1 時，SVM 分類率為 100%，
對於經過 PCA 特徵抽取的 IR_2 而言，當σ =200、C=1
時，SVM 分類率為 99.3%，所以 SVM 分類器比起 NMC
與 K-NN 有更好的分類率。 
 
4.4 圖樣經過 LDA 特徵抽取的分類器比較與討論 
由於訓練的圖樣數和類別數之和比需要大於特徵
的維度才能確保其類別內散佈矩陣為可逆的，所以先
利用 PCA 將維度縮減後，分別取前 t 個最大特徵值所
對應的特徵向量 t 為 50、100、150、200、250、300、
350，再運用 LDA 特徵抽取，將圖樣投影到 C-1 的維
度空間中，C 為類別總數空間維度為 49，在 LDA 的理
論中，分類 C 類的問題中，只需要取 C-1 的維度即可。
將原本維度大小為 500*644 的 IR_1 和 IR_2 分別進行
LDA 特徵抽取。原本每張影像維度為 644，分別進行
抽取 t 個最大特徵值所對應的特徵向量，由最近距離分
類器(NN)找尋最佳的特徵抽取筆數 t。由表 4.1 可知對
於 IR_1 而言，經過 PCA 特徵抽取最佳筆數 t 為 100，
再運用 LDA 投影到空間維度為 49，IR_1 維度大小變
為 500*49。對於 IR_2 而言，經過 PCA 特徵抽取最佳
筆數 t 為 50，再運用 LDA 投影到空間維度為 49，IR_2
維度大小變為 500*49。 
 
表4.4 IR_1&IR_2經過LDA特徵抽取實驗結果
(Classification Rate：%) 
Classifier IR_1 IR_2 
ED MD MA ED MD MA
NMC 
99.5 99.5 99.5 96.4 90 92.8
Type ED MD MA ED MD MA
K=1 99.9 99.8 99.6 98.4 97.4 97.4
K=3 99.8 99.4 99.6 93 86 85.8
K-NN
K=5 99.6 99.2 99.2 90.8 81.4 83.8
SVM 100 98.4 
 
將 NMC 與 K-NN 兩種分類器中的最佳分類率的
測距方式與 SVM 做比較。對於經過 LDA 特徵抽取的
IR_1 而言，當σ =100、C=0.01 時，SVM 分類率亦為
100%，對於經過 LDA 特徵抽取的 IR_2 而言，當
σ =200、C=1 時，SVM 分類率為 98.4%，所以 SVM
分類器比起 NMC 與 K-NN 有更好的分類率。 
 
4.4 圖樣經過 KPCA 特徵抽取的分類器比較與討論 
進 行 KPCA 特 徵 抽 取 時 ， 運 用 核 函 數
RBF-Kernel，藉由調整σ 將 IR_1、IR_2 投影到不同的
特徵空間中後，再進行 PCA 特徵抽取，分別進行抽取
前 t 個最大特徵值所對應的特徵向量，t 為 50、100、
200、300、400 個最大特徵值所對應的特徵向量，再運
用最近距離分類器(NN)分類，尋找最佳的特徵值所對
應的特徵向量個數 t 和σ 。由表 4.1 可知對於 IR_1 而
言，經過 KPCA 特徵抽取最佳筆數 t 為 300 和σ 為 800，
IR_1 維度大小變為 500*300。對於 IR_2 而言，經過
KPCA 特徵抽取最佳筆數 t 為 300 和σ 為 1000，IR_2
維度大小變為 500*300。 
 
表4.5 IR_1&IR_2經過KPCA特徵抽取實驗結果
(Classification Rate：%) 
Classifier IR_1 IR_2 
