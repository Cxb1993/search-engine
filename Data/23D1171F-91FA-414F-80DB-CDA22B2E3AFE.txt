行政院國家科學委員會補助專題研究計畫 ■ 成 果 報 告   □ 期中進度報告 
 
以使用者為導向的社群網絡建構與分析—子計畫一：利用資
料探勘技術於社群網路中使用者行為分析(I)  
 
計畫類別：□ 個別型計畫  ■ 整合型計畫 
計畫編號：NSC 100－2221－E－259－010  
執行期間： 100 年 8 月 1 日至 101 年 10 月 31 日 
 
計畫主持人：李官陵 教授 
計畫參與人員：陳奕鈞，張家榮，林延睿，楊質彬，江東哲，劉思吟，林修
豪，劉奕圻，楊盛富，林宛琦，金柏均 
 
 
成果報告類型(依經費核定清單規定繳交)：■精簡報告  □完整報告 
 
本成果報告包括以下應繳交之附件： 
□赴國外出差或研習心得報告一份 
□赴大陸地區出差或研習心得報告一份 
■出席國際學術會議心得報告及發表之論文各一份 
□國際合作研究計畫國外研究報告書一份 
 
 
處理方式：除產學合作研究計畫、提升產業技術及人才培育研究計畫、
列管計畫及下列情形者外，得立即公開查詢 
          □涉及專利或其他智慧財產權，■一年□二年後可公開查詢 
          
執行單位：國立東華大學資訊工程學系 
 
中   華   民   國  101 年    11 月    2 日 
 
 
 
2 
 
動，而這些交互的作用與關係，形成
了一種虛擬的社群，我們稱這樣的虛
擬社群為網路社群。 
本計劃將社群網站中使用者間的
關聯視為一個圖，以圖形結構表示
之，根據利用疊加後的圖形所形成的
全域圖有效探勘頻繁最大完全子圖，
藉以研討量化使用者間因交互作用而
產生的關聯性；接著，再將社群網站
的環境視為一個資料串流的環境，利
用我們提出的路徑樹演算法，有效的
探勘出序列式樣，如此可以找出使用
者近來關注議題的演進史。最後，我
們以結構化同儕網路為基礎，考慮擴
大搜尋的範圍來滿足各種的查詢，並
利用支持檔案名稱部份配對設計出有
效的搜尋機制。 
研究方法 
我們總共討論三個議題，分別為
探勘最大完全子圖，在資料串流環境
下探勘序列式樣以及在結構化同儕網
路下設計支持部分檔名查詢的有效搜
尋機制，茲分述如下: 
探勘最大完全子圖 
近年來，圖形探勘已是資料探勘中熱
門的研究項目並且應用在相當多的領
域。然而，大部份的高頻圖形探勘演
算法並沒有專注於特定拓撲結構，像
是完全子圖(clique)。本篇研究中，我
們將探討在圖形資料庫中，找出一種
最大且頻繁出現的特殊結構：完全子
圖(clique)。 
首先，我們將探討如何在靜態資料中
探勘完全子圖的問題，我們將問題描
述如下，讓 Σ 表示為一標籤集合，一
個圖形(graph) G = ( V, E, λ ) 則代表著
一個無向標籤圖形，其中 V 代表著圖
中的節點 (vertex)集合 , E 代表著邊
(edge)的集合，而 λ 則為一對應函數，
將每一個節點對應到一個屬於 Σ 的標
籤。而一個完全子圖(clique), C, 則為
一個完全連結的節點集合，且當子圖
內包含 k 個節點時，則稱為 k-clique。
在圖形探勘的問題中，首先要面對的
就是圖形異種同形(isomorphism)的問
題，異種同形的定義如下: 
Definition (isomorphic) 
A graph G1 = (V1, E1, λ1 ) is isomorphic 
to another graph G2 = (V2, E2, λ2 ) iff the 
following two conditions hold 
1. |V1| = |V2| 
2. there exists a bijection  f : V1 
→V2  such that for u≠v if 
(u,v)E1 then ( f(u), f(v))E2 and 
if λ1(u) =λ1(v), then λ1(f(u)) = 
λ1(f(v)) 
當一個子圖 H 與圖形 G 裡的某一個完
全子圖是異種同形時，我們則稱圖形 G
支持完全子圖 H。為了節省判斷異種
同型的時間，我們將資料庫中所有的
圖形先全部疊加成一張疊加的圖形，
而為了保證所有圖形中的完全子圖都
會在疊加後的圖形中找到一個同構的
子圖存在，我們將每一張圖拆成一個
一個的邊，並根據其節點上的標籤將
其排序，依序加入疊加圖中，圖 1 展
示的是圖形資料庫原本的樣子，而圖 2
則為整理後的疊加圖。 
4 
 
用有效率的 GVG_Mine 演算法探勘最
大頻繁完全子圖。 
在資料串流環境下探勘序列式樣 
因為現今社群網路已變成社會大
眾大多數人每天會登入交流的平台，
每天都會有數以百萬筆資料做更新，
因此我們將社群網站的環境視為一個
資料串流的環境。在本篇研究中，我
們就是要探討在資料串流的環境下如
何有效探勘序列式樣。 
由於大多數的使用者感興趣的是當下
的資訊，而非先前的資訊，我們將透
過時間窗(time window)的機制來區分
哪些資料為使用者感興趣的資訊。並
且我們設計出一個樹狀的資料結構：
路徑樹(Path tree)，將各使用者的瀏覽
路徑資料都紀錄下來，然而，為了避
免儲存所需的資訊時會造成龐大記憶
體使用量，我們勢必得選擇性的儲存
資料。我們以下面的例子說明如何建
立此樹狀結構。圖3為使用者在不同時
間區間中瀏覽資料的序列，共有二個
使用者，而在時間區間1中(Time period 
1)，使用者1(s1)瀏覽到{A,C}二個網
頁，使用者2(s2)瀏覽到{B}網頁。在圖
4中，顯示隨著時間片段的經過，路徑
樹的建置；在此路徑樹中，為了要完
整的紀錄使用者瀏覽的一般化序列，
並能在新的資料加入時，還能有效的
判斷哪些序列是可以增長的，所以在
路徑樹中，我們必須紀錄這個序列是
由誰走過以及該序列起始的時間。例
如，在時間區間1時，樹中記錄著使用
者1走訪A和C，使用者2走訪B；當時
間走到時間區間2時，我們發現到使用
者1沒有再走訪網頁，而是使用者2走
訪了{A,B,C}，因此我們要將此資訊存
入路徑樹中；並且我們發現A在時間區
間1時出現在使用者1中，而時間區間2
時會出現在使用者2中，這表示會記錄
s1-> s2 這種型式的序列有A，而該序列
的起始時間為時間區間1。我們要將這
些資訊記錄下來，如果沒有記錄，當
新的資料進來時，我們將無法判斷哪
些序列可以增長。在路徑樹中，每個
節點序列的支持度，即為該序列最後
一個節點所包含的項目個數。 
 
圖3. Data of sensor gathering in each time 
period 
 
 
 
圖4. Path Tree constructed from  
由於在路徑樹中，每個瀏覽路徑都有
一相對應的路徑(path)來保存其一般化
序列資訊，所以需要巨大的儲存容
量。在本篇研究中，我們首先提出
PAlgorithm來有效率的產生節點並選
擇性的儲存資料。根據Apriori的特
性，若一序列為頻繁序列式樣，則其
所有的子序列皆為頻繁序列式樣。我
們根據此一特性，使用一門檻值，當
6 
 
完’+’與”*’之後，我們將從檔案發表
(File puplish) 以及查詢處理 (Query 
processing)兩方面來討論。 
 在 CHORD 中，每一個發表的檔
案會經由一個雜湊函式，將其檔名(或
是根據關鍵字)對應成在 CHORD ring
上的一個值，而該檔案的索引值則會
儲存於負責範圍包含該值的節點上。
所以在計畫中，我們將考慮如何將發
表檔案之檔名對應到 CHORD ring 上
的一個值，且必須要能提供部分檔名
的查詢。我們的初步想法為，當一個
檔案要被發表時，我們將其發布的檔
名(或關鍵字，在之後的討論中我們皆
以檔名統稱之)利用滑動視窗(sliding 
window) 切 成 一 個 一 個 長 度 為
d(d-length) 的 片 段 ， 而 且 每 一 個
d-length 的片段會被雜湊到一個索引
序列(index sequence 0 1 1, ......, dv v v   )
中，我們稱為 IS，範圍介於0 1iv r  
和0 1i d   間。d 與 r 這二個參數分
別代表的是在映成函數中的維度
(dimension)和在每一個維度中的範圍
(range)。在得到這些長度為 d 的片段
後，我們將利用公式一將一個長度為 d
的片段對應為 CHORD ring 上面的一
個特定的鍵值(specific key): 
1
m
0 1 1
0
( , ......, ) ( )  mod 2
d
j
d j
j
Loc v v v v r




………公式一 
在式中， m 代表在 CHORD 中
Finger table 的大小，並且，如果 r 和 d
會滿足這個等式 mod 2 0d mr  ，那麼
將會達到負載平衡。對每一個要發表
的檔案來說，我們利用滑動視窗將檔
名切成長度為 d 的片段。將每一個片
段丟入發表函數(publish function)中，
如公式二，來形成 IS。在公式二中， jIS
表示為從第 j 個特徵片段開始的索引
序列，p 為發表檔名的長度，h 為一雜
湊函數。 
1 1
[ ] mod r , if ' '
( )
random value from 0 to r-1, if ' '
( ), ( ), ..., ( ) , 0
i i
i
i
j j j j d
h a a
f a
a
IS f a f a f a j p d  
 

 
    

………公式二 
根據以上的公式，每一個檔案可以被
表示為和檔案符合的 jIS 的集合，以
CIS 表示之。根據公式一可以得到每一
個在 CIS 的 IS 在 Chord 中會對應到一
個特定的鍵值。因此，每一個檔案會
對應到 (p-d+1)個鍵值並且會放置在
Chord 中。下面我們列出檔案發表的演
算法：  
 Algorithm File Publish
Input :
         : filename
         : dimension
Procedure    Publish (  , )
1: if ( .length  )
2:    for (int  = 0 ;   .length -  ; ++)
3:         = substring (  ,  , +
p
d
p d
p d
i i p d i
s p i i


-1) // : viriable to store 
substring
4:        Translate  into a key according to equation 1
5:        Publish  in Chord according to the key
6: else    // .length < 
7:     = append ( - .length) 
d s
IS
p
p d
s d p '+' at the end of 
8:    Translate  into a key according to equation 1
9:    publish  in Chord according to the key
10:end
p
IS
p
    
8 
 
本計劃的研究成果，我們於國際期刊
和國際會議的發表如下： 
[1] Guanling Lee, Sheng-Lung Peng, 
Shih-Wei Kuo and Yi-Chun Chen, 
“Mining Frequent Maximal Cliques 
Efficiently by Global View Graph,” The 
9th International Conference on Fuzzy 
Systems and Knowledge Discovery, 
2012.(EI) 
[2] Guanling Lee, Kuo-Che Hung and 
Yi-Chun Chen, “Path Tree: Mining 
Sequential Patterns Efficiently in Data 
Streams Environments,” submitted to 
International Computer Symposium, 
2012. 
[3] Guanling Lee, Sheng-Lung Peng, 
Yi-Chun Chen, and Jia-Sin Huang, “An 
Efficient Search Mechanism for 
Supporting Partial Filename Queries in 
Structured Peer-to-peer Overlay”, 
Journal of Peer-to-Peer Networking and 
Applications Vol. 5, 2012.(SCI) 
 
Dear Guanling Lee, 
Paper ID : P1825 
Paper Title : Mining Frequent Maximal Cliques Efficiently by Global View Graph in Large 
Databases 
 
(All Chinese characters in this email are intended for authors from China's mainland only. 
请浏览会议网站上的中文注册和终稿上传信息。) 
Congratulations! We are pleased to inform you that your above paper has been accepted 
for presentation at the 9th International Conference on Fuzzy Systems and 
Knowledge Discovery (FSKD'12) to be held from 29-31 May 2012, in Chongqing, China. 
After you complete the requirements below, your paper will appear in conference 
proceedings and will be indexed by both EI Compendex and ISTP, as well as the IEEE 
Xplore (ICNC'12: Conference Record Number 19846; IEEE Catalog Number 
CFP12CNC-ART; ISBN 978-1-4577-2133-5; FSKD'12: Conference Record Number 
19847; IEEE Catalog Number CFP12FSK-ART; ISBN 978-1-4673-0024-7). Substantially 
extended versions of best papers will be considered for publication in a ICNC'12-FSKD'12 
special issue of the Computers and Electrical Engineering journal (SCI-indexed). Only 
registered papers will be considered for the SCI journal special issue and only the 
selected authors will be notified by 25 April 2012. 
The conference will feature world-renowned keynote speakers: Philip Chen, University of 
Macau, IEEE Fellow; President-Elect, IEEE Systems, Man, Cybernetics Society; 
Pau-Choo Chung, National Cheng Kung University, IEEE Fellow, Distinguished Professor; 
Dimitar P. Filev, Ford Motor Company, IEEE Fellow; Vice President Cybernetics, IEEE 
Systems, Man, and Cybernetics Society; Jun Wang, Chinese University of Hong Kong, 
IEEE Fellow, National Thousands-talent Chair Professor, China. 
In order for your paper to be included in the proceedings indexed by Ei Compendex/ISTP, 
it is important that you closely follow each and every instruction below, as the acceptance 
is conditional on your accurate and timely reactions : 
1. Revise your paper, appropriately addressing the reviewer comments (at the end of this 
email, if any) which are intended to help you improve your paper for final publication. If 
any review comments seem vague, please revise your paper according to your best 
understanding. 
2. Strictly follow the IEEE format requirements; incorrectly formatted papers cannot be 
included in the proceedings. Please refer to the conference 
Mining Frequent Maximal Cliques Efficiently by 
Global View Graph 
 
Guanling Lee, Sheng-Lung Peng, Shih-Wei Kuo and Yi-Chun Chen 
Department of Computer Science and Information Engineering 
National Dong Hwa University, Hualien, Taiwan, R.O.C 
guanling@mail.ndhu.edu.tw 
 
 
Abstract—Graph mining problem has been a popular research 
issue in recent years. Many kind of data can be represented as a 
graph and solve the particular problem by using a specific graph 
algorithm. Recently, the applications of graph mining are 
growing quantity. In this paper, the main subject is to find a 
specific topology called clique which is maximal and frequent in a 
set of graphs. In our approach, the graphs are first summarized 
into a global view graph. It is shown that any clique contains in 
the graph database, there must exist an isomorphic subgraph in 
the summarized graph according to our summarization process. 
Therefore, the frequent maximal clique mining process will focus 
on the global view graph. Moreover, by comparing with other 
existing methods, a set of experiments is performed to show the 
benefit of our approach. 
Keywords-component; Graph mining, Frequent subgraph 
mining, Maximal clique mining, Graph summary 
I.  INTRODUCTION  
Recently, the research of Graph Mining has grown a great 
quantity. However, most frequent graph mining algorithms do 
not focus on a certain topology such as clique, bipartite, and 
rings. Actually, there are more and more applications in 
computing some certain chosen graphs. For example, M. 
Garofalakis et al. proposed an approach of enumerating Web 
occurrences of cliques [3] , G. Liu et al. proposed an approach 
of finding maximal bicliques for Web community discovery 
and maximal concatenated phylogenetic dataset discovery [5], 
and R. Kumar et al. proposed an approach of finding Web rings 
for building Web knowledge bases [4], and J. Wang et al. 
proposed another approach of finding cliques from stock 
market graphs in order to identify groups of highly-correlated 
stocks [7]. 
There are many special topologies of graphs. Clique is one 
of the most complicated structures for mining process. The 
frequently occurring clique patterns can be viewed as the dense 
core of different objects to show the intensity in a set of graph 
transactions. However, identifying cliques from a graph is an 
NP-complete problem. As other subgraph mining problems, 
isomorphism testing usually costs the most time in the whole 
mining process. A clique in a graph G is a complete subgraph 
of G (i.e., it is a subset S of the vertices such that every two 
vertices in S form an edge in G). Therefore, the isomorphism of 
subclique checking has to check every vertex of C that also 
appears in G’. 
The problem of mining cliques from a single graph is 
introduced in [6]. CLAN [7] was the first approach focusing on 
mining frequent closed cliques from a set of graph transactions. 
It uses embedding count to represent the support count of the 
graph database and the canonical form to uniquely represent a 
clique which can simplify the clique isomorphism testing. Then 
the canonical form was used to perform frequent clique 
enumeration. A lattice-like structure has been conceptually 
constructed after all frequent cliques generated. By depth-first 
traversing the lattice-like structure, a list of frequent cliques 
was generated. The remaining frequent cliques need to be 
checked to see whether it is closed after the process of mining 
complete set of frequent cliques. 
In this paper, an algorithm called GVG_Mine is proposed to 
mine maximal frequent cliques from large graph databases. In 
the approach, a graph named global view graph (GVG in short) 
is created to summarize the information contained in the graph 
database. By removing the low weighted edges and dividing 
the global view graph into several biconnected components, all 
possible maximal frequent cliques contained in the database 
can be determined. After getting the information, a mining 
method similar to MaxMine [2] is used to mine out the 
maximal frequent cliques in the graph database. Finally, the 
mining results are obtained. The focus of CLAN [7] and our 
approach is on the same graph topology. The difference 
between the two approaches is that the mined out patterns of 
CLAN are closed frequent cliques but ours are maximal 
frequent cliques.  
The rest of this paper is arranged as follows. Section 2 
describes the problem definition and preliminaries. We will 
present the design of the algorithm in Section 3. Experimental 
results and analysis are discussed in Section 4. Finally, we 
conclude our work in Section 5. 
II. PROBLEM DEFINITION 
Let Σ be a label set. A graph G = ( V, E, λ ) is defined as an 
undirected labeled graph where V is the set of vertices, E is the 
set of edges, and λ is a labeling function which maps every 
vertex of V to a label of Σ. A clique, C, is defined as a set of 
fully connected vertices. A clique of size k is called k-clique 
which contains {k*(k-1)}/2 edges. 
Without loss of generality, we assume the missing label 
is ( )ivλ . That is, there does not exist a vertex v in GGVG such 
that ( ) ( )i GVGv vλ λ= . In this case, one new vertex 1GVGCv +  is 
inserted into GVGV . And 1( ) ( )GVGGVG C iv vλ λ+ =  is added into λGVG. 
Let xv be the vertex of GVGV  such that ( ) ( )GVG x jv vλ λ= and x is 
the smallest index in GVGV , edge ( 1)GVGx Ce +  is inserted into GVGE . 
The process is summarized in the following. 
1
( 1)
( 1)
{ };
{ ( ) ( )};
{ };
. 1;
1;
GVG
GVG
GVG
GVG GVG C
GVG GVG GVG x j
GVG GVG x C
x C
GVG GVG
V V v
v v
E E e
e weight
C C
λ λ λ λ
+
+
+
= ∪
= ∪ =
= ∪
=
= +
 
Case 3: Both λ(vi) and λ(vj) are defined in λGVG. 
In this case, we can find two vertices pv  and qv  with labels 
( )ivλ  and ( )jvλ  in GVGV  and (p,q) is the smallest index pair 
among all possible pairs of GVGG . We have the following three 
subcases. 
Case 3.1: pq GVGe E∉  
The edges pqe  will be inserted into GVGE  and .pqe weight  
is set to 1. 
Case 3.2: pq GVGe E∈  
We increase .pqe weight  by one. 
Case 3.3: The vertex pair ( , )p qv v does not exist, e.g., 
p qv v= . 
A new vertex 1GVGCv +  is inserted into GVGV  and  
)()( 1 pGVGC vv GVG λλ =+  is added into λGVG. Then, a new edge 
( 1)GVGp C
e
+
 is inserted into GVGE . 
The process is summarized as follows. 
Case3.1 :  
{ };
. 1;
GVG GVG pq
pq
E E e
e weight
= ∪
=
 
Case3.2 : . 1;pqe weight+ =  
Case3.3 : 
 
1
1
( 1)
( 1)
{ };
{ ( ) ( )};
{ };
. 1;
1;
GVG
GVG
GVG
GVG
GVG GVG C
GVG GVG GVG C GVG p
GVG GVG p C
p C
GVG GVG
V V v
v v
E E e
e weight
C C
λ λ λ λ
+
+
+
+
= ∪
= ∪ =
= ∪
=
= +
 
Because in the edge insertion strategy, we always pick the 
vertex with the minimum vertex number or the vertices with 
the minimum vertex number pair, the information of the most 
graphs will be gathered in the vertices with small vertex 
number in GVG. Based on the above observation and the graph 
summary steps, we have the following property for our 
construction. If a clique C is contained in some graph G, it will 
also be contained in GGVG in our graph summarization steps. 
III. MAXIMAL FREQUENT CLIQUE MINING 
In this section, we propose our main algorithm called 
GVG_Mine to mine the maximal frequent cliques in a graph 
database.  First, the edges with weight less than min_sup*|DB| 
will be removed by the property that there does not exist a 
frequent clique contained in GGVG which has an edge is not 
frequent. Moreover, because a clique cannot have a cut point, 
the GGVG is further decomposed into biconnected components. 
This step can help the candidate cliques’ generation described 
later.  
The next step is executing GVG_Mine algorithm for each 
components of GGVG. Algorithm GVG_Mine includes the 
maximal frequent pattern mining process, called MaxMiner [2] 
as a subroutine with a slightly modification. The MaxMiner’s 
main pseudo code is shown as follow. 
 
MAX-MINER(Data-set T) 
Set of Candidate Groups C←{ } 
Set of Itemsets F←{GEN-INITIAL-GROUPS(T,C)} 
while C is non-empty do 
scan T to count the support of all candidate groups in C 
for each g∈C such that h(g)∪t(g) is frequent do 
F←F∪{h(g)∪t(g)} 
Set of Candidate Groups Cnew←{ } 
for each g∈C such that h(g)∪t(g) is infrequent do 
F←F∪{GEN-SUB-NODES(g, Cnew)} 
C ← Cnew 
remove from F any itemset with a proper superset in F 
remove from C any group g such that h(g)∪ t(g) has a 
superset in F 
return F 
The test data is generated by the real data of US stock 
market database which was also used in CLAN [7]. The 
parameter setting for generating the test data are shown in 
Table 1. I means the total numbers of graphs in database. V 
shows the average vertex numbers of each graph of database 
and E shows the average edge numbers of each graph of 
database. The parameters V and E can be used to determine 
whether the graph database is dense or sparse. 
Graph_Sum
0.1
1
10
100 125 150 175 200 225 250 275 300
Graph Numbers
Tim
e(s
)
V20.E130
V40.E520
V20.E50
V40.E100
 
Figure 2. Execution time of GVG_Summary for sparse and 
dense graph dataset 
Figure 2 shows the execution time of graph summary 
process on sparse and dense graph dataset. As shown in the 
result, algorithm Graph_Sum is efficient for the sparse graph 
database. Moreover, the denser the database is, the longer the 
execution time the approach takes. Figures 3 and 4 indicate that 
GVG_Mine is more efficient than MaxMiner as the support 
threshold larger than 5%. However, when the minimum 
support gets small, GVG_Mine will generate a lot of false 
positive candidates. As a result the execution time of 
GVG_Mine is longer than that of MaxMiner in the small 
support threshold case. 
I100.V20.E130
0.1
1
10
100
12% 13% 14% 15% 16% 17% 18% 19% 20%
Support Threshold
Tim
e(s
)
GVG_Mine
MaxMiner
 
Figure 3. Execution times of two algorithms for dense 
graph dataset I100.V20.E130 
I100.V20.E50
0.1
1
10
100
5% 6% 7% 8% 9% 10% 11% 12% 13% 14%
Support Threshold
Tim
e(s
) GVG_Mine
MaxMiner
 
Figure 4. Execution times of two algorithms for sparse 
graph dataset I100.V20.E50 
 
V. CONCLUSIONS 
In this paper, the maximal frequent clique mining problem 
is discussed. The main idea of the proposed approach is the 
graph summary method. Moreover, an efficient graph mining 
algorithm called GVG_Mine is proposed to mine maximal 
frequent cliques from large graph databases according to the 
summarized graph. The experimental results show the 
efficiency of the proposed mining method for mining maximal 
frequent cliques. 
REFERENCES 
 
[1]  A. Br¨ ugger, H. Bunke, P. Dickinson, K. Riesen. Generalized Graph 
Matching for Data Mining and Information Retrieval. ICDM’08 
[2]  R.J. Bayardo. Efficiently Mining Long Patterns from Databases. 
SIGMOD’98 
[3]  M. Garofalakis, R. Rastogi, S. Seshadri, K. Shim. Data mining and the 
Web: past, present and future. WIDM’99 
[4] R. Kumar, P. Raghavan, S. Rajagopalan, A. Tomkins. Extracting large-
scale knowledge bases from the Web. VLDB’99 
[5] G. Liu, K. Sim, and J.Li. Efficient Mining of Large Maximal Bicliques. 
DaWaK’06 
[6]  J. Pei, D.Jiang and A. Zhang. On Mining Cross-Graph Quasi-Cliques, 
KDD 05. 
[7]  J. Wang, Z. Zeng, L. Zhou. CLAN: An Algorithm for Mining Closed 
Cliques from Large Dense Graph Databases. ICDE’06 
  
 
100年度專題研究計畫研究成果彙整表 
計畫主持人：李官陵 計畫編號：100-2221-E-259-010- 
計畫名稱：以使用者為導向的社群網絡建構與分析--子計畫一：利用資料探勘技術於社群網路中使用
者行為分析(I) 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 1 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 2 0 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
