online dictionary translation, the results are very 
different. Moreover, the word meaning could affect 
users to make decisions. Therefore, opinion words 
translation in opinion sentences is particularly 
important. In our project＇s first year, we purpose a 
translation disambiguation method using the feature-
opinion association and dependency distance for 
opinion word translation. In the second year, we 
integrate our cross-lingual information retrieval 
system and the above developed components to 
construct a cross-lingual travel opinion search 
system. 
英文關鍵詞： cross-language opinion search, opinion mining, 
unsupervised opinion word translation 
 
中文摘要 
隨著網際網路的興起，由使用者創作的內容（User-Generated Content），成為網路消費者在
從事消費行為時，非常重要的依據。雖然目前規模較為領先的搜尋引擎 Google 和 Yahoo!
提供討論區、部落格搜尋等功能，使用者依然得從數千篇不等的評論文章中，逐一閱讀來
瞭解他人想法。近年來海外購物風潮盛行，特別是使用中日韓三種語言的東亞地區，由於
文化上的相互影響，這種現象更是顯著。然而國人消費者在查詢國外商品資訊時，往往受
限於語言隔閡，無法理解以外語撰寫的評論。有鑑於此，本計畫擬發展跨語意見搜尋系統，
運用文字探勘技術，將這些評論加以整理歸納，並翻譯句中最關鍵的詞彙：產品名稱、特
徵詞、意見詞，幫助使用者做快速且正確的決策。由於意見詞詞性大多為形容詞，在經過
線上字典查詢過後，翻譯結果差異性比較大，且用詞程度也會影響使用者決策，翻譯評論
句中的意見詞就顯得格外重要。第一年研發意見詞翻譯元件提出利用特徵意見關聯
（Feature-Opinion Association）與相依距離（Dependency Distance）的翻譯消歧方法。第二
年整合研究團隊已研發多年的跨語檢索技術和第一年研發的各項元件，開發出跨語旅遊意
見搜尋系統。 
ABSTRACT 
As the rapid development of Internet, the user-generated content has become a very important 
criterion for consumers engaging in consumption behavior. Although the leading search engines 
such as Google and Yahoo! provide search functions for forums and blogs, users still have to 
read thousands of articles one by one to understand other people's ideas. In recent years, overseas 
shopping becomes a trend. Since the cultural interaction especially for people in East Asia, this 
phenomenon is even more significant. However, when local consumers query for foreign product 
information, they can't understand the reviews written by other languages because the language 
barriers. This proposed project hope to develop a cross-language opinion search system which 
apply the text mining techniques for summarizing these reviews and translating the key lexicons 
(product names, feature words, opinion words) to help users make decisions accurately and 
quickly. For opinion words, the POS are mostly adjectives. After online dictionary translation, 
the results are very different. Moreover, the word meaning could affect users to make decisions. 
Therefore, opinion words translation in opinion sentences is particularly important. In our 
project’s first year, we purpose a translation disambiguation method using the feature-opinion 
association and dependency distance for opinion word translation. In the second year, we 
integrate our cross-lingual information retrieval system and the above developed components to 
construct a cross-lingual travel opinion search system.  
研究計畫前言與目的 
The development of Web 2.0 has made it easier for internet users to post their reviews or 
comments about products or services on structured websites. Online shoppers are increasingly 
likely to look at these reviews before deciding on a purchase. In recent years, the research field 
of sentiment analysis has focused on analyzing this form of textual-information, particularly 
opinions or sentiments expressed by internet users. 
However, given the international nature of the web and online shopping, opinions in a user’s 
mother language may not be available. Translation of online customer reviews is therefore an 
important service sought after in many markets. A crucial aspect of customer review translation 
is translating opinion words, key words that capture the sentiments. At present, machine 
translation (MT) systems can translate whole sentences or even complete paragraphs. This not a 
trivial task, however, because opinion words usually have multiple possible translations and the 
MT systems have low accuracy on polysemous words [1]. 
This project proposed an unsupervised method of selecting the most appropriate Chinese 
translation for an opinion word in a given Japanese sentence. Candidate translations are retrieved 
from a bilingual dictionary. Consider the following Japanese sentence: 
 綺麗な夜景とともに食事を楽しむことができました。 
 (I was able to enjoy a nice meal with a beautiful night view.) 
The target opinion word 綺麗 has three candidate translations: 漂亮 (beautiful), 乾淨 (clean), 
and 清楚 (clear) in Chinese. In this example, the most appropriate translation is 漂亮 (beautiful). 
This disambiguation problem is known as Word Translation Disambiguation (WTD). 
One way to solve the WTD problem is to calculate the sum of association scores of pairs among 
translation of the target word and all its surrounding words’ translations, and then select the one 
with the highest score. However, since the different surrounding words have different amounts of 
influence on the target word, it is necessary to add some weighting factors (e.g., word distance). 
Since our goal is disambiguating opinion words in opinionated sentences, the product features 
(or aspect expressions) should have direct influence on translation selection. In the above 
example, 夜景 (night view) and食事 (meal) are product features, the former having the greatest 
influence on the opinion word綺麗 (beautiful). 
The experimental results show that our weighting factors have significantly improved translation 
accuracy. Compared to Google Translate and Excite translation system, our system can translate 
opinions more accurately, which could be a boon for Chinese online shoppers seeking 
accommodations in Japan.  
研究方法 
We introduce our method for selecting the translation of a given opinion word in a sentence in 
this section. The procedure consists of six parts: (1) related word extraction, (2) related word 
translation, (3) translation corpus, (4) Japanese dependency analysis, (5) related product feature 
identification, and (6) word translation disambiguation scoring method. The procedures are 
described in detail in the following sections. 
1 Related Word Extraction 
We use the following procedure to extract nearby words related to the target word: First, the test 
sentences are analyzed by a Japanese part-of-speech (POS) and morphological analyzer, MeCab 
[12]. The MeCab output contains not only the segmented words with POS tags but also detailed 
information on the katsuyou form, root form, and pronunciation of each word. The katsuyou is 
the inflection of the yougen (a verb, an adjective, or an auxiliary verb). According to its tense and 
voice, the yougen may have different inflections. For example, 美味しい (delicious) should 
inflect to美味しかった in the past tense and美味しくない (not delicious) in the negative. 
However, dictionaries usually do not include all these inflections. So we use the root forms 
instead of the original segmented words in subsequent processing steps. 
Table 1 – Japanese Compound Combination Rules 
noun → noun-verbal | noun-common | noun-proper-misc 
prefix → prefix-nominal 
suffix → noun-suffix-misc 
noun' → noun' + noun | noun + noun 
comnoun → prefix + noun + suffix | prefix + noun' | noun + suffix | noun' + suffix | noun' 
comadj → verb-main + adjective-sub 
location → noun-proper-place-misc + noun-suffix-place 
comword → comnoun | comadj | location 
 
comadj: compound adjective 
comnoun: compound noun 
comword: compound word 
In addition, we found one difficulty using MeCab: due to the annotation standards of its   
training corpus, MeCab sometimes treats one compound or loanword as many morphemes.   
For example, 従業員(staff) is separated into従業(work) and員(member), and the loanword エ
ントランス(entrance) is separated intoエン (dollar) andトランス (transformer). In both cases, 
the original meaning is lost. To solve this problem, we apply the Japanese compound 
combination rules shown in Table 1. Most of these morphological rules are based on POS tags. 
3 Translation Corpus 
We compiled our translation corpus from snippets returned by Google Search for conjunctive 
queries of word pairs. These snippets provide useful clues related to the semantic relations that 
exist between two words. First, we take Chinese word pairs in which one word is a candidate 
translation of the target word and the other is a translation of a related word. Then, we submit 
each word pair joined by the Boolean operator “AND” to Google Search and collect the first 500 
snippets for our text corpus. 
4 Japanese Dependency Analysis 
In order to obtain the dependency distance between the target word and a related word, we use 
CaboCha, a Japanese dependency structure analyzer based on Support Vector Machines (SVMs) 
and the most accurate publicly available system to date, with a reported accuracy of 89.29% [14]. 
CaboCha uses a parsing algorithm based on the Cascaded Chunking Model. 
 
Figure 1 – An example of Japanese dependency parsing 
The basic syntactic unit used in Japanese parsing is the bunsetsu, which consists of one or more 
words followed by either nothing or function words such as particles and auxiliary verbs. 
Figure 1 shows an example of Japanese dependency parsing for a sentenceお部屋の照明の照度
は大変明るいです！ (The illumination of the lighting of the room is very bright!). In this 
example sentence, we first find the last node which contains the target word明るい (bright). 
Then we calculate all dependency distances from other nodes which contain a related word. For 
example, the distance from the target word’s node to the third node containing the related word 
照度 (illumination) is one and the distance to the second node containing照明 (lighting) is two. 
5 Related Product Feature Identification 
In opinionated sentences, opinion words often describe product attributes or features, such as 
cleanliness, staff attitude, food quality, etc. in the hotel domain. We believe that considering the 
product feature(s) related to the target opinion word is helpful for disambiguation of the opinion 
word. To implement this feature, we enumerated product features3 for the hotel domain. 
6 Word Translation Disambiguation Scoring Method 
This section describes the word translation disambiguation scoring method. Assume the target 
                                                      
3 The product feature list is available at http://iisr.cse.yzu.edu.tw/~guohau/coling/feature.list 
お部屋の
(of the room)
照明の
(of the lighting)
照度は
(the illumination)
大変
(very)
明るいです！
(is bright)
and t'2,k, if AssociationT (t, t'1,j) is greater than AssociationT (t, t'2,k) and AssociationS (o, s1) is 
greater than AssociationS (o, s2), but AssociationT (t, t'1,j) and AssociationT (t, t'2,k) are both 
negative (PMI score), AssociationT (t, t'1,j) * AssociationS (o, s1) is not guaranteed to be larger 
than AssociationT (t, t'2,k) * AssociationS (o, s2). Such a result is not appropriate for our 
application here. 
To solve this problem, PMI is mapped to an exponential function where the value is always 
positive, which is defined as: 
( , )( , ) PMI t tExpPMI t t e
                              (3) 
6.2 Association Score between the Opinion Word and Related Words in the Source 
Language 
We aim to determine the translation of an opinion word by scoring its association to its related 
words in the source language. Different related words have different influence on the target word, 
so added weighting factors are necessary. There are two factors that we consider: dependency 
distance and feature-opinion association. 
Distance weighting has been used in several studies [16-18] as a means of estimating the 
association between two words. The exponential model, in which association between two words 
decreases exponentially when the distance between them increases, is a commonly used 
approach. We employ Beeferman et al. [16]’s distance weighting approach. Therefore, the 
association score of o and si is defined as: 
( , )( , ) idistance o sS iAssociation o s e
                          (4) 
where distance(o, si) is the dependency distance (see Section 4 for the details) between o and si; 
and μ is the parameter for decay rate determined by maximum likelihood estimate: 
2
0
1log 1 , [ ] ( )
[ ] p kp
E k kp k
E k


                              (5) 
where )(
~ kp is the probability of the distance between o and si being k. 
Since our goal is disambiguating opinion words in opinionated sentences, we should give 
product-feature words more influence on the translation selection than normal words. To do this 
automatically, we modify Formula 4 by introducing the feature-opinion association (FOA) score, 
which is defined as: 
結果與討論 
We conducted experiments with our Japanese hotel review corpus to empirically evaluate the 
translation accuracy of our WTD scoring method using different sets of weighting factors and the 
modified PMI formula. We also compared our system’s performance to that of Google Translate 
and the Excite translation system. 
Dataset 
Our dataset consists of 956,892 reviews of 15,291 hotels from the Rakutan Travel website4, the 
largest hotel-booking/review website in Japan. The sentences are segmented and duplicate 
content is removed. After processing, the dataset contains 4,341,266 sentences. We also use this 
data to create the product feature list. 
Experiment Design 
We selected the top-10 most common polysemous opinion words and annotated each of their 
occurrences in the dataset with their translations. For each of the ten opinion words, we 
constructed test examples by randomly selecting 1,200 sentences from the dataset. Each test 
example contains only one opinion word. The ground truth of each translation was assigned by 
two human annotators. Statistics for the gold standard dataset are presented in Table 3. 
Table 3 – Statistics for the gold standard dataset 
Word #Sense #Instance Avg length Min length Max length 
明るい (bright) 2 992 36.3 7 135 
甘い (sweet) 2 808 40.3 7 145 
暖かい (warm) 2 979 41.6 6 147 
丁寧 (polite) 2 1,057 37.9 11 125 
冷たい (cool) 2 957 44.0 6 174 
薄い (thin) 2 1,041 38.3 6 141 
綺麗 (beautiful) 3 736 35.2 9 113 
きつい (tiring) 3 755 41.9 10 136 
寂しい (lonely) 3 794 38.7 8 120 
厳しい (strict) 4 506 45.0 7 141 
Avg. 2.5 862.5 39.9 7.7 137.7 
As shown in Table 3, our gold standard dataset contains a total of 8,625 test examples with an 
average of 2.5 senses per word. The average length of the test examples is 39.9 Japanese 
characters. 
                                                      
4 http://travel.rakuten.co.jp/ 
Compared with the online translation systems, Table 4 shows our system outperforms Excite and 
Google for opinion word translation. The two online translation systems perform even worse 
than MFS on average. 
Table 4 – Comparison of different translation systems and configurations 
Word MFS Excite Google AT(PMI) AT(PMIExp)
AT(PMIExp) 
+AS(D) 
AT(PMIExp) 
+AS(D+F) 
明るい 0.7323 0.7311 0.6460 0.8656 0.9067 0.9198 0.9212 
甘い 0.7679 0.7679 0.7291 0.8062 0.8431 0.8608 0.8876 
暖かい 0.5234 0.4766 0.7103 0.6685 0.7988 0.8183 0.8600 
丁寧 0.8284 0.0439 0.7854 0.5045 0.8287 0.8679 0.8711 
冷たい 0.9098 0.9119 0.6790 0.9382 0.9119 0.9210 0.9386 
薄い 0.9033 0.9033 0.8198 0.8734 0.9088 0.9293 0.9549 
綺麗 0.4845 0.5313 0.5408 0.7341 0.7804 0.7875 0.7889 
きつい 0.5436 0 0.0408 0.6563 0.7458 0.7649 0.7729 
寂しい 0.5275 0.1157 0.0725 0.6263 0.6201 0.6352 0.6666 
厳しい 0.4886 0.4846 0.2039 0.5571 0.5592 0.6026 0.6209 
micro 0.6932 0.5102 0.5622 0.7327 0.8081 0.8280 0.8456 
macro 0.6709 0.4966 0.5227 0.7230 0.7903 0.8107 0.8283 
In addition, we performed a two-tailed paired T-test on the average accuracies of different 
weighting factors. The T-test results in Table 5 show that different weighting factors can have a 
statistically significant impact (bold text results) on system performance. 
Table 5 – T-tests on the average accuracies of different weighting factors 
Word AT(PMIExp)
AT(PMIExp)
+AS(D) 
T-test 
p-value 
AT(PMIExp)
+AS(D) 
AT(PMIExp) 
+AS(D+F) 
T-test 
p-value 
明るい 0.9067 0.9198 1.86E-24 0.9198 0.9212 0.00886 
甘い 0.8431 0.8608 2.33E-25 0.8608 0.8876 7.05E-33 
暖かい 0.7988 0.8183 3.15E-23 0.8183 0.8600 6.85E-34 
丁寧 0.8287 0.8679 3.16E-34 0.8679 0.8711 2.51E-06 
冷たい 0.9119 0.9210 7.07E-16 0.9210 0.9386 1.42E-26 
薄い 0.9088 0.9293 2.03E-29 0.9293 0.9549 3.5E-36 
綺麗 0.7804 0.7875 9.85E-10 0.7875 0.7889 0.120067 
きつい 0.7458 0.7649 2.77E-20 0.7649 0.7729 1.16E-13 
寂しい 0.6201 0.6352 7.97E-21 0.6352 0.6666 4.46E-35 
厳しい 0.5592 0.6026 3.16E-30 0.6026 0.6209 1.02E-26 
micro 0.8081 0.8280 1.63E-38 0.8280 0.8456 2.33E-40 
macro 0.7903 0.8107 2.62E-38 0.8107 0.8283 2.31E-39 
 
跨語旅遊
In this se
this syste
select one
When use
search cri
意見搜尋系
ction, we d
m shows th
 location a
rs click the
teria. 
統 
escribe our
e hotels rec
nd one room
 search but
 cross-lingu
eived lates
 type as th
ton, the sys
al travel op
t comment
eir search c
tem will p
inion searc
s. Users are
riteria. 
resent a ran
h system. T
 allowed to
ked list of 
he entranc
 input keyw
hotels that 
e page of 
ords and 
match the 
參考文獻 
1. Carpuat, M. and D. Wu. Evaluating the Word Sense Disambiguation Performance of 
Statistical Machine Translation. in Proceedings of the 2nd International Joint Conference 
on Natural Language Processing (IJCNLP 2005). 2005. Jeju Island, Korea. 
2. Marsi, E., et al. Word Translation Disambiguation without Parallel Texts. in Proceedings 
of the International Workshop on Using Linguistic Information for Hybrid Machine 
Translation (LIHMT 2011). 2011. Barcelona, Spain. 
3. Chklovski, T., et al. The SENSEVAL-3 Multilingual English-Hindi Lexical Sample Task. 
in Proceedings of the third International Workshop on the Evaluation of Systems for the 
Semantic Analysis of Text (SENSEVAL-3). 2004. Barcelona, Spain. 
4. Jin, P., Y. Wu, and S. Yu, SemEval-2007 Task 5: Multilingual Chinese-English Lexical 
Sample, in Proceedings of the 4th International Workshop on Semantic Evaluations 
(SemEval 2007)2007, Association for Computational Linguistics: Prague, Czech 
Republic. p. 19-23. 
5. Lefever, E. and V. Hoste, SemEval-2010 Task 3: Cross-lingual Word Sense 
Disambiguation, in Proceedings of the 5th International Workshop on Semantic 
Evaluation (SemEval 2010)2010, Association for Computational Linguistics: Los 
Angeles, California. p. 15-20. 
6. Ng, H.T., B. Wang, and Y.S. Chan, Exploiting Parallel Texts for Word Sense 
Disambiguation: An Empirical Study, in Proceedings of the 41st Annual Meeting on 
Association for Computational Linguistics (ACL 2003)2003, Association for 
Computational Linguistics: Sapporo, Japan. p. 455-462. 
7. Chan, Y.S. and H.T. Ng, Scaling Up Word Sense Disambiguation via Parallel Texts, in 
Proceedings of the 20th National Conference on Artificial Intelligence (AAAI 2005)2005, 
AAAI Press: Pittsburgh, Pennsylvania. p. 1037-1042. 
8. Dagan, I. and A. Itai, Word Sense Disambiguation Using a Second Language 
Monolingual Corpus. Computational Linguistics, 1994. 20(4): p. 563-596. 
9. Tsunakawa, T. and H. Kaji. Augmenting a Bilingual Lexicon with Information for Word 
Translation Disambiguation. in Proceedings of the 8th Workshop on Asian Language 
Resources (ALR 2010). 2010. Beijing, China. 
10. Liu, P. and T. Zhao. Unsupervised Translation Disambiguation Based on Maximum Web 
Bilingual Relatedness: Web as Lexicon. in Proceedings of the 6th International 
Conference on Fuzzy Systems and Knowledge Discovery (FSKD 2009). 2009. Tianjin, 
China. 
11. Liu, P., et al. Minimum Normalized Google Distance for Unsupervised Multilingual 
Chinese-English Word Sense Disambiguation. in Proceedings of the 4th International 
Conference on Genetic and Evolutionary Computing (ICGEC 2010). 2010. Shenzhen, 
China. 
 國科會補助專題研究計畫成果報告自評表 
請就研究內容與原計畫相符程度、達成預期目標情況、研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）、是否適
合在學術期刊發表或申請專利、主要發現或其他有關價值等，作一綜合評估。
1. 請就研究內容與原計畫相符程度、達成預期目標情況作一綜合評估 
■達成目標 
□未達成目標（請說明，以 100 字為限） 
□實驗失敗 
□因故實驗中斷 
□其他原因 
 
2. 研究成果在學術期刊發表或申請專利等情形： 
論文：■已發表 □未發表之文稿 □撰寫中 □無 
專利：□已獲得 □申請中 ■無 
技轉：□已技轉 □洽談中 ■無 
其他：（以 100 字為限） 
 
3. 請依學術成就、技術創新、社會影響等方面，評估研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）（以
500 字為限） 
本計畫主要提出利用特徵意見關聯（Feature-Opinion Association）與相依距離
（Dependency Distance）的翻譯消歧方法，並以日本旅遊住宿評論為例，將方法
應用在跨語意見探勘中最關鍵的意見詞翻譯上，其成果已發表至自然語言處理與
計算語言學 top conference COLING 2012 並被接受。另外，由實驗結果顯示，本
計畫所提出的翻譯消歧方法，其翻譯正確率皆比三組基準值包含常用的線上翻譯
系統較好。藉由使用本計畫提出的跨語旅遊意見搜尋系統，使用者可以更瞭解這
些日文評論的內容，對於華人在自助旅遊收集與整理所要的資訊，能夠節省相當
大的時間成本。 
 
  
國科會補助計畫衍生研發成果推廣資料表(二) 
日期： 102 年 1 月 31 日 
國科會補助計畫 
計畫名稱：網際網路意見探勘、摘要與翻譯技術之研發－以 
中日／中韓跨語旅遊意見搜尋系統之建構為例 
計畫主持人：蔡宗翰 
計畫編號：NSC 99-2628-E-155-004 領域：WEB 技術 
研發成果名稱 
（中文）利用特徵意見關聯與相依距離的翻譯消歧方法 
（英文）Word Translation Disambiguation Method Using 
Feature-Opinion Association and Dependency Distance 
成果歸屬機構 元智大學 發明人 (創作人) 蔡宗翰 
技術說明 
評論文章中意見詞的翻譯，對於使用者了解其相關資訊相當重
要。以往機器翻譯的技術可分為規則式與統計式兩種，然而規則
式方法很難去完全的包含所有的規則，統計式則因需要依賴語料
庫，先行準備工作繁雜且翻譯準確度也未必較佳。本計畫提出非
監督式日文意見詞翻譯方法，並利用線上辭典和語料，透過特徵
詞與意見詞在評論句中共同出現的情況與其他資訊來判斷評論句
中最關鍵的意見詞詞義。 
The opinion word translation is very important for users to understand 
the product reviews. Recently, the machine translation technology can 
be divided into rules-based and statistical method. However, 
rules-based method is difficult to contain all the rules completely, 
statistical method needs a pre-prepared training corpus and the 
precision is not always good. Our research proposes a Japanese 
opinion word translation method based on unsupervised word sense 
disambiguation. The method only needs a well-made online bilingual 
dictionary, then uses co-occurrence of product features and opinion 
words and other features to deter¬mine the word sense in opinioned 
sentence. 
產業別 資訊擷取、意見探勘等自然語言處理領域 
技術/產品應用範圍 將評論文章中特徵詞與意見詞擷取出來，再利用非監督式詞義消歧演算法，翻譯出正確的意見詞詞義。 
技術移轉可行性及預期
效益 
利用此技術不只可以翻譯日文評論文章中的意見詞，在未來甚至
可搭配意見探勘領域的特徵詞與意見詞配對，讓華人在閱讀以外
語撰寫的評論文章時，能夠更加了解其內容。 
註：本項研發成果若尚未申請專利，請勿揭露可申請專利之主要內容。  
三、考察參觀活動(無是項活動者略) 
無。 
四、建議 
政府近年來加強在國際能見度以及國內學術研究與國際間之交流接軌，對於跨國合作、
爭取國際會議在臺灣舉辦等推行不少政策，然而台大雖曾爭取此次 ACL 舉辦權但仍然
未能獲取，實在可惜。實際參加此次韓國主辦單位，其環境與舉辦方式顯得樸素且簡單，
臺灣相較其他國家雖較少有舉辦國際會議之經驗，然而此次主辦情況與台灣國內會議舉
辦情況相較，其實台灣學術單位已具有相當能力可以爭取國際頂尖會議來台舉辦，或許
往後能結合國內各單位之力量，盡力爭取諸如 ACL 此類國際頂尖會議來台舉行，一方
面便利我國研究學者、學子能以最低的成本參加頂尖會議，一方面也能使我國於國際上
的能見度提昇，此外也能夠吸引世界知名學者前來，促使我們的學研能有更好的發展。 
五、攜回資料名稱及內容 
ACL 2012 論文集。 
六、其他 
無 
 
100年度專題研究計畫研究成果彙整表 
計畫主持人：蔡宗翰 計畫編號：100-2628-E-155-001- 
計畫名稱：網際網路意見探勘、摘要與翻譯技術之研發－以中日／中韓跨語旅遊意見搜尋系統之建構
為例(2/2) 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 3 3 100%  
研究報告/技術報告 0 0 100%  
研討會論文 3 3 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 1 1 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 1 1 100% 
人次 
 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
