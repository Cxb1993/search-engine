Bandwidth Allocation (DBA) mechanism is a critical 
issue in an optical multi-service network 
environment. In order to solve the above issue, we 
proposed a project to develop an algorithm to improve 
performance. First, we have designed an optimal 
algorithm to improve performance indexes in terms of 
(I) bandwidth utilization and (II) packet delay. 
Second, some existing optimal algorithms in terms of 
(III) fairness and (IV) QoS will furthermore be 
integrated with the designated algorithm. The 
finished results are (1) A completely integrated DBA 
algorithm, (2) An EPON simulation model in an open 
source and reliable network simulator, (3) Measure of 
the  improvement of the proposed DBA algorithm in a 
simulated multi-service environment, (4) Report 
writing and paper publication.  
This project is based on our previous work on the NSC 
project (NSC97-2221-E-006-142), and we expect that 
the results of this project would provide significant 
advance to the system design of EPON. We also believe 
that the results of this project could provide good 
insights in the QoS designs of EPON systems. Students 
who are involved in this project will also develop 
excellent experiences in optical access system 
research. 
 
英文關鍵詞： Dynamic Bandwidth Allocation (DBA), Ethernet Passive 
Optical Network (EPON), Quality of Service (QoS), 
Optical Line Termination (OLT), Optical Network Unit 
(ONU). 
 
摘要 
近年來隨著網路使用人數快速增加，多媒體的網路服務需求也隨之增高，現行網路架構所提供的頻寬
已逐漸不敷使用，因此發展下一世代的網路架構已成為目前重要的研究議題，以光網路為主軸的新世
代網路，可分為(1)核心網路(Core Networks)與(2)接取網路(Access Networks)，本研究著重於探討光接
取網路，新世代光接取網路將可提供更大的頻寬，此網路架構稱為被動光網路(Passive Optical Networks 
- PON)，PON 是一種全新的光纖到府(FTTH)概念，使用者在家可直接透過光纖連結至光核心網路，大
幅提升使用者端的頻寬，近年又以乙太被動光網路(Ethernet PON - EPON)最為看好，由於光纖網路獨
特的高頻寬以及快速傳輸特性，若沒有一個支援服務品質的動態頻寬配置機制，將無法因應未來的光
多重服務應用。  
為解決上述問題，本計畫設計了一個全方位整合的動態頻寬配置演算法來全面提升 EPON 在各指標上
的效能，首先針對效能指標(I)頻寬利用率(Bandwidth Utilization)和(II)封包延遲(Packet Delay)最佳化演
算法。其次整合效能指標(III)公平性(Fairness)及(IV)服務品質(QoS) 於最佳演算法。計畫成果為(1)一
個全方位整合的動態頻寬配置演算法，(2)在一個開放且公信的網路模擬器上建立 EPON 模型，(3)模
擬多重服務環境來量測所設計演算法的改善幅度，(4)撰寫研究報告及發表論文。由於本計劃是構築於 
本人過去於光接取網路保護架構設計(NSC97-2221-E-006-142)之經驗與成果，我們相信本計劃的研發
成果可以提供 EPON 系統於多重服務品質議題的創見與洞悉力，並對光接取網路的研究產生重大的進
展與影響。所有參與學生也將會於相關的光接取網路系統發展上有很好的研發經驗。 
 
關鍵詞：動態頻寬配置，乙太光被動網路, 服務品質，光終端設備，光網路元件 
 壹、 報告內容 
一、 前言 
為了滿足快速增加的網路服務需求，研究人員已經研發了一種可大幅度改善頻寬利用度的被動式
光纖網路(PONs)架構，PON 通常由分時多工(Time Division Multiple, TDM)或分波多工(Wavelength 
Division Multiple , WDM)這兩種機制所建構。而由於 TDM-PON 機制相較於 WDM-PON 機制較節省建
構成本而受到網路營運商的喜愛。目前已經有多種的 TDM-PON 標準被提出，像是 Asynchronous 
Transfer Mode(ATM) PON [1]、Broadband PON [2]和 Ethernet PON(EPON)。由於今日乙太網路(Ethernet)
的盛行，使得 EPON 在部署上非常容易，因此被大量的研究與實作。圖 1 顯示了 EPON 的架構，當
OLT 執行下傳傳輸時會透過分光器(optical splitter)將封包廣播給所有的 ONU，而 ONU 會根據封包的
標頭資訊來判斷攫取或丟棄此封包。而當 ONU 執行上傳傳輸時則利用 TDM 機制來避免在傳輸個別資
料時發生碰撞。 
 
圖 1 EPON 架構 
固定式頻寬分配(Fixed Bandwidth Allocation , FBA)演算法由於可能會讓某些處於低頻寬需求的
ONU 得到過多的頻寬而造成頻寬浪費，因此被視為一種不具效率的演算法。因此，藉者由 Multiple Point 
Control Protocol(MPCP) 所支援的動態頻寬分配 (Dynamic Bandwidth Allocation, DBA)演算法由於可
更彈性的使用頻寬，因此在近幾年來越來越受到重視。 
下圖 2 為第一個 EPON DBA 演算法 Interleaved Polling with Adaptive Cycle Time (IPACT)[7]-[8]，
利用一個 Interleaved Polling 的機制來排程所有 ONU 的上傳時間，在一個 ONU 的連續兩個上傳時槽
之間，OLT 會安排讓其他所有 ONU 上傳，若加總其他所有 ONU 的上傳時間夠長，就可以減少甚至消
除此 ONU 的 idle 時間(包含 DBA 演算法計算時間與 round trip delay)。在[7]-[8]中提出了 IPACT 的不
A. Excess bandwidth redistribution: 
Excess bandwidth redistribution 演算法中分配頻寬的方式為考慮所有 ONU 的頻寬需求，即可將
light-load ONU(頻寬需求小於保證頻寬)的多餘頻寬重新分配給 heavy-load ONU(頻寬需求大於保證頻
寬)，因此若有充足的多餘頻寬，便可讓 heavy load ONU 的 queue size 維持在一個可以可接受的大小。
此種演算法雖然可以在不影響最大 cycle time 的情況下更有效的分配頻寬，但卻因為 OLT 必須等收集
到所有 ONU 的 report 後才能作 DBA 演算法來分配上傳頻寬，造成 upstream channel 有一段時間沒有
ONU 在上傳封包，造成頻寬浪費，此段浪費的時間稱為 idle time。 
B. Early allocation-dynamic bandwidth allocation: 
為了解決 idle time 的問題，文獻[11]提出了一個稱為 Early Allocation (EA)的排程方式。其排程方
式為 OLT 會提早分配頻寬給 light-load ONU 讓其提早上傳以減少 idle time。而 EA 所使用的頻寬分配
演算法 DBA1 是將 light-load ONU 的剩餘頻寬加總後根據 high-load ONU 的 request 以比例的方式分
配。圖 4 顯示了 EA-DBA1 的作法。然而，雖然讓 light-load ONU 提早上傳，但若 light-load ONU 上傳
時間不夠長，還是無法完全解決 idle time問題。此外，由於DBA1設計過於簡單以致於可能讓 heavy-load 
ONU 拿到超過其 request 的頻寬，造成頻寬利用度下降。因此在文獻[12]-[13]提出的 EDSA1 演算法在
頻寬分配前增加了一個檢查步驟來避免這種情況。另外，為了符合 EA 特性，ONU 的上傳順序無法固
定，因此可能會影響到 jitter performance。 
 
圖 4 EA-DBA1 
C. Improved allocation-dynamic bandwidth allocation: 
在文獻[14]-[15]中，為了改善 EA-DBA1 仍會有的 idle time 問題，提出了一個演算法 IEA-DBA1，
IEA-DBA1比起EA-DBA1不同處在於OLT除了提早分配 light-load ONU的頻寬外，若在 light-load ONU
上傳時間太少無法完全消除 idle time 時，OLT 會將一些 heavy-load ONU 也提早分配，藉此消除 idle 
time。如圖 5 所示，在 light-load ONU(e.g. ONU1)被提早分配頻寬後，由於尚有 idle time 存在，因此
heavy load ONU(e.g. ONU 0)也被提早分配頻寬，由於 OLT 尚未收到所有 ONU 的 report，因此被提早
分配的 heavy load ONU 只能拿到保證頻寬。然而，IEA-DBA 雖然可以藉者犧牲某些 heavy-load ONU
得到多餘頻寬的機會來消除 idle time，卻依然無法解決因 ONU 上傳順序不固定而 jitter performance 受
影響的問題 
E. 研究動機 
圖 7 根據 scheduling timing 和其所採用的頻寬分配機制將先前提到的 DBA 作分類，線連接的兩端
分別代表在前面介紹過的排程機制與其所使用頻寬分配機制。 
Bandwidth 
allocation
Reference
Limited service [7][8]
DBA1 [11]
EPON dynamic 
scheduling algorithm 
1
[12][13]
Weighted round 
robin variations
[18][19]
[20]
Proposed
Elastic weighted granting
Reference Scheduling timing
[7][8] Interleaved polling
[9] Interleaved polling 
with stop
[11] Early allocation
[14][15] Improved early 
allocation
[16][17] Double-phase polling 
algorithm
Proposed
Fitting scheduling timing
 
圖 7:參考文獻概要 
在本研究中，假設為了簡化設計所以目前的 ONU 不採用 traffic shaper，且時間複雜度 O(N2)是不
可被接受的，此外，IEA 被視為比 EA 好，而 EDSA1 則被視為比 DBA1 好。根據以上假設，在排程
機制中只有 IPACT、IEA 和 DPA 符合需求，而在頻寬分配機制中只有 Limited 和 EDSA1 符合需求。
為了清晰的證明本研究所提方法(FST-EWG)之貢獻，將 FST-EWG 與 IPACT-Limited、IEA-EDSA1 和 
DPA-EDSA1 拿來與本研究所提出的方法作比較。 
本研究提出的 Fitting Scheduling Timing (FST)是用來決定 OLT 執行上傳頻寬分配機制的時機和排
程所有 ONU 的上傳時間，必須達到以下三項目標: 
1. 維持所有 ONU 的上傳順序。 
2. 讓 OLT 盡可能收集越多來自 ONU 的 report 訊息再處理。 
3. 盡可能消除 idle time 
同樣的，為了有效的分配上傳頻寬，Elastic Weighted Granting (EWG)必須達到以下五項目標: 
1. 藉由限制 cycle time 長度來確保平均封包延遲不會過久。 
2. 避免惡意使用者連接的 ONU 霸佔上傳頻寬，讓上傳頻寬可以被正常的 ONU 使用。 
3. 將 light-load ONU 的剩餘頻寬分配給 high-load ONU 使用以避免因 MPCP message 與 guard 
time 等 overhead 比例的增加所造成的 short cycle time problem。 
4. OLT 分配給每個 ONU 的上傳頻寬不可超過該 ONU 的頻寬要求。 
5. 上傳頻寬分配的計算不能過於複雜，必須能夠維持在 O(N)。 
 
 
要達到在研究動機小段提到的三項目標。要達成第一項目標不困難，只要 OLT 排程 ONU 時維持其上
傳順序不改變即可，這樣可讓一個 ONU 的兩次上傳之間都間隔了另外 N-1 個 ONU 的上傳，藉此來維
持 jitter performance。當考慮到第二項目標時，最理想的情況為當 OLT 收到自所有 ONU 的 report 
message 後才執行 DBA 演算法，但此種排程方式執行 DBA 演算法的時間點就會和文獻[9]中的 IPS 很
相似，因此也會產生和 IPS 相同的 idle time 問題，如圖 8 所示，而這段 idle time 可用公式(1)來表示。 
 
1
idle begin end
s s
DBA guard GATE process
T t t
T T RTT T T
 
       (1) 
end
st 1
begin
stschedule
sT 1
schedule
sT
schedule
sT
 
圖 8 上傳頻寬分配所產生的 idle time 示意圖 
從公式(1)可發現若要等收集到所有 ONU 的 report message 後才作 DBA 演算法會造成很長的 idle 
time，因此違反第三項目標(盡可能消除 idle time)。為了可以同時達成第二項與第三項目標，必須找出
一次處理多少個 ONU 的 report 最適合。若 OLT 一次處理 m 個 ONU 的 Report message 訊息(0<m<N)，
而處理這 m 個 report message 所產生的 idle time，理論上可藉由另外 N-m 個 ONU 在這段時間上傳封包
來減少。但若要完全消除此 idle time，就必須要有足夠的 N-m 個 ONU 在這段時間上船封包。因此 m
越小，idle time 就越容易被消除，但若 m 越大，則更有機會有效的分配頻寬。 
因此，在有效分配頻寬與消除 idle time 之間有個權衡在，這兩點對於 upstream bandwidth utilization
的影響如下: 
1. Idle time 上升問題:當 m 自 1 增加到 N-1，想藉由另外 N-m 個 ONU 上傳封包來完全消除 idle
可能性就越低，因此剩餘的 idle time 會造成 upstream bandwidth utilization 下降。 
2. Efficiency 下降問題:當 m 自 N-1 減少至 1，由 light-load ONU 產生的剩餘頻寬越無法有效的
分給 heavy-load ONU，如此一來 cycle time 會變短，造成 MPCP overhead 在 cycle time 所佔
的比例增加，因而降低 upstream bandwidth utilization。 
雖然以上兩種情況最後都會造成 upstream bandwidth utilization 下降，但其實狀況 2 的影響與狀況 1 相
比來說較小，因為在狀況 2 中雖然 cycle time 變小會增加 overhead 在其中所佔的比例，但同時也會降
低同一個 ONU 兩次上傳的間隔時間，使得平均上傳 packet delay 下降。因此本研究所提出的 FST 就是
在盡可能不產生 idle time 的前提下想辦法一次多處理一些 ONU 的 report message。 
begin
s
end
s tt 1
LST
st
schedule
sT 1
schedule
sT
schedule
sT
 
(a) 
begin
s
end
s tt 1
LST
st
schedule
sT 1
schedule
sT
schedule
sT
EST
st
 
(b) 
begin
s
end
s tt 1FSTst FSTst 1
REPORT
it REPORTit 1
REPORT
it 2
REPORT
Nit 1
schedule
sT 1
schedule
sT
schedule
sT
 
(c) 
圖 9:排程時間點(a)最晚(b)最早(c)最適合 
在 IPACT-Limited、EA-DBA1、IEA-DBA1 與 DPA-DBA1 等先前介紹的研究中，採用的排程方式
為 OLT 在每個 cycle 中分配固定數量 ONU 頻寬，但在本研究中提出的排程方式 FST，OLT 是採用在
每次排程中分配變動數量 ONU 頻寬的方式。雖然 OLT 在每次排程中分配頻寬的 ONU 數目不固定，
但這些 ONU 的上傳順序還是固定的。我們使用代表 OLT 自開機後所收到的第 i 個 report message 的
編號，另外，由於 ONU 的上傳順序是固定的，因此 也同時可代表根據第 i 個頻寬需求所產生的 GATE
訊息編號。假設在過時間點 FSTst 後收到的第一個 report message 的編號為 i，而在時間點 1
FST
st  之前所收
   max * *grant cycle REPORT guardcycleb T N T T C    (5) 
EWG第二項目標則是避免惡意使用者連接的ONU霸佔上傳頻寬，讓上傳頻寬可以被正常的ONU
使用。為了達成這項目標最直接的作法就是讓OLT為每個上傳Report message的ONU保證一段上傳頻
寬，這樣一來，頻寬要求小於保證頻寬的Report message就一定可以被滿足而不會受到惡意使用者連接
的ONU影響。接下來要決定每個Report message的保證頻寬，由於N個連續的Report message其所得到
的頻寬分配加總一定小於等於 grantcycleb ，因此我們可以合理設定N個連續的Report message其保證頻寬加
總為 grantcycleb ，接下來為了決定
grant
cycleb 分配給每個Report message的比例，我們使用Report message的權重(即
發出此Report message的ONU權重)來作分配比例，所以每個Report message的保證頻寬可以從公式(6)
得到。 
 
*
latest
N
guarantee granti
i cycle
h
h F
w
b b
w

 
 (6) 
公式(5)和公式(6)只需要在 EPON 開始運作的時候計算一次即可而不用在每次排程時都重複計算
一次，這是由於公式(5)和公式(6)所使用的參數 ONU 的總數、最大 cycle time 長度和每個 ONU 的權重
在整個系統執行的時間中是維持不變的。 
另外，由於 OLT 在每次排程中所要處理的 Report message 數量是不固定的，因此在每次排程中可使用
大保證頻寬總和也必需根據在這次 schedule 中會排程到 Report message 數量做調整。因此在第 s 次排
程中的保證頻寬總和為 schedule
s
guarantee
i
i F
b

 。 
接下來，使用下面介紹的三個步驟來簡易說明 EWG 如何在第 S 次排程中公平的分配可用上傳頻寬。 
1. 在第 S 次排程收到的 Report message 中，若 Report message 其 requestib 小於等於
guaranteed
ib ，那麼分
配給發出此 Report message 的 ONU 的上傳頻寬 grantib 就會等於
request
ib ，此 Report message 就被稱
為被滿足的 Report message。 
2. 計算出剩餘頻寬 excessib 。 
3. 將剩餘頻寬按照特定的順序分配給未被滿足的 Report message，且每個 Report message 被分配到
的頻寬不可超過其所要求的頻寬。 
藉者上面介紹的三個步驟，由於剩餘頻寬可以被分配給未被滿足的 Report message，所以可盡可
能地避免 short cycle time problem，因此 EWG 的第三項目標可被達成。接下來利用步驟一與步驟三中
所使用的滿足的 Report message 概念來達成 EWG 的第四項目標(OLT 分配給每個 ONU 的上傳頻寬不
可超過該 ONU 的頻寬要求)，最後，再利用特殊的頻寬分配順序來達成 EWG 的第五項目標(上傳頻寬
分配的計算不能過於複雜，必須能夠維持在 O(N))。 
1. Details of three major steps: 
EWG 的步驟一(Alg.EWG.1)可以總結為以下的式子。 
 
, 0
, , 0
min ,
grantschedule
s i
request request
jschedule schedule grant i
s s j
j i
jgrant request excess
j j s
i
i F b
excess excess grant
s s j
b bif j F i F b
w w
w
then b b b
w
b b b
 
          
      
 

 
另外，當所有 Report message 的頻寬總和小於保證頻寬的總和時，Alg.EWG.3 的頻寬分配結果也
會與分配給每個 Report message 其所要求的頻寬量相同。經過 EWG 步驟一到步驟三，OLT 也就完成
了第 s 次排程的頻寬分配，接者 OLT 會將 EWG 的計算結果透過 Gate message 通知在第 s 次排程的
ONU，並等待下一次排程。 
2. Refinement: 
但其實還有一個可以討論的問題存在，就是在第 s 次排程後尚有剩餘頻寬沒有使用完，這些浪費
的剩餘頻寬會造成 cycle time 變短，使得 MPCP overhead 在 cycle time 的比例也會相對應的變高。在本
研究中，並非所有 ONU 都會在一次排程中被排程，因此在第(s-1)次排程的剩餘頻寬就可以轉讓給第 s
次排程使用，藉此來降低 MPCP overhead 在 cycle time 中的比例。因此我們將剩餘頻寬公式計算修改
成公式(9)。 
 
1
schedule schedule
s s
excess excess guarantee grant
s s i i
i F i F
b b b b
 
   
 (9) 
透過公式(9)，在第 s 次排程中剩餘頻寬可以有效的分配給高頻寬需求的 ONU 使用，但如果網路負載
再經過好幾次排程後還是一直很低，那麼根據公式(9)，剩餘頻的值會被累積到很高，若這被累積到很
高的剩餘頻寬在未來在某次排程中被一次分配出去，會造成很長的 cycle time，使得 packet delay 也被
相對應提高很多。 
為了避免上述的問題，在 EWG 限制了最多可以轉讓給下一次排程使用的剩餘頻寬總量為前 N 個
已經被分配頻寬的 Report message 所產生的剩餘頻寬。因此第 i 個 Report message 所可以繼承到的剩
餘頻寬量可由公式(10)所表示。 
 
 1 , 0iexcess guarantee granti h h
h i N
b max b b

 
      (10) 
再將公式(10)擴展到一次處理 m 個 Report message，也就是說，第 s 次排程可以繼承的剩餘頻寬不
僅僅是第(s-1)次排程的所剩下的，而是可繼承前 N 個已經被分配頻寬的 Report message 所產生的剩餘
頻寬，最後的結果如公式(11)所示。 
 ONU 個數:16 
 Round-trip time:200μs 
 Message processing time:16384ns 
 Guard time:1μs 
 封包大小分布:[25] 
 ONU Queue size:1MB 
 Self-similar packet generation model: Hurst parameter=0.8 
 模擬時間:{30,200}秒 
 模擬程式執行次數:10 
 演算法:IPACT-Limited，IEA-EDSA1，DPA-EDSA1，FST-EWG 
此外， 當使用本計畫提出的演算法(FST-EWG)與其他方法(IPACT-Limited service，IEA-EDSA1，
DPA-EDSA1)作比較時，若改善幅度落在 5% 之內，由於本實驗的模擬次數不夠充足且由於 self-similar 
流量的特性，可以把該幅度認定是統計的誤差。 
A. Average	Packet	Delay:	
圖 10 顯示了四種 DBA 演算法的 average packet delay，當 system load 小於 0.8 時，由於 FST-EWG
演算法相較於其他三種演算法的改善幅度皆小於 0.5%，可說是十分接近。但當 system load 介於 0.8
到 0.95 之間時，FST-EWG 演算法與其他三種演算法比起來就有明顯的改善幅度，這現象是由於當
system load 低時，尚有許多未用到的上傳頻寬可以應付 Burst transmission。另一方面，當 system load
越來越高時，可用上傳頻寬會隨者上傳負載越高而吃緊，如何有效的分配上傳頻寬就變得很重要。可
看出在高 system load 時(load 0.8 到 0.95)FST-EWG 可改善 IPACT-Limited 8%~27%、改善 IEA-EDSA1 
8%~24%、改善 DPA-EDSA1 11%~18%。 
再進一步分析這些模擬結果，首先討論 FST-EWG 對於 IPACT-Limited 的改善幅度，當 system load
從 0.8 增加到 0.95 時其改善幅度都會相對應的增加，但在 system load 從 0.9 到 0.95 這區間中改善的增
幅並不明顯，這是由於 FST-EWG 改善 IPACT-Limited 的主要方式為將頻寬要求較低的 ONU 的剩餘頻
寬分配給頻寬要求較高的 ONU，所以當系統處於高負載情況時，可以分配的剩餘頻寬較少，因此改善
幅度的增幅也就不明顯。 
再來討論 FST-EWG 對於 IEA-EDSA1 的改善幅度，可發現當 system load0.85 以上時改善幅度較明
顯。另外，當負載從 0.85 增加到 0.95 時，IEA-EDSA1 被改善的幅度會先增加然後減少，這主要是由
於 IEA-EDSA1 利用 Early Allocation 機制來消除 idle time，當 system load 較高的時候(i.e. 0.85 到 0.9)，
較多的 heavy load ONU 只會被分到保證頻寬，造成可以被有效分配到剩餘頻寬的 heavy load ONU 數
目減少，當 system load 更高時(i.e. 0.9 到 0.95)，幾乎所有的 ONU 頻寬要求都會大於保證頻寬，所以
只要少數幾個 ONU 被提早分配上傳頻寬就可以消除 idle time，因此剩餘頻寬可以較有效的重新分配。 
Packet dropping probability
0
0.001
0.002
0.003
0.004
0.005
0.006
0.007
0.008
0.009
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
Offered load
IPACT-Limited
IEA-EDSA1
DPA-EDSA1
FST-EWG
Packet dropping prob. improvement
0
0.0005
0.001
0.0015
0.002
0.0025
0.
05
0.
11
0.
16
0.
21
0.
26
0.
31
0.
36
0.
41
0.
46
0.
50
0.
55
0.
61
0.
65
0.
70
0.
76
0.
80
0.
85
0.
90
0.
95
Offered load
FST-EWG : IPACT-Limited
FST-EWG : IEA-EDSA1
FST-EWG : DPA-EDSA1
 
圖 11 Packet dropping probability 
 
C. Qos	consideration:	
由於 jitter performance 與 data packet 沒有明確的相關性，所以許多先前提出的 dynamics 演算法中
並沒有對於 aggregated traffic(資料、影像和聲音)需要的 jitter performance 作出一個完整分析。有些先
前的研究[26]已經解決了 EF traffic 的 jitter performance 問題(在 EF packet delay variation 方面)。本計畫
提出的 FST-EWG 是一種在 OLT 運行的 inter-ONU 排程演算法，而 QoS (Quality of Service)則可以藉者
調整 intra-ONU 排程的方式來達到，假設 FST-EWG 採用 non-strict priority intra-ONU 排程演算法[11]，
由於先前的拿來比較的演算法都沒有考慮 QoS 的問題，因此我們使用一個有名的 multiservice access 
based 的頻寬分配演算法 DBAM[27]作為我們的比較對象。EF packet delay 和 AF packet delay 的模擬結
果顯示在圖 12(a)，可以看出不論是 EF packet delay 和 AF packet delay，搭配 non-strict priority 演算法
的 FST-EWG 都有較好的表現。尤其當 system load 為 0.95 時，FST-EWG 對於 DBAM 的改善幅度在
EF delay 為 128%而在 AF delay 則為 256%。 
改善原因可由以下來說明，在 DBMA 中，由於 self-similar traffic 的 unpredictability 特性可能會造
成 OLT 分配過多的剩餘頻寬給 ONU 造成頻寬浪費以及讓其他 ONU 的 packet delay 上升。而 FST-EWG
則可以藉由 elastic weighted granting 的機制而非預測的機制來分配剩餘頻寬，如圖 12(b)可觀察到，在
system load 從 0.7 到 0.95 的這段區間，由於 DBMA 跟 FST-EWG 比起來有較長的 cycle time，所以造
成其有較長的 packet delay。 
00.5
1
1.5
2
2.5
3
3.5
4
0 5000 10000 15000 20000 25000 30000
Ab
so
lu
te
 va
lu
e o
f E
F d
el
ay
 va
ria
tio
n (
m
s)
packet
EF delay variation
DBAM FST-EWG
 
圖 13 EF delay variation 
藉由調查在 EPON 上的動態頻寬分配演算法，可發現到影響 EPON 效能最顯著的兩個因素為
scheduling timing 和 bandwidth allocation。本計畫提出了一個可以改善 EPON 效能的演算法稱為
FST-EWG，FST-EWG 是基於兩個最主要的概念，分別為利用 FST 機制來消除 idle time，並且利用 EWG 
機制來重新分配剩餘。藉者算出 fitting timing 讓 FST-EWG 可以動態的決定在一次排程中的 ONU 數量
而不是每次都固定排程所有的 ONU 或一半數量的 ONU。而 EWG 則是利用三個主要步驟在每次排程
中公平的分配上傳頻寬給每個 ONU。此外，FST-EWG 的計算複雜度為線性的，可用 O(N)來表示(其
中 N 為 ONU 的個數)。當 FST-EWG 與其他演算法比較時，可發現在 average packet delay 和 average 
dropping probability 上 FST-EWG 比起 IPAC-Limited、IEA-EDSA1 和 DPA-EDSA1 都有較好的表現，而
在 QoS issue 上，FST-EWG 也比 DBAM 表現得更好。 
表格 2 Performance improvement	
FST-EWG improvement IPACT-Limited IEA-EDSA1 DPA-EDSA1 
Average packet delay 8%~27% 8%~24% 11%~18% 
Packet dropping prob. 2.3*10-3 1.2*10-3 9.3*10-4 
QoS improvement FST-EWG vs. DBAM (under load 0.95) 
EF packet delay 128% 
AF packet delay 256% 
EF delay variation 166% 
 
貳、 參考文獻 
[1] Broadband Optical Access Systems Based on Passive Optical Network (PON),” ITU-T, Recommendation G. 983.1, 1998. 
[2] “ONT Management and Control Interface Specification for B-PON,” ITU-T, Recommendation G.983.2, 2000. 
[3] “Gigabit-capable Passive Optical Networks (GPON): General Characteristics,” ITU-T, Recommendation G.984.1, 2003. 
[4] G. Kramer, B. Mukherjee, and G. Pesavento, “Ethernet PON (EPON): Design and Analysis of an Optical Access Network,” 
Photonic Network Communication, vol. 3, no. 3, pp. 307-19, Jul. 2001. 
[5] T. Holmberg, “Analysis of EPONs Under the Static Priority Scheduling Scheme with Fixed Transmission Times,” IEEE 
Conference on Next Generation Internet Design and Engineering (NGI), pp. 192-199, Apr. 2006. 
[6] IEEE Std 802.3ah, IEEE Standard, 2004. 
 參、 計畫成果自評 
1. 本計畫提出的Fitting report position已被IEEE/ACM Transactions on Networking,接受。 
C. C. Sue and H. W. Cheng, "A Fitting Report Position Scheme for the Gated IPACT Dynamic 
Bandwidth Algorithm in EPONs," IEEE/ACM Transactions on Networking, pp.1-14, Apr. 2009. 
2. 本計畫提出的FST-EWG已被IEEE/OSA Journal of Optical Communications and Networking接受。 
Chuan-Ching Sue; Wei-Nung Sung, "Fitting scheduling timing-elastic weighted granting (FST-EWG): 
An EPON DBA algorithm," IEEE/OSA Journal of Optical Communications and Networking, vol.4, 
no.6, pp.468-479, Jun. 2012. 
 
表 Y04 2
11) QoS management 
12) Systems and Software engineering 
13) Wireless and Wireline communications. 
藉由上述相關主題，讓本人吸收不少網路技術以及網路計算相關的資訊、觀念以及應用。 
 
二、與會心得 
藉由參與此次大會，本人從中了解到行動計算以及網路技術等相關研究議題，會議中所
發表的論文偏向於資訊科技應用設計與實作，因此在報告與討論過程中，有許多學者與業界
先進對於報告者提出的架構相當感興趣，並且給予許多的寶貴意見，其中有許多問題，的確
是可以再進一步探討的研究議題，同時由於業界參與的先進也相當多，因此我也得到一些以
實務觀點切入的意見，這些意見也讓我對於系統實作必須考量的問題更加清楚。經由和國外
學者的討論，不僅可以增廣見聞、增加學術涵養亦可以讓自己語言能力提升。這次來到日本
東京，除了參與研討會之外，本人利用一些閒餘時間，欣賞當地的建築特色，瞭解一些歷史
背景，感受到不同的文化。 
感謝國科會計畫補助得以參加此次國際會議，於其間得知學界及產業界對未來網路的見
解與方向，對本人未來研究方向著實有重大的助益。 
 
三、建議 
ICCIT/WASET吸引來自全球各地對資訊相關領域及其相關應用專精或有興趣之學者、專
家齊聚一堂共同研討，進行學術與經驗交流，其會議討論內容包含理論、應用、及實務等議
題，是一個值得參與，可以廣泛吸取電腦科學新知及與國際交流增進視野之會議。但本人有
以下觀察。 
[1] 此次參加研討會，發覺國內參與人數不少，顯見教育部及學校已多有獎勵及補助國內學
者參加國際會議學術交流活動。 
[2] 網路方面的研究成果與應用的不斷推陳出新，因此不論是學界或業界的研究人員都不應
只專注於自身的研究領域，而應多參與類似的國際性研討會，以了解目前最新的研究與
實務動向以及他人的研究成果。 
 
四、攜回資料名稱及內容 
參加本次國際會議共攜回一張光碟，收錄所有發表論文的電子檔。 
 
 
ABSTRACT 
ICCIT/WASET 2012 is an international conference. The refereed conference proceedings 
(ISSN: 2010-3778 reviewed and indexed by Thomson Reuters (ISI), SCIRUS, Google Scholar, 
Engineering Index (Compendex), EBSCO, GALE, DOAJ, INTUTE, ScientificCommons and 
Electronic Journal Library) is internationally distributed both in Electronic CD-ROM and 
Proceedings book. ICCIT 2012 includes a full two-day program of technical sessions. ICCIT 2012 
was held from 29 May to 30 May in Tokyo Tobu Hotel this year. Totally, 278 papers were presented 
in two-day program. Particularly, participants including academic and industry colleague in ICCIT 
表 Y04 4
realized history in Tokyo, Japan and felt different culture. 
I appreciate the support of NSC Project. This project supports me airplane fare, 
accommodation fee, and registration fee. With the chance of attending conference this time I 
learned the opinion and direction of future development. 
4. SUGGESTION 
(1) In this conference, I found that more people are from Taiwan. Hence, our government has 
encouraged and promoted national students or scholars to attend this conference or any 
international conference. 
(2) Network technology and application are frequently updated. Therefore, the researchers have to 
continue upgrading theirs knowledge by attending international conference. 
5. DATA 
A CD-ROM is brought back. 
 
  
  
Abstract—Dynamic bandwidth allocation in EPONs can be 
generally separated into inter-ONU scheduling and intra-ONU 
scheduling. In our previous work, the active intra-ONU scheduling 
(AS) utilizes multiple queue reports (QRs) in each report message to 
cooperate with the inter-ONU scheduling and makes the granted 
bandwidth fully utilized without leaving unused slot remainder (USR). 
This scheme successfully solves the USR problem originating from the 
inseparability of Ethernet frame. However, without proper setting of 
threshold value in AS, the number of QRs constrained by the IEEE 
802.3ah standard is not enough, especially in the unbalanced traffic 
environment. This limitation may be solved by enlarging the threshold 
value. The large threshold implies the large gap between the adjacent 
QRs, thus resulting in the large difference between the best granted 
bandwidth and the real granted bandwidth. In this paper, we integrate 
AS with a cooperative prediction mechanism and distribute multiple 
QRs to reduce the penalty brought by the prediction error. 
Furthermore, to improve the QoS and save the usage of queue reports, 
the highest priority (EF) traffic which comes during the waiting time is 
granted automatically by OLT and is not considered in the requested 
bandwidth of ONU. The simulation results show that the proposed 
scheme has better performance metrics in terms of bandwidth 
utilization and average delay for different classes of packets.  
 
Keywords—EPON, Inter-ONU and Intra-ONU scheduling, 
Prediction, Unused slot remainder.  
I. INTRODUCTION 
THERNET passive optical network (EPON) is a kind of 
access networks. It has some advantages like good 
scalability and low cost, and becomes the potential solution of 
“last mile” [1].  
EPON is formed with an optical line terminal (OLT) and 
several optical network units (ONUs) which are connected by a 
splitter/combiner and optical fibers, namely distribution and 
feeder fibers. The communication between OLT and ONUs is 
clearly defined by multi-point control protocol (MPCP) in IEEE 
802.3ah [2].  
All ONUs use Time Division Multiplexing (TDM) to 
transmit data to OLT in the upstream wavelength. Since each 
ONU has different bandwidth requirement, it’s important for 
OLT to allocate appropriate bandwidth to each ONU for 
transmission. Therefore, dynamic bandwidth allocation 
 
Chuan-Ching Sue* is with the department of Computer Science and 
Information Engineering, National Cheng Kung University, Taiwan (phone: 
886-6-2757575 ext. 62543; fax: 886-6-2747076; e-mail: suecc@ 
mail.ncku.edu.tw).  
Shi-Zhou Chen and Ting-Yu Huang are with master students in the 
DCNLAB, Department of Computer Science and Information Engineering,  
National Cheng Kung University, Taiwan (e-mail: dcnlab@csie.ncku.edu.tw). 
This work was supported in part by the National Science Council, Taiwan, 
R.O.C., under Grant NSC 99-2221-E-006-193-MY2. 
methods became so popular in the past few years [3-6]. 
The unused slot remainder (USR) problem is inevitably 
unavoidable for a high-load ONU. As shown in Fig. 1, the 
granted bandwidth of a high-load ONUi is always smaller than 
its requested bandwidth. Thus ONUi can only transmit packets 
up to the granted bandwidth. Due to the inseparability of an 
Ethernet packet (or frame), the last packet cannot be 
transmitted. The mean value of USR can be derived as 595 
bytes, which leads to the wasted bandwidth utilization [7-8]. 
 Fig. 1 Unused slot remainder problem 
In order to eliminate the USR problem, the active intra-ONU 
scheduling (AS) presented in our previous work [9] utilizes the 
multiple queue reports (QRs) in each report message to 
cooperate with the inter-ONU scheduling. Each QR is set 
according to the different threshold values for different 
priorities of packets. Here three classes of packets, i.e. EF, AF, 
and BE defined in [10] are assumed in this study. Particularly, 
the first queue report is set according to the maximum 
guaranteed bandwidth to avoid the waste of QRs when the 
requested bandwidth is lower than the maximum guaranteed 
bandwidth. In addition, to guarantee QoS, packets of higher 
priorities have smaller threshold values than those of lower 
priorities. In this way, packets of higher priority occupy more 
QRs to increase the possibility to transfer early. While 
inter-ONU scheduling executed in OLT decides the temporary 
granted bandwidth, OLT just choose one QR whose value is 
mostly near and not greater than this temporary granted 
bandwidth. In this way, AS definitely makes the real granted 
bandwidth always equal to the bandwidth request recorded in 
one of QRs. Accordingly, USR is completely eliminated. 
However, without proper setting of threshold value in AS, the 
number of QRs constrained by the IEEE 802.3ah standard is not 
enough, especially in the unbalanced traffic environment. This 
limitation may be solved by enlarging the threshold value. But 
the large threshold implies the large gap between the adjacent 
QRs, thus resulting in the large difference between the real 
granted bandwidth and the best granted bandwidth. 
In this paper, we integrate AS with a cooperative prediction 
mechanism and propose the rules based on the predicted granted 
bandwidth to distribute multiple QRs to avoid generating large 
difference between the real granted bandwidth and the best 
granted bandwidth. 
The remainder of this paper is organized as follows. Section 
Chuan-Ching Sue*, Shi-Zhou Chen, and Ting-Yu Huang 
Active Intra-ONU Scheduling with Cooperative 
Prediction Mechanism in EPONs 
E
World Academy of Science, Engineering and Technology 65 2012
1220
  
waiting time is. After receiving all ONUs’ reports containing 
,i tλ  and ,i tB , OLT can estimate the queue size of all ONUs in 
the next cycle. Then OLT can calculate the temporary granted 
bandwidth based on this information and transmit it as the 
predicted granted bandwidth ,
pre
i tG . Concurrently, for the real 
requests in queue reports (QRs), OLT just performs the normal 
inter-scheduling, like DWRR [11], and directly allocates 
bandwidth ( ,i tG ) to ONUs.  
G
i ,t-1 , G
i,t-1 p
re
G
i,t , G
i,t p
reQ
R
i,
t, 
λ
i,
t
Q
R
i,
t+
1
, 
λ
i,
t+
1
Q
R
i,
t-
1
, 
λ
i,
t-
1
 
Fig. 3 Timing diagram of ASPQR 
As shown in Eq. (1), the queue size of ONUi in the (t+1)-th 
cycle is composed of two parts. One is the size of the packets 
that cannot be transmitted in the t-th cycle, i.e. 
, ,i t i tB G− . 
Second is the size of incoming packets during the waiting 
time ,i tWT , i.e. ,
wt
i tB = , ,i t i tWTλ × . Although there exist some 
method like LSTP in [12] which can directly estimate ,
wt
i tB in the 
ONU, the prediction is prone to errors due to the unknown 
waiting time.  In this paper, we just let ONU estimate the arrival 
rate only according to Eqs. (2)-(4). In this way, the prediction 
error can be reduced since OLT can provide the correct 
,i tWT   
, 1 , , ,
wt
i t i t i t i tB B G B+ = − +  (1) 
                          
, 1 , ,i t i t i tλ α λ+ = ×  (2) 
,
, 1 ,
,
0.5
i t
i t i t
i t
err
α α
λ+
= + ×    (3) 
, , , 1i t i t i t
err λ λ += −  (4) 
Since EF class of packets are assumed to arrive to the queue 
in the constant bit rate (CBR), i.e. the size of EF packets arriving 
during the waiting time is easily obtained, OLT can allocate 
bandwidth in advance to the EF class of packets. Two benefits 
can be achieved accordingly. First, the EF packet delay can be 
reduced. Second, we do not need to waste queue reports for EF 
class of packets. 
B. Predictive Queue Report 
In this paper, we are not meant to propose an error-free 
prediction method. Instead, we adopted the well-established 
prediction methods which are either used in ONU or in OLT. 
Note that there exist error probabilities in these methods. Worse 
than that, the bandwidth allocation is closely related to all 
ONUs not one single ONU. Thus, the error scenarios become 
more complex. In this paper, we proposed a predictive queue 
report to reduce the penalty induced by the prediction errors. 
One REPORT message contains at most 13 Queue Reports. 
ASPQR uses the last two queue reports, i.e., 
, [12]i tQR  
and , [11]i tQR , to record ,i tλ 與 ,i tB , respectively. The remaining 
11 queue reports are set according to , 1
pre
i tG − , ,i tB and
guaranteed
iB . 
When 
,
guaranteed
i t iB B≤ , OLT will certainly allocate 
bandwidth  ,i tB to ONU no matter what value is recorded in the 
multiple queue reports and no USR problem occurs in this case.  
What we concern most is when ,
guaranteed
i t iB B> occurs. In this 
case, the allocated bandwidth could be ,
best
i tG to maximize the 
number of packets to be transmitted if the prediction is correct. 
However, the prediction error is inevitable. So we provide three 
rules considering the relationship among , 1
pre
i tG − , ,i tB , and 
guaranteed
iB . 
Case 1: 
, 1 ,
guaranteed pre
i i t i tB G B−≤ <  
This case shows that the prediction result is reasonable 
because when ONU requested more than the maximum 
guaranteed bandwidth, OLT would allocate bandwidth to ONU 
in the range between the maximum guaranteed bandwidth and 
the requested bandwidth. However, the reasonable result is not 
guaranteed to be correct so that it is necessary to use queue 
reports to record the possible bandwidth requests centered 
with
, 1
pre
i tG − , e.g. , ,[4] [8]i t i tQR QR− . As shown in Fig. 4, we use 
, [0]i tQR  to record the bandwidth request which is guaranteed to 
be transmitted. The remaining 10 queue reports are allocated in 
a quartile way. The detailed formulae for case 1 is presented in 
Eq. (5).  
1
Q
3
Qguaranteed
iB , 1
pre
i tG − ,i tB
1
QR
2
QR
3
QR
4
QR 5QR 6QR 7QR 8QR 9QR 10QR 11QR0QR
 
Fig. 4 Case 1 queue report distribution 
, , ,
0 0
[0] ( [ ] | [ ] )
m m
guaranteed
i t m i t i t i
k k
QR MAX P k P k B
= =
= ≤∑ ∑  
( ), , , ,
0 0
[ ] [ ] | [ ] ( 6) , 4,...,8
m m
best
i t m i t i t i t
k k
QR j MAX P k P k G j jα
= =
 
= ≤ + − × = 
 
∑ ∑  
( ), 11
2
pre guaranteed
1 i t iQ = G B−× + , ( ), 1 ,1
2
pre
3 i t i tQ = G B−× +                    (5) 
, , ,
0 0
[ ] [ ] | [ ] ( ) , 1, 2,3
m m
i t i t i t 1
m
k k
QR j MAX P k P k Q j-2 jα
= =
 
= ≤ + × = 
 
∑ ∑  
, , ,
0 0
[ ] [ ] | [ ] ( ) , 9,10
m m
i t i t i t 3
m
k k
QR j MAX P k P k Q j-9 jα
= =
 
= ≤ + × = 
 
∑ ∑  
Note that the parameter α decides the gap between adjacent 
queue reports. As shown before, this gap is the upper bound of 
the difference between the best granted bandwidth and the real 
granted bandwidth. Although making α larger can tolerate 
larger prediction errors, we limit the value of α to 1538 in order 
to limit the above gap difference, achieving lower packet delay 
accordingly.  
Case 2: , 1 ,
pre guaranteed
i t i i tG B B− < <  
When this case occurs, the prediction result is inconceivable 
World Academy of Science, Engineering and Technology 65 2012
1222
  
ASPQR_EF can both achieve 0.9. 
0.0000
0.0005
0.0010
0.0015
0.0020
0.0025
0.0030
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
E
F
 A
v
er
a
g
e 
D
el
a
y
(s
)
Load
AS
ASPQR
ASPQR_PreEF
R-IPSA
 
Fig. 7 Average EF packet delay in unbalanced traffic environment 
0.00000
0.00050
0.00100
0.00150
0.00200
0.00250
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
C
y
cl
e 
ti
m
e(
s)
Load
AS
ASPQR
ASPQR_PreEF
R-IPSA
 
Fig. 8 Cycle time in unbalanced traffic environment 
0.0000
0.0020
0.0040
0.0060
0.0080
0.0100
0.0120
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
A
F
 A
v
e
r
a
g
e
 D
e
la
y
(s
)
Load
AS
ASPQR
ASPQR_PreEF
R-IPSA
 
Fig. 9 Average AF packet delay in unbalanced traffic environment 
0.0000
0.1000
0.2000
0.3000
0.4000
0.5000
0.6000
0.7000
0.8000
0.9000
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
B
E
 A
v
e
ra
g
e
 D
e
la
y
(s
)
Load
AS
ASPQR
ASPQR_PreEF
R-IPSA
 
Fig. 10 Average BE packet delay in unbalanced traffic environment 
Ideally, if the number of queue reports is infinite, the ASPQR 
or ASPQR_PreEF should always approach the zero gap 
difference between the best granted bandwidth and the real 
granted bandwidth. Fig. 12 shows the gap difference percentage 
which is defined to be the ratio between gap difference and the 
best granted bandwidth. As seen in Fig. 12, our proposed 
method can greatly reduce the gap difference especially when 
the load is higher. This reduction can contributed to the proper 
handling of the multiple queue reports according to the 
predicted result. 
0.00000
0.10000
0.20000
0.30000
0.40000
0.50000
0.60000
0.70000
0.80000
0.90000
1.00000
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
U
ti
li
za
ti
o
n
Load
AS
ASPQR
ASPQR_PreEF
R-IPSA
 
Fig. 11 Upstream channel utilization 
0
10
20
30
40
50
60
70
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
G
a
p
 d
if
fe
re
n
ce
 p
er
ce
n
ta
g
e(
%
)
Load
AS
ASPQR
ASPQR_PreEF
 
Fig. 12 The gap difference percentage 
V. CONCLUSIONS 
This paper aims to solve the problems faced by our previous 
proposed active intra-ONU scheduling (AS). By introducing the 
cooperative prediction method, the original AS can be improved 
to be AS with predictive queue reports (ASPQR). Three major 
predictive queue report allocation rules are presented to reduce 
the penalty induced by the prediction errors. To further improve 
the EF performance, ASPQR_PreEF further transmits the 
packets which come during the waiting time in advance. 
Simulation results have confirmed that the proposed ASPQR or 
ASPQR_PreEF has achieved the better QoS in terms of the 
packet average delay and upstream channel utilization. Even 
under the limited number of queue reports, the proposed scheme 
can greatly reduce the gap difference between the best granted 
bandwidth and the real granted bandwidth. How to integrate the 
prediction error information in the proposed scheme is our 
future work. 
REFERENCES   
[1] G. Kramer and G. Pesavento, “Ethernet PON: Building a 
Next-Generation Optical Access Network,” IEEE Commune. Mag., vol. 
40, no. 2, pp. 66-73, Feb. 2002. 
[2] IEEE Std. 802.3ah for Information Technology-Telecommunications and 
Information Exchange Between Systems-Local and Metropolitan Area 
Network-Specific Requirements Part, IEEE Std. 802.3ah, Jul. 2004. 
[3] H. J. Byun, I. M. Nho, and J. T. Lim, “Dynamic Bandwidth Allocation 
Algorithm in Ethernet Passive Optical Networks,” Electronics Letters, 
vol. 39, no. 13, pp. 1001-1002, Jun. 2003. 
[4] H. J. Byun, I. M. Nho, and J. T. Lim, “Dynamic Bandwidth Allocation 
Algorithm in Ethernet Passive Optical Networks,” Electronics Letters, 
vol. 39, no. 13, pp. 1001-1002, Jun. 2003. 
World Academy of Science, Engineering and Technology 65 2012
1224
國科會補助計畫衍生研發成果推廣資料表
日期:2012/08/17
國科會補助計畫
計畫名稱: 全方位整合的乙太被動光纖網路動態頻寬配置演算法之設計
計畫主持人: 蘇銓清
計畫編號: 99-2221-E-006-193-MY2 學門領域: 計算機網路與網際網路
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
本計畫相關內容亦配合教育部通訊教改計畫編輯教材. 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
