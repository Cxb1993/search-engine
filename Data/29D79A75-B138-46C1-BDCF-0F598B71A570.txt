  I
摘要 
在本計畫中，我們針對數位式影像穩定系統進行研究，設計了一套適合數位攝影機平
台的演算法，藉由數位式補償，以達到穩定影像的目的；並整合了影像穩定系統與視訊編
碼器，以精簡移動估計的運算，使得整體架構更適合硬體實現。除此之外，我們利用多重
畫面的影像資訊，以提高攝影機影像畫質。 
數位式影像穩定系統的架構可以分為兩大部分，一部份為總體移動估計，另一部份為
總體移動補償。總體移動估計主要是測量當攝影機震動時，影像框架之間的總體移動。總
體移動補償則是根據計算出的總體移動，在感光元件上取出穩定而且連續的影像。 
在本報告中，我們提出了三種不同的影像穩定系統與MPEG-4視訊壓縮整合之架構，並
對整合的結果去做各個層面的分析與比較。此外，我們以既有的演算法作為基礎，加強在
攝影機跟拍以及鏡頭變焦時的穩定效果。同時，我們在本報告中證明了我們設計的數位式
影像系統所計算出的總體移動估計，可以媲美利用gyro-sensor所量測到攝影機晃動的數
值。去分析數位與光學式影像穩定系統整合的可行性以及效果。 
 
關鍵詞: 數位式影像穩定系統，移動估計，總體移動估計，視訊編碼，數位攝影機 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  III
Contents 
 
I. Introduction...............................................................................................................................................1 
II. Digital Stabilization ..................................................................................................................................1 
A. Previous Work ..................................................................................................................................................................1 
1) Block-Based Motion Estimation ..............................................................................................................................2 
2) Global Motion Detection..........................................................................................................................................3 
3) Global Motion Smoothing........................................................................................................................................3 
4) Global Motion Compensation ..................................................................................................................................4 
5) Performance Evaluation ...........................................................................................................................................4 
III. Image Stabilization for Camera Zooming and Panning............................................................................5 
A. Camera Zooming ..............................................................................................................................................................6 
B. Detection of Rapid Camera Panning ................................................................................................................................6 
IV. Impact of Image Stabilization on Video Coding ......................................................................................6 
V. Integration of Digital Stabilizer with Video Codec ..................................................................................7 
A. Scheme 1 ..........................................................................................................................................................................8 
B. Scheme 2 ........................................................................................................................................................................11 
C. Scheme 3 ........................................................................................................................................................................12 
VI. Performance Evaluation..........................................................................................................................13 
A. Computational Cost ........................................................................................................................................................13 
B. Coding Efficiency...........................................................................................................................................................14 
C. Accuracy of Global Motion Detection............................................................................................................................14 
VII. Discussion ...............................................................................................................................................15 
A. Higher-Order Global Motion Models .............................................................................................................................15 
B. Search Range, Resolution, and Fast Motion Estimation.................................................................................................15 
C. Full Frame Recovery ......................................................................................................................................................15 
VIII. Conclusion .......................................................................................................................................16 
 
Achievements 
 
Published Paper List.......................................................................................................................................20 
                                                                                         
  2
 
Figure 2.  Block diagram of the digital stabilizer.
motion induced by the unwanted camera 
movement and then compensate the induced 
image motion to stabilize the image sequence. 
Each stabilized image is then input to the video 
encoder. 
Uomori et al. [3] proposed a digital 
stabilization system that estimates the global 
image motion by correlating block-based local 
motion vectors. Paik et al. [4], [5] proposed the 
estimation of global image motion based on the 
isolativity and stability of the local motion vectors 
determined by edge pattern matching. In [6], 
Egusa et al. developed a fuzzy theorem to control 
the stabilization system. In [7], a bit-plane 
matching algorithm was applied to reduce the 
computational complexity of the motion 
estimation while preserving its accuracy. Along 
the same direction, a Gray-coded bit-plane 
matching algorithm and hardware architecture was 
proposed in [8], [9] to make bit-plane matching 
more reliable. In [10], a multiple weighted 
bit-plane matching method was used in image 
stabilization applications. A low-pass filter was 
adopted by Ertürk to smooth the interframe global 
motion [11], and improved variants of the filter 
were reported in [12]-[14]. An inversed triangle 
method was proposed in [15] based on a point 
matching algorithm [3], whereas a wavelet 
transform algorithm was used in [16] to improve 
the performance of the digital stabilizer. A 
performance evaluation and characterization of 
various image stabilization algorithms were 
presented in [17], [18], and a comparative review 
of digital stabilization for mobile communications 
was presented in [19]. 
The motion field of an image sequence is 
contributed by three kinds of motions: 1) object 
motion, 2) intentional camera motion such as 
panning, and 3) unwanted camera motion such as 
hand jiggles. The main challenge of a digital 
stabilizer is to distinguish the jerky image motion 
caused by the unwanted camera motion from the 
object motion and from the intentional camera 
motion. 
In our approach, the camera motion (either 
intentional or unwanted) is separated from the 
object motion first. Then the motion induced by 
hand shaking is removed from the resulting 
camera motion [34]-[37]. 
When the moving objects do not dominate 
(in terms of image size) the scene, the global 
image motion induced by the camera can be 
extracted from the motion of background pixels. 
Furthermore, since the unstable camera movement 
caused by hand jiggles usually is of higher 
frequencies than the intentional camera movement, 
smoothing the global motion by a low-pass filter 
generates the desired stabilization effect. When 
the moving objects dominate the scene, the 
camera motion thus obtained is predominantly 
contributed by the moving objects. In this case, 
applying the low-pass filter to the computed 
global motion would smooth both the camera 
motion and the object motion. 
Fig. 2 shows the architecture of the proposed 
digital stabilizer. First, the motion field between 
the current frame and the preceding frame is 
computed using block-based motion estimation. 
The resulting motion field is input to the global 
motion (GM) detection module, which determines 
the global motion vector (GMV) for each video 
frame. Then the global motion is filtered by a 
motion smoother to remove the unstable camera 
movement. Finally, the current frame is motion 
compensated to achieve stabilization. The 
stabilized video frame is then input to the video 
encoder. Each step of the proposed digital 
stabilizer is described in detail next. 
1) Block-Based Motion Estimation 
Various techniques, such as edge-based, 
optical flow, feature-based, and phase correlation, 
have been proposed for global motion estimation 
[4], [5], [20]-[23]. To be compatible with video 
coding standards such as MPEG-4, we adopt the 
block-based motion estimation (BME) method to 
determine the motion field. 
Our algorithm works as follows. First, it 
divides the current frame into a number of 
macroblocks (MBs) and computes the motion 
  4
  
(a) (b) 
Fig. 5. (a) Global motion before and after smoothing. (b) Accumulative global motion before and after smoothing. Only the y-component is depicted 
here. 
 
Figure 6.  Video camera testbed with gyro sensors and a vibrator. 
Figure 7.  Comparison of the global motion obtained by our system 
and angular velocity sensor. 
real-time processing, a causal low-pass filter 
described by 
 
0
,
m
n i n i
i
c −
=
′ = ∑g g  (6) 
where gn represents the global motion vector of 
frame n, g'n the resulting smoothed motion, and ci 
the normalized coefficients of the filter, is used in 
our algorithm. 
Eq. (6) can be considered as a weighted 
moving average filter with window size m. With 
this filter, g'n becomes smoother as m increases. 
Fig. 5(a) shows the values of gn and g'n of a test 
sequence in the y-direction for m=7. The 
corresponding accumulative global motion, which 
represents the trajectory of the camera, is shown 
in Fig. 5 (b). 
4) Global Motion Compensation 
Stabilization of a video frame is achieved by 
performing motion compensation on the video 
frame. Given gn and g'n of frame n, this is done by 
shifting the display window with respect to the 
previous display window by dn according to the 
equation 
 ,n n n′= −d g g  (7) 
The image area within the display window of 
the current video frame is cropped and output to 
the video encoder. In practice, the size of the 
display window, which is always smaller than the 
input video, depends on the magnitude of the 
unwanted camera motion. A large margin around 
the display window should be allocated to 
compensate for large hand shaking. For a fixed 
output video size, this effectively imposes a 
requirement on the resolution of the image sensor. 
5) Performance Evaluation 
Evaluation of the performance of a digital 
stabilization algorithm is a difficult task since the 
ground truth of hand shake is unavailable. Instead 
of seeking a solution to measure the hand jiggling 
motion, we set up a camera platform on which 
both our digital stabilizer and a gyro-based motion 
detection module [28] used in state-of-the-art 
digital cameras are installed. Specifically, the 
platform consists of a camera module to capture 
video, a mechanical vibrator to generate jiggling 
motion in the horizontal (x-) direction, and a 
  6
Figure 10.  Motion field of zooming without camera movement. 
Figure 11.  Motion field of zooming with camera movement. 
Note that the motion field appears radial and 
that the center of the motion field is near zero. 
A.  Camera Zooming 
In the case where both camera motion and 
optical zooming occur, the resulting local motion 
field would look like the one shown in Fig. 11. 
Unlike the pure zooming case, the local motion 
vectors at the center of the motion field are not 
zero. These nonzero motion vectors are the result 
of camera movement. In our algorithms, they 
serve as the basis for computing the camera 
movement. However, dividing the central region 
into small blocks and applying block-based 
motion estimation to each block may lead to 
inaccurate global motion estimation. To solve the 
problem, we select a large block at the central 
region of the image and use it to estimate the 
global motion by (1). Within the search window, 
the displacement vector ( , )x y=v that gives rise to 
the minimum SAD is solution for the global 
motion. Then, as described in Section II-A, the 
stabilized image sequence is obtained by 
smoothing the global motion of each frame. 
Normally, a larger search window leads to a better 
estimate of the global motion but at the expense of 
additional computations. 
B.  Detection of Rapid Camera Panning 
The image frames are repositioned to achieve 
stabilization by shifting the display window 
according to the difference between the original 
global motion gn and the smoothed global motion 
g'n. As rapid panning occurs, we want the display 
window to follow the camera motion as closely as 
possible. While being able to removes the unstable 
movement, the lowpass filter described in Section 
II-A introduces a delay to the stabilized image 
sequence. The apparent delay between the 
stabilized image sequence and the original 
sequence increases as the camera pans rapidly. To 
solve the problem, a fuzzy control approach is 
proposed in [9]. Here, we use a weighted average 
approach, in which the smoothed global motion is 
refined as follows: 
 ( )1 ,n n nb b′′ ′= × + − ×g g g  (9) 
where n′′g  is the modified smoothed global motion, 
and b is the coefficient. This helps the display 
window to catch up with camera panning. 
The global motion induced by rapid camera 
panning has large value and high temporal 
correlation; therefore, we may use these properties 
to detect camera panning. The mean and variance 
of the global motion are computed over N samples 
as follows: 
 
1
0
1 ,
N
n n i
iN
−
−
=
= ∑g g  (10) 
 ( )1 2
0
1 ,
N
n n i n i
iN
−
− −
=
= −∑g g g  (11) 
where ng and ng , respectively, are the mean and 
variance of the global motion. Fig. 12 shows the 
accumulated global motion induced by rapid 
camera panning for the sequence Game in our 
experiment. We choose N=7, 3n >g , and 10n <g . 
Under these parameters, the rapid camera panning 
detected is shown by the red curve (marked with 
triangle) in Fig. 12. 
IV. IMPACT OF IMAGE STABILIZATION ON VIDEO 
CODING 
Before the digital stabilizer described in the 
  8
 
Figure 13.  Sequence Game. 
 
 
Figure 14.  Sequence Lab. 
 
20
25
30
35
40
45
0 1000 2000 3000 4000 5000 6000
Bitrate(Kbps)
PS
N
R
(d
B)
original_H264
stabilized_H264
original_MPEG4
stabilized_MPEG4
 
Figure 15.  Comparison of the R-D curves of Sequence Game. 
 
25
30
35
40
45
0 500 1000 1500 2000 2500
Bitrate(Kbps)
PS
N
R
(d
B)
original_H264
stabilized_H264
original_MPEG4
stabilized_MPEG4
 
Figure 16.  Comparison of the R-D curves of Sequence Lab. 
 
TABLE  III 
PSNR AND BIT COUNTS FOR MOTION VECTORS OF SEQUENCE GAME 
CODED BY MPEG-4. 
 
Original Stabilized 
QP 
PSNR Motion bits PSNR 
Motion 
bits 
Motion 
bits diff 
PSNR 
diff 
Bitrate 
diff (%) 
5 35.002 830095 35.008 823231 -6864 0.006 2.92 
10 30.184 794271 30.194 782001 -12270 0.009 2.98 
15 28.176 791440 28.191 771514 -19926 0.015 2.71 
20 26.813 785251 26.824 765121 -20130 0.011 1.52 
25 25.913 787658 25.920 765869 -21789 0.007 0.45 
30 25.157 786315 25.161 766514 -19801 0.004 -0.42  
TABLE  IV 
PSNR AND BIT COUNTS FOR MOTION VECTORS OF SEQUENCE LAB 
CODED BY MPEG-4 
 
Original Stabilized 
QP
PSNR Motionbits PSNR
Motion 
bits 
Motion 
bits diff 
PSNR 
diff 
Bitrate 
diff (%)
5 36.362 543569 36.343 517133 -26436 -0.019 0.88 
10 32.993 532702 32.963 497875 -34827 -0.030 0.17 
15 31.505 552357 31.474 512583 -39774 -0.032 0.22 
20 30.450 560585 30.413 520769 -39816 -0.037 0.29 
25 29.730 568956 29.673 528078 -40878 -0.057 0.30 
30 29.106 572619 29.026 530171 -42448 -0.079 0.46  
side. It is applicable when the original video 
capturing device is not equipped with an image 
stabilizer. This integration scheme can be offered, 
for example, via plug-in software for personal 
computers as a post processing package. 
A. Scheme 1 
In this scheme the digital stabilizer needs to 
be modified, but the video encoder remains the 
same. Therefore, the main task in the design of 
this integration scheme is to ensure that the 
performance of the digital stabilizer is maintained. 
Delay is a major issue of this integration 
scheme. Since the image stabilization is 
performed before the video coding, the motion 
vectors received by the digital stabilizer at any 
time instant correspond to a previous frame. In 
other words, there is always a time delay. If the 
bi-directional prediction mode (i.e. B frame) is 
turned off so that the video frames are encoded in 
the same order as they arrive at the video encoder, 
the delay is one frame time. If B frame is enabled, 
the delay is more complicated. Any such delay 
would affect the performance of the digital 
stabilizer and even renders it powerless. 
Therefore, the digital stabilizer has to 
compute the motion vectors of the current frame; 
the delayed motion data generated by the video 
encoder cannot be used directly for image 
stabilization. Obviously, the additional 
  10
 
(a) 
 
⎛ ⎞   
(b) 
 
Figure 20.  (a) The misalignment of macroblocks between the 
images before and after stabilization. (b) Motion interpolation in 
Scheme 2. 
image. The second one uses the GM thus obtained 
to determine a background region (BR), which is 
basically a rectangular region consisting of one or 
more macroblocks. The BR is then used by the 
digital stabilizer to compute the global image 
motion corresponding to camera motion. 
For a macroblock belonging to the 
background, its motion vector v can be modeled 
as the global motion vector g plus an additive 
noise n, 
 [ ] [ ], , ,i j i j= +v g n  (12) 
where ( ),i j is the index of the macroblock and 
[ ],i jn is assumed to be independent and 
identically distributed (i.i.d) Gaussian signal with 
zero-mean. With this model, the best BR is 
determined by 
[ ]1 1
( , )
BR arg min , ,
w w
x y k w l w
i k j l
− −
=− =−
⎧ ⎫= + + −⎨ ⎬⎩ ⎭∑ ∑ v g (13) 
where w is an adjustable parameter that controls 
the number of macroblocks for the BR. Note that 
the background region of each frame is 
dynamically estimated, and the size of the BR 
does not have to be fixed either. An example of 
BR is shown in Fig. 18. 
The BR determined from frame n–1 is used 
as the prediction of the BR of frame n. Therefore, 
after the BR is identified, the digital stabilizer 
performs BME on all macroblocks within the BR 
for the next input frame. In our simulation, we set 
the size of the BR to as small as 64×64 (i.e. w = 2), 
and the resulting global motion is still very 
accurate. At this BR size, the computational cost 
of BME for the digital stabilizer is reduced by a 
factor of (720×480)/(64×64) = 84.375. 
The system flow shown in Fig. 17(a) is 
designed for the case where the structure of the 
group of pictures (GOP) only includes I and P 
frames. When the GOP structure contains B 
frames (e.g. IBBP), the frames are not encoded in 
 
Figure 18.  Background region (indicated by the gray area) extracted 
from a motion field. 
 
 
 (a) (b) 
 
Figure 19. The assignment of background region under different GOP 
structures: (a) IPPP and (b) IBBP. 
  12
TABLE V 
REGULARIZATION OF MOTION VECTORS IN SCHEME 3.  
 
MB mode 
/Frame type 
Reference 
frame(s) Regularized MV 
Intra/In, Pn, and Bn None average(g[n-1], g[n+1]) 
Inter/Pn P(I)n-2 v/3 
Forward/Bn 
P(I)n-1  
P(I)n-2 
v 
v/2 
Backward/Bn 
P(I)n+1 
P(I)n+2 
–v 
–v/2 
Bi-directional, 
Direct /Bn 
{P(I)n-1 ,P(I)n+2} 
{P(I)n-2 ,P(I)n+1} 
average(vF, –vB/2) 
average(vF/2, –vB) 
 
GOP structure is IBBP. 
vF denotes the forward motion vector, and vB the backward motion 
vecrtor. 
In general, the interpolated motion vectors 
obtained by (14) are sufficiently close to the ones 
obtained by full-search motion estimation (FSME) 
if it were used to estimate the motion. However, 
such an interpolation scheme gives poor results 
for regions across the boundary of moving objects. 
Any further local refinement of the motion vectors 
of such regions cannot help improve the accuracy. 
The coding efficiency drops. 
To solve this problem, we do the motion 
interpolation selectively. More specifically, we 
measure the variance of the four motion vectors vi 
used in (13). If the variance is small enough, the 
video encoder interpolates the motion vectors 
according to (13) and then applies a small 
diamond search (SDS) [27] around the 
interpolated motion vector to improve the result. 
Otherwise, the video encoder applies FSME to 
obtain the motion vector for macroblock A. In 
both cases, a sub-pixel motion estimation is 
applied to further refine the resulting integer-pel 
motion vectors. With this approach, the coding 
efficiency is greatly improved. We find from our 
experiments that only 13% of the macroblocks 
require FSME in the video encoder. For the 
remaining macroblocks, the video encoder does 
not have to perform FSME. Motion vectors with 
good accuracy can be obtained by simply applying 
motion interpolation and SDS for these 
macroblocks. 
The system flow of the scheme is depicted in 
Fig. 21(a). For simplicity only the function blocks 
that are involved in the integration are shown. 
Here, like in Fig. 17, the white blocks represent 
the functions performed by the digital stabilizer, 
the dark gray blocks are the functions performed 
by the video encoder, and the gray block is the 
new function introduced as a result of the 
integration. The data flow of the scheme is shown 
in Fig 18(b). 
C. Scheme 3 
In this scheme, the digital stabilizer is 
integrated with the video decoder, and the 
compressed video is stabilized while being 
decoded. The system flow is shown in Fig. 22. 
Because the motion information of the video 
sequence already exists in the video bitstream, the 
digital stabilizer can simply apply the decoded 
motion vectors to perform global motion detection 
and smoothing by following the procedure 
described in Section II.B. 
However, the motion data available in the 
bitstream may not correspond to the motion 
between neighboring frames required for digital 
stabilization. For example, when the GOP 
structure is IBBP, the motion of the P frame is 
measured with respect to the I frame. But what is 
needed for stabilizing this P frame is the motion 
relative to the preceding B frame in the display 
order. The main task of Scheme 3, therefore, is to 
derive such motion from the available motion 
data. 
 
 
 
Figure 22. System flow of Scheme 3. 
  14
In Table VI, the computational cost of 
Scheme 2 is shown for different cases, depending 
on the methods used for the refinement of the 
interpolated motion vectors. If only sub-pel 
refinement is performed around the interpolated 
motion vector without small diamond search, the 
computational cost increases about 12%. This 
increment due to larger input frame for stabilizer. 
If the small diamond search is applied, the 
computational cost is increased by 14%. Here, the 
cost of SDS is converted to the cost of FSME by 
considering the number of SADs calculated. We 
evaluate this cost on various sequences and find 
the variance of the increased cost is small. 
Therefore, we believe it can be regarded 
content-independent. In the final case, we apply 
SDS in regions where the variance of motion 
vectors is small and FSME in regions where the 
variance is large. The computational cost increases 
by 16%, which is still much smaller than that of 
the non-integration system. 
Scheme 3 integrates the digital stabilizer with 
the video decoder and the BME operation is 
totally skipped in the digital stabilizer. Compared 
with the operations in the video decoder, the cost 
of GM detection and GM smoothing in the digital 
stabilizer is negligible. 
B. Coding Efficiency 
In Scheme 1, the additional functions, GM 
detection, and BR identification, introduced to the 
integrated system are performed after video 
encoding. These functions do not affect the video 
encoder. Hence, the coding efficiency remains the 
same after the integration. 
In Scheme 2, the motion estimation process 
of the video encoder is modified as a result of the 
integration. We implement Scheme 2 on the C++ 
MPEG-4 reference software to investigate the 
impact of integration on the coding efficiency. The 
rate-distortion curves of the sequence Basketball 
are shown in Fig. 23. 
We compare two cases. The curve that is 
labeled “Scheme 2” in Fig. 23 corresponds to the 
case in which the video encoder performs 
half-pixel motion vector refinement around the 
interpolated motion vectors. The coding 
performance of this scheme decreases about 0.1 
dB at high bitrates and 0.8 dB at low bitrates. As 
explained earlier, this is due to the inaccuracy of 
the interpolated motion vectors for regions around 
the boundaries of objects. 
The curve that is labeled “Improved Scheme 
2” in Fig. 23 represents the second case in which 
the motion interpolation is performed selectively 
according to the variance of the four reference 
MVs. Because the interpolated motion vector is 
refined using the small diamond search and new 
motion vector are computed using FSME for 
macroblocks with large motion variance, the 
coding performance is very close to that of the 
original video encoder. The improvement in 
coding efficiency over the first case is consistent 
across all bitrates. 
C. Accuracy of Global Motion Detection 
In Scheme 1, the digital stabilizer only 
performs BME in the background region. With 
w=2, the GMVs determined by the original digital 
stabilizer and this integrated scheme are shown in 
Fig. 24. The RMSE of the difference between 
these two GMV curves is 0.034 only. With w=8, 
this RMSE value reduces to 0.014. In practice, we 
have found that w=2 is generally good enough. 
Choosing an extremely small value for w is not 
recommended since it is more likely to run into 
detection errors caused by fast moving objects of 
smooth texture. 
In Scheme 2, we do not modify the image 
stabilizer, so the accuracy of GMVs remains the 
same as that of the original digital stabilizer. 
In Scheme 3, the global motion is estimated 
from the motion information in the bitstream. Our 
simulation shows that the results are very accurate. 
For example, for the Basketball sequence the 
RMSE between GMVs generated by Scheme 3 
-12
-10
-8
-6
-4
-2
0
2
4
6
8
1 11 21 31 41 51 61 71
Frame number
G
lo
ba
l m
ot
io
n
Original system
Scheme 1
 
Figure 24. Comparison of global motion vectors estimated by Scheme 
1 and the original image stabilizer. Only the y-component is depicted 
here. 
  16
undefined image area. 
All these full frame recovery techniques can 
be incorporated into our integration schemes to 
form an integral part of the whole system. 
VIII. CONCLUSION 
In this report, we have presented a digital 
stabilization algorithm and three integration 
schemes for integrating the digital stabilizer with 
the video codec of digital video cameras. 
Designed by taking hardware architecture 
into consideration, the digital stabilizer works as 
effectively as gyro-based sensors and integrates 
nicely with the video codec. The global motion 
determined by these integration schemes is as 
accurate as that by the standalone digital image 
stabilizer, and the coding performance is as good 
as the standalone video encoder. As a result of the 
integration, Schemes 1 and 2 reduce the 
computational cost by a factor of 2, and Scheme 3 
costs almost nothing as compared to the video 
decoder. 
REFERENCE 
[1] M. Oshima, T. Hayashi, S. Fujioka, T. Inaji, 
H. Mitani, J. Kajino, K. Ikeda, and K. 
Komoda, “VHS camcorder with electronic 
image stabilizer,” IEEE Trans. on Consumer 
Electronics, vol. 35, no. 4, pp. 749-758, Nov. 
1989. 
[2] K. Sato, S. Ishizuka, A. Nikami, and M. Sato, 
“Control techniques for optical image 
stabilizing system” IEEE Trans. on 
Consumer Electronics, vol. 39, no. 3, pp. 
461-466, Aug. 1993. 
[3] K. Uomori, A. Morimura, H. Ishii, T. 
Sakaguchi, and Y. Kitamura, “Automatic 
image stabilizing system by full-digital signal 
processing,” IEEE Trans. on Consumer 
Electronics, vol. 36, no. 3, pp. 510-519, Aug. 
1990. 
[4] J.-K. Paik, Y.-C. Park, and S.-W. Park, “An 
edge detection approach to digital image 
stabilization based on tri-state adaptive linear 
neurons,” IEEE Trans. on Consumer 
Electronics, vol. 37, no. 3, pp. 521-530, Aug. 
1991. 
[5] J.-K. Paik, Y.-C. Park, and D.-W. Kim, “An 
adaptive motion decision system for digital 
image stabilizer based on edge pattern 
matching,” IEEE Trans. on Consumer 
Electronics, vol. 38, no. 3, pp. 607-616, Aug. 
1992. 
[6] Y. Egusa, H. Akahori, A.Morimura, and N. 
Wakami, “An application of fuzzy set theory 
for an electronic video camera image 
stabilizer,” IEEE Trans. on Fuzzy Systems, 
vol. 3, no. 3, pp. 351-356, Aug. 1995. 
[7] S.-J. Ko, S.-H. Lee, and K.-H. Lee, “Digital 
image stabilizing algorithms based on 
bit-plane matching,” IEEE Trans. on 
Consumer Electronics, vol. 44, no. 3, Aug. 
1998. 
[8] S.-J. Ko, S.-H. Lee, and S.-W. Jeon, “Fast 
digital image stabilizer based on Gray-coded 
bit-plane matching,” in Proc. International 
Conference on Consumer Electronics, Los 
Angeles, CA, USA, June 1999, pp. 90-91, 
[9] G.-R. Chen, Y.-M. Yeh, S.-J. Wang, and 
H.-C. Chiang, “A novel structure for digital 
image stabilizer,” in Proc. Asia-Pacific 
Conference on Circuits and Systems, Dec. 
2000. pp. 101-104. 
[10] H. R. Pourreza, M. Rahmati, and F. Behazin, 
“Weighted multiple bit-plane matching , a 
simple and efficient matching crierion for 
electronic digital image stabilizer 
application,” in Proc. International 
Conference on Signal Processing 2002, vol. 
2, pp. 957-960 Aug. 2002. 
[11] S. Ertürk, “Image sequence stabilization by 
low-pass filtering of interframe motion,” in 
Proc. SPIE, Visual Communication and 
Image Processing, vol. 4310, 2001, pp. 
434-442. 
[12] S. Ertürk, and T. J. Dennis, “Image sequence 
stabilization based on DFT filtering,” in IEE 
Proc. Image Vision and Signal Processing, 
vol. 127, pp. 95-102, 2000. 
[13] S. Ertürk, and M. K. Gullu, “Membership 
function adaptive fuzzy filter for image 
sequence stabilization,” IEEE Trans. on 
Consumer Electronics, vol. 50, no. 1, pp. 1-7, 
Feb. 2004. 
[14] S.-C. Hsu, S.-F. Liang, and C.-T. Lin, “A 
robust digital image stabilization technique 
based on inverse triangle method and 
background detection,” IEEE Trans. on 
Comsumer Electronics, vol. 51, no. 2, pp. 
335-345, May. 2005. 
[15] H. R. Pourreza, M. Rahmati, and F. Behazin, 
“An electronic digital image stabilizer based 
