Binomial and Distant Restricted Tournament Replacement
(BRTR & DRTR)
for Estimation of Distribution Algorithms ∗
1 Introduction
In 2007, Coffin and Smith [7] have found that the hierarchical Bayesian optimization algorithm
(hBOA) [27] scales exponentially on parity functions. Since hBOA is one of the most successful
EDAs [23, 30], it was believed that parity function is difficult for EDAs in general. Surprisingly, our
previous work [6] has shown that some simple EDAs scale polynomially on parity functions as well
as so-called pairwise allelic independent functions. According to our previous results, the spurious
linkages induced by the restricted tournament replacement (RTR) [20] may be the main reason that
causes the exponential scalability.
RTR has a strong ability to keep diversity in the search space and is extensively used by many
EDAs, but little literature discusses the properties of RTR, especially about induced spurious link-
ages. This works further discusses the behavior of RTR to analyze the failure of linkage learning on
parity functions. On the other hand, from the idea of keeping diversity in RTR, this work proposes
two new niching mechanisms, namely the binomial restricted tournament replacement (BRTR) and
distant restricted tournament replacement (DRTR) to conquer the weakness of RTR.
1.1 Genetic Algorithms with Linkage Learning
Genetic algorithms (GAs) [21, 14] are stochastic search and optimization methods that require only
the quality information of solution candidates. The term simple GA (SGA) refers to a specific class
of GAs that does not involve learning problem structures. SGAs have been used for optimization
in various fields for decades and have achieved great success. An SGA, however, does not address
the issue of linkage (i.e., chromosomal encoding) adequately. In 1989, Goldberg et al. showed that
if the decision variables have non-neglectable dependencies, an SGA would work only when those
dependent variables are tightly encoded.
Starting from Holland’s notion [21] of a building block (BB) — a small and significant sub-
solution, a decomposition methodology has been proposed for the successful design of competent
GAs [15, 16]. Since then, much work has been done for GAs to correctly identify BBs and efficiently
mix them. The term estimation of distribution algorithm (EDA) refers to one major category of
such GA developments. Unlike an SGA, an EDA builds a model describing fitter individuals after
selection and then uses the model to generate offspring.
∗Part of this work has been published in Ho & Yu (2012): A linkage-learning niching in estimation of distribution
algorithm. GECCO 2012: 649-650.
1
(a) equally distributed over local optima (b) distributed according to the quality 
Figure 1: Concept of niching techniques.
in the population but may get rid of inferior local optima rapidly. Without sufficient local optima,
EDAs converge prematurely when dealing with multimodal problems. With niching, sufficient local
optima help EDAs approach the global optimum.
1.3 Niching and Linkage Learning
Although niching techniques are originally developed for multimodal problems, they have been
shown useful for traditional optimization problems as well. It has been shown that the improvement
of solution quality is given by [26, 4, 1]
f¯t+1 = f¯t + I · σt, (1)
where t is the number of the generation, f¯t is the average fitness at the t-th generation, σt is the
variance of fitness at the t-th generation, and I is a constant. The above equation indicates that
keeping diversity (keeping σt large) is crucial for GAs and EDAs to find better solutions. Based on
this observation, niching techniques have been widely used, especially for hierarchical problems [35,
36, 27], where preserving alternative solution candidates is the key to conquer hierarchical difficulty.
Recently, RTR is one of the most commonly used niching techniques adopted in EDAs due
to its low implementation cost and embedded elitism. RTR works as follows: When an offspring
chromosome is generated, we find its closest parental chromosome, and replace the parent with
offspring if and only if the offsprings fitness is better. With the help of RTR, EDAs are able to
solve hierarchical problems within sub-quadratic number of function evaluations. However for some
problems, like parity functions, EDAs with RTR scales exponentially. It is not for sure yet whether
or not the RTR causes the problem, since little literature discusses the behaviour of RTR. The goal
of this work is to investigate RTR and proposes a new niching mechanism that is suitable for linkage
learning in EDAs.
2 Need of Another Niching Mechanism
This section gives the background knowledge used in this work. First, we will describe the detail
of parity function and explain why this parity function is a allelic pairwise independent for EDAs.
Then, we introduce the main idea of RTR to show how it works with EDAs.
3
Algorithm 1 Restricted Tournament Replacement(RTR)
Input: Parent population A = {a1, a2, ..., an} and offspring population B = {b1, b2, ..., bn}
Output: Next generation population O with n individuals.
1: Set window size w = min(l,n/20), where l is the length of problems
2: for i = 1→ n do
3: Choose random subset Aw with w size from A
4: {s1, s2, ..., sw} ←− Aw
5: for j = 1→ w do
6: Calculate distance dj ←− Hamming Distance(bi, sj)
7: end for
8: Find minimal x←− argx∈{1,2,...,w}min{d1, d2, ..., dw}
9: if Fitness{bi} ≥ Fitness{sx} then
10: sx ←− bi
11: end if
12: Aw ←− {s1, s2, ..., sw}
13: end for
14: O ←− A
defined by kullback-leibler distance [22]. It has been used as the linkage-learning metric in many
EDAs. The general form of mutual information is as follows:
I(X ; Y ) =
∑
x
∑
y
p(x, y) log
p(x, y)
p(x)p(y)
. (5)
In this equation, X and Y are two random variables, x and y are the outcomes of X and
Y respectively, and p(.) is the probability of the corresponding outcome. The value of I(X ; Y ) is
between 0 and 1. A greater value indicates a stronger relation between X and Y . If the two variables
have greater mutual information, it is suggested to arrange them as one BB from being disrupted.
Furthermore, we utilize a 3-bits parity function as an example to discuss linkage detection.
Figure 2 shows a simple parity function. The fitness of each individual is assigned if the out-
comes is even. Linkage detection begins after selection operator, because EDAs want to detect the
meaningful information. Obviously, in this example after selection, the mutual information value
of any two variable reveals I(X ; Y ) = 0. Briefly speaking, any EDAs that start with pairwise
linkage detection never detect any linkage structure, so we call parity function as allelic pairwise
independent functions.
However, if parity function is too easy such that linkage detection is not needed, why hBOA
scales exponentially is mysterious. The main difference between ECGA and hBOA is that hBOA
employs RTR, so RTR may play an important role on misleading linkage learning. For example,
extend from the Figure 2 results, we utilize RTR to form new population in the Figure 3. The new
population is generated from parent and offspring population. However, the mutual information
value of any variables may not equal to 0. The results may lead linkage learning technique to
consider the independent pair as a related pair. The misleading linkage structure produced by RTR
may affect EDAs to find the global optimum. This is the reason that linkage-learning-based EDAs
with RTR will scale exponential on some easy problems.
The niching mechanisms may raise the (false) dependency on independent pairs, because pre-
serving local optima enchants unnecessary relations. This misleading linkage usually call spurious
5
00.001
0.002
0.003
0.004
0.005
0.006
0.007
0.008
0 5 10 15 20 25 30 35
RTR
Full Replacement
Generation
N
f
e
Figure 4: DSMGA with and without RTR solve a 100 bits one max. The example shows the average
mutual information on the independent pair in every iteration of trap function. The higher average
value mean the more serious spurious linkage produced.
linkage. In most cases, the effect of spurious linkages is not severe enough to fail EDAs, since the
selection operator usually conquers the misleading. RTR raises the mutual information of indepen-
dent pairs, but it is unclear how serious this can be. Here, we conduct an experiment on the one
max problem.
In Figure 4, we tested a 100 bits one max problems with RTR and full replacement (FR) by
using DSMGA. For the case with FR, DSMGA converged at the 30-th generation. The average
mutual information increased at the beginning, but then decreases toward the end. On the other
hand, DSMGA with RTR still finds the optimal solution, but causes greater mutual information on
independent pairs than the one with FR. The results show that RTR may cause spurious linkages,
which fails EDA on parity functions.
4 Binomial Restricted Tournament Replacement
This section presents a new niching mechanism, called as binomial restricted tournament replace-
ment (BRTR). The difference between RTR and BRTR is that BRTR utilizes the binomial distri-
bution to choose chromosomes to pair with.
4.1 Ideal Distribution
BRTR is designed based on the idea to preserve characteristics of the distribution. As an example,
the binomial distribution is ideal for OneMax.
Here we use a fitness-ranked estimation as our fitness assignment. For example, if we have 2N
individuals in the pool including parent and offspring population, the new fitness assignment is
subsequently as 1
2N
, 2
2N
, ..., 2N
2N
. We use the symbol of r for rank value in the latter discussion.
Next, we define the relative occurrence rate to explain the method. We define two parameter p
and q. p means the occurrence rate of schema for each individuals. For example, if the BB size is
single bit and 1 presents the most occurrence BB, pi of this i-th individual 01100 00100 is
3
10
= 0.3.
q is the same definition as p, but the difference is that p is for current population and q is for the
7
niche size is difficult to decide since it is problem dependent.
The idea of this work is to obtain those characteristics from the current population. In the
preview section, we observed the rate p of occurrence schema and anticipated q of every individual.
These two parameter will help us to define the ideal size of each niching.
By using estimated qr, we define what is the ideal distance given the binomial distribution. dr
is defined as the ideal distance of the rth individual to its nearest individual. Given qr, we can
estimate dr by calculating the distance between qr and average pa of population. The equation is
as follows:
dr = [qr(1− pa) + pa(1− qr)] ·m · k, (8)
where m is the problems size and k is the bounded of sub-problems. Because we have already
obtained the qr from normal approximation, the equation can be reduce as follows:
dr = [2pa(1− pa) + αr
√
pa(1 + pa)
l
(1− 2pa)] · ℓ. (9)
Finally, according to the fitness rank, we can obtain ideal distance for every niche. In our definition,
each chosen individuals can be seem as a independent niche and the distance is defined as dr. This
section describes how we define the ideal distance if we have a estimated binomial distribution.
4.3 The Flow of BRTR
Now we can estimate the ideal distance according to observing occurrence rate p. However, in
implementation, it is difficult to decide ideal distance due to finite individuals. Hence, we use the
binomial distribution to calculate the probability of matching between real distance and equivalent
distance. If the equivalent distance of any pair of individuals is closer to the real distance, the
probability is high. This probability is more meaningful than Hamming distance.
Before discussing the new method, we first look back RTR. Although RTR’s distance detection
has some weakness on detecting similarity of individuals, RTR has been proven to success in many
deception problems. The goal of work is the change the Hamming distance as our probability
metric. As the success of RTR, we will keep some characteristic form RTR. Like RTR mechanism,
we compete the most similar pair to compete. Furthermore, we would not use the distance detecting
metric as RTR. RTR uses the Hamming distance as the detecting metric and compare the most
similar pair with fitness. However, the distance metric will throw too more better solutions if those
solutions are too close. Hence, according to our probability, even if better solutions have closest
distance, they are still preserved according the equivalent distance. We still use the restricted
tournament replacement to replace the population. Hence, we call our new niching method as
binomial restricted tournament replacement (BRTR), because we use binomial distribution as our
estimation.
The flow of BRTR is similar as RTR. First, we begin as a offspring to tournament replacement.
Second, we use the probability metric to define the most equivalent distance matching between
offspring and parent population. Finally, use tournament mechanism to decide which individual
should be keep. The only different is that we choose the new probability metric of equivalent. Here,
we define the parameter Q as the probability of similarity. It means if we have two individual
estimated qi and qj . Q is the probability of estimated distance by two individual i and j.
Q = qi · (1− qj) + (1− qi) · qj. (10)
Now that we have obtained the values of qi and qj , Q can be evaluated. Here, Q presents the ideal
distance if individuals i and j are sampled from the binomial distribution. Then, we define dtheory as
9
Algorithm 2 Fitness Normalization
Input: Parent population A = {a1, a2, ..., an}, offspring population B = {b1, b2, ..., bn}
, and model structure C = {c1, c2, ..., cm}, where m is the size of sub-problems
Output: Next generation population O with n individuals.
1: Assume {α1, α2, ..., αn} are the normalized value of {a1, a2, ..., an}
2: Assume {β1, β2, ..., βn} are the normalized value of {b1, b2, ..., bn}
3: for i = 1→ n do
4: for j = 1→ m do
5: if ai has most occurrence schema at position cj then
6: αi+=
1
m
7: end if
8: if bi has most occurrence schema at position cj then
9: βi+=
1
m
10: end if
11: end for
12: end for
Algorithm 3 Binomial Restricted Tournament Replacement(BRTR)
Input: Parent population A = {a1, a2, ..., an} with normalized values {α1, α2, ..., αn}
and offspring population B = {b1, b2, ..., bn} with normalized values {β1, β2, ..., βn}
Output: Next generation population O with n individuals.
1: Set window size w = min(l,n/20), where l is the length of problems
2: for i = 1→ n do
3: Choose random subset Aw with w size from A
4: {s1, s2, ..., sw} ←− Aw, where {σ1, σ2, ..., σw} are their normalize values
5: for j = 1→ w do
6: Distance dj ←− Hamming-Distance(bi, sj)
7: Equivalent distance ej ←− Equivalent(βi, σj)
8: Probability pj ←− binomial cdf(l, dj, ej)
9: end for
10: Find Minimal x←− argx∈{1,2,...,w}min{p1, p2, ..., pw}
11: if Fitness{bi} ≥ Fitness{sx} then
12: sx ←− bi
13: end if
14: Aw ←− {s1, s2, ..., sw}
15: end for
16: O ←− A
11
104
105
106
60 84 120 171 240
Problem Size
BRTR
RTR
N
f
e
(a) CP/TF problems with k = 3
104
105
106
107
108
40 56 80 112 160
Problem Size
BRTR
RTR
N
f
e
(b) CP/TF problems with k = 4
Figure 6: EDA solves CP/TF problem. y axis is the number of function evaluation
0
0.2
0.4
0.6
0.8
1
10 15 20 25 30
FR
RTR
BRTR
N
u
m
b
er
o
f
D
iff
er
en
t
O
p
ti
m
a
Generation
(a) k = 3
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
20 25 30 35
FR
RTR
BRTR
N
u
m
b
er
o
f
D
iff
er
en
t
O
p
ti
m
a
Generation
(b) k = 4
Figure 7: Assume sub-problems have many global optima. The experiment is to test the ability of
maintaining diversity. y axis is percent of different kinds of global optima. If y = 1.0 means all of
population are all global optima and different with others
13
BB-wise distance Meaning Whom to pair with
0 Identical chromosomes The closest
1 Chromosomes in the same niche The closest
> 1 Chromosomes in different niches The most inferior
Table 1: The behavior of DRTR
individuals instead of the closest one when dBB is greater than 1. The algorithm is shown as
follows (Algorithm 4).
Algorithm 4 Distant Restricted Tournament Replacement(DRTR)
Input: Parent population A = {a1, a2, ..., an} and offspring population B = {b1, b2, ..., bn}
Output: Next generation population O with n individuals.
1: Set window size w = min(l,n/20), where l is the length of problems
2: for i = 1→ n do
3: Choose random subset Aw with w size from A
4: {s1, s2, ..., sw} ←− Aw
5: for j = 1→ w do
6: Calculate BB-wise distance dj ←− BB-wise Hamming Distance(bi, sj)
7: end for
8: Find minimal x←− argx∈{1,2,...,w}min{d1, d2, ..., dw}
9: if dx > 1 then
10: Find minimal x←− argx∈{1,2,...,w}min{Fitness(a1), F itness(a2), ..., F itness(aw)}
11: end if
12: if Fitness{bi} ≥ Fitness{sx} then
13: sx ←− bi
14: end if
15: Aw ←− {s1, s2, ..., sw}
16: end for
17: O ←− A
5.2 Experiment Results
DRTR might seem to be too simple to be useful at the first glance; however, the experiment results
showed that it indeed worked quite well.
Figure 8 illustrates the comparison of DRTR, RTR and FR on OneMax and MK-Trap. From the
figure, we see that DRTR performs similarly to FR on OneMax. Both DRTR and FR outperformed
RTR on OneMax by about 40 100%. On the other hand, FR consumed about 8 times more function
evaluations than DRTR and RTR on MKTrap because niching speeds up linkage learning. While
RTR has a stronger ability of niching than DRTR, DRTR still performed pretty well. DRTR
consumed only less than 20% more evaluations than RTR. From the experiments, we conclude that
DRTR combines the strengths of both FR and RTR.
As mentioned before, one of the drawbacks of RTR is that it preserves some unnecessary inferior
chromosomes and causes superiors linkages for EDAs. Next we examine the mutual information
15
niching mechanisms: BRTR and DRTR.
BRTR is developed based on the concept of using the binomial distribution to minimize the
mutual information among independent genes. Empirically, EDAs with BRTR solves both deceptive
problems and allelic pairwise independent problems. In other words, BRTR preserves sufficient
local optima and prevent to generate extra spurious linkage as well. The most important key is
that BRTR acquire the knowledge of linkage structure from DSMGA. One of the main drawback
of BRTR is that it needs the information of the schemata with the most occurrences for every BBs,
which requires extra computational power to obtain.
DRTR, on the other hand, has been shown to have a similar capability as BRTR, while the
computation is simple. DRTR combines the strengths of both FR and RTR. It preserves enough
alternative solution candidates while the mutual information between any pairs of independent
genes remains minimum.
Both BRTR and DRTR require explicit information of BBs. While such information is easy
to obtain for some EDAs, like ecGA and DSMGA, it is not so for other EDAs, such as BOA and
hBOA. Our goal in the near future would be to extend the applicabilities of BRTR and DRTR to
those EDAs where the BB information is implicit.
To conclude, with the success of EDAs, the development of ordinary GA operator needs to be
EDA-friendly. In other words, such development should not impair the model building for EDAs.
The work in this project might be only the first step. We, as GA researchers, need to investigate
more for such possibility to enhance EDAs.
References
[1] T. Ba¨ck. Generalized convergence models for tournament- and (mu, lambda)-selection. In
Proceedings of the 6th International Conference on Genetic Algorithms, pages 2–8, 1995.
[2] S. Baluja. Population-based incremental learning: A method for integrating genetic search
based function optimization and competitive learning. Technical report, Carnegie Mellon Uni-
versity, 1994.
[3] A. Barron, J. Rissenen, and B. Yu. The MDL principle in coding and modeling. IEEE
Transactions on Information Theory, vol. 44(no. 6):2743–2760, 1998.
[4] T. Blickle and L. Thiele. A mathematical analysis of tournament selection. In Proceedings of
the 6th International Conference on Genetic Algorithms, pages 9–16, 1995.
[5] D. J. Cavicchio. Adaptive search using simulated evolution. Doctoral dissertation, University
of Michigan, Ann Arbor, MI., 1970.
[6] S.-C. Chen and T.-L. Yu. Difficulty of linkage in estimation of distribution algorithms. In
Proceedings of the Genetic and Evolutionary Computation Conference (GECCO2009), pages
397–404, 2009.
[7] D. J. Coffin and R. E. Smith. The limitations of distribution sampling for linkage learning. In
IEEE Congress on Evolutionary Computation 2007 (CEC 2007), pages 364–369, 2007.
[8] J. De, J. S. D. Bonet, C. L. Isbell, and P. Viola. MIMIC: Finding optima by estimating
probability densities. In Advances in Neural Information Processing Systems, pages 424–430,
1996.
17
[25] S. W. Mahfoud. Crowding and preselection revisited. Parallel problem solving from nature,
2:27–36, 1992.
[26] H. Mu¨hlenbein and D. Schlierkamp-Voosen. Predictive models for the breeder genetic algo-
rithm: I. continuous parameter optimization. Evolutionary Computation, 1:25–49, 1993.
[27] M. Pelikan and D. E. Goldberg. Escaping hierarchical traps with competent genetic algorithms.
In Proceedings of the Genetic and Evolutionary Computation Conference (GECCO2001), pages
511–518, 2001.
[28] M. Pelikan, D. E. Goldberg, and E. Cantu´-Paz. BOA: The bayesian optimization algorithm.
In Proceedings of the Genetic and Evolutionary Computation Conference (GECCO-99), pages
525–535, 1999.
[29] M. Pelikan and H. Mu¨hlenbein. The bivariate marginal distribution algorithm. In Advances in
Soft Computing - Engineering Design and Manufacturing, pages 521–535, 1999.
[30] M. Pelikan, K. Sastry, and E. Cantu´-Paz, editors. Scalable Optimization via Probabilistic
Modeling from Algorithms to Applications. Springer-Verlag, 2006.
[31] J. Rissanen. Modeling by shortest data description. Automatica, 14:465–471, 1978.
[32] J. Rissanen. Hypothesis selection and testing by the MDL principle. the Computer Journal,
42:260–269, 1998.
[33] C. E. Shannon. A mathematical theory of communication. The Bell System Technical Journal,
vol. 27:379–423, 1948.
[34] M. Tsuji, M. Munetomo, and K. Akama. Modeling dependencies of loci with string classification
according to fitness differences. In Genetic and Evolutionary Computation (GECCO 2004),
pages 246–257, 2004.
[35] R. A. Watson, G. S. Hornby, and J. B. Pollack. Modeling building-block interdependency.
parallel problem solving from nature (PPSN-V), pages 97–106, 1998.
[36] R. A. Watson and J. B. Pollack. Hierarchically consistent test problems for genetic algorithms:
Summary and additional results. In Late breaking papers at the genetic and evolutionary com-
putation conference, pages 292–297, 1999.
[37] S. Wright. Evolution and the genetics of population: A treatise. University of Chicago Press,
1968.
[38] T.-L. Yu, D. E. Goldberg, A. Yassine, and Y.-P. Chen. Genetic algorithm design inspired by
organizational theory: Pilot study of a dependency structure matrix driven genetic algorithm.
In Proceedings of Artificial Neural Networks in Engineering 2003 (ANNIE 2003), pages 327–
332, 2003.
19
ii. Distance-Based Bias in Model-Directed Optimization of Additively Decomposable Problems 
(Martin Pelikan and Mark Hauschild) 
In GAs, the relationships between variables are important because that treat variable into 
groups can reduce the population size which is needed to solve the problem. Some works try to 
calculate the distance between each pair of variables to judge that which of the variables must to 
be treated as a same group. The authors tried to describe a method that combines such a 
problem-specific distance metric with information mined from probabilistic models obtain in 
previous runs of speed, accuracy and reliability. Their experiment results showed that compared 
to other techniques for learning from experience put forward in the past, this technique is both 
more practical and more broadly applicable. 
 
2. GA Session 
A. Our presentation at session GA1 
We presented lastly in this session. The main purpose of our work to detect the existence of building 
blocks directly from the fitness function without performing GAs. To do so, this paper extends the 
convergence time model and the gambler's ruin model so they can be applied to a larger variety of problems. 
With proposed models, the number of fitness evaluations can be estimated for both of these two cases: 
(1)some genes are transferred together in crossover (treated as a building block); (2)the genes are 
transferred separately. Therefore, we can compare the number of fitness evaluations and identify the 
existence of building blocks for a large family of fitness functions without actually performing a genetic 
algorithm. Prof. Thierens and Rothlauf were interested in our work and asked some interesting questions. 
We also had dinner with them after the presentation and discussed some possible future work. 
 
3. Poster Session, Keynotes and DETA/PES/BIO Session 
A. Our presentation at poster session 
During the poster section, many participants are interested in our work because they are also studying 
the affective content via bio-sensors or some machine learning methods. Combining affective content and 
evolutionary computation to investing the relationship between music and video is a really attractive idea 
for many researchers in both ECs and multimedia. There were also several works related to evolutionary art. 
However, most of them are designed for artistic purpose, while our work is more practical in use. 
B. Interesting topics 
i. How to look inside the brain (Carl Schoonover) 
Carl is a very famous researcher due to his works on the understanding of the complicated 
neuron connections and interactions in our brain. In this lecture, he demonstrated how to illustrate 
the neuron circuits with the aids of some advanced tools such as Green Fluorescence Protein, 
Channel rhodopsin, and virus-mediated tracing of neuronal projections. In the Brainbow project, 
neurons are colored randomly to show the huge, complex, and beautiful structure in brain. Due to 
the colorized image, we can easily understand the connections and hierarchy among neuron 
circuits. He also demonstrates an impressive experiment called Optogenetics that uses optical 
fiber to send light signal into a specific region in mice in order to easily change the behavior of 
the mice. His works are really impressive and creative. With the advance in understanding the 
duration instead of Pareto dominance as main comparison criterion. With this selection scheme, NSGA-II 
and MO-CMA-ES with asynchronous steady-state reproduction schemes both find the Pareto front on the 
costly region where the original version do not find. The author finds a way to handle a problem from 
real-world application, but he conducts the experiment on artificial test function. To use this method on the 
real-world problem is left on future work. Parallelization is interesting, and seems simple at first glance. 
However, there are many practical issues when dealing with real world problem, which is interesting and 
worth further research. 
 
5. EMO (Evolutionary Multi-objective Optimization) Best Papers 
EMO mainstream techniques are mostly unfamiliar to our core concepts in GA/EDA research. Nevertheless, 
ideas in this field can give us some insights into our researches. We actually face multi-objective problems in 
many scenarios. Moreover, this track includes interesting topics such as co-evolutionary algorithms and 
evolutionary game theory. The best papers in this track thus are worth noting. 
A. Local Preference-inspired Co-evolutionary Algorithms (Rui Wang, Robin Purshouse, Peter 
Fleming) 
Preference-inspired co-evolutionary algorithms (PICEAs) are a new class of approaches to solving 
multi-objective problems. This paper proposes a new algorithm, local PICEA (LPICEA). The special fitness 
calculation method is the key point that PICEAs succeed. The modification proposed this paper is sort of 
like niching methods for other GAs/EDAs. They use a clustering technique on candidate solutions. We can 
adopt the concept to preserve potential solutions. 
B. Equitable Equilibrium: Evolutionary Detection (Réka Nagy, Mihai Alexanru Suciu, D. Dumitrescu) 
We are interested in the evolutionary game theory. In a multi-player game, many methods from 
different fields have been proposed to find a Nash equilibrium which provides both fair and efficient 
payoffs. This paper proposed a new technique to solve this kind of problems. In the aspect of EMO, we can 
regard this scenario as a multi-criteria optimization problem. This work is based on Lorenz equilibrium. The 
authors proposed Lorenz equilibrium in their previous work. A crowding based differential evolution (DE) 
method is proposed to detect the Lorenz-optimal solutions. DE. We could pay more attention to 
developments in DE. 
C. On the Properties of the R2 Indicator (Dimo Brockhoff, Heike Trautmann, Tobias Wagner) 
This paper is sort of a review paper. The R2 and the Hypervolume (HV) indicator represent two 
recommended approaches. While the HV indicator has been comprehensively analyzed, it focuses on 
investigations of the properties of the R2 indicator. Moreover, this paper presents the differences between 
R2 and HV indicators. For researches in EMO, this kind of integration is important. 
 
6. Conclusion 
There are many interesting issues in evolutionary computation. However, most of the posters and papers 
attended in the conference were more related to the application area, and fewer papers concentrate on the 
evolutionary computation theory. After attending this conference, we felt the essence to develop GA theory and to 
improve the efficiency of GA. We also seek insights into our researches from different fields such as PGA, DE, 
evolutionary game theory and EMO. Moreover, while presenting our papers and poster, we received many  
useful suggestions. We believe that these ideas from the conference would help our future work. 
100年度專題研究計畫研究成果彙整表 
計畫主持人：于天立 計畫編號：100-2221-E-002-233- 
計畫名稱：基因演算法中支援鏈結學習的小生境技術發展 2/2 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 7 7 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 1 1 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
