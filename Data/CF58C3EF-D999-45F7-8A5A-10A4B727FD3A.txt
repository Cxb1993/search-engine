國科會補助提升產業技術及人才培育研究計畫成果精簡報告 
學門領域：系統整合與應用 
計畫名稱：智慧型行動保全機器人 
計畫編號：NSC 94－2622－E－214－003－CC3 
執行期間：民國 94 年 5 月 1 日~95 年 6 月 30 日 
執行單位：義守大學電機系 
主 持 人：莊景文 
參與學生： 
姓   名 年   級 
(大學部、碩
士班、博士
班) 
已發表論文或已申請之專利 
(含大學部專題研究論文、碩博
士論文) 
工作內容 
吳昆澤 碩士班  硬體製作協助 
余承勳 碩士班  硬體製作協助 
    
合作企業簡介 
合作企業名稱：佩辰企業有限公司 
計畫聯絡人：蔡奉錡 
資本額：貳佰萬元 
產品簡介：工業監控軟體 
網址：              電話：(07)8126237 
研究摘要(500 字以內)： 
人才培育成果說明： 
技術研發成果說明： 
技術特點說明： 
可利用之產業及可開發之產品： 
推廣及運用的價值：如增加產值、增加附加價值或營利、增加投資/設廠、增
加就業人數………等。 
※ 備註：精簡報告係可供國科會立即公開之資料，並以四至十頁為原則，如
有圖片或照片請以附加檔案上傳，若涉及智財權、技術移轉案及專
利申請而需保密之資料，請勿揭露。 
Imaging”, AGV and “VisioMatic”. The substitution preserves personnel's arduous service, and 
provides a field new product ponder direction. 
 
人才培育成果說明： 
參與本計畫的研究人員獲得如下的訓練以及研發的經驗： 
1. 參與人員學習到影像處理的相關理論與實務應用。 
2. 參與人員學習到影像辨識的相關理論與實務應用。 
3. 參與人員學習到灰色預測理論的相關理論與實務應用。 
4. 參與人員學習到灰色模糊控制的相關理論與實務應用。 
5. 參與人員學習到自走車控制的相關理論與實務應用。 
6. 參與人員學習到灰色模糊控制的相關理論與實務應用。 
7. 參與人員學習到無線網路的相關理論與實務應用。 
8. 參與人員學習到網頁製作與無線網路的相關理論與實務應用。 
9. 參與人員學習到無線遙控電路的相關理論與實務應用。 
 
技術研發成果說明： 
本計畫中以 NB 為基礎，利用 webcam 做為視覺迴授工具，並製作相關的驅動電路雛
形版，完成一個以視覺導引的行動機器人雛形，其外觀圖如圖一所示。 
 
 
圖一、自走車雛形外觀圖 
目前該行動機器人已可在室內走廊自由行走，研究成果已在 IEEE 國際研討會中發表如
附件一，並另外有兩篇論文於國際期刊複審之中。 
 
技術特點說明： 
本計畫為了降低成本，本考量在室內環境低速運行的情況下，因此以印表機介面作為
Command
Feedback
Grey Prediction
Delay
+
_
( )1~ +ke
( ) ( )keke −+1~
( )ke
( ) ( )1−− keke
( )ke
+
+
( )ku∆
( )ku0
Control Signal
Upper-Layer Fuzzy Controller
Base-Layer Fuzzy Controller
 
圖四、兩層式灰色模糊控制器架構圖 
 
可利用之產業及可開發之產品： 
本計畫研發之技術與成果，目前已有雛形產生，廠商目前正致力於商品化，預計將先
推出教學用之行動機器人，之後再推廣至工業界。 
 
推廣及運用的價值：如增加產值、增加附加價值或營利、增加投資/設廠、增
加就業人數………等。 
如上一項所述，目前已有教育用行動機器人即將上市，預計將為參與廠商增加一年約
百萬的營利收入。 
classical fuzzy rule [3-4] [6-8], whose input variables are the
position error and the error difference. In order to correct the
error caused by the time spent by image processing, the
upper-layer fuzzy controller is used to correct the base-layer
fuzzy controller. The upper-layer consists of the two input
variables, which are the estimated error and the estimated error
difference. The Grey theory is used to predict the position error
at the time of finishing image process. The Grey theory is
proposed by Dr. Deng in 1982 [9]. Most of other predictive
rules need to collect the long time-series data to make up the
mathematic model. It will take lots of usage of memory and
calculation time. Different from these rules, the Grey prediction
needs only four time-series data to estimate the next position
[3-4] [9-13]. The Grey theory is belonged to the piecewise
estimation. Hence, this rule is suitable for on-line and
simultaneous estimation work. The novel control rule will guide
the UAV to drive on the lanes based on vision feedback without
swinging phenomenon.
Finally, an experimental UAV is developed to examine the
proposed control rule in this paper. The experimental results
show the good performance of vision-based automatically
driving. The results also show the practical capability of the
proposed rule in the intelligent transportation systems.
II. IMAGE PROCESSING
The subject of the image processing is to figure out the
necessary information from the grabbed image. In order to
along the lane, the driving direction has to be decided firstly.
Fortunately, the objects of the road and both sides have obvious
or easy differences to come to conduct to distinguish, such as
the asphalt road and meadow. Hence, the first step of image
processing is to isolate the obviously distinguishing targets in
the color image. The simplest method is to specify the
thresholding interval for each of the three color components.
Then, color thresholding converts a color image to a binary
image. The pixels of the distinguishing targets are set to 1, the
others are set to 0. According to the driving speed of vehicle, the
search paths are specified to be two horizontal lines drawn
across the image. The edge detection process will look for edges
along the search paths among the binary image. Because of the
width, there are two points found in the lane mark. The next step
is to find the center pixel of the inner two edge point on the each
search path. The diagram of image processing can be shown in
Fig. 2.
Fig. 2 Image Processing
According to these two center points shown in Fig. 3, the
driving direction can be determined as the angle from vertical
by the following eq. (1).
 











 
DownUpUp
DownUp
YYY
XX
2
1
tan 1 (1)
Fig. 3 Determination of Driving Direction
According the above mentioned method, the experimental
result of image processing is shown in Fig. 4. Usually there are
black baseboards in the bottom of the sidewall of corridor, as
shown in Fig. 4a. Hence, let the baseboard be the distinguishing
target in image processing. The thresholding interval is
specified as (30~75) for each color component. After
thresholding operation, the particles of the baseboards are set to
1, the background is set to 0. The color image converting to
binary image result is shown in Fig. 4b. The two adaptive search
paths are defined in Fig. 4c. The edge points and the inner center
points are figured out. Using eq. (1), the angle from vertical, that
is the driving direction, can be decided in Fig. 4d.
IEEE ICSS2005 International Conference On Systems & Signals 
~ 239 ~
 
 

 
 

 
 

 
 




































































kE
kE
kE
km
km
km
km
km
km
km
km
km
TT
)0(
)0(
)0(
)1(
)1(
)1(
1
)1(
)1(
)1(
)1(
)1(
)1(
1
2
1
11
12
1
11
12
1
11
12
b
a
(9)
Once obtaining the parameters of the Grey Model, the next
status can be estimated like eq. (10).
  
a5.01
ab
1~
)0(
)0(

 keke (10)
and
   Bias1~1~ )0(  keke
C. The Grey-Fuzzy-Fuzzy Control
The novel control scheme is developed based on the above
mentioned control rules. The error ke and the error
difference    1 keke compose the base-layer fuzzy
controller. The base-fuzzy controller plays the main role of
generating basic guidance signal ku0 . Due to the error
caused by the time from fetching image to making image
information, the Grey prediction is used to compensate the
possible error. The estimated error  1~ ke means the error at
the time of making image information. Then, by the estimated
error  1~ ke and the estimated error difference
   keke 1~ , the upper-layer fuzzy controller figures out
the correcting signal ku to correct the base-layer fuzzy
controller. The detailed diagram of the Grey-Fuzzy-Fuzzy
control is shown in Fig. 6.
Fig. 6 Diagram of Grey-Fuzzy-Fuzzy Control
IV. EXPERIMENTAL UNMANNED AUTOMATIC VEHICLE
In order to examine the potential of the proposed control
scheme, an experimental UAV is developed in this paper. The
hardware diagram is shown in Fig. 7.
WebCAM
Notebook
Unmanned Vehicle
PWM Circuit
Printer Port Cable
Fig. 7 Experimental Unmanned Automatic Vehicle
The notebook of the Pentium grade deals with the hardware
input/output control and the necessary software calculation of
the image processing and the proposed controller. The human
machine interface is programmed by the software of LabVIEW
and Matlab/Simulink. A web cam is connected with the
notebook by the USB connector, which is used to grab image of
front direction of vehicle. Through the printer port, the 8-bits
pulse width modulator prototype board is used to control the
both DC motors drive the both-side wheels. The P89C51RD2H
IC is used to deal with the communication and the both PWM
signals output. The battery for car is used to support the
necessary electrical power for the circuit. The detailed
schematic diagram is shown in Fig. 8. The sampling interval is
set to 500ms. The maximum speed of the UAV is 1km/hr.
Fig. 8 Schematic Diagram of PWM Circuit
V. EXPERIMENTAL RESULTS
The experiment is carried out in the corridor of the teaching
building of I-Shou University in Taiwan. The moving ahead
speed of the UAV is maintained at the maximum speed that is
1km/hr. By mechanical vision-based distinguishing the
baseboard of both side-walls, the UAV moves along the center
of the corridor. The experimental photographs are shown in Fig.
9.
Fig. 9 Experimental Photographs
The PID control rule is used to compare with the proposed
control scheme. Fig. 10 shows the experimental results of both
the PID and the Grey-Fuzzy-Fuzzy controllers while
maintaining the speed at 1km/hr. The initial angle from vertical
is set to 45. The PID controller will cause the obviously
swinging driving phenomenon. The Grey-Fuzzy-Fuzzy
IEEE ICSS2005 International Conference On Systems & Signals 
~ 241 ~
