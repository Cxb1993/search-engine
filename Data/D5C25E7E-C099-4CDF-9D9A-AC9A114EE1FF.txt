行政院國家科學委員會補助專題研究計畫成果報告 
應用馬氏田口系統與粒子群最佳化演算法於非平衡資料分類
模式之建構-實證與討論(I) 
 
計畫類別：■個別型計畫  □整合型計畫 
計畫編號：NSC －99－2221－E－030－004 
執行期間：99 年 08 月 01 日 至 100 年 07 月 31 日 
 
 
計畫主持人：李天行 
共同主持人： 
計畫參與人員：謝弘一、陳麒文、連甲玫 
 
執行單位：輔仁大學企業管理學系 
 
 
中  華  民  國 1 0 0 年  1 0 月  1  日
行政院國家科學委員會專題研究計畫成果報告 
3 
由於資料探勘技術漸受重視，其技術愈趨成熟，所應用之範圍亦日趨廣泛，研究者遂將
目光聚焦於類別不均(class imbalance)問題，將其納入機器學習的研究議題。雖然類別不均的
問題存在已久，但卻直到近年才逐漸受到機器學習領域的重視，有越來越多的學者發現他們
所研究的資料中某些類別的樣本數占了樣本總數的極大比例，而相較之下其他類別樣本所占
的比例卻微乎其微，具有類別不均的特性，然而多數標準的分類器如決策樹、鑑別分析、神
經網路等分類工具，通常假設訓練樣本的類別間分配均勻(balanced distribution)，因此模型易
受佔樣本多數的主要類別(majority class)影響，而忽略佔樣本少數的次要類別(minority class)，
造成分類器過度適配(overfit)於主要類別，在主要類別上得到極高的分類正確率，但卻無法正
確辨別出次要類別，甚至將次要類別的樣本視為雜訊，且在建構模型時將其完全忽略，使得
模型績效不彰(Chawla et al., 2004；Su & Hsiao, 2007；Xie & Qiu, 2007)。在許多實例中都可發
現類別不均的問題，主要類別與次要類別之樣本數比可能是 1:10，1：100，1：1000，和 1：
10000，甚至是更高的比例(Chawla et al., 2004；Wasikowski, 2009)，實務應用領域包括：詐欺
偵測(Phua et al., 2004)、風險管理(Huang et al., 2006)、文件分類(Liu et al., 2009；Sun et al., 
2009)、醫療診斷(Cohen et al., 2006；Mazurowski et al., 2008；Thongkam et al., 2009)等皆存在
類別不均現象。 
目前針對類別不均問題所提出的各種解決方案，分別從資料層面和演算法兩種方向進行
探討(Batista et al., 2004；Guo & Viktor, 2004；Phua et al., 2004)。資料層面方法的主要概念是
以抽樣方法重複抽取 (oversampling)次要類別的樣本或對主要類別的樣本縮減取樣
(undersampling)，以平衡類別的分配，但前者可能造成雜訊，後者則可能刪減某些重要資訊。
演算法方面包括透過調整成本矩陣(cost matrices) 對次要類別分類錯誤的情況設定較高的誤
置成本，和改變門檻值等方法(Chawla et al., 2004；Grzymala-Busse et al., 2004；Huang et al., 
2004)，然而兩種方法皆可能導致訓練樣本的過度適配。演算法方面尚有一研究趨式，係以辨
識基礎(recognition-based)的分類方式，針對單一類別進行訓練學習，建構分類模型；此種方
法的概念為：若模型能一般化到新的觀察值，則此新觀察值必屬於建構模型所使用的類別，
否則即為模型外的另一類別(Japkowicz et al., 1995)。單一類別支援向量機(one-class SVM, 
one-class support vector machines)是其中最常見的工具，單一類別 SVM 模型優於同時使用兩
種類別所建構的 SVM 模型，且單一類別的學習方式特別適用於由高維度雜訊特徵空間(high 
dimensional noisy feature space)所構成的類別不均資料(Raskutti & Kowalczyk, 2004)；但也有學
者抱持相反的意見，認為 one-class SVM 對學習參數(learning parameters)和核心(kernel)函數過
於敏感，無法得到穩定的分類表現(Manevitz & Yousef, 2002)。其他常見的工具尚包括由神經
網路所發展來的自編碼類神經網路(autoencoder neural networks, AENN or autoencoder)，其只使
用單一類別的資料建立模型，屬於非監督式的學習方法，當資料空間是 multimodal 時，AENN
優於使用兩種類別建立模型的多層感知器(multi-layer perceptrons, MLP) (Japkowicz, 2001)。 
除了 one-class SVM 與 AENN，近來馬氏─田口系統(Mahalanobis-Taguchi system, MTS)
逐漸受到注意。MTS 為田口玄一博士針對多變量資料提出診斷與預測之分類新技術，由於其
並非直接自訓練樣本中學習，而是使用單一類別樣本，並藉由建立連續型的衡量量表進行分
類器建構，因此 MTS 模型的架構不會受資料分配影響，此特色有助於克服類別不均的問題，
因此近來亦有學者將 MTS 應用於類別不均資料之分類任務(Su & Hsiao, 2007)。MTS 尚有許
多特點，使其不同於其他典型的多變量工具，包括其以資料本身為基礎進行分析，而非源於
機率理論，因此不需對自變數的分配做任何假設(Taguchi et al., 2001；Taguchi & Jugulum, 
5 
資料探勘技術係結合資訊科技與統計專業兩大領域而得之新興科技，藉由電腦強大的運
算能力與各學科的專業知識，從現存大量資料或資料庫中，萃取內隱難見、未知(或超乎想
像)，且深具價值的資訊。是當前資料(庫)應用領域中極為熱門且廣為使用的重要技術，更榮
膺美國麻省理工學院(MIT)於 2001 年初之科技評論雜誌(technology review)，評選為二十一世
紀影響人類生活最大之十項新興科技。由表 1 即可發現，資料探勘與人腦機器介面、自然語
言辨識等，共列為未來十大重要科技。 
有關資料探勘的定義，依據相關文獻的解釋，大體一致。Berry & Linoff (1997)認為它是
利用自動學習或經驗配合等方式進行分析，藉以找尋、獲得有意義的關係或法則。Cabena et al. 
(1997)定義資料探勘係將前所未知且有效的資訊，自大型資料庫中萃取而得的過程，並將所
得之有用資訊提供予決策者，作為決策制定之參考依據。Grupe & Owrang (1995)認為資料探
勘是應用於既有的資料庫中，從而發掘新的事實，抑或發現目前尚未知曉的新關係。Frawley 
et al. (1991)指出進行資料探勘時，可能無法以直覺方式探掘出隱含於資料中的知識或相關
性，而必須經過特殊處理或特殊的工具技術，方能發現知識。 
表 1、科技評論雜誌預測未來影響人類之十大新興科技趨勢 
 人腦機器介面 
(Brain-Machine Interface) 
 自然語言辨識 
(Natural Language Processing) 
 塑膠晶片 
(Flexible Transistors) 
 微光電學 
(Microphotonics) 
 資料探勘 
(Data Mining) 
 公開程式碼 
(Untangling Code) 
 數位權利管理 
(Digital Rights Management) 
 機器人設計 
(Robot Design) 
 生物辨識學 
(Biometrics) 
 微流體學 
(Microfluidics) 
Note：  from “The Technology Review Ten” by MIT Technology Review, 2001, MIT 
Technology Review. Retrieved December 11, 2001, from http:// www. 
technologyreview.com/magazine/jan01/tr10_toc.asp. 
資料探勘與傳統資料分析的相異處，在於資料探勘不需事先對資料提出假設，而是在其
分析的過程中探勘出資料存在的各項條件，因此更能真實地反映出資料的隱藏特徵(Cios et al., 
1998)。資料探勘主要針對不同的議題及資料型態，如預測模式 (prediction)、分類問題
(classification)、資料摘要(summarization)、相依模式(dependency modeling)以及變動與偏差偵
測(change and deviation detection)等(Fayyad et al., 1996)，賦予相關的解決方案，是一個分析技
術的名詞總稱。而其範圍包括了資料視覺化(data visualization)、分類、關聯性法則(association 
rules)、集群分析(clustering)、序列分析(sequential patterns)、時間序列(time series)、機器學習
(machine learning)及其他統計技術(statistical techniques)等。由於近年來資料探勘技術漸受重
視，其所應用範圍也因之與增日廣。目前資料探勘技術所應用的領域，包含了天文，地質、
經濟、商業、行銷、工業、體育、生物、醫學等相關學門。 
 
7 
各自建構模型，證明 one-class SVM 模型優於同時使用兩種類別所建構的模型，並發現單一類
別的學習方式特別適用由高維度雜訊特徵空間(high dimensional noisy feature space)所構成的
類別不均資料。Japkowicz (2001)研究發現當資料空間是 multimodal 時，autoencoder 優於使用
兩種類別建立模型的多層感知器(multi-layer perceptrons, MLP)。 
如前所述，在類別不均的情況下，以整體正確率來衡量模型分類表現的方法有失偏頗，
故有許多學者針對分類模型的評估法則進行討論，建議以作業特性曲線(receiver operating 
characteristic curve, ROC curve)與成本曲線(cost curve)為衡量標準(Drummond & Holte, 2001；
Fawcett, 2003；Furnkranz & Flach, 2003；Provost & Fawcett, 2001)，其他常見的方法包括利用
精確率(precision)、召回率(recall)計算的 F 測量值(F-measure) (Manevitza & Yousef, 2002；
Manevitza & Yousef, 2007)，以及考慮敏感度(sensitivity)和特異度(speciticity)的 g 平均(g-means)
和相對敏感度(relative sensitivity, RS)兩種指標(Akbani et al., 2004；Guo & Viktor, 2004；Su & 
Hsiao, 2007；Wu & Chang, 2005)。 
(三) 模型建模工具 
本研究使用之兩個實證資料庫，皆為銀行信用卡之客戶授信資料，而是否授與顧客信用
之決策，可被處理成資料探勘中的分類(classification)問題，針對分類(classification)問題之處
理，在學術上已有多種工具可供應用，可概分為傳統統計、無母數及人工智慧(artificial 
intelligence, AI)兩大類： 
1. 傳統統計 
鑑別分析係由 Fisher 於 1930 年代中期所提出之劃分群體技術，其原理是根據預測變數某
些特性，將研究對象區分為兩個以上的群體。藉由尋找預測變數之線性組合，使組間差異平
方和相對於組內差異平方和(或總差異平方和)比值最大，而每一線性組合與先前已獲線性組
合均不相關(邱志洲、李天行、周宇超、呂奇傑，2002)，目標係建立一套判別模型，使此線
性判別模型具有區別群體的最佳效果。 
鑑別分析其背後蘊含嚴謹的統計假設，要求其所分析資料必須滿足常態性、獨立性及均
質性等相關統計假設條件 (Johnson &Wichern, 2002)，此外亦要求分析變數共變異矩陣
(covariance matrix)需具備均質性與常態性之特性。然而信用卡資料包含類別屬性，且其好客
戶與壞客戶間之共變異矩陣常違反均質性，而資料通常不具常態分配特性(West, 2000)，因此
鑑別分析於信用卡資料之適用性常遭到質疑，且鑑別結果往往不佳。 
羅吉斯迴歸並無如同鑑別分析一般之強烈前提假設，要求所有變數均須服從常態分配
等，然而由於羅吉斯迴歸與傳統的迴歸分析(regression analysis)性質類似，唯獨其反應變數
(response variable)屬於間斷變數，因此在應用上仍須符合一些傳統迴歸分析的假設，例如自變
數間若存在共線性問題(multi-collinearity)，則模型將會產生偏差之估計值，並且其標準差
(standard errors)將會異常擴大。因此，鑑別分析與羅吉斯迴歸兩者皆較適合於處理變數間符合
線性變數型態之分類問題。 
雖然鑑別分析與羅吉斯迴歸於信用卡資料之適用性常遭到質疑，且鑑別結果往往不佳，
然而由於傳統統計方法中，鑑別分析與羅吉斯迴歸為目前最廣為使用的信用評分建模工具
(Crook et al., 2007；Noh et al., 2005)。因此為求結果穩健，本研究亦將採用 LDA 與羅吉斯迴
歸作為行為評分模型之分析工具。此外，若將風險高低處理成多元分類問題時，必須使用多
9 
近來關於類神經網路研究皆顯示出其具有強大的樣式分類(pattern classification)與樣式辨
認(pattern recognition)能力(Vellido, Lisboa & Vaughan, 1999；Wong, Bodnovich & Selvi, 1997；
Zhang et al., 1998)，並可廣泛地應用於監督式(supervised)與非監督式(unsupervised)學習問題
中。由於類神經網路具嚴謹數學基礎、大量平行處理能力、容錯能力、高聯想力以及雜訊過
濾等特性，且能彌補傳統統計方法建構模型時要求的許多假設條件之不足(Rumelhart, Hinton 
& Williams, 1986)，因此廣泛應用於相關領域，如市場區隔、股價指數預測、匯率/利率預測、
破產預測、企業危機預警、信用預測、信用評分及保險問題中的道德危機等(李天行、唐筱菁，
2004；李天行、陳能靜、蔡榮裕，2001；Berry & Linoff, 2004；Fish, Barnes & Aiken, 1995；
Hann & Steurer, 1996； Vellido et al., 1999；Wong et al., 1997；Zhang et al., 1998)，並且得到良
好成效。 
直至今日，已有許多神經網路模型被提出，在眾多神經網路模型中，以使用前饋式
(feedforward)多層感知器並應用倒傳遞(back propagation)為演算法方式最常見且廣受歡迎
(Rumelhart, Widrow & Hehr, 1994)。所謂倒傳遞即比較期望輸出值與實際輸出值所產生誤差訊
號，經由網路向後逐層傳遞，進而調整每一層連接鍵權重，以降低誤差之過程。根據 Vellido et 
al. (1999)的研究指出，於 1992 到 1998 年間，在商業領域中使用類神經網路作為研究方法者，
約有 78%的比例採用倒傳遞類神經網路(back-propagation network, BPN)。由於倒傳遞類神經
網路具有學習準確度高、回想速度快等優點(Rumelhart et al., 1986)，故本研究亦採用倒傳遞類
神經網路作為行為評分模型之分析工具。 
(2) 支援向量機 
支援向量機(SVM)是一種以統計學習理論(statistical learning theory)為基礎所發展出來的
新興分類工具。取代最小化訓練樣本均方誤差(mean-square-error)的做法，支援向量機係以結
構風險最小化原理(structural risk minimization inductive principle)為基礎，藉由使群體間點之邊
界(margin)極大化方式，解決凸二次規劃(convex quadratic programming)問題。若以黑、白兩
色圓點，分別表示兩種不同資料類型，如圖 2 (b)所示，原始支援向量機係用於處理二元分類
問題，其主要思維是在高維度的特徵空間(high-dimensional feature space)中尋找一個擁有最大
邊界之超平面(hyperplane)，以有效分隔兩種不同類型的資料。當面對非線性問題時，如圖 2 (a)
所示，SVM 的作法係將輸入向量 x 透過非線性映像(mapping)的轉換方式，使其對應至高維度
特徵空間中，然後再於該特徵空間之輸入向量，建構出最佳分割超平面。 
 
 
 
 
 
 
(a) 
 
 
 
 
 
 
(b) 
圖 2、SVM 分類示意圖 
最佳超平面 
邊界 
非線性映像轉換
11 
 
 
 
 
 
 
圖 3、多變量診斷系統 
資料來源：The Mahalanobis-Taguchi Strategy. A pattern technology system (p. 
5), by G. Taguchi & R. Jugulum, 2002, NY: John Wiley & Sons. 
傳統馬氏距離用於衡量已知與未知樣本集合間的相似性，Taguchi 將調整過之馬氏距離導
入多變量診斷系統，藉由建構出的尺度進行系統中個體監測(Taguchi & Jugulum, 2000)。假設
系統中存在 k 個變數的 n 筆樣本，第 j 筆觀測樣本的調整後馬氏距離如方程式 2 所示： 
1(1/ ) Tj ij ijMD k
 Z C Z  (2) 
其中 1, ...,i k    ， 1, ...,j n  。方程式 2 的符號說明如下： 
1 2( , ,..., ) ( ) /iij j j kj ij iZ Z Z X S  Z X ，係由 Xij 向量求得之標準化向量。 
C-1：為相關矩陣之反矩陣 
T
ijZ ：標準化向量 Zij之轉置矩陣 
iX ：第 i 個變數之平均數 
Si：第 i 個變數之標準差 
馬氏田口系統的執行程序，首先必須定義出正常群體(或稱為參考群體，reference group)，
並利用正常群體計算平均數、標準差與相關矩陣，據以建構出馬氏空間。當樣本數 n 夠大且
所有 Xij服從常態分配，利用 n 筆正常樣本求出的原始馬氏距離服從自由度為 k 之卡方分配，
因此可知調整後之馬氏距離，其平均數趨近於 1，故而馬氏空間又稱為單位空間(unit space)。
利用參考群體建構出的馬氏空間可視為一基準，如圖 4，當樣本來自正常群體時，其調整後
馬氏距離較小，而當有一樣本並非來自正常樣本時，則其利用參考群體所求之平均數、標準
差與相關矩陣產生之調整後馬氏距離會變大。 
診斷系統 
變數 (X1, X2,…, Xk)
噪音因子 
輸出訊號 (y) 輸入訊號 (M) 
13 
表 2、第 i 類案例歸類矩陣 
第 i 類 是否位於區間內 是 否 
是 
否 
為 
類 
別 
i 
是 A(i) B(i) 
否 C(i) D(i) 
在表 2 中，A 表示屬於類別 i 且位於區間內之案例數，B 表示屬於類別 i 卻位於區間外之
案例數，C 表示不屬於類別 i 卻位於區間內之案例數，而 D 則為不屬於類別 i 且位於區間外
之案例數，其中 A 與 D 為歸類正確，而 B 與 C 則為歸類錯誤。進行案例篩選時，由於類別 i
的案例 A 集合中僅包含該類別，因此進行訓練案例篩選時，係取 4 組 A(i)之聯集。本研究將實
驗此訓練集合篩選方案，對分類鑑別率將產生何種影響。 
四、 結果與討論 
本研究採用 LDA、LR 與 SVM 等資料探勘技術建構分類模型，並針對類別不均問題，利
用 MTS 進行案例篩選，並希望提升其鑑別正確率。為降低模型建構過程中出現樣本偏誤現
象，並確保模型穩健性(robustness)，本研究採用 5-fold 交叉驗證(5-fold cross-validation)方式進
行模型建構，因此每種工具都將建構 5 個模型。由於過去研究指出，多元適應性雲形迴歸
(multiple adaptive regression splines, MARS)擁有優異之變數篩選能力，利用 MARS 篩選出之
重要變投入各分類模式，除可節省模型建構時間，更可能增加其分類績效，因此各實驗將分
別採用所有變數與 MARS 篩選所得重要變數進行模型建構。實驗一首先利用加州大學 UCI
資料庫提供之 German credit data 測試資料集合進行可行性研究；實驗二則利用個案銀行提供
之信用卡客戶資料進行研究，以了解 MTS 篩選方案對建構時間成本與分類鑑別率之影響。 
表 2 為 German credit data 之實證結果，由表中可知，LDA、LR 與 SVM 訓練集合之整體
鑑別率指標分別為 73.23%、78.05%與 78.58%，而測試集合之整體鑑別率指標分別為 71.50%、
76.30%與 75.60%。由於本研究使用之實證資料屬於類別不均之資料庫，如果單採整體鑑別率
(overall accuracy, O)進行實證結果比較，可能扭曲分類結果，因此整體鑑率指標僅列做參考，
而以幾合平均(g-mean, G)指標進行實證結果比較。由表 2 可知，LDA、LR 與 SVM 訓練集合
之 G 指標分別為 73.50%、67.65%與 67.94%，而測試集合之 G 指標分別為 70.70%、65.06%
與 63.49%，而利用本研究提出之 MTS 篩選方案，可提升 LR 與 SVM 兩工具之 G 鑑別率，分
別改善 0.24%與 3.4%，因此可證明本研究提出篩選方案之可行性。 
15 
由表 4 可知，原始訓練集合 5-fold 交叉驗證於 LDA、MLR 與 SVM 之測試集合平均 G 指
標鑑別率分別為 68.00%、89.58%與 92.50%，而利用 MTS 進行案例篩選，所得 5-fold 交叉驗
證於 LDA、MLR 與 SVM 之測試集合平均 G 指標鑑別率分別為 73.81%、91.09%與 92.86%。
此外，除了 G 鑑別指標外，三種工具於 MTS 篩選方案所得之平均整體鑑別率指標均可觀察
到績效改善現象。 
五、 計劃成果自評 
類別不均問題存在已久，然而多數標準的分類器如決策樹、鑑別分析、神經網路等分類
工具，通常假設訓練樣本的類別間分配均勻，因此模型易受佔樣本多數的主要類別影響，而
忽略佔樣本少數的次要類別，造成分類器過度適配於主要類別，使得模型績效不彰。本研究
提出一以 MTS 作為訓練案例選擇工具之模式建構程序，以解決分類任務於前述類別不均之不
足之處。實證結果顯示，以 MTS 作為訓練子資料集合篩選工具之測試集合分類指標明顯優於
原始集合之鑑別結果，因此本研究提出之 MTS 案例篩選方案，可有效應用於類別不均之分類
問題。 
 
參考文獻 
[1]  李天行、唐筱菁(2004)，「整合傳統財務指標與智慧資本以建構企業危機預警系統─類
神經網路與 MARS 之應用」，資訊管理學報，11(2)，161-190。 
[2]  李天行、陳能靜、蔡榮裕(2001)，「現貨盤後期貨交易資訊內涵之研究─以新加坡交易
所日經 225 指數期貨為例」，管理學報，18，567- 588。 
[3]  邱志洲、李天行、周宇超、呂奇傑(2002)，「整合鑑別分析與類神經網路在資料探勘上
之應用」，工業工程學刊，19(2)，9-22。 
[4]  Akbani, R., Kwek, S., & Japkowicz, N. (2004). Applying support vector machines to 
imbalanced datasets. Proceeding of 15th European Conference on Machine Learning 
(ECML ’04), 39–50. 
[5]  Batista, G., Prati, R.C., & Monard, M.C. (2004). A study of the behavior of several methods 
for balancing machine learning training data. SIGKDD Explorations, 6(1), 20–29. 
[6]  Berry, M. J. & Linoff, G. (1997). Data mining techniques : For marketing, sales, and 
customer support. New York, NY: John Wiley & Sons, Inc. 
[7]  Burges C. J. C. (1998). A tutorial on support vector machines for pattern recognition. Data 
Mining and Knowledge Discovery, 2(2), 121-167. 
[8]  Cabena, P., Hadjinaian, P.O., Stadler, R., Verhees, J., & Zanasi, A. (1997). Discovering data 
mining from concept to implementation. Upper Saddle River, NJ: Prentice-Hall. 
[9]  Chawla, N.V., Japkowicz, N., & Kolcz, A. (2004). Editorial: special issue on learning from 
imbalanced data sets. SIGKDD Explorations, 6(1), 1–6. 
[10]  Chen, W.-H., & Shih, J.-Y. (2006). A study of Taiwan’s issuer credit rating systems using 
support vector machines. Expert Systems with Applications, 30(3), 427-435. 
17 
[28]  Huang, C. L., Chen, M. C., & Wang, C. J. (2007). Credit scoring with a data mining 
approach based on support vector machines. Expert Systems with Applications, 33(4), 
847-856. 
[29]  Huang, K., Yang, H., King, I., & Lyu, M. (2004). Learning classifiers from imbalanced data 
based on biased minimax probability machine. Proceedings of IEEE CS Conf. Computer 
Vision and Pattern Recognition (CVPR ’04), 558–563. 
[30]  Huang, Z., Chen, H., Hsu, C.-J., Chen, W.-H., & Wu, S. (2004). Credit rating analysis with 
support vector machines and neural networks: A market comparative study. Decision 
Support Systems, 37(4), 543-558. 
[31]  Japkowicz, N. (2000b). The class imbalance problem: Significance and strategies. 
Proceedings of the 2000 International Conference on Artificial Intelligence (ICAI’ 2000). 
[32]  Japkowicz, N. (2001). Supervised versus unsupervised binary learning by feedforward 
neural networks. Machine Learning, 42(1-2), 97–122. 
[33]  Japkowicz, N., Myers, C., & Gluck, M. (1995). A novelty detection approach to 
classification. Proceedings of the Fourteenth Joint Conference on Artificial Intelligence, 
518–523. 
[34]  Japkowicz, N., Myers, C., & Gluck, M. (1995). A novelty detection approach to 
classification. Proceedings of the Fourteenth Joint Conference on Artificial Intelligence, 
518–523. 
[35]  Johnson, R. A., & Wichern, D. W. (2002). Applied multivariate statistical analysis (5th ed.). 
NY: Prentice-Hall. 
[36]  Li, S.-T., Shiue, W., & Huang, M.-H. (2006). The evaluation of consumer loans using 
support vector machines. Expert Systems with Applications, 30(4), 772-782. 
[37]  Liu, Y., Loh, H.T., & Sun, A. (2009). Imbalanced text classification: A term weighting 
approach. Expert Systems with Applications, 36(1), 690–701. 
[38]  Luo, S.-T., Cheng, B.-W., & Hsieh, C.-H. (2009). Prediction model building with 
clustering-launched classification and support vector machines in credit scoring. Expert 
Systems with Applications, 36(4), 7562-7566. 
[39]  Manevitz, L.M., & Yousef, M. (2002). One-class SVMs for document classification. 
Journal of Machine Learning Research, 2, 139–154. 
[40]  Manevitza, L., & Yousef, M. (2007). One-class document classification via neural networks. 
Neurocomputing, 70, 1466–1481. 
[41]  Mazurowski, M.A., Habas, P.A., Zurada, J.M., Lo, J.Y., Baker, J.A., & Tourassi, G.D. (2008). 
Training neural network classifiers for medical decision making: The effects of imbalanced 
datasets on classification performance. Neural Networks, 21(2-3), 427–436. 
[42]  Noh, H. J., Roh, T. H., & Han, I. (2005). Prognostic personal credit risk model considering 
censored information. Expert Systems with Applications, 28(4), 753-762. 
[43]  Phua, C., Alahakoon, D., & Lee, V. (2004). Minority report in fraud detection: Classification 
of skewed data. SIGKDD Explorations, 6(1), 50–59. 
19 
[62]  Wu, G., & Chang, E.Y. (2005). KBA: Kernel boundary alignment considering imbalanced 
data distribution. IEEE Transactions on Knowledge and Data Engineering, 17(6), 
786–794. 
[63]  Xie, J., & Qiu, Z. (2007). The effect of imbalanced data sets on LDA: A theoretical and 
empirical analysis. Pattern Recognition, 40(2), 557–562. 
[64]  Yu, L., Yue, W., Wang, S., & Lai, K. K. (2010). Support vector machine based multiagent 
ensemble learning for credit risk evaluation. Expert Systems with Applications, 37(2), 
1351-1360. 
[65]  Zhang, G., Patuwo, B. E., & Hu, M. Y. (1998). Forecasting with artificial neural networks: 
The state of the Art. International Journal of Forecasting, 14, 35-62. 
[66]  Zhou, Z.H., & Liu, X.Y. (2006). Training cost-sensitive neural networks with methods 
addressing the class imbalance problem. IEEE Trans Knowledge and Data Engineering, 
18(1), 63–77. 
 
 
either a ‘good credit’ group that is likely to repay financial 
obligation or a ‘bad credit’ group whose application should be 
denied because of its high possibility of defaulting on the 
financial obligation. Therefore credit scoring lies in the domain 
of the more general and widely discussed classification 
problems [4]. Credit scoring is done on the front end when new 
consumer applies for credit. On the other hand, behavioral 
scoring evaluates the credit risk of existing consumers based on 
the same principles. In building behavioral scoring models, one 
uses the credit scoring variables and includes others which 
describe the behavior [3].  
Behavioral scoring has gained more and more attention 
because the explosion of competition in recent years making it 
difficult to attract and retain profitable, low-risk customers. 
Generally, most business revenue, sometimes up to 90 percent, 
is being produced from repeat transactions with existing 
customers [2]. In addition, the financial health of customers 
may change over time; thus must be continuously monitored 
and managed. By forecasting their future performance, 
behavioral scoring models allow financial institutions to make 
decisions faster and better to retain creditworthy and valuable 
customers. 
Traditional research often treats credit scoring and 
behavioral models as binary classification problem, the 
approaches that might miss useful information [5]. In order to 
discover more knowledge for advanced credit risk management, 
multi-class classifiers are needed [6]. As a result, this study 
used multi-class models to build behavioral scoring models. 
III. RESEARCH METHODOLOGY 
A. Artificial Neural Networks 
A neural network, modeled following the neural activity in 
the human brain, is a computer-intensive, algorithmic 
procedure for transforming inputs into desired outputs using 
highly interconnected networks of relatively simple processing 
elements. Neural networks are increasingly found to be useful 
in modeling non-stationary processes due to their associated 
memory characteristics and generalization capabilities. Neural 
networks have been widely used in engineering, science, 
education, social research, medical research, business, finance, 
forecasting, and related fields. Neural networks have also been 
explored in handling credit and behavioral scoring problems [4] 
and the results show that the scoring accuracies of neural 
networks are better than those using traditional statistical and 
parametric approaches. 
B. Support Vector Machine 
SVM is a novel non-parametric statistical learning 
algorithm developed by Vapnik [7]. The original SVM was 
designed for solving the binary classification problem, and has 
gained popularity due to many attractive features and 
promising generalization performance. Based on the structured 
risk minimization (SRM) principle, SVM seeks to minimize an 
upper bound of the generalization error instead of the empirical 
risk minimization (ERM) principle implemented in most of the 
traditional neural network models. Generally, the neural 
network models may tend to fall into the problem of local 
minimum. On the other hand, the SVM will be equivalent to 
solve a linear constrained quadratic programming (QP) 
problem so that it can provide both global and unique solutions. 
In order to create a classifier, the basic principle of SVM is 
learning to find out a line or hyperplane between the two-class 
data set. If the margin is maximized, the hyperplane is called 
optimal separating hyperplane (OSH). When the data is not 
linearly separated, the SVM uses the kernel method to map the 
input data into a high-dimensional feature space via a nonlinear 
mapping, and then performs a linear separating between the 
two classes in this space.  
The SVM works very well when dealing with the high-
dimensional data and therefore avoids the curse of 
dimensionality problem. It has been widely used in modeling 
credit and behavioral scoring problems and preliminary 
evidence suggest support vector machines seem to be most 
accurate [8]. For a detailed introduction, the readers are 
referred to [7]. 
IV. EMPIRICAL STUDY 
The aim of this study is to explore the performance of 
behavioral scoring using three commonly discussed data 
mining techniques-LDA, BPN, and SVM. To demonstrate the 
effectiveness of behavioral scoring using the above-mentioned 
techniques, behavioral scoring tasks are performed on one bank 
credit card dataset in Taiwan. The dataset consists of totally 
10769 cardholders. Each cardholder in the dataset contains 41 
variables, such as demographics, credit history, account 
balances, payment history, etc., which are used to describe the 
cardmembers' characteristics, credit status as well as credit card 
usage behavior. The dataset are divided into four groups: 
transactor users, revolver users, inactive users without using 
their credit cards, and bad credit customers. The number of the 
four groups are 3835, 2567, 3884, and 483. Table I summarizes 
the distribution of the dataset. 
TABLE I.  DISTRIBUTION OF DEPENDENT VARIABLE 
Groups Description Frequency Percentage 
Group 1 Transactor users 3835 35.61%
Group 2 Revolver users 2567 23.84%
Group 3 Inactive users 3884 36.07%
Group 4 Bad credit customers 483 4.49%
Total  10769 100.0% 
 
In order to minimize the possible bias associated with the 
random sampling of the training and testing samples, 
researchers tend to use n-fold cross-validation scheme in 
evaluating the classification capability of the built model. In n-
fold cross-validation, the entire dataset is randomly split into n 
mutually exclusively subsets (also called folds) of 
approximately equal size with respect to the ratios of different 
populations. The classification model will then be trained and 
tested n times. Each time the model is built using (n－1) folds 
as the training sample and the remaining single fold is retained 
for testing. The training sample is used to estimate the 
behavioral scoring model’s parameters while the retained 
holdout sample is used to test the generalization capability of 
the built model. The overall classification accuracy of the built 
fold, with average accuracy of 96.91%, while group 2 has the 
worse classification accuracy ranging from 88.50% to 93.00%. 
TABLE IV.  CROSS-VALIDATION RESULTS OF THE SVM MODELS 
Behavioral scoring results 
Fold 
number {1-1} {2-2} {3-3} {4-4} 
Average 
correct 
classification 
rate 
1 95.83% (735/767) 
89.28% 
(458/513) 
94.98% 
(738/777) 
97.94% 
(95/97) 
94.06% 
(2026/2154)
2 96.22% (738/767) 
89.47% 
(459/513) 
94.85% 
(736/777) 
94.85% 
(92/97) 
94.05% 
(2025/2154)
3 95.05% (729/767) 
88.50% 
(454/513) 
94.34% 
(733/777) 
96.91% 
(94/97) 
93.31% 
(2010/2154)
4 95.96% (736/767) 
91.25% 
(469/514) 
95.37% 
(741/777) 
93.75% 
(90/96) 
94.52% 
(2036/2154)
5 95.70% (734/767) 
93.00% 
(478/514) 
95.10% 
(738/776) 
95.83% 
(92/96) 
94.84% 
(2042/2153)
Mean 95.75% 90.30% 94.93% 95.85% 94.16% 
 
D. Comparison of Results of Different Behavioral Models 
Finally, in order to evaluate the classification capabilities of 
the above three constructed behavioral scoring models, the 
summarized results can be shown in Table V. From the results 
revealed in Table V, we can conclude that the BPN model has 
the best behavioral scoring capability in terms of the average 
classification rate in comparison with LDA and SVM. In 
consideration of group classification accuracies, SVM achieved 
the best accuracy in both group 1 and 3; BPN achieved the best 
accuracy in both group 2, 4. 
TABLE V.  GROUP ACCURACY COMPARISONS  
Group 
Accuracy LDA BPN SVM 
Group 1 92.57% 95.72% 95.75% 
Group 2 73.86% 91.27% 90.30% 
Group 3 71.29% 94.77% 94.93% 
Group 4 93.17% 97.93% 95.85% 
Overall 80.46% 94.42% 94.16% 
 
V. CONCLUSIONS AND FUTURE RESEARCH 
Consumer credit risk management has gained more and 
more attention during the past few years due to the impact of 
serious financial crises. Behavioral scoring is a widely used 
tool for banks to continually assess the ongoing credit risks and 
consumer behavior of their existing customers. This paper 
investigates the classification capability of three modeling 
techniques in building behavioral scoring tasks. Experimental 
results showed that BPN model has better overall classification 
accuracy than those of the other models. However, the overall 
classification accuracy is not the only criterion to assess the 
capability of model. For example, if the business strategy of the 
bank is to make a black list on bad credit accounts, BPN model 
then can be used to accomplish this goal as it achieved the 
highest classification accuracy in group 4 (see Table V). On the 
other hand, if the business strategy is to identify the inactive 
customers who are at risk of being lost to a competitor, then 
SVM model should be used to conduct this task. 
Future studies may aim at collecting more important 
independent variables that will increase the behavioral scoring 
accuracies. Combining feature selection tools with 
classification techniques is also recommended. Integrating 
other artificial intelligence techniques, like fuzzy discriminant 
analysis, genetic algorithms and gray theory, with support 
vector machine in further improving the behavioral scoring 
accuracies may also being discussed. Other related topics about 
credit cards like customer retention, market basket analysis, 
profit scoring, and collection scoring models may also being 
investigated in future research works.  
 
REFERENCES 
[1] J.M. Donato, J.C. Schryver, G.C. Hinkel, R.L. Schmoyer Jr., N.W. 
Grady, and M.R. Leuze, “Mining multi-dimensional data for decision 
support,” Future Gener. Comp. Syst., vol. 15, pp. 433–441, 1999. 
[2] M. Banasiak and E. O'Hare, “Behavior scoring,” Bus. Credit, vol. 103, 
pp. 52–55, 2001. 
[3] L.C. Thomas, “A survey of credit and behavioural scoring: forecasting 
financial risk of lending to consumers,” Int. J. Forecast., vol. 16, pp. 
149–172, 2000. 
[4] T.S. Lee, C.C. Chiu, C.J. Lu, and I.F. Chen, “Credit scoring using the 
hybrid neural discriminant technique,” Expert Syst. Appl., vol. 23, pp. 
245–254, 2002. 
[5] H.J. Noh, T.H. Roh, and I. Han, “Prognostic personal credit risk model 
considering censored information,” Expert Syst. Appl., vol. 28, pp. 753–
762, 2005. 
[6] G. Kou, Y. Peng, Y. Shi, M. Wise, and W. Xu, “Discovering credit 
cardholders’ behavior by multiple criteria linear programming,” Ann. 
Oper. Res., vol. 135, pp. 261–274, 2005. 
[7] V.N. Vapnik, The Nature of Statistical Learning Theory, 2nd ed., NY: 
Springer. (2000). 
[8] J.N. Crook, D.B. Edelman, and L.C. Thomas, “Recent developments in 
consumer credit risk assessment,” Eur. J. Oper. Res., vol. 183, pp. 1447-
1465, 2007. 
[9] C.W. Hsu, C.C. Chang, and C.J. Lin, “A practical guide to support 
vector classification,” Technical Report, Department of Computer 
Science and Information Engineering, National Taiwan University, 2003. 
 
 
 6
 
圖1 Prof. Hugo de Garis 演講 
 
圖2 Prof. Peng 演講 
 8
而由此次研討會可知，大陸對於研討會以及會展相關產業非常重視，此次研討會有大陸政府的會展中心參與提供相關的
協助，這值得台灣參考，利用國際學術研討會開發潛在的觀光會展的商機。 
 
三、攜回資料名稱及內容 
 
CiSE 2010 會議議程、收錄論文全文之光碟片。 
99 年度專題研究計畫研究成果彙整表 
計畫主持人：李天行 計畫編號：99-2221-E-030-004- 
計畫名稱：應用馬氏田口系統與粒子群最佳化演算法於非平衡資料分類模式之建構-實證與討論(I) 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 1 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 2 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 3 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 0 1 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 1 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 3 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
