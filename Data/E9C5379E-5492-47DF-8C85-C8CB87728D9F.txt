 2 
processing, and mobile messenger. The 
purpose of this research is to develop an 
interactive space browsing system, in which 
user can browse the scene of interest in 
real-time, under a wireless environment on 
mobile devices. The main application is to 
provide user a photorealistic browsing 
system for outdoor or indoor scene of interest. 
However, rendering complex 3D scenes on 
mobile devices interactively is a challenge, 
due to that mobile devices are restrained by 
its limited computing power, memory 
capacity, and the lack of 3D rendering 
hardware to accelerate computation. This 
research therefore focuses on providing an 
image based walkthrough that renders scenes 
in real-time for handhelds with such limited 
computing capabilities. 
Our system is based on a Server/Client 
architecture, with a PC that has good 
computation power as the server, and users 
using mobile devices as the clients. Server 
collects photographs of a scene supplied by 
users, and synthesizes the scene by 
combining the photographs into a panorama, 
through detecting feature points and 
determining the parts of the scene that 
overlap in the photographs. To accommodate 
the limitations of mobile devices, server cuts 
the panorama into smaller parts of a suitable 
size and compresses them. The parts of 
interest are sent to the client, which is 
rendered along with the user interface using 
OpenGL|ES on the mobile device in 
real-time, as user browses through the 
panorama. Even though the technical 
approach for building our system is 
somewhat alike that of Google Street View, 
we allow real-time interaction with users to 
update the scene. Particularly, if a panorama 
has already been created, and user sends in a 
new photograph of the scene, server would 
compare the new photograph with the 
existing panorama, and determine the 
differences, then locally updates the 
panorama in places the differences had 
occurred. 
 
Keywords: mobile devices, image based 
walkthrough, panorama, OpenGL|ES, 
Google Street View 
 
二、前言 
 
The research aims to develop an image 
based walkthrough system allowing users to 
navigate the scene of interest under a 
wireless environment using mobile devices. 
It is developed based on Server/Client 
architecture. The generator stitches a series 
of overlapping photographs into a panorama 
of a scene after scene photographs are 
provided. On-demand transmission is 
developed for segmenting the panorama into 
smaller segments of a suitable size. The parts 
of interest are sent to client and rendered in 
real-time on user interface while a user 
browses the panorama. Hence, the data size 
is decreased at an average of 53.2% per 
transmission. It provides users a walkthrough 
environment with flexible and dynamic 
routes, which differs from Google Street 
View. Most current GPS navigation systems 
do not provide sufficient scene information. 
Hence, the proposed system can be applied 
and ported on such systems to display real 
world’s scene. 
 
三、緣由與目的 
 
As mobile phones have became 
ubiquitous over the past decade, many 
techniques and applications have been 
migrated into mobile devices providing new 
functionalities such as face morphing, online 
games, image processing, and mobile 
messenger. Its additional capabilities, such as 
photographing and video recording, and 
mobile quality become increasingly 
important [1]. However, limited hardware 
support and limited capabilities pose a big 
challenge while developing functions for 
mobile devices. Performing 3D graphics on 
mobile device needs much computing power 
and time, and requires much space for 
storage of geometrical data. 
On the other hand, image-based 
rendering (IBR) has been popularized and 
widely exploited for developing a 
walkthrough system. IBR is a technology that 
detects feature points between input images, 
and uses them to construct an image’s space 
of new viewpoints [2, 3, 4, 5]. IBR composes 
images of any location viewed in any 
direction by computing available 
photographs. Hence, even though the scene is 
 4 
uses the starting time value of each node to 
find the node's corresponding panorama and 
hot spot images in the other two tracks. 
Furthermore, they use camera panning and 
zooming actions to simulate the user 
navigation of the image-based virtual 
environment. Their system was implemented 
on computers with a lower computing power 
in 1995, and the mechanisms for their 
objectives are highly suitable for us to refer 
to when implementing on contemporary 
mobile devices with limited computing 
power.  
 
五、研究方法 
 
Our image based walkthrough system is 
an on-demand client-server based system. 
The overall processing flow is divided into 
offline and online parts as shown in Fig. 1(A) 
(see end of the report). Preprocessing unit 
processes scene photos user provided and 
stores them in the panorama database at 
offline part. Stitching and Panorama List 
Generator are involved in the preprocessing 
unit. Stitching is firstly to construct image 
based virtual environment. SIFT 
(Scale-Invariant Feature Transform) is 
exploited to match and blend adjacent input 
pictures. After stitching, a list of panoramas 
is created, each of which has a unique 
panorama id, panoramic picture, a list of 
panorama corresponding nodes, and 
panorama GPS coordinate in the panorama 
list. Panorama id is used to index the 
panoramic picture to enable our system to 
display panorama properly. A list of 
panorama corresponding nodes is used to 
construct the relationship between panoramas. 
Moreover, the relative relation of panorama 
nodes is also defined. Panorama GPS 
coordinate is used for creating UL-map and 
displaying the user location in virtual 
environment. 
At online part, user can connect to the 
server through wireless network. As 
illustrated in Fig. 1(B), the server contains 
two components: Request handler and User 
Information Storage. Request Handler 
processes client’s request and sends image 
files according to user’s request. A data 
streaming method is used to extract part of 
the panoramic image file needed by a user. 
Afterwards, it sends corresponding image file, 
walking cross information and user’s current 
location information calculated and extracted 
from panorama database to client, and then 
sends user’s current location to User 
Information Storage. 
Fig. 1(C) shows the architecture of 
client, which contains four components: 
Control Manager, Path Logger, Network 
Manager, and Renderer. At the beginning, 
server detects whether the user’s current 
location allows for walking cross panorama 
or not, and sends the message to client. If the 
message states that walking cross is allowed, 
Renderer will display a walking cross touch 
button for the user to walk cross other 
panoramas. Then Control Manager on the 
client side catches one of the two user 
moving modes, and sends the request to 
server through client’s Network Manager. 
Server then extract the corresponding part of 
panoramic image according to user 
movement, and sends the image with its 
panorama GPS coordinate to client. Finally, 
client’s Network Manager forwards the 
obtained image and coordinates to Renderer, 
which displays the corresponding image on 
the scene and draws user moving path from 
previous to current panorama coordinate with 
current location on UL-map. 
Due to the limitations of power and 
hardware capabilities of mobile device, 
several approaches are exploited to develop 
an image based walkthrough system for 
mobile devices. Methods of data streaming, 
detecting difference of images, and 
producing UL-map are described in this 
section. 
 
Data streaming method 
Data streaming method which is used 
for image data transmission brings the 
advantage of not having to resend a new 
image to client when user moves. Basically, 
the desired image is divided into many 
blocks of sub images, each of size 80*80 
pixels, and is transmitted separately to 
decrease network transmission bandwidth. 
Besides, the speed of user navigation is 
determined using the time interval between 
user’s touch pen state changes. Client only 
has to send the obtained vector of user’s 
movement to server. The user moving 
 6 
minimum and maximum GPS 
coordinates is detected by searching 
from each panorama GPS coordinate, 
and each coordinate is normalized to 
a normal number form. The size of 
bounding box is then scaled to 
UL-map size. 
Step3. Map GPS to UL-map. After Step 2, 
the GPS coordinate bounding box of 
UL-map size is mapped to UL-map 
relative coordinate on mobile screen. 
 
At the beginning of UL-map drawing 
flow, client sends user moving action, 
panning or walking cross, to server, and both 
server and client check the user action 
whether he/she is walking cross or not at the 
same time. On the server side, if the received 
user action is walking cross, server will 
check whether the user’s current panorama 
coordinate has been transformed through the 
steps above. On the client side, if user has 
completed walking cross, it will assign the 
past transformed coordinate to previous point, 
and upon receiving relative current 
transformed coordinate sent from server, it 
draws a line from previous point to current 
point with the point of current user location. 
 
六、結果與討論 
 
The system is based on Server/Client 
architecture, with the client implemented on 
HTC P3651 device runs Windows Mobile 6.0 
on a Qualcomm MSM 7200 400 MHz with 
128MB main memory. A series of 
experimental results for testing performance 
of the proposed approaches are reported in 
this section. 
 
Performance of using data streaming 
method 
A direct way to evaluate the 
performance of proposed data streaming 
methods is to test the decreasing amount of 
network transmission. Table 1 (see end of the 
report) indicates comparisons of data 
transmission using original method without 
Data Streaming transmission and Data 
Streaming method with DDI transmission. In 
the initial case, both transmission methods 
have to transmit 20 sub images of CVIS, and 
the total amount of transmitted file size is 
240 Kbytes, with file size of each sub image 
is 12 Kbytes. The best case of current method 
as (movetimex, movetimey) is (0, 0) and the 
worst case are (-2, -2), (-2, 2), (2, -2), and (2, 
2). It is observed from Table 1 that no matter 
in the best or the worst case, the transmission 
using the proposed Data Streaming method 
performs better than using the original 
transmission method. 
We test all cases that may happen with 
both methods, and calculate the average 
amounts of transmitted file size. Compared 
with both methods, the average decreased 
files size of Data Streaming with DDI 
transmitting method reduces about 53.2% 
than original transmission method. 
 
Performance of using image combination 
method 
Image Combination is implemented to 
combine the block images sent by server 
back into one at client for reducing the 
computation on mobile device. Using our 
original method, client directly renders the 
received 20 sub images. We use three cases 
of different rendering amount of texture (20 
textures, 4 textures, and 1 texture) for testing, 
and then analyze their computation time to 
decide which case should be used. Fig. 3 
shows the flow of our three experimental 
cases in details, all of them begin with 
loading 20 sub images of CVIS. Rendering 
20 textures case is the original rendering flow, 
and the remaining two flows on the right of 
Fig. 3 are the proposed cases. The two 
proposed cases differ from the original 
method in combining 20 sub images into 4 
and 1 respectively, as shown in Fig. 4. 
Computing times of three cases are 
shown in Table 2. It is observed that 
combining 20 sub images into 1 has the best 
performance. Compared with the original 
method without Image Combination, Render 
1 texture method is 1.5 times faster. 
Therefore, we choose Rendering 1 texture 
with Image Combination method as our 
favorite method. 
 
 8 
We have developed a client-server 
image-based walkthrough system on a thin 
client mobile device. A panorama generator 
based on SIFT is to stitch adjacent pictures 
with about 20% image content overlap to 
construct panoramic images at offline 
process. We then design a panorama list 
generator to store each panorama’s 
information into a panorama database and 
link neighboring panoramas together for 
server to retrieve. The most important 
scheme at server side is Data Streaming 
Method using DDI. It considers both spatial 
coherence and temporal coherence. Server 
decomposes the desired image into several 
sub images, and detects the difference 
between previous and current image of user 
location. Exploiting the scheme reduces 
transmission time, and DDI decreases an 
average of 53.2% data size per transmission, 
thus efficiently reduces network loading. Due 
to limited hardware support of mobile 
devices, client only has to perform simple 
work, such as sending the user movement 
message, receiving the image of 
corresponding user location. 
Our system differs from other similar 
researches with fixed walkthrough routes 
provides flexible and dynamic routes for 
walkthrough by analyzing distance and 
panorama corresponding nodes between 
adjacent panoramas, and has RCN of about 
22 degrees allowable walking cross angle for 
user to walk cross the adjacent panoramas. 
We aim to develop a system suitable for 
mobile device with limited hardware support. 
In the future, the system will provide 
multi-level of zooming magnification ratios, 
to prevent the displayed image from 
becoming severely blurred when viewing the 
scene with a high magnification ratio. We 
also plan to apply morphing technique for 
smoother transition of user movement as well 
as prefetching technique for faster 
performance. 
 
九、參考文獻 
 
[1]  Lee, J.B. et al, 2003. Evaluation of 
technological Innovation in the cellular 
phone display. Proceedings of Portland 
International Conference on 
Management of Engineering and 
Technology. pp. 140- 149. 
[2]  Buehler, C. et al, 2001. Unstructured 
Lumigraph rendering. SIGGRAPH Conf. 
Proc. pp. 425-432. 
[3]  Lee, D. and Jung, S. 2003. Capture 
configuration for image-based street 
walkthroughs. Proceedings of Second 
International Conference on 
Cyberworlds. pp. 151. 
[4]  Hu, Z.P. et al, 2006. A new IBR 
approach based on view synthesis for 
virtual environment rendering. IEEE 
ICAT. pp. 31-35. 
[5]  Aliaga, D. et al, 2003. Interactive 
image-based rendering using feature 
globalization. Proceedings of 
SIGGRAPH Symposium on Interactive 
3D Graphics. pp. 163-170. 
[6]  Engel, K. et al, 2000. A framework for 
interactive hardware accelerated Remote 
3D visualization. Proceedings of 
EG/IEEE TCVG Symposium on 
Visualization. pp. 167–177. 
[7]  Lei, Y. et al, 2004. Image-based 
walkthrough over Internet on mobile 
devices. Grid and Cooperative 
Computing GCC. pp. 728-735. 
[8]  Jiang, Z. et al, 2006. PanoWalk: a 
remote image-based rendering system 
for mobile devices. Advances in 
Multimedia Information Processing 
PCM. pp. 641-649. 
[9]  Lei, Y. et al, 2005. Adaptive streaming 
panoramic video for image based 
rendering system. Proceedings of 
Networking, Sensing and Control. pp. 
153-158. 
[10]  Liu, D.S.M. et al. 2010. Using mobile 
device for remote image-based walkthrough. 
Springer-Verlag Lecture Notes in Computer 
Science, pp. 261-268, IADIS International 
Conference on Web Virtual Reality and 
Three-Dimensional Worlds, Freiburg, 
Germany. 
[11]  Liu, Chi-Hsien. 2009. Interactive 
image-based walkthrough for mobile 
devices. Master Thesis. Computer Science 
Department, National Chung Cheng 
University. 
   
1୯ࣽ཮ံշ஑ᚒࣴزीฝ໨Πрৢ୯ሞᏢೌ཮᝼Јளൔ֋
                                    ВයǺ 99 ԃ 8Д 15 В
΋ǵୖу཮᝼࿶ၸ
忁ᾳ⣏夷㧉䘬䞼妶㚫㭷⸜㍸ὃḮ䚠斄⬠侭⮰⭞⛐暣儎丒⚾䚠斄柀➇㈨埻ᶲ㚱ᶨᾳ⚳晃
⿏Ṍ㳩䘬㨇㚫炻军Ṳ⶚㗗䫔⋩⯮冱彎Ḯˤ㬌㫉㚫嬘冱埴䘬⛘溆⛐桐⃱㖶⩂䘬≈㊧⣏刦ỗ
⟼䚩䎕⣓ⶪˤ䓙㕤廱䦳㍍㨇䘬墯暄⹎炻ㆹ㏕ḀḮ䓙楁㷗廱⼨㹓⒍厗䘬梃㨇炻᷎⛐䔞⛘㕭
棐 䔁Ḯᶨ㘂ˤ䫔Ḵ⣑ℵ⇵⼨⌉≈⇑ⶪ䘬⮷㨇⟜炻ℵḀ⛸ℑᾳ⮷㗪䘬⶜⢓㚨⼴ㇵ⇘忼䎕
⣓ⶪˤ
嬘䦳㛇攻⣏㚫⬱㌺Ḯ姙⣂⟜㫉䘬 keynote speech炻ㆹḇ悥⃀⎗傥䘬⍣修倥⬠佺ˤㆹ䘬⎋柕
⟙⏲⟜㫉塓⬱㌺⛐䫔ᶨ⣑䘬ᶳ⋰ˤ⚈䁢埴䦳⬱㌺ᶲ䘬⍇⚈炻⎒傥⛐⇵ᶨ⣑䘬㘂ᶲ⇘忼炻
⚈㬌䦵䁢㚱㗪ⶖᶲ䘬⚘㒦ˤḇ⚈䁢埴䦳䵲㷲炻栏ᶵ⼿㕭徼䕚⁁䘬ね㱩ᶳ炻⛐䫔Ḵ⣑⯙ 
Ḯ婾㔯䘬⟙⏲ˤᷳ⼴⛐㕭棐䔍䁢ẹ〗⼴炻ℵ䁢㫉㖍➡梲⃭㱃䘬橼≃炻ẍ㕡ὧ庽檮⛘⍣修
倥℞Ṿᷣ柴䘬婾㔯䘤堐ˤ怬⤥ỷ⭧䘬⛘㕡㍸ὃḮ䃉䶂䵚嶗䘬㚵⊁炻⚈㬌⎗ẍ⇑䓐⇵ᶨ⣑
ीฝጓဦ NSC ɡ  98 ɡ2221 ɡ E ɡ 194 ɡ044
ीฝӜᆀ Real-time interactive image-based walkthrough on mobile devices
Ș埴≽墅伖ᶲ䘬Ḻ≽⺷⌛㗪㚜㕘⚾⁷崘姒䲣䴙ș
р୯Γ঩
ۉӜ ∱冰㮹
୍ܺᐒᄬ
Ϸᙍᆀ
⚳䩳ᷕ㬋⣏⬠屯妲ⶍ䦳⬠䲣∗㔁㌰
཮᝼ਔ໔
99ԃ 6Д 24ВԿ
99ԃ 6Д 26В ཮᝼Ӧᗺ
≈㊧⣏刦ỗ⟼䚩䎕⣓ⶪ
཮᝼Ӝᆀ
(ύЎ)
(मЎ) 10th International Symposium on Smart Graphics
ว߄ፕЎ
ᚒҞ
(ύЎ)
(मЎ) A cross-platform framework for physics-based collaborative 
augmented reality
3⚳䥹㚫⮵㕤↢ⷕ⚳晃㚫嬘䘬墄≑炻䡢⮎傥⣈溻⊝⣏⭞䧵㤝㈽䧧␴⍫冯炻␴Ἦ冒ℐ䎫⎬⛘
䘬⮰⭞⬠侭忚埴⬠埻Ṍ㳩ˣ倥⍾㚨㕘䘬䞼䨞ㆸ㝄␴寸⭴䘬䞼䨞䴻槿ˤ㚜⎗ẍ㥳⿅⮯㛔幓
䘬䞼䨞⮰攟㈽⮬ℍᶵ⎴䘬柀➇ẍ⍾⼿㚜⺋㲃䘬ㅱ䓐炻ḇ⎗傥⚈㬌⺢䩳崟列⤥䘬⬠埻⎰ἄ
ᷳ嶗ˤ
ϖǵឫӣၗ਑ӜᆀϷϣ৒
㬌埴ⷞ⚆Ḯ⣏㚫䘬⌘⇟䳁䇰䘬婾㔯普炻ℏ⭡⊭㵝Ḯ㇨㚱⛐㚫㛇攻䘤堐䘬婾㔯ˤ侴⊭㵝䘬
柀➇ḇ䚠䔞䘬⺋㲃ˤ㬌㫉⣏㚫䘬婾㔯普普䳸ㆸᶨℲ炻䓙 Springer䘤埴䘬 Lecture Notes in 
Computer Science䲣↿ˤ
Ϥǵځд
⣏㚫䘬䵚⛨㗗烉
http://www.smartgraphics.org/sg10/index.html
98年度專題研究計畫研究成果彙整表 
計畫主持人：劉興民 計畫編號：98-2221-E-194-044- 
計畫名稱：行動裝置上的互動式即時更新圖像走訪系統 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 2 2 100%  
博士生 1 1 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 1 1 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
 
