 2
將可大量提供互動式之醫療、娛樂、教育、文化與
科技服務，大大改變消費者現有生活模式。再加上
寬頻網路的風行與 3G 數位時代來臨，加上各種應
用服務不斷的研發。網路電話、視訊電話、隨選視
訊之多媒體通訊的高科技時代產物，小型化及無線
化多媒體通訊與娛樂，將是一種趨勢。應用高效率
之視訊壓縮技術，建構數位視訊通訊及數位廣播系
統將是未來世界的明星產業技術主流。 
國際標準組織 (ISO)動態影像專家委員會
(MPEG) 與 國 際 通 信 協 會 (ITU) 同 步 制 定
H.264/AVC，於 2003 年 5 月定案。H.264 的吸引力
在近月已經表現出來，越來越多的公司公佈了將推
出 H.264 解碼器的計畫，目前國內外均尚未有
H.264 相關之商業化之 VLSI 產品。目前已有多家
公司已有提供 DSP 即時編碼器，依其之網站資料
表顯示 H.264 與 MPEG-2 及 MPEG-4 ASP 使用之
參數功能。可於相同 DVD 品質下，H.264/AVC 比
MPEG-4 ASP 約省 40%的位元率；亦比 MPEG-2
視訊壓縮約省 66%的位元率。 
過去我們主要已完成 H.264/AVC 快速法研究
工作、編碼效率、發展整數離散轉換與後處理為主
要其具體成果計完成：1)整數型態離散餘弦轉換演
算法之研究；2)可變區塊大小快速動態搜尋演算法
之研究; 3)無失真編碼架構之算術編碼架構研究；
4)位元率控制與可調式視訊編碼之研究；5) 小波理
論（Wavelet transform）之結合設計；6) H.264 即
時系統之實現。同時於 TMS320DM320 晶片完成
H.264 之即時解碼器，並於 TMS320DM642 晶片完
成 H.264 編碼器。 
本計畫為提高其應用性，研究 H.264 架構下，
更進一步研究 H.264 的視訊服務及應用技術。近年
來由於 H.264 之優越性能，Envivio 公司採用 H.264
視訊編碼證明，其於高畫質 HD-DVD 之應用，同
時行動數位視訊廣播(DVB-H)亦將考慮採用 H.264
視訊編碼為共同標準。DVB-H 將規劃單頻廣播
網，多個頻道同時使用共同較寬的無線廣播網路以
增加其穩定性及多用性。因此，研究多個 H.264
視訊壓縮之最佳編碼，如何同時保持多個影像品
質，並適當彼此支援頻寬，以增進網路效率，將是
一個實用且有學術價值之研究主題。 
 
三、執行方法與研究項目 
基於上述理由，本計畫預期規劃多通路 H.264 視
訊最佳即時編碼，H.264 轉碼技術，H.264 容錯設計，
以及 H.264 立體視訊處理編碼研究為四大研究主
軸，並於 TI DM 642 晶片實現編碼演算法複雜度簡
化，並以三年完成以下工作內容： 
第一年以配合 DVB-H 之行動數位視訊廣播與
HD-DVD 之高畫質數位影音機之發展及應用，研究
關於視訊轉碼架構 MPEG-2 與 H.264/AVC 相關轉碼
架構及編碼理論為首要工作，完成初步轉碼器之實
現。研究多個 H.264 視訊壓縮之最佳編碼，並規劃多
點視訊會議及多通道攝影機監控系統，並建立 3D 視
訊壓縮之實驗設備及分析其可行性。第二年以第一年
研究之H.264轉碼架構為背景，增加MPEG-2到H.264
轉碼之功能性，並開發以 PC 為平台之 H.264 多點視
訊會議及 H.264 多通道攝影機監控系統用以研究多
通道數位視訊壓縮之最佳位元控制與分配機制之相
關主題，同時研究 H.264 錯誤控制高壓縮效率編碼技
術及適應性調節群影像進去改善 H.264/AVC 的編
碼效能。第三年以研究任意形狀 H.264/AVC 編碼技
術及 H.264 錯誤防制與補償機制之進一步研究外，本
年度以 DM642完成即時實現 H.264/AVC多點視訊會
議系統、即時實現 H.264/AVC 多通道監錄系統雛型
系統、及即時實現 H.264/AVC 之 2D/3D 壓縮及解壓
縮系統，以完成計畫總目標。 
 
 
四、期中研究成果 
本年度以配合 DVB-H 之行動數位視訊廣播與
HD-DVD 之高畫質數位影音機之發展及應用，研
究後續關於視訊轉碼架構 MPEG-2 與 H.264/AVC
相關轉碼架構及編碼理論為首要工作，完成可對影
像長寬同時縮小 4 倍之轉碼器實現。同時完成快速
H.264/AVC 編碼器之框內外模式決策用以完成研
究本年度 H.264 錯誤控制高壓縮效率編碼技術之目
標。並研究多個 H.264 視訊壓縮之最佳編碼，規劃
多點視訊會議及多通道攝影機監控系統，也研究適
應性調節的群影像進去改善 H.264/AVC 編碼效。
本年度至目前為止，已完成四項研究：1) 4:1 
MPEG-2 到 H.264 轉碼器設計；2) 快速 H.264/AVC
編碼器之框外模式決策；3) 快速 H.264/AVC 編碼
器之框內模式決策；4) 使用適應性調節的群影像
來改善 H.264/AVC 視訊編碼，以下將分四個小章
節略述其初步成果： 
 
 
4.1.. MPEG-2 到 H.264 轉碼器設計: 
 
4.1.1 MPEG-2 到 H.264 4:1 轉碼器之背景與目的 
本年度 4:1 轉碼器架構是延續上年度 2:1 
MPEG-2 到 H.264 轉碼器設計而成，因為在一些原
始影像為高畫質尺寸、一些嚴格限制頻寬或是使用
者端本身運算上的限制，此時 4:1 MPEG-2到H.264
轉碼器的實現就變成相當的重要。在實際的應用中
與 2:1 MPEG-2 到 H.264 轉碼器相同，如果使用串
接式轉碼器必定會產生計算複雜度過高的問題，而
無法達成即時轉碼的目標。 
 4
domain)來執行預測。接著對預測誤差(prediction 
error) 執行整數型態的離散餘旋轉換 (integer 
DCT)，如此可避免轉換與反轉換之間，數值的不
匹配問題(mismatch problem)。H.264 有兩種不同大
小的內部區塊編碼(intra-block coding)，也就是 4x4
及 16x16 的區塊編碼，圖(四)顯示針對 4x4 的內部
區塊編碼，H.264 定義了九種不同的預測方向如圖
(五)。除了 4x4 區塊的內部預測，還有 16x16 區塊
的內部預測，它包含了四種不同的預測方向。至於
8x8 的彩度區塊(chroma blocks)，其預測編碼的方
式，和 16x16 區塊非常相似。 
在 H.264 的編碼過程中，所有可能的內部預測
模式(intra prediction mode)都必須一一加以編碼，
求得各的位元率及失真，再選擇ㄧ個最佳的預測模
式 ， 這 個 程 序 稱 為 位 元 率 - 失 真 最 佳 化
(rate-distortion optimization)，簡稱 RDO。因為 RDO
的複雜度相當高，影響系統的即時化(real-time)，
所以如何降低決定預測模式所花費的計算量，成為
H.264 編碼器的重要課題。 
我們觀察到在一張圖像中，相同邊界方向(edge 
direction)的像素(pixel)經常有近似的像素值。所以
如果我們先判斷這個區塊的邊界方向，再以相同邊
界方向的鄰近像素做為預測值，常會得到不錯的預
測效果。基於這個構想，針對每一個需要編碼的區
塊，我們先找出區塊的邊界方向，再以這個方向做
為內部預測編碼的方向，如此ㄧ來，在決定內部編
碼模式時(intra mode decision)，就不須考慮所有的
編碼模式，可以大幅的減少計算量。 
 
Mode Number Prediction Direction 
7 Vertical 
1 Horizontal 
2 DC 
3 Diagonal down left 
4 Diagonal down right 
5 Vertical right 
6 Horizontal down 
7 Vertical left 
8 Horizontal up 
 
圖(四) 針對 4x4 區塊的九種內部預測方向 
A B C D E F G H
I
J
K
L
M
1 (Horizontal)
A B C D E F G H
I
J
K
L
M
0 (Vertical)
A B C D E F G H
I
J
K
L
M
3 (Diagonal Down-Left)
A B C D E F G H
I
J
K
L
M
4 (Diagonal Down-Right)
A B C D E F G H
I
J
K
L
M
2 (DC)
Mean
(A ~ D,
I ~ L)
A B C D E F G H
I
J
K
L
M
7 (Vertical-Left)
A B C D E F G H
I
J
K
L
M
8 (Horizontal-Up)
A B C D E F G H
I
J
K
L
M
5 (Vertical-Right)
M A B C D E F G H
I
J
K
L
6 (Horizontal-Down)
圖(五) 針對 4x4 區塊的九種內部預測 
 
4.2.2. 區塊邊界方向的偵測 
我們利用一種在轉換域(transformed-domain)
而非空間域(spatial-domain)的邊界偵測方法，來求
得區塊的邊界方向。首先將每一個 4x4 的區塊切割
成四個次區塊(sub-block)，如同圖(六)所示。每一
個像素值式為 
 3,2,1,0,),,( =nmnmx  (5) 
每一個次區塊的像素值和為 
 
 ∑∑
= =
=++=
1
0
1
0
.1 ,0,),2,2(
i j
ab bajbiaxS  (6) 
藉 由 Sab 與 表 ( 一 ) ， 找 出 最 大 的 θδ ，
∈θ }4/3 ,2/ ,4/ ,0 ,NE{ πππ ，其相對應的角度θ即為
此區塊的邊界方向。此五種區塊方向圖示於圖(七)。
之後，此 4x4 block X 經過整數型 DCT 轉換得到 block 
Y，其轉換矩陣為 
 
 
⎥⎥
⎥⎥
⎦
⎤
⎢⎢
⎢⎢
⎣
⎡
−−
−−
−−=
1221
1111
2112
1111
H   (7) 
 
則其反轉換可描述為 
 ∑∑
= =
=
3
0
3
0
),(),(),(),(
u v
vnGvuYumGnmx  (8) 
其中 G 為 H 的反矩陣。將(8)帶入(6)，可得， 
 
∑∑∑∑
= = = =
++=
1
0
1
0
3
0
3
0
),,2(),(),2(
i j u v
ab vjbGvuYuiaGS
 1 ,0,,),(),(
3
0
3
0
== ∑∑
= =
bavuYvuw
u v
ab
 (9) 
其中 
.),2(),2(),(
1
0
1
0
∑∑
= =
++=
i j
ab vjbGuiaGvuw  (10) 
 
藉由 wab(u,v)及表(二)，我們可以重寫表(一)內的參數
為 
 ||20 V=δ  (7) 
 |}||,max{|
3
4
4/ DVHDVH −+++=πδ  (8) 
 ||22/ H=πδ  (9) 
 |}||,max{|
3
4
4/3 DVHDVH −−+−=πδ  (10) 
其中  
 
 )3,0()3,0()1,0()1,0( 0000 YwYwH +=  
1600/)]3,0(20)1,0(60[ YY −=  (11) 
 )0,3()0,3()0,1()0,1( 0000 YwYwV +=  
1600/)]0,3(20)0,1(60[ YY −=  (12) 
 )3,3()3,3()1,1()1,1( 0000 YwYwD +=  
0
1
6
4
57
3
8
 6
析(motion vector relation analysis)來決定出最後所
採用的方塊模式；以下將針對這兩部份作更進一步
的介紹。 
 
4.3.1 利用鄰近的資訊來決定初始方塊模式 
 
我們觀察到未編碼巨方塊所採用的方塊模式
與其相鄰且已編碼巨方塊的方塊模式有很高的相
關性；舉例來說，假設目前未編碼巨方塊的左邊巨
方塊是採用 16x16 模式，上方巨方塊也是採用
16x16 模式，則此巨方塊選到 16x16 模式的機率也
將相對的提高，為了更進一步的探討各種模式在不
同組合下所發生的機率，我們統計了目前未編碼的
巨方塊在各種可能的鄰近方塊模式組合中，各模式
所發生的機率，其結果如下表(四)所示。 
其中表(四)中的數字 1、2、3、8、9、10 分別
代表 16x16、16x8、8x16、P8x8、I4MB、I16MB
七種不同的方塊預測模式，利用上表，我們便能夠
根據不同鄰近方塊模式的組合，選取出最大機率的
方塊模式當作初始模式，接下來只要再配合後面介
紹的同質條件與移動向量相關性分析，便能快速的
決定最後的方塊模式；除了巨方塊模式的機率分析
外，我們也對 P8x8 方塊中各模式的機率作了統
計，其結果如下表(五)所示。 
由表(五)可知，在各種 P8x8 方塊模式中，8x8
模式所發生的機率最高，因此在 P8x8 的情況下，
我們將選定 8x8 模式來當作初始模式。 
 
表(四) 各模式所發生機率 
 
表(五)次方塊各模式所發生機率 
8x8 mode 8x4 mode 4x8 mode 4x4 mode 
0.4663 0.2036 0.2076 0.1224 
 
4.3.2 同質條件與移動向量相關性分析 
 
選定了初始的方塊模式後，接著我們將利用同
質條件與移動向量相關性分析來決定下一步所要
搜尋的方塊模式。在我們的方法中，一個 NN × 方
塊在作完移動估計後，如果它的四個
22
NN × 子方塊
R0~R3(如下圖) 
 
圖(九) NN × 方塊之子方塊圖 
 
都滿足下式的話，我們就說它是一個完全同質方塊
(complete homogeneous block)，如果只有某些子方
塊滿足的話，則稱它為部分同質方塊 (partial 
homogeneous block) 
 
 3,2,1,0    ,
64
3),(
22
1
2
1
=<−∑ ∑
= =
kQNMjir step
N
i
N
j
kk
 (14) 
 
其中 Mk為子方塊 Rk內殘值的平均，Qstep則為量化
階數。有了同質方塊條件後，接著我們便可利用移
動向量相關性分析來決定下一步所需搜尋的方塊
模式，以下將介紹整個的搜尋步驟。 
 
4.3.2.1. 初始模式為 16x16 模式 
(1) 作 16x16 ME 並檢查同質條件。  
(2) 檢查有幾個子方塊滿足同質條件。 
0: 跳到步驟 2.2。  
1: 跳到步驟 2.2。  
2: 若為(0, 1) 或 (2, 3): 16×8 模式。 
   (0, 2) 或 (1, 3): 8×16 模式。 
   (0, 3) 或 (1, 2): 跳到步驟 2.2。 
3: 計算 16×16, 16×8, 8×16, 和 8×8 模式
的位元率-失真耗費並選擇對應到最
小耗費的模式當作下一個搜尋模式. 
4: 16×16 模式 
 
4.3.2.2. 初始模式為 P8x8 模式 
(1) 作 8x8 ME 並檢查同質條件。 
(2) 檢查有幾個子方塊滿足同質條件。 
0: 跳到 P8×8 程序。 
1: 跳到 P8×8 程序。 
 8
然而，I 影像編碼其實是最浪費位元率的， 但是他
們卻沒有考慮到。  
在本年度中，如何依照視訊內文的變化率去
調節 GOP 的大小是主要的工作之一。第二，要採
用何種資訊作為可參考的內文變化率也是要實現
的目標， 最後， 我們希望利用既有的視訊編碼過
程中的參數去獲得視訊內文的變化率。 
 
4.4.1 應用在 H.264/AVC 適應性的 GOP 偵測與影像
變化偵測 
 
我們利用 H.264/AVC 的編碼過程中去獲得視訊
內文的變化率，參考的資訊為移動向量與殘值(sum of 
absolute transformed differences: SATD)， 對於適應性
的 GOP 設計，我們採用統計整張影像的移動向量，
包含 4x4 至 16x16 所有區塊的向量值。 所有不同大
小的區塊都將切割成最小的 4x4 區塊而相對表示成
4x4 區塊的移動向量， 定義單一 16x16 的區塊中 16
個 4x4 區塊的所有移動向量如下: 
 ∑
=
+=
15
0
.,
j
y
ji
x
jii mvmvNAMV   (19) 
x
jimv ,  與 y jimv ,  表示在第 i 個 16x16 的區塊中， 第 j
個 4x4 的區塊的水平方向與垂直方向的移動向量。  
 ∑−
=
=
1
0
I
i
it NAMVSAMV  (20) 
SAMVt 表示 t 張影像內， 所有的移動向量的總和。  
 )1(for   ,)1(log p
1
2 −≥+= ∑
−−=
k
T
LTt
t
k
k LCSAMVL
m
k
γ  (21) 
式 21 是說， k 群影像間平均的 SAMVt可以得到一個
mk值。 mk值可以用來表示不同群影像間的視訊內文
變化率。 假如我們定一個臨介值， 則我們可以獲得
不同種類的視訊內文變化率。 如此一來便可依照不
同的視訊內文給予不同的 GOP 長度。  
對於變化影像的偵測方式， 我們利用兩張影像間的
移動殘值比例(motion residual ratio : MRR) 獲得， 定
義如下: 
 MRR = η≥
−1t
t
SATD
SATD
  (22) 
圖(十二)為本專題 H.264/AVC 的適應性 GOP 與影像
變化偵測流程圖: 
Cp
Eq. (7)
AGD 
by Pseudo Codes
Intra Coding
(Cp = 0 and T = T + 1
For next new GOP)
SCD in Eq. (9)
Yes
No
Yes
Inter Coding
(Cp = Cp + 1, T = T + 1
for next intra or 
inter coding decision )
No
Sequence
4m
3m
2m
1m
Cp = (L5 – 1)
Cp ≥ (L1 - 1) and Cp < (L2 - 1)
Cp ≥ (L2 - 1) and Cp < (L3 - 1)
Cp ≥ (L3 - 1) and Cp < (L4 - 1)
Cp ≥ (L4 - 1) and Cp < (L5 - 1)
 
圖(十二) 結合適應性 GOP 偵測與影像變化偵測的 
4.4.2 實驗結果 
 
4.4.2.1 適應性 GOP 實驗影像群 
 
A: Football + Stefan (90 + 300 frames),  
B: Foreman + Flower (400 + 250 frames), C: Table + 
Highway (300 + 700 frames), D: News + Akiyo 
(300 + 300 frames),  
E: Mobile + Waterfall (300 + 260 frames), F: Tempete + 
Bridge-close (260 + 740 frames),  
G: Football + Akiyo + Foreman (90 + 300 + 400 frames). 
 
4.4.2.2 影像變化偵測實驗影像群 
 
H (Akiyo + Bridge-far + Coastguard + Football + Hall + 
Ice + Mobile + Silent + Stefan + Waterfall + Basket 
+ Bus + Crew + Dl + Foreman + Harbour + Kiel + 
News + Singer + Table + Bridge-close + City + 
Dancer + Flower), 
 
I (Akiyo + Coastguard + Hall + Mobile + Stefan + Basket 
+ Crew + Foreman + Kiel + Singer + Bridge-close 
+ Dancer + Highway + Bridge-far + Football + Ice 
+ Silent + Waterfall + Bus + Dl + Harbour + News 
+ Table + City). 
 
表(七)為影像改變的實驗數據，在我們的模擬中，誤
判(Fault detection)較無偵測(miss detection)到所需付
出的代價較高，因此我們希望在完全無誤判下去評估
我們影像變化偵測率的效能 . 實驗結果證明使用
SATD 有較佳的偵測效果.  
 
表(七) 影像改變偵測率模擬結果 
Combined sequences H and I 
CIF 
Total: 46 scene changes 
DOH HOD BH Proposed 
Detects 46 46 46 46 
Miss Detects 0 0 0 0 
Fault Detects 9 17 7 5 
Recall 100 100 100 100 
Optimal 
Recall rate
Precision 
% 
84 73 87 90 
Detects 37 35 30 45 
Miss Detects 9 11 16 1 
Fault Detects 0 0 0 0 
Recall 80 76 65 98 
Optimal 
Precision 
rate 
Precision 
% 
100 100 100 100 
 
 
表(八)為適應性GOP 與傳統固定GOP的實驗數據. 實
驗結果表示， 比較高的視訊內文變化應該採用比較
小的 GOP 尺寸， 比較低的視訊內文變化應該採用比
較大的 GOP 尺寸. 
實驗結果證實對於 H.264/AVC, 我們能夠增加
0.62dB 的 PSNR, 並且有 98% 的影像變化偵測率。 
 
 
 10
selection in hybrid video coder control,” in Proc. 
of IEEE International Conference on Image 
Processing, 2001. 
21. T. Wiegand, H. Schwarz, A. Joch, F. Kossentini, 
and G. J. Sullivan, “Rate-constrained coder 
control and comparison of video coding 
standard,” IEEE Trans. on Circuits Syst. Video 
Technol., vol. 13, no. 7, pp. 688–703, July 2003. 
22. A. Vetro, H. Sun, and Y. Wang, “MPEG-4 rate 
control for multiple video objects,” IEEE Trans. 
on Circuits Syst. Video Technol., vol. 9, no. 1, pp. 
186–199, Feb. 1999. 
23. C.-W. Lin, T.-J. Liou, and Y.-C. Chen, “Dynamic 
bit rate control in multipoint video transcoding,” 
in Proc. IEEE Int. Symp. Circuits and Systems, 
vol. 2, May 28–31, 2000, pp. 17–20. 
24. D. Marpe, H. Schwarz, and T. Wiegand, 
“Context-based adaptive binary arithmetic coding 
in H.264/AVC video compression standard,”, 
IEEE Trans. on Circuits Syst. Video Technol., vol. 
13, no. 7, pp. 620–644, July 2003. 
25. Yamaguchi H, Tatehira Y, Akiyama K and 
Kobayashi Y, “Stereoscopic images disparity for 
predictive coding,” in Proc. IEEE ICASSP, 23-26 
May 1989. 
26. James F. Blinn, “W Pleasure, W Fun,” Microsoft 
Research, May/June 1998. 
27. Fantini and Martins, “A configurable and portable 
benchmark for 3D graphics,” Computer Graphics 
and Image Processing, 2001 Proceedings of XIV 
Brazilian Symposium on, 15-18 Oct. 2001. 
28. Dubois E, “A projection method to generate 
anaglyph stereo images,” in Proc. IEEE ICASSP, 
Volume: 3, 7-11 May 2001. 
29. Cutler and Byars, “A modified strategy for 3D 
image reconstruction from axially adjacent bed 
positions,” IEEE Nuclear Science Symposium and 
Medical Imaging Conference, 1994. 
30. D. Marr and T. Poggio, “A theory of human stereo 
vision,” in Proc. R. Soc London, vol B204, 
p:301-328, 1979. 
31. J. A. Williams, M. Bennamoun and S. Latham, 
“Multiple view 3D registration: a review and a 
new technique,” International Conference on 
IEEE SMC '99 Conference Proceedings, Oct 
1999. 
32. J. Weng, N. Ahuja and T. S. Huang, “Matching 
two perspective views,” IEEE Trans. on Pattern 
Analysis and Machine Intelligence, Aug. 1992. 
33. Texas Instrument, “TMS320DM642 
Video/Imaging Fixed-Point Digital Signal 
Processor (Rev. G)”, Data Manual, Literature 
Number: SPRS200G, August 2004. 
34. ETSI, “IP Datacast Baseline Specification, PSI/SI 
Guidelines for IPDC DVB-T/H Systems”. DVB 
Document A079, April 2004. 
35. Faria, G.: MOTIVATE report on laboratory tests 
for mobile DVB-T. Paper was presented in 
DVB-TM. Geneva, March 99.  
36. A. Vetro, C. Christopoulos, and H. Sun, “Video 
Transcoding Architectures and Techniques: An 
overview,” IEEE Signal Processing Magazine, 
vol. 20, no. 2, pp. 18–29, Mar. 2003. 
37. J. Xin, C. W. Lin, and M. T. Sun, “Digital Video 
Transcoding,” Proc. of the IEEE, vol. 93, no. 1, pp. 
84-97, Jan. 2005. 
38. J. Xin, A. Vetro, and H. Sun, “Converting DCT 
Coefficients to H.264/AVC Transform 
Coefficients” TR-2004-058, Mitsubishi Electric 
Research Laboratories (MERL). 
39. B. Shen, “From 8-Tap DCT to 4-Tap 
Inter-Transform for MPEG to H.264/AVC 
Transcoding”, In Proc. of IEEE International 
Conference on Image Processing, Singapore, May 
2004. 
40. N. I. Cho and S. U. Lee, "Fast algorithm and 
implementation of 2-D discrete cosine 
transform," IEEE Transactions on Circuits and 
Systems for Video Technology, vol. 38, pp 
297-305, Mar. 1991. 
41. A. Hallapuro and M. Karczewicz, “Low 
complexity transform and quantization,” in Joint 
Video Team (JVT) Docs. JVT-B038 and 
JVT-B039, Jan. 2002. 
42. R. Dugad and N. Ahuja, “A fast scheme for image 
size change in the compressed domain,” IEEE 
Transactions on Circuits and Systems for Video 
Technology., vol. 11, no. 4, pp. 461–474, Apr. 
2001. 
43. C. Chen, P. H. Wu, and H. Chen, “MPEG-2 to 
H.264 Transcoding”, in Proc. Picture Coding 
Symposium, San Francisco, CA, Dec. 2004. 
44. Y. Su, J. Xin, A. Vetro, and H. Sun, “Efficient 
MPEG-2 to H.264/AVC Intra Transcoding in 
Transform-domain,” In Proc. of IEEE 
International Symposium on Circuits and Systems, 
Kobe, May 2005. 
45. K. P. Lim, S. Wu, D. J. Wu, S. Rahardja, X. Lin, F. 
Pan, and Z. G. Li, “Fast inter mode selection,” in 
Joint Video Team (JVT) Doc. JVT-I020, Sept. 
2003. 
46. B. Jeon and J. Lee, “Fast mode decision for 
H.264,” in Joint Video Team (JVT) Doc. 
JVT-J033, Dec. 2003. 
47. G. Sullivan, T. Wiegand, and K.-P. Lim, “Joint 
model reference encoding methods and decoding 
concealment methods,” in Joint Video Team (JVT) 
Doc. JVT -I049, Sept. 2003. 
48. A. Hallapuro and M. Karczewicz, “Low 
complexity transform and quantization,” in Joint 
Video Team (JVT) Docs. JVT-B038 and 
JVT-B039, Jan. 2002. 
49. Q. Chen and Y. He, “A fast bits estimation 
method for rate-distortion optimization in 
國家科學委員會補助出席國際學術會議報告 
96年6月4日 
報告人: 楊家輝教授 
國立成功大學 電機系 電腦與通信工程研究所 
計畫編號 NSC 94-2220-E-006-005 
會議時間：96年5月27日- 30日   會議地點：美國 新紐澳良市 
中文會議名稱： 二OO七年IEEE國際電路暨系統學術研討會 
英文會議名稱: 2007 IEEE International Symposium on Circuits and Systems 
 
 
會議摘要 
 
    本人依計畫參加於美國新紐澳良市(New Orleans, USA)舉行之2007 IEEE國
際電路與系統研討會(2007 IEEE International Symposium on Circuits and Systems 
簡稱 ISCAS 2007)出國其目的有六：  
     1) 發表二篇會議論文； 
     2) 主持一場議程； 
     3) 報告由成大主辦之2009 IEEE國際電路與系統研討會執行情形； 
     4) 共同主持多媒體應用與系統技術委員會 (Multimedia Systems & 
Applications TC)會議； 
     5) 參加視訊訊號處理與通訊技術委員會 (Visual Signal Processing & 
Communications TC)會議； 
     6) 參加2006 IEEE國際電路與系統之IEEE Fellow之受獎。  
 
 
一、會議大要 
  「二OO七IEEE國際電路暨系統學術研討會」係國際電子電機工程師學會
電路暨系統學術會(IEEE Circuits and Systems Society)主辦之全球年會，本年在
美國路易斯安納州新紐澳良市之希爾頓飯店(Hilton Hotel)會議中心舉行，參與
人數超過1200人以上。本會議分 
類比信號處理(Analog Signal Processing) 
生醫電路與系統(Biomedical Circuits and Systems) 
盲信號處理(Blind Signal Processing) 
蜂巢類神經網路與陣列計算(Cellular Neural Networks and Array Computing) 
通訊電路與系統 (Circuits & Systems for Communications) 
電腦輔助網路設計(Computer-Aided Network Design) 
消費者技術與應用(Consumer Technologies & Applications) 
數位信號處理(Digital Signal Processing) 
圖形理論與計算(Graph Theory and Computing) 
生活科學與應用(Life-Science Systems and Applications) 
多媒體系統與應用(Multimedia Systems and Applications) 
奈米電子技術與系統(Nanoelectronics and Gigascale Systems) 
神經系統與應用(Neural Systems and Applications) 
非線性電路與系統(Nonlinear Circuits and Systems) 
 3
 
5月29日：ISCAS 2007大會議程(二) 
1. 參與多場口頭及海報論文發表並與國內外學者專家討論研究相關問
題。 
2. 以委員會秘書身份共同主持Multimedia Systems & Applications技術委
員會會議。 
3. 參加大會晚宴。 
 
5月30日：ISCAS 2007大會議程(三) 
大會正式議程最後一天，參加會議發表論文。 
1. 參與多場口頭及海報論文發表並與國內外學者專家討論研究相關問
題。 
2. 發表論文：Combined Decoding and Flexible Transform Designs for 
Effective H.264/AVC Decoders (Oral) 
3. 發表論文：Fast H.264 Inter Mode Decision Based on Inter and Intra 
Block Conditions (Poster) 
2. 參加晚上大會再見酒會(Farewell Party)。 
 
 
三、攜回資料 
1. 2007 International Conference on Acoustics, Speech, and Signal Processing 
(ICASSP2007)之論文集光碟一片及大會手冊各乙份。 
 
四、心得 
1. 本人此次獲選為IEEE Fellow為國增光，其顯示台灣學者之研究能力已達到
世界一流水準。 
2. 此次會議議題相當廣泛，大家參與會議時討論亦非常熱烈，大會安排多場
海報式發表，使得大家可以針對自己興趣之主題充分與發表者深入討論，
因此收獲相當多。 
3. 此次會議台灣之論文佔全部10%，可說相當熱烈，也由於有多人參會，大家
亦可交換心得及了解目前在各個領域之研究情形。 
4. 經由這次會議的參與，不但得以認識一些相關領域之學者，互相交換研究
心得，而且可吸收最新資訊，對日後計劃之執行將有所助益。 
5. 當我國學術水準達到某層次之後，如何進入大會或國際組織核心變成比發
表論文更重要，本次獲得以ISCAS 2009主辦權，收穫很多，也替國家爭取
學術地位。 
6. 由於國家矽導計畫之推動，擴增SoC相關教師員額，本次國人論文錄取篇數
為全球第二，佔10%；僅次於美國，顯示矽導計畫大幅培養人才之成果顯
現。 
 
 (5) . 
16×16 prediction mode or chroma DC coefficients, the 4×4 
or 2×2 DC inverse transform which is inverse Hadamard 
transform (IHT) will be executed. The other transform, 
which is 4×4 inverse integer transform (IIT) is applied 
behind the IQ. The functional blocks in details are described 
as follows. 
A. CAVLC Decoder 
Five syntax elements should be decoded in the CAVLC 
decoder. Those syntax elements are described as follows: 
• coeff_token: Both the number of all non-zero 
coefficients (TotalCoeff) and the number of trailing 
ones (TrailingOnes) are encoded by this syntax 
element. 
• trailing_ones_sign_flag: This syntax element 
encodes the sign bit of each trailing one in reverse 
zig-zag scan order. 
• level: The value of each non-zero coefficient except 
for trailing ones is encoded in reverse zig-zag scan 
order by this syntax element. 
• total_zeros: It denotes the total number of zero 
coefficients preceding the last non-zero coefficient in 
zig-zag scan order. 
• run_before: It describes the number of successive 
zero coefficients preceding each non-zero coefficient 
in reverse zig-zag order. 
The CAVLC decoder decodes those five syntax 
elements sequentially because of data dependency. 
B. Inverse Quantization 
In H.264/AVC, the rescaling operation of the inverse 
quantization [1] is 
)6/(2 QPfloorijijij VZW ⋅⋅=                                  (1) 
where Zij is the quantized coefficient decoded from CAVLC 
decoder, and ijV  is the rescaling factor shown in Table I. 
 
Table I. Rescaling factors for inverse quantizaton in H.264/AVC. 
QP%6 
positions 
(0,0),(2,0),(0,2),(2,2) 
positions 
(1,1),(1,3),(3,1),(3,3) 
other 
positions 
0 10 16 13 
1 11 18 14 
2 13 20 16 
3 14 23 18 
4 16 25 20 
5 18 29 23 
C. Inverse Transforms 
The H.264/AVC 4×4 IIT is used to both luma and 
chroma components. It is defined as [1] 
 Tii XCCY =      (2) 
where 
 








−−
−−
−−
=
5.0111
115.01
115.01
5.0111
iC . (3) 
However, the H.264/AVC 4×4 IHT is defined as [1] 
   Tff XHHY =                                       (4) 
where 
 








−−
−−
−−
=
1111
1111
1111
1111
fH
   
Further, the H.264/AVC 2×2 IHT is defined as [1] 
    TttXHHY =                                       (6) 
where 
                   


−
=
11
11
tH .                                     (7) 
The Hadamard transforms are adopted in the second 
level transforms to increase the compression gain by 
performing them for the 4×4 array of luma DC coefficients 
in intra 16×16 prediction mode and for the 2×2 array of 
chroma DC coefficients. Therefore, the 4×4 or 2×2 IHT is 
only applied in luma DC coefficients in intra 16×16 mode or 
chroma DC coefficients. 
III. PROPOSED ARCHITECTURE 
Figure 2 depicts the proposed architecture for decoding 
residual data. Since each non-zero coefficient has to be 
processed by the IQ, the IQ procedure of residual data 
decoded without the IHT can be combined into CAVLC 
decoder. If the decoding pixels are chroma DC components, 
the input of IHT/IIT will be 2×2 pixels. Otherwise, the input 
of IHT/IIT is 4×4 pixels. The architecture of IHT/IIT can 
achieve high throughput which is 8 pixels/cycle. If the 2×2 
or 4×4 pixels are chroma DC coefficients or luma DC 
coefficients encoded in intra 16×16 prediction mode, the 
pixels should be stored in the 4×4 pixel array. The reason is 
the pixels should be integrated into the AC pixels and make 
up an entire 4×4 block including DC and AC coefficients. 
Besides, the IQ procedure of these DC coefficients should 
be processed before the IIT process instead of CAVLC 
decoding process.  
 
Figure 2. Entire architecture for decoding residual data. 
A. CAVLC Decoder and Inverse Quantization 
Figure 3 is the CAVLC decoder and IQ architecture. In 
the run_before stage, we can get the actual corresponding 
position of each pixel in a 2×2 or 4×4 block. Therefore, the 
IQ process of pixels decoded without the IHT process can 
3136
 Fig. 7 can be reconstructed to realize this inverse transform 
and Fig. 8 is more detailed architecture for it. 
+⁄–
+⁄–
+⁄–
+⁄–
+⁄–
+⁄–
+⁄–
+⁄–
X00
X02
X01
X03
X20
X22
X21
X23
X10
X12
X11
X13
X30
X32
X31
X33
+
–
+
+
+
reg
reg
reg
reg
reg
reg
reg
reg
+
+
+
+
+
+
+
+
Y10
Y11
Y12
Y13
Y20
Y21
Y22
Y23
Y00
Y01
Y02
Y03
Y30
Y31
Y32
Y33
Z00
Z01
Z10
Z11
–
–
–
–
–
–
–
–
–
–
–
R00
R01
R00
R11
R10
R11
R10
R01 2 2 IHT
4 4 IHT
 
Figure 7. The architecture for 4×4 and 2×2 IHT. 
 
Figure 8. The architecture for 2×2 IHT. 
IV. SIMULATION RESULTS 
We have implemented the proposed architecture in the 
cell-based design flow. We synthesized our design by using 
Synopsys Design Compiler targeted towards an Artisan 
TSMC 0.18 µm cell library. Table II shows the comparison 
of the different architectures. In our design, we implemented 
the total decoding flow of residual data and efficiently 
design the interface of each functional block. In this way, 
the fewest IQ components are needed. Although the 
architecture in [4] needs more number of IQs, it is suitable 
for H.264/AVC encoder to complete the forward transforms 
and inverse transforms for the real-time requirement. This 
proposed design can help the H.264/AVC decoder with 
higher performance and less chip area. 
The detailed area for each function is shown in Table III. 
The synthesized gate count of CAVLC decoder and one 
fully IQ is 8.4k. The flexible 2-D inverse transform 
architecture for computing the IIT and IHT in the same 
architecture acquires 6.7k gates. Since the proposed 
architecture is designed at the macroblock level, the 4×4 
pixel array is needed and the gate count is 3.5k, including 
one brief IQ architecture and the controller. Therefore, the 
gate count of overall architecture is 18.6k. 
The maximum clock frequency in the proposed 
architecture can be operated at 125 MHz. For the worst case, 
the architecture can process 4800 macroblocks in 1/30 
second. Thus, the proposed design achieves 4VGA 
(1280×960)@30 frames/sec for the real-time requirement. 
 
V. CONCLUSIONS 
In this paper, we proposed an area-efficient and high 
throughput architecture for decoding residual data in 
H.264/AVC. The IQ procedure is combined into CAVLC 
decoder so as to design the more efficient interface. The 
flexible 2-D transform architecture can be applied to all 
inverse transforms, which include 4×4 IIT, 2×2 IHT, and 
4×4 IHT. Further, the throughput of inverse transforms is 8 
pixels/sec. The simulation results show that the 
implemented gate count is 18.6k and the maximum 
operating frequency is 125 MHz. For the real-time 
requirement in the worst case, this proposed design achieves 
4VGA (1280×960)@30 frames/sec in 4:2:0 format. 
REFERENCES 
[1] ITU-T Rec. H.264/ISO/IEC 11496-10, Advanced Video Coding, Final 
Committee Draft, Document JVTG050, March 2003. 
[2] I. E. G. Richardson, H.264 and MPEG-4 Video Compression: Video 
Coding for Next-Generation Multimedia. Chichester, UK: John Wiley 
& Sons, 2003. 
[3] T. C. Wang, Y. W. Huang, H. C. Fang, and L. G. Chen, “Parallel 4×4 
2D transform and inverse transform architecture for MPEG-4 
AVC/H.264,” in Proc. IEEE ISCAS, May 2003, pp. 800-803. 
[4] H. Y. Lin, Y. C. Chao, C. H. Chen, B. D. Liu, and J. F. Yang, 
“Combined 2-D transform and quantization architectures for H.264 
video coders,” in Proc. IEEE ISCAS, May 2005, pp. 1802-1805. 
[5] W. Di, G. Wen, H. Mingzeng, and J. Zhenzhou, “A VLSI architecture 
design of CAVLC decoder,” in Proc. IEEE Int. Conf. ASIC, Oct. 
2003, vol. 2, pp. 21-24. 
[6] J. Nikara, S. Vassiliadis, J. Takala, and P. Liuha, “Multiple-symbol 
parallel decoding for variable length codes,” IEEE Trans. VLSI Syst., 
vol. 12, pp. 676-685, July 2004. 
[7] H. C. Chang, C. C. Lin, and J. I. Guo, “A novel low-cost high-
performance VLSI architecture for MPEG-4 AVC/H.264 CAVLC 
decoding,” in Proc. IEEE ISCAS, May 2005, pp. 6110-6112. 
[8] Y. H. Moon, G. Y. Kim, and J. H. Kim, “An efficient decoding of 
CAVLC in H.264/AVC video coding standard,” IEEE Trans. 
Consumer Electron., vol. 51, pp. 933-938, Aug. 2005. 
Table II. The comparison of different architectures.
 [4] [7] Proposed 
CAVLC decoder No Yes Yes 
IQ Yes No Yes 
Inverse Transform Yes No Yes 
Interface of CAVLC  
decoder and IQ Not needed 
2 16×16 SP 
SRAM Not needed 
Level 4×4 Block 4×4 Block Macroblock 
Process (µm) 0.35 0.18 0.18 
Number of IQs 8 (Brief) 8 (Brief) N/A 
1 (Fully) 
and 
1(Brief) 
Max Frequency (MHz) 62 56 175 125 
Gate Counts (k) 8.264 (IIT) 
8.094 
(IHAD) 
9.943 
(excluding 
SRAM) 
18.6 
Table III. The synthesized gate count of each decoding function.
Decoding Function Gate Counts 
CAVLC decoder and one fully IQ 8.4k 
Flexible Inverse Transform Architecture 6.7k 
4×4 pixel array, one brief IQ, and controller 3.5k 
Total Architecture 18.6k 
3138
In (2), ),( yx vjvif ++
∧
 and ),( jif  denote the (i, j)th elements of 
the reference block 
∧
F  and the current block F , respectively. And in 
(3), ),( jic  is the (i, j)th element of C , which is the Hadamard 
transform of difference of 
∧
F  and F  depicted as  
2
)( THH TFFTC −=
∧
,                                                                  (4) 
with 
⎥⎥
⎥⎥
⎦
⎤
⎢⎢
⎢⎢
⎣
⎡
−−
−−
−−=
1111
1111
1111
1111
HT
.                                                                (5) 
In (1), λ(Qp) is an approximated exponential function of the 
quantization parameter Qp and R(MVD) represents the rate cost 
contributed by motion vector difference (MVD), is expressed as: 
MVD = yyxx vvvv −+− ,                                                     (6) 
where ),( yx vv  is the predicted motion vector defined in the 
standard. After motion vector search, we can get the motion vector 
for each sub-block and its corresponding cost Jsb. The next step is to 
find the best partition mode with the least cost. The cost is defined as 
follows: 
Jmode = ∑
∈macroblocksb
sbJ      ,                                                        (7) 
where Jmode denotes the cost of the partition mode and Jsb is the 
cost of the sub-block within the macroblock.  
Besides the inter mode, H.264 also allows the inter block to be 
coded as the intra mode (I16MB and I4MB) and the final mode is 
selected from all possible modes.   
From the above, we can see that the computation complexity for 
deciding the best inter mode is very high since the motion estimation 
is performed for all possible block sizes. Therefore, how to accelerate 
the coding process and maintain the coding performance 
simultaneously is a very important subject in H.264/AVC interframe 
coding. In the next section, we will develop a fast algorithm for inter 
mode decision. 
III. FAST IINTER MODE DECISION ALGORITHM  
In the original inter mode decision algorithm, we have to select 
the best inter mode and this is very time-consuming. In this paper, we 
will propose a fast inter mode decision algorithm by utilizing 
neighboring information and homogeneous condition to select the 
best mode more rapidly and efficiently. The detail of each part will be 
introduced in the following subsections. 
A. Neighboring Information for Inter Blocks  
After the observation of the mode relation between current 
macroblock and neighboring macroblocks (Left and Top), we find 
that there is a highly correlation between the best mode of the current 
macroblock and the modes of neighboring macroblocks. For instance, 
if the left macroblock and the top macroblock are both coded as 
16×16 mode, the current macroblock will also have a great chance to 
be coded as 16×16 mode.  To get the probabilities for each 
macroblock type in different combinations of neighboring 
macroblock types, we have tested five sequences, Foreman, Mobile, 
Coastguard, News, and Stefan with CIF format (352×288) in 
different QP (20, 29, 38) and the average result is shown in Table I. 
In Table I, each number stands for  a particular mode where 1, 2, 3, 8, 
9, and 10 stand for 16×16 mode, 16×8 mode, 8×16 mode, P8×8 mode, 
I4MB mode, and I16MB mode, respectively. And the term, (a, b) 
means the combination of neighboring macroblocks where a and b 
are the modes of the left and top macroblocks, respectively. By using 
Table I, we can get the initial mode for the current macroblock so that 
we will have a higher probability to find the correct mode. Besides 
the analysis of the macroblock type, we also investigate the 
probabilities for smaller partition type within one 8×8 block and the 
average result is shown in Table II. From Table II, we can see that 
when considering P8×8 mode, 8×8 mode has the highest probability 
so that we can choose the 8×8 mode as the initial mode for P8x8 
mode. 
Although we can just use the probability to get the searching 
order, we suggest that we should only use this for the initial mode 
selection. For the subsequent searching process, we will use 
homogeneous condition with motion vector relation to decide the 
following searching mode. 
B. Homogeneous Condition for Inter Blocks 
In the past, there were some papers that use either spatial 
homogeneous or residual homogenous to accelerate the inter mode 
decision process [4], [5]. However, they only check if the current 
block is homogeneous or not but do not use the characteristic of 
homogenous condition inside the block. Therefore, if we can utilize 
the homogeneous condition to find the following most possible mode, 
we can save more computation. Here, we will use residual 
homogeneous and investigate the homogenous condition to accelerate 
the coding process. In this paper, the definition of the residual 
homogenous is the same as [5] except the threshold is modified. One 
N×N block is said to be complete residual homogeneous if its residue 
block satisfies the following condition: 
3,2,1,0    ,
64
3),(
22
1
2
1
=<−∑ ∑
= =
kQNMjir step
N
i
N
j
kk
      (8) 
In (8), ),( jirk  and kM  represent the (i, j)
th element and the 
mean individually of  the kth  sub-block Rk of the residue block, which 
is shown as Fig. 2. However, if the N×N block is not complete 
residual homogeneous but partial residual homogenous, we can also 
analyze the homogeneous condition and motion vector relation to 
find the following possible mode. For example, after doing the 16×16 
motion estimation and checking the homogeneous condition, if there 
are two homogenous sub-blocks within the 16×16 block, we will then 
find the positions of these two sub-blocks. If the homogeneous sub-
blocks are R0 and R1, the following possible mode is 16×8 mode. The 
overall searching process is addressed as follows: 
1. Initial mode selection 
By using Table I with the neighboring information, we can get 
the initial mode for the current macroblock. For example, if the mode 
of the left macroblock is P8×8 and the mode of the top macroblock is 
8×16, the initial mode will be P8×8. 
2. Following possible mode selection 
After initial mode selection, we will take different strategies 
according to different initial modes. The detail is described as follows: 
2.1. If the initial mode is 16x16 mode 
(1) Do 16x16 ME then check homogeneous condition. 
(2) Check the number of homogeneous sub-block. 
3648
