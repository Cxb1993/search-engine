I 
 
中、英文摘要及關鍵詞 
 
本計劃以小波轉換或多重小波轉換為基礎，結合階層式樹狀結構的集合分組
(SPIHT)演算法的影像分享系統。這個系統除使用小波轉換的特性外，更運用多
重小波轉換的特性，如提供多重的基底函數而這些函數同時具有正交性
(orthogonality)、對稱/抗對稱性(symmetry/antisymmetry)、及短支撐(support)
等。此計畫包括下列主題：一、具小分存和及時漸進式重建的機密影像分享系統。
二、具嵌入式之容錯的漸進式影像傳輸系統。 
第一個主題是藉由整數小波轉換或多重小波轉換及 Shamir 的(r, m)機密分
享機制，以達成機密影像分享時，其每份分存的資料量能夠大大減少，且可以及
時漸進式重建，而可以進行有效率的儲存或傳輸。採用小波或多重小波轉換的表
示法的特性，使得大部份的能量更集中於低頻帶，及轉換係數在塔形的多重解析
表示上，由大至小的順序與在空間的由左上至右下的方向性一致，這些性質對發
展具小分存和及時漸進式重建的影像分享方法非常重要，這個方法可以僅使用整
數的加法及位元位移兩種運算子快速的完成計算。 
第二個主題，採用階層式樹狀結構的集合分組(SPIHT)演算法及工作於
Galois 場之修改的 Shamir 的(r, m)機密分享機制，獲得具嵌入式編碼且高度緊
密的分存影像之容錯的漸進式影像傳輸系統。這個系統具有嵌入式編碼能力、小
分存和很好的位元率-失真的效能，同時也具有容錯的方法(Pattern 
Recognition 38(2005), 2466-2471)所具有的優點。 
 
關鍵詞: 影像分享、多重解析表示、多重小波轉換、漸進式重建 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
III 
 
 
 
 
 
 
目  錄 
 
一.報告內容…………………………………………………………1. 
1. 前言與研究目的   ……………………………………………1. 
2. 研究方法    …………………………………………………1. 
3. 結果與討論  …………………………………………………2. 
二.參考文獻…………………………………………………………6. 
三.計畫成果自評部份………………………………………………8. 
四. 附錄   …………………………………………………………9. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
2 
 
pre-process in the respective subbands to produce combination coefficients for use in 
the (r, m) threshold scheme. Since the numbers suitable for the (r, m) threshold scheme 
are from 0 to 255 for image with 8-bit intensity levels, we need to take care of this 
requirement. Hence, preprocess procedures are designed by concatenating 
neighboring transform coefficients (or coefficients differences in the smooth subband) 
into one byte in case they are small enough or else scaling their values into the 
appropriate range. So the size of the resulting combination coefficients is reduced and 
its range is adjusted. The sequence of the process starts from the smooth subband and 
follows a zigzag path to the detail subbands in a hierarchical tree such that the 
progressive transmission can be readily achieved. The method has been extended to 
the second topic for embedded and fault-tolerant progressive transmission images.  
 
3. 結果與討論 
Experiments were conducted using single wavelet and multiple wavelet transform, 
respectively as follows. Four images — Lena, Jet, Monkey, and Peppers each has 
512512×  pixels with 8-bit gray levels per pixel — were used in our experiments. 
A. Experiments on Using Wavelet Transform  
The integer wavelet transform derived from Daubechies’ 5/3 biorthogonal wavelet, 
6-level decomposition, and the (r, m) threshold scheme with r=4 and m=6 were used. 
The smaller size compact shadows produced by our method (WT) are shown in Table 
1 in comparison to those obtained by Thien and Lin’s (TL’s) method [6]. The real time 
progressive transmission and reconstruction performance using four of the six 
shadows with different percentages of shadow coefficients from these four shadows is 
shown in Table 2. Note that using the whole shadow coefficients from these four 
shadows results in lossless reconstruction.  
Fig. 1(a) shows the integer wavelet transform of Lena image decomposed to 2 scale 
levels. The combination procedure using sequence 2 was applied to Fig 1(a) to get 
result shown in Fig 1(b). The sharing phase was then applied to Fig 1(b) to get 
shadows and the smooth band of Fig. 1(a) is inserted to every shadow resulting in Fig. 
1(d). Note that the size of each shadow with 128404×  bytes is still smaller than that 
of the shadow with 128512×  bytes using the existing method in [7]. The secret 
image is revealed lossless using all coefficients of any four of those shadows and is 
shown in Fig. 1(c). Benefits of this method are that it is not only with progressive 
transmission capability but also with easier management of the shadows. 
B. Experiments on Using Multiwavelet Transform  
The integer multiwavelet transform with box-and-slope multiscaling functions 
(multiplicity=2) was employed, and its associated integer pre/post-filters are given in 
[12], [13]; 3-level decomposition and the (r, m) threshold scheme with r=4 and m=6 
4 
 
 
 
 
 
 
 
           (a)                      (b)                   (c) 
 
 
 
 
 
 
 
 
 
(d) 
Fig. 1. (a) Integer wavelet transformation of Lena image, (b) The result of 
combination process, (c) The revealed image uses four of the six shadows in (d), (d) 
Shadows with smooth band generated by our algorithm with r=4, m=6 
 
 
 
 
 
 
 
 
 
 
6 
 
二.參考文獻 
[1] N. Bourbakis and, A. Dollas, “Scan-based compression-encryption hiding for 
video on demand,” IEEE Multimedia Mag., vol. 10, pp. 79-87, 2003. 
[2] L. M. Marvel, G. G. Boncelet, C. T. Retter, “Spread Spectrum image 
steganography,” IEEE Trans. on Image Process., vol. 8, pp. 1075-1083, 1999. 
[3] A. Benazza and J. C. Pesquet, “A unifying framework for lossless and 
progressive image coding,” Pattern Recognition, vol. 35, pp. 627-638, 2002. 
[4] A. Shamir, “How to share a secret,” Communication of ACM, vol. 22(11), pp. 
612-613, 1979. 
[5] G. R. Blakley, “Safeguarding cryptography keys,” Proc. of the AFIPS 1979 
National Computer Conference, vol. 48, pp. 313-317, 1979. 
[6] C. C. Thien and J. C. Lin, “Secret image sharing,” Computers & Graphics, vol. 
26, pp. 765-770, 2002. 
[7] C. C. Thien and J. C. Lin, “An Image-sharing method with user-friendly shadow 
images,” IEEE Trans. on CSVT, vol. 13(12), pp. 1161-1169, 2003. 
[8] H. Kim and C.C. Li, “Lossless and lossy image compression using biorthogonal 
wavelet transforms with multiplierless operations,” IEEE Trans. on circuit and 
systems-II: analog and digital signal processing, vol. 45(8), pp. 1113-1118, 1998. 
[9] A. Zandi, J. Allen, E. Schwartz, and M. Boliek, “CREW: Compression with 
reversible embedded wavelets,” Proc. 5th IEEE Data Compression Conf., 
Snowbird, UT, pp. 212-221, 1995.  
[10] W. Kim and C. C. Li, “On Preconditioning Multiwavelet Systems for Image 
Compression,” International Journal on Wavelets, Mutliresolution, and 
Information Processing, vol. 1, pp. 51-74, 2003. 
[11] J. T. Miller, C. C. Li, “Adaptive Multiwavelet Initialization,” IEEE Trans. on 
Signal Processing, vol. 46(12), pp. 3282-3291, 1998. 
[12] K. W. Cheung, and L. M. Po, “Integer Multiwavelet Transform for Lossless 
Image,” Proceeding of 2001 International Symposium on IMVSP, Hong Kong, pp. 
117-120, 2001. 
[13] A. Benazza-Benyahia, J. C. Pesquet, and N. Azzabou, “A new Interband 
Multiwavelet Decomposition For Exact Coding of Multicomponent Images,” 
Proceedings of  2002 ICASSP, v. 4, Orlando, FL, pp. 3521-3524, 2002. 
[14] A. R. Calderbank, I. Daubechies, W. Sweldens, and B.L. Yeo, “Wavelet 
transforms that map integers to integers,” Applied and Computational Harmonic 
Analysis, vol. 5, pp. 332-369, 1998. 
[15] M. D. Adams, and R.K. Ward, “Symmetric-extension-compatible reversible 
integer-to-integer wavelet transforms,” IEEE Trans. on Signal Processing, vol. 
8 
 
三.計畫成果自評部份 
 
In the project a new system based on integer wavelet transform or integer 
multiwavelet transform to share a secret image has been conducted. Taking 
advantages of the transform coefficient magnitude decay and excellent energy 
compaction in wavelet multi-resolution, coefficient combination and processing 
sequences are developed for use in the application of the (r, m) threshold scheme to 
generate shadows for image sharing. It results in shadow size reduction and capability 
for progressive transmission. The effectiveness of our algorithm has been illustrated 
by experimental results on test images. When we keep the smooth subband and insert 
it to every shadow, our algorithm has an additional characteristic for easier 
management of shadows. When compared to the existing method reported in [6], [7], 
our method has the following advantages: (1) with smaller size of shadows, (2) with 
perfect reconstruction capability, and (3) with progressive transmission capability. Out 
of the project, one journal paper (in Journal of International Journal of Wavelets, 
Multiresolution and Information Processing,  Vol.6, No. 6, 907–931, 2008) and two 
conference papers (one in Proceedings of ICICS 2007 and the other in Proceedings of 
ICWAPR 2007) have been published. The manuscript for the published journal paper 
has been attached in the appendix. 
  
 10 
 
SECURE AND PROGRESSIVE IMAGE 
TRANSMISSION THROUGH SHADOWS GENERATED 
BY MULTIWAVELET TRANSFORM 
 Chin-Pan Huang1, Ching-Chung Li2 
 
 
ABSTRACT 
In this paper, multiwavelet transform is used in the context of image sharing employing the 
SPIHT-generated bit stream with the modified Shamir’s (r, m) threshold scheme over Galois field. This 
provides multiwavelet-based embedded shadow images for progressive transmission and 
reconstruction. Both integer multiwavelet transform and balanced multiwavelet transform are 
considered in the method. It is secure and fault-tolerant, and gives small shadow size and excellent 
rate-distortion performance. Experimental results and sample applications are given to demonstrate 
the characteristics of this method. 
Keywords: multiwavelet transform ; secure and progressive transmission; shadow image; SPIHT.  
1Department of Computer and Communication Engineering 
Ming Chuan University, Taoyuan 333, Taiwan R.O.C. 
Tel: 886-3-3507001 ext. 3428 
Fax:886-3-3593876 
Corresponding author: hcptw@mail.mcu.edu.tw 
2Department of Electrical and Computer Engineering 
University of Pittsburgh, Pittsburgh, PA 15261 USA 
 12 
 
three stages: initialization, sorting pass and refinement pass. The output of the SPIHT algorithm is a 
binary bit stream. The detail procedure may be found in [1], [12], and [13]. 
This paper is to present a new image sharing method as an extension of our previous work [6] and 
the secure and progressive transmission of the image shadows [7]. The multiwavelet transform (MWT) 
[8-21] is used instead of the scalar wavelet transform, and sharing is done in the SPIHT generated 
bitstream of the multiwavelet transform coefficients of the image instead of working in wavelet 
coefficients directly. Both integer multiwavelet transform (IMWT) [8,9,14,15] and balanced 
multiwavelet transform (BMWT) [16-21] are considered. Multiwavelet transforms have properties of 
orthogonality, symmetry/antisymmetry and short support simultaneously which are advantageous with 
regard to decorrelation of subband coefficients and computation efficiency. Sharing of the embedded 
transform coefficient bit stream is achieved with the use of the modified Shamir’s thresholding over 
Galois field. We divide the bit stream for every 8 bits into m shares (channels) over Galois field. With 
such embedded shares, it gives excellent rate-distortion and small size shadows for secure, 
fault-tolerant and progressive image transmission. Furthermore, for secret image transmission, the 
system security will be greatly improved.  
The remaining sections are organized as follows. Section 2 reviews briefly multiwavelet transform 
multiresolution decomposition and the modified Shamir’s (r, m) threshold scheme for secret data 
sharing. Section 3 describes the proposed new method for secure image sharing and progressive 
 14 
 
decomposition, the scaling (low-pass) filter coefficients are given by {H(-n)}={[hij(-n)]} (i, j = 1, 2) 
and wavelet (high-pass) filter coefficients are given by {G(-n)}={[gij(-n)]}, (i, j = 1, 2). For 
reconstruction, matrix filters {HT(n)} and {GT(n)} are used. A multiwavelet system has properties of 
orthogonality, symmetry/antisymmetry, and short support simultaneously, but it needs a vector input to 
matrix filters {H(-n)} and {G(-n)} in the signal decomposition. This may be obtained from the input 
signal {f(n)} by taking even-indexed samples {f(2n)} in the first channel and odd-indexed samples 
{f(2n+1)} in the second channel as shown in Fig 1. In general, a proper prefiltering of the vector input 
is needed such that the filtered vector will represent the scaling coefficient vector [ ]T0201 c,c  at the 
scale level 0 for decomposition and multiresolution representation to provide the most useful 
information in applications. A proper post-filtering will give a perfect reconstruction of the input signal. 
 
Fig. 1 Multiwavelet matrix filter bank decomposition and reconstruction. 
      The matrix filter bank in Fig. 1 is equivalent to a multi-channel filter bank shown in Fig. 2 
where {H1(-n)} and {H2(-n)} are low-pass filters, and {H3(-n)} and {H4(-n)} are high-pass filters.  
They receive the same input signal {f(n)} and their outputs are down-sampled by a factor of 4. The 
down-sampled outputs of filters {H1(-n)} and {H2(-n)} are interleaved to give the combined low-pass 
 16 
 
moments of wavelets is not accompanied by other equivalent properties. If a multiwavelet system is 
designed so that such properties also hold true, it is called a balanced multwavelet basis [16-18] with 
the balancing order K denoting its low-pass and high-pass filter banks preserving and annihilating, 
respectively, polynomials of degree k < K. In this case, no prefiltering is needed. For an unbalanced 
multiwavelet system, a suitable prefiltering is needed to transform the input vector to compensate for 
the absence of certain preservation/annihilation property.  
     The multiwavelet transform for a 2-d image can be obtained, using the separable 
two-dimensional basis, by taking the tensor product of two 1-d multiwavelet transforms, first in the 
horizontal direction and then in the vertical direction. For an l-level decomposition, the pyramidal 
structure contains (3l+1) matrices, ( ) ( ) ( ){ }
lj1
3
jlj1
2
jlj1
1
jl U,U,U,S ≤≤≤≤≤≤    giving a total of (3l+1)ρ
2 subimages. 
The Sl contains four subimages of scaling coefficients (smooth subbands) coming from two channels, 
and each of  ( ) ( ) ( )
lj1
3
jlj1
2
jlj1
1
j U,U,U ≤≤≤≤≤≤    ,(j = 1, 2, …, l), contains four subimages of wavelet 
coefficients (detail subbands) from two channels, as shown in Fig. 3(a).  
 
          (a)                         (b)                         (c) 
Fig.3 (a) Schematics of multiwavelet (with multiplicity ρ=2) image decomposition in two levels l=2, 
(b) Multiwavelet multiresolution representation for House image with l=2, ρ=2, (c) Balanced 
multiwavelet multiresolution representation for House image with l=2, ρ=2. 
 
 18 
 
     The first order balanced multiwavelet system of Lian-Chui has short support multiscaling 
functions and multiwavelets [20] shown in Fig. 5. The filter coefficients (in reference to the 4-channel 
filter bank of Fig. 2) are given by  
 
[ ]
[ ]
[ ]
[ ] . /32+ /6,   -1/22/3,  - 2+ 2/1 /3,   0,  2- /6,   -1/22/3,    21/2- 
4
1(n) = H
,/4 2   -1/3+ /4,   1/6,2 -1/3- /4,   1,  2,   -1/3- /4,   +1/62-1/3+ 
4
1(n) = H
,/42,   1/3- /4,   -1/62 1/3+ /4,   1,  26,   1/3+ /4,    -1/21/3- 
4
1(n) = H
,1/34/3,1/3,
4
1(n) = H
4
3
2
1
     (6) 
The balancing order is 1, hence it preserves/annihilates polynomials of degree 0 and the zeroth 
moments of high-pass filters {H3(n)} and {H4(n)} are all zero.  With no need of a prefilter, this 
balanced multiwavelet transform in two scale levels for the 512 x 512 House image is illustrated in Fig. 
3(c).  
        
 
 
 
 
(a) Support=[0,1]                          (b) Support=[0,2] 
 
                                    
 
 
 
 
 
         (c) Support=[0,2]                         (d) Support=[0,2] 
Fig. 5 Basis functions of the Lian-Chui order-1 Balanced MWT: (a) and (b) multiscaling functions φ1(x) 
and φ2(x); (c) and (d) multiwavelet functions ψ1(x) and ψ2(x).  
 
 
 
 20 
 
given any r of the m pairs ( ){ } m,,2,1i,D,i i L= , the coefficients 1r210 a,a,a,a −L  can be solved from 
(7) and (8) by using Largrange’s interpolation method. 
3.   THE PROPOSED METHOD 
As an extension of our previous work on secret image sharing [6], the proposed method for secure 
and progressive image transmission based on multiwavelet transform is diagrammatically shown in 
Fig. 6. In the encoding phase, the input image X is first processed by the multiwavelet (multiplicity 
equal to 2) decomposition to a selected scale level J to form a multi-resolution hierarchical 
representation. Then, the SPIHT encoder is used to process the transform coefficients to obtain an 
embedded bit stream. Finally, this bit stream is shared with the use of the sharing function of the 
modified (r, m) threshold scheme to generate m shadow images. In the decoding phase, the inverse 
process of the encoding phase is followed: first, revealing the embedded bit stream from the received 
shadows, then, applying SPIHT decoder, and finally, taking the inverse multiwavelet transform to 
obtain a reconstructed image Xˆ . 
 
 
 
 
 
Fig. 6. The block diagram of the multiwavelet-based secure and progressive image transmission. 
 22 
 
1. Select parameters J, m and r (r≤m). Perform mulwavelet transform to decompose an image to a 
selected scale level J to obtain transform coefficients arranged in the hierarchical multiresolution 
representation. 
2. Apply SPIHT encoder to encode the transform coefficients into an embedded bit stream. 
3. Share the bit-stream by sequentially taking 8 bits from the bit stream to form a sharing number and 
taking r sharing numbers to form a sharing section.   
4. Use the r sharing numbers of the sharing section generated in Step 3 to serve as the r coefficients of 
the polynomial sharing function qb(x) of equation (7). Evaluate qb(x) in GF(28) for shadow numbers 
x = 1,2,. . . ,m, to generate m pixels for the m shadow images. 
5. Repeat Steps 3 and 4 until all bits in the bit stream generated in Step 2 are processed. Thus, m 
shadow images are obtained. 
3.2.  Decoding Phase 
The encoded data can be decoded by using any r of the m shadows via the following steps. 
1. Take one pixel (coefficient) from each of the r shadows to form a sharing section sequentially from 
left to right and for all sections from top to bottom. 
2. Use each set of these r numbers Di’s and apply Lagrange’s interpolation method to solve for the 
values of polynomial coefficients ,a,a 10 1r2 a,a −L  in equations (7) and (8).  
3. Repeat steps 1 to 2 until a given bit rate is reached or until all pixels of the r shadows are processed. 
 24 
 
There are 256 possible solutions in solving for r unknown coefficients using the above r − 1 equations, 
and hence the probability of guessing the correct solution is 1/256 if the shadow images have uniformly 
distributed intensity levels. There are v sharing sections, thus, v polynomials for the whole bit stream of 
an image (multiwavelet transform coefficients), and hence the probability of obtaining the correct 
image is (1/256) v.  For example, for a 512512× image, if r =2, there are about 100,000 polynomials 
to be involved.  The probability of guessing the right pixel values in a shadow image is 
000,100
256
1 ⎟⎠
⎞⎜⎝
⎛  
which is extremely small. An intruder has only this near zero probability to get the correct bit stream, 
not to mention the difficulty of reconstructing the original image. The reconstructed image for the 
example on House image using the IMWT (with r=4, m=6) is shown in Fig. 7, (a) using three (r-1=3) 
shadow images and one randomly estimated shadow image and (b) using four (r=4) shadow images. 
The reconstructed image using BMWT (with r=4, m=6) for the example has the similar result as that in 
Fig 7. These results indicate that there is practically no correlation between the original image (House) 
and the reconstructed image when less than r shadow images are used. The original image is perfectly 
reconstructed when r shadow images are used. Since the above security analysis of the sharing method 
is based on the assumption of uniformly distributed intensity levels of shadow images, we examine 
experimentally obtained histograms of shadow images to justify the assumption. Let us consider the 
normalized histogram f(xi) of a shadow image with intensity levels {xi, i=0,1,⋅⋅⋅, n } so that f(xi) gives 
an estimate of the distribution of ix .  
 
 26 
 
 
 
 
 
 
 
 
 
 
                      (a)                                    (b)  
 
 
 
 
 
 
 
 
 
 (c)                                   (d) 
Fig. 9.  Four test images: (a) House, (b) Barbara, (c) Scene, and (d) Peppers. 
The average value of the ratio of standard deviation to mean for m shadow image histograms of each 
test image, using the new multiwavelet based method (either IMWT or BMWT) is shown in Fig. 8 in 
comparison to those obtained by using Integer Wavelet Transform (IWT) method [6] and Chen and 
Lin’s (CL’s) method [3]. The new method (IMWT- or BMWT-based) has smaller average values of 
f/σ  in the experimental study. This supports the assumption that histograms of the shadow images 
in our new method are almost uniformly distributed, the best among four methods, and the probability 
of guessing the right shadow images will be extremely small, and so the new method is very secure. 
 28 
 
higher reconstruction quality in PSNR and the BMWT method had the highest quality among all 
methods. Note that the wavelet based methods can reconstruct the whole image at any bit rate while 
CL’s method can reconstruct the whole image only at a fixed rate depending on the designated 
threshold settings [3]; thus the proposed method is more flexible in applications. For a fair comparison, 
no entropy coding was involved in these methods. The experimental results on Barbara image are 
shown in Fig. 12 for visual examination. Fig. 12(a) and (b) show the integer multiwavelet transform 
and the balanced multiwavelet transform of Barbara image, respectively. In Fig. 12(c) and (d), six 
embedded shadows of equal importance were generated by the IMWT method and the BMWT method, 
respectively. The image can be reconstructed using any four of the six shadows with different bytes of 
coefficients as shown in Fig. 13 for the IMWT method and in Fig. 14 for the BWMT method. Any two 
shadows could be damaged or lost without affecting the reconstruction, so our method is fault-tolerant. 
For a secret image, it transmits shadows in six different channels; an interception up to 3 (r-1=3) 
channels by an adversary can not reveal the secrecy.  
 
 
 
 
 
 
Fig. 10. Shadow size comparison.  
 
 
 
 30 
 
 
 
 
 
 
 
 
 
 
 
 
                          (a)                                (b)  
                   
 
 
 
 
 
 
 
 
 
 
                        (c)                                (d) 
Fig. 13. Embedded Progressive reconstruction by the IMWT method using any 4 out of 6 shadows in 
Fig. 12(c) with the following bpp and the resulting PSNR (dB): (a) 0.01, 21.93, (b) 0.1, 27.85, (c) 1.0, 
38.36, and (d) 4.8, lossless.                                                               
 
 
(a)                                   (b)  
                   
 
 
 
 
 
 
                  (c)                                    (d) 
Fig. 14. Embedded Progressive reconstruction by the BMWT method using any 4 out of 6 shadows in 
Fig. 12(d) with the following bpp and the resulting PSNR (dB): (a) 0.01, 22.41, (b) 0.1, 28.33, (c) 1.0, 
38.86, and (d) 4.8, 70.5. The corresponding results obtained by the IWT method [6] are 21.78dB, 
22.50dB, 27.18dB and 68.50dB, respectively.  
 32 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
                   (a)                                 (b) 
 
                    
 
 
 
 
 
 
 
 
 
 
 
                    (c)                                 (d) 
Fig. 16. Reconstructed images by the following methods at the bit rate of 2.0 bpp with the resulting 
PSNR (dB): (a) IMWT, 39.05, (b) BMWT, 39.67, (c) IWT, 28.50, and (d) CL’s, 20.81. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 34 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
                   (a)                                      (b) 
 
 
 
 
 
 
 
 
 
 
                  (c)                                        (d) 
Fig.19  Progressive reconstruction of Military Map1 by the BMWT method (m=6, r=4, J=3) using  
any 4 out of 6 shadows with the following percentages of coefficients and the resulting PSNR: (a) 1%, 
24.67dB, (b) 5%, 29.67dB, (c) 15%, 37.09dB, (d) 50%, 59.35dB. The corresponding results obtained 
by the IWT method are 21.38dB, 23.72dB, 25.73dB and 32.15dB, respectively, as reported in [6]. 
 
 
 
 
 
 
 
 
 
 
 
 
 36 
 
The reveal process provides progressive reconstruction of a mammogram. A mammogram is shown in 
Fig. 17(a). Since the method has progressive transmission capability, a doctor at a remote clinic may 
unveil a small percentage of the reconstruction coefficients for a quick examination as illustrated in 
Fig. 17 (b) or (c). He can progressively get high quality and lossless reconstruction as shown in Fig. 
17(d) to examine the mammogram in detail and/or to consult with other physicians at different sites.  
Next, let us illustrate the application to military map (secret image) telebrowsing.  Let the 
BMWT method be used where each map image is represented by m shadows that are distributed to 
various sites. It can assure that the secret images are securely protected. Small shadows help to reduce 
the storage space requirement as the volume of military maps used in a war is huge. At the receiving 
end, soldiers (viewers) may use the progressive reconstruction to browse through coarse images 
quickly to skip irrelevant maps and to find the desired map efficiently. Two military maps, Map 1 and 
Map 2, from [23] are shown in Fig. 18. If the desired map is not Map1, a soldier may skip it at a glance 
of its reconstructed image of the lowest possible resolution, e.g., in Fig. 19 (a). The soldier will look for 
the target image Map2 in Fig. 20, and will keep progressive reconstruction to the required quality; even 
to the perfect reconstruction should the received shadow images be uncorrupted by any channel noise.  
Compare these results with those obtained by the IWT method in [6], we find that the BMWT method 
(with m=6 and r=4) is more efficient and gives better reconstruction quality at various bit rates.  
6.  Conclusions 
A new method for image sharing and progressive transmission based on multiwavelet transform is 
presented. Both integer multiwavelet transform and balanced multiwavelet transform are considered in 
the method. The modified Shamir’s (r, m) threshold scheme is used in constructing m shares of the bit 
stream generated by SPIHT of the multiwavelet transform of an image. It posesses security protection 
and progressive reconstruction features, gives small shadows, and has good reconstruction quality at 
low bit rate. Experimental results have shown that, even when low order multiwavelets are used, the 
method gave better performance than that of the scalar integer wavelet transform based method 
reported in [6]. When the order-1 Lian-Chui balanced multiwavelets are used, the method (BMWT 
method) has slightly better performance than that when the low order integer multiwavelets are used 
(IMWT method). The overall advantages of this method can be summarized as follows: (1) An image 
can be reconstructed by using any number of bytes of its r shadow images so that it is an embedded 
progressive transmission; (2) it may allow m−r shadows to be possibly lost, hence it is fault tolerant; 
 38 
 
12. M. Contronei, D. Lazzaro, L. B. Montefusco, L. Puccio, “Image Compression Through Embedded 
Multiwavelet Transform Coding,” IEEE Trans. on Image Processing, vol. 9 (2), pp.184-189, 2000. 
13. B. Martin and A. E. Bell, “New Image Compression Techniques Using Multiwavelets and 
Multiwavelet Packets,” IEEE Trans. on Image Processing, vol. 10 (4), pp. 500-510, 2001. 
14. K. W. Cheung, and L. M. Po, “Integer Multiwavelet Transform for Lossless Image”, Proceeding of 2001 
International Symposium on IMVSP, Hong Kong, pp.117-120, 2001. 
15. A. Benazza-Benyahia, J. C. Pesquet, and N. Azzabou, “A new Interband Multiwavelet Decomposition For 
Exact Coding of Multicomponent Images,”  Proceedings of  2002 ICASSP, v. 4, Orlando, FL, pp. 
3521-3524, 2002. 
16. J. Lebrun, M. Vetterli, “Balanced Multiwavelets Theory and Design,” IEEE Trans. On Signal Processing, vol. 
46 (4), pp. 1119-1125, 1998. 
17. J. Lebrun, M. Vetterli, “High-Order Balanced Multiwavelets: Theory, Factorization, and Design,” IEEE Trans. 
On Signal Processing, vol. 49 (9), pp. 1918-1930, 2001. 
18. I. W. Selesnick, “Multiwavelet Bases with Extra Approximation Properties,” IEEE Trans. on Signal 
Processing, vol. 46 (11), pp. 2898-2908, 1998. 
19. I. W. Selesnick, “Balanced Multiwavelet Bases Based on Symmetric FIR Filters,” IEEE Trans. on 
Signal Processing, vol. 48 (1), pp. 184-191, 2000. 
20. J. A. Lian, C. K. Chui, “Balanced Multiwavelets with Short Filters,” IEEE Trans. On Signal 
Processing Letter, vol. 11(2), pp. 75-78, 2004. 
21. L. Ghouti, A. Bouridane, M. K. Ibrahim, and S. Boussakta, “Digital Watermarking Using Balanced 
Multiwavelets,” IEEE Trans. On Signal Processing, vol.54 (4), pp. 1519-1536, 2006. 
22. R. Z. Wang and C. H. Su, “Secret image sharing with smaller shadow images,” Pattern Recognition 
Lett., Vol. 27, pp. 551-555, 2006. 
23. The Library of Congress website, http://memory.loc.gov/ammem/gmdhtml/milhome.html. 
24. E. O. Sheybani, R. Sankar, “ATMTN: a telemammography network architecture,” IEEE 
Transactions on Biomedical Engineering, vol.49 (12), pp. 1438-1443, 2002. 
 
 
Detection and Recognition of Scoreboard for Baseball 
Videos 
Chaur-Heh Hsieh1, Chin-Pan Huang1 , and Mao-Hsiung Hung2  
 
1 Dept. of Computer and Communication Engineering, Ming Chuan University 
Taoyuan, Taiwan 
2 Dept. of Information Engineering, I-Shou University 
Kaohsiung, Taiwan 
 1hsiehch@mail.mcu.edu.tw  
Abstract. This paper presents an effective and efficient detection and 
recognition of scoreboard caption method for baseball videos. The method first 
identifies the scoreboard type using template matching and then extracts the 
caption region of each type. Next it recognizes the extracted caption utilizing a 
novel digit recognition scheme which is constructed by a simple neural network 
classifier. It results in a much simpler method with significantly higher 
recognition rate over that of the universal OCR scheme. Experimental results 
demonstrate the effectiveness of the proposed method and indicate that it 
identifies twelve scoreboard types correctly and recognizes scoreboard caption 
over 98%.  
Keywords: Detection and recognition of scoreboard caption, OCR, neural 
network classifier 
1   Introduction 
Over the past decade, the amount of multimedia information has grown 
explosively. This trend necessities the development of efficient content-based 
indexing and retrieval techniques. Recently, automatic sports video analysis has 
received increasing attention, because sport video appeals to large audiences. The 
processing of sports video generates various valuable applications such as 
highlighting, summarization, indexing/retrieval, athlete’s training and entertainment. 
The application systems make the delivery and searching of video contents more 
effective and efficient. For example, highlight or summarization makes it easy to 
deliver sports video over even narrow band networks, such as the Internet and hand-
held wireless, since the valuable semantics generally occupy only a small portion of 
the whole content. Due to the automatic indexing of sport contents, users can retrieve 
their preferred particular clips of sport videos such as hits of baseball or goals of 
soccer. 
position of a scoreboard, and then determines scoreboard type and the location of 
each field of the scoreboard. This process only performs for the initial part of a test 
video, called initial clip. In the recognition process, it identifies the data of each field 
of a scoreboard for a whole video. The details are described in the following. 
 
 
Scoreboard type 
identification 
l
Initial clip 
Field box 
cropping 
Testing 
video
Digit & base 
recognition 
Multi-frame 
majority decision
Scoreboard 
Info 
Location process 
Recognition process 
Field location
 
Fig. 2. Flow chart of overall scoreboard detection and recognition 
2.1   Location Process  
Scoreboard Type Identification. The flow chart of the scoreboard type identification 
is shown in Fig. 3. The purpose of this stage is to determine which scoreboard type is 
embedded in the testing video. The identification procedure contains four steps as 
follows: 
 
 
 
Fig. 3. Flow chart of scoreboard type identification 
(1) Temporal averaging calculates the average intensity through a few (say 300) 
consecutive frames of an initial clip of a video. The procedure is similar to that of our 
previous work [4]. Superimposed caption is attached at fixed location in the video, 
and generally the caption always exists in all video frames. Therefore, after temporal 
averaging, the superimposed caption still remains, whereas the other video contents 
would disappear.  
(2) A simple binarization detects the caption region from the average image. Given 
the average image A(x,y), the binary image B(x,y) is obtained by Eq.(1) 
Our experiment result indicates 100% of identification rate is obtained by using 
both shape and texture matching. However, 75% of accuracy can be achieved if only 
shape matching is employed. 
 
 
  
  
Fig. 4. Original caption and its blurred version 
Field Location. A scoreboard contains several game status fields including team 
names, base, score, inning, out#, ball# and strike#. The positions of all fields for a 
particular scoreboard type are fixed, so the field position information can be obtained 
by manual labeling. Fig. 4 illustrates field locations of a typical scoreboard type. The 
locations of the important fields (marked by green rectangle) of all scoreboard types 
are pre-stored in a database. Once the type of a scoreboard is determined, its 
corresponding field location information can be obtained by checking the database, 
and then the results are sent to the field box cropping of the recognition process. 
2.2. Digit Recognition 
In the recognition phase, the image of each field is cropped out according to the field 
location information obtained from the location process mentioned above. These 
images including base status and digit data are then identified. The base status can be 
easily identified using color information since it changes from one color to another 
when the base is occupied. The recognition of digits of 0 to 9 includes three stages, 
preprocessing, feature extraction and neural network classifier, as shown in Fig. 5. 
Firstly, the preprocessing binarizes and partitions digit boxes from the original frame. 
Then, feature extraction calculates a set of feature vector representing the digit inside 
the cropped box. Finally, a simple neural network classifier, obtained by a prior 
training process, identifies the input digit. The detailed is described in the following. 
Preprocessing. It executes the following steps in this stage. 
Step 1: size enlargement 
Step 2: binarization using three membership functions for RGB components  
Step 3: morphological erosion  
Step 4: size normalization based on the minimum bounding box of the binary image 
Step 5: extraction of outside contour and inside contour of a digit  
For the binarization, we define three membership functions μR(r), μG(g) and μB(b), 
for R, G, and B components, respectively, using the domain knowledge of the 
scoreboard styles. Our investigation indicates that the image features of scoreboards 
vary with different scoreboard styles. Thus, we define several sets of membership 
functions for various styles, as shown in Fig. 6. 
 Fig. 7. Outside and inside contours of 10 digits 
For the outside contour, all types of orientation features, denoted as v1, v2,…, v8, 
are used. For the inside contour, only four types of orientation features including 
horizontal, vertical, slash I and backslash I, denoted as v9, v10,…, v12, are considered. 
For the outside contour, all types of zoning features, represented as v13, v14,…, v20, are 
used. For the inside contour, only the horizontal zone is considered and its features 
are denoted as v21 and v22. In summary, a 22-D feature vector from a digit image is 
extracted. For the digits “1”, “2”, “3”, “5” and “7”, there are no inside contour, so 
zero is padded for the corresponding dimensions including (v9, v10,…, v12) and (v21, 
v22). 
Table 1. Orientation patterns of eight types 
[ ]11  ⎥⎦
⎤⎢⎣
⎡
1
1  ⎥⎦
⎤⎢⎣
⎡
01
10  ⎥⎦
⎤⎢⎣
⎡
10
01  
Horizontal Vertical Slash I Backslash I 
⎥⎥
⎥
⎦
⎤
⎢⎢
⎢
⎣
⎡
01
10
10 or
⎥⎥
⎥
⎦
⎤
⎢⎢
⎢
⎣
⎡
01
01
10  
⎥⎥
⎥
⎦
⎤
⎢⎢
⎢
⎣
⎡
10
10
01 or
⎥⎥
⎥
⎦
⎤
⎢⎢
⎢
⎣
⎡
10
01
01
⎥⎦
⎤⎢⎣
⎡
011
100 or ⎥⎦
⎤⎢⎣
⎡
001
110
⎥⎦
⎤⎢⎣
⎡
110
001 or ⎥⎦
⎤⎢⎣
⎡
100
011  
Slash II Backslash II Slash III Backslash III 
 
Table 2. Zoning partition of four types 
 
 
   
Horizontal Vertical Slash Backslash
Neural Network Classifier. A neural network of single layer of ten neurons is 
employed to classify ten digits, as shown in Fig. 8. Log-Sigmoid of transfer function 
and Widrow-Hoff learning rule are employed [5]. In training stage, the digits of 
twelve caption styles (i.e. twelve digit fonts) were collected, and their feature vectors 
using the scheme mentioned above were extracted. Then, applying the feature vectors 
into learning until mean square error (MSE) has been converged below an acceptable 
3.  Experimental Results 
In the experiments, baseball videos from seven baseball games of American League Champion 
Series (ALCS) of 2004 MLB playoffs are used. Those videos are denoted as ALCS 1~7, where 
ALCS 1, 2, 6 and 7 were taken place in Yankee Stadium (home of New York Yankees) and 
ALCS 3, 4 and 5 in Frenway Stadium (home of Boston Red Sox). All the videos are 
compressed in MPEG-1 format with frame size of 352x240 and frame rate of 30 fps. 
Experimental results are summarized in the following. 
Five items of information on the scoreboard including occupied base, scores, top/bottom 
inning and number of out are planned to identify. The goal is achieved by using the scheme 
described in Section 2. The results of scoreboard recognition are listed in Table 3. It indicates 
that average recognition rate achieved is over 98%. In addition, the performance is rather stable 
for all games. 
The commercial OCR SDK, designed for all of alphabets, digits and symbols, of Lab 
Asprise [6] is utilized in experiment. It is applied to recognize score and out# captions in videos, 
and its results are compared with our scheme in Table 4. It indicates our scheme performs 
significantly better than OCR does. In addition, our scheme is much simpler than OCR in 
implementation. 
Table 3. Results of scoreboard recognition of proposed scheme 
Games Base Scores of two teams Top/bottom inning # of out 
ALCS 1 99% (78/79) 100% (158/158) 100% (79/79) 100% (79/79) 
ALCS 2 100% (71/71) 100% (142/142) 100% (71/71) 100% (71/71) 
ALCS 3 97% (95/98) 99% (195/196) 100% (98/98) 100% (98/98) 
ALCS 4 100% (107/107) 99% (212/214) 99% (106/107) 97% (104/107) 
ALCS 5 94% (118/126) 99% (250/252) 98% (123/126) 95% (120/126) 
ALCS 6 99% (74/75) 94% (148/150) 99% (74/75) 99% (74/75) 
ALCS 7 98% (82/84) 99% (166/168) 100% (84/84) 98% (83/84) 
Average 
accuracy 
rate 
98% (625/640) 99% (1271/1280) 98% (635/640) 98% (629/640) 
PS: %100
 truthground of#
detectedcorrect  of #rateaccuracy ×=  
4.   Conclusions 
An effective and efficient method for detecting and recognizing baseball 
scoreboard caption in broadcast videos has been presented in this paper. The method 
consists of three novel schemes including scoreboard type identification, field box 
location and digit recognition. It achieves more than 98% of recognition rate for the 
baseball scoreboard, which is significantly better than the conventional OCR. In 
addition, the appropriate usage of the domain model makes the system much simpler 
than OCR in implementation. The extension to other sport videos is currently 
investigated. 
 
