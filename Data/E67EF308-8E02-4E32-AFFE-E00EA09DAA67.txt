 2
目 次 
摘要. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3 
一、計畫緣起與目的. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4 
二、系統架構. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6 
三、計畫執行與整合方式. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9 
四、對過去重要審查意見之回覆. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15 
五、計畫成果展示. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16 
六、計畫成果自評. . . . . . . . . . . . . . . . . . .. . . . . . . . . .25 
七、參考文獻. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28 
 4
一、 計畫緣起與目的 
電視的數位化可以提昇電波頻譜的使用效率，提供民眾更高品質的視聽服
務及多元的選擇，並促進平面顯示器、數位電視機及數位內容等相關產業的發
展，因此歐美日等先進國家自十餘年前即開始推動廣電產業的數位化。美國於
2009 年 6 月 12 日起全面停止播送類比地面廣播電視信號，開始進入全數位電視
廣播的時代，歐洲國家從 2010 年起陸續停播類比電視信號，日本於今(2011)年全
面停播類比廣播電視，台灣地區則預計於明(2012)年全面停播類比地面廣播電
視。我國並將數位電視的發展遠景定為「數位電視普及化、數位頻道多元化、數
位內容優質化、數位落差極小化」，期望藉由明確之政策宣示、優惠之輔導獎勵、
並輔以宣導推廣等措施，以達成我國近期電視全面數位化的目標。 
除了透過傳統地面廣播、衛星廣播、與有線廣播等接收技術之外，近年來
數位電視也開始強調移動接收與手持裝置技術。在手持式行動裝置（如手機或 平
板電腦）上收看電視節目，可以讓廣大的行動通信用戶隨時隨地獲取他們需要的
資訊和喜愛的節目，也可以讓通訊業者提供更多樣化的多媒體加值服務。隨著各
國行動數位電視系統的陸續開通，全球行動電視服務的用戶數將會有明顯的成
長，2010 年全球行動電視用戶數約達 1 億之規模。另外，工研院 IEK 預估 2011
年內嵌行動電視的手機（電視手機）的銷售量會超過 1.2 億支，普及率(penetration)
將超過 10%。從行動電視發展趨勢及我國產業結構來看，手持式行動電視結合行
動通訊及應用服務，將是我國產業發展非常好的機會。 
目前國際間已（試）營運的手持式電視系統，包括 DVB-H、T-DMB、ISDB、
MediaFLO、ATSC-M/H 及 CMMB 等幾種。在這幾種標準中，DVB-H 標準是目
前聲勢最浩大且市佔率較高者；而且對於數位電視地面廣播系統採用 DVB-T 標
準者（如我國），採用 DVB-H 將可相容於現有地面廣播傳輸模式與終端接收設
備；也因此，本計畫以實作 DVB-H 標準為目標。 
 
圖一、DVB-H 的通訊協定堆疊 
 6
二、 系統架構 
為有效實現本計畫之目標，本專案除了總計畫之外，另外包括其他 5 個子計畫，
並由總計畫統整合成為一個完整的接收系統。各子系統分別為： 
 總計畫(MAIN)：嵌入式 DVB-H 接收系統之開發，除了負責撰寫主程式、
進行專案管理與系統整合，亦同時開發使用者介面與 ESG 解析軟體。 
 子計畫一(VIDEO)：DVB-H 視訊解碼軟體之開發，包含音訊解碼 
 子計畫二(IPDC)：DVB-H 網路與傳輸層軟體之開發 
 子計畫三(LINK)：DVB-H 資料鏈結層軟體之開發 
 子計畫四(MPEGTS)：DVB-H 傳輸串流解碼軟體之開發 
 子計畫五(ANT)：DVB-H 具全頻寬縮小化天線之開發 
各子計畫在通訊協定堆疊 Android 架構之定位如圖二所示，由天線(ANT)收集 RF
訊號，其餘模組則順序負責從 MPEG-2 傳輸串流到影音視訊與輔助資料的解碼與
呈現。 
MPEG-2 TS packet
IP datagram
FLUTE / ALC / LCTRTP / RTCP
UDP
IP
User Interface / Viewer
Video Audio ESG
MPE-FEC frame
MPE sections
(with Time Slicing)
MPE-FEC sections
(with Time Slicing) 
MPEG-2 TS Decoder
DVB-H PHY
DVB-H Antenna
MAIN
VIDEO
IPDC
LINK
MPEGTS
ANT
Application Layer
Service Layer
Library and Native
Service Layer
Hardware Adaptation Layer
Hardware Layer
 
圖二、本專案各子計畫在通訊協定堆疊及 Android 架構之定位 
 8
MAIN-EI-01
DVB-H user
EMS(UI)
DVB Message Parser 
M
AI
N
-U
I-0
1
DVBDeocder
LINK
MPEGTS
M
AI
N
-U
I-0
2
M
AI
N
-U
I-0
3
M
AI
N
-U
I-0
4
MAIN-II-02
DVB-HMAIN-EI-02 MAIN-EI-03
VIDEO
MAIN-II-01 MAIN-II-05
MAIN-II-07
MAIN-II-03
MAIN-II-04
M
AI
N
-U
I-0
5
MAIN-II-06
DVBController
IPDC
Communication and 
Control  Module
DVB Srevice
MAIN-II-08
MAIN-II-09
MAIN-II-11
MAIN-II-10
M
AI
N
-U
I-0
6
 
圖五、本計畫之系統架構圖 
 
 10
 Android service 實作  
 修改國科會審查完畢之 RSD&PEP 文件  
 完成 SDD 文件  
 Sprint #5 - Integration by Parts and by Scenarios  2010/4/22 – 2010/6/15 
 建立主要 data flow 各模組的測試檔案 phase 2: IPDC & VIDEO 
 建立主要 data flow 各模組的測試檔案 phase 3: get ESG content 
 各子計畫確認在 Android 軟體架構之程式流程  
 各子計畫開發各別 DVB-H 模組  
 測試 Scenario 1: StartService (Initilalization) 
 測試 Scenario 2: getESG  
 完成 STD 文件  
 撰寫期中進度報告 
 Sprint #6 - Performance Optimization on Android   2010/6/17 – 
2010/8/10 
 修改國科會審查完畢之 SDD 文件  
 改善在 Android/PC 平台之效能問題  
 測試 Scenario 3: play 
 Code Review 
 Sprint #7 – 1st-Year Project TouchDown  2010/8/11 – 2010/9/9 
 測試 Scenario 4: stop 
 DVB-H Service 效能提升  
 強化系統穩定度與強健性  
 撰寫開發手冊與使用者手冊  
 修改國科會審查完畢之 STD 文件  
 程式碼及手冊上傳至 Open Foundry 
 報名 2010 開放原始碼創新應用開發大賽  
 Sprint #8 - Transition to 2nd-Year Project   2010/9/10 – 2010/10/14 
 確認第二年計畫目標  
 解決反覆操作(換台、換頁、返回)的當機問題  
 ANT 確認發射器，完成 DVB-H 訊號發射與實測的準備  
 Sprint #9 – Requirement Set-Up and Preparation of 2nd-Year Project  
2010/10/15 – 2010/11/18 
 建立 Android 2.2 開發環境 (EAS) 
 解決 Android 2.2 音訊播放的問題 (VIDEO) 
 Sprint #10 – Preparation for Android Pads 2010/11/19 – 2010/12/16 
 第二年計畫 RSD 及 PEP 文件撰寫  
 完成在 Android PAD 上之展示規劃 (EMS) 
 確認如何使用 RTP streaming server (EAS, VIDEO, IPDC) 
 12
 PAD 使用者介面優化  
 Sprint #17 – Happy Ending  2011/8/5 – 2011/9/2 
 設定 demo scenarios 的錯誤率(MPEGTS, LINK, VIDEO, MAIN)  
 code review (phase 2, MPEGTS, IPDC, VIDEO, MAIN) 
 期末成果簡報及實體展示  
 修改使用手冊 
 Remaining Bug Fixing 
 程式整理 
 完整的整合測試 
本專案之實體展示架構如圖六所示。由於台灣地區目前並沒有實際播送
DVB-H的電視訊號，所以我們以事先錄製的DVB-H節目(MPEG Transport Stream
的格式)，透過藍芽 Bluetooth 或 WiFi 做無線射頻訊號的傳送與接收，然後利用
本專案的軟體在 Android 手機或平板上進行 DVB-H 電視節目的觀賞。 
 
圖六、本計畫之實體展示架構 
根據本專案「需求規格報告書」操作概念所規範的使用者案例（圖四），我
們設計詳細的循序圖(Sequence Diagram)作為動態模型，其中 getESG（讀取電子
節目選單）與 Play Program（播放節目）兩個 Scenarios 的循序圖如圖七所示。本
專案之 Class Diagram 如圖八所示。 
 14
 
圖八、本計畫 Agent Related Class Diagram 
本計畫為自由軟體專案，全部以開放原始碼的方式進行軟體開發。本計畫
採用之軟體開發環境與工具如下： 
 Project Management: ezScrum  
 Version control: subversion 
 Linux OS: Ubuntu 9.10  
 IDE  
 Eclipse 3.5(J2SE 6.0)  
 CDT 5.0 
 Subclipse 1.6 
 CppUnit 1.12.x 
 STL ARM-Porting Version 
 Android ADT 10.0.1 
 Android SDK 3.0 with SDK tools Revision 10 
 Android NDK r5b  
 
 16
五、 計畫成果展示 
1. 總計畫(MAIN)，除了負責撰寫主程式、進行專案管理與系統整合，亦同時開
發使用者介面與 ESG 解析軟體。 
MAIN 主要實做之 7 大功能如圖九所示，分別為頻道播放器、掃描頻道、
頻道清單、節目行程表、設定系統參數、藍芽傳輸和 Wi-Fi 傳輸。底層所實作的
模組包括：掃描頻道、檔案管理、 ESG 儲存表、解析 Bootstrap、解析 ESG Data 
Model、解析 FDT(File Description Table)、解析 SDP(Session Description Protocol)
和解壓縮(ungzip)模組，最後還有跟其它子計畫之間的溝通模組。本系統目前掃
描的動作，是從 Bootstrap 頻道裡面取得所有 ESG Provider 資訊，接著掃描所有
ESG Provider 頻道取得 ESG 資訊，然後將這些資訊儲存起來，方便以後使用者
快速查詢 ESG 資訊。 
 
圖九、涵括於 MAIN 的 EMS 子系統架構圖 
 
啟動 DVB-H Player 後，會進入到初始化畫面。如果已經切換到其它畫面，
可以按 Menu 鍵>Preferences 回到初始化畫面。在初始化畫面中，需要設定 DVB-H
資訊來源，包含來源類型及 IP、Port Numer。來源類型可以是 File、Bluetooth、
或 Wi-Fi，利用手指在螢幕上水平滑動可切換至各個來源類型的畫面。按下 OK
按鈕系統會自動載入使用者先前的設定，按下 setting 按鈕系統會進入所選取的
來源設定畫面，使用者在設定頁面裡選擇資訊來源的位址(WiFi IP、Bluetooth 
MAC…等)。設定完 DVB-H 資訊來源後，按 OK 按鈕回到初始頁面，初始化成
功後會切換到掃描頻道列表畫面，失敗則會顯示相關訊息，如圖十。按 Menu 鍵 
> Scanner 會進入到掃描頻道列表畫面。按下 Scan Channel 按鈕後開始掃瞄頻道
列表，此時掃瞄的進度會顯示在畫面上，完成後會切換到頻道列表。如果掃瞄頻
道列表過程中想要中止，可以按 Cancel 按鈕中止，如圖十一。按 Menu 鍵>Service 
 18
 
圖十二、節目列表顯示畫面 
由頻道列表點擊頻道，或是按 Menu 鍵>DVBHPlayer 可以進入到播放節目畫
面。在播放節目畫面中，可以進行以下動作，如圖十三到圖十六所示： 
(1) 上一個頻道。 
(2) 開始/停止節目播放。 
(3) 下一個頻道。 
(4) 音量調節控制器，左邊為靜音按鈕。 
(5) 將頻道加入我的最愛的按鈕。 
(6) 進入操作說明頁面按鈕。 
(7) 更多進階設定。 
(8) 節目資訊按鈕 
(9) 變更畫面大小按鈕。 
(10) 快速切換頻道選單。 
(11) 快速叫出節目時間表。 
(12) 於播放畫面中，由左往右/由右往左滑動可切換至上一個/下一個頻道。 
     
 
圖十三、播放畫面 
 20
2. VIDEO 子計畫 
VIDEO 子計畫以 Android MediaPlayer 為基礎進行 H.264/AVC 視訊及
HE-AAC 音訊的解碼，並另外完成在 Android 平板電腦環境影音解碼所需的其他
工作，整體流程圖如圖十七所示。細部工作項目包括：(1) SDP 影音解碼資訊之
解析，包括 H.264 參數集(Parameter Set)、(2) RTP 與 RTCP 封包之接收與處理、
(3)收集 H.264 NALU 及 HE-AAC 封包，配合 Android MediaPlayer 進行影音之解
碼與播放、(4)開發 RTSP streaming server，以串流的形式播放影音、(5)影音同步
(lip synch)、(6)開發強健性解碼與錯誤隱藏機制，讓影片在 RTP 封包遺失或錯誤
時仍可順利播放、(7)移植到 Android 3.0 並完成在 PAD 上之整合測試、(8)撰寫文
件及使用手冊等。使用本計畫錯誤隱藏技術的結果如圖十八所示。 
 
圖十七、VIDEO 子計畫流程圖 
     
未做錯誤隱藏                          增加錯誤隱藏 
圖十八、錯誤隱藏的結果比較 
 22
4. LINK 子計畫 
本子計畫連接 MPEGTS 子計畫及 IPDC 子計畫。MPEGTS 子計畫負責傳輸
串流解碼，它將屬於所要觀看節目的傳輸串流封包 (transport stream packets) 濾
出，並解出 sections 傳遞給本子計畫。本子計畫以里得所羅門解碼改正串流中的
錯誤位元，並解除 MPE/MPE-FEC 封裝得到 IP datagrams，再將 IP datagrams 傳
給 IPDC 子計畫。 
從參考文獻的研究結果發現，規格書中依據 CRC 檢查結果以決定整個
section 是否正確的方法效果較差，反而使用傳輸串流封包中的錯誤旗標 
(transport error indicator) 來決定此傳輸串流封包的內容 (payload) 是否正確的效
果較佳。因此我們依據此利用錯誤旗標決定每一個傳輸串流封包正確度的原則，
修改 section 解封裝的方法。我們重新設計兩種新的演算法，改善資料鏈結層軟
體的強健性，並以電腦模擬確認這兩種方法的確優於原建議的演算法。這三個演
算法的效能評估如圖二十所示。另外，在本年度的計畫中，我們也加快資料鏈結
層軟體(尤其是里德所羅門碼解碼演算法)執行速度，以適用於 Android 平板電腦
的使用環境。 
0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 0.5
10
-6
10
-5
10
-4
10
-3
10
-2
10
-1
10
0
Packet Error Rate
B
yt
e 
E
rr
or
 R
at
e
 
 
基本演算法
新演算法1
新演算法2 (10 bytes error/packet)
0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 0.5
10
-6
10
-5
10
-4
10
-3
10
-2
10
-1
10
0
Packet Error Rate
B
yt
e 
E
rr
or
 R
at
e
 
 
基本演算法
新演算法1
新演算法2 (10 bytes error/packet)
 
(a)在均勻通道下，IP 封包長度為 200    (b) 在均勻通道下，IP 封包長度為 1000 
及列數為 256 來比較三種解碼方法        及列數為 256 來比較三種解碼方法 
圖二十、三種鏈結層解碼演算法的效能比較 
 
 24
6. ANT 子計畫 
ANT 子計畫已完成 DVB-H 全頻寬指叉耦合機制 PIFA 天線（如圖二十二所
示），頻寬涵蓋 470~950MHz（如圖二十三所示），寬頻化效果主要是利用兩個彎
折路徑(路徑 CD、路徑 EF)及一個接地路徑(路徑 BC)在結合指叉式電容耦合結構
組合而成，利用改變指叉電容的手指數及長度與間隔，來控制電容式耦合量的大
小，由於是耦合饋入架構使得輸入輻射阻抗可大大提升，可用來匹配近似折疊偶
極天線高輻射阻抗的架構，如此設計可將外露式全頻寬天線縮小至 30 × 80 mm2 
並融入手持式平板電腦中，達到天線縮小以及效能取捨的平衡性，也因折疊偶極
天線的關係，使得縮小化天線卻保有良好的輻射增益。 
 
 
圖二十二、DVB-H 全頻寬指叉耦合機制 PIFA 天線結構細部尺寸圖 
 
 
圖二十三、全頻寬數位電視指叉耦合機制 PIFA 天線模擬與實際量測之 Return Loss 
 26
本專案完成之軟體已上傳至自由軟體鑄造廠(OSSF)，相關資訊如後： 
專案名稱「DVB-H simulator software release (version 2.0)」， 
網址 http://www.openfoundry.org/of/projects/1379 
 
本專案除了軟體之外，亦提供以下相關使用文件(Documentations): 
 DVB-H Player 使用手冊 (含安裝說明) 
 DVB-H Player 開發手冊  
 DVB-H Native Service (VIDEO, IPDC, LINK, MPEGTS) 開發手冊 
   
 28
七、 參考文獻 
[1] 徐愛蒂等，2008 通訊年鑑（工研院 IEK 電子分項），出版編號： ITRIEK-0453-T701(97)，
出版日期： 2008/07/03。 
[2] Gilles Printemps, Deep Inside Android, Esmertec, Inc. 
[3] Special Issue on Global Digital Television: Technology and Emerging Services, Proceedings of 
the IEEE, Jan. 2006. 
[4] G. Faria, J. A. Henriksson, E. Stare, and P. Talmola, “DVB-H: digital broadcast services to 
handheld devices,” Proceedings of the IEEE, vol. 94, no. 1, pp. 194 - 209, Jan. 2006. 
[5] M. Kornfeld and G. May, “DVB-H and IP datacast－broadcast to handheld devices,” IEEE Trans. 
Broadcasting, vol. 53, no. 1, pp.161- 170, March 2007. 
[6] EBU, Digital Video Broadcasting (DVB); Transmission system for handheld terminals (DVB-H), 
ETSI EN 302 304, v1.1.1, 2004. 
[7] EBU, Digital Video Broadcasting (DVB); Framing structure, channel coding and modulation for 
digital terrestrial television, ETSI EN 300 744, v1.6.1 (final draft), 2008.  
[8] EBU, Digital Video Broadcasting (DVB); Specification for Service Information (SI) in DVB 
systems, ETSI EN 300 468 v1.9.1, 2008. 
[9] EBU, Digital Video Broadcasting (DVB); DVB specification for data broadcasting, ETSI EN 301 
192, v1.4.2, 2008.  
[10] EBU, Digital Video Broadcasting (DVB); IP Datacast over DVB-H: Program Specific 
Information (PSI)/Service Information (SI), ETSI TS 102 470, v1.1.1 (2006-04).  
[11] EBU, Digital Video Broadcasting (DVB); IP Datacast over DVB-H: Set of Specifications for 
Phase 1, ETSI TS 102 468, v.1.1.1, 2007. 
[12] EBU, Digital Video Broadcasting (DVB); IP Datacast over DVB-H: Content Delivery Protocols, 
ETSI TS 102 472, v1.2.1 (2006-12). 
[13] EBU, Digital Video Broadcasting (DVB); IP Datacast over DVB-H: Electronic Service Guide 
(ESG), ETSI TS 102 471, v1.2.1 (2006-11).  
[14] EBU, Digital Video Broadcasting (DVB); IP Datacast over DVB-H: Content Delivery Protocols 
(CDP) Implementation Guidelines, ETSI TS 102 591, v1.1.1 (2007-10). 
[15] EBU, Digital Video Broadcasting (DVB); Specification for the use of video and audio coding in 
DVB services delivered directly over IP protocols, ETSI TS 102 005, v1.3.1, 2007. 
[16] EBU, Digital Video Broadcasting (DVB); Guidelines on implementation and usage of Service 
Information (SI), ETR 211, Second Edition, 1997. 
[17] Advanced Video Coding for Generic Audiovisual Services, ITU-T Rec. H.264 and ISO/IEC 
14496-10 (MPEG-4 AVC), Version 8, Apr. 2007. 
[18] ISO/IEC: Information Technology - Generic Coding of Moving Pictures and Associated Audio 
Information - Part 1: Systems, ISO/IEC 13818-1, 1997. 
[19] ISO/IEC: Information Technology - Coding of audio-visual objects - Part 3: Audio, ISO/IEC 
 30
可供推廣之研發成果資料表 
□可申請專利  ■可技術移轉                                 日期：100 年 10 月 29 日 
國科會補助計畫 
計畫名稱：嵌入式 DVB-H 接收系統之開發—總計畫(2/2) 
計畫主持人：楊士萱教授 
計畫編號：NSC 99-2220-E-027-001 學門領域：資訊 
技術/創作名稱 Android 行動電視接收系統 
發明人/創作人 楊士萱、陳偉凱、尤信程、梁文耀 劉建宏、吳和庭、劉玉蓀、林丁丙 
技術說明 
中文： 
本技術開發 Android 手機/平板之 DVB-H 行動數位電視即時接收系
統。除了行動數位電視原有之技術功能外，本系統針對 Android 手
機/平板提供符合使用者需求的觸控式介面，讓使用者可以流暢地
觀賞串流形式的行動數位電視節目。 
英文： 
In this project, we develop a real-time DVB-H reception system for 
Android phones and tablets. In addition to the fully implemented 
DVB-H specifications, this system provides user-friendly interface on 
touch panels. With the developed software, viewers can watch mobile 
streaming digital TV programs reliably and smoothly. 
可利用之產業 
及 
可開發之產品 
手機、平板電腦、數位電視、多媒體等相關產業 
技術特點 
 高品質及高容錯之電視影音播放 
 實體層與 DVB-T 相容 
 採用 H.264 及 HE-AAC 等高壓縮比的影音編碼標準，提高頻
寬使用效率 
 結合 IPDC 和 ESG，可提供電視廣播以外的其他資訊服務，並
且可以提供和 2G/3G 通訊系統的介接 
可供技轉項目 
 DVB-H Receiver/Player on Android 
 DVB-H Service (Android native service in C/C++), including 
MPEG-TS Parser 
 IP-based Multimedia Technology (IPDC, ESG, H.264, AAC, 
3gp/mp4) 
國科會補助專題研究計畫項下赴國外(或大陸地區)出差或研習心得報告 
                              日期： 100  年 7 月 25 日 
 
一、赴國外出差（參加會議）經過 
 
2011 年國際電機電子工程師學會多媒體與展示年會(2011 IEEE International Conference 
on Multimedia & Expo, ICME 2011)，2010 年 7 月 11 日至 15 日在西班牙巴塞隆納 Ramon 
Llull Univeristy 舉行，其中 7 月 11 日及 7 月 15 日只舉行 Workshop（須另外繳費），大會主
要議程集中於 12 日至 14 日三天。本人於 7 月 9 日深夜搭乘華航 CI-63 班機，經 13 小時之
飛行，於 7 月 10 日清晨抵達奧地利維也納，在維也納短暫停留二日之後，於 7 月 12 日上午
搭乘奧地利航空 OS-397 班機，於中午抵達西班牙巴塞隆納，並隨即參與大會各項活動。 
7 月 13 日的 keynote speech 由 UC Berkeley 的 Dr. Avideh Zakhor 主講，講題是 Fast, 
Automatic, Photo-Realistic, 3D Modeling of Building Interiors。實驗的環境是由人背負結合雷
射掃描、攝影機、與方位測量裝置的儀器，蒐集建築物內部的各項資料，以重建建築物內部
的 3D 模型。和傳統 3D 模型建立與虛擬實境的主要不同與挑戰在於，他們考慮更為複雜的
環境，包括樓梯、洞穴、和不平滑的表面，Dr. Zakhor 展示在 UC Berkeley 系館的實驗成
果，顯示其可以達到一定的準確性，未來這項技術還可以運用到 3D 環境的 Image-Based 
Rendering 或是行動擴增實境(Augmented Reality)。7 月 14 日的 keynote speech 由 Microsoft 
Research Cambridge 的 Dr. Andrew Blake 主講，講題是 Body Part Recognition for Kinect。微
軟(Microsoft)的遊戲機 Xbox 360 Kinect，除了一個一般的攝影機之外，另外配備一組可偵測
深度的紅外線攝影機，所以可以提供非接觸式的人機介面，包括手勢和肢體位置的辨認。最
早期圖形人機介面(Graphic User Interface; GUI)受限於鍵盤與滑鼠的操作，近期則增加（多
點）觸控(touch)，最新的自然人機介面(Natural User Interface; NUI)，則希望直接利用語音
(speech)、視覺辨識(camera-based vision)、及體感裝置，讓人與電腦之間的溝通更自然，這
些需要大量運用與結合語音合成、語音辨識、影像處理、電腦圖學、與人工智慧等技術。 
計畫編號 NSC 99-2220-E-027-001 
計畫名稱 嵌入式 DVB-H 接收系統之開發--總計畫(2/2) 
出國人員姓
名 楊士萱 
服務機構及
職稱 國立台北科技大學資訊工程系教授 
出國時間 100 年 7 月 9 日至 100 年 7 月 21 日 出國地點 
西班牙巴塞隆納 (Barcelona, Spain) 
2011 IEEE International Conference on 
Multimedia & Expo (ICME 2011) 
二、與會心得與建議 
 
ICME 自從 2000 年起，由 IEEE Circuits and Systems, Communications, Computer, 與
Signal Processing 四個分會(Societies)共同贊助舉辦，探討多媒體科技、系統、與應用之最新
研究成果及未來發展趨勢，除論文發表外，並安排廠商參展，目前已成為多媒體領域最重要
之旗艦會議。本人過去曾多次參加 ICME (2001, 2004, 2005, 2008, 2010)，本年度 ICME 會務
有重大變革，這次會議共有 744 篇一般論文投稿，第一階段每篇論文都至少有 3 個審查
(81%論文有 4 個以上審查)並採取雙盲(double blind)制，最後收錄 223 篇論文，錄取率約
30%，第二階段則鼓勵作者提出 3 到 5 分鐘的簡報，根據技術優點與簡報品質，挑選出 59
篇口頭發表論文，另外也挑選出 Top 15%的論文，同時進行壁報論文發表，大會也鼓勵作者
提供實際展示(demo)，本次共有 46 件 demo 作品。本人投稿的 Industrial/Short Paper Track 共
有 140 篇論文投稿，68 篇被接受，錄取率也只有 49%。 
與會期間與世界各地專家學者當面討論相關問題，獲得諸多寶貴建議與經驗；此外也遇
見國內本領域知名學者，包括台灣大學陳宏銘教授、清華大學林嘉文教授、中研院廖弘源教
授，台科大陳建中教授、屏科大童曉儒教授、元智大學施皇嘉教授、高應大陳朝烈教授、本
校黃士嘉教授等，台灣發表的論文數名列前茅，實屬可喜。Keynote speeches 與多場論文報
告，對都本人未來的研究具有相當啟發性。除了一般的學術性論文之外，有許多發表論文重
視實做上的貢獻並有 demo 展現，為學界與產官研合作的成果，或為我們注重 SCI 論文之
餘，也應該努力的方向。 
 
三、附件：發表之論文與海報 
 
H.264 that leads to better coding efficiency is the inclusion 
of adaptive block sizes for motion estimation with 1/4-pixel 
precision and multiple reference frames. Some MC-FRUC 
methods have recently been proposed for H.264 [8][9]. In 
this paper, we propose a new and fast MC-FRUC algorithm 
for H.264 coded image sequences. The true motion vector is 
directly estimated from the already received MVs without 
resorting to motion estimation or any access to the decoded 
images. Motion compensation is conducted in units of 44 
blocks to achieve better accuracy and alleviate blocking 
artifacts. The candidate set of MVs contains the zero motion 
vector, MV of the collocated block, and MVs of spatially 
neighboring blocks. Based on the coherence of motion 
trajectory, the appropriateness of an MV is judged from the 
similarity of the corresponding blocks in multiple frames. 
Vector medium filtering is applied to remove irregular 
motion and the new frame is generated from bilateral 
interpolation. Compared to other MC-FRUC methods, the 
proposed method achieves better PSNR performance with 
much less computation. 
The rest of this paper is organized as follows. An MC-
FRUC framework that is most relevant to our work is 
reviewed in Section 2. The proposed algorithm is presented 
in Section 3. The simulation results are given in Section 4, 
followed by the concluding remarks. 
 
2. MOTION COMPENSATED FRAME 
INTERPOLATION 
 
In this section, we review the typical motion compensated 
frame interpolation (MCFI) method and use the Zhai’s 
scheme [3] as an example. Some common terminologies of 
MC-FRUC will be explained as well. The flowchart of the 
MCFI scheme in [3] is shown in Fig. 1. The relationships of 
relevant blocks and frames are shown in Fig. 2. We denote 
the frame to be interpolated as F(t-1) and the adjacent 
correctly received frames as  F(t-2) (previous frame) and F(t) 
(next frame), respectively. For a block X (of size 88) in 
F(t-1) to be interpolated, the motion vector (from F(t) to 
F(t-2)) of its collocated block Y in F(t), denoted as 2MVY, 
is taken as the initial guess for the true motion required for 
X.  
The first step of MCFI is MV classification. Judging 
from the SAD (sum of absolute difference) and BAD 
(boundary absolute difference), the initial MV is classified 
as either good or bad according to some thresholds. SAD is 
computed between B0 and B2 and BAD is computed for B2 
and pixels surrounding B0. If MVY is close to the true 
motion, the calculated SAD and BAD should be small since 
B0 and B2 are on the motion trajectory of X. Blocks with 
bad initial MVs will perform additional overlapped block 
bidirectional motion estimation that extends the 8×8 block 
to the 12×12 region to obtain a more reliable MV. The 
following motion vector smoothing process calculates the 
variation of the obtained MV and its neighboring MVs. 
Vector median filtering will be applied for significantly 
deviated MVs. Finally, overlapped block motion 
compensation (OBMC) that takes the average of the 
overlapped regions is employed for interpolation. 
 
 
Fig. 1. Flowchart of the MCFI algorithm in [3]. 
 
Fig. 2. Correspondences of motion information. 
 
3. PROPOSED MC-FRUC METHOD 
 
Most MC-FRUC methods in the literature re-perform 
motion estimation at the decoder when the initial MV is 
found un-reliable. The added motion estimation, however, 
may greatly increase complexity with limited quality 
improvements. Furthermore, some ad-hoc thresholds need 
to be determined for good performance. We propose a fast 
MC-FRUC method based on multiple frames. Similarity 
comparison with an enlarged candidate set of MVs is used 
on multiple frames to increase accuracy. The proposed 
method, which involves no motion estimation and no 
Table 1. Experimental settings for H.264 coded sequences 
Field Parameter 
CODEC H.264 JM16.2 
Profile Baseline 
Frame Size QCIF (176x144) 
Frame Rate 30 (original), 15 (dropped) 
Frame Skip 1 
Number of Frames to Encode Complete Sequence 
Quantization Parameter (QP) 25 
Number of Reference Frames 
for H.264 Motion Estimation 1 
Motion Vector Resolution 1/4 Pixel 
Search Range 32 
RDO On 
Fast Motion Estimation Fast Full Search 
Fast Mode Decision Off 
Table 2. Effects of using multiple reference frames 
Sequence 
PSNR (dB) 
Interpolation 
with MV0 
Interpolation with the 
Proposed Method 
Foreman 34.50 35.24 
Carphone 32.13 33.78 
News 34.07 35.21 
Akiyo 40.57 40.67 
Salesman 37.26 37.63 
Claire 42.43 43.00 
Mother-D. 38.72 38.93 
Coastguard 33.74 34.67 
Hall-monitor 37.11 37.94 
Average 36.73 37.45 
 
Next, we compare the proposed MC-FRUC method 
with reference [3]. Performance is evaluated in terms of 
average PSNR of the interpolated frames and relative time 
savings (TS) defined as 
100%
Time
TimeTime
 TS Relative
[3] ref.
proposed[3] ref.         (7) 
The results in Table 3 show that the proposed method 
provides better performance, with an average 0.39 dB 
increase in PSNR and 67.6% TS. 
Table 3. Comparison with Zhai et al. [3] (QP =25) 
Sequence PSNR (dB) Relative TS of proposed methodRef. [3] Proposed 
Foreman 34.66 34.23 75.0% 
Carphone 33.63 32.21 76.1% 
Salesman 37.18 37.62 72.5% 
Claire 41.65 42.93 58.1% 
Mother-D. 38.01 39.37 52.2% 
Coastguard 34.08 35.22 71.9% 
Average 36.54 36.93 67.6% 
 
5. CONCLUSION 
 
A new fast and efficient FRUC method is presented in this 
paper. The proposed method finds the required good motion 
vector from the candidate set without motion estimation. By 
incorporating more frames for verifying the motion 
coherence, the obtained motion vector is closer to the true 
motion. Compared with the conventional FRUC algorithm, 
significantly less computation is achieved together with 
higher average PSNR. 
 
ACKNOWLEDGEMENT 
 
This work is supported in part by the National Science 
Council, R.O.China, under Grant NSC 99-2220-E-027-001. 
 
REFERENCES 
 
[1] Y. K. Chen, A. Vetro, H. Sun, and S. Y. Kung, “Frame-
rate up-conversion using transmitted true motion 
vectors,” IEEE Multimedia Signal Processing, Second 
Workshop, pp. 622 -627, Dec. 1998. 
[2] G. de Haan, P. W. Biezen, H. Huijgen, and O. A. Ojo, 
“True-motion estimation with 3-D recursive search 
block matching,” IEEE Trans. Circuits Syst. Video 
Technol., vol. 3, no. 5, pp. 368–379, Oct. 1993. 
[3] J. Zhai, K. Yu, J. Li, and S. Li, “A low complexity 
motion-compensated frame interpolation method,” Proc. 
IEEE International Symposium on Circuits and Systems 
(ISCAS), vol. 5. May. 2005, pp. 4927–4930. 
[4] B. D. Choi, J. W. Han, C. S. Kim, and S. J. Ko, 
“Motion-compensated frame interpolation using 
bilateral motion estimation and adaptive overlapped 
block motion compensation,” IEEE Trans. Circuits Syst. 
Video Technol., vol. 17, no. 4, pp. 407–416, Apr. 2007. 
[5] T. Y. Kuo and C.-C. J. Kuo, “Motion-compensated 
interpolation for low-bit-rate video quality 
enhancement,” Proc. SPIE Vis. Communication. Image 
Process., vol. 3460, pp. 277–288, July 1998. 
[6] Y. Zhang, D. Zhao, X. Ji, R. Wang, and W. Gao, “A 
spatial temporal auto regressive model for frame rate up 
conversion,” IEEE Trans. Circuits Syst. Video Technol., 
vol. 19, no. 9, pp. 1289-1301, Sep. 2009. 
[7] Advanced Video Coding for Generic Audiovisual 
Services, ITU-T Rec. H.264, or ISO/IEC 14496-10 
Information technology — Coding of audio-visual 
objects — Part 10: Advanced Video Coding (MPEG-4 
AVC), Fifth Edition, May 2009. 
[8] Z. Gan, L. Qi, and X. Zhu, “Motion compensated frame 
interpolation based on H.264 decoder,” Electronic 
Letters, vol. 43, pp. 96-98, Jan. 2007.  
[9] A. Lopez, Frame Rate Up-Conversion with Frame 
Interpolation Over Non-Regular Block Partitions of 
H.264, Master Thesis, Royal Institute of Technology, 
Stockholm, Sweden, Dec. 2008. 
國科會補助專題研究計畫項下赴國外(或大陸地區)出差或研習心得報告 
                              日期： 100  年 7 月 25 日 
 
一、赴國外出差（參加會議）經過 
 
2011 年國際電機電子工程師學會多媒體與展示年會(2011 IEEE International Conference 
on Multimedia & Expo, ICME 2011)，2010 年 7 月 11 日至 15 日在西班牙巴塞隆納 Ramon 
Llull Univeristy 舉行，其中 7 月 11 日及 7 月 15 日只舉行 Workshop（須另外繳費），大會主
要議程集中於 12 日至 14 日三天。本人於 7 月 9 日深夜搭乘華航 CI-63 班機，經 13 小時之
飛行，於 7 月 10 日清晨抵達奧地利維也納，在維也納短暫停留二日之後，於 7 月 12 日上午
搭乘奧地利航空 OS-397 班機，於中午抵達西班牙巴塞隆納，並隨即參與大會各項活動。 
7 月 13 日的 keynote speech 由 UC Berkeley 的 Dr. Avideh Zakhor 主講，講題是 Fast, 
Automatic, Photo-Realistic, 3D Modeling of Building Interiors。實驗的環境是由人背負結合雷
射掃描、攝影機、與方位測量裝置的儀器，蒐集建築物內部的各項資料，以重建建築物內部
的 3D 模型。和傳統 3D 模型建立與虛擬實境的主要不同與挑戰在於，他們考慮更為複雜的
環境，包括樓梯、洞穴、和不平滑的表面，Dr. Zakhor 展示在 UC Berkeley 系館的實驗成
果，顯示其可以達到一定的準確性，未來這項技術還可以運用到 3D 環境的 Image-Based 
Rendering 或是行動擴增實境(Augmented Reality)。7 月 14 日的 keynote speech 由 Microsoft 
Research Cambridge 的 Dr. Andrew Blake 主講，講題是 Body Part Recognition for Kinect。微
軟(Microsoft)的遊戲機 Xbox 360 Kinect，除了一個一般的攝影機之外，另外配備一組可偵測
深度的紅外線攝影機，所以可以提供非接觸式的人機介面，包括手勢和肢體位置的辨認。最
早期圖形人機介面(Graphic User Interface; GUI)受限於鍵盤與滑鼠的操作，近期則增加（多
點）觸控(touch)，最新的自然人機介面(Natural User Interface; NUI)，則希望直接利用語音
(speech)、視覺辨識(camera-based vision)、及體感裝置，讓人與電腦之間的溝通更自然，這
些需要大量運用與結合語音合成、語音辨識、影像處理、電腦圖學、與人工智慧等技術。 
計畫編號 NSC 99-2220-E-027-001 
計畫名稱 嵌入式 DVB-H 接收系統之開發--總計畫(2/2) 
出國人員姓
名 楊士萱 
服務機構及
職稱 國立台北科技大學資訊工程系教授 
出國時間 100 年 7 月 9 日至 100 年 7 月 21 日 出國地點 
西班牙巴塞隆納 (Barcelona, Spain) 
2011 IEEE International Conference on 
Multimedia & Expo (ICME 2011) 
二、與會心得與建議 
 
ICME 自從 2000 年起，由 IEEE Circuits and Systems, Communications, Computer, 與
Signal Processing 四個分會(Societies)共同贊助舉辦，探討多媒體科技、系統、與應用之最新
研究成果及未來發展趨勢，除論文發表外，並安排廠商參展，目前已成為多媒體領域最重要
之旗艦會議。本人過去曾多次參加 ICME (2001, 2004, 2005, 2008, 2010)，本年度 ICME 會務
有重大變革，這次會議共有 744 篇一般論文投稿，第一階段每篇論文都至少有 3 個審查
(81%論文有 4 個以上審查)並採取雙盲(double blind)制，最後收錄 223 篇論文，錄取率約
30%，第二階段則鼓勵作者提出 3 到 5 分鐘的簡報，根據技術優點與簡報品質，挑選出 59
篇口頭發表論文，另外也挑選出 Top 15%的論文，同時進行壁報論文發表，大會也鼓勵作者
提供實際展示(demo)，本次共有 46 件 demo 作品。本人投稿的 Industrial/Short Paper Track 共
有 140 篇論文投稿，68 篇被接受，錄取率也只有 49%。 
與會期間與世界各地專家學者當面討論相關問題，獲得諸多寶貴建議與經驗；此外也遇
見國內本領域知名學者，包括台灣大學陳宏銘教授、清華大學林嘉文教授、中研院廖弘源教
授，台科大陳建中教授、屏科大童曉儒教授、元智大學施皇嘉教授、高應大陳朝烈教授、本
校黃士嘉教授等，台灣發表的論文數名列前茅，實屬可喜。Keynote speeches 與多場論文報
告，對都本人未來的研究具有相當啟發性。除了一般的學術性論文之外，有許多發表論文重
視實做上的貢獻並有 demo 展現，為學界與產官研合作的成果，或為我們注重 SCI 論文之
餘，也應該努力的方向。 
 
三、附件：發表之論文與海報 
 
H.264 that leads to better coding efficiency is the inclusion 
of adaptive block sizes for motion estimation with 1/4-pixel 
precision and multiple reference frames. Some MC-FRUC 
methods have recently been proposed for H.264 [8][9]. In 
this paper, we propose a new and fast MC-FRUC algorithm 
for H.264 coded image sequences. The true motion vector is 
directly estimated from the already received MVs without 
resorting to motion estimation or any access to the decoded 
images. Motion compensation is conducted in units of 44 
blocks to achieve better accuracy and alleviate blocking 
artifacts. The candidate set of MVs contains the zero motion 
vector, MV of the collocated block, and MVs of spatially 
neighboring blocks. Based on the coherence of motion 
trajectory, the appropriateness of an MV is judged from the 
similarity of the corresponding blocks in multiple frames. 
Vector medium filtering is applied to remove irregular 
motion and the new frame is generated from bilateral 
interpolation. Compared to other MC-FRUC methods, the 
proposed method achieves better PSNR performance with 
much less computation. 
The rest of this paper is organized as follows. An MC-
FRUC framework that is most relevant to our work is 
reviewed in Section 2. The proposed algorithm is presented 
in Section 3. The simulation results are given in Section 4, 
followed by the concluding remarks. 
 
2. MOTION COMPENSATED FRAME 
INTERPOLATION 
 
In this section, we review the typical motion compensated 
frame interpolation (MCFI) method and use the Zhai’s 
scheme [3] as an example. Some common terminologies of 
MC-FRUC will be explained as well. The flowchart of the 
MCFI scheme in [3] is shown in Fig. 1. The relationships of 
relevant blocks and frames are shown in Fig. 2. We denote 
the frame to be interpolated as F(t-1) and the adjacent 
correctly received frames as  F(t-2) (previous frame) and F(t) 
(next frame), respectively. For a block X (of size 88) in 
F(t-1) to be interpolated, the motion vector (from F(t) to 
F(t-2)) of its collocated block Y in F(t), denoted as 2MVY, 
is taken as the initial guess for the true motion required for 
X.  
The first step of MCFI is MV classification. Judging 
from the SAD (sum of absolute difference) and BAD 
(boundary absolute difference), the initial MV is classified 
as either good or bad according to some thresholds. SAD is 
computed between B0 and B2 and BAD is computed for B2 
and pixels surrounding B0. If MVY is close to the true 
motion, the calculated SAD and BAD should be small since 
B0 and B2 are on the motion trajectory of X. Blocks with 
bad initial MVs will perform additional overlapped block 
bidirectional motion estimation that extends the 8×8 block 
to the 12×12 region to obtain a more reliable MV. The 
following motion vector smoothing process calculates the 
variation of the obtained MV and its neighboring MVs. 
Vector median filtering will be applied for significantly 
deviated MVs. Finally, overlapped block motion 
compensation (OBMC) that takes the average of the 
overlapped regions is employed for interpolation. 
 
 
Fig. 1. Flowchart of the MCFI algorithm in [3]. 
 
Fig. 2. Correspondences of motion information. 
 
3. PROPOSED MC-FRUC METHOD 
 
Most MC-FRUC methods in the literature re-perform 
motion estimation at the decoder when the initial MV is 
found un-reliable. The added motion estimation, however, 
may greatly increase complexity with limited quality 
improvements. Furthermore, some ad-hoc thresholds need 
to be determined for good performance. We propose a fast 
MC-FRUC method based on multiple frames. Similarity 
comparison with an enlarged candidate set of MVs is used 
on multiple frames to increase accuracy. The proposed 
method, which involves no motion estimation and no 
Table 1. Experimental settings for H.264 coded sequences 
Field Parameter 
CODEC H.264 JM16.2 
Profile Baseline 
Frame Size QCIF (176x144) 
Frame Rate 30 (original), 15 (dropped) 
Frame Skip 1 
Number of Frames to Encode Complete Sequence 
Quantization Parameter (QP) 25 
Number of Reference Frames 
for H.264 Motion Estimation 1 
Motion Vector Resolution 1/4 Pixel 
Search Range 32 
RDO On 
Fast Motion Estimation Fast Full Search 
Fast Mode Decision Off 
Table 2. Effects of using multiple reference frames 
Sequence 
PSNR (dB) 
Interpolation 
with MV0 
Interpolation with the 
Proposed Method 
Foreman 34.50 35.24 
Carphone 32.13 33.78 
News 34.07 35.21 
Akiyo 40.57 40.67 
Salesman 37.26 37.63 
Claire 42.43 43.00 
Mother-D. 38.72 38.93 
Coastguard 33.74 34.67 
Hall-monitor 37.11 37.94 
Average 36.73 37.45 
 
Next, we compare the proposed MC-FRUC method 
with reference [3]. Performance is evaluated in terms of 
average PSNR of the interpolated frames and relative time 
savings (TS) defined as 
100%
Time
TimeTime
 TS Relative
[3] ref.
proposed[3] ref.         (7) 
The results in Table 3 show that the proposed method 
provides better performance, with an average 0.39 dB 
increase in PSNR and 67.6% TS. 
Table 3. Comparison with Zhai et al. [3] (QP =25) 
Sequence PSNR (dB) Relative TS of proposed methodRef. [3] Proposed 
Foreman 34.66 34.23 75.0% 
Carphone 33.63 32.21 76.1% 
Salesman 37.18 37.62 72.5% 
Claire 41.65 42.93 58.1% 
Mother-D. 38.01 39.37 52.2% 
Coastguard 34.08 35.22 71.9% 
Average 36.54 36.93 67.6% 
 
5. CONCLUSION 
 
A new fast and efficient FRUC method is presented in this 
paper. The proposed method finds the required good motion 
vector from the candidate set without motion estimation. By 
incorporating more frames for verifying the motion 
coherence, the obtained motion vector is closer to the true 
motion. Compared with the conventional FRUC algorithm, 
significantly less computation is achieved together with 
higher average PSNR. 
 
ACKNOWLEDGEMENT 
 
This work is supported in part by the National Science 
Council, R.O.China, under Grant NSC 99-2220-E-027-001. 
 
REFERENCES 
 
[1] Y. K. Chen, A. Vetro, H. Sun, and S. Y. Kung, “Frame-
rate up-conversion using transmitted true motion 
vectors,” IEEE Multimedia Signal Processing, Second 
Workshop, pp. 622 -627, Dec. 1998. 
[2] G. de Haan, P. W. Biezen, H. Huijgen, and O. A. Ojo, 
“True-motion estimation with 3-D recursive search 
block matching,” IEEE Trans. Circuits Syst. Video 
Technol., vol. 3, no. 5, pp. 368–379, Oct. 1993. 
[3] J. Zhai, K. Yu, J. Li, and S. Li, “A low complexity 
motion-compensated frame interpolation method,” Proc. 
IEEE International Symposium on Circuits and Systems 
(ISCAS), vol. 5. May. 2005, pp. 4927–4930. 
[4] B. D. Choi, J. W. Han, C. S. Kim, and S. J. Ko, 
“Motion-compensated frame interpolation using 
bilateral motion estimation and adaptive overlapped 
block motion compensation,” IEEE Trans. Circuits Syst. 
Video Technol., vol. 17, no. 4, pp. 407–416, Apr. 2007. 
[5] T. Y. Kuo and C.-C. J. Kuo, “Motion-compensated 
interpolation for low-bit-rate video quality 
enhancement,” Proc. SPIE Vis. Communication. Image 
Process., vol. 3460, pp. 277–288, July 1998. 
[6] Y. Zhang, D. Zhao, X. Ji, R. Wang, and W. Gao, “A 
spatial temporal auto regressive model for frame rate up 
conversion,” IEEE Trans. Circuits Syst. Video Technol., 
vol. 19, no. 9, pp. 1289-1301, Sep. 2009. 
[7] Advanced Video Coding for Generic Audiovisual 
Services, ITU-T Rec. H.264, or ISO/IEC 14496-10 
Information technology — Coding of audio-visual 
objects — Part 10: Advanced Video Coding (MPEG-4 
AVC), Fifth Edition, May 2009. 
[8] Z. Gan, L. Qi, and X. Zhu, “Motion compensated frame 
interpolation based on H.264 decoder,” Electronic 
Letters, vol. 43, pp. 96-98, Jan. 2007.  
[9] A. Lopez, Frame Rate Up-Conversion with Frame 
Interpolation Over Non-Regular Block Partitions of 
H.264, Master Thesis, Royal Institute of Technology, 
Stockholm, Sweden, Dec. 2008. 
國科會補助計畫衍生研發成果推廣資料表
日期:2011/10/26
國科會補助計畫
計畫名稱: 總計畫(2/2)
計畫主持人: 楊士萱
計畫編號: 99-2220-E-027-001- 學門領域: 自由軟體暨嵌入式系統
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
本系統為第一個在 Android 開放軟體架構實現之 DVB-H 接收系統，除了完整的
DVB-H 技術功能外，我們針對 Android 手機及平板提供更符合使用者需求的觸
控式介面，並且改善系統的可靠度與強健性，可流暢地觀賞串流形式的 DVB-H
數位電視節目。 
本專案完成之軟體已上傳至自由軟體鑄造廠(OSSF)，相關資訊如後：專案名稱
「 DVB-H simulator software release (version 2.0) 」， 網 址
http://www.openfoundry.org/of/projects/1379 
本專案除了軟體之外，亦提供以下相關使用文件(Documentations): 
 DVB-H Player 使用手冊 (含安裝說明) 
 DVB-H Player 開發手冊  
 DVB-H Native Service (VIDEO, IPDC, LINK, MPEGTS) 開發手冊 
本整合型計畫第一年度成果獲得自由軟體暨嵌入式系統計畫績優團隊獎（第二
年度績優團隊仍在評選中），第二年度成果亦獲得評審委員高度肯定，因而獲邀
在 2011 年 10 月，代表國科會參加「2011 台北國際發明暨技術交易展」的實際
展示。參與計畫學生以計畫內容為主題（作品名稱：手持式行動數位電視 DVB-H 
接收系統），參加 2010 開放原始碼創新應用開發大賽（主辦單位：經濟部工業
局、執行單位：財團法人資訊工業策進會），亦榮獲學生組優等（獎金 10 萬與
獎座乙座）之殊榮。 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
