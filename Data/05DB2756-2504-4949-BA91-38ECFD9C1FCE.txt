intelligent robots, but also in extending the 
applications of the proposed methods to perform 
complicated tasks in the fields of home-caring, 
edutainment, health-caring, restaurant servicing and 
manufacturing. 
英文關鍵詞： Autonomous grasping, autonomous manipulations,  dual 
arm configuration, embedded control, mechatronics, 
object recognition, position/visione cooperation 
control, intelligent control, system integration. 
 
   
Fig.1 Physical structure of the anthropomorphous dual-arm 
manipulators. 
 
The design and implementation of the 
anthropomorphous dual-arm robots or manipulators have 
been widely reported; for example, the authors in [5-9] 
presented several important methodologies for system 
design, object recognition using two cameras, embedded 
implementation, control and path planning. However, many 
techniques reported in the literature [5-9] remain to be done. 
For example, no attempts have been paid to investigate 
positions of any object to be grasped by using Kinect, and 
achieve desired dexterous manipulations for our daily life 
via Kinect. 
Fig. 2.Overall system structure. 
The objectives of this report are to develop methodologies 
and techniques for vision-guided grasping and manipulations 
of anthropomorphous dual-arm manipulators using Kinect. 
The report is written in two principal contributions. First, a 
systematic approach to vision-guided grasping using Kinect 
is presented. Second, a systematic method to vision-guided 
manipulations is proposed for coffee-making. An interesting 
coffee-making  procedure conducted by the laboratory-built  
anthropomorphous dual-arm manipulators   
Object gasping is particularly an important research 
topic for anthropomorphous dual-arm robots or 
manipulators. Object grasping usually involves five 
techniques: active vision, object recognition, object 
localization, visual servoing, and path planning and grasping 
control of the dual arms. In this aspect, Vahrenkamp et al. 
presented a visual servoing approach to enabling a 
humanoid robot to robustly execute dual-arm grasping 
and manipulation tasks. Song et al. [11] proposed a 
vision-guided grasping approach for a dual-arm manipulator 
driven by an omnidirectional mobile platform. However, the 
well-popular Kinect has not been used to accomplish object 
grasping tasks yet! In addition, manipulations of cooperative 
dual arms using a vision-guided approach have been 
intensively addressed in the literature [9-10]. Based on the 
vision-guided approach, several kinds of manipulations 
using cooperative dual-arm manipulators can be done for 
various tasks in our daily life. Vahrenkamp et al. showed 
how their viual servoing approach can be applied to handle 
two tasks in a kitchen room [9]. However, no systematic 
approach was proposed to do these tasks.    
The rest of report is outlined as follows. Section II 
briefly describes the system description of the 
anthropomorphous dual-arm manipulators, and Section III 
describes a vision-based object recognition method using 
SURF, and the object localization problem is addressed in 
Section IV. Section V describes coordinate transformation of 
the object’s positions in the Kinect system into the ones with 
respect to the dual arms. In Section VI, the object recognition 
method is applied to recognize the objects used for coffee 
making. Section VII discusses the task decomposition by 
autonomous dual-arm cooperation. Section VIII presents 
experimental results that achieve marking coffee. Section IX 
concludes the report. 
 
II. SYSTEM DESCRIPTION AND CONTROL 
STRUCTURE 
As shown in Fig. 1, the anthropomorphous dual-arm 
manipulators are equipped with a Kinect module mounted on 
a two-degrees-of-freedom robotic head module, a small size 
  
 Fig.3 The correspondence image between the scene and the database. 
 Fig.4. Coordinate frames of the Kinect on the robotic head 
module. [ 1 Tnn n npp x yk
′= = ]                                                (3) 
B3 Defining Central Point 
Since the homography matrix has the properties of 
invariance of rotation and scale even for different distances 
and angles, the object’s position can be determined in the 
image planes. 
Once the homography has been computed, the 
transformation relationship between the object and the image 
will be found, and the positions of four corner points will 
then be calculated.  To link the four points in the clockwise 
direction, one finds the current position of the object. By 
calculating the mean of the four corner points, the mean is 
thought of as the reference point for further robot control. 
Fig. 3 shows an example about the object recognition. 
 
B2 RANSAC 
     As mentioned before, four feature points are required to 
determine the planar transformation matrix. Although a 
group of corresponding points could be found after feature 
point extraction and the Nearest Neighborhood algorithm, it 
is necessary to find a more accurate transformation matrix in 
order to compute more precise feature corresponding points. 
In doing so, the RANSAC(Random sample consensus) 
algorithm is used as below.  
 
    RANSAC is a condition-end random algorithm, when the 
error between np ′  and  (i.e., nP
2
n nP p ′− ) is less than  a 
threshold value , which means that the finding matrix  is 
proven correct between two sets of feature points.   The 
proposed RANSAC algorithm is depicted as following steps.  
1. Randomly choose a set of 4 feature points obtained in 
the homography in order to solve H. 
2. Calculate the transformed positions of all feature points 
by using the transformation matrix H obtained from Step 
1. Then calculate the transformed positions of other 
feature points in the database, and compute the Euclidean 
distances between one feature point nP in the actual 
image and the other feature point np ′  in the database 
after the use of the matrix H. 
3. Solve all the distances of all feature points; if the 
distance is less than a defined threshold distance tD , 
which means the pair ( np ′ , nP ) is properly chosen for the 
transform matrix, then count the number of correct 
matching feature pairs. 
IV. OBJECT  LOCALIZATION 
Once the object has been recognized, the next phase is to 
control the manipulators to grasp the object. Position-based 
visual servo (PBVS) approach is adopted in this task. In the 
PBVS approach, the relative position between robot and 
target has to be determined to guide both manipulators to 
move toward the target and then grasp it. In this task, the 
depth image acquired by Kinect is used to both localize the 
object and model the workspace. Since the object is already 
recognized in Section III, the 3D position of the object to be 
grasped can be easily determined from the center of the 
object. 
 
V. GRASPING AND TRAJECTORY PLANNING  
As mentioned in previous sections, both 
anthropomorphous arms and hands have been designed for 
easily catching and carrying desired objects from one 
position to another. To use these arms and hands to achieve 
some specific tasks, one should deal with the forward and 
inverse kinematics of each seven-degrees-of-freedom (DOF) 
arm and hand. Forward kinematics and inverse kinematics 
of the arms and hands are two basic issues for studying their 
kinematics motion, path planning, cooperation and  
autonomous task execution. Similar to conventional 
definitions, forward kinematics is concerned with how to the 
final posture of each arm if all its joint angles are given, 
whereas inverse kinematics puts emphasis on how to find all 
the joint angles of each arm if its posture is known. Hence, a 
kinematics algorithm is used to calculate all joints angles to 
move the end effector to the goal posture. Note that the 
problem to solve for the kinematics algorithm is indeed a 
redundant problem. An analytic inverse kinematics was  
 
 
  After the aforementioned procedure has been executed N 
times, one can find the most correct matching number  
exceeding desired threshold number ,and the calculated 
transformation matrix H at this maximum matching 
condition  is considered as our desired transformation matrix.   
tS
 
 Fig. 9. The result of objects recognition. 
 
Fig.10. Flow chart of the coffee making experiment. TABLE I. The Real Objects’ Positions. 
 
 X-Coordinate Y-Coordinate Z-Coordinate
Tea Cup 50 mm -281 mm 363 mm 
Grinder 60 mm -125 mm 513 mm 
Filter -135 mm -238 mm 643 mm 
Bottle 150 mm -175 mm 633 mm 
 
TABLE II. The Position errors. 
 X-Coordinate Y-Coordinate Z-Coordinate
Tea Cup 0.4930 mm -0.4902 mm 1.1152 mm 
Grinder 4.2901 mm -6.3428 mm 3.4239 mm 
Filter -4.6840 mm -3.7613 mm 2.9793 mm 
Bottle 0.5438 mm -5.6172 mm 1.9442 mm 
 
pour water. This task can be composed of many sub-tasks 
without concurrent working of the two arms. Therefore, the 
sub-task analyses of the full tasks are one of the most 
important steps to two-arm cooperation.     
 
VII. EXPERIMENTAL RESULTS AND DISSCUSSION 
In this section, the results of objects recognition are 
shown in Fig.9. The objects to be recognized are Tea Cup, 
Grinder, Filter, and bottle. TABLE I shows the actual  3D 
positions of these real objects, while TABLE II depicts  the 
position errors after calibration. 
Fig.10 displays the procedure of the coffee making 
experiment. There are five procedures: to grind beans, to 
open grinder, to pour the powder of coffee, to install the 
filter, and to pour water. The whole task is done by 
sequentially executing the analyzed motion processes: 
grinding, opening, pouring, grabbing. The cooperation of 
two arms, hands and the stereo vision camera was 
implemented by using C language.  
The following experiment displays the results of the 
coffee-making procedure. In Fig.11(a) the sub-task of 
grinding was executed by two arms; the grinder was hold by 
the left arm, and the beans of coffee were grinded by the 
right arm. Fig.11(b) describes the motion process of opening; 
the grinder was separated by the dual arms. Fig.11(c) shows  
Fig.11. (a) ~ (f):  Pictures of the coffee making process. 
 
 
the pouring sub-task for coffee powder. The powder was 
poured into the filter, and then the filter was mounted on the 
cup by the left arm, as shown in Fig.11(d). Finally, Fig.11(e) 
displays the hot water that was poured into the filter by the 
right arm. In this experimentation, the making coffee task 
was achieved by the dual arms with the proposed conceptual 
cooperation, as shown in Fig.11 (f).  
It is worthwhile to mention that the successful 
recognition of the proposed method relies heavily upon the 
light intensity in the environment, and  enough recognition 
templates in many orientations. If the recognition templates 
術，所開發的感測、致動、運動控制、系
統整合設計方法與SoPC嵌入式系統晶片等
關鍵零主件與系統技術，可提昇國內仿人
行雙手臂的操作性能；所研發的系統軟硬
體建置與相關實務技術，不但有助於現今
與人共生機器人的研製，同時可推廣應用
於其他的製造、教育、服務、娛樂休閒等
應用。本計畫亦提出有效且實用的工程設
計方法，配合軟硬體的實作，建置完成可
進行實驗測試與展示的半人型雙手臂機器
人。配合本計畫之執行，將可提昇智慧雙
手臂機器人系統之關鍵零主件的研發設計
能量。另外，本子計畫已經訓練參與本計
畫之碩士班究生兩名及博士生一名，目前
已有兩位碩士生以本專題計畫部分成果，
參與國內教育部微電腦競賽，榮獲佳績，
已顯著說明本研究的成果。 
 
(3) 主要發現及其他相關價值：本計畫主要發
現或貢獻有兩項: 第一項為該雙手臂機器人
測試平台所衍生的技術，一低成本Kinect視
覺、物件辨識以及手眼協調控制；第二項
為以該雙手臂機器人所衍生的視覺導引的
操作的概念與技術。本計畫之主要貢獻技
術可提昇一仿人式雙手臂機器人的手眼協
調控制功能，可提昇該機器人系統的操作
功能。另外，所研發的手眼協調控制演算
法，可進一步開發成系統IC晶片。 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 2
於10:30-12:10,13:40-15:30，16:00-18:00 等三兩時段內每時段最多有12場同時進行的小組技術
會議。10/11與10/12等兩場大會演講的題目與演講者分別是Prof. Jose Del R. Millan 主講第二場
題目 「Brain-Robot Interaction」(以腦波辨識與學習為主，進而控制輪椅與機器人)，Prof. Robert 
O. Ambrose主講第三場大會題目「Humans & Humanoids」(行動雙手臂機器人與太空的應用)。
並於在10/11 10:30至12:00間， 安排由Keith Hipel, Jim Tan, Mo Jamshidi等三位SMC會士，舉辦
論壇，介紹SMC方法，吸引多人參加研討. 
除了吸引近數百人聆聽的大會演講的精彩演講外，更引人入勝的是各種研究領域的小組技
術研討會議。每一小型技術會議裡有 6 篇與主題相關的論文發表，每篇論文的發表者必須在 20
分內結束報告並有完成問題回答時間。如果您對某些論點特別感興趣，除了當場請教外，也可
私底下互相交流溝通。由於每依時段的 12 組小型技術會議於同時段裡進行，聽者可穿梭於會場
中，聽取自己所需的論文發表。105 組小型技術會議的主題幾近乎包含廣闊，從服務系統，國
土安全系統，虛擬與擴增實境與訓練系統，腦機器界面(BMI)，以人為中心的交通系統，知覺科
學與工程，軟性計算，企業資訊系統與適應合作，社會訊號處理，基礎結構系統，製造系統，
計算智慧，高等機器學習，醫學機電整合學，醫學與健康照護系統，智慧電力與能源系統，計
算集體智慧，智慧系統, 圖項辨識，生物量測學與生物資訊學，影像處理，分享控制，殘障人
士的支持系統，系統建模與故障偵測，感測網路，人機系統，人電腦互動，學習決策與控制，
welfare IT, 多媒體安全與私密性，Data Mining, Agent-based modeling, 演化智慧系統與學習，
Human information processing, 類神經網路，最佳化、演化計算與混合模型，智慧型控制、智慧
型交通系統、非線性控制、模糊控制、類神經網路控制、灰色系統、Petri 網路，決策支持系統，
Human-centered systems, Swarm 智慧，Granular 計算，複雜分析與認知心理，醫學資訊學，行
動機器人、行動機器人系統與控制，合作的無線感測系統，認知計算，反恐佈人士應用的資訊
技術，輔助技術，Kansei 工程與 Affective computing, 知識系統，衝突解，多代理人與分散系統，
Haptics 與人-機器人互動，手勢互動，社會機器人學與機器人學習,、模式辨識與驗證、混合控
制、嵌入式系統等多方面的實務技術。在諸多的主題裡，筆者僅選擇相關有興趣的認知識別，
認知計算，演化學習，學習控制，智慧學習控制等相關的論文聆聽，參與相關的研討。雖是短
暫的交流，對目前研究動態的掌握，未來研究方向的釐定，甚有助益。 
 本次代表團由團長李祖聖教授率領，以 Special Session 方式參與 SMC 2011 國際研討會，
參與論文計有共7篇。筆者所組成的Special session 隸屬於10月11日（星期二）上午的T.SPS.C10 
『Intelligent learning in control systems』Session，共有六篇論文發表，參與的教授有蔡清池，蘇
順豐，黃旭志，呂虹慶，王偉彥，呂藝光等教授。筆者參與本次 SMC2010 的論文有壹篇，其
篇名為「Intelligent Adaptive Trajectory Tracking Control Using Fuzzy Basis Function Networks 
for an Autonomous Small-Scale Helicopter」，於 10 月 11 日（星期二）下午的『Intelligent learning 
in Control systems 』Session 內發表，其內容為針對自主直昇機之非線性模型，採用模糊基底函
數類神經網路，配合適應倒逆部方法，發展智慧適應控制法則，使自主直昇機達成快速軌跡追
蹤與 aggressive maneuvers。  
    主辦單位為加強學者專家、與會者間的交流，特別安排四個Social Events. 除10/9歡迎酒宴
外，於10/10晚上有各期刊主編、副編、TC chairs, Chapter chairs等VIPs，於Hilton Hotel 的第15
樓頂樓聚會,並提供晚餐。於12:00-14:00間在Hilton Hotel 的第15樓頂樓，大會邀請 SMCS VP, 
Prof. Loi Lei Lai 進行SMC會員促銷活動，說明如何成立支會，學生分會等相關議程，其深入
淺出的說明，讓與會者有不少教授願意成立支會與學生分會。最後大會在Hilton Hotel的宴會廳
(ballroom)，舉辦大會宴會，使與會者可共進晚餐，進而互增友誼。眾人把酒暢談，並相約一
年後韓國漢城相見。在大會宴會期間，有精彩的頒獎儀式，美國老鷹與拉雪橇狗的現場展示，
以及愛基斯摩人的音樂文化表演。 
 
（四）與會心得 
系統、人與仿生技術之科技是一不斷地隨時代的需求推陳出新，符合人性需求的重要技術。
 
SMC 2011 大會論壇活動 
 
 4
  
SMC 2011 大會宴會活動 
 6
 
SMC 2010  大會第三場專題演講: Dr. Ambrose 主講第三場題目「 Humans and Humanoids」. 
 
 8
Intelligent Adaptive Trajectory Tracking Control 
Using Fuzzy Basis Function Networks for an 
Autonomous Small-Scale Helicopter 
Ching-Chih Tsai, Chi-Tai Lee* 
Department of Electrical Engineering  
National Chung Hsing University 
Taichung, Taiwan, R.O.C. 
e-mail: cctsai@nchu.edu.tw, *ChiTai.Lee@gmail. com 
  Kao-Shing Hwang 
Department of Electrical Engineering 
National Chung Cheng University 
Minhsiung, Chiayi County 62102,  Taiwan, R.O.C. 
e-mail: hwang@ccu.edu.tw
 
Abstract—This paper presents an intelligent adaptive trajectory 
tracking controller using fuzzy basis function networks (FBFN) 
for an autonomous small-scale helicopter. With the on-line FBFN 
approximation to the vehicle mass and the coupling effect 
between the force and the moments, the intelligent adaptive 
controller is systematically synthesized using backstepping 
technique. This controller is shown to achieve the semi-global 
ultimate boundedness of the closed-loop helicopter dynamics and 
accommodate agile flight maneuvers in trajectory tracking. The 
effectiveness and merit of the proposed method are exemplified 
by performing one nonlinear simulation and by performance 
comparison with a well-known controller. 
Keywords- autonomous helicopter, fuzzy basis function 
networks (FBFN), intelligent adaptive control, trajectory tracking 
I. INTRODUCTION 
Recently,many researchers have paid significant attention 
to the study of autonomous helicopters which are also called 
rotary unmanned air vehicles (UAVs) [1-2]. With hovering, 
vertical take-off and landing (VTOL) maneuver abilities, 
autonomous helicopters have outstanding and remarkable 
advantages in a narrow environment. However, helicopter 
systems are characterized by the high nonlinearity of the 
aerodynamics and the strong coupling effect between the 
forces and torques produced by the vehicle actuators. 
Helicopters are sensitive to atmospheric disturbances, such as 
wind gusts or turbulence; therefore, their dynamic 
characteristics change with various flight conditions. How to 
handle the nonlinearity and the coupling effect is one of the 
important issues in the control of such unmanned helicopters. 
Although stabilization and autonomous flight of unmanned 
helicopters have been achieved by past researches, their 
performance is generally modest in comparison with a skilled 
pilot.  
The systematic and recursive backstepping technique can 
stabilize all states simultaneously and lead to possible 
significant improvements on the transient performance without 
the timescale separation assumption [3-4]. Furthermore, 
instead of neglecting the coupling effect as did in other 
approximate modeling approaches [1-2], researchers have 
proposed a full   model of this kind of helicopter in their 
proposed controllers using neural networks [1-2]. Among 
numerous neural network (NN) schemes, the fuzzy basis 
function networks (FBFN) has been shown to perform 
excellent approximations for the curve fitting problems; 
moreover, they can be trained to learn some classes of 
nonlinear functions and system dynamics easily and quickly. 
One of the advantages of FBFN is the fact that linear weights 
associated with the output layers can be treated separately 
from the hidden layer neurons. In the hidden layer, weights are 
adjusted through a nonlinear optimization procedure, whereas 
the weights of the output layer are adjusted through linear 
optimization. The approximation accuracy and convergent rate 
of the FBFN may be further improved with a strategy for 
selecting appropriate centers and widths of the receptive fields 
[5-9]. Actually, the technique of combining the adaptive 
backstepping control and the NN approximation has been 
proposed to overcome the uncertainties and nonlinearities 
existing in the complex controlled plants [10-13]. To date, 
however, no studies have attempted to apply the adaptive 
backstepping design method augmented by on-line FBFN 
approximation to uncertainties to control an autonomous 
small-scale helicopter.  
The objective of this paper is to propose an intelligent 
adaptive trajectory tracking controller using FBFN for an 
autonomous small-scale helicopter. This paper is written in 
two principal contributions. First, the intelligent adaptive 
backstepping design method augmented with FBFN is 
successfully applied to achieve trajectory tracking of a small-
scale helicopter. Second, the semi-globally ultimate 
boundedness of nonlinear flight dynamics of the closed-loop 
helicopters is proven using the Lyapunov stability theory. All 
the updating laws are derived and implemented 
simultaneously and recursively.  
The rest of the paper is organized as follows. Section II 
briefly recalls the mathematical model of the helicopter 
dynamics and the FBFN approximation used for the controller 
design. Section III elaborates the complete design procedure 
of the adaptive backstepping integral controller in detail. 
Section IV, one numerical simulation is conducted to illustrate 
the performance and merit of the proposed control method. 
where 2• means the 2-norm of the vector; 1 8
T
j j jc cα ⎡ ⎤= ⎣ ⎦"  
8R∈ and 1j Rβ ∈  are respectively the center vector and  the 
inverse of the derivation of the i-th neuron in the hidden layer, 
and are to be tuned during the control process.  Moreover, the 
vector 82 3 1 2[ , , , ]TX Rδ δ ε ε= ∈  represents the output vector of the 
FBFN input layer.  Note that the input elements of FBFN input 
layer consist of the velocity error vector, 32 Rδ ∈ , the thrust 
error, 33 Rδ ∈ , the heading error, 11 Rε ∈ , and the yawing rate 
error, 12 Rε ∈  , which are defined in the next section. Then, the 
output vector of the hidden layer are represented by 
[ ]1 1 1 2 2 2( , , ) ( , , ), ( , , ),..., ( , , ) TN N NS X s X s X s Xα β α β α β α β=  where α =  
8 1
1[ ... ]
T T T N
N Rα α
×∈ and 1 2[ ]T NN Rβ β β β= ∈" . Finally, the 
output vector of the FBFN output layer is given as TW SΔ =  with 
the connective weight matrix 3jk NW w ×⎡ ⎤= ⎣ ⎦  between the hidden 
layer and the output layer. All the weights ( ijα , jβ  , and jkw ) of 
the FBFN are randomly initialized and adjusted during on-line 
operation. 
Now, let the optimal FBFN outputs ( *Δ ) be used to 
approximate accurately the small body forces in (2) and 
expressed as ( )( )* *1 ˆˆ( ) b T T TMKu W S W W S Sm ℜ Θ = = + +   where 
notations *, ^ , and ~  are for the optimum, estimation, and 
error values, respectively. In order to achieve good estimation 
of coupling forces and online fine tuning of ˆ TW , Sˆ , αˆ , and βˆ , 
the expansion of S  is taken in a Taylor series as follows; 
 ˆ ˆ
ˆ ˆ
S SS h
α α α αβ β β β
α β
α β= =
=
=
⎡ ⎤ ⎡ ⎤∂ ∂
= + +⎢ ⎥ ⎢ ⎥∂ ∂⎣ ⎦ ⎣ ⎦
    (8) 
where the matrix α  is expanded as a vector of 8N*1 
dimension and h  is a vector of higher order terms with a 
boundary of hh b≤ . In addition, 1ˆ ˆ
ˆ ˆ
( ) ( )
T
T TNssS
α α α α
β β β βα α α
= =
= =
⎡ ⎤ ∂∂∂ ⎡ ⎤
=⎢ ⎥ ⎢ ⎥∂ ∂ ∂⎣ ⎦ ⎣ ⎦
  " , 
1
ˆ ˆ
ˆ ˆ
( ) ( )
T
T TNssS
α α α α
β β β β
β β β= =
= =
⎡ ⎤ ∂∂∂ ⎡ ⎤
=⎢ ⎥ ⎢ ⎥∂ ∂ ∂⎣ ⎦ ⎣ ⎦
  "  , where js
α
∂
∂

 and j
s
β
∂
∂

 are computed 
as follows; 
 N Nˆ 1 1 8 8
ˆ ( 1) 8 ( ) 81 8 1 (8 )
ˆ ˆ ˆ2 0,..., 0 , ( ) ,..., ( ) , 0,..., 0j j j j j j
j N j
N
s
x s x sα α
β β
β α α
α =
=
− × − ×
× ×
∂
= − − −⎡ ⎤∂ ⎢ ⎥⎣ ⎦

	
  (9) 
 N N
2
ˆ 2ˆ ( 1) ( )
1 1 ( )
ˆ0,...,0 , , 0,...,0j j j
j N j
N
s
X sα α
β β
αβ =
=
− −
×
∂ ⎡ ⎤
= −⎢ ⎥∂ ⎣ ⎦

	
  (10) 
where 2
2
ˆ ˆˆ ˆˆ ( , , ) e x p { } , 1, . . . ,j j j j js X X j Nα β α β= − − = . 
Finally, the coupling forces in (2) can be replaced by the 
following equation, 
 
*
ˆ ˆ
ˆ ˆ
ˆˆ ˆ ˆ, T T TS SW S W W h
α α α αβ β β β
α β
α β= =
=
=
⎡ ⎤ ⎡ ⎤∂ ∂Δ = Δ + Δ Δ = + + +⎢ ⎥ ⎢ ⎥∂ ∂⎣ ⎦ ⎣ ⎦
       (11) 
where ˆˆ ˆ TW SΔ = is the estimation of coupling forces, Δ  is the 
estimation errors, and the union of the high order items, 
ˆ T Th W h W S= +
  , to be bounded maxh ε≤

. 
III. INTELLIGENT ADAPTIVE TRAJECTORY 
TRACKING 
For the purpose of trajectory tracking, the three positions 
and the heading are chosen as the desired outputs. The desired 
trajectories are given by the position vector, ( )idP t , the heading 
angle, ( )d tψ and their time derivatives ( idP , idP , idP , dψ , dψ ). The 
control objective is to find the control laws for b
Tu  and bMu  such 
that all the output errors (
iδ ,i=1..4 and jε ,j=1,2) can converge 
towards zero for any initial condition. For tracking any 
trajectories of an autonomous helicopter, the proposed method 
is based on the full rigid body dynamics (1)-(4) where the 
coupling forces in (2) are not neglected. All control inputs of 
the thrust ( b
Tu ) and moments ( bMu ) are explicit early in the 
second error dynamic equation (
2δ ). To successfully complete 
the backstepping control design, two techniques of the 
dynamic extension and the FBFN approximation are adopted 
for the thrust control and the moment controls respectively in 
the proposed method. Therefore, the so called pseudo controls 
(
mrT ,ω ) are first derived in the proposed adaptive backstepping 
design and then the actual controls ( b
Tu , bMu ) can be computed 
based on them. In addition, the estimation rule of the vehicle 
mass is added to overcome the weight variation in the whole 
flight.  
A. Adaptive Backstepping Control Augmented by FBFN 
Step 1: 
For the trajectory tracking, two tracking error vectors are 
defined as follows. 
 31 ,i idP P Rδ = − ∈  (12) 
 32 1 10,   
ti i i i
d d d P IR with P k k dδ ν ν ν δ δ τ= − ∈ = − − ∫  (13) 
where idP  and idP  are given by the path planner and Pk  and Ik  
are two positive tuning gains. The time derivative of 1δ  is 
easily got as 
 1 2 1 10
t
P Ik k dδ δ δ δ τ= − − ∫  (14) 
Then define the Lyapunov function candidate for 1δ  by 
 1 1 1 1 10 0
1
2 2
Tt tT IkV d dδ δ δ τ δ τ⎡ ⎤ ⎡ ⎤= + ⎢ ⎥ ⎢ ⎥⎣ ⎦ ⎣ ⎦∫ ∫  (15) 
Step 2: 
Further define the third tracking error vector as 
 
3
3
3 3 2 1
ˆ ˆˆ ˆ( )   ,b i id m mr d dT k T e with T ge Rδ ν δ δ= − ℜ Θ + Δ = − + + ∈  (16) 
where the parameter ˆmk  is used to estimate the variable mass 
( 1mk m= ) and the coupling effect term 
1 ( ) bMR Kum
Θ  is replaced 
by the estimation of the FBFN outputs ( Δˆ ) in (11). Taking the 
time derivative of 2δ  yields 
 2 3 2 1 3ˆ( ) bm mrk T R eδ δ δ δ= − − − Θ + Δ   (17) 
where mk  is the estimation errors of the total mass. Then the 
Lyapunov function candidate for 2δ  is chosen as follows. 
 2 1 2 2
1
2
TV V δ δ= +  (18) 
Step 3: 
Taking the time derivative of 3δ  and substituting (3) lead to 
 3 3 3 3ˆ ˆ ˆ ˆˆ ˆ ˆ( ) ( ) ( ) ( )b b bd m mr m mr m mrT k T e k T sk e k T eδ ω= − ℜ Θ − ℜ Θ − ℜ Θ + Δ
     (19) 
2 2 2 2 2 2' '
1 2 3 4 1 2
4 4 3 1 1
1
2 2 3 3
2 3 4 5
1ˆ( )
1 1 1 1
P P P
T T b T
m mr mr_max m m
T T T T
V k k k
U k T U e T k k W W
W W W W
δ δ δ δ ε ε
γ λ
α α β βλ λ λ λ
= − − − − − −
+ Δ − ℜ Θ + +
+ + + +

     
         
 (40) 
where ⋅  denotes the Euclidean norm and 4 2 3(1 )T T TPU kδ δ= + +  
( ) 43 2 TP Ik k δ+ + + . With the substitution of (11) for Δ  and the 
following parameter adjustment rules ,  
 4 3ˆ ˆ( )T bmrm m
mr_max
Tk k U e
Tγ
= − = − ℜ Θ   (41) 
 4 ˆˆk k k kW W u Sλ= − =  , k =1,2,3 (42) 
 4 4 ˆˆ T
SU Wα α λ
α
⎡ ⎤∂
= − = ⎢ ⎥∂⎣ ⎦
   (43) 
 5 4ˆ ˆT
SU Wβ β λ β
⎡ ⎤∂
= − = ⎢ ⎥∂⎣ ⎦
   (44) 
the time derivative of the overall Lyapunov function 
( ), , , , ,i j mV k Wδ ε α β   along the trajectories of the tracking errors 
is 
 2 2 2 2 2 2' '1 2 3 4 1 2 4TP P PV k k k U hδ δ δ δ ε ε= − − − − − − +
  (45) 
where the last item of undetermined sign is about the 
approximation error vector of the FBFN function. With 
assumption of maxh ε≤

, the time derivative of V  can be 
rewritten by the following inequality, 
 ( )( )( ) ( )( )
2 2 2' '
1 2 1 2 2
3 3 4 41 3 2
P P P max
P max P I max
V k k k
k k k
ε ε δ δ δ ε
δ δ ε δ δ ε
≤ − − − − −
− − + − − + +

 (46) 
which is negative semidefinite only if 
 ( ) ( )2 3 4,  1 ,  and  3 2max P max p I maxk k kδ ε δ ε δ ε≥ ≥ + ≥ + +  (47) 
with positive Pk , Ik and Pk ′ . This shows that the solutions of 
the error dynamic equations have the properties of uniform 
and ultimate boundedness. The following theorem summarizes 
the aforementioned result. 
Theorem 1: Assume that the parameters Pk , Ik , Pk ′ , Ik′ , γ  
and iλ ,i=1,…,5, are positive so that the overall Lyapunov 
function in (39) is positive semidefinite and radially 
unbounded, as well as its the time derivative in (46) will be 
negative semidefinite. For the trajectory tracking, the closed-
loop dynamics of the small-scale helicopter is described by the 
set of the equations of motion (1-4), the control laws (37-38), 
the parameter adjustment rule of the mass (41) and the 
adaptation rules of the FBFN weight matrices from (42) to 
(44). With the positive estimation ˆmk  and the attitude 
singularities of 2π± , all error variables , 1,..., 4i iδ = , 
and , 1,2j jε = , are semi-globally ultimately bounded and 
converge to some neighborhood of the origin as t → ∞ . 
Furthermore, the size of the neighborhood is described by 
(47), depending heavily upon the maximum approximation 
error to the coupling forces, maxε . 
IV. SIMULATIONS AND DISCUSSION 
In this section, one numerical simulation is conducted to 
investigate the effectiveness and performance of the proposed 
autonomous helicopter control system. The high- fidelity and 
well-validated nonlinear model [2] of a small scale helicopter 
incorporating with unmodeled dynamics and measurement 
uncertainties is adopted in the numerical simulation. The 
intelligent adaptive tracking controller augmented with FBFN 
approximation to the coupling forces of an autonomous 
helicopter was implemented as the low-level motion 
controller.  
A. Nonlinear Modeling and Simulation Setup for a Small Scale 
Helicopter 
The multidimensional and highly nonlinear dynamic 
modeling of the small scale helicopter developed by Gavrilets 
et al. in [2] is adopted here. The high-fidelity modeling 
incorporates the aerodynamics of rotor thrust, engine governor 
model, rotor flapping dynamics and actuator dynamics into the 
rigid-body model. This physics-based helicopter dynamic 
model has been validated using flight data to show good 
fidelity for a variety of flight conditions with advance ratios up 
to 0.15. In dynamic respect, this model is suitable to 
accurately represent the small scale helicopter motions and has 
been frequently used to evaluate control design methods [14-
15]. Therefore, in addition to the rigid-body dynamics used by 
the controller design, the wing aerodynamics and the rotor 
flapping dynamics especially are also constructed in the 
nonlinear simulations to validate the robustness of the 
proposed controller to those unmodeled dynamics and 
uncertainties. All helicopter’s parameters are the same to those 
in [2].Some parametric and dynamical uncertainties are  also 
considered in [2].  
B. Performance Indices 
For the purpose of trajectory tracking control, the position 
errors of the four control outputs should be maintained as 
small as possible. The smaller the tracking errors are 
maintained, the better the control performance is evaluated for 
a trajectory tracking controller. The index of mean squared 
tracking error is introduced here. With the heading error for 
example, 
 21
1
1 ( )
N
i
MSE i
N
ε
=
= ∑  (48) 
where N is the total number. The same way can be applied to 
the position errors 1δ . 
The second index is the attitude quickness (AQ) quoted 
from the ADS-33 handling qualities specification [16]. It is 
defined as the ratio of peak pitch (roll) rate to change in pitch 
(roll) attitude during a helicopter maneuver. 
 pk pkAQ q θΔ= or pk pkp φΔ  (49) 
where ( )pk pkq p  is the maximum pitch (roll) rate and ( )pk pkθ φΔ Δ  
is the maximum pitch (roll) angle during the attitude time 
response. The required attitude changes shall be made as 
rapidly as possible from one steady attitude to another without 
significant reversals in the sign of the cockpit control input 
relative to the trim position. The attitude changes required for 
compliance with this requirement shall vary from 5 deg in 
國科會補助計畫衍生研發成果推廣資料表
日期:2012/10/22
國科會補助計畫
計畫名稱: 子計畫一：智慧手眼力協調控制、自主抓取與操作、以及類腦功能之任務執行
(I)
計畫主持人: 蔡清池
計畫編號: 100-2221-E-005-028- 學門領域: 智慧型機器人
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
本計畫團隊已建立輪型雙手臂居家服務應用平台，且已參與 2012 TIROS 展示，
參與 2012 TIROS MC 舉辦智慧機器人創意競賽與 2012 TIROS 教育部為電腦系統
設計競賽，協助推動兩岸機器人學的技術與經驗交流，且已舉辦 SIRcon 
2011,FIRA 2011,AM 2012, ISR 2012, iUZZY2012,iACC2012 等國際研討會。 
 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
