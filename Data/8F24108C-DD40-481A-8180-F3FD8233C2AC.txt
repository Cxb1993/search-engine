一、 中文搞要 
本研究計畫執行重點在於主動式之監
控模式開發。我們融入了人工智慧機制及模
糊類神經系統架構在我們的影像追蹤系統
下，以監控環境之因子或追蹤目標物之特徵
為我們的判斷依據，達到適時調整追蹤結果
以符合實際環境需求，並隨時提供使用者警
示訊息或反應建議，務求達到主動即時性之
研究目的。本計畫另一發展重心在融入影像
辨識機制於監控環境中，並以提升在監控環
境下的影像追蹤系統以及辨識系統之高度
實用性以及適切性為執行目標。此外針對追
蹤主體物的特徵不易顯現及影像隨著環境
的劇烈變化等議題，我們也以達到辨識率提
高的要求，並以獨特實用性之辨識系統開發
為本研究計畫的執行重心。 
關鍵詞：監控環境、影像追蹤、影像辨識、
人工智慧、類神經網路、模糊系統。 
 
Abstract 
This research project focuses on the 
development of actively monitoring models 
which incorporate AI (Artificial Intelligence) 
and neural fuzzy techniques in our developed 
systems of image tracking and recognition. 
We make use of the surrounding factors of the 
monitored environments and the features of 
tracking targets to be the basis of judgment. 
Also, we flexibly adjust tracking outcomes to 
meet the practical environments and respond 
the systematic suggestions or warning advises 
appropriately in order to achieve the goal of 
real-time and mobility. Another importance of 
this project lies in the combination of image 
recognition mechanism and intelligent 
monitoring system. Our project also enhances 
the applicability and practicability under 
conditions of drastic changes of surrounding 
luminance. Moreover, our project aims at 
improving the image recognition rate 
practically and constructing a unique 
recognition system under real environments. 
Keywords: Monitoring environment, image 
tracking, image recognition, artificial 
intelligence (AI), neural networks, fuzzy 
system. 
二、 計畫緣由與目的 
由於電機資訊科技與人工智慧技術的
蓬勃發展，人類對科技技術及居家安全的需
求亦隨之迅速地增加著，居家安全監控系統
(surveillance system)也因為此一需求而孕育
而生；過去已有許多即時辨識系統的研究提
出，但是依然有許多具有挑戰性的議題需要
研究，例如前景的取得，以及辨識速度等問
題。但在對於各種物體的偵測方面，大部份
仍是採用監督式的學習分類法(Supervised 
Classification)。一般來說，這些方法都
可被分成三個步驟：(1)移動物體的分離，
(2)物體特徵的抽取，與(3)物體的辨識。以
下是針對這三項步驟常見使用方法做比較
詳細的介紹： 
(1) 移動物體的分離 
移動物體的分離目的在找出連續畫格
中的移動物體。常見的法方法大致分為三
類，1.光流法(Optical Flow)，2.立體視覺
(Stereo  Vision)3.時間差異法(Temporal 
Difference)。4. 背景相減法。光流法可以
被用來偵測單一移動物體的移動情形。在[1]
中，光流的技術被使用在交通工具的偵測
上。但使用此技術偵測移動物體的缺點就是
其計算的複雜度相當高，若是想要將系統運
用在即時(Real-Time)的物件偵測上，運算
速度會是一個相當重要的考量。此外，光流
的技術在對於非剛性物體的移動偵測並不
適用。立體視覺法，如[2]利用二隻以上的
攝影機對同一場景的物體做取景，最大的優
點在於對於靜止不動的物體也能有效分
離，但是由於需要較高的設備裝置費用，在
商業應用上是很最重的缺陷。而時間差異法,
如[3]則是利用單一攝影機取得的連續影
像。做前後兩張影像相減。藉此方法獲取在
影像中移動的物體。這種方式的好處在於計
算時間快，但明顯的問題是無法針對靜止不
動的物體。根據這幾種原因。近年來比較常
見的方式為背景相減法。如 Smith et.[4]，
利用事前建立的背景與現在取得的景像做
由於我們希望建立一個能夠自行適應
各種架設環境，亦不需隨環境不同而得人工
去調整參數之系統。因此我們必需建立一個
會自行隨時間持續去做更新，能適應背景的
光線及背景物體移動的強健背景。因為如果
背景的模式是固定又不會隨時間及環境更
新，所相減出來的移動物體將可能包含背景
區域。因此將會增加錯誤的檢測率。根據以
上種種因素，使用高斯混合模型(Gaussian 
mixture model, GMM)來建構背景[7]是一個
良好的選擇。其方法流程如圖 3-2所示。其
中時間軸差異是用來偵測可能的背景區
域。而背景模型就是以高斯混合模型演算法
來建構。在高斯混合模型演算來建構。高斯
混合模型演算法中，每一個像素的背景皆可
由數個高斯分佈 N ~ (μ ,σ )組合而成。
每一個高斯代表著不同背景的分佈情形，並
且藉由隨著時間的變動遞迴更新背景，因此
可以解決多重背景的問題。並且在實際實驗
中可發現到，往往需要用超過三個以上的高
斯混合模型來建構背景才足應付較複雜的
環境。 
為了降低雜訊的干擾與確保所得到的
訓練影像的完整性，首先利用高斯濾波器對
影像做雜訊的濾除，隨後將去除雜訊的影像
做二值化處理，並經過兩次形態學的膨脹來
避免取得的前景影像過於破碎，再將其以連
通成分法(Connected Components)[8]分離
出前景影像中移動之物件。且為了因應有時
會有移動物體破裂的情況，將每一個移動物
體附近可能是一體的物件融合，並經過一個
大小濾波器(Size Filter)的限制機制來避
免雜訊的影響。最後得到每一個獨立分離的
移動物體之後可以再加上消除陰影的動作
以確保所得前景，如圖 3-3所示。但在此同
時因為連通成分法的判斷方式，也許會將兩
個在畫面中重疊的物體指派為同一物件，這
樣的情況會產生誤判。特別是當一群人並排
行走的情況，因此我們對此種狀況提出一種
方式稍作分割。因為人的頭部是全身都重疊
的情況下最有可能保持獨立不重疊的部
分，且其形狀較為特殊容易區別，故以頭部
的橢圓形作為分離移動物體主要的依據。圖
3-4(a) 為一個橢圓形遮罩，(0,0)為此遮罩的
中心點，“●”表頭位的位置而“*”則為背景的
位置。根據此遮罩設定一定範圍對前景作搜
尋，符合一定相似程度者則有可能為頭部之
位置。經過前面的搜尋會得到部分符合條件
的中心位置，如圖 3-4(b) 頭部中間範圍。
將這些中心點在 X 軸上做累積，如圖如圖
3-4(b)上方。因此可以分離出主要的幾個群
體，以圖 3-4(b)兩人為例，此兩群的群中心
(圖 3-4(b)頭部中的點)則可用來推測頭部中
心點的位置，因此我們決定這一個移動物體
中實際上是含有兩個不同的物體，可以將它
們分割再做辨識。但若是人手舉高等可能造
成頭部位置之誤判，為了避免此問題，我們
將整個移動物體在X 軸上做累加如圖 3-4(b)
下方，符合峰值者才有可能為頭部之位置。
其實際結果如圖圖 3-5 所示。 
圖 3-2 移動物體的擷取流程圖 
 
 
(a)濾除前 (a)濾除後 
圖3-3 雜訊濾除前後結果 
Background
Update
Temporal 
Difference
GMM
Algorithm
Noise
Elimination
Noise
Elimination
Frame t-T Frame t
Background 
Model
Background Model











































1
1
1
1
0010
0001
1020
0102
: 
t
t
t
t
t
t
t
t
x
y
x
y
x
y
x
y
ModelTracking
 
(x,y)代表此物體中心在畫面中的位置，以
目前畫面(t)及上一畫面(t-1)的位置來預
測下一畫面(t+1)的位置。藉由卡爾曼濾波
器對連續狀態的遞迴分析以及雜訊排除，則
可以在當物體移動的過程中發生被其它物
體遮蔽或其它因素造成失去追蹤時，能精確
的推測出出該移動物體下一畫面可能出現
之位置。下列圖 3-7 為物體追蹤的流程圖。
圖 3-8與圖 3-9為不同環境下追蹤結果。 
Kalman
Filter
Update
Target
Model
T
Define new
Target Model
FSimilarity
> Thb
N- Target  
Models
M- Target 
Candidate
Color
Histogram
Representation
Color
Histogram
Representation
Prediction by
Kalman Filter
# Target
Model
mismatch
F
T
Position
Color 
Histogram
Tracking A
Tracking A
Tracking A
Tracking B
Bhattachaya
Similarity
Measure
T
 
圖3-7 物體追蹤流程圖 
2 物體特徵的抽取 
 為了使系統能夠自動分類各種在畫面
中出現的各種移動物體，並且為後端辨識系
統紀錄各物體有用的資訊。因此在經過移動
物體的分離的步驟後，將對所有偵測出的移
動物體做特徵抽取。由於本系統目的並非單
一針對某項特徵物件做辨識，所以在特抽取
的過程中將會針對所有可能用到的特徵資
訊做紀錄。其中包含物體的形狀，顏色以及
位移資訊三大項目。 
在物體的形狀方面，我們紀錄的特徵為 
(1)物體的大小與(2)物體的長寬比。物體大
小以獨立物體在偵測影像中所佔像素個數
代表。而物體的長寬比則以偵測物體在影像
座標軸X與座標軸Y上的分別投影大小作相
除代表。在物體的顏色方面，為了節省系統
不要必地重覆計算，直接以在追蹤的過程中
的(3)顏色機率密度分佈來做代表。唯一差
異在於對於三個分別的顏色向量將統一量
化成四階表示。在物體的位移方面，我們將
紀綠當時(4)物體的位置與(5)物體的速
度，其中物體的位置以各獨立物體的影像中
心座標做為代表。物體的速度為當時物體的
瞬時移動速度。 
  
(a)GMM背景 (a)GMM背景 
  
(b)移動前景 (b)移動前景 
  
(c)追蹤結果 (c)追蹤結果 
圖3-8 公路場景追
蹤結果 
圖3-9 十字路口場
景追蹤結果 
 
3. 物體的辨識 
再取得物體特徵後，我們則需選擇一個
適當的方法來做為我們的分類器。對我們的
系統而言，相同物體往往會因為時間或位移
的因素造成形態上特徵的不同(如車輛的正
面與側面)。甚至相同概念的物體會因為人
為的因素造成在某些特徵上有很大的差異
(如行人穿著衣物的顏色)。以類神經網路來
分析並自動設計一般的模糊邏輯法則，對以
上所提到的設計問題，提供了一個嶄新且可
行的解決方法。整體而言，適應性模糊系統
所做的調整可分為二類：結構調整（Structure 
而總物體判斷成功率公式如下： 
       
1=
M
M
i
i
R


總物體分類成功率  (11) 
     
1 > 5 0 %
0
iR

 

物體正確分類率
其它
 (12) 
在測詴的過程中，我們將同場景影片分為兩
部份，其中一部份偵測物體用作模糊神經網
路訓練之用。另一部份拿來測詴。 
1. 十字路口 
表4-2 十字路口測詴結果 
實驗項目 結果(%) 
物體平均偵測率 91.6% 
錯誤偵測率 6.2% 
物體錯誤追蹤率 9.1% 
物體平均分類率 56.8% 
總物體分類成功
率 
91.7% 
其結果如表4-2所示，其中用來做分類
測詴的物體總數為24個。如圖4-5所示在該
段影片造成錯誤偵測率較高的原因是當太
陽光源如果突然產生變化，由於高斯混合模
型背景建構更新的速度較改變的速度慢，所
常會因為光線不同而得到不正確的前景。另
外如果監視器架設高度過高且偵測物體靠
太近，可能會因為偵測時太小無法利用橢圖
形遮罩的方式順利分割。 
 
2. 公路 
其結果如表 4-3所示，其中用來做分類
測詴的物體總數為 24 個。在該段影片物體
平均偵測率較低的原因是由於道路遠方之
車輛因為所偵測出移動物體的大小過小。如
圖 4-6上方所示。在經過大小濾波器過濾小
範圍雜訊，被當成雜訊濾除或大小未達到物
體判斷的限制，因此造成偵測率下降。 
表 4-3公路測詴結果 
實驗項目 結果(%) 
物體平均偵測率 82.3% 
錯誤偵測率 0.9% 
物體錯誤追蹤率 9.3% 
物體平均分類率 62.4 
總物體分類成功
率 
100% 
 
 
3. 公園 
表4-4 公園測詴結果 
其結果如表4-4所示，其中用來做分類
測詴的物體總數為8個。在該段影片中因為
狗的毛色和背景雷同，造成背景相減後的前
景稍微破碎，如圖4-7所示。故錯誤偵測的
情況較為嚴重。並且因物體不完整，在物體
分類這項步驟容易造成誤判。 
 
  
(a)偵測結果 (b)移動前景 
圖4-5 光線變化結果 
  
(a)偵測結果 (b)移動前景 
圖4-6 公路偵測結果 
  
(a)偵測結果 (b)移動前景 
圖4-7 移動物與背景相似結果 
實驗項目 結果(%) 
物體平均偵測率 95.3% 
錯誤偵測率 23.7% 
物體錯誤追蹤率 2.9% 
物體平均分類率 57.2% 
總物體分類成功率 75% 
六 參考資料 
[1] P. H. Batavia, D. E. Pomerleau, and C. E. Thorpe, 
“Overtaking vehicle detection using implicit 
optical flow,” IEEE Conference on Intelligent 
Transportation System, Nov.1997, pp. 729-734. 
[2] C. Orrite-Uruñuela, J. Martínez del Rincón, J. 
Elías Herrero-Jaraba, G. Rogez, “2D Silhouette 
and 3D Skeletal Models for Human Detection 
and Tracking,” Proceedings of the 17th 
International Conference on Pattern Recognition 
(ICPR’04), 2004. 
[3] C. E. Smith, C. A. Richards, S. A. Brandt, and N. 
P. Papanikolopoulos, “Visual tracking for 
intelligent vehicle-highway systems,” IEEE 
Transactions on Vehicular Technology, Vol. 45, 
No. 4, pp. 744-759, Nov. 1996. 
[4] C. E. Smith, C. A. Richards, S. A. Brandt, and N. 
P. Papanikolopoulos, “Visual tracking for 
intelligent vehicle-highway systems,” IEEE 
Transactions on Vehicular Technology, Vol. 45, 
No. 4, pp. 744-759, Nov. 1996 
[5] J. Zhou and J. Hoang, “Real Time Robust Human 
Detection and Tracking System,” Proceedings of 
the 2005 IEEE Computer Society Conference on 
Computer Vision and Pattern Recognition 
(CVPR’05) 2005. 
[6] L. Zhao and C. E. Thorpe, “Stereo- and neural 
network-based pedestrian detection,” IEEE 
Transactions on Intelligent Transportation 
Systems, Vol. 1, No. 3, pp. 148-154, Sept. 2000. 
[7] C. Stauffer and W.E.L Grimson, “Adaptive 
Background Mixture Models for Real-Time 
tracking,” In IEEE Conference on Computer 
Vision and Pattern Recognition, pp. 246-252, 
June 1999 
[8] H.Samet and M.Tamminen. “Efficient Component 
Labeling of Images of Arbitrary Dimension 
Represented by Linear Bintrees.” IEEE Trans. 
Pattern Anal. Mach. Intell 
[9] R. Venkatesh Babu, P. P e´rez, and P. Bouthemy. 
“Robust tracking with motion estimation and 
local kernel-based color modeling.” Image Vis. 
Comput. In Press, 2007. 
[10] Roweis, S. and Ghahramani, Z., “A unifying 
review of linear Gaussian models,” Neural 
Comput. Vol. 11, No. 2, (February 1999), pp. 
305–345. 
[11] Jang, J.-S. R., "ANFIS: Adaptive-Network-based 
Fuzzy Inference Systems," IEEE Transactions on 
Systems, Man, and Cybernetics, Vol. 23, No. 3, 
pp. 665-685, May 1993. 
[12] Chin-Teng Lin, Linda Siana, and Yu-Wen Shou, 
“A Conditional Entropy Based Independent 
Component Analysis for Applications in Human 
Detection and Tracking”, submitted to the Special 
Issue on Advanced Image Processing for Defense 
and Security Applications in EURASIP Journal 
on Advances in Signal Processing. 
[13] Yu-Wen Shou, Chien-Ting Yang and Chin-Teng 
Lin, “An Effective Algorithm for Shadow 
Removal in Intelligent transportation system”, 
Proceedings of the ASME 2009 International 
Mechanical Engineering Congress & Exposition, 
Florida, U.S.A, Nov. 2009. 
[14] Yu-Wen Shou, “Intelligent Judgment System for 
Vehicle-Overtaking by Motion Detection in 
Subsequent Images”, Proceedings of the ASME 
2009 International Mechanical Engineering 
Congress & Exposition, Florida, U.S.A, Nov. 
2009. 
 
 
 1  
參加國外研討會之心得報告 
本人於2009年11月13日到19日參加在美國佛羅里達州Orlando由ASME協會所主辦的研討會並於此次的研討會發表論文。本
次研討會的名稱為“Proceedings of the ASME 2009 International Mechanical Engineering Congress & Exposition”，這次的研討會
屬於ASME協會每年固定舉辦的大型研討會，而本次的研討會討論的議題主要可以分為Advances in Aerospace Technology、
Biomedical and Biotechnology Engineering、Combustion Science and Engineering、Design and Manufacturing、Electronics and 
Photonics、Emerging Technologies(In Structural and Materials Aspects of Alternative Energy Systems)、Energy Systems: Analysis, 
Thermodynamics and Sustainability、Engineering Education and Profession Development、Engineering to Address Climate 
Change、Heat Transfer, Fluid Flows, and Thermal Systems、Mechanical Systems and Control、Mechanics of Solids, Structures and 
Fluids、Micro and Nano Systems、New Developments in Simulation Methods and Software for Engineering Applications、
Processing and Engineering Applications of Novel Materials、Safety Engineering, Risk Analysis and Reliability Methods、
Sustainable Products and Processes、Transportation Systems、Sound, Vibration and Design、Early Career Development Series等21 
個主要機械及電機資訊相關領域。本人在這個研討會裡所發表的研討會論文是屬於其中的Transportation Systems領域裡的智
慧型運輸系統，當然在智慧型運輸系統中有很多的研究主題和領域亦和資訊電機密不可分，這次論文的主題也是和智慧型
運輸系統裡的駕駛輔助系統開發息息相關，其中的研究是以輔助駕駛者開車時變換車道與否之適性建議為主要方向。在這
次的研討會期間除了論文發表的時間有機會和在相類似或相同領域的先進交換彼此的心得之外，研討會的主辦單位也主辦
了很多重要且符合目前科技主流的演講，其中最受到大家熱烈參與的演講請到了NASA著名的太空人Rear Admiral T.K. 
Mattingly (USN, Ret.)，演講的主題為“Space Exploration: Commemorating the Past, Envisioning the Future”；主要的內容是以
阿波羅13號如何在當時的困境中安全的回到地球，當然其中包含很多外人所不清楚的NASA在執行任務時所採取的必要措
施以及當時的隨機應變方法；當然這次的演講不僅僅受到與會者普遍的好評，也讓我在這次的演講中得到在個人研究外的
不少驚喜的收穫。
 3  
occurred, and could be inconvenient for manual operations of 
lane marking. Fortunately, our features proposed in this paper 
could work well without using any information of surrounding 
lane markers. 
For the related applications about the development of warning 
systems in traffic situations, various approaches have been 
presented, including psychological studies and experiments of 
information science. The literatures, [6~8], established the traffic 
warning system by video surveillance schemes, target tracking, 
detection, and image segmentation, while the studies in social 
fields tried to explain the traffic situations in semantic 
interpretations [9~11]. Though the aforementioned studies could 
give a suitable mechanism in classifying targets as a single person, 
a group of people, and vehicles, the system would be too 
complicated to be carried out in the real-time cases. As for video-
based object segmentation, the sufficiency of a-priori information 
determined how complete the proposed methods would be by 
automatic and semi-automatic procedures [12~13]. However, the 
requirement of higher visual quality of the source videos or images 
might restrict the uses of structured methods. 
Many studies focused on searching for features which were 
used to characterize the object of interest in the traffic scenes, 
inclusive of different dimensions of vectors. Like the earlier 
contributions [14], they made use of the characteristics of 2-D and 
3-D located in the object in discussion. Some schemes by statistics 
of features were also applied to ITS. [15] tried to take advantage of 
spatial and temporal information oriented models, and [16] used 
the statistical results of probability distributions extracted from 
images to provide some analyzed tool. The features indeed could 
help understand and characterize the object of target for some kind 
of applications like object detection and tracking. But for the 
judgment system which would be easily influences by the 
variations of intensities in the change of scenery, the efficiency of 
the previous methods could be much lower than expected.  
In the researches of image compression/decompression and 
ending/ decoding, some popular parameters, like the signal to 
noise ratio (SNR), spatial/temporal scalability, could be 
considered as an evaluation tool to give the reasonable 
explanations for proposed approaches [17]. Since there would 
be not useful measures to estimate the performance of the 
related applications of ITS such like our proposed schemes, we 
were inspired to define our estimates in this paper to evaluate 
how our features and rule-based constraints could be enhanced 
by the variations of parameters. This paper would be articulated 
by organizing the following sections, including our proposed 
systematic structure, feature extraction and analysis, decision 
mechanism, experimental results, and conclusions.  
 
METHODOLOGY 
1. Our systematic architecture 
In this paper, we proposed an innovative feature for 
detecting the dynamic motion in the tested files of videos to 
represent how stable the detected image frames in sequence 
would be in the specified time interval, which implies the right 
time when to overtake another car. To test if our proposed 
features can work well for detecting the dynamic behaviors of 
subsequent images, we use the pre-recorded files of video as 
our input of the system which has been shown in Fig. 1. 
 
 
 
Fig. 1 The overall systematic mechanism 
 
Fig. 1 represents our entire systematic mechanism which 
includes the processing methods in solid squares, the 
intermediate analytical schemes in dotted-line blocks and 
arrows, and signals occurred during the whole processes. First 
of all, the video-typed files could be captured by digital cameras 
mounted on the rear-view mirror. Each frame from the original 
video files should be taken as the input of our system for further 
analysis in the detection of motion features. We defined a new 
feature set that can be described as a feature curve giving the 
motive dynamics for each specified frame. The statistical 
Input 
(Video-typed files) 
Image Acquisition  
Digital video-capture devices 
 
Image frames 
detected 
Feature Extraction  
Motion feature 
Analysis 
Rule-based 
Judgment 
Output 
(Giving advices 
whether to overtake 
another car) 
Motion 
features extracted 
processed 
frame by 
frame 
Ratios of 
arguments 
Analysis by 
statistics 
 5  
both horizontal and vertical orientations, ac2 is equipped when 
used in the related applications on road. Since the slight 
changes of intensities would have a great impact on 
performances of image processing technique, we decide to 
concentrate on effectiveness and promptness for major 
considerations in what kind of applicable methods choosing 
from. In addition to the variation caused by moving of vehicles, 
drastic changes of backgrounds in each frame of image might 
give rise to a big change of the argument ac2. The index ac2, the 
implication of the 1
st
 order gradient of projected curves in some 
extent, is endowed with useful information in statistics. ac1 is 
developed to improve the insufficiency of ac2 by using the 
definition of variation in ac2. As matter of fact, subsequent small 
changes in ac1 may imply the big change of backgrounds of 
images but not the moving of vehicles passing by. A sudden big 
change in ac2 is most likely to result from an instantaneous 
move of vehicles. For all these reasons, we should combine ac1 
and ac2 to give a better analytic method so as to yield a more 
precise signal showing when to overtake the nearby vehicle. 
 
3. The decision mechanism 
In this section, we would introduce our decision 
mechanism based on vehicle-overtaking rules to decide when to 
change lanes during driving. We shall separate our rule-based 
system into two main parts, motion detection and avoidance of 
interferences. These two parts are classified in accordance with 
the pursuits of applications of image processing and how we try 
to apply our developed features. 
(1) Motion detection 
The features for detecting motions as well as the moving of 
vehicle passing by that we proposed in this paper should be 
correlated with the variation of dominant pixels of binary 
images by adaptive thresholding. 
A. Adaptive thresholding 
We determine the threshold by the distribution of 
luminance of digital images in gray scale to acquire the binary 
image frame captured from the source video file. A simple 
formulated equation interpreting our thresholding procedure is 
given as the equation (IV). 
   


 

o t h r e w i s e
EGI
jiBI
N
,0
,1
),( …………………… (IV) 
where BI indicates the acquired binary image as mentioned in 
the previous section, GI is the image in gray scale for each 
corresponding frame from the original videos in RGB color 
formats, and EN represents our defined N
th
 estimate of gray-
level value of the relative frame of image. The number N 
reveals how many sectors we try to distribute into within a 
complete range of 256 gray scales. EN would be generally 
higher if the average luminance of images in gray scale 
distributes in the higher range. Relatively, EN would go lower 
with a lower range of average luminance of images. Besides, the 
higher N contributes to the higher complexity of feature analysis 
while the lower N results in the lack of distinguishability of 
motion vectors. We determine the value of N in this paper by 
performances of experimental results due to the huge influences 
even by the small variation of intensities of images. The results 
in details will be given in the experimental part. 
B. Judgment rules of motion detection 
We defined the rules of motion detection in compliance 
with judgmatical capability and sensitivity when detecting the 
moves of vehicles or changes of surroundings. The 
characteristic feature ac2 can be regarded as a measurable 
parameter to estimate how much variation may be caused by 
moving objects of foregrounds. We give the constraint in (V). 
ac2 (j)  >  th1………………………………(V) 
where th1 is threshold for deciding the level of variation, and 
the counter j records which frame of interest. Usually the range 
from 10 to 15 percents of th1 indicates a sudden change of 
foreground of image. A much higher ac2 sometimes originates 
from the drastic variation of background of image rather than 
the moving of vehicles. Also, continuous qualified results 
satisfying the constraint (V) imply the fast moving of vehicles, 
especially in the smooth change of background of image. Since 
we aim at giving the correct signal showing when to overtake 
the nearby car, another defined constraint is shown in (VI). 
))((
~
22
1

endnnj
c thja

 ..................................... (VI) 
It is obvious that the formulation defined in (VI) gives the 
logical symbol which inducts the intersection of every satisfying 
condition. In (VI), n1 and nend stand for the first and last number 
of frame in which the logical restrictions are satisfied. We can 
also flexibly adjust the difference between n1 and nend on 
account of the source video file. As a result, we take this 
constraint to decide the appropriate timing of changing lanes. 
(2) Avoidance of interferences 
The feature ac2 unfortunately would be interfered easily by 
the surroundings of backgrounds, that is to say, more constraints 
should be set to test the variation caused by passing of vehicles. 
That is the reason why we start with the uses of ac2 to avoid 
such interferences. We exhibit this rule-based constraint as 
(VII) to decrease the false alarms caused by scenery changing in 
the images.  
313131 )1(  )(  )1( thjaandthjaandthja ccc  …
……………………………………………………………. (VII) 
As what we show in (VII), three consecutive frames can be 
examined to see whether the requirements are met. In some 
manner, subsequent high values of ac1 which result from the 
high variations of ac2 in series would be physically brought 
about by abrupt changes of scenes in each frame of image.  
 
4. Experimental results 
We simulated our experimental results in this paper by 
using a pre-recorded video file in mpeg format taken from the 
rear-view mirror of the driving vehicle. In order to demonstrate 
the capability of our proposed features, we would at first show 
how the image-frames vary while the nearby vehicles passing by 
in some circumstances without big changes. As Fig. 3 displays, 
we would present 32 image frames in around 1 sec, for the 
 7  
incorporating other information in images like colors, shapes, 
and so on into our feature series. Also, we will try more 
systematic techniques in artificial intelligence and neural-fuzzy 
systems to take stead of our rule-based decision mechanism to 
make the decision of parameters in this paper adaptively and 
automatically. Finally, we wish to improve the results of 
determining the right frame and timing when the rear vehicles 
start speeding up, and apply to more related applications of ITS 
in the near future. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
                            
 
 
 
 
      Fig. 3 Image-frames in 1 sec for (a) original images (b) images in gray level (c) binary images by proportional thresholding 
(a) 
(b) 
(c) 
