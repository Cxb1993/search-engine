2號(signal synthesis)。
在本子計畫的第一年度，原先規劃作
韻律自然度提升的研究；第二年度，規劃
作音色轉換的研究；第三年度，則規劃作
text planning 的研究。
雖然本子計畫通過了第一年的審查，
但是總計畫”未來車”並未通過審查。因此
我們決定直接進行語音合成系統裡音色轉
換的研究。我們以 HNM (harmonic plus
noise model)信號模型作基礎，來進一步研
究音色轉換的方法，以便在僅使用一個錄
音者所錄的語音單元下，讓 HNM 模型合
成出多種音色(如男生、女生、小孩之音
色)、且音質清晰的語音信號。如此就可讓
使用者選擇自己喜歡的音色，而使合成出
的語音變得更有親切感。
三、研究方法
3.1 基本觀念
文 獻 上 可 找 到 一 些 關 於 voice
conversion 的 成 果 論 文 ， 但 是 voice
conversion 所指的意思是，在特定的兩人 A
與 B 之間，將 A 所說的話經過語音轉換的
處理之後，轉變成如同 B 所說的話一樣，
亦即聽到的是 B 的音色而不是 A 的音色。
在本計畫裡，我們有興趣的是音色的多樣
性，而不關心轉換出的音色是否接近某一
特定人的音色。
經由比較小孩、成年女生、成年男生
的語音聲紋圖(spectrogram)，可知他們的音
色差異，表現在聲學上的一個重要特性是
共振頻率的高低差異，也就是小孩的共振
頻率最高，成年女生的會降低一些，而成
年男生的則最低。此種現象的解釋是，成
年男生的聲道(vocal track)長度較長，所以
共振頻率較低，而小孩的則因為尚未發育
聲道長度較短，所以共振頻率較高。
因此可以藉由壓縮頻譜的包絡來調降
共振頻率，而把女生音色轉換成男生音
色，相反地也可藉由伸展頻譜的包絡來調
升共振頻率，而把女生音色轉換成小孩音
色。頻譜包絡壓縮的一種簡易作法是，把
各組HNM諧波參數 <f, a,> (頻率, 振幅,
相位)中的頻率值乘以一個小於 1 的倍率，
並且把雜音(noise)的頻譜包絡乘以相同之
倍率。
不過， 簡單地壓縮頻譜包絡，並不能
夠把女生音色轉換成理想的男生音色，因
為所轉出的男生音色，會帶有娘娘腔的味
道，因此我們研究了另外一種轉換的方
法，詳細作法於 3.2 節裡說明。
3.2 實施方式
我們以 HNM 為基礎，來考慮音色轉
換的實施方式。HNM 是由 Y. Stylianou 所
提出的一種語音信號的模型，希望在作語
音處理(編碼，合成)時，仍能保持信號的清
晰度與自然度。HNM 在分析模型參數時，
提供了最大有聲頻率 MVF (maximum
voiced frequency) 的一個偵測方法，依
MVF 值可將一個語音音框(frame)的頻譜
分割成低頻、高頻之兩個部分，如圖 1 所
示之/a/音框之頻譜例子。對於低頻部分的
MVF noiseharmonicdB
Hz
圖 1 頻譜分割之例子
信號成分，採取以諧波成分 (harmonic
partials)的加總來 modeling，在此以 fi, ai,i
表示音色轉換前第 i 個諧波成分的頻率、
振幅、與相位。至於高頻部分的信號成分，
則 採 取 以 平 滑 的 頻 譜 包 絡 (spectral
envelope)來塑模(modeling)，實際上是以少
數(如 20)的倒頻譜(cepstrum)係數來代表此
頻譜包絡；當把倒頻譜係數序列後面補上
一些 0 值，再經 DFT (discrete Fourier
transform)轉換回頻譜域，固定 100Hz 間隔
取樣得到的弦波頻率與振幅，在此以 gi, bi
來表示。
4各個音框(或控制點)的頻譜參數，常用的頻
譜參數如 MFCC (mel frequency cepstrum
coefficient) 及 LSF (line spectral
frequency)。當藉由頻譜參數還原出一條連
續的頻譜曲線之後，我們變可對它作取
樣，來得到各個諧波成分的頻率和振幅
值，然後再把這些取樣得到的數值交給方
塊(c)去作音色轉換的處理，之後方塊(d)、
(e)和(f)就可按序進行下去。
Syllable ID and its prosody data
Determine pitch-original HNM
parameters
Place control points and
construct time-mapping function
Voiced segment:
Synthesize HNM harmonic signal
Synthesize HNM noise signal
Syllable signal
Transform spectrum with FAS,
PLFM, or PLFM+FAS
Determine pitch-tuned HNM
parameters
Unvoiced segments:
Synthesize HNM noise signal
(a)
(b)
(c)
(d)
(e)
(f)
圖 5 音色轉換及語音合成之處理架構
關於方塊(a)所作處理的細節，可參考
我們最近發表的研討會論文:
古鴻炎、吳昌益，「基於 ANN 之頻譜演進
模型及其於國語語音合成之應用」，第二
十 屆 自 然 語 言 與 語 音 處 理 研 討 會
(ROCLING 2008)，台北，第 66-77 頁 ,
(2008/9/4~5)。
另外，關於方塊(b)、(d)、(e)和(f)所作處理
的細節，則可參考我們發表的期刊論文:
Gu, Hung-Yan and Yan-Zuo Zhou, “An
HNM Based Scheme for Synthesizing
Mandarin Syllable Signal”, International 
Journal of Computational Linguistics and
Chinese Language Processing, Vol. 13, No.
3, pp. 327-341, (2008).
五、聽測實驗
在進行聽測實驗之前，我們使用所建
造的系統，預先合成出 5 個音檔，分別以
AA, AB, AC, AD 和 AX 來代表，其中 AA,
AB, AC, AD 是使用 FAS 方法來作音色轉
換，它們使用的縮放係數分別是設定為
0.9, 0.8, 0.7 和 0.6；至於音檔 AX，則是使
用 PLFM 方法來作音色轉換。這些音檔可
從 網 頁 http://guhy.csie.ntust.edu.tw/
TmbrHNM/ F2M.html 去下載和試聽。
我們邀請了 12 位聽測者，每位聽測者
都允許不限次數地聆聽這 5 個音檔，然後
我們分別詢問每一位聽測者，AA, AB, AC,
AD 四個音檔之中，那一個的音色最接近
AX 的音色，結果 12 位之中有 11 位認為
AB 的音色最接近 AX。
根據前述的結果，接者我們請每一位
聽測者聆聽比較兩音檔 AB 和 AX，然後詢
問那一個音檔的音色較有男性味、及那一
個音檔比較可理解說話內容，在此評分的
方式是，2 分表示 AX 比 AB 明顯地更有男
性味、或更可理解，1 分表示 AX 比 AB 稍
微地有男性味、或可理解，0 分表示不能
分辨，-2 和-1 分則表示 AX 比 AB 差的方
向。
對於聽測者所給的評分，我們計算平
均分數、標準差後，所得到的結果如表 1
所示，由表 1 的分數可知，我們提出的
PLFM 轉換方法，在”男性味”方面平均得
到 0.75 分，而在”理解度”方面，平均得到
0.33 分，這表示 PLFM 法可用以改進轉換
出音色的”男性味”，並且不會喪失”理解
度”。
表 1 聽測之分數
AX vs. AB 平均 標準差
Manfulness 0.75 0.92
Intelligibility 0.33 0.94
六、成果與討論
經由本計畫的執行，我們在 HNM 信
號模型的基礎上，研究了語音音色轉換的
方法，並且把音色轉換的方法整合到之前
發展的國語語音合成系統裡，現在我們的
系統可以對原始女性錄音者的音色作轉
換，而合成出男性或小孩的國語語音。
1出席國際學術會議心得報告
計畫編號 NSC 97-2221-E-011-052
計畫名稱 未來車－語音合成與音色轉換系統
出國人員姓名
服務機關及職稱
古鴻炎
台灣科技大學資訊工程系副教授
會議時間地點 2009/05/06 ~ 2009/05/09, 泰國芭達雅
會議名稱 ECTI-CON 2009 international conference
發表論文題目 Model Spectrum-progression with DTW and ANN for Speech Synthesis
一、參加會議經過
這 次 的 ECTI-CON 2009 國 際 研 討 會 ， 由 泰 國 ECTI (Electrics/Electronics, Computer,
Telecommunication, Information)學會主辦，而由泰國 IEEE 支會協辦，接受的論文將收錄於 IEEE
Xplore 資料庫。由於該研討會接受的研究領域包含了信號處裡，並且個人未曾到過泰國，因此
選擇投稿 ECTI-CON 2009 研討會。由論文題目可知，我們的研究成果是，以動態時間校正
(DTW)加上類神經網路(ANN)來建立頻譜演進(spectrum progression)模型，可用來提昇合成語音
的流暢度。
ECTI-CON 2009 研討會共有 459 篇論文
投稿，而被接受的論文有 295 篇(接受率
64.3%)，分別來自 17 個國家。我的論文排
於 5 月 7 日的 TAM1-5 session (Speech/Audio
Processing)，以口頭報告方式發表，右圖就
是進行論文發表時，在會場所拍攝的照片。
整個研討會共分成 8 個平行 session 作發
表，”信號處理”是其中一個平行的主軸，不
過，語音與聲訊有關的只有一個 session，其
餘的 session 主要含蓋的是影像處理方面的
論文，因此我只得選擇比較有興趣的信號處
理 session 來參與。
在行程方面，由於 5 月 6 日那一天排有三節課要上，且不易調課，所以只好決定搭乘 5 月 6
日晚上 10 點半的班機前往曼谷，然後再包車轉往芭達雅，到達旅館時已是 5 月 7 日凌晨的當地
時間四點，而於八點半開始的 session，我就必需作報告，也就是參加研討會的去程，是非常的
3Model Spectrum-progression with DTW and ANN
for Speech Synthesis
Hung-Yan Gu and Chang-Yi Wu
Dept. CSIE, National Taiwan University of Science and Technology
43 Keelung Road, Section 4
Taipei, 106 Taiwan
Abstract-In this paper, an ANN based spectrum-progression model
(SPM) is proposed. This model is intended to improve the fluency
level of synthetic Mandarin speech under the situation that only a
small training corpus is available. In constructing this model, first
each target syllable is matched with its reference syllable by using
DTW. Then, each warped path, i.e. spectrum-progression path, is
time normalized to fixed dimensions, and used to train an ANN
based SPM. After training, the SPM is used together with other
modules such as text analysis, prosody parameter generation, and
signal sample generation to synthesize Mandarin speech. Then, the
synthetic speech is used to conduct perception tests. The test
results show that the SPM proposed here can indeed improve the
fluency level noticeably.
I. INTRODUCTION
There are many languages, e.g. autochthons’languages and
Hakka in Taiwan, that face the crisis of disappearance. It
would be helpful for these languages if synthetic speech’s
quality can be promoted by using only a small training corpus.
Note that resource (manpower and money) are usually very
limited for these languages to record utterances and prepare
training corpus. Therefore, we keep in mind that speech
synthesis techniques developed should be economically
transferrable to another language. Even though the language
studied here is Mandarin and is of large population, we still
study to improve its synthetic speech’s quality by using only a
small training corpus.
Speech-Fluency Factors: FT Discontinuity vs. Spectrum Progression
It is well known that prosody models play important roles in
synthesizing natural Mandarin speech [1, 2, 3]. The prosodic
parameters that are modeled include pitch contour, syllable
duration, amplitude, and syllable-front pause. In the past, we
had some research experiences in model-based speech
synthesis, i.e. prosodic parameters and signal waveforms are
separately modeled and generated. However, the synthetic
speech is not perceived as fluent as uttered by a real person
even thought the generated prosodic parameters are natural
enough. We once attributed this phenomenon to the
discontinuities of formant traces (FT) between two adjacent
syllables. Therefore, we had spent some efforts to solve the
problem of formant trace discontinuities by means of unit
selection [4]. Some improvement in fluency is observed when
adopting this method. Nevertheless, a gap in fluency is still
perceived between synthetic and real speeches.
Recently, we found that the problem, lack of fluency, is
already noted by several researchers [5, 6, 7]. The solution
method they proposed is to slice a syllable into several
segments in terms of an optimal state sequence of an HMM
(hidden Markov model). Each segment is characterized by a
specific spectral envelope that is modeled with a Gaussian
mixture on a state. In addition, the duration of a segment is
modeled with a state-staying PDF (probability density
function). In our viewpoint, the HMM based method is a more
detailed planning method to subdivide a sylable’s duration
into several comprising segments’ durations in a non-uniform
manner. That is, different segments of different spectral
envelope are assigned unequal durations. The purpose of such
unequal assignments of segment durations we think is to more
delicately mimic the progression of spectrum with time in
which a real person articulates.
Spectrum-Progression Path and Modeling
The dynamic changing of spectrum (or spectral envelope)
with time is an important concept, and is termed “spectrum
progression”here. Also, the term, spectrum progression path
(SPP), is frequently used. SPP means a spectrum mapping
curve between a syllable uttered within a sentence and a
syllable uttered in isolation that has same pronunciation. An
example of SPP is shown in Fig. 1, in which the waveform on
/lin/ uttered within a sentence
/lin/uttered
in
isolation
Fig. 1. An example of spectrum progression path.
the horizontal axis is the syllable /lin/ uttered within a
sentence and the waveform on the vertical axis is the same
syllable but uttered in isolation. In the past, synthetic speeches
from many Mandarin speech synthesis systems are felt as
lacking of fluency. We think the main cause is that they don’t
adopt a SPP model and set the SPP directly to a straight line.
Therefore, we began to study the problem of SPP modeling
and generation. Here, we don’t follow previous researchers to
adopt HMM. One major reason is that our training corpus is
small and is not affordable for training HMM. Another minor
58 contextual param eters
32 dim . spectrum -prog. param eters
Fig. 4. ANN structure for spectrum progression modeling
As to the contextual data, consider that the spectrum
progression of the t-th syllable, St, of a sentence is chiefly
influenced by the tone type, syllable initial and final types of
the syllable, St. In addition, the tone type and final type of the
last syllable, St-1, and the tone type and initial type of the next
syllable, St+1, may still have some effects. Therefore, the
contextual data prepared for each target syllable are as the 8
types listed in Table 1. In Table 1, the last item, time index, is
Table 1 Contextual data for a target syllable
Ite
ms
to
ne
of
St-1
clas
s of
St-
1 final
to
ne
of
St
ini
t.
of
St
fi
nal
of
St
t
one
of
S
t+1
class
of
St+1
init.
ti
me
In
dex
Bit
s 3 4 3 5 6 3 3
Vo
id
intended to carry timing information. If the current syllable is
the t-th syllable of a sentence of T syllables, then the value of
time index is set to the floating-point number t/T. For the data
items of tone, 3 bits are allocated to represent each of the tone
items because Mandarin has 5 different tones. For the initial of
St, 5 bits are allocated because Mandarin has 21 different
syllable initials. Similarly, 6 bits are allocated to represent the
final of St because Mandarin has 39 different syllable finals.
Here, because the number of recorded target syllables is not
large enough, we decide to group the final types of St-1 into
9 classes and group the initial types of St+1 into 6 classes in
order to decrease the number of possible combinations for the
ANN’s input data. Hence, just 4 bits and 3 bits are alocated to 
represent these classes, respectively.
III. INTEGRATION OF OUR SYSTEM
After the ANN SPM is trained, we integrate it with other
modules to build a Mandarin speech synthesis system. With
this system, wave files for perception tests are then
synthesized. The other modules involved are as those blocks
in Fig. 5, including text analysis, prosodic parameter
generation, and signal waveform synthesis. When the text of a
Chinese sentence is inputted, it is parsed, in the“text analysis”
block, into a sequence of words by looking up word
dictionaries. In the same time when dictionaries are looked up,
a Chinese character’s pronunciation syllable and tone are
determined. Next, tone sandhi rules are applied. Then, the
sequence of syllables and tones are fed to both the left and
right blocks of Fig. 5 to generate spectrum progression
parameters and prosodic parameters for each syllable.
Text input
Spectrum-progression
param. generation
Prosodic param.
generation
Text analysis
Signal waveform
synthesis
Speech signal
Fig. 5. System structure of our Mandarin synthesis system
A. Generation of Prosodic Parameters
The prosodic parameters for each syllable include pitch
contour, duration, and intensity. These parameter values are
determined in the right block of Fig. 5. Here, we have
constructed a separate ANN for each of the three prosodic
parameters, and each ANN is of the structure as shown in Fig.
4. In fact, the ANN for pitch contour generation was trained in
our previous work [11] by using 375 training sentences uttered
by a male speaker. The reason for not building a combined
ANN for the three parameters is that the quantity, 375, of
training sentences is not large enough. However, by
appropriate grouping the values of some contextual data items
as seen in Table 1, the generated prosodic parameters can still
show acceptable performance in naturalness level. This can be
checked by browsing our web page, http://guhy.csie.ntust.edu.
tw/spmdtw/, to listen to the example wave files of synthetic
speech.
B. Synthesis of Signal Waveform
In the bottom block of Fig. 5, signal samples for each
syllable, St, are synthesized in terms of its reference syllable.
Because each reference syllable is recorded and saved only
once, hence there is no chance to do unit selection. In addition,
consider that syllable signals of diverse prosodic
characteristics need to be synthesized, and the signal
waveforms synthesized by the traditional method, PSOLA
[12], are not stable in quality when pitch contour or duration is
considerably changed. Therefore, we decided to develop an
HNM (harmonic plus noise model) [13] based method for
synthesizing the signal samples of a Mandarin syllable. By the
efforts spent in the previous study [14], we had developed an
HNM based and improved method that satisfies our needs.
Before the synthesis procedure can start, each reference
syllable must be analyzed beforehand to obtain its HNM
parameters, i.e. amplitude, frequency, and phase parameters
for each harmonic partial and 20 cepstrum coefficients for
representing the envelope of noise spectrum. In our synthesis
procedure, the first step is to place control points uniformly on
the time axis of a synthetic syllable. The spacing between two
adjacent control points is fixed to 100 sample points. As the
second step, the HNM parameters for each control point are
derived. By using the spectrum progression parameters
generated in the left block of Fig. 5, the time position of a
control point can be mapped to a time point on the reference
sylable’s time axis. Accordingly, two adjacent frames
