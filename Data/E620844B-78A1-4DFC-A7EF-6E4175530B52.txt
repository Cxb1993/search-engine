and recovery of ellipsis and co-reference using 
templates and machine learning. 
英文關鍵詞： virtual patient, clinic diagnostic dialogue, 
ellipsis, co-reference, natural language processing 
 
 2
行政院國家科學委員會專題研究計畫期末報告 
電腦化虛擬病人對話模組中省略與同指涉現象之處理 
Ellipsis and Co-reference Resolution in the Dialogue Module of the 
Computerized Virtual Patient 
計畫編號：NSC 100-2221-E-019 -062 - 
執行期限：100 年 08 月 01 日至 101 年 07 月 31 日 
主持人：林川傑 國立台灣海洋大學資訊工程學系 
計畫參與人員： 陳彥亨、鮑建威、溫政達、涂毓城、林萬哲、
陳彥豪 
 
一、摘要 
 
電腦化虛擬病人  (computerized virtual 
patient) 是以電腦系統擔任虛擬病人的角
色，經由模擬問診的方式訓練學生推敲病因
的教學方法。系統需提供一個自然語言的對
話界面，讓擔任醫生角色的使用者可以用最
自然的方式提出問題來問診，也可避免其他
PBL 系統以選單方式提問造成過多提示的缺
點。然而自然語言中常出現的省略以及同指
涉現象，會使得使用者所提出來的問句難以
與教案中所準備的問題進行比對。本計畫擬
研究醫寮問診中會出現的省略與同指涉現
象，並嘗試回復被簡省的資訊，以增進問句
比對模組的效能。 
本計劃原先規劃在三年的整合型計畫之
中，然而整合型計畫僅第一年獲得補助。本
次改以兩年期個別型計畫提出，獲補助期間
只有一年，因此本成果報告僅說明原先規劃
在第一年之工作，包括省略與同指涉現象之
分類統計，以及依樣板資訊及機器學習偵測
並還原省略與同指涉現象的實驗結果。 
 
關鍵詞：虛擬病人、問診對話、省略現象、
同指涉現象、自然語言處理 
 
Abstract 
 
The Computerized Virtual Patient System 
is a system which plays the role of a virtual 
patient in the training of diagnosis for medical 
students.  This system provides a natural 
language dialog interface to let the students 
interrogating in a natural way which avoids the 
disadvantage of giving additional hints as other 
PBL systems often do in which a list of 
questions is provided.  However, the common 
problems such as ellipsis and co-reference in 
NLP can harm the success rate of matching 
questions in the prepared educational cases.  
This project plans to study the ellipsis and 
co-reference phenomena in medical diagnosis 
dialogs, and then proposes methods to resolve 
these problems in order to improve the 
performance of question matching. 
This plan was originally included in a 
three-year integrated research project, which 
was sponsored for the first year.  After re- 
proposing as a two-year individual research 
project, another one-year sponsor was approved.  
Therefore, this report only contains the results 
of the works originally scheduled in the first 
year, including the classification of ellipsis and 
co-reference, and the experiments on detection 
and recovery of ellipsis and co-reference using 
templates and machine learning. 
 
Keywords: virtual patient, clinic diagnostic 
dialogue, ellipsis, co-reference, natural 
language processing 
 
二、緣由與目的 
 
虛擬病人 (virtual patient) 是用來訓練
醫學院學生推理判斷病情的重要教學方法。
以往虛擬病人的實行方式，是由教師擔任病
人的角色，以模擬問診的方式讓學生推敲出
真正的病因。這種「問題導向學習」
(problem-based learning, PBL) 的學習方式，
學生可由接近真實情境的經驗中建構出自己
 4
2008; Stoyanov et al., 2009; Zhang et al., 2009; 
Vemulapalli et al., 2009; Recasens and Hovy, 
2010)，直接針對中文對話系統中處理同指涉
的研究較少。而且已有幾個大型評比計畫提
供了實驗資料集，像是 MUC-7 和各屆 ACE
等語料庫，因此名詞詞組均有標示，也各別
有名詞之語意類別資料。和我們所要處理醫
療問診對話有相當程度的差異。 
各研究團隊的做法有許多相同處，大多
都採用機器學習，特徵大致可歸類為字面、
文法、語意、位置四類，僅有 Wang 和 Ngai 
(2006) 採非監督式機器學習  (unsupervised 
learning) 方式。Vemulapalli 等人 (2009) 引
入了投票機制預測同指涉的可能性，而
Recasens and Hovy (2010) 則是比較了不同
語言、不同語料庫情形下，同指涉處理的差
異性。 
電腦化虛擬病人的對話主題限定在醫學
診斷的領域上，主題交錯及詞意歧義性上的
問題較少，醫生病人的虛擬角色的共識也可
預設僅為醫學領域常識，又可蒐集豐富的醫
學知識資源來使用。若引入領域知識的資
源，對於對話中自然語言現象的處理比較容
易成功。Williams (2000) 認為加入領域知
識，對於對話中自然語言現象的處理比較容
易成功。電腦化虛擬病人系統提供了一個可
行但仍具相當挑戰性的對話系統研究環境。 
 
四、實驗資料 
 
本計畫主要目的是處理問診對話中所會
出現的自然語言現象，因此蒐集一個大型的
實際對話語料集非常重要。藉由大量的觀
察，我們可以較完整地歸納出所有需要處理
的省略及代名詞指涉現象和特徵。 
實際問診對話資料有兩種來源，一是醫
學院中實施虛擬病人的實際教學錄音，一是
醫院中實際的門診對話。取得對話錄音後，
先請人將錄音聽打成文字，再請具有醫學背
景的人校對內容。除了整合型計畫第一年所
蒐集錄音外，本年度又多蒐集了幾段實際門
診錄音。刪去許多錄音不清楚或不適合做為
實驗資料的檔案後，目前共有實際門診錄音
20 段，虛擬病人上課錄音 47 段。總句數是
5,684 句，這其中醫生說了 2,362 句話，病人
則是 3,322 句話。 
由於實際門診進行錄音時，參與對話的
人常常不只醫生和病人，還包括了陪同前來
的病人家屬。我們會在第三方的話句前後加
上特殊標記。雖然說本計畫所設計之系統不
會有第三方參與對話 (僅有使用者扮演醫生
而系統擔任病人)，第三方所說話語仍可能含
有後續對話中所省略資訊或被指涉對象，故
予以保留。 
聽打並校對完的資料再由標記人員確認
對話中省略或同指涉現象出現的句子、標記
指涉字串、並寫出被省略或被指涉的資訊。 
 
五、省略現象之偵測與還原 
 
5.1 省略現象之分析 
 
觀察被省略的資訊，發現大多數屬於幾
個常在問診中被提及的語意類別，例如身體
部份或症狀等等。我們依照語意以及省略型
式，訂出了七類常見的省略方式，統計如下： 
 
省略資訊 醫生句 病人句 總計
癥狀 21 0 21
身體部位 354 260 614
部位+症狀 132 154 286
疾病 67 62 129
藥物 8 12 20
檢查 7 8 15
危害人體物質 72 41 113
其他 9 4 13
總計 670 541 1211
 
以下分別簡介各類省略型式並舉例，例
子中被省略資訊以{}括註。七類中有六類都
是指先前對話已提及的該語意類型資訊被省
略，包括： 
(1) 癥狀：「背後會{痛}嗎」 
(2) 身體部位：「{頭}痛多久了」 
(3) 疾病：「{糖尿病}發現到現在多久了」 
(4) 藥物：「吃{止痛藥}多久」 
(5) 檢查：「醫生會幫我量{血壓}」 
(6) 危害人體物質：「已經三年沒喝{酒}了」 
 
而這六類資訊中，身體部位和癥狀常一起被
 6
訊的語意類型，還原省略資訊時就是以對話
前方曾經出現過的同類型詞語當做候選對
象。這裡提出三種還原規則： 
(1) 距離最靠近者 
(2) 到目前為止出現最多次者 
(3) 若最靠近者距離過遠則改取最高頻者 
 
六、同指涉現象之偵測與還原 
 
6.1 同指涉現象之分析 
 
在 67 份實驗資料中，同指涉現象出現了
270 次，比起省略的 1,211 次及代名詞指涉的
1,301 次要少，但仍有一定數量而需處理。 
出現同指涉現象時，句中一定有一個字
串擔任指涉者，所以同指涉現象的偵測就是
在決定指涉字串的邊界。研究發現，不論被
指涉資訊為何，指涉字串的詞性序列有相似
的規則，例如「這個情形」「那種感覺」都
是 Nep+Nf+Na 型式。這是我們的主要方向。 
被指涉對象的語意類型變異就比較大，
因為中文口語中常以「這個」「那個」指涉
各式各樣的資訊，被指涉的可能一個詞也可
能是一件事，很不容易處理。由於未來的系
統是以打字進行對話，太不明確的指涉方式
應該會較少。 
此外，有些型式的指涉出現次數太少，
無法得出有意義的結論。因此本年度研究
中，同指涉偵測會包含實驗資料中所有指涉
出現處，但是被指涉對象的還原則著重在指
涉對象為「疾病」、「癥狀」、「身體部位」
及「部位+癥狀」這四者。在實驗資料中，這
類同指涉現象共出現了 133 次。 
 
6.2 同指涉現象之偵測 
 
將實驗資料進行斷詞及詞性標記後，抽
取被標記為指涉字串部份的詞性序列來統計
出現次數，發現僅出現 11 種不同的詞性序
列，其中有些詞性其實都是固定的詞彙，顯
示指涉字串確實有固定句型。研究有意義的
詞性序列後，歸類出六種句型： 
 
(1) 這/該/那+[Nf]+[DE]+Na 
其中 Nf 是量詞，DE 是 “的”，這兩者可
出現可不出現。Na 這裡指特定名詞，包
括 “情形”、“感覺”、“部位”、“時候” 等
的同義詞或近義詞。例：「這個情形」。 
(2) 這樣/類似+[DE]+Na 
Na 同樣指特定名詞的同義詞或近義詞。
例：「這樣的情形」。 
(3) Na 
“情形” 與 “症狀” 類的詞彙可單獨成為
指涉字串。例句：「休息一下，情形就改
善了」。 
(4) 這邊/這裡 
“這邊” 與 “這裡” 這兩個詞常直接用來
指涉身體部位。例句：「這邊痛多久了」。 
(5) 這+個 
“這 個” 這字串則常用來指涉病症，相當
於第 1 種句型但 Na 被簡省了。例句：「這
個是健康檢查才查出來的」。 
(6) 這樣/這樣子 
“這樣” 與 “這樣子” 這兩個詞也可單獨
成為指涉字串。例句：「這樣子多久啦」。
但這兩個字串又很常做為程度副詞，或在
句尾當做口頭禪，歧義性較高。 
 
6.3 指涉對象之還原 
 
「疾病」、「癥狀」及「部位+癥狀」這
三者的指涉字串有著很相似的表徵，因此在
還原資訊分類上把它們合併為「病症」一大
類。「身體部位」維持自成一類。 
當指涉字串的句型屬第 1 ~ 3 種，而其
Na為 “部位” 類同義詞或近義詞，則猜為「身
體部位」；若為 “情形” 與 “症狀” 類同義
詞或近義詞，則猜為「病症」。指涉字串屬
第 4 種句型者猜為「身體部位」，而屬第 5、
6 種句型者猜為「病症」。 
與省略還原相同，尋找先前對話中同類
型資訊距離最近或出現次數最多者，做為最
可能之指涉對象。 
除了規則式策略外，我們也設計了 50 種
特徵來試著還原「病症」類的指涉情形，包
括距離相關、出現次數相關、候選詞種類、
發語者等等各類特徵。同樣以實驗來檢視機
器學習的效果。 
 
七、實驗 
 
實驗以 67 段錄音中所標記的 1,211 次省
 8
還原時只以先前對話中出現的該類型資訊為
候選對象。若是以 CRFtotal 或 CRFellipsis 判斷
的，所有類型資訊都可為候選對象。 
還原規則有三個： 
 
Dist: 距離最靠近者 
Freq: 出現次數最多者 
DF[k]: 在 k 回合內有距離最靠近者，否則選
出現次數最多者 
 
實驗結果如下表： 
 BPE-2 SE-2 
 P R F P R F 
Dist 79.8 82.4 81.1 57.1 57.1 57.1
Freq 88.2 91.0 89.6 42.9 42.9 42.9
DF[1] 83.6 86.3 84.9 42.9 42.9 42.9
 藥物 檢查 
 P R F P R F 
Dist 50.0 95.0 65.5 100.0 71.4 83.3
Freq 40.4 95.0 56.7 70.0 50.0 58.3
DF[2] 50.0 95.0 65.5 100.0 71.4 83.3
 危害人體物質 CRFellipsis 
 P R F P R F 
Dist 82.6 98.9 90.0 77.6 75.8 76.7
Freq 81.0 89.0 84.8 54.9 53.6 54.2
DF[2] 82.6 98.9 90.0 78.0 76.2 77.1
 CRFtype 
 P R F 
Dist 57.5 57.0 57.3
Freq 47.0 46.6 46.8
DF[3] 58.0 57.5 57.7
 
 
實驗結果發現，不同類型的資訊適用不
同的還原規則。我們最後的系統也是採不同
類型的還原規則，最後整體系統的還原效能
如下表： 
% P R F 
CRFtotal 70.77 76.96 73.73
樣板+CRFellipsis 82.99 83.82 83.40
樣板+CRFtype 75.83 76.96 76.39
 
7.4 同指涉偵測實驗 
 
以第 6.2 節設計的六種句型來判斷對話
句中指涉字串的出現，字串的邊界必須與人
工標記的答案相同才算正確。六種句型偵測
同指涉現象的精確率如下表： 
 
% P % P 
句型 1 100.00 句型 4 100.00
句型 2 89.47 句型 5 84.62
句型 3 94.44 句型 6 84.21
 
六種句型一起使用的整體效能如下表： 
類型 P R F 
全部 94.72 92.96 93.83
病症 88.14 86.67 87.39
身體部位 100.00 100.00 100.00
小計 89.31 87.97 88.64
 
其中第二行是以所有 270 個指涉來評估，而
第三、四行則是僅考慮還原實驗的「病症」
「身體部位」兩大類指涉情形來評估。 
 
7.5 同指涉還原實驗 
 
本次實驗僅以「病症」、「身體部位」
兩大類指涉情形來進行，共記有 133 次的同
指涉現象，其中「病症」120 次，「身體部
位」13 次。還原實驗是以規則或機器學習法
猜測這 133 次指涉之對象為何，評估公式為
猜測之正確率 (accuracy)。 
還原規則與省略還原實驗相同，都是依
距離及出現次數為判斷依據。與省略還原實
驗不同的是，因為在實驗資料集中，被省略
的資訊數量不少，會影響距離或頻率的計
算。我們以被省略資訊有無還原的兩種情形
來評估其對同指涉還原的影響。實驗結果如
下表： 
 
省略已還原 病症 身體部位 小計
Dist 50.83 84.62 54.14
Freq 75.83 84.62 76.69
DF[1] 63.33 92.31 66.17
 10
Domain Knowledge for Dialogue Model 
Adaptation,” Proceedings of the 5th International 
Conference on Intelligent Text Processing and 
Computational Linguistics, Lecture Notes in 
Computer Science (LNCS 2945), pp. 70-78. 
Merchant, Jason (2007) “Three kinds of ellipsis: 
Syntactic, semantic, pragmatic?” Presented at the 
Semantics workshop, pp. 1-58. 
Ng, Vincent (2007) “Semantic Class Induction and 
Coreference Resolution,” Proceedings of the 45th 
Annual Meeting of the Association of Computational 
Linguistics (ACL 2007), pp. 536-543. 
Nielsen, Leif Arda (2003) “A corpus-based study of verb 
phrase ellipsis,” Proceedings of the 6th Annual 
CLUK Research Colloquium, pp. 109-115. 
Recasens, Marta and Eduard Hovy (2010) “Coreference 
Resolution across Corpora: Languages, Coding 
Schemes, and Preprocessing Information,” 
Proceedings of the 48th Annual Meeting of the 
Association for Computational Linguistics (ACL 
2010), pp. 1423-1432. 
Ren, Feiliang and Jingbo Zhu (2008) “An Effective 
Hybrid Machine Learning Approach for Coreference 
Resolution,” Proceedings of Sighan4 workshop of 
IJCNLP2008, pp. 24-30. 
Stoyanov, Veselin, Nathan Gilbert, Claire Cardie, and 
Ellen Riloff (2009) “Conundrums in Noun Phrase 
Coreference Resolution: Making Sense of the 
State-of-the-Art,” Proceedings of ACL-IJCNLP 
2009, pp. 656-664. 
Su, Yi, Fang Zheng, Yinfei Huang (2001) “Design of a 
Semantic Parser with Support to Ellipsis Resolution 
in a Chinese Spoken Language Dialogue System,” 
Proceedings of EUROSPEECH-2001, pp. 2161- 
2164. 
Sumita, Eiichiro, Setsuo Yamada, Kazuhide Yamamoto, 
Michael Paul, Hideki Kashioka, Kai Ishikawa, and 
Satoshi Shirai (1999) “Solutions to Problems 
Inherent in Spoken-language Translation: The 
ATR-MATRIX Approach,” Proceedings of the 7th 
Machine Translation Summit, pp. 229-235. 
Vemulapalli, Smita, Xiaoqiang Luo, John Pitrelli, and 
Imed Zitouni (2009) “Classifier Combination 
Techniques Applied to Coreference Resolution,” 
Proceedings of the NAACL HLT, Student Research 
Workshop and Doctoral Consortium, pp. 1-6. 
Wang, Chi-shing and Grace Ngai (2006) “A Clustering 
Approach for Unsupervised Chinese Coreference 
Resolution,” Proceedings of the Fifth SIGHAN 
Workshop on Chinese Language Processing, pp. 
40-47. 
Williams, Sandra (2000) “Anaphoric Reference and 
Ellipsis Resolution in a Telephone-Based Spoken 
Language System for Accessing Email,” in Simon 
Botley and Antony Mark McEnery (eds.), 
Corpus-based and computational approaches to 
discourse anaphora, John Benjamins, Amsterdam, 
Chap 9, pp. 171-187. 
Wu, Hsiao-Hung (2003) On Ellipsis and Gapping in 
Mandarin Chinese, Master Thesis, National Tsing 
Hua University. 
Xu, Yushi, Jingjing Liu, Stephanie Seneff (2008) 
“Mandarin Language Understanding in Dialogue 
Context”, Proceedings of the 6th International 
Symposium on Chinese Spoken Language 
Processing (ISCSLP '08), pp. 1-4. 
Yamamoto, Kazuhide and Eiichiro Sumita (1998) 
“Feasibility study for ellipsis resolution in dialogues 
by machine-learning technique,” Proceedings of 
COLING-ACL'98, pp.1428-1435. 
Zhang, Yihao, Jianyi Guo, Zhengtao Yu, Zhikun Zhang, 
and Xianming Yao (2009) “The Research on 
Chinese Coreference Resolution Based on Maximum 
Entropy Model and Rules,” Proceedings of Web 
Information Systems and Mining (WISM 2009), pp. 
1-8. 
陳銘軍, 葉瑞峰, 吳宗憲 (2003) “以知識概念模型
為基礎之多主題對話管理系統,＂ Proceedings of 
ROCLING XV. 
魏廷冀 (2008) “從英漢對比分析談漢語空缺結構之
類型,” 華語文教學研究, Vol. 5, No. 1, pp. 67-85. 
有來自歐美國家的研究人員。其中又有不少同是從事自動問答技術的團隊，大家可在會議期間互
相觀摩彼此的想法策略，交換心得，並從中得到新的靈感，實是難得的機會。 
這次在會議中所發表的論文題目之一是「The Description of the NTOU RITE System in 
NTCIR-9」，提出了判斷句對之間推論關係的技術。給定一對句子 <t1, t2> 且預設 t1 成立時，句對
間推論關係有兩種分類分式。第一種 (BC task) 是判斷 t1 “可以” 或 “無法” 推論出。第二種 (MC 
task) 判斷兩者之間是否有以下這五種關係之一：forward entailment (可由 t1 推論出 t2)、reverse 
entailment (可由 t2 推論出 t1)、bidirectional entailment (兩者可推論彼此)、contradiction (兩者內含資
訊矛盾) 以及 independence (其他狀況)。我們提出了 20 種特徵，以機器學習的方式訓練分類器。
特徵除了用到字串比對重疊比例外，也用到句子間各字詞是否具有近義以及反義的關係等資訊。
實驗中也發現，若是將句對順序交換來新增訓練資料量、採用比例型的特徵而非數量值，效果較
佳。同時也發現，以多類別分類器 (MC classifier) 來進行 BC 或 MC 的工作都有較好的效能。 
本次會議焦點是另一篇同樣做句對推論的論文，作者宣稱在目前只能拿到少量的訓練資料情
形下，利用網路眾多一般使用者協助判斷規則的撰寫 (crowd sourcing 為當前新研究方向)，所整
合出的規則正確率可達 90%以上。由於目前不管在英文還是其他語言，正確率都還在六七成之譜，
這篇論文自然引起大家的注意。可惜在與作者詳細追問後，發現他們的系統中有一項同義詞詞典
資訊，在判斷一個新句對關係前，會請網路使用者協助提供該句對間的近義關係。由於系統引入
了人力，並非完全全自動程序，該系統效能不應與大多數研究單位的自動系統相比較。 
議程中安排了未來展望的座談，大家集思廣義，提出許多具新穎性的研究方向。像是是否可
能在文章中偵測數學公式的出現，甚至解讀或比對數學公式的意義。或是將句對推論技術應用在
其他系統中，像是自動問答系統、自動摘要系統等等。收穫非常豐富！ 
三、考察參觀活動(無是項活動者略) 
四、建議 
資訊工程領域的國際會議常是最新技術互相交流的場合，會議論文的審查制度也相當嚴謹，
應受到與期刊論文相同的重視與支持。 
五、攜回資料名稱及內容 
論文集及評比實驗資料 
六、其他 
Given two words w1 and w2, all their senses are paired and looked 
up in WordNet.  The WordNet relatedness score of a pair of 
senses is defined as follows. 
As shown in Figure 1(a), given two senses s1 and s2, let c be their 
nearest common ancestor, a and b the lengths of paths from the 
two senses to their common ancestor c, and d the length of the 
path from the root to c.  If more than one possible path is found, 
the shortest one is selected.  The WordNet relatedness score 
WNrel(s1, s2) of a pair of senses is defined as: 
WNrel(s1, s2) = (c + depthMAX – (a + b)/2) / 2depthMAX 
where depthMAX is the length of the longest path started from the 
root to a leaf node.  As we can see in the definition of the 
equation, the WordNet relatedness score of two words is higher 
when their WordNet distance (i.e. a + b) is shorter and their 
common ancestor has more specific sense.  The addition of 
depthMAX is to make sure that the score will not become negative.  
The score is normalized into 0 ~ 1 by divided by 2depthMAX. 
When two senses do not have a common ancestor in WordNet, 
their relatedness score is defined as 0. 
The WordNet relatedness score in antonymy relationship is 
defined in the similar way except that, as depicted in Figure 1(b), a 
pair of ancestors (c1, c2) who are antonyms to each other is 
identified instead of a common ancestor.  Now a and b are 
defined as the lengths of paths from s1 and s2 to their respective 
ancestors, and d is the average of the depths of c1 and c2 via a 
common ancestor c, i.e. d = dc + (d1 + d2) / 2, where d1 and d2 are 
the lengths of paths from c1 and c2 to their common ancestor c, and 
dc is the length of the path from c to the root. 
The WordNet relatedness score of two words is defined as the 
highest relatedness score measured among their sense pairs, i.e. 
),(max),( 2121
)(
),(
22
11
ssWNrelwwWNrel 
wSenses
wSenses


 
2.3 Word Alignment 
Given a pair of sentences (t1, t2), the system first collects the 
content words in them, denoted as P = {p1, p2, … pm} and H = {h1, 
h2, … hn}.  Redundant words and stop words are removed in 
advanced.  The second step is to do one-to-one word alignment 
between P and H.  Word alignment is found by two strategies, 
exact match and WordNet similarity.  The words in the 
intersection of P and H are first aligned and removed from P and 
H.  All unaligned words left in P and H are paired and searched 
in WordNet.  These pairs of words are sorted according to their 
WordNet relatedness scores.  The similar or antonymous pair 
with the highest score is chosen as alignment and removed from P 
and H repeatedly until no more pairs with a common ancestor can 
be found.  The word alignment algorithm is shown in Figure 2. 
2.4 Features 
20 features are used to train our SVM classifier.  Feature values 
can be determined by the result of word alignment.  The 
definitions of the features are given as follows. 
f|P|: number of distinct words in t1 (= m) 
f|H|: number of distinct words in t2 (= n) 
f|P||H|: number of overlapped words in t1 and t2 
ovr|P|: ratio of overlapped words in t1 (= f|P||H| / f|P|) 
ovr|H|: ratio of overlapped words in t2 (= f|P||H| / f|H|) 
fcapP: number of capitalized words in t1 
fcapH: number of capitalized words in t2 
fcapPH: number of overlapped capitalized words 
ovrcapP: ratio of overlapped capitalized words in t1 
(=fcapPH / fcapP) 
ovrcapH: ratio of overlapped capitalized words in t2 
(=fcapPH / fcapH) 
fNsim: number of aligned similar nouns 
fNant: number of aligned antonymous nouns 
fN: total number of aligned nouns 
fVsim: number of aligned similar verbs 
fVant: number of aligned antonymous verbs 
fV: total number of aligned verbs 
dNsim: average of the scores of aligned similar nouns 
dNant: average of the scores of aligned antonymous nouns 
dN: average of the scores of aligned nouns 
dVsim: average of the scores of aligned similar verbs 
dVant: average of the scores of aligned antonymous verbs 
dV: average of the scores of aligned verbs 
Some features are explained in more details here.  The values of 
fN* and fV* are obtained by counting the aligned pairs according to 
their type attributes in each POS.  Since each aligned pair has a 
WordNet relatedness score, the values of dN* and dV* are obtained 
by averaging the WordNet relatedness score of the aligned pairs in 
each POS. 
2.5 Classification 
Our classifier is trained to label 5 classes defined in the 
Multi-Class (MC) subtasks which classes are forward-entailment 
(F), reverse-entailment (R), bidirectional-entailment (B), 
contradiction (C), and irrelevant (I).  The classifier is used 
directly in a MC subtask. Given P = {p1, p2, … pm} and H = {h1, h2, … hn}: 
 When producing a run in Binary-Class (BC) subtasks, the 
multi-class labels are mapping into binary-class labels in the 
following way: labels F and B are mapped into label Y (entailment) 
while labels R, C, and I are mapped into label N (non-entailment). 
Let A be the chosen alignment.  Set A as  initially. 
For each pair (pi, hj) where pi  P, hj  H, and pi = hj, 
P  P – {pi}; H  H – {hj} 
A  A + {(pi, hj, identical)} 
3. LEARNING APPROACHES  For each pair remains in P  H 
We have experimented on several learning approaches including 
threshold setting of distance to the common ancestor, training 
corpus expansion, and feature selection.  There approaches are 
explained in this section. 
Measure its WordNet relatedness score. 
Repeat 
Select a pair (pi, hj) with the highest relatedness score 
Let type be their relationship (similar or antonymous)
P  P – {pi}; H  H – {hj} 
A  A + {(pi, hj, type)} 
Until P or H is empty. 
Figure 2. Algorithm of word alignment for RITE pairs 
3.1 Ancestor Distance Threshold 
When finding a common ancestor of a sense pair in WordNet, if 
the common ancestor is too far away from any of the sense, we 
The results are different from what we have seen in the training 
phase.  Expanding training corpus still succeeded in most cases, 
but using ratio and score average features outperformed the setting 
of using all features. 
Surprisingly, MC classifiers outperformed BC classifiers in most 
cases, even in a BC task.  MC classifiers can do better guessing 
for Y-pairs and B-pairs thus improve the performance. 
4.3 RITE4QA Evaluation 
Table 4 shows the results of our systems in the RITE4QA subtask.  
The outcome is totally different!  The system trained by using all 
features and the original training set performs much better than the 
other two.  We are still finding the reasons. 
Table 4. RITE4QA evaluation results 
System RunID Acc MRR
allf_c1_mc NTOUA-CT-RITE4QA-03 0.6346 0.3824
allf_c2_mc NTOUA-CT-RITE4QA-01 0.5459 0.3803
scoref_c2_mc NTOUA-CT-RITE4QA-02 0.5124 0.3572
 
5. CONCLUSION AND FUTURE WORK 
It is our first attempt to develop a textual entailment system.  
Several approaches have been proposed to train entailment 
relationship classifiers, including ancestor distance threshold 
setting, training corpus expansion, feature selection, and classifier 
setting.  The results show that a MC classifier trained by using an 
expanded training corpus and scoring features performs the best 
with an accuracy of 64.22% in BC task and 46.11% in MC task. 
Because we use Google Translate to rewrite all the sentences from 
Chinese into English, the errors of translation might have hurt the 
performance of our system.  In the future, we plan to use a 
different strategy to abolish the language gap of well-known 
thesaurus. 
6. REFERENCE 
[1] Rodrigo, A., Penas, A., and Verdejo, F. 2008. Overview of 
the Answer Validation Exercise 2008. In Working Notes for 
the CLEF 2008 Workshop. 
[2] Lloret, E., Ferrández, Ó., Muñoz, R., and Palomar, M. 2008. 
A text summarization approach under the influence of 
textual entailment. In Proceedings of the 5th International 
Workshop on Natural Language Processing and Cognitive 
Science (NLPCS 2008). 22–31. 
[3] Bentivogli, L., Clark, P., Dagan, I., Dang, H.T., and 
Giampiccolo, D. 2010. The Sixth PASCAL Recognizing 
Textual Entailment Challenge. In TAC 2010 Workshop 
Notebook Papers and Results. 
[4] Bos, J., Zanzotto, F.M., and Pennacchiotti, M. 2009. Textual 
Entailment at EVALITA 2009, In Proceedings of EVALITA 
2009. 
[5] Shima, H., Kanayama, H., Lee, C.W., Lin, C.J., Mitamura, 
T., Miyao, M., Shi, S., and Takeda, K. 2011. Overview of 
NTCIR-9 RITE: Recognizing Inference in TExt. In 
NTCIR-9 Proceedings, to appear. 
 
100年度專題研究計畫研究成果彙整表 
計畫主持人：林川傑 計畫編號：100-2221-E-019-062- 
計畫名稱：電腦化虛擬病人對話模組中省略與同指涉現象之處理 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 4 4 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
