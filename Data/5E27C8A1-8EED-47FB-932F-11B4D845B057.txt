 1 
 
 
   
 
 
NSC 99-2221-E-431 -001 -
 
  2 
二、報告內容 
I. Introduction 
Software reliability can be viewed as a powerful measure of quantifying software failures 
and it is defined as the probability of failure-free software operation for a specified period of 
time in a specified environment.  Since software is embedded in everything and permeates 
our daily life, the correct performance of software systems becomes an important issue of 
many critical systems.  For this purpose, a number of software fault detection/removal 
techniques are widely used by the program developers or testing teams.  In applying these 
techniques, the Software Reliability Models (SRMs) always play a rather important role in the 
field of SRE, as they can provide quite useful information for developers and testers during 
the testing/debugging phase.  These models can be divided into two main categories: 
analytical model and data-driven model [1, 2].  Analytical SRMs are proposed based on 
underlying assumptions about the nature of software faults, the stochastic behavior of the 
software processes and the development environments.  An essential example of such a 
model is Non-homogeneous Poisson Process (NHPP) SRM with a software failure density 
function.  But due to mathematical adaptabilities of stochastic processes, some certain prior 
assumptions made by the analytical models may not always be applicable in an actual 
software development environment and thus it has been shown that no single such model can 
obtain accurate predications across all different software projects [3-5].  On the contrary, the 
so-called data-driven models, borrowing heavily from artificial intelligence techniques, rely 
directly on the collected data describing input and output characteristics. Compared to 
analytical SRMs, data-driven models have much less unpractical assumptions and are much 
abler to make abstractions and generalizations of the software failure process.  In this 
research, Section 2 shows the proposed model framework and presents our methodology in 
detail. The experiments and results are presented in Section 3.  Finally, the conclusions are 
made in Section 4.   
II. Backgrounds and Methodology  
Support vector machine (SVM) [6] was introduced as a pattern classifier and it seeks to 
determine a separating hyperplane.  Separating hyperplanes can differ in how large a margin 
of separation.  For linearly separable training data there exists many hyperplanes that might 
classify the data.  One reasonable choice as the best hyperplane found by SVM is defined by 
the maximum margin of separation between any training point and the hyperplane.  Figure 1 
shows a simple example of this approach.  Suppose each data point of Figure 1 belongs to 
one of two classes, and the target is to decide which class a new data will be in.  Here, two 
hyperplanes (H1 and H2) are the margins of the classifier boundary and they separate balls 
from diamonds. The maximum-margin hyperplane (H0) is shown as a solid line.  Samples on 
the margin are called the support vectors because they define the decision boundary.   
.  
Fig. 1.  A simple example of a binary classsification problem. 
1H
2H
0H
  4 
GA is an efficient, parallel, and global optimal solution searching method based on the 
principle of the survival of the fittest.  During the process of solution searching, it attempts to 
retain genetic information from generation to generation, and finally approaches the global 
optimal solution. GA use chromosome to simulate biological evolution, each chromosome 
presents a candidate solution to a given problem; and each gene refers to a particular element 
of the candidate solution.  The GA processes populations of chromosomes in each generation.  
Each chromosome always requires a fitness value to evaluate its survival ability in the current 
population.  The fitness evaluation of a chromosome depends on how well that chromosome 
solves the problem at hand.  The higher the fitness value that it gets, the more survival ability 
it has.  So, the high-fitness valued candidate chromosomes should be retained and be 
combined to produce new offspring.  In general, offspring are generated by using operators 
analogous to biological processes.  Among these operators, crossover and mutation are the 
most basic and popular operators.  In the selection process, all chromosomes are evaluated 
using a fitness to determine whether the chromosomes are eliminated or retained.  GAs use 
crossover and mutation operations to evolve the solutions for an application.  A crossover 
operation tries to create better chromosomes by exchanging part genes of the fittest 
chromosomes.  Moreover, a mutation operation randomly changes some of the genes in a 
chromosome with a very small mutation rate. These steps of evolution are repeated until the 
specific termination conditions are satisfied.  The detail explanation for basic steps of SVM 
using GA is presented as follows. 
Phase I. Representation and initiation 
We use LIBSVM [10-12] to rain the SVM models. In this study, the parameter ranges are 
log2C{-5,…,15} and log2  {-15,…,3}.  According to the references [10-14] and our 
observations, the tuned values would cover a range of the parameter search space which can 
lead to a high validation accuracy. Since the tuning parameters (C and ) of SVM are usually 
real-valued numbers, we apply the floating point encoding method to express each 
chromosome.  In the initiation phase, the values of the initial chromosomes are generated by 
random bit stings.  Figure 3 gives this coded chromosome.  Furthermore, the initial 
population was composed of 100 randomly generated chromosomes.  The population size of 
100 was considered as a trade-off between the convergence time and the population diversity. 
 
    
bitsbits
parameterCparameter
19
1011010110111011000
21
100011001010101100101

 
Fig. 3.  Parameter coding in a chromosome. 
Phase II. Training and fitness evaluation 
After generating the initial population, the training dataset and the assigned value of each 
chromosome representing C and  and were used to train the SVM process.  The 
performance of each chromosome can be calculated through the fitness function for GA.  
The chromosome with a higher fitness  
value has a better chance to be preserved to the successive generations. In this research, the 
fitness value for each chromosome was calculated as follows: 
 
., 1
))((
1
2
MSEk
yxf
fitnessMSE
k
i
ii

 

 
 
where l is the number of training dataset; yi is the actual value, and f(xi) is the predicted value.  
From the measure of MSE, we can obtain quantitative comparisons for long-term predictions 
between actual and predicted values.  A lower MSE indicates better performance of fitting 
the real software data.  Therefore, the solution with a smaller MSE of the training data set 
has a higher fitness value and thus has a better chance of surviving in the next generation.  
Phase III. Genetic operation 
  6 
Comparison Criteria 
We adopt some evaluation criteria [3-5] in the comparison of goodness-of-fit of the models.  
The comparison criteria are described as follows:  
(1) The Squared Error (SE) is defined as : SE 2)ˆ( ii yy  .  
where  yi is the actual value and iyˆ  is the predicted value.  
 (2) The Mean Squared Error (MSE) is defined as :  
MSE 2)ˆ(
1
1
ii
n
mi
yy
mn


 
 , 
where m is the starting point and n is the end point in the prediction phase.  From the 
measure of MSE, we can obtain quantitative comparisons for long-term predictions between 
actual and predicted values.  A lower MSE indicates better performance of fitting the real 
software data.  
(3)The Relative Errors (RE) [3-5] is defined as:  
.
)(
Z
Z
z
tm
RE


   
Suppose Z failures were observed by the end of test time tz, we  
use the failure data up to time ti ( ztit  ) to estimate the parameters of m(t).  Moreover, a 
lower absolute value of RE indicates better performance of fitting the real software data.  
(4) The Mean of Relative Errors (MRE) is defined as: .
1
)(1




l
t
t
z
t
Z
Z
z
tm
l
MRE
 
Note ti is the time when the observed i failure is detected and l is the cumulative number of 
detected faults after the test.  Besides, in order to check the predictive validity of the model, 
the procedure can be executed for various values of ti and the result can be shown by plotting 
the curve of the RE for different values of tz. 
SVM Training and Prediction Processes 
In software reliability modeling, suppose that xi is the cumulative number of failures in the 
software execution ti, we want to forecast xi+1 by use of (x1, x2,…,xi).  The data set is divided 
into two parts: training and testing data set. The training data set is then fed into the SVM 
model and consequently the parameters which lead to the best accuracies are selected.   
Finally, the obtained parameters are tested for the testing data set.  Here, two different 
architectures are applied. 
Recent failure data with sliding window size k:  
In this approach, we consider the reliability assessment problem over software failure data 
streams, with respect to the recent k data elements seen so far.  The architecture is shown in 
Figure 4.  The training model can refect the mapping of input and ouput of this process by 
learning a set of training data pairs, {(xj, xj+1)}, where the observed data is within the sliding 
window.  In Figure 4 (a), the input (xi-k ,xi-k+1,…,xi-1) is fed into SVM model, and the 
corresponding target value is (xi-k+1 ,xi-k+2,…,xi).  After the trainging process, the SVM model 
has learnt the inherent internal correspondence of the software failure process between these 
above two vectors [2, 13, 16].  Therefore, a given input value xi, the predicted value ixˆ  can 
be obtained, as illustrated in Figure 4 (b).  Furthermore, when each new data element is 
arrived, the traing and prediction processes of SVM model are performed alternately.  For 
example, if the (i+1)th data element is gathered, the model could be trained again with new 
input vector (xi-k+1 ,xi-k+2,…,xi) and target vector (xi-k+2 ,xi-k+3,…,xi+1), and then the trained 
model can be used to forecast the predicted value of 2ˆ ix ..  In this approach, we know that 
not all available failure data is used, only the data elements in the siliding window seen so far 
are relevant.   This could be due to the instinctive phenomenon that early failure behavior of 
the testing process may have less impact on the later failure process [2].   
  8 
TABLE I. COMPARISON RESULTS 
Data [15] Recent failure data with 
window size w =4 
Total Recently failure data 
with  window size w =1 
week ix  ixˆ  RE SE ixˆ  RE SE 
1 
2 
3 
4 
5 
6 
7 
8 
9 
10 
11 
12 
13 
14 
15 
16 
17 
18 
19 
20 
21 
2 
2 
2 
3 
4 
6 
7 
16 
29 
31 
42 
44 
55 
69 
87 
99 
111 
126 
132 
135 
136 
 
 
 
 
 
4.4986 
6.9991 
8.4975 
29.0596 
30.9923 
41.9492 
43.9645 
50.6667 
69.0393 
86.9903 
98.9905 
111.0162 
125.9892 
132.0138 
135.0001 
136.0084 
 
 
 
 
 
0.2502 
0.0001 
0.4689 
0.0021 
0.0002 
0.0012 
0.0008 
0.0788 
0.0006 
0.0001 
0.0001 
0.0001 
0.0001 
0.0001 
0 
0.0001 
 
 
 
 
 
2.25 
0.00 
56.29 
0.00 
0.00 
0.00 
0.00 
18.78 
0.00 
0.00 
0.00 
0.00 
0.00 
0.00 
0.00 
0.00 
 
 
 
 
 
4.4976 
6.999 
8.7488 
29.0092 
30.9568 
41.719 
44.0003 
50.18 
68.9678 
87 
98.9404 
110.9993 
125.9995 
131.9995 
135.0006 
136 
 
 
 
 
 
0.2504 
0.0001 
0.4532 
0.0003 
0.0014 
0.0067 
0 
0.0876 
0.0005 
0 
0.0006 
0 
0 
0 
0 
0 
 
 
 
 
 
2.26 
0.00 
52.58 
0.00 
0.00 
0.00 
0.00 
23.23 
0.00 
0.00 
0.00 
0.00 
0.00 
0.00 
0.00 
0.00 
TABLE II. COMPARISON RESULTS FOR MRE & MSE 
 
Recent failure data with 
window size w =4 
Total Recently failure data with  
window size w =1 
MRE MSE 
MRE MSE 
Data [15] (from 6th to 21th) 0.0502 4.83 0.0501 4.88 
V. References 
[1] Q. P Hu, Y. S. Dai, M. Xie and S. H. Ng.,”Early software reliability prediction with extended ANN model,” Proceedings of the 30th 
Annual International Computer Software and Applications Conferencde (COMPSAC’06), Vol. 2, pp. 234-239, Setpember 2006. 
[2] Bo. Yang, Xiang. Li, “A study on software reliability prediction based on support vector machines”, The Annual IEEE International 
Conference on Industrial Engineering and Engineering Management, pp. 1176-1180, 2-4 Dec. 2007. 
[3] Musa, J. D., Iannino, A., Okumoto, K.: Software Reliability, Measurement, Prediction and Application. McGraw-Hill (1987) 
[4] Musa, J. D.: Software Reliability Engineering: More Reliable Software, Faster Development and Testing. McGraw-Hill (1998). 
[5] Lyu, M. R.: Handbook of Software Reliability Engineering. McGraw-Hill (1996) 
[6] V. Vapnik, The Nature of Statistical Learning Theory, New York: Springer-Verlag, 1995. 
[7] S.A. Rojas and D. Fernandez-Reyes, “Adapting multiple kernel parameters for support vector machines using genetic algorithms,” The 
2005 IEEE Congress on Evolutionary Computation, vol. 1, pp. 626-631, September, 2005. 
[8] X. Liang and F. Liu, “Choosing multiple parameters for SVM based on genetic algorithm,” 6th International Conference on Signal 
Processing, vol. 1,pp. 117-119, August, 2002. 
[9] S. Liu, C. Y. Jia, and H. Ma, “A new weighted support vector machine with GA-based parameter selection,” Proceedings of 2005 
International Conference on Machine Learning and Cybernetics, vol. 7. pp. 4351-4355, August, 2005. 
[10] C. C. Chang and C. J. Lin, “LIBSVM: a library for support vector machines,” Department of Computer Science and Information 
Engineeirng, National Taiwan University,2001, Software available at http://www.csie.ntu.edu.tw/~cjlin/libsvm, 2001. 
[11] C. W. Hsu and C. J. Lin, “A Comparison of methods for multiclass support vector machines,” IEEE Trans. Neural Networks, vol. 13, 
pp. 415–425, March 2002. 
[12] C. W. Hsu, C. C. Chang and C. J. Lin, “A Practical Guide to Support Vector Classification,” Department of Computer Science and 
Information Engineeirng, National Taiwan University, Available at http://www.csie.ntu.edu.tw/~cjlin/papers/guide/guide.pdf, 2003. 
[13] P. F. Pai and W. C. Hong, “Software reliability forecasting by support vector machines with simulated annealing algorithms,” Journal 
of Systems and Software, vol. 79, no. 6, pp. 747-755, 2006. 
[14] M. S. Bazaraa and C. M. Shetty, Nonlinear Programming: Theory and Algorithm, John Wiley & Sons, 1993. 
[15] J. D. Musa, Software Reliability Data, Report and Data Base Available from Data and Analysis Center for Software, Rome Air 
Development Center (RADC). Rome, NY.292-296 May 1985 
[16] L. Tian and A. Noore, “Dynamic software reliability prediction: an approach based on support vector machines,” International Journal 
of Reliability, Quality and Safety Engineering, vol. 1w, no. 4, pp. 309-321,2005. 
 
 
 3 
3. 
500  
 5 
Antennas - Design, Modeling and Measurement Artificial Intelligence 
Microwave Circuits - Systems and Applications Bioinformatics 
Computational Electromagnetics Software Engineering 
Radio Propagations Parallel and Distributed Computing 
Integrated Optics B11: Technology in Education 
除了聽取每位演講者報告研究成果外，並參與各個 Session 的討論，報告人並於 8 月 3 日進行個人論文的發表，此次
發表的個人論文為口頭報告，在過程中獲得與會學者的熱烈迴響與討論，由於本論文是以支援向量機在軟體可靠度預測
上的應用，因此許多學者對支援向量機如何在軟體可靠度處理有興趣，報告人也逐一回答相關問題，收穫豐碩。另外
會議論文集已刊登在 IEEE 的電子論文集內，並提交 Ei Compendex, INSPEC 和 Thomson ISI。 
此次研討會主題涉及電子與資訊科技應用兩方面，主亞洲國家出席率逾半成。來自各國從事電機資訊科技研究的學者
藉此會議進行學術交流，並分享彼此的研究成果。會中聽取 Professor Wang Jun (IEEE Fellow,The Chinese 
University of Hong Kong)及 Fumitoshi Matsuno(Department of Mechanical Engineering and Science)兩位學者的學術
專題演講，穫益良多；也認識了不少知名學者。教師從事研究，常局限於單一思考的方向，若能與其它學者先進充份
討論交流，既能增進本身的知識，又可了解自身不足之處。參與學術研討會，不僅能將自己的研究成果發表，並獲取
他人建議，更有機會向他人學習，獲得自己本身並未考慮到的方向及知識，利用此次機會切磋心得，讓自己更上一層
樓。且站在台上向大家報告研究內容，更了解流利的外文能力對於溝通、聽講的重要性。參加這次會議讓我發現自己
的英語聽、說能力尚待加強，有了流利的語言溝通能力，才能在會議中得到更多、更清楚的資訊。此次會議提供一個
平台，供世界各地研究員，工程師，學者以及工業專業人士介紹他們的研究成果和電子計算機技術開發活動的機會。
透過此會議的思想和應用經驗交流，並可尋求全球合作夥伴的未來合作
會議結束後參觀京都古城及 Kyoto University 等大學
希望國科會能持續鼓勵學校教師出國參加國際會議，除了可以增廣見聞、提升語文及溝通能力，藉由此一研討會，還可
提高台灣及佛光大學的知名度，並發揚台灣在科技上的表現，一舉數得。由於與會人員來自世界各地，大家同時討論互相
請教，更能提供學者們不同的意見和思考模式，若是能盡量提供教師參與此類型的國際會議，必能增加教師的視野與看法，
將有助於增加教師的國際觀，以及更完整成熟的思考邏輯，便可激發出更大的研究創意，想法與能量。 
此次開會帶回大會議程、論文集光碟及 會議徵求論文啟事一份。
感謝國科會提供資助前往海外進行學術研討，對於學術生涯有相當大的助益，在此感謝國科會的大力支持。
The 2010 International Conference on Electronics and Information Engineering (ICEIE 2010) 
 
- 2 - 
ICEIE 2010 will check the format of all the registered papers first, so the authors don’t need to upload the paper to the 
IEEE. After the registration, we will send all qualified papers to the IEEE for publishing directly. 
If the above requirements are met by the set deadlines, the paper will be included in the ICEIE 2010 conference 
proceeding, and will be listed in the IEEE Xplore, and indexed by EI Compendex and Thomson ISI. 
Maybe some unforeseeable events could prevent a few authors not to attend the event to present their papers, so if you 
and your co-author(s) could not attend ICEIE 2010 to present your paper for some reasons, please inform us. And we 
will send you, the official receipt of registration fee, proceedings and/or other materials after ICEIE 2010 free of 
charge.  
Please strictly adhere to the format specified in the conference template while preparing your final paper. If you have 
any problem in preparing the final paper, please feel free to contact us via iceie@vip.163.com. For the most updated 
information on the conference, please check the conference website at http://www.iceie.org/.The Conference Program 
will be available at the website in Early July, 2010. 
Finally, we would like to further extend our congratulations to you and we are looking forward to meeting you in Kyoto, 
Japan! 
Yours sincerely, 
 
ICEIE 2010 Organizing Committees 
http://www.iceie.org/  
Kyoto, Japan 
國科會補助計畫衍生研發成果推廣資料表
日期:2011/10/31
國科會補助計畫
計畫名稱: 基於支援向量機及基因演算法的軟體可靠度評估之建構與分析
計畫主持人: 羅榮華
計畫編號: 99-2221-E-431-001- 學門領域: 程式語言與軟體工程
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
在本研究中，我們結合支援向量機的技術以及基因演算法搜尋近似最佳參數解
的能力進行軟體可靠度的預測。我們利用支援向量機方法來做預測，它已成功
的被使用在解決非線性迴歸和時間序列的問題。另外透過基因演算法 Genetic 
Algorithm (GA)的複製、交配與突變來搜尋支援向量機的參數值。實驗當中，
使用軟體錯誤歷史資料，並提出依比例選取資料、累計至目前的歷史資料以及
最近幾筆資料三個資料訓練型態來進行實驗，經由實驗結果得知我們提出的三
個資料訓練型態是可行的。另外在兩個實例與相關文獻比較下，本研究所提出
的方法有較佳的預測能力。 
對於參與本研究之研究及相關工作人員而言，參與本研究計畫使研究團隊成員
們均獲得了學習軟體可靠度模型之發展、建立、解析與評估的機會。並熟悉如
何運用適當的軟體工具(例如 Matlab)與軟體技術來進行可靠度數值模擬分析。
在研究成果的發表方面，本計畫除已將相關方法之應用內容投稿於 ICIEA2010、
ICECT2010 及 ICEIE2010 等國際研討會，並獲得接受且已完成發表之外﹔另外
同時並將研究成果逐年發表在 IEEE Trans. on Computers、IEEE Trans. on 
Reliability、IEEE Trans. on Software Engineering、Journal of Systems and 
Software 等國際性知名刊物及會議上，以增加本次研究成果的實用性，並使本
研究的貢獻和實際應用性更具體可見。整體而言，本原規劃為為期二年的計畫
在計畫第一年期間，不論是在理論整合運用、實際系統開發或論文發表上的質
與量進度表現，均已達成原設定之階段性目標。 
 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
