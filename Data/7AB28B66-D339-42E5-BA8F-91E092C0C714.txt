  I 
摘要 
多核心系統已經快速的成為一個新的應用程式執行平台，為了要更容易設計
適合多核心平台的程式，以利用其潛在的運算能力，我們將這個問題分成二個不
同的層級來討論解決辦法–應用程式的切割與平台的虛擬化，在應用程式方面，
我們主要著重於利用縱向與橫向的平行化來幫助程式的切割與排程。在平台層級
部分，主要的工作是進行多核心架構的虛擬，讓它表現出類似有著中央處理器與
硬體加速器的平台或是有著多個由不同核心組成的其他架構。在實際案例的討論
方面，我們採用了軟硬體架構協同需求較高的無線感測網路模擬器作為研究之對
像，來取代原本所提出的多媒體應用程式。 
Abstract 
Multi-core processors are fast emerging as a new class of platforms for applica-
tions. To realize their full potentials while enabling good programmability, we pro-
pose to divide the problems into application-level partitioning and platform-level vir-
tualization. At the application level, we choose to focus on partition and schedule ap-
plication by utilizing horizontal and vertical parallelism. At the platform level, the aim 
of this work is to virtualize the multi-core architecture so that it appears like CPU + 
accelerator structure to software presently, and it may appear as other architectures in 
the future. For case study, this work considers applications in the form of hard-
ware/software cosimulators for wireless sensing systems as a more fruitful alternative 
to multimedia as originally proposed. 
 
 
keyword： multi-core, computation/communication trade-off, partitioning, pipelining, 
dynamic programming, virtualization, simulator 
  1 
前言 
 Multi-core programming is essentially taking parallel computing to the chip 
level, and it has always been complex and difficult. The two approaches to parallel 
programming are shared memory and message passing. Shared memory programming 
is done typically in terms of threads such as POSIX or Windows threads, though they 
are not integrated with compilers or languages. OpenMP adds user-inserted directives 
to the compiler to annotate parallelism explicitly.  Problems with shared memory 
programming include the memory bottleneck and synchronization. On the other hand, 
message passing uses an explicit API for send and receive of messages over a network 
among tasks on different cores or the same core. This approach is scalable and effec-
tive of problem can be decomposed cleanly, but it is not always possible. When there 
are dependencies across core boundaries, then data needs to be replicated explicitly 
for efficient execution. Tracking such dependencies can be an error-prone problem. 
Efficient execution of applications on multi-core platforms requires a structured 
approach. This research work aims to make multi-core architectures both easier to 
program while executing efficiently. For execution efficiency, we develop optimiza-
tion algorithms for the partitioning and scheduling of application-level tasks on the 
cores and inter-core communication.  For programmability, we propose virtualization. 
That is, instead of programming the cores and scheduling the communication directly, 
we introduce a virtualization layer (in the OS sense) so that the programmer sees a 
different logical architecture that better matches the topology of the application. The 
virtualization layer will make a group of cores appear like a hardware accelerator. We 
divide the application into two parts: one part is application-specific algorithms, often 
executed on general-purpose processors, and the other part is system service, often 
executed on hardware accelerators.  The system service part can be implemented 
with real or virtual accelerators using a subset of the multiple cores. On one extreme, 
it enables today's software to be executed with little or no modification. Over time, as 
programming methodology advances, the virtualization layer can provide another ar-
chitecture on the same hardware for better support. If successful, the partitioning and 
virtualization will bring the two sides of the gap closer together. 
For case study, we chose simulators for wireless sensor networks as a fruitful al-
ternative to the original multimedia applications. WSN hardware and software offer 
also horizontal and vertical parallelisms, and they pose challenges in speedup due to 
the inherent use of the event queue. 
  3 
研究目的 
I. Scheduling and partitioning 
Scheduling and partitioning of tasks onto multiple processors with communica-
tion scheduling has been studied for embedded systems with multiple processors. Luo 
et al [1] considers periodic and aperiodic tasks for power reduction but do not consid-
er communication. Pop et al [2] performs scheduling to meet timing constraints while 
taking into bus access, though it assumes TDMA over a shared bus. Hu et al [3] tar-
gets a more general, heterogeneous network-on-chip (NoC) architecture consisting of 
n-by-n tiled, 2D mesh architecture, and it saves up to 44% power for multimedia ap-
plications. All of these problems and many others are NP-hard. Liu et al [4] formulat-
ed a problem that fits a pipelined architecture but with a shared bus rather than 
point-to-point connection. It has a polynomial-time optimal solution and actually fits 
the way we decompose the applications. The work has been extended [5] to combine 
data compression with functional partitioning and scheduling in the generalized dy-
namic programming formulation. The complexity is kept polynomial time, rather than 
NP-hard. We choose to focus on this approach as the basis of the partitioning algo-
rithm. 
II. Horizontal and Vertical Parallelism 
Now, we take wireless sensor network simulator as an application to show the 
mapping of thread to core. The scalable of the simulation network size is limited by 
the performance of the wireless sensor network simulator and the biggest performance 
bottleneck is synchronization. On a single-core computer, each simulation node is 
simulated serialized, and therefore communication to the other node need to be syn-
chronized. The synchronization overhead in the multi-core system is greater than that 
in the single-core system and becomes the most critical bottleneck of the simulator. In 
order to reduce the synchronization overhead, we need to decompose the simulation 
task into not only horizontal parallelism but also vertical parallelism.  Horizontal 
parallelism is further divided into coarse-grained parallelism with sensor nodes or 
base stations that run as peers, and fine-grained parallelism with hardware units on 
each sensor node running in parallel.  Vertical parallelism can also be divided into 
coarse-grained phases of events and fine-grained frames of processing. 
  5 
文獻探討 
ATEMU [6] uses a cycle-by-cycle strategy to run application code. The code is 
binary compatible with the MICA2 platform. That is done through emulation of the 
AVR CPU used by MICA. ATEMU offers an accurate emulation model in which each 
MICA mote can run different application code.  
The cycle-by-cycle implementation strategy achieves synchronization for free 
but scales poorly, as each device adds work to be done each clock cycle. ATEMU only 
runs accurately with up to 120 nodes. Aside from the overhead involved in decoding 
instruction-by-instruction, ATEMU also suffers the same overhead as object-oriented 
models. One radio transmission can affect every other node in the network, creating 
an O(n
2
) algorithm. Despite the scalability problems, ATEMU is one of the most ac-
curate sensor simulators available.[8] 
TOSSIM [9] is designed specifically for TinyOS applications to be run on MICA 
Motes. The developers had four key concepts in mind when creating TOSSIM: scala-
bility (the system should be able to handle thousands of nodes with different network 
configurations), completeness (as many system interactions as possible must be cov-
ered in order to accurately capture behavior), fidelity (subtle interactions must be 
captured if testing is to be accurate), and bridging (validating the implementation of 
algorithms). 
In order to achieve its goal of scalability, each node in the simulator is connected 
in a directed graph where each edge has a probabilistic bit error. For perfect transmis-
sion, the bit error is 0, and can be changed for different situations. Also in the name of 
efficiency, every node in TOSSIM runs the same application code; all nodes are iden-
tical. The goal of scalability is successfully achieved, results show it be able to handle 
larger networks than almost any other simulator or emulator. However, TOSSIM loses 
the fine-grained timing and interrupt properties of the code that can be important 
when the application runs on the hardware and interacts with other nodes. 
 Avrora [7] is an emulator implemented in Java. Similar to many of the ob-
ject-oriented simulators, Avrora implements each node as its own thread. Like 
ATEMU, Avrora runs code in an instruction-by-instruction fashion. However, the 
simulator attempts to achieve better scalability and speed by not synchronizing all 
nodes after every instruction. 
  7 
研究方法 
Our technical approach is both top-down and bottom-up. The top-down part, 
written in our original proposal, is the partitioning of the application-specific algo-
rithm onto a multi-core architecture. The bottom-part, which is newly added and not 
in the original proposal, is to build up the virtualization layer. It is meant to bring do-
main-specific solutions into a hardware accelerator structure, so that the general pur-
pose processors can take advantage of them without drastic changes to the program-
ming model. 
I. Scheduling and Partitioning 
We make the assumption that the application code has more thread-level paral-
lelism and can be allocated to a number of cores, as limited by the memory bandwidth.  
We assume that the accelerators do not have much thread-level parallelism. Instead, 
they will rely on pipelining at different granularity levels. For instance, each SPE 
(Synergistic Processing Element) in the IBM Cell processors [20] supports fi-
ne-grained, instruction-level pipelining, and multiple SPEs can be composed as a 
pipeline at the task level.  
The mcLSI case study is currently under way. The algorithms are open source. 
This work represents a collaboration effort with biomedical engineering at UC Irvine 
(collaborator: Bernard Choi) 
II. Horizontal and Vertical Parallelism 
Horizontal parallelism refers to inherently parallel hardware units, whether they 
are coarse-grained systems such as sensor nodes, base stations, or computers; or fi-
ne-grained hardware component inside one such system, such as MCU, RF, sensor, 
ADCs, storage device, or accelerator units.  However, horizontal parallelisms are 
inherently limited by the need to synchronize both within the system and among sys-
tems. Although many speculative execution techniques with checkpoint-and-rollback 
have been proposed, they are effective only if the dependency is loose.  For tight 
dependency, the synchronization overhead dominates. 
  9 
System virtualization can be done in a manner entirely transparent to the guest 
OS (i.e., pure virtualization, as in QEMU [10], VirtualBox [13], VMWare [15]), or in 
cooperation with the guest OS, (i.e., para-virtualization, as in Xen [14]). Both tech-
niques have several advantages and disadvantages. Primarily, pure virtualization can 
support unmodified OSs, but can suffer performance loss when the OS makes as-
sumptions about the hardware that are invalid for virtualized resources [14]. Pa-
ra-virtualization eliminates these assumptions, but sometimes requires significant 
modifications to the guest OSs and the hardware/software interface. In addition, there 
are many cases where para-virtualization is inapplicable or unnecessary, such as when 
supporting legacy software. It is hard to predict which particular approach — pure or 
para — if not both, will survive, given the diverse application domain for virtualiza-
tion [19]. 
The extension we make is to make not only additional virtual instances of the 
cores but actually create the appearance of hardware accelerators from groups, or is-
lands, of cores in addition to the general-purpose cores. The virtual machine thus 
needs the ability to take advantage of the parallelism available, and the accelerator 
functionality may be coded manually using domain-specific and architecture-specific 
knowledge so that it is fully optimized. The other code can then take advantage of the 
island as a blackbox.  However, one key question is how to divide the cores between 
those for the application execution and those that emulate hardware accelerators. To-
day's SMPs assume shared memory.  One major problem is the memory bottleneck. 
Memory is already slow for one core and one thread. Having multiple cores or threads 
accessing the same memory region or interface will overwhelm the already slow 
memory interface. In fact, the instructions per cycle as the number of cores increase 
may flatten out beyond two or three.  Therefore, it is important to allocate just the 
right number of cores to either the main processor or the emulated accelerators, or 
else it becomes counterproductive. 
A many-core architecture inherently follows message passing, but virtualization 
brings it back to a more shared-memory model. Therefore, one possible modification 
to future many-core architectures will be to study the addition of shared-memory con-
trollers that will help virtualization of few-core or accelerator-based architectures that 
rely on shared memory. 
  11 
參考文獻 
[1] J. Luo and N. K. Jha, "Power-Conscious Joint Scheduling of Periodic Task Gra-
phis and Aperiodic Tasks in Distributed Real-Time Embedded Systems," in Proc. 
ICCAD, Nov. 2000. 
[2] Paul Pop, Petru Eles, Zebo Peng, "Bus Access Optimization for Distributed Em-
bedded Systems Based on Schedulability Analysis," in Proc. DATE 2000. 
[3] Jingcao Hu, Radu Marculescu, "Energy-Aware Communication and Task Sched-
uling for Network-on-Chip Architectures under Real-Time Constraints,", in Proc. 
Design Automation and Test in Europe Conference, Paris, France, Feruary 2004. 
[4] Jinfeng Liu, Pai H. Chou, "Combined Functional Partitioning and Communica-
tion Speed Selection for Networked Voltage-Scalable Processor,", in Proc. ISSS, 
2002. Pp. 14-19. 
[5] Jinfeng Liu and Pai H. Chou, Energy Optimization of Distributed Embedded 
Processors by Combined Data Compression and Functional Partitioning, in Proc. 
International Conference on Computer-Aided Design (ICCAD), November 9-13, 
2003. pp.201--208. 
[6] J. Polley, D. Blazakis, J. McGee, D. Rusk, and J.S. Baras, ―ATEMU: a fi-
ne-grained sensor network simulator,‖ Sensor and Ad Hoc Communications and 
Networks, 2004. IEEE SECON 2004. 2004 First Annual IEEE Communications 
Society Conference on, 2004, pp. 145-152. 
[7] B.L. Titzer, D.K. Lee, and J. Palsberg, ―Avrora: scalable sensor network simula-
tion with precise timing,‖ Proceedings of the 4th international symposium on In-
formation processing in sensor networks, Los Angeles, California: IEEE Press, 
2005, pp. 67. 
[8] D. Curren, ―A Survey of Simulation in Sensor Networks,‖ University of Bing-
hamton. 
[9] P. Levis, N. Lee, M. Welsh, and D. Culler, ―TOSSIM: accurate and scalable sim-
ulation of entire TinyOS applications,‖ Proceedings of the 1st international con-
ference on Embedded networked sensor systems, Los Angeles, California, USA: 
ACM, 2003, pp. 126-137. 
[10] F. Bellard, ―QEMU, a fast and portable dynamic translator,‖ Proceedings of the 
annual conference on USENIX Annual Technical Conference, 2005, pp. 41-41 
[11] F. Bellard, KQEMU, http://fabrice.bellard.free.fr/qemu/kqemu-tech.html 
[12] Qumranet Inc, KVM, http://kvm.qumranet.com/ 
[13] SUN xVM. VirtualBox, http://www.virtualbox.org/ 
國科會補助專題研究計畫項下出席國際學術會議心得報告 
                                   日期：   年   月   日 
                                 
一、參加會議經過 
IEEE SECON conference 是由 IEEE INFOCOM conference 於 2004延伸出來，目的是為了增加與
Sensor, Mesh and Ad Hoc Communications Networks 相關之重要研究議題的討論。第七屆的 SECON 
conference 提供一個良好的討論平台，讓各個研究學者交換他們在 Sensor, Mesh and Ad Hoc 
Communications Networks 領域相關的嶄新的研究及經驗。 
這次會議徵求的議題包括： 
• Vehicular Networks, Underwater Networks, Urban Sensing, and other Emerging Areas 
• Measurements and Experimental Research  
• Security 
• Survivability, Network Management and Fault Tolerance 
• Modeling, Algorithms, and Performance Evaluation 
• Hardware and Software Platforms, Middleware 
計畫編號 NSC 98-2220-E-007 - 006 – 
計畫名稱 
前瞻異質多核心系統開發工具研發 
子計畫五：多媒體應用之軟硬體共同設計於多核心架構 
出國人員
姓名 
杜依璇 
服務機構
及職稱 
國立清華大學 
會議時間 
99年 6月 20日至 
99年 6月 25日 
會議地點 美國波士頓 
會議名稱 
(中文)  
(英文) IEEE SECON 2010 
發表論文
題目 
(中文) EcoExec: 微型無線感測平台上之高互動執行框架 
(英文) EcoExec: An Interactive Execution Framework for Ultra Compact 
Wireless Sensor Nodes  
platform，透過與各國人士的交流，獲得寶貴的經驗。 
 
二、與會心得 
很開心以很榮幸能在碩士生涯中，就能投上國際conference的paper。這次參加SECON conference，
獲得很多寶貴的經驗，尤其這次我必頇負責上台報告我們的paper，全程必頇以英文再來自各地的研
究學者面前報告及回答問題，對我來說是個既緊張又特別的經驗，也是很好的學習。 
 
感謝我的指導教授周百祥老師，從paper開始撰寫投稿時，就給予許多的協助及建議；在準備
presentation的投影片及練習時，也不斷的給我指導。也很感謝會議中各其他學者提供的意見，讓我
從中成長不少。 
 
三、考察參觀活動(無是項活動者略) 
無 
 
四、建議 
 無 
 
五、攜回資料名稱及內容 
 SECON Final Book 
 會議中所有的發表論文 
 
六、其他 
 無 
 
98年度專題研究計畫研究成果彙整表 
計畫主持人：周百祥 計畫編號：98-2220-E-007-006- 
計畫名稱：前瞻異質多核心系統開發工具研發--子計畫五：多媒體應用之軟硬體共同設計於多核心架
構(3/3) 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 5 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 1 0 100% 
篇 
EcoExec: An 
Interactive 
Execution 
Framework for 
Ultra Compact 
Wireless Sensor 
Nodes 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
 
