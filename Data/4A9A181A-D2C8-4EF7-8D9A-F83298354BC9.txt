 1
行政院國家科學委員會補助專題研究計畫 結案成果報告 
用於居家看護之自動視訊影像監控系統的研究與開發 
Automated video surveillance for home-care and health-care monitoring:  
foreground segmentation, motion representation and activity recognition 
 
   計畫編號：NSC 96-2221-E-155-009-MY3 
執行期限：96 年 8 月 1 日至 99 年 7 月 31 日 
主持人：蔡篤銘   元智大學工業工程與管理系 教授 
 
一. 中文摘要(關鍵詞：機器視覺，動態影像
分析，視訊監控，居家看護，前景分離，
行為辨識) 
 
由於臺灣已步入一個高齡化社會，因此
老人對健康醫療以及居住安養之需求也日
漸重要。老年照護可分醫療機構照護、輔助
生活社區照護以及居家照護，不論那種類型
照護，在人力不足，或老年人獨自發生意外
而無法立即警示時往往會造成不可挽救之
結果。本研究將利用機器視覺之技術開發自
動 視 訊 監 控 系 統 （ Automated video 
surveillance ） 並 著 重 於 居 家 看 護
（Home-care）與醫療看護（Health-care）之
應用，希望藉由此系統監控老者在日常居家
或看護期間之活動以及行為模式（Activity 
and behavior recognition），而能自動辨識異
常之事件。 
傳統人體活動辨識之研究大多集中於
利用動態影像分析之技術於特定人體姿勢
（如走路，跑步，跌倒，手勢（Gestures），
步態（Gait）之辨識），並且採用微觀（Micro 
view）之策略將人體分解成細節部位再進行
分析，而本研究所面臨之居家看護活動類別
眾多且異常事件無法事先逐一描述，因此將
採用巨觀（Marco view）之策略直接描述移
動主體在時間與空間所構成之維度中的變
化。在視覺技術開發上，將以往在製造環境
之靜態影像的瑕疵/異常檢測技術延伸至服
務業環境之動態影像的異常行為偵測。 
 在第一階段(第一年)中，本計劃進行移
動 主 體 的 前 景 分 離 （ Foreground 
segmentation），透過多張時序影像所構成之
灰階紋路特性，提出統計管制界限為基礎之
前景分割方法，依照多張時序影像之平均值
與變異數變化情形，將超出管制界限之前景
分割出來，具有偵測靜止不動前景的能力以
及不受背景改變的干擾，且計算快速。本計
劃之兩種前景分割方法皆不需要建立任何
參考背景影像，能有效解決背景變異之問
題，但又能同時分離移動主體之完整形狀。 
在第二階段(第二年)中，本計劃進行動
態人體活動之表達：由第一階段於每張影像
所分離之移動主體，探討此主體在時間-空
間維度中的最佳表達方式（Time-spatial 
representa -tion），並由此表達方式中設計能
有效區分動作/行為差異的特徵指標，作為
各種行為模式之分類依據，即可進行活動/
行為之分類以及異常事件的判別。 
在第三階段(第三年)中，本計劃開發動
作/行為之分類方法：藉由第二階段所設計
之時間-空間表達方式以及特徵指標，針對
居家看護環境之活動及行為模式特性，設計
能有效辨識異常事件的學習機制以及分類
器（Classifiers），實驗結果顯示巨觀模式下
的行為表達方法與正常行為模型的訓練，透
1. 不需要將主體進行細部分解，可節省大
量影像處理的計算時間，也較不易受前
景分割（主體形狀）不完整或環境雜訊
之干擾。 
2. 除特定事先定義之異常動作外，隨觀察
及學習時間的增加，可偵測未事先（或
無法事先）定義但卻明顯違反正常（規
律而重複）生活之事件。 
 
本計劃將分三年三階段完成用於居家
及看護環境之自動視訊監控系統之雛形。就
動態影像分析技術之開發而言，第一年（第
一階段）將著重於人體前景區域自背景影像
中分離（Foreground segmentation）的技術
開發。本研究所使用之監控攝影機為固定式
（Still camera），由於居家及看護場景常會有
背景物（例如椅子、書報等）被移動之情形、
或有照明燈光開關、窗簾開關之問題，將採
用不需參考背景影像（Background template）
的時序差異（Temporal differencing）的策
略，但不同於傳統時序差異法因只考慮連續
兩張影像中移動主體之差異而只能分離主
體部分不完整的邊緣資訊，本研究將採用創
新之傅立葉轉換技術解決背景物體移動
（Non-stationary background objects）之問題
但同時能萃取完整移動主體的形狀。 
本研究第二年（第二階段）將利用第一
階段在視訊影像中所萃取之一系列前景主
體，將其在時間與空間維度上的變化設計有
效 的 時 - 空 表 達 方 式 （ Time-spatial 
representation）並由此表達方式中擷取代表
各種人體活動或行為的特徵指標組合。 
第三年（第三階段）的研究則利用第二
階段對於動態動作所設計的時-空表達方式
及特徵指標進行分類辨識（Classification）
的工作。由於居家看護之活動繁多且有些異
常事件無法逐一事先描述，因此分類之方式
將使用 Fuzzy C-means（FCM）之叢集
（Clustering）技術，以有效達成人體活動及
行為模式分類的目標。 
 
三、研究方法 
  
 本節將分別介紹計畫中各階段針對自
動視訊影像監控系統所開發之演算法。3.1
節將描述第一年提出之前景分割方法：統計
管制界限(SPC)為基礎之時序差異(Temporal 
difference)前景分割方法；3.2 節則描述第二
年使用第一階段在視訊影像中所萃取之一
系列前景主體，將其在時間與空間維度上的
變 化 設 計 有 效 的 時 - 空 表 達 方 式
（Time-spatial representation）並由此表達方
式中擷取代表各種人體活動或行為的特徵
指標組合；3.3 節說明第三年以 FCM 為基礎
之遞迴(recursive)FCM 行為分群及異常行為
偵測方法。 
 
3.1 統計管制界限之前景分割方法 
假設由 張N CR× 影像堆疊成 CRN ×× 時
間序列影像 ( )yxft ,
個樣本點，其中
，在每個像素點位置皆
代表在空間位有
置
N ( )yxft ,( )y
,,K
x,
,1
之 第 t 張 影 像 的 灰 階 值 ，
Rx 2= 、 C
Nt ,
y ,1= ,K,2 、
,2,1 K= ，當時間為 1−t 時，可透過式
每個 值(1)與式 (2)求出 像素位置的平均
( )yx,1−tμ 與標準差 ( )yxt ,1−σ 來表示灰階值的分
佈情形，如式(1)與式(2)： 
( )
 
( )yxS
N
yx tt ,
1, 11 −− =μ       (1) 
( ) ( )[ ] [ ]{ }( )yx, 2
(2) ( ) ( )yxyxS
N
fEyxfEyx
tt
ttt
,,1
,,
2
1
2
1
1
2
1
2
1
−−
−−−
−⋅=
−=
μ
σ
 (3) ( ) ( ) ( )yxyxfyxS N
i
itt ,,,,
1
1 ∀=∑
=
−−
 3
energy）來表示，即在目前時間為T (或第T
張影像)之時序影像中的動態能量圖(Motion 
energy map)可表示為 ( )yxET , 為 
 ( ) ( ) α⋅+= y x,EMy x,E 1-TTT        (8) 
其中α 為動態能量遞減率， 10 ≤< α  
( ) ( )
⎩⎨
⎧ ==
otherwise0
1if
,  
x, y B,  T
x, yM TenergyT
 
圖 2 是各種正常行為的連續序列影
像，以及其所對應之動態能量圖，圖
2(a1)~(a4)為走路之時序影像，圖 2(a5)則為
走路行為對應之動態能量圖，一開始主體位
於圖 2(a1)
於 2(b1)~(b4) 2(a1)~(a4)
2(b5)
2(c1)~(c4)
2(e1)~(e4) (f1)~(f4)
訊，而人數與行為的往返情形也會造成彼此
的時間觀
察， 如小偷闖入偷竊、搬家甚至與搶匪鬥
及異常事件的判別，本
究提出下列 12 種特徵指標(標示為 )來描
矩量
(mom
近所
，而且對
7 種不變矩量特徵之
左下角朝著右上角門口前進，由
於走路行為停留的時間較短，加上能量會隨
著式(8)遞減，因此當主體走到圖 2(a4)右上
角時，動態能量圖之左下角位置的能量已經
趨近 0，而圖 則是與圖
相反方向之走路行為，圖 為所對應之
動態能量圖，由於方向相反，因此右上角為
主體一開始的位置，隨著主體移動到左下角
時，動態能量圖之右上角能量也比左下角
低，說明了行為的前後順序會構成不同的動
態能量圖；圖 則是多人在畫面中
的複雜行為以及動態能量圖，動態能量較高
的部分是因為隨著三位同學的聚集討論所
構成，說明在多人模式之下，動態能量圖不
需進行人數的計算或分割，可同時保留所有
行為所產生之能量；圖 2(d1)~(d4)為長時間
坐在位子上的行為，說明雖然坐在位子的移
動不大，但會隨著時間逐漸累積，可代表行
為停留的時間；圖 、 則表
現出在固定區域內來回往返時會累積較高
的能量，這說明了依照行為往返的程度會構
成不同的動態能量圖。由上述動態能量圖發
現縱使行為相同但方向相反之能量變化會
有所不同，因此動態能量圖還包含著方向資
的差異，此動態能量圖應是一個有效表達連
續動作在 x-y-t 時空關係的方法，也表現出
各種正常行為模式之間的差異性相當大，造
成異常行為偵測的困難度提高。 
 
行為模式透過動態能量圖的表達方法可應
用在觀察時間較長的表達，因為動態能量圖
之好處在於不用設定觀察之時間間隔，而且
異常行為的發生往往需要較長
例
毆等行為。接下來將藉由動態能量圖表達方
法，設計相關動態活動特徵指標 (Motion 
features)，以作為判別活動類別以及是否為
異常事件之依據。 
 
3.3 行為特徵萃取 (Feature extraction) 
為了有效分辨出不同行為所形成的動
態能量圖，必須設計出具有代表性的特徵值
來進行行為之分類以
研
述不同的動態能量圖  ：7 個不變
ent invariant)、熵(entropy)、最大能量、
能量加總、能量面積、能量平均。  
首 先 七 個 不 變 矩 量 特 徵 指 標
( 71 ~ CC )(Hu, 1962)此組不變矩量不受平
移、旋轉及大小比例改變的影響，因此可避
免前景主體之行為在不同位置出現所造成
的平移差異，以及移動主體距離鏡頭遠
造成的大小比例差異，不過要注意的是這些
不變矩量並不足以區別所有的行為
雜訊很敏感。除了上述
外 ， 本 研 究 還 提 出 下 列 五 種 特 徵
( 128 ~ CC )，並且說明在不同的行為模式之
間特徵指標的意義。 
動態能量圖的熵(Entropy, 8C )，當動態
影像中行為越複雜時，能量的變化程度也越
大，因此透過熵來描述行為的複雜程度，而
熵的計算方式如式(9)，其中 ip 為在動態能
 5
迴(recursive)FCM 分群法，能夠透過遞迴的
方式增加分群的數量，以區隔出各種正常行
為之群集。在初始分群時，先設定C 組群集
數量，當正常行為訓練流程每遞迴一次
FCM 分群時，會增加C 組正常行為之群聚
中心，直到所有訓練樣本與其歸屬之中心距
離皆小於實驗所設定之臨界值，因此能達到
自動決定分類數量的效果。 
 
3.4.1 遞迴(recursive)FCM 分群法 
 
由於各種正常行為之種類繁多, 無法
事先定義行為之數量, 因此遞迴 FCM 分群
法的主要概念是透過每次遞迴逐漸增加群
集數, 來找到一最佳分群結果, 當收集到之
正常行樣本 { }KxxxX ,,, 21 K=  共有 K 筆資
料, 且 iv 代表著第 i 個群集之中心。可計算
其 樣 本 與 所 屬 群 集 中 心 之 距 離
( ) 2, ikikd vxvx −= 。遞迴 FCM 分群法之
目標式及限制式可定義如下 
 
Min β  
s.t. ( )
ii ddik
d σβμ ⋅+≤vx ,  
 
其中 
id
μ 與
id
σ 代表著樣本與所歸屬群集中
心之距離 ( )id k vx , 的平均值與標準差, 而 β
代表著管制界限之參數. 限制式
idid
σβμ ⋅+
同時可作為每個個別群集之管制界限 dT i 。 
因此若 FCM 分群結果完成, 代表所有收集
之正常行為樣本皆可歸屬至最近的群集之
中, 所有訓練樣本皆能符合所屬群集之限
制式, 並且具有最小的管制界限參數β 。而
管制界限之參數 β 越小, 則每
由於一開始無法
始群集數(本
劃 C=10), 以及設定較寬鬆之
個群集之管
制界限越小, 代表每個行為群集的界限越
明確。 
得知正常行為樣本之
合理群集數, 先設定 C 作為起
計 β ( 3=β ) 
作為初始管制參數 傳統 FCM 之分
群步驟, 初始分群結果之後可透過上
之管制界線進行分群, 若有樣本仍落於
限 , 
至另外C組群集之中, 直到所有樣本皆歸屬
, 此
管制界 之外 則進行第二次遞迴 FCM 之
分群, 將超出管制界限之樣本, 再重新分群
於其分群中心並符合管制界限之限制
時所有之分群結果則代表正常行為之群集
中心。而管制界限 β 設定越小,也會分成越
多的群集數, 因此接下來為了找出最合適
之群集管制界限, 在總分群數不超過 maxC
前提下, 必須找出最小管制界限之參數 β , 
透過逐步降低參數 β , 並重新進行遞迴分
群之步驟, 直到所有樣本符合參數 β 之管
制界限且不超過 群集數, 
，針對模擬小偷、搬家、
種異常行為 測，皆能正確即時發
max
正常行為樣本之訓練 , 本計劃設定為
maxC =60, 可依照不同環境之複雜度而調
整。 
 
3.4.2 異常行為偵測(Classification) 
當正常影像之訓練結束後，所得到之每
個群集中心代表著各種日常生活中的正常
行為模式，因此可觀察動態時序影像中的主
體活動時所累積的動態能量圖與正常行為
群集中心的距離，若為日常生活常見之行為
模式，應可歸屬於正常行為群集之中，當環
境中出現無法歸屬之動態能量圖時，便可判
斷為該行為模式不屬於日常生活中所常見
的異常行為。本研究連續收集兩天之實驗
日常生活行為，假設實驗室的正常行為模式
主要是由這些行為所組成，並隨機抽樣出其
中 15%的動態能量圖作為訓練樣本( ,030
筆)，進行行為模式分類器的訓練，在此訓
練樣本之下，本研究所提出之訓練方法自動
出 50 群的正常行為類別，以此 50 群正
常行為
C
進
則代表完成
1
打架以及暈
偵
室
5
測結
訓練
四
果。
倒 行偵
出警報，如圖 4 為四種異常事件之
 
 
四、實驗結果與討論 
 
為了瞭解本研究提出之異常行為偵測
結果在長時間的實際應用情形，以及當環境
中誤判產生時，更新群集中心的策略是否會
影響異常行為偵測的效果，因此本研究連續
, 並進行
找出
述
 7
 9
1763-1770. 
 A. C. Berg, G. Mori, J. M
action at a distance, in: Proc. Intl. 
 W. E. L. Grimson, Learning patterns 
ticulated objects using 
 
esentation an
p. 928-934. 
. 
3 
ng a sparse Bayesian classifier, in: 
 
 D. Jepson, 
Vol. 2, 1999, pp. 246-252. 
scene activity: a review, Image and Vision 
Computing 21 (2003) 125-136. 
[6] N. V. Boulgouris, Z. X. Chi, Human gait 
recognition based on matching of body 
components, Pattern Recognition 40 (2007) 
[7] A. A. Efros,
Recognizing 
alik, 
Conf. on Computer Vision, 2003, pp. 726-733. 
[8] T. W. Liao, Clustering of time series data - a 
survey, Pattern Recognition 38 (2005) 
1857-1874. 
[9] C Stauffer,
of activity using real-time tracking, IEEE Trans. 
Pattern Anal. Machine Intell. 22 (2000) 747-757. 
[10] M. Black, A. Jepson, Eigentracking: robust 
matching and tracking of ar
a view-based representation, International Journal 
of Computer Vision 26 (1996) 63-84. 
[11] M. M. Rahman, S. Ishikawa, Human motion
recognition using an eigenspace, Pattern 
Recognition Letters 26 (2005) 687-697. 
[12] J. Davis, A. Bobick, The repr d 
recognition of human movement using temporal 
templates, in: Proc. Conf. on Computer Vision 
and Pattern Recognition, 1997, p
[13] A. F. Bobick, J. W. Davis, The recognition of 
human movement using temporal templates, 
IEEE Trans. Pattern Anal. Machine Intell. 23 
(2001) 257-267
[14] G. R. Bradski, J. W. Davis, Motion segmentation 
and pose recognition with motion history 
gradients, Machine Vision and Applications 1
(2002) 174-184. 
[15] S.-F. Wong, R. Cipolla, Continuous gesture 
recognition usi
Proc. International Conference on Pattern 
Recognition, Vol. 1, 2006, pp. 1084-1087. 
[16] C. Shan, Y. Wei, X. Qiu, T. Tan, Gesture
recognition using temporal template based 
trajectories, in: Proc. International Conference on 
Pattern Recognition, Vol. 3, 2004, pp. 954-957. 
[17] D. J. Fleet, M. J. Black, Y. Yacoob, A.
Design and use of linear models for image motion 
analysis, International Journal of Computer 
Vision 36 (2000) 171-193. 
[18] H. Zhong, J. Shi, M. Visontai, Detecting unusual 
activity in video, in: Proc. Conference on 
Computer Vision and Pattern Recognition, Vol. 2, 
2004, pp. 819-826. 
[19] C. Stauffer, W. E. L. Grimson, Adaptive 
background mixture models for real-time tracking, 
In: Proc. IEEE Conference on Computer Vision 
and Pattern Recog., 
[20] BEHAVE Interactions Test Case Scenarios, Univ. 
of Edinburgh 2007, available online: 
http://groups.inf.ed.ac.uk/vision/BEHAVEDATA
/INTERACTIONS/ 
Fuzzy 
n 
 Journal on Advances 
e unusual event detection in 
[21] M. K. Hu, Visual pattern recognition by moment 
invariants, IRE Trans. Info. Theory IT-8 (1962) 
179-187.  
[22] J. C. Bezdek, Pattern Recognition with 
Objective Function Algorithms, Kluwer 
Academic Publishers, Norwell, MA, 1981. 
[23] D. M. Tsai and W. Y. Chiu, Motion detection 
using Fourier image reconstruction, Patter
Recognition Letters, 29 (2008) 2145-2155. 
[24] W. Y. Chiu and D. M. Tsai, A macro-observation 
scheme for abnormal event detection in daily-life 
video sequences, EURASIP
in Signal Processing, 2010 (2010), Article ID 
525026, 19 pages. 
[25] D. M. Tsai and W. Y. Chiu, A macro-observation 
approach for real-tim
video,” The 12th IEEE International Conference 
on Computer Vision (ICCV), Demo Session, 
Kyoto, Japan, 2009. 
 
   
(a1) 走路(t=1) (b1) 走路(t=1) (c1) 討論(t=0) 
   
(a2) 走路(t=10) (b2) 走路(t=10) (c2) 討論(t=100) 
   
(a3) 走路(t=15) (b3) 走路(t=15) (c3) 討論(t=200) 
   
(a4) 走路(t=20) (b4) 走路(t=20) (c4) 討論(t=300) 
   
(a5) 動態能量圖(a1)~(a4) (b5) 動態能量圖(b1)~(b4) (c5) 動態能量圖(c1)~(c4)
圖 2 各種正常行為所對應之動態能量圖 
 (fps=10，t 表示第 t 張影像) 
 
 11
  
(a) 動態能量圖 (b) 動態能量圖 (c) 動態能量圖 (d) 動態能量圖 
 
(e) 動態能量圖 (f) 動態能量圖 (g) 動態能量圖 (h) 動態能量圖 
 
(i) 動態能量圖 (j) 動態能量圖 (k) 動態能量圖 (l) 動態能量圖 
 
圖 3 時間序列行為之動態能量圖示意圖 
 
 13
  
打架 搬家 小偷 暈倒 
(a) 測試影像 
 
(b) 動態能量圖 
 
dΔ dΔ dΔ dΔ
tt
(c) 管制界限圖 
圖 4. 異常行為偵測結果: (a) 異常行為之序列影像; (b) 所對應之動態能量圖; (c) 異常行為
超出管制界限的距離 =0 代表行為符合於管制界限內)。 
 
C
event duration (seconds) false alarms (per day)
tt  
( dΔ
 
表 2.平均每天異常事件警報次數。 
ategory of  Number of  
Event duration > 1 s 3.6 
Event duration > 5 s 2.3 
Event duration > 30 s 1.4 
Event duration > 60 s 1.0 
Event duration > 90 s 0.7 
Event duration > 120 s 0.6 
 
 15
表 Y04 
行政院國家科學委員會補助國內專家學者出席國際學術會議報告 
                                                      2009 年  10 月  6  日 
報告人姓名  蔡篤銘 
 
服務機構
及職稱 
 
元智大學工業工程與管理系所 
 
     時間 
會議 
     地點 
2009/09/29 至 10/03 
日本、京都 
本會核定
補助文號
NSC 95-2221-E-155-009-MY3 
會議 
名稱 
The 12th IEEE International Conference on Computer Vision (ICCV 2009) 
發表 
論文 
題目 
A macro-observation approach for real-time unusual event detection in video 
報告內容應包括下列各項： 
一、參加會議經過 
第十二屆 IEEE 國際電腦視覺研討會(ICCV 2009)是機器視覺領域中最盛大的國際研討
會，是由(美國)電氣和電子工程師學會(IEEE)主辦每兩年一次的國際會議，議程包含機
器視覺的各大研究領域，其中有影像分割、人臉偵測、行為辨識、前景追蹤等議程，全
部議程皆屬於機器視覺的範疇，因此能夠匯集各個國家的專家學者互相討論。本次參與
ICCV Demo Session 中所發表之題目為 A macro-observation approach for real-time unusual 
event detection in video，進行連續兩天下午的現場即時成果展示，同時提供海報及傳單
宣導研究成果及實驗室相關資訊，現場其他參觀學者提問十分踴躍，也藉此機會與許多
國外學者交流。 
 
二、與會心得 
本次研討會為電腦視覺領域中相當重要之國際研討會，在會中看到了許多新穎的概念及
想法，而在議程的安排上也有蠻多適合工業工程領域借鏡的地方，例如在 ICCV 對於投
稿的文章審核非常嚴謹，平均錄取率不到一成，而議程同時只舉行一個 Session，使參加
的學者能夠有更多聚集交流的機會，不會造成學者分散或奔波兩邊會場的困擾，本屆
Demo Session 中，除了能夠在國際場合中推廣研究的成果，也藉此吸引許多國外安全監
控廠商的青睞，瞭解安全監控的市場與重要性，也期許台灣能在這塊領域持續深耕。 
 
三、考察參觀活動(無是項活動者省略) 
無 
四、建議 
在此次規模如此龐大的研討會場中，關於安排議程與場次的策略，相當值得台灣許多研
討會作為參考，首先關於會場的安排，報告的會場足以容納上千人，可匯集許多相關領
域的學者齊聚交流，且議程的安排也不會與其他場次重疊，造成人員的分散，可增加接
觸國外專家學者的機會，且足夠的演講時間使得演講者可以完整詳盡的報告研究成果。
 
五、攜回資料名稱及內容 
ICCV 2009 研討之會議論文全文光碟，光碟內容收錄與會之所有論文全文。 
 
96年度專題研究計畫研究成果彙整表 
計畫主持人：蔡篤銘 計畫編號：96-2221-E-155-009-MY3 
計畫名稱：用於居家看護之自動視訊影像監控系統的研究與開發 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 1 1 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 2 2 100%  
研究報告/技術報告 0 0 100%  
研討會論文 3 3 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 1 1 100%  
博士生 1 1 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
 
