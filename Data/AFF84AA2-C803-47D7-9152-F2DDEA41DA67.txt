 2
行政院國家科學委員會專題研究計畫成果報告 
遍地即時多媒體系統與技術－子計畫五:多媒體傳輸安全機制與可調
音訊編碼(III) 
Secure Multimedia Delivery and Scalable Audio Coding (III) 
計畫編號: NSC 95-2221-E-009 -071 -MY3 
執行期限: 97 年 8 月 1 日至 98 年 10 月 31 日 
主持人: 杭學鳴  國立交通大學電子工程學系 教授 
計畫參與人員：林鴻志、蔡家揚、洪朝雄、周正偉、徐崇毓、賴辰彥 
 交通大學電子工程學系研究生 
 
中文摘要 
本計畫為遍布即時多媒體系統與技術群體計畫的子計畫。本計畫全程為三年，本報告將
摘要敘述這三年度的成果，我們以較多篇幅描述第三年度。前兩年的成果包括: a)視覺上可
移除的數位浮水印實現可調式多媒體階層式保護，b)可替換式數位版權管理系統及其嵌入式
裝置實作，c)輪廓轉換(contourlet transform)之研究，d) universal audio and speech coding，及
e) MPEG Surround 編碼研究等。本年度主要是可調式視訊演算法的探討，大致有三項：
「H.264/AVC 可調式視訊編碼之時域預測模式快速演算法」、「H.264/AVC 可調式視訊編碼之
平行化演算法與於 NVIDIA CUDA 之實現」、以及「適用於可調式視訊之小波轉換參數訊源
模型研究」等。 
第一部份中，我們提出了一套在層級時域預測架構的需求設定下，針對雙向預測之低複
雜度決定機制快速演算法，有效地大量減少非必要之雙向預測的龐大運算量。主要是利用大
切割模式與小切割模式兩者之間的時域預測模式的高度相關特性，來節省雙向預測之運算
量，並且統計了雙向預測在不同大小的切割模式所貢獻的壓縮效能程度。最後，與 JSVM 參
考軟體作比較，測試了數種不同視訊特性之影像，實驗結果顯示我們所提之演算法可以節省
50%~60%之計算量，並且可維持原有之壓縮視訊品質。 
而在第二部分中，由於顯示處理器的快速發展，近年來漸漸發展出將顯示處理器應用於
非圖形的運算，以輔助中央處理器，此技術通稱為 GPGPU。美國 NVIDIA 公司在 2007 年
提出一個全新的顯示處理器架構，其全名為「統一運算單元架構」，簡稱 CUDA，為現今對
運算能力要求極高的資料密集型應用程式提供了具彈性的大型平行運算平台。我們提出高度
平行化的 H.264/AVC-SVC motion estimation 方法，將 SVC 參考軟體的演算法轉換成
block-level 平行化的結構，特別是在耗費最多運算時間的 motion estimation 部分。並針對
CUDA 的結構最佳化。 
最後，第三部分為提出了適用於可調式小波視訊編碼的 rate-distortion 模型，此模型可
測量動態預測之效率。傳統上拉格朗日(Lagrangian)最佳化方法被廣泛使用於解決編碼時所
遭遇的 rate-distortion 問題，特別是在模式決定(mode decision)與位元率限制(rate-constrained)
 4
algorithm into a block-level parallel structure, particularly on the motion estimation part, which 
consumes the highest percentage of computation among all operations. 
Finally, a rate-distortion model for motion prediction efficiency in scalable wavelet video 
coding is proposed in this research. The Lagrangian multiplier is widely used to solve the 
rate-distortion optimization problems in video coding, especially on mode decision and 
rate-constrained motion estimation. Different from the non-scalable video coding, the scalable 
wavelet video coding needs to operate under multiple bitrate conditions and it has an open-loop 
structure. Therefore, the conventional rate-distortion optimization technique is not suitable for the 
scalable wavelet case. By analyzing the rate-distortion trade-off due to different bits allocated to 
motion information, we propose a motion information gain (MPG) metric to measure motion cod-
ing efficiency. Based on the MPG metric, a new cost function for mode decision is thus proposed. 
Compared with the conventional Lagrangian multiplier optimization method, our experiments 
show that the new mode decision procedure can generally improve the PSNR performance for, 
particularly, the combined SNR and temporal scalability. 
 
Keywords: Scalable Video Coding, Temporal Scalability, Hierarchical Prediction Structure, En-
coder Optimization, Parallel Processing, Rate-distortion Optimization , Lagrangian Optimization 
 
  
 6
B.2 H.264/AVC 可調式視訊編碼之平行化演算法與於 NVIDIA CUDA 之實現 ................ 24 
B.2.1 研究背景與動機 ................................................................................................... 24 
B.2.2 相關文獻探討 ....................................................................................................... 25 
B.2.3 快速演算法設計 ................................................................................................... 26 
B.2.4 實驗結果與討論 ................................................................................................... 30 
B.3 適用於可調式視訊之小波轉換參數訊源模型研究 ....................................................... 32 
B.3.1 研究目的 ............................................................................................................... 32 
B.3.2 文獻探討 ............................................................................................................... 32 
B.3.3 研究方法 ............................................................................................................... 33 
B.3.4 結果與討論 ........................................................................................................... 37 
C. 參考文獻 .................................................................................................................................... 39 
D. 計畫成果自評 ............................................................................................................................ 43 
Publications (From 2007 to 2009) ................................................................................................... 43 
 
 
 8
Table A-1. 重建圖形與原始圖形之訊噪比(PSNR) 
Airplane baboon BMW earth flower fruit 
58.053802 59.987682 57.544605 58.980923 56.687248 57.961796 
lena nuclei peppers2 peppers Sailboat Tiffany 
57.069214 57.189980 56.536079 56.601677 56.913784 57.939541 
A.2 可替換式數位版權管理系統及其嵌入式裝置實作 
A.2.1 研究目的 
數位版權管理(digital right management, DRM)是一種概念，目的是控制數位媒體的消費
和散佈，現在嵌入式媒體的裝置越來越普遍，也增加了數位版權管理的需求，由於有各式各
樣的嵌入式媒體裝置，理想的數位版權管理系統應該與平台的種類不相關，然而這種需求增
加了軟體實現上的複雜度，因此，我們提出了一種想法，在嵌入式系統的裝置上，實現可替
換式的數位版權管理系統。 
實作所選擇的嵌入式系統裝置是凌陽的開發裝置(SPG290)，而可替換式數位版權管理的
設計是整合了 IPMP 和 OMA 的概念所完成的，所以我們將分三部份來說明我們的研究。 
A.2.2 研究方法 
由消費者的觀點來看，各種不同的 DRM 系統有時候在使用上會造成困擾，舉個例子，
使用者可能想要在不同的裝置上使用同一個數位媒體，其中一個解決的方法，就是把每個裝
置都事先建立好 OMA DRM，這樣使得每一種不同的裝置都能夠播放同一個數位媒體
(Content)，除此之外，也擁有效率上和相容性上的優點。 
然而在消費性數位裝置受到很多環境限制的條件下，所以如果我們希望達到上述的功
能，必須在系統的計算能力以及儲存空間的需求之間找到平衡點，因此，我們提供了一個折
衷方案來實現這個目的。 
基本的概念是事先將各式各樣的 DRM 模組先建立好，然後設計成可從模組提供者下載
到嵌入式系統的裝置上，既然對應平台的 DRM 模組已經事先建立好了，所以就不再需要複
雜的工具管理系統了，另外一方面，我們提供了一個 bootstrap 模組，用來決定使用哪一種
DRM 模組，並且在下載它之前，先作到驗證身分的動作。最後，整個設計上的特色如下所
列： 
 可下載的 DRM 模組達到了彈性選擇的功能 
 DRM 模組的安全性問題會經由 bootstrap 模組來作確認 
 即時性的複雜工具處理系統不再需要 
 額外增加的需求是對 DRM 模組的儲存空間和對它們的驗證工作 
A.2.3 實驗結果 
為了證明我們的設計能做到可替換式的 DRM 系統，我們選用凌陽所開發的嵌入式系統
平台(SPG290)，這個平台式原來的設計是用來發展電視遊戲或是其他應用程式，在我們的研
究上，我們使用它當作是一個擁有 SD 卡的行動裝置，而且事前把 bootstrap 程式寫好，放在
 10
而會有一些奇怪的喀喀聲，雖然此聲音並不大。此外，實驗結果亦顯示出，參數的微調對於
語音壓縮也是很重要的，舉凡 block 之大小，LPC order，不同取樣頻率需如何對應等皆對語
音品質有很大的影響。 
-4
-3.8
-3.6
-3.4
-3.2
-3
-2.8
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17
Sequences
OD
G
TD-LPC
MPEG Ref
FD-LPC
 
Fig. A-3 64kbps 比較圖，其中 14~19 為語音，其餘為音樂 
A.4 使用以小波轉換為基礎的輪廓轉換的影像編碼 
A.4.1 研究目的 
小波轉換(wavelet transform)對一維(one dimensional)的訊號具有良好的壓縮效果，但是
對二維的表現效果並不好，故後來有人提出了方向性濾波器頻帶(directional filter bank)的轉
換，如曲線轉換（curvelet transform）和輪廓轉換(contourlet transform)來解決這個問題。輪
廓轉換因為使用了拉氏金字塔(Laplacian pyramid)造成資料量的增加，故改用小波轉換來取
代拉氏金字塔。 
雖然小波轉換對一維的訊號的壓縮率有不錯的效果。但因為忽略了二維訊號的連續性故
對二維訊號的處理並不理想。Minh N. Do[2]提出了輪廓轉換這種考慮方向性的表示方法來建
立新的圖片壓縮方法。但輪廓轉換使用了拉式金字塔[3]造成了資料量的增加，故後來 Eslami
和 Radha 使用了小波轉換取代拉式金字塔來達成多重解析度轉換分析，稱為以小波轉換為基
礎的輪廓轉換[4]。 
A.4.2 研究方法 
我們以 Eslami 和 Radha 所提出的以小波轉換為基礎的輪廓轉換實現出來，並且重新設
計較小的方向性濾波器，然後使用類似 JPEG2000 的 EBCOT coding 方法，提出一套以這個
轉換為基礎的影像編碼。分為四個步驟： 
全區域的多重解析度轉換分析 
輪廓轉換如Fig. A-4(a)所示，所使用拉式金字塔不會對高頻訊號作降頻取樣(down sam-
ple)，故轉換後資料量增加，之後會對高頻訊號作方向性分析。而以小波轉換為基礎的輪廓
 12
給每個方向標記(label)，而當在某位元平面(bit-plane)上的某個系數 X 第一次變成有意義時，
我們給 8 個相鄰系數的標記，如Fig. A-6(b)所示。 
A.4.3 實驗結果 
Fig. A-7是使用不同的方法壓縮 Barbara 的結果。WT+ESCOT 是使用小波轉換和
3D-ESCOT，DT(23-45)+Proposed ZC 是使用以小波轉換為基礎的輪廓轉換和所提出的零編
碼以及使用的方向濾波器大小為 23x23 和 45x45，DT(7-13)+Proposed ZC 所使用的方向濾波
器大小為 7x7 和 13x13。可以看出 DT(23-45)+Proposed ZC 是最好的，DT(7-13)+Proposed ZC
雖然差了 0.2dB 左右，但計算量少得多，只有前者的 1/10 左右。 
25
26
27
28
29
30
31
32
33
0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 0.5
bits per pixel(bpp)
PS
N
R
WT+ESCOT
DT(23-45)+Proposed ZC
DT(7-13)+Proposed ZC
 
Fig. A-7 使用不同的方法壓縮 Barbara 的 PSNR 
A.5 MPEG Surround 編碼研究 
A.5.1 研究目的 
音樂是人們生活上不可獲缺的一部份。為了重現演奏者那優美的音樂，人們發展了各
式各樣的方式保存與展現音樂。雙聲道音訊展現了良好的品質，並成為目前主要的聆聽方
式。然而雙聲道始終存在著一些限制，並無法達成重現真實環境中那種的細微的迴響感
覺，更不容易清楚的感受到聲音是來自那個方向。為了能夠在有限的頻寬下傳送多聲道音
訊，MPEG 於 2006 年 6 月定訂了多聲道音訊壓縮標準，MPEG surround。MPEG Surround
傳輸的資訊為一個傳統的單聲道 codec，再加上 3~32 kb/s 之 side information [7]。明顯的這
樣的資訊將不會很大，因此可以應用在傳統雙聲道數位廣播上。我們嘗試著研究其它編碼
方式，以更少的 bits 來編碼 parameters。由於常見的多聲道音訊為 5.1 聲道，因此我們的設
計將以 5.1 聲道為主。 
A.5.2 研究方法 
在三個參數中，CLD 佔的 bits 最多。標準的編碼方式為，將 CLD 參數先經過一個
Quantizer，此 Quantizer 僅有兩個 model 可以選。由於相鄰時間與頻帶之參數具有關連性，
Quantized data將經由 first order prediction，改傳送與前一個data之差值。此差值苦以是前後
一個時間或前一個頻帶。 
由上述的方法可以發現，MPEG Surround 在 coding CLD 時，僅使用最簡單的差值。然
 14
速。傳統以關鍵字為基礎的檢索方式若應用到影音上，勢必要人為給定關鍵字。但實際應
用上，人工輸入不僅耗時費力，關鍵字的精確度也很難界定。希望能在一個多媒體檢索系
統中提供一致的內容摘要表示法。 
儘管目前仍無研究宣稱可近似人類的高階語意表達，但有些方式可在有限的系統表達能
力中，試圖解析並趨向語意，其中之一為 relevance feedback。本研究主題將著重於使用者回
饋的介面改進，配合既有的 relevance feedback 技術，研究並整合以提高影像檢索的準確度。 
A.6.2 研究方法 
使用者回饋介面的改進 
Relevance feedback 輔助影像檢索，多年來已衍生不少文獻。大部分研究假設檢索結果
出現後，使用者會挑選對系統最具影響力的結果回饋，因此系統調整檢索參數時，不論是收
歛性或收斂速度都在一定的合理範圍。另外，提到展現多張照片於同一介面，在影像檢索領
域有一個主題稱為 image browsing，其主要目的在於利用瀏覽的方式，導引使用者在影像資
料庫中找尋所需的影像。因此，我們將結合 relevance feedback 與 image browsing 技術，讓
使用者能直觀瞭解檢索結果，從而清楚自己的意圖與檢索系統的認知差異，如此一來可導引
使用者回饋較高價值的資訊。 
在二維平面上展現檢索結果之間的相似度 
雖然影像特徵已經是影像的精簡表示法，但大部分的影像特徵仍為高維度向量。因此，
影像特徵的相似度，可視為高維度空間的距離。若想將彼此間的距離表現於二維空間中，就
必須降階。假設影像特徵表示於高維歐幾里得空間，理論上 Principle Component Analysis 
(PCA)可得到最小的降階誤差。但是，影像特徵的距離定義，很可能不是 Euclidean distance，
因此 PCA 降階運算不太可行。相較於 PCA 依賴於 Euclidean distance 的假設，另一類資料分
析法 Multidimensional Scaling (MDS) 就比較具有彈性。MDS 最初的發展目的，就是為了呈
現高維度資訊於低維度空間中，方便視覺化呈現。MDS 不僅可用於非 Euclidean distance 的
情況，且不要求必須有完整的相互關係。也就是說，如果有 N 筆資料，且其中 M 組關聯存
在 (例如 M 組彼此距離)，原則上 MDS 就可以進行分析。 
清晰與操作便利的使用者介面 
有了代表影像位置的二維座標後，經過反覆實驗，我們發現有兩個問題必須克服，否則將影
響瀏覽的主觀感受。 
 Outlier 影像的偵測與移除：儘管檢索結果應該都是相似的影像，但有些情況可能產生
例外，例如 MDS 對應誤差，或是檢索數量超出資料庫中實際相似照片的總數。這些
例外的影像很容易成為二維空間分佈中，與主群體距離很遠的特殊座標。因為這些座
標的變異極大，若是等比例顯示於有限的螢幕空間，就會出現主群體彼此重疊嚴重，
二維顯示平面的利用率很低的現象。 
 座標相近影像的呈現：利用 MDS 與 outlier detector 可以有效於二維平面上呈現影像
之間的距離，但仍無法避免座標相近的影像互相重疊的問題。主要導因於影像以圖像
呈現時，必須維持一定的大小，以方便使用者瀏覽。最極端的狀況為兩張同大小影像
 16
B. 本年度研究計畫成果 
B.1 H.264/AVC 可調式視訊編碼之時域預測模式快速演算法 
B.1.1 研究目的 
如Fig. B-1所示，為了滿足串流系統在網路上的多樣應用，MPEG 與 ITU 標準小組發展
出了一個可調式視訊編、解碼系統(Scalable Video Coding, SVC) [9][10]。其目的是希望能以
單一位元流來滿足各種接收機的傳輸頻寬、運算能力與解析度。目前，列入標準的整體架構
是德國 HHI 提出以 MPEG-4 14496-10 精進視訊壓縮標準做為延伸的技術。此視訊壓縮標準
已於最近制訂完成，以 H.264/AVC 視訊編碼標準[11][12]為基本層架構，可同時提供空間上
(Spatial)、時間上(Temporal)、和畫質精細(Quality)可調的特性，其壓縮端參考編碼架構命名
為 Joint Scalable Video Model (JSVM)，其編、解碼技術可用在各式不同的設備儀器上，小至
手執式之畫面接收器，大至高解析度接收機[13]。 
 
Fig. B-1 可調視訊編碼應用環境 
由 HHI 所提供之標準參考軟體(Reference Software)，稱為 Joint Scalable Video Model 
(JSVM) [9]。然而，為了使其編碼效率達到最佳，因此編碼器在執行編碼時所選取的編碼參
數會直接影響到最後的壓縮效能，故 JSVM[9]在兩項參數設定下採用全域搜尋(Exhaustive 
Search)之方式： 
 最佳之編碼切割模式(Partition Mode)：類似於 H.264/AVC 視訊編碼標準[11][12]，
編碼器會將視訊影像中每個宏塊(Macroblock)搜尋不同大小的切割模式，而 JSVM 
[9]在加強層(Enhancement Layer)中，均會利用層間預測(Inter-layer Prediction)之機
制來使編碼效能改善。我們測試兩組典型的視訊影像(FOREMAN 與 CITY)，統計
出加強層(Enhancement Layer)的運算複雜度約略是基本層(Base Layer)的 2.5 倍到
3.3 倍，如Table B-1。這代表了當編碼層數增加時，會使得編碼時間大幅度提高。 
 18
 Inter-layer Motion Prediction：加強層之宏塊的切割模式(Partition Mode)、參考畫面索引
(Reference Frame Index)與動作向量(Motion Vector)可以利用其相對應之基本層宏塊所
擁有的資訊推算得知。 
 Inter-layer Residual Prediction：基本層所重建回來之 DCT 數值可以用來減少加強層中編
碼所需之位元數。 
 
Fig. B-2 JSVM 編碼器架構示意圖 
Table B-2. Functionality of Switches 
Switch number Functionality 
1,2 Intra/Inter mode decision 
3 Inter-layer motion prediction 
4 Inter-layer residual prediction (transform domain) 
5 Reconstruction at the enhancement layer 
6 Inter-layer texture prediction 
 
B.1.3 相關文獻探討 
發展可調式視訊編碼標準前，已有許多針對 H.264/AVC 編碼標準所設計之快速演算法
[18]-[26]。然而，目前針對可調式視訊編碼標準所設計之快速演算法相關文獻並不多，以下
我們分為內部預測(Intra Prediction)與畫面間預測(Inter Prediction)來說明現有文獻之作法及
缺失： 
 內部預測(Intra Prediction)：在[27]與[28]兩篇文獻當中，指出在加強層中的 Intra16x16
與 Intra8x8 兩種預測模式在編碼過程中即使被完全的忽略不作測試，並不會有顯著的編
碼效能損失。根據文獻指出，加強層中超過 90%的宏塊均是採用 Intra4x4 與 IntraBL 為
 20
參數 數值變小而增加，這是因位在高碼率的應用下，可以允許有更多的位元來減少
壓縮時所造成的失真，但是另一方面，編碼動作向量(Motion Vector)的位元數也就會隨
之增加。因此，為了平衡碼率(Rate)與失真(Distortion)兩項的因素，並非所有的切割模
式都採用雙向預測(BI)就會得到最好的壓縮效能。我們可以觀察到，大切割模式(16x16、
16x8 與 8x16)在低時域層時，雙向預測(BI)可以提供較好的編碼效能，然而，在小切割
模式(8x8~4x4)時，不到十分之一的方塊會選擇以雙向預測(BI)為其最佳時域預測模式
(Temporal Prediction Type)。 
1 2 3 4
0
10
20
30
40
50
60
FOREMAN: 16x16
Temporal layer
P
er
ce
nt
ag
e 
(%
)
1 2 3 4
0
10
20
30
40
50
60
FOREMAN: 16x8
Temporal layer
1 2 3 4
0
10
20
30
40
50
60
FOREMAN: 8x8
Temporal layer
1 2 3 4
0
10
20
30
40
50
60
FOREMAN: 4x4
Temporal layer
 
 
FW (Qp = 40)
BW (Qp = 40)
BI (Qp = 40)
FW (Qp = 30)
BW (Qp = 30)
BI (Qp = 30)
1 2 3 4
0
10
20
30
40
50
60
70
CITY: 16x16
Temporal layer
P
er
ce
nt
ag
e 
(%
)
1 2 3 4
0
10
20
30
40
50
60
70
CITY: 16x8
Temporal layer
1 2 3 4
0
10
20
30
40
50
60
70
CITY: 8x8
Temporal layer
1 2 3 4
0
10
20
30
40
50
60
70
CITY: 4x4
Temporal layer  
Fig. B-3 Distribution of Temporal Prediction (FW, BW, and BI) 
Table B-3. Conditional Probabilities of , , and  
Sequence     
FOREMAN 40 0.98 0.98 0.98 0.98 0.99 0.99 CITY 0.98 0.99 0.97 0.99 0.99 0.99 
FIREMAN 30 0.94 0.97 0.93 0.97 0.97 0.99 CITY 0.89 0.98 0.85 0.97 0.92 0.99 
 
 大切割模式之雙向預測(BI)相關性： 
因為Fig. B-3所示，16x8、8x16 與 8x8 的雙向預測(BI)機率都遠比 16x16 來的小。因此，
我們接著想觀察的統計特性是 16x16 所擁有的時域預測模式(Temporal Prediction Type)
是否可以有效地給 16x8、8x16 與 8x8 當作參考資訊使用。考慮三個條件機率，其定義
如下： 
 
 
 
如Table B-3所示，條件機率 在不同時域層，平均而言都有 90%以上。這項統計
數據提出了強烈的證據，充分顯示出 16x16 所擁有的最佳時域預測模式(Temporal Pre-
 22
 
 
如Table B-5所示，條件機率 與 在不同時域層，平均而言都有 90%以上。這項統計數
據提出了強烈的證據，充分顯示出 8x8 所擁有的較佳前向預測模式或後向預測模式可以
給 8x4、4x8 與 4x4 一個相當可靠的資訊。 
Table B-5. Conditional Probabilities of  and  
Sequence   
FOREMAN 40 0.94 0.97 0.91 0.96 CITY 0.92 0.96 0.93 0.95 
FIREMAN 30 0.89 0.93 0.89 0.92 CITY 0.87 0.90 0.89 0.90 
Perform Exhaustive Search in Inter16x16 Prediction 
(FW, BW, BI)
Inter16x8 
FW Prediction
Inter16x8 
BW Prediction 16x16 is BI
Inter16x8 
BI Prediction
Inter8x16 
FW Prediction
Inter8x16 
BW Prediction 16x16 is BI
Inter8x16 
BI Prediction
NO
YES
Inter8x8 
FW Prediction
Inter8x8 
BW Prediction 16x16 is BI
Inter8x8 
BI Prediction
NO
YES
NO
BW Prediction for 
8x4, 4x8, 4x4
FW Prediction for 
8x4, 4x8, 4x4
RDcost8x8,FW ≦ RDcost8x8,BW
YES
YES NO
Step 2 Step 3Step 1
 
Fig. B-4 Selection of Temporal Prediction Algorithm 
 
B.1.5 快速演算法設計 
根據B.1.4節所提供的研究數據分析，我們提出了一套在層級時域預測架構(Hierarchical 
Temporal Prediction Structure)的需求設定下，針對雙向預測(BI)之低複雜度決定機制快速演
算法，有效地大量減少非必要之雙向預測(BI)的龐大運算量，其演算法流程圖，可參考Fig. 
B-4，主要含三大步驟，如下： 
Step 1 (Exhaustive Prediction Type Search for Inter16x16)：16x16 切割模式中的三種時域
預測模式(Temporal Prediction Type)採用全域搜尋之方式，並保留有效之編碼資訊，以供
Step 2 使用。 
Step 2 (Conditional BI Elimination for Large Partitions)：根據 Step 1 所得到的編碼資訊，
JSVM 編碼器可以得知何時不需要測試雙向預測(BI)，以達到減低運算複雜度，並保留
8x8 切割模式有效之編碼資訊，以供 Step 3 使用。 
Step 3 (Adaptive Prediction Type Selection for Small Partitions)：根據 Step 2 所得到的編
 24
 
 
如Table B-7與Table B-8所示，實驗結果顯示出我們所提出之演算法有效地大量減少在層
級時域預測架構(Hierarchical Temporal Prediction Structure)下所需之編碼時間，其減少幅度可
以達到 60%。 
 另外，我們跟前人所設計的演算法[30]作效能比較，如Table B-9。明顯地，演算法[30]
不僅只提供了 36%的運算節省，但也造成了較大的編碼效能損失，因此，這充分顯示了我
們所設計的快速演算法，比較適合層級時域預測架構(Hierarchical Temporal Prediction 
Structure)下來使用。 
Table B-9. Performance Comparisons with Li’s Method [30] 
GOP = 8 Li’ method Proposed (dB) (%) (%) (dB) (%) (%) 
BUS -0.15 2.05 36.5 -0.06 1.18 53.7 
FOOTBALL -0.13 1.67 30.5 -0.05 0.99 50.1 
CREW -0.16 2.55 35.3 -0.01 0.37 55.7 
HARBOUR -0.07 1.14 42.7 -0.02 0.49 52.9 
 
B.2 H.264/AVC 可調式視訊編碼之平行化演算法與於 NVIDIA CUDA 之實現 
B.2.1 研究背景與動機 
H.264/AVC 已成為目前最受歡迎的高效能編碼器之一。SVC 基於 H.264/AVC 架構，提
供了 temporal、spatial、SNR 的可調能力，然而複雜度也大幅上升，因此如何降低 SVC 的複
雜度及加速編碼，變成一個重要的議題。 
 
Fig. B-5 單核心處理器效能成長表(與 VAX-11/780 比較) [36] 
在過去幾年，隨著 CPU 遇到半導體製程的問題，而無法再提高時脈，如功耗問題(power 
 26
在經過 2004 年至 2005 年，數次的會議討論及實驗競賽結果後，可調式視訊壓縮標準
之方法以 H.264/AVC 為主，並併入 MPEG-4 Part 10 Advanced Video Coding 之可調式延伸
版本(Scalable Extension)之標準制定，其主要的壓縮方法與軟體則以 HHI 所提出的版本為
主，稱為 JSVM(Joint Scalable Video Model)。 
過去視訊編碼標準的發展一直以編碼效率(coding efficiency)為目標，例如 MPEG-2、
H.264/AVC，而 Scalable Video Coding(SVC)主要提供了視訊的可調性，主要分為三種可調
性： 時間可調性(temporal scalability)、空間可調性(spatial scalability)及畫質可調性(quality 
scalability)，這項技術可以用在許多應用，單一被壓縮過的可調式視訊之位元流(bit 
stream)，可以支援如家用電腦、行動裝置、高畫質電視(HDTV)等多種不同接收端。 
Fig. B-7顯示了 H.264/AVC-SVC 的編碼器架構，圖中分為兩層 spatial layer，一開始輸入
的視訊會先做 down-sample，產生解析度較低的視訊，我們稱解析度最低的視訊為基層(base 
layer)(layer 0)，其它為增強層(enhancement layer)(layer 1)，編碼器會先對 base layer 的第一張
frame 進行編碼，之後再對 enhancement layer 的第一張 frame 編碼，接著再對 base layer 的第
二張 frame 編碼，以此類推。 
Base layer 的編碼與 H.264/AVC 大同小異，但是在 enhancement layer 的編碼部分，則新
增了三種預測方式：Inter-Layer Motion Prediction、Inter-Layer Residual Prediction及 Inter-Layer 
Intra-Prediction [43]，主要是使用了 base layer 的資訊來進行動量估計。 
與 H.264/AVC 相比，SVC 的複雜度大幅上升，如何簡化及加速編碼運算，成為一個重
要的議題。而隨著處理器往多核心發展，使用平行處理來加速也成為一種熱門的加速方式。
然而目前以完全的 block 層級平行化的研究並不多，完全 block 層級平行化能適合於大量平
行處理器的平台。這種平台在未來很有可能普及，因此本計劃即以此當做研究的重點。 
 
Fig. B-7 H.264/AVC-SVC 的編碼器結構 [42] 
 
B.2.3 快速演算法設計 
在本計劃中，我們針對最耗費時間的 motion estimation 做平行化加速，我們將程式分為
 28
 
Fig. B-9 Bi-prediction 會先從反方向的 reference block 產生新的 original block 後，再使用新的
block 做搜尋 
Forward prediction
Backward prediction
Bi-prediction
 
Fig. B-10 動量估計流程圖 
對於每一張 frame，這個預算次數取決於一開始的編碼參數，官方的預設為 4 次。由於
每一種 block size 都要產生一張新的 frame，因此每次都要產生 7 張新的欲編碼 frame。最後
整體的 temporal layer motion estimation 流程圖如Fig. B-10。 
如Fig. B-10所示，除了 macro block 編碼以外，所有的 motion estimation 運算皆做 block
層級的平行化，並使用 CUDA 平台運算。 
 30
在 enhancement layer 的動量預測中，我們將平行化 mode 1 及 mode 3 的部分，也就是一
般的動量預測方式，以及使用 base layer residual 的動量預測；而 mode 2 及 mode 4 則採用原
始的程式。由於在編碼 enhancement layer 時，base layer 已先被編碼，因此從 frame 的角度
來看，會有一張 base layer residual frame。因此一開始直接先將目前擬做編碼的 frame，和
up sample 後的 residual frame 做相減，之後再使用與 base layer 相同的方式做預測。 
 我們使用了 CUDA 的 texture memory，並讓程式能接受不同的 frame 大小，根據傳入的
參數來運算不同的 spatial layer，如Fig. B-12。 
 
Fig. B-12 Spatial scalable 實作，上圖為 base layer，下圖為 enhancement layer。後者會送入相
減後的 frame，CUDA function 會根據傳入的 frame 參數來做資料大小的調整 
 
B.2.4 實驗結果與討論 
1. 各別效能分析： 
在各別函數的效能分析中，我們將同樣的演算法寫成 C 語言及 CUDA 兩種版本，測試
CIF(352x288)的影像，使用 CUDA Visual Profiler [44]來量測 CUDA 程式所耗費的時間，而
CPU 的程式則使用 C 語言的函數來量測，Table B-11列了五個具代表性的運算，分別是 4x4 
SAD 計算、16x16 的 SAD 比較、interpolation、16x16 的 1/4 精度移動向量預測，及產生新
的欲編碼 frame。 
Table B-11. 對於每張 frame 的五個代表性運算時間(msec)及加速程度。 
msec 4x4 SAD calc 16x16 IMV interpolation
16x16 
FMV new frame 
CPU 906 140 16 16 16 
CUDA 24.6 12.4 2.2 0.5 0.7 
SPEEDUP 37X 11X 7X 32X 23X 
由於 enhancement layer 的運算與 base layer 大致相同，只差在 frame 大小，以及 inter layer 
 32
 
B.3 適用於可調式視訊之小波轉換參數訊源模型研究 
B.3.1 研究目的 
    傳統編碼廣泛使用的拉格朗日(Lagrangian)最佳化方法可針對單一位元率進行有效的位
元率分配。由於可調式小波視訊編碼的量化(quantization)步驟獨立於編碼之外，並且單一壓
縮位元流(bitstream)須同時滿足不同位元率需求，因此拉格朗日方法不適用於可調式小波視
訊編碼。如研究計畫提案之規畫，本研究目的為提出適用於小波視訊編碼之最佳化方法。此
最佳化之方法可在不同位元率條件下，得到適用之動態資訊(motion information)。 
 
B.3.2 文獻探討 
在可調式視訊編碼領域中，目前主要有兩大分支：以 DCT 為基礎之 H.264 可調式視訊
編碼版本與以小波為基礎之畫面間小波(interframe wavelet)可調式視訊編碼。由於小波訊好
本身具有兼具時域與頻域可調解析度的特性，此項特性可充份運用在影像與視訊編碼之中，
如可在可調式編碼中調整畫面率與畫面解析度。經過小波轉換後的影像，次頻帶(suband)呈
現類似階層分布，不同階層展現不同的影像細節；藉由此自然的特性，影像的細節可經過越
多層次頻帶訊號的獲取而得到漸近式的改良[45]。 
    近年來由 Sharpiro [46]， Said 與 Pearlman [47]，以及 Taubman [48] 等人的研究已展現
了小波編碼在影像壓縮上的良好表現。而在相關視訊壓縮的進展方面，由於 Ohm [49]，Hsiang
與 Woods [50]，Secker 與 Taubman [51]，以及 Xu et al. [52]等人提出了動態補償時間濾波
(motion compensated temporal filtering) (MCTF)技術使得小波視訊編碼也得到極大的進展。此
外，為了得到適用於內嵌式(embedded)小波影像/視訊編碼架構下最佳的編碼效能，許多 rate 
-distortion(R-D)分析技巧也被提出[48][53][54]。在小波視訊編碼之相關 rate-distortion 研究方
面，Wang 與 Schaar 在[55]中提出分析跨次頻帶之 rate-distortion 模型，並且建立了描述在
MCTF 過程所產生錯誤累積的數學模型。然而在以上的幾種不同 rate-distortion 模型皆為針
對單一位元率進行最佳化，較不適用於可調式編碼的需求。 
由於可調式小波視訊編碼之量化(quantization)，或稱切取(truncation)步驟是在編碼完成之後
直接對資料流(bistream)進行，獨立於編碼過程之外，此編碼架構稱之為開放式迴圈(open loop)
架構。而傳統以 DCT 為基礎之編碼方法，編碼與量化步驟則是在同一次的編碼流程中逐塊
相依進行，此架構稱為封閉式迴圈(closed loop)架構。在封閉式結構中量化的過程可以有效
被控制，並且可以參考已量化之資料進行位元率的控制；然而在開放式架構中，由於量化步
驟獨立與編碼過程外，因此，動態資訊(motion information)與殘存訊號(residue signal)間位元
率大小的分配(bit allocation)無法有效被控制。然而，動態資訊的位元分配不良會造成以下兩
個現象：(1) 動態資訊量的多寡會影響動態向量的準確度，進而影響 MCTF 在進行時間軸次
頻帶訊號拆解(decomposition)的效率；(2)動態資訊在切取後的資料流中所占的比例分配若是
過高，則會導致殘存訊號的失真(distortion)過大。在以下的研究方法中，我們提出了們提出
了所謂的 MPG 值 (Motion Prediction Gain, 動態預測增益)以測量動態資訊的預測效率。此
MPG 值最大的特點，在於 MPG 理論上與最後輸出/切割之位元率無關，可客觀在各位元率
 34
    根據 Shannon 所提出之消息理論[56]，我們將 Laplacian 訊源模型之 R-D 函式代入至(1)
中，則可得到以下之等效不等式 
( )
0
1 12 2T TR R R   v                                   (2)
 
0 20 40 60 80 100 120
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
 
(a) 
0 20 40 60 80 100 120
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
 
(b) 
Fig. B-15 點狀分佈表示殘存訊號之真實機率分佈，實線則為 Laplacian 機率模型之模擬結
果。(a)第一個時間層次之第一張殘存畫面，(b)第二個時間層次之第一張殘存畫面。測試影
像為 Mobile，大小為 CIF，30fps. 
其中Λv 表示經由動態向量 v 補償後所得到之殘存訊號之 Laplacian 機率模型參數，且此參數
可利用殘存訊號之變異數(variance)進行估測。因此，我們再利用殘存訊號之變異數將(2)進
行化簡，可得到如下的等效不等式 
   2 0 2log log 1
R
  
v                                 (3) 
由(2)化簡至(3)的過程中，我們可以發現原先所設定之切取位元率 RT項在化簡的過程中被消
去。此消去的現象意謂著(3)與切取位元率無關，換句話說，在(3)中所呈現的動態資訊位元
率與殘存訊號的關係在各位元率要求下皆成立。 
    我們進一步分析(3)，首先令Φv值為動態向量 v所造成的殘存訊號之標準差的對數值; 我
 36
    MCTF 利用相鄰畫面進行時間濾波，可得到高頻(high-pass)與低頻(low-pass)畫面，這些
產生的低頻畫面則會被利用進行下一個時間層次(temporal level)之 MCTF。此架構可有效進
行濾波，然而由於其樹狀架構，在解碼端解碼時，底層之失真會因此逐層擴散至上層時間層
次，濾波效率因而降低。為了改善此現象，我們將在(10)中的 C 值隨著時間層次的不同而更
動，藉以調整動態資訊在不同時間層次間的重要性。由於 MCTF 進行時只與上層所產生之
低頻畫面相關，我們利用一個簡單的一階馬可夫(Markov)模型去預測不同時間層次的 C 值變
化，為了表示 C 值與時間層次之間的關聯性，我們改寫 C 為 Ct 如下 
1t tC w C                                                (11) 
其中 w 為常數。當 t=1 時，我們可以得到第一個時間層次之 C 值，(11)可再推導如下 
0
t
tC w C                                               (12) 
因此，(10)可改寫如下 
2 ( )2( , | ) ( ) 2 tC RtJ C     vss v v                                 (13) 
    利用(13)我們可以進行模式決定。可調式小波視訊編碼的模式決定方法與 H.264 的方法
近似，以巨方塊(macroblock ,簡稱 MB)為基本編碼單位進行，而每個 MB 又可細分為數種次
方塊組合: 16x16、16x8、8x16、8x8、8x4、4x8、與 4x4，而每種方塊組合即為一種編碼模
式。而模式決定可分為三個主要步驟，如Fig. B-16所示: 
Step 1: 選擇最佳之參數組合 
    我們所提出的代價函式含有一個須事先設定之參數值 Ct，且如(12)所示，Ct還可再分為
兩個參數值 w 與 C0。經過繁複的測試後，我們在[57]中提出 w 與 C0之值分別為 0.8 與 7 左
右之值，可適用於各種不同之測試視訊。 
Step 2: 計算各預測模式之最佳動態向量集合 
假定對其中一種編碼模式 m，m 屬於 M 集合，其對應到在 MB 內共有 Nm個次方塊。在
此 m 模式中，MB 中的動態向量集合為 vm，對應至殘存訊號為 bm，表示如下 
1
1
( ,..., )
( ,..., )
m
m
m N
m N
b b
v v


b
v                                          
(14) 
因此，每一個 bi所對應之最佳動態向量 vi*可利用下列之代價函式決定 
 *
2 ( )2
arg min ( , | )
with  ( , | ) ( ) 2 t
i
i Motion i tv
C R v
Motion i t b
v J b v C
J b v C v

 

 
S                          (15) 
對此 m 模式而言，此 MB 所得到最佳之動態向量集合可表示如下 
* * *
1( ,..., )mm Nv vv                                      (16) 
Step 3: 選擇最佳之預測模式 
    當求出每個模式之最佳動態向量集合後，重新計算每個模式之殘存訊號變異量與平均動
 38
Coastguard; 此四個測試視訊皆為 CIF 大小，畫面率為 30fps。第二個測試則是綜合時間
(temporal)與 SNR 兩種可調性，我們預先設定 6 個位元率由低至高並具不同畫面率的測試
點，然後測量解碼視訊之平均 PSNR 值，所使用的影像為 City，Crew，Harbour 與 Soccer
皆為 4CIF 大小，畫面率為 60fps。如Fig. B-17與Table B-14所示，我們可以發現所提出之適
用於可調式小波視訊轉換編碼之模式決定方法，可得到相較傳統拉格朗日作法要有更好的
PSNR 表現。 
43
44
45
46
47
48
49
50
51
52
53
200 400 600 800 1000 1200 1400 1600
kbps
Akiyo
Lagrangian
Proposed
30
31
32
33
34
35
36
37
38
39
40
200 400 600 800 1000 1200 1400 1600
kbps
Tempete
Lagrangian
Proposed
35
36
37
38
39
40
41
42
43
44
45
200 400 600 800 1000 1200 1400 1600
kbps
Waterfall
Lagrangian
Proposed
33
34
35
36
37
38
39
40
41
42
43
200 400 600 800 1000 1200 1400 1600
kbps
Coastguard
Lagrangian
Proposed
P
S
N
R
P
S
N
R
P
S
N
R
P
S
N
R
(a) (b)
(c) (d)  
Fig. B-17 所提出之模式決定方式與傳統拉格朗日最佳化方法之 PSNR 比較表。(SNR 可調性
測試) 
Table B-14. 所提出之模式決定方式與傳統拉格朗日最佳化方法之 PSNR 比較表。(綜合時間
與 SNR 可調性測試) 
Sequence 
(4CIF) 
GOP Cost Func-
tion 
750k 
15fps 
1024k
15fps 
1200k
30fps 
1500k
30fps 
2048k 
60fps 
3000k 
60fps 
 
City 
 
32 
Lagrangian 36.39 37.33 37.42 37.983 38.49 39.33 
Proposed 36.73 37.69 37.80 38.40 38.85 39.62 
 
Crew 
 
32 
Lagrangian 36.39 37.30 36.74 37.34 37.18 38.20 
Proposed 36.46 37.39 36.92 37.52 37.33 38.28 
 
Harbour 
 
32 
Lagrangian 33.91 34.97 34.96 35.59 36.25 37.50 
Proposed 33.94 35.01 34.98 35.65 36.29 37.52 
 
Soccer 
 
32 
Lagrangian 36.28 37.22 36.92 37.61 38.00 39.20 
Proposed 36.51 37.50 37.19 37.95 38.23 39.43 
 
 40
[17] H. Schwarz, D. Marpe, and T. Wiegand, “Hierarchical B Pictures,” ISO/IEC 
JTC1/SC29/WG11 and ITU-T SG16 Q.6, JVT-P014, 2005. 
[18] Y.-D. Zhang, F. Dai, and S.-X. Lin, “Fast 4x4 Intra-prediction Mode Selection for H.264,” 
IEEE International Conference, vol. 2, 27-30 June 2004, pp. 1151-1154. 
[19] F. Pan, X. Lin, R. Susanto, K. P. Lim, Z. G. Li, G. N. Feng, D. J. Wu, and S. Wu, “Fast Mode 
Decision Algorithm for Intra Prediction in JVT,” ISO/IEC JTC1/SC29/WG11 and ITU-T 
SG16 Q.6, JVT-G013, 2003. 
[20] C.-L. Yang, L.-M. Po, and W.-H. Lam, “A Fast H.264 Intra Prediction Algorithm Using Ma-
croblock Properties,” International Conference, vol. 1, 24-27 Oct. 2004, pp. 461-464. 
[21] Z. Zhou and M.-T. Sun, “Fast Macroblock Inter Mode Decision and Motion Estimation for 
H.264/MPEG-4 AVC,” International Conference, vol. 2, 24-27 Oct. 2004, pp. 789-792. 
[22] P. Yin, H.-Y.C. Tourapis, A.M. Tourapis, and J. Boyce, “Fast Mode Decision and Motion 
Estimation for JVT/H.264,” Proceedings of International Conference on Image Processing, 
2003, pp. 853-856. 
[23] K.-H. Han and Y.-L. Lee, “Fast Macroblock Mode Decision in H.264,” IEEE Conference, vol. 
A, 21-24 Nov. 2004, pp. 347-350. 
[24] C. Grecos and M.-Y. Yang, “Fast Inter Mode Prediction for P Slices in the H.264 Video Cod-
ing Standard,” IEEE Transactions, vol. 51, Issue 2, June 2005, pp. 256-263. 
[25] J. Lee and B. Jeon, “Fast Mode Decision for H.264,” IEEE Int'l Conf. on Multimedia and 
Expo., vol.2, June 2004, pp. 1131-1134. 
[26] F. Zhang and X. Zhang, “Fast Macroblock Mode Decision in H.264”, ICSP 2004 7th Interna-
tional Conference, vol. 2, 31 Aug.-4 Sept. 2004, pp. 1179-1182. 
[27] L. Xiong, “Reducing Enhancement Layer Directional Intra Prediction Modes,” ISO/IEC 
JTC1/SC29/WG11 and ITU-T SG16 Q.6, JVT-P041, 2005. 
[28] L. Yang, Y. Chen, J. Zhai, and F. Zhang, “Low Complexity Intra Prediction for Enhancement 
Layer,” ISO/IEC JTC1/SC29/WG11 and ITU-T SG16 Q.6, JVT-Q084, 2005. 
[29] H. Li, Z.-G. Li, and C.Wen, “Fast Mode Decision for Coarse Grain SNR Scalable Video 
Coding,” IEEE Int’l Conf. on Acoustics, Speech and Signal Processing, 2006. 
[30] H. Li, Z.-G. Li, and C. Wen, “Fast Mode Decision Algorithm for Inter-Frame Coding in Fully 
Scalable Video Coding,” IEEE Trans. Circuits Syst. Video Technol., vol. 16, no. 7, pp. 
889-895, 2006. 
[31] J. Ren and N. Kehtarnavaz, “Fast Adaptive Early Termination for Mode Selection in H.264 
Scalable Video Coding,” IEEE Int’l Conf. on Image Processing, 2008. 
[32] H.-C. Lin, W.-H. Peng, and H.-M. Hang, “A Fast Mode Decision Algorithm with Macrob-
lock-Adaptive Rate-Distortion Estimation for Intra-Only Scalable Video Coding,” IEEE Int’l 
Conf. on Multimedia and Expo, 2008 
 42
[51] A. Secker and D. Taubman, “Lifting-Based Invertible Motion Adaptive Transform (LIMAT) 
Framework for Highly Scalable Video Compression,” IEEE Trans Image Processing, vol. 12, 
no. 12, Dec. 2003. 
[52] J. Xu and et al., “3D Subband Video Coding Using Barbell Lifting,” ISO/IEC 
JTC1/SC29/WG11 MPEG, M10569, 2004. 
[53] S. Mallat and F. Falzon, “Analysis of Low Bit Rate Image Transform Coding,” IEEE Trans 
Signal Processing, vol. 46, no. 4, pp. 1027-1042, Apr. 1998. 
[54] P.-Y. Chen, J. Li, and C.-C. J. Kuo, “Rate Control for an Embedded Wavelet Video Coder,” 
IEEE Trans. Circuits Syst. Video Technol., vol. 7, pp. 696-702, Aug. 1997. 
[55] M. Wang and M. van der Schaar, “Operational Rate-distortion Modeling for Wavelet Video 
Coders,” IEEE Trans. Signal Processing, vol. 54, no. 9, pp. 3505-3517, Sept. 2006. 
[56] T. Berger, Rate Distortion Theory, Englewood Cliffs, NJ: Prentice Hall, 1984. 
[57] C.-Y. Tsai and H.-M. Hang, “Rate-distortion Model for Motion Prediction Efficiency in 
Scalable Wavelet Video Coding,” Packet Video Workshop, Seattle, May 2009. 
 
 44
Multimedia & Expo, Hannover, Germany, 23-26 June, 2008. 
[10] W.-N. Chen and H.-M. Hang, “H.264/AVC Motion Estimation Implementation on Compute Unified 
Device Architecture (CUDA),” IEEE Int’l Conf. on Multimedia & Expo, Hannover, Germany, 23-26 
June, 2008. 
[11] F.-C. Chang and H.-M. Hang, “An Improved Presentation Method for Relevance Feedback in a Con-
tent-Based Image Retrieval System,” International Conference on Intelligent Information Hiding and 
Multimedia Signal Processing (IIHMSP’08), pp. 91-94, Aug. 2008. 
[12] F.-C. Chang, C.-Y. Chang, and H.-M. Hang, “A Study on the Meta-data Design for Long-Term Digital 
Multimedia Preservation,” International Conference on Intelligent Information Hiding and Multime-
dia Signal Processing (IIHMSP’08), pp. 95-98, Aug. 2008. 
[13] J.-J. Tsai and H.-M. Hang, “On Modeling Genetic Pattern Search for Block Motion Estimation,” IEEE 
International Conference on Image Processing (ICIP’08), pp. 1980-1983, Oct. 2008. 
[14] C.-H. Hung and H.-M. Hang, “Image Coding Using Short Wavelet-based Contourlet Transform,” 
IEEE International Conference on Image Processing (ICIP’08), pp. 2884-2887, Oct. 2008. 
[15] J.-J. Tsai and H.-M. Hang, “Modeling of Pattern-Based Block Motion Estimation and Its Applica-
tion,” IEEE Trans. Circuits Syst. Video Technol., vol. 19, no. 1, pp. 108-113, 2009. 
[16] C.-H. Hung and H.-M. Hang, “Decision-directed Adaptive Wavelet Image Coding with Diretional 
Decomposition,” IEEE International Symposium on Circuits and Systems (ISCAS’09), Taipei, Taiwan, 
May 2009. 
[17] C.-Y. Tsai and H.-M. Hang, “Rate-distortion Model for Motion Prediction Efficiency in Scalable 
Wavelet Video Coding,” Packet Video Workshop (PV’09), Seattle, May 2009. 
[18] K.-L. Huang and H.-M. Hang, “Consistent Picture Quality Control Strategy for Dependent Video 
Coding,” IEEE Trans. Image Processing, vol. 18, no. 5, pp. 1004-1014, 2009. 
[19] C.-H. Hung and H.-M. Hang, “Decision-directed Adaptive Wavelet-based Contourlet Transform 
Coding Based on Mean Shift,” IPPR Conference on Computer Vision, Graphics, and Image 
Processing (CVGIP’09), Nantou, Taiwan, Aug. 2009. 
 
Theses 
(1) Ernie Chu, 朱育成, “Layered Protection of Scalable Media using Perceptual Removable 
Watermarking,” MS Thesis, NCTU, to be finished in June 2007. 
(2) Chiao-Lin Wu, 吳巧琳, “A Switchable DRM Scheme with Embedded Device Implementa-
tion,” MS Thesis, NCTU, to be finished in June 2007. 
(3) Hao-Ting Chu, 朱浩廷, “Design and Implementation of MHP Video and Graphics Accele-
rators on Xilinx ML403 Platform,” MS Thesis, NCTU, August 2007. 
(4) Shang-Yu Yeh 葉尚諭, “Coding Efficiency and Quality Improvement for MPEG Surround 
Encoding,” MS Thesis, NCTU, June 2008. 
(5) Chen-Yen Lai 賴辰彥, “H.264/AVC-SVC Encoder Parallelized Realization on NVIDIA 
CUDA,” MS Thesis, NCTU, July 2009. 
