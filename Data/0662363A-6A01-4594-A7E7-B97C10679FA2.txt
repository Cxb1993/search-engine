to texts, emotions can be collected from images 
(faces or gestures) and voices (tones). However, 
extra devices (cameras, speakers⋯) are needed and it 
would be more difficult to keep track of the emotion 
changes during the day. In contrast, collecting 
emotions from personal texts can record an emotional 
life history of people, which will be useful in 
building a comfortable space afterwards. The best of 
it is that we only need the Internet to make the 
whole system work, which is available in most offices 
and e-homes. 
This project will focus on extracting and tracing 
emotions on personal texts by discussing their 
characteristics and features. To develop an efficient 
system, machine learning and personalize technique 
will be applied. The intelligent emotional component 
will generate an emotion history of the resident for 
the interactive circumstance builder. The builder 
then will generate the suitable space for him. To 
achieve this, the interactive circumstance builder is 
equipped with an atmosphere lamp which controls the 
LED light of different colors, a projector to project 
figures, photos and wall papers, and a music player 
in a handheld device. Learning functions will be 
implemented according to the resident＇s feedback. 
The performance of the system will be evaluated and 
improved by real testers. 
英文關鍵詞： emotion analysis, personal context, intelligent home, 
ambient intelligence 
 
 2
我們的研究： 
                                                   
 
  
                                                 
                                     
   
 
 
 
 
圖 一：過去研究概念與我們提出的研究概念之比較 
 
就智慧情境方面，不同於過去由使用者設定或選擇的各種情境，我們的目的
是要研究一可依照使用者目前情緒，自動為其選擇最適合的情境。另外，我們
的研究能夠依照使用者的使用習慣 (如使用者更改設定的歷程資訊) 反饋資訊，
自動學習出適當的情緒-情境對應。 
本計畫之產出可讓國內的研究學者，直接利用個人化文本情緒分析的技術，
將此資訊用於相關研究上。而對於國內的廠商，除了前端情緒分析元件可供與
產品結合外，更可以利用具學習模組的智慧空間元件，提高產品技術價值與進
入難度，進一步提昇競爭力。國內的醫療與教育相關機構，則可利用此技術建
置出適合的情境系統。在國際上，由於中文已成為世界最多人使用的語言，因
此本計劃所提供之中文相關技術元件，更可支援國際研究上多語技術的開發與
應用。 
 
五、文獻探討 
 
本計劃橫跨自然語言處理與智慧空間兩大領域，欲研究整合兩大領域所需之
基礎技術，結合兩者之專長，期開發一具理想人機學習功能之智慧情境系統，
以建立一個從「溫暖關懷」出發的人本科技技術。計劃背景可由自然語言處
理、智慧空間、兩者結合、雲端資料與 Android 平台控制系統四方面來說明： 
 
 自然語言處理方面 
 情緒分析是一近期相當受到注目的研究主題，又因其應用廣泛與跨領域的
特性受到學界的重視。關於這個主題迄今已不少研究，主要希望能找出影響代
表情緒之分數、情緒類別、以及文本評價的主要變因(Hu and Liu, 2004; Pang and 
Lee, 2005; Ku et al., 2009) 。過去的研究已顯示出採取不同演算法於不同資料集
上的效能，特別是在多數的研究中都提到，此研究主題的特性不同於其他傳統
的自然語言處理議題 (Pang et al., 2002; Ku et al., 2007)，因此，處理實驗語料、
產生標準答案與評估實驗結果的方式皆需經過特別設計 (Wiebe et al., 2001; Seki 
et al., 2007)。 
個人 個人所使用的各種社交工具， 
如 MSN、即時通、部落格或推特 
各種應用 個人情緒歷程 
 4
2007 年推出 LivingColors 情境燈，單價高達 120 英鎊，依然熱銷 25 萬組。2009
推出第二代和 LivingColors Mini。因此飛利浦情境燈目前還是居龍頭地位。其
功能可組合出 160 萬種色彩，燈座底下有一感應器，可放置地板感應人體溫度 
(藉以改變燈光色彩)，其他則完全靠使用者利用色盤調整燈光，也就是說，目
前的產品只具簡易人體生理訊號 (體溫)的探測功能，該置地感測器對體溫的感
測效果如何尚未可知，且產品也無法與使用者互動學習，達到量身訂作的個人
化目標。 
 
圖二：Philips LivingColors 
 
燈光為視覺效果與情緒感知的連結。影響情緒與居家情境另一有力的途徑便
是聽覺效果，目前相關的研究，主要是將音樂依照情緒分類，供使用者選聽 
(Yang and Chen, 2011)，但尚未有分析使用者情緒並連結至使用者偏好的研究。
在聲音氣氛的營造上，我們的研究是由智慧元件與學習元件根據使用者的背景
資料、情緒與使用習慣一併學習，達到最後的目標：使用者一進入居家環境，
智慧元件就能夠自動選擇最適當的情境，藉由視覺與聽覺的搭配，讓使用者的
情緒放鬆，而有舒適的感覺。智慧元件可以提供使用者方便且適切的使用環
境，不需每次心情不好、緊張、壓力大時還需要重複設定，並且藉由學習使用
者的習慣，讓使用者感受到關懷。 
我們最終的目標是根據使用者的背景資料、使用歷程與情緒資訊、自動去學
習在此條件下最好的情境設定，表現如下對應： 
 
軟體系統(使用者資訊，情緒) => (燈光, 音樂) 
 硬體系統(燈光, 音樂) => 智慧居家環境 
 
除了前述技術上的特殊之處，目前的智慧環境中也並無類似的設計或功能，
因此無論是技術或應用，本計劃皆提出了創新的概念。 
 
 自然語言與智慧空間的結合 
綜合上面所提到的兩方面技術，目前智慧空間的相關技術多著重於「方便
性」與「自動性」，且多關心使用者生理層面 (體溫、脈搏、血壓、記憶，例如
Philips LivingColors 的溫度感測)，而未觸及心理層面。就心理層面而言，最直
接的作法就是關懷情緒，若能做好情緒管理，既可釋放壓力，又能感到舒適而
幸福。而研究已指出，顏色與聲音可直接影響情緒 (Dalgleish et al., 2003, Kaya 
 6
雲端的概念和平台，既可結合智慧的功能，又不需另外適應設備與使用方法，
免除學習新產品的陣痛期，更加容易推廣並為使用者接受。 
 
六、研究方法 
 
在研究方法上，我們分成兩個部份來討論。第一個部份是如何由個人化文本
分析出使用者情緒，並根據使用者情緒提供適合的情境；第二個部份則是設計
並建構一系統，讓使用者能夠使用此技術。 
 
6.1 使用者情緒分析技術 
 
實驗材料 
為了初步從文本中找出使用者的情緒資訊，我們採用了兩個字典：一是中文
情感字典 (NTUSD, Ku and Chen, 2007) 另一個則是中文心情字典 (Lin et al., 
2008)。中文情感字典將情緒詞分成正負面，而心情字典則將一般詞彙歸類於八
個心情類別，包括新奇、溫馨、驚訝、傷心、有用、開心、無聊、及生氣。這
八類皆是由 Yahoo!新聞的分類而來，並非傳統心理學上的心情分類，因此我們
在使用此字典之前，先將它們對應到 Parrott (2004) 的心情分類架構中，對應不
到的則分至「其他」類別。  
我們利用即時訊息的文本來偵測使用者心情。實驗中使用八位使用者的
Yahoo!即時通與 MSN Messenger 的記錄檔。我們設計了一個收集此類記錄文本
的程式。當程式開啟時，它會以 Windows 服務的形式執行並持續收集使用者目
前輸入的對話，只要出現任何的對話訊息，每小時就會跳出視窗詢問使用者目
前的心情，並請使用者選擇想聽的音樂與情境背景。一共有 3,290 首歌曲、15
種燈光設定及 6 種情境設定供使用者選擇。選擇情境時，模擬圖會以全螢幕呈
現以達到最好的效果。最後一共有 150 筆有效資料收集為實驗用，這些資料的
統計數據見下表。 
 
心情 1 2 3 4 5 6  
 11 80 1 15 39 4  
燈色 1 2 3 4 5 6 7 
14 6 5 25 9 5 11 14
8 9 10 11 12 13 14 15
11 7 4 13 7 15 5 13
情境 1 2 3 4 5 6  
 28 40 16 33 17 16  
表一. 標記實驗資料的統計資訊  
(心情 -- 1:愛 2:歡喜 3:驚訝 4:生氣 5:傷心 6:害怕) 
 
我們收集 Yahoo!部落格文章中具有表情符號的句子做為我們的訓練語料，
這些表情符號是作者在撰寫句子時加上，因此在我們的假設中，它們可代表作
者在寫這些句子時的心情。因為句子中若出現多個表情符號，可能會出現混淆
 8
為包含詞彙 wi的總文章數。 我們將算出的 idf 分數依照詞彙出現在四十類心情
的機率加以分配，就可得到同一詞彙在每類心情的表情分數 emoticon(wi, cj)。公
式 (2) 與 (3) 計算此表情分數。 
 
 
)()(),( , icwji widfsprobcwemoticon ji ⋅=  (2) 
N
sN
sprob ji
ji
cw
cw
)(
)( ,, =    (3) 
 
公式中的 ji cws , 為表情類別為 cj 且包含 wi的句子。 接著，詞彙 wi 在心情類別 
ek 的分數就可由公式 (4) 加總出來。表情符號類別與心情類別的對應如下表所
示。搜尋句 sq 的心情類別則由公式 (5) 計算出的結果決定。 
 

∈
=
kj ec
jiki cwemoticonewemotion ),(),(  (4) 

∈
=
qik sw
ki
e
q ewemotionsclassemo ),(maxarg)(_  (5) 
 
ek (心情) cj (表情符號) 
愛 7(愛), 8(害羞), 10(親吻) 
歡欣 1(微笑), 4(開心), 13(得意), 18(笑) 
驚訝 11(驚訝) 
生氣 12(生氣) 
傷心 17(哭), 37(嘆氣) 
害怕 15(擔心) 
表三. 表情符號類別與心情類別對應表 
 
因為每個含有表情符號的句子被視為一篇文章，因此，當句子中有多個相同
詞被發現時，它的 idf 分數將會累加。因此在公式 (5) 中已經包含了詞彙頻率的
資訊，我們不需要再將計算好的 idf 分數乘以詞頻 (tf)。 
 
2. 情緒方法 
使用 tf•idf 分數來計算重要性的概念是找到經常出現但出現在較少文章，因
此具有鑑別度的詞彙，而這些詞彙可用來代表該篇文章。在情緒方法中，我們
則是試著找出能代表特定表情符號類別的詞彙，因此概念轉變為尋找經常出現
但出現在較少表情符號類別的詞彙。根據以上的想法，我們將所有含有相同表
情符號的句子結合起來，視為一篇文章，產生了共 40 篇文章，並以此 40 篇文
章計算詞彙的 tf•idf 分數 emoticon(wi, cj)，也就是說情緒方法與主題方法的不
同之處，在於個別詞彙的分數。有了詞彙的分數以後，最後的心情類別
emo_class(sq) 同樣由公式 (4) 與公式 (5) 決定。 
 
3. 擷取方法 
在擷取方法中，我們將找出句子對應的表情符號問題類比為資訊檢索的問
題。如果能夠找出一個未知句子所對應的表情符號，也就是自動加上表情符
 10
 
 
 
圖三. IlluMe 系統架構 
 
在 IlluMe 中，當 LED 燈組根據搖控傳送出的控制訊號改變燈色時，系統會
從使用者的個人電腦傳送對應的 RF 訊號到 ANT 電路板 (Dynastream Innovations 
Inc.)，接著 ANT 電路板就能控制 LED 燈板來改變燈色。 
音樂則會根據偵測到的心情狀態 (類別) 播放。播放的功能與控制的功能都
以智慧型手機軟體的形式開發出來。考慮到現代人的使用習慣，音樂則直接由
智慧型手機播放。圖四說明 IlluMe 的操作流程。 
 
 
 
 
 
 
 
 
 
 
 
 
 
圖四. 操作流程 
 
 
燈光
情境學習模組
ANT
 
 
 
智慧型手機 
音樂
設定
使用者對話
記錄 
心情分析元件
個人資訊
喜好控
制元件 
情境控
制元件
 設定
輸入 
媒體選擇
模式地點
自動
播放音樂
地點
手動
顯示燈光效果
臥室 客廳
燈光設定 心情對應
情境
 12
詞彙方法與其他三個方法不同之處，在於它並不是利用表情符號句來計算分
數，此方法是四個方法之中第二佳的方法。由於並未使用表情符號句，故此法
的優點在於即使詞彙並未出現在表情符號句中，我們仍能計算其分數並由此得
知搜尋句所屬之表情符號類別。表六中的心情類別「驚訝」就顯示出這個現
象，該類使用詞彙方法的效能明顯高於其他方法。雖然如此，詞彙方法仍有其
缺點，那就是它的詞彙集仍然是有限的。在某些類別中，由於具有大量的表情
符號句，因此也包含了許多詞彙，這些詞彙的分數都可由主題方法習得，此
時，詞彙方法相較之下，有限的詞彙集就成為它的缺點，因此決定搜尋句類別
的效能反而較差。  
 
 
 
圖五. 四十個表情符號類別中，表情符號句數與效能的曲線圖 
 
在表六的心情偵測效能中顯示，四個方法對於心情類別「愛」、「生氣」與
「害怕」都表現得不好。對「生氣」與「害怕」類別，表二顯示造成效能不佳
的原因之一是缺乏足夠的表情符號句。表一則顯示標記者較少選擇這些心情類
別。這些類別的對話記錄可能只跟表達特殊場合或事件的詞彙有關，而不是跟
特定的主觀詞彙有關。  
表七為心情偵測結果的混淆矩陣。從中我們可看出，「傷心」類別的句子經
常被誤判為「歡欣」類別。在「傷心」類的對話記錄中我們發現兩個主要的特
點：句子中缺乏詞彙/詞彙較少或是句子中只包含常用詞彙。第一個特點造成判
斷心情類別時缺乏足夠的資訊；對於第二個特點，我們可能需要額外的文本資
訊，例如使用 n-gram 方式取代單一的詞彙來得到更多資訊。 
Bellegarda 在他的研究中，提到他的方法能在區分六類心情類別時，達到 f
分數 0.340。他的方法是從讀者的角度來判斷句子帶來什麼心情，而我們的研究
則是需要判斷作者在撰寫此文本時的心情，兩者並不相同。從讀者角度來判斷
心情類別一般被認為較困難，原因是當使用者寫出一段文本時，他本身的心情
未必與此文本相符。因此，雖然 Bellegarda 的實驗與我們的實驗使用不同的資
料集，評估的判準也不相同，但我們的主題方法能夠達到微平均 (micro-average) 
0.480，是一個相當不錯的結果。 
 14
7.3 系統展示 
 
 
圖六. 以模擬屋方式呈現 
 
 
 
 
圖七. 以個人燈組方式呈現 
 
 16
6. 在心情偵測的正確率上，我們的方法能夠與過去研究者提出的方法相匹敵，
甚至達到更好的效能。 
7. 我們是第一個利用心情偵測的結果，自動設定情境，並評估效能。過去並未
有相關的研究可供比較。 
8. 系統設計的使用流程，可同時考慮協同過濾的技術與使用者偏好的資訊，以
自動設定最佳情境。 
 
在系統的設計上，我們則有以下的結論： 
 
1. 我們使用以上研發出來的技術，開發出 IlluMe 系統，該系統能即時分析使
用者最新網路對話記錄中的心情，並依照此心情自動設定居家情境。 
2. 系統需求為使用者常用來網路即時訊息對話之桌機或筆記電腦、智慧型手機
及配合燈具。 
3. IlluMe 系統以居家燈光控制及智慧型手機音樂 MP3 播放來營造情境。 
4. 燈光控制部份我們使用 ANT 電子板與 LED 燈板做出各種燈色組合供使用者
選擇。 
5. 音樂播放方式及整體系統控制程式我們在 Android 平台設計並於智慧型手機
上執行，以配合現今使用者的使用習慣。 
6. IlluMe 系統已開發為一軟硬體功能完整的產品，可配合模型屋展現居家情
境，此系統獲邀至日本 Good Design 展示。 
7. 將 IlluMe 系統個人化後，我們以個人桌燈/組合燈配合音樂的方式，獲得
ACL 2012 demo 論文接受並於會場展示。 
 
未來我們將持續收集使用者用後回饋的資訊，以做為系統改進。 
 
7.4 建議 
 
除了在國外展覽展示技術與系統外，若於國內能有更多機會展示，對於學界
技術的推廣應有相當大的助益。 
本計劃執行期間共參與四次國際會議發表論文，希望計劃經費中能夠多補助
出國差旅費及註冊費的部份，更能夠出國發表技術提高台灣於國際的能見度。 
 
參考文獻 
 
葉明貴 , 林澤勝 , 智慧空間共通平台技術發展現況 (2)：歐美標準探討 , 
http://www.ils.org.tw 
Bellegarda, Jerome R. 2010. Emotion Analysis Using Latent Affective Folding and 
Embedding. Proceedings of the NAACL HLT 2010 Workshop on 
Computational Approaches to Analysis and Generation of Emotion in Text, Los 
Angeles, 1-9.  
Blakeman, Adam. 2004. An Investigation of the Language of Internet Chat Rooms. 
http://www.lancs.ac.uk/fss/courses/ling/ling201/res/dissertations.html. 
 18
Ku, Lun-Wei, Liu, I-Chien, Lee, Chia-Ying, Chen, Kuan-hua. and Chen, Hsin-His. 
2008. Sentence-Level Opinion Analysis by CopeOpi in NTCIR-7.  Proceedings 
of the 7th NTCIR Workshop Meeting, Tokyo, Japan. 260-267. 
Lin, Kevin Hsin-Yih, Yang, Changhua, and Chen, Hsin-His. 2008. Emotion 
Classification of Online News Articles from the Reader’s Perspective. 
Proceedings of the 2008 IEEE/WIC/ACM International Conference on Web 
Intelligence. 220-226. 
Liu, Dong, “Intelligent Evaluation and Intelligent Home Appliances,” Proceedings 
of International Conference on New Trends in Information and Service Science 
(NISS '09), 932-936, July 2009. 
Lucking-Reiley, David, Bryan, Doug, Prasad, Naghi and Reeves, Daniel, “Pennies 
from eBay: The Determinants of Price in Online Auctions,” Journal of Industrial 
Economics, 55(2):223–233, 2007. 
Pak, Alexander, Paroubek, Patrick, “Twitter as a Corpus for Sentiment Analysis and 
Opinion Mining,” Proceedings of the Seventh International Conference on 
Language Resources and Evaluation (LREC 2010), 1320-1326, May 2010. 
Pang, B., & Lee, L. (2005). Seeing stars: Exploiting class relationships for sentiment 
categorization with respect to rating scales. In Proceedings of the 43rd Annual 
Meeting on Association for Computational Linguistics (pp. 115 – 124). 
Morristown, NJ: ACL. 
Parrott, W. “Emotions in Social Psychology”, Psychology Press, Philadelphia, 2001. 
Seki, Y., Evans, D.K., Ku, L.-W., Chen, H.-H., Kando, N., & Lin, C.-Y. (2007). 
Overview of Opinion Analysis Pilot Task at NTCIR-6. In Proceedings of the 6th 
NTCIRWorkshop Meeting on Evaluation of InformationAccess Technologies: 
Information Retrieval, Question Answering, and Cross-Lingual Information 
Access (pp. 265–278). Tokyo, Japan: National Institute of Informatics. 
SentiWordnet, Istituto di Scienza e Tecnologie dell’Informazione, Consiglio 
Nazionale delle Ricerche, http://sentiwordnet.isti.cnr.it/, 2010. 
Sidorenko, V. N., “Effects of the Medical Resonance Therapy Music in the 
Complex Treatment of Epileptic Patients,” Integrative Psychological and 
Behavioral Science, Volume 35, Number 3, 212-217, DOI: 
10.1007/BF02688782, 2000.  
Stone, N., “Designing Effective Study Environments,” Journal of Environmental 
Psychology, 21(2), 179-190, 2001. 
Su, Hsi-Yao. 2003. The Multilingual and Multi-Orthographic Taiwan-Based 
Internet: Creative Uses of Writing Systems on College-Affiliated BBSs. Journal 
of Computer-Mediated Communication 9(1). 
http://jcmc.indiana.edu/vol9/issue1/su.html. 
Tawari, A., Trivedi, M.M, “Speech Emotion Analysis: Exploring the Role of 
Context,” IEEE transactions on multimedia, Vol 12(6), 502-509, October 2010. 
Wiebe, J., Bruce, R., Bell, M., Martin, M., & Wilson, T. (2001). A Corpus Study of 
Evaluative and Speculative Language. Proc. 2nd ACL SIGdial Workshop on 
Discourse and Dialogue. Aalborg, Denmark, September, 2001.  
 
國科會補助專題研究計畫出席國際學術會議心得報
告 
                           
日期：101 年 10 月 30 日 
 
計畫編
號 
NSC100－2218－E－224－013－ 
計畫名
稱 
個人化文本情緒分析於智慧居家情境建構之研究 
出國人
員姓名 古倫維 
服務機
構及職
稱 
國立雲林科技大學資訊工
程系助理教授 
會議時
間 
2011年 11月 8
日至 
2011 年 11 月
13 日 
會議地
點 
泰國清邁 
會議名
稱 
(中文) 第五屆自然語言處理國際聯合會議 
(英文)The 5th International Joint Conference on Natural 
Language Processing 
發表題
目 
(中文) 為意見分析工作預測意見依存關係 
(英文)  Predicting Opinion Dependency Relations for 
Opinion Analysis 
Treebank, and then proposed methods to find their corresponding dependency 
relations on the dependency trees generated from the same sentence. With 
these relations, we could train a model to annotate opinion dependency 
relations automatically to provide an opinion dependency parser, which is 
language independent if language resources are incorporated. Experiment 
results show that the annotated syntactic structures and their corresponding 
dependency relations improve at least 8% of the performance of opinion 
analysis. 
四、建議 
參與國際會議的發表對學生還是相當重要的訓練，同時也可讓學生見識大型
國際會議的規模與研究水準，建議盡量予以補助。 
五、攜回資料名稱及內容 
會議論文電子檔 
 
 
 
Predicting Opinion Dependency Relations for Opinion Analysis 
 
Lun-Wei Ku 
National Yunlin University 
 of Science and Technology 
Douliou, Yunlin 64002, Taiwan 
lwku@yuntech.edu.tw 
Ting-Hao Kenneth Huang
National Taiwan University
No.1, Sec.4, Roosevelt Rd., 
 Taipei, Taiwan 
tinghaoh@andrew.cmu.edu 
Hsin-Hsi Chen 
National Taiwan University
No.1, Sec.4, Roosevelt Rd.,
 Taipei, Taiwan 
hhchen@ntu.edu.tw 
 
Abstract 
Syntactic structures have been good fea-
tures for opinion analysis, but it is not easy 
to use them. To find these features by su-
pervised learning methods, correct syntac-
tic labels are indispensible. Two possible 
sources to acquire syntactic structures are 
parsing trees and dependency trees. For the 
annotation processing, parsing trees are 
more readable for annotators, while depen-
dency trees are easier to use by programs. 
To use syntactic structures as features, this 
paper tried to annotate on human friendly 
materials and transform these annotations 
to the corresponding machine friendly ma-
terials. We annotated the gold answers of 
opinion syntactic structures on the parsing 
tree from Chinese Treebank, and then pro-
posed methods to find their corresponding 
dependency relations on the dependency 
trees generated from the same sentence. 
With these relations, we could train a mod-
el to annotate opinion dependency relations 
automatically to provide an opinion depen-
dency parser, which is language indepen-
dent if language resources are incorporated. 
Experiment results show that the annotated 
syntactic structures and their corresponding 
dependency relations improve at least 8% 
of the performance of opinion analysis. 
1 Introduction 
Opinion analysis has drawn much attention in 
research communities of machine learning and 
natural language processing. In the early stages, 
words in documents were used as the main 
features (Pang et al., 2002). Some opinion dic-
tionaries were created for this demand (Ku et 
al., 2007). However, researchers soon realized 
that word features were not sufficient for ac-
quiring good performances, so they started to 
include syntactic structures and semantic in-
formation (Qiu et al., 2008). Their researches 
showed that linguistic knowledge is helpful in 
determining opinions.  
For various applications related to opinions, 
syntactic structures have become powerful 
tools for extracting useful clues. To find opi-
nions in product reviews, modification rela-
tions were used to identify the product and 
their features (Lu et al., 2009), e.g., a good 
price (feature) of this camera (product). To 
find opinion holders and targets, templates and 
linguistic rules were adopted (Breck et al., 
2007). To find more opinion words, dependen-
cy relations were utilized (Qiu et al., 2011). 
Even when applying the basic negation rule 
that flips opinion polarity over, we need to find 
its modified word first by syntactic clues. 
However, we will show that syntactic relations 
do not directly suggest opinions. 
Syntactic relations are obtained usually from 
all kinds of syntax trees. Parsing trees (phrase 
structured) and dependency trees (grammatical) 
are the most commonly seen ones. Parsing 
trees are in-order trees which keep the order of 
words in sentences, so they are more readable 
for people. Instead, nodes in dependency trees 
are displayed by the head-modifier relations, in 
which the sentence sequence probably is not 
remained. People could find the opinion pas-
sages if they can understand the whole sen-
tence, i.e. from parsing trees. However, when 
the linguistic background is needed, it could be 
difficult for most people to reconstruct the 
whole sentence from the dependency trees in 
order to find the opinion passage. Therefore, if 
we want to find annotators to build a corpus 
which could be used to train an opinion rela-
tion recognizer, parsing trees are the better ma-
terials compared to dependency trees. Howev-
er, compared to relations between words, com-
plicated tree structures are more challenge to 
be utilized by algorithms (Doan et al., 2008).  
Figure 3. In the trio tri = (3, NP-OBJ, 圆满, 成功, 
Substantive-Modifier),  triID = 3, oparent  = NP-
OBJ, oleft =圆满 (perfect), oright =成功(success), 
and t = Substantive-Modifier. 
 
Figure 2. A sample parsing tree with trios. 
1, IP, 活动, VP, Subjective-Predicate 
2, VP, 取得, NP-OBJ, Verb-Object 
3, NP-OBJ, 圆满, 成功, Substantive-Modifier 
Figure 3. Opinion trios 
Note that because the annotation of trios is 
on nodes of parsing trees, which appear in-
orderly, oleft will always appear before oright in a 
sentence, and keeping this in mind will help 
understand the meaning of each inter-word 
relation t.  
Now for the sentence S, we have its parsing 
tree T, the annotated opinion trios Tri(S) on it, 
and its dependency relations Rdep(S). The next 
step is to mark the op(r) on Rdep(S) according 
to its corresponding Tri(S). For each trio tri, if 
any descendent of its left node oleft and any 
descendent of its right node oright together build 
a relation )(SRdepr , the opinion judgment 
of gop(r) of the relation r is set to true. Other-
wise, gop(r) is set to false. Now we have gop(r) 
for each r in Rdep(S), our goal is to find good 
methods to generate op(r) so that it can predict 
gop(r) as precisely as possible. We propose 
methods to achieve this goal in Section 3. 
3 Methods 
As mentioned, our goal is to predict opinion 
dependency relations as precisely as possible. 
However, to use more readable materials, opi-
nion trios are first annotated on Chinese Tree-
bank 5.1, and then they are mapped to the cor-
responding dependency relations. Before the 
aligning process, we use the annotated trios for 
training to predict the opinion trios in Section 
3.1. Using these predict trios for opinion anal-
ysis shall show the performance before the 
aligning process. After that, the aligned depen-
dency relations, i.e., the gold opinion depen-
dency relations are adopted for training to pre-
dict the opinion dependency relations in Sec-
tion 3.2. Because the parsing tree and the de-
pendency tree are generated by the same parser, 
we can always align them by the provided 
word ID numbers. 
After prediction, the opinion dependency re-
lations are available, and they can provide ne-
cessary information for many applications. 
However, we go one step further to test wheth-
er they benefit the opinion analysis. To fulfill 
this purpose, a basic method which uses the 
opinion dependency relations to extract opi-
nionated sentences and determine their polari-
ties is proposed in Section 3.3. 
3.1 Predicting Opinion Trios 
We predict the opinion trios by the sequential 
labeling model Conditional Random Field 
(CRF, Lafferty et al., 2001).  In a parsing tree, 
the tag of the internal node is the syntactic 
structure of its sub-tree, and the tag of the leaf 
node contains its part of speech and the content 
word. For each node, tags of its first four 
children (the first level), first four children of 
them (the second level), and their three 
children are used as features of this node. 
Features of its siblings (the window size is five) 
are considered, too. 
The labels l we would like the CRF to pre-
dict labels for each node, which are N or labels 
of the form t-C, where Rptt , },{ RLC  , L 
indicates that the current node is oleft in some 
opinion trio and R indicates oright. The label N 
indicates that the current node does not belong 
to any Tritri . The cardinality of the set Rpt 
is five, so that a total of 11 labels are used in 
CRF. CRF++1 is selected for experiments. 
3.2 Predicting Opinion Dependency Rela-
tions 
After aligning the opinion trios to the depen-
dency relations, we will have gop(r) for each 
one of them. In the previous research, usually 
only some relations were selected for opinion 
analysis. No statistical numbers showed the 
connection between the dependency relations 
and the opinions. We believe that it is because 
                                                 
1 http://crfpp.sourceforge.net/ 
 ))((1),,()( mmh wRMopsnwwrelSrops  (4)
That is, the opinion score of a dependency 
relation is an average of the aggregate scores 
of its descendent dependency relations. In 
practice, we design different rules for calculat-
ing opinion scores by the current relation type 
rel in S(.). Here to simplify the problem, we 
adopted Formula (1) and treated wm as oleft and 
wh as oright in it. 
4 Experiments 
Though there were researches which predicted 
opinion dependency relations, they did not 
predict directly from the parsing results. In-
stead, they predicted from documents or sen-
tences according to the context and a large 
quantity of training instances were needed. 
They did not predict on all dependency rela-
tions either. Therefore, there is no existing da-
taset containing correct opinion labels on de-
pendency relations. In this section, we describe 
how to generate opinionated syntactic dataset 
on parsing trees, and align the annotated labels 
to dependency trees. After that, qualitative and 
quantitative analyses of opinion dependency 
relations are provided. At the end, we discuss 
the evaluation results of the proposed methods. 
4.1 Data Set and Preprocessing 
To use the Stanford parser as our tool to gener-
ate dependency tree for experimental sentences 
and to avoid errors as possible, we adopted 
Chinese Treebank 5.1 as experiment materials. 
Sentences in Chinese Treebank are already 
segmented and part of speech tagged, and its 
tagging set is the same with the one Stanford 
parser uses. Therefore, the Stanford parser can 
take the data from the Chinese Treebank to 
generate more accurate dependency trees.  
The dataset Chinese Treebank 5.1 contains 
507,222 words, 824,983 Hanzi, 18,782 sen-
tences, and 890 data files. For the opinion 
analysis experiments, opinionated labels, i.e., 
opinionated, non-opinionated, positive, neutral, 
negative, were annotated on all sentences in 
Chinese Opinion Treebank. Afterward 57,706 
trios were annotated on the parsing trees of 
gold opinion sentences, i.e., sentences which 
were annotated as opinionated. Methods for 
generating the gold opinion sentences pro-
posed by Ku et al. (2007) were adopted. 
Next, the Stanford parser took all sentences 
in Chinese Treebank as input to generate their 
dependency trees. A total of 416,581 depen-
dency relations were generated, and 284,590 of 
them were in opinion sentences. Then the an-
notated trios were aligned to their correspond-
ing dependency relations, and because trios 
were only annotated on opinionated sentences, 
the gop(r) of these aligned relations were set to 
true. At the end, a total of 54,753 relations 
gop(r) were set to true. 
 Opinion 
Polarity Positive Neutral Negative 
# 6,916 1,824 1,937 
% 64.78 17.08 18.14 
Total # 10,677 
Total % 56.84 
Table 1. Statistics of opinions. 
Rpt Number Percentage 
Substantive-Modifier 21,317 36.94  
Subjective-Predicate 15,860 27.48  
Verb-Object 18,010 31.21  
Verb-Complement 1,208 2.09  
Other 1,311 2.27  
Total 57,706 100.00  
Table 2. Statistics of structural trios. 
Table 1 shows the distribution of the opi-
nion and polarity labels. Table 2 shows the 
statistics of trios. Trios of the Substantive-
Modifier and Verb-Object types are the ma-
jority in opinion sentences, while trios of the 
Verb-Complement type are few. 
Table 3 further shows the distribution of de-
pendency relations. It shows that previously 
the most adopted dependency relations for 
opinion analysis, e.g., amod (adjective modifi-
er) or advmod (adverb modifier), do not cer-
tainly bear opinions or appear in opinion sen-
tences. In Section 4.3, we will further test the 
performance of finding the opinionated rela-
tions with the help of the opinion word dictio-
nary, which was also widely adopted by pre-
vious work (Feng et al., 2009). 
4.2 Evaluation of Opinion Trio Prediction 
In this section, results of predicting opinion 
trios by CRF mentioned in Section 3.1 are 
shown. We first predicted the appearance of 
head in other relations of the same sentences, 
and RM(w) returns w’s modifier. For each 
},,{ mh wwrelr  in this category: 
.)( 
,)(
,   )(),(,, ofany   
falsergopelse
truergop
NTUSDiniswRMwRHwwif mhmh

  
 Minor supportive: with the support value 
above 0.2, e.g., rcomp, advmod, mmod, 
range. For each },,{ mh wwrelr  in this cat-
egory:    
.)( 
,)(
,   )(),(,, of all  
falsergopelse
truergop
NTUSDiniswRMwRHwwif mhmh

  
 Not supportive: with the support value less 
than 0.2. Relations in this category are 
viewed as non-opinionated and their gop(r) 
are automatically set to false. 
Experiment Settings P R f-Score
Appearance: oleft and oright 0.60 0.52 0.56 
t = Substantive-Modifier 0.59 0.41 0.49 
t = Subjective-Predicate 0.53 0.46 0.49 
t = Verb-Object 0.62 0.65 0.64 
t = Verb-Complement 0.44 0.13 0.20 
Table 4. Prediction of the appearance 
 of children nodes in trios. 
Experiment Settings P R f-Score
t = Substantive-Modifier 1.00 0.25 0.40 
t = Subjective-Predicate 1.00 0.25 0.41 
t = Verb-Object 1.00 0.39 0.56 
t = Verb-Complement 1.00 0.13 0.23 
Table 5. Prediction of trios. 
All dependency relations 
Rel P R f-Score 
Nsubj 0.4507 0.7028 0.5492 
Advmod 0.3675 0.6851 0.4784 
Dobj 0.6097 0.8566 0.7124 
Rcmod 0.4195 0.8509 0.5620 
Amod 0.5031 0.7953 0.6163 
Mmod 0.3289 0.7388 0.4552 
Neg 0.4313 0.6404 0.5155 
Range 0.3630 0.5762 0.4454 
Top 0.4833 0.5461 0.5128 
Rcomp 0.3371 0.5817 0.4269 
Ba 0.4286 0.5817 0.4935 
Dvpmod 0.8244 1.0000 0.9037 
Pass 0.5819 0.7455 0.6536 
Npsubj 0.5000 0.7073 0.5859 
Total 0.4713 0.6178 0.5347 
Modification dependency relations 
Total 0.4070 0.2371 0.2997 
Table 6. Performance of predicting opinion 
dependency relations. 
The results of two experiment settings are 
listed: prediction performed on all dependency 
relations and on only modification-related de-
pendency relations (in the form of lex-mod, 
e.g., amod, rcmod, etc.) The later are the rela-
tions adopted in many previous researches. 
Table 6 shows the performance of predicting 
opinion dependency relations. It indicates that 
if only modification related relations were con-
sidered, the f-score dropped nearly half be-
cause more than half of the opinion dependen-
cy relations were expelled in this case. In other 
word, results show that predicting on all rela-
tions instead of taking only modification-
related dependency relations as clues can cap-
ture more opinion relations, and hence the pre-
diction of opinion relations is necessary. 
4.4 Evaluation of Opinion Extraction Us-
ing Predicted Opinion Trios and De-
pendency Relations 
In this section, predicted opinion trios and pre-
dicted opinion dependency relations were uti-
lized in an opinion extraction system. In order 
to make use of these structural cues, opinion 
analysis methods proposed by Ku et al. (2007) 
were selected. Their methods calculated opi-
nion scores of sentences from characters and 
words accumulatively, so syntactic cues can be 
added in and function jointly. 
Five settings for opinion analysis were expe-
rimented: 
 C+W+N: characters, words, and negations 
were used as cues for calculating opinion 
scores. It was the original method proposed 
by Ku et al. 
 C+W+N+goldTrio: annotated opinion trios 
were utilized additionally. 
 C+W+N+Trio: predicted opinion trios were 
utilized additionally. 
 C+W+N+goldDep: opinion dependency 
relations aligned from the annotated trios 
were utilized additionally. 
 C+W+N+Dep: predicted opinion dependen-
cy relations were utilized additionally. 
The results were shown in Table 7. The per-
formance of the opinion extraction improves 
10.40% (0.7162->0.7993) when utilizing opi-
nion trios and 8.66% (0.7162->0.7782) when 
utilizing opinion dependency relations. These 
results clearly indicate that the syntactic in-
formation benefit opinion analysis. Because of 
References 
Abbasi, A., Chen, H., and Salem, A. 2008. Senti-
ment analysis in multiple languages: Feature se-
lection for opinion classification in Web forums. 
ACM Trans. Inf. Syst. 26, 3 (Jun. 2008), 1-34. 
DOI= http://doi.acm.org/10.1145/1361684. 
1361685 
Bikel, D. M. and Castelli, V. 2008. Event Matching 
Using the Transitive Closure of Dependency Re-
lations. Proceedings of the 46th Annual Meeting 
on Association for Computational Linguistics, 
pages 145-148. 
Breck, E., Choi, Y. and Cardie, C. 2007. Identify-
ing Expressions of Opinion in Context. Proceed-
ings of the 20th International Joint Conferences 
on Artificial Intelligence, pages 2683-2688. 
Chang, P.-C., Tseng, H., Jurafsky, D. and Manning 
C. D. 2009. Discriminative Reordering with 
Chinese Grammatical Relations Features. Pro-
ceedings of the Third Workshop on Syntax and 
Structure in Statistical Translation, pages 51-59. 
Doan, H., Cao, Y., Lin, C.-Y. and Yu, Y. 2008. 
Searching Question by Identifying Question 
Topic and Question Focus. Proceedings of the 
46th Annual Meeting on Association for Compu-
tational Linguistics, pages 156-164. 
Feng, S., Wang, D., Yu, G., Yang, C. and Yang, N. 
2009. Chinese Blog Clustering by Hidden Sen-
timent Factors. ADMA, Vol. 5678, Springer 
(2009), pages 140-151. 
Ku, L.-W. and Chen, H.-H. 2007. Mining Opinions 
from the Web: Beyond Relevance Retrieval. 
Journal of American Society for Information 
Science and Technology, Special Issue on Min-
ing Web Resources for Enhancing Information 
Retrieval, 58(12), 1838-1850. 
Ku, L.-W., Huang, T.-H. and Chen, H.-H. 2009. 
Using Morphological and Syntactic Structures 
for Chinese Opinion Analysis. Proceedings of 
Conference on Empirical Methods in Natural 
Language Processing, pages 1260-1269. 
Ku, L.-W., Lo, Y.-S. and Chen H.-H. 2007. Test 
Collection Selection and Gold Standard Genera-
tion for a Multiply-Annotated Opinion Corpus. 
Proceedings of the 45th Annual Meeting on As-
sociation for Computational Linguistics, pages 
89-92. 
Lafferty, J., McCallum, A. and Pereira, F. 2001. 
Conditional Random Fields: Probabilistic Mod-
els for Segmenting and Labeling Sequence Data. 
Proceedings of International Conference on Ma-
chine Learning, pages 282-289. 
Lu, Y., Zhai, C.X. and Sundaresan, N. 2009. Rated 
Aspect Summarization of Short Comments. Pro-
ceedings of 18th International World Wide Web 
Conference, pages 131-140. 
de Marneffe, M.-C. and Manning, C. D. 2008. Stan-
ford typed dependencies manual. Technichal re-
port. http://nlp.stanford.edu/software/depend 
encies_manual.pdf 
Pang, B., Lee, L. and Vaithyanathan, S. 2002. 
Thumbs up? Sentiment classification using ma-
chine learning techniques. Proceedings of the 
2002 Conference on Empirical Methods in Natu-
ral Language Processing, pages 79-86. 
Qiu, G., Wang, C., Bu, J., Liu, K. and Chen, C. 
2008. Incorporate the Syntactic. Knowledge in 
Opinion Mining in User-generated Content. Pro-
ceedings of NLPIX’08. 
Qiu, G., Liu, B., Bu, J. and Chen, C. 2011. Opinion 
Word Expansion and Target Extraction through 
Double Propagation. Computational Linguistics, 
March 2011, Vol. 37, No. 1: 9.27 
Seki, Y., D. K. Evans, L.-W. Ku, L. Sun, H.-H. 
Chen and N. Kando. 2008.  Overview of Multi-
lingual Opinion Analysis Task at NTCIR-7. 
Proceedings of the 7th NTCIR Workshop Meet-
ing on Evaluation of Information Access Tech-
nologies:Information Retrieval, Question Ans-
wering, and Cross-Lingual Information Access, 
pages 185-203. 
Somasundaran, S., J. Ruppenhofer and J. Wiebe. 
2007. Detecting arguing and sentiment in meet-
ings. Proceedings of the SIGdial Workshop on 
Discourse and Dialogue 2007. 
Wiebe, J., E. Breck, C. Buckly, C. Cardie, P. Davis, 
B. Fraser, D. Litman, D. Pierce, E. Riloff and T. 
Wilson. 2002. NRRC summer workshop on mul-
ti-perspective question answering, final report.  
ARDA NRRC Summer 2002 Workshop. 
Zhou, Q. 2008. Automatic rule acquisition for Chi-
nese intra-chunk relations. Proceedings of Inter-
national Joint Conference of Natural Language 
Processing (IJCNLP-2008). 
 
一、參加會議經過 
  本次出國主要的目的是去參加 NTCIR-9，NTCIR是國際三大評比會議之一，
本次我們參與的是 RITE 任務，並會議中與其他各隊一同張貼論文海報 The 
Yuntech System in NTCIR-9 RITE Task 
以說明我們的系統與技術。RITE 任務共分成英文、簡體中文與正體中文三個
子任務，我們參加了其中的簡體與正體中文部份。NTCIR 一向在日本東京 NII
總部舉辦，主要議題探討各種資訊檢索的技術，並設計任務，提供語料供研
究者參加與使用。會議第一天為本屆各任務的介紹，接著幾天就是各任務效
能最佳的隊伍報告各自的技術，同時其他各隊還會有海報 session 的觀摩。 
本次是我們第一次參與此項任務，因此效能與各隊相較，大約在中等的程度。
海報觀摩時段在第三天的下午，但還是有許多隊伍在場互相討論與交流，也
見到有些隊伍將技術開發為系統。由於大家都是在同一份語料上處理同一個
問題，因此在此一會議中，各隊互相討論都相當聚焦，也很清楚對方在做什
麼，這應該是跟其他會議較為不同之處。 
二、與會心得 
過去都是協助辦理 NTCIR 的相關任務，這次是第一次單純以參加隊伍的身份
在會議與各研究人員討論。除了遇到許多過去認識的研究者並討論目前的研
究方向外，也能專心去看各隊伍提出方法的長處，及處理同樣問題的思考模
式，是相當愉快的經驗。 
會中有些隊伍將演算法的各個步驟由系統呈現出來，可以即時檢驗結果與問
題，並當場與有興趣的其他與會者討論，這種作法相當有效率，將來我們的
系統也可以考慮用類似的方式來呈現研究技術與處理的結果，讓更多的其他
研究人員了解我們所提出的方法。 
三、發表論文全文或摘要 
NTCIR-9 RITE task evaluates systems which automatically detect entailment, 
paraphrase, and contradiction in texts. The Yuntech team developed a preliminary 
system for the NTCIR-9 RITE task and was described in this paper. The major 
aim of this system was to determine the type of the relation of two sentences.  A 
straightforward assumption was proposed for achieving this aim: the relation 
between two sentences was determined by the different parts between them 
instead of the identical parts. Therefore, we considered features including 
sentence lengths, the content of matched keywords, quantities of matched 
keywords, and their parts of speech to capture the difference between two 


3. For the MC subtask in Run 2, an additional criterion was added 
in the gray rhombus: 
3. Whether the number of identical words of the POS selected 
in criterion 1 exceeded 5. 
Adding this criterion in MC will add weights to the identical parts 
of two sentences. 
 
Figure 1. System flow for the BC subtask 
 
 
Figure 2. System flow for the MC subtask 
3. Experiment 
As the proposed system was rule based, the training sentence 
pairs were used only to do minor adjustments in the design of 
rules. Then these rules were applied directly on the testing 
sentence pairs. The proposed system was developed on traditional 
Chinese materials. Simplified Chinese sentences were translated 
into traditional Chinese ones before processing in our system.  
3.1 Mapping Rules for BC in Run 2 
As mentioned in section 2, we utilized the MC type results in Run 
1 to generate BC results for Run 2 directly. The mapping rules are 
as follows: 
1. Type F in MC Run 1 was mapped to type Y in BC Run 2. 
2. Type B in MC Run 1 was mapped to type Y in BC Run 2. 
3. Type R in MC Run 1 was mapped to type Y in BC Run 2. 
4. Type C in MC Run 1 was mapped to type N in BC Run 2. 
5. Type I in MC Run 1 was mapped to type N in BC Run 2. 
Note that the third mapping rule was not a correct one. In fact, 
type R in MC should be mapped to type N in BC. For sentence 
pairs of type R, T1 cannot infer T2 by definition. 
3.2 Experimental Results 
Table 1 shows the experimental results of two runs. Run 1 
achieved better results than Run 2. For the BC subtask, Run 1 
performed better than Run 2 because one of the mapping rules 
was incorrect. If we fixed the rule, their results became 
comparable. For the MC subtask, Run 1 performed better than 
Run 2 suggested that giving more weights to the identical parts 
would not contribute to the performance, which responded to our 
assumption. Generally, the proposed preliminary system can 
compete some other systems in the traditional Chinese (TC) MC 
subtask, though the results were not good enough in other 
subtasks. In Table 2-5, the detail results from the confusion 
matrixes of Run 1 are shown further. 
Table 1. Accuracy of Run 1 and Run 2  
for the BC and MC subtasks 
         Accuracy
Run BC (CS) BC (CT) MC (CS) MC (CT)
1 0.636 0.528 0.528 0.477 
2 0.560 0.524 0.398 0.388 
 
Table 2. Confusion matrix of the BC subtask 
(simplified Chinese,  run 1) 
         Answer
System Y N  
Y 243 128 371 
N 20 16 36 
 263 144  
 
Table 3. Confusion matrix of the BC subtask 
 (traditional Chinese, run 1) 
         Answer
System Y N  
Y 404 379 783 
N 46 71 117 
 450 450  
 
 
 
 
YES
NO 
Find words of POS VA, VC, VCL, VH, VJ, Nb, Nc
Load Sentences T1&T2 
Meet any 
criteria? 
BC:Y 
BC:N
NN 
Y Y 
Load Sentences T1&T2 
Give default type according to the lengths of T1&T2
T1>T2, MC: F; T1=T2, MC:R, T1<T2, MC:B 
Find words of POS Nb, Nc, Nd, Neu, Ncd, VA, VC, 
VH, VJ. Find the negation words. Find the number 
of identical word-POS pairs between T1&T2. 
Meet any 
criteria? 
Give MC: F, R, B  
according to default types 
MC: I 
Meet 
criterion I? 
MC: C
5. The additional keywords did not provide additional 
information but restricted the meaning of modified words 
instead. Usually these keywords, referring to the different 
things in two sentences, are very similar, i.e., having the 
same subsequences. Words with underlines in the following 
examples show these subsequences. 
For example, 
  <pair id="115" label="N"> 
 t1:2004年 聽障 奧運 (Deaflympic) 在雅典舉行 
 t2:2004年 奧運 (Olympic) 在雅典舉行 
 
  <pair id="157" label="N"> 
 t1:2005 年 7 月 7 日倫敦地鐵爆炸事件是在「利物浦街站」
(Liverpool St. Station) 附近的地鐵「都會線」(Metropolitan 
line) 爆炸 
 t2:2005 年 7 月 7 日倫敦地鐵爆炸事件是在「利物浦」
(Liverpool) 爆炸 
4.2 Error Analysis for the MC Subtask 
For the MC subtask, our system performed satisfactory for 
identifying forward entailment (F), paraphrase (B), and reverse 
entailment (R) types but badly for contradiction (C) and 
independence (I) types. The proposed system often mis-judged 
the contradiction type (C) as the paraphrase (B). This is because 
two sentences look very similar (usually only one difference) but: 
1. The positions of identical words were different in two 
sentences, and there was no other different words or too few 
to determine them as a contradiction. This happened also in 
the BC subtask. 
For example, 
<pair id="565" label="C"> 
t1:20030501 台北市立 (Taipei) 和平醫院護理長陳靜秋因照顧
SARS 病患被感染於林口  (Linkou) 長庚醫院 (Chang Gung 
Hospital) 病逝 (passed away) 
t2:20030501 林口  (Linkou) 和平醫院護理長陳靜秋因照顧
SARS病患被感染於台北市立 (Taipei) 長庚醫院 (Chang Gung 
Hospital) 病逝 (passed away) 
 
  <pair id="786" label="C"> 
 t1:美國認為伊拉克具有  (has) 生化武器  (biochemical 
weapon)，甚至 (even) 可能發展核子武器 (nuclear weapon)  
 t2:美國認為伊拉克具有 (has) 核子武器 (nuclear weapon)，甚
至 (even) 可能發展生化武器 (biochemical weapon) 
 
2. No thesaurus or resources were involved in our system. 
Therefore, it had no ability to recognize synonyms (女兒, 千
金, daughter) and antonyms (反感, disfavor, 好感, favorable) 
so that further judgments based on them were not feasible. 
 
3. The processing of Chinese numbers and units of 
measurement was still an issue for the MC subtask. They 
needed to be converted into the same form. 
 
It was difficult to find rules to identify the independence type (I) 
because various sentences could be of this type. Those sentence 
pairs of type I were wrongly judged as F, B and R types in our 
system, and this was because the decisions of this type were made 
mainly according to the sentence lengths since there was no other 
suitable rule to apply. 
5. Conclusion and Future Work 
We have designed a preliminary system which considered the 
different parts of a sentence pair to tell whether the first one can 
infer the second one or to determine the type of sentence relations. 
This simple rule-based system gave an overall passable 
performance and even a good performance for some types, but 
there was much room for improvement. Considering the order of 
words and modifying relations, involving thesaurus and resources, 
and converting numbers and units are some possible directions for 
instant improvements.  
We found some important clues in the process of designing rules 
for our system. Therefore, beside the mentioned quick 
improvements, our next step is to utilize these clues by a learning 
process to implement a better rule-based, machine learning or 
hybrid system for determining types of sentence relations. 
After the analysis, we also found that errors were due to two 
major phenomena: the alternation of the sentence meaning and the 
occurrence of the additional information. We will focus on 
observing the characteristics of these two phenomena to solve the 
system errors in the future and enhance the system performance. 
6. ACKNOWLEDGMENTS 
Research of this paper was partially supported by National 
Science Council, Taiwan, under the contract NSC 100-2218-E-
224-013-. 
7. REFERENCES 
[1] H. Shima, H. Kanayama, C.-W. Lee, C.-J. Lin, T. Mitamura, 
Y. Miyao, S. Shi,  and K. Takeda. Overview of NTCIR-9 
RITE: Recognizing Inference in TExt. In NTCIR-9 
Proceedings, to appear, 2011. 
[2] CKIP Chinese word segmentation system. 
http://ckipsvr.iis.sinica.edu.tw/ 
[3] CKIP (Chinese Knowledge Information Processing Group). 
(1995/1998). The Content and Illustration of Academica 
Sinica Corpus. (Technical Report no 95-02/98-04). Taipei: 
Academia Sinica. 
 
 
100年度專題研究計畫研究成果彙整表 
計畫主持人：古倫維 計畫編號：100-2218-E-224-013- 
計畫名稱：個人化文本情緒分析於智慧居家情境建構之研究 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 4 3 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 3 2 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
