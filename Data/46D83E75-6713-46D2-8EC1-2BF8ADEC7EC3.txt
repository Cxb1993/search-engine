bus is used to provide an assessment of estimation of 
the requirement level of buses to the transportation 
center. In addition to construct the system of the 
estimation of the number of people waiting for bus on 
the DSP development board and integrated in the smart 
bus transportation system. The traffic information 
which the subproject collected will be send back to 
the central control station, and the station will 
make the decision of the period of sending buses and 
the vehicle type of the sending buses. Therefore we 
can efficiently reduce the rate of empty bus by 
sending buses with appropriate size in an appropriate 
time. The information from the system of counting the 
number of people will play an important role in the 
solution of the traffic jam 
英文關鍵詞： Intelligent Bus Transportation System, Image 
Recognition, Crowd Estimation 
 
 2 
一、 本階段研究計畫之目的及成果 
本研究報告為國科會一般型研究計畫「下世代智
慧型公車運輸系統之研發-子計畫一: 影像辨識技術
應用於智慧型公車運輸系統之設計與研發(II)」之期末
研究成果報告。在本年度的計畫進行到此，將對以往
的方法進行改良的同時，了解到光學鏡頭對此類型系
統之極限，從而決定了所要採用的方法。在本年度不
但完成了人數估測系統之外，也將其轉錄至 DSP開發
板上，除了完成本計畫所需要的影像處理技術函式外，
更透過對系統流程的了解，重新建立基本函式庫，以
及基於此基本函式庫所建立出來的更高階的函式庫，
並進行了靜態測試。此外，在本階段將同時針對訊息
傳遞進行開發，本計畫將利用藍芽傳輸的方式進行人
數統計的傳遞，將本子計畫所計算的人數傳達給系統
後端，以利進行後續處理。 
在本年度的時間裡，我們除了強化了原始的演算
法並使用了 DSP開發模組，更完成了本系統網路平台
通訊方式的協調。最終，我們進行長時間的戶外架設，
測試白天、傍晚以及夜晚等不同的影像，以確定本系
統能夠克服日夜間的光照環境不同，以及不同天氣所
帶來的影響，透過這些實驗，來證明本系統具有克服
多種光照環境的能力， 
二、 研究發展及進行步驟 
在本年度的計畫中，所預計要完成的進度如下：
(1)建構影像估測候車人數之原型，(2)進行系統原型的
靜態功能測試，(3)系統原型的修正與強化，(4)影像估
測候車人數系統在 DSP開發板上的實現，(5)與其他子
計畫進行系統網路平台通訊方式的協調；於期中時的
進度中，(1)至(4)項已經有一定的完成度，期末之前，
我們除了完成前四項外，也達成了最後的第五項目標，
並進行了實際的測試，以驗證本系統傳輸資訊的可行
性，在接下來的報告中將會呈現完成的介紹。 
2.1系統原型的修正與強化 
 透過第一年執行計畫所得的經驗顯示，以光學影
像為基礎的候車系統，須要能夠經得起不同時段或者
是不同天氣對於環境光線的影響，因此在背景模型的
建立上，我們挑選不同天氣以及不同時段的影像作為
背景，總數量達到數十張，而在影像輸入系統之後，
透過截取輸入影像的局部天空區塊，來分析現在的天
候與背景中哪一幅背景較為相近，再透過灰階影像的
直接背景相減法來取得前景。 
然而這樣的作法在實際分析上遭遇到很大的困
難，除了背景資料庫過度龐大冗餘之外，最明顯的問
題就在於對光影變化的敏感性極高，雖然短時間內影
響尚在可以修正的範圍內，但是將實驗時間延伸到半
天，甚至一天之後，前景切割的結果將令人難以分析。 
以灰階影像直接進行背景相減運算，首先得要設
計一個臨界值來判斷該點像素與背景相比是否類似，
倘若答案為真，則判斷該像素為背景，否則為前景
[1][2]，這類作法的優點在於速度快，以及實現容易；
但是缺點就在於判斷一個像素為前景或者是背景的機
制難以決定；此外，因為直接背景相減運算之後，所
得的資料基本上就是一群連通區塊，利用這些連通區
塊的輪廓，以及頂部曲線(作為後續分析的頭肩部曲線)
來分析該區塊是否為人類，而這個作法有些很重要的
前提在於目前所分析的連通區塊真的為人類，以及行
人與行人之間少有重疊，否則這個方法都產生誤差，
例如車道上急駛而過的車輛，其車燈所照射出來的三
角錐狀光柱，在直接背景相減運算中無可避免地被保
留為前景，並且因為其外型酷似側面人型，而被判斷
為行人，又或者車燈照射範圍擴大，涵蓋了大部分等
車區，而使得相減運算之後只留下一個很大塊的連通
區域，細節完全消失，而更直接的缺點則是所切割出
來的前景區塊雖然包含了一個行人在裡面，但是因為
陰影以及其他因素，而使這個只包含單一行人的區塊
完全不具有人型的特點；因此，經過實驗之後，發現
該作法的前提雖然有時候可以滿足，但是卻非日常生
活中的通例，雖然可以用其他演算法為了保留這種作
法的優點，並且修正其在本系統中所產生的缺陷，但
是所耗費的運算成本也因此提高許多，所以有必要從
另一個角度來解決人數計算系統的問題。 
經過分析之後，我們決定採用「梯度背景相減法」，
透過將原始影像進行梯度運算，在利用其梯度數值進
行相減，所取得的資訊則是邊緣強度資訊，接下來將
呈現此方法對於本系統所產生的優點。 
 4 
例，先將影像轉換為灰階之後，進行梯度運算以得到
梯度大小影像，再將此影像與梯度背景相減，可得到
圖 2(c)，這張影像黑色的部分其數值為負，因為在輸
入影像中，該部分區塊的梯度小於背景之梯度，因此
在相減之後會呈現負值；在此得要注意，負值的結果
就代表著輸入影像在該區域表現較為平滑，因此相較
於我們所要尋找的「輪廓」或者「邊緣」而論，這些
區塊自然就不是我們所要尋找的對象，透過濾除掉這
些呈現負值的區塊，可以得到圖 2(d)，在這張圖的結
果中可以發現行人的邊緣被大部分地保留了下來，而
其他區塊，像是地面這種比較穩固的對象，其運算結
果幾乎都降到可以忽略的程度，因此我們現在則可以
將注意力集中在明顯的輪廓上，這些輪廓也就是我們
接下來所要分析的前景元素。 
2.1.2 以虛擬立體空間建立感興趣區域 (region of 
interesting, ROI)遮罩 
在實地拍攝場景中，可以發現同一個物體從左下
角移動到右上角時，其身影由大變小，由此可以知道
即使是一個物體，在影像中也會呈現不同的大小，此
即透視幾何上的影響，因此，若要在影像中建立 ROI
必須要考慮到空間中的透視幾何所造成的干擾，否則
在計算人數的時候可能會有很大的誤差，會將非行人
的物體判斷為是行人，或者是將行人判斷為非行人，
這些都不是我們希望的結果。 
為了建立此 ROI，我們將攝影機放置在固定位置
之後，利用實際拍攝的影片來建立一個基於這個場景
中的透視幾何所產生的縮放係數，如前所述，物體由
左下角往右上角移動時，身影由大變小，這個因透視
幾何而起的變化，可以透過追蹤一個特定標的來建立
出一個虛擬的透視空間(圖 3)，考慮到候車區域僅侷限
在人行道範圍，因此只對單一消失點製作 ROI遮罩。 
  
(a) (b) 
  
(c) (d) 
  
(e) (f) 
 
(g) 
   
 
(h) 
圖 3虛擬透視空間 ROI遮罩。(a)-(f)建立虛擬透視空間所
採用的影像；(g)合成路徑影像及 ROI遮罩；(h)前中後景
ROI互相有重疊區域。 
 
 6 
張擴增模板。 
 
 
 
 
(a) 
 
(b) 
 
(c) 
圖 6 樣板與輸入影像迴旋積之結果。(a)採用的樣板以
與輸入影像迴旋積示意圖；(b) 迴旋積之後的結果；(c)
假色處理(pseudo-color)結果。 
樣板得到之後，可以利用此樣板來找出目前所處
理的影像中是否有包涵此樣板的區塊存在，方法就是
將樣板與目前所輸入的影像進行迴旋積分(圖 6(a))，倘
若某位置經過運算後所出現的數值相較起其他區域的
數值要來的高的話，那麼就代表著此模板在該區域出
現的機會也會提高；為了在每張未知影像上都能有相
同的表現，我們將每張迴旋積分的結果正規化，使最
小數值為零，最大數值為一，如此一來，我們可以設
定一個臨界值，例如 0.9，藉此將迴旋積分結果變成二
值影像，而在此二值影像中，前景區塊就代表著與人
型樣板匹配程度很高，反之則不太可能是人型樣版出
現的區塊。 
圖 6(a)中，輸入影像已經經過了全域 ROI框選處
理範圍，透過與樣板的迴旋積分之後，可以發現在影
像中間偏右的人頭出現了很高的峰值(圖 6(b))，同時
也可以參考圖 6(c)的粉紅色區塊，兩者所代表的視同
一張影像，圖6(c)只是以色彩突顯出數值大小之差異；
透過更多樣板的處理之後，將有機會找出單張影像中
存在幾個等車的行人。 
2.1.4 均值飄移演算法(mean shift algorithm) 
在行人計算系統中，所遇到的最重要的問題就在
於行人間的遮蔽，因為這個原因，所以沒有辦法擷取
出完整的人型，對於這一個問題，我們並非採取切割
人型的方式來決，而是找出可能出現人型的位置，因
此最後出現的資訊是一個點集合，透過分析此點集合
之密度集中趨勢，可以嘗試算出影像中人型的可疑區
域；因此，透過使用均值飄移演算法[11]，在系統已
經標記出多個可疑區塊的中心並且透過這些中心點座
標形成點集合，之後以均值飄移演算法對此集合做處
理，以找出在當下的影像中，點集合共可以分成幾群。 
在此只簡單介紹均值飄移演算法，假定所取得的
離散資料都是取樣自一個密度函數，則此演算法的目
的就在於在這密度函數中尋找最大值，因此對於偵測
密度分布的模式；在假定一個起始資料 x之後，建立
一個核函數 )( xxK i − ，這個核函數的目的在於重新估
測 x周邊資料之均值，這是因為考量到 x周邊資料與
x之間的距離會影響到這些周邊資料對於均值的貢獻
程度，而通常這個核函數會以高斯函數方式表示，最
後這個由 K 所決定的在這個視窗範圍內的加權均值
將如下式所示： 
∑
∑
∈
∈
−
−
=
)(
)(
)(
)(
)(
xNx i
xNx ii
i
i
xxK
xxxK
xm  (2) 
)(xN 代表著 x的周邊資料，且當 )(xNxi ∈ 時，
 8 
影片的訊框數目約有 1800張，因為每秒有 24張影像
被存取起來，所以影片時間約略有一分多鐘左右，透
過每隔五秒擷取一張影像，來分析該張影像中的行人
數量共有多少： 
 
(a) 
 
(b) 
 
(c) 
 
(d) 
圖 10 日間夜間分析結果。(a)日間影片之首張影像；
(b)日間分析結果；(c)夜間影片之首張影像；(d)夜間分
析結果。 
自日間與夜間各取十張連續影像進行分析，每張
影像間隔五秒，在分析過程中會發現數值並不是很穩
定，除了系統在分析上的障礙，例如人與人的互相遮
蔽，致使人數下降之外，還有就是過往行人對候車人
數估測之影響也很大，在圖 10(b)以及圖 10(d)中，我
們可以發現有幾個數值在直方圖中相對地突出，這是
因為候車的人的行為所導致的結果，因為人們候車時
總是保持著相同的姿勢或者是位置，因此雖然人來人
往會導致數值上有所差異，但是因為已經透過限制候
車區域 ROI，因此過往行人被計算進入候車人數中的
情況下降了一些，雖然仍有一定的影響力，但是可以
假設候車人數在較長時間的分析中，應該會是數值較
為突出的數字，由圖 10(a)可以得知此數值是 5，而在
圖 10(c)中則是 6和 7。 
分析其原因，在於日間的情況中，候車的人並沒
有固定站或者是做在某個位置上，因此計算上較實際
人數多出一人；而在夜間的情況，則是因為有一人被
柱子擋住，然而偶爾會因移動而顯出他的身型，故在
直方圖上呈現了雙峰值，在此直接以最大數字 7作為
此例之輸出。 
 
 
 10 
 
  
圖 14 頭肩部曲線模板。 
3.4 靜態功能測試 
計畫進行一年以來，除了根據之前的經驗重新設
計系統之外，並且完成了建構本系統所需要的基於
DSP開發板的所有函式庫。而本計畫靜態功能測試的
部份，其錯誤率的計算公式如方程式(3)所示，其意義
是在每一張影像中可能會估測錯誤的人數。 
平均錯誤率 =  |實際人數−系統估測人數|
實驗影像張數
 (3) 
在本計畫的實驗呈現中(圖 15)，我們以每 5秒擷
取一張影像來進行人數估測，在白天的部分共使用了
158張影像，統計估測人數之錯誤率大約為 0.7，即在
白天的每張影像中可能會比實際人數多或少算了 0.7
個人。在傍晚與晚上的部分共使用了 133張影像，由
於光線較不足的關係，統計估測人數之錯誤率大約為
0.9，即在傍晚與晚上的每張影像中可能會比實際人數
多或少算了 0.9 個人。由實驗結果可以得知，在複雜
與光線不足的場景中，本系統依舊保有足夠的可信度，
且對於日夜變化也能有一定的容忍度。 
 
(a) 
 
(b) 
圖 15 人數計算實驗結果。(a)白天實驗結果；(b)夜間
實驗結果。 
3.5 另一個站牌的實驗測試 
 除了原先的站牌之外，我們額外挑選了鄰近的另
一站牌做為實驗對象，實驗結果如圖 16所示。 
 
(a) 
 
(b) 
圖 16 另一場景之靜態測試。(a)實驗場景；(b)實驗結
果直方圖。 
 12 
Conf. Computer Vision and Pattern Recognition, vol. 
2, pp. 886-893, 2005. 
[5] Q. Zhu, S. Avidan, M.C. Yeh, and K.T. Cheng, 
“Fast human detection using a cascade of histograms 
of oriented gradients,” in Proc. of IEEE Conf. 
Computer Vision and Pattern Recognition (CVPR 
'06), Vol. 2, pp. 1491-1498, 2006. 
[6] Q. J. Wang and R. B. Zhang, “LPP-HOG: A new 
local image descriptor for fast human detection,” 
IEEE International Symposium on Knowledge 
Acquisition and Modeling Workshop, pp.640-643, 
2008.  
[7] F. Xu, and M. Gao, “Human detection and tracking 
based on HOG and particle filter,” Image and Signal 
Processing (CISP), pp.1503-1507, 2010. 
[8] X. Ding, H. Xu, P. Cui, and L. Sun, “A cascade 
SVM approach for head-shoulder detection using 
histogram of oriented gradient,” IEEE International 
Symposium on Circuits and Systems,  
pp.1791-1794, 2009. 
[9] M. Arie, A.Moro, Y. Hoshikawa, T. Ubukata, K. 
Terabayashi, and K. Umeda, “Fast and stable human 
detection using multiple classifiers based on 
subtraction stereo with HOG features,” IEEE 
International Conference on Robotics and 
Automation (ICRA), pp.1050-4729, 2011. 
[10] C. Yibo, S. Lifeng, and Y. Shiqiang, “Pedestrian 
detection using improved histogram of oriented 
gradients,” International Conference on Visual 
Information Engineering, pp.388-392, 2008. 
[11] D. Comaniciu and P. Meer, “Mean shift: A Robust 
Approach toward Feature Space Analysis,” IEEE 
Trans. Pattern Analysis Machine Intelligence, Vol. 
24, no. 5, pp. 
個會場，雖然輕鬆了一些，但是依舊需要兩頭奔跑，解釋兩篇論文的內容以及演算
法；第一次出國參加研討會並且用英文解釋自己的論文，有點緊張，在這過程中許
多研究相關領域的與會人士問了許多問題，除了指出系統中可能存在的錯誤之外，
也給了我許多建議，獲益良多。 
  
(a) (b) 
  
(c) (d) 
  
(e) (f) 
圖 1 2012 ICIEA 紀錄照片。 (a) poster會場；(b) 我以及我報告的論文；(c) 我以及我報告的論文；
(d) 參加的台灣研究生；(e) 參加的台灣研究生；(f) 參加的台灣教授。 
 
 
 
12/8/5 Gmail - Paper P0259 has been Accepted for ICIEA 2012
https://mail.google.com/mail/u/0/?ui=2&ik=9cff0c274e&view=pt&q=ICIEA&qs=true&search=query&m…
洪裕筆 <upen24931251@gmail.com>
Paper P0259 has been Accepted for ICIEA 2012
ICIEA 2012 <iciea2012@elite.sg> 2012年2月7日上午9:37
回覆：iciea2012@elite.sg
收件者： upen24931251@gmail.com
副本：iciea2012@elite.sg
Dear Mr. Yu-Bi HONG
 Paper ID : P0259
 Paper Title : X-ray Inspection Image Enhencement Using Shearlet Transform
The review process for the 7th IEEE Conference on Industrial Electronics and Applications (ICIEA 2012) has
been completed. All the papers submitted to the conference from 49 countries/regions were peer reviewed by
international experts.
Based on the recommendations of the reviewers and the Technical Program Committee, I am very pleased to
inform you that your paper identified above has been accepted for presentation in ICIEA 2012. You are
cordially invited to present the paper at ICIEA 2012 to be held between July 18 - 20, 2012 in Singapore.
This notification email serves as our formal acceptance of your paper as well as an invitation to present your
work at ICIEA 2012. Please note that this email will be sent to your co-authors as well.
Detail information on the preparation of the final paper, conference registration, etc., are/will be posted at
http://iciea.elite.sg/2012/ under the Authors Information's page.
Your login details are as follows:
    Author ID: 2012A2403
    Password: 395FC8DE
The acceptance of your paper is made with the understanding that at least one author will register and attend
the Conference to present the paper. In order for your paper to be included in the conference proceedings, we
require that:
   1. your Final Manuscript must be prepared using the ICIEA 2012 template and IEEE Xplore-
compatible;
   2. the final PDF file and abstract in plain text are uploaded to the conference website by 31 March 2012;
   3. the Copyright Transfer Form for your paper is received by 07 April 2012;
   4. the Registration with payment is received by 15 April 2012.
If the above requirements are not met by the set deadlines, the paper will not be published in the
conference proceedings. It is our obligation to eliminate 'no shows' if at all possible since missing
presentations cause a lot of disruptions in a session and disappoint the attendees who spend a significant
amount of time, money, and effort to come to your presentation.
Please note that the submission of your final paper should correspond to your Paper ID, ie, P0259.pdf. Please
strictly adhere to the format given in the template for ICIEA 2012 while preparing your final paper.
In addition to excellent technical sessions, we will also have stimulating and enriching keynote speeches by
renowned researchers. For the most updated information on the conference, please check the conference
website at http://www.ieeeiciea.org/. The Preliminary Program will be available at the website in early May
2012.
12/8/5 Gmail - Paper P0536 has been Accepted for ICIEA 2012
https://mail.google.com/mail/u/0/?ui=2&ik=9cff0c274e&view=pt&q=ICIEA&qs=true&search=query&m…
洪裕筆 <upen24931251@gmail.com>
Paper P0536 has been Accepted for ICIEA 2012
ICIEA 2012 <iciea2012@elite.sg> 2012年2月7日上午9:38
回覆：iciea2012@elite.sg
收件者： upen24931251@gmail.com
副本：iciea2012@elite.sg
Dear Mr. Yu-Bi HONG
 Paper ID : P0536
 Paper Title : Differential Count of White Blood Cell in Noisy Normal Blood Smear
The review process for the 7th IEEE Conference on Industrial Electronics and Applications (ICIEA 2012) has
been completed. All the papers submitted to the conference from 49 countries/regions were peer reviewed by
international experts.
Based on the recommendations of the reviewers and the Technical Program Committee, I am very pleased to
inform you that your paper identified above has been accepted for presentation in ICIEA 2012. You are
cordially invited to present the paper at ICIEA 2012 to be held between July 18 - 20, 2012 in Singapore.
This notification email serves as our formal acceptance of your paper as well as an invitation to present your
work at ICIEA 2012. Please note that this email will be sent to your co-authors as well.
Detail information on the preparation of the final paper, conference registration, etc., are/will be posted at
http://iciea.elite.sg/2012/ under the Authors Information's page.
Your login details are as follows:
    Author ID: 2012A2403
    Password: 395FC8DE
The acceptance of your paper is made with the understanding that at least one author will register and attend
the Conference to present the paper. In order for your paper to be included in the conference proceedings, we
require that:
   1. your Final Manuscript must be prepared using the ICIEA 2012 template and IEEE Xplore-
compatible;
   2. the final PDF file and abstract in plain text are uploaded to the conference website by 31 March 2012;
   3. the Copyright Transfer Form for your paper is received by 07 April 2012;
   4. the Registration with payment is received by 15 April 2012.
If the above requirements are not met by the set deadlines, the paper will not be published in the
conference proceedings. It is our obligation to eliminate 'no shows' if at all possible since missing
presentations cause a lot of disruptions in a session and disappoint the attendees who spend a significant
amount of time, money, and effort to come to your presentation.
Please note that the submission of your final paper should correspond to your Paper ID, ie, P0536.pdf. Please
strictly adhere to the format given in the template for ICIEA 2012 while preparing your final paper.
In addition to excellent technical sessions, we will also have stimulating and enriching keynote speeches by
renowned researchers. For the most updated information on the conference, please check the conference
website at http://www.ieeeiciea.org/. The Preliminary Program will be available at the website in early May
2012.
  
X-ray Inspection Image Enhencement Using Shearlet 
Transform
Sheng-Fuu Lin 
Dept. of Electrical Engineering 
National Chiao Tung University 
Hsinchu, Taiwan  
sflin@mail.nctu.edu.tw 
Tung-Ying Wu 
Dept. of Electrical Engineering 
National Chiao Tung University 
Hsinchu, Taiwan  
tonyingwu@gmail.com 
Yu-Bi Hong 
Dept. of Electrical Engineering 
National Chiao Tung University 
Hsinchu, Taiwan 
upen24931251@gmail.com 
Abstract— In automatic X-ray inspection, to denoise and 
enhance characteristics is a very important issue for 
application, especially the images used to inspect the wires 
in chips. Because the methods used to enhance or denoise 
may degrade the characteristic of the wires which can be 
seen as curves such that the efficiency is not enough. 
Shearlet has been approved of its perfect performance on 
curve description. In this paper, the method is applied and 
the method of coefficient modification is used. As a result, 
it shows that the wires are effectively enhanced while the 
noise is also attenuated. 
 
Keywords-X-ray, shearlet transform inspection 
I.  INTRODUCTION  
X-ray has been used not only in medical use, but in 
industrial applications in recent years by higher requirement 
on production quality. Such as the application on inspecting 
wire bounding in a chip after packaging, and the wires are 
very important to figure out from the background in order to 
classify the bounding quality. Due to the image captured is of 
low contrast, high noise, and occluded, so the X-ray images 
analysis, however, are always be obstructed. Therefore the 
target could not be observed easily.  In order to have higher 
efficiency on oberservation, it has been a key issue to enhance 
and emphasize the curves and other characteristics in X-ray 
images. 
Techniques for enhancing X-ray images have been discussed 
during the past decades with the development of medical use. 
Wavelet is a common method on image processing. Many 
interesting results have been obtained in various fields such as 
image analysis, compression, segmentation, and enhancement 
[1][2][3][4]. Wavelet has some advantages, such as it is easy to 
manipulate the coefficients, and its ROI (Region Of Interest) 
property can make it easy to enhance areas with different 
characteristic based on different criteria. Breast cancer tumor 
detection is one of the medical application of enhancement on 
breast X-ray images [1]. 2D wavelet transform, however,  is 
implemented by means of applying 1D wavelet transform 
along the horizontal direction and vertical direction 
respectively. A planar curve is regarded as piecewise 
combination of the two orthogonal directions and the 
directional information which is very important to a curve is 
not presented on wavelet transform. As a result, hyper-wavelets 
are developed in order to deal with those problems which may 
occur in higher dimensions. For example, ridgelet emphasizing 
the “ridges” in an image [6], and curvelet applies directional 
frequency analysis to avoid losing curve information on other 
directions except for the horizontal and vertical [5].  In this 
paper, a method named as “shearlet” is proposed. Shearlet is an 
affine system with a single generating mother shearlet function 
parameterized by a scaling, shear, and translation parameter 
[7]. Shearlet processes the directional frequency bands of 
images and it has intensive directional sensitivity. Traditional 
wavelet transform can perfectly deal with the point singularities 
but shearlet utilizes the shear parameter capturing the direction 
of singularities [7]. Like wavelet, shearlet provides a multi-
resolution analysis, and the property makes it is easy to develop 
fast algorithm [8]. 
II. SHEARLET TRANSFORM 
A. Continuous Shearlet 
Continuous shearlet can be constructed by combining affine 
system and multi-scale analysis. As in 2 dimension space, 
shearlet can be expressed as 
22/
,, ,,),(|det|)({)( ZkZljkxABAx
jlj
kljAB ∈∈−== ϕϕϕ (1) 
BA, are 2×2 reversible matrices, and  |det| B =1. Matrix A is 
related to scale factor as B is related to keeping area invariant 
when rotating or shear transforming. Let ψ be a continuous 
wavelet with perfect properties, and the wavelet transform of 
function  can be expressed as 
>=< atftaWf ϕ,),(  
 and 
))(()( 11 txaaxat −=
−− ϕϕ  
(2) 
The singularity of f  can be nearly localized. As   
approaches 0, function ),( taWf  can also rapidly goes to 0 
when t  is around the singularities [7]. When BA,  are 
considered, the  singularity can be distinguished in direction. In 
frequency domain, the support is as below : 
                                       
 
(ii) Use PPFFT to compute 
j
df
~
 on a polar grid and the 
result is 
j
dfP
~
. 
(iii) Applying band pass filter such as translating window 
function to 
j
dfP
~
. 
(iv) Use inverse PPFFT on the result from the previous step. 
 
 
(a) 
 
 
 
  
(b) 
Figure 3. (a) Original image (b) 8 images after 1 level 
shearlet transform. 
 
III. SHEARLET ENHANCEMENT AND DENOISE 
An image will be decomposed into j2  sub-band images 
after applying shearlet transforming. Each sub-band image 
contains the directional high frequency component. 
Modification of the detailed shearlet coefficients is an efficient 
method to enhance the image as emphasizing the curves. 
Noise, however, is always a problem and especially in X-ray 
image due to its principle of imaging. Thus, the enhancement 
procedure will also focus on denoising for preventing from 
enhancing the undesired noise. 
A. Detailed coefficient enhancement 
Detailed coefficient comes from the shearlet transform 
result with j2  directional detail information of the image. 
Donoho’s shrinkage method is effective to denoise in detail 
image and the threshold can be computed by [9] 
nthreshold log2⋅= σ  (8) 
where σ  is the variance and n is the number of the 
coefficients. There are two ways to commit shrinkage. One is 
hard shrinkage and the other is soft shrinkage. 
Hard shrinkage: 
⎩⎨
⎧ ≥
=
else
thresholdfiff
y
,0
,  (9) 
Soft shrinkage: 
⎩⎨
⎧ ≥−×
=
else
thresholdfifthresholdff
y
,0
||)|(|)sgn(  (10) 
After noise is attenuated by shrinkage, salient coefficients 
are left. We have to design an enhancing function 
)( denoiseenhance fgy =  (11) 
)(⋅g is a continuous enhancing function and )(⋅g  has the 
properties: 
(i) )()( bgag >  if ba > ; 
(ii) )(lim)(lim tgtg atat −+ →→ =  
ba, are the detailed shearlet coefficients. 
                                       
 
  
(b) (c) 
Figure 8. (a) Original image of wire area(b) Enhanced image 
with shrinkage threshold 0.3 (c) Enhanced image with 
shrinkage threshold 0.05. with  (d) Enhanced image using 
Wavelet Transform method. 
 
  
(a)  
  
(b) (c) 
Figure 9. (a) Original image of wire area(b) Enhanced image 
with shrinkage threshold 0.3 (c) Enhanced image with 
shrinkage threshold 0.05. (d) Enhanced image using Wavelet 
Transform Fusion method.  
 
The evolution to the result of enhancement can use the 
Michelson Contrast Index (MCI), [10] 
minmax
minmax
Michelson LL
LLC
+
−
=
 (14) 
The MCI of the original image is 0.461 and the image after 
Wavelet Transform enhancement is 0.572. The MCI of the 
image after Shearlet enhancement with shrinkage threshold 
0.05 is 0.602 and MCI of the shrinkage threshold  0.3 is 0.611. 
IV. CONCLUSION AND FUTURE WORK 
The figures and the MCI show the final result after 
enhancing. Comparing to the original, the wires with curve 
shape can be obviously enhanced with noise attenuated. 
Shearlet with its perfect performance on curve can be more 
effective on application than other methods such as wavelet, or 
grayscale enhancement.  
Considering the limit of X-ray image, contrast and 
brightness are always the problem for automatic inspection and 
the enhancing function may vary with the quality of the  
captured images. It can be an issue to develop an adaptive rule 
for the enhancing functions based on application requirement. 
ACKNOWLEDGMENT 
This work was supported in part by National Science 
Council, Taiwan, R. O. C., under contract No. NSC 100-2221-
E-009-038. The author would also like to thank Industrial 
Technique Research Institute (ITRI) for the support of the 
research. 
REFERENCES 
[1] P. Wei,  J. Li,  S. Zhao,  D. Lu,  G. Chen, “A Method of Detection 
Micro-Calcifications in Mammograms Using Wavelets and Adaptive 
Thresholds,” in the 2nd International Conference on Bioinformatics and 
Biomedical Engineering (iCBBE), Shanghai, pp. 2361 - 2364, May 2008. 
[2] Y. Jin, E. Angelini and A. Laine, Wavelets in medical image processing: 
denoising, segmentation, and registration, J. Suri, D.L. Wilson, S. 
Laximinarayan, Editors, Handbook of Medical Image Analysis: 
Advanced Segmentation and Registration Models, Kluwer Academic 
Publishers, New York, 2004. 
[3] H. C. Sateesh Kumar, K. B. Raja, K.R.Venugopal and L. M. Patnaik, 
"Automatic Image Segmentation using Wavelets," in proc. of IJCSNS 
International Journal on Computer Science and Network Security, vol. 9, 
no. 2, Feb. 2009. 
[4] M.S. Song, "Wavelet Image Compression," Proceedings of the 2005 
Symposium on Great Plains Operator Theory, AMS Contemporary 
Mathematics book series, 2005. 
[5] D. L. Donoho and M. R. Duncan,   "Digital curvelet transform: Strategy, 
implementation and experiments,"  Proc. SPIE,  vol. 4056,  pp.12 - 29 , 
2000. 
[6] D. L. Donoho,   "Orthonormal ridgelets and linear singularities",  SIAM 
J. Math Anal.,  vol. 31,  no. 5,  pp. 1062 - 1099 , 2000 
[7] G. Easley , D. Labate and W.-Q. Lim   "Sparse directional image 
representations using the discrete shearlet transform,"  Appl. Comput. 
Harmon. Anal.,  vol. 25,  p.25 , 2008. 
[8] D. Labate , W. Lim , G. Kutyniok and G. Weiss   "Sparse 
multidimensional representation using shearlets,"  Proc. SPIE,  vol. 
5914,  pp.254 - 262 , 2005. 
[9] D. L. Donoho and I. M. Johnstone "Minimax estimation via wavelet 
shrinkage,"  Ann. Statist.,  vol. 26,  p.879 , 1998. 
[10] E. Peli, “Contrast in complex images,” J. Opt. Soc. Amer., vol. 7, pp. 
2032-2040, 1990. 
                                                                                         
 
Figure.2 illustrate  the blok diagram of our system. As 
shown in this figure, the system has four major parts whose 
details are explained in the next section. 
 
Figure.2 System architeture. 
 
A. RGB channel analysis and adjustment 
Because the un-uniform stain, image of blood smear 
usually appear unitary hue, or incorrect hue. Therefore, take 
hue as a clue of segmentation is hard to accomplish. 
According to visual observation, the saturation can be the 
clue for image segmentation. Before we use the 
transformation equation to transform RGB color space to 
HSL color space (1), we have to correct the disadvantages 
from un-uniform. 




























ogro
orbo
obgo
obgo
o
h
240
minmax
60
120
minmax
60
360
minmax
60
0
minmax
60
0
 





max
minmax
0
s  
(1) 
Max and min mean the maximum and minimum values 
in R, G, and B elements. 
Figure.3 shows the RGB channels of a blood smear 
image, and the modified B-channel. Because histogram of 
B-channel has the trend to high gray-level, the result of 
transformation equation of S-channel will not meet the 
intuition. 
 
Figure.3 RGB analysis and adjustment. 
 
B. Segmentation of white blood cell 
After modification of RGB color space, we use (1) to 
transform color space to HSL. For proceeding region growth, 
we must set a group of seeds. This pre-process can be 
accomplished by setting a threshold to the S-channel. 
According to experiments, the applicable threshold is 
located in [0.7 0.85]. The results of threshold will be 
displayed in Fig.4. 
  
(a) (b) 
Figure.4 The result of threshold of S-channel. (a)with 
original RGB color space; (b)with modified color space. 
 
Based on the truth that the nucleus should be the much 
large region, so we filter out the small regions which smaller 
than 150 pixels.  
The process above may cause over filtering (Fig.5), 
therefore we proceed a region growth method to reduce the 
probability of over filtering. The algorithm of region growth 
describe in Table.1. 
 
                                                                                         
 
 
Figure.7 The result of re-description. 
 
D. The classification of the complete nucleus 
The features we used here for classifying the complete 
nucleus consist of two categories mentioned in [5]. One is 
shape feature, the other is texture feature. For directly 
distinguishing granulocyte from others, we present a shape 
feature which is about the number of lobes of nucleus.  
Table.1 The feature we used 
Category of 
Feature 
Table Column Head 
Shape 
(1)relative area with RBC 
(2)variance of boundary curvature 
(3)variance of the distance of center to boundary 
(4)roundness 
(5)solidity 
(6)number of lobe 
texture 
(1)energy 
(2)contract 
(3)correlation 
(4)entropy 
(5)homogeneity 
Number of lobe is a important feature to discriminate the 
granulocyte from other cells, like lymphocyte, and monocyte. 
For extraction this feature, we apply the distance 
transformation and mean-shift algorithm to analyze the 
number of lobe of nucleus. 
The process of distance transformation is displayed in 
Figure.8. We normalize the result of distance transformation, 
and set multiple thresholds to know which regions have 
much larger value. These regions will be the candidates of 
the lobes of nucleus. 
      
(a) (b) (c) (d) (e) (f) 
Figure.8 Threshold of distance transformation. (a)original 
image; (b) threshold value 0.4; (c) threshold value 0.45; (d) 
threshold value 0.5; (e) threshold value 0.55; (f) threshold value 
0.6; 
For each threshold operation, we can get some region that 
higher than the threshold. Using these centers of regions as 
the input of mean-shift algorithm to analyze the dense of 
these points, and find out how much clusters of these points 
exist. The number of cluster will be the number of lobes. 
III.  EXPERIMENTAL RESULT 
This section used to verify the contribution of this paper 
by experiment, divided into three parts: 1) the white blood 
cell image segmentation nucleus, 2) re-description of white 
blood cell nuclei, and 3) classification of white blood cell 
nucleus. 
A. The white blood cell image segmentation nucleus 
As a comparison, the paper cite [2] as well as several 
traditional ways to cut white blood cell nuclei image, like 
Otsu method[3] and Niblack method[4], and experiment in 
different situation (Table.1). 
Table 2. The white blood cell nucleus image segmentation 
image\methods expert 
This 
paper 
[2] Otsu Niblack 
(a) no overlapping 1 1 1 2 2 
(b)Overlapping 1 1 1 4 3 
(c)Non-uniform 
dyeing 
1 1 3 5 5 
(d) Non-uniform 
dyeing 
1 1 1 5 10 
(e) Underexposed 1 2 2 9 8 
(f) Underexposed 1 1 2 15 19 
 
Because the un-uniform stain, the segmentation method 
of [2], Otsu, and Niblack display poor results. The 
experiment result shows that how important of modification 
of the disadvantage of un-uniform stain. 
B. Re-description of white blood cell nuclei 
For further analysis,  the completeness of a nucleus is a 
necessary condition. We will display what situation that the 
re-description algorithm can solve. 
                                                                                         
 
ACKNOWLEDGMENT 
We are grateful to Dr. Clarire Liu for providing the 
blood smear, and the ground truth information and guidance 
which helped us in significantly improving the paper. 
REFERENCES 
[1] H. Ramoser, V. Laurain, H. Bischof, and R. Ecker, “Leuko-cyte 
segmentationand classification in blood-smear images,” in 27th 
Annual Intern. Conf. of the Engineering in Medicine and Biology 
Society, September 2005, pp. 3371–3374. 
[2] M. Habibzadeh, A. Krzyzak, and T. Fevens, “Counting of RBCs and 
WBCs in Noisy Normal Blood Smear Microscopic Images,” in 
Proceedings of SPIE on Medical Image, Lake Buena Vista, Florida, 
USA, Feb. 2011, vol. 7963, pp. 79633I-79633I-11.I. S. Jacobs and C. 
P. Bean, “Fine particles, thin films and exchange anisotropy,” in 
Magnetism, vol. III, G. T. Rado and H. Suhl, Eds. New York: 
Academic, 1963, pp. 271–350. 
[3] Shi Dongcheng; Kan Guohui; Liang Chao, “An Improved 
Segmentation Method for Color Image,” Intelligent Information 
Technology Application, 2008. IITA ‘08. Second International 
Symposium, vol. 1, pp.453-456, Dec. 2008 . 
[4] J. He, Q. D. M. Do, A. C. Downton and J. H. Kim, “A Comparison of 
Binarization Methods for Historical Archive Documents,” 8th 
international conf. on Document Analysis and Recognition 
(ICDAR05),  pp.538-542, 2005. 
[5] G. Ongun, U. Halici, K. Leblebicioglu, V. Atalay, M. Beksac, and S. 
Beksak, “An automated differential blood count system,” In Proc.Int. 
Conf. of the IEEE Engineering in Medicine and Biology 
Society,volume 3, pages 2583–2586, 2001. 
[6] D. Comaniciu and P. Meer, “Cell image segmentation for diagnostic 
pathology,” Advanced algorithmic approaches to medical image 
segmentation:state-of-the-art application in cardiology, neurology, 
mammographyand pathology, pages 541–558. Springer, 2001. 
[7] Q. Liao and Y. Deng, “An accurate segmentation method for white 
blood cell images,” In Proc. Int. Symposium on Biomedical Imaging, 
pages 245–248, 2002. 
[8] S. Sanei and T. K. Lee. “Bayesian classification of eigencells,” In 
Proc. Int. Conf. on Image Processing, volume 2, pages 929–932, 2002. 
[9] N. Theera-Umpon, and S. Dhompongsa, “Morphological 
granulometric features of nucleus in automatic bone marrow white 
blood cell classification,” IEEE Trans. Inf. Technol. Biomed., 2007, 
11, (3), pp. 353–359. 
[10] M. Adjouadi, N. Zong, and M. Ayala, ”Multidimensional pattern 
recognition and classification of white blood cells using support 
vector machines,” Part. Part. Syst. Charact., 2005, 22, (2), pp. 107–
118. 
[11] H. Ramoser, “Leukocyte segmentation and SVM classification in 
blood smear images,” Int. J. Mach. Graph. Vis., 2008, 17, (1), pp. 
187–200. 
100年度專題研究計畫研究成果彙整表 
計畫主持人：林昇甫 計畫編號：100-2221-E-009-038- 
計畫名稱：下世代智慧型公車運輸系統之研發--子計畫一: 影像辨識技術應用於智慧型公車運輸系統
之設計與研發(II) 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 1 1 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 3 0 100%  
博士生 2 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 2 1 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
