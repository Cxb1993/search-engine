整合配電自動化(DAS)與自動圖資(OMS)之智慧型配電系統規劃與運轉策略研究—
子計畫八：運用粒子群集及其衍伸演算法於配電系統重構問題之研究 
計畫編號：NSC 97-2221-E-027-110  
執行期限：97 年 8 月 1 日至 98 年 7 月 31 日 
主持人：蔡孟伸  副教授  國立台北科技大學自動化科技研究所 
 
摘要： 
本計畫研究初期係研究開發一套配電系統之自動
資料擷取界面輔助系統，透過台電既有的停限電運轉
圖資管理系統(OMS)中之電力設備的電氣連結性及配
電線路之導線、開關、負載等相關表單與屬性資料，
擷取配電系統之相關運轉資料，建立以主開關為連結
性之配電系統模型，並計算饋線開關區段間導線長
度、負載及其他相關饋線線路的參數，同時藉由電力
運轉資料倉儲系統(Data Warehouse)取得配電調度控
制系統(DDCS)之每小時運轉電壓、電流、有效功率及
無效功率，並透過負載潮流計算軟體(LFCP)的運算，
完成實際且有效的整合應用，除可快速獲得饋線各開
關節點之運轉電壓及電流，同時，也提供一套可建置
實際之配電網路系統之模型，以利研究計畫之後續執
行、且可應用於相關配電系統問題範疇，如饋線重構、
復電等。 
 
Abstract： 
Automatic data extraction system is developed in this 
research. By using the electric connectivity provided by 
the Outage Management System (OMS) and related 
tables and attributes of lines, switches and loads in 
distribution feeder, operating data can be extracted from 
OMS.  The feeder can be built based on the extracted 
information. The information of conductor lengths, loads 
and other related line parameters are calculated.  
Meanwhile, the operating voltage, current, real power 
and reactive power of each hour in the Distribution 
Dispatch Control System (DDCS) can be obtained by 
Data Warehouse. The information are integrated and 
used for Power Flow Calculate Program (PFCP).  The 
voltage at each switch node and current on each 
conductor can be obtained rapidly. The integrated system 
can then be used for feeder reconfiguration and 
restoration.  Finally, a real distribution network is used 
as a demonstration of the proposed integrated system. 
 
II. 源起與目的： 
電力系統乃是由電源、電網和負載三大部分組
成。目前電力系統的主要架構係由大容量發電廠產生
之電能，經由升壓變壓器提高至超高壓 345kV 級，藉
由 345kV 輸電線輸送至超高壓變電所(E/S)，降低至特
高壓 161kV 級供電特高壓用戶，藉由 161kV 一次輸電
線輸送至一次變電所(P/S)或一次配電變電所(D/S)，分
別降低至特高壓 69kV 級供電特高壓用戶或降低至高
壓 22.8kV 及 11.4kV 級高壓配電電壓供電高壓用戶，
而藉由 69kV 二次輸電線輸送至二次變電所(S/S)，降
低至高壓 11.4kV 級高壓配電電壓供電高壓用戶。最
後，透過高壓配電線引送至桿上變壓器或大樓配電
室，降壓至低壓 110V 或 220V 級配電電壓供電一般低
壓用戶使用。由二次變電所或一次配電變電所引接一
條或多條配電饋線大部分以輻射狀型態構成配電系
統。 
因配電系統幅員遼闊，且負載變動係屬隨機分
佈，因此所含的資料相當複雜。台灣電力公司為能即
時掌握配電系統運轉資訊，開發「停限電運轉圖資系
統(OMS)」[1]，建立數位化之配電系統圖及饋線操作
圖，圖資電腦化後，於資料面可提高資料之正確性、
一致性，於執行面可加速圖資維護更新、調度搶修時
效、加強用戶服務等優點。數位化之配電系統圖(如圖
1~圖 3)上之設備均為物件之圖元，可供規劃、運轉、
維護人員即時查詢設備的屬性、電流方向、上下游負
載量、用戶數等資訊。如此以電腦科技作為輔助工具，
建立及維護整體配電系統資料庫，記錄所有重要的系
統資訊，若能再配合相關應用程式的建立，即可有效
地支援各種配電自動化之功能。 
台電公司現行之 OMS 系統，在調度運轉操作、
停限電、工作停電安排及停電用戶、停電區域之定位
等方面，已具有相當強大之功能及效益。惟在更進一
步的配電管理及應用上，諸如：配電饋線之電容器最
佳裝置位置選定、故障電流計算、配電系統不平衡負
載潮流檢討、保護協調檢討、無效電力損失計算、配
電系統之供電最佳化、損失最小化、最佳轉供方案…
等，仍付之闕如，而上述應用所需饋線參數數據之取
得，尚須開發相關之應用軟體或擴充系統功能才能有
效解決。 
本研究將先探討台電之停限電運轉圖資管理系
統，了解並分析此資料庫中所有電力元件之間的關係
與屬性，如何從大量且複雜的圖資、地理資訊與電力
元件的相對位置等資訊中，發展一套合適的輔助介面
程式，整理出簡單扼要之實際的配電系統資料，以利
解決相關配電系統問題所需的資訊，或配電負載潮流
程式所需的資訊，以建立配電系統架構，並利用負載
潮流計算軟體分析負載的電流與壓降等，且此階段的
研究成果，將有助於後續研究計畫的進行。 
 
III. 研究方法： 
如上所述，配電系統在配電管理之應用領域上，
學術界已有不少有關這方面之推導及研究論文，惟大
多僅以簡易或模擬系統加以研究[2]，研究結果能應用
在實際配電系統上者仍然有限。本計劃之研究，旨在
將現有配電系統以饋線為主軸，透過下列步驟建構「饋
線網路模型」。說明如下： 
(1) 追蹤 OMS 之電氣連結性，以取得饋線之完整區
段及節點相互關係，利用樹狀結構其電氣連結性追蹤
(Trace)步驟，以軟體程式先取得饋線電源端斷路器圖
元代碼，透過階層性依樹狀網絡由上往下進行追蹤，
遇上層連接多個下層設備時，依序進行追蹤至線路末
端或常開點開關為止 (如圖 4、圖 5)。 
路傳輸矩陣所建立而成矩陣的演算法，以求解負載潮
流的解[3]～[5]，利用負載潮流計算軟體執行配電系統
負載潮流計算如圖 9、圖 10。 
將上述開發之 OMS 饋線網路模型與配電負載潮
流計算軟體整合為一套配電系統之自動資料擷取界面
輔助系統(如圖 11)。 
 
 
圖 9: 負載潮流計算軟體 
 
 
 
 
 
 
10: 配電系統負載潮流計算 
 
 
 
 
圖 11: OMS 饋線網路模型建置與配電負載潮流之整合運用流程圖 
 
IV. 系統模擬與結論： 
為驗證自行開發之自動化界面軟體，在解決能夠
即時獲得配電饋線實際線路參數之有效性，本研究實
際應用於台電公司某區處轄內二次變電所 EQ42 配電
線路中。所選取之饋線裝置有自動化開關以便於比對
本系統之有效性，有關 EQ42 共有 20 節點 (區段)，其
中第 10、14、15、17 節點為自動化開關，第 10、14
節點為常閉開關，第 15、17 節點則為常開開關，EQ42
饋線線路圖(如圖 12)，架空自動化開關裝置及相別標
示參考圖則（如圖 13），本系統模擬所採用之電源端
參數，供電電源以主變二次匯流排電壓為依據，饋線
有效功率、無效功率則參考 EQ42 饋線尖載期間日負
載曲線圖(如圖 14)及 EQ42 饋線尖載期間日負載資料
表(如表 1)，模擬計算選擇夏季尖載期間日間 12 時及
夜間 20 時兩個時段，以該兩時段之實際負載資料回饋
調整 OMS 饋線網路模型內各區段之負載值，並與其
他線路參數及連結資料輸入 LFCP 軟體進行饋線各節
點負載潮流計算。模擬計算結果所得到之開關節點電
壓，與從自動化開關 FTU 定時回傳之記錄比對結果如
表 2、表 3 EQ42 饋線節點開關電壓 FTU 記錄與 LFCP
TABLE 
Feeder 
Breaker 
Switch 
Busbar 
Jump 
Edge 
Merge 
Node 
Sxfmr 
Pole 
Dsbnroom 
CONNECTIVITY 
TABLE 
Data Process 
Algorithm 
OMS Feeder Network Modeling
(OMS-FNM) 
Connectivity 
tracing 
Load Flow 
  Calculation Data Warehouse 
DDCS、FDCS 
REAL TIME 系統模擬 
饋線節點、區段即時運轉電
壓、電流 
Simple Map 
Create Feeder Data 
 Line、Switch 
 Section 
 Sxfmr
 
 
 
表1：EQ42饋線尖載期間日負載資料表 
時間(小時) 1 2 3 4 5 6 7 8 9 10 11 12 
饋線負載(kW) 3643 3662 3524 3432 3310 3313 3310 3675 5173 6015 6094 6056
饋線無效電力(kVAR) 746.6 782.3 695.2 665 544.9 542.1 548.5 773 1592.3 1963.9 2022.6 1987.3
時間(小時) 13 14 15 16 17 18 19 20 21 22 23 24 
饋線負載(kW) 5252 5930 6152 6074 5802 4938 4626 4440 4399 4146 4073 3963
饋線無效電力(kVAR) 1534.4 1905.3 2045.3 2005.9 1880.9 1405.3 1379.1 1333.2 1208.3 1030.8 943.4 844.3
 
 
表2：EQ42饋線節點開關電壓FTU記錄與LFCP計算結果比較表 
  測定時間:14 時  自動化開關(LS) LFCP 計算值(kV)  
誤差值 
(V) 
誤差百分比(%)
狀態 
開關裝置地
點圖號座標 
開關
節點
VT(FTU) 
引接相別 
電壓紀錄(kV) R 相 S 相 T 相 
常閉點 B3739BA36 10 T 6.77 6.73 6.771 6.761 9  0.133%
常閉點 B3738HB65 14 T 6.77 6.73 6.771 6.758 12  0.177%
常開點 B3738BC62 15 S 6.76 6.729 6.771 6.759 11  0.163%
常開點 B3639GA43 17 T 6.74 6.734 6.773 6.761 21  0.312%
 
 
表3：EQ42饋線節點開關電壓FTU記錄與LFCP計算結果比較表 
 測定時間:20 時 自動化開關(LS) LFCP 計算值(kV) 
誤差值 
(V) 
誤差百分比(%)
狀態 
開關裝置地
點圖號座標 
開關
節點
VT(FTU) 
引接相別 
電壓紀錄(kV) R 相 S 相 T 相 
常閉點 B3739BA36 10 T 6.80 6.746 6.774 6.765 35 0.515% 
常閉點 B3738HB65 14 T 6.82 6.746 6.773 6.765 55 0.806% 
常開點 B3738BC62 15 S 6.81 6.746 6.774 6.765 36 0.529% 
常開點 B3639GA43 17 T 6.79 6.75 6.775 6.767 23 0.339% 
 
 
 
Tutorial & Workshop 
09:00-12:30 
ROOM311 
Workshop/Tutorial TA1 
 
Modelling and Control of Electroactive Polymers As Actuators 
  
14:00-17:30 
ROOM311 
Workshop/Tutorial TB1 
 
Robot-Based Nanohandling Automation 
 
AIM 2009 Technical Program Wednesday July 15, 2009        
AIM 2009 Technical Program Wednesday July 15, 2009  
Track1 Track2 Track3 Track4 Track5 Track6 Track7 
10:00-11:48 
ROOM309 
Invited 
Session WA1 
 
Flexure-Base
d 
Mechatronics 
(Flexonics), 
Sensors, and 
Applications 
10:00-11:48 
ROOM310 
Regular 
Session 
WA2 
 
Actuators in 
Mechatronic 
Systems 
10:00-11:48 
ROOM311 
Regular Session WA3
 
Bio-Mechatronics and 
Micro/Nano-Manipulati
on 
10:00-11:48
ROOM312
Regular 
Session 
WA4 
 
Novel 
Industry 
Applications 
of 
Mechatronic
s
10:00-11:48
ROOM313
Regular 
Session 
WA5 
 
Humanoid 
Robots I 
10:00-11:48 
ROOM314 
Regular 
Session WA6 
 
Neural 
Networks 
10:00-11:48
Theatre 
Regular 
Session WA7
 
Computation
al Models 
and Methods
              
13:30-15:18 
ROOM309 
Regular 
Session WB1 
 
Control 
Application in 
Mechatronics 
I 
13:30-15:18 
ROOM310 
Regular 
Session 
WB2 
 
Design 
Optimization 
in 
Mechatronic
s I 
13:30-15:18 
ROOM311 
Regular Session WB3
 
Modeling and Design 
of Mechatronic 
Systems I 
13:30-15:18
ROOM312
Regular 
Session 
WB4 
 
Robot 
Dynamics 
and Control 
I 
13:30-15:18
ROOM313
Invited 
Session 
WB5 
 
Management 
and 
Supervisory 
Control of 
Networked 
Manufacturin
g Systems
13:30-15:18 
ROOM314 
Regular 
Session WB6 
 
Human-Machin
e Interfaces I 
  
  
  
  
  
  
              
15:40-17:28 
ROOM309 
Regular 
Session WC1 
 
Sensors and 
Sensing 
Systems 
15:40-17:28 
ROOM310 
Regular 
Session 
WC2 
 
Applications 
of Nano 
Technology 
15:40-17:28 
ROOM311 
Regular Session WC3
 
Biomechatronics 
15:40-17:28
ROOM312
Regular 
Session 
WC4 
 
Machine 
Vision and 
Intelligent 
Sensors 
15:40-17:28
ROOM313
Regular 
Session 
WC5 
 
Manufacturin
g 
Applications 
and Design
15:40-17:28 
ROOM314 
Regular 
Session WC6 
 
Control 
Application in 
Mechatronics II 
  
  
  
  
  
  
AIM 2009 Technical Program Thursday July 16, 2009       
AIM 2009 Technical Program Thursday July 16, 2009  
              
15:40-17:28 
ROOM309 
Regular 
Session FC1 
 
Control 
Application in 
Mechatronics 
IV 
15:40-17:28
ROOM310
Regular 
Session FC2
 
Machine 
Vision 
15:40-17:28 
ROOM311 
Regular 
Session FC3
 
Control 
Application in 
Mechatronics 
III 
15:40-17:28 
ROOM312 
Regular Session 
FC4 
 
Actuators and 
Intelligent 
Sensors 
15:40-17:28
ROOM313
Regular 
Session FC5
 
Design 
Optimization 
in 
Mechatronics 
II
15:40-17:28 
ROOM314 
Regular 
Session FC6 
 
Intelligent 
Sensors and 
Systems 
  
  
  
  
  
  
 
二、與會心得 
 
在參加這次的會議過程中，筆者結識了相當多的專家學者，也討論有關類神經網路的理論架
構與實際應用的經驗，對於日後的研究相信會有相當的助益。最後要感謝國科會在來回機票
與註冊費的經費補助。 
 
三、攜回資料 
主要攜回會議論文集光碟，可供相關研究人員參考。 
 
  
 
Abstract—Neural networks play an important role in artificial 
intelligence application domains. In most of applications, neural 
networks are often implemented in software form. Although the 
software implementation of neural networks provides flexibility, 
the computation speed is limited due to the sequential machine 
architecture. In most applications using artificial neural 
networks, the learning procedure is carried off-line. A large 
amount of mathematic operations are needed when learning task 
of neural networks is performed. The software implementation 
of neural network systems can only work well using high 
performance computers. The learning performance is not 
adequate when it is implemented on embedded systems. 
Following the development of modern semiconductor 
technologies, people attempt to realize the neural networks by 
hardware in order to improve the performance. Designs utilizing 
special architectures and parameters to achieve the performance 
were proposed in the past. This paper proposes a high efficiency 
and generic neural network hardware architecture. The 
architecture uses the toroidal series multiple data stream to 
process the back propagation neural network operations, which 
has the full function of recall and learning capabilities. Users can 
adjust the number of processor elements (PEs) in the system 
based on the requirement of the applications by setting the 
values in registers. Since the proposed system is developed in 
hardware, it can be integrated into embedded systems easily. 
The experimental results show that the system can reach much 
higher performance by using fewer logical elements while 
maintaining flexibility 
I. INTRODUCTION 
NE of the characteristics of artificial neural network is 
a highly parallel computation structure.[1]-[7]  The 
calculation in each node is performed simultaneously.  The 
result of such a structure is a network that can be used to 
process complex tasks.  
In the past decade, several hardware implementations of 
artificial neural networks have been proposed [1].  The 
computation capability of hardware based artificial neural 
network performs hundred or even thousand times faster than 
software based artificial neural network.  The power 
consumption of hardware based artificial neural networks is 
also much less than software based artificial neural networks 
 
Manuscript received January 5, 2009  
M.S. Tsai is with the Graduate Institute of Automation Technology, 
National Taipei University of Technology, 10608, TAIWAN. (phone: 
886-2-27712171 Ext 4326; fax: 886-2-27733217; e-mail: mstsai@ 
ntut.edu.tw).  
Y.H. Fu, is with the Graduate Institute of Automation Technology, 
National Taipei University of Technology, 10608, TAIWAN. (e-mail: 
t6618028@ntut.edu.tw) 
 
when they are running about the same speed.  However, the 
long development period and less flexibility are two of the 
major hurdles when developing hardware based artificial 
neural networks.  With recent development of semiconductor 
technologies, high density FPGA chips are generally available 
at a reasonable cost.  Due to the reconfiguration 
characteristics of FPGAs, implementing and synthesizing of 
hardware based artificial neural can be done in a laboratory.  
By interconnecting many simple basic PEs and specialized 
bus structure, the hardware based artificial neural networks 
can be implemented easier with higher flexibility.  In this 
paper, a general purpose hardware based artificial neural 
network based on modified toroidal structure is proposed.  
The structure is designed in a flexible way such that different 
node counts on each layer in a network can be modified easily 
without redesign.  The pipeline and parallel calculation are 
also implemented in the proposed hardware based artificial 
neural network in order to further improve the performance. 
Because of the high performance and low energy consumption, 
the hardware based artificial neural network can be applied to 
many fields where the speed and power are of the major 
concerned  
II. HARDWARE STRUCTURE 
A. Modified Toroidal Structure  
The back propagation neural network (BPNN) is a layered 
structure. Beside the input layer, the inputs of each layer come 
from the outputs of previous layer. The nodes in each layer 
performed the same calculation. The toroidal structure 
proposed in [2] implemented a general purpose artificial 
neural network.  In [2], the number of required PEs in the 
whole network is equal to the total number of PEs in the 
hidden and output layers.  During the calculation on hidden 
layer, the PEs associated with hidden layer are activated.  The 
PEs that are associated with output layers are then activated 
when the hidden layer calculation is done.  Therefore, some 
PEs are not activated during the calculation.  When inspecting 
the forward calculation flow of artificial neural networks, it is 
found that the calculation on one layer relies on the outputs of 
pervious layer.  The calculation on different layers cannot be 
performed simultaneously.  Therefore, the same PEs can be 
used to perform the calculation at different layers.  For 
example, PE1 can be used to perform hidden layer and output 
layer calculation as long as the correct inputs and weights are 
provided.  A new toroidal structure is proposed in this paper 
Implementation of High Performance Hardware Based Toroidal 
Neural Network with Learning Capability 
Men-Shen Tsai, Member, IEEE and Yao-Hsien Fu 
O 
2009 IEEE/ASME International Conference on Advanced Intelligent Mechatronics
Suntec Convention and Exhibition Center
Singapore, July 14-17, 2009
978-1-4244-2853-3/09/$25.00 ©2009 IEEE 180
  
 
1 1
n is output layer
( )  n is hidden layer
n
j j
n
n nj
k jk
k
D Y
e
w  
 
  

  ...................... (4)
 
(1 )n n n nj j j je Y Y    .................................................... (5) 
n
j
n
i
n
ijij Ytwtw 
1)1()(   ................................... (6) 
n
j
n
i
n
ij
n
ij
n
ij Ytwtwtw 
1)1()1()(   .................... (7) 
 
wij(t), wij(t-1) : weight at the t-th and (t-1)th iteration 
wij(t), wij(t-1) : weight deviation at the t-th and (t-1)th 
iteration 
 : Momentum factor 
 : Learning factor 
 
III. DETAILED HARDWARE IMPLEMENTATION 
A. Control Unit 
The main purpose of a control unit it to control the flows of 
data among the PEs.  The control unit generates signals at 
correct instances to guide the data flows from one PE to an 
adjacent PE and calculate the product sum within PEs.  The 
control unit also generates accessing and clearing signals to 
PEs in order to clear the accumulator and select input signal to 
complete one layer of ANN calculation.  The complete state 
flow of the control unit of the proposed artificial neural 
network is shown in Fig. 3. 
 
PE Weight 
Initial
START
PE Array 
operation
Transfer 
function 
computation
Transfer 
function 
computation
δ  
Computation
Recall Result
Batch training complete
Next training data
Recall 
Complete
feedward 
operation
Next Layer 
computation
Wait PE Array 
computation
Wait output layer 
result
Wait result
Hidden layer
Output Layer
Wait weight Queue 
of PE
PE Stack Initial 
Complete
Recall Learning
Wait result signal 
Backward 
computation
Wait weight change 
complete
δ
Wait 
instruction
Siginal transmission PE
δwait computation complete
 
Fig. 3.  State Flow of Control Unit 
 
B. Activation Function 
Sigmoid function is commonly used as activation function 
for Back-Propagation neural networks.  Look-up table with 
linear interpolation method is used in this paper to implement 
the activation function. Since the sigmoid function is 
symmetrical at point (0, 0.5), the absolute value of the input is 
taken if the given input is negative. Eq. (8) is used to calculate 
the correct input value for the implemented sigmoid function.  
By taking advantage of symmetric feature, the memory usage 
can be reduced.  
 












boundaryxfor 
xboundaryfor xP
boundaryxfor xP
boundaryxfor 
xS
 ,0
0- ,)(1
0 ,)(
 ,1
)(
 ................ (8) 
S(x)  : the output of look-up table 
P(x) : the value of look-up table 
Boundary : the extreme value (0 or 1) is return if the input 
value exceeds the boundary 
 
A new concept of linear interpolation is proposed in this 
paper. Instead of placing two end points of a line segment on 
the curve, the two end points of a line section is placed above 
or below the line such that the maximum Euclidean Distance 
between the line and the curve is with-in the specified 
tolerance.  Traditional linear interpolation method is shown in 
Fig. 4(a).  The proposed interpolation method is shown in Fig. 
4(b).  As seen from the two diagrams, the proposed method 
has smaller error between the target curve and the interpolated 
line section when the same line section length is used.  Eq. (9) 
is used to calculate the Euclidean Distance between the line 
and the curve.  The tolerance of the proposed interpolation 
method is specified beforehand.  Optimization method, such 
as Genetic Algorithm, is applied to find the minimum number 
of line sections that satisfies the required tolerance. 
Interpolated 
Line Section
End-Point
End-Point
_EmaxxE )(
)(xE
Target 
Curve
_EmaxxE )(
)(xE
-
End-Point
Interpolated 
Line Section
End-Point
 
(a)                                  (b)  
Fig. 4.  Comparison of interpolation methods  
 
)(-)())(-)(()( 2 xSxfxSxfxE   ............................. (9) 
 
f(x) : sigmoid curve to be synthesized 
S(x) : synthesized lines by proposed method 
 
nnn yxxmxP  )()(  .................................................. (10) 
P(x) :  approximate of given curve 
xn :  the left boundary of the n-th line section  
mn :  the slope of the n-th line section 
yn  : the offset of the n-th line section 
 
The approximated curve can be calculated using Eq. (8) and 
(10).  The differences between the actual curve and the 
approximated curve are shown in Fig. 5 when the specified 
tolerance (max_E) is 1.010-5. In this case, the number of line 
sections is 95 and the mean absolute error is 2.8210-6. Only 
one multiplier in the actual implementation is required.  The 
operation frequency is 50MHz and the calculation requires 7 
clock cycles.  The detailed hardware implementation is shown 
in Fig. 6.The number of required line sections and hardware 
resources when different tolerances are specified is shown in 
182
  
information during learning process.  During the initialization, 
the weights are stored in the weight queue of learning unit.  
These weights are also stored in the PE array.  In the learning 
process, the weights are calculated and stored in the weight 
queue.  The weight in each PE is also updated when a learning 
cycle completes.   
 
FIFO
Reg
FIFO

Stack
Input
Stack
Output
Mux
w
FIFO
w




 



Mux
Output Destination

Modified 
Weight
Layer
Layer
Initial 
Weight
1
RegReg

w
w
Input of PE
Output of PE 
To Input 
Data Bus
 
Fig. 10. Hardware Structure of Learning Unit 
  
IV. SIMULATIONS AND VERIFICATIONS 
An embedded system that contains an NIOS-II process is 
developed for evaluating and comparing the performance 
between hardware and software based artificial neural 
networks.  For the hardware based neural networks, the 
NIOS-II processor is used to provide training and testing data 
to the hardware neural network.  For the software based neural 
network, the NIOS-II is used to perform training and recall 
processes.  A standard NIOS-II structure is implemented as 
shown in Fig. 11.  A high speed timer with resolution of 20ns 
is developed and used to calculate the time required during the 
training and recall process. 
 
A. Protective Relay Curve Fitting 
In this experimental, a neural network is formed to emulate 
the IEC-255-4 over current protection curve.  The 
over-current protective curve is a time inverse curve.  Eqs. (11) 
and (12) are used to calculate the delay time, T[s], by given K 
and 

X . In the equations, the value of T[s] is the delay time of 
the relay. The value of 

X  is the ratio between the measured 
and preset currents.  The normal inverse curve with the values 
of  and  as 0.02 and 0.14 respectively is used in this 
experimental.  
1
][











X
K
sT
 .......................................................... (11) 



I
I
X  ...................................................................... (12) 
 
Fig. 11.  The NIOS-II System with hardware-based ANN 
 
Since an input, 

X , is required to obtain the delay time of the 
normal inverse over-current protection curve, 1-8-1 structure 
is used in this experimental.  The synthesized hardware neural 
network contains 8 PEs.  All the input data are normalized 
such that their values are between 0.1 and 0.9 before they are 
fed into the neural network. 
 
B. Experimental Results and Performance Analysis 
 
The training samples were generated by the NIOS 
processor.  These training samples were fed to the hardware 
for training.  When the training process completed, recall 
process is performed.  The outputs of the trained neural 
network by giving different values of k and x (currents) are 
shown in Fig. 12.  The performance and the absolute error are 
listed in Table II.   
1 2 3 4 5 6 7 8 9 10
0
2
4
6
8
10
12
14
16

X
][sT
K=0.1 Epoch=10800
K=0.3 Epoch=7000
K=0.5 Epoch=4000
K=0.7 Epoch=10400
K=0.9 Epoch=8600
 
Fig. 12.  Learning of normal inverse over-current protection curves 
 
From the results, the hardware based ANN has about the 
same performance with personal computer running at 2.8 GHz.  
Since the fixed point numerical representation is used in the 
hardware based ANN, the hardware based ANN has higher 
error values then software based ANN which uses IEEE-754 
floating point representation.  The largest error occurs when 
the value of x is equal to 1.5 which is a rare scenario in real 
applications. 
 
184
