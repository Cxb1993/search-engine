 
英文關鍵詞： Biometrics； Multimodal Biometrics； Face； Iris 
 
I 
 
目錄 
目錄 ........................................................................................................................................ I 
摘要 ...................................................................................................................................... II 
Abstract ................................................................................................................................ III 
第一章  緒論 ................................................................................................................... 1 
1.1.  前言 ................................................................................................................... 1 
1.2.  實驗生物特徵資料庫 ....................................................................................... 3 
(1)  虹膜影像資料庫 ....................................................................................... 3 
(2)  人臉影像資料庫 ....................................................................................... 4 
1.3.  系統評估方式 ................................................................................................... 4 
第二章  單一生物辨識系統辨識改良 ........................................................................... 6 
2.1.  研究目的 ........................................................................................................... 6 
2.2.  研究方法 ........................................................................................................... 6 
2.3.  實驗結果 ......................................................................................................... 15 
2.4.  討論與建議 ..................................................................................................... 16 
第三章  雙模態生物辨識系統 ..................................................................................... 18 
2.1.  研究目的 ......................................................................................................... 18 
2.2.  研究方法 ......................................................................................................... 18 
(1)  影像前處理與特徵萃取 ......................................................................... 18 
(2)  雙模態生物辨識系統基本架構 ............................................................. 21 
2.3.  實驗結果 ......................................................................................................... 22 
第四章  總結 ................................................................................................................. 25 
Reference ............................................................................................................................. 27 
III 
 
Abstract 
Multimodality is an exciting method to improve the accuracy of biometric recognition 
systems. By chaining a variety of biometrics, it contains too much unnecessary information 
in it. Therefore, information fusion is the key process of achieving high accuracy 
multimodal biometric systems. Some researchers suggested that the system is feasible for 
development at sensor-level and feature-level.  
A new fusion strategy of shuffling feature at feature level is introduced. Our approach 
encodes the large information into binary codes with low-resource requirements that can be 
realized easily, and named shuffle-based feature-level fusion (S-FLF).  
Finally, the developed methods are tested on UBIRIS v1 Session 1 iris database, 
CASIA v4 iris database and FEI face database. The experimental results show that the 
proposed system works well and increases the performance significantly under multimodal 
biometric systems. 
 
Keywords: Biometrics; Multimodal Biometrics; Face; Iris; 
 
2 
 
在這三個層級之中，特徵層級的層級最為困難，這是由於不同的特徵萃取技術所
描述特徵的方式不同，導致於特徵融合變成是非常困難，甚至是不能融合。而在決策
層級的融合，所能處理的資訊有限，因此影響系統的可能很小。因此，許多的文獻是
專注於分數層級的融合。 
 
圖 1：多模態生物辨識系統分類。 
由於單一生物特徵的個人身份辨識系統的不確定性，使得使用者對於基於生物特
徵的自動化辨識系統仍然不是十分的信賴，沒有一個完全的生物辨識系統是被人們所
信賴。因此，一個新的研究專注於多種生物特徵或辨識技術的融合討論，被稱為多模
態的生物辨識系統，其分類如圖 1 所示，分成辨識前（pre-classification）和辨識後
（post-classification），被分類成感測器層、特徵層、分類辨識層與決策層的融合方案。 
因此，第一年度計畫目的在於討論單一生物特徵辨識系統的改善討論，建立一具
有旋轉位移不變性質的虹膜辨識系統。在第二年度計畫中多模生物特徵辨識系統的解
決方案，目的是以人臉、虹膜和掌紋構成多模態的生物特徵。希望利用多個生物特徵
的融合來改善系統，修正因為單一生物特徵產生誤差的可能。最後，在第三年度計畫
中多模生物特徵辨識系統的解決方案，主要針對原始的訊號進行融合，結合了人臉、
與虹膜的辨識系統。 
4 
 
CASIA-IrisV4-Thousand 一千位使用者的虹膜影像。(vi) CASIA-IrisV4-Syn 除了設備
擷取的影像外，另外以影像合成的方式增加虹膜影像。 
   
(a) V3-Interval  (b) V3-Lamp     (c) V3-Twins 
   
(a) V4-Distance    (b) V4-Thousand     (c) V4-Syn 
(a) 圖 3：CASIA v4 人眼資料庫。 
(2) 人臉影像資料庫 
FEI 人臉資料庫為 FEI 大學電機工程學系人工智慧實驗室（Artificial Intelligence 
Laboratory, Department of Electrical Engineering, University of FEI）提供。FEI 的人臉
影像擷取系統，使用者背後為純色背景，照像機從十個角度、兩張不同光線強度影像、
兩張不同表情影像拍攝。每個使用者拍攝 14 張人臉影像，男性與女性各佔 100 位，
總共 2800 張彩色人臉以 PNG 格式儲存成 640×480 像素影像。 
 
圖 4：FEI 人臉影像資料庫。 
1.3. 系統評估方式 
身份驗證系統是使用者提供生物特徵後，經過處理後將特徵量化，之後系統依照
6 
 
第二章  
單一生物辨識系統辨識改良 
2.1. 研究目的 
對於本計畫基於臉型與虹膜辨識之雙模態生物認證技術之研究，透過融合多種生
物特徵以提高生物辨識系統的安全性，而在本計劃中首先討論單一生物特徵辨識系統
的改善可能性。在此以虹膜為例，目標使用虹膜的色彩特徵為身份辨識的依據，原因
在於經過外在設備的擷取後，若在一般的環境之外由於人眼的鞏膜容易反射外在光
源，進而影響紋理特徵的擷取和系統效能。因此，我們在此提出使用虹膜色彩為特徵，
取代以往利用紋理特徵的虹膜辨識系統。 
該年度研究重點在於虹膜定位設定、虹膜展開的討論和色彩的特徵萃取方式和色
彩特徵的可用性。本研究中辨識系統主要分為三部份進行：影像前處理、特徵萃取和
分類辨識。虹膜環定位步驟部份，該研究設計一個利用色彩上的差異度進行虹膜環的
定位，和 Hough 轉換等常見的方法不同的是，我們的方式已經有一既定的方向去進
行虹膜環追蹤，可以降低計算的難度，且在實驗過程中發現，該虹膜定位方法對於虹
膜外徑有一好的定位結果。特徵萃取步驟中，用以實驗對照的紋理特徵萃取採用
Gabor filter，並以漢明距的分類辨識。在色彩特徵萃取，我們設計簡單的流程，預先
將大量的色彩資訊壓縮，並且保留其分佈特性的轉換。再以不變矩的方式計算其幾何
上的特徵，經由實驗結果驗證，得到一好的基於色彩資訊特徵之虹膜辨識系統。 
2.2. 研究方法 
虹膜辨識系統架構如圖 5 所示分為三步驟：虹膜影像前處理，特徵萃取和比對。
當輸入一張人眼影像時，除了感興趣的虹膜區域，另外包含眼白、眼瞼、皮膚和睫毛
等雑訊，因此必須透過影像前處理步驟將感興趣虹膜區塊取出， 針對色彩和紋理萃
取特徵，最後進行比對系統測試。 
8 
 
當依照不同初始條件取出假設虹膜邊界區塊，如圖 8(a)(b)所示，由於虹膜與瞳孔
跟內外徑有極大的差異性，因此我們可以利用 k-means clustering 分群演算法將像素值
分群，即可得到如圖 (c)(d)二值邊界影像。 
      
(a)   (b)   (c)   (d) 
圖 8：虹膜邊界偵測區域。 
之後以垂直方向加總得到像素值統計結果 p，並找到平均值處的座標點 i，  
 argmin i p
i
d  p  (1) 
其中μp 為向量 p 的平均值，如圖 9 中某方向上邊界偵測計算範例，曲線為累積向素
值，點線則代表了所有 d 值。 
 
圖 9：初始邊界決定。 
之後再對每一水平軸方向找到最近障礙像素，即是每一虹膜區塊展開方向，與初
始邊界線座標點上像素相異距離最近像素，該障礙像素結果如圖 10 所示。並不斷的
進行迭代虹膜半徑 r 和圓心 p，直到滿足收歛條件 distance(Ci+1, Ci) < t。 
10 
 
 
圖 11：非線性虹膜正規化模型。 
觀察圖 11 中，點 A 是 OA 線段的與 arc(PI')交點，要描述點 A 這一個交點，我們
有許多不一樣的座標系可以選擇來描述點 A，若將點 A 使用極座標系來表示，我們只
要知道點A與瞳孔中心O的距離OA線段和點A＇與瞳孔中心連線與 y軸的夾角θr(i), 
即可描述出點 A 的直角座標，如下式: 
 
    
    
1
1
x r
y r
A i sin i
A i cos i


 
   (3) 
其中 OA 線段為Δ1(i)，要求解Δ1(i)，可先觀察點 A'與 arc(P'I')的圓心 o2 和瞳孔
中心 O 會形成一個三角型，此三角型三邊長都是我們給定的，因此由餘弦定理可以
知道三角型任一角的角度θr(i)。求解出θr(i)之後，點 A 與 arc(PI')的圓心 o1 和瞳孔
中心 O 會形成另一個三角型，在這一三角型三邊長中求得θr(i)，因此 OA 一樣可由
已知的兩邊長和一內角θr(i)藉由餘弦定理求得 OA 線段，至此我們已經求得θr(i)與
Δ1(i)如下式： 
       
22 2
2 2 21
2 22
ref
r
ref
y r i r
i cos
y r i
 
         
 (4) 
      12 2 21 1 1 1 12 ri r y r y cos i     (5) 
12 
 
 
(a) R-G      (b) R-B      (c) B-G 
圖 13：色彩幾何形狀。 
由於我們未對影像作正規化的動作，因此並沒有相同基準可以利用色彩統計方式
進行特徵萃取和比對，因此我們對其做二值化動作，如圖 14。 
   
(a) R-G      (b) R-B      (c) B-G 
圖 14：二值化色彩幾何形狀。 
從圖 14 中可以看出來色彩分佈是十分的散亂，因此，在統計前進行色彩值的正
規計算並進行濾波，得到圖 15 的 binary color map。 
   *
i i
i i
i i i
i i
R r
dG g
r g b
B b
                
 (6) 
   
(a) R-G      (b) R-B      (c) B-G 
圖 15：正規化色彩之二值化幾何形狀(binary color-map)。 
圖 16 展示了兩個類別的 binary color-map 圖，透過這種平面投射的方式依然能夠
保留色彩的旋轉和位移不變性質的優點，這是因為該投影的方式依然是沒有進行影像
14 
 
  ,p qpqm x y f x y 
 
   (10) 
經由線性代數可推導出七個 Moment Invariants，這七個方程式具有尺度、平移、
旋轉的不變性，Hu 也利用了其中兩個方程式來說明如何辨識不同的文字，此後
Moment and Moment Invariants 開始被廣泛的應用在電腦視覺領域。Hu 先以中心矩
（Central moment）的型式經由線性代數推導出下列七個方程式（此時仍不具有尺度
不變性）： 
      0 0 ,p qpq x x y y f x y  
 
    (11) 
從定義我們可知 Geometric moment 是將影像函數 投影到單項式 上，
但不幸的是 這組函數並不是正交基底，這種非正交基底的 Moments 所產生的資
訊其實是冗餘的。而且在影像重建這項任務上，因為它的非正交性使得影像重建的效
果不好，為了改善這項缺點，Teague 建議使用具有正交性質的多項式來取代原本的
核心函數，兩種廣為人知的正交多項式 Legendre 和 Zernike 被應用在影像重建的領
域上，藉由此二多項式所形成的 Legendre 和 Zernike Moments 大幅的提升了影像重
建的效能，此後大家也漸漸將研究重心轉移到正交函數所形成的 Moments 之上，
Zernike 多項式定義： 
  
     /2
0
!
1
! ! !2 2
p q
k
pq
k
p k
R r
p q p qk k k

             
    
  (12) 
和 
      , , jqpq pq pqV x y V r R r e    (13) 
將該多項式代入核心參數可得： 
    1 2
0 0
1 ,jqpq pq
nZ rR r e f r drd

  
    (14) 
因為 Zernike 的型式，我們可以發現當影像旋轉角度 θ時，僅僅造成相位的改變
而不會影響其他數值的大小，因此 Zernike Moments 具有旋轉不變性。 
16 
 
 
(a) Hu     (b) Geometric     (c) Zernike 
圖 17：binary color map 實驗結果。 
2.4. 討論與建議 
本研究色彩虹膜辨識系統中有別於一般虹膜辨識系統所使用的紋理影像，而是採
用色彩的資訊投射到平面得到幾何形狀的描述 binary color map 資訊並使用 moment 
invariant 特徵萃取技術擷取代表人的身份特徵。對於本虹膜辨識系統更是針對
UBIRIS.v1 S1 和 UBIRIS.v1 S2 兩種不同外在環境干擾的資料庫測試系統的強健性，
並且測試若是不考慮到虹膜內徑的定位資訊是否也能夠有好的辨識結果，意即免除虹
膜內徑的定位失敗是否且有好的辨識效果。因為本研究中前處理步驟所提出的基於色
彩差異性的虹膜邊界定位方式，對於邊界範圍差異度受到光源影響而無法提到一個好
的 k-means 分群結果時容易得到定位失敗的結果，而此失敗在本實驗測試中大多發生
在虹膜內徑之中，因此本研究測試除去虹膜內徑是否會有很大的影響，也正是因為我
們利用到色彩的旋轉不變特性，和紋理講求正規和影像位置的特性，才有辨法執行此
一測試。根據前節實驗結果，紋理特徵若是包含到錯誤的定位和光影的影響其最好實
驗結果分別為 EER=3.3 和 EER=8.3%，但在我們採用 binary color map 的資訊作特徵
擷取的時候，最好的實驗結果分別為 EER=8.2 和 EER=3.0%；這是因為對於虹膜紋理
來說，錯誤的虹膜定位會影響到虹膜環的展開正規化，得到錯誤的紋理資訊。但是本
研究中所提出之基於 binary color map 在作平面投射時，每一個像素值並不會特別的
具有影響力，某一特定的雜訊會在投射影群聚於一小點，經由濾波之後便會被移除。
另外我們所提之 binary color map 有別於以往研究移除掉虹膜色彩的旋轉不變性質，
依然保留此一優點，配點不變矩的幾何特徵計算能夠得到足以代表個人身份特徵。 
18 
 
第三章  
雙模態生物辨識系統 
2.1. 研究目的 
單一生物特徵的個人身份辨識系統的不確定性，使得使用者對於基於生物特徵的
自動化辨識系統仍然不是十分的信賴。因此，在計畫中多模生物特徵辨識系統的解決
方案，目的是以人臉、虹膜和掌紋構成多模態的生物特徵。希望利用數個生物特徵來
改善系統因為單一生物特徵產生誤差的可能。 
計畫中，人臉、虹膜和掌紋各自有一套的影像前處理；人臉影像採用 FEI 人臉影
像庫，並以熱門的 Haar-like 特徵搭配 boosting 的方式定位，以雙立方內插法對目標
人臉正規化。虹膜影像則是採用 UBIris v1 人眼資料庫，利用 push and pull 定位出虹
膜環，以直角座標系統投影至雙無維度極座標系統的方法正規化並切割出虹膜影像。
掌紋則是利用結構的知識定位出掌紋區塊，與其它不同的是，我們採用直角座標系統
投影至雙無維度極座標系統的方法正規化並切割出掌紋影像。之後對正規化影像進行
紋理特徵的強化，並使用局部和全域的統計特徵作為計畫中的融合特徵使用。 
計畫中所提出的特徵融合技術我們稱為「Shuffle」，並且有一種可能的融合策略：
「multiple traits one feature」。「Shuffle」的目的在產生新的特徵，新特徵的特徵空間
使得不同的特徵具有相關性。一開始特徵向量會各自正規化到新的區間，並映射到實
數空間，最後以編碼的方式呈現新的特徵，系統並利用 Hamming distance 進行特徵碼
的辨識比對，制定門檻值接受或拒絕使用者。 
2.2. 研究方法 
(1) 影像前處理與特徵萃取 
系統架構如圖 18 所示，會有多個生物特徵的輸入，每一個生物特徵有獨立一套
的影像前處理，最後輸出強化後的紋理影像。在該系統架構中，特徵萃取採用兩種技
20 
 
 
Step 7. 圖 19：虹膜定位流程 
B. 人臉影像前處理 
人臉定位的流程如圖 20 所示，FEI  人臉資料庫 640×480 像素影像會先轉為灰階
影像，接著轉為積分影像以加速人臉偵測的計算，之後萃取 Haar-like 特徵輸入事先
以 Boosting 訓練好的分類器以 Cascade 的方式進行人臉偵測，最後以雙立方內插法對
目標人臉正規化成 64×64 和 128×128。 
 
圖 20：人臉定位流程。 
Step 1. 彩色影像轉換至灰階影像。 
Step 2. 計算積分影像。 
Step 3. 萃取 haar-like 特徵。 
Step 4. 以 boosting 分類出人臉位置。 
Step 5. 以雙立方內插法對目標人臉正規化成 64×64 和 128×128。 
Step 6. 以 Ma et al.提出的背影光源移除法強化紋理特徵。 
C. 特徵萃取 
經過影像前處理後，二種生物特徵會被正規化並強化紋理特徵，如圖 21 所示。
由於影像包含巨大的資料量，所以在辨識時，必須抽取突顯特徵並且精簡的向量資訊
以供使用，我們採用了兩個特徵萃取方式，局部像素強度的平均值當作局部特徵，以
及使用 Local binary pattern histogram 當作全域特徵，再進行混合。 
當影像前處理模組處理執行完畢時，系統會輸出正規化並強化紋理的影像。為了
萃取局部特徵，我們以 8×8 像素區域為單位計算平均像素強度，作為局部統計特徵。 
22 
 
的測試。使用者的編碼會和資料庫所儲存的樣本以漢明距離（Hamming distance）比
對，並設定門檻值（threshold）接收或拒絕使用者的登錄。 
經過前處理得到強化後的紋理影像，並針對該紋理影像萃取局部 8×8 區域大小的
平均值統計特徵，和全域的紋理特徵 local binary pattern histogram。之後系統輸入我
們所提的 shuffled 特徵混合模組，產生新的代表該生物特徵的編碼。最後再以漢明距
離比對兩個特徵編碼，最後再訂定門檻值接受或拒絕使用者的登錄。 
2.3. 實驗結果 
單一生物特徵輸入系統後，經過前處理得到強化後的紋理影像，並針對該紋理影
像萃取局部 8×8 區域大小的平均值統計特徵，和全域的紋理特徵 local binary pattern 
histogram。之後系統輸入我們所提的 shuffled 特徵混合模組，產生新的代表該生物特
徵的編碼。最後再以漢明距離比對兩個特徵編碼，最後再訂定門檻值接受或拒絕使用
者的登錄。 
表 3 為 5-fold 測試平均結果，而表中的(a)大欄是當輸入特徵向量 A 為平均值統
計特徵的局部特徵，輸入特徵向量 B 為 LBP histogram 的全域特徵。(b)大欄則反之。
表 3 為映射參數 p=32。我們可以清楚的看出來(a)大欄實驗條件具有比較好的測式結
果。我們將輸入的特徵向量正規化到[0,1]的區間，並計算區域特徵和全域特徵相對特
徵組的差值(ai - bi)，B 特徵向量的值多數大於 A 特徵向量，如圖 23 所示。因此本計
畫 shuffled 適用於 B 特徵向量的值大於 A 特徵向量。然而經過量化後，對照實驗結
果可知好的正量化後，其差值的統計分佈會近似於常態分態的情況。 
24 
 
由於我們為了將生物特徵向量融合，進行了多次的數據重新分配的操作，過程中
是否損失重要且具有代表性仍未討論。且當新樣本輸入到正規化函數，當發現越界情
況時，我們並未重新訓練我們的正規化函數的參數，而是直接視為 0 或極大值 p，是
否也造成系統的不安定也是必須另外討論。但是就以實驗結果來觀察，我們所提出來
的系統架構的確是可行的。 
26 
 
融合。而轉換後的二進位編碼，能夠有較輕的維度詛咒情況，且能夠很容易的串接，
使得特徵融合的可能性更加延伸且簡單。最後的實驗結果更是展現我們所提的方法具
有很好的強健性，且多生物特徵的融合是可行的。 
28 
 
[12] W. C. Wang, W. S. Chen, and S. W. Shih, “Biometric Recognition by Fusing 
Palmprint and Hand-geometry based on Morphology,” in 2009 IEEE Int'l Conf. on 
Acoustics, Speech and Signal Processing, pp. 893–896, 2009. 
[13] W. W. Boles and B. Boashash, “A Human Identification Technique Using Images of 
the Iris and Wavelet Transform,” IEEE Trans. on Signal Processing, vol. 46, no. 4, 
pp. 1185–1188, 1998. 
[14] J. Fu, H. J. Caulfield, S. M. Yoo, and V. Atluri, “Use of Artificial Color Filtering to 
Improve Iris Recognition and Searching,” Pattern Recognition Letters, vol. 26, no. 
14, pp. 2244–2251, 2005. 
[15] L. Ghouti and F. S. Al-Qunaieer, “Color Iris Recognition Using Quaternion Phase 
Correlation,” in 2009 Symposium on Bio-inspired Learning and Intelligent Systems 
for Security, pp. 20–25, 2009. 
[16] R. M. Haralick, K. Shanmugam, and I. Dinstein, “Textural Features for Image 
Classification,” IEEE Trans. on Systems, Man, and Cybernetics, vol. 3, no. 6, pp. 
610–621, 1973. 
[17] M. K. Hu, “Visual Pattern Recognition by Moment Invariants,” IEEE Trans. on 
Information Theory, vol. 8, no. 2, pp. 179–187, 1962. 
[18] M. Y. Javed and U. Qayyum, “Face Recognition using Processed Histogram and 
Phase-Only Correlation (POC),” in 2007 Int'l Conf. on Emerging Technologies, pp. 
238–242, 2007. 
[19] A. Khotanzad and Y. H. Hong, “Invariant Image Recognition by Zernike Moments,” 
IEEE Trans. on Pattern Analysis and Machine Intelligence, vol. 12, no. 5, pp. 
489–497, 1990. 
[20] J. S. Noh and K. H. Rhee, “Palmprint Identification Algorithm using Hu Invariant 
Moments and Otsu Binarization,” in 4th Annual ACIS Int'l Conf. on Computer and 
Information Science (ICIS’05), pp. 94–99, 2005. 
[21] C. Sun, F. Melgani, D. N. Francesco, C. Zhou, L. Zhang, and X. Liu, “Incremental 
Learning Based Color Iris Recognition,” in 2008 7th Mexican Int'l Conf. on 
Artificial Intelligence, pp. 319–324, 2008. 
30 
 
[33] X. Xia and L. O’Gorman, “Innovations in Fingerprint Capture Devices,” Pattern 
Recognition, vol. 36, no. 2, pp. 361–369, 2003. 
[34] J. Yang, J. Y. Yang, D. Zhang, and J. F. Lu, “Feature Fusion: Parallel Strategy vs. 
Serial Strategy,” Pattern Recognition, vol. 36, no. 6, pp. 1369–1381, 2003. 
[35] A. Kong, D. Zhang, and M. Kamel, “Palmprint Identification using Feature-level 
Fusion,” Pattern Recognition, vol. 39, no. 3, pp. 478–487, 2006. 
[36] C. J. Liu and H. Wechsler, “A Shape- and Texture-based Enhanced Fisher Classifier 
for Face Recognition.,” IEEE Trans. on Image Processing : A Publication of the 
IEEE Signal Processing Society, vol. 10, no. 4, pp. 598–608, 2001. 
[37] D. A. Fay, A. M. Waxman, M. Aguilar, D. B. Ireland, J. P. Racamato, W. D. Ross, 
W. W. Streilein, and M. I. Braun, “Fusion of Multi-sensor Imagery for Night Vision: 
Color Visualization, Target Learning and Search,” in Procs. of 3rd Int'l Conf. on 
Information Fusion, pp. 3–10, 2000. 
[38] A. Rattani, D. R. Kisku, M. Bicego, and M. Tistarelli, “Feature Level Fusion of 
Face and Fingerprint Biometrics,” in 2007 1st IEEE Int'l Conf. on Biometrics: 
Theory, Applications, and Systems, pp. 1–6, 2007. 
[39] A. Rattani and M. Tistarelli, “Robust Multi-modal and Multi-unit Feature Level 
Fusion of Face and Iris Biometrics,” Advances in Biometrics, pp. 960–969, 2009. 
[40] A. Ross and R. Govindarajan, “Feature Level Fusion of Hand and Face Biometrics,” 
Defense and Security, vol. 5779, pp. 196–204, 2005. 
[41] C. C. Chibelushi, “Feature-level Data Fusion for Bimodal Person Recognition,” in 
6th Int'l Conf. on Image Processing and its Applications, vol. 1997, no. 443, pp. 
399–403, 1997. 
[42] D. J. Field, “Relations Between the Statistics of Natural Images and the Response 
Properties of Cortical Cells,” J. of the Optical Society of America. A, Optics and 
image science, vol. 4, no. 12, pp. 2379–94, 1987. 
[43] K. P. Hollingsworth, K. W. Bowyer, and P. J. Flynn, “The Best Bits in An Iris 
Code,” in 18th Int'l Conf. on Pattern Recognition, vol. 31, no. 6, pp. 461–464, 2006. 
  
行政院國家科學委員會補助國內專家學者出席國際學術會議報告 
報 告 人 
姓   名 
 
陳  文  雄 
 
服務機構 
及 職 稱 
國立暨南國際大學  
電機工程學系 
教授 
      時間 
會議 
      地點 
自101年10月5日至101年10月7日 
巴塞隆納 西班牙�Barcelona, Spain 
本會核定 
補助文號 
 
NSC 
99-2221-E-260-023-MY3 
 
會 議 名 稱 
 (中文) 2012年第四屆國際計算智慧聯合會議 
 
(英文) 2012 The Fourth International Joint Conference on Computational 
Intelligence�IJCCI2012 
發表論文題目 
 (中文) 基於毛髮與臉部幾何特徵之性別分類 
 
 (英文) Component-based gender classification based on hair and facial geometry 
features 
 
一︾前言「國際計算智慧聯合會議�International Joint Conference on Computational Intelligence; 
IJCCI為國際資訊︾控制與通訊系統與技術學會�The Institute for Systems and 
Technologies of Information, Control and Communication; INSTICC與IEEE�The Institute 
of Electrical and Electronics Engineers所聯合舉辦的國際學術會議︽為國際間有關智慧型
計算理論與技術領域相當重要且知名的國際會議〈IJCCI 是三個會議所共同組成的聯合
會議︽包括「ECTA, FCTA 與NCTA〈本人所參加的會議為NCTA�International Conference 
on Neural Computation Theory and Applications〈2012年第四屆國際計算智慧聯合會議
�ICCGI2012今年於西班牙的大城巴塞隆納�Barcelona舉行〈此會議集合了全世界
各國與計算理論及技術領域相關之研究學者發表最近一年的研究成果︽所發表的論文均
經嚴格之審查︽今年論文接受率約50%左右〈今年的IJCCI2012會議於 2012年10月5日至 
10月7日連續三天在舉世聞名的藝術觀光勝地 西班牙 巴塞隆納�Barcelona舉行︽ 
IJCCI2012整個會議包含三場 keynote lectures�每天各安排一場以及一場Panel 
Discussion〈論文議程共分為八場parallel technical sessions以oral形式發表及三場poster 
sessions〈我們的論文被分在第三天下午的poster session 2︽以壁報形式發表︽論文題目
為”Component-based gender classification based on hair and facial geometry features”〈 
 
二︾參加會議經過「由於上課與班機時間之故︽未能提早出發︽本人於10月4日�週四深
夜11:35搭乘長榮班機由桃園出發直飛巴黎轉機︽於法國當地時間 10月5日清晨6:40抵達
CDG機場︽並隨即轉機前往 西班牙 巴塞隆納︽於中午前抵達︽隨即check in於下榻的旅
館︽同時也是會議舉行的地點〈即赴會議報到註冊並領取相關資料︽亦聆聽第一場Keynote 
address演講︽講題為「”The infinity computer and numerical computations with infinite and 
infinitesimal numbers”，演講者為Prof. Yaroslav D. Sergeyev（University of Calabria, Italy）〈
論文發表會是從10月5日上午9:30開始至10月7日下午5:45結束〈每天的  technical 
session︽就根據自己的專長及興趣︽到各個不同的場次聽論文發表︽或與相識的國內外
  
論文接受信函�e-mail  
 
Dear Prof. Wen-Shiung Chen, 
 
We are happy to inform you that the regular paper you have submitted to NCTA, with number 42, entitled 
''COMPONENT-BASED GENDER CLASSIFICATION BASED ON HAIR AND FACIAL GEOMETRY 
FEATURES'', has been accepted for a poster presentation.  
Papers presented as a poster are assigned a 4-page limit in the conference proceedings. 
 
 
All reviews performed by the program committee are now available at the PRIMORIS Author's Home: 
http://www.insticc.org/Primoris/.  
Please login and then click on Author’s home / Paper Reviews, to access the reviews. 
The e-mail associated with your account is the following username: wschen@ncnu.edu.tw 
 
It is very important that you try to follow the suggestions indicated in the reviews during the preparation of the 
camera-ready manuscript.  
Furthermore, it is EXTREMELY important that you follow the camera-ready paper format and preparation 
guidelines for the proceedings, which are available at the NCTA web site: 
http://www.ncta.ijcci.org/PaperTemplates.aspx 
 
Any non-conformance with the specified format may force the proceedings editing team to return the paper to you 
for re-formatting, and in case of repeated problems it may prevent the paper from being published altogether.  
 
 
Please note that the publication of any paper in the conference proceedings requires that we: 
- receive the camera ready; 
- received the filled copyright form by e-mail, mail or fax (the document is available for download at your 
“Author’s Area”; 
- disregarding the accepted paper type, one of the authors must be registered as a speaker before 5 July 2012 . 
You can only complete your registration after you submit your camera ready. 
 
 
The registration is an on-line process and the payment methods you may select are:  
 
- PayPal (using a credit card - a PayPal account is necessary. Creating one may take up to 5 working days due to 
  
 
 
 
 
 
 
  
 
國科會補助計畫衍生研發成果推廣資料表
日期:2013/10/30
國科會補助計畫
計畫名稱: 基於臉型與虹膜辨識之雙模態生物認證技術之研究
計畫主持人: 陳文雄
計畫編號: 99-2221-E-260-023-MY3 學門領域: 圖形辨識
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
