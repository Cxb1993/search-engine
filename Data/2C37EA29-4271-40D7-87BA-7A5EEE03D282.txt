2 
 
2 研究目的 
 本研究工作處理對象主要針對 footprint 直徑在 1m 以內的光達系統，此類光達系統
主要功能為獲得三維物表坐標，並作為生產 DSM 及建立三維建物模型等需要高精度建
物角點與邊緣點坐標的應用，因此有必要提升光達坐標的精度與描述物表的細節程度。
由於記錄完整波形的光達系統尚不普遍，本研究發展出完整波形模擬器與幾何定位模擬
器，用以產生實驗地形與光達掃瞄資料作為研究。主要工作區分為三部分：(1)分析傳統
光達系統各種時間取樣方式在僅記錄單一個時間或第一與最終兩個時間時造成量測距
離的誤差，以了解現行模式可能的問題；(2)完整波形資料的波形處理方法測試與分析；
(3)應用完整波形的優勢來提升光達點位定位精度，研究建物邊緣光達點位萃取方法獲得
精確的邊緣線上點坐標。 
3 研究方法介紹(含文獻探討) 
3.1 研究工作流程 
本研究工作始於設計幾何定位與完整波形模擬器，並以模擬器生產模擬資料進行實
驗。研究前端為實驗測試分析各種時間偵測方法於傳統取樣模式下的定位精度與變因探
討，研究主軸為利用完整波形來提升雷射測距的精度進而提升光達點位精度，並測試能
提升建物邊緣線上之光達點位坐標精度之方法。而為了更精確獲得鄰近建物邊緣線之光
達點位坐標，本研究利用發射紀錄時間脈衝的回波推算，獲取物表反應波形與精確時
間，並針對建物邊緣光達點位，利用發射位置與建物的位相關係計算精確三維坐標。本
研究工作流程如圖 1 所示。 
 
圖 1 研究流程圖 
4 
 
3.2.3 結合幾何定位與完整波形模擬器 
 雷射脈衝模擬器架構在雷射垂直投射物表，雷射光束垂直於 X 軸且平行 Z 軸的坐
標系統下計算回波時間與距離。當雷射非垂直向下時可藉由幾何定位方式，模擬改變飛
行方位與掃瞄角度並計算 footprint 涵蓋的物表位置及 footprint 至發射位置之距離，同時
也改變回波時間。計算程序設計上先定義模擬坐標系，暫將物表的地形坐標系經坐標轉
換轉至模擬坐標系，轉換過程如下: 假設地形坐標系 Y 軸與飛機航向之夾角為 κ、掃瞄
角為 α，首先藉由轉換 κ 將地形坐標系 Y 軸轉至平行飛機航向，接著將 Z'藉由轉換掃
瞄角 α轉至平行雷射向量，轉換後即為模擬坐標系。經由坐標轉換將地形坐標(X, Y, Z)
轉至模擬坐標(x, y, z)。模擬坐標系中 y 軸平行飛機航向且 z 軸平行雷射向量，x 軸與 y
軸、z 軸三軸正交且構成一個右旋系統。轉換後的雷射光束垂直投影在模擬坐標系之物
表上，可套用至前述演算法的假設，即雷射回傳時間僅與物表高程有關。 
 獲得回波時間與光子數組成之波形後，可依不同的時間偵測法計算雷射距離，並於
物表坐標系下計算光達點位坐標。雷射光束受地形遮蔽的問題是常見的現象，模擬器計
算被遮蔽區的演算法主要概念為將地形點分割成許多大小合適之網格，每一網格內取高
程最高的地形點，其餘視為被遮蔽點，此方法優點是計算方便，缺點是地形點將減少，
且網格大小必須合適(約與地形坐標內插網格相同)以避免刪除過多地形點。 
3.3 雷射測距時間偵測模式 
傳統光達系統常以簡易的方式計算並作時間偵測與取樣，圖 2 所表示的是常見的回
波時間偵測方法，包括 50% Rise time point、Peak、Center of Area、Mean、Mid point、
Threshold 等方法(Abshire, 1994)，計算方法參照表 1。各個方法的優劣取決於地形複雜
度與反射強度的變化而定，這些方法若遭遇較複雜的多重疊波形就不足以描述物表的複
雜程度且大部分都不適用，更容易造成光達點位坐標所謂的錯位誤差(如圖 3 所示)，此
誤差是起因於時間偵測與取樣計算的距離並非真正由物表所反射的距離。 
 
圖 2 時間偵測方法示意圖(Abshire, 1994) 
 
 
 
6 
 
 
圖 3 錯位誤差示意圖(以 Mean 偵測法為例) 
3.4 多重疊波分解 
 本工作介紹的多重疊波分解法主要有兩種，第一種方法是把經過預處理降低雜訊後
的完整波形視為高斯混合模型(Gaussian mixed model)，並以EM演算法估計所有單一波
的組成參數(Persson et al., 2005)。第二種同樣是利用高斯混合模型來描述完整波形，而
以最小二乘法(Least Squares, LSM)求解所有單一波組成參數(Hofton et al., 2000; 
Reiberger et al., 2006)，這兩種方法最終皆能獲得高斯混合模型參數，其處理流程如圖4。 
預處理 起始值計算
EM
LSM
高斯混合模型未處理的波形
(1)MAD門檻值法 (2)高斯濾波平滑
Maximum法偵測
 
圖4 多重疊波分解法流程圖 
 
3.5 建物邊緣光達點位萃取 
 使用時間偵測或多重疊波分解所萃取的光達點位比傳統光達系統所提供的資料更
豐富且更準確，在應用上能提供相當好的精度(Wagner et al., 2004)，但是在建物邊緣位
置偵測上仍無法獲致精確的結果。當 footprint 落於建物邊緣線上時(如圖 5a)，將於回波
上產生如圖 5b 所示的兩個波形，依照光達點位萃取可以萃取出兩個光達點位，一個位
於地面，一個位於屋頂面，但是位於屋頂面的點未必是邊緣線上的點，因此本節從回波
產生的特性與雷射打在建物的位相關係來論述一個能更精確獲得邊緣線上光達點位的
方法。建物邊緣光達點位萃取可分成四個步驟：(1)使用多重疊波分解法獲得所有單一波
參數。(2)判斷由屋頂面所反射的回波，並計算一組光達點位坐標。此光達點位坐標坐落
8 
 
完整波形
資料
Fourier轉換
位相判斷
輔助資料:
掃瞄姿態、
建物坡度
計算建物邊緣光
達點位三維座標
擷取發射時刻之
回波時間區間
多重疊波
分解
近似光達
座標
 
圖 7 建物邊緣光達點位萃取解算流程圖 
4 結果與分析 
本研究所發展之光達模擬器包括幾何定位模擬與完整波形模擬，因此可就掃瞄角、
掃瞄距離、目標物方位、掃瞄密度等變因模擬單一光達點位的完整回波或是整條航帶的
光達掃瞄結果，供測試多重疊波分解模式、建物邊緣光達點位萃取。 
 實驗資料分為模擬資料與小部分實際資料，由於現行提供完整波形紀錄的光達系統
於國內尚不普及，資料不易取得，且必須配合實際地測資料，如建物邊緣線位置等高精
度的資料才能測試建物邊緣光達點位萃取的實際精度，因此目前只能以模擬資料進行測
試。在探討多重疊波分解模式的部分，本研究以模擬資料與 LVIS(Laser Vegetation 
Imaging Sensor)實際資料進行實驗。 
4.1 footprint 離邊緣線之距離對距離精度之影響 
實驗地形使用平屋頂邊緣，雷射發射位置固定於航高 1000 公尺處掃瞄角約略垂直
地面掃瞄，掃瞄方向從邊緣線的右側 0.5 公尺至左側 0.5 公尺之間每隔 0.091 公尺產生 1
個 footprint，如圖 8 所示。 
 
圖 8 footprint 落於邊緣線上 
(黃色點為 footprint 中心位置；三軸單位：公尺) 
圖 9 為各種時間偵測模式下距離錯位誤差的變化情形，掃瞄點編號 1、2、9、10 為
僅有一個波峰值，即 footprint 並未接觸到不同高程的物表，其餘回波則有二個波峰值。
以 Mid Point 為偵測方法在僅有唯一波峰值時誤差為零，但在具有二個回波值時會有固
定的距離誤差量，且其誤差量為所有方法中最大者。以 Peak 為偵測方法所呈現的誤差
平屋頂
地面 
點號 1 
點號 10 
10 
 
4.2.1 改變建物與地面高差 
 本實驗測試的配置為掃瞄角度 0 度，即雷射向量垂直 XY 平面且 footprint 中心位置
落在建物屋頂面上，航高 1000 公尺，分別針對五組模擬建物與地面高差不同之掃瞄回
波結果。圖 11 中，實驗回波波形得知增加高差造成兩個回波間距變大。圖 12 中顯示以
COA 與 Mean 兩種方法時距離誤差值隨高差增加而線性遞增，其他時間偵測方法則與增
加高差無關。 
ΔH=1m ΔH=2m ΔH=3m ΔH=4m ΔH=5m 
圖 11 改變建物與地面高差(ΔH)的回波波形 
 
 圖 12 改變建物與地面高差的距離錯位誤差變化 
4.2.2 改變掃瞄角度 
 本實驗的配置是改變雷射發射的平面位置來產生不同的掃瞄角度，航高皆為 1000
公尺，建物屋頂面與地面高差皆為 2 公尺，光達點位的真實位置也是皆相同。圖 13 為
掃瞄後回波波形成果，實驗中 footprint 涵蓋建物屋頂面的面積多於涵蓋地面因此會有由
建物屋頂面反射之回波能量較強的現象。比較五組波形，掃瞄角度漸增時，兩個回波的
間距也會增大，而掃瞄角度越大總能量越低之現象是由於實驗配置使得掃瞄角度越大距
離越遠。圖 14 為比較掃瞄角度漸增，時間取樣的距離誤差變化，採 Mean 與 Mid Point
兩種方法時距離誤差值隨掃瞄角度增大而緩慢增加，其原因同樣為 footprint 涵蓋之物表
高差變大。 
 以 Mean 法作為時間偵測與能量有關，因此反射強度、footprint 涵蓋面積等皆有影
響。比較本節實驗 1 中物表高差為 2 公尺的實驗組與實驗 2 中掃瞄角度 0 度的實驗組，
兩者皆為掃瞄角 0 度且物表高差 2 公尺，但同樣以 Mean 法計算，前者距離誤差為 0.95
公尺，後者距離誤差為 0.425 公尺，兩者的差別在於 footprint 涵蓋地面面積不同，因此
在回波能量上有所差異。 
0 200 400 600 80
0
1
2
3
4
5
Return Waveform
time [100 psec]
1/
10
0 
ph
ot
on
s 
0 200 400 600 8
0
1
2
3
4
5
Return Waveform
time [100 psec]
1/
10
0 
ph
ot
on
s 
0 200 400 600 80
0
1
2
3
4
5
Return Waveform
time [100 psec]
1/
10
0 
ph
ot
on
s 
0 200 400 600 8
0
1
2
3
4
5 Return Waveform
time [100 psec]
1/
10
0 
ph
ot
on
s 
0 200 400 600 8
0
1
2
3
4
5
Return Waveform
time [100 psec]
1/
10
0 
ph
ot
on
s 
1 2 3 4 5
-0.5
0
0.5
1
1.5
2
2.5
3
錯位誤差
高程差 [m]
差
值
 [m
] 
Centroid of Area
50%rise
Mean
Mid
Peak
Threshold
12 
 
表 2 建物邊緣光達點位萃取實驗結果 
地形 斜屋頂 平屋頂 女兒牆 
實驗組別 1 2 3 1 2 1 2* 
近似光達
點誤差 
ΔX=0.047 
ΔY=0.008 
ΔZ=0.296 
ΔR=0.3 
ΔX=0.045 
ΔY=0.008 
ΔZ=0.243 
ΔR=0.247 
ΔX=0.055
ΔY=0.01 
ΔZ=0.312
ΔR=0.317
ΔX=0.044
ΔY=0.008
ΔZ=0.005
ΔR=0.045
ΔX=0.044
ΔY=0.008
ΔZ=0.002
ΔR=0.045
ΔX=0.044 
ΔY=0.008 
ΔZ=0.006 
ΔR=0.045 
ΔX=0.037
ΔY=0.007
ΔZ=0.018
ΔR=0.041
建物邊緣
點誤差 
ΔX=0.033 
ΔY=0.006 
ΔZ=0.03 
ΔR=0.045 
ΔX=0.036 
ΔY=0.006 
ΔZ=0.034 
ΔR=0.05 
ΔX=0.01 
ΔY=0.002
ΔZ=0.065
ΔR=0.066
ΔX=0.044
ΔY=0.008
ΔZ=0.017
ΔR=0.047
ΔX=0.042
ΔY=0.007
ΔZ=0.017
ΔR=0.046
ΔX=0.044 
ΔY=0.008 
ΔZ=0.02 
ΔR=0.048 
ΔX=0.037
ΔY=0.006
ΔZ=0.003
ΔR=0.037
*：與內側邊緣線比較之誤差 
統整以上三種類型屋頂面實驗結果可得以下幾點結論： 
(1) 比較斜屋頂與平屋頂實驗結果，屋頂面坡度大時則近似光達點位模式誤差越大，邊
緣點萃取模式則誤差較小。屋頂面坡度不大時近似光達點位模式可與邊緣點萃取模
式有相似的精度。 
(3)  女兒牆實驗中，若 footprint 涵蓋兩側邊緣線，邊緣點萃取模式可以計算女兒牆內外
側邊緣線上的邊緣點，但僅與掃瞄點距離近的邊緣線之邊緣點精度高(表 2 僅列出
精度高的部分)。而近似光達點位模式僅能獲得女兒牆上單一光達坐標。 
(4) 完整波形分析與計算三維坐標能比傳統單點或數點的記錄方式較不受 footprint內高
程差異的影響而得到較好的精度，若配合地形特性判斷如邊緣點萃取模式可得到更
精確的三維坐標，理想情況下的精度理論值可達公分級。 
4.4 多重疊波分解測試 
 本實驗由實驗區中選取三組光達回波波形進行測試，分別以最小二乘法與 EM 演算
法求解高斯混合模型參數，實驗之原始波形首先經過預處理的步驟來濾除雜訊，第一步
驟為使用 MAD 法濾除低能量的雜訊，第二步驟以罩窗大小為 1×3 的高斯濾波器平滑。
起始值計算是以 Maximum 偵測模式偵測出每個波峰的位置作為模型 μ 參數與 A(振幅)
參數的起始值，而以脈衝寬度的 1/6 為模型 σ參數的起始值。而由於資料受雜訊影響，
標準的最小二乘法無法得到理想的收斂結果，因此以 Levnberg-Marquartz 法來迭代以獲
得最佳的收斂結果。根據經驗法則最小二乘法的迭代停止條件為前後兩次後驗單位權中
誤差的差值小於該次的 1/1000，EM 演算法迭代停止條件為兩次參數差值小於前次參數
的 1/1000。三組實驗結果如表 3。 
 
 
 
 
 
14 
 
5 結論與建議 
1. 傳統的光達系統只能提供以簡易的時間取樣方式而得的光達資料，研究結果顯示簡
易的時間偵測方式(如 Mean)所獲得的光達點位在地形高程變化複雜如建物邊緣的
斷線位置等會產生明顯的距離錯位誤差，且錯位誤差與地形複雜度、掃瞄角度、航
高、光達特性(包括散射角度、脈衝寬度、時間解析度等)有密切相關，因此傳統光
達系統隱藏著許多誤差因素在，光達點位的精度有限。 
2. 完整波形的記錄方式具有許多優勢：(1)使用者能依自己需求決定時間偵測方式與萃
取所需點數，使用上更有彈性。(2)具有更多的資訊可供分類等應用。(3)藉由萃取
更多光達點可提升光達定位精度。 
3. 系統誤差影響與錯位誤差影響在本研究中以實驗測試並分析比較，兩種誤差類型各
有不同的誤差型態，系統誤差影響屬於全面性、系統性，而錯位誤差影響則主要在
地表高程變異大之處，屬於局部性且影響量各自獨立不同。 
4. 波形預處理的成果會影響多重疊波分解的成果以及起始值的計算，因此必須根據雜
訊程度與使用需求選擇合適的平滑罩窗。 
5. EM 演算法與最小二乘法使用於多重疊波分解的成果相差異不大，以最小二乘法解
算的成果雖然稍優於 EM 演算法，但是較容易受波形的雜訊所干擾，導至可能產生
無法收斂之情形而必須以其他方法(如 Levnberg-Marquartz 法)使其收斂。 
6. 本研究針對建物邊緣位置需要更高定位精度的光達點位所提出之建物邊緣線光達
點位萃取方法經由模擬實驗測試能有效獲得高精度的光達點位，有利於由光達波形
資料中萃取建物邊線點特徵。 
7. 完整波形的光達系統比傳統僅紀錄少數點的光達系統更具有優勢，在此將兩者的特
色整理如表 4。 
8. 本研究發展之空載光達幾何定位與完整波形模擬器能模擬諸多實際作業狀況，未來
可發展更完善的操作介面與功能以做為研究甚至工作任務的規劃之用。 
9. 建物邊緣線光達點位萃取方法未來若能取得實際完整波形之空載光達資料與地面
控制資料可作進一步的驗證與發展至其他物表的應用上。 
10. 本研究針對嶄新的光達資料完整波形記錄方式之處理模式與流程進行分析與研
究，並提出針對建物邊緣線光達點位的精度分析與評估，未來期望能夠供作投入類
似研究者在完整波形處理上參考之用。 
表 4 完整波形之光達系統與傳統光達系統之比較 
 完整波形之光達系統 傳統光達系統 
資訊提供 可提供豐富的地表回波資訊 僅提供少數點坐標與強度值 
資料精度 點位精度高 地形複雜時點位精度低 
資料儲存 儲存量大 儲存量小 
使用彈性 使用者可使用不同時間偵測方法決定點坐標 只能使用由系統提供的點坐標 
資料處理 資料前處理較費時 資料可直接使用 
應用範圍 應用範圍廣 應用範圍較小 
國外差旅心得報告： 
   本人於 2008.07.07~2008.07.11赴北京參加 ISPRS 2008 Congress, 並以海報方
式發表” Feature-based Registration of Terrestrial LIDAR Point Clouds”(如后附
件)。 
此研討會為國際航遙測學會(International Society for Photogrammetry and 
Remote Sensing)每四年所舉辦的盛會，結合學術與尖端產業科技之最新作品發表。
與會收穫除增廣見聞外，在幾天的研討會中與國際學者專家有許多寶貴經驗的交
流，對個人學術精進非常有幫助。 
 
adequate spatial closeness upon transformed onto the same 
coordinate system or using the normal vectors of corresponding 
conjugate 3D plane features. Strategically, this study also 
demonstrates the simultaneous registration scheme for all scans, 
which avoids error accumulations and would reach better 
solutions. The tools developed in this study for LIDAR point 
clouds registration on features basis are introduced in more 
detail in the following section. 
 
2. METHODOLOGY 
The feature-based transformation models in this study consist 
of point-based, line-based and plane-based 3D similarity 
transformations. The working scheme proposed in this study 
for registering LIDAR point clouds is illustrated in Figure 1. 
The 3D similarity transformation is mathematically described 
by a 7-parameter spatial similarity transformation, including a 
scale parameter (S), a translation vector (TX, TY, TZ), and three 
rotation angles (ω,φ, κ). Note that, for the reason of simplicity 
for data processes, 3D line segment expressed by two 3D 
end-points is employed to present 3D line features, and 3D 
plane patch expressed by normal vector is employed to present 
3D plane features throughout this study. 
 
     
 Figure 1. Proposed working scheme 
 
As shown in Figure 1, conditions that lead to solutions can be 
met either by using single type or combined features, offering a 
highly flexible working environment for registration tasks. 
 
2.1 Point-based Transformation Model 
The spatial transformation of point clouds on point features 
basis can be established by a point-to-point correspondence and 
solved by least-squares adjustment. The functional model can 
be formulated as Equation (1) 
 
቎
X୧
ଵ′
Y୧
ଵ′
Z୧
ଵ′
቏ ൌ ൥
TX
TY
TZ
൩ ൅ S ൥
mଵଵ mଵଶ mଵଷ
mଶଵ mଶଶ mଶଷ
mଷଵ mଷଶ mଷଷ
൩ ቎
X୧
ଵ
Y୧
ଵ
Z୧
ଵ
቏,          (1) 
 
where ሾTX TY TZሿT: the translation vector from system 1 to 
system 2;  
S: the scale parameter;  
mଵଵ~mଷଷ: elements of the rotation matrix. 
 
Equation (1) can be expressed as the model of observation 
equations (indirect observation equations), seen as Equation (2) 
 
yଷ୬ൈଵ ൌ Aଷ୬ൈ଻ξ଻ൈଵ ൅ eଷ୬ൈଵ，e~ሺ0, σ଴ଶPିଵሻ ,       (2) 
 
where n : number of conjugate points;  
y: coordinate vector of points;  
A: partial derivative coefficient matrix of form of 
equation (1) with respect to parameters;  
e: error vector of points;  
P: weight matrix;  
ξ: incremental parameter vector. 
 
To balance the transformation equation for solving seven 
parameters while providing a sufficient datum, three 
independent points are at least needed. Note that the coplanar 
3D point features should be excluded for a non-singular 
solution under minimum number required for the solution. 
 
2.2 Line-based Transformation Model 
The condition for line-based transformation model I is realized 
by constraining that a 3D line feature transformed to another 
coordinate system be collinear with its conjugate counterpart, 
implying that point to point correspondence is not needed. The 
aforementioned collinearity property for one end point can be 
established by Equation (3)     
 
X౟
మିX౟
భ′
୪౟
మ ൌ
Y౟
మିY౟
భ′
୫౟
మ ൌ
Z౟
మିZ౟
భ′
୬౟
మ ,                    (3) 
 
where  i: the i୲୦ line feature, i ൌ 1, 2, 3ڮn;  
n: the number of conjugate line features;  
ሾl୧
ଶ,m୧
ଶ, n୧
ଶሿT: the directional vector of ith line feature in 
coordinate system 2;  
ሺX୧
ଵ′, Y୧
ଵ′, Z୧
ଵ′ሻ: the end point ሺX୧ଵ, Y୧ଵ, Z୧ଵሻ transformed 
from system 1 to system 2;  
ሺX୧
ଶ, Y୧
ଶ, Z୧
ଶሻ : the end point of conjugate line in 
coordinate system 2. 
 
The mathematical model upon linearization can be regarded as 
the model of “condition equation with unknown parameters” 
and expressed as equation (4)    
 
wସ୬ൈଵ ൌ Aସ୬ൈ଻ξ଻ൈଵ ൅ Bସ୬ൈଵଶ୬ሺyଵଶ୬ൈଵ ൅ eሻ 
  e~ሺ0, ∑ ൌ σ଴ଶPିଵሻ,                         (4) 
 
where  n: the number of conjugate line pairs; 
y: coordinate vector of end points of 3D lines;  
A: partial derivative coefficient matrix of form of 
Equation (3) with respect to parameters;  
B: partial derivative coefficient matrix of form of 
Equation (3) with respect to point coordinates. 
 
Now let yത ൌ w െ By and eത ൌ Be, Equation (4) can be further 
derived and expressed as the model of observation equations, 
seen as equation (5) 
 
      yതସ୬ൈଵ ൌ Aସ୬ൈ଻ξ଻ൈଵ ൅ eതସ୬ൈଵ 
m: number of overlapping data sets;  
Npint: number of point feature total matching mates;  
Nline: number of line feature total matching mates;  
Nplane: number of plane feature total matching mates; 
nPointi, nLinei, nPlanei: numbers of conjugate features 
of i୲୦ matching mate. 
 
The minimum numbers of needed features for point-based, 
line-based, and plane-based transformation models are listed as 
in Table 1. 
 
 
Number of 
parameters 
Min. numbers of 
features 
Redundancy
Point-based 7 3 2 
Line-based  7 2 1 
Plane-based 7 4 5 
 
Table 1. The configuration of minimum features and 
redundancy 
 
3. EXPERIMENTS AND ANALYSES  
The following tests, including simulated and real data sets, 
were aimed to demonstrate the flexibility, reliability and 
accuracy that the feature-based transformation model would 
supply.  
 
3.1 Simulated Data Set 
For its simplicity, two overlapping scans with well distributed 
features under minimum requirements for each transformation 
model were configured, as shown in Figure 2. Ten check points 
were set to compare registration accuracy of all transformation 
models with various random errors. The tested standard 
deviations are 0.005, 0.01, 0.03, 0.05, 0.09 meters for each 
coordinate component. Figure 3 together with Table 2 shows 
total root mean square error (RMSE) for point-based, 
line-based, plane-based and feature-based transformation 
models. As revealed in Figure 3 as well as in Table 2, 
feature-based transformation model renders better registration 
accuracy than other transformation models for all levels of 
measurement error. 
 
Figure 2. The distribution of features; Dots are the check points 
 
Figure 3. The total RMSE(unit: m) of  
different transformation models 
 
Error-Std. Point-
based
Line- 
based 
Plane- 
based 
Feature-
based 
0.005 0.0076 0.0182  0.0166  0.0048
0.01  0.0316 0.0448  0.0372  0.0213 
0.03  0.0609 0.0826  0.0817  0.0395 
0.05  0.0951 0.0997  0.0992  0.0801 
0.09  0.1372 0.1277  0.142 0.1164 
 
*Total RMSE 222 )_()_()_( ZRMSEYRMSEXRMSE ++±=  
 
Table 2. The total RMSE*(unit: ±m) of  
different transformation models 
 
The feature combining scheme offers alternative ways to 
processing the point clouds registration. One can combine the 
measurements among three features to solve seven parameters. 
Table 3 depicts several effective feature combinations for 
solving transformation parameters under the minimum 
requirement. 
 
Combined features Number of obs. Degree of freedom
1 Point – 1 Line 7 0 
 1 Point – 2 Planes 9 2 
1 Line – 1 Plane 7 0 
 1 Plane – 2 Lines 11 4 
 
Table 3. The examples of effective feature combinations 
 
3.2 Real Data Set 
3.2.1 Description of Data Sets: Five successive scans of 
LIDAR point clouds, as shown in Figure 4, covering the 
facades of guardroom of National Taiwan University were 
collected by Trimble Mensi GS200 for verifying the 
registration achievements of simultaneous adjustment of 
feature-based transformation model. The evaluation of the 
registration accuracy was to compute the total RMSE of 15 
external check points. The information of the five scans of 
point clouds is listed in Table 4. 
 
-5
0
5 10
15
20
25
-2
-1
0
1
2
3
4
Y
2
3 Points
X
1
3
Z
-10
-5
0
5 14
16
18
20
-2
-1
0
1
2
3
4
Y
1
2 Lines
X
2
Z
