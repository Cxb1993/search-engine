 2
special light changing. Experimental data 
reveals that the recognition rate of the 
proposed method has been dramatically 
improved comparing with EigenFace method. 
Experimental results also show that the 
proposed method can indeed achieve reliable 
and satisfactory performance in face 
recognition.  
 
Keywords: Surveillance system, object 
detection, object tracking, human behavior 
analysis, biometric features, face verification.  
 
二、緣由與目的 
自動化的環境監控系統，在近年來是一
個相當熱門的主題，尤其是在電腦視覺領
域上，以影像辨識為基礎用在自動環境監
控系統上更是活躍。自動化環境監控系統
存在著許多的好處，如大量的精簡人力事
成本、避免人為疏失，自動化監控系統更
主要的一項好處是，可以對所發生的事件
作資料備分，以利於事後還原現場。然而，
視訊監控系統是項極為複雜且困難度高的
主題，國外的研究機構於近兩三年，才投
入大量人力從事技術研發工作；國內研究
單位則是處於起步階段，如工研院等。針
對視訊識別(video understanding)技術，可
以分為下列各模組：移動目標物偵測
(moving target detection)、目標物追蹤(target 
tracking)、目標物判別(target classification) 
與行為分析(behavior analysis)。 
在傳統的VSAM中系統偏向於移動物
體追蹤與行為分析，並未繼續深入探討追
蹤物體身份識別的問題，因而我們希望能
夠結合生物特徵識別等技術，增加傳統
VSAM中，辨識 video中人物的身份功能，
生物特徵識別技術利用人類的獨特生理或
行為特性，用以確認每個人身份，生物特
徵確認方法克服了傳統密碼基礎的系統，
他除了免除記憶密碼的麻煩之外，尚能隨
身攜帶，且具有獨特性與不易仿造的優
點。一般而言，常用的生物特徵包括了指
紋、語音、臉譜、手勢、虹彩、簽名、掌
型/掌紋、走勢或手勢考量視訊影像解析度
問題，以臉譜、走勢或手勢特徵較適於視
訊影像資料中做身份確認。 
 自 動 化 監 控 系 統 （ Automated 
Surveillance Systems）很適用於商業機密、
社會安全、交通流量測量控制、高速公路
事故偵測、人潮擁擠的公開場合、消費地
區人口統計、核能安全、停車場、絕種動
物、軍事要點、國界巡邏、難民營、大使
館等等安全考慮的監控，加上工業製程進
步和監控攝影機的價格下滑，使得設備器
材不在這麼昂貴；但是監控操作人員的支
出卻是逐年提高，雖然監控攝影機廣泛的
運用在銀行、商店、大樓24 小時的安全錄
影，但卻沒有實際運用數位攝影機的優
點，也就是視訊認知（video understanding）
和即時（real-time）的效能。 
 所以我們想辦法利用這項技術優點來
提供即時察覺辦公室夜盜、大樓門禁系統
和公開場所犯罪的預防，而自動化的操作
和電腦資料庫連線，達到人員身分辨識的
出入許可，大大的減少人工、資源的浪費，
更可以提高監控人員的效率。智慧型視訊
監控系統相較於傳統監控系統更切合大眾 
的需求，其原因有以下幾點： 
z 數位視訊監控系統除了具備傳統監控
系統記錄、儲存之功能外，更具備人
工智慧技術包括主動偵測、監控、通
知、嚇阻等功能。使監控系統功能更
完備提供更完整的服務。 
z 隨著網路盛行，數位視訊監控系統可
藉由網路，透過網路傳輸將目睹一切
實況發生情境，而這些技術可以運用
於超商、居家保全、停車場等公共區
域可以預防犯罪行為發生。 
z 目前很多社區成立守望相助服務隊，
用以加強鄰里安全，這些措施必須藉
由大量人力輔助，尤其是監控部分，
必須由一位專門保全人員全程目不轉
睛觀看監視螢幕，是項極為耗體力工
作。若使用智慧型監控系統，可以協
助安全人員適時提醒安全人員，既可
節省人力，更有效率。 
 
三、研究方法 
 
3.1主動式外觀模型 
主動式外觀模型（ Active Appearance 
Models，AAM）是由 Edwards[32] 所提出
 4
 
上式中， g 代表正規化紋理資訊向量之平
均， gP 則是利用主成分分析法（Principal 
Component Analysis）所得到特徵値所對應
之特徵向量所形成的矩陣， gb 則代表紋理參
數（Texture Parameter）的集合。因此，在
外形模組與紋理模組的建立之後，任何一
張人臉影像的容貌與形狀都應該可以用向
量 sb 與向量 gb 來描述之。由於形狀的變異與
紋理的變異有些許關聯，因此，利用此資
訊進行主成分分析法（Principal Component 
Analysis）以建立外觀模型。 
⎟⎟⎠
⎞
⎜⎜⎝
⎛
−
−=⎟⎟⎠
⎞
⎜⎜⎝
⎛=
)(
)(
ggP
xxPW
b
bW
b T
g
T
ss
g
ss  （3.5）
上式中， sW 代表每個外形參數（Shape 
Parameter）的權重所形成之對角矩陣。接
下來，利用主成分分析法（ Principal 
Component Analysis）於這些向量上，即可
得到外觀模型，如下式： 
b Qc=  （3.6） 
上式中， Q 代表利用主成分分析法
（Principal Component Analysis）所得到特
徵値所對應之特徵向量所形成的矩陣，c
則代表外觀參數（Appearance Parameter）
的集合，其可同時控制外觀模型中形狀與
紋理資訊。此外，由於外形參數（Shape 
Parameter）與紋理參數（Texture Parameter）
之平均皆為零，故外觀參數（Appearance 
Parameter）c 的平均亦為零。 
 因此，主動式外觀模型即是結合外形
模組（Shape Model）與紋理模組（Texture 
Model）而成，可由下式表示之，並透過參
數 c 以函式的方式表示形狀與紋理資訊： 
 
cQPgg
cQWPxx
gg
sss
+=
+=
 
（3.7） 
⎟⎟⎠
⎞
⎜⎜⎝
⎛=
g
s
Q
Q
Q
 
（3.8） 
 
從上述式子可知所有人臉影像即可利用參
數 c 來產生形狀與灰階資訊來做合成。 
 
3.2 人臉生物特徵擷取 
 我們提出一種利用人臉區塊特徵來提
升人臉辨識準確率的方法。在光線變化強
烈的環境中，如果利用整張人臉影像作辨
識，由於膚色區域極容易受到光線變化影
響導致辨識率下降，故本系統提出以人臉
五官區塊取代整張人臉的的辨識方法。 
本系統的演算法首先是利用 Active 
Appearance Model(AAM)偵測出所需要的
五官影像，分別為左眉毛、右眉毛、左眼、
右眼、鼻子及嘴巴這六個 components。取
出這六個區塊之後，使用 Principal 
Component Analysis(PCA) 個別抽取五官
的特徵向量同時降低資料維度，將這些特
徵向量利用 K-means 方法分群，再使用
Support Vector Machine(SVM)將這 K個類
別的資訊訓練出分類模組。 
 
3.2.1 以AAM做人臉特徵搜尋 
一張測試影像要做搜尋時，AAM會先初始
影像特徵點的位置，再用參數對這位置做
正規化，由此正規劃後的影像取出 texture 
img 。 將 img 投影到 texture model 為
)(Tg 1s imu g
−= 。為了要最佳化搜尋的過
程，所以希望 Appearance Model的 texture
資訊 cQg g+=mg ，與測試影像的 sg 差異性最
小，如(3.9)所示，其中 p 為模組的參數組。 
ms ggpr −=)(  (3.9) 
藉由調整模組參數 p ，將差異向量的強
度降到最小，而差異向量的強度定義為
2E r= 。然而因為 Appearance Model有許多
的參數，這顯然會是個困難的高維度最佳
化問題。為了解決這個問題，AAM利用在
搜尋的過程中所獲得的資訊以達到解決此
問題的目標。其方法是學習 r與模組參數 p
所造成的差異性之間的關係，此關係如
(3.10)。 
)( pRrp −=δ    
p
r
p
r
p
rR
TT
δ
δ
δ
δ
δ
δ 1−⎟⎟⎠
⎞
⎜⎜⎝
⎛=
 
(3.10) 
 
並且將所學到的關係代入一個迭代的演算
法以達到最小化 E。 
 
3.2.2 人臉五官特徵切割 
實驗結果如下圖所示，圖表 2(a)為原始影
像， 圖表 2(b)為做完 AAM搜尋之後的影
像。圖表 2(c)為每個人切割完之後的六個
 6
比對準則： （1）區域比對（Local Match）：
利用Chamfer Distance進行區域比對；（2）
整體比對（Global Match）：利用姿勢模組
與搜尋結果兩者區域重疊比例與搜尋結果
區域超出姿勢模組區域的面積比例。 
 
1. Chamfer Distance(C.D.)：計算前景物邊
緣上的每個像素點與利用姿勢模組所
得到的搜尋結果兩者外型的相似性。
C.D.是指物體邊緣上每一個點至另一
個物體邊緣的最短距離總和，其值越
大則表示兩者外形之差異越大；反
之，值越小則兩者外形越相近。 
 
2. 姿勢模組與搜尋結果兩者區域重疊比
例（Covered Region Rate，C.R.）：即
是計算利用姿勢模組所搜尋的結果
中，特徵點所形成的區域中佔姿勢模
組特徵點所形成區域的比例，如下圖
與下式所示： 
原始面積
交錯面積重疊比例 =(C.R.)  
 
3. 搜尋結果區域超出姿勢模組區域的面
積比例（Redundant Region Rate，
R.R.）：即是計算利用姿勢模組所搜
尋的結果中，特徵點所形成的區域中
超出姿勢模組特徵點所形成區域的比
例，如下式所示： 
搜尋結果區域
重疊區域搜尋結果區域多餘區域比例 −=) ..( RR  
 
綜合上述三種方法，利用比例結合的方式
並選擇適當的權重值將三種方法得出的結
果做組合以得到最後的判定結果，用此結
果決定六種姿勢中哪一種姿勢最符合目前
前景物的姿勢，如下式所示。 
 
.).1(...'.Match   321 RRWRCWDCWValue −×+×+×=
 
表 格  1 展 示 各 姿 勢 模 組 Chamfer 
Distance、區域面積重疊比例、多餘面積比
例的値，以及最後姿勢辨識的辨識值。可
得姿勢模組三與目標前景物的姿勢最為相
似。其中，W1、W2、W3三個權重値在本
論文分別設為0.5、0.3、0.2。 
 
表格 1 人體姿勢 match value 
 
 
四，實驗成果 
 
4.1 人臉實驗資料庫 
取像環境為有光線變化的環境，其中包含
了光源的變化，分別為天花板上的日光燈
及桌上的桌燈；光方向性的變化分別為日
光燈全開及各關一半，還有兩盞擺放成45
度的桌燈當日光燈全開及全關的情況下，
桌燈全開及各關一盞。因此組合出九種光
線變化的影像. 
 
 
圖表 5 光線變化之人臉影像 
 
4.2 人臉辨識 
此實驗所使用的訓練影像包含了所有的光
線變化，也就是說每一個人隨機從每一組
光線變化的影像裡面挑出三張來做訓練，
剩下的一張來做測試。如此重複四次的隨
機挑選，最後平均這四次的辨識率，就為
此次實驗的最終辨識率。每一次的實驗影 
 
 8
兩者與行為辨識率之關係。 
綜合上述圖表 6, 圖表 7的結果，本系統
將訓練樣本的序列長度定為40（frames），
而測試樣本之序列長度定為30（frames），
分辨對包含四種行為之589段測試樣本作
實驗，可得到以下結果：根據下表所示，
四種行為共589段測試樣本一共有550段測
試樣本的行為辨識正確，39段測試樣本辨
識錯誤，其中在跛行行為辨識中有22段測
試資料辨識為走路行為，主要原因是因為
以30張影像為一單位將影片做分割時，跛
行行為中會包含與走路行為極為類似的片
段，因而造成行為之誤判。因此，根據本
實驗結果經計算可得辨識率為93.37%。 
 
4.4 多重專家系統整合 
由上所述，本系統已經具備人臉辨識以
及個人行為分析的資訊，將這些資訊透過
Support Vector Machine(SVM)，找出區分這
些群組的最佳hyperplane。傳統的SVM通常
是用於binary class的資料分類，而當面對的
是multiclass的資料時，可以應用 binary 
class的概念來解決此問題。以下提出三種
方法： 
(1) One-Against-All 
此方法是每次將一個群組當作類別
一，而其餘的群組都當作類別二。因
此假設有c個群組，SVM會訓練出c個
模組，如圖表 8所示。 
(2) One-Against-One 
此方法是每一個群組之間兩兩相比
較，因此如果有c個群組，SVM會訓練
出 2)1( −cc 個模組，如圖表 9所示。 
(3) Directed acyclic graph SVM 
(DAGSVM) [33]  
此方法訓練的方式和One-Against-One
相同，也會有 2)1( −cc 個模組。而這
兩種方法是在後來預測的方式不相同。 
 
One-Against-One 在 預 測 時 ， 會 將
2)1( −cc 個模組都預測過後，選出票數最
多的那個群別。而DAGSVM是以類似於
binary search的方式做預測，如圖表10所
示，假設有四個群別，由最上方第一類別
和第四類別比較，若不是第一類別，就比
較第二類別和第四類別，以此類推，經由
一層層的篩選，到最後就會有預測的結果。 
 
 
圖表 8 One-Against-One示意圖 
 
 
圖表 9 One-Against-One示意圖 
 
 
圖表10 DAGSVM預測方法示意圖 
 
因為One-Against-All此方法只要訓練c
個模組，另外兩種方法都必須訓練
2)1( −cc 個模組。並且One-Against-All此
方法在辨識上也有不錯的效果。所以本論
文將分群完的K個群組當作K個類別，再將
此資訊採用SVM訓練分類模組。而此SVM
就是使用One-Against-All的方法來支援
multiclass的分類。 
 
 10
Architecture for Fast and Robust Face Detetion, 
" IEEE Transactions on Pattern Analysis and 
Machine Intelligence, Vol. 26, NO. 11, pp. 
1408-1423, 2004. 
[19]  Hakan Cevikalp, Marian Neamtu, Mitch Wilkes, 
and Atalay Barkana, " Discriminative Common 
Vectors for Face Recognition, " IEEE 
Transactions on Pattern Analysis and Machine 
Intelligence, Vol. 27, NO. 1, pp. 4-13, 2005. 
[20]  Joseph (Yossi) Gil, and Ron Kimmel, " Efficient 
Dilation, Erosion, Opening, and Closing 
Algorithms, "IEEE Transactions on Pattern 
Analysis and Machine Intelligence, Vol. 24, NO. 
12, pp. 1606-1617, 2002. 
[21]  Chin-Chuan Han, Hong-Yuan Mark Liao, 
Gwo-Jong Yu, and Liang-Hua Chen, " Fast face 
detection via morphology-based pre-processing, 
" Pattern Recognition, Vol. 33, pp. 1701- 1712, 
2000. 
[22]  Chiunhsiun Lin, and Kuo-Chin Fan, " Pose 
classification of human face by weighting mask 
function approach, " Pattern Recognition Letters, 
Vol. 24, pp. 1857- 1869, 2003. 
[23]  S.L. Wang, W.H. Lau, and S.H. Leung, " 
Automatic lip contour extraction from color 
images, " Pattern Recognition, Vol. 37, pp. 
2375- 2387, 2004. 
[24]  R.P.W. Duin, D.M.J. Tax, “Experiments with 
classifier combining rules”, First International 
Workshop on Multiple Classifier System, 
Cagliari, Italy, June 2000,Proceedings, p16-29 
[25]  C.Y. Suen, L. Lam, “Multiple classifier 
combination methodologies for different output 
levels”, First International Workshop on 
Multiple Classifier System, Cagliari, Italy, June 
2000,Proceedings, p52-66 
[26]  L. Lam, “Classifier combinations: 
Implementations and theoretical issues”, First 
International Workshop on Multiple Classifier 
System, Cagliari, Italy, June 2000,Proceedings, 
p77-86 
[27]  A.F.R. Rahman, M.C. Fairhurst, “An evaluation 
of multi-expert configurations for the 
recognition of handwritten numerals”, Pattern 
Recognition, Vol.31, No.9, pp.1255-1273,1998 
[28]  I. Haritaoglu, D. Harwood and L. S. Davis. “W4: 
who? When? Where? What? A Real-Time 
System for Detecting and Tracking People.” 
Proc. International Conference on Face and 
Gesture Recognition, April, 14-16, 1998. 
[29]  Surendra Gupte, Osama Masoud, Robert F. k. 
Martin, and Nikolaos P. Papanikolopoulos, 
“Detection and classification of vehicles.” IEEE 
Transactions on Intelligent Transportation 
System, Vol. 3, no. 1, March 2002 
[30]  T. Horprasert, D. Harwood and L.S. Davis, “A 
statistical approach for real-time robust 
background subtraction and shadow detection,” 
in Proc. IEEE Frame-Rate Workshop, 1999 
[31]  M.D. Beynon, D.J. Van Hook, M. Seibert, A. 
Peacock and D. Dudgeon, ”Detecting 
abandoned packages in a multi-camera video 
surveillance system,” in Proc. IEEE Conf. 
Advanced Video and Signal Based Surveillance, 
pp. 221-228, 2003. 
[32]  M. B. Stegmann, B. K. Ersbøll, R. Larsen, 
FAME - A Flexible Appearance Modelling 
Environment, IEEE Transactions on Medical 
Imaging, vol. 22(10), pp. 1319-1331, Institute 
of Electrical and Electronics Engineers (IEEE), 
2003 
[33]  J.C. Platt, N. Cristianini and J. Shawe-Taylor, 
“Large Margin DAG’s for Multiclass 
Classification, “Advances in Neural Information 
Processing Systems”, Cambridge, MA: MIT 
Press., vol. 12, pp.547–553, 2000.
