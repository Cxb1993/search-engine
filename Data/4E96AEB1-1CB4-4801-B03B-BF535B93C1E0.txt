中文關鍵詞： 人智運算、分析模擬、網際網路實驗、行動人智運算、地理
標註 
英 文 摘 要 ： ``Human Computation｀｀ represents a new paradigm of 
applications that take advantage of people｀s desire 
to be entertained and produce useful metadata as a 
by-product. By creating Games With A Purpose (GWAP), 
human computation has shown promise in solving a 
variety of problems that computer computation cannot 
currently resolve completely. Using the ESP game as 
an example, we have proposed a framework of 
mathematical modeling and analysis for evaluating the 
performance of human computation systems, and also 
used analysis to study the inner properties of the 
ESP game. We argue that human computation systems 
should be Played With A Strategy (PWAS). We have 
implemented an Optimal Puzzle Selection Algorithm 
(OPSA) based on our analysis, and demonstrated that 
the system performance of the ESP game can be 
significantly improved using our proposed strategy. 
 
In this project, we propose to research general 
system design strategies for existing human 
computation systems. First, we extend our preliminary 
analytical results and consider another two important 
factors, namely the playing time per game/round, and 
the agreement quality. Second, we investigate the 
mathematical modeling and analysis for the other two 
types of human computation games, namely inversion-
problem games and output-agreement games. Finally, we 
research future human computation systems in mobile 
networks. Using geographic tagging as an example, we 
research the analytical model for mobile human 
computation systems, and design appropriate 
strategies. By mashing up the information obtained 
from social networks, we investigate future advance 
network service that provides customized services 
based on the information provided by the mobile human 
computation systems. 
 
We tackle the above mentioned technical issues of 
human computation by performing analysis, and 
 行政院國家科學委員會補助專題研究計畫   
■成果報告    □期中進度報告  
 
人智運算系統效能提昇之系統設計策略研究 
 
 
計畫類別：■ 個別型計畫	 	 □ 整合型計畫 
計畫編號：ＮＳＣ－９８－２２２１－Ｅ－００１－０１４－ＭＹ３ 
執行期間：９８年０８月０１日至	 １０１年０７月３１日 
 
計畫主持人：陳伶志 
共同主持人： 
計畫參與人員：黃冠豪、鄭淙勻、呂孟林、李威賢、郭千瑜、余孝萱、 
              李嘉偉	 
 
 
成果報告類型(依經費核定清單規定繳交)：□精簡報告  ■完整報告 
 
本成果報告包括以下應繳交之附件： 
□赴國外出差或研習心得報告一份 
□赴大陸地區出差或研習心得報告一份 
□出席國際學術會議心得報告及發表之論文各一份 
□國際合作研究計畫國外研究報告書一份	 
 
處理方式：除產學合作研究計畫、提升產業技術及人才培育研究計畫、
列管計畫及下列情形者外，得立即公開查詢 
          □涉及專利或其他智慧財產權，□一年□二年後可公開查詢 
           
執行單位：中央研究院資訊科學研究所 
 
中   華   民   國 	 一 	 O 	 一 	 年 	 十 	 月 	 廿  八 	 日 
II. BACKGROUND
The Games With A Purpose (GWAP) genre [33, 35] is
a type of Human Computation that outsources certain steps
of the computational process to humans [19, 32, 37]. By
taking advantage of people’s desire to be entertained, GWAP
attract people to play voluntarily, and also produce useful
metadata as a by-product. The games have shown promise
in solving a variety of problems, such as image annotation
[34] and commonsense reasoning [22, 36], which computer
computation has been unable to resolve completely thus far.
Several GWAP-based geospatial tagging (geotagging) appli-
cations have been proposed in recent years [8, 11, 13, 17, 25,
26, 29, 30]. Generally, they can be grouped into two categories,
non mission-based and mission-based, depending on the level
of interaction among the players in a game. Non mission-based
GWAP geotagging systems perform human computation by
providing players with incentives to contribute geospatial tags
voluntarily, without implementing the concept of missions.
They are generally implemented in the form of location-based
social networks (LBSN) (such as Foursquare [2], Gowalla
[5], and GyPSii [6]) or by following the rules of conventional
games [25, 26, 29, 30].
For instance, the GeoTicTacToe [30] game, which is based
on the traditional TicTacToe game, is used to study the
synchronization problem in geospatial gaming systems. In the
CityPoker [29] game, which is an adaptation of the popular
card game, each player must try to improve his/her starting
hand by changing cards at 15 locations in the real world. By
analyzing the players’ tracks, CityPoker provides researchers
with a way to model the players’ behavior and interpret
the trajectory of a person moving in a spatial environment.
The results can help spatially grounded intentional systems
provide adequate services automatically according to the users’
intentions. Moreover, CityExplorer, proposed by Matyas et al
[25, 26], is a location-based variant of the popular board game
Carcassonne [1], which only allows players to place tokens
(followers) in pre-defined types of real-world locations. As a
result, players are “forced” to explore the unstructured game
area, which allows the system to collect specific geospatial
data, such as the geographic coordinates and the classifications
of real-world objects, as a by-product.
As their name suggests, mission-based GWAP geotagging
systems generate ‘missions’ that players must solve. They
provide incentives via a reward scheme that gives points to
players when they contribute to the system (e.g., when they
initiate or solve a task, or review a solution) [8, 11, 13, 17].
Since non mission-based games follow certain rules, in this
study, we regard them as special instances of mission-based
systems with multiple tasks that are assigned all at once in each
round. In this context, ‘multiple tasks’ means all the actions
that players are allowed to take.
For instance, Hitcher [13] is a location-based mobile game
that exploits the cellular infrastructure. Specifically, in a
Hitcher game, players create digital hitch hikers (with names,
destinations and questions to ask other players) and drop them
into their current cellular phone cell; or they pick up available
hitchers from their current cell, answer their questions, carry
them to new locations, and drop them again. As the hitchers
pass from player to player, phone to phone and cell to cell,
the system collects the meaningful space names of each
cell as a by-product. MobiMission [17] is a location-based
pervasive social game in which missions are created, solved,
and reviewed by players. The system does its best to assign
“nearby” missions to players (e.g., Find a good cafe near the
Empire State Building). If there are no nearby missions, it
assigns “location-independent” missions instead (e.g., Take a
picture of a tall building). Similarly, in the Gopher game [11],
missions are created, solved, and reviewed by players, but the
system only assigns missions to “nearby” players. Finally, the
Eyespy game [8] allows players to tag geographic locations
with photos or text; or ‘confirm’ the locations of places that
other players have tagged. The MarkIt game [27] encourages
players to take pictures of their physical surroundings and
upload to the game server. Then, players view all pictures
and have one chance with each image to label it or map it
to where they feel the picture was taken. As a result, Eyespy
and MarkIt produce a collection of recognizable and locatable
geographic details, which could be used for navigation and
location-based applications.
Although most GWAP-based geotagging works focus on
the design, implementation, and measurement of real-world
applications/systems, recent studies have shown that the per-
formance of GWAP systems can be improved significantly if
they are designed and played with strategies [12]. This finding
motivates us to investigate the design strategies of generic
GWAP-based geotagging systems. We present our analysis in
the following sections.
III. GWAP-BASED GEOTAGGING SYSTEMS
In this section, we describe GWAP-based geotagging sys-
tems and formulate the problem in sub-sectionIII-A. Then, we
present our analysis in sub-section III-B, and propose the three
evaluation metrics, namely the throughput utility, the fairness
utility, and the system utility, in sub-section III-C.
A. Game Description
We describe a generic GWAP-based geotagging system that
is both centralized and mission-based. The server is respon-
sible for data storage and task assignment, while the clients
are mobile players equipped with GPS-enabled handhelds and
wireless connectivity (e.g., 3G/WiFi) to the server via the
Internet. There are two game-playing roles: Requester and
Solver; and players are allowed to switch between the roles
freely during run time.
We assume that there are N locations of interest (LOI) in a
game, and that the server maintains N FIFO-based task queues
for each LOI in the system. Let Qi denote the task queue of
the i-th LOI, and let players arrive at the i-th LOI at a Poisson
rate of λi per time unit. We denote the ratio of the number of
Requesters over the number of Solvers as r (i.e., the Requester
arrival rate is rr+1λi and the Solver arrival rate is
1
r+1λi). The
arrival rate at the i-th LOI is λir+1 . Therefore, the proba-
bility that there will be n solvers at the i-th LOI can be
derived by Equation 3. However, since λi is unknown in
real systems, we use Equation 4 to approximate λi based
on the exponential moving average (EMA), where α is a
constant smoothing factor (0 < α < 1), and Ni(t) is the
number of player arrivals at the i-th LOI at time t.
pi(n) =
( λir+1 )
ne−
λi
r+1
n!
. (3)
λ′i(t+ 1) = αλ
′
i(t) + (1− α)Ni(t). (4)
The popularity factor of the task v (which is located at
the i-th LOI) is then defined as the probability that there
will be three or more solvers at the i-th LOI3, i.e.,
fp(v) = 1− pi(0)− pi(1)− pi(2). (5)
Let NSolveri (t) be the number of solver arrivals at the i-th
LOI at time t; ui(t, j) be the j-th solver arriving the i-th LOI
at time t; and vki (t, j) be the k-th task assigned to him/her
(1 ≤ k ≤ K). For ease of presentation, we use Wk to denote
W (ui(t, j), v
k
i (t, j)). Thus, the number of tasks completed in
each round, denoted by Ii,j(t), forms a Bernoulli distribution
with a success probability 1− p0, i.e.,
Ii,j(t) =
{
0 , with a probability p0;
1 , with a probability 1− p0; (6)
where p0 represents the probability that no tasks will be
completed in a round. Let pk be the probability that the j-
th solver chooses to complete the k-th task out of the K
tasks assigned (either all-at-once or one-by-one). Then, we
can obtain the values of p0 and pk in the following two cases:
• Case 1: The headmost K tasks are assigned all at once.
Since the solver can choose to complete one task (i.e.,
with a willingness Wk for the k-th task) or reject all the
K tasks, we let W0 denote the solver’s unwillingness
to accept any k tasks and define the value of W0 by
Equation 7. Thus, we can obtain the value of pk for 0 ≤
k ≤ K by Equation 8.
W0 = 1−
∑K
k=1Wk
K
. (7)
pk =
Wk∑K
l=0Wl
. (8)
• Case 2: The headmost K tasks are assigned one-by-one.
In this case, the K tasks are consecutive and independent
Bernoulli events with a success probability Wk for each
k ∈ [1 · · ·K], and the game round stops when one of the
tasks is completed. Therefore, p0 represents consecutive
failures and the value of pk, for 0 ≤ k ≤ K, can be
obtained by Equation 9.
3We define fp(v) as the probability of three or more solvers at the i-th
LOI, because triads have been widely accepted as the most elementary and
non-precarious social and sociological unit [28, 31].
pk =
{ ∏k−1
l=1 (1−Wl)Wk , if 1 ≤ k ≤ K;∏K
l=1 (1−Wl) , if k = 0.
(9)
Let T (t, i) be the number of tasks completed by the solver
arrivals of the i-th LOI at time t; and let A(t) be the overall
number of tasks solved in the system up to time t. We derive
T (t, i) and A(t) by Equations 10 and 11 respectively.
T (t, i) =
NSolveri (t)∑
j=1
Ii,j(t). (10)
A(t) =
N∑
i=1
t∑
j=1
T (j, i). (11)
Let pi denote the popularity of the i-th LOI. Then, we can
obtain T˜ (t, i), the normalized system throughput at the i-th
LOI at time t (w.r.t. pi) by Equation 12; and derive µ˜(t), the
average normalized system throughput at time t by Equation
13.
T˜ (t, i) =
∑t
j=1 T (j, i)
pi
, (12)
µ˜(t) =
1
N
×
N∑
i=1
T˜ (t, i). (13)
In addition, the coefficient of variation of the normalized
system throughput at time t, c.v.(t), can be derived by:
c.v.(t) =
√
1
N
∑N
i=1 (T˜ (t, i)− µ˜(t))2
µ˜(t)
. (14)
C. Evaluation Metrics
As mentioned earlier, GWAP-based geotagging systems
have two goals. To evaluate the system performance, we
propose the following three evaluation metrics. First, the
system prefers players’ best-efforts, i.e., they should solve
as many tasks as possible. Based on this criterion, we eval-
uate the system performance by using the throughput util-
ity metric, Uthroughput(t), which is identical to A(t), i.e.,
Uthroughput(t) = A(t).
Second, the system prefers fairness, i.e., the number of
solved tasks must be in proportion to the popularity of each
LOI. To assess this criterion, we use the fairness utility
metric, Ufairness(t), which is the inverse of c.v.(t), i.e.,
Ufairness(t) =
1
c.v.(t) .
To accommodate the two objectives, we design a third
metric called system utility, Usystem(t), by taking the product
of Uthroughput(t) and Ufairness(t), i.e.,
Usystem(t) = Uthroughput(t)× Ufairness(t). (15)
exponential distribution scenario (EXP), the Self-similar Least
Action Walk scenario (SLAW), and the Taipei city scenario
(TPE). It is assumed that there are 400 LOIs uniformly
distributed on a 20 × 20 grid, and that players arrive at the
i-th LOI at a Poisson rate of λi per time unit. In the scenarios,
the value of λi is determined as follows:
1) The EXP scenario: the value of λi is determined based
on an exponential distribution with the rate parameter
set to 0.2.
2) The SLAW scenario: we apply the SLAW model [21]
to a 2,000 × 2,000 area, and set the SLAW parameters
n wp (i.e., the number of waypoints to be generated)
and v Hurst (i.e., the Hurst parameter used in frac-
tional Brownian motion) at 2,000 and 0.75, as suggested
in [7], respectively. After using the SLAW generator [7]
to generate the waypoints, we divide the area into a 20
× 20 equal-sized grid and determine the value of λi by
counting the number of waypoints in the i-th cell. The
mean and the standard deviation of λi are 6 and 11.4926
respectively.
3) The TPE scenario: we use the map of central Taipei,
which covers approximately 25 sq. km (north to Taipei
SongShan Airport, east to Taipei City Hall, south to
National Taiwan University, and west to Taipei Main
Station), and divide it into a 20 × 20 equal-sized grid.
To determine the value of λi, we count the number of
bus stops in the i-th cell4. The mean and the standard
deviation of λi are 3.4485 and 2.2394 respectively.
For convenience, we set the smoothing factor α (cf. Equa-
tion 4) at 0.95 5. Moreover, unless otherwise specified, we
assume that two-thirds of the arriving players are requesters,
and the other one-third are solvers (i.e., r=2). The distance
threshold (cf. Equation 2) is set to five cell units (i.e., τ=5), and
the size of each LOI’s task queue is infinite. Each requester
initiates a new task at his current LOI, and each solver is
assigned K tasks in a round using one of the five task
assignment algorithms. All the results presented here are based
on the average performance of 100 simulation runs.
A. Evaluation results under the five schemes when K = 1
First, we evaluate the five task assignment algorithms in
the three scenarios when the number of tasks assigned in each
round, K, is equal to one. In Figures 3 and 4, we compare
the Uthroughput and Ufairness performance respectively. We
observe that the ARFA scheme achieves the highest throughput
performance, but it yields the worst fairness performance.
This is because the scheme always assigns the tasks with
the highest willingness estimates (i.e., Equation 1); thus, it is
more productive than the other schemes, but at the expense of
increased unfairness. In contrast, because the LTFA scheme
gives priority to fairness, it achieves a good coefficient of
4Information about bus routes in Taipei city is available at http://www.e-
bus.taipei.gov.tw/english/en index 6 1.html
5The parameters (α, the grid size, and the number of LOIs) are set to the
values based on the scenarios and heuristics in this study, and they are tunable
to match various scenarios of interest.
TABLE I
THE TIME REQUIRED BY EACH ALGORITHM TO COMPLETE ONE
SIMULATION ROUND IN THE THREE SCENARIOS. (UNIT: SECONDS)
RA SA ARFA LTFA HA
O(N) O(1) O(NlogN) O(NlogN) O(N2)
EXP 14.90 10.93 234.27 424.67 3,280.70
SLAW 16.07 11.95 239.68 460.79 3,230.19
TPE 13.64 8.95 85.76 153.13 1,149.50
variation performance, as shown in Figure 4; however, it
suffers from the equality of outcomes problem (i.e., lower
throughput performance), as shown in Figure 3. The results
in Figure 4 also show that the LTFA curve oscillates a great
deal at the beginning of the SLAW and TPE scenarios. This
is because its c.v.(t) performance depends to a large extent
on the accuracy of the λ estimation (cf. Equation 4), which
needs a warm-up period to become stable and accurate.
By combining the two metrics, we can compare the system
utility performance of the five algorithms, as shown in Figure
5. The results demonstrate that the HA scheme significantly
outperforms the other schemes. We also observe that, although
the RA and SA schemes represent the “golden mean” in Fig-
ures 3 and 4, they are not suitable because their system utility
performance is poor. However, we note that the computational
complexity of the HA scheme is too expensive to be deployed
in real-world systems (see Table I); hence, the LTFA scheme
is more favorable because its system utility performance is
comparable to that of the HA scheme, and its computational
complexity is moderate.
Figure 6 compares the distributions of the solve rates per
LOI of the five algorithms in Cumulative Distribution Function
(CDF) curves. The ‘solve rate’ is the percentage of tasks
solved at each LOI. The results show that under the ARFA
scheme, more than 50% of the LOIs produce zero outcomes
(i.e., the solve rate is zero), which confirms our intuition
that the scheme tends to suffer from the starvation problem.
Moreover, we observe that the curves of the HA and LTFA
schemes are nearly vertical, while the others are slanted. The
results also confirm our intuition that the two schemes are
better able to preserve the fairness of the normalized system
throughput. The HA scheme’s solve rate is higher than that of
the LTFA scheme because its throughput performance is better,
as shown in Figure 3. Finally, we observe that the ARFA curve
rises sharply in the SLAW and TPE scenarios, but not in the
EXP scenario. This is because the SLAW and TPE scenarios
are based on a 2D mobility model, whereas the EXP scenario
is a 1D model. Consequently, the SLAW and TPE scenarios
are better able to capture the spatial locality of popular LOIs.
Since the ARFA scheme can leverage this characteristic to
find a task in nearby areas easily, it increases the value of the
distance factor and the willingness estimate.
The results in Figure 7 show that the system utility of the
SA and ARFA schemes is consistent regardless of the value
of τ ; whereas the system utility of the RA, LTFA and HA
schemes increases with τ . This is because the SA scheme
always assigns the tasks that are at the same LOI as the solver,
 0
 100000
 200000
 300000
 400000
 500000
 600000
 700000
 800000
 1  2  3  4  5  6  7  8  9
U s
ys
te
m
(10
0)
τ
SA
ARFA
RA
LTFA
HA
(a) EXP scenario
 0
 25000
 50000
 75000
 100000
 125000
 150000
 175000
 200000
 1  2  3  4  5  6  7  8  9
U s
ys
te
m
(10
0)
τ
RA
SA
ARFA
LTFA
HA
(b) SLAW scenario
 0
 25000
 50000
 75000
 100000
 125000
 150000
 175000
 200000
 1  2  3  4  5  6  7  8  9
U s
ys
te
m
(10
0)
τ
RA
SA
ARFA
LTFA
HA
(c) TPE scenario
Fig. 7. Simulation results of the system utility performance with various τ values after 100 time units in the three scenarios when K = 1.
scenario, the HA scheme outperforms the other schemes, and
the LTFA scheme is ranked second, regardless of the values
of τ .
Finally, we observe the impact of r, i.e., the ratio of the
number of requesters to the number of solvers, on the system
utility performance. The results in Figure 9 show that, as the
value of r increases, the system utility performance improves
initially, and degrades after r becomes larger than a certain
number. For instance, under the HA scheme, the optimal value
of r is equal to 1 and 2 in the 1D mobility model scenario (i.e.,
the EXP scenario) and the 2D mobility model scenarios (i.e.,
the SLAW and TPE scenarios) respectively; whereas, under
the LTFA scheme, the optimal value of r is about 2 in the
three scenarios. The reason is that, when r is very small (i.e.,
most players are solvers), the system is short of tasks to assign
to solvers; whereas, when r is very large (i.e., most players
are requesters), the system is short of solvers to solve tasks.
As a result, there is one ‘optimal value’ of r that can yield the
highest system utility. Moreover, to ensure that the system is
productive, it is important to provide ‘just-enough’ incentives
to keep the value of r around the optimal value.
B. Evaluation results under the LTFA scheme when K > 1
As mentioned earlier, the LTFA scheme is the most suitable
for GWAP-based geotagging systems because its system utility
performance is competitive and its computational complexity
is moderate. Therefore, in this subsection, we only evaluate
the LTFA algorithm when the system assigns more than one
task (i.e., K > 1) to a solver in each game round.
Figures 10, 11, 12, and 13 show the Uthroughput perfor-
mance and Ufairness performance when K tasks are assigned
in a one-by-one manner and an all-at-once manner. Clearly, the
system throughput increases with the value of K; hence, the
larger the value of K, the faster the Ufairness performance
will converge. This is because the solver is more likely to
contribute a solution to one of the assigned tasks when the
value of K increases, so the system throughput will increase.
Moreover, since the LTFA algorithm favors the fairness cri-
terion when assigning tasks, the Ufairness performance also
converges to the equilibrium state more quickly.
Figure 14 shows that the system utility increases with the
value of K regardless of the value of r. It is recommended that
tasks be assigned in a one-by-one manner because the system
utility is consistently higher than when tasks are assigned all
at once. In addition, when the value of r is fixed at 2, Figure
15 shows that the system utility has a tendency to converge to
an equilibrium state when K is sufficiently large, regardless of
whether the K tasks are assigned in a one-by-one manner or
an all-at-once manner. However, the value of K must not be
too large in practice; otherwise, players will become annoyed
and discouraged.
The results in Figure 14 also demonstrate that, as the value
of r increases, the system utility performance improves at the
beginning, and degrades after r becomes larger than a certain
number. Moreover, the ‘optimal’ r value that yields the highest
system utility performance is consistent regardless of the value
of K and whether the K tasks are assigned all-at-once or one-
by-one. Specifically, the optimal value of r is equal to 1 and
1.5 in the 1D mobility model scenario (i.e., the EXP scenario)
and the 2D mobility model scenarios (i.e., the SLAW and
TPE scenarios) respectively. Again, the results confirm our
previous finding that, to ensure the system is productive, it is
important to provide ‘just-enough’ incentives to keep the value
of r around the optimal value.
C. Evaluation results under the LTFA scheme with various
buffer sizes
Next, we evaluate the impact of the buffer size per LOI on
the performance of GWAP-based geospatial tagging systems
in terms of the ‘block rate’, i.e. the percentage of tasks that are
blocked from entering the system because of buffer overflow.
Due to space limitations, it is not possible to provide a detailed
evaluation of each task assignment algorithm with different
system configurations. Instead, we only present the evaluation
results of the LTFA scheme when K = 1, as it provides the
baseline performance of the LTFA scheme. It has been shown
that the scheme is the most effective solution for GWAP-based
geospatial tagging systems.
Figure 16 compares the block rates per LOI in CDF curves
with various r values when the buffer size is set at 50 and
100 tasks in the three scenarios. We observe that, in all
scenarios, the curves are higher when the buffer size is larger
and the value of r is smaller. The reason is simply that the
larger the buffer size, the greater the likelihood that tasks will
be allowed to enter the system. Moreover, given the same
number of players in the system, the number of players that
 0
 10000
 20000
 30000
 40000
 50000
 60000
 70000
 80000
 0  10  20  30  40  50  60  70  80  90  100
U t
hr
ou
gh
pu
t
Time
k=1
k=2
k=5
k=10
(a) EXP scenario
 0
 10000
 20000
 30000
 40000
 50000
 60000
 70000
 0  10  20  30  40  50  60  70  80  90  100
U t
hr
ou
gh
pu
t
Time
k=1
k=2
k=5
k=10
(b) SLAW scenario
 0
 5000
 10000
 15000
 20000
 25000
 30000
 35000
 40000
 45000
 0  10  20  30  40  50  60  70  80  90  100
U t
hr
ou
gh
pu
t
Time
k=1
k=2
k=5
k=10
(c) TPE scenario
Fig. 12. Simulation results of the Uthroughput performance in the three scenarios, when r = 2 and the K tasks are assigned by the LTFA scheme in an
all-at-once manner.
 0
 2
 4
 6
 8
 10
 12
 0  10  20  30  40  50  60  70  80  90  100
U f
ai
rn
es
s
Time
k=1
k=2
k=5
k=10
(a) EXP scenario
 0
 1
 2
 3
 4
 5
 6
 7
 8
 9
 0  10  20  30  40  50  60  70  80  90  100
U f
ai
rn
es
s
Time
k=1
k=2
k=5
k=10
(b) SLAW scenario
 0
 1
 2
 3
 4
 5
 6
 7
 8
 9
 10
 0  10  20  30  40  50  60  70  80  90  100
U f
ai
rn
es
s
Time
k=1
k=2
k=5
k=10
(c) TPE scenario
Fig. 13. Simulation results of the Ufairness performance in the three scenarios, when r = 2 and the K tasks are assigned by the LTFA scheme in an
all-at-once manner.
 0
 200000
 400000
 600000
 800000
 1e+006
 1.2e+006
 0  0.5  1  1.5  2  2.5  3
U s
ys
te
m
(10
0)
r
K=1
K=3
K=5
K=7
K=9
(a) EXP scenario, all-at-once
 0
 400000
 800000
 1.2e+006
 1.6e+006
 0  0.5  1  1.5  2  2.5  3
U s
ys
te
m
(10
0)
r
K=1
K=3
K=5
K=7
K=9
(d) EXP scenario, one-by-one
 0
 100000
 200000
 300000
 400000
 500000
 600000
 0  0.5  1  1.5  2  2.5  3
U s
ys
te
m
(10
0)
r
K=1
K=3
K=5
K=7
K=9
(b) SLAW scenario, all-at-once
 0
 100000
 200000
 300000
 400000
 500000
 600000
 700000
 800000
 0  0.5  1  1.5  2  2.5  3
U s
ys
te
m
(10
0)
r
K=1
K=3
K=5
K=7
K=9
(e) SLAW scenario, one-by-one
 0
 100000
 200000
 300000
 400000
 0  0.5  1  1.5  2  2.5  3
U s
ys
te
m
(10
0)
r
K=1
K=3
K=5
K=7
K=9
(c) TPE scenario, all-at-once
 0
 100000
 200000
 300000
 400000
 500000
 600000
 0  0.5  1  1.5  2  2.5  3
U s
ys
te
m
(10
0)
r
K=1
K=3
K=5
K=7
K=9
(f) TPE scenario, one-by-one
Fig. 14. Simulation results of the system utility performance with various values of K and r after 100 time units, when the K tasks are assigned by the
LTFA scheme in an all-at-once manner and a one-by-one manner respectively.
problem, i.e., the number of the tasks available is less than
the number of solvers in the system. The results in Figure 17
show that the curve of the average queueing time per task (i.e.,
the time between when a task is input to the system until it is
completed by solvers) decreases initially, and then increases as
the value of r increases. The reason is that, when the value of r
is very small, there are not many tasks available in the system,
so the probability that a solver will be assigned a nearby task
decreases. As a result, solvers tend to reject the assigned tasks,
and the average queueing time per task increases. Meanwhile,
 0.4
 0.45
 0.5
 0.55
 0.6
 0.65
 0.7
 0.5  1  1.5  2  2.5  3
a
vg
. Q
ue
ue
ing
 T
im
e
r
BufferSize=50
BufferSize=100
(a) EXP scenario
 0.65
 0.7
 0.75
 0.8
 0.85
 0.9
 0.5  1  1.5  2  2.5  3
a
vg
. Q
ue
ue
ing
 T
im
e
r
BufferSize=50
BufferSize=100
(b) SLAW scenario
 0.76
 0.78
 0.8
 0.82
 0.84
 0.86
 0.88
 0.9
 0.92
 0.94
 0.5  1  1.5  2  2.5  3
a
vg
. Q
ue
ue
ing
 T
im
e
r
BufferSize=50
BufferSize=100
(c) TPE scenario
Fig. 17. Simulation results of the average queueing time of each task with various buffer sizes after 100 time units when K = 1 and r = 2 under the LTFA
scheme.
Second, the proposed model assumes each task is a simple
mission that involves only one LOI. It does not consider
complex missions comprised of multiple LOIs (e.g., Find
all Indian restaurants on Hollywood Boulevard) and/or the
transitions among multiple LOIs (e.g., What is the fastest
way to get to the airport from downtown in rush hour?).
Obviously, the model will require substantial modification so
that it can handle such complex missions. For example, it is
necessary to 1) redefine the concept of system utility when
a task is comprised of multiple LOIs; and 2) provide both
quantitative and qualitative metrics to evaluate the transitions
among multiple LOIs. Again, we defer a detailed discussion
of this issue to a future work.
VI. CONCLUSION
In this paper, we have studied emerging GWAP-based
geotagging systems, presented an analysis of their intrinsic
properties, and proposed three metrics to measure the system
performance. Based on our analysis, we designed five task
assignment algorithms that incorporate different heuristics
and optimization strategies. Using a comprehensive set of
simulations of synthetic and realistic mobility scenarios, we
found that the Hybrid Assignment (HA) algorithm achieves
the best system utility performance, but it is too computation-
hungry to be deployed. In practice, the Least-Throughput-First
Assignment (LTFA) algorithm is the most suitable scheme
because its computational complexity is moderate, and its
overall performance is comparable to that of the HA scheme.
Moreover, to improve the system utility, it is better to assign
as many tasks as possible in each game round; however,
assigning too many tasks at the same time may annoy players.
Finally, when multiple tasks are assigned in each round, it is
better to assign them in a one-by-one manner, rather than an
all-at-once manner, in order to maximize the system utility.
The proposed analysis is simple and applicable to emerging
GWAP-based geotagging systems. We believe the results of
this study could improve the design and implementation of
GWAP-based geotagging systems.
REFERENCES
[1] Carcassonne. http://www.carcassonne.de/.
[2] Foursquare. http://foursquare.com/.
[3] GeoTagging Flickr. http://www.flickr.com/groups/geotagging/.
[4] Google Maps. http://maps.google.com/.
[5] Gowalla. http://gowalla.com/.
[6] Gypsii. http://www.gypsii.com/.
[7] SLAW Generator. http://netsrv.csc.ncsu.edu/.
[8] M. Bell, S. Reeves, B. Brown, S. Sherwood, D. MacMil-
lan, J. Ferguson, and M. Chalmers. Eyespy: Supporting
navigation through play. In ACM SIGCHI, 2009.
[9] S. H. Bokhari. Assignment Problems in Parallel and
Distributed Computing. Springer, 1987.
[10] T. L. Casavant and J. G. Kuhl. A taxonomy of scheduling
in general-purpose distributed computing systems. IEEE
Transactions on Software Engineering, 14(2):141–154,
Feburary 1988.
[11] S. Casey, B. Kirman, and D. Rowland. The gopher
game: a social, mobile, locative game with user generated
content and peer review. In International Conference on
Advances in Computer Entertainment Technology, 2007.
[12] L.-J. Chen, B.-C. Wang, and K.-T. Chen. The Design of
Puzzle Selection Strategies for GWAP Systems. Journal
of Concurrency and Computation: Practice and Experi-
ence, John Wiley & Sons Ltd., 22(7):890–908, May 2010.
[13] A. Drozd, S. Benford, N. Tandavanitj, M. Wright, and
A. Chamberlain. Hitchers: Designing for Cellular Posi-
tioning. In UbiComp, 2006.
[14] J. Froehlich, J. Neumann, and N. Oliver. Measuring the
Pulse of the City through Shared Bicycle Programs. In
ACM UrbanSensing, 2008.
[15] N. Gershenfeld. The Nature of Mathematical Modeling.
Cambridge University Press, 1998.
[16] J. Goldman, K. Shilton, J. Burke, D. Estrin, M. Hansen,
N. Ramanathan, S. Reddy, V. Samanta, M. Srivastava,
and R. West. Participatory Sensing: A Citizen-powered
Approach to Illuminating the Patterns That Shape our
World. Foresight & Governance Project, White Paper,
2009.
[17] L. Grant, H. Daanen, S. Benford, A. Hampshire,
A. Drozd, and C. Greenhalgh. MobiMissions: the game
of missions for mobile phones. In ACM SIGGRAPH,
2007.
[18] T. Horanont and R. Shibasaki. An Implementation of
Mobile Sensing For Large-Scale Urban Monitoring. In
Least-Throughput-First Assignment algorithm (LTFA) is the
most effective approach because it can achieve competitive
system utility, while its computational complexity remains
moderate. We also find that, to improve the system utility, it
is better to assign as many tasks as possible in each round.
However, because players may feel annoyed if too many
tasks are assigned at the same time, it is recommended that
multiple tasks be assigned one by one in each round in order
to achieve higher system utility.
3) Bo-Chun Wang, Wen-Yuan Zhu, and Ling-Jyh Chen,
“Improving Amazon-like Review Systems by Considering the
Credibility and Time-Decay of Public Reviews,” Informatica
Journal, volume 35, number 4, pages 463-472, December
2011.
Abstract:
In this study, we investigate the review system of Amazon.com,
which is regarded as one of the most successful e-
commerce websites in the world. We believe that the review
results provided by Amazon’s review system may not be
representative of the advertised products because the system
does not consider two essential factors, namely the credibility
and the time-decay of public reviews. Using a dataset
downloaded from Amazon.com, we demonstrate that although
the credibility and time-decay issues are very common,
they are not handled well by current public review systems.
To address the situation, we propose a Review-credibility
and Time-decay Based Ranking (RTBR) approach, which
improves the Amazon review system by exploiting the
credibility and time-decay of reviews posted by the public.
We evaluate the proposed scheme against the current Amazon
scheme. The results demonstrate that the RTBR scheme is
superior to the Amazon scheme because it is more credible
and it provides timely review results. Moreover, the scheme
is simple and applicable to other Amazon-like review systems
in which the reviews are time-stamped and can be evaluated
by other users.
4) Kuan-Ta Chen, Chien-Wei Lin, Ling-Jyh Chen, and Irwin
King,, chapter “Human Computation Games and Optimization
of Their Productivity,” Web Intelligence and Intelligent
Agents, Zeeshan-Ul-Hassan Usmani, editor, pages 289-304,
InTech, 2010.
Abstract:
Web 2.0 technology enables people worldwide to collaborate
over the Internet, a phenomenon known as social collaboration.
While the incentives for social collaboration are primarily
enthusiasm for a particular subject, building a reputation,
or gaining a benefit by doing something in exchange for
using services or downloading files, the emergence of human
computation games has shown that the prospect of having fun
can be a strong incentive for participants to actively engage
in such collaboration. Among the human computation games,
ESP game (ESP stands for Extrasensory Perception) is one of
the most popular ones. To play an ESP game, two randomly
matched players assign labels that appropriately describe an
image provided by the system. It has been shown that the
“outcomes” of ESP games have many useful applications,
such as image-based CAPTCHA tests and semantic image
searches. In this chapter, we provide an overview of human
computation games and present an analytical model for
computing the utility of ESP games, i.e., the throughput
rate of appropriate labels for given images. The model
targets generalized games, where the number of players,
the consensus threshold, and the stopping condition are
variable. Via extensive simulations, we show that our model
can accurately predict the stopping condition that will yield
the optimal utility of an ESP game under a specific game
setting. A service provider can therefore utilize the model to
ensure that the hosted ESP games produce high-quality labels
efficiently, given that the number of players willing to invest
time and effort in the game is limited.
5) Yu-Song Syu, Hsiao-Hsuan Yu, and Ling-Jyh Chen,
“Exploiting Puzzle Diversity in Puzzle Selection for ESP-like
GWAP Systems,” IEEE/WIC/ACM International Conference
on Web Intelligence (WI’10), Toronto, Canada, 2010.
Abstract:
The ESP game belongs to the genre called Games with
a Purpose (GWAP), which leverage people’s desire to
be entertained and also outsource certain steps of the
computational process to humans. The productivity of
ESP-like GWAP systems depends to a great extent on the
puzzle selection strategy used in the system. Although
traditional approaches seek to determine the optimal number
of agreements reached in each puzzle, they may be affected
by the equality of outcomes issue because they ignore the
differences among puzzles. In this paper, using realistic game
traces, we define the puzzle diversity issue and propose
a novel approach, called the Adaptive Puzzle Selection
Algorithm (APSA), to promote equality of opportunity
in ESP-like GWAP systems. We also introduce a data
structure called the Weight Sum Tree (WST) to reduce
the computational complexity of the proposed scheme and
facilitate its implementation in real-world systems. Using a
comprehensive set of simulations, we evaluate the APSA
scheme against the traditional OPSA scheme, and demonstrate
that APSA can better accommodate the differences among
puzzles in ESP-like GWAP systems.
6) Ling-Jyh Chen, Bo-Chun Wang, and Wen-Yuan Zhu, “The
Design of Puzzle Selection Strategies for ESP-like GWAP
Systems,” IEEE Transactions on Computational Intelligence
and AI in Games, volume 2, number 2, pages 120-130, June
2010.
Abstract:
The ‘Games With A Purpose’ (GWAP) genre is a type of
‘Human Computation’ that outsources certain steps of the
computational process to humans. Although most GWAP
studies focus on the design and analysis of GWAP systems,
a systematic and thorough evaluation of existing systems is
lacking. We address the issue in this paper. Taking the ESP
game as an example, we propose a metric, called system
utility, for evaluating the performance of GWAP systems, and
use analysis to study the properties of the ESP game. We
argue that GWAP systems should be designed and played with
strategies. To this end, based on our analysis, we implement
an Optimal Puzzle Selection Strategy (OPSA) to improve
GWAP systems. Using a comprehensive set of simulations,
we show that the proposed OPSA approach can improve the
system utility of the ESP game sufficiently. In addition, we
implement a quasi ESP game, called ESP Lite, which embeds
three puzzle selection algorithms transparently and records
the complete game trace for evaluation and further research.
During a one-month experiment, we have investigated the
inner properties of the three strategies in real-world GWAP
systems, and verified that the OPSA scheme achieves the best
system utility for the ESP game. The results of this study
demonstrate that GWAP systems are more efficient if they are
designed and played with strategies.
7) Ling-Jyh Chen, Bo-Chun Wang, and Kuan-Ta Chen, “The
Design of Puzzle Selection Strategies for GWAP Systems,”
Concurrency and Computation: Practice and Experience, John
the utility of ESP games, i.e., the throughput rate of
appropriate labels for given images. The model targets
generalized games, where the number of players, the
consensus threshold, and the stopping condition are variable.
Via extensive simulations, we show that our model can
accurately predict the stopping condition that will yield the
optimal utility of an ESP game under a specic game setting. A
service provider can therefore utilize the model to ensure that
the hosted ESP games produce high-quality labels efficiently,
given that the number of players willing to invest time and
effort in the game is limited.
13) Ling-Jyh Chen, Bo-Chun Wang, Kuan-Ta Chen, Irwin King,
and Jimmy Ho-Man Lee, “An Analytical Study of Puzzle
Selection Strategies for the ESP Game,” IEEE/WIC/ACM
International Conference on Web Intelligence (WI’08), 2008.
Abstract:
“Human Computation” represents a new paradigm of
applications that take advantage of people’s desire to be
entertained and produce useful metadata as a by-product.
By creating games with a purpose, human computation
has shown promise in solving a variety of problems that
computer computation cannot currently resolve completely.
Using the ESP game as an example, we propose a metric,
called system gain, for evaluating the performance of
human computation systems, and also use analysis to study
the properties of the ESP game. We argue that human
computation systems should be played with a strategy.
To this end, we implement an Optimal Puzzle Selection
Strategy (OPSA) based on our analysis to improve human
computation. Using a comprehensive set of simulations,
we demonstrate that the proposed OPSA approach can
effectively improve the system gain of the ESP game, as
long as the number of puzzles in the system is sufciently large.
B. Released Source Codes / Dataset
1) GWAP API: http://hcomp.iis.sinica.edu.tw/GWAP API/
2) ESP Lite: http://hcomp.iis.sinica.edu.tw/GWAP/ESPLite/
3) ESP Lite Dataset: http://hcomp.iis.sinica.edu.tw/dataset/
C. Research Assistants Mentoring
The project is considered productive not only in terms of the
number of the papers published in inter- national venues, but
also the professional training for MS/PhD students to learn
emerging computer network theories, research, implementa-
tion, and troubleshooting skills. We have mentored/supervised
the following students and research assistants during the
project years.
1) Year 1
a) Mr. Wen-Yuan Zhu (MS student, National Taiwan
Normal University)
b) Ms. Tsu-Tsai Lin (MS student, National Cheng Chi
Univeristy)
c) Mr. Ying-Yu Chen (Research Assistant, Academia
Sinica)
2) Year 2
a) Mr. Guang-How Huang (BS student, National Tai-
wan University)
b) Ms. Yi-Yin Chang (Research Assistant, Academia
Sinica)
c) Mr. Cheng-Hong Lin (Placement: Mediatek Inc.)
d) Mr. Fu-Wei Chen (Placement: Military Service)
e) Ms. Hsiao-Hsuan Yu (Research Assistant,
Academia Sinica)
3) Year 3
a) Mr. Meng-Lin Lu (MS student, National Taiwan
University)
b) Mr. Tsung-Yun Cheng (MS student, National Tai-
wan University)
c) Mr. Guang-How Huang (BS student, National Tai-
wan University)
d) Mr. Wei-XIan Lee (MS student, National Taiwan
Normal University)
e) Ms. Chien-Yu Kuo (MS student, National Taiwan
Normal University)
f) Mr. Chia-Wei Li (Research Assistant, Academia
Sinica)
g) Ms. Hsiao-Hsuan Yu (Placement: MS student, Uni-
versity of California at Irvine)
98年度專題研究計畫研究成果彙整表 
計畫主持人：陳伶志 計畫編號：98-2221-E-001-014-MY3 
計畫名稱：人智運算系統效能提昇之系統設計策略研究 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 1 1 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 6 4 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 1 0 100% 
人次 
 
期刊論文 3 1 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
