First, we build a self-protect walking robot for 
obstacle avoidance automatically. This is also a 
prototype platform for further research in this area. 
Secondly, we use the HDR techniques to improve image 
when the light is too dark or too bright in some 
region, so the robot can see the lines, the shapes, 
the corners and the colors clearly. And finally, we 
use the SIFT algorithm with the geometric 
relationships and limitations between two consecutive 
images to remove false matching points, and then we 
can reconstruct the spatial relationships. 
 
英文關鍵詞： autonomous robots, obstacle avoidance, high dynamic 
range image, corner detection, SIFT feature 
transformation, key point matching, perspective 
projection, vanishing point, vanishing line, service 
robots, space cognition, care robots. 
 
 2 
對亮度做調整。而機器人之視覺也是相同，如何克服類似的問題，成為重要的關鍵。自主機器人在居
家的環境下，常因環境不同的光線、照度，造成對環境之辨識與認知，有極大之差異。我們希望對這
點有所改善，才能再談空間認知的問題。 
在空間認知方面，人類視覺系統中，雙眼是唯一能夠認知距離的利器。有了距離感我們才能一眼
就拿到我們想要的東西，沒有失誤，我們也才能精準掌握與前車安全的距離，不會發生擦撞。故立體
視覺中深度的資訊，對自走機器人來說，亦是相當重要。在微軟 Kinect感測器，除提供影像資訊外，
即增加一組紅外線發射器和紅外線 CMOS攝影機，構成 3D深度感應器，除提供影像外，還提供深度的
資訊。深度訊息基本上透過雙鏡頭即可提供，若同時沒有雙鏡頭，透過雙視界(Two View)加上複雜的
數學計算公式，亦可提供深度之訊息。吾人即希望機器人對服務之空間概況有所認識，即對空間之比
例有所概念，在室內提供相關之空間訊息。 
 
三、 文獻探討 
 
在『行』的方面:自走機器人，機器人分足型機器人[1]和輪型機器人，足型機器人靈活度較高，
可克服各種障礙物，但設計上相對較為困難，而輪型機器人設計則相對簡單，適用於一般平坦的路面
上。本研究以一般室內空間為主，故採輪型機器人，在機器人自走車，自我感知方面，機器人常用的
感測器為超音波感測器和紅外線感測器，Ando等人[2]利用聲納感測器，讓機器人能沿著牆行走，而
Tsai[3]則利用多個超音波發射器和接收器，讓機器人得知障礙物相對正確的方向和位置。 
在『視』的方面:看得見重要特徵，看得出相對距離，感官的視覺上是相當重要的一件事，在室內
空間中，常充滿許多直的線條，在室內設計上，除非是一些特殊的藝術設計，否則也多以直線、直角
的造型為主，因此在無形中，提供我們雙眼許多距離判斷之依據。在先前的研究中”以二維影像進行
室內空間距離之估測” [4]，我們利用單張影像，以及空間中之幾何投影關係，初步找出空間中距離
之比例關係。但因只用單張影像，相對距離較遠，所得到的比例關係，誤差亦隨著距離變遠而加大。
再加上兩三年前的傻瓜相機鏡頭，感光度偏低，取得的影像僅能在照度清楚的情況下，運作才會有較
佳之結果。碰到有高反差的環境，空間中之相關直線線條不易篩選出。所以在看得見重要特徵，看得
出相對距離之需求下，前提還要看得見、看得清楚、看得準確。 
近年來，高動態範圍影像(High Dynamic Range Image, HDR Image)，隨者單眼或類單眼相機開始
流行，也看見有廠商將相關功能建入高單價的相機中。早期一般相機，由於環境光度變化太大，而相
機只能針對部分區域”看清楚”，照顧到亮的區塊，暗的區塊亮度即明顯不足，照顧了暗部區域，亮
的區塊即發生明顯過曝。Debevec與 Milik[5][6]即提出當遇到高對比反差的景象時，對欲拍攝的場景
拍攝多張曝光時間不同的照片，以擷取場景中由暗到亮動態範圍不同之影像，再將此多張照片加以合
成出一張高動態範圍影像的照片，清楚表現影像清晰的細節，大大消除影像局部不清的情形，明顯解
決亮部或暗部有部分區塊不清楚的問題。 
單張影像，理論上不具備深度資訊，Kinect 用額外的紅外線發射與接收器提供了深度資訊，但資
訊有效距離大概數公尺左右，一般深度訊息可透過雙鏡頭立體影像計算出，當然也有有效距離。若自
走車機器人之攝影機為單鏡頭，但在行走過程中，卻能連續提供多張影像，以 Two view角度，若找到
空間之相對對應點，配合[4]先前單張影像測出空間比例之關係，就可延伸空間距離之深度訊息。 
 4 
方法則偏向第二種，由不同角度，空間中在不同位置，才能有不同之畫面。因此，機器人『行』的重
要性就顯現了。針對行的部分，我們建置了一台能自動避障的自走車，模擬機器人自主行動或遠端操
控時，近接時，具有自我避障之能力。雖機器人可以有視覺，但第二層的自我保護，可避免自走車機
器人，在視界不明時，發生誤撞或跌落落差地面的可能。整個具自我避障功能之自走機器人系統流程
圖如圖表 1所示。本研究採用單一個超音波感測器搭配伺服馬達來回旋轉，以感知近 360度大範圍空
間中是否有障礙物，此方法可降低成本，也可避開多顆感測次易發生相互會干擾之問題，再配合 QTI
循線感測器，檢知地面是否有地面落差，適時防止機器人跌落樓梯落差地面。控制中以邊緣偵測之演
算法為最高優先，其次為超音波避障之演算法，最後才由電腦操控，如此可保護自走車在人為不當操
作下發生毀損之可能。 
 
在『視』的方面， 自主機器人在居家的環境下，常因環境不同的光線或照度，造成對環境之辨識
與認知有極大之差異。針對機器人視界不明的情況多半是，白天天氣陰暗而室內未開燈，或內、外光
線照度相差太大，或窗邊有逆光的情形，或半夜機器人行走走廊時，多半照明半開，有些區塊亮、有
些區塊暗。這種情形，既使調整影像全域亮度或做全域對比增強，都無法解決。故吾人採高動態影像
之方法，改善光度過度與不足的情形，讓機器人能清楚看出高反差的景象。我們所用的方法以 Debevec
與 Milik[5][6]所提出的方法為主架構，即將亮到暗取得多張不同曝光程度之照片，合成出一張照片
的 HDR影像，如此解決亮部或暗部有部分區塊不清楚的問題。我們使用 Debevec與 Milik之架構，拍
攝三張 EV值不同之照片，修改合成照之權重配置，進行高動態範圍影像照片，讓整個視界都能很清晰，
以利後續方便特徵點之尋找。如此高動態影像之方法，改善影像過曝或不足的情形，改善因環境照度
不佳、對比反差過大之情況。 
在空間認知特徵點之比對上，我們採取 SIFT [10] [11]之架構進行特徵點比對，再依照空間之幾何
關係將不必要之對應關係刪除。在假設連續拍攝影像中兩張照片，移動空間位置不大，且車體行進之
方向即為攝影機的方向，第 n 張影像與第 n+1 張影像對應點之法則應如是。我們即以此消去過多的對
應點，以形成空間之幾何對應。 
遠 
近 
#n 
#n+1 
圖表 2 特徵點消去之幾何空間法則 
 6 
  
 
 
圖表 4 左上、右上、左下圖分別為原始圖不同曝光影像圖，右下角為高動態範圍影像
處理合成結果，室內清晰可見，室外光景與色板也依然清楚 
圖表 5  SIFT處理後之對應點 
 8 
 
參考文獻 
 
[1] S. Kajita and K. Tani, "Experimental study of biped dynamic walking," IEEE Control Systems Magazine, 
vol. 16, pp. 13-19, 1996. 
[2] Y. Ando and S. Yuta, "Following a Wall by an Autonomous Mobile Robot with a Sonar-Ring," IEEE 
International Conference on Robotics and Automation, vol. 3, pp. 2599-2606, 2005. 
[3] Ching-Chih Tsai, "A localization system of a mobile robot by fusing dead-reckoning and ultrasonic 
measurements," IEEE Transactions on Instrumentation and Measurement, vol. 47, pp. 1399-1404, 1998. 
[4] 駱有聲, 李昀翰 ,“以二維影像進行室內空間距離之估測” , 銘傳大學 2010 年國際學術研討
會 , 電子工程組，pp. 206 - pp. 218, Mar. 2010. 
[5] Paul E. Debevec and Jitendra Malik. "Recovering high dynamic range radiance maps from photographs", 
in Proceeding of Computer graphics and interactive techniques (SIGGRAPH '97), New York, NY, USA, pp. 
369-378, 1997.  
[6] Paul Debevec. “Rendering synthetic objects into real scenes: bridging traditional and image-based 
graphics with global illumination and high dynamic range photography”. In ACM SIGGRAPH 2008 classes 
(SIGGRAPH '08). ACM, New York, NY, USA, Article 32 , 10 pages. 2008. 
[7] Shan Zhu; Kai-Kuang Ma, “A new diamond search algorithm for fast block-matching motion estimation,” 
Image Processing, IEEE Transactions on , vol.9, no.2, pp.287-290, Feb 2000. 
[8] C. Harris, and M. Stephens, “A combined corner and edge detector,” 4th Alvey Vision Conf., Manchester, 
UK, 1988, pp. 147–151. 
[9] J.-B. Ryu, C.-G. Lee and H.-H. Park, “Formula for Harris corner detector,” Electronics Letters , vol.47, 
no.3,  pp.180-181,  February 3 2011. 
[10] David G. Lowe, “Distinctive image features from scale-invariant keypoints,” International Journal of 
Computer Vision, vol. 60, no. 2, pp. 91-110, 2004. 
[11] David G. Lowe, “Object recognition from local scale-invariant features,” Proceedings of International 
Conference on Computer Vision, vol. 2, no. 9, pp. 1150-1157, 1999. 
[12] A. Vedaldi and B. Fulkerson, “VLFeat: An Open and Portable Library of Computer Vision Algorithms”, 
2010, ACM Proceedings of the international conference on Multimedia 2010. 
[13] Sift 函式庫網站，http://www.vlfeat.org/ . 
[14] 駱有聲、魏士亮、莊子賢、盧昭男,“自走車避障之研究” , 銘傳大學 2012 資訊科技與實務國際
研討會，pp. 99 - pp. 106, Mar. 2012. 
 
99 年度專題研究計畫研究成果彙整表 
計畫主持人：駱有聲 計畫編號：99-2221-E-130-016- 
計畫名稱：機器人室內空間認知之研究 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 1 0%  
研究報告/技術報告 0 0 100%  
研討會論文 1 1 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
