 2
There are many research institutes 
investigating this research topic worldwide, 
but few in Taiwan. Our team has been 
working on automatic speech recognition, 
spoken document retrieval, audio 
segmentation, speaker clustering, and 
speaker recognition for many years. In this 
project, we want to spend three years to 
extensively investigate the Speaker 
Diarization task. We will establish Chinese 
benchmark corpora to promote this research 
topic in Taiwan. The techniques developed in 
this project can be used to automatically 
extract metadata from video or audio, which 
will be very useful for management of and 
access to multimedia video/audio databases. 
This project focuses on: (1) 
establishment of speech corpora for 
benchmark test, (2) audio segmentation and 
speaker clustering, (3) study on prosodic and 
linguistic features for speaker diarization, (4) 
study on speaker and language identification 
for speaker diarization, and (5) system 
integration. 
 
Keywords: Speaker Diarization, Audio 
Segmentation, Speaker Clustering, Speaker 
Recognition 
 
二、計畫緣由與目的 
 
過去數十年，美國NIST(National Institute of 
Standard and Technology)主辦過無數次自
動語音辨識(Automatic Speech Recognition, 
ASR)技術評比，對於自動語音辨識技術的
發展，功不可沒。自2002年起，NIST評比
任務主要為RT(Rich Transcription)，其目的
是希望自動語音辨識結果有更高的可讀
性，讓人們易於使用電腦來管理及使用大
量的錄音資料。因此，任務首重音轉字轉
寫(Speech-to-Text Transcription, STT)和後
設資料擷取(Metadata Extraction, MDE)兩
大類。目前RT任務使用的標準語料庫包括
廣播新聞語料、電話對談語料及會議錄音
語料。STT評比涵蓋英文、中文和阿拉伯
文，但MDE評比只考慮英文。參與的研究
機構主要包括：MIT Lincoln Laboratory, 
CMU, Cambridge University, University of 
Washington, Brown University, Karlsruhe 
University, Athens Information Technology, 
IBM, LIMSI, INRIA, SRI International, 
International Computer Science Institute等。 
在RT評比之前，NIST主辦過的評比項
目包括廣播新聞語音辨識、語音文件檢索
(Spoken Document Retrieval)等，前者屬於
單純的自動語音辨識任務，但是廣播新聞
語音信號中可能包含各式各樣的雜訊，而
說話的人和說話方式千變萬化，對自動語
音辨識系統而言，確實是很大的挑戰，例
如，一般的語音辨識系統對於攝影棚內主
播字正腔圓的播音，辨識率相當高，但是
對於新聞事件現場雜訊環境下，被採訪者
的即興口語(Spontaneous Speech)，卻可能
一籌莫展。經過數年的努力，雖然現今的
自動語音辨識系統對於雜訊環境下的即興
口語辨識率仍舊偏低，但確實已經向前跨
越了一大步。語音文件檢索的任務定義是
利用自動語音辨識技術對廣播電視新聞等
語音文件進行語音辨識，然後利用辨識結
果建立索引(Indexing)，再整合資訊檢索
(Information Retrieval)技術，讓語音文件像
文字檔案一樣，可以被方便查詢。RT任務
中的STT屬於自動語音辨識，MDE相當於
對語音文件自動建立除了文字內容之外，
更豐富的文件內涵索引。 
在 MDE 評比類別中，有一個項目是語
者自動分段標記(Speaker Diarization)，又稱
作"Who Spoke When"，顧名思義，就是要
在一段錄音資料中區分出不同說話者的說
話區段，並一一標示出來。這項工作主要
涉及三個步驟：(1)將音訊自動切割成為很
多小區段，目標是每一小區段只包含一個
說話者；(2)對這些小區段進行自動分群，
希望每一群集都只包含一個說話者的聲
音；(3)判別每一群集的性別，給予一個說
話者識別身分，最後與 STT 產生的自動語
音辨識結果整合。 
Speaker Diarization在國外上已經有不
少研究機構投入，但國內迄今無任何團隊
從事相關研究。我們實驗室過去在自動語
音辨識、語音文件檢索、自動音訊分段和
分群、語者辨識等方面已累積多年的經
驗，想利用三年的時間，將這項研究議題
做一個徹底的探討。相關的技術可以用來
自動抽取多媒體影音資料庫的後設資料，
對於多媒體影音資料的管理及查詢將非常
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 4
圖二: 凝聚分群法示意圖 
 
(2) 音訊/語者分段技術研發 
以 BIC 為基礎的音訊/語者分段法是音訊/
語者分段研究領域中的一大主流方法
[5][6][8]。其中，window-growing-based 分
段法 (WinGrow) [5] 是目前公認的一種高
正確率的分段方法；然而，其缺點是這種
類似由下而上(bottom-up)的作法計算複雜
度很高。有鑑於此，我們提出兩個基於 BIC
之分割且克服(divide-and-conquer)的分段
方法 –DACSeg1 與 DACSeg2 ；相較於
WinGrow，它們是由上而下(top-down)的偵
測法，計算複雜度較低；而根據我們的實
驗結果，它們卻得到較高的分段正確率。
我們已將此研究成果發表在著名的國際會
議(ICASSP 2008) [9]，其延伸的完整版本則
發表在 IEEE Transactions on Audio Speech 
and Language Processing 期刊[10]。 
   以下簡介我們的第一個方法。如演算法
一所示，DACSeg1 以遞迴的方式，用
WinGrow [4] 中的單一分段點偵測法
(OCD-Chen)尋找分析窗(analysis window)
中 ΔBIC 最大的時間點，假定為 t，然後在
t 將分析窗切割成兩個子窗(sub-window)。
若 t 的 ΔBIC 值大於 0，則將其標註為分段
點。在遞迴返回時，檢查每一個沒有被標
註為分段點的切點；檢查的方式是在 
Combine stage 計算 t 左右相鄰兩音段的
ΔBIC 值，若大於 0 則 t 被標註為分段點，
否則不為分段點。對一個很長的音訊串
流，比如一小時的廣播新聞錄音，將一整
個音訊串流作為初始的分析窗在計算上是
不可達到的(infeasible)；所以，我們進一步
提出一種依序式分割且克服音訊/語者分段
法來解決此問題。如圖三所示，我們在一
個固定長度(例如 20 秒)的分析窗上執行
DACSeg1 演算法，若有偵測到分段點，則
從時間上最大的分段點開始進行下一回合
的偵測；否則，將分析窗在時間軸上平移 ηL
之後，再進行下一回合的偵測，其中 L 表
示分析窗的長度。如此，我們可依序地使
用 DACSeg1 偵測長音訊串流中的分段點。 
 
procedure CPÅ DACSeg1(W) 
//input: W, the analysis window . 
//output: CP, the set of change points detected in W. 
Begin 
1. //Check termination 
    if (the size of W is smaller than Nmin) 
       CP Å empty set; 
       goto End; 
2. //Divide 
    perform OCD-Chen on W, and let t be the time index 
with the largest ΔBIC value; 
    divide W into two sub-windows, W1 and W2, at t; 
3. //Solve sub-instances 
    CPW1 Å DACSeg1(W1); CPW2 ÅDACSeg1(W2); 
4. //Combine 
    if (ΔBIC{W1, W2}(t) calculated in 2) is larger than zero) 
       CP Å t ∪ CPW1 ∪ CPW2 ; 
    else 
       let X be the segment left to t in W1 and Y be the  
segment right to t in W2 ; 
       if (ΔBIC{X, Y} (t) > 0) //t is a change point 
         CP Å t ∪ CPW1  ∪ CPW2 ; 
       else //t is not a change point 
          merge X and Y; 
          CP Å CPW1 ∪ CPW2 ; 
End 
 
演算法一: DACSeg1 分割且克服音訊/語者
分段法 
 Audio stream
L
Seg1 Seg2 Seg3 Seg4
DACDec1 or
DACDec2
 
 
 
 
 
 
 
 
圖三:依序式 DACSeg1 分段法 
 
在 第 一 個 方 法 中 我 們 用 WinGrow 的
OCD-Chen決定DAC的切點；這是整個演算
法中計算成本最高的部分。為了提升速
Analysis
indoww
表一：在 EER 時各分段法在 RT03 上的 real-time factor (xRT) 
表二：各 speaker diarization 系統在 RT03
上的 Diarization Error Rate (DER) (in %)，
各系統並沒有做 post processing 
Approach Data se t DER 
Dev 8.7 DACSeg1_AHC Eval 13.39 
Dev 8.46 DACSeg2_AHC Eval 13.69 
Dev 9.29 WinGrow_AHC Eval 14.12 
Dev 9.19 DISTBIC_AHC Eval 13.94 
Dev 11.52 FixSlid_AHC Eval 17.57 
 6
 
表三：各 speaker diarization 系統在 RT03
上的 DER (in %)，各系統皆用 Viterbi 
re-segmentation 做 post processing 
Approach Data se t DER 
Dev 8.35 DACSeg1_AHC Eval 13.16 
Dev 7.96 DACSeg2_AHC Eval 13.67 
Dev 8.65 WinGrow_AHC Eval 13.79 
Dev 9.1 DISTBIC_AHC Eval 13.06 
Dev 10.9 FixSlid_AHC Eval 14.91 
 
(3) Speaker Diarization 系統改良 
圖一所示的 speaker diariztation 基線系統中
的"Speaker segmentation"若用 WinGrow 來
實現，則我們稱此系統為 WinGrow_AHC；
我們用相同的方式建置了另外兩個基線系
統，即 DISTBIC_AHC 與 FixSlid_AHC。
同樣地，利用新提出的分段法，我們建置
了 DACSeg1_AHC 與 DACSeg2_AHC。表
二與三分別顯示各系統在 RT03 上"有"與"
沒有"用Viterbi re-segmentation做後處理的
實 驗 結 果 。 由 表 二 我 們 可 看 到 ，
DACSeg1_AHC 與 DACSeg2_AHC 的 DER
皆比其他三個基線系統小；說明了一個較
佳 的 音 訊 / 語 者 分 段 法 可 讓 speaker 
diarization 系統有較佳的 diarization 正確
率 。 由 表 三 我 們 可 看 到 ，  Viterbi 
re-segmentation 對有較高分段錯誤率系統
的 DER 有較明顯的改善，如 FixSlid_AHC 
(DER 由 17.57%降為 14.91%)。 
    在證實了一個較佳的音訊/語者分段法
可讓 speaker diarization 系統有較佳的
diarization 正確率之後，我們進一步對語者
分群技術做改良。在 speaker diariztation 基
線系統中的凝聚分群法 (agglomerative 
hierarchical clustering) 有 著 二 次 性
(quadratic)的時間複雜度，所以不適合用在
大量資料的處理。我們將凝聚分群法嵌入
於分割且克服(divide-and-conquer)的架構
中；由於分割且克服的演算法特性，此法
大大地增快了語者分群的速度，更適用於
大 量 資 料 的 處 理 。 此 成 果 發 表 在
Interspeech2009 國際會議[11]。我們提出的
DAC diariztion 架構如下: 
 
procedure ClsÅ DACDiar(W, DPset, GLRset)  
//input: W: the speech stream; 
DPset = {DP1,…, DPN}: the divide-points in W; 
GLRset = {GLR1,…,GLRN}: GLRi denotes the GLR 
value at DPi for i = 1, 2, …,N; 
//output: Cls: the set of output clusters 
1) //Check termination 
if (DPset is empty) 
ClsÅW; 
return; 
2) //Divide 
search in DPset and let DPk be the divide-point whose 
GLR value is the largest in GLRset; 
let t be the time index of DPk; 
divide W into two sub-streams, W1 and W2, at t; 
divide DPset into two sub-sets, DPset1 = {DP1,…,DPk}  
and DPset2 = {DPk+1,…,DPN}; 
divide GLRset into two sub-sets, GLRset1 = 
{GLR1,…,GLRk} and GLRset2 = {GLRk+1,…,GLRN; 
3) //Solve sub-instances 
ClW1Å DACDiar(W1,DPset1,GLRset1); 
ClW2Å DACDiar(W2,DPset2,GLRset2); 
4) //Combine 
Cls Å perform clustering on ClW1∪ClW2; 
 
如圖六所示，輸入的音訊串流經過分段與
SAD 的非語音濾除之後，我們將所輸出的
語音片段串接，兩鄰兩音段的邊界則為一
切點，其伴隨著一個對應於相鄰兩段距離
Approach WinGrow DISTBIC FixSlid DACSeg1 DACSeg2 
xRT 0.53 0.025 0.019 0.22 0.022 
Speedup over WinGrow 1 21.2 27.89 2.41 24.09 
EER (%) M: 17.19, 
F:16.59 
M:22.3 
F:21.08 
M:34.68
F:33.12 
M:16.44 
F:15.95 
M:18.47 
F:17.24 
 8
除了在語者分群演算法的改良之外，
我 們 亦 朝 另 一 方 向 來 改 良 speaker 
diarization 系統，也就是群與群之間的距離
量測準則。在我們的研究過程中，我們發
現目前常用在 speaker diarization 系統的語
音特徵，即 cepsptral 係數，常常同時包含
語者特徵與語音特徵；因此，我們希望能
發展出一套方法使得在做群與群之間距離
量測時，語音特徵的影響能減至最低。關
於此研究方向我們已有初步的成果發表在
Interspeech2010 國際會議 [12]。在此論文
中，我們提出一個語音子空間混合模型 
(phonetic subspace mixture model, PSM)，以
及基於此模型的∆BIC 距離量測準則；其在
做 speaker diarization 時可去除語音內容的
影響。在理論上我們亦證明，在子空間數
目為 1 的時候，我們提出的∆BIC 等價於傳
統的∆BIC；也就是說，後者是前者的一種
特殊實例。而我們在 RT02、RT03 與
MATBN 資料集上的實驗結果也驗證了我
們方法的有效性，如表五所示，與基線系
統比較，我們的方法確有較低的 diarization
錯誤率。 
 
(4) 中文廣播新聞語料標準測試集訂定 
目前用於 speaker diarization 評比的語料庫
大部分是由美國 NIST 發行的英文語料
庫。我們用實驗室過去所收集，委託中華
民國計算語言學學會所發行的 MATBN 中
文廣播新聞語料庫 [13] 中的發展集
(development set)與測試集(evaluation set)
建立了一套中文語料庫。我們分析 MATBN
的標記檔，以產生 speaker turn 的時間標
註，作為 speaker diarization 正確率計算之
用。MATBN 發展集與測試集中的音訊內
容資料統計如表六與表七所示。 
表八是我們在 MATBN 上的 speaker 
diarization 實驗結果。與基線系統相較，我
們的方法雖然有略低的正確率，但有較快
的速度。 
 
(5)語者辨識技術改良 
表四：DACDiar 與其對應的基線系統在 RT03 上的 DER (in%) 
Approach Data set DER Speedup of DAC over AHC 
Dev 16.77 9.13 DACDiar_BIC Eval 18.14 9.17 
Dev 20.68 - DACSeg2_AHC_BIC Eval 17.72 - 
Dev 10.00 1.56 DACDiar_BIC_SID Eval 11.94 2.37 
Dev 10.56 - DACSeg2_AHC Eval 12.61 - 
 
表五：PSM-based ∆BIC 的 DER (in%) 
Corpus NIST-RT02 NIST-RT03 MATBN 
Phonetic Subspace DEV EVAL DEV EVAL DEV EVAL 
15.43 1 PS (baseline) 10.33 17.67 10.76 18.25 20.03 
15.23 17.19 2 PS 9.86 15.61 10.03 19.45 
我們為 GMM-based 的語者識別 (speaker 
identification)提出一個貝氏方法。在計算一
個測試語句的語者分數時，我們所提出的
貝氏法以資料概似值對模型參數的事後機
率的期望值，也就是貝氏積分，作為語者
分數，而不是傳統上只用單一對於點估計
所得的模型參數的概似值。然而，此貝氏
積分並無法用分析的分法求得；因此，我
們用Laplace approximation來導出貝氏積分
值。在理論上，我們所提出的貝氏法在無
限多訓練語料的情況下等價於GMM-UBM
法。表九顯示GMM-UBM法與貝氏法在
TIMIT資料集上的辨識正確率。由表中可知
我們提出的貝氏法在少量訓練語料時比
3 PS 9.86 16.13 15.61 10.03 17.22 19.30 
10.01 4 PS 9.68 16.23 16.11 17.91 19.47 
9.40 5 PS 15.76 24.69 13.67 25.20 23.73 
6 PS 9.85 16.94 25.23 16.83 30.69 27.87 
 10
證所求出之語者特徵，其鑑別性完全集中
在有助於實驗效果的目標維度上，而捨棄
的維度則不含有任何的鑑別資訊，如圖八
所示。而由圖九和十的實驗結果看來，不
管是以線性還是二次分類器，幾乎在所有
維度上，fGLRDA相較於LDA和HLDA均有
十分傑出的表現。這個研究結果發表在
ICPR2010國際會議[15]。 
 
四、計畫成果自評 
 
我們已建置了目前最先進的系統做為我們
的基線系統。在音訊/語者分段技術方面，
我們提出兩個基於 BIC 的分割且克服
(divide-and-conquer)分段法，經實驗證實其
有高正確性及高效率性。我們已將此新分
段法整合至 Speaker Diarization 系統中，實
驗結果顯示其 Diarization 正確率優於基線
系統；我們並進一步將凝聚分群法(AHC)
嵌入於分割且克服的架構中，大幅增快了
語者分群的速度。另外，我們在語者辨識
及鑑別式特徵參數擷取方面也有不錯的成
果。 
在論文發表方面，本計畫已將音訊分
段技術發表 ICASSP2008 會議論文一篇
[9]，延伸的完整版本及將其應用至 Speaker 
Diarization 系 統 的 結 果 發 表 在 IEEE 
Transactions on Audio Speech and Language 
Processing 期刊[10]；Speaker Diarization 系
統改良部份，發表 Interspeech2009 及
Interspeech2010 會議論文各一篇[11][12]；
語者辨識技術部份發表 Interspeech2010 和
ICPR2010 會議論文各一篇[14][15]；另外，
我們與計畫共同主持人合作開發的基於
minimum Rand index 的語者分群技術則發
表在 Computer Speech and Language 期刊
[16]。 
 
五、參考文獻 
 
[1]  C. Barras, X. Zhu, S. Meignier, and J.-L. 
Gauvain, “Multistage Speaker Diarization of 
Broadcast News,” IEEE Transactions on 
Audio, Speech and Language Processing, 
Special Issue on Rich Transcription, 2006. 
[2]  J. Pelecanos and S. Sridharan, “Feature 
warping for robust speaker verification,” in 
Proc. A Speaker Odyssey - The Speaker 
The geometric 
criterion 
nn×ℜ∈Θ
Discriminatory 
subspace 
Rejected 
subspace 
The GLR 
criterion 
Discriminatory 
subspace 
nn×ℜ∈Θ
Rejected 
subspace 
(a) (b)
圖八：(a) LDA (b) fGLRDA 對於三維空間的投影示意圖 
 
  
圖九:以線性鑑別函數為分類器，在各種方
法上的分類錯誤率 
圖十:以二次鑑別函數為分類器，在各種方
法上的分類錯誤率 
國科會補助專題研究計畫項下出席國際學術會議心得報告 
                                                        日期：99 年 7 月 30 日 
計畫編號 NSC 96-2628-E-001 -024 -MY3 
計畫名稱 音訊內容之語者自動分段標記 
出國人員
姓名 王新民 
服務機構
及職稱 
中研院資訊所 
研究員 
會議時間 
99 年 7 月 20 日至 
99 年 7 月 22 日 會議地點 Singapore
會議名稱 
 (中文)  
 (英文) 2010 IEEE International Conference on Multimedia & Expo 
發表論文
題目 
Homogeneous Segmentation and Classifier Ensemble for Audio Tag 
Annotation and Retrieval 
一、參加會議經過 
 
此行於 7 月 19 日早上搭乘長榮航空班機，於中午時間抵達新加坡樟宜國際機場，出了
海關，便直接前往住宿旅館，將行李安置妥當後，先前往會場辦理報到手續，順便用餐
。此次會議的reception安排在正式議程的前一晚，所以今晚便參加了reception，會議主
辦單位本來貼心的安排全體與會者搭乘新加坡摩天輪，不巧前一日摩天輪因雷擊導致冷
氣系統故障，暫停營運，會議主辦單位因此改安排大家分批搭船遊新加坡河，對於此行
沒有多餘時間觀光的我而言，對這個安排特別感到窩心。 
 
ICME2010跟過去幾年的ICME會議比起來，最大的改變是論文接受率大幅降低至30%，
而且明訂將最好的15%論文錄取為oral presentation papers，次好的15%論文則為poster 
presentation papers。因此，ICME2010雖收到約630篇論文投稿，經過嚴格的雙盲審查，
只錄取約180篇論文，安排在18個口頭報告論文議程和9個壁報報告論文議程。另外，此
次會議還有8個特別議程、3個專題演講、2個panels、3個demo議程、會前6個tutorials、
及會後有7個workshops。 
 
此次會議的3個專題演講都很有趣，第一位講員是微軟亞洲研究院的院長洪小文博士，
演講內容是有關多媒體、多模式人機互動和跨領域創新研究的未來發展；第二位講員是
日內瓦大學的Nadia Magnenat-Thalmann教授，她跟大家分享其研究團隊在人與虛擬人物
及機器人互動的研究經驗，並分析未來的發展趨勢；第三位講員是HP的Susie Wee博士，
演講內容則是使用者經驗、設備、服務及雲端計算的產業發展與展望。 
 
這次會議還有一個創舉就是讓獲得最佳論文獎的兩篇論文分別緊接著第二、三場專題演
講的後面發表，讓所有與會人員都可以參與，個人比較喜歡第一篇論文，其研究議題是
探討如何將撕碎的相片還原，作者的演講非常生動有趣。 
 
我們的論文獲接受為口頭報告論文，被安排在 20 日下午 14:30-15:50 時段的"Audio and 
Music Processing"議程，本人也與中國科學院的 Changsheng Xu 博士共同擔任該場議程
的主席。 
無研發成果推廣資料 
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
