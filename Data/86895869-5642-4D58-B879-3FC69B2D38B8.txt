可供推廣之研發成果資料表 
V 可申請專利  V 可技術移轉                                     日期：99 年 10 月 4 日 
國科會補助計
畫 
計畫名稱：智慧型家庭中監測整合 
計畫主持人：郭景明         
計畫編號：NSC 96－2221－E－011－172－MY3 
學門領域：智慧型控制 
技術/創作名
稱 
智慧型家庭中監測整合 
發明人/創作
人 
郭景明 
技術說明 
中文：指紋辨識系統利用指紋特徵不變性廣泛地應用在刑事與法
醫鑑定上，然而在進行交叉比對時所面臨的挑戰為龐大的資料
庫，這過程會耗費大量的時間進行交叉比對。將指紋適當分類為
一個有效提升交叉比對效率之方法，因此分類正確率也會影像到
整體指紋辨識系統的效率。在先前的研究中所遇到的問題主要有
兩個，其中一個是指紋影像品質；另一個則是指紋影像類型模
糊，造成一枚在人工前分類上無法給定一個確立的類型。因此在
本年度的研究中，我們針對指紋特徵進行分析，建立一個完整的
指紋分類模型，解決前述指紋類型模糊之問題，並且提出以指紋
奇異點與方向場當作主要特徵的分類方法，主要使用我們提出的
中心點到三角點連線流向偵測(CDF)與平衡臂流向偵測(BAF)兩種
方法進行分類。在實驗結果的部分，我們所提出的方法與以往研
究之比較，在分類正確率(CCR)有相當的提升。 
 
關鍵詞: 指紋、指紋辨識、指紋奇異點、決策樹、指紋分析 
 
英文：Automatic bioinformatics-based recognition system is reliable for 
criminal identification and forensic for its invariance. Yet, the huge database 
is the key issue to make the system obtuse, and which is also a problem for 
fingerprint recognition system. Former works pre-classify the fingerprints 
before it is further processed, yet the classified accuracy is still an issue. In 
this study, a complete fingerprint model is proposed to solve this problem. 
Moreover, two methods, namely Center-to-Delta Flow (CDF) and Balance 
Arm Flow (BAF), are utilized for extracting more effective features for this 
application. As documented in the experimental results, the proposed 
method can outperform the former scheme in the literature in terms of the 
Correct Classification Rate (CCR). 
 
Keywords Fingerprint; fingerprint identification; fingerprint 
singularities; decision tree classifier; fingerprint analysis; 
 
附件二 
時間進行交叉比對。將指紋適當分類為一個有效
提升交叉比對效率之方法，因此分類正確率也會
影像到整體指紋辨識系統的效率。在先前的研究
中所遇到的問題主要有兩個，其中一個是指紋影
像品質；另一個則是指紋影像類型模糊，造成一
枚在人工前分類上無法給定一個確立的類型。因
此在本年度的研究中，我們針對指紋特徵進行分
析，建立一個完整的指紋分類模型，解決前述指
紋類型模糊之問題，並且提出以指紋奇異點與方
向場當作主要特徵的分類方法，主要使用我們提
出的中心點到三角點連線流向偵測(CDF)與平衡
臂流向偵測 (BAF)兩種方法進行分類。在實驗結
果的部分，我們所提出的方法與以往研究之比
較，在分類正確率(CCR)有相當的提升。 
關鍵詞 : 指紋、指紋辨識、指紋奇異點、決策
樹、指紋分析 
 
ABSTRACT 
Automatic bioinformatics-based recognition system is 
reliable for criminal identification and forensic for its 
invariance. Yet, the huge database is the key issue to 
make the system obtuse, and which is also a problem for 
fingerprint recognition system. Former works pre-
classify the fingerprints before it is further processed, yet 
the classified accuracy is still an issue. In this study, a 
complete fingerprint model is proposed to solve this 
problem. Moreover, two methods, namely Center-to-
Delta Flow (CDF) and Balance Arm Flow (BAF), are 
utilized for extracting more effective features for this 
application. As documented in the experimental results, 
the proposed method can outperform the former scheme 
in the literature in terms of the Correct Classification 
Rate (CCR). 
Keywords Fingerprint; fingerprint identification; 
fingerprint singularities; decision tree classifier; 
fingerprint analysis; 
 
1. INTRODUCTION 
Fingerprint is widely used in individual identification, 
largely due to the bio-invariant characteristic of human 
fingerprints. In fingerprint identification systems, 
particular details are employed to categorize fingerprints 
into different classes. Former fingerprint verification 
methods normally demand users to input their personal 
information through various means, such as name or ID 
card. With this approach, the system directly verifies the 
correspondence between the captured fingerprint and 
the user’s personal information. However, this kind of 
system is inefficient as the users have to operate the 
system, for example key in their name or directly insert 
an ID card, which is not solely to capture the fingerprint. 
To overcome this problem, there is an alternative 
approach [1] that does not require a user’s interaction, 
yet this method needs cross reference of fingerprints in 
the database [1] with extensive processing complexity. 
Currently, fingerprint cross-reference is still a time-
consuming process. In some related works [2]-[3], a 
common strategy to deal with this problem was to pre-
classify the tested fingerprints in the database into 
different categories, and the verification mechanism only 
cross-references the captured fingerprint within specific 
categories. This strategy effectively reduces the number 
of stored fingerprints that required matching process.  
 
    
Arch (A) Whorl (W) Left loop (L) Right loop (R) 
Fig. 1. Four different classes of fingerprints (4C). 
 
     
Arch (A) Tented arch (T) Whorl (W) Left loop (L) Right loop (R) 
Fig. 2. Five different classes of fingerprints (5C). 
 
In previous researches, several systems were 
proposed to classify fingerprints into different classes. 
For example, in [4] the fingerprints are separated into 
four classes (4C): Arch (A), Whorl (W), Left loop (L), 
Right loop (R), as illustrated in Fig. 1. The original Arch 
class can be further divided into Arch (A) and Tented 
arch (T) classes, resulting in a five-class separating 
system (5C) as used in [5]. Figs. 2(a)-(e) illustrate these 
five classes. In practice, fingerprints can still be 
separated further into more classes [6], but dividing into 
too many classes can raise other issues, such as 
ambiguous classes that cannot be accurately classified 
even by experts [1], [7]. Figure 3 shows some examples 
of fingerprints that are difficult classified. Thus, the 4C 
system is adopted in this study as a standard system for 
classification. 
 
   
Tented arch 
(T) 
Left loop (L) Whorl (W) 
Fig. 3. Some fingerprints which are difficult  to classify [4]. 
In the literature, several features extraction 
techniques can be adopted in fingerprint classification, 
e.g. Orientation Field (OF), Singular Point (SP), Ridge 
Flow (RF), Gabor Filer (GF). Based on these features, 
higher than 240, this image is classified as with white 
background, and vice versa. This decision is 
schematically described in the pre-processing stage, as 
shown in Fig. 6. When the original fingerprint is 
estimated as with white background, the corresponding 
Preprocessing 1 block includes grad (will be detailed 
later), and orientation field with average filter range of 6; 
in another background condition, since the test images 
are frequently suffered from noise and thus exhibit poor 
quality, it would need more enhancements. The 
corresponding Preprocessing 2 block includes histogram 
equalization, grad, orientation field, segmentation, Gabor 
filtering and orientation field again with average filter 
range of 12. The details of these procedures will be 
explained in the following sub-sections. 
 
 
Fingerprint background 
estimation
Preprocessing 2
Gray background
Preprocessing 1
Singular point 
extraction
Bottom center point
Top center point
NoYes
Delta point
Yes
Delta point No
AMethod of 
CDF
Method of 
BAF
NoYes
W
Error
Yes
Flow rule
L
No
Flow rule
White Background
A R
End
Original fingerprint 
image
LA R
 Preprocessing 
Feature extraction 
Decision tree
 
 
Fig. 6. Overall procedure of the proposed classification. 
 
 
 
      
      
(a) (b) (c) (d) (e) (f) 
Fig. 7. Results of preprocessing, in which the first  and second rows are the 
examples of gray and white backgrounds, respectively. (a) Original images. 
(b) Histogram equalization. (c) Grad image. (d) Segment image. (e) 
Orientation image. (e) Enhance image. 
 
2.1.1 Histogram equalization 
The contrast of a fingerprint image fluctuates each time 
when it is captured. Thus, histogram equalization is 
applied to yield a stable grayscale distribution. The 
corresponding transformation function is 
 image
x
i
A
jiHEH
jiHE

 0
)),((
255),( , (1)
 
where )(H  denotes the histogram at a specific grayscale 
and imageA  denotes image area. Figure 7(b) shows the 
corresponding enhanced result.  
 
2.1.2 Grad field 
Grad field associates to the energy distribution of an 
image, and which supports a mask to assist the 
segmentation between both foreground (denotes 
fingerprint) and background. 
 ),(),( yxImage
x
yxGx


 , (2) 
 ),(),( yxImage
y
yxGy


 , (3) 
 
 





2
2
22
2
2
2
),(),(
1
),(
W
i
W
iu
yx
W
j
W
jv
vuGvuG
W
jiGrad
. (4) 
In practice, Sobel operator is employed to derive 
),( yxGx  and ),( yxGy . The variable W denotes the 
average filter range. Figure 7(c) shows the 
corresponding grad result.  
 
2.1.3 Segmentation 
The segmentation process separates )(HE  image into 
foreground and background two region by the above 
),( jiGrad  information using variance thresholding [21]. 
This method divides an image into non-overlapped 
blocks, and performing the processing as below,  
 





1
0
1
0
),(
1 M
m
N
n
nmHE
NM
Mean , (5) 
 







1
0
1
0
2)),((
1 M
m
N
n
MeannmGrad
NM
Var , (6) 
 






VarnmGrad
VarnmGradnmHE
nmImageSegment
),( if        ,255
 ),( if ,),(
),( , (7) 
where MxN denotes the block size. Figure 7(d) shows 
the corresponding segmented result )(SegmentImage . 
Notably, this procedure is performed when the 
fingerprint is with gray background.  
 
2.1.4 Orientation field 
 








(i,j)D
(i,j)D
delta
center
- if point, delta
- if point,Center 
Point type , (22) 
where )(angle  denotes the difference between two 
angles in orientation field with different positions; kr  and 
kR  denote the inside and outside radii as shown in Fig. 
11, in which the notation x in the center denotes the 
currently processing position; variable   denotes the 
single-side error toleration, and which is empirically set 
at 25 in this work. Herein, two different Poincaré 
indexes are calculated using Eqs. (18) and (19), which 
represent the total angle differences of internal and 
external radii, respectively. In general, an ideal center or 
delta singular point has the calculated ),(internal jiP  or 
),(external jiP  close to 180  or 180  because of the ridge 
structure around it. Based on this characteristic, we 
applied a decision rule with toleration   to locate the 
center or delta point, as in Eq. (22). In practice, the 
number of candidate points can be more than one. In 
this case, the singular point of each possibility is the mass 
center of the candidate points. 
 
  
(a) (b) 
Fig. 10. Example of (a) Center point 180 , and (b) Delta point 180- . 
 
R0
&
R1
"
R2
"
R3
"
R4
(
R15#
r0
&
r1
"
r2
(
$R5
R14# r7# x $r3 $R6
R13#
%
r6
!
r5
'
r4
$R7
%
R12
!
R11
!
R10
!
R9
'
R8
 
Fig. 11. Operational range matrix. 
 
3. FINGERPRINT CLASSIFICATION 
In this section, different types of fingerprints are further 
investigated. From this analysis, a series of rules are 
introduced to assess and define different fingerprint 
classes. As shown in Fig. 12, FVC database fingerprint 
images are of different quality levels. One critical case is 
the Incomplete fingerprint, in which the fingerprint 
structure is not entirely obtainable in the image. 
Fingerprint samples in this group are obviously with low 
quality and which can lose some singular point 
information. Thus, the proposed method is discussed in 
terms of the two quality conditions of a fingerprint, 
perfect and imperfect. At the end of this section, an 
overall feature analysis and summary is specified. We 
will also show how to apply this feature analysis scheme 
to classify fingerprint with different methods. Two 
methods are used to classify a fingerprint when it cannot 
be classified by singular point type and number. 
 
   
   
Good poor Incompleteness 
Fig. 12. Examples fingerprint images of different  quality. 
 
3.1 Balance line 
3.1.1 Center-to-Delta Flow (CDF) 
This method is used to locate a balance line when both 
of the top center point and the delta point can be found.  
Symmetric Flow: A balance line connects the 
center point and delta point, and the obtained line is 
always perpendicular to the orientation field. Moving 
along this balance line, if the ridge structure on two sides 
of the balance line is reflexive symmetry (the symmetry 
between an object and its image by a plane mirror), then 
which is called flow symmetry in this work. The 
corresponding example is illustrated in Fig. 13.  
 
  
 
(a) (b) (c) 
Fig. 13. Example of flow symmetry (tented arch). (a) Obtained singular 
points. (b) Flow window. (c) Enlarged image of Fig. 12(b). 
 
Asymmetric Flow: The center point is connected 
with delta point to obtain the balance line, then examine 
the ridge pattern on both sides of the balance line. 
Instead of having symmetric pattern as above, Figure 14 
shows the asymmetric patterns. Fig. 14(b) shows a 
quasi-symmetric ridge flow, the pattern looks symmetric 
but in fact, it does not perfectly match into the 
orientation field, it is just an oppositely arranged pattern. 
The fingerprints belong to this group have asymmetric 
flow characteristic. 
 
Tented arch (T): Here we discuss the case in 
which a part of T fingerprint is missing. This kind of 
imperfect condition can be seen in Fig. 18(a), where a 
delta point that should be included is not available. For 
this case, since a delta point is missing, the decision basis 
is lost. As a result, a new decision basis from fingerprint 
image is required. For this, the BAF method is 
employed to obtain the balance line in the tented arch 
class. According to the experimental results, the 
orientation flows of the both sides of balance line are 
symmetrical. The procedure is shown in Fig. 19. 
Whorl (W): The whorl class includes a bottom 
center point, yet it does not include a top center point in 
imperfect condition, which is shown in Fig. 18(c)-(d). 
Moreover, this type of fingerprints can be classified by 
its unique singular point information, which means that 
the bottom center point is even in an imperfect condition.  
Left and Right loop (L and R): In fact, the delta 
point does not appear on the fingerprint in some 
situations as the examples shown in Fig. 18(e) and (f). In 
addition, this condition also occurs on the tented arch 
case. To deal with this problem, the BAF method is 
employed to obtain a balance line for calculating the 
obviously direction of balance line. This is an effective 
feature of fingerprint for separating left, right, and tented 
arch classes.  
Incompletion condition: An incomplete fingerprint 
image may include a delta point and other features are all 
missing. Thus, in this situation, the fingerprint image is 
categorized into incompletion condition, as shown in Fig. 
18(b). The fingerprint can be classified by locating the 
delta point position. If the delta point locates on the right 
hand side of the center point then the class of fingerprint 
is determined as “right loop”; otherwise the delta point is 
located on the left hand side of the center point, and the 
class of fingerprint is determined as “left loop”; if the 
delta point is located at the central region such as center 
point then the class of fingerprint image is determined as 
“arch class”. 
   
(a) (b) (c) 
   
(d) (e) (f) 
Fig. 18. Imperfect fingerprints: (a) Tented arch. (b) Incomplete 
fingerprint image. (c) Whorl with delta image. (d) Whorl without delta 
image. (e) Left loop image. (f) Right loop image. 
   
(a) (b) (c) 
Fig. 19. Example of BAF (tented arch). (a) original image. (b) Balance 
line. (c) Orientation flow around the balance line. 
 
3.3 The description of singular point quadrantal 
diagram 
The relationships between different singular points are 
analyzed in sub-section 3.2.1 and 3.2.2. Table I 
organizes the relationships between singular points. 
Moreover, a three-dimension diagram with eight 
quadrants divided by three axes of singular points is also 
utilized to illustrate these relationships, as shown in Fig. 
20. The positive axis of this figure denotes the belonged 
classes have the corresponding singular point, and vice 
versa. In this figure, the W, I, A, and U classes denote 
the fingerprint classes of the Whorl, Incompletion, Arch, 
and Undecided, respectively. The class U comprises 
three classes, tented arch, left loop, and right loop. A 
common feature of these classes is that each one has 
one center and delta point, thus this feature can confuse 
the classifier. For further classification between these 
classes, the distance between the extracted center and 
delta point can provide another powerful feature as 
shown in Fig. 21. The corresponding distances are 
defined below:  
 
deltacenter xxx  , (23) 
 
deltacenter yyy  . (24) 
 
 
Fig. 20. Singular points quadrantal diagram, in which the Whorl, Arch, 
Incompletion, and Undecided are denoted by ○W , ○A , ○I , ○U , 
respectively. 
 
 
method and Singular point any images 
 
5. CONCLUSIONS 
Fingerprint classification system is an effective manner 
for further improving the correct recognition rate and 
reducing the cross-reference time between a user’s 
fingerprint and the data stored in database. However, 
the low quality of a captured fingerprint image and 
ambiguous fingerprint classification schemes are issues 
that decrease the recognition performance. In this study, 
a 4-class clear classification rule is established based on 
the FVC database. Moreover, both of the conditions of 
perfect and imperfect fingerprints are considered. 
Consequently, the decision tree comprising query, CDF, 
and BAF methods is established for constructing the 
proposed fingerprint classification system. As 
documented in the experimental results, the classification 
performance of the proposed method can yield an 
excellent accuracy rate at 91.7%, and which is 
significantly superior to the former scheme in the 
literature.  
 
REFERENCES  
[1] D. Maltoni, D. Maio, A. K. Jain, and S. Parbnhankar, Handbook of 
Fingerprint  Recognition Second Edition, Springer, 2009. 
[2] N. K. Ratha, S. Chen, K. Karu, and A. Jain, “A real-time matching 
system for large fingerprint  databases,” IEEE Trans. Pattern Anal. 
Mach. Intell., 18(8), pp. 799-813, 1999. 
[3] X. Tan, B. Bhanu, and Y. Lin, “Fingerprint identification: 
classification vs. indexing,” Proc. IEEE Conf. Advanced Video and 
Signal Based Surveillance (AVSS’ 03), pp. 151-156, 2003. 
[4] E. R. Henry, “Classification and Use of Fingerprint ,” Routledge, 
London, 1900. 
[5] C. I. Watson and C. L. Wilson, NIST special database 4, U.S. 
National Institute of Standards and Technology, 1992.  
[6] R. Cappelli, A. Lumini, Dario Maio, and D. Maltoni, “Fingerprint 
Classification by Directional Image Partitioning,” IEEE Trans. 
pattern analysis and machine intelligence, vol. 21, no. 5, May 1999. 
[7] X. Tan and B. Bhanu, “Fingerprint Classification Based on Learned 
Features,” IEEE Trans. systems, man, and cybernetics—part c: 
applications and reviews, vol. 35, no. 3, August 2005. 
[8] M. Kawagoe and A. Tojo, “Fingerprint pattern classification,” 
Pattern Recognition, vol. 17, pp. 295-303, 1984. 
[9] K. Karu and A. K. Jain, “Fingerprint classification,” Pattern 
Recognition, vol. 29, no. 3, pp. 389-404, 1996.  
[10] Q. Zhanga and HongYan, “Fingerprint classification based on 
extraction and analysis of singularities and pseudo ridges,” Pattern 
Recognition, vol. 37, pp. 2233-2243, 2004. 
[11] L. Wang and M. Dai, “Application of a new type of singular points 
in fingerprint classification,” Pattern Recognition Letters, vol. 28, 
pp. 1640-1650, 2007. 
[12] J. H. Chang and  K. C. Fan, “A new model for fingerprint 
classification by ridge distribution sequences,” Pattern Recognition, 
vol. 35, no. 6, pp. 1209-1223, 2002. 
[13] C. H. Park and H. Park, “Fingerprint classification using fast Fourier 
transform and nonlinear discriminant analysis,” Pattern Recognition, 
vol. 38, no. 4, pp. 495-503, 2005. 
[14] J. K. Min, J. H. Hong, and S. B. Cho, “Effective Fingerprint  
Classification by Localized Models of Support Vector Machines,” 
Lecture Notes in Computer Science 3832 LNCS, pp. 287-293 2006. 
[15] J. Lia, W. Y. Yau, and H. Wanga “Combining singular points and 
orientation image information for fingerprint  Classification,” 
Pattern Recognition, vol. 41 no. 1, pp. 353-366, 2008 
[16] H. W. Jung and J. H. Lee, “Fingerprint Classification Using the 
Stochastic Approach of Ridge Direction Information,” FUZZ - 
IEEE 2009, Korea August 20-24 2009. 
[17] S. Bernard, N. Boujemaa, D. Vitale, and C. Brioct, “Fingerprint 
Classification Using Kohonen Topologic Map,” in Proc. Int. Conf. 
Image Processing, 2001. 
[18] A. W. Senior and R. Boll, “Fingerprint classification by decision 
fusion,” in Automatic Fingerprint Recognition Systems, Springer, 
New York, pp. 27-53, 2004.  
[19] T. Kristensen, J. Borthen, and K. Fyllingsnes, “Comparison of 
neural network based fingerprint classification techniques,” 
Proceedings of International Joint Conf. Neural Networks, Orlando, 
Florida, USA, August 12-17, 2007. 
[20] J. C. Amengual, A. Juan, J. C. Prez, F. Prat, S. Sez, and J. M. Vilar, 
“Real time minutiae extraction in fingerprint images,” Proc. 6th 
International Conf. image processing and its application, pp. 871-
875, 1997. 
[21] B.M. Mehtre, “Fingerprint Image Analysis for automatic 
identification,” Machine Vision and its Applications 6, 124-139, 
1993. 
[22] H. Lin, W. Yifei, and J. Anil, “Fingerprint Image Enhancement: 
Algorithm and Performance Evaluation,” IEEE Trans. pattern 
analysis and machine intelligence, vol. 20, no. 8, August 1998 
[23] D. Maio, D. Maltoni, R. Cappelli, J. L. Wayman, and A. K. Jain, 
FVC2000: Fingerprint Verification Competition. Biolab internal 
report, University of Bologna, Italy, September 2000. Available 
from http://bias.csr.unibo.it/fvc2000/ 
[24] D. Maio, D. Maltoni, R. Cappelli, J. L. Wayman, and A.K. Jain, 
FVC2002: Fingerprint Verification Competition. Biolab internal 
report, University of Bologna, Italy, April 2002. Available from 
http://bias.csr.unibo.it/fvc2002/ 
[25] H. Choi, K. Choi, and J. Kim, “Mosaicing Touchless and Mirror-
Reflected Fingerprint Images,” IEEE Trans. information forensics 
and security, vol. 5, no. 1, March 2010. 
 
 
國科會補助計畫衍生研發成果推廣資料表
日期:2010/10/12
國科會補助計畫
計畫名稱: 子計畫六：智慧型家庭中監測整合
計畫主持人: 郭景明
計畫編號: 96-2221-E-011-172-MY3 學門領域: 智慧型控制 
研發成果名稱
(中文) 子計畫六：智慧型家庭中監測整合
(英文)
成果歸屬機構
國立臺灣科技大學 發明人
(創作人)
郭景明
技術說明
(中文) 在本年度的研究中，我們提出結合區塊與像素基礎的階層式演算法，並且利用
Codebook模型來建立背景模型，其利用Codebook模型好處是能夠有效的壓縮資訊
進而達到較佳的處理速度。在這裡區塊基礎稱為粗糙層(coarse level)，像素基
礎稱為精細層(fine level)。在本論文中的粗糙層是選擇非重疊類型，另外在粗
糙層的特徵值是利用12個維度來描述一個區塊，其取得方式的概念是來自於區塊
截斷編碼(Block Truncation Coding；BTC)，由於BTC的低複雜度能夠擁有較佳的
處理速度。粗糙層的好處是可以快速的移除大部分的背景，且不會因此降低True 
Positive (TP) rate，但不幸的是非重疊的粗糙層之精確度較差。為了克服這種
情況，使用精細層來加強其精確度，並且也可以降低False Positive (FP) 
rate。除此之外，為了能更適應目前的環境，採用短期資訊來改善背景模型的更
新。
(英文) This project presents a hierarchical scheme with block-based and pixel-based codebooks 
for foreground detection. The codebook is mainly used to compress information to 
achieve high efficient processing speed. In the block-based stage, 12 intensity values are 
employed to represent a block. The algorithm extends the concept of the Block 
Truncation Coding (BTC), and thus it can further improve the processing efficiency by 
enjoying its low complexity advantage. In detail, the block-based stage can remove most 
of the noises without reducing the True Positive (TP) rate, yet it has low precision. To 
overcome this problem, the pixel-based stage is adopted to enhance the precision, which 
also can reduce the False Positive (FP) rate. Moreover, the short term information is 
employed to improve background updating for adaptive environments. As documented in 
the experimental results, the proposed algorithm can provide superior performance to that 
of the former related approaches.
產業別 研究發展服務業；其他專業、科學及技術服務業
技術/產品應用範圍
本技術可推廣應用於即時監控系統、門禁管理系統、侵入檢測系統，其後續可搭配行為
分析演算法，於不同場合設定不同之警報姿勢，例如商店，針對疑似偷竊的動作發出警
報，提醒店員注意監視畫面，又如安養中心，針對疑似老人跌倒之行為發出警報，提醒
看護人員注意是否有意外發生，以免延誤送醫。
技術移轉可行性及
預期效益
由於社會與環境安全的需求，帶動了監控產業的興起，而監控產業發展至今，最需要積
極推動的就是監控系統的自動辨識，自動辨識監控系統的第一步就是發展物件追蹤的技
術，以此技術銜接後續行為分析之處理，可因應各場合之需求，依不同情況發出警報，
因此技術移轉可行性非常高。
註：本項研發成果若尚未申請專利，請勿揭露可申請專利之主要內容。
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
本年度本人辦理國際影像處理暨電腦視覺論壇，共有 4位分別來自美國、韓國、
泰國講員及 240 位學員參加。 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
