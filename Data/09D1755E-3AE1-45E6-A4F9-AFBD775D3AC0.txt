where a training set with known class labels is used to 
first organize a neural network, and then apply the 
network in a recall mode for classification of the feature 
patterns. It defined near-optimal decision borders 
between the classes, even in the sense of classical 
Bayesian decision theory [5]. In Fig. 2, the network 
architecture contains an input layer, a single hidden 
layer of neurons and an output layer. Training is 
performed in two successive steps: the hidden layer 
parameters are estimated using an unsupervised 
approach, and afterwards, the output layer weights are 
updated in a supervised manner using the hidden layer 
parameters evaluated in the previous step [9]. In our 
implementation, we collect grass, soil and other pixels 
from different playfields as training data firstly. Input 
vectors were two-dimensional [U,V] values of pixels, 
this accounts for the greater sensitivity of the human 
visual system to changes in luminance than changes in 
chromatic components [8]. The number of units in the 
hidden layer depends on the overlap among the 
population of [U,V] distributions for grass, soil and 
other in various playfields. In this work, 12 hidden units 
have been incorporated. Then, each input vector is 
connected to the neurons in the hidden layer and the 
winner is determined by using Eq. (1) and (2). 
1
1
1
1
21
1
S
W p
W p
n
W p
⎡ ⎤−⎢ ⎥⎢ ⎥−⎢ ⎥= − ⎢ ⎥⎢ ⎥−⎢ ⎥⎣ ⎦
#
, 
 
 
(1) 
 
1 1( )a compet n= , (2)
where 1S is the number of neurons in hidden layer, and 
1n  represents a vector in  1 1S × dimension, which is 
obtained by calculating the distance (Euclidean distance) 
of the training vector p to the weight vector  1iW of 
each neuron. 1a  is a transfer function with the same 
dimension as  1n  and the nearest neuron is declared as 
the winner, it will transfer the corresponding winner 
neuron to 1, others to 0. The labeled result of Eq. (2) 
will propagate to linear layer. 
In the supervised part (liner layer) of the learning 
procedure, the weight vector 2W of the output layer, 
which group the clusters found by the hidden layer into 
classes by using Eq. (3). 
2 2 2 1a n W a= = , (3)
where 2S in Fig. 2 is the number of neurons in output 
layer, and 2a  is the expected class of the training vector. 
If the actual and training network outputs are 
coincidence, the winning neuron is reinforced (pull) 
toward the training vector; otherwise, the connected 
weight of the neuron is moved away (push) from the 
training vector. The update mechanism for these 
weights is described by the following expression. 
( ) ( ) ( )( )1 1 11i s i s winner sW t W t a p W tα+ = + − , (4)
where ( )1i sW t represents thi  neuron’s weighting at 
time st , α  is learning rate (0,1]∈  and a = 1± (pull or 
push). After the learning stage, the network implements 
the input-output mapping rule and can generalize it to 
input vectors not being part of the training set [9]. 
In summary, a LVQ network with three (soil, 
grass and other) outputs was built. For each frame of 
input video sequence, RGB color space is transferred to 
YUV for separating luminance and chromatic 
components. According to our extensive experiments, 
12 neurons ( 2 for grass, 3 for soil and 7 for other) in 
competitive layer and 3 neurons in linear layer 
respectively. The soil (red), grass (green) and other 
(blue) are 3 primary components for field map in this 
work. In Fig. 3, we may observe that a great diversity of 
[U,V] distributions caused by different field structures 
and broadcasting devices. However, experimental 
results show that the proposed soil-grass separation 
using LVQ approach can segment playfields in various 
baseball video types accurately.  
 
3. Filed map 
 
After the training procedure, the LVQ neural 
network was able to classify pixels as soil, grass and 
other (player, clothing colors, caption and audience) 
classes, the next step is to transfer the pixels of a frame 
into these 3 primary color components, it is called “field 
map” in this report. The technique proposed in the 
report has the following advantages: 
1. Each transferred pixel possesses class concept rather 
than low-level feature, besides, the “field map” 
approach can lower the playfield variations caused by 
the change of illumination and different broadcasting 
devices. 2. The “field map” can also preserve spatial 
feature to characterize the distribution of baseball field 
layout. 
In Fig. 4, we only demonstrate the transferred 
“field maps” of pitch scene for different baseball 
playfields to avoid lengthy descriptions, and the 
observation can claim that the approach can solve the 
problem of field variations effectively.  
  
4. Experiment Results 
 
To demonstrate the performance of our proposed 
method, three baseball videos, Chinese Professional 
Baseball (CPB), Major League Baseball (MLB, USA), 
and Nippon Professional Baseball (NPB, Japan) 
including pitch, infield, outfield, close-up and audience 
scene types are conducted. 
Firstly, we manually collect various pixels from 
baseball videos for LVQ neural network training, 1000 
pixels for each class, i.e. 3000 training samples are used 
for 3-classs (soil, grass and other) classifier. To verify 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Table 1. Evaluation results of inside test for different number of neurons. 
 
 
 
 
 
 
 
 
 
Fig. 6. The field map feature of 
pitch scene for MLB and NPB 
baseball playfields. 
Fig. 7. The field map feature of 
infield scene for MLB and 
NPB baseball playfields.
Fig. 8. The field map feature of 
outfield scene for MLB and 
NPB  baseball playfields.
 
Fig. 9. The field map feature of 
close-up scene for MLB and 
NPB baseball playfields. 
Fig. 10. The field map feature of 
audience scene for MLB and 
NPB baseball playfields. 
Number of neurons 9 10 11 12 13 
Accuracy 92.6% 92.7% 92.9% 93.4% 93.3% 
Fig. 4. The transferred field maps of same 
scene (pitch) for different baseball fields 
(CPB, MLB, NPB). 
Fig. 5. The misclassification results of skin 
and soil colors in classifier. 
 - 2 - 
一、參加會議經過 
2008 IEEE 亞太設計自動化研討會是由國際電機電子工程師學會(IEEE)、哈
爾濱工業大學(HIT)、國立高雄應用科技大學(KUAS)、中華民國人工智慧學會等
單位所聯合主辦的，今年的會議地點是中國黑龍江省哈爾濱市的友誼宮裡面，會
議為期三天 (Aug. 15-17, 2008)。本次會議共有 650 篇論文來自世界各個國家投稿
並選擇 346 篇論文發表，此研討會的論文將可以在 EI 國際重要的工程論文資料
庫系統中索引到。 
會議行程如下： 
08 月 15 日 (第一天): 
第一天為大會的 Keynote Speech(I)邀請到了 Mobile and Media System Lab, 
HP 的 Professor Ton Kaller(IEEE Fellow)，他在 watermarking 方面有相當深地研
究。講題為；The state of Reversible Watermarking，其內容主要是介紹 watermarking
在 multimedia content 上的 protection 技術，並提及四種常用的 reversible 
watermarking 種類，還有提到一種新觀念─semantic coding，並介紹它如何應用在
reversible watermarking。接著，在論文發表方面有幾個 session─A05 Techniques and 
Algorithms for Multimedia Security(i) 、 A10 Techniques and Algorithms for 
Multimedia Security (ii)、A13 Video Signal Processing 是我比較感興趣的。 
08 月 16 日 (第二天): 
第二天為大會的 Keynote Speech(II)邀請到了在美國華盛頓大學電機系任教
的 Professor Ming-Ting Sun (IEEE Fellow)，他在 Multimodality Signal Fusion 方面
有相當深地研究。講題為；Multimodality Signal Fusion and Application，其內容主
要是介紹 Multimodality Applications by fusing information from multimodal signal
上技術，並討論所面臨的問題及未來挑戰。本人發表的論文安排在本日，Session 
B09 發表。在這篇論文中我們利用以距離為基礎的截斷平均濾波器以及卡曼濾波
器對視訊的向下轉換編碼之運動向重新估測提出了一個精確且快速的方法,此論
文提出以距離為基礎的截斷平均濾波器有效去除差異性大的運動向量，提昇重估
測的運動向量精確度，再藉由卡曼濾波器精煉其已重估測之運動向量，使重估測
的運動向量更為精確,實驗結果顯示，我們所提出的方法比傳統的方法得到較好的
輸出表現,對將來視訊向下轉換編碼的研究有很大的助益。 
08 月 17 日 (第三天): 
第三天為大會的Keynote Speech(III)邀請到了在National Laboratory of Pattern 
Recognition 服務的 Professor Tie-Niu Tan (IEEE Fellow)。講題為；Human 
Identification Based on Iris Image Analysis，其內容主要是介紹一些 Iris 
Recognition 基本原理及其藝術，並討論 complete iris recognition system, detection, 
iris image quality assessment, iris image synthesis 等。 
 
