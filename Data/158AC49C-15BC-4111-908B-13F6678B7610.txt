2 Related Works
Currently, most digital watermarking methods deal with 1D or 2D contents
such as audio, 2D images, and video, etc. By contrast, methods for 3D
contents are relatively few. We only introduce the part of works related to
our method in this section. For a more comprehensive survey, please refer to
the survey papers [10,16]. Previous literatures suggested several classification
criteria to the digital watermarking methods:
• Blindness: a method is called a blind watermarking method if the
extraction of the embedded message needs no additional information
other than the cover medium itself; otherwise, the method is called a
non-blind watermarking method.
• Robustness: a method is claim to be a robust watermarking method
if it is able to extract the embedded message successfully from a series
intentional/unintentional attacks; opposed to this, if the extraction of
the embedded message is very sensitive to the determent of the cover
medium, then this method is called a fragile watermarking method.
• Space of Embedment: similar to previous watermarking methods for
2D images, according to the space of the embedment, the watermark-
ing methods for 3D meshes may be classified into spatial domain or
transform-domain techniques.
Spatial domain techniques embed the watermark to the spatial informa-
tion such as the vertex coordinates, vertex normals, and the topology (vertex
connectivity) of the cover object. A number of previous works of such kind
are illustrated as follows.
Ohbuchi et al. made use of the geometric structure of the cover object in
combination with TSQ (Triangle Similarity Quadrature) and TVR(Tetrahedral
Volume Ratio embedding) techniques to embed watermark to the vertex co-
ordinates [18]. Benedens etl al. suggested embedding the watermark by mod-
ification of surface normal and its distribution [4, 5]. Wagner et al. suggest
embedding the watermark in the curvature normal of the target object [24].
Zafeiriou et. al. proposed another method by embedding the watermark
data to the r-coordinate of a set of vertices within a certain range of angles
in pseudo-random order [25]. The method is robust against both geometric
transforms and mesh simplifications. However, It require an alignment pro-
cess to translate and rotate the disguised mesh to its initial pose. Cotting
proposed directly applies watermark embedding to the point clouds without
the need to derive consistent connectivity information [9]. On the basis of
2
The new method provides progressive watermark authentication of progres-
sively transmitted 3D objects and is robust enough to extract visually dis-
tinguishable watermark after common/malicious attacks such as the coor-
dinate transform, cropping, or simplification. Furthermore, the extracted
watermark appears progressively as the cover object has been progressively
transmitted.
3 THE PROGRESSIVEWATERMARKING
ON PROGRESSIVE MESH
In our previous system, we have adopted the approach suggested by Wagner
et. al. to embed the watermark into the local curvature normals of the ver-
tices [24]; however, it requires original content as a reference for watermark
extraction. In this paper, we propose an alternative approach to progressive
watermarking on progressive 3D meshes. Similar to the previous system, the
new watermark authentication system as shown in Fig. 1 contains four mod-
ules: the preprocessing, embedding, extraction, and authentication modules.
Figure 1: A possible framework of our new progressive mesh watermarking
method.
We have assumed that the cover object is a polygonal mesh M(V,E,F)
consisting of a set of vertices V = {vj|vj = (xj, yj, zj) ∈ R3} in a 3D Carte-
sian space, a set of edges E = {(vi, vj)|vi, vj ∈ V}, and a set of triangular
faces F = {(vi, vj, vk)|vi, vj, vk ∈ V}. According to topology convention [13],
4
a base part and a series of refinement records sequenced from lower to higher
frequencies.
3.3 Progressive Mesh Encoder
For a 3D polygonal mesh, we adopt the progressive mesh (PM) suggested by
Hoppe et al. [13]; hence, the cover object, a polygonal mesh M0, is converted
to a base mesh Mn and a series of refinement operations, the vertex splits
S = {sn−1, sn−2, ..., s0}, after n edge collapses applied to M0. The conversion
and restoration to and from the original mesh are illustrated by the flow
diagram shown in Fig. 2.
Figure 2: The conversion and restoration of a progressive mesh.
We have devised our simplification algorithm on the basis of a fast edge
collapse-based simplification algorithm [6], which performs the simplification
by selecting the lowest cost edge collapse among the star of a vertex. To
simplify the encoding and decoding process, the overall greedy selection is
not applied. In order to guarantee a consistent output, the simplifications
are performed under the following restrictions:
• Consistent manifold property: each edge collapse performed must guar-
antee a manifold output. Hence, if two rings R(vi) and R(vj) are
6
Note that A and D are the sum and difference filters of two neighboring
pixels, respectively. With Wn×n we may derive a lower resolution image and
three sets of refinement coefficients as follows.
WIWT =
[
AIAT AIGT
GIAT GIGT
]
=
[
B V
H D
]
3.5 The Watermark Embedding
We assume that the DWT-transformed watermark image I2k×2k are serialized
by a function M : I× I → I, k = M(i, j), k = 0→ |S|, and i, j = 0→ 2k−1
such that the watermark wi,j ∈ W are embedded to the split operation sk
and an inverse function M−1 : I → I × I exists that help us establish the
correspondence between the vertices of the input mesh and the pixels of the
watermark image. The transformed image is then sequenced in this manner
and embedded into the vertex split stream of the progressive mesh S from
low to high frequencies.
Unlike Wagner’s approach, we do not directly embed the watermark code
to the vertex in the original mesh. Instead, the watermark code is embedded
into the relative scale l of the new vertex resulted from a full-edge collapse.
Hence, if a full-edge collapse is performed on an edge eij = (vi, vj), which
essentially merges the two vertex ring neighborhoods ddviee and ddvjee such
that the vertex ring ddvkee of the new vertex vk equals ddviee ∪ ddviee.
We first calculate the normal vector ni of vertex vi for each vertex in V
as follows.
ni =
∑
∀vj∈R(vi) vj
|R(vi)| − vi (1)
By summing up the normal vectors ni of all the vis in V , we can find the
average normal n¯ by
n¯ =
∑
∀vi∈V ni
|V | (2)
Then, for each new vertex vk introduced by an edge collapse, we compute
the relative scale lk of the normal nk with respect to n¯ by letting where c is
a heuristic constant.
lk = c× |nk||n¯| (3)
Let lk =< lkp−1 , lkp−2 , · · · , lk0 >, the watermark code c =< cq−1, cq−2, · · · , c0 >,
and p > q. The embedment is as follows.
8
we may evaluate the extracted watermark quality through the NC value. To
provide a modest assessment for the verification of the extracted watermark,
a common way is to calculate the noise ratio compared with the original
watermark (peak to noise ratios, PSNR). In general, the noise ratio is defined
as
PSNR = 10− log10
2552
MSE
dB, (9)
MSE =
1
m2
× 1∑m
i=1
∑m
j=1 (αij − βij)2
(10)
Where, MSE stands for the the mean square error of two m×m gray-scale
digital images, αij and βij respectively represents the pixel of the original wa-
termark images and the pixel of the extracted watermark located on position
(i, j). Note that, larger PSNR value means greater similarity.
4 Experimental results
In the experiments, a test image shown in 4, the Logo of National Chin-Yi
University of Technology, is used as the watermark and three 3D models, the
Dragon, the Rabbit, and the Happy Buddha meshes downloaded from the
Standford Repository of Stanford University are applied as the cover objects.
Each models are individually encoded to the progressive mesh format and
embedded with the DWT-transformed watermark. A summary of the tests
are listed in
Mesh Name |V0| |Vn| |S| |W |
Dragon 5205 2500 2705 32*32
Rabbit 67038 2500 64538 128*128
Happy 543652 2500 541152 512*512
Table 1: A summary of the tests
Since the model will recovered to its original form after the received pro-
gressive mesh is completely decoded, no distortion will be introduced by
the watermark embedment. In addition, the watermark image used in the
experiments is rescaled to a 2k × 2k grey-level image in proportion to the
size of progressive stream |S| with k =
⌊
log2
√
S
⌋
. In this paper, we sim-
ply applies a straightforward mapping funtcion k = M(i, j) to establish the
10
Transfered |V | Dragon Rabbit Happy
2500
27560
3524
6596
68036
543652
Figure 5: The extracted watermark during the transmission of the cover
meshes.
12
[8] Paolo Cignoni, Claudio Rocchini, and Roberto Scopigno. Metro: mea-
suring error on simplified surfaces. Technical report, Paris, France,
France, 1996.
[9] Daniel Cotting, Tim Weyrich, Mark Pauly, and Markus Gross. Robust
watermarking of point-sampled geometry. In SMI ’04: Proceedings of
the Shape Modeling International 2004, pages 233–242, Washington, DC,
USA, 2004. IEEE Computer Society.
[10] Ingemar Cox, Matthew L. Miller, and Jeffery A. Bloom. Digital water-
marking. Morgan Kaufmann Publishers Inc., San Francisco, CA, USA,
2002.
[11] Ying He, Boon-Seng Chew, Dayong Wang, Chu-Hong Hoi, and Lap-
Pui Chau. Streaming 3d meshes using spectral geometry images. In
MM ’09: Proceedings of the seventeen ACM international conference on
Multimedia, pages 431–440, New York, NY, USA, 2009. ACM.
[12] Keiichiro Hoashi, Toshiaki Uemukai, Kazunori Matsumoto, and Ya-
suhiro Takishima. Constructing a landmark identification system for
geo-tagged photographs based on web data analysis. In ICME’09: Pro-
ceedings of the 2009 IEEE international conference on Multimedia and
Expo, pages 606–609, Piscataway, NJ, USA, 2009. IEEE Press.
[13] Hugues Hoppe. Progressive meshes. In SIGGRAPH ’96: Proceedings of
the 23rd annual conference on Computer graphics and interactive tech-
niques, pages 99–108, New York, NY, USA, 1996. ACM.
[14] Chiou-Ting Hsu and Ja-Ling Wu. Hidden digital watermarks in images.
IEEE Transactions on Image Processing, 8(1):58–68, 1999.
[15] Satoshi KANAI, Hiroaki DATE, Takeshi KISHINAMI, and Satoshi
Kanai Hiroaki Date. Digital watermarking for 3d polygons using mul-
tiresolution wavelet decomposition. In Proc. Sixth IFIP WG 5.2 GEO-6,
pages 296–307, 1998.
[16] Stefan Katzenbeisser and Fabien A. Petitcolas, editors. Information
Hiding Techniques for Steganography and Digital Watermarking. Artech
House, Inc., Norwood, MA, USA, 2000.
[17] Marc Levoy, Kari Pulli, Brian Curless, Szymon Rusinkiewicz, David
Koller, Lucas Pereira, Matt Ginzton, Sean Anderson, James Davis,
Jeremy Ginsberg, Jonathan Shade, and Duane Fulk. The digital
michelangelo project: 3d scanning of large statues. In SIGGRAPH ’00:
14
出席國際會議心得報告 
本人於 2010 年 3 月 24 日至 26 日參加於中國上海舉辦之 IEEE International 
Symposium on Broadband Multimedia Systems and Broadcasting (BMSB)，並有幸於
該學術研討會中口頭發表一篇全文論文。該研討會今年來自各個國家共有近 200 
個學者與會。本次會議包含 Poster 共有 17 個議程。此次的論文發表於 3/24 下午
3:20~5:00 於 WPM-2C 室舉行的 Content Protecting and Adaptation 議程中。議程
的主持人是來自加拿大Communications Research Centre的Dr. Demin Wan與上海
交大的宋利教授。議程中口頭發表的論文則是本計畫的一個先期成果：
"Progressive Watermarking on 3D Meshes"。發表的過程相當順利，聆聽的人數將
近四十人左右。問題的提問也相當的踴躍，可見本論文相當受到關注。議程完畢，
並與來自知名手機處理晶片 Qualcomm 公司與德州儀器的代表討論並交換意
見，並與議程主持宋教授一同共進晚餐。 
幾日的議程中，我發現目前中國大陸在高清電視廣播及相關領域之研究相當
積極。幾個通訊晶片大廠甚至派代表至會場積極尋求研究夥伴，並以合作方式提
出專利申請，可見該領域之競爭與專利的攻防相當激烈。此處，希望我政府能重
視此一領域的研究與產業技術的開發，以免我相關產業將來面對國際競爭時又因
專利技術之缺乏淪為弱勢族群。最後，非常感謝國科會能補助本人出席經費參加
此會議，本人頗覺受益良多。 
 
報告者：陳宏光 
國立勤益科技大學電子工程學系 
98年度專題研究計畫研究成果彙整表 
計畫主持人：陳宏光 計畫編號：98-2221-E-167-015- 
計畫名稱：三維網格之漸進式數位浮水印認證技術研究 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 0 0 100%  
研究報告/技術報告 1 1 100%  
研討會論文 1 1 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 4 2 200%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
 
