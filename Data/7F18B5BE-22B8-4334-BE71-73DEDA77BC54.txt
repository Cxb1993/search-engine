 2
行政院國家科學委員會專題研究計畫成果報告 
 
計畫編號：NSC 98-2221-E-011-118 
執行期限：98 年 8 月 1 日至 99 年 7 月 31 日 
主持人：楊英魁   國立台灣科技大學 電機工程研究所 
 
 
一、中文摘要 
 
在實際應用系統的取樣資料中，由於
各種因素影響，常常使得取樣資料中存有
一般雜訊(noise)或大誤差(outlier)的資
料。若將這些雜訊或大誤差資料直接使用
在系統行為函數的建模上，往往使得所建
立的系統模式與實際的系統行為產生很大
的誤差，這種現象稱為「過度適應」
(overfitting)。 
為了解決這個問題，本研究提出一個
非監督模糊建模方式，可直接由具有雜訊
及大誤差的輸入-輸出取樣資料中擷取模
糊規則，以建立系統行為的近似函數。所
提方法主要有兩個特色：(1) 提出一個強健
式 fuzzy c-means(RFCM)演算法，以降低雜
訊及大誤差的影響。(2)提出一個模糊資料
篩選器(FDS)，可尋找資料轉折特徵點，藉
以將一個非線性系統分割成片段的子系統
組合。因此，可以建立起一個較少規則及
較少誤差的 Takagi and Sugeno 模糊模式。 
 
 
關鍵詞：模糊群聚，函數趨近，強健式，
模糊建模，雜訊，大誤差 
 
Abstract 
 
Due to influence of various factors, 
the sampling data used for system 
modeling often include various kinds of 
noise and outliers. If such sampling data 
is directly being used to model a system, 
there will be a big difference, named 
overfitting, on the system behavior 
between the resultant modeled system 
and the actual system.  
To overcome this problem, this 
proposal presents an unsupervised fuzzy 
model construction approach to 
extracting fuzzy rules directly from 
numerical input–output sampling data 
mixed up noise and outliers for nonlinear 
systems. There are two core ideas in the 
proposed method: (1) The robust fuzzy 
c-means (RFCM) algorithm is proposed 
to greatly mitigate the influence of data 
noises and outliers; and (2) A 
fuzzy-based data sifter (FDS) is 
proposed to locate good turning-points to 
partition a given nonlinear data domain 
into piecewise clusters so that a Takagi 
and Sugeno fuzzy model can be 
constructed with fewer rules and less 
errors. 
 
Keywords: fuzzy clustering ， function 
approximation，robust，fuzzy modeling， 
noise ， outlier, fuzzy clustering, pattern 
classification, data distribution, feature 
weight 
 4
analysis)的技巧，在不需要指定大誤差的
的資料點下，將資料的雜訊及大誤差的的
資料點降低其影響程度，並可以不需事先
指定歸屬函數及規則的個數前提下，即能
將資料依照其分佈(distribution)的特徵
自動分成不同的群聚，並以此群聚為基
礎，為系統的行為模式建立近似函數，並
將降低雜訊及大誤差的影響後的資料點，
作為所建立模式的訓練樣本，以調整系統
行為的近似函數參數，如此可使得所建立
的系統模式更符合系統的行為函數。 
 
  
三、研究結果與討論 
   
 本研究的主要目的在於提出一個
強健式(robust)的演算法，將取樣資料點
的雜訊及大誤差的影響減到最低，以得到
一組足以代表系統行為的資料點，再以這
些資料點作為模糊建模過程中所需的取樣
資料，以建立系統行為的近似函數。 
在過去的二、三十年來，模糊建模被
成功的應用在複雜系統的建模上。模糊系
統依照知識庫的結構可分為語言式的模糊
模式(linguistic fuzzy models)、模糊關
係 模 式 (fuzzy relational models) 及
Takagi-Sugeno 模糊模式(TS model)三
種。其中 TS 模糊模式將系統的輸入空間分
割成多個子空間(subspace)，這些子空間
被視為一個描述線性或非線性系統的群
聚。當取樣資料點的雜訊及大誤差的影響
減到最低後，如何有效的建立一個好又正
確的系統模式成為主要的課題。對此，本
研究的目的是提出一個新的建構TS模糊模
式方法以解決具有雜訊及大誤差的非線性
系統函數近似問題。為了使用 TS 模糊模式
建立系統的行為模式，將分析所獲得代表
系統行為模式的群聚中心，以產生群聚中
心的轉折點(turning point)。所謂轉折
點，代表系統行為模式的區域最大點或區
域最小點。在 TS 模糊模式中，每一條規則
的後件部代表系統行為模式的輸出可以用
系統輸入變數的線性組合加以描述，而轉
折點代表系統行為模式輸出的區域最大點
或區域最小點。因此，利用轉折點作為系
統的切割依據，即可將系統切割成線性子
群聚的組合，每一個群聚以一條 TS 模糊模
規則來表達。為計算系統行為模式群聚中
心的轉折點，本研究使用一個具有模糊型
樣比對滑動窗(slip window)的模糊資料篩
選器(fuzzy–based data sifter)計算群
聚中心符合峰值(peak value)及谷值
(valley value)特徵的符合程度(match 
degree)，將符合程度值較高的群聚中心點
作為系統建模時切割的依據，這些符合程
度值較高的取樣點稱之為轉折點。一個群
聚 中 心 點 若 是 具 有 峰 值 特 徵 點
(characteristic)，代表此點為系統群聚
中心點中的區域最大點(local maximum)，
相反地，一個群聚中心點若是具有谷值特
徵點，代表此點為系統群聚中心點中的區
域最小點(local minimum)。所以峰值及谷
值特徵的轉折點代表系統取樣資料分佈趨
 6
特徵愈高，該點即可當作系統的切割
點，當系統切割時，依群聚中心點的
歸屬值，由大到小依序取出作為切割
的依據。這些轉折點將系統分割成線
性子群聚的組合，因此，每一個子群
聚的輸入-輸出關係可用一個線性方
程式表達，亦即，一個子群聚可以用
一條TS模糊模式規則來描述。 
當系統切割完後，即使用線性迴歸方
法來計算每一個子群聚的輸入-輸出的線
性迴歸參數，再以此參數建立系統的 TS 模
糊模式。由於是使用由 RFCM 所得的群聚中
心作為訓練資料，所產生的參數受到雜訊
及大誤差資料點的影響已被排除或很小。
本研究將RFCM所得的群聚中心作為訓練資
料，以梯度下降法來細調 TS 模糊模式的參
數，以獲得更近似系統行為函數的參數。 
 
 
四、未來應用方向 
 
1. 在本計畫的研究中，提出一個強健式
模糊群聚演算法，對於文字外型分析
時，可以找出足以代表文字字型的骨
架。因此，未來可延續這個成果，用
在字型辨識及圖形識別的研究上。 
2. 將本計畫的理論繼續發揚光大，以適
用在資料探勘(data mining)、知識管
理(knowledge management)、控制等
領域上。 
五、重要參考文獻 
 
 
[1] George J. Klir and Bo Yuan, Fuzzy Sets 
and Fuzzy Logic ： Theory and 
Applications, Prentice Hall Inc.,New 
Jersey, 1995. 
[2] V. Boskovitz, H. Guterman, “An adaptive 
neuro-fuzzy system for automatic image 
segmentation and edge detection, ” 
IEEE Trans. On Fuzzy Systems, vol. 10, 
pp. 247 -262 , Apr. 2002. 
[3] N. Li, Y.F. Li, “Feature encoding for 
unsupervised segmentation of color 
images ” IEEE Trans. On Systems, Man, 
and Cybernetics, Part B, vol. 33, no.  3, 
pp. 438 –447, Jun. 2003.  
[4] S. Eschrich, Ke Jingwei, L.O. Hall, and 
D.B. Goldgof, “Fast accurate fuzzy 
clustering through data reduction” IEEE 
Trans. On Fuzzy Systems, vol. 11, no. 2 , 
pp. 262 –270, Apr. 2003.  
[5] C. Stutz, T.A. Runkler, “Classification 
and prediction of road traffic using 
application-specific fuzzy clustering” 
IEEE Trans. On Fuzzy Systems, vol. 10, 
no. 3 , pp. 297 –308, Jun. 2002.  
[6] N.R.Pal, J.C.Bezdek, “On cluster validity 
for the fuzzy c-means model,” IEEE 
Trans. On Fuzzy Systems vol. 3, no. 3, pp. 
370-379, Aug. 1995. 
[7] A.M. Bensaid, L.O. Hall, J.C. Bezdek, L. 
P. Clarke, et al. “ Validity-guided 
(re)clustering with applications to image 
segmentation, ” IEEE Trans. On Fuzzy 
Systems, vol. 4, no. 2, pp. 112-123, May 
1996. 
[8] C.C.Lee, “Fuzzy logic in Control 
Systems : Fuzzy logic controller, part 
I&II,” IEEE Trans. on Systems, Man, 
and Cybernetics, vol.20, no.2,  
pp.404-435, Mar./Apr. 1990. 
[9] M. Sugeno, “An introductory survey of 
 8
clustering neural networks,” IEEE 98 on 
Fuzzy Systems Proceeding, 
pp.1088-1093,1998. 
[26] H.M. Lee, C.M. Chen, J.M. Chen, and 
Y.L. Jou “An efficient fuzzy classifier 
with feature selection based on fuzzy 
entropy ” IEEE Trans. on Systems, Man, 
and Cybernetics, Part B, vol. 31, no. 3, 
pp. 426-432, Jun. 2001. 
[27] W. Pedrycz, “Fuzzy sets in pattern 
recognition: Methodology and 
methods,” Pattern Recognition, vol. 23, 
no. 1/2, pp. 121-146, 1990. 
[28] L. I. Kuncheva, Fuzzy Classifier Design, 
Physica-Verlag,New York, 2000. 
[29] E.H. Ruspini ,“A new approach to 
fuzzy clustering ,” Information and 
Control. vol. 15, pp.22-32,1969 . 
[30] J. C. Dunn, “A fuzzy relative of the 
ISODATA process and its use in 
detecting compact well separated 
clusters,” J. 
Cybern.,vol.3,no.3,pp.32-57,1974. 
[31] J. C. Bezdek, Pattern Recognition with 
Fuzzy Objective Function Algorithms, 
Plenum Press, New York,1981. 
[32] M.P. Windham, “Cluster validity for the 
fuzzy c-means clustering algorithm,” 
IEEE Trans. on Pattern Analysis and 
Machine Intelligence, PAMI-4 ,no.4, 
pp.357-363, July 1982. 
[33] J.-S.R.Jiang , C.-T.Sun, and E.Mizutani, 
Neuro-Fuzzy and Soft Computing 
Prentice-Hall Inc. , pp.18-19,1997. 
[34] Seymour Lipschutze, Theory and 
Problems of Probability, McGraw-Hill, 
Inc., New York, 1968. 
[35] R. A. Fisher, “The use of multiple 
measurements in taxonomic problem,” 
Annals of Eugenics, vol. 7, no. 2, pp. 
179-188, 1936. 
[36] G. Castellano and A.M. Fanelli, “A 
staged approach for generation and 
compression of fuzzy classification 
rules,” The Ninth IEEE International 
Conference on Fuzzy Systems, vol. 1, 
pp.42-47, May 2000. 
[37] K. Nozaki, H. Ishibuchi, and H. Tanaka, 
“Adaptive fuzzy rule-based classification 
systems,” IEEE Trans. on Fuzzy Systems, 
4(3):238–250, Aug. 1996. 
[38] D. Nauck and R. Kruse, “Nefclass - a 
neuro-fuzzy approach for the 
classification of data,” in Proceedings of 
the 1995 ACM Symposium on Applied 
Computing, pp. 461-465, Nashville, Feb 
1995
 1
參加 ICAI2010研討會心得報告 
報告人： 楊英魁  2010.07.13 
時間： 2010年 7月 12日 ~ 2010年 7月 15日 
地點： Las Vegas, USA 
報告內容： 
這次在 Las Vegas, USA為期四天所舉行的研討會 The 2010 International Conference on 
Artificial Intelligence (ICAI2010)，是學術界在人工智慧與控制領域上重要的一次會議。ICAI2010
是WORLDCOMP10 (The 2010 World Congress in Computer Science, Computer Engineering, 
and Applied Computing)中 25個研討會之一。由於它的重要性，所以有另外九個與人工智慧領
域有關的研討會一起舉行。總共有來自全球不同領域的超過兩千五百個專家學者參與，氣氛熱
絡，連當地旅館都不容易定到，每位 Keynote Speaker都是在人工智慧領域裡大師級的人物。 
參加這次 ICAI2010，主要是去發表一篇由國科會所支持研究的成果論文：A Novel Approach 
of Enhancing CMAC Learning Mechanism。發表此論文時，大約有 90幾位專家學者參與討論，
氣氛對非常熱絡，對此論文所提出的方法與理論，與會者都極為肯定。 
這幾天期間，與各地學者專家深入討論各個不同的領域，受益良多，也能正確的掌握目前
人工智慧的領域，尤其是每天第一場的 keynote speech更是精采。主講者不但學術豐富，有幽
默感，而且明確指出今後在此領域上可以進行的幾個方向，足以當作最好的參考。 
參加此研討會，不但有機會與來自世界各地的學者專家廣泛討論，相互切磋，也因此更確
定目前所進行的研究方向是正確的。而且同時可以參加六個相關研討會，真是不虛此行
 3
input state after a learning iteration. An appropriate grey learning rate is then derived by incorporating 
the calculated grey relational coefficient with the number of learning iterations. Then the credit 
distributed to an addressed hyper cube is in inverse proportion to the number of trainings.  
 
2. CMAC Architecture 
The basic structure of a conventional CMAC model [1] is shown in Figure 1. A CMAC model 
quantizes the learning space into several discrete states that serve as input states of the CMAC model 
and are represented as set S in Figure 1. Each input state is mapped from indexed memory A to the 
corresponding real memory cells W that store the input states information and are summed to produce 
actual output value. A mapping block is a hyper cube between axes. The total hyper cubes are real 
memory cells that store relational information regarding addressed input states.  
1S
kS
S A
W
∑
l e a r n i n g
s p a c e
m e m o r y
i n d i c e s
m e m o r y
c e l l s
y
a c t u a l
o u t p u t
∑
yˆ t a r g e to u t p u t
+
−e r r o r
  
Figure1. Basic structure of a CMAC model 
If there are Nh hyper cubes in which each input state maps to Ne hyper cubes, then the actual 
output is shown in following Equation (1). The ys denotes the actual system output for input state s, 
T
sa  is the indexed vector, and w is the memory cell vector.  
 
                                                                   (1) 
 
 
 
 
During the learning phase, the error of actual output value to the desired output value is uniformly 
distributed to regulate and train the memory cells of a CMAC model. The weight relation between 
before and after trainings of a memory cell is shown in Equation (2). 
( 1)
( ) ( 1)
,
( )T ii i ss
j j s j
yw w a
N e
α
∧ −
− −= + ⋅ ⋅ a w                 (2) 
In Equation (2), s denotes an input state, ( )ijw  represents the weight of j-th hyper cube in the training 
iteration of number i, ,s ja  is an index vector for input state s and hyper cube of number j, 
( 1)( )T issy
∧ −− a w  denotes the learning error, α represents learning rate, and each input state corresponds to 
Ne hyper cubes.  
1
2
,1 ,2 , ,
1
[ , , , ]
h
h
h
N
T
s s s s N s s j j
j
N
w
w
y a a a a w
w
=
⎡ ⎤⎢ ⎥⎢ ⎥= = =⎢ ⎥⎢ ⎥⎢ ⎥⎣ ⎦
∑a wL M
 5
max
maxmin
)(
))(ˆ),(( Δ⋅+Δ
Δ⋅+Δ= ξ
ξ
k
kykyGRC
y
                            (5) 
where )(ˆ)()( kykyky −=Δ  , )(maxmax kyk Δ=Δ , )(minmin kyk Δ=Δ  and 1))(ˆ),((1max
min
≤≤+
+Δ
Δ
kykyGRCξ
ξ . 
Because both maxΔ  and minΔ  are constant values for a CMAC model, the grey relational 
coefficient increases with decreasing output error )(kyΔ . 
During the learning phase, the output errors of input states should be also related to the inverse of 
the number of training iterations. Therefore, this paper proposes an adaptive regulation of learning rate, 
termed grey learning rate, that is based on the number of training iterations and grey relational 
coefficients of input states in a CMAC model. During the i-th training iteration, the grey learning rate 
at the input state ks  is proposed as follows.   
))(),((
)(
)1(
1)(_
kykyGRC
i
i
i
kgrey ∧−=α                            (6) 
where ))(),(()1( kykyGRC i
∧−  is the grey relational coefficient at state ks  in the (i-1)-th training 
iteration. Initially, 1))(),(()0( =∧ kykyGRC  and 1)(_ )1( =kgrey α . When the training iteration i becomes 
larger, it means the systems has been trained more times already. Similarly, when the grey relational 
coefficient GRC becomes large, it means the system is closing to the final state. In these two cases, 
Equation (6) shows that the learning rate should be a smaller value. That is, the system is tuned by 
smaller changes to avoid any overshooting or instability. 
 
3.3 Grey-area-time Credit Apportionment  
  A hyper cube that includes more input states is more influenced by the learning interference 
during the learning phase. To mitigate this effect, the distribution of errors among the addressed hyper 
cubes must be proportional to the hyper cube creditability. The key information available for use as 
credit is the number of times a hyper cube has been updated [8][9]. In addition, conceptually, the 
accuracy of the stored weights in hyper cubes should increases with the number of input states during a 
learning phase. For this, the trained proportion of input states is proposed to be considered as one 
factor of creditability. Further, as discussed previously, an adaptive learning rate is necessary to avoid 
an unstable system. This means the grey relational grade in a hyper cube should be also a factor 
involving creditability of the hyper cube. Consequently, the number of updated times for hyper cubes, 
the trained proportion of input states and grey relational grade in a hypercube can be integrated to 
provide an indicator of hyper cube creditability. The credibility, termed grey-area-time, is defined as 
shown below. 
∑
=
−
−
××+
××+=−− m
c
ii
ii
i
jGRGjact
jGRGjajtjtimeareagrey
1
1)()(
1)()(
)(
))(()()1)(((
))()()1)((()(             (7) 
where )( jt  denotes the accumulative learning times of the j-th hyper cube, and m represents the 
number of addressed hyper cubes for an input state ks . Notice that )(ct  must include the value 1 to 
 7
Grey-area-time CMAC has been stable and achieved convergence faster than other three methods. 
 
Learnig comparisons
0
0.01
0.02
0.03
0.04
0.05
0.06
0.07
1 2 3 4 5 6 7 8 9 10
training iteration
RM
SE
 er
ro
r Conventional CMAC
Time-credit CMAC
Fuzzy-time-credit CMAC
Grey-area-time CMAC
 
Figure 2: Learning comparison for different CMAC models 
 
Example 2:  
 The target function is 2 2( , ) ( ) sin 5z x y x y x= −  where -1< x < 1 and -1< y < 1. The 
distinguishing coefficient is set to 1.0=ξ . Learning comparison adopts root mean square error 
(RMSE). Figure 3 shows the performance for different CMAC models. It can be observed from Figure 
3 that the proposed Grey-area-time CMAC results in less RMSE than other three models since the first 
learning cycle. Furthermore, the RMSE monotonically decreases in the Grey-area-time CMAC until it 
stabilizes after 9 learning cycles. 
Learning comparisons
0
0.01
0.02
0.03
0.04
1 2 3 4 5 6 7 8 9 10
training iteration
RM
SE
 er
ro
r Conventional CMAC
Time-credit CMAC
Fuzzy-time-credit CMAC
Grey-area-time CMAC
 
Figure 3: Learning Comparisons for different CMAC models   
 
5. Conclusions 
 This paper presents an enhanced strategy for creating a novel learning framework for the CMAC 
model. The accumulated frequency of updating to the hyper cubes [2][6], the trained proportion of 
input states and grey relational grade of hyper cubes are integrated into a measure of the credibility of 
the hyper cubes for each input state. This paper also considers the adaptive regulation of learning rate 
with the number of training iterations and grey relational coefficients in the CMAC model. The credit 
apportionment is combined with the grey learning rate to improve system performance. The conducted 
experiments indicate that the proposed approach works well in terms of system stabilization, fast 
國科會補助計畫衍生研發成果推廣資料表
日期:2011/01/04
國科會補助計畫
計畫名稱: 一個強健式模糊群聚以及新式模糊建模方法的整合與加強之研究
計畫主持人: 楊英魁
計畫編號: 98-2221-E-011-118- 學門領域: 人工智慧
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
