tools to construct Go opening book in the system of a 
single computer, to study the basic concept and the 
implementation of volunteer computing, and to 
construct Go opening book by using simple volunteer 
computing system. In the second year, we construct 
9x9 Go opening book by using volunteer computing 
system. In the third year, we make the opening book 
better by combining group intelligence to correct it. 
In 1997, chess program, ＇Deep Blue＇, defeated the 
best player, and founded the milestone for Artificial 
Intelligence. In the field of computer Go, research 
organizations, in serious competition, all want to 
make some record in the history of computer game. 
Cooperating with MogoTW, it had the record of 
defeating the world Go champion in a nonofficial game 
in October of 2009. However, it still takes great 
effort to win in the official best of seven game. 
This project combined the volunteer computing system 
to speed up the pace of constructing Go opening book. 
Finally, our computer Go program defeat a Go pro in 
the official best of seven game, and create a new 
milestone for Artificial Intelligence. 
 
英文關鍵詞： Computer Games, Computer Go, Monte Carlo Tree Search, 
Go, Opening game, digital game 
 
 1 
 
計畫中文摘要 
 
目前電腦圍棋程式棋力已進步到足以在九路棋盤上與高段棋士爭一短長，但距離人類世界棋王
仍有一段距離，目前瓶頸在於開局部分。我們將利用蒙地卡羅樹狀搜尋演算法建構九路圍棋開局庫，
由於開局庫建構過程中需要大量的計算資源，因此我們結合其他子計畫所提供之志願型計算系統，
藉由聯合多台異構電腦之計算資源，以建構接近完美的開局庫。 
本子計畫預計三年完成。第一年主要工作是在單機系統上完成基本的圍棋開局庫之建構工具，
並研究志願型計算之基本概念與實作方式，於簡易型志願型計算系統上建構圍棋開局庫。第二年將
在志願型計算系統上建構九路圍棋開局庫。第三年將利用其它圍棋程式，納入群體智慧以修改開局
庫，使開局庫更臻完善。 
本計劃符合資訊學門人工智慧規劃重點研究方向中內容服務之數位遊戲方向。本計畫有以下貢
獻：蒙地卡羅上界信賴樹狀搜尋演算法對於對局類遊戲的發展，包括兵棋推演，都將會有革命性的
影響，我們投入此研究，將使得台灣在此方面不至落後。執行計畫的學生，將來畢業時，能夠將此
方法應用在產業界、金融界與國防工業。計畫進行時，也將開發出一些平行計算演算法，參數最佳
化演算法及機器學習理論，共有 20篇的相關論文發表。本計劃結合志願型計算系統有效率的加快開
局庫建構之腳步。在計畫結束前一個月，2013年六月，九路圍棋程式正式在七番賽中擊敗職業棋士，
創造人工智慧新的里程碑，完成計畫預定目標。 
 
關鍵詞：電腦對局、電腦圍棋、蒙地卡羅樹搜尋、數位遊戲、圍棋、開局庫 
 
 3 
 
目錄 
1 前言............................................................................................................................................................ 4 
2 研究目的.................................................................................................................................................... 4 
3 文獻探討.................................................................................................................................................... 5 
3.1 蒙地卡羅上界信賴樹狀搜尋演算法(MCTS) .............................................................................. 6 
3.1.1 上界信賴演算法........................................................................................................................ 6 
3.2 蒙地卡羅上界信賴樹狀搜尋演算法............................................................................................ 7 
3.3 蒙地卡羅上界信賴樹狀搜尋演算法在圍棋上的應用................................................................ 8 
3.4 利用蒙地卡羅上界信賴樹狀搜尋演算法建構圍棋開局資料庫.............................................. 10 
3.5 志願型計算與桌機格網計算...................................................................................................... 11 
3.5.1 志願型計算(Volunteer Computing) ........................................................................................ 11 
3.5.2 桌機格網計算(Desktop Grid) ................................................................................................. 11 
3.6 參考文獻...................................................................................................................................... 12 
4 研究方法.................................................................................................................................................. 15 
4.1 第一年：研究並實作於單機以及簡易型志願型系統上建構圍棋開局庫之方法.................. 15 
4.1.1 蒙地卡羅上界信賴樹狀搜尋演算法之研究.......................................................................... 15 
4.1.2 研究於共享記憶體架構下建構九路圍棋開局資料庫的方法.............................................. 15 
4.1.3 研究並實作於單機上建構圍棋開局庫.................................................................................. 15 
4.1.4 志願型計算基本概念之研究.................................................................................................. 15 
4.1.5 於簡易型志願型計算系統上建構圍棋開局庫之研究.......................................................... 16 
4.2 第二年：在志願型計算系統上建構九路圍棋開局庫.............................................................. 16 
4.2.1 研究志願型計算系統.............................................................................................................. 16 
4.2.2 研究於志願型計算系統上建構圍棋開局庫之方法.............................................................. 16 
4.2.3 與子計畫 V1作整合測試 ....................................................................................................... 16 
4.2.4 回饋問題與建議至子計畫 V1 ................................................................................................ 17 
4.2.5 隨子計畫 V1之修改，繼續完成整合測試 ........................................................................... 17 
4.3 第三年：研究與其他程式對戰並自我學習以改進九路圍棋開局庫...................................... 17 
4.3.1 研究透過對戰並自我學習以改良開局庫的方法.................................................................. 17 
4.3.2 與其他程式進行實際對戰以改進九路圍棋開局庫.............................................................. 18 
4.3.3 進行進階測試以增進開局庫的穩定性以及程式棋力.......................................................... 18 
5 結果與討論.............................................................................................................................................. 19 
5.1 本計畫完成工作項目概述.......................................................................................................... 19 
5.2 對於參與之工作人員，獲得之訓練.......................................................................................... 19 
5.3 本計畫貢獻.................................................................................................................................. 19 
5.4 本計畫發表之論文列表與索引.................................................................................................. 20 
 
 5 
 
 
3 文獻探討 
 
自從1950年由Shannon提出利用電腦來下西洋棋的概念以來，電腦對局(computer game)就成為人
工智慧領域中最吸引人的課題之一。1997年IBM在超級電腦上開發出來的”深藍”(Deepblue)戰勝了人
類西洋棋冠軍，可說是人工智慧的一個重要的里程碑 [34]。對於目前世界上廣為流傳且有悠久歷史，
為人類研究較多的七種代表性的棋盤遊戲的複雜度如表1。Chechers(西洋跳棋)、Othello(黑白棋)在電
腦上的發展，已到達超越人類思考的程度；Chess(西洋棋)、Chinese Chess(象棋) 、Shogi(日本將棋)
而言，電腦已到達世界冠軍的水準；至於19×19 Go (圍棋)的比賽中，本計畫主持人顏士淨業餘六段多
次在正式電腦對局比賽中擊敗Zen，圖1 是顏六段在2013年七月在印度海德拉巴2013 IEEE-FUZZ會場
擊敗Zen的棋譜，顯示目前電腦圍棋棋力仍然停留在業餘高段，仍有很大的進步空間。 
棋類名稱 Log(stat
e space) 
Log(game 
tree size) 
世界目前最強之程式與人類職業棋
士比較，括號中為目前最佳紀錄 
程式作者 
Checkers 17 32 Chinook > H (2007 Solved) Jonathan Schaeffer, 
(Alberta University) 
Othello 30 58 Logistello > H (1997, 6-0 Takeshi 
Murakami) 
Michael Buro 
(Othello strong player) 
9×9 Go 40 85 東華七號 >= H (2013/6, 七番賽 4-3
勝 黨希昀職業二段 ) 
周政緯、顏士淨 
(東華大學) 
Chess 50 123 DeepBlue >= H (1997/5, 3.5-2.5 Garry 
Kasparove棋王) 
許峰雄團隊 
(IBM) 
Chinese 
Chess 
48 150 Shiga >= H (2006/11, 紅先勝 陳振國
八段 1) 
鄭明政、顏士淨 
(東華大學) 
Shogi 71 226 GPS Shogi >= H (2013/4, won 
Hiroyuki Miura三浦浩幸八段) 
Tanaka Tetsuro et.al. 
GPS team (東京大學) 
19×19 Go 160 400 Zen < H (2012/11, 持黑被讓 4 子勝 
周俊勳九段) 
Yoji Ojima, Hideki 
Kato (東京大學) 
表 1. 七種代表性棋類複雜度與相關程式跟人類棋力之比較 
由表1中可以看出圍棋的複雜度很高，這是因為盤面比較大，如果使用暴力法搜尋，由於每層的
分支數過多，將無法搜尋很深。因此，一些全域搜尋的方式通常不適合用於圍棋這種複雜度太高的遊
戲。但是這種局面被近年來被提出的新演算法給打破了，使得圍棋也可以進行全域搜尋，並且大幅地
提升了圍棋程式的棋力。這個新的演算法，便是本計畫的主角--蒙地卡羅上界信賴樹狀搜尋演算法
(UCB for Tree Search, UCT) [110]。 
蒙地卡羅上界信賴樹狀搜尋演算法是一種全域搜尋的演算法，它以蒙地卡羅模擬演算法作為局面
評估的依據，又利用上界信賴演算法使得搜尋樹可以往較優秀的子點展開成為一棵不平衡樹，從而達
到裁剪的目的以增加搜尋深度，適用於解決高複雜度的問題。此方法運用於圍棋領域，已然取得極大
的成功，使用此演算法的圍棋程式囊括了2007年電腦奧林匹亞圍棋項目的前三名，並且對2006年的冠
軍取得了接近百分之百的勝率，可說是電腦圍棋史上的一個突破點。 
                                                 
1 八段為台灣最高段，相當於中國大陸職業棋士大師級水準。中國大陸象棋協會禁止大陸現役職業棋士與電腦比賽，因此我們無法跟九段比較。 
 7 
精神。所謂的吃角子老虎問題，簡述如下：目前有若干台吃角子老虎機，每台機器可以投入一定數
量的金額並拉動操縱桿，此時會得到收益(reward)，投錢、拉桿、得到收益的過程，稱之為一個 Play。
每台吃角子老虎機有不同的收益率，倘若玩家想要在這若干次的 Play裡獲得最大總收益，那麼玩家
該怎麼作? 
一般來說，玩家會開始動手玩，並且依照目前累積的經驗來決定下一次的 Play 要選擇哪一台機
器，這稱之為開發(exploitation)。相對地，如果玩家不斷地依照目前所獲得的經驗來決定，而不試圖
嘗試其他的機器，則可能會忽略收益率更高的機器，因此適度地嘗試其他機器是必須的，這稱之為
探索(exploration)。如何在開發與探索之間保持平衡，就是上界信賴演算法試圖解決的開發與探索
(Exploitation VS. Exploration, EXE)問題。 
上界信賴演算法根據目前獲得的資訊，配合上一個調整值，試圖在開發與探險間保持平衡。大
致上而言，每一次 Play時，上界信賴演算法會根據每一台機器目前的平均收益值(亦即其到目前為止
的表現)，加上一額外參數，得出本次 Play每台機器的上界信賴值，然後挑選出擁有最大上界信賴值
的機器，作為本次 Play 所要選擇的機器。其中，所謂「額外參數」，會隨每一台機器被選擇的次數
增加而相對減少，其目的在於讓此公式選擇機器時，不過份拘泥於舊有的表現，而可以適度地探索
其他機器。這個公式可以這樣表示： 
i
ii T
NXUCB ln2+=  
其中， ki ≤≤1 ，k為機器總數；UCBi代表第 i 台機器經由上界信賴公式運算後所得到的值，Xi
代表第 i 台機器到目前為止所獲得的平均收益，Ti表第 i 台機器的總 Play次數，N 代表到目前為止
全部機器加起來的總 Play 次數。此公式中，等號右邊的左項即為此台機器之「過去表現」，右項則
是「調整參數」。 
3.2 蒙地卡羅上界信賴樹狀搜尋演算法 
蒙地卡羅上界信賴樹狀搜尋演算法其實就是把上界信賴演算法的公式運用於樹狀搜尋上的一個
方法，並且在收益值評估部分採用蒙地卡羅演算法作為衡量的方式。概念上而言，蒙地卡羅上界信
賴樹狀搜尋演算法把每一個節點都當作是一個吃角子老虎問題，而此節點的每一個分支，都是一台
吃角子老虎的機器。選擇分支，就會獲得相對應的收益。搜尋開始時，蒙地卡羅上界信賴樹狀搜尋
演算法方法會建立一棵樹，然後： 
STEP 1. 選擇(Selection)：選擇一條從根節點到葉節點的最佳路徑。選擇的方式則是從  根節
點開始，利用上界信賴公式計算每個子點的上界信賴值，選擇此值最高的子點，然後
重複此方式，不斷往下搜尋，直到遇到葉節點為止。 
STEP 2. 拓展(Expansion)：若步驟 1 最後找到的葉節點已經拜訪過，則我們會產生此葉 節點
的子節點，以找到從未拜訪過的葉節點。 
STEP 3. 模擬(Simulation)：找到從未拜訪過的葉節點後，我們會使用蒙地卡羅模擬以得到此葉
節點的收益值。 
STEP 4. 倒傳遞(Backpropagation)：根據步驟 3得到的收益值，更新這條從根節點到葉節點的
 9 
所有子點模擬棋局的結果。對於任一節點，其收益值為「此一節點之模擬棋局勝利數/此點拜訪(經過)
次數」，亦即其勝率。上式中所謂的勝利數，指的是指向此節點的分支所代表的顏色(黑棋或白棋)在
模擬時的勝利次數。 
在實際上執行蒙地卡羅上界信賴樹狀搜尋時，其流程可以圖 2表示： 
                     
 
圖 2. 蒙地卡羅上界信賴樹狀搜尋的流程 
上圖中，所謂「得到最佳路徑」，指的是從根節點開始，根據上界信賴公式向下搜尋，直到找到
葉節點為止的過程。所謂葉節點，就是未曾拜訪過的節點。當搜尋時，若拜訪到的節點雖非葉節點，
但仍無子點，則會產生子點，子點的多寡，直接影響到搜尋的深度與棋力的高低，因此對於產生出
來的子點，必須加以裁減，搜尋的效率才會提高。 
第三個步驟是模擬棋局。所謂的模擬棋局，就是由上一個步驟所找到的葉節點開始，由電腦接
以當前盤面建立
根節點 
更新上界信賴搜尋樹 
模擬次數加一 
判斷是否達到目
標模擬次數 
否 
是 
回傳根節點底下勝率最高的
子點作為搜尋的結果 
 由根節點開始， 
得到最佳路徑 
執行模擬棋局 
 11 
向成長，影響開局庫的強度與可信度。因此在建立開局庫時，將電腦程式的時限設得較長，以增加
其實力，避免下出錯著，是一個可以想像的方法。然而這樣一來，勢必極度耗費計算資源，為解決
此一問題，本子計畫試圖在志願型計算系統上建構開局庫，藉由此系統強大的計算能力，希冀能夠
解決耗費計算資源之問題。 
3.5 志願型計算與桌機格網計算 
3.5.1 志願型計算(Volunteer Computing) 
傳統雙人零和遊戲(zero-sum game)的搜尋策略大都採用結合 alpha-beta 搜尋和專家經驗的著手
評估法則來進行遊戲的模擬搜尋。此類搜尋方法在某些遊戲搜尋的設計上，能發揮相當大的效果，
如：西洋棋(Chess)、黑白棋(Othello)等。但在複雜度相當高的遊戲上，如：圍棋、象棋和六子棋就不
是那麼的管用，主要原因在於複雜度高的遊戲的搜尋樹中，每一個階層的分支度都相當大，如果要
對每一種合法的著手進行著手評估，再進行 alpha-beta搜尋，將會在每一個階層耗費相當大的計算時
間，如此的作法會限制搜尋的深度，當然也就無法提供正確的搜尋結果。 
近幾十年以來，科學家不斷的在努力著想要解決大量計算和大量資料存取的需求。在早期，是
利用超級電腦(Super Computer)來執行大量的計算，但是超級電腦的價格昂貴且系統複雜難以維護，
因此，為了解決這樣的問題，志願型計算(Volunteer Computing )便誕生了。 
志願型計算可看作是分散式計算(Distributed Computing)的延伸，它蒐集並整合多個分散的小型計
算資源或儲存空間，任何想分享資源(Resource)的電腦都可以自由的加入。而它在經濟和便利性上的
優勢，使得它逐漸取代超級電腦，成為現在運用在大量計算上的主要系統。目前的桌機格網(Desktop 
Grid)即為志願型計算系統的一種。 
志願型計算的特性如下︰ 
 任何想分享資源(Resource)的電腦都可以自由的加入以及離開 
 資源動態性比較高，彼次配備差異 
 依使用者需求提供功能 
 提供單台或是一小群機器在有限時間內無法達到的功能 
 透過共同語言以及互動協定，整合各地運算資源、資訊與服務 
 遠端提供的服務用起來與與近端(區域)提供的服務一致 
 可促成大規模的科學或是商業合作，提供遠端實驗、高效能分散式運算與資料分析 
 
志願型計算專案最早是在 1996 年開始，運用在數學上，幫助尋找 Mersenne 質數，名為
GIMPS(Great Internet Mersenne Prime Search)，此後，在 1997到 1998年間，Bayanihan、 Popcorn、 
Superweb與 Charlotte…等以 Java 為基礎的志願型計算系統開始相繼出現。到 1999年，SETI@home
被提出後，吸引了數以萬計的志願者加入，志願型計算開始廣為人知。一直到現今，許多公司開始
將它門商業模組的概念加入志願型計算。 
3.5.2 桌機格網計算(Desktop Grid) 
桌機格網計算也被稱做是志願者計算(Volunteer Computing)，因其計算資源都源於志願者自己提
供。桌機格網透過網路收集處於閒置狀態的電腦，他主要包含用戶端(Client)、志願者(Volunteer)、伺
服器(Server)等三個部分，用戶端提供應用程式提交工作(Job)給伺服器，並且查詢結果，志願者提供
資源，當其處於閒置狀態的時候捐獻出電腦的資源。伺服器則集中管理所有志願者與工作。伺服器
可以透過檔案主機去協助維護所有被使用的檔案以及儲存工作與運算結果。提供應用程式提交工作
給伺服器維護所有的檔案、工作與運算結果集中管理所有志願者與工作提供資源。 
 13 
24. S Gelly and D Silver, "Combining Online and Offline knowledge in UCT," in Proceedings of the 24th 
International Conference on Machine Learning, Corvalis, Oregon, 2007, pp. 273-280. 
25. G Chaslot, C Fiter, JB Hoock, A Rimmel, O Teytaud. ―Adding expert knowledge and exploration in 
Monte-Carlo Tree Search . Advances in Computer Games. pp. 1-13, 2010. 
26. G. Chaslot, M. Winands, J. Uiterwijk, and H.J. Van der Herik, "Progressive Strategies for Monte Carlo 
Tree Search," in Proceedings of the 10th Joint Conference on Information Sciences (JCIS 2007), 2007, pp. 
655-661. 
27. L. Kaelbling, M. Littman, and A. Cassandra. ―Planning and acting in partially observable stochastic 
domains . Artificial Intelligence, 101:99-134, 1995. 
28. S. Russell and P. Norvig, Artificial Intelligence, A Modern Approach. Third Editon, Pearson 2010. 
29. N Sturtevant, "An analysis of UCT in Multiplayer Games," in Proceedings of the 6th International 
Conference on Computers and Games. , volume 5131 of Lecture Notes in Computer Science, pp. 37–49. 
Springer, 2008. 
30. J Long, N Sturtevant, M Buro, and T Furtak, "Understanding the Success of Perfect Information Monte 
Carlo Sampling in Game Tree Search," in Proceedings of the 24th AAAI Conference on Artificial 
Intelligence, Atlanta, 2010. 
31. M. Zinkevich, M. Johanson, M. Bowling, and C. Piccione, "Regret Minimization in Games with 
Incomplete Information," in Proceedings of the 21st ACNIPS, 2007, pp 1729 – 1736. 
32. D. Koller and N. Megiddo. ―The complexity of two-person zero-sum games in extensive form . Games 
and Economic Behavior, pp 528–552, 1992. 
33. M Lanctot, K Waugh, M Zinkevich, and M Bowling, "Monte Carlo Sampling for Regret Minimization in 
Extensive Games ," in Proceedings of the 23rd ACNIPS, , 2009, pp. 1078-1086. 
34. M. Bowling et al, ―A Demonstration of the Polaris Poker System , in Proceedings of the 8th International 
Conference. on Autonomous Agents and Multiagent Systems (AAMAS 2009), May 2009, Hungary, pp. 
1391 –1392. 
35. T. Cazenave and N. Jouandeau, "On the Parallelization of UCT," in ACG 2007, pp 93-101. 
36. G.M.J-B. Chaslot, M. Winands, and H.J. van den Herik, "Parallel Monte-Carlo Tree Search," in 
Proceedings of the 6th International Conference on Computers and Games, volume 5131 of LNCS, pp. 
60–71. Springer, 2008. 
37. H.J. Berliner, Some Necessary Conditions for a Master Chess Program, Proceedings of the 3rd 
International Joint Conference on Artificial Intellignce, (Menlo Park: SRI), Stanford, 1973, pp. 77-85. 
38. Bernard Helmstetter, Chang-Shing Lee, Mei-Hui Wang, Fabien Teytaud, Olivier Teytaud, Shi-Jim Yen, 
"Random positions in Go," 2011 IEEE Conference on Computational Intelligence and Games, 2011, Seoul, 
South Korea. 
39. Van Lishout, F., Chaslot, G., Uiterwijk, J.: Monte-Carlo Tree Search in Backgammon. In: Computer 
Games Workshop, pp. 175–184 (2007) 
40. G. Van den Broeck, K. Driessens, J. Ramon, Monte-Carlo tree search in poker using expected reward 
distributions, in: Advances in Machine Learning, First Asian Conference on Machine Learning, ACML 
2009, pp. 367–381.. 
41. Borsboom, J., Saito, J.-T., Chaslot, G., and Uiterwijk, J. W. (2007b). A comparison of monte-carlo 
methods for phantom go. BNAIC 2007, Utrecht, The Netherlands. 
42. P. Ciancarini and G.P. Favini, “Monte Carlo tree search in Kriegspiel,” Artificial Intelligence, vol. 174, Jul. 
2010, pp. 670-684. 
43. M. Enzenberger, M. Müller, B. Arneson and R. Segal. “Fuego - An Open-Source Framework for Board 
Games and Go Engine Based on Monte Carlo Tree Search,” IEEE Transactions on Computational 
Intelligence and AI in Games, 2(4), 259-270, 2010. 
44. Bouzy, B. and Chaslot, G. (2006). Monte-Carlo Go Reinforcement Learning Experiments. 2006 IEEE 
Symposiumon Computational Intelligence and Games(eds. G. Kendall and S. Louis), pp. 187-194, Reno, 
USA. 
45. Bernard Helmstetter, Chang-Shing Lee, Mei-Hui Wang, Fabien Teytaud, Olivier Teytaud, Shi-Jim Yen, 
"Random positions in Go," 2011 IEEE Conference on Computational Intelligence and Games, 2011, Seoul, 
South Korea. 
46. Thompson, K. (1986). Retrograde analysis of certain endgames, ICCA Journal, Vol. 9 No.3, pp. 131-139, 
 15 
 
4 研究方法 
4.1 第一年：研究並實作於單機以及簡易型志願型系統上建構圍棋開局庫之方法 
 （2010年 8月至 2010年 10月）蒙地卡羅上界信賴樹狀搜尋演算法之研究。 
 （2010年 11月至 2011年 1月）於共享記憶體架構下建構九路圍棋開局資料庫。 
 （2011年 2月至 2011年 3月）研究並實作於單機上建構圍棋開局庫。 
 （2011年 3月至 2011年 4月）志願型計算基本概念之研究。 
 （2011年 5月至 2011年 7月）於簡易型志願型計算系統上建構圍棋開局庫之研究。 
4.1.1 蒙地卡羅上界信賴樹狀搜尋演算法之研究 
蒙地卡羅上界信賴樹狀搜尋演算法，是上界信賴演算法(Upper Confidence Bound, UCB) [P. Auer, 
N. Cesa-Bianchi, and P. Fischer, 2002]結合蒙地卡羅演算法[Horowitz, Sahni and Rajasekaran, 2008]並應
用於樹狀搜尋的一種嶄新的演算法，目前在圍棋領域取得了極大的成功。在本階段中，我們將此演
算法運用於九路圍棋程式 Coldmilk上，且加入一些基於圍棋領域的經驗法則，以提升圍棋程式之棋
力，以供未來能夠更準確地建構九路圍棋開局庫。 
本階段已完成以下兩個部分： 
1. 建構一個基於蒙地卡羅上界信賴樹狀搜尋演算法的九路圍棋程式，可供未來建構九路圍棋開
局庫使用。 
2. 加入一些基於圍棋領域的經驗法則，提升此圍棋程式之棋力。 
4.1.2 研究於共享記憶體架構下建構九路圍棋開局資料庫的方法 
目前的中央處理器架構大多為多核心，在本階段中，我們研究在多核心且共享記憶體的架構下，
如何使用蒙地卡羅上界信賴樹狀搜尋演算法建構圍棋開局資料庫，藉由平行計算的研究，作為未來
在志願型計算系統上設計程式之基礎。在本階段中，我們以上一階段撰寫之九路圍棋程式 Coldmilk
為基礎，研究[Pierre Audouard et. al. 2009]所提出的建構開局庫的演算法如何施行於共享記憶體架構
下的多核心機器上。 
4.1.3 研究並實作於單機上建構圍棋開局庫 
本階段主要就是將前兩個階段的研究付諸實現，在單機系統上實際建構圍棋開局庫，並將此一
單機之實現作為雛型系統，以研究開局庫著手之選擇等議題，並作為未來在志願型計算系統上建構
開局庫的基準。在本階段中，我們實作了在共享記憶體的多核心機器上建構九路圍棋開局庫的方法，
並依照此方法實際建構了一個小型的九路圍棋開局庫。  
 
4.1.4 志願型計算基本概念之研究 
在本階段中，我們研究志願型計算之基本概念，藉由研究分析現存之志願型計算系統、格網系
統、桌機格網系統等等現存系統之異同，作為在志願型計算系統上發展程式之敲門磚。 
 17 
穩定性以及諸如帳號權限等系統實際上線時會遇到的諸多問題，並據此與子計畫 V1 互相討論與成
長。 
本階段結束時，經由實際上線測試，我們已經修正九路圍棋開局庫建構系統中，大部分事前考
慮不周的錯誤，並新增了容錯機制以及錯誤處理機制，使整個系統更加強固與完善，有助於接下來
對於九路圍棋開局庫的建立。  
4.2.4 回饋問題與建議至子計畫 V1 
在本階段中，我們開始利用前幾個階段打造的九路圍棋開局庫建構程式來實際建構開局庫，並
隨時回饋問題與建議至子計畫 V1。在本階段中，我們以精確性較低，但耗費計算資源較少，建構速
度較快的參數來建構一個測試用的九路圍棋開局庫。 
在本階段完成時，我們已經擁有一個運作在志願型計算系統上的九路圍棋開局庫建構程式，並
利用此程式自動建構出一個迷你的九路圍棋開局庫，以供後續測試之用。 
4.2.5 隨子計畫 V1之修改，繼續完成整合測試 
在本階段中，我們持續讓程式繼續自動建構九路圍棋開局庫，以擴大此開局庫之深度與廣度；
與此同時，我們試圖讓程式使用此開局庫進行測試，以釐清此一自動建構之開局庫是否真的能夠幫
助程式棋力增長。在本階段中，我們獲得了一些正面的實驗結果，可以將程式的勝率，由未使用開
局庫的 52.2%，增加到使用開局庫後的 61.8%。最後，我們更改建構時的各種參數，並透過大量實
驗，探討參數改變帶來的各種影響，以建立更佳之開局庫。 
4.3 第三年：研究與其他程式對戰並自我學習以改進九路圍棋開局庫 
 （2012年 8月至 2012年 12月）研究透過對戰並自我學習以改良開局庫的方法 
 （2013年 1月至 2013年 5月）與其他程式進行實際對戰以改進九路圍棋開局庫 
 （2012年 5月至 2012年 7月）進行進階測試以增進開局庫的穩定性以及程式棋力 
4.3.1 研究透過對戰並自我學習以改良開局庫的方法 
在前一個階段，我們主要透過自己與自己對戰進行學習，發展出一套九路圍棋開局庫，並取得
不錯的成績。然而，與自己對戰所獲得的開局庫仍有其極限。所謂他山之石，可以攻錯，有一些圍
棋攻殺上的缺點，在自行對戰時看不出來，非得要跟其他具有相當實力之程式對戰，才會暴露出這
些弱點，並加以防範。因此在這個階段，我們研究如何透過與其他程式的高水準對戰，截長補短，
來找到既有的開局庫中的弱點，並透過自我學習的方式，逐漸避開這些弱點，以發展出一套適合自
己的圍棋開局庫。 
自我學習有幾個要注意的地方，首先是對手的部分，如果對手太過單一，有可能僅依賴對手的
弱點獲得勝利，此時開局庫的發展便會走偏，因此必須取得多個不同風格的對手，才有可能達到找
出弱點的目的。此外，何時決定根據過往勝負結果落子，何時又該給其他著手機會，也是考量的關
鍵所在。如果僅根據過往勝負結果發展開局庫，確實可以對於某一個分支搜尋得較深，但是缺點是
失之過狹，一旦對手走出意料之外的著手，便會太快脫譜，導致開局庫無用武之地；然而若是常常
選擇其他著手，則可能失之過廣，下沒幾手變缺乏應對著手，也一樣會脫離開局庫。因此這個部分
主要著重於研究如何透過多個程式間的對戰修正開局庫，使得開局庫能夠更加均衡，以提升程式的
 19 
5 結果與討論 
5.1 本計畫完成工作項目概述 
本計畫完成之工作項目概述如下，相關研究內容已發表在期刊論文與研討會論文。 
 第一年：研究蒙地卡羅上界信賴樹狀搜尋演算法，於共享記憶體架構下建構九路圍棋開局
資料庫，研究並實作於單機上建構圍棋開局庫，並完成志願型計算基本概念之研究，最後
配合九路圍棋程式 Coldmilk，研究在簡易型志願型計算系統上建構九路圍棋開局庫之方法，
並修正一些因為系統差異造成的問題，以作為來年實際投入志願型計算系統之堅實基礎。 
 第二年：首先研究志願型計算系統，接著研究於志願型計算系統上建構圍棋開局庫之方法，
然後實現平行化的九路圍棋開局庫建構系統。經由實際上線測試，修正九路圍棋開局庫建
構系統中大部分的錯誤，並新增容錯機制以及錯誤處理機制，最後利用此程式自動建構出
一個迷你的九路圍棋開局庫，使程式的勝率有著大幅的提升；此外，我們也對建構開局庫
時所需之參數進行最佳化，以提升開局庫之品質。 
 第三年：研究與其他程式對戰並自我學習以改進九路圍棋開局庫，接著實際其他程式進行
對戰，使得開局庫之漏洞獲得補強，然後進行進階測試以增進開局庫的穩定性以及程式棋
力，最終在七戰四勝制的挑戰賽中擊敗圍棋職業棋士黨希昀。 
5.2 對於參與之工作人員，獲得之訓練 
對於參與的人員，將對人工智慧中的電腦對局、各種搜尋方式、機器學習和資料探勘方法有更
深入的瞭解及產生相關的研究成果。執行計畫的學生畢業時，能夠將 MCTS應用在產業界與國防工
業，對於培養前瞻性科技與技術研發人才將有所貢獻。目前國內數位遊戲產業中，由於在數位遊戲
領域，人工智慧應用的範圍越來越廣，所以相當缺乏遊戲人工智慧人才，以本實驗室為例，通常畢
業前就有很多遊戲製作公司來詢問人才。本計劃可幫助學生具有此一方面的能力，可以培養相關技
術研發人才，畢業後投入業界，提升產業競爭力，對相關產業發展有所幫助。 
5.3 本計畫貢獻 
MCTS 對於對局類遊戲的發展，包括兵棋推演，都會有革命性的影響，我們投入此研究，使得
台灣在此方面不至落後。計畫的成果不僅可以幫助研發出棋力高強的電腦對局程式，也可應用於電
腦遊戲上，這些開發出的技術，也可幫助國內遊戲廠商開發相關遊戲，提高國際競爭力。 
目前世界上流傳最廣的棋類有象棋、圍棋、西洋棋等，其中以圍棋人口為最多，象棋次之，而
六子棋則是新興遊戲。相關的數位內容發展，已漸漸成為華人世界的焦點之ㄧ。大陸的各學術單位
近年來對此著力頗深，已經有一年一度的省對抗電腦對局比賽及世界級的電腦對局比賽，已漸漸威
脅台灣在此方面的領先地位，本計劃可提升我們電腦對局研究團隊的競爭力。 
計畫成果包括學術或技術上創新的 MCTS 相關搜尋演算法及其應用，及機器學習理論，目前共
有包括 IEEE TRANS. 兩篇，SCI期刊論文共 10篇與 10篇研討會議論文發表，論文詳列於本章後段。 
所研發製作出的電腦對局程式，三年來都有參加國際性的比賽，三年來比賽的成績如下表。在
圍棋、象棋、六子棋與暗棋等，繼續保持在世界前兩名的佳績。並且多次打敗職業棋士，建立數項
電腦圍棋的里程碑。 
綜合以上所述，本計劃已經達到預期的目標，確實完成預定的成果。 
 
 
 21 
8. Shi-Jim Yen*, Shih-Yuan Chiu+, Cheng-Wei Chou+, Chang-Shing Lee, Hassen Doghmen, Fabien 
Teytaud and Olivier Teytaud, "Human vs. Computer Go Competition in FUZZ-IEEE 2011," ICGA 
Journal, vol. 34, no. 4, 2011, pp. 243-247. (IF = 1.167) 
9. Ching-Nung Lin+ and Shi-Jim Yen*, "The TAAI 2012 Computer Go Tournaments and Human vs. 
Computer Go Competition," ICGA Journal, vol. 36, no.4, pp. 53-56, 2013. (IF = 1.167) 
10. Cheng-Wei Chou+, Ching-Numg Lin+, Shi-Jim Yen*, Hideki Kato, and Jr-Chang Chen, "The 6th GPW 
Cup 9x9 and 13x13 Computer Go Tournaments," ICGA Journal vol. 35, no.1, pp. 59-60, 2012. (IF = 
1.167) 
 已發表相關國際會議論文(共十篇)： 
1. Shi-Jim Yen, Chen-Shin Lee+, Jr-Chang Chen, Tai-Ning Yang, Shun-Chin Hsu, "Suffix Tree Index 
Structure on Go Game Record," The 27th Annual Conference of the Japanese Society for Artificial 
Intelligence, June 4-7, Toyoma, Japan, 2013. 
2. Yu-Jie Ho+, Shun-Chin Hsu, Shi-Jim Yen, "An Efficient Index Structure for Go," The 27th Annual 
Conference of the Japanese Society for Artificial Intelligence, June 4-7, Toyoma, Japan, 2013. 
3. C. S. Lee, M. J. Wu, M. H. Wang, O. Teytaud, H. M. Wang, and S. J. Yen, “T2FML-based Adaptive 
Assessment System for Computer Game of Go,” 2013 IEEE International Conference on Fuzzy 
System (FUZZ-IEEE 2013), Hyderabad, India, Jul. 7-10, 2013.  
4. Ching-Nung Lin+ and Shi-Jim Yen, "A New Framework to Solve Open Boundary Semeai Problems in 
the Game of Go," the 17th Game Programming Workshop (GPW-2012), November 9-11, 2012, 
Hakone Seminar House, Kanagawa, Japan.  
5. Shi-Jim Yen and Tsan-Cheng Su+, "An efficient algorithm for solving Fillomino," 2011 IEEE 
International Conference on Fuzzy Systems, June 27-30, 2011. 
6. Shi-Jim Yen, Tsan-Cheng Su+ and Shun-Chin Hsu, "An efficient algorithm for solving Fillomino," 
2011 IEEE International Conference on Fuzzy Systems( IEEE FUZZ 2011 ), June 27-30, 2011, Taipei, 
Taiwan. 
7. Shi-Jim Yen, Cheng-Wei Chou+, Tsan-Cheng Su+, Shun-Chin Hsu, Hsin-Hung Chou and Jr-Chang 
Chen, "Monte Carlo Tree Search in Chinese Dark Chess ," the 16th Game Programming Workshop 
(GPW-2011), November 4-6, 2011, Hakone Seminar House, Kanagawa, Japan. GPW-2011. 
8. Ping-Chiang Chou, Hassen Doghmen, Chang-Shing Lee, Fabien Teytaud, Olivier Teytaud, Hui-Ming 
Wang, Mei-Hui Wang, Li-Wen Wu and Shi-Jim Yen, "Computational and Human Intelligence in Blind 
Go," 2011 IEEE Conference on Computational Intelligence and Games( IEEE CIG 2011), August 31- 
September, 2011, Seoul, South Korea. 
9. Olivier Teytaud, Cheng-Wei Chou+, Ping-Chiang Chou, Hassen Doghmen, Chang-Shing Lee, 
Tsan-Cheng Su+, Fabien Teytaud, Olivier Teytaud, Hui-Min Wang, Mei-Hui Wang, Li-Wen Wu, 
Shi-Jim Yen, "Towards a solution of 7x7 Go with Meta-MCTS," Advances in Computer Games 13, 
November 20-23, 2011, Tilburg University, The Netherlands. 
10. Cheng-Wei Chou+, Olivier Teytaud, Shi-Jim Yen, "Revisiting Monte-Carlo Tree Search on a New 
Normal Form Game: NoGo," European Conference on the Applications of Evolutionary Computation 
2011(Evoapplications 2011), April 27-29, 2010, Torino, Italy. 
A Simple Tsumego Generator  
 
 
Ping-Chiang Chou1, *Shi-Jim Yen2, Cheng-Wei Chou2, Ching-Nung Lin2 
Chang-Shing Lee3, Olivier Teytaud4, Hassen Doghmen4, Tai-Ning Yang5  
 
 
Abstract: Generating problems is an interesting challenge, for both pedagogical purpose and for assessment. We propose a 
simple solution for generating problems, which can be used on a wide range of games and simulators, and evaluate it in the 
framework of the game of Go, providing problems from lowest amateur range to problems which are not trivial even for 
professional players. 
 
Keywords: Go, tsumego, problem generator 
 
 
 
1. Problems and Tsumegos     
Generating an interesting test case is a classical important 
problem. A nice test bed is the case of games; but generating 
problems is also an issue in industry. Most approaches for the 
game of Go are based on specific generators [3-5]; such tools 
provide very good Tsumegos, interesting for players of arbitrary 
strength. Other game-specific tools for generating problems are 
those based on complexity results, like [7] (generating 
incredibly complicated ko-fights) and [8] (which provides 
boards which are not so much bigger than the 19x19 board). 
However, these tools generate very artificial problems, and are 
usually too big for the 19x19 board, which makes them not that 
interesting for humans. Here we focus on methods which can be 
used for any game. Such a generalist approach has been 
proposed in [6]; however, the point there was to generate very 
surprising, unnatural situations; here we want to generate 
situations: 
 possible difficult (we provide a player, and we want 
the situation to be too hard for him); 
 which can occur in real life. 
 
2. A Simple Algorithm: STG 
We propose the simple Tsumego generator (STG) as follows, 
for generating a Tsumego (i.e. an interesting position). The 
algorithm depends on a strong player (supposed to be strong 
enough for correctly evaluating positions) and a “weak” player 
                                                                
 †1 Taiwan Go Association. cabon1224@hotmail.com 
†2 Dept. of Computer Science and Information Engineering, National 
Dong Hwa University, Hualien, Taiwan. Email: 
sjyen@mail.ndhu.edu.tw, kapakapa@gmail.com, 
jironglin@gmail.com 
 †3 Dept. of Computer Science and Information Engineering, 
National University of Tainan, Taiwan. Email: 
leecs@mail.nutn.edu.tw 
 †4 TAO team, Inria Saclay IDF, LRI, UMR 8623(CNRS - Universite 
Paris-Sud), France. Email: olivier.teytaud@gmail.com, 
hassen.doghmen@gmail.com 
†5Department of Computer Science and Information Engineering, 
Chinese Culture University, Taipei, Taiwan. Email: 
tnyang@faculty.pccu.edu.tw 
(the position will be too hard for the weak player); it starts in a 
position which is in favor of the weak player: 
 
Inputs: 
1. a turn-based game, which is unfair, i.e. easier for one 
side than for the other (e.g. “7x7 Killall-Go with no 
handicap”, or Go with komi 30.5) 
2. a strong player 
3. supposed to be practically perfect on this game; 
4. playing the difficult side. 
5. a weak player 
6. playing the easy side; 
7. supposed to do at least occasionally some mistakes. 
 
Algorithm: 
1. found=false 
2. While (not found) 
3. play one game of the weak player against the strong 
player, until 
4. either the strong player loses the game 
5. or the strong player detects that the situation is a win; 
then: 
6. found ← true. 
7. Output the last situation which was a win for the weak 
player 
8. Output the move chosen by the strong player on this 
situation 
 
Outputs: 
1. a situation 
2. an optimal move for this situation 
 
The algorithm is quite simple, but it is efficient, as we will 
see in next sections. 
3. Experiments on the game of Go 
We consider two games: 
 7x7 Killall-Go, with no handicap, as in Fig. 1-6. This 
means that black plays first, then players play as usual, 
and White wins if and only if he can have at least one 
 3.2 7x7 Go 
It is widely assumed that the fair Komi in 7x7 Go is 9, 
which means that with komi 8.5, 
Black should win. Therefore, we can apply STG for 
generating Tsumegos as follows: 
 Game = 7x7 Go with Komi 9.5. 
 Weak player = MoGo with 100 000 000 simulations per 
move and automatically generated opening book 
(generated by Meta-MCTS [1]). 
 Strong player = MoGo with 100 000 000 simulations per 
move and handcrafted opening book (designed from the 
games in Taipei 2011 and Brisbane 2012 [2], using 
discussions with professional players and strong 
amateurs). 
 
Incidentally, this was helpful for checking the automatically 
generated opening book. 
 This generated (in roughly 48 hours, Intel Celeron 2.2 
GHz) the following Tsumego: Black should play E2 to win. 
Importantly, this move is difficult, even for a professional 
player; the optimal move is E2 in Chinese rules. 
 
 
Fig. 7: A difficult Tsumego (Black to win, komi 8.5) 
 
 
Fig. 8: Solution by Ping-Chiang Chou (5P). 
 
4. Conclusion and Future work 
4.1 Conclusion 
We proposed a simple algorithm for generating problems. 
This algorithm can be used in the following case: 
 There should be a safe strategy. 
 There is a solver strong enough for checking where is the 
mistake in  a game. 
 We can design a player roughly of the expected strength 
of the Tsumego. 
 Its outputs are problems: (1) at the level of the weak 
player; (2) not necessarily at endgame level;(3) 
accompanied with a solution; (4) as natural as the game 
style of the weak and strong player. 
 
Some by-products of this work: 
 including the solution to the 7x7 Tsumego with komi 9.5, 
we get a 7x7 Go player which never lost games, among 
many trials against strong MCTS programs: 
 before including Ping-Chiang's correction, there was an 
opening for White leading to many losses for Black, in 
spite of komi 8.5, even for 10^8 simulations per move; 
 after including Ping-Chiang's correction, there were still 
losses, for permutations of this opening; 
 after including these permutations, we got no loss with 
10^7 and 10^8 simulations per move (out of 64 and 73 
games played as Black and White respectively, including 
24 as Black against the specific opening on which MoGo 
was losing as black before Ping-Chiang correction); 
 however we still get  18% and 9% loss respectively for 
Black and White, when playing with 10000 simulations 
per move, so the opening book is not enough for making 
the game trivial. 
 several Tsumegos of various amateur levels (including 
seki situations); 
 one Tsumego of strong amateur or professional level. 
 
4.2 Future work 
STG is here applied to Go, but it can be applied to other 
games, and also to other problems. The strong player decide the 
faults (with a constraint such as “no more than K faults”), the 
weak player makes the operator decisions, then the equivalent of 
a Tsumego is a situation in which the optimal decision by the 
human operator is not trivial. There is for sure a gap between 
our tests, in this paper, in a game, and an industrial application, 
but conceptually nothing prevents such a transfer, and as we 
have access to such simulators and solvers this further work is 
our priority. 
 
Acknowledgements. The authors are grateful to NSC for 
support NSC 100-2811-E-024-001, to Bielefeld Search 
methodologies seminar, to BIRS game theory seminar, to 
Dagstuhl's seminar on Theory of Evolutionary Computation. 
 
References 
 
1) C.-W. Chou, P.-C. Chou, H. Doghmen, C.-S. Lee, T.-C. Su, F. 
Teytaud, and O. Teytaud, “Towards a solution of 7×7 go with 
meta-MCTS,” in Proceedings of Advances in Computer Games 
2011. 
2) Chang-Shing Lee, Olivier Teytaud, M.-H. Wang, S.-J. Yen. Science 
meets the game of Go, Computational Intelligence Magazine, 
國立東華大學 
專任教師出席國際學術會議報告 
 
報告人姓名 
 
顏士淨 
 
服務機構 
及職稱 
國立東華大學資訊工程系 
教授 
會議時間 2013/7/7-10 會議地點 印度海德拉巴 
會議 
名稱 
 (中文) 2013 電機電子工程師學會(IEEE) 模糊系統國際研討會 
 (英文) 2013 IEEE International Conference on Fuzzy Systems 
發表 
論文 
題目 
 (中文) 基於第二型模糊推論系統的圍棋可適性評估系統 
 (英文) T2FML-based Adaptive Assessment System for Computer Game of Go 
報告內容應包括下列各項： 
一、參加會議經過 
 
參加 2013 IEEE International Conference on Fuzzy Systems 國際會議，發表學術論文，
T2FML-based Adaptive Assessment System for Computer Game of Go。並參與協辦人腦對電腦圍棋
比賽與測試基於第二型模糊推論系統的圍棋可適性評估系統。 
 
二、與會心得 
電腦科技日新月異，此會議中主題為模糊推論系統。模糊推論系統為具有潛力的學術研究領域，
各國在這領域琢磨甚多。參加此次會議，與各國學者交流，感覺受益良多。 
 
三、考察參觀活動(無是項活動者省略) 
 
無 
 
四、建議 
 
模糊推論系統為具有潛力的學術研究領域，可在國內加以推廣。 
 
 
五、攜回資料名稱及內容 
 
Proceedings of 2013 IEEE International Conference on Fuzzy Systems 
 
 
六、其他 
 
無 
0940222修訂/表 RD104 
developed to allow system designers to express their expertise 
by using “interval type-2 fuzzy logic system (IT2FLS)” [6, 9, 
10]. This paper combines the technologies of the ontology 
with UCT, T2FS, and T2FML to propose a T2FML-based 
adaptive assessment system for computer game of Go. From 
the experimental results, the proposed approach is feasible to 
estimate the Go player’s rank. The remainder of this paper is 
organized as follows: Section II describes T2FML-based 
adaptive assessment system. Section III introduces the 
adaptive Go-ranking construction and analysis for number of 
simulations. The T2FML-based fuzzy inference mechanism 
for the proposed system is presented in Section IV. 
Experimental results are shown in Section V and finally, 
conclusions are given in Section VI. 
II. T2FML-BASED ADAPTIVE ASSESSMENT SYSTEM 
A. Structure Overview 
For humans, it will have much more fun when playing 
with one human than with one computer Go program. Playing 
with the computer Go program may be boring because the 
computer Go program cannot express its feelings, especially in 
one lopsided game. If the computer Go program can 
adaptively assess its opponent’s strength and provide one real-
time feedback mechanism for Go players, it will be helpful for 
humans to increase their interest in playing with the computer 
Go program and find their relevant opponents and/or relevant 
handicap. Hence, in this paper, one T2FML-based adaptive 
assessment system for game of Go is proposed. Fig. 1 shows 
its structure and Table I lists its brief description for the 
adaptive assessment system. 
PlayersMoGoTW
Game Results
Repository
Players Rank
Repository
T2FML-based 
Fuzzy Inference Mechanism
Adaptive UCT-based
Go-Ranking Mechanism
Bradley-Terry Model 
Estimation Mechanism
T2FS Construction Mechanism 
for Simulation Number 
Analysis and Comparison
Mechanism 
Domain Expert
KB/RB
Repository
Adaptive Go-Ranking
Assessment Ontology
Human vs. MoGoTW
PSO Model 
Estimation Mechanism
 
Figure 1. Adaptive assessment system for computer game of Go. 
 
TABLE I. BRIEF DESCRIPTIONS FOR THE ADAPTIVE ASSESSMENT SYSTEM. 
Step1. Domain expert establishes the adaptive Go-ranking assessment 
ontology based on the past held human vs. computer Go competitions. 
Step2. Several Go players with Kyu (K) or Dan (D) level are invited to play 
with MoGoTW. According to IRT, the adaptive UCT-based Go-ranking 
mechanism adaptively adjusts the number of simulations per move to 
make MoGoTW’s strength as close to a Go player’s rank as possible. 
That is, when MoGoTW has a higher winning rate, then this mechanism 
decreases the simulations to weaken its strength. On the contrary, this 
mechanism increases the simulations to strengthen its level. The 
number of simulations per move and game result for each game each 
Go player are stored in the game results repository. 
Step3. T2FS construction mechanism for simulation number retrieves the 
collected numbers of simulations from the game results repository to 
construct the T2FS for the simulation number. 
Step4. Domain expert uses the T2FML to describe the knowledge base (KB) 
and rule base (RB) of the proposed system by referring to the output of 
the T2FS construction mechanism for simulation number and the 
related information about the past held games. The built KB and RB are 
stored in the KB/RB repository. 
Step5. Based on the established ontology, KB, and RB, T2FML-based fuzzy 
inference mechanism infers the Go player’s rank according to each 
game’s komi, board size, and simulation number. 
Step6. Bradly-Terry model and particle swarm optimization (PSO) model 
estimation mechanisms also assess the maximum likelihood of number 
of simulations to acquire the Go player’s rank, respectively. 
Step7. Analysis and comparison mechanism makes a comparison for the 
estimated rank and stored the results into the players rank repository. 
B. Adaptive Go-Ranking Assessment Ontology  
A three-layer adaptive Go-ranking assessment ontology, 
shown in Fig. 2, is constructed, including a domain layer, a 
category layer, and a class layer. The class layer is composed 
of the Where layer, Who layer, When layer, and What/How 
layer. 
 
Figure 2. Adaptive Go-ranking assessment ontology. 
 
Below is its brief descriptions: (1) Doman Layer: The 
domain name is Adaptive Go-Ranking Assessment Ontology; 
(2) Category Layer: For game of Go, two players alternately 
place one black stone and then one white stone on the vacant 
intersections of the board. The board size could be 7×7, 9×9, 
13×13, or 19×19. Hence, we use the board size as a category 
of the ontology; (3) Where Layer represents the venue that 
holds the event. Since 2008, National University of Tainan 
(NUTN) in Taiwan and other academic organizations have 
hosted or organized several human vs. computer Go-related 
events at God Temple, NUTN, and NCKU, in Taiwan, and in 
IEEE CIS flag conferences, including FUZZ-IEEE 2009 (Jeju 
Island, Korea), IEEE WCCI 2010 (Barcelona, Spain), IEEE 
4LSN , and 5LSN  represent number of simulations that the 
human lost Games 1 and 2, but won Game 3, and then lost 
Games 4 and 5, respectively. 
181.0)log(027.0)log(*008.0 2 +×+−= SNSNRankGoPlayer  (4) 
C. T2FS Construction Mechanism for Simulation Number 
Go is one of the most complex game in the world, and it is 
a game with high certainty, which is suitable to use T2FS 
estimate the strength of a human. The membership function of 
a type-2 fuzzy set ( X~ ) is a three dimensional and includes a 
Footprint of Uncertainty (FOU), bounded between Lower 
Membership Function (LMF, X ) and Upper Membership 
Function (UMF, X ). A trapezoid type-2 fuzzy set, X~ , is 
represented by the following parameters on the x-axis {[BSL, 
BCL, ECL, ESL], [BSU, BCU, ECU, ESU]}, where (1) BSL, BCL, 
ECL, and ESL represent the begin support, begin code, end 
code, and end support of the X , respectively, and (2) BSU, 
BCU, ECU and ESU represent the begin support, begin code, 
end code, and end support of the X , respectively. T2FS 
construction mechanism for simulation number constructs the 
T2FS for fuzzy variable simulation number according to the 
game results repository. Its procedures are listed in Table II. 
TABLE II. T2FS CONSTRUCTION FOR SIMULATION NUMBER. 
Step1. T2FS of the simulation number (SN) for each player with different 
level is constructed according to the collected simulation numbers 
per move for K games each round for one player against the 
computer Go program. The constructed T2FSs of simulation number 
for N1, N2, N3, N4, N5, and N6 Go players with 1D, 2D, 3D, 4D, 5D, 
and 6D are {
1D11D1
~
 ..., ,
~
NNSNS −− }, { 2D21D2
~
 ..., ,
~
NNSNS −− }, 
{
3D31D3
~
 ..., ,
~
NNSNS −− }, { 4D41D4
~
 ..., ,
~
NNSNS −− }, 
{
5D51D5
~
 ..., ,
~
NNSNS −− }, and { 6D61D6
~
 ..., ,
~
NNSNS −− }, 
respectively. /*N1, N2, N3, N4, N5, and N6 denote number of the 
invited Go players with 1D, 2D, 3D, 4D, 5D, and 6D, respectively.*/ 
Step2. Domain expert chooses 6, 5, 6, 2, 8, and 3 Go players with 1D, 2D, 
3D, 4D, 5D, and 6D to be the reference to construct the knowledge 
base of the NS
~
. 
Step3. Category “1D and 2D,” “3D and 4D,” and “5D and 6D” as three 
different groups, because the variations in number of simulations per 
move are not so big for the adjacent-rank players. 
Step4. Domain expert constructs the knowledge base of the LowNS
~
 by 
referring{
1D11D1
~
 ..., ,
~
NNSNS −− } and 
{
2D21D2
~
 ..., ,
~
NNSNS −− }. 
Step5. Domain expert constructs the knowledge base of the HighNS
~
 by 
referring {
5D51D5
~
 ..., ,
~
NNSNS −− } and 
{
6D61D6
~
 ..., ,
~
NNSNS −− }. 
Step6. Domain expert constructs the knowledge base of the MediumNS
~
 by 
referring the constructed T2FSs LowNS
~
and HighNS
~
. 
/* LowNS
~
, MediumNS
~
, and HighNS
~
 denote the T2FS for the 
linguistic term of the fuzzy variable NS
~
.*/ 
Step7. End 
 
IV. T2FML-BASED FUZZY INFERENCE MECHANISM 
A. Type-2 Fuzzy Inference Structure 
This section describes the type-2 fuzzy inference structure. 
However, in order to reduce computational cost, an interval 
type-2 fuzzy set (IT2FS), a special case of T2FS, is adopted in 
this paper. Fig. 3 shows the T2FML-based controller tree for 
inferring player’s rank. It indicates that there are three fuzzy 
variables, simulation number (SN), board size (BS), and Komi 
for this study. SN and Komi have three linguistic terms, 
including Low, Medium, and High, and BS has two linguistic 
terms, including Small and Big. The number of fuzzy rule is 
18 adopted in this paper. 
T2FML-based Adaptive Assessment System
for Computer Game of Go
Knowledge Base Rule Base
Rank Rule 1 Rule 2 Rule 18
IF 
SN is and
BS is           and 
Komi is  
THEN Rank is 
SN BS Komi
IF 
SN is and
BS is            and 
Komi is  
THEN Rank is 
IF 
SN is and
BS is           and 
Komi is  
THEN Rank is 1D~
High~
Big~
Low~
Small~
Low~
1D~
Low~
Small~
Medium~
High~
6D~
Low~ Low~
Medium~ Medium~
High~ High~
Small~
Big~
1D~
6D~
2D~
3D~
4D~
5D~
 
Figure 3. T2FML-based controller tree for inferring player’s rank. 
 
A six-layer interval type-2 fuzzy inference structure for 
inferring Go player’s rank, including a input layer, an 
antecedent layer, a rule layer, a consequence layer, a type-
reduction layer, and an output layer, is constructed. The input 
layer represents the values of the input variables, such as SN, 
BS, and Komi. The antecedent layer denotes the membership 
for each input variable. However, for an IT2FS, the 
membership is an interval, for example, the membership of 
LowNS
~  is )](),([ SNSN
LowLow SNSN
μμ . The rule layer is used to 
compute the firing interval of the rule by PROD operator, 
where ],[
11 ff  represents the firing interval of the first rule. 
For our case, ],[
11 ff =[ )(SN
LowSNμ . )(BSSmallBSμ .
)(Komi
LowKomi
μ , )(SN
LowSNμ . )(BSSmallBSμ . )(KomiLowKomiμ ]. 
The consequence layer computes the centroid of each 
consequent IT2FS, where ],[
11 RankRank  is an interval for 
the first-rule consequent. The type-reduction layer computes 
the Rankl and Rankr. Finally, the crisp output of the IT2FS, 
Rank, is computed by averaging Rankl and Rankr [8, 15, 16]. 
B. T2FML-based Fuzzy InferenceMechanism 
Fig. 4 shows the content of the game results repository. Let 
us assume that one player is against MoGoTW for K games 
each round. The information of each game, including the 
number of simulations per move, board size, komi, and game 
result (win or loss). For example, Game 1 is one game that 
MoGoTW plays n1 moves so the number of simulations per 
move is SN11, …, and 11nSN . BS1, Komi1, and Result1 are the 
level to play with the MoGoTW for 9x9 games with komi 6.5 
at National University of Tainan (NUTN) in Taiwan on May 
27, 2012. Second, all of the invited Go players are Black and 
MoGoTW is White. Third, each human player plays five 
games for each round, but each human player is allowed to be 
against MoGoTW as many rounds as possible. Fourth, the 
UCT-based Go-ranking mechanism sets the initial value of SN 
is 30000. Table IV shows the game information on the 
competition and indicates that the total number of games is 
620 but 385 games are from Go players with Dan level. We 
can observe that number of games for 4D and 6D players is 10 
and 20, respectively, which is relatively fewer than the other 
players with other levels. Additionally, we only consider the 
Go players with Dan level and we also filter some games with 
some weaknesses. For example, we neglect one 6D player 
because he didn’t finish five games for one round. In addition, 
some players are against MoGoTW for many rounds. In order 
to simplify the situation, we only choose one of the best 
rounds as our experimental data. Table V shows the inferred 
rank for each game each player. It indicates that human’s 
strength is variable and not steady very much. For example, 
some players with 2D can be with the strength of 5D. On the 
other hand, 6D player is also possible to perform the strength 
of 1D, 2D, or 3D. Perhaps, this is caused by the variation in 
the simulation number in each game. 
TABLE IV. GAME INFORMATION ON MAY 27, 2012. 
No. Rank No. of Go Players 
No. of 
Rounds 
No. of 
Games 
1 Kyu 16 36 180 
2 1D 7 22 110 
3 2D 6 22 110 
4 3D 7 11 55 
5 4D 2 2 10 
6 5D 9 24 120 
7 6D 3 4 20 
Total from Dan Players 34 85 440 
Total from all Players 50 113 620 
 
After the competition, the rank of the Go player is 
estimated by three methods, including Bradley-Terry Model 
(BTM), PSO Model (PSOM), and the proposed approach in 
this paper. The initialization of the PSO model contains the 
dimension of the problem’s search space is 1, the searching 
bound is between the maximum and minimum number of 
simulations that the human won or lost, the number of 
particles in the population is 25, and the maximum iteration is 
1000. Table VI shows the estimated rank and standard 
deviation (SD) for each player. Fig. 6 shows the bar chart of 
SD for BTM, PSOM, and the proposed approach. From Fig. 6, 
we can observe the following situations: (1) The proposed 
method has the smallest SD for estimating the level of the Go 
players with 2D, 3D, 5D, and 6D. The proposed approach’s 
SD for 1D is not the smallest, but its SD is very close to zero; 
(2) BTM is the best to estimate the 3D and PSOM performs 
the best for 1D; (3) Compared to 1D, 2D, 3D, and 5D, the SD 
values for 4D and 6D are much relatively higher. Perhaps, it is 
caused by the collected data from 4D and 6D are not enough 
to construct a trustful T2FS. Fig. 7 shows the distribution of 
number of simulations corresponding to human players’ rank 
for BTM and PSOM, where x axis is human’s rank and y axis 
is log2 (number of simulations corresponding to human players’ 
rank). Figs. 7(a)-(b) also show the curves of the median data 
and mean data, respectively, according to different ranks. Fig. 
7 indicates that number of simulations has a tendency to 
increase when the human is with stronger level and some 2D 
Go players perform better than the other much stronger 
humans. 
TABLE V. INFERRED RANK FOR EACH GAME FROM EACH PLAYER. 
Player 
No. 
Dan: Inferred Rank 
R: Game Result (W: human wins, L: human loses) 
Game 1 Game 2 Game 3 Game 4 Game 5 
Dan R Dan R Dan R Dan R Dan R 
1D-1 2D L 1D L 1D L 1D W 1D L 
1D-2 1D L 1D L 1D L 1D W 1D L 
1D-3 2D L 1D L 1D W 1D L 1D L 
1D-4 3D L 2D L 1D L 1D L 1D W 
1D-5 2D L 1D L 1D W 1D L 1D L 
1D-6 2D L 1D L 1D W 1D L 1D L 
1D-7 2D L 1D L 1D W 1D L 1D W 
2D-1 2D L 1D W 2D L 1D W 2D L 
2D-2 2D L 1D W 2D L 1D L 1D W 
2D-3 2D L 1D W 2D L 1D L 1D L 
2D-4 3D W 5D W 1D L 5D L 2D L 
2D-5 2D L 1D L 1D L 1D W 1D L 
2D-6 2D W 5D L 2D L 1D L 1D L 
3D-1 3D L 2D L 1D W 2D L 1D W 
3D-2 2D L 1D L 1D W 1D L 1D L 
3D-3 2D L 1D L 1D W 1D L 1D W 
3D-4 2D L 1D W 1D L 1D L 1D W 
3D-5 2D L 1D W 2D L 1D W 1D L 
3D-6 2D L 1D L 2D L 1D L 1D W 
3D-7 2D L 1D L 1D L 1D W 1D L 
4D-1 2D L 1D L 1D W 1D L 1D W 
4D-2 2D L 1D L 1D W 1D W 1D L 
5D-1 3D W 5D L 2D L 1D L 1D W 
5D-2 2D W 1D L 1D W 1D W 2D L 
5D-3 2D W 5D L 5D L 1D W 1D L 
5D-4 2D L 1D L 1D W 1D W 1D L 
5D-5 2D L 1D L 1D W 1D W 2D L 
5D-6 2D W 5D L 2D L 1D W 1D L 
5D-7 2D L 1D W 2D W 5D L 2D L 
5D-8 2D L 1D L 1D L 1D W 1D L 
5D-9 2D L 1D W 3D W 5D L 2D L 
6D-1 3D L 2D W 5D L 2D W 5D W 
6D-2 3D W 5D L 2D L 1D L 1D W 
 
TABLE VI. ESTIMATED RANK AND SD FOR EACH PLAYER. 
Rank Player No. 
Estimated Rank SD 
BTM PSOM Proposed Method BTM PSOM 
Proposed 
Method 
1D 
1D-1 2.47 0.9 1.25 
0.24 0.082 0.13 
1D-2 1.06 0.89 1 
1D-3 1.17 1.08 1.25 
1D-4 1.16 0.91 1.75 
1D-5 1.18 1.10 1.25 
1D-6 1.17 1.11 1.25 
1D-7 1.74 1.52 1.33 
2D 
2D-1 2.49 2.3 2 
0.35 0.35 0.19 
2D-2 1.75 1.52 1.66 
2D-3 1.50 1.31 1.5 
2D-4 3.73 3.48 2.6 
2D-5 1.05 0.88 1.25 
2D-6 1.66 1.37 2.25 
3D 
3D-1 2.47 2.28 2.3 
0.55 0.61 0.57 
3D-2 1.17 1.07 1.25 
3D-3 1.67 1.44 1.3 
3D-4 2.04 1.82 1.66 
3D-5 2.46 2.27 1.66 
國科會補助計畫衍生研發成果推廣資料表
日期:2013/10/28
國科會補助計畫
計畫名稱: 運用志願型計算系統建構圍棋開局庫
計畫主持人: 顏士淨
計畫編號: 99-2221-E-259-009-MY3 學門領域: 人工智慧與仿生計算
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
所研發製作出的電腦對局程式，三年來都有參加國際性的比賽。在圍棋、象棋、
六子棋與暗棋等，繼續保持在世界前兩名的佳績。並且多次打敗職業棋士，建
立數項電腦圍棋的里程碑。 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
