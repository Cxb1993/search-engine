functions. We compared the 
performance of the Daubechies D4, D6, 
CDF , CDF and CDF scaling functions 
employed in the wavelet-based optical 
flow estimation. We estimated the 
optical flow from two synthetic and four 
real sequences. The average errors and 
computation time of the D4 are 19.85, 
34.23 degrees and 130.6, 156.8, 144.4, 
182.9, 238.1 and 181.5 seconds. The 
average errors and computation time of 
the D6 are 0.701, 5.136 degrees and 
153.5, 200.0, 163.0, 199.9, 256.3 and 
197.8 seconds. The average errors and 
computation time of the CDF 6/2(6) are 
0.633, 5.369 degrees and 149.7, 202.1, 
163.6, 198.8, 255.3 and 197.5 seconds. 
The average errors and computation 
time of the CDF 9/7(7) are 0.644, 5.073 
degrees and 180.9, 249.9, 180.1, 238.7, 
308.0 and 233.4 seconds. The average 
errors and computation time of the CDF 
9/7(9) are 0.661, 4.475 degrees and 
265.4, 318.5, 209.0, 253.1, 315.7 and 
250.5 seconds. When compared with the 
orthogonal bases, the biorthogonal bases 
have better performance. 
 
一. 緣由與目的 
   Optical flow estimation is an 
essential problem in motion analysis of 
video. It provides information needed 
for video object segmentation, object 
tracking and motion estimation etc. 
Optical flow is the distribution of 
apparent velocities of movement of 
brightness patterns in an image. Optical 
flow can arise from relative motion of 
objects and the viewer. Consequently, 
optical flow can give important 
information about the spatial 
arrangement of the objects viewed and 
the rate of change of this arrangement. 
Discontinuities in the optical flow can 
help in segmenting images into regions 
that correspond to objects. Attempts 
have been made to perform such 
segmentation using differences between 
successive image frames. Several papers 
address the problem of recovering the 
motions of objects relative to viewer 
from the optical flow. Optical flow 
estimation methods proposed in the 
literature can be classified into three 
categories: the gradient-based, the 
region-based matching and the 
spatiotemporal energy-based. 
The gradient-based approach is 
based on conservation of image intensity. 
It was first addressed by Horn and 
Schunck in 1980~81 [13]. The basic 
concept is based on the fact that when 
the three-dimensional (3-D) motion of 
corresponding object points is projected 
onto the two-dimensional (2-D) image 
plane the sum of the intensity of 2-D 
points is constant. This relation can be 
employed to relate the horizontal and 
vertical velocity of pixel in a first-order 
liner equation called the gradient 
constraint which together with the 
smooth constraint can be solved to 
obtain optical flow. The region-based 
matching approach is based on the 
conservation of local intensity 
distribution [3] [4] [15]. For every pixel 
 id x . Once the set of derivative order 
1,...., nd d  is decided, the function 
1 2
2
...
...
n
n
d d d
l l  can be calculated for all 
combinations of 1,...., nl l . 
The connection coefficients used in 
the computation of optical flow include 
   i ix x dx                 (3a) 
       x xi ix x dx              (3b) 
     ,i j i jx x x dx            (3c) 
 
Where      x x x
x
 



 and 
   i x x i   . It is obvious that 
0 1   and 0i  , for all 0i  , if the 
scaling function  x  is orthogonal. 
Now, we rewrite Eq. (1)  as 
2 2 2 2 2E= [ 2 2 2 )
x y t x y x t y t
I u I v I I I uv I I u I I v     
2 2 2 2( )]x y x yu u v v dxdy            (4) 
Suppose the image size is .M M  
Based on wavelet series expansion, the 
flow vector [ ( , ), ( , )]u x y v x y  can be 
expanded as 
   
1 1
,
0 0
, ,
M M
m n
m n
u x y u x m y n
 
 
    (5a) 
   
1 1
,
0 0
, ,
M M
m n
m n
v x y v x m y n
 
 
    (5b) 
where ,m nu  and ,m nv  are the expansion 
coefficients, and ( , )x m y n s    are 
the wavelet bases of subspace 0V  at 
resolution 0. Once the weighting 
coefficients ,m nu  and ,m nv  of ( , )u x y  
and ( , )v x y  are determined, the optical 
flow (OF) problem is solved. Thus, the 
OF problem is converted into process of 
determining the 22M  variables, ,m nu  
and ,m nv . Similarly 
   
1 1
2
,
0 0
, ,
M M
x m n
m n
I x y a x m y n
 
 
   (6a) 
   
1 1
2
,
0 0
, ,
M M
y m n
m n
I x y b x m y n
 
 
   (6b) 
   
1 1
2
,
0 0
, ,
M M
t m n
m n
I x y c x m y n
 
 
   (6c) 
   
1 1
,
0 0
, ,
M M
x y m n
m n
I I x y d x m y n
 
 
    
(6d) 
   
1 1
,
0 0
, ,
M M
x t m n
m n
I I x y e x m y n
 
 
    
                             (6e) 
   
1 1
,
0 0
, ,
M M
y t m n
m n
I I x y f x m y n
 
 
    
                             (6f) 
 
If we decompose the constraint 
function E in Eq. (4) into 
3 6 10
0 4 7
2i i i
i i i
E E E E
  
            (7) 
and use the connection coefficients, we 
have 
biothogonal bases of compactly support 
are the two most popular wavelets [6] 
[10]. For each family of 
orthogonal/symmetrical biothogonal 
bases, the order of approximation 
accuracy and regularity can be raised by 
increasing the length of the associated 
filters. However as the length of filters is 
increased the localization power 
becomes poorer and the computation 
load is also increased. Thus, 
approximation accuracy, regularity and 
filter length become a tradeoff and the 
design of a suitable wavelet basis for an 
application requires thorough 
understanding theory and practicing 
expertise from an engineer. 
The integration of wavelet theory 
and optical flow analysis can produce 
accurate optical flow estimation that is 
robust to noise and perspective 
deformation [2] [8] [23]. In this project, 
we investigated the performance of 
optical flow estimation in video object 
segmentation using both orthogonal and 
biorthogonal wavelets. We compared the 
performance of different wavelet 
functions in terms of computation time, 
accuracy. 
 
三. 研究結果 
   Five different scaling functions were 
used for comparison. The five scaling 
functions are D4, D6, CDF 6 /2(6), CDF 
9 /7(7) and CDF 9 /7(9). We used six 
standard image sequences to test the 
performance of the scaling functions. 
The first two are synthetic and the rest 
are real image sequences. The angular 
error between the correct velocity 
( , )c cu v and the estimated velocity 
( , )e eu v  is given by 
2 2 2 2
1
arccos
1 1
e c e c
error
e e c c
u u v v
u v u v

  
 
     
 
 
The average errors of error were 
calculated by neglecting a 3-pixel-wide 
boundary. The test images were 
presmoothed by a Gaussian filter 
with =1.4. 
The experimental results of 
150*150 Translating Tree image 
sequences calculated by using the five 
scaling functions are shown in Fig. 2. In 
Fig. 2, (a) shows the original image 
sequences; (b), (c), (d), (e) and (f) show 
the estimated optical flow results by 
using D4, D6, CDF 6 /2(6), CDF 9 /7(7) 
and CDF 9 /7(9)scaling function 
respectively without resolution reduction; 
(g), (h), (i), (j) and (k) show the 
corresponding estimated optical flow 
results with resolution reduction. Table 1 
summarizes the performance of the 
different scaling functions applied to 
Translating Tree in terms of average 
error and computation time. The four 
columns of Table 1 were the results 
obtained by using the 4th and 8th frame 
of the Translating Tree sequences as the 
test images. From the results shown in 
Table 1, it can be seen that the 
performance of the biorthogonal scaling 
functions are better than that of the 
orthogonal scaling functions. 
(d)                                  (i) 
 
(e)                                 (j) 
 
(f)                                (k) 
   Figure 2 The performance comparison of scaling functions by using “Translating 
Tree”. (a) A frame grabbed form the Translating Tree image sequences. (b) Estimated 
OF from D4. (g) OF with resolution reduction from D4. (c) Estimated OF from D6. (h) 
OF with resolution reduction from D6. (d) Estimated OF from CDF 6 /2(6). (i) OF 
with resolution reduction from CDF 6 /2(6) (e) Estimated OF from CDF 9 /7(7). (j) 
OF with resolution reduction from CDF 9 /7(7). (f) Estimated OF from CDF 9 /7(9). 
(k) OF with resolution reduction from CDF 9 /7(9). 
 
Table 1 Flow angle error and computation time for the Translating Tree. 
 
Scaling 
function   
D4  D6  6/2(6)  9/7(7)  9/7(9)  
Ave. Error 
(without 
resolution 
reduction) 
 
 
o19.8474  
 
 
 
o0.7011  
 
 
 
o0.6327  
 
 
 
0.6441  
 
 
 
o0.6612  
 
(b)          (g) 
 
(c)         (h) 
 
(d)          (i)  
 
(e)          (j) 
Computation,” Feb. 26, 1999. 
[3] J. L. Barron, D. J. Fleet and S. S. 
Beauchemin, “Performance of 
Optical Flow Techniques,” 
International Journal of Computer 
Vision 12, Page(s): 43 - 77, 1994. 
[4] P. J. Burt, C. Yen and X. Xu, 
“Multi-resolution Flow through 
Motion Analysis,” Proceeding of 
IEEE Computer Society Conference 
on Computer Vision and Pattern 
Recognition, Page(s): 246 – 252, 
1983. 
[5] C. H. Chen, Y. C. Chiou, M. K. Wu 
and Y. F. Li, “An Efficient Video 
Object Segmentation Algorithm 
Using Change Detection and 
Background Updating Technique,” 
International Conference on 
Systems and Signals, 2005. 
[6] A. Cohen, I. Daubechies and J. C. 
Feauveau, “Biorthogonal Bases of 
Compactly Supported Wavelets,” 
Communications on Pure and 
Applied Mathematics, Vol. 45, 
Page(s): 485 – 560, 1992.  
[7] L. F. Chen, J. C. Lin and H. Y. M. 
Liao, “Wavelet-Based Optical Flow 
Estimation,” Pattern Recognition, 
2000. Proceedings. 15th 
International Conference, Vol. 3, 
Page(s): 1056 – 1059, Sept. 2000. 
[8] L. F. Chen, H. Y. M. Liao and J. C. 
Lin, ”Wavelet-Based Optical Flow 
Estimation,” Circuits and Systems 
for Video Technology, IEEE 
Transactions, Vol. 12, No. 1, 
Page(s): 1 – 12, Jan. 2002. 
[9] I. Daubechies, Ten Lectures on 
Wavelets, SIAM, Philadelphia, 
Philadelphia: Society for Industrial 
and Applied Mathematics, 1992. 
[10] I. Daubechies, “Orthogonal Bases 
of Compactly Supported Wavelets,” 
Society for Industrial and Applied 
Mathematics, Vol. 24, No. 2, 
Page(s): 499 – 519, Mar. 1993.  
[11] A. Graps, “An Introduction to 
Wavelets,” IEEE Computational 
Science and Engineering, Vol. 2, 
No. 2, Page(s): 50-61, Jun. 1995. 
[12] R. C. Gonzalez and R. E. Woods., 
Digital Image Processing, 2nd ed., 
NJ: Prentice Hall, 2002.  
[13] B. K. P. Horn and B. G. Schunck, 
“Determining Optical Flow,” 
Artificial Intelligence, Vol. 17, 
Page(s): 185 - 203, 1981. 
[14] A. Latto, H. L. Resnikoff and E. 
Tenenbaum, Aware, Inc. “The 
Evaluation of Connection 
Coefficients of Compactly 
Supported Wavelets,” Aug. 1999.  
[15] S. H. Lai and B. C. Vemuri, 
“Robust and Efficient Algorithm 
for Optical Flow Computation,” 
Proceeding of IEEE International 
Conference on Computer Vision, 
Page(s): 455 – 460, 1995. 
[16] Weiping Li, Jens-Rainer 
Ohm,Mihaela van der Schaar, Hong 
Jiang, Shipeng Li, “The MPEG-4 
Video Standard Verification Model 
version 18.0,”ISO/IEC 
JTC1/SC29/WG 11 N3908, Jan. 
2001. 
無研發成果推廣資料 
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
國科會補助專題研究計畫成果報告自評表 
請就研究內容與原計畫相符程度、達成預期目標情況、研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）、是否適
合在學術期刊發表或申請專利、主要發現或其他有關價值等，作一綜合評估。
1. 請就研究內容與原計畫相符程度、達成預期目標情況作一綜合評估 
■達成目標 
□未達成目標（請說明，以 100字為限） 
□實驗失敗 
□因故實驗中斷 
□其他原因 
說明： 
2. 研究成果在學術期刊發表或申請專利等情形： 
論文：□已發表 ■未發表之文稿 □撰寫中 □無 
專利：□已獲得 □申請中 ■無 
技轉：□已技轉 □洽談中 ■無 
其他：（以 100字為限） 
3. 請依學術成就、技術創新、社會影響等方面，評估研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）（以
500字為限） 
本計畫開發-小波式光流估測演算法，可應用於視訊的物件切割上。 
