 研 究 摘  要 
 
 
本計畫係針對變電所（站）電力變壓器研製與建立一套資料收集與監測系統，此系
統的目的，在於收集與監測變壓器的電力參數(包含電壓、電流、實功與功因)、變壓器高低
壓側外殼振動模式、以及油中主要氣體總含量 TCG，即時通知運轉人員，其中並傳送資料供
操作運轉人員先行判讀，必要時安排專業人員前來進行油中氣體取樣與檢測分析，並利用檢
測分析結果的油中可燃性氣體成分的樣本資料，藉由本計畫所建立的多層支撐向量機網路模
型（Multi-Layer Support Vector Machine，SVM）診斷出發生故障的先期徵兆，以便進一步停
機進行相關維護程序，以有效降低變壓器維護成本，並期延長變壓器運轉壽命與提升變電所
之供電可靠度。最後本計畫係以高雄港務局第五貨櫃中心變電站之變壓器進行實測與資料收
集，並將蒐集所得油中氣體成分資料，佐以 IEC 60599 資料庫及台電歷年來之故障案例樣本
資料，以所提之多層支撐向量機網路模型及徑向基底函數（Radial Basis Function，RBF）進
行實際案例診斷，驗證系統之可用性，藉以建立整合式之監視系統，以有效監測出變壓器可
能的故障先期徵兆，並及早發現潛在之故障。 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
應用多層式支撐向量機分類器之即時電力變壓器溶解氣體分析故障診斷器之
研究 
 
計畫編號：NSC 97-2221-E-151-058 
執行期間：九十六年八月一日到九十七年七月三十一日 
主持人：卓明遠 
 
 
Abstract 
 
In this study, we propose a method of using an 
Artificial Neural Network (ANN) and multi-layer 
Support Vector Machines (SVM) with features and RBF 
kernel parameters selection to predict incipient fault of 
power transformers. A clonal selection algorithm 
encoding technique is applied to improve the accuracy 
of classification which removed redundant input 
features that may be confusing the classifier. 
Experiments demonstrated our method may improve 
the test successful rate to near perfect, and with very 
small computation time. 
  
1. Introduction 
 
Power transformers are definitely vital devices in 
power systems. Hence they need to be carefully 
monitored and fault alarms must be given as early as 
possible. The most popular method for detecting 
incipient faults was known as the dissolved gas 
analysis (DGA) [1]. According to IEC 567 [2], 
degradations of the transformer oil and insulating 
materials produce gases such as hydrogen (H2), oxygen 
(O2), nitrogen (N2), methane (CH4), ethylene (C2H4), 
acetylene (C2H2), ethane (C2H6), carbon dioxide (CO2), 
and carbon monoxide (CO), they all can be detected 
from a DGA examination. Existence of these gases, 
meaning corona or partial discharge, thermal heating 
and arcing may happen. The energy dissipation is least 
in corona or partial discharge, medium in thermal 
heating, and highest in arcing [3].  
Various fault diagnosis techniques have been 
developed, including the conventional key gas method, 
ratio-based method. The shortcomings of the key gas 
and ratio methods are, their fault diagnosis using DGA 
data may vary from utility to utility hence no general 
mathematical formulation can be utilized. 
Recently many artificial intelligence (AI) methods 
have been introduced, namely the expert system (ES), 
fuzzy logic (FL) and Artificial Neural Network (ANN). 
For ES and FL approaches information such as 
influence of transformer size, volume of oil, gassing 
rates and past diagnosis result are usually needed to 
establish DGA standards for their decision-making 
system [4]. However, difficulty of acquiring such 
knowledge and maintaining an updated database are 
their intrinsic shortcomings. Traditional ANN methods 
overcome the shortcomings of the expert system by 
acquiring experience from training data. However, its 
weaknesses include the need for a large number of 
controlling parameters, difficulty in obtaining a stable 
solution and the danger of over-fitting. Combinations 
of these methods have been attempted to reduce their 
individual shortcoming effects and are quite promising. 
This Paper proposes a method to improve the 
performance of Support Vector Machines (SVM) and 
ANN for fault diagnosis of power transformers by a 
clonal selection algorithm (CSA). The idea of SVM 
was first proposed by Vapnik of the AT&T Bell 
Laboratories [5]. It combines the structural risk 
minimization (SRM) principle and the statistical 
machine learning theory (SLT), risk minimization was 
then carried out on a nested set of separating 
hyperplanes. SVM was highly successful for solving 
classification and functional regression in many 
applications [6]. It is especially powerful for nonlinear 
problems with high dimensional but small samples. It 
provides a unique solution and is a strongly regularized, 
particularly appropriate for ill-posed problems. 
The CSA is based on the clonal selection principle 
of biology, which an adaptive immune system 
responds to the invasion of a pathogenic 
microorganism, called an antigen (Ag). When an 
antigen invades our body, a subset of the immune cells 
recognizes it through a complementary match, hence 
begins its selection and reproduction. The cellular 
reproduction is asexual (mitosis or cloning). During 
reproduction, the clone suffers a hypermutation 
(mutation with high rates) process that alters their 
shapes in relation to the parental cells, possibly  
For SVM, it becomes a very complicated non-linear 
global optimization problem. In general the number of 
support vectors shall be minimized if bigger margin is 
chosen first. Lee and Lin [10] using all training 
samples to execute an exhaustive search for the 
optimal hyper parameter. It indeed minimized the 
expectation test of the leave-one-out (loo) error rate. 
The shortcoming is it required extensive computing 
time. To overcome this, we may take the existing VC 
theoretical bound on the generalization error for 
SVM’s instead of the loo cross-validation.  
The classical Lagrangian duality enables the primal 
problem to be transformed into the equivalent dual 
problem as follows [2]:  
2 1
1 , 12max ( ) ( , )
n n
i i i j i j i j i jW y y k x xα α α α α= == −∑ ∑ (1) 
subject to 0≤αi for all 1, ,i n= K  and 1 0ni i iyα= =∑   
where k(.) is the kernel function and RBF is our choice. 
The decision function is: 
1
( ) ( . ) ,
l
i i i
i
f y k bα
=
= +∑x x x  and ( ( )).y sign f= x
  
(2) 
where αl, α2,...,αi are the Lagrange multipliers. Each 
sample has corresponding αi, i=1,…,l. Only a small 
fraction of αi are nonzero. The corresponding pairs of 
αi entries are known as support vectors and they fully 
define the decision function [3]. 
Consider the following loss function 
0 if  ( , )
( , ( , ))
1 if  ( , )
y f
L y f
y f
αα α
=⎧= ⎨ ≠⎩
x
x
x
               (3) 
Due to the probability distribution of expected risk 
functional is unknown; we may replace it by an 
empirical risk functional 
1
1( ) ( , ( , ))
l
emp i i
i
R L y f
l
α α
=
= ∑ x                    (4) 
For Remp(α) to be a close approximate of the expected 
risk, Vapnik presented a bound theorem [11]. For 
probability at least 1-η (0≤η≤1), the inequality must 
hold true for all functions  
4 ( )
( ) ( ) 1 1
2
emp
emp
R
R R
αεα α ε
⎡ ⎤≤ + + +⎢ ⎥⎢ ⎥⎣ ⎦
           (5) 
where ε = (4/l)(h(ln(2l/h)+1-lnη) and h is the VC 
dimension of the set of functions f(x,α), α∈Λ. 
From (5), we see that minimizing of the two terms 
on the right-hand side of (5) at the same time in turns 
minimizing of the expected risk R(α). The first term 
Remp(α) is minimized by the learning process, the 
second term varies with the VC dimension h and the 
number of examples l. hence the smaller the VC 
dimension h and the larger the number of examples l, 
the smaller the value of the second term. 
In the features extraction phase, we are concerned 
not only from the basic gas ratios of DGA data, but 
also their mean (µ); root mean square value (rms), 
variance (σ2); and other higher order central moments: 
{[ ] }ni
n n
E y µγ σ
−= , n = 1,10,             (6) 
where E represents the expected value of the function. 
Total numbers of derived features are 36. We randomly 
extracted instances for learning sets, validation sets and 
test sets for corresponding phases. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Fig.2. Block diagram of the clonal selection algorithm 
 
3. Experimental results  
 
Two sets of DGA data were compiled for the 
feasibility study of our proposed method. First data set 
consist 134 gas records from IEC TC10 Database 
which have been discriminated into 6 classes based on 
IEC 60599 described values corresponding to different 
actual conditions [12]. The second data set contained 
635 historical dissolved gas records from different 
transformers of the Taipower Company.  
 
3.1. Performance for IEC TC 10 dataset  
 
Classification results are presented for straight 
ANN’s and SVM’s with/without features and 
parameter selection. For each case of straight ANN, the 
number of neurons in the hidden layer was kept at 24; 
for straight SVM’s, a constant width (σ) of 0.5 and 
tradeoff regularization parameter (C) of 100 was used. 
These values were chosen as the basis of initial trials of 
trainings.  
The left part of Table 1 shows the classification 
results for straight ANN’s and SVM’s with the first 
IEC TC 10 dataset. In each case all features from the 
DGA signals are without CSA features and parameters 
optimization. The test success of straight ANN’s was 
83.6% and 90.4% for SVM’s.  In the right part of 
C1
Pi
M
Select 
Nd
Reselect
1
2
3
4
5
6
C
Pr
P
Clone
Maturate
