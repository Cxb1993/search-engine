users can accept collaborating work with a robot in an office 
environment as well as general users‘ expectation of the robot’s 
ability. The second sub-project developed an office delivery robot, 
mainly focusing on its visual servoing capabilities to carry out three 
kinds of services, namely, ’serve tea’, ’people following’ 
and ’document delivery’. The third sub-project proposed a learning 
collision-free navigation in static environments could be 
accomplished using only instance-based examples without using 
global information such as the map and the goal location. The fifth 
sub-project investigated pitch patterning and durational cues of 
emotional speech in Taiwan Mandarin. Acted connected speech in 
anger, joy, sorrow, fear and neutral emotions were recorded for 
analyses. An emotion model based on Hidden Markov Model is 
proposed in the sixth sub-project to simulate the dynamic processes 
of emotional self-regulation and emotional transference under the 
influence of the same stimuli arouse by the result of emotional 
speech recognition. 
Carrying out this integrated project could effectively combine the 
development, manufacture, design, and application of robots for 
technical manpower, and will reach the goals as technological 
communicating and resource sharing. 
 
一、前言： 
隨著已開發國家少子化及高齡化的現象日趨嚴重，各國皆期望藉由研發機器人技術以解
決這社會現象所帶來的衍生問題，也漸漸地將服務型機器人定為研發重心，市場預估在不久
的將來服務型機器人市場的總產值將超過工業用機器人，而智慧型機器人市場也將大幅成長。
根據各國機器人產業調查資料顯示，預估到了 2015 年智慧型機器人市場產值將突破千億美
元。 
一般而言，智慧型機器人可分為工業型及服務型機器人兩類，工業型機器人自 1970 年代
便開始發展，大多運用於組裝、焊接噴漆、加工及搬運等，以取代人類在危險的環境下和重
覆性高的工作。目前工業型機器人技術已漸趨成熟，未來工業型用機器人將簡化產品功能，
朝向單一化功能產品發展，降低機器人製造成本，提高廠商使用意願。目前工業型機器人以
電子、平面顯示器、半導體等無塵室用機器人成長最快。 
智慧型機器人涉及的技術十分多元，包括移動平台、機電控制、電源技術、系統整合技
術、造型設計、電腦工程、人工智慧、感測技術、精密機械等，其相關的產業亦涵蓋電機、
機械、資訊、通訊、電子、能源及材料，為一高度整合型產業。過去智慧型機器人的發展受
限於技術，因此沒有突破性的發展，應用也只局限在工業型機器人，但從 1990年代起，微電
子科技、電腦科技、生物科技、材料技術、通訊和自動化機械技術等相關科技快速發展，提
供了機器人所需的基礎技術。使智慧型機器人的發展越來越迅速，進而帶動了相關的研究領
域，機器人的應用場合不再局限於工廠、軍事、實驗室等，而是更多元的應用場合，如家庭、
醫院、公共場所等，因此機器人系統之研究已逐漸演進至一個嶄新的世代，如何讓機器人成
功的融入在人類的生活環境，並服務與滿足人類各式各樣的需求，已是各個先進國家和國際
大廠積極投入的研發項目之一，例如日本的機器人造鎮計畫、韓國的家用機器人普及計畫以
及國際大廠 Google、Intel和 Microsoft共同投資機器人相關研發計畫等。 
二、研究目的 
本計畫的研究目的為發展一套智慧辦公環境之服務型機器人族系統(如圖 1 所示)，其中
差遣遞物機器人則提供一般上班員工所需的差遣服務，如物品遞送、茶點服務、公文遞送等
服務，並進一步與上班員工和諧共處；多功能秘書機器人則提供主管所需的秘書服務，如行
程規劃、開會提醒、移動式文書列印等；不同功能屬性之機器人服務任務設計皆參考一般職
  
圖 2 日本 Sumihisa Iwashita 和 Tsutomu Asada 所研發的服務型機器人概念與雛型 
  
                        (a)                                (b) 
圖 3 辦公室機器人: (a)Jijo-2 (b)Robovie-IV 
Hüttenrauch 等人[4]開發出適用於辦公環境之遞送機器人 Cero，其載具由 Nomadic 
Technologies 公司出產，Cero 能協助在辦公室行動不便的人傳遞所需的物品，Cero 的頭頂配
有轉動小人模型可呈現不同動作，來代表 Cero 的移動方向，如圖 4 所示。除此之外，Cero
亦兼具一般辦公室機器人所需之聽與播放之功能，並可由 PDA 遠端搖控。 
活語義，Hitachi 公司希望在不久的將來能讓 Emiew 2 在辦公室等場所中負責引導來客、巡邏
監視或遞送文件等工作。 
  
      (a)                              (b) 
圖 6 日本 Hitachi 所開發的第二代機器人 Emiew 2：(a)站立與跪姿 (b)行進中 
由於目前辦公室機器人造價仍相當昂貴，圖 5 中的 ASIMO 和 Wakamaru 及圖 6 的 Emiew 2
可說是目前日本研發中可用於辦公室之機器人的代表，除有和藹可親、值得信賴的外觀外，
系統的穩定性、對指令的達成效率等，是商業用途不可忽視的。 
 
圖 7 Fujitsu 所開發的辦公室傳遞物品機器人 
 
最近，日本 Fujitsu 公司所開發的辨公室傳遞機器人[8]如圖 7 所示，配備有立體視覺、雷
射測距儀、增強型同步定位與地圖建置，可精確地定位在 10 公分以內，中間為置物層共可乘
  位於美國加州矽谷的一家科技公司 Anybots，最近開發出一台遠程出席機器人 QA[10]如
圖 9 所示，其配有 802.11g 無線網路、500 萬畫素攝影機、夜視燈、7 吋 LCD 螢幕等，在家
或公司透過 QA 便可以輕易地在辦公室行走移動，並與他人進行視訊會議，為傳統視訊會議
室提出了一個新的解決方案。 
四、研究方法 
總計畫第一年之計畫目標包括：探討工作場域中導入智慧型機器人之使用者需求、探討
機器人於工作職場角色定位、定義機器人與人之角色關係及提出不同功能之機器人角色與需
求分析。第一年以調查研究(survey)等方法針對工作環境的需求與機器人角色定位進行研究，
協助各子計畫定義各自的機器人角色及機器人群內互動形式與人與機器人群互動形式，做為
各子計畫機器人發展的基礎。為了解辦公室環境中，工作職員對智慧型機器人的看法。本研
究以問卷調查研究的方式，探索職場員工對辦公室環境服務型智慧機器人在服務、外型、與
人互動三個方向的需求、偏好及同意程度。除此之外，試圖在眾多不同的工作屬性中，區分
公關、社交及差遣遞物型機器人的需求差異比較。問卷分為兩部分，第一部分探討整體上對
辦公室機器人的看法；第二部分針對三種類型機器人，找出其差異的各項需求。結果以描述
性統計方式進行分析及比較。受訪者背景：29位來自台大智慧生活科技整合與創新研究中心
的工作成員。年齡分布 19~45 歲，28~35 歲占大多數(45%)。男女生幾乎各占一半(52%、
48%)。工作中的位階，大部分為基層員工(82%)，即研究助理。服務功能：由表一可知，秘
書型機器人需要事務性服務、文書服務、資訊服務；公關型機器人，認為需要多媒體服務、
社交服務 ；差遣遞物機器人最需要文書服務、勞務服務、遙控服務 。外型：由表二可知，
秘書及公關型多強調像女性、體型嬌小、像人且以肢體變化、有人聲。秘書與公關唯一差別
在於表情變化的需求，公關是被要求要有表情變化的；差遣遞物型強調像男性、體型高大壯
碩、像機器且抽像、機械聲。與人互動：由表三可知，秘書及差遣遞物型強調情緒穩定、合
作、謹慎；公關機器人強調情緒穩定、開放、外向。對於秘書和公關，亦強調有判斷能力及
情緒表達能力。本研究結果發現，針對不同類型的機器人，在功能、外型、互動模式中，存
在各自不同的需求及偏好差異。但在某些向度及程度上，亦有重疊之處。在此初探調查中，
可以了解對未來辦公室中智慧機器人可能發展的方向，並由此結果，深入職場環境中，進行
進一步的探索分析及需求調查。 
 
 
五、各分項計畫成果簡述 
新世代辦公大樓之「智慧型服務機器人族」(1/3) 
子計畫一：辦公室多功能智慧型秘書機器人 (1/3) 
主  持  人：傅立成 教授    台大電機系、資工系 
共同主持人：岳修平 教授    台大生傳系 
Abstract: 
This paper presents our new intelligent interactive robot, which is constructed to eagerly provide 
multi-functional services in an office environment. We investigate the conditions under which users 
can accept collaborating work with a robot in an office environment as well as general users' 
expectation of the robot’s ability. Besides, in order to endow a full interactive capability of our 
robots for realizing so-called human-robot interaction (HRI), there are two kinds of cameras to 
accomplish human detection/tracking and object detection/recognition. In addition to cameras, there 
are two kinds of lasers mounted in the front and at the back of the robot to detect and track human 
legs. Not only by these sensors, human interact with the robot also by some natural way, such as 
touching the interface screen and talking with the robot through microphone. Last but not the least, 
since the office environment is dynamic, this paper proposes a context-aware navigation method to 
deal with some situations which may take place in the office environment. For overall situation, we 
design a finite state machine (FSM) approach to enable the robot to solve the emergent tasks and to 
accommodate human users in real office environment. Finally, the effectiveness of the proposed 
work is tested and validated by some of experiments. 
 
Results of Projects: 
 Intelligent Interactive Robot 
The appearance, as shown as in Fig. 10 , and specification of our office robot is briefly described 
in this section. The design philosophy is to build an autonomous mobile robot with various 
functions so that it can exhibit the capability for interacting with human. There are two computers 
employed in charge all of the computational tasks, and they communicate with each other through a 
local area network. The computational tasks of the office robot are divided into low and high levels. 
PC-1 is employed for low level computations, taking care of such as motor motion and intelligent 
navigation, whereas PC-2 is employed for high level computations, handling e.g. human-robot 
interaction, speech recognition, vision, etc. Table 4 lists various specifications of our office robot. 
 Fig. 11. Finite state machine of the office robot 
 Human Guiding and Following 
Fig. 12 shows the guiding mode, the robot will stop to wait when it detects no human behind it.  
On the other hand, Fig. 13 shows the situation where the human is in front of the robot, and 
therefore it can follow human to anywhere and keep a comfortable distance between human and 
robot when human stop in front of the robot. 
   
t=1 t=4 t=7 
   
t=10 t=13 t=15 
Fig. 12. The snapshots of human guiding. 
   
t=1 t=3 t=6 
   
t=6 t=8 t=10 
Fig. 13. The snapshots of human following. 
 
 
 
use of the Visual C++ programming tool and the OpenCV image processing library. There is also a 
wireless Ethernet module on the SBC reserved for multi-robot communication. 
For the subsequent experiments, the visual servo system is required to grabs digital color images 
of 320x240 pixels in a 30Hz frame rate, performs the visual tracking task in real-time (i.e. within 
every 33ms period), and sends the servo command to the motion control module via the parallel I/O 
interface. 
 
 
Fig. 14 System setup of the office delivery robot Fig. 15 SPCE061A EMU board developed by 
SUNPLUS Technology Co., Ltd. 
 
 Hand and Head Gesture System 
Usually  interactions  from  the  vocal  modality  alone can not fully express one’s 
intention; therefore, we try to implement additional modalities of human-robot interactions  
that  help resolve the ambiguity  and  express friendly. For example, when people interact 
with each other, it is natural to indicate their agreement, acknowledgment, or disinterest simply 
by hand and head gestures. On the other hand, people use the gestures together with verbal 
expressions to properly convey their intentions and emotional states. Body signs from gestures 
reveal rich information to indicate one’s emotional state and intentions. 
To realize the hand and head gestures, we first mount an animated head system on the top of 
the robot body and two seven-degree-of-freedom manipulators on the shoulder. The animated 
head is a fully assembled mechanical construction with three movable parts, including eyes, 
mouth, and neck, as shown in Fig. 16. These movable parts are controlled by  mini-servo 
motors to produce several head gestures such as “head  shake”, “head  nod”,  and ”eyes  
glance”, which can supplement additional information accompanying with a vocal 
communication. We utilized the Parallax servo controller, as shown in Fig. 17, which can 
新世代辦公大樓之「智慧型服務機器人族」(1/3) 
子計畫三：學習型辦公室社交招待機器人 (1/3) 
主  持  人：王傑智 副教授  台大資工系 
Abstract： 
While collision-free navigation could be done using traditional rule-based approaches, it 
becomes more attractive to use learning from demonstration (LfD) approaches to ease the burden of 
tedious coding and parameter tuning procedures recently. Given the world model, the starting pose, 
and the goal pose, a path could be learned using trajectory-based LfD approaches. In this paper, we 
argue that learning collision-free navigation in static environments could be accomplished using only 
instance-based examples without using global information such as the map and the goal location. The 
experimental results using a real robot with a laser scanner demonstrated that the low level control 
commands for collision-free navigation are learnable from demonstration using the proposed 
approach. 
 
Results of Projects： 
 The Learning to Search (LEARCH) Algorithm 
Recall that the goal is to identify a mapping function from features of any given state to costs 
such that the resulting minimum cost plans capture well the demonstrated behavior. To get a 
minimum cost path, it is essential to get the cost value on each state in the map as  iFs  which 
could be generated by querying the feature function F to get the features in a given state i and 
applied it with the learned costmap s. The costmap is then further modified to the exponential form 
as  iFse  to create a hypothesis space of cost functions with substantially higher dynamic ranges for a 
given set of features and fulfill the requirement of many planning algorithms with strictly positive 
costs in order to ensure the existence of an admissible heuristic. 
The procedure of the LEARCH algorithm is presented in Algorithm 1. The log-costmap is 
initialized as zero. Then the loss function and feature function are used to compute the 
loss-augmented costmap. Here the loss function is used to perform margin-maximization like the 
similar interpretation in support vector machine [11] and could be easily defined by the users. The 
feature function is used to provide the observed features at a given state. A planner in the learner 
then plans a path using the loss-augmented costmap. According to the current planned and example 
paths, the learner generates positive and negative examples and then further trains a regressor or 
 
Fig. 21. One of the demonstrations in the navigation environment. The ambiguous regions within the green rectangles 
would cause the poor performance when testing. 
 
  
(a) The laser scans in the bottom ambiguous region in Fig. 
21. The left and right passages with respect to the robot may 
cause the ambiguity in control policy. The control command 
is turning left in the training data. 
(b) The laser scans in the top ambiguous region in Fig. 21. 
The center and right passages with respect to the robot may 
cause the ambiguity in control policy. The control command 
is turning right in the training data. 
Fig. 22. The blue dots are the corresponding laser scans in the ambiguous regions. The cross in red color indicates the 
robot position. 
  
(a) The overall generated path. The robot exchanged the 
control commands between trying to pass through the 
center passage and the right passage whereas resulted in 
hitting the obstacles. 
(b) A closer look at the end of the generated path. The 
direction of the robot is changed obviously at the final 
few steps before hitting the obstacle. 
Fig. 23. The result when testing with the ambiguous environment. 
 
 
 Speech Rate 
Fig. 25 shows the results of speech rate. As can be seen, sorrow had the slowest speech rate 
among all the emotions, and the speech rate was negatively correlated with strength. On the other 
hand, speech rates were in a positive correlation with anger and joy. An emotion (4) ×strength (2) 
two-way ANOVA was conducted to test the above observations. Results showed that only the main 
effect of emotion was significant  [F(3,175) = 4.81, p< .01, η2=.08]. Post-hoc tests with LSD 
adjustments showed that speech rates were significantly slower in sorrow than in anger, joy, and 
neutral (p < .01). No significant differences were found between fear and the other emotion 
categories, and no significant effects involving strength were found. 
 
Fig. 25. Results of speech rate for each emotion 
 Pitch Range 
Figure 3 shows the results of pitch range. As can be seen, the overall pitch range and register 
of females were significantly larger and higher than those of males. Comparing across different 
emotions, one can see that the pitch register was the highest in anger, followed by joy, and it was 
the lowest in sorrow, fear, and neutral. Comparing across different strengths, one can see that there 
was a positive correlation in anger, which is mainly resulting from higher maximum 𝐹0 .For joy, 
there was no obvious correlation between pitch range and emotion strength. For sorrow, male  
speakers showed a raised pitch register in the strong version, while female speakers expanded pitch 
range by raising maximum F 0and lowering minimum 𝐹0 . Three emotion (4) × strength (2) × 
gender (2) three-way ANOVAs were conducted on pitch range, maximum 𝐹0 , and minimum 𝐹0 
to verify the above observations. For pitch range, results showed that there was a significant main 
effect of gender [F(1, 168) = 88.65, p < .01, η2= .35]. The interaction effect of emotion × gender 
新世代辦公大樓之「智慧型服務機器人族」(1/3) 
子計畫五：機器人與人類工作環境共生模式之分析與設計 (1/3) 
主  持  人：連豊力 副教授  台大電機系 
Abstract： 
Artificial emotion model is considered as a key factor to achieve a more effective and 
believable human-robot interaction. As the speech communication plays an essential part of our 
daily life, the utilization of the emotional speech is expected to make human-robot communication 
smooth. In this paper, an emotion model based on Hidden Markov Model is proposed to simulate 
the dynamic processes of emotional self-regulation and emotional transference under the influence 
of the same stimuli arouse by the result of emotional speech recognition. In addition, by selecting 
the parameters of the model, the models of optimistic and pessimistic personality traits are also built. 
In order to maintain the consistency of the personality traits, the personality models under the 
influence of all the combinations of recognition error are considered and analyzed to figure out the 
relationship with model parameters through a series of simulation. 
 
Results of Projects： 
 Emotional Speech Recognition 
Emotional speech recognition has been developed for decades with more and more interest. 
The classification of emotional speech is the first important task of emotion recognition, and it 
can be widely used in variety of fields for application. The typical process of emotional speech 
classification is depicted in Fig. 27. The speech samples used in this paper are obtained from 
Berlin database. Several typical acoustic features based on previous researches are selected to 
proceed with feature extraction. And then, the best suitable features are selected by WEKA 
(Waikato Environment for Knowledge Analysis) in [13] which is a machine learning software 
written in Java as description of emotional speech to analyze the characteristics of emotions in 
speech. Finally, the selected features are also classified by WEKA to present certain kinds of 
emotion.  
near 1 in correspondence with the change of T , while ( )Tp  of other emotion states decreases from 
corresponding emotion state initial probability distribution to near 0. The rule of change in emotion 
state probability distribution satisfies the hypothesis that one kind of stimulus arouses only one 
corresponding kind of emotion state. 
 
Figure 29: The change curve of emotion state probability distribution in correspondence with the change of θ 
It can be seen that the maximum change rate of 
 T
ip  is increasing when parameter   is 
increasing. In the meanwhile, the linear change region will become narrower and the maximum 
value of T  will become smaller. That is to say, with greater value of  , the reaction rate of 
emotion to stimulus is faster. Therefore, parameter   can be used to adjust the response rate of 
emotion to stimulus. 
Figure 30 shows the change curve of emotion intensity of emotion state 1 ( )
1
TP  in 
correspondence with different initial probability distribution  . The relevant parameters are as 
follows: 1m  , 1.06k  , 12  ,  * 1 3 1 3 1 3  . 
 
Fig. 30: The change curve of emotion intensity corresponds to the change of T, while the limit probability is the same, 
but the initial probability distribution of personality transfer matrix is different. 
It can be seen that emotion intensity ( )
1
TP  is increasing in correspondence with the changes of 
T  under the influence of stimulation. When ( )10 0.45
TP  , the change of emotion intensity 
seems to grow linearly; while when ( )
1 0.45
TP  , the change of emotion intensity becomes very 
slow. As a whole, the change rate of ( )
1
TP  is similar in different initial probability distribution  . 
That is to say, initial probability distribution only provides different value of emotion intensity in 
transfer process of emotion state. 
0 10 20 30 40 50 60
-0.1
-0.08
-0.06
-0.04
-0.02
0
0.02
0.04
0.06
0.08
0.1
T

p
i(T
)
 
 
=7
=12
=18
0 5 10 15 20 25 30 35 40 45 50 55 60
-0.4
-0.3
-0.2
-0.1
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
T
P
1

(T
)
 
 
=[4/12 4/12 4/12]
=[6/12 3/12 3/12]
=[8/12 2/12 2/12]
=[9.4/12 1.3/12 1.3/12]
=[10/12 1/12 1/12]
=[3/12 4.5/12 4.5/12]
=[2/12 5/12 5/12]
=[1/12 5.5/12 5.5/12]
=[0.4/12 5.8/12 5.8/12]
國科會補助計畫衍生研發成果推廣資料表
日期:2011/10/31
國科會補助計畫
計畫名稱: 總計畫：新世代辦公大樓之「智慧型服務機器人族」
計畫主持人: 傅立成
計畫編號: 99-2221-E-002-190- 學門領域: 智慧型機器人
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
