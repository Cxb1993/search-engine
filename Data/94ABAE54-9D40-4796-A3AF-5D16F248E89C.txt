2) 我們的實驗結果顯示在系統
CPU使用率不管是在接近0%，
甚至於趨近於100%的環境下，
我們的負載平衡方法都能達到
很好的效果。 
3) LAPoG方法可以監控每一節點
電腦的workload並且可以根據
狀況自己調整平衡參數來應付
負載環境的改變。 
    在接下來的章節部份，第二章介
紹在實驗設計中使用的Benchmark以
及使用的監控軟體以及跟過去提出的
其他負載平衡方法。第三章介紹
LAPoG方法的架構，以及其演算法。
第四章模擬以及實驗結果，描述如何
產生workload進行分配，以及以實驗証
明LAPoG負載平衡方法的效能，最後
第五章為結論以及未來工作。  
 
2.背景 
 
2.1 Grid Benchmark 
 
NAS Grid Benchmarks (NGB) [15]
是從 NAS Parallel Benchmarks (NPB)演
化而來，NGB 主要由四個主要的程式所
組成，分別是 Embarrassingly Distributed 
(ED)、Helical Chain (HC)、 Visualization 
Pipeline (VP) 以 及 Mixed Bag 
(MB)[15]，每個程式根據運算時間的長
短可細分成 S、 W、A、B 四種 problem 
size。  
ED problem 為多次執行相同的程
式，如圖一所示，在 ED 架構中，SP 會
根據 problem size 的大小而被執行多
次，並且自具有獨立性。HC problem 此
程式則是重複執行一系列包含 BT，SP，
以及 LU 的程式。執行的順序具有相依
性，並一個執行完的結果丟給後一個電
腦繼續執行，後面的工作必須等待前一
個工作的完成。VP problem 則是摸擬
pipeline 的程序，MB problem 則是與 VP
相似，但它是不對稱的。 
圖一 Data flow graph of NGB 
 
2.2 Ganglia 
     
Ganglia [16]監控軟體是一個主要
用來監控系統性能的軟體，它可監控
如: CPU、記憶體、硬碟使用率、I/O
負載、網路流量等等狀況，通過如圖
二的曲線很容易看到每個節點的工作
狀態，對於系統調整，或系統資源的
分配，對於提高系統整體的性能可以
發揮重要的作用。 
Ganglia 是分散式的監控系統，有
兩個 Daemon，分別是客戶端 Ganglia 
Monitoring Daemon (gmond)和服務端
Ganglia Meta Daemon (gmetad)。 
 
 
 
 
           圖二 Ganglia 
1) Grid Information: 在客戶端節點
電腦收集到的各節點系統資訊，
將來傳遞給主控端的電腦做記
錄，成為負載平衡的最重要資訊
來源。  
2) LEG: 我們所提出的方法是根據
歴史資料產生預測值來調整負載
平衡的參數，歷史的資料以及各
節點的負載值由 Grid Information
搜集資訊過來。 
3) DMTT: 在負載平衡的決策機制
以及工作傳遞機制，則是由 LEG
產生的預測值來調整各節點負載
平衡的順序，再根據負載值高低
分配工作。 
 
3.1 Grid Information  
 
在我們的動態負載平衡機制中，
必須要不斷的更新各格網節點的負載
值資訊，才能產生準確的預測值來估
計各節點間的運算效能。如圖六所
示，我們可以把整個執行環境劃分成
兩部份，一個是 master 電腦，一個是
slave 電腦群組，在執行 LAPoG 的環境
下，每一個 slave 群組裡的格網電腦(參
數設為 nSG )，會將每一次工作期間的
負載值，包含 CPU 使用率以及工作完
成 時 間 回 報 給 master 格 網 電 腦
( ( )masterG )。 
( )masterG 電腦最主要的工作就是收
集各 slave 節點回報的負載值，統一記
錄在資料庫中，成為之後負載平衡程
式用來計算出預測值的重要歷史數
據，並且也可監控各 slave 節點電腦的
狀況。 
為了方便監控系統中各電腦的系
統狀況及負載情形，我們安裝了
Ganglia 軟體，透過 Ganglia 我們除了
可以在網路上透過網頁介面監看各電
腦的狀況外，我們的 LAPoG 負載平衡
程式更可以直接從 Ganglia 產生的
XML 文件中取得我們程式中想獲得負
載值，包含各電腦的 CPU 使用率。 
 
St
ate
 in
for
ma
tio
n
Send task
圖六 LAPoG 的集中式負載平衡方法 
  
 
3.2 LEG Algorithm                                  
 
在 LEG 演算中，主要透過週期性
的從 Grid Information 中取得歷史資料
來產生新的負載預測值。 
LAPoG 方法中最主要的決策機制
是透過預測值來預測未的負載值，計
算預測值的公式如下所示: 
1
( )
( )
m
n
i
n
T SG
P SG
m


……………. (1) 
在這 ( )nP SG 代表由過去的資料計
算出來的預測值，預測值包含 CPU 的
使用率以及每一工作預計所需耗費的
時間。 ( )nT SG  代表每一 slave 電腦的
負載值，記錄每一次工作耗費的時
間。而系統的負載值 ( totalL ) 則記錄
slave 電腦的 CPU 使用率。m  代表我
們記錄 totalL 的資料筆數，在 本研究
中，我們設定m 為 10。因此， ( )masterG
根據每一個 slave電腦過去的每十筆的
運算資料，系統就會更新新的預測
值，來預測每一 slave 電腦的效能。 
在程式上，我們以 java 語言來編
寫演算法程式，每一筆計算出來的預
測值則以 excel 格式儲存，程式的虛擬
碼如下所示: 
________________________________ 
do  
 1. ( )masterG gather ( )nT SG  from slave 
grid node. 
表一 硬體配備 
 
相同 CPU 使用率的情況下，各電腦運
算效能還是會有所差異，這是因為各
電腦安裝的軟體以及環境因素所影
響。  
在執行 LAPoG 負載平衡測試，首
先我們先在低負載的環境下進行測
試，我們將各 slave 格網電腦 CPU 負
載值控制在 0~20%的條件下進行 NGB 
benchmark 測試，如圖八所示，我們透
過 NGB 每一次分配五個 task 出去，再
分別經過 LAPoG 方法以及 RR、RD 機
制到各 slave 電腦執行，記錄十次工作
分配後所耗費的整體平均時間。可以
觀察到我們提出的 LAPoG 方法比 RR
跟 RD 來的好，LAPoG 可以透過預測
值將工作有效的平均分配給適合的電
腦去執行，而 RR 方法，因為是輪流分
配，沒有考慮到電腦的運算能力，而
導致每次執行耗費的時間都不一致。
而 RD 方法為亂數選取，所以效能為最
差。 
接著模擬高負載的環境進行實
驗，我們將各 slave 格網電腦的 CPU
使用率透過 QuickSort java 程式增加到
80~100%，如圖九所示，LAPoG 方法
在十次的實驗中，執行的時間，平均
在 12~15 秒之間，而 RR 方法，因為無
法避開部份電腦在高負載值時會有運
算瓶頸，導致每次的運算的時間差異
性會很大。 
最後的實驗部份，我們進一步分析在
負載值是無法預期的環境下進行實驗 
 
 
0
20
40
60
80
100
120
0 10 20 30 40 50 60 70 80 90 100
CPU utilization(%)
Ti
me
 in
 se
c
Grid02
Grid03
Grid04
Grid05
Grid06
Grid07
Grid08
Grid09
Grid10
Grid11
 
圖七 slave Grid 電腦在各 CPU 使用率
階段進行 NGB problem ED, class S 效
能測試。 
 
 
0
2
4
6
8
10
12
14
16
1 2 3 4 5 6 7 8 9 10
Run number
Ti
me
 in
 se
co
nd
s
LAPoG
RR
RD
圖八 slave Grid 電腦在 CPU 使用率
0~20%負載下進行 NGB problem ED, 
class S 效能測試。 
Hostname Processor Model Number of 
Processor 
Memory OS Kernel version 
Grid01 Intel®Pentium®4 CPU 3.00GHz 2 2GB CentOS4.4 2.6.9-42.ELsmp 
Grid02 Intel®Pentium®4 CPU 3.00GHz 2 2GB CentOS5.2 2.6.18-92.el 5xen 
Grid03 Intel®Pentium®4 CPU 3.00GHz 2 2GB CentOS4.4 2.6.9-42.ELsmp 
Grid04 Intel®Pentium®4 CPU 3.00GHz 2 2GB CentOS4.4 2.6.9-42.ELsmp 
Grid05 Intel®Pentium®4 CPU 3.00GHz 2 2GB CentOS4.4 2.6.9-42.ELsmp 
Grid06 Intel®Pentium®4 CPU 3.00GHz 2 2GB CentOS4.4 2.6.9-42.ELsmp 
Grid07 Intel®Pentium®4 CPU 3.00GHz 2 2GB CentOS4.4 2.6.9-42.ELsmp 
Grid08 Intel®Pentium®4 CPU 3.00GHz 2 1GB CentOS4.4 2.6.9-42.ELsmp 
Grid09 Intel®Core™2 Quad CPU Q6600 @ 2.40GHz 4 2.7GB CentOS5.1 2.6.18-53.el 5xen 
Grid10 Intel®Core™2 Quad CPU Q6600 @ 2.40GHz 4 2.7GB CentOS5.1 2.6.18-53.el 5xen 
Grid11 Intel®Core™2 Quad CPU Q6600 @ 2.40GHz 4 2.7GB CentOS5.1 2.6.18-53.el 5xen 
[7] Jacques M. Bahi, Sylvain 
Contassot-Vivier, and Raphael 
Couturier, "Dynamic Load 
Balancing and Efficient Load 
Estimators for Iterative 
Algorithms," IEEE Transactions 
on Parallel and Distributed 
Systems, vol. 16, no. 4, 
pp.289-299 April 2005. 
 
[8] Zeng Zeng, Bharadwaj Veeravalli, 
"Design and Performance 
Evaluation of 
Queue-and-Rate-Adjustment 
Dynamic Load Balancing Policies 
for Distributed Networks," IEEE 
Transactions on Computers, vol. 
55, no. 11, pp. 1410-1422 
November 2006. 
[9] Kevin Barker, Andrey Chernikov, 
Nikos Chrisochoides, and Keshav 
Pingali, "A Load Balancing 
Framework for Adaptive and 
Asynchronous Applications," 
IEEE Transactions on Parallel and 
Distributed Systems, vol. 15, no.2, 
pp. 183-192, February 2004. 
[10] Jerrell Watts and Stephen Taylor, 
"A Practical Approach to Dynamic 
Load Balancing," IEEE 
Transactions on Parallel and 
Distributed System, vol. 9, no. 3, 
pp. 235-248, March 1998. 
[11] Zhong Xu, Rong Huang, 
"Performance Study of Load 
Balancing Algorithms in 
Distributed Web Server Systems," 
CS213 Parallel and Distributed 
Processing Project Report. 
[12] Sandeep Sharma, Sarabjit Singh, 
and Meenakshi Sharma, 
"Performance Analysis of Load 
Balancing Algorithms," 
Proceedings of World Academy of 
Science, Engineering and 
Technology, vol. 28, pp. 38-47, 
April 2008. 
[13] D.Grosu and A.T. Chronopoulos, 
"A Game-Theoretic Model and 
Algorithm for Load Balancing in 
Distributed Systems," Proc. 16th 
Int’l Parallel & Distributed Symp, 
pp. 146-153, April 2002. 
[14] Z. Zeng and V. Bharadwaj, "A 
Static Load Balancing Algorithm 
Via Virtual Routing," Proc. Conf. 
Parallel and Distributed 
Computing and Systems 
(PDCS’03), Nov. 2003. 
[15] Rob F. Van der Wijngaart, Michael 
Frumkin, NAS Grid Benchmarks 
Version 1.0, NASA Technical 
Report NAS-02-005 July 2002. 
[16] Ganglia http://ganglia.info/. 
[17] M. Mitzenmacher, "The Power of 
Two Choices in Randomized Load 
Balancing," IEEE Transactions on 
Parallel and Distributed Systems, 
vol. 12, no. 10, pp. 1094-1104, Oct. 
2001. 
[18] R. Motwani and P. Raghavan, 
"Randomized algorithms," ACM 
Computing Surveys (CSUR), vol. 
28, no.1, pp. 33-37, 1996. 
表 Y04 
二、與會心得 
參加這一次國際會議的主要目的，是可以聽到四場精彩的 keynote，對於格網
的相關研究，又有更一層的認識。同時，也認識一些最頂尖的研究學者，可以與
頂尖學者互相討論，尋求研究的新方向與靈感。很高興國科會能提供經費讓本人
參加此會議。雖然短短的三天會議，但是收穫卻很多。 
 
三、考察參觀活動(無是項活動者省略) 
無 
 
四、建議 
覺得國內應該多多舉辦類似此類的國際學術會議，多邀請在此領域方面的頂
尖學者，提供格網方面相關的研究議題，這樣可以不用親自跑到國外來聆聽，也
可以省下交通費的開銷。況且這樣的學術會議，可以提升國內研究的水準與地位。
 
五、攜回資料名稱及內容 
因參加 Basic Registration，僅有會議手冊一本。 
 
六、其他 
無。 
 
 
 
 
 
 
 
 
 
 
 
 
