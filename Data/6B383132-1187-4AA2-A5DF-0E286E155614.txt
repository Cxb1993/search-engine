 2 
 
 
中文摘要 
 
本研究將提出一個利用搜尋結果進行動態分群之中文分群演算法。首先，我們使用自行
研發的斷詞系統以及網路熱門關鍵詞進行文件斷詞，這個演算法是以網頁內容重要性來對每
個群組評比。其次，系統會根據現有分群結果即時判斷此查詢是新群組或屬於現有群組，同
時允許同一網頁屬於多個群組。依據本演算法所實作的 Cayley 中文搜尋引擎，其具有即時
分群、語意層級分群、相關查詢列表、無參數設定、計算關鍵字之間相關程度、擴展性、極
少的相關領域參數設定、能夠處理不同類型的資料、高維度、對任意形狀資料進行分群、具
有良好的雜訊處理能力、分群結果可解釋且使用以及分群結果與使用者輸入資料順序不相關
等特性。 
本論究我們將做使用者評比及模擬評比。針對使用者評比的部份，我們以熱門關鍵字為
評比對象，結果顯示我們語意層級分群明顯的優於一般具有文法分群之中文搜尋引擎。其次
我們針對模擬評比的部份，此部份我們以 Mean Reciprocal Rank(MRR)、Total Reciprocal 
Rank(TRR)、Mean MRR(MMRR)以及 Mean TRR(MTRR)指標來進行評比。而我們模擬對象
包含三類：熱門關鍵字、隨機產生關鍵字以及一段期間使用者的關鍵字(2006/9 至今)，根據
模擬結果，我們的結果皆明顯優於目前提供分群之搜尋引擎。 
 
關鍵詞：即時文件分群、語意層級分群、資料探勘、網頁搜尋、中文斷詞 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 4 
 
壹、導論 
近年來，由於網際網路的盛行，使得網路上所擁有的頁面已經超過一百多億個頁
面[Gulli & Signorini 2005]，因此我們需要一種新的技術，它能將原始頁面轉成有用的
資訊。資料探勘(Data Mining)就是能夠分析原始資料庫的資料，將原先隱含以及未知
的資訊萃取出來的技術[Kolatch 2001; Lent et. al. 1997]。空間資料探勘(Spatial Data 
Mining)是資料探勘的一個分支，其主要處理空間資料[Kolatch 2001]。資料分群(Data 
Clustering)屬於空間資料探勘中一個相當有趣的議題，其主要是將一串有形或抽象的
資料，依照其個別的類別或相似度予以適當分群，因此同一群組內的物件擁有高度的
相似性，且不同群組之間的物件所俱備的相似性是較低[Han & Kamber 2000]。目前
分群的觀念被廣泛的應用在醫學、生物資訊、模式辨別、圖像處理等。分群技術會因
為演算法的不同而影響分群的結果，一般來說，Han 及 Kamber[2000]以下列幾項指
標來判斷分群結果的優劣: 
1. 延展性 (Scalability)：當一個分群演算法不會因為資料的大幅增加而使效能大幅
降低，進而有效的處理資料。 
2. 參數設定：大部份的分群演算在進行分群時都會要求使用者輸入適當的參數，
而分群即是以這些參數進行分群，然而當使用者輸入不當的參數，將會使分群
結果不良。 
3. 異質性資料：大部份分群演算法只能處理數值型或類別型資料，然而在許多的
應用上可能用到各種不同類型的資料。 
4. 高維度：資料庫或資料倉儲可能包含多維度的資料，然而許多的分群演算法對
於低維度處理相當良好，然而對於高維度資料處理就不甚理想。 
5. 任意形狀的分群：一般分群是以物件間距離來衡量資料的相似度，這樣的方法
對於任意形狀分群的辨識能力有限。 
6. 雜訊處理：良好的分群演算法必頇能夠去除資料庫中的雜訊或離群值，因為這
些可能會影響分群的優劣。 
7. 可解釋性：使用者對於分群演算法所產生的結果必頇可以解釋。 
8. 資料輸入順序：有些分群演算法會因為輸入資料順序的不同，造成分群結果不
同，這樣會造成使用者困擾。 
 
一般而言，目前分群演算法一般可分成五大類[Guha et. al. 2000]: 
1. 分割法(Partitioning)：主要是將原始資料分割成一些較小的群組，透過不斷的分
割，可以使得每個群組內的物件具有高度相似，而群組外的物件相似度較低。
在分割法之中，使用者必頇先決定要分群的數目，然後再以 Centroid-based 或是
Medoid-based 的方式進行分群。此方法的評估標準有：Manhattan distance 與
Euclidean distance。MacQueen[1967]提出 K-means 方法即是 Centroid-based 的一
種類型，它的優點是可以找到最佳分群，然而它的缺點包含分群結果容易受
Noise 或 Outlier 影響，同時當資料庫的資料龐大時，其效能是相當不良。另一
方面，K-means 方法的 K 值影響分群結果的優劣，當 K 值愈大時，分群的結果
愈優良，但所需的計算時間將會成長。相反的，當 K 值愈小時，所需的計算時
 6 
方法以高密度及高網格為基礎進行分群，此方法可以自動尋找最高維度之子空
間具有高密度分群，此方法可以很容易的調整維度，而不會使效能明顯降低。 
5. 模型法(Model)：模型法是以數學模式為基礎，利用數學模式來逼近資料內分群
的情形。Fisher[1987]提出 COBWEB 方法，其是以統計資料分佈的機率為其核
心，並以分類樹的概念進行分群，但此方法無法處理大型資料庫。另外，也有
依照距離轉化為類神經網路的 SOM(Self Organizing Map)以及設定群組間相似
程度的門檻值的 ART 方法[Carpenter & Grossberg 1998]。 
 
我們的搜尋引擎具有語意層級，並不是單單語法層級，此語意層級目前並無任何搜尋引
擎實作1。因此，根據我們在使用者評比及模擬評比所獲得的結果，我們的結果是明顯的優
於其它搜尋引擎。 
在本研究裡所使用的分群方法皆可以運用至任一搜尋引擎。然而，根據我們先前研究的
結果顯示，根據搜尋引擎彼此間投票所產生結果的搜尋引擎向量投票方法(Search engine 
Vector Voting, SVV)明顯的優於其它搜尋引擎，因此本研究的分群方法就是建立在 SVV 所產
生的結果，第二節我們將會回顧 SVV 方法及其結果。第三節我們會討論一個全新的分群機
制，此機制具有兩個全新的特性：中文語意層級及即時分群。在第四節裡，我們將會做一系
列的評比，其中的評比對象包含 Google、Yahoo，這些搜尋引擎本身擁有相當多的庫存頁面，
同時也提供分群的功能。而我們的評比方式包含兩部份：使用者評比及模擬評比。使用者評
比是以使用者的角度出發，透過使用者使用熱門關鍵字進行搜尋，並由使用者提供回饋評比，
並加以數量化。模擬評比則是針對 Mean Reciprocal Rank(MRR)、Total Reciprocal Rank(TRR)、
Mean MRR(MMRR)以及 Mean TRR(MTRR)指標來進行評比，而模擬評比的對象包含熱門關
鍵字、隨機產生關鍵字以及一段期間使用者的關鍵字(2006/9 至今)，根據模擬結果，我們的
結果皆明顯優於目前提供分群之搜尋引擎。在第五節裡，我們會對本研究進行結論。 
 
貳、搜尋引擎向量投票 
我們之前曾發展出一套全新的 Cayley 搜尋引擎[Chen & Luh 2005; Chen et. al. 2005; Luh 
& Chen 2007; 陳林志&陸承志 2005]，其中包含三種搜尋方法。而搜尋引擎向量投票(Search 
engine Vector Voting, SVV)所提供的結果與現行搜尋引擎相同，皆為廣度資料的收集，因此
其它形式的廣度搜尋引擎且可適用於我們所提出的分群演算法。 
在 SVV 方法中，我們採用 6 個標準搜尋引擎的搜尋結果來進行投票分析2。在計算網站
權重之前，我們瞭解一般使用者對於排名前面網站的喜好度會比後面網站來得大，而且喜好
度會逐漸遞減，此即心理學的 primacy effect[Morris et. al. 2002]。根據 primacy effect，我們
定義出下列的使用者行為函數(User Behavior Function, UBF): 
UBF =

 sii x ,    (1) 
                                                 
1
 根據 SearchEngineWatch[2003],下列搜尋引擎提供文件分群服務: Google, Yahoo, AltaVista, Lycos, Dogpile, 
Excite, MetaCrawler, WebCrawler, Vivisimo, AlltheWeb, AskJeeve, Teoma, WiseNut, iWon, Aeiwi, EZ2WWW, 
Kartoo, Infonetware, Ixquick, Query Server, Turbo10, Mamma, Search.com, Gimenei, Searchy.co.uk, TeRespondo, NBCi, Ditto, 
然而這些搜尋引擎皆無提供語意層級。 
2
 我們目前所採用的搜尋引擎分別是 : Google, Yahoo, AltaVista, LookSmart, Overture 以及 Lycos，根據
SearchEngineWatch[2003]所提供的搜尋引擎，這六個搜尋引擎具有下列特性: 擁有獨立資料庫以及這六個搜尋
引擎是屬於現行商業性搜尋引擎的前十名。而 SVV 方法的架構足以擴展成任意個搜尋引擎，即由其彼此間投
票，當 SVV 選定的搜尋引擎具有足夠的代表性，則 SVV 投票結果會隨著成長。 
 8 
因此我們亦將提供每個網站與查詢3的關聯程度，以提供使用者更多決策的幫助。
我們利用下列公式計算每個網站與查詢關聯程度: 








.,
)4(3,
3,
otherwiseLow
wwwMiddle
wwHigh
R wp
wp
s 

 
其中 Rs 代表網站 s 與此查詢相關程度，w代表在此查詢下所有回傳網站的
平均權重，w 代表在此查詢下所有網頁權重的標準差。此處我們根據 Chebyshev’s
定理[Walpole et. al. 1998]，得知網站權重>平均權重+3 倍權重標準差的機率小於
九分之一，因此該網站與查詢高度相關。我們以不同色球表達網站間的相關程度，
例如圖 2 中排名 1 的網站其相關程度為高，排名 2 及 3 的網站其相關程度為中。 
 
 
圖 2: SVV 運用於”東華大學資管系”查詢 
 
至於 SVV 搜尋的演算法顯示如下(其中輸入參數 Query 代表使用者所輸入的查
詢): 
 
Algorithm Search_Engine_Vector_Voting (Query as String) 
{  
                                                 
3
 在本研究中，”查詢”代表”使用者輸入的關鍵字”，而”使用者輸入的關鍵字”，在研究中會簡寫
成”關鍵字”，故在研究中”查詢”與”關鍵字”是交互使用。 
 10 
參、文件分群 
本研究主要是完成即時中文網頁分群，且分群結果具有語意層級。為了完成這個分群演
算法，我們必頇完成下列兩項演算法：中文斷詞演算法以及即時中文網頁分群演算法。我們
分述如下： 
 
(1) 中文斷詞演算法：本研究所使用的中文斷詞詞典是中研院平衡語料庫 (Sinicia 
Corpus)[CKIP 1997]，我們首先統計每個詞出現的頻率，之後使用我們所提出的的
WordRank 方法(類似 Google 的 PageRank 方法[Henzinger 2001])去計算每個詞的統計量，
此方法可針對分辨常用詞及稀有詞。WordRank 的另一個功能還可以整合網路熱門詞彙
以及未知詞彙，以此完成整個中文斷詞。至於中文斷詞演算法顯示如下(其中輸入參數
FullText 代表使用者所輸入的文章): 
 
Algorithm Chinese_Word_Segmentation (FullText as Text) 
{ 
 Search match patterns from FullText according to Sinicia Corpus; 
 Sort all match patterns through its frequency; 
 Set pattern list as any pattern which have the highest pattern weight; 
 Do a WordRank on the pattern list 
 { 
  Calculated which patterns are authorized patterns according to patterns list; 
  Calculated which patterns are hub patterns according to patterns list; 
  If (the weight of authorized patterns  threshold value) 
  { 
   If (the authorized patterns are hot keywords on Internet) 
    Set the authorized patterns to hot list; 
   Else 
    Set the authorized patterns to unknown list; 
   Set the authorized patterns to rarely word list; 
  } End of If; 
  Else 
  { 
   If (the authorized patterns are hot keywords on Internet) 
    Set the authorized patterns to hot list; 
   Else 
    Set the authorized patterns to unknown list; 
   Set the authorized patterns to common word list; 
  } End of Else; 
  Add next highest pattern to pattern list;   
 } End of Do; 
} End of Algorithm; 
 
 12 
    } End of If; 
   } End of If; 
  } End of Foreach; 
 } End of While; 
 Output RelatedQueriesQuery,(Di,k); 
 Output ),(, kDiQueryR ; 
} End of Algorithm; 
 
圖 2 顯示 OTFDC 演算法的結果，我們 OTFDC 演算法具有兩個相當優良的特性：分群結
果具有語意層級及即時分群。所謂語意層級即是兩兩相關查詢可能不存在任何語法的相關性4，
但確是具有高度相關性。例如：當使用者輸入”東華大學資管系”，系統會跑出”楊維邦”、”資
管學會”、”朱彩馨”、”劉漢榆”、”許芳銘”，這些查詢本身存在語意層級的關聯性(即代表這些
關鍵字是有關聯，但字面看不出意義)，同時其無任何語法層級的關聯性，但找出的關鍵字確
是具有高度相關性5。所謂即時分群代表每次執行分群演算法時，系統會根據使用者輸入的查
詢進行動態的分群，由於我們的分群演算法屬於動態分群所於相同的查詢最後分群的結果可
能不儘然相同，分群演算法會根據系統內所收集到最新的頁面及斷詞結果進行分群配對，進
而找出動態結果。我們在實際進行分群是以 SVV 搜尋頁面為基礎，而這些頁面在上述中文斷
詞下所產生斷詞詞庫即為動態分群的詞庫來源，我們稱為候選斷詞詞庫，雖然這些候選斷詞
詞庫與全部斷詞詞庫在數量上是減少至可觀範圍，然而以搜尋的角度來說其資料量仍是相當
可觀。圖 4 顯示”東華大學資管系”相關字詞查詢之概念圖，假設此查詢產生的搜尋頁面 = 
O(500)，透過中文斷詞，假設每個頁面所產生的候選斷詞詞庫 = O(100)，則我們在此查詢下
總共存在 O(50,000)個候選斷詞詞庫。若要計算查詢與查詢之間是否存在一個關係，則是透過
某一個搜尋頁面存在於那幾個查詢的關係去計算而得，以此例表示相關查詢 = O(50)，因此當
考慮查詢之間關係時所產生的候選詞詞庫 = O(2,500,000)。為了能夠從這些龐大的資料內尋找
最適合的詞庫(即相關字詞)，我們使用 B+ tree 進行搜尋，這樣可以確保我們的搜尋時間是以
對數時間(logarithm time)成長，這樣的時間是相當符合我們即時分群的要求。 
 
 
 
 
 
 
 
 
 
 
圖 4: ”東華大學資管系”相關字詞查詢之概念圖 
                                                 
4
 我們所定義的語法層級是指：關鍵字與關鍵字本身擁有部份或全部相同的字彙。例如：”東華大學”與”東華大
學資管系”本身就是符合語法層級(彼此都包含”東華大學”字彙)。然而符合語法層級有相當程度不存在語意層級。
例如：”王建民”與”汪建民”符合語法層級(彼此都包含”建民”字彙)，然而這兩個關鍵字並無語意層級關係。 
5
 上面找出的人名都是目前服務於東華大學資管系。 
”東華大學資管系” 
 
www.im.ndhu.edu.tw 
候選詞庫 = 100 
”楊維邦” 
 
… 
 
… 
 
每個查詢在此方向代表產生 O(500)搜尋頁面 
 每個頁面在此方向代表透過中文斷詞產生 O(50)相關查詢 
 
 14 
表 1: 熱門關鍵字之分群結果運用於 SVV, Google 及 Yahoo 
搜尋引擎 
關鍵字 
SVV Google Yahoo 
台鐵 4.57 4.43 4.51 
中央氣象局 4.49 3.26 3.69 
王建民 4.65 3.14 3.25 
無名小站 4.78 2.13 2.45 
mlb
7
 4.67 2.23 2.67 
統一發票 4.34 4.21 4.32 
楓之谷 4.24 4.21 4.22 
火車時刻表8 4.55 2.34 4.45 
Foxy 4.33 4.26 4.28 
歌詞 4.71 4.43 4.47 
平均 4.53 3.46 3.83 
 
表2: 熱門關鍵字之ANOVA分析—使用者評比 
 SS DF MS F 
Treatments 14.472 2 7.23618 6.072403 
Error 1879.234 1577 1.19165  
Total 1893.706 1579
9
   
 
表 3: 熱門關鍵字之 LSD 檢定—使用者評比 
 
 
 
                                                 
7
 從我們的使用者回饋機制發現，當使用者輸入”mlb”很有可能是要找”王建民”等相關資料，由於現行搜尋引擎
只有做到語法層級，因此無法計算到這兩個關鍵字是有絕大的關聯性。而我們的分群演算法屬於語意層級，因
此可以找出彼此存在關聯性。 
8
 在”火車時刻表裡”，SVV 找出的分群結果都是與台鐵火車時刻表有關的關鍵字，然而 Google 只有兩個關鍵字
與台鐵火車時刻表有關，其分別是: “台鐵火車時刻表”及”火車時刻表查詢”。 
9 自由度(Degree Freedom, DF)的總和是 n-1, 其中 n = 10 * 158 (10 個查詢及 158 個使用者)。 
 16 
 
圖 5: SVV, Google 及 Yahoo 的 MRR 評比 
 
 
圖 6: SVV, Google 及 Yahoo 的 TRR 評比 
 
 
 
 
 18 
的搜尋結果當成 OTFDC 演算法的輸入。圖 7 及圖 8 顯示當 Google 使用我們的分群演算法
(Google_OTFDC)的 MRR 值(85.24%)及 TRR 值(8.51)明顯的優於 Google 本身所採用的分群演
算法的 MRR 值(64.76%)及 TRR 值(6.35)，相同情形，Yahoo 也是如此。亦即 OTFDC 演算法
運用至其它搜尋引擎，所得的效能將會有顯著提昇。 
 
圖 7: Google, Google_OTFDC, Yahoo 及 Yahoo_OTFDC 的 MRR 評比 
 
 
圖 8: Google, Google_OTFDC, Yahoo 及 Yahoo_OTFDC 的 TRR 評比 
 20 
 
圖 10: SVV, Google 及 Yahoo 的 MTRR 評比—隨機個數查詢 
 
圖 11 及圖 12 顯示 MMRR 及 MTRR 運用於一段時間使用者真正使用所產生的關鍵字查
詢。在這項模擬中，我們發現 SVV 所採用的分群演算法仍明顯的優於 Google 及 Yahoo。 
 
圖 11: SVV, Google 及 Yahoo 的 MMRR 評比—一段時間使用者查詢 
 22 
我們只著重在重要點(網頁)存在那些可能維度(查詢)，而並不是所有維度(查詢)中的所有
點(網頁)都考慮。在我們實作過程中，我們對於高維度資料處理效果相當良好。 
5. 處理任意形狀資料：由於每個查詢所產生的網頁，可能不儘然相同，這樣造成分群問題
變成任意形狀分群問題。然而在我們演算法中，我們是以點(網頁)的觀念去推論維度(查
詢)，其中每個點所代表的意義是固定的，即每個點代表每個網頁，因此我們的處理方法
並不會因為每個查詢所產生網頁個數不同而無法處理。 
6. 處理雜訊資料：以我們分群所定義的雜訊代表不相關的查詢或網頁。在我們實作時，使
用者可以以控制權重的方式讓系統只選擇重要權重的網頁，而這些網頁透過演算法自然
可以產生相關重要查詢。相對的沒被選取的網頁，其所代表查詢自然也不會被選取，因
此我們的方法可以透過控制權重的方式來過濾雜訊資料。 
7. 可解釋性：我們的方法屬於語意層級，因此兩兩查詢必存在一個語意關係，系統透過此
一關係才會被找出，例如：當輸入”東華大學資管系”，系統找出的部份關鍵字”楊維邦”、”
朱彩馨”、”許芳銘”及”許志堅”的關係都是：這些人名都服務於”東華大學資管系”。因此
我們的分群演算法所找出的相關查詢都是具有可解釋性。 
8. 不受資料輸入順序影響：我們的方法是以 B+ tree 建立，是以每個查詢及其所產生網頁的
關係建立而成。當我們實際分群資料時，並不考慮使用者輸入的先後順序，而以其彼此
間所具有的語意來進行分群。因此我們的方法並不會受輸入順序而影響。 
 
參考文獻 
1. Agrawal, R., Gehrke, J., Gunopulos, D., and Raghavan, P., “Automatic subspace 
clustering of high dimensional data for data mining applications”, International 
Conference Management of Data 1998, pp: 94-105. 
2. Ankerst, M., Breunig, M., Kriegel, H. P., and Sander, J., “OPTICS: Order-ing points to 
identify the clustering structure”, Proceedings of 1999 ACM SIGMOD International 
Conference Management of Data 1999, pp: 49-60. 
3. Berry, M. J. A. and Linoff, G., “Data Mining Techniques: For Marketing, Sales, and 
Customer Support”, John Wiley and Sons, 1997. 
4. Berry, M. J. A. and Linoff, G., “Mastering Data Mining: The Art and Science of 
Customer Relationship Management”, John Wiley and Sons, 1997. 
5. Carpenter, G. A. and Grossberg, S., “The ART of Adaptive Pattern Recognition by a 
Self-Organizing Neural Network”, IEEE Computer (21:3) 1998, pp: 77-88. 
6. Chen, L. C. and Luh, C. J., “Web Page Prediction from Metasearch Results”, Internet 
Research: Electronic Networking Applications and Policy (15:4) 2005, pp: 421-446. 
7. Chen, L. C., Luh, C. J., and Jou, C., “Generating Page Clippings from Web Search 
Results Using a Dynamically Terminated Genetic Algorithm”, Information Systems 
(30:4) 2005, pp: 299-316. 
8. CKIP, “A Description of the Sinica Corpus”, Technical Report 95-02, Academia Sincia, 
1997, available online at http://godel.iis.sinica.edu.tw/CKIP/wordsegment.htm. 
9. Date, C. J., “An Introduction to Database Systems, Addison Wesley, 1999. 
10. Ester, M., Kriegel, H. P., Sander, J., and Xu, X., “A Density-Based Algorithm for 
Discovering Clusters in Large Spatial Databases with Noise”, Proceedings of the 
