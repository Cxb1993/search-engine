 Fig. 1.Attack sophistication vs. intruder technical knowledge 
 
Most network managers consider the firewall as a very good security tool. However, the firewall 
cannot prevent all network attacks. The basic principle of the firewall is to check the IP header and then 
determine if the connection is accepted or denied. A firewall has no capability of detecting whether the 
information passing through the gate is illegal. Hence, hackers can explore the wrong setting of a firewall 
and try to break into it. According to the “Overview of Attack Trends” reported by CERT/CC in 2002 [2], 
firewalls have the increasing difficulty of defending new attacks. There is another problem that a firewall 
is not aware of what is happening inside. In order to enhance the security of the network, an intrusion 
detection system (IDS) may be used along with a firewall. 
2. ???? 
 “Intrusion detection” determines whether unauthorized intrusions or malicious attacks are active in 
the systems and network [3]. The IDS is often described as an alarm system, which provides the 
information and time of intrusion. 
 Three essential components of IDS are sensor, console and response [4]. The sensor component 
captures data in the network packet or system log for the console unit. The console unit is responsible for 
analyzing data and looking for attack signatures. When the console detects an intrusion, the response 
component records the event immediately and then sends out an alert to notify network managers with a 
detailed report. 
There are two basic types of intrusion detection: host-based and network-based. Host-based intrusion 
detection uses system logs as its data source. Network-based intrusion detection uses the information of 
the network traffic. There are two basic techniques for intrusion detection: anomaly detection and misuse 
detection. Anomaly detection is designed to discover abnormal behaviors using the patterns trained from 
normal events. Misuse detection uses specifically known patterns of unauthorized behaviors in order to 
detect intrusion events. 
A. Intrusion detection system 
Some intrusion detection systems are briefly discussed in this section. The HIDS (host-based 
intrusion detection system) is installed to identify tampering or malicious activity in a computer. The 
HIDS monitors application files, system files and/or system configurations to detect any attempt to 
change these files. The HIDS can also detect a user who acquires the privileges of an administrator. If any 
 (1) Test the entire network for security vulnerabilities and provide suggestions to fix them. 
(2) Scan operating systems such as UNIX, Linux and Windows 2000. 
(3) Keep the latest vulnerability testing programs and alerts. 
(4) Have friendly interfaces and optional functions. 
(5) Provide the customizable management report with detailed information for the vulnerability. 
 
 At present, many misuse network-based intrusion detection systems using attack signatures are 
available. However, there still exist various research issues for the misuse NIDS. One of them is how to 
enhance the performance of NIDS in a fast growing network [10, 11, 12]. If an NIDS cannot deal with the 
large amount of network traffic, unchecked packets will become the security leak.  
 Generally speaking, the misuse NIDS has to match packets with all signatures in order to detect 
attacks. Such a system is not very efficient because not all signatures need to be used. Each signature is 
suitable for a certain environment. In other words, a network environment only requires some related 
signatures. Therefore, unnecessary signatures in the misuse NIDS will degrade the performance of 
real-time detection. 
In this project, a novel method "signature customization” for a misuse NIDS is proposed and used. 
This method customizes signatures for each protected host and uses the host status and vulnerability 
information to select signatures. Signature customization has two approaches for signature selection: 
environment selection and vulnerability selection. Environment selection exploits the host status to 
choose signatures, which are suitable for every protected host. Vulnerability selection exploits the 
vulnerability information to choose signatures that detect attacks using the host’s vulnerability. Signature 
customization does not require the modification of the original system and setting values. It helps the 
misuse NIDS to eliminate unnecessary signature match and enhances the system’s performance. 
 Snort is freely available and is a misuse NIDS with a list of rules [13]. Each one of the Snort rules 
defines an attack signature and has a corresponding event description. In addition, Nessus [14] is used as 
the vulnerability scanner. Nessus is a free and powerful security scanner, which scans a target network in 
order to seek vulnerabilities in the network hosts. It also outputs a detailed report for the network 
manager. 
C. Snort 
 Snort is a free open NIDS for lightweight and cross-platform under the GNU license [13, 15]. It 
 (4) Logger/Alerter. Logging and alerting are two separate subcomponents. The information collected 
by the packet decoder may be in the tcpdump format. Alerts can be configured and sent to the syslog, 
UNIX sockets or a database. Optionally, the alerting may be turned off completely during the test or 
penetration studies. By default, all logs are written in the /var/log/Snort folder and all alerts are 
written to the /var/log/Snort/alerts file. 
 
The snort rule is simple, flexible and robust enough to detect a broad variety of suspicious network 
traffic. A Snort rule is divided into two sections: the rule header and the rule option. The rule header 
contains the rule action, protocol, source and destination IP addresses. The rule option contains many 
available "option keywords" that inspect certain parts of the packet such as TCP flags, packet payload, 
packet size and alert messages. Fig. 3 shows as an example of Snort rule. 
 
 
Fig. 3: A sample Snort rule 
 
In figure 3, where "alert tcp any any -> 192.168.1.0/24 111" is the rule header and "(content:"|00 01 86 
a5|"; msg: "mounted access";)" is the rule option. The words before the colons in the rule option section 
are known as the option keywords. Some common option keywords are given below. 
• msg: Print a message in alerts and packet logs. 
• ttl: Test the IP header's TTL field value. 
• id: Test the IP header's fragment ID field for a specific value. 
• ipoption: Watch the IP option fields for specific codes. 
• dsize: Test the packet’s payload size against a value. 
• flags: Test the TCP flags for certain values. 
• seq: Test the TCP sequence number field for a specific value. 
• ack: Test the TCP acknowledgement field for a specific value. 
• itype: Test the ICMP type field against a specific value. 
• icode: Test the ICMP code field against a specific value. 
• icmp_id: Test the ICMP ECHO ID field against a specific value. 
• icmp_seq: Test the ICMP ECHO sequence number against a specific value. 
 matched, the current plug-in function calls the next plug-in in the list. If no match is found, the packet is 
then checked against the next OTN in the OTN list. 
 Snort is known for its sturdy matching scheme. The Snort rule tree makes use of intelligent 
classification to accelerate packet match.  Inevitably, longer OTN chains will result in the longer 
computing time. The reason is that when a packet is assigned to one OTN chain, all nodes on this chain 
are used to scan this packet. One OTN corresponds to one Snort rule. If two OTNs are in the same OTN 
chain, then their corresponding rules are for the same service. However, each rule is written for different 
operation systems and vulnerability applications. This situation makes the Snort inefficient. That is, a 
method to create a subset of rules for each protected host may be found to speed up signature match. That 
is, the size of the Snort rule tree will be reduced to eliminate unnecessary matching. Moreover, the 
proposed method can make the rule set aiming at the service on irregular ports. 
C.3 Match mode 
String match is the major detection method of Snort. However string match is difficult in defining all 
malicious attacks and may generate a large number of false alarms. In the following sections, some 
matching approaches used by Snort are described. 
(1) Protocol match. The protocol examination is used to enhance the ability of detecting attacks against 
the packet protocol. Examples of such examination are the flag bits of TCP packets and protocol 
anomaly. In Fig. 5, protocol matching is performed using the flags, sequence, and acknowledgement 
of TCP packets.  
 
 
Fig. 5: An example of protocol match 
(2) String match. Signature strings of network attacks are usually obtained manually based on attack 
motives and clues. In Fig. 6, the pattern string is "/bin/ps" which can be used to detect the web attack 
of a command attempt. Snort uses one of the best string matching algorithms, the Boyer-Moore 
algorithm [16] for string match.  
 
 for all publicly known vulnerabilities and security exposures. Each plug-in links to CVE for 
administrators to retrieve further information on published vulnerabilities. They also include 
references to CERT, Bugtraq and other security vendors. It is worth noting that the output of Nessus 
always includes links to solutions or patches as well as instructions for fixing the problem. 
• Up-to-date security vulnerability database. This database of security check is updated on a daily 
basis and all new security checks are available. 
 
3. ???? 
Our method uses the host status and vulnerability information to select signatures. Misuse NIDS uses 
attack signatures to detect harmful actions from network packets. With more and more exposed 
vulnerabilities and attack tricks, the misuse NIDS has to update and expand its signature database 
constantly. Performance of misuse NIDS is degraded with the growing signatures. 
 In this project, the approach “signature customization” is introduced to enhance the matching 
efficiency of misuse NIDS without modifying its original system architecture. This method generates a 
set of signatures for each protected host. For each protected host, the corresponding packets are scanned 
using this small set of signatures. 
A. Procedures of Signature Customization 
 The goal of signature customization is to select appropriate signatures and mark exact conditions for 
each protected host. Fig 8 presents the flowchart of customization, which consists of vulnerability scan, 
status report, signature selection, and host indication. Two approaches, environment selection and 
vulnerability selection, may be used for signature selection.  
 
 B1 smtp 25 SMTP 
B2 http 80 IIS 
 
Table 2: Vulnerability sheet 
HOST: 192.168.0.1 
Port number Vulnerability database number 
80 CVE: CVE-2000-0165, BID: 808 
25 CVE: CAN-1999-1529 
 
(3) Signature selection. The process of signature selection uses the host status sheet and vulnerability 
sheet to select signatures for each protected host. Signature selection includes environment selection 
and vulnerability selection. 
(4) Host indication. When a particular signature is picked, a host indication is appended to it. The host 
indication identifies the host and the corresponding ports used by the particular signature. Fig. 9 and 
Fig. 10 present the Snort rules with and without the appending host indication. Using customized 
signatures, the performance of misuse NIDS may be improved dramatically. 
 
 
 
Fig. 9: Original Snort rule without appending host indication 
 
 
Fig. 10: Snort rule appending IP address and service port of the protected host 
B. Environment selection 
 In the misuse NIDS, one signature is used to detect an attack. The attack often occurs in particular 
environments. For example, the "Code Red" worm [19] exploits the vulnerability in Windows machines 
with IIS web server. Therefore, “Windows” and “IIS” are two environmental conditions that will be used 
by a signature to protect a host from the attack of “Code Red”. Therefore, each signature is suitable for 
 relation with the host environment. 
(2) Service. This type of signature is used to detect suspicious requests for the network service. Some 
scanning tools use the responding message of a service to know its status, the corresponding program and 
whether the message is encrypted.  
(3) Service and Operation System. This type of signature aims at a certain network service and 
operating system. For example, the worm of W32.Blaster uses the vulnerability of RPC service in the 
Windows 2000/XP system. 
(4) Service and Application. This type of signature is used to protect the vulnerability of a certain 
combination of application and service, which is platform independent and affects many operating 
systems. For example, the web server program Apache can be installed in different UNIX systems. If one 
version has the vulnerability, all installed platforms will be affected.  
(5) Service, Operating System, and Application. This type of signature aims at a certain combination 
of service, OS and application program. 
(6) Operating System or Application. This type of signature is used for protecting the vulnerability of 
OS or application program. Table 4 lists some signatures for various kinds of vulnerability, where 
“*” means that any case can happen under this term.  
 
 
Table 4: Some signatures for various kinds of vulnerability 
Signature ID Service OS type OS name Application 
100 * * * * 
101 ftp * * * 
102 msrpc WIN WIN2000/XP * 
104 ftp UNIX * Apache 
106 http WIN WIN2000/XP IIS 
  
 Some attacks use the vulnerability in the exterior module of an application. For instance, Apache can 
be attacked through Perl and Java Serverlet modules or CGI programs. However, a vulnerability scanner 
cannot detect the accessory modules and programs in the application. Therefore, the application name that 
offers this service is used instead of its appended modules or programs to classify attack signatures.  
C. Signature selection using environment selection 
 105 * UNIX * * 
106 ftp UNIX * Wu-ftp 
107 http WIN WIN2000/XP IIS 
108 * UNIX * Apache 
109 * WIN WIN2000/XP * 
110 * * * * 
 
Table 7 presents the IDs of signatures for two hosts “192.168.0.1” and “192.168.0.2” in table 5 using 
the environmental selection algorithm, where ID 105 is for a vulnerability not related to a specific service 
port. Table 8 gives the signature of the common vulnerability for these two hosts. 
D. Vulnerability selection 
 Generally speaking, a network attack can successfully invade the hosts on the Internet using the 
host’s vulnerability or setting defects. In other words, if there is no vulnerability, most network attacks 
will not be successful. The vulnerability selection uses a host’s vulnerability to select signatures, which 
have a direct relation with the server’s vulnerability. It is very likely that hackers may use this 
vulnerability to attack the server. 
 
 
 
Table 7: The signatures, obtained using environmental selection, for two protected hosts 
IP: 192.168.0.1 Port: 80 
ID 
101 
102 
108 
IP: 192.168.0.1 Port: 21 
ID 
106 
IP: 192.168.0.1 
ID 
105 
IP: 192.168.0.2 Port:8080
ID 
107 
109 
 which has the corresponding CVE numbers. If it is not possible to find a corresponding CVE number, the 
common reference vulnerability database can still be used to find the serial number. Signatures searched 
by the vulnerability selection will be appended to the host IP address and port number of inspected hosts.  
 The vulnerability selection also needs signatures, which are grouped under the common vulnerability 
of environment selection. Since these attacks detected by such signatures do not aim at the vulnerability 
of the host system and service, the vulnerability selection cannot pick these rules from the vulnerability 
report.  
E. Signature customization for Snort 
 Snort expresses each attack signature using a Snort rule. Snort will construct a rule tree with these 
rules at the initialization stage. The characteristic of the Snort rule tree is that the rules belonging to the 
same service with the same port number will be grouped as a chain as shown in Fig. 12. That is, each rule 
of the rule chain, related or not related to the receiving host of the packet, is included to inspect the packet. 
These redundant inspections will result in more system loading with increasing network flow. Using the 
signature customization approach, only related snort rules are selected for the protected host. Using this 
method, the packet for a host will fall into the rule chain customized for the target host. 
 
 
Fig. 12: An example of the original Snort rule tree 
 
 In Fig. 13, we assume that there are three hosts A, B, and C to be protected. The original rule tree is 
shown in Fig. 12. Using signature customization, the corresponding rule trees are shown in Fig. 14. As 
shown in Fig. 14, rule trees are shorter due to appropriate rules are selected and unnecessary ones are 
excluded. Meanwhile, the packet confirmed with the IP address and port number immediately falls into 
the corresponding rule chain for precise matching. The drawback of using customized rules for hosts is 
that a larger memory space may be required. Thus, using extra memory space to increase the overall 
  There are two hosts TA and TB to be protected as shown in Fig. 15 and their operating systems are 
Windows 2000/XP and Red Hat. Table 9 lists the services provided by TA and TB. Nessus, a vulnerability 
scanner, scans TA and TB to obtain the vulnerability report. This report will be used to generate 
customized Snort rules for TA and TB, respectively. The Snort on the network backbone, which takes 
every packet and conducts signature match, is run on a PC. In the experiment, a traffic generator is 
responsible for sending fixed amounts of packets to TA and TB. In order to avoid the unnecessary 
processing of noise packets, the log mode of Snort is used to capture the experimental packets generated 
by the traffic generator. 
A uniform format of TCP/IP packet is set up and sent by the traffic generator. The major design 
allows Snort to use all rules that examine all packets. In other words, a designed packet will be checked 
by all rules since most packets in the network are normal packets. One point to be addressed is that the 
payload of TCP header will be filled with a string of length 1000. 
 
Fig. 15: The experimental environment 
 
Table 9: Service list of host TA and TB 
 TA (WIN2000/XP) TB (RedHat ) 
service name port num service program port num service program 
http 80 IIS 5.0 80 Apache 1.3.20 
ftp 21 IIS-FTP 5.0 21 Wu-ftp 2.6.1 
Smtp 25 Exchange 2000 25 Sendmail 8.11.6 
netbios-ssn 139 N/A 139 Samba 
Rpcbind N/A N/A 111 Portmapper 
 
 Table 12: Vulnerability information of the first experiment 
HOST: 10.1.10.1 (TA) 
Port number Vulnerability database number 
80 
CVE:CVE-1999-0739; CVE:CVE-1999-0751; CVE:CVE-1999-1011; 
CVE:CVE-2000-0071; CVE:CVE-2000-0114; CVE:CVE-2000-0408; 
CVE:CVE-2000-0457; CVE:CVE-2000-0630; CVE:CVE-2000-0746; 
CVE:CVE-2000-0884; CVE:CVE-2001-0333; CVE:CVE-2001-0500; 
CVE:CVE-2001-0506; CVE:CVE-2001-0507; CVE:CVE-2001-0508; 
CVE:CVE-2001-0544; CVE:CVE-2001-0545; CVE:CVE-2002-0071; 
CVE:CVE-2002-0074; CVE:CVE-2003-0109;  
BID:1065; BID:1190; BID:1193; BID:1488; BID:1594; BID:1595; 
BID:1806; BID:2690; BID:2708; BID:2880; BID:3190; BID:3194; 
BID:3195; BID:4474; BID:4483; BID:529; BID:5305; BID:5900; 
BID:631; BID:7116; BID:7344; BID:7353; BID:8037; 
HOST: 10.1.10.2 (TB) 
Port number Vulnerability database number 
80 
CVE:CVE:-2001-1013; CVE:CVE:-2002-0081; CVE:CVE:-2002-0082; 
CVE:CVE:-2002-0392; CVE:CVE:-2002-0653; CVE:CVE:-2002-0839; 
CVE:CVE:-2002-0840; CVE:CVE:-2002-0843; CVE:CVE:-2002-0985; 
CVE:CVE:-2002-1157; CVE:CVE:-2003-0172;  
BID:3335; BID:4183; BID:4189; BID:5033; BID:5084; BID:5562; 
BID:5847; BID:5884; BID:5995; BID:5996; BID:6029; BID:7187; 
BID:7197; BID:7198; BID:7199; BID:7210; BID:7256; BID:7259; 
BID:8226; 
 
Table 13: Number of rules selected using vulnerability selection for the first experiment 
Scanned host
Rule 
Classifications 
Host TA Host TB 
Total 23 7 
 
 In the first experiment, the performances of Snort with environment selection, vulnerability selection 
and no modification are evaluated. The number of tested packets were 2000, 4000, 6000, 8000 and 10000 
respectively. Half of the tested packets are sent to TA and TB respectively. Fig. 16 shows the CPU time of 
scanning packets using Snort with vulnerability selection, environment selection and no modification, 
respectively.  
  
 Table 14: Host status for the second experiment 
HOST: 10.1.10.1 (TA) OS type: win OS name: win2000 
No. Service Port number Application  
B1 http 80 IIS 
B2 ftp 21 IIS-FTP 
B3 Smtp 25 Exchange sever 
B4 netbios-ssn 139 Pass 
HOST: 10.1.10.2 (TB) OS type: UNIX OS name: Linux 
No. Service Port number Application  
A1 http 80 Apache 
A2 ftp 21 Wu-ftp 
A3 Smtp 25 Sendmail 
A4 netbios-ssn 139 Samba 
A5 rpcbind 111 Portmapper 
 
 
 
Table 15: Rule distribution using environment selection for the second experiment 
Scanned host
Rule 
classification 
Host TA Host TB 
http 235 185 
ftp 25 32 
smtp 3 24 
netbios 21 7 
rpcbind 0 51 
WIN2000 32 0 
Linux 0 8 
common vulnerability 220 220 
Total 536 527 
 
 
 
 
 
 Table 17: Vulnerability information of host TB for the second experiment 
HOST: 10.1.10.2 (TB) 
Port number Vulnerability database number 
80 
CVE:CVE-2001-1013; CVE:CVE-2002-0081; CVE:CVE-2002-0082; 
CVE:CVE-2002-0392; CVE:CVE-2002-0653; CVE:CVE-2002-0839; 
CVE:CVE-2002-0840; CVE:CVE-2002-0843; CVE:CVE-2002-0985; 
CVE:CVE-2002-1157; CVE:CVE-2003-0172;  
BID:3335; BID:4183; BID:4189; BID:5033; BID:5084; BID:5562; 
BID:5847; BID:5884; BID:5995; BID:5996; BID:6029; BID:7187; 
BID:7197; BID:7198; BID:7199; BID:7210; BID:7256; BID:7259; 
BID:8226; 
21 
CVE:CVE-1999-0497; CVE:CVE-2001-0188; CVE:CVE-2001-0249; 
CVE:CVE-2001-0550; CVE:CVE-2001-0582; CVE:CVE-2001-0680; 
CVE:CVE-2001-1335;  
BID:2270; BID:2550; BID:2618; BID:2786; BID:3581; 
25 
CVE:CVE-2001-0714; CVE:CVE-2001-0715; CVE:CVE-2002-0906; 
CVE:CVE-2002-1165; CVE:CVE-2002-1337; CVE:CVE-2003-0161; 
BID:3027; BID:3378; BID:3898; BID:5122; BID:5845; BID:6991; 
BID:7230; 
139 
CVE:CVE-1999-0504; CVE:CVE-1999-0506; CVE:CVE-1999-0519; 
CVE:CVE-1999-0520; CVE:CVE-1999-0980; CVE:CVE-2000-0222; 
CVE:CVE-2000-1200; CVE:CVE-2003-0085; CVE:CVE-2003-0086; 
CVE:CVE-2003-0196; CVE:CVE-2003-0201;  
BID:7106; BID:7107; BID:7294; BID:754; BID:8026; BID:959; 
111 CVE:CVE-1999-0189; CVE:CVE-1999-0632; BID:205; 
 
Table 18: Rule distribution using vulnerability selection for the second experiment 
Scanned host
Rule 
classification 
Host TA Host TB 
http 23 7 
ftp 6 4 
Smtp 7 8 
Netbios 3 6 
Rpcbind 0 4 
Common vulnerability 220 220 
Total 259 249 
  
 5. ???? 
 [1] J. McHugh, A. Christie, and J. Allen, “Defending Yourself: The Role of Intrusion Detection 
Systems,” IEEE Software, Vol. 17, Issue: 5, September 2000, pp. 42-46. 
[2] Overview of Attack Trends, URL: 
http://www.cert.org/archive/pdf/attack_trends.pdf 
[3] An Introduction to Intrusion Detection, URL:  
http://www.acm.org/crossroads/xrds2-4/intrus.html 
[4] J. S. Sherif, and T. G. Dearmond, “Intrusion Detection: Systems and Models,” The Eleventh IEEE 
International Workshops on Enabling Technologies: Infrastructure for Collaborative Enterprises 
(WETICE'02), pp. 115-135, June 2002, Pittsburgh, Pennsylvania, USA. 
[5] D. E. Denning, “An Intrusion-Detection Model,” IEEE Transactions on Software Engineering, Vol. 
SE-13, No. 2, February 1987, pp. 222-232. 
[6] E. Lundin, and E. Jonsson, “Anomaly-Based Intrusion Detection: Privacy Concerns and Other 
Problems,” Proceedings of the Computer Networks, Vol. 34, No.5, pp. 624-640, August 2000. 
[7] A. K. Ghosh, J. Wanken, and F. Charron, “Detecting Anomalous and Unknown Intrusions Against 
Programs,” Proceedings of 14th Annual Computer Security Applications Conference, pp. 259-267, 
December 1998. 
[8] R. F. Erbacher, K. L. Walker, and D. A. Frincke, “Intrusion and Misuse Detection in Large-Scale 
Systems,” IEEE Transactions on Systems, Vol. 27, No.3, February 2002, pp.38-48. 
[9] U. Lindqvist and P. A. Porras, “Detecting Computer and Network Misuse Through the 
Production-Based Expert System Toolset (P-BEST),” Proceedings of the 1999 IEEE Symposium on 
Security and Privacy, pp. 109-120, May 1999. 
[10] C. Kruegel, and F. Valeur, “Stateful Intrusion Detection for High-speed Networks,” IEEE Symposium 
on Security and Privacy, pp. 285-301, May 2002. 
[11] Optimizing NIDS Performance, URL: 
 http://www.securityfocus.com/infocus/1589 
[12] Increasing Performance in High Speed NIDS, URL: 
 http://www.linuxsecurity.com/articles/intrusion_detection_article-4617.html 
[13] Snort Network-based Intrusion Detection System, URL:  
  http://www.snort.org 
 year to continue this work. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
??????????????? 
????:  96 ? 7? 13?
?     ? ??? ??????
??????
??????
?? 
????
(O) 
(02)2461-2192x6648 
(H) (04) 23605963 
?????  41? 10? 04? ?       ?  ???? 
???? 
???? 
(?)  
(?)  
???? 
? ? ? 
  ? ? ? ? ? ? ? ?? ? ? ? 
? ? ? 
? ? ? 
(??)  
 
(??) 
???? 
???? 
(??) ??????????? 
(??) IEEE 
