 2
interactive requirement in large databases. 
We will also investigate the many-to-many 
mapping issue due to the imperfect 
segmentation results and multiple similar 
objects. The image distance will be defined 
in region level based on the estimated 
correspondence, and we will study the 
penalization of distance due to the 
unmatched or irrelevant regions in database 
images. 
In relevance feedback, the 
correspondence estimation becomes a 
prerequisite among feedback regions. In 
addition to regions’ features and adjacent 
relationship within images, we aim to 
incorporate the matching results so as to 
facilitate finding out the region 
correspondence across feedback images. The 
estimated correspondence will be adopted to 
classify feedback regions into groups, refine 
the target query in region level, and adjust 
the image distance. 
 
Keywords: content-based image retrieval, 
region, matching, relevance feedback, 
correspondence, spatial organization, 
adjacent relationship 
 
二、緣由與目的 
 
隨著儲存媒介之容量與日俱增，如何
有效地檢索在資料庫的數位影像，已是多
媒體研究的主流之一。近年來影像檢索的
研究領域，多集中在探討以內涵資訊為基
礎的影像檢索方法。運用影像處理的相關
技巧，電腦可以自動從每張影像中擷取許
多特徵，如顏色的分佈、紋理的變化等，
而影像搜尋時，則是尋找資庫中具有類似
特徵值的影像。此種內涵式影像檢索方
法，不僅可以擷取出許多難以用文字描述
的影像特性，而且可以讓電腦自動化去計
算特徵值，省去大量的人力成本。 
由於影像的顏色與材質分佈，不易以
文字描述，現今的查詢方式多要求使用者
提供一張範例影像(example query)進行檢
索。即使如此，由於不同使用者對相同範
例影像的認知不同，查詢的結果往往不如
人意，因此，現行的影像檢索方法多利用
相關回饋技術，根據使用者回饋的影像，
更新範例影像所提供的資訊以及修正影像
比對方式，以使查詢結果更符合使用者的
需求。 
歸納內涵式影像檢索方法，不外乎以
下三大部份： 
 
一、特徵擷取 (feature extraction)：特徵擷
取的方法，可粗分為全域(global)與局
部性(local)的特徵擷取。 
二、影像比對 (image matching)：比對範例
影像與資料庫中每張影像間特徵值的
差異。 
三、相關回饋 (relevance feedback)：使用
者可以自搜尋的結果中，勾選哪些影
像是與目標接近的，並回饋給系統；
系統再根據這些回饋的影像，動態調
整特徵的權重、甚至是比對的方式，
以使搜尋的結果更接近使用者的需
求。 
 
由於使用全域特徵，無法將影像之間
局部的差異表現出來，近來的影像檢索研
究，多以將影像分成局部區域，並以其局
部區域中的特徵記錄影像中的局部變化。
例如：將影像切成許多不重疊的矩形區
塊，或是運用影像切割技術，將影像切割
為許多具有相近特徵的不規則的區塊，再
自每個區塊中計算低階影像特徵值。當影
像的局部特徵計算出來後，這張影像除了
可以各個區塊特徵表示外，這些區塊間的
空間相對位置也成為另一個非常重要的影
像特性。 
在區塊表示法下，影像比對問題將變
得很複雜。首先，每張影像經區塊切割後，
所得到的區塊不但數目不同、且呈不規則
形狀。當比對兩張影像時，相當於比對兩
群區塊之間的差異程度；因此，兩群區塊
之間的對應關係，必須先被決定出來。此
外，由於影像切割結果往往不盡理想，相
同的物體在不同的影像中可能被切割成不
同大小的區塊，在區塊對應中也必須考慮
此種因素。更甚者，即使我們找到了影像
間的區塊關係後，並非所有找到的區塊對
應都有意義，例如：很不相像的影像間並
無明顯的對應性，或是影像中部份區塊有
 4
依此學習 hidden semantic concepts。 
圖三舉例說明我們自回饋影像學習
concepts 的方法。我們先計算範例影像與回
饋影像的區塊對應關係，例如得知前景與
背景物體互相對應，接著就可以根據估測
得到的對應關係，將回饋影像的區塊分群。 
我們利用之前研究的方法 [13] 進行
計算範例影像與每張資料庫影像的區塊對
應關係。在該方法中，我們藉由考慮區塊
週遭的對應關係，以判斷兩區塊是否對
應。我們將每張影像以圖形  (graph) 表
示，每個影像的區塊代表圖形的頂點 
(node)，區塊的特徵為頂點的特徵 (node 
attribute)，而相鄰區塊的相似程度，則為邊
的權重 (edge weight)。針對代表兩張影像
的圖形 DG 與 MG ，我們提出以 maximum 
likelihood 的方法求出最佳的對應關係： 
( )SS
S
|,maxargˆ MD GGP= ，      (1) 
其中S 為區塊對應矩陣。在該方法中，我
們利用 extremum principal 求出最佳解。 
在圖三的例子中，假設範例影像的前
景物體“老虎”，分別對應回饋影像的前景
物體 “老虎” 與 “鸭子”，而背景物體亦互
相對應。我們藉由這樣計算所得的對應關
係，將回饋影像的區塊分為兩群，一群代
表前景物體，一群代表背景物體，每一群
即代表一種區塊。我們假設每一群即代表
一個新的 hidden semantic concept，故本例
中，將會自回饋的影像學習出兩個 hidden 
semantic concept，分別代表前景與背景。 
針對每一群，我們使用 support vector 
machine (SVM) 去 學 習 一 個 binary 
classifier，代表其對應的 hidden semantic 
concept。假設{ }HCCC ,,, 21 K 是目前已有的
hidden semantic concepts，而每個 region br  
皆如下表示： 
( ) ( ) ( )[ ]bHbbb rPrPrP ||| 21 CCC L=h  (2) 
則我們利用每一群裡所有區塊的 bh 進行學
習。這部份主要的精神，在於利用目前已
知的 concepts 與區塊的關係，學習新的
concepts。 
令{ }K,, 21 DD 為所學到的 concept，用
以代表這次檢索過程中、使用者試圖尋找
的目標。由於每個 mD 皆以 SVM 求得，故
可以藉由 SVM 的標準方法，求得每個區塊
含有該 concept 的機率 ( )bm rP |D 。 
 
 
利用區塊對應關係進行影像比對 
 
 在我們方法的架構下，有兩種利用區
塊對應關係進行影像比對的方法。在一次
檢索過程中，第一次進行檢索時，由於代
表範例影像的 concepts { }K,, 21 DD  未知，
故我們直接利用區塊對應矩陣與低階特徵
計算影像之間的矩離： 
( ) ( )∑ ∑
∈ ∈
=
D MVa V
aaMD yxdSGGd
α
αα ,,    (3) 
 在檢索過程的相關回饋步驟中，每次
我 們 先 自 回 饋 影 像 求 得 一 組 hidden 
semantic concepts { }K,, 21 DD ，接著便利用{ }K,, 21 DD 與區塊對應矩陣，針算每張影像
與{ }K,, 21 DD 的相似程度。 
 圖 四 舉 例 說 明 如 何 計 算 影 像 與
{ }K,, 21 DD 的相似程度。在該例中， 1D 求得
自前景物體， 2D 求自背景物體，故針對一
張新的影像，如果已知範例影像與該張資
料庫影像的區塊對應關係，即可得知 1D 對
應到該張影像的前景、 2D 對應到該張影像
的背景。 
   我們利用 Bayes’ formula 求解。給定一
張影像 aI ，若已知範例影像與 aI 的區塊對
應矩陣為 aS ，則計算 aI 與{ }K,, 21 DD 相似
程度的方法如下： ( )
( ) ( )
( )K
K
K
21
21
21
,
,,|,
,|,
DD
DD
DD
P
IPIP
IP
aaaa
aa
SS
S
=   (4) 
由於 ( )aaIP S, 與 ( )K21,DDP 對每張 aI 而言
皆為常數，故我們只需考慮 likelihood 項：
( )aaIP S,|, 21 KDD 。由於已知 aS ，我們求
得此 likelihood 項如下： 
( )
( ) ( ){ }∏ =∈∝
m
bmIrbm
aa
aab
rP
IP
1,,
21
|
,|,
S
S
D
DD K
   (5) 
此即我們所提出的、在跨檢索歷程的架構
下，利用區塊對應關係比對影像與 hidden 
semantic concept 的方法。 
 
 
 
