一、中文摘要 
隨著交通問題日益嚴重，行的問題與人
類的生活緊密結合，解決交通問題已是世界
各主要都市的首要目標。由於車輛交通意外
發生頻繁，依據統計，九成以上肇事因素皆
人為所致。本計畫最主要的目的在於建構駕
駛管理模式進行預防管理，經由了解造成異
常駕駛的原因，預防異常行為的發生，以進
一步達到降低意外發生。 
本計劃利用三套模組進行偵測與分析，
分別為：1.膚色模組：建立人臉偵測（Detection 
Model）模組，過程包含：(1)傳統 RGB Model
交集 YCbCr Model；(2)連結破碎特徵後的邊
緣影像；(3)對數背景相減法；(4)利用前幅人
臉追蹤結果校正膚色區域；(5)8 方向的元件
連結（8-connected component）以扣除過小的
候選區塊。2.追蹤模組（Tracking Model）：
利用該模組來持續更新與修正候選人臉資
訊，追蹤所得結果可再用於下一幅畫面的膚
色模組修正。針對追蹤結果作特徵分析
(Feature Analysis)，可藉由尋找雙眼(或耳朵)
與鼻子中心的幾何關係判斷該候選臉是否確
為人臉。3.事件模組（Event Model）：利用
事件模組分析駕駛行為與狀態，來進行行為
特徵之取得及分析。藉由交通部之意外統計
資料，定義危安事件相異權值，包含自動分
析轉頭聊天、疲勞、使用手機、連續低頭及
全臉遮蔽，藉由方向估計、瞳孔偵測、特徵
變化及手部膚色搜尋等。 
實驗結果顯示，透過了即時監控裝置，
分析駕駛員之行為特徵，適時發出警告且有
效降低交通意外之發生。 
 
關鍵詞：即時監控、駕駛行為、人臉偵測 
 
二、Abstract 
The purpose of our project is to realize the 
reasons of abnormal driving, build driving 
behavior detection and control models, develop 
abnormal driving analytical algorithms and 
validate the models with actual 
experimentations, therefore, alarm and avoid 
abnormal driving behaviors to decrease traffic 
accidents. 
In Taiwan, Intelligent Transportation 
System（ITS）has been popularized since 1997, 
especially the establishment of Commercial 
Vehicle Operation is the most important and 
key event for to demonstrate the government 
determination to improve driving safety. 
Commercial Telematics is the core equipment 
to perform terminal diagnosis, real-time 
location, real-time communication, driving 
behavior control, and digital administration etc. 
The real-time location information and 
real-time communication can help and transfer 
real-time instructions, and provide immediate 
support for car accidents. Driving behavior 
analysis control can help understand whether 
drivers have undue behavior like speeding, 
rapid acceleration, and abrupt deceleration 
under normal driving conditions or even 
driving under the influence of alcohol or 
physical fatigue. The real-time digital 
administration information can be connected 
with police organization directly through the 
enterprise host. In addition to expediting the 
registration process of general license tax and 
fuel tax, police organization can acquire 
real-time information about driving safety, like 
the position, speed, and the dangerous goods of 
the vehicle. Commercial Telematics system 
includes driving recorders and transfers related 
record to the enterprise control center quickly 
to reduce the accident rate. If accident happens, 
police can judge the responsibility according to 
the information of the driving behavior stored 
in the system.  
The project will obtain and analyze 
features of the drivers’ behavior through 1.Skin 
 
圖 1 系統內部圖 
 
在前處理中，我們先對畫面作連續且嚴
謹之膚色模組(Skin-color Model)搜尋，再經
多種原創性或改良式之臉部偵測與追蹤演算
法，取得候選目標物及臉部特徵；後續處理
時，先檢驗特徵位置與距離之合理性(Feature 
Inspection)、再以改良後之三角計算法[12]求
得人臉方向，最後分析五種危安狀況之個別
權值。若連續五幅畫面之權值總和超過閥
值，即發出警告訊息提醒駕駛，整個系統包
含偵測模組 (DetectionModel) 、追蹤模組
(Tracking Model)及事件模組(Event Model)。 
膚 色 區 域 建 立 屬 於 偵 測 模 組
(DetectionModel)之範疇，整合了五項影像處
理 結 果 ： (1) 以 傳 統 RGBModel 交 集
YCbCrModel 取得膚色區域 (2)連結破碎特
徵之邊緣影像 (3)光度修正影像 (4)利用前
幅畫面之臉部追蹤結果來校正臨界膚色區(5) 
8方向元件連結法(8- Connected Component)。 
人臉偵測之後續處理為追蹤模組
（Tracking Model），找出可能的候選臉位置
後，使用追蹤法持續更新、修正人臉資訊。
最後，我們針對追蹤結果作特徵分析(Feature 
Analysis)，藉由計算雙眼(或耳朵)與鼻子之位
置與幾何關係來判斷該候選臉是否確實為人
臉。我們利用事件模組（EventModel）來分
析記錄駕駛之危險行為或狀態，管理車輛駕
駛。 
本計劃之系統流程如圖2所示，分為臉部
偵測、臉部追蹤、特徵檢驗及危安分析四個
階段。 
Video File
Edge 
Detection
Skin Model 8-Way Connected
Illumination 
Remedy
Motion 
Detection
Overlapped 
Face Match
Danger 
Analysis
Feature Re-
linked
Feature 
Analysis
Boundary, 
Size check
Final Skin-
color
圖 2 系統流程圖 
 
人臉偵測與追蹤 
人臉偵測 
膚色為彩色畫面中一項重要的資訊。在
自然背景與條件下，與人類皮膚色彩具同質
的比例不多；此外，若將膚色轉換到色彩空
間且去除亮度資訊後，將會收斂於一個小區
塊，容易分離非膚色資訊。故利用膚色作最
初的人臉模組建立，是相當可靠與迅速的。 
我們採取下列兩種演算法的交集判定膚
色：Georgios等人[6]提出的改良式YCbCr以
及 ARAKI 等 人 [9] 提 出 的 RGB 膚 色 率
（Skin-color ratio），如下。所有像素經由CCD 
攝影機擷取之RGB色彩轉換至Y、Cb、Cr 三
值後（如下式），便作為膚色判定之參數。 
 
if ( Yi>128) then  
16
25621
Y−+−=θ  
16
256202
Y−−=θ  
63 =θ   84 −=θ  
if ( Y<128) then 61 =θ    122 =θ  
32
23
Y+=θ   
16
164
Y+−=θ  
(Q,R,S,T)中不只一項為1，則P 點的標記設定
等同為1 的其中某點之標記，而其他為1 的
點，亦設為與此點同樣的標記。 
（2）合併同類別 (Merging Classes)，連
通具有相同標記的群組。 
本計畫掃瞄順序為左上、上、右上與左
方，連結順序亦然。至少需有500 個像素之
區塊才需進一步作臉部判斷，以期望去除小
元件的膚色雜訊。 
 
人臉追蹤 
本計畫使用關連性比對（Correlation）尋
找與前畫面人臉最為接近的新臉中心（亦即
具最小關聯值）。藉由相鄰畫面目標物之重
疊與否及歷史紀錄臉之資訊來追蹤移動物新
座標，屬於SSD（Sum of Squared Difference）
的方式，所得關聯值越小，表示比對結果越
相近，即越有可能是該目標物新中心位置。 
在分析過程中，有可能會發生單一畫面
同時出現兩個以上滿足匹配的候選臉。若相
同畫面有兩個以上候選臉互相交錯，便需對
兩臉進行合併或切割之判定。合併表示僅保
留一張人臉，切割則表示兩臉分離性夠高，
不需進行合併。 
 
臉界偵測與計算 
本計畫透過統計學上的期望值概念分別
求得左右界的位置（公式如下），其中X為
間斷型隨機變數，P(X) 為其機率密度函數。
由上而下計算候選臉於每一列第一次連續出
現膚色像素之水平座標，經由期望值計算
後，即可估計臉部左、右邊界的大致位置。 
( ) ( )∑
∈
∗=
boundskinX
XPXXE
_
 
而由Huang Shan等人[27]在人臉橢圓模
組之大量觀察統計，臉部的高度約為寬度之
1.2至1.5倍，如圖3，其中D為單位長度。因
此可得到上、左、右之臉界進而取得下界位
置，將可減少臉部偵測誤判率，並增加系統
執行速度。 
 
圖3 臉部高度與寬度比例 
 
臉遮蔽之修正 
我們依據臉部比率之分析，判斷遮蔽之
標準。判定標準為：若雙眼(耳)區域皆可找到
且鼻子受遮蔽（即Partial Occlusion），系統
判斷該狀態仍屬安全；在人臉已出現的條件
下，若接續三幅畫面皆搜尋不到雙眼(耳)區
域，便判定發生完全遮蔽（Full Occlusion）
之危險事件。 
 
人臉方向計算 
我們採用Chiunhsium等人提出之演算法
辨識來分析人臉為正面或側面，使用特徵之
三角計算法分析人臉方向，特性為：(1)小型
人臉亦容易判斷。(2)適用於複雜背景。(3)不
受臉部扭曲或雜訊影響。(4)正臉與側臉皆可
正確判斷。 
 
特徵檢驗與標記 
人臉中雙眼(耳)與鼻子的邊緣性質相較
於周遭區域是比較高的，將修正後的膚色模
組作水平方向膚色計算時，經過雙眼(耳)與鼻
子的掃瞄區域，至少會存在一個區域極小值
滿足搜尋結果。我們使用掃描方式找出膚色
之區域極小值，包含眼睛(耳朵)及鼻子的初步
位置資訊，透過平均值計算以及特徵間的幾
何限制，確認臉部偵測之正確與否。取得眼
睛(耳朵)與鼻子之可能位置後，再利用幾何特
性加以過濾，刪除許多不符合臉部特性之偵
測結果。 
 
駕駛狀態權重分析 
系統針對五大類危安事件來定義權值，
並將其總和正規化為1，以利稍後運算。如圖
估量轉頭之可能性、利用部份臉遮蔽判斷與
手部膚色搜尋來分析駕駛是否低頭或使用手
機。28 個測試檔，其中22個測試檔包含一種
以上之危險狀態，分析結果作統計如表2所
示。 
表 2 各類危安事件及危安提醒精確率 
 
FRR(False Rejection rate)表示將已經發
生之事件，錯誤排除為沒有發生、FAR (False 
Acceptance Rate)表示將沒發生之事件，失誤
判定為已經發生。危安條件定義的越嚴苛，
FRR 越小，但相對地FAR 越大，反之亦然。
系統設計的要點在於儘量使兩值皆低，達到
可接受之平衡點。 
如表1所示，駕駛發生疲勞之事件實際發
生13次，但系統只偵測到11次，故FRR為
15%(＝2/13)；駕駛實際使用手機次數為9
次，但不正確偵測到3次，故FAR為25%（＝
3/12）。表下方之“嚴重危險次數”代表危險權
超過閥值的次數，也是危安駕駛監控系統之
結果。由表可知系統對於駕駛是否打手機或
受遮蔽之事件容易誤判，但是整體效能頗高
(FRR 與FAR都在10％以下)。 
 
六、結論 
本計畫中，我們設計一個完整的安全駕
駛監控系統，對小型車內的駕駛人臉進行偵
測、追蹤與各種危險行為分析。除了常見之
疲勞偵測與遮蔽分析，系統亦添加轉頭聊天
判斷、手機使用以及駕駛是否低頭等分析。 
採用改良式YCbCr 膚色模組初步尋找
人臉位置，結合破碎邊連結法與區域搜尋方
式來修正模糊特徵區域，並使用對數相減法
減緩區域亮度不均問題。 
利用相鄰畫面目標物的重疊資訊與歷史
紀錄臉資訊計算移動物間關連性作為臉部追
蹤，以追蹤候選目標之新座標，藉此減少人
臉偵測的次數；由於偵測次數大幅減少，時
間複雜度降低，故5fps 之取像速度大致仍可
即時處理，且系統亦改良橢圓模組之統計數
值修正部分遮蔽造成之追蹤錯誤。藉由降低
演算法之數學運算流程，可以更進一步提升
每秒鐘處理之幅數(fps)。 
結合膚色與特徵判定，使得約2000幅畫
面之人臉與特徵搜尋(含眼鏡、墨鏡與部分遮
蔽)，平均正確率達91％，且三角計算法可處
理不同大小之人臉、相異的姿勢與表情、計
算簡單亦不受亮度或雜訊影響。 
運用交通事故統計資料，定義並標準化
五種危安事件之權值，並謹慎加權連續五幅
畫 面 之 權 重 總 和 ， 以 降 低 錯 誤 發 訊
(False-alarm)機率。 
實驗設計含28 個測試影像檔(約2000 
幅畫面)，經過統計證明在多種東方人與西方
人(不含黑人)中，本計畫提出的危安監控策略
均有顯著效果。 
 
七、參考文獻 
[1] 道路交通事故狀況分析，內政部警政署，
2003、2004。 
[2] C.H. Monmoto, D. Koons, A. Amir, M. 
Flickner, “Pupil Detection and Tracking 
Using Multiple Light Sources”, Image and 
Vision Computing 18, (2000) 331-335. 
[3] R Hsu, M. Mottleb, A. K. Jain, “Face 
Detection in Color Images”, IEEE 
Transaction on Pattem Anlysis and 
Machine Intelligence Vol4, No. 5, May 
2002. 
[4] A.Haro, M. Flicker, I. Essa, “Detecting and 
Tracking Eyes by using Their Physiolocal 
Properties, Dynamics and Appearance”, 
Proceeding CVPR. 
[5] K.H. Rho, K.H. Park, and M.H. Han, 
“Automatic mirror adjustmentsystem using 
