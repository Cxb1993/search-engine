 2 
 
 
and (3) bi-criterion stochastic optimization with consideration of probabilistic 
distributions of activity times and costs. In the end, the three classes are integrated 
into a solver platform, which helps project managers construct the Pareto front of 
time-cost tradeoff with high flexibility (allow all different forms of activity time-cost 
functions), strong efficiency (requires only single direction communication in contrast 
to pair-wise crossover), and great simplicity (implement a straightforward mechanism 
with only two equations). The solver platform can solve the time-cost tradeoff 
problem in both deterministic and stochastic cases. In addition, the stochastic Pareto 
front, the optimization result of the third class, will assist project managers in 
performing proper risk management tasks under uncertainty. 
 
Keywords: Scheduling, Multiobjective optimization, Particle swarm optimization, 
Swarm intelligence, Algorithm, Risk assessment 
 
 
二、研究目的 
 
A construction project can be defined by a set of individual activities and their 
inter-precedence constraints. To meet a specified deadline, a direct approach is to 
accelerate some of the activities at an additional expense, i.e., by allocating more or 
better resources (labor and equipment). How to minimize the sum of activity direct 
costs while meeting a specified deadline is of practical interest and has been dubbed 
as the project crashing problem. Variants of the project crashing problem extend the 
objective function to include time-dependent overhead cost and delay penalty. Both 
classes of problems are called the time-cost tradeoff (TCT) problem. 
In practice, however, there are frequently occasions when activities in the same 
project have different types of time-cost functions (Moussourakis and Haksever 2004). 
The arbitrary mix of piecewise linear, nonlinear (convex or concave), and discrete 
relationships constitutes a complex problem that is difficult to solve for classical 
optimization techniques, such as linear programming and integer programming. 
Moreover, the time-cost relationships may consist of discontinuous pieces, i.e., 
defined at distinct regions (Moder et al. 1995). This occurs when an activity can be 
performed by various methods, each of which leads to a different range of possible 
time and cost. For example, excavation can be done manually or mechanically; 
whereas the former takes 10 to 15 days the later may need only 3 to 5. Therefore, the 
activity time-cost function contains two distinct regions, each of which defines the 
possible time and cost for a particular method. 
Conventional solution approaches have been used to solve TCT problems; they 
 4 
 
 
use of the same resources (material, equipment, and labor). When the unit cost of a 
resource rises either due to limited supply or higher transportation expense, it would 
affect all the related activities (Touran 1993; Wang 2002a). The last type of 
correlation exists between the time and cost of each activity. This correlation is 
realized when labor and equipment is paid on a daily or weekly base. For the same 
activity option, longer duration therefore entails higher cost. Such a correlation can be 
estimated by a regression analysis on historical data (Chan 2001; Zayed and Halpin 
2005). 
The aim of this study is to develop an optimization algorithm to solve both TCT 
and STCT problems with higher efficiency, increased robustness, and greater 
flexibility. To attain broader applicability and greater flexibility, the developed 
particle swarm optimization (PSO) algorithm is designed to treat any type of activity 
time-cost functions. In terms of efficiency, the algorithm optimizes both criteria (time 
and cost) simultaneously, i.e., to construct the entire Pareto front in a single run. This 
would greatly reduce the cumbersome burden of repetitive runs, each of which 
optimizes only one objective (time or cost) while treating another as a constraint 
(budget or deadline). As for the robustness, it has been realized that using metrics (the 
Euclidean distance from a solution to another in the objective space), which 
determine relative weights of criteria, may render the algorithm susceptible to the 
scaling problem (Alvarez-Benitez et al. 2005). That is, different scales of time and 
cost (e.g., changing the unit of time or currency of cost) would influence the 
optimization performance. The scaling problem hurts the robustness and therefore 
needs to be avoided. In terms of flexibility, the proposed algorithm allows all the 
existing types of activity time-cost functions: linear, nonlinear (Moder et al. 1995; 
Deckro et al. 1995), discrete (Skutella 1998). On top of these is the most difficult case 
where the activity time-cost function involves both nonlinearity and discontinuity. 
The case may arise in practice when the time-cost function is a result of nonlinear 
regression (Li et al. 1999), and consists of discontinuous portions, each of which may 
be associated with a different working method, or a choice of equipment. 
The first two years of the study were focused on the development of single- and 
multi-objective TCT models whereas the third year was spent in a new STCT 
framework. Since the TCT results have been discussed at length (Yang 2007a, 2008a), 
this report addresses the following issues of the STCT analysis 
1. All the three types of aforementioned correlation should be incorporated into the 
STCT analysis to assess the risk with higher accuracy. 
2. To provide the greatest modeling capability, the proposed STCT analysis 
framework should be distribution-free and nonparametric, in that no prior 
restrictions are placed on the distribution type and estimation process. 
 6 
 
 
masonry and Erlang distributions for electrical work. 
When historical data is unavailable, the other alternative is to elicit the 
distributions based on experts’ judgment. The method of three-point estimates is 
familiar to most estimators and has been included as standard practice in PMBOK 
(PMI 2008). It takes the minimum, most-likely, and maximum values to derive the 
distributions of simulation components, with respect to time (Malcolm et al. 1959; 
Clark 1962; AbouRizk and Halpin 1992) and cost (Wang 2002b; Goodpasture 2003). 
The underlying distribution is customarily assumed to be continuous beta because it 
can model asymmetrical situations and always confined within definite limits 
(Schexnayder et al. 2005). 
The probability density function (PDF) of a general beta distribution is 
0,0 ,  
))(,(
)()(),,,;( 1
11
>>≤≤−
−−= −+
−−
βαUxL
LUβαB
xULxULβαxf
βα
βα
(1)
where ),( βαB  is the beta function, defined by 
∫ −− −=+= 1
0
11 )1()(Γ/)(Γ)(Γ),( dtttβαβαβαB βα (2)
There are four parameters in Eq. (1): shape parameters α and β, lower bound L, 
and upper bound U. While both bounds would have been specified as three-point 
estimates, an additional piece of information is needed to establish the entire beta 
distribution. AbouRizk et al. (1991) suggested using any pair of the mean, variance, 
and mode to compute the shape parameters α and β. The first two moments of the beta 
distribution can be estimated by the Project Evaluation and Review Technique 
(PERT) 
6
4ˆ UmLμ ++= (3)
36
)(ˆ
2
2 LUσ −=
 
(4)
where μˆ  is the mean, 2σˆ  is the variance, and m is the most likely value. Once the 
mean and variance are estimated, the analytic formulas for estimating the shape 
parameters are 
1)1(
2
−+−= τ
υ
ττ
β
 
(5)
τ
βτ
α −= 1  (6)
based on standardized estimates 
) /()ˆ( U-L-Lμτ = (7)
22 )/(ˆ LUσυ −= (8)
The conventional three-point estimates assume that the minimum and maximum 
points represent 0 and 100 percentiles, which imply that the true value would never 
fall outside the limits. Yet, past researchers revealed that human experts are hesitated 
 8 
 
 
highly impractical when the number of variables is large. 
Three types of correlation are handled in the present study: (1) correlation 
between the durations of activities, (2) correlation between the costs of activities, and 
(3) correlation between the duration and cost of individual activities. Because each 
activity is associated with 2 variables: one for duration and one for cost, the 
correlation coefficients can be stored in a two-dimensional square matrix M, whose 
size is 2d×2d where d is the number of activities. Fig. 1 depicts matrix M and its 4 
sub-matrices. Sub-matrix T consists of correlation between durations: t1 through t3 
for activities 1 through 3. Sub-matrix C contains correlation between costs: c1 
through c3. Sub-matrices TC and CT are transpose to each other; they include the 
correlation coefficients between duration and cost for each activity. The entire 
correlation matrix, by definition, is symmetric with unit diagonal. 
The proposed framework uses the Gaussian copula to model the correlation 
between distributions of activity durations and costs. The Gaussian copula is a 
function that joins univariate distribution functions to form a multivariate normal 
distribution function (Nelsen 1998): 
 ))(Φ),...,(Φ),(Φ(Φ)M;,...,( 2d
-1
2
-1
1
-1
M221 uuuuuuC d =  (12)
where M is the specified correlation matrix; MΦ  represents the multivariate normal 
distribution function with M; )(-1 uΦ  denotes the inverse of the normal cumulative 
distribution function (CDF), and d is the number of activities. 
The required input of the proposed framework includes (1) the marginal 
distributions of activity durations and costs, and (2) the correlation matrix. The 
underlying concept is to use the Gaussian copula to represent a vector of correlated 
normal variates, transform them into uniform variates by the aid of the normal CDF, 
and then map the variates into their individual marginal distributions. The generated 
random variates are used to represent the activity durations and costs with the desired 
correlation structure. Since all the marginal distributions are always preserved, the 
procedure is applicable to any types of distributions, which need not belong to the 
same parametric family. 
The correlated MCS procedure is implemented as follows 
1. Check whether the correlation matrix is positive semidefinite, i.e., all the 
eigenvalues are nonnegative. If not, one can resort to the closest replacement 
using the eigenvalue correction procedure described in (Yang 2008b). 
2. Use the Cholesky factorization to find a suitable square-root C of correlation 
matrix M such that  
TCCM =  (13)
3. Draw a vector Z of uncorrelated standard normal variates. 
4. Transform Z into a vector of correlated standard normal variates by 
 10 
 
 
another solution v if the former is superior to the latter in at least one objective and 
not worse in the other objective. Because project duration and cost are the two 
objectives being minimized, the dominance relation, denoted by ufv, holds if any of 
the following conditions is met 
Tu < Tv and Cu ≤ Cv 
Cu < Cv and Tu ≤ Tv (18)
 The goal of multi-objective optimization is to find the non-dominated solutions, 
which cannot be further improved. In the time-cost scatter chart, the non-dominated 
solutions constitute the convex Pareto front. Since solutions in a non-dominated set 
are mutually non-dominating to one another, a solution on the Pareto front always lies 
in other non-dominated solutions’ second (upper left) or fourth (lower right) quadrant. 
Fig. 3 illustrates 6 solutions and their objective values (VaRs of project duration and 
cost). Solutions 1 through 3 are non-dominated and represent the Pareto front as the 
dotted area. Solution 4 is dominated by solution 2 to a small extent whereas solution 6 
is greatly dominated by solutions 1~4. Solution 5 is dominated by solution 3. 
 The dominance relations in Fig. 3 are fairly clear because every solution in the 
objective space can be represented as a clear-cut point. It gets complicated when the 
objective values are evaluated in stochastic environments, where the values are not 
certain numbers. Now, the solution cannot be represented as merely a point. 
Variations must be accounted for by two confidence intervals (CIs): the horizontal 
interval denotes the possible range in time whereas the vertical one stands for cost. 
The CIs would look like crosshairs with the point estimate of VaR lying within. Fig. 
4(a) illustrates the CIs of the six solutions in Fig. 3. 
 The CIs for VaR can be established as follows. Let pξ  denotes the VaR 
(p-quantile). Given a series of ordered samples Z1, Z2, …, Zk, we can use the binomial 
distribution to evaluate the probability 
∑∑ −
=
−−
=
− −⎟⎟⎠
⎞
⎜⎜⎝
⎛−−⎟⎟⎠
⎞
⎜⎜⎝
⎛=<< 1
0
1
0
)1()1(}{
r
i
iki
s
i
iki
spr ppi
k
pp
i
k
ZξZP  (19)
where 1<r<s<k. When k is greater than 20, the indices r (lower bound of CI) and s 
(upper bound of CI) can be approximated as follows 
)1(Φ
2/)1(
pkpkpr
α
−+= −  
)1(Φ 2/)1( pkpkps α −+= +  
(20)
where Φ  is the standard normal distribution and α  is the desired confidence 
coefficient for the p-quantile. If r and s are not integer, the CI bounds are obtained 
using linear interpolation. To be conservative, both p and α  are usually specified 
close to 1, such as 0.90, 0.95, or 0.99. Note that Eq. (20) is based on rank-order, so it 
does not depend on the population fitting any parameterized distribution (Conover 
 12 
 
 
solution B in objective X, we still need a rule to determine the overall dominance 
relation in terms of both objectives. The rule is to further compare the VaRs in 
objective Y. As long as the VaR of solution A is lower than that of solution B, A is 
considered not inferior to B in objective Y; thus, the dominance relation holds. For 
example, solution 5 in Fig. 4(a) is stochastically dominated by solution 3 since the 
latter is significantly better in time (no overlap in CIs) and not worse in cost (having a 
lower VaR). 
 
四、結果與討論 
 
PROPOSED STCT FRAMEWORK 
The flow diagram of the proposed framework is depicted in Fig. 5. Since the 
STCT analysis is non-differentiable, gradient-based optimization methods are of 
limited use. In contrast, the use of particle swarm optimization (PSO) to solve the 
STCT problem is appealing because it converges fast within a high dimensional 
search space and has only few parameters to adjust. Consequently, the outer loop is 
performed by a multiobjective PSO algorithm. The original PSO scheme was 
designed to mimic the cooperation within a biological population, such as a group of 
birds or a swarm of insects (Kennedy and Eberhart 1995). Within the swarm, 
multi-dimensional particles, each a possible solution, are flown through the problem 
space, in search of the optimal solutions. Each particle has its own velocity, which is 
determined by (1) local best: the memory of the best solution it has visited thus far 
and (2) global best: the best solution found by the entire swarm.  
The proposed PSO algorithm is configured to search for the optimal activity 
options in a discrete space. Hence, the real-valued particle positions have to be 
transformed to integers. The discretization is performed through a nearest integer 
function, which rounds the real value to the closest integer. In the proposed algorithm, 
the position of the kth particle is d-dimensional (d equals the number of activities) and 
expressed in a vector form: ],...,,[ 21
k
d
kk yyy . The position component in dimension d 
determines which option is selected for activity d. 
The proposed algorithm iteratively changes the particle positions as follows 
)1()()1( ++=+ tvtyty kdkdkd  (21)
where )1( +tykd  is the component in dimension d of particle k at iteration t+1; 
1( +tvkd ) is the velocity at iteration t+1, which is determined by 
))](())(()([)1( 21 tygBestcrtypBestcrtvχtv
k
dd
k
dd
k
d
k
d −+−+=+  (22)
where χ  is the constriction factor; )(tvkd  is the velocity at the previous iteration; c 
is the learning constant; r1 and r2 are two pseudo-random numbers; dpBest  is the 
 14 
 
 
of CIs in Fig. 4(b). A pseudocode is given in Fig. 6 to implement the multi-leveled 
prescreening strategy. 
The efficiency of the prescreening strategy is inversely dependent on the portion 
of nondominated solutions. Suppose the number of nondominated solutions is p% of 
all the feasible solutions, and q% of the sample size is used to exclude the solutions 
being dominated. The required number of function evaluations can be reduced from 
100% to 
)%
100
(%100%%%)1( pqqppqp −+=×+×−  (24)
Because p and q are usually small, the prescreening strategy is quite efficient. For 
instance, when p=1% and q=10%, the computation time is greatly reduced to 10.9%. 
It is noteworthy to stress that the effectiveness of the prescreening strategy is 
built on the definition of stochastic dominance relations. Only when the stochastic 
dominance relation is clearly defined can we be confident in using a small portion of 
samples to foresee the potential of the solution being considered against existing 
archive members. 
Since PSO may converge to local optima prematurely when solving highly 
multimodal problems, the proposed algorithm includes a turbulence operator to 
re-initiate particle locations randomly when the solutions converge prematurely. The 
premature convergence is detected if the elite archive has not grown much in the past 
m iterations. This approach contributes toward increasing the diversity of solutions. 
The stopping criterion is met either when the iteration counter or the amount of 
computation time exceeds a preset limit. At the end, the elite archive is reported as the 
most desired tradeoff solutions. 
APPLICATION AND VALIDATION 
A practical project from (Feng et al. 2000) is used to demonstrate the 
performance of the proposed framework. Activity descriptions and precedence 
relationships are shown in Fig. 7. Table 1 lists the three-point estimates for activity 
durations and costs. Note that although subjective estimates are used here, the 
proposed framework can accept input inferred from historical data. 
All three types of correlation are integrated into a correlation structure listed in 
Table 2. In the second column, T denotes time whereas C denotes cost. For example, 
because the same crew is employed to lay out forms, tie rebar, and pour concrete, 
activity 2 (forms and rebar) and activity 5 (pour foundation and piers) are considered 
correlated. In addition to subjective elicitation, historical correlation from similar 
projects may be of assistance if it is judged that past experience is a guide for the 
future. 
After a number of pilot runs, only one PSO tuning parameter needs to be set: the 
learning constant is 2.05, leading to the constriction factor of 0.72. This highlights the 
 16 
 
 
that activity 5 is twice likely to be critical, compared to activity 6. With this 
information, more management efforts should be directed to activity 5 to ensure its 
on-time completion. 
 Having the entire Pareto front assists project planners in exercising their 
judgment on the overall best plan. Although every project has its management 
background, we will illustrate some scenarios here to reflect practical considerations 
about the best plan. The mean values of direct costs (time-cost curve) are represented 
by the solid line in Fig. 13. It becomes apparent that both ends of the Pareto front are 
not worth consideration. Solution 1 costs a lot more than solution 2 just to crash the 
project by less than one day. In contrast, solution 11 takes 40 days longer than 
solution 10 but the saving in cost is only marginal. 
 The set of nondominated solutions can be expanded to include indirect costs, 
such as general overhead and other costs of estimating, bid preparation, scheduling, 
and interest on financial transactions. The indirect costs for this project has a 
minimum of $5,000 and an increasing cost slope of $200 per day. The mean values of 
the total costs at various project durations are plotted as the dashed line in Fig. 13. 
Solution 10 provides the minimum total cost: $124,270.5. 
 Another scenario is to consider financial incentives for on-time completion. The 
contract indicates that the work should be completed within 90 days. Otherwise, a 
clause would entitle the owner to liquidated damages in an amount equal to $800 per 
day, not to exceed a total of $8,000. In this case, the total cost plus possible penalty, 
shown as the dotted line in Fig. 13, would change the best plan to solution 8, which 
completes the project within 89.32 days. 
 
五、計畫成果自評 
 
The present study spends three years in developing a new solver platform for 
TCT and STCT analyses. The platform is equipped with elitist PSO algorithms to deal 
with both deterministic and stochastic cases. The results of the first two years are 
TCT algorithms published in (Yang 2007a; Yang 2008a). The proposed TCT 
algorithm alters the selection of personal and global bests in classical PSO schemes 
and develops an elite archive to store the nondominated solutions, which are updated 
iteratively. The algorithm has been shown effective and efficient in obtaining the 
Pareto front.  
The proposed TCT algorithm contributes in three ways. First, it can locate the 
Pareto front in a single run of the algorithm and therefore can help decision makers 
evaluate the pros and cons of all the possible solutions with considerable efficiency. 
 18 
 
 
International Journal of Advanced Manufacturing Technology, in press. 
Alvarez-Benitez, J.E., Everson, R.M., Fieldsend, J.E. (2005). “A MOPSO algorithm 
based exclusively on Pareto dominance concepts.” Lecture Notes in Computer 
Science, Springer-Verlag, Heidelberg, Germany, pp. 459-473. 
Azaron, A, Perkgoz, C. and Sakawa, M. (2005). “A genetic algorithm approach for 
the time-cost trade-off in PERT networks,” Applied Mathematics and 
Computation, 168, 1317–1339.  
Chan, A.P.C. (2001), "Time-cost relationship of public sector projects in Malaysia", 
International Journal of Project Management, Vol. 19 No.4, 223-229. 
Chou, J.S., Yang, I.T., and Chong, W.K. (2009). "Probabilistic simulation for 
developing likelihood distribution of engineering project cost." Automation in 
Construction, 18, 570-577. 
Clark, C.E. (1962). “The PERT model for the distribution of an activity.” Operations 
Research.10 ,405-406. 
Clerc, M. and Kennedy, J. (2002). “The particle swarm-explosion, stability and 
convergence in a multidimensional complex space.” IEEE Transactions on 
Evolutionary Computation, 6(2), 58-73. 
Cohen, I., Golany, B., and Shtub, A. (2007). “The stochastic time–cost tradeoff 
problem: a robust optimization approach,” Networks, 49, 175–188. 
Conover, W.J. (1980). Practical nonparametric statistics, 2nd edition, John Wiley & 
Sons, New York. 
Deb, K., Pratap. A, Agarwal, S., and Meyarivan, T. (2002). “A fast and elitist 
multi-objective genetic algorithm: NSGA-II.” IEEE Transaction on Evolutionary 
Computation, 6(2), 181-197.  
Deckro, R.F., Hebert, J.E., Verdini, W.A., Grimsrud, P.H., and Venkateshwar, S. 
(1995) “Nonlinear time/cost tradeoff models in project management.” Computers 
and Industrial Engineering, 28(2), pp. 219-229. 
Demeulemeester, E., Herroelen, W., and Elmaghraby, S.E. (1996). “Optimal 
procedures for the discrete time/cost trade-off problem in project networks.” 
European Journal of Operational Research, 88, 50–68. 
Elmaghraby, S. E. (1993). “Resource allocation via dynamic programming in activity 
networks”, European Journal of Operational Research, 64, pp. 199-215. 
Ezeldin, A.M. and Ahmed Soliman, A. (2009). “Hybrid time-cost optimization of 
nonserial repetitive construction projects.” Journal of Construction Engineering 
and Management, ASCE, 135(1), 42-55. 
Farid, F. and Koning, T.L. (1994). ‘‘Simulation verifies queuing program for 
selecting loader-truck fleets.’’ Journal of Construction Engineering and 
Management, ASCE, 120(2), 386–404. 
 20 
 
 
analysis using LP/IP hybrid method.” Journal of Construction Engineering and 
Management, ASCE, 121(4), 446-454.  
Malcolm, D.G., Roseboom, C.E., Clark, C.E. and Fazar, W. (1959). “Application of a 
technique for research and development program evaluation.” Operations 
Research, 7, 646-649. 
Moder, J.J., Phillips, C.R., and Davis, E.W. (1995). Project management with CPM, 
PERT and precedence diagramming. 3rd edition, Blitz Publishing Company, 
Wisconsin. 
Moonan, W. J. (1957). “Linear transformation to a set of stochastically dependent 
normal variables.” American Statistical Association Journal, 52, 247-252. 
Moussourakis, J. and Haksever, C. (2004). “Flexible model for time/cost tradeoff 
Problem.” Journal of Construction Engineering and Management, ASCE, 130(3), 
307-314. 
Nelsen, R.B. (1998). An Introduction to Copulas. Springer-Verlag, New York. 
Ng, S.T. and Zhang, Y. (2008). “Optimizing construction time and cost using Ant 
Colony Optimization approach.” Journal of Construction Engineering and 
Management, ASCE, 134(9), 721-728. 
Nocedal, J., and Wright, S.J. (2000). Numerical Optimization, 2nd edition, Springer, 
New York, 264-266. 
Pathak, B.K., Srivastava, S., and Srivastava, K. (2008). “Neural network embedded 
multiobjective genetic algorithm to solve non-linear time-cost tradeoff problems 
of project scheduling.” Journal of Scientific and Industrial Research, 67(2), 
124-131. 
Perera, S. (1980). “Linear programming solution to network compression.” Journal of 
the Construction Division, ASCE, 106(3), 315-326.  
Perry, C. and Grieg, I.D. (1975). “Estimating the mean and variance of subjective 
distributions in PERT and decision analysis.” Management Science, 21, 
1477-1480. 
Phillips, S. and Dessouky, M. I. (1977). “Solving the project time/cost tradeoff 
problem using the minimal cut concept.” Management Science, 24, 393–400. 
Project Management Institute (PMI) (2008). Project management book of knowledge, 
4th edition, Project Management Institute, Drexel, Pa. 
Reda, R.M. and Carr, R.I. (1989). “Time-cost tradeoffs among related activities.” 
Journal of Construction Engineering and Management, ASCE, 115(3), 475-486. 
Salem, O., AbouRizk, S., and Ariaratnam, S. (2003). “Risk-based life-cycle costing of 
infrastructure rehabilitation and construction alternatives.” Journal of 
Infrastructure Systems, 9(1), 6–15. 
Schexnayder, C., Knutson, K., and Fente, J. (2005). “Describing a beta probability 
 22 
 
 
Zayed, T.M. and Halpin, D.W. (2005). “Productivity and cost regression models for 
pile construction.” Journal of Construction Engineering and Management, ASCE, 
131, 779-789. 
Zheng, D.X.M., Ng, S.T., and Kumaraswamy, M.M. (2005). “Applying Pareto 
ranking and niche formation to genetic algorithm-based multiobjective time–cost 
optimization.” Journal of Construction Engineering and Management, ASCE, 
131(1), 81-91. 
 
 24 
 
 
Table 2. Correlation structure 
 
  Pairwise correlation 
Correlation 
coefficient 
Time vs. Time 
T2-T5 0.5 
T4-T6 0.8 
T4-T7 0.8 
T6-T7 0.8 
Cost vs. Cost 
C2-C5 0.8 
C4-C6 0.8 
C4-C7 0.8 
C6-C7 0.8 
Time vs. Cost 
T1-C1 0.7 
T2-C2 0.8 
T3-C3 0.6 
T4-C4 0.7 
T5-C5 0.6 
T6-C6 0.7 
T7-C7 0.8 
 26 
 
 
 
 
Fig. 1. Correlation matrix with four sub-matrices 
 28 
 
 
 
 
Fig. 3. Solutions in objective space (deterministic) 
 30 
 
 
Generate initial swarm
Set V, pBest, gBest
Register solutions 
to Archive
Perform correlated MCS
Evaluate project duration 
and cost
Use Archive to update 
pBest and choose gBest
Generate new solutions
Perform correlated MCS w/ 
prescreening strategy
Evaluate project duration 
and cost
Update Archive
Is premature 
convergence detected? Yes
Apply turbulence 
operator
Is stopping criteria met?
No
No
Report Archive as the 
nondominated solution set
Pilot run to determine 
PSO tuning parameters 
and MCS sample size
Yes
 
 
Fig. 5. Flow diagram 
 32 
 
 
1. Site preparation 7. Erect girders
6. Deliver PC girders
5. Pour foundation 
and Piers
4. Precast concrete 
girders
3. Excavation
2. Forms and Rebars
 
Fig. 7. Example network 
 34 
 
 
$100,000
$110,000
$120,000
$130,000
$140,000
$150,000
$160,000
$170,000
$180,000
60 70 80 90 100 110 120 130 140 150
Project duration (days)
C
os
t (
$)
Proposed algorithm Enumeration
 
 
Fig. 9. Proposed algorithm vs. enumeration 
 36 
 
 
T > 90.00
0.8 %
Mean=81.43
0
0.02
0.04
0.06
0.08
0.1
0.12
65 70 75 80 85 90 95
Project duration (days)
 
 
C > 120,000
2.1%
Mean=$109,490.5
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
95 100 105 110 115 120 125
Cost in thousands
 
(a) PDF of project duration         (b) PDF of direct cost 
 
Fig. 11. Probability distribution functions of time and cost (solution 7) 
 38 
 
 
95.90 , $124,270.50
89.32 , $126,552.37
$90,000
$100,000
$110,000
$120,000
$130,000
$140,000
$150,000
$160,000
$170,000
$180,000
$190,000
60 70 80 90 100 110 120 130 140 150
Project duration (days)
C
os
t (
$)
direct cost total cost total cost+penalty
 
 
Fig. 13. Scenarios in determining the best plan 
 
 
