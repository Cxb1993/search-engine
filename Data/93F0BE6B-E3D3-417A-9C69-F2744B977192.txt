究與實作 
合作企業簡介 
合作企業名稱：明瑞企業股份有限公司 
計畫聯絡人：陳水明 
資本額：500 萬元 
產品簡介：電腦軟硬體設備、電子測試儀器與視聽教學設備等。 
網址：http://23603405.aloha.com.tw/   電話：(02)29318117 
研究摘要(500 字以內)： 
垃圾郵件氾濫於今日，造就各種防堵機制群雄並起，而在內容過濾比對法中又以機械學習
理論的支援向量機(Support Vector Machine, SVM)與貝氏演算法(Naïve Bayes)最為出色。故
本研究論文主要擷取 SVM 以超平面快速分類的特點及貝氏演算法的彈性，設計規劃一套兩
階層式之垃圾郵件過濾機制。本研究的實驗樣本採用中、英文郵件訓練樣本各 1000 封，以
及測試樣本各 200 封，於中文斷詞、英文斷字後，再以 Information Gain 計算結果決定 SVM
訓練之關鍵字。最後將 SVM 對測試樣本之分類結果，以本論文定義的四種邊界距離挑選出
落於模糊區間的郵件樣本，經由本研究提出之貝氏機率改良模型進行計分以判斷郵件類
別。研究結果呈現四種邊界距離擷取出資料再計算後的準確率皆有所提升，其中又以最大
距離(Maximum Distance)或平均距離(Average Distance)的改善最顯著；若加上在最佳化模式
的預測下，中、英文樣本整體分類的精確度(Accuracy)皆達 97%以上，因此可驗證本研究提
出之兩階層式過濾機制與貝氏演算法改良模型的可行性與貢獻度。 
 
人才培育成果說明： 
對 Linux 及 Mail server 有深入了解。 
對 Machines Learning 上著名的方法，如 SVM、Genetic Algorithm 與 Association Rule
有深刻體會。 
學習如何將上面理論的觀念轉為實際可應用的系統。 
對文件(郵件)分類有實作經驗。 
對竄改郵件及中英文郵件不同(如何)處理的經驗。 
訓練如何從事研究、尋找問題最佳解決的方法。 
訓練参與人員及早預備就業能力 
 
技術研發成果說明：中、英文樣本整體分類的精確度(Accuracy)皆達 97%以上，因此可
驗證本研究提出之兩階層式過濾機制與貝氏演算法改良模型的可
摘要 
 
垃圾郵件氾濫於今日，造就各種防堵機制群雄
並起，而在內容過濾比對法中又以機械學習理論的
支援向量機(Support Vector Machine, SVM)與貝氏
演算法(Naïve Bayes)最為出色。故本研究論文主要
擷取 SVM 以超平面快速分類的特點及貝氏演算法
的彈性，設計規劃一套兩階層式之垃圾郵件過濾機
制。本研究的實驗樣本採用中、英文郵件訓練樣本
各 1000 封，以及測試樣本各 200 封，於中文斷詞、
英文斷字後，再以 Information Gain 計算結果決定
SVM 訓練之關鍵字。最後將 SVM 對測試樣本之分
類結果，以本論文定義的四種邊界距離挑選出落於
模糊區間的郵件樣本，經由本研究提出之貝氏機率
改良模型進行計分以判斷郵件類別。研究結果呈現
四種邊界距離擷取出資料再計算後的準確率皆有
所提升，其中又以最大距離或平均距離的改善最顯
著；若加上在最佳化模式的預測下，中、英文樣本
整體分類的精確度皆達 97%以上，因此可驗證本研
究提出之兩階層式過濾機制與貝氏演算法改良模
型的可行性與貢獻度。 
關鍵詞：垃圾郵件、支援向量機、貝氏演算法、
Information Gain。 
 
Abstract 
 
Support Vector Machine (SVM) and Naïve 
Bayes are well-known machine-learning algorithms 
for the application of content filtering against spam. 
On the basis of fast classification through the 
hyper-plane of SVM and flexible threshold setting of 
Bayes, in this thesis we proposed a two-tier filtering 
scheme which combine SVM and new Naïve Bayes 
model for anti-spam. In the first tier, Information Gain 
is the way to decide keywords for training vector of 
SVM. This thesis also defines four margin of the 
hyper-plane and pick out the testing data which locate 
on the scope for the second tier Bayesian probability 
calculation, in order to decide the category of sample 
data. As the results of our research which indicated 
that all kinds of the margin setting bring the improved 
accuracy (Accur) about 1%~4%, especially the 
Maximum Distance and Average Distance Margin. 
Additionally, the optimal model performs the total 
accuracy of Chinese and English data above 97%. 
However, the proposed two-tier filtering scheme and 
new Naïve Bayes model were verified with 
availability and contribution. 
Keywords: Spam, SVM, Naïve Bayes, Information 
Gain. 
 
1. 前言 
 
透過電子郵件所衍生出的變相問題，不外乎是
早期的「病毒郵件」以及現今吵得沸沸揚揚的「垃
圾郵件」。而此二者又能相互結合，當病毒郵件使
一台電腦中毒，病毒作者再將中毒電腦名單販賣給
垃圾郵件發送者，使其利用這台電腦當作跳板來發
送垃圾郵件，形成一加一大於二的危害。這種病毒
郵件與垃圾郵件交相賊的情況，令病毒為垃圾郵件
創造更多機會，至少已有超過 30%的垃圾郵件都是
透過此種中毒電腦的方式來發信[1]。然而目前各防
毒廠商偵測病毒的技術成熟，更新病毒碼之效率已
臻於快速且穩定，從發現新病毒到釋出新病毒碼時
間相差不會大於八小時，故對於病毒信件的攔截，
防毒軟體已可做到幾近完善；但針對「垃圾郵件」
的防堵，由於人人對信件的合法性與非法性的定義
不同，因此沒有百分之百精確的方法。可是對於大
多數人而言，只要郵件信息本身有其「目的」，有
想要表達廣告、商業的意圖和立場，皆會認定其為
「垃圾郵件」。然而在過濾垃圾郵件的方法中，以
機器學習理論而言，由於訓練方式與演算方法的不
同，造就出精確率的結果就不盡相同。本研究主要
目的即在於提出一結合Naïve Bayes與 SVM兩種演
算法，先以 SVM 做初步分類，將落入模糊區的郵
件交由 Bayes 進行機率判斷並給定分數，如此對郵
件作兩階層式的分類，期望提高過濾垃圾郵件的精
確率，降低錯分正常郵件的誤判率，亦即發揮一加
一大於二的效果[2][3]。 
本論文共五個章節。第一章簡述本研究之動
機、背景與目的。第二章介紹一般的垃圾郵件判別
過濾方法，包括 RBL、DCC、Razor、Pyzor、Naїve 
Bayes、SVM 等。第三章則詳述本研究論文之實作
方法，包括結合 SVM 與貝氏演算法的兩階層過濾
方式及其流程。第四章將呈現本系統效能分析的結
果。第五章則歸納研究結果並提出未來後續研究發
展的方向。  
 
2. 相關研究與技術 
 
本章將介紹目前常見之垃圾郵件判別與過濾
的方法和理論，分別是即時性黑名單(Real Time 
Black-hole Lists, RBL)、DCC、Razor、Pyzor、支援
向量機(Support Vector Machine, SVM)和貝氏演算
法(Naïve Bayes)等[2][5][6]。  
 
2.1 即時性黑名單 
 
面對全球 Spammer 每日更迭的 IP 位置、主機
名稱，網路上已有專門收集資訊，建立完整黑名單
資料庫，稱作「即時性黑名單」(Real Time Black-hole 
Lists, RBL)，各郵件伺服器可透過即時查詢 RBL 的
資料以判斷郵件是否為垃圾郵件來源，而後決定是
否拒收相應的郵件。然而目前線上即時黑名單之管
理制度寬鬆不一，寬者即將對方加入黑名單前會主
動發信通知 SPAM 的郵件主機管理者，要求改善；
若主機管理者遲遲未處理，才會將該主機列入黑名
代表在給定
jC 類別的前提下， kW 出現在 jC 類別的
比率（「出現關鍵字
kW 的信件數」除以「該類別的
總信件數」所得的條件機率）。而 ),,,( 21 mWWWP L
代表關鍵字 kW 出現在全部總文件的機率。 
分類器依下式將文件 d 歸類為 kC 類（設 kC 為
某一已知類別），則從 d 在各類別得到機率的最大
值，來判斷其所屬類別，如式(2)所示： 
),,|(),,|( 21...121 mjNjmk WWWCPMaxWWWCP LL ==    (2) 
貝氏演算法在郵件系統的應用十分廣泛，許多
著名軟體如 SpamAssassin 已內嵌經此方法作垃圾
郵件的過濾。其最大優點在於經由貝氏演算法計算
後，會針對郵件產生一組易於識別機率分數，屆時
與使用者於郵件伺服器所設定之門檻值比對，若分
數超過門檻值，則判定此文件為垃圾郵件，而門檻
值又可依經驗設定，若發覺過濾器誤刪太多正常信
件，可以將門檻值訂得較為寬鬆，對個人化而言，
貝氏分類法算是較彈性的一種規則[3]。 
 
3. 兩階層式的過濾機制 
 
本研究論文主要是設計一兩階層式垃圾郵
件過濾機制，取 SVM 分類演算法所能形成之模
糊區間，及其快速分類的特性；搭配貝氏演算
法透過樣本的大量建立，提高機率分數給予之
準確性，期望二者的結合優於單一演算法，展
現更佳的過濾效能。  
在郵件樣本的選取上，分為訓練樣本與測
試樣本。訓練樣本旨在做為 SVM 關鍵字之挑選
以及貝氏關鍵字資料庫的建立。挑選上依目前
一般使用者收到信件類別的比例，垃圾郵件比
正常郵件為 4：1，故在英文郵件的訓練樣本中
垃圾郵件為 800 封，正常郵件 200 封；中文的
訓練樣本亦以垃圾郵件 800 封，正常郵件 200
封進行訓練。測試樣本的數量，中英文郵件皆
為垃圾郵件與正常郵件各 500 封，共 1,000 封進
行 測 試 。 樣 本 來 源 方 面 ， 英 文 郵 件 使 用
Ling-spam、TREC Spam Corpus 以及個人收集之
混合型樣本；中文郵件則為收集多位使用者信
件之混合型樣本，其中測試樣本與訓練樣本為
個別收集，刻意避免文件之重複，最後進行效
能分析評估。  
本機制之流程主要為程式訓練、挑選 SVM 關
鍵字、SVM 分類、決定 SVM 分類後模糊區間範圍，
以及貝氏演算法計算機率分數等，以下將詳述其步
驟程序。 
 
3.1 訓練關鍵字 
 
由於辭典式斷詞法須具備一龐大資料庫，
且須人工建立，定期維護、更新，加上中研院
CKIP 斷詞軟體價格高昂，故本研究訓練關鍵字
的方式主以統計式斷詞法的概念，於程式紀錄
字詞出現次數，包括在垃圾郵件中出現次數、
正常郵件出現次數、垃圾郵件中出現封數，與
正常郵件出現封數等資訊。其中「出現封數」
為關鍵字在不同郵件類別出現過的封數紀錄，
可適用於決定 SVM 分類的 Information Gain 關
鍵字挑選條件，以及貝氏資料庫中關鍵字機率
分數的紀錄[7]。  
   在關鍵字的擷取方面，中英文樣本方法不一。
英文主要以空白字元或標點符號來決定欲擷取單
字之位置，而後挑選出來做次數、封數的紀錄。由
於語文的特性，英文在資訊索引上較容易識別，且
單字通常即可代表完整意義，故關鍵字的決定則以
其在文件中出現之次數、封數的頻率為主。然而有
些單字出現頻率甚高，但其具備「關鍵」字特性的
地位並不高，例如人稱代名詞、連接詞、定冠詞等，
可濾過不需比對。 
至於中文字詞的擷取，由於一個全形中文字大
小為 2bytes，且文句中字與字，或詞與詞間並沒有
明顯的空白或標點符號隔開，加上目前的中文郵件
事實上多屬中英文夾雜信件 (英文字母大小為
1byte)，故在斷詞方法上本研究先以 ASCII 碼比對，
分離出英文或中文字，而後再進行英文關鍵字的訓
練，以及中文字串的斷詞，紀錄其出現次數與封
數。針對中文斷字本研究於程式中並無使用類似
CKIP 的文字資料庫，主要原因在於其所佔空間與
資源量大、申請價格高昂、對詞庫判斷依賴性高(若
詞庫沒有相同的詞句，則全部斷成一個個單獨的中
文字)；本研究以每兩個中文字做斷詞，蓋因中文
多以二字組合即具詞意，超過二個字以上的詞句，
實際上也以二個字為基本單位。另外，以每兩個字
做斷詞或許有些詞不具意義，但在樣本數量足夠的
訓練情況下，具備意義的關鍵字排名亦會超越前
序。 
 
3.2 關鍵字轉換 SVM 特徵向量 
 
經由 Information Gain 計算關鍵字分數後，本
研究分別擷取「垃圾信關鍵字」與「正常信關鍵
字」，而擷取的方向分為二： 
(1). Overlapping Keywords: 垃圾信關鍵字的條
件為其出現在垃圾信的封數大於在正常信出現之
封數，且依 Information Gain 值由大至小排序，取
前 100 名；同樣的正常信關鍵字為其出現在正常信
之封數大於在垃圾信出現的封數，依 Information 
Gain 值排序取前 100 名，然而在訓練樣本中，正常
信為 200 封，加上一般正常信的性質為字數較少、
無特定類別，因此最後訓練出來符合上述條件的正
常信關鍵字自然比垃圾信關鍵字數量少。故在此中
文信件所使用的關鍵字共 132 個，英文信共 136 個。 
(2). Independent Keywords: 垃圾信關鍵字條件
為其在正常信件中出現次數為 0 者，再依
Information Gain 值排序挑選前 100 名；正常信關鍵
件之機率分數，之後針對從SVM模糊區間挑選出的
資料，以貝氏資料庫關鍵字的機率分數作運算，並
預設一門檻值分數，判斷其為垃圾抑或正常郵件。 
根據貝氏演算法，任一關鍵字經由計算後所得
之機率分數，可視其為一獨立事件，可對其作數學
運算。以一關鍵字「專業」為例，其在垃圾郵件樣
本中出現的機率為 0.8889，在文件類別只有二種的
情況下，「專業」相對於出現在正常郵件樣本中的
機率即為 0.1111。在此很明顯可看出此關鍵字出現
在垃圾郵件的機率較高，故此關鍵字可獲得一機率
分數 0.8889-0.1111=0.7778，且隸屬於垃圾信的關鍵
字，同樣的方法亦可建立一套正常信的關鍵字機率
分數。 
獲得上述貝氏關鍵字機率分數資料庫後，針對
待測郵件的記分，本研究提出四種記分方式，即貝
氏機率演算方式之改良，其中 P (Wi)為垃圾信關鍵
字之機率分數，P (Wi’)為正常信關鍵字之機率分
數，Ni為關鍵字在單一文件中出現之次數： 
 
(1). 
i i
i i
P(W ) P(W ')−∏ ∏  
(2). 
i i i i
i i
P(W )* N P(W ')* N '−∏ ∏  
(3). 
i i
i i
P(W ) P(W ')−∑ ∑  
(4). 
i i i i
i i
P(W )* N P(W ')* N '−∑ ∑  
   
4. 研究結果分析 
 
首先對英文郵件之SVM訓練過程為將訓練樣
本800封垃圾信與200封正常信轉化為特徵向量
後，交由grid.py程式訓練，找出最佳-c值與-g值，
以產生最適之model檔案提供未來測試工作。 
第一階段在垃圾郵件關鍵字與正常郵件關鍵
字之間相互獨立情況下(Independent Keywords)，以
Information Gain挑選109個特徵值，轉換向量後得
出最佳-c值為2048，-g值為0.0004882，對負極資料
被錯分的懲罰度為5，之後會產生一個model檔，再
將原本訓練檔案當作測試檔案，以svmpredict.exe程
式進行前測。接著以垃圾信關鍵字與正常信關鍵字
間不相互獨立之關鍵字(Overlapping Keywords)所
產生的136組特徵向量，經由grid.py訓練得出最佳-c
值為32，-g值為0.001953，同樣-w值為5，接續以之
產生model檔，並再次進行前測。分析結果以
Overlapping Keywords作為特徵向量的分類平均準
確性較高，如圖1所示(SP為精確率、SR為召回率、
Accur是準確率、Err是錯誤率)。 
 
0%
10%
20%
30%
40%
50%
60%
70%
80%
90%
100%
SP SR Accur Err
Independent Keywords Overlapping Keywords
 
圖 1 英文關鍵字於 SVM 前測結果比較 
 
至於中文信件則以訓練樣本中垃圾郵件關鍵
字與正常郵件關鍵字相互獨立的 Independent 
Keywords 特徵值，轉換為每筆資料 111 向量，以訓
練樣本 1000 筆資料作前測，最佳-c 值為 2048，-g
值為 0.0004882，對負極資料被錯分的懲罰度-w 為
5 。接著以訓練樣本中關鍵字不相互獨立的
Overlapping Keywords，經 Information Gain 計算找
出 132 個關鍵字，轉化成向量對原本訓練樣本再進
行前測，最佳-c 值為 32768，-g 值為 0.000122，-w
值亦為 5。同樣地在中文信件的前測結果中，以
Overlapping Keywords 作為特徵值分類之準確度較
高，如圖 2 所示。 
 
0.00%
10.00%
20.00%
30.00%
40.00%
50.00%
60.00%
70.00%
80.00%
90.00%
100.00%
SP SR Accur Err
Independent Keywords Overlapping Keywords
 
圖 2 中文關鍵字於 SVM 前測結果比較 
 
最後，呈現經過 SVM 分類出之後，把所有錯分
的信件完全地挑選出交由貝氏法進行機率演算，視
其能否驗證兩階層式過濾方法在最佳化的情況
下，準確率能有效提升。 
原先 SVM 對 1,000 封測試英文郵件的分類結
果已於圖 2 呈現，在最佳化的前提下，將所有錯分
信件挑選出來，交由第二層貝氏運算，英文郵件即
是以
i i i i
i i
P(W )* N P(W ')* N '−∑ ∑ 演算法來進行貝氏
機率分數之判定，其得到效能之提升結果如圖 3 所
示，可明顯看出運用兩階層式過濾法的結果與原本
單一 SVM 相比，各評估指標包括精確率(SP)、召回
