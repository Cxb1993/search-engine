image forensic becomes more and more important. 
However, the both roles - image forgery and image 
forgery detection can be viewed as the hackers and 
system administrators in the information security 
area. The never-ending war for attacks and defenses 
will keep on. To design a good image forensics 
system, we must first understand the various means of 
image forgery. In contrast, a powerful image forgery 
technique should forging images as far as possible be 
detected without leaving traces.  
  The main purpose of the plan is to develop a new 
method to do the copy-move forgery detection. In this 
study, a rotation robust forensics approach for 
detecting copy-move forgery is proposed. Two 
descriptors, corner histogram and grayscale histogram 
under different size of circles were presented as 
feature vectors. Then, a matching step is performed 
to determine the candidate corner pairs using the 
feature vectors. Finally, a forged image decision 
scheme is proposed. The experimental results show 
that our method is reasonably robust to general and 
rotation copy-move post processing. 
 
英文關鍵詞： digital forensic, copy-move detection, image forgery, 
Harris coner detection, Region-Filling 
 
 2 
Image 
Forensics 
Image Source 
Identification 
Source-
Model 
Identification 
Individual 
Source 
Identification 
Identification 
of Synthetic 
Images 
Image 
Forgery 
Detection 
1) pixel-
based 
techniques   
2) format-
based 
techniques  
3) camera-
based 
techniques 
4) physically 
based 
techniques 
5)geometric-
based 
 
圖1、影像偽造與偽造偵測技術的攻防 
美國紐約大學 J. Fridrich 教授不僅是多
媒體安全領域的專家，從 2002 年起就利用
數位相機 CCD 上 sensor 裝置的取樣特性，
成功發展出可以辨識影像來源(哪一台相機
所拍攝 )的方法，另外她也致力於利用
JPEG 影像 DCT 量化方式的特性，發展出
以區塊為基礎的影像鑑識方法。H. Farid 可
以說是現今國際上影像鑑識的權威之一，
他在影像鑑識領域上的研究近三年的產出，
超過 50 篇學術論文。美國哥倫比亞大學
S.F. Chang 教授等人認為，影像鑑定演算
法可以粗略分成主動式與被動式兩大類，
所謂主動式的影像鑑識方式即是利用資料
隱藏方法是將額外的資訊嵌入影像之中，
這一類的研究通常被歸屬在數位浮水印的
範疇內。在這類機制中，在資料來源端(例
如數位相機)嵌入一個數位浮水印，然後在
驗證端藉由偵測及檢視抽回之浮水印品質
來判斷影像是否遭到偽造竄改。為達到上
述驗證的目的，所嵌入的浮水印在影像被
應用過程中與影像是不可分離的，它將與
影像一起被傳輸、儲存或處理。這是種破
壞性內容改變方式，但經改變影像後影像
的外觀品質不致被人眼所識破，經浮水印
嵌入後的影像，被修改或是偽造合成時，
就可以偵測出哪些區塊被竄改，這類方法
已經有非常多的演算法被提出。 
  第二類的方法稱為被動式或是盲目的影
像鑑識方式，就是進行影像鑑識時，除了
待測試的影像外，沒有任何有關此影像的
資訊或是註冊資料可以參考，鑑識者必須
由單一影像的訊號中，進行影像特徵分析
以決定該影像是否已經遭受到竄改或偽造
的目的。這類方法的設計必須先了解偽造
影像的手法以及影像取像的原理，其主要
的概念在於偽造或修改影像時會對原影像
造成可偵測出的變化，例如統計上的變化。
Sencar 等人將數位影像鑑識的方法分成三
類 ； Image Source Identification, 
Identification of Synthetic Images 和 Image 
Forgery Detection，而 Farid 又將 Image 
Forgery Detection 細分成五種方法： (1) 
pixel-based(2)format-based (3)camera-based 
(4)physically-based (5)geometric-based 的技
術。我們整合兩人的分類，成為圖 2 的研
究方法分類架構。 
 
 
   
 
圖 2、影像鑑識方法分類架構(本研究整理)。 
然而要研發優良的影像鑑識技術，必須
要深入了解目前影像合成時常使用的處理
方式與技術，這就像是資訊安全的攻擊與
防守，駭客與系統安全管理者之間的戰爭，
要想研發功能較好的影像假造偵測系統，
必須先研究影像合成的技術。 
在數位圖像上進行偽造是相當容易的，只
需在相同圖片上複製貼在想竄改的地方，
即可完成一張假造影像。底下為簡單的利
用 copy-move 的假造影像例子。 
 4 
心，以 ri 為半徑，記錄每一個 Ri 內灰階亮
度的直方圖，也被採用當作特徵，描述如
下： 
                     
      
 
   
 
                  (4) 
 
之後即可推導出下列複製區域偵測演算法，
步驟如下： 
 
Image Forgery Detection Method 
Step 1: Compute the coordinate distance between the 
two signature points (pi,pj) which have the 
most smallest matching distance in image I by 
applying equation (3) to check all the 
candidate corners. Assume the length of           
is γ, we can construct two groups, G1 and G2, 
with            . 
Step 2: Another pair of corners (px,py) can be involved 
into the group G1 and G2, respectively, if they 
satisfy the following rule: 
                                         
                           (5) 
Step 3: Assume there are totally M pairs of signature 
points which are selected into G1 and G2, 
compute the diameters of G1 and G2 denoted 
as Diameter(G1) and Diameter(G2), 
respectively. The Diameter(G) is demoted as 
the longest distance of two different signature 
points in G. Then, image I can be said to be 
forged if the following condition is satisfied: 
             
                             
 
      (6)                          
 
 
 
 
 
   (a)                  (b) 
圖5、執行所提出方法的實驗結果(a)原始
結果(b)去除稀疏的match line。 
如圖5所示，因為影像中存在許多相似的特
徵點(連附近環境都類似)，但是在copy-
move的物件上，相對的這些match lines會
較密集，所以我們可以訂一個門檻來過濾
稀疏的match line，如圖5(b)所示。 
四、實驗結果與討論 
為了評估所提方法的效能，如圖6所示，首
先進行區塊的複製，原始區塊中包含一個
特徵點Pr，當作參考點，兩種方式(a)copy-
move只有位移  (b)copy-rotation-move包含
位移與旋轉，用來檢視所使用特徵直方圖
是否可以有效偵測，由圖6(c) 圖6(d)可知，
P37與P63擁有最低的距離，代表所使用特徵
直方圖的確可以準確的尋找到被複製的區
塊。 
 
(a) (b)                          
Pr P37 Pr P63 
 6 
 
Void Regin_Fill(int x1,int y1, int x2, int y2) 
{ 
 if  (Similarity(x1,y1,x2,y2)>= threshod)  
 { 
  Mark(x1,y1,x2,y2,r); // Draw 2 circular regions 
   ψ=θ+π/2; 
Region_Fill(x1+r*cos(θ), y1+ r*sin(θ), x2+ r, y2); 
  Region_Fill(x1- r*cos(θ), y1- r*sin(θ), x2-r , y2); 
  Region_Fill(x1+r*cos(ψ), y1+ r*sin(ψ), x2, y2+r); 
  Region_Fill(x1-r*cos(ψ), y1- r*sin(ψ), x2, y2-r); 
 } 
} 
 
 
假設已經找到兩個相似特徵點P1(x1,y1)與
P2(x2,y2)，上述所提遞迴演算法的概念是，
每次動作，採用四個方向往鄰居以r個像素
長度拓展(P1以θ，P2以上下左右)，如果P1 
P2拓展出去的區塊(r為半徑)相似度大於門
檻值，則將此兩個對應區塊塗色，然後持
續呼叫下一次動作。直到到達圖片邊界或
是不再相似為止，如此即可尋求最大相似
的兩塊區域，如圖9所示， 
 
 
 
 
 
 
 
 
圖9、Region-Filling演算法示意圖。 
 
 
 
 
 
 
 
利用所提改良式Region-Filling的演算法，
我們成功地將複製區塊給描繪出來。圖10
與圖11為兩個實例。 
 
 
 
 
 
 
 
 
 
圖10、結合特徵點偵測與改良式Region-
Filling演算法的複製區塊偵測結果。 
 
 
圖11、結合特徵點偵測與改良式Region-
Filling演算法的複製區塊偵測結果。 
 
 
 
 
 
 
 
 
 
P1 
P2 
 
θ 
到國內其他學校來參加的學者，包含如中山大學、雲科大、東華大學等校的教授或博士
班學生，透過彼此研究心得與研究環境的交流，藉由其他學者所提問的問題，激發出更
多的研究動機與方向，對於自己後續研究有實際助益。 
  
與會心得 
這次會議地點在札幌世貿中心舉行，會場環境十分寬廣舒適，在出席會議的這幾天，
參觀下來，不論是戶內或戶外公共場所，就連地鐵、火車站都看不到垃圾桶，自己的垃
圾必須帶回旅館才能丟棄，但是整體環境仍舊維持的十分乾淨，可見到日本人守紀律的
精神。另外大陸這些年在資訊領域上的進步有目共睹，這次研討會也有許多篇論文發表，
尤其近幾年大量舉辦國際研討會，同時送出許多碩博士留學生並發表大量論文。可見在
資訊學術領域上，台灣的優勢漸漸消失，大陸、韓國已逐漸超越台灣，希望政府多多鼓
勵學者出國留學與發表論文，才能感受到國際上尤其是亞洲的學術競爭氣息，並藉由參
與國際學術活動，刺激研究動機以增強競爭力。 
 
  
 
攜回資料名稱及內容 
會議論文光碟片一片，研討會論文一冊。 
 
 
 
 
 
 
 
 
 
  
Yoshikazu MIYANAGA Hokkaido University, Japan  
Sung-Jea KO Korea University, Korea  
Prabhas CHONGSTITVATANA Chulalongkorn University, Thailand  
 
ITC-CSCC 2012 Technical Program co-Chairs 
Takayuki NAKACHI NTT, Japan  
Hyun Wook PARK KAIST, Korea  
Prayoot AKKARAEKTHALIN KMUTNB, Thailand 
 
 
 
of this algorithm would be yielding a complexity of O(N log 
N). But it still very time consuming. 
Recently, Amerini et, al.[10] proposed a fast method based 
on the use of SIFT features. Their approach can reliably 
detect if a certain region has been duplicated and, furthermore, 
determine the geometric information applied to perform such 
tampering. However, their method still needs about 5 seconds 
to deal with a test image of size 800×600 and it is not 
practical for some real-time applications.  
In this study, we used Harris corners and defined two 
feature histograms, named corner and grayscale histograms, 
as feature vectors for matching different regions in an image. 
We also proposed a forgery decision scheme to improve the 
executing time.  
II. THE CORNER AND GRAYSCALE HISTOGRAMS 
To represent a region effectively and discriminatively is an 
important issue in developing invariant local descriptors. The 
proposed scheme considers a histogram-based representation 
of the corner point numbers in the local region around each 
corner point. We assume that several corners have been 
detected from an image I. For each corner pc, in the center of 
circular region Ri, the corner point histogram PH is denoted as  
 
                     ,                                           (1) 
 
Where ni is the number of corner points located in the circular 
region Ri centered with Pc, Fig.1 shows the diagram of the PH 
descriptor and the center of the coordinate is the corner point 
Pc.                                 The corner point histogram 
PH can be used as the feature vectors to compute the 
similarity between different corners.  
 
 
 
 
 
 
 
 
Fig. 2: The diagram of the PH descriptor. 
 
Assume a set of corner points              with their 
corresponding PH descriptors {PHp1,PHp2,…,PHpN} is 
extracted from a test image. A matching operation is 
performed among the PH vectors of each corner to identify 
similar local patches in the test image. 
 
However, the PH descriptor alone may not work well for any 
case since it lacks content information. We define another 
descriptor using the grayscale information. For each corner pc, 
in the center of circular region Ri, the grayscale histogram GH 
is denoted as  
                      
      
 
   
 
                                       (2) 
 
Where N is the number of pixels in Ri and f(pk) is the gray 
value of pk. 
Then, we can define the distance between two corner points 
for corner point matching as: 
 
                                                           (3) 
 
Where D(,) is the Euclidean distance. Then we can obtain a 
set of matched points using equation (3) to perform the 
matching operations. However, it can happen images that 
contain areas with very similar texture yield matched corners 
that might induce false alarms.  Therefore, a proper choice of 
the distance threshold Th is required to determine an effective 
match between those corner points. 
III. FORGERY DECISION 
The matching process of similar corners is not enough for 
forgery detection since most of the natural images would have 
many similar regions. The forgery decision can be made only 
if there are more than a certain number of corner points that 
are connected to each other within a small range of distances. 
Therefore, we develop a simple scheme to detect image 
forgery based on the Harris corners invariant properties. The 
Harris corner detection is based on a local structure matrix 
which is smoothed by a Gaussian filter and can be denoted as 
 
               
 
  
  
  
  
  
  
  
  
  
  
  
 
  
  
  
                                     (4) 
Where      is a Gaussian filter with standard deviation   
and the operation * denotes convolution. Then the measure of 
corner response at each pixel coordinates (x,y) can be defined 
by 
 
                                
                   (5) 
 
Where k is an adjustable constant and              is the 2×
2 local structure matrix at coordinates(x,y). Points having a 
Harris response greater than a pre-specified threshold are 
selected as feature points. We sort these feature points in 
decreasing order of Harris response and select N points with 
the maximum responses for signature extraction. Corner 
points by Harris filter are considered as robust to general 
geometric attacks. Therefore, a forgery detection algorithm is 
proposed using Harris corners and is described as follows: 
Step 1: Compute the coordinate distance between the two 
signature points (pi,pj) which have the most smallest 
matching distance in image I by applying equation (3) 
to check all the candidate corners. Assume the length 
of           is γ, we can construct two groups, G1 and G2, 
with            . 
Step 2: Another pair of corners (px,py) can be involved into 
the group G1 and G2, respectively, if they satisfy the 
following rule: 
                                     γ              γ         (6) 
 
ri 
Rj 
rj 
Ri 
pc 
   
(a)                                             (b)  
 
(c)                                            (d) 
Fig. 5: Examples of the forged image detection using the proposed method. 
 
(a) 
(b) 
(c) 
Fig. 6: Another example to show the matching corner pairs;(a)forged 
image by a copy-move operation (b)result of Harris corner detection(N=800) 
(c) result of the proposed method. 
 
 
V. CONCLUSIONS 
In this paper, a rotation robust forensics approach for 
detecting copy-move forgery was proposed. Two descriptors, 
corner histogram and grayscale histogram under different size 
of circles were presented as feature vectors. A forged image 
decision scheme combined with Harris corner detector and the 
usage of the two descriptors is proposed. Experimental results 
show that the proposed method is reasonably robust to general 
and rotation copy-move post processing.  
 
ACKNOWLEDGEMENT 
This work was supported in part by National Science Council, 
R.O.C., under grant NCS 100-2221-E-328-002. 
 
REFERENCES 
[1] V. Christlein, C. Riess and E. Angelopoulou, “On Rotation 
Invariance in Copy-Move Forgery Detection”, Proceedings of 
the 2010 Second IEEE Workshop on Information Forensics and 
Security, Seattle, USA,  Vol. 12,  pp.12.-15, 2010. 
[2] J. Fridrich, Defending Against Fingerprint-Copy Attack in 
Sensor-Based Camera Identification with M. Goljan and Mo 
Chen, IEEE Trans. on Info. Forensics and Security, vol. 6, no. 1, 
pp. 227-236, March 2011.  
[3] J. Fridrich, D. Soukal, and J. Lukas, "Detection of Copy-Move 
Forgery in Digital Images", Proc. Digital Forensic, Research 
Workshop, Cleveland, OH, August 2003. 
[4] C. Riess and E. Angelopoulou, "Illumination as an Indicator of 
Image Manipulation", International Workshop on Information 
Hiding, 2010. 
[5] T.T. Ng, S. F. Chang, C.Y. Lin, Q. Sun, Passive-blind Image 
Forensics, Elsevier, Hawthorne, NY, USA, 2006. 
[6] M. Arnold, M. Schmucker, S.D. Wolthusen, Techniques and 
Applications of Digital Watermarking and Content Protection, 
Artech House, Inc., Norwood, MA, USA, 2003.  
[7] C. Rey, J. L. Dugelay, A survey of watermarking algorithms for 
image authentication, EURASIP Journal on applied Signal 
Processing pp. 613–621, 2002. 
[8] H. T. Sencar and N. Melon,Overview of State-of-the-Art in 
Digital Image Forensics, 
       http://isis.poly.edu/~forensics/pubs/sencar_memon_chapter.pdf 
[9] H. Farid, Digital Forgery Detection-Survey, IEEE Signal 
Processing Magzine, 2009.  
[10] Amerini, L. Ballan, R. Caldelli, A. Del Bimbo, and G. Serra, "A 
SIFT-based forensic method for copy-move attack detection and 
transformation recovery," IEEE Transactions on Information 
Forensics and Security, vol. 6, no. 3, pp. 1099-1110, 2011. 
 
100年度專題研究計畫研究成果彙整表 
計畫主持人：吳美宜 計畫編號：100-2221-E-328-002- 
計畫名稱：利用影像裝置取像特徵於數位影像鑑識之研究 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 1 1 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 2 2 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 1 2 50%  
研究報告/技術報告 0 0 100%  
研討會論文 1 2 50% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
