I 
 
智慧型影像中人體姿勢分析之研究 
A Research on Intelligent Human Posture Analysis in Videos 
計畫編號：NSC 96-2221-E-214-061- 
執行期限：96 年 10 月 1 日至 97 年 7 月 31 日 
主持人：歐陽振森   義守大學資訊工程學系 
計畫參與人員：劉秀玲、楊翰霖、陳文玲、張曜麟 義守大學資訊工程學系 
 
 
中文摘要 
本計畫中，我們發展了一套智慧型影像中人體姿勢分析方法。首先，我們提出一個
基於局部模糊樣本紋理特徵之移動物件偵測方法，來對影像中移動之人體物件作偵測。
接著，將偵測所得之人體的遮罩，利用一自我組織映射類神經網路將此遮罩轉換成二元
樣本。利用所收集到多種姿勢的二元樣本來訓練一模糊類神經網路。之後，此模糊類神
經網路用以針對偵測所得之人體的二元樣本作姿勢之分類。我們主要的貢獻在於提出一
更具強韌性的局部模糊樣本之紋理特徵，使得在前景偵測所偵測到的人體物件更為準
確，且更適用於背景較為複雜的情況。此外，在人體姿勢分類問題上，我們採用具有學
習能力與強韌性之模糊類神經網路來做為人體姿勢特徵之學習與分類。 
 
關鍵詞：人體姿勢分析、移動物件偵測、局部模糊樣本、人體姿勢分類、模糊類神經網
路。 
 
Abstract 
In this project, we develop a technique of intelligent human posture analysis in videos. 
Firstly, we propose a moving object detection method based on LFP (local fuzzy 
pattern)-based textures, and use it to detect the moving human objects. Then, a 
self-organizing map neural network is used to transform the detected human object mask into 
a binary pattern. Finally, we train a fuzzy neural network using a collection of some kinds of 
human postures and use it to classify an unknown binary pattern of the detected human into a 
class of human posture. Besides, we adopt a fuzzy neural network with learning capability 
and robustness to learn and classify the human postures. 
  
Keywords: human posture analysis, moving object detection, local fuzzy pattern, human 
posture classification, fuzzy neural network
 
 
2 
 
時間內的像素值 產生一非參數式的機
率密度函數。如果目前的畫面之像素代
進去所得到的機率值小於設定之門檻
值，則該像素將被視為前景的像素。此
法之優點為可以為背景像素建立多個模
型，特別有利於那些有些許變化的背景
像素。 
第二類屬於靜態攝影機之遞迴式
方 法 。 近 似 之 中 間 值 濾 波 器
(approximated median filter)如 McFarlane
及 Schofield [6]提出一簡單之遞迴式濾
波器來估測中間值。其中間值估計的方
式甚為簡單，若輸入的像素值較估計值
大，則估計值加 1；反之，若輸入的像素
值較估計值小，則估計值減 1。最後，估
計值將趨近於中間值；卡曼濾波器
(kalman filter)是一種常用於解決移動物
追蹤問題的遞迴式方法。目前有許多以
Kalman filter 為基礎的背景模型建立方
法，不同之處主要在於所使用的狀態空
間。例如 :[7] 使用亮度值 (luminance 
intensity)、Karmann 及 von Brandt 等學
者 [8] 使用亮度及時間導數 (temporal 
derivative)、Koller 等學者[9]使用亮度及
空間導數(spatial derivative)。混合高斯
(Mixture of Gaussians; MOG) 如 N. 
Friedman 及 S. Russell [10]首先將混合高
斯運用在背景模型建立問題上。不同於
卡曼濾波器僅考慮單一高斯分佈，混合
高斯可以同時考慮多個高斯分佈。由於
此法是屬於參數式模型，因此不需另外
儲存一段影像資訊，而可以動態地更新
背景模型的參數。 
第三類屬非靜態攝影機的背景模
型。S. E. Chen 等學者[11]架設固定位置
的攝影機，以不同的角度拍攝，利用軟
體的方法比對，以建立 360 度的全景影
像 Y. Ren 等學者[12]使用空間上的高斯
分佈（spatial distribution of Gaussian）處
理攝影機受到風吹的微小震動。S. Kang
等學者 [13]使用鑲嵌式的方法（mosaic 
technique）將單一角度的影像投射出攝
影機各種不同仰（俯）角、側擺方向的
影像，運用各種角度的搭配計算出相似
的矩陣（homogeneous matrix），以比對
出相對應的位置，此法的好處是無須知
道攝影機的內部參數，如焦距等等，缺
點則是若攝影機轉動後，擷取到的影像
不是事前定義好的連續有交疊的影像
時，需要重新更新才能繼續偵測移動物
件，解決之道可採用廣角的攝影機，不
過也會有影像失真的問題。 
2. 人體姿勢分類 
目前，人體姿勢分類的方法可以分
成兩大類：基於二維之模型(2-D based 
model)及基於三維之模型 (3-D based 
model)。以下分別詳述這兩大類方法的
概念、優點、缺點、以及幾種代表性的
方法。人體模型(human body model)：此
法著重於建立完整且詳細之人體模型，
例如:紙板模型(card board) [14]。比較著
名的系統有 C. R. Wren 等學者所提出的
Pfinder [15]、I. Haritaoglu 等學者提出的 
[16]；人體輪廓分析 (human silhouette 
analysis)：此法算是最常被使用的方法之
ㄧ。H. Fujiyoshi 等學者[17]提出以最外
圍邊界點所組成的合成表示法-星狀骨
架(Star Skeleton)。I.-C. Chang 等學者[18]
使用型態學運算(morphological operation)
來擷取骨架，並用隱藏式馬可夫模型來
進一步處理。此外，其他方法如 S. Pinzke
等學者[19]及 J. Freer 等學者[20]使用了
類神經網路(neural network)的技術。M. 
Rahman 等 學 者 [21] 則 是 提 出 了
EigenSpace 的方法，雖較不受人體衣著
的影響，但其假設大部分的姿勢都已經
被學習，較不符合實際狀況。 
 
 
 
 
 
 
 
4 
 
))(),(,),2(),2(),1(),1((),( 101010 PtPtttttyxT K
r = (3)    
利用來進一步計算出局部模糊樣本 
12   ),,,,(),( 10 −== Pl lhhhyxh K
r
  (4) 
上式中 ),( yxh
r
的計算方式如下所示： 
∑
=
′
′
= l
i
l
l
l
h
hh
0
            (5) 
)()2()1( 21 Pttth Pbbbl ×××=′ K     (6) 
其中 pbbb K21 為一 p 位元之二進位數，
其十進位值為 l。 lh 表示該中心點的紋理
特徵值為 l的程度值。 
接著，以像素 ),( yx 為圓心，把半徑
regionR 內各鄰域像素所求得的 h
r
做加
總，得到一個 l維度的向量 ),(' yxh LFP
r
，
如下式所示： 
∑
∈
=
),()','(
' )','(),(
yxNyx
LFP yxhyxh
rr
     (7) 
其中 ),( yxN 以像素 ),( yx 為圓心，半徑
regionR 內各鄰域像素的集合。之後，將
),(' yxh LFP
r
作正規化後，得到最後的
),( yxhLFP
r
。 ),( yxhLFP
r
即代表像素 ),( yx
的模糊局部樣本直方圖，亦即表示該像
素的紋理特徵。 
1.3 建立背景模型 
每個像素 ),( yx 皆有 K 背景模型，表
示為 )},(),...,,(),,({ 21 yxmyxmyxm K
vvv 。每個
背景模型 ),( yxmk
v 都有一個相對應的權
重值 ),( yxkω 。一開始預設為前面五張畫
面對應位置所得到的模糊局部樣本直方
圖。 
1.4 前景偵測 
對於目前輸入之畫面，我們進行前
景偵測。對於每一像素 ),( yx ，我們將其
所求得之模糊局部樣本直方圖 ),( yxhLFP
r
與其對應之 B 個背景模型算歐式距離，
此 B 個背景模型乃是由原先 K 個當中選
取的。選取的標準乃是依照各背景模型
的權重值由大至小排列，且陸續加總，
若加總大於使用者定義的門檻值 BT ，則
選取這 B 個背景模型，如下式所示： 
[0,1]T   , B10 ∈>++ − BB Tωω K   (8) 
依照上述所得的 B 歐式距離值，將之與
門檻值 PT 做比較。如果全部的歐式距離
皆高於門檻值，則像素 ),( yx 為前景像
素；反之，則為背景像素。 
1.5 背景模型更新 
當像素 ),( yx 完成前景偵測步驟
後，接著還要利用其 ),( yxhLFP
r
做背景模
型更新。此時，我們是將其所求得之模
糊局部樣本直方圖 ),( yxhLFP
r
與其對應之
原先 K 個背景模型算歐式距離。若所有
的距離皆高於門檻值 PT ，則將 ),( yxhLFP
r
取代掉原先 K 個背景模型裏具有最小權
重值的一個。並將此新的背景模型之權
重預設為 0.01。 
反之，若有一個或一個以上的距離
低於門檻值 PT ，則我們選取這些距離所
對應模型中具最小距離的背景模型
),( yxms
v ，更新其 ),( yxms
v 及 ),( yxsω ： 
[0,1]  , )1( b ∈−+= ααα sbbs mhm r
rr
  (9) 
[0,1]  , )1( ∈−+= ωωω αωααω kkk M  (10) 
上式中，每一背景模型的權重都要更
新，當 k=s， 1=kM ；若否， 0=kM 。 bα
和 wα 則為決定了背景模型的更新幅度
與權重的更新速率之學習參數。學習率
越大，背景模型向量和權重更新率越快
速。 
6 
 
參考文獻 
[1] R. Cucchiara, M. Piccardi, and A. Prati, 
“Detecting moving objects, ghosts, and 
shadows in video streams,” IEEE 
Transactions on Pattern Analysis and 
Machine Intelligence, vol. 25, pp. 1337-1342, 
Oct 2003. 
[2] B. Lo and S. Velastin, “Automatic 
congestion detection system for underground 
platforms,” in Proceedings of 2001 
International symposium on intelligent 
multimedia, video, and speech processing, pp. 
158-161, (Hong Kong), May 2001. 
[3] B. Shoushtarian, and H. E. Bez, “A practical 
adaptive approach for dynamic background 
subtraction using an invariant colour model 
and object tracking,” Pattern Recognition 
Letters, vol. 26, no. 1 pp. 5-26, 2005. 
[4] K. Toyama, J. Krumm, B. Brumitt, and B. 
Meyers, “Wallower: Principles and practice 
of background maintenance,” in ICCV, vol. 
1, pp. 255-261, 1999. 
[5] A. Elgammal, D. Harwood, and L. Davis, 
“Non-parametric model for background 
subtraction,” in Proceedings of IEEE 
ICCV'99 Frame-rate workshop, Sept. 1999. 
[6] N. McFarlane and C. Schofield, 
“Segmentation and tracking of piglets in 
images,” Machine Vision and Applications, 
vol. 8, no. 3, pp. 187-193, 1995. 
[7] C. R. Wren, A. Azarbayejani, T. Darrell, and 
A. P. Pentland, “Pfinder: Real-time tracking 
of the human body,” IEEE Transactions on 
Pattern Analysis and Machine Intelligence, 
Vol. 19, No. 7, pp. 780-785, 1997. 
[8] K.-P. Karmann and A. Brandt, “Moving 
object recognition using and adaptive 
background memory,” in Time-Varying 
Image Processing and Moving Object 
Recognition, V. Cappellini, ed., 2, pp. 
289-307, Elsevier Science Publishers B.V., 
1990. 
[9] D. Koller, J. Weber, and J. Malik, “Robust 
multiple car tracking with occlusion 
reasoning," Tech. Rep. UCB/CSD- 93-780, 
EECS Department, University of California, 
Berkeley, Oct 1993. 
[10] N. Friedman and S. Russell, “Image 
segmentation in video sequences: A 
probabilistic approach,” in Proceedings of 
the Thirteenth Annual Conference on 
Uncertainty in Arti_cial Intelligence (UAI 
97), pp. 175-181, Morgan Kaufmann 
Publishers, Inc., (San Francisco, CA), 1997. 
[11] S. E. Chen, “QuickTime VR – An image 
based approach to virtual environment 
navigation,” Proc. SIGGRAPH 95, pp. 29-38, 
1995. 
[12] Y. Ren, C. S. Chua, and Y. K. Ho, 
“Statistical background modeling for 
non-stationary camera,” Pattern Recognition 
Letters, Vol. 24, pp. 183-196, 2003. 
[13] S. Kang, J. Paik, A. Koschan, B. Abidi, and 
M. A. Abidi, “Real-time video tracking using 
PTZ cameras,” Proc. of SPIE 6th 
International Conference on Quality Control 
by Artificial Vision, Vol. 5132, pp. 103-111, 
2003. 
[14] S. Ju, M. Black, and Y. Yacob, “Cardboard 
people: A parameterized model of articulated 
image motion,” in Proc. 2nd Int. Conf. 
AutomaticFace Gesture Recognition, 1996, 
pp. 38–44. 
[15] C. R. Wren, A. Azarbayejani, T. Darrell, and 
A. P. Pentland, “Pfinder: Real-time tracking 
of the human body,” IEEE Transactions on 
Pattern Analysis and Machine Intelligence, 
Vol. 19, No. 7, pp. 780-785, 1997. 
[16] I. Haritaoglu, D. Harwood, and L. Davis, 
“Ghost: A human body partlabeling system 
using silhouettes,” in Proc. Int. Conf. Pattern 
Recognition, vol. 1, 1998, pp. 77–82. 
[17] H. Fujiyoshi and A. Lipton, “Realtime 
human motion analysis lly by image 
skeletonization,” in Proc. IEEE Workshop 
Applicat. Comput. Vision, 1998, pp. 15–21. 
[18] I.-C. Chang and C.-L. Huang, “The 
model-based human body motionanalysis 
system,” Image Vision Comput., vol. 18, no. 
14, pp. 1067–1083, 2000. 
[19] S. Pinzke and L. Kopp, “Marker-less systems 
for tracking workin postures—Results from 
two experiments,” Appl. Ergon., vol. 32, no. 
5, pp. 461–471, 2001. 
[20] J. Freer,B. Beggs, H. Fernandez-Canque, F. 
Chevriet, and A. Goryashko, “Automatic 
recognition of suspicious activity for camera 
based security systems,” in Proc. Eur. 
Convention Security Detection, 1995, pp. 
54–58. 
[21] M. Rahman, K. Nakamura, and S. Ishikawa, 
“Recognizing human behavior using 
universal eigenspace,” in Proc. Int. Conf. 
Pattern Recognition, vol. 1, 2002, pp. 
295–298. 
[22] M. Heikkila and M. Pietikainen, “A 
Texture-Based Method for Modeling the 
Background and Detecting Moving Objects” 
IEEE Transactions on Pattern Analysis and 
Machine Intelligence, vol. 28, pp. 657-662, 
Apr. 2006. 
[23]  S.-J. Lee, C.-S. Ouyang, and S.-H. Du, "A 
Neuro-Fuzzy Approach for Segmentation of 
Human Objects in Image Sequences," IEEE 
Transactions on Systems, Man, and 
Cybernetics — Part B: Cybernetics , vol.33, 
no.3, pp.420-437, 2003.6 
