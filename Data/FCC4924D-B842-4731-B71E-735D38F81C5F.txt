 2
行政院國家科學委員會專題研究計畫成果報告 
文字探勘技術之發展與其在科學與技術文獻分析之應用 
Development of Text Mining Techniques and Their Application to Literature 
Analysis of Science and Technology 
計畫編號：NSC 95-2221-E-003-016- 
執行期限：95年 08月 01日至 96年 07月 31日 
主持人：曾元顯   國立台灣師範大學 
計畫參與人員：林瑜一，蔡鎮陽 
 
一、中文摘要： 
現今知識經濟的時代，各先進及發展
中國家，在科學與技術方面的進步，可謂
一日千里。因此引發國與國之間的經濟與
政治影響力的競爭，越發激烈。在數位媒
體發達的今天，從大量龐雜的文獻資料
中，透過先進資訊擷取、檢索、組織、分
析等探勘工具的輔助，來快速掌握科學領
域的發展，對優勢科技政策之分析與擬
定，可提供相當有價值的資訊。 
本計畫之目的，是以技術發展的角
度，來探討文字探勘技術運用於科學與技
術文獻的分析上。具體而言，我們將以科
學論文及技術專利為對象，發展相關的詞
彙擷取、知識關聯、網絡分析、內容摘要、
主題歸類、文件分類、資訊檢索、資訊視
覺化等探勘技術。本計畫特別注重結構化
與非結構化資料的結合，將依此概念發展
視覺化資訊擷取與分析模式，進行多重交
叉或關聯互動，以有效呈現資料探勘的結
果。本計畫成果除了增進使用者存取
（access）隱含於其中的資訊或知識外，
也希望透過開發出來的視覺化分析技術，
達到輔助各種科技領域分析的目的。 
關鍵詞：文字探勘、領域分析、標題生成、
資訊視覺化、主題地圖 
Abstract： 
 The purpose of this project is to 
develop a set of text mining techniques so as 
to apply to the analysis of science and 
technology literature. Specifically, by use of 
scientific bibliographic (including abstracts) 
and technical full-text patent documents, 
this project plans to develop keyword 
extraction, term association, citation 
network analysis, content summarization, 
topic clustering, document categorization, 
information retrieval, and information 
visualization techniques to support text 
mining processes. This project emphasizes 
on the combined use of the structured data 
and the unstructured data to provide 
multi-view, multi-layered interactive visual 
analysis. The results of this project not only 
can provide better information access for a 
large collection of scientific or patent 
literature, but also help in scientific and 
technical policy analysis for various 
domains. 
Keywords: Text Mining, Domain Analysis, 
Title Generation, Information Visualization, 
Topic Map 
 
二、報告內容 
請參考附件中發表之論文。 
 
三、計畫成果自評 
 
本計畫已將相關的研究結果發表在
AIRS 亞 洲 資 訊 檢 索 會 議 [1]、 IPM
（ Information Processing and 
Management）國際期刊[4]、以及 ISSI 國
際科學計量學雙年會議[5]，提供國內外研
究者參考。其中 IPM 同時收錄於 SCI 與
SSCI，乃圖書館學與資訊科學領域中，長
年排名於前 3-10 名的重要期刊；而 AIRS
為亞洲區最重要的資訊檢索會議；ISSI則
是全球最重要的科學計量學會議，每兩年
才一次。除此之外，本計畫也將相關的技
術應用於專利技術文獻的檢索[3]以及教
育評鑑領域的學術文獻分析。整體而言，
本計畫的成果同時具備實用性與學術性，
This article was originally published in a journal published by
Elsevier, and the attached copy is provided by Elsevier for the
author’s benefit and for the benefit of the author’s institution, for
non-commercial research and educational use including without
limitation use in instruction at your institution, sending it to specific
colleagues that you know, and providing a copy to your institution’s
administrator.
All other uses, reproduction and distribution, including without
limitation commercial reprints, selling or licensing copies or access,
or posting on open internet sites, your personal or institution’s
website or repository, are prohibited. For exceptions, permission
may be sought for such use through Elsevier’s permissions site at:
http://www.elsevier.com/locate/permissionusematerial
Au
th
or
's 
  p
er
so
na
l   
co
pysome Asian countries. Public institutions in China, Japan, Korea, Singapore, and Taiwan have invested var-ious resources in the training and performing of the task of creating visualized results for ease of various anal-
yses (Liu, 2003). For example, the Korean Intellectual Property Oﬃce plans to create 120 patent maps for
diﬀerent technology domains in the next 5 years (Bay, 2003).
Patent analysis or mapping requires considerable eﬀort and expertise. For example, Table 1 shows a typical
patent analysis scenario which is based on the training materials designed for patent analysts, such as those in
Chen (1999). As can been seen, these processes require the analysts to have a certain degree of expertise in
information retrieval, domain-speciﬁc technologies, and business intelligence. This multi-discipline require-
ment makes such analysts hard to ﬁnd or costly to train. In addition, patent documents are often lengthy
and rich in technical and legal terminology. To read and analyze them may consume a lot of time even for
experts. Automated technologies for assisting analysts in patent processing and analysis are thus in great
demand.
A patent document contains dozens of items for analysis; some are structured, meaning they are uniform in
semantics and in format across patents such as patent number, ﬁling date, or assignees; some are unstructured,
meaning they are free texts of various lengths and contents, such as claims, abstracts, or descriptions of the
invention. The visualized results from patent analysis are called patent graphs if they are from the structured
data and patent maps if they are from the unstructured texts, although, loosely speaking, patent maps can refer
to both cases.
Before their publication, patent documents are given one or more classiﬁcation codes based on their textual
contents for topic-based analysis and retrieval. However, these pre-deﬁned categories may be either too broad
or not meet the goal for a particular analysis. Self-developed classiﬁcation systems are often needed. For
example, Table 2 shows part of a patent map created by analyzing 92 patent documents (Mai, Hwang, Chien,
Wang, & Chen, 2002). These patents, issued before February 19, 2002, are the search results of the keyword:
‘‘carbon nanotube’’ from the database of USPTO (United States Patent & Trademark Oﬃce). In Table 2,
manually assigned categories regarding the technology aspects of the patents are listed in rows and those
Table 1
A typical patent analysis scenario
1. Task identiﬁcation: deﬁne the scope, concepts, and purposes for the analysis task
2. Searching: iteratively search, ﬁlter, and download related patents
3. Segmentation: segment, clean, and normalize structured and unstructured parts
4. Abstracting: analyze the patent content to summarize their claims, topics, functions, or technologies
5. Clustering: group or classify analyzed patents based on some extracted attributes
6. Visualization: create technology-eﬀect matrices or topic maps
7. Interpretation: predict technology or business trends and relations
Table 2
Part of the technology-eﬀect matrix for ‘‘Carbon Nanotube’’ from 92 US patents
Technology Eﬀect (function)
Material Performance Product
Carbon nanotube Purity Electricity FED
Manufacture Gas reaction 5346683 6181055 6221489 6232706
6129901 6190634
. . .
Catalyst 5424054 6333016 6339281
5780101
. . .
Arc discharging 5424054 6190634 5916642 5916642
6331262
Application Display 6346775 5889372
5967873
. . .
Y.-H. Tseng et al. / Information Processing and Management 43 (2007) 1216–1247 1217
Au
th
or
's 
  p
er
so
na
l   
co
py
mining process commonly discussed in the literature, such as those in Hearst (1999), Losiewicz, Oard, and
Kostoﬀ (2000).
Text mining, like data mining or knowledge discovery (Fayyad, Piatetsky-Shapiro, Smyth, & Uthurasamy,
1996), is often regarded as a process to ﬁnd implicit, previously unknown, and potentially useful patterns from
a large text repository. In practice, the text mining process involves a series of user interactions with the text
mining tools to explore the repository to ﬁnd such patterns. After supplemented with additional information
and interpreted by experienced experts, these patterns can become important intelligence for decision-making.
The purpose of this paper is to present a text-mining approach that help automate the patent analysis sce-
nario discussed above, based on the patent documents from USPTO. In particular, we propose and implement
a text mining method for each technical step in Table 1. The adopted methodology is ﬁrst introduced in Sec-
tion 2. The technical details of each method are described in Section 3. Evaluation of some critical techniques
is conducted in Section 4. In Section 5, an example of analyzing a set of patents is given. Section 6 discusses the
implications and related work. Finally Section 7 concludes this paper.
2. A general methodology
Patent analyses based on structured information such as ﬁling dates, assignees, or citations have been the
major approaches in practice and in the literature for years (Archibugi & Pianta, 1996; Be’de’carrax & Huot,
1994; Ernst, 1997; Lai & Wu, 2005). These structured data can be analyzed by bibliometric methods, data min-
ing techniques, or well-established database management tools such as OLAP (On-Line Analytical Processing)
modules. Recently, there has been an interest in applying text mining techniques to assist the task of patent
analysis and patent mapping (ACL-2003 Workshop on Patent Corpus Processing, 2003; Fattori, Pedrazzi,
& Turra, 2000 Lent, Agrawal, & Srikant, 2000; Fattori et al., 2003; Lent et al., 1997; Yoon & Park, 2004).
A well-utilization of the full texts in the patent documents may complement the interpretations derived from
the bibliometric analysis.
Therefore, based on the patent analysis scenario introduced above, a text mining methodology specialized
for full-text patent analysis is proposed and shown in Fig. 2. First, full patent documents relevant to the
analysis purpose are collected. This may involve a repeated process of devising a set of query terms (query
formulation), searching a couple of patent databases (collection selection), ﬁltering undesired patents (rele-
vance judgment), and downloading patents for local analysis (data crawling). Depending on the analysis pur-
pose, the step can be as easy as, for example, fetching all the patents under some IPC (International Patent
Document Preprocessing 
- Collection Creation 
- Document Parsing and Segmentation 
- Text Summarization 
- Document Surrogate Selection 
Indexing
- Keyword/Phrase Extraction 
- Morphological Analysis 
- Stopword Filtering 
- Term Association and Clustering 
Topic Clustering 
- Term Selection 
- Document Clustering/Categorization 
- Cluster Title Generation 
- Category Mapping 
Topic Mapping 
 - Trend Map 
 - Query Map 
 - Aggregation Map 
 - Zooming Map 
Fig. 2. The general text mining methodology for patent analysis.
Y.-H. Tseng et al. / Information Processing and Management 43 (2007) 1216–1247 1219
Au
th
or
's 
  p
er
so
na
l   
co
py
3. Technique details
This section presents the details of the proposed techniques in dealing with patent documents. Each tech-
nical step in the above methodology is addressed in sequence. The rationales behind these techniques are dis-
cussed. Eﬃciency, eﬀectiveness, robustness, and degree of automation are taken into consideration. For better
presenting the proposed techniques, a number of examples are given when necessary.
3.1. Text segmentation
The textual content of a patent document from USPTO is in HTML format and contains title, abstract,
claims, and description. The description, the main body of the detailed content, often have sub-sections with
titles in uppercase, such as FIELD OF THE INVENTION, BACKGROUND, SUMMARY OF THE
INVENTION, and DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENT. Although some
patents may have more or fewer such sub-sections or have slightly diﬀerent title names, most patents do follow
this style. Thus a regular expression matcher is devised to extract each of these segments. The method takes
advantage of the rule that each sub-section’s title is in a single line paragraph separated by two HTML tags:
‘‘ÆBRæÆBRæ’’. After splitting the paragraphs based on these tags, a set of Perl expressions: (/Abstract/i,
/Claims/i, /FIELD/i, /BACKGROUNDjArt/i, /SUMMARY/i, /DESCRIPTIONjEMBODIMENT/i) are
used to match the patent segments. An exception is that if FIELD OF THE INVENTION is not detected,
the ﬁrst text paragraph of the BACKGROUND segment is extracted as the FIELD segment. As long as
non-relevant single-line paragraphs are properly ﬁltered (those that are too long, too short, and do not contain
the above title words), the ratio of false drops (the cases of incorrect detection of the segment titles) can be
kept to a minimum. The whole process is quite ad hoc. The details can be varied slightly without aﬀecting
the eﬀectiveness very much. We have observed that our colleagues achieved performance similar to ours in
this task based on our guidelines, rather than on our source code.
3.2. Text summarization
Automatic summarization techniques have been widely explored in recent years (Document Understanding
Conferences). They can be mainly divided into two approaches: abstraction and extraction. In abstraction,
natural language understanding techniques are applied to analyze sentential semantics and then to generate
concise sentences with equivalent semantics. Sophisticated techniques such as sense disambiguity or anaphoric
resolution and large human-maintained resources may be applied. In extraction, statistical techniques are
applied to rank and select the text snippets as a summary. In our method, the extraction approach is adopted
for its relatively low cost and high robustness across technical domains. It is divided into three processing
stages: sentence breaking, sentence weighting, and sentence selection and presentation.
Our extraction-based method takes sentences as the smallest units for summarization. As such, each
segment is broken up by simply judging a period and question mark as a sentence break. But care has to
be taken for exceptions involving ﬂoating-point digits, mathematical or chemical expressions (such as
‘‘X.sub.i’’), various abbreviations (such as ‘‘ Fig. 1’’), or sentences within sentences (such as those containing
citations).
Next, each sentence is weighted by the number of keywords, title words, and clue words it contains. Fur-
thermore, the position of the paragraph containing the sentence in a segment and the position of the sentence
in the containing paragraph are considered as more important information for weighting. (Recall that para-
graphs in the USPTO patent documents are separated by the ‘‘ÆBRæÆBRæ’’ HTML tags.) Here the keywords
are those maximally repeated patterns extracted by the algorithm to be described. The title words are those
non-stopwords that occur in the title of a patent document. As to the clue words, they are a list of about
25 special words that reveal the intent, functions, purposes, or improvements of the patent. These words
are prepared by several patent analysts based on their experiences and are listed in Appendix A for reference.
In our implementation, the weight of a sentence is calculated as follows:
Y.-H. Tseng et al. / Information Processing and Management 43 (2007) 1216–1247 1221
Au
th
or
's 
  p
er
so
na
l   
co
py
stopwords from the head and tail of the candidates recursively. Fig. 3 shows the algorithm. The rule for merg-
ing, dropping, and accepting terms is implicit expressed in the algorithm. Fig. 4 shows a running example, in
which each capital letter denotes a word.
The above algorithm is based on the assumption that a document concentrating on a topic is likely to men-
tion a set of strings a number of times. Many natural language documents have this property, including Chi-
nese, Japanese, or even melody strings in music (Tseng, 1999). We found that a longest repeated string often is
a correct word (or phrase), since its repetition provides evidence for decision on its left and right boundaries.
Similarly, a repeated string that subsumes the others may also be a legal term. The sources of errors mainly
come from the inadequate coverage of the stopword list.
3.5. Term association
There are a number of approaches to extract terms relevant to the same topics from the entire document
collection. One commonly used heuristic rule is based on term co-occurrence (Salton, 1989). Given a collection
of n documents, an inverted term-document structure is ﬁrst constructed, where each term is denoted in a
1. Convert the input text into a LIST of words. 
2. Do Loop 
   2.1 Set MergeList to empty. 
   2.2 Put a separator to the end of LIST as a sentinel and set the occurring frequency of the separator to 0. 
   2.3 For I from 1 to NumOf(LIST) - 1 step 1, do 
2.3.1    If LIST[ I ] is the separator, Go to Label 2.3. 
2.3.2    If Freq(LIST[ I ]) > threshold and Freq(LIST[ I+1]) > threshold, then 
   Merge LIST[ I ] and LIST[ I +1] into Z. 
   Put Z to the end of MergeList. 
           Else 
   If Freq(LIST[ I ]) > threshold and LIST[ I ] did not merge with LIST[ I - 1], then 
        Save LIST[ I ] in FinalList. 
If the last element of MergeList is not the separator, then 
                 Put the separator to the end of MergeList. 
End of For loop 
   2.4 Set LIST to MergeList. 
   Until NumOf(LIST) < 2. 
3. Filter terms in FinalList based on some criteria.
Fig. 3. The keyword extraction algorithm.
Example: Given an input string: BACDXAYCDBACD.
Let threshold=1, separator=x. 
Step 1: Create a list of single tokens:
   LIST = (B:2, A:3, C:3, D:3, X:1, A:3, Y:1, C:3, D:3, B:2, A:3, C:3, D:3, x) 
Step 2:
  After 1st iteration :
      MergeList = (BA:2, AC:2, CD:3, x, CD:3, DB:1, BA:2, AC:2, CD:3, x) 
      FinalList = (A:3) 
  After 2nd iteration : 
      MergeList = (BAC:2, ACD:2, x, BAC:2, ACD:2, x) 
      FinalList = (A:3, CD:3) 
  After 3rd iteration :
      MergeList = (BACD:2, x, BACD:2, x) 
      FinalList = (A:3, CD:3) 
  After 4th iteration :
      MergeList = (x) 
      FinalList = (A:3, CD:3, BACD:2)
Fig. 4. A running example of the algorithm, where the number following a semicolon denotes the occurring frequency of the associated
string.
Y.-H. Tseng et al. / Information Processing and Management 43 (2007) 1216–1247 1223
Au
th
or
's 
  p
er
so
na
l   
co
py
collection. To obtain closer relations among terms, they are further clustered based on their associated words.
In our implementation, additional similarities among terms are calculated based on how many common asso-
ciated terms are shared. The complete-link clustering algorithm is then used with a strict threshold to yield
small clusters having high intra-similarities. As a result, terms which do not co-occur in any documents
may be clustered together. It is noted that although Latent Semantic Indexing (LSI) (Deerwester, Dumais,
Furnas, Landauer, & Harshman, 1990) exhibits this similar advantage, its time complexity is higher than
the method presented here.
3.6. Topic clustering
Clustering is a powerful technique to detect topics and their relations in a collection. Various clustering
methods have been proposed for years, such as HAC (Hierarchical Agglomerative Clustering) (Jain, Murthy,
& Flynn, 1999), MDS (Multi-dimensional Scaling) (Kruskal, 1977), and SOM (Self-organization Map)
(Kohonen, 1997). Many of their computer implementations either in standalone programs or in integrated
packages can be found and downloaded from the Web for free (such as those in Karypis; Frank, Hall,
&Trigg,Trig). Use of these tools requires a speciﬁcation of how similarities between items are computed.
3.6.1. Document clustering
Speciﬁcally, in document clustering, each document is processed into a vector form, such as
di ¼ ðti1; ti2; . . . ; timÞ, where tij is the weight of an indexed term j in document i. The eﬀectiveness of clustering
relies on (1) how terms are selected; (2) how they are weighted; (3) and how similarities are measured. From
the experience of topic-based retrieval, term selection aﬀects the performance most among these three factors;
the other two are second (Tseng et al., 2004). In our implementation, term selection is based on the extracted
key terms, associated terms, and TF or IDF ﬁltering. Terms whose TF in a document is lower than a threshold
are removed from that document. Terms whose DF is lower than a threshold or higher than another threshold
are also removed. After this basic ﬁltering for outliers, depending on how much information is to be used in
the clustering, all the indexed terms can be retained; or only those extracted key terms are kept; or most strictly
only those terms in the term relation structure are selected. Although intuitively the last choice may result in
the highest-quality (and smallest) set of terms, topic-based retrieval experiments showed that long queries
(having long description of information need including seemingly noisy terms) often lead to better perfor-
mance than short queries (Fang, Tao, & Zhai, 2004). In text categorization tasks, excessive term selection
and reduction may also hurt eﬀectiveness in some real-world test collections (Bekkerman, El-Yaniv, Winter,
& Tishby, 2001; Joachims, 1998; Yang & Pedersen, 1997). Therefore, selection of terms for clustering becomes,
more or less, a try-and-error process. This was also observed in text visualization studies, such as (Booker
et al., 1999) where parameters are provided for term selection. Although there are performance indices such
as the overall intra-cluster and inter-cluster similarities to objectively compare diﬀerent clustering results, these
indices do not directly correspond to the quality of the clusters perceived by humans. From the analyst’s point
of view, the interpretability of the resulting clusters seems to be more associated with its quality. Therefore, to
reduce un-expected eﬀorts in tuning the clustering results, manual veriﬁcation of selected terms is always rec-
ommended whenever it is possible.
As to the weighting of the selected terms, TF · IDF is used, which is combined with the cosine function to
yield a similarity measure. This choice has a simple reason: the measure ranges from 0 to 1, a range compatible
with those required by the mapping tools to be used. Other similarity measures, such as pivoted normalization
(Singhal, Buckley, & Mitra, 1996) or OKAPI BM25 (a probability model) (Robertson & Walker, 1994), that
perform better in other information retrieval tasks simply do not ﬁt since their similarities are beyond this
range and do not reﬂect the Euclidean distances among clusters.
3.6.2. Term clustering followed by document categorization
Another way for topic clustering is to perform term clustering followed by document categorization. Pre-
vious work used the term-document index for term clustering (Noyons & van Raan, 1998b). In our implemen-
tation, terms are clustered based on their co-occurred terms described above. Using all the terms (clustered
and their co-occurred) as training data, documents can then be classiﬁed into these clusters based on some
Y.-H. Tseng et al. / Information Processing and Management 43 (2007) 1216–1247 1225
Au
th
or
's 
  p
er
so
na
l   
co
py
beds, then a title labeled ‘furniture’ would be perfect for this cluster, especially when this hypernym does not
occur in this cluster. This case is often solved by human experts, such as those in Lai and Wu (2005), Glenis-
son, Glanzel, Janssens, and De Moor (2005), where cluster titles are given manually. Below we propose an
automatic solution by use of an extra resource, i.e., WordNet.
WordNet is a digital lexical reference system developed by the Cognitive Science Laboratory at Princeton
University (WordNet: a lexical database for the English language). English nouns, verbs, adjectives and
adverbs are organized into synonym sets. Diﬀerent relations, such as hypernym, hyponym, meronym, or hol-
onym, are deﬁned to link the synonym sets. With these structures, one can look up in WordNet all the hyper-
nyms of a set of given terms and then choose the best among them with some heuristic rules. Since the
hypernyms were organized hierarchically, the higher the level is, the more generic the hypernyms are. To main-
tain the speciﬁcity of the set of terms while revealing their general topics, the heuristics have to choose as low-
level common hypernyms as possible. When there are multiple choices, ranks should be given to order the
hypernyms in priority.
In our implementation, we look up for each given term all its hypernyms alone the path up to the root in the
hierarchical tree. The number of occurrence (f) and the depth in the hierarchy (d) of an encountered hypernym
are recorded. With the root being given a depth value of 0, a weight proportional to the normalized f and d is
calculated for each hypernym as follows:
weightðhypernymÞ ¼ f
nt
 2 1
1þ expcd  0:5
 
where nt is the number of given terms to normalize the occurrence f to a value ranges from 0 to 1 and c (0.125
in our implementation) is a constant to control the steepness of the sigmoid function 1=ð1þ expðc dÞÞ
whose value approaches 1 (1) for large positive (negative) d. Since the depth d only takes on non-negative
value, the actual range of the sigmoid is from 0.5 to 1. It is thus subtracted with 0.5 and then multiplied
by 2 to map the value of d into the normalized range: 0 to 1. Note that a term having no hypernym or not
in WordNet is omitted from being counted in nt. Also note that a term can have multiple hypernyms and thus
multiple paths to the root. A hypernym is counted only once for each given term, no matter how many times
the multiple paths of this term pass this hypernym. This weight is ﬁnally used to sort the hypernyms in decreas-
ing order to suggest priority.
Back to the previous example where the three terms were given: table, chair, and bed, their hypernym: ‘‘fur-
niture’’ did result from the above calculation with a highest weight 0.3584 based on WordNet version 1.6.
3.7. Topic mapping
To represent the detected knowledge structures, two techniques are mainly used: HAC and MDS. Based on
the pre-calculated similarities between each topic, the HAC method organizes the topics in a hierarchical way.
This creates a structure that is readily available to the folder tree representation. In order to get higher intra-
cluster similarities, the traditional complete-link clustering algorithm is chosen and developed as our HAC
method. Similarly, from the pairwise similarities, the MDS technique computes the coordinates of each topic
in speciﬁed dimensions of Euclidean space, which are usually 2 or 3 for ease of visual interpretation. With
these coordinates, a topic map can be created by a plotting tool. We use the MDS program in the RuG/
L04 package (Kleiweg (Sof ware for Dialectometrics & Cartography)) for coordinate computation and the
GD module in Perl for plotting. A circle is used to denote a topic. The size of the circle is designed to reﬂect
the number of patents in it. Before plotting, the topics are further clustered by the complete-link algorithm
with a speciﬁed threshold to divide them into several groups. Topics belonging to the same groups are plotted
with the same colors so as to make the map more informative.
More advanced topic maps such as those introduced in Section 2 can be created by combining the struc-
tured information from the patents. For examples, by use of the patents from diﬀerent time spans based
on their ﬁling or application dates, we may draw a series of growth maps or evolution maps. Speciﬁcally,
patents not within the speciﬁed dates are removed from those clusters. The similarities among the resultant
clusters are re-calculated and mapped based on the reduced number of patents. As long as the number of pat-
ents does not change largely, the change in the map should be minimal. With a series of such slightly changed
Y.-H. Tseng et al. / Information Processing and Management 43 (2007) 1216–1247 1227
Au
th
or
's 
  p
er
so
na
l   
co
py
6. cla: corresponds to the Claims section of each patent.
7. seg_ext: corresponds to the top-ranked sentences of each document from the sets: abs, app, task, sum,
and fea.
8. full: corresponds to all the documents from the sets: abs, app, task, sum, and fea.
Each document in the segment extract set (seg_ext in the above) is the concatenation of the machine-generated
summaries from each of the ﬁve segments (not including the Claims segment) in the same patent. The best s
sentences are selected as the summary from each segment, where s is 6 in our implementation. Similarly, each
document in the full set is the concatenation of the un-summarized texts from each of the ﬁve segments.
To show the segmentation results, among 6 · 92 = 522 segments in the CNT collection, only 9 do not con-
tain any text, an empty rate of 1.63%. These include one empty document in the ‘app’ set, two in the ‘task’ set,
ﬁve in the ‘sum’ set, and one in the ‘fea’ set. Among these nine empty documents, ﬁve are due to the lack of
such sections in the original patent documents, three are due to the use of special section titles, and one is due
to the erroneous spelling of the section title. The other two segments, the Abstract and Claims sections, always
lead to correct extraction.
4.2. Text summarization
The use of segment summaries as document surrogates is an important feature in our approach. Knowing
whether they are useful for subsequent processing and analysis is a key question to be answered. However,
evaluation of automated summaries is not an easy task. Two main approaches are commonly applied: intrinsic
and extrinsic (Mani, 2001). In intrinsic evaluation, manually prepared answers or evaluation criteria are com-
pared with those which are machine generated. In extrinsic evaluation, automated summaries are evaluated
based on their performance or inﬂuence on other tasks. We ad pt the extrinsic approach since it is obviously
suitable for our purpose.
In manual creation of a technology-eﬀect matrix or a patent map for analysis, it is helpful to quickly spot
the keywords that can be used for classifying the patents in the map. Once the keywords or category features
are found, patents can usually be classiﬁed without reading all the texts. Thus a summary that retains as many
important category features as possible is preferable. Our evaluation design therefore is to reveal whether the
segment extract set (the seg_ext in the above) contains enough such features, compared to the other seven doc-
ument sets.
In the following, the method for selecting category features for classiﬁcation is introduced. By using the
CNT patent map as our experimental data, the segments where important features occur are recorded for each
patent and such occurrences are accumulated over all patents. The location distributions of important features
among these segments are then compared.
4.2.1. Feature selection
Selecting the best category features for document categorization has been studied in the ﬁelds of machine
learning and information retrieval. Yang and Pedersen (1997) compared ﬁve diﬀerent methods. They found
that Chi-square is among the best that lead to highest performance. The Chi-square method computes the
relatedness of term T with respect to category C as:
v2ðT ;CÞ ¼ ðTP TN FN FPÞ
2
ðTPþ FNÞðFPþ TNÞðTPþ FPÞðFNþ TNÞ
which is exactly the square of the correlation coeﬃcient introduced previously. However, as pointed out by Ng
et al. (1997), the correlation coeﬃcient selects exactly those terms that are highly indicative of membership in a
category, whereas the Chi-square method will not only pick out this set of terms but also those terms that are
indicative of non-membership in that category. This is especially true when the selected terms are small in
number. As an example, in a small real-world collection of 116 documents with only two exclusive categories:
construction vs. non-construction in civil engineering tasks, some of the best and worst terms that are com-
puted by Chi-square and correlation coeﬃcient are shown in Table 5. As can be seen, due to the square nature,
Y.-H. Tseng et al. / Information Processing and Management 43 (2007) 1216–1247 1229
Au
th
or
's 
  p
er
so
na
l   
co
py
CNT map creators. The results are shown in Table 8. The ﬁrst row shows that among 7 relevant features, 6 of
them occur in the ‘abs’ set, covering 87.5% of them.
The term-covering percentage (of the best terms and the relevant terms) of each set was accumulated and
averaged over all categories with respect to the technology taxonomy and the eﬀect taxonomy, respectively, as
follows:
MBTCðsÞ ¼ 1
Catj j
X
c2Cat
1
M
X
ICF2s\c
1
where jCatj denotes the number of categories in the taxonomy. The results are shown in Table 9. The second
column denotes the number of categories (nc) in that taxonomy and the third column denotes the average
number of terms in each category (nt) for calculating the term-covering average. The rows with a star in
the ﬁrst column denote that the average is calculated from the human-judged relevant terms. As the bold-faced
data show, most machine-derived ICFs occur in the segment extracts, while most human-judged ICFs occur in
the abstract section.
To see if important sets change when the number of ICFs changes, we varied the number M for additional
values, i.e., 10 and 50, and calculated the averaged term-covering rates again. The results in Fig. 6 show that
‘abs’, ‘sum’ and ‘seg_ext’ are important sets. The ‘full’ set becomes important only when more terms are
included for consideration.
4.2.3. Findings
From Fig. 6 and Table 9, it can be seen that: (1) Most ICFs ranked by correlation coeﬃcient occur in the
segment extracts, the Abstract section, and the SUMMARY OF THE INVENTION section. (2) Most ICFs
selected by humans occur in the Abstract section or the Claims section. (3) The segment extracts lead to more
Table 7
Occurrence distribution of 30 top-ranked terms in each set for some categories
Category T_No abs app task sum fea cla seg_ext full
FED 30 16/53.3% 14/46.7% 22/73.3% 19/63.3% 21/70.0% 19/63.3% 21/70.0% 22/73.3%
Device 30 21/70.0% 17/56.7% 9/30.0% 16/53.3% 7/23.3% 19/63.3% 17/56.7% 8/26.7%
Electricity 30 12/40.0% 10/33.3% 10/33.3% 10/33.3% 8/26.7% 8/26.7% 13/43.3% 12/40.0%
Purity 30 12/40.0% 12/40.0% 7/23.3% 20/66.7% 9/30.0% 17/56.7% 18/60.0% 14/46.7%
Magnetic 30 18/60.0% 11/36.7% 6/20.0% 14/46.7% 14/46.7% 13/43.3% 15/50.0% 13/43.3%
Table 8
Occurrence distribution of manually judged terms in each set for some categories
Category T_No abs app task sum fea cla seg_ext full
FED 7 6/85.7% 6/85.7% 6/85.7% 4/57.1% 6/85.7% 4/57.1% 6/85.7% 5/71.4%
Device 2 2/100.0% 1/50.0% 0/0.0% 1/50.0% 1/50.0% 2/100.0% 1/50.0% 0/0.0%
Electricity 2 2/100.0% 2/100.0% 0/0.0% 1/50.0% 1/50.0% 1/50.0% 0/0.0% 1/50.0%
Purity 8 6/75.0% 2/25.0% 3/37.5% 5/62.5% 1/12.5% 2/25.0% 4/50.0% 1/12.5%
Magnetic 2 2/100.0% 2/100.0% 1/50.0% 2/100.0% 1/50.0% 1/50.0% 2/100.0% 0/0.0%
Table 9
Distribution of M-best term coverage in each segment averaged over all categories
Taxonomy Set abs app task sum fea cla seg_ext full
nc nt
Eﬀect 9 M ¼ 30 52.96% 41.48% 37.41% 53.33% 34.81% 47.04% 57.04% 41.85%
Eﬀect* 8 4 86.96% 66.34% 45.40% 64.33% 51.03% 54.02% 55.09% 30.49%
Tech. 21 M ¼ 30 49.37% 25.56% 26.51% 56.51% 34.44% 46.51% 56.03% 40.95%
Tech.* 17 4.5 59.28% 29.77% 23.66% 49.43% 34.46% 60.87% 44.64% 32.17%
Y.-H. Tseng et al. / Information Processing and Management 43 (2007) 1216–1247 1231
Au
th
or
's 
  p
er
so
na
l   
co
py
4.4. Cluster title generation
For comparison, we used three methods to rank cluster terms for title generation, namely the modiﬁed Cor-
relation Coeﬃcient (CC0.5), Term Frequency in Cluster (TFC), and multiplication of these two: CC · TFC.
These ranking methods were applied to three sets of clustering results. The ﬁrst is the ﬁrst-stage document
clustering from the CNT patents. The second is the second-stage document clustering from the CNT patents.
The third is the third-stage term clustering from clustering the keywords extracted from NSC patents based on
their co-words. For each cluster, at most 5 best terms were selected as its title. Two master students majored in
library science then compared the relative quality of these terms under the same clusters. For each ranking
method, the number of cases where it has the best title quality over the other methods was counted. Multiple
best choices for a cluster are allowed and those cluster titles that are hard to assess can be omitted from being
considered. The ranking methods are coded in such a way that the assessors do not know which method is
used to generate the examined titles. The results are shown in Table 10. Note that hierarchical clustering struc-
tures were shown to the assessors. They were free to examine whatever clusters or sub-clusters they were inter-
ested in. This is why the numbers of examined clusters diﬀer between them.
In spite of this diﬀerence, this preliminary experiment shows that titles generated by CC0.5 or CC · TFC are
favorable by one assessor, while those generated by TFC are not by either. This is somewhat surprised to
know, since most past studies use TFC or a variation of it to generate cluster titles.
Fig. 7. An application example of the extracted keywords and their associated terms.
Table 10
Comparison of three title ranking methods among three cluster sets
Cluster set Ranking method
Assessor Number of
clusters examined
Number of clusters that
CC0.5 is the best
Number of clusters that
TFC is the best
Number of clusters that
CC · TFC is the best
First-stage 1 73 52 71% 5 7% 20 27%
doc. clusters 2 19 12 63% 6 32% 13 68%
Second-stage 1 13 9 69% 0 0% 6 46%
doc. clusters 2 7 3 43% 1 14% 5 71%
Third-stage 1 16 12 75% 5 31% 9 56%
term clusters 2 10 4 40% 5 50% 8 80%
Y.-H. Tseng et al. / Information Processing and Management 43 (2007) 1216–1247 1233
Au
th
or
's 
  p
er
so
na
l   
co
py
4.5. Mapping cluster titles to categories
The proposed title mapping algorithm is applied to two real-world cluster sets: the ﬁrst is a term cluster set,
the second is a document cluster set, both are the ﬁnal-stage clustering results from the NSC patents to be
discussed in the next section. The ﬁrst set has 10 clusters and the second has 6. Their cluster titles are shown
in the second column of Table 11.
The proposed method is compared to a similar tool called InfoMap (Information Mapping Project)
which is developed by the Computational Semantics Laboratory at Stanford University. This online tool
ﬁnds a set of taxonomic classes for a list of given words. It seems that WordNet is also used as its refer-
ence system, since the output classes are mostly WordNet’s terms. An agent program is written to send
the title words to InfoMap and collect the results that it returns. Only the top-three candidates from
both methods are compared. They are listed in the last two columns in Table 11, with their weights
appended.
The reasonable classes are marked in boldface in the table. As can be seen, the two methods perform sim-
ilarly. Both achieve a level of 50% accuracy in either set.
5. Application example
5.1. The NSC patent set
One of the objectives of this work is to help analyze the US patents whose assignee is National Science
Council (NSC). NSC is the major government agency that sponsors research activities in Taiwan. Institutes,
universities, or research centers, public or private, can apply for research fundings from NSC. Once the
research results yield any US patents, the intellectual property rights belong to NSC. In other words, NSC
becomes the assignee of the patents. However, this policy has been changed since year 2000. NSC no longer
insisted on the ownership of the rights. The applicants own the management rights of these intellectual
properties.
Due to this background, these documents constitute a knowledge-diversiﬁed collection with relatively long
texts (about 2000 words per document) describing various advanced technical details. Analysis of the topics in
this collection becomes a non-trivial task as very few analysts know of such diversiﬁed technologies and ﬁelds.
Although each patent has pre-assigned International Patent Classiﬁcation (IPC) or US Patent Classiﬁcation
(UPC) codes, many of these labels are either too general or too speciﬁc to ﬁt the intended knowledge struc-
tures for topic interpretation. Therefore, using them alone does not meet the requirement of the analysis. As
such, organizing the collection by text mining techniques becomes an important method to help humans
understand this collection.
The NSC collection was created by searching the USPTO’s web site using ‘‘National Science Council’’ as
the search term limited to the assignee ﬁeld. A total of 612 patents were downloaded on 2005/06/15.
5.2. Text mining processing
The 612 patents were parsed, segmented, and summarized. Among the 6 * 612 = 3672 segments, only 79
empty segments resulted, yielding an empty rate of 2.15%. The full texts of these patents take up 23.9 MB.
After summarization with at most 6 sentences for each of the 5 segments (the Claims segment is excluded from
the task of topic analysis), the size becomes 2.93 MB, a compression ratio of 87.74%. In spite of this, the lost
important terms are few. From the full text set, a total of 20,072 keywords (terms occur at least twice in a
document) were extracted. Among them, 19,343 can be found from the 5-segment summary set. Most of
the 20,072 keywords occur in one document. Only 2714 of them occur in at least two and have at least one
co-occurred terms associated with them.
These 2714 terms were then used to index the document surrogates. With these concise representations in
documents and terms, a set of topic maps were generated.
Y.-H. Tseng et al. / Information Processing and Management 43 (2007) 1216–1247 1235
Au
th
or
's 
  p
er
so
na
l   
co
py
More types of advanced analysis can be obtained by combining the topic maps with the patents’ structured
information. Their implementation involves techniques from the ﬁelds of database management and user
interface. The details of which are beyond the scope of this discussion.
5.4. Topic analysis comparison
The topic distribution of the NSC patents had actually been analyzed by a subsidiary center of NSC: Sci-
ence and Technology Information Center (STIC). STIC analyzed this patent set ﬁrst by IPC. The results in the
form of the topic tree are shown in Table 14, where major categories are shown in boldface and with their IPC
Table 12
Final-stage term clusters from the NSC patents
1: 313 terms: 0.110708 (resin: 67.0, group: 50.3, polymer: 49.8, compound: 33.8, methyl: 31.3)
o 5: 247 terms: 0.517729 (resin: 99.0, group: 83.3, polymer: 77.5, acid: 47.3, formula: 46.0)
+ ID = 131: 120 terms: 0.262248(resin: 48.2, alcohol: 36.0, polymer: 28.6, group: 24.3, phenolic: 21.0)
+ ID = 473: 127 terms: 0.130294(phenyl: 34.7, amino: 21.0, acid: 20.9, formula: 20.3, activity: 12.3)
o 11: 66 terms: 0.425685 (roller: 31.9, cam: 22.2, compound: 20.7, pitch: 18.0, thread: 14.5)
+ ID = 6: 29 terms: 0.6842(compound: 15.2, methyl: 5.9, tube: 5.6, borohydride: 5.6, phosphonium: 4.9)
+ ID = 61: 37 terms: 0.343894(roller: 30.9, cam: 21.8, variable: 18.0, pitch: 17.6, mechanic: 16.1)
2: 655 terms: 0.193269 (circuit: 249.9, output: 243.0, input: 223.0, signal: 194.3, voltage: 162.5)
* 3: 592 terms: 0.526790 (signal: 238.3, output: 199.9, layer: 198.7, input: 182.9, light: 177.0)
o 1: 500 terms: 0.708007 (circuit: 209.4, signal: 159.7, output: 151.6, layer: 140.6, input: 138.8)
+ ID = 484: 236 terms: 0.1288(layer: 138.8, substrate: 55.2, semiconductor: 47.2, schottky: 41.3, . . .)
+ ID = 296: 264 terms: 0.177278(output: 148.5, circuit: 107.8, signal: 102.3, input: 61.7, terminal: 53.8)
o ID = 493: 92 terms: 0.126080(optic: 46.6, light: 35.3, ﬁeld: 17.5, index: 15.7, layer: 13.1)
* ID = 440: 63 terms: 0.136660(circuit: 20.7, line: 9.5, voltage: 4.0)
3: 289 terms: 0.361452 (silicon: 49.4, layer: 41.6, material: 40.2, substrate: 33.8, powder: 33.4)
* 13: 220 terms: 0.399435 (dielectric: 40.0, ceramic: 34.6, layer: 29.2, silicon: 28.5, catalyst: 28.4)
o ID = 243: 86 terms: 0.200064(dioxide: 24.2, liquidate: 19.8, phase: 19.0, substrate: 10.9, deposit: 9.4)
o ID = 503: 134 terms: 0.1236(ceramic: 49.0, material: 17.5, dielectric: 17.0, powder: 16.4, mixture: 15.7)
* ID = 593: 69 terms: 0.102624(thermal: 15.7, silicon: 11.5, ﬁlm: 4.7, substrate: 2.6)
4: 159 terms: 0.186075 (system: 38.5, edge: 32.0, signal: 13.5, type: 7.4, device: 6.8)
* 35: 129 terms: 0.289348 (edge: 40.0, ﬂow: 32.6, system: 26.0, vortex: 25.6, air: 23.6)
o ID = 94: 47 terms: 0.304667(air: 23.2, edge: 14.2, upstream: 13.4, transfer: 12.0, system: 11.1)
o ID = 602: 82 terms: 0.100589(ﬂow: 25.8, vortex: 23.8, pressure: 19.5, ﬂuid: 18.9, pipe: 16.8)
* ID = 370: 30 terms: 0.153259(signal: 8.5, fourier: 7.0, demodulator: 6.3, software: 6.3, value: 6.3)
5: 105 terms: 0.365060 (solution: 34.2, polyaniline: 20.1, derivative: 14.5, acid: 9.5, aqueous: 9.5)
* ID = 90: 71 terms: 0.305932 (solution: 23.4, copper: 7.7, pitch: 7.0, sieve: 7.0, molecular: 7.0)
* ID = 67: 34 terms: 0.335136 (polyaniline: 19.7, derive: 13.8, derivative: 13.4, water: 7.0, solvent: 7.0)
6: 77 terms: 0.250290 (sensor: 16.9, magnetic: 14.2, record: 10.4, calcium: 9.0, phosphate: 9.0)
* ID = 38: 51 terms: 0.392179 (magnetic: 14.2, record: 9.1, calcium: 8.4, composition: 8.2, phosphate: 7.7)
* ID = 146: 26 terms: 0.252356 (sensor: 7.2, mndr: 5.6, fabrication: 4.9, temperature: 4.2, ethanol: 4.2)
7: 109 terms: 0.353365 (gene: 31.9, cell: 26.4, viru: 16.6, infection: 13.9, plant: 13.9)
* ID = 68: 57 terms: 0.332308 (combustion: 9.1, chamber: 9.1, cell: 7.0, nip: 7.0, solar: 7.0)
* ID = 13: 52 terms: 0.496672 (gene: 45.0, viru: 18.7, infection: 15.4, plant: 13.8, sugar: 8.9)
8: 84 terms: 0.256320 (density: 16.6, treatment: 12.5, strength: 10.4, control: 9.1, arrhythmia: 8.3)
* ID = 51: 53 terms: 0.359096 (density: 23.0, ﬁlm: 2.3)
* ID = 4: 31 terms: 0.782113 (treatment: 8.3, arrhythmia: 7.7, hypertension: 5.6, display: 5.6, breast: 5.6)
9: 86 terms: 0.505293 (force: 42.0, bear: 28.0, rod: 20.1, plate: 18.4, member: 15.6)
* ID = 78: 43 terms: 0.316616 (force: 24.4, bear: 11.2, steel: 10.6, application: 10.5, pawl: 8.4)
* ID = 33: 43 terms: 0.407034 (member: 23.1, rod: 19.0, end: 15.4, plate: 10.1, connect: 9.8)
10: 104 terms: 0.300222 (transistor: 29.8, layer: 27.4, channel: 20.1, amorphous: 15.9, eﬀect: 11.8)
* ID = 52: 34 terms: 0.358806 (amorphous: 14.1, amorphous silicon: 8.4, design: 4.9, uhv: 4.2, . . .)
* ID = 87: 70 terms: 0.306677 (eﬀect: 23.1, rat: 9.1, transistor: 9.1, ingaa: 8.4, region: 7.7)
Y.-H. Tseng et al. / Information Processing and Management 43 (2007) 1216–1247 1237
Au
th
or
's 
  p
er
so
na
l   
co
py
either ambiguous or not at the detailed-enough level or abstract-enough level that is needed by an analyst.
Further breakdown of those ambiguous categories yields similarly divergent and skewed distribution. This
makes them hard for further analysis.
As an alternative, STIC used the division information of these patents to show their topic distribution, as is
shown in Table 15. This academic division information comes from the actual divisions of NSC where the
Table 14
Breakdown of major IPC categories for the NSC patents
A: 87 docs.: Human Necessities
+ A61: 71 docs.: Medical Or Veterinary Science; Hygiene
+ A*: 16 docs.: A01(7), A21(2), A23(2), A42(2), A03(1), A62(1), A63(1)
B: 120 docs.: Performing Operations; Transporting
+ B01: 25 docs.: Physical Or Chemical Processes Or Apparatus In General
+ B05: 28 docs.: Spraying Or Atomising In General; Applying Liquids Or Other Fluent Materials To Surfaces
+ B22: 17 docs.: Casting; Powder Metallurgy
+ B*: 50 docs.: B32(12), B29(11), B62(6), B23(4), B24(4), B60(4), B02(2), B21(2), B06(1), B25(1), . . .
C: 314 docs.: Chemistry; Metallurgy
+ C07: 62 docs.: Organic Chemistry
+ C08: 78 docs.: Organic Macromolecular Compounds; Their Preparation Or Chemical Working-Up; . . .
+ C12: 76 docs.: Biochemistry; Beer; Wine; Vinegar; Microbiology; Mutation Or Genetic Engineering; . . .
+ C*: 98 docs.: C23(22), C25(20), C01(19), C04(10), C09(10), C22(8), C03(5), C30(3), C21(1)
D: 6 docs.: Textiles; Paper
E: 8 docs.: Fixed Constructions
F: 30 docs.: Mechanical Engineering; Lighting; Heating;
G: 134 docs.: Physics
+ G01: 49 docs.: Measuring; Testing
+ G02: 28 docs.: Optics
+ G06: 29 docs.: Computing; Calculating; Counting
+ G*: 28 docs.: G10(7), G11(7), G05(6), G03(5), G08(2), G09(1)
H: 305 docs.: Electricity
+ H01: 216 docs.: Basic Electric Elements
o H01L021: 92 docs.: Processes or apparatus adapted for the manufacture or treatment of semiconductor
o H01L029: 35 docs.: Semiconductor devices adapted for rectifying, amplifying, oscillating, or switching;
o H01L*: 89 docs.: others.
O H01*: 53 docs.: H03K(23), H03M(11), H04B(10), H04L(7), H04N(7), H01B(5), H03H(4), H04J(4), . . .
+ H03: 51 docs.: Basic Electronic Circuitry
+ H04: 30 docs.: Electric Communication Technique
+ H*: 8 docs.: H05(5), H02(3)
Table 15
Division distributions of the NSC patents
Abbrev. Division Percentage
Ele Electrical Engineering 28.63
Che Chemical Engineering 14.70
Mat Material Engineering 14.12
Opt Optio-Electronics 13.15
Med Medical Engineering 10.44
Mec Mechanical Engineering 6.58
Bio Biotechnology Engineering 5.03
Com Communication Engineering 2.90
Inf Information Engineering 2.90
Civ Civil Engineering 1.16
Others 0.39
Total 100.00
Y.-H. Tseng et al. / Information Processing and Management 43 (2007) 1216–1247 1239
Au
th
or
's 
  p
er
so
na
l   
co
py
this cluster should be more about medical chemistry, while less about hygiene. In Cluster 6 it co-occurred with
C12 such that the patents should be more about biomedical chemistry or biomedicine, while less about beer,
wine, etc. Fig. 11 supports these observations in all these six clusters.
Comparing among Fig. 9, Tables 14 and 15, these three classiﬁcation systems provide diﬀerent facets to
understand the topic distribution of the patent set. Each may reveal some insights if we can interpret it.
The IPC system results in divergent and skewed distributions which make it hard for further analysis (such
as trend analysis). The division classiﬁcation is the most familiar one to the NSC analysts, but it lacks
inter-disciplinary information. As to the text mining approach, it dynamically glues related IPC categories
together based on the patent contents to disambiguate their vagueness. This makes future analysis possible
even when the division information is absent, as may be the case in later published patents to which NSC
no longer claims their right.
6. Discussions
This section discusses the ﬁndings, experiences, and implications from the above application examples and
evaluation results. Related studies are also reviewed, of which some inspire our solutions and some compen-
sate our work.
The patent sections appear quite regular and each has its own functions in describing the innovations. This
regularity makes the segment matcher a simple case to design. Our ad hoc implementation shows only a frac-
tion of segments (less than 3%) fails to be extracted. Most failure cases are due to the omission of the corre-
sponding sections.
The purpose of summarization is to facilitate people’s understanding of a text quickly or easily. In the pat-
ent analysis scenario for patent map generation, the tasks include quickly spotting the topic-relevant sections
and in those spotted sections quickly focusing on the topic-indicative terms for classiﬁcation. Our work
through document segmentation and summarization has provided strong evidence to help solve these tasks.
Speciﬁcally, our results show that the Abstract, Summary, and summaries from each section in a patent doc-
ument are the most topic-relevant sections, regardless of whether the classiﬁcation is for technological aspects
or functional aspects. The implication is that if one would like to quickly determine a patent’s category based
on only a few terms in a quick pace, one should ﬁrst read the Abstract section or the Summary section. Or
alternatively, one could ﬁrst browse the ‘‘segment extracts’’ generated automatically.
However, our heuristic-based method needs further improvement to yield summaries suitable for direct
manual analysis, especially for the ‘‘summary of the invention’’ and ‘‘detailed description’’ sections. Although
‘‘problems to be solved’’ extracted from the background section seem feasible, as shown in our example, auto-
mated summarization of ‘‘the solution methods’’ is still a challenge. In addition, the claims in patent docu-
ments are written in a special style that is not easy to read. It is thus also an important part that needs
further processing. Recent studies have shown promising in transforming, although not summarizing, original
long claims into short sentences to inc ease readability (Sheremetyeva, 2003; Shinmori, Okumura, Marukawa,
& Iwayama, 2003).
An eﬃcient key term extraction algorithm is presented and used in the text mining process. Although Fagan
(1989) and Smadja (1993) had presented similar phrase extraction algorithms without using machine-readable
dictionaries, their methods use corpus-wide statistical information such as document frequency of a term or a
pair of terms. As such, their results and eﬀectiveness depend on the corpus used. In contrast, ours can be con-
sidered as rule-based. It uses only three simple rules to respectively drop, merge, and accept the sub-phrase
units during a merging back process based only on their term frequencies within a document. The accepted
repeated patterns are then ﬁltered by a stopword list. As such, its eﬀectiveness depends on whether our
assumption (i.e., ‘‘If a document focuses on a topic, it is likely to mention a set of strings repeatedly’’) holds
for the document language and the domain we are dealing with. For languages like Chinese or for domains
like the technical patents, our method works well in terms of non-dictionary topical terms that can be
extracted.
The co-word analyses based on document-wide co-occurrence or latent semantic indexing require enor-
mous computation for large collections. Therefore, an analysis based on snippet-wide co-occurrence is
devised. Although such an idea has been proposed previously, such as those in Brown, Della Pietra, De Souza,
Y.-H. Tseng et al. / Information Processing and Management 43 (2007) 1216–1247 1241
Au
th
or
's 
  p
er
so
na
l   
co
py
Al Shehabi, Hoﬀmann, and Francois (2003) pointed out that this method only provides the analyst with gen-
eral overview of the topics covered by the patents. They then proposed a MultiSOM model that introduces the
concepts of viewpoints and dynamics to assist information analysis based on its multi-map display and its
inter-map communication process. Speciﬁcally, each viewpoint corresponds to a map which is created based
on a speciﬁc section of the patent. Inter-map communications are activated through the same set of patents in
diﬀerent maps. The advantages of the MultiSOM method include reducing the noise which is inevitably gen-
erated in an overall classiﬁcation approach while increasing the ﬂexibility and granularity of the analyses.
With this potential usefulness, we started to try from the basic SOM by use of the tool developed by Kle-
iweg (Extended Kohonen maps). We used the default setting of the tool and varied the map size from 8 · 8,
10 · 10, 16 · 16, to 34 · 34. Unfortunately, all these maps could not lead us to a meaningful result for this
NSC patent set. The resulting SOMs do not show desired clustering when each patent was labeled with the
academic divisions introduced above. Most divisions scatter all over the map. Even the most unique Biotech-
nology has outliers in diﬀerent locations. In the end, no further variation of SOM was tried.
In another attempt to compare our results with others’, we also have tried to cluster these NSC patents
based on their co-cited and co-citing intensity. But only 123 (among 612) patents are co-cited by others result-
ing in 99 co-cited pairs and only 175 (among 612) patents co-cite others resulting in 143 co-citing pairs. Such
sparseness may lead to biased analysis. Therefore, citation analysis is not suitable in this case.
In short, we have tried to compare our approach with others, but this eﬀort has not yet led to meaningful
results.
7. Conclusions and future work
This paper describes a series of mining techniques that conforms to the analytical process adopted by and
used to train patent analysts (at least in Taiwan, see Chen, 1999). The automation of the whole process not
only helps create ﬁnal patent maps for topic analysis, but also facilitates other patent analysis tasks because
each step in this process has its own application. For example, after segmentation, more eﬀective classiﬁcation
can be achieved by combining individual segment matching rather than by whole patent matching (Kim,
Huang, Jung, & Choi, 2005). After abstraction, the topics, functions, or technologies revealed in each patent
can be more easily accessed and shared by the analysts. After keyword extraction and co-word analysis, rel-
evant terms can be suggested to users in prior art search to relieve the human burden in devising domain-spe-
ciﬁc search terms. After clustering, the patent collection is organized in a way that may complement the IPC or
UPC partition of the collection for analytic purpose. And ﬁnally, visualization is a way to combine all these
results to suggest patterns, relations, or trends.
In the design of these techniques, we have proposed a rigorous approach to verify the usefulness of segment
extracts as the document surrogates, a dictionary-free keyphrase extraction algorithm, an eﬃcient co-word
analysis method, and an automatic procedure to produce generic cluster titles. Evaluation of these techniques
has shown some success.
Nevertheless, more patent-related text mining issues can be studies. Unlike scientiﬁc publications, the reg-
ular style of the patent documents deserves more attention. So far we only use the summaries of the segments
for document surrogates. The functions of each segment have yet to be explored. For example, one may use
only the background segment for domain analysis, since it covers the domain background of a patent, not the
details of it. Moreover, one may extract the problem to be solved from the background segment and major
solution methods from the summary of the invention with more sophisticated summarization techniques.
By clustering the problems and solutions individually like the patent mapping task in the NTCIR Workshop
4, an analytic map similar to the technology-eﬀect matrix can be created for a domain of patents. Our future
work may explore this direction in using the patent segments.
Acknowledgements
This work is supported in part by NSC under the grants numbered: NSC 93-2213-E-030-007- and NSC
94-2524-S-003-014-.
Y.-H. Tseng et al. / Information Processing and Management 43 (2007) 1216–1247 1243
Au
th
or
's 
  p
er
so
na
l   
co
py
References
ACL-2003 Workshop on Patent Corpus Processing, 12 July 2003, Sapporo, Japan. http://www.slis.tsukuba.ac.jp/~fujii/acl2003ws.html.
ACM SIGIR 2000 Workshop on Patent Retrieval. http://research.nii.ac.jp/ntcir/sigir2000ws/.
Archibugi, D., & Pianta, M. (1996). Measuring technological change through patents and innovation survey. Technovation, 16(9),
451–468.
Bay, Y.-M. (2003). Development and applications of patent map in Korean high-tech industry. The ﬁrst Asia-Paciﬁc conference on patent
maps, Taipei, October 29, pp. 3–23.
Be’de’carrax, C., & Huot, C. (1994). A new methodology for systematic exploitation of technology databases. Information Processing &
Management, 30(3), 407–418.
Bekkerman, R., El-Yaniv, R., Winter, Y., & Tishby, N. (2001). On feature distributional clustering for text categorization. In Proceedings
of the 24th annual international ACM-SIGIR conference on research and development in information retrieval, pp. 146–153.
Booker, A., Condliﬀ, M., Greaves, M., holt, F. B., Kao, A., Pierce, D. J., et al. (1999). Visualizing text data sets. IEEE Computing in
Science and Engineering, 1(4), 26–34.
Brown, P. F., Della Pietra, V. J., De Souza, P. V., Mercer, R. L., & Lai, J. C. (1992). Class-based N-gram models of natural language.
Computational Linguistics, 18(4), 467–479.
Campbell, R. S. (1983). Patent trends as a technological forecasting tool. World Patent Information, 5(3), 137–143.
Chen, B. (1999). Introduction to patent map. Lecture notes for the training of patent mapping and patent analysis. Taipei, National Science
Council (in Chinese).
Choueka, Y. (1988). Looking for needles in a haystack, or locating interesting collocational expressions in large textual databases. In
Proceedings of the RIAO, pp. 609–623.
Deerwester, S., Dumais, S. T., Furnas, G. W., Landauer, T. K., & Harshman, R. (1990). Indexing by latent semantic analysis. Journal of
the American Society for Information Science, 41, 391–407.
Document Understanding Conferences. http://www-nlpir.nist.gov/projects/duc/.
Ernst, H. (1997). Use of patent da a for technological forecasting: the diﬀusion of CNC-technology in the machine tool industry. Small
Business Economics, 9, 361–381.
Fagan, J. L. (1989). The eﬀectiveness of a nonsyntactic approach to automatic phrase indexing for document retrieval. Journal of the
American Society for Information Science, 40(2), 115–132.
Fall, C. J., Torcsvari, A., Benzineb, K., & Karetka, G. (2003). Automated categorization in the international patent classiﬁcation. ACM
SIGIR Forum, 37(1), 10–25.
Fang, H., Tao, T., & Zhai, C. X. (2004). A formal study of information retrieval heuristics. In Proceedings of the 27th annual international
ACM SIGIR conference on research and development in information retrieval, Sheﬃeld, United Kingdom, pp. 49–56.
Fattori, M., Pedrazzi, G., & Turra, R. (2003). Text mining applied to patent mapping: a practical business case.World Patent Information,
25, 335–342.
Fayyad, U., Piatetsky-Shapiro, G., Smyth, P., & Uthurasamy, R. (1996). Advances in knowledge discovery and data mining. AAAI Press/
The MIT Press.
Frakes, W. B., & Baeza-Yates, R. (1992). Information retrieval: Data structure and algorithm. Prentice Hall.
Unfortunately, most data mining technologies cannot be used with large volumes of data. Further, most
analytical techniques used in data mining are algorithmic-based rather than data-driven, and as such, there
are currently little synergy between data mining and data warehouses. Moreover, from a usability perspec-
tive, traditional data mining techniques are too complex for use by database administrators and applica-
tion programmers, and are too diﬃcult to change for a diﬀerent industry or a diﬀerent customer.
One analytic algorithm that performs the task of modeling multidimensional data is ‘‘cluster analysis’’.
Cluster analysis ﬁnds groupings in the data, and identiﬁes homogenous ones of the groupings as clusters.
If the database is large, then the cluster analysis must be scalable, so that it can be completed within a
practical time limit.
In the prior art, cluster analysis typically does not work well with large databases due to memory limita-
tions and the execution times required. Often, the solution to ﬁnding clusters from massive amounts of
detailed data has been addressed by data reduction or sampling, because of the inability to handle large vol-
umes of data. However, data reduction or sampling results in the potential loss of information.
Thus, there is a need in the art for data mining applications that directly operate against data warehouses,
and that allow non-statisticians to beneﬁt from advanced mathematical techniques available in a relational
environment.
Y.-H. Tseng et al. / Information Processing and Management 43 (2007) 1216–1247 1245
Au
th
or
's 
  p
er
so
na
l   
co
py
The 8th Science and Technology Foresight Survey – Study on Rapidly-Developing Research Areas – Interim Report, Science and
Technology Foresight Center, National Institute of Science & Technology Policy, Japan, 2004. http://www.nistep.go.jp/index-e.html.
Tseng, Y.-H. (1999). Content-based retrieval for music collections. In Proceedings of the 22nd international ACM SIGIR conference on
research and development in information retrieval, August 15–19, Berkeley, USA, pp. 176–182.
Tseng, Y.-H. (2002). Automatic thesaurus generation for Chinese documents. Journal of the American Society for Information Science and
Technology, 53(13), 1130–1138.
Tseng, Y.-H., Juang, D.-W. (2003). Document-self expansion for text categorization. In Proceedings of the 26th international ACM SIGIR
conference on research and development in information retrieval, pp. 399–400.
Tseng, Y.-H., Juang, D.-W., & Chen, S.-H. (2004). Global and local term expansion for text retrieval. In Proceedings of the fourth NTCIR
workshop on evaluation of information retrieval, automatic text summarization and question answering, June 2–4, Tokyo, Japan.
Tseng, Y.-H., Juang, D.-W., Wang, Y.-M., & Lin, C.-J. (2005). Text mining for patent map analysis. In Proceedings of IACIS Paciﬁc 2005
conference, May 19–21, Taipei, Taiwan, pp. 1109–1116.
Uchida, H., Mano, A., & Yukawa, T. (2004). Patent map generation using concept-based vector space model. In Proceedings of the fourth
NTCIR workshop on evaluation of information access technologies: information retrieval, question answering, and summarization, June 2–
4, Tokyo, Japan.
United States Patent and Trademark Oﬃce. http://www.uspto.gov/.
van Rijsbergen, K. Information retrieval. http://www.dcs.gla.ac.uk/Keith/Chapter.2/Table_2.1.html.
WordNet: a lexical database for the English language, Cognitive Science Laboratory Princeton University. http://wordnet.princeton.edu/.
Yang, Y., Ault, T., Pierce, T., & Lattimer, C. W. (2000). Improving text categorization methods for event tracking. In Proceedings of the
23rd annual international ACM-SIGIR conference on research and development in information retrieval, pp. 65–72.
Yang, Y., Liu, X. (1999). A re-examination of text categorization methods. In Proceedings of the 22nd annual international ACM-SIGIR
conference on research and development in information retrieval, pp. 42–49.
Yang, Y., Pedersen, J. (1997). A comparative study on feature selection in text categorization. In Proceedings of the international
conference on machine learning, pp. 412–420.
Ye, J.-Y. (2004). Evaluation of term suggestion in an interactive Chinese retrieval system. Master Thesis, Department of Library and
Information Science, Fu Jen Catholic University.
Yoon, B., & Park, Y. (2004). A text-mining-based patent network: analytical tool for high-technology trend. Journal of High Technology
Management Research, 15, 37–50.
Y.-H. Tseng et al. / Information Processing and Management 43 (2007) 1216–1247 1247
