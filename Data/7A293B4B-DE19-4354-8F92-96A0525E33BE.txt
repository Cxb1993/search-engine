 ii
目錄 
目錄.................................................................................. ii 
中文摘要............................................................................. iii 
英文摘要.............................................................................. iv 
報告內容............................................................................... 1 
一、 前言.......................................................................... 1 
二、 研究目的...................................................................... 1 
三、 主題性文字極性分析之研究...................................................... 1 
四、 時序性文件摘要之研究.......................................................... 5 
五、 產品評論探勘.................................................................. 8 
六、 計畫執行自評與討論........................................................... 10 
參考文獻.............................................................................. 11 
 
 
 iv
英文摘要 
 
The Web nowadays contains plenty of documents that most of them chronologically express real world 
events or happenings. In this research project, we will investigate an unsupervised learning algorithm to 
identify text polarities of a news event. Previous works on text polarity analysis generally rely on 
human-composed polarity lexicons. However, the pre-defined lexicons are usually too general to adapt to all 
kinds of applications. In this project, we will analyze word usages of events in terms of Principal 
Components Analysis (PCA) to construct the polarity keywords of the events automatically. We will also 
revise the formula of correlation coefficient to solve the problem of text sparseness in text polarity analysis. 
The revised formula will distinguish representative samples from noisy data to improve the performance of 
text polarity identification. In addition to identify the polarities of events, the identified polarities will be 
summarized to provide users all-around and unbiased understandings of the event stories. Previous 
researches on text summarization indicate that a representative summary should possess high diversity to 
detail the content of the summarized documents. However, when the documents are related to an 
evolutionary news event, only diversity is not enough and the temporality of the event documents should be 
considered to make the event summary comprehensible. It is interesting to note that polarities of a news 
event usually react to one another. For instance, the event of a presidential campaign would consist of 
reactions of various parities. To catch the reactions or dependencies of polarities, we will identify temporal 
developments of polarities and link them chronologically according to their timestamps and text similarities 
to form the evolution graph of an event. With the help of summaries and evolution graphs, users can 
understand the storylines of events easily.  
 
Keywords: text polarity analysis, event summarization, temporal text mining. 
 
 
 
 
 
 
 2
 
其中 an,i，如果以 row 的觀點來看代表第 篇區塊向量中第 i 個人名的人名頻率，如果以 column 的觀點
來看，代表第 i 個人名向量中，此人名出現在第 篇區塊的次數。我們使用 Principal Component Analysis 
(PCA)來進行人名極性分群，PCA 一開始會透過矩陣 A 內的資訊來建立一個 人名關係矩陣 R，這
個矩陣中的( , )-entry 是人名 與人名 的相關係數，如下所示 : 
 
 
 
ri,j的範圍介於-1 到 1 之間，上式中的 u~i代表第 個人名出現在所有區塊的平均頻率，u~j亦然。當 ri,j > 0
時，代表人名 ui與 uj 傾向於共同出現(或共同不出現)於文件區塊，當 ri,j < 0 時，代表人名 ui與 uj傾向
於不共同出現，而當 ri,j = 0 時，代表人名 ui與 uj彼此獨立。我們研究發現 R 的主要特徵向量(principal 
eigenvector)可顯示人名於事件的重要性，此外，在 PCA 中，相關係數的正規化程序賦予矩陣 正值與
負值，並讓所求的特徵向量有正負之分，而這正負號剛好可以將人名分成兩互斥族群。 
運用 PCA 來處理文字性資料會遭遇資料稀疏性(data sparseness)問題，在此，資料稀疏性會導致以下兩
種情況：(1)當兩個人名常常共同出現時，資料稀疏性有可能會導致相關係數被低估。(2)而當兩個人名
不相關時，意謂不常一起出現，資料稀疏性也有可能會導致相關係數被高估。為解決這些問題，我們
提出了 weighted correlation coefficient，將相關係數做一些變化，加入考量共同出現與不共同出現的因
素，其公式如以下所示： 
 
 
( )/ 
 
 
代表人名 與人名 共同出現的區塊集合， 是一個調整共同出現與不共同出現的系統參數，該值
介於 0 到 1 之間，當 時，該式便與原先的相關係數公式同。此外，考量離題區塊也會導致相關
係數過度估計，這是由於人名常常一起不出現於離題區塊的現象所造成的，這會讓原本負相關的人名
變成正相關，在本研究，我們提出了一個離題區塊去除的方法(off-topic block elimination – OBE)，我們
將所有的人名向量加總平均，並設立一個向量相似門檻值 β 以濾除離群的區塊，在我們的實驗中，我
們設 β=0.3 以觀察去離題區塊是否會影響人名極性分群的準確度(accuracy)。 
結果與討論 
在實驗部分，我們收集了 12 個主題，分別包含 4 個體育、4 個政治與 4 個商業事件，所有的新聞文件
資料均來自 Google News。我們首先探討去離題文方法與 weighted correlation coefficient 對於準確度的
影響，我們分別對事件內累積頻率前 50%，60%與 70%的人名進行 PCA 極性辨識，並且調整系統參數
值由 0 到 1，所得結果如下： 
 4
我們發現，當 傾向於 1 時，準確度較高，換句話說，互斥的人名傾向不共同出現，這有幾種可能：(1)
記者的寫作習慣不同，一篇新聞只討論某個人物，而讓 較高時有較佳的準確度。(2)新聞主題的選擇也
會讓人名的出現產生不同的分配結果。此外，我們與知名的 HAC(Hierarchical Agglomerative Clustering)
及 K-means 演算法進行人名極性分群比較，結果如下所示： 
表一、K=50%時與其他方法的比較 
K=50% accuracy
Our method 81.58%
K-means (best) 72.09%
K-means (average) 64.71%
K-means (worst) 58.14%
HAC (single) 63.29%
HAC (complete) 70.89%
HAC (average) 68.35%
HAC (centroid) 67.09%
Baseline 53.16%
表二、K=60%時與其他方法的比較 
K=60% accuracy
Our method 79.81%
K-means (best) 66.13%
K-means (average) 58.02%
K-means (worst) 54.03%
HAC (single) 55.65%
HAC (complete) 68.70%
HAC (average) 61.74%
HAC (centroid) 58.26%
Baseline 50.43%
表三、K=70%時與其他方法的比較 
K=70% accuracy
Our method 73.97%
K-means (best) 64.60%
K-means (average) 56.93%
K-means (worst) 52.17%
HAC (single) 51.90%
HAC (complete) 55.06%
HAC (average) 56.96%
HAC (centroid) 55.70%
Baseline 50.63%
由上表可知，我們的方法較其他兩分群法有更好的極性分群準確度，而在未來的研究中，我們希望能
夠去探究 β 的設定對於去離題文還有準確度的影響。 
 
 6
圖四、summary-to-document content similarity 實驗比較圖 
SDCS 主要是檢視摘要內容於原始文件內容的相關度或覆蓋率，由於 TSCAN 僅摘要主題文件內最重要
的故事主軸，一些較細微的主題內容並不會納入摘要結果，因此，TSCAN 的摘要覆蓋率會較其他方法
為低，但在產生小量摘要內容時(即 L 值小時)，TSCAN 會因其專注於重要故事主軸而能產生高品質的
摘要結果。 
圖五、ROUGE-1 實驗比較圖 
 8
五、產品評論探勘 
研究方法概述 
關於這研究議題，我們發表了一篇 AIRS 會議論文[15]與一篇 Decision Support Systems 期刊論文[6]。當
許多產品評論探勘的研究致力於探索和分析評論中的極性意見時，鮮少有研究專注於評論內容品質的
判斷。Web 2.0 的精神在於鼓勵知識的分享，因此大部分的線上協同工具並不會限制使用者撰寫評論的
內容及方式。自由的編寫方式導致評論之間的內容品質有極大的差異。我們觀察亞馬遜網站上所收集
的產品，發現有不少的評論僅帶有簡單的意見描述，例如「I love this camera and it is really nice」，這類
型的評論缺乏建設性的描述，應避免使用於監督式意見及評論探勘的訓練流程中。實際上，許多電子
商務網站(如亞馬遜)都已經開始注意到評論品質不一的問題且提供了一個讓使用者對評論進行投票的
系統，並藉由投票的結果來評估評論的資訊品質以將評論排序。但這類的投票的結果仍受到不公正投
票偏差(imbalance vote bias)、贏者迴圈偏差(winner circle bias)以及早起者偏差(early bird bias)等影響，
導致這類投票系統無法有效反應評論的資訊品質[11]。因此，目前有迫切的需要來設計有效文字探勘演
算法來協助網際網路使用者、企業、及意見探勘演算法過濾出具資訊價值的產品評論。 
在本研究議題，我們將產品評論之品質評估視為一個分類問題，並且採用多類別支持向量器(multiclass 
support vector machine, multiclass SVM) [17]來訓練評論品質分類器。另外，我們引用了資訊品質理論
(information quality) [16]來分析評論內容以求得具代表性的評論特徵(features)，這些特質能提升評論分
類之效能。資訊品質是從資訊消費者的觀點來研究資訊項目(information item)的特性以及找出資訊項目
的重要特徵[16]。資訊品質的理論與架構在過去二十年間已被大量的運用在各種的領域中，在本計畫，
我們將一篇評論視為一個資訊項目並以Wang和Strong提出的資訊品質架構[16]為基礎來衍生資訊導向
的評論特徵，下表為該資訊品質架構所包含的資訊品質維度，但有些維度不適用於產品評論品質的評
估，因此在本研究中，我們僅考慮九個資訊品質維度以及 51 個評論特徵，並用其於分類器訓練及測試。
藉由資訊品質理論，我們可提升評論品質評估之準確度，另外，藉由分析所訓練的分類模型，我們可
了解哪些評論特徵是具有資訊價值的。 
表四、階層式資訊品質架構[16] 
資訊品質類別 
(IQ category) 
資訊品質維度(IQ dimensions) 
內在的 
(Intrinsic IQ) 
可信度(believability)、正確性(accuracy)、客觀性
(objectivity)、來源信譽(reputation) 
內容的 
(Contextual IQ) 
附加價值(value-added)、相關性(relevancy)、適時性
(timeliness)、完整性(completeness)、可用資訊量
(appropriate amount of information) 
表述的
(Representational IQ) 
可解釋性(interpretability)、容易理解性(ease of 
understanding)、表述一致性(representational 
consistency)、表述精簡性(concise representation) 
易存取的 
(Accessibility IQ) 
易存取性(accessibility)、存取安全性(access security) 
 10
表七、SMM SVM with the linear kernel 之實驗比較 
digital cameras mp3 players 
 
mac-precision mac-recall mac- F1 mic-F1 mac-precision mac-recall mac-F1 mic-F1
Bag-of-word [12] ****0.424 ****0.323 ****0.366 ****0.670 ****0.361 ****0.257 ****0.300 ****0.580
shallow syntatic [18] ****0.279 ****0.283 ****0.281 ****0.608 ****0.213 ****0.239 ****0.225 ****0.298
lexical [10] ****0.595 ****0.362 ****0.450 ****0.744 ****0.472 ****0.306 ****0.371 ****0.683
informativeness [11] 0.853 ***0.562 *0.677 ****0.886 ***0.794 0.463 *0.585 **0.844
Our method 0.856 0.593 0.701 0.906 0.845 0.483 0.614 0.862
*, **, ***, and **** represent right-tail paired t-tests with α=0.1, 0.05, 0.025, and 0.01, respectively. 
表八、OVA SVM with the RBF kernel 之實驗比較 
digital cameras mp3 players 
 
mac-precision mac-recall mac- F1 mic-F1 mac-precision mac-recall mac-F1 mic-F1
Bag-of-word [12] ****0.696 ****0.412 ****0.517 ****0.782 ****0.711 ****0.389 ****0.503 ****0.757
shallow syntatic [18] ****0.796 ****0.577 ****0.669 ****0.888 0.817 0.491 0.613 ****0.852
lexical [10] **0.821 ****0.576 ***0.677 ****0.895 ****0.801 0.515 0.627 ***0.856
informativeness [11] 0.836 0.590 0.692 ****0.904 ****0.800 **0.488 ***0.606 ****0.856
Our method 0.866 0.597 0.707 0.914 0.836 0.505 0.630 0.876
 
六、 計畫執行自評與討論 
在本計畫執行的過程中，我們分別對文字極性辨識、文件摘要化與產品評論探勘等議題進行了深度的
研究與探討。對於文字極性辨識，我們已將初步研究成果發表於 International Conference on 
Computational Linguistics，該會議為自然語言處理之重要發表場合，我們所研究的人名極性判斷雖與文
字極性分析有關，但至今仍無相關之研究發表，可謂為一新興的研究議題。此外，該議題更可延伸至
多極性議題之人名極性辨識與時序性極性摘要，極具研究之潛能。文件摘要方面，我們已有論文發表
於 ACM SIGIR 與 IEEE Transaction on Knowledge and Data Engineering (TKDE)期刊上，這兩刊物分別為
資訊檢索與資料探勘之頂級發表場合。此外，我們的摘要化方法考慮了文字的時序性，亦被 SIGIR 的
論文評審視為一創新之研究。由其獨特性，我們也將該摘要化方法申請台灣與美國的專利以期應用之
可行性。產品評論探勘方面，我們已有論文發表於 Asia Information Retrieval Symposium (AIRS)與
Decision Support Systems (DSS)，AIRS 為亞太地區重要的資訊檢索會議，而 DSS 為決策科學之重要期
刊。除上述成果外，我們另有一篇時序性文件自動分群的論文發表於 ACM Transaction on Information 
Systems (TOIS)，TOIS 亦為資訊檢索領域之頂級期刊。在執行本計畫的期間內，我們總計發表了 6 篇
與本計畫相關的期刊與國際會議論文，且仍有一篇期刊論文正進行審查，由學術發表的角度來看，我
們有確實執行計畫。 
 
 
 
 12
(2006), 573-580. 
14. Tadashi Nomoto and Yuji Matsumoto, “A new approach to unsupervised text summarization,” In 
proceedings of the 24th annual international ACM SIGIR conference on research and development in 
information retrieval (2001), 26-34. 
15. You-De Tseng and Chien Chin Chen, "Using an Information Quality Framework to Evaluate the Quality 
of Product Reviews," In Proceedings of the Fifth Asia Information Retrieval Symposium (AIRS), 
100-111, October 21-23 2009. 
16. Richard Y. Wang and Diane M. Strong, “Beyond Accuracy: What Data Quality Means to Data 
Consumers,” Journal of Management Information Systems 12 (4) (1996) 5-33. 
17. Jason Weston and Chris Watkins, Multi-class Support Vector Machines, Technical Report CSD-TR-98-04, 
Royal Holloway, University of London, Department of Computer Science (1998). 
18. Zhu Zhang and Balaji Varadarajan, “Utility Scoring of Product Reviews,” in Proceedings of the 15th 
ACM international Conference on Information and Knowledge Management (2006) 51-57. 
 
 
 
 
 
 14
3. 請依學術成就、技術創新、社會影響等方面，評估研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）（以
500 字為限） 
在本計畫執行的過程中，我們分別對文字極性辨識、文件摘要化與產品評論探勘等議題進
行了深度的研究與探討。對於文字極性辨識，我們已將初步研究成果發表於 International 
Conference on Computational Linguistics，該會議為自然語言處理之重要發表場合，我們所
研究的人名極性判斷雖與文字極性分析有關，但至今仍無相關之研究發表，可謂為一新興
的研究議題。此外，該議題更可延伸至多極性議題之人名極性辨識與時序性極性摘要，極
具研究之潛能。文件摘要方面，我們已有論文發表於 ACM SIGIR 與 IEEE Transaction on 
Knowledge and Data Engineering (TKDE)期刊上，這兩刊物分別為資訊檢索與資料探勘之頂
級發表場合。此外，我們的摘要化方法考慮了文字的時序性，亦被 SIGIR 的論文評審視為
一創新之研究。由其獨特性，我們也將該摘要化方法申請台灣與美國的專利以期應用之可
行性。產品評論探勘方面，我們已有論文發表於 Asia Information Retrieval Symposium 
(AIRS)與 Decision Support Systems (DSS)，AIRS 為亞太地區重要的資訊檢索會議，而 DSS
為決策科學之重要期刊。除上述成果外，我們另有一篇時序性文件自動分群的論文發表於
ACM Transaction on Information Systems (TOIS)，TOIS 亦為資訊檢索領域之頂級期刊。在
執行本計畫的期間內，我們總計發表了 6篇與本計畫相關的期刊與國際會議論文，且仍有
一篇期刊論文正進行審查，由學術發表的角度來看，我們有確實執行計畫。 
 
 
 
 
 2
還要能根據使用者的 context information 來提供正確的地理資訊。作者運用了 German Wikipedia 作
為系統中結構性 knowledge base 的資訊來源，並透過資訊擷取(information extraction)的技術來強化
knowledge base 內的資訊。作者提出了一嶄新的 supervised learning 方法(稱之為 self-annotation)來擷
取 entity 之間的 relation，該方法可自動標註 relation extraction model 所需的訓練資料集，並可使用
無結構性文字作為 model input 來訓練擷取模型。除了該篇論文，我們也觀察到有越來越多的研究
開始採用 Wikipedia 來解決 entity relation extraction 等議題。 
 
二、與會心得 
本屆 COLING 吸引相當多的學者聽取論文報告，在會場我也遇到了不少來自台灣的學者，如元智
大學的蔡宗翰教授與中研院資訊所的陳克健教授，我並與蔡教授討論了一些未來的學術研究方
向。除了台灣的學者，我發現到會場內有相當多的中國學者與研究生，本屆 COLING 亦有相當多
的論文是由中國學者所貢獻的，由此可感受到中國學界對於自然語言處理與資訊檢索的研究十分
重視。由於中國的快速崛起，中文資訊處理越顯重要，我們應需十分的努力，讓台灣在中文資訊
處理方面能佔有一席之地。 
 
三、考察參觀活動(無是項活動者略) 
無 
四、建議 
無 
 
五、攜回資料名稱及內容 
大會論文集 
 
六、其他 
無 
 
 
 
97年度專題研究計畫研究成果彙整表 
計畫主持人：陳建錦 計畫編號：97-2221-E-002-225-MY2 
計畫名稱：以主成分分析為基礎之非監督式時序性文字極性辨識研究 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 1 1 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 2 2 100%  
博士生 1 1 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 3 3 100%  
研究報告/技術報告 0 0 100%  
研討會論文 3 3 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 1 1 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
 
