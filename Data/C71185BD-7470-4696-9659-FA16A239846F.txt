因為沒有現今常用的裝置可支援與顯示如此低解析度影像。基於以上
理由，我們也將研發數位半色調視訊浮水印技術於高解析度輸出裝置
如電子紙、雷射印表機、掃瞄器等使用。 
研究方法 
於發展能在電子紙裝置上播放半色調視訊之技術過程中，我們發
現了第一個問題：在電子紙播放視訊的過程中，相同位置上黑點與白
點高速交互變換，將產生對人類視覺強烈影響之現象，稱為閃爍
(flicker)。由於閃爍對於人類視覺有相當強烈且負面的影響，因此，
消除閃爍為半色調視訊技術發展的首要條件。為解決閃爍現象，我們
引 進 人 類 閃 爍 現 象 靈 敏 函 數 (human flicker sensitivity 
function)，將閃爍現象區分為必要閃爍像素及非必要閃爍像素。必
要閃爍像素為視訊中畫面動量(motion)產生的正常影像變動，而非必
要閃爍則為半色調轉換過程中所產生的額外雜訊(noise)。因此，借
由此分類方式可將所需刪除的非必要的閃爍去除。 
在去除閃爍之過程中，為節省儲存空間，我們只記錄每個訊框
(video frame)與其參考訊框之間的必要閃爍像素，其後發現此一記
錄方式使得單一訊框之構成區塊(block)具有相當程度的自我相似性
(self-similarity)，且多數為零區塊(zeros block)，有助於發展視
訊壓縮技術(video compression technique)。因此，我們結合區塊
[1] Chao-Yung Hsu, Chun-Shien Lu, and Soo-Chang Pei, ``Scalable 
Multi-Layer Halftone Video Display for Electronic Paper,’’ Proc. IEEE 
Int. Conf. on Multimedia and Expo, 2008. 
[2] Chao-Yong Hsu, Chun-Shien Lu, and Soo-Chang Pei, ``Compression 
of Halftone Video for Electronic Paper,’’ Proc. IEEE Int. Conf. on Image 
Processing, 2008. 
[3] Chao-Yung Hsu, Chun-Shien Lu, and Soo-Chang Pei, ``Video 
Halftoning for Electronic Paper,’’ submitted to IEEE Trans. on Circuits 
and Systems for Video Technology, 2008. 
supported by the architecture of e-paper or not. In view of this, we
aim to propose a power-scalable multi-layer halftone video dis-
play technique that provides ƀexible video display with different
frame rates on e-paper. We study and compare uniform sampling
and non-uniform sampling of original halftone video for display
with different frame rates. The halftone video is generated using
our previous video halftoning method [7], which achieves tempo-
ral consistency with efſcient ƀicker reduction. Power saving is
measured in terms of number of ƀickers per second since power is
consumed when halftone values are changed. To our knowledge,
this is still a rather unexplored ſeld.
2. VIDEO HALFTONING PRESERVING TEMPORAL
CONSISTENCY
2.1. Flicker Flaws in Video Halftoning
A general video halftoning method consists of spatial error diffu-
sion and temporal error diffusion, both of which create the ƀicker
phenomenon. Flicker means the change of halftone values (either
from black to white or from white to black) during the display of
consecutive video frames that will be easily perceived by human
eyes. For temporal error diffusion, this procedure will cause the
pixels located at the same positions of neighboring video frames
to have different halftone values due to the introduction of diffused
temporal errors in particular when the pixels have the same or sim-
ilar gray values. For spatial error diffusion, the diffused spatial er-
rors will affect the halftoning results of the subsequent gray-scale
pixels. If the area of gray-scale pixels located at the same posi-
tions of neighboring video frames is affected by different diffused
spatial errors, then the resultant halftone values may be different,
leading to ƀicker ƀaws. This situation occurs with higher proba-
bilities in particular with pixels with gray-scale values close to the
quantization threshold (e.g., 128) of halftoning. In our study, the
ƀicker ƀaws caused by either temporal error diffusion or spatial
error diffusion are called illegal ƀicker, which must be eliminated.
2.2. GOP-based Inter-Frame Reference Video Halftoning
In [7], we presented a new video halftoning method, which is com-
posed of intra-frame error diffusion and inter-frame reference, to
reduce ƀicker ƀaws in halftone video. In our method, the video
frames are divided into many groups of pictures (GOPs) for video
halftoning. Each GOP consists of an I frame and a number of
P frames, where P frames refer to I frame during the halfton-
ing process. During halftoning, the ſrst video frame, I(x,y,z1), is
halftoned by spatial error diffusion [4] to generate the ſrst halftone
frame H(x,y,z1). To reduce the ƀicker ƀaws, the remaining halftone
video frames are not generated by means of spatial error diffusion.
On the contrary, each of them is compared with its previous frame
during the subsequent halftoning process. For example, the second
frame I(x,y,z2) is compared with the ſrst one for inter-frame error
diffusion. If the gray level difference between two pixels located
at the same position is smaller than a so-called ƀicker sensitivity
threshold, then the halftone value of the pixel in the second frame
is assigned to be the same as that in the ſrst frame; otherwise,
the halftone value is determined via a quantization process in er-
ror diffusion. No matter which condition occurs, the quantization
errors still need to be diffused. In fact, the former is similar in
principle to block-based compression with skip mode for bit-rate
saving. Therefore, our halftoning processing also has potential to
beneſt halftone video compression. In the proposed video halfton-
ing method, video frames are halftoned sequentially.
3. PROPOSED METHOD
In this section, a power-scalable multi-layer halftone video dis-
play scheme is proposed for display over e-paper. In order to serve
to display under different frame rates, the original halftone video
obtained using [7] is divided into 1 base layer and several enhance-
ment layers. Basically, the base layer contains the most important
information that must be displayed ſrst while the enhancement
layers are used to improve video quality if higher frame rate is
permitted. The idea is similar to traditional layer video coding
in that the base layer and more/fewer enhancement layers are in-
corporated for display if high/low frame rate is considered in an
e-paper device.
An intuitive method for arranging the halftone video frames
into a multi-layer structure is to apply uniform sampling. More
speciſcally, a video sequence is divided into many segments of the
same size. Next, all the ſrst frames in the intervals are collected
to form the base layer, all the second frames in the segments are
collected to form the ſrst enhancement layer, and so on. Actually,
uniform sampling is a simple way to achieve the goal of display-
ing a halftone video with different frame rates. However, uniform
sampling will lead to severe ƀicker ƀaws because the relationship
between neighboring frames is broken due to sampling. In addi-
tion, the base layer may not contain the most important informa-
tion in a video. That is, uniform sampling produces a multi-layer
structure that violate the spirit of video shot change detection in
video summarization, where important video frames are preserved
with higher priority.
To deal with these two problems, non-uniform sampling is
adopted in our method.
3.1. Encoding Multi-Layer Halftone Video based on Non-Uniform
Sampling
In order to non-uniform sample a halftone video into one base
layer and a number of enhancement layers, we take advantage of
the GOP structure generated in our video halftoning method [7].
For generation of the base layer, we ſrst uniformly set the posi-
tions of the video frames in the base layer according to the frame
rate. Suppose the frame rate is f fps (frames per second). The
integer multiplier of f plus 1, i.e., fα+1 (where α ≥ 0 is an inte-
ger), will be deſned as the positions of video frames in base layer.
Here, the I frames of GOPs, which have positions close to fα+1,
are selected as elements of the base layer for a good video summa-
rization in a low frame rate situation. If no I frames are available,
then the P frames located at the positions of fα + 1 are selected.
An example of the base layer generation is shown in Fig. 2, where
there are 60 frames in a video clip and the frame rate is 15 fps. In
this example, the I frames with indices 1, 30, 46, and the p frame
with index 16 are chosen to constitute the base layer. Among them,
although frame 16 is a P frame, it must be chosen since there is no
I frame close to position 16. However, each P frame selected to be
in the base layer will be reconstructed by means of a logical XOR
process because P frames refer to their corresponding I frame in a
GOP during the halftoning process [7]. Under this circumstance,
a P frame is only used to store the different pixels between itself
and its corresponding I frame. Therefore, a P frame can be fully
1446
(a) Vassar
(b) Secretary
(c) Dolphin
Fig. 3. Comparisons of power consumption for halftone videos,
Vassar (a), Secretary (b), and Dolphin (c).
halftone video and our multi-layer halftone video were compared
in terms of HTPSNR. In Eq. (1), the video frame X is either a non-
layered halftone video frame or a multi-layer halftone video frame
while Y is an original gray-scale video frame. The HTPSNR val-
ues measured for the three video sequences, “Vassar,” “Secretary,”
and “Dolphin,” are shown in Fig. 4. We can observe from Fig. 4
that the HTPSNR values for the non-layer halftone video and our
multi-layer halftone video are almost the same. This implies that
our method does not degrade the quality of halftone videos.
5. CONCLUSION
In view of the fact that video halftoning will play an important role
in supporting the use of the emerging display device, e-paper, this
paper proposes a power-scalable multi-layer halftone video display
technique that can support halftone video display under various
frame rates. The main contribution is that our method can save
more power over the state of the art video halftoning method and
nearly does not introduce quality degradation. To our knowledge,
this is the ſrst work that can achieve ƀicker rate reduction and
power saving. Future work will study halftone video compression.
6. REFERENCES
[1] C. B. Atkins, T. J. Flohr, D. P. Hilgenberg, C. A. Bouman,
and J. P. Allebach, “Model-based color image sequence
quantization,” in Proc. SPIE/IST Conf. Human Vision, Visual
(a) Vassar (b) Secretary
(c) Dolphin
Fig. 4. Comparisons of halftone video quality for halftone videos,
Vassar (a), Secretary (b), and Dolphin (c).
Processing, and Digital Display V , Vol. 2179, pp. 310-317,
Feb. 1994.
[2] P. J. Barten, “Physical model for the contrast sensitivity of
the human eye,” in Proc. IS&T/SPIE Int. Symp. on Electronic
Imaging Science and Technology, Vol. 1666, San Jose, CA,
Feb. 9-14, pp. 57-74, 1992.
[3] G. P. Crawford, “A bright new page in portable displays,”
IEEE Spectrum, Vol. 37, pp. 40-46, Oct. 2000.
[4] C. Gotsman, “Halftoning of image sequence,” Vis. Comput.,
Vol. 9, No. 5, pp. 255-266, 1993.
[5] H. Hild and M. Pins, “A 3-D error diffusion dither algorithm
for half-tone animation on bitmap screens,” in State-of-the-
Art in Computer Animation-Proceedings of Computer Ani-
mation. Springer-Verlag, pp. 181-190, 1989.
[6] D. P. Hilgenberg, T. J. Flohr, C. B. Atkins, J. P. Allebach, and
C.A. Bouman, “Least-squares model-based video halfton-
ing,” in Proc.SPIE/IST Conf. Human Vision, Visual Process-
ing, and Digital Display V , Vol. 2179, pp. 7-10, 1994.
[7] C. Y. Hsu, C. S. Lu, and S. C. Pei, “Video halftoning preserv-
ing temporal consistency,” Proc. IEEE Int. Conf. on Multime-
dia and Expo, Beijing, China, 2007.
[8] C. S. Lu and C. Y. Hsu, “Geometric distortion-resilient image
hashing scheme and its applications on copy detection and
authentication,” ACM Multimedia Systems Journal, special
issue on Multimedia and Security, Vol. 11, No. 2, pp. 159-
173, December 2005.
[9] Mitsubishi Electric Research Laborato-
ries, “MERL multiview video sequences,”
ftp://ftp.merl.com/pub/avetro/mvctestseq.
[10] Z. Sun, “Video halftoning,” IEEE Trans. on Image Process-
ing, Vol. 15, No. 3, pp. 678- 686, 2006.
[11] http://www.eink.com
[12] http://www.sipix.com.tw
1448
frame, it is individually halftoned like via an image halfton-
ing procedure. For a P-frame, it is halftoned by storing the
different pixels between it and its corresponding reference I
frame. Therefore, several pixels of a halftoned P frame are
zeros. More specifically, since flicker flaw can be efficiently
reduced by our method, the background during a series of
video frames can be almost kept the same. As a result, this
will lead to efficient compression of a halftone video se-
quence by saving a lot of bit rates used for encoding the
changeable background due to the introduction of flicker
flaws. In other words, a video halftoning scheme that can
efficiently reduce the flickers is beneficial to achieve higher
compression ratio under the constraint of the same bit-rate.
3. PROPOSED METHOD
Different from quantization of gray-scale image, quantizing
the coefficients of halftone frames in the transform domain
may make decoded pixel values undefined in the spatial do-
main. This is because a decoded pixel value must be either
0 or 1 to meet the characteristic of halftone images. There-
fore, it is important to directly study spatial-domain quanti-
zation for halftone video compression.
Our halftone video compression scheme is mainly com-
posed of three components: block decomposition, block-
based halftone quantization, and source coding. It should be
noted that the input to the proposed scheme is the halftone
video generated using the video halftoningmethod described
in Sec. 2.
3.1. Block Decomposition
Given a frame of size m × n, it is first divided into k × k
blocks, called coding units. A coding unit is further de-
composed into a number of symbol blocks with a size of
r × r, where r is usually far less than k. Therefore, in
a coding unit, there will be in total (kr )
2 (= B) symbol
blocks. Lossy compression is achieved by finding represen-
tative blocks, called quantized symbol blocks, to replace the
original symbol blocks.
3.2. Block-based Halftone Quantization
The purpose of quantization in compressing halftone video
is to find representative symbol blocks. That is, the sym-
bol blocks will be represented with the quantized symbol
blocks via a quantization process under the constraint of ac-
ceptable distortion. In the halftone quantization process, the
smooth block (e.g., Fig. 1(a)) can be represented with differ-
ent halftone blocks (e.g., Figs. 1(b) and (c)), both of which
represent the same meaning in terms of gray-scale. In fact,
there are in total C168 (= 12870) halftone blocks to present
the gray-scale block in Fig. 1(a), where 16 comes from the
number of pixels in a block and 8 comes from the number of
either black points or white points in a smooth block. How-
ever, the frequently used blocks are limited. In the above
example, Fig. 1(b) can be replaced by Fig. 1(c) since the
visual difference between the two halftoned blocks is very
small, and thus, they play the same role. For this reason,
to achieve the goal of compression, the halftone quantiza-
tion process will be finding frequently used blocks as the
representative symbol blocks.
(a) (b) (c)
Fig. 1. An example of halftone quantization: (a) a 4 × 4
smooth block with gray-scale values 128; (b) a halftone ver-
sion of (a); and (c) another halftone version of (a).
3.2.1. Compression Ratio vs. Number of Quantized Symbol
Blocks
Let s (1 ≤ s ≤ (kr )2) be the number of representative or
quantized symbol blocks in a coding unit. Because log2(s)
bits are needed to store a compressed quantized symbol blocks,
the total bits used to store s compressed quantized symbol
blocks is (kr )
2 · log2(s). At the decoder side, s quantized
symbol blocks are stored required for decoding purpose and
r2 · s bits are needed to store them. Therefore, there are in
total
(
k
r
)2 · log2(s)+ r2 · s (1)
bits required to store a coding unit during compression. With
Eq. (1), the compression ratio of this coding scheme is de-
rived as:
CR =
k2
(kr )
2 · log2(s)+ s · r2
. (2)
Since s in Eq. (2) is variable, it can be properly adjusted to
achieve lossy compression of different compression ratios.
However, to achieve the target compression ratio, it is
necessary to determine the number of quantized symbol blocks,
s. Based on Eq. (2), we can obtain the relationship between
the target compression ratio, CR, and the number of quan-
tized symbol blocks, s, as:
CR ≤ k
2
(kr )
2 · log2(s) + s · r2
, (3)
because log2(s) is larger than or equal to log2(s). Eq. (3)
can be further derived as:
0 ≤ 2β − s · 2s·α2 , (4)
Fig. 3. Comparison of lossless compression ratio for the
“ballroom” sequence between our method and JBIG2.
where HV S() denotes a contrast sensitivity function of the
human visual system [1]. In Eq. (7), the video frame X is a
compressed halftone video frame and Y is an original gray-
scale video frame. The RD performance for the two videos
is shown in Fig. 4. The original uncompressed bit rate is
4500 Kbits/s.
Fig. 4. Rate-distortion performance of our halftone video
lossy compression scheme.
For visual quality inspection, the results are shown in
Fig. 5 for comparison. Fig. 5(a) shows an original video
frame with a size of 128×128while Figs. 5(b)∼(d), respec-
tively, show the lossy compression results with 128, 32, and
8 quantized symbol blocks. We can observe there is obvi-
ous quality degradation in Fig. 5(d). These results suggest
that the visual quality can be acceptable when the number
of quantized symbol blocks is large than or equal to 32.
5. CONCLUSION
In view of the fact that video halftoning will play an im-
portant role in supporting the use of the emerging display
device, e-paper, this paper proposes a new halftone video
compression method. For lossless compression, compari-
son with the binary image compression standard, JBIG2, in-
dicates that our method achieves effectiveness compression.
For lossy compression, we have demonstrated the RD per-
formance. To our knowledge, this should be the first work in
halftone video compression. We believe that halftone video
compression will continue to play an important role for the
(a) (b)
(c) (d)
Fig. 5. Lossy halftone video compression: (a) the original
video frame; (b)∼(d), respectively, show the lossy compres-
sion results with 128, 32, and 8 quantized symbol blocks.
upcoming display - electronic paper.
Acknowledgment: This research was supported by the Na-
tional Science Council under grants NSC 96-2221-E-001-
029 and NSC 95-2422-H-001-031.
6. REFERENCES
[1] P. J. Barten, “Physical model for the contrast sensitivity of
the human eye,” in Proc. IS&T/SPIE Int. Symp. on Electronic
Imaging Science and Technology, Vol. 1666, San Jose, CA,
Feb. 9-14, pp. 57-74, 1992.
[2] C. Gotsman, “Halftoning of image sequence,” Vis. Comput.,
vol. 9, no. 5, pp. 255-266, 1993.
[3] C. Y. Hsu, C. S. Lu, and S. C. Pei, “Video Halftoning Pre-
serving Temporal Consistency,” Proc. IEEE Int. Conf. on
Multimedia and Expo, Beijing, China, 2007.
[4] ISO CCITT Recommend. T.4,Standardization of group 3 fac-
simile apparatus for document transmission, 1980.
[5] ISO/IEC JTC1 CD 11544: Coded representation of picture
and audio information-progressive bi-level image compres-
sion, 1993.
[6] IBIG2 Final Draft International Standard, ISO/IEC
JTC1/SC29/WG1N1545, Dec. 1999.
[7] Mitsubishi Electric Research Laborato-
ries, “MERL multiview video sequences,”
ftp://ftp.merl.com/pub/avetro/mvctestseq.
[8] Z. Sun, “Video Halftoning,” IEEE Trans. on Image Process-
ing, Vol. 15, no. 3, pp. 678- 686, 2006.
2I. INTRODUCTION
In the film, “Minority Report,” there is a clip showing John Anderton (acted by Tom Cruise) boarding a train
to hide himself in the crowd in order to escape from his partner. Before he enters the train, he is captured and
identified by a surveillance camera. Soon, the focus of picture moves from John’s face to the newspaper shown
on an electronic device owned by a passenger who sits opposite John. As shown in Fig. 1, we can find that some
columns of the newspaper are changed from “Molecular nano-technology?” and “Medical nanodevice triumphs!”
(Fig. 1(a)) to “Breaking News! Precrime Hunts its Own!” (Fig. 1(b)). It was just a movie in 2002, but it is becoming
reality now.
(a) (b)
Fig. 1. The content in the electronic device can be dynamically and instantaneously changed: (a) the front page of a newspaper shown on
the electronic device; (b) the content of some columns of the newspaper is changed.
The monitor industry is actively pursuing a new display technology to make the monitor lighter, thinner, and more
portable. The electronic paper (e-paper) or smart paper [23], [24] is exactly the advanced and emerging display
technology, which enables one to get a digital file form from a personal computer through I/O port and keep it on
the screen without needing power. Compared with traditional monitors, e-paper, indeed, consumes little power and
is advantageous to the environment in that no trees are hewn during the generation process.
During the past few years, many companies, such as Philips, eInk, Sony, and Xerox, have devoted themselves
to manufacturing the first high-resolution electronic ink-based display module for reading-intensive applications. In
particular, eInk began to sell their products in 2005; it can be envisioned, that, in the future most applications based
on traditional paper and liquid crystal display (LCD) will be replaced by e-paper. Since digital halftone image is
the only format that many electronic devices can read, the development of digital halftone image/video techniques
4Fig. 2. Digital halftoning process.
composed of spatial error diffusion and inter-frame reference error diffusion, to eliminate flicker flaws (i.e., preserve
temporal consistency). Furthermore, since our method can efficiently reduce the flicker flaws, an additional benefit
is that the halftone video sequence can be efficiently compressed. Like traditional gray-scale/color video sequences,
which are compressed before transmission, halftone video compression definitely has become an emerging research
topic in e-paper. This relatively unexplored issue is the second focus of this paper.
It is known that JBIG [12], [13] is a lossless bi-level image compression scheme, which has been established in
the Joint Bi-level Image Experts Group, standardized as ISO/IEC standard 11544 and as ITU-T recommendation
T.82. In JBIG, arithmetic coding is used to achieve the goal of entropy coding. However, this scheme cannot be
directly applied to halftone video compression because, in some cases, we need to control the bit-rate but JBIG
doesn’t provide lossy compression. In addition, JBIG is only designed for compression of bi-level images. Different
from JBIG, JBIG2 is the first international standard for lossy compression of halftone images. Unfortunately, the
arithmetic coding used in JBIG and inverse halftoning used in JBIG2 incur high computational overhead, which is
not permitted in power-limited mobile devices that support the applications of e-paper.
Here, a new halftone video lossless/lossy compression method is proposed, which is mainly composed of three
components: block decomposition, block-based halftone quantization, and source coding. For block decomposition,
our scheme is proposed to compress a halftone video frame in a block-based manner, like traditional block-based
video coding. For halftone quantization, block replacement is used to achieve the goal of lossy compression. For
source coding, a kind of block-based entropy coding is presented for lossless compression of the bitstream resulted
from the quantization process (for lossy compression) or block decomposition process (for lossless compression).
We do not adopt arithmetic coding as source coding because it consumes considerable power, which is prohibitive
6temporal error diffusion, this procedure will cause the pixels located at the same positions of neighboring video
frames to have different halftone values due to the introduction of diffused temporal errors, in particular, when the
pixels have the same or similar gray values. For spatial error diffusion, the diffused spatial errors will affect the
halftoning results of the subsequent gray-scale pixels. If the area of gray-scale pixels located at the same positions
of neighboring video frames is affected by different diffused spatial errors, then the resultant halftone values may
be different, leading to flicker flaws. This situation occurrs with higher probabilities in particular with pixels with
gray-scale values close to the quantization threshold (e.g., 128) of halftoning. Fig. 3 shows the effect of flicker
flaws. Specifically, the while dots in Fig. 3(c) indicate the changes of halftone values, which will make the human
eye uncomfortable when viewing Figs. 3(a) and (b) successively. In our study, the flicker flaws caused by either
temporal error diffusion or spatial error diffusion are called illegal flicker, which has to be eliminated. However,
there is also a kind of flicker flaw, which is called legal flicker and is caused by apparent motion in the video
stream, which is permitted. Under this circumstance, the pixels located at the same spatial locations between two
neighboring video frames can have different halftone values.
(a) (b) (c)
Fig. 3. Flicker flaws: (a) and (b) show the neighboring halftone video frames and (c) shows the differences, illuminated with white dots
(i.e., flicker flaws), between (a) and (b).
B. Flicker rate-distortion (FRD) optimization
Let V c be an original continuous tone video, and let V h be the halftone version of V c. The goal of video
halftoning is to minimize the visual difference between V c and V h. Since a video sequence can be regarded as
8subject to AFR(V h, V hf ) ≤ desired AFR or
V ∗ = min︸︷︷︸
V hf
AFR(V h, V hf ) (3)
subject to HTPSNR(V h, V hf ) ≥ desired HTPSNR.
III. VIDEO HALFTONING PRESERVING TEMPORAL CONSISTENCY
The proposed video halftoning method [11] is based on intra-frame error diffusion and inter-frame reference with
the aim of reducing flicker flaws in halftone video. We describe our method without considering different types of
video frames (e.g., group of pictures (GOPs)) in Sec. III-A and with GOPs taken into account in Sec. III-B. Here,
we only present our algorithms based on halftoning gray-scale videos. However, our algorithms can be extended to
color video halftoning. Namely, when the color space is determined, our algorithms are applied on each channel
of the color space.
A. Inter-frame reference error diffusion-based video halftoning
Fig. 4 shows the block diagram of the proposed method without considering GOPs. Compared with the existing
methods, our method avoids adopting 3D error diffusion. As shown in Fig. 4, the first video frame, I(x, y, z1),
is halftoned by spatial error diffusion [4] to generate the first halftone frame H(x, y, z1). To reduce the flicker
flaws, the remaining halftone video frames are not generated by means of spatial error diffusion. On the contrary,
each of them is compared with its previous frame during the subsequent halftoning process. For example, the i-th
frame I(x, y, zi) is compared with the (i−1)-th frame I(x, y, zi−1) for inter-frame error diffusion. If the gray level
difference between two pixels located at the same position is smaller than a so-called flicker sensitivity threshold
, then the halftone value of the pixel in the i-th frame is assigned to be the same as that in the (i − 1)-th frame;
otherwise, the halftone value is determined via a quantization process in error diffusion. No matter which condition
occurs, the quantization errors still need to be diffused. In fact, the former is similar in principle to block-based
compression with “skip mode” for bit-rate saving. Therefore, our halftoning processing also has potential to benefit
halftone video compression. In the proposed video halftoning method, video frames are halftoned sequentially. In
each frame, the pixels are processed in the order, from left to right and top to bottom.
10
In Fig. 5, the frequency response, P (f), is defined as:
P (f) = af, (4)
where a is scaled to unity for simplicity. The impulse response of R is defined as:
r(t) = exp(−( ln(
t
τ )
σ
)2), (5)
where τ and σ are parameters that determine the peak position and width of the impulse response, respectively.
Based on the two frequency responses, P (f) and R(f), the frequency response H(f) of the flicker sensitivity
model is expressed as:
H(f) = R(f)P (f), (6)
where R(f) is the frequency response of r(t). Based on Fourier transform of Eq. (6), and using Eqs. (5) and (4),
we can derive the impulse response of the flicker sensitivity model as:
h(t) =
∫ ∞
−∞
H(f)ejωtdf
=
∫ ∞
−∞
R(f)P (f)ejωtdf
=
∫ ∞
−∞
R(f)
af
j2πf
(j2πfejωt)df
=
a
j2π
∂
∂t
∫ ∞
−∞
R(f)ejωtdf
=
a
j2π
∂
∂t
r(t)
=
j2aln( tτ )
tσ
exp(−( ln(
t
τ )
σ
)2). (7)
With the impulse response of the flicker sensitivity model, we can now derive the flicker sensitivity threshold  as:
[I(x, y, z)h(t) + I(x, y, z − 1)h(t− T )]− [I(x, y, z − 1)h(t) + I(x, y, z)h(t + T )] < d, (8)
where d is a constant and represents the maximum flicker energy [20] that can be ignored by human eyes and T
is the sampling interval of video frames (i.e., the reciprocal of frame rate). We can further derive from Eq. (8) to
obtain:
I(x, y, z) − I(x, y, z − 1) < d− I(x, y, z − 1)h(t− T ) + I(x, y, z)h(t + T )
h(t)
= . (9)
12
value between 0 and 1 during the halftoning process.). If the value of quantization error accumulated at a pixel
exceeds 1, then its halftone value cannot be determined using inter-frame reference. On the contrary, the halftone
value must be set to the value opposite that decided using inter-frame reference in order not to accumulate more
quantization errors. The cost is that the flicker flaw at single points will occur. Fortunately, a single flicker point
will not lead to apparent visual quality degradation.
On the other hand, in order to endow the proposed method with the ability to suppress error propagation, similar
to video coding, the video frames are divided into many group of pictures (GOPs) for video halftoning. Each GOP
consists of an I frame and a number of P frames, where P frames refer to I frame during the halftoning process.
There may be two ways of achieving the segmentation of GOPs. The first one is similar to video shot change
detection in that an abrupt change of video content will represent an I frame, i.e., the start of a new GOP. The
second one, which is adopted in this paper, refers to the change of average flicker rate to determine the existence
of an I frame. Fig. 7 shows the block diagram of our video halftoning method taking GOPs into consideration. In
order to evaluate the performance of flicker reduction, the average flicker rate (AFR) between a pair of neighboring
halftone video frames defined as:
AFR =
X∑
x=1
Y∑
y=1
(I(x, y, z) − I(x, y, z − 1))/(X · Y ) (10)
is used as a metric for indicating the degree of flicker flaw. In Eq. (10), X × Y denotes the size of a video frame
and z denotes the frame number. If AFR (0 ≤ AFR ≤ 1) is larger than a threshold, then the frame z is regarded
as an I frame, which is halftoned by means of 2D error diffusion. Since I frames are used to refresh the halftoning
process, spot defects can be blocked at the expense of increasing flicker flaws between an I frame and its previous
frame. As for P frames, the algorithm described in Sec. III-A is used to achieve video halftoning.
IV. COMPRESSION OF HALFTONE VIDEO
After a halftone video is generated, it needs to be further compressed to save storage. Different from quantization
of a gray-scale image, quantizing the coefficients of halftone frames in the transform domain may make decoded
pixel values undefined in the spatial domain. This is because a decoded pixel value must be a binary value to meet
the characteristic of halftone images. Therefore, it is important to directly study spatial-domain quantization for
14
or white points in a smooth block. However, frequently used blocks are limited. In the above example, Fig. 8(b)
can be replaced by Fig. 8(c) since the visual difference between the two halftone blocks is very small; thus, they
play the same role. For this reason, to achieve the goal of compression, the halftone quantization process will find
frequently used blocks as the representative symbol blocks or quantized symbol blocks.
(a) (b) (c)
Fig. 8. An example of halftone quantization: (a) a 4× 4 smooth block with gray-scale values 128; (b) a halftone version of (a); and (c)
another halftone version of (a).
1) Compression Ratio vs. Number of Quantized Symbol Blocks: Let s (1 ≤ s ≤ (kb )2) be the number of
representative or quantized symbol blocks in a coding unit. As log2(s) bits are needed to store a quantized
symbol block, the total bits used to store (kb )
2 quantized symbol blocks in a coding unit are (kb )
2 · log2(s). At
the decoder side, s quantized symbol blocks must be stored for decoding purposes and b2 · s bits are needed to
store them. Therefore, there are in total
(
k
b
)2 · log2(s)+ b2 · s (11)
bits required to store a coding unit during compression. With Eq. (11), the compression ratio of this coding scheme
is derived as:
CR =
k2
(kb )
2 · log2(s)+ s · b2
. (12)
Since s in Eq. (12) is variable, it can be properly adjusted to achieve lossy compression of different compression
ratios.
However, to achieve the target compression ratio, it is necessary to determine the number of quantized symbol
blocks, s. Based on Eq. (12), we can obtain the relationship between the target compression ratio, CR, and the
number of quantized symbol blocks s as:
CR ≤ k
2
(kb )
2 · log2(s) + s · b2
, (13)
16
possible, the parameter b that is related to the symbol block size, b× b, can be easily determined first to simplify
our derivation. Since b is a compromise between the resolution of halftone video quality and compression ratio,
we have empirically found that b = 4 makes a satisfactory tradeoff. Fixing b = 4, we now proceed to derive the
relationship between s and k. We use 100 images to gather the statistics of s by varying k and empirically observe
that s ≈ 1.017 × (k4 )1.5. Substituting the derived result into Eq. (13), we get:
CR ≤ k
2
(k4 )
2 · log2(1.017(k4 )1.5) + 1.017(k4 )1.5 · 42
. (17)
By differentiating the right term of Eq. (17) for k, we can derive the upper bound of compression ratio as 1.63
when k = 60.
C. Source Coding
After a coding unit is quantized in a lossy manner, it is further compressed via the source coding to achieve
lossless compression. Source coding is used to losslessly decrease the average code length of symbols in a coding
system. The major concept is to use fewer bits to represent the symbols that frequently occur, and use more bits
to represent the symbols that occur infrequently. In this paper, the symbol is, in fact, a block of size r × r. As a
result, we call the entropy coding used, block-based entropy coding. Since P frames are always composed of zero
halftone bits, run-length coding is further applied to increase compression ratio.
V. POWER-SCALABLE MULTI-LAYER HALFTONE VIDEO DISPLAY
Since our video halftoning method adopts GOP structure (Sec. III-B), it is beneficial to develop a multi-layer
halftone video display strategy, which enables one to display halftone video under different frame rates. According
to the GOP structure, a halftone video is divided into one base layer and several enhancement layers. Basically,
the base layer contains the most important information that must be displayed first while the enhancement layers
are used to improve video quality if a higher frame rate is permitted. The idea is similar to traditional layer video
coding in that the base layer and more/fewer enhancement layers are incorporated for display if a high/low frame
rate is considered in an e-paper device.
An intuitive method for arranging the halftone video frames into a multi-layer structure is to apply uniform
sampling. More specifically, a video sequence is divided into many segments of the same size. Next, all the first
18
obtain, as described as follows.
The first enhancement layer is composed of the frames that are located between two neighboring frames in the
base layer. The second enhancement layer is composed of the frames that are located between two neighboring
frames in the first enhancement layer and base layer. This process is repeated until all frames are assigned to either
a base layer or an enhancement layer.
Fig. 9. An example of encoding multi-layer halftone video based on non-uniform sampling.
B. Decoding multi-layer halftone video based on frame insertion
The decoder can decide the frame rate according to the power supply capability of e-paper. For a desk device,
more enhancement layers can be included to improve the quality of the displayed halftone video. For a mobile
device, only fewer enhancement layers can be included in order to save power consumption. Since a halftone video
is encoded into a multi-layer structure, the decoding process is done by simply inserting the frames of enhancement
layers back into the previous layer. For example, the frames in the first enhancement layer are first inserted back
into the intervals between the frames in the base layer to form a temporarily decoded halftone video. Then, the
remaining enhancement layers are subsequently inserted back into the temporarily decoded video to accomplish
decoding under the constraint of a given frame rate. This kind of insertion is accomplished by searching the intervals.
However, a problem caused by non-uniform sampling is that the number of frames in each enhancement layer
is different. More specifically, the total number of frames in the j-th enhancement layer may be smaller than the
20
average flicker rate for video halftoning; (ii) Sun’s method [21] consistently outperforms [4], [7]; (iii) our method
consistently obtains the lowest average flicker rates among the four methods, and the differences are very significant.
We also find that a few AFRs of the four methods are very close for those frames with large motions. In fact,
they (the peaks in the curve generated using our method) occur in I frames. Furthermore, we find that for videos
with large motions, more I frames will be determined (e.g., note that many peaks appear in Fig. 12). On the other
hand, our method also indicates from these figures that, for video sequences with small or moderate motions, the
average flicker rate is less than 0.05 while for video sequence with large motions, the average flicker rate is within
[0.05 0.10]. These results actually match the human visual model-based flicker sensitivity, as we discussed in Sec.
III-A1.
Fig. 10. Comparison of average flicker rates for the Vassar video between our method, 3D error diffusion [7], 2D error diffusion, and Sun’s
method [21].
B. Flicker rate-distortion
To verify that the quality of halftoned video is not destroyed by unconditionally reducing average flicker rate,
we also demonstrate the flicker rate-distortion performance in this section. We give several different values of  to
obtain halftoned videos with different average flicker rates. The corresponding HTPSNR values are also measured.
The flicker rate-distortion performance for the three video sequences are shown in Fig. 13∼Fig. 15, respectively.
We can observe from these curves that (i) HTPSNR values fast achieve a steady state under small flicker rates; (ii)
when flicker rates are increased, the HTPSNR values will not increase much; (iii) compared with the results shown
22
Fig. 13. Flicker rate-distortion performance of our method for the Vassar video.
Fig. 14. Flicker rate-distortion performance of our method for the Secretary video.
C. Halftone video compression
In the experiment of halftone video compression, two 24-bit color video sequences [19] with frame size of
640× 480 and frame rate of 15 frames per second were used. Among them, the results obtained from the “Vassar”
video with slow motions and the “Ballroom” video with large motions were reported here. The parameters for
halftone video compression were determined as described in Sec. IV-B3. The size of a coding unit was set to
64 × 64 (k = 64). A symbol block is has a size of 4 × 4 (r = 4). As a result, there were a total of (644 )2 = 256
symbol blocks in a coding unit. Lossless compression and lossy compression were, respectively, used to verify the
compression capability of our method.
We first verify the lossless capability of our method and compare it with the lossless coding standard, JBIG2
[14]. Note that our method can also achieve lossless compression if halftone quantization, as described in Sec.
24
compressed halftone video, the HTPSNR between a compressed halftone video frame and its original gray-scale
video frame is adopted as the criterion (see Eq. (1)). The RD performance for the two videos is shown in Fig. 17.
The original uncompressed bit rate is 4500 Kbits/s.
Fig. 17. Rate-distortion performance of our halftone video lossy compression scheme.
For visual quality inspection, the results are shown in Fig. 18 for comparison. Fig. 18(a) shows an original video
frame with a size of 128 × 128 while Figs. 18(b)∼(d), respectively, show the lossy compression results with 128,
32, and 8 quantized symbol blocks, where obvious quality degradation is observed in Fig. 18(d). These results
suggest that the visual quality can be acceptable when the number of quantized symbol blocks is greater than or
equal to 32.
D. Multi-layer halftone video display
In order to evaluate whether our multi-layer halftone video display strategy can efficiently save power under
various frame rates, the average power consumption measured in terms of number of flickers per second is a good
indicator. In this aspect, our method and Sun’s video halftoning method [21], which can be recognized as a state-
of-the-art video halftoning technology, were used for comparison. Fig. 19 shows the average power consumption
for the “Vassar,” “Secretary,” and “Dolphin” video sequences, respectively, where the x axis denotes the frame rate
(frames per second, fps) and the y axis denotes the power consumption (number of flickers per second).
It can be observed from these results that our method consistently consumes less power under different frame
rates. We can find from Fig. 19(a) that the power consumption of our method is less than that of Sun’s method
when the frame rate is 1 fps. The reason is that “Vassar” is a slow-motion video, which has the GOP of “IPPP...”
in the original encoded video stream. Therefore, the base layer contains only one I frame and other P frames.
26
(a) Vassar (b) Secretary (c) Dolphin
Fig. 19. Comparisons of power consumption for halftone videos, Vassar (a), Secretary (b), and Dolphin (c).
VII. CONCLUSIONS AND FUTURE WORK
In view of the fact that the video halftoning technology will play an important role in supporting the use of
the emerging display device, e-paper, the issues of video halftoning, halftone video compression, and multi-layer
halftone video display are considered in this paper. First, we propose a new video halftoning method that can
preserve temporal consistency between video frames by reducing flickers. An additional benefit is that efficient
compression of halftone video can be achieved due to the background content not incurring flickers. Second, we
propose a new halftone video compression scheme built upon the proposed video halftoning scheme. For lossless
compression, comparison with the binary image compression standard, JBIG2, indicates that our method achieves
effective compression. For lossy compression, we have demonstrated the RD performance. Third, we propose a
power-scalable multi-layer halftone video display strategy that can support halftone video display under various
frame rates. The main contribution is that our method can efficiently save power over the state of the art video
halftoning method and nearly does not introduce quality degradation. To our knowledge, these three issues have
not been jointly considered in the literature.
When e-paper is envisioned to be widely used, the incoming question is the copyright protection of digital halftone
video sequences and images. In this aspect, our previous work [9] has shown that the current digital halftone image
watermarking methods are not suitable for protecting the output generated from high-resolution devices because even
the lowest resolution of the commonly used printers and scanners can achieve 100 dpi. Therefore, it is meaningless
to embed watermarks into low-resolution halftone images. Based on the above reasons, we will plan to study a new
digital halftone video watermarking method that is well suited for high-resolution output devices such as e-papers,
