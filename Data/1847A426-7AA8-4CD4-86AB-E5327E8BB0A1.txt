 中文摘要 
 
近年來由於網路的普及，以及使用者對於影像的需求量大增，使得多媒體資料庫大幅
成長，需要更有效率的影像搜尋技術，因此出現了許多影像搜尋的方法。相關回饋(Relevance 
Feedback，RF)是利用與使用者不斷的互動回饋，用來取得與查詢影像相似的影像。目前大
多數的相關回饋方法都只注重個別使用者的經驗並且使用硬式相關回饋，分別是相關
(relevant)與不相關(nonrelevant)。因此本論文將影像細分為四個相關的等級，分別是極佳
(Excellent)、尚可(Fair)、無所謂(Don’t care)、差(Bad)，用來取得更詳細的使用者回饋資訊，
並且我們提出一個軟式關聯規則(Soft Association Rule)的新方法來增進影像查詢的效能，而
傳統的相關回饋技術也都必須依循這個方法修改。另外利用多個使用者的回饋經驗學習的
次級知識可以用來增進未來系統回覆精確率的提升。我們提出一個軟式關聯規則探勘方法
用來處理這些回饋資訊，系統利用取得的回饋資訊以關聯規則探勘來推導出影像之間的相
關程度，另外也利用信賴度量化及偵測冗餘來縮減規則以及二元搜尋法與優先搜尋法來增
進搜尋關聯規則的速率，以提升影像查詢的效能。實驗的結果驗證本論文所提出的影像相
關回饋方法大幅提升了傳統的影像相關回饋方法的查詢精確率。 
 
關鍵字：內容導向式影像讀取，相關回饋，關聯規則探勘，偵測冗餘，二元搜尋法，優先
搜尋法。 
Content-based image retrieval using association rule mining
with soft relevance feedback
Peng-Yeng Yin *, Shin-Huei Li
Department of Information Management, National Chi Nan University, 303 University Rd., Puli, Nantou 545, Taiwan
Received 9 May 2005; accepted 17 April 2006
Available online 19 June 2006
Abstract
With the rapid development of internet technology, the transmission and access of image items have become easier and
the volume of image repository is exploding. An eﬃcient and eﬀective query reformulation is needed for ﬁnding the rel-
evant images from the database. Relevance feedback (RF) is an interactive process which reﬁnes the retrieval results to
a particular query by utilizing the user’s feedback on previously retrieved images. Most of the existing approaches deal
with hard feedback (relevant and nonrelevant) and focus on individual experience only. We propose to facilitate the
use of soft feedback (involving excellent, fair, don’t care, and bad) to better capture user’s intention. To add this feature,
all of the traditional RF techniques should be modiﬁed accordingly. Further, the meta-knowledge exploited from multiple
users’ experiences can improve the performance of future retrieval results. We propose a soft association rule mining algo-
rithm to infer image relevance from the collective feedback. The number of association rules is kept minimum based on
conﬁdence quantization and redundancy detection. Also, binary search and best-ﬁrst search techniques are implemented
to expedite the process of relevance inference from the association rules. The proposed model provides a more ﬂexible
interface for relevance feedback and the experimental results manifest that the retrieval performance of the proposed
model is better than that of traditional methods.
 2006 Elsevier Inc. All rights reserved.
Keywords: Association rules; Conﬁdence quantization; Content-based image retrieval; Redundancy detection; Soft relevance feedback
1. Introduction
With the rapid development of internet technology, the transmission and access of image items have
become easier and the volume of image repository is exploding. To facilitate the retrieval of image data, many
content-based image retrieval (CBIR) systems [1–4] have been developed. These systems provide various
means for the users to describe their queries, such as a SQL-like query language, sample query images, iconic
query pictures, or sketch query pictures, just to name a few. The system responds to the query by returning a
set of database images that are ‘similar in content’ to the query. The search conducted by CBIR systems can be
J. Vis. Commun. Image R. 17 (2006) 1108–1125
www.elsevier.com/locate/jvci
1047-3203/$ - see front matter  2006 Elsevier Inc. All rights reserved.
doi:10.1016/j.jvcir.2006.04.004
* Corresponding author. Fax: +886 49 2915205.
E-mail address: pyyin@ncnu.edu.tw (P.-Y. Yin).
the modiﬁcation of the association rule mining algorithm for coping with fuzzy support, the reduction of asso-
ciation rule set, the inference of image relevance, the speed-up of association rule searching, and the modiﬁ-
cation of traditional RF techniques for dealing with soft feedback.
The remainder of this paper is organized as follows. Section 2 describes the related works on relevance feed-
back and the motivation and contributions of this research. Section 3 presents the proposed IRARM model.
Section 4 gives the experimental results and provides comparative performances. Finally, Section 5 presents
the conclusions of the paper.
2. Previous works
2.1. Relevance feedback techniques
Considering a CBIR system, a user submits a query image for retrieval purpose. Let the query image
and a database image be represented by feature vectors X = (x1,x2, . . .,xd) and Y = (y1,y2, . . .,yd), respec-
tively, where d is the number of selected features and xi and yi are the values of the ith feature. The sys-
tem derives the similarity between X and Y using the given dissimilarity metric. The normalized Euclidean
metric DistðX ; Y Þ ¼
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃPd
i¼1ðxi  yiÞ2=d
q
is generally used for this purpose. The top t database images that
are the nearest neighbors of the query are then returned to the user. If the user is not satisﬁed with the
retrieval result, he/she can activate an iterative RF process until satisﬁed. In the following subsections, the
main existing RF techniques are presented.
2.1.1. Query vector modiﬁcation
The query vector modiﬁcation (QVM) approach [5,6] iteratively reformulates the query vector based on
user’s feedback in order to move the query toward a topological region of more relevant images and away
from nonrelevant ones. Let a user submit the ith database image as the query and have experienced j RF iter-
ations, and let X ðjÞi denote the current query formulation. Also let the set of relevant images identiﬁed at the jth
iteration be R, and the set of identiﬁed nonrelevant images be N. For the (j + 1)th RF iteration, the method
reformulates the query vector by X ðjþ1Þi ¼ aX ðjÞi þ b
P
Y k2R
Y k
jRj  c
P
Y k2N
Y k
jN j, Yk are images that belong to region
R or N, and a, b, and c are the parameters controlling the relative weight of each component. The eﬀect of the
QVM can be illustrated in Fig. 2. For simplicity, let us assume that only two features, f1 and f2, are used for
image similarity matching. All of the database images spreading over the feature space are either relevant
(indicated by symbol ‘•’) or nonrelevant (indicated by symbol ‘’) to the current query X ðjÞi according to
the user’s intention. However, the most ‘similar’ images to the query according to the machine’s subjective
(Euclidean metric) are those residing at the interior of the circle centered at X ðjÞi (see Fig. 2a). Thus, the query
f1
f2
Xi(j)
f1
f2
Xi(j+1)
a b
Fig. 2. Illustration of the QVMmethod. (a) The closest neighbors to the current query according to the Euclidean metric are retrieved. (b)
A query reformulation can move the query to a topological region involving more relevant images.
1110 P.-Y. Yin, S.-H. Li / J. Vis. Commun. Image R. 17 (2006) 1108–1125
incumbent query, and p (Y|R) and p (Y|N) be the conditional probabilities that an image is Y given that it is
relevant or nonrelevant to the query. Bayesian theory provides a framework to compute the a posteriori prob-
abilities p (R|Y) = p (Y|R)p (R)/p (Y) and p (N|Y) = p (Y|N)p (N)/p (Y). Then, the system can judge whether a
database image Y is relevant to the query using the classiﬁer Jh (Y) = p (R|Y)/p (N|Y) = p(Y|R)p (R)/
p(Y|N)p (N). The conditional probabilities p (Y|R) and p (Y|N) can be approximated by parametric models such
as Gaussian kernels using the feature vectors of the images that are identiﬁed as relevant or nonrelevant, and
p (R)/p (N) can be treated as a small constant since the number of relevant images is much less than that of
nonrelevant images. Thus, the retrieval system can output the top t images with the highest values of Jh (Y).
2.1.4. Classiﬁcation-based methods
The classiﬁcation-basedmethods train a 2-class classiﬁer (such as a support vector machine (SVM), boosting,
or Bayesian classiﬁer) from the prior history of feedback for classifying the database images as relevant or non-
relevant. Tong and Chang [11] proposed the SVM-active learning which trains the SVM by asking the user to
label the selective images that are closest to the current SVM boundary. After the feedback rounds, a ﬁnal
SVM is learned from all feedback data and retrieves the t images that are farthest from the SVM boundary.
Huang et al. [12] introduced their work related to three learning issues in CBIR, the ﬁrst one attacking the small
sample biased learning, the second attempting the integration of visual features and keywords, and the third
addressing the user interface design. Tieu and Viola [13] presented a method for boosting image retrieval using
a very large number (46,875) of selective features. Each feature is treated as a weak classiﬁer. Since each image
responds to only a few features, a boosting algorithm can be applied to learn a strong classiﬁer relying on a small
subset of features for each query image.
2.2. Long-term learning
Early RF techniques concentrate on the improvement of retrieval performance within a single query session
only. A query session is the period that consists of the submittal of the original query and all the subsequent feed-
back rounds for further reﬁning the retrieval results. So the query session always starts without the a priori rel-
evance information. The meta-knowledge generated during this session is not used for assisting future query
sessions. Nevertheless, there exists agreement, to some extent, among multiple query sessions and diﬀerent users
for judging image relevance and it would improve future retrieval performance if the historical feedback obtained
from multiple sessions can be systematically exploited. Recent works have considered long-term learning across
multiple sessions as an important role in improving retrieval precision.
Bhanu and Dong [14] used a semi-supervised fuzzy clustering approach in conjunction with prior
retrieval experience to partition the database into clusters related to high-level concepts, which can be used
for eﬃcient indexing. Yin et al. [15] proposed a systematic framework that extends the ability of tradition-
al relevance feedback techniques to the exploitation of accumulated retrieval experiences by the use of vir-
tual features (VF), storing the semantic concepts learned from multiple users. Li et al. [16] presented a
statistical correlation model which estimates the probability that two images are semantically similar to
each other based on the co-occurrence frequency that both images are marked as relevant during a query
session. He et al. [17] developed a retrieval system which makes use of both long-term and short-term
learning. The long-term learning infers a semantic space and the short-term learning helps reﬁne the
semantic feature of the query image and yield better results. Jiang et al. [18] described a multi-layer
semantic representation (MSR) which can model the multi-correlation among images from multiple ses-
sions and derive the long-term relevance degree. It is then combined with the short-term relevance degree
derived from the SVM-active learning algorithm [11] to improve the retrieval performance. A log-based
relevance feedback technique is proposed in [19] which utilizes the users-speciﬁed relevant images as the
seeds to search through the long-term feedback logs and obtain more training samples for training the
SVM such that the future retrieval precision improves. It is demonstrated in [19] that the use of soft label
can help SVM deal with uncertain source. Yin et al. [20] presented an image relevance reinforcement
learning (IRRL) model for integrating existing short-term relevance feedback techniques in one system.
Various integration schemes are proposed to maximize the synergism and a long-term memory is used
to exploit the meta-knowledge across multiple sessions.
1112 P.-Y. Yin, S.-H. Li / J. Vis. Commun. Image R. 17 (2006) 1108–1125
3.1. RF techniques with soft feedback
To better capture the user’s perception subjectivity about the image relevance, Rui et al. [7] proposed ﬁve
relevance levels, namely, ‘‘highly relevant’’, ‘‘relevant’’, ‘‘no opinion’’, ‘‘nonrelevant’’, and ‘‘highly nonrele-
vant’’, for relevance feedback annotation. Experimentally, we ﬁnd that although it’s more convenient to
express user’s subjectivity about relevance by ‘‘highly relevant’’, ‘‘relevant’’, and ‘‘no opinion’’, it is diﬃcult
for the user to discriminate ‘‘nonrelevant’’ and ‘‘highly nonrelevant’’ retrieved images. Since the repository
images may have extremely diverse content in general CBIR systems, it is hard to say which image is more
‘‘nonrelevant’’ if the image does not contain the information that the user seeks for. Hence, in our system,
we provide the user with four levels of relevance, namely ‘‘excellent’’, ‘‘fair’’, ‘‘don’t care’’, and ‘‘bad’’.
Traditional RF techniques are performed with hard feedback which allows the user to identify the retrieved
images as ‘‘exactly relevant’’ and ‘‘exactly nonrelevant’’ only. To cope with soft feedback, each relevance level
is assigned a soft value. In particular, we assign each retrieved image I an image relevance weight rI, and let
rI ¼
0:5 if image I is excellent
0:1 if image I is fair
0 if the user does not care
0:1 if image I is bad:
8>><
>>:
ð1Þ
Thus, the image relevance weight represents the signiﬁcance degree with which a given image is relevant to the
query image. The image relevance weight is distinct from the feature relevance weight introduced in FRE
where the latter indicates the signiﬁcance degree with which a particular feature distinguishes an image from
the query. The image relevance weight will be used by the RF technique for taking soft feedback into consid-
eration. Herein, we propose the strategies for employing various RF techniques with soft feedback.
• Soft QVM: Let the submitted query be the ith database image and have experienced j RF iterations, and let
X ðjÞi denote the current query formulation. The system returns t images as current retrieval results and
requests for soft relevance feedback. The user identiﬁes relevance degree of each retrieved image using
our four-level annotation interface. Let R be the set of excellent and fair retrieved images and N be the
set of bad retrieved images. The soft QVM derives the reformulated query vector as
X ðjþ1Þi ¼ aX ðjÞi þ b
P
Y k2R
rY k Y kP
Y k2R
rY k
þ cPY k2N
rY k Y kP
Y k2N
rY k
, i.e., each relevant (involving excellent and fair retrieved
images) and nonrelevant (bad retrieved images) image is discounted by the corresponding image relevance
weight. The retrieved images with ‘‘don’t care’’ annotation are not involved in the reformulation because its
image relevance weight is 0. As such, the new query reformulation formula can work with soft feedback.
Soft RF technique 
Parameter updating 
Image database
Similarity matching
Relevance itemsets 
Association rule 
mining 
Next query
Current retrieval results
Soft annotation interface
Soft relevance feedback
Image relevance inference 
Fig. 4. The system diagram for the image relevance association rule mining (IRARM) model.
1114 P.-Y. Yin, S.-H. Li / J. Vis. Commun. Image R. 17 (2006) 1108–1125
three transaction records have been stored. A transaction record consists of a transaction ID, the IDs of the
retrieved images and the corresponding image relevance weights. The historic retrieval results with many users
and many feedback iterations will form a large transaction database. Finding the frequent itemsets of retrieved
images can infer consensus relevance concepts and improve the precision of future retrieval results. However,
the Apriori algorithm copes with hard transactional data, i.e., the support count of an itemset is increased by
one if an additional occurrence of this itemset is observed. Our system interacts with the users through soft
feedback, a new scheme referred to as soft Apriori algorithm for counting the number of fuzzy occurrences
of itemsets is thus proposed. Using the above example as shown in Fig. 5, we ﬁrst ﬁnd the set of 1-itemsets
which is denoted L1 (see Fig. 6a). The support count of each 1-itemset is the sum of image relevance weight
given in the corresponding transaction record since the image relevance weight indicates the relevance degree
of the image occurring in the record. For instance, the support count of itemset {I1} is computed
by sup({I1}) = 0.1 + 0.1 = 0.2. For the set of 2-itemsets denoted L2 (see Fig. 6b), the support count of each
2-itemset is the sum of the average image relevance weight computed from the corresponding transaction
record. For instance, the support count of itemset {I1, I2} is computed by sup({I1, I2}) = (0.1 + 0.1)/
2 + (0.1 + 0.5)/2 = 0.4. As such, the other Lk, k = 3 and 4, and the support count of each itemset can be
derived (see Figs. 6c and d). It should be noted that the Apriori property may be not guaranteed in the soft
Apriori algorithm, for instance, sup({I1}) < sup({I1, I2}). Hence, the prune step which is used in the normal
Apriori algorithm cannot be performed here. Also, all the itemsets should be found by our algorithm since
a frequent k-itemset could be generated from a nonfrequent (k-1)-itemset.
After yielding all the itemsets and the corresponding support counts, the strong association rules whose
conﬁdence values are larger than the minimum conﬁdence can be generated. An association rule is of the form
A) B where A and B are both itemsets. The conﬁdence of an association rule is deﬁned as
confðA ) BÞ ¼ supðA [ BÞ
supðAÞ ; ð2Þ
where A is called the rule antecedent and B is called the rule consequent. Here, we restrict our association rules
to those where A is a 1-itemset. The larger the conﬁdence value, the more relevant the relationship between the
images in B and the image of A. Thus, we can generate the strong association rules whose conﬁdence values
are larger than the speciﬁed minimum conﬁdence and use them to retrieve most relevant images as response to
a given query.
3.2.2. Rule set reduction
As the number of strong association rules can still be extremely large which may cause expensive searching
time, it is desired to reduce this number with minimum precision sacriﬁce. We propose two types of rule set
L1 L2
Itemset Support count Itemset Support count 
{I1} 0.2 {I1, I2} 0.4 
{I2} 0.6 {I1, I3} 0.3 
{I3} 1.0 {I2, I3} 0.3 
{I4} 0.1 {I3, I4} 0.3 
{I5} 0.5 {I3, I5} 0.5 
{I6} 0.5 {I3, I6} 0.5 
{I4, I5} 0.3 
{I4, I6} 0.3 
{I5, I6} 0.5 
L3 L4
Itemset Support count Itemset Support count
{I1, I2, I3} 0.23 {I3, I4, I5, I6} 0.4 
{I3, I4, I5} 0.37 
{I3, I4, I6} 0.37 
{I3, I5, I6} 0.50 
{I4, I5, I6} 0.37 
a
c
b
d
Fig. 6. Generation of itemsets.
1116 P.-Y. Yin, S.-H. Li / J. Vis. Commun. Image R. 17 (2006) 1108–1125
• The second-order inference rule seeks for the rules A) B and C) D with A = {q} and C  B. It infers the
relevance of image d, d 2 D, with respect to query q as Uq (d) = Conf (A) B) · Conf (C) D).
The relevant images are sorted in the decreasing order of image relevance derived by the inference rules.
The top t most relevant images are returned to the user. If the number of relevant images in the sorted list
is less than the user-speciﬁed number of retrieved images, the lack is ﬁlled by the most similar images accord-
ing to Euclidean metric. Apparently, in additional to the above inference rules, we can use other higher order
inference rules to ﬁnd more relevant images. However, we avoid this for two reasons. (1) The image relevance
derived from the third-order or higher order inference is usually low due to the multiplication of multiple con-
ﬁdence values. The image with low inferred relevance should be discredited since the prior experience is devot-
ed by few individuals and their feedback could be outliers to the subjective of mass users. This is analogous to
the use of minimum conﬁdence for eliminating insigniﬁcant rules. (2) Using higher order inference rules would
deﬁnitely incur expensive computation time and contribute little in retrieval improvement. We thus consider
only the ﬁrst two orders of relevance inference for saving computations.
3.2.4. Binary search and best-ﬁrst search
To expedite the computation for relevance inference, we propose some practical implementation techniques
using binary search and best-ﬁrst search. The process is proceeded as follows. All of the image relevance asso-
ciation rules are sorted in the category of rule antecedent, and in each category, rules are sorted in the decreas-
ing order of rule conﬁdence. An example is shown in Fig. 9. Thus, for a given query, the association rules
satisfying the ﬁrst-order and the second-order inference rules can be quickly accessed using binary search (note
the image labels in the association rules are represented by numeric image IDs). We do not have to infer the
image relevance of all images, the process is terminated once the top t most relevant images have been deter-
mined. This is achieved by the best-ﬁrst search. For the example in Fig. 9, if the user submits image a as the
query, Rule 1 is the ﬁrst one which satisﬁes the ﬁrst-order inference rule. The most relevant images are now
{a, b}. Then the system forks two cursor pointers, one points to Rule 2 which satisﬁes the ﬁrst-order inference
rule and the other points to Rule 4 which satisﬁes the second-order inference rule. Since Rule 4 has a higher
relevance (0.651 · 0.426 = 0.277) than that of Rule 2 (0.253), the most relevant images are augmented to
{a, b, h, i, j}. The second pointer now moves to Rule 5 which also satisﬁes the second-order inference rule.
As the relevance of Rule 5 is 0.210 (=0.651 · 0.323), the images in Rule 2 are more relevant. The most relevant
images are augmented to {a, b, h, i, j, c, d, e} and the ﬁrst pointer moves to Rule 3 which has relevance value
of 0.185. Hence, the most relevant images are further augmented to {a, b, h, i, j, c, d, e, k, l, m, n} by including
the consequence of Rule 5. The inference process is proceeded until the top t most relevant images have been
determined or the inferred image relevance is lower than the speciﬁed minimum conﬁdence. The tie with the
same relevance value is broken according to Euclidean matching score.
The precise algorithm for the IRARM model is presented in Fig. 10 and is explained as follows. When a
user starts a new query session by submitting a query, say, image i, if the image was never used as a query
before, the algorithm computes the t nearest images according to the Euclidean metric; otherwise, the algo-
rithm retrieves the most relevant images from the prior association rules using image relevance inference.
Next, if the user is not satisﬁed with the retrieved results, he/she can identify the relevance level of each
retrieved image through our annotation interface and perform the adopted soft RF technique to improve
Rule ID Association rules Confidence 
1 {a} {b} 0.651 
2 {a} {c, d, e} 0.253 
3 {a} {f, g} 0.185 
4 {b} {h, i, j} 0.426 
5 {b} {k, l, m, n} 0.323 
: : : 
: : : 
: : : 
Fig. 9. Example for image relevance inference using association rules.
1118 P.-Y. Yin, S.-H. Li / J. Vis. Commun. Image R. 17 (2006) 1108–1125
contain only boats but with no sails. It is seen fromFig. 12b that the next retrieval results contain two images with
sailboats (the 1st and 9th retrieved images). On the other hand, the annotation interface of hard QVM provides
two-level of relevance degree only, namely ‘‘excellent’’ and ‘‘bad’’ (see Fig. 12c), the user identiﬁes the ﬁrst
retrieved image as ‘‘excellent’’ since it contains a sail and annotates the other retrieved images as ‘‘bad’’ because
they do not actually contain a sail. The next retrieval results (see Fig. 12d) return only one ‘‘excellent’’ image
which is the same as the one in the ﬁrst retrieval results and no new ‘‘excellent’’ image is found. This is because
the two-level annotation interface is less ﬂexible and is unable to provide further information besides ‘‘excellent’’,
so the query reformulation process conducted by hard QVM is ineﬃcient.
The scenarios for other relevance feedback approaches are similar, i.e., the soft version FRE and BI out-
perform the hard label FRE and BI, and we omit the experiments here for limited space. Hoi and Lyu [19]
have also shown that the soft label technique can help SVM-based relevance feedback method improve retriev-
al performance.
4.2. Performance of image relevance association rule mining
To evaluate the quality of retrieval results with soft feedback, we deﬁne a new performance measure called
retrieval score (RS) as follows:
Fig. 12. Retrieval examples obtained using soft QVM (SQVM) and hard QVM annotation interfaces. (a) The ﬁrst retrieval results
obtained using Euclidean distance matching; (b) the next retrieval results obtained after one SQVM iteration; (c) the ﬁrst retrieval results
obtained using Euclidean distance matching; (d) the next retrieval results obtained after one hard QVM iteration.
1120 P.-Y. Yin, S.-H. Li / J. Vis. Commun. Image R. 17 (2006) 1108–1125
at diﬀerent numbers of relevance feedback iterations. We observe that the RS curve of ASQVM is signiﬁcantly
higher than that of ESQVM at all relevance feedback iterations. The RS curve of ASQVM starts with a very
high score (3.79) due to the contribution of IRARM which infers many truly relevant images in the ﬁrst dis-
play, and the RS value further increases gradually by the SQVM relevance feedback as the number of itera-
tions increases. While the RS curve of ESQVM starts from 1.45 since the traditional Euclidean matching
cannot model the semantics from retrieval experience, in which case the retrieval performance can still be
improved by the proposed SQVM mechanism and the RS increases rapidly at the ﬁrst three iterations, then
the improvement ratio becomes slower for the rest iterations. Hence, the IRARM method can greatly improve
the performance of retrieval systems with relevance feedback, and even the user sticks to Euclidean matching
the proposed SQVM scheme can help improve the retrieval results signiﬁcantly.
4.2.2.2. Comparative performances between diﬀerent relevance feedback approaches. We have implemented dif-
ferent relevance feedback approaches belonging to long-term and short-term learning methods, respectively.
The long-term learning methods include the ASQVM, VF [15], and the log-based approach [19], while the
short-term learning methods contain the SVM active [11], Soft QVM, and Hard QVM. Since these methods
use diﬀerent types of feedback mechanism (either soft or hard), they are assessed using the average precision
which is deﬁned as the average ratio between the number of the relevant images in the retrieved images and the
number of total retrieved images. For the test methods using the soft feedback, only the retrieved images that
are marked as excellent are considered as relevant when computing the average precision since fair images,
although helpful for reﬁning results, are actually wrong. Fig. 14 shows that all of the test long-term learning
methods outperform the group using the short-term learning. As for the long-term learning approaches, the
average precision of ASQVM and VF is comparable, while the average precision of log-based method is slight-
ly lower. This is because both of ASQVM and VF apply the long-term learning for the ﬁrst display of retrieved
images, but the log-based method uses the Euclidean matching for the ﬁrst display and borrows in the long-
term logs after the ﬁrst feedback round, thus the precision lags behind the other two methods. As for the short-
term learning approaches, the SVM-active method seems to be superior to the QVM approach with either soft
or hard feedback mechanism. However, it is interesting to note that the SVM-active method does not perform
well at the ﬁrst two feedback rounds for our application, this is due to the fact that the SVM classiﬁer needs
more training samples for improving the performance.
Figs. 15a and b show a typical example of the ﬁrst retrieval results using the IRARM with soft QVM
(ASQVM) and the improved retrieval results after applying one SQVM iteration. It is seen that among the
ﬁrst display of retrieved images there are six images marked as ‘‘excellent’’, three as ‘‘fair’’, and one as
‘‘bad’’, obtaining an RS value of 3.2. In the retrieval results after applying one SQVM iteration, the results
are improved where eight images are marked as ‘‘excellent’’, one as ‘‘fair’’, and one as ‘‘bad’’, obtaining an
Fig. 13. The average RS values obtained using the IRARM with soft QVM (ASQVM) and the Euclidean matching with soft QVM
(ESQVM) at diﬀerent numbers of relevance feedback iterations.
1122 P.-Y. Yin, S.-H. Li / J. Vis. Commun. Image R. 17 (2006) 1108–1125
RS value of 4.0. As for the retrieval results obtained using the Euclidean matching with soft QVM (ESQVM)
(see Figs. 15c and d), the RS value increased from 0.2 (two ‘‘excellent’’ and eight ‘‘bad’’ retrieved images) to
0.4 (two ‘‘excellent’’, one ‘‘fair’’, and seven ‘‘bad’’ retrieved images), indicating a minor improvement.
4.2.3. Target search
As mentioned before, the purpose of target search is to ﬁnd a particular image as fast as possible. The pro-
posed ASQVM method also has great contribution in expediting the target search. The same ﬁve persons
involved in the category search experiment are asked to evaluate the performance of target search. Each per-
son is presented by 22 query images with each query selected from each class. The corresponding target image
for each query is also presented simultaneously for guiding the user to submit relevance feedback. The average
number of feedback iterations needed to ﬁnd the target image is 10.2 and 13.67 for ASQVM and ESQVM,
respectively. This is because ASQVM provides much better retrieval results which assist the SQVM in formu-
lating the query vector for searching the target image.
Fig. 16 shows a typical target search example using ASQVM and ESQVM. The ﬁrst retrieval results for the
given query using ASQVM are shown in Fig. 16a, the target image is found in the display of retrieved images
after applying 10 feedback iterations (see Fig. 16b). On the other hand, Figs. 16c and d show the ﬁrst retrieval
results and the ﬁnal retrieved images containing the target image using ESQVM. It is seen that the target
image is found after applying 23 feedback iterations which is longer than that using ASQVM.
Fig. 16. Retrieval examples obtained using ASQVM and ESQVM. (a) The ﬁrst retrieval results obtained using ASQVM; (b) the ﬁnal
retrieval results containing the target image obtained using ASQVM after 10 feedback iterations; (c) the ﬁrst retrieval results obtained
using ESQVM; (d) the ﬁnal retrieval results containing the target image obtained using ESQVM after 23 feedback iterations.
1124 P.-Y. Yin, S.-H. Li / J. Vis. Commun. Image R. 17 (2006) 1108–1125
 計畫成果自評 
 
本計畫之成果如下： 
z 已達成所有計畫書所提之預期目標，包括(1)設計及實作軟式相關回饋介面，能
夠精確的捕捉使用者的查詢概念。(2)設計及實作軟式相關回饋技術，擴增傳統
相關回饋技術的功能。(3)設計及實作軟式關聯規則技術，分析長期回饋資訊，
提高查詢結果精確率。(4)設計及實作關聯規則壓縮技術，降低記憶體空間的需
求。(5)設計及實作關聯規則索引技術，加快查詢關聯規則的速度。 
z 本計畫之部份研究成果已發表在國際知名期刊 Journal of Visual Communication 
& Image Representation, Vol. 17, 2006, pp. 1108-1125，延續過去一系列有關相關
回饋技術之論文發表(例如 IEEE Trans. on Pattern Analysis and Machine 
Intelligence 27 (10), 2005, pp. 1536-1551、Pattern Recognition Letters 23, 2002, pp. 
113-126 等)，已獲得國際相關學者的重視，分別來信詢問及請求合作研究。 
z 本計畫之研究成果具有推廣及運用的價值，可技術移轉並且對於設計及實作多媒
體資料庫或多媒體網路搜尋引擎的產業有很大的助益。 
