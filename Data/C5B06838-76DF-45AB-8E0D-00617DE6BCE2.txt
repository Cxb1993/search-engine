An Efficient External Sorting Design for NAND Flash-based
Storage Systems
Chin-Hsien Wu
chwu@mail.ntust.edu.tw
Department of Electronic Engineering
National Taiwan University of Science and Technology, Taipei, Taiwan
ABSTRACT
Since huge-capacity flash-memory is now an economic so-
lution for various portable devices and embedded systems,
a NAND flash-based storage system has replaced a hard-
disk drive in many applications. Recently, implementation
of database systems on NAND flash-based storage systems
has become an important research topic. In particular, the
external sorting is an important operation on database sys-
tems. With the very distinctive characteristics of flash-
memory, the typical external sorting that adopts a clus-
tered sorting could result in performance degradation of
NAND flash-based storage systems and reduce the reliability
of flash-memory. In the paper, we propose an unclustered
sorting that considers the flash-memory characteristics and
then propose an integration to exploit the advantages of
the clustered sorting and the unclustered sorting for NAND
flash-based storage systems. The improve ratio of the exe-
cution time and the energy consumption can be about 25%
in the experiments.
1. INTRODUCTION
Flash-memory has become a popular alternative in stor-
age systems, due to its characteristics in non-volatility, shock-
resistance, and low power consumption. In recent years,
flash-memory devices have advanced along with the wave of
consumer electronics and embedded systems. Flash-memory
could be considered as an alternative to hard-disk drives in
many applications. For example, a NAND flash-based solid
state drive (SSD) that is a data storage device has become
popular and has replaced hard-disk drives in many applica-
tions. Many Manufacturers (such as SanDisk, STEC, Sam-
sung, Mtron, and PNY) have released huge-capacity NAND
flash-based SSD (e.g., 64GB SSD) in the markets. Now,
the implementation of the external sorting, which is an im-
portant operation on database systems on disks, must be
considered with regard to NAND flash-based storage sys-
tems. However, with the very distinctive characteristics of
flash-memory, the traditional external sorting design such
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for profit or commercial advantage and that copies
bear this notice and the full citation on the first page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior specific
permission and/or a fee.
Copyright 200X ACM X-XXXXX-XX-X/XX/XX ...$5.00.
as the external merge sort may result in the severe perfor-
mance degradation of NAND flash-based storage systems
and significantly reduce the reliability of flash-memory.
There are four critical issues which have a significant im-
pact on the efficiency of the external sorting in flash-memory:
(1) write-once with bulk-erase (2) the endurance issue (3)
unsymmetrical operations (4) no mechanical latency. Flash-
memory can not be over-written (updated) unless it is erased.
As a result, out-of-date (or invalid) versions and the latest
copy of data might co-exist simultaneously on flash-memory.
Furthermore, an erasable unit of flash-memory is relatively
large so that valid data copying might be involved in the
erasure. Frequent erasing of some particular locations of
flash-memory also quickly deteriorates the overall lifetime of
flash-memory (the endurance issue), because each erasable
unit has a limited cycle count on erase operations. In par-
ticular, reads and writes on flash-memory are different from
those on hard disks. Reads on flash-memory have faster
access speed and less energy consumption than writes on
flash-memory. Therefore, reads and writes on flash-memory
are unsymmetrical operations. Since flash-memory has no
disk header and disk platter, no seek and rotational latency
will be needed so that random access and sequential access
to flash-memory have no mechanical latency problem.
With the very distinctive characteristics of flash-memory,
the typical external sorting that adopts a clustered sort-
ing could result in performance degradation of NAND flash-
based storage systems and reduce the reliability of flash-
memory. In the paper, we propose an unclustered sorting
that considers the flash-memory characteristics. We show
that there are pros and cons for the clustered sorting and
the unclustered sorting in NAND flash-based storage sys-
tems. An integration is then proposed to exploit the advan-
tages of the clustered sorting and the unclustered sorting
for NAND flash-based storage systems. The major contri-
butions of this paper are summarized as follows:
• We compare the clustered sorting with the unclustered
sorting in NAND flash-based storage systems. We pro-
pose an integration of the clustered sorting and the
unclustered sorting by three steps and two rules. The
three steps for the integration will not result in addi-
tional overhead and the two rules are derived by the
experimental results.
• The proposed unclustered sorting will create small meta-
items to describe each record. Instead of directly sort-
ing the records, the meta-items are sorted and then the
record rearrangement/replacment is proposed to rear-
range the records by scanning the sorted meta-items.
1
to small random writes to flash-memory, an in-page logging
(IPL) approach [15] used a log-structure-like operation to
decrease the number of page writes. Furthermore, a dy-
namic self-tuning index structure [16] was proposed for the
B-tree index structure so that the performance of index over
flash-memory was improved.
In particular, sorting in database systems is an important
operation for grouping with aggregation, duplicate removal,
sort-merge join and set operations [19]. However, because
the size limit of the main memory, a large file can not be
sorted in memory so that the external merge sort in disk-
based database systems has been studied extensively. Many
previous research [17, 18, 19, 20, 21, 22, 23, 24] has been
proposed for the external merge sort in disk-based database
systems. In [17], a parallel external sort was proposed to
use multiple processors each with its own main memory and
disk. In [18], a practical external sort was proposed for
scientific and commercial databases, where variable-length
records, in-place, and restartable features were also con-
sidered. In [19], a method for run-time adjustment of in-
memory work-space for external mergesort was proposed.
In [20], a memory management method was proposed for
variable-length records during run formation for external
merge sort. The idea was to retain in memory as much
as possible of the previous run while generating the next
run. In [21], a replacement selection was proposed to handle
fixed-length and variable-length records. It used two ideas
for reducing cache misses and caused fewer cache misses,
fewer instructions, fewer comparisons. In [22], a hybrid tech-
nique that used quick sort and merge sort was proposed to
reduce the I/O (read and write) complexity. In [23], the sur-
vey collected many sorting techniques to improve both sort
performance and the ability to adapt gracefully to resource
fluctuations. In [24], a compression method was proposed
to provide fast compression and decompression and allow
random access to individual records. As a result, the ex-
ternal sorting design on flash-based storage systems should
be different from the implementations and considerations on
disk-based storage systems.
3.2 Motivation
While the storage capacity of flash-memory keeps increas-
ing, many systems, including mobile devices (e.g., PDA’s,
smart phones, Sony VGN-FS500P12 laptops, and IBM X60
laptops), now have flash-memory as secondary storage de-
vices. In particular, a NAND flash-based solid state drive
(SSD) has been available in the markets and is widely used in
PC-based and embedded computing systems. NAND SSDs
mainly consist of NAND flash-memory, SDRAM, and con-
troller to emulate hard disk drives so that many database
applications that run on hard-disk drives might now access
data stored in NAND flash-based storage systems (such as
NAND SSD). Because sorting is an important operation
in database systems, IBM DB2, Informix, Microsoft SQL
Server, Oracle 8, and Sybase ASE all adopt the external
merge sort for a large file. Due to the significant over-
head in the manipulations of the external merge sort in
flash-memory, many applications that need sorting will have
serious performance degradation in sorting data in flash-
memory. As a result, we must investigate the influence of
the external merge sort in NAND flash-based storage sys-
tems. A typical external merge sort consists of two phases.
The first phase is to read records from a large file to the
main memory and sort them in memory and then write out
to flash-memory as a run. A sequence of runs will be gener-
ated by repeating the process. The second phase is to read
appropriate runs to main memory and merge them by main
memory. These runs will be merged to a long run. While the
number of the total runs becomes one, the external merge
sort ends up and the last run is the sorted result. During
the generation of runs and the merge of runs, considerable
intermediate data (i.e., a lot of merged runs) will be gener-
ated and written out to flash-memory. In the experiments,
we find that to sort a large file whose size is about 2.4GB
could result in about 3.6GB data written during the typical
external sorting.
When flash-memory is considered as the storage devices,
updating (or writing) data in flash-memory is a very com-
plicated and expensive operation. A lot of data written will
result in frequent page writes to flash-memory and cause
a sequence of negative effects such as free space on flash-
memory can be consumed very quickly. Garbage collection
will happen frequently to reclaim free space. Because of the
frequent garbage collection activities, flash-memory is fre-
quently erased and the overall lifetime of the flash-memory
is reduced. Another problem is execution time and energy
consumption due to a lot of page writes and block erases
during the typical external sorting and the garbage collec-
tion. It is because that page writes and block erases con-
sume much more execution time and much more energy than
reads. As a result, we will propose an efficient external sort-
ing design for flash-memory storage systems. It not only
provides a reasonable solution to existing systems but also
significantly reduce the write overhead.
4. AN EXTERNAL SORTING DESIGN
4.1 Overview
The typical external sorting is a clustered sorting that is
to make records sorted in a continuous space so that ac-
cessing the sorted records in disk-based database systems
has better performance. We propose an unclustered sorting
that is to create small meta-items that point to the records
and then sort these meta-items. After these meta-items are
sorted, we can rearrange the original records according to
the sorted meta-items. In the experiments, we can observe
that the sum of page reads and page writes for unclustered
sorting is more than that of clustered sorting, as shown in
Table 2. Undoubtedly, clustered sorting is always adopted
in disk-based database systems because the sum of reads
and writes is small, and reads and writes on hard disks are
symmetrical operations. However, the unclustered sorting
can trade the number of page reads for the number of page
writes so that the number of page writes and block erases
could be less than that of clustered sorting. For NAND flash-
based storage systems, because reads, writes, and erases on
flash-memory are unsymmetrical operations, reads on flash-
memory have faster access speed and less energy consump-
tion than writes and erases on flash-memory, as shown in
Table 1. Therefore, the unclustered sorting could have faster
execution time than clustered sorting, as shown with ♠ in
Table 2. However, in some cases such as record length is
512B, 16B, and 8B, clustered sorting could be superior to
unclustered sorting. As a result, there are pros and cons for
the clustered sorting and the unclustered sorting in NAND
flash-based storage systems. An external sorting design is
3
Physical Block
Address
(block,page)
LBA = 3
Address Translation
Table (in main-memory)
(0,3)
(0,1)
(0,6)
(0,4)
(4,7)
(1,0)
(2,1)
(1,2)
(1,3)
0
1
2
3
4
5
6
7
8
9
10
11
.
.
.
Flash Memory
Input 1
Input 2
Input B-1
.
.
.
Output
Flash Memory
page
Logical Block
Address
(array index)
.
.
.
They have the
same content
Lock Table
10
3
.
.
.
Add the logical address
3 to the lock table
Figure 3: A Lock Table
output buffer is identical to some page in flash-memory if
the content of the output buffer is identical to the content
of some input buffer.
Theorem 4.3.1. The content of the output buffer is iden-
tical to some page in flash-memory if the content of the out-
put buffer is identical to the content of some input buffer.
Proof. Because the read/wrtite unit of the flash-memory
is one page, the size of the input buffer and the output buffer
should be equal to the size of the page in flash-memory.
Each run in flash-memory consists of pages and each run
is read into the corresponding input buffer one page at a
time. As a result, the content of each input buffer is read
from some page in flash-memory. While the content of the
output buffer is identical to the content of some input buffer,
it means that there exists a page in flash-memory that is
identical to the content of the output buffer. 2
According to the theorem, we can detect if the content of
the output buffer and that of the input buffer are the same.
We can use B−1 counters to quickly compare their contents
without any memory operations (e.g., memcmp). Note that
each input buffer has one corresponding counter. During
the merge of the B − 1 (input buffer) pages, the smallest
value of one meta-item would be chosen and written to the
output buffer, and its corresponding counter is increased
one. If there exists one counter whose value is identical to
the maximum number of meta-items in one input buffer, it
means that all meta-items in the input buffer are always
chosen as the smallest value and the content of the input
buffer must be identical to the content of the output buffer.
As a result, if there exists one counter like this, it must have
a page that has the same content with the output buffer
in flash-memory. Therefore, the output buffer will be not
written to flash-memory and the logical address of the page
should be added to the lock table.
4.3.3 Rearrangement and Replacement
In the section, we will rearrange the records in the record
file by scanning the sorted meta-items. The sorted meta-
items point to the records in the record file. According to
the record order in the sorted meta-items, the records in the
record file are read and written out to the sorted record file.
During the record rearrangement, B buffer pages will be
used to buffer the records and replacement will be needed
while the buffer pages are full. We list three cases of the
replacement problem in the following:
• Case 1: If the size of a record is smaller than that
of a page, a page can contain other records. That is,
.  .  .(k4, p4) (k3, p3) (k1, p1) (k2, p2)
A  sorted
meta-item file
(kn, pn)
record1 record2 record3
A page in the flash
memory contains record4
record4
Figure 4: Case 1
when a record will be read, a page that contains the
record will be read into the buffer page and then the
buffer page may contain some content of other records.
As shown in Figure 4, assume that record4 will be
read by the meta-item (k4, p4). A page that con-
tains record4 is read into the buffer page and it also
contains record1, record2 and record3. For decreas-
ing the number of page reads, record1, record2 and
record3 should be buffered in the buffer pages because
they will be needed at later time. Note that when a
record in the buffer page is written out, the occupied
space by the record can be reused. However, the num-
ber of buffer pages is limited (i.e., B buffer pages),
not all records can be put in the buffer pages. As a
result, we propose to replace the least recently used
record. As shown in Figure 5, assume that record(n)
will be read by the meta-item (kn, pn) and there are
only free space in the buffer pages for two records. A
page that contains record(n) will be read and record(n-
3), record(n-2), and record(n-1) will be read into the
buffer pages. After record(n-3) and record(n-2) are
read into the buffer pages, there is no free space for
record(n-1). As a result, record2 will be replaced due
to the limit of the free space. This is because (k2, p2)
is the last meta-item in the sorted meta-item file so
that record2 will be the the least recently used record.
A technical problem is how to quickly find the least
recently used record. Assume that the meta-items in
the sorted meta-item file are in ascending order. That
is, the least recently used record must have the largest
primary key in the buffer pages. As shown in Figure 5,
record2 has the largest primary key in the buffer pages
so that it is replaced. We shall show that the least re-
cently used record in the buffer pages must have the
largest primary key.
Theorem 4.3.2. The least recently used record in
the buffer pages must have the largest primary key.
Proof. The correctness of this theorem can be proved
by an induction on the number of records in the buffer
pagesN , i.e., |N |. For the induction base, i.e., |N | = 1,
this theorem is correct because it must be the largest
primary key. Suppose that the theorem is correct for
N being equal to some integer k ≥ 1 (Induction Hy-
pothesis). We shall show that this theorem remains
correct for |N | = (k + 1). Let r be the last record
being included in N so that |N | = (k + 1). If r has
the largest primary key in N , then r’s meta-item in
the sorted meta-item file should be scanned later than
other records in the buffer pages. Therefore, r is the
least recently used record. If r has no the largest pri-
mary key in N , then there exist one record δ in the
buffer pages whose primary key is larger than r. That
5
We set up two rules to determine which sorting method is
applied to the variable-length records. These rules are based
on the observations and the experimental results.
Rule1 Let Ψ be a record set such that ∀rec ∈ Ψ, rec’s size
is between X and Y .
Rule2 rs is between Z and W .

	
		
	 	

 
Ψ−Φ Ψ



Φ
	


Figure 7: Integration of the Clustered Sorting and
the Unclustered Sorting
As shown in Figure 7, the integration of the clustered
sorting and the unclustered sorting is described by three
steps. Regardless of which sorting method, Step1 is needed
for generating runs in the clustered sorting or generating
meta-items in the unclustered sorting. In Step2, rs can be
maintained for those records whose length is between X and
Y while every new record is inserted such that Φ can be par-
titioned into Φ − Ψ and Ψ. In Step3, we can quickly check
which sorting method is adopted according to Rule1 and
Rule2. In Section 6, we will derive X, Y , Z, and W for
Rule1 and Rule2 according to the experimental results. As
a result, 3 steps for the integration of the clustered sorting
and the unclustered sorting can be overlapped with original
operations of the clustered sorting and the unclustered sort-
ing so that the integration will not result in additional over-
head. In the following section, we will give insights behind
the integration of the clustered sorting and the unclustered
sorting by I/O analysis.
5. I/O ANALYSIS
Number of pages of a large file N
Number of buffer pages (i.e., main memory) B
Size of a record γ
Size of a page p
Size of a meta-item m
Number of pages in a block np
Constant Value (0 < ² ≤ 1) ²
Table 3: Parameter Definition
In the section, we will derive the I/O analysis of the clus-
tered sorting and the unclustered sorting for NAND flash-
based storage systems. Table 3 is the parameter defini-
tion. Nr, Nw, Ne and Nrw denote the operation time for
N page reads, N page writes, N block erases and N page
reads/writes, respectively. For example, Nrw with N=5 de-
notes that the operation time for 5 page reads and 5 page
writes. Why do we distinguish between page reads and page
writes? This is because reads and writes are unsymmetrical
operations on flash-memory. Reads on flash-memory always
have less overhead than writes on flash-memory. Accord-
ing to Table 1, the access speed of a page read may be
faster seven times than that of a page write. Page writes
can incur a sequence of garbage collection activities that
also contain page reads, page writes and block erases. Fur-
thermore, a lot of pages writes and block erases can reduce
the lifetime of flash-memory. That is why we should dis-
tinguish between page reads and page writes from flash-
memory. The I/O cost of the clustered sorting can be de-
fined as follows: Nrw is to generate runs in the first phase.
(N ∗ logB−1 dN/Be)rw is to merge the runs in the second
phase. ((N +N ∗ logB−1 dN/Be)/np)e is the average erase
cost during the first case and the second phase. Assume that
writes in the clustered sorting are in an appending (and se-
quential) fashion, one block erase will be needed after np
page writes. In the following equation, X denotes the I/O
cost of the clustered sorting.
X = Nrw+(N∗logB−1 dN/Be)rw+((N+N∗logB−1 dN/Be)/np)e
(1)
I/O Y =M + S + E +R
Cost
M Nr+(dN ∗ mγ e)w
S (dN ∗ m
γ
e ∗ logB−1 dN∗mB∗γ e)rw
E ((dN ∗ m
γ
e+ dN ∗ m
γ
e ∗ logB−1 dN∗mB∗γ e)/np)e
R I/O cost during the record rearrangement and replacement
Table 4: I/O Analysis of the unclustered sorting
We also summarize the I/O analysis for the unclustered
sorting, as shown in Table 4. M , S, and E denote the cost
for the generation of the meta-item file, the cost for the
sorting of the meta-item file, and the cost for the recycling
during sorting, respectively. R denotes the I/O cost during
the record rearrangement and replacement. Assume that
X > Y such that X > M + S + E + R. We can derive the
following inequality: Let m
γ
be α, where 0 < α ≤ 1.
X −M − S − E > R
=> (d(1− α) ∗Ne)w + (d(1− α) ∗Ne ∗ logB−1 dN/Be −
dα ∗Ne ∗ logB−1 α)rw + ((d(1− α) ∗Ne+ d(1− α) ∗
Ne ∗ logB−1 dN/Be − dα ∗Ne ∗ logB−1 α)/np)e > R
=> Nw + (N ∗ logB−1 dN/Be)rw+︸ ︷︷ ︸
((N +N ∗ logB−1 dN/Be)/np)e > R︸ ︷︷ ︸
Let α be 0 and the left side will become the largest
(2)
According to Inequality 2, we can have the following ob-
servations:
• If X > Y , R must be as small as possible. In other
words, I/O cost during the record rearrangement and
7
an ascending order, the number of page reads of the unclus-
tered sorting was decreased and even was close to that of the
clustered sorting. It was because that the buffering ability
during the record rearrangement and replacement had better
performance for sorted records. Generally speaking, when
rs was increased, the number of pages reads of the unclus-
tered sorting could be decreased and the clustered sorting
had no significant influence due to no need of the record
rearrangement and replacement. On the other hand, when
record length was 512B, the number of page reads of the
unclustered sorting was not different under any rs values.
It was because that the record length was equal to a page
size so that Case 2 was satisfied and had no any buffering
during the record rearrangement and replacement.
6.3 Number of Page Writes
No matter the value of rs, the number of page writes
of the unclustered sorting in most cases was less than or
close to that of the clustered sorting, as shown in Figure
8.(b). It was because that a smaller meta-item could incur
less page writes during the sorting process. Additionally,
we also detected if the output buffer was identical to some
page in flash-memory so that additional page writes could
be saved. When the record length was decreased to the size
of a meta-item, the number of page writes of the unclustered
sorting can not be reduced significantly and even was more
than that of the clustered sorting. It was because that the
unclustered sorting can not benefit significantly from the
sorting of the meta-items when the record length is close to
that of a meta-item.
6.4 Number of Block Erases
The number of block erases was proportional to the num-
ber of page writes. Because the number of page writes of
the unclustered sorting in most cases was less than that of
the clustered sorting, the number of block erases of the un-
clustered sorting was also less than that of the clustered
sorting, as shown in Figure 8.(c). We know writes can in-
cur a sequence of garbage collection activities that contains
page reads, page writes, and block erases. Most writes and
erases can also damage the lifetime of flash-memory so that
we should reduce the activities of writes and erases as more
as possible. We observe that the unclustered sorting can re-
duce the number of page writes and block erases with smaller
rs and larger record length. As a result, we should exploit
the advantages of the unclustered sorting and the clustered
sorting to reduce the garbage collection overhead.
6.5 Execution Time and Energy Consumption
We also measured the execution time and the energy con-
sumption according to the number of page reads, page writes,
and block erases. As shown in Figure 9.(a) and Figure 9.(b),
the unclustered sorting had faster execution time and less
energy consumption in most cases. The maximum improve
ratio of the execution time and the energy consumption
was about 25% when the unclustered sorting was adopted.
When the record length was decreased to the size of a meta-
item, the execution time and the energy consumption of the
unclustered sorting were be inferior to that of the clustered
sorting. It was because that the unclustered sorting can not
benefit from the smaller record length so that additional
page writes were needed for the the creation and sorting of
the meta-items plus page writes in the record rearrangement
0
500
1000
1500
2000
2500
3000
3500
51
2 
(r
s=
0)

25
6 
(r
s=
0)

12
8 
(r
s=
0)

64
 (r
s=
0)

32
 (r
s=
0)

16
 (r
s=
0)

8 
(r
s=
0)

51
2 
(r
s=
0.
25
)
25
6 
(r
s=
0.
25
)
12
8 
(r
s=
0.
25
)
64
 (r
s=
0.
25
)
32
 (r
s=
0.
25
)
16
 (r
s=
0.
25
)
8 
(r
s=
0.
25
)
51
2 
(r
s=
0.
5)

25
6 
(r
s=
0.
5)

12
8 
(r
s=
0.
5)

64
 (r
s=
0.
5)

32
 (r
s=
0.
5)

16
 (r
s=
0.
5)

8 
(r
s=
0.
5)

51
2 
(r
s=
0.
75
)
25
6 
(r
s=
0.
75
)
12
8 
(r
s=
0.
75
)
64
 (r
s=
0.
75
)
32
 (r
s=
0.
75
)
16
 (r
s=
0.
75
)
8 
(r
s=
0.
75
)
51
2 
(r
s=
1)

25
6 
(r
s=
1)

12
8 
(r
s=
1)

64
 (r
s=
1)

32
 (r
s=
1)

16
 (r
s=
1)

8 
(r
s=
1)

E
x
ec
u
ti
o
n
 T
im
e 
(s
)
Unclustered Sorting Clustered Sorting
(a) Execution Time
0
20
40
60
80
100
120
140
51
2 
(r
s=
0)

25
6 
(r
s=
0)

12
8 
(r
s=
0)

64
 (r
s=
0)

32
 (r
s=
0)

16
 (r
s=
0)

8 
(r
s=
0)

51
2 
(r
s=
0.
25
)
25
6 
(r
s=
0.
25
)
12
8 
(r
s=
0.
25
)
64
 (r
s=
0.
25
)
32
 (r
s=
0.
25
)
16
 (r
s=
0.
25
)
8 
(r
s=
0.
25
)
51
2 
(r
s=
0.
5)

25
6 
(r
s=
0.
5)

12
8 
(r
s=
0.
5)

64
 (r
s=
0.
5)

32
 (r
s=
0.
5)

16
 (r
s=
0.
5)

8 
(r
s=
0.
5)

51
2 
(r
s=
0.
75
)
25
6 
(r
s=
0.
75
)
12
8 
(r
s=
0.
75
)
64
 (r
s=
0.
75
)
32
 (r
s=
0.
75
)
16
 (r
s=
0.
75
)
8 
(r
s=
0.
75
)
51
2 
(r
s=
1)

25
6 
(r
s=
1)

12
8 
(r
s=
1)

64
 (r
s=
1)

32
 (r
s=
1)

16
 (r
s=
1)

8 
(r
s=
1)

E
n
er
g
y
 C
o
n
su
m
p
ti
o
n
 (
jo
u
le
)
Unclustered Sorting Clustered Sorting
(b) Energy Consumption
Figure 9: Execution Time and Energy Consumption
and replacement. On the other hand, when rs was increased,
the unclustered sorting and the clustered sorting can have
faster execution time and less energy consumption. Obvi-
ously, to detect if the output buffer was identical to some
page in flash-memory can decrease a lot of page writes for
both sorting methods, especially when rs was increased.
In conclusion, the sum of page reads of the unclustered
sorting may be more than that of the clustered sorting be-
cause the unclustered sorting can trades the number of reads
for the number of writes. Due to unsymmetrical operations
on flash-memory, the performance of the unclustered sorting
can be better than that of the clustered sorting with smaller
rs and larger record length.
6.6 Rules
According to the experimental results in Figure 8 and Fig-
ure 9, we can define two rules for the integration of clustered
sorting and unclustered sorting in Section 4.4. We list the
two rules in the following:
Rule1 Let Ψ be a record set such that ∀rec ∈ Ψ, rec’s size
is between 32 and 512.
Rule2 rs is between 0.75 and 1.
The two rules can be configured in advance when system
configuration (such as main memory size or record length)
is determined. We can find that the execution time and
the energy consumption of the unclustered sorting was not
better than that of the clustered sorting in Figure 9 when
record length was 512B. The reason was that the number of
passes during the merging process of runs by the clustered
sorting was only one under 32 MB main memory. As a re-
sult, the number of page writes by the unclustered sorting
that included page writes for the generation of meta-items
9
11
??????
?????????????????????????????????
???????????????????????????????????
???????????????????????????????????
???????????????????????????????????
???????????????????????????????????
????????????????????????????????(main
memory)???????????????????????????????
???????????????????????????????????
???????????????????????????????????
??????????????????????????????????
????????????????1???10?????????????ACM
Transactions in Embedded Computing Systems??????????????
?????????????????
??????????????????????:
1. C. H. Wu, ``An Energy-Efficient I/O Request Mechanism for Multi-Bank
Flash-Memory Storage Systems,'‘ ACM Transactions on Design Automation 
of Electronic Systems (ACM TODAES) , Volume 14, Issue 1 (January 2009).
2. C. H. Wu, ``A Time-Predictable System Initialization Design for
Huge-Capacity Flash-Memory Storage Systems,'‘ ACM/IEEE International 
Conference on Hardware/Software Codesign and System Synthesis, Atlanta,
USA, October 2008 (ACM/IEEE CODES+ISSS 2008).
3. Z. W. Hong, K. Y. Chin, Y. P. Liou, J. M. Lin, and C. H. Wu, ``An
Agent-Based Internet Advertising System by Using PULL Mechanism,'‘ IEEE 
International Symposium on Information Technology (IEEE ITSim 2008).
