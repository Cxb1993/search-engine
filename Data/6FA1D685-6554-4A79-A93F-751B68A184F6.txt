carry a strong theoretical guarantee while enjoying superior performance in practice. We
will discuss some details of each piece of our work below.
3 Combining Ordinal Preferences by Boosting
Ordinal ranking is a special type of cost-sensitive classification problem that can be
used to model human preference. In particular, it asks the learner to predict the ranks
of input instances. For instance, the predicted rating of a movie might be one of the
ranks {do-not-bother, only-if-you-must, good, very-good, run-to-see}. Because
there is a natural order among the ranks, the cost depends on the “closeness” of the
mis-prediction. For example, the cost of mis-predicting a do-not-bother movie as
run-to-see should be higher than the cost of mis-predicting it as good. That is, or-
dinal ranking can be viewed as a cost-sensitive classification problem with the so-called
V-shaped cost vectors (Lin and Li 2009).
In our work (Lin and Li 2009), we continued from my Ph.D. thesis (Lin 2008) and
further analyzed the relationship between ordinal ranking and binary classification. We
also proposed a novel boosting approach, which can be used to improve any cost-sensitive
ordinal ranking algorithms. Our proposed approach can be viewed as an extension of the
well-known AdaBoost algorithm and thus inherits many of its good properties. One of the
empirical results is listed in Figure 1. It demonstrates how our proposed algorithm (the
green bar; AdaBoost.OR) can to boost the performance of a simple ordinal ranking
algorithm (the blue bar; ORStump) to reach a comparable performance to the state-of-
the-art algorithm (the red bar; SVOR). Our paper (Lin and Li 2009) was published in
the Preference Learning workshop at ECML/PKDD 2009, with travel expenses partially
supported by this project. It is attached in the Appendix for reference.
4 A Simple Cost-sensitive Classification Algorithm
Using One-versus-one Comparisons
One-versus-one (OVO) decomposition is a general way of reducing multi-class classifi-
cation to binary classification. The reduction is formed by comparing examples from
two of the classes. We have successfully followed a methodology proposed in my Ph.D.
thesis (Lin 2008) to extend the OVO decomposition to a new algorithm: cost-sensitive
2
iris balance car diabetes glass vehice vowelsegment
0
50
100
150
200
250
300
350
400
T
e
s
t 
c
o
s
t
 
 
OVAŦM5P
PCRŦM5P
(a) Using M5P as Regression Learner
iris balance car diabetes glass vehice vowelsegment
0
50
100
150
200
250
300
350
400
450
500
T
e
s
t 
c
o
s
t
 
 
OVAŦNNet
PCRŦNNet
(b) Using Neural Network as Regression Learner
Figure 3: Experimental Results of PCR versus OVA
5 Cost-Sensitive Classification via Reducing to Re-
gression
First, we designed a reduction from cost-sensitive classification to regression (Tu and Lin
2009a) by asking a regression learner to predict the answers to the following question:
How likely does this example belong to class i?
The likeliness depends on the cost information, and we have proved a theoretically justi-
fied way to represent the likeliness. In particular, we have demonstrated that encoding
the likeliness by the negative cost (or any of its shifted version) is sufficient to make the
reduction work (Tu 2009; Tu and Lin 2009a). In other words, a good regression learner
can be transformed to a good cost-sensitive classification learner. We also applied the
reduction to design the per-class regression (PCR) algorithm for cost-sensitive classifi-
cation. Note that PCR can also be viewed as a theoretically-justified extension of the
traditional one-versus-all (OVA) algorithm. We have compared PCR (the yellow bar)
with OVA (the green bar) using many experiments, which are partially shown in Fig-
ure 3. We see that PCR could use the cost information appropriately and achieve better
performance than OVA.
Furthermore, in another work (Tu and Lin 2009b), we analyzed the looseness of the
PCR cost bound and proposed a better reduction. In particular, we found that reducing
to least-squares regression may not be the optimal choice, and it suffices to reduce to the
one-sided regression instead. That is, we can ask the regression learner to predict the
4
References
Abe, N., B. Zadrozny, and J. Langford (2004). An iterative method for multi-class cost-
sensitive learning. In W. Kim, R. Kohavi, J. Gehrke, and W. DuMouchel (Eds.), Pro-
ceedings of the 10th ACM SIGKDD International Conference on Knowledge Discovery
and Data Mining, pp. 3–11. ACM.
Beygelzimer, A., V. Daniand, T. Hayes, J. Langford, and B. Zadrozny (2005). Error
limiting reductions between classification tasks. In L. D. Raedt and S. Wrobel (Eds.),
Machine Learning: Proceedings of the 22rd International Conference, pp. 49–56. ACM.
Beygelzimer, A., J. Langford, and P. Ravikumar (2007). Multiclass classification with
filter trees. Downloaded from http://hunch.net/~jl.
Langford, J. and A. Beygelzimer (2005). Sensitive error correcting output codes. In
P. Auer and R. Meir (Eds.), Learning Theory: 18th Annual Conference on Learning
Theory, Volume 3559 of Lecture Notes in Artificial Intelligence, pp. 158–172. Springer-
Verlag.
Lin, H.-T. (2008). From Ordinal Ranking to Binary Classification. Ph. D. thesis, Cali-
fornia Institute of Technology.
Lin, H.-T. (2009). A simple cost-sensitive classification algorithm using one-versus-one
comparisons. Technical report, National Taiwan University.
Lin, H.-T. and L. Li (2009). Combining ordinal preferences by boosting. In E. Hu¨llermeier
and J. Fu¨rnkranz (Eds.), Proceedings of the ECML/PKDD 2005 Preference Learning
Workshop.
Tu, H. (2009). Regression approaches for multi-class cost-sensitive classification. Master’s
thesis, National Taiwan University.
Tu, H. and H.-T. Lin (2009a). Multiclass cost-sensitive classification via regression. Tech-
nical report, National Taiwan University.
Tu, H. and H.-T. Lin (2009b). One-sided support vector regression for multiclass cost-
sensitive classification. Technical report, National Taiwan University.
Vapnik, V. N. (1998). Statistical Learning Theory. New York, NY: Wiley.
6
and showed that any binary classification algorithm can be casted as an ordi-
nal ranking one with EBC. Still some other approaches fall into neither of the
perspective above, such as Gaussian process ordinal regression [6].
Given the wide availability of ordinal ranking algorithms, a natural question
is whether their performance could be further improved by a generic method. In
binary classification, there are many boosting algorithms that serve the purpose.
They usually work by combining the hypotheses that are produced from a base
binary classification algorithm [7], including the well-known adaptive boosting
(AdaBoost) approach [8]. There are also some boosting-related approaches for
ordinal ranking. For example, Freund et al. [9] introduced the RankBoost ap-
proach based on the pairwise comparison perspective. Lin and Li [10] proposed
ordinal regression boosting (ORBoost), which is a special instance of the EBC
perspective. However, both approaches take a base binary classification algo-
rithm rather than a base ordinal ranking one. In other words, they cannot be
directly used to improve the performance of existing ordinal ranking algorithms
such as PRank or SVOR.
In this paper, we propose a novel boosting approach for ordinal ranking.
The approach improves the performance of any cost-sensitive ordinal ranking
algorithm, including PRank and SVOR. Our approach directly extends the orig-
inal AdaBoost, and inherits many of its good properties. The approach is de-
signed with a technique called reverse reduction, which complements the reduc-
tion method of Li and Lin [5]. The technique not only helps in designing our
proposed approach, but also reveals strong theoretical connections between or-
dinal ranking and binary classification.
The paper is organized as follows. In Section 2, we introduce the basic setup
as well as the reduction method of Li and Lin [5]. Then, we discuss the reverse
reduction technique and its theoretical implications in Section 3. We use the
technique to design and analyze the proposed AdaBoost.OR approach in Sec-
tion 4. Finally, we show the experimental results in Section 5 and conclude in
Section 6.
2 Background
We shall first define the ordinal ranking problem. Then, we introduce the reduc-
tion method of Li and Lin [5] and the consequent error bound.
2.1 Problem Setup
In the ordinal ranking problem, the task is to predict the rank y of some input
x ∈ X ⊆ RD, where y belongs to a set K of consecutive integers 1, 2, · · · ,K.
We shall adopt the cost-sensitive setting, in which a cost vector c ∈ RK
is generated with (x, y) from some fixed but unknown distribution P on X ×
K × RK . The k-th element c[k] of the cost vector represents the penalty when
predicting the input vector x as rank k. We naturally assume that c[y] = 0 and
c[k] ≥ 0 for all k ∈ K. An ordinal ranking problem comes with a given training
Theorem 1. If g(x, k) is rank-monotonic, i.e.,
g(x, k−1) ≥ g(x, k), for 2 ≤ k ≤ K−1,
or if every cost vector c is convex, i.e.,
c[k+1]− c[k] ≥ c[k]− c[k−1] , for 2 ≤ k ≤ K−2,
then π(rg) ≤ πb(g).
Proof. The details can be found in the work of Lin [12].
3 Reverse Reduction Technique
Theorem 1 indicates that if there exists a decent binary classifier g, we can ob-
tain a “good” ordinal ranker rg. Nevertheless, it does not guarantee how good rg
is in comparison with other ordinal rankers. If we denote g∗ as the optimal bi-
nary classifier under Pb, and r∗ as the optimal ordinal ranker under P, does
a small regret
(
πb(g) − πb(g∗)
)
in binary classification translate to a small re-
gret
(
π(rg) − π(r∗)
)
in ordinal ranking? In particular, is π(rg∗) close to π(r∗)?
Next, we introduce the reverse reduction technique, which helps to answer the
questions above.
3.1 Reverse Reduction
The reverse reduction technique works on the binary classification problems gen-
erated by the reduction method described in Section 2. We can use the technique
to not only understand more about the theoretical nature of ordinal ranking, but
also design better ordinal ranking algorithms. Reverse reduction goes through
each stage of the reduction method in a different direction. In the training stage,
instead of starting with the ordinal examples (xn, yn, cn), reverse reduction deals
with the weighted binary examples (xn, k, znk, wnk). It first combines each set
of binary examples sharing the same xn to an ordinal example by

yn = 1 +
K−1∑
k=1
Jznk > 0K ;
cn[k] =
K−1∑
ℓ=1
wnℓ
K−1 · Jyn ≤ ℓ < k or k < ℓ ≤ ynK . (3)
It is easy to verify that (3) is the exact inverse transform of (2) on the training
examples. These ordinal examples are then given to an ordinal ranking algorithm
to obtain an ordinal ranker r. In the prediction stage, reverse reduction works by
decomposing the prediction r(x) to K−1 binary predictions, each as if coming
from a joint binary classifier
gr(x, k) = 2 Jk < r(x)K− 1. (4)
Then, a lemma on the generalization ability of gr immediately follows.
sign(0) assumed to be +1.
r∗(x) ≡ argmin
ℓ
E
c∼P(·|x)
c[ℓ] ,
g∗(x, k) ≡ sign
(
E
(w,z)∼Pb(·|x,k)
(w · z)
)
.
It is not hard to prove that r∗ and g∗ are optimal, i.e., for any ordinal ranker r
and any binary classifier g,
π(r) ≥ π(r∗), πb(g) ≥ πb(g∗) . (5)
With the definitions of r∗ and g∗, the reverse reduction technique allows a
simple proof of the following regret bound.
Theorem 2. If g(x, k) is rank-monotonic, or if every cost vector c is convex,
then
π(rg)− π(r∗) ≤ πb(g)− πb(g∗).
Proof.
π(rg)− π(r∗) ≤ πb(g)− π(r∗) (from Theorem 1)
= πb(g)− πb(gr∗) (from Lemma 1)
≤ πb(g)− πb(g∗)
(
from (5)
)
An immediate implication of the regret bound is as follows. If there exists
one optimal binary classifier g+ that is rank-monotonic, both the right-hand-side
and the left-hand-side are 0. That is, every optimal binary classifier under Pb
leads to an optimal ordinal ranker under P. In other words, locating an optimal
ordinal ranker is “no harder than” locating an optimal binary classifier. On the
other hand, binary classification is also“no harder than”ordinal ranking, because
the former is a special case of the latter with K = 2. Therefore, if there is
a rank-monotonic g+, ordinal ranking is equivalent to binary classification in
hardness.4 In the following theorem, we show a general sufficient condition for
the equivalence.
Theorem 3. Assume that the effective cost
cx[k] = E
c∼P(·|x)
c[k]−min
ℓ
E
c∼P(·|x)
c[ℓ]
is V-shaped with respect to yx = argminℓ cx[ℓ] = r∗(x) on every point x ∈ X .
Let g+(x, k) ≡ 2 Jk < yxK− 1. Then g+ is rank-monotonic and optimal for Pb.
4 Note that the equivalence in hardness here is qualitative and considers neither the
number of independent examples N needed nor the number of classes K.
Theorem 4. (prediction with the weighted median) For any ordinal ranking en-
semble H = {(rt, vt)}
T
t=1, assume that vt ≥ 0 and
∑T
t=1 vt = 1. Then,
rH(x) = min
{
k :
T∑
t=1
vt Jk ≥ rt(x)K > 1
2
}
. (7)
Proof. Let k∗ = min
{
k :
∑T
t=1 vt Jk ≥ rt(x)K > 12}. Then,
T∑
t=1
vt Jk ≥ rt(x)K > 1
2
if and only if k∗ ≤ k. That is,
∑T
t=1 vt Jk < rt(x)K ≥ 12 if and only if k < k∗.
Thus, rH(x) = 1 + k
∗ − 1 = k∗.
Therefore, the prediction rule (6) that goes back and forth between reduction
and reverse reduction can be equivalently performed by computing a simple
and intuitive statistic in (7): the weighted median. Note that the rule in (7) is
not specific for our approach. It can be applied to ordinal ranking ensembles
produced by any ensemble learning approaches, such as bagging [13].
4.2 Training Steps
We now look at the training steps. The steps of the original AdaBoost are
listed in Algorithm 1. After plugging AdaBoost into reduction and a base ordinal
ranking algorithm into reverse reduction, we can equivalently obtain Algorithm 2:
AdaBoost.OR. The equivalence is based on maintaining the following invariance
in each iteration.
Lemma 2. Substitute the indices m in Algorithm 1 with (n, k). That is, xˆm =
(xn, k), zˆm = zˆnk, and wˆm = wˆnk. Take gˆt(x, k) = grt(x, k), and assume that in
Algorithms 1 and 2,
c(τ)n [k] =
K−1∑
ℓ=1
wˆ
(τ)
nℓ
K−1
· Jyn ≤ ℓ < k or k < ℓ ≤ ynK (8)
is satisfied for τ = t with wˆ
(τ)
nℓ ≥ 0. Then, equation (8) is satisfied for τ = t+ 1
with wˆ
(τ)
nℓ ≥ 0.
Proof. Because (8) is satisfied for τ = t and wˆ
(t)
nℓ ≥ 0, the cost vector c
(t)
n is
V-shaped with respect to yn and c
(t)
n [yn] = 0. Thus,
N∑
n=1
(
c(t)n [1] + c
(t)
n [K]
)
=
N∑
n=1
K−1∑
k=1
wˆ
(t)
nk .
reduction is equivalent to running AdaBoost.OR with the base algorithm. Ada-
Boost.OR takes AdaBoost as a special case of K = 2, and inherits many of its
good properties, as discussed below.
4.3 Properties
AdaBoost.OR can take any cost-sensitive base algorithm that produces individ-
ual ordinal rankers rt with errors ǫt ≤
1
2 . In binary classification, the
1
2 error
bound can be naturally achieved by a constant classifier or a fair coin flip. For
ordinal ranking, is 12 still easy to achieve? The short answer is yes. In the follow-
ing theorem, we demonstrate that there always exists a constant ordinal ranker
that satisfies the error bound.
Theorem 5. Define constant ordinal rankers r˜k by r˜k(x) ≡ k for all x. For any
set {cn}
N
n=1, there exists a constant ranker with k ∈ K such that
ǫ˜k =
(
N∑
n=1
cn[r˜k(x)]
)/( N∑
n=1
cn[1] + cn[K]
)
≤
1
2
Proof. Either r˜1 or r˜K achieves error ≤
1
2 because by definition ǫ˜1 + ǫ˜K = 1.
Therefore, even the simplest deterministic ordinal rankers can always achieve
the desired error bound.5 If the base ordinal ranking algorithm produces better
ordinal rankers, the following theorem bounds the normalized training cost of
the final ensemble H.
Theorem 6. Suppose the base ordinal ranking algorithm produces ordinal rankers
with errors ǫ1, · · · , ǫT , where each ǫt ≤
1
2 . Let γt =
1
2 − ǫt, the final ensemble rH
satisfies the following error bound:
∑N
n=1 cn[rH(xn)]∑N
n=1 cn[1] + cn[K]
≤
T∏
t=1
√
1− 4γ2t ≤ exp
(
−2
T∑
t=1
γ2t
)
.
Proof. Similar to the proof for Lemma 2, the left-hand-side of the bound equals(
N∑
n=1
K−1∑
k=1
wnk
q
znk 6= gHˆ(xn, k)
y)/( N∑
n=1
K−1∑
k=1
wnk
)
,
where Hˆ is a binary classification ensemble {(gˆt, vt)}
T
t=1 with gˆt = grt . Then,
the bound is a simple consequence of the well-known AdaBoost bound [8].
Theorem 6 indicates that if the base algorithm always produces an ordi-
nal ranker with ǫt ≤
1
2 − γ for γ > 0, the training cost of H would decrease
5 Similarly, the error bound can be achieved by a randomized ordinal ranker which
returns either 1 or K with equal probability.
more sophisticated boundaries that approximate the underlying quadratic curves
better.
5.2 Benchmark Data
Next, we run AdaBoost.OR on eight benchmark data sets6 with the absolute
cost. We keep the splits provided by Chu and Keerthi [1], and also average
the results over 20 trials. Thus, our results can be fairly compared with their
benchmark SVOR ones.
We couple AdaBoost.OR with three base algorithms: ORStump, PRank [4],
and a reduction-based formulation of SVOR [1] proposed by Li and Lin [5].
For the PRank algorithm, we adopt the SiPrank variant, and make it cost-
sensitive by presenting random examples (xn, yn) with probability proportional
to maxk∈K cn[k]. In addition, we apply the pocket technique with ratchet [16]
for 2000 epochs to get a decent training cost minimizer. For SVOR, we follow
the same setting of Li and Lin [5] except for the choice of parameter. In partic-
ular, we set the parameter C in the t-th iteration as the smallest number within{
2−20, 2−18, · · · , 220
}
that makes ǫt ≤ 0.3. The setup guarantees that SVOR pro-
duces a decent training cost minimizer without overfitting the training examples
too much.
We run AdaBoost.OR for T = 1000, 100, 10 iterations for ORStump, PRank,
and SVOR respectively. Such a setup is intended to compensate the computa-
tional complexity of each individual base algorithm. Nevertheless, a more sophis-
ticated choice of T should further improve the performance of AdaBoost.OR.
For each algorithm, the average training cost as well as its standard error
is reported in Table 1; the average test cost and its standard error is reported
in Table 2. For each pair of single and AdaBoost.OR (short-handed AB.OR)
entries, we mark those within one standard error of the lowest in bold. We also
list the benchmark SVOR results from Chu and Keerthi [1] in Table 2, and mark
the entries better than the benchmark ones with †.
From the tables, we see that AdaBoost.OR almost always improves both the
training and test performance of the base algorithm significantly, especially for
ORStump and SVOR. It is harder for AdaBoost.OR to improve the performance
of PRank, because it sometimes cannot produce a good rt in terms of minimizing
the training cost even with the pocket technique.
Note that a single-shot execution of the SVOR base algorithm is much worse
than the benchmark SVOR in terms of test cost. The difference can be explained
by looking at their parameter selection procedures. The SVOR base algorithm
chooses its parameter by only the training cost to guarantee ǫt ≤
1
2 , which is the
condition that allows AdaBoost.OR to work (see Theorem 6). On the other hand,
the benchmark SVOR goes through a complete parameter selection procedure
using cross-validation, which justifies its good test performance but is quite time-
consuming. On the other hand, AdaBoost.OR (especially with ORStump) is
6 They are pyrimdines, machineCPU, boston, abalone, bank, computer, california, and
census [1].
References
[1] Wei Chu and S. Sathiya Keerthi. New approaches to support vector ordinal
regression. In Luc De Raedt and Stefan Wrobel, editors, Proceedings of
ICML 2005, pages 145–152. ACM, 2005.
[2] Eibe Frank and Mark Hall. A simple approach to ordinal classification. In
Luc De Raedt and Peter Flach, editors, Proceedings of ECML 2001, volume
2167 of Lecture Notes in Artificial Intelligence, pages 145–156. Springer-
Verlag, 2001.
[3] Ralf Herbrich, Thore Graepel, and Klaus Obermayer. Large margin rank
boundaries for ordinal regression. In Alexander J. Smola, Peter J. Bartlett,
Bernhard Scho¨kopf, and Dale Schuurmans, editors, Advances in Large Mar-
gin Classifiers, pages 115–132. MIT Press, 2000.
[4] Koby Crammer and Yoram Singer. Online ranking by projecting. Neural
Computation, 17:145–175, 2005.
[5] Ling Li and Hsuan-Tien Lin. Ordinal regression by extended binary clas-
sification. In Bernhard Scho¨lkopf, John C. Platt, and Thomas Hofmann,
editors, Proceedings of NIPS 2006, volume 19, pages 865–872. MIT Press,
2007.
[6] Wei Chu and Zoubin Ghahramani. Gaussian processes for ordinal regres-
sion. Journal of Machine Learning Research, 6:1019–1041, 2005.
[7] Ron Meir and Gunnar Ra¨tsch. An introduction to boosting and leveraging.
In S. Mendelson and A. J. Smola, editors, Advanced Lectures on Machine
Learning, volume 2600 of Lecture Notes in Computer Science, pages 118–
183. Springer-Verlag, 2003.
[8] Yoav Freund and Robert E. Schapire. A decision-theoretic generalization of
on-line learning and an application to boosting. Journal of Computer and
System Sciences, 55(1):119–139, 1997.
[9] Yoav Freund, Raj Iyer, Robert E. Shapire, and Yoram Singer. An efficient
boosting algorithm for combining preferences. Journal of Machine Learning
Research, 4:933–969, 2003.
[10] Hsuan-Tien Lin and Ling Li. Large-margin thresholded ensembles for ordi-
nal regression: Theory and practice. In Jose´ L. Balcaza´r, Philip M. Long,
and Frank Stephan, editors, Proceedings of ALT 2006, volume 4264 of Lec-
ture Notes in Artificial Intelligence, pages 319–333. Springer-Verlag, 2006.
[11] Naoki Abe, Bianca Zadrozny, and John Langford. An iterative method
for multi-class cost-sensitive learning. In Won Kim, Ron Kohavi, Johannes
Gehrke, and William DuMouchel, editors, Proceedings of KDD 2004, pages
3–11. ACM, 2004.
[12] Hsuan-Tien Lin. From Ordinal Ranking to Binary Classification. PhD
thesis, California Institute of Technology, 2008.
[13] Leo Breiman. Bagging predictors. Machine Learning, 24(2):123–140, 1996.
[14] Robert E. Schapire, Yoav Freund, Peter Bartlett, and Wee Sun Lee. Boost-
ing the margin: A new explanation for the effectiveness of voting methods.
The Annals of Statistics, 26(5):1651–1686, 1998.
國科會補助出國出席國際會議
出國報告
林軒田助理教授
台灣大學資訊工程系
NSC 98-2218-E-002-019
一、會議資訊：
（一）會議名稱：
歐洲機器學習/資料探勘年會: 喜好學習討論會
European Conference on Machine Learning (ECML)/ Principles and Practice of
Knowledge Discovery in Databases(PKDD): Preference Learning (PL) Workshop
（二）會議地點：
Bled, Slovenia (斯洛維尼亞)
（三）會議時間：
9/7/2009至 9/11/2009。大會時間為9/8至 9/10，討論會時間為 9/7及 9/11。
其中「喜好學習(Preference Learning)」的討論會於 9/11 全天舉行。
二、會議心得：
考量轉機及時差時間，此次在台灣於 9/5 出發，搭乘華航班機至德國法蘭克福機場
轉當地短程飛機抵達Solvenia首都Ljubljana，再乘坐巴士至會場所在地Bled。Slovenia為
最早自前南斯拉夫獨立之國家之一，為一純樸之國家。路途中多可見綠色農村景色，
十分怡人。
由 9/7 起即積極參與會議相關活動，9/7 主要參加的是「多標籤分類問題(multi-
labelling classification)」的討論會。多標籤分類問題是近年來機器學習領域的新興熱
門問題，在資訊檢索、影像分析等領域有許多應用。舉例而言，一篇新聞文章，可能
同時是「經濟」、「教育」、「政治」三個類別，而多標籤分類問題，便是探討如何
使機器自動將所有類別都準確地找出來。本次大會中的最佳學生論文，即在探討一個
多標籤分類問題的演算法，可見此問題的重要性。這個討論會以一個概論式的教學做
為開始，為初次接觸此領域的人做了基本的介紹，而伴以數個口頭報告及數個海報報
1
