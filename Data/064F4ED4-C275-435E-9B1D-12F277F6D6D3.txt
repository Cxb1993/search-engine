 1
行政院國家科學委員會專題研究計畫成果報告 
利用粗糙集合理論及基因演算法來解決台語文轉音系統之多音歧異問題 
計畫編號：NSC 98-2221-E-270-002 
執行期限：98 年8 月1 日至99 年7 月31 日 
主持人：林義証 建國科技大學資訊管理系 
計畫共同主持人：余明興 (國立中興大學資訊科學與工程系) 
計畫參與人員：廖盈智 楊文德 吳坤展 吳政彥 
 
摘要 
本計畫提出一個利用粗糙集合理論來預測台語文轉音系統中的一詞多音的
發音，台語中的一詞多音指的是一個詞在不同的場合下會有不同的發音，例如
『他』這個詞有二種發音，分別是代表主格或受格『他』的/yi8/和代表所有格
『他的』的/yin8/。一個台語的文轉音系統必須能正確決定這些詞的發音，以
得到瞭解度高的台語合成語音。在解決一詞多音問題上，我們之前曾提出結合
語言模型和決策樹的組合式策略來預測台語的一詞多音，本計畫則利用了在分
類效果很好的粗糙集合理論來解決台語的一詞多音問題，實驗證明利用改良式
的粗糙集合理論，在預測『上』和『不』的發音有較佳的正確率。 
 
關鍵詞：台語文轉音系統、一詞多音、粗糙集理論、組合式策略 
 3
前言 
近十幾年間，國內在中文的文轉音系統研究上，有許多的研究成果[Bao etc. 
2002; Ma etc. 2003; Chen etc. ISCSLP 2002; Chen etc. ICASSP 2002; Chen 
etc. 1996; Dong & Lua 2002; Lu 2002; Shih & Sproat 1996; Sproat 1998; Wu 
etc. 2007; Yu etc. 2005; 周福強 1997； 魯弘茂 2002]，而一些中文文轉音
的經驗也陸續被應用到台語的文轉音系統上[黃將豪 1996; Yang 1999; 林順傑 
2000；佘永吉 etc. 1999；Lin & Chen 1999; 黃競億 2001 ; 鐘祥睿 2002; 楊
叡承 2003; 黃保章 1999; 傅振宏 2000; 楊鈺清 1999; 何鎮仲 2000]。 
通常一個台語的文轉音系統指的是將輸入之文字轉換成台語語音輸出，由於
目前台語並沒有像中文一樣有正式且統一的文字，所以一般從事台語文轉音系統
的研究大都是將輸入的中文文句轉成台語語音輸出，也就是所謂的中文轉台語語
音合成系統(Chinese to Taiwanese TTS system)。 
如同中文文轉音系統一樣，一個中文轉台語文轉音系統具備了(1) 文句分析
模組、(2) 音的韻律訊息處理模組、和(3) 語音處理及輸出模組等三個重要且基
本的部分。 
在文句分析模組中，一個台語的文轉音系統必須針對輸入的中文文句作分
析，所分析到的中文文句經斷詞後，再依照中文-台語對照詞典來決定每個音節
的發音，並依台語的連音變調方式決定每個音節的正確聲調(本調或是變調)；在
音的韻律訊息處理模組中，則必須決定每個音在發音時的參數，有音調（tone, 
frequency, pitch），音量（volume, intensity, energy），音長（duration），
音與音之間的停頓時間（pause），音與音之間相連音（coarticulation）的程度
等；而在語音處理及輸出模組的部分，則必須依照所給的韻律訊息及語音合成的
基本單位(unit)，將每個音和連音做適當的處理，以得到所需要的台語語音。 
台語文轉音系統的一詞多音問題一直是文句分析的重要工作之一。我們已提出了
語言模型[Lin etc. 2005; Lin etc. 2008]、組合式策略等方法來預測台語的一詞多音
[林義証 等 2008]，也獲得了很好的預測結果。然而使用語言模型會有資料稀疏
的問題，組合式策略則是取語言模型和決策樹的優點來預測台語的一詞多音，組
合式模型對於大部分的詞的一詞多音有很好的效果，但仍有一些詞的一詞多音的
預測結果不甚理想，這當中包含有六種台語發音且常出現在文章中的『不』。本
文將提出以粗糙集合理論為基礎的發法來預測台語的一詞多音，粗糙集合理論已
廣泛被應用在股市預測、醫療預測、工業等方面，具有推導出決策規則的優點[李
昆鴻  2002; 莊宜娟 2005; 張文俊 2005;黃俊霖 2004]。 
1. 研究目的 
在台語文轉音系統中，我們首先必須將中文文句轉換成台語文句。在這
個部份，系統應該要能將正確的斷詞以及每個詞或字正確的台語發音標出
 5
 
圖一、台語文轉音系統之文句處理模組。 
     
這個文句處理模組要能夠將輸入的中文文句轉成具正確標音的台語文句，如
此才能提供完整且正確的台語單音訊息供韻律訊息處理及語音合成模組處理，進
而獲得品質較佳的合成語音。以『我們真希望科學家能發明打下去不會痛的針』
為例，其文句處理的過程及結果如下所示： 
【原始中文文句】 
(Ex1)我們真希望科學家能發明打下去不會痛的針。 
【經過中文文句的斷詞後】 
(Ex2)我們 真 希望 科學家 能 發明 打 下去 不會 痛 的 針。 
【台文語句】 
(Ex3)阮 真 希望 科學家 能夠(ei3-dang3) 發明 注 下去 不
(bhei7) 痛 的 射。 
 
這當中有幾個多音歧異的詞或字，首先是原始文句中的『我們』，這個詞在
台語有二種發音，一種是包含聽者的『咱』，另一種是不包含聽者的『阮』。這類
需要判斷上下文語意的多音歧異，我們稱為語意的多音歧異。 
文句中的另一個多音字為『不』，不同於中文，『不』的台語發音高達六種，
分別是/bhuaih4/、/bhei7/、/bho5/、/m7/、/but4/和/mai7/。類似『不』的多
音現象的詞，在台語為數不少，如『你』、『上』、『下』和『會』等，這一類的多
音歧異現象，我們稱為一詞多音。 
另一類為『詞被分開』，如 Ex1 中的『打』和『針』，如果系統無法分辨文句
中被分開的『打』和『針』是屬於同一個詞，那文句分析系統便無法得到正確的
台語標音結果。 
 
(一) 語意的多音歧異 
 7
bhuaih4 
bho5 
m7 
bhei7 
but4 
不 ㄅㄨˋ 
mai7 
 
(三) 詞被分開 
『詞被分開』指的是我們常常在書寫文章或講話時，會將一個詞的中間置入
一些修飾的文字，如『洗澡』。我們可以很輕易的知道 Ex9 的『洗』和『澡』的
發音分別為/se2/和/sin-khu/，因為我們知道『洗澡』是一個詞且在中文-台語
的雙語辭典中可以查到這個詞對應的發音；然而，從 Ex10 卻較難以給『洗』和
『澡』適當的發音，因為『洗』和『澡』中間隔了許多的字，光靠斷詞和查雙語
辭典是無法獲得正確的發音。 
(Ex9) 我在浴室洗澡。 
(Ex10) 我在浴室洗了一個舒服的澡。 
    類似這樣的詞，在台語也不少，我們在表二中列出了幾個常見的詞。 
表二、一些『詞被分開』的例子 
 
 
在上述的三種多音歧異現象中，以一詞多音問題較普遍，比起中文的多音字
(破音字)，台語有一詞多音的現象有數倍之多。因此，本文主要解決台語一詞多
音的問題，試圖找到其他可行的方法。 
 
3.2 粗糙集合理論 
 
Zdzislaw Pawlak 在早起 1982 提出了粗糙集理論[Pawlak 1982; Pawlak 
2002]，它主要處理含糊性(Vagueness)和不確定性(Uncertainty)問題的數學工
具。近幾年發展快速，對於人工智慧與認知科學是一個重要的方法，特別是機器
學習(machine learning)，決策分析(Decision Analysis)、資料庫知識發掘
 9
粗糙集合理論提出對資訊系統進行屬性因子的縮減(Reduction of 
Attributes)，主要因為於資訊系統中可能包含過多對於樣本分類無益的因子，
因此對於資訊系統的簡化，找到資訊系統中知識的核心(本質)部份是一個必要的
程序。 
假設資訊系統IS = (U,A,D, f ) 中， 若A = {{a1,a2 ,...,an}U{d}} ，
其中{d}為決策屬性因子，則此資訊系統被稱為決策表。我們可由縮減後的決策
表中擷取出描述樣本如何被決策的規則組，其中任一規則的型式則為「if <約簡
後的屬性因子值> then <決策屬性因子值>」。這些規則表達了由原始資料集中
擷取出的知識。對於一個不屬於原資訊系統中的新樣本來說，我們只需比對其對
應的屬性因子值，視其適用於規則組中的哪些特定規則後，即可依據該規則推論
其決策值。 
 
將我們的一詞多音問題對應到粗糙集合理論上時，我們可以視每一筆的訓
練語料為U的一個元素xi，而實驗所使用的屬性則為相鄰詞或相鄰詞性，因此每
一個屬性的值域將會有數萬(詞典之詞數)或近百(標記之詞性數)。而粗糙集合資
訊系統中的決策集合D則為每一個一詞多音的所有發音可能。以『上』這個詞的
資訊系統來說，其決策集合D={d1, d2, d3}，d1代表發音/ding2/，d2代表發音
/jiunn7/，d3則代表發音/siang7/。我們接下來將利用粗糙集合理論提出的計算
步驟，分別針對以詞為屬性特徵和以詞性為屬性特徵來看其預測發音的正確率。 
 
4. 實驗結果 
我們的實驗語料來源是中研院平衡語料庫(ASBC3.0)，ASBC 3.0 中的文句包
含了斷詞的結果，是目前國內公認最完整的中文語料庫。我們擷取了與台語一詞
多音有關的語料；如你、我、他、上、下、不、大等七個台語一詞多音，並透過
人工標音工具，請數名大學生幫忙協助標音工作，將句子中的一詞多音均標示出
正確讀音；實驗語料分成訓練語料及測試語料比例為 9:1。表四為七個實驗之訓
練語料之分布情形。 
表四、訓練語料之分布情形 
詞 台語發音 訓練語料筆數 比例 
/li2/ 1784 87.8%你 /lin2/ 248 12.2%
/ghun2/ 1029 19.85%我 /ghua2/ 4154 80.15%
/yi7/ 3022 87.85%他 /yin7/ 418 2.09%
/bhe7/ 4184 12.02%不 
/bhuaih4/ 1140 3.27%
 11
Dfb ADV Nh N V_2 Vt 
Di ASP SHI Vt   
Dk ADV T T   
FW FW VA Vi   
I T VAC Vt   
NAV NAV VB Vi   
Na N VC Vt   
Nb N VCL Vt   
Nc N VD Vt   
我們利用了粗糙集演算法經過訓練語料訓練後並做外部測試，並且針對以
詞性為特徵去實驗。訓練完後的粗糙及模型會根據訓練語料產生許多的決策規
則，由於一個句子可能同時有數條規則會符合，因此將每條規則所預測的分類投
予一票，採累加制，最後依票數最多的為最終預測結果(若票數一樣則選擇訓練
語料分佈中最多樣本的分類)。 
表六、以詞性為特徵之實驗結果 
詞 台語發音 
測試
語料
筆數 
正確語
料筆數 正確率
總正確
率 
/li2/ 97 199 48.74%你 /lin2/ 15 26 11.56% 49.78% 
/ghun2/ 26 112 23.21%我 /ghua2/ 363 463 78.40% 67.65% 
/yi7/ 260 299 86.96%他 /yin7/ 4 45 8.89% 76.74% 
/bhe7/ 0 479 0.00%
/bhuaih4/ 4 125 3.20%
/bo5/ 1460 1600 91.25%
/but4/ 14 1274 1.10%
/m7/ 0 357 0.00%
不
/mai3/ 0 34 0.00%
38.20% 
/ziunn7/ 2 38 5.26%
/siong7/ 1527 1709 89.35%上
/ding2/ 51 382 13.35%
74.21% 
/au7/ 0 105 29.52%
/e7/ 3 59 1.69%
/ha7/ 442 480 97.50%下
/loh8/ 0 40 0.00%
65.06% 
/dai7/ 0 5 0.00%大 /dua7/ 935 1076 86.90% 98.06% 
表六為以前後各二個詞性為特徵，利用粗糙集合理論所得的實驗結果，我
們發現以詞性為特徵的預測結果並不理想。 
 
 13
0.00%
20.00%
40.00%
60.00%
80.00%
100.00%
你 我 他 上 下 不 大
詞性
詞
 
圖二、不同屬性以粗糙集合理論預測台語一詞多音之比較 
 
4.3 改良式之粗糙集合理論實驗結果 
 
由於 Rough Set Theory 會導出一些規則，在訓練語料中每一條 Rule 的正
確率不見得都是 100%，因此我們計算出每條 rule 在訓練語料的正確率當成該
rule 的 confidence，並以此 confidence 值當成每條 rule 的投票數 ，方法如
下： 
1. 先將粗糙集所得到的 rule list 進行 inside test。 
2. 統計在 inside test 中每條 rule 所使用次數與預測正確的次數，得到每
條 rule 對於訓練語料的正確率。這個正確率即為該 rule 的 confidence。 
3. 在 outside test 時依據步驟(2)所得到的正確率當成票數，在依票數統計
結果，最多者的發音為預測結果(若票數一樣則選擇訓練語料中較多樣本
的分類，以表四的分布來說，『上』的預設發音為/bo5/)。 
 
表八為以相鄰詞性為特徵，利用粗糙集合理論加上前述之 confidence
計算每一條 rule 權重的實驗結果，和表六的結果比較，我們發現給予每一
條 rule 不同的權重，在正確率的提升上是有其效果的。 
 
表八、以詞性為特徵之改良式粗糙集合理論實驗結果 
詞 台語發音
測試
語料
筆數
正確
語料
筆數
正確率 總正確率 
/li2/ 185 199 100.00%你 /lin2/ 8 26 0.00% 88.44% 
/ghun2/ 58 112 0.00% 我 /ghua2/ 447 463 100.00% 80.52% 
/yi7/ 295 299 100.00%他 /yin7/ 6 45 0.00% 86.92% 
/bhe7/ 220 479 4.18% 不 
/bhuaih4/ 16 125 0.00% 
48.51% 
 15
/au7/ 59 105 83.81%
/e7/ 35 59 67.80%
/ha7/ 466 480 91.88%
下 
/loh8/ 15 40 42.50%
85.67%
/dai7/ 0 5 0.00%大 
/dua7/ 1060 1076 99.63%
99.17%
 
5. 實驗比較 
從上一節之實驗結果分析，我們可以發現加上 Confidence 之後，正確
略均有明顯的上升。而詞性不管是否有加上 Confidence 均比詞來的差，這
應該是一詞多音與前後詞的詞性並無太大直接關聯的結果，而且結果雖都有
比 Baseline 好。 
圖三是本文各種方法和組合式策略實驗結果[林義証 2008]比較，對於
某些詞(如『你』、『我』和『他』等)來說，我們發現組合式策略還是有其較
高正確率之處，但以改良式粗糙集合理論的實驗結果來看，其中的『上』與
『不』的正確率為 88.07%與 71.88%，均比組合式策略的 83.88%與 69.29%
來的好。而『大』的部分例子較為特別，因為詞性加上 Confidence 會將全
部預測的結果預測到數量最多的分類去，而『大』的資料內讀音/dai7/只有
五筆遠低於讀音/dua7/，所以正確率才會比詞加上 Confidence 來的高。 
 
 
圖三、各種方法和組合式策略之實驗結果比較 
 
6. 計畫成果自評 
本計畫於當初提案時為一個二年期的計畫，國科會僅核准了一年的計畫，
而當初規劃計畫的第一年是完成利用粗糙集合理論來解決台語的多音歧異問
題，第二年則是希望能透過基因演算法試著利用非監督學習方式找到自動學習分
類，又不需過多人工標助的方法。本計畫使用了粗糙集演算法來解決在 TTS 系統
 17
[14] 楊鈺清， "台語文句翻語音系統之製作",交通大學電信工程系碩士論文， 1999 年， 台灣。 
[15] 楊叡承， "以華台雙語資訊及韻律調整為改進之台語文字轉語音系統"， 長庚大學資訊工程
研究所碩士論文, 2003 年 6 月。 
[16] 魯弘茂，"中文語音合成技術之實作與分析"，交通大學電信工程系碩士論文，2002 年 6 月，
台灣。 
[17] 鍾祥睿， "台語 TTS 系統之改進"， 交通大學電信工程系碩士論文， 2002 年 6 月，台灣。 
[18] H. Bao, A. Wang, and S. Lu, “A Study of Evaluation Method for Synthetic Mandarin Speech”, 
Proceedings of ISCSLP 2002, The Third International Symposium on Chinese Spoken Language 
Processing, pp. 383-386. 
[19] B. F. Chen, G. P. Hu, and R. H. Wang, “Large Lexicon Construction for TTS System”, Proc. 
ISCSLP 2002, pp. 273-276. 
[20] S. H. Chen, S. H. Hwang, and Y. R. Wang, “A Mandarin Text-to-Speech System”, Computational 
Linguistics and Chinese Language Processing, Vol. 1, No. 1, Aug. 1996, pp. 87-100. 
[21] W. Chen, F. Lin, J. Li, and B. Zhang, “Generation of Chinese Prosodic Phrasing Rules by an 
Extension Matrix Algorithm”, Proceedings of IEEE ICASSP 2002.pp. 489-492. 
[22] M. Dong and K. T. Lua, “Prosodic Phrase Detection for Chinese TTS Using CART and Statistical 
Model”, Proceedings of ISCSLP 2002, pp. 291-294. 
[23] Jiawei Han,Micheline Kamber,”Data Mining Concepts and Techniques”, Morgan Kaufmann 
publishers,1999. 
[24] C. J. Lin and H. H. Chen, "A  Mandarin to Taiwanese Min Nan Machine Translation System 
with Speech Synthesis of Taiwanese Min Nan",International Journal of Computational Linguistics 
and Chinese Language Processing, Vo.14, No.1 pp.59-84, 1999. 
[25] Yih-Jeng Lin, Wang-Song Ji, Ming-Shing Yu, and Shang-De Li (2005), “Some Important Issues 
on Text Analysis in a Chinese to Taiwanese TTS Ssystem,” in Proceedings of the 9th IEEE 
International Workshop on Cellular Neural Networks and their Applications (CNNA2005). 
[26] Yih-Jeng Lin, and Ming-Shing Yu (2005), “USING LANGUAGE MODELS TO SOLVE THE 
POLYSEMY PROBLEMS IN A CHINESE TO TAIWANESE TTS SYSTEM — THE CASE OF 
“我們”,” in Proceedings of The 10th Conference of Artificial Intelligence (International Track of 
TAAI 2005). 
[27] Y. J. Lin, M. S. Yu, and C. J. Huang, “The Polysemy Problems, An Important Issue in a Chinese 
to Taiwanese TTS System”, in proceeding of the 2008 International Congress on Image and 
Signal Processing ,P1234, May 28-30, Sanya, China, 2008. 
[28] H. M. Lu, “An Implementation and Analysis of Mandarin Speech Synthesis Technologies”, M. S. 
Thesis, Institute of Communication Engineering, National Chiao-Tung University, June 2002. 
[29] Z. Pawlak, ”Rough Sets”, International Journal of Computer and Information Science,Vol. 11,No. 
5, pp. 341-356,1982. 
[30] Z. Pawlak, ”Rough Sets and Intelligent Data Analysis”, Information Science, Vol. 147, pp.1-12 , 
2002. 
[31] C. Shih and R. Sproat, “Issues in Text-to-Speech Conversion for Mandarin”, Computational 
Linguistics and Chinese Language Processing, Vol., 1, No. 1, Aug. 1996, pp. 37-86. 
[32] R. Sproat, “Multilingual Text-to-Speech Synthesis: The Bell Labs Approach”, Kluwer Academic 
Publishers, 1998. 
[33] C. H. Wu, C. C. Hsia, J. F. Chen, and J. F. Wang, ”Variable-length Unit selection in TTS Using 
Structural Syntactic Cost”, IEEE Transactions On Audio, Speech, And Language Processing, Vol. 
15, No.4, pp. 1227-1235, May 2007. 
[34] X. Ma, W. Zhang, Q. Shi, W. Zhu, and L. Shen, ”Automatic Prosody Labeling Using Both Text 
and Acoustic Information”, Proc.IEEE ICASSP 2003, pp.I516-I519. 
[35] Y. C. Yang, "An Implementation of Taiwanese Text-to-Speech System", Master thesis, 
Department of Communication Engineering, National Chiao Tung University, 1999. 
[36] M. S. Yu, T. Y. Chang, T. H. Hsu, and Y. H. Tseng, "A Mandarin Text-to-Speech System Using 
Prosodic Hierarchy and a Large Number of Words", Proc. 17th Conference on Computational 
Linguistics and Speech Processing, (ROCLING XVII), pp. 183-202, Sep. 15-16, 2005, Tainan, 
無研發成果推廣資料 
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
