行政院國家科學委員會專題研究計畫成果報告 
智慧型嬰幼兒監護與安撫晶片系統─子計畫一：低功率智慧型嬰幼兒監護視訊處理系統設
計  
Low Power Intelligent H.264/AVC Region-of-Interest Video Coding System 
計畫編號：NSC 97-2221-E-005-094-MY2 
執行期限：97年 9月 1日至 100年 1月 31日 
計畫主持人：賴永康 副教授    國立中興大學電機工程學系 
一、 中文摘要 
H.264/AVC是目前最新穎的視訊標準，然而其運算以及運
算複雜度遠超過傳統常見的視訊編解碼演算法。根據研究
文獻的分析，實現高效能低功率之 H.264/AVC視訊編碼系
統目前仍有許多高難度之設計挑戰。在本計劃中，我們利
用從系統層至電路架構層提出不同的低功率演算法以及
相關電路架構設計，設計了一低功率以及具功率感知之
H.264/AVC編碼系統。於系統層級設計，我們提出一混合
型三級MB區塊管線資料排程改善傳統四級MB區塊資料
排程之缺點。於演算法層，我們針對運算量最大的幀間畫
面預測提出了三個快速演算法分別為二階段漸進式快速
移動估計演算法、幀間模式預先決策技術、以及幀間運算
提早中止技術，有效率的降低整體幀間畫面預測的運算。
於電路架構層，我們針對我們提出之二階段漸進式快速移
動估計演算法設計相應之硬體架構，硬體實作顯示，當我
們利用 TSMC 0.18µm 1P6M CMOS製程，整數動態估計電
路架構僅止需約 100K之邏輯閘，於 60MHz的工作頻率下
即可以 190mW的功耗完成 HDTV720p之即時視訊壓縮。
此外，我們也針對幀內畫面編碼器，提出一有效率之多視
訊標準轉換電路解決當今對於幀內畫面模式決策必須仰
賴 SAITD模型之缺點。根據實驗結果顯示，我們提出的演
算法與架構可實現低功率與具功率感知之 H.264/AVC 編
碼器。此外，使用一個名為 built-in object tracking的方法，
讓 object tracking的運算，內建至 motion estimation內部，
當 MV計算出來時，能同時做 object tracking，如此一來便
可應用於嬰幼兒監護視訊處理系統。 
英文摘要 
In this project, a low-power and power-aware H.264/AVC 
encoder system is proposed based on proposed different low 
power algorithms from system level to architecture. For 
system level, we propose a hybrid scheduling 3-stage MB 
pipeline scheme to shorten the latency of the intra frame 
coding engine. For algorithm level, three fast algorithms for 
inter prediction are proposed. Our fast inter prediction 
algorithms consist of coarse-to-fine fast integer motion 
estimation algorithm, early termination mechanism of ME 
operation, and inter mode pre-decision scheme to efficiently 
reduce the computation of the inter prediction in H.264/AVC. 
In the light of our coarse-to-fine fast algorithm, we propose a 
parallel architecture to efficiently perform our fast algorithm 
with the parallel PE array, intelligent memory configuration 
and memory interleaving techniques. According to our chip 
implementation, the total gate count of our IME architecture 
is about 98K NAND2 gates. Our architecture can perform 
HDTV720p@30fps video coding with 60-MHz working 
frequency, and the power consumption is about 59-mW. 
Moreover, we also propose a H.264/AVC intra frame coder 
with SATD model to guarantee the RD performance of our 
intra frame coder as the same as JM reference code.Moreover, 
using the method called built-in object tracking. When the 
MV calculated, they can also do object tracking. In other 
words, it can be applied in video-based surveillance system of 
the baby care.  
二、 緣由與目的 
H.264/AVC此新興的視訊標準是目前具有最好的 R-D
表現曲線的視訊標準。根據圖一中 H.264編碼器之即時運
算量分析，在 CIF的視訊規格之下，H.264/AVC編碼已需
205 GIPS之運算量以及 400 GB/sec之記憶體存取次數。若
於 HDTV 視訊規格下，根據文獻[1]之研究，H.264/AVC
編碼需要高達 3600 GIPS之運算量以及 5570 GB/sec之記
憶體存取次數。因此低功率高效能之 H.264/AVC編碼硬體
架構成了即時視訊系統最大的挑戰。 
傳統對於視訊編碼器電路架構設計，典型的系統設計
概念是採用二級 Macroblock（MB）管線式架構。整個編
碼流程可劃分為 ME 以及 BE，將兩個 MB同時在 ME 以
及 BE中執行運算任務，在時間軸上以及 MB為階層完成
管線化編碼流程提高電路之編碼效率。然而，由於
H.264/AVC 其超高複雜之運算量以及新加入之編碼工具
造成編碼過程具有許多循序運算以及資料相依性，導致傳
統二級MB管線式架構無法有效率之應用於H.264/AVC編
碼系統上。 
為了解決傳統二級MB管線式架構無法有效率的解決
H.264/AVC於上述所遭遇之各種視訊編碼設計挑戰。Chen 
[2][3]等人提出了四級 MB 管線式架構有效率的將 IME、
FME、IP、EC＆DB 等五個主要核心電路透過資料排程利
用四級 MB管線完成視訊編碼過程。此四級 MB管線之概
念不但應用於全球第一顆 HDTV 720p編碼器上[3][4]，同
時也廣泛的被其他重要的編碼器架構所採用[5]。 
此外，根據根據 H.264/AVC編碼器的功率分佈，Chen 
[6]等人顯示幀間預測包含整數點移動估計運算以及小數
點精準度移動估計運算佔據了整體編碼器的功率消耗超
過 70%。除了利用快速的 IME以及 FME演算法降低運算
Integer ME
59.9%Fractional ME32%
IntraStage
(prediction,DCT,Q,IQ,IDCT)
3.9%
Others(Deblocking,MC..)
0.8%
Mode Decision
1.2%Interpolation
2.2%
 
Analyzing Tools：Intel Vtune Performance Analyzer
Platform：Intel C2D 1.66GHz
Software：JM12.2 baseline profile
SR：32
FPS：30
Iperiod：30
Ref. Numbrer：1
Sequence：foreman
Sequence size：CIF (352x288) , 300frames
Total Instructions：205220.5MIPS
Total Memory Access：400GB/s
 
Fig. 1. Runtime profiling of functional blocks in H.264 baseline encoder 
數為 30 時提升到 60.998％，這種大幅的改變導因於區塊
內較複雜的資訊（如衣服紋理，遠處的行人）被大量捨去，
造成大部分區塊很容易被視為背景區塊，且另一個原因在
於 Lagrangian成本計算方程式中的編碼成本（Rate），會隨
著量化參數而增加，造成基本區塊更不易分割成細小的區
塊（因為區塊分割的越小越會增加編碼成本），因此越容
易選擇到省略模式編碼。 
然而，一些提出硬體導向的演算法是基於快速省略模
式偵測演算法來做提早中斷移動估算[23][24][25][26]。不
過，這些是取決於固定的門檻值[24] 或者是經由大量的模
擬數據算得到的經驗值[23][25][26]。本論文提出一個提早
中斷機制能在完成 IME 過程前有效地偵測到同質性和靜
止的基本區塊。主要是鑑於理論模型，用一個數學的方法
來決定是否提早中斷移動估測運算的門檻值。利用運動補
償誤差數據的機率分佈建立一個基於 Generalized Gaussian 
distribution (GGD)的混合模型，可計算出針對不同情況而
調整我們所提出之提早中斷機制的門檻值。 
由於省略模式會被大量使用，而且移動向量大多數會
是 MVP與（0,0）點，因此我們利用原先省略模式的四個
條件（移動向量為 MVP）為一組門檻，加上移動向量為
（0,0）點這個條件與其餘三個條件為一組，總共兩組門檻
條件預先在作幀間編碼前便先檢查，若符合我們的條件便
可以直接終止掉幀間編碼的運算，直接作幀內運算
（transform、quantization、entropy）以及省略模式的檢查。 
首先我們由文獻 [27][28]知道對畫面補償誤差
（Residue）作統計後，發現曲線可用 Zero-Mean之 General 
Gaussian Distribution機率模型近似，而機率密度函數通式
如下， 
( ) ( ) R ,exp,; ∈⋅= xbx-axp αασ   (1) 
 
( )
( )
( )α
α
σ
α 3
1  ;112
1
Γ
Γ=
+Γ
= b
b
a     (2) 
上式α為形變參數（shape parameter），其中 General 
Gaussian Distribution 會因為不同的α得到不同的機率分佈
曲線，如α=2時為 Normal Distribution（簡稱 ND）以及α=1
時則為 Laplacian Distribution（簡稱 LPD），而前述提到的
文獻[33]便是使用 Laplacian Distribution 這單一模型作為
AZDB的參考模型，但我們由文獻[27][28]知道補償誤差並
不能由任何單一的模型作近似，因此接下來我們為了證明
在 H.264編碼中的 Residue是否會近似於 General Gaussian 
Distribution，我們使用了上述的 ND與 LPD來模擬之外，
另外增加了α＝1.5 的機率分佈模型（簡稱 GGD）以得到
更精準的分析 
於電路架構層次方面，我們利用我們所提出之二階段 
漸進式快速移動估計演算法實作一低功率且支援高解析
度畫質之移動估計電路。為了能夠完美的執行整個快速演
算法，我們利用有效率的記憶體組織以及記憶體插補技術
達到有效率的記憶體存取，同時針對演算法設計最佳化的 
資料排程並利用平行化技術，讓整體電路使用率達到
100%。 
圖三(a)為我們所提出之快速幀間預測技術之處理流
程圖，整個流程包含了幀間預測提早中止機制以及幀間模
式預先決策技術。當整個幀間預測程序開始啟動的時候，
幀間預測提早中止機制會最先被執行。當幀間預測提早中
止檢查結果為未通過，則會如同一般傳統的 IME以及 FME
運算編碼流程完成幀間預測程序；若是幀間預測提早中止
檢查結果為通過，整個幀間預測程序包含 IME與 FME的
運算將會提早被終止，而移動向量將會被設定在搜尋區域
的中心點或是 MVP，而動態補償後之冗餘殘值畫面像素將
會被送至幀內畫面編碼器。此外，AZC旗標也會用於幀內
畫面編碼器決定整個動態補償後之冗餘殘值畫面像素編
碼程序。當 AZC 旗標致能的時候，動態補償後之冗餘殘
值畫面像素將強制設定其轉換且量化後之係數值為零，如
此可以進一步中止轉換運算以及量化運算達到低功率的
需求。 
整個完整的幀間預測提早中止機制流程圖如圖三(b)
所示。由於 H.264/AVC採用的是 4×4整數轉換，因此 MB
區塊將會被切割為十六個 4×4區塊，然後比對此十六個區
塊各別之 SAD 數值是否都比門檻值還低。若十六個區塊
中有任何一個區塊之 SAD 數值超過門檻值，則整個預測
提早中止機制將中止跳離回歸正常的幀間預測編碼程序
以確保每個 4×4區塊其轉換且量化後之係數值為零。 
經過提早模式選擇會決定出一種切割模式，與計算出
的移動向量。由於管線架構，當整數點移動估算計算完，
會將所使用的移動向量預測點傳送給高精準度移動估算
器使用，整數點移動估算器存下的方塊切割模式與移動向
量以接線方式連接至高精準度移動估算器，並作讀寫控制
將所需資料存至緩衝記憶體中，與 FME 溝通介面如圖五
所示。同時，Current enable和 Reference enable會舉起來，
分別代表所需的 current 和 reference 資料開始送出。圖五
表示 FME的區塊圖。 
效能分析 
我們將演算法加入 JM12.2 的原始碼中，以 1 張參考
畫面、搜尋範圍為-32到+32、30FPS、I-period為 30的設
定之下，以各種 CIF影像來模擬不同類型的畫面下我們演
算法的效果，經過模擬後，我們的演算法最多掉 0.2dB
（Mobile），平均掉約 0.1dB，而編碼位元率最大增加 5%。
在畫面變動較低的影像，我們的 R/D 曲線會幾乎貼近於
Checking 
start
4x4 SAD
SAD<TH
All 4x4 blks are 
processed?
Early Termination 
Pass
Early Termination 
Fail
 
         (a)                       (b)  
Fig. 3. (a) Proposed fast inter prediction algorithm with early 
termination scheme and inter mode pre-decision. (b) The detail 
decision flow of proposed early termination scheme.  
 
 
Fig. 4. IME&FME block diagram 
ET_valid
Inter_bmode
Inter_minmcost
MVPint
MVint (1~16)
Cur_mem_wen
Cur_mem_wdata
Ref_mem_wen
Ref_mem_wdata
Current MB
Mem.
Reference Pel.
Mem.
Interpolation Unit
PU Array
4 4 blk
PU
4 4 blk
PU
4 4 blk
PU4 4 blk
PU
4 4 blk
PU4 4 blk
PU
4 4 blk
PU
4 4 blk
PU
 Fig. 5. FME block diagram 
送所需資料，其他區塊大小則因 data reuse 需較少時脈週
期傳送，如 current memory每次傳送一個 memory module 
8x2個 pixel的資料，傳完需花費 16個時脈週期。資料傳 
完後，則開始作高精準度移動估算運算，整數點移動估算
也開始計算下個基本區塊。 
圖十二(a)顯示當我們定義motion vector的箭頭方向為
被參考畫面至現有畫面時，箭頭的起點即為被參考畫面。
我們給予此不為零的 motion vector 之起點為 Br，也就是
reference block。箭頭的終點為現有畫面，我們給予此不為
零的 motion vector之終點為 Bc，也就是 current block。圖
十二 (b)則顯示不移動物件是使用在對抗雜訊造成的
motion vector 暫時消失，因為經過 I-Frame而造成的motion 
vector 消失等情況。當一個物件從移動變成不移動時，在
開始停止的畫面會具有上一張的motion vector及消失的下
一張 motion vector。因此該位置對應之 motion vector所指
位置為 Bm，也就是 moving block。而現有畫面的位置為
Bc，也就是 current block。因此我們從下一張把對應的 block
標示為不移動物件，也就是 unmoving block。不移動物件
隨時間遞減其明亮度，在一定時間後繼續不移動則消失，
或是再移動。其後我們改進 modification of vector-featured 
regions的方法，把原本修正不適當 unmoving block的方法
由回頭修正 k frames改為取消 unmoving block clock方式。
將 使 用 minimum bounding rectangular 方 式 改 為
block-based。並且改進原本無法應付背景雜訊的部分，使
用濾波器來增強其性能。 
圖十三為 Build-in object tracking 流程圖，首先讀入
H.264 的 motion estimation 計算結果的 modes 及 motion 
vectors。將計算出來的 motion vector經過 median filter及
Gaussian filter 濾除雜訊部分。其後把 motion vector分為其
起始點及終點兩部分計算。起始點的部分也就是被參考的
部分，可以得到 reference block的所在位置。終點的部分
也就是現有畫面的部分，可以得到 current block的位置。
而 reference block及 current block重疊部分，就是代表前
後都有非零的 motion vector。因此這個區域判斷為 moving 
block。而前面為 moving block，後面為 current block 代表
該 block後面的 motion vector為零靜止，判斷為 unmoving 
block。 
其中所謂的每一張畫面的 motion vector，是指該畫面
為 motion vector終點。因此需要 motion vector為起點的部
分，就是下一張畫面的 motion vector。所以圖中的起點的 
部分，產生會比終點的部分晚一張畫面的順序。因此終點
部分產生的 bc必須被保存到下一張畫面 motion vector進
入時，在 Br得以被產生後，同時決定 Bm的產生。這也就
是為什麼 Bm 順序放在 Bc 前面的關鍵原因。而不是直觀
的 Bc、Br、Bm 順序。同樣的 Bu 產生條件為上一張為 Bm，
下一張為 Bc 圖五流程圖的順序剛好滿足這項需求，於是
在 Bc決定的同時可以決定 Bu的所在位置。最後利用 Bm、
Bu的結果進行 Object Tracking。這麼一來就可以把物件順
利的追蹤出來。上述的運算利用 motion estimation的結果
motion vector去處理，就可以得到我們想要的結果。圖十
五為利用此演算法之物件追蹤結果。 
圖十四為我們提出之二階段漸進式快速演算法流程
圖。第一階段要考慮的參數有三個，分別為 MSEA 中的
level 值（level 為 3 或 4）、區塊取樣率（四個候選者區塊
選一，或十六個候選者區塊選一）與留下的最小候選者區
 
         (a)                           (b) 
Fig. 12. (a) Region Definition for Moving Object Detection. (b) 
Region Definition for Unmoving Object Detection. 
 
Terminal Point of MV Generation
Current Blocks (Bc)
Unmoving Blocks (Bu)
Fetch modes & motion vectors
Median filter
Gaussian filter
Initial Point of MV Generation
Reference Blocks (Br)
Moving Blocks (Bm)
Tracking Decision
 
Fig. 13. Flow chart of the proposed buid-in object tracking algorithm 
 
S = 4、16M = 12 ~ 20、2 ~ 6
p = 1、2
Level = 3、4 
   
Fig.14. Flow chart of the proposed coarse-to-fine fast algorithm  
 
TABLE I 
RD PERFORMANCE COMPARISON BETWEEN PROPOSED FAST INTER PREDICTION AND JM12.2 REFERENCE SOFTWARE CODE 
QP 
JM12.2 PreMD PreMD + Early Termination HQ (n=3) LP L1 (n=2) LP L2 (n=1.5) UltraLP (n=1) 
PSNR Bitrate (kb/sec) PSNR bitrate PSNR (bitrate S% (PSNR (bitrate S% (PSNR (bitrate S% (PSNR (bitrate S% 
24 38.473 2524.511 -0.135 5.01% -0.077 5.06% 4.05% -0.099 5.33% 12.22% -0.084 5.23% 8.70% -0.123 5.56% 15.47% 
26 36.924 1946.288 -0.149 4.97% -0.068 4.85% 1.35% -0.071 5.09% 7.22% -0.085 5.22% 12.77% -0.128 5.84% 17.24% 
28 35.413 1487.963 -0.143 5.08% -0.064 4.97% 3.18% -0.072 5.25% 10.67% -0.086 5.34% 14.42% -0.134 6.18% 18.18% 
30 33.728 1087.315 -0.121 5.26% -0.067 5.20% 5.58% -0.076 5.52% 12.82% -0.089 5.80% 15.61% -0.139 6.92% 18.92% 
32 32.182 794.886 -0.130 5.31% -0.082 5.74% 9.88% -0.096 5.98% 14.87% -0.117 6.39% 16.99% -0.157 7.65% 19.55% 
34 30.783 592.476 -0.136 5.54% -0.098 6.25% 12.09% -0.109 6.68% 15.86% -0.129 7.23% 17.88% -0.182 9.44% 20.94% 
36 29.279 438.35 -0.144 5.20% -0.101 6.29% 13.06% -0.118 6.80% 16.28% -0.136 7.54% 18.16% -0.208 11.45% 22.77% 
 
用了三十六個記憶體模組，分別為四個目前區塊記憶體模
組與 32個搜尋區域記憶體模組，達到平行存取的功能。 
由於前端 IME為 raster scan計算，故本 FME亦為水
平掃描運算，圖十八為高精準度移動估算插補單元架構，
假設當一個 4x4的區塊作插補時，會需要 10x10的參考資
料，而資料處理的流程如下：在第一個週期先進來左邊垂
直第一排資料經過插補單元存到垂直半點的暫存器（圓形
暫存器），並且暫存器之後每個週期並跟著新進來插補的
資料而水平往後推，當參考像素填滿垂直的暫存器後，跟
著啟動水平插補的 6-tap filter 存到水平半點的暫存器
（中間排三角形暫存器），而下一個週期在推至右邊排三
角形暫存器，而這時黑色框框就為處理單元（PU）所需要
計算的參考資料輸入。 
圖十九為在計算 reference pixel 與 current pixel
相減給 1D Hadamard轉換，傳至暫存器陣列存起來，經過
4 個時脈週期依序往下推滿 16 個後，在轉置方向給 1D 
Hadamard 轉換，最後把 16 個轉換後的值做相減絕對值累
加可得到 SATD，接下來根據不同的切割模式去把所需要
4x4 的 SATD 累加起來當作那個切割區塊大小的 SATD，當
半點的八個 SATD與中間點傳進來的 SATD取出最小找到最
相近的半點時，丟回 FME在繞一圈做四分之一點的運算，
這時會使用到雙線性濾波器（bilinear filter）插補出
四分之一點，運算最後會得到四分之一點的 MV和 SATD加
上編碼成本（rate cost）。 
圖二十為 buid-in object tracking的硬體架構方塊圖，
我們使用的 Median Filter在 9個輸入的大小排列中只需要
19 個加法運算取代傳統泡沫排序法所需要的 30 個加法運
算。Gauss Filter 是用來消除雜訊，Address & Condition 
Calculator和 BG分別計算所有的地址&條件和其相對應的
區塊(Block)。BP 是用來更新 unmoving block的背景，它
需要 unmoving block (bu) 和 moving block (bm)的資訊。TD
是用來決定前景和追蹤的旗標，此電路分為兩個 Stage，並
且在每個功能方塊圖前都使用 Pipeline技術以縮減 critical 
path。 
在 H.264/AVC IME的架構中，因整體電路的運算周期
數敘述如下：於第一階段，若搜尋範圍為-p ~ p - 1，則此
階段處理候選者所需要的時脈週期數為（p / 4）+ 2 +（p / 
2），便可以得到 M 個具有最小 MSEA 值之候選者區塊；
於第二階段，當處理 M個候選者區塊，而其小範圍全域搜
尋範圍為為-l ~ l - 1，所需要花費的時間為 9 × 2 × l2 × M個
時脈週期數，整體架構所需要的時脈週期數為（p / 4）+ 2 
+（p / 2）+ 9 × 2 × l2 × M個時脈週期。 
最後，在 H.264/AVC IME電路晶片實作上採用 Artisan
的標準單元庫以及 TSMC 0.18um 1P6M製程實作，晶片實
作結果，在節省面積和提升運算速度的綜合表現為全搜尋
架構之二十倍，表示整個晶片所使用的輸入與輸出腳位，
驗 證 的 方 式 是 從 JM 參 考 原 始 碼 中 的
SubPelBlockMotionSearch()這個函式裡產生我們所需要的
測試向量，透過 testbench 輸入到我們設計的架構中，而產
生出來的mcost與移動向量再送回 testbench與測試向量作
比對；電路規格上我們工作頻率設定在 62.5MHz，這是我
們以後在系統上的考量。完成符合我們演算法的硬體描述
語言（Verilog Code）之後我們緊接著會使用 Debussy nLint
來檢查我們的程式碼，檢查項目有 Naming Convention、
Coding Style、Synthesis、Static Timing Analysis、Design For 
Test、Design Style 等，在符合所有規定下我們再使用
transEDA 的 Vanvigator 來驗證程式碼之涵蓋率（code 
coverage），接下來再使用 TSMC 0.18um 1P6M的製程來作
進一步的邏輯合成，透過 Synopsys design compiler 的使
用，將程式碼從 RTL Level轉換成 GATE Level，最後再使
用 Cadence SOC Encounter作最後的 Place&Route的工作，
最後再作 Post Simulation、Prime Power等得到電路功率消
耗以及是否符合我們所定的規格 
圖二十一以及表 II為實作晶片照像圖與晶片規格。此
晶片於 60 MHz 的工作頻率下，可處理 HDTV720p 的畫
面，消耗功率為 194 mW，晶片面積為 3.77×3.46 mm2。而
在 build-in object tracking的部份則採用 CIC的 UMC 90nm 
1P9M製程實作，其運算速度可操作於 100MHz，其消耗功
率為 132 mW，晶片面積為 2.003×2.003 mm2。圖二十二及
表 III為其晶片 Layout圖與晶片規格。 
圖二十三為 62.5 MHz的工作頻率進行合成，各module
所佔面積的百分比可由圖中得知，其中所佔的最大部分為
memory，IME current block memory佔了 9%的面積，IME 
search area memory佔 41%的面積，，FME current block 
memory佔了 2%的面積，FME search area memory佔 9%的
面積，而 IME除了記憶體以外的計算單元與控制電路，所
佔的面積為 23%，FME除了記憶體以外的計算單元與控制
電路，所佔的面積為 16%。由圖中可以看出共使用了 36
個 memories，分別是 4個 current block memory modules與
32個 search area memory modules，分布於 chip 周圍。其餘
的 cell則是由 SOC Encounter 擺放在中間適當的位置，此
chip 的工作頻率為 60 MHz，power consumption 為 33.76
到 61.57 mW，其餘詳細的 power consumption參考表 IV和
表 V 。IME和 FME其功率消耗參考圖二十四和二十五。 
 
Fig. 21. Chip microphotograph of the proposed H.264/AVC variable 
block size IME architecture. 
 
 
Fig.22 Chip Implementation of the proposed built-in object tracking 
architecture 
 
 
Fig. 20. Overall block diagram of the proposed build-in object 
tracking architecture.  
 
of an HDTV720p 30 frames/s H.264/AVC encoder,” IEEE 
Trans. Circuits Syst. Video Technol., vol. 16, no. 6, pp. 673-688, 
June 2006. 
[2] T.-C. Chen, Y.-W. Huang, and L.-G. Chen, “Analysis and design 
of macroblock pipelining for H.264/AVC VLSI architecture,” in 
Proc. IEEE Int. Symp. Circuits Syst., pp. II-273 - II-276, May 
2004. 
[3] T.-C. Chen, S.-Y. Chien, Y.-W. Huang, C.-H. Tsai, C.-Y. Chen, 
T.-W. Chen, and L.-G. Chen, “Analysis and architecture design 
of and HDTV720p 30 frames/s H.264/AVC encoder,” IEEE 
Trans. Circuits Syst. Video Technol., vol. 16, no. 6, pp. 673-688, 
June 2006. 
[4] Y.-W. Huang, T.-C. Chen, C.-H. Tsai, C.-Y. Chen, T.-W. Chen, 
C.-S Chen, C.-F. Shen, S.-Y. Ma, T.-C. Wang, B.-Y. Hsieh, H.-C. 
Fang, and L.-G. Chen, “A 1.3TOPS H.264/AVC single chip 
encoder for HDTV applications,” in ISSCC Dig. Tech. Papers, 
Feb. 2005. 
[5] H.-C. Chang, J.-W. Chen, C.-L. Su, Y.-C. Yang, Y. Li, C.-H. 
Chang, Z.-M. Chen, W.-S. Yang, C.-C. Lin, C.-W. Chen, J.-S. 
Wang, and J.-I. Quo, “A 7mW-to-183mW dynamic 
quality-scalable H.264 video encoder chip,” ISSCC Dig. Tech. 
Papers, Feb. 2007. 
[6] Y.-H. Chen, T.-C. Chen, and L.-G. Chen, “Power-scalable 
algorithm and reconfigurable macro-block pipeline architecture 
of H.264 encoder for mobile application,” in Proc. IEEE Int. 
Conf. Multimedia and Expo, pp. 281-284, July 2006. 
[7] Z. Zhou, M.-T. Sun, and Y.-F. Hsu, “Fast variable block-size 
motion estimation algorithm based on merge and split 
procedures for H.264/MPEG-4 AVC,”in Proc. IEEE Symp. 
Circuits Syst., vol. 3, pp. III-725-8, May 2004. 
[8] D. Wu, F. Pan, K. P. Lim, K. P. Lim, S. Wu, Z. G. Li, S. 
Rahardja, and C. C. Kuo, “Fast intermode decision in 
H.264/AVC video coding,”IEEE Trans. Circuits Syst. Video 
Technol., vol. 15, no. 3, pp. 378-401, March 2005. 
[9] T.-C. Chen, Y.-H. Chen, C.-Y. Tsai, and L.-G. Chen, “Low 
power and power aware fractional motion estimation of 
H.264/AVC for mobile applications,” in Proc. IEEE Symp. 
Circuits Syst., pp. 5531-5334, May 2006. 
[10] C.-L. Su, W.-S. Wang, Y.-L. Chen, Y. Li, C.-W. Chen, J.-I. Guo, 
S.-Y. Tseng, “Low complexity high quality fractional motion 
estimation algorithm and architecture design for H.264/AVC,” 
in Proc. IEEE Asia-Pacific Conf. Circuits Syst., pp. 678-581, 
Dec. 2006. 
[11] Y.-K. Lin, C.-C. Lin, T.-Y. Guo, T.-S. Chang, “A 
hardware-efficient H.264/AVC motion estimation design for 
high definiation video,” IEEE Trans. Circuits Syst. I: Reg. 
Papers, vol. 55, no. 6, pp. 1126-1135, July 2008. 
[12] D. Wu, F. Pan, K. P. Lim, S. Wu, Z. G. Li, X. Lin, S. Rahardja, 
and C. C. Ko, “Fast intermode decision in H.264/AVC video 
coding,“ IEEE Trans. Circuits Syst. Video Technol., vol. 15, no. 
7, pp. 953-958, July 2005. 
[13] C. S. Kannangara, I. E. G. Richardson, M. Bystrom, J. R. Solera, 
Y. Zhao, A. MacLennan, and R. Cooney, “Low-complexity skip 
prediction for H.264 through Lagrangian cost estimation,” IEEE 
Trans. Circuits Syst. Video Technol., vol. 16, no. 2, pp. 202-208, 
Feb. 2006. 
[14] C.-C. Lin, Y.-K.Lin, and T.-S. Chang, “Hardware efficient skip 
mode detection for H.264/AVC,” in Proc. IEEE Int. Conf. 
Consum. Electron., pp. 1-6, March 2008. 
[15] I.-M. Pao and M.-T. Sun, “Modeling DCT coefficients for fast 
video encoding,” IEEE Trans. Circuits Syst. Video Technol., vol. 
9, no. 4, pp. 608-616, June 1999 
[16] H. Wang, and S. Kwong, “Hybrid model to detect zero 
quantized DCT coefficients in H.264,” IEEE Trans. Multimedia, 
vol. 9, no. 4, pp. 728-735, June 2007. 
[17] Y.-W Huang, B.-Y. Hsieh, S.-Y. Chien, S.-Y. Ma, and L.-G. 
Chen, “Analysis and complexity reduction of multiple reference 
frames motion estimation in H.264/AVC,” IEEE Trans. Circuits 
Syst. Video Technol., vol. 16, no. 4, pp. 507-522, April 2006. 
[18] T.-C. Chen, S.-Y. Chien, Y.-W. Huang, C.-H. Tsai, C.-Y. Chen, 
T.-W. Chen, and L.-G. Chen, “Analysis and architecture design 
of and HDTV720p 30 frames/s H.264/AVC encoder,” IEEE 
Trans. Circuits Syst. Video Technol., vol. 16, no. 6, pp. 673-688, 
June 2006. 
[19] TIAN Gang, HU Rui-Min, WANG Zhong-Yuan, ZHU Li. 
“Object Tracking Algorithm Based on Meanshift Algorithm 
Combining with Motion Vector analysis,” First International 
Workshop on Education Technology and Computer Science. pp 
987 - 990. 2009. 
[20] Takanori Yokoyama, Toshiki Iwasaki, and Toshinori Watanabe, 
“Motion Vector Based Moving Object Detection and Tracking 
in the MPEG Compressed Domain,” Seventh International 
Workshop on Content-Based Multimedia Indexing. pp 201 - 206. 
2009. 
[21] Azzam Sleit, Imad Salah, and Rahmeh Jabay, “Approximating 
Images Using Minimum Bounding Rectangles,” Proceedings of 
IEEE Conference of Applications of Digital Information and 
Web Technologies (ICADIWT), pp.394-396, 2008. 
[22] Mansour A Al Zuair, and Bandar Al Rashed, “Tracking Using 
Motion Estimation,” IEEE Proceedings of the International 
Conference on Computer and Communication Engineering, 
pp.393-395, 2008. 
[23] Y.-H. Chen, T.-C. Chen, and L.-G. Chen, “Power-scalable 
algorithm and reconfigurable macro-block pipeline architecture 
of H.264 encoder for mobile application,” in Proc. IEEE Int. 
Conf. Multimedia and Expo, pp. 281-284, July 2006. 
[24] D. Wu, F. Pan, K. P. Lim, S. Wu, Z. G. Li, X. Lin, S. Rahardja, 
and C. C. Ko, “Fast intermode decision in H.264/AVC video 
coding,“ IEEE Trans. Circuits Syst. Video Technol., vol. 15, no. 
7, pp. 953-958, July 2005. 
[25] C. S. Kannangara, I. E. G. Richardson, M. Bystrom, J. R. Solera, 
Y. Zhao, A. MacLennan, and R. Cooney, “Low-complexity skip 
prediction for H.264 through Lagrangian cost estimation,” IEEE 
Trans. Circuits Syst. Video Technol., vol. 16, no. 2, pp. 202-208, 
Feb. 2006. 
[26] C.-C. Lin, Y.-K.Lin, and T.-S. Chang, “Hardware efficient skip 
mode detection for H.264/AVC,” in Proc. IEEE Int. Conf. 
Consum. Electron., pp. 1-6, March 2008. 
[27] Lam E.Y., Goodman. J.W., “A mathematical analysis of the 
DCT coefficient distributions for images,” in IEEE 
Transactions on Image Processing, vol. 9, no. 10, pp. 1661 – 
1666. 
[28] Lam E.Y., “Analysis of the DCT coefficient Distributions for 
Document Coding,” in IEEE Signal Processing Letters, vol. 11, 
no. 2, part 1, pp. 97 –100. 
[29] K. Kumagai, C. Yang, H. Izumino, N. Narita, K.Shinjo, S. 
Iwashita, Y. Nakaoka, T. Kawamura, H. Komabashili, T. Minato, 
K. Ambo, T. Suzuki, Z. Liu, Y. Song, S. Goto, T. Ikenaka, Y. 
Mabushi, and K. Yoshida, “System-in-silicon architecture and 
its application to H.264/AVC motion estimation 
for1080HDTV,” ISSCC Dig. Tech. Papers, pp. 1706-1715, Feb. 
2006. 
[30] K. Mizuno, J. Miyakoshi, Y. Murachi, M. Hamamoto, T. Iinuma, 
T. Iishihara, F. Yin, J. Lee, H. Kawaguchi, and M. Yoshimoto, 
“An H.264/AVC MP@L4.1 quarter-pel motion estimation 
processor VLSI for real-time MBAFF encoding,” in Proc. IEEE 
Int. Conf. Electron. Circuits Syst., pp. 1179-1182, Aug. 2008. 
[31] Y. Kim, Y. Choe, Y. Choi, “Fast mode decision algorithm for 
H.264 using AZCB prediction,” in International Conference on 
Consumer Electronics(ICCE’06), pp. 33 – 34. 
[32] L. Shen, Z. Liu, Z. Zhang, G. Wang, “A novel algorithm to fast 
mode decision with consideration about video texture in 
H.264,” in IEEE/ACS International Computer Systems and 
Applications (AICCSA’07), 2007, pp. 684 – 687. 
[33] C.-Y. Cho, N.S.-Y. Huang, J.-S. Wang, “Design of 
Computation-Aware Mode Decision Scheme for H.264/AVC,” 
in IEEE International Conference on Acoustics, Speech and 
Signal Processing (ICASSP’06), 2006, vol.2. 
[34] C. Kim, C.-C. J. Kuo, “Feature-Based Intra-/InterCoding Mode 
Selection for H.264/AVC,” in IEEE Transactions on Circuits 
and Systems for Video Technology (CSVT’07), vol.17, no. 4, 
pp.441 – 453. 
[35] H.-M. Wang, J.-K. Lin, J.-F. Yang, “Fast H.264 Inter Mode 
Decision Based on Inter and Intra Block Conditions,” in IEEE 
International Symposium on Circuits and Systems(ISCAS’07), 
pp. 3647 – 3650. 
[36] B. Zhan, B. Hou, R. Sotudeh, “An efficient fast mode decision 
algorithm for H.264/AVC intra/inter predictions,” in IEEE 
International Conference on Acoustics, Speech and Signal 
Processing (ICASSP’08), 2008, pp. 1057 – 1060. 
[37] S.-H. Ri, J. Ostermann, “Fast Mode Decision for H.264/AVG 
using Mode and RD Cost Prediction,” in First International 
Conference on Communications and Electronics (ICCE’06), pp. 
264 – 269. 
[38] Q. Wang, D. Zhao, Wen Gao, Siwei Ma, “Low complexity 
RDO mode decision based on a fast coding-bits estimation 
model for H.264/AVC,” in IEEE International Symposium on 
Circuits and Systems (ISCAS’05), 2005, vol. 4. 
[39] C. S. Kannangara, I. E. G. Richardson, M. Bystrom, J. R. Solera, 
Y. Zhao, A. MacLennan, and R. Cooney, “Low-complexity skip 
prediction for H.264 through Lagrangian cost estimation,” IEEE 
Trans. Circuits Syst. Video Technol., vol. 16, no. 2, pp. 202-208, 
Feb. 2006. 
[40] C.-L. Su, W.-S. Yang, Y.-L. Chen, Y.-C. Yang, C.-W. Chen, J.-I. 
Kuo, and S.-Y. Tseng, “A low complexity high quality integer 
motion estimation architecture design for H.264/AVC,” in Proc. 
IEEE Asia-Pacific Conf. Circuits Syst., pp. 398-401, Dec. 2006 
 
 2
各國學者專家交換心得，經驗，提升研究之品質。以下茲就議程之重點詳述如下：  
第一天（11/22）:為 Keynote speech，包括有“High performance and low power SoC 
Design for IT convergence – making the impossible, possible”在介紹高效能低功率SOC設計
技術對經濟的影響的進展。“Low Power Design Methodology: Past, Now and Future” 在介
紹低功率，低成本電腦輔助設計軟體工具的需求。這些演講者的內容，給了我很多新的
啟發，使我獲益良多。其他也包含了數個 oral session, poster session, and special 
session。 
第二天（11/25）：今天為此會議最後一天議程亦是論文發表 Session， 我發表了針
對多標準視訊解碼器中可重組離散餘旋反轉換之設計與製作，係探討多標準視訊解碼器
中如何設計有效率可切換之離散餘旋反轉換架構，亦吸引了相當多的關注，使我獲益良
多。參加了此 Session，讓我覺得許多論文之研究與我目前之研究課題息息相關，因此,
這些最新的研發課題皆讓我有深刻的體會。今天的議程也包含了數個專題演講。我也參
與了許多精彩論文發表，於論文發表之後，許多相關領域的專家學者熱烈迴響，我也與
他們交換了許多的寶貴經驗，使我的視野更開闊了些。同時也藉由與會發表論文之機
會，將研究成果公諸於國際會議上，提升我科技研究之水準。 
此會議針對未來低功率設計技術領域所可能面臨的問題均加以深入探討，並提出解
決之可能策略，對未來低功率設計技術提供一新的方向。此會議不愧為國際電機電子工
程協會每年在電路與系統領域方面韓國舉辦之大型國際會議，問題之探討及意見之溝
通，皆相當有啟發性，是一個值得參加的國際會議。 
二、與會心得 
由於低功率電路與系統技術整合之未來趨勢，它對科技研究以及產業分工，將有極
大衝擊。而且它對人文社會、文化、生活等之巨大影響正逐漸成形中。因此如何掌握 低
功率電路與系統技術整合技術，實為我國是否能延續目前高科技產業命脈之重要關鍵之
一。我國目前在資訊產業方面的產值高居全世界第三位，半導體積體電路產值也居全世
界第四位，而消費電子產業，亦位居世界前茅。加上政府所建構之良好基礎環境，科學
園區之建設與經驗，電信自由化之驅動，電信國家型計劃快速推動之努力，未來我國正
可以藉由低功率電路與系統整合科技之推動與發展，延續半導體 IC 科技與資訊產業之
 4
自國內的論文有數篇，分別來自國立中興大學、台大、中山等大學，這些論文同時在此
次大會發表，對提昇我國低功率電路與系統研究的國際學術地位有一定的貢獻。建議政
府能繼續鼓勵及推動國內低功率電路與系統領域之研究，繼續提昇國內信號，系統與電
子研究的能力與成果。 
此次會議之論文方向不僅有理論探討，更著重於實務應用，對學術界與工業界甚
有幫助。此一研究趨勢，將有利於產學合作。另外，由於低功率電路與系統技術主題非
常熱門，全世界學術界與工業界均提出一些方法，這使我瞭解了目前低功率電路與系統
技術的困難在於要設計一低功率電路與系統且能夠執行多種演算法，只有設計一低功
率、高效能的 Programmable Processor 是較為理想的解決方案。 參加此次會議，與各
國學者專家交換心得，經驗，相信對我在研究方法、過程、成果乃至未來研究領域的擴
展，助益良多，並能提升研究之品質。 
三、建議事項 
最後，我深深感謝能給予筆者出席國際會議的機會，讓筆者參加此一重要國際會議，
進行國際交流。建議國內應多爭取舉辦類似大型國際會議，讓國內學術界及產業界有更
多人參與，一方面可激勵國內的低功率電路與系統領域研究風氣，培育人才，同時可提
高我國在國際上的能見度及學術地位。 
 
四、攜回資料名稱及內容 
參加此次研討會帶回 2010 國際系統晶片設計會議論文集，有需要者可與本人聯絡
(Tel:04-22840688~805，E-Mail：yklai@dragon.nchu.edu.tw)。  
本人出國參加此次國際會議，獲益良多,在此謹致謝忱。 
 
 
 
97 年度專題研究計畫研究成果彙整表 
計畫主持人：賴永康 計畫編號：97-2221-E-005-094-MY2 
計畫名稱：智慧型嬰幼兒監護與安撫晶片系統--子計畫一：低功率智慧型嬰幼兒監護視訊處理系統設
計 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 1 1 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 3 3 100%  
博士生 2 2 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
研討會論文 3 3 100% 
已發表於以下會
議論文 
1.L.-F. Chen, 
S.-Y. Huang, 
C.-Y. Liao, and
Y.-K. 
Lai, ＇Hardware 
Efficient 
Coarse-to-Fine 
Fast Algorithm 
for H.264/AVC 
Variable Block 
Size Motion 
Estimation,＇ 
Proc. of IEEE 
Int＇l. 
Symposium on 
Circuits and 
Systems (ISCAS), 
Taipei, Taiwan, 
ROC, May 2009. 
2.Model-based 
Early 
Termination 
Scheme for 
H.264/AVC Inter 
Prediction,＇ 
Proc. of IEEE 
Int＇l. 
Conference on 
Acoustics, 
Speech, and 
Signal 
Processing 
(ICASSP), 
Taipei, Taiwan, 
ROC, April 2009.
3. Y. K. Lai, L. 
F. Chen, T. E. 
Hsieh, and S. Y. 
Huang, ＇ Hybrid 
parallel motion 
estimation 
architecture 
based on fast 
pel-subsampling 
algorithm, ＇
Proc. of IEEE 
Int ＇ l. 
Conference on 
Multimedia 
&amp ； Expo. 
(St d t B t
 
