1 
 
區域空間之智慧型整合式安全監控系統-II 
 
 
計畫編號：NSC 97-2221-E-324-047 
執行期限：97年8月1日至98年7月31日 
執行單位：朝陽科技大學 資訊工程系 
計畫主持人：鄭文昌 博士 
 
 
摘要 
在此計畫中我們針對智慧化居住空間建置提出一系列智慧化安全監控技術，不同於傳
統的安全監控系統，我們賦予安全監控智慧化的能力，將被動變成主動角色，能在第一時
間主動發現異狀時提出警告，有效完成智慧化主動式居住空間的安全監控。在此計畫中我
們完成三維人臉重建與辨識、行人偵測與追蹤、行人行為辨識、火災自動偵測、人員自動
定位系統等技術，對於人臉辨識我們利用電腦立體視覺重建技術重建三維人臉模型，並且
提出一個類神經網路的回歸模型用來修正由立體視覺重建的三維人臉模型，使更接近真實
人臉立體模型，此外利用支持向量機辨識前景物體是否為一行人，能排除因為光影或雜訊
等移動前景造成的誤判，並且利用另一個支持向量機訓練學習行人姿勢辨識，透過姿勢判
斷能在第一時間判斷是否有危險行人姿勢存在。另一方面，由於火災會造成生命和財產重
大損失，為了能夠減少火災的危害，必須在火災發生同時能夠快速發出警報，才能有更充
足的時間進行滅火或人員疏散，透過影像視覺分析方法，不僅可以減少因人力不足或其他
人為疏失造成災害更加地擴大，也較能夠節省裝置的成本。且使用影像視覺的偵測方法也
比其他非基於影像視覺的偵測方法具使用彈性和更遠的偵測範圍，因此在此計畫中，我們
也完成火災自動偵測技術，從實驗的結果發現，其結果與其他現有方法有相同的高正確率，
並且比其他方法有更低的誤報率，最後為了更有效識別入侵者或合法人員，我們利用主動
式 RFID 提出一套室內人員自動定位系統，透過合法人員身上所配戴的主動式 RFID 標籤，
我們可以隨時掌握人員進出與位置狀況，因此能更有效偵測出入侵者存在，結合上述技術，
我們可以達到全方位的智慧化居間空間安全監控的目的。 
 
關鍵詞：視訊監控、人臉偵測、人臉辨識、行人偵測、行人追蹤、背景重建、火災偵測，
三維重建，立體視覺，支持向量機 
 
3 
 
影機進行接替追蹤的動作，如此一來可以避免跟丟的情形發生。再者利用已設置好的攝影
機結合視訊煙霧及火源偵測程式達成火災自動偵測系統，當偵測到煙霧或火源時在第一時
間主動提出警報，能夠減少反應時間有效降低傷害，最終達成全方位智慧化居住空間安全
監控的目的。 
二、 研究目的 
此計畫的目的是將針對居住空間的應用提出一套智慧化整合式視訊安全監視系統，整
合居住環境中各種攝影機所取得的視訊資料，建構一個全方位、無死角、且具主動性的安
全監控系統，此系統能夠針對入侵者進行偵測、辨識、追蹤、紀錄以及行為分析，並配合
煙霧及火焰偵測系統及主動 RFID 自主定位系統，達到真正全方位的主動式視訊安全監視
系統。 
三、 文獻探討 
3.1 三維重建 
人臉辨識除了傳統二維影像人臉辨識外，三維人臉辨識技術是近年來非常熱門的研究
議題，以往要建立三維人臉模型必須使用到三維掃描器，然而三維掃描器動輒數百萬，在
實際應用成本考量上是一大負擔，解決的方法則是利用電腦視覺領域中立體重建技術來解
決，此類技術大都數是利用多張影像計算出消失的深度資訊重建三維模型[1-5]，在先前的
研究中，已經有很多學者提出三維重建的方法及應用，而這些研究，大部分應用在機器人
視覺及工業測量方面[6-9]。 
人臉影像擷取相較於大型建築物，在相機座標的對準上相對容易，我們只需要利用外
部校正圖的比對，即可達成相機座標的對準，如此將可排除外部參數求取問題，因為相機
座標已經準確的對準過，內部參數我們可以藉由測量外在的世界座標數據，然後利用成像
幾何公式求得內部參數。 
 
圖 1. 相機針孔模型 
圖 1 所示為針孔相機模型，C 為鏡頭中心，O 為影像平面中心，f 為焦距，由相似三角
形的關係，世界座標（ ZYX  , , ）與影像座標（ y,x ）可表示為： 
Zf
X
f
SFx
−=
⋅ , 和 
Zf
Y
f
SFy
−=
⋅                               (2) 
其中 SF 為 Scale Factor，由於影像單位為像素（Pixels），而空間中的物理單位為厘米（mm），
直接運算會造成比例上錯誤，必須先求取 Scale Factor 進行兩單位間轉換，其作法是首先選
5 
 
3.2 移動物體偵測 
 物體偵測技術是智慧型環境一個重要的核心技術。利用連續影像資料，直接作差異分
析，用以判斷影像中移動物體的位置，此技術對動態環境會自動適應(Self-adaptive)的能力，
但對相關的特徵點萃取效果很差，其次是利用光流(Optical Flow)的計算完成物體偵測[10]，
此方法計算較複雜，雖然可以得到較完整的移動目標物特徵資訊，但不適用於即時
(Real-Time)的應用，而背景差異法[11]是最簡單的方法，利用事先預存的背景影像與即時影
像進行相減運算，以偵測出物體的位置，此方法雖可提供完整特徵資料，但對光線改變或
背景的改變的容忍程度差，改良背景差異法(Modified Background Subtraction)是基於上述三
種方法的整合，一個新的「背景環境」的漸進統計模式備提出[12-13]，以提供一機制可以
適應背景環境緩慢改變，前景的像素點可以定義為該點的灰階值大於背景平均值兩倍標準
差以上，最後利用前景像素點的相連元件(connected component)方法聚集，最後得到移動物
體。 
 由於背景影像隨著時間改變，因此對於背景影像須建立一套更新學習的機制，使得背
景影像能隨時更新，以得到當下最接近實際環境的背景影像，常用在更新背景影像的方法
分為兩種，一種是盲目更新方法，也就是針對新進的影像一律以某一個比例原則加入背景
影像模型中，其運算可以表示如下方程式 
    ( ) ( ) ( ) yxyxIyxByxB ttt  ,      ,  ,  ,1),(1 ∀+−=+ αα                        (8) 
其中 [ ]1,0∈α 唯一比例值，B表示背景影像，而 I為輸入影像。此方法好處為可以適應背景
實際情況之改變來更新背景影像，但缺點則是不論前景或背景都被當作背景影像模型的學
習資料，故前景物體有可能被學習入背景影像而不被正確的偵測出來；另一種是選擇性更
新的方法，此方法僅僅將被歸類為背景的部分加入背景影像模型中，優點為偵測效果較佳，
缺點則是若背景因光線或其他原因改變時，而背景影像模型未能反映此種改變，則會造成
永久性的警報，形成死結，因此有學者提出改善的方法[14]，針對背景影像模型中任一位置
的像素值進行更新，利用相同位置的連續幾張畫面像素數值的中間值，或是連續幾張相同
位置的像素值的最大統計值，不管是採用中值或最大統計值，最大缺點是計算耗時且須大
量記憶體紀錄連續幾個畫面的資料，而優點則是效果優於盲目更新以及選擇性更新的方
法，不僅考慮到背景隨時間改變光線改變的問題，同時也考慮到當前景物體常駐後變成背
景物體的情況。 
 背景差異法移動物體偵測，此運算可以表示如下列方程式： 
   yx
ThyxByxI
ThyxByxI
yxF
tt
tt
t  ,     , ) ,() ,(,0
) ,() ,(,1
),( ∀
⎩⎨
⎧
<−
≥−=                      (9) 
其中 ) ,( yxFt 、 ) ,( yxIt 、以及 ) ,( yxBt 代表在座標點( yx, )的前景影像、輸入視訊影像以及背
景影像，下標 t 代表時間，Th 為預設臨界值。前景的像素點可以定義為該點的灰階值大於
背景平均值兩倍標準差以上，接著利用前景像素點的相連元件(connected component)方法聚
集，最後得到移動物體的輪廓。 
 
3.3 行人追蹤 
 移動物體的追蹤問題，可視為一連串疊代求最佳解之過程，對於每一張視訊的影像，
7 
 
二維對數搜尋，找到圖中被標示為 3 且填滿灰色的區塊，依此類推，直到找尋間隔剩下 1
個像素為止，最後決定區塊的移動向量，如圖 4 中被標示為 MV 的向量。 
 
圖 4. 二維對數的搜尋的區塊移動向量比對法示意圖 
 
3.4 主動式 RFID 
對於人員進行定位系統，能有效識別人員是入侵者或或是住戶，對於人員定位除利用
影像處理技術外，亦可以利用其他方式進行人員定位。對於人員、車輛、以及物品的定位
與追蹤，全球衛星定位系統(GPS)扮演著重要的角色，全球衛星定位系統早期由軍方為作戰
需要而開發，雖然 GPS 已經成功由軍用轉型至一般生活使用，但 GPS 較適合應用於戶外沒
有遮蔽的環境，對於室內應用，則因為衛星的收訊原因導致無法使用，為了改善這個問題，
有學者提出利用主動式 RFID 做為室內定位系統。 
主動式 RFID 和被動式 RFID 的區別，主要是被動式 RFID 電子標籤本身不具有電源，
而是以讀取器的電磁波感應轉換成電力的來源，以便進行電子標籤和讀取器的溝通，被動
式電子標籤使用的頻率有 LF(125KHz)、HF(13.56MHz)、UHF(902-928MHz)，且其讀取距
離短，而主動式 RFID 電子標籤本身具有電源(電池)，主要使用的頻率是 433MHz 及
2.45GHz，主動式讀取器的讀取距離可達到 200 公尺，因此在於應用上有別於被動式無線射
頻系統的應用，目前常見在主動式 RFID 應用可分為人員定位、車輛管控、資產管理及追
縱、貨櫃管理及無線感知等。 
利用主動式 RFID 做為室內定位系統，以通訊方式在可讀取區域(Zone)內辨識電子標籤
為主，因此並無法明確指出電子標籤在佈置區域內的特定位置點，而僅能判斷所在特定區
域，此外在佈建時為了讓二個相鄰的讀取器，為避免兩者讀取器相互溢波(Overlap)產生辨
識在何區域的困難，甚至發生系統畫面出現欲定位的人員在兩個相鄰區域瞬間跳動的情
形，須考量決擇兩偵測區域中間有訊號間隙(gap)的缺點，以避免溢波問題，解決方法可以
透過讀取器的接收訊號強度指數(RSSI)作為判斷運算的輸入，並且搭配固定參考位置的電
子標籤，以計算出電子標籤被讀取的相對位置，此方法稱為 LANDMARC[18-21]的方法。 
9 
 
 
   
(a) (b) (c) (d) 
圖 5. 人臉影像擷取和特徵點偵測結果，(a)左相機影像 (b)右相機影像 (c)左相機影像 (d)
右相機影像 
 
 
 
 
 
 
 
 
(a) (b) (c) (d) 
圖 6. 三維人臉模型結果，(a)仰視圖 (b)側視圖 (a)側視圖 (b)回歸計算重建結果側視圖 
 
 完成立體人臉重建後，接著完成三維人臉重建。在此計畫中我們利用類似於影像中簽
名(signature)的方法抽取特徵，以每一個立體人臉模型中的最高點為圓心，一般為鼻子的
位置，以r為半徑畫圓並且每間隔θ角度取樣人臉深度值一次，並且進一步將這些人臉深度
取樣值與圓心深度值進行正規化計算，計算方法如下: 
( )
( )Z
ZZD
max
max θ
θ
−=                                                      (16) 
其中 θZ 為角度為θ 時距離圓心 r 之人臉深度值，接著利用此數值作為人臉特徵，以 SVM 進
行辨識，在此實驗中我們針對 10 個人利用我們提出的方法重建三維人臉模型進行人臉辨
識，結果如表一所示，辨識率可達到 98%的準確度，其中失敗的辨識原因是測試人臉角度
過大時，將造成人臉深度資訊簽名取特徵的結果誤差太大，其次是另一個失敗的例子則是
取立體人臉最高深度位置不是在鼻子而是額頭位置，結果導致辨識失敗。 
 
表一. 人臉辨識結果 
 訓練資料 測試資料 
準確率 100% 98% 
 
 
11 
 
 
圖 8. 輪廓的中心點與距離 
 
 為了驗證我們提出即時行人偵測與追蹤系統的實用的可行性，我們比須先了解 SVM 是
否可以辨識出行人與非行人的差別，實驗中以行人資料和非行人資料庫訓練 SVM 分類器，
行人資料庫裡共計有 200 張，非行人資料庫裡共計有 170 張，總共是 370 張。所有的影像
背景包含有室內與戶外，其中室內有部分在研究室取景以及在校園內建築物大廳取景。在
真實情況下，測試的資料庫裡行人共計有 20 張，非行人資料庫裡共計有 15 張，總共是 35
張。表二顯示實驗結果，並將結果比較於類神經網路辨識結果，SVM 辨識行人後的正確率
可達 90%以上。接下來我們利用先前提出追蹤的方法來追蹤行人，透過區塊影像的移動向
量偵測，我們可以決定出前後視訊畫面中行人的對應關係，既使在行人偵測不完整的情況
下，透過移動向量的偵測趨勢，既使在部分畫面中行人被判斷為非人的情況下，仍能估測
出移動物體前後的對應關係，完成行進路徑的紀錄。 
 
表二. 行人辨識結果 
方法 正確率(%) 訓練資料 測試資料 
NN (BP) 88.12% 86.35% 
SVM 93.68% 90.00% 
  
在判斷為行人後我們接下來進行姿勢的判定，在實驗中我們以具攻擊性資料和非具攻擊性
資料庫訓練 SVM 分類器，具攻擊性資料庫裡共計有 110 張，非具攻擊性資料庫裡共計有
170 張，總共是 380 張。所有的影像背景都不同，有的在研究室取景，有的在大廳上取景，
戶內外環境影像皆有。在真實情況下，測試的資料庫裡行人共計有 20 張，非行人資料庫裡
共計有 30 張，總共是 50 張。結果如表三所示，正確率可達 88%，因為部分的攻擊性行為
為連貫動作，所以容易有誤判的情形，但是如果有明顯的攻擊性行為，在分類的結果都可
以比 90%更加準確。 
表三. 姿勢辨識結果 
方法 正確率(%) 訓練資料 測試資料 
NN (BP) 85.78% 80.70% 
SVM 92.782% 88.02% 
 
13 
 
(c)所示，我們可以發現，二維對數樣板比對法若一開始即搜尋錯誤，將導致最後搜尋結果
錯誤，如圖 10(b)所示，紅色方框框錯位置。 
 
  
(a) (b) 
圖 9. 測試影像，(a)前一畫面 (b)現在畫面 
 
 
(a) (b) (c) 
圖 10. 移動向量偵測結果，(a)前一張畫面與選取的樣板 (b)二維對數樣板比對結果 (c)模擬
退火比對結果 
  
4.4 影像式火災自動偵測系統 
火災偵測系統採用一般攝影機，擷取輸入影像進行火焰的偵測。如圖 11 所示，整個系統的
架構流程可包含影像輸入、背景的訓練、取出前景影像、Label method、火焰偵測及標示火
焰偵測結果。 我們利用擷取攝影機影像作為偵測系統的影像輸入來源。以中位數法，
每隔一段時間抓取一張圖片作為背景影像的訓練材料，而每個座標點的數值經過排序後取
其中位數，該值便當作是背景的像素值，每點做法皆相同，最後完成中位數法的背景更新。
前景影像取得則是透過輸入影像與背景影像相減，且亮度必須要達到一定的門檻值，並符
合火焰的 RGB 色彩範圍，才被認定為是屬於前景影像，其計算方法如下： 
    ( ) ( ) ( ) ( ) ( )⎩⎨
⎧ >>>=     
otherwise,0
 , , , , ,,1
  ,
ThyxIyxByxGyxR
yxT              (25) 
其中 ) ,( yxT 為去除背景後的影像， ) ,( yxI 為輸入的影像， ) ,( yxR 、 ) ,( yxG 及 ) ,( yxB 分別
表示色彩空間中的紅色、綠色以及藍色，Th 為自定的門檻值。接著將前景影像以區塊標示
出來，並且去計數各前景影像區塊的像素值，最後將各個前景影像區塊的資訊提供給火焰
偵測程式處理。火焰偵測是利用比較目前的前景影像和前一張前景影像的變化量，若前一
張影像與目前影像中的前景區塊有交集的地方，便將目前交集到的前景區塊分成上下兩個
區塊，其中上下兩區塊各佔交集區塊的一半，而變化量計算方法如下： 
15 
 
表四. 火焰偵測結果 
方法 正確率 錯誤率 
Max Red[23] 93.9% 66.4% 
rgb color space[24] 97% 58.4% 
YCbCr space [25] 99% 31.5% 
連續偵測 + YCbCr[24] 99% 15.0% 
Our method 99% 3.0% 
 
4.5 主動 RFID 自我定位系統 
 由於傳統停車場的管理及服務成效不彰，而 GPS 的使用範圍也侷限於室外，到了室內
後則無法繼續做定位及導覽的功能，因此我們將利用主動式無線射頻辨識(RFID)完成一套
室內定位系統，並且應用於停車場定位及自動引導至停車格的系統。由於被動式使用距離
較短，除了提供進出入與收費管理外，並無法提供進一步資訊，例如進入停車場後仍然無
法得知車輛目前位置以及停車格位置等資訊，而主動式 RFID 辨識距離遠，可以用來完成
定位系統，並結合網路資訊與簡訊服務的配合，讓使用者在未到達停車場前就可得知停車
場那的服務及資訊如：預約停車的時間、停車場內的停車格數量等等的資訊都可在未到達
停車廠之前都可一清二楚，在到達停車場後，藉由主動式 RFID 定位系統引導車輛至停車
格，不必讓使用者漫無目的的尋找車位降低在停車場內的危險性及尋找停車位的糾紛；再
搭配定位及簡訊的服務，讓車主在離開停車場後可透過網路得知車輛於停車場訊息，如果
車輛遭受移動的話透過簡訊的服務讓車主在第一時間掌握車輛的訊息。提高停車場的服務
範圍和管理的效率及準確性，結合現代科技與實際生活應用的問題，讓停車場更趨向智慧
化的管理及人性化的使用。 
 傳統的三角定位方式是利用三個讀取器在可偵測到標籤的範圍內，依據標籤的訊號強
度(RSSI)與三個讀取器交集判斷標籤的所在位置，如圖 13 所示，其中綠色長方形代表主動
式 RFID 的讀取器，紅色圓圈範圍為每一個讀取器可讀取的有效範圍，透過三個讀取器讀
取電子標籤 RSSI 訊號強度，決定出待測物體的位置，如圖 13 中藍色圓點所示，其優點是
原理及計算簡單，但缺點是需要利用較多的讀取器，由於主動式 RFID 讀取器價格比起電
子標籤或被動式讀取器價格高出許多，因此造成成本高，且直接透過 RSSI 決定電子標籤位
置，準確性有待考慮。 
 
圖 13. 三角定位法示意圖示意圖 
17 
 
  
圖 16. 應用讀取的 Reader 圖 17. 應用的參考點 Tags 和追蹤 Tag 
 
五、 結果與討論（含結論與建議） 
在此計畫中我們針對智慧化居住空間安全監控完成一系列基於視訊的核心技術研發，
其中包含三維人臉辨識門禁管理系統、入侵者的偵測、追蹤、行為判斷以及路徑監控、火
災自動偵測系統、主動式 RFID 室內人員定位系統等，結合提出一套智慧化居住空間監控
系統。此系統能自動偵測是否為人形移動物，可以避免光影與其他非人移動物體影響，透
過行人的追蹤與路徑比對，若此行人行徑是否依循正常路線行進，則不是入侵者，則可自
由行動，若此行人由窗戶或翻牆進入，則為入侵者，則此時系統可以透過預設的撥號系統
通知屋主或以其他刑事警告其他人，屋主也可以透過家中的網路攝影機確認為入侵者身分
後，再決定是否進行報警處理。再者利用火災自動偵測系統，當偵測到煙霧或火焰時，在
第一時間主動提出警報，減少反應時間有效降低傷害。最終達成全方位智慧化居住空間安
全監控的目的 
透過本計畫完成發展的相關智慧型視訊核心技術，對於市場競爭及產品的價值將有極
高之附加價值。此外對於參與的研究人員將可深入地瞭解現有視訊監控產品的架構，及其
在數位影像系統應用上的角色與功能；同時瞭解安全監控基礎建設的技術與產業界生產之
產品的整合工作，建立測試與修正的研究經驗，甚或開創研究的視野，這對於參與者而言
都是相當寶貴的經驗，有助於研究實力的累積，更為國家培育優秀的機電與資訊工程人才。 
 
 
參考文獻 
[1]. R. Hartley and A. Zisserman, Multiple View Geometry in Computer Vision, Cambridge 
University Press, 2003.  
[2]. D. A. Forsyth and J. Ponce, Computer Vision: A Modern Approach ,Prentice Hall, 2003.  
[3]. O. Faugeras, Three-Dimensional Computer Vision: A Geometric Viewpoint. MIT Press, 
Cambridge, 1993.  
[4]. M. Pollefeys, R. Koch and L. V. Gool, “Self-Calibration and Metric Reconstruction in spite 
of Varying and Unknown Internal Camera Parameters,” International Journal of Computer 
Vision, 32(1), pp. 7-25, 1999. 
[5]. M. Pollefeys, L. V. Gool, M. Vergauwen, F. Verbiest, K. Cornelis, J. Tops and R. Koch, 
19 
 
10-14 Sept. 2007, pp. 56 – 64. 
[22]. C. Harris and M. Stephens, “A Combined Corner and Edge Detector,” Proceedings of 4th 
Alvery Vision Conference, Manchester: The University of Sheffield Printing Unit, pp. 
147-151, 1988. 
[23]. T. Chen, P. Wu, Y. Chiou, An early fire-detection method based on image processing, in: 
Procedings of IEEE International on Image Processing, 2004, pp. 1707–1710. 
[24]. T. Celik, H. Demirel, H. Ozkaramanli, Automatic fire detection in video sequences, in: 
Proceedings of European Signal Processing Conference (EUSIPCO 2006), Florence, Italy,   
September 2006. 
[25]. Turgay Çelik, Hasan Demirel, “Fire detection in video sequences using a generic color 
model” Fire Safety Journal, Volume 44, Issue 2, February 2009, Pages 147-158. 
 
 
 
images can be calculated. This is defined below: 
( )[ ]
N
xx
x
N
n
nn∑
=
−
=Δ 1
2
12
12
,           (3) 
where N is point number. Scale factor on horizontal 
direction is: 
    
hS
xSF Δ= ,                       (4) 
where hS  is the distance of horizontal movement in 
space. 
 
3. Stereo Camera Geometry  
 
 
Figure 2. Two-view pinhole camera model 
 
For example, figure 2 is two view pinhole 
camera model simulating human being eyes. We have 
two same cameras and coordinate system is 
calibrated. Where w is world coordinate and B 
distance between two lens centers. The world 
coordinates (x1, y1) and (x2, y2) are projected on two 
images: 
 ( )
f
SFxZfX ⋅⋅−= 11 , and          (5) 
( )
f
SFxZfX ⋅⋅−= 22 .              (6) 
Z coordinates of w are the same in two camera 
coordinate systems; therefore, combining equation (4) 
with equation (5) can have the following result: 
SFx
BffZ ⋅Δ
⋅−= ,                  (7) 
where xΔ = (x2-x1) is the pixel deviation value, 
which is extracted and corresponded from the images 
of two cameras on the x direction of w coordinates. 
From equation (6), for the sake of obtaining 
depth information, the corresponding points from two 
images have to be extracted. Hence, through our 
method, interest points from an image first are 
decided and then matched with feature points from 
the other image. The Harris Corner Detector can 
extract the interest points from the great intensive 
points of the gradient between horizontal and vertical 
direction in the images. It can be computed as:  
( ) ( )[ ]2 , ,,∑ ++−=
W
yx vyuxIyxIC ,    (8) 
where u and v refer to x and y respectively, I(x, y)is an 
image intensity value on image coordinate (x, y) and 
W is an image windows function. For simplifying the 
equation (7), Taylor series expansion is employed to 
get approximation: 
    2222 , 2 yyxxyx IvIuvIIuC ++≈ ∑ ,   (9) 
when (u, v) is concerned with small shift variety, 
yxC  ,  can be defined as matrix below: 
  [ ] [ ]Tyx vuvuC ,, , M= ,             (10) 
where M is the 2 by 2 matrix: 
    
⎥⎥⎦
⎤
⎢⎢⎣
⎡= 2
2
yyx
yxx
III
III
M .               (11) 
Let α and β be the two eigenvalues of M matrix. 
When α and β are greater than the threshold, which 
means the greater intensive points of the gradient 
variety between horizontal and vertical direction. 
 
Figure 3. Stereo camera reconstruction the 
example (a) left camera image, (b) right camera 
image, (c) reconstruction result. 
 
Figure 3 is an example of stereo camera 
reconstruction. Two same cameras are used. Both of 
cameras’ coordinates system are correctly calibrated, 
and then let two lens centers in parallel have a fixed 
distance to extract two different angular images, i.e. 
Figure 3 showed. The images are extracted from left 
and right cameras respectively. Figure 3(c) shows the 
reconstruction result. 
 
(a) (b) 
(c) 
Where the redder in the Figure 7, the greater in depth 
value. On the contrary, the bluer, the smallest. Where 
the unit for (X, Y, Z) coordinates is millimeter. From 
the experimental results, the reconstructed data 
especially conform to actual rate of human face. 
On the other hand, since 120 feature points are 
discontinuously scattered on a face image, in order to 
get complete 3D face model, a method of 
interpolation with neural network is finally used. In 
other words, by the application of neural network 
regression method, the smoother 3D face model can 
be realized. Figure 8 shows the results of neural 
network regression. Where the Figure left is the 
lateral view of the original 3D face model and the 
Figure right is the effect on curve-fitting result 
through neural network regression. Where the blue 
points are the corresponding feature point positions 
on the face image and green points the approximate 
result by regression. The results are even close to 
actual 3D face model. 
 In order to verify the accuracy of the 3D face 
recognition we provide, we are going to proceed the 
mean squared error calculation with our result and the 
face model which recognized by the high accuracy 
3D scanner.  First, find the top or the highest part of 
every model and fix it as the center of a circle which 
normally located on the nose. Draw a circle by using 
r as the radius and record the depth by every θ 
distance. Then, take the sample number and the depth 
of the center in the circle from the depth of the face, 
and normalize them, here is the method. 
        ( )( )Z
ZZD
max
max θθ
−= .            (13) 
where θ is the distance of the circle which r is the 
depth of the face, in this experiment, we use the same 
sample of the 3D face model, using 24 degrees as the 
angle we measure and record the depth, and fix the 
radius as 20, 40 and 60 pixel. The experimental result 
is as shown in Table 1.  
 
(a) (b) 
Figure 6. Feature detection on a face image (a) left 
camera image, (b) right camera image. 
 
6. Conclusion 
In this paper, two-view stereo reconstruction 
techniques with neural network regression method 
realize 3D face reconstruction. Two-view stereo 
reconstruction techniques apply two cameras to 
extract two images simulating left and right eyes. For 
having corresponding points part, through equations, 
images depth information can be computed. As for 
not having corresponding points part, we propose 
using neural network regression to solve. Finally, 3D 
face model can be reconstructed by neural network 
regression. This method, in the experimental results, 
can quickly, efficiently and economically compute 
3D face depth information. 
As for future research, we are focusing on two 
directions. (1) In this paper, we first mark the 
positions on the face beforehand with detecting 
interest points to extract left and right corresponding 
points on images. In practice, it is impossible that a 
user is marked beforehand. Thus we employ 
non-invasive method instead, for example, 
illuminants and fringe projection or point light 
sources. (2) The reconstructed 3D face model can 
realize 3D face recognition system for improving the 
accuracy of the traditional 2D face recognition. 
 
(a) 
(b) 
Figure 7. 3D face model reconstruction results (a) 
top view, (b) lateral view. 
 
 
Table 1. Mean squared error of 3D Scanner model 
and reconstruction model. 
r Avg. 20 40 60 
0.2829 0.1143 0.1028 0.1667
 
 
階層式模擬退火法應用於移動向量偵測 
Using Hierarchical Simulated Annealing to Detect The 
Motion Vectors in Video 
鄭文昌* 鄭永義** 
*朝陽科技大學資訊工程系 **朝陽科技大學資訊工程系 
Wen- chang Cheng*  Yung-I Cheng** 
*Department of Computer Science, Chaoyang University 
**Department of Computer Science, Chaoyang University 
 
wccheng@cyut.edu.tw  s9727634@cyut.edu.tw  
 
摘要 
 本篇論文針對視訊中移動物體的移動向量偵
測提出一個新的方法，此方法主要是基於模擬退火
法。由於移動向量偵測可視為是求最佳化解的問
題，因此我們利用模擬退火法結合樣板比對法完成
移動向量的偵測，透過模擬退火法的特有退火機
制，使得求得最佳化解，並且避免落入局部最小值
中，此外為提升移動向量偵測的準確性，我們提出
一個新的階層式模擬退火法，經實驗證明，此方法
比較於常用的二維對數搜尋法更能正確偵測出正
確的移動向量，雖然時間消耗大於二維對數搜尋
法，但仍能在有限時間內完成。 
 
關鍵字：模擬退火、移動向量、樣板比對、前景偵
測 
 
1. 前言 
移動向量(Motion Vector)的偵測是影像處理中
常用的技術，例如 Mpeg4 的影像壓縮、視訊影像
分割、以及物體的追蹤等[1]，移動向量的偵測技
術常見的方法有光流估測法、特徵點比對法、以及
樣板比對法等[1-5]。光流估測法主要缺點是需要龐
大的計算量，因此不適於即時的應用，而特徵比對
法利用搜尋連續畫面中相近的特徵點完成移動向
量偵測，此方法是屬於點對點的移動向量偵測技
術，與光流估測法一樣需要龐大計算量，不適合用
於即時視訊移動物體偵測。 
樣板比對法是一種簡單的移動向量偵測的方
法，此方法是將輸入的視訊影像以固定尺寸切割成
相同大小的樣板，再將每一樣板對應到前一張輸入
的視訊影像中相同位置，並以一個特定範圍作為搜
尋最近似的樣板，最後可以決定出每一樣板對應到
前一張輸入視訊影像的移動向量，雖然樣板比對法
計算簡單，但其缺點仍是計算耗時，因此有學者針
對耗時的問題提出改善方法，例如二維對數的樣板
搜尋法[1]改善樣板搜尋的順序，使得搜尋相當快
速，但此方法有一個致命的問題，就是當一開始搜
尋的方向如果錯誤，將導致最後搜尋結果錯誤。 
由於移動向量的偵測可視為是在影像樣板的狀態
空間中找出最佳化解的問題，因此在本論文中我們
提出利用模擬退火法[6]的概念來完成移動向量的
偵測，由於模擬退火法已被證實能有效應用於搜尋
最佳化解問題，它透過模擬退火的機制，使得搜尋
過程有機會跳脫局部最小值的特性，以致能在有限
時間內搜尋到全域的最小值，此外為了增加模擬退
火法的準確性，我們提出階層式模擬退火法架構來
完成移動向量的偵測，經實驗證實，我們提出的方
法能正確應用於移動物體的移動向量偵測。 
其他的文章結構如下，第二章介紹二維對數搜
尋法，第三章將介紹我們提出的階層式模擬退火法
以及如何應用於影像中移動物體的移動向量偵
測，第四章利用視訊所擷取的連續影像驗證我們提
出方法的效能，並將結果比較於二維對數樣板搜尋
法，最後章節則是結論與未來研究方向。 
2. 二維對數樣板比對搜尋法 
 
圖一、樣板比對移動向量偵測示意圖 
 
樣板比對法是計算移動向量常用的方法[1]，
此方法將目前輸入的視訊影像以固定尺寸切割成
相同大小的樣板區塊，再將每一樣板區塊對應到前
一張輸入的視訊影像，並且以一個特定範圍搜尋最
近似樣板區塊，最後可以決定出每一樣板區塊對應
到前一張輸入視訊影像的移動向量，圖一為樣板比
對法的示意圖，圖一右圖為目前輸入的視訊影像
(標示為 Target frame)，以 N 像素為邊長切割成
NN × 像素的樣板區塊，假設其中某一樣板區塊
的中心座標為 ) ( 0,0 yx ，對應於前一張輸入的視訊
影像(標示為 Reference frame)，如圖一左圖所示，
以 ) ( 0,0 yx 為中心，以(2p+1, 2p+1)為搜尋範圍搜尋
最近似的樣板區塊，如圖一左圖中標示為 Matched 
macroblock 的樣板區塊所示，即為最近似樣板區
塊，因此連接此最近似樣板區塊的中心座標與座標
) ( 0,0 yx 即為此樣板區塊的移動向量。 
我們定義兩樣板近似程度計算方法為 MAD(i, 
計算速度無法太快，為了改善此一問題且提升正確
率，我們提出一個階層式模擬退火法架構用於移動
物體的移動向量偵測，此方法先將搜尋範圍以中心
為原點切割成右上、右下、左上、及左下四個象限，
接著針對此四個象限範圍分別進行個別的模擬退
火法的最佳解搜尋，比較此四個個別象限的最佳
解，並找出其中最佳解作為此階段的全域最佳解，
接著重複上述步驟重複，如同模擬退火法，當新的
全域最佳解比目前全域最佳解好，則將現在的全域
最佳解取代成新的全域最佳解，否則利用退火機制
來決定是否跳脫或取代。完整階層式模擬退火法說
明如下: 
步驟 1. 將搜尋範圍以中心為原點切割成右上、右
下、左上、及左下四個象限範圍。 
步驟 2. 針對此四個小範圍分別進行模擬退火法搜
尋個別的最佳解。比較此四個小範圍的個
別最佳解，並且找出其中的最佳解當作目
前全域最佳解。 
步驟 3. 重複步驟 2 取得一個新的最佳解。 
步驟 4. 若步驟 3 的最佳解比目前最佳解好，則以
步驟 3 的解取代目前最佳解；否則透過退
火機制決定最後是跳脫或取代。 
步驟 5. 重複步驟 2 與步驟 4，直到收斂。 
 
4. 實驗結果 
為了驗證階層式模擬退火法的效能，我們將
此方法與與二維對數搜尋法進行時間與正確率比
較。在二維對數樣板搜尋法中，如果一開始搜尋的
方向錯誤，則將會落入局部最小值的解，而且不管
重複執行多少次都會發生相同的錯誤，但是退火則
與二維不同，透過退火機制可以跳脫局部最小值的
解，進而找到全域最小值。 
實驗主要是利用實際道路汽車即時視訊作為
測試，我們從實際道路視訊中隨機取出任意連續兩
張畫面，如圖三所示，圖三(a)為某一時間的前一張
影像畫面，而圖三(b)為某一時間的影像畫面，首
先我們利用隨機的方式在圖三(a)影像畫面中選取
一個樣板，如圖四(a)紅色正方形框所示的樣板，其
中方框大小 N 為 12 像素，搜尋範圍 P 為 16 像素，
接著利用我們提出的方法與二維對數樣板搜尋法
分別搜尋圖三(b)影像畫面中最相似的樣板，其結
果如圖四(b)與(c)所示，圖四(b)為針對圖四(a)隨機
取樣的樣板利用二維對數搜尋結果，而圖四(c)為利
用我們提出方法所偵測結果，很明顯，二維對數樣
板比對法若一開始即搜尋錯誤，將導致最後搜尋結
果錯誤，如圖四(b)所示紅色方框框錯位置。 
  
(a) (b) 
 
圖三、測試影像(a)前一畫面，(b)現在畫面 
(a) 
(b) (c) 
圖四、移動向量偵測範例結果，(a)前一張畫面與
選取的樣板，利用(a)二維對數樣板比對結果與(b)
我們提出的方法的比對結果 
 
表一為利用上述實驗方法所完成的實驗結
果，比較表，其中每一個數值均採用 10 次的平均
值，由數據顯示，我們提出的方法五次的平均 MAD
為 0.049，而二維對數樣板比對搜尋法的五次平均
MAD 為 0.205，很明顯的，我們提出的方法正確率
較高。其次，我們提出的方法五次的平均時間為
46.6ms，而二維對數樣板比對搜尋法五次的平均時
間為 1.1ms，雖然我們的方法耗時約為二維對數樣
板比對法的 40 倍，但是以實際應用來說，我們提
出的方法所消耗時間已經很少，足以應付即時的應
用。此外，兩者的搜尋範圍變數 P 越大，則兩者都
會造成搜尋時間較久的問題，但是二維的移動向量
正確率會下降，但退火則沒有此類的困擾。 
 
表一、實驗數據結果比較表 
階層式模擬退火樣板比對搜尋法  
(初始溫度 = 1, 退火因子 = 0.9) 
No. Time (ms) MAD  
1 49.564 0.083 
2 44.51 0.052 
3 55.61 0.068 
4 42.642 0.036 
5 40.711 0.006 
平均 46.607 0.049 
二維對數樣板比對搜尋法 
No. Time (ms) MAD 
1 0.940 0.170 
2 1.018 0.102 
3 0.906 0.270 
4 1.391 0.205 
5 1.176 0.277 
平均 1.086 0.205 
 
