 2 
Figure Index 
中文摘要........................................................................................................................ 7 
英文摘要........................................................................................................................ 8 
一、 計畫的緣由與自的........................................................................................ 9 
A. The Embedded Compressor/Decompressor ................................................... 9 
B. The High Profile Intra Predictior ................................................................. 10 
C. The Reduced Patterns Comparison Embedded Compressor/Decompressor (RPCC) 11 
D. The Bitplane Truncation with Pattern Comparison Coding Embedded Compressor/Decompressor
 13 
E. An Area-efficiently High-accuracy Prediction-based CABAC Decoder for H.264/AVC 14 
F. A Predefined Bit-Plane Comparison Coding (PBPCC) for Mobile Video Applications. 15 
二、 研究方法及成果.......................................................................................... 17 
A. The Embedded Compressor/Decompressor ................................................. 17 
(1) Proposed Embedded Compression Algorithm ................................. 17 
(2) Hardware Design ............................................................................. 19 
(3) Integration with H.264 Decoder ...................................................... 20 
(4) Evaluation Result ............................................................................. 22 
B. The High Profile Intra Predictior ................................................................. 23 
(1) Proposed High-Profile Intra Predictor ............................................. 23 
(2) MBAFF Decoding with Data Reuse Sets ........................................ 24 
(3) Intra 8x8 Decoding with Base-Modes ............................................. 27 
(4) Simulation Results ........................................................................... 29 
C. The Reduced Patterns Comparison Embedded Compressor/Decompressor30 
(1) The Proposed RPCC Embedded Compression Algorithm............... 30 
(2) Proposed Architecture ...................................................................... 34 
(3) System Integration And Verification ................................................ 36 
(4) Simulation Result ............................................................................. 38 
D. The Bitplane Truncation with Pattern Comparison Coding Embedded Compressor/Decompressor
 39 
(1) Proposed BTPCC Embedded Compression Algorithm ................... 39 
(2) Proposed BTPCC Embedded Compression Architecture ................ 42 
(3) System Integration ........................................................................... 43 
(4) Experimental Results ....................................................................... 45 
E. An Area-efficiently High-accuracy Prediction-based CABAC Decoder for H.264/AVC 46 
(1) proposed prediction scheme: ......................................................... 46 
(2) Proposed prediction-based Architecture .......................................... 50 
(3) Experimental result .......................................................................... 52 
F. A Predefined Bit-Plane Comparison Coding for Mobile Video Applications.54 
(1) Proposed Embedded Compression Algorithm ................................. 54 
(2) Proposed Architecture ...................................................................... 58 
 4 
Figure Index 
Figure 1: Memory hierarchy of high-profile intra prediction. ................................. 11 
Figure 2 : Block Diagram of Traditional CABAC Decoder .................................... 14 
Figure 3: Flowchart of the proposed embedded compression algorithm ................. 17 
Figure 4: Flowchart of the proposed embedded compression algorithm ................. 18 
Figure 5: Context adaptive ripple architecture......................................................... 19 
Figure 6: The MUX structure................................................................................... 19 
Figure 7: Encoder architecture ................................................................................. 20 
Figure 8: Decoder architecture ................................................................................. 20 
Figure 9: H.264 decoder architecture with proposed embedded compression algorithm 21 
Figure 10: Simulation result of Station sequence(HDTV)....................................... 23 
Figure 11: Block diagram of the proposed high-profile intra predictor. .................. 23 
Figure 12: The updated direction of upper/left buffer memory in (a) frame and (b) field mode MB pair.
.......................................................................................................................... 24 
Figure 13: Line SRAM data_out replaces the last sub-row of upper buffer. .......... 25 
Figure 14: The updated direction of corner pixel buffers. ....................................... 26 
Figure 15: The pipeline scheme of MBAFF decoding ............................................ 26 
Figure 16: (a) Architecture of an intra 8×8 decoding module, and (b) behavior of shared filter. 29 
Figure 17 Compression methods of our proposed algorithm................................... 31 
Figure 18 Reduced patterns comparison coding concept ........................................ 31 
Figure 19 The compressed 32-bit data format ......................................................... 32 
Figure 20 Four predefined bit planes ....................................................................... 32 
Figure 21 Distribution of PSNR loss in 4x1-based PCC algorithm ........................ 34 
Figure 22 Hardware design for the MBPTC ............................................................ 34 
Figure 23 The hardware architecture of RPCC ........................................................ 35 
Figure 24 Data flow of the encoder ......................................................................... 35 
Figure 25 Data flow of the decoder ......................................................................... 36 
Figure 26 The architecture of our proposed H.264 decoder with EC capability ..... 36 
Figure 27 Block Diagram in CoWare simulation platform ...................................... 37 
Figure 28 Compression flow of the proposed algorithm ......................................... 39 
Figure 29 Compressed 32-bit segment format ......................................................... 40 
Figure 30 Flowchart of the pixel truncation ............................................................ 40 
Figure 31 Flowchart of the selective bitplane .......................................................... 41 
Figure 32 Flowchart of the rounding ....................................................................... 41 
Figure 33 An example of partitioning 4x2 block ..................................................... 42 
Figure 34 Compressor architecture .......................................................................... 43 
Figure 35 Decompressor architecture ...................................................................... 43 
Figure 36 H.264 decoder with proposed embedded compression ........................... 44 
Figure 37 Simulation result of station sequence (HDTV) ....................................... 45 
Figure 38: Block Diagram of Proposed CABAC Decoder ...................................... 46 
 6 
Table Index 
Table 1: PSNR comparison ...................................................................................... 22 
Table 2: Numbers of filtered pixels in intra 8x8 modes ........................................... 27 
Table 3: The average cycles for different video sequences...................................... 29 
Table 4: Comparison results ..................................................................................... 30 
Table 5 Ratio of error rate per position in each 4x1 bit plane .................................. 33 
Table 6 Weights under different coding thresholds .................................................. 33 
Table 7 All cases of read access required by MC with/without EC ......................... 38 
Table 8 Comparison of Simulation .......................................................................... 39 
Table 9 Three Groups of Eight Patterns ................................................................... 42 
Table 10 All Cases of Read Access Requirement .................................................... 44 
Table 11 PSNR Comparison .................................................................................... 45 
Table 12 Comparison Among Previous Work .......................................................... 46 
Table 13: Status of Difference.................................................................................. 48 
Table 14: Hit Rate of Prediction Process ................................................................. 52 
Table 15: Comparison of the Proposed Design and Previous Works....................... 54 
Table 16: Three Groups of Eight Patterns ................................................................ 58 
Table 17: All Cases of Read Access Requirement ................................................... 61 
Table 18: PSNR Comparison ................................................................................... 61 
Table 19: Comparison Among Previous Work......................................................... 62 
 
 8 
英文摘要 
It is well understood that research efforts, for next-generation video decoding system, have to cover not 
only multi-standard and multi-mode operation capability, but also less power dissipation and power awareness 
with optimal picture quality, especially when mobile video services are taken into account. As a result, in this 
3-year (2008/8~2011/7) research project proposal, we further investigate several key issues related to 
so-called low-power, low-cost, and multi-mode video decoder solutions. Based on our previous work on a 
dual-mode video (2005/8~2008/7), we leverage the available design platform and research results to further 
explore new design approaches. For multi-mode task, we investigate the specifications defined in H.264/SVC 
and add those key modules into our H.264/MPEG2 decoder platform. Not only new key modules are explored, 
but also system decoding behaviors are analyzed to study a better system architectural model so that a 
stand-alone and IP-based decoder solution can be obtained. For low-cost issue, the major problem lies in 
memory management and limited bus bandwidth. It is necessary to take into account available stand-alone 
memory modules; even SoC solutions become a must. Therefore developing a well-organized memory 
hierarchy and access mechanism to meet decoding requirements under limited resources (storage space and 
bus bandwidth) has been further explored. For low-power issue, an analysis of the decoding behavior and 
related hardware architecture has been conducted. Thus system exploration, module design, and data flow 
have been investigated to reduce power dissipation at different levels. In addition, leakage current due to 
nano-meter CMOS process has been considered to provide a competitive video decoder solution. Finally an 
FPGA prototype has already been set up to evaluate the performance of the proposed video decoder and 
related key modules. 
 
Keywords: 
Video Decoder, Multi-Mode, Multi-Standard, Low-Power, Low-Cost, Mobile Video 
 
 10 
for each coding unit is not a constant, and leads to the complicate embedded compressor design. In [4], the 
authors modified Hadamard transform and combined with Golomb-Rice coding. With the shortest encoded 
cycles, MHT becomes the most flexible embedded compression scheme to be embedded into a video decoder.  
In this report, a new transform-based lossy embedded compression scheme is proposed. Taking 4x4 
pixels as a coding unit and each unit is compressed with compression ratio two, only 64 bits is needed to store 
in external memory. And with the simple modified bit plane zonal coding, the decoding process of a 4x4 block 
can be done within 4 cycles including the data fetching. This algorithm can be pipelined into two stages. A 
MB only needs 34 cycles to decode and has 5.29dB quality improvement compared with MHT [4].  
 
B. The High Profile Intra Predictior 
H.264/AVC [6]-[7] is the latest international video coding standard from MPEG and ITU-T Video 
Coding Experts Group. It consists of three profiles which are defined as a subset of technologies within a 
standard usually created for specific applications. Baseline and main profiles are intended as the applications 
for video conferencing/mobile and broadcast/storage, respectively. Considering the H.264-coded video in high 
profile, it targets the compression of high-quality and high-resolution video and becomes the mainstream of 
high-definition consumer products such as Blu-ray disc. However, high-profile video is more challenging in 
terms of implementation cost and access bandwidth since it involves extra coding engine, such as 
macroblock-adaptive frame field (MBAFF) coding and 8×8 intra coding, for achieving high performance 
compression.  
In the MBAFF-coded pictures, they can be partitioned into 16x32 macroblock pairs, and both 
macroblocks in each macroblock-pair are coded in either frame or field mode. As compared to purely 
frame-coded pictures, MBAFF coding requires two times of neighboring pixels size and therefore increases 
implementation cost. To cope with aforementioned problem, we propose neighboring buffer memory (include 
upper/left/corner) to reuse the overlapped neighboring pixels of an MB pair. Furthermore, we present memory 
hierarchy and pixel re-ordering process to optimize the overall memory size and external access efficiency. On 
the other hand, H.264 additionally adopts intra 8×8 coding tools for improving coding efficiency. It involves a 
reference sample filtering process (RSFP) before decoding a Luma intra_8x8 block. These filtered pixels are 
used to generate predicted pixels of 8×8 blocks. Hence, the additional processing latency and cost are required, 
 12 
to reduce power consumption, but data transmission still dominates huge amount of system power. Hence, 
reduce data access between on-chip processing modules and external memory is the critical consideration in a 
mobile video device. Although the mobile video devices are suffered from limited battery capability, the 
visual quality requirement is not as high as high resolution applications. Therefore, the embedded 
compression is suitable to lessen the volume of data access and the size of off-chip memory under the premise 
of maintaining acceptable visual quality. The mobile video devices are more and more important due to their 
various functions at the present time. Reducing the usage of bandwidth and the required resource of hardware 
in the mobile video devices is a critical topic.  
In general, the compression methods are classified into two categories: lossless compression and lossy 
compression. It is obvious that lossless compression methods [15] completely reserve the information while 
truncating the size of data, so there has no quality loss. However, some problems of lossless compression are 
so fatal that it’s not suitable for system integration application. The lossless compression suffers from variable 
length of lossless compressed data that we cannot regularly control the compression ratio, frame memory size 
and bandwidth requirement. These disadvantages are also attributed to the needs of memory to prepare for the 
worst case of data access and the unknown size of data. Therefore, there exists an important characteristic of 
lossy compression methods [16]-[19] which differs them from lossless compression methods. The 
characteristic of fixed compression ratio allows us to improve the disadvantages of lossless compression 
methods mentioned previously. Although lossy compression algorithm will sacrifice tolerable visual quality, 
the reduced power consumption, memory size and bandwidth requirement are more attractive for mobile 
video devices.  
Several lossy compression schemes have been proposed in [16]-[19]. The transform-based compression 
methods can convert the signal from time domain to frequency domain and move the energy to up-left corner. 
In human visual system, the lower frequency component is more important than the higher frequency 
component whose feature can be exploited to efficiently compress the amount of data, such as in [16]-[17]. In 
[16], both Modified Hadamard Transform (MHT) and quantization of Golomb-Rice Coding (GRC) are 
employed. To improve the quality loss of [16], [17] adopts Discrete Cosine Transform (DCT) and Modified 
Bit Plane Zonal Coding (MBPZC) instead of MHT and GRC. Although transform-based schemes provide 
good compressed quality, MHT and DCT are too complicated to suit for being embedded with H.264 mobile 
 14 
power consumption.  
 
E. An Area-efficiently High-accuracy Prediction-based CABAC Decoder for H.264/AVC 
 H.264/AVC [13] is the state of the art video compression standard in current video applications. It 
supports two entropy coding tools. One is Context-based Adaptive Variable Length Coding (CAVLC), and the 
other is Context-based Adaptive Binary Arithmetic Coding (CABAC) [13]. CABAC can achieve 9% to 14% 
bit-rate saving in average compared with CAVLC. However, it has notably strong data dependency to restrict 
throughput. Even if a DSP processor can work at 3GHz, it would be difficult to achieve the real-time CABAC 
decoding for HD video at 30 frames/s.  
Many state-of-the-art works has been proposed for raising the throughput. In [26]-[28], multiple-bin 
decoding mechanism provides a significant improvement for throughput. However, it also provides extra 
overhead for hardware cost. Besides, previous works [25] clearly described the syntax element switch 
overhead (SESO) problem and presented a prediction scheme to solve it.  
In this report, we proposed high-accuracy prediction scheme and area-efficient decoding architecture. 
Furthermore, we optimized the memory system to reduce extra overhead. Through our design, the overall 
CABAC decoder can be implemented by less hardware cost and still have acceptable throughput.  
In the traditional CABAC decoding flow, it separates 4 pipeline stages - Context index Calculate (CC), 
Context model Load (CL), Arithmetic Decode (AD) and DeBinarization (DB).  In Figure 2, the pipeline 
would be stalled when ctxIdx depend on bin from AD, or SE[i+1] depend on SE[i]. That was main critical 
performance lost in traditional CABAC decoder.  
Arithmetic
Engine
Calculate
Context index
External 
CPU
SE_type[i+1]Neighbor
MEM Value
Context
Model
ctxIdx
DeBinarization
SE_type[i]
Next 
module
 
Figure 2 : Block Diagram of Traditional CABAC Decoder 
 16 
lengths of the compressed data result in irreducible frame-memory size. Hence, existing lossless algorithms 
are not suitable for frame compression because their primary purpose is to achieve high coding efficiency 
rather than low latency, computation complexity, and high random accessibility.  
Lossy compression algorithms, compared with lossless compression algorithms, accomplish the fixed 
compression ratio (CR). Several lossy compression algorithms have been proposed, such as the modified 
Hadamard transform (MHT) with the quantization of Colomb–Rice coding [32], discrete cosine transform 
with modified bit-plane zonal coding [33], and so on. Yang and Chai [34] exploit 64 patterns to improve block 
truncation coding, where Amarunnishad et al. try to enlarge acceptable quality loss by reducing the number of 
compared patterns in [34]. Lossy compression algorithm with the fixed CR can guarantee the reduction of 
frame-memory size. However, how to maintain an acceptable visual quality remains to be solved. 
Consequently, it is important to design a lossy algorithm with the following features: 1) low-distortion visual 
quality; 2) low complexity; 3) low bandwidth requirement; and 4) low power consumption.  
In this report, a novel embedded lossy algorithm based on predefined bit-plane comparison coding 
(PBCC) is proposed. The CR is fixed at 2. Each 4 × 2 block can be compressed into a 32-bit segment. The 
proposed PBCC encodes a 4 × 2 block in 2 cycles and decodes a 4 × 2 block in 1 cycle to meet the 
requirement of embedded frame data processing.  
 
 18 
Sign bit plane can be considered as union of sign flags for each coefficient. Second, to improve the coding 
efficiency, we record the start plane. Search each bit planes from MSB to LSB (not including sign bit plane), 
and the first plane contains nonzero bits is the start plane. To avoid adding too many extra cycles and to 
simplify the hardware complexity in system view, we use one simple type only for recording each bit plane, 
though other complex types which can be more scrimping on bit using do exist. For each bit plane, we simply 
record the maximum row (RMAX) and column (CMAX) which have a “1” in this row or column, and then 
pack the bits in this zone which is enclosed by RMAX and CMAX. 4 bits are used to record RMAX/CMAX 
of each plane. And then, we packed the sign bit plane. Since we have only 64 bits budget for each 4x4 unit, 
the situation of unable to pack all the information may be happened frequently. Since not every coefficient can 
be packed, packing whole sign bit plane may become a waste. So we take the maximum value of RMAX and 
CMAX out of each packed bit plane and packing useful sign bits only by using those two boundaries. Under 
this method we do not waste extra bits to pack those unused sign bits, and the RMAX/CMAX of sign bit 
plane need not to be packed since they can be derived from the previous coded information. Finally, the end 
plane needs to be estimated and packed to specify when to stop. 
 
(ii) Packing Mechanism 
The overall packing scheme is introduced in this part. After doing discrete cosine transform, we get 16 
coefficients from each 4x4 block. There are 15 AC coefficients and one DC coefficient. Sine DC coefficient is 
the average value and is the most important in transform, we reserve 8 bits budget for the DC coefficient of 
every 4 x 4 block. DC coefficient is always positive, so we don’t have to worry about the sign bit for DC 
coefficient. For the rest 15 coefficients, we first packed the start plane and end plane (6 bits total). Then, we 
separate RMAX/CMAX and plane content of those planes which are between start plane and end plane, and 
connecting all the RMAX/CMAX together and all plane content together respectively. Sign bit information is 
inserted between the CMAX/RMAX and the plane content. Figure 4 shows the compressed segment format.  
Plane 
content4
Plane 
content3
Plane 
content7
Plane 
content6
Plane 
content5
DC_coef, start plane, end plane CRmax4
CRmax
7
CRmax
6
CRmax
5
CRmax
3
Sign bit plane content 
14bits CMAX/RMAX Plane Contents
 
Figure 4: Flowchart of the proposed embedded compression algorithm 
 
 
 20 
(iii) Encoder Design and Decoder Design 
Figure 7 shows the pipeline architecture of compressor design. Since compressor has more time to 
handle the encoding process, we use three stages here and each stage needs 4 cycles. This design with longer 
cycles can shrink the gate count by reducing one dimension four points DCT units. Under this design, a MB 
needs 72 cycles to encode.  
Stage 2Stage 1 Stage 3
Data 
packing
Modified 
bit plane 
zonal coding
1-D 
DCT
1-D DCT
64 bits 
data 
segment
4 x4 
block
Data 
transport
DC coefficient
AC coefficient
 
Figure 7: Encoder architecture 
 
Figure 8 shows the architecture of decompressor. To provide data for motion compensation unit suitably, 
the decompressor must support higher throughput inevitably. The decompressor is divided into two stages and 
each stage needs 2 cycles, a 4x4 block needs 4 cycles to decode, including the data-fetching. Decoding a MB 
just needs 34 cycles. 
Data 
rearrange
Modified 
bit plane zonal 
decoding
1-D DCT 1-D DCT
64 bits data 
segment
DC coefficient
AC coefficient
Data 
transport
4 x4 block
Stage 2
Stage 1
 
Figure 8: Decoder architecture 
 
(3) Integration with H.264 Decoder 
Figure 9 shows the block diagram of the H.264 video decoder containing an embedded compressor. 
Embedded compressor works as the interface between decoder IP and external memory. And the EC 
mechanism is ready to be used by adding extra address control logic. Since the compression ratio of our 
embedded compressor is two, each data is compressed into half of the original size. The address control logic 
is very easy to implement.  
 22 
(4) Evaluation Result 
Software implementation of the proposed algorithm is integrated with JM12.4. The reference frame is 
compressed by the proposed algorithm and compared with the result of previous work using MHT and GR 
coding respectively. The test sequences are Foreman, Stefan, Mobile and Akiyo in CIF format and Station in 
HDTV format. All sequences are organized in one I frame follows nine P frames format. For each sequence, 
100 frames are used to compute the average PSNR value reference to the original sequences.  
Table 1 is the simulation result of five sequences and shows the performance of original H.264 decoder 
without any recompression, embedded with MHT and embedded with our proposed algorithm.  
 
 
 
 Table 1: PSNR comparison 
Test 
Sequence 
Algorithm 
(@CR = 2.0) 
PSNR (dB) 
(original ) 
PSNR lost 
(dB) 
Forman 
(CIF) 
original 35.57 0 
MHT 29.48 6.08 
proposed 34.21 1.36 
Stefan 
(CIF) 
original 36.02 0 
MHT 28.64 7.38 
proposed 33.86 2.16 
Mobile 
(CIF) 
original 33.75 0 
MHT 23.10 10.65 
proposed 29.27 4.48 
Akiyo 
(CIF) 
original 39.64 0 
MHT 32.17 7.47 
proposed 38.33 1.31 
Station 
(HDTV) 
original 38.85 0 
MHT 32.97 5.88 
proposed 37.13 1.72 
 
 
The proposed method maintains better quality in slow motion sequences than high motion sequences. 
However, performance of the proposed method in all sequences is better than previous MHT work. The 
average PSNR degradation of proposed method is 2.21dB while the MHT is 7.5dB. Figure 10 shows the 
embedded result with Station sequence in HDTV format. Although the quality drop is inevitable, the proposed 
 24 
(2) MBAFF Decoding with Data Reuse Sets 
MBAFF is proposed to improve coding efficiency for interlaced video. However, it introduces longer 
dependency than conventional frame-coded picture. In this section, we analyze and realize it via upper, left, 
and corner data reuse sets (DRS) to reuse the pixels and improve the cost and access efficiency.  
(i) Upper DRS 
For decoding an MBAFF-coded video, upper buffer memory is used to store the constructed upper pixels 
of current MB pair. These upper buffers are updated with the completion of prediction process on every 4×4 
block. For each updated sub-row(s), they can be reused by the underside 4×4 blocks. According to the 
different prediction modes of MB pair, the upper buffer will store data from different directions. If current MB 
pair is frame mode, it only needs to load one row of upper buffer (16 pixels) at first, and when a 4×4 block is 
decoded, updating the two sub-rows in two rows (8 pixels) of upper buffer from top to down at one time, as 
illustrated in Figure 12(a). In Figure 12 (b), a field-coded MB pair needs to load two rows of upper buffer (32 
pixels), two times of frame-coded MB pairs. Then, only one sub-row of upper buffer memory will be updated 
when a 4×4 block is decoded. However, considering the fifth 4×4 block, it still needs a sub-row of upper 
buffer to predict, as shown in Figure 13. In order to reduce the upper buffer memory size, the Line SRAM 
data_out is directly used. The only penalty to this scheme is that the Line SRAM data_out must hold the 
value until fifth 4×4 block is decoded.  
first
second
third
fourth
sub-row row
s
u
b
-c
o
lu
m
n
c
o
lu
m
n
4x4 
block
4x4 
block
 
(a) (b) 
Figure 12: The updated direction of upper/left buffer memory in (a) frame and 
 26 
has two processing states: reuse and reload. The first corner is reused when 1) the mode of current MB pair is 
identical to that of previous (left) MB pair or 2) before decoding the bottom MB of frame-coded MB pair. On 
the other hand, the first corner is reloaded when 1) the current MB pair has the different modes as previous 
(left) MB pair or 2) before decoding the bottom MB of field-coded MB pair. In summary, using neighboring 
buffer memory and their different directions of updates according to different modes of MB pair can reuse the 
neighboring pixels and improve the access efficiency. The associated pipeline structure of MBAFF decoding 
is shown in Figure 15. We can see that during a MB pair decoding process, the interaction between buffers 
and Line SRAM can be completed easily and efficiently, and the communication between another Line 
SRAM and external SDRAM can be done at the same time.  
first 
corner 
reuse
fi
rs
t 
c
o
rn
e
r 
re
u
s
e
Bottom 
Field
Top 
Field
A1 A2 A3A0
A0 A1 A2 A3
A4
Bottom 
Frame
Top 
Frame
A1 A2 A3 A4A0
A0 A1 A2 A3
Bottom 
Frame
Top 
Frame
A3 A2 A1 A0A4
A4 A3 A2 A1
A0 A1 A2 A3 A4 A3 A2 A1 A0 A1 A2 A3
first 
corner 
reload
first 
corner 
reuse
first 
corner 
reload
Bottom 
Field
Top 
Field
A1 A2 A3A0
A0 A1 A2 A3
A4
Bottom 
Field
Top 
Field
A3 A2 A1A4
A4 A3 A2 A1
A0
Bottom 
Frame
Top 
Frame
A1 A2 A3 A4A0
A1 A2 A3A0
A0 A1 A2 A3 A4 A3 A2 A1 A1 A2 A3A0
first 
corner 
reload
first 
corner 
reuse
fi
rs
t 
c
o
rn
e
r 
re
lo
a
d
first 
corner 
reload
first 
corner 
reuse
Last even row pixel
Last odd row pixel
 
Figure 14: The updated direction of corner pixel buffers. 
 
Line 
SRAM2 
data_out 
Write 
data 
(second row)
Write 
data 
(first row)
Decoding bottom MB2Decoding top MB2
Field mode 
MB Pair
Line 
SRAM2 
data_out 
Read 
data (to 
first row)
Line 
SRAM1 
data_out
Decoding top MB1
Frame mode 
MB Pair
Read 
data (to 
first row)
 M
B
  
d
e
c
o
d
in
g
Decoding bottom 
MB1
L
in
e
 
S
R
A
M
1
L
in
e
 
S
R
A
M
2 Read 
data (to 
second row)
Write 
data 
(two row)
Time
First 
corner 
reload
First 
corner 
reload
previous MB 
pair has 
different mode 
to current MB 
pair
current MB pair is field mode
Hold until 
fifth 4x4 
block Is 
decoded
Communicate with SDRAM
Communicate with SDRAM
 
Figure 15: The pipeline scheme of MBAFF decoding 
 
 
 
 28 
5 (Vertical right) 17 
6 (Horizontal down) 17 
7 (Vertical left) 16 
8 (Horizontal up) 8 
 
- -
   
M M N M M N
Extra latency
P P P P
       
          
       
 , where   0, 8, 16,  17
   0  6
   4
M or
N or
P



 
 
(1) 
 
In a four-parallel intra prediction module, the latency of an 8x8 block will be increased to 0~5 cycles 
according to the different modes of 8×8 blocks. In order to reduce the latency penalty, we reserve filtered 
pixels when the mode of the first/third is equal to 3 or 7 and second/fourth 8x8 block is equal to 0, 2 (if upper 
is available), or 3~7 (i.e. the value N = 6. Otherwise, N = 0). Then these filtered pixels are directly used to 
predict second/fourth 8×8 block. To clarify the extra latency, Eq. (1) lists the decoding extra latency in an 
intra_8x8 MB, and Table 2 summarizes the # of filtered pixels in each 8×8 intra coding mode (i.e. the value of 
M). In particular, we list some examples to clarify the processing behavior of an intra 8×8 block in Figure 
16(b). If the modes of first and second 8×8 blocks are 3 (diagonal bottom left) and 7 (vertical left) or 3 
(diagonal bottom left) and 4 (diagonal bottom right), only 10 and 11 pixels are needed to be filtered while 
decoding the second 8×8 block, as described in Figure 16(b).  
1
1
Corner, Upper, Left 
Buffer Memory
Base 
Mode 
Predictor
Prediction Output
             
Prediction 
Generator
RSFP
Neighbor 
Distribution
+
Shared portion
Prediction 
Output
+
+
<<1
MUX
>>2
Unit
Rounding
Prediction 
Output
+
+
<<1
MUX
>>2
Prediction 
Output
+
+
<<1
MUX
>>2
Prediction 
Output
+
+
<<1
MUX
>>2
1
1
1
1
1
1
Filtered Pixels 
Buffer Memory
 
(a) 
 30 
Table 4. The overheads for supporting Luma intra_8x8 are 10% and 7.5% compared to [10].  
 
Table 3: The average cycles for different video sequences. 
Test Video 
Sequence 
Intra Prediction 
@ BL [11] 
Proposed Intra 
Prediction @ HP 
Cycle 
Overhead 
Foreman 342.68 355.81 3.8% 
Grandma 275.63 285.28 3.5% 
Suzie 294.90 307.28 4.2% 
 
 32 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
0
4
1
5
2
6
3
7
4x2 Block
0
4
1
5
2
6
3
7
MBPTC
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
0
4
1
5
2
6
3
7
RPCC
Part 
A
Part 
B
4x Average
 
Figure 17 Compression methods of our proposed algorithm 
 
The second step is to deal with remaining bit planes after MBPTC by RPCC. As shown in Figure 18, we 
partition a 4x1 section with 4 bits into four 4x1 layers. According to the coding threshold adopted, the RPCC 
will select the left or right strategy. While we set the coding threshold to level 2, RPCC compares layer 1 and 
layer 2 with eight 4x1-based patterns at the same time. If there is no error in layer 1 and layer 2, RPCC adopts 
the left strategy to compress the 4x1 section. Otherwise, RPCC adopts right strategy. According to the 
simulation result with different thresholds, while the right strategy is adopted, the right strategy is often in 
worse case. We exploit this feature to improve the drawback in 4x1-based PCC algorithm.  
4x1 Section
4x1-based PCC 1x Average
2x Average
1x Average
2x Average
Level 1
Level  2
Level 3
Level 4
4x1-based PCC
4x1-based PCC
4x1-based PCC
 
Figure 18 Reduced patterns comparison coding concept 
 
 34 
We derive the formula (1) from the simulation result. It is about the PSNR loss of 4x1-based PCC 
algorithm. i is the number of 4x1 error bit plane. Pm is the error rate and Pn is the ratio of error rate per 
position in each 4x1 bit plane as described in Table 5. As described in the previous section, we can setup the 
different coding thresholds (Level 0~4) in 4x1-based PCC algorithm to obtain corresponding weight (Wi) as 
described in Table 6. We can exploit the formula to estimate for the PSNR loss in 4x1-based PCC algorithm 
while the previous parameters are modified.  
    



4
0i
44
i 1C  ) based-(4x1 Loss PSNR i
i
nmnm WPPPP  (1) 
 
Table 5 Ratio of error rate per position in each 4x1 bit plane 
240
720
720
240
W1
W2
W3
W4
Wi
0W0
Level 0
112
224
112
0
0
Level 1
48
48
0
0
0
Level 2
16
0
0
0
0
Level 3
0
0
0
0
0
Level 4
  
 
Table 6 Weights under different coding thresholds 
4.65
4.65
8.70
P1
P2
P3
Pn
8.68P0
Error Rate 
(%)
17.43
17.43
32.60
32.54
Total Ratio 
( % )
 
 
Figure 21 shows the distribution of PSNR loss in all thresholds. It helps improving the coding 
performance of the algorithm.  
 
 36 
produced by MBPTC and the threshold is defined by users with different levels as described in Table 5. (Here 
we adopt Level 2)  
 
 0
 1
SP
Coding 
Threshold
Coded Data 
Segment
4x1-based PCC
4x1-based PCC
4x1-based PCC
4x1-based PCC
1x Average
2x Average
1x Average
2x Average
Layer 1
Layer  2
Layer 3
Layer 4
  
Figure 23 The hardware architecture of RPCC 
 
 
(iii) Data Rearrange 
Data unpacking is a simple reverse process of encoding. The decoder focuses on putting the data on 
proper positions. According to the coded data format, the SP selects the initial bit plane of decoding. The 
continuous four layers are then placed on corresponding positions depending on strategy bits. Afterward the 
average of part A and B is placed on the continuous two bit planes after the four layers.  
 
(iv) Overall Design of Encoder and Decoder 
The overall compressor design is shown in Figure 24. It takes one cycle to deal with 4x2 block. Here 
each MB takes 16 cycles to be encoded.  
MBPTC
RPCC
Average
4x2 
Block
1 Cycle
32-bit Data 
Segment
 
Figure 24 Data flow of the encoder 
 
 38 
 
The related accesses of EC are partitioned into write accesses and read accesses. Write accesses from 
deblocking filter write the data to external memory and read accesses read the data from external memory to 
MC. Many methods have been proposed to improve embedded compression and all of them aim to improve 
the performance of embedded compression. However most of performance measured by these methods is 
fragmental, lacking verification from system level. In addition, we expect to precisely estimate the amount of 
read/write accesses on system view point. Thus, we employ “CoWare” to deal with the complicated problems. 
As shown in Figure 27, “CoWare” provides many functions to simulate a complete system and the 
user-defined means user’s design. It makes more efficient that we can change the user-defined field relied on 
our demands. We add the proposed design and H.264 system into user-defined field. The AMBA interface 
between “CoWare” and user-defined is coded in System C and it provides a protocol to commutate each other. 
Furthermore, user-defined means all designs in this filed need to be coded in Verilog.  
  
Figure 27 Block Diagram in CoWare simulation platform 
 
Because the proposed algorithm provides fixed CR as two, the write access times after adding the EC are 
always half of original system. The reduction ratio of write access is 50%. The embedded decompressor 
decompresses the data from external memory to MC. Because the bandwidth of system bus is 32 bits and the 
external memory is 32 bits per entry, the original system takes 4x1 pixels as access unit. The read access 
 40 
System
Working 
Frequency
Total Gate Count
Processing Data 
Unit
Cycle 
Count 
(Cycle)
For a MB
(Encoder/Decoder)
PSNR Loss
Power 
Consumption
MPEG-2 Decoder
100 MHz
20 K
8x1 Array
( 8 Pixels )
2 for first 1x8, 
1 for Pipeline Stage
33 Cycles/33 Cycles
11.81 dB~14.57 dB
N/A
H.264 Decoder
100 MHz
30K
4x4 Array
( 16 Pixels )
12 for first 4x4, 
4 for Pipeline Stage
72 Cycles/34 Cycles
3.22 dB~8.39 dB
2.78 mW / 1.66 mW
H.264 / SVC
100 MHz
3.1 K
4x2  Array
( 8 Pixels )
2 for each 4x4
33 Cycles/32 Cycles
4.42 dB~7.10 dB 
( Average: 5.98 )
228 uW / 130 uW
MHT + GRC [4] DCT + MBPZC [5] Proposed
4 for first 4x4, 
2 for Pipeline Stage
2 for each 4x4
Technology UMC 90 nm UMC 90 nm UMC 90 nm
Encoder
Decoder
2 for first 1x8, 
1 for Pipeline Stage
 
 
D. The Bitplane Truncation with Pattern Comparison Coding Embedded Compressor/Decompressor 
(1) Proposed BTPCC Embedded Compression Algorithm 
(i) Algotrithm 
The proposed algorithm compresses a 4x2 block (64-bit) from the output of the deblocking filter. The CR 
is fixed at 2. After compressing, a 4x2 block will become a 32-bit segment. With fixed CR, the amount of the 
coded data is constant. Therefore, this compression can guarantee access times. Besides, in H.264 standard, a 
4x4 block which is a basic coding unit can be partitioned into two 4x2 blocks.  
Figure 28 shows the flowchart of the proposed compression algorithm. We divide the algorithm into four 
parts: 1) Pixel Truncation, 2) Selective Bitplane, 3) Rounding, and 4) Pattern Comparison. These parts will be 
described in the following paragraphs. The compressed 32-bit segment format is shown in Figure 29. The 
representation format consists of 2-bit Mode, 2-bit Start Plane (SP), 2-bit Decision L, 2-bit Decision R, 12-bit 
Coded Data L, and 12-bit Coded Data R.  
4x2 Block
Pixel Truncation
Selective Bitplane
Rouding
Left 2x2 Block Right 2x2 Block
Pattern Comparison
Bitstream Packer
32-bit Segment
Pattern Comparison
 
Figure 28 Compression flow of the proposed algorithm 
 42 
B7 != All 0's
NO
YES
B6 != All 0's
NO
YES
B5 != All 0's
NO
YES
B7 != All 0's
NO
YES
B6 != All 1's
NO
YES
B5 != All 0's
NO
YES
B7 != All 1's
NO
YES
B6 != All 0's
NO
YES
B5 != All 0's
NO
YES
B7 != All 1's
NO
YES
B6 != All 1's
NO
YES
B5 != All 0's
NO
YES
Bitplane Transform
Mode 3Mode 2Mode 1Mode 0
Truncated 4x2 Block
Select Maximum Start Plane and Record Mode
SP=0
SP=1
SP=2
SP=3 SP=3
SP=2
SP=1
SP=0 SP=0
SP=1
SP=2
SP=3
SP=0
SP=1
SP=2
SP=3
Start Plane Mode  
Figure 31 Flowchart of the selective bitplane 
 
We define that B7 represents the MSB plane while B0 represents the LSB plane. Second, the start plane 
(SP) is searched for four successive bitplanes from the MSB bitplane with four modes as follows: 1) from B7 
to B5 are all-0, 2) B6 is all-1; B7 and B5 are all-0, 3) B7 are all-1; B6 and B5 are all-0, and 4) B7 and B6 are 
all-1; B5 is all-0. In the first mode, if both B7 and B6 are all-0 and B5 is not all-0, then SP is equal to 1. 
Similarly, the other modes like as the first mode. Finally, the maximum start plane of four modes is selected to 
record the mode and start plane.  
 
C. Rounding 
Since lower bitplanes are truncated due to the limited budget, a simple rounding is applied here. The 
rounding is applied when the significant bit of the truncated bits is nonzero and the coded bits are not all 1’s. 
In Figure 32(a), the simple idea is shown. This idea leads to a satisfied quality improvement. Two rounding 
modes are proposed because the pattern comparison has two data compressed formats. As shown in Figure 
32(b), the first one is the compressed code rounding and the other is the uncompressed rounding. For pattern 
comparison, the first rounding method is applied to the first three types and the second rounding method is 
only for the final type.   
0 1 0 1 1 0 01
Start Plane
End Plane
0 1 1 1 1 0 00
Coded
bits
Truncated
bits
MSB LSB
Input Pixel
Output Pixel
Significant
bit
 
0 1 0 1 1 0 01
Significant
bit
Start 
Plane
3-bit
Input 
Pixel
2. Uncompressed Code Rounding
0 1 0 1 1 0 01
Significant
bit
Start 
Plane
4-bit
Input 
Pixel
1. Compressed Code Rounding
 
(a) (b) 
Figure 32 Flowchart of the rounding 
 
 
 44 
4x2
Block
Pixel
Truncation
Selective
Start Plane
Rounding
Selective
Pattern 
Comparison
Packer
32 bits
segment
Stage 1 Stage 2
 
Figure 34 Compressor architecture 
 
 
(ii) Decompressor Design 
Figure 35 shows the pipeline architecture of decompressor. The decompressor only needs one stage with 
one cycle, including parser, start plane decoding, and pattern decoding. This decompressor reaches a higher 
throughput; therefore we can provide a higher random accessibility.  
 
 Reconstructed
4x2 Block
Parser
Start Plane
Decoding
Pattern
Decoding
Stage 1
32 bits
segment
 
Figure 35 Decompressor architecture 
 
(3) System Integration  
The overall H.264 decoder [31] with the embedded compression codec is shown in Figure 36. The 
embedded compressor works between the deblocking filter and the external memory. The embedded 
decompressor works between the external memory and the motion compensation. To design address controller 
of EC is very simple since our compression ratio is fixed at two. Our system bus is 32 bits and the external 
memory is 32 bits per entry.  
 
 46 
(4) Experimental Results 
Table 11 PSNR Comparison shows the software result of the proposed algorithm which is integrated with 
JM16.2. The test sequences are Akiyo, Forman, Mobile, Stefan, and Station. Each test sequence executes 100 
frames. And then the average PSNR value is calculated. Results show that the PSNR loss of the proposed 
algorithm is from 1.27 to 3.94dB.  
Table 11 PSNR Comparison 
Sequence Format H.264 (dB) Proposed (dB) PSNR loss 
Akiyo CIF 43.72 41.16 2.56 
Forman CIF 41.23 39.20 2.03 
Mobile CIF 37.61 34.14 3.47 
Stefan CIF 38.82 34.88 3.94 
Station HDTV 39.12 37.84 1.27 
 
Table 12 shows the comparison among previous work. It can be found that our proposed hardware 
provides less hardware complexity and better visual quality. Especially, the proposed decoder just requires one 
cycle with higher random accessibility for embedded compression without degrading overall system 
performance. The power consumption of the proposed hardware is better than Lee’s [16] and Wu’s [31]. 
Figure 37 shows the Station sequence result of the original system with EC in HDTV format. The propagation 
of quality loss is unavoidable but video quality remains acceptable.  
 
Figure 37 Simulation result of station sequence (HDTV) 
 
 
 
 48 
On the other hand, we often produce extra overhead for getting neighbour information and requesting 
data from external memory. So, we optimize our memory system to solve this problem. We prefetched and 
compressed the neighbour information to reduce the storage and the latency.  
 
A. Prediction Process 
This section we proposed three methods to raise throughput at limited resource by single-bin engine.  
Raised Hit Rate – In the Figure 39(a) and Figure 39(b), they are traditional arithmetic engine decoding 
flow. In the beginning, we have current value of Range and Offset before we decoded the bin. After we read 
the value of LPS range, we can know offset is in the field of MPS or LPS. In fact, we can recognize the trend 
that the bin may be MPS before we decoded the bin. Before we get the LPS range, we already have current 
value of Range and Offset. So, if we observe the difference between Range and Offset, we can find out when 
difference is the larger and MPS rate is the higher. And then, following this principle we use two bits 
according as Table 13 to recognize which status is mostly happened. We can make sure next bin at status “00” 
and ‘11”, because the value are over the limit of standard. This result can significantly raise hit rate, but the 
other status still cause prediction miss. Actually, we also can use this method to pState and so on. The extra 
two bits can raise hit rate when we are at status “01” or “10” and can produce at the same time when 
processing difference. So, it couldn’t increase critical path in our prediction process. Finally, we can make 
sure at status “00” and “11” and have four-bit tips to predict what next bin is at status “01” and “10”. 
Fortunately, we overall got more than 90% hit rate in our simulation results by our prediction process.  
 
 50 
B. Memory System 
This section we proposed three methods to reduce cost, latency and memory bandwidth requirement.  
(1) Solved Syntax Element Switching Overhead (SESO) –In the previous work [3], we can clearly 
understand the effect of SESO that seriously decreased performance. In the other issue, getting neighbor 
information may enhance the latency when we access data from external memory. When we request data from 
system bus, the latency may exceed over our estimate significantly. The reasons could be system clock are 
asynchronous with external memory, other module compete memory bandwidth requirement especially for 
Motion Compensation and so on. So, this may be a potential problem even if original storage aren’t huge than 
other module. The immediate solutions are included an internal memory to store all information we need, but 
this method will get large overhead when we upgrade to HD sequences. We should include almost 20 Kbits 
SRAM even double in MBAFF for CABAC. So, this is inefficient to implement. To overcome these 
unexpected problems, the best solutions are reduced the stored neighbor information. In our works, we 
prefetch the data to simplified buffer (described in following paragraph) when decoding first SE of 
MacroBlock (MB) and precalculate SE for neighbor MB. Therefore, we adjust the latency for getting neighbor 
data to average 1.333 cycles/MB.  
(2) Reduced MEM. BW. Occupation – In our analysis, motion vector different (mvd) is the biggest part 
of all neighbor information. However, we shouldn’t use the total bits to calculate next ctxIdx. We show the 
control conditions at the Figure 40(a) from standard, and we find out most of cases can be determined by two 
bits. So, we store each mvd from 10 bits to 2 bits and use 5 bits to store extra mvd when it’s bigger than 3 just 
like Figure 40(b). When we need to refer the mvd, we should access 2 bits mvd and extra mvd which is bigger 
than 3from external memory. And, in our analysis, most of mvd are smaller than 2. Finally, we can efficiently 
reduce about 70% storage in our simulation by this method. 
 52 
First, we parallel the bin-decoded process and ctxIdx- calculated process by two independent paths, and 
we record each status of pipeline stages in shift register from SE parser. So, we can break the data dependency 
by prediction process and controlled SE parser. By the way, we use multiplexer and buffers to choose context 
(valMPS and pState) or up which can be data reused or not.  
Second, we may find a problem when we calculate the ctxIdx. That is we need neighbour information to 
calculate current ctxIdx. So, we increase one stage to deal with this problem and are shown in Figure 42. 
Actually, syntax elements are produced after second stage, and the third stage can’t affect the pipeline. In the 
other problems, the mvd which is bigger than 3 is too dispersed to achieve high storage reduction. So, we 
implement a transfer unit to compress data. This unit compresses at most 6 5-bit mvd to adaptive 32-bit BUS, 
and the transmission times can be reduced significantly. Oppositely, we should increase an inverse transfer 
unit to decompress data when we need to reference data.  
Bit
Buff.
AD DB
Bin
Buff.
valSE
Buff. CC
Output (Next module)
Input
Left Neighbor 
Buffer
Compress
Data
Top Neighbor 
Buffer
CtxIdx
Calculate
Decompress
Data
Current
Status
Prediction
Transfer
 
Figure 42: Architecture of Proposed Memory System 
Third, we integrate the prediction process (Part A) and memory system (Part B) to our proposed CABAC 
decoder which is shown in Figure 43. In our design, this may cause data hazard problem in some special cases 
or SEs, for example, coded_block_pattern. Therefore, we should increase a forward process to deal with this 
problem and use multiplexer to select regular path or forward path. On the other hand, we should have a unit 
to deal with miss penalty. When we predict miss, the status registers can’t be shifted. We should stall one cycle 
to calculate correct ctxIdx, and we use previous bin instead of predicted bin. Finally, we make a FSM to 
control initialization process and decoding process. 
 54 
In other works, we reduce the storage and test in full-HD sequences. We count the range distribution of 
mvd and show our results which compared with our optimal and traditional solutions in Figure 44. And, we 
get reduction rate from 58.01% to 75.13%. It means we can reduce bandwidth requirement or system buffer 
utilities efficiently.  
0
500,000
1,000,000
1,500,000
2,000,000
2,500,000
3,000,000
3,500,000
4,000,000
4,500,000
shields
stockholm
parkrun
riverbed
station
sunflower
Reduce
Optimal
 
Figure 44: Reduce Rate of Memory System 
 
 
The RTL simulation result shows that the proposed design can decode 0.95 bins per cycle in average. The 
synthesis results of proposed architecture and a performance comparison with previous works are shown in 
Table 15. By applying the mechanisms, the proposed architecture can efficiently reduce at least 45% hardware 
cost than previous works. However, we still can achieve Level 5.0 MP. The maximum throughput of the 
proposed design is 239.4 Mbins/s and the maximum working frequency is 249 MHz.  
 
 
 
 
 
 
 56 
described in the following paragraphs. The compressed 32-bit segment format is shown in Figure 46. The 
representation format consists of 2-bit Mode, 2-bit Start Plane (SP), 2-bit Decision L, 2-bit Decision R, 12-bit 
Coded Data L, and 12-bit Coded Data R.  
4x2 Block
Pixel Truncation
Selective Bitplane
Rouding
Left 2x2 Block Right 2x2 Block
Pattern Comparison
Bitstream Packer
32-bit Segment
Pattern Comparison
 
Figure 45: Compression flow of the proposed algorithm 
 
Mode Start Plane
2-bit
Decision RDecision L
2-bit
Coded Data L Coded Data R
12-bit 12-bit2-bit 2-bit
Header
 
Figure 46: Compressed 32-bit segment format 
 
 
 
A. Pixel Truncation 
Figure 47 shows the flowchart of the pixel truncation. First, we calculate the average value (Avg.) of the 
4x2 block and the difference value (Diff.) between maximum pixel and minimum pixel of the 4x2 block. 
Second, according to the average and the difference, we classify those 4x2 sub-blocks into five types as the 
following: 1) Avg. from 0 to 63 and Diff. less than 32, 2) Avg. from 64 to 127 and Diff. less than 64, 3) Avg. 
from 128 to 191 and Diff. less than 64, 4) Avg. from 192 to 255 and Diff. less than 32, and 5) no change. In 
type 1, if each pixel is larger than or equal to 64, we force the pixel to be 63. In type 2, if each pixel is less 
than 64, we force the pixel to be 64; if each pixel is larger than or equal to 128, we force the pixel to be 127. 
Types 3 and 4 are processed like types 2 and 1 respectively. In type 5, the original pixel value remains 
unchanged.  
 58 
We define that B7 represents the MSB plane while B0 represents the LSB plane. Second, the start plane 
(SP) is searched for four successive bitplanes from the MSB bitplane with four modes as follows: 1) from B7 
to B5 are all-0, 2) B6 is all-1; B7 and B5 are all-0, 3) B7 are all-1; B6 and B5 are all-0, and 4) B7 and B6 are 
all-1; B5 is all-0. In the first mode, if both B7 and B6 are all-0 and B5 is not all-0, then SP is equal to 1. 
Similarly, the other modes like as the first mode. Finally, the maximum start plane of four modes is selected to 
record the mode and start plane.  
 
C. Rounding 
Since lower bitplanes are truncated due to the limited budget, a simple rounding is applied here. The 
rounding is applied when the significant bit of the truncated bits is nonzero and the coded bits are not all 1’s. 
In Figure 49(a), the simple idea is shown. This idea leads to a satisfied quality improvement. Two rounding 
modes are proposed because the pattern comparison has two data compressed formats. As shown in Figure 
48(b), the first one is the compressed code rounding and the other is the uncompressed rounding. For pattern 
comparison, the first rounding method is applied to the first three types and the second rounding method is 
only for the final type.   
0 1 0 1 1 0 01
Start Plane
End Plane
0 1 1 1 1 0 00
Coded
bits
Truncated
bits
MSB LSB
Input Pixel
Output Pixel
Significant
bit
 
0 1 0 1 1 0 01
Significant
bit
Start 
Plane
3-bit
Input 
Pixel
2. Uncompressed Code Rounding
0 1 0 1 1 0 01
Significant
bit
Start 
Plane
4-bit
Input 
Pixel
1. Compressed Code Rounding
 
(a) (b) 
Figure 49: Flowchart of the rounding 
 
 
D. Pattern Comparison 
The final step encodes the preserving bitplanes. First, the truncated 4x2 block is partitioned into two 2x2 
blocks that are called the left 2x2 block and the right 2x2 block as shown in Figure 50(a). In Figure 50(b), 
both the left 2x2 block and the right 2x2 block exploited the equal SP and compressed individually. Second, 
four types for a 2x2 block is classified as follows: 1) Group A, 2) Group B, 3) Group C, and 4) 
 60 
 
 
B. Decompressor Design 
Figure 52 shows the pipeline architecture of decompressor. The decompressor only needs one stage with 
one cycle, including parser, start plane decoding, and pattern decoding. This decompressor reaches a higher 
throughput; therefore we can provide a higher random accessibility.  
 Reconstructed
4x2 Block
Parser
Start Plane
Decoding
Pattern
Decoding
Stage 1
32 bits
segment
 
Figure 52: Decompressor architecture 
 
(3) System Integration 
The overall H.264 decoder with the embedded compression codec is shown in Figure 53. The embedded 
compressor works between the deblocking filter and the external memory. The embedded decompressor works 
between the external memory and the motion compensation. To design address controller of EC is very simple 
since our compression ratio is fixed at two. Our system bus is 32 bits and the external memory is 32 bits per 
entry.  
 62 
Table 17: All Cases of Read Access Requirement 
Case of MV (x, y) 
Access Cycles for 
System without EC 
Access Cycles for 
System with Proposed 
EC 
Reduction of Access 
Cycles without EC 
(Align, Align) 4 2 50 
(Align, Not Align) 4 2/3 50/25 
(Align, Sub) 9 5 44.4 
(Not Align, Align) 8 4 50 
(Not Align, Not Align) 8 4/6 50/25 
(Not Align, Sub) 18 10 44.4 
(Sub, Align) 12 6 50 
(Sub, Not Align) 12 6/9 50/25 
(Sub, Sub) 27 15 44.4 
Average 13.2 6.8~6.9 49.1~48.3 
 
 
(4) Experimental Results 
Table 18 shows the software result of the proposed algorithm which is integrated with JM16.2. The test 
sequences are Akiyo, Forman, Mobile, Stefan, and Station. Each test sequence executes 100 frames. And then 
the average PSNR value is calculated. Results show that the PSNR loss of the proposed algorithm is from 1.27 
to 3.94dB.  
Table 18: PSNR Comparison 
Sequence Format H.264 (dB) Proposed (dB) PSNR loss 
Akiyo CIF 43.72 41.16 2.56 
Forman CIF 41.23 39.20 2.03 
Mobile CIF 37.61 34.14 3.47 
Stefan CIF 38.82 34.88 3.94 
Station HDTV 39.12 37.84 1.27 
 
 
 
Table 19 shows the comparison among previous work. It can be found that our proposed hardware 
provides less hardware complexity and better visual quality. Especially, the proposed decoder just requires one 
cycle with higher random accessibility for embedded compression without degrading overall system 
performance. The power consumption of the proposed hardware is better than Lee’s [31] and Wu’s [32]. 
Figure 54 shows the Station sequence result of the original system with EC in HDTV format. The propagation 
of quality loss is unavoidable but video quality remains acceptable.  
 
 
 
 
 
 64 
(3) The Reduced Patterns Comparison Embedded Compressor/Decompressor 
(4)The Bitplane Truncation with Pattern Comparison Coding Embedded Compressor/Decompressor 
(5) An Area-efficiently High-accuracy Prediction-based CABAC Decoder for H.264/AVC 
(6) A Predefined Bit-Plane Comparison Coding for Mobile Video Applications 
We described as below: 
 
First, we proposed a flexible algorithm which achieves good coding efficiency and is suitable to be 
integrated with any video decoder. The proposed architecture is synthesized with 90-nm CMOS standard-cell 
library. The operation frequency is 108 MHz. The gate counts of proposed algorithm for 
compressor/decompressor are 15.8K/14.2K respectively. With the help of this embedded compression engine, 
we can reduce the bandwidth requirement and the external frame memory size. The proposed architecture 
costs 30K gate counts and deals with a 4x4 block unit while MHT costs 20K gate counts in dealing with a 1x8 
pixels array. The proposed algorithm not only gains 5.29dB in picture quality but also achieves an 
area-efficient hardware implementation. 
Second, we propose a high-profile intra predictor to support MBAFF and Luma intra_8x8 decoding. The 
proposed memory hierarchy includes upper, left and corner memory buffer which reuses the neighboring 
pixels for follow-up prediction procedures. In Luma_8x8 decoding process, we propose base-mode predictors 
to minimize the additional hardware cost, latency penalty, and filtered pixel buffer memory size. Compared to 
the existing design [10] without supporting intra 8x8 coding, this design only introduce 10% and 7.5% of  
gate counts and SRAM overheads. The proposed design can achieve real-time processing requirement for 
HD1080 format video in 30fps under the working frequency of 100MHz. 
Third, we have proposed a new embedded compression algorithm for mobile video applications. With 
these advantages of the proposed EC engine, we can lessen the size of external memory and bandwidth 
utilization to achieve the goal of power saving. Due to the fixed Compression Ratio, the proposed function is 
easy to be integrated with an H.264 system. The proposed architecture is synthesized with 90-nm CMOS 
standard-cell library and the gate counts of the proposed algorithm for embedded compressor/decompressor 
are 1.8K/3.1K respectively. The average PSNR loss of proposed algorithm is 5.98 dB. The working 
frequencies are 5 (CIF), 100 (HD 720) and 150 (HD 1080 + HD720) MHz depending on different operation 
 66 
 
四、 參考文獻 
[1] R. J van der Vleuten et al, “Low-complexity scalable DCT image compression”, IEEE Proc. Image 
Processing, vol.3 pp. 837-840, Sep. 2000 
[2] Yongje Lee; Chae-Eun Rhee; Hyuk-Jae Lee; “A New Frame Recompression Algorithm Integrated with 
H.264 Video Compression” Circuits and Systems, 2007. ISCAS 2007. IEEE International Symposium, 
pp. 1621-1624, May 2007 
[3] A. Bourge and J. Jung, “Low-Power H.264 Video Decoder with Graceful Degradation,” SPIE Proc. 
Visual Commun. and Image Process., vol. 5308, pp. 1234-1245, Jan. 2004 
[4] T.-Y. Lee, “A New Frame-Recompression Algorithm and its Hardware Design for MPEG-2 Video 
Decoders,” IEEE Trans. CSVT, vol. 13, no. 6, pp. 529-534, June 2003.  
[5] Byeong Lee, “A new algorithm to compute the discrete cosine Transform” Acoustics, Speech, and Signal 
Processing, IEEE Transactions on Volume  32,  Issue 6,  pp:1243-1245, Dec 1984  
[6] Joint Video Team, Draft ITU-T Recommendation and Final Draft International Standard of Joint Video 
Specification, ITU-T Rec. H.264 and ISO/IEC 14496-10 AVC, May 2003.  
[7] T. Wiegand, G. J. Sullivan, G. Bjontegaard, and A. Luthra, “Overview of the H.264/AVC video coding 
standard,” IEEE Trans. on Circuits and Systems for Video Technology, vol. 13, no. 7, pp. 560–576, July 
2003.  
[8] Yu-Wen Huang, Bing-Yu Hsieh, Tung-Chien Chen, and Liang-Gee Chen, “Hardware architecture design 
for H.264/AVC intra frame coder”, ISCAS 2004.  
[9] Esra Sahin and Ilker Hamzaoglu, “An Efficient Intra Prediction Hardware Architecture for H.264 Video 
Decoding”, DSD 2007.  
[10] Jia-Wei Chen, Chien-Chang Lin, Jiun-In Guo, and Jinn-Shyan Wang, “Low Complexity Architecture 
Design of H.264 Predictive Pixel Compensator for HDTV Application”, ICASSP 2006.  
[11] Ting-An Lin, Sheng-Zen Wang, Tsu-Ming Liu and Chen-Yi Lee, “An H.264/AVC Decoder with 4x4 
Block-Level Pipeline,” Proc. ISCAS, pp. 1810-1813, May, 2005.  
[12] Tsu-Ming Liu and Chen-Yi Lee, “Design of an H.264/AVC Decoder with Memory Hierarchy and 
Line-Pixel-Lookahead,” Journal of VLSI Signal Processing Systems, Aug. 2007. 
[13] “ITU-T Recommendation H.264 and ISO/IEC 14496-10, Advanced Video Coding for Generic 
Audiovisual Services”, May 2003.  
[14] T. Wiegand, G. J. Sullivan, G. Bjøntegaard, and A. Luthra, “Overview of the H.264/AVC video coding 
standard,” IEEE Trans. Circuits Syst. Video Technol., vol. 13, no. 7, pp. 560–576, July 2003.  
[15] R. Manniesing, R. Kleihorst1, R. V. Vleuten1, and E. Hendriks, “Implementation of lossless coding for 
embedded compression,” IEEE ProRISC, 1998.  
[16] T. Y. Lee, “A New Frame-Recompression Algorithm and its Hardware Design for MPEG-2 Video 
Decoders,” IEEE Trans. CSVT, vol. 13, no.6,   pp. 529-534, June 2003. 
[17] Y. D. Wu, Y. Li, and C. Y. Lee, “A Novel Embedded Bandwidth-Aware Frame Compressor for Mobile 
Video Applications,” in Proc. IEEE Intelligent Signal Processing and Communication Syst. (ISPACS), 
pp. 1-4, Feb 2009. 
[18] C. K. Yang and W. H. Tsai, “Improving block truncation coding by line and edge information and 
adaptive bit plane selection for gray-scale image compression,” Pattern Recognition Letter, vol. 16, pp. 
67-75,  1995. 
[19] T. M. Amarunnishad, V. K. Govindan, and T. M. Abraham, “Block Truncation Coding Using a Set of 
Predefined Bit Planes,” in Proc. IEEE Int. Conf. Computational Intelligence and Multimedia Applications 
(ICCIMA), vol. 3, pp. 73-78, Dec 2007.  
[20] “Draft ITU-T recommendation and final draft international standard of Joint Video Specification (ITU-T 
Rec. H264-ISO/IEC 14496-10:2005 AVC),” JVT G050, 2005.  
[21] J. Kim, and C. M. Kyung, “A Lossless Embedded Compression Using Significant Bit Truncation for HD 
Video Coding,” IEEE Trans. CSVT,   accepted, 2010.  
[22] T. M. Liu, and et al., “A 125/spl mu/w, fully scalable MPEG-2 and H.264/AVC video decoder for mobile 
applications,” in Proc. IEEE Int. Solid-State Circuits Conference (ISSCC), pp. 1576–1585, 2006. 
[23] Joint Video Team (JVT) of ISO/IEC MPEG&ITU-T VCEG, “Joint Draft ITU-T Rec. H.264 | ISO/IEC 
14496-10/Amd.3 Scalable video coding,” July 2007. 
 68 
國科會補助專題研究計畫成果報告自評表 
請就研究內容與原計畫相符程度、達成預期目標情況、研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）、是否適
合在學術期刊發表或申請專利、主要發現或其他有關價值等，作一綜合評估。 
1. 請就研究內容與原計畫相符程度、達成預期目標情況作一綜合評估 
■ 達成目標 
□ 未達成目標（請說明，以 100 字為限） 
□ 實驗失敗 
□ 因故實驗中斷 
□ 其他原因 
說明： 
 
 
 
2. 研究成果在學術期刊發表或申請專利等情形： 
論文：■已發表 □未發表之文稿 □撰寫中 □無 
專利：□已獲得 □申請中 ■無 
技轉：□已技轉 □洽談中 ■無 
其他：（以 100 字為限） 
 
 
 
3. 請依學術成就、技術創新、社會影響等方面，評估研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）（以
500 字為限） 
在此計畫執行中，我們提供兩個可應用於行動通訊之下世代低功耗視訊解碼
器元件，其中分別為： 
(A)An Area-efficient High-accuracy Prediction-based CABAC Decoder for 
H.264/AVC. 
(B)A Predefined Bit-Plane Comparison Coding for Mobile Video 
Applications. 
所提的低功耗視訊解碼方案,可提供行動視訊應用下,有效降低傳輸頻寬和節
能的需求,有助於提升行動裝置的使用時限. 
 
 
 
 70 
解除困惑。 
 
二、與會心得 
學生本次是錄取會議的 poster 部分，不同於會議報告的方式，有更多的時間和機會與其他人交
談並分享經驗。 
除了聽一些 technical lecture，我也有去參加 keynote speech，印象最深也最有興趣的就是微軟工
程師講解對於未來人體和電子晶片中間的 touch interface，這讓吾人想到最近當紅的 iPhone，就是
強打良好的觸控式介面，使人面在使用電子產品的時候，更加人性化和也更增進不少娛樂性，而
微軟現今也在電視遊樂器上 XBOX 引進 motion detection 方法，讓玩家不用任何的硬體設施介面就
能模擬臨場的效果，讓人們在遊戲上除了考慮益智也能考驗姿體的協調度，讓玩遊戲機不再只是
呆坐在位子上，而是讓玩遊戲也好像到戶外運動一樣，提高了電子產品在娛樂性上更高的層面，
而微軟已經在實驗是否將一些 touching 的介面轉移到人體的思考和肌膚表面，透過腦波和身體的
震動波偵測判別，將訊號輸入到電子晶片上，達到免手持硬體輸入介面以提高便利性。 
除了演講上的新知吸收，這次會議中也有 coffee break、welcome party、banquet 能和來自各地的
人士交流機會，除了更多了解不同領域還有不同研究環境的訓練方式，更提升自己不少英文聽力
和口說能力，如何能不失禮貌且親和的與人在宴會或者餐桌上談話，也是一種學問。 
 
三、考察參觀活動(無是項活動者略) 
四、建議 
如果是 poster的話，如果可以有現場 demo會更吸引人 
五、攜回資料名稱及內容 
1. 2011 ISCAS電子檔案論文。 
2. 2011 ISCAS會議手冊。 
3. 2011 ISCAS紀念後背包。 
4. 2011數本電路設計相關紙本期刊。 
5. 2012各大電子電路 conference的 call for paper。 
六、其他 
 
97 年度專題研究計畫研究成果彙整表 
計畫主持人：李鎮宜 計畫編號：97-2221-E-009-167-MY3 
計畫名稱：應用於行動通訊之下世代低功耗視訊解碼器 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 3 3 100%  
博士生 2 2 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 1 1 100%  
研究報告/技術報告 3 3 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
