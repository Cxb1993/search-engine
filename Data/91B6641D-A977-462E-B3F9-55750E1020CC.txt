 I 
 
 
 
摘要 
 
在這份報告中，我們將深入探討活動辨識(Activity Recognition)的研究並著重在
多人環境中的活動辨識。在建構一個智慧型家庭(Smart Home)時，多人環境的活動
辨識是一個主要的挑戰。我們首先使用條件機率場(Conditional Random Field)建
模多人活動辨識並以不同方式評估結果，以期推廣條件機率場在多人活動辨識上的
應用。為評估結果，我們使用了 Washington State University 提供的 CASAS 
dataset。結果顯示，人與感測器(Sensor)之間的資料關聯性對於改善多人活動辨
識的效果極為重要。此外，這個結果顯示，若要進一步改善準確性，可加入人與人
互動性做為參考。根據這樣的結果，我們設計一個考量人與人互動性的新的模型，
這個模型是架構於動態貝式網路(Dynamic Bayesian Network)上的對偶隱藏馬可夫
鏈(Coupled Hidden Markov Model)，並增加一些節點來建模個人和合作的活動。
實驗的結果顯示，這個模型比基本的分類器效果來得好。 
 
關鍵字: 智慧家庭，機率式行為辨識，隱藏式馬可夫鍊，條件機率場 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 III 
目錄 
 
一、前言 ……………………………………………………………………………  1 
二、資料集 …………………………………………………………………………  2 
三、資料配對與多人行為辨識 ……………………………………………………  2 
四、使用者互動與多人行為辨識 ………………………………………………… 11 
五、結語 …………………………………………………………………………… 18 
六、參考文獻 ……………………………………………………………………… 19 
Table 1: The 15 activities asked to perform by residents in CASAS project
individual cooperative
Filling medication dispenser Moving furniture
Hanging up clothes Playing checkers
Reading magazine Paying bills
Activity Sweeping floor Gathering and packing picnic food
Setting the table
Watering plants
Preparing dinner
of data association and that of activity estimation. After that, we design a new
probabilitic model to use the context of human interactions between residents for
acivity recognition. In this work, the interactive activities we deal with are those
cooperative, or specifically, probabilistically dependent ones.
2 Dataset
In this report, we use the CASAS dataset to run our experiments. The CASAS
“WSU Apartment Testbed, ADL Multiresident Activities” dataset is collected by
the CASAS project in the WSU smart workplace[14]. There are 26 files of differ-
ent participant pairs containing sensor events and their corresponding annotations
whereby we utilize to validate our proposed models. There are about 400 to 800
sensor events in each file, totally 17,238 events in this dataset. The data represent
two residents being asked to perform 15 activities of daily living (ADLs), which
are shown in Table1. Of these activities, some are individual activities, which are
performed by one resident and which are independent to the activities performed
by other residents. On the other hand, cooperative activities are performed by one
or more residents, and multiple activities are dependent. The deployed sensors
include motion sensors, item sensors, and cabinet sensors (see Figure 2). The out-
put format of a sensor event and its annotation is (Date, Time, SensorID, Value,
ResidentID, TaskID). The detail of the dataset can be found in [13].
3 Data association and multi-resident activity recog-
nition
The previous work on multi-subject activity recognition generally follow the fol-
lowing procedures for recognizing activities of multiple residents. First, sensor
2
(a) The flowchart for general multiple-resident activity recognition
(b) The flowchart for iterative training data association and activity recognition
Figure 2: The environment in CASAS smart home project
data are preprocessed and then transformed into feature vectors whereby the pa-
rameters of activity models are learnt. The transformed features are used to deter-
mine the data association variables and the determined variables can assist to infer
activities. Figure2(a) shows the flowchart for the above-noted general multiple-
resident activity recognition.
For describing our models, several issues should be addressed. The first issue
is the problem we intend to handle and the notation definitions. The second is
how to preprocess sensor data. The third is the material of conditional random
field (CRF) applied to resolve multiple-resident activity recognition. The fourth is
the mechanism to iteratively gain the data association variables and the activities.
The last is the decomposition inference given the data association.
3.1 Problem Formulation
The associated notations are introduced here in recognizing activities of two resi-
dents. Given n observations O1:n, and define each observation at time t as a vector,
Ot = (Datet ,Timet ,SensorIDt ,Valuet). Let the preformed activities be A1:n and
the data association sequence be θ1:n, where At = 1, . . . ,15 (each one is an index
to an activity of interest) and θ1:n=1,2 which indicates that the observation Ot is
triggered by the θt-th resident. To be unambiguous, activity At is defined to be
performed by the θt-th resident at time t. The purpose of multiple-resident activ-
ity recognition is to determine A1:n and θ1:n given O1:n without prior knowledge
between A1:n and θ1:n.
3.2 Data Preprocessing for Data association Experiment
For each time slice, the preprocessed data are fed into the recognizer. Three types
of preprocessed data are concerned: raw data, environment data and room-level
data. The raw data refer to the data with the date and time removed from Ot .
4
Figure 4: The graphical representation of the linear-chain conditional random
field.
Figure 5: The graphical representation of the CRF for multiple-resident activity
recognition.
feature function) between these vertices (random variables). If C is the set of
cliques in G, in conditional random fields, we can define a condition probability
P(Y |X) = 1
Z(X) exp{∑c∈C λc fc(Xc,Yc)}, where Yc and Xc are random variables in
a clique c in G, Z(X) is a normalization factor, fis are the feature functions, and
λis are the parameters of this CRF. For example, Figure3.3 is a typical linear-
chain conditional random field (LCRF) model. X = {X1, . . . ,Xn} is a observation
sequence, and Y = {Y1, . . . ,Yn} is a state sequence. In this CRF model, there are
two kinds of feature functions: fts for transition model and gts for observation
model. The condition probability in this CRF model is
P(Y |X) =
1
Z(X)
exp
{
n−1
∑
t=1
θt ft(yt ,yt+1)+
n
∑
t=1
λtgt(yt ,xt)
}
where Θ = {θt}
n−1
t=1 and Λ = {λt}
n
t=1 are the parameters to be learned from
training data.
Optimization methods like conjugate gradient[12] and improved iterative scaling[3]
can be used to train CRFs. The most commonly used method is an improved
quasi-Newton method called L-BFGS[10].
6
(a) The linear-chain CRF for initialization
(b) The CRF to infer the data association sequence
(c) The CRF to infer the activity sequence
Figure 6: The environment in CASAS smart home project
8
Table 2: Average and variance pairs for distinct models and data preprocessing.
Decomp. denotes the decomposition method.
Iteractive Decomp. (transition) Decompo. (iterative)
raw data 0.5067 / 0.0139 0.5953 / 0.1070 0.6416 / 0.0128
environment data 0.3323 / 0.0950 0.3026 / 0.0083 0.3425 / 0.0118
room level data 0.2449 / 0.0065 0.2333 / 0.0131 0.2655 / 0.0090
3.6.1 Experiment 1: Tendency of Data Preprocessing
Table3.6.1 shows the averaged accuracy for the three models we are interested
in, of which the best one is greater than the accuracy in [5] (0.6060), but still
not satisfacto-rily accurate. Moreover, the CRFs decomposition method outper-
forms others, which shows that if we can properly separate the dataset, we can
apply single-resident model to the multiple-resident problem. However, the in-
sufficient accuracy may be due to the nature of the human activity pattern un-
der the multiple-people condition. The CRF with iterative training is intuitively
competent in those files with more interactions than the one with decomposition
training. On the other hand, inferring the activities of two residents separately
performs well in the case of less relation between the resi-dents. However, the
dataset is a mixture of individual and cooperative activities, thus causing insuffi-
cient accuracy. The accuracy for models coupled with distinct preprocessed data
are also illus-trated in Table 2. Surprisingly, the highest accuracy occurs while the
model coupled with the raw data. This decline in accuracy for more manipulation
is probably attrib-uted to the sensitivity to noises. That is, taking all information
into consideration may result in overfitting to the noises. Furthermore, the lower
accuracy of room level data would seem to stem from little dependency between
room-level features and their associated activities.
3.6.2 Experiment 2: Correlation between data association and accuracy
In this experiment, we compare the existing mechanisms and the CRFwith decompo-
sition given data association. As shown in Table3.6.2, the accuracy of data asso-
ciation and the accuracy of activity are positively correlated. In addition, the low
accuracy of the model coupled with transition table may be due to three factors:
noise, smoothing and relevance of data association and activity. The transition
accuracy may be highly sensitive to the noise. Moreover, if a transition does not
appear in the training phase, data smoothing is required. Finally, according to the
dataset, it suggests that some activities are performed by a specific resident.
10
is essentially different to that in the object sensor event. In the dataset, 10 object
sensors are deployed, thus causing 20 possible cases for these object sensor events
because each object sensor has two states. With a null value being added, the car-
dinality is 21. For the location sensors in loc-obj and loc-obj with locoff feature
vector, a room-level granularity is choosed. That is, unlike the raw feature vector,
the location sensors are embedded into a measure space. Specifically, we divide
the environment into six regions as shown in Figure 3.2. Motion sensors in the
same region are aggregated and mapped to the same index. The cardinality of this
feature is seven because of the six regions and one null value. The loc-obj with
locoff feature vector adds an extra location related feature, locoff, into loc-obj fea-
ture vector. This feature records the “off” event of the motion sensor. Because we
also take a room-level granularity in this feature, the cardinality of this feature is
also seven. The locoff feature is used to indicate a recently occupied region that is
now empty and this design provides extra information or correction to the loc-obj
feature.
Finally, in all the three types of feature vectors, the dimension “interaction”
is defined to be a binary feature which captures the information of activities be-
tween each resident. This feature becomes 1 if and only if the two residents are
in the same region of the environment. We extract this feature because the “in-
teractive activities” we are interested in are cooperative activities. As shown in
Table1, these cooperative activities are usually performed by the residents in the
same room in the dataset. This feature contains the information about the human
interaction by observing if two residents are in the same region.
To sum up, we define three types of feature vectors, and each feature vector
is generated by one corresponding data preprocessing method. The three feature
vectors are raw, loc-obj, and loc-obj with locoff feature vector. These feature
vectors are represented as (event, interaction), (object, location, interaction), and
(object, location, off-location, interaction) respectively. We generate three types
of data according to these feature vectors in the data preprocessing step and eval-
uate their effectiveness in our experiments.
4.2 Human Interaction Modeling in Multi-resident Activity Recog-
nition
In order to compare the performance among different models, we adopt the fol-
lowing three models in this paper, which are all based on the typical hidden
Markov model. These three models are parallel hidden Markov model (PHMM),
coupled hidden Markov model (CHMM)[4], and a dynamic Bayesian network
which extends CHMM by adding some informative vertices.
12
Figure 7: PHMM consists of two independent HMMs.
=
P(O(1),O(2)|A(1),A(2))P(A(1),A(2))
P(O(1),O(2))
∝ P(O(1),O(2)|A(1),A(2))P(A(1),A(2))
Given the condition independence in the graphical structure of Figure 4.2.2,
we can factorize P(O(1),O(2)|A(1),A(2)) and P(A(1),A(2)) as follows:
P(O(1),O(2)|A(1),A(2))
= P(o
(1)
1 ,o
(2)
1 |a
(1)
1 ,a
(2)
1 ) . . .P(o
(1)
T ,o
(2)
T |a
(1)
T ,a
(2)
T )
=
T
∏
t=1
P(o
(1)
t |a
(1)
t )P(o
(2)
t |a
(2)
t )
and
P(A(1),A(2))
= P(a
(1)
1 ,a
(2)
1 )
T
∏
t=2
P(a
(1)
t ,a
(2)
t |a
(1)
t−1,a
(2)
t−1)
= ∏
m={1,2}
P(a
(m)
1 )
(
T
∏
t=2
P(a
(m)
t |a
(1)
t−1,a
(2)
t−1)
)
14
newly added vertices that the CHMM does not define, we can still separate the
joint probability of activity sequence as follows:
P(A(1),A(2))
= P(a
(1)
1 ,a
(2)
1 )
T
∏
t=2
P(a
(1)
t ,a
(2)
t |a
(1)
t−1,a
(2)
t−1)
= ∏
m={1,2}
P(a
(m)
1 )
(
T
∏
t=2
P(a
(m)
t |a
(1)
t−1,a
(2)
t−1)
)
The “state transition” parameters in this model are identical to those in a
CHMM. However, the observation and interaction feature sequences become
P(O(1),O(2), I|A1,A(2))
= P(o
(1)
1 ,o
(2)
1 , i1|a
(1)
1 ,a
(2)
1 )
T
∏
t=2
P(o
(1)
t ,o
(2)
t , it |a
(1)
t ,a
(2)
t , it−1)
= P(i1|a
(1)
1 ,a
(2)
1 )
(
T
∏
t=2
P(it |a
(1)
t ,a
(2)
t , it−1)
)(
∏
m={1,2}
T
∏
t=1
P(o
(m)
t |a
(m)
t , it)
)
,
where the probability of observation here depends on not only the activity but
also the interaction features.
We implement the three models using GMTK, the Graphical Models Toolkit[1].
The details about what inference and training algorithms are used by GMTK can
be found in the GMTK document. Note that the difference between the above
dynamic Bayesian network and the CHMM is whether the interaction feature is
taken into consideration. The reason we select these three models in this paper is
thus clear: the three models are similar with the exception of how much they take
the human interaction into account. We want to verify if this difference affects
the performance of these three models under a multi-resident environment. The
difference will be more clarified when comparing among Figure 4.2.1, 4.2.2, and
4.2.3. We can see the independent property, the cross edges, and the additional
interaction vertices in the three graphical models.
4.3 Experiments and Results of Human Interaction Modeling
order to examine whether taking human interaction into account can help a multi-
resident model get better accuracy, we make use of GMTK[1] to implement the
three models and run the experiments on the CASAS “WSU Apartment Testbed,
ADL Multiresident Activities” dataset. We run leave-one-out cross validation ex-
periments and use the three different data pre-processing methods we describe
16
Table 4: Experimental results of the three models running on the dataset with three
data preprocessing methods. Sub.1 and Sub.2 are resident 1 and 2’s activities, and
joint is counted when both Sub.1 and Sub.2 are correct. Int. CHMM is the CHMM
model with human interaction vertices.
PHMM CHMM Int. CHMM
Feature set Sub.1 Sub.2 Joint Sub.1 Sub.2 Joint Sub.1 Sub.2 Joint
loc obj 0.68 0.55 0.39 0.71 0.72 0.62 0.77 0.77 0.70
loc obj+locoff 0.70 0.58 0.43 0.73 0.73 0.62 0.77 0.78 0.69
raw 0.79 0.76 0.62 0.82 0.84 0.75 0.85 0.86 0.78
5 Conclusion
In this report, we proposed two recent research results for iCare2.0 project. We
first address the result of dealing with data association problem by applying CRFs
with different strategies, which include different ways to train a CRF and to pre-
process the dataset. We also investigate the importance of data association in
multiple-resident activity recognition. In the first experiment of this work, the
CRFs decomposition method outperforms other classi-fiers we proposed, which
shows that if we can properly decompose the dataset for each individual, we can
apply single-resident model to a multiple-resident problem to some degree. How-
ever, the insignificant accuracy of the CRF with decomposition training indicates
that totally ignoring the interactions among residents does compromise the recog-
nition accuracy. Moreover, in this experiment, preprocessing the dataset results in
low accuracies, which is contrary to our expectation. This result suggests that in
preprocessing a dataset, we have to take into consideration some factors such as
the noise in the dataset and the prior knowledge of the environment. In the second
experiment, we show that data association in a multi-resident environment is a
vital issue. If we have a good algorithm for data association problem, the activ-
ity recognition accuracy may be improved efficiently. This study shows that data
association is an inevitable issue in dealing with multi-resident activity recogni-
tion. It also reveals that modeling human interactions is also necessary in making
the system more reliable. We therefore encourage researchers to develop more
appropriate solutions for these two critical issues so that the methods proven ef-
fective for single-resident activity recognition can be extended and applied to a
multi-resident environment.
The second work in this report is to compare the new multi-resident activity
recognition model with two other directed graphical models including PHMMs,
CHMMs. We extract two kinds of features, the object used and the locations of
18
computing. In The 6th International Conference on Mobile and Ubiquitous
Systems: Computing, Networking and Services (MobiQuitous ’09), pages
1–10, Toronto, Canada, November 2009.
[6] John Lafferty, Andrew McCallum, and Fernandos Pereira. Conditional ran-
dom fields: Probabilistic models for segmenting and labeling sequence data.
In Proc. 18th International Conference on Machine Learning, pages 282–
289. Morgan Kaufmann, San Francisco, CA, 2001.
[7] Chia-Chun Lian and Jane Yung-jen Hsu. Probabilistic models for concur-
rent chatting activity recognition. In IJCAI’09: Proceedings of the 21st in-
ternational jont conference on Artifical intelligence, pages 1138–1143, San
Francisco, CA, USA, 2009. Morgan Kaufmann Publishers Inc.
[8] Iain McCowan, Daniel Gatica-Perez, Samy Bengio, Guillaume Lathoud,
Mark Barnard, and Dong Zhang. Automatic analysis of multimodal group
actions in meetings. IEEE Transactions on Pattern Analysis and Machine
Intelligence, 27:305–317, 2005.
[9] Nguyen Nguyen, Svetha Venkatesh, and Hung Bui. Recognising behaviours
of multiple people with hierarchical probabilistic model and statistical data
association. In BMVC06, volume 3, pages 1239–1248, 2006.
[10] Jorge Nocedal. Updating quasi-newton matrices with limited storage. Math-
ematics of Computation, 35(151):773–782, 1980.
[11] Judea Pearl. Probabilistic reasoning in intelligent systems: networks of
plausible inference. Morgan Kaufmann Publishers Inc., San Francisco, CA,
USA, 1988.
[12] Jonathan R Shewchuk. An introduction to the conjugate gradient method
without the agonizing pain. Technical report, Pittsburgh, PA, USA, 1994.
[13] Geetika Singla, Diane J. Cook, and Maureen Schmitter-Edgecombe. Rec-
ognizing independent and joint activities among multiple residents in smart
environments. Journal of Ambient Intelligence and Humanized Computing,
1(1):57–63, 2010.
[14] Washington State University. Casas smart home project. available:
http://ailab.eecs.wsu.edu/casas/.
[15] Tim van Kasteren, Athanasios Noulas, Gwenn Englebienne, and Ben Kro¨se.
Accurate activity recognition in a home setting. In UbiComp ’08: Proceed-
ings of the 10th international conference on Ubiquitous computing, pages
1–9, New York, NY, USA, 2008. ACM.
20
國科會補助專題研究計畫成果報告自評表 
1. 請就研究內容與原計畫相符程度、達成預期目標情況作一綜合評估 
■  達成目標 
□ 未達成目標（請說明，以 100 字為限） 
□ 實驗失敗 
□ 因故實驗中斷 
□ 其他原因 
說明：此計畫為一整合計畫之子計畫. 多數預期目標都已達成. 主要未達成部分為可適性行
為辨識系統(adaptive activity recognition system), 以及因其他子計畫未通過, 無法完成整合成
為一個完整的系統. 
2. 研究成果在學術期刊發表或申請專利等情形： 
論文：■已發表 □未發表之文稿 □撰寫中 □無 
專利：□已獲得 □申請中 □無 
技轉：□已技轉 □洽談中 □無 
其他： 
發表論文如下: 
1. Yi-Ting Chiang, Yi-Ting Tsao, and Jane Yung-jen Hsu. A Framework for Activity 
Recognition in a Smart Home. In Proceedings of the 15th Conference on Artificial 
Intelligence and Applications Domestic Track (TAAIDT 2010). November, 2010. 
2. Yi-Ting Chiang, Kuo-Chung Hsu, Ching-Hu Lu, Jane Yung-Jen Hsu, and Li-Chen Fu. 
Interaction Models for Multiple-Resident Activity Recognition in a Smart Home. In 2010 
IEEE/RSJ International Conference on Intelligent Robots and Systems(IROS). October, 
2010. 
3. Kuo-Chung Hsu, Yi-Ting Chiang, Gu-Yuan Lin, Ching-Hu Lu, Jane Yung-Jen Hsu, and 
Li-Chen Fu. Strategies for Inference Mechanism of Conditional Random Fields for 
Multiple-Resident Activity Recognition in a Smart Home. In The Twenty Third International 
Conference on Industrial, Engineering & Other Applications of Applied Intelligent Systems 
(IEA-AIE). June, 2010. 
4. Gu-yuan Lin, Shih-chiang Lee, Jane Yung-jen Hsu, and Wan-rong Jih. Applying Power 
Meters for Appliance Recognition on the Electric Panel. In Proceedings of The 5th IEEE 
Conference on Industrial Electronics and Applications (ICIEA2010). June, 2010. 
 
行政院國家科學委員會補助國內專家學者出席國際學術會議報告 
2010年  9 月 17 日 
報告人 
姓名 許永真 
服務機構 
及職稱 
國立台灣大學 
資訊工程系所暨網路與多媒體研究所 
時  間 
會議地點 
99年 7月 11日 至 99年 7月 15日 
美國、Atlanta 
本會核定 
補助文號  
會議 
名稱 
(中文) 第 24屆國際人工智慧會議 
(英文) Twenty-Fourth AAAI Conference on Artificial Intelligence (AAAI 2010) 
發表 
論文題目 
(中文) 結合用電行為及電器辨識達到節能提醒 
(英文) Appliance Recognition and Unattended Appliance Detection for Energy 
Conservation 
一、參加會議經過 
AAAI 為人工智慧研究領域中，最具學術代表性之國際會議。藉由本會議，凝聚了人工智
慧各方面的專家學者，並使得這些來自世界各地的學者們能有一個充分交換意見的討論空間。
國際上許多知名的企業和機構都是 AAAI的贊助者，例如：Google、Yahoo、IBM、MicroSoft、
Intel、NSF、ISI等。藉由本會議，凝聚了與人工智慧研究相關之專家學者，並使得這些來自世
界各地的學者們能有一個充分交換意見的討論空間。與往年相同，今年的 AAAI有 1千多人參
與，與會者多為相關領域的資深研究學者專家，所有與會學者均相當投入會議之各項活動，使
得會議期間的討論氣氛十分熱絡。 
本人此行於 7月 12日於 PAIR: Plan, Activity, and Intent Recognition的 AAAI Workshop，
發 表 論 文 Appliance Recognition and Unattended Appliance Detection for Energy 
Conservation。主要是探討如何由日常生活的用電行為，改善平常的用電習慣，進而達到節能
的目的。論文中利用 human computing來收集一般大眾的日常行為與電器的關聯性，透過收集
到的用電行為 common sense建立出 appliance-activity model，配合以 machine learning方法
辨識出電器開關狀態，來偵測出目前是否有浪費電的行為，達到節能的目的。本篇論文雖然被
安排在當天最後一篇報告，本人報告完後，與會學者們皆對此論文有熱烈迴響，也得到多位參
與學者的肯定，並贊許我們每次都有極具研究價值之成果，讓本人對我們的研究團隊深感榮耀
與驕傲。 
本次會議為期五天，前兩天為 tutorial及 workshop，7月 13日至 7月 15日為主要會議，
討論議題包含 Dimensionality Reduction、Search、Game Play、Auction、Mechanism Design、
Machine Learning、Planning、Activity Recognition、Voting 等。大會也邀請了 Leslie Pack 
Kaelbling、Michael Thielscher、Carla P. Gomes、David C. Parkes、Barry O’Sullivan等學者，
他們分別針對 robotics、game play、computational sustainability、mechanism design 及
constraint programming等主題來給演講。本人於開會期間與其他參加學者有密切接觸，並進
行學術交流，直到整個會議結束。 
AAAI-10所討論的議題以理論為主、實務為輔，在 Invited talk中講者針對各個領域的理論
用來嘗試解決現實生活的各種問題，如環境、保育、經濟、癌症、醫學影像分析等，更另有 AI 
三、建議 
對於有志投稿、參與國際研討會的學者，應多鼓勵參與類似 AAAI 之頂尖國際會議。由這
些最具有代表性的國際會議中，能接觸到許多傑出的研究者，進而得到機會與頂尖的學者們交
換經驗，並分享目前的主要研究議題。這些將是台灣學者未來研究方向的指引，也提供台灣與
國際學者合作的機會。 
台灣學界若能參與此會議，對於台灣學術研究地位，必定有極大的幫助。由於 AAAI 為創
新研究先驅聚集之會議，發表的論文涵蓋了近代新興技術之研究，且具一定的深度，諸多學者
人士雖未能夠發表亦參與此會議尋找相關資料，或與論文作者直接討論。每個討論主題的研討
會，也都有相當不錯的水準，也提供一般大型會議沒辦法做到的直接探討方式。本次會議來自
台灣的學者並不多，但來自其他亞洲各地的學者卻不少，像是來自日本、中國大陸，新加坡等，
這是本報告人認為比較可惜的地方，建議國內相關研究領域人員可考慮投稿，汲取參與高品質
國際學術會議之經驗，也希望過內相關單位能給予適時的補助，提升過內學者與學生外出參與
大型國際會議的經驗，以提升國內學術機構在國際上的知名度。 
由於會議地點旅途遙遠，對於有志參與國際研討會的研究人員而言，是極大的負擔，應鼓
勵國內專家學者參與類似具國際代表性的會議，並有彈性地提供交通費用補助。以提高台灣國
際學術研究的地位。 
 
四、攜回資料名稱及內容 
 AAAI 2010 Proceedings 
 AAAI 2010 PAIR Workshop Technical Report 
 大會議程 
 大會專題演講系列投影片 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
96年度專題研究計畫研究成果彙整表 
計畫主持人：許永真 計畫編號：96-2628-E-002-173-MY3 
計畫名稱：iCare 2.0: 次世代數位生活服務--以情境感測資訊進行機率式行為辨識之研究 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 1 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 5 3 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 2 0 100%  
博士生 2 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
 
