2中文摘要
本延續性計畫研究目的在利用自行研發的電腦輔助顏顎手術計劃軟體與光學追蹤系統
開發新穎性醫療手術規劃與引導，並嘗試性的往臨床醫療大步邁進。本研究與成大醫院口
腔顎面外科、牙科、整合外科的專業醫師密切合作，對於手術計劃與術中困難處均有深入
的了解。過去研究已完成三維醫學影像大部分的基礎功能並進入手術規劃核心，本年度計
劃更將深入口腔顎面手術計畫的臨床技術開發上，開發新穎性醫療技術將一向以傳統平面
為計畫基礎的功能推向三維，提供成大醫院口腔顎面科、牙科、整型外科的先驅性手術技
術，應用於適合的個案與特定需求上。
本計畫延續口腔顎面手術計畫與臨床技術開發，還有數個重點研發目標，一是建立植
牙方位與植體分佈的自動化專家系統，根據病患下顎骨外型與掃描資訊，自動化地尋找出
最佳化的建議方位與分布情形；二是咬合運動的追蹤與其假牙製作及病灶診斷之應用，期
望透過化個人咬合運動數學模組建立，取代目前呆板的機械式咬合器，這將是挑戰傳統牙
科在咬合學的新科技；三是開發三維實體模型手術計畫新技術，藉由自行開發的光學式追
蹤系統提升外科醫師建立外觀上功能上都符合目標的手術計畫。
關鍵詞：植牙手術、咬合運動追蹤、模型手術計畫
Abstract
Aim of this research is to create some new clinical techniques applying in surgical planning
software for oral and maxillofacial surgery. It is an inter-discipline cooperation research among
departments of mechanical engineering, oral institution, dentistry, and surgery in NCKU hospital.
In our previous study, the most of the kernel functions in medical image-guided surgical planning
are completely fulfilled. Base on this infrastructure, we move deeply into new clinical techniques
innovation by providing fully three-dimensional planning rather than in two dimensions. The
pioneer study will be suitable for customized surgery for specific acquirements from surgeons.
There are a few interested targets in this research. The first is in dental implant field. We
build an expert-based dental implantation system in which a guiding stent for implant body
insertion is generated automatically. To construct a personal occlusion modeling from the
outcomes of occlusion movement tracking is our second target. The third is to develop a brand
new model surgery technique based on our invention patent–symmetry evaluation.
Keywords: dental implant surgery, occlusion movement tracking, model surgery.
4或下顎，在面板上繪出哥德弧(gothic arch)與箭頭點(arrow point)，用來紀錄病人的中心關
係(centric relation)與後牙側向的邊緣運動的情形[10,11]。近年來隨著描繪方法與咬合器
(articulator)的發展，已能較正確地模擬出患者的咬合關係和上下顎相對運動位置。機械式
咬合器的設計乃是參考人類顎關節的構造，以模擬出類似患者牙弓功能位置與咬合運動，
為了要使石膏模型在咬合器所產生的閉合弧(arc of closure)能如真實位置一般，必須將上顎
牙弓對髁頭(condylus)的位置關係轉移至咬合器上，下顎模型則依照中心關係(centric
relation)及中心咬合(centric occlusion)的相對位置放入咬合器，如此一來，石膏牙模在咬合
器內即可以像嘴裡的牙齒一樣地咬合，不過一般機械型咬合器所提供的導引，大都設計成
具有滑動自由度的樞紐軸(hinge axis)旋轉對(pair)，無法重現複雜的人體控制下顎運動機制。
是故到目前為止，沒有一個上市的人工咬合器可以設定並重現來自咀嚼系統所有成員的影
響數據。近年來，有相關研究試著找出合適的咬合運動路徑敘述方法，有些利用連桿式的
機械裝置，直接地記錄上下顎的相對應位置關係[12]，有些則搭配著追蹤裝置與運動學相
當的模型來建立[13, 14]，透過模擬人體咬合的運動模型之繁雜設定與完整的輸入串列資料，
表達出相對應的耦點(couple point)路徑，找出合適的參數方程式。
此外，在口腔顎面手術規畫方面，傳統上外科醫師會在術中憑直覺選定某塊骨骼的最
佳位置，或是利用周遭環境建立參考點或參考面，再進行搬移手術。一般正顎手術由於
傳統影像資訊來源有限，手術計劃ㄧ直是以統計資料的紙上測顱技術(Cephalometry)
[15-18]來進行，作法是在描繪有 X 光圖像的紙張與透明片上模擬手術的進行，找出一個
側向描圖的特徵角與特徵長度合理的標準位置，在投影平面上規劃顎骨切割處以及分割
出的顎骨塊所需移動或平面旋轉的量，再將該規劃目標以牙齒咬合板轉移至臨床手術上。
這方法在簡單側向歪斜的正顎手術中使用似乎可行，雖然完美程度有所侷限，由於移動
量不大，大部分都有比原來較為對稱的結果。可是，在一些較複雜嚴重非軸向歪斜的病
例中，欲將規畫目標完整呈現於臨床，尚無合理可用的方法，就得仰賴醫師的經驗感與
技術，規劃目標與臨床呈現就可能有頗大的出入，甚至造成手術的失敗。事實上，特別
是在骨骼需要做旋轉移動時，這種平面式的紙上作業並不十分恰當。
另一種規劃則是在特定位置植入人工合成材料(俗稱骨水泥)或鈦金屬固定片，傳統的
方法只能在手術進行中製作這些合成物或固定片，不但費時，更受限於手術中缺乏良好
的參考座標。另外，植入物的大小、厚薄、幾何外形、及置放位置都不夠精準，在十分
講究功能外觀之協調性與對稱性的情況下，重建之後可能無法達到預期的理想目標。為
幫助醫師解決這些技術上的問題使重建結果更臻理想，最常見的相關研究工作是利用電
腦來開發輔助手術模擬軟體[19-22]，二維的手術計畫軟體可提供頭部側面或單一角度的
觀視面來做模擬[23-24]，搭配電腦幾何模型輔助工具與成型技術即可製作實體模型[25]，
而此部份國內的相關臨床應用有整合性電腦支援顎面外科手術及顏面膺復體製作[26-27]，
上述研究皆希望在手術前經由電腦進行術前模擬，希望使醫師能先在電腦上執行模擬手
術以取代傳統平面作業。
二、 研究方法與成果
本研究以追蹤分析咬合運動與自動化搜尋植體植入方位為主，工作分項有五：1. 建構
個人化咬合運動追蹤系統；2. 開發咬合運動數學模組；3. 開發石膏模型手術技術；4. 訂
定植牙之最佳植體植入方位；5. 手術用鑽頭受力資訊分析與統計整理。上述工作項目所用
之研究方法與成果如下所述：
6二所示，在固定板上鑲數顆註冊定位用陶瓷珠與追蹤板，如此一來追蹤板與齒列可視為一
剛體，在兩者無相對運動產生的前題下，只需要確定追蹤板上 LED 與齒列的相對座標，即
可正確地進行耦點運動(couple point)分析，推算上下顎任意點的運動軌跡。
圖二 運動追蹤板
如圖三所示，定位陶瓷珠與追蹤器的座標轉換 T1、T2 則可透過外部量測獲得，齒列模
型與定位陶瓷珠的相對座標 T3、T4 可從重建影像獲取，如此即建立上下顎的耦點運動關係，
只需透過數位模型的點選取，就能推算出上下顎任意點的運動軌跡。
圖三 模型註冊與座標轉換
2. 開發咬合運動數學模組
一般具正常咬合的人均可做到下顎張口閉口、邊緣及側向咬合的運動，此部分工作針
對此三類運動模式進行數學參數化，建立個人咬合運動的參數曲線與曲面，其主要工作分
類如下：
咬合運動分類與紀錄—根據咬合學理論我們針對三種特徵咬合運動－邊緣運動
(border movement)、側咬運動(lateral exclusion)、與張口閉口運動(open-close movement)
進行三類數學模組的開發，並教導受試者進行分項運動的紀錄工作。
咬合路徑參數化—由於所蒐集資料是為不連續無次序性的雲點集合，將定義高次函
數，預計利用數值求解方法與端點連續限制(constrains)求出高次方程式的參數，建立
出合適的參數化數學模組。
追蹤器
固定片
標記球
齒列
紅外線 LED
8模之移動可由定位追蹤板在空間追蹤結果顯現於程式中。
最佳對稱面評估－藉由患者 CT 影像資訊分別建立上下顎骨最佳對稱面資訊，產生上
下顎最佳對稱面夾角，加以記錄術前患者對稱性資訊。
追蹤上下顎骨新位置－由醫師調整可追蹤的上下顎石膏齒模，利用定位追蹤板追蹤
所規劃之石膏齒模新位置，找出顎骨新位置與原座標的相對移動量，並進行最佳對
稱面的分析。
偵測石膏模型手術計畫與傳統二維測顱手術計畫目標－石膏齒模新位置的調整是依
據 X光測顱的平面資訊，齒模的調整由於是人為且缺乏移動基準，常有誤判與人為失
誤的發生，我們藉由比對石膏模型手術計畫與傳統二維測顱計畫的目標，以偵測石膏
模型手術計畫人為移動的失誤。
輸出手術用咬合定位模板－確立手術計畫後，導入集合運算概念進行模板雛型與手
術計畫中之上下齒模之集合運算，產生手術計畫中所需之各步驟之上下顎咬合定位
模版。
術後追蹤與資料彙整─利用術後 CT，評估模型手術計畫與目標之差異量，進行最佳對
稱面分析。
如此醫生即可依據手術計畫目標切割石膏齒模，如圖六所示，對此病例的手術計畫進
行下顎石膏切割，調整過程中，遂由咬合器提供完整的咬合資訊，再配合螢幕顯示目前的
骨骼相對關係，給予醫師骨骼外觀的參考，醫師可由正、側視圖取得二維測顱分析用的特
徵點、線與邊緣輪廓，依據醫師經驗與人體測顱術學理，透過手動調整模型的相對位置，
找到一個既合乎病患咬合需求又較具對稱美觀的外型。
圖六 手術計畫擬定與結果預視
10
圖九 植體分佈(a)安全終點線；(b)咬合面進入點連線
5. 手術用鑽頭受力資訊分析與統計整理
為了找出密度與回饋力之對應模型，我們採用鑽孔切削的經驗公式(式1)來描述結果。
2
sin
2
D
aKT S (1)
其中 T是鑽孔推力(N)，Ks為材料的特定切削能量(Specific Cutting Energy)，a是
進給速率(mm/rev)，D是鑽頭直徑(mm)，β為尖端角(1/rad)。Allotta[28]在其研究中指
出係數 Ks和極限拉伸強度為線性關係，且 Hayes 和 Mow 在其書[29]中提出，海綿骨的拉伸
強度和密度為乘冪關係式
BARu  (2)
其中Ru為材料的拉伸強度，ρ為骨密度。以此式描述仿人體海綿骨塊密度與拉伸強度的關
係，可得到Ａ為78.71，Ｂ為1.945，方程式的確定係數(Coefficient of Determination) 2r
值為0.9998。針對本實驗設定Ks為常數C乘以Ru，將此關係與其他的參數設定值代回式(1)
得到骨密度與鑽孔力為乘冪關係式
945.1779.0 CT (3)
以上式趨近鑽孔實驗的結果，發現設定Ｃ為15時可適當描述實驗結果，得到海綿骨密度與
鑽孔力關係式為
945.186.11 T (4)
然後再根據不同海綿骨密度與CT係數的對應關係，建立兩者的線性關係，然而骨塊的CT係
數並不如真實骨骼，因為缺少了體液，因此本研究假設骨塊內的空氣替代為體液，將五種
密度骨塊的CT係數皆加上1000得到關係式式為
0044.00011.0 #  CT (5)
其中ρ為骨密度，CT#為CT係數，此式相當近似Rho[12]等人以真實人骨研究得到的關係式。
將式(5)代入式(4)，得到以CT係數計算海綿骨鑽孔力的關係式為
945.1# )0044.00011.0(86.11  CTT (6)
第二組多密度骨塊由兩塊皮質骨夾一塊海綿骨所構成，經由鑽孔力量量測結果，取鑽入皮
質骨層與鑽出皮質骨層的實驗資料，以二次曲線描述鑽孔力
(a) (b)
12
methods of Making Surgical Models for Correction of Facial Asymmetry,”International
Journal of Oral and Maxillofacial Surgery, 63:200-208. (SCI)
8. 方晶晶，“電腦輔助口腔顎面及脊椎重建手術計劃，”to be published in 國科會工程
科技通訊學刊，2008。
9. Jing-Jing Fang, Tai-Hong Kuo (2008), “Modeling of mandibular movement,” Computers
in Biology and Medicine, Volume 38, Issues 11-12, Pages 1152-1162. (SCI)
10.White G. E. The Gerber Articulator and System of Full Denture Construction. The Dental
Technician, Vol. 26 No. 3, 1973.
11.Arial J. Raigrodski, Avishai Sadan, Philip L. Carruth. A technique to stabilize record bases
for gothic arch tracings in patients with implant-retained complete dentures. Journal of
prosthodontics. Vol. 7, No. 4, pp. 273-276, 1998.
12.Russell S. A. and Kemal S., Jaw movement alters the reaction of human jaw muscles to
incisor stimulation, Annals of Biomedical Engineering, pp. 165-76, 2005 May.
13.Weingartner, T. Hassfeld, S. Dillmann, R. Dynamic simulation of the jaw and chewing
muscles for maxillofacial surgery, IEEE Proceedings of Non-rigid and Articulated Motion
Workshop. 1997.
14.Reyes Enciso, Ahmed Memon, Douglas A. Fidaleo, and et al. The Virtual Craniofacial
Patient: 3D Jaw Modeling and Animation, MMVR11, IOS Press, pp. 65-71, 2003.
15.Tiziano Baccetti, Lorenzo Franchi, James A. Mcnamara Jr., and Isabella Tollaro, "Early
dentofacial features of Class II malocclusion: A longitudinal study from the deciduous
through the mixed dentition," American Journal of Orthodontics and Dentofacial
Orthopedics, Vol. 111, No. 5, pp. 502-509, 1997.
16.Kenji Takada, Yuka Sorihashi, Christopher D. Stephens, and Satsuki Itoh, "An inference
modeling of human visual judgment of sagittal jaw-base relationships based on
cephalometry: Part I," American Journal of Orthodontics and Dentofacial Orthopedics, Vol.
117, No. 2, pp. 140-147, 2000.
17.Yuka Sorihashi, Christopher D. Stephens, and Kenji Takada, "An inference modeling of
human visual judgment of sagittal jaw-base relationships based on cephalometry: Part II,"
American Journal of Orthodontics and Dentofacial Orthopedics, Vol. 117, No. 3, pp.
303-311, 2000.
18.Dali Yin Weining Yue, Chengjun Li, Guoping Wang, and Tianmin Xu, "Automated 2-D
Cephalometric Analysis on X-ray Images by a Model-Based Approach," IEEE Transactions
On Biomedical Engineering, Vol. 53, No. 8, pp. 1615-1623, 2006.
19.Lemke HU, Vannier MW, Inamura K and Farman AG, “Computer Assisted Radiology and 
Surgery,” Proceedings of the 12th International Symposium and Exhibition, 1998.
20.McAloon K “Rapid Prototyping Technology: A Unique Approach to the Diagnosis and 
Planning of Medical Procedures,” The Society of Manufacturing Engineers, 1997.
21.Perry M, Bankd P, Richards R,Friedman EP and Shaw P, “The Use of Computer-Generated
Three-dimensional Models in Orbital Reconstruction,” British Journal of Oral and 
Maxillofacial Surgery, Vol. 36, pp.275-284, 1998.
22.Taylor RH, Lavalee S, Burdea GC and Mosges R, “Computer-Integrated Surgery —
14
可供推廣之研發成果資料表
■ 可申請專利 ■ 可技術移轉 日期： 年 月 日
國科會補助計畫
計畫名稱：電腦輔助口顎手術計畫臨床應用新技術開發 II
計畫主持人：方晶晶
計畫編號：NSC 97－2221－E－006－028 學門領域：機械固力學門
技術/創作名稱 參數化咬合路徑模型之建立
發明人/創作人 方晶晶、郭泰宏
技術說明
中文：
使用光學式空間位置追蹤器進行上下顎運動情形的紀錄，透過數位
化的紀錄方式取代傳統的機械式咬合器的呆板模擬，並進行咬合行
程動點的自動化區分與各行程之三次或高次曲線的數學逼近，並利
用正規化的咬合距離作為參數，求得任意咬合點運動的數學模組，
所建立出參數化的咬合運動數學模型將便於紀錄與量化比較。同時
根據咬合理論與運動學理論，發展出無輻射劑量的髁狀突位置探知
方法，以進行髁狀突病灶的科學化診斷。
英文：
可利用之產業
及
可開發之產品
自動化醫學工程
髁狀突病灶的科學化診斷
提供個人電腦級顏口顎手術計畫軟體與週邊系統
技術特點
以數學方法忠實地描述受測者的咬合運動，與市面上泛用型純旋轉
運動的機械式咬合器所虛擬出來的近似結果有著本質上的差異，其
擬真的模擬方式能完整地模擬出齒列複雜的三度空間關係，功能上
將取代一直被奉為牙科矯正圭臬的機械式咬合器，打破咬合運動是
針對一樞紐軸旋轉的假設。
推廣及運用的價值
口腔顎面臨床診斷、正顎手術執行需要性之判定、醫學教育訓練系
統、術後病灶追蹤
※ 1.每項研發成果請填寫一式二份，一份隨成果報告送繳本會，一份送 貴單位
研發成果推廣單位（如技術移轉中心）。
※ 2.本項研發成果若尚未申請專利，請勿揭露可申請專利之主要內容。
※ 3.本表若不敷使用，請自行影印使用。
附件二
足夠的時間交談結識數位外籍友人教授，同時也在輕鬆的受邀晚宴會場上認識幾位朋友，有來自
台灣、日本已定居於美國的數位教授相談甚歡。
三、考察參觀活動(無是項活動者省略)
無
四、建議
全球的不景氣引發經濟上全面性的蕭條，筆者感謝國科會計畫提供專任教授出席國際會議，
設法增加台灣在國際舞台的研究知名度與名號，我們也盡力達成該項目標。唯油價能源上漲相對
帶動機票與各城市生活基本支出費用的上揚，建議經濟部計畫取消採用國科會訂定之日支生活費
與機票費標準 1，採實報實銷方式，以單據核銷，建議只須鎖定計畫總出國旅費上限。
五、攜回資料名稱及內容
共有一片光碟，及會議議程一本：
1. 21st International Conference on Computers and Their Applications in Industry and
Engineering PROGRAM.
2. Proceedings of 21st International Conference on Computers and Their Applications in
Industry and Engineering, CD ROM.
六、其他
無
表 Y04
changing weights, made curve shaper or flatter by closer to or away from its corresponding control points [4, 5].
Fig. 1. Connection problems on left-side bodice.
Juhász and Hoffmann [6] have pointed out that shape control of B-spline curves can be achieved by modifying
one of its knots. In 2004, they modified three consecutive knots to enable local shape modification subject to reposition
a required point under certain tangent constraints [7]. The advantage of this method is that the modified B-spline curves
are still contained in the convex hull region of the initial control points. However, there are some constraints on the
relocation range of the required points and the position of the extremity of the tangent lines. With regard to length
constraints on generating B-spline curves, Wang and Hu modified weights by assigning a specific length to the
associated piecewise polynomial to generate a length-constrained B-spline curve [8].
Lu et al. [9] proposed a method which involves changing the control points and their corresponding weights on a
B-spline curve to achieve a so-caled “nose feature” in plane. Moreover, they used the method to move the “nose” to a 
target position, in which deformation of other curve segments was reduced dramatically by adjusting the knots. A
nose-like B-spline curve drawing of a side view of a human face was created by this method while retaining the original
continuity. Nevertheless, this method can neither be extended to three dimensions nor solve the connection problem
between two B-spline surfaces.
The authors propose a new algorithm to develop an angle-constrained B-spline curve with cusp which is used in
computer-aided design tools. A specific angle is given to control the sharpness of the cusp in a B-spline curve. This
approach will be widely applicable to general B-spline surfaces. The problem of C0 continuity at the edge of two
B-spline surfaces is solved. The presented methods for creating cubic B-spline curves with cusp are based on
multiplying knot elements, so that a required point of the original B-spline curve is transformed from C2 into G2
continuity. The definition of a cusp and its related methods are presented in the following sections. Cusped curves
manipulation with angle constraint is also implemented and discussed.
2 KNOT MULTIPLICITY
In this study, a cubic B-spline curve is initially developed through the reorganized structure points sequence based
表 Y04
1 2
1 2
arccos( )
v v
v v
 

 (5)
where 1 2v v

is the dot product of 1v

and 2v

, andθ is applied within (0,).
4 ALGORITHM
The goal in this research is to provide a cusped curve under a specific angle constraint. We catalog the whole
procedure into three steps. First, locate the candidate point for developing a cusp in the data set. Second, determine a
range for potential cusp location such that the order of data set cannot be altered. Third, locate a cusp under a certain
cusp angle constraint.
A cusp-generating is primarily developed on a sequence of reorganized structure point set {Qi}. The bending
value method Bv(i) [13] is adoped to detect the candidate point in the data set. Let the candidate point
Qc = {Qj | Bv(j) >Bv(i), fori=0,…,n, i≠j }. (6)
Then Qc divides the data set {Qi}i=0,…,n into two subsets with Qc duplicated both in sets {Q0,Q1,Q2,…,Qc} and
{Qc,Qc+1,Qc+2,…,Qn}.
1cQcQ
1cQ
)(' 11  ifc tCQ
)(' 11  ifc tCQ
cpP
Fig. 2. Qc relocation tolerance.
And the least square method is used to determine the searching range for potential cusp position. The potential
cusp range near Qc and along the curve Cf(t) which is approximated by one of the selected subsets. To determine the
subset to approximate Cf, we define the error function
2
| ( ) |
i
i f i
Q
R Q C t  (7)
The least R determines the selected data subset, then the cusp Pcp would be located inside Cf. For the purpose of
preventing knots or wiggles occurred, some distance tolerances are used. As shown in Fig. 2, the relocation tolerance of
Qc is determined by the parameterized domain [t c-1, t c+1], where Cf(t c-1) and Cf(t c+1) are the nearest positions on Cf to
Qc-1 and Qc+1, respectively.
The geometrical relationship between the B-spline curve and its cusp is affected by two major factors: the data
distribution and the curve Cf. Cf is usually determined before locating the cusp; therefore, a specific constraint angle
within a reasonable range should be set. To determine a reasonable range for the required angle, we consider the
autocorrelation properties of the data set first. The angleQc-1QcQc+1 in Fig. 2is caled the “natural angle”. This angle
表 Y04
Table 1 lists the outcomes in implementation of different natural angle and specific angle constraints between
every two feature segments to form a cusp. We evaluate the results by the equation e = |θ −θc| based on the deviation
between the desired angle and the implemented angle. The mean error of these 12 examples of natural angle and
specific angle constraints are 0.27°, 0.21° and the standard deviation are 0.27°, 0.17°, respectively. All the cusps
generated in both groups satisfy the angle tolerance within 1°. Two representative results of the cusped cubic B-spline
generation process are shown in Fig. 5.
(a) (b)
Fig. 4. (a) Structure points and (b) lines on a digital human body
6 CONCLUSION AND DISCUSSION
In this paper, a simple method of cusp generation on a cubic B-spline curve is presented. Continuity problems
which arise when connecting several B-spline segments can be solved by using one single curve instead of two or more.
The spatial cusp angle is defined by constraint-based manipulation. The tolerance of the angle constraint can vary with
special requirements in different applications. There are two types of angle constraint in this study, one natural and one
assigned. Base on the distribution of the data set, the natural angle is selected as the constraint angle in the cases
implemented. The results demonstrate that the absolute errors in these cases are all less than 1°. Moreover, it is shown
that a fast cusp-position location algorithm under certain angle constraints running on a Pentium 4 2.4G 512MB
platform would provide real-time curve reshaping.
In conclusion, future work could extend this research to generate multi-cusp cubic B-splines, the coincidence of
two cusp curves with sharing of a partial data set, the generating of NURBS surfaces with a cusped curve boundary, and
the development of crests inside an NURBS surface.
Table 1. Evaluation of angle constraints.
Case
Natural
angle
θ e
Constraint
angle
θ e
1 113.81° 113.53° 0.28° 100.00° 99.67° 0.33°
2 104.35° 104.29° 0.06° 80.00° 80.03° 0.03°
3 90.34° 90.33° 0.01° 90.00° 90.08° 0.08°
4 90.36° 90.58° 0.22° 90.00° 89.67° 0.33°
5 63.71° 64.48° 0.77° 90.00° 90.17° 0.17°
6 83.40° 83.45° 0.05° 90.00° 89.83° 0.17°
7 83.83° 83.67° 0.16° 100.00° 100.57° 0.57°
8 116.51° 116.72° 0.21° 80.00° 80.05° 0.05°
9 98.91° 99.01° 0.10° 90.00° 89.91° 0.09°
表 Y04
國科會補助國內專家學者出席國際學術會議報告
98 年 7 月 6 日
報告人姓名
方晶晶
服務機構
及職稱 國立成功大學機械工程學系
時間
會議
地點
98/6/29~98/7/3
新加坡
核定
補助文號
A97-0064
會議
名稱
(中文) 2009 年「第四十屆國際模擬及遊戲協會—從遊戲到學習，從學習
到遊戲」國際研討會議
(英文) The 40th International Simulation and Gaming Association Conference
on Game to Learn, Learn to Game; ISAGA 2009
報告內容應包括下列各項：
一、參加會議經過
2009 年「第四十屆國際模擬及遊戲協會」國際研討會議今年在新加坡的國立新加坡大學
NUS(National University of Singapore)國際會議廳舉行，為期五天。與會人員多屬於教育
工作者，研究主題上相當分歧，均是以數位化教材、寓教於樂的學習活動，來啟發各種遊戲
性學習教育概念，主辦單位仔細為各論文分門別類共分為 26 個組別，由三個會議廳同時進行
所有論文發表，來自全世界各國投稿論文共計 130 篇，均為口頭發表。該會議是由國際模擬
遊戲組織所承辦，我們的論文投稿至 ISAGA 研討會中，被分類在虛擬實境的技術類。
由於國內研究計畫事務繁忙，筆者只參與中間三天的會期演講，會期第一天尚在旅途中，
第五天則在返國路上。大會共辦了七場專題演講，邀請有
1. 荷蘭 Wageningen Universityt, Prof. Gert Jan HOFSTEDT，探討不同文化對電玩遊
戲的影響與衝擊。
2. 英國 The University of Coventry, Prof. Sara de FREITAS 探討沉浸式體驗如何用
於提升社會人際間的互動能量。
3. 新加坡 The National Institute of Education, Prof. Yam San CHEE 探討遊戲式學
習在 21 世紀的的機會與挑戰。
4. 蘇俄 Moscow State University, Prof. Dmitriy KAVTARADZE 研究遊戲智慧與學習知
識間的關係。
5. 新加坡 National University of Singapore, Prof. Ryohei NAKATSU 呈現數位與互
動媒體的未來的看法。
6. 澳大利亞 George Mason University, Prof. Daniel DRUCKMAN 研究從遊戲到學習與
從學習到遊戲間設計者與玩家的角色扮演。
7. 台灣台北師範大學 Prof. Shih-Tsung CHANG 報告從競賽分析的角色模擬遊戲到寓教
於樂的學習義意。
此外，除了會期的第三天與第五天外，更於每天下午 4:00 以後開設五場平行的互動遊戲
活動，由相關研究人員設計各類遊戲學習主題，提供與會者腦力激盪，抒發個人創意思
維。大會利用第三天半天時間辦了三場參觀活動，大夥一起搭鴨子船遊江，再分成四批
表 Y04
國科會補助國內專家學者出席國際學術會議報告
98 年 7 月 6 日
報告人姓名
蔡佳彰
服務機構
及職稱 國立成功大學機械工程學系
時間
會議
地點
98/6/29~98/7/3
新加坡
核定
補助文號
A97-0064
會議
名稱
(中文) 2009 年「第四十屆國際模擬及遊戲協會」國際研討會議
(英文) The 40th International Simulation and Gaming Association Conference
on Game to Learn, Learn to Game; ISAGA 2009
報告內容應包括下列各項：
七、參加會議經過
學生於台灣時間 6 月 29 日禮拜一下午 2 點半搭乘新加坡航空前往新加坡，於當地時間晚
上 7 點到達大家公認最美麗機場之一的樟宜機場。到達飯店時天色以晚，加上舟車勞頓，簡
單梳洗後即上床就寢。
新加坡位於馬來半島南端，毗鄰馬六甲海峽南口，四季如夏與台灣沒有時差，此時日落
時間約為晚上七點，而於早上六點才破曉，和台灣差不多。
簡單用餐後即搭乘地鐵前往會議舉辦地點，新加坡國際大學(National University of
Singapore, NUS)，由於飯店和 NUS 有段距離，必須先搭地鐵在轉公車到達大學附設醫院後，
在轉搭校園公車，經過一個半小時後終於到達會場。此會議為教育和遊戲方面一項大型的年
度國際會議，研討範圍包含教育、管理及電腦計算領域，與會人數眾多。會議舉辦時間為 6/29
～7/3，這幾天先後挑選了幾場學生有興趣的報告
 3D Interactive Virtual Dissector
 High Tech, Low Touch; Low Tech, High Touch: Training by Interactive Pixel Art
 Chihlee Commumity Empowerment Project using Second Life
 Microblogging Virtual Communities and Game Elements–An Exploration of Plurk
 Acceptance of New Technology Fads: What Would Motivate Laggards to Become Adopters?
 Collaboration in Virtual Worlds
 An IBM Power System Education Project in Second Life
 Gaming World Becomes University Classroom
學生要報告的論文於 7 月 2 日。Track: Virtual Reality, Focus: Technology。報告的時間為
下午 2 點。報告結束後於 7/3 中午 12 點半搭乘班機返回，並於台灣時間 7/3 下午 5 點返抵台
灣。
八、與會心得
本次會議為學生第一次參加這種大型會議，學生非常緊張，所幸過程一切安好，有驚無
表 Y04
表 Y04
set up a wall-scale visual realization. However, while playing the game, it does not tell the
topological relationship between the paddle and the ball target so that it is unable to exhibit a
spin response on screen. In 2007, Lin (Lin, Fang, & al, 2007) have developed a special-purpose
virtual environment with digitized content of simple games, such as ball catching in a few
specific distances, target ball throwing, etc. It aims to evaluate and rehabilitate a group of DCD
(Developmental Coordination Disorder) children which lacks an interest to normal people. Chen
(Chen, Tien, Chen, Tsai, & Lee, 2009) tracked a baseball game by video camera in order to
analysis the players’ movements in a basketbal game. It is good for players to learn overall
tournament strategy, but less for entertainment. Boye (Boye, Gustafson, & Wiren, 2006)
developed a voice-activated game for the tales developer. It was useful in a voice-driven
activity.
Aim of the study is to provide a new way of delivering the computer games by more realistic
phenomena and more interactive tools than common computer games. In this article, we present
a new type table tennis game by using a self-developed movement tracker and an interactive
multimedia paddle. Moreover, we also developed a physics-based digital content for table tennis
game to match up the hardware tools. It would provide a more realistic virtual game that meets
our daily experiences. In section 2, we introduce the integrated system structure including
hardware components using in the virtual ping pong game. The simple physical model using in
the system is described in section 3. Several pictures in the playing ground are taken and shown
in section 4. Finally, we describe the novelties and limitations of the developed virtual game
system.
System structure
The purpose of this research is to develop an integrated playground for table tennis players. A
six degree-of-freedom optical tracker is used as the game controller of the game that
synchronizing the positions of the virtual bats with the multimedia bat in real. Players can hold
and move the physical paddle, and the associated paddle in the virtual game would show the
corresponded movements. We use one desktop connected to one screen to play against the
computer, or two players can use one computer connected to two screens to play against each
other. Current scores of both sides will appear in the virtual space. Since the tracking system can
obtain spatial coordinates of the paddle in every instant, speed and acceleration of the paddle
can be obtained instantly by calculation. In addition, it can also instantly receive the
information of the rotation angle including the topspin, backspin or sidespin, therefore
appropriate responses can be given. No matter what serving or receiving, the system is able to
response a reasonable physical phenomenon in real time when the ball hit the paddle.
As shown in Fig.1, the whole system includes a virtual ping pong playground with some
interactive objects, a set of tracking devices, and display screens. The digital game environment
was developed by the use of OpenGL(Wright & Sweet, 1999), C++(Horton, 1998), and MFC(Prosise,
1999) without using commercial software. System interface is the use of magnetic or optical
tracking devices. A pair of low-price webcams is used to develop a tracking device.
表 Y04
Fig.3 LEDs embedded on the paddle
Games can use two types of tracking devices. Magnetic tracker can be purchased in the market.
Advantages are high accuracy, tracking speed of up to 60fps, but the high price. Based on the
price of the reasons, we have adopted a cheap webcam to develop a set of optical tracking
system. Optical tracking device is a fixed location of the camera, and the installation of filters in
front of the camera to capture infrared light. And in the racket may be issued on the installation
of four infrared light led. Optical tracking devices to track the number of LEDs of the coordinate
system set up to determine the racket position in space. We developed an optical tracking
system, the accuracy did not lose a sense of magnetic tracking devices, a lot of cheap, the only
disadvantage for the subject to camera sample rate coupled with the highest computing function
can only be reached 25fps. Optical tracking device to track paddle is more difficult, it is
expected the future to enhance the speed and accuracy of webcam should be up to 30fps more
than sample rate.
We use acrylic as a paddle shell, placed in one of vibration motors, LED and small speakers. The
paddle has a Micro Control Unit, MCU (here we use 8051(MacKenzie, 2006)). The MCU
communicates with PC through wireless connection, ex: Bluetooth(Bluetooth, 2001; Bray &
Sturman, 2002). Every time when the paddle in the screen hits the ball, PC sends a signal
through wireless communication to the paddle, which makes it vibrate.
The Bluetooth module connected with MCU is eb500 from A7 EngineeringTM. It supports simple
serial UART communications, so that it can connect with any PC which supports Bluetooth
service. Once the connection is built, through simple control interface, say, HyperTerminal, PC
and MCU on the paddle can communicate with each other, just like there’s an invisible RS232 
line(Lai, 2008).
In addition to wireless module, we connect some other devices as input or output with MCU,
providing multiple modes of interfacing with the paddle, which is the reason why we call it
“multimodal paddle.” For instance, we connect a button to MCU. When the player serves,
he/she can simply press the button, and the paddle in the screen serves as well. Also, given a
speaker connected with MCU as output, the paddle even makes a sound when hitting the ball, as
表 Y04
the plane takes the ball back and change the speed of the ball.
Fig.5 Sphere through the racket diagram
Real-world ping-pong game, the contestants will hit spin. When the ball is in rotation will be one
rotation axis and rotation Axials _ speed vels _ . Our goal is to calculate the ball's rotation
axis (see Fig.6). Axis of rotation method of calculation is the speed of the ball on the racket
velBall _ vector velocity vector of the velBat _ to do cross, such as equation (1).
velBatvelBallAxials ___  (1)
velBall _ velBat _
N
 Axials _
velchgvelBall _'_ 
'_ Axials
Fig.6 Schematic diagram of the ball with the racket collision
Topspin have two effects, one is the ball and the air friction to change the path of the ball, a
ball are in touch desktop and noodle making, the ball's path will not change. In order to achieve
the immediate effect of the response, the Game does not consider air resistance, only spin and
plane physical phenomena. Spin in touch desktop and make faces, because the relationship
between rotation velocity vector will have one velchg _ . This vector allows the path of the ball
have changed, this vector can be derived using mathematical formulas. Unit normal vector N

and Axials _ are known, then velchg _ is the Axials _ cross N

, available
表 Y04
Results
Fig.9 is the game’s screen, showing the upper left corner of the three-dimensional number is the
ratio of serving and reserving. Since the process of hitting paddle’s angle and the bal hit the 
bouncing, the ball has high and low speed difference. Desktop or paddle have a rotating reaction,
because the paddle and the ball friction. Coordinates obtained by the change in the direction of
the paddle relative speed and acceleration, the ball with the paddle used to determine the
corresponding relationship between the identification of batting skills. For example: the
forehand backhand return of serve, attack, block, pull the ball, cut the ball, twist cut, call the
ball, smash, side spin and so on. Fig.10 shows the official venue set up by the scene, with more
than one table. Fig.11 shows a double rally of the ping pong tournament, the left screen showing
off our moves the ball. Black opponents paddle position by the right side of the screen to see the
perspective of opponents. We have made real-time optical tracking device to track the
trajectories of the racket, the screen showed synchronous movement and ball. Self-made paddle
can be an instant hit ball back to the sound and vibration effects, meanwhile paddle built-in LED
lights flashing simultaneously, showing the creative scene and virtual paddle to catch up.
Fig.9 Single game
Fig.10 Virtual play ground scenery
表 Y04
References
Bluetooth, S. o. (2001). Version 1.1.
Boye, J., Gustafson, J., & Wiren, M. (2006). Robust spoken language understanding in a
computer game. Speech Communication, 48(3-4), 335-353.
Bray, J., & Sturman, C. F. (2002). Bluetooth: Connect Without Cables.
Brunnett, G., Rusdorf, S., & Lorenz, M. (2006). V-Pong: an immersive table tennis
simulation. Paper presented at the IEEE Computer Graphics and Applications,
pp.10-13.
Chen, H.-T., Tien, M.-C., Chen, Y.-W., Tsai, W.-J., & Lee, S.-Y. (2009). Physics-based ball
tracking and 3D trajectory reconstruction with applications to shooting location
estimation in basketball video. Journal of Visual Communication and Image
Representation.
Horton, I. (1998). Ivor Horton's Beginning C++ : The Complete Language ANSI/ISO
Compliant: Wrox Press.
Lai, K.-J. (2008). Implementation of a Digital Environment Ordering Experience System
via Integrated RFID and Bluetooth Technology. Unpublished Master Thesis,
National Chen Kung University, Tainan, Taiwan.
Lin, Y., Fang, J.-J., & al, e. (2007). Virtual Environment Construction for Developmental
Coordination Disorder Assessment. Paper presented at the The ninth Asian
Symposium on Visualization.
MacKenzie, S. (2006). The 8051 Microcontroller.
Nintendo (2009). Retrieved January 18th, 2009, from http://wii.com/
Prosise, J. (1999). Programming Windows with MFC, Second Edition: Microsoft Press.
Wright, R. S., & Sweet, M. (1999). OpenGL SuperBible, Second Edition (2nd Edition):
Pearson Education.
表 Y04
6 分鐘內完成，故相關問題多在會後討論。
十四、 考察參觀活動(無是項活動者省略)
參觀日本 Koyasan 一座最高信仰景點的森林保護區，由寺廟統籌管理多個對日本有貢獻
的皇族、大型企業員工的衣冠塚。
十五、 建議
全球的不景氣引發經濟上全面性的蕭條，筆者感謝國科會計畫提供專任教授出席國際會
議，設法增加台灣在國際舞台的研究知名度與名號，我們也盡力達成該項目標。唯油價能源
上漲相對帶動機票與各城市生活基本支出費用的上揚，建議經濟部計畫取消採用國科會訂定
之日支生活費與機票費標準，採實報實銷方式，以單據核銷，建議只須鎖定計畫總出國旅費
上限。
十六、 攜回資料名稱及內容
會議議程一本：
5. Proceedings of the 9th Pacific and Asian Society of Minimally Invasive Spine Surgery.
十七、 其他
無
表 Y04
國際合作研究計畫心得報告
國科會計劃主持人 方晶晶
ㄧ、雙方 Email 聯繫時間：2009/1/9~2009/8/27
二、本年度由於英方 Heriot-Watt University, Glasgow Dental School,
Strathclyde University 的整合性研究討論尚未提出具體方向，故而拖延
向 EPSRC 提出研究合作計劃案。中英雙方將以 Email 方式先進行計畫書討
論，並未以實質上出差進行雙方互訪，預定下次的互訪時間在 2010 年。以
下一時間先後順序列示，合作研究提案初稿以及 Email 通訊內容。
a. 研提 EPSRC 計畫案初稿
Computer-Aided Surgical Planning, Evaluation and Rehearsal (CASPER) using Haptic
Virtual Reality
Aim
To research a haptic maxillofacial surgical planning system and to evaluate its performance in
operating situations against current surgical planning methods.
Abstract
Maxillofacial surgical planning covers a broad range of surgical procedures and processes which require detailed
planning for each individual patient well before surgery can take place. There are a number of issues associated with
current practice which particularly involve the need to predefine critical geometrical parameters associated with the
patient’s physical form, determine what the key movements in the associated facial skeleton are to correct identified 
deformities and provide detailed instructions for the surgeon to enable them to follow key aspects relating to the
procedure itself and associated milestones.
The purpose of this project is to create and research a haptic virtual reality (VR) based surgical planning system called
CASPER (Computer Aided Surgical Planning, Evaluation and Rehearsal) which will use the interactive and intuitive
nature of haptics to support the full strategic planning of a surgery. This will involve interfacing haptic VR to patient
radiographs to automatically evaluate the key axially symmetric parameters of facial features, support the definition of
osteotomy planes and manipulation of maxillary and mandibular segments to the desired final positions whilst
dynamically calculating, in real time, the key parameters associated with facial symmetry. This will allow the surgeon
表 Y04
especially in conceptual design. As an experienced researcher Dr. Lim has a proven track record of
publications and interdisciplinary work. He has over 35 international journals and conference
publications covering Automatic Feature Recognition, Optimising Tool Selection, Computational
experiments for Virtual Reality (VR) and force feedback Human Computer Interfaces, Design for
Manufacturing and Assembly and Optical computing networks.
Please add your bios here…
Prof. Fang leads her research team working in the filed of CAD, Virtual Reality, Biomedical
Engineering, Object-oriented Programming, Computer Graphics, and Computational Geometry.
Based on the kernel technologies, she deeply involves into the topics of digital human modelling,
automatic anthropometry, 3D garment design, pattern generating, and virtual try-on, and also the
topics of image-guided surgical planning, surgical navigation, and recently, occupational therapy
and rehabilitation. Her team has been granted over 60 projects from government and industry since
1996. Prof. Fang has a proven track record of publications and industry cooperation. She gains four
invention patents from US and TW, and 6 technical transfers from industry. She has over 120
international journals and domestic conference publications, 10 creativity awards since 1996.
Prof. Wong…
Heriot-Watt University is recognised as International Leading in applying user logging and activity
monitoring in a number of unique areas within both design and manufacturing process planning
using immersive virtual reality and haptics. This has included the successful automatic generation
and time estimation of procedural assembly plans for product building [41,42] from user logged
activity data, rationale, reasoning, knowledge capture and information push during design changes
[43], time and motion study analysis of 3D activities through the application and automatic
generation of therbligs and chronocyclegraphs [44,45] and haptic task analysis and evaluation
comparing virtual and real world activities [44-47]. All of these achievements are original in their
concept and have led to a set of tools which can be transferred from manufacturing into the medical
domain to greatly enhance the simulation, planning and capture of medical procedures and expert
surgical knowledge.
Please add Uni/dept specific track record here…
National Cheng Kung University’s establishment in 1931, it has developed into a research intensive
and comprehensive university with integrated academic fields in nine colleges: Liberal Arts,
Sciences, Engineering, Electrical Engineering & Computer Science, Planning & Design,
Management, Social Sciences, Medicine, and Bioscience & Biotechnology. The NCKU College of
Engineering forms the largest engineering college, and is also the most strong and famous
nationwide in Taiwan. In Engineering College, Mechanical Engineering is the oldest and the most
表 Y04
due to the close proximity of highly vulnerable anatomical structures and complex morphology of
the region [13]. For a surgeon to experience surgery kinaesthetic interaction should be included. Yet
the role of physical interaction in the development of surgical knowledge remains underexplored
[14].
Many computer-aided surgical (CAS) simulators have been developed to varying degrees. However,
it remains to be established if any of these systems allow cognitive constructs of surgical knowledge
through the virtual and/or physical examination of surgical practice relationships mediated between
hands and patient. There are still many theoretical and practical problems with software-based
systems, in particular the ability to transfer preoperative planning data to the operating theatre [12].
There is also little attention paid to the assessment of the psychomotor skills that underlie surgical
technique [15,16].
The main projectaims are to streamline the preoperative process in preparing the patient’s treatment 
(including the manufacture of intraoral wafers), minimise operating theatre time and associated
patient trauma, minimise the cost to the funding body associated with the treatment and free up both
resource and human capacity to enable more procedures to be carried out. On average 69% of costs
relate to surgical planning, examination and evaluation (25% relating to manufacturing
consumables used in the surgical procedure) [9]. Currently, within the Glasgow Dental School, a
typical orthognathic operation averages 6.7 theatre hours with around 30 hours of preoperational
planning, examinations and evaluation taking place. If inroads could be made on reducing this by
streamlining the current planning process then considerable cost savings could be achieved. Current
methods incur an average cost to the NHS/patient at £250,000/treatment from initial appointment
through to post-operative follow-up. Currently, for this health board alone, the total cost comes to
around £xxxxxxxx/annum with a potential saving of around £xxxxx/annum assuming a 20%
reduction in operating time. Across the UK this could potentially amount to savings of
£xxxxx/annum.
2. Related work and Application domain
CAS methods have provided surgeons invaluable tools to visualise and to facilitate preoperative
diagnosis, simulate surgery and operation planning [13,15]. Bohner et al’s[17] system for the
simultaneous planning and execution of cranio-maxillofacial operations applied concepts relating to
industrial assembly and process planning with autonomous robots. The automatic generation of
operation plans consider geometric factors like avoidance of critical structures and easy
accessibility of regions to be osteotomised. Aoki et al [18] facilitated computerised drafting of
surgical plans and postoperative prediction using a 3D wireframe head model and surgical functions
for cutting and shifting of bone by mouse operation. Zachow et al’s[19] ‘draw and cut’ 
computer-assisted osteotomy planning method used a pen tablet to draw 2D lines which were
projected onto the 3D surface, giving a surgeon the impression of drawing directly on the planning
model. Olszewski et al [12] proposed augmented reality as a viable method to improve the accuracy
註解 [TL1]: Asraf/Sunny: could you
please check and fill in the xxxs.
表 Y04
surgical knowledge, accrue the surgical skills, compute associated risks and cognitive embodiment
needed to integrate and translate skills. Mol [14] explains the need to examine the role of the
surgeons’ hands with emphasis on objects and their relationships to medical knowledge. Studying 
the relationship between hands and object during surgery moves the observation away from visual
and cognitive models towards a focus on what happens at the interface of hands and instruments.
The cognitive feedback loop of what happens between hands and mind is equally important in
learning [29,36,38,39].
This research aims to address this important gap. CASPER is designed not for ‘realism’ rather its
objective is a generic computer-based platform to conduct surgery planning, evaluation and
rehearsal. The initial focus is on dentofacial surgery planning, investigating methods to understand
and reformulate knowledge about a patient’s metadata and surgeons’ actions so that they are 
digitally compatible. In doing so, CASPER will have the capability to analyse in detail the aspects
associated with the actions and procedural thinking of the surgeon where both detailed task analysis
and surgical rationale and knowledge can be captured both for procedural planning, future use and
expert knowledge ‘push’ to inexperienced surgeons using such systems. It also offers a means of
providing both automated and objective assessment of performance. The essential elements for
logging surgeons and ergonomically analysing procedures, formally capturing and representing
surgical planning methods explicitly with surgical rationale and methods with associated knowledge
push will enable CASPER to be a highly cognitive and experiential learning environment.
3. Research context and objectives
Recent solutions for VR surgery planning have been developed. However, for the surgeon, there are
several disadvantages including restricted mobility (vision-based systems), difficult handling of the
instruments (augmented reality systems) and difficult hand/eye coordination (space-mouse systems);
often with no kinaesthetic feedback. For those that incorporate haptic displays, few have addressed
haptic cognitive issues and even less on qualifying surgical plans, evaluating risks and the ability to
reconstruct surgical knowledge for rehearsals. Surgical learning is inherently tacit and includes
intensive and structured skills training (i.e. seeing, interpreting and intervention). Surmountable
research remains in the area of the man-machine interface.
The literature has revealed that no commercial CAS system in clinical use exists without the need
for a system’sengineer’s inputor has the capability to post-process and output surgical procedure
workflow documentation. Through clinical experience both the Glasgow Dental School and NCKU
hospital have indicated that the matching process is a weak point in most systems. The literature has
further shown there are fundamental gaps in the application of haptic technologies to surgical
processes. No real haptic surgical planning methods have been researched and assessed which allow
the intuitive, real-time generation of surgical process data/instructions for subsequent use at the
operating table. An important part of any surgical procedure is the strategic planning combined with
the tactical aspects. Most systems researched previously in the domain of maxillofacial surgery tend
to look at parts of the process with a view to mimicking ‘reality’. This research recognises that,
表 Y04
Input
Scanned: (e.g. DICOM)–Polygon: (e.g. STL, OBJ)–Image: (e.g. Tiff, JPEG)
P
atientM
etadata
H
istologicaltree
structure
su
pporting:
M
edicalna
rrative
s
+
Im
ages
+
2D
/3D
M
od
el+
K
now
ledge
m
anagem
ent
B
ased
on
O
penE
H
R
stru
cture
(h
ttp://w
w
w
.openehr.o
rg/ho
m
e.htm
l)
Rendering
Multi-modal: Volumetric, Mesh, Points
Texture mapping
Visualisation and Physics
Format: OpenGL
SDK: VTK/ITK, ODE
Toolkit: MITK
Stereoscopic support: desktop, full scale human theatre
ergonomics
Bio Model
Properties: Material, Anatomical features and structures
Function: Geometry and topology query, accessibility,
region classification, etc.
Haptic
Rendering: Elasto-mechanical properties, Friction, Viscosity,
Damping, Vibration, etc.
Device: Phantom Desktop, Omni
Mode: Bimanual, Single
SDK: H3dAPI - VHTK
CASPER Tools
Planning
Method: Interactive,
Manual, Assisted, and
Narrative.
Process: Tracking haptic
motions, hand motions,
interaction capture, data
logging, cognitive
interrogation, G-Theory.
Support: Therbligs,
Chronocyclegraphs, Path
calculation, Feature-
Graphs, heuristics,
Bayesian networks, etc.
Output: Rationale,
Procedural maps, task
documentation, Log files
Evaluation
Method: Objective and
Subjective assessment.
Process: Time-based Skills,
performance accuracy,
coordination trait, motion
analysis, applied forces,
risks.
Support: Haptic, Functional
and morphological fitness
test, comparison to real
domains, Cephalometrical
mapping, scalars and shape
index.
Output: Performance data,
risk ANOVA, Log files
Rehearsal
Method: Replay, Selective
practice.
Process: Time-based,
performance optimisation,
strategy comparison,
Critical incidence.
Support: Haptic, 2D/3D
visualisation, Stereoscopic
views, Desktop or Human
scale, Information ‘Push’.
Output: Self-assessment
data, Optimised plans or
procedures, Log files
Teaching/Training & Assessment/Management
Figure 1: Computer-Aided Surgery Planning,
Evaluation and Rehearsal (CASPER) overall
The research programme focuses on
investigating the use of haptics and associated
3D interaction with patient data to
strategically plan surgery. Research has
indicated attempts to replicate in detail the
physical environment being studied using this
form of technology because there is an inherent
belief that realism is crucial to the effective
planning of such procedures. While the
applicants recognise that realism is a very useful
capability to have, the effective application
of haptic virtual environments is being delayed
because of this conviction. This was also the
case in the mid ‘90s in the domain of assembly
planning, when there was also a conviction
in the literature that assembly planning had to be
carried out in the same realistic manner
[45]. Using immersive VR and contrived
snapping tools allowed assembly planners
the ability to plan intuitively, more effectively
and in much less time than traditional methods
without the need for a physical prototype.
This same philosophy is being applied within this
research study. The applicants feel that a similar,
intuitive strategic planning tool could be researched in a reasonably short period of time and
evaluated to a level where it can be applied in supporting actual surgical procedures. As realism
becomes more and more possible then this planner can subsequently be developed to accommodate
this capability at the appropriate stage of the process assuming that it is necessary. Focussing on
the strategic nature of the surgical planning, where important stage-by-stage activities and decisions
are made, rather than distracting the research into real world simulations and detailed tactical
surgery, opens up substantial opportunities to demonstrate the capability of this technology to the
wider surgical world in real life situations. An overview of the CASPER framework is shown in
Figure 1.
Regarding the academic partners, the team from Heriot-Watt University comprise the Digital Tools
Group which is part of the EPSRC’s Innovative Manufacturing Research Centre, the SMI
(www.smi.hw.ac.uk). Having had considerable success in applying virtual environments, including
haptics, to product design and manufacturing processes as well as user evaluation and knowledge
capture they are now in a position to apply the same methods to surgical planning, which they see
as a natural extension to the manufacturing domain. This part of the project will be led by Prof. J.
表 Y04
feedback obtained from expert surgeons. It is also deliberately targeted at the lower cost range
solutions with a view to applying the outputs from the work as widely as possible once completed;
the only way to achieve this is by keeping the investment costs associated with the technology to a
minimum. Open source software solutions will be used where possible, again with a view to
keeping the costs down. The Wii wand-type device will also be evaluated to see if an even cheaper
solution can be obtained. A rapid prototyping facility is also requested since this will be used to
evaluate the system against previous operations carried out as well as providing a means of
validating the planned surgical procedures before the system is used in anger. The equipment
recommended is as follows:
 2 Phantom haptic devices (2 x £13,000).
 Wall mounted VR display (inc. projectors, glasses) (£30,000).
 Personal Space tracking system (£4000).
 Desktop display/PC (£7000).
 Wii (2 x £150).
 Laptops (2 x £2000).
 Software: H3D API, VTK/ITK/OpenGL, ODE (Open Dynamics Engine), OpenEHR,
MSVC2008.
 Voice input software (Dragon Naturally Speaking) (£100)
 Fused-deposition modelling (FDM) rapid prototyping (RP) machine (£35,000).
4.1.2 System Design, Operation and Work Plans
It is planned to run the project in two sequential work packages:
1. WP 1–Fundamental strategic maxillofacial planning and training.
2. WP 2–Enhanced maxillofacial jaw bone replacement planning and training.
However, it should be borne in mind that there is potential for overlap depending on the progress of
WP1 as well as opportunities for NCKU to considerably extend the later WP should their proposal
applications be successful. A Gantt chart summarising the project plan is given in Appendix 1.
WP 1- Fundamental strategic maxillofacial planning and training
CASPER intends to allow surgeons to directly manage and develop a strategic approach to
sequencing surgical activities from patient radiographic data (Figure 2). This relates to procedures
carried out to support patient full jaw reconstruction, particularly those associated with orthognathic
treatment, a particular specialism of Glasgow Dental School. This process was defined after both
detailed discussion with the surgical experts involved in this project and through the direct
observation of actual operations, particularly by the non-medical academics. WP1 aims to provide
an interactive 3D haptic VE that allows the surgeon to plan the procedure in a simpler, intuitive and
user friendly sequence of recognisable steps which truly represent all of the stages of the overall
process. A similar approach and interface developed in [48,49] discovered that human behaviour in
the real and virtual worlds mapped onto each other, even through various precedence, could be
easily broken. Individuals immersed in a VE were found to carry out tasks in the same manner as in
表 Y04
 Procedural process map supplemented with video images of virtual planned process, key
parameters and English syntax/voice instructions all combined to form a readable time-phased
multiple output storyboard.
 Final jawbone displacement positions and axes from surgical datum.
 Symmetry values for patient.
 Jaw template masters, spacers for preoperational cutting and forming of same.
 Screw, spacer, template picking list.
 Intraoral wafer set for jaw alignment.
Initially, the system will be used by experienced surgeons with a view to its evaluation and
improvement both operationally and interactively. As the system becomes useable prior patient
procedures will be studied and these will be planned and compared using the new tool. Although it
will be difficult to determine exactly what the improvements are over previously used methods
some degree of magnitude will hopefully become apparent, especially at specific stages of the
process. One key aspect of the research at this stage will be the use of the FDM machine to provide
detailed skull models of the patient. These will be cut up following the process outlined by the
system and the jaw templates, teeth templates, screw positions and spacers checked using this
model. This will be done in around 30 cases to determine the robustness and accuracy of the system.
Amendments will be made to the system based on feedback from these RP tests. Once confidence in
CASPER is definite and its outputs and benefits become apparent, it will then be applied to actual,
on-going procedures in parallel with existing methods. When full confidence is obtained from the
surgical team then it will be used as the sole method for planning such surgical procedures.
CASPER wil also be evaluated in detail as a training tool, as expert surgeons’ strategies wil be 
captured and compared to those developed by trainee surgeons. This will involve similar techniques
and methods researched in the product design and manufacturing domain whereby the inexperience
of the user will be identified and then advice pushed to the trainee surgeon regarding the optimum
process. A number of trials will take place whereby trainee surgeons will be asked to operate the
system at various stages in their training and their ‘learning’ wil be logged and evaluated against 
best practice. They will then be compared to a control group which will go through the training for
this type of procedure in the traditional way. One key output for the trainee surgeons will be RP
models demonstrating the physical accuracy of their solutions; giving them real feedback on what
they would have achieved –theoretically- in the operating theatre. These physical models can be
compared with physical models of the expert solution for the problem that they have attempted.
Such a process should not only allow the rapid advancement of trainee surgeons up the learning
curve but will also allow them to strategically experience the process time and time again until they
are confident in how it is carried out. These confidence levels can also be measured through the
system with information push from experts being embedded in the system to help weaker trainees in
a manner similar to that developed and implemented in the mechanical product engineering domain.
表 Y04
Similar to WP1, a key aspect of
the research will also be the use of
the FDM to provide detailed
skull models of the patient for
evaluation prior to full system use.
These will be cut following
the process outlined by the system
and the jaw templates,
replacement bone fragment,
screw positions and spacers
checked using this model. This will
be done in around 30 cases to determine the robustness and accuracy of the planner, although
confidence in using this method has already been obtained by the Taiwanese partners [ref].
Amendments will be made to the system based on feedback from these RP tests. Once confidence in
the system is definite and its outputs and benefits become apparent, it will then be applied to actual,
on-going procedures in parallel with existing methods. When full confidence is obtained from the
surgical team then it will be used as the sole method for planning such surgical procedures.
Again, this part of the system will be used and evaluated for training purposes. Control group
training will also be included as in WP 1 and the training experiments, incorporating expert
knowledge push, designed in exactly the same way as before.
5. Outputs
The main outputs from this research will be as follows:
 A virtual reality haptic maxillofacial surgical planning tool covering two major procedures
within this domain; this system forming the foundation for expansion into real-world virtual
surgical representations, e.g. cutting, tissue simulation, mapping onto actual operation tracking
 Results from robust, well designed experimentation and cost-benefit analyses demonstrating the
potential of this technology for strategic and tactical surgical planning in actual procedures.
 Formalised methodologies for evaluating and testing such tools in surgical environments.
 Human factors feedback on system design, modification and performance in real surgical
situations.
 A fully operational tool for future use in surgical planning within the medical partners’ facilities.
 Instantiations of automated surgical knowledge capture from expert surgeons.
 A thorough evaluation of haptics as a surgical training technology.
5.1 Exploitation
Assuming the tool can be developed by a systems development company it will be developed as a
marketable opportunity and will be exploited by the joint academic partners in the form of an IP
agreement which will reflect the proportion of the work carried out by each institution. (Have to
Figure 3: WP2: Maxillofacial Jaw Replacement Surgical
Planning and Training System
表 Y04
system specification and implementation as well as experimental planning and organisation. The
second RA will also have a strong programming background along with human factors experience
in evaluating human-machine interfaces. They will both be tasked with ensuring that proper systems
evaluation takes place as defined by the project proposal as well as the output of properly and
professionally documented code.
In terms of equipment, the following hardware is requested:
 Two pairs of haptics devices enabling the implementation of bimanual operational procedures
(£26,000)
 Two passive bench-top 3D stereo displays to evaluate the tool in typical office environments
(£7,000).
 A multi-user immersive wall supporting full ergonomic scale manipulation and planning for
comparison with bench-top solution (£30,000).
 A FDM machine to produce skull and bone parts for the physical evaluation of planned
procedures (£40,000).
 Two laptops for presentations and data gathering (£2,000).
 Voice input software (£100).
 Wiis (£300).
University of Strathclyde
Xxxxxx
Glasgow Dental School
Xxxxxxx
National Cheng Kung University, Taiwan
The resources being dedicated to the project by NCKU include……
8. Industrial Contribution
The project will receive support (in both cash and kind) from collaborators representing both potential developers and
users of the technology. Discussions are currently underway with the following organisations: (Need to firm this up!!!)
Xxxxxxxxxxxxxxxxxxx
9. Management of project
Day to day management: this will be the responsibility of the investigators at each site with the
overall coordination carried out by the senior RA. There will be weekly meetings with supervisors.
In addition to this, there will be regular, quarterly, formal Programme Committee meetings. This
forum will comprise project participants from the academic institutions, project collaborators (when
available). NCKU will be included depending on funding from Taiwan; however, a web-based
communications environment will be set up for document exchange, on-line meetings and regular
註解 [TL5]: JC: Any gear needed?
註解 [TL6]: Asraf/Sunny: Have already
included your requirements for VR
equipment above. Please let me know if
alright.
註解 [TL7]: All: Please can you write a
few lines regarding the companies who
you’l approach for this project.
表 Y04
wide range of engineering journals.
References
1. Ludmerer K.M., Time to heal: American Medical Education from the Turn of the Century to the
Era of managed Care, New York, Oxford University Press, 1999.
2. Cuschieri A., Human reliability assessment in surgery–A new approach for improving surgical
performance and clinical outcome, Annuals of the Royal College of Surgeons England,
82:83-87, 2000.
3. Arnold L, Assessing Professional Behaviour: Yesterday, Today, and Tomorrow. Academic
Medicine. 77(6):502-515, 2002.
4. Mishra R., Study cites risks of low-volume surgeries. Boston Globe, 1 March 2003.
5. Brasel K., Surgical critical care. The American Journal of Surgery, 193(1):127 - 129, 2007.
6. Graber T.M., Vanarsdall Jr R.L. and Vig K.W.L., Orthodontics. Current principles & techniques,
4th edition, Pub: Elsevier, St Louis, Missouri, USA, 2005. ISBN: 0-323-02621-4.
7. Neumann P., Siebert D., Schulz A., Faulkner G., Krauss M., Tolxdorff T. Using Virtual Reality
Techniques in Maxillofacial Surgery Planning. Virtual Reality, 4:213-222, 1999.
8. Panula K., Keski-Nisula L., Keski-Nisula K., Keski-Nisula S., Oikarinen K., Costs of
surgical-orthodontic treatment in community hospital care: An analysis of the different phases
of treatment. Int. J Adult Orthodon. Orthognath. Surg., 17(4):297-306, 2002.
9. Kumar S., Williams A., Sandy J., Orthognathic cases: what are the surgical costs? European
Journal of Orthodontics, 30(1):31-39, 2008.
10. Opitz C., Ring P., Stoll C., Orthodontic and Surgical Treatment of Patients with Congenital
Unilateral and Bilateral Mandibulofacial Dysostosis, J. of Orofacial Orthopedics, 65(2): 150 -
163, 2004.
11. Sharifi A., Jones R., Ayoub A., Moos K., Walker F. Khambay B., McHugh S., How accurate is
model planning for orthognathic surgery?, Int. J. Oral Maxillofac. Surg., 2008. DOI:
10.1016/j.ijom.2008.06.011.
12. Olszewski R., Villamil M.B., Trevisan D.G., Nedel L.P., Freitas C.M.D.S., Reychler H., Macq
B., Towards an integrated system for planning and assisting maxillofacial orthognathic surgery,
Computer Methods and Programs in Biomedicine, 91(1):13-21, 2008.
13. Zeilhofer H-F, 3D applications in modern high-tech surgery, Materialise Medical Innovations
Conference, Vienna, Austria, May 30-31, 2008.
14. Mol A., The Body Multiple: Ontology in medical practice. Duke University Press, 2002.
ISBN-10: 0822329174.
15. Martin J.A., RRegehr G., Reznick R., Macrae H., murnaghan J., Hutchinson C., Brown M.,
Objective structure assessment of technical skills (OSATS) for surgical training, British J. of
Surgery, 84:273-278, 1997.
16. Darzi A., Mackay S., Skills assessment of surgeons, Surgery, 131(2):121-124, 2002.
註解 [TL10]: All: Any others you think
should be added?
表 Y04
32. Moody L., Baber C. and Arvanitis T.N. Objective metrics for the evaluation of simple surgical
skills in real and virtual domains. Presence, 12(2): 207-221, 2003.
33. Burgert O., Salb T., Gockel T., Dillmann R., Hassfeld S., and Muhling J. A VR-system
supporting symmetry related cranio-maxillofacial surgery. Stud. Health. Technol. Inform.
94:33-35, 2003.
34. Eriksson M.G. Haptic and Visual Simulation of a Material Cutting Process. A Study Focused on
Bone Sugery and the Use of Simulators for Education and Training. Licentiate Thesis, Dept. of
Neuronic Engineering KTH-STH, SE-141 57 Huddinge, 2006. ISSN 1653-3836.
35. Zachow S., Gladilin E., Zeilhofer H-F. and Sader R. Improved 3D Osteotomy planning in
cranio-maxillofacial surgery. In W. Niessen and M. Viergever (Eds.), MICCAI 2001, LNCS
2208, pp. 473-481, 2001.
36. Harders M., Szekely G., Le Mercier B., Drif A., Citerin J., Pocheville A., Hatab M., Talbi N.,
Kheddar A., Sgambelluri N., Valentina H., Esen H., Fritschi M. and Buss M. Report on
Demonstration Scenario Specifications. TOUCH-HapSys Towards a Touching Presence: High
Definition Haptic Systems. IST-2001-38040, 2004, http://www.touch-hapsys.org.
37. SensAble Technologies Inc., 15 Constitution Way, Woburn, MA 01801.
http://www.sensable.com.
38. Baber C., Cognitive aspects of tool use, App. Ergon., Fundamental Reviews, 37(1):3-15, 2006.
39. Zadeh M.H., Wang D., and Kubica E. Active manipulation of users in haptic-enabled virtual
environments. Proc. 1st Int. Conf. on Amb. Media and Sys., Quebec, Canada, Feb. 11 - 14, 2008.
40. Salb T., Brief J., Burgert O., Hassfeld S. and Dillmann R., Haptic based risk potential mediation
for surgery simulation, Proc. 1st Int. Workshop on Haptic Devices in Medical Applications
(HDMA), Paris, June 1999.
41. Ritchie J.M., Sung R.C.W., H. Rea, Lim T., Corney J.R., I. Howley, The Use of Non-intrusive
User Logging to Capture Engineering Rationale, Knowledge and Intent during the Product Life
Cycle, PICMET '08, Portland, July 27-31, 2008.
42. Ritchie, J.M., Sung R.C.W., Rea H.J., Lim T., Corney J.R., Salamon C., Howley I., Automated
knowledge capture in 2d and 3d design environments, 2nd International Workshop on Virtual
Manufacturing, VIRMAN'08, 6 Oct 2008.
43. Ritchie, J.M., T. Lim, Sung R.C., Medellin H., Generation of Assembly Process Plans and
Associated Gilbreth Motion Study Data, 2nd Int. Workshop on Virtual Manufacturing,
VIRMAN'08, 6 Oct 2008.
44. Lim T., Corney J., Ritchie J., Assessment of a Haptic Virtual Assembly System that uses
Physics-based Interactions, IEEE Int. Sym. on Assembly and Manufacturing, 2007.
45. Ritchie J.M., Lim T., Sung R.C.W., Corney J.R., Rea H., PART B: The analysis of design and
manufacturing tasks using haptic and immersive VR–Some case studies, ASI’07, Crete, Greece, 
30 May–6 June 2007.
46. Lim T., Ritchie J.M., Dewar R.G., Corney J.R., Wilkinson P., Calis M., Desmulliez M. and Fang
J-J., Factors affecting user performance in haptic assembly, Virtual Reality Special Issue,
Springer Publications, ISSN: 1359-4338, 2007.
表 Y04
b. Email 通訊內容
From: Lim, Theodore
To: Ashraf Ayoub ; Jonathan Corney ; Jing-Jing Fang ; Ritchie, James M ; Xiu T Yan
Sent: Saturday, January 24, 2009 3:55 AM
Subject: RE: Surgical proposal
Hi Ashraf,
Yes. Please give some dates that may be good for you.
Best,
Theo.
From: Ashraf Ayoub
To: Lim, Theodore ; Jonathan Corney ; Jing-Jing Fang ; Ritchie, James M ; Xiu T Yan
Sent: Saturday, January 24, 2009 1:56 AM
Subject: RE: Surgical proposal
Dear Theo,
I am wondering if we should meet in Glasgow to discuss this proposal further, thus may facilitate the next
phase of structuring the grant application.
Regards
Ashraf Ayoub
From: Ritchie, James M
To: Jonathan Corney ; Lim, Theodore ; Jing-Jing Fang ; Xiu T Yan ; Ashraf Ayoub
Sent: Friday, January 23, 2009 7:20 PM
Subject: RE: Surgical proposal
Hi
Sounds fine to me... Main concerns and comments highlighted below.
The concept behind the proposal is to research a strategic planning system, not one
that totally tries to mimic tactically an actual cutting, 'assembly' and joining
procedure with force feedback too earl on. The aim being to provide a cost-effective
tool using proprietary kit and software that, when researched, can be picked up and
表 Y04
Hi JC,
Sounds good. I like the idea of building our own haptic devices. But i guess we'll still need to have at least a
pair of Omni's or Novint Falcons to begin with. Speaking to Johan, it seems the Novint Falcon can be
modified with finger thimbles and if so, can be reconfigured to create a cross between a spider haptic and
cybergrasp device. The Falcons go for under Euro 200, config is a 3-axis parallel haptic device.
Actually this system from http://www.ps-tech.com/product/psp/ is pretty useful for surgical simulation. Real
surgical tools can be used if necessary. Tried it at a recent conference. Shouldn't be too much work to make
a system like that based on Wii-motes, webcams and reflective tape. But will still need some force feedback
device for kinaesthetic interaction.
I've seen some Eden 3D samples from Coventry Uni... really nice. Are you guys getting the Eden?
Please add your contributions to the document and scope out a work plan. Could you also write a few lines
on the impact of this in section 11?
Many thanks,
Theo.
From: j.r.corney@gmail.com on behalf of Jonathan Corney
Sent: Thu 22/01/2009 21:52
To: Lim, Theodore; Jing-Jing Fang; Ritchie, James M; Xiu T Yan; Ashraf Ayoub
Subject: Re: Surgical proposal
Hi,
If its useful we could reduce the equipment costs a bit.....
We have just placed an order for any Objet printer
http://www.objet.com/
The materials, appear to be suitable for medical applications
http://www.objet.com/Default.aspx?tabid=450
so the budget need only be for material costs rather than a whole machine?
Also discussed the project with Xiu, ..we thought that perhaps we should
aim to build our own haptic system, specifically designed for
表 Y04
Many thanks,
Theo.
From: Lim, Theodore
To: Jing-Jing Fang ; Ashraf Ayoub ; Ritchie, James M ; Balvinder Khambay
Cc: jonathan.corney@strath.ac.uk ; wongty@mail.ncku.edu.tw
Sent: Wednesday, January 14, 2009 5:30 PM
Subject: RE: Surgical proposal
Hi Jing-Jing,
Thank you for the comments. I will amend the document.
Many thanks,
Theo.
From: Jing-Jing Fang [mailto:fangjj@mail.ncku.edu.tw]
Sent: Tue 13/01/2009 06:59
To: Lim, Theodore; Ashraf Ayoub; Ritchie, James M; Balvinder Khambay
Cc: jonathan.corney@strath.ac.uk; wongty@mail.ncku.edu.tw
Subject: Re: Surgical proposal
Dear all,
Happy New Year.
Here are some comments input from Dr. Wong.
I wound suggest not limiting the use of this CASPER in orthognathic surgery, though we
may find the new system most useful in this scope. Computer-assisted surgery has been
applied mostly to the reconstruction cases in our clinic, such as following segmental
mandibulectomy. The impact of this study will be very positive. Shortening the
planning or operation time is just one of the benefits. We can apply the new
technologies in the surgery to accomplish that degree of accuracy and predictability
unparallel before.
Hope it help.
Best Regards,
表 Y04
for fairly similar procedures in the US but have not found any papers or articles for UK or EU.
Regarding budget... i'm expecting it to be between £850K to £975K FEC as we wish to seek 2 RAs and 2
PhDs. I think if we get most of our equipment from Inition, Stuart will give a good discount. He's already
indicated he'll provide a letter of support.
Many thanks for your comments.
Much appreciated,
Theo.
----- Original Message -----
From: Ritchie, James M
To: Ashraf Ayoub ; Lim, Theodore ; Balvinder Khambay
Cc: fangjj@mail.ncku.edu.tw ; jonathan.corney@strath.ac.uk ; wongty@mail.ncku.edu.tw
Sent: Sunday, January 11, 2009 6:49 PM
Subject: RE: Surgical proposal
Happy New Year Ashraf!
Thanks for this useful feedback and the recommended improvements. In WP1 we already have suggested
that we validate the system by looking at previous cases; this is one of the reasons we have asked for the
RP machine, to do this physically as well. Apologies for the MRI mistake, it was me and not Theo that put
together that section initially, so thanks for the correction.
Theo and I will get back to you next week sometime regarding your suggestions. However, in the meantime,
if you could approach the CEO of Di3D as well as recommend an NHS economist, cancer surgeon and
statistician then that would be excelent. If you require us to find the later then we wil try and do this. We’l 
also look for other industrial partners.
We weren’t sure if we could include patient assessment in the way you’ve suggested, so it’s excelent that 
this is the case. Your suggestion will certainly bring a lot of credibility to the research; a great idea.
Regards,
Jim
Prof. James Ritchie
表 Y04
clinicians and perhaps technologist who are currently conduct prediction planning on plaster models
how to operate in an VE
c.We require the necessary equipment to build a 3D virtual lab. which includes 3D projector, lap top,
screen, etc for clinical demonstration and to allow the trainees to carry out interactive simulation of
surgical correction of maxillofacial deformities. Patients may be also invited to this lab to discuss
treatment options, explained surgical techniques and get them to take part in the decision making
process. Full partnership of the patients in the surgical treatment would be an added strength to our
proposed grant application. Evaluation of patients' satisfaction and improvement regarding their
understanding of the surgery that they are about to have would be also analysed and measured.
d. Glasgow university would request some funding (salary recope) to cover some of the time that
Sunny & I would be spending in this project.
7. We need to involve a statistician to carry out power calculation and sharpen our approach
for data analysis.
At this stage it may be useful to agree on the total budget of the project and the time table to
conclude this application.
Regards
Ashraf Ayoub
From: Lim, Theodore [mailto:T.Lim@hw.ac.uk]
Sent: Mon 05/01/2009 18:17
To: Ritchie, James M; Balvinder Khambay; Ashraf Ayoub
Cc: fangjj@mail.ncku.edu.tw; jonathan.corney@strath.ac.uk; wongty@mail.ncku.edu.tw
Subject: RE: Surgical proposal
Hi all,
Please find the newly formatted version with 'tracked changes'. Please could everyone also add their bios,
contributions and a short description of your respective establishment.
The work packages also needs to be 'firmed' up. Please add relevant references and check that the work
packages are acceptable and edit where necessary.
Sunny and Victor:
Could you please fill in (or edit) approximate surgical costs and provide an idea on how much time and cost
is directly attributed to the planning procedure based on an average complex case? Also, please review and
表 Y04
From: raf-bounces@list-serve.hw.ac.uk [mailto:raf-bounces@list-serve.hw.ac.uk] On Behalf Of Thompson, Paul J
Sent: 08 January 2009 08:48
To: raf@list-serve.hw.ac.uk
Subject: RAF: Grant applicants to be rated on impact and excellence
All,
>From rr.com:
The research councils will this year require grant applicants to describe the potential social and economic impact of
their research proposals, as well as convincing reviewers of a proposal's excellence.
Following changes to grant application requirements, applicants will be asked to produce an 'impact summary'
addressing who will benefit from their research, how they will benefit and what they will do to ensure benefit.
Meanwhile, peer reviewers will be asked to consider whether the plans to increase impact are appropriate and justified,
given the nature of the proposed research. And they will be told to consider both excellence and impact when
prioritising research proposals for funding.
The Biotechnology and Biological Sciences Research Council will be the first to implement the changes, from 15
January. The Economic and Social Research Council and the Arts and Humanities Research Council will bring in the
changes in February. The Natural Environment Research Council, the Engineering and Physical Sciences Research
Council and the Science and Technology Facilities Council will do so in April.
The Medical Research Council, which unlike the other councils doesn't use the Joint Electronic Submissions system, or
Je-S, does not plan to make changes. However, a spokeswoman for Research Councils UK said applicants to the MRC
are already required to answer questions on the potential impact of their research.
RCUK says the principle of requiring researchers to consider the impact of their research isn't entirely new, but that the
explicit inclusion of questions on the subject will set out more formally who the potential beneficiaries of research will
be. An RCUK spokeswoman claimed that the changes would not result in research without an obvious or immediate
impact losing funding. "We do recognise that impact takes many forms and can take a while to realise," she said.
_________________________________________
Dr Paul J Thompson,
Information & Planning and ERPem/SRPe Administration,
TRS - Technology & Research Services
Heriot-Watt University, Scott Russell Building
表 Y04
Room 2.33
James Nasmyth Building
Riccarton
Edinburgh
EH14 4AS
Phone: + 44 (0) 131 451 4364
Fax: +44 (0) 131 451 3129
J.M.Ritchie@hw.ac.uk
From: Lim, Theodore
Sent: 23 December 2008 18:09
To: Ritchie, James M
Cc: fangjj@mail.ncku.edu.tw; jonathan.corney@strath.ac.uk
Subject: RE: Surgical proposal
Hi Jim, JC, Jing-Jing,
Here's the latest version with some diagrams.
Could you start to review it and add your parts in? We will need to shrink Part 2 of the document to 6 pages.
Also, please add in your relevant papers in the lit review.
I'm hoping we can get a draft for Glasgow people by early or mid Jan 09.
Many thanks.
Merry Xmas,
Theo
From: Lim, Theodore
To: Ritchie, James M ; Balvinder Khambay ; Ashraf Ayoub
Cc: fangjj@mail.ncku.edu.tw ; jonathan.corney@strath.ac.uk ; wongty@mail.ncku.edu.tw
Sent: Tuesday, January 06, 2009 2:17 AM
Subject: RE: Surgical proposal
Hi all,
Please find the newly formatted version with 'tracked changes'. Please could everyone also add their bios,
contributions and a short description of your respective establishment.
表 Y04
Many thanks in advance,
Theo.
From: raf-bounces@list-serve.hw.ac.uk [mailto:raf-bounces@list-serve.hw.ac.uk] On Behalf Of Thompson, Paul J
Sent: 08 January 2009 08:48
To: raf@list-serve.hw.ac.uk
Subject: RAF: Grant applicants to be rated on impact and excellence
All,
>From rr.com:
The research councils will this year require grant applicants to describe the potential social and economic impact of their
research proposals, as well as convincing reviewers of a proposal's excellence.
Following changes to grant application requirements, applicants will be asked to produce an 'impact summary' addressing who
will benefit from their research, how they will benefit and what they will do to ensure benefit. Meanwhile, peer reviewers will
be asked to consider whether the plans to increase impact are appropriate and justified, given the nature of the proposed
research. And they will be told to consider both excellence and impact when prioritising research proposals for funding.
The Biotechnology and Biological Sciences Research Council will be the first to implement the changes, from 15 January.
The Economic and Social Research Council and the Arts and Humanities Research Council will bring in the changes in
February. The Natural Environment Research Council, the Engineering and Physical Sciences Research Council and the
Science and Technology Facilities Council will do so in April.
The Medical Research Council, which unlike the other councils doesn't use the Joint Electronic Submissions system, or Je-S,
does not plan to make changes. However, a spokeswoman for Research Councils UK said applicants to the MRC are already
required to answer questions on the potential impact of their research.
RCUK says the principle of requiring researchers to consider the impact of their research isn't entirely new, but that the
explicit inclusion of questions on the subject will set out more formally who the potential beneficiaries of research will be. An
RCUK spokeswoman claimed that the changes would not result in research without an obvious or immediate impact losing
funding. "We do recognise that impact takes many forms and can take a while to realise," she said.
_________________________________________
表 Y04
b. We would need a Haptic device, this is required in a clinical environment for training clinicians and
perhaps technologist who are currently conduct prediction planning on plaster models how to operate in
an VE
c.We require the necessary equipment to builda 3D virtual lab. which includes 3D projector, lap top,
screen, etc for clinical demonstration and to allow the trainees to carry out interactive simulation of
surgical correction of maxillofacial deformities. Patients may be also invited to this lab to discuss
treatment options, explained surgical techniques and get them to take part in the decision making
process. Full partnership of the patients in the surgical treatment would be an added strength to our
proposed grant application. Evaluation of patients' satisfaction and improvement regarding their
understanding of the surgery that they are about to have would be also analysed and measured.
d. Glasgow university would request some funding (salary recope) to cover some of the time that Sunny
& I would be spending in this project.
7. We need to involve a statistician to carry out power calculation and sharpen our approach fordata
analysis.
At this stage it may be useful to agree on the total budget of the project and the time table to conclude
this application.
Regards
Ashraf Ayoub
From: Ritchie, James M
To: Ashraf Ayoub ; Lim, Theodore ; Balvinder Khambay
Cc: fangjj@mail.ncku.edu.tw ; jonathan.corney@strath.ac.uk ; wongty@mail.ncku.edu.tw
Sent: Sunday, January 11, 2009 6:49 PM
Subject: RE: Surgical proposal
Happy New Year Ashraf!
Thanks for this useful feedback and the recommended improvements. In WP1 we already have suggested
that we validate the system by looking at previous cases; this is one of the reasons we have asked for the
RP machine, to do this physically as well. Apologies for the MRI mistake, it was me and not Theo that put
together that section initially, so thanks for the correction.
Theo and I will get back to you next week sometime regarding your suggestions. However, in the meantime,
if you could approach the CEO of Di3D as well as recommend an NHS economist, cancer surgeon and
statistician then that would be excelent. If you require us to find the later then we wil try and do this. We’l 
also look for other industrial partners.
表 Y04
Meanwhile, could you send me a few lines on where you see the impact of this research.. e.g. in NHS's view
and also to your domain. I'm not sure if this is to be on a separate page or within the 'case for support' but
this is now required by the funding councils.
Could you also let us know average timeframes of current planning procedures? I've cited the average time
for fairly similar procedures in the US but have not found any papers or articles for UK or EU.
Regarding budget... i'm expecting it to be between £850K to £975K FEC as we wish to seek 2 RAs and 2
PhDs. I think if we get most of our equipment from Inition, Stuart will give a good discount. He's already
indicated he'll provide a letter of support.
Many thanks for your comments.
Much appreciated,
Theo
From: Lim, Theodore
To: Jing-Jing Fang ; Ashraf Ayoub ; Ritchie, James M ; Balvinder Khambay
Cc: jonathan.corney@strath.ac.uk ; wongty@mail.ncku.edu.tw
Sent: Wednesday, January 14, 2009 5:30 PM
Subject: RE: Surgical proposal
Hi Jing-Jing,
Thank you for the comments. I will amend the document.
Many thanks,
Theo.
From: Jing-Jing Fang [mailto:fangjj@mail.ncku.edu.tw]
Sent: Tue 13/01/2009 06:59
To: Lim, Theodore; Ashraf Ayoub; Ritchie, James M; Balvinder Khambay
Cc: jonathan.corney@strath.ac.uk; wongty@mail.ncku.edu.tw
Subject: Re: Surgical proposal
Dear all,
Happy New Year.
表 Y04
Please edit the document and send me the edited version. I will then merge all comments and edits,
hopefully to a 6 page draft in the net few weeks.
Looking forwards to your input.
Many thanks,
Theo.
From: "Jonathan Corney" <Jonathan.Corney@strath.ac.uk>
To: "Lim, Theodore" <T.Lim@hw.ac.uk>; "Jing-Jing Fang" <fangjj@mail.ncku.edu.tw>; "Ritchie, James
M" <J.M.Ritchie@hw.ac.uk>; "Xiu T Yan" <x.yan@strath.ac.uk>; "Ashraf Ayoub"
<a.ayoub@dental.gla.ac.uk>
Sent: Friday, January 23, 2009 5:52 AM
Subject: Re: Surgical proposal
Hi,
If its useful we could reduce the equipment costs a bit.....
We have just placed an order for any Objet printer
http://www.objet.com/
The materials, appear to be suitable for medical applications
http://www.objet.com/Default.aspx?tabid=450
so the budget need only be for material costs rather than a whole machine?
Also discussed the project with Xiu, ..we thought that perhaps we should
aim to build our own haptic system, specifically designed for
maxillofacial surgery simulation, e.g. large forces, restricted
access, two handed grips
rather than the pen like stylus?
We don't think that it would be technically that difficult, see for example
www.deskeng.com/articles/aaaedn.htm
http://windblownbytes.wordpress.com/2008/03/05/realistic-sense-of-touch-via-haptic-tech/
http://cat.inist.fr/?aModele=afficheN&cpsidt=18182962
表 Y04
Hi
Sounds fine to me... Main concerns and comments highlighted below.
The concept behind the proposal is to research a strategic planning system, not one
that totally tries to mimic tactically an actual cutting, 'assembly' and joining
procedure with force feedback too earl on. The aim being to provide a cost-effective
tool using proprietary kit and software that, when researched, can be picked up and
used in everyday mode by the surgeons in a wide variety of areas; this is a key selling
point of the research. This will also provide us with a means of estimating cost benefits.
I don't think we want to lose this too much.
However, having a realism/training with a device like this would be a good thing as
well since it shows we're thinking about where this would go in the future. So, if
we do this 'realism' type of project in parallel to the procedural planning work and
make sure it fits in ok with this aim and doesn't dominate or distract from the overall
main scope of the project then it should be ok. I just hope the reviewers don't see
it as two separate projects; so we'll have to be careful. I think with Strathclyde
also doing something on the data mining/analysis stage as well then the link will
be strong enough. Analysing material properties, bone, etc. for cutting will also
be a good joint project between HWU and Strathclyde.
Good idea with the RP materials, which we can still buy of course, but we'd still
like a project-specific RP machine here as part of the work since we'd like to try
out sequences beforehand. Maybe Theo has another view on this. However, in the end
we'll just have to see how the costs work out.
Regards,
Jim
Prof. James Ritchie
Heriot-Watt University
School of Engineering and Physical Sciences
Mechanical Engineering
Room 2.33
James Nasmyth Building
Riccarton
Edinburgh
