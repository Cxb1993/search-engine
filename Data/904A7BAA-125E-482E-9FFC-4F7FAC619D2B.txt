  - 2 - 
we adopt a new framework to match the 
syllable sequences coming from the best 
combination of acoustic and language model in 
the PPR experiment with the language 
dictionary to create the words test on 
code-switching speech corpus without language 
boundary information. Through the advanced 
accuracy estimation by two different evaluated 
methods, i.e. language tag and duration of 
monolingual segment, we achieve the identified 
accuracy about 83.4% and 78%, respectively. 
 
2. 計畫緣由 
台灣是一個多語系的環境，華語與台語是目
前台灣人們在溝通上最主要且普遍的兩種語
言。因此我們可以常常聽到華語與台語混合
的語句在平常的對話中，如「今天晚上有“夜
市仔”」。這樣的混合語句 (Code-Switching 
speech)，也可在香港(英語-粵語的混合語句)
或新加坡(英語-華文的混合語句)等地聽到 
[1-3]。而這樣的情況也越來越受到這個領域
的專家學者重視。 
所謂的混合語句指的就是由在地語者講
出一段語音包含了兩種或兩種以上的語言，
而這段語音中，兩種與間相互的交替轉換 
[4]。語者從一種語言轉用另一種語言的原因
主要歸分為兩類，一是語者利用特定的詞彙
或語言可以表達出更合宜或更恰當的感受，
二是說出特定的語言可以讓聽眾更有群主
感。這種情況常常可以在公共場合或電視台
聽到 [1]。 
轉換原因諸如遇到談話主題、對象或場
合的不同時，或是說話者雖有某事物的概
念、卻僅能以某種語言形式表達它時，語句
中便會換用該語言形式，例如：「Star Bucks
的咖啡很好喝」等華英2種語言的轉換用法。
人們在不同場合，經常自動進行語碼轉換，
例如在證交所或百貨公司等國際商業交易場
所中，與交易者對話時 常轉用華語或英語；
與朋友聊天時，為表親切可能會夾雜台語或
英語；而地方方言與國語則多被混合使用於
與家庭成員日常生活的談話中，如圖一就是
一個華台語混合的例子「今年的“風颱”特
別多」。 
 
圖一 華台語混合語句範例 
 
3. 問題描述與相關文獻探討 
混合語句在一句話中包含兩種語言，且每種
語言的時間相當的短暫，(根據所收集的語
料，其每段華語約只有1.1秒，台語的片段約
0.9 秒 ) ， 要 做 語 言 辨 認 (Language 
Identification，簡稱  LID)或是語音辨識
(Automatic Speech recognition，簡稱ASR)時，
這將是一大挑戰。原因為，在傳統的語言辨
認裡，主要是在一段單一語言的片段中，來
判斷這段語音的語言。而我們處理混合語
言，要做語言辨認，必須在包含兩種語言的
片段中，找出哪裡到哪裡是屬於華語，哪裡
到哪裡是屬於台語，且要在短時間內來做判
斷，實是需要做研究。 
目前在自動語言辨認的課題上，大部份
仍是以純單一語言構成之語音為主，混合語
言語音之研究則較為少見。香港的Joyce Y. C. 
CHAN等人曾在2004、2006發表關於廣東話與
英語混雜的混合語言語音研究[2, 5]，分別嘗
試使用Knowledge Base和Data Driven兩種不
同的語言混合音素集合辨識語音序列，並以
Bi-phone出現在廣東話中的機率做為語言判
別準則，其辨識結果約69.62%、76.54%。而
在國內，成功大學林俊憲等人對於華語與英
語混雜語音的相關研究[6]，使用BIC預先切割
  - 4 - 
Phone
Recognition
Language 1
Language Model
Language 2
Language Model
Language X
Language Model
…
…
Combine 
& Pick MaxInput 
Speech
Hypothesize
Language…
…
…
…
 
圖三 Phone Recognizer followed by Language 
Models (PRLM) 
 
    由於PRLM僅靠單一的音素辨識器做為
音素的辨識，很容易因音素判別錯誤而增加
語言辨認上的錯誤率。故有人提出了兩種不
同的方法來解決這個問題。第一種方法為平
行音素辨識器後接語言模型 (Parallel PRLM, 
PPRLM)[2,3]的架構(圖四)，也就是將數個
PRLM平行相接在一起。在這個架構下，輸入
語音會平行的經由數個音素辨認器做辨認得
到數個音素序列，並計算各個音素序列與各
個語言模型的相似度，對應相似度最高者為
最後語言辨認結果。 
 
Language 1 Language Model
Language 2 Language Model
Language X Language Model
…
Language A
Phone
Recognition
Combine 
& Pick Max
Input 
Speech
Hypothesize
LanguageLanguage 2 Language Model
Language X Language Model
Language 1 Language Model
…
Language 1Language Model
Language X Language Model
Language 2 Language Model
…
Language B
Phone
Recognition
Language C
Phone
Recognition
……
……
……
 
圖四 Parallel PRLM 
 
 
Language X 
Phone Recognition & 
Language Model
…
…
Combine 
& Pick Max
Input 
Speech
Hypothesize
Language
Language 2 
Phone Recognition & 
Language Model
Language 1 
Phone Recognition & 
Language Model
…
…
 
圖五 Parallel Phone Recognizer (PPR) 
 
    第三種方法為平行音素辨識 (Parallel 
Phone Recognizer, PPR)[3]的架構(圖五)。在這
個架構下，需同時訓練欲辨識語言的音素辨
認器以及語言模型，故若想辨識的語言為X
種，則需有這X種語言的音素辨識器和語言模
型。輸入語音將平行通過X種語言的音素辨認
器與其相應的語言模型，計算出語言相似
度，以相似度最高者為最後語言辨認結果。
依語言鑑別能力結果比較，PPR的能力最優，
PPRLM次之，最後才是PRLM。但在整體系
統的發展上，PPR也相對複雜許多。 
    另外一方面，N-連文（N-gram）的語言
模型也可以提供一種語言中其文字的序列規
則，並以統計和機率的方式來呈現。以下是
N-連文的表示式，W為n個w的集合，其中每
個w代表一個字詞。假設第n個字詞的出現只
與前面N-1個字詞相關，而與其他任何字詞都
不相關，整句的機率就是各個字詞出現機率
的乘積。這些機率可以通過直接從語料中統
計N個字詞同時出現的次數得到。當N愈大時
所需統計語料將愈多。  
 
1 2 3 1 2 1 1 2 1
1 2 1
1
( ) ( ) ( ) ( | ) ( | )
         ( | )
n n n
n
i i n i i
i
P W P w w w w P w P w w P w w w w
P w w w w
−
− − − −
=
= =
=∏
K L K
K
 
    對正確的語言現象，字與字之間的共同
出現機率較高，對一些較不符合語法者，字
與字之間的共同出現機率較低。可以反映出
一個語言的局部規律。例如：今天和今仔日
有相同的意義，但“今+日”這種組合在華語
中出現機率相對比在台語中出現機率高，而
“今+仔+日”這種組合在台語中出現機率相
對會比在華語中出現機率高。 
 
5. 混合語言語音錄製 
我們所錄製的混合語言語料庫，參與錄音的
人數總數為 29人，由麥克風及個人電腦的 32k
音效卡，在安靜無噪音的環境底下錄製，並
以WAV格式音檔儲存整個混合語言語料庫，
我們依據混合語言的不同分為三類：華語與
台語部份，由 10人錄製，合約 750句，平均
每句長度為 2 秒；華語與英語部份，亦由 10
人錄製，全約 1000句，平均每句長度為 2秒；
最後是其他語言（台語與英語、華語台語與
英語）的部份，由 9人錄製，合約 54句。表
一是關於此份語料的統計資。 
  - 6 - 
    圖六為混合語言語音的語言辨認架構
圖，整個流程順序為：當一個混合語言語音
輸入系統後，先將其進行特徵的擷取，經由
聲學模型和語言模型兩部份，將得到一個音
節序列；再將這個音節序列給予語言判別區
塊，最後便可得到這整段語的語言類別。 
 
6.1 聲學模型 
 
圖七聲學模型.系統架構圖 
 
我們提出了一套整合專家背景知識與實
際語音分析的方法，來產生一組新的聲學單
位，並且對這一組聲學單位的數目，使用差
分貝式資訊法則來做最佳的處理。從訓練好
的隱藏式馬可夫聲學模型中，計算其聲學單
位之間的相似度矩陣，之後透過語音學和音
韻學的知識，限定了各個聲學單位，其可以
群化的上限，根據不同限定的群化上限，使
用聚合階層式分群法，來建立不同的結構
樹。之後，利用差分貝式資訊法則，將每一
個結構樹中發音相近的聲學單位做合併，當
差分貝式資訊法則的值小於零的時候，就停
止合併，而新合併成一群的聲學單位則為新
的聲學單。 
多語聲學單位分類的方法，大致上可分
為兩種：(一)以專家知識的方法； (二)從資料
分析的角度(data-driven)，合併多語言之相似
音素。現分別介紹如下：  
6.1.1.利用專家知識的方法 
聲學單位利用專家知識的方法，可分為 1.語
言相關(Language Dependent)與 2.語言獨立
(Language Independent)的方式。其中，語
言相關的聲學單位是結合各自語言的音素而
成的，依據此方法，聲學模型的訓練上，各
個語言間具相同發聲的音素彼此之間並不共
用訓練語料。如華語和台語，這兩種語言都
有/a/的發音，透過專家的認定，將台語語音 
/a/ 和華語語音 /a/ 的發音，標記成[a_T]
與[a_M]，因此但每個音素符號會分別帶上各
個語言的標記。但此作法的缺點是具相同發
音的音素在不同的語言裡，彼此的語料並不
能共用，而可能會使得某些訓練語料相對的
不足，而造成聲學模型在做參數估計的時候
會不夠強健。 
相反的，語言獨立的方法，則是利用一
套能包含所有語言的音標符號，如IPA、SAMPA 
[10] 和 Worldbet [11]等，將不同語言但相
同發音的音素標記成相同的符號，因此，如
台語的 /a/ 和華語的 /a/ 的發音通通都標
記成 [a] 的發音符號。此種作法可以有效地
將相同發音部分的音素做合併，以減少語音
音素的數目，相對的，在同樣多的多語訓練
語料上，此種方法其每個聲學單位所能分配
到的訓練語料會比其語言相關的方法來的
多，因此，所訓練出來的聲學模型參數也會
更加強健。  
然而，使用語言獨立的方法的缺點為：
此方法沒有辦法反映出實際語料的發音特
性。原因是，其音素的定義是完全建立在專
家的知識上，而非從資料特性上做考量。理
論上，假設所有的語料都發音的和標記的完
全相同，這樣以專家知識上所定義的聲學單
位分類是完美的。但，在真實情況下卻不是
這樣的。往往，事先標記好的劇本，錄音員
並不能百分之一百的完全照著劇本的發音音
  - 8 - 
6.1.3.音素合併的條件 
貝式資訊法則(簡稱BIC)，由Schwarz在1978
所提出[15]，是一種非對稱模組選取的準
則。其利用最大概似度(Maximum Likelihood)
的方式從p個模型中找出最能代表n比資料
d
in RxxxX ∈= ,,...,1 的最佳模型。假設，每筆資
料都是相互獨立的。而第p個模型的BIC公式
如下 
 
   log
2
1),...,(log 1 nkxxBIC inii λ−= l 其中 pL
是模型 p 的最大概似度，λ是一個微調值，
而 pd 是 p模型裡的參數數目。 
Delta-BIC則是將兩群不同的貝式資訊
法則值做相減，簡化之後，可以轉化成兩個
不同群的最大概似度值做相加，之後減去兩
群組合併後的最大概似度值，再加上模型參
數目的函數值。這項技術常常被拿來當作語
者交換點或語言交換點偵測的一個判斷
[16]，通常一般法則是當delta-BIC大於0的
時候，就判定兩群組的邊界資料為一個交換
點。而本篇論文將此方法拿來作為多語聲學
模型單位最佳數目的根據。根據[16]，針對
第p個、第q個模型和兩個合併之後的r模型的
delta-BIC 公式如下所示： 
 
   log)
2
)1((
2
1||log
2
||log
2
||log
2 rr
r
q
q
p
p
n
dddn
nn
BIC
+++∑+∑−∑−
=∆
λ
 
其中 qp
nn ,
分別為模型p和q所對應的訓練語
料數目， qpr
nnn +=
，而 qp
∑∑ ,
分別為模型p
和q的共變異數矩陣的行列式， d為參數數
目。 
    因此，由上式我們可看出，如果模型p和
q以及合併之後的r模型，其最大概似度還大
於合併之前個別模型p和q的最大概似度總
和，則我們相信，這兩個模型是可以合併的。
所以，針對上述的聲學單位分類範圍，透過
delta-BIC的方法，最後可找出最佳的聲學單
位數目。而如果其中的λ值為零的話，(式四)
就退化成一般的最大概似度估計了。但一般
在做模組選取時是採用delta-BIC，因為直接
用大於或小於零就可判別，但如用一般最大
概似度估計，則要對每個不同的狀況設下不
同門檻值，才能作決定，因此本論文也採用
delta-BIC來做多語聲學模型最佳化的判準。 
    根據之前依不同限定所產生的結構樹，
我們從結構樹最下面，兩兩聲學模型或群組
間的delta-BIC 值大於零的部分做合併，而
合併後的聲學單位，利用[16]的技術，將原
本未合併之前模型p和q所對應的訓練語料分
享給新的合併之後的r模型，而達到聲學單位
整合的目的。這樣的合併會採由下而上的方
式一直進行，直到當delta-BIC 值小於零的
時候才會停止。停止後所合併的群組則為新
的一組聲學單位，用來訓練聲學模型，做語
音辨識。 
除此之外，在選好了最佳的聲學單位之
後，我們在訓練 HMM時，在每個狀態下的 GMM
數目，會依照有多少的訓練資料而決定。基
本上是個成正比的比例，也就是說，GMM的增
加，必須考慮到實際語音訓練量的狀況，而
不能一昧著增加 GMM 的數目。我們所用的公
式如下： 
    )(
i
OR
N
roundM pip =  
  - 10 -
有可能不存在於多字詞詞典中。以圖 3.6 為
例，最後的 dou hern tien（都很甜）這個音節
組合並不存在於詞典中。面對這種問題我們
將改以，直接使用單字詞詞典判斷單一音節
的語言種類，來解決，故最後將得到 hern（M）
|| tien（M）||的結果。第二，有些字詞是同時
存在於不同語言間共同使用，也就是原先分
類為*M/*T 的字詞，如圖十一中的 lai a
（*M/*T）||。 
最 近 的 梨仔 都 很 甜
zuei zin der (M)|| lai a (*M/*T)|| dou (M)|| hern (M)|| tien (M)||
最初斷詞結果 共同詞 音節組合不在詞典中
 
圖十一 字詞邊界與語言判別初步結果 
 
在共同詞的處理上，會分為多字詞與單字
詞的兩種處理方式。在多字詞的處理上，我
們使用中研究 CKIP 語料庫與實驗室語料庫
所統計得到的在不同語言所出現的字詞與其
出現次數表，利用詞在不同語言出現的相對
頻率多寡來決定所屬語言。例如，共同發音
字詞 ker ci，在台語中出現次數為 149次，而
華語僅 79次，分別除以所統計的華語、台語
總詞數，可以得到詞句在語言中出現的頻
率，取兩者相對頻率較高者，而在此我們發
現得到的在台語詞中出現機率較高，故將 ker 
ci標記為一個台語發音詞。 
 
表五 華語與台語出現的字詞與其出現次數
表 
 
 
表六 語言共同字詞處理 
 
uo zuei (M)|| si (*M/*T)|| ghuan ki (T)||
if (P(zuei_M si) > P(si ghuan_T)) => si(M)
uo zuei (M)||        si (M)|| ghuan ki (T)||
if (P(zuei_M si) < P(si ghuan_T)) => si(T)
uo zuei (M)||        si (T)|| ghuan ki (T)||
 
表七 字詞機率的共同詞處理 
 
6.3 詞與音節混合的 Bi-gram 
在我們的假設觀點中，混合語言語音中語言
轉換較可能發生於詞上，故若能得知詞與詞
間之相應機率，相信對混合語言語音之語言
辨認應會有所幫助。但由於各種語言中，詞
的數量皆相當多，若想以詞為單位訓練出其
Bi-gram機率，則所需的訓練語料資料量將會
相當龐大，因此我們折衷計算部份較常出現
的詞與音節間的 Bi-gram機率。由於我們既有
的已標音完成的語料庫資料不足，故我們需
要重新收集並製作新的語料庫。首先，收集
大量文章文字。我們嘗試由新聞稿、鄉土文
學、散文、生活小品等文章中，收集結成約
10 萬句總字數約 100 萬字的文章，但這些文
章皆無標音。接著，我們將這些文章中的文
字做標音。由於我們期望能得到類似語言夾
雜此類較貼近我們主題的文句，故我們先以
約 2 萬詞較常用台語多字詞為主與文章文字
做比對，將有出現在文章中的詞均先標記成
台語發音音標，其餘尚未標音的文字再以同
樣方式，以約 7 萬華語字詞標記成華語發音
音標。 
在整個標音過程中，真正有使用到的多字
詞個數約 22731；其中華語多字詞數為 15881
個，台語多字詞數為 6765個，而華語與台語
共同字詞數 85個。另外，在標音的同時，我
si bheh (T)|| sang (*M/*T)|| ho li (T)||
si bheh (T)||     sang (T)     || ho li (T)||
  - 12 -
• 插入錯誤（Insertion）：語言判別結果所
多餘的語言標籤部份。 
• 替換錯誤（Substitution）：正確答案的語
言標籤與語言判別結果的語言標籤不
相符。 
 
我 最 喜 歡 去 夜 市 仔 吃 東 西
正確語言
辨識結果
M MM M M M T T T M M
M M M M T T T T M T M
 
圖十三 語言標籤做為評估單位範例 
 
    得到這四種不同的數值後，以現在目前
常使用的衡量標準精確率、召回率與F測度來
評估我們的語言辨認率： 
• 精確率（Precision Ratio）：在語言判別
結果的語言標籤總數中，正確語言標
籤所佔比率。 為語言判別結果中正確
的語言標籤數(Hit總數)， 為語言判別
結果全部的語言標籤數 (Hit總數
+Substitution總數+Insertion總數)。 
H
L
Nprecision
N
=
 
• 召回率（Recall Ratio）：在正確答案中
有被判別出來且為正確的語言標籤佔
正確答案語言標籤總數比率。 為正確
答案中有被辨識出且為正碓的語言標
籤數(Hit總數)， 為正確答案中的語言
標籤總數 (Hit總數+Substitution總數
+Deletion總數)。 
e H
c
N
r c a l l
N
=
 
    通常，當有高召回率時，便很難能有高
精確率；反之，有高精確率時，將難有高召
回率。故我們另使用F-測度（F-Measure）做
評估。F-測度是依據上面的精確率和召回率
兩個衡量標準，取其調合平均數(Harmonic 
Mean)而成的另一個評估指標。 
 
1 1
1 1 1 1( )
2
2 2
p recis ion reca ll
F m ea sure precisio n reca ll
precision reca llF m ea sure
precisio n reca ll
= ⋅ +
−
⋅
⇒ − = = ⋅
+ +
 
     
    在F-測度中，需要同時滿足精確率和召
回率皆較高時才能得到高的數值，而這樣的
方法可以在精確率和召回率上取得一個平
衡。 
 
7.1.2 語言時間資訊評估法 
    第二種評估方式是使用語言時間資訊來
做為評估的單位，語言的時間資訊所指是每
個語言標籤在語音中的起始時間、結束時間
與持續時間長度(Duration)。這種評估方式，
是參考[17]在辨認語音中不同語者(Speaker)
的正確率計算方法，由於在語音中有一個以
上不同語者交替出現與語音中有不同語言交
替出現相類似，故我們使用[17]的評估方式來
評估我們的正確率。首先，將語言判別結果
的語言時間邊界與正確答案語言時間邊界做
對位（Alignment）的動作，以判別結果語言
區塊時間佔正確答案語言區塊時間比例為主
要對位上的準則。在完成對位後再比較兩者
的語言標千，同樣可以得到Hit、剛除錯誤、
插入錯誤、替換錯誤 4種數值，但在這邊數
值的計算方式是取用時間來表示。以下圖為
例 ： Hit 數 為 9 個 ， 總 時 間 長 度 為
(0.1-0)+(0.2-0.1)+……+(1.3-1.2)=1.07；刪除錯
誤數為1個，時間長度為0.45-0.3=0.15；插入
錯誤數為1個，時間長度為0.7-0.65=0.05；替
換錯誤數為1個，時間長度為1.2-1.1=0.1.。 
 
  - 14 -
 
語言 人數 語音句數 總時間
（小時） 
訓練語料 華語 100 43078 11.3 
台語 100 46086 11.2 
測試語料 混合 10 750 0.5 
表八 華台雙語訓練語音資料庫與華台混合
測試語音資料庫的相關統計數字 
 
在混合語言語音的語言辨認架構的實驗
部分部份，特徵參數我們採用了以梅爾倒頻
係數(簡稱 MFCC)為主的方法，而 20 毫取一
個音匡，每 10 毫秒移動一個音框，每個音匡
有 39維度。在聲學模型上，我們採用了兩種
不同聲學模型分別做討論。 
一 為 語 言 相 依 聲 學 模 型 (Language 
Dependent Acoustic Model, LDAM)，其則得到
的字串中每個音節本身即會帶有語言標籤。
在這種音節序列中發現的語言共有單字詞，
便直接以音節本身所帶的語言標籤做為語言
判別依據。 
二為語言獨立聲學模型  (Language 
Independent Acoustic Model, LIAM)，其所得
到的字串中音節將不帶有語言標籤。因本身
沒有語言標籤，故我們無法以直接的方式得
到語言種類。考慮到在我們假設轉換單位為
詞的前提下，應不會以一個音節做一次快速
轉換，若前後兩個相鄰詞為相同語言時，則
此音節應與前後兩相鄰詞為同一語言。 
以上為第一個方法，但這個想法並無法完
全解決所有語言共有單字詞的問題，若語言
共有單字詞出現在前後兩相鄰詞為不同語言
類別間時，便會無法處理。為此，我們提出
了第 2 種方法，利用與前後兩相鄰單字詞同
時出現的機率大小做為判別依據。與 N 連文
的概念相同，當機率值相對較高時，表示愈
有可能為同種語言。在加入這個方法後，將
可以成功處理所有語言共同單字詞。 
在兩種聲學模型中，每個聲學模型使用
HMM來做訓練，而模型的單位為左右相關音
素，而每個 HMM 有 3 個狀態，每個狀態下
的高斯分佈模型(簡稱 GMM)數目，則是依照
每個狀態下所能對應到的訓練語料量來決
定，根據[18]原則，所對應到的訓練語料量越
多的狀態，其 GMM 數目也會越多，在此系
列實驗中，我們設定每個 GMM必須要有 30
個以上的音匡。所以如果每個狀態下的 GMM
數目的增加是根據訓練語料的多寡來決定語
言相依聲學模型。另外語言模型為 Bi-gram。 
 
7.3 式實驗結果 
實驗的結果有兩樣，一是多語言語言辨認結
果，二是混合語言辨認結果。 
 
7.3.1 多語言語言辨認結果 
 
表九多語言語言辨認結果 (使用 LDAM 與 
LIAM) 
 
    比較兩種不同聲學模型下所有組合所得
到的語言辨識率，可以發現在組合相同時，
語言相依之聲學模型(LDAM)比語言獨立之
聲學模型(LIAM)約高了 2%的語言辨識正確
率。故在語言辨識上，由於語言的混淆性，
混合語言的聲學模型會比獨立語言的聲學模
型辨識效果上略差。因此在之後的混合語言
辨認實驗，我們將採用語言相依之聲學模型。 
 
7.3.2 混合語言辨認結果 
我們將結果呈現在表十(以語言標籤為評估單
  - 16 -
組，比較詞與音節的 Bi-gram語言模型對於語
言辨認上是否有益。 
 
 
表十二 以語言標籤為評估單位正確率 
 
 
圖十七 以語言標籤為評估單位 
 
 
表十三 以語言時間資訊為評估單位正確率 
 
圖十八 以語言時間資訊為評估單位 
 
由實驗統計可發現，無論以語言標籤為評估
單位或以語言時間資訊為評估單位，詞與音
節混合的 Bi-gram 方法所得到的結果皆比音
節 Bi-gram進步了約 3%左右。由此可知，以
word-base 的 Bi-gram 語言模型的確比音節 
Bi-gram的語言模型更具有語言鑑別能力。 
在整個語言辨認實驗中，我們目前能得到的
最佳正確率在於使用以語言標籤做為評估方
式且取合併後的語言區塊做為計算單位的情
況，可達 83.4%。但同樣情況時在以語言時間
資訊為評估方式時則會降至 78%，從我們先
前的討論中可得知，以語言時間資訊為評估
方式會比使用以語言標籤做為評估方式更加
能顯示整體的效能，故在這邊我們採用以語
言時間資訊評估方式為我們整體語言辨認實
驗最後的結果。 
 
七、結論與計畫成果自評 
在本計畫中，我們已經完成以下的工作
目標：收集了29人的華台語、華英語與華台英語
的混合語言語料庫。透過這個語料庫，我們也做
了混合語言的語言辨認研究。在這個研究中，我
們發展了一套混合語言語音的語言辨識平台，這
個平台包含了聲學訊號擷取、聲學模型與語言模
型的建立。由實驗上，透過兩種的評估方式，我
們瞭解到，直接使用39維MFCC在我們的系統能
有較好的語音識別表現。在聲學模型上，以語言
相依的聲學模型能得到較好的結果，而在語言模
型上，使用Bi-gram可表現出語言的規律性，有助
於語言的鑑別，且以詞與音節混合 Bi-gram又可
比使用音節Bi-gram 得到更高的語言鑑別度。 
 
八、參考文獻 
[1] C.-M. Chen, “Two types of code-switching in 
Taiwan,” paper presented in Sociolinguistics 
Symposium15, Newcastle, 2004 
[2] Joyce Y.C. Chan, P. C. Ching and Tan 
  - 18 -
Audio, Speech, And Language Processing, Vol. 
14, SEPTEMBER 2006 
[18] Dau-Cheng Lyu, Ren-Yuan Lyu, Yuang-chin 
Chiang and Chun-Nan Hsu,”Language 
Identification by Using Syllable-based 
Duration Classification on Code-switching 
Speech”, In Proceedings of Lecture Notes in 
Artificial Intelligence, Kent Ridge, Singnpore, 
Dec. 2006  
 
  20 
 
相關碩士論文 
[7] 廖子宇, “台語文字處理應用於混合語音之語言辨識” 碩士論文, 長庚大學
資訊工程學研究所 2010, 指導教授：呂仁園 
相關博士論文 
[8] Liang, Min Siong ,"Multilingual Speech Corpus Construction and Applications in 
Taiwanese Languages", Ph.D Thesis, Department of Electrical Engineering, Chang 
Gung University, Tao-Yuan, Taiwan, R.O.C., 2008, 指導教授：呂仁園 
[9] Dau-Cheng Lyu, "A Unified Framewrk for Speech Recognition on 
Code-Switching Speech", Ph.D Thesis, Department of Electrical Engineering, Chang 
Gung University, Tao-Yuan, Taiwan, R.O.C., 2009, 指導教授：呂仁園 
 
 
96 年度專題研究計畫研究成果彙整表 
計畫主持人：呂仁園 計畫編號：96-2221-E-182-032-MY3 
計畫名稱：多語夾雜之語音的語言偵測、語言指認及語音識別 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 1 1 100%  
研究報告/技術報告 0 0 100%  
研討會論文 1 1 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 6 6 100%  
博士生 3 3 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 1 1 100%  
研究報告/技術報告 0 0 100%  
研討會論文 3 3 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
 
