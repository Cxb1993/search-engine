摘要： 
要改善模型建構式基因遺傳演算法執行效率，首先我們必須了解其解題能力的極限。目前
模型建構式遺傳演算法都是由觀察兩組基因開始學習其中的關聯性。這麼做的主要原因是
考慮執行效率的問題。一般而言，若一次觀察 k 組基因來建構模型的話，要花 O(lk)的時間，
其中 l 是問題的大小。尤此可見，從 k=2 開始是個很合理的近似。然而，這樣的近似可能
造成解題能力的下降。我們於是詴著探討是否存在如下的問題：某 k 組基因間有強烈的關
聯性，但是任兩組基因之間卻觀察不出任何關聯。如果此問題存在，則模型建構式遺傳演
算法可能因為無法學習到正確的關聯資訊而無法解決該問題。研究的結果，簡單而言，使
用華許函數 (Walsh function) 可以設計出使模型建構失敗的問題。然而基因遺傳演算法仍
可找出最佳解，但需要花更長的時間。 
 
關鍵詞： 
基因遺傳演算法、模型建構、模型建構式基因遺傳演算法、問題困難度、關聯學習。 
 
Abstract: 
To improve the efficiency of model-building genetic algorithms, or estimation of distribution 
algorithms (EDAs), first we need to fully understand their ability to solve problems. So far, all 
EDAs learn linkage information by starting with observing two genes only. The primary reason 
for doing so is the efficiency concern. In general, it takes O(l
k
) time to observe k genes at a time, 
where l is the problem size. Therefore, starting with k=2 is a reasonable approximation. However, 
such approximation may incur EDAs' ability to solve problems. In this research, we investigate 
the existence of the problem where there exists strong dependencies among k genes while no 
dependencies between any two genes. If such a problem exists, EDAs might fail to converge to 
correct alleles because of incorrect linkage information. Briefly speaking, in this research we use 
Walsh functions to design problems that EDAs fail to learn linkage from. However, EDAs are 
still able to find the optimal solution with incorrect linkage information, despite of consuming 
longer time.  
 
Keywords: 
Genetic Algorithms, Model Building, Estimation of Distribution Algorithms, Problem Difficulty, 
Linkage Learning. 
 
 
 
 
 
 
 
 
 
 
I 
 
2 
performances of different EDAs on that problem. We derive a convergence model to verify the 
scalability of EDA on the parity function. Then we discuss about another allelic-pairwise 
independent function and experiment on it. Finally, we have some analyses and conclusions on 
the empirical results. 
 
2  PREVIOUS WORK ON PARITY 
 One of the simplest ways to design an allelic-pairwise independent function to assign the 
same fitness to the individuals with the same parity. Coffin and Smith (2007) described the 
concatenated parity function (CPF) and the concatenated parity/trap function (CP/TF) in their 
work. CPF is defined as a concatenation of parity functions: 




1
0
)1( )()(
m
i
kikik xxparityXCPF  , 
where the parity function is defined as  
otherwise
even is in unitary 
)(
X
C
C
Xparity
odd
even



 . 
 Coffin and Smith investigated the performance of hBOA (Pelikan & Goldberg, 2001), the 
hierarchical version of BOA, on these problems. Surprisingly, hBOA scaled exponentially on 
both problems. It is believed that hBOA is robust and reliable on nearly decomposable problems, 
so they stated that CPF is hard for EDAs to solve and discussed about the reasons and possible 
solutions. Furthermore, Echegoyen et al. (2008) investigated the exact model building on 
Bayesian network based EDAs, and verified that the linkages in CPF can be learned by building 
an exact model. Emmendorfer and Pozo’s work (2008) also employed CPF to test their design of 
EDA. 
 
3  PERFORMANCE OF CGA ON CPF 
 To understand the reason that hBOA scales exponentially on CPF, we first start testing CPF 
with the compact genetic algorithm (CGA), a simple univariate EDA which has shown to be 
approximately equivalent to a simple GA (Harik, Lobo, & Goldberg, 1998). Since hBOA failed 
to solve CPF within polynomial number of function evaluations, we expect that CGA would fail 
as well. 
 Surprisingly, empirical results show that CGA scales polynomially on CPF (Figure 1). CGA 
solves CPF reliably with about O(m
1.32
) number of function evaluations and apparently contradict 
with the previous assumption that CPF should be difficult for CGA. 
  To verify the empirical finding, we start to derive an analytical model which theoretically 
supports the experiments. At the end, we successfully derived the time-to-convergence model for 
CGA on CPF as follows: 











1
2
1
)2(2
)1(
2kconv k
mN
t


, 
where N is the population size and ε is the initial random bias. According to the gambler's ruin 
4 
 To design such a problem, we utilize Walsh functions (Forrest & Mitchell, 1993; Goldberg, 
1989), whose codes for lengths of 2 and 3 are shown in Figure 2. Take length of 3 as an example. 
If we remove the first bit in the Walsh codes, then no dependency can be detected between any 
two bits since all four possible combinations, 00, 01, 10, and 11 take place with the same 
frequency. However, strong high-order dependencies exist among several bits. Empirical results 
indicate that EDAs fail to learn the correct linkage model for this so-call concatenated 
Walsh-code function (CWCF). Nevertheless, EDAs are still able to solve CWCF with incorrect 
linkage information though with more function evaluations. Empirically, CGA was able to solve 
CWCF within O(m
1.67
) function evaluations, where m is the number of Walsh codes in the 
problem (Figure 3). 
 
 
Figure 3: Performance of CGA on CWCF. 
 
5  CONCLUSIONS 
 In this research, we investigated the difficulty of linkage learning in EDAs, which mostly 
starts from learning pairwise dependency. So we investigated the performance of EDAs on 
problems with allelic-pairwise independent functions, which has been believed to be hard for 
EDAs. The empirical results showed that CPF can be solved in polynomial time by CGA, but 
hBOA scaled exponentially on it (Coffin & Smith, 2007). We believe that hBOA did not perform 
well due to spurious linkage (Lima, Pelikan, Goldberg, Lobo, Sastry, & Hauschild, 2007), which 
caused the overfitting issue (Wu & Shapiro, 2006). To verify the exact reason of the different 
performance between hBOA and CGA, we also investigated the performance of ECGA with 
spurious linkage, which also scaled exponentially on CPF like hBOA did. 
 Moreover, we proposed the concatenated Walsh-code function (CWCF), which deceives the 
linkage-learning mechanisms in EDAs. EDAs are still able to solve CWCF with incorrect linkage 
information, but consume more function evaluations than CPF. 
 Although EDAs are unable to build correct linkage models for these allelic-pairwise 
independent functions, they still can solve these problems according to our experiments and 
derivational models of convergence time, which is a polynomial (O(mlogm)) to the problem size. 
But for multivariate EDAs, they may perform worse than univariate EDAs if too many spurious 
6 
evolutionary computation. Kluwer Academic Publishers. 
Lima, C., Pelikan, M., Goldberg, D., Lobo, F., Sastry, K., & Hauschild, M. (2007, Sept.). 
Influence of selection and replacement strategies on linkage learning in boa. In 
Evolutionary Computation, 2007. CEC 2007. IEEE Congress on (pp. 1083–1090). 
Mühlenbein, H., & Paass, G. (1996). From recombination of genes to the estimation of 
distributions i. binary parameters. In PPSN IV: Proceedings of the 4th International 
Conference on Parallel Problem Solving from Nature (pp. 178–187). London, UK: 
Springer-Verlag. 
Pelikan, M., & Goldberg, D. E. (2001). Escaping hierarchical traps with competent genetic 
algorithms. In Proceedings of the Genetic and Evolutionary Computation Conference 
(GECCO2001) (pp. 511–518). Morgan Kaufmann.  
Pelikan, M., Goldberg, D. E., & Cantú-Paz, E. (1999). Boa: The Bayesian optimization algorithm. 
In Proceedings of the Genetic and Evolutionary Computation Conference (GECCO-99) (pp. 
525–532). 
Pelikan, M., Goldberg, D. E., & Lobo, F. G. (2002). A survey of optimization by building and 
using probabilistic models. Comput. Optim. Appl., 21(1), 5–20. 
Pelikan, M., & Mühlenbein, H. (1999). The bivariate marginal distribution algorithm. In Roy, R., 
Furuhashi, T., & Chawdhry, P. (Eds.), Advances in Soft Computing - Engineering Design 
and Manufacturing (pp. 521–535). London. 
Tsuji, M., Munetomo, M., & Akama, K. (2004). Modeling dependencies of loci with string 
classification according to fitness differences. In Genetic and Evolutionary Computation 
(GECCO 2004) (pp. 246–257). 
Wu, H., & Shapiro, J. L. (2006). Does overfitting affect performance in estimation of distribution 
algorithms. In GECCO ’06: Proceedings of the 8th annual conference on Genetic and 
evolutionary computation (pp. 433–434). New York, NY, USA: ACM. 
Yu, T.-L., Goldberg, D. E., Yassine, A., & Chen, Y.-P. (2003). A genetic algorithm design 
inspired by organization theory: a pilot study of a dependency structure matrix driven 
genetic algorithm (Technical Report). Urbana, IL: IlliGAL, University of Illinois at 
Urbana-Champaign. 
 
 
  
出席國際學術會議心得報告 
                                                             
計畫編號 NSC 97-2218-E-002 -020 -MY3 
計畫名稱 改善模型建構式基因遺傳演算法所需之記憶空間及執行效能 
出國人員姓名 
服務機關及職稱 
于天立 
國立台灣大學電機工程學系 
會議時間地點 7/8~7/12, Montreal, Quebec, Canada 
會議名稱 Genetic and Evolutionary Computation Conference (GECCO) 
發表論文題目 
Difficulty of Linkage Learning in Estimation of Distribution Algorithms (Oral) 
Co-Evolvability of Games in Coevolutionary Genetic Algorithms (Poster) 
 
1、 參加會議經過 
 
GECCO is the biggest and the most significant conference in evolutionary computation. It contains 
2 keynotes, 42 tutorials, 16 tracks, and 13 workshops this year. We attended most programs related to 
this project, namely the estimation of distribution algorithm (EDA) track and the genetic algorithm (GA) 
track. We presented our poster on 7/9 in the poster session and our oral paper on 7/11 in the best paper 
nomination session. 
 
2、 與會心得 
 
Below are some presentations in EDA & GA tracks that we attended and directly related to our 
project. Some of the ideas and techniques are inspiring and might be suitable to adopt in our project. 
 
1. The Estimation of Distribution Algorithm Track 
1.1 EDA-RL: Estimation of Distribution Algorithms for Reinforcement Learning 
Problems 
This paper is nominated for the best paper award of EDA track. Handa (Okayama University, 
Japan) proposed an EDA for reinforcement learning problems, which can be found in frameworks of an 
intelligent agent design. In this algorithm, conditional random fields (CRF) are adopted to estimate the 
conditional probabilistic models. In the experimental section of the work, four different CRFs, which are 
linear-chain, independent-feature, anterior state-action and 3-clique, are tested on different problems. 
Linear-chain models worked well on probabilistic transition problems, and only the 3-clique model was 
able to solve perceptual aliasing problems. This EDA-RL method is also comparable with Q-learning 
method. 
1.2 Difficulty of Linkage Learning in Estimation of Distribution Algorithms 
In our work, we investigated the difficulty of linkage learning, which is an essential core in EDAs. 
To find the possible limitation of EDAs (also called PMBGA), we tested compact GA (CGA) and extended 
ensemble crossover (REX). The author demonstrated AER on several test functions including function 
with multimodal structure. Compared to an existing GA, AER outperforms the existing one and prevents 
premature convergence. 
2.4 Co-Evolvability of Games in Coevolutionary Genetic Algorithms 
Our work investigates the co-evolvability of games. Games with mixed strategy Nash equilibrium 
are less co-evolvable since the expected payoff is the same. Pure strategy games are co-evolvable and 
niching technique is helpful. Finally, a relatively hard game, which requires exponentially large 
population, is designed to illustrate the existence of hard games. 
 
3 Conclusion 
Some research results present the improvement of genetic and evolutionary computation’s 
performance, and some other work involves novel designs of EDAs. After further investigations and 
experiments, these works may be useful for improving the performance of model-building GAs to fulfill 
the goal of this project. 
 
Difficulty of Linkage Learning in
Estimation of Distribution Algorithms
Si-Cheng Chen, Tian-Li Yu
National Taiwan University
r96921065@ntu.edu.tw, tianliyu@cc.ee.ntu.edu.tw
Abstract
This paper investigates the difficulty of linkage learning, an essential core, in EDAs. Specif-
ically, it examines allelic-pairwise independent functions including the parity, parity-with-trap,
and Walsh-code functions. While the parity function was believed to be difficult for EDAs in
previous work, our experiments indicate that it can be solved by CGA within a polynomial
number of function evaluations to the problem size. Consequently, the apparently difficult
parity-with-trap function can be easily solved by ECGA, even though the linkage model is
incorrect. A convergence model for CGA on the parity function is also derived to verify and
support the empirical findings. Finally, this paper proposes a so-called Walsh-code function,
which is more difficult than the parity function. Although the proposed function does deceive
the linkage-learning mechanism in most EDAs, EDAs are still able to solve it to some extent.
1 Introduction
Estimation of Distribution Algorithms (EDAs) (Larran˜aga & Lozano, 2002; Mu¨hlenbein & Paass, 1996),
or probabilistic model-building genetic algorithms (PMBGAs) (Pelikan, Goldberg, & Lobo, 2002),
became an important branch of genetic evolutionary computations (GEC), because of their ro-
bustness and scalability. EDAs can be categorized into various classes based on their linkage-
learning mechanisms. The most basic ones are univariate EDAs, e.g., PBIL (Baluja, 1994) and
Compact GA (Harik, Lobo, & Goldberg, 1998), which do not have any linkage-learning mecha-
nism and assume all the variables in the problem are independent. Bivariate EDAs, like MIMIC
(Bonet, Isbell, & Viola, 1997) and BMDA (Pelikan & Mu¨hlenbein, 1999), can detect pairwise de-
pendencies between the variables, but do not search for the optimal distribution model among
multiple variables. Finally, multivariate EDAs, such as ECGA (Harik, 1999),
BOA (Pelikan, Goldberg, & Cantu´-Paz, 1999), D5 (Tsuji, Munetomo, & Akama, 2004),
EBNA (Etxeberria & Larran˜aga, 1999) and DSMGA (Yu, Goldberg, Yassine, & Chen, 2003), build
interacting models to reveal dependencies among multiple variables, are more powerful for solving
nearly decomposable problems.
Linkage learning is an inevitable issue in bivariate and multivariate EDAs, which must exploit
the linkage information to estimate joint probabilities and construct the models. The computa-
tional cost for determining the exact dependency model scales exponentially with problem size,
and hence a proper mechanism is required for building an approximate model. Most of the mul-
tivariate EDAs construct the interacting models by starting with pairwise linkages between only
two variables, since it is impractical to explore the whole possible search space of multi-variable
linkage. It takes O(lk) to compute all dependencies among k variables in a problem of size l, so
it makes more sense to start with only pairwise linkages with cost limited to O(l2). For example,
ECGA builds the marginal product models by merging building blocks according to the minimum
description length metric, and it need to detect the pairwise dependency at the very beginning of
model building. BOA also exploits pairwise dependency to decide the addition or deletion of an
edge between two variables.
However, a quick approach is generally deficient in precision, which may consequently delay
the convergence time of linkage. As the linkage should be learned before the alleles converge in
EDAs (Goldberg, 2002), reaching for balance between efficiency and precision is a critical issue in
1
101 102
101
102
Number of Building Blocks, m (log scale)
M
in
im
al
 P
op
ul
at
io
n 
Si
ze
, N
 (lo
g s
ca
le)
101 102
102
103
104
Number of Building Blocks, m (log scale)
N
um
be
r o
f E
va
lu
at
io
ns
 (lo
g s
ca
le)
 
 
O(m log m)
Empirical Result
Figure 1: Minimal population found by bisection method and the polynomial scalability of CGA
on CPF (log-log scale) with a convergence time bound of Θ(m logm), the slope of the trend line
indicates the order of the scalability.
method since the Hamming distance between a string and a chosen global optimum is always not
larger than m, so it needs only m or less mutations to find a global optimum.
To verify whether a simpler GA or EDA might work on this problem, we investigate the
scalability of compact GA (CGA), a univariate EDA without any linkage learning , on CPF.
The approximate equivalence between CGA and a simple GA (SGA) with uniform crossover has
been verified in (Harik, Lobo, & Goldberg, 1998), so the performance of CGA on CPF should be
replicable with SGA. Similar to the setup in (Coffin & Smith, 2007), we choose the block size k=5
, Codd = 5 and Ceven = 0 for CPF. A bisection method is also exploited to determine the minimal
population size required for different m value, and take the average number of evaluations from
100 runs for each problem size and population size. As the result shown in Fig.1, CGA solves
CPF reliably with obviously bounded polynomial times, which is about Θ(m1.32) and differs from
previously assumption that CPF should be hard for EDAs.
4 The Scalability Model of CGA
Since the CGA works successfully on CPF, we attempt to derive a model to simulate the perfor-
mance of CGA on CPF. First, we extend the definition of CPF to simplify the calculation. Let
Codd =
{
0
k
Ceven =
{
k if k is even
0 otherwise,
(5)
i.e., the individual Xk where u(Xk) = k is always an optimum, k is the size of each subproblem.
Then the analysis on CPF starts from the problem with only single building block (BB), and the
result will be extend to multiple BBs later.
4.1 CPF with Single Building Block
In CGA, probability vector (PV) is adopted to generate two individualsXa, Xb for every generation.
When the PV is expected to be converged to an individual Xk, there must be an initial bias ε0,
3
−0.2 −0.15 −0.1 −0.05 0 0.05 0.1 0.15 0.2
−0.02
0
0.02
0.04
0.06
0.08
Bias Value, ε
∆ k
 
V
al
ue
 
fo
r k
=3
−0.2 −0.15 −0.1 −0.05 0 0.05 0.1 0.15 0.2
−0.04
−0.03
−0.02
−0.01
0
0.01
0.02
0.03
0.04
Bias Value, ε
∆ k
 
V
al
ue
 
fo
r k
=4
Figure 2: Verifications of ∆k models, the ε values near zero has better accuracy because the model
is a 1st-order estimation
4.2 Scalability with Multiple BBs
By the central limit theorem, the distribution of the fitness of a BB is approximately normally
distributed. Using the decision-making argument (Goldberg, Deb, & Clark, 1992), the probability
of making the right decision between two competing individuals in a single trial of a problem with
m independent equally-weighted BBs is:
p = Φ(
d√
2m′σbb
), (14)
where m′ = m − 1, d is the difference of fitness between two competing BBs, σ2bb is the variance
of BBs, and Φ denotes the cumulative distribution function of a unit normal distribution. We can
incorporate this probability to estimate the scalability of CGA with multiple BBs. Since we might
make wrong decision and lead the PV to the opposite side, the modified ∆k value should be
∆′k = p∆k − (1− p)∆k. (15)
With Eq.(11) and (14), the modified ∆′k become
∆′k ≃
2√
pim′
1
N
2k−2εk−1t . (16)
With the same integration procedure previously, the final convergence model become
t ≃ N
√
pim′
2(k − 2)(
1
2εk−20
− 1), (17)
which is an approximated bound of the scalability of CGA.
Since the population sizeN should be Θ(
√
m logm) (Harik, Cantu´-Paz, Goldberg, & Miller, 1999),
this model indicates the convergence time of CGA on CPF would be bounded by Θ(m logm), which
is polynomial to the problem size.
5
102
102
Problem Size, l (log scale)
M
in
im
al
 P
op
ul
at
io
n 
S
iz
e,
 N
 (l
og
 sc
ale
)
102
103
104
Problem Size, l (log scale)
N
um
be
r o
f E
va
lu
at
io
ns
 (l
og
 sc
ale
)
 
 
Trend Line
Empirical Result
slope=2.32
Figure 4: Minimal population found by bisection method and the polynomial scalability of ECGA
on CPF (log-log scale)
6 Discussions
How does ECGA solve CP/TF in polynomial time while hBOA does not? To answer the question,
we first investigate their linkage models, table 1 shows the model built by ECGA only includes
building blocks of trap functions, so ECGA is not able to learn the linkages in parity subproblems.
But ECGA still can solve them with similar mechanism as CGA does, and learn the linkages in
the trap subproblems at the same time. Since ECGA could solve these subproblems separately,
no matter which subproblem converges slower, it always requires only polynomial time. How-
ever, it is evident that EDAs are unable to identify building blocks of parity functions correctly,
so the linkages learned by hBOA are considered spurious possibly due to the selection bias, and
it has been confirmed that using tournament selection in BOA results in less accurate models
than truncation selection (Lima, Pelikan, Goldberg, Lobo, Sastry, & Hauschild, 2007). Further-
more, the overfitting phenomenon observed in EDAs was correlated with the performance of EDAs
(Wu & Shapiro, 2006), and might also caused the exponential scalability of hBOA on CPF.
To verify this assumption, we create a model with compulsorily added spurious linkages instead
of original linkage-learning mechanisms in each generation of ECGA. Starting with l independent
clusters each containing only one gene, we merge two randomly chosen clusters each step and
repeat l/2 times for each model, , and the size of each cluster is limited to k ≤ 3. Then we test this
modified ECGA on CPF again, as the result shown in Fig. 5, ECGA scales exponentially on CPF
with spurious linkages, which may explain the unfavorable performance of hBOA on problems with
parity functions.
7
Table 2: Walsh codes
j l = 2 l = 3
0 1111 11111111
1 1010 10101010
2 1100 11001100
3 1001 10011001
4 11110000
5 10100101
6 11000011
7 10010110
generalized Walsh-code functions is defined as:
w(X) =


C1 if X ∈ Wj
C2 if X ∈ W ′j
C3 otherwise,
(20)
where W ′j are one’s complements of Wj , which are designed to be the most competing building
blocks in this problem.
Since EDAs with linkage learning should be unable to learn the linkages between variables in
the Walsh-code function, the remaining question is whether it can be solved by univariate EDAs
or not. Thus we experiment with CGA on the concatenated Walsh-code function (CWCF) , where
k = 5, C1 = 5, C2 = 4 and C3 = 0. As the empirical result shown in Fig. 6, although the order of
evaluations on CWCF is slightly greater than CPF, which indicates that CWCF is more difficult
than CPF, it is still solved reliably by CGA. But with a larger subproblem size k, CWCF becomes
more difficult since the number of optima is always 2l when k < 2l while CPF has 2k−1 optima,
which are proportional to 2k.
8 Conclusions
In this paper, we discussed the difficulty of linkage learning in EDAs, which mostly starts from
learning pairwise dependency. So we investigated the performance of EDAs on problems with
allelic-pairwise independent functions, which has been believed to be hard for EDAs.
The empirical results showed that parity function can be solved in polynomial time by CGA
and ECGA, but hBOA scaled exponential on it (Coffin & Smith, 2007). In our discussion, it was
believed that hBOA did not perform well due to the spurious linkages
it had learned (Lima, Pelikan, Goldberg, Lobo, Sastry, & Hauschild, 2007), which caused the over-
fitting issue (Wu & Shapiro, 2006). To verify the exact reason of the different performance between
hBOA and ECGA, we also investigated the performance of ECGA with spurious linkage, which
also scaled exponentially on CPF like hBOA did.
Moreover, we proposed the Walsh-code function, which was another function which could de-
ceive the linkage-learning mechanisms in EDAs successfully. With such a function, the concate-
nated Walsh-code function is a more difficult problem for EDAs than CPF, even though not
significantly.
Although EDAs are unable to build exact models for these allelic-pairwise independent func-
tions, they still can solve these problems without learning any correct linkages according to our
experiments and derivational models of convergence time, which is a polynomial time model of
Θ(m logm). But for multivariate EDAs, they may perform worse than univariate EDAs if too
many spurious linkages are learned or added, so linkage learning becomes unwanted when it is
handling allelic-pairwise independent functions.
However, while multivariate EDAs are robust and effective methods to solve most of nearly
decomposable problems reliably, it is desirable to discover another problem which can not solved
reliably by multivariate EDAs. This problem should be hard for EDAs just because multivariate
EDAs can not construct the exact linkage model of this problem correctly before all the alleles
converge, and subsequently end up with the local optima. If such a problem actually exists,
9
