2變得不清晰，甚至於會出現合唱(chorus)、
迴音(reverberation)等副作用。
若採取純粹的單元選取之 corpus-
based 的合成方法，則必須錄製非常大量的
語音，且合成單元的切割與標示，也需花
費人力來作程式處理後的校對、更正。所
以，實作上大多是採取混合式的作法，亦
即仍然會對一些合成單元作韻律特性的調
整處理，而一般選取的處理方法多是
PSOLA，此時就會面臨清晰度和流暢度的
抉擇的兩難問題，例如想要保持清晰度，
就不對音長差異(原始值、目標值之間)較大
者作處理，結果可能造成合成語音的說話
速度忽快忽慢地改變，而降低了流暢性。
三、清晰度改進之研究
在此我們以 HNM (harmonic plus noise
model)為基礎，對它作改進，以便用來合
成出清晰的國語語音信號。HNM 是由 Y.
Stylianou 所提出的一種語音信號的模型，
希望在作語音處理(編碼，合成)時，仍能保
持信號的清晰度與自然度。HNM 可看成是
弦波模型的改進，它對於語音高頻部分的
雜音 (noise)信號成分，建立了較好的模
型。HNM 的模型參數分析程序裡，提供了
最大有聲頻率 MVF (maximum voiced
frequency) 的一個偵測方法，依 MVF 值可
將一個語音音框(frame)的頻譜分割成低
頻、高頻之兩個部分，對於低頻部分的信
號成分，採取以諧波成分(harmonic partials)
的加總來塑模(modeling)，而對於高頻部分
的信號成分，則採取以平滑的頻譜包絡
(spectral envelope)來塑模，實際上是以少數
的倒頻譜(cepstrum)係數來代表此頻譜包
絡。
3.1 音色一致性及音長調整
當應用 HNM 來合成國語語音時，我
們發現有幾個議題，其解決方法並未能在
HNM 的文獻上找到，第一個議題是，如何
讓合成的音節信號保持音色(timbre)的一
致性(consistency)? 由於我們只希望對各
種國語音節錄製一次發音，然後透過修改
一個音節的基週軌跡的高度及形狀，來合
成出其它聲調的音節信號，因此當一個欲
合成音節的基週軌跡被指定時，我們必需
使用一種適當的方法來調整 HNM 各諧波
成分的參數值，以同時滿足基週軌跡及音
色一致性的要求。
第二個議題是，對於一個放置於欲合
成音節之時間軸上的一個控制點(control
point)，如何決定此控制點上的 HNM 參數
的數值? 在合成一個音節的信號時，我們
需要調整該音節原始錄音的音長以滿足韻
律單元所指派的合成音節之音長，因此在
合成音節時間軸上的一個控制點，當它被
對映(mapping)至一個位於原始音節兩分析
音框之間的時間點時，我們必需使用一種
適當的內差方法來計算此控制點上的
HNM 參數值。
我們研究了前述二項議題的解決方
法，當要合成一個音節的信號時，程序上
先作控制點的佈放、對映(mapping)，對映
是指對映至原始音節之音框；再去內差出
音高(pitch)未變之控制點上的 HNM 參數；
然後，進行可保持音色之另一種內差處
理，以求取音調改變後之 HNM參數數值。
前述步驟的作法細節，可參考我們已發表
之研討會論文: 古鴻炎、周彥佐，「基於
HNM 之國語音節信號的合成方法」，第十
九 屆 自 然 語 言 與 語 音 處 理 研 討 會
(ROCLING 2007)，台北，第 233-243 頁，
2007。
3.2 信號合成之主流程
此外，我們也依據前述的解決方法建
造出了一個由 HNM 作改進的國語音節信
號合成系統，此系統的主要處理流程如圖
1 所示。當要合成一個音節的信號時，很
明顯地此音節的各個韻律參數值已經由韻
律單元訂定、指派好了，因此圖 1 裡的第
一個方塊首先作的是，將合成音節的音長
規劃、分割成此音節的組成音素(phoneme)
的時長(duration)，接著依據相連音素的時
長來建造一個片斷線性(piece-wise linear)
的時間校正函數，以便將合成音時間軸上
的時間點對映至原始音的時間軸上；在圖
1 裡的第二個方塊，先均勻地在合成音的
4譜特性(例如頻譜包絡, spectrum envelope,
的形狀 )，並且以特定的狀態駐留 (state
staying)機率分佈來掌握在各個狀態上所應
停留的時間長度。這樣的作法，以我們的
觀點來看，就是在於作更細緻的規劃，把
一個音節的時長以某一種非均勻的方法作
切割，而讓不同的狀態(也就是頻譜包絡)
分配到不等的時間長度，以便更細緻地模
仿真人發音(articulation)時的頻譜隨著時間
變化的關係。
4.1 頻譜演進
前述頻譜(包絡形狀)隨著時間演變的
關係，在本文裡簡稱之為頻譜演進
(spectrum progression)，而頻譜演進路徑(簡
稱為頻演路徑)指的是，當把欲合成的音節
放在橫軸上，而把相同拼音的原始錄音音
節放在縱軸上，此時橫軸上各時間點所應
對應的縱軸時間點，需要一條曲線來描述
此對映(mapping)關係，一個例子如圖 4 所
示，這樣的對映曲線就是本文所謂的頻演
路徑。過去很多的國語語音合成系統，其
合成出的語音的流暢性不佳的一個主要原
因，我們認為是因為它們直接把頻演路徑
設定為直線，而沒有特別考慮頻演路徑的
塑模(modeling)，再據以產生出逼近真人講
話方式的頻演路徑。
圖 4 頻譜對映曲線之例子
因此，我們便開始研究頻演路徑塑模
及產生的問題，在此我們不追隨前人採取
HMM 來建立頻演路徑的模型，原因是
HMM 未 去 掌 握 時 間 上 相 鄰 的 觀 測
(observation)向量之間的依存(dependency)
性，這相當於假設時刻 t 的觀測向量 Ot 和
Ot+1 (或 Ot-1)之間沒有依存關係，而只有
去掌握 Ot 和它所停留的狀態之間的關連
性，這樣的 modeling 方式令我們懷疑其是
否可以滿足語音合成上的需求；此外，一
個合成音節的頻演路徑並不會是只有固定
的一條而已，而是會隨著左右鄰接音節的
不同，去行走不同的路徑(也就是 context
dependent)，在此情形下，一個 HMM 的各
個狀態如果只是各自去考慮 state duration
的機率分佈，而沒有考慮鄰接狀態和鄰接
音節之間的相關性，則不免讓我們懷疑其
完善性。
4.2 頻演模型
基於前述的考量，我們逐決定以 ANN
(artificial neural network)來建立頻演路徑
的模型，而模型的訓練步驟是: (a)錄製單獨
發音的參考音節和句子發音的語句，然後
把語句裡的音節切割成各別的目標音節檔
案；(b)逐一將整句發音裡的音節信號放在
橫軸，而把相同拼音的單獨發音音節信號
放在縱軸，再以DTW(dynamic time warping)
來匹配出一條頻演路徑；(c)將橫、縱軸上
的音節信號的時間範圍各自正規化成 0 至
1 之間，然後在橫軸音節上均勻放 32 個正
規化的時間點，各點再依頻演路徑對映至
縱軸而得到介於 0~1 之間且隨著橫軸作非
線性漸增的 32 的數值；(d)將各個句子發音
裡的音節對映出的 32 個正規化的時間值
(稱為頻演參數)作為 ANN 模型學習的目
標，並且把該音節及其前、後鄰接音節的
資訊(也就是語境資料)作為 ANN 的輸入資
料，去訓練頻演參數的 ANN 模型。
目前我們只錄了 375 個訓練語句，共
2,926 個音節，來訓練頻演模型。頻演模型
建立後，就可用它來產生出一個欲合成音
節的 32 個頻演參數，再依這些頻演參數去
作片段線性內差而得到如圖 4 所示的對映
函數。然後，這個對映函數就可帶入第三
節的 HNM 合成法裡，去對映合成音節的
一個控制點至原始音節上的分析音框，來
取得控制點上所需的 HNM 參數。
欲合成音節/yao/
原
始
音
節
/yao/
