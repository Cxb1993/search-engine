 1
摘要 
關鍵字：病房活動監測、無線射頻識別(RFID)、語音辨識、電腦視覺、影像處理。 
醫療機構的服務目的在於提供最佳的健康照護，如何利用資訊工程技術，結
合醫院的功能與設施，以病患為中心，以其在院流程為藍圖，照顧病患之安全，
乃是現代智慧型醫院追求高品質醫療照護之主要目標。利用資訊工程來提昇醫療
服務品質之技術，基本上可區分為兩類，第一類為運用醫學工程與資訊工程之技
術，來發展具診斷或治療疾病功能的醫療儀器，以提昇醫療技術品質。第二類則
為利用電腦、網路與無線傳輸技術在醫療服務支援作業方面，提昇醫院作業效率
與醫療服務品質。本計畫利用非接觸式感應技術，以病人為中心，做智慧型醫院
病房內各種活動之自動化防護與監測，目的是為提昇醫療服務品質。 
本計畫已完成下列研究項目： 
一、點滴含量偵測與提醒服務 
二、病床周圍事件偵測 
三、視訊自動控制 
 3
此項屬病患例行性檢查自動化技術開發，本計畫將進行下列工作： 
z 開發點滴含量偵測系統。 
(二) 病床周圍事件偵測 
此項屬環境事件監測自動化之技術開發，本計畫將進行下列工作： 
z 開發可判斷病患上下床狀態之技術。 
z 開發可自動判斷病患是否跌下床之防護機制。 
z 利用影像資訊判斷病患狀況。 
(三) 視訊自動控制 
此項屬病人活動與防護自動化之技術開發，本計畫將進行下列工作： 
z 開發追蹤眼球位移之技術，並將此技術應用於視訊系統中。 
z 開發追蹤與監控病患狀態的人物動作捕捉技術。 
z 硬體設備與視訊系統連結之建立。 
2. 點滴含量偵測與提醒服務                                       
吊點滴是在醫療行為中常用來補充病患水份或熱量的一種方式，或者用於病
患因嘔吐、昏迷無法進食、腹瀉吸收不良、無法服藥時，就用注射藥物的方式輔
助病患吸收達到改善病情的效果。但是吊點滴的過程約需歷經一到二個小時，所
以醫護人員可能在注射後就忙著去做其他事務，此時可能會忽略即將快滴完的點
滴，而此時如果病患睡著了並且也沒有陪伴的人注意到，將會發生點滴瓶空了卻
沒有人處理的問題。所以本項研究課題提出運用影像處理技術擷取點滴圖像來偵
測點滴剩下的量，並在點滴量少於設定的下限時，主動提醒醫謢人員更換點滴。
如此一來不但能減少醫護人員作業上的程序(不需時時注意更換點滴的時間)，更
能避免忘記更換點滴的問題，家屬也能更放心的將病患交給院方。 
本項研究課題擬設計一個利用視訊監控來檢查點滴容量的方法。利用視訊攝
影器材取得影像後將其進行灰階亮度轉換，並進行影像分割等處理，在取出所要
的特徵後，進行該特徵的分析處理。通常病房內的點滴都被放置在固定位置的點
滴架上，而其特徵也單純不易有太大變化，如圖 2 所示，利用影像處理技術進行
分割取得所要的點滴特徵值後，進行目前點滴使用時間估計，並在到達點滴更換
時間時，主動提醒醫護人員進行更換。 
 5
 
圖 5. 綠燈表示正常 
 
圖 6. 紅燈異常狀況 
 
圖 7. 紅燈異常狀況 
 
 7
在此系統中，我們加入了 ROI（Region of Interest）偵測，而 ROI 偵測的目
的是為了要使上下床判斷能夠順利達成。在此，上下床判斷必需搭配 ROI 區域
正確選取才能夠實行。 
圖 9 為 ROI 框選的示意圖，選取正確的 ROI 區域，選取到的區域將可做上
下床的判斷，但不會做跌倒判斷。 
 
圖 9. ROI 框選示意圖 
於 ROI 選取時，當我們按下滑鼠時會先記錄起點的 X 位置和Y 位置，此起
始位置稱之為 xStart 和 yStart ，接著當我們放開滑鼠時會記錄 X 位置和Y 位置，
此終止位置稱之為 xEnd 和 yEnd 。框內為 ROI 區域，專門負責病人上下床的部
份；ROI 區域外則專門處理判斷是否有病人發生跌倒。如圖 10 所示：  
 9
( )max max
min max
RH RW
sum
y RH x RW
Binary B f
= =
= ∑ ∑                                           （2） 
max minbRH RH RH= −                                                 （3） 
max minbRW RW RW= −                                                 （4） 
0
1
sum b b
det er mine
sum b b
, Binary RH RW
Bed
, Binary RH RW
≤ ×⎧= ⎨ > ×⎩
                   （5） 
 
利用公式（1）二值公式將 ROI 影像做二值化，接著，利用公式（2）統計
出所有 ROI 區域白色像素點的總數，再利用公式（3）和公式（4）找出 bRH 和
bRW ，最後如果 sum b bBinary RH RW≤ × 則 0det remineBed = ，那麼結果判定為下床；
若 sum b bBinary RH RW> × 則 1det er mineBed = ，那麼結果判定為在床上。利用如此的
方式便可以輕易判斷上下床動作。 
如圖 11 所示，紅色框標示 “In bed” 即表示 sum b bBinary RH RW> × 則
1det er mineBed = ，所以判斷結果為床上有人，結果即為病人在床上；如圖 12 所示，
紅色框標示“Falling down”即表示 sum b bBinary RH RW≤ × 則 0det er mineBed = ，所以判
斷結果為床上沒有人，結果即為病人不在床上。 
avgR  = R 通道的平均值 
avgG   = G 通道的平均值 
avgB  = B 通道的平均值 
n   = 累積像素的個數 
minOH  = 物件高度的最小值 
maxOH  = 物件高度的最大值 
minOW  = 物件寬度的最小值 
maxOW  = 物件寬度的最大值 
( )B f  = 為轉換函數 
Max  = 最大值 
W   = 權值 
RHb = 影像高度 
RWb = 影像寬度 
 11
在做物件追蹤之前，我們必須先用編號演算法將影像中的各個物件做區分，
再依照編號演算法區分的各個區塊對應到原圖算出 RGB 三通道的平均像素，以
及此物件最重要的像素特徵，獲得之後即給予一個權值，下一張影像進來時便開
始比對，比對成功便可建立關聯；若無，則給予一個新的編號。影像追蹤流程如
圖 13 所示： 
 
圖 13. 影像追蹤流程示意圖 
追蹤演算過程如下： 
1. 利用編號演算法將各區塊做區分，再將各區塊對應到原影像，計算 R 通道
的平均值、G 通道的平均值和 B 通道的平均值，如公式（6）（7）（8）所示。 
2. 將 R 通道的平均值、G 通道的平均值和 B 通道的平均值做比較，從三個通
道中找出最大值，並判斷此最大值是哪一個通道，若為 R 通道，則為 1；若
為 G 通道，則為 2；若為 B 通道，則為 3。如公式（9）（10）所示。 
 
目前影像 
物件追蹤 
判斷比對資
料是否相同 
利用新
資訊進
行追蹤
1R 通道平均像素 
1G 通道平均像素 
1B 通道平均像素 
特徵權重值 
資料比對 
nR 通道平均像素 
nG 通道平均像素 
nB 通道平均像素 
特徵權重值 
2R 通道平均像素
2G 通道平均像素
2B 通道平均像素
特徵權重值 
有 
存入一比
新資料 
無 
物件資料 
 13
 
如圖 14 所示，兩個人在畫面中，黑色衣服編號為 1，粉紅色衣服編號為 2，
圖 14（a）為交錯前的畫面，交錯之後的結果如圖 14（b），兩圖的編號沒有因為
交錯而錯亂，依舊是黑衣服為 1，粉紅衣服為 2。 
 
（a）                                        （b） 
圖 14. 移動物體交會圖，（a）交錯前，（b）交錯後 
多人追蹤主要功用在於當系統判斷病人為下床時，那麼系統將自動開始追
蹤，掌握病人動態，當病人在下床活動發生跌倒之時，能夠第一時間的發揮功效，
降低跌倒所造成的傷害。 
4. 視訊自動控制                                                 
本項研究課題主要是利用影像辨識技術，辨識眼球的動作，而達到能操控病
房周邊設備的目的。當眼睛受到外來光線照射時，因為結構的不同，會造成不同
的反射差異，尤以瞳孔部份對光線的反應更為明顯。對於影像辨識而言，辨識瞳
孔外圍會較辨識其他位置容易，且該部位不易被眼瞼遮蔽，準確度亦較高。 
avgR  = R 通道的平均值 
avgG   = G 通道的平均值 
avgB  = B 通道的平均值 
n  = 累積像素的個數 
minOH  = 物件高度的最小值 
maxOH  = 物件高度的最大值 
minOW  = 物件寬度的最小值 
maxOW  = 物件寬度的最大值 
( )B f  = 為轉換函數 
Max  = 最大值 
W  = 權值 
 15
 
否 
否 是 
是 
計算影像座標 
位移量 
滑鼠按鈕
是否按下 
滑鼠點擊 滑鼠未點擊 
輸入瞳孔影像並計 
算其螢幕注視點 
注視點是
否有變化 
 
圖 16. 視訊自動控制流程圖 
如圖 17 所示，此為眼睛看中間的情況；如圖 18 所示，此為眼睛看右邊的情
況，當眼睛停留在右邊的位置達到五秒，則定義為肚子餓的情形；如圖 19 所示，
此為眼睛看左邊的情況，當眼睛停留在左邊的位置達到五秒，則定義為尿急，想
小便的情形；如圖 20 所示，此為眼睛看下面的情況，當眼睛停留在下面的位置
達到五秒，則定義為心情不好的情形；如圖 21 所示，此為眼睛看上面的情況，
當眼睛停留在上面的位置達到五秒，則定義為身體不舒服的情形。 
 17
 
圖 19. 眼睛看左邊 
 
圖 20. 眼睛看下面 
 19
參考文獻                                                         
[1] M. Lampe and M. Strassner, The potential of RFID for moveable asset 
management, in: Workshop on Ubiquitous Commerce, Ubicomp'03, Seattle, 
USA (October 2003).  
[2] Harald Vogt, Efficient Object Identification with Passive RFID Tags, 
Proceedings of the First International Conference on Pervasive Computing, 
p.98-113, August 26-28, 2002. 
[1] G. Matheron, “Random sets and integral geometry,” Wiley & Sons, New York, 
1975. 
[2] J. Serra, “Image analysis and mathematical morphology,” London:Academic, 
1982. 
[3] P. Soille, “Morphological image analysis-principles and application,” Springer, 
2003. 
[4] A. C. Sanderson, and L. E. Weiss, “Image-base visual servo control using 
relational graph error signals,” in Proceedings of IEEE International Conference 
on Cybernetics and Soceity, pp. 1074-1077, 1980. 
[5] C. Anderson, Peter Burt and G. van der Wal, “Change detection and tracking 
using pyramid transformation techniques,” in Proceedings of SPIE - Intelligent 
Robots and Computer Vision, Vol. 579, pp. 72-78, 1985. 
[6] L. Wang, W. Hu and T. Tan, “A survey of visual analysis of human motion,” 
Chinese Journal of Computers, vol. 25, no. 3, pp.225-237, 2002. 
[7] J. Aggarwal and Q. Cai, “Human motion analysis: a review,” Computer Vision 
and Image Understanding, vol. 73, no. 3, pp. 428-440, Mar. 1999. 
[8] M. Oren, C. Papageorgiou, P. Sinha, E. Osuna, and T. Poggio, “Pedestrian 
detection using wavelet templates,” in Proceedings of IEEE Conference 
Computer Vision and Pattern Recognition, June 1997, pp. 193-199. 
[9] I. Haritaoglu, D. Harwood and L. S. Davis, “W4: real-time surveillance of people 
and their activities,” IEEE Transactions on Pattern Analysis and Machine 
Intelligence, Vol. 22, No. 8, pp. 809-830, Aug 2000. 
[10] A. Mohan, C. Papageorgiou, and T. Poggio, Member, “Example-based object 
detection in images by components,” IEEE Transactions on Pattern Analysis and 
Machine Intelligence, vol. 23, no. 4, pp. 349-361, Apr. 2001. 
[11] M. H. Tsai, and S. J. Wang, “A new region tracking model for visual surveillance 
systems,” IPPR Conference on Computer Vision, Graphics and Image Processing 
(CVGIP), July 2006. 
[12] W. H. Wu, and R. C. Lo, “A stucy on the lending support of blocks detecting 
