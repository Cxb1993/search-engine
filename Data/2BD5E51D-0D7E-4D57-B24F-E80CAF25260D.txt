可供推廣之研發成果資料表 
■ 可申請專利  ■ 可技術移轉                                      日期：95 年 9 月 12 日 
國科會補助計畫 
計畫名稱：有效的三階段演算法應用於人臉偵測 
計畫主持人：王敬文        
計畫編號：NSC 94-2213-E-151 -012  學門領域：資訊二 
技術/創作名稱 強韌型人臉偵測系統 
發明人/創作人 王敬文 
中文：我們提出一個新穎的演算法以萃取人臉器官，其中包括眼
睛偵測、嘴巴寬度測量、及姿態估算。在這個演算法中，我們設
計小波框架特徵模板並使用支援向量機及小波散度濾波器來搜索
切割人臉 T 字部位。此 T 字部位通常包括眼睛及嘴巴區塊可用來
選取相對應的視角辨識器進行人臉辨識。實驗結果顯示在複雜的
背景下我們的方法具有相當優異的成果。 
技術說明 
英文：In this project, we present an efficient algorithm for facial 
component extractions, which are eyes detection and the mouth width 
measuring, and pose estimation. The algorithm is based on the novel 
overcomplete wavelet feature template, the support vector machine 
(SVM) classifier, and the wavelet entropy filtering to robustly detect 
and segment the T-shape face region. The segmented T-shape face 
region, which is the smallest area enclosed by the face ellipse including 
eyes and mouth, is used to select the corresponding view-based 
classifier for face recognition. The experimental results show that the 
proposed method is robust against the complex scenes. 
可利用之產業 
及 
可開發之產品 
適用產業：資訊、電子、醫工、機電、國防、保全業 
適用產品別：門禁安全、差勤管制、人臉追蹤、視訊會議、機器
人、殘障輔助系統、資料壓縮、資料檢索、軍事用途...。 
技術特點 
人臉偵測: 不受人數、背景、及光源之影響，可適用各種環境。
搭配適當鏡頭時，偵測距離可達 10 米。 
即時的性能: 使用 3.0 GHz CPU 執行單一人臉偵測辨識，平均耗
時 0.5 秒，偵測辨識結果立即上傳預設站台，同時經由 USB I/O
界面輸出 ON/OFF 控制信號。 
推廣及運用的價
值 
因應個人通訊 3G、4G 時代的來臨，與人有關的多媒體視訊處理皆
可適用，在生活面及安全性上非常實用。 
附件二 
all ROIs have been covered. The ROI is scanned at 10 
scales each a factor of 1.25 larger than the last.  
 
Step 4: To locate the potential candidate, the rectangle 
feature of W × H pixels in the feature template can be 
computed as follows  
 
|),(|][
0,0
∑
<≤<≤
=
HyWx
yxdi DWFLH ,                     (1) 
 
where d DWFLH  is the nonsubsampled version of discrete 
wavelet transform (DWF, discrete wavelet frames) in 
the LH horizontal subband and } ..., ,1{ Ii∈ , I = 9 is the 
number of  rectangles in the proposed feature template. 
At each location within ROI, check the decision rule of 
equation (2) that indicates whether the face template is 
satisfied or not. 
 
 1  2  3 
 4  5  6 
 7  8  9 
 
( [1] > [4] )  && ( [3] > [6] ) &&  ( [1] > [2]  ||  [3] > 
[2] )  && ( [5] > [4] ) && ( [5] > [6] ) && ( [8] > [7] ) 
&& ( [8] > [9] )                                                             (2) 
 
Step 5: Merge templates that can be counted as 
enclosing the same face since it is common to have 
multiple findings with small displacements horizontally 
and/or vertically.  
 
Step 6: Normalize all the candidate regions – resizing to 
24 × 24 pixels and using histogram equalization. 
 
Step 7: Classify the face candidate using the SVM 
classifier. If the class corresponds to a face, we draw a 
rectangle around the face in the output image. 
 
Step 8: Normalize the detected face rectangle to size 
40×60 pixels .  An entropy-based smoothing filter is 
introduced to move the center from pixel to pixel in the 
rectangle to remove the coefficients located at outside 
the facial component regions. This continues until all 
pixel locations have been covered and facial component 
object are to be created for extraction. The entropy 
filtering of the pixels in the 3 × 3 (N  =  3)  
neighborhood defined by the mask is given by the 
expression 
 
) ,(log) ,(1_
1
0,
2
yxdyxd
N
entropyWavelet DWFLH
N
yx
DWF
LH∑−
=
−= .  (3)  
 
According to anthropometry, we could perform the 
inter-orientation projection along the horizontal and 
vertical axes respectively to locate human eyes and 
mouth. Search for the centroid in the facial component 
region, we approach region segmentation by finding 
meaningful boundary based on point aggregation 
procedure. Choosing the center pixel of the component 
region is a natural starting point and grouping points to 
form the region of interest with paying attention to 4-
connectivity would yield a clustering result, when no 
more pixels for inclusion in the region. After growing, 
the region centroid is relocated and therefore eyes, 
mouth, and face size are also known. An adaptation is 
finally carried out to mark the eyes and mouth positions 
and refine the bounding rectangle as an ellipse of fitting 
facial oval shape (Fig. 1(b)). 
 
    Note that one needs to do further works as the next 
step for the view-space separation of human face while 
the final objective of facial component extraction is for 
face recognition. 
 
Step 9: The view-space separation procedure presented 
in Fig. 2 is defined in the image plane. The points 
),( LL yx  and ),( RR yx  as displayed in the following 
illustration are the coordinates of the left and right eyes, 
respectively, and the point ),( MM yx  is the center of the 
mouth. We define the pan θ  of equation (4) as the angle 
between the lines passing through the right eye and the 
center of the mouth and passing through the left eye and 
the center of the mouth. The face image with rotation in 
plane θ can be rotated back to the upright position 
(orientation alignment) and then the left-view can be 
separated from the right-view based on the skin color 
ratio between the left cheek and the right cheek of the 
segmented face. The color ratio range is determined as 
(0.8, 1.2) for the frontal view face recognition, which is 
corresponding to pan rotation in (-20°, 20°). The left 
view with rotation angle (-60°, -20°) is defined as the 
color ratio less than 0.8, and the color ratio with value 
larger than 1.2 is responsible for the right view with 
rotation angles (20°, 60°).  
 
 
πθ /180
2/)(
2/)(
tan 1 ×⎟⎟⎠
⎞
⎜⎜⎝
⎛
+−
+−= −
LRM
LRM
yyx
xxx .           (4) 
 
),( yx MM
),( yx RR
),( yx LL
θ
