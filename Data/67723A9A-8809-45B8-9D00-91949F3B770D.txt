synthesizer to generate the virtual scenes. After the 
inte-gration of real view decoder and virtual view 
synthesizer, applications including conventional 
2DTV, 3DTV, multi-user 3DTV, and virtual reality can 
all be achieved. In this project, the SoC integration 
of the worldwide first free-viewpoint 3DTV set-top 
box SoC is introduced. First, a hard-ware-oriented 6D 
FVVS flow is introduced along with the corresponding 
architecture to solve the high processing capability 
of both the real-view decoder and virtual-view syn-
thesizer. The 1911MPixels/s throughput in maximum is 
achieved, and is 9x to 40.5x higher than the previous 
works. Second, the cache-based texture reorder 
architecture with the dynamic warping reference frame 
selection (DWRFS) scheme reduces the ex-ternal memory 
bandwidth by 95.7% in view synthesis. Finally, the 
precision-optimized Homographic Transform (HT) and 
the single iteration inpainting save 68% area of 
warping engine and 93.3% of computing cycles 
respectively. 
英文關鍵詞： System-on-a-Chip (SoC), Video, Compression, Free-
viewpoint, 3D, 3DTV, FTV, virtual reality, Codec, 
Parallel archi-tecture, Low Power, MVC, Multiview 
Video Coding, H.264, MPEG, AVC 
 
智慧型視訊訊號處理-子計畫二: 
多重視角視訊處理及架構設計之研究 
Design and Implementation of Multiview Video Processing System  
計劃編號：97-2221-E-002-191-MY3 
執行期限：2010/08/01 ~ 2011/07/31 
子計劃主持人：陳良基 教授  Email: lgchen@cc.ee.ntu.edu.tw 
執行機構：國立臺灣大學電子工程學研究所 
計畫參與人員：叢培貴、林品志、陳冠宇、莊子德 
 
 
 
一、 中文摘要 
 
本計畫為多視角視訊處理與架構設計
之研究，在前兩年的計劃中，我們對於多
視角的視訊壓縮系統做出了演算法與硬體
架構上的研發與改進，而在本計畫的最後
一年，在整合了之前的研究成果，與本年
度的階段目標之後，我們研發出了能夠支
援各式不同的多視角 3D 視訊應用的高效
能低頻寬自由視角 3D 電視機上盒系統晶
片  (Free-viewpoint 3DTV Set-top Box 
SoC)。經由目前最高的視訊解析度 Quad 
Full-HD (4096x2160 pixels)，目前最多的視
角個數所需要的每秒鐘 216 張 Quad 
Full-HD 的自由視角畫面輸出規格，以及
目前最高規格，能夠即時解碼 Quad 
Full-HD@30fps 的 MVC 解碼器，不光是
目前的 2D 與 3D 電視，未來電視產業的多
人裸視 3D 電視以及虛擬實境的應用都可
以在我們的系統晶片中實現。在晶片實做
上，我們發現若是不作任何的最佳化，每
生成一個虛擬視角需要 31.5GB/Sec 的系
統記憶體頻寬與 66.2TOPS 的運算量。因
此，在本次計畫中我們從演算法層級，系
統層級，硬體層級提出了各式各樣的最佳
化技巧。更發現並解決了在世界上其他的
研究單位都尚未解決的視角間的色彩補償
(Inter-view Color Calibration)。在系統的層
級，在整合了 6D 自由視角生成流程，
Dynamic Warping Reference Frame Selec-
tion，On-chip Buffer Optimization 還有
Texture Reorder Cache 之後，我們節省了
95.7%的系統記憶體頻寬。另外，經過了
數學運算以及浮點精確度的最佳化後，在
Warping Engine 的部分我們能夠節省 68%
的硬體面積需求，在 Inpainting Engine 的
部分，我們首先提出了以深度的資訊提升
畫質的 Depth-based Inpainting，在硬體的
資 料 流 程 中 則 實 現 了 單 一 循 環 的
Depth-based Inpainting 把節省 93.3%所需
的 Cycle 數同時維持更好的畫面品質。 
關鍵詞：系統晶片，視訊，自由視角，3D，
虛擬實境，壓縮，編解碼器，移動估計，
位移估計，平行架構，低功率，MVC，多
視角影像編碼，H.264，MPEG，AVC，
FTV，Free-viewpoint。 
英文摘要 
 
    3DTV is the promising mainstream of 
the next-generation TV systems. High reso-
lution 3DTV provides users vivid watching 
experience. Moreover, free-viewpoint view 
synthesis (FVVS) extends the common 
two-view stereo 3D vision into the virtual 
reality by generating unlimited views on any 
desired viewpoint. In the next-generation 
3DTV systems, the set-top box (STB) SoC 
requires both a high-definition (HD) mul-
tiview video coding (MVC) decoder to re-
construct the real camera-captured scenes 
and a free-viewpoint view synthesizer to 
generate the virtual scenes. After the inte-
gration of real view decoder and virtual 
view synthesizer, applications including 
 3 
點，其中最為嚴重的就是在自由視角的運
算中的不規則性。由圖一所示，一般在數
位晶片設計領域最常見的資料讀取與暫存
方式分為兩種，一種是 Line-buffer，另外
一種是 Block-pipeline，Line-buffer 主要用
在視訊畫面的前/後處理，而視訊壓縮則通
常是採用 Block-pipeline 的流程。但不管是
哪一種架構都沒有辦法支援我們這次計畫
所需要的 6D 的自由視角生成。這個原因
很單純，當我們必須要考慮任意的旋轉以
及平移的時候，輸入的資料與輸出的資料
的幾何形狀必然會不同，因此，不論是Line
或是 Block，在經過了可能的旋轉位移之
後，需要輸出的幾何形狀就必然不是原本
的 Line 或是 Block 了。但這在需要資料規
律進出的晶片設計領域裡面是不能夠做到
的。另外，在所有硬體設計中都會遇到的
硬體資源不足的問題，包含了 system 
memory bandwidth，on-chip SRAM，area
等等的問題，在我們這麼巨大的目標規格
底下自然也是更為嚴重了。圖二為在本次
計畫中所要面臨的問題，最大的問題還是
在前面提到的，沒有辦法用一般的 Block 
Pipeline 或是 Line Buffer 的方法解決在自
由視角環境中會遇到的各種可能的幾何形
狀的問題。就如同在圖十二的地方所解釋
的，直接應用傳統的資料排程會造成非常
大的系統記憶體頻寬的浪費。在這邊我們
利用了 MPEG-FTV Group 所發表的虛擬
視角生成模擬軟體(View Synthesis Refer-
ence Software，VSRS) [8]，在經過修改加
上了系統記憶體頻寬的模擬之後，我們發
現，假如在我們目標的 Quad Full-HD 的情
況下，用直接實做的方法將會讓每生成一
個虛擬視角需要 31.5GB/Sec 的系統記憶
體頻寬。考慮到目前的 HDMI 傳輸線所能
夠提供的頻寬也才大約 1GB/Sec，這顯然
是遠遠的超過一個系統晶片所能夠負荷的
範圍。第二點則是超高的運算量需求，由
於 Warping 需要大量矩陣運算，而
Inpainting 則是有非常多需要重覆執行的
指令，用直接實做的方法將會讓每生成一
個虛擬視角，需要 66.2TOPS 的運算量，
這也遠遠超過目前最高效能的 CPU 所能
夠負擔的運算量。最後，由於需要跟 MVC
的解碼器整合，要怎麼樣提供一個具有彈
性 ， 並 且 能 夠 負 擔 我 們 的 目 標
(QFHD@216fps)這麼大量的系統輸出的
系統控制，也是非常重要的課題。 
Design Challenges of Virtual View 
Synthesis (6D Geometry)
1. Source Data LoadingBlock Based Scheduling Example:
Virtual View (Shift and 
Rotate along X-axis)Reference View (Left)
Single 8*8 
Block
Spread to Multiple 
Blocks
Real Camera Virtual Camera
Warp
Need to iteratively update 
multiple blocks
 
圖一：圖解為何當考慮到6D的幾何形狀的
時候，一般的block pipeline沒有辦法支援
的原因。 
      64 Bits Decoder Bus
DRAM 2D/3D Display Processor
6D Free-Viewpoint View Synthesis CTRL
Texture Reorder Inverse Reorder
Warping 
Engine
MVC Decoder CTRL
Texture 
SRAM
Texture Texture 
SRAM
Texture Texture 
SRAM
Gradient SRAM
Depth 
SRAM
Epipolar Rec. Pixel 
Buf.
Epipolar Ref. Pixel 
Buf.
Stripe SRAM
Gradient SRAMCur. Block Buf.
Dynamic Warping Ref. 
Selection CTRL
Cur. Block Buf.
Entropy 
Decoder
Texture 
Decoder
Deblocking
Filter
Dual 64 Bits Bus Interface
Texture 
AM
In
te
r-V
ie
w
 C
o
lo
r 
C
a
lib
ra
tio
n
 C
T
R
L
Stage1-1: 
Entropy & Texture
Stage 1-3: 
Deblocking
Stage 1-2: 
Prediction
Stage 2-2: Waping
Stage 2-1: Texture Reorder Stage 2-4: Inverse Reorder
Stage 2-3: Inpainting
3DTV Set-top Box SoC
Prediction 
Engine
Cache SRAM
MC CacheResidual SRAM
Reconstruct SRAM
Inpainting 
Engine
      64 Bits Synthesis Bus
Line-based/Block-
based Scheduling 
Cannot Support 6D 
Geometry
Irregular Memory Request & 
Bandwidth Consumpti n: 
31.5GB/s/View
Large 
Computational Cost: 
66.2TOPS/View
Integration/Calibration 
with MVC Decoder
Large Throughput: 
QFHD@216fps
= 1.9G Pixel/s
 
圖二：在本次計畫中，所需要解決的問題
以及系統模擬數據。 
 
三、 研究方法及成果 
 
    在這部分，我們將介紹在本計畫中
所開發的研究方法，將會分成演算法與
 5 
須利用一些畫面處理的演算法來填補起
來。在 MPEG-FTV Group 中建議使用的演
算法為 Inpainting。這是利用周遭畫素的分
布來填補畫面的一種演算法，然而，由於
Inpainting 的演算法並不是針對 3D 電視所
發展的，因此在原始的 Inpainting 演算法
中，會利用 Occlusion 周圍所有的畫素來
均勻的填補 Occlusion，由圖六的結果看
來，這樣顯然不足以提供我們所需要的高
畫質的銳利度。為了在我們目前的虛擬視
角生成環境中最佳化 Inpainting 的效能，
我們提出了參考深度資訊的 Inpainting 演
算法(Depth-based Inpainting)。演算法流程
如圖七所示。首先，利用深度的資訊，將
虛擬視角的 Occlusion 周圍的畫素分成前
景與背景兩個部分，之後，我們將只針對
背景的部分執行 Inpainting 的動作，而前
景的部分則保持原來的邊界，這樣一來， 
Inpainting 的結果就能夠在保持住前景的
銳利度的情況下，又能夠把背景缺失的部
分給補齊了。 
    圖八為我們所提出的 Depth-based 
Inpainting 與一般傳統的 Inpainting (例如
VSRS所使用的OpenCV Inpainting)的比較
圖。在一般的作法中，整張畫面中的
Occlusion 部分都是非常模糊的，也因此畫
面銳利度就下降了非常多。反觀我們在成
功利用了深度資訊將前景與背景分別處理
之後，可以將每個物體的邊界都保持的非
常好。在圖八中我們可以發現即使是幾乎
一樣深度的牆壁與欄杆，我們都可以將這
兩個物體分別處理到他們理論上應該會有
的形狀與紋理。 
 
圖六：利用原始的 Inpainting 演算法的結
果，前景背景都會均勻的被填補在
occlusion 之內。 
 
圖七：我們所提出的 Depth-based 
Inpainting 的流程圖。 
Proposed Inpainting OpenCV Inpainting
 
圖八：我們提出的 Depth-based Inpainting
與傳統的 Inpainting (OpenCV Inpainting)
的比較。 
Reference View
θ = 0⁰ θ = 11.25⁰ θ = -11.25⁰ θ = -22.5⁰ θ = 45⁰θ = 22.5⁰
8
 P
ix
e
ls
1 Pixel
θ = -45⁰
7 Kinds of Access Patterns for Texture Reorder/Inverse Reorder
Pixel 
Reordering
Engine
Example Virtual View Epipolar Geometry: 
Rotation along Y- and Z-axis
 
圖九：我們提出的以七種不同的資料存取
形式與紋理重組流程解決在自由視角時所
需的不同幾何形狀的記憶體存取。 
 7 
在超大畫面解析度的情況下，我們仍然需
要更多的系統記憶體頻寬的節省技巧，才
能夠在有限的晶片頻寬下支援到四倍
Full-HD 的畫面解析度。圖十一的上半部
分是從不同的參考畫面中生成的目標虛擬
視角畫面，這兩張畫面除了 Occlusion 在
不同的位置之外，其他的部分幾乎是一模
一樣的，除了 Occlusion 的部份之外，其
他兩個參考畫面都運算到的部分就是一種
浪費，而重複的計算也相對應的浪費了系
統記憶體頻寬來重複讀取以及輸出資料。
為了解決此一問題，我們提出了動態的參
考視角選擇如圖十一所示。我們會先決定
一個視角為主要的參考視角(Main Refer-
ence View, Main Ref.)，並且”只”以此參考
視角作為參考視角畫面，直到所生成的虛
擬視角畫面中出現了 Occlusion 之後，我
們會用 Warping Engine 去運算出目前的
Occlusion 在另外一個參考視角上面的位
置，利用這樣的方法，在自由視角生成流
程中不論有幾個參考視角，每生成一個虛
擬視角畫面的畫素所需要的參考畫素都可
以維持在大約一個的程度，跟傳統的
Blending 比較起來，我們能夠省掉至少
50%的系統記憶體頻寬。 
Virtual View Image
 
圖十二：在外部記憶體使用比例造成的頻
寬問題。紅色的部分代表僅包含部分所需
的參考畫素的 DRAM 欄位。 
Original Block Order Stripe Block Order  
圖十三：Stripe-based Block Scan Order 示
意圖。 
Block*2
B
lo
c
k
*3
Ready to Output
Block*2
B
lo
c
k
*3
Ready to Output
Block*2
B
lo
c
k
*3
Ready to Output
Block*2
B
lo
c
k
*3
Ready to Output
Inverse Reorder 
Buffer
Inverse Reorder 
Buffer
Inverse Reorder 
Buffer
Inverse Reorder 
Buffer  
圖十四：在 Inverse Reorder Stage 中所使用
的資料暫存器以及相對應的資料排程。紅
色的虛線內部是準備要輸出到晶片外部的
資料，而橘色的部分則是剛被重組完，最
新進入暫存器的 Block。黃色部分代表暫存器中已經有
資料，白色則代表暫存器尚未填入資料。 
 
c. On-Chip Texture Buffer Optimiza-
tion: 
    除了前面所提出的畫面層級上面的系
統記憶體頻寬問題，在字元(Word)層級也
仍然有繼續最佳化的空間。如圖十二所
示，由於我們使用的各種不同的外部記憶
體存取形式並不是一般 DRAM 所能夠支
援的正方形或是長方形的字元形式，在不
能夠動態修改 DRAM 存取字元的幾何形
狀的情況下，必然會有很多地方會需要比
真實資料量更多的頻寬才有辦法把所有資
料都讀取或輸出晶片。在圖十二中紅色的
部分就代表了僅包含部分所需的參考畫素
的 DRAM 欄位。 
為了能夠提升每一個字元所包含的資
料量比例，進而降低系統記憶體的頻寬消
耗，必需要有有效率的字元層級資料排程
 9 
實世界的轉換關係，再把物體在真實世界
的座標，經由目標的虛擬視角的矩陣求得
物體在目標視角上面的畫面座標。然而，
這樣的運算在需要作相機矩陣的反運算，
這會帶來大量的浮點數除法運算，這在硬
體上是相當大的負擔。因此，在本次計畫
中我們採用了 Holographic Transform 的等
效數學化簡，數學式如下所示： 
           
2 2 1
2 2 2 1
2 ( )
= =
1 1 1
XX XY XI
YX YY YI
IX IY Z
x x h h h x
w y y h h h y
w h h
       
        
       
              H
 (2) 
         
1 1 1 1
2 2
1 1 1 1
, 
1 1
XX XY XI YX YY YI
IX IY IX IY
h x h y h h x h y h
x y
h x h y h x h y
   
 
   
 (3) 
在(2)中，輸入跟輸出的訊號都是畫面的座
標，也因此不需要做反矩陣運算了，然而，
這樣的化簡要付出的代價是必須要針對每
一個深度值求出矩陣 H(Z)。也就是說，當
有 8Bits 的 Depth Map 時，我們必須事先
儲存好 256 種的矩陣。在硬體架構上面來
說，這樣的化簡節省了運算的邏輯，但代
價是大量的 Register Buffer，尤其在矩陣運
算時我們又需要浮點數的精確度，這讓
Buffer 的容量需求又變得更大了。 
H(Z)
Z
2551280
H(Z)
64 192
HLIA-4(Z)
HLIA-1(Z)HLIA-2(Z)  
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
ballet 1-2 breakdancers 3-4
pantomime 37-38 Gate Count
LIA-1 LIA-2 LIA-4 LIA-8
20000
17500
15000
12500
10000
7500
5000
2500
0
G
at
e
 C
o
u
n
t
A
ve
ra
ge
P
ix
e
l L
o
ca
ti
o
n
 E
rr
o
r
LIA of different intervals
 
圖十六：在 Homographic Transform 中的
線性逼近分析。 
4-stage pipeline
Vector Division
Linear
Interpolation
Z
Hbase,0
Hinc,0
Hbase,1
Hinc,1
virtual(x,y)
H(Z)
Hbase,Hinc
(x ,y ,w )‘ ‘ ‘
source
(x,y)
 
圖十七：在 Homographic Transform 中的
一個 Warping PE 所對應的硬體架構。 
8x Parallel
Virtual Block 
Buffer1
Virtual Block 
Buffer2
Virtual Block 
Buffer3
Request New
View1 Block
Request New
View2 Block
p
a
ra
lle
l v
ie
w
s
Source View2 Control
Source View1 Control
WARPING
PE
DEPTH
SELECT
D
is
p
a
ri
ty
T
a
b
le
L
o
c
a
ti
o
n
 B
u
ff
e
r
S
c
a
n
 L
in
e
 S
ta
tu
s
 B
u
ff
e
r
Scan Line
Status 
Update
Virtual Buffer2 Control
Virtual Buffer1 Control
Virtual Buffer3 Control
F
lu
s
h
C
o
n
tr
o
l
view1/2 block data
Next Location
s
o
u
rc
e
(x
,y
)
Z
virtual(x,y)
 
圖十八：Warping Engine 的架構。 
Area Reduction
3D Space
Projection
HT
This 
Work
576064
246168 218268
175968 68%
: memory
: logic
 
圖十九：在 Warping Engine 中的硬體面積
需求分析。 
Calculate 
Gradient 
Gradient
Inpainting
Check hole
Hole?
Conventional 
Implementation
Virtual block
Gradient
Padding
Virtual block
Virtual block
Foreground
Padding
Depth Based 
Raster Scan
Load Previous 
Gradient 
Fast 
Gradient
Proposed Single Iteration
Scheme
Y
Yleft Look-Up 
Table
G
ra
d
ie
n
t
 
c
y
c
le
s
/b
lo
c
k
360 24
1-iteration 
method
Computation 
Cycles
93.3%
VSRS General 
Mode  
圖二十：我們所提出的 Single Iteration 
Depth-based Inpainting Engine 與傳統的
 11 
硬體架構，首先計算 Occlusion 周邊的紋
理走向 (Texture Gradient) ，並且根據
Occlusion 周圍的紋理執行畫素的延伸
(Padding)。為了滿足 Depth Constraint，當
兩個 Inpainting Padding出的畫素同時想要
覆蓋在同一個 Occlusion 的位置時，我們
會根據 Depth 的資訊，讓比較接近背景的
部分覆蓋在上面。針對在 Block 的最上面
或是最下面因為精確的 Warping 所產生的
最多一個畫素的 Occlusion，由於不是因為
深度不同產生，我們則是會根據離
Occlusion 最近且最靠近前景的畫素來做
修補。最後，對於仍然沒有被填補的
Occlusion，我們會以 Raster-scan 的順序把
所有畫素填滿。由圖二十的最右邊我們可
以看到，在整合了我們的 Depth-based 
Inpainting 之後，我們可以把原本所需的
Cycle 節省掉 93.3%，並且維持更好的畫面
品質。 
Reference View
X-direction Shift 
(Conventional Design)
2D Planar Shift Rotation 10⁰
Yaw 12⁰Zoom Out
Zoom In
Example Results from the Proposed Chip
Region of 
outputted 
frame
:
Region of 
warped 
ref. frame
:
 
圖二十四：我們的晶片所能夠實現的自由
視角生成範例。 
Max Virtual View 
Synthesis Capability
Max Real View 
Decoding Capability
Total Power 
Efficiency**
* Free-View-Point 3D Functionality =  
0 Point: No Virtual View Synthesis; 1~6 Point: 
The supported virtual view dimension count (3 
dimension for translation and 3 dimension for 
rotation)
** Total Power Efficiency =  
(Max spec. for decoder + view 
synthesis)/(Power under max spec.)
Free-Viewpoint 
3D Functionality*
4Kx2K 
216 fps
4Kx2K 
120 fps
4Kx2K 
60 fps
4Kx2K 
30 fps4Kx2K 
24 fps
1080p 
60 fps
Horizontal 
Shift
Trans-
lation
Full Geo-
metry
27.5
MPixels/mW
20
MPixels/mW
10
MPixels/mW
      This Work
ISSCC 2010
ISSCC 2007
VLSI Sym. 2009
Overall System 
Performance 
Comparison
On-Chip SRAM
Logic Gate Count
Technology
Total Power Efficiency **
Power Consumption
Supported Standard
Max Decoder Capability
Free-Viewpoint 3D 
Functionality *
Max View Synthesis 
Capability
N/A
1744K
0.13um
0.12MPixels/mW
379mW@50MHz
Not Supported
Not Supported
1 Dimension
1280×1024@36fps
N/A
930K
0.13um
4.2MPixels/mW
36mW@60MHz
N/A (Only MC and 
color space 
conversion part)
352×288×2view
@49fps
1 Dimension
1280×1024@116fps
9.0KB
414K
90nm
3.6MPixels/mW
59mW@200MHz
H.264 High Profile
MVC High Profile
SVC High Profile
4096×2160@24fps
Not Supported
Not Supported
19.9KB
1416K
40nm
27.5MPixels/mW
69.5mW@240MHz
H.264 High Profile
MVC High Profile
4096×2160@30fps
6 Dimensions
4096×2160@216fps
ISSCC 2007 VLSI Sym. 2009 ISSCC 2010 This Work
1.25× to 26.7×
12.5× to 40.5×
6×
6.6× to 229×
9× to 40.5×
Overall 
System 
Capability
 
圖二十五：我們的晶片與其他的 3D 電視
晶片的比較。 
 
 
四、 結論與討論 
在今年的計畫中，我們完成了一個高
效能低頻寬的自由視角 3D 電視機上盒系
統 晶 片 (Free-viewpoint 3DTV Set-top 
Box SoC)的的演算法分析及架構設計，並
以硬體描述語言及 EDA tools 完成晶片設
計。可及時運算畫面最大為 2160p QFHD 
(4096x2160)，每秒 216 張畫面(9 個視
角，各每秒 24 張畫面)的自由視訊影像資
料。並且也能夠支援 H.264/AVC High 
Profile，H.264/AVC Multiview High Pro-
file 的 2D 與 3D 多視角及時解碼，在解碼
器的部份的最高規格為 2160p QFHD 
(4096x2160)，每秒 30 張畫面。成果包含
完整的晶片規格（邏輯閘個數、消耗功率、
消耗記憶體頻寬等）、支援的可調式功能選
項及影像品質等數據。晶片規格及實體照
片如圖二十二及圖二十三。 
另外，由圖二十四所示，我們的晶片
能夠支援包含了六個維度的旋轉與移動，
跟之前僅能支援水平方向，也就是左右眼
之間轉換的 3D 電視晶片相比，有著六倍
的維度提升。而其他硬體方面的比較如圖
二十五所示，跟之前的 3D 電視晶片相較
之下，由於本計畫為世界上第一顆自由視
角 3D 電視機上盒系統晶片，我們擁有最
高的系統整合程度，不管在能夠支援的自
由視角維度(六倍於之前的晶片)，虛擬視
角生成的運算能力(12.5~40.5倍於之前的
晶片 ) ，多視角解碼器的運算能力
(1.25~26.7 倍於之前的晶片)，以及功率消
耗的效率(6.6~229 倍於之前的晶片)，都
遠遠的超出之前的晶片的規格。 
本研究群的相關研究結果，99 年發表
7 篇 IEEE 會議論文， 100 年發表 IEEE
會議論文 2 篇，另有一篇 IEEE 會議論文
已被接受將在 101 年 1 月發表。並於 99
年發表 IEEE 期刊論文 1 篇。 
 
參考文獻 
國科會補助計畫衍生研發成果推廣資料表
日期:2011/12/14
國科會補助計畫
計畫名稱: 子計畫二:多重視角視訊處理及架構設計之研究
計畫主持人: 陳良基
計畫編號: 97-2221-E-002-191-MY3 學門領域: 訊號處理
無研發成果推廣資料
權利金 0 0 100% 千元  
碩士生 2 2 100% 
其中一位碩士班
畢業時獲得斐陶
斐會員 
博士生 2 2 100% 
其中一位博士班
獲得台大傑出研
究獎 
博士後研究員 0 0 100%  
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
在本年度的計畫中，我們展現了我們的研發成果，在論文發表方面，我們的研
發成果連續第三年獲選進入 ISSCC 會議論文，並且在本年度特別被選為該
Section 第一篇報告的論文。而在競賽方面，我們今年的研究成果參與了旺宏
金矽獎的競賽，也獲得了設計組的最佳成績:評審團鑽石大賞，以及最佳創意獎
兩項最重要的獎項。 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
