further raised than that of using a single image.  
In addition to using multiple images, we study 
the light normalization problem that is very 
challenging in computer vision and face 
recognition.  We proposed a new approach for 
lighting normalization by building an intrinsic 
illumination subspace.  Unlike illumination 
cone, this space is built by using the intrinsic 
images instead of by the appearance images.  
We show that the proposed method can solve 
the lighting-variation problem effectively, and 
increase the recognition performance.  In 
addition to the study on face recognition and 
verification, we also support the main project 
for system integration.  Based on the kernel 
LDA method developed in this project, we 
developed a face verification module and 
integrated it with the speaker-verification 
module.  An on-line identity verification 
system was then built by combining face and 
speaker verification. In this system, we also 
developed a method to solve a fundamental 
problem in pattern classification: how to 
classify imbalanced data set that appears in the 
learning process of a person-identification 
problem quite often. Finally, we study the 
problem of photometric stereo under arbitrary 
lighting conditions. Such a technique is 
potentially useful for 3D-based face recognition. 
We proposed the first method that can perform 
photometric stereo for Lambertian objects 
under arbitrary lighting by using only four 
images.  
 
Keywords: Face recognition; Person identity 
verification; Photometric stereo. 
 
二、 緣由與目的 
本計畫的研究目的是發展一套以人臉為基礎
的身份辨識技術，以應用於身份確認。此外，
亦提供總計畫人臉辨識的模組，由總計畫進
行整合，以期發展更可靠的多模式身份確認
系統。 
在第一年計畫人臉辨識與確認的研究上，我
們已經有以下的成果：在人臉樣本部分，我
們發展出一套人臉樣本蒐集系統，可方便地
蒐集多角度的人臉資料以進行方法的訓練
與測試。此成果發表在AFG 2004 會議 [2]，
其完整版本已被期刊 IEEE Trans. SMCA所
接受 [5]。 
在人臉偵測的部分，我們採用Paul Viola 所
提出的串接式分類器（a cascade of boosted 
classifiers）[13]。此方法是近來極受重視的
物體偵測方法，在人臉偵測上可以達到相當
快的速度與準確率。在人臉辨認上，我們發
展過一個基於影像序列的物體辨識方法，發
表在 ECCV 2004 會議 [1]。其完整版本刊
登於期刊 Pattern Recognition [4]。我們並開
發 了 一 個 以 Kernel Linear Discriminant 
Analysis (Kernel LDA) 演算法為基礎的單
張影像人臉辨識方法，適合與其它模式的方
法進行整合。 
在第二年的計畫中，我們持續探討多張影像
的人臉辨識方法，以進一步提昇辨識效能：
我們發展了  Inter-subspace distance (ISD) 
方法，藉由比較兩個子空間的距離來進行辨
識。此方法可視為  nearest neighbor 的延
伸，並有更好的效果。此方法發表於 ICPR 
2004 會議 [3]。 
我 們 也 提 出 新 而 有 效 的  lighting 
normalization 方法：我們藉由分解影像成為
內在影像 (intrinsic images) 的方式，建構一
個 intrinsic illumination subspace，並透過非
負 矩 陣 分 解  (non-negative matrix 
factorization) 的原理，將測試影像投影至此
子空間，以得到其光照影像  (illumination 
image) 與反射度影像 (albedo image)。經比
較，我們的方法比起過去常用的 quotient 
image 方法，更能去除因光照變化所產生的
影響。此方法已發表於電腦視覺界最重要的
國際會議 ─ ICCV 2005 [7]（該會議接受率
僅有 19.8％）。 
我們並將第一年中所發展的以 Kernel LDA 
為基礎的人臉辨識方法模組化。並將其提供
給整合型計畫之總計畫「結合音訊與視訊之
多模式身分確認之研究」進行整合，完成了
一個結合人臉與聲音的身份識別系統雛
形。此系統整合成果的相關論文已經已於
2006 荷蘭舉辦的 ICME 2005 會議 [6] 進行
口頭論文發表。 
在第三年度的計畫中，我們更進一步探討在
身份確認研究上常會遇到的問題 ─ 不平
衡資料集的訓練問題。該問題之有效處理有
助於整體辨識效能的提昇。我們提出了一個
中進行。 
我們的目標為找出能夠最小化目標函式的子
空間投影矩陣 w。假設投影矩陣 w 為訓練資
料 投 影 至 高 維 空 間 的 線 性 組 合
，則原本的目標函式可以轉換
成為 
( )∑
=
Φ=
i
ii
1
xw αl
( ) ,
Nαα
Mαα
α T
T
J =  
其中， 
( )( )
( ) ( )∑
∑
=
=
=
−−=
il
k
i
kj
i
ji
c
i
T
titii
k
l
l
1
1
,,1
,
xxM
MMMMM
( )∑
=
−=
cj
T
jlj j
K,1
1 KIKN , 
jK ： 的矩陣，jll × ( ) ),( jmnnmj k xxK =  
I： 的單元矩陣 jj ll ×
jl
1 ： ，其內容均為jj ll ×
jl
1 的矩陣 
( )yx,k ： ( )σ2exp yx −−  
經由上面的步驟將原本求解投影矩陣w的問題
轉換成求解係數向量 ，而此目標函式的解為
中具有最大特徵值的特徵向量。而為了
在求解時能更穩定，我們參考
α
MN 1−
[29][30]的作法，
將N更改為 IN μ+ ，其中I為單位矩陣，μ 為一
微小值。 
在求得 之後，Kernel LDA 的投影矩陣可表示
為 ，所以資料 x 其 Kernel LDA 的投
影為 
α
( )∑
=
Φ
i
ii
1
xαl
)( )( ) ( ) ( )( ) ( xxxxxw ,
11
i
l
i
ii
l
i
i k∑∑
==
=Φ⋅Φ=Φ⋅ αα 　 （1） 
以上是 Kernel LDA 尋找子空間投影矩陣的
方法。當找到投影矩陣之後，一般利用 Kernel 
LDA進行分類的作法是在投影的子空間上直
接利用最近鄰居法(NN)進行分類。在經過多
方嘗試後，在我們的方法中，採用 support 
vector machine (SVM)來處理投影後的資料。 
（3） 人臉影像集合辨識 
在人臉辨認的研究中，包含了人臉偵測以及
人臉辨認問題。在偵測問題中，以目前一般
技術上而言，要快速偵測到大略的人臉方位
是沒有問題的，然而若要精確地偵測出人臉
的位置及大小，使其與當初資料庫中所存放
的人臉樣本較為精確地吻合，仍有困難。由
此而發生的 miss-alignment 問題會影響到單
張影像的人臉辨認的準確度。人們可能稍微
變換一下人臉的方位，其人臉偵測的匡取位
置僅有稍許變動，即有可能讓原先的辨認結
果出現相反的答案。 
解決此問題的方法，可在訓練階段使用更多
張的影像。然而訓練階段影像越多，所訓練
出的分類器的複雜度越高，且要做準確的訓
練也越困難。因此另外一個解決此問題的方
向是在辨認階段使用多張影像。由於人臉偵
測的結果僅是一個大概的位置，真正更準確
的位置可能在其附近，因此這些多張影像可
以經由在附近變換偵測框之大小及位置來取
得，以便補償人臉偵測的不準度。此外，我
們也可以同時經由影像序列中的多張 
frame，來取得更多的影像。 
所取得的多張影像可視為一影像集合，而此
集合中的影像彼此並不一定有順序關係。而
原先的訓練資料也是另一個影像集合。因此
辨認的問題可轉化成為兩個影像集合間的比
對問題。過去在這樣的問題上，已經有一些
方法被提出與探討。在 [16] 中，此一問題被
轉換成比較兩個統計分佈的相似度問題，並
利用Kullback Leibler Divergence (KLD) 來測
量 其 相 似 度 。 而 在  [15] 中 提 出 了 
mutual-subspace method (MSM)，將此問題視
為求取兩個通過原點之子空間的夾角問題。
此夾角可轉換成為一個 singular value 的估
測問題，並由夾角的大小來判斷兩個子空間
的相似度。 
在我們的方法中，利用兩個子空間的距離來
進行相似度估測。而此兩個子空間並不一定
通過原點。我們的方法與過去線性組合物體
空間的原理具有關連性。在過去文獻中，曾
經探討當某類物體的各個不同轉換及不同光
照影像會近似地形成一個線性的子空間，此
線性子空間可以由某些抽樣的影像經線性組
合來表示。因此，若將所取得的影像集合線
性組合出其子空間，有助於克服因轉換與光
照不同所造成的影響。 
在影像 (intrinsic image) 的原理。一張人臉影
像 I 可以分解成為光照影像 L與反射度影
像 R。這些影像皆稱為內在影像。Weiss 在
2001 年於ICCV上提出了一個根據同一個物
體的多光源影像，進行內在影像分解的方法 
[14]， 
I(x,y) = R(x,y)L(x,y) 
利用此一方法，我們可以將一個含有同方位
多光源的 database，為其中每一個人，分解
出其光照影像。在考慮 attached shadow 的狀
況下，光照影像可以表示成 
L(x,y) = ∑i max(n(x,y) ⋅ li, 0),  
其中 n(x,y) 為 (x,y) 的法向量。這些光照影
像的集合與原先此人之人臉外觀影像 
(appearance image)的不同處在於反射度已經
被去除。考慮其所形成的子空間，與原先外
觀影像所形成的子空間有相同的形狀，只有
每個軸的縮放不同。因此這些光照影像所形
成的子空間仍然為一個 polyhedral cone。此 
cone 的基底數目為物體形狀的法向量數
目，而此 cone 可由這些基底經由正係數線
性組合來構成。 
接著我們考慮同一類的物體（例如人臉）。要
為一類的物體進行光線變化的考慮是非常困
難的。然對於人臉而言，我們考慮其形狀皆
為近似。若假設每個人臉的形狀接由一個 
generic face model 來代表，則在針對一個 
database 進行內在影像分解時，可以不考慮
人的不同，而只考慮光線變化的影響。因此
可以統一分解出一組光照影像。我們稱這組
光照影像所形成的空間為 generic intrinsic 
illumination space (GIIS)。 
GIIS與不同人之外觀影像所形成的空間有顯
著的不同。由於不同的人其人臉形狀雖可視
為近似，但其反射度有顯著不同。因此雖然
單 人 的 不 同 光 照 外 觀 影 像 形 成 一 個 
polyhedral cone，但多人的外觀影像所形成的
子空間可能非常的複雜。相反而言，僅由光
照影像所形成的子空間仍然可以近似成為一
個polyhedral cone。一個三度空間示意圖如圖
三所示。過去在Barsi and Jacobs 的分析中顯
示一個人的外觀影像所形成的  polyhedral 
cone 可以用低維度的空間來有效的表示 
[10]。由於 GIIS 與一個人的外觀影像子空間
形狀類似，因此我們有足夠的理由相信 GIIS 
仍可以有效地用低維度子空間來表示 ─ 即
使其所描述的已經不限於單一物體，而是一
整類人臉物體。 
為了建構此一子空間，以利於輔助光照正規
化，我們捨棄一般的PCA作法，改以非負矩
陣分解 (NMF) [11] 來進行。我們並經實際
測試發現NMF的效果在此一問題上比 PCA 
來得好。當利用一個 database 建立了 GIIS 
之後（此處我們透過Yale face database來建
立），此 GIIS 即可被用來輔助其它的測試影
像取得其光照影像，接著再透過與外觀影像
與其相除，即可得到反射度影像。而反射度
影像在各個光源下皆相同，更適合用來進行
人臉辨識，因此達到了去光或光照均一化的
效果。 
當給定一張測試影像後，我們首先利用其它
影像處理領域的去光辦法。這些辦法通常是
藉由一個低通濾波器來達成。此處我們使用
Gaussian smooth function 進行低通濾波。接
著我們將這樣初步估測的光照的影像投影至
我們所建構的 GIIS，進一步得到更準確的光
照影像。 
在過去，能夠為單張人臉影像進行光線影像
去除的方法，以 Shashua 等人 的 quotient 
image 法 [17] 為代表。我們的方法與其方法
的不同處在於他們只考慮單一點光源，而我
們可以允許多個光源。此外，他們並為考慮
任何 shadow，而我們針對 attached shadow 
作了完整的考慮。 
我們利用 Yale face database 以及 CMU PIE 
database 來測試人臉辨認的結果。此處只針
對光線變化來加以考慮，所使用的是正面人
臉影像，比對的方法是計算兩張去光影像間
的 correlation（即 cosine measure）。在 Yale 
database 的測試中，使用隨機選取的一半張
影像來建構 GIIS。我們也實作了以 PCA（3
個基底）以及 NMF（12 個基底）來分解的方
法，並與 quotient image 法進行比較。測試
結果如圖四所示。我們並進行了 CMU PIE 
database 的實驗，此處的 GIIS 建構是以所有
的 Yale database 中的影像來進行。因此是一
個跨 database 的測試。所的結果如圖五所
式，抽取出與正例數目相同的訓練資料。接
著利用一般的分類器（如 SVM）針對如此之
正反例資料，訓練出一個分類器。重複以上
的步驟，隨機再抽取同樣數目的反例資料若
干次。可得到多個 SVM 分類器。最後我們將
這些分類器整合成一個新的分類器：方法是
將輸入資料同時輸入這些分類器，再將這些
分類器輸出類別多數的那一類，當成最後的
分類結果。藉由如此的方式，可保證每次皆
將一般分類器應用在資料平衡的狀況下進行
分類。此外，我們也不需要產生原先不存在
的訓練資料。根據我們的經驗，就整體的考
慮（包含正確率、執行效率）而言，AB 十分
適合應用在身份確認上。 
然而AB仍有一些不足之處，特別是利用隨機
取樣的反例集合所產生的分類器，有時候需
要相當多的數目，才能得到可接受的結果。
我們提出一個將AB所得到的多個分類器做
進一步改進的方法 [9]，此法可以使用更少的
分類器，得到更好的效果。 
我們方法的大致原理介紹如下，首先將 AB
所得到的所有分類器賦予一個向量值。向量
的維度為總共訓練資料的數目（含所有正反
例）。如果某個分類器對於某個正例訓練正
確，則在該維度取值為 1,否則為−1。依照此
方式，每個分類器皆可產生一個向量值。 
這些向量的平均向量代表原先的AB在針對
這些訓練向量得到的結果。而在理想上，向
量 [1 1 … 1]T 代表每個訓練向量皆能正確
分類。為了做更好的選取，我們考慮一個新
的參考向量，此參考向量與 [1 1 … 1]T 及平
均向量共平面，且與平均向量垂直。取垂直
方向的目的是希望能夠與平均向量互補，以
便優先選取比較好的向量所代表的分類器。 
 
圖六：理想向量、平均向量、與參考向量之
概念示意。 
假設接著我們選取所有夾角與參考向量在 90
度以內的分類器，只利用這些分類器進行整
合。如此所產生的整合分類器比起原來的AB
更有效率（因為使用較少的分類器進行整
合），而且根據我們的實驗結果，其效果比
起原先AB所產生的分類器更好。此外我們也
提出一個將分類器依序排列的方法，詳情可
參考 [9]。 
我們分別針對六個不平衡資料集進行實驗。
這些資料集狀況如下表所示： 
 
我們分別比較三種方式：直接利用 SVM 對於
不平衡資料集分類，利用 ，以及利用我們
的方法（ABVCO）。由下表中，我們發現
ABVCO在所有的資料集皆得到最好的結果。 
 
在執行效率方面，由於我們的方法需要整合
的分類器數目較少，因此也比 AB 更有效率。 
我們也將此方法應用在身份確認上。我們所
開發的人臉確認方法與一個利用 Gaussian 
Mixture 的聲音確認方法結合，將兩者（人
臉與聲音）所得的結果利用 SVM 進行整合。
我們利用不平衡資料集的方法進一步改良此
結果，將整合分類器由 SVM 置換成為我們的
方法，所得結果如下： 
 
Recognition, AFG’05, Seoul, Korea, May 
2004. 
[3] J. H. Chen, S. L. Yeh, and C. S. Chen, 
“Inter-subspace Distance: A New Method 
for Face Recognition with Multiple 
Samples,” Proceedings of International 
Conference on Pattern Recognition, ICPR 
2004, Cambridge, UK, August 2004. 
[4] J. H. Chen and C. S. Chen, “Object 
Recognition Based on Image Sequences 
by Using Inter-Feature-Line 
Consistencies,” Pattern Recognition, Vol. 
37, Issue 9, pp. 1913-1923, September 
2004. 
[5] P. H. Lee, C. S. Chen, and W. Y. Chang, 
“On Automatic Collection of Multi-Angle 
Face Prototypes,” accepted and to appear 
in IEEE Transactions on Systems, Man, 
and Cybernetics, Part A (scheduled to be 
published on 2007) 
[6] H. T. Cheng, Y. H. Chao, S. L. Yeh, C. S. 
Chen, H. M. Wang, and Y. P. Hung, “An 
Efficient Approach to Multi-modal Person 
Identity Verification by Fusing Face and 
Voice Information,” Proceedings of IEEE 
International Conference on Multimedia 
& Expo, ICME 2005, Amsterdam, The 
Netherlands, July 2005. 
[7] C. P. Chen and C. S. Chen, “Lighting 
Normalization with Generic Intrinsic 
Illumination Subspace for Face 
Recognition,” Proceedings of IEEE 
International Conference on Computer 
Vision, ICCV 2005. 
[8] C. P. Chen and C. S. Chen, “The 4-Source 
Photometric Stereo Under General 
Unknown Lighting,” Lecture Notes in 
Computer Science, LNCS 3953 (ECCV 
Proceedings), 2006. 
[9] H. T. Cheng and C. S. Chen, “A 
Complementary Ordering Method for 
Class Imbalanced Problem,” Proceedings 
of International Conference on Pattern 
Recognition, ICPR 2006, August 2006. 
[10] R. Barsi and D. Jacobs, “Lambertian 
Reflectance and Linear Subspaces,” IEEE 
Transactions on Pattern Analysis and 
Machine Intelligence, Vol. 25, No. 2, 
2003. 
[11] D. D. Lee and H. S. Seung, “Learning the 
Parts of Objects by Non-negative Matrix 
Factorization” Nature 401, 1999. 
[12] S. Mika, Kernel Fisher Discriminants. 
PhD thesis, University of Technology, 
Berlin, October 2002. 
[13] P. Viola and M. Jones, “Rapid Object 
Detection using a Boosted Cascade of 
Simple Features,” Proceedings IEEE 
Conference on Computer Vision and 
Pattern Recognition, CVPR 2001. 
[14] Y. Weiss, “Deriving Intrinsic Images from 
Image Sequences,” Proceedings of IEEE 
International Conference on Computer 
Vision, ICCV 2001, 2001. 
[15] O. Yamaguchi, K. Fukui, and K. Maeda, 
“Face Recognition Using Temporal Image 
Sequence,” Proceedings of International 
Conference on Automatic Face and 
Gesture Recognition, AFG’98, Nara, 
Japan, 1998. 
[16] G. Shakhnarovich, J. W. Fisher, and T. 
Darrell, “Face Recognition from 
Long-term Observations,” Proceedings of 
European Conference on Computer Vision, 
ECCV 2002. 
[17] A. Shashua and T. Riklin-Raviv, “The 
Quotient Image: Class-based Re-rendering 
and Recognition with Varying 
Illuminations,” IEEE Transactions on 
Pattern Analysis and Machine Intelligence, 
Vol. 23, No. 2, 2001. 
[18] H. Cevikalp, M. Neamtu, M. Wilkes, and 
A. Barkana, “Discriminative Common 
Vector for Face Recognition,” IEEE 
Transactions on Pattern Analysis and 
Machine Intelligence, Vol. 27, No. 1, 
2005. 
[19] http://www.intel.com/software/products/o
pensource/libraries/cvfl.htm 
[20] N. Chawla, K. Bowyer, L. Hall, and W. P. 
Kegelmeyer, “SMOTE: Synthetic 
Minority Over-sampling TEchnique,” 
Journal of Artificial Intelligence and 
Research, 2002. 
[21] M. Kubat and S. Matwin, “Addressing the 
curse of imbalanced training sets: 
One-sided selection" Proceedings of ICML 
2002. 
[22] Nugroho, et al., “A solution for 
imbalanced training sets problems by 
