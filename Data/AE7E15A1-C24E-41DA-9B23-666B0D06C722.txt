mobile base and dual arms,  (iii) bio-inspired 
localization and navigation, and anticipation of 
human reactions； (iv) skill and behavior learning by 
demonstration and reinforcement learning, and self-
organizing learning； (v) advanced navigation, speech 
communication, coordination and cooperation for two 
mobile service robots； (vi) human-robot interaction 
using intelligent multi-agent approach and service-
oriented architecture for multiple users and service 
mobile robots.  All the developed key components 
together with developed subsystems will be 
implemented into an experimental robotic system, 
which will be considered as a test platform to 
evaluate how the proposed methods work well and how 
the robot interacts with people.  Aside from many 
theoretical innovations and improvements, all the 
proposed core technologies or functions must be 
realistically implemented and verified via 
experimentations on the laboratory-built robot. 
英文關鍵詞： Coordination and cooperation, dual arms, motion 
control, motion planning, human-robot interaction, 
learning through instructions, intelligent service 
robot, localization, navigation, stereo vision, 
object recognition, anticipation of human reactions, 
self-organizing learning, speech communication, skill 
learning by demonstration 
 
手眼力等合作功能之靈巧雙手臂、自主抓取操作與類
腦認知功能的任務執行，含雙手臂與輪式四輪全方位
運動平台的智慧型整合運動控制與路徑規畫，結合仿
生式定位與使用者行為預測，示範式的行為學習與自
我組織學習，先進導航系統整合、語音溝通與協調合
作，以及多使用者與多機器人之經驗式學習與人機互
動等關鍵科技。 
    為有效地達成此一願景目標，本整合型計畫共有
有六個子計畫，總計畫須協調統合各子計畫完成所需
的單項關鍵核心技術的研發，並完成整體機器人系統
之實體研製，整合所有關鍵核心的軟硬體以及控制技
術與其實現技術，進而建置機器人系統實驗平台與測
試其各項功能，以及完成成果交流、共享與技術推展
等工作。另為提昇研究的成效與卓越性，本計劃擬國
外大學(如美國西北與普渡大學，日本東京大學，京都
度大學，日本早稻田大學HRI研究機構合作，日本東北
大學，與歐盟德國內大學，)，進行次世代輪型雙手臂
行動服務機器人的機構設計與控制，以及其他雙手臂
的設計與控制。為提昇此研究的應用價值，本計畫將
和國內相關研究單位(工研院機械與系統所，精密機械
發展中心與金屬工業研究中心)與國內廠商(如華寶通
訊，華碩，均豪，上銀，茂創等公司)進行技術合作，
研究國內產品化的實際需求與實施方法，並進行研究
成果商品化的研究。最後，本計畫將透過TIROS產品發
表 會 、 學 術 研 討 會 (SIRcon 2011,FIRA 2011,ISR 
2012)、展示與測試已整合完成系統，提供國內機器人
研發團隊與廠商有關次世代輪型雙手臂行動服務機器
人系統之設計參考。 
   本整合計畫團隊是由具備機構設計，感知，控制，
導航，電腦視覺，學習，認知，人工智慧，資訊與嵌
入式系統晶片等跨領域專長之研究學者所組成，六個
子計畫各司其職，總計畫以三個階層加以整合智慧型
機器人系統核心技術。本整合型計畫的目的是針對次
世代黃金十年裡的智慧機器人的研究需求與議題，研
發如圖1，具有靈巧雙手臂與運動平台同時循跡控制功
能，以及上開功能規格的輪型雙手臂行動服務機器人
系統，以及探討該系統設備之關鍵核心技術及其相關
系統晶片與軟硬體實現技術。此系統之關鍵核心技術
研發項目，由六子計畫分別執行，總計畫的重點是整
合以上核心技術，本年度預定完成家事服務應用功
能，並且進行必要的使用者評估。除創新理論與技術
的發展外，所有的單項關鍵技術與整合系統功能均需
被實際地製作，並分別在原型實體設備上進行實驗測
試以檢證其可行性與有效性。 
 
二、智慧手眼力協調控制、自主抓取與
操作、以及類腦功能之任務執行(I)  
   本年度子計畫一之報告目的是設計與製作仿人式
靈巧雙手臂之手眼協調控制、電腦模擬及其嵌入式控
制晶片。該報告應用機電整合與嵌入式控制晶片等技
術，以一年的時間發展靈巧雙手臂之兩大主要技術: 第
一是結合Kinect感測器，發展雙手臂系統的低成本手
眼協調控制。第二項以雙手臂與手指系統的手眼協調
控制為基礎，致力於發展SURF 物件辨識，抓取點選定，
物件抓取等關鍵技術，接著探討雙手臂與手指系統的
基本合作動作，如以雙手合作取物、開罐、組裝、書
寫等，進而構成複雜動作與操作。最後以泡咖啡為範
例，從咖啡豆研磨，開罐，傾倒咖啡粉，過慮器裝置
以及倒水等動作，進行擬人型雙手臂系統的物件辨
識，自主抓取以及自主抓取等實驗，用以驗證所提出
方法之可行性與價值性。 
 
2.1 系統架構 
圖 1 描繪子計畫所研製的行動雙手臂機器人系
統，該實驗裝置搭載一 Kinect 視覺模組、一準系統 PC
電腦、二隻七個自由度的機械手臂以及一以四個
Mecanum 車輪為基礎的全方位行動平台。圖 2 為整個
行動雙手臂機器人的系統架構。Kinect 視覺模組被用
來找尋頭部系統與物件之間的矩離，辨識物件種類及
其位置。準系統電腦用來執行物件種類辨識，計算物
件位置，進行分析式逆向運動學和手臂移動路徑平滑
化。兩組 StraixII 的實驗版分別被用以雙手臂各種馬達
的 PIV 運動控制，以及全方位行動平台的軌跡追蹤控
制。 
 
2.2 研究方法 
   子計畫一首先探討基於Kinect感測器，致力於發展
SURF 物件辨識，抓取點選定等技術，然後著重發展雙
手臂系統的低成本手眼協調控制方法與其實作。該整
體手眼協調系統的控制分成非視覺伺服的開迴路控制
以及視覺伺服的閉迴路控制。非視覺伺服的開迴路控
制系統需發展可即時計算執行的分析式逆向運動學計
算步驟，接著發展軌跡規劃產生器使手臂運動軌跡平
滑化與PIV法則控制馬達，最後執行開迴路手眼協調控
制，即是在雙手臂執行任務的過程中，Kinect感測器
並未提供迴授資訊。相反地，以視覺伺服為基礎的閉
迴路控制必須以Kinect感測器，提供即時的抓取器的
姿態迴授資訊，配合Inverse Jacobin 方法，執行閉
迴路控制。最後以泡咖啡任務，用以說明該手眼協調
系統的可行性。在實作方面利用SOPC技術，C程式技
巧和模組化理念來分別完成實現控制器模組。 
 
2.3 結果與討論 
   圖 3 與圖 4 分別為非視覺伺服的開迴路控制系統以
及視覺伺服的閉迴路控制系統。圖 5 描述 SURF 演算
法的辨識結果以及泡咖啡任務中物件之辨識結果；表 1
為經辨識後，泡咖啡任務中四種物件的抓取位置誤差。 
圖 7 說明結合 SURF 演算法與開迴路控制結構的泡咖
啡任務之實驗結果；該結果說明 Kinect 視覺模組對物
件與機器人的矩離量測、物件辨視與雙手合作的整合
實驗結果，用以驗證子計畫所提的非視覺伺服的開迴
路控制系統的可行性。圖 8 陳述使用視覺伺服閉迴路
控制結構用於物件抓取之實驗結果，用以說明視覺伺
服閉迴路控制結構的效用性。以性能比較而言，如果
物件的位置在雙手臂捉取誤差的容許範圍內，開迴路
控制方式有效且實作較為容易，但如果物件的位置有
4.1 系統架構 
    子計畫 3自行發展兩種機器人系統平台。第一種
是以工研院所研發的公用平台Ubot為基礎的競賽式機
器人，如圖 15 所示。在此一平台之上，子計畫 3加上
一 HP 筆記型電腦為主要計算模組，一種 Logitech 
pan-tilt 網路攝影機以及一具遠距離量測功能的
Hokuyo 2D 雷射掃瞄器，一隻簡易的機器手臂，並以
45x45 mm 鋁製模塊製作該機器的支撐架構與硬體。子
計畫 3亦設計一電源模組，可分別供應筆記型電腦，
機器手臂與及 Ubot 移動平台的電源。在軟體方面，子
計畫 3使用標準的 OS，以及一般商用的語音與影像辨
識軟體，以利快速發展。 
   子計畫 3的第二種移動平台，如圖 16 所示，仍以
鋁製模塊製作其主要支撐硬體，用以簡化製作過程，
使整體硬體製作的複雜度越小越好，且使重量減輕。
該機器人仍使用 HP 筆記型電腦為主要計算模組，差動
式驅動模組，但使用 Kinect 感測器作為主要外部感測
器，以及使用 Open Natural Interaction groups 
OpenNI 的相關應用軟體。 
 
4.2 研究方法 
子計畫 3 在探討預測使用者的動作與反應時，必
須先瞭解使用者的指令與當時的情況相依，比如說煮
咖啡的指令，在早上的時間比一天內其他時間更有可
能。再者，就使用者可能的指令行為而言，可適應的
預想學習系統(adaptive meta-learning system)似乎
是較佳的構想。圖 17 說明傳統的人-機器人互動方式
與預想系統的差異性。圖 17 中的左圖是傳統的人-機
器人互動模式中，使用者說明其意圖，但機器人必須
再一次確認其指令；比如口語指令常易生錯誤，機器
人必須有第二次確認的需求。圖 17 中的右圖中機器人
可依據使用者 Context 內容(可能是一天的時間，每週
內的哪一天，或者天氣)，計算可能指令之機率之事先
預估。因此子計畫 3融合 deep belief networks and 
echo state networks 等兩類神經網路，結合事先的
經驗訊息(prior information)，發展可預測使用者的
動作，然後使用人機互動系統，進行相關實驗。。 
 
4.3 結果與討論 
   圖 18 描述子計畫 3 所提的結合 deep belief 
networks and echo state networks 等兩類神經網路
的人臉像辨識流程圖；該流程圖的輸入使用資料是需
事先使用 SURF 演算法對人臉像處理後的結果。圖 19
為 經 SURF 演算法處理人臉像的輸出結果。圖 20 說
明 DBN 網路的辨識率，高達 99.375%的正確率，遠比
其他三種方法(Eigenfaces, Fisherfaces, Laplacianfaces)
有更好的辨識率。 
 
五、以示範及加強式學習法則構成行為
自我組織機制(I) 
    工業機器人已被廣泛使用於現代工業裡。在目前
智慧自動化的需求裡，人與工業機器人的合作，進而
完成精密工作，已逐漸得到更多的關注。子計畫 4 希
望機器人可依據外力執行所需的動作。因此，力量感
測器即是該種機器人的重要組件。由於一般的力量感
測器相當昂貴，子計畫 4 提出一種便宜且內建的轉矩
感測器，用以實現力量控制。為展示所研製感測器的
效用性與實用性，子計畫 4 發展阻抗補償控制與摩擦
補償等兩種控制方式，然後進行實驗驗證。另外兩種
控制方式亦被應用於移動人型機器人的行走控制，並
得到良好的順應能力，用以避免危險。 
 
4.1 系統架構 
    子計畫 4 發展兩種實驗系統：其一是具便宜且內
建的轉矩感測器之機器人關節，如圖 20所示，該關節
使用應變規與惠斯登電橋，配合特殊設計的機構，完
成對外力的線性量測功能。其二是，如圖 21 所示，一
具足部力感測器的人型機器人與控制系統架構；該機
器人是修改自 Bioloid 機器人，使用 AI 伺服機與
Bluetooth 通訊裝 置，並以 PC 為主要控制器。 
 
4.2 研究方法 
    圖22說明該關節的阻抗控制模型；該模型參數可
經由實驗方式，取得其參數。該模型使用以下的阻抗
動態方程式: T M D Kθ θ θ= + +&& & 其中 T為外力， M
為其質量， D為阻尼， K為彈簧常數。將該阻抗動態
方程式以狀態變數表示之，然後以Euler數值法則求得
下列之值。 
1 1
1 1
1 0
1
k k
k k
t
K D Tt t
M M M
θ θ
θ θ
+ +
+ +
Δ
t
⎡ ⎤ ⎡Δ⎡ ⎤ ⎡ ⎤ ⎤⎢ ⎥ ⎢= +⎢ ⎥ ⎢ ⎥ ⎥⎢ ⎥ ⎢Δ ⎥− Δ − Δ Δ⎣ ⎦ ⎣ ⎦⎣ ⎦ ⎣
& &
⎦
)
 
若進行摩擦補償，則需估計摩擦力的大小值；其
方程式為 ˆˆ (fm m mLJ mτ θ θ= − −& & ；L=900; 為馬達轉
動慣量；
mJ
ˆ
mθ& 為瑪達角速度 mθ& 的估計值； ˆ fmτ 為估計的
摩擦力值。另外 Q-learning 方法被用於 Bioloid 機器人
的阻抗控制行走運動。 
 
4.3 結果與討論 
   子計畫 4以上開的研發方法進行機器人關節的阻抗
補償控制與摩擦補償控制，以及 Bioloid 機器人的行走
運動實驗。在實驗前，先設定 M=1; D=3; K=3。圖 23
陳述該關節運動時之阻抗補償控制結果；該結果顯示
該關節在固定外力的作用時可到達所需的位置。圖 24
為該關節在人造外力時之摩擦補償控制結果；該結果
說明補償控制其可達成預期的控制效果。 
   圖25分別說明Bioloid 機器人的阻抗控制行走運動
實驗時，左、右腳腳趾頭與足跟之力感測波形。該波
形顯示。圖 25(a)中足跟的力反應較腳趾頭部分慢；。
圖 25(b)中則足跟的力僅有些微的力反應。整合而言，
阻抗控制方式在行走機器人的控制應用有良好效果。 
 
六、先進導航系統整合協調合作與語音溝通
(I) 
   子計畫5的研究係以過去所開發之點餐服務機器人
第四代為主要平台，在傳統的同步定位與環境地圖建
有的技術上，而沿用申請人過去在服務導向計算的基
礎，我們考慮機器人的服務為網絡服務的服務規劃，
研究個人化服務的可能性。研究重點仍在於系統的服
務內容並不能完全滿足不同的使用者，每位使用者的
需求及喜好皆不盡相同，針對不同的使用者喜好提供
使用者所期待之適合服務內容，將可讓使用者與機器
人互動更為友善。為了達到服務個人化的目的，則必
須事先得知使用者的喜好(Preferences)，而最普遍的方
法便是建立並分析使用者模型(User Model)。這些研究
多數屬於網際網路的搜尋或網絡服務中熱烈探討的主
題，可是在於機器人服務將是值得做的研究，本研究
將不同機器人視為不同的服務提供者，所提供的服務
則可以是高階或底層服務。 
如圖 34 所示，系統從使用者端搜集到該使用者
的相關資料(使用者資料搜集)，並建立該使用者的使用
者定義(建構使用者定義)，最後將建立好的使用者定義
給予特定的應用程式使用(應用程式)，以達到服務個人
化的目的。流程中的明確/不明確資訊則分別代表著直
接由使用者提供的資訊(明確)以及經由系統分析得來
的資訊(不明確)。今年度的重點放在個人本體論模型的
建設，透過使用者平常瀏覽網頁的記錄及VALS (Values 
and Lifestyles)類型來建構使用者定義，此方法改善了
使用者定義內容不夠貼近使用者本身的資訊之缺點及
無法捕捉使用者短期喜好。 
 
7.2 研究方法 
子計畫 6 的研究方法共分為 6 部分，第一部分小
說明所提出一個可能的方向，來設計通用的個人本體
論，但最後並沒有使用這個本體論，就可以完成系統
的需求。第二部分將說明如何透過資料準備工作，建
立使用者定義，並且組合成興趣-行為矩陣來計算相似
度。第三部分說明已經有了計算相似度的方式，怎麼
用資料探勘中的分類方法來將使用者歸類。第四部分
描述如何進行合作式篩選第二、三步驟，篩選出使用
者，並用這些人選產生推薦。第五部分陳述使用者回
饋機制，以及第六部分說明本研究提出方法的流程圖。 
 
 
7.2 結果與討論 
圖 35 說明子計畫 6 所提出之方法的流程圖。一
開始必須先讓使用者註冊，以便系統能夠辨識使用
者。註冊包括輸入帳號、密碼，填寫 VALS 問卷等。接
下來，系統便能夠記錄使用者的瀏覽行為，根據使用
者興趣與行為，建構個人的興趣-行為向量。如果目標
使用者已經是系統的會員，則進行更新個人向量的動
作。更新完會進入分類機制，進行群組調整，重新計
算與群組中心使用者的相似度，系統會檢查是否還是
屬於原本的群組或者要從此群組刪除。 
如果目標使用者是新加入的會員，也是與其它群
組中心使用者進行相似度計算，根據門檻值來進行目
標使用者的第一次分類。分類結束後，如果使用者希
望得到系統自動產生的推薦，系統將會從目標使用者
所屬的群組中，挑出 k個與目標使用者相似度最高的，
來當成合作推薦物品的使用者人選。如果使用者不希
望系統自動產生推薦，流程就直接結束。最後，若目
標使用者選擇了系統建立的推薦清單中的物品，則進
入使用者回饋機制，動態修改目標使用者對於這些合
作推薦之使用者的信任值。 
以上的研究成果著重在如何完成推薦系統的討
論，所得到的成果符合以下在於子計畫 6 所提的產出 
所需的技術: (1)指令式互動學習：使用者可以主導教
導機器人關於物件的定義及其分類，使用者可藉由高
階指令與機器人溝通；(2)使用者及環境互動：使用者
藉由單純語音為機器人互動介面，同時機器人也可以
與環境物件有互動；(3)日常生活規劃與建議：使用者
的生活習慣及喜好可提供當天的行程規劃，以及適當
的提醒與建議；(4)意圖及喜好模型。以上所提的技術
可應用於單純語音系統與行程安排系統等系統的開
發，然後可應用於智慧屋。 
  
八、結論  
本報告已精簡敘述如何完成協調統合各子計畫完
成第一年預定工作項目，並協助各子計畫完成必要的
單項技術設計與實現。目前本整合型計畫已進行多次
小型成果交流、分享與交換相關技術，解決共有問題，
並協助各子計畫積極進行預定的工作項目與實驗,且獲
得上述子計畫成果。 
本整合計畫團隊已建立輪型雙手臂居家服務應用
平台，且已參與2012 TIROS展示，參與2012 TIROS MC
舉辦智慧機器人創意競賽與2012 TIROS教育部為電腦
系統設計競賽，協助推動兩岸機器人學的技術與經驗
交流，且已舉辦SIRcon 2011,FIRA 2011,ISR 2012等國
際研討會。 
 
九、參考文獻  
子計畫一 
[1] H. Iwata and S. Sugano, “Design of human symbiotic robot 
TWENDY-ONE,” IEEE International Conference on Robotics and 
Automation, pp. 580-586, 2009. 
[2] K. Kaneko, K. Harada, F. Kanehiro, “Humanoid Robot HRP-3,” in 
Proc. of IEEE/RSJ International Conference on Intelligent Robots 
and Systems, pp.2471 – 2478, 2008. 
[3]  Y. Sakagami, R. Watanabe, C. Aoyama, S. Matsunaga, N. Higaki 
and K. Fujimura,“The intelligent ASIMO: System overview and 
integration,”Proc. of IEEE Int. Conf. Intelligent Robotics and 
System, pp. 2478-2483, Oct., 2002. 
[4] Beira, M. Lopes, M. Praga, J. Santos-Victor, A. Bernardino, G. Metta, 
F. Becchi, R. Saltaren, “Design of the Robot-Cub (iCub) Head,” in 
Proc. of IEEE international conference on Robotics and 
Automation, pp. 94-100, 2006. 
[5] C. C. Tsai, Y. S. Wang, Y. Y. Li, F. C. Tai, “Motion Planning and 
Cooperation of an Anthropomorphous Two-Armed Robot,” 
Proceedings of 2009 CACS International Automatic Control 
Conference, Taipei, Taiwan, Nov. 27-29, 2009. 
[6] C. C. Tsai, Y. S. Wang, Y. Y. Li, “Design and Implementation of an 
Anthropomorphous Two-Armed Robot with Multiple Task 
Applications,” Proc. of 2009 International Conference on Service 
and Interactive Robots, Taipei, Taiwan, August 6-7, 2009. 
[7] C. C. Tsai, T. T. Liang, Y. Y. Li, “Trajectory Planning and Motion 
Control of a Two-Armed Robot,” Proc. of the SICE Annual 
Conference 2010, Taipei, Taiwan, August 2010. 
[8] C. C. Tsai, Y. S. Wang, Y. Y. Li, F. C. Tai, “Cooperation and Task 
Execution of an Anthropomorphous Two-Armed Robot: an 
Application to Coffee Making,” Proc. of the 2010 International 
Conference on System Science and Engineering, Taipei, Taiwan, 
Nature 304 (5922): 111–114. DOI:10.1038/304111a0. PMID 6866101. 
[25] N.M. Mayer and I. Fasel. Autism as an impairment in detecting 
riants. In Development and Learning (ICDL), 2010 IEEE 9th 
national Conference on, pages 269{273. IEEE, 2010. 
inva
Inter
reco er. 
201
autis :255{268, 
197
face
Pro
hem
Neu
Inte
feat
110(
oper mation 
Tec
volu
with
200 {1951. 
IEE
Pro
[26] Ken-Liang Liu. How eye-movement behaviors of facial expression 
gnition and gaze following correlate in autistic spectrum disord
0. 
[27] T. Langdell. Recognition of faces: An approach to the study of 
m. Journal of Child Psychology and Psychiatry, 19(3)
8. 
[28] M.L. Spezio, R. Adolphs, R.S.E. Hurley, and J. Piven. Analysis of 
 gaze in autism using. Neuropsychologia, 45(1):144{151, 2007. 
[29] E. De Renzi, D. Perani, G.A. Carlesimo, MC Silveri, and F. Fazio. 
sopagnosia can be associated with damage con_ned to the right 
ispherean mri and pet study and a review of the literature. 
ropsychologia, 32(8):893{902, 1994. 
[30] U. Frith. Autism: Explaining the enigma. Cambridge, En, 1989. 
[31] P. Viola and M.J. Jones. Robust real-time face detection. 
rnational journal of computer vision, 57(2):137{154, 2004. 
[32] H. Bay, A. Ess, T. Tuytelaars, and L. Van Gool. Speeded-up robust 
ures (surf). Computer Vision and Image Understanding, 
3):346{359, 2008. 
[33] L. Yunqi, L. Haibin, and J. Xutuan. 3d face recognition by surf 
ator based on depth image. In Computer Science and Infor
hnology (ICCSIT), 2010 3rd IEEE International Conference on, 
me 9, pages 240{244. IEEE, 2010. 
[34] S. An, X. Ma, R. Song, and Y. Li. Face detection and recognition 
 surf for human-robot interaction. In Automation and Logistics, 
9. ICAL'09. IEEE International Conference on, pages 1946
E, 2009. 
[35] G. Du, F. Su, and A. Cai. Face recognition using surf features. In 
c. of SPIE Vol, volume 7496, pages 749628{1, 2009. 
 
子計畫四 
[1]. Sabina Jeschke, Honghai Liu, and Daniel Schilberg,“Intelligent 
Robotics and Applications,” International Conference on Intelligent 
Robotics and Applications, pp. 281-290, 2011. 
[2]. 津村稔：“ ロボットと力覚センサ－ロボット力覚 センサの研
究開発事例”,ビー・エル・オートテッ ク株式会社．2008 
[3]. 九州ロボットセンター.com，“ 知能ロボット
http://www.k-robotcenter.com/chinou.html ” 
[4]. 藤岡寛之他:“ 関節軸トルク制御を用いたマニピ ュレータの
運動・力・インピーダ ンス制御 ”,東京電機大学総合研究所年
報,2003. 
[5]. 川上智弘他:“低インピ-ダンスを実現するトルク エンコーダ
型関節駆動系の開発”, 日本ロボット 学会学術講演会 2009, 
3C3-01,2009. 
[6]. Hogan, Neville, “Impedance Control: An Approach to 
Manipulation,”  American Control Conference, 
pp.304-313, 1984. 
[7]. Luc Le Tien, Alin Albu-Schaffer, Alessandro De Luca, and Gerd 
Hirzinger, “Friction Observer and Compensation for Control of 
Robots with Joint Torque Measurement,” IEEE/RSJ International 
Conference on Intelligent Robots and Systems, pp. 
3   789-3795, 2008. 
[8]. 西山禎泰:“ 日本におけるロボットの変遷と表現との関係”, 
名古屋造形大学紀要,Vol.17, 151-166,2011. 
[9]. ロボット図鑑,“ 活躍するロボット達 ”,自動化技 
術, Vol.27,No.1,1995. 
[10]. Zhang, G. and Furusho, J “Control of Robot Arms Using Joint 
Torque Sensors,” Proceedings in Robotics and Automation, pp.  
3148-3153, 1997. 
[11]. A. Parmiggiani, M. Randazzo, L. Natale, G. Metta and G. Sandini, 
“Joint torque sensing for the upper-body of the iCub humanoid 
robot,”International Conference on Humanoid Robots, 2009. 
[12]. H. Nakamoto, F. Kobayashi, N. Imamura and H. Shirasawa, 
“Universal robot hand equipped with tactile and joint torque 
sensors,” in Proceedings of the 10th World Multi-Conference on 
Systemics Cybernetics and Informatics, vol. 2, pp. 347–352, 
2006. 
 
子計畫五 
[1] M. G. Dissanayake, P. Newman, S. Clark, H. Durrant-Whyte, and M. 
Csorba, “A solution to the simultaneous localization and map 
building (SLAM) problem,” IEEE Trans. Robot. Autom., vol. 17, no. 
3, pp. 229–241, Jun. 2001. 
[2] H. J. Chang, C. S. G. Lee, Y.-H. Lu, and Y. C. Hu, “A computational 
efficient SLAM algorithm based on logarithmic-map parititioning,” 
in Proc. IEEE/RSJ Int. Conf. Intell. Robots Syst., Sep. 2004, pp. 
1041–1046. 
[3] M. Montemerlo, S. Thrun, D. Koller, and B. Wegbreit, “FastSLAM: 
A factored solution to the simultaneous localization and mapping 
problem,” in Proc. AAAI Nat. Conf. Artif. Intell., Edmonton, AB, 
Canada, 2002, pp. 593–598. 
[4] A. Eliazar and R. Parr, “DP-SLAM 2.0,” in Proc. IEEE Int. Conf. 
Robot. Autom., May 2004, vol. 2, pp. 1314–1320. 
[5] D. Hähnel, W. Burgard, D. Fox, and S. Thrun, “An efficient 
FastSLAM algorithm for generating maps of large-scale cyclic 
environments from raw laser range measurements,” in Proc. 
IEEE/RSJ Int. Conf. Intell. Robots Syst., 2003, pp. 27–31. 
[6] S. Thrun, M. Beetz, M. Bennewitz, W. Burgard, A. Cremers, F. 
Dellaert, D. Fox, D. Hähnel, C. Rosenberg, N. Roy, J. Schulte, and 
D. Schulz, “Probabilistic algorithms and the interactive museum 
tour-guide robot minerva,” Int. J. Robot. Res., vol. 19, no. 11, pp. 
972–999, 2000. 
[7] Simone Frintrop and Patric Jensfelt, “Attentional landmarks and 
active Gaze control for visual SLAM,” IEEE Transactions on 
Robotics, vol. 24, no. 5, October 2008.  
[8] Andrew P. Gee, Denis Chekhlov, Andrew Calway, and Walterio 
Mayol-Cuevas, “Discovering higher level structure in visual 
SLAM,” IEEE Transactions on Robotics, vol. 24, no. 5, October 
2008.  
[9] Rodrigo Munguía and Antoni Grau, “Closing loops with a virtual 
sensor based on monocular SLAM,” IEEE Transactions on 
Instrumentation and Measurement, vol. 58, no. 8, August 2009.  
[10] Nathan Kirchner, Dikai Liu and Gamini Dissanayake, “Surface type 
classification with a laser range finder,” IEEE Sensors Journal, vol. 9, 
no. 9, September 2009.  
[11] Pedro Pini´es and Juan D. Tard´os, “Large-scale SLAM building 
conditionally independent local maps: application to monocular 
vision,” IEEE Transactions on Robotics, vol. 24, no. 5, pp. 
1094-1106, 2008. 
[12] David Schleicher, Luis M. Bergasa, Manuel Ocaña, Rafael Barea 
and María Elena López, “Real-time hierarchical 11 outdoor SLAM 
based on stereovision and GPS fusion,” IEEE Transactions on 
Intelligent Transportation Systems, vol. 10, no. 3, September 2009. 
[13] D. Schroter, T. Weber, M. Beetz, and B. Radig, “Detection and 
classification of gateways for the acquisition of structured robot 
maps,” in Proc. 26th Pattern Recog. Symp., Aug. 2004, pp. 553–561. 
[14] H. Jacky Chang, Yung-Hsiang Lu, Y. Charlie Hu, “P-SLAM: 
simultaneous localization and mapping with environmental-structure 
prediction,” IEEE International Conference on Robotics and 
Automation, vol. 23, no. 2, April 2007. 
[15] Anas Fattouh and Salah Nader, “Preliminary results on dynamic 
obstacle avoidance for powered wheelchair”, Information and 
Communication Technologies, 2006. ICTTA '06. 2nd vol. 1, pp. 
849 – 853, April 2006. 
[16] Chang-bae Moon, Seokgyu Kim, Minki Choi, Jaesik Choi, Hoyeon 
Kim, Woojin Chung, and Jae-Bok Song, “Safe navigation of a 
mobile robot considering visibility of environment,” Industrial 
Electronics, IEEE Transactions, vol. 56, no 10, pp. 3941 - 3950, Dec. 
2009. 
[17] C.-B. Moon, W. Chung, S. Kim, and J.-B. Song, “Safe navigation 
of a mobile robot using the visibility information,” in Proc. IEEE 
ICRA, Rome, Italy, Apr. 2007, pp. 1304–1309.  
[18] R. Simmons, D. Apfelbaum, W. Burgard, D. Fox, M. Moors, S. 
Thrun, and H. Younes, “Coordination for multi-robot exploration 
and mapping,” in Proc. AAAI Nat. Conf. Artif. Intel., Austin, TX, 
2000, pp. 852–858. 
[19] W. Burgard, M. Moors, C. Stachniss, and F. Schneider, 
“Coordinated multi-robot exploration,” IEEE Trans. Robot., vol. 21, 
no. 3, pp. 376–386, Jun. 2005. 
[20] G. Grisetti, C. Stachniss, and W. Burgard, “Improving grid-based 
SLAM with Rao-Blackwellized particle filters by adaptive proposals 
and selective resampling,” in Proc. IEEE Int. Conf. Robot. Autom., 
Apr. 2005, pp. 2443–2448.  
[21] B. Stewart, J. Ko, D. Fox, and K. Konolige, “The revisiting 
problem in mobile robot map building: A hierarchical Bayesian 
approach,” in Proc. 19th Annu. Conf. Uncertainty Artif. Intell., 2003, 
 +
−
dX dθ θ
 
圖 4.使用視覺伺服的閉迴路控制結構 
 
圖 8、使用視覺伺服閉迴路控制結構用於物件抓取之實
驗結果 
 
圖 5、使用 SURF 辨識複雜物件的實驗結果以及泡咖啡
任務中物件之辨識結果 
 
表 1. 泡咖啡任務中四辨識物件的位置誤差  
 X-Coordinate Y-Coordinate Z-Coordinate
Tea Cup 0.4930 mm -0.4902 mm 1.1152 mm 
Grinder 4.2901 mm -6.3428 mm 3.4239 mm 
Filter -4.6840 mm -3.7613 mm 2.9793 mm 
Bottle 0.5438 mm -5.6172 mm 1.9442 mm 
圖 9.子計畫 2所研製的四輪全方位移動機器人。 
CPU
On-chip
RAM
On-chip
ROM
UART
PIO
Timer
SPI
QEP
Decoder
Digital 
Filter
PACOPSO
Algorithm
Nios II Embedded Processor
Embedded Optimal Controller
/
+
/
/
/
D/A
Converter/ /
Trajectory
Command
4
4
4
/
4
4 4
4
4
Output to the
Platform
Signals from
Rotary Encoders
+
_
lwIP
PACOPSO-based Platform Controller IC based on  Altera FPGA 
Data from/to PC
User IP core library
A
valon B
us
A
valon B
us
/
 
 
圖 6、SURF 的辨識結果以及泡咖啡任務中物件之辨識
結果 
 
圖 10. 四輪全方位移動機器人平台的嵌入式
PACOPSO 最佳控制器。 
圖 7、結合 SURF 演算法與開迴路控制結構的泡咖啡任
務之實驗結果 
  
圖 17. 子計畫 3所提的使用者意圖的預測概念 
 
 
圖 21. 具內建轉矩感測功能的機器人關節 
 
 
 
圖 18. 子計畫 3所提的結合 deep belief networks and 
echo state networks 等兩類神經網路的人臉像辨識 
 
圖 21. 具足部力感測器的人型機器人與控制系統架構 
 
 
圖 19. 經 SURF 演算法處理人臉像的輸出 
 
 
 
圖 22. 阻抗補償控制模型 
 
圖 23. 該關節運動時之阻抗補償控制結果 圖 20. DBN 網路的辨識率 
Service 
Robot 2 
Service 
Robot 1
Service 
Robot 3 
圖 32：多使用者與多機器人之互動 
User1 User2 User3 User4
圖 33：智慧型代理人架構 
Robot1 User 1
World 
Model
IA 
IA 
IA
IA
IA
Robot 2 
Appliance
Active 
Cooperation 
(SOA) 
IA
User 2 
 
 
圖29. 子計畫5所提的WV-SLAM演算法架構   
 
圖30. 子計畫5所提的實驗場地 
 
 
圖 34 服務個人化示意圖 
圖31. 優化後的環境地圖(第二個實驗環境) 
 
附錄二、計畫成果自評 
(1)與原計劃相符程度與達成預期目標情況：本整合計畫第一年的目標是研發具有整合移動智能，手、眼、力與
人機互動等功能的次世代智慧輪型雙手臂行動服務機器人系統，以及探討該系統設備之關鍵核心技術及其相關
嵌入式控制晶片與軟硬體實現技術。此系統之關鍵核心技術研發項目，由六子計畫分別執行，其重點涵蓋仿人
式靈巧的雙手臂之手眼合作技術，智慧型運動平台之控制與路徑規畫，使用者行為預測，力回饋控制與機器人
的學習式行走控制，WV-SLAM 同時定位與導航技術，以及單一使用者與單一機器人之人機互動等六項。六個
子計畫已依計畫逐項完成，並提出一創新，有效實用的工程設計方法，發展軟硬體的實作技術，並建置完成可
進行實驗展示與實驗測試家事服務機器人系統。因此，總計畫已完成第一年計劃中之既定項目，但仍有少許項
目正在積極從事研製工作，預計將於本期結束時完成。 
 
(2) 研究成果之學術或應用價值：總計畫針對智慧屋內的家事服務機器人系統平台，協調子計畫1,2共同開四輪
全方位運動平台的控制與路徑規畫，室內定位與導航策略，人機互動，任務執行等關鍵零主件與次系統技術，
以及應用系統整合技術，其中包括定位導航功能之四輪平台，更精巧的力順應動作控制、手眼協調控制，使用
者命令預測系統，智慧人機互動與嵌入式系統晶片研製。所研發的技術可提昇國內智慧輪型雙手臂行動服務機
器人的感知、學習、行動、操控性、智慧決策、安全等功能；所研發的系統軟硬體建置與相關實務技術，不但
有助於現今家事服務機器人的研製，同時可推廣應用於其他的製造、教育、服務、娛樂休閒等應用。本計畫亦
提出有效且實用的工程設計方法，配合軟硬體的實作，建置完成可進行實驗測試與展示的與人共生機器人。配
合本計畫之執行，將可提昇國內控制與自動化機電控制系統之關鍵零主件的研發設計能量。另外，總計畫今年
已完成訓練參與本計畫之碩士班究生12多名及博士生2 名，俾使其分別獲得機電整合、定位、導航、力感測、
系統控制、晶片設計、電腦視覺、智慧資訊處理、人工智慧、資訊技術與系統晶片等技術之分析設計與實作經
驗，對國內智慧輪型雙手臂行動服務機器人系統與控制研究人才的培育與訓練有相當裨益，這些人才對提昇國
家知識產業經濟競爭力將有顯著貢獻。 
 
(3) 主要發現及其他相關價值：總計畫主要發現或貢獻有雙手臂與立體視覺的協調控制，四輪全方位運動平台之
智慧型控制與路徑規畫，使用者命令預期系統，新型力感測系統研發與Q學習式的力量順應控制，視覺式定位
與建圖系統，使用多重代理人系統的人機互動系統與等新技術之研發。所研發的系統軟硬體建置，系統整合與
相關實務技術，有助於現今智慧輪型雙手臂行動服務機器人系統的實際研製技術。 
 
100年度專題研究計畫研究成果彙整表 
計畫主持人：蔡清池 計畫編號：100-2221-E-005-033- 
計畫名稱：次世代輪型雙手臂行動服務機器人之智慧控制、學習與任務執行--總計畫：次世代輪型雙
手臂行動服務機器人之智慧控制、學習與任務執行(I) 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 1 1 100%  
研討會論文 3 2 150% 
篇 
 
論文著作 
專書 1 1 100%   
申請中件數 1 1 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 0% 件  
技術移轉 
權利金 0 0 0% 千元  
碩士生 2 2 100%  
博士生 2 2 100%  
博士後研究員 0 0 0%  
國內 
參與計畫人力 
（本國籍） 
專任助理 1 1 100% 
人次 
 
期刊論文 3 2 150%  
研究報告/技術報告 0 0 100%  
研討會論文 5 2 250% 
篇 
 
論文著作 
專書 1 1 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
國科會補助專題研究計畫成果報告自評表 
請就研究內容與原計畫相符程度、達成預期目標情況、研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）、是否適
合在學術期刊發表或申請專利、主要發現或其他有關價值等，作一綜合評估。
1. 請就研究內容與原計畫相符程度、達成預期目標情況作一綜合評估 
■達成目標 
□未達成目標（請說明，以 100字為限） 
□實驗失敗 
□因故實驗中斷 
□其他原因 
說明： 
2. 研究成果在學術期刊發表或申請專利等情形： 
論文：■已發表 □未發表之文稿 □撰寫中 □無 
專利：□已獲得 ■申請中 □無 
技轉：□已技轉 □洽談中 ■無 
其他：（以 100字為限） 
本整合計畫已發表至少 12 篇研討會論文，部分研討會論文正改寫投稿期刊中。 
本整合計畫團隊已建立輪型雙手臂居家服務應用平台，且已參與 2012 TIROS 展示，參與
2012 TIROS MC 舉辦智慧機器人創意競賽與 2012 TIROS 教育部為電腦系統設計競賽，協助推
動兩岸機器人學的技術與經驗交流，且已協助舉辦 SIRcon 2011,FIRA 2011,AIM 2012,ISR 
2012, iFUZZY2012,iACC2012 等國際研討會。 
3. 請依學術成就、技術創新、社會影響等方面，評估研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）（以
500字為限） 
總計畫針對智慧屋內的家事服務機器人系統平台，協調子計畫 1,2 共同開四輪全方位運動
平台的控制與路徑規畫，室內定位與導航策略，人機互動，任務執行等關鍵零主件與次系
統技術，以及應用系統整合技術，其中包括定位導航功能之四輪平台，更精巧的力順應動
作控制、手眼協調控制，使用者命令預測系統，智慧人機互動與嵌入式系統晶片研製。所
研發的技術可提昇國內智慧輪型雙手臂行動服務機器人的感知、學習、行動、操控性、智
慧決策、安全等功能；所研發的系統軟硬體建置與相關實務技術，不但有助於現今家事服
務機器人的研製，同時可推廣應用於其他的製造、教育、服務、娛樂休閒等應用。本計畫
亦提出有效且實用的工程設計方法，配合軟硬體的實作，建置完成可進行實驗測試與展示
的與人共生機器人。配合本計畫之執行，將可提昇國內控制與自動化機電控制系統之關鍵
零主件的研發設計能量。另外，總計畫今年已完成訓練參與本計畫之碩士班究生 12 多名
及博士生 2 名，俾使其分別獲得機電整合、定位、導航、力感測、系統控制、晶片設計、
電腦視覺、智慧資訊處理、人工智慧、資訊技術與系統晶片等技術之分析設計與實作經驗，
對國內智慧輪型雙手臂行動服務機器人系統與控制研究人才的培育與訓練有相當裨益，這
些人才對提昇國家知識產業經濟競爭力將有顯著貢獻。 
