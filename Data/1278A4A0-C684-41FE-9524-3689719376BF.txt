2 
 
練中，並且在許多語音辨識的議題上獲得良好的成果[7, 
8, 9, 10, 11, 12]，這些以邊際資訊為主的方法，其共通概
念 皆 源 自 於 統 計 式 學 習 理 論 (statistical learning 
theory)[13]，其目標在於最小化一個由訓練資料固有的
錯誤與決策邊界到最近訓練語句樣本(samples)間的距離
(邊際)所結合的函數[10, 11, 12]。雖然這些基於邊際資訊
的方法是由嚴謹的理論基礎所推導而得，但若探究其相
對應訓練目標函式的最佳化過程，卻可以詮釋一種訓練
資料選取過程。也就是說為了讓聲學模型有較好的鑑別
性與一般化性(discrimination and generalization)而選取距
離決策邊際較近的訓練樣本作為訓練使用。舉例來說，
最大邊際隱藏式馬可夫模型估測 (large-margin hidden 
Markov model estimation, LME)[7]視每一語句整體為一
個訓練樣本，並且使用一個鑑別式函式去選擇落於預先
定義邊際範圍內之正樣本(positive samples)作為聲學模型
訓練使用。另一方面，柔性邊際估測 (soft margin 
estimation, SME)[8][9]推導出音框和語句層次的資料選
取。為此，先進行訓練語句的正確詞序列與語音辨識所
得辨識(假設)詞序列間之比對，以確認出一組候選的音
框樣本；接著，從所選出來的這些音框中，以正確與相
競爭聲學模型之間的平均音框層次對數相似度比率(log-
likelihood ratios)來施行語句層次資料選取。這兩種方法
尚未能直接與一般常用於大詞彙連續語音辨識的鑑別式
訓練演算法(諸如 MMI 與 MPE)作結合(或實作)。  
從本質上來看，目前流行的鑑別式訓練方法，諸如
MCE、MMI 與 MPE，其實已經隱含著某種語句層次(如
MCE 和 MMI)或是音素層次(MPE)的訓練資料選取機制。
更精確的說，對於 MMI 而言，若一訓練語句其正確(參
考)詞序列有較高事後機率時，則此一訓練語句對於訓練
目標函式最佳化過程的貢獻將較為減少。反之，若一訓
練語句其正確(參考)詞序列有較低事後機率時(換言之，
即是一句容易辨識錯誤的訓練語句時)，其在訓練目標函
式最佳化過程將會扮演著較為重要的角色[3]。另一方面，
藉由 S 型函數(sigmoid function)的使用，MCE 強調了那
些訓練語句其損失函式(loss function)的值是介於兩個極
值(如 0 和 1)之間的中間值，並且淡化那些損失函式值
太高(很像是異常樣本)或太低(幾近可以被完全正確辨識)
的訓練語句[1, 12]對於聲學模型訓練的貢獻。再者，
MPE 簡單地忽略每一訓練語句的詞圖上某些音素段落，
當這些音素段落的期望詞序列之音素正確率(指通過某一
音素段落的所有詞序列的平均音素正確率)與整個詞圖所
有詞序列的平均音素正確率是相等時[6]。 
在此三年期的研究計畫，我們總共研究了三種不同
的訓練資料選取方法，以用於大詞彙連續語音辨識器
(LVCSR)之鑑別式聲學模型訓練上。其目的在於降低聲
學模型訓練時所需耗費的時間，同時又可以得到一個較
具鑑別力的聲學模型。首先，利用每一句訓練語句對應
的詞圖(word lattice)上所有候選詞序列的平均音素正確
率來進行語句層次(utterance-level)的資料選取。其次，
我們提出使用詞圖上每一個音素段落(phone arc)的期望
正確率與詞圖上所有音素段落的平均正確率差值來作為
音素層次(phone-level)資料選取的依據。最後，發展基
於從詞圖中求出的正規化音框層次高斯事後機率的熵值
(normalized frame-level entropy of Gaussian posterior 
probabilities)的音框層次(frame-level)資料選取方法。 
本研究計畫報告書之後撰寫的架構如下：第二節將
介紹本研究計畫所實作發展出的兩種可應用於大詞彙連
續語音辨的鑑別式聲學模型訓練方法。第三節將簡單地
介紹以邊際為基礎的鑑別式聲學模型訓練方法。第四節
將詳細地闡述我們所提出資料選取方法。在第五節與第
六節說明實驗設定與其對應的實驗結果，最後，第七節
總結研究計畫並與提出未來展望。 
2. 鑑別式聲學模型訓練 
2.1. 最大化交互資訊估測法 (MMI) 
MMI 被視為 ML 以外最具代表性的聲學模型訓練方法之
一，是首次在小詞彙語音辨識的聲學模型訓練議題上被
提出[3]，MMI 的主要訓練目標是希望在給定每一語句
的語音特徵向量序列後，其對應的正確(參考)詞序列發
生的事後機率能越大越好。以數學符號來表示，則是在
給定一組含有 K 句語句的訓練集的對應語音特徵向量序
列集合 { }Kk OOOO  ,.., ,..,1= 後，以 MMI 為基礎聲學模型訓
練可以被視為是最大化下列目標函式： 
∑ ∑
∑
=
∈′
=
⎟⎟
⎟
⎠
⎞
⎜⎜
⎜
⎝
⎛
′′=
=
K
k
W k
kkk
K
k kkMMI
k
WPWOP
WPWOP
OWPF
1
1
)()|(
)()|(log               
)|(log)(
W λλ
λλ
λλ
 (2.1) 
其中， λ表示為我們所需要估測的參數; kW 表示語句 k的
語音特徵向量序列 kO 所對應的正確詞序列; ( )kk OWP |λ 是
給定 kO 後， kW 發生的事後機率; W′是在 kO 的詞圖 kW 所
有可能詞序列中的某一條[14]; ( )kk WOP |λ 是正確詞序列
kW 產生語音特徵向量序列 kO 的可能性， ( )kWPλ 是 kW 的
語言模型機率。圖 1 為一個詞圖的範例，在詞圖中含有
語音辨識產生之可能的候選詞序列。值得注意的是對於
每一句訓練語料，式(2.1)的最佳化不只要求最大化分子
項 ( ) ( )kkk WPWOP λλ | (這等同於 ML 聲學訓練)，並且同時
 
圖 1：為一個詞圖的範例，在詞圖中含有語音辨識所
有可能產生的候選詞序列。 
隱藏
飛蛾
(flying moth)
一群 影響
生命
疫情
(epidemic situation)
影響
(influence)
影響
生命
(life)
生活
SIL
SIL
(silence)
肺炎
(pneumonic)
疫情
一群
(a flock of)
隱藏
(hide)
疫情
疫情
生活
(living)
SIL
T
t10 t3
t2
肺炎
t3
t4
t5
t6
t6
t7
t8
t9
t11
t12
t10
4 
 
⎥⎥
⎥
⎦
⎤
∑
∑ ′′
∑
∑ ′
−
⎢⎢
⎢
⎣
⎡
∑
∑ ′′
∑ ′′
∑ ′′′
∑
=∂
∂
∈
′∈∈′
∈
∈
∈
′∈∈′
′∈∈′
′∈∈′
=
k
k
k
k
k
k
k
k
u
k
uqu
k
u
k
v
k
u
k
uqu
k
uqu
k
vqv
k
k
k
MPE
uPuOp
uPuOp
uPuOp
vRawAccvPvOp
uPuOp
uPuOp
uPuOp
vRawAccvPvOp
qOp
F
W
W
W
W
W
W
W
W
)()|(
)()|(
)()|(
)()()|(
)()|(
)()|(
)()|(
)()()|(
)|(log
)(
,
,
,
,
λ
λ
λ
λ
λ
λ
λ
λ
λλλ
λ
  (2.12) 
其中 k
q
u
k
uqu
k
k
k
uPuOp
uPuOp
γ
λ
λ =∑
∑ ′′
∈
′∈∈′
W
W
)()|(
)()|(
, ，
∑ ′′
∑ ′′′
′∈∈′
′∈∈′
uqu
k
vqv
k
k
k
uPuOp
vRawAccvPvOp
,
,
)()|(
)()()|(
W
W
λ
λ
為在詞圖 kW 中所有經過音素 q 的候選詞序列相對語句 k
的 正 確 轉 寫 之 期 望 正 確 率 ， 記 作 )(qck ，
∑
∑
∈
∈
k
k
u
k
v
k
uPuOp
vRawAccvPvOp
W
W
)()|(
)()()|(
λ
λ 為在詞圖 kW 中所有候選詞序
列相對於語句 k 的正確轉寫之期望正確率，記作 kavgc 。
即式(2.12)可表示成： 
( )kavgkkq
k
MPEMPEk
q cqcqOp
F −=∂
∂=
=
)(
)|(log
)( γλγ
λλλ
  (2.13) 
)(qck 與 kavgc 此二者統計量可在詞圖上使用波氏重估演
算法(extended Baum-Welch re-estimation, EBW) [17]來求
得，請參見圖 2 及圖 3。其中 )(qAcc 為音素段落 q 之正
確率，可表示成： 
⎭⎬
⎫
⎩⎨
⎧
+−
+−=
∈ 其他
為相同的音素跟
),(1
 ),(21
max)(
zqe
qzifzqe
qAcc
kWz
 (2.14) 
之長度音素
之重疊長度與音素
  
    ),(
z
zqzqe =    (2.15) 
其中為語句 k 的正確轉寫(詞序列)
 
kW 。最後詞圖 kW 中
某一候選詞序列W 的原始音素正確率可表示成[6]： 
∑=
∈Wq
qAccWRawAcc )()(    (2.16) 
另外，圖 4 上述說明 )(qc 與 avgc 計算方式，假設辨識後
之詞圖包含兩條語句「去-打滑-才-都」與「其他-好在
-都」，其事後機率分別為 0.7 與 0.3。每段詞分枝之正
確率如圖中所示，如「去」之正確率，Acc(去)=-1.1；
「都」之正確率，Acc(都)=0.75 等等。「去-打滑-才-
 
圖 2：最小化音素錯誤訓練法則中之前向演算法。 圖 3：最小化音素錯誤訓練法則中之後向演算法，
並求其 )(qc 與 avgc 統計量。 
for  t=T-2 to 0 
for 結束時間為 t 的音素 q  
0=qβ  
0=tmp  
for 開始時間為 t+1 且可連至 q 的音素 r  
      )|()|( rOpqrprqq βββ +=  
      )|()|( rOpqrptmptmp rβ+=  
 end 
 0=qβ  
 for 開始時間為 t+1 且可連至 q的音素 r  
( ))()|()|( rAcc
tmp
rOpqrp
r
r
qq +′⋅+′=′ ββββ  
end 
end 
end 
∑
∑ ′=
−
−
qT q
qT qq
avgc
的音素分枝所有結束時間為
的音素分枝所有結束時間為
1
1
α
αα
 
for 每一音素 q  
 qqqc βα ′+′=)(  
end 
 
for 開始時間為 0 的音素 q  
 )(qAccq =′α  
 )|( qOpq =α  
end 
for t=1 to T-1 
 for 開始時間為 t 的音素 q  
     0=qα  
   0=tmp  
      for 結束時間為 t-1 且可連至 q 的音素 r  
  )|( rqprqq ααα +=  
  )|( rqptmptmp rα+=  
      end 
     )(qAccq =′α  
     for 結束時間為 t-1 且可連至 q 的音素 r  
  
r
r
qq tmp
rqp αααα ′⋅+′=′ )|(  
   end 
    )|( qOpqq ⋅=αα  
 end 
end 
6 
 
)( kavg
k
q
k
q
k
q cc
MPE −= γγ     (2.28) 
其中 hqq k =∈ ,W 表示為音素段落 q 屬於詞圖 kW  而與實體 HMM h 有關聯; kavgc 是詞圖上所有詞序列的平均期
望音素正確率; kqc 是詞圖中所有詞序列包含音素段落 q 期
望音素正確率; ( )dot 是在音框 t 的語音特徵向量 )(tok 的
第 d 維度; qs 和 qe 表是為音素段落 q 開始與結束時間;
k
qγ 為語句 k 中音素段落 q 的事後機率; )(tkqmγ 是第 k 句
音素段落 q 的高斯 m 在第 t 個音框的事後機率 ; numhmγ ,( )Onumhmdθ 和 ( )2Onumhmdθ 是從那些實際對應 HMM h 音素段落
q 中蒐集 HMM h 混和成分 m 的訓練統計值且 kqc 大於
k
avgc ,而同樣的 denhmγ , ( )Odenhmdθ ( )2Odenhmdθ 是從那些實際對應
HMM h 音素段落 q 中蒐集 HMM h 混和成分 m 的訓練
統計值且 kqc 小於 kavgc ; hmdμ 和 2hmdσ 是平均數與變異數各自
在前一次遞迴中被估測;而 D 是一個常數被用來確保變
異數為正值。另一方面， kavgc  與
k
qc 的計算是基於於詞圖
中音素段落的音素正確率，如式(2.14)、圖 3和圖 4 所示。
我們可以從式(2.24)至式(2.28)觀察出，在 MPE 聲學模
型訓練中，每一句訓練語句的詞圖上那些音素段落有原
始音素正確率高於平均可以提供正貢獻；相反的，正確
率低於平均可以提供負貢獻。另一方面，在詞圖上那些
期望正確率等於所有詞序列的平均正確率的音素段落將
會被忽略。 
I-平滑(I-Smoothing)技術[5]同樣是為輔助函數引入
平滑函數 )(λsmoothIg − ，但此平滑函數是以最大化相似度
估測之統計資訊作為超參數(Hyperparameters)，故此函
數 )(λsmoothIg − 可定義為 [6]：  
⎥⎥
⎥
⎦
⎤
⎟⎟
⎟
⎠
⎞
⎜⎜
⎜
⎝
⎛
Σ⎟⎟⎠
⎞
⎜⎜⎝
⎛
⎟⎟⎠
⎞
⎜⎜⎝
⎛−+
⎢⎣
⎡ −Σ−+Σ∑−=
−
−−
1
22
1
)()(
)
)(
()
)(
(|)log(|
2
)(
hmML
hm
ML
hm
ML
hm
ML
hm
ML
hm
ML
hm
hmhm
T
ML
hm
ML
hm
hmhm
hm
hmsmoothI
OO
tr
OO
g
γ
θ
γ
θ
γ
θμγ
θμτλ
 (2.28) 
其中 hmτ 是一個高斯分布層次的平滑係數，表示要由最
大化相似度統計資訊加入的資料點數，因此 MPE 正貢
獻的統計資訊要修改為[5]： 
hm
num
hm
num
hm τγγ +=′     (2.29) 
)()()( OOO MLhmdML
hmd
mnum
hmd
num
hmd θγ
τθθ +=′    (2.30) 
)()()( 222 OOO MLhmdML
hmd
hmnum
hmd
num
hmd θγ
τθθ +=′   (2.31) 
其中 
)(tMLkhm
t
k
ML
hm γγ ∑∑=     (2.32) 
)()()( totO k
MLk
hm
t
k
ML
hm γθ ∑∑=    (2.33) 
T
kk
MLk
hm
t
k
ML
hm tototO )()()()(
2 γθ ∑∑=   (2.34) 
)(tMLkmγ 表示在第 k 句訓練語句音框 t 時，以最大化相似
度法則所估測之 HMM h 混和成分m的佔有機率。在我
們的學習研究中，我們透過實驗得到訓練語料語句
2.41%音素段落(有關實驗語料的資訊，請參見第 5.2 節)
被傳統的 MPE 聲學模型訓練訓練所篩除。有興趣的讀
者可參閱相關延伸研究[6]。 
3.以邊際為基礎的鑑別式訓練方法 
以邊際資訊為基礎的分類器，在機器學習領域中已經成
功地被驗證可以有效地幫助分類。這也使得以邊際為基
礎的聲學模型訓練方法成為一股新的趨勢，被應用於語
音辨識議題中，如最大邊際估測法則與柔性邊際估測法
則。 
3.1. 最大邊際(Large-Margin)估測法則 
根據統計學習理論[13]，我們得知分類器一般化錯誤率
的上界與其所包含邊際有關。而以最大邊際作為原則的
分類器，即是要最大化最小邊際。啟蒙於最大邊際分類
器，在語音辨識議題中，最大邊際估測法則的主旨在於
藉由調整隱藏式馬可夫模型的參數來最大化語音辨識器
的邊際，使得在訓練集中屬於正邊際的訓練語句能讓語
音辨識器於一般化能力上可以獲得提升。 
一般在語音辨識過程中，在給定一測試語句的對應
語音特徵向量序列O ，常用的以最大事後機率(MAP)為
辨識解碼準則可表示成： 
( ) ( )WOpWPW
W
λW∈= maxarg
ˆ    (3.1) 
其中我們假定語言模型機率 ( )WP 為已經先給定，因此我
們以 ( )WOpλ 作為邊際評估的標準，亦即將其視作為一
鑑別式函式。而在聲學模型訓練時，訓練的主旨便在於
最大化給定某個訓練語音特徵向量序列 kO 其正確對應
的詞序列 kW 的相似度(Likelihood)。基於此，最大邊際
估測法中，其分離邊際(Separation Margin)定義為[7]： 
[ ])|()|(min               
)|(max)|(      )(
 ,
,
ikkkWWW
ikWWWkkk
WOpWOp
WOpWOpOd
kii
kii
λλ
λλλ
−=
−=
≠∈
≠∈
W
W  (3.2) 
其中 W為所有可能候選詞序列所成的集合； )|( kk WOp
為訓練語句 k 的正確詞序列 kW 對應之聲學模型產生訓
練語句 k 的語音特徵向量序列 kO 之相似度； iW 為語音
8 
 
order cone programming)[23]被用來改善LME 訓練速度。 
而針對一個分類器來說，LME 所強調的訓練重點為
那些標記正確的訓練樣本。那些不滿足 LME 限制條件
(即分類錯誤)的訓練樣本被 LME 排除訓練之外，但是所
衍生的問題是這些訓練樣本對分類器而言也是關鍵的。
其次，在經最大邊際估測法則的模型訓練後，訓練樣本
的分離邊際變大且可容錯的能力也變大，代表模型更具
有一般化能力。然而，實際上的語音辨識器多半其實是
無法分割訓練樣本的分類器(也就是說辨識器對於訓練資
料的辨識率尚未達到完美)，尤其是當最大邊際估測法則
應用於大詞彙連續語音辨識任務上時。這會造成存在於
支持向量集合內的樣本個數非常有限，導致在調整過後
的聲學模型對提升整體辨識率的影響不大。因此，有柔
性之最大邊際估測法則(soft-large margin estimation, Soft-
LME)被提出來改善此一問題[24]，同時將所有分類正確
與錯誤的訓練語句全部納入考量，並使用半正定規劃法
加以最佳化。 
3.2. 柔性邊際(Soft-Margin)估測法則 
有鑑於前述最大邊際估測法則會因忽略訓練樣本而造成
決定邊際附近訓練資訊的遺失(也就是一昧地以最大化分
類邊際使得所訓練出來的分類器，其一般化的能力不足)，
因此以柔性邊際為訓練法則[9]被提出，分類器於測試集
的分類錯誤已被證明在一定的機率之上，會受限於一個
上界 (Upper Bound)，而此上界為分類器的經驗風險
(Empirical Risk)加上另一項一般化量值(Generalization (or 
Regularization) Term)，表示如下: 
))
4
log()1)2(log((1)()(
dim
dim
δλλ −++≤
VC
NVC
N
RR emp  (3.10) 
其中 )(λR 是分類器 λ 的分類錯誤， )(λempR 為經驗風險，
根號內乃是一個有關分類器之 VC 維度 (Vapnik-
Chervonenkis(VC) dimension)，用以衡量一分類器的複
雜度)的函數[25]。因此，欲加強語音辨識器在測試語料
上的辨識率，除了要最大化此語音辨識器的邊際外，更
要降低其在訓練語料上的經驗風險。將這兩個不同面的
考量整合在一起，於是柔性邊際估測法則的目標函數可
表示為[8]： 
∑+=
=
K
k
k
SME Ol
K
L
1
),(1)( λρ
ηλ    (3.11) 
其中 λ 為隱藏式馬可夫模型的參數； ρ 為柔性邊(soft 
margin)；η為一常數，用來平衡柔性邊際的最大化與經
驗風險的最小化，顯而易見地，當η越小則越懲罰此分
類器的經驗風險； K 為所有的訓練語句； ),( λkOl 為一
語句 kO 的減損函數。因此，柔性邊際估測法則便藉由
最小化此目標函數來降低辨識器於測試語料上的分類錯
誤。與傳統鑑別式聲學模型訓練最大的不同是，鑑別式
訓練只專注於經驗風險(即為 ∑
=
K
k
kOlK 1
),(1 λ )的最小化，而
忽略一般化量值(以 ρ
η 來近似)。然而在最大邊際估測法
則中，卻只把重點放在加大邊際以降低一般化量值，而
忽略了經驗風險的影響[24]。 
柔性邊際估測法則中的減損函數 ),( λOl 是一項影響
整體訓練的重要元件，其設計必須跟其目標：提高分類
器之邊際，有一定的關連性。故定義為： 
( )( ) ( )UOIOdOl kkSMEk ∈−= λρλ ,),(    (3.12) 
其中 ( )•I 為一個指示函數(indicator function)；U 為所有
訓練語句的子集合，其定義為 
( ){ }0, >−= λρ kSMEk OdOU    (3.13) 
而 ( )λ,kSME Od 為 kO 的分離估量(separation measure)，用
以衡量其正確轉寫詞序列與對應之最為競爭 (most 
competitive)詞序列在聲學分數上的差距，定義為： 
( )
( ) ( ) )()|(
)|(log1)(
 ,
kk
t ckk
kk
k
k
SME FtoI
Wtop
Wtop
n
Od ∈∑ ⎥⎥⎦
⎤
⎢⎢⎣
⎡=
λ
λ  (3.14) 
其中 kW 為 kO 的正確轉寫詞序列、 ckW  , 為所有候選詞序
列中相似度最大的一句，其擁有對正確詞序列最大的競
爭力(就以最大事後機率解碼原則而言)； kF 是 kW 與
ckW  , 之所有含不同音素類別(Phone Label)標記的不同時
間音框 t 所構成之集合； kn 為 kF 的元素個數；( ) )|( kk Wtopλ 與 ( ) )|(  , ckk Wtopλ 分別為語音特徵向量 kto
在 kW 和 ckW  , 上的相似度(於目前的聲學模型λ上所估測
求得)。因此，只有其分離估量小於 ρ 的訓練語句才會
被納入於目標函數內(意謂著錯很多的訓練語句也會被
納入考量)，而對於那些分離估量遠大於 ρ 的訓練語句
(換句話說，即是容易被分類正確)，被視為不存在分類
風險，對於模型參數的估測沒有影響，所以不納入考量。
以一個非線性且不可分割的二元分類器來加以說明，如
圖 6 所示。在決定邊界兩側的虛線到決定邊界的距離即
為邊際 ρ ，針對每一個訓練樣本(其中□代表＂+＂類別，
○代表＂-＂類別)，其與決定邊界的距離即為分離估量，
當此分離估量小於邊際 ρ 時(實心的樣本圖例)，便會被
選入於集合U ，不管其是否被分類器給正確分類。 
故將式(3.13)、(3.14)整合於式(3.12)，則柔性邊際估
測法則的目標函數可表示為： 
10 
 
而加總所有時間音框的音框層次減損函數即為最終的減
損函數： 
( ) ( ) ( )( ) ( ){ }∑ ∈−=∑=
t
kktkt
t
ktk FoIodolOl λρλλ ,,,  (3.22) 
將式(3.18)與式(3.22)取代原本目標函數中的減損函數，
則可將柔性邊際估測法則應用於大詞彙連續語音辨識系
統之聲學模型訓練上，並可使用延伸波式重估演算法進
行最佳化[27]。 
在本小節所有上述的減損函數中，皆一致的認為當
訓練語句的分離估量小於預先定義的柔性邊際 ρ ，即對
於模型參數調整能有貢獻。但，當一訓練語句其分離估
量非常小(遠小於零)時，它其實可能是一個異常訓練樣
本(Outlier)，對於整個訓練過程無法提供任何幫助。因
此，可藉由引進一個其值為負的參數τ 將之過濾，則語
句層次的減損函數可定義為[27]： 
( ) ( ) ( )
⎩⎨
⎧ >>−=
otherwise                             ,0
, if  ,,
,
__ τλρλρλ k
USME
k
USME
k
OdOd
Ol  (3.23) 
而音框層次減損函數可定義為： 
( ) ( )( ) ( )( )⎪⎩
⎪⎨⎧ >>−==
otherwise                             ,0
 if  ,,
,
_ τρλρλ toWptodol kkk
FSME
zt  (3.24) 
4. 本研究所提出之訓練資料選取方法 
4.1. 語句選取 (Utterance Selection) 
在過去的研究中已經有學者提出了基於對數可能相似度
比例來做為訓練語句選取的依據，如[27, 28]。在本研究
中，我們提出了一個變通方法嘗試在 MPE 訓練中直接
以音素正確率的值域範圍作為訓練語句選取標準。一句
訓練語句 k 的詞圖(辨識產生的結果、假定的空間) kW提供給訓練目標函式詞圖上競爭的資訊在鑑別式訓練中
扮演重要的角色。我們的方法能幫助過篩除詞圖中缺乏
鑑別資訊的訓練語句。舉例來說，在 MPE 訓練中，由
平均音素正確率 kavgc 除以訓練語句 k 正確轉譯答案音素
的個數得到每句訓練語句 k 的正規化平均音素正確率 
k
avgcˆ ，可以顯露出假定空間詞圖 kW 上某種混淆的程度
[29]。擁有太高正規化平均音素正確率的語句代表著它
(或它產生的假定空間)提供較少的競爭資訊，而有太低
的正規化平均音素正確率代表著它可能是一個損害嚴重
的訓練樣本(或是一個例外)因此排除它。受到此研究啟
發，我們引導出基於正規化平均音素正確率 kavgcˆ 的訓練
語句選取。 
 
我們首先估測所有訓練語句 kavgcˆ 的平均值，記作
avgcˆ ，然後配合 kavgcˆ 選取落在由下列式子所定義值域區
間的訓練語句來作 MPE 訓練： 
δδ +≤≤− avgkavgavg ccc ˆˆˆ    (4.1) 
其中δ 為預先定義的門檻值。在這裡值得一提的是像這
樣資料選取方法是基於音素正確率範圍(或同樣意思的，
音素錯誤率範圍)上去選擇較具鑑別性的語句，這和
LME、SME 是基於對數相似度比例範圍(log-likelihood 
ratio)上選取訓練語句[7, 8, 27, 28]，有明顯的區別。 
4.2. 音素段落選取 (Phone Arc Selection) 
從整體來看，使用一個句子作為訓練資料選取的基本單
位是有些粗糙的。因此，我們也提出了在 MPE 訓練上
以音素正確率範圍領域音素層級的資料選取方法。就我
們所知，在 MPE 訓練中，平均音素正確率 kavgc  被視為蒐集音素段落 q的訓練統計值到分子項或分母項的決定
邊際，描述如式子(2.23)至(2.27)。因此，我們為了選出
那些較關鍵的音素段落採用邊際 kavgc ，而那些音素段落
藉由錯誤率選出靠近決定邊際 [29]。最後，在 HMM h
上 MPE 訓練最後的輔助函數可以被定義為： 
( ) ( )[ ]
( ) ( )( )qmqmkkqm
K
k
hqq
e
st m
kk
q
k
avg
k
q
k
qMPE
tONt
AcIcchg
k
q
q
Σ×
∑∑ ∑∑ ∈−=
= =∈ =
,,log                 
)(
1
,
μγ
γW    (4.2) 
( ){ }βκα ≤−≤−= kavgkqkqk cccA    (4.3) 
其中 )(•N 為高斯分布; )(•I 是一個克羅內克函數
(Kronecker Delta Function)，當 kkq Ac ∈ 時，回傳值 1;其
他為零：正參數α 和 β 所構成邊際用來實作訓練資料的
選取;κ 是一正規化因子使得 ( )kavgkq cc −κ  範圍逼近於-1
至 1 間; kA 是落在邊際 [ ]βα  ,− 間的音素段落集合，邊際
以音素正確率作為定義的範圍。只有那些在 kA 的音素
段落貢獻他們蒐集到的統計值會對 MPE 訓練產生影響。 
圖 7 說明了我們所提出的音素段落選取的例子。在
圖中，每一條藍色線代表某一句訓練語句產生詞圖中的
 
 
圖 7：一個說明音素層級資料選取方法的範例。 
12 
 
音辨識的實驗被均分為兩部分。第一部份作為發展集被
使用來調整訓練設定參數。第二部分為測試集(或評估
集)即所有的語音辨識實驗配合由發展集所得最佳化設
定後聲學模型實作在此測試集上。因此，在接下來章節
研究所呈現的實驗結果能證實我們所提出方法在現實生
活資料上的有效性，另一方面，這裡被選來作語音辨識
實驗的聲學模型由 112 個右音相關 (right-context-
dependent)聲母和 38 個音獨立(context independent)韻母。
他們被選定為中文音節的基本聲學結構。這裡，聲母
(INITIAL)表示為音節的初始子音而韻母(FINAL)是母音
(或雙母音)部分但也包含一個可選擇中間的或鼻音的結
尾。每個聲母由一個含有 3 個狀態的 HMM 表示而每個
韻母由 4 個狀態所表示。每個狀態的高斯混和個數範圍
為 2 至 128 個，視訓練資料的數量而定。 
聲學模型在最佳化後的設定下以最大化相似度 ML
法則也就是波式訓練演算法訓練而成。以 MMI 與 MPE
為基礎的鑑別式訓練方法使用於 ML 訓練過的聲學模型。
單連詞語言模型的限制在鑑別式訓練時被用來從詞圖中
蒐集統計資訊。對 MPE 訓練來說，靜音(silence)與短間
歇(short pauses)標記都被納入作為假定空間(hypothesis 
space)上詞序列的正確率計算。 
5.3. 詞典與 N 連詞序列語言模型 
首先，辨識用詞典包含六萬七千詞。使用前後二連詞統
計資訊[35]自動擷取大約五千字的複合字集合加入詞典
形成七萬兩千字的詞典。本研究所使用作為背景語言模
型由最大相似度所評估出包含二連詞和三連詞的語言模
型，是使用 ML 準則估測而成，使用中央新聞社(CNA)
在 2001 與 2002 年(the Chinese Gigaword Corpus released 
by LDC)[36]蒐集包含 1.7 億中文字的語料庫。在實作時，
我們使用 SRI 語言模型工具來訓練 N 連詞模型[37]。 
5.4. 語音辨識 
語音辨識器的實作由左至右的音框同步維特比複製樹搜
尋和一詞彙前序樹[38]。對每一個語音音框，光束剪裁
(Beam Pruning)技術，考量他們對應的單連詞語言模型
前看分數和音節層級的聲學模型前看分數所結合而成假
定路徑空間上解碼分數[32]，被用來選出最有可能的路
徑。並且，如果在每個語音音框的詞假定空間尾部的分
數比預定門檻值還高時，他們相關的解碼資訊，如詞的
開始和結尾音框、目前的詞和前一個詞的鑑別和聲學分
數，將被保留來建構詞圖作為更進一步的詞圖語言模型
重計分。我們使用雙連詞語言模型於搜尋樹而三連詞語
言模型於詞圖的重新計分(word graph rescoring)[14]。 
6. 實驗結果 
在本節我們將呈現一系列的實驗於測試集(參見 5.2 節)
中來評估我們所提出的訓練資料選取方法及其結合之效
能。其中聲學模型由發展集所調整出來的基礎設定訓練
而成。由於在中文語言裡，並沒有使用特別明確的標記
符號如空格或空白來分離詞彙，在中文語言使用時常遇
到詞斷詞的問題。因此，中文的語音辨識中效能評估經
圖 10：整合語句層級資料選取方法於 MPE 訓練字錯
誤率結果。 
圖 11：整合音素段落資料選取於 MPE 訓練所得到字
錯誤率結果。 
 
表 1：各自使用 MPE 與 MMI 訓練所達成的基礎實驗
字正確率結果。 
訓練次數 MPE MMI 
1 22.34 22.79 
2 21.72 22.57 
3 21.41 22.23 
4 21.23 22.06 
5 20.90 21.86 
6 20.67 21.69 
7 20.63 21.59 
8 20.63 21.48 
9 20.57 21.69 
10 20.46 21.58 
 
20.00
20.50
21.00
21.50
22.00
22.50
23.00
23.50
0 1 2 3 4 5 6 7 8 9 10
Iteration
CER(%)
MPE
MPE+US
MPE+USv
20.00
20.50
21.00
21.50
22.00
22.50
23.00
23.50
0 1 2 3 4 5 6 7 8 9 10
Iteration
CER(%)
MPE
MPE+PS
MPE+PSv
14 
 
6.4. 音框選取實驗結果 
在第三個實驗部分，我們評估音框層次訓練資料選取對
於 MMI 與 MPE 訓練效能的影響(各自記作 MMI+FS 與
MPE+FS，對應的結果如圖 12 與圖 13 所示。在這裡，
用於音框層級正規化熵值為主的資料選取的門檻值Thr
是設為 0.05(如前面 4.3 節所描述)。因此，最後被使用
來訓練的音框樣本大約四百萬(佔所有訓練音框樣本的
45%)。因為聲學模型在每次訓練後都會被更新，使得每
一個語音音框的熵值每一次訓練都不同於前一次訓練，
導致 MMI 與 MPE 所選取的音框樣本數會隨訓練次數有
些許不同。如圖 12 圖 13 所示，當聲學模型在剛開進行
訓練時，加入音框層次訓練資料選取 (MMI+FS 與
MPE+FS)可以明顯地增進聲學模型的語音辨識效能。這
意味著音框層次訓練資料選取不僅可以幫助減少在訓練
時花費的時間，並且可以同時維持與傳統 MMI 和 MPE
具有同樣的語音辨識效能。 
然而，當聲學模型在訓練次數多(如第 9 和 10 次訓
練)時，音框層次訓練資料選取(MMI+FS 與 MPE+FS)的
語音辨識效能各自都較傳統 MMI 與 MPE 的語音辨識效
能來的差。可能的理由是因為在某種程度上，這種資料
選取方法會遭遇到資料稀疏的問題，使得聲學模型過度
訓練，特別是當使用較多訓練次數時。因此，我們不只
試圖應用音框層級資料選取於 MMI 和 MPE 訓練，並且
同時隨著訓練次數增加緩緩減少門檻值 Thr (各自記作
MMI+FSv 與 MPE+FSv)。這樣一來，將可隨訓練次數的
增加逐漸地獲得較多的訓練資料，而減緩過度訓練的問
題。MMI+FSv 與 MPE+FSv 對應的結果各自如圖 12 與
13 所描述。在較多訓練次數時，修正過的音框層次訓練
資料選取(特別是 MMI+FSv)的辨識效能的減少，可以得
到了某種程度的補償。 
另一方面，我們額外加了亂數的選取於 MPE 訓練
中(記作 MPE+R)。在每次的訓練中，亂數選取了所有音
框層次訓練樣本的 45%做為 MPE 訓練使用，其相對應
的實驗結果如圖 13 所示。由此，可以看出我們所提出
音框層次訓練資料選取的能力的確與藉由亂數選取來的
好許多，再次驗證我們所提出方法之可行性。 
6.5 結合不同層次訓練資料選取方法 
最後，我們研究不同種資料選取的結合方法於 MPE 聲
學模型訓練。我們根據考慮訓練樣本的細緻程度，由較
大單位往較小單位向下實作資料選取：依次是語句層次、
音素層次和音框層次。其對應的結果如圖 14 所示。可
以發現的是，相對於單獨的音素層次訓練資料選取
(MPE+PSv)或是音框層次訓練資料選取(MPE+FSv)，音
素層次與音框層次的結合(MPE+PSv+FSv)可以提供較好
效能的增進。而在十次的訓練次數中，MPE+PSv+FSv
不僅優於傳統 MPE，而且使的聲學模型的訓練相較於傳
統 MPE 提早於第五次訓練獲得收斂。值得注意的是我
們所有的實驗是在一般的個人電腦上執行，每一次訓練
將耗時超過一天(≧24 小時)才能完成一次 MPE 訓練。
這意味著透過我們訓練資料選取方法(MPE+PSv+FSv) 幫
助，我們能減少超過百分之五十聲學模型的訓練時間(超
過五天)，同時又能得到一組一樣好的鑑別式聲學模型。 
然而，當我們更進一步的整合了語句層次與音素層
次的訓練資料選取 (MPE+USv+PSv) 或是音框層級 
(MPE+USv+FSv)或者結合全部不同層次的訓練資料選取
(MPE+USv+PSv+FSv)，可以發現這些嘗試事實上較音
素層次訓練資料選取(MPE+PSv)或音框層次訓練資料選
取(MPE+FSv)或音素與音框層次訓練資料選取的結合 
(MPE+PSv+FSv)並不能帶來額外的效能增進。可能的解
釋是：當語句層次訓練資料選取和其他兩種層次訓練資
料選取來作比較時，語句層次訓練資料選取是相對粗糙
的。 
以上的結果的確證明了我們的假設，也就是藉由適
當地整合各種不同層次訓練資料選取於聲學模型訓練中，
我們將可使得鑑別式訓練的演算法更專注於有用的訓練
樣本，並能夠在新的測試集中，達到一個較好的語音辨
識效能。 
7. 結語 
在本三年期計畫執行期間，我們除了成功地建立起中文
大詞彙連續語音辨識系統與一些鑑別式聲學模型訓練方
法外，亦進一步地提出了三種嶄新的訓練資料選取
(training data selection)方法來改進鑑別式聲學模型訓練
之效能。首先，利用每一句訓練語句對應的詞圖(word 
lattice)上所有候選詞序列的平均音素正確率來進行語句
層次(utterance-level)的資料選取。其次，我們提出使用
詞圖上每一個音素段落(phone arc)的期望正確率與詞圖
上所有音素段落的平均正確率差值來作為音素層次
(phone-level)資料選取的依據。最後，發展基於從詞圖
中求出的正規化音框層次高斯事後機率的熵值
(normalized frame-level entropy of Gaussian posterior 
probabilities)的音框層次(frame-level)資料選取方法。實
驗的結果說明了音素與音框層次的訓練資料選取可以減
 
 
圖 14：整合不同層級結合方法於 MPE 訓練的字錯誤率
結果。 
20.00
20.50
21.00
21.50
22.00
22.50
23.00
23.50
0 1 2 3 4 5 6 7 8 9 10
Iteration
CER(%)
MPE
MPE+USv+PSv
MPE+USv+FSv
MPE+PSv+FSv
MPE+USv+PSv+FSv
16 
 
Automatic Speech Recognition and Understanding, 
pp.284-289, 2007. 
[30] S.H. Liu, F.H. Chu, S.H. Lin, H.S. Lee, B. Chen, 
“Investigating data selection for minimum phone error 
training of acoustic models,” in Proc. IEEE International 
Conference on Multimedia & Expo, pp. 348-351, 2007. 
[31] H. Misra, and H. Bourlard, Spectral entropy feature in 
full-combination multi-stream for robust ASR,” in Proc. 
the Annual Conference of the International Speech 
Communication Association, pp. 2633-2636, 2005. 
[32] B. Chen, J.W. Kuo, W.H. Tsai, “Lightly supervised 
and data-driven approaches to mandarin broadcast news 
transcription.” in Proc. IEEE Int. Conf. Acoustics, 
Speech, Signal Processing, pp. 777-780, 2004. 
[33] G. Saon, M. Padmanabhan, R. Gopinath, S. Chen, 
“Maximum likelihood discriminant feature spaces,” In: 
Proc. IEEE Int. Conf. Acoustics, Speech, Signal 
Processing, 2, pp. 1129–1132, 2000. 
[34] M. J.F. Gales, “Maximum likelihood multiple 
subspace projections for hidden Markov models,” IEEE 
Trans. on Speech and Audio Processing, vol. 10(2), 
pp.37-47, 2002. 
[35] G. Saon, M. Padmanabhan, “Data-driven approach to 
designing compound words for continuous speech 
recognition,” IEEE Trans. on Speech and Audio 
Processing, 9(4), pp. 327-332, 2001. 
[36] H.S. Chiu, and B. Chen, “Word topical mixture models 
for dynamic language model adaptation,” in Proc. IEEE 
Int. Conf. Acoustics, Speech, Signal Processing, pp.169-
172, 2007. 
[37] A.Stolcke. SRI language modeling toolkit. Version 
1.3.3, 2000. http://www.speech.sri.com/projects/srilm/. 
[38] X.L. Aubert, “An overview of decoding techniques for 
large vocabulary continuous speech recognition,” 
Computer Speech and Language, 16, pp. 89-114, 2002. 
[39] J.W. Kuo, S.H. Liu, H.M. Wang, B. Chen, “An 
empirical study of word error minimization approaches 
for mandarin large vocabulary speech recognition,” 
International Journal of Computational Linguistics and 
Chinese Language Processing, 11(3), pp. 201-222, 2006. 
[40] H.Y. Chan and P.C. Woodland, “Improving broadcast 
news transcription by lightly supervised discriminative 
training,” in Proc. IEEE Int. Conf. Acoustics, Speech, 
Signal Processing, pp.737-740, 2004. 
[41] L. Mathias, G. Yegnanarayanan, J, Fritsch, 
“Discriminative training of acoustic models applied to 
domains with unreliable transcripts,” in Proc. IEEE Int. 
Conf. Acoustics, Speech, Signal Processing, pp.109-112, 
2005. 
[42] H.M. Wang, B. Chen, J.W. Kuo, S.S. Cheng, 
“MATBN: a Mandarin Chinese broadcast news corpus.,” 
International Journal of Computational Linguistics & 
Chinese Language Processing, 10(1), pp. 219-235, 2005. 
 
18 
 
[14] Shih-Hsiang Lin, Yao-Ming Yeh, Berlin Chen, 
“Investigating the use of speech features and their 
corresponding distribution characteristics for robust 
speech recognition," the IEEE workshop on Automatic 
Speech Recognition and Understanding (ASRU 2007), 
pp. 87-92, Kyoto, Japan, December 9-13, 2007.  
[15] Yi-Ting Chen, Shih-Hsiang Lin, Hsin-Min Wang, 
Berlin Chen, “Spoken document summarization using 
relevant information,” the IEEE workshop on 
Automatic Speech Recognition and Understanding 
(ASRU 2007), pp. 189-194, Kyoto, Japan, December 9-
13, 2007.  
[16] Shih-Hsiang Lin, Yao-Ming Yeh, Berlin Chen, 
“Cluster-based polynomial-fit histogram equalization 
(CPHEQ) for robust speech recognition,” the 8th 
Annual Conference of the International Speech 
Communication Association (Interspeech 2007), pp. 
1054-1057, Antwerp, Belgium, August 27-31, 2007.  
[17] Yi-Ting Chen, Hsuan-Sheng Chiu, Hsin-Min Wang, 
Berlin Chen, “A unified probabilistic generative 
framework for extractive spoken document 
summarization,” the 8th Annual Conference of the 
International Speech Communication Association 
(Interspeech 2007), pp. 2805-2808, Antwerp, Belgium, 
August 27-31, 2007. 
[18] Yi-cheng Pan, Hung-lin Chang, Berlin Chen, Lin-shan 
Lee, “Subword-based position specific posterior 
lattices (S-PSPL) for indexing speech information,” the 
8th Annual Conference of the International Speech 
Communication Association (Interspeech 2007), pp. 
318-321, Antwerp, Belgium, August 27-31, 2007.  
[19] Berlin Chen, Yi-Ting Chen, "Word topical mixture 
models for extractive spoken document 
summarization," IEEE International Conference on 
Multimedia & Expo (ICME 2007), pp. 52-55, Beijing, 
China, July 2-5, 2007.  
[20] Shih-Hung Liu, Fang-Hui Chu, Shih-Hsiang Lin, Berlin 
Chen, "Investigating data selection for minimum phone 
error training of acoustic models," IEEE International 
Conference on Multimedia & Expo (ICME 2007), pp. 
348-351, Beijing, China, July 2-5, 2007.  
[21] Shih-Hsiang Lin, Shih-Hung Liu, Yao-Ming Yeh, 
Berlin Chen, "Improved histogram equalization (HEQ) 
for robust speech recognition," IEEE International 
Conference on Multimedia & Expo (ICME 2007), pp. 
2234-2237, Beijing, China, July 2-5, 2007.  
[22] Hsuan-Sheng Chiu, Berlin Chen, “Word topical mixture 
models for dynamic language model adaptation,” the 
32th IEEE International Conference on Acoustics, 
Speech, and Signal Processing (ICASSP 2007), Vol. IV, 
pp. 169-172, Hawaii, USA, April 15-20, 2007.  
[23] Jia-yu Chen, Chia-yu Wan, Yi Chen, Berlin Chen, Lin-
shan Lee, "Minimum phone error (MPE) model and 
feature training on mandarin broadcast news task," the 
5th International Symposium on Chinese Spoken 
Language Processing (ISCSLP 2006), Singapore, 
December 13-16, 2006. Lecture Notes in Artificial 
Intelligence, LNAI4274, 2006, Springer-Verlag, pp. 
270–281.  
[24] Tzan-Hwei Chen, Berlin Chen, Hsin-min Wang, "On 
using entropy information for improving posterior 
probability based confidence measures," the 5th 
International Symposium on Chinese Spoken 
Language Processing (ISCSLP 2006), Singapore, 
December 13-16, 2006. Lecture Notes in Artificial 
Intelligence, LNAI4274, 2006, Springer-Verlag, pp. 
454–463.  
[25] Yi-Ting Chen, Suhan Yu, Hsin-min Wang, Berlin Chen, 
"Extractive Chinese spoken document summarization 
using probabilistic ranking models," the 5th 
International Symposium on Chinese Spoken Language 
Processing (ISCSLP 2006), Singapore, December 13-
16, 2006. Lecture Notes in Artificial Intelligence, 
LNAI4274, 2006, Springer-Verlag, pp. 660–671. 
[26] Shih-Hsiang Lin, Yao-Ming Yeh, Berlin Chen, 
“Exploiting polynomial-fit histogram equalization and 
temporal average for robust speech recognition,” the 7th 
Annual Conference of the International Speech 
Communication Association (Interspeech 2006), 
Pittsburgh PA, USA, September 17-21, 2006. 
 
表 Y04 
 
 
 
計畫主持人的兩篇論文分別下列兩個 Oral Sessions中發表： 
L3 Spoken Language Systems (12月 18日上午 10:00至 12:00)  
L6 Speech Recognition (12月 19日下午 13:30至 15:30 ) 
透過與不同的研究者交流討論，對於所發表的兩篇論文我們發現了許多之前從未察覺的
思考方向，也啟發了一些新的想法。值得一提的，計畫主持人所指導的研究指導的李鴻
欣同學所發表的論文 “Improved Linear Discriminant Analysis Considering Empirical 
Pairwise Classification Error Rates”在眾多論文中脫穎而出，獲得最佳論文獎的榮耀。 
在會場中我們也遇到來來自台大(李琳山教授)、中研院(鄭秋豫教授、王新民教授)、成大
(王駿發、吳宗憲、簡仁宗教授)、交大(陳信宏、王逸如教授)的研究人員，我們也與其中
幾位聚在一起，暢談與會經驗。成大王駿發教授將代表台灣接下 2010年第六屆中文口
語語言處理國際研討會的主辦事宜。 
計畫主持人與研究生一行人於 12月 20日搭機返回台北，此次的出國開會與論文發
表任務算是圓滿達成。 
 
二、與會心得 
從這一次中文口語語言處理國際研討會中可以看得出峽兩岸四地(台灣、大陸、香
港、新加坡)的華人在語音處理研究上的確有相當程度進展，尤其大陸、香港、新加坡的
學者在近幾年都常出席語音相關國際研討會甚至擔任國際組織的重要職務，反觀台灣似
乎在這方面還需大家一同在努力！ 
總之，經由此次的與會，讓計畫主持人的研究視野不論是廣度與深度都開拓了不
少。相信對今後在台師大資工所從事的相關學術研究，定能帶來莫大的幫助。 
 
三、考察參觀活動　 無。 
 
四、攜回資料名稱及內容 
1. ISCSLP CDROM: 為一光碟，其包含了會議簡介、會程安排、及主要是會議中所
發表文章之全文。 
 
五、其他　無。 
 
 
2. RELATED WORK 
2.1. Mixture-based language model 
To capture the local word regularity and the global document 
style simultaneously, we can use the mixture-based language 
model [6]. For this model, the training corpus was separated 
into several groups according to the topics of documents. 
Moreover, a simple k-means clustering technique can be used 
to cluster the documents into different groups (topics) if the 
categorical labels of the training set are not clearly indicated. 
An n-gram language model is trained for each group and then 
a mixture-based language model is constructed with these n-
gram language models through a simple linear combination, 
i.e. 
( ) ( )¦
=
−−−−
=
K
1j
j1i2iij1i2iiMIX M,w,w|wPw,w|wP λ  (1) 
where K  is the number of groups (topics), jλ  is the weight 
for each model jM . During speech recognition, the set of 
weights K,,,j,Ȝj !21=  can be optimized using the history 
word sequences or the top scoring one, as well as the EM 
(Expectation-Maximization) algorithm. To avoid the data 
sparsity problem, the n-gram language model trained with a 
non-partitioned corpus can also be included as an additional 
mixture. Moreover, smoothing techniques like Good-Turing 
smoothing can be performed for each language model. 
2.2. Probabilistic latent semantic analysis 
PLSA is a general machine learning technique for modeling 
the co-occurrences of words and documents, and it evaluates 
the relevance between them through a low-dimensional factor 
space [8]. When PLSA is applied to language model 
adaptation in speech recognition, for a decoded word iw , we 
can interpret each of its corresponding search histories 
iw
H
as a history (or document) model 
iHw
M  used for predicting 
the occurrence probability of iw :( ) ( ) ( )¦
=
=
K
1k
HwkkiHiPLSA iiw
MTPTwPMwP  (2) 
where kT  is one of the latent topics and ( )ki TwP |  is the 
probability of the word iw occurring in kT . The latent topic 
distributions ( )ki TwP | can be estimated beforehand by 
maximizing the total log-likelihood of the training (or 
adaptation) text document collection. However, the search 
histories are not known in advance and their number could be 
enormous and varying during speech recognition. Thus, the 
corresponding PLSA model of a search history has to be 
estimated on the fly. For example, during the speech 
recognition process, we can keep the topic factors ( )ki TwP |
unchanged, but let the search history’s probability distribution 
over the latent topics ( )
iHwk
MTP |  be gradually updated as 
path extension is performed, by using the EM update formulas. 
Then, the probabilities of the PLSA and background n-gram 
(e.g., trigram) language models can be combined using a 
simple linear interpolation: 
( )
( ) ( ) ( )12
12
1
−−−
−−
⋅−+⋅= iiigramnwiPLSA
iiiAdapt
wwwPHwP
wwwP
i
αα
 (3) 
where α  is a tunable interpolation weight. 
3. POSITION INFORMATION FOR 
LANGUAGE MODELING 
3.1. Position information among documents 
In order to verify our belief of the usefulness of word position 
information, we try to analyze the word usage of a broadcast 
news corpus partitioned by the structure of documents. A left-
to-right HMM segmenter was trained and applied to separate 
every broadcast news document of the corpus into partitions. 
By using the HMM segmenter, each partition within a 
document is expected to be semantically cohesive. Table 1 
and Figure 1 show the style words with higher rank of 
multiplication of term frequency (TF) and inverse document 
frequency (IDF) scores and their probabilities on four 
partitions of the corpus, respectively. The detailed description 
of the corpus will be given in Section 4. According to Table 1 
and Figure 1, we can observe that the word usage with respect 
to different partitions (or positions) is apparently quite 
different. For the first partition (P1), most of the words are 
about introductory remarks, e.g., greetings, notices or 
conjunctives. For the second and third partitions (P2 and P3), 
most of the words are content words because the themes and 
events of documents are mostly described in the middle parts 
of a news report. For the final partition (P4), most of the 
words are actions, reporter names or TV station names. They 
signal an ending of the news report. Reporters usually make a 
short conclusion and a footnote about where the event took 
place. Moreover, the word probabilities are more specifically 
distributed for the final partition (P4), and some high-
frequency words at this partition will have zero probabilities 
at the other partitions. Consequently, we can conclude that 
words in the marginal positions of documents are more 
specific while words in the middle positions are more 
comprehensive for the broadcast news documents. 
3.2. Positional n-gram model 
In this paper, we propose a positional n-gram model in 
attempt to explore the positional information inherent in the 
broadcast news documents. For this model, the training 
corpus might be partitioned according to the structure of 
documents, such as the introductory remarks, related studies 
or events, elucidations of methodology or affairs, conclusions 
of articles, and references or footnotes of reporters. In this 
preliminary study, we split each document of the corpus into 
Table 1. Style words selected on four partitions of 
the broadcast news corpus. 
P1 P2 P3 P4
1儋儛
Continue 
4携ズ
Doctor 
7⸇䞮
Student 
10⏻尥
TV station name 
2䚍⫃
Locale 
5偁恾
Internet 
8劐ズ
Teacher 
11倫⚗⫀⺝
Roundup 
3㷰扝
Welcome 
6䙙䛩
Coral 
9伂握
Rice wine 
12偷巾
Edit and translate 
Figure 1. The distributions of selected style words on four 
partitions of the broadcast news corpus.
0.0E+00
1.0E-03
2.0E-03
3.0E-03
4.0E-03
5.0E-03
6.0E-03
7.0E-03
1 2 3 4 5 6 7 8 9 10 11 12
Selected Style Words
W
o
rd
 P
ro
b
ab
il
it
y
P1
P2
P3
P4
102978-1-4244-2942-4/08/$25.00 (c) 2008 IEEE
Pr
f
uniform segmentation at most cases. One possible reason 
might be that the broadcast news documents intrinsically do 
not have paragraphs with equal length, so uniform 
segmentation fails to match the corpus characteristics well. 
Second, the CER performance of the nondeterministic 
positional n-gram model outperforms that of the deterministic 
one. Third, increasing the number of partitions will not 
always lead to the CER improvement. One possible 
explanation is that the document structure of the evaluation 
set is not complicated enough to be split into such many 
partitions. More precisely, the language models of all 
partitions behave quite the same, except that of the last 
partition. Although the use of a specific language model for 
the last partition might provide an additional benefit, its short 
duration (compared to the other positions) will make its 
contribution to the overall CER improvement insignificant. 
We have experimentally observed that, when documents were 
being segmented into four partitions by the HMM segmenter, 
the resulting ratios for the durations of the four partitions (P1 
to P4) in a document were 31%, 35%, 28% and 6% on 
average. On the other hand, as can be seen, the positional n-
gram model performs comparably to the mixture-based 
language model (in the bottom part of Table 2), when the 
number of partitions is kept small. 
In the next set of experiments, we compare the original 
PLSA language model with the positional PLSA language 
model (with uniform segmentation) under different numbers 
of topics and partitions. The results obtained from PLSA and 
positional PLSA are shown in Tables 3 and 4, respectively. 
The performance of CER and PP for positional PLSA tends to 
be better as the topic mixture number increases, while 
contrary results are obtained as the partition number increases 
(e.g., when the partition number is set equal to 4). The 
performance of positional PLSA seems not to be significantly 
different from that of PLSA. 
Finally, although the performance gains are not very 
significant for our proposed positional n-gram model and 
positional PLSA model, we believe that the use of position 
information still has it potential, according to the observations 
exemplified in Section 3.1. In the meantime, we are also 
being devoted to the investigation of better ways to model the 
document styles and structures more precisely for speech 
recognition. Furthermore, position information might be taken 
as an additional feature in the n-best (or word-lattice) 
rescoring task that uses discriminatively trained language 
models. 
6. CONCLUSIONS 
In this paper, we have incorporated the position information 
into language modeling. We proposed two position-dependent 
language models, i.e., the positional n-gram model and the 
positional PLSA model. The corresponding structures and 
characteristics were extensively investigated, while the 
performance was also analyzed. The preliminary results seem 
to demonstrate that the proposed position-dependent models 
are comparable to the mixture- and topic-based models. 
7. REFERENCES 
[1] L. Saul and F. Pereira, “Aggregate and mixed-order Markov 
models for statistical language processing,” EMNLP 1997.
[2] P. Brown et al., “Class-based n-gram models of natural 
language,” Computational Linguistics, 18(4), 1999. 
[3] C. Troncoso et al. “Trigger-based language model construction 
by combining different corpora,” IEICE Technical Report,
SP2004-100, 2004. 
[4] H. S. Chiu and B. Chen, “Word topical mixture models for 
dynamic language model adaptation,” ICASSP 2007.
[5] C. Chelba and F. Jelinek, "Structured language modeling,”
Computer Speech and Language, 14(4), 2000. 
[6] P. R. Clarkson and A. J. Robinson, “Language model adaptation 
using mixtures and an exponentially decaying cache,” ICASSP 
1997.
[7] J.R. Bellegarda, “A multispan language modeling framework 
for large vocabulary speech recognition,” IEEE Trans. on 
Speech and Audio Processing, 6(5), 1997. 
[8] D. Gildea and T. Hofmann, “Topic-based language models 
using EM,” Eurospeech 1999.
[9] Y. C. Tam and T. Schultz, “Dynamic language model 
adaptation using variational bayes inference,” Interspeech 2005.
[10] B. Chen et al., “Lightly supervised and data-driven approaches 
to mandarin broadcast news transcription,” ICASSP 2004.
Table 2. The CER and PP results of positional n-
gram models and mixture-based models. 
 CER(%) PP 
Background Trigram  20.32 682.10 
+ Deterministic 
Positional n-gram  
CER(%) 
Uniform/HMM 
Segmentation 
PP 
Uniform/HMM 
Segmentation 
1 partition 19.23 434.46 
2 partitions 19.09/19.44 402.31/387.08 
4 partitions 19.29/19.54 408.02/382.78 
8 partitions 19.62/19.37 416.41/378.20 
16 partitions 19.85/19.36 453.59/387.48 
+ Nondeterministic 
Positional n-gram  
CER(%) 
Uniform/HMM 
Segmentation 
PP 
Uniform/HMM 
Segmentation 
2 partitions 19.08/19.12 392.48/389.33 
4 partitions 19.08/18.94 399.67/392.93 
8 partitions 19.19/19.05 408.54/401.47 
16 partitions 19.35/18.97 423.13/405.99 
+Mixture-Based LM CER(%) PP 
2 topics 19.12 388.00 
4 topics 19.17 384.26 
8 topics 18.95 377.64 
16 topics 18.80 372.26 
Table 3. The CER and PP results of PLSA models.
PLSA CER(%) PP 
8 topics 19.76 563.70 
16 topics 19.77 554.07 
32 topics 19.60 545.14 
64 topics 19.71 539.61 
128 topics 19.55 533.29 
Table 4. The CER and PP results of positional PLSA 
models (with uniform segmentation).
CER(%) 
Topics 
8 16 32 
2 partitions 19.76 19.57 19.63 
3 partitions 19.73 19.68 19.68 
4 partitions 19.69 19.75 19.68 
PP 
Topics 
8 16 32 
2 partitions 555.97 546.27 538.73 
3 partitions 547.90 544.28 537.77 
4 partitions 552.22 554.66 557.70 
104978-1-4244-2942-4/08/$25.00 (c) 2008 IEEE
Pr
of
Figure 1: Plot of Eq. (6) and Eq. (7) with various values of k. 
The horizontal axis represents the Mahalanobis distance ijΔ .
2. LDA AND RELATED WORK 
2.1. LDA 
Let n nB
×
∈S \  and n nW
×
∈S \ , respectively, denote the between-
class and within-class scatter matrices for a data set of C classes 
and are defined as follows: (Note that BS  can be expressed in 
terms of class-mean differences [6].) 
( ) ( )
1 1
1
,
2
C C
T
B i j i j i j
i j
p p
= =
= − −¦¦S m m m m   (1) 
1
.
C
W i i
i
p
=
=¦S S      (2) 
Here, m  denotes the global mean. ip , im , and iS  denote the 
prior probability, mean, and covariance matrix of class i, 
respectively. The goal of LDA is to seek a linear transformation 
n p×
∈Ĭ \  that reduces the dimensionality of a given n-dimensional 
feature vector to p ( )p n<  by maximizing the discrimination 
criterion [7]: 
( ) ( ) ( )( )1trace ,T TF W BJ −=Ĭ Ĭ S Ĭ Ĭ S Ĭ   (3) 
which can be solved as a generalized eigen-analysis problem 
B i i W iλ=S ș S ș  with iș  and iλ  being the i-th eigenvector and 
eigenvalue of 1W B
−S S .  
From the viewpoint of pattern classification, it is worth 
mentioning that, in the two-class condition, LDA can be implicitly 
considered to minimize the Bayes classification error by 
maximizing the Mahalanobis distance between the class pair, while 
attaining the optimal result only under the assumption that both 
classes share the same within-class covariance. 
2.2. Weighted LDA 
As mentioned in Section 1, the LDA criterion is not optimal for a 
multi-class classification task. One of the possible solutions to this 
problem is to modify the LDA criterion by replacing  BS  with the 
following weighted form: 
( )( )( )
1 1
1
w ,
2
C C
T
B i j ij i j i j
i j
p p
= =
= Δ − −¦¦S m m m m  (4) 
where w( )•  is a weighting function of the class-mean difference 
ijΔ , which is defined by  
( ) ( )1 .Tij i j W i j−Δ = − −m m S m m    (5) 
It can be shown that the weighted LDA transformation ′Ĭ  can be 
easily derived by solving the eigen-analysis problem 
B i i W iλ′ ′=S ș S ș , which is similar to that of LDA, cf. [5]. Further, 
note that under the equal-covariance assumption, ijΔ  can be 
deemed the Mahalanobis distance between classes i and j. 
In [4], based on the minimization of the theoretical pairwise 
Bayes errors occurring between any two Gaussian-distributed 
classes, w( )ijΔ  is defined by  
( )
2
1
w erf
2 2 2
,ij
ij
ij
Δ
Δ =
Δ
§ ·
¨ ¸© ¹
   (6) 
where erf( )•  means the error function that is twice the integral of 
the Gaussian distribution with 0 mean and variance of 1/2. Another 
weighting function was introduced in [8], which is defined by 
( )w ,  0.kij ij k−Δ = Δ >     (7) 
We can see that both of Eqs. (6) and (7) in essence are 
monotonically decreasing functions of ijΔ  such that those class 
pairs with large ijΔ  will not be overemphasized (see Fig. 1). 
Yet another modification [5], advocating the concept of pairwise 
class confusion information, takes the practical classification error 
rates resulted from a given classifier into consideration, rather than 
operating merely in the Bayesian sense (cf. Eq. (6)). The 
corresponding weighting function is expressed as 
( ) ( )w 1 CI ,  0 1,ij ijα α αΔ = + − × ≤ ≤   (8) 
where CI ij  represents the empirical classification error rate for a 
sample item that belongs to class i but is misclassified to class j, 
and α  denotes an adjustable factor trading off between the 
empirical classification error rates and the class-mean distances, 
which can only be set heuristically. We can see that if 1α = , this 
approach apparently is reduced to LDA; and if 0α = , not only 
will the class pairs with CI 0ij ≠  dominate the whole weightings, 
but the class pairs with CI 0ij =  will get completely ignored. 
3. DISTANCE-ERROR COUPLED LDA 
3.1. Observations 
We first define the empirical pairwise classification error rate as 
,  1 ,ij ji
ij
i j
e e
ER i j C
n n
+
= ≤ < ≤
+
   (9) 
where in  denote the number of sample items of phone (or silence) 
class i, and ije  denotes the number of sample items that originally 
belong to phone (or silence) class i but are misallocated to phone 
(or silence) class j by the ASR. ijER , in a sense, can be used to 
measure the confusability between any class pair i and j. That is, 
for class i, the higher the value of ijER , the more confusable it 
would be with class j.  
Next, in the context of speech recognition, we can divide all of 
the class pairs into two groups: phone-phone and silence-phone 
according to their corresponding class labels. For example, if class 
i belongs to silence, any class pair including class i will be 
classified into the silence-phone group; on the contrary, the rest 
150978-1-4244-2942-4/08/$25.00 (c) 2008 IEEE
Pro
of
