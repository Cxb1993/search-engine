An Endurant Spanning Tree for Assurant Data 
Aggregation on Wireless Sensor Networks 
Jen-Yeu Chen Member IEEE, Da-Wei Juan and Cheng-Sen Huang 
Department of Electrical Engineering  
National Dong Hwa University 
Hualien, Taiwan, R.O.C.  
{jenyeu,dwj,arvin}@mail.ndhu.edu.tw 
 
Final Report: NSC- 98-2221-E-259-010 
 
Abstract— In this report, an energy-aware distributed algorithm 
is proposed to construct an endurant spanning tree for data 
aggregation on wireless sensor networks. On the constructed 
aggregation tree, nodes with higher residual energy are arranged 
close to the trunk to maximize the lifetime of the tree and 
maintain the integrity of aggregated data. Data aggregation, in 
which a node processes the data collected from all its children 
nodes and then transmits the processed result to its parent node 
by a single message, is an energy efficient way to collect data 
from sensor nodes. However, in the tree hierarchy for data 
aggregation, a node failure close to the root of the tree (the sink 
node of a sensor network) will cause severe data loss (all data 
from the downstream of this failure node will be lost.). This 
motivates our algorithm to arrange those nodes with higher 
residual energy close to the root of aggregation tree and relieve 
the responsibility of nodes with less residual energy. Our 
algorithm for tree construction is distributed; each node makes 
its own decision by exchanging information with its neighboring 
nodes. The experiment results show that the constructed 
aggregation tree by our algorithm, named Distributed Endurant 
Spanning Tree (DEST) is the most endurant, i.e., of the longest 
time to reach a certain level of data loss due to node failures from 
running out of energy, compared to other representative energy-
aware aggregation trees in the literature. This also indicates a 
less frequent re-construction of data aggregation tree, which 
further reduces the energy consumption on sensor networks. 
Keywords-wireless sensor network, data aggregation, spanning 
tree, energy, energy-aware algorithm, lifetime 
I.  INTRODUCTION  
Recently, wireless sensor networks (WSN) have induced 
tremendous efforts from both academia and industry due to its 
various applications. For most applications, an underlying 
algorithm to effectively collect the measurement data stored at 
sensor nodes is essential to the successful operation of a sensor 
network.  
Among many applications, the aggregate statistics (in 
short, aggregate), such as Max/Min, Sum, Average, over the 
data of all or a portion of sensor nodes, are more significant 
than the data stored in each individual node [15]. To effectively 
compute these aggregates, data aggregation tree methods  
[1,2,3,7,9,10,11,13] along with other epidemic-based methods 
[16,17,18] have been proposed. We refer readers to [18] for the 
detail comparison of these two types of approaches. In the 
aggregation tree approaches, a spanning tree (i.e., an 
aggregation tree) is constructed for nodes to convergecast [10] 
their data to the root of the spanning tree. The root node is 
called the sink node and is a gateway of the sensor network to 
interact with outside world. The convergecast starts from leaf 
nodes and works in the following way. Every leaf node sends 
its data (a measurement value) to its parent node. After 
collecting the data from all children nodes, an intermediate 
node computes the local aggregate, taking input on those 
received data and its own data, and then sends the computed 
result to its parent node by a single message. This procedure is 
so-called data aggregation as shown in Fig. 1. In the end, the 
root node will obtain the global aggregate. For example, to 
compute global Max of all data (values), every leaf node sends 
its value to its parent node. After collecting the values from all 
its children, every intermediate node then computes the local 
Max among the received values and its own value and then 
sends the computed local Max to its parent node. After all, the 
root of the tree obtains the global Max among all values of the 
sensor networks. Fig. 1 shows the benefit of reducing the 
number of messages for a node to send upward by the data 
aggregation of the convergecast. 
 
Fig. 1 The reduction of the number of messages by data aggregation 
The main disadvantage of the aggregation tree approaches 
is that a node failure close to the root of the tree will cause 
severe data loss (all data from the downstream of this failure 
node will be lost.). The closer the failure node is located to 
the root, the more severe data loss. This motivates our 
algorithm to arrange those nodes with higher residual energy 
close to the root of the aggregation tree and relieve the 
responsibility of nodes with less residual energy.  
The proposed algorithm is distributed. Our experiment 
results show that the constructed aggregation tree by our 
algorithm is the most endurant over time, i.e., with the 
longest time to reach a certain level of data loss due to node 
links) respectively. We assumed every node has the same 
communication range. Two nodes can communicate with each 
other, or say, are joined with an edge, when they are within 
each other’s communication range.  
All the nodes may be of the same initial energy at the 
network setup stage. However after running applications for a 
while, sensor nodes will have different residual energy. (Note 
that a sensor network may execute other applications in 
addition to our application of data aggregation.) Every node 
may consume a different amount of energy after a period of 
time. Thus we assume the residual energy of a node according 
to a random distribution. The DEST algorithm needs to be 
executed periodically to maintain a healthy tree structure. We 
refer readers to [5] for the energy consumption models of a 
wireless sensor network. 
In Table I, we summarize the notations and definitions that 
are used throughout this paper.  
B. The Distributed Endurant Spanning Tree Algorithm 
The proposed Distributed Endurant Spanning Tree 
algorithm consists of four steps: 
 
 Broadcasting Energy Information 
Prior to the tree construction, each sensor node will 
broadcast to its neighborhood a message including its 
identification number and its residual energy. 
Therefore, every node will have the energy information 
of all its neighboring nodes. 
 Edge Selection Rules 
Every intermediate tree 
x
T  rooted at node x is a super 
node.  The root can know the set of boundary edges 
 EjiTjTijiTTB
yxyx
 ),(,,|),(:),( and the 
residual energy information of the end nodes of each 
edge in ),( yx TTB . By these information, the root of 
each tree evaluates each edge in ),( yx TTB  and select 
the best edge for combining two trees (super nodes). 
There are four rules for the edge evaluation and 
selection. They are executed in order, i.e., rule on is 
executed before rule 2, and so on. We explain these 
rules by an example in Fig.2. 
rule 1). For each boundary edge )(),(:
x
TBjie  the 
root node x computes the weight of the edge,
))(),(min()(
min
jEiEeE  , i.e., the lower 
residual energy between the two end nodes of 
an edge. Then it selects the edge with the 
highest weight among all its boundary edges, 
i.e., ))((maxarg)(__
min
)(
eETlinktreeInter
xTBe
x

 . 
As show is Fig. 2(a). The bottom edge with the 
weight of 7J will be selected. 
rule 2). In case that there is a tie among the edges’ 
weights by rule 1, then amid these edge, the 
edge containing an end node of the highest 
residual energy will be selected. For example, 
in Fig.2(b), a tie occurs between the middle 
edge and the bottom edge. The middle edge 
will be selected as it contains a end node of the 
highest residual energy 9J among all end nodes 
of the edges in a tie. in Fig. 1(b). If there is no 
unique solution, then the comparison to the 
next procedure. 
rule 3). In case there is still a tie, as the middle edge 
and the bottom edge in Fig.2(c), the edge with 
the largest sum of the id numbers of its two 
end nodes is selected. In Fig.2(c), the bottom 
edge with id sum 16 will be selected over the 
middle edge of of id sum 14.  
rule 4). In case there is still a tie, as the middle edge 
and the bottom edge in Fig.2(d). Two edges 
have the same id sum. Then, the edge with the 
largest absolute difference between the id 
numbers of the two end nodes will be selected. 
In Fig.2(d), the bottom edge with the absolute 
id difference of value 4 is selected over the 
middle edge with the absolute id difference of 
value 2. 
  
     (a)                                    (b) 
 
(c)                                 (d) 
Fig. 2  Examples of four edge selection rules 
 Tree (super node) Integration  
After the step 2, each super node has selected an edge 
through which it should start to merge with the 
corresponding neighboring super node. After the 
merging, a new root should be elected and a new 
parent-child tree structure should be constructed within 
the merged tree (super node). Among the roots of all 
the trees merging together, the one of the highest 
residual energy will be elected to be the new root of the 
new merged tree. To achieve this, a Change message 
will be send out by the root, containing its node id and 
its residual energy. Other nodes, upon receiving a 
Change message, compare the information of the 
Change message with their stored data    
),),(,(
iri
EriEi to determine their root node and their 
parent node in the new merged tree. The detail 
25:       node k sends a new Change message ))(,(
kk
rErch back to 
all nodes on the tree  
x
T via ),()(__ jiTlinktreeInter
x
  
26:     else   % )()(
x
rExE   
27:       node k sends a new Change message ))(,(
kk
rErch back to 
all nodes on  the tree 
x
T via ),()(__ jiTlinktreeInter
x
  
28:     End If 
29:   End If 
30: End while 
 
C. Analysis – the correctness of the DEST algorithm 
We prove in this subsection that the graph constructed by 
the four edge selection rules of the DEST algorithm contains 
no cycle, i.e., the merged super node is a tree.  
Lemma 1: After step 2 and step 3 of the proposed DEST 
algorithm, any merged super node contains no cycle. 
 
Fig. 5 The edge selection amid n super nodes  
Proof: We prove this lemma by contradiction. Take any 
n super nodes, 3n , and these super nodes form a 
cycle by the DEST algorithm. 
Let the set of )(__
x
TlinktreeInter be 
 
1,1,2,15,44,33,22,1
,,,,,,
nnnnn
eeeeeee

 , 
which is a strict partial order set. We have the following 
relationship for the super node 1 
     
1,2,1 n
ee                                            (1) 
Also, for node 2, node 3 … and node n , we have 
,and,,
,11,3,24,32,13,2 nnn
eeeeee

   respectively, 
which yields 
2,11,
ee
n
 , a contradiction to Eq. (1). 
Theorem 2: The graph constructed by the DEST 
algorithm is a spanning tree. 
Proof: This directly follows Lemma 1 and the truth that 
in the end of the DEST algorithm all nodes are included 
in the constructed graph. 
Due to the limited space of this paper, the analytical results 
of the performance of  the DEST algorithm will be presented in 
a longer version of this paper. 
IV. SIMULATIONS 
A. Simulation setup 
We first evaluate the performance of the DEST algorithm 
on a Poisson random geometric graph. Within a square region 
of 50 ×  50, one hundred nodes are uniformly at random 
scattered. Every node has the same communication radius of 10. 
The residual energy of each node is uniformly at random 
chosen from 1J to 10J. The associated network graph is shown 
in Fig. 6(a). The corresponding spanning trees constructed by 
Espan [1], Eratio [2] and DEST are show in Fig. 6(b), Fig. 6(c), 
and Fig. 6(d), respectively. The node in red circle is the root. In 
the Fig. 6(d), the DEST re-select a new root in its step 4 to 
reduce the height of the spanning tree.  
 
(a)                                                     (b) 
 
(c)                                                     (d) 
Fig. 6  (a) the network graph, (b) the spanning tree by Espan[1] , (c) the 
spanning tree by Eratio[2], (d) the spanning tree by the DEST [this paper] 
Endurance of the spanning tree 
We compare the Endurance, which is measured by the number 
of effective nodes upon some node failures occurring on the 
spanning tree, of the spanning tree constructed by Espan [1], 
Eratio [2] and DEST in Fig. 7 and Fig. 8. The X-axis indicates 
the number of failure nodes and the y-axis represents the 
remaining effective nodes on the spanning tree.  Fig. 7 is the 
result on the topology of Fig. 6(a) whereas the Fig. 8 the 
average result over 100 different graph topologies. In a sensor 
network, since all the nodes proceed similar tasks, those nodes 
of lower residual energy are tend to exhaust their energy and 
fail earlier  in time. Thus, in the X-axis, we consider that nodes 
fail in a descending order of their residual energy. 
The failure of an intermediate node on a tree branch will make 
all of its offspring nodes down the branch become in-effective 
because their data cannot be obtained at the root (the sink node).  
Since the proposed DEST algorithm arranges the nodes of low 
residual energy close to leaf nodes and those nodes of high 
residual close to the root, the constructed spanning keeps a high 
percentage of effective nodes. In contrast, it is possible that a 
node of low residual energy is located close to the root on the 
spanning trees constructed by Espan[1] and Eratio[2]. If this 
node fails, all of its offspring nodes and itself become in-
effective. This explains the dramatically drop on the curves of 
Espan and Eratio in Fig. 7.  
[18] S. Boyd, A. Ghosh, B. Prabhakar and D. Shah, “Randomized Gossip 
Algorithms,  ” in Proc. IEEE Transactions on Information Theory, 
Special issue of IEEE Transactions on Information Theory and IEEE 
ACM Transactions on Networking, June 2006, 52(6):2508-2530.
 
2010/6/26
1
Optimal Gossip-Based Aggregate 
Computation
Jen-Yeu Chen               Gopal Pandurangan
Dept. Electrical Engineering
NDHU, Taiwan 
Division of Mathematical Science 
NTU, Singapore
SPAA 2010
Outline
• What is an aggregate statistic
• Compute aggregates by gossiping
• DRR-gossip algorithms 
– Protocols in each phase   -- Analytical results
• Application to sparse networks
• Lower bound on address oblivious algorithms
2010/6/26
3
Comparisons to main previous works 
on Kempe’s network model
Algorithm Time Message Add. oblivious
Efficient gossip 
[Kashyap]
O(logn loglogn) O(n loglog n) no
Uniform gossip 
[Kempe]
O(logn) O(n logn) yes
DRR-gossip
[this paper]
O(logn) O(n loglog n) no
[10] Srinivas Kashyap, Supratim Deb, K. V. M. Naidu, Rajeev Rastogi, and Anand
Srinivasan, Efficient gossip-based aggregate computation, PODS, 2006, pp. 308-317.
[11] David Kempe, Alin Dobra, and Johannes Gehrke, Gossip-based computation of 
aggregate information, FOCS, 2003, pp. 482-491.
Network Model  - network graph 
• Physical network
G(V,E), |V|=n nodes
• Logic Overlaying 
n-clique
• The data value vector
v=[vi],
• Compute aggregates 
over  value vector v
i V
3
41
2
65
1
5
2
3
6
4
Overlaying 
Clique
Physical 
Network
2010/6/26
5
A
B
C
C
A
B
Gossip over
Root Clique
Overlaying Clique
Physical Network
9
DRR & 
Convergecast over 
Phase 1 – Distributed Random Ranking
• Each node i independently and uniformly at 
random chooses rank(i) from [0,1]
• Each node i samples up to (log n -1) random 
nodes (one in each round)
• if i finds a node j with the higher rank rank(j), 
i.e., rank(j) > rank(i), 
– stops sampling! 
– sets j as its parent node and connects to it
• None of the (log n -1) sampled nodes have a 
higher rank 
– i becomes a root of a tree
• DRR produces a forest of disjointed trees
i
j
n-1 neighbors
samples up to (log n -1)
random nodes
2010/6/26
7
Phase 2 Convergecast
• Compute the local aggregate of a tree along the tree 
branches up to the root
• Convergecast-max
– To compute the local Maximum within a tree
– Every node collects values from its children
– Send the Maximum amid the collected values with its own to its 
parent node
• Convergecast-sum  
– To compute the local Sum within a tree
– Every node collects values from its children
– Send the Sum of the collected values and its own to its parent 
node
A
B
C
B
C
A
Root Clique
Overlaying 
Clique
14
After Convergecast
- Each root can broadcast its address to the members 
of its tree
- Each member then can directly connect to its root
2010/6/26
9
A
B
C
B
C
A
Root Clique
Overlaying 
Clique
Randomly pick B 
17
Uniformly at random  picks B
Phase 3 Gossip
Gossiping on the root Clique
Implementation on overlaying Clique                  
(case 1)
A
B
C
B
C
A
Root Clique
Overlaying 
Clique
pick
Uniformly at random pick
18
Phase 3 Gossip
Gossiping on the root Clique
Implementation on overlaying Clique                  
(case 2)
forward
2010/6/26
11
Phase 3  Gossip (Gossip-max) 3/3
• Gossip-max : gossip and sampling procedures
– sampling procedure for O(log n) rounds
– In each round:
• Every root independently and uniformly at random selects a node 
in V (the network) and sends a sampling request
– If the selected node is a root,  done!
– If the selected node is a non-root node, the selected node forward 
the sampling request message to its root
• Every sampled root sends it value to the inquiring root
• Every inquiring root update its value to the larger value between 
the received value and its own
Phase 3 Gossip - Analytical Results
• Theorem 5. After the sampling procedure of the Gossip-max 
algorithm, i.e., O( log n) rounds of sampling, all roots know the
global Maximum, Max, whp.
• Theorem 6. Running Gossip-ave algorithm Whp, there exists a 
time 
such that for all time             the relative error of the estimate 
of average aggregate on the root of the largest tree is at most                
(m is the number of roots).  
• no sampling procedure in Gossip-ave
(log log ) (log ), 0,aveT O m n O n    
avet T
2/( 1);n 
2010/6/26
13
Phase 3 DRR-Gossip - Complexity
Time Message
DRR O(logn) O(n loglogn)
Convergecast O(logn) O(n )
Gossip O(logn) O(n )
Total O(logn) O(n loglogn)
Sparse networks: Local-DRR 1/2
• Sparse networks:
– Each node can simultaneously send ranking 
messages to all direct neighbors
– P2P: Chord; 
– Wireless networks: Ad hoc network, wireless 
sensor networks 
• Broadcast nature of a wireless transmission
• Local-DRR works on the physical networks
2010/6/26
15
The End
Thank you
Jen-Yeu Chen, Gopal Pandurangan
98年度專題研究計畫研究成果彙整表 
計畫主持人：陳震宇 計畫編號：98-2221-E-259-010- 
計畫名稱：異質感測網路之分散式跨層最佳化資訊保全 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 1 1 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 1 1 100% 碩士生 已畢業 
博士生 1 1 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 0 1 100% 已投稿 
研究報告/技術報告 0 0 100%  
研討會論文 0 1 100% 
篇 
已投稿 論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
 
