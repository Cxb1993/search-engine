  
 計畫中文摘要 
 
本三年期計畫以分散式視訊編碼(Distributed Video Coding, DVC)為主要研究課題。相較於
傳統的視訊編碼，分散式視訊編碼改在解碼端進行動作估計，因此可將大部份的計算負擔由
編碼端移至解碼端，因此成為需要低複雜度視訊編碼應用（如無線視訊感測器、手機電話、
與網路攝影機等）所關注的技術。雖然理論上，不管是在編碼端或在解碼端去估計畫面間相
關性，都應能達到接近的的效果，但是實際的情況卻並非如此。目前分散式視訊編碼的文獻，
相較於傳統以預測編碼為基礎的視訊編碼器，其壓縮效能仍有一段差距。本計畫的主要目的，
即在於發展高碼率─失真表現、低編解碼複雜度的分散式視訊編碼演算法，並提出兩種改良
的DVC架構。考量DVC效能與傳統視訊編碼（如H.264）的差距，主要原因在於DVC在解碼
端所得到參考影像的相關性，本計畫第一個構想先藉由利用預測動作向量(PMV)進行快速模
式選擇，再觀察編碼區塊本身特性（如與前一張畫面的絕對誤差）及鄰近區塊的編碼資訊（如
編碼區塊模式和碼率），做為判斷是否在編碼端進行動作估計的依據。我們提出的構想只需在
編碼端增加少量的計算，即能改善解碼端旁資訊不準確的問題。第二個構想採用以區塊(block)
為單位的分散式視訊編碼架構，在編碼端做簡單的快速區塊模式的分類 (block mode 
classification )，以極簡單的動作估計，將區塊分類為Wyner-Ziv區塊或intra區塊。Wyner-Ziv
區塊使用turbo coding來做更正，intra 區塊使用H.264 intra coding直接編碼。我們提出更具彈
性的intra區塊更新法則，以提高編碼效率；在解碼端利用所做過的快速區塊模式分類的資訊，
來輔助解碼旁資訊的建立。實驗証明我們所提出的兩個構想，在低碼率的情況下相較於傳統
視訊編碼，具有良好的效能改進。 
 
 
關鍵詞： 分散式視訊編碼、錯誤保護、Wyner-Ziv編碼、區塊模式分類、動作估計、解碼旁資
訊 
 
 2
分析前二年度的編碼架構我們可以歸
結出一些需要解決的問題，包括如何進一
步提升編碼影像品質、如何能更有效產生
高相關性的 side-information、是否能進一
步有效利用編碼端的資訊等等。因此本計
畫提出了兩種有別於前一年度編碼系統的
新架構，並參考[9]以區塊(Block)為單位的
系統，將區塊分類為 Wyner-Ziv 區塊及
INTRA 區塊兩種進行處理。 
研究重點在於如何更進一步的提升整
體編碼效能。以下為本計畫的研究項目： 
z 藉由在編碼端建立區塊分類 (Block 
Classification)的機制，取得編碼端額
外的輔助資訊加以利用，以達到改善
side-information 不精確的問題，並以
極少的動作估計的時間，找到小於門
檻值的區塊，利用傳送區塊分類資訊
及動作向量，減少區塊因為小範圍移
動而被視為 INTRA 區塊的機率。 
z 空間上的每一個區塊位置都有自己的
INTRA 週期，此週期稱為時域區塊群 
(TGOB)。提出漸近式快速區塊分類門
檻值的決定，當 TGOB 越大時，快速
區塊分類的門檻值越嚴格，達到彈性
門檻值的效果。 
z 提出產生 Wyner-Ziv side information
的方法，為要讓 Turbo code 可以先由
最高有效位元平面(most significant bit 
plane) 到 最 低 有 效 位 元 平 面 (lost 
significant bit plane)依序做更正。 
z 在利用編碼端資訊的同時，避免增加
太多計算負擔於編碼端。 
 
III. 研究方法 
 
本計畫提出了兩種新的編碼架構，分
別為圖三及圖七，以下將個別說明。 
 
i.利用編碼端輔助資訊之分散式視訊編碼 
在架構 A 當中將影像序列分成兩種畫
面去做編解碼，一種是 Key Frame，另一種
是 Wyner-Ziv Frame，這兩種畫面使用獨立
而且不同的編碼方式來完成，而解碼時則
是採用聯合解碼。Key Frame 所使用編碼方
式為單純 H.264 Intra 編碼，且編解碼端均
為獨立操作。而 Wyner-Ziv Frame 首先則利
用區塊分類機制，目的在於把目前欲編碼
區塊分類後，針對欲編碼區塊選出較佳的
處理方式，藉此提升 side-information 的精
確度。本系統的作法為 Key Frame 與
Wyner-Ziv Frame 交錯，即一張 Key Frame
後面接一張 Wyner-Ziv Frame。 
 
 
Wyner-
Ziv 
Frame
Key 
Frame
H.264 Intra 
Encoder
H.264 Intra 
Decoder
Block 
classification
Turbo 
Encoder
Encoder 
Buffer
Turbo 
Decoder Reconstruction
Wyner-
Ziv 
Frame
Key 
Frame
Interpolation/Ex
trapolation
Turbo code
Side 
Inforamtion
 
圖三：本系統架構圖 A 
 
架構 A 主要分為兩個部份進行探討，
分別為如何利用編碼端輔助資訊，及
side-information 的產生方式。 
 
利用編碼端輔助資訊： 
 如何利用編碼端輔助資訊為此架構的
主要研究目的，其方式是在編碼端加入了
區塊分類的機制，先藉由利用預測動作向
量(Predicted Motion Vector, PMV)在編碼端
進行快速區塊模式選擇，並觀察編碼區塊
本身特性（如與前一張畫面的絕對誤差）
及鄰近區塊的編碼資訊（如編碼區塊模式
和碼率），做為判斷是否在編碼端進行動作
 4
選擇取得了編碼端的輔助資料，此時將有
三種模式的區塊將會產生。表一為在兩種
情況下 skip mode 與 16x16 ME mode 的效
能表現，左邊欄位表示在確定區塊屬於 skip 
mode 的情況下，分別以 skip、16x16 ME
貼補出 Wyner-Ziv Frame 的結果；同樣的，
在右邊欄位則是在確定屬於 differentiate 
mode 的情況下，以上述兩種方式產生貼補
影像的效果比較。 
觀察 skip 與 16x16 ME 在 skip mode
時，兩者的差異皆不大，且在 differentiate 
mode 才有較為明顯的差距，而此結果也再
次証明了以 CBP 值做為是否 skip 的判斷條
件的正確性，在只損失些微品質的情況下
節省了進行動作估計所花費的時間。 
 
表一：skip 與 ME mode 之比較表 
G_skip = 1 (skip mode) G_skip = 0 (differentiate mode)
影像序列 
skip 16x16 ME skip 16x16 ME 
foreman 37.88 38.27 35.03 35.93 
mother 38.60 38.90 35.45 36.79 
container 37.75 37.81 33.37 34.67 
mobile 38.15 38.17 32.50 34.38 
 
接下來觀察 16x16 ME mode 與 BME 
mode 的結果如圖六所示，紅色區塊表示此
區塊使用 16x16 ME 的效果較佳，反之綠色
區塊則代表使用 BME 效果較佳。此結果可
以發現一張 frame 中並不一定全部使用何
種處理方式最好，而應該是有著各自較佳
的不同處理方式。 
 
圖五：ME 與 BME mode 之比較 
因此，此時的 side-information 即是由
三種模式組成。目的在於挑選出各自最好
的處理方式組合，如圖五所示，包含了不
用進行動作估計，使用 PMV 貼補的 skip 
mode；需在編碼端進行動作估計的 16x16 
ME mode 以及不需在編碼端進行動作估
計，而在解碼端進行雙向動作估計的 BME 
mode。 
Skip 
mode
BME 
mode
16x16 
ME 
mode  
圖六：side-information 組成示意圖 
 
ii.利用快速區塊分類之分散式視訊編碼 
圖七為本計畫提出的架構 B，首先，
Block Mode Classification (BMC)將一張
frame 切割成非重疊的 16*16 區塊，將每一
個區塊分類成 intra block、 skip block、 
SDSP block 類別，並且產生每一個區塊分
類資訊(Block Mode Information, BMI)傳送
給解碼端。再使用 Mode decision 將 block 
分成 WZ 和 Intra 兩個部分，Intra 的區塊
直接使用 H.264 FMO 編碼自己想要編碼的
巨區塊， skip block 及 SDSP block 這些區
塊皆為 Wyner-Ziv blocks，會依據 BMI 傳
送對應的動作向量給解碼端。為了使
Wyner-Ziv blocks 在編碼端與解碼端資訊
可以相對稱，本論文也利用 BMI 將所有
Wyner-Ziv blocks 整合產生 WZ Slice 在
編、解碼端，並且使用 CRC code 判斷是否
需要再做 Turbo code 的更正。 
在解碼端，Intra區塊被解碼到Decoded 
Key block 內。Wyner-Ziv Side Information 
是使用 BMI 及前一張重建畫面的資料產生
新的旁資訊，然後再用 Turbo code 更正旁
 6
如圖十，為 Akiyo 第 100 張重建畫面，
框起來的部分都是由前一張貼補而得到的
區塊，連續 99 張畫面都沒有做 intra 編碼。 
 
(a) Akiyo099 QP=35 
 
(b) Akiyo099 QP=15 
圖十： 不同 QP 值 TGOB=100 的區塊 
 
Wyner-Ziv 區塊 Side information 的產生: 
在每一張畫面都會產生一個新的
Wyner-Ziv Slice，Wyner-Ziv slice generator
是將Mode decision所判斷BMI不為零的區
塊(即 Non INTRA block) ，如圖十一斜線
部分，把這些 16*16 的區塊整合成 16*16*n
的一個 Wyner-Ziv slice，n 為 Non INTRA 
block 數量。 
而解碼端的 WZ SI slice generator 則也
是如圖十一相同的方法，使用由編碼端所
傳送的 BMI 資訊，讀取前一張重建畫面同
位置或動作向量區塊，產生 Wyner-Ziv slice
的 side information。 
Frame-0 Frame-1 Frame-2 Frame-4Frame-3
WZ Slice-1 WZ Slice-2 WZ Slice-3 WZ Slice-4
INTRA block
Non INTRA
block
圖十一： 新 WZ Slice 的產生 
 
與相關分散式視訊編碼 H.264 效能比較: 
在本節中，將比較本論文「利用快速
區塊分類之分散式視訊編碼」與蔡東展「基
於時域上動態關鍵區塊選擇的 Wyner-Ziv 
視訊編碼技術」論文[9]以及 H.264(I)比較
其效能與時間。在初始 SAD 門檻值設為
600 下，進行 100 張的測試碼率與 PSNR 值
及花費時間的比較，如圖十二所示。本論
文在靜態影像時，低碼率較參考文獻[9]
高，並且沒有時間延遲，比 H.264(I)多
1~10dB 的增益。 
 
結論： 
 本計畫提出的兩種新架構，針對前一
年度的編碼系統分析並加以改善，以提升
其編碼效能[10],[11]。架構 A 當中，在編碼
端加入了區塊的分類機制以達到利用編碼
端 資 訊 的 效 果 ， 進 一 步 的 改 善 了
side-information 的精確度。架構 B 當中應
用以下各點以提升編碼效能：(1) 快速區塊
分類在編碼端花費少量的動作估計，將區
塊分成 INTRA 區塊和 Non INTRA(包含
Early stop 區塊、 Small Diamond Search 
區塊)，傳送 BMI 和依照不同類別傳送不同
碼率的動作向量給解碼端，取代因為小動
作而需做 H.264 intra coding 的區塊。(2) 
在空間上每一個區塊位置都有自己的
INTRA 週期，稱為時域區塊群(TGOB)，並
利用 TGOB 越大快速區塊分類的動態門檻
值越嚴格，使大量靜態的區塊不需固定週
期重新用 H.264 intra 編碼更新。(3) 提出產
生 Wyner-Ziv side information 的方法，讓
Turbo code 可以先由最高有效位元平面
(most significant bit plane)到最低有效位元
平面(lost significant bit plane)依序做更正。
實驗結果顯示，本論文在低碼率時，較參
考文獻[9]高，且沒有時間延遲的問題，較
H.264 Intra 高 1~10dB 的增益，適中移動
影片及較靜態影片在低碼率時也較 H.264 
Intra 高。 
表三：測試結果-A (QCIF 0.5bpp) 
Image size 前年度 本年度 
Foreman 31.01 32.12 
 8
可供推廣之研發成果資料表 
□ 可申請專利  ; 可技術移轉                                    日期： 98 年 9 月 25 日 
國科會補助計畫 
計畫名稱： 分散式視訊編碼的實現與應用 
計畫主持人： 楊士萱教授 
計畫編號： NSC 95－2221－E－027－028－MY3  
學門領域：訊號處理 
技術/創作名稱 以小波為基礎的分散式視訊編碼技術 
發明人/創作人 楊士萱 
中文： 
發展高碼率─失真表現、低編解碼複雜度的分散式視訊編碼演算
法，並提出改良的 DVC 架構，在低碼率的情況下相較於傳統視訊
編碼，具有良好的效能改進。 
技術說明 英文： 
We developed high rate-distortion, low complexity algorithms for 
distributed video coding. Compared to the conventional video coding, 
the proposed algorithms achieves good performance improvement.  
可利用之產業 
及 
可開發之產品 
 相機電話與感測器網路等配備較簡單視訊編碼器之產品。 
技術特點  以小波為基礎的分散式視訊壓縮。 
推廣及運用的價值  提供編碼結構較簡單視訊編碼器之參考。 
※ 1.每項研發成果請填寫一式二份，一份隨成果報告送繳本會，一份送貴單位研發成果
推廣單位（如技術移轉中心）。 
※ 2.本項研發成果若尚未申請專利，請勿揭露可申請專利之主要內容。 
※ 3.本表若不敷使用，請自行影印使用。 
 10
介紹發表論文的題目與發表者，並引導論文發表結束後的答詢。進行到補發表論文第二篇時
Prof. Schatter 終於到場（他也是論文發表者之ㄧ），於是我將最後兩篇論文（包括我報告的論
文）交給他主持。我發表的論文題目是 An Improved H.264 Fast Inter-Mode Decision 
Algorithm，我大約用了 15 分鐘介紹論文的背景、動機、演算法、實驗結果與未來展望，其
後詢答時 Dr. Ghanbari 問了兩個問題，一個為演算法在高編碼碼率下之侷限與改進方式，另
一個為論文中同位巨區塊的定義，並由本人逐一回覆。本場次最後在下午 3 時 40 分順利結束，
與會人士繼續到擺設下午茶的大廳進行開放式討論。 
   
     論文發表演講廳 G.C. Lecture Theatre 外留影  口頭報告論文發表現場 
本人於 7 月 14 日與 7 月 15 日繼續參加大會各項活動，與世界各地之專家學者進行面對
面交流，其間並與國內學者高雄第一科大黃承龍副教授、淡江大學蕭富元助理教授等討論相
關學術問題。會議於 7 月 15 日中午結束。本人於 7 月 17 日由英國倫敦希斯洛機場，搭乘長
榮航空 BR068 班機，經約 18 小時之飛行，於 7 月 18 日晚間返抵國門。 
 
二、與會心得 
EuroIMSA 2009 為一個小型的國際研討會，總共發表篇數僅約 30 篇，論文作者遍及世界
各地，其中台灣佔了 5 篇為各國之冠。在同一地點（劍橋大學 Fitzwilliam College）有另外兩
個 IASTED 的國際研討會一起舉辦，使整個會場的人氣稍能維持。除了一般的學術性論文之
外，有許多發表論文重視實做上的貢獻，為學界與產官研合作的成果，或為我們注重 SCI 論
文之餘，也應該努力的方向。由於會議的主題相當廣泛，同一 Session 的論文彼此的歧異仍
大，但也可以因此吸收到不同領域的新知。研討會上的詢答討論氣氛熱烈，與台灣一般研討
會冷清、靠 Session Chair 問問題撐場面的情形頗不相同，值得學習。 
本人主要專注於影像編碼與傳輸之論文，在會場中與世界各地專家學者當面討論相關問
題，獲得諸多寶貴建議與經驗。最後，本次會議之會場交通不便，另有許多論文作者並未出
席發表論文(no show)，是較為可惜之處。 
 
三、附件 1：發表之論文，附件 2：Session Chair 證書。 
 
 
 12
MB in the previous frame. An adaptive threshold is 
required to validate the proposed statistical inference. 
Shen et al. [6] use the sum absolute difference (SAD) of 
each 4×4 block and the texture characteristic to reduce the 
set of candidate modes. Observing that more zero blocks 
for residual coding imply a higher probability of M-type 
partitioning, Chen and Yang [7] propose using coded 
block patterns (CBP) for fast mode selection. Their 
method achieves twice reduction in ME time as compared 
to the Early-SKIP algorithm [3] and the overall 
performance is comparable to [4]. It should be noted that 
both [4] and [7] include the Early-SKIP condition in [3] 
as a part of their algorithm. 
In this paper, we extend the CBP-based method in [7] 
with the mode of the co-located macroblock. The CBP is 
a syntax element in the H.264 macroblock layer, which 
specifies which of the six 8×8 blocks after motion 
estimation requires residual coding. The co-located 
macroblock is the macroblock of the same position in the 
previous frame. The CBP value and the coding mode of 
the co-located macroblock can be used to predict the most 
plausible inter-mode of current macroblocks. We 
extensively evaluate accuracy and efficiency for each of 
the simplifying criteria, and incorporate them into the fast 
mode-decision algorithm. Compared with the 
state-of-the-art approaches in the literature [4]-[7], the 
proposed method provides comparable or better results 
with more elegant expediting criteria.  
The rest of this paper is organized as follows. In 
Section 2, H.264 inter-mode selection and CBP are 
investigated. The proposed algorithm is presented and 
analyzed in Section 3. The simulation results are given in 
Section 4, followed by the concluding remarks. 
 
 
2.  H.264 Inter-Mode Selection 
 
2.1 H.264 RATE-DISTORTION OPTIMIZATION 
FUNCTION 
An optimal H.264 encoder chooses the best mode in 
the rate-distortion minimization sense. The H.264 RDcost 
function can be expressed as a Lagrange cost function J 
shown below 
)|MODE,,( MODEcsJ λ  
)MODE,,()MODE,,(SSD csRcs MODE ⋅+= λ  (1)
where SSD denotes the sum of the square differences 
between the original blocks s and its reconstruction c, 
MODE indicates the selected mode from the candidate set 
{SKIP, 16×16, 16×8, 8×16, 8×8, 8×4, 4×8, 4×4, Intra16, 
Intra4}. R(s, c, MODE) is the number of bits associated 
with the examined mode. SSD, R(s, c, MODE), and the 
Lagrange multiplier λMODE are notably implicit functions 
of the quantization parameter QP, which is a variable used 
for scaling transform coefficient levels [1]. It has been 
observed [4]-[7] that the simplest SKIP and 16×16 modes 
dominate the best mode for typical QP values. To expedite 
the mode decision, macroblocks pertaining to the SKIP 
mode or macroblock types should be identified without 
full RDcost evaluations. In this paper, we will use the 
shorthand notation J(mode) to denote the RDcost of a 
specific mode. For instance, J(16x16) represents the 
RDcost of the 16×16 mode.  
 
2.2 H.264 CODED BLOCK PATTERNS 
The Coded Block Pattern (CBP) is a syntax element 
in the H.264 macroblock layer, which specifies which of 
the six 8×8 blocks (for 4:2:0 subsampling) may contain 
non-zero transform coefficient levels [1]. A CBP consists 
of six bits b5b4b3b2b1b0, where b3b2b1b0 
(CodedBlockPatternLuma) individually specifies the 4 
luma blocks and b5b4 (CodeBlockPatternChroma) jointly 
specifies the 2 chroma blocks, as shown in Fig. 2. Some 
CBP examples and their implications on mode decision 
are given below: 
• Cbp = 0 (000000). All the luma and chroma 
blocks are uncoded, which implies that 16×16 
motion estimation is very accurate. If this 
macroblock is not skipped, it is very likely to be 
of m types. 
• Cbp = 1, 2, 4, or 8. in this case, only one of the 
four luma blocks (and no chroma blocks) requires 
residual coding. The probability of choosing m 
types is high. 
• Cbp = 16 or 32. the luma blocks are uncoded while 
some chroma blocks require residual coding. The 
probability of choosing m types is still high. 
• Cbp = 15, 31, or 47. in this case, all the luma 
blocks are nonzero. Therefore, m-type motion 
estimation is hardly satisfactory. Sub-macroblock 
types will be needed for a better match. 
 
Figure 2 - Bit assignment of CBP. 
 
To calculate the RDcost of a 16×16 macroblock, the 
residual macroblock after performing 16×16 motion 
estimation are divided into sixteen 4×4 blocks, and each 
of them is transformed and quantized. The predicted CBP 
is obtained by enumerating the six 8×8 blocks with 
non-zero coefficients, and it is used for estimating R(s, c, 
16×16) in (1). Therefore, a predicted CBP value is 
inherently available without extra computation while 
computing J(16x16) (for the 16×16 motion estimation). 
The obtained CBP is called “predicted” because the 
actual CBP may differ when the 16×16 mode does not 
 14
4.  Experimental Results 
 
The proposed algorithm is tested on the H.264 
JM13.2 reference software [9] where the rate-distortion 
optimization (RDO) is turned on (JM RDOptimization 
= 2). The motion vector resolution is set to be 1/4 pixel 
and the built-in fast motion estimation (hybrid 
Unsymmetrical-cross Multi-Hexagon-grid Search strategy, 
UMHexagonS [10]) is employed (JM SearchMode = 1). 
The speed-up performance of a fast inter-mode algorithm 
is measured by its total encoding time savings percentage 
(TS) compared to the original optimal mode selection 
with exhaustive RDcost evaluations: 
100%
Time
TimeTime
TS
original
proposedoriginal ×−=      (2) 
The rate-distortion performance is measured in 
terms of DPSNR (differential PSNR) and DBR 
(differential bit rate) that indicate the average 
differences in PSNR and bit rate relative to the optimal 
mode selection, respectively. A negative value in DPSNR 
implies quality degradation while a positive value in DBR 
implies a rate increase for an investigated method. In the 
following, we extensively compare the proposed method 
with the state-of-the-art approaches in the literature. The 
comparisons are individually made because different 
coding parameters are adopted in each of the evaluated 
schemes. 
We first compare our method with [4] and [7], and 
the results are shown in Table II. The simulation is 
conducted in H.264 Baseline profile with five reference 
frames and search range equal to ±32 pixels. The results 
are averaged over the first 100 frames of each test 
sequence. All the three methods incorporate the 
Early-SKIP and Selective-Intra conditions [3] that have 
been implemented in the H.264 JM reference software [8], 
[9]. The Selective-Intra condition compares the average 
boundary error (ABE) between the current macroblock 
and its adjacent encoded macroblocks, and the average 
number of bits required to encode the residual block 
under the best inter mode (AR). When ABE is larger than 
AR, all INTRA-modes will be neglected. Three extra 
criteria are introduced in [4] based on the relationships 
among J(16×16), J(8×8), and J(4×4) of the current 
macroblock and its spatially and temporally adjacent 
macroblocks. For instance, the coding mode is restricted 
to M types if J(16×16) of the current macroblock is less 
than the average J(16×16) in the previous slice. On the 
other hand, Ref. [7] (our previous work) is a pure 
CBP-based approach. The rate-distortion performance in 
Table III is objectively evaluated by BDPSNR 
(Bjøntegaard Delta PSNR) and BDBR (Bjøntegaard Delta 
Bit Rate) [11] from the rate-distortion curves for QP 
varying in the set {28, 32, 36, 40}. It is observed from 
Table II that the proposed method consistently provides 
higher time savings (more than 10%) with negligible loss 
in BDPSNR and BDBR. 
We next compare our method with [5] and the 
results are shown in Table III. The simulation is 
conducted in H.264 Main profile with the IPPP GOP 
(group of pictures) structure, where the first 200 frames of 
each test sequence are used. Only one reference frame is 
used, and the search range is set to ±16 pixels. The 
tracking-MB algorithm in [5] first determines the most 
correlated MB in the previous frame using an 
integer-pixel 16×16 motion estimation. If the most 
correlated MB has a sufficiently high correlation with the 
current MB (with a overlapping area larger than an ad hoc 
threshold τ), this most correlated MB is called the 
“tracked MB”. The mode of the tracked MB determines 
the candidate modes of the current MB, and the RDcost of 
the tracked MB is used as a decision threshold. The TS, 
DPSNR, and DBR of the two algorithms are evaluated 
over three QP values 24, 28, and 32. The proposed 
method provides slightly more time savings than Ref. [5] 
especially for larger QP values. 
Finally we compare our method with [6] and the 
results are shown in Table IV. The simulation is conducted 
in H.264 Main profile with the IPPP GOP structure, where 
the first 150 frames of each test sequence are used. 
Moreover, CABAC (Context Adaptive Binary Arithmetic 
Coding) is employed in this case. The 16 SADs of the 4×4 
blocks and its matching blocks and the vertical and 
horizontal mean absolute deviations (MAD) of a 
macroblock are used to reduce the set of candidate 
inter-modes in [6]. Again, more time savings are observed 
at medium-to-low bit rates (QP = 28, 32) for the proposed 
method with a comparable rate-distortion performance. 
Furthermore, the proposed algorithm imposes no 
restriction on the number of reference frames and 
involves no ad-hoc thresholds. (Recall that only one 
reference frame is adopted in [5] and [6].) The QP value 
notably affects the CBP values and therefore changes the 
percentage of macroblocks that satisfy the Check-MB 
condition of the proposed method. An investigation on 
offering more time savings for small QP values in our 
scheme is currently under study.  
 
5.  Conclusion 
 
A new fast inter-mode decision algorithm based on 
the CBP, mode of the co-located macroblock, and 
RDcosts has been presented. Special CBP values are used 
for fast selection of SKIP mode and M-type macroblocks, 
with the aid of spatial and temporal correlation of modes. 
The expediting criteria assume very high accuracy and 
provide consistently good performance for videos of 
various characteristics. The proposed method provides 
better or comparable speed and rate-distortion 
performance compared to other state-of-the-art mode 
decision methods that involve more elaborate 
mechanisms. 
 
 16
TABLE III. Performance comparison with ref. [5] (Kim et al.). (TS and DBR in %, DPSNR in dB). 
Proposed Method Kim et al. [5] Sequence QP 
TS DPSNR DBR TS DPSNR DBR 
24 68.2 -0.05 1.94 70.8 -0.00 0.67 
28 73.4 -0.07 2.85 62.9 -0.02 0.87 Salesman (QCIF) 
32 76.6 -0.07 0.63 64.3 -0.03 0.00 
24 55.0 -0.05 0.94 54.7 -0.07 0.73 
28 62.0 -0.03 1.54 54.6 -0.06 1.00 Paris (CIF) 
32 67.6 -0.08 2.00 56.5 -0.06 0.79 
24 56.9 -0.08 -0.46 58.4 -0.08 0.54 
28 63.7 -0.06 -0.36 61.0 -0.04 0.84 Mother & Daughter (CIF) 
32 69.2 -0.06 -0.59 61.6 -0.03 0.67 
24 43.6 -0.05 -1.68 57.6 -0.07 -1.92 
28 65.8 -0.08 -3.05 64.0 -0.08 -2.03 Hall Monitor (CIF) 
32 75.2 -0.09 -2.91 66.1 -0.05 -1.63 
24 71.2 -0.06 -0.15 70.1 -0.04 -0.17 
28 74.9 -0.08 -1.74 69.1 -0.03 -1.08 Akiyo (CIF) 
32 77.2 -0.05 -2.33 69.8 -0.03 -0.36 
Average 66.7 -0.06 -0.22 62.8 -0.05 -0.07 
 
TABLE IV. Performance comparisons with ref. [6] (Shen et al.). (TS and DBR in %, DPSNR in dB). 
Proposed Method Shen et al. [6] Sequence QP 
TS DPSNR DBR TS DPSNR DBR 
24 63.7 -0.06 0.47 62.3 -0.10 0.57 
28 68.9 -0.08 -0.07 63.3 -0.09 -0.32 News (CIF) 
32 72.3 -0.07 -0.04 60.0 -0.07 -2.44 
24 35.6 -0.09 0.55 38.6 -0.08 -0.12 
28 47.0 -0.12 0.78 45.7 -0.06 0.27 Foreman (CIF) 
32 55.2 -0.13 0.24 43.3 -0.08 -0.21 
24 16.8 -0.05 0.01 29.9 -0.03 2.45 
28 29.3 -0.05 0.11 33.8 -0.04 2.99 Bus (CIF) 
32 40.9 -0.05 0.21 35.2 -0.04 2.23 
Average 47.7 -0.08 0.25 45.8 -0.07 0.60 
 
出席國際學術會議心得報告 
                                                             
計畫編號 NSC 95-2221-E-027-028-MY3 
計畫名稱 分散式視訊編碼的實現與應用（第 2 年） 
出國人員姓名 
服務機關及職稱 
楊士萱 
國立台北科技大學資訊工程系教授 
會議時間地點 June 23-26, 2008, Hannover, Germany. 
會議名稱 IEEE International Conference on Multimedia & Expo (ICME2008) 
發表論文題目 
1. Using H.264 Coded Block Patterns for Fast Inter-Mode Selection 
2. Foreground Stabilization of Image Sequences 
 
一、參加會議經過 
 
2008 年國際電機電子工程師學會多媒體與展示年會(2008 IEEE International Conference on 
Multimedia & Expo, ICME2008)於六月 23日至 26日在德國漢諾威(Hannover)舉辦。本人於 6
月 22 日晚上出發搭乘華航 CI 61 班機，約經 13 小時之飛行至德國法蘭克福(Frankfurt)，再
轉 ICE 高鐵至漢諾威，最後搭乘公車至會場 Hannover Congress Centrum。若由台北離家起
算，至漢諾威會場約共需 24小時，也算是有點辛苦。 
6 月 23 日晚上參加大會接待酒會，6 月 24 日起聆聽各場 keynote speeches，並參與各 oral 
sessions與 poster sessions之論文發表與討論，與世界各地之專家學者進行面對面交流。其間
並與本校杭學鳴院長，台大陳宏銘教授、Winston 許教授，清大陳永昌教授、林永隆教授、
林嘉文教授，成大楊家輝教授、吳宗憲教授、李國君教授，中正柳金章教授、賴文能教授、
林維暘教授，慈濟李錫錕教授、中研院呂俊賢博士等討論相關學術問題。 
與會期間本人於 6月 24日下午 16:30-18:00擔任 TU-PM2-P1 Application I (Poster)場次之主
席，該場次共有 11 篇壁報論文發表，其中包括一篇防手震之論文  “A Robust Video 
Stabilization System By Adaptive Motion Vectors Filtering” (與本人口頭發表論文主題相同)，
並當面向作者請教相關問題；本人並於  6 月 25 日上午於 WE-AM1-L2 Application II 
(Lecture)場次(10:30-12:30)以口頭發表論文該場次第一篇 “Foreground Stabilization of Image 
Sequences” (10:30-10:50)，演講結束後反應頗為熱烈，共有 3位與會者分別提問有關如何進
行視訊品質客觀評估、影片中如有超過一個前景物件之處理、以及是否可用影像內插等相關
技術，讓手震補償後的影片解析度不會變小，並由本人逐一回覆；繼於 6 月 25 日下午於
WE-PM1-P1 H.264/Video Coding (Poster)場次 (14:30-16:00)發表壁報論文  “Using H.264 
Coded Block Patterns for Fast Inter-Mode Selection”，亦有 6位與會者前來詢問相關問題，
尤其是有關 CBP值的取得，及其與快速模式選擇的關係。 
USING H.264 CODED BLOCK PATTERNS FOR FAST INTER-MODE SELECTION 
 
Bo-Yuan Chen and Shih-Hsuan Yang  
 
Department of Computer Science and Information Engineering 
National Taipei University of Technology 
 
ABSTRACT 
 
The support of variable block-sizes, though significantly 
improves the compression efficiency, imposes a big 
computational challenge on an H.264 encoder. In this paper, 
we present a new fast inter-mode decision algorithm based 
on the coded block pattern (CBP). Specifying which blocks 
within a macroblock are uncoded, CBP is a good indicator 
of block-matching accuracy and can be used to reduce the 
rate-distortion calculation required for mode selection. 
Experimental results show that the proposed method 
achieves more than 50% reduction in computation time 
relative to the exhaustive mode search with negligible 
degradation in visual quality. Other merits of the proposed 
method include 1) no extra computation is needed for 
obtaining CBP; 2) no ad-hoc threshold is involved in the 
algorithm; 3) in contrast to the previous early-skip 
algorithm that yields very limited improvement for high-
activity videos, the proposed method is highly reliable for 
various video characteristics. 
 
Index Terms— Image sequence analysis, video coding, 
video signal processing 
 
1. INTRODUCTION 
 
H.264 is the newest video-coding standard jointly 
developed by ITU and ISO [1]. H.264 provides good video 
quality at substantially lower bit rates than previous coding 
standards. One distinguished feature of H.264 is to provide 
adaptive mode decision with flexible block sizes for motion 
estimation (ME). There are seven possible ME blocks in 
H.264, as shown in Fig. 1. A larger block of sizes 16×16, 
16×8, or 8×16 (called the macroblock types or MB types in 
this paper) can be chosen in slow-moving or homogeneous 
regions, to reduce the required computation and overhead 
information. On the other hand, a smaller block of sizes 
8×8, 8×4, 4×8, or 4×4 (P8×8 types) is preferred in detailed 
or high-motion regions to increase the matching accuracy. 
Although the adaptive mode decision effectively 
increases the compression efficiency, exhaustive search for 
the best mode demands high computation. Several methods 
based on spatial homogeneity have been proposed to reduce 
the required complexity. Lee and Jeon [2] proposed an 
early-skip decision for an uncoded macroblock to omit all 
the remaining rate-distortion calculation. They also 
proposed a selective-intra condition to avoid 
comprehensive evaluation of the intra modes. Their 
algorithm has been implemented in the H.264 reference 
software [3]. However, limited improvement is achieved for 
high-activity videos. Values or distribution of quantized 
DCT coefficients are employed in [4]-[6] as an indicator of 
the homogeneity of coding blocks. The algorithm in [7] 
determines if a macroblock is homogenous by its edge map 
using the Sobel operator. A non-homogeneous block is split 
into smaller blocks until it reaches 4×4. 
 
Fig. 1. Block types in H.264. 
 
In this paper, we present a new fast inter-mode 
decision algorithm based on the coded block pattern (CBP). 
The CBP is a compact representation of zero blocks and 
can be regarded as the accuracy of motion estimation. More 
zero blocks within a macroblock imply a better chance of 
MB types. Note that a predicted CBP value is inherently 
calculated for each macroblock of size 16×16 before 
estimating the rate-distortion cost. In addition, no ad-hoc 
threshold is involved in the algorithm. Experimental results 
show that the proposed CBP-based fast algorithm assumes 
very high accuracy and provides consistently good 
performance for videos of various characteristics. The 
proposed method achieves twice reduction in ME time as 
compared to the Lee and Jeon’s early-skip algorithm [2] 
with unnoticeable degradation in visual quality. 
The rest of this paper is organized as follows. In 
Section 2, the H.264 inter-mode selection and coded block 
pattern are introduced. The proposed algorithm is presented 
and analyzed in Section 3. The simulation results are given 
in Section 4, followed by some concluding remarks. 
 
Table I. Best mode distribution for foreman (QCIF, QP =28). 
The value indicates the number of counts. 
CBP 0,16,32 1,2,4,8 15,31,47 others 
SKIP 2898 279 1 106 
MB 4838 1620 211 1834 
P8x8 444 547 369 1555 
sum 
% in total 
8180 
55.64% 
2446 
16.64% 
581 
3.95% 
3495 
23.77%
 
3.2. Enhanced Version: CBPMD_LJ 
 
Lee and Jeon’s Early-SKIP algorithm [2] aborts the RDcost 
evaluation for zero macroblocks (CBP = 0) with motion 
vector equal to the PMV (predicted motion vector) in the 
previous frame. They also propose the Selective-Intra 
condition that calculates the average boundary error (ABE) 
between the current macroblock and its adjacent 
macroblocks. When ABE is larger than the average rate 
(AR), INTRA-modes will be neglected. Their algorithm 
was found effective and was included in H.264 reference 
software [3]. We have thus seamlessly incorporated their 
algorithm with the proposed CBPMD method. The 
combined algorithm, called CBPMD_LJ, is shown in Fig. 3. 
We then verify the precision of three branching 
conditions in CBPMD_LJ, a) Early-SKIP, b) Check-MB, 
and c) Check-P8×8, averaged over QP = 28, 32, 36, 40. 
The results in Table II confirm the high accuracy of 
Early-SKIP and Check-MB. The resolution of test 
sequences used in this paper is also given in Table II. 
 
 
Fig. 3. The CBPMD_LJ algorithm. The shaded portion was 
developed by Lee and Jeon [2]. 
TABLE II. Precision of CBPMD_LJ branching conditions. 
Sequence Resol-ution
p(SKIP | 
Early-SKIP) 
p(MB | 
Check-MB)
p(P8×8 | 
Check-
P8×8) 
foreman 94.93% 93.70% 35.49% 
carphone 97.16% 93.28% 53.44%
news 
QCIF
98.94% 92.16% 58.54%
tennis 97.13% 88.14% 36.89%
football 95.07% 91.26% 48.49%
garden 92.04% 87.14% 58.56% 
mobile 
SIF
86.38% 89.89% 68.13%
hall_monitor 98.64% 91.52% 54.79%
container 98.91% 96.20% 53.16%
coastguard 
CIF
93.57% 93.19% 27.23%
Average 95.28% 91.65% 49.47%
 
4. EXPERIMENTAL RESULTS 
 
The proposed algorithm is incorporated into H.264 
JM10.2 [3] for simulation. Some of the important 
simulation parameters are listed below:  
a) Profile: Baseline, 
b) Number of reference frames: 5, 
c) RDO (Rate-distortion optimization): on, 
d) Motion vector resolution: 1/4 pixel, 
e) Search range: 32, 
f) Fast motion estimation [9]: on. 
The rate-distortion performance is objectively evaluated by 
BDPSNR and BDBR [10]. The computational complexity 
is measured by the Speed-Up rate (in percentage) defined 
below 
100%
Time
Time-Time
Up-Speed
org
proposedorg ×=           (3) 
All the experiments are conducted on a PC with Intel 
Pentium-IV 2.80 GHz CPU and 1 GB RAM. Note that 
using CBP incurs no extra computation time because CBP 
is inherently calculated for each macroblock before full 
RDcost evaluation.  
The CBPMD and CBPMD_LJ algorithms are 
compared with Lee and Jeon’s algorithm [2] relative to the 
optimal mode selection. The rate-distortion and speed 
performance results, averaged over QP varying in the set 
{28, 32, 36, 40}, are shown in Tables III and IV. It is 
observed from Table III that the incurred loss of 
CBPMD_LJ is almost unnoticeable with average BDPSNR 
and BDBR equal to 0.035dB and 0.79%, respectively. The 
CBPMD algorithm alone surpasses the Early-SKIP 
algorithm by almost twice reduction in ME (motion 
estimation) time (43% to 23%). This margin is especially 
significant for videos with fast-moving or complex scenes, 
where tiny improvement is achieved with Early-SKIP. The 
combined algorithm CBPMD_LJ achieves an average 51% 
reduction in time and CBPMD_LJ is reliable that the 
FOREGROUND STABILIZATION OF IMAGE SEQUENCES 
 
Shih-Hsuan Yang and Pei-Cheng Huang  
 
Department of Computer Science and Information Engineering 
National Taipei University of Technology 
 
ABSTRACT 
 
Hand jitters result in unintentional fluctuation of image sequences taken by hand-held video cameras. Stabilization of the 
foreground object of interest in pictures is essential for good visual quality. In this paper, foreground stabilization algorithms 
of image sequences are proposed and evaluated. After performing the block-based motion estimation, grouping techniques 
are used to identify the foreground motion. The tested grouping techniques include the iterative centroid of foreground, the 
k-means clustering, and the LMedS (Least Median of Squares) algorithms. An adaptive IIR filtering technique is 
subsequently applied for motion correction. Compared to conventional stabilization techniques without foreground 
separation, the proposed methods substantially improve the visual quality of image sequences both subjectively and 
objectively. 
 
Index Terms— Image motion analysis, pattern clustering methods, video cameras, video signal processing 
 
1. INTRODUCTION 
 
The popularity of video phones and mini-DVs has made video shooting a joyful and simple task. However, shooting with 
these handy cameras usually suffers the unwanted camera vibrations. Image sequence stabilization (ISS) is the technology to 
minimize the unpleasant fluctuation of image sequences due to hand jitters. ISS can not only raise the visual quality but also 
improve the compression efficiency [1]. ISS is fulfilled in two major processes: motion estimation (ME) and motion 
correction (MC), as shown in Fig. 1. The ME process finds the global camera motion from the image sequences. The MC 
process identifies the camera shake from the global camera motion and counteracts it.  
 
Fig. 1. An ISS system. 
 
For most image sequences taken by a video phone or mini-DV, there is a major foreground object (e.g., a person) in the 
middle. Since the foreground object is the major focus of interest, its stabilization is essential for good visual quality. 
Furthermore, conventional stabilization techniques that extract features from the whole picture or background may fail to 
give satisfactory results due to the possibly blurred background. In this paper, we propose and investigate several grouping 
techniques to extract the foreground motion for ISS.  
Although object detection has been an active research topic [2], few approaches have actually applied to ISS. In [3], the 
foreground and background were determined by priori knowledge. Pan and Ngo [4] assumed a Gaussian mixture model for 
objects and applied expectation maximization to calculate the affine parameters associated with objects. This approach is 
very computation expensive. In this paper, we proposed more realistic techniques for identifying the foreground motion. 
These techniques include the iterative centroid of foreground, k-means clustering, and LMedS algorithms, and they will be 
evaluated by accuracy and computational complexity. 
The rest of this paper is organized as follows. In Section 2, the overall ISS framework used in this paper is introduced. 
The proposed grouping algorithms for foreground motion estimation are presented in Section 3. The motion correction 
mechanism is introduced in Section 4. Simulation results are given in Section 5, followed by some concluding remarks. 
 
2. OVERVIEW OF THE ISS FRAMEWORK  
The flowchart of the proposed ISS framework is depicted in Fig. 2. Block-based motion estimation is first used to generate 
the local motion vectors (LMVs), which indicate the displacement between an input block (of size 8×8) and the found match 
in the previous frame. The blocks are equally spaced, as shown in Fig. 3 and consequently 17×13 = 221 LMVs will be 
produced for an image of size 320×240. Full search with full-pixel resolution is taken over the whole search range to achieve 
the required reliability of motion. 
 
Fig. 3. Block-based motion estimation. 
 
Since some of the obtained LMVs are “noisy”, three qualifying tests, namely “Lack of Features”, “Low SNR”, and 
“Repeated Patterns” are used to remove the ill-conditioned LMVs [5]. After removing these outliers, the LMVs belonging to 
the foreground will be identified by the grouping algorithms explained in the next section. The median of the identified 
foreground LMVs is taken as the foreground global motion vector (GMV). The hand jitters will be estimated and 
counteracted by the motion correction process to be explained in Section 4.  
There usually exists a major foreground target for pictures shot by handheld video cameras. One example is shown in 
Fig. 4, where the doll is the object of interest. Most photographers will keep the object of interest in the center of the picture 
with a reasonably large portion. Compared with the rather complex background, the foreground is more suitable for 
obtaining coherent camera motion. Furthermore, in most cases reducing the jiggling with respect to the foreground (like a 
walking person) will be more beneficial to visual quality. The major improvement of this paper from our previous work [1] is 
to use various MV grouping techniques to extract the foreground motion. 
  
Fig. 4.  Valid motion vectors (green: foreground, red: background).  
Step 1 (Initialization): Collect all the valid LMVs in the pre-determined foreground region RFG shown in Fig. 7. Denote this 
set as C. 
Step 2: Randomly select three vectors from C. Find the coordinates of corresponding block centers. Plug these three pairs of 
coordinates into (1) and solve the motion parameters a1, a2, . . ., a6. The other vectors in C are called the non-selected vectors 
and the corresponding block is called a non-selected block. 
Step 3: Use the LMV for a non-selected block Bi in frame n-1 to obtain its position in frame n. Also, apply the motion model 
(1) to Bi and find its position in frame n. Calculate the squared error of these two positions. Repeat the above procedure for 
the other remaining non-selected blocks in C. 
Step 4: Take the median of the squared errors gathered in Step 3. 
Step 5: Repeat the iteration (Steps 2-4) 100 times. Choose the estimated affine parameters for which the median of the 
squared errors is minimal. Apply the obtained parameters to the central block to obtain the coordinates in frame n. The 
coordinate difference is the required GMV. 
There are two variants of LMedS used in this paper. 
(1) Method 3: Foreground-only LMedS (F-LMedS) 
In Step 1, use only the vectors in the pre-determined foreground region RFG. 
(2) Method 4: Iterative LMedS (I-LMedS) 
Step 5’: After the motion parameters are obtained, find the coordinates v  in frame n of the spatial-centroid block.  
Step 6: Replace C with the valid LMVs that are within Tr-radius of .v  (Tr = 4.5)  
Step 7: Take v  as the GMV if the process converges (or it has already been 5 times); go back to Step 2 otherwise. 
 
4. MOTION CORRECTION 
 
One of the central tasks of ISS is to separate hand jitters from the estimated global camera motion. In contrast to the 
intentional camera movement that tends to be steady in velocity, hand jitters are usually small and fluctuating in amplitude. 
In this paper, an adaptive IIR filtering technique adapted from [1] (without 2D compensation) is employed. An interested 
reader can refer to [1] for more details. 
A good motion correction algorithm should generate a smooth motion vector (SMV) that resembles the intentional 
camera movement. The used method calculates SMV in the form of first-order autoregression,  
SMV(n) = α SMV(n-1) + (1- α)GMV(n). (2) 
(0 ≤ α ≤ 1) where the index n indicates the frame number. This first-order IIR filter incurs little delay and requires little 
memory. The parameter α can be regarded as the smoothing factor. A larger value leads to a smoother, but perhaps 
artificially stabilised, image sequence. It is noted that a fixed value of α  hardly leads to good stabilised image sequences. To 
avoid the lag of intentional movement, the following adaptation mechanism of α is used, 
DV(n) = GMV(n) – SMV(n-1).   (3) 
If (DV(n)>T1 and DV(n-1)>T2 and DV(n-2)>T3) or  ((DV(n)<-T1 and DV(n-1)<-T2 and DV(n-2)<-T3) 
    α = 0.1 
else    α = 0.9  (4) 
where T1, T2, and T3 are pre-determined thresholds usually in decreasing magnitude.  
After SMV is calculated through (2)-(4), the hand-jitter motion vector, HMV, is obtained by 
HMV(n) = GMV(n) - SMV(n).  (5) 
To restore the current frame to its stabilised position, we offset the current frame by the accumulated hand-jitter motion 
vector, AMV, defined by 
∑ == n mi in )(HMV)(AMV       (6) 
where m is the first frame since the last scene change. 
 
5. EXPERIMENTAL RESULTS 
 
The proposed methods are evaluated against 5 test sequences taken by a video phone, with a frame rate of 15 fps. The 
characteristics of these sequences are listed in Table I. The resolution of the original images is 320×240, and that of the 
stabilized images is 260×200. In all the images sequences, there is a major foreground object around the center of the images. 
All the video has some degrees of hand jitters. Sequences A and D suffer further from the keystroke; sequence B has a 
significantly blurred background. 
Table II. RMSE comparisons (search range = 8). 
Seq. No ISS 
ref. 
[1] 
Method 
1 
Method 
2 
Method 
3 
Method 
4 
A 3.04 1.43 1.12 1.19 0.77 1.17 
B 2.81 1.12 0.94 1.03 0.90 0.65 
C 0.77 0.69 0.67 0.65 0.45 0.47 
D 3.44 2.45 1.12 1.14 1.14 1.31 
E 4.26 2.17 1.76 2.01 2.30 1.73 
Table III. RMSE comparisons (search range = 16). 
Seq. No ISS 
ref. 
[1] 
Method 
1 
Method 
2 
Method 
3 
Method 
4 
A 3.04 1.37 1.08 1.10 0.74 0.95 
B 2.81 1.54 0.92 1.23 1.14 1.20 
C 0.77 0.68 0.64 0.67 0.45 0.46 
D 3.44 2.32 1.09 1.10 1.03 1.38 
E 4.26 1.70 1.26 1.24 1.20 1.34 
 
6. CONCLUSION 
 
Foreground stabilization methods have been proposed and evaluated in this paper. These methods generally provide 
significantly better performance than conventional global or background stabilization approaches, and are suitable for the 
handheld video camera applications. Among the evaluated methods, the F-LMedS algorithm achieves the minimal RMSE 
while the clustering methods achieve comparable results with much less computational cost. 
 
ACKNOWLEDGEMENT 
 
This work was supported in part by Reallusion, under the collaboration project “Image Sequence Stabilization for Video 
Phones”. 
 
REFERENCES 
 
[1] S.-H. Yang, F.-M. Jheng, and Y. C. Cheng, “Two-dimensional adaptive image stabilisation,” Electronics Letters, vol. 43, no. 8, pp. 
446-448, April 2007. 
[2] Y. Wang, J. Ostermann, and Y. Q. Zhang, Video Processing and Communications, Prentice Hall, 1st edition, 2001. 
[3] A. Engelsberg and G. Schmidt, “A comparative review of digital image stabilizing algorithms for mobile video communications,” 
IEEE Trans. Consumer Electron., vol. 45, no. 3, pp. 591-597, Aug. 1999. 
[4] Z. Pan and C. W. Ngo, “Selective object stabilization for home video consumers,” IEEE Trans. Consumer Electron., vol. 51, no. 4, pp. 
1074-1084, Nov. 2006. 
[5] S.-H. Yang and F.-M. Jheng, “An adaptive image stabilization technique,” In Proceedings of the IEEE International Conference on 
Systems, Man, and Cybernetics (SMC2006), pp. 1968-1973, Oct. 8 - Oct. 11, 2006. 
[6] S. Araki, T. Matsuoka, N. Yokoya, and H. Takemura, “Real-time tracking of multiple moving object contours in a moving camera 
image sequence,” IEICE Trans. Inf. & Syst., vol. E83-D, no. 7, pp. 1583-1590, Jul. 2000. 
次介紹發表論文的題目與發表者，並引導論文發表結束後的答詢。進行到補發表論文第二篇
時 Prof. Schatter終於到場（他也是論文發表者之ㄧ），於是我將最後兩篇論文（包括我報告
的論文）交給他主持。我發表的論文題目是 An Improved H.264 Fast Inter-Mode Decision 
Algorithm，我大約用了 15分鐘介紹論文的背景、動機、演算法、實驗結果與未來展望，其
後詢答時 Dr. Ghanbari問了兩個問題，一個為演算法在高編碼碼率下之侷限與改進方式，另
一個為論文中同位巨區塊的定義，並由本人逐一回覆。本場次最後在下午 3 時 40 分順利結
束，與會人士繼續到擺設下午茶的大廳進行開放式討論。 
   
     論文發表演講廳 G.C. Lecture Theatre外留影  口頭報告論文發表現場 
本人於 7月 14日與 7月 15日繼續參加大會各項活動，與世界各地之專家學者進行面對
面交流，其間並與國內學者高雄第一科大黃承龍副教授、淡江大學蕭富元助理教授等討論相
關學術問題。會議於 7月 15日中午結束。本人於 7月 17日由英國倫敦希斯洛機場，搭乘長
榮航空 BR068班機，經約 18小時之飛行，於 7月 18日晚間返抵國門。 
 
五、與會心得 
EuroIMSA 2009 為一個小型的國際研討會，總共發表篇數僅約 30 篇，論文作者遍及世
界各地，其中台灣佔了 5 篇為各國之冠。在同一地點（劍橋大學 Fitzwilliam College）有另
外兩個 IASTED的國際研討會一起舉辦，使整個會場的人氣稍能維持。除了一般的學術性論
文之外，有許多發表論文重視實做上的貢獻，為學界與產官研合作的成果，或為我們注重
SCI 論文之餘，也應該努力的方向。由於會議的主題相當廣泛，同一 Session 的論文彼此的
歧異仍大，但也可以因此吸收到不同領域的新知。研討會上的詢答討論氣氛熱烈，與台灣一
般研討會冷清、靠 Session Chair問問題撐場面的情形頗不相同，值得學習。 
本人主要專注於影像編碼與傳輸之論文，在會場中與世界各地專家學者當面討論相關問
題，獲得諸多寶貴建議與經驗。最後，本次會議之會場交通不便，另有許多論文作者並未出
席發表論文(no show)，是較為可惜之處。 
 
六、附件 1：發表之論文，附件 2：Session Chair證書。 
 
 
and temporally adjacent macroblocks to reduce the search 
set of the optimal mode. Kim et al. [5] determine the 
candidate modes from the most correlated MB in the 
previous frame. An adaptive threshold is required to 
validate the proposed statistical inference. Shen et al. [6] 
use the sum absolute difference (SAD) of each 4×4 block 
and the texture characteristic to reduce the set of 
candidate modes. Observing that more zero blocks for 
residual coding imply a higher probability of M-type 
partitioning, Chen and Yang [7] propose using coded 
block patterns (CBP) for fast mode selection. Their 
method achieves twice reduction in ME time as compared 
to the Early-SKIP algorithm [3] and the overall 
performance is comparable to [4]. It should be noted that 
both [4] and [7] include the Early-SKIP condition in [3] 
as a part of their algorithm. 
 
In this paper, we extend the CBP-based method in [7] 
with the mode of the co-located macroblock. The CBP is 
a syntax element in the H.264 macroblock layer, which 
specifies which of the six 8×8 blocks after motion 
estimation requires residual coding. The co-located 
macroblock is the macroblock of the same position in the 
previous frame. The CBP value and the coding mode of 
the co-located macroblock can be used to predict the most 
plausible inter-mode of current macroblocks. We 
extensively evaluate accuracy and efficiency for each of 
the simplifying criteria, and incorporate them into the fast 
mode-decision algorithm. Compared with the state-of-the-
art approaches in the literature [4]-[7], the proposed 
method provides comparable or better results with more 
elegant expediting criteria.  
 
The rest of this paper is organized as follows. In Section 2, 
H.264 inter-mode selection and CBP are investigated. 
The proposed algorithm is presented and analyzed in 
Section 3. The simulation results are given in Section 4, 
followed by the concluding remarks. 
 
 
2.  H.264 Inter-Mode Selection 
 
2.1 H.264 Rate-Distortion Optimization Function 
An optimal H.264 encoder chooses the best mode in the 
rate-distortion minimization sense. The H.264 RDcost 
function can be expressed as a Lagrange cost function J 
shown below 
)|MODE,,( MODEcsJ λ  
)MODE,,()MODE,,(SSD csRcs MODE ⋅+= λ  (1)
where SSD denotes the sum of the square differences 
between the original blocks s and its reconstruction c, 
MODE indicates the selected mode from the candidate set 
{SKIP, 16×16, 16×8, 8×16, 8×8, 8×4, 4×8, 4×4, Intra16, 
Intra4}. R(s, c, MODE) is the number of bits associated 
with the examined mode. SSD, R(s, c, MODE), and the 
Lagrange multiplier λMODE are notably implicit functions 
of the quantization parameter QP, which is a variable 
used for scaling transform coefficient levels [1]. It has 
been observed [4]-[7] that the simplest SKIP and 16×16 
modes dominate the best mode for typical QP values. To 
expedite the mode decision, macroblocks pertaining to the 
SKIP mode or macroblock types should be identified 
without full RDcost evaluations. In this paper, we will use 
the shorthand notation J(mode) to denote the RDcost of a 
specific mode. For instance, J(16x16) represents the 
RDcost of the 16×16 mode.  
 
2.2 H.264 Coded Block Patterns 
The Coded Block Pattern (CBP) is a syntax element in the 
H.264 macroblock layer, which specifies which of the six 
8×8 blocks (for 4:2:0 subsampling) may contain non-zero 
transform coefficient levels [1]. A CBP consists of six 
bits b5b4b3b2b1b0, where b3b2b1b0 
(CodedBlockPatternLuma) individually specifies the 4 
luma blocks and b5b4 (CodeBlockPatternChroma) jointly 
specifies the 2 chroma blocks, as shown in Fig. 2. Some 
CBP examples and their implications on mode decision 
are given below: 
• CBP = 0 (000000). All the luma and chroma 
blocks are uncoded, which implies that 16×16 
motion estimation is very accurate. If this 
macroblock is not skipped, it is very likely to be 
of m types. 
• CBP = 1, 2, 4, or 8. in this case, only one of the 
four luma blocks (and no chroma blocks) requires 
residual coding. The probability of choosing m 
types is high. 
• CBP = 16 or 32. the luma blocks are uncoded 
while some chroma blocks require residual coding. 
The probability of choosing m types is still high. 
• CBP = 15, 31, or 47. in this case, all the luma 
blocks are nonzero. Therefore, m-type motion 
estimation is hardly satisfactory. Sub-macroblock 
types will be needed for a better match. 
 
 
FIGURE 2 - BIT ASSIGNMENT OF CBP. 
 
To calculate the RDcost of a 16×16 macroblock, the 
residual macroblock after performing 16×16 motion 
estimation are divided into sixteen 4×4 blocks, and each 
of them is transformed and quantized. The predicted 
 
Figure 3 - Flowchart of the proposed algorithm. 
 
 
4.  Experimental Results 
 
The proposed algorithm is tested on the H.264 JM13.2 
reference software [9] where the rate-distortion 
optimization (RDO) is turned on (JM RDOptimization 
= 2). The motion vector resolution is set to be 1/4 pixel 
and the built-in fast motion estimation (hybrid 
Unsymmetrical-cross Multi-Hexagon-grid Search strategy, 
UMHexagonS [10]) is employed (JM SearchMode = 1). 
The speed-up performance of a fast inter-mode algorithm 
is measured by its total encoding time savings percentage 
(TS) compared to the original optimal mode selection 
with exhaustive RDcost evaluations: 
100%
Time
TimeTime
TS
original
proposedoriginal ×−=      (2) 
The rate-distortion performance is measured in terms of 
DPSNR (differential PSNR) and DBR (differential bit 
rate) that indicate the average differences in PSNR and 
bit rate relative to the optimal mode selection, 
respectively. A negative value in DPSNR implies quality 
degradation while a positive value in DBR implies a rate 
increase for an investigated method. In the following, we 
extensively compare the proposed method with the state-
of-the-art approaches in the literature. The comparisons 
are individually made because different coding 
parameters are adopted in each of the evaluated schemes. 
 
We first compare our method with [4] and [7], and the 
results are shown in Table II. The simulation is conducted 
in H.264 Baseline profile with five reference frames and 
search range equal to ±32 pixels. The results are averaged 
over the first 100 frames of each test sequence. All the 
three methods incorporate the Early-SKIP and Selective-
Intra conditions [3] that have been implemented in the 
H.264 JM reference software [8], [9]. The Selective-Intra 
condition compares the average boundary error (ABE) 
between the current macroblock and its adjacent encoded 
macroblocks, and the average number of bits required to 
encode the residual block under the best inter mode (AR). 
When ABE is larger than AR, all INTRA-modes will be 
neglected. Three extra criteria are introduced in [4] based 
on the relationships among J(16×16), J(8×8), and J(4×4) 
of the current macroblock and its spatially and temporally 
adjacent macroblocks. For instance, the coding mode is 
restricted to M types if J(16×16) of the current 
macroblock is less than the average J(16×16) in the 
previous slice. On the other hand, Ref. [7] (our previous 
work) is a pure CBP-based approach. The rate-distortion 
performance in Table III is objectively evaluated by 
BDPSNR (Bjøntegaard Delta PSNR) and BDBR 
(Bjøntegaard Delta Bit Rate) [11] from the rate-distortion 
curves for QP varying in the set {28, 32, 36, 40}. It is 
observed from Table II that the proposed method 
consistently provides higher time savings (more than 10%) 
with negligible loss in BDPSNR and BDBR. 
 
We next compare our method with [5] and the results are 
shown in Table III. The simulation is conducted in H.264 
Main profile with the IPPP GOP (group of pictures) 
structure, where the first 200 frames of each test sequence 
are used. Only one reference frame is used, and the 
search range is set to ±16 pixels. The tracking-MB 
algorithm in [5] first determines the most correlated MB 
in the previous frame using an integer-pixel 16×16 
motion estimation. If the most correlated MB has a 
sufficiently high correlation with the current MB (with a 
overlapping area larger than an ad hoc threshold τ), this 
most correlated MB is called the “tracked MB”. The 
mode of the tracked MB determines the candidate modes 
of the current MB, and the RDcost of the tracked MB is 
used as a decision threshold. The TS, DPSNR, and DBR 
of the two algorithms are evaluated over three QP values 
24, 28, and 32. The proposed method provides slightly 
more time savings than Ref. [5] especially for larger QP 
values. 
 
Finally we compare our method with [6] and the results 
are shown in Table IV. The simulation is conducted in 
H.264 Main profile with the IPPP GOP structure, where 
the first 150 frames of each test sequence are used. 
Moreover, CABAC (Context Adaptive Binary Arithmetic 
Acknowledgements 
 
The work is supported by the National Science Council, 
R.O.China, under the Grant NSC 95-2221-E-027-028-
MY3. 
 
References 
 
[1] ISO/IEC International Standard 14496-10, 
Information technology – Coding of audio-visual 
objects – Part 10: Advanced Video Coding, third edition, 
Dec. 2005, corrected version, March 2006. 
[2] G. J. Sullivan and T. Wiegand, Video compression - 
from concepts to the H.264/AVC standard, Proceedings 
of the IEEE, 93(1), 2005, 18-31. 
[3] J. Lee and B. Jeon, Fast mode decision for H.264, 
IEEE International Conference on Multimedia and Expo, 
Taipei, Taiwan, 2004, 1131-1134. 
[4] C. Grecos and M. Yang, Fast mode prediction for the 
baseline and main profiles in the H.264 video coding 
standard, IEEE Trans. Multimedia, 8(6), 2006, 1125-1134. 
 
[5] B.-G. Kim, Novel inter-mode decision algorithm 
based on macroblock (MB) tracking for the P-slice in 
H.264/AVC video coding, IEEE Trans. Circuits Syst. 
Video Technol., 18(2), 2008, 273-279.  
[6] L. Shen, Z. Liu, Z. Zhang, L. Wang, and G. Wan, 
Novel intermode decision algorithm in H.264/AVC, 
Journal of Electronic Imaging 17(1), 2008, 013006. 
[7] B.-Y. Chen and S.-H. Yang, Using H.264 coded block 
patterns for fast inter-mode selection, IEEE International 
Conference on Multimedia & Expo, Hannover, Germany, 
2008, 721-724. 
[8] K.-P. Lim, G. Sullivan, and T. Wiegand, Text 
description of joint model reference encoding methods 
and decoding concealment methods, STUDY OF 
ISO/IEC 14496-10 and ISO/IEC 14496-5 / AMD6, 
Document JVT-O079, April 2005.  
[9] H.264/AVC Software Coordination, 
http://iphome.hhi.de/suehring/tml/. 
[10] Z. Chen, P. Zhou, and Y. He, Fast Integer Pel and 
Fractional Pel Motion Estimation for JVT, JVT-F017, 6th 
JVT Meeting, Awaji Island, Japan, Dec. 2002 
[11] G. Bjøntegaard, Calculation of average PSNR 
differences between RD-curves, ITUT-T Q6/SG16, Doc. 
VCEG-M33, Apr. 2001. 
 
TABLE II. Performance comparisons with CBPMD_LJ (Chen and Yang [7]) and ref. [4] (Grecos and Yang). 
(TS and BDBR in %, BDPSNR in dB) 
Proposed Method CBPMD_LJ [7] Grecos and Yang [4]  QP = 28, 32, 36, 
40 TS BDPSNR BDBR TS BDPSNR BDBR TS BDPSNR BDBR
Foreman 74.7 -0.08 1.57 59.2 -0.06 1.25 58.2 -0.09 0.08 
Container 86.8 -0.06 1.37 79.7 0.01 0.28 79.3 0.02 -0.74 
Carphone 75.6 -0.14 2.84 61.8 -0.06 1.10 61.4 -0.10 -0.12 
News 82.7 -0.11 1.95 71.9 -0.05 0.80 73.2 -0.09 0.35 
QCIF 
Silent 82.2 -0.08 1.73 68.0 -0.06 1.14 67.7 -0.04 0.18 
Foreman 72.7 -0.15 3.27 59.5 -0.08 1.67 60.0 -0.11 0.30 
Container 85.3 -0.05 1.17 75.3 -0.02 0.38 - - - 
Hall_Monitor 81.7 -0.07 1.90 71.6 -0.03 0.73 - - - 
Tempete 66.0 -0.06 1.47 49.2 -0.03 0.66 55.3 -0.03 -0.40 
CIF 
Coastguard 59.6 -0.05 1.39 41.2 -0.03 0.95 51.4 -0.03 -1.67 
 Average (of 8 common seq.) 75.0 -0.09 1.95 61.3 -0.05 0.98 63.3 -0.06 -0.25 
