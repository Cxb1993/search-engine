戶外停車場空位自動偵測系統 
計畫編號：100-2221-E-009-149-  
執行期限：2011.08.01 至 2012.07.31 
主持人：王聖智 (交通大學電子工程系教授) 
計畫參與人員：廖姿婷、羅介瑋、姜政銘、蔡秉宸、謝佳峻 (交通大學電子所研究生) 
 
中文摘要 
 在本計畫中，我們提出了一套停車場空
位偵測系統。與一般以車輛偵測導向或是空位
偵測導向的方法不同，我們是以停車場為導
向。在我們系統中，我們將停車場視為多平面
組成的架構。在這樣的架構中，為了推論空車
位，我們提出了一套基於表面階層的架構，整
合三度空間資訊與區塊式的影像觀測。為了增
強系統穩定性，我們使用Histogram of Oriented 
Gradients (HOG)進行區塊的特徵向量擷取。將
這樣的特徵向量整合至系統中，我們可以有效
的透過最佳化推論停車場的狀態，特別是針對
一些困難的處理情況如遮蔽現象，光影問題，
三度空間失真問題以及光照狀況不佳的白天
或是夜晚情形。 
關鍵詞：停車位偵測、基於表面的偵測、方位
梯度統計、貝氏推論。 
 
Abstract 
We proposed a surface-based vacant 
parking space detection system. Unlike many 
car-oriented or space-oriented methods, the 
proposed system is parking-lot-oriented. In the 
system, we treat the whole parking lot as a 
structure consisting of plentiful surfaces. A 
surface-based hierarchical framework is then 
proposed to integrate the 3-D scene information 
with the patch-based image observation for the 
inference of vacant space. To be robust, the 
feature vector of each image patch is extracted 
based on the Histogram of Oriented Gradients 
(HOG) approach. By incorporating these texture 
features into the proposed probabilistic models, 
we could systematically infer the optimal 
hypothesis of parking statuses while dealing 
with occlusion effect, shadow effect, perspective 
distortion, and fluctuation of lighting condition 
in both day time and night time. 
Keywords: Parking space detection; 
Surface-based detection; Histogram of Oriented 
Gradients; Bayesian inference 
 
1. INTRODUCTION 
In practice, the major challenges of vision-based 
parking space detection come from the occlusion 
effect, the shadow effect, the perspective 
distortion, the fluctuation of lighting change, and 
detection in nighttime. Nowadays, to overcome 
those difficulties, many methods have been 
proposed. These approaches can be classified 
into two categories: car-oriented methods and 
space-oriented methods.  
For car-oriented methods, thanks to the progress 
of object detection [1-2], many algorithms 
utilized texture features, such as Histogram of 
Oriented Gradients (HOG), to overcome the 
lighting change and the geometry distortion 
during targets detection. Generally, those 
methods perform well even under environmental 
variations. However, for the task of vacant space 
detection in a parking lot, the car-oriented 
methods may not work as robust as we expected 
contrast, the space-oriented approaches, which 
were designed to analyze the texture of the 
image area corresponding to a vacant parking 
space, can better handle the perspective 
distortion by adding 3-D scene information. 
Hence, if we can find a way to benefit from both 
kinds of approaches, we may achieve robust 
performance.  
In terms of car-oriented approaches, systems 
usually check the image area, as shown in Figure 
1(a), to check the existence of a car. As for the 
space-oriented approaches, the pixel-based or 
texture-based feature inside the region of a 
parking space is used for analysis, as shown in 
Figure 1(b). In comparison, our approach treats 
the parking spaces as a set of cubes, as 
illustrated in Figure 1(c). Each cube is composed 
of six patches like Figure 1(d). If looking into 
the details, we may find that the ground plane of 
a parking space is the ground patch, while a car 
is made up of patches. Thus, we suggest using 
surfaces to represent the parking lot structure so 
that we can benefit from both the car-oriented 
and space-oriented methods. 
          (a)                    (b) 
        (c)                   (d) 
Figure 1. (a) Image area for car-level regions. (b) 
Image area for ground patches. (c) Model the room of 
a parking space as a cube. (d) The elementary planes 
for a parking space. 
 
3. SURFACE-BASED INFERENCE 
FRAMEWORK 
3.1 Image Observation 
For a structural parking lot, we may detect 
the status of each parking space by observing 
occlusion patterns inside each image patch. To 
be specific, we demonstrate various kinds of 
patterns inside different projection patches in 
Figure 2. In total, there are 14 different patterns. 
Here, owing to the regularity of occlusion 
patterns among objects, an image patch presents 
distinguishable textures for vacant space 
detection. Thus, a direct method to determine the 
parking statuses is to classify the selected 
patches into one of the 14 occlusion patterns.  
After patch classification, an important step is to 
relate the classification results to the statuses of 
spaces. To achieve the goal, we related the 
classification results to 14 status-related 
classification labels in the form of “Typ_Ind”, 
where “Typ” indicates the surface type and “Ind” 
shows the index number of occlusion patterns of 
this “Typ”. The correspondence between 
occlusion patterns and labels are shown in 
Figure 2. Here, the possible surface types 
include “side (S)”, “front (F)”, “top (T)”, and 
“ground (G)” of a 3-D cube. For a surface type, 
it has two or four different occlusion patterns 
inside the observed patch. Without loss of 
generality, we assume that the patch of “T” 
surface has two possible patterns because the 
patch is mainly affected by the parking status of 
one space in our system. Note that the status of 
one space could be {vacant (1), occupied (0)}. 
On the other hand, all the other surface types 
have 4 possible patterns in that the pattern is 
affected by the statuses of two neighboring 
spaces. In other words, the 4 occlusion indexes 
indicate the 4 statuses of two spaces. Hence, for 
the ith observed patch oi, we classify it as one of 
the 14 classification labels {{S_j}j=1~4,{F_ j}j=1~4, 
{G_ j}j=1~4,{T_ j}j=1~2}. The label li of the ith 
label are enough for training. After the LDA 
process, the feature dimension is reduced from 
64 to 3, and we attain two three-dimensional 
feature sets {Xj|T_1}i=1~L and {Xj|T_2}j=1~L. Here, 
we assume the distribution of each class is a 
Gaussian function. Therefore, the likelihood 
model of a label is represented as 
1
3/2 1/2
1 1( ; , ) exp ( ) ( ) . (1)
(2 ) | | 2
TL π
−⎛ ⎞Σ = − − Σ −⎜ ⎟Σ ⎝ ⎠µ µ µX X X
 
By using the training sets {Xj|T_1}j=1~ L and {X 
j|T_2}i=1~3 L, we can estimate the mean vectors and 
covariance matrixes for the model 
_1( ; , )TL ΣX µ  
and the model 
_ 2 ( ; , )TL ΣX µ . 
 
Figure 3.  Feature distributions of 14 likelihood 
models. 
 
For all the other surface types “S”, “F”, and 
“G”, the training process is similar except that 
we use a 4-class Linear Discriminant Analysis 
and learn 4 likelihood models for each surface 
type. Thus, we totally have learned 14 models 
for the inference. Figure 3 shows that the feature 
distributions of the 14 different classes are 
well-separated after LDA process.  
If we denote the feature reduction process 
from the ith high-dimensional feature oi to the 
low-dimensional feature Xi as Xi=R(oi), we 
could define the likelihood model as  
( | ) ( ( ); , ) ( ; , ).            (2)
i i
i i i il l
p o l L R o L= Σ = Σµ µX  
 
3.3 3-D Scene Information 
Based on the local image features, we could 
classify image patches and extract the parking 
status implied by the labeling results. However, 
the extracted statuses from relevant patches may 
sometimes happen to report inconsistent statuses 
for the same space. In Figure 4, we use a 
three-space case to explain the inconsistency. In 
this example, after patch classification, the top 
patch of space “c” is labeled as T_2, which 
implies space “c” is vacant (1). On the other 
hand, the ground patch of space “c” is labeled as 
G_3, which implies both space “b” and “c” are 
occupied (0). Here, the reported statuses of “c” 
are inconsistency. To resolve the inconsistency, 
we use scene information. Based on the scene 
model, we can generate status hypotheses S. In 
our 3-space example, we have 8 hypotheses for 
spaces “a”, “b”, and “c”. Given a hypothesis, 
such as S=(1,0,0), its corresponding expected 
label set LS could be generated. Since LS and S 
are one to one mapping, to determine the 
statuses of the three spaces, we only need to 
measure the likelihoods of 8 expected label sets 
and pick the optimal one. Here, for status 
inference, we only check the possible expected 
label sets, which the labels are always consistent. 
Obviously, we do not measure the likelihood of 
inconsistent labeling combinations. Thus, the 
inconsistency is resolved. As for the likelihood 
measurement, the detail is given in the next 
section.  
 In summary, with the 3-D scene information, 
we have two benefits. First, the image patches 
for analysis are systematically selected by 
geometric projection. Note that those patches are 
overlapped. Second, once 3-D surfaces and 
image patches are related, the expected 
classification labeling passed from the scene 
layer could be used to reduce the inconsistency 
of patch labeling and enhance the performance. 
 
To assess the likelihood term ( | )Si ip o l , we use 
the trained models in equation (2). To solve the 
optimal problem in (6), an exhaustive search of S 
is workable. However, in our system, we adopt 
the standard graph-cuts technique [11-12] to 
speed up the inference of the parking status.  
 
4. EXPERIMENT RESULTS 
4.1 System Evaluation 
In our experiments, we evaluate our system in 
the outdoor parking lot. Here, we set up an IP 
camera on the roof of a building near the parking 
lot. The camera was geometrically calibrated 
beforehand and monitored the status of parking 
spaces both day and night. In the parking lot, 
there are three major blocks and 72 parking 
spaces. Figure 5 shows some images of the 
parking lot and the detection results. To evaluate 
the performance of our system, we calculate 
false positive rate (FPR), false negative rate 
(FNR), and accuracy (ACC). 
PN
NPVˆFPR =           (7) 
VN
NVPˆFNR =           (8) 
pV NN
NNCC +
+= PPVV ˆˆA         (9) 
where PN  denotes the number of total parked 
spaces, VN  denotes the number of total vacant 
spaces, PVNˆ  denotes the number of parked 
spaces being detected as vacant, PVNˆ  denotes 
the number of vacant spaces being detected as 
parked, VVNˆ  denotes the number of vacant 
spaces being detected as vacant, and PPNˆ  
denotes the number of parked spaces being 
detected as parked. 
 
(a)
 
(b)
 
(c)
 
Figure 5.  Results of vacant space detection.  
As aforementioned, there are four challenges 
for vision- based parking space detection: 
occlusion effect, shadow effect, perspective 
distortion, and fluctuation of lighting condition 
in both day time and night time. To evaluate our 
system under those conditions, we firstly divide 
a whole day into the day period (5:00~19:00) 
and the nigh period (19:00~5:00). For day time, 
we used four testing video sequences, including 
a sunny day, a cloudy day, a normal day, and a 
rainy day, to test our system. Each sequence 
presents challenging occlusion effect, shadow 
effect, perspective distortion, and lighting 
change. Moreover, we also evaluated the 
performance of detection over different blocks to 
evaluate the influence of perspective distortion. 
In Table I, we list the experimental results 
including the detection result of each parking 
block and the performance in a normal day, a 
sunny day, a cloudy day, and a rainy day. In our 
experiments, perspective distortion and weather 
changes cause little degradation. For the night 
time, we used another three video sequences for 
evaluation, which include unpredictable lighting 
change caused by car headlights as shown in 
Figure 5(c). The performance of detection over 
different blocks was also evaluated. The 
[7] K. Yamada, M. Mizuno, “A Vehicle Parking Detection 
Method Using Image Segmentation,” Electronics and 
Communications, 2001. 
[8] C.C. Huang, S. J. Wang, “A Hierarchical Bayesian 
Generation Framework for Vacant Parking Space 
Detection,” IEEE Transactions on Circuits and Systems 
for Video Technology, vol. 20, no. 12, pp. 1770-1785, 
Dec., 2010. 
[9] N. Dalal and B. Triggs, “Histograms of Oriented 
Gradients for Human Detection,” IEEE Conference on 
Computer Vision and Pattern Recognition, vol. 1, pp. 
886-893, June 2005.  
[10] Martinez, A. M. and Kak, A. C., “PCA versus LDA,” 
IEEE Transactions on Pattern Analysis and Machine 
Intelligence, vol. 23, no.  2, pp. 228-233, 2001. 
[11] Y. Boykov, O. Veksler and R. Zabih, “Efficient 
Approximate Energy Minimization via Graph Cuts,” 
IEEE Transactions on Pattern Analysis and Machine 
Intelligence, vol. 3, pp.1222-1239, 2001 
[12] Vladimir Kolmogorov and Ramin Zabih, “What 
Energy Functions can be Minimized via Graph Cuts?” 
IEEE Transactions on Pattern Analysis and Machine 
Intelligence, vol. 26, pp. 147-159, February 2004. 
[13] Ching-Chun Huang. (2010). Huang’s Projects [Online]. 
Available at  
http://140.113.238.220/~chingchun/Lotprojects.html. 
 
 
TABLE I.  SPACE DETECTION RESULTS IN DAY TIME 
#of tested spaces Proposed method  
vacant parked total FPR FNR ACC 
Normal 4937 7519 12456 0.0028 0.0097 0.9945 
Sunny 8259 3405 11664 0.0012 0.0115 0.9915 
Cloudy 5774 6250 12024 0.0022 0.0002 0.9988 
Rainy 3668 6916 10584 0.0078 0.0049 0.9932 
Block_1 6857 10017 16874 0.0012 0.0004 0.9986 
Block_2 8701 8173 16874 0.0020 0.0064 0.9955 
Block_3 7080 5900 12980 0.0034 0.0145 0.9905 
TABLE II.  SPACE DETECTION RESULTS IN NIGHT TIME 
#of tested spaces Proposed method  
vacant parked total FPR FNR ACC 
Seq_1 4592 3112 7704 0.0135 0.0294 0.9770 
Seq_2 4659 2631 7200 0.0049 0.0282 0.9803 
Seq_3 4540 2588 7128 0.0232 0.0172 0.9806 
Block_1 4480 3476 7956 0.0147 0.0221 0.9811 
Block_2 5051 2905 7956 0.0048 0.0123 0.9904 
Block_3 4170 1950 6120 0.0256 0.0434 0.9623 
100年度專題研究計畫研究成果彙整表 
計畫主持人：王聖智 計畫編號：100-2221-E-009-149- 
計畫名稱：戶外停車場空位自動偵測系統 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 1 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 1 0 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 5 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
