1以高階檢索技術及自動教學元件切割為基礎
之行動多媒體百科數位學習系統(精簡報告)
計畫編號：NSC 95－2221－E－034－007－
執行期間：95 年 08 月 01 日 至 96 年 07 月 31 日
吳宗德
中國文化大學 資訊傳播學系
中文摘要
隨著網路寬頻化的普及以及電腦處理影音多媒體資訊的能力大幅提升，人們藉由網際網路搜
尋及獲取知識的方式將不再侷限於傳統的以文字為主的檢索方式，由於圖片、聲音及影片等多媒
體的資訊內容呈現方式，相較於單純的文字敘述方式，可以更精確有效率的傳達資訊。因此多媒
體資訊的檢索需求將成為近年來資訊服務研究，例如數位學習等研究的重要課題。
在數位學習的應用中，由於以往數位教學影片製作時並無強調影片物件化的概念，多為完
整的教學影片，來自於同一來源，例如自行拍攝之影片或利用原本教學影片資源（錄影帶、VCD、
DVD 等）轉製而成，較少利用到多方的影片資源。近來由於影片分享機制成熟，許多的影片在
網路上分享流傳，於是產生了需求欲以其影片或部分片段來做為教材編輯的影片學習元件，欲使
用這些非原以教學為目的而製作的影片，作為教材部份內容時，會遇到許多困難。以欲將一段檢
索出的影片片段，製成符合 SCORM 執行環境標準的學習元件來舉例，這個過程中沒有統整影片
檢索系統與學習元件的封裝工具，利用檢索系統檢索出的影片片段所被賦予的後設資料標籤及其
內容，增加編輯者製作教材時的時間與繁複的手續。基於以上動機，本研究將發展一學習元件封
裝工具，並能夠利用檢索後產生的後設資料進行封裝，補足從影片檢索至製成學習元件間的鏈
結，並以一個行動數位學習系統來做測試。
關鍵詞：數位學習、XML、metadata。
3目前大多數的使用者對於影片的存放是將直接影片透過數位化過程儲存成數位檔案，並未包
含相關資訊可供未來以不同形式展示時利用。以數位學習為例，當教師需要將影片進行教材編輯
或是從龐大的視訊庫中找尋所需的內容(甚至是內容中的某個片段) 、從大量的視訊資料中濾出
個人所指定的視訊資料、以及從冗長的視訊中做一些綜合性的整理和瀏覽性資料時會有許多時間
和人力成本的浪費。 整合視訊自動處理技術及數位學習將會是教師製作多媒體教材的一大利器。
二、 研究目的
本研究的主要目的是希望能夠利用影片場景偵測技術，進行影片場景偵測及主要畫面的自動
判斷及擷取，以進行影片自動化分割，並快速產生影片索引及關鍵畫面，以簡化並縮短數位學習
多媒體教材的製作流程，如此便可大大減少所需的時間與人力。以影片學習元件來組成教材成為
近年來熱門討論的議題。開發影片檢索系統的研究欲跨足學習元件，而開發教學內容管理系統的
研究亦希望多媒體檢索技術能夠融入其中。本研究的問題核心在於解決兩方標準上轉換所面臨之
問題。檢索出的影片片段後設資料與描述學習元件封裝的後設資料，皆是以 XML Markup
Language 來表示，由於 XML 著重於利於程式開發的特性，皆是以文字型態來開發，相對於其他
程式語言，工具開發的支援較少也較為複雜。不同的後設資料標準，亦有相同意義的欄位，但表
示格式不盡相同。必須對標準的差異加以分析，以導出轉換模式。讓搜尋 SCORM 學習元件時，
亦可以搜尋到多媒體教材本身影片的內容（導演、劇情及人物等），亦可用所謂的 Visual Metadata
來檢索（例如 key Frames、video shots 等）。以期使用者方便對數位學習元件(Learning Objects)
內容進行搜尋及使用。
三、 文獻探討
要做到自動化視訊分析及切割，首先需要瞭解整個視訊的結構及特性，以及其偵測變化的技
術，目前大致可分為兩個領域[註 9]。一個是未壓縮的領域，也就是 Raw Data Domain，經研究
後未壓縮視訊偵測場景變化技術可用下列三種技術：1. pixel-wise comparison、2. likelihood ratio、
5面中各區域的直流值，再分別當成一個點來組成直流值的畫面，然後比較兩畫面中直流值的差
異，其中並利用了 Sliding Window 的觀念來減低因 panning 與 zooming 兩種鏡頭移動效果所產生
的錯誤判斷。判斷式如下：
1
,
( , 1) | ( , ) ( , ) |t t
i j
D t t P i j P i j  
Pt 為第 t 張的直流值畫面
( , )tP i j 為第 t 張直流值畫面的第(i,j)的值
( , 1)D t t 則為第 t 與 t+1 張畫面間的差異的絕對值總和
( , 1)D t t > 1則為突然式變化
1：臨界值。
若連續數張畫面的 ( , 1)D t t ＞ 2，其中 1> 2，且累積值大於 1，則為漸進式變化。[註 16]
1. 測量影片特徵差異法
利用影片中每格畫面間的差異性，可使用影像中特徵(像素、顏色統計值、邊緣等)計算其畫
面特徵值差異，如果差異過大超過所設定的臨界值時，此畫面為關鍵畫面。Zhang[註21]等人提
出的方法，是先將其影片中第一個畫面設定為關鍵畫面，再由開始畫面循序計算到現在畫面與關
鍵畫面間顏色統計差異(Color Histogram Difference)，若是超過所設定值則將成為新的關鍵畫面，
依此將影片中的所有關鍵畫面擷取出來。此種概念是利用影片中連續的畫面與畫面之間應會有其
相似性，若是忽然差異性過大時，表示此畫面是這段影片片段的開始畫面，也可代表此影片片段
之關鍵畫面。此類演算法於一個影片片段只取一個關鍵畫面，若是畫面間顏色統計改變不大時，
也就是有相同的顏色統計分佈時，會被誤認為相同影片片段，則此景中的關鍵畫面將不會被取出。
2. 分群(Clustering)演算法
將影片分成適當的群數，群的距離公式採用畫面顏色特徵或是其他影像特徵皆可，每群內成
員之畫面相似度高，因此可於每群內取出一張代表做為關鍵畫面。Hanjali 和Zhang[註22]利用分
群有效性分析(Clustering Validity Analysis)找出最佳群數，將最佳群數找出之後，關鍵畫面選擇
7據不同學習目的重組∕排序 SCO，並由符合 SCORM 標準的平台派送這些即時組裝的課程內容。
四、 結果與討論
VideoAnnEx annotation tool 提供了自動將鏡頭片段與包含於片段中的關鍵影格做自動分
類，能讓使用者自行定義影片的描述。首先我們先自行定義每個鏡頭（shot）的三大主要描述值，
分別為事件、背景和主體。自行定義鏡頭描述欄位結構圖如表 4.1 所示。
表 4.1. 預設鏡頭描述欄位表（以記錄片為例）
事件 背景 主體
片頭 街道 人物
片尾 商店 食物
人物訪問 建築物 動物
美食介紹 山林 植物
物品介紹 草原 人造物品
景點介紹 海洋 交通工具
故事介紹 廣場 景觀設施
串場劇情 車站 自然景觀
民俗慶典 機場 礦石
動物捕食 飯店
自然災害 遊樂場
建築工程
經由勾選描述值之後，可以利用預設事件、背景及主體，三個主要的描述值來描述一個鏡頭內容，
此外也可透過自行加註的關鍵詞來補充預設欄位的不足。因此每個鏡頭我們以一張關鍵影格作為
代表圖片，並搭配三個主要的描述值來做為影片鏡頭（shot）的內容描述，如圖 4.1 所示：
圖 4.1 影片的最小單位-鏡頭（shot）的描述介面
最後，影片鏡頭的結構描述檔案會以 XML 的檔案格式輸出。由圖 4.2 可看輸出的結果，以
FreeTextAnnotation 元素做為片段的描述，包括了片段的時間，Segments 的收集指的是所有切割
區塊的收集，這個資訊主要是針對查詢系統中所有找尋全部的影像特徵所使用。XML 具有可擴
展性、高度結構化和良好的資料組織能力，能夠有效的表達網路上各種知識，為資料的交換和處
9XML 能夠有效的表達網路上各種知識，為資料的交換和處理提供新的機制，因此 XML 將
促使網路從資訊處理階段跨越到知識管理階段。從資訊傳播的角度而言，傳播的目的在於建立收
送彼此雙方的共同性（Commonness），亦即設法共享資訊（Information）、觀念（Idea）、態度
（Attitude）或知識（Knowledge）（徐佳士，民 76 年，《大眾傳播理論》）。建立好的 XML 文件，
必須先檢測其語意或結構上有無錯誤才能進行爾後的處理。因此，剖析模組的任務便是依據 DTD
或 XML Schema 的定義，檢測文件的完構性及有效性，以便於除錯及修改。目前已有許多公司
以 API 或 ActiveX 方式提供現成的剖析器（Parser），可作為發展剖析模組之用，如 Microsoft 的
MSXML[註 25]。
我們依場景事件：『物品介紹』作為查詢值，即可以查詢出此段影片中共包含 39 筆以『物品
介紹』為描述值的鏡頭片段資料，點選關鍵影格畫面即可呼叫 MediaPlayer 播放該鏡頭片段影片，
也可透過勾選自行選擇欲播放的鏡頭片段加入播放清單中。如圖 4.5 所示：
圖 4.5 影片場景內容進階查詢
圖 4.6 為行動學習系統的展示結果：
圖 4.6 行動學習系統結果展示
【計畫成果自評】
感謝國科會支持本項專題研究計畫之執行，使本研究可以順利進行。
本專題研究成功完成下列研究：(一) 視訊壓縮域與非壓縮域特徵抽取、場景偵測、關鍵影
附件：行政院國家科學委員會補助專題研究計畫 出國報告
****************************************************
以高階檢索技術及自動教學元件切割
為基礎之行動多媒體百科數位學習系統
出 國 報 告
****************************************************
計畫類別：■ 個別型計畫 □ 整合型計畫
計畫編號：NSC 95－2221－E－034－007－
執行期間：95 年 08 月 01 日至 96 年 07 月 31 日
撰寫人：吳宗德
執行單位：中國文化大學 資訊傳播學系
2Integrating technology and education: Past, present and future
Prof. Leung Chun Ming
Vice President (Technology & Development)
The Open University of Hong Kong
Theatre
10:30-11:00 Coffee Break
11:00-12:00 Keynote Session:
From the E-learning Lab to society -- Some new progress in
e-learning
Prof. Shen Ruimin
Director
E-Learning Lab
Shanghai Jiaotong University
Bank of China Lecture
Theatre
12:15-1:30 Lunch Buffet Metropark Hotel Kowloon
1:30-5:45 Parallel Paper Presentations, Workshops and Exhibitions G28-G36
Bank of China Lecture
Theatre
DAY 2 10 July 2007 (Tuesday) St Paul's Convent School
8:15-9:00 Registration Entrance of St Paul's
Convent School
9:10-9:30 Welcome
9:30-10:30 Keynote Session:
Developing online learning communities
Prof. Binshan Lin
BellSouth Corporation Professor
College of Business Administration
Louisiana State University in Shreveport
St Paul's Convent School
Hall
10:30-11:00 Coffee Break
11:00-12:00 Keynote Session:
Facing the challenges of emerging technologies and pedagogies
Prof. David Murphy
Director
Centre for the Advancement of Learning and Teaching
Monash University, Melbourne
St Paul's Convent School
Hall
12:15-1:30 Lunch Buffet Regal Hong Kong Hotel
