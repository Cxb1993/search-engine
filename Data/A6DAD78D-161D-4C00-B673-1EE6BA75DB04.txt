 I
摘要 
數位時代的快速發展，數位媒體資料如文字、影像、聲音、影片等透過網路快速傳播，
大多數資料無使用者限制，可以廣為他人瀏覽且相當容易取得。但是在資料提供他人瀏覽、
下載、複製的過程中，無可避免的出現了舉凡被抄襲，盜用甚至被破壞等安全上的問題，
增加了數位媒體資料在安全與智慧財產權上維護的困難。數位浮水印便是一種保護數位資
料智慧財產權的技術，至今也已發展多年，但保護數位影像智慧財產權的議題依舊受到重
視，仍然有不少學者在這個領域不斷努力提出新的方法以求影像可以受到完整的保護，足
以證明這部份的研究還有更多發展的空間及其存在的必要性。本研究計畫結合空頻率轉換
法、Subsampling 技術、以及統計上的常態分配理論與特性，來建構一個可以將浮水印嵌藏
在影像中，並且可以輕易處裡黑白或灰階浮水印的著作權保護方法，我們的方法可以免除
某些方法需要仰賴公正客觀的第三者機構來做一個仲裁的缺點。 
 
關鍵詞：離散小波轉換、浮水印、常態分配理論 
 1
壹、研究背景及目的 
隨著網際網路的快速發展，已經有愈來愈多的數位資料透過網際網路來進行傳送與交
換，例如文字、影像、聲音、影片等。因為數位資料容易複製、偽造與破壞的特性，加上
網際網路的開放環境，使得數位資料的合法智慧財產權受到很大的威脅，因此，如何保護
數位資料的合法擁有權不被非法侵害已經成為一項極為重要的研究課題。近年來，已有許
多數位資料的智慧財產權保護機制相繼被提出，而數位浮水印技術(digital watermarking)即
是用來保護數位影像智慧財產權的一種方法。所謂數位浮水印技術指的就是將一組數位訊
號嵌藏在一張受保護的數位影像中，當此一數位影像的合法所有權產生爭議時，就可以透
過浮水印的擷取程序將嵌藏在影像中的浮水印取出，以證明影像的所有權。 
基本上，數位浮水印可分為可見浮水印(Braudaway et al., 1996; Chen, 2000)與不可見浮
水印(Cox et al., 1997; Low and Maxemchuk, 1998; Matsui et al., 1996; Ohbuchi et al., 1998)兩
種，可見的浮水印會直接顯現在受保護的影像上，而不可見的浮水印則是以人眼無法辨識
的方式隱藏於影像之中。在本研究中，我們將以不可見的浮水印為主要的研究探討對象。
通常，一個好的數位浮水印方法必須滿足某些要求，例如不可察覺性(imperceptibility)、強
韌性(robustness)、辨識明確性(unambiguousness)、安全性(security and keys)、高資訊容量
(capacity)、低計算複雜度(low computation complexity)等(Cox et al., 1997; Katzenbeisser and 
Petitcolas, 2000; Koch et al., 1994; Nikolaidis and Pitas, 1996)。在這些要求當中，某些條件之
間可能會存在著互相矛盾的特性，例如不可察覺性與高資訊容量的要求，就會與強韌性的
要求存在矛盾的關係，因此，在技術上經常面臨如何同時滿足所有要求的挑戰。 
在文獻上，數位浮水印技術通常可以區分為兩大類：一類為空間域的方法
(spatial-domain approaches) (Hou and Chen, 2000; Low and Maxemchuk, 1998; Ohbuchi et al., 
1998)，另一類則為頻率域的方法(transform-domain approaches) (Chang et al., 2002; Cox et al., 
1997; Hsu and Wu, 1999; Kim et al., 1999)。因為大部分的方法在嵌藏浮水印時，都必須改變
受保護的影像，因此當不只一個浮水印要被藏入影像中時，原先藏入的浮水印勢必會遭受
破壞。此外，許多的方法在取出浮水印時，都需要有原圖的協助，因此降低了方法的可用
性(availability)與可攜性(portability)。還有，因為許多方法都必須使用受保護影像上的許多
個像素來隱藏浮水印上的一個訊號，因此它所能藏的浮水印通常都不會太大，當然這些方
法是絕對不可能藏入一張比受保護的影像還大的浮水印。 
近來，許多研究針對不需破壞受保護影像的影像著作權保護機制有深入的探討，例如
Chang et al. (2002)、Chang et al. (2000)、Hwang (2000)、Chang and Chuang (2002)等。這些
方法並不像浮水印技術需要將一張浮水印嵌藏在寄主影像(host image)中，而是由受保護的
影像中，萃取出比較不易遭受攻擊與破壞的影像特徵，然後再將萃取出來的影像特徵，與
一張用來驗證所有權的影像(我們稱為所有權聲明影像)結合，產生所謂的所有權影像
(ownership share)，最後再將所有權影像交付給受信任的第三者機構，以作為驗證之用。如
果要驗證影像所有權，則再由有爭議的影像中，以同樣的方法萃取出影像特徵，再與存放
在受信任的第三者機構中的所有權影像結合，來產生可供驗證辨認的所有權聲明。因此，
在這些方法中，影像並不會遭受破壞，也不會有藏入多張浮水印時，後藏入的浮水印會破
壞先藏入的浮水印的缺點。為了與傳統浮水印的方法有所區別，在這些不需改變影像的方
法中，我們將使用“所有權聲明影像＂(“ownership statement”)這個名稱，來取代“浮水印＂
一辭。以下，我們簡單描述這些研究的作法。 
 3
(2) 取出所有權聲明影像時需要原圖協助的問題 
(3) 後來藏入的所有權聲明影像會破壞原先藏入的所有權聲明影像的問題 
(4) 所有權聲明影像大小受限於受保護影像的問題 
(5) 如何確保安全性的問題 
(6) 如何確保強韌性與辨識明確性的問題 
(7) 如何處理灰階與彩色所有權聲明影像的問題 
我們在九十五年度所通過的國科會研究計畫中，曾經試圖透過樣本均數抽樣分配的相
關理論與特性，來解決上列的問題。基本上，我們的方法同樣包含所有權影像建構階段
(ownership share construction phase)與所有權聲明影像重建階段 (ownership statement 
revelation phase)。首先，針對藏入所有權聲明影像時會改變受保護影像以及取出所有權聲
明影像時需要原圖協助的問題，我們由受保護影像中以抽樣的方式來產生樣本均數，然後
以樣本均數與所有權聲明影像的內容來產生所有權影像，以做為日後辨識所有權之用。因
為我們的方法不需改變受保護影像的內容，所以我們不但可以達成取出所有權聲明影像不
需原圖協助的目標，也可以避免後來藏入的所有權聲明影像會破壞原先藏入的所有權聲明
影像的問題。另外，針對所有權聲明影像大小受限於受保護影像的問題，我們利用放回式
隨機抽樣(sampling with replacement)的方式，由受保護影像進行抽樣來產生主控影像，由於
放回式隨機抽樣可以不限次數一直持續進行，因此主控影像的大小可以配合所有權聲明影
像的大小來建構，也就是說這個方法不會使所有權聲明影像的大小受限於受保護的影像，
因此我們就可以處理任意大小的所有權聲明影像。接著，我們利用中央極限定理(central limit 
theorem)來確保主控影像中的每一個色階都具有幾乎相同的出現機率，因此，利用我們的方
法所產生的所有權影像是非常安全的，也就是說我們不太可能由所有權影像中獲得任何有
關所有權聲明影像的訊息，所以應用我們的方法來驗證數位影像的合法所有權是值得信賴
的。最後，我們利用統計參數與特性不會因為許多常見的影像處理運算而改變的特質，使
得數位浮水印技術的強韌性與辨識明確性可以獲得確保。根據目前我們所得到的研究結
果，我們的方法在強韌性方面有不錯的表現，同時，我們也能夠輕易處理灰階與彩色影像。 
以上不需破壞原圖的影像著作權保護方法，較為人所詬病的缺點就在於沒有真正將浮
水印藏入影像中，因此整個所有權驗證的過程，必須仰賴公正客觀的第三者機構來做一個
仲裁，這一點與浮水印方法的精神相去甚遠；因此，我們希望在本年度的研究計畫中，延
續前一年度的方法，也就是透過統計上有關常態分配的相關理論與特性，來建構一個可以
將浮水印嵌藏在影像中，並且可以輕易處裡黑白或灰階浮水印的著作權保護方法，我們的
方法可以免除需要仰賴公正客觀的第三者機構來做一個仲裁的缺點。Chu (2003)曾經結合離
散餘弦旋轉換(DCT)與 subsampling 的技術來建構浮水印方法，這個方法所稱的浮水印 X = 
(x1, x2, …, xn)，是一串由標準常態分配的母體所隨機產生的亂數，因此，浮水印基本上也是
常態的，要嵌藏浮水印前，必須先利用 subsampling 的方法，將原始影像分解成四份外觀看
來相似的子影像(subimages)，接著再利用離散餘弦轉換法將每張子影像轉成頻率域係數，
然後由這四張轉換後的影像中，取這四張子影像的中頻帶的相對應位置，利用虛擬亂數隨
機抽取其中一對 DCT 係數(V1, V2)來隱藏浮水印 xi (for i = 1, 2, …, n)，其方式如下： 
 
2
)( 21 VVV += ， (1) 
假如  
 5
貳、逆向常態累積機率密度函數 
令 Z 代表平均數與標準差分別為 0 與 1 的隨機變數且其機率密度函數為 
 
2
2
1
2
1)(
Z
eZf
−= π 。 (8) 
對於 Z 的一個特定值 z 而言，我們定義 Pr(Z ≤ z) = α表示 Z ≤ z 的機率值，則 
 dZe
Zz 2
2
1
2
1 −
∞−∫= πα 。 (9) 
我們定義 Inv_NCD(α)為一個逆向常態累積機率密度函數(inverse normal cumulative density 
function)，也就是說，給定一個機率值α，則 Inv_NCD(α)可以求算出一個滿足 Eq.(9)的 z 值，
如此我們只要利用 Inv_NCD(α)這個函數就可以輕易地找到λ − 1 個切割點(partition points)， 
zr = Inv_NCD(r/λ), for r = 1, 2, …, λ − 1,  
可以將 Z 尺度切割成λ個等機率的區段。在最極端的情況下，也就是λ = 2 時，我們可以用
z1 = 0 將 Z scale 切割成兩個等機率的區段，也就是 Z < 0 與 Z ≥ 0 這兩個區段，這兩個區段
可以分別對應到黑白影相的白點與黑點；同樣地，我們也可以利用 
zr = Inv_NCD(r/256), for r = 1, 2, …, 255, 
來產生 255 個切割點 z1, z2, …, z255，這些切割點則可以用來將 Z 尺度切割成 256 個等機率的
區段，其中每個區段對應到灰階影像中的一個灰階值。有關逆向常態累積機率密度函數
Inv_NCD(α)的相關資料，可以參考(Acklam, 2004; Bialas, 2004)。 
參、研究方法 
在本研究中，我們結合頻率域轉換方法(例如 DCT 與 DWT)、subsampling、常態分配理
論以及逆向常態累積機率密度函數，來建構一個數位影像的智慧財產權保護機制並下列要
求： 
(1) 取出所有權聲明影像時不需要原圖協助 
(2) 確保浮水印機制的安全性 
(3) 確保強韌性與辨識明確性 
(4) 可以輕易處理灰階浮水印 
假設著作權擁有者想要利用一張 N1 × N2 大小的灰階浮水印 W，來保護一張大小為 M1 × M2
的灰階影像 H 的影像所有權。我們同時假設灰階影像具有 256 種色階變化。基本上，我們
的方法包含浮水印隱藏與浮水印取出階段，在這兩個階段中，我們需要利用 
zr = Inv_NCD(r/256), for r = 1, 2, …, 255,  
來產生 255 個切割點 z1, z2, …, z255，這些切割點則可以用來將 Z 尺度切割成 256 個等機率的
區段，其中每個區段對應到灰階影像中的一個灰階值。在浮水印隱藏階段，我們首先由一
個標準常態分配的母體中隨機產生一串數字 X = (x1, x2, …, xn)，其中 n = N1 × N2，接著，我
們會利用 subsampling 的方法將原始影像 H 分解成四張相似的子影像，然後利用 DCT 或是
DWT 將子影像轉成頻率域係數，然後再透過 Chu 的方法並配合一個虛擬隨機亂數產生器種
子 K 將 X 藏入影像中，在隱藏 X 的一個值 x 的過程中，我們利用下列方法來產生所有權影
 7
當影像的所有權擁有者發現他所合法擁有的影像被侵權使用時，他必須針對受爭議的影
像 H′，透過浮水印的重建程序來取出被隱藏在影像中的所浮水印，以證明影像的合法擁有
權。在浮水印取出的階段，所有權擁有者必須提供被他秘密保存的所有權影像O與 secret key 
K，然後，再利用下列演算法來取出浮水印： 
 
Algorithm WatermarkExtractingProcedure(H′, O, K): 
Input:  A gray-level host image H′ with M1 × M2 pixels, a gray-level ownership share O with N1 
× N2 pixels, and a secret key K. 
Output:  A recovered watermark W′ of size N1 × N2 pixels. 
Step 1.  Generate 255 partition points z1, z2, …, z255 by zr = Inv_NCD(r/256), for r = 1, 2, …, 
255. Then, the partition points are used to partition the Z scale into 256 
equal-probability segments numbered from 0 to 255. 
Step 2. Decompose H′ into four subimages by subsampling, and then convert them into 
frequent-domain coefficients by DCT or DWT. 
Step 3. For each pixel o of the ownership share O, randomly select a pair of DCT/DWT 
coefficients, (U1, U2), using a pseudo-random number generator seeded by K, and let  
2
)( 21 UUU +=  
Step 4. If  
α621 ≥−
U
UU  
 then we set x′ = 0; otherwise x′ is recovered with:  
⎟⎟⎠
⎞
⎜⎜⎝
⎛
+
−=′
21
211
UU
UUx α . 
Step 5.  If x′ falls in the segment g of the Z scale where g ∈ {0, 1, …, 255}, then the pixel w′ of 
the recovered watermark W′ is w′ = o ⊕ g. 
Step 6.   Repeat Step 3 to Step 5 until all pixels of the ownership share O are processed. 
 
肆、結果與討論 
根據上述的研究構想，我們進行實驗來驗證本研究構想在安全性與強韌性方面的可行
性。我們以圖一(a)中大小為 1024 × 1024 pixels 的灰階影像作為受保護的影像，以圖一(b)
中大小為 256 × 256 pixels 的灰階影像作為浮水印。本實驗使用一階離散小波轉換，浮水印
強度α = 2.5，其結果如圖二所示： 
 
 9
 
 
為了驗證本研究構想在安全性方面的可行性，我們分析所有權影像的色階分布情形，
圖三顯示所有權影像的色階分布相當均勻，幾乎呈現均勻分配(uniform distribution)，因此，
我們很難由所有權影像獲得任何有關浮水印的資訊，更難反推 secret key K。因此，在 secret 
key K 不被洩漏出去的前提下，我們可以說我們的研究構想在安全性方面應該是可以值得信
賴的。關於浮水印強韌性的分析，我們以 Photoshop CS 8.0 版本來進行 JPEG 壓縮攻擊，其
結果如圖四所示。圖四顯示本研究的方法在 JPEG 的攻擊之下，JPEG 壓縮的影像品質下降
並不會造成太大的 PSNR 值的下降。 
 
0
2
4
6
8
10
12
14
0 2 4 6 8 10
Quality
PS
NR
 
圖四：JPEG 壓縮攻擊實驗結果 
 
參考文獻 
[1] Acklam, P. J., 2004. An algorithm for computing the inverse normal cumulative distribution 
function. Available: http://home.online.no/~pjacklam/notes/invnorm/ 
[2] Berenson, M. L. and Levine, D. M., 1999. Basic Business Statistics: Concepts and 
Applications, Prentice-Hall, Inc., New Jersey, pp. 337-353. 
[3] Bialas, W. F., Summer 2004. Lecture Notes in Applied Probability. Department of Industrial 
Engineering, the State University of New York at Buffalo. 
[4] Braudaway, G. W., Magerlein, K. A., and Mintzer, F., (1996). “Protecting Publicly-available 
Images with a Visible Image Watermark,” In Proc. of SPIE, Vol. 2659, pp. 126-133. 
[5] Chang, C.C. and Chuang, J.C. (2002) An image intellectual property protection scheme for 
gray-level images using visual secret sharing strategy. Pattern Recognition Letters 23, pp. 
931-941. 
[6] Chang, C.C., Hsiao, J.Y., and Yeh, J.C. (2002), “A Colour Image Copyright Protection 
Scheme Based on Visual Cryptography and Discrete Cosine Transform,” The Imaging 
Science Journal, Vol. 50, pp.133-140. 
[7] Chang, C.C., Hwang, K.F., and Lin, Y. (2000) A proof of copyright ownership using 
moment-preserving. The 24th Annual International Computer Software and Application 
 11
計畫成果自評 
本研究的主要目的在於應用常態分配理論建構一套數位影像智慧財產權保護方法，我
們在研究的過程中，按照原訂的計畫以下列的研究方法與步驟，有系統地來進行本研究計
畫： 
1. 資料及文獻的蒐集與整理 
2. 現有技術之探討與分析 
3. 應用 Subsampling、DCT、DWT、常態分配理論在數位浮水印之可行性分析 
4. 建立以 Subsampling、DCT、DWT、常態分配理論為基礎的數位浮水印基本架構 
5. 浮水印的隱藏方法的設計 
6. 浮水印取出方法的設計 
7. 系統安全性分析 
8. 利用測試影像驗證本方法對於攻擊的強韌性 
其中步驟 1 至步驟 7 皆按原訂計畫順利完成，步驟 8 的工作我們也已經完成 JPEG 壓縮攻
擊的實驗。本研究計畫進行時程為一年，並以月為單位，將本研究的步驟與時程分為九個
工作項目，然後針對每個工作項目規劃出所需的時間。下表為各工作項目所需時間的規劃，
在這個進度規劃之下，我們已經有系統地完成本研究計畫預定的各項任務。 
 
 第
1月
 
第
2月
 
第
3月
 
第
4月
 
第
5月
 
第
6月
 
第
7月
 
第
8月
 
第
9月
 
第
10月
 
第
11月
 
第
12月
 
1. 準備工作             
2. 資料及文獻之收集             
3. 現有技術探討與分析             
4. 應用Subsampling、DCT、DWT、常
態分配理論於數位影像智慧財產權
保護之可行性分析 
            
5. 建立數位影像智慧財產權保護機制
的基本架構 
            
6. 浮水印隱藏與取出方法的設計             
7. 系統安全性分析             
8. 利用測試影像驗證本方法對於各種
攻擊的強韌性 
            
9. 撰寫報告             
預定進度累計百分比 10% 15% 20% 30% 40% 50% 60% 70% 80% 90% 95% 100%
 
本研究主要目的在於以 Subsampling、DCT、DWT、常態分配理論等基礎，來建構一
個數位影像智慧財產權的保護機制，我們已透過本研究計畫的進行，提出一套有效的方法
來解決下列有關數位浮水印機制的問題： 
1. 取出著作權聲明影像時需要原圖協助的問題 
2. 取出浮水印需要原浮水印的問題 
3. 如何確保安全性的問題 
4. 如何確保強韌性的問題 
月 
次 項 
目 
 1
出席國際學術會議心得報告 
                                                             
計畫編號 NSC 96-2221-E-130-018 
計畫名稱 結合小波轉換、統計理論與模數運算之影像著作權保護系統之研究 
出國人員姓名 
服務機關及職稱 
許慶昇 
銘傳大學資訊管理學系/助理教授 
會議時間地點 2008/04/23~2008/04/26, 韓國釜山(Busan, Korea) 
會議名稱 The 2nd International Conference on Multimedia and Ubiquitous Engineering (MUE2008) 
發表論文題目 An Imperceptible Watermarking Scheme Using Variation and Modular Operations 
 
一、參加會議經過 
在九十六年度國科會專題研究計劃即將告一段落之前，本人利用學校期末考結束後
的時機，出席參加於韓國釜山的海雲台韓華渡假村所舉行的「The 2nd International 
Conference on Multimedia and Ubiquitous Engineering (MUE 2008)」國際學術研討會，本
次會議的時間為 2008年 4月 23日至 4月 26日，而會議主題包含： 
1. Ubiquitous Computing and Beyond 
此大項主要包含下列議題：Ubiquitous Computing and Technology, Ambient and Artificial 
Intelligence, Context-Aware Ubiquitous Computing, Parallel/Distributed/Grid Computing, 
Novel Machine Architectures, Semantic Web and Knowledge Grid, Smart Home and 
Natural Interfaces, Multimedia Modeling and Processing, AI and Soft Computing in 
Multimedia, Computer Graphics and Simulation, Content-Based Image Retrieval / QBE, 
Medical Image and Signal Processing, Multimedia Indexing and Compression, Virtual 
Reality and Game Technology, Current Challenges in Multimedia. 
2. Ubiquitous Services and Applications  
此大項主要包含下列議題：Protocols for Ubiquitous Services, Ubiquitous Database 
Methodologies, Ubiquitous Application Interfaces, IPv6 Foundations and Applications, 
Smart Home Network Middleware, Ubiquitous Sensor Networks / RFID, U-Commerce and 
Other Applications, Database and Data Mining. 
3. Multimedia Services and Applications  
此大項主要包含下列議題：Multimedia RDBMS Platforms, Multimedia in Telemedicine, 
Multimedia Embedded Systems, Entertainment Industry, E-Commerce and E-Learning, 
Novel Multimedia Applications, Computer Graphics in Industry, Multimedia and Ubiquitous 
Security, Security in Commerce and Industry, Security in Ubiquitous Databases, Key 
Management and Authentication, Privacy in Ubiquitous Environment, Sensor Networks and 
RFID Security, Multimedia Information Security, Forensics and Image Watermarking. 
4. Other IT and Multimedia Applications 
 3
幾乎很難用英語來溝通，例如在舉辦會議的飯店裡只能看到韓文的標示，很難看到英文
的指示與用語，連舉辦會議的飯店接待人員都無法流利使用英文跟與會人員溝通，這一
點對於只能靠英文溝通的外國人來說，確實存在著許多障礙。 
最後，本人在此要特別感謝行政院國家科學委員會提供經費補助，使本人得以順利
參加於韓國釜山舉辦的MUE2008國際學術研討會 
 
 
2
coefficients of the HL3 and LH3 bands. For each time 
of embedding, we take two coefficients to adjust their 
distance. For not modify the coefficients too much to 
degrade the image quality, we adjust remainders of 
coefficients according to a predefined modulus. When 
extracting the watermark, we need the original host 
image to acquire appropriate variation of the LL3 band. 
 
(a) The original image (512 × 512) 
 
(b) The transformed result 
Figure 1. An example of 3-level wavelet transform 
 
2.1. Watermark embedding 
 
At first, the LL3, HL3, and LH3 bands are divided 
into non-overlapping blocks of 2 × 2 size, respectively. 
Then, we compute the variation v for each block of 
LL3 by Eq. (1). 
 ( )∑ −=
c
ccv 2 , (1) 
where c is the coefficient within a block. Next, each 
block of LL3 is sorted according to its variation by 
ascending order. Obviously, the higher the variation is, 
the more the transparence is. That is to say, the 
modification of blocks with higher variation is more 
imperceptible for human eyes. Since coefficients of the 
same position within respective bands are transformed 
from the same pixels, we can infer the imperceptibility 
of coefficients of LH3 and LH3 from those of LL3. 
Therefore, we sort the blocks of HL3 and LH3 
according to the order of blocks of LL3 so that we can 
see which blocks are more imperceptible. Suppose that 
Bθ = { θib | i = 0..(l − 1)} and denotes the set of sorted 
blocks, where θ = {HL3, LH3} and l is the number of 
blocks of a band. Considering imperceptibility, we 
embed the watermark into 
θ
lb2  to 
θ
)1( −lb  only. 
As we have mentioned in the beginning of the 
section, we adjust the distance between remainders of 
two coefficients to embed the watermark. Let’s explain 
how to embed a watermark bit in detail. For each bit w 
of the watermark, we take a pair of wavelet 
coefficients ( )θ1, +ijij cc  of successive blocks θib  and θ 1+ib , 
where j ∈ {0, 1, 2, 3} and denotes the position of the 
coefficient in a block. Based on a predefined modulus 
R, we compute the following remainders f and r: 
 
Rcr
Rcf
i
j
i
j
mod
mod
1+=
=  (2) 
Borrowed from the concept of a circular array, we 
can see f and r as the front and rear pointer of a ring 
with length R. And the distance d between the front 
and rear pointer is computed as follows [4]. 
 d = (R − f + r) mod R (3) 
If w = 1, ( )θ1, +ijij cc  is adjusted so that the distance is a 
three-fourths R; otherwise, it is adjusted so that the 
distance is a quarter R. After all watermark bits are 
embedded, we can get a watermarked image. 
The complete algorithm of embedding watermark is 
as follows. 
Algorithm Embedding(c1, c2, w, R) 
f = |c1| mod R 
r = |c2| mod R 
f
c
ccc ⋅−=∆
1
1
11 )(
 
r
c
ccc ⋅−=∆
2
2
22 )(
 
d = (R − f + r) mod R 
if w = 1 then 
    d′ = (R − 1)*(3/4) − d 
else  
    d′ = (R − 1)/4 − d 
RRdff  mod )
2
( +⎥⎥
⎤⎢⎢
⎡ ′−=  
RRdrr  mod )
2
( +⎥⎦
⎥⎢⎣
⎢ ′+=  
f
c
ccc ⋅+∆=′
1
1
11 )(  
r
c
ccc ⋅+∆=′
2
2
22 )(  
 
2.2. Watermark extraction 
 
At first, the watermarked image is 3-level wavelet 
transformed, and the LL3, HL3, and LH3 bands are 
 
 
4
 
(a) Lightening (PSNR = 30.13) (h) NC = 1.0 
 
(b) Darkening (PSNR = 29.32) (i) NC = 1.0 
 
(c) Blurring (PSNR = 29.33) (j) NC = 0.788 
 
(d) Sharpening (PSNR = 29.13) (k) NC = 0.533
 
(e) Cropping (PSNR = 27.32) (l) NC = 0.762 
 
(f) Drawing (PSNR = 29.23) (m) NC = 0.807
 
(g) JPEG (PSNR = 38.72) (n) NC = 0.947
Figure 3 The experimental results 
 
Table 1. The comparison of Reddy and Chatterji’s and 
ours method under various attacks 
 Reddy and 
Chatterji’s 
Ours 
Lightening 0.993 1.0 
Darkening 0.947 1.0 
Blurring 0.005 0.851 
Sharpening 0.013 0.577 
Cropping 0.868 0.738 
Drawing 0.785 0.863 
 
In addition, we compare the NC values of the 
extracted watermark under JPEG attack with various 
compression ratios, and the result is shown in figure 4. 
Naturally, the NC value decreases with the increment 
of the compression ratio. However, the NC values of 
ours decline more slightly than those of Reddy and 
Chatterji’s.  
 
Figure 4. The comparison of Reddy and Chatterji’s and 
ours method under JPEG attack with various 
compression ratios 
