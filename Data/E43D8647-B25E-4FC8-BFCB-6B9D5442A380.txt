in order to facilitate future planning, analysis, and 
navigation in the Cyber City. Under these concepts, 
we provide an efficient, accurate, and rapid 
mechanism in three-dimensional building model 
reconstruction for GIS. 
In this project, we produce/collect a large set of 
multi-view images about the buildings using low-cost 
digital cameras for reconstruction of three-
dimensional building models.. Using these images as 
inputs, we reconstruct the 3D models of these 
buildings through the following steps. In the first 
step, we detect automatically a sparse set of 
corresponding points using the Harris filter and 
Difference of Gaussian filter. In the second step, we 
can use the sparse corresponding points and 
properties of 3D geometries to generate a quasi-dense 
set of corresponding points. And then we can apply 
the epipolar transfer to remove incorrect 
corresponding points. After that, we can reduce the 
projection error by applying standard bundle 
adjustment algorithm repeatedly and get the improved 
camera parameters and 3D point cloud. Finally, the 
three-dimensional build models can be reconstructed 
from the good corresponding points. Refer to the 
similarity measurement, the 3D patch projection is 
used to improve the results of correspondence. 
We take a large set of virtual multi-view images as 
the experimental data and apply our mechanism to 
reconstruct the 3D models. We integrate our results 
with geographic information system to generate a 
realistic campus model. One may hope to conduct a 
virtual reality system using our model for campus 
navigation. 
 
英文關鍵詞： Bundle Adjustment, Structure from Motion, Epipolar 
Transfer, Trifocal Tensor, 3D Model Reconstruction, 
Multi-View Images, GIS 
 
式之進步影響下，不同於以往二維(平面)方式，三維空間在簡易應用層面上，可讓使用者透
過查詢、超鏈結(Hyper-Link)方式獲得上述資訊，極適用於導覽及查詢為主的領域，可針對潛
勢災區水土保持及防災資料以 3D 形式進行導覽及查詢時之建置參考。除了 3D 空間物件表現
外，專家們結合各種屬性形成其他維度建成多維度系統，使觀察者可由不同角度對屬性有視
覺感應(可視化)，在 internet 上以 VR、CAD 及 GIS 的方式整合查詢、展示及分析的功能，以
達到資訊傳播及提醒功能，可見得多維度系統之建立，是種真正的資料運用革命，尤其是對
我們世界之理解化(reasoning)、顯現化(representation)和結構化(structuring)尤然，更能發揮空
間資料的呈現與效用。 
Martinec D. and Pajdla T.(2007)描述到以多視角影像重建模型，首先必須評估相機旋轉方位
(rotations)與移動量(translations)。作者採用線性最小二乘法自動評估旋轉方位，以線性二階錐
(Second Order Cone Programming)來評估移動量，以提高對應點精確度。Mellor, J.P.(2003)[10]
呈現一種方法，使用相機結合衛星定位系統、慣性感測器(inertial sensors)與自動測斜儀
(incli-nometer)，拍攝數以千計之影像，偵測建築物表面高密度點雲資訊。同時利用雜訊重新
進行校正評估，補償影像明亮度之差異，並進行影像敷貼，建構出建築物模型。Kamberov, G. 
et al (2006)提出處理任意角度拍攝、未經相機校正之影像，為了解決如此決複雜又不一致問
題，建構三維幾何模型。 
Furukawa, Y. et al(2007)[4][5]提出一種新的演算法，利用多視角影像產生密集小矩形補綴面
(patch)，而這些密集補綴面覆蓋於物體表面上，並可見於影像中。其處理程序包含三個階段：
對應(matching)、擴展(expansion)與過濾處理(filtering)，為了可以達到區域光度(photometric)的
一致性，與全域可見度一致性，因此在對應的過程中，找出稀疏分散於影像的對應點，並於擴
展過程中在有限區域範圍內擴增密集對應。作者將傳統對應的問題，結合三維幾何關係的處理，
使對應點的偵測更合理化，相對地準確度也會提高。然而，若尋找稀疏對應點的分佈不夠分散，
在擴展的步驟上則會造成部分區域沒有對應點可以擴展，而產生密集對應點分佈不均勻，且模
型建構產生空洞的問題。 
三、 研究方法 
本計畫主要的技術包含多視角影像自動建構密集對應點、及利用光束調整法 (Bundle 
Adjustment)最佳化相機參數與三維模型重建。透過這些技術，將可以獲取不錯的建物模型。 
3.1 多視角幾何 
要能夠整合多張影像的資訊，最重要的技術之一就是：多張影像彼此之影像對應(Image 
Correspondence)關係[1][3][6]。把多張影像物體投影到二維影像，根據影像與影像彼此之間，
找出相對投影幾何關係[8][9]。一旦找到彼此之幾何關係，就能夠整合多張影像的資訊。此小
節我們先介紹幾種較常用的多張影像之間的幾何關係： 
3.1.1 極線幾何與基礎矩陣 
在二張影像之間的內部投影幾何關係稱之為『極線幾何 Epipolar Geometry』[7]，與影像中之
物體的形狀、顏色無關，主要的影響是來自於相機的內部參數及外部參數。『基礎矩陣
而我們的計畫加入三焦張量(Trifocal Tensor) [7]數學模型以三張影像幾何關係改善對應點的
準確度。 
本計畫主要目的是在多視角影像的環境下過濾對應點並取得該影像的相機參數。所以會先輸
入多張未校正的影像，接著計算每一張影像的特徵點與特徵點之間的對應關係，隨後加入基
礎矩陣的幾何關係過濾掉部分對應點，最後以從運動中恢復結構的方法計算相機參數，而我
們的流程而是使基礎矩陣過濾後的對應點加入三焦張量重覆過濾，使任三張影像都滿足三焦
張量的幾何關係，使對應點的對應關係能夠更精確。由於在取得多視角影像特徵點以及對應
點使用到Bundler，接下來章節中首先驗證Bundler可用性，以及將三焦張量用於過濾對應點，
最後擴展到多張影像進行實驗以達到最終目的。 
3.2 從多視角幾影像重建三維點雲 
在進行三維物體重建前，我們必須先找出影像間的幾何對應關係，過程中我們會先自動產生
稀疏對應點，進一步再擴展為密集對應點而產生物體三維座標點資訊。 
3.2.1 多視角幾何萃取精確影像對應 
此節將介紹如何從多視角影像中萃取精確影像對應，在萃取影像特徵點的部份，我們使用海
利斯角隅偵測及高斯差分方法在多視角影像中萃取出特徵點；對應點配對的部份，我們透過
極線幾何的特性縮小對應點配對的範圍，並以我們提出的漸進式走訪法發掘潛在的候選點，
我們以補綴面基礎的區塊比對方法，加上我們提出的相互支持概念與動態高斯濾波法，在多
視角影像中萃取精確影像對應；三維點重建的部份，我們使用直接線性轉換將萃取出的對應
點轉換為三維點。 
補綴面為基礎比對方法在投影補綴面三維點至多視角影像時，若兩台像機的影像投影面與補
綴面三維點的距離差異過大，則會造成投影點過於集中或是過於分散兩種情況，如圖 1，當
投影點過於集中時，投影點所涵蓋的像素區塊量變少而且重複性高，當投影點過於分散雖然
投影點所涵蓋的像素區塊量不變，但是會因為縮放的比例造成像素資訊程度性的失真，當出
現此兩種情況時，相似度的測量容易發生誤判的情況，其中投影點過於集中造成的影響尤其
嚴重，資訊量過少的情況並不容易處理，因此我們提出相互支持概念，將參照影像與投影影
像的角色互換，將投影點過於集中的情況皆轉為投影點過於分散的情況。 
 
圖 1：投影點集中與分散示意圖、相互支持概念示意圖。 
透過上述相互支持概念的處理，補綴面為基礎比對方法在投影補綴面三維點至多視角影像時
只會產生投影點分散的情況，接著我們提出動態高斯濾波法改善因為縮放的比例造成像素資
訊程度性的失真的問題，將投影點的角點與其對角相鄰點的二分之一距離向外延伸，可以得
到動態高斯濾波網格的 4 個角點，如圖 2 動態高斯濾波法示意圖左圖所示，對動態高斯濾波
   
圖 4：由左至右分別為 3DMAX 實驗相片，LiDAR 第一組與第二組實驗相片。 
我們採用較接近的疊代次數來比較實驗結果，PSO 實驗採用 10 組隨機取樣的粒子個體經過
疊代計算 117 次，共進行 1170 次疊代，而 LMedS_PSO 方法先計算成功取樣機率為 80%，正
確資料為 50%的一組結果，套用隨機取樣公式需要 412 次，接著隨機取樣 9 組粒子個體後，
結合 LMedS 的一組結果，之後 10 組再進行疊代 76 次，共需要 1172 疊代次數，而 LMedS
的方法直接將成功取樣機率設為 99%，正確資料為 50%，需要疊代 1177 次。 
 完成上述的步驟後，我們稱為進行一組實驗，在本研究中，將使用 1000 組資料的平均誤
差當作實驗結果，如表 1、2。 
表 1：3DMAX 場景估測基礎矩陣結果 
方法 1000 組平均誤差 1000 組標準差 1000 組需要時間 
PSO 0.077 像素 0.0547 像素 5 小時 
LMedS_PSO 0.086 像素 0.0548 像素 18 小時 
LMedS 0.097 像素 0.0548 像素 41 小時 
表 2：3DMAX 場景估測基礎矩陣標準差分佈 
方法 小於平均標準差 小於 0~1 倍 小於 1~2 倍 
PSO 678 個 667 個 11 個 
LMedS_PSO 632 個 629 個 3 個 
LMedS 581 個 577 個 4 個 
從表 1、2 中我們可以發現，PSO 的平均誤差和花費的時間皆是最少的，而小於平均標準差
的數量也是最多，而其兩兩組資料也都是類似的結果。從圖表中我們看出，PSO 的方法在接
近的疊代次數中，時間成本和平均誤差值皆是表現最好的。 
從三組實驗結果看出來，三種方法用接近的疊代計算次數比較，使用 PSO 的方法比過去使用
強健式方法 LMedS 快上不少，平均誤差值也較小，而我們另外結合兩種方法的 LMedS_PSO
則是在時間成本、平均誤差值皆介於中間，這是可以預期的，第一組 3DMAX 資料因為是我
們用電腦模擬，包括相機的參數皆有的情況下，算出來的誤差值較小，而第二組 LIDAR 資
料因為在找對應點時遇到記憶體不足的問題，調整後已經造成些誤差，再來利用投影矩陣投
影回相片上時，需要做正規化，這部份也產生了誤差，因此整體比較下來，誤差比 3DMAX
資料大，但是就 LIDAR 資料來說，我們提出的方法是有效率且誤差值較小的，有了這些資
訊後，適合未來繼續進行相關研究。 
4.1.2 利用三焦張量輔助評估多視角幾何實驗結果 
將三焦張量的幾何關係在三張影像進行實驗，從實驗結果可以發現三焦張量確實可以將
Bundler 對應點的準確性提升。也因此我們將三焦張量的幾何特性擴增到多張影像上，刪除不
符合的對應點，使任三張影像皆具有此關係。下表 7 為實驗刪除對應點平均誤差的變化情形。 
斯濾波法。 
從實驗結果可以得知補綴面基礎的比對方法相較於區塊比對方法，較不容易受到多視角影像
拍攝視角變化的影響，可以有效改善區塊比對方法的影像旋轉問題，因此在相似度判斷的正
確性比較高，另外補綴面基礎比對方法特有的影像縮放問題，經過我們提出的相互支持概念
與動態高斯濾波法處理之後，在相似度判斷的正確性上有顯著的提升。 
因此我們進一步們將在多視角影像的環境下，進行萃取精確影像對應與三維點重建的實驗，
如圖 6 三維點重建實驗場景介紹圖所示，我們在 3ds Max 實驗場景中，分別對於暴龍
(Tyrannosaurus Rex)及翼龍(Pteranodon)兩組模型進行實驗，其中暴龍的實際尺寸為長度 14 公
尺、寬度 4 公尺、高度 6.5 公尺，暴龍的實際尺寸為長度 336 公尺、寬度 130 公尺、高度 48
公尺，在暴龍的實驗場景中，我們架設了 30 部相機，在翼龍的實驗場景中，我們架設了 25
部相機，並透過相機取得一系列多視角影像，照片的像素比例皆為 1600 x 1200，多視角影像
的拍攝以可以將模型完全入鏡為原則，相機的擺設方式並無一定規律。 
 
圖 6：三維點重建實驗場景介紹圖。 
在萃取影像特徵點的部份，我們使用海利斯角隅偵測及高斯差分方法在多視角影像中萃取出
特徵點，，對應點配對的部份，我們透過極線幾何的幾何特性縮小對應點配對的範圍，並以
直接線性轉換計算出對應候選點的三維點座標。實驗中比對區塊大小為 7 x 7 的像素區塊，我
們以補綴面基礎的區塊比對方法，加上我們提出的相互支持轉換、動態高斯濾波法與綜合性
相似度評估函數，對三維點進行相似度量測，並使用 K-Means 分群演算法與線性內插法發掘
潛在的三維點，在多視角影像中萃取精確影像對應與三維點重建。 
  
圖 7：暴龍與翼龍點雲影像圖。 
實驗結果如圖 7 暴龍與翼龍點雲影像圖所示，點雲影像圖是我們使用 3ds Max 軟體，將於三
維空間之點雲資訊攝影後的結果，經過三維點重建後的點雲資訊，每一個三維點除了有三維
座標之外，還有綜合性相似度評估函數所計算出來的分數，其值的範圍為-1 至 1，我們以 0.4
做為門檻值(threshold)，過濾掉分數低於門檻值的三維點，可以透過調整門檻值將不理想的三
維點去除，門檻值愈高三維點中離群資訊的數量就愈少，但通過門檻值的三維點數量也會愈
少，反之，門檻值愈低過門檻值的三維點數量就愈多，但三維點中離群資訊的數量也愈多，
以 0.4 做為門檻值過濾之後，暴龍有 28005 個三維點，翼龍有 28664 個三維點。 
從實驗結果的觀察中發現，我們以相互支持轉換、動態高斯濾波法與綜合性相似度評估函數，
未來，如何在多視角影像的環境下萃取精確影像對應與三維點重建，是個值得研究的議題，
對應點與三維點的精確度，將會影響未來三維立體模型重建，或者其他相關應用的成效，雖
然我們所提出的方法經由實驗結果證實，可以在多視角影像的環境下，提升萃取影像對應與
三維點重建的精確度，但本研究所提出的方法或許仍然有其他可以改進的空間，我們將未來
可以將影像的色彩資訊，加入綜合性相似度評估函數的相似度量測之中，藉由光度一致性、
色彩一致性與幾何強健性的綜合性評估，提升相似度測量值的辨識力與可信度。 
參考文獻 
[1] Brown, M. Z., Burschka, D., (2003), “Advances in Computational Stereo”, IEEE Trans. 
Pattern Analysis and Machine Intelligence, Vol. 25, No. 8, pp. 993-1008. 
[2] Danahy, J. (1999), “Visualization Data Needs in Urban Environmental Planning and Design”, 
in Proceedings of the Photogrammetric Week, Karlsrnhe, pp. 351-365. 
[3] Dubuisson, M. P., Jain, A. K., (1994), “A Modified Hausdorff Distance for Object Matching”, 
Proc. of IAPR Int. Conf. on Pattern Recognition, Vol. 1 pp. 566-568. 
[4] Furukawa, Y. and Ponce J.(2007), "Accurate, Dense, and Robust Multi-View Stereopsis", in 
Proceedings of the IEEE conference on Computer Vision and Pattern Recognition, pp.1-8. 
[5] Furukawa, Y. and Ponce, J. (2008), “Accurate Camera Calibration from Multi-View Stereo 
and Bundle Adjustment”, in Proceedings of the IEEE conference on Computer Vision and 
Pattern Recognition, pp.1-8. 
[6] Georgescu, B., Meer, P. (2004), “Point Matching under Large Image Deformations and 
Illumination Changes”, IEEE Trans. Pattern Analysis and Machine Intelligence, Vol. 26, No. 6, 
pp. 674-688. 
[7] Hartley, R. and Zisserman, A. (2003), Multiple View Geometry in Computer Vision, 2nd Ed., 
Cambridge University Press. 
[8] Lhuillier, M. and Quanm L. (2003), “Image-Based Rendering by Joint View Triangulation”, 
IEEE Transcations on Circuits and Systems for Video Technology, Vol.13, No.11, pp. 
1051-1063. 
[9] Lowe, D.G. (2004), “Distinctive Image Features from Scale-Invariant Keypoints”, 
International Journal of Computer Vision, Vol.60, pp.91-110. 
[10] Mellor, J.P. (2003), "Geometry and Texture from Thousands of Images", International Journal 
of Computer Vision 51, pp. 5-35. 
[11] Snavely, N., Seitz, S. M., and Szeliski, R. (2006), “Photo Tourism: Exploring Photo 
Collections in 3D”, ACM Transactions on Graphics, Vol. 25, No. 3, pp. 137-154. 
[12] Snavely, N., Seitz, S. M., and Szeliskix R. (2008), “Modeling the World from Internet Photo 
Collections”, International Journal of Computer Vision, Vol. 80, No. 2, pp. 189-210. 
[13] Volz, S., and Klinec, D. (1999), “Nexus: the Development of a Platform for Location Aware 
Application”, in Proceedings of the third Turkish-German Joint Geodetic Days, Vol. 2, 
Istanbul, pp. 599-608. 
[14] http://phototour.cs.washington.edu/bundler/ 
[15] Ground Truth data, http://cvlab.epfl.ch/~strecha/multiview/denseMVS.htm 
 2
visualization and its Applications；第四場由 Demetri Terzopoulos教授(Computer 
Science Department, University of California, USA)主講，講題為Computer Vision 
in Virtual Reality；第五場由 Gerald Schaefer 博士(Department of Computer 
Science, Loughborough University, UK)主講，講題為 Navigating Large Image 
Databases；第六場由 Vijay K. Arora教授(Division of Engineering and Physics, 
Wilkes University, USA) 主 講 ， 講 題 為 Quantum Nanophysics and 
Nanoengineering of Low-Dimensional Devices and Circuits；第七場由 Alexander 
P. Yefremov 教授 (Peoples’ Friendship University of Russia)主講，講題為
Relativistic Danger for Spacecraft from Fast Satellites of the Solar-System 
Planets。可惜議程安排與專業報告衝突，無法一一前往聆聽，至為可惜。 
 
2. 發表論文 
本次會議，攜同博士班研究生詹凱軒先生一同出席。大會安排我們於 7月 27
日晚上發表論文，題目為「3D Model Reconstruction Refinement from Multiple 
Images」。 
 
論文主要之貢獻在於對影像處理中之影像對應(image matching)方法之精進。
影像對應是影像處理中一個非常基本且重要的問題，良好的影像對應方法可
作為由多張影像建立三維物體模型以及多種影像處理問題的基石。大抵在
2004年，David Lowe曾經提出一個特別的演算法(SIFT: Scale Invariant Feature 
Transform)在影像對應上有不可忽視之貢獻，然而他的方法可能受雜訊影響而
導致精確度不良。我們的論文採用改良的方法，對抗雜訊較佳，能提高精確
度。實驗證明我們的方法的確提高了在雜訊干擾下的精確度。 
 
與會學者對我們的研究成果相當有興趣，但由於會議安排不善，不同類別的
論文被安排在同一場次報告，同時論文集之安排也非常凌亂，台上報告論文，
台下在找相關資料卻屢屢無法找到(發表之論文眾多，只拿到與本人研究有關
之部分論文集，然台上報告者之論文並不在手邊之論文集內)，因此對他人之
報告無法有最好的瞭解。 
 
二、 綜合感想 
 
急功近利，是時下社會中的通病，生活上如此、工作上如此、學術研究上也如此。
而此次研討會上所聽到歐美科技先進大國科研政策推動負責人或科研經費核准負
責人對科研的看法與態度，卻令我震驚不已，久久不能忘懷。記得以前我們常常用
愛迪生的故事（愛迪生在研究製作燈泡的過程中，嘗試過無數材料均不成功，旁人
笑他虛擲光陰一事無成，可是他說：「不會啊，我已經知道這些材料都不能用，這
就不會虛擲光陰了。」）來鼓勵（或安慰）自己。可是在實際研究上卻急功近利，
卻跳不出「虛擲光陰一事無成」的框框（陰影），豈不自相矛盾。 
 4
的期刊與會議，同時鼓勵同儕與學生們投稿時，將好的研究成果優先投在國內發
表，點數不會少算，這樣一來，自己的期刊或會議有一流的論文，國外自然不敢輕
視，自然而然能提升國內期刊與會議的水準。二十年前如果做了，今天國內的期刊
與會議論文水準一定可觀。這種事，今天不做明天就會後悔的，可是有多少人肯做
呢？ 
 
 
報告人：何瑁鎧  二０一一年七月三十日初稿 
八月二十四日修正 
99 年度專題研究計畫研究成果彙整表 
計畫主持人：何瑁鎧 計畫編號：99-2221-E-004-011- 
計畫名稱：應用於地理資訊系統之使用多視角影像重建三維建物模型 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 2 2 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 3 3 100%  
博士生 1 1 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 2 2 100%  
研究報告/技術報告 0 0 100%  
研討會論文 1 1 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
