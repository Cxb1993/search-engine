應用於數位電視的雙模視訊解碼器 
“Dual-Mode MPEG-2/H.264 Video Decoder for Digital TV Application” 
計畫編號:NSC96-2221-E-009-180 
執行期間：94年 8月 1日至 97年 7月 31日 
主  持  人: 李 鎮 宜  交大電子工程學系/電子工程學研究所教授 
 
 
一、中文摘要 
本計畫的目的針對於雙模式的視訊解
碼，以及低功率的議題來做深入的研究與探
討，特別是應用於數位電視的視訊傳播系統當
中。 
由於最新視訊標準(H.264)的出現，使得目
前的視訊標準面臨標準的不相容情況。例如傳
統的 MPEG-x 系列的視訊標準便無法用 H.264
的解碼器來播放。因此，本計劃提出一個雙模
MPEG-2 和 H.264 的視訊解碼器，以期能夠共
用相同的模組並且降低整合上的負擔。此外針
對低功率的需求，本計劃亦提出一些相關的低
功率模組，以期減少對記憶體的存取和減少所
需的工作頻率，來達到低功率的單晶片系統設
計。 
並且再加以考量視訊畫面在錯誤的通道
中傳送時，將造成的解碼畫面損失。經由提出
兩種錯誤偵測法，用以提昇視訊畫面的傳輸品
質。這兩種錯誤偵測分別為(A) Soft CAVLC 錯
誤偵測法，此偵測法可以及早發現錯誤並且及
早隱藏。此外針對錯誤隱藏，我們發現其演算
方式跟 H.264/AVC 之去區塊雜訊濾波器很接
近，因此我們提出一個合併的演算方式，藉以
提升其硬體的共用率，並且降低實作的硬體成
本。另一項為(B) Memory-based CAVLC 區塊
邊界預測法，此預測法可以偵測區塊邊界
(Block Boundary)，進行 Re-Synchronization 的
動作，以阻止當錯誤發生後，所造成的錯誤傳
遞的嚴重畫質失真，及時的將錯誤畫面進行修
正，並使得其後的解碼仍能繼續進行正確的解
碼，並進而利用 Memory-based 的特性，ㄧ方
面能儲存區塊邊界的比對資訊，同時也能支援
多重視訊編碼格式，達成具有高功能性的熵解
碼器(Entropy Decoder) 
 
Abstract 
The objective of this project is to highlight 
design challenges for low-power and dual-mode 
video standard requirements, especially in 
Digital-TV applications. Due to the advent of 
newly announced H.264/AVC, a generic problem 
of standard-incompatibility is appeared between 
H.264 and prevalent MPEG-x video standards 
and must to be resolved both in algorithmic and 
architectural levels. Furthermore, several 
low-power techniques targeted at achieving 
lower memory requirements and processing 
cycles are also described and discussed.  
Moreover, to improve the visual quality for 
the video transmission over error-prone channel, 
two error detection mechanisms are proposed to 
detect erroneous position correctly and thereby 
conceal them for a better quality display in the 
video broadcasting system. (A) A new error 
detection method on CAVLC decoder by 
introducing soft information from the channel 
side. It can improve the error detection capability 
and obtain better visual quality. Moreover, due to 
the similar algorithm between the deblocking 
one hand spatial error concealment exploits the 
surrounding correctly received image data for 
concealment. Temporal error concealment on the 
other hand utilizes correlations between current 
decoded and previous decoded frame, such as 
motion information. Altogether, aforementioned 
methods greatly improve the subjective and 
objective visual quality but seem to have their 
limitation. This is because that they often assume 
that video errors have been correctly located; 
otherwise error concealment method cannot be 
properly applied. The success of error 
concealment greatly relies on the correct 
detection of erroneous macroblocks (MBs). 
Hence, detecting or localizing the erroneous 
position is an important task for the video 
transmission over an error-prone or broadcasting 
channel. 
 
In addition to the aforementioned error 
detection, error concealment methods are also 
effective for visual quality improvement when 
considering low-delay and low-complexity 
requirement. Error concealment (EC) intends to 
ameliorate the impact of channel impairments by 
utilizing neighboring information in order to 
provide subjectively acceptable restoration of 
damaged picture regions. On the other hand, 
using a deblocking filter for improving visual 
quality is more or less helpful in the block-based 
video transmission over an error-prone 
environment. The reason is that the 
functionalities of deblocking filters are similar to 
that of error concealment since both modules 
smooth the block boundaries by a pre-defined 
interpolating procedure. In particular, the error 
concealment will be disabled when the 
bit-streams are of error-free. On the contrary, the 
deblocking filter can be turned off when the error 
has been detected. Therein, deblocking filter can 
be replaced with error concealment module for 
improving visual quality. In other words, both 
deblocking filter and error concealment will not 
activate simultaneously. Hence, the second task 
of this proposal is to realize an area-efficient 
design to combine both deblocking filter and 
error concealment units. 
 
三、研究方法及成果 
(A). 雙模式H.264/AVC和MPEG-2之系統
整合 
 
This section addresses an introductory 
overview of dual-mode techniques from the 
perspective of a cost-saving design issue. 
Because the design goal concentrates on the low 
bit-rate Digital-TV systems, this report 
introduces a dual-mode video decoder integrating 
MPEG-2 simple profile (SP) and H.264 baseline 
profile (BP). At first, in the algorithmic point of 
view, motion compensation and intra prediction 
in MPEG-2 are just a sub-set of that in H.264. 
That is, they can be totally merged into H.264 by 
sharing the hardware resources. With regard to 
the entropy decoder, H.264 features to adaptively 
select tables, but it is still similar to variable 
length codes defined in MPEG-2. So far, H.264 
can be partially compatible to MPEG-2 video 
coding standard. Nevertheless, the IDCT 
algorithms between MPEG-2 and H.264 are so 
diverse that they are difficult to combine. 
Similarly, the integration of deblocking filters 
also has the same problem. In the following, we 
will pay more attentions on these critical modules 
between MPEG-2 and H.264. 
 A major focus while combining MPEG-2 
and H.264 is IDCT since it faces the most diverse 
algorithm over the whole design. Specifically, the 
32
b
 b
yp
as
s
w
en
 
     (c) 
Figure 1: A memory system in terms of (a)(b) 
data organization and (c) memory hierarchy 
 
According to the decoding flow of the 
specification in H.264, a 4x4 sub-block is the 
smallest processing unit. To efficiently transfer 
4x4 pixel data among modules, we discuss two 
strategies to organize the word-length for data 
transactions [4]. One is a 4x1 row-by-row 
decoding ordering, and the other is a 1x4 
column-by-column decoding ordering. Although 
the 1x4 is similar to the 4x1 within a 4x4 
sub-block, the decoding orders in a 16x16 
macroblock (MB) are widely different. Figure 1(a) 
and (b) show the 4x1 and 1x4 decoding orderings 
in one luma MB, respectively. A line passing 
through each 4x4 sub-block stands for the 
decoding flow of one luma MB. Compared to the 
4x1 row-by-row decoding ordering, the 1x4 
column-by-column decoding ordering provides a 
better data structure, reducing the processing 
cycles on intra and inter prediction modules. For 
example, an intra prediction module requires left 
neighboring pixels to spatially create the 
predicted pixels. These neighboring pixels can be 
easily fetched through the 1x4 ordering since they 
behave in a column-wise manner. As for the inter 
prediction module, extra initialization cycles are 
required when a passing line turns. Therefore, the 
access times are related to the probability of 
turning events. The results proved that the 1x4 
column-by-column decoding ordering reuses the 
neighboring pixels and reduces the turning events, 
yielding the cycle reduction of 17% and 28% in 
intra and inter prediction modules respectively 
[4]. 
Using a memory hierarchy is advantageous 
to a large memory system. To reduce memory 
power consumption, we aim at a memory 
hierarchy where copies of data from larger 
memories that exhibit high data-correlation are 
stored to additional layers of smaller memories. 
In this way, a great part of data access is moved 
to smaller memories and the significant power 
savings can be achieved since accesses to the 
smaller level of memory hierarchy are less power 
consumption. Figure 1(c) shows a three-level 
memory hierarchy for an H.264 video decoding 
system [2]. The first level of memory hierarchy 
includes several pipelined registers and data 
buffers. The second and third level of memory 
hierarchy are slice pixel SRAM and external 
SDRAM. Because intra prediction and 
deblocking filter modules require lots of upper 
neighboring pixels to construct the predicted and 
filtered pixels, the slice pixel SRAM, storing 
upper rows of pixels, is explored to break the 
data dependency. However, a great penalty for 
this row storage is the large memory size, 
increasing memory power consumption. To 
reduce the memory size, a novel 
line-pixel-lookahead (LPL) unit [5] is allocated in 
Figure 1(c). It exploits spatial locality of vertical 
pixels to enhance the access efficiency. 
Particularly, the Decoding TAG (i.e. D. TAG) 
forecasts that whether the neighboring pixels 
should be kept or not. The Neighboring TAG (i.e. 
redundant pixels to perform filtering processes 
when the filtering edges are switched from 
vertical to horizontal directions. However, these 
redundant accesses will increase processing 
cycles in the DF. To alleviate this problem, we 
deduce a filtering order on 4x4 sub-block levels 
instead of 16x16 MB levels. The main idea is that 
we use four pixel buffers to keep the intermediate 
pixel value and perform the vertical and 
horizontal filtering process in one hybrid 
scheduling flow. Therefore, the proposed method 
prevents the re-access for different directions and 
combines the vertical and horizontal edge filters 
at a rule of standard-compliance. Compared to 
existing solutions, the proposed design can 
averagely save about one-half of processing 
cycles per MB. 
 
 
Figure 2: Processing cycle breakdown in each 
architectural design phase. 
 
 
   Let’s make a brief summary in terms of 
processing cycles in Figure 2. In the beginning, 
we propose several techniques to reduce the 
processing cycles in the MC. They are the 1x4 
decoding ordering, horizontal-switch method, 
and efficient memory interface. Therefore, the 
processing cycles are reduced by 37% as 
compared to conventional designs. Next, the 
processing cycles on the MC module have been 
reduced, whereas the deblocking filter becomes 
the cycle bottleneck in a system’s point of view. 
To further reduce the processing cycles, the 
hybrid scheduling and LPL prediction methods 
are proposed to improve the memory access 
efficiency and a 34% of cycle reduction can be 
further obtained compared to the previous design 
stage. 
 
(B). 錯誤偵測及修正架構設計 
 
(1). Soft CAVLC錯誤偵測機制 
This paragraph addresses an introductory 
overview of soft-input H.264/AVC decoder. 
Because a soft-input stream retains the data 
reliability and informs the decoder about channel 
behaviors, it provides a reliable estimator to 
detect or correct corrupted video. To apply a 
soft-stream into the video decoding system, a soft 
context-adaptive variable length decoder 
(CAVLD) has been newly designed and is 
capable of detecting erroneous positions. Figure 
3 summarizes the soft-input video decoding 
system based on our previous work [8]. First, the 
stream input is determined by the number of 
de-quantization levels (hard: 2-level; soft: 
N-level). Through the data partition and unequal 
error protection, the header stream is strongly 
protected, and residual coefficients are less 
protected and decoded by soft CAVLD. The soft 
CAVLD notifies error concealment that whether 
the corrupted macroblock (MB) occurs or not. 
Therefore, the corrupted data can be correctly 
concealed and the objective and subjective visual 

 
Figure 4: A soft VLC algorithm using graph 
representation. 
 
 
Figure 5: A soft VLC decoding path w/ and w/o 
errors. 
 
 When errors occur, a key observation is that 
the minimal BM will increase, indicating the large 
square difference between received soft streams 
and decoded codewords. Figure 5 depicts the 
behavior of minimal BM in the 1st and 2nd 
macroblocks of one frame. The minimal BM of 1st 
MB is very small because the received stream is 
correct while the 2nd MB is corrupted by the 
channel disturbance, yielding the large BM value. 
In addition, to enlarge the erroneous magnitude 
for detecting errors, we exploit the summation of 
BM over one MB as a measurement of error 
detection (i.e. PM). A formal statement of the 
detection algorithm follows: 
 
Soft Detection Algorithm: 
Storage: 
 {i, j}  ({symbol, bit} index) 
      PM(i,j), BM(i,j)    (path metric, branch 
metric) 
Initialization: 
 {i, j} = {0,0} , 0 < i < N, 0 < j < B; 
         PM(i,j) = 0;     BM(i,j) = 0; 
Recursion: Compute 
PM(i+1,j’) = PM(i,j) + BM(i,j);  j = j’ + code length 
Error Measurement = PM(N-1,B-1) / B; 
 
Although the PM value indicates the error 
behavior, each MB has different number of coded 
bits due to the variable length characteristics. 
Hence, the PM has to be translated and 
normalized by the number of coded bits. In 
Figure 5, this MB contains B-bit and the derived 
PM is divided by B as the following equation 
listed. The threshold THR can be determined 
through the simulation or channel behavior. 
Hence, the detection information ERR_FLAG 
can be used as the enable signal to activate the 
post-processing unit such as error concealment 
for improving visual quality. 
1,
_
0,
PM
if THR
BERR FLAG
PM
if THR
B


 
 

 
We verify the proposed soft CAVLD 
coupled with error detection capability over the 
AWGN channel using BPSK modulation. The 
input sequence is encoded by H.264/AVC 
baseline profile with a data partition. In the data 
partition mode, we have assumed that the texture 
part, composed of a sequence of VLC 
code-words, is corrupted by AWGN. The other 
parts are of error free. This assumption can be 
achieved by exploiting the unequal error 
 
Figure 6: Block diagram under wireless 
transmission 
 
 
In our proposed error robust algorithm, 
we hypothesize the error bit occurred on the 
syntax element of Coefficient_Token of 
CAVLC with the one-bit-reverse error 
pattern. If we can confirm the end place of 
this error 4x4 blocks in bitstream, we can 
resynchronize the decoding flow to the next 
4x4 blocks to prevent the error propagation. 
Therefore, the proposed mechanism is to list 
all possible combinations of Total_Zeros and 
Run_Before from H.264 specification and 
then sieve out some combinations by the 
amounts and length of 1 string to generate 
the self-defined end-of-block codewords 
database memory. Figure.XX shows the 
format of EOB structure.  
 
 
Figure 7: The format of End of Block 
 
After the built of EOB database, the 
EOBs can be viewed as a virtual decoding 
codewords to judge the block boundary. 
Figure 7 is a part of simulated result of EOB 
database, and we will take Figure 7 as 
example to introduce the EOB search 
process. First of all, we hypothesize the 
bitstream is as below: 
0000_0000_0110_0110_0000_0000_0000_0 
1011_0100….. 
 
1. Do group searching 
PCLC_mincode1(29’b0000_0000_0101_1
111_0000_0000_0000_0) < 
bitstream_num < 
PCLC_mincode2(29’b0000_0000_0110_1
011_0000_0000_0000_0) 
The matching group: G1 
2. Send group information 
 code length = 16-bit, PCLC_mincode = 
29’b0000_0000_0110_0100_0000_0000
_0000_0, base_addr(6-bit) =6’b1000_00. 
3. Find the valid VLC_codeoffset, which is 
the code length most significant bits of the 
result of subtracting the PCLC_mincode 
from the bitstream_num 
Bitstream_num(29’b0000_0000_0110_011
0_0000_0000_0000_0) – 
PCLC_mincode(29’b0000_0000_0110_01
00_0000_0000_0000_0) = 
29’b0000_0000_0000_0010_0000_0000_
0000_0. 
The valid VLC_codeoffset = 
15’b0000_0000_0000_001= 1. 
4. Extract the VLC_codeoffset operand, 
which has the same word length as the 
symbol address 
VLC_codeoffset = 6’b0000_01= 1. 
5. Calculate the decoded symbol address 
symbol_addr = base_addr(6’b1000_00) + 
VLC_codeoffset(6’b0000_01) = 
6’b1000_01= 33. 
6. Fetch the decoded symbol 
 sym_memory[33] = S33. 
 
As a consequence, we can store flag as the 
S33 in the location of database address 33. The 
flag means if hit or miss for the EOB checking. 
 
Y_PSNR 
(dB) 
38.46 9.18 35.42 
Y_PSNR 
(dB) 
40.44 24.73 40.44 
Y_PSNR 
(dB) 
40.97 25.69 40.97 
Picture 
    
     
四、結論與討論 
在本計劃之研究中，我們首先提出了利用演算
法以及架構上的調整來降低整合的面積。此
外，我們發展三個重要的低功率架構設計，分
別是改善記憶體階層設計，低功率的移動補償
和去區塊雜訊濾波器設計。經由本研究之進
行，發現記憶體的功率消耗可以降低 50%。而
且針對所需的工作頻率也能大大降低 60%，這
對現今低功率的視訊解碼端設計而言是相當
有參考價值的。另外，在錯誤偵測及錯誤更正
領域，我們首先提出了利用通道端的 soft 資訊
來幫助視訊解碼器做錯誤的偵測。研究發現在
2.7×10-3錯誤率下，平均能夠提升 1dB 以上的
視訊品質，這對現今要求良好畫值的視訊解碼
端設計而言，是相當有參考價值的。此外，我
們也在錯誤隱藏及去區塊濾波上，做出有效的
硬體分享，能夠降低 30%的實體面積。並且更
有 error re-synchronization 的方法，而這個方法
的好處在於可以用傳統的 group-based VLC 
decoding 的演算法，達到邊界預測的目的；而
在這樣的方法下，傳送端不用多傳其他輔助抵
抗錯誤的資訊，也就是在視訊無線傳輸的環境
下，不用付出頻寬成本的代價，就可以有抵抗
錯誤的效果。 
 
五、參考文獻(本計劃研究成果) 
[1] Tsu-Ming Liu, Ting-An Lin, Sheng-Zen Wang, 
Wen-Ping Lee, Kang-Cheng Hou, Jiun-Yan Yang 
and Chen-Yi Lee, “A 125μW, Fully Scalable 
MPEG-2 and H.264/AVC Video Decoder for Mobile 
Applications,” ISSCC Digest of Technical Papers, 
pp. 402-403, Feb. 2006. 
[2] Tsu-Ming Liu, Ting-An Lin, Sheng-Zen Wang, 
Wen-Ping Lee, Kang-Cheng Hou, Jiun-Yan Yang 
and Chen-Yi Lee, “An 865-μW H.264/AVC Video 
Decoder for Mobile Applications,” IEEE Asian 
Solid-State Circuit Conference (A-SSCC’05), pp. 
301-304, Nov. 2005. 
[3] Tsu-Ming Liu, Wen-Ping Lee, Chen-Yi Lee, “An 
Area-Efficient and High-Throughput De-blocking 
Filter for Multi-Standard Video Applications,” IEEE 
International Conference on Image Processing, pp. 
III-1044-1047, Sept. 2005. 
[4] Ting-An Lin, Sheng-Zen Wang, Tsu-Ming Liu, 
Chen-Yi Lee, “An H.264/AVC Decoder with 
4X4-block Level Pipeline,” IEEE International 
Symposium on Circuit and System (ISCAS'05), pp. 
1810-1813, May 2005. 
[5] Tsu-Ming Liu, and Chen-Yi Lee, 
“Memory-Hierarchy- Based Power Reduction for 
H.264/AVC Video Decoder,” IEEE International 
Symposium on VLSI Design, Automation, and Test 
(VLSI-DAT’06), pp. 247-250, April 2006.  
[6] Sheng-Zen Wang, Ting-An Lin, Tsu-Ming Liu, 
Chen-Yi Lee, “A New Motion Compensation 
Design for H.264/AVC Decoder,” IEEE 
International Symposium on Circuit and System 
(ISCAS'05), pp. 4558-4561, May 2005.  
[7] Tsu-Ming Liu, Wen-Ping Lee, Ting-An Lin, 
Chen-Yi Lee, “A Memory-Efficient Deblocking 
Filter for H.264/AVC Video Coding,” IEEE 
International Symposium on Circuit and System 
(ISCAS'05), pp. 2140-2143, May 2005.  
[8] Tsu-Ming Liu, Ting-An Lin, Sheng-Zen Wang, 
Wen-Ping Lee, Kang-Cheng Hou, Jiun-Yan Yang 
and Chen-Yi Lee, “A 125μW, Fully Scalable 
MPEG-2 and H.264/AVC Video Decoder for Mobile 
Applications,” IEEE Journal of Solid-State Circuits, 
vol. 42, no. 1, pp. 161-169, Jan. 2007.  
[9] Tsu-Ming Liu, Sheng-Zen Wang, Bai-Jue Shieh and 
Chen-Yi Lee, “A New Soft Variable Length 
Decoder for Wireless Video Transmission,” IEEE 
Transactions on Circuits and Systems for Video 
Technology, vol. 17, no. 2, pp. 224-236, Feb. 2007.  
[10] Tsu-Ming Liu, Ting-An Lin, Sheng-Zen Wang and 
Chen-Yi Lee, “A Low-Power Dual-Mode Video 
Decoder for Mobile Applications,” IEEE 
Communications Magazine, vol. 44, no. 8, 
pp.119-126, August 2006 
[11] Tsu-Ming Liu and Chen-Yi Lee, “An Improved 
Soft-Input CAVLC Decoder for Mobile 
Communication Applications (Invited),” The 2006 
IEEE Asia-Pacific Conference on Circuits and 
Systems, APCCAS'06, pp. 583-586, Dec. 2006.  
[12] Wen-Ping Lee, Tsu-Ming Liu, and Chen-Yi Lee, 
“A Joint Architecture of Error-Concealed 
Deblocking Filter for H.264/AVC Video 
Transmission,” 2007 IEEE International VLSI 
