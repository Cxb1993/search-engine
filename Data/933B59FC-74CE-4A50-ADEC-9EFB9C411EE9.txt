2行政院國家科學委員會專題研究計畫成果報告
智慧型自動吉他伴奏系統之實現
Implementation of an Intelligent Automatic Guitar Accompaniment
System
計 畫 編 號：NSC 95-2221-E-218-025-
執 行 期 限：95 年 8 月 1 日至 96 年 7 月 31 日
主 持 人：趙春棠 南台科技大學 電機工程系
計畫參與人員：黃建生 南台科技大學 電機工程系
一、中文摘要
本計畫目的在實現一個智慧型自
動吉他伴奏系統，希望能應用我們所設計
的自動吉他系統，結合 MIDI 技術以及智慧
型的學習，擴充其具有伴奏的功能。基於
實用上的考量，我們將提供兩種模式的伴
奏效果。首先第一種模式，主要為演奏者
配合伴奏系統模式，演奏者可以透過 MIDI
樂器演奏樂曲，系統將紀錄並分析所演奏
的樂譜，來決定伴奏音樂每一音符的發音
時間，此外，伴奏音樂的每一個音符的發
音時間，都可以開放由演奏者來修改或設
定。在這種模式下，雖然演奏者可以決定
伴奏樂曲的每一音符的節奏，可是伴奏樂
曲每次伴奏時，是不可以即時作改變的，
是以此模式又稱為演奏者配合伴奏系統模
式。第二種模式則主要是伴奏系統配合演
奏者，這種模式下，伴奏系統有能力跟隨
演奏者的節奏，也就是說當演奏者很隨興
的每次慢慢加快或放慢演奏速度時，伴奏
系統都能夠有智慧地，亦即有學習功能
地，且即時地改變伴奏的節奏，如此才能
符合真正伴奏的意涵。此時我們將設計有
效率的類神經網路來學習樂曲中每一音節
的演奏特性，有效的達成智慧學習的效
能。我們深深的希望藉由此類音樂機器人
計畫之實現，除了能增進電子、機械等方
面之設計技術與人才培養外，亦能促進科
技與藝術的結合。
關鍵詞：自動吉他、類神經網路、樂器數
位介面、自動伴奏系統、科技與藝術
Abstract
In the proposed project, we intend to
apply the techniques of MIDI and intelligent
learning to implement an intelligent
automatic guitar accompaniment system that
employs the automatic guitar designed by us.
Based on practical considerations, we will
provide two modes in the proposed system.
In the first mode, the player should play his
desired tempo through a MIDI instrument
connected to the computer. Then the user can
properly define the time schedule of the
corresponding accompaniment in the
presented software interface. In the second
mode, the proposed system can intelligently
follow the player’s tempo in real time that
finally makes an ideal accompaniment
system. We apply an efficient Neural
Network to accomplish this work. The
syllable number of the music is added to the
input of the Neural Network since the playing
characteristics are in fact different in every
syllable. Some other important inputs with
special messages are added to the Neural
Network and yield satisfactory results. We
deeply hope this musical robot kind of
project can not only improve the design
techniques in electrical and mechanical
engineering, but also promote the
combination of arts and technology.
Keywords: Automatic guitar 、 Neural
network、MIDI、Automatic accompaniment
system、Arts and technology
二、緣由與目的
4面，讓使用者輸入伴奏樂譜，在此介面下
即可進行合音音效模擬。
3.1.2 MIDI 檔案轉換
本系統亦提供對於伴奏樂曲轉換成
MIDI 檔案的功能。此功能的優點，在於使
用者若對於系統所提供的伴奏樂音滿意，
則可以將它儲存成 MIDI 檔案，方便日後隨
時播放。MIDI 檔案結構是由 Chunk 所組
成，包含了二種型式的 Chunk，分別為
Header Chunk 及 Track Chunk。一個 MIDI
檔只有一個 Header Chunk，用來記錄基本
格式資料，其後可以接一個或數個 Track
Chunk 用來記錄音符資料及 MIDI 命令資
料。MIDI 檔案由於所佔空間小，且能模擬
多種實際樂器的音效，所以廣受歡迎。
特別值得一提的是 MIDI 檔頭中，「分
割數」與節拍時間的關係必須辨明清楚。
例如若以四分音符為一拍，而分割數為
100，意思就是說一拍之內，再分割 100 個
基本時間單位，這時間單位其實就是系統
計時的中斷時間了。例如四分音符為一
拍，若拍速為每分鐘 120 拍，則一拍應有
0.5 秒，這一拍再分割 100 份，則每一基本
時間單位為 0.005 秒。而 MIDI 檔案中的音
符間隔時間，就都是用分割數表示了，亦
即如下式所示。
音符間隔時間= 分割數 * 基本時間單位
在說明 MIDI 檔案轉換之前，必須先說
明在自動吉他硬體控制方面，我們訂定了
如表 1 的自動吉他硬體控制碼，以控制自
動吉他的壓弦、撥弦、以及把位移動等動
作。
如上一小節所述，本系統在圖 3 的六
線譜編輯介面下，亦可將伴奏曲目轉換成
MIDI 檔案。但實際上，無論是上一小節的
「MIDI 合音音效模擬」，或是本小節的
「MIDI 檔案轉換」，在完成這些動作之前，
我們都是先將伴奏樂曲用硬體控制來表示
的。由於我們在上一小節 MIDI 音效模擬
中，已經能夠取得所發的音（不論單音或
合音）的音階，以及發音的時間長度，如
此一來，再配合我們對 MIDI 檔案的了解，
即可順利完成硬體控制碼轉MIDI檔案的工
作。
3.1.3 MIDI 訊息擷取
MIDI 訊息傳輸是「串列」「非同步」
傳輸的方式，速率為每秒 31,250 bits；又
每個MIDI訊息 (一組MIDI資料的單位)需
要 10 bits 來記錄，所以 MIDI 每秒鐘可以
傳送 3,125 個資料。由於 MIDI 所傳送的是
數位控制訊號，並不是聲音訊號，故可以
很有效率的表示音聲。
以鍵盤樂器連接電腦為例，當鍵入 Do
時，會傳送 903C40 的碼，這 3 個 Byte 分
別表示：
90: 發音碼（Note On）
3C: 表 DO 音 （Note Number）
40: 按鍵時的力道 （Velocity）
若要改變下一個音為吉他的音色，此時便
傳送 C019 訊息。MIDI 訊息。
簡單而言，MIDI 訊息分為兩種格式，
第一個格式為表示「命令」（command）的
「狀態位元組（Status Byte）」，第二個
格式為配合命令的「資料位元組（Data
Bytes）」。MIDI 訊息通常以一個狀態位元
組帶著二個資料位元組，共三個 bytes 組
成一道指令。若以訊息功能分類，則如圖 4
所示。
本計畫中，我們撰寫 VB 程式，擷取
MIDI 樂器傳來的主奏音樂訊息，即可了解
演奏者所演奏的音符，經由系統的分析學
習處理，決定伴奏的音符與時間。
3.2 伴奏系統設計與學習
一個包含主奏與伴奏的樂譜，如圖 5
所示。本節將說明如何設計一個理想的伴
奏系統，有關伴奏模式、音符群、學習樣
本、類神經網路學習等主題，分節說明如
下。
3.2.1 伴奏系統模式
為了增加伴奏系統的實用性，我們提
供了以下兩種模式。
模式 1：演奏者配合伴奏系統模式。
演奏者可以透過 MIDI 樂器演奏音樂，
6有類神經網路學習經驗的工程人員應
該都知道，類神經的網路架構與所要學習
的系統息息相關，結構太大或是太小，都
不適宜。經過許多測試，本計畫的類神經
網路的架構使用三層（多層）的網路架構，
分別有五個輸入、五個神經元構成的隱藏
層，以及一個輸出。我們將前述所紀錄的
學習樣本中每一次取出四筆間隔時間，前
三筆的間隔時間當作是類神經網路的前三
個輸入，第四筆的間隔時間則作為類神經
網路的輸出期望值。
類神經網路的第四個輸入，則是取當
時樂譜的行數以及該行樂譜節數所合成的
資訊。此點為本系統的特色，因為樂譜中
的每一音符間的時間間隔，與其所在的音
節息息相關，實驗驗證發現，加上此輸入，
可以大大的改善學習的結果。例如觀察過
去文獻中的結果[3]，對於彈奏者的分析，
平均就約有 0.1 秒的時間差，但對於專業
的音樂家而言，他們則希望誤差在 0.05 秒
以內。
但由於過去文獻的作者將整首樂曲一
概而論，忽略了每一音節的演奏特性。過
去文獻中的做法，是將目前所彈奏的音符
群與標準樂譜間的時間差，以及前兩個音
符群的時間差，總共三個值，作為系統的
輸入。而事實上，彈過樂器的人都應該有
所感覺，那就是對於無論初學者或是高級
的演奏者而言，演奏的節奏特性，應該每
一個音節都會不一樣的。例如對於初學者
而言，某音節不熟練，所以那個音節的節
奏反應自然會與其它地方大不相同；而對
於熟練高級的演奏者而言，為了表達音樂
的情感，也是在每一音節的詮釋都會自然
地大異其趣的。
基於此，本系統在類神經網路的輸入
上，所增加的第四個輸入節點，表示樂譜
行數與節數的資訊，以增加系統學習的成
果，是非常具有意義的，結果也顯示可以
大大地改善學習的成果。
類神經網路的第五筆輸入則是用來加
強類神經網路反應的靈敏度，因為如果樂
譜的節奏長時間維持在一定的節奏時，如
果此時有一筆節奏變化很快的資訊進來，
我們發現學習系統無法很快的反映出此變
化，而會加大學習結果的延遲效應。所以
我們試著增加此輸入，以改善系統的學習
響應速度，結果發現確實能更進一步改善
學習結果。
測試程式方面:
在相同的類神經網路架構下，輸入的
間隔時間變成即時資料，是以此測試程式
方面，是結合「學習」以及「測試」兩大
部分。也就是說，程式不只是能產生輸出
結果，而且也可以把即時輸入的間隔時間
一面做測試輸出和一面做學習的動作(修
正加權值)，在全部的測試完畢後，還會詢
問使用者，對這一次的測試結果是否滿
意？如果滿意的話，還可以重複學習這一
次的即時輸入的測試樣本，更新類神經網
路的加權值；但是如果不滿意的話，則將
類神經網路的加權值還原為進入該次測試
前的結果。
實際測試結果:
以圖 5 的鋼琴樂譜作為範例，測試後
的結果如圖 8 所示，其中橫軸為 0~120 音
符群，縱軸則為 mse 均方差。結果顯示預
測伴奏的誤差在沒有突然節奏變化的情況
下，預測誤差都維持在 0.01 秒以下，而在
突然節奏變化的情況下，學習誤差的振盪
亦會增大，但是在一、二個音節群後，振
盪就會很快的趨於平緩，而振盪期間的學
習誤差也都維持 0.05 秒以下，符合我們的
需求。
四、參考文獻
[1]. 高盟欣，樂譜編輯與電腦音樂的應用，淡江
大學資訊工程所碩士論文（1998）。
[2]. 蕭鈺恆，MIDI 在吉他編曲上的應用，淡江大
學資訊工程所碩士論文（1998）。
[3]. 模糊類神經節奏控制器在自動伴奏系統上的
應用，中華大學電機工程所碩士論文（2000）。
[4]. 陳以哲，自動鋼琴之研製，交通大學控制工
程所碩士論文（1991）。
[5]. 郭清界、張少華，卡爾卡西現代奏法 古典吉
他大教本（上）（下）。台灣：天音出版社（2001）。
[6]. 奇 美 博 物 館 ， Web:
http://www.chimei.com.tw/museum/index.html
[7]. 台灣樂蘭（Roland）企業股份有限公司
http://www.rolandtaiwan.com.tw/
[8]. 趙春棠，林奕志，進階自動吉他演奏系統之
設計與實現，pp . d-197，2005 年中華民國自動控
8圖 1. 系統架構圖
圖 2. 鋼琴鍵 Keynote 值圖示
圖 3. 六線譜樂曲編輯介面
10
圖 6.音符群圖示
1X
2X
3X
4X
5X
1H
2H
3H
4H
5H
)1,(_ hixhw
)1,(_ hixhw
),1(_ jhhyw
),1(_ jhhyw
)( jy
圖 7.類神經網路架構圖
0 20 40 60 80 100 120
0
0.2
0.4
0.6
0.8
1
1.2
x 10
-3
m
se
圖 8. 學習結果
