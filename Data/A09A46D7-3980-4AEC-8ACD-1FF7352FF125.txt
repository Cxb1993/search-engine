 ii
ABSTRACT 
 
Many scientific disciplines use maximum likelihood evaluation (MLE) to 
solve problems. As the data to be analyzed grows with the improvement 
of observation equipment, MLE demands parallelism to improve analysis 
efficiency. Unfortunately, it is very hard for scientists and engineers to 
study distributed programming languages, to learn distributed computing 
environments, and to develop their own distributed MLE applications. It 
is even harder to develop an MLE application to monitor the distributed 
system status and to use the information as feedback to adapt to the 
computing environment. From the view of software engineering, this is a 
painstaking task for application developers. 
In this thesis, we present a dynamic load-balancing MLE framework. The 
framework is based on a widely used parallel programming library, the 
message passing interface (MPI) library. Programmers can easily build 
their own adaptive distributed MLE applications based on our framework. 
Our approach does not use any extra middleware services to support 
system monitoring and load-balancing decision. Experimental results 
indicate that our framework can adapt to the change of computing 
environment. The results also show that our approach has very low 
overhead in stable computing environments. 
 
Keywords: scientific computing, distributed system, dynamic 
load-balancing, maximum likelihood evaluation/estimation, MPI 
 
 2
  除此之外，在分散式的環境之下，負載平衡(Load Balance)是一個重要的議
題，一個好的負載平衡策略能讓效能有明顯的提升。加上使用一般單處理器電腦
來處理實際的 MLE 科學或工程計算問題，通常這些演算法會需要數百到數千個
回合才能收歛到一個合理的解答，而且每一個回合常常耗費數小時完成，因此若
能在分散式 MLE 的應用程式中，加上一個調節工作負載的策略，除了可以增加
效率，也能減少開發 MLE 程式的負擔，因為科學家與工程師就可以不用分心於
設計或偵測系統的組態。 
 
三、文獻探討 
 
  本章將探討研究計畫所使用到工具，第一節介紹 MLE，是科學計算上常用
的方法，同時為本計劃所採用的方法。第二節將介紹 MPI，是一套分散式計算常
用的工具。最後一節則是介紹分散式系統中，影響效能的關鍵之ㄧ，負載平衡
(Load Balance)策略之介紹。 
 
3-1 MLE (Maximum Likelihood Evaluation/Estimation)： 
 
  最大可能性估算(MLE)，或稱為最大似然估計，是統計學的方法，它常常出
現在各種工程或科學計算的應用程式上，MLE 的方法是針對一個給定的機率公
式(Function)以及給定的資料集(Data Set) 去尋找一組最佳的參數，使得這個公式
可以產生最大的可能性。通常這個計算公式可以表示為: 
 
                                  ………..………… (1) 
 
  在 Eq.(1)中， )(QL 代表最大可能性的結果，Q 是所要尋找的參數，F 是計
算其最大可能性的公式，而 iX 是所給定的資料集中的一組資料。由於機率相乘
的結果會使得 )( QL 的結果變得很小(例如 10010  )，所以通常會將式子的兩側
都用 ln 計算後再同乘以-1，再去找左式 (或右式) 的最小值，如 Eq. (2)所示:  
 
…...……………(2) 
 
  MLE 可以平行或分散式處理的地方在於 Eq.(2)右式的加總過程，如果 n 夠
大，或者 F 函式的計算很費時，那麼使用分散式處理就可以加速 MLE 的計算。
計算 MLE 的演算法通常都為疊代式的演算法，如圖 1 所示。 
 
 
 
 
 
 
 
 
圖 1. 分散式 MLE 演算法計算過程 
)F()(
1
Q|XQ i
n
i


L
))ln(F())(ln(
1
Q|XQ i
n
i


 L
 4
Cluster，或是超級電腦，幾乎所有的機器都有支援 MPI，包含了 Linux (IA32, 
x86-64)、Mac OS/X (PowerPC, Intel)、Solaris (32-bit, 64-bit)、Windows、Blue Gene、
Cray、SiCortex 等。 
 
3-3 負載平衡 (Load Balance)： 
 
  計算網格上分配工作量的方法有很多種，第一種是以工作排程 (Job 
Scheduling)為主的工具，這一類的工具通常都需要一個集中式的服務來幫忙工作
排程，如 Globus[14]就是一個最好的例子；第二種是使用動態網格的作法，通常
這種網格系統會以 Peer-to-Peer 的方式連接在一起，而且應用程式可以只在某一
個 Peer 的節點上執行，然後行程或工作就會逐漸擴散到網格系統上空閒的電腦
執行，有名的例子如 IOS(Internet Operating System)[15][16]；第三種的研究集中
在提供一個可以在網格上使用的應用程式或計算架構，它允許使用者撰寫特殊的
應用程式模組，並將這個模組整合入它的架構中並放到網格上去執行。 
 
  而本計劃所使用的工具 MPICH2 也提供了許多種將行程(Processes)分散至各
個不同工作節點的方式，在此僅介紹其中兩種－Round-Robin 分散以及檔案指定
對應分散(Machine File Mapping)。 
 
  MPICH2 預設的分散方式是採用 Round-Robin，依照發起工作的機器之
mpdtrace (檢測有哪些機器開啟了 Message Passing Daemon 的指令)順序將行程平
均的送至各機器。假設 mpdtrace 的順序為 Machine0，Machine1，Machine2，執
行檔之名稱為 exe，欲開啟的行程數量為 10個(P0~P9) ，則輸入的指令為：mpiexec 
-n 10./exe (-n 參數之功能為指定行程數量)。 
 
  另一種方式是採用 machinefile 進行檔案指定對應分散，也就是將分配工作
的方式存入一份文字檔中，執行時在指令列輸入參數將檔案引入。若是使用者在
執行程式之前，已經先對所有使用到的機器進行過效能測試，便可依照測試結果
進行工作量分配，machinefile 內容的範例如下(圖 2)： 
 
#Comment Line 
Machine0:4 
Machine1 
Machine2:5 
圖 2. machinefile 內容範例 
 
  其中#字號為註解行符號，讀取檔案時會跳過註解行(即範例中的第一行)，
範例中的第二行之後，冒號前為機器名稱(Hostname)，冒號後為該機器可執行之
行程數量，若無冒號者則視為該機器只接受一個行程。假設 machinefile 範例之
檔名為 MF，使用者輸入之指令為 mpiexec -machinefile MF -n 9./exe (-machinefile 
參數之功能為讀入指定檔案)，使用此模式需要注意的是開啟的行程數量不可超
過 machinefile 內所設定的可執行的行程總和(範例檔 MF 上限為 10 個行程， 指
定 9 個行程可正常啟動，若是指定 11 個行程，則系統會回傳 too few entries in 
 6
化，系統的真實效能仍會是隨時間改變的，因而造成靜態效能預測的不準確，網
路頻寬就是一個很好的範例。 
 
  因此，為了彌補靜態負載平衡策略的不足，我們還需要一個可以調整工作量
的動態負載平衡的機制來進行行程的微調，在程式的動態執行時期，偵測並調整
上述效能估計錯誤的問題，以協助 MLE 程式在不同的分散式運算環境下達成較
佳的效能輸出。 
 
4-3 混合靜態與動態負載平衡之分散式 MLE 程式架構 
 
  在 MLE 的計算過程中，每一個 Iteration 都要將資料集中的每一個資料點
(Data Point)丟入 MLE 的公式中進行計算工作，當資料集的數量龐大時，我們採
用 Master-Worker 的計算架構，由 Master Process 將資料集切割為數個不重複的
子集(Subset)，再將這些子集分散給不同的 Workers 進行計算工作，便能降低整
個 MLE 的計算時間。 
 
  所以，我們一開始利用 machinefile 的配置方式，讓 master 傳送子集的資料
到各台機器上運作，同時去要求每個 Worker 回傳 Worker 內部各個 process 執行
的時間，並讓執行時間包裹在要回傳給 master 的資料中，在每一次執行完畢的
Iteration，我們先去判斷是否符合終止的條件，若符合，則終止程式；若未符合，
則執行我們開發之動態負載平衡策略。 
 
  動態負責平衡策略的執行與否，是由 master 去做判斷，master 先取出各台機
器裡面執行時間最長之 process 執行時間，因此，每一個 process 都會提供一個執
行時間，我們將提供的執行時間中最長與最短的兩個值做相減，並且去除上最短
的執行時間，判斷計算出來的值是否在我們容忍範圍之內，容忍值可以由使用者
自定義之，若超出容忍則執行重新分配。 
 
  範例如下：假設表 1 為執行時間，我們會從 Mach0 中取出 100、Mach1 中取
出 125、Mach2 中取出 80，接著將(125 – 80) / 80 所得到的即是容忍值，並比較
自定義的容忍值去作執行與否的判斷。 
表 1. Worker Process 回傳之執行時間 
Machine Mach0 Mach1 Mach2 
Process ID 0 1 2 3 4 5 6 7 8 9 10 
時間(sec) X 98 100 93 88 120 118 125 75 80 78 
 
  重新分配時，我們將各機器最長的執行時間取倒數並去乘上用來計算的
process 數量以及子資料集大小，並去把計算後的值加總，讓每一個機器去除上
此值，以求得各機器佔總執行效率的比率，接著將比率值去乘上此次 iteration 的
 8
五、結果與討論 
 
  MLE 大多需要經過數百或數千輪的計算之後才會收斂至合理解答，因此僅
使用靜態的負載平衡程式雖然少跑了一段判斷分配的程式碼，但是在靜態平衡分
配不當，以及系統情況不穩定的時候，反而會造成效能下降。 
 
  因此，我們利用本實驗室所架設的 cluster 來進行測試，我們使用一百萬筆
Data Point 的資料集做為 Input Data，以不同的 Process 數量進行 Scalability 實驗 
(圖 3)。我們發現到，即使動態的 MLE 多做了重新分配的步驟，而且實驗階段，
UGC-Cluster 的環境是處於穩定的狀態下，但其效能表現相對於只使用靜態負載
平衡的 MLE 的效率，最高提昇度卻可以達到 8.34%(圖 4)，可見本研究所開發
的動態負載平衡機制確實能改善靜態平衡分配不均的問題。 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
圖 3. Scalability Experimental Results 
 
 
 
 
 
 
 
 
 
 
 
 
圖 4. 系統穩定下 Dynamic MLE 效能改善百分比 
 10
http://etds.ncl.edu.tw/theabs/index.html. 
[9]. ISI Web of Knowledge, Available: http://apps.isiknowledge.com/. 
[10]. Message Passing Interface Forum., MPI: A Message-Passing Interface Standard 
Version 2.1., June, 2008. [Online]. Available: 
http://www.mpi-forum.org/docs/mpi21-report.pdf. [Accessed: July 21, 2009]. 
[11]. MPICH2, Available: http://www.mcs.anl.gov/research/projects/mpich2/. 
[12]. Open MPI, Available: http://www.open-mpi.org/. 
[13]. LAM/MPI, Available: http://www.lam-mpi.org/. 
[14]. Globus. Available: http://www.globus.org/ 
[15]. K. E. Maghraoui, T. J. Desell, B. K. Szymanski, and C. A. Varela., The internet 
operating system: Middleware for adaptive distributed computing., International 
Journal of High Performance Computing Applications (IJHPCA), Special Issue on 
Scheduling Techniques for Large-Scale Distributed Platforms, 10(4):467–480, 
2006. 
[16]. K. E. Maghraoui., A Framework for the Dynamic Reconfiguration of Scientific 
Applications in Grid Environments., Rensselaer Polytechnic Institute, PhD thesis, 
2007. 
[17] 本計劃程式碼放置在實驗室空間，網址為 http://140.115.52.21/code.zip 
[18] 實驗室研究生畢業論文 
http://thesis.lib.ncu.edu.tw/ETD-db/ETD-search-c/getfile?URN=965202103&file
name=965202103.pdf 
 
計畫成果自評 
 
  本研究計劃讓程式設計師可以利用我們所提出的計算架構，很快速的建立一
個分散式 MLE 應用程式，不必重複撰寫演算法，也不需要考慮如何讓各節點工
作量負載平衡的問題，簡化了分散式科學計算應用程式的發展過程。 
 
  同時降低了 MLE 入門的門檻，讓沒有分散式背景的使用者只需提供公式，
而不用去煩惱分散式程式撰寫的問題，且我們不僅僅提供分散式 MLE 程式，亦
關注於效能上的問題，所以提出一個混合式的負載平衡策略，實驗結果也確實的
顯示出對於效能是有所提升。 
 
  未來，為了讓更多人願意去使用本程式，我們需要把一些元件加到程式中，
例如多樣化 MLE 演算法的選擇，效能的再提升，大量資料的處理，都會是我們
努力的方向，這次的研究計畫，符合了當初我們預期的目標，同時也提供了我們
更多可以持續發展方向，我們將會朝這個方向做更深入的研究。 
雜等問題，需要由資訊工程領域之人員，利用各種軟體以及相關
技術作為支援。 
3. 利用不同領域研究員共同合作的方式，達成國際學術交流的目
的。爲了突破以往研究計畫中過於理論傾向，進而達到軟體實用
化的目的，本實驗室和中央大學天文所及美國夏威夷大學天文所
進行合作及技術交流，藉由使用者的實際操作及回應，我們便能
夠理解使用者需求以及問題，進而改進提昇系統完整度。同時學
習不同領域之專業知識，以符合專業人員之需求。 
4. 建構統合性資料管理介面，供未來使用者分析管理各種系統資
訊。由於 Pan-starr 計畫之各個系統目前仍然處於獨立運作的狀態，
此次出國研究另一個目的便是爲 Pan-starr 計畫設計整合性系統介
面的原型，讓不同使用者能夠利用同個介面管理及使用 Pan-starr
計畫資料，同時能讓管理者利用簡單的方式監控系統狀況。 
(二) 心    得 
因為是第一次受邀出國參加跨國計畫的暑期研究，覺得此行獲益良
多，認為未來資訊工程領域與其他不同領域的應用結合，對於雙方都
會有很大的發展空間，同時培養研究生的國際觀以及實作經驗，國內
應鼓勵跨領域以及國際化的合作方式；另外，非常期待下次能再出國
參與各種不同的研究計畫。 
