 1
Transaction on Wireless Communications. In the second year of the project, the idea that the 
channel-with-memory nature can be nearly weakened to blockwise independence by the insertive 
transmission of “random bits” between two consecutive blocks was experimented. Based on this 
idea, we further conjectured that these ``random bits'' can be another parity check bits generated 
due to interleaved information bits such that additional coding information can be provided to 
improve the system performance. A simplest exemplified structure that follows this idea is the 
parallel concatenated convolutional code (PCCC). We thus derived its respective iterative MAP 
algorithm for time-varying channel with first-order Gauss-Markov fading, and tested whether or 
not the receiver can treat the received vector as blockwise independence with 2-bit blocks 
periodically separated by single parity-check bit from the second component recursive 
systematic convolutional (RSC) code encoder. Also done in the second year was the derivation 
of the channel capacity of time-varying Gauss-Markov fading channels for comparison with the 
proposed system. Specifically, we first remarked on four different definitions of channel 
capacities according to whether the transmitter and the receiver have or do not have the channel 
state information (CSI). We then provided detailed derivations for the channel transition 
probability of the Gauss-Markov channels. As the true capacity formula for blind-CSI in both 
transmitter and receiver is hard to obtain, we derived its independent upper bound instead, and 
establish a close-form expression of the independent bound for any memory order M. 
Discussions are finally given by numerical evaluation of the independent bounds. In the last year, 
the project, we simulated and found by following our results in the previous two years that the 
performance of the insertive-random-bit system we proposed is at most 0.9 dB away from the 
Shannon limit at BER=2×10-4. Also completed in the last year of the project is the extension of 
the novel concept, combining channel estimation, equalization and error protecting coding 
technique, introduced by Skoglund, Giese and Parkvall in 2002, to the time-varying fast fading 
channel such as Gauss-Markov channels. By deriving the pairwise error probability as a code 
search criterion, our codes are shown to provide coding gains of about 3.5 dB and 6 dB, 
respectively, on the Gauss-Markov channels with channel memory orders 1 and 2 over those in 
[15] at WER= 10-2. 
 
Keywords: Time-varying multipath fading channel, Channel estimation, Channel equalization, 
Error correcting coding 
 
2.???? 
2.1 Introduction and motivations: 
 The organization of present typical receivers for wireless communications mostly includes 
channel estimation and channel equalization devices in order to compensate the channel effect. A 
milestone research in 2002 by Skoglund, Giese and Parkvall [12] however demonstrated that a 
communication scheme which jointly considers error correcting code and multipath fading effect 
can achieve markedly better performance than a typical communication system even if perfect 
channel estimation and equalization are assumed. This exciting result provides a prospect that 
makes possible the achievement of a high data transmission rate for highly mobile users. 
The main technology obstacle for high-bit-rate transmission under high mobility is the 
seemingly highly time-varying channel characteristic due to movement; such a characteristic 
enforces the dependence between consecutive symbols, and further enlarges the difficulty in 
compensating the intersymbol interference. In principle, the temporal channel memory can be 
 3
2.2 The research procedures in this project: 
Based on the above motivation, there are two issues on which we concentrate in the first 
year of the project. The first issue is to establish the optimal criterion for decoding the equalizer 
codes. The second issue is to derivate the metric formulas of the bit-wise soft-decision decoding 
for the symbol-based modulation. We describe the details in the following subsections. 
In the second year, there are two questions on which we concentrate. The first is to 
experiment on a different view in the neutralization of channel memory, where the “intersymbol 
space” may be of use to enhance the system performance. The second question that the research 
aims at is that what the capacity of a time-varying channel, like Gauss-Markov [3][4] is. Seldom 
publications have been emerged in the capacity study of Gauss-Markov channels. The 
understanding of this quantity helps the researchers understand the gap between a transmission 
scheme and the underlying limit. 
In the last year of the project, we focused on the code design over the Gauss-Markov 
channel. The reason that we are enthusiastic about Gauss-Markov channels is that it can imitate 
any fast time-varying channels as long as the order of Markov factor is large enough. We design 
two kind of codes for this channels, i.e, PCCC code with iterative MAP decoder of 
Gauss-Markov channels and a nonlinear codes searched by simulated annealing. Details will be 
provided subsequently. 
 
2.2.1 Equalizer code design: 
In the first issue in the first year, our goal is to establish a framework of a systematic 
equalizer code in the time-varying environment. An important step in this phase is to find the 
optimal decoding metric. In addition, we also need to examine the properties of the derived 
metric in order to help the code construction and subsequent decoder design. The procedure of 
our research is separated into several parts. (1) The mathematical expression of the considered 
fading channels should be well-defined. (2) Based on the chosen channel model, what the 
maximum-likelihood (ML) criterion is under i.i.d. input information bit sequence. (3) Based on 
the derived ML criterion, how to construct a code, and design its feasible decoding algorithm for 
the code. (4) Finally, to derive the channel capacity of the channel, and to examine whether our 
code can achieve the capacity of the channel. 
Two types of fast time-varying channel models are often adopted in the literature. The first 
type [11] such as Jakes’ model, second-order Butterworth and rectangular spectrum…etc. is not 
analyzable. These models are widely accepted as realistic fading channel models and are usually 
utilized in simulations; however, they are mostly not analytically tractable. The second type of 
fast time-varying channel models includes autoregressive (AR) model, time-independent model, 
polynomial model [2] and quasi-static channel, which are basically analyzable. In this part of the 
research, we chose the first-order AR model as our research goal. This model is often named 
Gauss-Markov model, which is defined as: 
kk
T
kk nr += ha  and kkk vhh += −1α  
 5
This result can gradually migrate to frequency-selective fading channels. In addition, the 
recursive property of the ML criterion can be easy to use in an iterative decoding algorithm, such 
as Soft-Output Viterbi algorithm (SOVA). 
Our next focus is on the code construction (possibly non-linear) for the chosen 
Gauss-Markov channel. The approach taken is basically to derive the pairwise error probability 
for two candidate codewords, and then uses simulated annealing algorithm to search for a good 
code. Subsequently, the mutual information of the Gauss-Markov channel is examined so that it 
can be applied to the evaluation of the channel capacity of the Gauss-Markov channel with 
unknown channel state information (CSI). 
 
2.2.2 Bit-wise decomposition of M-ary maximum-likelihood symbol metric: 
Another result that we obtained in the first year is a systematic recursive formula for 
bit-wise decomposition of M-ary symbol metric. The decomposed bit metrics can be applied to 
improve the performance of a system where the information sequence is binary-coded and 
interleaved before M-ary modulated. A straightforward receiver designed for certain system is to 
de-map the received M-ary symbol into its binary isomorphism so as to facilitate the subsequent 
bit-based manipulation, such as hard-decision decoding. With a bit-wise decomposition of M-ary 
symbol metric, a soft-decision decoder can be used to achieve a better system performance. The 
idea behind the systematic formula is to decompose the symbol-based maximum-likelihood (ML) 
metric by equating a number of specific equations that are drawn from squared-error criterion. It 
interestingly yields a systematic recursive formula that can be applied to some previous work 
derived from different standpoint. Simulation results based on IEEE 802.11a/g standards [8][9] 
show that at bit-error rate of 10−5, the proposed bit-wise decomposed metric can provide 3.0 dB, 
3.9 dB and 5.1 dB improvement over the concatenation of binary-demapper, deinterleaver and 
hard-decision-decoder for 16QAM, 64QAM and 256QAM symbols, respectively. Also, only 0.13 
dB performance degradation is resulted by introducing 32-level quantization for 16QAM signals. 
The quantization impact for 64QAM signals under 64-level uniform quantization can even be 
reduced to 0.07 dB. No further performance degradation, in addition to that due to quantization, 
can be observed, when mismatch of AGC gain is limited to be within± 40%. The robustness of 
the proposed bit-decomposed metric against phase noise is also examined. When the phase drift 
increases up to± 6o, the BER due to our bit-decomposed metric will increase from 10-5 to around 
4×10-5 at Eb/N0 = 6.7 dB for 16QAM modulation. This phase drift tolerance reduces to± 4o at 
Eb/N0 = 9.7 dB for 64QAM modulation, where Eb/N0 is chosen such that the no-phase-drift BER 
is approximately 10-5. The system architecture considered is as follows. 
 
 7
impulse response hk =?hk + vk at time k, where vk is a complex white Gaussian with mean d and 
covariance C, and ? is a complex first-order Markov factor whose absolute value |?| = e-?T 
with Doppler spread ?/? and sampling period T [13]. As it can be seen, the Gauss-Markov 
channel is a channel whose time-varying behavior is constituted by Markovians and Gauss 
random variables. 
 
2.2.4 A lower bound of the Shannon limit: 
There are four kinds of capacities according to different assumptions on the knowledge that 
the transmitter and the receiver have. In notations, C(S) corresponds to that both the transmitter 
and the receiver are unaware of the channel state, while C’(S) is the capacity under the 
assumption of perfect CSI knowledge to both the transmitter and the receiver. If only the receiver 
knows the channel state, the capacity is denoted by C(R)(S). If only the transmitter is aware of the 
CSI, the capacity is denoted by C(T)(S). Their formulas are listed below. 
dydh
yp
xyp
hxypxPhpSC
dydh
hyp
hxyp
hxypxPhpSC
dydh
yp
xyp
hxypxPhpSC
dydh
yp
xyp
hxypxPhpSC
Y
XY
y HXY
Xx
XSPbPH H
HY
HXY
y HXY
Xx
XH HSPbP
R
Y
XY
y HXY
Xx
XSPbPH H
T
Y
XY
y HXY
Xx
XH HSPbP
X
X
X
X



=



=



=



=
∫∑∫
∫∑∫
∫∑∫
∫∑∫
∈∈
∈∈
∈∈
∈∈
)(
)|(
log),|()(max)()('
)|(
),|(
log),|()()(max)(
)(
)|(
log),|()(max)()(
)(
)|(
log),|()()(max)(
|
,|)(
|
,|
,|)(
)(
|
,|)(
)(
|
,|)(
 
After defining four definitions of channel capacity, we wish to evaluate the last one based on 
the Gauss-Markov fading channel model. Unfortunately, the problem of finding the channel input 
statistics that maximizes the channel input-output mutual information is beyond our management 
at this stage. Thus, we turn to the determination of good upper bounds for capacities. 
 
Theorem. Assume that there exists a complex number µk such that µk,i = ρi µk for some real 
number ρi for every 1 ≤ i ≤ M, where µk = [µk,1, µk,2, …, µk,M]. Also, C is diagonal. Then, the 
capacity-cost function for blind-CSI system is upper-bounded by: 
dtStSeSSCSC
R
t∫ 










 +−=≤ −∞ 22/2 2||
2coshlog
2
12)()(
2
δδπδ  
where 
2
1
1 ,2
2
2
||
||1
1
||1



−
−+=
∑
∑
=
=
M
i i
M
i ii
CS
µα
ασδ . 
With the availability of capacity upper bounds, performance lower bounds for bit error rates 
(BERs) can be obtained by means of the rate-distortion theorem and the joint source-channel 
coding theorem [15]. One can then evaluates the performance lower bound numerically in 
 9
z Set )()( 1 KsKs TT αβ =+  for s=0,?,15. 
z For i=K,?,1 and 15,,0 L=s , perform ),()()( 115
0
1 +
=
+∑= isiss isis TTTT γαβ  
4) Soft output: 
z For i=1,?,K, update 
∑
∑
∈
−−
∈
−−
−
−=Λ
)0(1
)1(1
),(
11
),(
11
)(
1 ),()()(
),()()(
log)(
i
i
s
i
s
i
i
s
i
s
BTT
i
s
i
s
i
s
i
s
BTT
i
s
i
s
i
s
i
s
n
TTTT
TTTT
i γβα
γβα
 
and 
)()()(
2
)()( )1(2
)1(
21)1(3
*
1)1(3
*
1)1(31)1(32
1)1(3
2
1)1(3)(
1
)(
1 iihrhr
G
ii ne
n
eiiii
i
inn
e
−−
+−+−+−+−
+−
+− Λ−Λ−+−Λ=Λ σσ  
Step 3: Calculate )(2
nΛ  and )(2neΛ  
1) Initialization:  
z For i=1,?,K, )1/(1}0Pr{ )()1(1 ii
n
eeu
−Λ+==  and }0Pr{1}1Pr{ =−== ii uu  
z For i=1,?,K, s=0,?,15 and 15,,1 L=s , compute ),( 1 isis TT −γ  as 







∪∉
∈=
∈=
= ∏
∏
=
=
− +−+−
+−+−
(1)
i
(0)
i
1
(1)
i
12
1
||
)(
(0)
i
12
1
||
)(
1
BB)( if,0
B)( if,}1Pr{
B)( if,}0Pr{
),(
2|3|32
)1)((3)1)((3
2|3|32
)1)((3)1)((3
i
s
i-
s
i
s
i-
sk
eqG
il
i
s
i-
sk
eqG
il
i
s
i
s
,TT
,TTeu
,TTeu
TT
iqiG
kilkil
iqiG
kilkil
&&&
&&&
&&&
&&&γ  
2) Forward recursive: 
z Set 1)( 00 =Tα  and for s=1,?,15, 0)( 0 =sTα . 
z For i=1,?,K and s=0,?,15, perform ),()()( 115
0
1 i
s
i
ss
i
s
i
s TTTT
−
=
−∑= γαα  
3) Backward recursive: 
z Set )()( 1 KsKs TT αβ =+  for s=0,?,15. 
z For i=K,?,1 and 15,,0 L=s , perform ),()()( 115
0
1 +
=
+∑= isiss isis TTTT γαβ  
4) Soft output: 
z For i=1,?,K, update 
∑
∑
∈
−−
∈
−−
−
−=Λ
)0(1
)1(1
),(
11
),(
11
)(
1 ),()()(
),()()(
log)(
i
i
s
i
s
i
i
s
i
s
BTT
i
s
i
s
i
s
i
s
BTT
i
s
i
s
i
s
i
s
n
TTTT
TTTT
i γβα
γβα
 
 11
construct good source codes, error-correcting codes, spherical codes [6], and also codes 
combining channel estimation and error protection [15] by optimizing the cost functions like 
distortion of source codes, minimum distance, minimum separating angle, and union bound of 
block error probability, respectively. 
 
2.3 Achievements: 
 
2.3.1 Equalizer codes technology: 
  
We derived the ML metric for nonzero-mean-channel-response Gauss-Markov channel, and 
developed a suboptimum metric for off-line Viterbi algorithm, where the optimal heuristic 
function for the fast fading channels with Gauss-Markov model is showed. Our ongoing aim is on 
the design and performance evaluation of iterate decoding algorithm for time-varying 
Gauss-Markov channel. 
 
2.3.2 Bit-wise decomposition of M-ary maximum-likelihood symbol metrics: 
 
The two figures below reveal our Soft-proposed metric can further improve the performance 
of hard-decision, and approach to ideal symbol-ML performance. Further empirical study on 
system imperfection implies that the proposed bit-wise decomposed metric also improves the 
system robustness against gain-mismatch and phase-noise. 
 1e-07
 1e-06
 1e-05
 0.0001
 0.001
 0.01
 0.1
 1
 0  1  2  3  4  5  6  7  8  9  10  11
B
E
R
Eb/No
16QAM
Symbol-ML
Soft-proposed
Hard
 
 1e-07
 1e-06
 1e-05
 0.0001
 0.001
 0.01
 0.1
 1
 0  1  2  3  4  5  6  7  8  9  10  11  12  13  14  15  16
B
E
R
Eb/N_o
64QAM
Symbol-ML
Soft-proposed
Hard
 
 
2.3.3 A lower bound of the Shannon limit: 
 
Figure 2 shows the independent bounds for Gauss-Markov channels of different memory 
orders. By intuition, for fixed Ci,i and µi, the higher the channel memory order, the more involved 
in received vector y at the receiver end. Thus, it is reasonable to expect a lower capacity for larger 
 13
 
Figure 4: (a) (left) Performance comparison between the iterative MAP decoding and a lower bound of the Shannon 
limit. Parameters of Gauss-Markov channels are ? = 0.995, 2vσ  = 0:01 and h0 = 1. (b) (right) Performance 
comparison between the iterative MAP decoding and a lower bound of the Shannon limit. Parameters of 
Gauss-Markov channel are?= 0:995, 2vσ  = 0:001 and h0 = 0:5. 
 
2.3.5 Code construction: 
We have simulated two designed codes for different channel lengths of the Gauss-Markov 
channel. One is for M=1, a singular path model, and the other for M=2, a channel with two fading 
paths. The codes were first encoded as BPSK signals, suffered fading through the Gauss-Markov 
channel, and then decoded according to the optimal rule. We compared the performance of our 
designed codes to the code presented in [15]. Figure 5(a) and 5(b) shows the word error rate 
(WER) for the designed (10, 5) code with N=10, K=5 when the channel length M=1 and M=2, 
respectively. Both codes use the optimal decoding rule. It can be observed that our designed code 
indeed outperforms the code given in [15] on Gauss-Markov channels. The coding gain is about 
3.5 dB at WER = 10-2 when M=1 and is enlarged to 6 dB when M=2. Hence, when the channel 
becomes multipath, the performance gain of the designed code is almost double to that of the 
code given in [715] even though both codes perform worse than on the single path channel 
(M=1). 
  
 
Figure 5: (a) (left) Word error rate for (10,5) code on the Gauss-Markov channel (M=1). (b) (right) Word error rate 
for (10,5) code on the Gauss-Markov channel (M=2). 
 
 15
[7] W. C. Y. Lee, “Estimate of channel capacity in Rayleigh fading environment,” IEEE Trans. 
Veh. Technol., vol. 39, no. 3, pp. 187-189, Aug. 1990. 
[8] IEEE Std 802.11a-1999, Part 11: Wireless LAN Medium Access Control (MAC) and 
Physical Layer (PHY) specifications: High-speed Physical Layer in the 5 GHz band,   
Sept. 1999. 
[9] IEEE Draft 802.11g, Part 11: Wireless LAN Medium Access Control (MAC) and Physical 
Layer (PHY) specifications: Further Higher Data Rate Extension in the 2.4 GHz band, 
Draft 8.2, Apr. 2003. 
[10] J. P. Imhof, “Computing the distribution of quadratic forms in normal variables," 
Biometrica, vol. 48, no. 3-4, pp. 419-426, 1961. 
[11] L. J. Mason, “Error Probability Evaluation for Systems Employing Differential Detection 
in a Rician Fast Fading Environment and Gaussian Noise, ” IEEE Trans. Commun., vol. 35, 
pp39-46, Jan. 1987. 
[12] M. Skoglund, J. Giese and S. Parkvall, “Code design for combined channel estimation 
and error protection,” IEEE Trans. Inform. Theory, vol. 48, pp. 1162-1171, May. 2002. 
[13] M. Stojanovic and Z. Zvonar, ``Performance of multiuser diversity reception in Rayleigh 
fading CDMA channels,'' IEEE Trans. Commun., vol. 47, no. 3, pp. 356-359, March 1999. 
[14] H. S. Wang and P.-C. Chang, “On verifying the first-order Markovian assumption for a 
Rayleigh fading channel model,” IEEE Trans. Veh. Technol., vol. 45, pp353-357, May. 
1996. 
[15] Chia-Lung Wu, Ya-Ting Cho, Po-Ning Chen and Yunghsiang S. Han, “Iterative MAP 
algorithm for Gauss-Markov channel, ” in preparation for submission. 
???????? 
1. ??? [2005 June], ????: ????-????????? (Code Construction 
for Gauss-Markov Fading Channel) 
2. ??? [2005 June], ????: ??-????????????????? 
(Iterative MAP algorithm for Gauss-Markov Channel) 
3. ??? [2005 June], ????: ??-????????????????????
? (Upper Bounds of Channel Capacity for Bipolar Transmission Over Gauss-Markov 
Fading Channel) 
4. ??? [2004 June], ????: ?????????????????????? 
(Bit-wise Decomposition of M-ary Symbol Metric) 
o ?????????? ???????????????  
5. Chia-Wei Chang, Po-Ning Chen and Yunghsiang S. Han, “A systematic bit-wise 
decomposition of M-ary symbol metric,” To appear, IEEE Trans. Wireless 
Communications. 
