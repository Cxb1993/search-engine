 行政院國家科學委員會補助專題研究計畫成果報告 
The research published the following thirteen SCI papers 
Ching-Liang Su, “Ring Line Mapping and Rotation Inertial for 
Fingerprint Identification,” INFORMATICA, (October 2010), EI, 
SCI (COMPUTER SCIENCE, INFORMATION SYSTEMS, 79/92, 
IF 0.329) (Accepted) 
Ching-Liang Su, “Palm-print Recognition by Matrix Discriminator,” 
EXPERT SYSTEMS WITH APPLICATIONS, 36 (May 2009) 
10259–10265, EI, SCI (COMPUTER SCIENCE, ARTIFICIAL 
INTELLIGENCE 33/229, IF 2.596) 
Ching-Liang Su, “Palm Extraction and Identification,” EXPERT 
SYSTEMS WITH APPLICATIONS, 36 (March 2009) 1082–
1091 ,NSC 96-2221-E-212-004, EI, SCI (COMPUTER SCIENCE, 
ARTIFICIAL INTELLIGENCE 33/229, IF 2.596) 
Ching-Liang Su, “Hand Image Recognition by the Techniques of 
Hand Shape Scaling and Image Weight Scaling,” EXPERT 
SYSTEMS WITH APPLICATIONS, Volume 34, Issue 4, May 
2008, Pages 2976-2987,NSC 95-2221-E-212 –003, EI, SCI 
(COMPUTER SCIENCE, ARTIFICIAL INTELLIGENCE 33/229, IF 
2.596) 
Ching-Liang Su, “Finger Edge Extraction and Finger Shape 
Comparisons for Person’s Identification By Using Index, Middle, 
and Ring Fingers,” Applied Mathematics and Computation, 197 
(March 2008) 643 – 653, NSC 96-2221-E-212-004, EI, SCI 
(APPLIED MATHEMATICS 59/150, IF 0.816) 
Ching-Liang Su, “Extraction of Index, Middle, and Ring Finger 
Characteristics and Their Identification,” SENSOR LETTERS, 
February 2008, Vol. 6, No 1, pp. 184–196, NSC 96-2221-E-212-004, EI, 
SCI (INSTRUMENTS & INSTRUMENTATION 11/55, IF 1.587) 
Ching-Liang Su, “Finger Shape Expansion and Recognition by 
Wavelet Transform,” Applied Mathematics and Computation 
190 (May 2007) 1583–1592, NSC 95-2221-E-212-003.EI, SCI 
(APPLIED MATHEMATICS 59/150, IF 0.816) 
 
 
ABSTRACT 
 
This study uses the object extracting technique to extract: thumb, index, middle, ring, and small 
finger from the hand images. The algorithm developed in this study can determine the precise 
locations of the fingertips and the finger-to-finger-valleys. The extracted fingers contain many 
useful geometrical features, which are used to identify different persons. The geometrical 
descriptor is used to transfer geometrical features of fingers to another feature domain for image 
comparison. Image subtraction is used to examine the difference of two fingers.  
 
Keywords: Finger shape information extraction, finger shape computation and identification. 
 
1. Introduction 
 
In the past twenty years, researchers have devoted much attention to identify the hands, which 
have included: hand-geometry matching [Amayeh et al., 2007; Ferrer et al., 2006; Malassiotis et 
al., 2006; Mitome et al., 2003; Savic et al., 2007; Su, 2003; Xionga et al., 2005; Xiong et al., 
2005; Yin et al., 2007; Yoruk et al., 2006], vector support recognition [Bartkut et al., 2009], group 
delau feature [Bastys et al., 2010; Lipeika et al., 2010], middle finger crease pattern matching [Joshi 
et al., 1998; Ravikanth et al., 2007], various finger size measurements [Sanchez-Reillo et al., 
2000], various finger lateral view size measurements [Sanchez-Reillo et al., 2000], vein pattern 
[Lin et al., 2004], eigenpalm, implicit polynomials [Oden et al., 2003], algebraic invariants [Oden 
et al., 2003], Karen invariant computation [Oden et al., 2003], line interception and slope 
comparisons, control point selection, coarse to fine strategy [Han et al., 2004], B-spline [Ma et al., 
2004], principal component analysis [Yoruk et al., 2006; Yoruk and Konuko˘glu et al., 2006], 
Hausdorff distance [Yoruk and Konuko˘glu et al., 2006;], watershed transform [Lin et al., 2004], 
and HMM. However, some of these techniques are very sensitive to noise [Joshi et al., 1998]; 
some have very complicated mathematical models [Oden et al., 2003]; some have very 
complicated neural training algorithms. 
In the aforementioned research, when performing hand-geometry matching for recognizing 
images, the hand must be placed in a precise fixed position before the camera can capture the 
same image. In the present study [Su, 2003] the hand does not need to be placed in a definite 
position; still, the hand recognition algorithm can recognize them. In past research a wavelet 
technique [Han et al., 2004] was used to locate the finger-to-finger valley, whereas, in the present 
study [Su, 2003], the proposed recognition algorithm automatically calculates and examines the 
finger-edge energy response signals and selects the high-energy signals to locate the 
finger-to-finger valleys. The proposed algorithm locates the finger-to-finger valleys more 
accurately and more efficiently; it amputates fingers from the hand image automatically and 
calculates the features and shapes of each finger; it also uses amputated fingers to generate 
additional geometrical features containing more opulent data than the finger crease pattern [Joshi 
et al., 1998] and the rude finger shape matching methods [Han et al., 2004; Sanchez-Reillo et al., 
2000]. Implicit polynomials [Oden et al., 2003] have much difficulty in describing finger shapes 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
3. The extraction of the index, middle, and ring fingers. 
 
By using the geometry feature of the fingertips and finger roots, one can extract the index, 
middle, and ring fingers. The extracted results are shown in figure 3.1.  
 
4. Image registration and image subtraction. 
 
The object’s centroid can be defined as (ic, jc). In equations 4.1 and 4.2, idistance represents the 
i-distance of a specific pixel g(i, j) to the object’s centroid (ic, jc) and  jdistance represents the 
j-distance of a specific pixel g(i, j) to the object’s centroid (ic, jc). Weightij represents the gray 
level of a specific pixel g(i, j). By using equation 4.3, the object’s orientation can be obtained. In 
equation 4.4, θdifference represents the difference of the orientations between two images. After 
performing the function of equation 4.4, a specific pixel in location (i, j) would be rotated to 
position (if, jf). After the image rotating, shifting, and interpolating, two finger images are 
overlapped. Since both finger images are overlapped, image subtraction can now be applied to 
compare the difference of these two finger images. By the subtracted result, one can identify the 
different persons. Figures 4.1 shows the image subtractions of the finger images.  
 
5. Results and conclusions. 
 
In this research, one person needs to place his hand at three different positions for the photos 
taken. Totally three photos are taken for each person. In this research, totally ten persons 
participate in the experimental test. These ten persons are divided into two groups. Each group 
Figure 2.3: The geometry features of the hand image.
 
Most-right pixel
Most-bottom pixel
Most-left pixel
Figure 2.4: The extracted fingertips and finger valleys.
 
 
 
Figure 4.1: Subtracted images. 
 
 
 
 
Figure 5.1: Comparison results. 
 
 
 
 
Original image Rotated andshifted image
Subtracted
image Original image
Rotated and
shifted image
Subtracted
image
1st person's 1st
picture subtract
1st person's 2nd
picture
3rd person's 1st
picture subtract
3rd person's 3rd
picture
1st person's 1st
picture subtract
3rd person's 1st
picture
1st person's 1st
picture subtract
5th person's 1st
picture
 
請依學術成就、技術創新、社會影響等方面，評估研究成果之學術或應用價值（簡要敘述
成果所代表之意義、價值、影響或進一步發展之可能性）（以 500字為限） 
This study published 13 SCI papers. To this study, the hand is fixed and the respective fingers are 
extracted separately. Next, the shape and geometrical features of them are compared. Thereby, 
they are recognized. In recent research, there are very few researchers have used fingers to 
recognize persons. Thus, there are very few academic publications in this area. Although there are 
some publications, they still have the following problems: They might be only in the primitive 
assumption stage. Thus, no actual coding or software test is conducted. Subsequently, no actual 
reorganization result is presented. For this study, computer coding, algorithm, mathematical 
model, and commercial database are used to conduct this study. After the camera takes the hand 
image, automatically the aforementioned integrated system processes the finger images without 
further human involvement. Subsequently, the “yes” or “no” result is given whether the compared 
fingers are belonging to the same person. The index finger is used as the test object to recognize 
person at the beginning of this study. Then middle and ring fingers are added in. After that palm 
and palm print are also tested. Both gray and binary images are studied. The nails are growing for 
the time being, whereby the fingertips are truncated. The finger roots are also truncated. As when 
one person takes his hand image, he might or might not stretch his five fingers widely. As a result, 
the finger roots might stick together. Subsequently, inaccurate fingers are extracted. Therefore, 
the finger roots are truncated. 
The advanced finger recognition technology is developed in this study. Several new algorithms 
and many advance mathematic models are also developed. Tremendous training is give to 
students, when guiding the students. Thereby huge amount of contribution is given to the industry 
and to the society.  
The hand back with finger sticking together is tested now. This developed technique can also be 
applied to iris and the knuckle crease pattern recognition. 
 
the hand image automatically and calculates the features
and shapes of each ﬁnger; it also uses amputated ﬁngers
to generate additional geometrical features containing
more opulent data than the ﬁnger crease pattern (Joshi
et al., 1998) and the rude ﬁnger shape matching methods
(Han, 2004; Han et al., 2003; Sanchez-Reillo et al., 2000).
Implicit polynomials (Oden et al., 2003) have much diﬃ-
culty in describing ﬁnger shapes by the power-of-seven
polynomial functions. In the previous research, palm-prints
(Han, 2004; Han et al., 2003), iris, ﬁngerprints, facial fea-
tures, and vein patterns (Lin & Fan, 2004) were also used
to identify diﬀerent individuals.
In this study, the techniques of database SQL searching
and manipulation, image dilation and erosion, object-posi-
tion locating, and image shifting, rotating, and interpolat-
ing are used to identify palms. The hand is ﬁxed each time
when a photograph is acquired, and one can assume that
each time when a hand image is acquired, the image is
the same as the previous one. Since the photographs are
the same, after the palm images have been extracted from
the hand image, the acquired images can be used to identify
diﬀerent persons.
This report consists of ﬁve sections. Section 2 describes
the process for acquiring the positions of ﬁngertips and ﬁn-
ger-to-ﬁnger-valleys; Section 3, the process for extracting
palm image. Section 4 explains image registration and
subtraction; Section 5, the other palm extraction methods.
Section 6 concludes this report.
2. Acquiring hand images and locating positions
Fig. 1 shows the acquired hand images. After further
processing, thinned images of hand-edges, as shown in
Fig. 2, can be obtained. By using Eq. (2.1), an energy
response signal from a hand-edge image can be obtained.
By using this signal, the positions of thumb tip, small ﬁn-
gertip, thumb-index-ﬁnger-valley, index-middle-ﬁnger-val-
ley, middle-ring-ﬁnger-valley, and ring-small-ﬁnger-valley
can be located. These features are shown in Fig. 3. Fig. 4
Fig. 2. Hand-edge images.
Rightmost pixel
Bottommost pixel
Leftmost pixel
Fig. 3. Fingertips and ﬁnger-valleys automatically located by algorithm.
Fig. 1. Acquired hand images.
C.-L. Su / Expert Systems with Applications 36 (2009) 1082–1091 1083
shows the database that is used to locate the middle-ring-
ﬁnger-valley. By using the mathematical calculation in
Eq. (2.1), one can generate an energy response signal from
the hand-edge, as shown in Fig. 4, wherein energy signal
energy (K259) has the minimum value among the response
signals listed. Thus, point K259 is selected as the middle-
ring-ﬁnger-valley. In Fig. 5, energy signal energy (K547)
has the minimum value among the response signals listed.
Thus, point K547, is selected as the thumb tip. By this
method, the locations of all feature points can be located.
Energy ðKnÞ
H and outline pixel number
n¼1
¼ Distance
H and outline pixel number
n¼1
kðKn10Þ toðKnþ10Þk
ð2:1Þ
3. Extracting palm
Fig. 6 shows the positions of the ﬁnger-valleys. As men-
tioned previously the positions of the ﬁnger-to-ﬁnger-val-
leys can be precisely located. After locating the valley
positions shown in Fig. 6, the index, middle, and ring ﬁn-
gers can be amputated, as shown in Fig. 7. All these par-
tially truncated images are shown in Fig. 8. Binary pixels
can be added to the truncated images to generate binary
images, as shown in Fig. 9. Fig. 10 shows the positions
of the small-ﬁngertip and the ring-small-ﬁnger-valley. After
locating these features, the small-ﬁnger can be dilated and
truncated as shown in Fig. 11. Fig. 12 shows all the four-
Fig. 6. Location of ﬁnger-valley positions.
Fig. 7. Image with index, middle, and ring ﬁngers truncated.
Fig. 8. Images after truncation of index, middle, and ring ﬁngers.
Fig. 9. Binary images.
C.-L. Su / Expert Systems with Applications 36 (2009) 1082–1091 1085
Var1 ¼
X128
j¼1
X128
i¼12  idistance  jdistance  weightij ð4:1Þ
Var2 ¼
X128
j¼1
X128
i¼1ðidistanceÞ
2  weightij

X128
j¼1
X128
i¼1ðjdistanceÞ
2  weightij ð4:2Þ
ObjO ¼
cos1 Var1ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
Var12þVar22
p
2
ð4:3Þ
if
jf
1
2
64
3
75 ¼
i cos hdifference þ j sin hdifference
i sin hdifference þ j cos hdifference
1
2
64
3
75 ð4:4Þ
5. Other extracting methods
Fig. 18 shows the further erosion and truncation of the
small-ﬁnger with two additional pixels. The same proce-
dure can be done for the thumb, as shown in Fig. 19.
Fig. 20 shows the erosion and truncation of the bottom
of a palm image. After performing these erosions, more
concise palm images can be obtained, as shown in
Fig. 21. Fig. 22 shows the geometrical comparison of these
images. Binary pixels can also be added into the eroded
palms. Then, the images can be compared to identify diﬀer-
ent individuals. Fig. 23 shows binary palms; Fig. 24, com-
parison of them.
6. Results and conclusion
In this study, each participant’s hand was placed in three
diﬀerent positions for photographing. Three photographs
of the hand were taken for each of the 57 persons partici-
pating in this study. By adjustment diﬀerent illuminations
were provided to each hand image. After the photographs
were taken, several problems were found in the hand
images; e.g., the middle and ring ﬁngers of several hands
Fig. 15. Hand images without ﬁngers.
Fig. 16. Image comparison.
C.-L. Su / Expert Systems with Applications 36 (2009) 1082–1091 1087
Fig. 22. Geometrical comparison.
Fig. 23. Binary images.
Fig. 24. Comparison between two images.
C.-L. Su / Expert Systems with Applications 36 (2009) 1082–1091 1089
downward-pointing arrow represents the value-range of
genuine comparisons. Fig. 29 shows the FAR and FRR
of the palms. It can be observed that the overall error rate
was below 3% for the entire experimental results.
Acknowledgement
The author expresses appreciation to Dr. Cheryl J. Rutl-
edge, Department of English, Da Yeh University, for her
editorial assistance.
References
Egiazarian, K. O., & Gonzalez Pestana, S. (2002). Hand shape identiﬁ-
cation using neural networks. The International Society for Optical
Engineering, 4667, 440–448.
Ferrer, M. A., Travieso, C. M., & Alouso, J. B. (2006). Using hand
knuckle texture for biometric identiﬁcations. IEEE A& E Systems
Magazine.
Han, C.-C. (2004). A hand-based personal authentication using a coarse-
to-ﬁne strategy. Image and Vision Computing, 22, 909–918.
Han, C.-C., Cheng, H.-L., Lin, C.-L., & Fan, K.-C. (2003). Personal
authentication using palm-print features. Pattern Recognition, 36,
371–381.
He, B., Qiu, Z.-D. & Sun, D.-M. (2002). Secure authentication system
incorporating hand shapes veriﬁcation and cryptography techniques.
In IEEE region 10 annual international conference, proceedings/TEN-
CON, Vol. 1 (pp. 156–159).
Joshi, D. G., Rao, Y. V., Kar, S., & Kumar, V. (1998). Computer vision
based approach to personal identiﬁcation using ﬁnger crease pattern.
Pattern Recognition, 31, 15–22.
Kumar, A., Wong, D. C. M., & Shen, H. C. (2003). Personal veriﬁcation
using palmprint and hand geometry biometric. In Lecture notes in
computer science, Vol. 2688 (pp. 668–678), . Heidelberg: Springer-
Verlag.
Lia, W., Zhang, D., & Xub, Z. (2003). Image alignment based on invariant
features for palmprint identiﬁcation. Signal Processing: Image Com-
munication, 18(5), 373–379.
Lin, C.-L., & Fan, K.-C. (2004). Biometric veriﬁcation using thermal
images of palm-dorsa vein patterns. IEEE Transactions on Circuits and
Systems for Video Technology, 14(2).
Lua, G., Zhang, D., & Wanga, K. (2003). Palmprint recognition using
eigenpalms features. Pattern Recognition Letter, 24(9–10), 1463–1467.
Ma, Y., Pollick, F., & Terry Hewitt, W. (2004). Using B-spline curves for
hand recognition. In Proceedings of the 17th international conference on
pattern recognition (ICPR’04).
Malassiotis, S., Aifanti, N., & Strintzis, M. G. (2006). Personal authen-
tication using 3D ﬁnger geometry. IEEE Transactions on Information
Forensics and Security, 1(1).
Mitome, A. & Ishii, R. (2003). A comparison of hand shape recognition
algorithms. In The 29th annual conference of the IEEE industrial
electronics society, November 2–6.
Oden, C., Ercil, A., & Buke, B. (2003). Combining implicit polynomials
and geometric features for hand recognition. Pattern Recognition
Letter, 24(13), 2145–2152.
Sanchez-Reillo, R., Sanchez-Avila, C., & Gonzales-Marcos, A. (2000).
Biometric identiﬁcation through hand geometry measurements. IEEE
Transactions on Pattern Analysis and Machine Intelligence, 22(10),
1168–1171.
Su, C.-L. (2003). Technique for person’s identiﬁcation: Using the extracted
index ﬁnger image to identify individuals. Journal of Intelligent and
Robotic Systems, Netherlands, 37(3), 337–354.
Sun, D.-M. & Qiu, Z.-D. (2004). Automated hand shape veriﬁcation using
HMM. In The seventh international conference on signal processing
proceedings (ICSP’04) (pp. 2274–2277).
Xiong, W., Xu, C., & Heng Ong, S. (2005). PEG-FREE human hand
shape analysis and recognition ICASSP (pp. 77–80).
Xionga, W., Toha, K.-A., Yaua, W.-Y., & Jiangb, X. (2005). Model-
guided deformable hand shape recognition without positioning aids.
Pattern Recognition, 38, 1651–1664.
Yoruk, E., Dutagaci, H., & Sankur, B. (2006). Hand biometrics. Image
and Vision Computing, 24, 483–497.
Yo¨ru¨k, E., Glu, E. K., & Sankur, B. (2006). Shape-based hand
recognition. IEEE Transactions on Image Processing, 15(7).
You, J., Li, W., & Zhang, D. (2002). Hierarchical palmprint identiﬁcation
via multiple feature extraction. Pattern Recognition, 35(4), 847–859.
First
person
Second
person
Third
person
Fourth
person
Fifth
person
FAR
.
.
.
0
5
10
FRR 1st group
.
.
.
FAR
0
5
10
FRR
2nd group
Fig. 29. FRR and FAR for palm images.
.
.
.
.
.
.
.
First
Person
Imposter
Comparison
Genuine
Comparison
Imposter
Comparison
Genuine
Comparison
Second
Person
Imposter
Comparison
Genuine
Comparison
Third
Person
Genuine
Comparison
Fourth
Person
Genuine
Comparison
Fifth
Person
5.4
4.7
5.8
6.6
4.5
.
.
.
Imposter
Comparison
14.2
5.8
7.9
9
10
11
12
5
6
7
8
2
3
4
Imposter
Comparison
3.7
5.4
Fig. 28. Gap between imposter and genuine comparisons for palm images
(·10,000 to obtain actual number).
C.-L. Su / Expert Systems with Applications 36 (2009) 1082–1091 1091
•         Translational Biomedical Research 
•        Women＇s Health Issues 
 
The ‘1st International Conference on Drug Design and Discovery’ was held in Dubai from February 4th - 7th, 
2008.  Eleven Nobel laureates and more than 850 international delegates participated in this event!  It was an outstanding 
success by all accounts. 
 
二、 與會心得 
I am very glad to join this conference. I talked with many scientists, who were coming from different 
countries. Many interesting papers are presented in this conference and I came out the following new 
things after I attended this conference:  
 
1. Discover a drug is a painful and hard process, many disease-survey and experimental-test are needed. 
However, the excitement is great when the job is accomplished. 
2. One female scholar from MIT presented the brain memory enhancement drug, by which to increase the 
ability of memorization of brain. To test the effectiveness of this drug, a special swimming pool 
equipped with electrical-shock poles is designed, by which to test the memorized ability of the 
rats. If the drug is injected, it proves the rat has stronger memorized-ability to memorize the 
path to back to home with fewer electrical-shock; however, it proves otherwise. 
3. One research presented the technique to find all the paths of retina vessels in the eye. 
4. The earlier detection of the breast cancer by the disease symptom of various sizes of growing tissue 
pea shape features is presented. 
5. H1N1 influenza detection by the equipment of Nero technology is shown in this conference. 
6. The new drug for cancer treatment which to kill the bad cells however to preserve the good ones 
is also presented. 
7. Microchips to allow the blind persons to regain their sights are also presented in this conference.
 
三、 考察參觀活動(無是項活動者省略) 
 
四、 建議 
In this conference, huge amount of scientist participate this conference. In the future, Taiwan needs
to promote its economy and develop more high-end technique. I hope we can invite other scientists to 
Taiwan to give a talk whereas high-end techniques can be developed in here.   
 
五、 攜回資料名稱及內容 
The various fliers of other future conferences are distributed in the conference board and they are 
carried back to Taiwan. Sever related interesting papers are received in recent days from other 
scientists, who attend this meeting. I obtained the addresses of them, who also conduct the image 
國科會補助計畫衍生研發成果推廣資料表
日期:2010/11/28
國科會補助計畫
計畫名稱: 手指指頭及掌形識別使用特性點自動擷取,指頭取出,矩陣相關迴旋,旋轉向量
不變慣性(I)
計畫主持人: 蘇慶良
計畫編號: 98-2221-E-212-016- 學門領域: 資訊系統
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
Member of International Program Committee, ＇The 6th International 
Conference on Computer Graphics Theory and Applications, GRAPP is 
organized by INSTICC - Institute for Systems and Technologies of 
Information, Control and Communication＇, Algarve, Portugal, 5 - 7 
March, GRAPP 2011 
  
Member of International Program Committee, ＇The 5th International 
Conference on Computer Graphics Theory and Applications, GRAPP is 
organized by INSTICC - Institute for Systems and Technologies of 
Information, Control and Communication＇, Angers, France, May 17-21, 
GRAPP 2010 
 
Member of International Program Committee, ＇The 4th International 
Conference on Computer Graphics Theory and Applications, GRAPP is 
organized by INSTICC - Institute for Systems and Technologies of 
Information, Control and Communication＇, Lisbon, Portugal, February 
5-8, GRAPP 2009 
 
 
 
 
SCI Journal Reviewer:  
Journal of Intelligent and Robotic Systems 
Journal of Computational and Applied Mathematics 
Journal of Intelligent Manufacturing, Information Sciences,  
IEE Proc. Vision, Image &amp； Signal Processing, 
International Journal of Computer Mathematics, 
IEEE Transactions On Instrumentation &amp； Measurement 
Journal of Network and Computer Applications 
Computers &amp； Electrical Engineering 
IEEE Transactions on Visualization and Computer  
Graphics.Optical Engineering 
IET Image ProcessingComputers &amp； Electrical Engineering 
IEEE Transactions on Electronics Packaging Manufacturing 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
