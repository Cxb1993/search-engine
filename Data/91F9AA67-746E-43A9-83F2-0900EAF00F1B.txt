情境ME-OWA運算子整合模式在多準則決策的應用與探討
中文摘要 
資訊的融合與整合在許多領域都是
極為重要的研究主題，而在先前的研究
中，循序加權運算子已被證實可成功地
解決這一類的問題。然而，先前的運算
子往往會發生與決策情境彼此獨立的問
題，此外，在面對具可加性、可乘性以
及語義的尺度偏好時，以適合的運算子
予以處理是必要的。 
為了解決上述的問題，本計畫提出
一 個 完 整 的 MCDM (Multi-Criteria 
Decision Making)整合模式，其中包含情
境 的 ME-OWA (Maximal Entropy - 
Ordered Weighted Averaging), 
ME-OWGA (Maximal Entropy - Ordered 
Weighted Geometric Averaging), 
ME-LOWA (Maximal Entropy - 
Linguistic Ordered Weighted Averaging), 
及 ME-LOWGA (Maximal Entropy - 
Linguistic Ordered Weighted Geometric 
Averaging) operators 運算子。所提出的
模式將會具有根據決策者對準則偏好的
態度的情境下處理 MCDM 問題的能
力。此模式的能力與性質也會透過一連
串的實驗與比較予以確認，且基於所提
出的四個運算子，可解決以加法的、乘
法的和語意的偏好給分的群體 MCDM
問題。本計畫第一年先利用數值分析的
根解來求出 ME-OWA 的權重，所運用
的方法有「迭代解」、「定點法」及「牛
頓法」，並且比較這三個根求法與
ME-OWA 分析解的權重之正確性比
較。並提出情境 ME-OWA 結合 MCDM
的演算步驟。在實例驗證方面，使用最
佳戰爭坦克的實例並與其他方法做比
較，驗證我們所提出的方法，在排序結
果中自然能涵蓋住其他方法的結果。第
二年主要執行數學模式推導，其內容為
（1）透過情境上的結合，我們將根據資
訊一致化來把情境 ME-OWA 運算子及
WGA 做結合，最後可以得到情境
ME-OWGA 運算子；（2）引入語意變
數，分別與 ME-OWA 與 ME-OWGA 結
合嘗試推導出情境的 ME-LOWA 與
ME-LOWGA 運算子。第三年實例驗證
與管理意涵可以分為三個階段來進行，
（1）將前兩年的研究成果做整合並提出
可行整體研究架構；（2）多個 MCDM
實證；（3）模式適用性探討。驗證部份
以國內上市電子公司 629 間為驗證資料
庫。 
 
Abstract 
Information fusion and aggregation 
are important research topic in many 
application areas, and the OWA (Ordered 
Weighted Averaging) operators have been 
extensively adopted to handle this kind of 
problems.  However, previous operators 
are usually independent of their situations 
and cannot reflect change in situations, 
and the additive, multiplicative or 
linguistic preferences should be 
aggregated with feasible operators.   
To solve above problems, an 
integrated MCDM (Multi-Criteria 
1 
ME-LOWA, and ME-LOWGA 
operators. (2) Utilize some practical 
examples for MCDM to verify 
proposed model. (3) Discuss the 
fitting and using condition for the 
proposed model. 
壹、前言 
 資訊融合與整合在很多應用的領
域中，都是重要的主題，例如類神經網
路、模糊邏輯控制器、專家系統、群體
決策制定及多準則決策制定等等…。決
策制定在日常生活是很平常的工作。決
策制定能夠從方案中找出最佳的決擇。
多人決策問題（MPDM）被定義為以不
同來源的資訊為基礎，必須做決擇的決
策情況，  （Chiclana et al., 1998; Fodor 
& Roubens, 1994; Herrera et al., 
2001;Kacprzyk & Fedrizzi, 1990; Saaty, 
1980）. 一般而言，資訊可由三種偏好
的結構方式來表達（Chiclana et al., 1998; 
Herrera et al., 2001）: (1) 方案的偏好順
序，(2) 效用函數 (3)偏好關係。 
多準則決策（MCDM）方法的特點
是求出有限方案的評估整合值。解決
MCDM 問題的主要目的是測量所有方
案的偏好值。MCDM 方法的分數是依每
個準則所能帶來的貢獻而定。在某些情
況下，兩個準則的測量單位可能是不同
的，我們不能直接用加法來整合資訊。
常用的數值尺度，如以正規化為例，必
須允許在準則值中做加法及乘法的動
作。每個方案的總分可以藉由整合每個
可比較的準則評分來計算，依憑準則所
分配到的重要性權重，來做出最後的決
策（Yoon & Hwang, 1995）。 
 有 兩 個 原 因 可 說 明 如 何 取 得
MCDM 準則權重的重要性（Beliakov & 
Warren, 2001; Moshkovich et al. 1998）。
第一、有很多評估準則權重的方法，用
來整合有序的評估值（Choo & Wedley, 
1985; Darmon & Rouzies, 1991; Dyer & 
Sarin, 1979; Nutt, 1980; Pekelamn & Sen, 
1974; Smolikova & Wachowiak, 2002; 
Solymosi & Dombi, 1986; Zhang et al., 
1992）。第二，一些實驗證明了用不同
衍生權重的方法可能導致不同的結果。
為了整合專家觀點及權重在 MCDM 的
問題，過去的學者已提出許多的運算子
（Borcherding et al., 1991; Shoemaker & 
Carter, 1982; Weber et al., 1988）。現在的
一般整合運算子有 t-norm （Yager, 
1980）, t-conorm （Yager, 1980）,平均
3 
orness(W)  
= −− n )1/1( ∑ −n iWin )*)((
=i 1
  
(W) = 
 (2) 
其中 orness α  是所謂情境參
數。另一個計算的方法是 dispersion 其
定義如下： 
ln   (3) 
算方 下 ： 
權
(W) = 
Disp(W) = -∑
=
n
i
iw
1 i
W
Orness 的計 法具有以 特性
1. },,{ 21 nwwwW …= 是 OWA 中的
重向量，其中 orness α  
2. },, 不但是 OWA
的權重向量，而且也是 W 的逆矩
,{' 11 wwwW nn …−=
陣。因此，orness (W’) = 1-α  
O’Hagan[20] entropy 
ierman, 1999; 
結合了最大
(Jaynes, 1989; Klir & W
Shan
求函數的極大值 ln
       
non, 1948)及 Yager 的方法(Yager, 
1988)，來決定這種 OWA 運算子的權重
結果，不僅先給定了 or 的程度等級，也
有最大 entropy 的 OWA 權重，這個方法
是以下述問題的解答為基礎 
∑n -
=i i
w
1 i
W  
     
限制 
∑
=− i in 11 0 1−=
n
win )(α , 1 α≤ ≤  （4）               
,1=∑
i
  
iw ]1,0[∈∀wi   , i=1,….,n 
 Fuller and Majlender [10]將Yager的
A 式 用
Lagrange 的方法。根據這二位學者
所提出的方法，我們可從下列三個公式
求得關聯權重值的向量。 
OW 等式轉換成多項式的等 ，使
的是
公式如下： 
1 1lnln
1111
ln − −−=⇒−
1
−
−= j −+ n jnjnjnj wwwwww n
jn
n
  
(5)   
w
ww
n
n
)1((= α
nn
n
1
1
1)1(
1)
−+−
+−−
α                   
(6)  
 
( )[ ]nww nn 11 11 −+− α  
( )[ ] 11 −− nn α ( )( )[ ]11 1+−− wnn α
的 特 例 ，
=   (7)
這 當裡
⇒==== w ......
n 時，
nn21 disp（W） = ww
1
ln α = 0.5，其中 iW 是權重向
5 
讓 }{ isS = , i =1,2,…,t，成為一 ∏ == nj j j1 ωαα
數權
個有
限的
元素，都代表語意變數的可能數值，且
必須符合下述性質 （Herrera et al., 1996, 
）：
(1) 子集是有順序性的:  if 
時 , 
重向
且為 離散語意元素，每個 is
FSS  
全序的
,ji ss ≥
ji ≥ ; 
(2) 有反向運算子: neg （ ） = 
其中 j=t+1-i; 
(3) 最大運算子: max（ ） = , 
if 
: min（ ） = , if 
LWGA 及 LOWGA （Xu, 2004） 運算
子可被定義為: 
】
均（ ）運算子可表示為 LWGA: 
is js  
ji ss , is
ji ss ≥ ; 
(4) 最小運算子 ji ss , is
ji ss ≤  
【定義 6  一個 n 維的語意權重幾何平
LWGA
,SS n →
 
 
若
1 2
1 2
1 2
n
n
n
LWGA ( s ,s ,...,s )
s ) ( s ) ... ( s )
ω α α α
( ωω ωα α α⊗ ⊗ ⊗  =
αααα ωωω ssss nn =⊗⊗⊗= )(...)()( 2211 (10
)       
當 Tn )
是
j
sα 的指
,...,,( 21 ωωωω =  
量，且 ∈jω [0,1], 
∑ = =nj j1 1ω , Ss jα ∈ . 
T111 GA 
幾 （
 若 nnn ),...,,(=ω , 則 LW
就稱做語意 何平均 LGA） 運算子。 
7】 n 維的語意循序
均（LOWGA）可以表示為 LOWGA:
【定義 權重幾何平
 
,SS n →  也結合一個指數權重向量
w = nwww ),...,,( 21 , 其 ∈jw [0,1] 且 T
∑ =nj =jw1 1可得  
W s )
1 2
1 2
1 2
n
n
n
w
ww w
LO GA ( s ,s ,...,
( s ) ( s ) ... ( s )
β β β
β β β= ⊗ ⊗ ⊗  
ββββ ssss nwnww =⊗⊗⊗= )(...)()( 2211   
(11)        
當 ∏ == nj wj j1ββ 時, 且 是 的第 j
  
Xu （ 2004）  證明了有一些與
LOWGA 運算子結合的屬性：交換性, 
單調性 有界性。
【定義 】 順序
的運算子，可圖示
為
j
sβ  jsα
個最大語意區段
,  
8  一個 n 維最大 entropy
權重平均(ME-OWA)
: n RR → , φ 其中 是屬性 1 到
屬性
n21 aaa ,...,,
n ，可以與權重向量結合為
7 
出演算法如下
S
資料蒐集來源為台灣經
電子產
業公司的 2 0 0 4 年及
2005 年的各季財務資料
作為本論文之研究，並
C 三
[21]，將營業成長
率>=100%的資料歸納
為等級 A，營業成長率
>=0%且<100%
納為等級
率為負數者則歸納為 
等級
Step 2.：選取屬性
A、B、
C 三個等級，將所選取
的固定資產、營業收入
毛額、營業收入淨額、
營業成本、營業費用、
計、折舊合計、營業毛
利、營業利益及員工人
數等十二個屬性利用選
取屬性方法分別選出
2004 年及 2005 年與營
業 成 長 率 最 
相關的前四個重要屬性
作為計算權重值指標屬
 
Step 3：資訊整合值 
運用 OWA 運算子，將
2004 年及 2005 年分別
值的權重計算整
屬性的整合 
Step 4.：分類
首先進
離散化
練集資
料，之後以訓練集資料產生分
 
Step 5
所選出的四個相關
策樹 C4.5 進行實驗，
氏網路進行實驗，以
 
網路進行實
Step 
 
Step 
情境指標 α 值
 
4. 分析與
第一年所
法，並利
A 的權重，所運用的方法有「迭
代解」、「定點法」 ，並且比
選出的各屬性依據情境
指標 α
，其架構如圖： 
tep 1.：蒐集資料與前處理 
濟新報資料庫，以國內
629 家的上市櫃
合為單一
值。 
 
行單一屬性整合值的
並將資料分成 67%的訓
料與 33%的測試集資
將不完整之資料先予以
過濾。其次，依據營業
成長率分為 A、B、
個等級
者則規
B，營業成長
C。 
 
依據營業成長率
類法則。
.：實驗 
1.利用訓練集所產生的分類法
則進行測試集的實驗以取得正
確率。 
2.將步驟二
屬性以決
以取得正確率。 
3.將步驟二所選出的四個相關
屬性以貝
取 得 正 確 率 。
4.將步驟二所選出的四個相關
屬性以多層感知器
驗，以取得 正確率。 
6.：結果比較 
 比較 OWA 粗集分類器、決策營業外收入合計、營業
外支出合計、薪資合
性。
樹、貝氏網路及多層感知器
網路等四種方法實驗結果。 
7.：萃取規則 
 從結果中比較
再哪一區間的正確率最高。 
比較 
提出 ME-OWA 的權重演算
用數值分析的根解來求出
ME-OW
及「牛頓法」
9 
[圖 5. 不同 alpha 與語意下三種主要戰
爭坦克的績效] 
第二年完成數學推導，並以實例驗證正
確性: 
z 實例驗證 
    實例驗證主要可以分為兩個部份，
第一部分為航空公司服務品質，第二部
分資料集為 Hajeeh & Al-Othman [11]。 
Tsau 所發放
間旅行社，該問卷含 15
個準則。其回收共 211 份，回收率為
47%。該問卷問項包含兩大部分，其一
決策重要比較，另一為航空公司
在每一個準則下的績效， Tsau 選擇三
主要研究目標。以
Analytic Hierarchy Process (AHP)來得到
個構面 15 準則所得到的評分。 
er OWA 
aggregation] 
eeh & Al-Othman [11]所
的權重值，表 4 為
值，圖 8 為 7 個準則下的
調整權重值的分布圖。 
by situational ME-OWGA operators] 
[Figure 8. The distribution of adjusted 
weights for seven criteria] 
ha 值
之
技術為
of 
首先第一部分的資料集為
450 份問卷給 29
為評估
間航空公司為
準則權重，並且以 Technique for Order 
Preference by Similarity to Ideal Solution 
(TOPSIS) [20]方法來做排序。圖 6 為 5
[Figure 6. Weights of five aspects and 15 
criteria [31]] 
本計畫驗證所提出之方法採用上述
Tsaur 所 使 用 的 資 料 集 ， 並 經 由
step1~step6 可得到不同情境 α下的五個
構面權重值(表 2)。 
[Table2. The weights of aspects aft
 
第二部分為 Haj
使用的資料集。其中從 4 個淡化海鹽工
廠定義出較適合的淡化技術，從圖 7 中
可得知 7 個準則 4 個決策。表 3 為 4 個
淡化技術對七個準則
經由 ME-OWGA 運算子求得各不同情
境 α下的權重
 
[Figure 7. The hierarchal structure for 
selection of desalination plant [11]] 
[Table 3. The relative weights for four 
desalination technologies [11]] 
[Table4. The adjusted weights of criteria 
經由兩個實驗比較如表 5 與表 6，並且
經由比較得知最後在各種不同 alp
下，會產生不同的結果。其表 6 最佳
“reverse osmosis”。 
[Table 5. The aggregation results of 
Example I] 
[Figure 9. The aggregative results 
Example I under α = [0.5,1.0]] 
[Table 6. The aggregation results of 
11 
forecasting the revenues growth rate of
lectronic industry, ” Expert Systems with 
, pp. 610-617, 
hology 27（1）, 93-102. 
ing, T. Epple, and D. V. 
Winterfeldt, 1991, Comparison of 
udgments in multi-attribute 
t 
1695-1699. 
H. Cheng, 
y 
king 
ato
37. 
b, 
imilarity 
generalized fuzzy 
 
aking 
tics and Systems: 
ion 
software 
ms 
 
s by fuzzy AHP 
, 
, J.-R. Chang, T.-H. Ho, 
en, 2005, Evaluating 
er Science 3558, 77-88. 
 
ic criteria 
 
 the numbers, IEEE Transactions on Fuzzy 
Systems 11（1）, 45-56. 
[8] S. J. Chen and S. M. Chen, 2005, 
Aggregating fuzzy opinions in the
heterogeneous group decision-m
environment, Cyberne
e
Applications, vol. 37, No.1
2010.(SCI/EI)  
 
七、參考文獻 
[1] J. Azcel, and T. L. Saaty, 1983, 
Procedures for synthesizing ratio 
judgments, Journal of Mathematical 
Psyc
[2] [2] G. Beliakov, and J. Warren, 2001, 
Appropriate Choice of Aggregation 
Operators in Fuzzy Decision Support 
Systems, IEEE Transactions on Fuzzy 
Systems 9（6）, 773-784. 
[3] K. Borcherd
weighting j
utility measurement, Managemen
Science 37（12）, 1603-1619 
[4] M. Carbonell, M. Mas, and G. Mayor,
1997, On a class of Monotonic 
 
cen
Extended OWA Operators, 
Proceedings of the Sixth IEEE 
International Conference on Fuzzy 
Systems （IEEE-FUZZ’97）, 
Barcelona, Catalunya, Spain, 
[5]  J.-R. Chang, T.-H. Ho, C.-
and A.-P. Chen, 2005, Dynamic Fuzz
OWA Model for Group Multiple 
Criteria Decision Making, Soft 
Computing, In Press. 
S. J. Chen and S. M. Chen, 200[6] 3a, A 
new method for handling 
multi-criteria fuzzy decision ma
problems using FN-IOWA oper
Cybernetics and Systems: An 
International Journal 34（2）, 109-1
[7] S. J. Chen and S. M. Chen, 2003
Fuzzy risk analysis based on s
measures of 
rs, [
An International Journal 36（3）, 
309-338. 
[9] S. J. Chen, and C. L. Hwang, 1992, 
Fuzzy Multiple Attribute Decis
Making- Methods and Applications, 
Springer, New York. 
[10] S. M. Chen, 2001 Fuzzy group 
decision making for evaluating the 
rate of aggregative risk in 
development, Fuzzy Sets and Syste
118, 75-88. 
[11] Y. C. Chen, 2002, An application of 
fuzzy set theory to the external 
performance evaluation of distribution 
ters in logistics, Soft Computing 6, 
64-70. 
[12] C.-H. Cheng, 1996, Evaluating naval
tactical missile system
based on the grade value of 
membership function, European 
Journal of Operational Research 96
343-350. 
[13] C.-H. Cheng
and A.-P. Ch
Airline Service Quality by Fuzzy 
OWA Operators, in Modeling 
Decisions for Artificial Intelligence 
Conference 2005, Tsukuba Japan, V. 
Torra et al. （eds.）, Lecture Notes in 
Comput
14] C.-H. Cheng, Y. Lin, 2002, Evaluating
the best battle tank using fuzzy 
decision theory with linguist
evaluation, European Journal of 
Operational Research 142, 174-186. 
13 
consensus in group decision making 
under linguistic assessments, Fuzzy
Sets and Systems 78, 73-87. 
[30] F. Herrera, E. Herrera-Viedma, a
 [38]
nd J. 
onsens
te 
ing – 
esian 
cision 
Systems 18, 
e 
ng, 
90, 
 Models 
lish
991, 
d Applications, Van 
ren
. 
g fuzzy sets theory for 
 
ts 
 
t 
ology, vol. III, Wiley, New York, 
t 
me 
n 
ds 
L. Verdegay, 1997, Linguistic 
Measures Based on Fuzzy 
Coincidence for Reaching C
in Group Decision Making, 
International Journal of Approxima
Reasoning 16, 309-334. 
us ev
[31] C.-L. Hwang, and K. P. Yoon, 1981, 
Multiple Attribute Decision Mak
Methods and Applications, 
A-State-of-the-Art Survey, 
Spring-Verlag, New York. 
[32] E. T. Jaynes, 1989, Cleaning up 
mysteries: The original goal, 
Maximum Entropy and Bay
Methods, Kluwer, Dordrecht. 
[33] J. Kacprzyk, 1986, Group de
making with a fuzzy linguistic 
majority, Fuzzy Sets and 
105-118. 
[34] J. Kacprzyk, and M. Roubens, 1988, 
Non-Conventional preferenc
Relations in Decision Maki
Springer, Berlin. 
[35] L. Kacprzyk, and M. Fedrizzi, 19
Multiperson Decision-Making
Using Fuzzy Sets and Possibility 
Theory, Kluwer Academic Pub ers, 
pport Systems 22, 73-84. 
[45] P. C. Nutt, 1980, Comparing metho
for weighting decision criteria, 
OMEGA 8, 163-172. 
M. O’Hagan, 1988, Agg
Dordrecht. 
[36] Kaufmann, and M. M. Gupta, 1
Introduction to Fuzzy Arithmetic 
Theory an
Norstrand Reinhold, New York. 
[37] G. J. Klir, 1988, Fuzzy Sets, 
Uncertainly and information, P
Hall. 
tice 
ers, Pacific Grove, CA, 
681-689. 
[47] C. Parkan, and M. L. Wu, 1999, 
 G. J. Klir, and M. J. Wierman, 1999, 
Uncertainty-Based Information, 2nded 
Edition, Physica-Verlag, Germany
[39] H. M. Lee, 1996, Group decision 
making usin
aluating the rate of aggregative risk
in software development, Fuzzy Se
and Systems 80, 261-271. 
[40] R. D. Luce, and P. Suppes, 1965,
Preference, utility and subjec
probability, in R D. Luce et al. （eds.）, 
Handbook of Mathematical 
Psych
249-410. 
[41] J. M. Mendel, 2000, Uncertain 
Rule-Based Fuzzy Logic Systems: 
Introduction and New Directions, 
Prentice Hall PTR, Upper Saddle 
River, NJ. 
[42] R. Mesiar, and S. Saminger, 2004, 
Domination of ordered weighted 
averaging operators over t-norms, Sof
Computing 8, 562-570. 
[43] G. A. Miller, 1956, The magical 
number seven or minus two: so
limits on our capacity of processing 
information, Psychology Reviews 63, 
81-97. 
[44] H. M. Moshkovich, R. E. 
Schellenberger, and D. L. Olson, 1998, 
Data influences the result more tha
preferences: Some lessons from 
implementation of multiattribute 
techniques in a real decision task, 
Decision Su
[46] regating 
template or rule antecedents in 
real-time expert systems with fuzzy 
set logic, Proc. 22nd Annu. IEEE 
Asilomar Conf. On Signals, Systems, 
Comput
15 
17 
 
ted 
 
s 
t
, 
ning, Parts 1 and 
 
y Logic, IEEE 
 
[69] R. R. Yager, 1980, On a general class Comp
of fuzzy connectives, Fuzzy Sets and
Systems 4, 235-242.  
[70] R. R. Yager, 1988, Ordered weigh
averaging aggregation operators in 
multi-criteria decision making, IEEE
Trans. Systems Man. and Cybernetic
18（1）, 183-190. 
[71] R. R. Yager, 1991, Connectives and 
quantifiers in fuzzy sets, Fuzzy Se s 
Klu
and Systems 40, 39-75. 
[72] R. R. Yager, and J. Kacprzyk, 1997
The Ordered Weighted Averaging 
Operators, Kluwer Academic 
Publishers, Boston. 
[73] K. P. Yoon, and C.-L. Hwang, 1995, 
Multiple Attribute Decision Making: 
An Introduction, Sage Publications, 
Inc., California. 
[74] L. A. Zadeh, 1965, Fuzzy Sets, 
Information and Control 8, 338-353. 
[75]  L. A. Zadeh, 1975, The concept of a 
linguistic variable and its application 
to approximate reaso
2,” Information Sciences 8, 199-249 &
301-357. 
[76] L. A. Zadeh, 1988, Fuzz
uter 21, 83-93. 
[77] D. Zhang, P. L. Yu, and P. Z. Wang, 
1992, State-dependent weights in 
multicriteria value functions, Journal 
of Optimization Theory and 
Applications 74（1）, 1-21. 
[78] H. J. Zimmermann, 1991, Fuzzy Set 
Theory and its Applications, 2nd eds., 
wer Academic Publisher, London.
[79] H. J. Zimmermann, and P. Zysno, 
1980, Latent connectives in human 
decision making, Fuzzy Sets and 
Systems 4, 37-51. 
 
 
 
 
 
 
 
 
 
 
 圖 2. 整體模式的初步研究架構 
 
19 
 
圖 5. 不同 alpha 與語意下三種主要戰爭 
 
 
Figure 6. Weights of five aspects and 15 criteria [31] 
 
21 
 Figure 9. The aggregative results of Example I under α = [0.5,1.0] 
 
 
Figure 10. The aggregative results of Example II under α = [0.5,1.0] 
 
Table2. The weights of aspects after OWA aggregation 
 α =0.5 α =0.6 α =0.7 α =0.8 α =0.9 α =1.0 
Tangibility ( ) '
1W 0.20000 0.28839 0.39617 0.53067 0.71044 1 
Reliability ( ' ) 
2W 0.20000 0.23528 0.25740 0.25651 0.20720 0 
Responsiveness ( ' ) 
3W 0.20000 0.19196 0.16724 0.12399 0.06043 0 
Assurance  ( ' ) 
4W 0.20000 0.15660 0.10859 0.05986 0.01679 0 
Empathy ( ) '
5W 0.20000 0.12777 0.07060 0.02897 0.00514 0 
 
 
23 
25 
Table 6. The aggregation results of Example II 
The proposed ME-OWGA model 
 α =0.5 α =0.6 α =0.7 α =0.8 α =0.9 α =1.0
AHP 
(H & A, 2005) 
MSF 0.18944 0 0.1636 0.16044 0.13351 0.11042 0.09356 0.0913
MED 0.17114 0.1 89 0.38600 0
VC 0.1 0.1 0.1 0.0 0.0 0.0
g 
9342 0.22262 0.26262 0.320 .2917 
1600 1096 0563 9982 9371 9130 0.1100 
RO 0.30464 0.31789 0.34230 0.37887 0.42425 0.43140 0.4346 
Rankin 4>1>2>3 4>2>1>3 4>2>1>3 4>2>1>3 4>2>3>1 4>2>3=1 4>2>1>3 
*H , 2005: Hajeeh & a 1
 
選取 4 個屬性
10 個條件屬性 
選取 4 個屬性 
 & A Al-Othm n, 2005 [1 ] 
 
Table 7.本研究與其他方法的比較結果 
12 個條件屬性
 
平均正確率 平均正確率 
  20  20  04 年 2005 年 04 年 2005 年
本研究方法 96.82% 95.01% 95.59% 92.83% 
純粗集理論 74.89% 68.64% 79 % .5% 60.62
決策樹 C4.5 74.47% 65.91% 73.71% 55.77% 
貝氏網路 71.01% 63.92% 72.2% 55.98% 
多層感知器 73.28% 52.17% 73.29% 52.03% 
 
on the rank of these weighting vectors after processing
aggregation.
An OWA of dimension n is a mapping f : Rn? R, that has an
associated weighting vector W = [w1,w2, . . . ,wn]T with the follow-
ing properties:
wi 2 ½0;1 for i 2 I ¼ f1;2; . . . ; ng and
X
i2I
wi ¼ 1
such that
f ða1; a2; . . . ; anÞ ¼
X
i2I
wibi; ð1Þ
where bi is the ith largest element in the collection of the aggre-
gated objects {a1, . . . ,an}. Thus, it satisﬁes the relation Mini[ai] 6
f(a1,a2, . . . ,an) 6Maxi[ai] (Ahn, 2006).
Yager (1988) introduced two important characterizing mea-
sures in respect to the weighting vector W of an OWA. One of these
two measures is orness of the aggregation (Chang & Cheng, 2006),
which is deﬁned as
ornessðWÞ ¼ ð1=n 1Þ
Xn
i¼1
ððn iÞ wiÞ; ð2Þ
where the orness(W) = a is a situation parameter.
The second one is a measure of dispersion of the aggregation,
which is deﬁned as
DispðWÞ ¼ 
Xn
i¼1
wi lnwi: ð3Þ
The orness measure has the following property:
W = {w1,w2, . . . ,wn} is the weight vector of an OWA with or-
ness(W) = a. Then, W0 = {wn,wn1, . . . ,w1} is the reverse order of
W, orness(W0) = 1  a (Liu, 2004).
O’Hagan et al. (1988) combines the principle of maximum en-
tropy and OWA to propose a particular OWA which has maximum
entropy with a given level of orness. The deﬁnition is presented as
follows:
Maximize the function 
Xn
i¼1
wi lnwi;
a ¼ 1
n 1
Xn
i¼1
ðn iÞwi; 0 6 a 6 1: ð4Þ
2.1.2. Fuller and Majlender’s OWA
Fuller and Majlender (2001) transform Yager’s OWA equation
to a polynomial equation by using Lagrange multipliers. According
to their approach, the associated weighting vector can be obtained
by (5)–(7)
lnwj ¼ j 1n 1 lnwn þ
n j
n 1 lnw1 ) wj ¼
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
wnj1 w
j1
n
n1
q
; ð5Þ
and w1½ðn 1Þaþ 1 nw1n
¼ ½ðn 1Þan1½ððn 1Þa nÞw1 þ 1; ð6Þ
if w1 ¼ w2 ¼    ¼ wn ¼ 1n ) dispðWÞ ¼ ln n ða ¼ 0:5Þ;
then wn ¼ ððn 1Þa nÞw1 þ 1ðn 1Þaþ 1 nw1 ; ð7Þ
where wi is weight vector, n is the number of attribute, and a is the
situation parameter.
2.2. Feature selection
Jain and Chandrasekaran (1982) point that feature selection is
deﬁned as follows: (1) give a set of candidate features; (2) select a
subset that performs the best under some classiﬁcation system.
This process has been very effective in reducing dimensionality,
removing irrelevant data, increasing learning accuracy, and
improving result comprehensibility (Liu et al., 2004).
Feature selection algorithms fall into two broad categories, the
ﬁlter model or the wrapper model (Das, 2001; Kohavi & John,
1997). The ﬁlter model relies on the general characteristics of the
training data to select some features independently of any learning
algorithm. Therefore, it does not inherit any bias of a learning algo-
rithm. The wrapper model requires one predetermined learning
algorithm and uses the performance of the learning algorithm to
evaluate and determine which features are selected.
2.3. Multiple linear regression
Multiple linear regression (Draper & Smith, 1998) is an exten-
sion of the simple linear regression methodology to multiple inde-
pendent variables. That is, rather than using just one independent
variable to explain the variation in y, multiple linear regression
permits the simultaneous use of several independent variables.
Additionally, multiple regression analysis studies the relation-
ships among three or more variables. Multiple regression model
is expressed as follows (Daniel & Terrell, 1995):
yi ¼ b0 þ b1x1j þ b2x2j þ    þ bkxkj þ ej; ð8Þ
where yi denotes a typical value of the dependent variable Y, from
the population of interest; b0,b1, . . . ,bk are the population partial
regression coefﬁcients; and x1j,x2j, . . . ,xkj are observed values of
the independent variables X1,X2, . . . ,Xk, respectively. Moreover, ej
is assumed to have a random and normal distribution N(0,r2),
j = 1,2, . . . ,n.
2.3.1. Stepwise regression
Stepwise regression is a popular and extremely effectivemethod
for establishing regression models. The most widespread stepwise
regression process works as follows. The user ﬁrst identiﬁes the re-
sponse, y, and the set of potentially important independent vari-
ables, x1,x2, . . . ,xk, where k is generally large. The response and
independent variables are then entered into the regression process
(the stepwise process begins) (McClave, Benson, & Sincich, 2005).
The algorithm of stepwise regression constructs the model via a
series of iterations. Each iteration involves one of two processes,
namely either adding a variable to the model (referred to here as
the selection process) or removing a variable from the model
(elimination). The process of stepwise regression involves of these
steps as follows:
1. Consider all possible regressions using one explanatory vari-
able. Select that variable with the largest t-ratio. If the t-ratio
is not signiﬁcance, then do not select any variables and halt
the process.
2. The next variable to enter is the one that makes the most signif-
icant contribution. To enter, the t-ratio must exceed a speciﬁed
t-value.
3. Next, delete the variable that makes the smallest contribution.
The deleted t-ratio must be below a speciﬁed t-value.
4. Repeat steps 2 and 3 until all possible additions and deletions
have been performed.
When only one variable is being considered recall that (t-ra-
tio)2 = F-ratio.
2.3.2. Beta coefﬁcient
The standardized the coefﬁcients are known as beta coefﬁcients,
and involve the following steps of the beta coefﬁcients are (Draper
& Smith, 1998):
C.-H. Cheng et al. / Expert Systems with Applications 36 (2009) 4988–4995 4989
Step 6: predict the clusters of testing data
From step 5, we can obtain the parameter a based on highest
accuracy rate. According to the obtained a, compute the single
integrate value of testing data by step 4. Calculate the distance
between cluster centers and the aggregated values of testing
data by Eq. (10),
E Distij ¼
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
ðCr center  ajÞ2
q
: ð10Þ
where Cr_center is the ith cluster center. The minimum E_Distij deter-
mined the aggregated value belonging to Cr.
Step 7: evaluation
This paper uses 50% data as training data and the other 50% data
as testing data in three different dataset. Additionally, each
experiment is used 10 times random sampling. For veriﬁcation,
we use three datasets to support the proposed method, and
compare with the listing methods.
4. Experiments and comparisons
In this section, the paper uses three datasets: (1) Iris, (2) Wis-
consin-breast-cancer and (3) Key Performance Indicators datasets
of a real supply chain case to support the proposed method, and
compare with the listing methods.
4.1. Iris dataset
Iris dataset is a well-known dataset. The dataset totally has 150
instances and three class variables:(1) setosa, (2) versicolor, and
(3) virginica. Every instance has four attributes: (1) Sepal_length
(SL), (2) Sepal_width (SW), (3) Petal_length (PL), and (4) Petal_-
width (PW). Then, the process of the experiment is represented
as follows:
Step 1: partition dataset into training data and testing data
This paper partitions 50% dataset as training data and the other
50% dataset as testing data. Additionally, each experiment is
used 10 times random sampling. The Iris dataset is shown in
Table 2.
Step 2: feature selection
In this step, the proposed method orders the attribute by the
beta coefﬁcients. The attribute, Sepal_width, is removed after
stepwise regression. The beta coefﬁcients are shown in Table
3. Then, we can obtain the ordering of important attributes by
beta coefﬁcients. It is presented as follows: Petal_length >
Petal_width > Sepal_length.
Step 3: calculate the OWA weights
In this step, OWA weights are generated by the algorithm of
OWA (as Fig. 2). The OWA weights (number of attribute = 3
and a = .5–1.0) are listed in Table 1.
Step 4: calculate aggregated value by OWA weights
Calculate aggregated values are repeated by a = 0.5, 0.6, 0.7, 0.8,
0.9 and 1.0. For example, n = 3 and a = 0.9, the aggregated value
can be calculated. The result is shown in Table 4.
Step 5: cluster the aggregated values
Using the K-means builds the clusters of training data by aggre-
gated values. For example, the result of a = 0.9 is shown in Table
5. The computation is repeated by a = 0.5, 0.6, 0.7, 0.8, 0.9 and
1.0. Then, we can obtain the highest accuracy rate by a = 0.8
and 0.9 (as Table 6). The cluster centers of the result (a = 0.9)
is shown in Table 7.
Step 6: predict the clusters of testing data
From step 5, we can predict the clusters of testing data based on
cluster centers (a = 0.8 and 0.9) by Eq. (10). The predict clusters
of testing data by a = 0.9 is shown in Table 8. The testing results
are shown in Table 9. After 10 times random sampling, the aver-
age accuracy of the classiﬁcation is 97.60% (94.67–98.67%)
when a = 0.9. But the average accuracy of the classiﬁcation is
97.20% (92.0–98.67%) when a = 0.8. Therefore, the result is bet-
ter when a = 0.9.
Step 7: evaluation
In this dataset, the experimental result is compared with listing
method (Chatterjee & Rakshit, 2004; Hong & Chen, 1999; Hong
& Lee, 1996; Ishibuchi & Nakashima, 2001; Lin, Yeh, Liang,
Chung, & Kumar, 2006; Setiono, 1997; Tsai & Chen, 2002); it
Fig. 2. The algorithm of OWA.
Table 1
OWA weights when n = 3
a = 0.5 a = 0.6 a = 0.7 a = 0.8 a = 0.9 a = 1.0
W1 0.3333 0.4384 0.5540 0.6819 0.8263 1
W2 0.3333 0.3232 0.2920 0.2358 0.1470 0
W3 0.3333 0.2384 0.1540 0.0819 0.0263 0
C.-H. Cheng et al. / Expert Systems with Applications 36 (2009) 4988–4995 4991
The proposed method not only raises the performance but also
reduces the complexity and dimensionality.
Table 5
The clusters of training data (n = 3 and a = 0.9)
Data_NO CLASS Cluster Data_NO CLASS Cluster Data_NO CLASS Cluster
1 1 3 26 2 1 51 3 2
2 1 3 27 2 1 52 3 1
3 1 3 28 2 1 53 3 2
4 1 3 29 2 1 54 3 2
5 1 3 30 2 1 55 3 2
6 1 3 31 2 1 56 3 2
7 1 3 32 2 1 57 3 1
8 1 3 33 2 3 58 3 2
9 1 3 34 2 1 59 3 2
10 1 3 35 2 1 60 3 2
11 1 3 36 2 3 61 3 2
12 1 3 37 2 1 62 3 1
13 1 3 38 2 1 63 3 2
14 1 3 39 2 1 64 3 1
15 1 3 40 2 1 65 3 1
16 1 3 41 2 1 66 3 2
17 1 3 42 2 1 67 3 2
18 1 3 43 2 1 68 3 2
19 1 3 44 2 1 69 3 2
20 1 3 45 2 1 70 3 1
21 1 3 46 2 1 71 3 2
22 1 3 47 2 1 72 3 1
23 1 3 48 2 1 73 3 2
24 1 3 49 2 1 74 3 1
25 1 3 50 2 1 75 3 2
Table 6
Training data result
Correct clustering Incorrect clustering Accuracy rate (%)
a = 0.5 64 11 85.33
a = 0.6 66 9 88
a = 0.7 65 10 86.67
a = 0.8 67 8 89.33
a = 0.9 67 8 89.33
a = 1.0 65 10 86.67
Table 7
Cluster center (a = 0.9, n = 3)
Center_1 Center_2 Center_3
5.0493 1.4052 4.0525
Table 8
The clusters of testing data (n = 3 and a = 0.9)
Data_NO Distance with
center_1
Distance
with
center_2
Distance
with
center_3
Original
cluster
Predictive
cluster
1 3.747349 0.103249 2.750549 2 2
2 4.012565 0.368465 3.015765 2 2
3 3.87578 0.23168 2.87898 2 2
4 3.536912 0.107188 2.540112 2 2
5 3.643675 0.000425 2.646875 2 2
6 3.726304 0.082204 2.729504 2 2
7 3.751524 0.107424 2.754724 2 2
8 3.666264 0.022164 2.669464 2 2
9 3.718413 0.074313 2.721613 2 2
10 3.728935 0.084835 2.732135 2 2
..
. ..
. ..
. ..
. ..
. ..
.
66 0.106929 3.751029 1.103729 1 1
67 0.315655 3.328445 0.681145 1 1
68 0.547926 4.192026 1.544726 1 1
69 0.34275 3.98685 1.33955 1 1
70 0.204255 3.848355 1.201055 1 1
71 0.238286 3.405814 0.758514 1 1
72 0.163549 3.480551 0.833251 1 1
73 0.287639 3.356461 0.709161 1 1
74 0.08618 3.55792 0.91062 1 1
75 0.415447 3.228653 0.581353 1 1
Table 9
Testing data result (n = 3 and a = 0.9)
Correct clustering Incorrect clustering Accuracy rate (%)
a = 0.8 74 1 98.67
a = 0.9 74 1 98.67
Table 10
Iris dataset, a comparison of the classiﬁcation accuracy rate
Methods Classiﬁcation accuracy rate (%)
The proposed method (a = 0.9) 97.60 (96–98.667)
Chatterjee and Rakshit (2004) 96
Hong and Chen’s (1999) method 95.57
Hong and Lee’s (1996) method 95.57
Ishibuchi and Nakashima (2001) 95.57
Lin et al. (2006) 94.7
Tsai and Chen (2002) 95.83
C4.5 (Setiono, 1997) 93.47
N.B. (Setiono, 1997) 94.53
N.N. (Setiono, 1997) 95.87
Note. Training dataset: 75 instances and testing dataset: 75 instances.
Table 11
Wisconsin-breat-cancer dataset
ID 63375 128059 . . . 160296
Clump thickness 9 1    5
Uniformity of cell size 1 1    8
Uniformity of cell size 2 1    8
Marginal adhesion 6 1    10
Single epithelial cell size 4 2    5
Bare nuclei 10 5    10
Bland chromatin 7 5    8
Normal nucleoli 7 1    10
Mitoses 2 1    3
Class 2 1    2
Note. The class values: 1 is benign, 2 is malign.
C.-H. Cheng et al. / Expert Systems with Applications 36 (2009) 4988–4995 4993
Wang, J. W., Cheng, C. H. (2006). Fuzzy Clustering-based on aggregate attribute
method (pp. 478–487). IEA/AIE, France, Lecture Notes in Computer Science (Vol.
4031).
Yager, R. R. (1988). On ordered weighted averaging aggregation operators in multi-
criteria decision making. IEEE Transactions on SMC, 18, 183–190.
Yager, R. R. (2004). Modeling prioritized multicriteria decision making. IEEE
Transactions on System, Man, and Cybernetics – Part B: Cybernetics, 23(6),
2396–2403.
C.-H. Cheng et al. / Expert Systems with Applications 36 (2009) 4988–4995 4995
In this model, a well-designed questionnaire was used to express
the experts’ opinions on the development of software projects with
respect to each criterion. The amount of evaluation results was
reduced by means of PCA with the aim at cutting down the number
of criteria but the accumulated variance of the original ones was pre-
served. OWA was used to flexibly obtain the weights of resultant
criteria under the consideration of information requirement. In
empirical validation, three software projects belonging to one
famous hospital in Taiwan were selected as the targets to examine
the appropriateness of this model. A comparison was taken to reveal
the superiority of this model. As expected, the model was more effec-
tive with the increased complexity the evaluation of software project
development.
INTRODUCTION
The main goal of software project management is to proceed with the
prevention and adjustment in advance with regard to the uncertain fac-
tors that might affect the schedule and quality in the duration of project
development (Krishnan et al. 2000). Expectedly, the occurrence of
damages on the credit and profit of software industry will be avoided
(Li et al. 2002; Jiang et al. 2004). From the viewpoint of management,
the function of evaluating software development process cannot only
assist the deciders with the prediction of feasibility and the impact of
benefits in advance, but also offer excellent help to the improvement pro-
cess of software project and the development of strategy of management.
In fact, software project management is a complicated issue. Its perform-
ance evaluation will also be a complicated multicriteria decision making
topic. However, two difficulties are inevitably encountered. One is the
high number of criteria needed for properly evaluating the performance
of software project and the other lies in deciding the weight distribution
of criteria.
This research treated the performance evaluation of software pro-
jects with an aim to develop an appropriate software project evaluation
model, i.e., PCA and OWA integrated evaluation model. In this model,
a suitable criterion structure and an integrated evaluation algorithm were
established to obtain the proper evaluation results for best decision-
making. First, this model adopts the PCA operator with the expectation
at using a few criteria to explain the original complex condition. As a result,
the degree of complexity of project evaluation would be considerably
290 D.-Y. YEH ET AL.
Since Yager (1988) has proposed OWA, various related algorithms
for determining the criterion weights for many research fields were
published in the literatures (Yager 1993). The most important character-
istic of this operator lies in deciding the associated weights of criteria by
analytical procedures and, simultaneously, possesses the reasonable and
flexible advantages at weight decision by means of the situation param-
eter, orness a. The basic definitions and operations are briefly described
as follows (O’Hagan 1988; Fuller and Majlender 2001; Cheng 2005):
The mapping function of OWA operator of dimension n: f : Rn ! R,
and
f ða1; a2; . . . ; anÞ ¼
Xn
i¼1
Wibi; ð1Þ
in which Wi belongs to the vector of associated weights:
W ¼ ½W1;W2; . . . ;WnT with
Pn
i¼1 Wi ¼ 1 and Wi 2 ½0; 1. bi is the ith
largest element of aggregated object set fa1; a2; . . . ; ang. In addition,
two measures were introduced to characterize the aggregation. The first
one, the measure of orness of the aggregation, is defined as
Orness ðW Þ ¼ 1
n 1
Xn
i¼1
ðn iÞWi ð2Þ
and it characterizes the degree to which the aggregation is like an or oper-
ation. The second one, the measure of dispersion of the aggregation, is
Figure 1. Criterion structure and the associated criteria for evaluating software project.
292 D.-Y. YEH ET AL.
implementation, if the p variables have the same scale of measurement,
one can directly use the correlation matrix to obtain principle compo-
nents. On the contrary, the standardization of data should be taken in
advance if the scales of measurement are not the same.
In PCA, the first principle component is obtained from the con-
dition its variance is equal to the maximal eigenvalue of the covariance
matrix and, as a result, contains the most amount of variance of the
original variables. The first principle component can be represented as
follows:
Y1 ¼ a11x1 þ a12x2 þ    þ a1pxp; ð8Þ
in which the coefficients of Y1 are the corresponding elements of eigen-
vector having maximal eigenvalue. Next, the second principle component
can be obtained by the same procedure with the additional condition of
zero correlative relationship between Y1 and Y2. Similarly, the remainder
can be obtained following the same procedure. Based upon the above,
the new synthetic variables Y1;Y2; . . . ;Yn are called the first, sec-
ond . . . nth principle components of the original variables and their
contained variances are gradually diminished, respectively.
The allocation of evaluation data in two-dimensional space could be
used to demonstrate the geometric meaning of PCA. Assume that k eva-
luators are requested to evaluate the target with respect to the two
criteria X(1) and X(2). Figure 2 shows the allocation of evaluation
results, in which each black dot represents an evaluation data coming
from one of k evaluators. Obviously, the profile of allocation in X(1)
and X(2) coordinates is approximately an oblique ellipse.
Figure 2. Allocation of k sets of evaluation data in X(1) and X(2) coordinates.
294 D.-Y. YEH ET AL.
number of variables, attempting to retain the content of the original
variable data and let new variables remain independent of each other.
PCA AND OWA INTEGRATED EVALUATION MODEL
The ‘‘PCA and OWA integrated evaluation model’’ was proposed to pro-
vide an appropriate model for evaluating the performance of software
projects. The characterizing integration of PCA and OWA lies in the
capture of respective advantages. Two phases involve in the evaluation
model, i.e., PCA mode and OWA mode and performance aggregation.
All the nine computation steps needed to implement this model are
shown as follows:
Phase 1: PCA Mode
After obtaining the k evaluation data of m software projects with respect
to each criterion, the steps of PCA mode include:
Step 1: Collecting the evaluation data in matrix form
Step 2: Obtaining the correlation matrix of criteria
Step 3: Obtaining the eigenvalues and eigenvectors of the correlation
matrix
Step 4: Deciding the number (n) of principle components based upon
the rule of totally accumulated variance  90%
Step 5: Transforming linearly the original evaluation data onto the
selected eigenvectors
Step 6: Obtaining the PCA scores of software projects (m n) based
upon the above linear transformation.
Phase 2: OWA Mode and Performance Aggregation
Step 7: Obtaining the weights of n principle components from Equa-
tions (5)–(7) according to the situation parameter a
Step 8: Aggregating the PCA scores and the OWA weights to obtain the
aggregated performances of software projects. The aggregation
algorithm is given as follows:
½Pij mn  ½Wj n1 ¼ Am1 ð11Þ
in which Pij represents the PCA score of ith software project
with respect to jth principle component. Wj is the weight of
296 D.-Y. YEH ET AL.
T
a
b
le
1
.
In
tr
o
d
u
c
ti
o
n
o
f
th
re
e
so
ft
w
a
re
p
ro
je
c
ts
u
n
d
er
ev
a
lu
a
ti
o
n
C
o
d
e
o
f
so
ft
w
a
re
p
ro
je
c
t
S
u
m
m
a
ry
o
f
sy
st
em
P
ro
je
c
t
(I
)
P
ro
je
c
t
n
a
m
e
M
ed
ic
a
l
m
a
n
a
g
em
en
t
in
fo
rm
a
ti
o
n
sy
st
em
o
f
T
a
li
n
T
zu
-C
h
i
H
o
sp
it
a
l:
W
eb
sy
st
em
o
f
th
e
o
b
st
et
-
ri
c
s
a
n
d
g
y
n
ec
o
lo
g
y
d
ep
a
rt
m
en
t.
In
se
le
ct
in
g
d
ev
el
o
p
m
en
ta
l
in
st
ru
m
en
ts
,
th
e
m
ic
ro
so
ft
vi
su
al
st
u
d
io
N
E
T
w
as
ch
o
se
n
fo
r
co
n
ve
n
ie
n
tl
y
em
p
lo
yi
n
g
W
E
B
to
sa
ve
a
sh
ar
in
g
d
at
a-
b
as
e,
in
w
h
ic
h
th
e
ca
se
h
is
to
ry
o
f
th
e
p
at
ie
n
ts
an
d
th
e
d
o
ct
o
rs
’
in
fo
rm
at
io
n
w
o
u
ld
b
e
sa
fe
ly
k
ep
t
an
d
u
se
d
.
T
h
e
d
at
a
u
ti
li
ty
an
d
sh
ar
in
g
m
ec
h
an
is
m
w
er
e
th
u
s
es
ta
b
li
sh
ed
.
T
h
e
m
an
ag
er
s
co
u
ld
en
jo
y
th
e
ad
va
n
ta
ge
o
f
d
at
a
ce
n
tr
al
iz
ed
m
an
ag
em
en
t
u
n
d
er
th
e
st
ru
ct
u
re
o
f
c
li
-
en
t=
se
rv
er
an
d
,
in
ad
d
it
io
n
,
th
e
cl
ie
n
t
si
d
e
co
u
ld
o
p
er
at
e
ev
er
yw
h
er
e
u
p
o
n
th
e
au
th
o
ri
ty
b
y
th
e
va
li
d
at
io
n
o
f
co
d
es
th
ro
u
gh
se
rv
er
w
h
ic
h
re
d
u
ce
th
e
co
st
fo
r
m
ai
n
ta
in
in
g
th
e
c
li
en
ts
’
so
ft
w
ar
e
an
d
u
p
g
ra
d
e
th
e
co
n
ve
n
ie
n
ce
o
f
n
ew
el
in
fo
rm
at
io
n
fo
r
th
e
co
m
p
le
te
sh
ar
in
g
o
f
d
at
a.
P
ro
je
c
t
(I
I)
P
ro
je
c
t
n
a
m
e
X
M
L
w
eb
se
rv
ic
e
p
ra
c
ti
c
es
:
a
n
ex
a
m
p
le
o
f
th
e
re
se
rv
a
ti
o
n
o
p
er
a
ti
o
n
sy
st
em
o
f
T
a
li
n
T
zu
-C
h
i
H
o
sp
it
a
l.
T
h
is
sy
st
em
a
ss
is
ts
th
e
re
la
te
d
d
o
c
to
rs
,
m
ed
ic
a
l
a
n
d
a
d
m
in
is
tr
a
ti
ve
p
er
so
n
n
el
to
p
ro
c
es
s
a
n
d
m
a
n
a
g
e
th
e
re
se
rv
a
ti
o
n
m
a
tt
er
s
to
sa
ti
sf
y
th
e
m
ed
ic
a
l
re
q
u
ir
em
en
t
in
th
e
h
o
sp
it
a
l
a
n
d
to
c
o
m
p
ly
w
it
h
th
e
re
la
te
d
re
g
u
la
ti
o
n
s
o
f
B
u
re
a
u
o
f
N
a
ti
o
n
a
l
H
ea
lt
h
In
su
ra
n
c
e
a
n
d
D
ep
a
rt
-
m
en
t
o
f
H
ea
lt
h
.
T
h
e
sy
st
em
w
a
s
b
a
se
d
u
p
o
n
In
te
rn
et
W
eb
a
n
d
X
M
L
w
eb
se
rv
ic
e
te
ch
n
iq
u
es
.
A
s
a
re
su
lt
,
it
fu
lf
il
ls
th
e
go
a
l
to
c
o
n
n
ec
t
to
th
e
in
te
rn
et
a
n
y
w
h
er
e,
a
n
y
ti
m
e
a
n
d
a
n
y
in
st
a
ll
a
ti
o
n
s
fo
r
c
o
n
ve
n
ie
n
t
o
b
ta
in
m
en
t
o
f
th
e
re
q
u
ir
ed
in
fo
rm
a
ti
o
n
a
n
d
se
rv
ic
e.
E
x
p
ec
te
d
ly
,
th
e
o
p
er
a
ti
o
n
a
l
c
o
st
is
re
d
u
c
ed
a
n
d
th
e
w
h
o
le
ef
fi
c
ie
n
cy
is
th
en
u
p
g
ra
d
ed
.
In
a
d
d
it
io
n
,
th
e
in
fo
rm
a
ti
o
n
p
er
so
n
n
el
c
o
u
ld
c
en
tr
a
li
ze
th
e
m
a
n
a
g
em
en
t
o
f
d
a
ta
b
a
se
a
n
d
,
c
o
n
se
q
u
en
tl
y,
c
o
u
ld
fu
lf
il
l
th
e
c
o
n
si
st
en
cy
a
n
d
im
m
ed
ia
te
a
sp
ec
t
o
f
d
a
ta
.
T
h
er
ef
o
re
,
th
e
m
a
in
te
n
a
n
c
e
o
f
th
e
sy
st
em
w
o
u
ld
b
e
ea
si
er
a
n
d
fa
st
er
.
P
ro
je
c
t
(I
II
)
P
ro
je
c
t
n
a
m
e
W
eb
o
p
er
a
ti
o
n
o
f
m
ed
ic
a
l
m
a
n
a
g
em
en
t
in
fo
rm
a
ti
o
n
sy
st
em
o
f
T
a
li
n
T
zu
-C
h
i
H
o
sp
it
a
l:
E
n
d
o
-
sc
o
p
e
a
n
d
C
li
n
ic
a
l
In
fo
rm
a
ti
o
n
S
y
st
em
.
T
h
e
m
ed
ic
a
l
m
a
n
a
g
em
en
t
in
fo
rm
a
ti
o
n
sy
st
em
w
a
s
es
ta
b
li
sh
ed
in
W
eb
ve
rs
io
n
to
a
ch
ie
ve
th
e
in
te
ra
c
ti
o
n
o
f
d
a
ta
a
n
d
fi
g
u
re
s.
T
h
e
fi
rs
t
su
b
sy
st
em
,
‘‘
fr
ie
n
d
ly
p
ro
je
c
t,
’’
fu
n
c
ti
o
n
s
a
s
th
e
m
ed
ic
a
l
a
n
d
el
ec
tr
o
n
ic
p
la
tf
o
rm
b
et
w
ee
n
T
a
li
n
T
zu
-C
h
i
H
o
sp
it
a
l
a
n
d
g
ra
ss
ro
o
ts
h
o
s-
p
it
a
ls
.
It
p
ro
v
id
es
th
e
d
ir
ec
ti
o
n
o
f
a
p
p
li
c
a
ti
o
n
a
n
d
d
ev
el
o
p
m
en
t
o
f
en
te
rp
ri
se
n
et
w
o
rk
th
ro
u
g
h
w
eb
c
o
m
p
u
ti
n
g
.
T
h
e
se
c
o
n
d
a
n
d
th
ir
d
su
b
sy
st
em
s
a
re
‘‘
E
n
d
o
sc
o
p
e’
’
a
n
d
‘‘
C
li
n
ic
a
l
In
fo
rm
a
ti
o
n
S
y
st
em
’’
.
T
h
ro
u
g
h
th
e
in
te
rn
et
,
th
e
m
ed
ic
a
l
p
er
so
n
n
el
a
re
a
ll
o
w
ed
to
m
o
re
ef
fi
c
ie
n
tl
y
m
a
n
a
g
e
th
e
d
ia
g
n
o
si
s
fu
n
c
ti
o
n
a
n
d
c
o
n
tr
o
l
th
e
p
a
ti
en
ts
’d
ia
g
n
o
si
s
d
a
ta
.
T
h
e
d
ev
el
o
p
m
en
t
in
st
ru
m
en
t
m
a
in
ly
re
fe
rs
to
m
ic
ro
-
so
ft
v
is
u
a
l
st
u
d
io
N
E
T
.
B
y
m
ea
n
s
o
f
w
eb
o
p
er
a
ti
o
n
,
th
e
b
u
si
n
es
s
w
a
s
n
o
t
li
m
it
ed
to
th
e
in
te
rn
a
l
h
o
sp
it
a
l.
A
s
lo
n
g
a
s
th
e
u
se
rs
a
c
c
es
s
to
th
e
a
u
th
o
ri
ty
,
th
ey
c
o
u
ld
u
se
th
e
sy
st
em
th
ro
u
g
h
th
e
in
te
rn
et
a
n
y
w
h
er
e
a
n
d
a
n
y
ti
m
e.
A
s
a
re
su
lt
,
it
ex
p
a
n
d
s
th
e
sc
a
le
o
f
th
e
se
rv
ic
e.
298
In other words, the performance ranking is Project (II) / Project (III) /
Project (I). In addition, the least difference between the aggregated per-
formances of these three software projects exists at the case of a ¼ 0.5.
The reason lies in the fact that ‘‘a ¼ 0.5’’ refers to the maximal entropy
in data and, therefore, results in the most uniformity in criterion weights,
i.e., all of the weights equal to 1=n.
Validation and Comparison
In order to further validate the appropriateness of the proposed model,
the study was done with SWA operator to proceed with the comparison
between the aggregated results. In implementing SWA, two types of
criterion weights were used. One was the uniform type, while the other
used the weights obtained by the model of Lee et al. (1999). Using the
model of Lee, the criterion weight distribution is shown in Table 3. After
aggregating these associated weights and the original evaluation data by
evaluators, the aggregated performances of these three software projects
are respectively presented in Table 4.
All the aggregated results (Table 4) illustrate the same performance
ranking, i.e., Project (II) / Project (III) / Project (I). This result pro-
vides a powerful evidence for validating this integrated evaluation model
for evaluating the performance of these three software projects. On the
other hand, as compared with SWA, this integrated evaluation model
would be a useful even by means of less amount of evaluation criteria
and corresponding information data. In addition, owing to the adoption
Figure 5. Aggregated performances of the three software projects for different values of a.
300 D.-Y. YEH ET AL.
In this model, a well designed questionnaire was used as the instru-
ment to express the experts’ opinions on the performances of targets
with respect to each criterion. Then, the PCA operator was used to
reduce the handling amount of data and the OWA operator was used
to analytically obtain the weight distribution of criteria. In the empirical
case of three software projects, the original 10 criteria were linearly
transformed into the reduced six principle components by means of
PCA, and transformed were the PCA scores of three software projects
with respect to the six principal components. After conducting OWA,
the weight distribution of six principle components was obtained. As
aggregating the PCA scores and the OWA weights, the ranking of aggre-
gated performance, Project (II) > Project (III) > Project (I), was
obtained for all different values of situation parameter a.
Two advantages contain in this model. One lies in the verified
evidence that this integrated evaluation model would be a useful model
for evaluating the performances of software projects even by means of
less amount of evaluation criteria and corresponding information data.
As a result, it reduces the complexity of software project evaluation.
The other lies in the fact that, owing to the adoption of situation param-
eter a, this integrated evaluation model provides a flexible possibility in
deciding the weight distribution of evaluation criteria.
REFERENCES
Boehm, B. W. 1988. A spiral model of software development and enhancement.
IEEE Computer, 21:61–72.
Cheng, C. H. 2005. Dynamic fuzzy OWA model for evaluating the risks of
software project. Soft Computing (in press).
Fuller, R. and P. Majlender. 2001. An analytic approach for obtaining maximal
entropy OWA operator weights. Fuzzy Sets and Systems, 124:53–57.
Hotelling, H. 1933. Analysis of a complex of statistical variables into principal
components. Journal of Educational Psychology, 24:498–520.
Humphrey, W. S. 1989. Managing the Software Process. MA: Addison-Wesley.
Jiang, J. J., G. Klein, H.-G. Hwang, J. Hunag, and S.-Y. Hung. 2004. An explo-
ration of the relationship between software development process maturity
and project performance. Information and Management, 41:279–288.
Krishnan, M. S., C. H. Kriebel, S. Kekre, and T. Mukhopadhyay. 2000. An
empirical analysis of productivity and quality in software products. Manage-
ment Science, 46(6):745–759.
302 D.-Y. YEH ET AL.
OWA rough set model for forecasting the revenues growth rate of the
electronic industry
Jing-Wei Liu a, Ching-Hsue Cheng a,*, Yao-Hsien Chen a,b, Tai-Liang Chen c
aDepartment of Information Management, National Yunlin University of Science and Technology, 123, Section 3, University Road, Touliu, Yunlin 640, Taiwan, ROC
bDepartment of Information Management, WuFeng Institute of Technology, 117, Section 2, Jianguo Road, Minsyong, Chiayi 621, Taiwan, ROC
cDepartment of Information Management and Communication, Wenzao Ursuline College of Languages, 900, Min-Tzu 1st Road, Sanming District, Kaohsiung 807 Taiwan, ROC
a r t i c l e i n f o
Keywords:
Attribute selection
OWA (ordered weighted averaging)
Rough set theory
Revenue growth rate
Electronic industry
a b s t r a c t
Business operation performance is related to corporation proﬁtability and directly affects the choices of
investment in the stock market. This paper proposes a hybrid method, which combines the ordered
weighted averaging (OWA) operator and rough set theory after an attribute selection procedure to deal
with multi-attribute forecasting problems with respect to revenue growth rate of the electronic industry.
In the attribute selection step, four most-important attributes within 12 attributes collected from related
literature are determined via ﬁve attribute selection methods as the input of the following procedure of
the proposed method. The OWA operator can adjust the weight of an attribute based on the situation of a
decision-maker and aggregate different attribute values into a single aggregated value of each instance,
and then the single aggregated values are utilized to generate classiﬁcation rules by rough set for fore-
casting operation performance.
To verify the proposed method, this research collects the ﬁnancial data of 629 electronic ﬁrms for pub-
lic companies listed in the TSE (Taiwan Stock Exchange) and OTC (Over-the-Counter) market in 2004 and
2005 to forecast the revenue growth rate. The results show that the proposed method outperforms the
listing methods.
 2009 Elsevier Ltd. All rights reserved.
1. Introduction
Besides the ﬁnancial index, the business operation performance
of listed companies is the most important factor of investment,
which deeply affects the long-term portfolio of investors in the
stock market. Investors will select some adequate performance
indices to evaluate the development capability of companies as
investment targets. Due to advances in electronic techniques and
international growth of economics, the manufacturers in the elec-
tronic industry have continuously designed and produced more
and more advanced electronic components and products. Further-
more, people have had more economic ability in pursuit of a com-
fortable life via consuming the latest advanced electronic products,
such as computer, communication, and common consumer electric
appliances that are so-called 3C products for short. Accommodat-
ing the global trend of development in the electronic industry
and supported by governments under Regulations of Encourage-
ment, that makes the electronic industry substantially grown up
in the last decades in Taiwan. Compared with other traditional
industries in Taiwan, the proportion of export and gross national
product in the electronic industry have been raising ceaselessly.
Concurrently, Taiwan has become one of the major electronic
products producers, and the electronic industries have had the
greatest number of listed companies in the Taiwan stock market.
Trade in the electronic section has become one of the most impor-
tant choices of investment in the Taiwan stock market. Moreover,
the stock price ﬂuctuation of the electronic section often essen-
tially affects the whole price index and even the cycle of the stock
market in Taiwan. For these reasons, accurately forecasting the
operation performances of those electronic companies will be dee-
ply related with the investment beneﬁts for stock investors.
For performance analysis, it is the major step to select a set of
proper input and output attributes as measure attributes, because
more adequate input and output attributes identiﬁed will bring
more suitable results of evaluation in the respective condition
(Charnes, Cooper, & Rhodes, 1984). Thore, Philips, Rueﬂi, and Yue
(1996) adopted six input attributes and three output attributes
to rank the efﬁciency of US computer companies. Reynolds and Biel
(2007) used seven attributes as input and four attributes as output
to measure productivity index. Both researches introduced reve-
nue as a major output indicator to measure the business operation
performance of industrial comparators. This paper employs 12
attributes as input of the developed forecasting model and revenue
0957-4174/$ - see front matter  2009 Elsevier Ltd. All rights reserved.
doi:10.1016/j.eswa.2009.06.020
* Corresponding author. Tel.: +886 5 534 2601x5312; fax: +886 5 531 2077.
E-mail addresses: g9523802@yuntech.edu.tw (J.-W. Liu), chcheng@yuntech.
edu.tw (C.-H. Cheng), g9523812@yuntech.edu.tw (Y.-H. Chen), 97007@mail.wtuc.
edu.tw (T.-L. Chen).
Expert Systems with Applications 37 (2010) 610–617
Contents lists available at ScienceDirect
Expert Systems with Applications
journal homepage: www.elsevier .com/locate /eswa
could be computed by using linguistic quantiﬁers. The OWA oper-
ator is obtained by the following steps:
(1) Reorder the input arguments in descending order.
(2) Determine the weights that associate with the OWA opera-
tor by using a proper method.
(3) Utilize OWA weights to aggregate these reordered
arguments.
An OWA operator of dimension n is a mapping, OWA: Rn? R,
that has an associated n vector w = (w1,w2, . . . ,wn)T such that
wj 2 [0,1] and
Pn
j¼1wi ¼ 1, such that
OWAwða1;a2; . . . ; anÞ ¼
Xn
j¼1
wibj; ð7Þ
where bj is the jth largest element of the collection of the aggre-
gated objects (a1,a2, . . . ,an).
Yager further introduced two characterizing measures, called
orness measure and dispersion measure. Both of them are associ-
ated with the weighting vector w of an OWA operator, where the
orness measure of the aggregation is deﬁned as
ornessðwÞ ¼ 1
n 1
Xn
j¼1
ðn iÞwi ð8Þ
where the orness(w) = a is a situation parameter that lies in unit
interval [0,1] and characterizes the degree to which the aggregation
is like an or operation. The second one, the dispersion measure of
the aggregation, is deﬁned as
dispðwÞ ¼ 
Xn
j¼1
wi lnwi ð9Þ
which measures the degree to whichw takes into account the infor-
mation in the arguments during the aggregation.
O’Hagan (1987, 1988) used orness measure and dispersion
measure to develop a new method to generate the OWA weight
that has a predeﬁned degree of orness and maximizes the entropy.
This procedure is based on the following constrained optimization
problem:
Maximize :
Xn
j¼1
wi lnwi ð10Þ
Subject to :
1
n 1
Xn
i¼1
ðn iÞwi ¼ a; 0 6 a 6 1
Xn
i¼1
wi ¼ 1; 0 6 wi 6 1; i ¼ 1;2; . . . ; n ð11Þ
2.2.2. Fuller and Majlender’s OWA
Fuller and Majlender (2001) proposed a new method by using
Lagrange multipliers to improve the problem in Eq. (5) and got
the following:
(1) If n = 2, then w1 = a, w2 = 1  a.
(2) If a = 0 or a = 1, then the associated weighting vectors are
uniquely deﬁned as w = (0,0, . . . ,1)T and w = (1,0, . . . ,0)T,
respectively, with the value of dispersion zero.
(3) If nP 3 and 0 < a < 1, then
wj ¼
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
wn11 w
j1
n
n1
q
ð12Þ
wn ¼ððn1ÞanÞw1þ1ðn1Þaþ1nw1 ð13Þ
w1¼½ðn1Þaþ1nw1n ¼ððn1ÞaÞn1½ððn1ÞanÞw1þ1 ð14Þ
wherewj is weight vector, n is the number of attributes, and a is the
situation parameter. The optimal OWA-associated weights are ob-
tained by solving Eqs. (6)–(8).
After obtaining the best a value, the principal components
scores and OWA-associated weights can aggregate into a single
integrated value by the following equation:
ak ¼ w1x1k þw2x2k þ    þwixik þwnxnk ð15Þ
where wi is ith input of the OWA-associated weight and xik is ith
attribute value of kth record.
2.3. Rough set theory
The rough set theory was proposed by Pawlak (2002), which
has been successfully applied in a great many domains, such as
controlling industrial processes (Chan, 1998; Jackson, Pawlak, &
LeClair, 1998), diagnosis analysis (Mitra, Mitra, & Pal, 2001;
Tay & Shen, 2003), image processing (Pal & Mitra, 2002), market
decision-making (Shen & Loh, 2004), environmental problem
detection (Che‘vre, Gagne’, Gagnon, & Blaise, 2003), data-mining
(Chen, Chang, & Chen, 2003), and web and text categorization
(Chouchoulas & Shen, 2001; Jensen & Shen, 2004). The basic
concept of the RST is the notion of approximation space, which
is an ordered pair A = (U,R), where U: nonempty set of objects,
called universe, and R: equivalence relation on U, called indis-
cernibility relation. If x, y 2 U and xRy then x and y are indistin-
guishable in A.
An approximation space can be noted by A ¼ ðU; eRÞ, where
eR ¼ U=R. A deﬁnable set in A is any ﬁnite union of elementary sets
in A. For x 2 U, let [x]R denote the equivalence class of R, containing
x. For each x # U, x is characterized in A by a pair of sets – its lower
and upper approximation in A, deﬁned respectively as:
AlowðXÞ ¼ fx 2 Uj½xR#Xg ð16Þ
AuppðXÞ ¼ fx 2 Uj½xR \ X – /g ð17Þ
3. The proposed method
The OWA operator is an important tool to cope with multi-attri-
bute data, and it is different from the classical weighted average in
that given weight method; further, OWA considers not only attri-
butes ordering but also decision-makers’ preferences (situation).
OWA provides a new method for aggregating multiple inputs that
lie between the max and min operators (Ahn, 2006); it also pro-
vides a uniﬁed framework for decision-making under uncertainty,
where different decision criteria, such as maximax (optimistic),
maximin (pessimistic), equally likely (Laplace), and Hurwicz crite-
ria, are characterized by different OWA operator weights (Wang,
Luo, & Hua, 2007).
Rough sets, proposed by Pawlak (2002), are an extension of the
set theory for the study of information systems characterized by
insufﬁcient and imperfect data, and it has been successfully ap-
plied in AI, knowledge discovery in database, and data-mining
(DM). There are at least two methods to study rough sets. One
is the constructive method, and the other is the axiomatic ap-
proach (Shen & Loh, 2004). The axiomatic approach is different
from the constructive approach; the axiomatic approach aims to
investigate the mathematical characters of rough sets, which
may help to develop methods for applications. Hence, the rough
set has two advantages: (1) attributes reduction of a single-
dimension data set; and (2) attributes reduction of a hybrid-struc-
tural data set.
In order to improve the accuracy of forecasting results, this study
employs the rough sets method to generate rules from aggregated
values by OWA. From the OWA and rough set advantages
612 J.-W. Liu et al. / Expert Systems with Applications 37 (2010) 610–617
4. A case study
To further demonstrate the performance of the proposed model,
we practically collected a dataset from the Taiwan Economic Jour-
nal (TEJ) database (TEJ, 1990). Furthermore, both the out-of-sample
forecasting and in-sample estimation are conducted to compare
with other methods.
4.1. TEJ dataset
The dataset of this research was sourced from the Taiwan Eco-
nomic Journal database, which includes macroeconomics, ﬁnance,
industries, and business datasets. All of the datasets provide the
basic data, ﬁnance data, and share price data of listed companies
and publicly held companies. For veriﬁcation, this research collects
the ﬁnancial data of the 629 public companies listed in the TSE
(Taiwan Stock Exchange) and OTC (Over-the-Counter) market elec-
tronic ﬁrms in 2004 and 2005, which includes 12 attributes with
2413 and 2490 records (in four seasons). The dataset is partitioned
into 67% training data (1616 records) and 33% testing data (797 re-
cords) in 2004, and training data (1668 records) and 33% testing
data (822 records) in 2005.
4.2. Analysis and results
In this section, we forecast the industrial growth rate by the
proposed algorithm in Section 3; the detailed processes are listed
in the following:
(1) Select attributes
In this step, we distinguish the dataset with three classes
(A,B,C) by operating grow-up rate. We set A, B, and C class,
respectively, by the operating grow-up rate P100%, 0–
100%, and <0%. We use ﬁve attribute evaluation methods
(Chi-Squared, Gain Ratio, Information Gain, ReliefF, and
Symmetrical Uncertainty) to order the attributes of the
dataset.
From Tables 1 and 2, we can see that Chi-Squared, Infor-
mation Gain, and Symmetrical Uncertainty have the same
orderings in the ﬁrst 4 attributes (1. Operating Inco-
me = OI; 2. Gross Sales = GS; 3. Operating Cost = OC; 4.
Employees numbers = GN). Therefore, this paper uses the
ﬁrst 4 attributes to forecast the industrial growth rate.
(2) Compute the OWA weights
From Step 1, the attribute number is four. Then, OWA
weights could be gotten by Eqs. (6)–(8). The OWA weights
are listed in Tables 3 and 4 under attribute numbers = 4
and a = [0,1.0].
Table 2
The results of selecting attributes (the same orderings in ﬁrst 4 attributes) in 2005 year.
Chi-Squared Gain Ratio Information Gain ReliefF Symmetrical Uncertainty
Operating proﬁt Operating proﬁt Operating proﬁt Net operating revenue Operating proﬁt
449.461 0.0889 0.137 0.00142 0.1025
Gross proﬁt Employee numbers Gross proﬁt Gross sales Gross proﬁt
309.928 0.0533 0.096 0.0014178 0.0633
Employee numbers Gross proﬁt Net operating revenue Cost of goods sold Employee numbers
200.732 0.0505 0.0452 0.0013796 0.0355
Net operating revenue Net operating revenue Gross sales Total non-operating expenses Net operating revenue
157.457 0.0291 0.0446 0.0013468 0.0336
Gross sales Gross sales Employee numbers Employee numbers Gross sales
155.963 0.0288 0.0302 0.0009295 0.0333
Total labor Total labor Cost of goods sold Total non-operating income Cost of goods sold
152.995 0.0235 0.021 0.0006504 0.0203
Cost of goods sold Cost of goods sold Total labor Operating proﬁt Total labor
72.155 0.0223 0.0199 0.0006418 0.0201
Total non-operating income Total non-operating income Total non-operating income Gross proﬁt Total non-operating income
45.693 0.0133 0.0133 0.0005293 0.0125
Operating expense Operating expense Operating expense Operating expense Operating expense
38.871 0.0128 0.0133 0.0005023 0.0112
Fixed asset Fixed asset Fixed asset Fixed asset Fixed asset
0 0 0 0.0003031 0
Total non-operating expenses Total non-operating expenses Total non-operating expenses Total depreciation Total non-operating expenses
0 0 0 0.0001037 0
Total depreciation Total depreciation Total depreciation Total labor Total depreciation
0 0 0 0.0000946 0
Table 3
The OWA operator weights in 2004 year.
a Operating proﬁt Gross proﬁt Net operating revenue Gross sales
a = 0.0 0 0 0 1
a = 0.1 0.0104 0.0434 0.1822 0.7641
a = 0.2 0.045 0.1065 0.2521 0.5965
a = 0.3 0.0987 0.1646 0.2754 0.4609
a = 0.4 0.1671 0.2133 0.2722 0.3475
a = 0.5 0.25 0.25 0.25 0.25
a = 0.6 0.3475 0.2722 0.2133 0.1671
a = 0.7 0.4609 0.2754 0.1646 0.0987
a = 0.8 0.5965 0.2521 0.1065 0.045
a = 0.9 0.7641 0.1822 0.0434 0.0104
a = 1.0 1 0 0 0
Table 4
The OWA operator weights in 2005 year.
a Operating proﬁt Gross proﬁt Net operating revenue Gross sales
a = 0.0 0 0 0 1
a = 0.1 0.0104 0.0434 0.1822 0.7641
a = 0.2 0.045 0.1065 0.2521 0.5965
a = 0.3 0.0987 0.1646 0.2754 0.4609
a = 0.4 0.1671 0.2133 0.2722 0.3475
a = 0.5 0.25 0.25 0.25 0.25
a = 0.6 0.3475 0.2722 0.2133 0.1671
a = 0.7 0.4609 0.2754 0.1646 0.0987
a = 0.8 0.5965 0.2521 0.1065 0.045
a = 0.9 0.7641 0.1822 0.0434 0.0104
a = 1.0 1 0 0 0
614 J.-W. Liu et al. / Expert Systems with Applications 37 (2010) 610–617
(6) Veriﬁcation and comparison
For comparison, this paper uses four data-mining methods
to compare with the proposed model. The four methods
are (a) rough set theory, (b) decision tree C4.5, (c) Bayesian
networks, and (d) multilayer perceptron. We use the 67%
dataset as training data and the 33% as testing data. Accord-
ing to the experiment’s result, we have the best accuracy;
96.82% and 95.01% in years 2004 and 2005. The result of
the accuracy rate is shown in Table 9.
5. Conclusions
In this paper, a hybrid method, which combines OWA and
rough set, has been proposed to enhance conventional classiﬁca-
tion methods. According to the experiments, we have two ﬁnd-
ings: (1) from Table 9, it is apparent that the proposed method
outperforms the listing methods; and (2) from Tables 7 and 8,
there is the optimal accuracy while the situation variable a is
1. It means apparently that investors will get a rather accurate
RGR forecast as long as they employ the ﬁrst input attribute,
operation proﬁt.
In future work, we will build a prototype system based on the
proposed method and use more open datasets to verify the perfor-
mance of the proposed method.
References
Ahn, B. S. (2006). On the properties of OWA operator weights functions with
constant level of orness. IEEE Transactions on Fuzzy Systems, 511–515.
Anderson, G. (1996). Nonparametric tests of stochastic dominance in income
distributions. Econometrica, 64, 1183–1193.
Chan, C. C. (1998). A rough set approach to attribute generalization in data mining.
Information Sciences, 107(1-4), 169–176.
Charnes, A., Cooper, W. W., & Rhodes, E. (1984). Measuring the efﬁciency of decision
making units: A comment. European Journal of Operational Research, 2, 429–444.
Chen, W. C., Chang, N. B., & Chen, J. C. (2003). Rough set-based hybrid fuzzy-neural
controller design for industrial wastewater treatment. Water Research, 37(1),
95–107.
Che‘vre, N., Gagne’, F., Gagnon, P., & Blaise, C. (2003). Application of rough sets
analysis to identify polluted aquatic sites based on a battery of biomarkers: A
comparison with classical methods. Chemosphere, 51(1), 13–23.
Chouchoulas, A., & Shen, Q. (2001). Rough set-aided keyword reduction for text
categorization. Applied Artiﬁcial Intelligence, 15(9), 843–873.
Fuller, R., & Majlender, P. (2001). An analytic approach for obtaining maximal
entropy OWA operator weights. Fuzzy Sets and Systems, 124, 53–57.
Grzymala-Busse, J. W., & Stefanowski, J. (1997). Discretization of numerical
attributes by direct use of the LEM2 induction algorithm with interval
extension. In Paper presented at the proceedings of sixth symposium intelligent
information systems, Zakopane.
Herrera, F., Herrera-Viedma, E., & Verdegay, J. L. (1996). A model of consensus in
group decision making under linguistic assessments. Fuzzy Sets and Systems, 78,
73–87.
Fig. 3. The partial rules under n = 4 and a = 0.5 in 2005 year.
Table 7
The accuracy rate under different a (2004 year).
a [Min,Max] Average accuracy rate (%)
a = 0.5 [0.93,0.957] 94.44
a = 0.6 [0.939,0.962] 95.22
a = 0.7 [0.944,0.968] 95.77
a = 0.8 [0.947,0.97] 96.12
a = 0.9 [0.948,0.975] 96.28
a = 1.0 [0.958,0.98] 96.82
Table 8
The accuracy rate under different a (2005 year).
a [Min,Max] Average accuracy rate (%)
a = 0.5 [0.908,0.941] 92.03
a = 0.6 [0.913,0.957] 93.08
a = 0.7 [0.916,0.953] 93.09
a = 0.8 [0.926,0.959] 94.04
a = 0.9 [0.93,0.964] 94.45
a = 1.0 [0.936,0.968] 95.01
Table 9
Comparison results with other methods for TEJ dataset.
Method Average accuracy rate (%)
2004 year 2005 year
The proposed method 96.82 95.01
Rough set theory (Jackson et al., 1998) 74.89 68.64
Decision tree C4.5(Quinlan, 1993) 74.47 65.91
Bayesian networks (Pearl, 1988) 71.01 63.92
Multilayer perceptron (Zhao et al., 1998) 73.28 52.17
616 J.-W. Liu et al. / Expert Systems with Applications 37 (2010) 610–617
 1
 3
參加本次會議除了個人發表目前所研究的心得外，尚有另外兩個目的。其一，便是去學
習了解到目前國際資訊科技理論應用的研究趨勢與課題。這些知識正好可以運用在目前教學
與研究上，並將這些新知分享給老師與其他研究同儕。 其二，經由本次的研會，也認識了許
多各國與本國學者，在廣結善緣的同時，也了解到更多有關國際期刊及研討會訊息，這些都
將是未來研究的最重要的動力來源。 
 
三、 建    議 
    由於雲科位置不在大都會區，所以在邀訪國際學者來校講學及研究有其先天限制。因此，
我們應儘量擴大鼓勵並獎勵各系所屬教師以及研究生，多參與國外研討會並發表論文，以吸
收國際新知，造福更多學生與人群為目的，進而達成促進國際交流的目標。 
四、 攜回資料名稱及內容 
光碟一片，會議論文集一本，會議議程一份 
 
 
 
 
 
【備註】會議結束返國後 15 日內，且須在核定補助當年（同一會計年度）12 月 10 日前，
將發表論文全文、出國報告及報告提要 PDF 檔傳送至國際事務處信箱：
tdx@yuntech.edu.tw，俾依規定公布於專屬網頁。逾期未繳交論文全文、出國報告
及報告提要電子檔者不予補助，且不得再提出申請。 
 
persuasiveness in determining universe of discourse and 
the length of intervals. (2) Don’t consider the different 
trend weights be assigned to various fuzzy relationships. 
(3) Don’t consider the dispersal condition of whole data. 
In order to solve these problems, an objective and 
reasonable approach is needed. 
For overcoming these drawbacks mentioned above, this 
paper proposes a new fuzzy time series based on two-
stage partition method to predict air quality by daily 
maximum 
3O  concentration. Firstly, fuzzy time series based 
on Cumulative Probability Distribution Approach to 
partition each interval into seven sub-intervals the 
universe of discourse. Secondly, use two partition 
methods, Cumulative Probability Distribution Approach 
and Uniform Discretion Method, to re-partition each 
interval into three sub-intervals. Two methods are more 
objective and reasonable to improve the persuasiveness in 
determining the universe of discourse, length of intervals , 
and each fuzzy relationships weight of fuzzy time series. 
 
2. Related works 
 
This section briefly reviews the related literature, 
including three sections: literature reviews of Fuzzy Time 
Series Models, of Cumulative Probability Distribution 
Approach and Uniform Discretion Method.  
 
2.1 Fuzzy Time Series Models 
 
In 1993, Song and Chissom [16,17] proposed the 
definitions of fuzzy time series and methods to model fuzzy 
relationships among observations. The concepts  of fuzzy 
time series are described as follows: 
Definition 1. Define the universe of discourse and intervals 
for rules abstraction.  
Based on the problem domain, the universe of discourse 
can be defined as [ ]endingstartingU ,= . As the 
length of interval is determined, it can be partition the 
universe of discourse into equal length intervals. 
Definition 2. Define fuzzy sets on the universe of 
discourse and fuzzify the historical data. 
Definition 3. Fuzzifying observed rules 
For example, a datum is fuzzified to 
jA  if the maximal 
degree of membership of that datum is in 
jA . 
Definition 4. Establish fuzzy logical relationships and 
group them based on the current states of the data of the 
fuzzy logical relationships.  
For example
21 AA ® , 11 AA ® , 31 AA ®  can be grouped 
as 
3211 ,, AAAA ® . 
Definition 5. Forecast 
Case1: If there is only one fuzzy logical relationship in the 
fuzzy logical relationship, let ( ) iAtF =- 1 , if ji AA ® , 
then the forecast of ( )tF  is equal to jA . 
Case2: If 
kjii AAAA ,,, K® , then the forecast of ( )tF  is 
equal to 
kji AAA ,,, K . 
Definition 6. Defuzzify.  
Centroid method: this procedure (also called center of area, 
center of gravity) is the most popular defuzzification 
method. 
 
2.2 Cumulative Probability Distribution 
Approach (CPDA)  
 
According to the rule of thumb, the universe of 
discourse can be partitioned by mean and standard 
deviation of the data. The cumulative probability of normal 
distribution is used to determine the intervals. The 
procedure of cumulative probability distribution approach 
is as follows: 
Definition 1. Test normal distribution. 
In this approach, the data must be normal distribution. The 
lilliefors test [8] is used to exam whether the data is normal 
distribution.  
Definition 2. Define the universe of discourse U. 
Let U = [Dmin -s , Dmax+s ], where Dmin and Dmax denotes 
the minimum and maximum in historical data, and s  
denotes the standard deviation of the data, respectively.  
Definition 3. Determine the length of intervals and build 
membership function. 
According to Miller [12], this paper defines seven 
linguistic values to have better identity. The PLB as lower 
bound cumulative probability and PUB as upper bound 
cumulative probability of each linguistic value are 
computed by 
PLB = (2i – 3) / 2n, (2 ? i ? 
n) 
(1) 
PUB = i / n, (1 ? i ? n) (2) 
where i denotes the order of the linguistic values, and n 
denotes the number of linguistic values. The lower bound 
of first linguistic value and the upper bound of last 
linguistic value are directly corresponded to lower bound 
and upper bound of universe of discourse, respectively. 
The inverse of the normal cumulative distribution function 
(CDF) is computed with parameters m  and s  at the 
corresponding probabilities in P, where m  denotes the 
mean, and s  denotes the standard deviation of the data, 
respectively. The normal inverse function in terms of the 
normal CDF is defined as 
( ) ( ){ }pxFxpFx === - smsm ,:,1  (3) 
Where 
value in the universe of discourse u , 
maxD  
denotes the maximum value in the universe of 
discourse u . 1D  and 2D  are two proper values for 
tolerant the noise in the universe of discourse u , 
and 
2max211min DDxxDD +£££- . 
Method 2: Partition the universe of discourse u  of 
the second-order into m  intervals 11u , 
12u , 13u , 21u , 22u , 23u , … , 73u , where 
[ )Exxxxu +== 001011 ,),[ , ),(),( 112112 Exxxxu +== ,
],(),( 223213 Exxxxu +== , [ )Exxxxu +== 001021 ,),[ ,
),(),( 112122 Exxxxu +== ,
],(),( 223223 Exxxxu +== , … , 
[ )Exxxxu +== 001071 ,),[ , ),(),( 112172 Exxxxu +== , 
],(),( 223273 Exxxxu +== , ( )[ ] 3/1min1 DDxE --=  
denotes the uniform discretion value in the interval 
of discourse u , and 
2max211min DDxxDD +£££- .  
Step5: Fuzzify dataset into linguistic values 
Define the linguistic terms of the two-stage 
represented by the fuzzy sets, 
kAAA ,...,, 21 , on the 
universe of discourse by Eq. (5).  
mm uauauaA /...// 12121111 +++=  (5) 
mm uauauaA /...// 22221211 +++=  
. 
. 
. 
mkmkkk uauauaA /...// 2211 +++=  
Step6: Establish fuzzy logic relationship 
There are two sub-steps included in this process as 
follow: (1) Establish a relationship between two 
consecutiv e linguistic values, ( )1-tAi  and )(tA j . 
Then, represent the relationship into a FLR such as 
ji AA ® , and (2) classify all FLRs  with the same 
LHSs  to form a FLR group.  
Step7: Calculate trend weighting  
Transfer these weights into a normalized weight 
matrix, )(tWn , which is defined in the following 
equation: 
[ ]
ú
ú
û
ù
ê
ê
ë
é
=
=
ååå ===
j
k k
k
j
k k
j
k k
jn
W
W
W
W
W
W
WWWtW
11
2
1
1
''
2
'
1
,...,,
,...,,)(  (6) 
Step8: Defuzzify linguistic and forecast 
Defuzzify to compute initial forecasts, the 
defuzzified matrix, )(tLdf , defined in Eq. (7), are 
employed (where 
im  is the midpoint of each 
linguistic interval, 
iu ) 
[ ]idf mmmtL ,...,)( 21=  (7) 
The process of “defuzzify” is defined in Eq. (8) to 
generate the initial forecasts based on the attribute 
of 
3O . 
Tndf tWtLtForcast )()()1( ·=+  (8) 
Step9: Evaluation 
We use MAPE and RMSE as evaluation criterion. 
 
4. The results of numerical experiments 
 
For verifying the proposed methods, we practically 
collect air quality 
3O  datasets  and compare with the listing 
methods.  
 
4.1 Experiment process 
 
The detailed demonstration is step by step introduced 
as  follows:  
Step1: Data preprocessing 
We practically collect air quality data of air quality 
inspection station dataset with 3O  attribute from 
January 1, 2007 to December 31, 2007 in Hsinchu 
city, Taiwan.  
Step2: Attributes selection 
From past literatures, this paper adopts fuzzy time 
series data for 
3O  attribute.  
Step3: Determine the universe of discourse U  
Define the universe of discourse, ]35.65,55.3[-=U , 
which can cover all observations of 
3O  in the air 
quality dataset.  
Step4: Partition U  into N intervals by two-stage methods 
First-order, we have partition U  into seven 
intervals  by CPDA methods. Use the two re-
partition methods to partition intervals: (1) second-
order of partition seven intervals  use CPDA  to re-
partition three intervals, such as , 
[ )01.11,55.311 -=u , )98.12,01.11(12 =u , ]65.14,98.12(13 =u . 
(2) second-order of partition seven intervals  use 
UDM to re -partition three intervals, such as 
[ )52.2,55.311 -=u , )58.8,52.2(12 =u ,
]65.14,58.8(13 =u .  
Step5: Fuzzify dataset into linguistic values 
Find out the degree of each 
3O  belonging to each 
iA  ( )mi ,...,1= . If the maximum membership of the 3O  
is under 
kA , then the fuzzified 3O  is labeled as kA .  
Step6: Establish fuzzy logic relationship 
Construct fuzzy logical relationships and build FLR 
groups.  
Step7: Calculate trend weighting 
