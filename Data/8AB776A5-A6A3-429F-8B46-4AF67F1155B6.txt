1符合 MPEG-7 高階多媒體檢索技術
之手持式行動多媒體百科全書(精簡報告)
計畫編號：NSC 94－2213－E－034－004－
執行期間：94 年 08 月 01 日 至 95 年 07 月 31 日
吳宗德
中國文化大學 資訊傳播學系
中文摘要
隨著網路寬頻化的普及以及電腦處理影音多媒體資訊的能力大幅提升，人們藉由網際網路搜
尋及獲取知識的方式將不再侷限於傳統的以文字為主的檢索方式，由於圖片、聲音及影片等多媒
體的資訊內容呈現方式，相較於單純的文字敘述方式，可以更精確有效率的傳達資訊。因此多媒
體資訊的檢索需求將成為近年來資訊服務研究，例如線上百科全書等研究的重要課題。
傳統的線上百科全書以純文字為主加上靜態圖片為輔，作為主要內容呈現方式，而導入數位
化之後的多媒體影音製作流程，使得大量的影音素材可以在短時間內被產生以及透過網路的快速
散佈與分享。多媒體的線上百科全書加入了大量的串流影片檔案，希望能夠藉由多重感官的訊息
傳達方式來提昇資訊傳播的效果，然而影片的前置作業包括獲取影片出版的索引資料和剪輯符合
需求的精要片段仍需要耗費大量的人力與金錢來達成。因此本研究嘗試利用符合標準化之影片場
景檢索技術來進行半自動化處理，以取得所需要的影片資訊，並快速產生影片索引表及索引影
像，透過影片分析工具產生符合 MPEG-7 標準的 XML 檔案和轉換 (XSL Transformation) 成為網
頁內容展示於使用者，有利於跨平台之間的影片索引資訊的傳遞。本計畫建立一個簡易的影片後
設資料(Metadata)資料庫檢索以及網路視訊影片串流播放服務雛形系統，藉由影片段落索引表的
呈現方式加強影片檢索的效能。
符合標準化的影片後設資料建置有助於數位影片的檢索和有效篩選影片片段內容。此項技術
可應用在透過網路傳送的多重播放(multicast)數位影音廣播服務，位於接收端(PC 或行動裝置)的
使用者可在影片播送的即時透過索引表瀏覽及後設資料的檢索，選擇感興趣的影片片段進行播
放，而服務內容提供者只需傳送所欲提供內容的 Metadata 至服務平台，由平台匯整排序後，提
供給使用者瀏覽。當使用者要求服務內容時，平台才將該要求轉送至服務內容提供者直接內容給
使用者。除了透過電腦自動化分析影格之間低階特徵值的差異（如顏色、紋理等），影片管理者
可利用文字補充人類語義層面的後設資料，彌補透過電腦自動化特徵値擷取所產生的檢索誤差。
關鍵詞：影片場景分析、串流影片、多媒體百科全書、XML、metadata。
3段。另一方面也可以減少不必要的資料傳輸和頻寬浪費。
目前大多數的傳統媒體出版業者對於影片的存放是將直接影片透過數位化的過程儲存成數
位檔案，而並未包含相關資訊可供未來以不同形式出版時利用。因此當出版業者需要將影片進行
出版或是從龐大的視訊庫中找尋所需的內容(甚至是內容中的某個片段) 、從大量的視訊資料中
濾出個人所指定的視訊資料、以及從冗長的視訊中做一些綜合性的整理和瀏覽性資料，這些工作
目前仍大都由人工處理，導致時間和人力成本的浪費。[註 2]國家型的數位典藏計畫初期以典藏
品數位化工作、數位內容之管理及詮釋資料整理為主，中、長期將以教育性質之利用推廣為主要
工作。國家典藏的數位化，可以有效提升知識的累積、傳承與運用，是知識經濟的重要基礎環節。
而在大量數位化的典藏品檔案中，有效管理不同種類多媒體與多媒體檔案的搜尋乃是一個非常重
要的研究課題。因此，產業及學界不斷在開發多媒體檢索與內容管理之核心應用技術[註 3]，例
如研究利用及整合關鍵詞抽取、語音辨識、圖像內涵辨識、索引詞等技術建立檢索點與關聯式索
引目錄索引之輔助工具，藉以降低整理數位典藏文物所需之人力成本與時間耗費。
二、 研究目的
本研究的主要目的是希望能夠利用影片場景偵測技術，進行影片場景偵測及主要畫面的自動
判斷及擷取，以進行影片自動化分割，並快速產生影片索引及關鍵畫面，以簡化並縮短數位影片
管理或出版的前置流程，如此便可大大減少所需的時間與人力。此外透過匯出的符合 MPEG-7
標準的 XML 的結構化資料儲存文件，有利於跨平台之間的資訊流通。
除了廣電媒體以及網際網路隨選視訊（VOD）服務等相關數位影音出版的應用之外[註 4]，
多媒體百科全書是最可以被廣為使用的其中一種應用，在面臨科技進步的衝擊，將知識以數位內
容儲存再加以包裝、傳播、勢必成為未來之趨勢。目前電子百科全書的發展仍舊是文字重於影像、
影像重於影片的狀況，例如大英百科全書與與微軟 Encarta 系列的百科全書，如此，並不能突顯
數位化的價值[註 5]，使用者對於融合多媒體與超文件的線上百科全書，反映出互動性高與活潑
的介面設計之需求。此外多數使用者偏好線上百科全書的重要原因包括了：多媒體的介面呈現、
使用方便的操作方式，以及快速更新等特性。因此本研究的目標為利用多媒體檢索之自動彙整功
能便利多媒體百科全書之建置、強化多媒體之展現以加強知識傳播之功能。
針對目前數位典藏所面臨的環境與議題[註 6]，包括如何找到龐大的數位典藏品，以及如何
確保數位典藏品的長久保存與取得，進而讓數位典藏品達到互通與共享。建置完善的 Metadata
是支援上述問題的一種方法，透過內涵結構化的標準與技術，數位典藏品將可視使用者的需求與
目的，以多元化的方式重新組合、呈現、再使用與轉換，及有效的知識組織與檢索。再者，3G
以及 WIFI 無線傳輸之環境漸趨成熟，透過 3G 行動電話或可攜式數位助理(PDA)可讓使用者隨
時隨地能獲得所需的知識，因此研究目標除了建置透過個人電腦線上瀏覽的多媒體百科全書，更
應用於無線通訊環境，並針對無線通訊環境的限制，研究多媒體資料之前製處理方法。故而本計
5多媒體資料 特徵值的抽取 多媒體資料分割
識別與分類 索引檢索
身抽取出其視覺特性，如顏色及紋理與運動方向等。音訊部份的特徵，則為音調、音量等音訊特
徵。而在多媒體資料分割此項步驟則是因為多媒體資料的組成元素數量大多都相當龐大，無法對
於一個整體進行所有的分析，因此需要在多媒體特徵發生重大改變時將其分割成不同長度的相同
性質的片段。
圖3.2 多媒體基本分析步驟
要做到自動化視訊分析及切割，首先需要瞭解整個視訊的結構及特性，以及其偵測變化的技
術，目前大致可分為兩個領域[註 9]。一個是未壓縮的領域，也就是 Raw Data Domain，經研究
後未壓縮視訊偵測場景變化技術可用下列三種技術：1. pixel-wise comparison、2. likelihood ratio、
3. histogram comparison。另一為壓縮領域，也就是 Compressed Domain，其偵測技術主要有下列
兩項：1. 以 DCT 係數為主的偵測片段變化方法、2. DC Image 為主的偵測片段變化方法[註 11]。
以下討論一般生活中較常接觸到的已壓縮影片探討相關的場景偵測技術。
壓縮域的場景偵測技術主要針對已壓縮影片直接進行處理，使其不需將影片進行解壓縮後
再行處理。目前此領域的技術研究已有眾多持續在進行中，在此將簡略介紹其中較常使用到的離
散餘弦係數及直流值畫面這兩項技術[註 11][註 18]。
(一)、離散餘弦係數 ( DCT coefficients )
研究(F. Arman, A. Hsu and M-Y Chiu, 1993) 上提到此方法主要針為 I 畫面進行判斷處理，但
由於影片中 I 畫面只佔全部畫面的少部份，因此這種場景偵測方法的失敗率較高，而本方法也主
要針對偵測突變式場景變化較準確。其主要原理是抽取影片中連續 I 畫面中個區塊的離散餘弦
係數，再取得這其中個區塊的離散餘弦其中的個係數，因此在第 f 個畫面可取出一個向量
1 2( , ,...., )( )f kV v v v k   ，再與相鄰 I 畫面中的向量 fV  ，再作內積。在這中若值越大，表示
用到畫面越多的區塊，相對的準確度也會提高，但計算量也會隨之增加，而若值越大，則代表
使用越多的離散餘弦係數，一樣的準確度提高，而計算量也會增大。
判斷式如下：
若1 | |   則表示發生突然式變化，其中0 1 
(二)、直流值畫面
此種方法主要是於研究(B.-L. Yeo and B. Liu, 1995) 中所提出，此項方法主要是取出每張畫
面中各區域的直流值，再分別當成一個點來組成直流值的畫面，然後比較兩畫面中直流值的差
| || |
f f
f f
V V
V V


 



7究中，便試圖提出一種電影摘要自動合成技術以及一種角色自動分析技術。將樣板比對法應用到
特寫鏡頭的偵測，利用鏡頭樣板來判別電影鏡頭是否為特寫鏡頭。再將特寫鏡頭依照臉部膚色特
徵來作叢集分析，來找到一部電影各個主要演員的戲份。最後根據演員的戲份比重，由特寫鏡頭
叢集中挑選代表性特寫鏡頭來合成電影摘要。由 HERMES 系統之研究中提到一個觀念，即在處
理多媒體資訊之擷取時，相似度不能以絕對比較值來決定，因此在對於此類資料擷取時必須採取
等級上的區分。在 Rui[14-15]等人的研究中對於影片分析、影片表示法、瀏覽與擷取方面進行探
討。在 Rui 等人的研究中，作者先將影片術語進行解釋，如鏡頭，關鍵畫面以及影片場景的觀
念，其中場景是語義上有關聯以及在時間軸上連續的鏡頭所聚集而成，以表達一個更完整的概念
或是故事。因此，場景之間是語義上的邊界沒有實體上的邊界，而鏡頭之間則有著實體上攝影鏡
頭開關間之邊界存在。簡單的說，場景由許多鏡頭組合而成，而連續的畫面又組成不同的鏡頭。
圖3.3 Browsing 和 Retrieval關聯圖
影片資料庫管理系統之組成元素有 Video Analysis、Video Representation、Video Retrieval 與
Video Browsing 等。影片分析包括了對影片之內容，格式，畫面等特性做分析，來找出足以代表
該影片之特徴資訊，這些特徵資訊將做為搜尋時之比對的主要資料（key)，而影片的表示則可以
將影片分析所得之結果進行組合，以得到一個合理且可代表該部影片之表示法，用以呈現該影
片，影片資料庫的擷取部份則是整合影片與資料庫系統之功能，可以查詢資料庫中之影片資料，
輸出結果由影片瀏覽功能將所查詢之影片資料呈現給使用者，
四、系統架構
本雛形系統架構如圖 4.1 所示大致可分為 Off-Line 及 On-Line 兩部份，並皆以 Microsoft
Windows XP 配合.NET framework 1.0 為主要應用平台。
圖 4.1. 雛形系統架構概念圖
4.1 Off-Line 系統
要將影片做一描述時，首先我們必須使用影音自動切割技術：視訊(Video)、音訊(Audio)內
容特徵分析與彼此相互融合分析，再建立場景Shot Change Detection(場景偵測)、Keyframe
9=
關鍵影格
… …
影格 1 影格 2 影格 299影格 298中央影格
最後，影片鏡頭的結構描述檔案會以 XML 的檔案格式輸出。由圖 3.4 可看輸出的結果，以
FreeTextAnnotation 元素做為片段的描述，包括了片段的時間，Segments 的收集指的是所有切割
區塊的收集，這個資訊主要是針對查詢系統中所有找尋全部的影像特徵所使用。XML 具有可擴
展性、高度結構化和良好的資料組織能力，能夠有效的表達網路上各種知識，為資料的交換和處
理提供新的機制，一般預料，XML 將成為新一代 Web 的整合技術。[註 25]
圖 4.5 以 XML 格式呈現的 MPEG-7 詮釋資料
其中每個<VideoSegment>節點下所包含的欄位值，代表每個場景切割出的鏡頭片段所內含的資
訊內容，如片段播放的時間以及該鏡頭內容的描述值等，如圖 4.6 所示：
圖 4.6 <VideoSegment>的資料結構表
以圖 4.7 這個鏡頭（shot）所呈現的畫面內容為例，播放的時間為 0 分 28 秒起播放 299
個影格，並以 0 分 33 秒的影格內容作為代表畫面，上層的場景事件為『景點介紹』，而該鏡頭所
拍攝的內容為主體是景觀而設施背景是飯店的畫面。因為是介紹三峽的溫泉飯店，因此我們可以
在關鍵詞中自行加註『三峽溫泉飯店』，以期能夠增加查詢系統的準確率，如圖 3.6 所示：
<?xml version="1.0" encoding="big5" ?>
<Mpeg7 xmlns="urn:mpeg:mpeg7:schema:2001"
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
xmlns:mpeg7="urn:mpeg:mpeg7:schema:2001"
xsi:schemaLocation="urn:mpeg:mpeg7:schema:2001 Mpeg7-2001.xsd">
<Description xsi:type="ContentEntityType">
<MultimediaContent xsi:type="VideoType">
<Video>
<TemporalDecomposition>
<VideoSegment>
</TemporalDecomposition>
</Video>
</MultimediaContent>
</Description>
</Mpeg7>
<VideoSegment>
<TextAnnotation type="scene" relevance="1" confidence="1">
<FreeTextAnnotation>飯店</FreeTextAnnotation>
<FreeTextAnnotation>景觀設施</FreeTextAnnotation>
<FreeTextAnnotation>景點介紹</FreeTextAnnotation>
<FreeTextAnnotation>三峽溫泉飯店</FreeTextAnnotation>
</TextAnnotation>
<MediaTime>
<MediaTimePoint>T00:00:28:11851F30000</MediaTimePoint>
<MediaIncrDuration mediaTimeUnit="PT1001N30000F">299</MediaIncrDuration>
</MediaTime>
<TemporalDecomposition>
<VideoSegment>
<MediaTime>
<MediaTimePoint>T00:00:33:11000F30000</MediaTimePoint>
</MediaTime>
</VideoSegment>
</TemporalDecomposition>
VideoSegment>
11
DB Server
自動
檢索
影片 Tom Server
Stream Se Server
檢索、查尋、瀏覽
播放(Player)
HTTP
RTP
勾選的動作。一方面可以針對不同類型的影片預設不同的場景描述值，此外也可以節省影片管理
者手動填入描述值的時間並可以減少對於影片畫面內容主觀判斷的誤差。
4.2 On-Line 系統
在此部份的系統基本架構如圖 4.9 所示，以下將針對各部份進行說明。
圖 4.9 線上檢視查詢介面
在本系統主要以一般個人電腦及 PDA 作為測試的使用者端設備，網頁伺服器為系統的主要
元件，其主要為提供圖形化的操作介面供使用者進行影片的檢索及瀏覽，負責整個系統的運作，
包括回應瀏覽器查詢等動作，並且需要與串流伺服器進行溝通聯繫，以提供影片播放的服務。本
系統主要為架構在 Microsoft Windows XP Professional+ IIS 5.0 的伺服器平臺。系統網頁程式
語言則使用 ASP .NET 搭配 Microsoft .NET Framework 1.1 來完成前端使用者介面的產生。
4.3 行動端 Stream System 架構設計
如圖4.7 所示。Client端的使用者，透過Internet Explorer向Tomcat Server界面，執行瀏覽、
查尋、要求等命令至Server端，在此溝通的程式則是使用JSP語言相容於Tomcat Server，以HTTP
通訊協定為傳輸協定。當Server端的Tomcat Server接收到使用者的命令，則會立即執行相對應
的Servlet程式向DB Server執行請求的命令，並且呈現至「自動檢索影片系統」，使用者則可
以選擇觀賞的影音，再經由Stream Server傳送影片至Client端的播放器。
圖 4.10 串流架構
五、實驗說明
5.1 台灣老街線上多媒體百科雛形
應用上述靜態影像及動態視訊的多媒體壓縮及檢索技術，以台灣老街為主題所建置的多媒體
13
Client 端之程式設計，增強易用性與跨平台的特性。行動端系統硬體平台與作業系統規劃如下：
Stream Server Client PDA
硬
體
中央處理器：Intel Pentium 4HT, 3.06 GHz
記憶體：8GB DDR800
儲存空間：SATA 120GMB
處理器：Intel® PXA270 416MHz
記憶體：64/RAM 128/ROM
軟
體
作業系統：Windows Server 2003 Enterprise Edition
伺服器軟體：Windows Media Streaming Server 9.0
網頁伺服器軟體：Apache Tomcat 5.5
作業系統：Microsoft® Windows
Mobile® 5.0
應用軟體：iPAQ 無線； Java 語言
本研究設計之 Client 程式，不需要針對 Client 的硬體直接控制，只針對軟體的支援有特別的
要求。程式碼的執行都在 Server 端，故在 Client 端則必須建構可執行的環境。虛擬機器的佈署：
1. WebSphereStudio Device Developer 安裝於 PC 2. 於\wsdd\ive\runtimes\ 下尋找欲佈置 virtual
machine 的平台 3. 選擇適當的處理器，將底下的所有東西複製到 pocket pc。Bin 底下為 virtual
machine 的 binary 檔包括 VM 的 console 等；lib 為 MIDP 所需要的 class 檔案。4. 佈署複製的
virtual machine（J9）到 Pocket PC 下的 WSDD5. 佈署自己的應用程式到 Pocket PC。[註 30]為達
成在不同行動裝置上皆可執行的跨平台目標，本專案選擇使用 JAVA 實作。JAVA code 可以跨平
台，其特性在於作業系統與應用程式之間加了一層 VM（Virtual machine）與 Bytecode。Sun 將
JAVA 針對不同領域分成 4 個版本[參考資料:JAVA, http://java.sun.com]：
1. J2EE：定位在伺服端的應用。除了完全支援核心函式，還有許多關於伺服端的套件。
2. J2SE：定位在個人電腦上的應用。這個版本也是JAVA 平台的核心。
3. J2ME：定位在消費性電子產品上。這個版本針對那些資源有限的裝置而精簡了核心的函式庫。
4. JAVA card：定位在智慧卡的應用。將 VM 內嵌在卡片上，使卡片能夠透過讀卡機來執行 JAVA
程式。
圖 5.6 JAVA平台核心
本專案所採用 J2ME 核心，其特性在 VM 有兩個概念-「Configuration」與「Profile」。針對
不同硬體特性的產品則有不同的設計規格。Configuration 是針對於硬體的運算能力、儲存容量、
網路能力來區分。目前是分為兩種：CDC（Connected Device Configuration）和 CLDC（Connected
Limited Device Configuration），前者對於硬體的支援較大，後者則是涵蓋一般個人行動裝置，
如手機與 PDA。Profile 則是一組延伸的 API，針對不同的應用類型提供對應的 API。為了滿足
硬體的規格，VM 必須要有適當的修改，因此在 J2ME 的平台拿掉了部分的核心，例如不支援浮
點運算、有限的錯誤處理能力等。開發廠商也有針對各自開發的 JAVA 行動裝置開發套件，但
是使用這些套件，將會造成程式無法跨平台到不同的手機或是 PDA 上。目前的 JAVA 手機與
PDA 上面的 VM 都符合 MIDP 1.0 的規定，我們的程式可以運作在任何支援 JAVA 標準的手機
與 PDA 上。本研究在播放器的實作上，考量到跨不同平台的特性，故採用兩種不同方式來呈現，
以應對不同的行動端在支援上的不足。因此，本研究將以 Microsoft® Windows Mobile® 5.0 支援
的 Windows Media Player 為其一。另外，因應不同的平台，則在 Client 端上撰寫播放程式，以 Java
語言來實作。而使用者可依硬體支援上的需求與限制，採用以上兩種作法之其一。 Server-Client
之間的影音串流服務，則採用 RTSP(Real Time Streaming Protocol)、RTP(real-time transport protocol)
與 RTCP(RTP Control Protocol)協定。而網頁伺服器則採用 HTTP 協定，透過 Internet Explorer 提
15
回收率=
準確率=
 實驗影片的內容如下：
挑選三段 10 分鐘左右的紀錄型影片，分別挑選該影片所出現鏡頭中的一位人物及一項物品
的畫面進行 QBE 方式查詢，並紀錄其回收率與正確率。
編號 1：鹿港老街遊覽，長度 9 分 40 秒，（Mpeg-1 352*240 29.97fps）。
查詢值: 人物 （主持人） ； 物品 （蝦蛄）
編號 2：士林夜市遊覽，長度 9 分 59 秒，（Mpeg-1 352*240 29.97fps）。
查詢值: 人物 （主持人） ； 物品 （彈珠檯）
編號 3：鶯歌老街遊覽，長度 11 分 06 秒，（Mpeg-1 352*240 29.97fps）。
查詢值: 人物 （主持人） ； 物品 （陶瓷）
圖 6.1 查詢結果
 實驗結果數據如下：
表 6.1 回收率與正確率
正確偵測到的數量
正確偵測到的數量 ＋漏判的數量
正確偵測到的數量
正確偵測到的數量 ＋誤判的數量
× 100 ％
× 100 ％
17
利用自動化的場景分割技術可以節省傳統以人工判斷場景(包含分割和檢查)約 2/3 的時間。
（以 5 分鐘的實驗影片為例，處理時間約為 8~10 分鐘）
 MPEG-7針對特徵値描述的分層機制可允許在不同的抽象級別上描述多媒體內容。許多低階
特徵可利用電腦程式全自動地擷取，而高階特徵則需要更多的人工交互。另外，還可以從不
同的應用需求角度來描述媒體資料，例如從子對象的角度、運動分析的序列角度、視頻的情
節架構等角度來描述多媒體內容。本專案另以人工編輯影片片段後設資料作為電腦自動化特
徵値分析的輔助，可彌補使用者在以文字或圖像做為檢索關鍵値所產生的語義層面的誤差。
 使用者可以透過影片索引表的瀏覽，快速的揀選出感興趣和欲播放的片段，可以減少等待影
片下載的時間，應用在隨選視訊或影音教學的服務上可以讓使用者在有限的時間內收看到符
合需求的電影或教學影片片段。
 藉由 ASP.NET 結合多媒體資料庫的動態網頁呈現，使用者可以依個人的需求輸入檢索値透
過伺服器自動產生合適的資料瀏覽頁面，增加了隨選影音服務網站的互動性和活潑性。
 結合 JPEG 2000 漸進傳輸和感興趣區域的兩大優點，可以解決許多原先不能解決的問題。例
如，醫學和航空遙測的圖片通常比一般圖片擁有龐大的資料量，雖然透過壓縮可以減少資料
傳輸所需的頻寬和時間，但是基於應用上的需求，希望能做到無損壓縮，這樣才能不受到失
真和雜訊點的影響而做出錯誤的診斷和判別。而透過感興趣區域的選取，可以讓使用者主觀
的決定針對圖像重要的區域做較小的壓縮率，而對於不重要的區域進行較特定比率的壓縮編
碼來減少圖像檔案的資料傳輸量。
 目前無論是廣電媒體或是影音網站所提供的影片瀏覽服務皆是以整部影片為單位，使用者必
須快轉或倒轉才能快速觀賞到所需的影片片段，透過互動式的數位電視服務或是動態資料庫
網頁的互動呈現，使用者將可以更便利的觀賞所需的影片內容，在影片創作者的部份也可以
製作多主軸劇情和多視角的數位影片，藉由開發更便利的電視選單或影片內容索引頁面增加
影音加值服務的活潑性和互動性。
【計畫成果自評】
 感謝國科會支持本項專題研究計畫之執行，使本研究可以順利進行。
 本專題研究成功完成下列研究：(一) 視訊壓縮域與非壓縮域特徵抽取、場景偵測、關鍵影
格抽取、場景匹配搜尋、MPEG-7 metadata 建制、PDA HCI 等技術；(二) 利用上述技術實
際建置一套無線手持式(PDA)線上多媒體百科全書雛型系統以作為 testbed，並研究最佳之百
科全書資訊無線傳播方法。現階段，我們的研究正設法應用於行動數位學習，而研究方向包
括 semantic 意涵式分析、多媒體行動平台調適(adaptive)技術、多媒體數位學習評量機制等
等。
 本計畫研究期間，除獲得一項檢索資料庫的專利(專利號碼 220483)外，並獲邀完成一篇 book
chapter，出版於美國 Idea Group Publishing 的專書“Multimedia Systems and Content-Based
Image Retrieval”，主題為”Object-Based Video Analysis and Interpretation。此外，投稿兩篇期
刊論文及發表數篇會議論文。
 本專題在有限的經費與時間之下，終能達成預定目標，未臻圓滿之處，來年加倍努力以求精
益求精。
