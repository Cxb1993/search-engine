應用類神經網路與支援向量機建構多變量管制圖 
非隨機樣式之辨識系統 
 
計畫編號：NSC 96-2221-E-155-036 
執行期間：96 年 08 月 01 日至 97 年 07 月 31 日 
計畫主持人：鄭春生 教授    元智大學工業工程與管理系 
 
一、中文摘要 
 
單 變 量 蕭 華 特 管 制 法  (univariate 
Shewhart control chart) 常被用來診斷製程中
是否存在可歸屬原因所造成之變異。管制圖
呈現之特定非隨機樣式有趨勢樣式、偏移樣
式、混合樣式與週期性樣式等。在某些製程
中，我們必須使用多變量管制圖 (multivariate 
control chart) 來同時監控數個彼此間具有相
關性之品質特性。正確辨識出多變量非隨機
樣式，將可縮小判斷製程可歸屬原因之範
圍，對於規劃改善對策有所助益。 
本研究之目的是使用類神經網路與支援
向量機，建構偵測與辨識多變量管制圖中之
非隨機樣式的辨識系統。研究結果顯示類神
經網路與支援向量機之辨識績效並無明顯差
異，但皆較傳統多變量區別分析為佳。 
本研究亦提出兩種不同方式之辨識程
序，用以改善非隨機樣式分類之效益。實驗
結果顯示，本研究所提出之程序二可以對非
隨機樣式有更佳之辨識能力。 
 
關鍵字：非隨機樣式、多變量製程管制、類
神經網路、支援向量機、區別分析 
 
Multivariate Control Chart Pattern 
Recognition using Artificial Neural 
Network and Support Vector 
Machine 
Abstract 
In the past, univariate Shewhart control 
charts have been widely used to determine 
whether assignable causes of process variation 
are presented. Control chart pattern recognition 
is an important aspect in the application of 
control charts. 
A recent research indicated that unnatural 
patterns may also occur in multivariate control 
charts. The purpose of this research was to 
investigate the feasibility of applying statistical 
learning algorithms for multivariate control 
chart pattern recognition. In this research, we 
considered two recognizers based on artificial 
neural network (ANN) and support vector 
machine (SVM). Furthermore, we used 
discriminant analysis as a baseline for 
comparison. The results showed that the 
performances of ANN and SVM were similar 
in classifying patterns of multivariate control 
charts. Both ANN and SVM can perform 
significantly better than discriminant analysis. 
In addition, two procedures were developed 
and compared in this research. Results from our 
experiment showed that the second procedure 
performed better than the first procedure. 
 
Keywords: unnatural patterns, multivariate 
process control, artificial neural 
network, support vector machine, 
discriminant analysis 
 
二、緒論 
 
傳統的單變量蕭華特管制法 (univariate 
Shewhart control chart) 常被用來監控製程，
藉由分析品質特性 (或稱為變量) 之數據，推
論並判斷在製程中是否存在可歸屬原因 
(assignable causes)。利用管制圖監控製程，可
以在瑕疵或不良品出現之前，先行發現製程
的異常並加以矯正。當製程受到可歸屬原因
之 影 響 時 ， 我 們 稱 製 程 處 於 管 制 外 
(out-of-control)。此時管制統計量會超出管制
界限，或者統計量會呈現非隨機之樣式 
(nonrandom pattern)。一些非隨機樣式常出現
在單變量的蕭華特管制圖中。依據美國 
Western Electric Company [19] 之定義，這些
非隨機樣式大致可分為：上升或下降趨勢樣
式 (increasing trend and decreasing trend)、偏
 3
但上述輔助測試法則並無法明確指出管制圖
存在何種非隨機樣式，而且使用過多的輔助
法則也會導致型Ⅰ誤差增加 [4]。 
過去學者較少探究在多變量管制圖中出
現之非隨機樣式。Mason 等學者  [10] 認
為，具有相關性之個別單變量管制圖所出現
的非隨機樣式透過多變量 2T 統計量的計算
後依然會呈現特定之非隨機樣式。根據他們
的研究結果， 2T 管制圖中的統計量也會出現
非隨機樣式之特徵。 
 
表1 多變量 2T 管制圖之非隨機樣式 
數據之狀態 出現在 2T 管制圖之非隨機樣式 
趨勢樣式 2T 統計量呈現上升或下降之趨勢 
偏移樣式 2T 統計量呈現分離的群集 
混合樣式 2T 統計量會在管制下限 0 以上呈現群集 
週期樣式 呈現重複之 U 型 
資料來源：Mason et al. [10] 
 
3.2 類神經網路偵測管制圖非隨機性樣式之
應用 
 
類神經網路應用之發展過程中，監督式 
(supervised) 的網路為最常用之方法。監督式
網路之學習乃是透過訓練的過程去辨認非隨
機樣式，而這些樣式之製程數據最好是來自
於實際的製程。但由於實務上搜集數據之困
難度，一般的作法是以預先定義之數學模型
模擬產生訓練樣本，並將訓練樣本的非隨機
樣式類別假設為已知的，以訓練監督式之網
路架構。Zorriassatine 和 Tannock [20] 回顧
了類神經網路應用於統計製程管制之相關研
究，並探討與彙整這些研究中所使用之網路
架構與相關參數之設定。其他類似的研究詳
見於相關文獻 (Cheng [1]; Guh and Tannock 
[4]; Guh and Hsieh [5]; Jang et al. [8]) 之成
果。而除了應用於非隨機樣式之辨識外，類
神經網路也會被使用於估計非隨機樣式之參
數 (Guh and Tannock [3])。 
 
3.3 支援向量機偵測管制圖非隨機性樣式之
應用 
 
支援向量機在處理分類問題時，是透過
一轉換過程將資料映射至高維度的空間中，
再使用超平面  (hyperplane) 進行分割。因
此，對於某些資料維度較高、較為複雜的問
題，支援向量機都能表現出很好的績效。 
在偵測製程平均值偏移的研究中，
Chinnam [2] 將支援向量機與傳統的機器學
習進行比較，並且針對具有相關性及非相關
性之製程進行探討。研究結果顯示支援向量
機即使是使用最簡單的轉換函數，對於製程
偏移之辨識能力還是很好。將辨識績效和傳
統的機器學習法則以及蕭華特管制法相比，
支援向量機都呈現較佳之結果。 
此外，支援向量機於管制圖非隨機樣式
辨識之相關應用，Rodrigues 等學者 [15] 在
研究中針對具有時間序列 (time series) 關係
之數據樣式進行特徵值的擷取，並且使用支
援向量機進行分類。研究中所使用之資料組
包含了管制圖的非隨機樣式數據  (趨勢樣
式、偏移樣式與週期樣式等)，並透過支援向
量機中不同之核心函數進行分類實驗。 
 
三、研究方法 
 
3.1 多變量統計製程管制法 
 
根據 Montgomery [12] 所討論之多變量
製程管制方法，假設有隨機之多變量樣本
nxxx ,,, 21 K ，其中第 i組樣本向量包含 p 個變
量，分別為 ipii xxx ,,, 21 K 。則該組樣本之平均
值向量可以被表達為： 
 
∑
=
=
n
i
in 1
1 xx  (1) 
 
樣本之共變異數矩陣為： 
 
∑
=
−−−=
n
i
iin 11
1 )'x)(xx(xS  (2) 
 
我們可透過樣本平均值向量與共變異數矩
陣，得到母體之不偏估計量 μx =)(E ，
ΣS =)(E 。 
因此，在具有 p 個品質特性之多變量製
程，若其聯合機率為一常態分配，平均值向
量為 ],,,,[' 321 pxxxx K=x ，其中 n 為組樣本
數。若已知管制內之製程平均值向量為μ、
共變異數矩陣為Σ。透過 2χ 管制法程序，則
 5
會越大。所以∑
=
N
i
i
1
ξ 越小代表分類結果越佳。
懲罰因子C 可以依照分類錯誤之嚴重性來取
決。當C 值越大，表示錯誤發生對目標函數
的影響越大。因此，決定C 時必須在對邊界
最大化，以及可接受的錯誤率之間進行取
捨。此外，還必須避免選擇過大的懲罰因子
C ，而造成過度學習的效果發生。 
Tan 等學者 [17] 指出，可以透過一種核
心轉換之技巧 (kernel trick)，將低維度空間
所無法線性分割之資料，映射至高維度的特
徵空間。因此，式 (5) 中之φ即為非線性之
轉換函數。此函數之作用在於將輸入向量映
射至高維度之特徵空間，而此轉換函數稱作
核心函數 (kernel function )，一般較常使用之
核心函數有下列四種： 
 
0 ),tanh(),(kernel sigmoid
0 },||||exp{),(kernelfunction  basis radial
0 ,)(),(  degree of kernel polynomial
),(kernellinear 
2
>+=
>−−=
>+=
=
γγ
γγ
γγ
rK
K
rKd
K
jiji
jiji
d
jiji
jiji
xxxx
xxxx
xxxx
xxxx
(6) 
 
上式中之 γ 、 r 與 d 為各核心函數之參
數。 
 
3.4 區別分析 
 
區別分析 (discriminant analysis, DA) 為
多變量分析中常被使用的方法之一。根據 
Johnson 與 Wichern 之著作 [9] 中指出，區
別分析主要是將可被分別之觀測資料組進行
區別，並定義出屬於各分類群之判斷準則。
而新的資料組則能夠依循準則被歸屬類別。 
Johnson 與 Wichern [9] 並進一步指出
使用區別分析，其最主要目標包含兩大項：
第一要務是針對從觀測資料組中所蒐集到的
各項特徵值，找到能夠敘述 (可應用圖形或
代數) 的方法，這些特徵值應儘可能地達到
「區別」的目的。其次，將觀測資料組給予
分類別 (或分類名稱)，此步驟主要在於推導
出一個能夠描述分類之準則。而新的觀測資
料將透過此一準則，判斷出歸屬於各個類別
之可能機率，此準則稱之為區別函數 
(discriminant function)。 
區別函數最大的目的在於判別觀測資料
歸屬於各群組之機率，而此機率稱為驗後機
率 (posterior probability)。為了要得到驗後機
率，我們必須給定已知的驗前機率  (prior 
probability)，並計算觀測資料與群組中心之
馬氏距離 (Mahalanobis distance)，以得到各
個分類群組之區別函數。本研究之區別分析
使用 Minitab [11] 軟體進行非隨機樣式之分
類。 
 
四、非隨機樣式之辨識系統 
 
以下說明數據之模擬方式，訓練及測試
樣本數量、程序架構、偵測流程與參數設定。 
 
4.1 訓練樣本之產生 
 
本研究將採用蒙地卡羅模擬法 (Monte 
Carlo) 產生非隨機樣式，作為類神經網路與
支援向量機之訓練樣本。對於單變量而言，
任何一個統計製程管制之樣式可以使用下列
數學通式加以表達： 
 
)()()( tdtntx ++= μ  (7) 
 
其中 μ 代表製程之平均值， )(tn 表示機遇原
因所造成之變異， )(td 則代表可歸屬原因 
(非隨機樣式) 所造成之變異。訓練樣本必須
包含各種樣式之不同變異程度的數據，以獲
得較佳之辨識效果。在本研究中，各樣式之
訓練樣本個數均為相同。 
 
表 2 各樣式之參數設定 
樣式類型 參數範圍 參數說明 
趨勢型樣式 (0.10, 0.125, 0.15) 斜率 
偏移型樣式 (1.5, 2.0, 3.0) 離平均值之距離
混合型樣式 (2.0, 2.5, 3.0) 離平均值之距離
週期型樣式 (1.5, 2.0, 3.0) 振幅 ( 16=Ω ) 
 
在模擬數據時必須考慮製程中不同變量之相
關性程度。我們先將各個變量之製程數據標
準化，使得這些變量之平均值為 0，標準差
為 1。此時共變異數矩陣 Σ為一關連形式 
(correlation form)，在該矩陣主對角線上之值
皆為 1，而非主對角線之值則為不同變量間
之成對相關係數 ρ  (Montgomery [12])。將多
變量之非隨機樣式數據模擬出以後，可以透
過計算得到統計量 2T 值。所產生之 2T 值則為
偵測多變量非隨機樣式之輸入向量。 
 
 7
達到 10000 次或目標錯誤率小於 0.001 則
停止訓練。 
SVM-2 亦為使用兩個支援向量機以建
構二階段之系統。在研究中分別以 SVM-2(a) 
與  SVM-2(b) 來 進 行 表 達 。 階 段 一 之 
SVM-2(a) 用來判別資料屬於正常樣式或非
隨機樣式，以 0 代表正常數據，以 1 代表
非隨機樣式數據。階段二之 SVM-2(b) 則是
將第一階段所判定之非隨機樣式資料進行分
類。SVM-2 亦是以 RBF 作為核心函數，各
階段之核心函數 03125.0=γ 、懲罰因子
10=C ，學習停止條件同 SVM-1。 
 
五、結果與討論 
 
為評估類神經網路與支援向量機之辨識
績效，本研究以辨識出非隨機樣式之正確率 
(accuracy) 作為效益指標。 
 
%100Accuracy ×+= 錯誤分類筆數正確分類筆數
正確分類筆數  (8) 
 
5.1 辨識程序一之測試結果 
 
表 3 與表 4 彙整在辨識程序一，
ANN-1、SVM-1 與傳統多變量區別分析所得
到之非隨機樣式辨識率平均值 (包含正常數
據之 5 類平均)。 
 
表3 平均辨識率比較  (程序一， 0>ρ ，
2=p ，一變量呈非隨機樣式) 
 分類法 ρ  ANN-1 SVM-1 DA 
0.1 93.13 / 93.20 93.22 / 93.15 88.65 / 88.31
0.3 94.30 / 94.47 94.36 / 94.50 89.75 / 89.89
0.5 96.58 / 96.51 96.81 / 96.53 93.60 / 92.70
0.7 98.89 / 98.95 98.96 / 99.00 96.99 / 96.81
0.9 99.99 / 99.98 99.99 / 99.99 99.51 / 99.45
 
表4 平均辨識率比較  (程序一， 0>ρ ，
2=p ，二變量呈非隨機樣式) 
 分類法 ρ  ANN-1 SVM-1 DA 
0.1 98.83 / 98.61 98.85 / 98.66 96.69 / 96.10
0.3 97.89 / 97.56 97.97 / 97.58 95.11 / 94.55
0.5 96.87 / 96.50 96.79 / 96.56 93.28 / 92.81
0.7 95.29 / 95.19 95.47 / 95.19 91.06 / 90.81
0.9 94.28 / 93.83 94.35 / 93.76 89.45 / 88.86
 
從表3 可知，當其中一個變量出現非隨
機樣式，而另一個變量為管制內之隨機樣式
時，區別分析、ANN與SVM之辨識率皆隨著
ρ 而呈現遞增之現象。從表4 可觀察出當兩
個變量同時出現非隨機樣式且其參數相同
時，三種辨識方法則隨著 ρ 呈現遞減的現象。 
在兩個變量負相關的辨識率部份，表5 
及表6 所呈現為ANN、SVM與區別分析之差
異。表5 為單一變量出現非隨機樣式，可觀
察出三種不同的方法都會隨著負相關程度的
增強，而使辨識率增加。表6 是兩個變量同
時出現非隨機樣式，其辨識率亦隨著負相關
程度而增加。比較表5 與表6 之結果，亦可
發現兩個變量同時出現負相關之非隨機樣
式，其辨識率皆高於僅有一個變量出現非隨
機樣式之情形。在不同方法的比較上，ANN
和SVM之辨識結果相近，而平均辨識績效都
較傳統的區別分析高。 
 
表5 平均辨識率比較  (程序一， 0<ρ ，
2=p ，一變量呈非隨機樣式) 
 分類法 ρ  ANN-1 SVM-1 DA 
1.0− 93.27 / 93.10 93.23 / 93.16 88.67 / 88.24
3.0− 94.43 / 94.33 94.35 / 94.34 90.02 / 89.75
5.0− 96.65 / 96.37 96.62 / 96.34 93.54 / 92.66
7.0− 98.81 / 98.99 98.95 / 99.07 97.19 / 96.81
9.0− 99.98 / 99.99 99.99 / 99.99 99.52 / 99.48
 
表6 平均辨識率比較  (程序一， 0<ρ ，
2=p ，二變量呈非隨機樣式) 
 分類法 ρ  ANN-1 SVM-1 DA 
1.0− 099.35 /099.22 099.31 /099.30 97.83 / 97.55
3.0− 099.71 /099.77 099.77 /099.83 98.72 / 98.56
5.0− 099.95 /099.93 099.98 /099.97 99.28 / 99.13
7.0− 100.00 /099.99 100.00 /099.99 99.64 / 99.62
9.0− 100.00 /100.00 100.00 /100.00 99.95 / 99.87
 
在三個變量的研究中，則考慮了三種不
同的情況。表7 至表9 分別為單一變量、兩
個變量與三個變量出現非隨機樣式時，不同
分類方法所得到的平均辨識率結果。 
 
表7 平均辨識率比較  (程序一， 0>ρ ，
3=p ，一變量呈非隨機樣式) 
 分類法 ρ  ANN-1 SVM-1 DA 
0.1 91.41 / 91.37 091.53 /091.43 86.51 / 85.86
0.3 93.71 / 93.47 093.75 /093.48 89.17 / 88.65
0.5 96.64 / 96.42 096.64 /096.43 93.27 / 92.93
0.7 99.17 / 99.15 099.28 /099.24 97.69 / 97.51
0.9 99.99 / 99.99 100.00 /100.00 99.73 / 99.70
 
 9
隨著相關係數 ρ 而有所不同。而經由實驗
結果也證實 2T 值隨著 ρ值的改變，確實會
影響辨識績效。 
3. 使用辨識程序二之兩階段偵測方式，ANN
與SVM可在固定相同之正常數據辨識率
下，有效改善非隨機樣式被誤判至正常數
據之情況，進而提升辨識率。 
本研究建議未來研究之發展如下： 
1. 其他樣式之選擇：本研究是針對趨勢、偏
移、混合與週期等四種非隨機樣式進行辨
識，而後續研究可考慮加入其他類別之非
隨機樣式。 
2. 變量之自我相關性 (autocorrelation)：本研
究僅考慮了變量之間彼此的相關性，未來
的研究可以深入探討個別變量之自我相關
性，建立出具自我相關之多變量非隨機樣
式辨識系統。 
 
七、參考文獻 
 
1. Cheng, C. S., “A neural network approach 
for the analysis of control chart patterns,” 
International Journal of Production 
Research, 35, 3, 667-697 (1997). 
2. Chinnam, R. B., “Support vector machines 
for recognizing shifts in correlated and 
other manufacturing processes,” 
International Journal of Production 
Research, 40, 4449-4466 (2002). 
3. Guh, R. S., and Tannock, J. D. T., “A neural 
network approach to characterize pattern 
parameters in process control charts,” 
Journal of Intelligent Manufacturing, 10, 
449-462 (1999a). 
4. Guh, R. S., and Tannock, J. D. T., 
“Recognition of control chart concurrent 
patterns using a neural network approach,” 
International Journal of Production 
Research, 37, 1743-1765 (1999b). 
5. Guh, R. S., and Hsieh, Y. C., “A neural 
network based model for abnormal pattern 
recognition of control charts,” Computers 
& Industrial Engineering, 36, 97-108 
(1999). 
6. Hotelling, H., “Multivariate quality 
control-illustrated by the air testing of 
sample bombsights,” in Techniques of 
Statistical Analysis, eds. C. Eisenhart, M. W, 
Hastay and W. A. Wallis, New York : 
McGraw –Hill, 111-184, (1947). 
7. Hsu, C. W., and Lin, C. J., “A comparison 
of methods for multiclass support vector 
machines,” IEEE Transactions on Neural 
Networks, 13, 415-425 (2002). 
8. Jang, K. Y., Yang, K., and Kang, C., 
“Application of artificial neural network to 
identify non-random variation pattern on 
the run chart in automotive assembly 
process,” International Journal of 
Production Research, 41, 6, 1239-1254 
(2003). 
9. Johnson, R. A., and Wichern, D. W., 
Applied Multivariate Statistical Analysis, 
Prentice Hall, NJ (2002). 
10. Mason, R. L., Chou, Y. M., Sullivan, J. H., 
Stoumbos, Z. G., and Young, J. C., 
“Systematic patterns in 2T  charts,” 
Journal of Quality Technology, 35, 1, 47-58 
(2003). 
11. Minitab. Minitab 14.0 User’s Guide. 
Minitab Inc (2004). 
12. Montgomery, D. C., Introduction to 
Statistical Quality Control, Wiley, New 
York (2005). 
13. Nelson, L. S., “The Shewhart control 
chart-tests for special cause,” Journal of 
Quality Technology, 16, 4, 237-239 (1984). 
14. NeuralWorks Professional II/Plus. Neural 
Computing: A Technology Handbook for 
Professional II/Plus and NeuralWorks 
Explorer. Pittsburgh: NeuralWare, Inc 
(1997). 
15. Rodriguez, J. J., Alonso, C. J., and Maestro, 
J. A., “Support vector machines of 
interval-based features for time series 
classification,” Knowledge-Based Systems, 
18, 171-178 (2005). 
16. STATISTICA. Statistica Data Miner. OK: 
Stat Soft, Inc (2005). 
17. Tan, P. N., Steinbach, M., and Kumar, V., 
Introduction to Data Mining, 
Addison-Wesley, Boston (2006). 
18. Vapnik, V. N., The Nature of Statistical 
Learning Theory, Springer, New York 
(2000). 
19. Western Electric Company, Statistical 
Quality Control Handbook, Western 
Electric Co. Inc., Indianapolis (1958). 
20. Zorriassatine, F., and Tannock, J. D. T., “A 
review of neural networks for statistical 
process control,” Journal of Intelligent 
Manufacturing, 9, 209-224 (1998). 
 2
研討會之議程概述如下： 
2007/10/17上午：Registration, Opening of The 5th Asian Quality Congress, Keynote 
Speech. 
 Keynote Speech 1: Overcome the crisis through innovation and 
change. 
 Keynote Speech 2: Customer Satisfaction: impact of country cultural 
differences and economic fluctuation. 
 Keynote Speech 3: The EOQ actual role in globalizing world. 
 Keynote Speech 4: Toray Sarhan Inc.’s achievement and quality 
management as a Korean-Japanese joint venture company. 
2007/10/17下午：Paper Presentation. 
2007/10/18全天：Paper Presentation 
    Keynote Speech 5: Case study of quality innovation in K-water . 
  Keynote Speech 6: Data technology and future development of Six 
Sigma. 
    Keynote Speech 7: China’s quality under globalized environment. 
    Keynote Speech 8: Quality Prize and its evaluation methods. 
    Farewell Dinner. 
2006/10/19上午：Optional Tour 
    1. Industrial Visiting 
    2. Seoul City Tour. 
與會心得 
 
此次研討會是由 ANQ 亞洲品質網絡組織所主辦，該組織成員來自於台灣、新
加坡、韓國、日本、香港、印度、泰國、伊朗…等各國之品管學會。由於參與者皆
為學術界與企業界在品管領域的菁英，因此，在會場有許多學習觀摩的對象與經驗
交流的機會。成立 ANQ 之目的主要為連結亞洲所有的品管學會與品管相關領域的
學者成為一個品質網絡，並且藉由網絡將其研究成果進行交流，因此特別舉辦 ANQ
研討會將這些成果具體的發表與分享。會中有幸與這些品管界的同好交流，包括中
華民國品質學會前理事長王治瀚先生、上任理事長盧淵源教授、現任理事長張文貴
教授、ANQ 秘書長曹志毅先生、品質學會陳寬仁教授、元智大學范書愷教授、亞
洲大學三位教授、ANQ Honorary Chairperson Dr. Noriaki Kano 以及東京大學 Dr. 
Yoshinori IIZUKA等人，大家的共同目標就是將品質管理的知識推展到世界各地。
 
攜回資料名稱及內容： 
 1. 研討會議程及論文摘要 
 2. 研討會論文集光碟 
 
 4
control chart. Mason et al. [5] indicated that many different systematic patterns may occur on multivariate control 
charts. The major drawback of most multivariate control chart procedures is that they do not directly tell which 
unnatural pattern really occurs. In order to address this issue, we propose a support vector machine approach for 
recognizing unnatural patterns in multivariate processes. The SVM has been introduced as a new technique for 
solving a variety of learning, classification and prediction problems. There is also some research on using support 
vector machines to monitor process variation [6-7]. 
2 Reviews of Control Chart Pattern Recognition 
2.1 Unnatural Patterns in Multivariate Processes 
In practice, there are many unnatural patterns that may appear in industrial processes indicating out-of-control 
conditions. The typical unnatural patterns on control charts include trends, sudden shifts, mixtures, cyclic patterns, 
and systematic variation. A complete description of these unnatural patterns on control charts can be found in the 
Statistical Quality Control Handbook [1]. The most familiar multivariate processes monitoring and control procedure 
is the Hotelling 2T chart for monitoring the mean vector of the processes. However, a recent study [5] indicated that 
unnatural patterns may appear on multivariate control charts. Fig. 1 depicts a sudden shift on control charts in a 
bivariate process with correlation coefficient ρ =0.5. Mason et al. [5] have proposed some visual methods to 
recognize patterns that occur in 2T chart as summarized in Table 1. 
X1
32241681
6
3
0
-3
-6
_
X
UCL
LCL
X2
32241681
6
3
0
-3
-6
_
X
UCL
LCL
Ts
qu
ar
ed
32241681
24
18
12
6
0
UCL
 
Fig. 1. A sudden shift in a bivariate process ( ρ =0.5) 
Table 1. Patterns associated with a 2T chart 
Pattern type Pattern that occurs in 2T  chart 
Trends 2T values trend upward/downward
Sudden shifts Distinct groupings of 2T values
Mixtures 2T values clustered above zero line
Cyclic patterns Repeated U shape (short period) 
Note: from [5]. 
2.2 Applications of Classification Techniques in Multivariate Processes 
In the last few years, many researchers have investigated the application of artificial neural networks to multivariate 
statistical process control. Wang and Chen [6] developed a neural-fuzzy model not only to identify mean shifts but 
also to classify their magnitudes. Chen and Wang [7] also proposed a neural network approach for monitoring and 
classifying the mean shifts of multivariate process. Low et al. [8] presented a neural network procedure for detecting 
variance shifts in a multivariate process. Zorriassatine et al. [9] applied a neural network classification technique 
known as novelty detection to monitor multivariate process mean and variance. Guh [10] designed a neural 
network-based model consists of two sequential modules that can identify and quantify the mean shifts in bivariate 
processes on-line. 
In recent years, the support vector machine has been introduced as a new technique for solving a variety of 
learning, classification and prediction problems. There is also some research on using support vector machines to 
monitor process variation [11-12]. 
The main purpose of this paper is to develop an efficient method to improve recognition of control chart patterns 
in multivariate processes. We implement two classifiers based on SVM and discriminant analysis to identify 
multivariate unnatural patterns. The discriminant analysis is used as a baseline for comparison. Furthermore, we also 
 6
Note: γ , r , and d  are referred to as kernel parameters. 
The SVM was originally designed for binary classification problem. That is, the data is separated by a hyperplane 
defined by a number of support vectors. However, many real-world problems have more than two classes. 
Constructing multi-class SVM is still an on-going research issue [14]. Hsu and Lin [14] provided a comparison of 
methods for multi-class support vector machines. Basically, two types of approaches usually applied to multi-class 
classification problem in recent year. The first case, the SVM was modified in order to incorporate multi-class 
learning in the quadratic solving algorithm. That is, the SVM treat all classes at once considering only one 
optimization problem. Unfortunately, this approach can lead to a high computational cost. The second case, several 
binary SVM classifiers were combined. The one-against-all and one-against-one methods were used in the second 
case. 
The one-against-all method separates each class from all others and builds a combined classifier. For m -class 
problem, it constructs m  binary SVMs. The i th SVM is trained with all the samples in the i th class with positive 
labels 1+=y , and all the other samples with negative labels 1−=y . The decision function chooses the class of a 
sample that corresponds to the maximum value of m  binary decision functions specified by the furthest positive 
hyperplane. Thus, it uses a winner takes-all scheme. The one-against-all method is the earliest approach for 
multi-class SVM. Another method is the one-against-one which consists on a pairwise classification. The basic idea 
is to use 2/)1( −mm  binary classifiers covering all pairs of classes instead of using only m  classifiers as in the 
one-against-all. Each of the 2/)1( −mm  binary SVMs casts one vote for its favored class, and finally the class with 
most votes wins. 
3.2 Generation of Training Data Set in Multivariate Processes 
In many industrial environments, there are a number of quality characteristics that need to be monitored 
simultaneously. The most commonly used statistics is the 2χ  statistic. Suppose that the 1×p  random vectors 1X , 
2X , …., tX , each representing the quality characteristics to be monitored, are observed over time. These vectors 
represent sample mean vectors from a sample of size n . The well-known 2χ control chart is based on a measure of 
distance to the target mean vector of the process. For simplicity, it is assumed without loss of generality that the 
in-control process mean vector is 0μ == ')0 ...,0 ,0 ,0(0 . 2χ  statistic can be modeled as follows 
 )()'( 0102 μXΣμX −−= − ttt nχ  (3) 
where Σ  is a known covariance matrix. The upper limit on the control chart is UCL = 2, pαχ where 2, pαχ is the 
upper α100  percentage point of the 2χ distribution with p  degrees of freedom. When the in-control mean vector 
and covariance matrix are unknown, they are often replaced by the sample estimator, X  and S , respectively. The 
test statistic for each sample that can be written as 
 )()'( 12 XXSXX −−= − ttt nT  (4) 
In this form, the control procedure is usually called the Hotelling 2T control chart. In practice, sufficient 
training examples of unnatural patterns may not be readily available. A common approach adopted by previous 
researches was to generate training examples based on predefined mathematical model [3], [15].  
A p -dimensional multivariate normal process was simulated by generating pseudo-random variates from a 
multivariate normal distribution whose mean was μ  and whose covariance matrix was a pp×  matrix. For 
simplicity, it is assumed that the covariance matrix Σ  is known. A natural (or random) pattern will be generated by 
a general form expressed as follows: 
 tt RμX +=  (5) 
where tX  is the p  quality characteristics observed at time t , μ  represents a known process mean of the 
data series when the process is in control, tR  is the random noise at time t .  When a pattern occurs, a second 
 8
the transformed space. The choice of kernel functions is highly problem-dependent and it is the most important factor 
in support vector machine applications. In our classification task, four different kernel functions from Table 2 are 
used and compared in terms of their classification performances for the selection of kernel function. Consequently, 
the best performance is obtained with a radial basis function (RBF) and it is by far the most popular choice of kernel 
types used in support vector machines. Hence, in our implementation, we chose the RBF kernel as our kernel 
function in order to achieve better performance. 
As mentioned previously, the use of SVM involves training and testing procedures, with a particular kernel 
function, which in turn has specific kernel parameters. For RBF kernel function, the parameters must be determined 
are the kernel parameter γ  and the penalty factor C . Kernel parameter defines the structure of the high 
dimensional feature space where a maximal margin hyperplane will be found. The SVM parameters are usually 
selected through experimentation. The parameter C  controls the trade off between maximizing the margin and 
classifying the training set without error. The larger the C , the more the error is penalized. The penalty factor C  
should be chosen with caution to avoid over-fitting. In determining these two parameters, a 10-fold cross-validation 
experiment was used to choose parameters that yield the best result. That is, we divided the training set into 10 
subsets. Then, we performed the tests for the 10 runs, each with a different subset as the test set and with the union of 
the other nine subsets as the training set. The cross-validation was carried out in two stages. In the first stage, a 
search was made for an estimate of the penalty factor C  and the kernel parameter γ  that achieves the highest 
classification accuracy. In the second phase of training, the estimated values of these two parameters were used to 
train an SVM model using the entire training samples. Subsequently, this set of parameters was applied to the test 
dataset. A grid-search on C  and γ  were recommended for using cross-validation. The pairs of C  and γ  were 
tried and the one with the best cross-validation accuracy was picked in practice. In this work, values for γ  and C  
were checked in the [0.03125, 2] and [2, 40] ranges, respectively. Different parameter settings will be used for data 
with different ρ  values. In this investigation, SVM was implemented in STATISTICA software [17]. 
3.5  Two Procedures for Out-of-control Signal Detection and Classification 
In this paper, two alternative schemes are proposed to construct multivariate unnatural pattern recognizers. The first 
scheme (referred to as one-stage classification procedure) comprises an SVM-based classifier (or the discriminant 
analysis) that is designed and trained to recognize patterns in multivariate processes at a time. The training inputs 
consist of unnatural patterns and in-control data. As Fig. 2(a) indicates, the number of class m  is set to 5, i.e., 
}5,4 ,3 ,2 ,1{∈iy . 
The second scheme of classification (referred to as Two-stage classification procedure) contains two SVMs in 
series, SVM-I and SVM-II, as shown in Fig. 2(b). The SVM-I works as a detector. When an out-of-control signal is 
detected, the SVM-II classifier is employed to identify which type of unnatural pattern for the detected signal. For 
SVM-I, the output class m  is set to 2. For SVM-II classifier, the number of class m  is set to 4, representing four 
types of unnatural patterns. 
 
Fig. 2. Architectures of two procedures 
4 Results and Discussion 
4.1 Performance Evaluation 
In the evaluation process, the rate of correct classification (ROCC) was calculated. The testing samples were 
 10
accuracy. For “one errant variable only” and “two errant variables” situations, the classification accuracies improve 
as the value of ρ  increases. On the contrary, the classification performance worsens as the value of ρ  increases in 
“all three errant variables” situation. The same observations hold for discriminant analysis. 
4.3 Comparison of Different Classification Procedures 
The comparisons of classification accuracy with two alternative classification procedures are presented in this 
session. Table 5 provides the confusion matrix of classification results for “one errant variable only” situation with 
various ρ ’s. The rows in the confusion matrix represent the desired results (i.e. trend, sudden shift, mixture, cyclic 
pattern), while columns indicate the output as recognized by classifier. Entries (in boldface) along the diagonal 
indicate correct classification; while off-diagonal entries would represent that the unnatural patterns have been 
misclassified as the wrong type of classes. We can observe that there is a strong agreement between training and 
testing results, indicating no over-fitting problems with SVMs. 
Table 5. Confusion matrix of SVM with various ρ ’s for two-stage classification procedure ( p =2, one errant variable only) 
 Recognized patterns        ρ         Input patterns Trend Sudden shift Mixture Cyclic pattern 
Trend 099.97 /099.99 000.03 /000.01 000.00 /000.00 000.00 /000.00 
Sudden shift 000.00 /000.00 100.00 /100.00 000.00 /000.00 000.00 /000.00 
Mixture 000.00 /000.00 000.00 /000.00 100.00 /100.00 000.00 /000.01 
0.9 
Cyclic pattern 000.00 /000.00 000.03 /000.00 000.00 /000.00 099.97 /100.00 
Trend 095.90 /095.19 003.90 /004.69 000.20 /000.09 000.00 /000.03 
Sudden shift 002.35 /002.26 096.55 /096.64 000.00 /000.01 001.09 /001.08 
Mixture 000.03 /000.16 000.03 /000.11 098.47 /098.42 001.47 /001.31 
0.5 
Cyclic pattern 000.00 /000.03 001.85 /001.54 000.14 /000.35 098.01 /098.08 
Trend 091.73 /092.00 007.77 /007.46 000.37 /000.42 000.13 /000.12 
Sudden shift 004.10 /003.95 093.48 /093.13 000.04 /000.06 002.38 /002.86 
Mixture 000.43 /000.50 000.30 /000.31 097.13 /096.72 002.13 /002.47 
0.1 
Cyclic pattern 000.11 /000.07 002.88 /002.73 000.82 /000.91 096.20 /096.30 
Trend 092.57 /092.54 006.93 /007.01 000.27 /000.29 000.23 /000.16 
Sudden shift 003.86 /004.65 094.00 /092.59 000.07 /000.09 002.07 /002.67 
Mixture 000.53 /000.59 000.17 /000.31 097.50 /096.75 001.80 /002.35 
-0.1 
Cyclic pattern 000.14 /000.07 003.40 /002.94 001.43 /000.89 095.02 /096.10 
Trend 095.53 /094.92 004.27 /004.99 000.17 /000.07 000.03 /000.03 
Sudden shift 002.18 /002.34 096.66 /096.57 000.00 /000.02 001.16 /001.06 
Mixture 000.30 /000.12 000.07 /000.08 098.23 /098.55 001.40 /001.25 
-0.5 
Cyclic pattern 000.00 /000.01 001.17 /001.83 000.24 /000.33 098.59 /097.83 
Trend 099.97 /099.96 000.03 /000.04 000.00 /000.00 000.00 /000.00 
Sudden shift 000.00 /000.00 100.00 /100.00 000.00 /000.00 000.00 /000.00 
Mixture 000.00 /000.00 000.00 /000.00 100.00 /100.00 000.00 /000.00 
-0.9 
Cyclic pattern 000.00 /000.00 000.00 /000.00 000.00 /000.00 100.00 /100.00 
Note: (a/b) denotes (training/test). 
0.90.70.50.30.1-0.1-0.3-0.5-0.7-0.9
100
95
90
85
80
Correlation coefficient
C
la
ss
ific
at
io
n 
ac
cu
ra
cy
1-stage
2-stage
Variable
 
Fig. 4. Overall performances of SVMs for different classification procedures ( p =2, one errant variable only) 
Fig. 4 illustrates the overall performances of SVMs for two types of classification procedures in bivariate 
processes ( p =2). For “one errant variable only” case, we can observe that two-stage classification procedure of 
SVM yields better results than that of one-stage approach. As Fig. 4 indicates, the SVM-based pattern recognizer has 
the same capability in detecting different directions of ρ  changes. Table 6 summarizes the overall performances of 
SVMs for two types of procedures in multivariate processes with p =3. As we can see, the two-stage classification 
procedure performs markedly better than one-stage approach. 
