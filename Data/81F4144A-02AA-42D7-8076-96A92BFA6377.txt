based on this method. To solve this problem, the 
first year project proposes an image enhancement 
algorithm without creating depth map. 
 Histogram modification method compresses or 
stretches the histogram of an image in order to 
enhance the contrast of an image, which involves the 
difference between objects and background, the shape, 
texture, edge, and other image details. In general, 
contrast enhancement must be applied to every frame 
of a sequence, thus increasing the complexity of 
video processing applications in many display 
devices, including laptops, PDAs, monitors, mobile 
camera phones, and so on. In order to keep the 
processing effect and to reduce the processing time, 
this paper proposes a substantial histogram search 
method with linked lists to avoid generating empty 
bins. This method is also further simplified by the 
proposed spatiotemporal thresholding method which 
evaluates the temporal redundancy in video sequences. 
The calculated threshold can simplify the contrast 
enhancement of each frame when the current frame 
undergoes only slight changes, while implementing the 
exact histogram modification method to the current 
frame if there are great contextual changes in the 
video sequence. Experimental results demonstrate the 
effectiveness of the proposed method in achieving a 
balance between the acceptable effect and low 
computational cost. 
英文關鍵詞： Image display, image enhancement, depth information, 
stereoscopic imagery, contrast enhancement, histogram 
construction, linked lists, motion estimation. 
 
                                                2 
 
提高物件和背景之間的差異進而提升影像設
備顯示品質。此外，對比度增強更可以應用
在醫療影像分析[1]、數位攝影[2]、雷達圖像
處理[3]、人臉識別[4]、文件影像處理[5]、物
件檢測[6]和液晶顯示器處理[7]等領域，以產
生各種令視覺愉悅(visual pleasing)的影像資
訊。因此，對比度增強可以說是影像處理發
展過程中不可或缺的重要角色。 
    各種對比度增強方法已經在許多論文中
被提出來[8]-[10],主要可以分成三大類:  
1) 空間域濾波器[11] - [13], 
2) 頻率域濾波器[14]-[15] 
3) 直方圖修正法 [16]- [18]  
空間域濾波器是透過區域或型態學的方法修
改每個像素的亮度值以提高影像對比度，然
而 local window 修改像素亮度的方式通常會
伴隨額外的計算負擔；另一方面，頻率域濾
波器則是藉由修改頻率係數如傅立葉、小波
轉換、餘弦轉換以增進影像對比度。頻率域
濾波器雖然可以增強影像的紋理、邊緣和其
他被隱藏的資訊，但影像的亮度卻無法獨立
被修正。除此之外，大尺寸影像的頻率轉換
和其相對應之反向轉換亦不適合用於即時處
理；由於直方圖修改法[9]-[10]兼具簡單、直
觀、快速等特性，因此在三大類對比度增強
方法中最受到關注。 
    傳統直方圖修正法藉由直方圖等化法
(histogram equalization, HE)修正每一個畫素
的灰階值。直方圖等化法利用累積分布函數
(cumulative distribution function, CDF) 產生
影像直方圖，映射函數再將像素強度做轉換。
Simplest histogram equalization (SHE)對應的
CDF 和對比增益為正比關係。一般而言，具
高機率的灰階像素分布的直方圖，會被擴展
到較大的範圍的分布，而具較低機率的灰階
像素分布的直方圖則傾向於被壓縮其分布的
範圍。因此，當影像直方圖出現高峰或低谷
時，SHE 通常會產生不自然的影像。 
    為解決上述問題，各種全域調整(global 
adjustment)、CDF 或直方圖分離 (histogram 
separation)的直方圖等化法已經在[16]-[18]中
被 提 出 。 Recursive sub-image histogram 
equalization (RSIHE)利用影像的區域中位數
將影像直方圖分割成數個區域再分別產生各
自對應的等化法，藉以減少 SHE 所帶來的缺
陷 [16]；Recursively separated and weighted 
histogram equalization (RSWHE)利用直方圖
分離技術及正規化伽瑪函數來平滑每個子直
方圖[17]。藉由修改後的子等化圖允許多等化
器在增強對比時也能同時保留影像特徵[17]；
Automatic weighting mean-separated histogram 
equalization (AWMHE)最佳化一些區域映射
以產生一個小量的空間變異與亮度的保存
[18]。可惜的是，上述直方圖等化法並未將相
鄰內容的資訊納入加權時的考量。因此，一
種基於最小弗羅貝尼烏斯範數總和(sum of 
Frobenius norms)並藉由平滑的二維目標直方
圖 之 contextual and variational histogram 
equalization (CVHE)在論文[19]中被提出。然
而，CVHE 是基於二維目標直方圖建構而成的，
運算時間較一般直方圖等化法為長。 
    為了減低建構二維目標直方圖的時間，
許多直方圖搜尋法(histogram search method)
在論文[20]-[22]中被提出。由於兩個相鄰的像
素為中心所形成的二維目標直方圖存在相當
大的冗餘(redundancy)可以被重複利用。在文
獻 [20]中，一種 boundary histogram search 
(BHS)藉累計相鄰兩像素二維目標直方圖相
交區域方式降低運算所需時間。可惜的是當
搜尋視窗變大時 BHS 仍然需要相當大的運算
量[21]；為了在常數時間內完成直方圖建置，
文獻[21]提出了一種 integral histogram search 
(IHS)方法。IHS 藉由遞迴傳遞每一個像素所
形成之影像 superset 使每一個目標直方圖可
以更容易地被計算出來。然而 IHS 的缺點是
建置 integral histogram 的過程需要消耗大量
的記憶體空間；一種根據分布的特性提出的
distribute histogram search(DHS)法用來分離
(disjoint)欄區域。DHS 法利用空間冗餘特性在
常數時間內運用最精簡的記憶體空間更新直
                                                4 
 
當目前畫面 (current frame, CF)和先前畫面
(previous frame, PF)很相近的時候，所提之方
法會直接使用前一張畫面產生之相近 HM 映
射函數，以降低整體運算時間。也就是說，
為了避免重複編碼(re-encoding)造成的多於運
算我們直接將近似結果套用在下一張畫面。 
 
A) 直方圖建構 
    圖二為所提之 SHS 法的示意圖。統計資
訊是直接第一列元素透過不同的算數運算而
得。欄的第一個像素是直接透過 exhaustive 
search 後計算而來。欄直方圖是藉由欄掃描的
程 序 分 別 使 用 addition 、 difference 和
subtraction 完成。 
    相同地，欄直方圖也是透過不同的操作
方式簡單的被更新。當最下方的像素存在時，
連續操作會被用來更新每個欄直方圖的元素。
另一方面，當最上方像素也存在於外部邊界
時，必須進一步使用逆算數運算。所提出之
SHS 法的虛擬碼被描述在演算法 1 中。根據
第 32 行，將我們所提架構和 DHS 法相比，
在每個核心直方圖被更新時可以不需要使用
到減法。 
 基於鍊結串列(linked lists, LL)，所提之
SHS 法可以有效地被實作。圖三為 LL 用來建
構直方圖的架構圖。所提之 LL 法的基本概念
是避免將非零 bins 儲存在結點上，以便有效
的維護直方圖。此外，為了提高時間效率，
我們將採用 hash table 來減少 LL 的搜尋時間
使複雜度從線性降低到常數時間。不過，LL
大部分的運算是為了保持 linked list 和其相對
應之 hash tables，藉由消除不必要的節點插入
與刪除，計算時間可以進一步的被減少。更
具體的說，基於更新 SHS 的經驗法則，特別
是成對的加法和減法運算，因為大部分的像
素都是相等的，所以 LL 可以避免掉維持
linked list 和 hash tables 的計算。 
 
 
 
演算法 1：SHS 法 
 
 
     
 
圖三、鍊結串列(LL)組織架構圖 
 
                                                6 
 
(x,y)灰階值出現用 ),( yxIp  表示，則二維目
標直方圖(H)便可以由以下公式表示： 
},,0|),({ LqpqphH        (7) 
其中L為灰階值，q為每個像素鄰居的灰階值，
h(p,q)為 H 的元素。需要特別注意的是每個 H
的元素會被初始化為零。基於我們利用 LL 實
作的 SHS 法，H 可以很有效率的在常數時間
內被生成。縱座標和橫坐標的差異同時做了
以下修改： 
),1/()1|)(|,(),( minmax  llqpqphqph (8) 
其中 lmax為最大的灰階值，lmin為最小灰階值。
用來更新 H 元素的方法可以進一步被正規化
為以下公式： 
).),(/(),(),(
max
min
max
min
 
 

l
la
l
lb
bahqphqph    (9) 
除了計算機率密度，擁有相等元素(U)的二維
uniform matrix 也可用於最大化熵理論。所有
U 的元素皆被以下公式所計算： 
)./(1),( 2Lqpu            (10) 
此外，平滑映射需滿足如下所示之 tri-diagonal 
matrix R：
,
110000
11000
00011
00001
0
0
0
0




























R (11) 
其中， 和 )/()2(0   為自適應參
數。矩陣 R 乘法的結果為 H 矩陣中水平元素
的差異。垂直方向的元素同時間也輕微地被
乘法所修改。 
).(1 UHRHt  
          (12) 
依照文獻我們將α、β和γ皆設成 1/3。因此，
R 的反矩陣可以被以後公式表示： 
 },,0|),({
1 LqpqpsSR     (13) 
其中，S 的元素為 s(p,q)。由於 R 為一般化
tri-diagonal matrix 的特例，每個元素在一開始
便可以輕易的設定成固定的型式。CVHE 法基
於H(CDFH)和Ht(CDFHT)的CDF的映射函數
可以分別被以下兩個公式計算： 
 
 
l
la
l
lb
bahlCDFH
min min
),,()(       (14) 
 
 
l
la
l
lb
t bahlCDFHT
min min
).,()(      (15) 
最後，映射函數可以被以下公式計算： 
},...,2,1,0{
|,)()(|minarg)(
Lc
f cCDFHTlCDFHlT

  (16) 
其中，l 代表每個可能的灰階值。如前所述，
使用二維直方圖需要額外的計算。因此，我
們所提方法可以利用門檻值來控制影像編碼
取出的 MVs，以進一步來改善時間域冗餘的
缺點。 
 
VI. 實驗結果 
    本章節總結了 CVHE 對比度增強演算法
和所提出用來增加其執行效率的 SHS、LL 和
STTC。需要注意的是 STTC 是架構在 H.264 
Joint Model 參考軟體(JM 17.0)[27]之上，使用
預設 baseline profile 並做了以下三種修改： 
1) 搜尋範圍從 32 修改至 16 
2) 使用 full search 計算 MVs 
3) 只使用 16×16 macroblock 
為了在不同情境下做測試，本計畫中我們使
用八種不同類型的影片。表格一列出了每段
影片的特性，包含攝影機的設定、影片規格、
影片張數、場景的特性和焦段的長度。 
                                                8 
 
 
圖七、”salesman”影片 (a)七張原始畫面 (b)經 CVHE
增強後之畫面 (c)CVHE結合 STTC法減化增強後之畫
面 
 
 
圖八、”street”影片 (a)七張原始畫面 (b)經 CVHE 增強
後之畫面 (c)CVHE 結合 STTC 法減化增強後之畫面 
 
 
圖九、”campus”影片 (a)七張原始畫面 (b)經 CVHE 增
強後之畫面 (c)CVHE結合 STTC法減化增強後之畫面 
 
 
圖十、”silent” 影片(a)七張原始畫面 (b)經 CVHE 增強
後之畫面 (c)CVHE 結合 STTC 法減化增強後之畫面 
圖十一、”stefan”影片 (a)七張原始畫面 (b)經 CVHE 增
強後之畫面 (c)CVHE結合 STTC法減化增強後之畫面 
 
 
圖十二、”waterfall”影片 (a)七張原始畫面 (b)經 CVHE
增強後之畫面 (c)CVHE結合 STTC法減化增強後之畫
面 
 
    圖九(a)為七張”campus”原始影片的示意
圖，經 CVHE 及簡化 CVHE 法增強過後的示
意圖則分別在圖九(b)、(c)呈現。我們可以輕
易的發現”campus”影片中有許多物件移動在
昏暗的停車區域。如圖九(b)、(c)所示 CVHE
法適度的增強了畫面的對比度及亮度且避免
掉顏色失真及其他缺陷。 
    圖十為七張”silent”原始影片、經過 CVHE
法和 STTC 法簡化的示意圖。”silent”影片為
一位女性無聲地在壁畫前比著手語。雖然主
體和背景可以在每一張畫面中被分辨出來，
但環境的亮度還是略顯不足。如圖十(b)、(c)
所示，主體與背景的紋理、邊緣、對比度和
其他細節透過 CVHE 及 STTC 加速後都有了
明顯的改善。 
    圖十一(a)為七張”stefan”原始影片的示意
圖。動態攝影機捕捉運動員在網球場打網球
的畫面。圖十一(b)(c)則分別為經由 CVHE 及
STTC 簡化法增強過後的影片示意圖。透過影
                                                10 
 
 
圖十四、分別為測試影片(a)container (b)hall (c)salesman (d)street (e)campus (f)silent (g)stefan (h)waterfall經由STTC
法產生之自適應性門檻值 
 
表格 2、測試影片經不同方法增強之時間總和報告 
 

 

1 2
1 2 ,
,
21
,
)min(
)max(
ln20
1
)(
S
i
S
i ji
ji
X
X
SS
XEME  (19) 
其中 max(Xi,j)和 min(Xi,j)分別為子圖 Xi,j中最
大和最小的灰階值。高對比的子圖擁有較高
的 EME 值，對於同質性的子圖來說其 EME
值則趨近於 0。在這裏我們採用大小為 8×8 的
W1×W2子圖[19]。 
    圖十三則為 container、hall、salesman、
street、campus、silent、stefan、和 waterfall
等八段影片的 AMBE、DE 及 EME 數值畫出
的曲線圖。需要注意的是，藍色線標示的是
CVHE 法，紅色的線則標示我們提出的 STTC
結合 CVHE 法的曲線。另外，x 座標為量化的
數值，y 座標為畫面張數值。結果顯示簡化的 
CVHE 法和原始 CVHE 法產生的增強結果十
分接近，因此在圖十三上幾乎是呈現重疊的
狀態。 
 
C) 效能評估 
    為了進一步驗證所提出的 STTC 法的效
率，所有被測試影片透過自適應門檻值決定
法決定的門檻值被畫在圖十四中以描述的簡
化過程。需要注意的是圖十四中，At 是用實
線表示，虛線代表 Vt，X 軸代表 macroblock
的變化量，Y 軸代表畫面張數。 
    一般而言，當影片在 spatiotemporal 上出
現較大程度的變動時如物體移動、場景轉換
或鏡頭變焦，則對比度增強法必須精確的施
行這些畫面上。相反地，當畫面只有少許變
動或是背景固定時，我們便可以簡化此流程。
如虛線所示每張畫面的 running average 值是
藉由 macroblock 被改變的機率計算而得。當
被更改的數量大於 running average 時，精確的
對比度增強法會被用來增進 CF 的品質，而當
CF 只有一點點改變時，便可以直接套用 PF
的轉換函數。換句話說，當所提出的方法接
近區域最大改變時，可以選擇性地採用精確
的對比度增強或沿用已經存在的轉換函數。 
透過表格二列出 SHS、LL 及 STTC 等方
法的時間消耗情形，用以評估各方法的效能。
需要注意的是 alarm 代表每段影片透過 STTC
運算後，macroblck 變化數量高於 running 
average 的次數。透過主觀評估與客觀檢驗的
結果可以證明，我們提出的基於 CVHE 的方
法可以有效率的提高影片對比度同時維持影
片的品質。 
                                                12 
 
enhancement," {\it Opt. Eng.}, vol. 50, no. 5, pp. 
057203(1-6), May 2011. 
[24]. C. A. Segall and A. K. Katsaggelos, ``Application of 
the motion vector constraint to the regularized 
enhancement of compressed video," {\it in Proc. 
IEEE Int. Conf. Image Process. (ICIP)}, 2001, pp. 
646-649. 
[25]. Y. Yang and L. Boroczky, ``System for and method 
of sharpness enhancement for coded digital video," 
US patent, 0206591 A1, Nov. 2003. 
[26]. E. B. Bellers, ``3-D recursive vector estimation for 
video enhancement," US patent, 0181590A1, Dec. 
2002. 
[27]. H.264 Reference Software Group [Online]. 
Available: 
http://iphome.hhi.de/suehring/tml/download/ 
Microphone 1 Loudspeakers 
\ 
Microphone 2 
Fig. 1. In-car two microphones test plan. 
corrupted a signal by statistical means [10]. As described 
in (1), a microphone signal y (an M-dimensional vector) is 
filtered by the Wiener filter W (an MxM filter matrix) and the 
output z (an M-dimensional vector) has to estimate the desired 
signal d with some residual error at sample k. 
e[k] = d[k] - z[k] = d[k] - W[kfy[k] (1) 
Equation (1) shows that when z = d then e = 0. This means 
that when e = 0, z is the estimated value of d. Therefore, 
when a desired signal comes with noise (white or coloured), 
a selected W matrix is available for estimating the desired 
signal. Thus the goal of speech enhancement is to compute 
the W matrix. In order to compute filters W[k], Doclo and 
Moonen [11] used the solution of the Wiener-Hopf equation 
W[k] = R;) [k] (Ryy - Rvv[k]) (2) 
where Ryy[ k] is the MxM auto-correlation matrix of the input 
signal and it is estimated during speech plus additive noise 
periods. Rvv[k] is the MxM auto-correlation matrix of the 
input signal which is estimated during noise-alone periods. The 
Toeplitz measurement correlation matrix is Rvv = E[y(k)/(k)]. 
During speech and noise periods, the desired noise + signal 
vector as primary input is defined as D(k) = [d(k), d(k -
1), ... , d(k - M + l)f, where n defines the order of the noise 
process and the Toeplitz signal + noise correlation matrix is 
Ryy = E[d(k)dT(k)]. 
Mic2 
Micl � 
� 
Fig. 2. Block diagram 
115 
III. WIENER FILTER IMPLEMENTATION 
FPGA is a highly attractive option for hardware implemen­
tation due to its flexibility and scalability. By using FPGA we 
can easily verify our design rapidly and be able to reduce time­
to-market period over Application Specific Integrated Circuit 
(ASIC). Figure 2 shows the block diagram of our design of 
noise cancellation system which is implemented by using the 
System-on-Chip (Soc) architecture. The system can be realized 
as three parts: Audio Codec Controller, MicroBlaze micro­
controller, and Wiener filter. On-chip Peripheral Bus (OPB) 
interface is used to connect those components together and 
dealing with the data transmissions. The hardware components 
are described below: 
(a)Audio Codec Controller: we adopt a standard audio 
codec which is composed of a pair of Analog to Digital 
Converters (ADC) and Digital to Analog Converter (DAC). 
This component is in charge of receiving signals from external 
microphones and transmit filtered signal to external speaker. 
(b)MicroBIaze microcontroller: MicroBlaze is a soft­
processor provided by Xilinx Incorporated. This part is used 
to deal with all the communications among all components. 
It receives digital signal from Audio Codec Controller and 
transmit to Wiener filter for filtering. After the signal has 
been filtered, MicroBlaze will receive the filtered signal from 
Wiener filter and can perform some additional operations such 
as ASR, cabin control, telecommunications, or send the filtered 
signal to Audio Codec Controller to playback the filtered 
signal. 
(c)Wiener filter: Wiener filter is the most significant 
component in our design. This filter receives digital signals 
from two independent microphones named Microphone 1 and 
Microphone 2 then filter out the stationary and non-stationary 
noises. Finally, it transmits the result to indicated component 
for further computations. The matrix size of Wiener filter W 
is pre-define d as 32x32. All the operations inside the Wiener 
filter is calculated in IEEE-754 single precision. As shown 
in Figure 4, the functionality of the Wiener filter core is to 
implement Equation (1) and (2). The operations of the Wiener 
filter is described as follows: 
• Collect 32 samples from Microphone 1 and Microphone 
2 and send to corresponding auto-correlation calculators 
(AC) respectively. 
• Two ACs will generate matrix Ryy and Rvv simultaneously. 
• After Ryy and Rvv have been obtained, the matrix subtrac­
tor will subtract Rvv from Ryy. At the same time, Ryy will 
be sent to matrix inverter to calculate R;) . 
• To obtain the filter matrix W, the matrix multiplier will 
generate the product of R;) and the result of Ryy - Rvv. 
• In order to calculate Equation (1), we need to obtain WT 
by performing a matrix transposition on W. 
• Finally, the Winer filter will perform a matrix-vector 
multiplication to get the product of WT and the 32 
samples from Microphone 2 and send the results back 
to MicroBlaze through the OPB bus interface.(Note that 
the samples from Microphone 2 are buffered in matrix-
not speaking, the radio voice is filtered out. As illustrated in 
the waveforms, when there comes a speech from the driver, 
the noise is filtered out with some unwanted distortion. Even 
though, the speech is still recognizable from our bare ear. 
Besides, our previous work [4] shows that a 73% hit rate 
can be obtained by linking the filtered signal to a commercial 
speech recognition kit called RS-07. 
Fig. 5. Experimental results. (a)lncoming voice signal at Microphone 1 -
close to noise (b )lncoming voice signal at Microphone 2 - close to speech 
(c )Filtered voice signal 
In addition, Figure 6 shows the spectrogram analysis of 
original noisy speech signal(Figure 6(a)) and filtered signal 
(Figure 6(b)). In order to measure the SNR, the waveform 
statistics are obtained by using Cool Edit Pro regarding the 
average power during the driver's speech period + noise from 
the radio period and also the noise only from the radio period. 
The SNR is computed as S ignalPowerdB - NoisePowerdB. 
Filtered Signal 
Microphone 2 
SNR improved 
TABLE II 
SNR ANALYSIS 
Avg Signal Power Avg Noise Power 
-57.95dB -27.68dB 
-37.70dB -23.28dB 
SNR 
30.27dB 
14.42dB 
15.85dB 
According to Table II, the results shows the SNR is im­
proved by 15.85dB between the filtered signal and the noisy 
signal received at Microphone 2. Compared to other related 
works [6], [7]. Table III shows that [6] can obtain 21dB 
SNR enhancement but the peak sampling rate is only 12KHz 
whereas our sampling rate can reach 88.628KHz. On the other 
hand, [7] tested their design under 48KHz sampling rate but 
the performance is only 2.39-10dB SNR improvement. 
proposed 
[6) 
[7) 
TABLE III 
PERFORMANCE COMPARISON 
SNR Improved 
15.85dB 
2 1dB 
2.39-lOdB 
Peak Sampling Rate 
88.62KHz 
12KHz 
tested at 48KHz 
117 
(.J 
I 
I 
(bJ 
, .... .... 
I ···'····1····1····1 .. ·. ···1····1·· .. '····1····'····,····,· .. , .... , . . .. , . . .. ,. ·',"'1 ... , .. . .  , 
� � .� � � � � � � � � � � � � � � .� � � 0 
Fig. 6. T he spectrograms of the waveforms: (a) Spectrogram at Microphone 
2. (b)Spectrogram of filtered signal 
V. CONCLUSION AND FUTURE WORK 
An FPGA implementation of adaptive Wiener filter based 
noise cancellation is described. The execution time of each 
32 samples is evaluated to 918 micro seconds. The perfor­
mance of the proposed design is measured as 15.85dB noise 
reduction. The throughput can be enhanced to 88.628KHz 
sampling rate by the exploitation of pipeline architecture. The 
proposed design can also be integrated into other design for 
more applications. For instance, headset-free video conference 
with background noise canceller, mobile phone speech en­
hancement, and active non-stationary noise canceller. 
In future work, the trade-off between performance and cost 
can be analyzed. Higher order of W matrix can lead higher 
SNR enhancement, by analyzing the relationship between 
performance and cost we can find a optimized point for the 
ratio of resource utilization and SNR enhancement. 
REFERENCES 
[I) M. Shozakai, S. Nakamura, and K. Shikano, "Robust speech recognition 
in car environments," in Acoustics, Speech and Signal Processing, 1998. 
Proceedings of the 1998 IEEE International Coriference on, vol. I, may 
1998, pp. 269 -272 voU. 
[2) Y Cho and H. Ko, "Speech enhancement for robust speech recognition 
in car environments using griffiths-jim anc based on two-paired micro­
phones," in Consumer Electronics, 2004 IEEE International Symposium 
on, 2004, pp. 123 - 127. 
[3) H. Agaiby and T. Moir, "A robust word boundary detection algorithm 
with application to speech recognition," in Digital Signal Processing 
Proceedings, 1997. DSP 97., 1997 13th International Coriference on, 
vol. 2, 2-4 1997, pp. 753 -755 vol.2. 
[4) T. Z. Qi and T. J. Moir, "A hybrid noise canceller with a real-time 
adaptive wiener filter and a geometric-based voice-activity detector for 
an automotive application," International Journal of Adaptive Control 
and Signal Processing, vol. 24, no. 6, pp. 508-522, 20 10. 
[5) Z. Qi and 1. T. Moir, "An adaptive wiener filter for automatic speech 
recognition in a car environment with non-stationary noise," Smart 
Sensors and Sensing Technology, vol. 20, pp. 299 - 3 15, 2008. 
[6) C.-M. Kim, H.-M. Park, T. Kim, Y-K. Choi, and S.-Y Lee, "Fpga 
implementation of ica algorithm for blind signal separation and adaptive 
noise canceling," Neural Networks, IEEE Transactions on, vol. 14, no. 5, 
pp. 1038 - 1046, sept. 2003. 
[7) U. Mahbub, T. Rahman, and A. Rashid, "Fpga implementation of real 
time acoustic noise suppression by spectral subtraction using dynamic 
moving average method," in Industrial Electronics Applications, 2009. 
ISIEA 2009. IEEE Symposium on, vol. 1,4-6 2009, pp. 365 -370. 
[8) N. Wiener, Extrapolation, Interpolation, and Smoothing of Stationary 
Time Series. Wiley, March 1964. 
[9) A. Kolmogorov, "Interpolation and extrapolation of stationary random 
sequences," Math Series, pp. 3 - 14, 194 1. 
[ 10) R. G. Brown and P. Y C. Hwang, Introduction to Random Signals and 
Applied Kalman Filtering. John Wiley & Sons, 1996. 
[ 1 1) S. Doclo and M. Moonen, "Gsvd-based optimal filtering for single 
and multimicrophone speech enhancement," Signal Processing, IEEE 
Transactions on, vol. 50, no. 9, pp. 2230 - 2244, sep 2002. 
100 年度專題研究計畫研究成果彙整表 
計畫主持人：阮聖彰 計畫編號：100-2221-E-011-093- 
計畫名稱：一種具低功率的 2D-3D 視訊顯示系統設計開發與硬體實現(I) 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 4 4 100%  
研究報告/技術報告 0 0 100%  
研討會論文 3 3 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
國科會補助專題研究計畫成果報告自評表 
請就研究內容與原計畫相符程度、達成預期目標情況、研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）、是否適
合在學術期刊發表或申請專利、主要發現或其他有關價值等，作一綜合評估。
1. 請就研究內容與原計畫相符程度、達成預期目標情況作一綜合評估 
□達成目標 
■未達成目標（請說明，以 100 字為限） 
□實驗失敗 
□因故實驗中斷 
■其他原因 
說明： 
計畫擬定之初預計是三年完成 2維影像轉換 3維影像系統，第一年完成彩色影像增強演算
法設計，轉換 3D 部分原訂是在計畫第二年開始執行。無奈計畫只通過一年在時間及人力上有
所限制，僅能將原先設定之彩色影像增強演算法開發完成並發表四篇期刊論文及三篇會議論
文，無法完成二維轉換三維系統之開發。 
2. 研究成果在學術期刊發表或申請專利等情形： 
論文：■已發表 □未發表之文稿 □撰寫中 □無 
專利：□已獲得 □申請中 ■無 
技轉：□已技轉 □洽談中 ■無 
其他：（以 100 字為限） 
國際期刊論文四篇，其中包含三篇 SCI/EI 一篇 EI。會議論文三篇，兩篇 EI。 
3. 請依學術成就、技術創新、社會影響等方面，評估研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）（以
500 字為限） 
本計畫第一年針對影像色彩模型進行分析與探討，並致力於影像資訊的品質改善和增強。
在不使用深度圖的前提之下，提出之影像增強演算法在運算量、硬體成本與功率消耗較先
前研究成果大幅下降。透過此第一年計畫之執行可以達到下列目標： 
1. 針對視訊中深度線索的搜尋方式做一完整的研究。 
2. 對深度圖產生 3D 影像的方式進行深入探討。 
3. 發展合適的深度線索評分方法加快深度圖的建立。 
4. 針對現行的色彩模型於影像增強的應用進行效率以及品質分析。 
5. 以直方圖為基礎而發展一套能夠與深度圖建立平行處理的演算法。 
6. 建立與實現一個完整的視訊顯示系統硬體架構。 
7. 比較不同顯示系統設計架構，並比較是否到達本人所設計的目標與需求。 
8. 實際建構視訊顯示系統晶片應用環境。 
9. 討論對於顯示技術更多元化應用，開拓新的學術議題。 
具體而言，參與人員此計畫的人員可以透過計畫執行過程而獲得下列益處： 
