 I 
 
中文摘要 
本計畫進行客語語音處理之研究，包含三個研究主題，一為建構高音質客語文句轉語音系
統，二為建構實用的客語及國客夾雜語音辨認系統，三為客語音韻學研究。以四縣腔客語
為研究主要對象，研究內容包含：(1) 基本資料的收集及建構，如詞典、文字語料、語音語
料等；(2) 客語構詞規則及文句分析；(3) 客語特殊詞之音韻研究；(4) 客語文字轉語音系
統發展；(5) 語言模式之建立；(6) 客語/國客語夾雜語音辨認系統發展。 
 
關鍵詞：客語文句轉語音、客語語音辨認、四縣客語、韻律模式、語言模式 
 
Abstract 
In this project, we studied three speech processing topics for Hakka language: (1) the 
development of a high-quality Hakka text-to-speech (HTTS) system, (2) the implementation of a 
Hakka speech recognizer, and (3) the study in prosodic rules of special Hakka words. The study 
was conducted maily on the major sub-dialect – ―Si-xian Hakka‖ spoken in Taiwan. Several 
important issues were investigated, including (1) The collection and processing of lexicon, text 
databases and speech databases; (2) The realization of a high-performance text analyzer; (3) 
Prosody modeling of special Hakka words; (4) The implementation of the HTTS system; (5) 
Language modeling; and (6) The realization of the Hakka/mixed Hakka-Mandarin speech 
recognizer. 
 
Keywords: Hakka text-to-speech system, Hakka speech recognition, Si-xian Hakka, 
Prosody, Language modeling 
 
 1 
一、 緒論 
1.1 研究背景及目的 
文字轉語音系統(Text-to-speech system, TTS)及語音辨認的研究已有很長的歷史
[14,15]，也都有很好的進展，近年來TTS 已進展到使用大型speech corpus 來選取適合
的語音片段直接連接而不做韻律調整，因而獲得相當好的音質，研究重點在於prosody 
modeling[23-25]以及如何選取最適合的音節片段做連接，以中文而言，台大[16]、交大
[26,29]、中研院、北京微軟 [19-21]、中國電子科大、 Infotalk 等都已有Mandarin 
corpus-based TTS system。在語音辨認方面，已進展到實用階段，許多應用相繼推出，而
研究方向則相當廣泛，如speaker adaptation、noisy speech recognition、spontaneous speech 
recognition 等；在中文ASR 的研究上，國內外有許多單位如台大、交大、清大、成大、
中山、北科大、北京微軟、北京清華、中國科學院等在進行，也都有很好的進展。 
然而，有關客語語音處理的研究則相當少，過去國內語言學家進行了一些客語相關
的研究[1-13]，但在TTS 及語音辨認方面的研究則很少[27]，因此研究所需的相關的資
料也不多，包括Lexicon、annotated text、speech corpora 都很零散。因此，為了增加研
究的深度及廣度，在這三年期的計畫，除了建立文字轉語音系統及語音辨認系統之外，
在蒐集及統整語音資料庫、文字資料庫、建立文字分析上付出相當的努力。另外，在客
語的音韻學研究上，也有初步的成果。希望本研究建立的文字轉語音系統及語音辨認系
統能應用於建立客語語言學習系統方面，輔助客語語言教學，除此之外，建立客語語音
辨認系統的經驗，也可應用於建立其他常用漢語方言的語音辨識系統，如閩南語、不同
腔調之客語等等，因此，本計畫對於方言之語音辨認技術、文字轉語音技術及自然語言
處理是有其必要性及重要貢獻。 
 
1.2 先前研究 
我們在過去受客委會贊助組成一個跨語音處理(陳信宏)及客語語言處理(余秀敏、羅
烈師)的團隊，共同發展了一套四縣客語文句轉語音(Hakka Text-to-Speech, HTTS)系統，
它係採用我們過去發展國語文句轉語音子系統相同的架構，系統包含四個模組：文句分
析 (Text analysis)、韻律信息產生 (Prosody generation)、合成單元波形表 (Acoustic 
inventory)、語音合成(Speech synthesis)，文句分析是將輸入文句做斷詞分析，以產生詞
串、詞類串、音節串；韻律信息產生是由文句分析的結果抽取一些語言參數，來產生適
當的韻律信息，用以合成自然流利的語音；聲音波形資料庫儲存所有的基本音節波形訊
號，它使用文句分析的結果，來組合出對應輸入文句音節串的基本音節波形串；語音合
成是使用韻律信息來調整基本音節波形串的韻律，使其成為自然流利的語音。各模組之
工作說明如下： 
 
1. 文句分析 
文句分析為HTTS 系統重要的一個部份，文句分析結果的優劣直接影響合成聲音的
 3 
 
例句一：當時(dong1 sii5,Nd) 介(ge2,De) 竹笐(zuk4 gong5, Na) ， 就像(ciu3 
ciong3, P) 這下(it4 ha3, Nd) 介(ge3, De) hiap4 錢(cien5, Na) 箱(siong1, Na) 
樣仔(iong3 e2, Na) 
 
其斷詞效能之評估如表1.1其效能仍有進步的空間，所以在本計畫執行的三年，我們
對斷詞系統重新設計，利用國語和客語之間相近的語言特性進行改善，在第三章有所詳
述。 
 
表1.1：斷詞效能評估 
 
 
2. 韻律信息產生 
韻律信息產生是要由語言參數來產生包含音節基週軌跡、音節能量軌跡、音節長度
(或聲韻母長度)、及音節間停頓長度等韻律信息，本系統使用的方法是遞迴式類神經網
路(Recurrent Neural Netword, RNN) [18] (見圖一），它由一個大的語料庫來學習語
言參數到韻律參數的對應關係，訓練時藉調整類神經網路的神經元間連結的加權
(weights)，在合成時，將語言參數輸入來產生韻律參數。 
 
圖1.1：遞迴式類神經網路韻律信息產生器架構圖 
 5 
1.3 研究方向 
本計畫擬進行客語語音處理之研究，包含三個研究主題：(1)高音質HTTS 系統之建
立，(2)客語及國客雙語語音辨認系統之建立。(3)客語音韻學研究 以下為本計畫三大內
容之概述： 
 
(1)高音質HTTS之建立 
改進先前研究建構之PSOLA-based HTTS 系統，完成一套客語文句轉語音系統。它
由斷詞系統、停頓預估系統、文脈分析器以及基於隱藏式馬可夫模型之語音合成器所組
成。文句輸入經由斷詞系統做分詞和詞性標記。由於客語語料的不足，本研究在此結合
中文斷詞條件隨機域模型、客語外掛詞典、中文內部詞典及客語構詞規則形成客語斷詞
系統。斷詞系統輸出斷詞資訊後，由靜音停頓預估系統預估詞後是否停頓，再由文脈分
析器輸出和語音合成器相對應之合成單元及語言參數，依據文字標記檔及合成器訓練端
所得到的模型進行音長、聲學、音高參數的預測，再得到合成語音輸出。最後我們也分
別設計實驗對斷詞系統、靜音停頓預估系統、合成器以及HTTS系統做出客觀效能評估，
HTTS系統在主觀評分上也得到了不錯的分數，顯示出我們已經有一套不錯的客語文字
轉語音系統。以下為建立高音質HTTS之重點研究工作項目： 
(a) 單一語者大型speech corpus 之錄製及處理。 
(b) 客語詞典之擴增。 
(c) Text Analysis之改進。 
(d) 停頓預估。 
(e) HMM-based 語音合成器之建立。 
 
(2)客語及國客雙語語音辨認系統之建立 
根據既有國語語音辨認系統輔助建立客語語音辨認系統，並且由單語言的語音辨認
系統，以不同定義的方式設計系統內的不同元件，建立雙語語音辨認系統。其中包括客
語語言模型的建立、雙語語料分析、雙語音素集的設計、針對雙語特性設計語言模型、
以及雙語系統等。由實驗證實，雙語語音辨認與客語語音辨認都朝向預期目標發展。其
中客語語音辨認系統對於加入之國語語言參數資訊，確實都能影響其辨認效能，不過由
於客語訓練語料數量的限制，客語語音辨認率明顯比國語語音辨認系統低，但是藉由分
析及實驗結果，得到許多對於客語語音辨認系統的有效知識及經驗，相信對於日後的發
展將有所助益。以下建立客語及國客雙語語音辨認系統之重點研究工作項目： 
(a) 訓練聲學模型(Acoustic Model, AM) 之文字語料收集及處理。 
(b) 多語者(約100人)大型speech corpus 之錄製及處理。 
(c) 訓練語言模型(Language Model, LM) 之文字語料收集及處理。 
(d) 國語三連音、客語雙連音、國客語混和三連音聲學模型訓練 
(e) LM 之建立。 
 
 7 
20kHz 的取樣頻率及 16-bit 之單聲道 pcm 格式錄音，文章來源由
龔萬灶老師所主筆的「阿啾箭个故鄉」，包含 42 篇文章、63,158 個
音節、639 個語音檔，有人工斷詞修正、詞類標記、對應中文翻譯、
正確語音切割。 
3. 羅老師海陸客語語料 
20kHz 的取樣頻率及 16-bit 之單聲道 pcm 格式錄音，是為龔老師
四縣客語語料的海陸腔帄行版本，也包含 42 篇文章、639 個語音檔，
錄製完成，但尚未做語音切割和發音標注。  
ii. 語音辨認用途 
1. 四縣腔客語語料： 
屬於麥克風朗讀語音(16kHz的取樣頻率及 16-bit之單聲道 pcm格
式錄音)。文章內容主要為客語故事，主要由苗栗的兩位退休教師，
一位是龔萬灶老師、另一位為陳碧娥老師所撰寫；並加入中華大學余
秀敏老師所新增的客語文句。由 92 人(男 43 人、女 49 人)朗讀錄製而
成，共 10,229 個檔案、153,911 個音節。 
2. 國客夾雜語料 
屬於麥克風朗讀語音(16kHz的取樣頻率及 16-bit之單聲道 pcm格
式錄音)。文句由中華大學余秀敏老師根據日常國客語夾雜使用情況
所撰寫，文句內容分為客語為主文句及國語為主文句，各 100 句。由
20 人(男女各 10 人)錄製而成，每人 20 句國語為主文句、20 句客語為
主文句，共 800 個檔案(國語為主、客語為主各 400 個)，國語為主之
語料包含 4,956 個音節，而客語為主之語料包含 4,960 音節。 
(2) 雛型系統 
甲、 中文 Text Analysis 
乙、 四縣客語 Text Analysis 
丙、 四縣客語文字轉語音系統 
丁、 四縣客語語音辨認系統 
戊、 國客語混合語音辨認系統 
(3) 論文發表 
甲、 客語文字轉語音系統方面 
Yi-Ling Tsai, Hsiu-Min Yu, Yih-Ru Wang, Chen-Yu Chiang, Lieh-Shih Lo, and Sin-Horng 
Chen, ―An HMM-based Hakka Text-to-Speech System,‖ accepted by OCOCOSDA 
2010. 
乙、 客語、國客混合語音辨認系統方面 
Tsai-Lu Tsai, Chen-Yu Chiang, Hsiu-Min Yu, Lieh-Shih Lo, Yih-Ru Wang and Sin-Horng 
Chen, ―A Study on Hakka and Mixed Hakka-Mandarin Speech Recognition,‖ accepted by 
ISCSLP 2010. 
丙、 客語音韻學研究方面 
 9 
二、 客語音韻之介紹 
客語又稱客家話或客話，是漢語方言學者及聲韻學家們公認的漢語七大方言群中的
一支重要方言系統[3]，以客語為母語的人口約佔中國漢族總人口之百分之四，估計有
四千五百萬人左右[3]，這些客語族群主要分佈在廣東東北、江西南部、福建西部及北
部、廣西南部、湖南、四川、東南亞等的海外華僑以及台灣等地[3]。楊福錦1967《客
方言的音韻成素》，依據聲、韻、調的語音特徵差異，廣義的將客語族群分為七大次方
言區：梅縣區、興寧區、饒帄區、海陸區、香港區、汀州區、以及永定區[3]，也許是
廣東梅縣是純客語的最大縣城，加上提倡客語和客家族群研究的最早先驅羅香林先生也
是梅縣人，學術界以及客家人本身一向以梅縣的次方言為客語的主要代表。至於台灣方
面，客家族群分佈在台灣北、中、南及花東地區的縣市城鎮，除了較少人口的詔安、大
埔、饒帄、和永定等次方言外，最主要的台灣客語次方言分別是四縣話（梅縣區的次方
言）和海陸話（海陸區的次方言）[3]，基本上仍以四縣話為主，而苗栗縣是台灣各客
語縣市中，說四縣客語人數最多的一個縣市[1]，因此，以苗栗客語為研究對象，對於
客語語音技術的研發來說，十分具有代表性。以下以余秀敏1994《苗栗客家話音韻研究》
[5]、羅肇錦1990《台灣的客家話》[3]以及鍾榮富2004《台灣客家語音導論》[2]所提
供的資訊為主，並以微幅修正的通用拼音為主要標音法，分別介紹苗栗客語的音節結
構、聲母、韻母、及聲調等的語音特徵。 
 
2.1 客語的音節結構 
如同其他的漢語方言，客語也是聲調語言：一個音節搭配一個具有辨別語意功能的
聲調，其聲韻調的音節結構如下圖所示[2]： 
 
圖2.1：客語音節結構 
 11 
尾的舒聲韻，有 m、n、ng，入聲韻則是由塞音節尾，共有 p、t、k。四縣客家話的韻母
共有 71個，如表 2.2 
表 2.2: 四縣客家話韻母表 
代碼 韻母 代碼 韻母 代碼 韻母 
1 ii 25 em 49 iep 
2 i 26 iem 50 ep 
3 e 27 am 51 ap 
4 ie 28 iam 52 iap 
5 ue 29 iin 53 iit 
6 a 30 in 54 it 
7 ia 31 en 55 et 
8 ua 32 ien 56 iet 
9 o 33 uen 57 uet 
10 io 34 an 58 at 
11 u 35 uan 59 uat 
12 iu 36 on 60 ot 
13 iui 37 ion 61 ut 
14 ai 38 un 62 iut 
15 uai 39 iun 63 ak 
16 oi 40 ang 64 iak 
17 ioi 41 iang 65 ok 
18 ui 42 ong 66 iok 
19 eu 43 iong 67 uk 
20 au 44 ung 68 iuk 
21 ieu 45 iung 69 FNULL 
22 iau 46 uang 70 iing 
23 iim 47 iip 71 uak 
24 im 48 ip     
 
2.4 四縣客家話之聲調 
漢語當中國語的聲調有四個，閩南語有七個，四縣客家話的聲調和其他次方言相較
之下較為簡單，共有六個，其調類、調號和例字如表 2.3所示： 
 
表 2.3: 四縣客家話聲調表 
調類 陰平 陰上 陰去 陰入 陽平 陽入 
調號 1 2 3 4 5 8 
例字 千 錢 淺 賤 絕 切 
 13 
 
三、 客語文字轉語音系統 
語音合成的技術主要有兩大類，一為基於語料庫之合成法(corpus-based)，近期的單
元選取合成系統(unit selection synthesis system)所合成出的語音品質已相當穩定，但在輸
出的語者特性或情緒上難以調適，並且頇保存大量語料庫；第二種是基於數據處理之參
數合成法(parametric speech synthesis)，不同於直接從語料庫挑選語音片段單元合成，在
訓練完模型參數後，只需保留訓練得到的模型，在可攜性(Portable)及適應性(Flexibility)
上有很大的進步。近年來，基於隱藏式馬可夫模型的語音合成系統(HMM-based Speech 
Synthesis System, HTS)[29,30]是基於parametric speech synthesis處理之合成法中最廣為應
用的合成技術，其應用上的彈性大，能合成出較自然的語音。 
本研究將使用基於隱藏式馬可夫模型語音合成系統，完成客語文字轉語音之系統實
作，系統基本架構如圖 3.1所示： 
文句輸入
斷詞系統
基於HMM
語音合成器
語音輸出
停頓預估系統
文脈分析器
 
圖 3.1: 客語文字轉語音系統 
本系統包含斷詞系統(Text Analysis)、停頓預估模型、文脈分析器以及基於 HMM 之
語音合成器；文句輸入經由斷詞系統做分詞(Segmentation)及詞性標記(Part of Speech 
Tagging)，接著由停頓預估模型預估詞後是否有停頓，文脈分析器將前一階段的輸出轉
成合成單元序列及其對應語言參數，接著 HTS 找到相對應之頻譜、音長和音高的 HMM
 15 
(2) 分詞單元 
此單元目的是將輸入的文句做出適當分詞，也是整個系統當中最核心的部分。分詞
單元是最前面的分詞階段，後來的「詞性標記單元」會利用此單元所產生的候選句標記
詞性。 
 
(3) 詞類標記單元 
詞類標記單元利用機率統計模型，標記所有可能的詞性組合，並從候選句當中選出
最合乎語法的句子。 
 
(4) 構詞單元 
四縣客家話中如「結結」（結實的樣子）同字疊字型態，或是名詞後加詞綴的「細
人仔」（小孩子）等，都是無法全部收錄至詞典當中，因此利用構詞規則合併詞組以提
供良好的斷詞結果。 
3.2 中文分詞與詞性標記 
中文分詞與詞性標記第一步是透過詞典及中文分詞條件隨機域模型得到可能的分
詞候選句；接著經由查詢詞典得到候選句中每個詞彙的詞性標籤組合，最後利用詞性標
記條件隨機域模型，從候選句中選出最佳結果，而此最佳結果為已標上詞性標籤的詞彙
序列；本節將對中文分詞以及詞性標記做介紹。 
當輸入某句文字序列序列C 時，我們要找到其最佳對應的詞彙序列W ，以及詞性標
記序列T ，可用以下公式表示： 
     , ,P W T C P T W C P W C 
           
(3-1) 
可分為  ,P T W C 和  P W C 兩機率值的相乘，  P W C 表示出現某個文字序列
時，出現某個詞彙組合的機率，即出現某個分詞組合之機率，我們由條件隨機域模型得
到最高機率前幾名作為分詞單元輸出候選句；   ,P T W S B 是在某個詞彙序列的情況
下，出現某個詞性標記序列的機率，候選句配合詞典中每個詞彙可能出現的詞性標籤輸
入至條件隨機域模型，模型會依照學習到的句法結構，給予候選句（從第一個到最後一
個）每一個詞彙一個最高機率數值，即最可能出現詞性標籤，以及其對應的機率； 
  ,P T W S B 和  P B S 兩機率相乘得到候選句的分數，最後選取分數最高組合的做為
最佳分詞與詞性標記結果。
 
 
3.2.1 中文條件隨機域模型 
 17 
數，特徵樣版表示我們擷取特徵的規則，本研究在訓練中文斷詞條件隨機域模型所選用
的特徵如表 3.1 所表示。其中字元 Cn、標點符號 PMn、數字字元 Dn、英文字元 En、和
詞典詞相對應的 WLn 及 WTn 幾項特徵為 Zhao[32]所提出；而本研究加入每個字元的部
首資訊 Bn 以及 DPn和 DTn兩項未收錄詞典詞之特徵，DPn及 DTn是關於在同一個句子
中是否找到重複出現的詞，可以補足詞典中未收錄之詞；例如在文章中常出現但詞典並
未收錄的專有名詞或是長詞，這兩項特徵可以提高此部分的分詞效能。 
在訂定適當的特徵後，我們將每個特徵依據其相關性及其前後資訊分組，稱為特徵
樣版，我們所採用的特徵樣版詳細列在表 3.2。 
表 3.1: 中文分詞之條件隨機域訓練特徵 
特徵 含意 
Cn 當前字元 
Bn 當前字元的部首 
PMn 當前字元是否為標點符號 
WLn 在詞典可找到包含當前字元的最長詞之詞長 
WTn 在詞典可找到包含當前字元的最長詞中，當前字元的詞位標注(B1,B2,B3,M,E,S) 
DPn 在同一句子當中，可以找到包含當前字元的最長詞之詞長，而此詞在包含當前字元
的詞出現前曾經出現過 
DTn 若當前字元可找到其包含當前字元的最長詞，而此詞在包含當前字元的詞出現前曾
經出現過，當前字元在此詞當中的詞位標注 
Dn 當前字元是否為數字 
En 當前字元是否為英文字母 
 
表 3.2 中文分詞之條件隨機域訓練特徵樣版 
特徵樣版 含意 
Cn-1 , Cn ,Cn+1 ,(Cn-1 Cn ), (Cn Cn+1 ), (Cn-1 Cn+1), PMn 字元與其臨近字元資訊 
( Bn Bn-1 ), ( Bn+1 Bn ), (Bn+2 Bn+1 ) 部首資訊 
(WLn WTn ), (WTn-1 WTn WTn+1), (WLn WTn DLn DTn) 詞典詞及重複詞資訊 
(Cn Dn-1 Dn+1 ) 數字字元資訊 
(En-1 En ), (En En+1 ), (En-1 En En+1) 英文字元資訊 
 
3.2.3 中文詞性標記 
詞性(Part of Speech, POS)可以代表一個詞在句子中的語法角色，而詞性標記單元的
功能，就是在斷詞單元產生 N 個最佳候選句後(本系統中 N=3)，給予每個詞彙相對應的
 19 
最佳斷詞與詞性標記序列。 
 
3.3.1 客語詞典 
詞典在 TTS 系統中有非常重要的功能，在分詞和標記詞性階段能提供詞和其詞性資
訊，在合成語音前的文字分析器當中必頇查詢詞典得到對應的音標和聲調。我們主要的
收集來源為「完整版中級詞彙彙整檔案」、「台北市客委會-現代客語詞彙彙編」、「教
育部客家語常用詞辭典」等；詞典內容包含詞、四縣音標、音節碼、詞性、中文翻譯以
及詞來源。目前所收錄的客語詞之數量如表 3.5 所示： 
 
表 3.5 客語詞典統計表 
詞長 1 2 3 4 5 6 7 8 total 
詞條數 6747 18078 5095 4217 250 80 60 14 34541 
 
 
客語外掛詞典是客語分詞與詞性標記系統中很關鍵的資訊，我們先將客語詞典中與
中文內部詞典相同的共用詞彙刪除，其所有外掛詞典之資料量在表 3.6 詳細列出。 
 
表 3.6 客語外掛詞典統計表 
詞長 1 2 3 4 5 6 7 8 total 
詞條數 91 5296 5521 3401 293 75 80 12 14769 
 
3.3.2 構詞規則 
分詞會將輸入的文句和詞典做比對，我們無法將所有可能的詞條列於詞典當中，這
些無法收錄於詞典之詞，有些是有規律的，可由「詞類標記單元」得到詞性標籤後再經
由「構詞單元」結合出來。 
客家話的構詞規則和國語非常相似，大致上分為四種，分別是重複，附加，附合及
合併。所謂重複是指單一詞彙之重複，如「洗湯」重複成「洗洗湯湯」（表廚房內擦擦
洗洗之事）。附加則是在詞的前後附加綴詞，如在「婆」之前加前綴詞「阿」形成「阿
婆」一詞，後綴詞如在「刀」之後加「仔」形成「刀仔」。附合詞是指兩個獨立的詞結
合而成另一個新詞，例如「青菜」是由「青」和「菜」組成，但「青菜」不一定是指「青
色的菜」，而是所有蔬菜的泛稱，附合詞兩個詞之間不能插加任何詞語，由此可見附合
詞並不單純是兩個詞的併列，而是有其密不可分的構詞特性。第四種構詞方式稱為合
併，這是中文構詞規則所沒有的，如 cin1（親）ga1（家）念快時會變成 cia1（親家），
這種合併結果是單音節多詞素的構詞。我們解決附合詞的方式為新增詞條至詞典，而合
併詞在四縣客家話當中並不常見，因此本系統所採用的構詞規則主要以重複和附加為
 21 
客語字 語料庫中出現對應中文字/POS 對應中文字/POS 加入客語外部詞典 POS 
擺 次/Nf 次/Nes_Nf Na_Nf_VC 
擺/VC 擺/VAC_VC 
本實驗從客語語料中統計出現次數最多的 40 個一字詞，將有此問題之單元整理其
對應詞性，並加入外掛詞典中，所加入之一字詞如附錄二所表示。 
3.4  HMM-based 語音合成器 
基於隱藏式馬可夫模型的語音合成系統 (HMM-based Speech Synthesis System, 
HTS)[29,30]是目前最廣為應用的合成法，與傳統的串接式合成系統比較，基於模型的語
音合成方法具有較高的可攜性以及適應性，儲存模型所需要的空間，遠小於串接式合成
系統所需儲存大量的音檔；另一方面，模型的可訓練性，能快速使模型參數進行調式或
轉換。本節將詳細介紹 HTS 工作原理、我們所採用的決策樹問題集、文本相關資訊，
以及對本研究在語音合成前所做的停頓預估系統加以討論。 
3.4.1 HMM-based 語音合成系統 
基於 HMM 之語音合成系統架構如圖 3.3 所示，主要分為訓練以及合成兩個階段： 
 
（一） 訓練階段： 
我們將得到切割資訊後的聲音語料，估算其特徵向量作為參數，包括頻譜部分
(spectrum,梅爾倒頻譜)以及其動態特徵向量、激發訊號部分(excitation,logF0) 以及其動態
特徵向量；聲音語料所對應的文字則由斷詞系統和文本分析器分析出對應的文脈相關序
列，使系統在訓練階段時可以透過合併分裂樹學習合成單元間的相連狀況；包含切割資
訊的語音訊號以及文本相關序列先經由 HMM 訓練，產生各合成單元的音高特徵模型、
頻譜特徵模型和音長特徵模型，再透過狀態合併決策樹問題集對模型進行分群，得到和
文本相關的 HMM 模型。 
 
（二） 合成階段： 
使用者輸入文字，由斷詞和詞性標記系統得到斷詞資訊後，再經由停頓預估器預估
出停頓位置（停頓預估系統將在 4.?節詳細介紹），送入和訓練部分相同的文本分析器
得到合成單元及其所對應的語言參數序列；透過分類及回歸樹挑選出相對應之 HMM 模
型序列，根據參數產生演算法產生特徵參數，最後通過梅爾對數頻譜近似濾波器(Mel Log 
Spectrum Approximation filter, MLSA filter)合成語音訊號輸出。 
基於 HMM 之語音合成器主要核心技術有三個；(1) 包含動態特性的參數生成演算
法，此演算法將在下節做詳細介紹。(2) 多空間機率分佈隱藏式馬可夫模型(Multi-space 
Probability Distribution HMM, MSD-HMM)，基頻在濁音處是有值的，但在清音處為零，
為了解決基頻在濁音處和清音處轉換上的不連續，MSD-HMM 在此定義濁音處的參數維
 23 
的靜態參數以及其動態參數，不僅擴大模型的參數維度，也讓模型在前後時間關係有更
好的描述。 
令      1 , 2 , ,
t
tc c c c M    為在時間點 t 的靜態特徵向量（例如頻譜參數），而相
對於
tc 的一階動態參數 tc ，以及二階動態參數
2
tc 計算式如下： 
   
 
 n
n
L
nn
t t i
i L
c i c 

   ， 0, 1, 2n                                           (3-5) 
   n i 表示第 n階動態參數對於時間點 t i 的靜態參數所附予的權重係數，i 表示作用範
圍，也就是時間點 t 往前後各  
n
L 個時間單位。 
 
 
 
 
'
0
1
0, , , , , , , ,0n n
n n
n n n n
L L Tt
t L t L
   

 
 
  
  
                                        (3-6) 
其中    0 0 1  以及  0 0L  。 
動態參數表現在時間上的物理意義會因為各階動態參數所對應設計的 n 而有所不
同，本研究的動態參數計算如下： 
1 1
1 1
2 2
t t tc c c   
                                                        
(3-7) 
   2 1 1t t t t tc c c c c                                                      (3-8) 
我們在圖 4-2 表示出一階及二階動態參數的關係： 
1 12 t t tc c c   
1tc 
1tc 
tc
      
1tc 
1tc 
tc 1t tc c 
1t tc c 
2
tc
 
圖 3.4: 一階及二階動態参數關係圖 
由圖可以看出，一階動態參數和自己本身的靜態參數沒有關係，是下一個單元以及
 25 
3.6 表示。 
1, 2 , , , ,n NS S S S  
HMM model
選擇
HMM model
1 2 n N
   
1
1 ' 1 ' 1C R r W U W W U 

   
1C 2C nC NC
前後文相關語言參數
 
圖 3.6: 參數生成示意圖 
合成階段將合成單元參數串接成O，  1 2 NO= O ,O , ,O ，接著產生整個輸入字串
的 HMM 模型  1, 2 , , N    ，模型的帄均值向量為
'
' ' '
1 2, , , N       ，共變異數矩
陣  U 1 2U ,U , ,UNdiag  ，我們需要找出使得已知模型產生O中機率最大的C ，也
就是找到最佳的C 使  OP  有最大機率值。其中O=WC ，由  OP  取對數值得到： 
     
' 1
U U U
1
log O
2
P O O K                                        (3-9) 
其中 U
1 3
log log 2
2 2
K MN    ，和O不相關。 
將式子對C 偏微分，在偏微分為零的地方為極大值： 
 log
0
P WC
C
 


                                                      (3-10) 
 27 
表 3.9: 文本相關資訊格式 
  聲母/韻母/停頓(initial/final/sp) 
p1 前一個聲母/韻母/停頓 
p2 當前聲母/韻母/停頓 
p3 下一個聲母/韻母/停頓 
  音節(Syllable) 
t1 前一個音節聲調  
t2 當前音節聲調 
t3 下一個音節聲調 
w1 當前音節在詞中的位置(從前面數來) 
w2 當前音節在詞中的位置(從後面數來) 
w6 音節位置屬於詞間或詞中 
s1 當前音節在句中的位置(從前面數來) 
s2 當前音節在句中的位置(從後面數來) 
PM 
音節後是否有標點符號  
1：「，」 
2：「。」 
3：「、」 
4：其他標點符號 
5：無標點符號 
  詞(Word) 
w3 前一個詞由幾個字組成 
w4 當前詞由幾個字組成 
w5 下一個詞由幾個字組成 
POS1 前一個詞的詞性 
POS2 當前詞的詞性 
POS3 下一個詞的詞性 
  句(Sentence) 
s3 前一個句子由幾個字組成 
s4 當前句子由幾個字組成 
s5 下一個句子由幾個字組成 
 
3.4.5 狀態合併決策樹問題集 
決策樹問題集紀錄資料分群規則，HTS 建立決策樹時會依據問題集進行分群。為了
達到最佳合併分裂結果，我們考慮了合成單元相關、字相關、詞相關、句相關以及聲調
相關五類問題。  
 29 
表 3.10: 停頓預估模型之特徵 
特徵 含意 
PMn 詞後是否有標點符號 
WLn 詞長 
POSn 詞性 
Win 
詞從前面數來第一個字的聲母發音類別 
1：b、d、g 
2：p、t、k 
3：m、n、ng 
4：z 
5：c 
6：f、s、h 
Wfn 
詞從前面數來最後一個字的韻母發音類別 
1：a、ai、au、am、an、ang、ap、at、ak 
2：e、eu、ieu、iau、im、em、en、ep、et 
3：i、ie、ia、io、iu、iui、ioi、iem、iam、in、ien、ion、iun、iang、iong、 iung、
ip、iep、iap、it、iet、iut、iak、iok、iuk、iing、iui 
4：o、oi、on、ong、ot、ok 
5：ue、ua、u、uai、ui、uen、uan、un、ung、uang、uet、uat、ut、uk、uak 
6：ii、iim、iin、iip、iit 
7：FNULL 
表 3.11: 停頓預估模型之特徵樣版 
特徵樣板 含意 
PMn-1, PMn, PMn+1, ( PMn-1PMnPMn+1) ( PMn-2PMn-1PMn) 詞後是否有 PM 資訊 
WLn-2,WLn-1,WLn,WLn+1,WLn,( WLn-2WLn-1WLnWLn+1WLn) 詞長資訊 
POSn-1, POSn, POSn+1 POS 資訊 
Win+1 下一個詞第一字聲母發音類別資訊 
Wfn 當前詞最後一字韻母發音類別資訊 
(Win+1Wfn),(POSnWin+1Wfn) 組合資訊 
 
3.5 實驗結果 
TTS 系統最主要的兩大部分為斷詞單元以及基於 HMM 之語音合成器，本節將針對
這兩部分做實驗設計以評估其效能。由於客語斷詞系統是結合中文分詞與詞性標記模
型、客語外掛詞典以及客語構詞規則，因此，本節將介紹訓練中文斷詞模型之語料，並
先對中文斷詞做效能分析；再結合客語外掛詞典和構詞規則後對客語語料做測詴以評估
 31 
2
F
 


精確率 召回率
分數
精確率 召回率
                                              (3-14) 
本研究的中文分詞系統之精確率、召回率以及 F 分數如表 3.13 所示，由表中可以看
出我們在中文分詞系統對中文分詞的效能上已有很好的結果： 
表 3.13: 中文分詞實驗結果 
 精確率 召回率 F 分數 
外部測詴語料 95.95% 96.79% 96.37 
內部測詴語料 98.94% 98.82% 98.88 
 
(b) 詞性標記效能評估 
而在詞性標記的實驗中，我們將已有標準分詞結果之中文詞彙序列輸入詞性標記系
統，系統將每個詞彙標記出最佳對應詞性標籤輸出；我們使用正確率來作為評估詞性分
析系統的效能，正確率之定義如下： 
系統標記詞性和參考答案相同的詞數
正確率=
總詞數
                             (3-15) 
我們在詞性標記系統測詴中，所得到的內部測詴正確率 96.01%，而外部測詴結果
為 94.73%，由實驗數據顯示，我們在中文詞性標記系統已有不錯的效能。 
  
3.5.2 客語分詞和詞性標記 
在評估了中文分詞與詞性標記系統的效能後，我們接著加入客語外掛詞典及客語構
詞規則，對客語文章進行分詞及詞性標記；本節將介紹客語測詴語料以及設計實驗以評
估客語斷詞系統之效能。 
 
(a) 測詴語料 
客語測詴語料庫為龔萬灶老師所主筆的「阿啾箭个故鄉」一書，其中包含 42 篇文
章，共有 63158 個單元(包含標點符號)；由余秀敏老師將此客語文語料翻譯成相對應之
中文帄行語料，先從中研院斷詞器得到此中文帄行語料之分詞和詞性結果標記，再以人
工校正的方法，將此分詞和詞性標籤資訊對應至客語語料，最後得到標記好詞性及分詞
結果之客語文章，我們把這份語料當作本實驗的參考標準答案。而此帄行語料中，國客
語使用詞彙完全一樣的詞共占了總詞數的 48.57%。 
在詞性標記測詴中我們使用和分詞測詴相同的語料，輸入為參考答案的分詞結果，
由客語詞性標記系統標記出相對應之詞性，再與參考答案的詞性標籤相比較以分析其效
能，此測詴語料共有 36450 詞。 
 
(b) 客語分詞實驗 
 33 
 
例子 2：實驗 B 在外掛詞典中收錄了客語詞「祖公祖婆」及「共下」 
實驗 A 斷詞結果 請|祖公|祖婆|共|下來|過年 
實驗 B 斷詞結果 請|祖公祖婆|共下|來|過年 
參考斷詞結果 請|祖公祖婆|共下|來|過年 
中文帄行語料斷詞結果 請|祖先|一貣|來|過年 
實驗 A 的客語字串「共下來」被斷成中文詞「共」和「下來」，再將「共下」加入
外掛詞典後，可正確斷出「共下」一詞。 
 
(e) 客語詞性標記實驗結果 
實驗 A 及實驗 B 對已給定的客語文章分詞結果標記詞性，正確率如表 3.15 所表示；
由中文詞性標記系統直接標記客語文章詞性的正確率為 59.41%，而加入外掛詞典後正
確率上升了 17.73%，由於在詞性標記階段，條件隨機域會依據詞典內的詞性組合給予
每段文句最佳的配對詞性標籤，而未加入客語詞典時，系統無法找到其對應之詞性標
籤，因此在實驗 B 的正確率較實驗 A 上升了許多。 
表 3.15: 客語詞性標記實驗結果 
  正確率 
實驗 A 59.41% 
實驗 B 77.14% 
 
3.5.3 停頓預估模型之效能分析 
在本研究中男性語料庫經由標記及修正切割位置後，得到各音節聲母、韻母及音節
後停頓資訊，我們將切割位置中 25ms 以上的停頓保留，而 25ms 秒以下皆視為沒有停頓。
其中訓練語料共有 36991 個詞，測詴語料包含 4095 詞。我們在此設計了兩個實驗，以
評估由條件隨機域訓練停頓預估模型的效能，分別為(1)實驗 A：詞後有標點符號則預估
為有停頓。(2)實驗 B：由條件隨機域訓練模型預估詞後是否有停頓。 
實驗 A：詞後有標點符號則預估為有停頓  
實驗 B：由條件隨機域訓練模型預估出詞後是否有停頓 
我們使用正確率和以下四種機率值來作為評估詞性分析系統的效能，其定義如下： 
系統標記是否有停頓和參考答案相同的詞數
正確率=
總詞數
                       (3-16) 
 11 =P
預估結果有停頓
正確答案有停頓
                                                (3-17) 
 35 
3.5.4 客語語音合成實驗結果與分析 
(a) 實驗與測詴語料 
實驗所採用的語料為男性語料庫語，音檔有 458 個，共有 63158 個音節，帄均發音
速度為 0.24syllable/second，我們從中取出 407 個音檔做為訓練語料，其餘 51 個當作測
詴語料。女性語料庫中共有 292 個語音檔，總音節數為 42337 個，帄均發音速度為
0.22syllable/second，其中 262 個音檔為訓練語料，測詴語料共有 30 個音檔。 
 
(b) 客觀評估 
我們採用客觀評估對模型的效能進行評估，評估的語料以及標準如表 3.19 所示： 
表 3.19: 客觀評估 
  語料/受測者 評估標準 
客觀評估 
內部測詴語料 
RMSE 
外部測詴語料 
我們採用均方根誤差(Root Mean Square Error, RMSE)作為本實驗的評估標準，計算
目標和其預測的音高軌跡、音節長度以及頻譜能量之間的誤差，例如目標之音高軌跡為
 1 2, , , NS s s s ，而預測音高軌跡是  1 2, , , NT t t t ，則 RMSE 之計算方式如下：
 
 
2
1,
N
i i
i
s t
RMSE S T
N




                                             (3-21) 
本實驗分別對男性及女性語料庫，計算在內部測詴語料和外部測詴語料的音高軌跡
和音長之 RMSE 值，如表 3.20 及表 3.21 所示。我們由此表看出男性語料模型在預測音
高軌跡有不錯的表現，比女性語料模型佳，這是由於女性在講話時，音高軌跡範圍較廣，
而且本實驗的女性發音人聲音特性較沙啞，在原始語料音高參數求取上較不準確，因此
在基頻的 RMSE 值較男性語料高。 
表 3.20: 基頻之 RMSE 值 
  內部測詴語料 外部測詴語料 
女性語料庫 37.35(Hz) 45.64(Hz) 
男性語料庫 16.08(Hz) 19.4(Hz) 
 
 37 
 
圖 3.7: 實驗之 MOS 比較 
 我們在男性模型的 MOS 表現都較女性 MOS 表現良好，這與客觀評估女性模型在
基頻的 RMSE 表現較差相對應，而加入停頓預估系統的實驗，不管是男性模型或女性
模型都比沒有加入停頓預估的合成語音分數高，顯示出我們在加入了停頓預估單元
後，能合成出較自然的語音。
 39 
實驗所使用的國語語音語料庫為 TCC300語料庫，語料庫是由台灣大學、成功大學、
交通大學各自擁有之語料庫集合而成，各校錄製之目的是為語音辨認研究，屬於麥克風
朗讀語音。其中台大語料庫主要包含詞及短句，文章經過仔細設計，考慮了音節及其相
連出現機率，由 100人錄製而成；成大及交大語料庫主要包含長文語料，文章由中研院
提供之 500萬詞詞類標示語料庫中選取，每篇文章包含數百字，再切割成 3至 4段，每
段含至多 231字，由 200人朗讀錄製，每人所讀文章皆不相同。詳細統計資訊如表 4.1
所示。 
 
表 4.1：TCC300 語料庫資訊統計表 
學校名稱 文章屬性 語者總數 總音節數 總檔案數 
台灣大學 
短文 
(平衡句) 
男 50 男 27,541 男 3,425 
女 50 女 24,677 女 3,084 
總計 100 總計 52,218 總計 6,509 
交通大學 長文 
男 50 男 75,059 男 622 
女 50 女 73,555 女 616 
總計 100 總計 148,614 總計 1,238 
成功大學 長文 
男 50 男 63,127 男 588 
女 50 女 68,749 女 582 
總計 100 總計 131,876 總計 1,170 
 
 客語語音語料庫 
台灣客家話有許多次方言，其中以四縣腔為最通行的腔調，本研究考量到客語的代
表性和實用性，因此選用客語人口最多的苗栗四縣客家話為發展國、客語語音辨認技術
的語料來源。以下所稱之客語皆為苗栗四縣客家話。 
實驗所使用的客語語音語料庫，為交通大學語音處理實驗室分四個時期錄製而成，
目的是為語音辨認研究，屬於麥克風朗讀語音。文章內容主要為客語故事[34]，主要由
苗栗的兩位退休教師，一位是龔萬灶老師、另一位為陳碧娥老師所撰寫；並加入中華大
學余秀敏老師所新增的客語文句。由 92 人朗讀錄製而成，詳細統計資料如表 4.2 所示。 
 
表 4.2：客語語音語料庫資訊統計表 
語者總數 總音節數 總檔案數 
男 43 男 70,193 男 4,627 
女 49 女 83,718 女 5,602 
總計 92 總計 153,911 總計 10,229 
 
 國客雙語語音語料庫 
實驗所使用的國客雙語語音語料庫，為交通大學語音處理實驗室錄製而成，目的是
為語音辨認研究，屬於麥克風朗讀語音。文句由中華大學余秀敏老師根據日常國客語夾
 41 
 一字詞 二字詞 三字詞 四字詞 五字詞 六字詞 七字詞 八字詞 總計 
詞條數 2,797 8,722 2,485 946 89 17 15 42 15,115 
詞頻 81,672 51,027 8,591 1,810 126 23 17 51 143,341 
 
(b) 人工標記詞性、國語翻譯的客語文章(以下稱為 textB) 
此文章來源為龔萬灶老師撰寫的客語文集，並且經由余秀敏老師人工標記詞類及國
語翻譯資訊而成，其文章內容為客語故事。使用的詞類標記共有 49 類，詳細詞類標記
資訊如附錄三；此文章帄均一個客語詞條有 1.14 個詞類標記、1.28 個國語翻譯。詳細統
計資訊如表 4.6 所示。 
表 4.6：人工標記客語文章資訊統計表 
 一字詞 二字詞 三字詞 四字詞 五字詞 六字詞 七字詞 八字詞 總計 
詞條數 1,179 4,825 1,466 534 47 9 1 5 8,068 
詞頻 25,729 16,610 3,393 758 51 10 1 5 46,581 
平均翻譯數 1.90 1.19 1.15 1.07 1.00 1.00 1.00 1.00 1.28 
平均詞類數 1.53 1.09 1.05 1.02 1.00 1.00 1.00 1.00 1.14 
 
(c) 客語詞典(以下稱為 dict) 
此客語詞典收錄來源有三個：台北市客委會、行政院教育部及龔老師文集。此詞典
紀錄每個客語詞條的發音及詞類，帄均一個客語詞條有 1.33 個詞類標記。詳細統計資訊
如表 4.7 所示。 
 
表 4.7：客語詞典資訊統計表 
 一 二 三 四 五 六 七 八 總計 
詞條數 6,643 23,690 7,454 5,224 323 84 85 18 43,521 
平均 pos 數 2.42 1.16 1.08 1.06 1.04 1.01 1.00 1.00 1.33 
 
另外，此客語詞典收錄的部分客語詞條(26,524 個)有國語翻譯的對應，這部份的客
語詞條帄均有 1.12 個國語翻譯。此部份翻譯標記的收錄來源有台北市客委會及余老師人
工標記的客語文章。詳細統計資訊如表 4.8 所示。 
 
表 4.8：國客雙語對照詞典資訊統計表 
 一 二 三 四 五 六 七 八 總計 
詞條數 1,225 16,762 4,924 3,295 205 59 44 10 26,524 
平均翻譯數 1.94 1.09 1.08 1.03 1.00 1.00 1.00 1.00 1.12 
 
 43 
此部份是指客語詞條和國語翻譯的漢字使用上是不一樣，通常是客語特有用法或是
一字詞， 
例如： 
客語詞條： 三十暗晡 八月半  
國語翻譯： 除夕夜 中秋節 的 
 
表 4.9: TextB 之中國客翻譯之型態分析 
分類 數量(比例)  
相同 4,482(47.1%)  
相似 2,597(27.3%)  
不同 2,437(25.6%)  
Total  9,516  
 
4.2.2 客語與國語的詞類分析 
此部份是對上述人工標記的客語文章與國語文章(NCTIR及光華雜誌)觀察詞類標記
的分布情況，客語與國語詞類標記分布情形如圖 4.2 至圖 4.4 所示，我們可以看出客語
詞條和國語詞條在文章中，其詞類標記的所佔比例是非常近似的。因此本研究假設客語
文句的詞類標記和國語文句是相同的。 
 
 
圖 4.2：客語詞類與國語詞類標記分佈比較(1) 
 45 
表 4.10：客語語音語料庫統計 
 訓練語料 測試語料 
673 syllable 134,612 19,388 
總段落數 8,658 1,571 
 
表 4.11：國語語音語料庫統計 
 訓練語料 測試語料 
411 syllable 300,728 31,252 
總段落數 8,036 843 
 
 
表 4.12：國客語夾雜語音語料庫統計 
 客語為主 國語為主 合計 
1084 syllable 4,710 4,707 9,417 
總段落數 380 380 760 
 
4.3.2 聲學模型之建立 
(a) 特徵參數抽取 
 在訓練模型前，首先必頇獲得足以充分描述語音特性，且參數量較原語音信號小之
特徵參數，而在語音處理當中，最廣泛為人使用之特徵參數為梅爾頻率倒頻譜係數
(Mel-Frequency Cepstrum Coefficient, MFCC)，本研究也將使用此特徵參數，以 32 毫秒之
漢明窗(Hamming window)且每位移 10 毫秒為一筆資料，求取 12 維 MFCC 加上 1 維能量
係數，以及這 13 維係數之一階與二階變量(delta and delta-delta)為特徵參數，但單純的能
量在參數中較為缺乏鑑別性，因此除去能量係數，得到 38 維向量做為本研究語音資料
之聲學特徵參數。在本研究也將利用倒頻譜帄均值正規劃法 (Cepstrum Mean 
Normalization, CMN)藉此消除不同語音信號之通道效應。 
 
(b) 單語聲學模型之建立 
 由於使用 Flat Start 訓練聲學模型，此種做法必頇花費較久的時間才能得到正確的模
型，且語句較長時也容易發生模型位置錯誤之情況。因此本研究利用音節內右相關聲/
韻母模型(Right-context-dependent Initial / Final Model, RCD)對語音語料做音節的切割，再
根據音節的切割位置訓練單語聲學模型，其建立流程如圖 4.5 所示。 
 47 
 
(a) 單語音素集 
單語音素集是考量語言實際使用時的發音狀況，完整描述語言的特性定義而成。因
為國語和客語皆為漢語語系，音節結構都為聲母加上韻母，所以音素的定義也將音節結
構位置考慮進去，詳細如表 4.13 以及表 4.14。 
表 4.13：國語音素集 
聲母(21) 
韻母(17) 
介音
(3) 
元音
(8) 
韻尾
(4) 
空韻母(2) 
M_b M_n M_m M_yi1 M_e M_en M_FNULL1 
M_c M_p  M_yu1 M_eh M_ng M_FNULL2 
M_ch M_q  M_wu1 M_o M_yi3  
M_d M_r   M_a M_wu3  
M_f M_sh   M_er   
M_g M_s   M_yi2   
M_h M_t   M_yu2   
M_j M_x   M_wu2   
M_k M_z      
M_l M_zh      
 
表 4.14：客語音素集 
聲母(21) 
韻母(17) 
介音
(2) 
元音
(6) 
韻尾
(8) 
空韻母(1) 
H_HH H_m H_l H_yi1 H_a H_ek H_FNULL 
H_NH H_n  H_wu1 H_eh H_em  
H_b H_ng   H_ii H_en  
H_c H_p   H_o H_eng  
H_d H_q   H_wu2 H_ep  
H_f H_s   H_yi2 H_et  
H_g H_t    H_wu3  
H_h H_v    H_yi3  
H_j H_x      
H_k H_z      
 
(b) 音素直接合併 
 此部份是將國語音素集與客語音素集直接合併產生雙語音素集，此音素集共有 76
個音素，詳細如表 4.15 所示。 
 
 
 
 
 49 
    , , , ,
1
; ,
M
j i k t jm i k t jm jm
m
b O c N O 

   (4.4) 
m表示為
jb 這個 state 中第m 個 mixture， jmc 表示為 jb 這個 state 中第m 個 mixture 的
weight。最後，log-likelihood measurement 實作流程分為三個步驟，步驟如下： 
步驟 1：各自訓練國語及客語的音素模型，並對原始語料做音素的切割而得音素的段落
標記(forced alignment)。 
步驟 2：對於每一個國語或客語音素，以式(3.2)計算對另一種語言(客語或國語)音素的
log-likelihood measurement，也就是
,i jD 。 
步驟 3：根據計算出的
,i jD 及國客語一對一的原則做距離大小的排序。 
 
表 4.16 為根據 log-likelihood measurement 計算兩語言之間音素模型的距離，根據距
離及一對一做排序的動作。 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 51 
接著，根據相同漢語音標、相同音節結構位置以及距離大小後，決定合併 22 個音素，
其中聲母有 14 個、介音 1 個、元音 5 個以及韻尾 2 個。詳細如表 4.17 以及 4.18 所示。 
 
表 4.17：雙語音素集，C_表示合併後的音素 
聲母(28) 
韻母(26) 
介音
(4) 
元音
(9) 
韻尾
(10) 
空韻母(3) 
C_b C_s H_v C_yi1 C_a C_eng H_FNULL 
C_c C_t M_ch H_wu1 C_eh C_en M_FNULL1 
C_d C_x M_g M_yu1 C_o H_ek M_FNULL2 
C_f C_z M_k M_wu1 C_wu2 H_em  
C_h H_HH M_q  C_yi2 H_ep  
C_j H_NH M_r  H_ii H_et  
C_l H_g M_sh  M_e H_wu3  
C_m H_k M_zh  M_er H_yi3  
C_n H_ng   M_yu2 M_wu3  
C_p H_q    M_yi3  
 
表 4.18：合併比率 
單位 
合併前 
合併後 共用比率 
國語 客語 合計 
Phone 38 38 76 54 40.7% 
Initial 21 21 42 28 50% 
Final 40 71 111 100 11% 
Syllable 411 673 1,084 1,008 7.5% 
 
4.4 客語語言模型 
4.4.1 基本客語語言模型 
基本客語語言模型是針對客語文章(textA)，使用統計的方式建立而成： 
  
 
 
 
   
1
1
11
1
,
                   , ,
|
    , 
textA i i
textA i i
textA ibaseline i i
baseline i baseline i
C w w
C w w k
C wP w w
w P w otherwise






 


 (4.5) 
及 
 
 
 
 
   , textA ibaseline i textA i
textA i
i
C w
P w C w k
C w
w
 

 
(4.6) 
 textAC 表示詞串在客語文章(textA)出現次數。 
 53 
        
 
|
i
pos i H i i H i
G w
P w P w G w P G w   (4.10) 
其中  iG w 表示客語詞條 iw 的詞類標記；     1|H i iP G w G w 和   H iP G w 表示客語詞
類模型；   1 1|H i iP G w w  和   |H i iP w G w 表示客語詞條與詞類標記的對應模型。 
 接著，將詳細介紹詞類模型及客語詞條與詞類標記的對應模型。首先是詞類模型，
詞類模型是根據人工標記的客語文章(textB)訓練而來，此模型記錄了詞類之間的轉移分
數： 
     
    
  
1
1
1
,
|
textB i i
H i i
textB i
C G w G w
P G w G w
C G w



  (4.11) 
和 
   
  
  
 i
textB i
H i
textB i
G w
C G w
P G w
C G w


 (4.12) 
而客語詞條與詞類標記的對應模型則是記錄了客語詞條與詞類的相互對應分數，此分數
有兩個來源，分別是由人工標記的客語文章以及詞典(dict)估算而來，其中人工標記的客
語文章的客語詞條與詞類的對應較為可靠，但是並不包含所有的客語詞條；而詞典則相
反，它包含了所有的客語詞條，但是其對應關係較不可靠，因為它僅記錄了客語詞條與
詞類的對應而已。所以這兩個對應分數，將對上述兩個來源做結合： 
   
     
     
  
 
|                            ,  ,
||
   ,  
i
textB i i textB i i
dict i i H iH i i
H
H i
G w
P G w w C w G w k
P G w w P G wP G w w
otherwise
P G w

 


 



 (4.13) 
其中，
  
  
  
,
|
1
|
i textB i i
i
textB i i
w C w G w k
H
textB i i
w
P G w w
P G w w

 
 


；k 為一個常數值，當對應次數大於 k 時將
直接使用人工標記的客語文章所估算的對應分數，反之則使用詞典內的分數。而另外一
個對應分數，因為客語的詞類標記僅分成 49 類，若直接估算   |H i iP w G w ，則會發生
資料量過於稀少的問題，所以此對應分數採用間接預估的方式計算： 
   
  
  
 
|
|
H i i
H i i baseline i
H i
P G w w
P w G w P w
P G w
  (4.14) 
其中  baseline iP w 表示基本客語語言模型的分數。 
 
 55 
翻譯的對應模型；   M iP G w 表示國語詞類模型的 unigram；  1TransP w 表示翻譯模型。
接著將對這四個模型做進一步的介紹。 
首先，因為國語有豐富的文字語料，所以國語詞條與詞類的對應模型及國語詞類模
型，都可以使用簡單的統計方式，就能建立不錯的模型： 
   
  
  
 i
textM i
M i
textM i
G M
C G M
P G M
C G M


 (4.18) 
及 
   
  
 
,
|
textM i i
M i i
textM i
C G M M
P G M M
C M
  (4.19) 
接著，客語詞條與翻譯的對應模型，這個對應模型記錄了客語詞條與翻譯的對應分
數，這個分數是根據人工標記的客語文章及詞典的翻譯對照估算而來的。其中人工標記
的客語文章的對應和詞類標記一樣較為可靠，但是並不包含所有的客語詞條；而詞典內
的詞條與翻譯對應的組合數較多，但是沒有對應次數的資訊。此分數是將這兩個來源做
結合： 
   
     
     
  
 
|                              ,  ,
||
 ,  
i
textB i i textB i i
textB i i Trans iT i i
T
Trans i
M w
P M w w C w M w k
P M w w P M wP M w w
otherwise
P M w

 


 



 (4.20) 
其中，
  
  
  
,
|
1
|
i textB i i
i
textB i i
w C w M w k
T
textB i i
w
P M w w
P M w w

 
 


。k 為一個常數值，當對應次數大於 k 時將
直接使用人工標記的客語文章所估算的對應分數，反之則使用詞典內的分數。 
最後翻譯模型，此模型記錄了國語翻譯的轉移分數。目前根據詞典內收錄的國語翻
譯與國語語言模型中詞頻最高的前 60,000 詞之對應關係，可分為三種情況，詳細統計資
訊如表 4.19 所示： 
表 4.19：國語翻譯與 60,000 詞分布情況 
分類 
詞條 
數量 比率 
Case 1 14,636 57.3% 
Case 2 9,487 37.1% 
Case 3 1,419 5.6% 
合計 25,532  
 
 
 57 
(c) 由國語語言模型資訊建立語言模型(Stage3) 
這個階層主要目的是藉由詞典翻譯直接使用國語語言模型中的詞條資訊。此階層將
針對表 4.19 中前後客語詞條的翻譯皆為 Case 1 的情況，做複製國語詞條轉移分數的的
動作： 
             
   1
1 1 1 1
,
| | | |
i i
Trans i i T i i M i i T i i
M w M w
P w w P w M w P M w M w P M w w

      (4.23) 
其中   |T i iP w M w 及   1 1|T i iP M w w  為客語詞條與翻譯的對應模型；
    1|M i iP M w M w  為國語語言模型，前後翻譯均為前 60,000 詞。 
表 4.20：Stage 3 客語語言模型混淆度估測 
語言模型權重參數 
(pos , trans) 
混淆度評估 
(perplexity) 
訓練語料 測試語料 
(1 , 0) 979 1,320 
(0.95 , 0.05) 1,229 1,725 
(0.9 , 0.1) 1,238 1,730 
(0.8 , 0.2) 1,230 1,756 
(0.7 , 0.3) 1,251 1,796 
 
4.5 雙語語言模型 
此節是針對日常生活中國客語夾雜使用情況而設計語言模型，目前僅考量以客語為
背景語言的語音辨認。此類型的語者所使用到的國語詞彙通常是專有名詞或較為新穎的
詞彙，穿插在客語文句之中。 
例如： 
頭擺人毋知麼 安到《網路遊戲》 
《摩托車》要買較大台 正會較穩 
其中《》內的文句為國語。 
因為，目前並無大量此類型的雙語文字，所以本研究是針對實驗所用的雙語語音語
料中國語語音和客語語音所佔的比例及出現的國語詞彙做語言模型的設計。 
 
雙語
語音語料
客語
語言模型
Adaptation
雙語
語言模型
 
圖 4.9：雙語語言模型建置流程圖 
 59 
(2) 雙語語言模型：Stage1 至 Stage3 對於目標語料的混淆度，依照資訊的增量增
加而降低。 
(3) Stage2 與 Stage3 的差異：對客語的測詴語料而言，其混淆度 Stage3 明顯高於
Stage2；但是，在雙語的測詴語料，其混淆度卻是相反的。此部份辨認率有待
觀察。 
 
4.6 實驗結果及討論 
 此節將介紹本研究所有的實驗設定及結果，並加以分析及討論。 
 
4.6.1 聲學模型實驗 
一般來說聲學模型之效能是直接由辨認率來評估，故本研究將對所建立之雙語混合
聲學模型(Mix)、國語聲學模型(M)、客語聲學模型(H)及國客語直接合併之雙語聲學模型
(H+M)等四個聲學模型做辨認率的比較，表 4.22 為各個模型的 GMM 數量。  
表 4.22：模型 mixture 數量 
Model Unit Mixture 
H RCD-I/F 19,813 
H Tri-ph. 19,784 
M Tri-ph. 52,807 
Mix Tri-ph. 52,627 
H+M Tri-ph. 72,591 
 
接著，依照測詴語料的不同做以下三種實驗：分別是客語的音節辨認率比較、國語
的音節辨認率比較及雙語之音節辨認率比較。 
 客語音節辨認率之比較 
表 4.23：不同聲學模型、待辨認音節對於客語測詴語料之音節辨認率比較 
Model Unit Syllable Text Cor. Acc. Del. Sub. Ins. Total 
H RCD-I/F H H 51.36 50.18 598 8,789 228 19,299 
H Tri-ph. H H 53.52 52.31 557 8,413 234 19,299 
Mix Tri-ph. H H 52.16 50.87 580 8,652 250 19,299 
H+M Tri-ph. H+M H 49.99 48.57 541 9,111 274 19,299 
Mix Tri-ph. Mix H 43.43 42.20 592 10,326 237 19,299 
 
由表 4.23 可以看出雙語混合聲學模型(Mix)與客語聲學模型(H)之音節辨認率比較
時，雙語混合聲學模型之音節辨認率介於客語 RCD-I/F聲學模型和客語 Tri-phone聲學
模型之間，所以雙語混合聲學模型對於客語音節的辨認率算是合理。 
 61 
最後，對雙語測詴語料做音節辨認率的比較，此語料完全是測詴語料，使用此語料
做音節辨認率的比較將會更為客觀。此部份主要是對雙語混合聲學模型與直接合併之雙
語聲學模型的音節辨認率之比較，詳細辨認率如表 4.26 所示 
 
表 4.26：不同聲學模型對於雙語測詴語料之音節辨認率比較 
Model Unit Syllable Text Cor. Acc. Del. Sub. Ins. Total 
H+M Tri-ph. H+M Mix 30.60 28.76 239 6,296 174 9,417 
Mix Tri-ph. Mix Mix 37.58 36.75 331 5,547 78 9,417 
 
由表 4.26 中的辨認率可發現當使用雙語語料做辨認時，雙語混合聲學模型的辨認率
明顯優於直接合併之聲學模型，這也是本研究所期望的結果。推測造成此原因應該是直
接合併之聲學模型對於兩語言中相似音節置換性錯誤問題十分嚴重。 
 
4.6.2 客語語言模型實驗 
此章節將特別針對客語語言模型做辨認率的比較，以評估語言模型的效能。目的在
於比較各個階層的所考量的資訊對於客語語音辨認的幫助。 
由於實驗要比較的是客語語言模型，所以此實驗之聲學模型設定為一個模型數量較
少的客語聲學模型來進行客語語言模型實驗，以加快實驗速度。 
選用的客語聲學模型為音節內右相關聲 /韻母模型 (Right-context-dependent 
Initial/Final Model, RCD)，每一個聲母之 HMM 模型採用 3 個由左至右(left-to-right)的狀
態(state)表示，而韻母之 HMM 模型則採用 5 個狀態來表示。其中每一個狀態以帄均 32
個高斯分布之高斯混合模型(Gaussian Mixture Model, GMM)描述其特徵參數之分布，聲
學模型之 HMM 設定及音節辨認率如表 4.27 及表 4.28 所示。 
表 4.27：HMM 模型之設定 
HMM 模型類別 狀態個數 模型數量 
Right-context-dependent Initial 3 87 
Final 5 71 
Silence 3 1 
Short pause 1 1 
 
表 4.28：RCD 聲學模型音節辨認率 
Correc
t 
Accuracy Deletion Substitution Insertion Total 
51.38 50.19 601 8,801 230 19,338 
 
接著，將使用上述的聲學模型對各階層的客語語言模型計算辨認率，第一個階層為加
入客語詞類資訊、第二個階層為加入國語詞類資訊、第三個階層為加入國語語言模型資
訊。詞、字元及音節辨認率分別如表 4.29、表 4.30 及 4.31 所示。 
 63 
40.79
58.99
66.29
42.99
60.79
68.63
44.45
62.17
69.07
44.56
62.12
69.18
0
10
20
30
40
50
60
70
80
Word Character Syllable
A
c
c
u
ra
c
y
(%
)
Baseline Stage 1 Stage 2 Stage 3
 
圖 4.10：客語語言模型辨認率 
 
由圖 4.10 客語語言模型辨認率，可以看出客語基本語言模型再加入了客語詞類資訊
後，不管是詞、字元還是音節辨認率，均明顯的提升，其中詞辨認率提升了 2.2%。而
再加入國語詞類資訊後詞的辨認率較 Stage1LM 提升了 1.46%。對於客語辨認而言，不
管是使用客語或國語的詞類資訊，對於最後的辨認結果都有明顯的改善，如此也證明了
國語與客語在文法結構上確實十分相似。 
接著分析詞類資訊對於哪些詞條的辨認率有顯著幫助，所以將比較各個詞條從
baseline 語言模型至 Stage 1 及 Stage 2 語言模型的辨認率，普遍詞條的辨識率皆有上升，
圖 4.11 為明顯提升的詞條。 
0.00 
10.00 
20.00 
30.00 
40.00 
50.00 
60.00 
70.00 
80.00 
90.00 
放
一
儕 再 較 也 盡 打
之
間
一
路 同 等 肚 想 行 就
阿
哥 坐 佢 先
毋
好 愛
A
c
c
u
ra
c
y
(%
)
baseline stage1 stage2
 
圖 4.11：詞類標記明顯幫助的詞條之 TOP20(詞條次數大於 15 次) 
 以詞性為單位，去觀察詞條的辨識率提升狀況： 
 65 
 
表 4.32：雙語辨認率之比較 
AM LM Unit Cor. Acc. Del. Sub. Ins. Total 
Mix 
None Syllable 37.58 36.75 331 5,547 78 9,417 
Bilingual 
(Stage 2) 
Word 40.15 37.16 349 1,413 88 2,944 
Character 56.03 54.33 137 1,934 80 4,710 
Syllable 57.98 56.24 140 1,839 82 4,710 
Bilingual 
(Stage 3) 
Word 41.58 37.84 303 1,417 110 2,944 
Character 57.15 55.27 126 1,892 89 4,710 
Syllable 58.13 56.14 131 1,841 94 4,710 
H+M 
None Syllable 30.60 28.76 239 6,296 174 9,417 
Bilingual 
(Stage 2) 
Word 25.44 21.33 463 1,732 121 2,944 
Character 40.08 34.86 134 2,688 246 4,710 
Syllable 43.42 38.09 140 2,525 251 4,710 
Bilingual 
(Stage 3) 
Word 26.12 21.98 443 1,732 122 2,944 
Character 40.83 35.61 142 2,645 246 4,710 
Syllable 43.84 38.47 150 2,495 253 4,710 
 
表 4.33：雙語語音辨認之詞辨認率分析 
AM LM 
比率%(個數) 總數 
客語正確率 國語正確率 客 -> 國 國 -> 客 客語 國語 
H+M 
Bilingual 
(Stage 2) 
28.56 (630) 16.12 (119) 1.04 (23) 72.49 (535) 2,206 738 
Bilingual 
(Stage 3) 
29.10 (642) 17.21 (127) 1.04 (23) 71.82 (530) 2,206 738 
Mix 
Bilingual 
(Stage 2) 
34.09 (752) 58.27 (430) 2.22 (49) 32.25 (238) 2,206 738 
Bilingual 
(Stage 3) 
35.86 (791) 58.67 (433) 1.99 (44) 33.06 (244) 2,206 738 
 
由上表，可觀察出 Stage 3 語言模型對於 Stage 2 而言，詞辨認率相對提高。且 Mix 聲學
模型對於國語的辨認有極大的幫助，推測因為欲辨認之文句皆是以客語為主文句，所以
造成 H+M 聲學模型辨認國語詞條容易辨認成客語詞條。接著，觀察其音節辨認的辨認
狀況： 
 67 
在雙語語音辨識的時候，Stage3 語言模型效能明顯比 Stage2 語言模型佳。接著，對聲學
模型的比較，如圖 4.14 所示： 
55.15
17.78
55.15
19.13
55.15
64.16
55.15
64.64
0
10
20
30
40
50
60
70
Hakka(Stage2) Mandarin(Stage2) Hakka(Stage3) Mandarin(Stage3)
S
y
ll
a
b
le
 A
c
c
u
ra
c
y
(%
)
H+M Mix
 
圖 4.14：不同聲學模型對於雙語語音辨認之辨認率比較 
 
對於 H+M 聲學模型與 Mix 聲學模型而言，不管是使用 Stage2 語言模型或 Stage3 語
言模型，對於國語音節的辨認率都有大幅提升，但是客語音節的辨認率沒有變化。Mix
聲學模型對於幫助非主語的詞彙，有顯著的幫助。 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 69 
六、 結論與未來發展 
6.1 結論 
在客語文字轉語音系統部分，我們實現了單機版的四縣客語文字轉語音系統，其系
統包含分詞與詞性標記單元、停頓預估單元以及基於HMM之語音合成器。在整個實作
過程中，我們得到了以下結論： 
1. 客語語料的取得是非常不容易的，因此我們在客語斷詞系統部分無法訓練客語專屬
分詞及詞性標記條件隨機域模型，本研究利用國語和客語有相同語言特性的特點，
在中文斷詞系統中加入客語外掛詞典以及客語規則，完成一套客語斷詞系統。 
2. 本研究在TTS系統中加入了預估詞後是否有停頓的單元，停頓預估的加入能讓合成
語音在韻律表現上更加自然。 
3. 由基於HMM之語音合成器所合成的客語語音在客觀及主觀評估上都有不錯的表
現，這對於客語TTS系統應用在本土語言學習中是一大幫助。 
 
在建立客語和國客夾雜語音辨認系統方面，使用國語及客語單語言的語音及文字語
料庫，訓練一個可做為國語、客語及國客語混合語音辨認的系統。也改善了原本客語的
單語言辨認系統，使用了客語詞類資訊、國語辭類資訊及國語語言模型資訊來強化原本
客語語言模型。根據各項實驗數據及研究過程，針對客語語音辨認系統及雙語語音辨認
系統歸納出以下幾項重點與成果： 
 客語語言模型：取得大量的客語文章其實是非常困難的，所以首要目標應是增加
國語與客語的對譯詞典，使用本計畫所提出的方法，利用國語語言模型的資訊幫
助客語語言模型的建立。 
 雙語音素集的定義：本計畫提出不同語言音素合併的規則，根據定義的音素結構
位置、相同的漢語音標對應及同種語言音素不合併等。相信對於雙語辨認會有不
錯的效果，且經由辨認可以發現音節辨認率明顯提升，尤其是對於非主要語語言。 
 雙語語言模型：目前對於非主要語言的國語詞彙，僅使用一個詞群做分類，給予
相同的轉移機率。相信這方面可以更改為使用詞類標記資訊，做為語言轉換時的
分數，因為由實驗可數據可看出國語詞彙與客語詞彙的詞類標記是極為相似的。 
漢語語系語言辨認系統：相信本研究所提出的方法，可以再應用於其他腔調的客家
話及台語，因為其文法結構及漢字特性都與國語十分相像。 
6.2 未來展望 
有以下幾點可以提供未來繼續深入探討並改進的方向： 
1. 雖然目前在客語詞典的收錄已有一定的數量，但是跟中文詞典和文章數比貣來還是
非常少，我們希望能在客語詞典中收錄中文對照翻譯之資訊，進而從斷詞系統中訓
 71 
[14] D. H. Klatt, "Review of Text-to-Speech Conversion for English,‖ J. Acoust. Soc. 
Am.,vol.82, no.3, pp.137-181, Sept. 1987. 
[15] R. Sproat, Multilingual Text-to-Speech Synthesis: The Bell Labs Approach, Kluwer 
Academic Publishers, 1998. 
[16] Fu-Chiang Chou, Chiu-Yu Tseng, Lin-Shan Lee, ―A Set of Corpus-Based 
Text-to-Speech Synthesis Technologies for Mandarin Chinese‖, IEEE Transactions on 
Speech and Audio Processing, Volume 10, Issue 7, Oct 2002, pp. 481- 494. 
[17] S. H. Chen, S. H. Hwang, and Y. R. Wang, ―A Mandarin Text-to-Speech System,‖ 
Computational Linguistics and Chinese Language Processing, Vol.1, No.1, pp.87-100, 
August, 1996. [18] S. H. Chen, S. H. Hwang, and Y. R. Wang, ―An RNN-based 
Prosodic Information Synthesizer for Mandarin Text-to-Speech‖, IEEE Trans. Speech 
and Audio Processing, Vol.6, No.3, pp.226-239, May 1998. 
[18] Min Chu, Hu Peng and Eric Chang, ―A Concatenative Mandarin TTS System without 
Prosody Model and Prosody Modification,‖in Proc. of 4th ISCA Workshop on Speech 
Synthesis, Scotland 2001 
[19] Min Chu, Hu Peng, Yong Zhao, Zhengyu Niu and Eric Wang, ―Microsoft Mulan –A 
Bilingual TTS System,‖ICASSP 2003, 
[20] Min Chu, Hu Peng, Hong-yun Yang, Eric Chang, ―Selecting non-uniform units from a 
very large corpus for concatenative speech synthesizer‖, ICASSP 2001, Vol.2, 
SPEECH-L2.2, 2001. 
[21] Xuedong Huang, Alex Acero, Hsiao-Wuen Hon, Spoken Language Processing, 
Prentice-Hall, Inc. 
[22] Tseng, Chiu-yu, Pin, Shao-huang, Lee, Yeh-lin, Wang, Hsin-min and Chen, 
Yong-cheng (2005).―Fluent speech prosody: framework and modeling,‖ Speech 
Communication, Vol.46,issues 3-4,(July 2005), Spe cial Issue on Quantitative Prosody 
Modelling for Natural Speech Description and Generation, 284-309. 
[23] S.-H. Chen, W.-H. Lai, and Y.-R. Wang, ― A New Duration Modeling Approachfor 
Mandarin Speech,‖ IEEE Trans. On Speech and Audio Processing, vol. 11, no. 4, July 
2003. 
[24] Sin-Horng Chen, Wen-Hsing Lai and Yih-Ru Wang, ―A statistical pitch contour model 
for Mandarin speech,‖J. Acoust. Soc. Am., 117 (2), pp.908-925, Feb. 2005. 
[25] Hsi-Chun Hsiao, Hsiu-Min Yu, Yih-Ru Wang and Sin-Horng Chen, ―Multilingual 
Speech Corpora for TTS System Development‖, Int. Symp. on Chinese Spoken 
Language Processing, Dec. 2006, Singapore; and Lecture Note in Computer Science, 
Vol. 4274/2006, Chinese Spoken Language Processing, Springer, pp.748-759 (SCI) 
[26] Hsiu-Min Yu, Hsin-Te Hwang, Dong-Yi Lin and Sin-Horng Chen, ―A Hakka 
Text-to-Speech System‖, Int. Symp. on Chinese Spoken Language Processing, Dec. 
2006, Singapore; and Lecture Note in Computer Science, Vol. 4274/2006, Chinese 
Spoken Language Processing, Springer,pp.241-247 (SCI) 
 73 
 
附錄一 
四縣腔客語 671 個音節、17 個聲母、71 個韻母對照表 
音碼 拼音 子音 母音 音碼 通用 子音 母音 音碼 通用 子音 母音 
1 bi b i 30 bok b ok 59 piak p iak 
2 be b e 31 buk b uk 60 pok p ok 
3 ba b a 32 pi p i 61 piok p iok 
4 bia b ia 33 pa p a 62 puk p uk 
5 bo b o 34 pia p ia 63 mi m i 
6 bu b u 35 po p o 64 me m e 
7 biu b iu 36 pu p u 65 ma m a 
8 bai b ai 37 piu p iu 66 mia m ia 
9 boi b oi 38 pai p ai 67 mo m o 
10 beu b eu 39 poi p oi 68 mu m u 
11 bau b au 40 peu p eu 69 mai m ai 
12 bin b in 41 pau p au 70 moi m oi 
13 ben b en 42 pin p in 71 meu m eu 
14 bien b ien 43 pen p en 72 mau m au 
15 ban b an 44 pien p ien 73 miau m iau 
16 bun b un 45 pan p an 74 min m in 
17 bang b ang 46 pon p on 75 men m en 
18 biang b iang 47 pun p un 76 mien m ien 
19 bong b ong 48 pang p ang 77 man m an 
20 biong b iong 49 piang p iang 78 mun m un 
21 bung b ung 50 pong p ong 79 mang m ang 
22 bit b it 51 piong p iong 80 miang m iang 
23 bet b et 52 pung p ung 81 mong m ong 
24 biet b iet 53 pit p it 82 miong m iong 
25 bat b at 54 pet p et 83 mung m ung 
26 bot b ot 55 piet p iet 84 mit m it 
27 but b ut 56 pat p at 85 met m et 
28 bak b ak 57 put p ut 86 miet m iet 
29 biak b iak 58 pak p ak 87 mat m at 
 
 
 
 
 
 75 
 
音碼 通用 子音 母音 音碼 通用 子音 母音 音碼 通用 子音 母音 
175 duk d uk 204 tet t et 233 nap n ap 
176 ti t i 205 tiet t iet 234 nit n it 
177 te t e 206 tat t at 235 net n et 
178 ta t a 207 tot t ot 236 nat n at 
179 to t o 208 tut t ut 237 not n ot 
180 tu t u 209 tak t ak 238 nak n ak 
181 tiu t iu 210 tok t ok 239 nuk n uk 
182 tai t ai 211 tuk t uk 240 li l i 
183 toi t oi 212 ni n i 241 le l e 
184 tui t ui 213 ne n e 242 la l a 
185 teu t eu 214 na n a 243 lo l o 
186 tiau t iau 215 no n o 244 lio l io 
187 tiem t iem 216 nu n u 245 lu l u 
188 tam t am 217 niu n iu 246 liu l iu 
189 tiam t iam 218 nai n ai 247 lai l ai 
190 tin t in 219 nui n ui 248 loi l oi 
191 ten t en 220 neu n eu 249 lui l ui 
192 tien t ien 221 nau n au 250 leu l eu 
193 tan t an 222 niau n iau 251 lau l au 
194 ton t on 223 nem n em 252 liau l iau 
195 tun t un 224 nam n am 253 lim l im 
196 tang t ang 225 nin n in 254 lem l em 
197 tong t ong 226 nen n en 255 lam l am 
198 tiong t iong 227 nan n an 256 liam l iam 
199 tung t ung 228 non n on 257 lin l in 
200 tep t ep 229 nun n un 258 lien l ien 
201 tap t ap 230 nang n ang 259 lan l an 
202 tiap t iap 231 nong n ong 260 lon l on 
203 tit t it 232 nung n ung 261 lion l ion 
 77 
 
音碼 通用 子音 母音 音碼 通用 子音 母音 音碼 通用 子音 母音 
349 cau c au 378 cut c ut 407 sen s en 
350 ciau c iau 379 cak c ak 408 sien s ien 
351 ciim c iim 380 ciak c iak 409 san s an 
352 cim c im 381 cok c ok 410 son s on 
353 cam c am 382 ciok c iok 411 sun s un 
354 ciam c iam 383 cuk c uk 412 sang s ang 
355 ciin c iin 384 ciuk c iuk 413 siang s iang 
356 cin c in 385 sii s ii 414 song s ong 
357 cen c en 386 si s i 415 siong s iong 
358 cien c ien 387 se s e 416 sung s ung 
359 can c an 388 sa s a 417 siung s iung 
360 con c on 389 sia s ia 418 siip s iip 
361 cion c iong 390 so s o 419 sip s ip 
362 cun c un 391 sio s io 420 sep s ep 
363 cang c ang 392 su s u 421 sap s ap 
364 ciang c iang 393 siu s iu 422 siap s iap 
365 cong c ong 394 sai s ai 423 siit s iit 
366 ciong c iong 395 soi s oi 424 sit s it 
367 cung c ung 396 sui s ui 425 set s et 
368 ciung c iung 397 seu s eu 426 siet s iet 
369 cip c ip 398 sau s au 427 sat s at 
370 cap c ap 399 siau s iau 428 sot s ot 
371 ciap c iap 400 siim s iim 429 sut s ut 
372 ciit c iit 401 sim s im 430 sak s ak 
373 cit c it 402 sem s em 431 siak s iak 
374 cet c et 403 sam s am 432 sok s ok 
375 ciet c iet 404 siam s iam 433 siok s iok 
376 cat c at 405 siin s iin 434 suk s uk 
377 cot c ot 406 sin s in 435 siuk s iuk 
 79 
 
音碼 通用 子音 母音 音碼 通用 子音 母音 音碼 通用 子音 母音 
523 kong k ong 552 nguai ng uai 581 ngok ng ok 
524 kiong k iong 553 ngoi ng oi 582 ngiok ng iok 
525 kung k ung 554 ngui ng ui 583 ngiuk ng iuk 
526 kiung k iung 555 ngau ng au 584 hi h i 
527 kip k ip 556 ngieu ng ieu 585 he h e 
528 kep k ep 557 ngiau ng iau 586 ha h a 
529 kap k ap 558 ngim ng im 587 hia h ia 
530 kiap k iap 559 ngiem ng iem 588 ho h o 
531 kit k it 560 ngam ng am 589 hio h io 
532 kiet k iet 561 ngiam ng iam 590 hiu h iu 
533 kat k at 562 ngin ng in 591 hai h ai 
534 kut k ut 563 ngien ng ien 592 hoi h oi 
535 kiut k iut 564 ngan ng an 593 heu h eu 
536 kak k ak 565 nguan ng uan 594 hau h au 
537 kiak k iak 566 ngion ng ion 595 hieu h ieu 
538 kok k ok 567 ngiun ng iun 596 hiau h iau 
539 kiok k iok 568 ngang ng ang 597 him h im 
540 kuk k uk 569 ngiang ng iang 598 hem h em 
541 kiuk k iuk 570 ngong ng ong 599 ham h am 
542 kuak k uak 571 ngiong ng iong 600 hiam h iam 
543 ngi ng i 572 ngiung ng iung 601 hin h in 
544 ngie ng ie 573 ngip ng ip 602 hen h en 
545 nga ng a 574 ngap ng ap 603 hien h ien 
546 ngia ng ia 575 ngiap ng iap 604 han h an 
547 ngo ng o 576 ngit ng it 605 hon h on 
548 ngio ng io 577 ngiet ng iet 606 hiun h iun 
549 ngu ng u 578 ngat ng at 607 hang h ang 
550 ngiu ng iu 579 ngut ng ut 608 hong h ong 
551 ngai ng ai 580 ngiak ng iak 609 hiong h iong 
 81 
附錄二 
新增至客語詞典之一字多義一字詞表 
客語詞 詞性組合 客語詞 詞性組合 
個 DE 肚 Ncd_Ng 
愛 D_VC_VE 當 Dfa_P 
係 SHI 儕 Na_Nf 
等 Di_VC 同 Caa_P 
該 Dk_Ncd_Nep_T 歸 Nb_Neqa 
異 Dfa 畜 Na_VC 
到  Caa_P_VCL 摎 Caa_P 
正 Da_D 屋  Na_Nc_Nf 
項 Ncd_Nf_Ng 適 P_VJ 
食 Na_VC 歇 VA_VCL 
好 D_VH 驚  Na_VK 
逐 D_Nes 企 Nc_VA 
誒 Di_T_VJ 識 D_VJ 
盡 Dfa 喊 P_VA_VC_VE_VF_VG_VL 
分 P_VD_VL 供 VC_VH 
擺 Na_Nf_VC 奈 Ncd_Nep_VJ_T 
著 P_VC 遽 D_VH 
恁  D_Dfa_VD 忒 Dfa_Di_VCL_VH 
兜  Dfb_Nf 仰  D_VC_VH 
仔 DE_Na_Nf 
  
 
 
 
 
 
 
 83 
附錄四  
聲母音素問題集 
 國語 客語 
鼻音 M_m, M_n H_m, H_n, H_ng, H_NH 
塞音 
M_p, M_t, M_ch, M_c, M_k, M_b, 
M_d, M_g, M_q 
H_p, H_t, H_c, H_k, H_b, H_d, H_g, 
H_q 
塞音清 M_p, M_t, M_ch, M_c, M_k H_p, H_t, H_c, H_k 
塞音濁 M_b, M_d, M_g, M_q H_b, H_d, H_g, H_q 
擦音 
M_f, M_s, M_sh, M_x, M_h, M_z, 
M_zh 
H_f, H_s, H_x, H_HH, H_h, H_v, H_z 
擦音清 M_f, M_s, M_sh, M_x, M_h H_f, H_s, H_x, H_HH, H_h 
擦音濁 M_z, M_zh H_v, H_z 
近音 M_j H_j 
邊近音 M_l H_l 
閃音 M_r  
唇 M_m, M_p, M_b, M_f H_m, H_p, H_b, H_f, H_v 
雙唇 M_m, M_p, M_b H_m, H_p, H_b 
唇齒 M_f H_f, H_v 
齦音 
M_n, M_t, M_d, M_s, M_z, M_l, 
M_r 
H_n, H_t, H_d, H_s, H_z, H_l 
捲舌 M_ch, M_sh, M_zh  
硬顎 M_c, M_j H_c,H_j 
 M_k, M_g, M_x, M_q H_ng, H_k, H_g, H_x, H_NH, H_q 
軟顎 M_k, M_g, M_x H_ng, H_k, H_g, H_x 
小舌 M_q H_NH, H_q 
 M_h H_HH , H_h 
會厭  H_HH 
聲門 M_h H_h 
客語韻母音素問題集(依照韻母結構設定問題) 
元音 H_a H_ek, H_em, H_en, H_eng, H_ep, H_et, H_wu3, H_yi3 
元音 H_eh H_em, H_en, H_ep, H_et, H_wu3 
元音 H_ii H_em, H_en, H_eng, H_ep, H_et 
元音 H_o H_ek, H_en, H_eng, H_et, H_yi3 
元音 H_yi2 H_em, H_en, H_ep, H_et 
介音 H_wu1 H_en, H_et 
介音 H_yi1 H_ek, H_em, H_eng, H_ep, H_wu3 
韻尾 H_ek 
H_a, H_o, H_wu1, H_wu2, H_yi1 
H_wu1, H_yi1 
H_a, H_o, H_wu2 
韻尾 H_em 
H_a, H_eh, H_ii, H_yi1, H_yi2 
H_yi1 
H_a, H_eh, H_ii, H_yi2 
韻尾 H_en H_a, H_eh, H_ii, H_o, H_wu1, H_wu2, H_yi1, H_yi2 
 85 
附錄五 
發表之論文依序為 
[1] Yi-Ling Tsai, Hsiu-Min Yu, Yih-Ru Wang, Chen-Yu Chiang, Lieh-Shih Lo, and 
Sin-Horng Chen, ―An HMM-based Hakka Text-to-Speech System,‖ accepted by 
OCOCOSDA 2010. 
[2] Tsai-Lu Tsai, Chen-Yu Chiang, Hsiu-Min Yu, Lieh-Shih Lo, Yih-Ru Wang and 
Sin-Horng Chen, ―A Study on Hakka and Mixed Hakka-Mandarin Speech Recognition,‖ 
accepted by ISCSLP 2010. 
[3] 余秀敏,―客語啊時貌之間的關係探討‖, 第八屆台灣語言及其教學國際研討會論文
集, pp. 216~227. 
synthesizer produces duration, pitch, and spectral 
parameters to generate the output synthesized speech. 
In the following, we discuss each part in more detail. 
 
2.1 The Hakka Parser 
In this study, we adopt a new approach to 
constructing the Hakka parser because we do not have 
a large text corpus to train a robust Hakka parser. The 
Hakka parser is an extended version of an existing 
Conditional Random Field [5] (CRF)-based Chinese 
parser attaching with a Hakka dictionary and 
incorporating with some Hakka word construction rules. 
The use of this approach is motivated by the fact that 
Hakka is a dialect of Mandarin Chinese so as to share 
many linguistic properties of Chinese, including using 
the same Chinese character set, using many Chinese 
words, and having a similar syntactic structure. An 
analysis of a well-tagged Hakka text corpus, which 
consists of many short articles of stories with total size 
of 63,158 syllables, reveals that the percentage of using 
Chinese words is as high as 48.97%. So, a Chinese 
parser can be used to assist in tagging Hakka texts, 
especially for processing those words commonly used 
in both Chinese and Hakka languages. As for the words 
with different form, we attach a Hakka dictionary and 
incorporate some Hakka word construction rules to 
process them. 
Figure 1 displays a block diagram of the proposed 
Hakka parser. It consists of five parts, including 
symbol normalization, word segmentation, POS tagger, 
word construction and grapheme to phone. Since the 
proposed Hakka parser is an extended version of an 
existing Chinese parser, we first introduce the Chinese 
parser and then describe its extension to Hakka 
language in the following. 
2.1.1 The CRF-based Chinese Parser 
2.1.1.1 Symbol normalization 
Since the Chinese parser takes BIG5 tokens to 
process word segmentation, the symbol normalization 
converts the format of input character sequence from 
ASCII to BIG5. Besides, it normalizes various BIG5 
codes of each punctuation mark (PM) type to a single 
representative BIG5 code. 
2.1.1.2 Word segmentation and POS tagging 
Word segmentation and POS tagging can be 
formulated by 
* *
,
,
, arg max ( , | )
          arg max ( | , ) ( | )
W S
W S
W S P W S C
P S W C P W C


                      (1) 
where W , S  and C  represent word, POS and 
character sequences, respectively; ( | )P W C  and 
( | , )P S W C  are correspondingly word segmentation 
and POS tagging model. In this study, both word 
segmentation and POS tagging models are 
implemented by the technique of Conditional Random 
Field (CRF) [5,6]. To simplify the decoding process in 
Eq. (1), top-N (N=3 in this study) word segmentation 
sequences are firstly generated by ( | )P W C  and then 
rescored by ( | , )P S W C . 
POS Tagger
Word Segmentation
Word construction
Chinese Lexicon
Hakka Lexicon
Character sequence
Symbol 
Normalization
Character sequence
Top-N Candidates 
of word sequence Words/POSs
Words/POSs sequence
Word construction Rules
Words/POSs sequence
Grapheme to phone
Word/POS Sequence, and phonetic/phonological label
Pronunciation dictionary 
 
Fig.1: A block diagram of the proposed Hakka parser. 
The CRF-based word segmentation can be viewed 
as a label-tagging problem. The word sequence W  is 
expressed by a tag sequence Y that represents character 
positions in words. In this study, a six-tag label set [6] 
that includes B1 (1
st
 character in a word), B2 (2
nd
 in a 
word), B3 (3
rd
 in a word), M (middle in a word), E (end 
in a word), and S (single character word) is utilized. 
Hence, the CRF-based word segmentation model is 
expressed by 
1
1 1
( | ) ( | )
1
exp ( , , )
( )
T I
i i t t
t i
P W C P Y C
f Y y Y C
N C
 
 

 
  
 

                    (2) 
where ( )N C  is a normalization factor to ensure 
( | ) 1
Y
P Y C  ; I represents the number of feature 
functions; and 1( , , )i t tf Y y Y C  is a feature function 
defined by 
1
1,  if  is satisfied and  
( , , )
0,  otherwise
j k
i t t
C h y y
f Y y Y C
 
 

  (3) 
where jh  represents the j-th possible feature context; 
ky  is the k-th possible tag to be labeled. Generally, 
feature contexts are organized into several groups, 
CRF-based pause predictor is constructed with the 
targets of the two classes (SP existence and SP absence) 
and the contextual linguistic features around the current 
word juncture. The feature and template set used to 
construct the CRF-based pause predictor is summarized 
in Table5. In the test phase, the existence/absence of 
SP on each word juncture is determined by the well-
trained CRF-based predictor using the input linguistic 
features. Then, the SP labels to be used in the HTS 
synthesizer are formed. 
Table 3: The set of word construction rules commonly 
used for Chinese and Hakka languages. 
word construction rules 
Chinese 
example 
Hakka 
example 
XXY(Z) 說說看 日日大 
X-XY-Y 乾乾淨淨 洗洗湯湯 
V+了/著/過/看/看看 想過 歇過 
名詞後詞綴：氏/度/性/家/長/師/
員/們/子/倆  
女性朋友們 細妹伴仔 
排行:數字＋姐/妹/哥/弟/伯/叔/姑 二伯 二伯 
VG+為/成/作/不了/得了  身為 身為 
Table 4: The set of parallel word construction rules 
used respectively for Chinese and Hakka languages. 
Chinese word 
construction 
rules 
Chinese 
example 
Hakka word 
construction 
rules 
Hakka 
example 
V+不+到/起/出 看不起 V+毋+到/起/出 看毋起 
越+來+越 越來越少 緊+來+緊 緊來緊少 
越+ X+越+Y 越穿越多 緊+ X+緊+Y 緊著緊多 
VB/VH+不休/兮
兮/不絕/不下/不
得/開來 
蜿蜒不絕 V+毋得 捨毋得 
老/小/阿+Na 小妹妹 細+Na 細妹仔 
2.4 Context Analyzer 
The context analyzer is designed to form the 
labels representing the contextual linguistic information 
for each HMM synthesis unit by using the outputs of 
the Hakka parser. In the study, syllable initials, syllable 
finals, and SP are taken as the basic synthesis unit. In 
the training of HTS, the labels hence contain the 
initial/final-level segmentation information, the 
contextual phonetic information, and some word-level 
and sentence-level linguistic features. Table 6 lists the 
labels generated by the context analyzer. In the test 
phase, the labels contain the same information as in the 
training phase, except for the two labels indicating the 
beginning/end timing information of HMM units 
because these two labels refer to HMM synthesis units’ 
durations to be predicted by the duration model in HTS. 
Table 5: Features and templates used in the CRF-based 
SP predictor. 
Feature description 
nPM  Pronunciation mark following word n 
nWL  Word length in syllable of word n 
nPOS  POS of word n 
nI  Initial type of the first syllable in word n 
nF  Final type of the last syllable in word n 
Template 
1nPM  , nPM , 1nPM  ,
1
1
n
nPM

 , 2
n
nPM   
2nWL  , 1nWL  , nWL , 1nWL  , 2nWL  ,
2
2
n
nWL

  
1nPOS  , nPOS , 1nPOS   
1nI  , nF ,( 1nI  + nF ),( nPOS + 1nI  + nF ) 
 
Table 6: The labels generated by the context analyzer. 
T1/T2 Beginning/end times of HMM unit 
p1/p2/p3 
Previous(PRE)/current(CUR)/following(FOL) 
Initial/Final/SP 
t1/t2/t3 Lexical tones of PRE/CUR/FOL syllable  
w1/w2 
Syllable position in a lexical word (LW) 
(forward/backward) 
s1/s2 
Syllable position in a sentence 
(forward/backward) 
PM Punctuation mark after the current syllable 
w3/w4/w5 Lengths of PRE/CUR/FOL LWs in syllable 
P1/P2/P3 POSs of PRE/CUR/FOL LWs 
s3/s4/s5 Lengths of PRE/CUR/FOL sentences in syllable 
 
2.5 HMM-based Speech Synthesizer 
The standard context-dependent HMM training for 
speech synthesis [4,5] is adopted here to 
simultaneously construct spectral, f0 and state duration 
models using the labels generated by the context 
analyzer and SP predictor. Five-state left-to-right 
HMMs are used to model each synthesis unit of 
syllable initial and final. Speech signal is converted 
into 24-dimensional mel-generalized cepstral (MGC) 
sequence in 5ms interval. The question set used for the 
decision-tree based context clustering of HMMs is 
formed by using the context labels. To achieve a better 
tree clustering result, we merge some individual 
linguistic features to form several complex questions 
according to their effects on spectral and prosody 
productions. For examples, the initial/final types are 
classified by the manner or place of articulation; lexical 
tones are tied according to their F0 level in the syllable 
the one using the proposed CRF-based pause predictor. 
The number of subjects involved in the test was ten 
(five females and five males). All the subjects’ mother 
tongues are Hakka. Utterances of ten sentences in the 
test set were chosen. The shortest and longest sentences 
had 20 and 72 characters, respectively. Subjects were 
requested to grade each test utterance in a five-level 
mean opinion score (MOS) as shown in Table 11. 
Table 11: Five-level MOS 
MOS 5 4 3 2 1 
Quality Excellent Good Fair Poor Bad 
 
Figure 2 displays the experimental results. It can be 
found from the figure that the system with the CRF-
based pause predictor performed better than the 
baseline system. We also find that the male voices 
sounded much more natural than the female voices. 
This is mainly resulted from the higher quality of the 
training dataset of the male speech. 
 
2
3
4
CRF-based pause predictor PM
Male Female
 
Fig. 2: MOSs of two TTS systems. 
 
4. Conclusion 
The design and implementation of an HMM-
based Hakka TTS system is presented in this paper. 
This study focuses on the realization of a reliable 
Hakka parser based on an existing CRF-based Chinese 
parser. Experimental results showed that the proposed 
Hakka parser is effective as we incorporate some 
Hakka word construction rules and attach a Hakka 
lexicon to the Chinese parser. Furthermore, the 
naturalness of the synthesized speech was improved by 
using a CRF-based pause predictor. Further study to 
use more Chinese language information to assist in 
improving the Hakka parser is worth doing in the future. 
 
ACKNOWLEDGMENT 
This work was supported by NSC of Taiwan under 
contract NSC98-2221-E-009-075-MY3. The authors 
would like to thank the Council for Hakka Affairs and 
MOE of Taiwan, H. M. Yu, and W. Z. Gong for 
supplying the lexicon and the text corpus. 
 
References 
[1] Wei-Chih Kuo, Xiang-Rui Zhong, Yih-Ru Wang and 
Sin-Horng Chen, “A High-Performance Min-Nan/ Taiwanese 
TTS System”, ICASSP2003. 
[2] Hsiu-Min Yu, Lie-Shih Lo, Hsin-Te Hwang, Hsi-Chun 
Hsiao, and Sin-Horng Chen, “On Constructing Speech 
Corpus for Implementing Hakka Text-To-Speech Synthesis,” 
OCOCOSDA, Dec. 2007. 
[3] H. Zen, T. Nose, J. Yamagishi, S. Sako, T. Masuko, A.W. 
Black, K. Tokuda, The HMM-based speech synthesis system 
version 2.0, Proc. of ISCA SSW6, Bonn, Germany, Aug. 
2007. 
[4] T. Yoshimura, K. Tokuda, T. Masuko, T. Kobayashi, T. 
Kitamura, Simultaneous modeling of spectrum, pitch and 
duration in HMM-based speech synthesis, Proc. of 
Eurospeech, pp.2347-2350, Sept. 1999. 
[5] J. Lafferty, A. McCallum, and F. Pereira. “ Conditional 
random fields: Probabilistic models for segmenting and 
labeling sequence data”, In Proc. of ICML, pp.282-289, 2001. 
[6] Hai Zhao, Chang-Ning Huang, and Mu Li, “An Improved 
Chinese Word Segmentation System with Conditional 
Random Field”, Proceedings of the Fifth SIGHAN 
Workshop on Chinese Language Processing (SIGHAN-5), 
pp.162-165, Sydney, Australia, July 22-23, 2006. 
[7] Hsu, Hui-li and Chu-Ren Huang, 1995. Design Criteria 
for a Balanced Modern Chinese Corpus. Proceedings of 
ICCPOL'95, Hawaii. 
[8] Wan-Zao Gong, The Taiwan Hakka Literature 
Collections (Global, Taipei, Taiwan, 2004), in 
Chinese/Hakka. 
 
  
reads 37 utterances in average. The mixed Hakka-Mandarin 
speech corpus is used to conduct a test of mixed 
Hakka-Mandarin speech recognition. It is generated by 19 
speakers and each speaker uttered 40 utterances in average. Its 
texts are mainly written in Hakka and embedded with 
Mandarin words in a ratio of 2206/738. Table 1 summarizes 
the main information about the speech corpora mentioned 
above. 
Table 1.  SUMMARY OF SPEECH CORPUS 
Corpus No. of Speakers No. of Syllables 
Hakka (H) 
Training 68 134,612 
Test 24 19,388 
Mandarin (M) Train 300 332,708 
Mixed H-M Test 19 4,710 
B. Text corpora 
The text corpora used in this study can be divided into two 
parts: Mandarin and Hakka. The Hakka part consists of the 
following three types of texts:  
 TextA: It contains many short articles collected from 
Internet. It is word-segmented by an automatic word 
matching algorithm [8] with the Dict lexicon discussed 
below. 
 TextB: It is a Hakka-Chinese parallel-text corpus. It is 
constructed by firstly selecting Hakka articles from the 
book „The Taiwan Hakka Literature Collections‟ [7], then 
tagged into word and POS sequences, and lastly translated 
into Chinese text by a Hakka expert. 
 Dict: It is a 43,521-word Hakka lexicon. Each word entry 
is associated with the pronunciation and POS tag. About 
26,000 entries have also Chinese translation.  
The Chinese corpus (TextM) is a large database with texts 
collected from Sinorama magazine [9] and the CIRB [10]. 
CIRB is a database built for information retrieval competition. 
Table 2 summarizes the main information about the text 
corpora. 
Table 2.  SUMMARY OF THE TEXT CORPORA 
Corpus No. of Words No. of word entries 
TextA 143,341 15,115 
TextB 46,581 8,068 
 Dict  43,521 
 TextM 117,163,131 591,825 
III. HAKKA SPEECH RECOGNITION SYSTEM 
A. Acoustic model 
The acoustic model (AM) is trained using the Hakka 
speech corpus. It is composed of 87 Right-context-dependent 
(RCD) 3-state initial HMM models and 71 5-state final HMM 
models. Each state is a 32-mixture GMM. Acoustic feature 
vector used in this study consists of 38 components (12 MFCC 
parameters, and their first and second order time derivatives, 
and energy parameter‟s first and second order time 
derivatives), which is analyzed at a 10-msec frame rate with a 
32-msec Hamming window size. Cepstrum Mean 
Normalization (CMN) is employed to compensate the bias of 
channel and/or speaker. Table 3 summarizes the main 
information about the AM. 
Table 3.  SUMMARY OF THE HAKKA AM 
Classification No. of models No. of states No. of mixtures 
Initial 87 261 8,352 
Final 71 355 11,360 
Silence 1 3 96 
Short pause 1 1 32 
 
B. Baseline langague model 
The baseline language model (LM) is a conventional 
n-gram model. An n-gram LM uses the last n-1 words of the 
history as its sole information source. Thus a bigram predicts 
iw  from 1iw   by 
  
 
 
1
1
1
,
|
TextA i i
bsl i i
TextA i
C w w
P w w
C w




 
(1)
 
where ( )TextAC  
denotes the count of samples in TextA. 
In a particle realization, Katz‟ backoff smoothing method 
[11] is adopted to obtain a more robust bigram LM. Due to the 
small size of TextA, most bigrams are backoffed to unigrams. 
Only 19,213 bigrams are estimated from TextA. Table 4 
displays the performance of the baseline Hakka speech 
recognition system.  
Table 4.  PERFORMANCE OF THE BASELINE SYSTEM ON THE HAKKA 
TEST CORPUS 
LM 
Accuracy (%) 
Word Character Syllable 
Free grammar 21.44 42.67 57.97 
Baseline 40.79 58.99 66.29 
C. Improvement on LM 
Since the data of TextA is not sufficient to construct a 
robust bigram language model, some useful syntactic and 
Hakka-Chinese translation information is incorporated to help 
to construct a robust Hakka LM. The proposed improved LM 
is formulated by 
 
 
   
   
   
1
1 1
1 1 1
2 1 1
|
| ,             ,
|
          + | ,  otherwise
i i
bsl i i textA i i
i pos i i
i trans i i
P w w
P w w C w w k
w P w w
w P w w



 
 
 
 

 


 (2) 
where ( )posP  
is an LM using POS information and  .transP  
is an LM using translation information. 
 
1) Stage 1: Incoporating POS information from Hakka 
text corpus 
We first use the POS information to construct a 
class-based LM. Each POS category is treated as a class. The 
model is formulated by 
 
    
   
       
1
1
,
1 1 1
| |
                | |
i i
pos i i i i
G w G w
i i i i
P w w P w G w
P G w G w P G w w


  
 


 
(3)
 
  
   
  
  
 
*
* *
|
|
i i
i i i
M i
P G w w
P w G w P w
P G w
   (7) 
where  i iM M w  denotes a possible Chinese translation of 
the Hakka word iw  found in Dict;  |T i iP M w  is the 
Hakka-to-Chinese word translation probability obtained by 
 
 
     
     
  
 
|
,
,  otherwiese
i
T i i
TextB i i TextB i i
Dict i i TextM i
TextM i
M w
P M w
P M w | w        C M w ,w k
P M w | w P M w
P M w

 


 



 (8) 
  TextB i iP M w | w  represents the probability of iw  being 
translated as a Mandarin word  iM w  estimated from the 
Hakka-Mandarin parallel text corpus (TextB);   Dict i iP M w | w  
represents the Mandarin-Hakka word pair statistics in Dict; 
and   TextM iP M w  is the unigram LM estimated from TextM. 
Since Dict contains only Mandarin-Hakka word translation 
pair information, the statistics   Dict i iP M w | w  is given by a 
fair floor value set to be the inverse of the number of possible 
Mandarin translation entries listed in Dict mapped with iw . 
  |M i iP G M M  is the POS-word model of Mandarin Chinese 
that
 
can be directly estimated from TextM. The resulting 
improved Hakka word unigram model is expressed by 
  
    
  
     
 
 
1
*
1 2 1 -1
,                          1
, ,
   | | ,
                                              2
,                                  otherwise
M i i
M i n
i M M M n n
i
i
P M w M w Case
P M w M M
P w P M P M M P M M
M w Case
P w
 

 

 




 (9) 
where   M iP M w  and  -1|M n nP M M  denote the Chinese 
unigram and bigram LMs estimated from TextM; and  iP w  
is the unigram Hakka LM estimated in stage 1. 
 
3) Stage 3: Incoporating the information of Chinese 
word bigram model and Mandarin-Hakka bilingual 
dictionary. 
This stage utilizes word-by-word Hakka-Mandarin 
translation information given by TextB and Dict. The Hakka 
LM using word translation information ( )transP  is formulated 
by
 
 
 
 
     
 
1
1
1 1 1
1 1 1
*
|
| | | ,    
              ( , )  and  1
,               otherwise
i
i
trans i i
T i i M i i T i i
M
i i i
TextB i i i
i
P w w
P w M P M M P M w
C w M k M Case
P w


  
  

  


 



 (10) 
where  |T i iP w M  and  1 1|T i iP M w   are Hakka-Mandarin 
and Mandarin-Hakka translation probability estimated from 
TextB (the latter is shown in Eq. (8));  1|M i iP M M  represents 
the Mandarin bigram LM;  * iP w  is the improved Hakka 
word unigram model shown in Eq. (9). It can be seen from Eq. 
(10) that, as more Hakka-Mandarin translation pairs occur in 
TextB, the Hakka bigram will relies more on the 
corresponding Mandarin bigram (  1|M i iP M M  ); otherwise it 
will be backoffed to the unigram  * iP w . 
D. Experimental Results 
The performances of these three proposed approaches to 
construct the improved LM for Hakka speech recognition are 
evaluated using the Si-Rhan Hakka speech corpus introduced 
in Section II. Fig. 1 displays the experimental results. It can be 
seen from the figure that the recognition performance was 
gradually improved as more information is incorporated in a 
higher stage to assist in constructing the improved LM. 
Specifically, the word recognition rate increased 2.2% over 
the baseline system as we used the POS information of Hakka 
language in Stage 1. Another 1.5% increase was gained as we 
added the POS information of Chinese in Stage 2. Lastly, a 
small improvement of 0.1% was gained when we further 
incorporated the information of Chinese word bigram model 
through the Hakka-Chinese word translation. These results 
show that the reliable Chinese LM can be used to assist in 
constructing more reliable LMs for improving the Hakka 
speech recognition. We believe that this is mainly resulted 
from the property that Hakka and Chinese have very similar 
syntactic structure. 
40.79
58.99
66.29
42.99
60.79
68.63
44.45
62.17
69.07
44.56
62.12 69.18
0
10
20
30
40
50
60
70
80
Word Character Syllable
A
cc
u
ra
cy
(%
)
Baseline Stage 1 Stage 2 Stage 3  
Figure 1.  Comprison of language model performance. 
    It is noted that the improvement of Stage 3 is negligibly 
small. Some possible reasons are discussed as follows. First, 
only about 61% of Hakka words have the translated Chinese 
words in the Hakka-Chinese dictionary (Dict). Many frequent 
or important Hakka words may have no Chinese word 
mappings so that the abundant information of Chinese LM is 
nothing to do with them. Second, the text corpora of Hakka 
and Chinese contain different types of articles. The Chinese 
text corpus is large and general to contain plenty of types of 
articles, while the Hakka text corpus is small and contains 
articles of Hakka-specific historic stories. So, their 
information contents are not matched. We hence need to put 
more efforts on this issue in the future. 
  
study, the bilingual dictionary contains 43,521 Hakka words 
and 738 Mandarin words. 
C. Experiments and Results 
The experimental results are displayed in Table 8 and Fig. 2. It 
can be found from Table 8 that the scheme using the bilingual 
mixed AM (Mix) performs much better than that using the 
directly-combined AM (H+M) for both bilingual LMs 
modified from the two Hakka LMs derived in Stages 2 and 3. 
We also find from Fig. 2 that both Hakka and Mandarin words 
are improved by using the mixed AM. Moreover, the 
improvement is more significant for Mandarin words. 
Table 8.  PERFORMANCES ON BILINGUAL CORPUS BY LANGUAGE MODEL 
Accuracy (%) 
AM LM Word Character Syllable 
Mix 
Stage 2 37.16 54.33 56.24 
Stage 3 37.84 55.27 56.14 
H+M 
Stage 2 21.33 34.86 38.09 
Stage 3 21.98 35.61 38.47 
 
28.56
16.12
34.09
58.27
29.1
17.21
35.86
58.67
0
10
20
30
40
50
60
70
Hakka word 
(H+M AM)
Mandarin word 
(H+M AM)
Hakka word 
(Mix AM)
Mandarin word 
(Mix AM)
W
o
rd
 A
cc
u
ra
cy
(%
)
(Stage 2) (Stage 3)  
Figure 2.  Comprison of language model performance. 
Table 9 displays the analysis on syllable accuracy and 
inter-language syllable confusions. It can be seen from the 
table that the use of Mix AM can greatly improve the accuracy 
of Mandarin syllables and reduce the confusion of recognizing 
Mandarin syllables as Hakka syllables (MH). Although the 
accuracy of Hakka syllables by using the Mix AM remains the 
same as the one using the H+M AM, the accuracy of Hakka 
words is significantly improved (as shown in Figure 2). This is 
probably because the reduction of MH syllable confusion 
makes less insertion errors of Hakka words. This result 
reconfirms the effectiveness of the proposed Mix AM 
modeling. 
 
V. CONCLUSION 
In this paper, a first study on Hakka and mixed 
Hakka-Mandarin speech recognition has been discussed. 
Several methods of language modeling have been proposed to 
help to solve the problem of lacking large text corpus in 
Hakka SR. For mixed Hakka-Mandarin SR, a new method of 
training a single mixed AM was discussed. Experimental 
results confirmed the effectivenesses of these proposed 
methods. Further study to use more Chinese language 
information to assist in improving the Hakka LM is worth 
doing in the future. 
Table 9.   ANALYSIS ON SYLLABLE ACCURACY OF HAKKA (H), 
MANDARIN (M), AND INTER-LANGUAGE CONFUSIONS OF HM AND MH IN 
THE BILINGUAL SPEECH RECOGNITION. 
AM LM % (count) 
H M H →M M →H 
H+M Stage 2 55.15 (1,782) 17.78 (263) 0.80 (26) 79.31 (1,173) 
Stage 3 55.15 (1,782) 19.13 (283) 0.84 (27) 77.76 (1,150) 
Mix Stage 2 55.15 (1,782) 64.16 (949) 1.80 (58) 32.86 (486) 
Stage 3 55.15 (1,782) 64.64 (956) 1.86 (60) 32.45 (480) 
Total syllable number = 3,231 (H) + 1,479 (M) = 4,730 
 
ACKNOWLEDGMENT 
This work was supported by NSC of Taiwan under contract 
NSC98-2221-E-009-075-MY3. The authors would like to 
thank Council for Hakka Affairs Executive Yuan, Republic of 
China (Taiwan), Ministration of Education, Taiwan, and 
College of Hakka Studies, National Chiao Tung University, 
Taiwan, H. M. Yu and W. Z. Gong for supplying the lexicon 
and the text corpus. 
 
REFERENCES 
[1] Hsiu-Min Yu, Lie-Shih Lo, Hsin-Te Hwang, Hsi-Chun Hsiao, and 
Sin-Horng Chen, “On Constructing Speech Corpus for Implementing 
Hakka Text-To-Speech Synthesis,” OCOCOSDA, Dec. 2007. 
[2] Dau-Cheng Lyu, Chun-Nan Hsu, Yuang-Chin Chiang and Ren-Yuan 
Lyu, “Acoustic Model Optimization for Multilingual Speech 
Recognition,” Computational Linguistics and Chinese Language 
Processing, Vol. 13, No. 3, September 2008, pp. 363-386. 
[3] Hakka Television Service Online, available at 
http://www.hakkatv.org.tw/ 
[4] Formosa Hakka Radio Online, available at 
http://www.formosahakka.org.tw/ 
[5] J. Köhler, “Multilingual phone models for vocabulary independent 
speech recognition task,” Speech Communication, Vol. 35(1-2), pp. 
21-30, 2001. 
[6] B. H. Juang, L. R. Rabiner, “A probabilistic distance measure for hidden 
Markov model,” Bell System Technical Journal, 64(2), pp. 391-408, 
1985. 
[7] Wan-Zao Gong, The Taiwan Hakka Literature Collections (Global, 
Taipei, Taiwan, 2004), in Chinese/Hakka. 
[8] Chen, Keh-jiann, Shing-Huan Liu,”Word Identification for Mandarin 
Chinese Sentences,”Proceedings COLING '92, pp.101-105, Nantes, 
France,1992 
[9] Sinorama magazine, available at 
http://dblink.ncl.edu.tw/sinorama/index.htm 
[10] Chen, Kuang-hua and Chen, Hsin-His, 2004, Overview of CIRB030 
Information Retrieval Test Collection, avialable at 
http://lips.lis.ntu.edu.tw/cirb/index.htm. 
[11] S.M. Katz, "Estimation of Probabilities from Sparse Data for the 
Language Model Component of a Speech Recogniser", IEEE 
Transactions on Acoustics, Speech and Signal Processing, ASSP-35, vol. 
3, pp 400-401, March 1987. 
 2 
  他一遇到人，就喜歡搭人家的肩膀。 
7）  阿旺伯動啊著就怨人,沒人愛同佢行兼 
  阿旺伯老是報怨他人，沒人喜歡和他走近。 
 
關鍵詞：客語時貌、客語啊、暫時貌、嘗試貌、反覆貌、緊密先前貌 
 
In this paper we concern ourselves with the multiple aspectual functions denoted by the 
Hakka aspect marker -a
55
-啊, which widely distributes in the deliminative construction, the 
tentative construction, the iterative construction, and the immediate anterior construction.  
Based on a mini corpus and the cross-aspectual analyses on -a
55
-啊, we propose that there is a 
semantic core shared by -a
55
-啊 in the above-mentioned Hakka aspectual constructions, which 
can be defined as scaling the extent of an action down, a definition like that indicated by the 
Hakka postverbal diminutive e 仔, or like the meaning of Mandarin verbal classifier yi-xia 一
下, referring to a short period of time and pragmatically serving as a downtoner.  With this 
essential meaning, -a
55
-啊 expresses the meaning of doing something a little bit in the 
deliminative construction [verbi（verbi）-a
55 
le
21
/-a
31
] as in (1), conveys the meaning of slightly 
engaging tentative actions in the tentative construction [try-verb-see-a
55 
le
21
/-a
31
] as in (2), 
refers to repeated actions by collocating with a reduplicated verb and the classical Hakka 
diminutive e 仔 in the iterative construction of [verbi-a
55 
-verbi-e
31
] as in (3), and functions 
as an immediate anterior marker in the construction of [verb-a
55 
-complement] where the core 
meaning of -a
55
-啊 has been metaphorically transformed from a short period of time into a 
tight temporal relational meaning between two events: in the single-event sentence it profiles 
an immediate relationship between the moment of speech and the event time indicated by the 
sentence, generating the meaning of just.  See example (4).  Nonetheless, in a 
complex-event sentence with the first event clause containing the construction of 
[verb-a
55
-complement], a
55
-啊 indicates an immediate sequential order of the two events.  
Example (5) illustrates.  Also, due to the temporally close relationship denoted by -a
55
- 
between two events, a pragmatic habitual reading is derived from contexts with the first event 
interpreted as the condition under which the second event occurs as shown in (6).  This 
explains why the clasue tung-a-do „動啊著 as soon as one moves‟ has been idiomatized into a 
phrase bearing the meaning of English always in progressive sentences, indicating one‟s 
annoying habitual behavior. See (7).   
 
(1) gie-zag se-moi-e an-zam, m hang-giam-a
55
, sii voi bun-ngin giug-zeu o!  
The girl is wonderful.  If you are not in close contact with her, she‟ll be chased 
away. 
(2)  m pa na! hi cii-siid-kon-a
55
, iu mo hem ng mai! 
   Go ahead!  Just have a taste for it.  You are not forced to purchase it. 
 4 
  他把電話號碼寫在紙上。 
 
另外，在重複動詞之間加入啊形成[V 啊 V]的構式，往往是強調某狀態的程
度（見 6、7），如： 
 
6）  佢汝生來恁呢無人緣啊 55 無人緣！醜醜啦5！ 
  你生來很沒人緣，醜醜的。 
7）  佢摎間項抨到淨利啊 55 淨利。 
他將坊間整理得十分乾淨。 
 
除此之外，研究客語啊的學者都提到，客語的啊字有作為動詞時貌的功能，
如讀中降調的啊 31 有扮演動詞暫時貌（deliminatives，見例 8）和嘗試貌
（tentatives，見例 9），高平調的啊 55 也和國語的[V 啊 V 的]結構一樣有[V 啊 V
仔] （中研院詞庫小組，2006：4）的說法，此時，此時啊 55 表示動作的反覆時
貌（見例 10）；以及讀成高平調啊 55 的緊密先前貌（immediate anterior，見例 11）： 
 
8）  新正年時，乜係行春時節，大家來去客家莊遶遶啊316。 
譯   新春時候，也是踏春時節，大家來去客家莊走一走。 
9）  先生講：用客語來寫文章，毋會當難，試寫看啊31毋使驚7。 
譯   老師說：用客語寫文章，並不難，可以試寫看看不必害怕。 
10）例  佢昨晡日打籃球撓著腳，行路跛啊55跛仔8。 
譯   他昨天打籃球扭傷腳，走路一跛一跛地/跛啊跛的。 
11） 落雨過啊55忒，山頂个路滑溜溜仔，行路愛細義9。 
譯   剛下完雨，山路滑溜溜地，走路要小心。 
 
儘管前人的研究都有指出啊在這四種時貌中出現，但卻無人深究其中的語意
關連性，因此本研究旨在探討以上四個時貌之間的語意關係，我們將指出：暫時
貌和嘗試貌的啊 31 其實是高平調啊 55 在句尾的變體，這些啊 55 的核心語意都有
具短時和降低某個動作的程度的語意，並由此核心語意透過隱喻的轉化，表達兩
個事件之間時間上的緊密性。 
 
                                                                                                                                      
4選自賴維凱 2006：46，但這種用法北四縣沒有。 
5選自賴維凱 2006：49。 
6選自《客語能力認證基本詞彙-中級、中高級暨語料選粹》：4-33。 
7選自《客語能力認證基本詞彙-中級、中高級暨語料選粹》：14-99。 
8選自《客語能力認證基本詞彙-中級、中高級暨語料選粹》：8-114。 
9選自《客語能力認證基本詞彙-中級、中高級暨語料選粹》：26-202 
 
 6 
所表現的時貌義方面，除了舉出同以上兩位作者的短時貌義（[V啊補語]：表達
剛剛及一﹍就﹍的意思）之外，他還列出嘗試貌的構式為[V看啊55/31]，這和林立
芳的嘗試貌構式[V阿欸]和 [V阿勝/阿勝欸]不同；此外，還有表達像國語V一V
時貌義的[VV啊]、以及表示「剛完成某一連續動作」的啊構式[V1啊V1]，該構式
表達的意思和林立芳的重複貌以及饒長溶的間接和直接持續貌十分類似，只是賴
維凱的構式中沒有最後的「欸/哩」。 
至於以苗栗次方言為基礎的啊研究，都指出啊中插在動補結構之中，有表示
„剛剛‟或„一﹍就﹍‟的意思（羅肇錦 1995；張雁雯 1998）。其中張雁雯認為：啊
在此位置其實是一種停頓，「藉由停頓，表現動作生動的效果」並「強調動作的
進行」20；此外，該作者也提出啊在 V 啊 55e31 結構中表示嘗試貌的語意，這和林
立芳的[V 阿欸]的嘗試貌構式一樣。 
由前人的研究我們可以觀察到，（1）啊的時貌義在不同客語次方言之間有同
亦有異，（2）就算是同一個時貌義，不同研究者也各自有一套術語來定義啊的時
貌義，以及（3）除了賴維凱運用了李文光等編輯的《李文谷再現江湖》的劇本
作為語料分析的基礎之外，大部分研究啊的論文，都依照作者的客語語感所想到
的單句話或詞組來舉例、並且都是以條列式的方式一一舉出啊的各種語意。然
而，個人語感容易有分歧的感受、而語意要素卻又往往受限於例句的影響而呈現
紛歧的歸類。為突破前人研究的句現，本研究先將語料腔調限定在苗栗次方言─
北四縣客語的代表─，並以小型語料庫所收集到 342 個例句來作為研究的基礎，
以避免因個人語感造成可能的不周延或偏見的產生，並將焦點放在由啊所引導出
來的四種時貌義之間的關連。 
 
3. 研究方法 
基本上本研究的方法是以苗栗四縣客語的小型語料庫為基礎，為呈現客語啊
的四個時貌義：暫時貌、嘗試貌、重複貌、和緊密先前貌之間的關連性，首先即
是收集相關的語料來建構四者之間的關係，語料來源有四：龔萬灶先生的《阿啾
箭个故鄉》和《客語實用手冊》、以及網路上的兩項官方的資源：行政院客委會
提供的《客語能力認證基本詞彙-中級、中高級暨語料選粹》以及教育部國推會
編輯的《台灣客家語常用詞辭典》；若需要額外補充例句，作者將自行編造句子，
以支持一些論點。 
 
4. 客語啊的四種時貌義的分析 
根據本文的統計，四種啊的時貌義之例句數的分佈是：暫時貌 103 句、嘗試
貌 47 句、重複貌 20 句、以及緊密先前貌 172 句。我們先在 4.1 節推論啊的
                                               
20張雁雯 1998：44。 
 
 8 
譯   叫他快點兒來，他十點左右才來，實在很不經心。 
18） 阿義仔，喊你睡當晝，你就走去搞水，皮弓緪啊31，等等分若姆修理26。 
譯   阿義，叫你睡午覺，你就跑去玩水，皮拉緊些，等著給你媽媽修理。 
 
以上例句的啊分別修飾狀語„早‟、„遽‟（快）、和„緪‟（緊），都表示一些、一點
之意，同修飾動詞時一樣，處於句中則讀為高平調、句尾則為中降調。 
 
4.2  嘗試貌的分析 
語料中，客語的嘗試貌構式的完全形式為[試-動詞-看-啊 55-哩 21/啊 31]，共有
47 句。該構式基本上和暫時貌的構式一樣，只是暫時貌的動詞，在嘗試貌中是[試
-動詞-看]，其中動詞試或看之一以及句尾助詞哩可以省去，但中降調的啊 31 卻一
定要保留，例如： 
 
19） 該細人仔毋知做麼个，噭到抽胲另命，過去試探看啊 55 哩 2127。（全形） 
譯   那個小孩子不知為什麼，哭得聲嘶力竭，過去探一探吧。 
20） 先生講：用客語來寫文章，毋會當難，試寫看啊31，毋使驚28。（省去
哩） 
譯   老師說：用客語寫文章，並不難，可以試寫看看不必害怕。 
21）例 阿忠仔，你去鄉公所問看啊31，農地休耕个錢撥下來吂29？（省去試、
哩） 
譯   阿忠，你到鄉公所問問看，農地休耕的錢撥下來沒？ 
22） 汝去試食啊31！異像異好時樣哩。（省去看、哩） 
  你去試吃看看，好像很好吃似的。 
 
從以上的語料看來，雖然嘗試貌的嘗試語意主要是由試或看貢獻的，但啊55哩21
或啊31基本上都要出現，若將以上例子的啊31省去，這些句子將會被四縣客語的
直覺判斷為有問題的句子。如： 
 
23） ？該細人仔毋知做麼个，噭到抽胲另命，過去試看哩。 
24） ？先生講：用客語來寫文章，毋會當難，試寫看，毋使驚。 
                                               
26選自《客語能力認證基本詞彙-中級、中高級暨語料選粹》： 8-149。 
27原句為<該細人仔毋知做麼个，噭到抽胲另命，過去試看啊55哩21>，選自《客語能力認證基本詞
彙-中級、中高級暨語料選粹》：9-104,原句並無主動詞為看而非探,為了呈現嘗試貌構式全形，作
者加入探字。 
28選自《客語能力認證基本詞彙-中級、中高級暨語料選粹》： 14-99。 
29選自《客語能力認證基本詞彙-中級、中高級暨語料選粹》：8-163。 
 
 10 
30） I‟ve just eaten dinner.  (so I don‟t want any more food.) 
 
除了以上基本的定義之外，當先前貌配合情境因素並引入最新狀態、或最新
消息時(new situation, hot news)，也具有強調的功能 (McCawley 1971; Anderson 
1982)，如： 
 
31） Mt. St. Helens has erupted again! 
32） Nixon has resigned! 
 
據此，Li及Thompson（1982）也認為國語句尾「了」同樣表達了與說話情
境相關的事件，因此，也可以算是國語先前式的時貌。 
而所謂的「先前」搭配「緊密」（immediate)是指先前的事件與當下的時間距
離很短，類似國語„剛剛‟英語„just‟之意。在客語裡頭表示動詞緊密先前的時間意
義的構式是[動詞-啊 55-補語]，其中動補結構中的補語（包括趨向詞、時貌及時
相詞、和結果補語）貢獻了動詞的終結點（telicity）、讓動補結構表現出終結式
（accomplishment）的時貌義，表示該動作已經完結（Vendler 1957, Levin 1993: 
105-106）；而緊密義則由原來表短時的暫時貌啊 55 透過隱喻的轉換，成為動詞事
件結束時間和說話的當下的時間距離很短，因此貢獻了„剛剛‟之意，例如以下的
對話：  
 
33） A： 若  爸  呢？ 
你的父親呢？ 
B： 佢行出去咧 21。 
他走出去了。 
B‟: 佢正行-啊 55-出去。 
他剛走出去。 
 
B 與 B‟的差別在於，B 句是先前貌而已，以情態語助詞咧 21（葉瑞娟 2000）結
尾，表達父親先前已經出門，是造成現在不在家的原因，並不強調這個出去的動
作與當下時間的距離很短；但 B‟的時間意義，除了點出父親之前已經出去之外，
更指出父親出門的時間與說話的當下很近。 
除了，單一事件的句子之外，構式 [動詞-啊 55-補語]也出現在雙事件的複雜
句子當中，如： 
 
34） 佢目珠 眨-啊 55-落, 就睡-忒哩。 
他眼睛 一闔下去，就睡-著了。 
35） 寒天飯菜煮-啊55-著，無跈等食，一下仔就冷泧泧仔32。 
                                               
32選自《客語能力認證基本詞彙-中級、中高級暨語料選粹》：28-126。 
 12 
 另外值得注意的是，172 個[動詞-啊 55-補語]例句中，有 21 個例句含有„動啊
著‟的句子，如： 
 
41） a.  同學恁久了，莫動啊著就發閼，火氣恁大35。 
同學那麼久了，別動不動就生氣，火氣那麼大。 
b. 佢性情古怪，動啊著就變面。 
他性情古怪，動不動就生氣。 
  c. 毋好動啊著就愛當天咒誓36。 
譯    不要動不動就對天發誓。 
  d. 毋好動啊著就飯匙堵貓，堵死人37。 
譯    不可以動不動就以歪理堵塞人家的說法。 
 
我們認為動啊著之所以演化成熟語，是因為在雙事件句子中，啊表達„一 ﹍就
﹍‟之意，強調兩個連續事件之間的時間距離很近，正由於這種關係，在相關雙事件出
現頻率很高的語用情境中，雙事件中的第一個事件很容易被詮釋成造成第二事件的條
件，此時，很容易發展出習慣性的語意，這也就能解釋為何子句動啊著會熟語化為描述
令人不悅的習慣性行為，類似英語出現進行式中的 always 的動不動、老是的負面語意
（見 7）。 
 
結語 
本文介紹了客語與表達短時、降低程度的啊 55 相關的四個時貌之間的語義 
關連。首先，相對於國語的暫時貌格式[V 一 V] （如想一想、搖一搖），以動詞
的重複和最小的數字一來表示動作只做一些或一下而已，客語則以[V（V）啊 55
哩 21/啊 31]的方式表示，其中非句尾的啊 55 和出現在句尾受到聲調下降影響的啊
31 都是表示某動作進行的程度很淺、幅度很小的樣子。和客語關係很近的廣東話
也有這種[V 吓 55]的結構，如：諗吓 „考慮一下：think for a while; consider‟ 、斟
吓„說一下：have a brief talk‟ 廣東話的吓（讀成 ha55）38和客語的啊 55 一樣都是
表示淺程度之意。 
此外，客語的暫時貌的啊 55 在嘗試貌裡頭一定要出現，因為，客語的嘗試構
式不僅要表現嘗試之意，同時也要求要表現出淺程度之意，因此，嘗試構式[試
-V-看-啊 55 哩 21/啊 31]中，表嘗試意義的試或看之一可以省去，但啊 55 哩 21/啊 31
則一定要保留。 
                                               
35選自《台灣客家語常用詞辭典》。 
36選自《客語能力認證基本詞彙-中級、中高級暨語料選粹》：16-83。 
37選自《客語能力認證基本詞彙-中級、中高級暨語料選粹》： 8-23。 
38選自 http://www.cantonese.sheik.co.uk/dictionary/characters/1005/ 
 
 14 
中文參考書目 
林立芳. 1997.《梅縣方言語法論稿》。廣東：中華工商聯合出版社。 
侯復生. 2002.〈梅縣方言謂詞後面的“阿”〉，《第四屆客家方言研討會論文集》。
廣州：濟南大學出版社。 
教 育 部 國 語 推 行 委 員 會 編 輯 ，《 台 灣 客 家 語 常 用 詞 辭 典 》。 網 址 ：
http://hakka.dict.edu.tw/ 
張雁雯. 1998. 《台灣四縣客家話構詞研究》，國立台灣大學中國文學研究所碩士
論文。 
賴維凱. 2006. 〈南北客家移民的源流、語言變化與虛詞啊〉。《第六屆客家研究
研究生學術論文研討會》論文集，頁 245~259。 
鍾萬梅等. 2009.《客語能力認證基本詞彙-中級、中高級暨語料選粹》。台北：行
政院客委會。 
鍾榮富. 2005. 《湖廣地區漢語方言鼻音尾/鼻化小稱語法化》. 研究國科會整合
型計畫報告。 
羅肇錦. 1988.《客語語法》。台北：五南圖書出版股份有限公司。 
饒長溶. 2001.〈關於於客家方言體貌助詞“啊”〉，《韶關學院學報》22.11。 
龔萬灶. 2003.《客語實用手冊》。苗栗：翰文印刷。 
───. 2004.《阿啾箭个故鄉》。苗栗：翰文印刷。 
英文參考書目 
Anderson, Lloyd B. 1982. The „Perfect ‟ as a universal and as a language-particular 
category. In Hopper 1982:227-64. 
Bybee, Joan, Revere Perkins and William Pagliuca. 1994. The Evolution of Grammar: 
Tense, Aspect, and Modality in the Languages of the World. Chicago and London: The 
University of Chicago Press.  
Crystal, David. 2006. A Dictionary of Linguistics and Phonetics. 5
th
 ed. Malden: 
Blackwell Publishing. 
Levin, Beth. 1995. English Verb Classes and Alternations – A Preliminary 
Investigation. Chicago and London: the University of Chicago Press. 
Hsieh, Fang-yi (謝芳怡). 2007. 《漢語「V 一下」格式的探討》 (Exploration of V 
yi-xia Constructions in Chinese: A Construction-based Account.)  Unpublished M.A. 
Thesis. Hsinchu, Taiwan: National Tsing Hua University. 
Li, Charles N. and Snadra A. Thompson. 1981. Mandarin Chinese: A Functional 
Reference Grammar. Berkeley and Los Angeles: University of California Press.  
McCawley, James D. 1971. Tense and time reference in English. In Fillmore and 
Langendoen 1971: 96-113. 
Vendler, Zeno. 1957. Verbs and Times, The Philosophical Review. Vol. 66, No. 2 
(Apr., 1957), pp. 143-160, Published by: Duke University Press on behalf of 
參加「Oriental-COCOSDA 2009 國際會議」心得報告 
 
 O-COCOSDA 是一個以亞洲語音語料庫收集、評估及標準化相關技術為討
論核心的國際學術會議，它由日本 Itahashi 教授在 1997 年發起，擔任
Oriental-COCOSDA Convener，於 1998 年在日本舉辦第一屆會議，以後每年皆由
Convener 主導在亞洲各國輪流舉行，過去已在台灣、大陸、韓國、泰國、新加
坡、印度、印尼、馬來西亞、越南、日本等國舉行會議，去年起由我國中央研究
院鄭秋豫博士擔任 Convener，負責會議之籌辦，今年為第十二屆，由大陸新疆
大學主辦，原預定在新疆烏魯木齊舉行，但因新疆暴動事件而改在北京清華大學
舉行。 
 此會議集合亞洲各國的語料庫及語音處理領域的專家學者，藉由各國對各自
語言語料庫的收集及後續的辨認、合成、評估等作經驗交流，並進一步發展出跨
國多語言的合作，其中最成功的是 A-STAR (The Asian Speech Translation 
Advanced Research) 計畫及 AESOP (Asian English Speech cOrpus Project) 計畫，
前者是由日本 NICT 主導的多國合作進行日語、英語、漢語的 speech-to-speech
即時翻譯研究，後者是由日本、台灣、香港、大陸等國合作進行的英語語料收集
及語言學習研究。此兩計畫在本屆會議以 Keynote speech 方式報告研究現況。 
 本次會議共安排四場 keynote，發表 25 篇 oral 論文及 12 篇 poster 論文，其
中 oral 論文由 IEEE Xplore 以紙本 proceedings 發行。參與的人數接近百人，包
括亞洲各國學者及英國學者。 
由此次會議可以看出亞洲各國對語音處理技術都十分重視，因此對發展語音
處理技術所需最核心基本的語料庫均長期投入大量的資源，其中日本、大陸、台
灣、韓國、新加坡已有完整大型的語料庫，而進行廣泛使用語料庫做各種應用研
發，印度、印尼、馬來西亞、泰國、越南也都進行國家層級的計畫來做語料庫的
建置及處理，其他如新疆、尼泊爾也積極趕上進行語料庫建置。藉由此會議的組
織交流，各國已開始進行跨國多語言處理的合作，未來此類型的合作計畫將會持
續及擴增，進行跨亞洲語言的各種應用系統的發展，期許將來大家可以使用自己
的語言暢遊於亞洲各國，包括旅行及網路瀏覽。 
 
 
in the most comfortable speed for the announcer. By
taking the normal speech as a reference, the other three
datasets of fast, median and slow rates were recorded.
Each dataset contained 348 utterances with 48035
syllables. Its associated texts were all short paragraphs
composed of several sentences selected from the Sinica
Treebank Version 3.0 [5]. Their speech rates (SRs),
from fast to slow, are 4.40, 3.82, 2.97, and 2.45
syllables/second. And the corresponding articulation
rates (ARs) are 5.46, 5.05, 4. I5, and 3.75
syllables/second. Notice that SR is defined as the
average number of syllable uttered per second while
AR is defined as the average number of syllable
uttered per second disregarding all inter-syllable
pauses.
3. Analysis Method
3.1. Prosody hierarchy and features
Figure I displays the prosody hierarchy adopted in
the current study. It is a modified version of the
structure proposed by Tseng [6]. It consists of four
layers: syllable (SYL), PW, PPh, and BG/PG. Two
types of prosody tags, break type of syllable juncture
and prosodic state of syllable, are employed to
characterize the prosodic constituents of these four
layers. A set of seven break types of syllable juncture n,
B; = {BO, Bl , B2-1, B2-2, B2-3, B3, B4}, is used to
delimit these four prosody layers. Notice that B2-1,
B2-2 and B2-3 are divided from B2 and defined as a
PW boundary with obvious FO reset, perceived short
pause and pre-boundary lengthening, respectively.
Primitive acoustic features used to specify the break
type are pause duration pd; and energy-dip level ed.;
B41 BGIPG IB4
~I ;;::;--=-;::::::::P=Ph::::::;:;:;==~1 B3~~B3' PPh ----l
~ B2 1 PW 1 L..f.-W'B2~---' I ----l
@g @g BIlBO @g r--.J ,-----.J ~L1 BIlBO~-,
Figure 1. The prosody hierarchy of Mandarin speech.
The prosodic state tag is conceptually defined as the
state in a prosodic phrase and used as a substitution for
the effects from high-level affecting factors In, such as
a word, a phrase or a syntactic tree. It is also assumed
to account for the variation of syllable logFO contour
SPn, syllable duration sd.; and syllable energy level sen
contributed by higher-level prosodic constituents (Le.
PW, PPh and BG/PG) that carry suprasegmental
property. Therefore, the pitch prosodic state Pn, the
duration prosodic state q., and the energy prosodic
state r.; of syllable n, are defined. On the other hands,
low-level affecting factors refer to some syllable-level
linguistic features which represent intrinsic
149
characteristics of Mandarin prosody on SYL level,
including lexical tones In. base-syllable type s.; and
final type In. Lastly, utterance-level normalization
factor u; is added to consider respectively the variation
in syllable duration due to SR and the variation in
syllable energy level due to the recording volume.
3.2. The PLM method
The analysis method utilized in this study is a
modified version of the PLM method extended with
syllable duration and energy level modelings. The
method is formulated as a parametric optimization
problem to find the best prosodic tag sequence {B~ ,
p~, q~, rn' I n= I~N } given with the acoustic feature
sequence {sp., sd.; sen. pd.; edn} of the input speech
utterance and the linguistic feature sequence {In, In. Sn,
In, Un} of the associated text:
B~· ,pt' ,qt' ,rIN'=arg Nm} :1f N [f:I P(SPn IPn , B:-l' l:~i ) (1)
HI ,Pi q\ ,lj n=l
P(sdnlqn,In.s;»,)P(senIrn,In,j" 'Un )NnP(PnIPn-1 ,Bn_1)P(qnlqn-I,Bn_1)P(rnlrn_1,Bn_1)
P(;I\P(ql )P(Ij)U(P(pdn,ednIBn.r, )P(Bn1ln))]
where P(sPniPn, B:_l'l:~II ) , P(sdnlqn,In ,sn,uJ and
P(senlrn,ln,fn'Un) are, respectively, syllable pitch
contour, duration and energy-level models that
describe syllable prosodic feature variation controlled
by the affecting factors considered in Section 3.1;
P(PnIPn-l'Bn-l) , P(qnlqn-l'Bn-1 ) and P(rnlrn_l'Bn_l )
represent pitch, duration and energy prosodic models,
correspondingly; P(pdn,ednIBn,ln) is break-acoustics
model describing relationship between break, linguistic
feature and pause duration and energy-dip level;
P(Bnlln) represents break-syntax model that build the
relationship between break type and linguistic features.
Notice that the syllable pitch contour, duration and
energy-level models are then elaborated under the
assumption that the effect of the considered affecting
factors are combined additively, hence we have
p(sPn IB,," l'Pn,(~l )=N(sPn;~'" +~p" +~~"_I IP"_I +~:" 'P" +~,R) (2)
p(sdnlqn,ln,sn,un)=N(sdn;r,"+Yq" +"'"+Yu"+/ld,Rd) (3)
p(senlrn,In,j" ,un)=N(sen;a,"+ar" +aJ" +a,,"+/le,Re) (4)
where fix, Yx and ax represent affecting patterns
(APs) of affecting factor x for syllable pitch contour,
duration and energy models, respectively; ~ / /ld / u,
and R / Rd / R, denote respectively the global means
and the variances of residual. In this study, the
Authorized licensed use limited to: National Chiao Tung University. Downloaded on October 30, 2009 at 07:30 from IEEE Xplore.  Restrictions apply. 
6. General Patterns ofPW, PPh and BG/PG
breaks respectively. On the other hands, the most
inconsistent labeling results took place in the case of
non-PM inter-word junctures (node 5). Interestingly, in
the case of following word being a mono syllabic
"DE" word (FWL=I and FWPOS=DE, node 20) , the
junctures tended to be more consistently labeled as
non-break than the other inter-word junctures. This
result conform well to the property that "D E" words
which are similar to a suffix build closer connection
with its preceding constituent to form a larger syntactic
unit. Due to the fact the inconsistent labeling results on
inter-word junctures, detail analysis is further
worthwhile doing in the near future.
1: interword
Sequences of pm n delimited by B2/B3/B4 at both
sides are regarded as prosodic state patterns formed by
integrating the log-FO level patterns of the high-level
prosodic constituents we considered. A superposition
model is therefore defined by
pmn =pm: +J}pw" +J}PPiI, +J}B(I/PG" (6)
where pm: is the residuals of log-FO at syllable n; J3x
represents APs of affecting factor x for log-FO;
To explore the general patterns of syllable pitch
contour, duration, and energy level for high-level
prosodic constituents ofPW, PPh, and BG/PG, we first
extract the prosodic state patterns from the observed
syllable prosodic features by eliminating the influences
of utterance, current tone, coarticulations from the two
nearest neighboring tones , base-syllable type, final
type, and the global means. Since the prosodic state
patterns are obtained in the same way for pitch,
duration and energy modeling, we only present the
exploration of the pitch patterns for simplicity. The
pitch prosodic state patterns can be expressed by
pm =sp _R _I'l l _Rb -II (5)
n n P '" P H"' b ,p". 1 P H" ,!p" ...
___ 48035
3: type.2-intrawo; d' • - _. 2: PM
~ 27602
~~ ----•' """ / r~ [~' c:jj"
,\/ ~~ ~~ "~··'~OS.D~"~" ~3
" '\ ' t o '\ '\: . : ~cild8 : ciJ~
Figure 7. Decision tree analysis on break types
labeled in various SRs. Notice that the bar charts
represent percentage of events E1 to E4 (from left to
right); solid and dash lines represent correspondingly
positive and negative answers to a question.PWl 2.92 (1.56) I.1 _~60 (3 98 ) 1
II...
PPh
lJi.E:~j ~6 (3 66) 1 l.I.~~~l~~J
~:(1 0 71 ) 1 lIi:L:j ~1~~~( 1.08) I
~ : (1008 ~: il1l..6 73 (3.63) ': 11 2.27 (0.97) I
,ua_ j , .,....- -- - ,l. 1.- _
o 25 50 0 5 10 15 20 25 1 2 3 4 5 6 7 8 9
Figure 6. Histograms of lengths of prosodic
constituents in fast , normal, median and slow SRs from
top to down (in syllable). Note that number in each
subplot represents average length and number in
bracket represents standard deviation.
To analyze this inconsistent break labeling results in
various SR, a decision tree analysis with a question set
formed by linguistic features was conducted. Four
events were defined to be classified according to the
formed question set: syllable juncture n of four parallel
SR speech were all labeled as (E I) non-break, (E2)
minor break, (E3) major break, and (E4) different
break types. It can be seen from Figure 7 that the
syllable junctures of intra-word and punctuation mark
(PM) were consistently labeled as non-break and major
It can be clearly seen from Figure 5 that corpus in
slower SR had more lengthened pause duration for B2-
2, B3 and B4 while no significant pause duration
lengthenings for BO, BI, B2-1 and B2-3 were observed.
Beside , pause durations of B2-2, B3 and B4 were
scattered more widely as SR became slower.
5. Analysis on Break Types
Table I shows the percentage of each break type
labeled in different SRs. It is obvious that the slower
speech was more likely to be delimited by minor break
(B2-1 , B2-2 or B2-3) and major break (B3 and B4).
Therefore, the lengths of prosodic constituents were
shorter when SR was slower as illustrated in Figure 6.
It was also found that the standard deviations of
prosodic constituent's lengths were reduced as SR was
slower. Among all prosodic constituents, these
phenomena were most obvious in the lengths ofPWs.
Table 1. The percentage of each break type in
diff SRI erent cortora.
BO BI B2-1 B2-2 B2-3 B3 B4
Fast 20.6 45.9 10.9 8.5 3.3 6.6 4.1
Normal 19.9 46.2 9.2 6.7 5.9 6.9 5.2
Median 14.1 44.5 8.4 13.9 4.8 9.0 5.3
Slow 14.1 41.9 7.2 17.2 5.9 8.5 5.3
\5\
Authorized licensed use limited to: National Chiao Tung University. Downloaded on October 30, 2009 at 07:30 from IEEE Xplore.  Restrictions apply. 
pw
fast
-:/
• - y ....
• --1 " _ !10rm~
- -'- CW"'T ;.c"/
---.~n:t~d i an
.......~1'?--~ low
5 10 15 20 25 30
Length in syllable
Figure 12. Energy patterns of BG/PG.
CD
-o
-5 ~.
o 5 10 15 0 5 10
Length in syllable Length in syllable
Figure 13. Energy patterns of PPh and pw.
guidelines, and pn-Iine interface", Proceedings of the Second
Language Processing Workshop 2000,2000, pp. 29-37.
[6] c-v. Tseng, S.-H. Pin, Y.-L. Lee, H.-M. Wang, and Y.-
C. Chen, "Fluent speech prosody: Framework and modeling",
Speech Commun. Special issue on quantitative prosody
modeling for natural speech description and generation,
Vo1.46, 2005, pp. 284-309.
10
pw
~~~~I'
~ _ normal
• ,,-~~'oy
~~*.med i a n
. .......----.
~ slow
. ;:: '.'.o
o
o
o
PPh
~~~~~t<t-l . median
n 'l :\.~\.... .
.. . ..
5
Length in syllable
Figure 9. LogFO patterns of PPh and pw.
o
o
0_025
~ 0
-0.05o~---=--------':-_----'-::-__----'::-~--'-----_-----':L:...-=----------'--"
10
Table 2. Total residual errors (TREs, %) w.r.t. different
aggregate combinations of prosodic constituent's
patterns for pitch, duration, energy modelings in various
SRs.
References
[1] 1. Yu, L.-X. Huang, J.-H. Tao and X. Wang, "Modeling
Incompletion Phenomenon in Mandarin Dialog Prosody",
Proceedings of the Interspeech2007, 2007, pp. 462-465.
[2] A.-1. Li, Y.-Q. ZU, "Speaking Rate Effects on Discourse
Prosody in Standard Chinese", Proceedings of the Speech
Prosody2008, 2008, pp. 449-452.
[3] C.-Y. Tseng, "Corpus Phonetic Investigations of
Discourse Prosody and I-ligher Level Information",
LANGUAGE AND LINGUISTICS, Vo1.9, No.3, 2008, pp.
659-719, in Chinese.
[4] C.-Y. Chiang, S.-H. Chen, H.-M. Yu, and Y.-R. Wang,
"Unsupervised Joint Prosody Labeling and Modeling for
Mandarin Speech", 1. Acoust. Soc. Am. 125, No.2, 2009, pp.
1164-1183.
[5] C.-R. Huang, K.-J. Chen, F.-Y. Chen, Z.-M. Gao, and K.-
Y. Chen, "Sinica Treebank: Design criteria, annotation
Pitch
SYL
+ PW
+ PPh
+ BG /PG
Duration
SYL
+ PW
+ PPh
+ BG/ PG
Energy
SYL
+ PW
+ PPh
+ BG /PG
fast
71.7
60.6
50.4
42.5
fast
69.9
54.7
43.7
39.0
fast
78.4
78.4
58.7
50.1
normal
60.3
51.7
44.6
37.4
normal
62.9
48.6
45.0
42.1
normal
48.0
46.9
32.7
26.0
median
63.8
53.6
44.7
39.2
median
70.6
53.4
51.6
47.0
median
75.7
74.1
55.9
48.9
slow
63.6
54.7
45.5
41.3
slow
70.1
52.0
50.2
46.8
slow
76.4
74.3
55.4
50.4
153
Authorized licensed use limited to: National Chiao Tung University. Downloaded on October 30, 2009 at 07:30 from IEEE Xplore.  Restrictions apply. 
辨認結果，我很同意 prof. Mari Ostendorf 的重要想法 “There is a great deal of 
importance in how you say something versus what you say”，更確認本試驗室的研
究方向是正確的。 
-1( | , , )
n
n n nP p Bsp L , -1( | , , )
n
n n nP sd q B L , and -1( | , , )
n
n n nP se r B L  are, 
respectively, syllable pitch contour, duration and energy-level 
models; 1 1( | , )n n nP p p B− − , 1 1( | , )n n nP q q B− −  and 1 1( | , )n n nP r r B− −  
represent pitch, duration and energy prosodic state transition 
models; ( , , , | , )n n n n n nP pd ed pj dl B l  is the break-acoustics 
model describing the relationship of various intersyllable 
acoustic features with break and linguistic features; ( | )n nP B l  
represents the break-syntax model that build the relationship 
between break type and linguistic features. 
The three syllable prosodic feature models are then 
elaborated to consider some major affecting factors that 
control their variations:  
1
1 1
-1
,
( | , , )
( ; , )  for normal speech
              (3)
( ; , )      for particular sound
n n nn n
n n
n
n n n
n pt B
n pr p
P p B
N
N
+− −
+ +⎧⎪≈⎨ ′ ′+ +⎪⎩
sp L
sp β β μ R
sp β β μ R
  
1
1 1
-1
,
( | , , )
( ; , ) for normal speech
     (4)
( ; , )     for particular sound
n n n nn n
n n
n
n n n
n s q d dt B
n pr p d d
P sd q B
N sd R
N sd R
γ γ γ μ
γ γ μ
+− −
+ + +⎧⎪≈⎨ ′ ′+ +⎪⎩
L
  
1
1 1
-1
,
( | , , )
( ; , ) for normal speech
        (5)
( ; , )           for particular sound
n n n nn n
n n
n
n n n
n f r e et B
n pr r e e
P se r B
N se R
N se R
α α α μ
α α μ
+− −
+ + +⎧⎪≈⎨ ′ ′+ +⎪⎩
L
 
where xβ , xγ  and xα  represent the affecting patterns (APs) 
of affecting factor x for syllable pitch, duration and energy 
models, respectively; μ / dμ / eμ  and R / dR / eR  denote 
respectively the global means and the covariances of residuals. 
In the practical realization, tone with coarticulation APs, i.e. 
{ xβ , xγ , xα |x= 11 1,n nn nt B+− − }, are obtained from decision trees for 
each current tone (tn) constructed by a question set. 
A special training procedure is designed. It first employs a 
sequential optimization to label prosodic tags and determine 
model parameters for the normal speech part of the unlabeled 
corpus. Then, the global means of normal speech models are 
used to assist in labeling prosodic tags and determine model 
parameters for the particular sound part. The reasons of 
adopting the special training procedure are stated as follows. 
First, it can prevent the training from being dominated by the 
particular syllable-like sounds which have wilder prosody 
variability. Second, using the same global means of normal-
speech prosodic models in the training of particular sound part 
makes their APs have the same bases to compare. 
III. EXPERIMENTAL DATABASE 
The database used consists of eight dialogue sessions 
selected from the Mandarin Conversational Dialogue Corpus 
(MCDC) [7] collected by the Institute of Linguistics of 
Academia Sinica, Taiwan. Its total length is about ten hours 
(121,242 syllables). It consists of 3,501 dialogue turns. The 
eight dialogue sessions were uttered by nine female and seven 
male speakers, and transcribed into Chinese texts with some 
other tags including discourse marker (DM), particles, and 
pauses by professional linguist annotators. Some important 
spontaneous speech phenomena were also annotated. They 
include disfluencies, particular pronunciation, discourse-
related items, and sociolinguistic phenomena.  
The preprocessing of the corpus included forced-alignment 
into syllable sequences, pitch detection, frame- and syllable-
wise speaker normalizations of pitch and duration/energy 
levels, and representation of syllable pitch contour by four 
coefficients of orthogonal transformation. 
IV. EXPERIMENTAL RESULTS 
The experiment was conducted on the MCDC corpus. The 
number of prosodic states was empirically set to be 20 
including 16 for normal speech and 4 for PPC. The training 
took 59 iterations to reach a convergence.  
A. Analyses on Model Parameters  
Table I displays the total residual errors (TREs) which are 
the percentage of sum-squared residue of log-F0/syllable 
duration/syllable energy level over the observed sum-squared 
counterparts with respect to the use of different combinations 
of affecting factors. As shown in the table, TRE is reduced as 
more APs were used. The lower-level APs (i.e., tone with 
coarticulation, base-syllable, final type, and particular 
syllable-like types) accounted for 9.4%/16.3%/13.2% of 
prosodic variation in pitch/duration/energy level for the 
normal speech part, and 11.9%/3.4%,/8.6% for the particular 
sound part. The high-level prosodic constituents contributed 
another 76.5%/82.0%/84.3% and 39.8%/82%/47.2% for these 
two parts. Obviously, the contributions of low-level APs are 
relatively small. 
TABLE I: TRES (%) OF THE SYLLABLE PITCH CONTOUR, DURATION AND 
ENERGY LEVEL MODEL W.R.T. THE USE OF DIFFERENT COMBINATIONS OF 
APS FOR (A) NORMAL SPEECH PART AND (B) PATICULAR SOUND PART. 
APs Pitch Duration Energy
+Tone with coarticulation 90.6 94.0 94.3 
+Base syllable/final  83.7 86.8 
(A)
+Prosodic state 14.1 1.7 2.5 
APs Pitch Duration Energy
+Particle Class 88.1 96.6 91.4 (B)
+Prosodic State 48.3 18.6 44.2 
 
Fig.2 shows the syllable duration APs of 5 tones, 82 
reduced base-syllable types, and 24 particular syllable-like 
classes. As expected, Tone 3 is shorter and Tone 5 is 
shortened seriously. Most APs of particular syllable-like 
classes are lengthened, while only three (particles of “GE”, 
“O”, and uncertain pronunciation) are shortened. 
1 2 3 4 5
-0.05
0
0.05
se
c
(a)
1 30 60 82
(b)
1 6 12 18 24
(c)
 
Fig. 2:  The syllable duration APs of (a) tone, (b) base syllable, and (c) 
particular syllable-like type. 
Fig.3 displays the prosodic state APs for normal speech 
(State 1 to 16), particular sound (State 17 to 19), and over-
lengthening syllable (State 20). As shown in Fig. 3(b), the 
many PWs of 1-4 syllables. Most PWs are delimited by B2-1 
with pitch reset. The insertion of the first B2-3 is due to 
hesitation. A major break B3 is set at the end of the first 
sentence. The speaker produces a DM (NE GE) with flat pitch 
and then followed by a PW “ji-long-yi-lan” with pitch accent 
to emphasize it. This example shows that our method 
functions quite well for automatic prosody labeling. 
0 5 10 15 20 25 30
5
5.5
Lo
gF
0
B2-1 B2-3 B2-1 B2-1 B2-1 B2-1 B2-3 B2-1B3 BPI
BP
BPOBPO
0 5 10 15 20 25 30
0
0.2
0.4
se
c
40
60
O
w
o
3
j
i
a
1
s
h
i
4
r
u
2
g
u
o
3
y
a
o
4
c
h
u
1
q
u
4
d
e
5
h
u
a
4
d
o
u
1
h
u
i
4
p
a
u
3
b
i
3
p
a
u
3
d
a
o
4
j
i
1
y
i
2
l
a
n
2
n
a
4
q
u
4
dB j
i
a
o
4
y
u
a
n
3
l
o
n
g
2
b
i
a
n
1
m
e
n
2
NE GE
  
Fig. 6: A prosody labeling example: it shows the observed (solid diamond) 
and prosodic state+global mean (open circle) of syllable log-F0 level (Upper), 
duration (middle) and energy level (lower). The utterance is “O(O) wo3-
men2(our) jia1-shi4(family is) ru2-guo3-yao4(if we want to) chu1-qu4-de5-
hua4(have a trip), dou1-hui4-pau3(always go) bi3-jiao4(quite) yuan3(far) 
pau3-dao4(go to), NE GE(NE GE) ji1-long2-yi2-lan2(Keenlong and Yilan) 
na4-bian1-qu4(there).”. 
2)  Edit Disfluencies 
The structure of edit disfluencies can be expressed by 
(reparandum) * [editing term] correction 
Here, ‘*’ indicates an interrupt point (IP). We now analysed 
three major types of IP: repetition, repair and restart. Their 
counts are 1379, 362, and 764. Fig. 7 displays the distribution 
of break tag labeling results. We found that all the three types 
of IP are more likely to be labeled as minor or major breaks 
than regular syllable junctures. Moreover, both repair and 
restart have more major breaks and B2-2 to show that they are 
likely to have long pause duration. On the contrary, most 
repetitions with B0/B1 are pragmatic repetitions.  
62% 13%
3%
5%
5%
12%
Break type of 
all syllable junctures
B0, B1 B2-1 B2-2 B2-3 B3, B4 BPI, BP, BPO
41%
14%
10%
13%
13%
10%
Break type of 
repetition IPs
10%
18%
23%
6%
23%
21%
Break type of 
repair IPs
15%
23%
20%
10%
22%
10%
Break type of 
restart IPs
 
Fig. 7.  IP corresponds to distribution of the break type 
Fig. 8 displays the normalized prosodic feature patterns of 
reparandum and correction for repetition, repair, and restart 
IPs with different lengths. From Fig 8(a), the beginning pitch 
levels of corrections for the three types of IP are likely to be 
reset to the beginning pitch levels of reparandums. From Fig. 
8(b), the pre-IP lengthenings of reparandum are reset and 
shortened for the beginning syllable of correction. From 
Fig.8(c), the beginning energy levels of correction for both 
repair and restart are likely to be reset to higher levels than 
those of reparandum. These findings match well with those of 
Tseng [8]. 
-0.1
-0.06
-0.02
0.02
0.06
0.1
Lo
gF
0
Reparandum Correction
-0.04
-0.01
0.02
0.05
0.08
0.1
se
c
1 2 3 4
-2
0
2
4
Length in syllable
dB
1 2 3 4
Length in syllable  
Fig. 8: (a) Log-F0, (b) duration and (c) energy patterns of reparandum and 
correction for repetition IP (solid line, solid diamond), repair IP (dotted line, 
open circle), and restart IP (dashed line, plus marker) with different lengths. 
V. CONCLUSION 
In this paper, an unsupervised joint prosody labeling and 
modeling (PLM) method for spontaneous Mandarin speech 
has been discussed. Experimental results on the MCDC 
corpus showed that rich and meaningful prosodic information 
can be explored from the well-trained prosodic models as well 
as from the automatically-labeled prosody tags. We believe 
that those findings should be beneficial to other spontaneous- 
speech. applications. 
ACKNOWLEDGMENT 
This work was supported by NSC under contract NSC98-
2221-E-009-075-MY3. The authors want to thank Dr. S.-C. 
Tseng of Academia Sinica for providing the MCDC Corpus. 
REFERENCES 
[1] Y. Liu, E. Shriberg, A. Stolcke, D. Hillard, M. Ostendorf, and M. 
Harper, “Enriching Speech Recognition with Automatic Detection of 
Sentence Boundaries and Disfluencies,” IEEE Trans. on Audio, Speech 
and Language Processing, vol. 14, no. 5, pp. 1526-1540, 2006. 
[2] C. K. Lin, and L. S. Lee, “Improved Features and Models for Detecting 
Edit Disfluencies in Transcribing Spontaneous Mandarin Speech,” 
IEEE Trans. on Audio, Speech and Language Processing, vol. 17, no. 
7, pp. 1263-1278, 2009. 
[3] J. Kolar, E. Shriberg, and Y. Liu, “On speaker-specific prosodic 
models for automatic dialog act segmentation of multiparty meetings,” 
in Proc. of Interspeech 2006, pp. 2014-2017. 
[4] S. Ananthakrishnan and S. Narayanan, "Unsupervised Adaptation of 
Categorical Prosody Models for Prosody Labeling and Speech 
Recognition," IEEE Transactions on Audio, Speech, and Language 
Processing, vol.17, no.1, pp.138-149, 2009. 
[5] C. Y. Chiang, S. H. Chen, H. M. Yu, and Y. R. Wnag, “Unsupervised 
Joint Prosody Labeling and Modeling for Mandarin Speech” J. Acoust. 
Soc. Am., vol. 125, no. 2, pp. 1164-1183, 2009. 
[6] C.-Y. Tseng, S.-H. Pin, Y.-L. Lee, H.-M. Wang and Y.-C. Chen, 
“Fluent speech prosody: framework and modeling,” Speech Commun., 
vol.46, Issues 3-4, Special Issue on Quantitative Prosody modeling for 
Natural Speech Description and Generation, pp. 284-309, 2005. 
[7] S. C. Tseng, “Processing spoken mandarin corpora,” Traitement 
Automatique des Langues, vol. 45, no. 2, pp. 89–108, 2004. 
[8] S. C. Tseng, “Repairs in Mandarin Conversation,” Journal of Chinese 
Linguistics, vol. 34, no.1, pp. 80-120, 2006 
96年度專題研究計畫研究成果彙整表 
計畫主持人：陳信宏 計畫編號：96-2221-E-009-030-MY3 
計畫名稱：客語文句轉語音及語音辨認之研究 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 3 0 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 2 2 100%  
博士生 4 2 200%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
 
