2[13], [19], [23], [24], [28], [31], [35], [36], further addressed
the QoS-related issue in the IEEE 802.11e-based network. In
[9], [10], Gannoune and Robert proposed the dynamic tuning
method on the maximum and minimum contention windows
to enhance performance of high-priority services in the ad hoc
mode. To support VoIP, a framework was proposed by Hwang
and Cho [13] for the IEEE 802.11e network. Iera et al. [19]
enhanced QoS of multimedia flows by dynamically adjusting
transmission rates for multimedia flows. In [23], Kim and Cho
estimated the status of contention using the virtual group (VG)
scheme to reduce collision rates. Lan et al. [24] proposed a
contention adaption (CA) scheme to reduce collision rates and
shorten delay time. In [28], a priority-based scheme for band-
width assignment depending on different traffic categories was
proposed by Mangold. In [31], a dynamic adjustment method
of the minimum contention window based on the network
status and needs of applications was proposed by Romdhani
et al. to achieve reduction of the collision rate and increase of
the medium utilization. Vinnakote et al. [35] shortened delay
time by adjusting the size of contention window and the length
of the arbitrary inter frame space (AIFS). In [36], Wong and
Donaldson proposed an age-dependent backoff (ADB) scheme
for adjusting the contention window according to time spent
in queue of real-time services to shorten delay of real-time
services.
For QoS-oriented wireless LANs, e.g., the IEEE 802.11e-
based wireless LAN, QoS guarantee is definitely an issue of
extreme importance. Except QoS guarantee, how to fairly allo-
cate resources of networks to different services is an extremely
important issue deserved to be addressed as well. Hence, a fair
scheme, for example, a fair scheduling scheme, to guarantee
fair resource sharing among services of different priorities in
the QoS-oriented wireless LAN is desirable and necessary.
To address this issue, literature review on scheduling is given
as follows. In the past, scheduling schemes for either wired
or wireless networks were extensively studied, e.g., [5], [21],
[22]. For having more specific discussion on fair scheduling
in wireless LANs, one may pay special attention to distributed
weighted fair queueing (DWFQ) [2], distributed elastic round
robin (DERR) [8], enhanced EDCF (EEDCF) [25], backoff-
interval based weighted fair scheduling with strict priority
(BIWF-SP) [26], IFS-based distributed fair queueing with
strict priority (IDFQ-SP) [26], adaptive fair enhanced DCF
(AFEDCF) [27], distributed deficit round robin (DDRR) [30],
and distributed fair scheduling (DFS) [34]. DWFQ [2] and
AFEDCF [27] ensure fairness by adjusting the contention
window, while DFS [34] adjusts the backoff interval to achieve
fairness. With the aid of mapping functions from allowance
[8], finish tag derived via DFS [26], and deficit count [30] to
values of IFS, no backoff is involved in DERR [8], IDFQ-
SP [26], and DDRR [30], which can achieve fairness by
suitably controlling parameters, including allowance, finish
tag, and deficit count etc. In [25], EEDCF was proposed
to address fairness and QoS together by incorporating the
allowance concept into the backoff interval adjustment and
using different values of weights to set different priorities for
offering differentiated services, while BIWF-SP [26] applies
the concept of DFS to the backoff procedure of EDCA to
achieve fairness and QoS guarantee.
Except the aforementioned papers, there are some other
papers addressed QoS and scheduling together, e.g., [3], [7],
[11], [20], [29], [32]. In [11], Grilo et al. proposed a scheduling
algorithm called scheduling based on estimated transmission
times - earliest due date (SETT-EDD) for HCF to achieve
better performance than the TGe scheduler [33] in IEEE
802.11e wireless LANs. Applying the concept of the virtual
packet, Fallah et al. [7] proposed a scheduling framework
called multiple access hybrid scheduling (MAHS) at the access
point for IEEE 802.11e wireless LANs to enable the use of
conventional schedulers for scheduling both uplink and down-
link packets. Utilizing adaptive service intervals, transmission
opportunities, and polling order, an application-aware adaptive
802.11e QoS scheduler for the centralized polling-based HCF
controlled channel access (HCCA) was proposed by Inan et al
[20]. In [32], a traffic scheduling algorithm performing channel
allocation based on the actual traffic for HCCA called adaptive
resource reservation over WLANs (ARROW) was proposed by
Skyrianoglou et al. In [29], Park et al. proposed a fair QoS
agent (FQA) for simultaneously providing per-class QoS and
per-station fair channel sharing in wireless access LANs. To
provide fair services and support QoS requirements in IEEE
802.11 networks with multiple access points, Bejerano and
Bhatia [3] presented a framework called MiFi based on the
centralized coordination.
In this project, we also aim at proposing fair schedul-
ing schemes, i.e., EDDRR, EDERR, EDDRR-BI, EDERR-
BI, which are capable of handling the interplay of fairness
and QoS simultaneously in the QoS-oriented IEEE 802.11e-
based wireless LAN based on concepts of deficit count
and allowance with cross-layer consideration. The proposed
scheduling schemes are designed for EDCA, while scheduling
schemes or frameworks proposed in [3], [11], [20], [32] are
designed for HCCA. Unlike DDRR [30] and DERR [8], the
proposed schemes employ multiple types of deficit count and
allowance so that QoS handling becomes easy. Moreover, the
proposed scheduling schemes are easy to implement because
of low complexity as compared to the DFS-based schemes,
e.g., IDFQ-SP [26], BIWF-SP [26]. Last but not least, the
proposed scheduling schemes not only provide better QoS
but also achieve better flow-level and station-level fairness,
while FQA [29] only provides per-station fairness with per-
class QoS. In this project, reasonable definitions of weights are
also explicitly given for EDDRR , EDERR, EDDRR-BI, and
EDERR-BI, but only manual setting on weights is employed
by EEDCF [25], resulting in an indirect or even unreasonable
way to handle QoS requirements.
The rest of the project is organized as follows. In Section
II, the proposed schemes are described in detail. To reflect
fairness, definitions of weights are definitely important. Hence,
Section III defines different types of weight. To examine the
performance of the proposed schemes, Section IV provides
extensive numerical examples with discussions. We show that
the proposed schemes not only offer better fairness but also
improve transmission efficiency. Finally, Section V gives the
self evaluation for the project.
4via mapping from the deficit count to the inter frame space.
IFSD,ja,i (t) =
SIFS + PIFS
2
− αDa DCja,i(t)rand(1, βD),(5)
IFSD,jv,i (t) = PIFS− αDv DCjv,i(t)rand(1, βD), (6)
IFSD,jd,i (t) = DIFS− αDd DCjd,i(t)rand(1, βD), (7)
where the superscript D or the subscript D is used to denote
EDDRR, rand(1, βD) denotes a random number between 1 and
βD (βD > 1), and IFSD,jl,i (t) denotes the inter frame space
at time t of the ith flow of access category l (l = a, v, d)
in station j. Note that different constants αDl , l = a, v, d,
are defined to make the resultant inter frame space IFSD,jl,i (t)
fall within [SIFS, (SIFS + PIFS)/2] for the access category
of voice, i.e., l = a, [(SIFS + PIFS)/2, PIFS] for access
the category of video, i.e., l = v, and [PIFS,DIFS] for the
access category of data, i.e., l = d to achieve that i) a higher
priority corresponds to a shorter inter frame space; ii) a larger
deficit count may have a shorter inter frame space in order
to get the medium more easer; iii) the same deficit count
can have a different inter frame space by using rand(1, βD).
Therefore, the above design allows EDDRR to guarantee
QoS of different access categories, to avoid starvation so
that fairness can be taken care, and to circumvent backoff if
perfect discrimination on values of the inter frame space can
be achieved (or less collisions occur for EDDRR as compared
to EDCA if no perfect discrimination on values of the inter
frame space is assumed and these collisions can still invoke
backoff procedures as those specified by IEEE 802.11e).
C. Enhanced Distributed Elastic Round Robin with Backoff
Interval (EDERR-BI)
Instead of using deficit counts, some elastic and adjustable
amounts of traffic data allowed for transmission called al-
lowances [8] are adopted in EDERR-BI to govern the kernel
of scheduling. Note that only one single type of allowance is
defined in [8] using a fixed quantum Q and a variable time
interval T . Once an allowance is set, the traffic data associated
with that allowance can be consecutively transmitted until the
amount of the traffic data is a bit more than the allowance.
More specifically, three types of allowance are defined in
EDERR-BI for access categories of audio, video, and data.
The definitions of these allowances at time t of the ith flow
of access category l in station j denoted by Ajl,i(t) are given
as follows:
Ajl,i(t) = K
j
l,i × (t− t′)− Ejl,i(t′), l = a, v, d, (8)
where Ejl,i(t′) is the excess amount at time t′ (t′ ≤ t) of the ith
flow of access category l in station j, which can be expressed
in terms of allowance at time t′ and the total amount of traffic
data transmitted at time t′ by the ith flow of access category
l in station j denoted by F jl,i(t′) as follows:
Ejl,i(t
′) = F jl,i(t
′)−Ajl,i(t′), l = a, v, d. (9)
From (8) and (9), one may easily understand that i) allowances
are in proportional to the desired throughput so that allowances
are allotted according to different demands; ii) allowances
increase linearly as time goes so that starvation for low-priority
access categories can be avoided; iii) deduction of the excess
amount at the latest time instant from the allowance enforces
fair scheduling. Compared to the definition of the allowance in
[8], our definitions of allowances give direct parameter setting
and ease operations.
Complying with the MAC operation and QoS requirement in
the IEEE 802.11e LAN necessitates the following relationship
between the allowance and the temporary backoff interval like
EDDRR-BI.
TBIE,jl,i (t) = CW
l
max − φEl Ajl,i(t), l = a, v, d, (10)
where superscript E is used to explicitly denote EDERR–
BI and constant φEl should be properly selected to make
TBIE,jl,i (t) fall within a suitable range according to the
IEEE 802.11e standard. Applying a similar design principle
employed by (4), the backoff interval BIE,jl,i (t) at time t of
the ith flow of access category l in station j can be defined
below using the temporary backoff interval TBIE,jl,i (t) and the
collision rate c.
BIE,jl,i (t) = max(0.2, 1− c)TBIE,jl,i (t), l = a, v, d. (11)
Hence, the backoff interval determined by (11) simultaneously
considers concepts of fair scheduling, QoS requirement, and
cross-layer design for performance improvement. For the same
reasoning in EDDRR-BI, the adjustment of the backoff interval
caused by a collision is not further addressed in this project.
D. Enhanced Distributed Elastic Round Robin (EDERR)
In contrast to EDERR-BI, we now design EDERR for
IEEE 802.11e. Using the three types of allowance defined
for EDERR–BI, i.e., Ajl,i(t), l = a, v, d, EDERR accumulate
allowances according to (8) in which the previous excess
amount defined by (9) is deducted. Similar to EDDRR, ED-
ERR works like EDCA but changes the inter frame space using
the mapping from the allowance to the inter frame space given
below.
IFSE,ja,i (t) =
SIFS + PIFS
2
− αEa Aja,i(t)rand(1, βE),(12)
IFSE,jv,i (t) = PIFS− αEv Ajv,i(t)rand(1.0, βE), (13)
IFSE,jd,i (t) = DIFS− αEd Ajd,i(t)rand(1, βE), (14)
where the superscript E or the subscript E denotes EDERR and
rand(1, βE) represents a random number between 1 and βE ,
where βE > 1, and IFSE,jl,i (t) denotes the inter frame space at
time t of the ith flow of access category l (l = a, v, d) in station
j. Like EDDRR, three constants αEl , l = a, v, d, are defined
so that the resultant inter frame space IFSE,jl,i (t) can fall within
[SIFS, (SIFS+PIFS)/2] when l = a, [(SIFS+PIFS)/2, PIFS]
when l = v, and [PIFS,DIFS] when l = d, respectively. The
ideas behind (12)–(14) are i) QoS guarantee: setting a shorter
inter frame space for a higher priority enables service differ-
entiation and QoS guarantee; ii) fair scheduling: no starvation
exists since a shorter inter frame space may be set for a larger
amount of allowance so that getting the medium becomes more
easer; iii) collision reduction/elimination: different values of
the inter frame space are set for the same allowance with
63 6 9 12 15 18
0
20
40
60
80
100
120
140
Number of stations
Th
ro
ug
hp
ut
 (K
B/
s)
Audio, EDCA
Audio, EEDCF
Audio, EDDRR−BI
Audio, EDERR−BI
Video, EDCA
Video, EEDCF
Video, EDDRR−BI
Video, EDERR−BI
Data, EDCA
Data, EEDCF
Data, EDDRR−BI
Data, EDERR−BI
(a) Individual throughput.
0 2 4 6 8 10 12 14 16 18
0
500
1000
1500
2000
2500
Number of stations
To
ta
l t
hr
ou
gh
pu
t (K
B/
s)
EDCA
EEDCF
EDDRR−BI
EDERR−BI
(b) Total throughput.
Fig. 4. Throughput comparison among EDCA, EEDCF, EDDRR–BI, and
EDERR–BI.
• throughput,
• delay,
• collision rate,
• measures of fairness: the reciprocal of standard deviation
about throughput-to-weight ratios can be employed to
indicate the degree of fairness [8]. Alternatively, the
closeness of fairness index FI , which is formally defined
as
FI = (
∑
f
Sf
wf
)2/
∑
f
∑
f
(
Sf
wf
)2,
where Sf and wf represent throughput and weight,
respectively, of flow (station) f , to the fairness index of
the ideal/perfect case with value of 1 can be applied to
represent the degree of fairness as well. For example, the
reciprocal of difference of fairness indices with respect
to the ideal case, i.e., 1/(1 − FI), can be simply used
to show the degree of this closeness [8], thus providing
another way to exhibit the degree of fairness.
B. Simulation Results
QoS-related performance, including throughput, delay, and
collision rate, and degree of fairness for different schemes,
including EDCA, EEDCF, EDDRR–BI, EDERR–BI, DERR,
EDDRR, and EDERR, are given as follows.
1) Throughput:
Let us first examine individual throughput given in Figs. 4(a)
and 5(a). First, one can see that constant throughput is kept for
the access category of audio because it has the highest priority
for all schemes. Second, throughput for the access category of
video starts to decrease when the number of stations reaches
9, 12, and 15 for DERR, EDCA, and EEDCF, while the
3 6 9 12 15 18
0
20
40
60
80
100
120
140
Number of stations
Th
ro
ug
hp
ut
 (K
B/
s)
Audio, EDCA
Audio, DERR
Audio, EDDRR
Audio, EDERR
Video, EDCA
Video, DERR
Video, EDDRR
Video, EDERR
Data, EDCA
Data, DERR
Data, EDDRR
Data, EDERR
(a) Individual throughput.
0 2 4 6 8 10 12 14 16 18
0
500
1000
1500
2000
2500
Number of stations
To
ta
l t
hr
ou
gh
pu
t (K
B/
s)
EDCA
DERR
EDDRR
EDERR
(b) Total throughput.
Fig. 5. Throughput comparison among EDCA, DERR, EDDRR, and EDERR.
same level (128 KB/s) is kept for EDDRR-BI, EDERR-BI,
EDDRR, and EDERR. Considering results at 18 stations,
we note that 8% (10 KB/s), 1.5% (2 KB/s), and 12% (14
KB/s) of improvement for EDDRR-BI, EDERR-BI, EDDRR,
and EDERR as compared to EDCA, EEDCF, and DERR,
respectively, can be observed. Third, a notable decreasing trend
in throughput for the access category of data is observed for
all schemes when the number of stations is over 9. Fixing
the number of stations at 18, we have 14% (3 KB/s), 28% (6
KB/s), 38% (8 KB/s), and 47% (10 KB/s) of improvement for
EDDRR-BI, EDERR-BI, EDDRR, and EDERR as compared
to EDCA; we have 41% (7 KB/s) and 58% (10 KB/s) of
improvement for EDDRR-BI and EDERR-BI as compared
to EEDCF; we have 7% (2 KB/s) and 14% (4 KB/s) of
improvement for EDDRR and EDERR as compared to DERR.
Regarding throughput for the access category of data, EEDCF
even performs worse than EDCA, while DERR performs
much better than EDCA. Moreover, EDERR performs best
and EDDRR, DERR, EDERR-BI, and EDDRR-BI follow suc-
cessively. From the above observations, we see that EDERR
and EDDRR can provide better throughput for all access
categories among schemes without backoff intervals, while
EDDRR-BI and EDERR-BI can provide better throughput for
all access categories among schemes with backoff intervals.
As for total throughput, one may see Figs. 4(b) and 5(b)
for details. We note that comparable throughput is observed
for all schemes when the number of stations is less than or
equal to 9. Over 9 stations, the best to the worst schemes
are EDERR, EDDRR, EDERR-BI, EDDRR-BI, and EDCA,
respectively. As for DERR and EEDCF, they perform worse
than EDCA within the interval [9, 13] but better than EDCA
when the number of stations reaches 14 and beyond.
850 100 150 200 250 300 350 400
0
0.001
0.002
0.003
0.004
0.005
0.006
0.007
0.008
0.009
0.01
Time (sec.)
Th
ro
ug
hp
ut
 / 
we
ig
ht
 (M
B/
s)
Audio 1
Audio 2
Audio 3
(a) EDDRR-BI.
50 100 150 200 250 300 350 400
0
0.001
0.002
0.003
0.004
0.005
0.006
0.007
0.008
0.009
0.01
Time (sec.)
Th
ro
ug
hp
ut
 / 
we
ig
ht
 (M
B/
s)
Audio 1
Audio 2
Audio 3
(b) EDERR-BI.
50 100 150 200 250 300 350 400
0
0.001
0.002
0.003
0.004
0.005
0.006
0.007
0.008
0.009
0.01
Time (sec.)
Th
ro
ug
hp
ut
 / 
we
ig
ht
 (M
B/
s)
Audio 1
Audio 2
Audio 3
(c) EEDCF.
50 100 150 200 250 300 350 400
0
0.001
0.002
0.003
0.004
0.005
0.006
0.007
0.008
0.009
0.01
Time (sec.)
Th
ro
ug
hp
ut
 / 
we
ig
ht
 (M
B/
s)
Audio 1
Audio 2
Audio 3
(d) EDDRR.
50 100 150 200 250 300 350 400
0
0.001
0.002
0.003
0.004
0.005
0.006
0.007
0.008
0.009
0.01
Time (sec.)
Th
ro
ug
hp
ut
 / 
we
ig
ht
 (M
B/
s)
Audio 1
Audio 2
Audio 3
(e) EDERR.
50 100 150 200 250 300 350 400
0
0.001
0.002
0.003
0.004
0.005
0.006
0.007
0.008
0.009
0.01
Time (sec.)
Th
ro
ug
hp
ut
 / 
we
ig
ht
 (M
B/
s)
Audio 1
Audio 2
Audio 3
(f) DERR.
50 100 150 200 250 300 350 400
0
0.001
0.002
0.003
0.004
0.005
0.006
0.007
0.008
0.009
0.01
Time (sec.)
Th
ro
ug
hp
ut
 / 
we
ig
ht
 (M
B/
s)
Audio 1
Audio 2
Audio 3
(g) EDCA.
Fig. 8. Throughput-to-weight ratios among flows within the access category of audio.
50 100 150 200 250 300 350 400
0.18
0.19
0.2
0.21
0.22
0.23
0.24
0.25
0.26
Time (sec.)
Th
ro
ug
hp
ut
 / 
we
ig
ht
 (M
B/
s)
Video 1
Video 2
Video 3
(a) EDDRR-BI.
50 100 150 200 250 300 350 400
0.18
0.19
0.2
0.21
0.22
0.23
0.24
0.25
0.26
Time (sec.)
Th
ro
ug
hp
ut
 / 
we
ig
ht
 (M
B/
s)
Video 1
Video 2
Video 3
(b) EDERR-BI.
50 100 150 200 250 300 350 400
0.18
0.19
0.2
0.21
0.22
0.23
0.24
0.25
0.26
Time (sec.)
Th
ro
ug
hp
ut
 / 
we
ig
ht
 (M
B/
s)
Video 1
Video 2
Video 3
(c) EEDCF.
50 100 150 200 250 300 350 400
0.18
0.19
0.2
0.21
0.22
0.23
0.24
0.25
0.26
Time (sec.)
Th
ro
ug
hp
ut
 / 
we
ig
ht
 (M
B/
s)
Video 1
Video 2
Video 3
(d) EDDRR.
50 100 150 200 250 300 350 400
0.18
0.19
0.2
0.21
0.22
0.23
0.24
0.25
0.26
Time (sec.)
Th
ro
ug
hp
ut
 / 
we
ig
ht
 (M
B/
s)
Video 1
Video 2
Video 3
(e) EDERR.
50 100 150 200 250 300 350 400
0.18
0.19
0.2
0.21
0.22
0.23
0.24
0.25
0.26
Time (sec.)
Th
ro
ug
hp
ut
 / 
we
ig
ht
 (M
B/
s)
Video 1
Video 2
Video 3
(f) DERR.
50 100 150 200 250 300 350 400
0.18
0.19
0.2
0.21
0.22
0.23
0.24
0.25
0.26
Time (sec.)
Th
ro
ug
hp
ut
 / 
we
ig
ht
 (M
B/
s)
Video 1
Video 2
Video 3
(g) EDCA.
Fig. 9. Throughput-to-weight ratios among flows within the access category of video.
tively, as compared to EDCA; ii) 8% and 15% of improvement
are achieved by EDDRR-BI and EDERR-BI, respectively, as
compared to EEDCF; iii) 59% and 115% of improvement are
achieved by EDDRR and EDERR, respectively, as compared
to DERR. In Fig. 10, throughput-to-weight ratios among flows
within the access category of data are given with values of
standard deviation 0.0133, 0.011, 0.011, 0.008, 0.0137, 0.017,
and 0.025 for EDDRR-BI, EDERR-BI, EDDRR, EDERR,
EEDCF, DERR, and EDCA, respectively. Again, these val-
ues enable us to have the following comparison results: i)
88%, 123%, 117%, 189% of improvement are achieved by
EDDRR-BI, EDERR-BI, EDDRR, and EDERR, respectively,
as compared to EDCA; ii) 7% and 22% of improvement
are achieved by EDDRR-BI and EDERR-BI, respectively, as
compared to EEDCF; iii) 48% and 98% of improvement are
achieved by EDDRR and EDERR, respectively, as compared
to DERR. Alternatively, we may observe the degree of fairness
via differences of fairness indices with respect to the ideal
case. Figs. 11(a) and 11(d) illustrate that the difference con-
cerning the access category of audio is zero (perfect fairness)
for all schemes. From Figs. 11(b) and 11(e), we have the
degree of fairness concerning the access category of video
1/(1 − 0.953) .= 21 for EDDRR-BI, 1/(1 − 0.9545) .= 22
for EDERR-BI, 1/(1 − 0.966) .= 29 for EDDRR, 1/(1 −
0.975) .= 40 for EDERR, 1/(1 − 0.948) .= 19 for DERR,
1/(1−0.95) .= 20 for EEDCF, 1/(1−0.9445) .= 18 for EDCA,
giving 17%, 22%, 66%, 122% of improvement achieved by
EDDRR-BI, EDERR-BI, EDDRR, and EDERR, respectively,
as compared to EDCA, 5% and 10% of improvement achieved
by EDDRR-BI and EDERR-BI, respectively, as compared to
10
50 100 150 200 250 300 350 400
0.1
0.15
0.2
0.25
0.3
0.35
0.4
0.45
0.5
Time (sec.)
Th
ro
ug
hp
ut
 / 
we
ig
ht
 (M
B/
s)
Audio 1
Audio 2
Audio 3
Video 1
Video 2
Video 3
Data 1
Data 2
Data 3
(a) EDDRR-BI.
50 100 150 200 250 300 350 400
0.1
0.15
0.2
0.25
0.3
0.35
0.4
0.45
0.5
Time (sec.)
Th
ro
ug
hp
ut
 / 
we
ig
ht
 (M
B/
s)
Audio 1
Audio 2
Audio 3
Video 1
Video 2
Video 3
Data 1
Data 2
Data 3
(b) EDERR-BI.
50 100 150 200 250 300 350 400
0.1
0.15
0.2
0.25
0.3
0.35
0.4
0.45
0.5
Time (sec.)
Th
ro
ug
hp
ut
 / 
we
ig
ht
 (M
B/
s)
Audio 1
Audio 2
Audio 3
Video 1
Video 2
Video 3
Data 1
Data 2
Data 3
(c) EEDCF.
50 100 150 200 250 300 350 400
0.1
0.15
0.2
0.25
0.3
0.35
0.4
0.45
0.5
Time (sec.)
Th
ro
ug
hp
ut
 / 
we
ig
ht
 (M
B/
s)
Audio 1
Audio 2
Audio 3
Video 1
Video 2
Video 3
Data 1
Data 2
Data 3
(d) EDDRR.
50 100 150 200 250 300 350 400
0.1
0.15
0.2
0.25
0.3
0.35
0.4
0.45
0.5
Time (sec.)
Th
ro
ug
hp
ut
 / 
we
ig
ht
 (M
B/
s)
Audio 1
Audio 2
Audio 3
Video 1
Video 2
Video 3
Data 1
Data 2
Data 3
(e) EDERR.
50 100 150 200 250 300 350 400
0.1
0.15
0.2
0.25
0.3
0.35
0.4
0.45
0.5
Time (sec.)
Th
ro
ug
hp
ut
 / 
we
ig
ht
 (M
B/
s)
Audio 1
Audio 2
Audio 3
Video 1
Video 2
Video 3
Data 1
Data 2
Data 3
(f) DERR.
50 100 150 200 250 300 350 400
0.1
0.15
0.2
0.25
0.3
0.35
0.4
0.45
0.5
Time (sec.)
Th
ro
ug
hp
ut
 / 
we
ig
ht
 (M
B/
s)
Audio 1
Audio 2
Audio 3
Video 1
Video 2
Video 3
Data 1
Data 2
Data 3
(g) EDCA.
Fig. 12. Throughput-to-weight ratios among flows across different access categories.
3 6 9 12 15 18
0
0.02
0.04
0.06
0.08
0.1
0.12
Number of stations
D
iff
er
en
ce
 o
f f
ai
rn
es
s 
in
di
ce
s
EDCA
EEDCF
EDDRR−BI
EDERR−BI
(a)
3 6 9 12 15 18
0
0.02
0.04
0.06
0.08
0.1
0.12
Number of audio flows
D
iff
er
en
ce
 o
f f
ai
rn
es
s 
in
di
ce
s
EDCA
DERR
EDDRR
EDERR
(b)
Fig. 13. Differences of fairness indices for flows across different access
categories.
respectively, as compared to EEDCF, and 67% and 122% of
improvement gained by EDDRR and EDDRR, respectively,
as compared to DERR. In Fig. 13, differences of fairness
indices with respect to the ideal case for flows across different
access categories are shown. Figs. 13(a)–(b) enable us to
obtain the degree of fairness for different schemes as follows:
1/(1−0.918) .= 12 for EDCA, 1/(1−0.942) .= 17 for EEDCF,
1/(1 − 0.945) .= 18 for EDDRR-BI, 1/(1 − 0.958) .= 24 for
EDERR-BI, 1/(1−0.94) .= 17 for DERR, 1/(1−0.963) .= 27
for EDDRR, and 1/(1 − 0.972) .= 36 for EDERR. These
3 6 9 12 15 18
0
0.02
0.04
0.06
0.08
0.1
0.12
0.14
0.16
Number of stations
D
iff
er
en
ce
 o
f f
ai
rn
es
s 
in
di
ce
s
EDCA
EEDCF
EDDRR−BI
EDERR−BI
(a)
3 6 9 12 15 18
0
0.02
0.04
0.06
0.08
0.1
0.12
0.14
0.16
Number of audio flows
D
iff
er
en
ce
 o
f f
ai
rn
es
s 
in
di
ce
s
EDCA
DERR
EDDRR
EDERR
(b)
Fig. 15. Differences of fairness indices for stations.
values give the following comparison results: i) 50% and 6%
of improvement for EDDRR-BI and 100% and 41% of im-
provement for EDERR-BI as compared to EDCA and EEDCF,
respectively, are obtained. ii) 125% and 59% of improvement
for EDDRR and 200% and 111% of improvement for EDERR
as compared to EDCA and DERR, respectively, are obtained.
Finally, we discuss fairness among stations. Using
throughput-to-weight ratios among stations for different
schemes shown in Fig. 14, we have 97%, 230%, 265%, and
341% of improvement gained by EDDRR-BI, EDERR-BI,
EDDRR, and EDERR, respectively, as compared to EDCA,
12
[7] Y. P. Fallah, A. Elfeitori, and H. Alnuweiri, “A unified scheduling
approach for guaranteed services over IEEE 802.11e wireless LANs,”
in Proc. IEEE BROADNETS ’04, 2004, pp. 375–384.
[8] H. W. Ferng, C. F. Lee, J. J. Huang, and G. M. Chiu, “Designing a fair
scheduling mechanism for IEEE 802.11 wireless LANs,” IEEE Commun.
Lett., vol. 9, no. 4, pp. 301–303, Apr. 2005.
[9] L. Gannoune and S. Robert, “Dynamic tuning of the maximum contention
window (CWmax) for enhanced service differentiation in IEEE 802.11
wireless ad-hoc networks,” in Proc. IEEE VTC ’04, 2004, pp. 2956–2961.
[10] L. Gannoune and S. Robert, “Dynamic tuning of the minimum con-
tention window (CWmin) for enhanced service differentiation in IEEE
802.11 wireless ad-hoc networks,” in Proc. IEEE PIMRC ’04, 2004, pp.
311–317.
[11] A. Grilo, M. Macedo, and M. Nunes, “A scheduling algorithm for QoS
support in IEEE802.11e networks,” IEEE Wireless Commun., vol. 10, no.
3, pp. 36–43, Jun. 2003.
[12] K. A. Hua, Y. Cai, and S. Sheu, “Patching: A multicast technique for
true video-on-demand services,” in Proc. ACM Multimedia ’98, 1998, pp.
191–200.
[13] G. Hwang and D. Cho, “New access scheme for VoIP packets in IEEE
802.11e wireless LANs,” IEEE Commun. Lett., vol. 9, no. 7, pp. 667–669,
Jul. 2005.
[14] IEEE 802.11 WG, “Information technology – Telecommunications and
information exchange between systems – Local and metropolitan area
networks – Specific requirements – Part 11: Wireless LAN Medium
Access Control (MAC) and Physical Layer (PHY) Specifications,” 1999.
[15] IEEE 802.11 WG, “Supplement to IEEE standard for information tech-
nology telecommunications and information exchange between systems
– Local and metropolitan area networks – Specific requirements – Part
11: Wireless LAN Medium Access Control (MAC) and Physical Layer
(PHY) Specifications: High-speed Physical Layer in the 5 GHz Band,”
1999.
[16] IEEE 802.11 WG. “Supplement to IEEE standard for information
technology – Telecommunications and information exchange between
systems – Local and metropolitan area networks – Specific requirements
– Part 11: Wireless LAN Medium Access Control (MAC) And Physical
Layer (PHY) Specifications: Higher-speed Physical Layer Extension in
the 2.4 GHz Band,” 1999.
[17] IEEE 802.11 WG, “IEEE standard for information technology –
Telecommunications and information exchange between systems – Local
and metropolitan area networks – Specific requirements – Part 11:
Wireless LAN Medium Access Control (MAC) and Physical Layer (PHY)
Specifications. Amendment 4: Further Higher Data Rate Extension in the
2.4 GHz Band,” 2003.
[18] IEEE 802.11 WG, “IEEE Standard for Information technology –
Telecommunications and information exchange between systems – Local
and metropolitan area networks – Specific requirements – Part 11:
Wireless LAN Medium Access Control (MAC) and Physical Layer (PHY)
Specifications. Amendment 8: Medium Access Control (MAC) Quality
of Service Enhancements,” 2005.
[19] A. Iera, A. Molonaro, G. Ruggeri, and D. Tripodi, “Dynamic prioritza-
tion of multimedia flows for improving QoS and throughput in IEEE
802.11e WLANs,” in Proc. IEEE ICC ’05, 2005, pp. 1184–1189.
[20] I. Inan, F. Keceli, and E Ayanoglu, “An adaptive multimedia QoS
scheduler for 802.11e wireless LANs,” in Proc. IEEE ICC ’06, 2006,
pp. 5263–5270.
[21] S. S. Kanhere, H. Sethu, and A. B. Parekh, “Fair and efficient packet
scheduling using elastic round robin,” IEEE Trans. Parallel and Dis-
tributed Systems, vol. 13, no. 3, pp. 324–336, Mar. 2002.
[22] M. Katevenis, S. Sidiropoulos, and C. Courcoubetis, “Weighted round-
robin cell multiplexing in a general-purpose ATM switch chip,” IEEE J.
Sel. Areas Commun., vol. 9, no. 8, pp. 1265–1279, Oct. 1991.
[23] S. M. Kim and Y. J. Cho, “ QoS enhancement scheme of EDCF in
IEEE 802.11 wireless LANs,” IEE Electronics Lett., vol. 40, no. 17, pp.
1091–1092, Aug. 2004.
[24] Y. W. Lan, J. H. Yeh, J. C. Chen, and Z. T. Chou, “Performence
enhancement of IEEE 802.11e EDCA by contention adaption,” in Proc.
IEEE VTC ’05, 2005, pp. 2096–2100.
[25] C. F. Lee, “Fair and efficient scheduling mechanisms for IEEE 802.11
wireless LANs,” Master Thesis of Natl. Taiwan Univ. of Sci. and Tech.,
Taipei, Taiwan, Jun. 2004.
[26] J. F. Lee, W. Liao, and M. C. Chen, “A per-class QoS service model in
IEEE 802.11e WLANs,” in Proc. IEEE QShine ’05, 2005.
[27] M. Malli, Q. Ni, T. Turletti, and C. Barakat, “Adaptive fair channel
allocation for QoS enhancement in IEEE 802.11 wireless LANs,” in Proc.
IEEE ICC ’04, 2004, pp. 3470–3475.
[28] S. Mangold, “IEEE 802.11e – Coexistence of overlapping basic service
sets,” in Proc. of the Mobile Venue ’02, 2002, pp. 131–135.
[29] E. C. Park, D. Y. Kim, C. H. Choi, and J. So, “Improving quality of
service and assuring fairness in WLAN access networks,” IEEE Trans.
Mobile Computing, vol. 6, no. 4, pp. 337–350, Apr. 2007.
[30] W. Pattara-Atikom, S. Banerjee, and P. Krishnamurthy, “Starvation
prevention and quality of service in wireless LANs,” in Proc. IEEE
Wireless Personal Multimedia Communications ’02, 2002, pp. 1078–1082.
[31] L. Romdhani, Qiang Ni, and T. Turletti, “Adaptive EDCF: Enhanced
service differentiation for IEEE 802.11 wireless ad-hoc networks,” in
Proc. IEEE WCNC ’03, 2003, pp. 1373–1378.
[32] D. Skyrianoglou, N. Passas, and A. K. Salkintzis, “ARROW: An efficient
traffic scheduling algorithm for IEEE 802.11e HCCA,” IEEE Trans.
Wireless Commun., vol. 5, no. 12, pp. 3558–3567, Dec. 2006.
[33] A. Soomro, S. Shankar, J. D. Prado, Y. Ohtani, J. Kowalski, F. Simpson,
and I. L. W. Lih, “TGe Scheduler – Minimum Performance Require-
ments,” IEEE 802.11-02/709r0, Nov. 2002.
[34] N. H. Vaidya, P. Bahl, and S. Gupta, “Distributed fair scheduling in a
wireless LAN,” in Proc. ACM MobiCom ’00, 2000, pp. 167–178.
[35] S. Vinnakote, N. Svs, S. Pasupuleti, and D. Das,“New-MAC protocol
for enhancement of QoS performance in wireless LAN,” in Proc. IFIP
Wireless and Optical Communications Networks ’06, 2006, pp. 1–5.
[36] G. W. Wong and R. W. Donaldson, “Improving the QoS performance
of EDCF in IEEE 802.11e wireless LANs,” in Proc. IEEE PACRIM ’03,
2003, pp. 392–396.
[37] The network simulator – ns-2, http://www.isi.edu/nsnam/ns.
2SVoice
Voice Interval Data Interval Dlim
DL   UL
TSCM
SData
DCF
TSCM cycle TSCM cycle
1 2 KData
flow 1 flow 2 flow 1 flow 2
Fig. 1. Time structure of TSCM.
participate in the transmitting process and the DCF mode gives
opportunities to all STAs, the TSCM mode should not keep
the control of the channel for a long time. Hence, the TSCM
mode will be terminated after some fixed contiguous cycles,
say, Ncycle, to enable the DCF mode so that new STAs have
opportunities to join in.
B. Time Structure of TSCM
As explained previously, TSCM is a polling-based media ac-
cess scheme. This necessitates that the system time should be
divided into consecutive cycles of channel access. In TSCM,
each cycle is further divided into two clearly distinguishable
time periods called Voice Interval and Data Interval (here,
the term “data” means all traffic different from voice) to poll
voice and data flows, respectively. The main reason for this
time allocation is to give a higher priority to the voice traffic,
which typically has the constant bit rate. With the fact that
the time to generate one packet for the vast majority of voice
codecs is much longer than the time to successfully transmit
it, a long period of packets generation is left to poll data traffic
flows. However, in order to keep the delay and jitter of voice
frames low, the length of the Data Interval should be properly
limited by Dlim, which is chosen according to the voice packet
generation time (see Fig. 1). Hence, the TSCM time structure
implicitly provides a higher priority for the voice traffic and
a lower priority for the data traffic.
Following the time structure described above, the TS coor-
dinator assigns time slots to STAs to access the media. To do
this, it first needs to calculate the length of the time slot. For
these purposes, the TS coordinator needs to get measurements
during the contention period, such as data rate of data traffic
RData and average payload sizes of data and voice traffic
denoted by LData and LV oice, respectively. According to
the time characteristics of Voice and Data intervals, it is
reasonable to assume that only one voice frame arrives during
one TSCM cycle for each voice flow in both uplink and
downlink. Furthermore, a longer Data Interval allows setting
a long enough time slot for each data flow to send multiple
data frames. This can increase data traffic throughput for sure,
while no harmful effect on the QoS of voice exists since the
Data Interval is limited by Dlim. Therefore, the length of
the time slot for data traffic is chosen to be a submultiple of
Dlim. However, it still should be long enough to transmit at
least one frame, giving a lower bound Smin which is the time
to transmit one frame with the maximum size defined by the
standard as follows:
Smin = Tmax + 2SIFS + TACK , (1)
where Tmax is the time to transmit a frame with the maximum
size, SIFS is the short inter frame space, and TACK is
the time to transmit an acknowledgement frame. With the
knowledge of parameters, e.g., LData and RData, we can find
the average number of packets expected in the data queue after
Dlim (denoted by KData) via
KData =
⌈
RData ·Dlim
LData
⌉
. (2)
Combining the above two equations leads to the setting of a
time slot for the data traffic SData as follows:
SData = max [KData(TData + 2SIFS + TACK), Smin]
(3)
where TData is the time to transmit a frame with the payload
size equal to LData. As for the voice traffic, the length of the
time slot SV oice is set to the time to transmit two frames (one
uplink and one downlink frame) with the size of LV oice:
SV oice = 2TV oice + 2SIFS, (4)
where TV oice is the time to transmit a frame with the payload
size equal to LV oice under the piggybacked acknowledgement.
Finally, the complete operation of TSCM is illustrated in
Fig. 2 by pseudo codes.
III. PERFORMANCE EVALUATION
Using the network simulator ns-2 [5], the performance of
EDCA, HCCA, Blackburst (denoted by Bburst), and TSCM
are evaluated in terms of end-to-end frame delay, number of
supported voice sessions, normalized throughput, and fairness
index. Note that we fix the number of low-priority flows
(data) and gradually increase the number of high-priority flows
(voice) to increase the system load. As for the simulation
environment, an infrastructure-based system with one AP and
four STAs under the IEEE 802.11b physical layer is taken into
consideration. For each STA, it has a number of bidirectional
64-kbps voice over IP (VoIP) traffic sources with the 160-
byte payload per 20 ms, while five data sources modeled by
FTP/TCP flows with the 1460-byte payload are generated at
the AP. About the other system parameters, they are given
in Table I. Let us now further elaborate on the choice of the
parameters for TSCM. First, the length of the Data Interval
Dlim is set to 15 ms to conform with the packet generation
time of voice codecs (which typically falls between 20 ms
and 30 ms). Next, the parameter Ncycle should be minimized
since it is related to the time that a new STA can join
the system. Because the average length of a TSCM cycle
is 20-25 ms, Ncycle is chosen to be 5 corresponding to the
contention-free period (CFP) of the HCCA mode chosen for
the experiment. Last, parameter Pth is set according to the
result of [4] which indicates that the collision probability of 0.7
results in the highly loaded network situation for which each
frame is required to be sent twice on average for a successful
transmission. Now, let us discuss the simulation results in the
following.
From Fig. 3(a) which shows the average end-to-end frame
delay, we observe first that the four schemes exhibit similar
results for the high-priority traffic (voice), while low-priority
4TABLE I
SIMULATION PARAMETERS
Parameter Value Parameter Value Parameter Value Parameter Value Parameter Value
EDCA HCCA Blackburst TSCM
Beacon 209 µs AIFShigh pr 50 µs Transmission Unit (TU) 1024 µs Dlim 15 ms
SIFS 10 µs CWhigh prmin 31 Superframe Duration 500*TU Black slot 20 µs
PIFS 30 µs AIFSlow pr 90 µs CFP Duration 100*TU Ncycle 5 cycles
DIFS 50 µs CW low prmin 63 CAP Rate 21 µs Slack time δ 5 ms
Channel Rate 11 Mbps TXOPLimit 9.53 ms CAP Max 8000 µs Pth 0.7
/* initialization */
1 repeat
2 DCF access mode is activated
3 TS coordinator measures LV oice, LData, RData
4 TS coordinator measures network condition
5 TS coordinator calculates Pc
6 cycle = 0 /* the current number of
continuous TSCM cycles */
7 while (Pc > Pth and cycle ≤ Ncycle)
/* calculation of time slots */
8 Smin = Tmax + 2SIFS + TACK
/* time slot to send one data frame */
9 S1Data = TData + 2SIFS + TACK
10 KData =
⌈
RData·Dlim
LData
⌉
11 SData = max
[
KData · S
1
Data, Smin
]
12 SV oice = 2TV oice + 2SIFS
13 TSCM access mode is activated
/* Voice Interval */
14 foreach i from (Voice STAs list)
15 TS coordinator polls station i
/* end of Voice Interval */
/* Data Interval */
16 Setting of timer TIME
17 while (TIME ≤ Dlim)
18 foreach i from (Data STAs list)
19 Setting of timer SLOT
20 while (SLOT ≤ SData)
21 TS coordinator polls station i
/* end of Data Interval */
22 TS coordinator measures network condition
23 TS coordinator calculates Pc
24 cycle = cycle + 1
/* end of current TSCM cycle */
25 until (end of system operation)
Fig. 2. Pseudo codes of the complete operation of TSCM.
traffic (data) is treated differently by each scheme. For both
EDCA and Blackburst, data traffic starves even at a low load.
As for HCCA and TSCM, acceptable delay of data frames can
be kept until there are 20 voice flows or so in the system. In
other words, TSCM outperforms both EDCA and Blackburst
and is comparable to HCCA in terms of number of supported
voice sessions when considering data traffic not being starved.
Second, two different stages for TSCM are explicitly shown
in Fig. 3(a) because it is initially controlled by the DCF
mode and the TSCM mode is activated when around 10
voice flows exist. Third, it is clear that TSCM experiences
a bit longer delay on average than the other schemes due
to its software implementation. However, the delay is still
acceptable. Shown in Fig. 3(b) is the normalized throughput
which is the percentage of the offered frames actually being
delivered to the destination. According to Fig. 3(b), Blackburst
provides almost 100% delivery of voice frames but much
loss for data traffic. One may see that a similar situation is
inherent for EDCA and HCCA. However, TSCM is able to
show high throughput for both voice and data traffic with the
smallest performance gap between these two kinds of traffic
among the four schemes. Comparing the aggregated (voice
+ data) normalized throughput when 25 voice flows exist,
TSCM shows 130% of improvement over EDCA, 95% of
improvement over Blackburst, and 15% of improvement over
HCCA.
Finally, the fairness index is reflected by Fig. 3(c). Here, the
fairness index is defined as (
∑
f
Sf
wf
)2/
∑
f
∑
f (
Sf
wf
)2, where
Sf and wf represent throughput and weight, respectively, of
flow f . As for the weight, it is calculated by wf = Df/
∑
iDi,
where Df (Di) is a desired throughput of flow f (i). In
our experiments, the desired throughput is set to 8 KB/s for
voice and 120 KB/s for data. Apparently, both EDCA and
Blackburst show strong decline in fairness as the number of
voice flows increases. For HCCA, more stable fairness indices
are observed. As for TSCM, two distinguishable segments
exist: the segment with the worst fairness index among the
four schemes when it is controlled by the DCF mode (the
segment when the number of voice flows is fewer than 10
in the system) and the segment with the best fairness index
among the four schemes when the TSCM mode is activated
(the segment with more than 10 voice flows).
IV. SELF EVALUATION
A new software-based channel access scheme called TSCM
is proposed in the second year of this project. Through
simulations, we successfully demonstrate that TSCM outper-
forms EDCA, HCCA, and Blackburst in terms of end-to-end
frame delay, number of supported voice sessions, normalized
throughput, and fairness index. Although frames in the TSCM
scheme may experience a bit longer delays than those in the
other schemes due to the software nature of TSCM, the delay
is still acceptable. However, right because of the software
flexibility, the implementation of TSCM is much easier. For
the above reasons, TSCM is strongly recommended for use in
IEEE WLANs.
Note that the current results obtained in this project have
been put into a manuscript submitted to IEEE Communications
Letters in April. Hopefully, it could be accepted soon. Also, we
have finished designing a synchronization scheme and a power
1NSC Project Report
Design of Some Enhanced Schemes
for Wireless LANs (3rd Year)
Project Number: NSC 96-2221-E-011-020-MY3
Project Duration: 2007/08/01–2010/07/31
Project Investigator: Huei-Wen Ferng
Department of Computer Science and Information Engineering
National Taiwan University of Science and Technology, Taipei 106, Taiwan
Abstract—How to guarantee both quality of service (QoS) and
fairness in wireless local area networks (WLANs) is a challenging
issue. To touch this issue, a fair medium access scheme called
fair round robin binary countdown (FRRBC), which adopts the
eminent concepts of allowance and binary countdown, is proposed
in the third year of the project. FRRBC can guarantee QoS of
both audio and video with the aid of adaptive adjustment on
system parameters and some extra rules based on delay bounds.
Using multiple allowances to fixed-bit binary numbers mapping
functions designed for different priorities, FRRBC not only
provides guaranteed system performance but also achieves good
fairness. Finally, we demonstrate that FRRBC can significantly
outperform the enhanced distributed channel access (EDCA) [14],
the synchronized medium access control (SYN-MAC) [23] and the
enhanced distributed elastic round robin (EDERR) [5] because
of its superiority to offer guaranteed QoS for both audio and
video, low delay jitter, low blocking ratio, and good fairness.
Index Terms—Wireless local area network, quality of service,
fairness.
I. INTRODUCTION
With the ability to enable people or devices to communicate
with each other without the pre-installed wired communi-
cation, the WLAN becomes one of essential technologies
in many fields, e.g., industrial, scientific, and medical ones.
Since WLANs are pervasive in urban areas, more sophisticated
services, including multimedia services, are highly demanded.
Unfortunately, the legacy medium access control (MAC) func-
tions of IEEE 802.11, i.e., distributed coordination function
(DCF) and point coordination function (PCF), were developed
to support the basic data communication only [11], [12], [13].
That is why the original WLAN is unable to well meet QoS
requirements for multimedia applications, e.g., voice over IP
(VoIP) [1] and video on demand (VoD) [9], etc. In order to
solve this problem, EDCA [14] was proposed by IEEE 802.11
task group E (TGe) to support QoS in WLANs.
Even DCF and EDCA have been standardized, the issue
of QoS guarantee is still not well handled by them [2], [3],
[8]. Therefore, many researchers tried to propose new MAC
protocols for achieving QoS guarantee and enhancing the
WLAN performance, e.g., throughput, collision rate, delay,
and fairness index [1], [4], [5], [6], [7], [10], [15], [16], [17],
[18], [19], [20], [22], [23], [24], [25]. Considering a fixed
contention time scheduling scheme, Wu et al. [23] proposed a
novel MAC scheme based on the binary countdown approach
called SYN-MAC to highly utilize the channel while keeping
a low collision rate. You et al. [24] proposed a collision-
free MAC protocol called CSMA/IC. However, it fails to
achieve good fairness because the MAC address is used as
the station ID so that the station with the largest MAC
address will always get the highest priority than the others. To
further enhance CSMA/IC, an additional slot in the original
CSMA/IC was inserted by You et al. [25]. For improving
QoS of EDCA, Gannoue and Robert [6], [7] adjusted the
minimum and maximum contention window sizes for each
access category (AC), while Iera et al. [15] adjusted the
real-time traffic transmission rate to reach this goal. In [17],
Kim and Cho used the virtual group to improve QoS of
EDCA, while Lan et al. [18] used the contention adaption
mechanism to improve performance of EDCA. Hwang and
Cho used the energy burst to improve voice performance of
EDCA in [10]. To simultaneously support fairness and QoS,
Banchs and Perez [1] employed the weighted fair queueing
to distribute link bandwidth among flows and Ferng et al. [4]
employed the concept of allowance to achieve better fairness
and throughput as compared to the distributed deficit round
robin (DDRR) [20] designed based on the round robin scheme
and deficit count. In addition, Ferng and Liau also proposed
extended schemes to improve both QoS and fairness in [5]. In
[19], Lee et al. proposed BIWF-SP and IDFQ-SP to support
strict priorities and proportional fair services. BIWF-SP is
designed based on the backoff interval, while IDFQ-SP is
designed based on the inter frame space (IFS). Vaidya et
al. [22] proposed a well-known scheme called distributed
fair scheduling (DFS) to achieve excellent fairness. Besides,
Katevenis et al. [16] proposed the weighted-round-robin cell
multiplexing algorithm to improve network performance under
a congested situation.
Like other researchers, we propose a new MAC protocol,
i.e., FRRBC, in the third year of the project to support both
QoS and fairness under various types of traffic. Basically,
FRRBC adopts the allowance [5] and the binary countdown
[23]. Using the allowance, FRRBC is expected to fairly
schedule the data transmission among flows or stations, while
the binary countdown can let FRRBC achieve a high channel
utilization and a low collision rate. Furthermore, multiple
3 
DIFS DATA DATA ACK 
   
 

 
	

 

  
   





  
… 




  
Fig. 1. Medium access mechanism of FRRBC.
[5], while (2) further makes video and best effort in FRRBC
perform much better (note that no explicit improvement is
observed for audio because of its constant-bit-rate nature).
To incorporate the allowance into FRRBC, the following
mapping functions are employed:
BNl,ji (t) = a
lMR+Round(
Al,ji (t)
MBSl
×blMR×rand(α, 1)), (4)
where BNl,ji (t) is an n-bit binary number at time t of the
jth flow of access category l at station i and the value of
BNl,ji (t) falls within [a
lMR, (al+ bl)MR] (MR is determined
by the number of contention slots, i.e., MR = 2n (n is set
to 11 based on the analysis provided by [23])). Furthermore,
a random number rand(α, 1) generating a uniform random
variable within [α, 1) (where 0 < α < 1) is employed
here to randomize the value of BNl,ji (t). As for non-negative
parameters al and bl with 0 ≤ al ≤ 1 and 0 ≤ bl ≤ 1 (in fact,
al+ bl = 1 for l = AU, V I but aBE + bBE < 1 to make sure
the maximum value of BNBE,ji (t) (i.e., (a
BE + bBE)MR) is
lower than the maximum value of BNl,ji (t) (l = AU, V I),
i.e., MR, so that higher chances to win the channel are set
for audio and video than best effort), they are used to fix
possible ranges of BNl,ji (t) for different priorities according
to ACs so that QoS requirements can be supported. Finally,
Round(.) is a rounding function. To give a specific AC a higher
(lower) priority, one can simply set a number closer to 1 (0)
to al since setting al closer to 1 (0) gives a larger (smaller)
BNl,ji (t) (closer to (farther from) MR), resulting in a higher
(lower) chance to win during the contention period using the
binary countdown scheme. Unlike [23], FRRBC can definitely
provide better fairness using (1)–(4).
Now, let us further elaborate on the binary countdown
scheme employed by FRRBC (as for the original idea of the
binary countdown scheme, one can refer to [23] for more
details). In Fig. 1, the FRRBC medium access mechanism is
shown. At first, any station, say, station i, having frames to be
sent must wait the channel to become idle for a DIFS period
specified by the IEEE 802.11 standard before contending the
channel. Once the DIFS period is past, station i computes
allowance Al,ji (t) for each flow served by the station using
(1). Once Al,ji (t) is computed, it is mapped to BN
l,j
i (t)
for contention using (4) if Al,ji (t) ≥ F ls. Among values of
BNl,ji (t), station i chooses the largest one denoted by BN
∗
i (t),
i.e., BN∗i (t) = maxl,j BN
l,j
i (t), and uses it to enter the
contention period with n contention slots. If the kth bit of
BN∗i (t) is equal 1, then station i jams the medium in the kth
slot; otherwise, station i listens to the medium in the kth slot.
Furthermore, whenever station i listens to the medium and
the medium is busy, then station i must give up immediately.
For FRRBC, each contention slot consists of an EDCA time
slot and a short jamming period to send a very short frame,
while each contention slot for SYN-MAC [23] consists of
the receiving and transmitting turnaround (RxTxTurnarround)
time and the time to transmit the physical layer convergence
protocol header (PLCPHeader) and a 48-bit receiver address,
making one contention slot in SYN-MAC much longer than
that in FRRBC. Definitely, the new design of a contention
slot in FRRBC greatly reduces the overhead. If station i can
survive at the end of the contention period, then station i can
start to exchange the binary request to send (BRTS) and the
binary clear to send (BCTS) messages with the receiver. The
BRTS message contains the PLCPHeader, a 48-bit receiver
address, and the value of BN∗i (t), while the BCTS message
contains the PLCPHeader and the value of BN∗i (t) from the
BRTS message. At the end of this phase, station i can activate
data transmission if it receives an uncorrupted BCTS message.
In the data transmission period, a station can send multiple
frames as long as the amount of accumulated data frames sent
is lower than or equal to Al,ji (t). Finally, this data transmission
period ends with an ACK transmission and the same procedure
is repeatedly performed.
From the previous explanation on the binary countdown
scheme employed by FRRBC, we know that a station must
go through the contention period before transmitting frames.
When the traffic load is low, the overhead caused by con-
tention seems to be fine since the total throughput gets little
affected. However, this overhead results in the reduction in
total throughput when the traffic load is high. To mitigate the
effect of this overhead, some extra rules can be added. To
facilitate the discussion on these rules, the following auxiliary
variables are defined: Dl,ji denotes the delay bound associated
with the jth flow of access category l at station i, it stands for
the idle threshold used to indicate a high traffic load or not,
rdl,ji (t) represents the delay received at time t by the frame
at the head of the queue for the jth flow of access category
l at station i, nal,ji = tn
l,j
i − t (where t is the current time
and t ∈ (tnl,ji − I l,j , tnl,ji )), and AT denotes the average idle
time of the wireless medium. Note that it is a pre-specified
parameter and should be greater than DIFS and a station judges
that the traffic load is high via AT < it (the larger it is, the
sooner a station will judge that the traffic load is high). Now,
the relevant rules are depicted as follows:
(R1) Because of no delay bound specified for the best
effort traffic, I
BE,j×MBSBE
FBEs
(the longest time needed
for ABE,ji (t) to achieve MBS
BE) is set to DBE,ji .
For the access categories of AU and VI, the agreed
delay bounds are associated accordingly.
(R2) If AT < it, the jth flow of access category at
station j is allowed to go through the contention
period by computing its BNl,ji (t) using (4) only when
rdl,ji (t) + na
l,j
i ≥ Dl,ji and Al,ji (t) ≥ F ls.
(R3) If AT < it, the jth flow of access category at station
j is still allowed to go through the contention period
(by first computing its BNl,ji (t) using (4)) when
Al,ji (t) = MBS
l even if rdl,ji (t) + na
l,j
i < D
l,j
i .
The idea behind (R2) is to reduce the number of overheads
carrying fewer real-time frames generated under the condition
Al,ji (t) ≥ F ls only (see Fig. 2(a)) caused by the normal
5TABLE I
TRAFFIC PARAMETERS OF AUDIO, VIDEO, AND BEST EFFORT
Access Category AU VI BE
Frame Size 160 bytes 1280 bytes 1500 bytes
Inter-Arrival Time 20 ms (constant) 10 ms (constant) 12.5 ms (exponential)
Mean Rate 8 KBps 128 KBps 120 KBps
Peak Rate - 640 KBps -
Buffer Size 25 Kb 1 Mb infinity
throughput, while the same initially given desired throughput
(8 KB/s) is set to all audios. Finally, each simulation is run
for 180 seconds.
B. Simulation Results
We now provide the performance metrics (delay, delay jitter,
throughput, collision rate, and blocking ratio) and fairness
index for all schemes. Before the following discussion, let us
give the definition of delay jitter J(i) associated with packet
i as follows [21]:
J(i) = |(TRi − TSi )− (TRi−1 − TSi−1)|, (8)
where TSi denotes the time instant to send the ith packet
and TRi stands for the time instant to receive the ith packet.
Based on (8), the mean delay jitter J¯ can be easily derived via
J¯ =
∑np
i=1 J(i)/np, where np is the total number of packets
collected for the delay jitter calculation.
1) Delay: Shown in Fig. 3 are mean delays for different
schemes and access categories under various numbers of
stations. First, one may note that the mean delays of audio
for all schemes (see Fig. 3(a)) fall below 22 ms (< 30 ms
which is the delay bound of audio set here) even though the
mean delay of audio for FRRBC is the highest one caused
by introduction of the extra rules in Section II. This shows
that the delay bound of audio is guaranteed for all schemes
because of the highest priority set to it. Second, only FRRBC
can guarantee the delay bound of video (40 ms) among the
four schemes (see Fig. 3(b)) mainly thanks to the introduction
of the extra rules in Section II. When the number of stations is
18 (corresponding to 36.864 Mbps requested by audio, video
and best effort), the mean delay of video in FRRBC is much
lower than (approximately 4% or less of) those in EDERR,
EDCA, and SYN-MAC. Of course, this great improvement
mainly comes from the introduction of the aforementioned
extra rules. Third, FRRBC has much lower delays of best
effort (see Fig. 3(c)) than EDERR when the number of stations
is lower than 10 (corresponding to 20.48 Mbps requested
by audio, video and best effort) although Fig. 3(c) does not
explicitly illustrate this. Fourth, FRRBC gains 44% of decline
as compared to EDERR, while EDCA and SYN-MAC get 51%
and 62%, respectively, of decline as compared to FRRBC as
far as the access category of best effort is concerned when
the number of stations is 18. There are two main reasons
why the delay of best effort in FRRCC is higher than that
in EDERR when much more stations exist in the system: i)
FRRBC well minimizes the delay of video for meeting the
corresponding delay bound because video is delay-sensitive
so that best effort may be delayed accordingly. ii) A short
2 4 6 8 10 12 14 16 18
0
10
20
30
40
50
M
ea
n 
de
la
y 
(m
s)
Number of stations
 
 
AU−EDCA
AU−EDERR
AU−SYN−MAC
AU−FRRBC
(a)
2 4 6 8 10 12 14 16 18
0
600
1200
1800
2400
M
ea
n 
de
la
y 
(m
s)
Number of stations
 
 
VI−EDCA
VI−EDERR
VI−SYN−MAC
VI−FRRBC
(b)
2 4 6 8 10 12 14 16 18
0
500
1000
1500
2000
2500
3000
3500
4000
4500
M
ea
n 
de
la
y 
(m
s)
Number of stations
 
 
BE−EDCA
BE−EDERR
BE−SYN−MAC
BE−FRRBC
(c)
Fig. 3. Mean delays for different access categories and schemes. (a) Audio.
(b) Video. (c) Best effort.
IFS range for all access categories in EDERR with the perfect
IFS discrimination assumption [5] (of course, this assumption
may make EDERR hard to implement or perhaps infeasible)
makes EDERR have the smallest contention period among four
schemes. In short, only FRRBC among the four schemes can
successfully guarantee the delay bound for both audio and
video with a bit higher delay for best effort as compared to
EDERR when the traffic load gets high.
2) Delay jitter: For real-time traffic, i.e., voice and video,
not only delay but also delay jitter should be minimized.
Therefore, let us further check the delay jitter for different
schemes. Shown in Fig. 4(a) are mean delay jitters regarding
72 4 6 8 10 12 14 16 18
0
20
40
60
80
100
120
140
Th
ro
ug
hp
ut
 (K
Bp
s)
Number of stations
 
 
BE−EDCA
BE−EDERR
BE−SYN−MAC
BE−FRRBC
VI−EDCA
VI−EDERR
VI−SYN−MAC
VI−FRRBC
AU−EDCA
AU−EDERR
AU−SYN−MAC
AU−FRRBC
(a)
2 4 6 8 10 12 14 16 18
0
500
1000
1500
2000
2500
3000
3500
4000
4500
5000
To
ta
l t
hr
ou
gh
pu
t (K
Bp
s)
Number of stations
 
 
EDCA
EDERR
SYN−MAC
FRRBC
Requested rate
(b)
Fig. 6. Throughput comparison among FRRBC, EDERR, EDCA, and SYN-
MAC. (a) Individual throughput. (b) Total throughput.
becomes much higher if the difference between the mean data
rate and the peak data rate of video is larger (observed by
simulations but not shown for brevity).
4) Throughput: The individual throughput is given in
Fig. 6(a), while the total throughput is given in Fig. 6(b). Let
us first discuss the individual throughput. First of all, one can
see that throughput of audio is fixed at 8 KBps (KB/s) for all
schemes except EDCA. Because the ranges of CW lmin and
CW lmax for l = AU and V I in EDCA are small, the collision
rate gets high when the number of stations increases, resulting
in the decrease of throughput of audio. As for the throughput
of video, it starts to decrease when the number of stations is
beyond 9 (corresponding to 18.432 Mbps requested by audio,
video and best effort) for EDCA and 13 (corresponding to
26.624 Mbps requested by audio, video and best effort) for
SYN-MAC. A similar reasoning for the decrease of throughput
of audio is still applicable to the decrease of throughput of
video in EDCA. For SYN-MAC, its static range of random
binary countdown values for all access categories and the fixed
frame size cause the decrease of throughput of video. As for
FRRBC and EDERR, the throughput of video is constant.
Because of the static setting of desired throughput and the
variable-bit-rate nature of video, EDERR can not well regulate
video frames and only achieves the throughput of 125.7 KBps.
However, FRRBC achieves a bit higher throughput (128 KBps)
than EDERR with the aid of adaptive setting on the desired
throughput. At the point of 18 stations, FRRBC gains 252%,
113%, and 2% of improvement as compared to EDCA, SYN-
MAC, and EDERR, respectively. Concerning the throughput of
best effort, the starvation problem occurring in SYN-MAC and
EDCA when the number of stations is beyond 13 (correspond-
ing to 26.624 Mbps requested by audio, video and best effort)
2 4 6 8 10 12 14 16 18
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
1.1
Fa
irn
es
s 
in
de
x
Number of stations
 
 
EDCA
EDERR
SYN−MAC
FRRBC
Fig. 7. Fairness indices across different access categories.
and 14 (corresponding to 28.672 Mbps requested by audio,
video and best effort), respectively, makes the throughput of
best effort in the two schemes fall to 0 KBps, while both
EDERR and FRRBC are able to prevent starvation so that
the throughput of best effort is still higher than 44 KBps.
Fixing the number of stations at 18, we have the following
comparison results: SYN-MAC and EDCA gain 100% and
100%, respectively, of decline as compared to FRRBC, while
FRRBC gets 46% of decline as compared to EDERR. Because
of existence of collisions for FRRBC by employing the binary-
countdown-based scheme rather than a perfect assumption
to achieve collision-free contention like EDERR, FRRBC
inevitably performs worse than EDERR when the system load
gets high in the throughput of best effort. In Fig. 6(b), one
can see that all schemes can carry the requested transmission
rate when the number of stations is lower than or equal to
10 (corresponding to 20.48 Mbps requested by audio, video,
and best effort). The total throughput starts decreasing for
SYN-MAC and EDCA when the number of stations is 11
(corresponding to 22.528 Mbps requested by audio, video, and
best effort) and 13 (corresponding to 26.624 Mbps requested
by audio, video, and best effort), respectively. For FRRBC
and EDERR, the requested transmission rate is still achievable
when the number of stations is lower than 15 (corresponding
to 30.72 Mbps requested by audio, video and best effort).
Considering the results at 18 stations, we have 47% and
66% of improvement for FRRBC as compared to EDCA and
SYN-MAC. Right because of the inevitable collision rate,
FRRBC still performs second to EDERR. However, only 8%
of decline for FRRBC as compared EDERR is reported when
there are 18 stations. To simultaneously consider throughput
as well as delay and delay jitter for real-time traffic (especially
video), the aforementioned results indicate that only FRRBC
can provide satisfactory performance in delay (in particular,
bounded-delay), delay jitter, and throughput.
5) Fairness: In the following, only fairness indices among
flows across different access categories are shown (note that
comparable results can be observed for EDERR and FRRBC
for the other two types of fairness index but they are omitted
here for saving space). From Fig. 7, one can see that SYN-
MAC has the lowest fairness index (the most unfair scheme),
while EDERR has the highest fairness index (the fairest
scheme) among the four schemes. If the number of stations
is below 12, almost identical fairness index like EDERR can
be observed for FRRBC. However, a gap between the fairness
Design of Fair Scheduling Schemes for
the QoS-Oriented Wireless LAN
Huei-Wen Ferng, Member, IEEE, and Han-Yu Liau
Abstract—How to simultaneously achieve fairness and quality-of-service (QoS) guarantee in QoS-oriented wireless local area networks
(LANs) is an important and challenging issue. Targeting at this goal and jointly taking priority setting, fairness, and cross-layer design into
account, four scheduling schemes designed for the QoS-oriented wireless LANmainly based on concepts of deficit count and allowance
are proposed in this paper to provide better QoS and fairness. Usingmultiple deficit count to interframe space (IFS) and allowance to IFS
mappings for different priorities, enhanced distributed deficit round robin (EDDRR) and enhanced distributed elastic round robin
(EDERR) schemes are designed to reduce (or even eliminate) possible collisions, while EDDRR with backoff interval and EDERR with
backoff interval schemes still keep the backoff procedure but dynamically adjust backoff intervals for nonfailure events (the events
excluding collisions and failed transmissions) depending on the priority setting and deficit count or allowance with a cross-layer design.
Through extensive numerical examples, we show that the proposed schemes outperform the closest scheduling schemes in the
literature and exhibit much better QoS as well as station-level and flow-level fairness.
Index Terms—Wireless LAN, quality of service, scheduling, fairness.
Ç
1 INTRODUCTION
WITH the rapid technological development of wirelesslocal area networks (LANs) and the popularization of
various kinds of mobile devices, we have witnessed
that intensive wireless LANs have been deployed in
metropolitan areas to facilitate wireless access in many
famous cities, including Philadelphia, Cleveland, and
Taipei. Pervasion of wireless LANs stimulates diverse and
multimedia applications, e.g., voice over IP (VoIP) [4], [13]
and video on demand (VoD) [12] run over wireless LANs
due to users’ needs. To support multimedia applications
over wireless LANs, bandwidth has been expanded from 2
Mbps (defined in the IEEE 802.11 standard [14]) to 54 Mbps
(defined in the IEEE 802.11a/g standard [15], [17]). Except
the fundamental bandwidth requirement to support multi-
media applications, how to achieve quality-of-service (QoS)
requirements requested by voice, video, and data, respec-
tively, in wireless (multimedia) networks is a challenging
issue and has drawn much researchers’ attention in the
past, e.g., [1], [6], [13], [35], and [36]. Unfortunately, QoS is
not well taken care and defined in IEEE 802.11 [14], 802.11a
[15], and 802.11b [16] standards. Hence, IEEE 802.11 task
group E (TGe) then modified the distributed coordination
function (DCF) previously defined in the medium access
control (MAC) layer of the IEEE 802.11 standard to form the
so-called enhanced DCF (EDCF) or enhanced distributed
channel access (EDCA) (see Fig. 1) defined in the hybrid
coordination function (HCF) of IEEE 802.11e [18] so that
multimedia transmission in IEEE 802.11 wireless LANs can
be supported. EDCA is able to strengthen some functions of
DCF, for example, multiple queues of different priorities for
fulfillment of QoS guarantee are defined (see Fig. 2). In the
literature, some papers, e.g., [9], [10], [13], [19], [23], [24],
[28], [31], [35], and [36], further addressed the QoS-related
issue in the IEEE 802.11e-based network. In [9] and [10],
Gannoune and Robert proposed the dynamic tuning
method on the maximum and minimum contention
windows to enhance performance of high-priority services
in the ad hoc mode. To support VoIP, a framework was
proposed by Hwang and Cho [13] for the IEEE 802.11e
network. Iera et al. [19] enhanced QoS of multimedia flows
by dynamically adjusting transmission rates for multimedia
flows. In [23], Kim and Cho estimated the status of
contention using the virtual group (VG) scheme to reduce
collision rates. Lan et al. [24] proposed a contention
adaption (CA) scheme to reduce collision rates and shorten
delay time. In [28], a priority-based scheme for bandwidth
assignment depending on different traffic categories was
proposed by Mangold. In [31], a dynamic adjustment
method of the minimum contention window based on the
network status and needs of applications was proposed by
Romdhani et al. to achieve reduction of the collision rate
and increase of the medium utilization. Vinnakote et al. [35]
shortened delay time by adjusting the size of the contention
window and the length of the arbitration interframe space
(AIFS). In [36], Wong and Donaldson proposed an
age-dependent backoff (ADB) scheme for adjusting the
contention window according to the time spent in queue of
real-time services to shorten the delay of real-time services.
For QoS-oriented wireless LANs, e.g., the IEEE 802.11e-
based wireless LAN, QoS guarantee is definitely an issue of
extreme importance. Except QoS guarantee, how to fairly
allocate resources of networks to different services is an
extremely important issue deserving to be addressed as
well. Hence, a fair scheme, for example, a fair scheduling
scheme, to guarantee fair resource sharing among services
880 IEEE TRANSACTIONS ON MOBILE COMPUTING, VOL. 8, NO. 7, JULY 2009
. The authors are with the Department of Computer Science and Information
Engineering, National Taiwan University of Science and Technology,
43 Keelung Road, Section 4, Taipei 106, Taiwan, ROC.
E-mail: {hwferng, M9315006}@mail.ntust.edu.tw.
Manuscript received 28 July 2007; revised 27 Apr. 2008; accepted 21 Oct.
2008; published online 5 Nov. 2008.
For information on obtaining reprints of this article, please send e-mail to:
tmc@computer.org, and reference IEEECS Log Number TMC-2007-07-0222.
Digital Object Identifier no. 10.1109/TMC.2008.156.
1536-1233/09/$25.00  2009 IEEE Published by the IEEE CS, CASS, ComSoc, IES, & SPS
Authorized licensed use limited to: National Taiwan Univ of Science and Technology. Downloaded on May 27, 2009 at 01:52 from IEEE Xplore.  Restrictions apply.
2 THE PROPOSED SCHEMES
In this section, four fair scheduling schemes mainly
designed for the IEEE 802.11e wireless LAN are proposed.
These four schemes can be categorized into schemes with
backoff intervals and schemes without backoff intervals.
Among the four proposed schemes, two of them are
designed based on the concept of deficit counts and the
remaining two are designed based on the concept of
allowances. Let us now elaborate on these four schemes in
the following four sections, respectively.
2.1 Enhanced Distributed Deficit Round Robin with
Backoff Interval (EDDRR-BI)
The deficit count (deficit counter) previously employed by
DDRR [30] plays an important role in scheduling for
EDDRR-BI (so does EDDRR described in the next section)
in which three types of deficit count rather than a single
type of deficit count as in DDRR are defined for access
categories of audio, video, and data (the access category of
background is not considered in this paper). Note that the
deficit count here is used to record the transmission deficit
from the viewpoint of a flow. For convenience, we shall use
the dummy variable l to denote the type of access category
(service class), e.g., l ¼ a is used to denote the access
category of audio, l ¼ v is used to denote the access category
of video, and l ¼ d is used to denote the access category of
data. In the following,DCjl;iðtÞ is nonnegative and is defined
to denote the deficit count at time t of the ith flow of access
category l in station j. DCjl;iðtÞ will accumulate according to
(1) when no data is transmitted since the transmission
deficit for this case is simply the product of the desired
throughput and an elapsed time period plus the previous
transmission deficit (see the linearly incremental segments
in Fig. 3):
DCjl;iðtÞ ¼ DCjl;iðt0Þ þKjl;i  ðt t0Þ; l ¼ a; v; d; ð1Þ
where DCjl;ið0Þ ¼ 0, t0 denotes a reference time instant
within the range of ðts; t with ts denoting the latest
transmission time instant or the starting time instant if no
transmission before t, and Kjl;i stands for the desired
throughput of the ith flow of access category l in station j
(we assume that the desired throughput can be properly
determined via a suitable negotiation process done by a
coordinator). Hence, the definition of deficit counts in (1)
explicitly shows the following two aspects: 1) deficit counts
accumulate linearly as time goes within each segment and
2) deficit counts are proportional to the desired throughput
within each segment. Note that only the desired through-
put Kjl;i is used in this paper for the definition of deficit
counts, while a fixed quantum Q and a variable time
interval T are required for the definition of the deficit
count in [30]. Hence, our definition of deficit counts eases
parameter setting. For the situation when a frame of the
ith flow of access category l in station j is transmitted at
time t under the condition DCjl;iðtÞ  Fls, the frame size
represents the completion amount of transmission and
should be deducted from the corresponding deficit count
right after the transmission (see the vertical segments in
Fig. 3), namely,
DCjl;iðtþÞ ¼ DCjl;iðtÞ  Fls; l ¼ a; v; d; ð2Þ
where DCjl;iðtþÞ ¼ limx>t;x!tDCjl;iðxÞ, and Fls is the frame
size corresponding to access category l. The deficit counts
governed by (1) and (2) can be used to well handle the fair
scheduling issue because of their linear accumulation with
respect to time, their proportional property with respect to
the desired throughput, and their faithful reflection on
transmission.
To incorporate the aforementioned idea of fair schedul-
ing into the IEEE 802.11e wireless LAN, deficit counts here
are related to backoff intervals for nonfailure events which
are events excluding collisions and failed transmissions, i.e.,
events of a busy medium and a successful transmission.
Note that a state variable CW ½l corresponding to access
category l should be maintained in EDCA so that it can be
used to determine the backoff interval when invoking the
backoff procedure. CW ½l can be dynamically adjusted for
different events, e.g., failure events, including collisions and
failed transmissions, and events triggered by successful
transmissions and should fall within ½CWlmin; CWlmax,
where CWlmin and CW
l
max denote the minimum and
maximum contention windows. With CW ½l, the backoff
interval is set randomly using a uniform distribution with
values taken from the range ½0; CW ½l for EDCA. For
EDDRR-BI, a connection between the deficit count and the
backoff interval is directly built for nonfailure events
through the temporary backoff interval at time t of the
ith flow of access category l in station j, i.e., TBID;jl;i ðtÞ
ðl ¼ a; v; dÞ, defined as follows:
TBID;jl;i ðtÞ ¼ CWlmax  Dl DCjl;iðtÞ; l ¼ a; v; d; ð3Þ
where the superscript D is used to explicitly denote
EDDRR-BI, and Dl is a selected constant used to make
the resultant TBID;jl;i ðtÞ fall within the IEEE 802.11e
specification on the backoff interval. To have more direct
results for Dl , l ¼ a; v; d, the following remark is given.
Remark 1. For EDDRR-BI, TBID;jl;i ðtÞ should fall within
½0; CWlmax, l ¼ a; v; d, i.e.,
0  TBID;jl;i ðtÞ  CWlmax; l ¼ a; v; d;
which yield
0  Dl DCjl;iðtÞ  CWlmax; l ¼ a; v; d:
Therefore,
0  Dl 
CWlmax
MDl
; l ¼ a; v; d;
882 IEEE TRANSACTIONS ON MOBILE COMPUTING, VOL. 8, NO. 7, JULY 2009
Fig. 3. Illustration of deficit count ðDCjl;iðtÞÞ versus time ðtÞ.
Authorized licensed use limited to: National Taiwan Univ of Science and Technology. Downloaded on May 27, 2009 at 01:52 from IEEE Xplore.  Restrictions apply.
it is easy to fix the value for D by selecting a number
within ð1;1Þ. With a fixed D and (5)-(7), we have
IFSD;ja;i ðtÞ 
SIFSþ PIFS
2
 Da MDa D;
IFSD;ja;i ðtÞ 
SIFSþ PIFS
2
 Da mDa 
SIFSþ PIFS
2
;
IFSD;jv;i ðtÞ PIFS Dv MDv D;
IFSD;jv;i ðtÞ PIFS Dv mDv  PIFS;
IFSD;jd;i ðtÞ DIFS Dd MDd D;
IFSD;jd;i ðtÞ DIFS Dd mDd  DIFS;
where mDl ¼ mini;j;tDCjl;iðtÞ ð 0Þ, l ¼ a; v; d. Combining
the prespecified ranges for IFSD;jl;i ðtÞ, l ¼ a; v; d, i.e.,
SIFS  IFSD;ja;i ðtÞ 
SIFSþ PIFS
2
;
SIFSþ PIFS
2
 IFSD;jv;i ðtÞ  PIFS;
PIFS  IFSD;jd;i ðtÞ  DIFS;
we can obtain the following limitations for Dl , l ¼ a; v; d:
SIFSþ PIFS
2
 Da MDa D SIFS;
PIFS Dv MDv D 
SIFSþ PIFS
2
;
DIFS Dd MDd D PIFS;
which provide
Da 
PIFS SIFS
2MDa D
;
Dv 
PIFS SIFS
2MDv D
;
Dd 
DIFS PIFS
MDd D
:
Since Dl , l ¼ a; v; d, are positive, their values can be
picked up from ranges ð0; ðPIFS SIFSÞ=ð2MDa DÞ,
ð0; ðPIFS SIFSÞ=ð2MDv DÞ, a n d ð0; ðDIFS PIFSÞ=
ðMDd DÞ, respectively.
With fixed D and 
D
l , l ¼ a; v; d, using Remark 3, the
feasible ranges of DCjl;iðtÞ, l ¼ a; v; d, for EDDRR are given
in the following remark.
Remark 4. Since SIFS  IFSD;ja;i ðtÞ  ðSIFSþ PIFSÞ=2,
ðSIFS þ PIFSÞ=2  IFSD;jv;i ðtÞ ; PIFS, a n d PIFS 
IFSD;jd;i ðtÞ  DIFS, the feasible ranges of DCjl;iðtÞ,
l ¼ a; v; d, for EDDRR are ½0; U^Dl  once all parameters
have been set, where
U^Da ¼
PIFS SIFS
2Da D
;
U^Dv ¼
PIFS SIFS
2Dv D
;
U^Dd ¼
DIFS PIFS
Dd D
:
Again, (1) can be changed to
DCjl;iðtÞ ¼ min DCjl;iðt0Þ þKjl;i  ðt t0Þ; U^Dl
 
; l ¼ a; v; d;
to explicitly incorporate these limitations on DCjl;iðtÞ,
l ¼ a; v; d.
Therefore, the above design allows EDDRR to guarantee
QoS of different access categories, to avoid starvation so
that fairness can be taken care, and to circumvent backoff if
perfect discrimination on values of the IFS can be achieved.
At least, fewer collisions occur for EDDRR as compared to
EDCA if no perfect discrimination on values of the IFS is
assumed. Note that these possible collisions can still invoke
the backoff procedure specified in the IEEE 802.11e
standard. Without declaration of the backoff procedure,
EDDRR here merely employs the backoff procedure
specified in the IEEE 802.11e standard for possible collisions
if no perfect discrimination on values of the IFS is assumed.
2.3 Enhanced Distributed Elastic Round Robin with
Backoff Interval (EDERR-BI)
Instead of using deficit counts, some elastic and adjustable
amounts of traffic data allowed for transmission called
allowances [8] are adopted in EDERR-BI to govern the kernel
of scheduling. Note that only one single type of allowance is
defined in [8] using the concept of excess amount and a
variable time interval T . Once an allowance is set, the traffic
data associated with that allowance can be consecutively
transmitted until the amount of the traffic data is a bit more
than the allowance. More specifically, three types of
allowance are defined in EDERR-BI for access categories
of audio, video, and data. The definitions of these
allowances at time t of the ith flow of access category l in
station j denoted by Ajl;iðtÞ are given as follows (also refer to
the linearly incremental segments in Fig. 4a):
Ajl;iðtÞ ¼ Kjl;i  ðt t0Þ  Ejl;iðt0Þ; l ¼ a; v; d; ð8Þ
where Ejl;iðt0Þ is the excess amount (see Fig. 4b) at a reference
time instant t0 (t0  t and t0 denotes specifically the latest
transmission time instant or the starting time instant if no
transmission before t) of the ith flow of access category l in
station j, which can be expressed in terms of allowance at
time t0 and the total amount of traffic data transmitted at
884 IEEE TRANSACTIONS ON MOBILE COMPUTING, VOL. 8, NO. 7, JULY 2009
Fig. 4. Illustration of allowance ðAjl;iðtÞÞ versus time ðtÞ and excess
amount ðEjl;iðtÞÞ versus time ðtÞ. (a) Allowance. (b) Excess amount.
Authorized licensed use limited to: National Taiwan Univ of Science and Technology. Downloaded on May 27, 2009 at 01:52 from IEEE Xplore.  Restrictions apply.
0 <Ea 
PIFS SIFS
2MEa E
;
0 <Ev 
PIFS SIFS
2MEv E
;
0 <Ed 
DIFS PIFS
MEd E
:
Therefore, El , l ¼ a; v; d, can be picked up from ranges
ð0; ðPIFSSIFSÞ=ð2MEa EÞ, ð0; ðPIFSSIFSÞ=ð2MEv EÞ,
and ð0; ðDIFS PIFSÞ=ðMEd EÞ, respectively.
Once E and 
E
l , l ¼ a; v; d, are fixed by using Remark 7, the
upper bounds of Ajl;iðtÞ, l ¼ a; v; d, for EDERR can be
obtained in the following remark:
Remark 8. Due to the fact that SIFS  IFSE;ja;i ðtÞ 
ðSIFSþ PIFSÞ=2, ðSIFSþ PIFSÞ=2  IFSE;jv;i ðtÞ  PIFS,
and PIFS  IFSE;jd;i ðtÞ  DIFS, the upper bounds of
Ajl;iðtÞ, l ¼ a; v; d, for EDERR are U^El once all parameters
have been set, where
U^Ea ¼
PIFS SIFS
2Ea E
;
U^Ev ¼
PIFS SIFS
2Ev E
;
U^Ed ¼
DIFS PIFS
Ed E
:
Specifically speaking, the feasible ranges of Ajl;iðtÞ,
l ¼ a; v; d, are ðFls; U^El . Now, (8) can be written as
Ajl;iðtÞ ¼ min Kjl;i  ðt t0Þ  Ejl;iðt0Þ; U^El
 
; l ¼ a; v; d;
to explicitly incorporate the upper bounds of Ajl;iðtÞ,
l ¼ a; v; d.
Note that the ideas behind (12)-(14) are 1) QoS guarantee:
setting a shorter IFS for a higher priority enables service
differentiation and QoS guarantee, 2) fair scheduling: no
starvation exists since a shorter IFS may be set for a larger
amount of allowance so that getting the medium becomes
easier, and 3) collision reduction/elimination: different
values of the IFS are set for the same allowance with the
aid of random number randð1; EÞ. Compared to EDCA,
this definitely reduces collisions or even eliminates colli-
sions if discrimination on values of the IFS is totally viable.
Of course, the backoff procedure specified by IEEE 802.11e
for collisions is still employed in our numerical examples
for EDERR if collisions occur for simplicity.
3 DEFINITIONS OF WEIGHTS
For EDDRR-BI, EDERR-BI, EDDRR, and EDERR, proper
definitions of weights are necessary so that measure of
fairness can be defined based on weights. In the following,
weights for flows within the same access category
denoted by w
½s;j
l;i associated with the ith flow of access
category l in station j (here, the superscript ½s is used to
denote the same access category), weights for flows across
different access categories denoted by w
½d;j
l;i associated with
the ith flow of access category l in station j (here, the
superscript ½d is used to stand for different access
categories), and weights for different stations denoted by
wj associated with station j are defined to make definitions
of flow-level and station-level fairness feasible. These three
types of weight are now defined as follows:
w
½s;j
l;i ¼
Kjl;iP
j
P
i K
j
l;i
; ð15Þ
w
½d;j
l;i ¼
Kjl;iP
l
P
j
P
i K
j
l;i
; ð16Þ
wj ¼
P
l
P
i K
j
l;iP
l
P
j
P
i K
j
l;i
: ð17Þ
Note that one may use the reciprocal of the standard
deviation for throughput-to-weight ratios to represent the
degree of fairness (see [8]). Hence, weights should be
proportional to the (desired) throughput. This gives the
reason why values of the desired throughput are used to
define weights in (15)-(17). Further note that no direct and
reasonable definitions of weights are given in [25] as
compared to definitions of weights here; hence, no
station-level fairness was associated with EEDCF [25].
Following the aforementioned definitions of weights,
weights for all schemes in the following simulation
experiments are defined accordingly, even for EEDCF.
One should note that weights defined above are only
necessary for performance evaluation. Therefore, weights
are not involved in the proposed schemes. For performance
evaluation, an evaluator should be in charge of the
computation of weights. Let us now sketch how an
evaluator can calculate the aforementioned weights from
the information ðKjl;iÞ distributed over the wireless LAN.
No doubt, a suitable information ðKjl;iÞ sharing mechanism
should be proposed and established first. Through the
information sharing mechanism, each station is asked to
periodically (the period should be further carefully
determined) send information ðKjl;iÞ update to the evalua-
tor. Once all necessary information ðKjl;iÞ for all flows/
stations has been collected by the evaluator, weights are
then ready to be computed. With weights and other
performance measures, the system performance evaluation
can be performed by the evaluator accordingly.
4 NUMERICAL RESULTS AND DISCUSSIONS
In this section, we study performance (including through-
put, delay, and collision rate) and fairness for the four
proposed scheduling schemes, EDCA, EEDCF1 [25], and
DERR [8] through a simulation approach which is done by
ns-2 [37] alongwith somemodifications provided in [27]. Let
us first elaborate on arrangement of simulation experiments
and define related performance metrics. Then, extensive
simulation results are shown along with discussions.
4.1 Arrangement of Simulation Experiments
The simulation programs of this paper are built upon the
well-known network simulator ns-2 [37]. Fig. 5 shows the
886 IEEE TRANSACTIONS ON MOBILE COMPUTING, VOL. 8, NO. 7, JULY 2009
1. No special backoff interval adjustment is employed except that
defined in IEEE 802.11e.
Authorized licensed use limited to: National Taiwan Univ of Science and Technology. Downloaded on May 27, 2009 at 01:52 from IEEE Xplore.  Restrictions apply.
complexity/overhead to implement EDERR (EDDRR) is
higher mainly due to the fact that perfect IFS discrimination
is not really easy.
Throughput. Let us first examine individual throughput
(per access category) given in Figs. 6a and 7a. First, one can
see that constant throughput is kept for the access category of
audio (hence, the curves in Figs. 6a and 7a for this access
category coincide) because it has the highest priority but the
lowest rate for all schemes (note that the total rate requested
by audio of 18 stations is only 1.152 Mbps ( 36 Mbps)).
Second, throughput for the access category of video slightly
decreases when the number of stations is beyond 9
(corresponding to 9.792 Mbps requested by both audio and
video), 12 (corresponding to 13.056 Mbps requested by both
audio and video), and 15 (corresponding to 16.32 Mbps
requested by both audio and video) for DERR, EDCA, and
EEDCF because of the priority of this access category lower
than the access category of audio but higher than the access
category of data and the access nature of these three schemes,
while the same level (128 Kbytes/s) is kept for EDDRR-BI,
EDERR-BI, EDDRR, and EDERR (note that the curves of this
access category coincide for EDDRR-BI and EDERR-BI
(EDDRR and EDERR) in Fig. 6a (Fig. 7a)). Considering the
results at 18 stations, we note that 8 percent (10 Kbytes/s),
1.6 percent (2 Kbytes/s), and 12 percent (14 Kbytes/s) of
improvement for EDDRR-BI, EDERR-BI, EDDRR, and
EDERR as compared to EDCA, EEDCF, and DERR, respec-
tively, can be observed. Third, a noticeable decreasing trend
in throughput for the access category of data is observed for
all schemes when the number of stations is over 9
(corresponding to 18.432 Mbps requested by audio, video,
and data). The noticeable decreasing trend in throughput for
the access category of data ismainly due to its lowest priority
among the three access categories considered. Fixing the
number of stations at 18, we have 14 percent (3 Kbytes/s),
28 percent (6 Kbytes/s), 38 percent (8 Kbytes/s), and
47 percent (10 Kbytes/s) of improvement for EDDRR-BI,
EDERR-BI, EDDRR, and EDERR as compared to EDCA; we
have 41 percent (7 Kbytes/s) and 58 percent (10 Kbytes/s) of
improvement for EDDRR-BI and EDERR-BI as compared to
EEDCF; we have 7 percent (2 Kbytes/s) and 14 percent
(4 Kbytes/s) of improvement for EDDRR and EDERR as
compared to DERR. Regarding throughput for the access
category of data, EEDCF even performs worse than EDCA,
while DERR performs much better than EDCA. Moreover,
EDERR performs best, and EDDRR, DERR, EDERR-BI, and
EDDRR-BI follow successively. From the above observa-
tions, we see that EDERR and EDDRR can provide better
throughput for all access categories among schemes without
backoff intervals, while EDERR-BI and EDDRR-BI can
provide better throughput for all access categories among
schemes with backoff intervals. Noting that DERR only
provides a single type allowance defined indirectly by the
excess amount and a time interval, DERR indeed cannot
properly handle the QoS issue. This intuitive reason explains
why EDERR and EDDRR can outperform DERR in terms of
throughput. Because of the indirect definition for the
allowance like DERR, EEDCF performs worse than
EDERR-BI and EDDRR-BI in terms of throughput. Further-
more, the fact that the allowances defined by (8) by which
consecutive transmissions are enabled make system opera-
tions more efficient than the deficit counts defined by (1)
clearly explains why EDERR (EDERR-BI) can outperform
EDDRR (EDDRR-BI). Along with the observation at the
beginning of this section, EDERR explicitly outperforms the
other schemes in terms of throughput. As for total
throughput, one may see Figs. 6b and 7b for details. We
note that comparable throughput is observed for all schemes
when the number of stations is less than or equal to 9
(corresponding to 18.432 Mbps requested by audio, video,
and data, which is about the medium load (18.432 Mbps/
36Mbps) for the system) because the system load is less than
the medium load. Over nine stations, the best to the worst
schemes are EDERR, EDDRR, EDERR-BI, EDDRR-BI, and
EDCA, respectively. As for DERR and EEDCF, they perform
worse than EDCA within the interval [9, 13] but better than
EDCA when the number of stations reaches 14 and beyond.
Finally, throughput dropsmuch for all schemes as compared
to the maximum throughput at 12 stations (corresponding to
24.576 Mbps requested by audio, video, and data, which is a
moderate high load (24.576 Mbps/36 Mbps) for the system)
when the number of stations reaches 18 stations (corre-
sponding to 36.864 Mbps requested by audio, video, and
data, which is heavily loaded (36.864Mbps/36Mbps) for the
system). No doubt, throughput gets even worse if the load
gets extremely high, say, 40 stations, further. However,
EDERR and EDDRR (EDERR-BI and EDDRR-BI) still per-
form better than DERR/EDCA (EEDCF/EDCA).
Delay. With the highest priority, all mean delays of all
considered schemes for the access category of audio are
(almost) zero as shown in Figs. 8a and 8b (therefore, the
curves of this access category coincide for EDCA, EEDCF,
EDERR-BI, and EDDRR-BI in Fig. 8a and for EDCA, DERR,
EDERR, and EDDRR in Fig. 8b). For the access category of
video, an approximately linear trend is observed (see
888 IEEE TRANSACTIONS ON MOBILE COMPUTING, VOL. 8, NO. 7, JULY 2009
Fig. 6. Throughput comparison among EDCA, EEDCF, EDDRR-BI, and
EDERR-BI. (a) Individual throughput. (b) Total throughput.
Fig. 7. Throughput comparison among EDCA, DERR, EDDRR, and
EDERR. (a) Individual throughput. (b) Total throughput.
Authorized licensed use limited to: National Taiwan Univ of Science and Technology. Downloaded on May 27, 2009 at 01:52 from IEEE Xplore.  Restrictions apply.
i.e., 1=0:0071 ¼: 141 for EDDRR-BI, 1=0:0067 ¼: 149 for
EDERR-BI, 1=0:0069 ¼: 145 for EDDRR, 1=0:0051 ¼: 196 for
EDERR, 1=0:0077 ¼: 130 for EEDCF, 1=0:011 ¼: 91 for DERR,
and 1=0:0084 ¼: 119 for EDCA, respectively, revealing the
following comparison results according to dIF : 1) 18 percent,
25 percent, 22 percent, and 65 percent of improvement are
achieved by EDDRR-BI, EDERR-BI, EDDRR, and EDERR,
respectively, as compared to EDCA, 2) 8 percent and
15 percent of improvement are achieved by EDDRR-BI
and EDERR-BI, respectively, as compared to EEDCF, and
3) 59 percent and 115 percent of improvement are achieved
by EDDRR and EDERR, respectively, as compared to
DERR. In Fig. 12, throughput-to-weight ratios among flows
within the access category of data are given with values of
the standard deviation 0.0133, 0.011, 0.0115, 0.00865, 0.0137,
0.017, and 0.025 for EDDRR-BI, EDERR-BI, EDDRR,
EDERR, EEDCF, DERR, and EDCA, respectively. Again,
these values enable us to have the following comparison
results based on the type-I degree of fairness for each
scheme, i.e., 1=0:0133 ¼: 75, 1=0:011 ¼: 91, 1=0:0115 ¼: 87,
1=0:00865 ¼: 116, 1=0:0137 ¼: 73, 1=0:017 ¼: 59, and 1=0:025 ¼
40 for EDDRR-BI, EDERR-BI, EDDRR, EDERR, EEDCF,
DERR, and EDCA, respectively: 1) 88 percent, 127 percent,
117 percent, and 189 percent of improvement are achieved
by EDDRR-BI, EDERR-BI, EDDRR, and EDERR, respec-
tively, as compared to EDCA, 2) 3 percent and 25 percent of
improvement are achieved by EDDRR-BI and EDERR-BI,
respectively, as compared to EEDCF, and 3) 48 percent and
97 percent of improvement are achieved by EDDRR and
EDERR, respectively, as compared to DERR. Alternatively,
we may observe the degree of fairness via the type-II degree
of fairness ðdIIF Þ. Figs. 13a and 13d illustrate perfect fairness
ðdIIF ¼ 1Þ for all schemes when concerning the access
category of audio. From Figs. 13b and 13e, we have the
type-II degree of fairness concerning the access category of
video 1=ð10:953Þ ¼: 21 for EDDRR-BI, 1=ð10:9545Þ ¼: 22
890 IEEE TRANSACTIONS ON MOBILE COMPUTING, VOL. 8, NO. 7, JULY 2009
Fig. 10. Throughput-to-weight ratios among flows within the access
category of audio. (a) EDDRR-BI. (b) EDERR-BI. (c) EEDCF.
(d) EDDRR. (e) EDERR. (f) DERR. (g) EDCA.
Fig. 11. Throughput-to-weight ratios among flows within the access
category of video. (a) EDDRR-BI. (b) EDERR-BI. (c) EEDCF.
(d) EDDRR. (e) EDERR. (f) DERR. (g) EDCA.
Authorized licensed use limited to: National Taiwan Univ of Science and Technology. Downloaded on May 27, 2009 at 01:52 from IEEE Xplore.  Restrictions apply.
type-II degree of fairness for different schemes as follows:
1=ð1 0:918Þ ¼: 12 for EDCA, 1=ð10:942Þ ¼: 17 for EEDCF,
1=ð10:945Þ ¼: 18 for EDDRR-BI, 1=ð1 0:958Þ ¼: 24 for
EDERR-BI, 1=ð1 0:94Þ ¼: 17 for DERR, 1=ð1 0:963Þ ¼: 27
for EDDRR, and 1=ð1 0:972Þ ¼: 36 for EDERR. These values
give the following comparison results: 1) 50 percent and
6 percent of improvement for EDDRR-BI and 100 percent and
41 percent of improvement for EDERR-BI as compared to
EDCA and EEDCF, respectively, are obtained and 2) 125 per-
cent and 59 percent of improvement for EDDRR and
200 percent and 111 percent of improvement for EDERR as
compared to EDCA and DERR, respectively, are obtained.
Finally, we discuss fairness among stations. Using
throughput-to-weight ratios among stations for different
schemes as shown in Fig. 16 to obtain the type-I degree of
fairness, we have 97 percent, 230 percent, 265 percent,
and 341 percent of improvement gained by EDDRR-BI,
EDERR-BI, EDDRR, and EDERR, respectively, as compared
to EDCA, 19 percent and 98 percent of improvement gained
by EDDRR-BI and EDERR-BI, respectively, as compared to
EEDCF, and 78 percent and 114 percent of improvement
gained by EDDRR and EDERR, respectively, as compared
to DERR. Fig. 17 shows alternatively differences of fairness
indices with respect to the ideal case for stations and
eases the calculation of the type-II degree of fairness,
892 IEEE TRANSACTIONS ON MOBILE COMPUTING, VOL. 8, NO. 7, JULY 2009
Fig. 14. Throughput-to-weight ratios among flows across different
access categories. (a) EDDRR-BI. (b) EDERR-BI. (c) EEDCF.
(d) EDDRR. (e) EDERR. (f) DERR. (g) EDCA.
Fig. 15. Differences of fairness indices for flows across different access
categories.
Fig. 16. Throughput-to-weight ratios among stations. (a) EDDRR-BI.
(b) EDERR-BI. (c) EEDCF. (d) EDDRR. (e) EDERR. (f) EDCA. (g) DERR.
Authorized licensed use limited to: National Taiwan Univ of Science and Technology. Downloaded on May 27, 2009 at 01:52 from IEEE Xplore.  Restrictions apply.
[18] IEEE 802.11 WG, IEEE Standard for Information Technology—
Telecommunications and Information Exchange between Systems—
Local and Metropolitan Area Networks—Specific Requirements—Part
11: Wireless LAN Medium Access Control (MAC) and Physical Layer
(PHY) Specifications. Amendment 8: Medium Access Control (MAC)
Quality of Service Enhancements, IEEE, 2005.
[19] A. Iera, A. Molonaro, G. Ruggeri, and D. Tripodi, “Dynamic
Prioritization of Multimedia Flows for Improving QoS and
Throughput in IEEE 802.11e WLANs,” Proc. IEEE Int’l Conf.
Comm. (ICC ’05), pp. 1184-1189, 2005.
[20] I. Inan, F. Keceli, and E. Ayanoglu, “An Adaptive Multimedia QoS
Scheduler for 802.11e Wireless LANs,” Proc. IEEE Int’l Conf.
Comm. (ICC ’06), pp. 5263-5270, 2006.
[21] S.S. Kanhere, H. Sethu, and A.B. Parekh, “Fair and Efficient Packet
Scheduling Using Elastic Round Robin,” IEEE Trans. Parallel and
Distributed Systems, vol. 13, no. 3, pp. 324-336, Mar. 2002.
[22] M. Katevenis, S. Sidiropoulos, and C. Courcoubetis, “Weighted
Round-Robin Cell Multiplexing in a General-Purpose ATM
Switch Chip,” IEEE J. Selected Areas in Comm., vol. 9, no. 8,
pp. 1265-1279, Oct. 1991.
[23] S.M. Kim and Y.J. Cho, “QoS Enhancement Scheme of EDCF in
IEEE 802.11 Wireless LANs,” IEE Electronics Letters, vol. 40, no. 17,
pp. 1091-1092, Aug. 2004.
[24] Y.W. Lan, J.H. Yeh, J.C. Chen, and Z.T. Chou, “Performance
Enhancement of IEEE 802.11e EDCA by Contention Adaption,”
Proc. IEEE Vehicular Technology Conf. (VTC ’05), pp. 2096-2100,
2005.
[25] C.F. Lee, “Fair and Efficient Scheduling Mechanisms for IEEE
802.11 Wireless LANs,” master’s thesis, Nat’l Taiwan Univ. of
Science and Technology, June 2004.
[26] J.F. Lee, W. Liao, and M.C. Chen, “A Per-Class QoS Service Model
in IEEE 802.11e WLANs,” Proc. Second Int’l Conf. Quality of Service
in Heterogeneous Wired/Wireless Networks (QShine ’05), 2005.
[27] M. Malli, Q. Ni, T. Turletti, and C. Barakat, “Adaptive Fair
Channel Allocation for QoS Enhancement in IEEE 802.11 Wireless
LANs,” Proc. IEEE Int’l Conf. Comm. (ICC ’04), pp. 3470-3475, 2004.
[28] S. Mangold, “IEEE 802.11e—Coexistence of Overlapping Basic
Service Sets,” Proc. Mobile Venue, pp. 131-135, 2002.
[29] E.C. Park, D.Y. Kim, C.H. Choi, and J. So, “Improving Quality of
Service and Assuring Fairness in WLAN Access Networks,” IEEE
Trans. Mobile Computing, vol. 6, no. 4, pp. 337-350, Apr. 2007.
[30] W. Pattara-Atikom, S. Banerjee, and P. Krishnamurthy, “Starva-
tion Prevention and Quality of Service in Wireless LANs,”
Proc. IEEE Wireless Personal Multimedia Comm. (WPMC ’02),
pp. 1078-1082, 2002.
[31] L. Romdhani, Q. Ni, and T. Turletti, “Adaptive EDCF: Enhanced
Service Differentiation for IEEE 802.11 Wireless Ad-Hoc Net-
works,” Proc. IEEE Wireless Comm. and Networking (WCNC ’03),
pp. 1373-1378, 2003.
[32] D. Skyrianoglou, N. Passas, and A.K. Salkintzis, “ARROW: An
Efficient Traffic Scheduling Algorithm for IEEE 802.11e HCCA,”
IEEE Trans. Wireless Comm., vol. 5, no. 12, pp. 3558-3567, Dec. 2006.
[33] A. Soomro, S. Shankar, J.D. Prado, Y. Ohtani, J. Kowalski,
F. Simpson, and I.L.W. Lih, TGe Scheduler—Minimum Performance
Requirements, IEEE 802.11-02/709r0, Nov. 2002.
[34] N.H. Vaidya, P. Bahl, and S. Gupta, “Distributed Fair Scheduling
in a Wireless LAN,” Proc. ACM MobiCom, pp. 167-178, 2000.
[35] S. Vinnakote, N. Svs, S. Pasupuleti, and D. Das, “New-MAC
Protocol for Enhancement of QoS Performance in Wireless
LAN,” Proc. IFIP Wireless and Optical Comm. Networks
(WOCN ’06), pp. 1-5, 2006.
[36] G.W. Wong and R.W. Donaldson, “Improving the QoS Perfor-
mance of EDCF in IEEE 802.11e Wireless LANs,” Proc. IEEE Pacific
Rim Conf. Comm., Computers and Signal Processing (PACRIM ’03),
pp. 392-396, 2003.
[37] The Network Simulator—ns-2, http://www.isi.edu/nsnam/ns,
2009.
Huei-Wen Ferng received the BS degree in
electrical engineering from the National Tsing
Hwa University, Hsinchu, Taiwan, in 1993 and
the PhD degree in electrical engineering from
the National Taiwan University, Taipei, in 2000.
He joined the Department of Computer Science
and Information Engineering, National Taiwan
University of Science and Technology, Taipei,
as an assistant professor in August 2001. Since
February 2005, he has been an associate
professor. Funded by the Pan Wen-Yuan Foundation, Taiwan, he spent
the summer of 2003 visiting the Department of Electrical Engineering
and Computer Science, University of Michigan, Ann Arbor. His research
interests include wireless networks, mobile computing, high-speed
networks, design of fair scheduling, teletraffic modeling, queuing theory,
and performance analysis. He was a recipient of the research award for
young researchers from the Pan Wen-Yuan Foundation, Taiwan, in
2003 and was a recipient of the Outstanding Young Electrical Engineer
Award from the Chinese Institute of Electrical Engineering (CIEE),
Taiwan, in 2008. He is a member of the IEEE.
Han-Yu Liau received the MS degree in
computer science and information engineering
from the National Taiwan University of Science
and Technology, Taipei, in 2007. He is currently
with the Department of Computer Science and
Information Engineering, National Taiwan Uni-
versity of Science and Technology. His research
interests include wireless LANs, design of fair
scheduling, and performance analysis.
. For more information on this or any other computing topic,
please visit our Digital Library at www.computer.org/publications/dlib.
894 IEEE TRANSACTIONS ON MOBILE COMPUTING, VOL. 8, NO. 7, JULY 2009
Authorized licensed use limited to: National Taiwan Univ of Science and Technology. Downloaded on May 27, 2009 at 01:52 from IEEE Xplore.  Restrictions apply.
LEONOVICH and FERNG: A TIME SLOTS COORDINATION MECHANISM FOR IEEE 802.11 WLANS 361
Svoice
Voice Interval Data Interval Dlim
DL   UL
TSCM
Sdata
DCF
TSCM cycle TSCM cycle
1 2 Kdata
flow 1 flow 2 flow 1 flow 2
Fig. 1. Time structure of TSCM.
this time allocation is to give a higher priority to the voice
traffic. With the fact that the time to generate one packet for
the vast majority of voice codecs is much longer than the
time to transmit it, a long period of packet generation is left
to poll data flows. To keep the delay and jitter of voice frames
low, the length of the Data Interval is confined to 𝐷𝑙𝑖𝑚 chosen
based on the voice packet generation time. This time structure
implicitly sets a higher (lower) priority to voice (data) traffic.
Following the aforementioned time structure, the TS coor-
dinator assigns time slots to STAs to access the medium. To
do so, it first needs to calculate the length of the time slot
based on measurements during the CP, including data rate of
data traffic 𝑅𝑑𝑎𝑡𝑎 and average payload sizes of data and voice
traffic denoted by 𝐿𝑑𝑎𝑡𝑎 and 𝐿𝑣𝑜𝑖𝑐𝑒, respectively. Considering
the time characteristics of Voice and Data intervals, it is
reasonable to assume that only one voice frame arrives during
one TSCM cycle for each voice flow in both uplink and
downlink. Furthermore, a longer Data Interval allows to set a
long enough time slot for each data flow to send multiple data
frames. This increases data traffic throughput without harmful
effects on the QoS of voice since the Data Interval is limited
by 𝐷𝑙𝑖𝑚. Therefore, the length of the time slot for data traffic
is chosen to be a submultiple of 𝐷𝑙𝑖𝑚. However, it still should
be long enough to transmit at least one frame, giving a lower
bound 𝑆𝑚𝑖𝑛 which is the time to transmit one frame with the
maximum size defined by the standard as follows:
𝑆𝑚𝑖𝑛 = 𝑇𝑚𝑎𝑥 + 2SIFS + 𝑇𝑎𝑐𝑘, (2)
where 𝑇𝑚𝑎𝑥 is the time to transmit a frame with the maximum
size, SIFS is the short inter frame space, and 𝑇𝑎𝑐𝑘 is the
time to transmit an ACK frame. With the knowledge of traffic
parameters, the average number of packets in the data queue
after 𝐷𝑙𝑖𝑚 (denoted by 𝐾𝑑𝑎𝑡𝑎) can be found via
𝐾𝑑𝑎𝑡𝑎 =
⌈
𝑅𝑑𝑎𝑡𝑎 ⋅𝐷𝑙𝑖𝑚
𝐿𝑑𝑎𝑡𝑎
⌉
. (3)
Combining the above two equations leads to the setting of a
time slot for the data traffic 𝑆𝑑𝑎𝑡𝑎 as follows:
𝑆𝑑𝑎𝑡𝑎 = max [𝐾𝑑𝑎𝑡𝑎(𝑇𝑑𝑎𝑡𝑎 + 2SIFS + 𝑇𝑎𝑐𝑘), 𝑆𝑚𝑖𝑛] , (4)
where 𝑇𝑑𝑎𝑡𝑎 is the time to transmit a frame with the payload
size 𝐿𝑑𝑎𝑡𝑎. As for the voice traffic, the length of the time slot
𝑆𝑣𝑜𝑖𝑐𝑒 is set to the time to transmit two frames (one uplink
frame and one downlink frame) with the size of 𝐿𝑣𝑜𝑖𝑐𝑒, i.e.,
𝑆𝑣𝑜𝑖𝑐𝑒 = 2𝑇𝑣𝑜𝑖𝑐𝑒 + 2SIFS, (5)
where 𝑇𝑣𝑜𝑖𝑐𝑒 is the time to transmit a frame with the payload
size 𝐿𝑣𝑜𝑖𝑐𝑒 under the piggybacked acknowledgment.
III. COMPLEXITY ANALYSIS
In this section, both time complexity and space complexity
for introducing TSCM are examined. For acquiring the time
complexity, we introduce the following notations: 𝑇1 is the
time to measure 𝑁𝑑𝑎𝑡𝑎, 𝑁𝑎𝑐𝑘, 𝑁𝑟𝑡𝑠, or 𝑁𝑐𝑡𝑠, 𝑇2 is the time to
measure 𝑅𝑑𝑎𝑡𝑎, 𝐿𝑑𝑎𝑡𝑎, or 𝐿𝑣𝑜𝑖𝑐𝑒, 𝑇3 is the time to calculate
𝜀, 𝑇4 is the time to compare 𝜀 with 𝜀𝑡ℎ, and 𝑇5 (𝑇6) is
the time to calculate a time slot of voice (data). Letting 𝑛
denote the number of beacon intervals observed in the DCF
mode (therefore, 𝑛 network/traffic parameter observations
exist in the DCF mode), let us examine the time complexity
for introducing TSCM under the following two cases: light
network load, i.e., 𝜀 < 𝜀𝑡ℎ, and heavy network load, i.e.,
𝜀 ≥ 𝜀𝑡ℎ. The time complexity 𝑓(𝑛) for the first case can
be expressed as 𝑓(𝑛) = (4𝑇1 + 3𝑇2 + 𝑇3 + 𝑇4)𝑛 ∈ 𝑂(𝑛),
while 𝑓(𝑛) ≤ (4𝑇1 + 3𝑇2 + 𝑇3 + 𝑇4)𝑛 + (4𝑇1 + 3𝑇2 +
𝑇3 + 𝑇4 + 𝑇5 + 𝑇6)𝑁𝑐𝑦𝑐𝑙𝑒𝑛𝑇 ∈ 𝑂(𝑛) for the second case,
where 𝑛𝑇 is the number of the TSCM mode activations with
𝑛𝑇 ≤ 𝑛. The results for the two cases enable us to conclude
that the time complexity is 𝑂(𝑛). Next, let us further examine
the space complexity for introducing TSCM. Since only fixed
memory storages are necessary for the TS coordinator, the
space complexity is 𝑂(1). Because TSCM uses the same MAC
functions as DCF does and only performs a rearrangement
of the medium access time of STAs by the software module
according to characteristics of traffic flows, the implementation
of TSCM is in deed simple as illustrated by the time and
space complexity analysis. On the contrary, the other reference
schemes need hardware changes of the IEEE 802.11 MAC
layer: a new set of MAC functions is required for EDCA
and HCCA; Blackburst requires the ability of jamming on
the medium by the AP and synchronization among STAs.
Definitely, simpler implementation and structural simplicity
make TSCM more preferable among these schemes.
IV. PERFORMANCE EVALUATION AND CONCLUDING
REMARKS
Using the network simulator ns-2 [5], EDCA, HCCA,
Blackburst (denoted by Bburst), and TSCM are evaluated in
terms of end-to-end frame delay, number of supported voice
sessions, normalized throughput, and fairness index [6]. Here,
we consider an infrastructure-based system containing one
AP and various numbers of STAs under the IEEE 802.11b
physical layer with 209-𝜇s beacon intervals. Each STA is
only associated with one traffic source. To increase the system
load, we gradually increase the number of voice STAs but fix
the number of data STAs at 5. For the voice source, it is a
bidirectional 64-kbps voice over IP (VoIP) traffic source with
the 160-byte payload per 20 ms, while an FTP flow with the
1460-byte payload generated at the AP is used to model the
data source. Additionally, the low-priority (data) contention
window (CW) size is set to 63 with AIFS = 90𝜇𝑠 and the
high-priority (voice) CW size is set to 31 with AIFS = 50𝜇𝑠
for EDCA; the HCCA transmission unit (TU) is set to 1024 𝜇s
with a superframe of 500*TU and a contention-free period
(CFP) of 100*TU; and the Blackburst slot is set to 20 𝜇s with
the slack time of 5 ms.
Let us further elaborate on the choice of the parameters for
TSCM. First, 𝐷𝑙𝑖𝑚 is set to 15 ms to conform with the packet
Authorized licensed use limited to: National Taiwan Univ of Science and Technology. Downloaded on April 12,2010 at 06:37:24 UTC from IEEE Xplore.  Restrictions apply. 
IEEE TRANSACTIONS ON MOBILE COMPUTING, VOL. XX, NO. XX, XX 2011 1
Design of Novel Node Distribution Strategies in
Corona-Based Wireless Sensor Networks
Huei-Wen Ferng, Member, IEEE , Mardianto Soebagio Hadiputro, and Arief Kurniawan
Abstract—Considering coverage, efficiency, and durability, three non-uniform node distribution strategies for a corona-based wireless
sensor network (WSN) are proposed in this paper. To derive lower bounds on sensor nodes in coronas, we investigate the optimal node
placement based on coverage. We then prove the feasibility of balanced energy depletion for a primitive geometric node distribution
(GND) and a primitive energy proportional node distribution (EPND). Applying the optimal node placement and GND enables us to
propose the first strategy (Strategy I) to reach completely balanced energy depletion. Combining the optimal node placement, EPND,
and a simple switch scheduling, the second strategy (Strategy II) and the third strategy (Strategy III) are designed for a uniform-width
corona model and a non-uniform-width corona model, respectively. Although balanced energy depletion may not be reached, Strategy
II achieves the longest network lifetime and Strategy III requires the fewest sensor nodes among the three strategies. Finally, the
performance investigation done by both analytical and simulation approaches exhibits the superiorities of the proposed strategies over
the two closest strategies in the literature in terms of number of sensor nodes, network lifetime, and residual energy.
Index Terms—Wireless sensor network, node distribution, corona model, sensor placement, energy hole problem.
F
1 INTRODUCTION
A wireless sensor network is a wireless network formed
by a large number of autonomous sensor devices to
monitor physical conditions of an area of interest with
broad applications, including disaster relief, environ-
ment control, bio-diversity mapping, etc. [5], [14]. For
different purposes, the size of a single sensor node varies
from the size of a dust to that of a shoe box. Basically,
each sensor node should be equipped with capabilities
of wireless communication, computation, and sensing.
Now, one can witness that most of sensor nodes may
include a microcontroller, a small random access mem-
ory, one or more flash memories, a wireless transceiver,
an antenna, an analog-to-digital converter, one or more
sensors, and a power supply [24]. Certainly, the power
supply can come from different energy resources, such
as batteries, capacitors, or solar cells [22], [23]. However,
sensor nodes are usually battery-driven. With limited
batteries, a sensor node will not be able to fulfill its
task anymore once its energy is depleted. Further noting
the fact made by many researchers (e.g., those in [1],
[25]) that replacing batteries might be very inconvenient,
in particular, in a harsh environment, energy efficiency
undoubtedly becomes a crucial issue in designing WSNs.
Besides, it has been observed that the sensor nodes closer
to the sink tend to die faster than those farther away
from the sink because of traffic imbalance among sensor
• The authors are with the Department of Computer Science and Informa-
tion Engineering, National Taiwan University of Science and Technol-
ogy, Taipei 106, Taiwan. E-mail: hwferng@mail.ntust.edu.tw, mhadipu-
tro@yahoo.com, arifku@ee.its.ac.id.
Manuscript received August 3, 2009; revised June 23, 2010; accepted October
1, 2010. The work was supported by the National Science Council (NSC),
Taiwan under Contracts NSC 96-2221-E-011-020-MY3 and NSC 97-2221-
E-011-045-MY3.
nodes, causing the energy hole problem [15]. The energy
of the survival sensor nodes is definitely left unused
once some sensor nodes around the sink die, raising
the following question: “Is it possible to let all sensor
nodes die simultaneously to reach zero residual energy
in a WSN?”. To answer this question, numerous schemes
with non-uniform initial energy at each node, mobile
sinks, energy-aware routing protocols, or energy-aware
node distribution, etc. were proposed in the past. The
related work will be briefly reviewed in the next section.
In this paper, we also try to answer the aforemen-
tioned question with the following main contributions.
1) The optimal position of a sensor node within a corona
is derived. Based on this fact, the minimum number
of sensor nodes deployed in a corona to fully cover
this corona is given. 2) Completely balanced energy
depletion is proven to be achievable for the GND and
EPND. 3) Three novel non-uniform node distribution
strategies are proposed. Strategy I is able to fully achieve
energy balance. It arranges more area in the outermost
corona to make the sensor nodes deployed there cover
more area and have a longer transmission/sensing range
than the sensor nodes deployed in the other coronas. By
doing so, it balances the workload among sensor nodes.
Compared to the scheme in [28], Strategy I uses fewer
sensor nodes in the outermost corona because of its
greater sensing range. Thus, the total number of sensor
nodes used, which can be determined by the number of
sensor nodes in the outermost corona, is reduced. In the
following, we shall simply call the scheme in [28] Wu’s
scheme. For Strategy II, it achieves the longest network
lifetime through the EPND and a simple sensing/non-
sensing switch scheduling. It is able to use as few sensor
nodes as possible with the help of the simple switch
scheduling. Therefore, only active sensor nodes need
IEEE TRANSACTIONS ON MOBILE COMPUTING, VOL. XX, NO. XX, XX 2011 3
in the network is still achievable. In fact, their proposed
strategy will be the stepping stone for Strategy I in this
paper. Nevertheless, we can prove in this paper that
completely balanced energy depletion is achievable with
the additional help of node transmission range arrange-
ment. Adjusting transmission ranges of sensor nodes has
also been discussed by Cardei et al. in [2] to give a
significant impact on the network lifetime. Besides the
aforementioned approaches, some researches devoted
to design a long-lived WSN via exploring transmission
schemes [17] and managing the status operation of each
sensor during the active/inactive period of a sensor or
the selection mechanism of cluster heads [9].
Since Wu’s scheme [28] is one of the most related
schemes to ours in the literature, let us further take a
closer look at it. In [28], Wu et al. first claimed that
balanced energy depletion among sensor nodes in a
uniform-width corona model (see the next section) is
impossible. Then, they proposed their non-uniform node
distribution strategy, i.e., the so-called Wu’s scheme in
this paper, based on the uniform-width corona model
and a routing protocol called q-switch routing specif-
ically designed for the corona-based WSN. For Wu’s
scheme, the number of sensor nodes in the ith corona de-
noted by Ni (i = 1, 2, . . . , k) should satisfy the following
arrangement. The number of sensor nodes in the corona
increases in geometric progression with a common ratio
q (> 1) from corona k − 1 to corona 1 and there are
Nk−1/(q − 1) sensor nodes in corona k (the outermost
corona). They also proved that their non-uniform node
distribution strategy can achieve the sub-balanced en-
ergy depletion. Note that the term sub-balanced energy
depletion in [28] means that the energy depletion is fully
balanced among all coronas except for the outermost
one, i.e., among coronas 1 to k − 1. As for q-switch
routing, it works as follows. The q-switch routing is one
of the shortest path routing algorithms based on the
residual energy. With the help of a network initialization
process, each sensor node can learn of its downstream q
(or q − 1) relay candidates in the inner corona adjacent
to the corona which the sensor node resides in. Among
the relay candidates, the source sensor node selects the
candidate with the maximum residual energy to serve
as the relay sensor node. With the selected relay sensor
node, the source sensor node can then forward its own
data or the data from its upstream sensor node. The
previous process is repeated sequentially for the selected
relay sensor node alternatively serving as a source sensor
node until the data reach a relay sensor node in the
innermost corona, which will direct the data to the sink.
3 CORONA MODELS AND DEFINITIONS
3.1 Corona Models
The corona models and the corresponding assumptions
used for our work are described as follows. First of all,
a circular area of radius R with a static sink located
at the center of the circular area monitored by sensor
nodes is considered. Second, a corona model used to
cover the monitored circular area is further considered
by dividing the circular area into several coronas. Gener-
ally speaking, we can use (k + 1)-tuple (k,w1, . . . , wk) to
describe the corona model, where k is the total number
of coronas, w1 is the radius of the innermost corona, and
wi, i = 2, 3, . . . , k, denote the width of the ith corona.
Based on the corona width/radius (but not deployment
area), the corona model can be classified into uniform-
width and non-uniform-width corona models. If a uniform
width/radius is employed, it is referred to as a uniform-
width corona model in which wi = su for i = 1, 2, . . . , k.
This corona model is one of the corona models consid-
ered in this paper and simply called corona model I for
simplicity and cross-referencing. In fact, corona model
I is employed by Wu’s scheme and Strategy II. On the
contrary, a non-uniform-width corona model has at least
one width/radius of a corona differs from the others.
Although such a general non-uniform-width corona model
can be defined, we shall not focus on this general non-
uniform-width corona model to avoid accompanying high
extra cost and complexity incurred in deployment of
sensor nodes. To improve the sub-balanced energy de-
pletion of Wu’s scheme to totally reach balanced energy
completion as the goal set by Strategy I, the simplest
way is to employ a different corona width (transmission
range) for the outermost corona (to be explained later).
Therefore, a special case of the non-uniform-width corona
model is considered in this paper instead to make an
applicable corona model without high extra cost and
complexity and to suit our proposed strategies, i.e.,
Strategies I and III. In this special case of the non-
uniform-width corona model, only the corona width of
the outermost corona is different from that of the others,
i.e., wi = s for i = 1, 2, . . . , k − 1 and wk = so. Likewise,
this special case of the non-uniform-width corona model is
called corona model II for simplicity and cross-referencing.
Moreover, some common assumptions regarding these
two corona models are listed as follows:
• Homogeneous sensor nodes with the same initial
energy ε are assumed, while an unlimited amount
of energy is set for the sink.
• Data logging applications or periodic data gathering
applications are considered for the WSN in which
each sensor node generates and sends L bits of
data per unit time to the sink via the multi-hop
communication. Therefore, our proposed protocols
are mainly limited to the applications of continuous
monitoring but not event-driven applications.
• For the theoretical analysis, an ideal MAC layer
with no collisions and retransmissions is assumed.
However, we consider TDMA as the MAC protocol
in our ns-2 simulations for investigating the impact
caused by the MAC protocol to make the assump-
tion realistic.
• For simplicity, there is no data aggregation at any
sensor node. In the literature, data aggregation is
IEEE TRANSACTIONS ON MOBILE COMPUTING, VOL. XX, NO. XX, XX 2011 5
( )1 1y b  
y  
x  
1
C  
1 1
b s+  
( )
1C
f y  
( )1 1f y b−  
1
w  
( )10,  b  
( )1 1x b  
(a)
1
1
i
j
j
w
−
=
∑  
( )1 iy b  
( )2 iy b  
y  
x  
iC  
1
i
j
j
w
=
∑  
( )0,  ib  
( )1 ix b  ( )2 ix b  
i i
b s−
 
i i
b s+
 
( )
iC
f y
 
( )i if y b−  
( )
1iC
f y
−
 
(b)
Fig. 1. Auxiliary figures for deriving the optimal position of
a sensor node within corona Ci. (a) Case of the innermost
corona. (b) Case of corona Ci, i ≥ 2.
Theorem 4.1: Assume a corona model
(k,w1, . . . , wi, . . . , wk) with si, i = 1, . . . , k, denoting
the sensing range of the sensor node in corona Ci and
wi
2 ≤ si ≤
√
2
(∑i
j=1 wj
)
. The optimal position of a
sensor node within corona Ci can be determined so
that the maximum corona coverage is reached. Let
this optimal position be located at the position with
distance bopti measured from the center of the corona,
then bopti , i = 1, 2, . . . , k, should satisfy the following
conditions:
bopt1 =
{ √
w21−s21
3 ,√
s21 − w21,
for w12 ≤ s1 ≤ w1,
for w1 < s1 ≤
√
2w1,
(1)
bopti =
√
(∑i−1j=1 wj)2+(∑ij=1 wj)2−2s2i
2 , i = 2, . . . , k.
(2)
Proof: Without loss of generality, we assume that the
sensor node within corona Ci is deployed at (0, bi), bi ≥
0. This theorem is then proven through the following
two cases: case of the innermost corona and case of
corona Ci, i ≥ 2, as shown in Fig. 1. With the help of
the symmetric property regarding y-axis, the first part of
this theorem, i.e., (1), is proven by finding the optimal
value of b1 such that the shaded area (half of the corona
coverage) shown in Fig. 1(a) is maximized. The second
part of this theorem, i.e., (2), is proven by finding the
optimal value of bi to minimize the shaded area (area
of the semi-circle minus half of the corona coverage)
shown in Fig. 1(b). Let us first consider the first case.
Substituting x2 = w12 − y2 into x2 + (y − b1)2 = s21, we
get y1(b1) of the cross point (x1(b1), y1(b1)) in the first
quadrant of the two circles shown in Fig. 1(a) as follows:
y1(b1) =
w21 + b
2
1 − s21
2b1
.
Let f(b1) denote the shaded area shown in Fig. 1(a), i.e.,
f(b1) =
∫ y1(b1)
0
f1(y − b1)dy +
∫ w1
y1(b1)
fC1(y)dy
=
∫ y1(b1)−b1
−b1
f1(y)dy +
∫ w1
y1(b1)
fC1(y)dy,
where f1(y) =
√
s21 − y2 and fC1(y) =
√
w21 − y2. Denot-
ing F1(y) and FC1(y) as the anti-derivatives of f1(y) and
fC1(y), respectively, f(b1) can then be rewritten as
f(b1) = F1(y1(b1)− b1)− F1(−b1) + FC1(w1)− FC1(y1(b1)).
The first derivative of f(b1) is then given by
f ′(b1) = f1(y1(b1)− b1)
(
dy1(b1)
db1
− 1
)
+ f1(−b1)
− fC1(y1(b1))
dy1(b1)
db1
= f1(−b1)− f1(y1(b1)− b1),
where the second equality holds because
f1(y1(b1)− b1) = fC1(y1(b1)) = x1(b1). Obviously,
f ′(bopt1 ) = 0, leading to b
opt
1 =
√
(w21 − s21)/3 when
w1
2 ≤ s1 ≤ w1 or
√
s21 − w21 when w1 < s1 ≤
√
2w1.
Of course, one can further check that these two
optimal values, i.e.,
√
(w21 − s21)/3 and
√
s21 − w21 , make
f ′′(bopt1 ) < 0. This proves the first part of this theorem.
Note that although the same coverage, i.e., the quadrant
shown in Fig. 1(a), can be reached if 0 ≤ b1 <
√
s21 − w21
when w1 < s1 ≤
√
2w1, the sensor node is too close to
the sink as compared to the point
√
s21 − w21 . Hence,
these positions are not included in the optimal positions
in this theorem. Using the same manner, we now prove
the second part of this theorem. The shaded area shown
in Fig. 1(b) denoted by g(bi), i ≥ 2, can be expressed as
g(bi) =
∫ bi+si
y2(bi)
fi(y − bi)dy −
∫ ∑i
j=1 wj
y2(bi)
fCi(y)dy
+
∫ y1(bi)
bi−si
fi(y − bi)dy +
∫ ∑i−1
j=1 wj
y1(bi)
fCi−1(y)dy
=
∫ si
y2(bi)−bi
fi(y)dy −
∫ ∑i
j=1 wj
y2(bi)
fCi(y)dy
+
∫ y1(bi)−bi
−si
fi(y)dy +
∫ ∑i−1
j=1 wj
y1(bi)
fCi−1(y)dy,
where fi(y) =
√
s2i − y2, fCi−1(y) =√(∑i−1
j=1 wj
)2
− y2, fCi(y) =
√(∑i
j=1 wj
)2
− y2,
y1(bi) =
(∑i−1j=1 wj)2+b2i−s2i
2bi
, and y2(bi) =
(∑ij=1 wj)2+b2i−s2i
2bi
.
Letting Fi(y), FCi−1(y), and FCi(y) denote the anti-
derivatives of fi(y), fCi−1(y), and fCi(y), respectively,
IEEE TRANSACTIONS ON MOBILE COMPUTING, VOL. XX, NO. XX, XX 2011 7
model:
Ei =

L[Nai (Eelec + ²d
α
i )
+
∑k
j=i+1N
a
j (2Eelec + ²d
α
i )], 1 ≤ i ≤ k − 1,
NakL (Eelec + ²d
α
k ) , i = k.
(4)
Under the basic operation mode, all sensor nodes are
active with the following corresponding energy con-
sumption per unit time denoted by EBi .
EBi =

L[Ni (Eelec + ²dαi )
+
∑k
j=i+1Nj(2Eelec + ²d
α
i )], 1 ≤ i ≤ k − 1,
NkL (Eelec + ²dαk ) , i = k,
(5)
where the superscript B is used to explicitly denote the
basic operation mode. Note that the main task of an
active sensor node is either sensing its surrounding area
and transmitting data to its child node or relaying data
from its parent node if it is chosen as the relay node.
If a sensor node does nothing at all, it will remain idle
to save energy. Hence, the energy consumption per unit
time with a minimum number of active sensor nodes
Nmini in corona Ci derived from Corollary 4.1 denoted
by EMi (here, the superscript
M is used to explicitly de-
note the minimum active sensor nodes getting involved)
is
EMi =

L[Nmini (Eelec + ²d
α
i )
+
∑k
j=i+1N
min
j (2Eelec + ²d
α
i )], 1 ≤ i ≤ k − 1,
Nmink L (Eelec + ²d
α
k ) , i = k.
(6)
4.4 Balanced Energy Depletion Analysis for Two
Primitive Node Distributions
In the following, the feasibility of balanced energy de-
pletion using two primitive node distributions, i.e., GND
specifically designed for corona model II and EPND, is
examined.
4.4.1 GND specifically designed for corona model II
In [28], Wu et al. have claimed that their GND under
corona model I merely achieves the sub-balanced en-
ergy depletion, i.e., balanced energy depletion among
all coronas except for the outermost one. This motivates
us to consider the GND designed for corona model II
rather than corona model I. To achieve balanced energy
depletion among all coronas, the transmission distance
in the outermost corona do should be properly adjusted
so that Tk−1 = Tk, i.e.,
εNk−1
EBk−1
= εNk
EBk
by Definition 3.1.
This condition and (5) lead to
Nk−1EBk = NkE
B
k−1,
Nk−1(NkL(Eelec + ²dαo )) = NkL(Nk(2Eelec + ²dα)
+Nk−1(Eelec + ²dα)).
Adding an extra condition Nk−1 = (q − 1)Nk (like Wu’s
scheme), we can further rewrite the above equation as
follows:
(q − 1)(Eelec + ²dαo ) = (2Eelec + ²dα)
+(q − 1)(Eelec + ²dα),
(q − 1)Eelec + (q − 1)²dαo = 2Eelec + q²dα + (q − 1)Eelec,
do =
[
2Eelec + q²dα
(q − 1)²
] 1
α
. (7)
With the GND, Nk = Nk−1/(q − 1), and the derived do,
we can show that (completely) balanced energy deple-
tion among all coronas is achievable in the following
theorem.
Theorem 4.2 (GND and balanced energy depletion): If the
number of sensor nodes in coronas Ck−1, . . . , C1 with
transmission distance of d increases geometrically with
a common ratio q (> 1) and there are Nk = Nk−1/(q − 1)
sensor nodes in corona Ck with transmission distance of
do =
[
2Eelec+q²d
α
(q−1)²
] 1
α
, balanced energy depletion among
all coronas is achievable.
Proof: Since all assumptions in [28] except the trans-
mission distance in the outermost corona are employed,
it is clear that balanced energy depletion can be reached
among coronas C1 to Ck−1. Therefore, we merely need
to show that balanced energy depletion exhibits between
coronas Ck−1 and Ck to complete the proof of this
theorem. Since all steps in deriving (7) are revertible,
one can easily reach Tk−1 = Tk. Further combining
the sub-balanced energy depletion obtained in [28], i.e.,
Ti = Tj , i, j ∈ {1, 2, . . . , k − 1}, we have Ti = Tj , i, j ∈
{1, 2, . . . , k}. Because of the homogeneous property of
operation for each sensor node in the same corona (see
Section 3), uniform energy consumption for each sensor
node in the same corona is obviously achievable. By
Definition 3.3, the proof of this theorem is completed.
4.4.2 EPND
As stated previously, each sensor node that is neither
sensing nor relaying data can be regarded as an idle
sensor node. Despite the fact that an idle sensor node
still consumes energy, this amount of consumed energy
can be neglected because of its insignificant impact
on the network lifetime. In the following corollary, we
show that balanced energy depletion among coronas is
achievable for the EPND.
Corollary 4.2 (EPND and balanced energy depletion):
Given Nk (≥ Nmink ) and Ei (i = 1, 2, . . . , k) (using (4)),
the network can achieve balanced energy depletion if
the number of sensor nodes in corona Ci (i = 1, 2, . . . , k)
is set to
(
Ei
Ek
)
Nk, i.e., Ni =
(
Ei
Ek
)
Nk, where
(
Ei
Ek
)
Nk is
an integer.
Proof: With the same reasoning in the proof of
Theorem 4.2, it can be shown first that uniform energy
consumption for each sensor node in the same corona is
achievable. By Definition 3.3, balanced energy depletion
IEEE TRANSACTIONS ON MOBILE COMPUTING, VOL. XX, NO. XX, XX 2011 9
5.1.3 Routing protocol
Because of the corona arrangement and the geometric
progression on the number of sensor nodes deployed
in a corona, the q-switch routing proposed in [28] and
described in Section 2 is still applicable to Strategy I for
data routing. Therefore, the routing protocol associated
with Strategy I in this paper is set to this q-switch
routing.
With the aforementioned design, one can clearly see
that Strategy I differs from Wu’s scheme [28] in the
following aspects. i) Strategy I is designed based on
corona model II, while Wu’s scheme is designed based
on corona model I. ii) Using Strategy I, completely
balanced energy depletion can be reached. However,
Wu’s scheme claimed that it is impossible to achieve
completely balanced energy depletion. Therefore, Wu’s
scheme simply reaches sub-balanced energy depletion.
iii) The optimal sensor placement is touched in this
paper and utilized by Strategy I. Since the optimal sensor
node placement is not touched in [28], Wu’s scheme does
not employ the optimal sensor node placement.
5.2 Strategy II (Designed for Corona Model I)
Strategy II consists of a constraint on the number of
sensor nodes that should be deployed based on the
EPND, a simple switch scheduling, and a q-switch-like
routing protocol under corona model I. Now, these are
explained in detail as follows.
5.2.1 Sensor node arrangement and deployment
In order to achieve better efficiency on sensor node
arrangement in each corona, each sensor node is as-
sumed to be either in the sensing or the non-sensing
state. With the same reasoning for the deployment of
sensor nodes in Strategy I, a deployment scheme based
on Theorem 4.1 except for the innermost corona in which
we suggest deploying sensor nodes at the middle of
the corona width is employed for Strategy II in the
following. As for the number of sensor nodes to be
deployed, it follows the EPND to form the following
constrained EPND (CEPND):
Ni =
{ ⌈⌈
EMi
EMk
Nmink
⌉
/Nmini
⌉
Nmini , for i = 1, . . . k − 1,
Nmink , for i = k,
(13)
Note that EMi , i = 1, 2, . . . , k − 1, are still applicable
here since the switch scheduling can control the energy
consumption to EMi for corona Ci. In the previous
calculation, the following operations are required. i) The
inner ceil function d·e is employed in order to have an
integer number of sensor nodes if E
M
i
EMk
Nmink is not an
integer. ii) The outer ceil function d·e is used to ensure
that the number of sensor nodes in corona Ci, i.e., Ni, to
be a multiple of the minimum number of sensor nodes
Nmini . Note that the requirement that Ni is a multiple of
the minimum number of sensor nodes Nmini is tailored
 
1: // While sensor nodes still have energy. 
2: while ( 0energyLevel > ) 
3:  // The sensor node is selected to sense its surrounding area. 
4:  if ( )maxmod 0i icounter counter =  then 
5:   // The sensor node selected both senses it surrounding area and 
6:   // relays data from its upper node. 
7:   if (SelectedToRelay = true) then 
8:    destID = SelectRelay; 
9:    Send(destID, OWN_DATA_MSG + RELAY_DATA_MSG); 
10:   // The sensor node selected senses its surrounding area only. 
11:   else 
12:    destID = SelectRelay; 
13:    Send(destID, OWN_DATA_MSG); 
14:   end if 
15:  // The sensor node is not selected to sense its surrounding area. 
16:  else if ( )maxmod 0i icounter counter ≠  then 
17:   // The sensor node relays data from its upper node. 
18:   if (SelectedToRelay = true) then 
19:    destID = SelectRelay; 
20:    Send(destID, RELAY_DATA_MSG); 
21:   end if 
22:  end if 
23:  // Change sensor node counter value. 
24:  ( ) max1 modi i icounter counter counter= + ; 
25: end while 
 
Fig. 3. Pseudocode of the switch scheduling.
for the switch scheduling with consideration of coverage.
With these extra operations, energy depletion is perhaps
not completely balanced among sensor nodes. However,
Strategy II is expected to give the best performance
in the network lifetime and efficiency on sensor node
arrangement as compared to Wu’s scheme and Strategy
I to be shown in the next section.
5.2.2 Switch scheduling
A simple switch scheduling in a turn-based manner
utilizing counters determines whether a sensor node
needs to sense its surrounding area or not. Shown in
Fig. 3 is the pseudocode for our designed switch schedul-
ing in corona Ci. Sensor nodes not chosen to sense
its surrounding area will remain idle or relay the data
received from its upper sensor node in the outer corona.
Of course, sensor nodes chosen to sense its surrounding
area need to perform this task solely or along with some
extra task, i.e., data relay, if any.
In our switch scheduling, the following arrangement
is made to determine sensing or not using a turn-based
manner implemented by counters.
• Within corona Ci (i = 2, . . . , k), sensor nodes are
deployed at the optimal positions according to The-
orem 4.1 with uniform distance of 2pibopti /Ni to each
other. For corona C1, we deploy sensor nodes at
the middle point of the corona width, i.e., w12 , with
uniform distance of piw1/N1 to each other. Nmin1 is
calculated according to Corollary 4.1 via replacing
bopt1 by
w1
2 accordingly. For sensor nodes, they are
grouped according to their counteri value ranging
from 1 to countermaxi = Ni/N
min
i ((13) guarantees
that countermaxi is an integer). Assign the first sen-
sor node a counter value of countermaxi , while the
subsequent sensor node is assigned a counter value
of countermaxi − 1. This process is repeated until
the counter value reaches 1. This procedure will
be repeatedly performed until all sensor nodes are
associated with their own counter values.
IEEE TRANSACTIONS ON MOBILE COMPUTING, VOL. XX, NO. XX, XX 2011 11
three proposed strategies as well as Wu’s scheme. As
for the uniform scheme, it can be counted easily because
of its fixed grid length. Let us now further derive the
network lifetime and residual energy as follows. By
Definition 3.2, the network lifetime T is
T = min{T1, T2, . . . , Tk}. (14)
For Wu’s scheme, the network lifetime TW can be de-
termined analytically in terms of any of T1, . . . , Tk−1
because T1 = T2 = . . . = Tk−1 < Tk (see [28]), i.e.,
TW = T1 = . . . = Tk−1. (15)
Because Strategy I balances energy depletion among sen-
sor nodes, the network lifetime TS1 can be analytically
expressed in terms of any of T1, . . . , Tk, i.e.,
TS1 = T1 = . . . = Tk. (16)
For Strategies II and III,
Ti =
εNi
EMi
=
ε
⌈⌈
EMi
EMk
Nmink
⌉
/Nmini
⌉
Nmini
EMi
≥
ε((E
M
i
EMk
Nmink )/N
min
i )N
min
i
EMi
=
εNk
EMk
= Tk, i = 1, 2, . . . , k − 1.
Therefore, their corresponding network lifetimes TS2 and
TS3 can be expressed by
TS2 = TS3 = Tk. (17)
Finally, it is easily understood that T1 ≤ T2 ≤ . . . ≤ Tk
for the uniform scheme. Accordingly, its network lifetime
TU is
TU = T1. (18)
As for the residual energy of the ith corona ERi (i =
1, 2, . . . , k), it can be calculated via
ERi =
 εNi − TEi, Wu’s Scheme, Strategy I,and Uniform Scheme,
εNi − TEMi , Strategies I and II,
(19)
where the network lifetime T for a different strategy
should follow the calculation in (15)–(18).
In this section, network lifetime and residual energy
are also validated by simulations written in the C#
programming language. Before the discussions on the
analytical results, let us further elaborate on the calcula-
tion/simulation arrangement first.
6.1 Calculation/Simulation Arrangement
In our calculation/simulation, each sensor node has
a uniform initial amount of energy ε = 0.5 J with
Eelec = 50 nJ/bit, ² = 0.0013 pJ/bit/m4, α = 4, and
η = 1 (the sensing range is the same as the transmis-
sion range). In the uniform scheme, Wu’s scheme, and
TABLE 1
Parameters employed in the calculation/simulation
Parameter Value
Initial energy of each sensor node (ε) 0.5 J
Path loss exponent (α) 4
Eelec 50 nJ/bit
² 0.0013 pJ/bit/m4
Length of data (L) 400 bits
Network radius (R) 300 ∼ 1000 m
Unit time (Round duration) 1 ms
Uniform corona width (su) in corona model I 100 m
Transmission range (du) in corona model I 100 m
Geometric progression ratio (q) 2
Grid length (for the uniform scheme) 50 m
300 400 500 600 700 800 900 1000
0
0.2
0.4
0.6
0.8
1
1.2
1.4
1.6
1.8
2
x 104
Network radius (in meters)
To
ta
l n
um
be
r o
f s
en
so
r n
od
es
 
 
Wu’s scheme
Strategy I
Strategy II
Strategy III
Uniform scheme
(a)
300 400 500 600 700 800 900 1000
0
10
20
30
40
50
60
70
80
90
100
Network radius (in meters)
R
at
io
 o
f s
en
so
r n
od
es
 
 
Wu’s scheme
Strategy I
Strategy II
Strategy III
Uniform scheme
(b)
Fig. 4. Total number of sensor nodes vs. network radius:
(a) Total number of sensor nodes used. (b) Ratio of the
total number of sensor nodes and the optimal number of
sensor nodes.
Strategy I, each sensor node generates 400 bits of data
each round with duration of 1 ms, while only the sensor
nodes staying in the sensing state for Strategy II/III
generate 400 bits of data. In Strategy I/III, c = 1, i.e., the
transmission range of each sensor node is equal to the
corona width. For a given network radius R, the number
of coronas k is obtained via k = R/du for all strategies
considered. Therefore, the corona width is fixed for
Wu’s scheme, Strategy II, and the uniform scheme. To
have a different network radius, a different number of
coronas is arranged accordingly. For Strategies I and
III, the number of coronas is determined like Strategy
II once a network radius is given. However, d and do
need to be recalculated based on (9) using the given
network radius. Consider an example of the 5-corona
network arrangement with network radius of 500 m. For
Strategy I/III, we have d = 94.0904 m, do = 123.6383
m, and Nmin5 = 15. For Wu’s scheme and Strategy II,
uniform corona width du = 100 m and Nmin5 = 19 are
set. Noting that sensor nodes are deployed at corners
of grids with grid length of 50 m for the uniform
scheme, we have uniform corona width du = 100 m,
N1 = 12, N2 = 36, N3 = 64, N4 = 84, and N5 = 120. In
Table 1, all corresponding parameters are listed.
6.2 Analytical Results and Discussions
6.2.1 Total number of sensor nodes
Shown in Fig. 4(a) are the analytical results on the total
number of sensor nodes used in the network for the five
IEEE TRANSACTIONS ON MOBILE COMPUTING, VOL. XX, NO. XX, XX 2011 13
four strategies. Explicitly, the uniform scheme gives the
worst performance among the five strategies.
Different from the uniform scheme, Wu’s scheme,
and Strategy I which let all sensor nodes sense the
surrounding area per round, Strategy II/III only sets a
minimum number of sensor nodes determined by Nmini
in corona Ci to sense the surrounding area per round.
Besides, Strategy III sets the same number of sensor
nodes with same energy dissipation for the outermost
corona as Strategy I, while Strategy II sets more sensor
nodes with less energy dissipation for the outermost
corona than Strategy I. Noting that the corona lifetime
of the outermost corona Tk determines the network
lifetime for Strategy II from (17) and Tk = εNkEk =
εNk
Nk(Eelec+²dαk )
= ε(Eelec+²dαu) for Strategy II is a constant,
its network lifetime is a constant. This explains why
a constant behavior of network lifetime for Strategy II
as shown in Fig. 5(a) is observed. (17) also shows that
the network lifetime of Strategy III is determined by
the corona lifetime of the outermost corona Tk. With
the same corona model and the same number of sensor
nodes with same energy dissipation in the outermost
corona as Strategy I, the network lifetime of Strategy III
is identical to that of Strategy I (see (16) and (17)). This
explains why the network lifetimes of Strategies I and III
coincide in Fig. 5(a). Since more sensor nodes with less
energy dissipation in the outermost corona for Strategy
II as compared to Strategy I, Strategy II has a longer
network lifetime than Strategy I as well as Strategy III
(see (16) and (17)).
The above observations clearly illustrate that the best
strategy to the worst strategy in terms of network
lifetime are Strategy II, Strategy I as well as Strategy
III, Wu’s scheme, and the uniform scheme. Since the
uniform scheme performs worst, we only show the
improvement ratios for Strategies I–III over Wu’s scheme
in Fig. 5(b). This figure shows that Strategy II gains 128%
of improvement over Wu’s scheme regardless of network
radii. At the network radius of 300 m (1000 m), Strategies
I and III can get 28% (8%) of improvement over Wu’s
scheme. This clearly reveals the superiority of Strategy
II over the other strategies in terms of network lifetime.
6.2.3 Residual energy of each sensor node
In this part, the residual energy for the five strategies
under a 5-corona model is evaluated. Note that sensor
nodes are assigned IDs starting from the outermost
corona to the innermost corona.
Shown in Fig. 6 is the residual energy of each node
(or called the residual nodal energy later) for the five
strategies. Explicitly, one can witness that the analytical
and simulation results match well. From Fig. 6(e), one
can easily see that the uniform scheme leaves an abun-
dant amount of nodal energy as expected, especially for
the sensor nodes in the outermost corona Approximately,
96% of the initial nodal energy is left there. Fig. 6(a)
shows that Wu’s scheme leaves a considerable amount
50 100 150 200 250 300
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
0.45
0.5
Node ID
R
es
id
ua
l e
ne
rg
y 
(in
 jo
ule
)
 
 
Simulation
Analysis
(a)
50 100 150 200
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
0.45
0.5
Node ID
R
es
id
ua
l e
ne
rg
y 
(in
 jo
ule
)
 
 
Simulation
Analysis
(b)
50 100 150 200 250
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
0.45
0.5
Node ID
R
es
id
ua
l e
ne
rg
y 
(in
 jo
ule
)
 
 
Simulation
Analysis
(c)
20 40 60 80 100
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
0.45
0.5
Node ID
R
es
id
ua
l e
ne
rg
y 
(in
 jo
ule
)
 
 
Simulation
Analysis
(d)
50 100 150 200 250 300
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
0.45
0.5
Node ID
R
es
id
ua
l e
ne
rg
y 
(in
 jo
ule
)
 
 
Simulation
Analysis
(e)
Fig. 6. Residual energy of each sensor node under
an ideal scenario. (a) Wu’s scheme. (b) Strategy I. (c)
Strategy II. (d) Strategy III. (e) Uniform scheme.
of remaining nodal energy (56% or so of the initial
nodal energy) in the outermost corona when the network
operation is terminated. For Strategy I, almost all sensor
nodes exhaust energy when the network operation is ter-
minated as shown in Fig. 6(b). In fact, the residual nodal
energy for most of sensor nodes is below 5×10−4 J when
applying Strategy I. As shown in Fig. 6(c), Strategy II
still gives quite good performance in the residual nodal
energy although not all sensor nodes completely exhaust
energy. The remaining nodal energy is at most 13% of the
initial nodal energy (in the 4th corona) only. Similar to
Strategy II, Strategy III gives quite good performance in
the residual nodal energy as well. As shown in Fig. 6(d),
only 16% at most of the initial nodal energy is left among
sensor nodes (in the 2nd corona).
To have a comparison on the degree of energy deple-
tion as compared to the ideal case with complete energy
depletion (zero energy left), one can use the following
two ways to gauge this degree. The first one is the
total residual energy in the network and the second
one is dνe =
∑
∀j(E
R,j)ν/nt. Here, dνe is the defined
degree of energy depletion as compared to the ideal case,
ER,j denotes the residual energy of the senor node with
ID j, ν ≥ 1 serves as a given amplifying factor used
to amplify the difference of the residual nodal energy
IEEE TRANSACTIONS ON MOBILE COMPUTING, VOL. XX, NO. XX, XX 2011 15
300 400 500 600 700 800 900 1000
0
1000
2000
3000
4000
5000
6000
7000
8000
Network radius (in meters)
N
et
w
or
k 
life
tim
e 
(in
 ro
un
ds
)
 
 
Wu scheme (Ideal)
Wu scheme (Realistic I)
Strategy I (Ideal)
Strategy I (Realistic I)
Strategy II (Ideal)
Strategy II (Realistic I)
Strategy III (Ideal)
Strategy III (Realistic I)
Uniform (Ideal)
Uniform (Realistic I)
(a)
300 400 500 600 700 800 900 1000
0
1000
2000
3000
4000
5000
6000
7000
8000
Network radius (in meters)
N
et
w
or
k 
life
tim
e 
(in
 ro
un
ds
)
 
 
Wu scheme (Ideal)
Wu scheme (Realistic II)
Strategy I (Ideal)
Strategy I (Realistic II)
Strategy II (Ideal)
Strategy II (Realistic II)
Strategy III (Ideal)
Strategy III (Realistic II)
Uniform (Ideal)
Uniform (Realistic II)
(b)
300 400 500 600 700 800 900 1000
0
20
40
60
80
100
120
Network radius (in meters)
Im
pr
ov
em
en
t r
at
io
 (in
 pe
rce
nt)
 
 
Strategy I
Strategy II
Strategy III
(c)
300 400 500 600 700 800 900 1000
0
10
20
30
40
50
60
70
80
90
100
Network radius (in meters)
Im
pr
ov
em
en
t r
at
io
 (in
 pe
rce
nt)
 
 
Strategy I
Strategy II
Strategy III
(d)
Fig. 7. Network lifetime and improvement ratio. (a) Network lifetime (Realistic I). (b) Network lifetime (Realistic II). (c)
Improvement ratio over Wu’s scheme (Realistic I). (d) Improvement ratio over Wu’s scheme (Realistic II).
TABLE 2
Total residual energy in the network and d2e for the five strategies under different scenarios
Scenario Wu’s Scheme Strategy I Strategy II Strategy III Uniform Scheme
Ideal 5.41 J, 4.9× 10−3 0.07 J, 9.2× 10−8 7.12 J, 1.3× 10−3 3.09 J, 1.9× 10−3 136.3 J, 0.195
Realistic I 5.21 J, 3.9× 10−3 0.47 J, 4.4× 10−6 5.88 J, 8.4× 10−4 2.72 J, 1.5× 10−3 135.2 J, 0.192
Realistic II 4.92 J, 3.7× 10−3 1.37 J, 3.6× 10−5 6.99 J, 1.0× 10−3 3.56 J, 1.9× 10−3 134.9 J, 0.191
50 100 150 200 250 300
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
0.45
0.5
Node ID
R
es
id
ua
l e
ne
rg
y 
(in
 jo
ule
)
 
 
Ideal
Realistic I
Realistic II
(a)
50 100 150 200
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
0.45
0.5
Node ID
R
es
id
ua
l e
ne
rg
y 
(in
 jo
ule
)
 
 
Ideal
Realistic I
Realistic II
(b)
50 100 150 200 250
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
0.45
0.5
Node ID
R
es
id
ua
l e
ne
rg
y 
(in
 jo
ule
)
 
 
Ideal
Realistic I
Realistic II
(c)
20 40 60 80 100
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
0.45
0.5
Node ID
R
es
id
ua
l e
ne
rg
y 
(in
 jo
ule
)
 
 
Ideal
Realistic I
Realistic II
(d)
50 100 150 200 250 300
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
0.45
0.5
Node ID
R
es
id
ua
l e
ne
rg
y 
(in
 jo
ule
)
 
 
Ideal
Realistic I
Realistic II
(e)
Fig. 8. Residual energy of each sensor node under ideal
and realistic scenarios. (a) Wu’s scheme. (b) Strategy I.
(c) Strategy II. (d) Strategy III. (e) Uniform scheme.
the residual energy is observed for the three scenarios
as far as a specific strategy is concerned, in particular,
the uniform scheme. To examine the degree of energy
depletion, Table 2 lists the total residual energy in the
network and d2e for the five strategies under the ideal
scenario and scenarios Realistic I and II. Compared to the
ideal scenario, only Strategy I shows remarkable impacts
caused by scenarios Realistic I and II. However, Strategy
I still possesses its superiority in energy depletion over
the other four strategies. Likewise, Wu’s scheme and
Strategies II and III almost have comparable perfor-
mance in energy depletion, while the uniform scheme
performs worst.
8 CONCLUSIONS
Three novel node distribution strategies designed for
a corona-based WSN are proposed in this paper to
mitigate the energy hole problem. Analyzing the corona-
based WSN, we get the optimal positions of sensor
nodes, lower bounds on sensor nodes to be deployed
within a corona, and proposals of GND as well as EPND.
These results enable the three proposed strategies to give
full WSN coverage while providing a long network life-
time. In fact, one of our proposed strategies, i.e., Strategy
I, has succeeded in solving one of the most difficult tasks
in WSNs, namely, balancing energy depletion among
sensor nodes. Incorporating switch scheduling, Strategy
II provides the longest network lifetime, full WSN cov-
erage, and high efficiency in using sensor nodes. Similar
to Strategy II, Strategy III incorporates switch scheduling
and reaches the best efficiency in using sensor nodes,
full WSN coverage, and a durable network lifetime.
Via both analytical and simulation observations, we can
show the superiority of the three strategies over the
other two most related strategies, i.e., Wu’s scheme and
the uniform scheme. We have successfully demonstrated
that Strategies I–III are highly recommended for use in
無研發成果推廣資料 
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
