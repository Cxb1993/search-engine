I 
摘要 
過去的研究早已證實在遠程作業系統中，遠端環境的回饋資訊的品質高低及時間長短
是影響操作效率及操作正確度的主要因素之一。然而在通訊頻寬有限且可能不斷變動的情
況下，為保持感官回饋資訊的即時性，最直接的作法即為發展出一套可變動壓縮比的有失
真壓縮(lossy compression)方法，將資訊根據其重要性而壓縮。而感官回饋資訊中最重要的
視覺訊號壓縮，除了近年發展的 MPEG-4 等方式外，利用視網膜解析度的不等分布而衍生
出的多解析度影像壓縮即時視訊方法是一個可以提供更高壓縮率的方法。由於多解析度影
像必須以使用者視角中心開始向外逐漸降低解析度，因此一般咸認為套用在遠端監視或控
制系統上必須要搭配視線追蹤(eye gaze tracking)系統，並且要知道顯示畫面大小與使用者視
角之間的關係。本計畫則提出讓使用者自主動態指定視野中心與中心範圍的操作方式，希
望僅利用一般的圖型使用者介面發展出廣視野、可動態對應頻寬的即時影像串流壓縮技術。
根據本計畫預定執行的進度，在第一年度我們的目標放在雛型系統之建置，包含以下三個
部份：(1)實作多解析影像壓縮模組、(2)建構廣視角即時視訊系統、(3)包含視線追蹤的操作
端使用者介面。我們順利的完成各部份的建置，也達成了預期的進度。目前整個系統達成
初步的整合，雖然各個部分的程式以及功能都實作完成，但仍有工作上效能並不理想等問
題，留待後續進行。 
 
關鍵詞：遠端作業、多解析影像、視線追蹤 
  
1 
一、 前言 
過去的研究早已證實在遠程作業系統中，遠端環境的回饋資訊的品質高低及時間長短
是影響操作效率及操作正確度的主要因素之一。在某些應用上(例如機器人在外太空)受限於
通訊方式的限制，時間延遲是非常顯著的。監督式控制(supervisory control)與預測顯示
(predictive display, or predictor display)技術因此被開發出來補償長時間延遲所造成的操作效
能低落問題[1]。然而在通訊頻寬不足且可能不斷變動的情況下，最糟糕的狀況即是回饋資
訊的產生速度高於平均傳送速度，而造成時間延遲不斷增加。因此，為保持回饋資訊的即
時性，最直接的作法即為發展出一套可變動壓縮比的有失真壓縮(lossy compression)方法，
將資訊根據其重要性而壓縮。 
一般的遠程作業系統架構如圖一所示，為了有效了解遠端環境，絕大部分的遠端機器
人均裝設攝影機與麥克風等裝置，以提供視覺、聽覺等的感官資訊。其中又因人類最倚賴
視覺資訊，因此回饋資訊中的影像串流應最為重要。不幸的是，與其他感測器產生的資料
相比，攝影機所產生的資訊量通常極為龐大。因此在各種感測器的回饋資訊中，攝影機(也
可稱為視訊感測器)所佔的比例遠超過其它感測器，更不用提反方向的指令。即使以現今的
影像壓縮技術，在可接受的解析度下一般的遙控自走車仍僅能傳送一個左右的攝影機畫面
(橫向約30~42 度角)。以人所擁有的180~200 度橫向視野(FOV, field of view)來說，這絕非
讓人滿意的情況。Marvin Minsky在1980 年即曾預言機器人及人機介面技術的不斷進步之
下，遠端操作系統終會演進至遠端臨場(telepresense)[2]的地步，也就是操作者身歷其境的
控制遠端機器人來進行作業。然而若要提供人類視野的遠端環境畫面，仍有必要在現況中
尋求技術上的突破。 
 
圖一 遠程作業系統的通信內容，包含指令與回饋資訊 
二、 研究目的 
本計畫的研究目的在開發出適合傳送即時廣視野影像的資訊壓縮方法以及其操作介面。
一般攝影機的影像均以同一解析度來取樣整個畫面，然而主導人類視覺解析度的椎細胞與
桿細胞在視網膜上卻是呈現極度不均勻的分布，導致人的視覺在靠近眼球中央(視網膜中央
窩)注視點的解析度最高，而後向周圍快速遞減。除此之外，人在不同亮度下對色彩的辨識
程度也不一致[3]。因此，若能根據人眼視力及可用頻寬，開發出具彈性的影像壓縮方法，
3 
 
圖二 log-polar mapping，左方任一點座標(x,y)均可被轉換至(ρ,θ)，並對應至右方座標軸
之(ln(ρ),θ)點上 
另一方面，從 1996 年開始美國德州大學的 Geisler 和 Perry 針對內含多解析度的單一
影像編碼發表了較為簡易的視角切割方法。此方法可使用一般攝影機，且計算量低，是目
前此議題咸認的前瞻研究。在文獻[11]中，Kortum  和 Geisler 提出了一個注視點追踪的雛
型系統(Foveated Imaging System, FIS)，其系統一開始先行初始化和校正系統，接著計算 
ResolutionGrid，也就是將影像切割成好幾塊對稱的方塊，離注視點越遠的方塊大小越大。
算完 ResolutionGrid 之後，開始偵測使用者眼睛的位置，並且計算出新的位置和上一次眼
睛位置的差異，如果此差異大於所定義的門檻值，則更新眼睛的位置。確認完眼睛位置之
後，開始使用  SuperPixel 演算法計算各方塊中影像的平均值，接著再將平均值繪至 
ResolutionGrid 的方塊中。當影像呈現至螢幕之後，系統會重新執行偵測眼睛位置的步驟。 
在上述系統中，其核心的演算法是 ResolutionGrid，圖三為如何利用 ResolutionGrid 改
變注視點位置的例子。一開始注視點在影像的中間，接著注視點慢慢移動到影像的右上角，
我們可以清楚的看到左下角的畫素逐漸變大，解析度變低。切割完影像之後，再使用 
SuperPixel 將方塊填上不同解析度的影像。 
 
圖三 當注視點改變時，ResolutionGrid 變化的過程[11] 
在  1998 年，Geisler 和  Perry 延續之前的研究，發展了一套新的系統  Foveated  
Multiresolution Pyramid (FMP)[12]，主要改善以往影像周圍動作的失真，並且引進新一代的
多解析度影像壓縮技術，此技術被命名為多解析度角錐(Multiresolution Pyramid)演算法。
FMP 是特別為低頻寛影片傳輸所設計的編碼解碼器，此系統有幾個主要的優點，將注視目
標和多解析度角錐演算法完全整合在一起，並且此系統是在一般的個人電腦中開發注視點
x 
y 
θ 
ρ 
5 
之後出來的結果是 Bitmap data型式，卻與一般的 BMP 格式不同。我們因此自行撰寫格式
轉換程式，再使用開放源碼軟體 FreeImage[16]來轉換為 JPEG 格式，以便容易和視訊串流
部份銜接。 
目前的靜態圖片壓縮效果如下圖所示。圖五是測試用圖片，JPEG 格式、大小是 1024×
768像素。我們將注視點設定於左上方並進行 FMP壓縮後的結果如圖六，可發現圖片畫質
不均等，愈遠離注視點的地方就愈模糊。將圖六經由 FreeImage進行 JPEG 格式轉換後，檔
案大小將大幅降低至 51938byte，也就是原始 JPEG檔案的 0.073倍。這個比例與 Geisler在
文獻中宣稱的壓縮比例相當接近[11]。 
 
圖五 未經過 FMP的原始圖片，file size：711,897 byte 
 
圖六 經過 FMP後產生的 bitmap file, file size：2,359,350byte 
在壓縮速度方面，我們使用 Intel Core 2 Duo 2.4GHz等級 CPU 連續四次壓縮範例圖片
的所需時間如下表。除了初始化所需時間較長外，第二張以後的壓縮時間也在 5.6~5.8秒之
7 
 
圖七 Eye Tracking功能流程圖 
      
(a)                       (b) 
圖八 Harr 特徵: (a)Edge Feature與 (b) Line Features 
由於操作限制在臉部不移動及轉動的情況下，因此針對頭部轉動的部分做偵測。當使
用者轉動時，能適時的發出警告。主要的概念是透過偵測兩眼與嘴巴之間所構成三角形的
底部與高的比例關係。當使用者正面面對螢幕操作時，所構成的三角形應為等腰三角形，
伴隨使用者的頭部轉動，三角形也會隨著產生改變。如圖九所示，使用者的頭部向右轉動，
則三角形以高為分割形成右邊的底，則逐漸增長，當超過固定門檻值時，則可判定使用者
頭部轉動，並發出警告告知使用者。 
 
利用Webcam擷取使用者影像作處理 TrackEye 
人臉偵測 
Harr Face Detection CamShift Algorithm 
人眼偵測 
Template Matching Adaptive PCA 
瞳孔偵測 
Circle Detection  
使用者選擇功能並作參數設定 
開始 Eye Tracking 
選擇慣用眼 
輸入注視上下左右四角等 
瞳孔座標，做為判別基準 
TrackEye 
本計畫 
將瞳孔座標轉換為注視螢幕的區塊代號 
透過 TCP/IP傳送給 Server端做處理 
標示人臉、眼睛與瞳孔在輸出影像上 
本計畫 
9 
道以及一個收取使用者指令的通道，並進行擷取圖片、裁切圖片、呼叫 MatLab 進行 FMP
壓縮。用戶端部分我們用 C#/.Net Framework實作，包含顯示收到影像的視窗以及對伺服器
送出指令。而在 Client/Server間的溝通，我們使用 TCP實作了簡單的指令碼。計畫開始時，
我們首先參照 RFC2435[19]嘗試使用 RTP 來作為傳送 JPEG 的封包格式，但實作後發現其
效能並不理想，且封包遺失率過高。由於現今以 RTP 傳輸 JPEG沒有一個實作較為完整的
方案，又在有限的時間內，所以我們改為直接使用單純的 TCP 來實作。 
在擷取圖片的部分，我們透過 Ladybug2 所提供的 API進行。Ladybug2包含一組 JPEG
壓縮晶片，可透過原廠的 API將六個 CCD 所擷取之影像拼接成一半球面之全景圖片，並可
壓縮成 4096*2048 pixel的 JPEG 格式。另外 Ladybug2有許多參數可供調校，可以搭配頻寬
或是圖片的需求調整圖片的品質以及大小。考慮到頻寬強烈影像的流暢，且本實驗假設使
用者並沒有看到整體的全景圖需求，而是某一區塊的視野，我們將過大的全景圖片裁剪成
適當的大小。實驗中我們將 4096*2048 pixel的 JPEG 格式裁剪成 1024*768 pixel與 800*600 
pixel 作為測試。因為透過 API擷取之全景圖為半球面，將 3D 的全景影像對應到 2D 的影
像，當視角變高或是鏡頭接合處的影像，會有扭曲失真的情形，此處我們使用 OpenGL 技
術，試圖將扭曲的圖片，針對其各個區塊不同的扭曲情形，將其再次扭曲變形，希望能達
到較為接近一般視覺的體驗。此實驗中我們嘗試了用兩種方法實作：將 JPEG 格式的圖片
轉成 glTexture成為可用的材質後貼上不同弧度的弧面或是不同形狀的平面。 
五、 結果與討論 
根據本計畫預定執行的進度，在第一年度我們的目標放在雛型系統之建置，包含以下
三個部份：(1)實作 FMP 壓縮軟體、(2)建構廣視角即時視訊系統、(3)操作端使用者介面。
在本年度中，我們順利的完成各部份的建置，也達成了預期的進度，而遭遇到了相對應的
問題原本是預計在第二年度完成，如果時間充裕的話，相信我們可以在第二年度將整個系
統完成，並且測試多解析影像運用於遠程操作系統時，其操作的正確性與效率。 
在實作 FMP 壓縮軟體的部份，我們已經成功的將美國德州大學發展出的 FMP 壓縮技
術運用在本計畫中的 Encoder端。並且撰寫了一個 Bitmap file程式，用來將轉換過的 Bitmap 
file壓縮成 JPEG 格式，以降低檔案大小。 
在建構廣視角即時視訊系統的部份，原本預計使用自行研發之廣視野攝影系統，不過
為了提高本系統的可用度，我們改採用 Ladybug2，並且成功地將 Ladybug2截取的到影像
透過 TCP 傳送到 Client端。 
在操作端使用者介面的部份，原本預計使用滑鼠及利用觸碰式螢幕兩種方式在畫面上
直接指定的互動介面，不過考量到在遠程操作系統之中，滑鼠和觸碰式螢幕會用於控制其
它的設備，例如 PTZ 攝影機的操作或是遙控自走機器人系統。所以，注視區域(AOI, Area of 
Interest)的定位，我們改採用 Eye tracking技術，將眼鏡所注視的的位置回傳。這樣就可以
在不影響使用者操作的情況下，順利的完成動態指定 AOI的動作。 
11 
Computer, Graphics and Image Processing, vol. 14, pp. 365-372, 1980. 
[8] E. Schwartz, Anatomical and Physiological Correlates of Visual Computation from Striate to 
Infero-Temporal Cortex, IEEE Transaction on Systems, Man, and Cybernetics, vol. SMC-14, 
no. 2, pp. 257-271, 1984. 
[9] A. Bernardino, and J. Santos-Victor, Binocular Visual Tracking: Integration of Perception 
and Control, IEEE Transactions on Robotics and Automation, 1999. 
[10] G. Sandini, P. Questa, D.Scheffer, B, Dierickx, and A. Mannucci, A retina-like CMOS sensor 
and its applications, in Proceedings of the 1st IEEE SAM Workshop, 2000. 
[11] P. Kortum and W. Geisler, Implementation of a foveated image coding system for image 
bandwidth reduction, in Proceedings of SPIE, vol. 2657, pp. 350-360, 1996. 
[12] W. S. Geisler and J. S. Perry, A real-time foveated multiresolution system for low-bandwidth 
video communication, Human Vision and Electronic Imaging, SPIE Proceeding, vol. 3299, 
pp. 294-305, 1998. 
[13] W. S. Geisler and J. S. Perry, Variable-resolution displays for visual communication and 
simulation, The Society for Information Display 30, pp. 420-423, 1999. 
[14] W. S. Geisler and J. S. Perry, Real-time simulation of arbitrary visual fields, ACM 
Symposium on Eye Tracking Research &Applications, 2002. 
[15] http://fi.cvis.psy.utexas.edu/index.shtml 
[16] http://freeimage.sourceforge.net/ 
[17] http://www.codeproject.com/KB/cpp/TrackEye.aspx 
[18] http://www.ptgrey.com/products/ladybug2/index.asp 
[19] http://www.faqs.org/rfcs/rfc2435.html 
 
W
ed
n
es
da
y 
D
ec
em
be
r 
10
,
 
20
08
 
08:45-09:15 Conference Opening [B111] 
09:15-10:15 WI/IAT Invited Talk [B111] Chair: Chengqi Zhang 
Planning for Coordination and Coordination for Planning by Edmund H. Durfee 
10:15-10:45 Tea/Coffee Break [Lobby, Block B, Building 5, Haymarket Campus, UTS] 
10:45 
- 
12:45 
Session 
10-A-WI-1 
[B111] 
Web Mining and 
Farming 
Chair: Dietrich 
Albert 
Session 
10-A-WI-2 
[B112] 
Semantics and 
Ontology 
Engineering 
Chair: Krzysztof 
Juszczyszyn 
Session 
10-A-WI-3 
[B113] 
Web Information 
Filtering and 
Retrieval 
Chair: Ngoc 
Thanh 
Nguyen 
Session 
10-A-WI-4 
[C.1.19] 
Social Networks 
and 
Social Intelligence 
Chair: James 
Caverlee 
Session 
10-A-IAT-5 
[C.1.20] 
Autonomy-Oriente
d 
Computing (AOC) 
Chair: Shih-Fen 
Cheng 
Session 
10-A-IAT-6 
[C.1.21] 
Agent Systems 
Modeling and 
Methodology 
Chair: Yuri 
Tijerino 
12:45-14:00 Lunch [China Grant Restaurant, Level 3, Market City, China Town] 
14:00-14:45 WI/IAT Invited Talk [B111] Chair: Longbing Cao 
Knowledge Based Search Engine: Granular Computing on the Web by Tsau Young Lin 
14:45-15:30 WIC Feature Talk [B111] Chair: Matthias Klusch 
Autonomy-Oriented Computing for Web Intelligence and Brain Informatics Jiming Liu 
15:30-16:00 Tea/Coffee Break [Lobby, Block B, Building 5, Haymarket Campus, UTS] 
16:00 
- 
18:00 
Session 
10-B-WI-1 
[B111] 
Web Mining and 
Farming 
Chair: Orland 
Hoeber 
Session 
10-B-WI-2 
[B112] 
Semantics and 
Ontology 
Engineering 
Chair: Francesco 
Amigoni 
Session 
10-B-WI-3 
[B113] 
Web Information 
Filtering and 
Retrieval 
Chair: Klemens 
Böhm 
Session 
10-B-WI-4 
[C.1.19] 
Social Networks 
and 
Social Intelligence 
Chair: Makoto 
Yokoo 
Session 
10-B-IAT-5 
[C.1.20] 
Autonomy-Oriente
d 
Computing (AOC) 
Chair: Alessandro 
Cucchiarelli 
Session 
10-B-IAT-6 
[C.1.21] 
Agent Systems 
Modeling and 
Methodology 
Chair: Virginia 
Dignum 
18:00-20:00 Reception [Lobby, Block C, Building 5, Haymarket Campus, UTS] 
Th
u
rs
da
y 
D
ec
em
be
r 
11
,
 
20
08
 
09:00-10:00 WI/IAT Invited Talk [B111] Chair: Boi Falting 
The Emergence of Web Science by Nigel Shadbolt 
10:00-10:30 Tea/Coffee Break [Lobby, Block B, Building 5, Haymarket Campus, UTS] 
10:30 
- 
12:30 
Session 
11-A-WI-1 
[B111] 
Web Mining and 
Farming 
Chair: Pericles 
A.Mitkas 
Session 
11-A-WI-2 
[B112] 
Semantics and 
Ontology 
Engineering 
Chair: Madhu 
Goyal 
Session 
11-A-WI-3 
[B113] 
Web Information 
Filtering and 
Retrieval 
Chair: Xiaocong 
Fan 
Session 
11-A-WI-4 
[C.1.19] 
Social Networks 
and 
Social Intelligence 
Chair: Jing He 
Session 
11-A-IAT-5 
[C.1.20] 
Autonomous 
Knowledge and 
Information 
Agents 
Chair: Zili Zhang 
Session 
11-A-IAT-6 
[C.1.21] 
Agent Systems 
Modeling and 
Methodology 
Chair: Boi 
Faltings 
12:30-14:00 Lunch [China Grant Restaurant, Level 3, Market City, China Town] 
14:00-15:00 WI/IAT Invited Talk [B111] Chair: Nigel Shadbolt 
The Language Grid: Service-Oriented Collective Intelligence for Intercultural Collaboration by Toru Ishida 
15:00-15:30 Tea/Coffee Break [Lobby, Block B, Building 5, Haymarket Campus, UTS] 
15:30 
- 
17:30 
Session 
11-B-WI-1 
[B111] 
Web Mining and 
Farming 
Chair: Yuefeng Li 
Session 
11-B-WI-2 
[B112] 
WI Foundations & 
World Wide 
Wisdom 
Web 
Chair: Huaifeng 
Zhang 
Session 
11-B-WI-3 
[B113] 
Web Information 
Filtering and 
Retrieval 
Chair: Richi 
Nayak 
 
Session 
11-B-WI-4 
[C.1.19] 
Intelligent 
e-Technology and 
Applications 
Chair: Ngoc 
Thanh 
Nguyen 
Session 
11-B-IAT-5 
[C.1.20] 
Distributed 
Problem 
Solving 
Chair: 
Mark 
Hoogendoorn 
Session 
11-B-IAT-6 
[C.1.21] 
Agent Systems 
Modeling and 
Methodology 
Chair: Frank 
Dignum 
18:30-22:00 Banquet/Award Ceremony [Showboat Cruise Dinner, King Street Wharf #5, Darling Harbour] 
Fr
id
ay
 
D
ec
em
be
r 
12
,
 
20
08
 
09:00-9:45 WI/IAT Invited Talk [B111] Chair: Jie Lu 
Using Web Clustering for Web Community Mining and Analysis by Yanchun Zhang 
9:45-10:30 WI/IAT Invited Talk [B111] Chair: Lakhmi Jain 
Thinking Big - AI at Web Scale by Michael Witbrock 
10:30-11:00 Tea/Coffee Break [Lobby, Block B, Building 5, Haymarket Campus, UTS] 
11:00 
- 
12:30 
Session 
12-A-WI-1 
[B111] 
Web Mining and 
Farming 
Chair: Bogdan 
Gabrys 
Session 
12-A-WI-2 
[B112] 
Web Agents & 
Web 
Services 
Chair: Ajith 
Abraham 
Session 
12-A-WI-3 
[B113] 
Intelligent 
Human-Web 
Interaction 
Chair: Helen Lu 
Session 
12-A-IAT-4 
[C.1.19] 
Autonomous 
Auctions 
and Negotiation 
Chair: Chayapol 
Moemeng 
Session 
12-A-IAT-5 
[C.1.20] 
MAS Applications 
Chair: Vladimir 
Gorodetsky 
 
12:30-14:00 Lunch [China Grant Restaurant, Level 3, Market City, China Town] 
14:00 
- 
15:30 
Session 
12-B-WI-1 
[B111] 
Web Mining and 
Farming 
Chair: Peter 
Herrmann 
Session 
12-B-WI-2 
[B112] 
Web Support 
Services 
Chair: Gabriella 
Pasi 
Session 
12-B-WI-3 
[B113] 
Intelligent 
E-Technology 
Chair: Yanchang 
Zhao 
 
Session 
12-B-IAT-4 
[C.1.19] 
MAS Applications 
Chair: Hien 
Nguyen 
  
Session 
12-B-IAT-5 
[C.1.20] 
Others 
Chair: Marcin 
Szczuka 
 
15:30-16:00 Tea/Coffee Break [Lobby, Block B, Building 5, Haymarket Campus, UTS] 
2. 與會心得 
 圖一、 Stakeholders of the Language Grid 
 
III. Recognizing and Filtering Web Images based on People’s Existence (Ou Wu, Haiqiang Zuo, 
Weiming Hu, Mingliang Zhu and Shuxiao Li)： 
在網路上如何辨識徒刑一直是很熱門的議題。圖形辨識的技術若能應用在網路上，便能
有效阻絕一些色情網站，甚至能夠作為判斷是否為垃圾郵件的技術。報告者此次前往報
告的題目便與垃圾郵件有很大的相關性，因此對於這篇這篇報告也十分感興趣。 
這篇報告的作者主要是希望能在網路上判斷出圖片中是否含有”人”，利用進一步的判斷，
來決定出這張圖片是否為色情圖片。而其判斷方式主要分為三個不同的機制，當截取到
一張圖片時，先利用影像處理的技術來決定圖片中的資訊，並利用 OCR的概念來擷取圖
片中所出現的文字以及圖片的標題，整合這三項資訊，最後算出一個整體的分數，來決
定此張圖片是否為色情圖片。下面圖二為整個判斷處理的流程： 
 
圖二、 圖片判斷流程 
圖二說明了作者如何處理一張圖片的資訊，利用圖片可以提供的三種不同的資訊：image, 
text, title，來決定圖片的總分。而最後再利用雙層過濾的概念來決定此張圖片是否為色情
圖片。作者在報告中提出了色情圖片都將會含有”人”的假設作為前提，因此在第一層的
過濾中便判斷圖片中含有”人”的機率，利用影像處理的技術抓出膚色的部位，並透過公
式來決定圖片中人體的動作做為第一層的判斷。下圖三便是其過濾的流程。 
報告人在參加這個 section 聆聽此報告時，也提出了下面的問題：”當在判斷圖片的過程
中，為了要達到更精準的效果，勢必需要龐大的 data set 來做依據，而作者是如何決定
image, text, title這三項資訊的權重，進而求出整體的分數？”。然而因為報告者並非原作
者的其中一(代為報告)，因此並沒有得到詳細的解答。 
1. 報告內容摘要： 
一般的垃圾郵件過濾器追求杜絕惱人的垃圾郵件的同時，也使得使用者的正常郵件
被誤判為垃圾郵件可能性上升，這是因為每位使用者所認定的正常郵件皆不相同，
並沒有一套泛用規則能夠適用於所有的使用者。一些垃圾郵件過濾器提供使用者自
訂規則以及訓練的方式對於使用者也實屬不便。為此，我們提出一個雙層的垃圾郵
件過濾方法，在傳統的單層垃圾郵件過濾架構中植入一個正常郵件過濾器，此過濾
器能夠依據使用者收件匣的內容迅速、自動地建立與更新正常郵件規則，將符合使
用者喜好的來信安全地交付到使用者的信箱，達到降低垃圾郵件過濾器誤判率之效
果。在建立郵件規則的部分，我們引進一種常見於資料探勘與資料檢索的 TF-IDF
加權方法來評估字詞在文件中的重要性。我們將此雙層過濾方法設置在郵件伺服器
端，並另外設置一個裝載單層垃圾郵件過濾之郵件伺服器作為對照組，比較兩者的
過濾情形，實驗顯示雙層式郵件過濾方法可大幅降低正常郵件被誤判的機率。 
 
圖五、 雙層式郵件過濾系統架構 
 
2. 報告情形： 
當天報告在台下聽中約有 20 人左右，因報告人的論文被選為 regular paper，固有
20分鐘的報告時間。而當天報告人用了 15分鐘左右的時間做完報告，剩餘的時間
則留給台下的聽眾提問並作回答。下面也就當天報告所遇到的兩個提問者作敘述： 
問 1：為何實驗結果顯示出來的 false negative rate會相同？ 
答 1：實際上兩組實驗結果的的 false negative rate並沒有相同，只是相當接近。在
實驗結果中，我們也發現使用我們雙層過濾系統會提升少量的 false negative rate，
但這是我們所預期的。因為我們的系統目的之一就是希望能夠保留那些使用者感興
趣的垃圾郵件，而我們的系統也達到了這樣的目的。 
 
問 2：在此系統中，為何會將正常郵件過濾器放置前端坐第一層的郵件過濾？ 
答 2：我們系統最大的目的就是在於”減少系統對正常郵件的誤判”，因此我們利用
雙層式的架構，當收到一封郵件時，系統可以在垃圾郵件過濾器過濾郵件之前先判
斷這封郵件對使用者來說是否含有其感興趣的內容，或是其內容與使用者的信箱的
信件有相似的內文，來將郵件先行救出，避免交給垃圾郵件過濾器造成誤判。我們
相信使用這樣的架構，將能有效降低 false positive rate，這也是為何我們將正常郵
件過濾器會先放在前端的原因。 
  
Incoming 
Mail
Legitimate Mail 
Filter (LMF)
Spam Mail Filter 
(SMF)
Junk Mail 
Box
User’s 
Inbox
Suspected mail
Legitimate mail
Spam mail
Not spam
Two-tier Spam Mail Filter
  拍攝日期：2008/12/09 
 拍攝地點：雪梨科技大學大型會議廳 
 照片說明：此照片拍攝於這次會議的大型會議室，也是 invited 
talk所舉行的場所。照片中可以看到兩個大型的投影布幕，而
所聆聽的演說為 Tsau Young Lin教授的 Granular Computing on 
the Web。 
 
 
and later Support Vector Machine (SVM) [8] [9] and 
Nearest Neighbor (NN) classifiers became popular on 
mail filtering tasks. Compared with rule-based 
approach, content-based approach alleviates the burden 
of human by analyzing and maintaining the rule set 
automatically; that is, to continuously learn from the 
incoming mails to maintain an “implicit rule set”. 
When implemented in user site, content-based 
approach may have more accurate and personalize 
filtering result by training through both spam and 
personal legitimate mails [9] [10]. In fact, without 
training legitimate mails from user’s inbox, the 
performance of a spam filter may decrease drastically 
[11]. However, machine learning skills also require 
constant user's feedbacks to prevent misclassifications. 
Theoretically, a user gives feedback by labeling 
misclassified mails. With well designed user interface, 
labeling a mail may be as easy as deleting one. 
However, users need to go through all filtered mails to 
check if there is any misclassified one. Therefore 
getting rid of this time consuming task is exactly what 
we need spam filters for! 
Since almost all spam filters are implemented as a 
binary classifier over one threshold, a practical solution 
to this problem is to increase the threshold such that 
misclassified legitimate mail doesn’t exist, i.e. the false 
positive (FP) rate approaches zero. The drawback of 
this method is obviously: the number of passed spam 
will inevitably increase if we loosen the restrictions of 
filter by increasing the threshold. In fact, this is the 
dilemma of all spam filters: if we raise the threshold, 
the false negative (FN) rate will increase. On the 
contrary, decreasing the threshold will improve the 
sensitivity of a spam filter, and more spam are detected 
and blocked, but the result will be a higher FP rate. 
To resolve this problem, we propose a two-tier 
filtering structure to adjust the distribution of FP rate 
and FN rate such that low FP rate may be reached 
without drastic increase of FN rate. 
 
2. The Two-tier Spam Filter Structure 
 
Current spam filter systems usually apply the most 
popular approach to employ multiple filters and to 
calculate the total score as a weighted sum [2] [11] 
[12]. This kind of systems usually shows high accuracy 
and comfortable precision. However, from the end 
user’s point of view, the labeling effort can be reduced 
only when the FN rate becomes low enough to be 
ignored. Therefore, the proposed two-tier filter 
structure gives emphasis on eliminating misclassified 
legitimate mail rather than the influence of accuracy 
and FP rate. Figure 1 shows the structure and the 
filtering process of the two-tier spam filter. 
The first stage of spam filtering is a filter called 
legitimate mail filter (LMF). The only purpose of LMF 
is to report a score which indicates the possibility of a 
legitimate incoming mail message. LMF is trained only 
by the legitimate mails inside the user’s inbox. One of 
the reasons that personal mails preferred to be 
separately trained is that the features of personal mails, 
comparing to spam, tends to keep consistent. On the 
contrary, spammers always try new skills to avoid 
spam filter, so the features of spam may vary from 
time to time. Therefore, the LMF alone is expected to 
generate stable output with high accuracy after short 
learning period. Another reason is that every user has 
different definition to legitimate mails. For example, 
some advertisement mails regarded as spam by some 
users might be considered as useful emails by the 
others. When a spam-like mail has the information user 
may be interested in, ordinary spam filters have a 
bigger chance to block this mail, whereas the LMF in 
our two-tier structure will let this mail pass through.  
The second stage is an ordinary spam mail filter 
(SMF) trained without personal mails. The purpose of 
SMF is the same with any other spam filters: to 
classify the incoming mail as spam or legitimate mails. 
In Figure 1, the LMF looks like in cooperation with 
SMF; however, LMF is designed to work 
independently. To filtering an incoming mail, LMF 
first decide the similarity of the incoming mail with a 
legitimate mail database, and then place the mail into 
the user’s inbox if it is classified as legitimate mail. 
Otherwise, the incoming mail will be regarded as 
suspect mail and being filtered by SMF. That is, SMF 
will examine the suspect mail to decide whether it is a 
spam or not. 
In the two-tier filtering structure, e-mails are 
classified as legitimate mails by LMF if the mail 
contains the information user may be interested in, and 
Incoming 
Mail
Legitimate Mail 
Filter (LMF)
Spam Mail Filter 
(SMF)
Junk Mail 
Box
User’s 
Inbox
Suspected mail
Legitimate mail
Spam mail
Not spam
Two-tier Spam Mail Filter
Figure 1. The structure of two-tier mail filter. 
 In order to show that the length of the words will 
influence the significance of word, we allow the 
original TF-IDF formula to multiply by a value, and we 
define this value as the square of the word’s length; i.e., 
(length(j))2. In this way, longer words receive higher 
weights. 
Cosine similarity [18] [19] is another technique 
often used to compare documents in text mining. It is a 
measure of similarity between two vectors of n 
dimensions by finding the angle between them, and we 
apply cosine similarity technique in the fifth stage. By 
using the selected words, we create a vector space and 
map each mail into a vector in this space. The number 
of the vector space dimension is very important. If the 
number of dimension is too large, the mapped vector 
may contain too many words which are unimportant, 
and it will also waste computer memory space and 
computing time. On the other hand, if the dimension is 
too small, it will be hard to completely represent the 
characteristics of a mail by its vector. Thus, the number 
of dimension must be flexible according to the number 
of mails in user’s inbox. Equation 3 shows how to 
define the dimension of the vector space. 
 
⎪⎪⎩
⎪⎪⎨
⎧
>⎥⎥⎦
⎥
⎢⎢⎣
⎢
≤
=
;10||,
log
10*||
;10||,100
_
dif
d
d
dif
DimensionMax
  
 (3) 
 
where |d| is the number of mails in user’s inbox, and 
Max_Dimension is the dimension of the vector space 
we finally decide. 
Let k=Max_Dimension and choose k words with 
higher weight, and then mail i can be expressed in a 
vector vi, where vi = (Wi1, Wi2,…Wij,…Wik), and Wij is 
the jth word in the ith mail. All mails in user’s inbox will 
be transformed to vector format to build the legitimate 
database. 
 
3.2. Filtering Legitimate Mails 
 
Figure 3 shows the flowchart of filtering new 
incoming mail in LMF. To filter a new incoming mail, 
LMF at first transform the mail into a vector using the 
same method as described above. After then, we use the 
cosine similarity technique and white-list database to 
operate in coordination and compute the total score, 
which indicates the possibility of this incoming mail 
being legitimate. Equation 4 shows how we calculate 
the score of every incoming mail. 
 
Create the vector of 
the incoming mail
Examine the 
similarity with mails 
in vector database
Parse mail and get 
the sender’s address
New incoming 
mail
Is the score 
higher than 
threshold?
Legitimate 
Mail
Suspected 
Mail
Vector Database of 
Legitimate Mails
Compute the score 
of the new incoming 
mail
Yes No
Put this mail in 
user’s inbox
processed by the 
spam filter in an 
ordinary way
Figure 3. Flowchart of Legitimate Mail Filter on 
filtering new incoming mails. 
 
⎟⎠
⎞⎜⎝
⎛
+=
3
*10*)),(( TumWhiteListNvucsMAXScore i    (4) 
 
where u is the vector of new incoming mail, and vi is 
the vector of the ith mail we stores in legitimate mail 
database we created in training stage. Using cosine 
similarity technique, we can examine the similarity of 
vector u and vector vi. MAX(cs(u,vi)) means the 
maximum similarity between the new incoming mail 
and all legitimate mails in user’s inbox. WhiteListNum 
is the number of times sender of this new incoming 
mail appears in white-list database, and T is the 
threshold we set. Equation 5 shows the formula of 
cosine similarity: 
 
i
i
i vu
vuvucs ⋅=),(      (5) 
 
To normalize u·vi, we divides it by the Euclidean 
distance between u and vi; i.e., u·vi/(|u||vi|). This ratio 
defines the cosine angle between the vectors, with 
values between 0 and 1. We use cosine similarity 
formula to compute the similarity numbers between 
new incoming mail and each mail in user’s inbox. 
New incoming mail will be given its own score by 
LMF, the score will decide whether the mail belongs to 
5. Conclusion 
 
 
Figure 5. The Impact of the two-tier structure 
on FP rate and FN rate. 
 
In this paper we argue that personalized content-
based spam filters should be divided into two parts: a 
legitimate mail filter and a spam mail filter. The 
proposed two-tier filtering structure puts more weight 
on reducing the number of misclassified legitimate 
mails, and the two thresholds of this structure brings 
higher flexibility on adjusting the values of FP rate and 
FN rate couple. To implement a legitimate mail filter 
for Chinese mail, we modified TF-IDF algorithm and 
implemented an SVM-based filter. Combined LMF 
and SpamAssasin, we performed experiments to 
measure the distributions of FP rate and FN rate. Early 
results show that compared with ordinary spam filter, 
our two-tier structure reaches much lower FN rate with 
slight increase to FP rate observed. 
The future research will include more experiments 
on various combinations of the threshold couples, and 
to derive the equations for threshold mapping.  
 
6. Acknowledgment 
 
This work is supported in part by the Taiwan 
Information Security Center (TWISC) under the 
National Science Council Grants No. NSC96-2219-E-
011-008. 
 
7. References 
 
[1] Messaging Anti-Abuse Working Group, MAAWG 
Email Metrics Program, First Quarter 2006 Report. 
June 2006. Available:  
http://www.maawg.org/about/FINAL_1Q2006_Metrics
_Report.pdf. 
[2] The Apache SpamAssassin Project [Online]. Available: 
http://spamassassin.apache.org/ 
[3] J. Clark, I. Koprinska and J. Poon, “LINGER - A Smart 
Personal Assistant for E-mail Classification,” in Proc. 
of the 13th Int. Conf. on Artificial Neural Networks 
(ICANN'03), 2003, pp. 274-277. 
[4] M. Sahami, S. Dumais, D. Heckerman, and E. Horvitz, 
“A Bayesian Approach to Filtering Junk E-mail,” AAAI 
TABLE 1. False negative rate under  three different system configurations 
Thresholds of 
SpamAssassin 1 2 3 4 5 6 7 8 9 
SpamAssassin only 0.87% 1.18% 2.43% 3.68% 4.56% 7.06% 8.56% 11.75% 13.87%
SpamAssassin with 
LMF, threshold = 8 1.7% 2.05% 3.4% 4.65% 5.15% 7.35% 9.45% 12.85% 14.6% 
SpamAssassin with 
LMF, threshold = 9 1.0% 1.35% 2.75% 3.75% 4.55% 6.9% 8.9% 12.05% 14.0% 
 
TABLE 2. False positive rate  under  three different system configurations 
Thresholds of 
SpamAssassin 1 2 3 4 5 6 7 8 9 
SpamAssassin only 68.12% 45.70% 30.37% 13.37% 8.25% 6.12% 4% 3.75% 1.87% 
SpamAssassin with 
LMF, threshold = 8 12.5% 9% 5.8% 3.5% 2.9% 2.4% 1.6% 1.4% 1% 
SpamAssassin with 
LMF, threshold = 9 13.1% 9% 6.0% 3.6% 2.9% 2.4% 1.6% 1.4% 1% 
          
