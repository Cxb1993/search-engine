2to develop GRNs hierarchically. To verify the
presented approach, three series of experiments have
been conducted to demonstrate how it works.
2. Methodology
The behavior expressions of a GRN are in fact
coordinated patterns of activities in time and space.
Hence, GRNs can be regarded as dynamical systems
that are perturbed by their interaction with the
environment. RNNs are appropriate choices working
as GRNs, because they have been shown to operate
as dynamical systems that do not explicitly perform
input-output mappings as other computational
mechanisms. RNNs have recurrent connections that
provide the possibility of generating oscillatory and
periodic activities. The complex activities can be
coordinated in the time domain, and the network
behaviors can be governed by a set of differential
equations.
There are several recurrent neural network
architectures, ranging from restricted classes of
feedback to full interconnection between nodes.
Vohradsky and colleagues have proposed the use of
fully recurrent neural network architecture in
studying GRNs such as those involved in the
transcriptional and translational control of gene
expression. In this work, we also take the same
architecture to model GRNs but unlike their work
that mainly simulates regulatory effects, our goal is
to establish an approach to reconstruct regulatory
networks from expression data measured.
In a fully recurrent net, each node has a link to
any node of the net including itself. Using such a
model to represent a gene regulatory network is
based on the assumption that the regulatory effect
on the expression of a particular gene can be
expressed as a neural network in which each node
represents a particular gene and the wiring between
the nodes define regulatory interactions. In a gene
regulatory network, the level of expression of genes
at time t can be measured from a gene node, and the
output of a node at time t+Δt can be derived from
the expression levels and connection weights of all
genes connected to the given gene at the time t. That
is, the regulatory effect to a certain gene can be
regarded as a weighted sum of all other genes that
regulate this gene. Then the regulatory effect is
transformed by a sigmoidal transfer function into a
value between 0 and 1 for normalization.
The same set of the above transformation rules
is applied to the system output in a cyclic fashion
until the input does not change any further. As in
work, here we use the basic ingredient to increase
the power of empirical correlations in signaling
constitutive regulatory circuits. It is to generate a
network with nodes and edges corresponding to the
level of gene expression measured in microarray
experiments, and to derive correlation coefficients
between genes.
After the network model is decided, the next
phase is to find settings of the thresholds and time
constants for each neuron, and the weights of the
connections between the neurons so that the network
can produce the most approximate system behavior
(i.e., the measured expression data). By introducing
a scoring function for network performance
evaluation, the above task can be regarded as a
parameter estimation problem with the goal of
maximizing the network performance (or
minimizing an equivalent error measure). To
achieve this goal, here we use the backpropagation
through time (BPTT) learning algorithm to update
the relevant parameters of recurrent networks in
discrete-time steps.
Instead of mapping a static input to a static
output as in a feedforward network, BPTT maps a
series of inputs to a series of outputs. The central
idea is the “unfolding”of the discrete-time recurrent
neural network (DTRNN) into a multilayer
feedforward neural network when a sequence is
processed. Once a DTRNN has been transformed
into an equivalent feedforward network, the
resulting feedforward network can then be trained
using the standard backpropagation algorithm.
As can be expected, when the number of genes
in a regulatory network and the interactions between
the genes increase in respect to the increasing
functional complexity the network has to deal with,
the direct modeling for a network becomes more and
more difficult to achieve. To scale up our approach
to solve more complicated reconstruction task, we
take an engineering point of view to tackle the
problem in a“divide and conquer”way. A clustering
technique is firstly employed to group the genes into
some small-scale networks, based on the analysis of
their corresponding expression data, and then the
small networks are reconstructed from the
expression data by the RNN-based approach
described in the above sections. Once all the small
networks have been obtained, each of them is
regarded as a self-contained system component of
the original network, and the learning algorithm
indicated previously is used to determine the
interactions between different system components.
The small networks can be decomposed again in the
similar way until the resulting networks can be
directly modeled.
In our current work, the self-organization
feature map (SOM) method is adopted for gene
clustering. Before a clustering method is applied to
the expression data, some features on the data set
have to be decided so that the clustering method can
40
0.2
0.4
0.6
0.8
1 5 9 13 17 21 25 29
G1 G2 G3 G4 G5
G6 G7 G8 G9 G10
(a)
0
0.2
0.4
0.6
0.8
1 5 9 13 17 21 25 29
G1 G2 G3 G4 G5
G6 G7 G8 G9 G10
(b)
Figure 1: System behaviors of the target (a) and
rebuilt (b) networks.
