一、中文摘要 
近日生物認證於安全維護方面被逐漸廣泛應用。尤其，以人臉為特徵而進行辨識，在
生物認證領域裡，於911恐怖行動後更成為該領域之主要研究問題之一。綜觀過去相關臉部
辨識之研究，多以單獨之2D或3D臉辨識為主，對於結合2D與3D臉部資訊研究極少。本計
畫為前ㄧ期國科會計畫(NSC 96-2221-E-324 -005)之第二期計畫，其主要目的為對前期所建
構一套之2D+3D人臉資訊以期增進系統之辨識能力；本研究為改善前期人臉對應之效率，
將使用霍普菲爾神經網路雙影像對應法(Hopfield neural network-based stereo matching)取得
3D人臉之深度資訊(Disparity)，結合原有2D人臉資訊，再運用資訊融合完成人臉辨視。本
計畫於特徵擷取方法上，採主成份分析(Principal Component Analysis, PCA)及區域自相關係
數(Local Autocorrelation Coefficient, LAC)等兩種特徵擷取方法，以改善人臉對於取像時位移
改變之影響，並將此兩種特徵擷取資訊進行整合。於分類方法上，採用最短歐氏距離法
(Minimum Euclidean Distance)及倒傳遞類神經網路(Back-Propagation Neural Network, BP)做
比較。 
本計畫將對一百五十位受測者進行取像，每位受測者均取十三種不同之表情影像，分
別作為訓練影像及測試影像，並將以 Borldand C++ Builder 之平台介面上實際建立此人臉辨
識系統，藉以評估實際之效用，且將對支持向量基之辨識結果與最短歐氏距離法及倒傳遞
類神經網路相比較，並做深入之探討。本計畫利用二維影像之資訊加上三維影像之深度資
訊，以期突破僅採用二維影像之平面資訊於辨識之瓶頸，進而獲得更佳之辨識能力。本計
畫之主要成果，除建立臉部辨識系統之外，並已將研究成果投稿且接受於 Expert Systems 
with Applications。 
 
關鍵字: 主成份分析法、區域自相關係數、臉部辨識、雙影像對應系統、BPN 
三 報告內容 
1 研究背景 
隨著網際網路應用及電子化交易日漸普，安全可靠之身分認證成為過去五年來重要之
議題；過去，使用者可能因記取過多組密碼，而導致錯誤發生外，密碼認證更有可能被盜
用或入侵之可能。然而，近來由於電腦速度及容量提升，利用個人獨特生物特徵，如人臉
(Face)、指紋(Fingerprint)、聲紋與虹膜(Iris)辨識等，已成為可行之「生理密碼」；因其具
有難以複製或遭竊之特性，故更可有效解決安全認證問題。 
生物認證(Biometrics)主要是針對人類獨有之生理特徵或行為表現進行辨識，其中以指
紋辨識之發展與應用最早。除指紋外，自 1990 年代以來，生物認證技術更發展到掌紋(Palm 
Prints)、人臉、虹膜及聲紋(Voiceprint)辨識等。將其生物特徵分為「生理特徵」與「行為特
徵」兩大類，如下： 
■ 生理特徵：使用於需要嚴格確認身份之情況，直接擷取人類之生理特徵之方式來辨識身
份。例如，指紋辨識、掌紋辨識、人臉辨識、虹膜辨識。 
■ 行為特徵：使用於較高便利性情況，是擷取人類行為表現之差異來辨識身份。例如：聲
紋辨識等。 
目前最廣泛應用於身份識別或驗證之依據為指紋或虹膜等生物特徵。虹膜具有極高唯
一性，但辨識設備價格高，且辨識時，眼睛需經掃描比對，造成受測者眼睛之不舒適。指
紋辨識為發展最久之身分辨識技術，透過指紋比對認證僅需一台讀取指紋之機器，但若受
測者有「手汗症(Hyperhidrosis)」或汗腺(Sweat Gland)特別發達之問題時，則將影響其辨識
效能。聲紋辨識則由於聲音較易進行偽造，且易受年齡、情緒、環境因素（如環境噪音）
等影響，另外，聲音辨識須建立完整之聲音及語調資料，以建立完整個人聲音資料，故須
使用較多時間。由於人臉辨識屬於非接觸式之機制，且為即時性，辨識目標無須刻意配合
辨識系統之動作要求，即可達成辨識之目的，故近年來被廣泛之研究，但其辨識率、辨識
速度、辨識容量(Capacity)等問題仍期待於技術上有更大之突破。綜觀過去之人臉辨識研
究，大多之研究著重於2D人臉辨識或是3D人臉辨識之範疇(Wang et al., 2002)，對於同時考
量並結合2D及3D人臉資訊作辨識極為少數，大多仰賴單一類型(2D or 3D)之辨識；然而，
目前使用2D+3D人臉資訊之辨識方法中，2D及3D人臉資訊多為分開取得，使得辨識方式往
往必須以off-line方式進行。 
文獻探討 (略) 
3. 研究方法 
本系統架構可分為將影像資訊讀入系統資料庫之訓練過程及回想(測試)過程(圖3-2)兩
階段。訓練階段主要為學習人臉之特徵，並將標準人臉特徵儲存於分類器內；而回想過程
則為對新取像人臉進行比對及回想。 
【人臉訓練流程】 
本研究之人臉辨識流程如圖3-1所示，其細節分述如下: 
人臉取像：本研究系統採用二維影像及三維影像之結合，以突破先前僅採用二維影像於辨
識率上之瓶頸；本研究之三維影像之產生方式採用雙影像對應技術，故共需配
置二部CCD攝影像，其設定上為將攝影機水平置於左右兩側，且相距13.5cm，
並與受測者相距約75cm，於室內環境進行取像，照明及背景均固定。 
雙影像對應：本研究之三維影像之產生方式，需經由兩張左右不同角度所拍攝之人臉影像，
進行雙影像對應，此處之對應法採用霍普菲爾類神經網路對應法(Hopfield 
neural network)，以左影像為基準影像，右影像為參考影像，逐列掃描，並進
行對應。 
影像前處理：將左影像及所得之三維影像擷取所需之臉部影像部份，並將其大小重新設定
為 500×500 像素之灰階影像。 
特徵擷取：此處採用 PCA 及 LAC 等兩種方法。PCA 具有能擷取重要之特徵代表原始變項
之功能，而 LAC 則有平移不變之性質。 
資訊整合：因 PCA 及 LAC 等兩種方法，其所轉換方式不同，即所投射至空間及維度均不
相同，故所求出之距離差距單位亦不相同，如要於歐氏距離中進行結合，需將
其各自所求出之距離進行正規化，如此才能進行影像之整合。其正規化之作法
為將一向量 b 其長度轉換為 1，亦即轉變為「單位長度」(Unit Length)，於本研
究裡，向量 b 之值為測試影像與訓練影像資料庫各影像之差。其正規化之公式
為： 
bb
bb
b
b
T
== 1*                               (3-1) 
其中， 
*b ：表示正規化後之向量 (Normalization)， 
取及資訊結合後，再以先前所得之 SVM 作辨識，其流程如圖 3-2 所示。 
 
 
 
圖 3- 2 人臉回想過程 
 3.2 進行步驟 
本計畫之進行步驟可分為三階段，各階段之執行內容敘述如下: 
【階段一】人臉取像及雙影像對應 
本研究於影像維度上，採用二維影像與三維影像之結合，其構想為利用二維影像之平
面資訊，加上深度資訊，以提高人臉辨識系統之辨識率。本研究於三維影像上，採用雙影
像對應之區域對應法，以產生臉部深度圖。雙影像對應之基本原理主要為模擬人眼之原理，
利用左右視覺所得之視差，計算3D之資訊；本研究以左影像為基準影像，右影像為參考影
像，逐列掃瞄，並進行基準影像與參考影像之點與點之對應，其對應方式則採用霍普菲爾
神經網路(Hopfield neural network)進行對應。然後再進行左右兩張影像之所有像素點之像
match.  Selecting randomly a feature point j (j≠ k) on the right scanline to replace the 
current match ( oldijV =0, 
old
ikV =1 and set 
new
ijV =1, 
new
ikV =0) as two new states.  Then 
calculate the change in energy function ΔEij and ΔEik after these two states change.  If 
the sum of ΔEij and ΔEik is less than zero, the new solution is found.  Repeat Step (3) 
until a new solution is generated and stored in s(t+1), or the convergence criterion in 
Step (4) is met. 
Step (4) Convergence. If the state vector s(t) remains unchanged for a pre-specified number of 
iterations, go to Step (5), otherwise go to Step (3). 
Step (5) End. 
 
 
    
圖 3- 3 Scanline 區域對應方式 
 
為將轉換後特徵參數與其平均值之間的散佈程度加大，必須找出能使
Zt
S 最大化之轉換矩陣
optP ，即 
P
Popt maxarg= ( )PSP xtT                                (3-7) 
於(3-7)式中，必須找出向量P，使 PSP
Xt
T 變為極大。但如不加限制， PSP
Xt
T 可能為無限大，
故向量P常被限制為單位長度，即 1=PPT ，故由(3-7)式及 1=PPT 之條件式，可得(3-8)式，
故僅須將下列函數極大化： 
( )1)( −−= PPPSPPF TtT x λ                             (3-8) 
為使F(P)最大化，必須根據P取其一階導數，並將其結果設為零。如此可以得到 
022)( =−=∂
∂ PPS
P
PF
xt
λ                               (3-9) 
再進一步移項化簡 
 PPS
xt
λ=  
( ) 0=− PIS
xt
λ           
(3-10) 
解(3-11)式之結果，可得P恰為
xt
S 之特徵向量（Eigenvector）所組之矩陣。 
PCA於人臉辨識上之應用，其流程如圖3-4，經由PCA於不同特徵數所轉換，其結果如
圖3-6，其中3-6(a)圖為原本之二維影像，經由PCA之轉換後，所重建之人臉可見3-6(b)圖，
此圖呈現分別特徵數為1、3及5之重建圖，由圖中可見特徵數愈多，所包含原始影像之資訊
亦相對增加；圖3-7則為三維影像經由PCA轉換所得之結果，3-7(a)圖為原本之三維影像，
經由PCA之轉換後，所重建之人臉可見3-7(b)圖，此圖呈現分別特徵數為1、3及5之重建圖，
由圖中可見特徵數愈多，所包含原始影像之資訊亦相對增加。 
              
(a)原始三維影像 
             
(b)不同特徵數之變化(特徵數分別為：1，3，5) 
圖 3-7 三維影像經由 PCA 所得結果 (前期成果) 
 
2. 區域自相關係數之人臉特徵擷取(Local Autocorrelation Coefficients) 
本研究於特徵擷取上所採用之另一方法為 LAC，其具有物體平上下或左右平移之不變
性(Invariant property)，及簡單且系統執行速度快等特色。本研究將其階數採用階數 0、階數
1 及階數 2 以擷取人臉影像之 25 個 LAC，如圖 3-8(a)之表示方式，以擷取人臉影像之 25
個 LAC，圖 3-8(b)則為將遮罩擴充之作法。遮罩之運用方法為將每一個遮罩掃瞄過整張影
像之每個像素，再將遮罩值與此影像上之像素值相乘，此值即為此遮罩於該像素點所得之
值，並將此遮罩於該影像上各像素點上所求得之值加總，此值即為此遮罩於此影像中所求
得之特徵值。本研究共使用 25 個遮罩，故可得 25 個不同之特徵值。以一張 N×N 個維度之
影像，其第 K 階之自相關係數採以下之計算方法： 
∑∑
= = =
++=
N
i
N
j
K
k
jjiik kk
fC
1 1 0
,C                          (3-11) 
式中 { }2,1,0∈K 為此區域自相關之階數， { } { }1,0,11,0,1),( −×−∈kk ji ，其指於遮罩上之黑點位
置。 ),( ji 則分別指此遮罩於影像 X 及 Y 座標。 
 
 
 
Order 0 
   (2)隱藏層處理單元數目：隱藏層處理單元數目若過少，將導致無法有效描述問題型態；
過多則將使得收斂速度減慢。一般選取原則如下： 
(a)隱藏層單元數目=(輸入層單元數+輸出層單元數)/2           (3-12) 
或 
(b)隱藏層單元數目=(輸入層單元數×輸出層單數) 2/1 。           (3-13) 
   (3)學習速率：學習速率太大或太小對網路之收斂性質均不利，設定太小則浪費時間，且
有可能掉入局部最小值而無法跳出；設定太大則容易產生上下大幅振盪，不易收斂。
一般設定 0.05~1.0 即有不錯之收斂效果。 
   (4)慣性項(Momentum Term)：即加上某比例之上次加權值改變量，以改善收斂過程中之
振盪現像，及加速收斂。 
(5) 訓練循環次數（Epochs）： 
         整體網路複雜度是影響訓練循環次數最主要關鍵因素，當問題複雜高則需要更多
隱藏層神經元數量，相對地越難達到最小誤差值，因此必須進行更多次訓練循環；另
外也可參考網路學習收斂之速度，速度越快則可減少訓練循環次數。本研究設定為
1000 次訓練循環。 
[步驟二]：以均佈隨機亂數設定加權值矩陣 ikW 及 hjW ，與偏權值向量 hθ 及 jθ 初始值。 
[步驟三]： 輸入一個訓練範例的輸入向量 I，與目標輸出向量 T。 
[步驟四]：計算推論論出向量 O。 
(1)計算隱藏層輸出向量 H。 
( )kk netf=H                                                 (3-14) 
 ∑ −⋅=
i
kiikk IWnet θ                                           (3-15) 
   (2) 計算推論輸出向量 O 
( )jj netf=O                                                  (3-16) 
∑ −⋅=
k
jkkjj HWnet θ                                           (3-17) 
[步驟五]：計算差距量δ  
(1)計算輸出層差距量δ  
( )( )jjjjj YTOO −−= 1δ                                           (3-18) 
( )jj netf=O                                                  (3-30) 
    ∑ −⋅=
k
jkkjj HWnet θ                                            (3-31) 
    學習過程即是將 BP 所訓練之資料，重複加以檢視及修正網路之加權值與偏權值之過
程。網路於建立時，各神經元之加權值及偏權值，均是隨機決定，當網路之訓練樣本結果
輸出後，即計算與目標輸出值之差距，再將網路之所有加權值及偏權值加以修正，經由不
斷學習，直至收斂為止。而回想過程即利用所學習完成之網路模型，以判斷另一樣本之結
果。 
 
4. 研究結果 
(1) 實驗設計 
本研究於三維影像上將採用雙影像對應，故於硬體設備上需配置兩台 CCD 攝影機，而
攝影機之配置方式，乃於同一平面上，平行放置此兩台 CCD 攝影機，而兩台攝影機之鏡頭
中心間距將設為 13.5cm，本研究所採用之設備可見表 3-1。 
取像環境設定方式，受測者所坐之椅子之位置將事先設定，使受測者與攝影機之距離
為約 75cm，且背景與照明設備固定不變，以確保無雜訊影響深度影像之對應效果，及影像
之辨識結果。 
表 4- 1 實驗所需設備 
設     備 名     稱 備     註 
影像擷取卡 
(Frame Grabber) 
Domino Alpha 2 可接兩台 CCD 
CCD Camera CIS VCC-870a  兩台 
CCD Camera 固定架 Stereovision 固定架 1 組(訂做) 
程式開發環境 Borland C++ Builder 6.0  
光源照明設備 
LED 點光源 
(及 power supplier) 
1 組 
影像擷取函式庫 e-Vision 
控制攝影機之
API 
影像處理函式庫 e-Vision (e-Match) 
個人電腦(PC) 
Intel(R) PentiumⅣ-2.8G，
1GB SDRAM (or more 
advanced) 
另需 Server 一
台，做為臉部影
像之儲存 
(h) Expression 8        (i) Expression 9        (j) Expression 10      
            
       
(k) Expression 11        (l) Expression 12     (m) Expression 13 
圖4-1 實驗表情13種 
本研究於深度圖上將採用兩部CIS VCC-870a 攝影機進行取像，其最高解析度為1376×
1032像素，其與前期實驗(640x480)之深度圖分別呈現如圖3-11及圖3-12，而像差範圍大小
分別為38及64，由此知較高解析度所取之影像進行深度圖之產生，所產生之深度圖之輪廓
較為明顯，其所包含之三維（深度）資訊越多，雙影像對應之效果亦會愈佳。為避免因人
臉影像包含之三維（深度）不足，造成雙影像對應欠佳，故將取像之影像解析度設定為1376
×1032像素，以取得具有較多三維資訊之影像。 
而雙影像之參數將設定如下： 
(1) 基準影像(左影像)之對應區域大小設定： 
左上角之座標為(122，155)，右上角之座標為(1112，965)，所圍成之矩陣。 
(2) 可允許變動之角度： 5± 度 
(3) 對應之最小相似度設定：-1，即不論相似度，符合其它參數設定，即對應成功。 
(1) 對應所得之最多特徵數設定：1，即一次僅對應到一個最為相近之特徵。 
(2) 區域對應之寬度設定：100 
(3) 區域對應之高度設定：20 
(4) 決定參考影像之區域對應之起始點：基準影像之 X 軸座標加上 288。 
             
      (a) 二維影像                  (b) 深度圖 
如圖 5-2 所示，受測者進行為表情三（ cf ）吐舌動作，由對應產生之深度圖可明顯看
出受測者之臉型輪廓與臉孔之深度變化，深度圖中之方框指出鼻子位置，而圓圈指出舌頭
位置。而圖 6 與圖 7 顯示由不同視角觀察深度圖之結果。觀察深度圖內紅色框可清楚看出
受測者吐出之舌頭大小，與鼻子之高、挺，等人臉三維（深度）資訊。 
 
圖 5-2  原始影像與所對應之深度圖（表情三吐舌） 
 
圖 5-3.  不同視角之人臉深度圖（表情三：吐舌） 
     
圖 5-4  不同視角之人臉深度圖（表情三：吐舌） 
以上結果得知，本實驗所使用之雙影像對應方式，已可有效表示人臉之高度變化，故
此雙影像對應方式產生之深度圖，擷取之人臉三維（深度）資訊量，可供後續特徵臉處理，
以進行人臉辨識之需求。 
 
特徵臉辨識系統，需設定之參數為特徵向量使用數。此參數決定所建立特徵空間之維
三維資訊之深度圖，不論資料庫之數目，其高於累積貢獻度門檻值所需之特徵向量，皆少
於左影像。故由此可得知相較於左影像，深度圖所包含之可供辨識資訊較少。 
 
<LAC 之遮罩大小設定> 
LAC 其辨識之效果，會因其遮罩大小而產生差異；在小樣本 20 個人及大樣本 100 個
人之影像中，而每張影像均為 200×200 像素，其辨識之效果可見圖 5-6、圖 5-7，於圖中可
見當遮罩大小為 151×151 時，辨識率最高，故本研究便採此設定值。 
0.4
0.2 0.25
0.3 0.35
0.4
0.8
1 1
0.9
0
0.2
0.4
0.6
0.8
1
1.2
11 31 51 71 91 101 131 151 171 191
遮罩大小
辨
識
率
 
圖 5-6 資料庫大小為 20 人之 LAC 辨識率 
 
0.26
0.2 0.18 0.21
0.31
0.36
0.65
0.91
0.79
0.57
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
11 31 51 71 91 101 131 151 171 191
遮罩大小
辨
識
率
 
圖 5-7 資料庫大小為 100 人之 LAC 辨識率 
 
<倒傳遞類神經網路之參數數設定> 
0 0 0 1 0 0 0 0 0………………...…………………….0 
 
 
 
第一百位受者 
0 0 0 0 0 0 0 0 0……………...……………………….1 
於學習速率及慣性項上，本研究採試誤法，以決定較佳之學習速率及慣性項之參數設
定。而所進行學習過程之二維影像及三維影像之數目，共取自 100 個人之影像，每位受測
者共七種表情影像，所以共有 700 張表情影像；於回想過程中，二維影像及三維影像中，
亦取自 100 個人之影像，每位受測者共六種表情影像，所以共有六百張表情影像，由圖 5-10
至圖 5-18 可得知不同之特徵擷取方法，與不同之影像維度，其慣性項及學習率之參數設定
方式，所得之辨識結果均不同，故本研究於此部份，採用各自辨識率最高時之參數設定，
做為 BP 之慣性項及學習率之最佳參數設定，見表 4-3，而其於訓練時之收斂狀況由圖 5-19
至圖 5-27 得知，故可知表 5-3 之參數設定均可得良好之收斂情形。 
0.96
0.965
0.97
0.975
0.98
0.985
0.99
0.995
1
0.2 0.4 0.6 0.8 1
學習率
辨
識
率
慣性項：0.4
慣性項：0.6
慣性項：0.8
 
圖 5- 1 LAC 於二維影像之參數設定所得結果 
 
…
…
…
0.935
0.94
0.945
0.95
0.955
0.96
0.965
0.97
0.2 0.4 0.6 0.8 1
學習率
辨
識
率
慣性項：0.4
慣性項：0.6
慣性項：0.8
 
圖 5- 5 PCA 於三維影像之參數設定所得結果 
 
0.988
0.99
0.992
0.994
0.996
0.998
1
0.2 0.4 0.6 0.8 1
學習率
辨
識
率
慣性項：0.4
慣性項：0.6
慣性項：0.8
 
圖 5- 6 PCA 於二維與三維影像結合之參數設定所得結果 
 
0.988
0.99
0.992
0.994
0.996
0.998
1
0.2 0.4 0.6 0.8 1
學習率
辨
識
率
慣性項：0.4
慣性項：0.6
慣性項：0.8
 
圖 5- 7 LAC 與 PCA 結合於二維影像之參數設定所得結果 
 
  
 
 
 
 
 
                                               
圖 5- 10 LAC 於二維影像之訓練狀況 
 
 
 
圖 5- 11 LAC 於三維影像之訓練狀況 
0.0 
0.2 
0.4 
0.6 
1.0 
0 500 1000 
訓練次數 
誤
 差
0.0 
0.2 
0.4 
0.6 
1.0 
0 500 1000 
訓練次數 
誤
  差
 
  
圖 5- 14 PCA 於三維影像之訓練狀況 
 
 
 
圖 5- 15 PCA 於二維與三維影像結合之訓練狀況 
0.0 
0.2 
0.4 
0.6 
1.0 
0 500 1000 
訓練次數 
誤
  差
 
0.0 
0.2 
0.4 
0.6 
1.0 
0 500 1000 
訓練次數 
誤
 差
圖 5- 18 LAC 與 PCA 結合於二維與三維影像結合之訓練狀況 
 
最後，於訓練次數上，受其網路複雜程度影響，當問題複雜性高時，進行一次循環時，
相對地時間也會增加，如要達到較佳之收斂值，勢必要增加循環次數。故本研究將其訓練
循環次數設定為1000，一方面以確保誤差均能降低至0.05以內，另一方面亦能考慮到系統
執行時間，如表4-4所示，其所建構出之網路模型如圖4-28所示。 
表 5- 3 BP 之系統執行時間及誤差(慣性項：0.6，學習率：0.6) 
 
二維影像 三維影像 二維影像+三維
影像 
執行時間 10：47 10：40 14：1 LAC 
誤差 0.0370124 0.0495023 0.0219118 
執行時間 12：48 12：40 16：3 PCA 
誤差 0.0212989 0.0236325 0.0043825 
執行時間 15：17 16：27 21：20 LAC+PCA 
誤差 0.0053654 0.0090532 0.0023692 
 
 
 
圖 5- 19 BP 模型 
 
擷取 
方法 
時間 
   及誤差 
影像維度 
輸入單元依特徵數而定
 
一
 百
 個
 輸
 出
 單
 元
 
隱藏層單元數 
=(輸入層單元數+輸出層單元數)/2 
0.9917 0.9958 0.9917 0.9938 0.9867
0.975
0.9639
0.9375
0.915
1 1 0.9972 0.9979
0.99
0.86
0.88
0.9
0.92
0.94
0.96
0.98
1
20 40 60 80 100
人數
辨
識
率
2D
3D
2D_3D
 
圖 5- 22 PCA 與 LAC 結合所得之辨識結果 
 
表5-5則將圖5-30、圖5-31及5-32等三張圖整理後所得之總表，由表中可見得當受測人
數少時，有較高之辨識結果；當人數逐漸增加後，辨識率便逐漸降低。故得知其辨識結果
與受測者人數有密切之相關；將PCA及LAC等兩特徵擷取方法相互比較，得知不論於二維
影像、三維影像或二維影像與三維影像之結合，PCA之辨識效果總是較高於LAC之辨識效
果；亦可得知於本研究中所採用之特徵方法中，二維影像及三維影像進行結合，均可提高
原本僅採二維影像或三維影像之辨識率；於LAC之特徵擷取方法中，受測者人數為40人時，
三維影像之加入，可提高6~7%之辨識率；但於PCA及LAC等兩特徵擷取方法之結合，可得
知對其僅採一種特徵擷取方法時相比較時，對辨識率並無明顯之提昇，甚至因LAC之影響，
而降低PCA原有之辨識率。 
 
 
 
 
 
 
 
 
 
0.9
0.92
0.94
0.96
0.98
1
2D 3D 2D+3D
影像維度
辨
識
率
Euclidean
BP
 
圖 5- 23 PCA 之辨識結果(受測者 100 人) 
 
0.8
0.85
0.9
0.95
1
2D 3D 2D+3D
影像維度
辨
識
率
Euclidean
BP
 
圖 5- 24 LAC 之辨識結果(受測者 100 人) 
 
0.86
0.88
0.9
0.92
0.94
0.96
0.98
1
2D 3D 2D+3D
影像維度
辨
識
率
Euclidean
BP
 
圖 5- 25 兩特徵擷取方法互相結合之辨識結果(受測者 100 人) 
 
表 5-6 則將圖 5-32、圖 5-33 及圖 5-34 等三張圖，進行彙整所得出之總表，由表中得知，
 三、計畫成果自評部份 
本計畫主要之研究領域為臉部辨識系統開發與應用，計畫中提供一名研究生參予研究
機會，藉由原 2D 資訊加入 3D 資訊，並利用 PC 及 BPN 之方法探討於小型 Database (100~300
人)之可行性，參與計畫之研究生可實際學習解決實務性問題之方法，並達到理論於實務結
合之目的；本研究之成果簡述如下： 
(1) 臉部辨識之方法 review; 
(2) 3D 臉部深度圖之方法建立與實踐; 
(3) 2D 與 3D 臉部資訊之整合 
(4) PCA、BPN 等相關技術之程式發展; 
(5) 成功發展臉部辨識之系統，且辨識率達 99%; 
(6) SCI 論文發表一篇(已接受於 Expert System With Applications)。 
 
唯，原規劃為兩年期計畫中之 SVM 部分，因核定通過僅有一年，於短時間內尚無法完成，
但目前仍在進行中。 
 
表 Y04                  共 5 頁    第 2 頁 
報告內容： 
一、參加會議經過 
1. 參加本次國際研討會之行程於 2008 年 5 月 4 日之下午 8:20 由台北出發，至香港及蘇黎世
轉機後，終於 2008 年 5 月 5 日早上抵達 Milano 後，直接至會場報到報到，並領取相關資
料，並至旅館 check in。 
  
2. 於5月6日為Workshop 之sessions，故至會場參觀相關之展示後，傍晚赴Milano之市區參觀
其主教堂等名勝。 
3. 5月7日中午11:30為大會之opening session及Panel，主要有兩場Keynote lectures，分別為
Masao Matsumoto及Jianchang Mao兩位學者做演講，分別講有關Service 
Computing EIS, World Panic and Our Role Change及 Machine Learning in 
Online Advertising，因對於Machine learning 較有興趣，其中Dr. Mao者服
務於Yahoo Lab，故介紹現今如將Machine learning之技術應用於Web 廣告
之領域上。該會後，再參與其他session之報告。 
 
表 Y04                  共 5 頁    第 4 頁 
5. 5月9日中午則參加北科大老師田方治之報告，田老師報告主題為Using GRA for 2D Invariant 
Object Detection，主要內容應用灰色理論作二維物件之不變辨識。下午4:00再參加台科大
郭人介教授之報告，主題為 An Order Clustering System Using ART2 Neural network and 
Particle Swarm Optimization Method。會後在至市區參觀。 
   
同session之報告       報告後之合影 
二、與會心得 
 參與此次研討會之行程中，並順道參觀 Milano 及 Roman 之建設與風景，義國之古蹟甚
多，文化之保存令人驚豔；而參與本次研討會過程中獲得以下心得： 
1. 於本 session 中發現，香港及大陸學者於國際會議之參與非常積極，表現亦相當傑出，研
究之報告清晰有條理，且研究之主題相當注重其實用性，值得台灣學者學習效法。 
2. 本次會議行程中，發現韓國、印度及大陸之學者參加人數愈來愈多，而台灣之學者相對稀
少，可見我國政府與學術機構對學術之重視程度相較遜色，且此次之研討會註冊、機票及
住宿所需金額相當高，國科會之補助卻甚少，降低國內學者參與的意願。 
 
三、考察參觀活動 
於研討會之末，與北科大田方治老師偕同至羅馬(Rome)參訪，發現該國之文化保存豐富，
其中尤以古羅馬之皇宮遺址、羅馬 coliseum 及 Vatican city 之文物為最，雖有其中文物部分破
壞，所保留之遺跡，實為西方文明的活歷史，但可惜因時間不足，無法一一參觀。 
