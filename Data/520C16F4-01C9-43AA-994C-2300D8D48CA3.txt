1行政院國家科學委員會補助專題研究計畫成果報告
全球資訊網圖片搜尋系統的設計與實作
Design and implementation of World Wide Web images search system
1 中英文摘要與關鍵字
由於網路的快速發達與網頁美觀的要求，網路
上的圖片數量以飛快的速度成長，因此 WWW
成為一個廣大的圖片資料庫，要如何快速而且
正確的擷取想要的圖片成為一個非常重要的
議題。透過本次研究，我們提出了自動網路圖
片的註解方法，分別為宿主網頁註解、連結分
析註解、區塊化網頁註解、分享註解。透過這
四種方法搭配我們所提出的網路圖片索引系
統架構，可以讓使用者快速擷取相關的圖片，
最後我們透過盲目測試法取代傳統資料檢索
的測試方法，證明透過我們的方法所設計的網
路圖片索引系統，可以讓使用者有更好的使用
觀感。
關鍵字： 網路圖片註解, 圖片索引系統
Abstract:
The number of images is growing in a rapid
speed with the popularity of digital cameras and
for enriching the visual aesthetics. WWW is
becoming a large image library for browsing,
and it is an important issue that how to retrieve
the images accurately on the web. In this
research project we sketch the architecture of an
image retrieval system with image annotation.
And we propose four methods to generate the
annotation automatically for every image from
its hosted web page, by analyzing the structural
blocks, collecting anchor text of link structures,
and gathering shared annotation with other
images with the same visual signature.
Keywords: Image Annotation, Image
Retrieval
2 Introduction
From the invention of World Wide Web by Tim
Berners-Lee on November 12, 1990, the population
on the Internet is growing in a rapid and uncontrolled
speed. The population brings commercial potential
onto World Wide Web. In order to attract users
staying and returning to the web site, the looks of
webs pages are more and more elegant. A large
number of images are used to enrich the visual
aesthetics. On the other hand, more and more digital
images are posted onto the web space with the
popularity of digital cameras. Lots of free web album
services are announced for users put their images for
sharing. For the above two reasons, the number of
images on the WWW is increasing in a fast way.
Such a large number of images are posted on
the WWW, the text content of web pages is a large
free text library as we know, the images are also
formed another library. It is becoming an important
issue to retrieve images with a quick and accurate
method on the web. Unlike the web page search, a
lots of text retrieval technique have already
developed for a long time. There are many difficult
problems for a web image retrieval system.
In the traditional images retrieval systems, they
add annotations to each image manually. Although it
is a good methodology to retrieve images through
text retrieval technologies, it is becoming impossible
to annotate images manually due the huge and rapid
growing number of web images. Some researches [1]
[2] [3] [4] create image retrieval systems by
analyzing the image content. They find out the size,
shapes, patterns, colors, and distribution of hues [5]
[6] [7] of each image, and transfer the properties into
a signature for the image. User can specify the
properties as the query signature, or submit a similar
3sub-system in a centralized model, which is putting
one centralized gathering coordinator to arrange the
URLs for the gathering clients. Figure 2 shows the
flow chart of a data gathering sub-system.
Figure 2 The flow chart of a data gathering sub-system
After the gathering phase, we now have the
images and pages in our database for our next phase
automatic image annotation. We will make the
thumbnails and collect the basic information, like
image width, height, format… for all the images and
transfer them into our internal format. And then
generates the annotation automatically from the
database, this will be described in detail next section.
The annotation for all gathered images can be
used for building the inverted index through the
traditional information retrieval techniques, and we
call it as index generator sub-system. The generated
inverted index, the thumbnails, and the basic
information from the images can be utilized for the
image retrieval sub-system. When a user submits a
query term contains some keywords to the image
retrieval sub-system, it will look up the inverted
index to matching the images with the automatic
generated annotation which is relative to the
keywords. And then show the image thumbnails to
the user according to some pre-defined ranking
methods.
4 Automatic Web Image
Annotation
Web pages are composed by HTML. There are a lot
of clues can be used for automatically generating
image annotation, especially the links characteristics
and structures. We will introduce the methods how
we generate the image annotation automatically by
following sub-sections.
4.1 Annotation from the Hosted Web
Page
We use the <img> tag to show an image in a HTML
page, the value of the property “alt”is a statement
composed by some words defined by the author. It is
generally to tell page consumers what the image
represents when the browser fails to load it.
Therefore, it is the best annotation candidate for an
image. Generally speaking, the text around the
<img> is describing the image. We can also say that
the image is used for emphasizing the text around it.
It is impossible for a web page author putting some
irrelevant images in the web page. The text around
the image can also be treated as an important
annotation for an image.
Figure 3 An example of Clown Anemonefish from URL:
http://animals.nationalgeographic.com/animals/fish/clown-anemonefish.html
The author of the web page may specify a
meaningful title to the page. The specified title can be
treated as the name of the page. Generally speaking,
the name contains the essential meaning of the page.
5main issue in this research project. We can just use a
simple method for visual signatures by resizing every
image to a pre-defined dimensions, and then use the
MD5 digest method to generate the signature for each
image. The visual signatures of duplicated images
and original one will be the same, even the duplicated
images are resized. Images with the same visual
signature could share the annotation to each others.
By sharing annotation from images with the
same visual signature can substantially increase the
source of annotation for every image. Although the
share annotation can not increase the result number
of retrieved images with different visual signatures, it
can help the ranking algorithm higher the score if one
image can gather more shared annotation from others.
It is because one image might be good if many
authors duplicate it and put it in their own sites.
Figure 5 The data flow of automatic image annotation generation.
Figure 5 displays the data flow of automatic
image annotation generation. We will generate the
annotation for each image through the methods we
described in the section 3.1 to 3.3. And then generate
the thumbnails and visual signature for each image.
The shared annotation can be generated the by
sorting the internal format according to their visual
signatures. The images with the same visual signature
will be put in the continuous location. It will be very
easy to collect all the shared annotation in linear
time.
5 Experimentation
We make an experimentation to gather some free web
albums and e-commerce sites in Taiwan. We first
mark some of the images as functional ones by
following rules.
A. Width/Height or Height/Width > 4
B. Width * Height < 2500
C. Image in GIF format with more than one layer
D. The image appears in the single page more
than once
We will take out the functional images, because
users are not interesting in these functional ones, for
examples: buttons, logos, separators and icons.
# of Web Pages 20,219,113
# of functional images 303,190,414
# of images 49,104,883
Table 1 The information of gathering data
Figure 6 Blind test for the experimentation
Table 1 shows the number of web pages,
functional images, and normal images we gathered
for this experimentation. We will create two set of
annotation for the experiment, the first set is the
annotation generated by the methods in section 3.1 to
3.3, and the second set is adding the shared
annotation. We select the top 10 query terms from the
query logs, and use blind test as shown in Figure 6 to
20 users. The retrieved result from two set will
randomly put in the two sides of the result page.
Testing users will assign one value from 1 to 5 for the
better side. The average value to the first set is 0.8,
and the value to the second set is 1.65. We can say
that shared annotation can improve the results in an
image retrieval system.
7for Information Science andTechnology 52 (10)
(2001) pp. 831-839
[12] S. Bloehdorn, K. Petridis, C. Saathoff, N.
Simou, V. Tzouaras, Y. Avrithis, S. Handschuh,
Y. Kompatsiaris, S. Staab and M.G. Strintzis,
“Semantic annotation of images and videos for
multimedia analysis”, Proceedings of the 2nd
European Semantic Web Conference (ESWC
2005) 29 May–1 June 2005, Heraklion, Greece
[13] Google Image Search,
http://images.google.com/
[14] Yahoo Image Search,
http://images.search.yahoo.com/images
[15] MSN Image Search,
http://search.msn.com/images/
8 計畫成果自評
8.1 研究內容與原計畫相符程度
我們所執行的計畫內容與原計畫申請內容
一致。針對網路圖片自動註解的關鍵技術進
行研究，並且提出網路圖片搜尋系統的架
構，此架構除網路圖片搜尋，更可以利用在
各種網路物件的搜尋之上。
8.2 預期達成目標情況
我們透過宿主網頁註解、連結分析註解、區
塊化網頁註解、分享註解四種註解方法，可
以使的網路圖片搜尋的結果更佳準確，提高
使用者的觀感，與預期的目標相當符合。
8.3 研究成果的學術或應用價值
網路圖片所形成的大型圖片資料庫，將可以
成為文字資訊以外的另一個重要免費資料
庫，透過此系統與技術，將可以快速與正確
擷取所需圖片，如此可以更有效利用此廣大
且免費的資源。本計畫所提出的共享註解更
是以往未曾出現的方法，可以更有效提升網
路圖片搜尋
出席國際學術會議心得報告
計畫編號 NSC 96-2218-E-182-067
計畫名稱 全球資訊網圖片搜尋系統的設計與實作
出國人員姓名
服務機關及職稱
張賢宗
長庚大學資訊工程學系 助理教授
會議時間地點 Heraklion, Crete Island, Greece, July 22-24, 2008
會議名稱 12th WSEAS International Conference on SYSTEMS
發表論文題目 Automatic Web Image Annotation for Image Retrieval Systems
一、參加會議經過
第十二屆 WSEAS 國際系統會議是第十二屆 WSEAS CSCC 綜合會議（12th
WSEAS CSCC Multiconference）中的一個會議，舉辦地點在希臘南部的克里特島首府伊
拉克里翁（Heraklion），是 WSEAS 的年度盛會，這一次的綜合會議一共有 1350 篇
Paper 投稿，期中的 641 篇 Paper 被接受並且發表，算是一個非常大型的會議。
因為台灣沒有任何本國籍飛機前往希臘，因此本人搭乘泰航班機在曼谷轉機前往雅
典，然後在雅典換國內線前往伊拉克里翁，整個飛行與等待的時間超過 20 小時，是一
段非常遙遠的旅程。
這一次的會議中包含 COMPUTERS、SYSTEMS、CIRCUITS、COMMUNICATION
（CSCC）四大部分，涵蓋的主題也非常的廣，主辦單位特別邀請了 2007 年 Turing Award
得主 Prof. Joseph Sifakis 前來演講，演講題目為 Embedded Systems–Scientific Challenges
and Work Directions，演講內容非常的精彩，與會者發問也非常非常的踴躍，是一場非常
難得演講，難得參加國際會議看到這樣的場面。
另外主辦單位也安排了三場 Keynote Speech，分別為 1) Distributed Estimation Using
Wireless Sensor Networks - Georgios B. Giannakis, 2) Tyflos : AWearable System-Prototype
for Assisting Visually Impaired - Nikolaos G. Bourbakis, 3) Algorithms for Rendering Depth of
Field Effects for Synthetic Image - Brian A. Barsky，雖然人數沒有前面那一場的人多，但是
演講內容也不錯。
SYSTEMS 這個會議一共有 17 Sessions，本人所發表的論文被安排在最後一天的第
15 個 Session發表，這一個 Session 一共有 12 Papers 發表，有兩篇 Paper 沒有人前來
報告，不知道是不是主辦單位刻意安排或是巧合，這一個 Session 裡都沒有母語是英文
的研究人員參與，所以整體來說大家英文的口音都蠻重的，雖然幾乎每一篇 Paper 都有
人提出一兩個問題，但是交流情況並不熱烈，在同一個 Session 中有另外兩篇論文也是
由台灣的學者發表，因此在會後也跟這些發表論文代表交換研究心得。
會議中有一位捷克的學者要報告的時候，因為發現主辦單位所使用的 Power Point
是 2003 版本，與他帶來的檔案（Power Point 2007）並不相容，所以他詢問有沒有人有
攜帶自己的 Laptop 有灌 Office 2007，剛好我帶的筆記型電腦有安裝，所以提供給他使
用，該為學者在會後也特地前來感謝，雖然只是舉手之勞，但是這樣的交流讓自己覺得
