 ii
目錄 
 
中文摘要及關鍵詞               iii 
英文摘要                 iv 
一、前言                 1 
二、研究目的                1 
三、文獻探討                2 
四、研究方法                3 
五、結果與討論               8 
六、結論與建議               12 
七、參考文獻                12 
附件一、所發表論文              14 
附件二、計畫成果自評 表             22 
附件三、研發成果推廣資料表            23 
附件四、出席國際學術會議心得報告          24 
 iv
Abstract 
Handwritten characters are usually input on-line by a device like tablet and touch-pad or offline 
input by an optical scanner. However, it would be very inconvenient for user to input characters 
to a mobile device like PDA or cellular phone for its tiny stylus or keyboard. Instead, we 
developed a video based input method which utilizes camera as it becomes standard equipment in 
mobile devices or smart phones. The finger tip acts like the pen tip is used to write characters in 
front of the camera. The finger tip is tracked and the trail is recorded as the handwritten strokes. 
Due to the lost depth information, all strokes including pen-up strokes which may not be suitable 
for character recognition are all concatenated. However, some stroke connection rules could be 
utilized to classify input strokes into pen-up strokes and pen-down strokes. We defined eight 
directional stroke types, eight semi-circle stroke types, and two loop stroke types for 
alphanumeric recognition. A 1-D sequential representation of extracted strokes is then matched 
with pre-built 1-D character models consisting of alternative pen-down and pen-up strokes. 
Recognition is conducted by dynamic time warp matching algorithm which could tolerate strokes 
insertion, substitution, and deletion. In the next year, we will generalize the model for Chinese 
handwritten character recognition. Stroke segmentation and large character set are two of the key 
problems need to be conquered. 
 
Keywords: Video processing, fingertip extraction, fingertip tracking, handwritten character 
recognition; 
 2
等。其中又可使用臉部及手勢辨識系統，讓言語或行動不便的人，使用電腦裝置的操作，更靈活
更直覺化。 
 
因此本計劃宗旨在設計一套以視訊為基礎的手寫輸入系統，應用在電腦、手機、PDA 等手持裝置上
當作輸入裝置。為了達到即時反應的需求，我們對數位攝影機擷取到的影像以相差取得運動區域，再
以膚色偵測、特徵比對，取得指尖的連續移動軌跡，並將此軌跡累積於一張影像上，加以流水號碼，
即可保存筆畫之動態資訊。再經過平滑化的處理步驟，即可對此文字的連續筆畫作特徵分析，進行文
字辨識。 
 
三、 文獻探討 
z 手勢辨識 
手勢是一種相當原始又自然之動作，在日常生活裡，手勢一直都是人與人互動最常使用的溝通方
式之一。因此手勢應用在人機介面上，已經成為一個新的研究方向。現在手勢輸入作為人與電腦間之
溝通介面，慢慢的已經被應用。以追蹤手勢動作與辨識手勢，作為電腦輸入介面之研究，主要有兩類
方法： 
1.手套為基礎之方法(Glove-Based Methods) [1] 
數據手套是一種感應裝置，可以用來辨識手的目前動作。較有名的VPL Data Glove是將光纖置
於手套中，利用光在光纖中反射的角度及強度變化，求出各手指關節彎曲角度，從而可得出手
勢資料。但價格昂貴而且厚重的手套，造成使用上之不便，因此降低了其實用性與方便性。 
2.視覺為基礎之方法(Vision-Based Methods) [2,3,4,5,6] 
透過攝影機擷取的影片，經過影像處理得到手部區域，再使用建立好的模型樣板來比對而取得
手勢資訊。但是手勢資訊易與其他物體產生混淆或者手指遮蔽，不易與模型比對，加上計算複
雜度高，時間花費較長，若影像較大或模型較多，對即時辨識容易產生時間上的延遲。 
z 手寫辨識 
手寫是最自然的文字輸入方式，簡易上手的操作環境，可讓使用者取代鍵盤或滑鼠的輸入方
式。用以進行手寫辨識的輸入設備有許多種，像是透過電磁感應式手寫板、感壓式手寫板，或是
觸控桌的光學觸控面板等，藉這類裝置所輸入的文字，其手寫文字辨認最常見的方法有三種： 
1.隱藏式馬可夫模型(Hidden Markov Model) [7,8,9,10,11,12] 
隱藏式馬可夫模型是由三種參數所組成，一個是初始狀態機率值，一個是狀態轉移機率值，
以及狀態觀測機率值。在使用隱藏式馬可夫模型時，必須從擁有的參數中確定該過程的隱含參
數，然後利用這些參數來達到進一步的分析。一般我們所擁有的只有實際出現的序列值，以及
各序列值對應各狀態的機率值，至於狀態的轉換情形無法明確得知，故稱為隱藏式馬可夫模型。 
2.類神經網路(Neural Network) [13,14,15,16] 
一般是指用電腦模擬人腦的結構，用許多小的處理單元模擬生物的神經元，用演算法實現
人腦的識別、記憶、思考過程。應用於圖像、語言、聲音等的識別，複雜的計算，以及趨勢預
測等領域。 
3.動態時間扭曲(Dynamic Time Warping) [17,18,19,20,21] 
這是一套基於「動態規劃」（Dynamic Programming，簡稱 DP）的方法，可以有效地將搜尋
比對的時間大幅降低。使用這演算法最主要的精髓在於能夠容忍不同長度的資料比對，即是說
即使是不同長度的資料，也可以去做相似度的比對，找出測試資料與參考資料間的非線性對應。 
 4
 
 辨識模組 – Two Stage Dynamic Time Warping 
在辨識模組裡面有筆畫與文字辨識的核心部份，我們都採用 Dynamic Time Warping的演算
法，因此我們將模組稱為Two Stage Dynamic Time Warping手寫辨識。 
 
z Stage 1：Features Extraction and Stroke Representation： 
從文字的軌跡，使用Time Warping抽取出各個有用的筆畫以及相關特徵，不同的筆畫特
徵組合可能是不同的文字筆畫，找出所有的可能特徵組合，將所有特徵以一維序列組合。透
過軌跡比對，找出相似筆畫，筆畫如圖三分成二類，(a)類屬於直線筆畫，具有一定長度的單
方向筆畫或是與前一筆畫的連續筆畫；(b)類屬於複合筆畫，由一連串小線段組成，有一定的
連續性，小線段的方向也是由圖三(a)所定義。 
 
   
(a) 
 
 
(A)     (B)     (C)     (D) 
 
(E)     (F)     (G)     (H) 
 
(O)    (Q) 
(b) 
圖三、(a) 直線筆畫，根據角度做區分；(b) 複合筆畫，根據軌跡起始點與開口方向做區分。 
 
 
z Stage 2：Character Recognition： 
對所有的1-D筆劃組合去和文字模型資料庫做比對，找出最相近的文字。以圖四為例，定
義數字8的模型筆畫組合是CEGA，根據我們前ㄧ步所抽取出的筆畫組合，即可比對出所有可能
 6
情況外，像是左右結構的字、左中右結構的字經常發生“↗”方向為不需要的筆劃，如圖所示。
但是有些文字卻有例外的情況發生，如圖七、。因此我們根據中文字書寫的習慣，利用兩筆以
上的連續筆劃特徵來決定“↗”方向為提筆或是下筆筆劃，並與右字部切割開來。如三點“氵”部
和“冫”部，當文字連續序列為“↘”+“↙”+“↗”時，我們判定“↗”方向筆劃為下筆筆劃。同理，如
“扌”部首，當文字連續序列為“→”+“↖”+“↓”+“↖”+“↗”時，除了判定“↗”方向為下筆筆劃外，
並將此三種部首之“↗”筆劃取適當長度以避免與右字部相連。 
(5)因為“↙”方向筆劃也經常屬於提筆筆劃，像是上下結構的字，如圖八、所示。在字中“↙”方
向除了為提筆筆劃，也可能為下筆筆劃，因此我們無法利用連續筆劃特徵來判定。經實驗與觀
察得知，當“↙”筆劃斜率之角度 者為提筆筆劃，反之，“↙”筆劃斜率之角度較大者為下
筆筆劃。我們藉由不會存在之筆劃、連續多筆筆劃、以及筆劃斜率方法，可濾除不應出現的筆
劃方向，以達到自動斷筆的功能。 
 
左右 
結構 
    
左中右 
結構 
    
圖六、“↗”應濾除之文字 
 
例外 
文字  
圖七、“↗”應保留之文字表示 
上下
結構  
圖八、“↙”應濾除之文字 
z 擴充式線上文字模型 
    每個文字都個別建立一組線上模型，如 Hsieh and Lee[25] 提出的“以模式導引作手寫中文字的
辨識”，除了利用八方向字串之外，並以定義好的兩連續筆劃關係來表示文字。我們則是依書寫般
的筆劃順序排成一維字串，不僅是包含筆劃型態也包括筆劃之間的關係，都被用於文字的模型描
述，因此我們將(1)方向、(2)斷筆、(3)長度比值和(4)夾角角度，各形成一連續的數字序列，以中文
字“王”、“青”來說明，如圖九。 
 
z 文字辨識-比對與合併 
    轉折點偵測後，中文字可用四項屬性的一維文字序列組合表示，但是每個人的書寫習慣不盡
相同，因此每個中文字的線上模型並非是獨一無二的，所以單一文字可建構一組以上的線上文字
模型。在比對方面，我們利用動態規劃之字串差異度比對，計算出最小的差異值以進行文字辨識。 
將其三項屬性特徵所組成的序列，以動態規劃之相似字串差異度演算法作比對，此演算法可
以容忍符號的插入、取代與刪除，因此，在一般情況下，動態規劃之差異度字串比對演算法，可
以將未知的文字筆劃串列找到一個最佳解，假定輸入的字串為 ，參考比對的字串為 ，演算法
如下: 
 8
 
三項屬性特徵所組合成序列進行字串比對，依照實際書寫情況如圖十、(a)所示。將輸入字串
與參考字串 比對，圖十、即是兩字串 所產生出來的 map[i][j]。當  和 
比對結果圖十、(b)所示，最右下角數值“0”。當  和 比
對結果圖十、(c)所示，最右下角數值“0”。當  和 比對結果圖十、(d)所
示，最右下角數值“2”。 當  和 比對結果圖十、(e)所示，最右下角數值
“2”。分別是比對出來的方向、長度比值和夾角的變化距離。 
將四種屬性特徵之差異度計算後，由文字特性可知，筆劃越少文字資訊相對也較少，如相似
字的方向字串相同，必須由長度和角度屬性特徵來辨別該文字，因此我們依照筆劃的多寡來決定
此四種屬性的權重值如 
表一所示。當文字筆劃越少，長度與角度的權重值就越高。同理，文字筆劃越多，文字多半
可由方向屬性辨識，因此長度與角度的權重值則越低。最後由此四種屬性差異度值依權重合併，
以計算出最小值所對應之該文字為辨識結果。 
 
表一、四項屬性特徵之權重值 
筆劃多寡n 方向權重  斷筆權重 長度比值權重 角度權重  
n <= 4 0.5 0.1 0.25 0.15 
n > 5 && 
n < 15 0.6 0.1 0.15 0.15 
n >= 15 0.7 0.1 0.15 0.05 
 
    我們將方向屬性差異度定義為 ，其權重為 、斷筆差異度為 ，其權重為 、
長度屬性差異度定義為 ，其權重為 、角度屬性差異度定義為 、其權重為 。因此
我們得到的差異度 公式如下式所示。 
 
 
 
五、 實驗結果與討論 
 
本實驗使用C語言開發系統軟體，以P4 PC為硬體實驗平台，搭配的視訊輸入設備為Logitech 
QuickCam® for Notebooks Pro，影像解析度為 320*240，實驗結果證明可行性。 
 
 Fingertip Tracking Result 
指尖抽取的精確度比系統執行速度更重要，因為若擷取不正確，系統就無法正確使用。許多人以
指尖書寫的習慣都會不一樣，造成距離攝影機遠近不同、手部旋轉、手寫筆畫位置都有所不同，我們
對這些情形都進行實驗，證實本系統指尖抽取的正確性。其中手部旋轉可容忍高達向左向右各45度。
此序列影像總共有 847 張影像，其中辨識錯誤的張數為 12，依此計算系統指尖抽取的精確度為 
98.58%。 
在辨識錯誤的情況下，最主要有兩大主因，首先，是影像中的強光影像膚色偵測的結果，因為會
造成所偵測出之膚色區域過於狹小。第二，手部移動的速度會影響時間像差的結果，太快會造成兩個
指尖同時出現，造成判斷錯誤，更甚者，手部移動到臉部區域，因為臉與手均為膚色區域，而且臉部
 10
我們的辨識率可提昇為 91.11%。再者，如果正確字元在前三名內，則辨識率為 96.44%。 
 
表三、英數字辨識率。 
 Test model number Correct number Correct rate(%) 
With confusion characters 900 745 82.77
Without confusion characters 900 820 91.11
Top three 900 868 96.44
 
 Handwritten Chinese Character Recognition Results 
由於在空中寫字無法辨別下筆和提筆的筆劃，因此在自動斷筆上我們依照所書寫的文字，先利用
線性近似法找出轉折點，且根據文字的特性偵測出提筆筆劃，提筆偵測利用了五種規則來判斷筆劃是
否為提筆或下筆，共測試了自建資料庫中的1000個中文字如圖十二所示，在正確筆劃順序的書寫狀況
下，準確率達91.56%，如表四所示。 
 
表四、1000中文字之斷筆準確率 
 正確字數 準確率 
People 1 912 91.2% 
People 2 908 90.8% 
People 3 926 92.6% 
People 4 919 91.9% 
People 5 913 91.3% 
Average 915.6 91.56% 
 
文字 轉折點偵測 斷筆偵測 
車 
  
走 
  
佳 
  
 12
 
表六、前三名候選字之手寫中文字辨識率 
 總字數 正確字數 加入候選字之辨識率 
People 1 3000 2842 94.733% 
People 2 3000 2873 95.766% 
People 3 3000 2915 97.166% 
People 4 3000 2887 96.233% 
People 5 3000 2901 96.7% 
Total 15000 14418 96.12% 
 
六、 結論與建議 
 
本系統最大之特色包括： 
1．設備簡單 
只需透過網路攝影機就能作手寫文字輸入，不需要使用額外的硬體設備，例如：鍵盤、觸控板、手
寫板、手寫筆等。 
2．使用方便 
不需要熟悉新的操作方法，只需使用手指，就能達到輸入的效果。 
3．有效擴展手寫輸入的使用範圍(SCOPE) 
在以視訊為基礎的輸入裝置上，突破了傳統介面如鍵盤、滑鼠、觸控板、手寫板等的筆與紙接觸的
限制。 
4．可取代滑鼠之功能 
運用手寫輸入的定位點，對映擷取影像的相對位置到螢幕位置，透過系統操作訊息，可以輕鬆達到
取代滑鼠操作的功用。 
 
七、 參考文獻 
[1] D. J. Sturman and D. Zeltzer, “A survey of glove-based input”, IEEE Computer Graphics and Appl., 
pp.30-39, 1994. 
[2] J. J. Kuch and T. S. Huang, “Vision based hand modeling and tracking for virtual teleconference and 
telecollaboration”, ICCV, pp.666-671, 1995. 
[3] J. M. Rehg and T. Kanade, “DigitEyes：vision-based hand tracking for human-computer interaction”, IEEE 
Workshop on Motion of Non-Rigid and Articulated Objects, pp.16-22, Nov. 1994. 
[4] J. Davis and M. Shah, “Visual gesture recognition”, Proc. of IEE on Vision, Image and Signal Processing, 
Vol.141, pp.101-106, Apr. 1994. 
[5] W. Du and H. Li, “Vision based gesture recognition system with single camera”, Proc. of ICSP2000, vol.2, 
pp.1351-1357, 2000. 
[6] C. L. Huang and S. H. Jeng, “A model-based hand gesture recognition system”, Machine Vision and Appl., 
vol.12, pp.243-258, 2001. 
[7] M. Stamp, “A revealing introduction to hidden Markov models”, http ：
 14
 
謝禎冏、林倚鈴,“基於指尖偵測之視訊手寫中文辨識系統,” 2010 數位生活科技研討會-智慧城市生活國際論
壇，成功大學，p 40, June 24-25, 2010. 
附件一 
 16 
 18 
 20 
 22
國科會補助專題研究計畫成果報告自評表 
請就研究內容與原計畫相符程度、達成預期目標情況、研究成果之學術或應用價值（簡要敘
述成果所代表之意義、價值、影響或進一步發展之可能性）、是否適合在學術期刊發表或申請
專利、主要發現或其他有關價值等，作一綜合評估。 
1. 請就研究內容與原計畫相符程度、達成預期目標情況作一綜合評估 
■   達成目標 
□ 未達成目標（請說明，以 100 字為限） 
□ 實驗失敗 
□ 因故實驗中斷 
□ 其他原因 
說明： 
 
2. 研究成果在學術期刊發表或申請專利等情形： 
論文：■已發表 □未發表之文稿 □撰寫中 □無 
專利：□已獲得 □申請中 □無 
技轉：□已技轉 □洽談中 □無 
其他：（以 100 字為限）論文將修改並新增內容，擬投稿 IEEE Trans. 期刊。 
 
3. 請依學術成就、技術創新、社會影響等方面，評估研究成果之學術或應用價值（簡要敘述
成果所代表之意義、價值、影響或進一步發展之可能性）（以 500 字為限） 
 
利用手寫進行文字輸入，在近幾年來日益普及。然而手寫板及觸控板在使用上雖簡易，卻
會造成攜帶上的不便。本計畫提出一套以斷筆與線上模型為基礎之手寫中文輸入系統，其
核心方法首先為利用指尖特徵抽取指尖位置，記錄指尖連續移動軌跡，利用直線近似法原
理將文字表示成一連續的直線段，依照筆劃轉折點作為特徵的判斷，由於深度資訊已經遺
失，無法區分下筆和提筆的筆劃，因此以文字書寫習慣作為斷筆依據，我們歸納出五種規
則，第一種為在書寫中文字的下筆上不會發生的方向筆劃，第二種為兩平行線之間的筆劃
不會存在，第三種為不會出現與上一筆筆劃相反方向，第四種為左右部首之間的提筆，第
五種為上下部首之間的提筆。接著以方向、斷筆、前後筆劃所形成的夾角及長度比例值，
組合成一連續的序列字串，在參考字串中，每個字我們建構了一組以上的線上模型，再以
動態規劃之字串差異度比對演算法進行比對，達到線上即時文字辨識。在實驗中，我們建
立了 1000 個中文字線上模型，邀請了 5 個人對每個字寫了 3 次，其中指尖追蹤準確率為
98.88%，每秒可處理 12.6 張圖片，斷筆準確率為 91.56%，文字辨識率為 93.61%。證明本
論文方法能正確比對識別中文字。 
 
 
附件二 
 24
 
國科會補助專題研究計畫項下出席國際學術會議心得報告 
                                     日期：99 年 9 月 15 日 
一、參加會議經過 
認識幾位先進教授: Wang Jun(The Chinese University of HongKong), Derong Liu (University of 
Illinois at Chicago)，將來可以邀請這些前輩給予指導。論文報告排在 7/7 大會第三天早上第二個
Section，比較以往參加的研討會，論文的數量多的驚人，也吸引許多國際人士參加，顯示中國大
陸舉辦的研討會已逐漸吸引全世界的注意力，瀏覽論文集，也可以發現論文的品質也不錯，因此
大陸學者的研究能力，也逐漸在國際舞台上吸引注目，對於未來的合作，本人覺得是一個機會。
在 2005 年中国普通高等学校工学 100 强排名中，遼寧省 5 所大学榜上有名，其中主辦單位大连理
工大学排名 14 位、东北大学排名 15 位，算是不錯的! 
二、與會心得 
電腦視覺其實就像是人的眼睛一樣，牽扯到很多的領域，比方說影像處理、人工智慧、模式識別
等，雖然這些科學已經發展很久，但是目前的電腦視覺其實還是非常的薄弱，甚至要模擬一隻小
狗視覺可能都很困難。小狗有辦法在家裡跑來跑去，即時的閃避障礙物，有辦法辨識出不同的人，
有辦法辨識一些異常的行為，有辦法認得回家的路。所以，電腦視覺其實還有很多的研究可以做，
且這類型的研究牽扯都相當廣。目前世界上有相當多的研究機關甚至是營利單位，都在積極的投
入電腦視覺相關的領域，如微軟 Microsoft 旗下 Natal project 正在研發新一代的遊戲主機 Xbox 360，
他們使用了一種兩個鏡頭的立體視覺攝影機，架設於主機前方，藉由攝影機來抓取玩家的動作與
計畫編號 NSC 97－2221－ E－036－038－MY2 
計畫名稱 以視訊為基礎之手寫輸入與操作系統 
出國人員
姓名 謝禎冏 
服務機構
及職稱 大同大學資訊工程系助理教授 
會議時間 99 年 7 月 5 日至 99 年 7 月 7 日 會議地點 中國大連市 
會議名稱 
(中文)2010 第二屆信號處理系統國際研討會 
(英文)2010 2nd International Conference on Signal Processing Systems 
發表論文
題目 
(中文)使用運動歷史影像進行即時手勢辨識 
(英文) A Real Time Hand Gesture Recognition System Using Motion History Image 
附件四 
F-A1402-002 
大同大學補助教師出席國際會議報告 
99年 4月 28日修訂 
報告人姓名 
中文: 謝禎冏 
英文: Chen-Chiung Hsieh 
單位及職稱 
資工系 
助理教授 
會議正式名稱 
中文: 2010 第二屆信號處理系統國際研討會 
英文: 2010 2nd International Conference on Signal Processing Systems 
發表論文題目 
中文: 使用運動歷史影像進行即時手勢辨識 
英文: A Real Time Hand Gesture Recognition System Using Motion History Image 
會 議 時 間 自 99年 7 月 5日至 99年 7月 7 日 地點 (國、州、城市) 中國大連市 
報告內容：(應包括參加會議心得、建議、攜回資料名稱及內容、其他) 
心得: 
1. 論文報告排在 7/7大會第三天早上第二個 Section，比較以往參加的研討會，論文的數量多的
驚人，也吸引許多國際人士參加，顯示中國大陸舉辦的研討會已逐漸吸引全世界的注意力，
瀏覽論文集，也可以發現論文的品質也不錯，因此大陸的研究學者的研究能力，也逐漸在國
際舞台上吸引注目，對於未來的合作，本人覺得是一個機會。在 2005年中国普通高等学校工
学 100强排名中，遼寧省 5所大学榜上有名，其中主辦單位大连理工大学排名 14位、东北大
学排名 15位，算是不錯的了! 
 
2. 後續將把此論文增修後，投稿到相關期刊論文。 
Computer vision concerns with the theories for building intelligent systems that could obtain 
information from images. The image data can be taken in many forms such as video sequences, views 
from multiple cameras, or multi-dimensional data from specific scanners. Though computer vision has 
been developed for a long time, the commercial applications of computer vision are still few. At the 
present stage, a considerable number of research institutes and companies are active in this field. For 
example, Microsoft’s Natal project is developing a new generation of game consoles Xbox 360 which 
could be operated by hand gestures. To recover the depth information, a two-lens stereo vision camera 
is deployed to capture the player's movements and postures without requiring user to hold any devices 
or sensors. Therefore, multi-cameras based approach to investigate more information for recognition of 
more complicated hand gestures is necessary in the future. 
 
3. 認識幾位先進教授: Wang Jun(The Chinese University of HongKong), Derong Liu (University of 
Illinois at Chicago)，將來可以邀請這些前輩給予指導。 
 
 
本報告請以 A4紙張依式書寫。 
國科會補助計畫衍生研發成果推廣資料表
日期 2010年09月23日
國科會補助計畫
研發成果名稱
發明人
(創作人)
技術說明
技術移轉可行性及
預期效益
技術/產品應用範圍
產業別
計畫名稱:
計畫主持人:
計畫編號: 學門領域:
(中文)
(英文)
成果歸屬機構
(中文)
(英文)
以視訊為基礎之手寫輸入與操作系統
謝禎冏
97 -2221-E -036 -038 -MY2 圖形辨識
基於斷筆偵測之視訊手寫中文
Video Handwritten Chinese Character Recognition System Using Stroke
Segmentation
大同大學 謝禎冏,林倚鈴
本計畫提出一套以斷筆與線上模型為基礎之手寫中文輸入系統，紀錄指尖連續
移動軌跡，利用直線近似法原理將文字表示成一連續的直線段，依照筆劃轉折
點作為特徵的判斷，由於深度資訊已經遺失，因此以文字書寫習慣作為斷筆依
據，並保存筆劃動態資訊。接著以方向、斷筆、前後筆劃所形成的夾角、及長
度比例值四種屬性，組合成一連續的序列字串，在參考字串中，每個字我們建
構了一組以上的線上模型，再以動態規劃之字串差異度比對演算法進行比對，
達到線上即時文字辨識。我們建立了1000個中文字線上模型，邀請了5個人對每
個字寫了3次，斷筆準確率為91.56%，文字辨識率為93.61%。
This project proposes a video handwritten Chinese character
recognition system using stroke segmentation and on-line model. The
trajectory is straight line approximated by finding the turning
points of strokes. Owing to the loss of depth information, character
writing habits are utilized to develop rules for pen-up and pen-down
strokes classification. In addition to stroke direction, stroke
types, stroke length ratio, and angle between two consecutive strokes
are also used to build the character online model as a four tuple
continuous sequence of string. Minimum edit distance by dynamic
programming is deployed to match the input character on-line string
with stored online character models for recognition. We build about
1000 Chinese character on-line models. The accuracy of pen-up and pen資訊服務業；研究發展服務業
IP Camera, Web Cam搭配手勢辨識軟體，手寫文字辨識軟體。
PC/Notebook搭配出售，成為一視訊人機介面，增加產品競爭力；或者單獨以文字輸
入軟體銷售。
註：本項研發成果若尚未申請專利，請勿揭露可申請專利之主要內容。
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
