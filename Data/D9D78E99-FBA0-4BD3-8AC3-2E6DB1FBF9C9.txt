 deteriorate rapidly within one year before bankruptcy. It is 
not easy to make prior forecast. 
 
B.   Bankruptcy Prediction 
 
Beaver studied the financial ratios of 79 health to 79 
crisis firms by discriminant analysis (DA) in 1966 and 
found three ratios—cash flow/total debt, net income/total 
assets and total debt/total assets had higher prediction 
effect than other ratios [10]. Altman proposed multiple 
discriminant analysis (MDA) had better prediction than 
DA. The last year classification correctness before 
bankruptcy can reach 95% and the second-year prior 
bankruptcy was 83% [2]. However, Ohlson proposed 
logistic analysis was better MDA in 1980 [3]. The last 
three-year classification correctness were 96.1%, 95.55% 
and 92.38%. 
Neural network methodologies were applied in firm 
crisis prediction studies since 1990. Odom and Sharda 
studied 64 health to 64 crisis firms sampled from 1975 to 
1982 and concluded the neural network model was better 
than multiple DA 100% vs. 87% in training and 81% vs. 
75% in testing [11]. Coats and Fant chose 93 crisis vs. 
188 health from manufacturing industries between 1970 
and 1989 as training data and concluded the classification 
correctness of BPNN model was 80% with 47 crisis vs. 94 
health as testing [12]. Lee et al. concludes BPNN was 
better than SOM in their 84 vs. 84 samples from 1995-
1998 Korean stock market [13]. 
Kumar and Ravi suggested financial crisis prediction 
model may integrate statistics and neural network to 
enhance the classification correctness [14]. Lee and Kim 
proposed a hybrid model—HYbrid NEural Network-
driven reasoning (HYNEN) in financial crisis 
classification [15]. Empirical study showed HYNEN was 
better than MDA and Analog Concept Learning System. 
Mckee and Lensberg proposed a hybrid model integrating 
rough sets and genetic algorithm in 2002 [16]. The study 
showed the correctness was improved to 83% from only 
using rough sets’ 67%. Hybrid model may have better 
effect than single model in neural network methodology. 
 
C.   Feature Selections 
 
Eta-square method. Eta-squared reflects the percentage 
of dependent variable variance explained by the 
independent variables in the sample data. It is equal to 
sum of square of treatment variable / sum of square of 
total variables. Eta square, also called the correlation ratio, 
is free of the assumption of linearity. In the case of linear 
relationships, correlation ratio equals the coefficient of 
determination. For nonlinear relationships, correlation 
ratio is not equal to the coefficient of determination. Since 
the eta square ratio is independent of the linearity 
assumption, and is also the best solution in the sense of 
the criterion of the least squares, it will be always greater 
or equal to the coefficient of determination. 
 
Stepwise method. Although there are many variations, 
the most basic procedure is to find the single best 
predictor variable and add variables that meet some 
specified criterion. The result is a combination of 
predictor variables, all of which have significant 
coefficients. There are two ways of stepwise regression: 
(1) choose or delete variables and (2) evaluate the 
importance of the factors. 
 
D.   Model Selections 
 
BPNN method. Back-Propagation Neural Network model 
was proposed by Rumelhart and McClelland in 1986. It is 
the most popular methodology in the neural networking. 
In Figure 1, there are three layers in neural network, the 
first layer—input layer, the second—hidden layer and the 
third layer—output layer. The hidden layer can be one or 
more layers, but we adopted the typical three-layer 
architecture in this study. The transfer function was 
sigmoid function as 
f(t)=1/(1+e-t). (1) 
The neurons of input layer were predictors. The 
outputs of neurons in output layer were the output of 
BPNN. There are links to connect the neurons of each 
layer. Every link has a relative weight to represent the 
importance of input information. The algorithm of BPNN 
is to input data from input layer into hidden layer where 
data were transferred by the log sigmoid function, and 
then output into output layer. The link weights of hidden 
layer were revised by the errors between the output value 
and the true value. The purpose of this algorithm is to 
reach the least error square. Repeat this procedure until 
the error square converged to a default condition.  The 
steepest descent method is used to adjust the deviation of 
weight. The adjustment ΔWij  was defined as 
ΔWij ＝ -η(əE/əWij),  (2) 
where ηis the learning rate; E is error function; Wij  the 
weight of link from neuron i to neuron j. 
 
 
Fig. 1. A typical three-layer BPNN architecture. 
 
GRNN method. General regression neural network 
model was proposed by Dr. Donald Specht in 1991. The 
GRNN mainly used in prediction and control. It only 
needs few data to train the neural model and its training 
 occurs when we classify the non-bankruptcy group into 
the bankruptcy group.  
Type II error. It means that the error of rejecting a null 
hypothesis when it is the true state of nature. In other 
words, this is the error of accepting an alternative 
hypothesis (the real hypothesis of interest) when an 
observation is due to chance. In bankruptcy prediction, it 
occurs when we classify the bankruptcy group into the 
non-bankruptcy group. 
Average Correctness. It means the average of probability 
of not rejecting a null hypothesis when it is true state of 
nature and rejecting a null hypothesis when the alternative 
hypothesis is the true state of nature, that is, the average 
of 1 – type I error and 1 - type II error. Average 
 
Fig. 3. The effects of Factor A, B and interaction. 
 
correctness represents the average probability when we 
classify the non-bankruptcy group into the non-
bankruptcy group and bankruptcy group into bankruptcy 
in bankruptcy prediction. 
Power.  It means the probability of rejecting a null 
hypothesis when the alternative hypothesis is the true 
state of nature, that is, 1 - type II error. In bankruptcy 
prediction, it occurs when we classify the bankruptcy 
group into the bankruptcy group.  
 
IV. RESULTS OF EXPERIMENTS  
 
In this experiment we used one-year, two-year, and 
tree-year training data before bankruptcy to train the 
BPNN and GRNN models. The predictors were selected 
by eta square method and those by stepwise method were 
named by eta square and stepwise respectively. Figure 4 
and Figure 5 have the highest average correctness and 
power within these three types of training data shown as 
Figure 6 (a) and (b) for average correctness; (c) and (d) 
for power. There are no significant interaction between 
classification model and feature selection. The types of 
Figure 4 and 5 are similar the type of Figure 3 (b). It 
means there is no difference between the BPNN and 
GRNN. Both the effects of average correctness and power 
of the predictors selected by eta square and those by 
stepwise have difference. The interaction effect is not  
 
 
 
 
Fig. 4. Average correctness of one-year training data before 
bankruptcy. 
 
 
Fig. 5. Power of one-year training data before bankruptcy. 
Applying Back Propagation Neural Network and 
Sequential Pattern Mining to Construct Corporation 
Crisis Prediction Model 
–A Case of Taiwan’s Electronic Industry  
 
Shu-Chuan Lo 
Graduate Institute of Information and Logistics 
Management 
National Taipei University of Technology, 
Taipei, Taiwan 
sclo@ntut.edu.tw 
Ching-Ching Lin 
The Math Group in General Education Center 
National Taipei University of Technology, 
Taipei, Taiwan 
lincc@ntut.edu.tw
 
 
Abstract—Traditional studies utilize data from financial 
statements to construct financial crisis alerting models by using 
statistical methods or artificial intelligence techniques. According 
to these models, researchers can evaluate the possibilities of 
bankruptcy. While these models can predict the future 
operational status with the aid of earlier financial data, they 
cannot consider the continuous classification signals which might 
be helpful to the prediction. Hence, according to priori studies, 
our study not only considers corporate factors and different 
sample matches but also uses financial ratios within different 
periods to construct Back-Propagation Neural Network models. 
Besides, we apply sequential pattern mining to signals of the best 
models, which we construct, in order to gain some prediction 
patterns, which we can utilize to predict a company’s operational 
status of next term. The study shows that the combination of 
Back-Propagation Neural Network model (BPNN) and sequential 
pattern mining can forecast the operational status without any 
financial information of next term and its predicting result is 
similar to the classification result which is made by BPNN. 
Keywords- Prediction Pattern; Back-Propagation Neural 
Network; Alerting model; Sequential Pattern Mining  
I.  INTRODUCTION 
The classification methodologies usually are used to 
distinguish the healthiness of cooperation in financial 
consideration. Classification models need to be trained by a 
past period of data. The classification rules are applied in the 
new coming or some independent data to evaluate the 
correctness of this classification model. This procedure ignored 
the time sequential information. But in general situation, the 
financial crisis will be exposed by the past tracks [1] [2]. These 
classification sequences are valuable information. Researchers 
will get more symptoms if they include the crisis patterns 
mined from failure or bankruptcy corporations. 
The prediction of classification model has no really pre-
warning effect because the classification result is from the 
given or post data. Moreover, the classifications are time 
independent. It can not predict the next classification signal at 
all. In this research, we want to integrate the classification 
method and sequential mining technology to give more precise 
crisis judge than classification for now and predict the next 
classification. 
The procedure of this research was to (1) give the crisis 
definition from literature reviews; (2) decide pairing rules of 
health and crisis companies; (3) choose the data span of our 
samples; (4) pick up meaningful variables from canonical 
analysis; (5) divide samples as training samples and testing 
samples; (6) build classification model by training data; (7) test 
classification correctness by testing samples; (8) mine 
sequential patterns from training data; (9) transfer frequent 
sequential patterns to be predicting patterns; (10) evaluate 
prediction correctness by testing samples.  
The back propagation neural network (BPNN) model has been 
widely used in many applications of classification topics in 
business since 1980s because it does not need to satisfy any 
assumption as statistical classification methodologies. We 
chose BPNN to be classification mechanism in this research 
because research shows it has higher classification correctness 
than multivariate discriminant analysis and self-organizing 
map (SOM) [3] [4]. Sequential mining method was modified 
by Look Ahead x Steps (Lax) [6] [7]. We chose 50 firm pairs 
with similar capital size from Taiwan’s electronic industries. 
We retrieved three-year financial indexes from crisis point in 
each company pair whose data spanned from 1997-2006. 
There are 10 independent extra testing pairs in this study. The 
BPNN was executed by NeuroShell®2. The sequential pattern 
mining was self coded by Borland C++ Builder 6.0. The 
experiments were run on PC with Pentium 43.2GHz and 
1.5GB memory.  
TIC-STH 2009
978-1-4244-3878-5/09/$26.00 ©2009 IEEE 409
B. Back-Propagation Neural Network model 
Back-Propagation Neural Network model was proposed by 
Rumelhart and McClelland in 1986. It is the most popular 
methodology in the neural networking.  
In Figure 1, there are three layers in neural network, the 
first layer—input layer, the second—hidden layer and the third 
layer—output layer. The hidden layer can be one or more 
layers, but we adopted the typical three-layer architecture in 
this study. The transfer function was sigmoid function as 
f(t)=1/(1+e-t). (1) 
The neurons of input layer were predictors. The outputs of 
neurons in output layer were the output of BPNN. There are 
links to connect the neurons of each layer. Every link has a 
relative weight to represent the importance of input 
information. The algorithm of BPNN is to input data from 
input layer into hidden layer where data were transferred by the 
log sigmoid function, and then output into output layer. The 
link weights of hidden layer were revised by the errors between 
the output value and the true value. The purpose of this 
algorithm is to reach the least error square. Repeat this 
procedure until the error square converged to a default 
condition.  The steepest descent method is used to adjust the 
deviation of weight. The adjustment ΔWij  was defined as 
ΔWij＝-η(əE/əWij),  (2) 
where η is the learning rate; E is error function; Wij  the 
weight of link from neuron i to neuron j. 
 
 
Figure 1.  A typical three-layer BPNN architecture 
C. Binary sequential mining 
Binary Sequence Analysis (BSA) was proposed by Chang 
[21] who adapted LAx [6] to mine frequency patterns. 
Therefore, BSA can be applied to mine frequency patterns 
from sequential binary data. 
To ensure that frequency patterns can be mined, Chen et al. 
[6] and Han and Fu [22] mentioned that employing two 
threshold mechanisms can avoid mining inappropriate 
frequency patterns. One threshold mechanism is traditional 
Large Threshold (LT). If the candidate sequence of length 
k (CSk) passes Large Threshold, CSk will become large 
sequence (LSk). The other threshold mechanism is Next Pass 
Large Threshold (NPLT). NPLS examines not only whether 
CSk passed the threshold but also whether CS(k+1), joined by 
LSk passed the threshold. 
The algorithm of BSA was shown as Figure 2, where 
sequence s  was composed of the outcome of a firm, S 
consisted of all sequences s , and D represented all 
classification signals generated by classification model.  
Since BSA mines the frequency patterns from binary 
signals of firms, this study adjusted the threshold of NPLT and 
LT. The new threshold mechanism of NPLT and LT were 
modified and shown as Equation 3. 
Ratio)Support  (Minimum_
*
⋅= totalkSThreshold ,           (3) 
where totalkS _  is the total number of length k in each 
sequences.  
 
1 LS1=<large 1-sequences> 
2 NPLS1=< 1-sequences which pass threshold> 
3 For (k=2;NPLSk-1≠0;k++)do 
4 Begin 
5 CSk=NPLSk-1 join NPLSk-1; 
6 ForAll csk ∈  CSk Do 
7 ForAll s ∈  D Do 
8 count the support csk in S 
9 End 
10 End 
11 
12 
NPLSk={csk|csk∈CSk and Support (csk)≧Next 
Pass Large Threshold} 
13 
14 
LSk={csk|csk ∈ CSk and Support(csk) ≧ Large 
Threshold} 
15 End 
Figure 2.  The algorithm of Binary Sequence Analysis 
 
After BSA mines frequency patterns from binary signals, 
confidence threshold will examine the confidence of these 
frequency patterns. The definition of confidence (AÆB) is 
shown in Equation 4. 
Support(A)
(AB)Support B)(A Confidence =→                               (4) 
In this study, the length of <B> is 1. Since this study is 
only two outcomes in prediction, this study set the confidence 
threshold to be greater than 50% so that it avoided the conflict 
between two classes have 50%confidence at the same time. 
The frequency patterns, which pass the confidence threshold, 
will be transformed into prediction patterns. The prediction 
patterns can provide the next outcome of the sequence. In this 
study, the longer prediction patterns, the more priority to use. 
As BSA predicts the next outcome of a sequence p, the 
prediction patterns will be compared to the sequence p. If the 
prediction patterns equal to the sequence p, the prediction 
patterns provided the next outcome of sequence p . 
411
TABLE IV.  THE PREDICTION PATTERNS AND THRESHOLDS 
Prediction patterns of different thresholds 
threshold=10% health   crisis   
Sequences p9-12 pattern prediction confidence% pattern prediction confidence %
 00 0 64 00 0 60 
 11 1 52.2 11 1 62.9 
threshold=20% health   crisis   
Sequences p9-12 pattern prediction confidence % pattern prediction confidence %
 00 0 64 00 0 60 
    11 1 62.9 
threshold=30% health   crisis   
Sequences p9-12 pattern prediction confidence % pattern prediction confidence %
 00 0 64 11 1 62.9 
 
C. Prediction Evaluation 
After we got the prediction patterns, we applied the health 
prediction pattern, the crisis prediction pattern and both health 
and crisis patterns on the testing samples—10 for health firms 
and 10 for crisis firms. The experimental results are presented 
in Table V, Table VI and Table VII, respectively. Some 
evaluation indexes are defined as following: 
Correctness = the number of correct predict / one period 
total predicts  
Correctness Average = sum of correctness / the number of 
period 
Incorrectness = the number of incorrect predict / one period 
total predicts 
Incorrectness Average = sum of incorrectness / the number 
of periods 
Pattern Unknown Prediction = the number of unknown 
prediction / one period total firms 
Unknown Prediction Average = sum of pattern unknown 
prediction / the number of periods  
 Table V shows the average correctness applying the health 
prediction pattern on 10 health firms is 72.5%. The average 
health pattern incorrectness prediction on 10 crisis firms is 25%. 
The unknown prediction is quite high with 51.25% on average 
for 20 testing firms. Table VI presents the average correctness 
applying the crisis prediction pattern on 10 crisis firms is 
52.5%. The average crisis pattern incorrectness prediction on 
10 health firms is 20%. The unknown prediction on average 
reaches 63.75% for 20 testing firms. These two tables exhibit 
the incorrectness of single pattern is within acceptable range 
20-25%, but there is quite high unknown prediction rate for 
single pattern prediction. Nevertheless, if we applied these two 
patterns on the 20 testing firms in Table VII, we found a firm 
only got neither health nor crisis prediction. There was no 
conflict prediction appearance. The incorrectness was 22.5% 
on average, within our expectation from the impression of 
single pattern testing. But the unknown prediction had 
significant reduction to 15%. The average correctness for both 
health and crisis patterns applying our 20 firms was 62.5%. It 
seems not very high for this absolute comparison. But if we 
exclude the unknown prediction, the average correctness may 
raise to 73.67% for all known predictions. 
TABLE V.  TESTING RESULTS OF HEALTH PREDICTION PATTERN ONLY 
Testing Data—Health Firms 
Period 9 10 11 12 
Predict health 6 7 8 8 
Predict unknown 4 3 2 2 
Correctness 60.00% 70.00% 80.00% 80.00%
Correctness Average 72.50% 
Testing Data—Crisis Firms 
Period 9 10 11 12 
Predict health 2 4 2 2 
Predict unknown 8 6 8 8 
Incorrectness 20.00% 40.00% 20.00% 20.00%
Incorrectness Average 25.00% 
Single Pattern Unknown Prediction 60.00% 45.00% 50.00% 50.00%
Unknown Prediction Average 51.25% 
TABLE VI.  TESTING RESULTS OF CRISIS PREDICTION PATTERN ONLY 
Testing Data—Crisis Firms 
Period 9 10 11 12 
Predict crisis 5 6 5 5 
Predict unknown 5 4 5 5 
Correctness 50.00% 60.00% 50.00% 50.00%
Correctness Average 52.50% 
Testing Data—Health Firms 
Period 9 10 11 12 
Predict crisis 2 2 2 2 
Predict unknown 8 8 8 8 
Incorrectness 20.00% 20.00% 20.00% 20.00%
Incorrectness Average 20.00% 
Single pattern unknown prediction 65.00% 60.00% 65.00% 65.00%
Unknown prediction average 63.75% 
 
 
 
413
無研發成果推廣資料 
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
兩篇國際期刊論文 (IEEE EI Index) 
一篇國內期刊論文 
兩位碩士生培訓 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
