2As for human detection, we propose an
algorithm of combining Histograms of Oriented
Gradients(HOGs) with global feature for human
detection from a non-static camera. We use
AdaBoost algorithm to learn local characteristics of
human based on HOG by giving massive training
samples. The idea of this work is to incorporate the
global feature for improving the detection accuracy.
Here, we adopt the head contour as the global
feature. The combination of the human detector
based on local features and head contour is achieved
through the adjustment of the hyperplane of support
vector machine
影像監控系統隨著相機製造技術日益成熟及
資料處理單元運算速度不斷提升，目前已廣泛裝
設於諸多環境中。相機影像資訊相較電流感測
器、壓力、或紅外線移動感測器等，其主要優點
在能完整感測環境資訊。人類活動感知(Human
Activity Perception) 為 目 前 影 像 監 控 系 統中
(Surveillance System) 重要核心技術之一，主要目
的在辨識環境中之人類活動類別，以作為系統提
供後續服務或啟動相關機制之重要決策依據。智
慧型環境應用(Intelligent Space)主要藉由感知居
住者活動狀態，自動調整環境狀態以符合使用者
需求，例如:啟動空調、撥放音樂或開啟電視，使
居住者感受到舒適與放鬆；老人健康照護應用中
(Health Care)，藉由辨識老年人活動狀態，當不尋
常行為(Abnormality)發生時，例如：跌倒或日常
生活習慣改變，系統可連繫醫護人員以迅速提供
相關醫療服務與諮詢。
應用電腦影像處理技術於多攝影機系統進行
無間隙人類活動感知技術已成為當前潮流。於此
研究計畫中，期望透過電腦視覺達到涵蓋智慧型
環境空間之人形偵測與追蹤，並達成多目標無間
隙追蹤與定位，最後針對空間中之人形進行姿態
估算與人類活動辨識，以提供使用者所需之數位
內容與服務。目前所提出之系統架構，其主要基
於下列三項假設 :(1) 所有相機皆固定不動
(Static) ； (2) 影 像 皆 可 同 步 擷 取 影 像
(Synchronized)。(3)相機網路系統其視野涵蓋所欲
監控之範圍，意即系統可獲得完整人類活動影像。
所欲辨識之人類活動，皆會呈現相對應之影像變
化。系統中每臺影像擷取裝置，首先會獨立對影
像進行下列處理步驟:前景切割 (Foreground
Segmentation)、人形偵測(Human Detection)、姿態
估 算 (Pose Estimation) 以 及 人 形 追蹤 (Human
Tracking)。前景切割主要目的為將前景自背景中
分離出來；人形偵測則在定位出所擷取前景中人
形位置。為獲得更充分之人類活動資訊，需進一
步估算影像中人形之姿態並進行追蹤，經過上述
處理後，其輸出為人形於單一相機監控視野中之
運動軌跡與姿態變化。於本計畫主要利用全景相
機以監控空間中場景，接著利用 PTZ 相機來定位
與追蹤所偵測之前景物體，並進行人形之偵測，
以利後續人類活動之辨識。
三、基於全景資訊之 PTZ 物體定位與切割
於智慧型監視系統中，一般攝影機視覺範圍狹
窄，其視角通常無法涵蓋所欲監控範圍。目前研
究中主要方式為透過安裝多個相機用以擴增監控
範圍，然此種作法須對環境中所裝設之相機進行
校正與定位，因此無法被廣泛應用於現有環境
中。因此，本研究主要概念為先經由全景攝影機
(Omni-Directional Camera)達成全場監視與目標物
的分析，在控制系統中經由 PTZ 攝影機進行目標
物定位與偵測。但由於 PTZ 攝影機其背景會隨著
運動而改變，因此無法透過背景模型方式進行前
景切割與物體偵測。為有效克服上述問題，本研
究提出一個演算法，先經由全景攝影機偵測出影
像中之前景物體，接著透過分享攝影機彼此分析
的資料，提供 PTZ 攝影機相關前景與背景資訊，
以進一步達到背景切除與偵測之目的。
對於多攝影機監控系統之研究，主要以物體追
蹤之準確性為研究目標。於文獻上主要可分為兩
類：一般多攝影機系統與全景攝影機結合 PTZ 攝
影機系統。一般多攝影機系統，大部分由多台固
定視角攝影機監視其區域，由於此系統一般使用
相同且視角固定攝影機，達到範圍較大環境之監
控。圖一為一般多攝影機系統之關係圖，圖中表
示各攝影機彼此位階相等，此類研究應用主要在
探討如何定位與追蹤物體於空間中之軌跡。[1] 則
4所示，全景攝影機一般採用魚眼鏡頭，使其視角
接近或等於 180°，可有效達到大範圍之影像其影
像(效果如圖四(b)所示)，然而由於鏡面曲率關
係，所獲得之影像會有嚴重之扭曲(Distortion)，由
圖可見影像離中心越遠，其變形現象越嚴重，導
致其無法直接轉換對應至世界座標系，故全景相
機影像須先進行扭曲校正。
圖三、兩攝影機座標幾何關係
(a) 全景相機 (b) 全景相機影像
圖四、兩攝影機座標幾何關係
本研究目前依據 Chen[3]所提出之構想，採用多個
校正點之方式，建立全景影像位置與世界座標之
對應方程式，以解決其扭曲所導致之對應問題。
於此研究中假設世界座標原點為最接近全景攝影
機所在位置正下方地面的校正點，如圖五所示其
中藍線為其世界座標軸方向，因此全景攝影機所
在位置可表示為  OOOO ZYXP ,, ，其中 OZ 為攝影
機高度，於 0Z 之平面上設立 N 個校正點，其座
標 表 示 為  NiZYXP iiii ,...,1:),,(  ， 其 中
NiZi ,...,1:0  而假設此 N 個校正點成像於全
景 攝 影 機 之 影 像 中 座 標 為
 Niyxp iii ,...,1:),(  ，如圖五(b)所示。
圖五、(a) 世界座標原點 (b) 實驗場景與校正點
由於全景影像扭曲以影像中心開始向外擴散，首
先將影像中位置座標 ii yx , 轉換為相對於中心之
之座標   ciciiii yyxxyxp  ,ˆ,ˆˆ ，其中 cc yx , 為
全景影像之中心點座標，依據[9]中所提出之布朗
扭曲模型(Brown's distortion model)，世界座標點
iP 與 ipˆ 之關係可依下列方程式表示。
ixixixixiix
iixiixiixix
iixiixiixixxi
ryxyx
rxrxrxy
rxrxrxxX
,12,
2
11,
2
10,9,
62
8,
42
7,
22
6,5,
6
4,
4
3,
2
2,1,0,
ˆˆˆˆ
ˆˆˆˆ
ˆˆˆˆ






(1)
iyixixixiix
iiyiiyiiyiy
iiyiiyiiyiyyi
ryxxy
ryryryx
ryryryyY
,12,
2
11,
2
10,9,
62
8,
42
7,
22
6,5,
6
4,
4
3,
2
2,1,0,
ˆˆˆˆ
ˆˆˆˆ
ˆˆˆˆ






(2)
其中 22 ˆˆ iii yxr  ， ix , 與 iy , 為校正誤差且  0, ixE  且   0, iyE 。  Tyxx 12,0,   為
iX 線性迴歸模型係數。  Tyyy 12,0,   為 iY
線性迴歸模型係數。表一為挑選參數數量 3~8 其
各種組合，於其估測值與實際值平方差總合(Sum
of Square Error)最小之組合，從中選出最少參數且
達到平均誤差小於 1 為最佳結果。最後定義 . 為
將全景座標系轉換至世界座標之轉換方程式，其
可表示為 ii pP  。
表一、參數估算結果
參數數量 xˆ SSE yˆ SSE
3 7.26426 4.51329
4 4.11770 2.49858
5 1.78844 0.73903
6 0.75395 0.53155
7 0.72196 0.37555
8 0.65658 0.36243
基於全景影像中之影像位於 0Z 平面上之
假設，透過上述演算法，可求取出全景影像點之
世界座標，於下列討論中，將探討如何計算 PTZ
與世界座標系間之轉換關係。  PPPP ZYXP ,, 為
PTZ 攝影機位置的世界座標， iiTiP f,, ,,  為使
PTZ 攝 影 機 影 像 中 心 點 對 準 世 界 座 標 點
)0,,( iii YXP  ，PTZ 所需控制之三個參數 Pan,Tilt,
6     )(
|)(
)(|
pIP
bgPbgpIP
pIbgP O
T
O
TO
T  (8)
其中由於   bgPpIP OT , 無法計算得知，因此假設
 
 pIP
bgP
O
T
為常數，  bgpIP OT | 為 p 位置像素與背
景模型的相似度，透過計算 p 位置像素與屬於 p
位置背景高斯之機率，其計算方式可依下列方程
式表示。
   


 iiOTO ibgOT pIGLpbgpIP ,;,| , (9)

 
   



 





i
O
Ti
T
i
O
T
i
ii
O
T
pIpI
pIG



1
2/12/3
2
1
exp
2
1
,;
(10)
最後藉由一個門檻值 OmniTh 用來判定其機率
是否屬於背景，若其機率大於所設定之門檻值
OmniTh ，則將影像點 p歸類為背景，圖 3-7 為背景
濾除之結果，其中白色部分為前景，黑色部分則
為背景。
圖九、前景偵測結果圖
於全景系統取得前景資訊，其中包括前景之物
體位置與色彩資訊，PTZ 系統透過全景攝影機所
偵測之前景位置資訊，可估算其於空間中之座標
並進而控制攝影機方向以追蹤物體。並透過整合
物體前景與背景色彩資訊，進一步達成物體前景
切割。全景攝影機首先將背景濾除之結果，框選
出感興趣物體，並計算其位置與色彩高斯模型。
於 PTZ 系統端，首先將前景世界座標轉換為 PTZ
旋轉座標，透過 PTZ 旋轉座標控制攝影機方向。
透過前景世界座標轉換關係，建立物體可能於影
像中位置之可能性高斯模型，接著將輸入影像透
過色彩分群量化其色彩，透過整合空間與色彩資
訊以達到背景濾除。
為控制 PTZ 攝影機以達到物體定位之目的，
首先須計算前景物體之世界座標，因此首先計算
於全景系統偵測之物體，物件a其影像區域重心
ac ，透過上述所介紹之世界座標轉換方程式，可
計算出 aC 中心點之世界座標位置。並將 aC 及色彩
資訊傳送到 PTZ 系統，以提供 PTZ 作為物體定位
與前景切割之依據。
於前景物體定位部分，首先將藉由物件位置
資訊，透過其位置資訊於空間中的關係，計算物
體於實際空間中位置，最後控制 PTZ 攝影機追蹤
其位置。由於轉換方程式的座標是以地面為基準
所建立，因此透過物件重心所得出 aa cC  ，其
於實際空間位置之關係，如圖十所示，其中
aH
P 為
物件於實際空間中站立位置， h表示為人一半的
身高， 0P 為全景攝影機之於地面座標。因此透過
相似三角形原理，即可推得物件於實際空間中站
立位置，可依以下方程式求得。
圖十、實際物件位置與其轉換座標關係圖
而 PTZ 攝影機對物體之定位，可藉由上述得
到人所站立之位置，為了使追蹤目標物在影像正
中間，設定追蹤點為人的中心點  hP
aH
,0,0 ，再
透過前述 PTZ 座標轉換，最後呼叫攝影機去追蹤
此座標，圖十一為經由上述 PTZ 攝影機依據全景
攝影機之前景位置資訊，對前景物體定位結果，
明顯可見，前景物體被定位於 PTZ 攝影機影像中。
8Representation 來描述人類行走之特性，透過統計
學結合真實(Real)和人造(Synthetic)行人之行走所
組成的一張 GEI (Gait Energy Image)來達成行人
偵測與識別。
4.1 特徵點分類器
為了能夠準確的區分行人與非行人，須選出
有效之特徵來做為行人特徵點，Dalal et al.針對不
同之特徵，包括 HOGs (Histogram of Oriented
Gradients)、Haar Wavelets、PCA-SIFT 以及 Shape
Context 等，運用於行人偵測上進行分析與討論，
其結果顯示 HOG 較能克服行人外觀之變化且偵
測效果良好。因此本研究採用行人區域特性之
HOGs 來做為本分類器系統基礎。先將欲偵測影
像畫分為許多不同大小之區塊(Block)，接著針對
所選取區塊之所有影像點，依據下列之方程式計
算其梯度強度及方向：
),1(),1(),( yxIyxIyxd x  (11)
)1,()1,(),(  yxIyxIyxd y (12)
22 ),(),(),( yxdyxdyxm yx  (13)
),(
),(
tan),( 1
yxd
yxd
yx
x
y
(14)
接著將每個區塊分為四單元(Cell)(如圖十三(a)
所示)，於每一單元中，我們統計其梯度強度在不
同九個方向之長條圖(Histogram)，每 40 度為一個
方向。換言之，一個 9 維向量 },....,,{ 921 vvv 可表示
一 個 單 完 的 外 觀 ； 一 個 36 維 向 量
},...,,....,,{ 36921 vvvv (分別對應至四個單元如圖十三
(b)所示)可用來表示一個區塊的外觀，此表示法
稱為 HOGs。
圖十三、HOGs 特徵表示過程
對於每個區塊，經由上述 HOGs 特徵點表示
法，其對應到一個 36 維向量，為在此 36 維空間
中有效區分行人與非行人特徵之差異，主要採用
線性支援向量機(Support Vector Machine)演算法
求出一個特徵點分類器，用以判斷一個給定的特
徵區塊是否屬於行人特徵。首先針對每筆不同類
的訓練資料 (Training Data)，分別以”+1”或”-1
”標示行人及非行人樣本。則線性支援向量機主
要的目的，在找出一個超平面稱為區分平面
(Separating Hyperplane)，能夠有效的將標註為
“+1”和標註為“-1”之二類資料區分；而線性
支援向量機的主要想法是希望所獲得之超平面能
夠使得訓練資料和區分平面之邊界值最大。然而
為求能表示出人形各種不同種類大小的特徵，並
以三種不同大小比例之方型區塊(1:1), (2:1),與
(1:2)來表示。
在將影像切割成許多區塊(Block)，及透過線
性支援向量機學習到所對應區塊之特徵分類器
後，為有效提升辨識的效率，將每個特徵分類器
視為獨立之 Weak Classifier，利用 AdaBoost 演算
法選取出數個最有效之 Weak Classifiers 組成所
謂 Strong Classifier 來達成行人偵測的目的。其訓
練樣本初始權重皆為相同，透過反覆抽取概念，
根據每回合所挑選之 Weak Classifier 的判斷，更
新分類錯誤的樣本權重，使得較難分辨的樣板權
重增加，易於辨識的樣板權重降低，達到挑選出
最有效的 Weak Classifier。
4.2 頭部全域特徵
依據上述描述中，一個基於行人區域特性之
梯度方向直方圖所架構出的分類器用以偵測影像
中是否存在行人特徵達到辨識。但其缺乏行人全
觀知識的區域特性分類器往往會受到凌亂複雜背
景的梯度資訊所影響，造成誤判使錯誤正確率
(False Positive Rate)增加，並且降低可靠性。因
此，為了要改進此缺失，增強分類器之準確度，
本論文提出行人形全域頭部輪廓整合到分類器
中。由於人們多樣化的外觀與高自由度的肢體動
作等，常會造成判斷上的困難與不確定因素的產
生，因此要能夠在行人身上找到一個可靠、穩固、
變動性小的全域特徵並不容易。有鑑於此，經過
觀察許多行人影像後發現，不管於行人之側面或
正面肩膀以上的頭部輪廓遮蔽不易，且相對於其
它的肢體變動性相對小的許多且較為可靠。
利用樣板比對之前，首先必須將樣板影像做
距離轉換(Distance Transform)，假設 F表示一特徵
影像（二值化的）中的特徵點集合，則對於該影
10
誤正確率相對。這表示對於實際輸入非訓練之影
像，因全域特徵之整合有效的提升偵測的結果，
不僅大幅提升實際影響之行人偵測率也降低錯誤
正確率之誤判現像。而在基於 AHOG 分器方面，
整合全域特徵之 AHOG+G 分類器也比原 AHOG
更為準確，雖然說整體錯誤正確率略為降低(約
1%)，但對偵測率與錯誤正確率間之權衡關係而
言，其偵測結果算是獲得有效之提升。
圖十五、不同數量 weak classifiers 之測試影像偵測率
五、參考文獻
[1] Francois Fleuret, Jerome Berclaz, Richard Lengagne and
Pascal Fua, “Multicamera People Tracking with a 
Probabilistic Occupancy Map,” IEEE Trans. Pattern
Analysis and Machine Intelligence (PAMI), vol. 30, no. 2,
pp. 267-282, 2008.
[2] S. Khan and M. Shah. , “Consistent labeling of tracked 
objects in multiple cameras with overlapping fields of
view”,  IEEE Trans. PAMI, 25(10):1355-1360, Oct. 2003
[3] C.-H. Chen, Y. Yao., D. Page, B. Abidi, A. Koschan,,M.
Abidi, “Heterogeneous Fusion of Omnidirectional and 
PTZ Cameras for Multiple Object Tracking”, IEEE
Transactions on Circuits and Systems for Video
Technology, Vol. 18, NO. 8, pages 1052-1063, August
2008.
[4] G. Scotti, L. Marcenaro, C. Coelho, F. Selvaggi, and C. S.
Regazzoni,“Dual camera inteligent sensor for high 
definition 360 degrees surveillance,” Vis., Image, Signal
Process., vol. 152, no. 2, pp. 250–257, Apr. 2005.
[5] 王志高, 吳先晃, “Video Surveilance System Based on 
Omni-directional and PTZ Cameras”,Proceedings of the
2005 Workshop on Consumer Electronics and Signal
Processing (WCEsp 2005), 2005.
[6] Chung-Hao Chen, Yi Yao, , Anis Drira, , Andreas
Koschan, and Mongi Abidi, “Cooperative Mapping of 
Multiple PTZ Cameras in Surveilance Systems,” IEEE
Conference on Computer Vision and Pattern Recognition
(CVPR 2009), June, 2009.
[7] T. Y. Li, C. M. Wang, Y. I. Hung, K. C. Fan, “A Visual 
Monitoring System Using Wide-Angle Cameras and
Pan-Tilt Camera”, IPPR Conference on Computer Vision,
Graphics and Image Processing (CVGIP), 2004.
[8] Chih-Ming Chen, Kuo-Chin Fan, “The Using of Omni and 
PTZ Cameras in Constructing In-door Surveillance System
for Face Recognition,” Department of Computer Science
and Information Engineering National Central University,
2004.
[9] D.C. Brown, “Decentering Distortion of Lenses,” 
Photogrammetric Eng., vol. 32, no. 3, pp. 444-462, May
1966.
[10] K. A. Patwardhan, G. Sapiro, and V. Morelas, “Robust 
foreground detection in video using pixel layers,” IEEE
Trans. Pattern Anal. Mach. Intell. 30(4), 746–751 ,2009.
[11] 林 莉 鳳 , “Rapid Pedestrian Detection for Driving
Assistance System using AdaBoost and Template
Matching Technique”, 國立中央大學資訊工程研究所 ,
台北 , 2007 .
[12] Mohan , C.Papageorgiou , and T.Poggio, “Example-Based
Object Detection in Images by Components “, IEEE
Transactions on Pattern Analysis and Machine
Intelligence , vol. 23, pp . 349-361, 2001 .
[13] D. M. Gavrila , “Multi-cue Pedestrian Detection and
Tracking from a Moving Vehicle”, International Journal
of Computer Vision, 2007 .
[14] Tao Zhao, Ram Nevatia , and Bo Wu ,“Segmentation and 
Tracking of Multiple Human in Crowded Environments ”,
IEEE Transactions on Pattern Analysis and Machine
Intelligence , 2007 .
[15] F.Suard, A.Rakotomamonjy, A. Bensrhair and A.
Broggi,“Pedestrian Detection using Infrared image and 
Histogram of Oriented Gradients”, Intelligent Vehicles
Symposium 2006 , June 13-15 , 2006 , Tokyo , Japan .
[16] Bastian Leibe, Edgar Seemann, and Bernt Schiele,
“ Pedestrian Detection in Crowded Scenes” , IEEE
Transactions on Pattern Analysis and Machine
Intelligence, 2005.
[17] Ju Han and Bir Bhanu,“Individual RecognitionUsing Gait
Energy Image”, IEEE Transactions on Pattern Analysis
and Machine Intelligence, VOL. 28, NO. 2, FEBRUARY
2006.
1國科會補助專題研究計畫項下出席國際學術會議心得報告
日期： 99 年 10 月 24 日
一、參加會議經過
ICGCS2010 國際會議今年於中國大陸上海舉辦，恰逢世博盛會，因此與會人數相當踴躍。此次
會議共計三天，於前兩天會議中本人主要參與以探討節能設計為主之電路與系統設計，以及應用
於影像與電路之最佳化演算法之議程，透過與國際學者討論的過程中，對此些領域之知識與技術
有更進一步之認知與瞭解。第三天議程中，本人共有兩篇論文於大會報告，報告過程中經由討論，
提供我對自己之研究主題新的想法與方向。此外，於會議議程相當緊湊，除了白天的論文發表外，
第二天晚上亦安排文化響宴。
二、與會心得
參與國際會議三天過程中，可以感受出主辦單位之用心，於議程內容安排上非常適當，會議場
地與動線規劃非常流暢，令人有賓至如歸的感受。在會議上，可看到許多學者針對問題，基於不
同的想法與觀點，提出不同之學理與系統來解決問題，足讓人眼界更加寬闊，均有助益於研究上
能夠更加精進不致淪為閉門造車。
計畫編號 NSC-98-2221-E-327-031-
計畫名稱 基於多相機系統之無間隙人類活動感知技術
出國人員
姓名
黃世勳
服務機構
及職稱
國立高雄第一科技大學電腦與通訊系
會議時間
99年 6月 21日至
99 年 6月 23 日
會議地點 上海
會議名稱
(中文) 綠色能源電路與系統國際研討會
(英文) International Conference on Green Circuits and Systems
發表論文
題目
(中文)(1)基於貝式濾波器之乘客辨識系統；(2)以影像為主之高速公路車輛追蹤
與分類
(英文)(1) Occupant Classification for Smart Airbag Using Bayesian Filtering；(2)
Image-Based Vehicle Tracking and Classification on the Highway
無研發成果推廣資料 
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
國科會補助專題研究計畫成果報告自評表 
請就研究內容與原計畫相符程度、達成預期目標情況、研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）、是否適
合在學術期刊發表或申請專利、主要發現或其他有關價值等，作一綜合評估。
1. 請就研究內容與原計畫相符程度、達成預期目標情況作一綜合評估 
■達成目標 
□未達成目標（請說明，以 100字為限） 
□實驗失敗 
□因故實驗中斷 
□其他原因 
說明： 
2. 研究成果在學術期刊發表或申請專利等情形： 
論文：■已發表 □未發表之文稿 □撰寫中 □無 
專利：□已獲得 □申請中 ■無 
技轉：□已技轉 □洽談中 ■無 
其他：（以 100字為限） 
國際會議論文 
已發表: CVGIP2010 
未發表: MMM2010 
 
國際期刊論文 
審查中: IEEE Transactions on Intelligent Transportation Systems 
 
