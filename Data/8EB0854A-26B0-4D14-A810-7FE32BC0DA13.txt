The segmented objects are described by means of a 
2D model that outlines the interrelations between 
primitive geometric image features such as lines, 
vertices, and ellipses. Extracted image features are 
used to define the model properties and construct a 
model of a manmade object of interest [4]. 
Computer perceptual of manmade objects in 
outdoor scenes is a challenging task due to the 
presence of both manmade and natural objects.  
Manmade objects in contour are generally rigid, 
therefore these models can adequately define their 
shape descriptions. However, the model-based 
approach is limited by the lack of 3D or 2D 
representation of natural objects. They require a 
prior knowledge about the shape of objects (object 
models), which is used to predict image features or 
match features in the image or in a transformed 
feature space. Manmade objects are used to 
described the object in natural image are 
unspecified and their appearance is unpredictable. 
Very few objects have compact shape descriptions, 
and it is difficult to establish complete boundaries 
between the objects of interest and background 
objects. The complexity of this task depends on 
many factors, such as the number of objects in the 
model database, and the amount of prior 
information about the scene. Iqbal and Aggarwal 
proposed an interesting way to extract the image 
structure from large manmade objects for image 
retrieval by perceptual grouping [5]. 
 Broadly speaking, the shape recognition 
problem can be approached with three main 
frameworks [6]: the statistical approach, the 
syntactic approach, and the hybrid of the two 
methods. The statistical approach uses global shape 
features, such as moments [7], autoregressive 
coefficients [8], and Fourier descriptors [6] to 
recognize shapes. Edge features are recognized as 
an important aspect of human visual perception and 
commonly used in shape analysis. The system [5] 
analyzes each image to extract features that are 
strong evidence of the presence of these objects. 
These features are generated by the strong 
boundaries typical of manmade structures: straight 
line segments, longer linear lines, coterminations, 
cotermination groups, “L” junctions, “U” junctions, 
parallel lines, parallel groups, “significant” parallel 
groups, and polygons, and uses the k-nearest 
neighbor framework to classify these features. 
There are some deficiencies in the system [5]. One 
problem is the database size will affect the 
efficiency for the image classification and retrieval. 
Another problem of the system is it is hard to 
define the similarity measurement. 
In this study, an efficient shape matching 
method is used to recognize shapes of objects using 
the proposed two consecutive primitive-edge 
differences (TCPD). Each given image is first 
segmented into several non-overlapping regions 
and then scan for different-attributed edges. For 
speed and efficiency, we extend the TCPD in a 
query image into several visual- pattern structures 
that are used to match the images from a large 
database. The basic principle of shape recognition 
in the proposed method is invariance to translation, 
rotation, and scale changes.  
 
三、 Shape Descriptions 
Segmentation of an image to obtain different 
regions followed by the analysis of their structural 
information to recognize the desired features is a 
top-down approach. Automatic segmentation and 
recognition of objects via object models is a 
difficult task, and the quality of segmentation 
directly affects the performance of an image 
retrieval system. Many researches focus on the 
moment-based operators have been successfully 
developed for image edge detection. For edge 
location computing [9], Pei and Cheng [10] applied 
the BQMP (binary quaternion-moment-preserving) 
thresholding technique to detect color edges with 
the precision to subpixel accuracy. A survey on 
moment-preserving thresholding algorithm has 
been developed by Tasi [11]. The 
moment-preserving principle has also applied to 
detect the edge of images in this paper.   
3.1 Proposed of edge detection 
A subpixel edge-detection modeling using the 
moment-preserving principle has been proposed 
[11,12]. In this model, the image will be partitioned 
into non-overlapping 4×4 blocks, and be applied to 
the moment-preserving principle to find the 
solutions of the parameters h1, h2, l, and θ  of the 
edge [13], where h1 and h2 are two representative 
colors of the block and the values of l and θ  are 
used to locate the edge at the block. In the uniform 
consecutive primitive differences (TCPD) method. 
  The proposal for two consecutive primitive 
differences method is based on chain-code method. 
Chain-code is widely used for describing edge 
drawings in image processing and recognizing, 
which was firstly proposed by Freeman in 1961[24]. 
In the chain-code process, the point coded moves 
along the digital curve or edge pixels with 
8-adjacency model in 8-direction code.  A 
boundary chain starts with a random point in the 
edge pixels. Each edge pixel has 8 neighboring 
points among which there is at least one edge point. 
The boundary chain-code is the direction 
description of the current point to the next one. The 
number 0 to 7 is used for direction description in 
8-direction chain-code as shown in Fig. 1.  
 
Fig.1. 3×3 grid and 8-direction codes 
An object edge in an image can be described 
with a start point and sequence direction codes as 
above. There are some problems of the chain-code 
method. First, the chain-code varies dramatically 
with different start point. Selecting the proper start 
point on the chain-code is a common process. 
Another problem is that the chain-code method 
cannot overcome to rotate and scale the object in an 
image. Based on the chain-code method, the 
consecutive primitive difference is proposed to 
describe the shape of an object. The concept of 
consecutive primitive edge difference (CPD) is as 
follows: 
CPD (Hi+1~Hi)=|Hi+1-Hi|             (1) 
where Hi and Hi+1 denote the consecutive primitive 
edges respectively. The detected CPD is mapped to 
7 types of visual patterns, as shown in Fig. 2. This 
assumes that the possible CPD in a 3×3 block are 
limited to multiple of 450 and it is quantized to be 
the nearest multiple of 450.  
 
 
Fig. 2. Possible 7 types of visual patterns in a 3×3 
block. 
Some types of CPD in the sense of human 
vision is the same in Fig. 2 such as CPD=1 and 
CPD=7, CPD=2 and CPD=6, and CPD=3 and 
CPD=5. The equation (1) is reformulated as 
follows: 
       
.
4|||,|8
4|||,|
)~(
11
11
1 ⎭⎬
⎫
⎩⎨
⎧
>−−−
<−−=
++
+++
iiii
iiii
ii HHHH
HHHH
HHCPD       (2) 
The histogram of virtual pattern is used to 
describe the shape representation in this paper. For 
practical purposes, the CPD method cannot 
efficiently and correctly described the shape of 
object in the equation (2). As shown in Fig. 3, the 
histogram of virtual pattern is the same as using the 
CPD method because it is discrete. To solve this 
problem, the equation (2) is modified into TCPD as 
follows: 
)()()~( 1212 ++++ −∪−= iiiiii HHCPDHHCPDHHCPD  (3)    
where notation ∪ denotes a union operation. 
Instead of representing edges in any possible 
combination, the detected TCPD is mapping to 49 
types of virtual pattern, as shown in Fig. 4. Note 
that the relationships among virtual-pattern 
organization and some virtual-pattern structures are 
the same from the sense of human vision such as 
Fig. 4(3, 6, 17, and 41), and so on. Thus, the 49 
types of virtual pattern are further merged into 20 
types of virtual-pattern. The remainder can be 
mapped into the 20 types of virtual-pattern through 
it is rotation or scaling. The 20 types of 
virtual-pattern are organized as shown in Fig.5. 
 
 
 
Fig. 3. An example for illustration the CPD 
method. 
segment semantic objects in an image as a single 
segment. For example, a color-based segmentation 
will segment a multicolor national flag into 
multiple segments, and thereby destroy the object 
semantics. A semantic object represents a group of 
segments whose relative shape, size, and spatial 
organization as a whole define the user’s notion of 
an object. Especially, the semantic object is 
grouped from multiple regions which shapes are 
connected (containing coterminal edge structure 
and/or coterminous line) with each other. In this 
paper, a semantic object is defined using a group of 
multiple regions or a single region dependent on 
whether the regions are connected each other.  
To obtain the same TCPD for any structure 
which includes one or more enclosed regions. The 
starting point is found by the following algorithm 
and an example shown as Fig. 7 to illustrate the 
process of PSPER. 
Algorithm 1. Proposes a searching algorithm to 
find the starting point of an enclosed region 
(PSPER). 
Input: An enclosed region. 
Output: A starting point. 
Method: 
1. Determinate the long axis of the region. 
2. Compute the center of the long axis. 
3. Compare the distance between the primitive 
edge of the region to the long axis, and assume 
the distances are represented as A={a1, a2, a3,…, 
an} and B={b1, b2, b3,…, bn}respectively. 
4. Find the max(|ai-bi|), i=1,2,…n. 
5. If the (max(|ai-bi|)) is not single, the max(|ai-bi|) 
is determined according to the far distance of ai 
and the center of the long axis. 
6. If(ai>bi) ai is the starting point. 
7. else bi is the starting point. 
 
Fig. 7. An example is given to illustrate the 
extraction of starting point. 
The proposed TCPD extracted from an image 
is shown as follows. 
Algorithm 2. Proposed a serial of TCPD extracted 
from an image. 
Input.  An image. 
Output. A set of TCPD serials. 
Method: 
1. Determine the starting point. 
1.1. If the region is segmented by the primitive 
edge which is small fragments grouped to form 
longer edge lines, the starting point is decided 
according to equation (5). 
1.2. If the region is an enclosed region, the 
starting point is decided using algorithm1.   
2. A serial of TCPD extracted according to the 
following rule. 
  2.1. The scanning sequence uses the clockwise 
method in any enclosed region. 
  2.2. The serial of primitive edge Hi, Hi+1, and 
Hi+2 extracted according to the Depth-First 
Search (DFS[14]) algorithm, to avoid the 
information loss, the front fragment of Hi+2 
and the rear fragment of Hi is overlapped. 
  2.3. If next fragment is a cotermination 
structure, the next fragment is determined 
using the equation (7). 
  2.4. If the edge is a coterminal edge which is 
only scanned one time. 
 
五、 Similarity measurement of shape 
representation 
Consider a database DB consisting of a large 
number of images. Each of them is represented as a 
high-dimensional feature 
vector },...,1;20,...,1},,{{ njijpifF === , where fi , 
and pj are the ith feature and the corresponding of 
number of TCPD in Fig. 5, respectively. The total 
number of TCPD in an image can be computed as 
          ∑
=
=
20
1
,
i
jiPχ                 (8) 
Let }20,...,1},,{{ == iipixX and 
}20,...,1},,{{ == jjqjyY  be feature vectors. Then the 
distance between X and Y based on the concept of 
QBIC method [27] is computed as 
 ∑ ∑∑∑
= =
−
=
+
=
=
20
1
20
1
,2
20
1
2
20
1
2),(2
i j
jqipjia
j
jq
i
ipYXD
        (9) 
