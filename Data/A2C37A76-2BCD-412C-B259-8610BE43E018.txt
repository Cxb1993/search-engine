implementing the concept, cluster-dependent feature 
selection, are also validated in the experiments. The 
promising experimental results demonstrate its 
effectiveness. 
英文關鍵詞： feature selection, multiple kernel learning, self-
organizing map, alternating optimization procedure 
 
 I 
多特徵表示下的資料分群技術之研發 
摘要 
 
本計畫的主要宗旨，在於發展一個資料分群技術，使得系統能夠利用擁有多種特徵表示的資料，
以獲得更佳的分群結果。我們可觀察到，來自不同類別之資料往往有其獨特之特徵，並依此特徵聚
集同類別資料與區隔其他類別資料。基於此一啟發，我們提出了一種將多核學習(Multiple Kernel 
Learning, MKL)融入訓練過程中的分群架構，並將其建構於自組織映射圖(Self-organizing Map, SOM)
此一類神經網路中，以實現一高效能之資料分群系統。透過此一分群架構，能夠同時實現依群特徵
選擇(cluster-dependent feature selection)之功能，亦即不同群將以各自獨特之特徵來加以描述。此一
架構的主要目的，旨在還原某個群與其相應特徵之間的本質關係。在實驗的部份，我們透過兩組標
竿資料集 UCI 之 iris dataset 以及 Caltech-101 dataset 來進行測試。相較於過去 k-means 或是僅使用
單一核函數之核化自組織映射圖(Kernel SOM)，我們所提出的方法能更進一步地提升分群結果之品
質，並呈現``依群特徵選擇”在分群上的優勢。 
 
關鍵詞：特徵選擇、多核學習、自組織映射圖、交替式最佳化 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 III 
目錄 
 
摘要……………………………………………………………………………………………… I 
 
一、前言 
 
1. 研究目的………………………………………………………………………………………… 1 
 
2. 文獻探討………………………………………………………………………………………… 2 
 
二、研究方法 
 
 1. 定義自組織映射圖……………………………………………………………………………… 3 
 
  1.1. 基本自組織映射圖……………………………………….…………….………………… 3 
 
  1.2. 融入多核學習…………………………………………………….…………….………… 4 
 
 2. 交替式最佳化過程……………………………………………………………………………… 5 
 
  2.1. 資料與分群之間的關係………………………………….…………….………………… 5 
 
  2.2. 特徵與分群之間的關係………………………………….…………….………………… 5 
 
三、結果與討論……………………….……….……….………………………………………………… 6 
 
參考文獻……………………….……….……….………………………………………………………… 8 
 
計畫成果自評（附件二）….……….……….…………………………………………………………… 9
 2 
文獻探討 
  在相關的文獻中，與本計畫最相似的架構為多視角分群(multi-view clustering)，其最佳解通常
用 EM (Expectation-Maximization) 演算法或是 spectral clustering 的方式來求得。例如，Bickel 與
Scheffer 透過 co-EM 演算法來尋找最佳多視角分群之結果。Zhou 與 Burges 則藉由將 single-view 
normalized cut 廣義化來延伸多視角資料下的 spectral clustering。Mirzaei [5] 提出多視角聚合式階層
分群法(multi-view agglomerative clustering)來延伸以多視角表示之物件下的階層分群法。Tzortzis 與
Likas [6]對於多視角之 convex mixture models 中之不同視角採用相異之權重。Lin 等人[18]提出依群
特徵選擇的方式。然而，上述方法遭遇到高運算複雜度的困難。 
  不同於多視角之分群架構，我們將透過依群特徵選擇的機制來探討特徵與分群間的本質關係。
於本計畫中，我們提出「多核自組織映射圖」(multiple kernel self-organizing map, MK-SOM)此一分
類架構。自組織映射圖為一種非監督式之類神經網路，其概念主要啟發自大腦功能的空間組織。自
組織映射圖能夠以低維度之流形(manifold)來描述高維度的資料，並且一般來說，是以梯度下降法
(gradient descent method)來進行最佳化。因此，相對於基於 EM 或是 spectral clustering 之分群方法
來說，MK-SOM 的運算複雜度可大幅降低。許多研究探索了如何將核化法應用於自組織映射圖上，
藉以幫助非線性資料的分群，然而，該如何選擇適當的核函數，以及其相關之參數該如何調控仍然
是一待解決之問題。類似上述關於核函數的選擇，或是參數設定的問題，可由多核學習來解決[10, 
11, 12, 13]。其中，我們將透過許多不同之基核(base kernels)作為輸入以進行核機器(kernel machine)
的學習。 
  在本計畫中，我們所要分群之資料，將以多種核函數來表示，其中每一種核函數對應著特定的
參數，或是使用不同的資料描述子。我們所提出的多核自組織映射圖，不僅將多核學習融入自組織
映射圖的訓練過程中，還同時體現了依群特徵選擇的能力。此亦即，不同群對應著不同的相似度測
量方式──由所使用的核函數來進行不同之特定的線性組合。
 4 
其中 xi當前屬於第 j 群，而 wj即自組織映射圖上第 j 個神經元對應之權重向量，也被視為群中心。
我們的目的是：藉由將該目標函數最小化，使得能夠找到一組具鑑別度之{wj}j=1
C
，俾使能達到良好
的資料分群。一般來說，此最佳化的過程通常透過最速梯度下降法(steepest gradient method)來實現，
此一部份我們將於稍後介紹。 
 
1.2. 融入多核學習 
  我們接著將多核學習融入自組織映射圖的學習過程中，使其能處理依群特徵選擇的任務。首先，
定義Φ: X → F為透過一合成核所產生之特徵映射，而訓練資料將映射至一個高維度的特徵空間中，
以 ϕ(xi)來表示。此外，權重向量可假設為所有訓練資料於高維度空間中之線性組合：即 
wj = ∑ αj, nϕ(xn)
N
n=1   
其中，{αj, n}n=1
N
為樣本係數，即表示：對於資料集中的第 n 筆資料，其在第 j 群中之權重。於是我
們可以將原本的目標函數改寫，並展開如下： 
E
MK-SOM
 = ∑ minj‖ϕ(xi)− ∑ αj, nϕ(xn)
N
n=1 ‖
2N
i=1   
 = ∑ minj [ϕ
T(xi)ϕ(xi)− 2∑ αj, nϕ
T(xi)ϕ(xn)
N
n=1
N
i=1   
 +∑ ∑ αj, nαj, n'
N
n'=1
N
n=1 ϕ
T(xn)ϕ(xn')]  
 
透過 kernel trick，我們將內積項以核函數取代，將上式進一步簡化為： 
E
MK-SOM
=∑ minj[k(xi,xi)− 2∑ αj, nk(xi,xn)+
N
n=1 ∑ ∑ αj, nαj, n'
N
n'=1
N
n=1 k(x𝑛,xn')]
N
i=1   
 
  至此，我們完成了核化自組織映射圖之推導。為了將多個核函數融入於此目標函數中，如同許
多類似關於多核學習的相關作品[10, 11, 12, 13]，此處之多核學習之目的是要根據給定的基核函數，
找到這些函數一最佳之線性組合。因此，此處的核函數 k為一合成核，表示為某些基核函數的 convex 
combination，亦即： 
k(xi,xj) = ∑ βmkm
M
m=1 (xi,xj) 
subject to ∑ β
m
M
m=1 =1, βm≥0  ∀m 
 
其中，β
m
為基核係數、M 為基核之個數。因此，最後的目標函數以下式表示之： 
E
MK-SOM
 = ∑ minj[∑ βmkm
M
m=1 (xi,xi) − 2∑ αj, n∑ βmkm
M
m=1 (xn,xi)
N
n=1
N
i=1   
+∑ ∑ αj, nαj, n'
N
n'=1
N
n=1 ∑ βmkm
M
m=1 (xn,xn')]  
 
  需注意的是，每一群將擁有其不同之合成核 k，而這也意味著此學習過程中將體現依群特徵（核）
選擇之特性與結果。 
  
 6 
  考慮額外的限制條件，我們將梯度下降之方向做調整。這可從幾個面向來進行： 
1) 若是基核係數為 0，則該係數不做更新，以避免違反係數需大於或等於 0 之規則。 
2) 係數總和保持為 1，即意味著更新方向總和為 0。 
 
綜合上述，梯度下降方向透過下式表示之： 
 dm = 
{
 
 
 
 0 if βm=0 and 
∂E
∂βm
−
∂E
∂dμ
>0
−
∂E
∂βm
+
∂E
∂dμ
if βm>0 and m≠μ           
∑ (
∂E
∂βυ
−
∂E
∂dμ
)υ≠μ,dυ>0       for m=μ                                     
   
 
  為了獲得較佳的數值穩定性(numerical stability)，式中之 μ 挑選為當前 β 向量中數值最大部份
其對應之索引。在獲得適當之更新方向後，βm便透過下式進行更新： 
βm ← βm + τdm 
 
其中，τ 為適當之步進大小(step size)。透過交替式的最佳化過程，MK-SOM 將訓練出適當之樣本
係數與基核係數。關於其訓練過程之演算法，請參看圖二。 
 
Algorithm 1: MK-SOM 
Input: Dataset D={xi}i=1
N  in the form of multiple kernels {km}m=1
M  
Output: Sample coefficient vectors j; 
  Base kernel coefficient vector ; 
Initial values for j and : 
 j is generated by uniform distribution [1, 1]; 
  is set as 1/M for satisfying constraints; 
for t ← 1, 2, …, T do 
 1. Update j by the steepest gradient method; 
 2. Update  by the reduced gradient method; 
2.1. Calculate gradient value E/m and descent direction dm; 
2.2. Iteratively update dm until convergence as E(
+)  E(),  
where + =  + maxd and max is the maximum step size; 
2.3. Line search along d for appropriate step size .  ←  +d; 
end for 
return j  and ; 
[圖二] 多核自組織映射圖之訓練過程。 
 
三、結果與討論 
  我們將多核自組織映射圖之技術應用在資料分群上，並透過兩組標竿資料集以及兩種不同對於
分群結果表現之評分方式來進行實驗。第一個資料集為 UCI 所收集之 iris dataset [15]，其中基核函
數透過 RBF 函數中使用不同 hyper-parameters 來建立。第二個資料集為 Caltech-101 datset [16]，使
用了五種不同的影像描述子，分別對應至五種不同的核函數。 
 
 8 
References 
[1] R. Xu and D. Wunsch II. Survey of clustering algorithms, IEEE Trans. Neural Networks, 2005. 
[2] L. Zelnik-Manor and P. Perona. Self-tuning spectral clustering, Neural Information Processing System, 2004. 
[3] S. Bickel and T. Scheffer. Multi-view clustering, in Proc. of Int. Conf. on Data Mining, 2004. 
[4] D. Zhou and C. Burges. Spectral clustering and transductive learning with multiple views, Int. Conf. on 
Machine Learning, 2007. 
[5] H. Mirzaei. A novel multi-view agglomerative clustering algorithm based on ensemble of partitions on 
different views, Int. Conf. on Pattern Recognition, 2010. 
[6] G. F. Tzortzis and A. C. Likas. Multuple view clustering using a weighted combination of exemplar-based 
mixture models, IEEE Trans. Neural Networks, 2010. 
[7] T. Kohonen. Self-organized formation of topologically correct feature maps, Biological Cybernetics, 1982. 
[8] B. Romain, J. Bertrand, R. Fabrice, and V. Nathalie. Batch kernel SOM and related Laplacian methods for 
social network analysis, Neurocomputing, 2008. 
[9] K. Lau, H. Yin, and S. Hubbard. Kernel self-organising maps for classification, Neurocomputing, 2006. 
[10] F. R. Bach, G. R. G. Lanckriet, and M. I. Jordan. Multiple kernel learning, conic duality, and the smo 
algorithm, Int. Conf. on Machine Learning, 2004. 
[11] A. Rakotomamonjy, F. Bach, S. Canu, and Y. Grandvalet. More efficiency in multiple kernel learning, Int. 
Conf. on Machine Learning, 2007. 
[12] A. Rakotomamonjy, F. Bach, S. Canu, and Y. Grandvalet. SimpleMKL, Journal of Machine Learning 
Research, 2008. 
[13] Y.-Y. Lin, T.-L. Liu, and C.-S. Fuh. Multiple kernel learning for dimensionality reduction, IEEE Trans. 
Pattern Analaysis and Machine Intelligence, 2011.  
[14] P. Wolfe. Methods of nonlinear programming, Recent Advances in Mathematical Programming, R.L. Graves 
and P. Wolfe (Eds.), 1963. 
[15] A. Asuncion and D. J. Newman. UCI machine learning repository, Irvine, CA: University of California, 
School of Information and Computer Science, 2007. 
[16] L. Fei-Fei, R. Fergus, P. Perona. Learning generative visual models from few training examples: an 
incremental bayesian approach tested on 101 object categories, Int. Conf. on Computer Vision and Pattern 
Recognition, 2004. 
[17] A. Strehl, J. Ghosh. Cluster ensembles – A knowledge reuse framework for combing multiple partitions, 
Journal of Machine Learning Research, 2002. 
[18] Y.-Y. Lin, T.-L. Liu, and C.-S. Fuh. Clustering complex data with group-dependent feature selection, 
European Conf. on Computer Vision, 2010. 
[19] D. Dueck and B. Frey. Non-metric affinity propagation for unsupervised image categorization, Int. Conf. on 
Computer Vision, 2007. 
 10 
3. 請依學術成就、技術創新、社會影響等方面，評估研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）（以
500 字為限） 
 
本計畫所探討議題，旨在對於一群未知的影像進行非監督式學習下的資料分群。透過融入了
多核學習的訓練過程，我們考量了不同特徵空間下的樣本距離，做為分群結果精進的基礎，
並可推廣至分類或辨識等議題，因此具有相當大的應用價值。以下列出目前所發展之演算法
進階發展的研究方向與技術創新： 
 將非監督式學習擴展至可處理半監督式學習：鑑於目前影像資料之高度複雜性，純非監
督式的效能有其限制，如何將目前所發展之演算法與小部分人工標示之資料作結合，並
提昇分群之準確性，將是本計畫後續發展的重點。 
 與影像分割的融合：影像資料之分群與分類之類別，往往只與影像中的部分區域(ROI or 
segment)相關，其他區域所取出之特徵，通常無助於分群，甚至降低分群之效能。如何利
用影像分割的技術來推估影像中與類別相關之區域，並藉此提高分群結果的效能，亦是
我們的目標。 
 同物件的影像分群：在自動化相簿管理中，這此一應用中，群的單位通常是同一物件(如
某人或某台車)，而非同一物件類別(人或車)，如何將現有之分群演算法應用於此例裡，
為一可行之研究方向。 
 
 
 2
二、與會心得 
IEEE ICIP 的議程常是五個 oral session 與一個 poster session 平行進行，我通常選擇與我研究題目最
為相關者參加，因此多為與電腦視覺應用有關的影像處理技術。這是我第一次參加 IEEE ICIP，在
收錄的論文裡，許多著墨於影像處理相關的應用，似乎純影像或訊號處理的論文並不多，然而這
些應用卻十分的多元，如電腦視覺領域的辨識、分群、分割、特徵萃取；多媒體影、錄像的內容
分析與檢索；醫學影像的強化、對位、分割或融合。機器學器技術亦扮演著許多論文中的關鍵角
色，例如針對大量影像資料分析而發展的大規模學習(large-scale learning)。另外，由於新世代攝影
機近來的蓬勃發展，它衍生出許多新穎的影像類別，如深度影像(depth image)、骨架影像(skeleton 
image)或點雲影像(point cloud image)；現有之``RGB 或 gray-level’’影像處理技術並無法直接使用在
這些新的影像種類上，因此於新型影像上發展影像處理技術，亦成為一個研究重點與趨勢。 
 
參加今年 IEEE 國際影像處理會議最大的收穫除了獲得目前影像處理研究最新知識外，透過論
文的報告亦可得到許多珍貴的回饋與意見，主要於壁報報告時與聆聽他人報告時的內容討論，這
有助於後續研究方向的制訂，技術的發展。另外，與國外學者互動有利於提高我國多媒體研究的
國際可見度，亦有助於促成跨國合作。 
三、發表論文全文或摘要 
 Abstract 
We aim to resolve the difficulties of action recognition arising from the large intra-class variations. 
These unfavorable variations make it infeasible to represent one action instance by other ones of the same 
action. We hence propose to extract both instance-specific and class-consistent features to facilitate action 
recognition. Specifically, the instance-specific features explore the self-similarities among frames of each 
video instance, while class-consistent features summarize within-class similarities. We introduce a 
generative formulation to combine the two diverse types of features. The experimental results 
demonstrate the effectiveness of our approach. 
四、建議 
無。 
五、攜回資料名稱及內容 
IEEE ICIP 2012 Electronic Proceeding。 
六、其他 
無。 
 
 
100年度專題研究計畫研究成果彙整表 
計畫主持人：林彥宇 計畫編號：100-2218-E-001-004- 
計畫名稱：多特徵表示下的資料分群技術之研發 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 2 0 67%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 3 3 50% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
國科會補助專題研究計畫成果報告自評表 
請就研究內容與原計畫相符程度、達成預期目標情況、研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）、是否適
合在學術期刊發表或申請專利、主要發現或其他有關價值等，作一綜合評估。
1. 請就研究內容與原計畫相符程度、達成預期目標情況作一綜合評估 
■達成目標 
□未達成目標（請說明，以 100字為限） 
□實驗失敗 
□因故實驗中斷 
□其他原因 
說明： 
2. 研究成果在學術期刊發表或申請專利等情形： 
論文：■已發表 □未發表之文稿 □撰寫中 □無 
專利：□已獲得 □申請中 ■無 
技轉：□已技轉 □洽談中 ■無 
其他：（以 100字為限） 
3. 請依學術成就、技術創新、社會影響等方面，評估研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）（以
500字為限） 
本計畫為一年期之研究計畫，旨在對於一群未知的影像進行非監督式學習下的資料分群。
透過融入了多核學習的訓練過程，我們考量了不同特徵空間下的樣本距離，做為分群結果
精進的基礎，並可推廣至分類或辨識等議題，因此具有相當大的應用價值。總結計畫研究
成果，在此期間我們提出了： 
1. 以群為單位之特徵選用：基於資料的外部區隔性與內部變異性常隨著群的不同而改
變，例如要聚集＇＇日落＇＇這群的影像，並將之與其他影像分開，顏色特徵會是一個較
佳的選擇，於＇＇腳踏車＇＇影像，因有類似之形狀，故形狀特徵對這群的影像來說是比
較合適的。所提出之分群技術應用在物件分類與 UCI 標竿資料集上，均得到不錯的實驗結
果。 
2. 融入多核學習之自組織映射圖：它可同時處理資料的多種特徵表示，並進行特徵選取，
這可使現有之異質特徵表示子(descriptors)，在一致之核函式上的進行結合，以增進資
料表示的精準度。 
 
以下列出目前所發展之演算法進階發展的研究方向與技術創新： 
1. 將非監督式學習擴展至可處理半監督式學習：鑑於目前影像資料之高度複雜性，純非
監督式的效能有其限制，如何將目前所發展之演算法與小部分人工標示之資料作結合，並
提昇分群之準確性，將是本計畫後續發展的重點。 
2. 與影像分割的融合：影像資料之分群與分類之類別，往往只與影像中的部分區域(ROI or 
