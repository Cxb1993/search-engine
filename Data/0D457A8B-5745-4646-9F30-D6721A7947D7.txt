需求進行調整，在設計時能更有彈性，也能藉由選擇合適的
設計，進一步提高平行後的效能增益。從實驗數據來看，在
知識系統的應用中平行後所帶來的效能增益最多能達到 25 倍
左右，而人力資源網站的應用則是能達到 260 倍左右的效能
增益；除了透過實驗呈現新設計的效能增益外，我們更進一
步探討平行化專家系統應用時影響實驗結果的因素，並整理
出幾點平行化時的建議供專家系統應用開發人員參考。 
中文關鍵詞： CLIPS、專家系統、平行化、流程式平行程式開發模型 
英 文 摘 要 ： CLIPS language is designed especially for developing 
expert systems. Programmers have no need to write 
algorithms for solving problems. Instead, they only 
need to list facts and rules. The feature makes the 
execution time much longer. In this thesis, we study 
how to utilize the compute power of emerging 
multicore computers, cluster systems, grid systems 
and cloud systems to parallelize CLIPS applications. 
In this two-year project, we investigate how to 
parallelize an expert system by allocating different 
combinations of inference to multiple processors, and 
how to design a workflow-based parallel programming 
model to exploit different kinds of parallelisms for 
an expert systems. 
In the first year, we investigate how to apply the 
idea of automatic parallelization to other kinds of 
applications. For instance, a rule usually requires 
choosing multiple data items from the knowledge base 
to match with. This kind of matching is a permutation 
problem. All the different permutations must be 
divided into partitions and assigned to slaves for 
independent inferences. A programmer only needs to 
use three simple directives to provide necessary 
information to automatically parallelize the 
execution of an application. Experiment results show 
that the best speedup is 10.38 when executing a 
knowledge management system in a heterogeneous 
cluster system with 12 processor cores. 
In the second year, we propose a workflow-based 
parallel programming model for enabling more 
complicate application developments. Programmers can 
partition an application into sections and specify 
the execution order of the sections by a workflow. A 
 I 
 
行政院國家科學委員會補助專題研究計畫■ 成 果 報 告   
□期中進度報告 
 
平行 CLIPS 語言及其解譯器中自我排程策略之設計 
 
計畫類別：■ 個別型計畫  □ 整合型計畫 
計畫編號：NSC 98－2221－E－018－008－MY2 
執行期間： 98 年 8 月 1 日至 101  年 9 月 31 日 
 
計畫主持人：伍朝欽 
共同主持人：賴聯福 
計畫參與人員：盧鍾、魏綜佑、林庭宏、賴嘉賢、江英傑、李原嘉 
 
執行機構及系所：國立彰化師範大學資訊工程學系 
成果報告類型(依經費核定清單規定繳交)：□精簡報告  ■完整報告 
 
本成果報告包括以下應繳交之附件： 
□赴國外出差或研習心得報告一份 
□赴大陸地區出差或研習心得報告一份 
■出席國際學術會議心得報告及發表之論文各一份 
□國際合作研究計畫國外研究報告書一份 
 
處理方式：除產學合作研究計畫、提升產業技術及人才培育研究計畫、列管計畫及下列
情形者外，得立即公開查詢 
      □涉及專利或其他智慧財產權，□一年□二年後可公開查詢 
     
中   華   民   國  100   年  11  月   29 日 
 III 
 
員選擇。 
因為以平行加速執行時係將應用分成數個區段後依各自設定的方式執行，故能提高
應用的平行度及執行效能；除此之外，區段執行方式的設定及先後順序都可以根據開發
人員的需求進行調整，在設計時能更有彈性，也能藉由選擇合適的設計，進一步提高平
行後的效能增益。從實驗數據來看，在知識系統的應用中平行後所帶來的效能增益最多
能達到 25 倍左右，而人力資源網站的應用則是能達到 260 倍左右的效能增益；除了透
過實驗呈現新設計的效能增益外，我們更進一步探討平行化專家系統應用時影響實驗結
果的因素，並整理出幾點平行化時的建議供專家系統應用開發人員參考。 
關鍵字： CLIPS、專家系統、平行化、流程式平行程式開發模型  
 V 
 
目錄 
中文摘要....................................................................................................................... II 
英文摘要...................................................................................................................... IV 
圖目錄.......................................................................................................................... VI 
表目錄....................................................................................................................... VIII 
第一章  緒論............................................................................................................ 1 
第二章  相關文獻.................................................................................................... 4 
第一節  專家系統 .............................................................................................................. 4 
第二節  CLIPS 和 Fuzzy CLIPS ....................................................................................... 5 
第三節  負載平衡問題及自我排程機制 .......................................................................... 6 
第四節  Data-parallel programming mode ........................................................................ 7 
第五節  Send-receive programming mode ...................................................................... 10 
第三章  平行程式開發模型.................................................................................. 14 
第一節  組合分工式平行程式開發模型 ..................................... 錯誤! 尚未定義書籤。 
第二節  工作流程式平行程式開發模型設計理念 ........................................................ 19 
第三節  工作流程式平行程式模型設計 ........................................................................ 29 
第四節  工作流程式平行程式軟體系統架構 ................................................................ 35 
第四章  研究成果與探討...................................................................................... 39 
第一節  組合分工式平行程式開發模型 ..................................... 錯誤! 尚未定義書籤。 
第二節  流程式平行程式開發模型 ................................................................................ 41 
第五章  總結、自評與未來展望.......................................................................... 52 
第六章  參考文獻.................................................................................................. 57 
 
 
 VII 
 
圖 24. 專案式程式規劃，平行前後檔案內容對應表......................................................... 30 
圖 25. 平行化專家系統應用程式流程及檔案內容對應示意圖......................................... 36 
圖 26.  Source-to-source interpreter 架構圖 ......................................................................... 37 
圖 27. 不同 problem sizes 下，各處理器個數執行所耗費時間比較 .............................. 40 
圖 28. 不同 problem sizes 下，不同處理器個數執行之效能增益比較. ......................... 41 
圖 29. 重要性歸屬函數......................................................................................................... 42 
圖 30. 符合程度歸屬函數..................................................................................................... 42 
圖 31. 人力資源網工作經驗及科系要求欄位設定畫面..................................................... 43 
圖 32. 模糊聚合運算後結果(依符合程度排序) .................................................................. 43 
圖 33. 以不同自我排程機制進行平行化效能增益(不同資料量) ...................................... 45 
圖 34. 以不同排程機制進行 data-parallel 平行化執行時間(不同 processor 數) ............... 46 
圖 35. 不同平行化方法使用 8 個 processors 效能增益圖(不同資料量) ........................... 47 
圖 36. 不同排程機制使用 32 個 processors 效能增益圖(不同資料量) ............................. 47 
圖 37. 不同排程機制平行化效能增益(不同 processor 數)................................................. 48 
圖 38. 以不同機型為主節點採 CSS(50)排程機制所需執行時間 ...................................... 50 
圖 39. 以 GSS 排程機制執行多次執行時間分佈圖 ........................................................... 51 
圖 40. 不同排程機制下各節點工作負載示意圖................................................................. 51 
 
  
 1 
 
第一章 緒論 
專家系統(Expert System)[1]係用電腦系統模擬人類專家解決問題，該系統常使用
CLIPS (C Language Integrated Production System)[2]進行應用開發，CLIPS與C或JAVA這
類演算法式程式語言(Algorithmic Programming Language)不同，前者不需要定義執行時
的每一個步驟，而是在定義事實(Facts)和規則(Rules)後以推理的方式找出問題的答案，
這種方式雖然能輕易撰寫出專家系統應用的程式，但因為推理時需要不斷比對事實及規
則直到不再產生任何新的事實後才結束，使得該類應用的執行時間受到規則複雜度及事
實的資料量所影響，若規則複雜且資料量大時，執行往往需要花費大量的時間。 
隨著近年多核(Multi-cores)、叢集式系統(Clusters)、格網系統(Grids)和雲端運算
(Cloud Computing)技術的發展[3-12]，使我們能仿照CLIPS語法設計及使用MPICH2 函式
庫[13, 14]提出數種程式設計模型，用以平行化專家系統應用，並實驗於環境驗證研究
成果[15-21]。先前研究中所提出的平行化方式約可分成兩類(1)Data-parallel：開發人員
利用預先定義之假指令標示出所需的平行資訊後，由後端程式自動完成平行化的轉換，
期間不需自行處理節點間訊息傳遞或負載平衡等牽涉平行知識的操作，對於CLIPS開發
人員而言不必重新適應開發方式及學習平行知識，但減少使用門檻的代價係該方法僅適
用於將無資料相依性的應用完全平行化，無法適用於大多數應用；(2)Send-receive：仿
照CLIPS的語法設計，新增負責訊息傳遞功能的語法，並將對應的函式定義嵌入推理引
擎，讓開發人員可以使用新增的訊息傳遞語法，根據應用中不同的程式特性安排訊息傳
遞及節點工作量的分配，因此能更為完整的平行化應用，但不是所有的開發人員都熟知
平行領域的知識，故若想以此方式加速應用，則需學習額外的知識處理複雜的訊息傳遞
和負載平衡問題。 
下面以平行化複雜的CLIPS應用為例，進一步說明先前研究中的不足，圖 1中分別
採用先前研究中所提出的兩種方式平行化範例中的未平行CLIPS程式(Sequential code)；
若採自動平行化方式，則可完全平行範例應用中無資料相依的部份，但剩下的程式內容
由於牽涉資料相依只能以循序的方式執行，故以循序方式執行之部份勢必成為該種平行
化方式的效能瓶頸；若採自行維護訊息傳遞的方式，則可平行化整個應用，但其執行效
能將受工作分配適當與否所影響。 
 方式有利於偵錯及維護；若根據流程式平行程式開發模型進行應用開發，則開發人員需
要定義每個模組所屬的區段，此範例中我們假設模組與區段的對應如下所示，平行化該
應用後共產生 4 個區段S1~S4，依據不同區段的程式特性決定該區段的執行方式，每個
區段所對應執行方式如圖 2所示(S1: sequential execution、S2: data-parallel、S3 及S4: 
job-parallel)。 
 
圖 2. 流程式平行程式開發模型工作流程示意圖 
實驗中我們使用知識系統及人力資源網站作為平行化探討的應用，平行化後這兩個
應用所具備的特性並不相同，知識系統中每個節點於推理前的初始化十分費時，所以比
較適合採用一次就將所需資料送給所有節點的方式平行化，反之則會因為反覆的初始化，
導致初始化所引起的負擔遽增，進而減少效能增益，所以使用初始分配較多工作的排成
方式能獲得較好的效能增益；人力資源網則是具備相反的特性，因此在該應用中負載平
衡問題所造成的影響遠超過初始化所帶來的影響，因此平行化時將工作都切成小等分以
多次送給節點是較為合適的作法，這是由於每一次節點所取得的工作都不需執行太久，
當負載不平衡問題出現時，整個閒置的時間也會很短，故適合的排程方式以一次分配次
數較多和每次分配數量較少的會有較好的效能增益；除此之外，我們更進一步探討於異
質環境中不同節點作為主節點所帶來的影響，以提供建議給平行化開發人員作為參考。 
總的來說使用流程式平行程式開發模型開發人員平行化應用時能有(1)更多的程式
設計彈性(不同的區段執行方式及流程安排)、(2)便捷的操作(假指令及類似 CLIPS 語法
的設計)、(3)良好的效能增益及(4)設計的建議(如前一小段落所述)。 
 
3 
 
   (data 2) 
  (data 3) 
  (data 4) 
  (data 5) 
) 
圖 3. 簡單循序 CLIPS 程式範例 
 
第二節  CLIPS和Fuzzy CLIPS 
CLIPS[2]係用來建置專家系統的程式語言，最早係由美國太空總署NASA開發及維
護，直到 90 年代後才成為公用軟體(Public Domain Software)。CLIPS由事實與規則所組
成，其中規則又可分為LHS與RHS兩個部份，分別的方式為”=>”符號，若位於該符號左
側則為LHS代表需要滿足的條件，如圖 3中的 ）?a data（ 等；反之右側為RHS係用於表示
滿足LHS後需執行的動作，如圖 3中的 ）crlf ?b〞>〝 ?a printout t（ 。推理引擎將知識庫中
所有事實與每個規則中的LHS進行比對，如符合則執行RHS的內容。CLIPS具有高可攜
性且為開放性的自由軟體，目前為最通用的專家系統開發語言[22-26]。 
Fuzzy CLIPS[27]係基於CLIPS再加上模糊邏輯(Fuzzy Logic)[28]的觀念開發而成，
因此能同時處理不明確表示(Fuzzy Terms)及明確表示(Normal Terms)，有別於經典邏輯
(Classical logic)使用布林作為表達的方式，模糊邏輯中數值皆根據關係函式(Membership 
Function)定義之，通常用來表達語意上模糊的概念，例如溫度的冷熱及居住地點的遠近
等。FuzzyCLIPS除了可表示模糊化的事實(Facts)和模糊化的規則(Rules)外，它還提供了
模糊規則的推理能力，讓使用者可以進行模糊推理，開發含有模糊邏輯的應用程式
(Fuzzy Applications)。 
為呈現系統的完整性，我們平行化基於 CLIPS 或 Fuzzy CLIPS 引擎的應用，並於
私有雲中進行實驗，除了探討新平行化方法的效能增益外，更進一步分析自我排程機制
於環境中不同參數所造成的影響，此影響會根據應用的不同而有所分別，故分析時以應
用作為討論的依據。 
 
 
5 
 
  
圖 4. 不同排程機制工作量分佈曲線圖 
表 1. 不同排程機制具體分配工作量一覽表 
Scheme Partition size 
CSS(125) 125,125,125,125,125,125,125,125 
FSS 125,125,125,125,63,63,63,63,31,31,31,31,… 
GSS 250,188,141,106,79,59,45,33,25,19,… 
TSS 125,117,109,101,93,85,77,69,61,53… 
 
第四節  Data-parallel programming mode 
在此方法中我們使用SPMD程式設計模型與MPICH函式庫[13]，使Fuzzy CLIPS能平
行於叢集式環境中執行並將平行化細節隱藏，其中SPMD為Single Program Multiple Data
的縮寫，此模型中所有節點皆載入相同程式，之後根據條件式的判斷執行對應的程式區
段。圖 5為使用C語言撰寫SPMD範例程式，其中rank為平行環境中用以區別不同節點
之變數，procs表示環境中總節點數(包含主節點及所有工作節點)，一般以rank 0 代表主
節點，其餘則為工作節點，因此若要區別主節點及工作節點的執行內容，可利用rank值
進行判斷，若rank值為 0 為主節點，其餘則為工作節點，使用此程式設計模型的好處在
於所有節點皆載入同一份程式，不需監測多份程式內容，因此易於程式的維護及開發。 
 
int rank; 
7 
 
 9 
 
;#TASK 
;(data (value 1)) 
;(data (value 2)) 
;(data (value 3)) 
;(data (value 4)) 
;(data (value 5)) 
;#END 
Return template 
;#RETURN result 
CLIPS define template 
(deftemplate MPI(slot RANK)(slot PROCS)) 
(deftemplate data(slot value)) 
(deftemplate result(slot value_1)(slot valut_2)) 
Reduce rule 
(defrule Master_Do 
  (MPI(RANK 0)) 
  (result(value_1 ?a)(value_2 ?b)) 
=> 
  (printout t ?a 〝>〞?b crlf) 
) 
Parallel rule 
(defrule Worker_Do 
  (MPI(RANK ?r:(neq ?r 0))) 
  (data (value ?a)) 
  (data (value ?b)) 
=> 
  (assert (result(value_1 ?a)(value_2 ?b))) 
) 
圖 6. 採 data-parallel 方法平行化程式設計模型範例 
圖 7 為使用上述程式設計模型平行化 Fuzzy CLIPS 程式流程，首先包含假指令的
Fuzzy CLIPS 程式碼會經由前處理取得平行化資訊，主節點取得平行事實及納簡規則，
工作節點取得平行規則及回傳樣板，接著主節點使用自我排程機制將平行事實透過
MPICH 函式庫傳給工作節點，工作節點收到工作後便開始執行平行規則，結束後根據
回傳樣板的定義，回傳符合該樣板的事實，如此反覆直到主節點將平行事實全數分配完
 仿照 CLIPS 的設計，新增負責訊息傳遞功能的語法，並將對應的函式定義嵌入推
理引擎，此方式中開發人員可根據應用中不同的程式特性安排訊息傳遞及節點工作量的
分配，與自動平行化不同處在於 send-receive 的平行化方法，需要由開發人員自行維護
節點間訊息傳遞，此特性使之能適用於更多專家系統應用的平行化，但此類平行化方式
要求開發人員對平行知識一定程度的瞭解。 
為達到上述功能，我們將MPICH函式庫與Fuzzy CLIPS所提供的應用程式介面結合，
圖 8為整合後流程圖，新增的平行化語法會由推理引擎中對應的定義處理，新增的定義
會根據程式碼中平行化語法的寫法，使用MPICH函式庫進行節點間訊息傳遞，基於簡
化使用及易於維護的特性，此處基於易於維護的特性，採SPMD程式模型作為基礎架構，
程式開發人員仍需以樣板MPI的RANK值作為區別主節點及工作節點的方式進行專家
系統應用的平行化。 
 
圖 8. 採 send-receive 平行化 Fuzzy CLIPS 程式流程圖 
在處理節點間訊息傳遞時，我們使用 package 而非 MPI_Send 或 MPI_Recv 處理，
係因按照 Fuzzy CLIPS 程式設計的邏輯在 RHS 處使用 Send，則會將事實『一筆一筆』
的送出去，如此將使節點間通訊成本大幅成長，因此我們導入 package 的概念，每個要
送出的事實都會先被放到對應不同節點的緩衝區中，才進行訊息傳遞的工作，待到傳送
時則送出整個緩衝區的資料給對應的節點，以減少資料傳遞的負擔，下面就訊息傳遞的
11 
 
 13 
 
表 3. 新增平行化語法定義及用途 
packFact 
Argumets 
Comments 
integer(r), FactPointer 
to push the facts into the #r virtual buckets 
packageSendTo 
Argumets 
Comments 
none 
to send out all the facts in the buckets 
packageRecvFrom 
Argumets  
Comments  
integer(r)  
to receive the facts which are sent by process #r  
packageISendTo 
Argumets  
Comments  
none  
same as packageSendTo, but non-blocking  
packageIRecvFrom 
Argumets  
Comments  
integer(r)  
same as packageRecvFrom, but non-blocking  
packBFact 
Argumets  
Comments  
FactPointer  
to push the facts into the bucket which is used to broadcast 
packageBcast 
Argumets  
Comments  
integer(f)  
broadcast the facts from process #f to all the other processes 
 
  
  
 
 
 
 
 
 
圖 11. CLIPS 規則舉例，規則中使用數筆事實進行配對 
假設一集合包含 A、B、C 和 D 四個元素(elements)，並從中任意挑出兩個元素，則
產生ܲ
 ଶ
ସ種可能，如圖 12(a)共 12 種組合，而後根據每個組合中第一個字母的不同與字母
順序，分成四個子集合(subset)，結果如圖 12(b)。舉例來說，第一個子集合中的所以組
合皆以‘A’作為該組合的第一個字母，依此類推。由於每個子集合在分割時皆已確定第
一個字母為何，故對每筆組合而言，第二個字母僅剩 3 種選擇，所以每個子集合中應
有 ଵܲଷ，3 筆組合。由於可將每個子集合做為分配 給工作節點進行獨立推理的工作單位
(task)，上述分配方式適合應用於平行化 CLIPS 的推理；為達成此目標我們需要定義該
如何告知工作節點下列資訊：(1)哪些規則需平行地進行推理(2)哪些事實將於平行推理
時被挑選進行配對。 
圖 12. 將事實產生的候選組合分配成數個子集合的例子 
15 
 
  
 
 
 
 
 
圖 14. 插入一筆對應條件於範例規則中 
需注意的是在原本的知識庫中並沒有 context-P 事實，而是於進行配對時根據不同
的 context 事實修改而來，這類新增的事實稱為對應事實(counterpart facts)；與 context
事實有所不同，context-P 事實並未存於任一工作節點上的知識庫中，只有主節點能於執
行時(runtime)存取。實際執行時，每個工作節點將從主節點處收到一筆 context-P 事實；
每個工作節點上都只會有一筆 context-P 事實，也只有 context-P 事實方能與對應條件進
行配對。基於平行條件與對應條件除事實名稱外皆相同的理由，於平行條件與 context-P 
事實配對時，能將工作節點所收到的 context-P 事實替換 context 事實，與平行條件進行
配對。 
舉例來說，假設有一工作節點收到的 context-P 事實為(context-P (type function) 
(context B31)(domain B31) (id 1421))，與條件 (context-P (type function) (context ?Px) 
(domain ?do1) (id ?id1))配對後，條件中的所有?Px、?do1 和?id1 變數將被替換成 B31、
B31 和 1421 的值；由於變數於規則中須保持一致，造成只有(context (type function) 
(context B31) (domain B31) (id 1421))事實能和規則中的平行條件(context (type function) 
(context ?Px) (domain ?do1) (id ?id1))進行配對如圖 14，因此每個工作節點上所進行的配
對，係由規則中特定條件與特定的 context 事實所完成。 
所提方法仍有其餘優點，若工作節點個數少於平行事實個數，則平行事實與規則中
條件的配對，不因平行後於各個工作節點上對複數筆平行事實進行推理，而使條件和平
行事實於整個執行中重複地配對，意即相同的條件和平行事實於 CLIPS 程式執行期間，
僅配對一次。在上述的假設中，主節點會將所有平行化事實存於工作池(tasks pool)中，
而後將之交由工作節點分別進行推理，且工作節點每次推理下一筆事實前需重置(reset)
推理引擎。 
17 
 
 19 
 
(TYPE SLAVE))。 
於 CLIPS 程式開始執行前，需先將所有假指令進行處理；對應事實將從 CLIPS 檔
案中讀出，而後存於主節點的記憶體上；回傳事實名稱由工作節點所保存；接著主節點
透過自我排程機制[17]決定每次分配給工作節點對應事實的數量，於每次排程時，複數
筆對應事實將指派給工作節點，而後一個一個的將包 含對應條件的規則與對應事 實進
行配對，好減少  inter-process communications；工作節點只要一完成該次指派對應事實
的推理，即將回傳事實送回主節點；最後主節點待所有指派給工作節點的對應事實都完
成推理並送回回傳事實後，以納簡規則對全部的回傳事實進行推理。 
 
第二節  工作流程式平行程式模型設計理念 
在大型或複雜的應用中常涵蓋不同程式特性的內容，若平行化時將程式特性列入考
量，將不同特性的程式內容給予合適的平行化方法，則可使應用的平行度提高且能大幅
減少執行所需時間。原先架構中，只能從 data-parallel 或 send-receive 中選擇一種，遇到
無法以該方法平行化的內容就維持循序執行，因此無法有效的平行化應用中所有可平行
程式碼(如圖 1)；上述的問題係因平行化時將載入整份程式碼，無法針對不同的內容給
予對應的執行，換句話說若將程式碼根據其內容特性做區隔，分成數個檔案，再將不同
的檔案套以合適的平行化方法即可解決該問題。 
上述的方案會根據分割時採取的方式影響平行化的效能增益，下面對不同的分割方
式進行探討。(1)以規則作為分割依據：CLIPS 應用的執行係通過事實及規則的比對所
決定，但對大型應用而言往往需要多個規則才能呈現一項完整的功能，因此若將負責同
一功能之規則定義於不同檔案之中，分別載入並套用不同的平行化方法，將使功能缺乏
完整性，況且可平行化的程式內容係由數個規則所組成(如無資料相依性或可同時執行
之獨立工作)而非單一規則，因此以規則做為分割依據並不恰當；(2)以模組作為分割依
據：模組通常係於開發大型 CLIPS 時使用，每個規則定義時可註明該規則係屬於哪個
模組之中(預設為 MAIN 模組)，通常開發人員會將將負責同一項功能的多個規則定義於
同一模組之中(因為同一時間能運作的只有屬於同一模組內的規則)，此設計利用模組進
行規則的群組化，進而提高調校及偵錯的效率，故以模組作為分割的依據較規則來的恰
 21 
 
send-receive parallel using message passing programming mode 
logic operation parallel using logic-parallel programming mode 
sequential execution sequential section executes in sequential way 
接著介紹區段間如何透過不同的workflow定義，呈現相異的程式設計模型，表 5中
呈現三種workflow類型。第一類中，workflow以循序方式安排區段的執行，每個區段都
需等待前一區段完成後才開始執行，此方法中區段可自行選擇適當的方法執行；第二類
中，同時執行多個個別以循序方式執行的區段，此方式適用於能以job-parallel平行化的
應用，每個區段分別對應一至多項可獨立執行之工作，雖然每個區段負責的工作不盡相
同，但皆使用相同的輸入(前一區段產生的中間結果)，因此以job- parallel能有效的加速
執行效能；最後一類係將前兩類組合後陳列，應用開發人員依據需求將程式分成多個區
段，再依據區段間互動的情況安排workflow，由於此方式可適性高故多用於複雜應用，
反之較為簡單的應用，則可使用前兩種方式安排不同區段的執行。下面我們以三個例子
進一步說明不同程式設計模型中dataflow及workflow的情況。 
表 5. 流程式平行開發模型所支援執行方式一覽表 
Workflow type Comments 
execute sections sequentially a section begins when previous section finish jobs 
execute sections in parallel execute different section at the same time 
mixed section combination a developer creates his own programming model 
一、 範例一：以混和方式平行化 
第一個範例應用程式由兩個部份程式碼所組成，前半部係由無資料相依性的運算所
組成，後半則係由可平行化程式碼組成，前面介紹過，平行化無資料相異性程式時以
data-parallel 方法平行化，其餘可平行化部份交由 send-receive 處理，如此能最大限度的
減少應用的執行時間，進而增加平行化應用所帶來的效能增益。 
圖 15 呈現範例一平行化時檔案內容的對應，原先的sequential code平行化後可對應成
三份檔案(workflow、S1 及S2)，workflow用來定義區段的執行順序，如圖中寫法則表示
S1 與S2 以表五中sequential方式安排執行順序，因此S2 的執行會等到S1 結束之後才會開
始，另外，任一個區段執行結束後，CLIPS引擎中的知識庫將清空並等待下個區段的資
料進來，因此若S2 需要用到S1 所產生的中間結果，需透過保留事實的操作將待保留之
事實存入記憶體，並於清空知識庫後載入，反之則可省掉workflow中保留事實的定義；
  
圖 16. 範例一：區段 S1,S2 中節點互動示意圖 
二、 範例二：適用多平行化範例 
範例二中 M1 和 M2 係彼此獨立的工作且不存在相依事實，故該範例可使用
data-parallel 或 job-parallel 平行化，下面將分別進行說明。 
圖 17為採用data-parallel方式平行化加速執行， 初始事實 D為所有事實的集合，其中
包含平行事實D1(parallel facts)及初始事實D2(initial facts)，平行事實僅由主節點載入並透
過自我排程機制分配平行事實作為工作節點推理的輸入。在新的開發模型中，採主從式
架構，不同平行化方式的內容將被分於不同區段檔案之中(如下圖中區段S1)，其中每個
區段包含初始事實及模組的定義，且平行後初始模組檔案需於LHS中加入RANK值的判
斷，以決定該規則係由何者所負責(特定節點、主節點或工作節點)，若是該規則係所有
節點皆需負責，可不必特別註明。 
圖 18為範例二使用data-parallel平行化工作流示意圖，假設環境中有三個節點(一個主節
點和兩個工作節點)，首先主節點需要將平行事實載入記憶體之中，並於收到來自工作
節點的工作要求(request)後，根據自我排程機制所計算出的資料量分配平行事實給該節
點，由於主節點同時只能處理單一要求，若同時有多個節點送出要求則只有其中之一的
要求會被處理，其餘的節點則進入等待階段直到該節點所送出的要求被接受為止，待到
所有平行事實分配完畢後，若主節點收到工作節點對平行事實的要求則會回傳結束訊號，
所有節點上的工作都完成後才代表該應用的執行完成。 
23 
 
 平行執行，故該應用平行化後工作流為圖 20，其中我們假設工作節點為W0 及W1 分別
處理區段S1 和S2 所對應的工作，前面提過分給不同節點的工作係彼此獨立，故可減少
同步及傳輸的時間。 
從對範例的說明中可以發現，開發人員可以根據對應用的瞭解採用平行開發模型所
提供的平行化方法加速執行，如此一來能得到最好的執行效能，設定的方式也只需要透
過假指令及資料流即可完成。除了說明我們設計的理念外，下面接著介紹在本篇論文中
新提出來的平行程式設計模式 logic-parallel programming mode，該設計模式係利用某些
應用執行時的特性(部份結果有解則代表已經找到答案，其他節點上的工作可不必繼續)
加速專家系統應用的執行效能。 
 
圖 11. 範例二：以 job-parallel 平行化資料流示意圖 
25 
 
 則推理需等到上一個規則完成後才能開始，因此該種執行方式為三種之中推理時間最長
的一種，執行時間為 。cba TTTT ++=
)T,T,Tmax( cba=
圖 22為非中斷平行的流程示意圖，由於不同規則
係交由不同工作節點負責處理，因此對於任一規則的推理都是同時開始，該種方式中先
推理完的節點需等待其他節點的完成，因此跟圖 21相比多了閒置的狀態，此種方式若
想使效能達到最好，通常需要透過負載平衡的機制，盡可能讓每個節點同時結束，該方
式所需執行時間為  T
 
圖 21. 依序執行之執行方式示意圖 
 
圖 22. 非中斷平行之執行方式示意圖 
圖 23中呈現使用中斷平行的流程示意圖，該應用包含三個規則的推理，推理時間長短
27 
 
  
第三節  工作流程式平行程式模型設計 
在新的設計中，我們將應用根據其程式特性分別數個區段以不同的方式執行，這樣
的方式由於可以根據每個區段的程式特性選擇執行方式，因此能比先前的方式有更高的
平行度及執行彈性，更重要的是平行度的提高能加速平行化後應用的執行。隨著將平行
前的 CLIPS 應用程式內容切割並加上對區段及其屬性的定義，開發人員能有效率且兼
具易維護性的方式進行應用的平行化，下面將詳細介紹平行前後所定義內容的差異。 
開發人員除了需要將不同模組定義規則內容，分別撰寫於與模組名稱相同之CLIPS
檔案中外，還需以假指令定義平行資訊。圖 24為使用新的設計其檔案定義內容平行前
後對照表，從圖中可以發現原先的一份程式內容將被切成多份檔案，這些檔案需經
source-to-source interpreter轉換後才會交由parallel CLIPS引擎執行；按照檔案的功能可分
成三類初始事實、模組檔案和專案檔，其中初始事實和模組檔案僅是將其內容獨立成數
個檔案，source-to-source interpreter會根據專案檔中的定義產生區段的檔案，此設計能有
效減少開發人員管理平行化檔案的複雜度，專案檔中除了包含原有的模組  定義及樣板
定義外，亦須定義應用中所使用到的模組名稱、區段名稱、區段的定義及區段間的執行
順序，下面依圖中不同功能程式內容進行說明，平行後所屬檔案名稱及不同程式內容於
小標題中以冒號分隔。 
 
29 
 
 31 
 
(parallel facts)的內容，定義方式可參考本章第三節內容。初始事實語法定義如下，該語
法定義初始事實包含兩筆分別為(data (value 1))和(data (value 2))，從事實的欄位可以判
斷出 data 屬於無序事實且需先定義樣板 data 後才可使用。 
(deffacts init  (data (value 1)) (data (value 2)) ) 
四、 Module file：module N rules 
於前一小節中提過新的設計中會將數個模組合併成一個區段，在這之前需要先將模
組包含的規則及樣板定義等內容分置於不同檔案中且檔名與模組名稱相同以利後續
source-to-source parallel interpreter 的處理，這類檔案在下面的描述中稱為模組檔；另外，
與平行前不同處在於，平行後視需求在規則中 LHS 加入事實 MPI 作為判斷該規則由哪
些節點負責的依據。語法定義如下，該語法定義名為 add_counter 的規則於模組 M1 之
中，該規則 LHS 包含兩個條件，其程式邏輯為當存在事實 data 且節點為工作節點時執
行 RHS 的部份，RHS 的動作係將 LHS 抓到的事實 data 透過事實指標?c 自知識庫中移
除，且新增一筆名為 pack 的事實，pack 存在兩個欄位分別為 name 和 value，name 處填
入工作節點之 RANK 值，而 value 則是將 data 處取得的值?v 加一後填入該欄位中。在
新的設計中除了將原先的定義進一步對應，開發人員需要透過假指令定義下列四項內容，
該定義係為提供 source-to-source parallel interpreter 產生平行資訊及產生區段檔案，
parallel CLIPS engine 將根據上述檔案進行應用的平行化，其中假指令的設計係為避免
與原先 CLIPS 語法有所衝突及降低使用門檻，因此假指令每一行的起始皆由;#開始，分
號在 CLIPS 語法中扮演著標示註解的用途，#則係為了區分假指令及 CLIPS 開發人員所
撰寫之註解。 
(defrule M1::add_counter 
?c <- (data (value ?v)) 
(MPI (RANK ?r&:(neq ?r 0))) 
=> 
(assert (pack (name ?r)(value (+ ?v 1)))) 
(retract ?c) 
) 
五、 Project file：module list 
Source-to-source parallel interpreter 需要知道應用中總共包含哪些模組才能找到對
應的模組檔(檔名與模組名稱相同)，並將其內容合併至對應的區段檔案中。用法如下，
假指令 MODULE 係用來定義使用到的模組名稱，不同模組名稱以空白隔開以資區別，
 33 
 
DEPENDON M1 M2 
(三) Starting module definition of the specified section 
此處係為定義該區段的起始模組，CLIPS 預設起始模組為 MAIN 模組，因此
source-to-source parallel interpreter 會根據此處的定義產生由 MAIN 模組切換到指定起始
模組的 CLIPS 語法，定義語法如下，其中 ENTERFROM 為假指令，空格後則為起始模
組之名稱，此處以模組 M1 為例，每個區段的起始模組只會有一個。 
ENTERFROM M1 
(四) Execution scheme definition of the specified section 
不同的區段有各自使用的平行方法，該方法會直接影響區段於應用中執行的方式，
因此需要以假指令標示，設計中使用 USING 定義區段平行化方法，其中
AUTOPARALLEL、MPI、LOGIC 及 SINGLE 係用來表示平行方法的假指令，分別對應 
第二章第三節的 data-parallel、第二章第四節的 send-receive 及第三章第四節的
logic-parallel 平行化方法和循序執行，並非所有程式片段都能平行，若無法平行則以
SINGLE 表示以循序方式執行該區段內容；另外 data-parallel 及 logic-parallel 可自行定
義回傳樣板的名稱，對 data-parallel 來說，回傳樣板係為將符合的事實送回主節點執行
納簡規則產生最終結果，對 logic-parallel 來說，回傳樣板係將該節點負責運算結果傳給
主節點做邏輯上的 AND 或 OR 運算進而計算出最終結果，回傳樣板的定義需透過假指
令 RETURN 定義之。除平行方法外，仍需定義保留事實(reserved facts)參數的內容，係
因 parallel CLIPS engine 會在區段執行完畢後清空整個知識庫，並載入下個區段的事實
及規則定義，因此若是區段間存在資料相依性，需保留上一個區段產生的中間結果時，
則得於清空前先將保留事實存入記憶體，待清空之後先載入事實再載入新區段的內容，
此處的保留及載入事實係同時成立的操作，因為有保留事實才需要從記憶體中載入。 
定義保留事實的語法使用假指令 POSTOP，考慮到事實的來源及需載入的節點可能
來自環境中的任一節點，因此仍需定義使用的訊息傳遞方式，基於一般性考量，此處僅
提供常見的訊息傳遞方式如 all-to-all、broadcast 及 reduce，若只是存於同一節點可使用
STORE標示，若完全不需保留事實至下一區段，則以假指令NONE標示之，其中 all-to-all
係將每個節點知識庫中符合樣板定義的事實複製 N-1 份，傳給除自己之外的所有節點；
broadcast 係將主節點上的保留事實傳給所有的工作節點；reduce 則是將所有節點知識庫
 35 
 
義執行，S3 及S4 則是採取job-parallel方式平行化，因此需於定義區段平行方法時選擇
SINGLE，並在定義execution flow時以大括號標出同屬job-parallel的區段，大括號內的
區段會交由不同節點負責且同時開始執行，不同區段執行結果可能於後續執行中使用，
故此處保留先前POSTOP的設計，於定義使用job-parallel的區段後以逗號隔開標明
POSTOP所使用的事實保留方式，同時支援上述常見訊息傳遞方式。所支援平行化方式，
依據不同的參數可分為三類，單一平行化、工作平行化及複雜平行化，具體說明整理如
表 6所示。 
;#EXECFLOW S1 S2 {S3 S4,NONE} 
表 6. 新開發模型支援平行化方式整理 
平行化類型 說明 
單一平行化 僅使用單一種平行化方法 
工作平行化 透過執行流程的定義，同時執行位於相同群組中的區段 
複雜平行化 應用牽涉數個區段，且不同區段使用不同平行化方法 
 
第四節  工作流程式平行程式軟體系統架構 
本節中將介紹如何透過系統提供前一小節之功能及語法定義，先從程式流程開始，
於新的開發模型中規範程式設計人員需將專案檔、模組檔及初始事實經由
source-to-source interpreter處理後交由parallel CLIPS engine執行，引擎執行流程約可分成
5 個階段，分別為前處理(preprocessing)、載入保留事實(loading reserved facts)、平行方
式(parallel mode)、存入保留事實(saving reserved facts)及清除(clear stage)，圖 25中呈現
如何將專案檔、初始事實及模組檔案等輸入經source-to-source interpreter產生中間檔案，
再交由於parallel CLIPS engine平行執行的流程，每個檔案包含的內容與前述圖 24相同，
主要元件由source-to-source interpreter及parallel CLIPS engine所組成，下面將一一介紹。 
一、 Source-to-source interpreter 
該元件的輸入由專案檔、初始事實及模組檔所組成，同時該輸入為將sequential code
平行化後所需定義之檔案(圖 24右側)，負責的工作係根據專案檔中定義，整合不同模
組檔案成區段檔案與產生包含平行資訊的檔案，由於該輸出為parallel CLIPS engine之輸
入，因此稱為中間檔案(intermediate files)。 
 圖 13.  Source-to-source interpreter 架構圖 
設計中依巴克斯範式定義語法規則，其中每一條規則可對應為程式語言中的函式，
由於該解析(parse)方式結構簡單，故常被用來描述電腦程式語言。巴克斯範式係由動作
函式(action function)及代符(token)所組成，動作函式表示符合該語法規則後需執行的運
算，代符則是具特殊意義之字串，將巴克斯範式規則、動作函式定義及代符定義整理如
表 7。 
 
表 7.  Source-to-source interpreter 之巴克斯範式、動作符號及代符格式 
Backus-Naur Form with Action Symbol 
<START> → <STATEMENT LIST> EOF 
<STATEMENT LIST> → { <STEMENT> } #para_info_gen 
<STATEMENT> → <DIRECTIVES> | <CLIPS> 
<DIRECTIVES> → DRTV <PROJECT DEFINE> 
<PROJECT DEFINE> → <MODULE LIST> 
<PROJECT DEFINE> → <SECTION DEFINITION> 
<PROJECT DEFINE> → <SECTION ATTRIBUTE > #sec_gen 
<PROJECT DEFINE> → <SECTION EXECUTION FLOW> 
<MODULE LIST> → KEYWORD(MODULE) WORD { WORD } 
<SECTION DEFINITION> → KEYWORD(DECLARE SECTION) WORD { WORD } 
<SECTION ATTRIBUTE> → <NAME> COM <DEP> COM <SCHEME> 
<NAME> → KEYWORD(SECTION) WORD 
<DEP> → KEYWORD(DEPENDON) WORD 
<SCHEME> → <PARALLEL METHOD> COM <POSTOP> 
<SCHEME> → KEYWORD(SINGLE) 
<PARALLEL METHOD> → KEYWORD(USING) <METHOD> 
<METHOD> → KEYWORD(AUTOPARALLEL <RETN> | KEYWORD(MPI) 
<RETN> → COM KEYWORD(RETURN) WORD { WORD } | φ  
<CLIPS> → { CLIPS_CODE | COMMENT } 
Meaning of Action Symbols 
#para_info_gen → to write the parallel information into file (parallel.info) 
#sec_gen → to integrate module files into the specific section file 
Token Types 
DRTV → Begin with a semicolon and a number sign, i.e., ;# 
37 
 
 39 
 
該階段所執行內容將依據前處理載入的平行資訊而決定，不同的平行化方法對應的
內容亦不相同，但此階段中皆需載入區段檔案內容，如平行化方法(data-parallel、
send-receive 和 logic-parallel)中，所有的工作節點皆載入相同的區段檔案，雖然載入的
是相同的內容，主節點及工作節點執行的工作內容係根據規則中 MPI 事實 RANK 值的
定義而決定，而 data-parallel 與 logic-parallel 則會額外載入平行事實的檔案，作為
data-parallel 中的 task；若以 job-parallel 平行化，每個區段檔案交由一個節點負責同時
推理，而每個節點中的推理都以非平行的方式進行。 
(四) 存入保留事實 
該階段可分成兩個部份進行說明，首先，存入之前需先將保留事實從知識庫中取出，
再將取出的保留事實以 vector 的資料結構存於記憶體之中。對大型應用而言，知識庫中
通常存有初始事實、計算過程中產生的中間事實及代表結果的事實等為數眾多的事實，
而取出的過程中又需要將知識庫內的所有事實一筆一筆取出，透過與保留事實的定義比
對，找出確切的保留事實，故此階段的執行時間受目前知識庫中事實的多寡所影響。 
(五) 清除 
CLIPS 程式的執行流程包含 Load、Reset、Run 及 Clear，Load 係將使用 CLIPS 語
言撰寫的應用程式碼載入，並將規則定義加入推理引擎；Reset 則是將知識庫內容清空
後再將新的事實定義加入知識庫中；Run 則是用來啟動推理引擎的推理；Clear 會將
CLIPS 環境初始化成未載入任何內容的情況，而清除的階段正是透過此副程式將環境調
成初始狀態等待下次載入。 
第四章 研究成果與探討 
第一節 組合分工式平行程式開發模型 
我 們 將 CLIPS-based KMKE (Knowledge Management through Knowledge  
Engineering) knowledge management system [38]建置於包含四台主機的異質性叢集式
(cluster)系統，以進行平行化KMKE效能的評估，其中KMKE係由知識模型化(knowledge 
modeling)、知識辨認(knowledge verification)、知識儲存(knowledge storage)和知識查詢
 41 
 
 
圖 28. 不同 problem sizes 下，不同處理器個數執行之效能增益比較. 
第二節 流程式平行程式開發模型 
一、 應用說明及執行特性 
在本次研究中我們分別以知識系統及人力資源網作為探討平行化專家系統之應用，
下面將依序介紹並就研究成果進行探討。 
知識系統(Knowledge Management through Knowledge Engineering, KMKE)係為一由
知識模組化、知識認證、知識儲存及知識查詢所組成之系統化架構，透過這些技術知識
系統可以從知識中推理有用的資訊。在進行推理之前，CLIPS 引擎會把初始事實載入知
識庫中，初始事實越多需要載入的資料量就越大，同時會使執行時間大幅增加，也就是
說在平行後每個工作節點在進行推理之前都需要同樣的操作及時間消耗；而知識系統是
屬於初始事實較多的應用，平行後載入初始事實的時間會大於推理的時間，可以預期效
能增益最高的平行化方法係為載入初始事實次數最少的 job-parallel。 
人力資源網站模糊查詢系統與資訊系統不同，前者係由Fuzzy CLIPS引擎所執行，
其中包含 3 個步驟，(1)模糊查詢條件的表示；(2) 模糊查詢條件與模糊資料的比對；(3) 
符合程度與重要程度的模糊聚合運算。第一點模糊查詢條件的表示，以找工作為例，使
用者可以透過網頁欄位根據對不同工作需求的符合程度及重要性進行設定並透過歸屬
函數定義如圖 29和圖 30，求職者與徵才公司需要刊登資訊大致包含工作經驗、工作地
點、畢業科系、薪資和 第二點模糊查詢條件與模糊學歷五項，輸入畫面如圖 30所示。
  
43 
 
圖 15. 人力資 欄位設定畫面 
圖 16. 模糊聚合運算後結果(依符合程度排序) 
 
二、 實驗結果 
為了確認前一節的預測結果及不同參數的影響，我們於異質性叢集式系統上進行實
驗，環境中所用機型規格整理如表 9，為方便後面實驗數據的說明，我們將不同機型依
據效能排序分別代稱為type 1 ~ type 5，數字越小表示效能越好，其中該環境最大工作節
點數為 48 個processors；另外，在使用job-parallel時係將可獨立執行的模組交由不同工
作節點負責執行，因此平行化所需要的工作節點數會與可獨立執行之模組數量相同，但
使用data-parallel或send-receive方式平行化則不在此限。依據不同的需求，本節中第一點
及第二點實驗僅使用type 1～type 3機型的機器，而第三點的實驗則係使用type 1 ~ type 5
源網工作經驗及科系要求
 
 
 45 
 
平行化方式的影響，從結果來看以job-parallel加速應用執行效能最好，這點符合我們前
一小節中的預期， -paralle 好每個節點所需要負責的工作內容，所以每
個節點上都只會執行一次載入初始事實的動作 ，大幅節省了
載入初始事實的次 因此能 allel方法中不同的排程機
制的結果，亦可發 規 且載入初始事實次數少的機制(GSS, 
FSS)相較之下能有 的結果 衡效果較好的機制反而因為載入初始事實的增
加，導致執行時間的拉長，故以加速知識系統應用來說，若環境中節點數較少(小於 16
個processors) job a-parallel會有較好的效能。 
 
7. 以不同 行化效能增益(不同資料量) 
圖 34中呈現資料量為 2690 影響，其中節點數少時
用的節點數增加FSS反而變成效果最差的方式，這
job l一開始就分配
，與data-parallel的方式相比
數， 有最好的效能增益；反觀data-par
現相同的 律，一次分配較多工作
不錯 ，而負載平
-parallel 的效果是最好的，反之則是dat
圖 1 自我排程機制進行平
時不同processors對四種排程機制的
0.00 
5.00 
10.00
FSS表現較其他機制突出，但隨著使
是由於FSS在節點數少時每個節點都能分到較多的資料並減少載入初始事實的次數；當
節點數增加後FSS所分出去的資料量則會減少，連帶的增加該次執行中所需的載入次數，
以知識系統來說每一次的載入都需要花費大量的時間，若未能處理夠多的推理，等同於
浪費時間在載入及訊息傳遞上，進而影響平行化後效能增益。 
 
15.00
20.00
6 134
Sp
ee
du
p
Speedup w
 
 
107 5 1614 1883 2152 2461 2690
Data size
ith 4 processors
CSS(50)
GSS
FSS
TSS
job‐level parallel
 47 
 
其他節點皆需等待其完工方能結束，因此比
另兩個方式多了等待的延遲。 
 
圖 36中呈現使用大量processors ，不同排程間效能增益趨勢
與使用較少 相同，但可看出
 
圖 不同排程機制使用 32 個 proce 效能增益圖( 料量) 
就越多，造成效能增益不如data-parallel；環境中並非所有節點都由相同機型所組成，為
了減少負載平衡所造成的影響，於data-parallel時我們採用不同的排程機制進行實驗，從
實驗結果來看CSS(50)及TSS能獲得較好的效能增益，分析其原因在於其餘兩種機制一
開始分派給效能較差節點的資料過多，導致
圖 19. 不同平行化方法使用 8 個 processors 效能增益圖(不同資料量) 
時不同排程機制的效能增益
processor processor數的增加會使效能增益成長。 
 20. ssors 不同資
0.98 
1.36 
1.53 
1.61 
1.69 
1.67 
10.36  
 
9.84
18.97 
31.49 
38.90
47.14 
48.87 
8.47
15.43 
 
31.66 
34.63 
35.47
9.80
21.37 
41.50
 
0.00 
20.00 
40.00 
60.00 
Data size
 
23.32
50.61
82.43 
1
3 
 
 
 
25.81  
 
 
58.09
77.13 
92.43 
80.00 
120.00 
140
160.00 
1000 2000 4000 6000 8000 10000
Sp
ee
du
p
d it ro r
1
4.6
143.41 
.00 
Spee up w h 8 p cesso s
job‐level parallel
CSS(50)100.00 
GSS
FSS
TSS
16.34 
40.46 
95.09 
151.62 
214.74 
265.13 
13.78 
39.57 
86.70 
126.05 
158.25 
179.03 
18.08 
39.86 
78.58 
97.90 
120.09 
137.14 
13.59 
42.18 
79.81 
123.18 
175.65 
203.43 
0.00 
50.00 
100.00 
150.00 
200.00 
250.00 
300.00 
Speedup with 32 processors
CSS(50)
GSS
1000 2000 4000 6000 8000 10000
Sp
ee
du
p
Data size
FSS
TSS
 49 
 
能增益將最差，甚至比最效能最差的節點作為主節點還差，這是由於身為 NFS 
server 的節點除了需要負責處理來自工作節點的需求外，還需佔用一部分資源處理來自
NFS client
並非主節點亦不會產生上述所提之效能瓶頸。 
同機型的機器進行實驗，可以看到由於寫檔的額外時間消耗對每個節點而言都是
效減
期其效
的操作，因此會在主節點處形成效能瓶頸；反之，若想達到最好的效能增益
則是將 NFS server 的節點作為工作節點之一，這是因為若 NFS server 作為工作節點則每
次寫入都是寫至本地端而不需加上網路傳輸及 NFS 系統的額外時間，因此能縮短整體
執行時間，同時因為 NFS server
為了驗證我們的推論於實驗中皆使用的最大資料量 10000 及五個來自不同機型的
processor cores作為環境中的節點，考慮到排程機制可能影響實驗結果，所以我們選擇
較穩定的CSS(50)作為實驗所使用的機制，CSS(50)指的是每次分配工作給節點時固定分
配 50 筆給工作節點，直到剩餘工作量不足 50，則將剩下的工作一併寄出。圖 38中呈
現實驗的結果，NFS server係屬於type 3 的機型，故可從包含NFS server的數據中發現若
以NFS server作為主節點則會產生相當大的效能瓶頸；若以NFS server作為工作節點反而
能有最好的效能增益，因為在該實驗中主要的執行時間係花在將結果寫入檔案的步驟而
非推理的步驟，這一點可以從扣除NFS影響的情況下不同效能的節點作為主節點所需要
的執行時間大致相同即可得知。另外圖中不包含NFS server的數據我們是使用與NFS 
server
相同的，因此若能以效能較差的節點作為主節點，效能較好的節點作為工作節點，能有
最好的效能增益，這是因為此時執行時間反而係以推理階段所花費的最多，且每個節點
都需要花費一段不少的時間才能完成一次分派的工作，因此主節點即使是效能最差的節
點也不會為了處理高頻率的需求而產生效能瓶頸，且以效能最好機器作為工作節點能有
少每一份工作所需的時間，兩者雙管齊下後能使效能增益在該環境中獲得最大的增
益。 
 51 
 
 
圖 23. 以 GSS 排程機制執行多次執行時間分佈圖 
 
圖 24. 不同排程機制下各節點工作負載示意圖 
  
0
5
10
15
20
25
30
1 4 7 10 13 16 19 22 25 28
E
xe
cu
tio
n 
tim
e 
(s
ec
)
Iterations
GSS, NP=8
0
5
10
15
20
25
CSS GSS
E
xe
cu
tio
n 
tim
e 
(s
ec
)
Self-scheduling schemes
Workload distribution in seconds
worker 1
worker 2
worker 3
worker 4
worker 5
worker 6
worker 7
 53 
 
為考慮到開發人員未必熟悉假指令和新增語法的使用，在剖析檔案時不採取 scan line
的方式逐一讀取後存入，而是透過 LL(1)的語法分析提供良好的除錯訊息(如錯誤發生於
第幾行或該錯誤類型係屬於語法錯誤或字彙錯誤等等)，如此能減少開發人員在偵錯及
維護所花費的時間；而 source-to-source interpreter 的輸出則係由 parallel CLIPS engine
所處理，處理時引擎將根據先前各區段定義的執行方式及順序安排各時段執行的內容及
方式，以達到有效率平行化專家系統應用的目的。在實驗中我們選用不同程式特性的應
用來呈現新設計所能支援的多樣性，選用的應用包含知識系統及人力資源網兩種。 
知識系統應用平行化後，每次工作節點取得新分配到的工作後，在開始進行推理前
都需要重新載入初始事實，而此步驟又需花費大量時間，故知識系統在選擇平行化方式
時較適合選擇載入初始事實次數越少越好的方式；以結果來看，在節點數小於 16 的情
況下，最好能有 15 倍的效能增益(以 job-parallel 平行執行)，若有更多的節點可以使用，
則最好能達到 25 倍左右的效能增益(CSS(50), GSS, TSS)。 
人力資源網應用與知識系統不同，該應用平行化後的執行時間主要花在推理的步驟，
也就是說若節點獲得過多的工作則會產生效能瓶頸，故該類應用較適合使用 CSS 這類
每次分配少量資料的排程機制分配工作，如此可避免負載不平衡所引起的效能瓶頸，最
佳化以後效能增益最多能達到 260 倍左右；除了呈現效能增益外，同樣的應用根據不同
的考量能選擇不同的方式平行化，如知識系統可使用 data-parallel、send-receive、
logic-parallel 及 job-parallel 幾種方式平行化，新的設計除了能提供良好的效能增益，更
重要的是它具備相當高的程式彈性及便捷的操作，有利於原專家系統應用開發人員進行
平行應用的開發。 
另外，根據實驗數據與不同參數間的影響，我們可以得到以下的結論(1)載入初始
事實需時較久的應用(知識系統)較適合採用每次分配較多資料量以減少載入次數，反之
(人力資源網應用)則應選用每次分配較少資料量的排程機制；(2)牽涉檔案讀寫時，需注
意 NFS server 的影響，應盡可能的避免該節點負責過多的工作，進而避免過多 NFS 存
取要求引起的效能瓶頸；(3)在異質性環境中，使用同樣的參數，實驗結果可能呈現兩
極化，因此在執行時建議多增加執行次數或選用每次分配較少工作量的排程方式可減少
該現象發生的機率。 
總的來說新的開發模型能提供良好的執行效能、高度的設計彈性及便捷的操作，基
 55 
 
Self-Scheduling Schemes for Rule-based Expert Systems,” The 2nd International 
Conference on Security-enriched Urban Computing and Smart Grids (SUComS 
2011), 21-23 September 2011, Hualien, Taiwan. 
[9] Chao-Chin Wu, Lien-Fu Lai, Liang-Tsung Huang, Syun-Sheng Jhan, Chang Lu, 
“Parallel TID-Based Frequent Itemsets Mining Algorithms with Dynamic Task 
Scheduling for Heterogeneous Cluster Systems,” The First Symposium on Cloud 
and Service Computing (SC2-2011), January 20-21, 2011, Taipei, Taiwan. 
（NSC98-2221-E-018-008-MY2） 
[10] Lien-Fu Lai, Yu-Cheng Lin, Chao-Chin Wu, Liang-Tsung Huang, "A 
Self-Adaptation Approach to Fuzzy-Go Search Engine," International Computer 
Symposium, Tainan City, Taiwan, Dec. 16 - 18, 2010. (Accepted) 
（NSC98-2221-E-018-008-MY2） 
[11] Chao-Chin Wu and Jia-Xian La, “A Min-Min-based Job Scheduling Algorithm for 
Fault-Tolerant Large Scale Computational Grid Systems,” the 2010 International 
Conference on Grid Computing and Applications (GCA'10), July 12-15, 2010, Las 
Vegas, Nevada, USA. (Accepted) 
[12] Chao-Chin Wu, Lien-Fu Lai, Yu-Shuo Chang, “Parallelizing CLIPS-based Expert 
Systems by the Permutation Feature of Pattern Matching,” The 2nd International 
Conference on Computer Engineering and Applications (ICCEA 2010), Vol.1, 
pp.214-218, March 19-21, 2010, Bali Island, Indonesia. Published by IEEE 
Computer Society. (EI) 
[13] Chao-Chin Wu, Liang-Tsung Huang, Lien-Fu Lai, “A Batch Fuzzy Query System 
for Predicting Protein Stability Changes,” The 2nd International Conference on 
Computer Engineering and Applications (ICCEA 2010), Vol.1, pp.257-261, March 
19-21, 2010, Bali Island, Indonesia. Published by IEEE Computer Society.  (EI) 
[14] Chao-Chin Wu, Lien-Fu Lai, Jenn Yang Ke, Syun-Sheng Jhan, Yu-Shuo Chang, 
“Improving Rule-Based System Performance by Dynamic Task Scheduling,” The 
6th Workshop on Grid Technologies and Applications (WoGTA’09), pp. 141-147, 
18-19 Dec., 2009, Taitung, Taiwan. 
[15] Chao-Chin Wu, Liang-Tsung Huang, Lien-Fu Lai, Ming-Lung Chen, “Enhanced 
Parallel Loop Self-Scheduling for Heterogeneous Multi-Core Cluster Systems”, 
The 10th International Symposium on Pervasive Systems, Algorithms and 
Networks (I-SPAN 2009), pp. 568-573, Dec. 14-16, 2009, Kaohsiung, Taiwan. (EI) 
[16] 伍朝欽、柯振揚、張育碩、朱文達，“以自我排程機制提升 FuzzyCLIPS 專家
系統之執行效能”,第十一屆海峽兩岸資訊（信息）技術研討會，pp. 268-275, 12
月 6 日~10 日，2009 年，中央大學，台灣。 
 57 
 
第六章 參考文獻 
[1] J.C. Giarratano, and G.D. Riley, Expert Systems: Principles and Programming, Fourth ed.: Course 
Technology, 2004. 
[2] CLIPS. "CLIPS: A Tool for Building Expert Systems," http://clipsrules.sourceforge.net/. 
[3] T. Amagasa, K. Kido, and H. Kitagawa, “Querying XML Data using PC Cluster System,” in 8th 
International Conference on Database and Expert Systems Applications, pp. 5-9, 2007. 
[4] T. He, J. Ni, and G. Wang, “A Heterogeneous Windows Cluster System for Medical Image Reconstruction,” 
in Proceedings of the First International Multi-Symposiums on Computer and Computational Sciences, pp. 
410-415, 2006. 
[5] L. JaeDeok, C. ByeongCheol, P. SoHee et al., “A Study of Providing the Integrity on Cluster System,” in 
10th International Conference on Advanced Communication Technology, pp. 1925-1928, 2008. 
[6] O. Mori, S. Matunaga, and N. Waeda, “Research and development of tethered satellite cluster systems,” in 
Proceedings. 2000 IEEE/RSJ International Conference on Intelligent Robots and Systems, 2000 (IROS 2000), pp. 
1834-1840, 2000. 
[7] E. Bartocci, D. Cacciagrano, N. Cannata et al., “An Agent-Based Multilayer Architecture for 
Bioinformatics Grids,” in IEEE Transactions on NanoBioscience, pp. 142-148, 2007. 
[8] A. Chervenak, I. Foster, C. Kesselman et al., “The Data Grid: Towards an Architecture for Distributed 
Management and Analysis of Large Scientific Datasets,” in J. Network and Computer Applications, pp. 187-200, 
2000. 
[9] I. Foster, C. Kesselman, and S. Tuecke, “The anatomy of the Grid: Enabling Scalable Virtual Organizations,” 
in International J. Supercomputer Applications, pp. 200-222, 2001. 
[10] F. Fox, and D. Gannon, “Computational grids,” in IEEE Computing in Science and Engineering, pp. 74-77, 
2001. 
[11] W. Li, M. V. P. Dib, and D. A. Cardoso, “Grid Service Agents for Real Time Traffic Synchronization,” in 
Proceedings of WI '04, pp. 619-623, 2004. 
[12] L. Meng, L. Bai, and W. Yang, “A Grid Information Service Model Based on E-Learning Grid,” in 
Proceedings of ICNC'07, pp. 545-548, 2007. 
[13] MPICH2. "MPICH2: High-performance and Widely Portable 
MPI," http://www-unix.mcs.anl.gov/mpi/mpich1/. 
[14] MPI: Message Passing Interface Standard. http://www-unix.mcs.anl.gov/mpi/. 
[15] C.C. Wu, L.F. Lai, and Y.S. Chang, “A Study of Designing a Grid-Enabled Expert System Language,” 
Journal of the Chinese Institute of Engineers, vol. 31, pp. 7, 2008. 
[16] C.C. Wu, L.F. Lai, and Y.S. Chang, “Towards Automatic Load Balancing for Programming Parallel Fuzzy 
Expert Systems in Heterogeneous Clusters,” Journal of Internet Technology, vol. 10, no. 2, pp. 8, 2009. 
 59 
 
[35] G.R. Jahanshahloo, F. Hosseinzadeh Lotfi, and M. Izadikhah, “Extension of the TOPSIS method for 
decision-making problems with fuzzy data,” Applied Mathematics and Computation, vol. 181, no. 2, pp. 
1544-1551, 2006. 
[36] Y.M. Wang, and T.M.S. Elhag, “Fuzzy TOPSIS method based on alpha level sets with an application to 
bridge risk assessment,” Expert Systems with Applications, vol. 31, pp. 309-319, 2006. 
[37] T. Yang, and C.C. Hung, “Multiple-attribute decision making methods for plant layout design problem,” 
Robotics and Computer-Integrated Manufacturing, vol. 23, pp. 126-137, 2007. 
[38] L.-F. Lai, “A knowledge engineering approach to knowledge management,”  Information Sciences, vol. 
177, no. 19, pp. 4072–4094, 2007. 
  
 61 
 
Schemes for Rule-based Expert Systems,” The 2nd International Conference on 
Security-enriched Urban Computing and Smart Grids (SUComS 2011), 21-23 September 2011, 
Hualien, Taiwan. Communications in Computer and Information Science, Vol. 223, pp. 
149–158, 2011. 
[2] Chao-Chin Wu, Lien-Fu Lai, Yu-Shuo Chang, “Parallelizing CLIPS-based Expert 
Systems by the Permutation Feature of Pattern Matching,” The 2nd International Conference 
on Computer Engineering and Applications (ICCEA 2010), Vol.1, pp.214-218, March 19-21, 
2010, Bali Island, Indonesia. Published by IEEE Computer Society. (EI) 
 
將發表之論文 
Chao-Chin Wu, Lien-Fu Lai, Liang-Tsung Huang, Chung Lu “A Workflow-based Parallel 
Programming Model for Developing Expert System Applications”, submitted to SC2 
2012. 
 
 
3. 請依學術成就、技術創新、社會影響等方面，評估研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）（以
500 字為限） 
 
第一年我們分析組合與排列方式的規律性，提出了一個事實配置的方法
來達到平行推理的目標，並且以自我排程策略來分配工作，以達到負載平衡
的效果。程式設計師只需標明哪些事實要以哪個規則平行推理，我們修改後
之解譯器會自動將程式平行化。我們提供三個用來標示哪些規則和事實可以
平行執行的假指令和定義規則應由主節點或工作節點負責進行推理的事實樣
板(fact template)。為驗證設計的效能增益，於含有十二個處理器核心的異
質性叢集式系統上，實作知識庫管理系統。結果顯示我們提出設計的效能增
益最多可達 10.38。其研究成果已經發表於 ICCEA 2010，收錄於 IEEE 電子資
料庫中。 
第二年我們提出流程式平行程式開發模型，目前設計所提供的區段執行
方式包含 data-parallel、send-receive、logic-parallel 及循序執行四種；
另外，根據區段執行流程的安排不同還能再提供 job-parallel 等不同的執行
方式加速應用執行。應用通常包含數個區段，且根據程式特性的不同每個區
段又可選擇多種不同的執行方式及執行順序，因此在新的設計中開發人員能
 國科會補助專題研究計畫項下出席國際學術會議心得報告 
                           日期：   年   月   日 
計畫
編號 
NSC 98－2221－E－018－008－MY2 
計畫
名稱 
平行 CLIPS 語言及其解譯器中自我排程策略之設計 
出國
人員姓名 
伍朝欽 
服
務機構
及職稱 
國立彰化師範大學資訊工程
學系副教授 
會議
時間 
自 99 年
3 月 19 日至
99 年 3 月 21 
日 
會
議地點 
印尼巴里島 
會議
名稱 
(中文)第二屆電腦工程及應用研討會 
(英文) The 2nd International Conference on Computer 
Engineering and Applications （ICCEA 2010） 
發表
論文題目 
(中文) 
(英文) Parallelizing CLIPS-based Expert Systems by the 
Permutation Feature of Pattern Matching 
一、參加會議經過 
本次雖然參加的是 ICCEA 2010 會議，但是基本上有四個
會議在同一個地點所舉行，其他三個分別為： 
z 2010 The 2nd International Conference on Telecom 
Technology and Applications (ICTTA 2010) 
63 
 
 65 
 
議論文。 
二、與會心得 
此次的主辦單位是 the International Association of 
Computer Science and Information Technology (IACSIT)，
該組織最近積極於各項學術活動，除了舉辦多項國際會議外，
也出版國際期刊論文。由於是剛從事相關活動，因此在議程規
劃上，有其可以改善的地方，例如該會議所涵蓋的領域相當廣
泛，但是其在報告時，未能作有效之分組，這將造成無法作較
深入的討論，雖然可以多聽其他領域的報告，而產生其他可能
的交流。另外，同一場次的報告論文數真的太多了，平均都有
十幾篇。由於同一場次的領域差異可能相當大，因此這麼多的
論文同時發表，總覺得太多了。倒是舉辦地點的選擇以及場地
的佈置都相當用心，可以讓與會者可以在相當宜人的環境中進
行學術上的意見交流，相當不錯。 
三、考察參觀活動(無是項活動者略) 
    無。 
四、建議 
IACSIT 是一個新興的組織，非常積極，或許可以鼓勵加
入此組織參與運作。 
五、攜回資料名稱及內容 
    ICCEA 2010 proceedings 
六、其他 
 
98 年度專題研究計畫研究成果彙整表 
計畫主持人：伍朝欽 計畫編號：98-2221-E-018-008-MY2 
計畫名稱：平行 CLIPS 語言及其解譯器中自我排程策略之設計 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 1 1 100%  
研討會論文 6 0 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 3 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 9 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 7 0 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 3 3 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
國科會補助專題研究計畫成果報告自評表 
請就研究內容與原計畫相符程度、達成預期目標情況、研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）、是否適
合在學術期刊發表或申請專利、主要發現或其他有關價值等，作一綜合評估。
1. 請就研究內容與原計畫相符程度、達成預期目標情況作一綜合評估 
■達成目標 
□未達成目標（請說明，以 100 字為限） 
□實驗失敗 
□因故實驗中斷 
□其他原因 
說明： 
2. 研究成果在學術期刊發表或申請專利等情形： 
論文：■已發表 □未發表之文稿 □撰寫中 □無 
專利：□已獲得 □申請中 ■無 
技轉：□已技轉 □洽談中 ■無 
其他：（以 100 字為限） 
Chao-Chin Wu, et al., ’The Performance Impact of Different Master Nodes on 
Parallel Loop Self-Scheduling Schemes for Rule-based Expert Systems,’ 
Communications in Computer and Information Science, Vol. 223, pp. 149–158, 2011.
 
 
 
3. 請依學術成就、技術創新、社會影響等方面，評估研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）（以
500 字為限） 
第一年我們分析組合與排列方式的規律性，提出了一個事實配置的方法來達到平行推理的
目標，並且以自我排程策略來分配工作，以達到負載平衡的效果。程式設計師只需標明哪
些事實要以哪個規則平行推理，我們修改後之解譯器會自動將程式平行化。我們提供三個
用來標示哪些規則和事實可以平行執行的假指令和定義規則應由主節點或工作節點負責
進行推理的事實樣板(fact template)。為驗證設計的效能增益，於含有十二個處理器核
心的異質性叢集式系統上，實作知識庫管理系統。結果顯示我們提出設計的效能增益最多
可達 10.38。其研究成果已經發表於 ICCEA 2010，收錄於 IEEE 電子資料庫中。 
第二年我們提出流程式平行程式開發模型，目前設計所提供的區段執行方式包含
data-parallel、send-receive、logic-parallel 及循序執行四種；另外，根據區段執行
流程的安排不同還能再提供 job-parallel 等不同的執行方式加速應用執行。應用通常包
含數個區段，且根據程式特性的不同每個區段又可選擇多種不同的執行方式及執行順序，
因此在新的設計中開發人員能更有彈性的平行化應用，再加上新設計中假指令及類似
CLIPS 語法的程式設計風格，能提供便捷的操作並降低使用的門檻，此設計讓開發人員可
