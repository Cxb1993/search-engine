英文關鍵詞： keyword extraction, microblog, short articles 
 
domain.
Both methods contribute by each providing
a list of keyphrases for a particular text, sorted
by their rank or “importance” as seen from
each approach. Ultimately, a collaborative al-
gorithm is executed, in which the two keyphrase
lists are merged to create an overall list of
keyphrases for that text. The merging algo-
rithm thus takes into account the ranks given
by both approaches to each keyphrase and pro-
duces a final, collaborative score reflected by
these ranks.
Our work focuses on extracting keyphrases
from short articles, as these are some of the
most common types of text documents avail-
able on the Internet today. We have tested
HybridRank on a large number of abstracts be-
longing to scientific papers across different do-
mains. The results of our experiments show the
effectiveness of the proposed method and of the
improvements made to the KEA and TextRank
algorithms. Our system obtained a higher pre-
cision and recall than both KEA and TextRank
in most cases, and obtained a higher precision
and recall than at least one of these two meth-
ods in all the cases. The evaluation of our sys-
tem also shows how knowledge from supervised
and unsupervised approaches can be shared to
produce keyphrases of better quality.
The remainder of this paper is organized as
follows: Section 2 reviews previous work on su-
pervised and unsupervised methods for auto-
matic keyphrase generation. Section 3 briefly
describes the original functioning of KEA and
TextRank. Section 4 describes the overall
framework of HybridRank, including the mod-
ifications we have made to the KEA and Text-
Rank algorithms. Section 5 presents the setup
and results of our experiments. Finally, we pro-
vide conclusions and future work in Section 6.
2 Related Work
Early research on the automatic generation
of keyphrases generally took one of two ap-
proaches: keyphrase assignment or keyphrase
extraction; both using machine-learning meth-
ods [16]. Keyphrase assignment selects
keyphrases from a preexisting controlled list of
terms and assigns them to a particular doc-
ument that can be best described by them.
Keyphrase extraction, on the other hand, ex-
tracts these terms from the document itself.
Recent work has further generalized these ap-
proaches and categorized them into either su-
pervised or unsupervised. Figure 1 illustrates
the different categorizations for keyphrase ex-
traction2 methods.
Supervised methods for keyphrase extrac-
tion, in essence, make use of training datasets—
a large corpus consisting of texts and their cor-
responding (previously assigned) keyphrases—
to classify candidate terms as keyphrases. Two
traditional methods in this category are KEA
[16] and GenEx [13]. KEA uses a Na¨ıve Bayes
classifier constructed from two features ex-
tracted from phrases in documents: the TFIDF
and the relative position of the phrase. GenEx
uses a steady-state genetic algorithm to build
an equation consisting of 12 low-level param-
eters. Its learning process adjusts the values
of these parameters values with each new en-
try from the training dataset to maximize the
system’s precision.
Frank et al. stated in their second KEA pa-
per [2] that despite testing their classifier with
several other features (some of them also exper-
imented with by Turney [13]), only the TFIDF
and the relative position turned out to be use-
ful. These features are referred to as the base
feature set in other research [3, 12, 7]. Even
though KEA and GenEx perform similarly well,
KEA has shown to be more practical to im-
plement, and has served as the base for other
supervised keyphrase extraction methods.
Hulth [3] used KEA as a base for her algo-
rithm and added more linguistic knowledge to
the process—such as syntactic features—rather
than just relying on statistics. Turney [12] also
made use of the base feature set for keyphrase
extraction and incorporated the degree of sta-
tistical association among candidate terms in
order to have more coherence between result-
ing keyphrases. Nguyen and Kan [7] adopted
the base feature set as well, and introduced
an additional feature set to extract keyphrases
from scientific publications. Their system cap-
tures the positions of words and phrases in a
document with respect to the logical section in
which they are found (e.g. abstract, introduc-
tion, methodology).
Despite being the current state-of-the-art,
supervised keyphrase extraction methods re-
quire training datasets and are generally
domain-specific.
Unsupervised methods rely solely on implicit
information found in individual texts. Many
unsupervised keyphrase extraction methodsare
graph-based, where a text is converted into a
graph whose nodes represent text units (e.g.
words, phrases, and sentences) and whose edges
2This paper will refer to the task in hand as
keyphrase extraction from here on.
2
2. Candidate phrases cannot be proper
names.
3. Candidate phrases cannot begin or end
with one of a list of 425 predetermined
stopwords.
3.1.2 Feature extraction
The features extracted from the candidate
phrases generated in the previous stage are
the heart of the KEA algorithm; they serve as
the learning base for the Na¨ıve Bayes classifier
and are used for the extraction of keyphrases.
The features originally extracted by Witten et
al. [16] in their KEA algorithm were the TFIDF
and the relative position.
TFIDF The TFIDF (Term Frequency x In-
verse Document Frequency) is a feature that
compares the frequency of a phrase in a partic-
ular document with its frequency in a global
collection of (training) documents. In other
words, the TFIDF indicates how important a
phrase is to a document in a collection, a higher
value having more importance. The TFIDF for
phrase P in document D is calculated the fol-
lowing way:
TFIDF(P,D) =
freq(P,D)
wc(D)
· log2
N
df(P )
,
where freq(P,D) is the number of times P oc-
curs in D, wc(D) is the number of words in D,
N is the number of documents in the global
collection G, and df(P ) is the number of docu-
ments that contain P in G. If document D is
not in G, then df(P ) and N are both increased
by 1 to simulate the document’s existence in
the collection.
Relative position The relative position is
the position of the first occurrence of phrase P
within the text of document D. It is calculated
as:
POS(P,D) =
pw(P,D)
wc(D)
,
where pw(P,D) is the number of words that
precede the first occurrence of P in D, and
wc(D) is the number of words in D
3.1.3 Training
The training stage uses the training docu-
ment set, which is composed of a collec-
tion of documents with their manually-assigned
keyphrases. First, phrases are generated from
each document in the set. The features for
each phrase are then extracted and stored in
a database.
The previously stored data serves as the
trained model for the Na¨ıve Bayes classifier,
having the Is Keyphrase binary class, i.e., true
if the phrase was manually assigned as a
keyphrase and false otherwise. This trained
model calculates the probability of a new
phrase being a keyphrase by making use of the
previously extracted features and their counts
for each of the two classes, as will be explained
in the following section.
3.1.4 Ranking
With the model having been trained, the Na¨ıve
Bayes classifier can extract keyphrases from a
new text by first selecting its candidate phrases
and then extracting each phrase’s features.
The model determines the probability of each
phrase being a keyphrase using Bayes’ formula
with the two extracted features.
The probability that a phrase is a keyphrase
given that it has TFIDF T and relative position
R is then calculated as:
P(k|T,R) = P(T |k) · P(R|k) · Y
Y + N
, (1)
where P(T |k) is the probability that a
keyphrase has TFIDF score T and P(R|k) is the
probability that it has relative position R. Y is
the number of phrases that were manually as-
signed as keyphrases in the training document
set and N is the number of phrases that were
not.
The previous values can be calculated by ob-
taining the counts for each item in the database
for both keyphrases and non-keyphrases. In the
original KEA method, the TFIDF and relative
position values are converted to nominal data
for the machine-learning scheme. In order to
perform this conversion, a discretization table
derived from the training data is constructed
for each feature. The table gives a set of nu-
meric ranges for each feature, and values are
replaced by the range into which the value falls.
An expression similar to equation (1) is used
to calculate the probability that a phrase is not
a keyphrase:
P(¬k|T,R) = P(T |¬k) · P(R|¬k) ·N
Y + N
, (2)
The overall probability that a phrase is a
keyphrase is then calculated with the following
formula:
P =
P(k|T,R)
P(k|T,R) + P(¬k|T,R) (3)
4
Supervised Ranking 
Unsupervised Ranking 
Merging 
Pre-Processing 
Training 
documents 
Pre-
processing 
Feature 
extraction 
Keyphrase list 
This paper presents the breadboard of 
the mechanical sl it mask to be designed 
for the MOSFIRE instrument of the KECK 
Telescope. This mechanism is designed 
to function at a cryogenic temperature 
of 120 K, in vacuum. The reconfigurable 
mask will  allow to form 41 optical slits 
in a 262 mm times 262 mm field of 
view. The slit length is fixed and their 
width can range from 50 mum to 260.5 
mm. The slit positioning accuracy is 
plusmn 5 mum and the slit width 
accuracy is plusmn8 mum. The paper 
concentrates on the working principle of 
the mechanism which is based on an 
improved "inch-worm" stepping motion 
of 92 masking bars forming the optical 
curtain. Voice coil  actuators are used to 
drive the various clutches and the 
principal mobile stage. Ratchets which 
engage in the teeth of a rack machined 
on the bars allow canceling the 
accumulation of motion errors as steps 
succeed one another. The design makes 
significant use flexure structures. 
Cryogenic performance and life tests 
have been performed successfully on 
subassemblies of the mechanism 
breadboard. 
Input Text 
Graph 
generation 
Trained 
model 
Post-
processing 
Candidate 
phrase 
generation 
TextRank 
Ranking 
Merge 
keyphrase lists 
Naïve Bayes 
Ranking 
Figure 2: HybridRank framework.
2. All non-alphanumeric characters are re-
moved, with the exception of punctuation
marks relevant to text structure and word
meaning (periods, commas, colons, semi-
colons, hyphens, and apostrophes).
3. The cleaned text is sent to the supervised
and unsupervised components for further
processing.
4.2 Supervised Ranking
The supervised component of our system con-
sists of a modified and extended version of the
KEA algorithm proposed by Witten et al. This
section will describe the modifications we made
in each of the stages of KEA.
4.2.1 Candidate phrase generation
The way candidate phrases are selected in
HybridRank has some variations from the pro-
cedure followed by the original KEA method.
We have carefully inspected the training docu-
ment set and have used this knowledge to con-
struct a more effective filter for phrase selection
(as is later shown in the experimental evalua-
tion). The following procedure is carried out:
1. Phrases composed of 1 to 4 words are ex-
tracted from each sentence when they com-
ply with the following criteria:
• They do not contain any of a list of
539 predetermined stopwords [9].
• They are composed of nouns, adjec-
tives and/or verbs in their gerund or
past participle forms.
• They do not contain words with less
than 3 letters.
• They do not contain words composed
only of numbers and/or other non-
letters.
• They do not end with an adjective.
• One-word phrases cannot be an ad-
jective or a verb.
2. Each word in the extracted phrases is then
converted to its stemmed form using the
WordNet [8] stemmer.
3. The phrases are passed as candidate
phrases to the Feature Extraction stage.
4.2.2 Feature extraction
We have included two additional features to the
learning scheme as proposed in other works:
the keyphrase frequency in the whole collection
of texts [2] and the PoS tag pattern [3]. Adding
these two features produced better overall re-
sults in our experiments.
Keyphrase frequency The keyphrase fre-
quency of phrase P in D is the number of times
P is manually assigned as a keyphrase in the
training document set G, excluding D.
PoS tag pattern The PoS (Part-of-Speech)
tag pattern of a phrase P is the sequence of
PoS tags that belong to P . These tags are as-
signed to each word in P using a Maximum
Entropy Part-of-Speech Tagger [11], which uses
the Penn Treebank PoS tagset [5].
4.2.3 Training
Unlike the original KEA method, we do not
discretize real-valued features (TFIDF and rel-
ative position) into numeric ranges; we instead
6
KEA Keyphrases
No. Phrase Score
1 technologies 0.17
2 forecasting 0.17
3 technology 0.17
4 cfd 0.14
5 forecasting emerging 0.10
6 emerging technologies 0.10
7 emerging 0.10
8 resultant products 0.09
9 diffusion 0.09
10 resultant 0.09
11 context 0.09
12 penetration 0.09
13 lack 0.07
14 bibliometric analysis 0.06
15 bass diffusion model 0.06
16 relevant data 0.06
17 bass diffusion 0.06
18 bass 0.06
19 growth rate 0.06
20 growth 0.06
21 diffusion model 0.06
22 computational fluid dynamics 0.05
23 market penetration 0.05
TextRank Keyphrases
No. Phrase Score
1 technologies 0.63
2 bibliometric analysis 0.60
3 bass diffusion model 0.58
4 computational fluid dynamics 0.48
5 growth rate 0.32
6 relevant data 0.31
7 market penetration 0.27
8 resultant products 0.26
9 cfd 0.20
10 diffusion 0.20
11 penetration 0.20
Table 1: Example of keyphrases extracted by KEA and TextRank for a particular text. Phrases in
bold are the actual keyphrases for that text.
KEA Keyphrases
No. Phrase Score
1 technologies 0.17
2 forecasting 0.17
3 technology 0.17
4 cfd 0.14
5 forecasting emerging 0.10
6 emerging technologies 0.10
7 emerging 0.10
8 resultant products 0.09
9 diffusion 0.09
10 resultant 0.09
11 context 0.09
12 penetration 0.09
13 lack 0.07
14 bibliometric analysis 0.06
15 bass diffusion model 0.06
16 relevant data 0.06
17 bass diffusion 0.06
18 bass 0.06
19 growth rate 0.06
20 growth 0.06
21 diffusion model 0.06
22 computational fluid dynamics 0.05
23 market penetration 0.05
TextRank Keyphrases
No. Phrase Score
1 technologies 0.63
2 bibliometric analysis 0.60
3 bass diffusion model 0.58
4 computational fluid dynamics 0.48
5 growth rate 0.32
6 relevant data 0.31
7 market penetration 0.27
8 resultant products 0.26
9 cfd 0.20
10 diffusion 0.20
11 penetration 0.20
12 forecasting -1.0
13 technology -1.0
14 forecasting emerging -1.0
15 emerging technologies -1.0
16 emerging -1.0
17 resultant -1.0
18 context -1.0
19 lack -1.0
20 bass diffusion -1.0
21 bass -1.0
22 growth -1.0
23 diffusion model -1.0
Table 2: Keyphrase lists extended with missing keyphrases. Phrases with a score of -1.0 are those
added from the other list.
phrases that appear in both lists. As-
suming that the lists are already sorted as
in Table 2, the reordering is done by ap-
plying the following algorithm to each list L:
1: reorderedK = {}
2: existentK = {}
3: inexistentK = {}
4: for each phrase P in L do
5: if P exists in both lists then
6: existentK.append(P )
7: else
8: inexistentK.append(P )
9: end if
8
KEA Keyphrases
No. Phrase Score
1 technologies 0.17
2 cfd 0.14
3 resultant products 0.09
4 diffusion 0.09
5 penetration 0.09
6 bibliometric analysis 0.06
7 bass diffusion model 0.06
8 relevant data 0.06
9 growth rate 0.06
10 computational fluid dynamics 0.05
11 market penetration 0.05
12 forecasting 0.17
13 technology 0.17
14 forecasting emerging 0.10
15 emerging technologies 0.10
16 emerging 0.10
17 resultant 0.09
18 context 0.09
19 lack 0.07
20 bass diffusion 0.06
21 bass 0.06
22 growth 0.06
23 diffusion model 0.06
TextRank Keyphrases
No. Phrase Score
1 technologies 0.63
2 bibliometric analysis 0.60
3 bass diffusion model 0.58
4 computational fluid dynamics 0.48
5 growth rate 0.32
6 relevant data 0.31
7 market penetration 0.27
8 resultant products 0.26
9 cfd 0.20
10 diffusion 0.20
11 penetration 0.20
12 forecasting -1.0
13 technology -1.0
14 forecasting emerging -1.0
15 emerging technologies -1.0
16 emerging -1.0
17 resultant -1.0
18 context -1.0
19 lack -1.0
20 bass diffusion -1.0
21 bass -1.0
22 growth -1.0
23 diffusion model -1.0
Table 3: Keyphrase lists after applying the reordering algorithm. The line in the middle shows the
division between the two partitions.
HybridRank Keyphrases
No. Phrase
1 technologies
2 bibliometric analysis
3 bass diffusion model
4 cfd
5 resultant products
6 computational fluid dynamics
7 relevant data
8 growth rate
9 penetration
10 market penetration
11 forecasting emerging
12 technology
13 emerging technologies
14 context
15 lack
Table 4: Final keyphrase list using the average
merging method.
of terms) and uncontrolled (any suitable terms)
keyphrases assigned by human annotators. In
our experiments, we only used the uncontrolled
keyphrases for training and testing.
5.1.2 Corpora statistics
Some statistics relevant to the analysis of our
experiments were extracted from the collections
used. Table 6 summarizes these statistics per
collection and subject.
The statistics show that—in general—only
51% of the manually-assigned keyphrases are
actually contained in the abstract text in their
stemmed forms. With this knowledge, it can be
deducted that the precision of any keyphrase
extraction method will rarely surpass this per-
centage on these corpora, which presents a diffi-
culty for adequate evaluation. For the purpose
of carrying out a fairer evaluation, a utopian
subset was selected from the testing test. Each
of this subset’s abstracts must contain at least
one of the manually-assigned keyphrases in the
text.
An average of 7 keyphrases were manually
assigned for each abstract by either authors or
other human annotators, which correspond to
roughly 6% of the total number of words per
abstract.
5.2 Experimental Setup
For evaluating the performance of HybridRank,
we have performed experiments on the utopian
subset using two other keyphrase extraction
methods: KEA and TextRank. HybridRank
has been separated into three different merging
methods, which we evaluate individually: aver-
age, min and max.
To further break down our evaluation, we
have performed experiments using the original
procedures stated in the KEA and TextRank
papers, and compared their performance with
our modified versions. Additionally, we sepa-
rated the evaluation of the KEA and Hybrid-
Rank methods by using two different feature
10
sets for the Na¨ıve Bayes classifier: the Base
Feature Set (New) and the PoS Tag Feature Set.
Base Feature Set (New) Only the TFIDF,
relative position and keyphrase frequency
are taken into account when calculating
formulas 1 and 2 in Section 4.2.4.
PoS Tag Feature Set Only the TFIDF, rel-
ative position and PoS tag pattern are
taken into account when calculating those
same formulas.
Contrastingly to what was described in Sec-
tion 4.2.4, the feature sets have been separated
in this manner because they presented the best
results for both KEA and HybridRank. Fur-
thermore, they allow a more granular evalua-
tion of the features extracted and used by the
classifier.
The three measures used in our evaluation
were the precision, recall and F-score. We com-
pare the output keyphrases of each method
with those in the manually-assigned list; the
keyphrases in each list are previously stemmed.
The number of keyphrases extracted per ab-
stract corresponds to 6This way of selecting
the number of output keyphrases presented the
best results.
5.3 Evaluation and Discussion
The results for the Hulth 2003 dataset are
shown in Figure 3. For this dataset, Hybrid-
Rank obtained the highest precision, recall and
F-score when using the Max merging method.
This best performance was obtained when ap-
plying either the Base Feature Set (New) or the
PoS Tag Feature Set on KEA. It can also be
observed in Figure 3 that our modified versions
of both KEA and TextRank performed better
than the original ones.
Figure 4 displays the results for the IEEE
Xplore dataset. In this dataset, when ap-
plying the Base Feature Set (New) on KEA
and using the Min merging method, Hybrid-
Rank performed better than the other meth-
ods. However, when applying the PoS Tag
Feature Set, the original KEA method outper-
formed the others. This is probably due to
the fact that the IEEE Xplore dataset has a
greater variety of subjects than the Hulth 2003
dataset. This wide range of subjects causes
the Keyphrase Frequency attribute—applied
on the Base Feature Set (New)—to become less
meaningful [2], thus allowing the PoS Tag Fea-
ture Set to predict a phrase’s class (keyphrase
or non-keyphrase) with higher accuracy.
We have additionally broken down the eval-
uation of our system and of the other methods
on some of the subjects belonging to the IEEE
Xplore dataset. Due to the large number of
subjects in the collection, we have randomly
selected four subjects for evaluation. Figures 5
through 8 show the results for the following
subjects, respectively: Computing and Pro-
cessing, Electromagnetics, Engineering General
Topics and Nuclear Engineering. HybridRank
outperformed all the other methods on the four
randomly selected subjects when using the Base
Feature Set (New). Our method also performed
better than either KEA or TextRank in all of
the cases. However, KEA obtained the best
results on the subjects of Electromagnetics and
Engineering General Topics when using the PoS
Tag Feature Set.
6 Conclusions and Future
Work
In this paper, we have described and evaluated
a hybrid keyphrase extraction method: Hybrid-
Rank. Our results show that collaboration be-
tween a supervised and an unsupervised ap-
proach can produce high-quality keyphrase lists
for short articles. We have compared the per-
formance of HybridRank with two other well-
known keyphrase extraction methods—KEA
and TextRank—and showed that HybridRank
obtained a higher precision, recall and F-score
when applied on the Hulth 2003 dataset.
On our second dataset (IEEE Xplore), the
original KEA algorithm performed better than
HybridRank and TextRank when using PoS
Tag Patterns because this dataset contains a
wide range of domains, affecting the perfor-
mance of the Na¨ıve Bayes classifier when us-
ing the Base Feature Set (New). Our method,
however, outperformed in all cases either the
supervised (KEA) or unsupervised (TextRank)
approaches. Furthermore, doing some modifi-
cations to KEA and TextRank improved their
performance in most cases as compared to the
original methods proposed by their authors.
We can conclude that HybridRank performs
the best when the unsupervised component
outperforms the supervised component. Ad-
ditionally, merging KEA’s and TextRank’s
keyphrases with the Min or Max methods pro-
duced better results than using the Average.
Among our planned future work is adopting
a weighting mechanism to both components,
so as to have biased merging, either towards
the supervised component or towards the unsu-
12
Precision Recall Fscore
HybridRank (Avg) 16.64% 20.64% 18.43%
HybridRank (Max) 17.50% 22.18% 19.56%
HybridRank (Min) 14.33% 20.64% 16.92%
KEA (modified) 10.88% 15.38% 12.74%
KEA (original) 5.71% 7.31% 6.41%
TextRank (modified) 13.97% 15.26% 14.59%
TextRank (original) 16.37% 19.10% 17.63%
0.00%
5.00%
10.00%
15.00%
20.00%
25.00%
IEEE Xplore (Electromagnetics) – Base FS New 
Precision Recall Fscore
HybridRank (Avg) 16.64% 20.64% 18.43%
HybridRank (Max) 15.10% 18.08% 16.46%
HybridRank (Min) 15.10% 18.72% 16.72%
KEA (modified) 15.68% 23.08% 18.67%
KEA (original) 21.07% 26.15% 23.34%
TextRank (modified) 13.97% 15.26% 14.59%
TextRank (original) 16.37% 19.10% 17.63%
0.00%
5.00%
10.00%
15.00%
20.00%
25.00%
30.00%
IEEE Xplore (Electromagnetics) – PoS Tag FS 
Figure 6: Precision, recall and F-score on the IEEE Xplore dataset for the subject of Electromag-
netics. The figure on the left displays the results when using the Base Feature Set (New), the one on
the right corresponds to the PoS Tag Feature Set.
Precision Recall Fscore
HybridRank (Avg) 14.35% 20.41% 16.85%
HybridRank (Max) 11.72% 17.60% 14.07%
HybridRank (Min) 15.77% 24.09% 19.06%
KEA (modified) 13.71% 20.29% 16.36%
KEA (original) 11.98% 18.50% 14.54%
TextRank (modified) 9.40% 13.53% 11.09%
TextRank (original) 9.11% 13.41% 10.85%
0.00%
5.00%
10.00%
15.00%
20.00%
25.00%
30.00%
IEEE Xplore (Engineering General Topics) – Base FS New 
Precision Recall Fscore
HybridRank (Avg) 11.98% 18.50% 14.54%
HybridRank (Max) 13.55% 18.80% 15.75%
HybridRank (Min) 12.95% 18.18% 15.12%
KEA (modified) 13.75% 19.85% 16.25%
KEA (original) 13.72% 19.71% 16.18%
TextRank (modified) 9.40% 13.53% 11.09%
TextRank (original) 9.11% 13.41% 10.85%
0.00%
5.00%
10.00%
15.00%
20.00%
25.00%
IEEE Xplore (Engineering General Topics) – PoS Tag FS 
Figure 7: Precision, recall and F-score on the IEEE Xplore dataset for the subject of Engineering
General Topics. The figure on the left displays the results when using the Base Feature Set (New),
the one on the right corresponds to the PoS Tag Feature Set.
Precision Recall Fscore
HybridRank (Avg) 22.23% 32.18% 26.29%
HybridRank (Max) 19.86% 29.62% 23.78%
HybridRank (Min) 20.94% 30.64% 24.88%
KEA (modified) 18.22% 24.10% 20.75%
KEA (original) 13.21% 17.56% 15.08%
TextRank (modified) 19.59% 27.69% 22.95%
TextRank (original) 16.57% 23.21% 19.33%
0.00%
5.00%
10.00%
15.00%
20.00%
25.00%
30.00%
35.00%
IEEE Xplore (Nuclear Engineering) – Base FS New 
Precision Recall Fscore
HybridRank (Avg) 13.21% 17.56% 15.08%
HybridRank (Max) 22.23% 32.18% 26.29%
HybridRank (Min) 21.79% 31.54% 25.77%
KEA (modified) 16.96% 24.62% 20.08%
KEA (original) 21.68% 25.90% 23.60%
TextRank (modified) 19.59% 27.69% 22.95%
TextRank (original) 16.57% 23.21% 19.33%
0.00%
5.00%
10.00%
15.00%
20.00%
25.00%
30.00%
35.00%
IEEE Xplore (Nuclear Engineering) – PoS Tag FS 
Figure 8: Precision, recall and F-score on the IEEE Xplore dataset for the subject of Nuclear
Engineering. The figure on the left displays the results when using the Base Feature Set (New), the
one on the right corresponds to the PoS Tag Feature Set.
14
□ 赴國外出差或研習 
□ 赴大陸地區出差或研習 
□ 出席國際學術會議 
□ 國際合作研究計畫出國 
心得報告 
計 畫 名 稱  計 畫 編 號  
報 告 人 
姓 名 徐珮玲（Pei-Ling Hsu） 
服 務 機 構
及 職 稱
資訊系統與應用研究所博士
生 
會議/訪問時間 
 地點 
The 7th International Conference on Networked Computing(INC) / 
2011-9-26~ 2011-9-28 
Gumi(Daegu) 
會 議 名 稱 The 7th International Conference on Networked Computing(INC) 
發表論文題目 （檢附論文檔案） 
 
一、主要任務摘要（五十字以內） 
出席國際學術會議，上台報告研究論文。 
二、對計畫之效益（一百字以內） 
會議聚集了相關研究人士，在場除了可以結識這些研究學者，進行討論之外，亦可聽
取對方新做的研究題目，瞭解推論目前研究題目的趨勢、方向、有何共同難題。 
而上台報告，可讓相關研究領域的人得知我們做出的研究成果。 
三、經過 
會議地點是大邱的龜尾[Gumi(Daegu)]。參與會議的主要目的是上台報告發表的paper。
 
我報告的時候狀況不錯。之前用英文報告都是用背稿的，一旦被打斷，就會接不起來。
這次因為投影片不斷修改，直至上台前還在修，我無法記熟全部的稿。然而另一方面，
又因為練習過很多次，所以知道每張投影片的重點是什麼，要接些什麼話，流程才順。
 
報告完之後，有一個人提問。他問我怎麼知道廣播系統該停止。我找到適合的投影片，
跟他說因為報告時間有限制，有些細節拿掉了。再解釋每個點都會紀錄它是第幾個廣
播點，還會紀錄整個系統目前有多少點，藉著這兩個資料，廣播點可以知道廣播覆蓋
率，接著得知何時停止廣播。他又接著提問如何得知整個系統有多少點。我的回答是：
這個問題在Peer to Peer的網路形態中是個很難的問題。在這篇研究中，我們作實驗
是用固定的數值，可是我們有另外一篇論文是專門研究這個問題的。回答完之後，提
問者點點頭，我想我回答的答案是很恰當的。 
 
在會場也聽了不少人報告。除此之外，也陸陸續續跟與會的研究人員聊天。大家除了
詢問對方是從哪個國家來的;也談論會議地點看出去都是工廠、住宿地點離會場遠不
遠、怎麼來會場等等。 
 
除了跟與會研究人員聊天外，這次也有機會跟工作人員聊天。因為某天錯過了從會館
回旅館的接駁車時間，便商請工作人員幫忙叫計程車。工作人員幫我們叫計程車之後，
帶我們到會場外，陪著我們等車。當時有小聊一下，他先是道歉他英文不太好。後來
問我們要在韓國待幾天，還有打算要到哪裡。他介紹龜尾，說這裡是工業大城、科技


A model proposed by Baraba´si and Albert [4], resulting in
“scale-free networks”, was shown to represent the Power-law
distributions in the node connectivity of the network. Their
main idea is to preserve more connectivity for those nodes that
stay in the system longer. In this work, we adopt this approach
to construct the networks desired in the experiments.
III. THEORETICAL MODEL OF BROADCASTING
Before developing the main algorithm, we studied the
interesting characteristics of broadcast. We begin with the
construction of a P2P network following the same method
as presented in the Baraba´si-Albert algorithm as mentioned in
Section II. We simulate the broadcasting processes by fixing
the number of delivered messages, n that is equal or less
than the smallest number of degrees in the network, for each
delivery.
The primary objective of this preliminary simulation is
to discuss the manner in which the system completes the
broadcasting process.We first define two important criteria,
message coverage rate (Definition 3.1) and network traffic load
(Definition 3.2), to evaluate the broadcasting performance.
Definition 3.1: (Message Coverage Rate)
The total coverage of message m in hop h, denoted as c(h),
is defined as the number of peers that any copies of m have
visited at least once. In addition, △c(h) denotes the incremen-
tal coverage from hop h−1 to h, and△c(h) = c(h+1)−c(h).
Note that c(0) = 1 initially, and the coverage rate is c(h)/|V |
at any hop h, where |V | is the network size.
Definition 3.2: (Network Traffic Load) The network traffic
load obtained by broadcasting message m to hop h is defined
as the total number of copies generated by all peers that
have been visited, denoted as r(h). Similarly, △r(h) is the
incremental traffic load of m from hop h − 1 to h, and
△r(h) = r(h+ 1)− r(h).
A. Growth Coverage Model
The following describes modeling the growth of coverage
by spreading messages. Based on our simulation, we found out
that the increment of coverage is determined by the number
of nodes being visited during the last hop and the number of
unvisited neighbors at this hop.
In the early stages of the broadcast, the number of nodes that
have received messages is few, and the rate of dissemination
is low. When the density of covered nodes reaches a certain
proportion, the process enters into an explosion stage. Due to
the limitation of network size, the growing of the coverage
alleviates at the final stage of the broadcast. At this stage,
numerous senders, but few unvisited neighbors among the
whole population, exist. This type of evolution is often called
the logistic growth stage, which is used to describe the
behaviors that are very similar to broadcasting processes in
health and social sciences [5], such as the spreading of plagues
or epidemics, the growth of human or biological (bacteria,
cancer cell) populations, and etc.
To demonstrate that our model matches the logistic growth
law, we first specify △c(h) by the following formula:
△c(h) ∝ ·c(h) |V | − c(h)|V | ·, h > 0 (1)
where n is the number of sending copies. While calculating
the increment of the nodes covered at hop h, we consider
the topology as being totally random, that is, all nodes can
communicate with one another without any restriction. In this
way, each of the nodes of c(h) is able to deliver n copies.
Because those peers in the node set covered cannot contribute
to the increments, the amount of dissemination should be in
proportion to the uncovered nodes (|V | − c(h))/|V |.
Let F (h) be a continuous and smooth function such that
F (h) = c(h)|V | +ϵh where ϵh is noise distributed with mean value
0 and small variances for all h. According to Equation (1), the
differential equation of the changing rate of the population
visited at any hop h can be written as
dF (h)
dh
= n · |V | · F (h)(1− F (h)) · λ. (2)
where λ is a probabilistic function describing if the sender
meets the uncovered peer. It is related to the topology of
network structures, or, for example, the degree of nodes. The
effects from function λ will not be discussed in this paper
since it serves as an indication of the degrees of the nodes
that obey Power-law.
The following Lemma demonstrates that when n > 2, F (h)
is equivalent to the growth of a logistic distribution.
Lemma 3.1: When n > 2,
F (h) =
1
1 + (|V | − 1)e−n|V |λh =
1
1 + e−
h−µ
β
, h > 0
(3)
Hence, F(h) is the Cumulative Density Function (CDF) of
a logistic distribution with parameters β = 1/(n|V |λ) and
µ = ln(|V | − 1)β.
Note that when n = 1, △c(h) = 1 for every hop, and
F (h) = h/|V |. Hence, we can estimate the discrete value of
the coverage increment at hop h by △c(h) = |V |(F (h) −
F (h− 1)) for all positive integers h. Moreover, the curves of
F (h) correlate with the number of copies. The correlations
between the parameters β, µ, and n are discussed in the
following.
By Lemma (3.1), β is inversely proportional to n. Thus, a
hyperbolic function (n− aβ)(β − bβ) = dβ , with parameters
aβ , bβ , dβ can fit the relationship for n > 2. Because µ is
proportional to β, we may expect that µ’s behavior is similar
to β that the function (n−aµ)(µ−bµ) = dµ, with parameters
aµ, bµ, dµ fits the correlation as well.
B. Effects of Traffic Increments
In addition to computing the coverage increments in each
hop, we monitored the consumption of traffic load which is
essential to obtain the required coverage.We can evaluate the
additional traffic△r(h) at any hop h as△r(h) ∝ ·c(h). As the
Algorithm 2 Select Candidates
Require: Specify the approach of selecting candidates
Input: Peer v, set S(v), and number of copies n
if Priority Approach then
for all every peer ui ∈ S(v) do
Initialize the constant value x
{Z represents a normalization
such that
∑
ui∈S(v)
Pr(ui) = 1}
Compute Pr(ui) = 1Z
∑
ui∈S(v)
deg(ui)− x · deg(ui)
end for
for j = 1 to n do
Select a peer u (the selection probability is based on
the distribution of Pr)
Set S(v) ← S(v)− {u}
Set S(u) ← S(u)− {v}
end for
else if Pure Random Approach then
for j = 1 to n do
Select a peer u randomly (not repeated with the previ-
ous ones)
end for
end if
B. Redundant Preventing Protocol
In certain rumor mongering algorithms, a peer may prevent
sending duplicate information to the neighbors to whom it
already sent [6]. We adapt this concept into our redundant
preventing protocol. Hence, instead of only fixing a set of can-
didates S(v) equal to N(v) for each peer v as in Algorithm 1,
S(v) could be adjusted, that is, whenever one peer sends a
message to another peer, both of them will be deleted from
each other’s candidate set. Thus, peers will try to distribute
the message only to those peers in S(v).
C. Flexible Time-to-Live Protocol
In our approach, the proper number of copies that a peer
should send is strongly affected by its own degree and the
time while receiving a message. A peer of higher degree has
more influence on the broadcasting process than those of lower
degree. Moreover, it is conceivable that the peers covered in
the beginning have an even larger impact on the performance
than those covered later. Hence, in the earlier stage when the
coverage is low, the peer should send more copies than that
in the later stage. In the later stage where most neighbors
have received the message, the peer should send less copy to
reduce the traffic. In order to avoid nonessential traffic in this
process, we design a flexible TTL protocol to determine the
life time of the message by considering the total coverage. In
this protocol, we attach a variable in the message regarding
the remaining time-to-live of the message. At the beginning of
the broadcast, the issuer calculates the initial TTL value iT as
a multiples of µ derived from the number of initial delivered
copies n by Lemma 3.1 and may be modified by any peer in
the early stages, as shown in Algorithm 3.
Algorithm 3 Flexible TTL
Require: The range w, the allowable change rate α of ad-
justable TTL, the maximum hop δ that can change the TTL
value, the number of initial delivered copies n, the network
size |V |
The initial TTL iT = w × µ
{µ is derived from n by Lemma 3.1}
Issuer attaches iT in the delivered message m
for all every peer ui received m do
if The current hop h 6 δ then
Obtain the number n′ of current delivered copies
The new TTL cT = w × µ
{µ is derived from n′ by Lemma 3.1}
if cT > α · iT then
cT = α · iT
end if
end if
Replace the TTL value with cT
end for
V. PERFORMANCE EVALUATION
A. Experimental Methodology
For a valid comparison, an open source P2P simulation
tool, PeerSim [7], was adapted in our simulation. It can
simulate both static systems and dynamic systems, where peers
may join and leave continuously. To visualize the impact
of dynamic scales on each method, we employed numerous
substitute rates, θ. The substitute rate indicates the rate at
which peers leave the network in the beginning of each cycle
and the identical number of new peers join the network.
Because several protocol variations exist, we categorize
them into the following.
• M1: the basic broadcasting protocol.
• CM1: the basic broadcasting protocol with the redundant
preventing protocol
• CM1 ttl: the basic broadcasting protocol with the redun-
dant preventing protocol and the flexible TTL protocol
We compare our results with several different gossip ap-
proaches that have been considered to perform well in dynamic
systems, including:
• Flood: the issuer and all receiving peers broadcast the
message to all neighbors.
• Gossip [8]: the issuer and all receiving peers deliver the
message to a fixed number n of their neighbors. The
notation of this method in the experimental figure is
Gspn, for example, Gsp2 represents the results of n = 2.
• CountGossip [6]: the same process as Gossip except that
CountGossip adopts the redundant preventing protocol.
Note that this method restricts the delivery times for
each peer, but we ignore it because the condition may
somehow reduce the reliability. The notation of this
method is CGspn.
5 10 15 20 25 30
Hops
0.2
0.4
0.6
0.8
1
Coverage percentage
CM1_ttl
CM1
CGsp5
CGsp2
Flood
Methods
(a) θ = 0.8%
5 10 15 20 25 30
Hops
0.2
0.4
0.6
0.8
Coverage percentage
CM1_ttl
CM1
CGsp5
CGsp2
Flood
Methods
(b) θ = 1.6%
Fig. 3. Coverage comparisons among various methods with |V | = 2000
and different substitute rates, θ.
5 10 15 20 25 30
Hops
2000
4000
6000
8000
10000
Total Traffic Load
CM1_ttl
CM1
CGsp5
CGsp2
Flood
Methods
(a) θ = 0.8%
5 10 15 20 25 30
Hops
2000
4000
6000
8000
10000
Total Traffic Load
CM1_ttl
CM1
CGsp5
CGsp2
Flood
Methods
(b) θ = 1.6%
Fig. 4. Traffic comparisons among different methods with |V | = 2000 and
different substitute rates, θ.
reducing traffic loads, retaining speed, and reaching a high
degree of coverage.
VI. CONCLUSION
In this work, we studied the characteristics of broadcasting
in P2P systems, and introduced a model that represents the
1 2
1
.
ti
o
n
0.6
0.8
e 
p
ro
p
o
rt
0.4
o
v
er
a
g
e
flooding
CGsp5
CM1
0
0.2
0 4 0 8 1 2 1 6 2
C
CM1_ttl
. . . .
Substitute rate s (%)
(a) hop h = 6
1
0.95
p
o
r
ti
o
n
0.85
0.9
a
g
e
 p
ro
p
flooding
0.8
C
o
v
e
r
a
CGsp5
CM1
CM1_ttl
0.75
0.4 0.8 1.2 1.6 2
Substitute rate s (%)
(b) hop h = 7
Fig. 5. Rate of decreasing coverage with increasing dynamic scales in |V | =
2000.
growth of coverage and traffic over the network. By utilizing
these properties, we proposed an algorithm that improves
broadcasting performance without the restriction of a fixed
TTL. Instead, we used a flexible TTL that can be calculated
by peers to control the end process and reduce the unnecessary
duplication. Our experimental results demonstrated that, com-
pared to other approaches, our method achieved the least trade-
off between the broadcasting speed and the traffic overhead,
especially in large populations.
REFERENCES
[1] S. Androutsellis-Theotokis and D. Spinellis, “A survey of peer-to-peer
content distribution technologies,” ACM Computing Surveys, vol. 36,
no. 4, pp. 335–371, 2004.
[2] M. Portmann and A. Seneviratne, “The cost of application-level broadcast
in a fully decentralized peer-to-peer network,” in ISCC ’02: Proceedings
of the Seventh International Symposium on Computers and Communica-
tions (ISCC’02), 2002, p. 941.
[3] M. Ripeanu, “Peer-to-peer architecture case study: Gnutella network,”
in P2P ’01: Proceedings of the First International Conference
on Peer-to-Peer ComputingProceedings of the First International
Conference on Peer-to-Peer Computing, 2001. [Online]. Available:
http://ieeexplore.ieee.org/xpls/abs all.jsp?arnumber=990433
[4] A.-L. Baraba´si and R. Albert, “Emergence of scaling in random net-
works,” Science, vol. 286, no. 5439, pp. 509–512, 1999.
[5] N. Balakrishnan, Ed., Handbook of the Logistic Distribution. Marcel
Dekker, Inc., 1992.
[6] M. Lin, K. Marzullo, and S. Masini, “Gossip versus deterministic flood-
ing: Low message overhead and high reliability for broadcasting on small
networks,” University of California at San Diego, Tech. Rep., 1999.
[7] “Peersim project website,” http://peersim.sourceforge.net.
[8] A. Demers, D. Greene, C. Hauser, W. Irish, J. Larson, S. Shenker, H. Stur-
gis, D. Swinehart, and D. Terry, “Epidemic algorithms for replicated
database maintenance,” in PODC ’87: Proceedings of the sixth annual
ACM Symposium on Principles of distributed computing, 1987.
99 年度專題研究計畫研究成果彙整表 
計畫主持人：陳宜欣 計畫編號：99-2221-E-007-092- 
計畫名稱：微網誌自動化意見分析與研究 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 0%  
研究報告/技術報告 0 0 0%  
研討會論文 0 0 0% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 6 0 60%  
博士生 1 0 40%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 0 1 50% 
一篇完成文稿已
投到 Information 
Systems 
研究報告/技術報告 3 0 30% 
三篇英文撰寫的
碩士學術論文 , 
目前正改寫投稿
到國際研討會 
研討會論文 1 2 20% 
篇 在計畫時間內發
表的研討會論文
一篇,以及超出計
畫時間外發表的
一篇研討會論文,
以及一篇正投稿
到其他研討會的
論文 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
國外 
參與計畫人力 
（外國籍） 博士生 0 0 100% 
人次 
 
國科會補助專題研究計畫成果報告自評表 
請就研究內容與原計畫相符程度、達成預期目標情況、研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）、是否適
合在學術期刊發表或申請專利、主要發現或其他有關價值等，作一綜合評估。
1. 請就研究內容與原計畫相符程度、達成預期目標情況作一綜合評估 
■達成目標 
□未達成目標（請說明，以 100 字為限） 
□實驗失敗 
□因故實驗中斷 
□其他原因 
說明： 
2. 研究成果在學術期刊發表或申請專利等情形： 
論文：□已發表 ■未發表之文稿 □撰寫中 □無 
專利：□已獲得 □申請中 ■無 
技轉：□已技轉 ■洽談中 □無 
其他：（以 100 字為限） 
已研究出在短文章中擷取關鍵字的方法，已將方法撰寫成下述論文，並投稿到 Information 
Systems 
 
Gerardo Figueroa, Yi-Shin Chen, HybridRank: A Collaboration between Supervised 
and Unsupervised Approaches for Keyphrase Extraction, Submitted to Information 
Systems at 2011 
3. 請依學術成就、技術創新、社會影響等方面，評估研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）（以
500 字為限） 
這個方法經過初步評估，可以用在微網誌的關鍵字擷取上，這個結果將有助於深入分析微
網誌作者的意見與情緒，用以進一步供行銷與社會化方面的應用。特別是微網誌最近頗為
盛行，其特性與一般部落格有些差異，此計畫的進行可提供微網誌內容意見分析研究與相
關應用的參考。 
 
我們也將會將這個結果利用到目前正在進行的國科會計畫研究『微網誌自動化意見分群』
上，由於意見與情緒分析是近年來越來越熱門之研究議題，其應用領域廣泛且重要。其所
必須要具備的相關背景知識包括自然語言處理、資料探勘、資訊檢索、語言模型、統計分
析等等。 
 
因此，本計畫的研究成果將能成為微網誌為 Web2.0 中重要服務的核心技術，也將可以利
用這個關鍵字擷取技術，將微網誌上的關鍵資料納為研究資料集。這個結果，也將有助於
發展即時反饋系統或大眾意見蒐集與探勘研究系統，也可以廣泛的應用在行銷、心理學、
