 2 
 
摘要 
關鍵詞：密度三維ART，三維小曲率轉換，三維傅立葉轉換 
 
    隨著電腦技術發展的日新月異，人類越來越想在電腦上模擬出真實世界的物體，而不僅
僅只是單純的相片、影像。也因為發展3D模型的工具和掃描技術的大幅發展，如AutoCAD、
3D Studio、Maya等開發軟體，使3D模型的製做變得相當容易。而網路的快速發展也凾不可沒，
它函速了資料的流通與獲取的管道。以前，往往只有機械工程師、動畫師等專業人士才能接
觸到大量的3D模型。所以在本計劃中，我們先結合Grid-based Principal Components Analysis 
(GPCA),Continuous Principal Component Analysis (CPCA)和PCA on the normals of the model’s 
faces (NPCA)，將3D模型擺正，避免3D模型旋轉時所造成的誤差，接著結合了密度3D-ART 
(Density 3D-ART Descriptor)、三維小曲率轉換(3D-Discrete Curvelet Transform, 3D-DCT)和三
維傅立葉轉換(3D-Discrete Fourier Transform, 3D-DFT)來擷取特徵，更詳細的描述模型的特
徵。 
一. 報告內容 
1. 前言 
近年來，3D 風潮如同旱地驚雷般地在所有領域颳起一陣旋風，諸如遊戲、動畫、網路、
機械、娛樂等，大量的 3D 模型應運而生。面對現今數量龐大的 3D 模型資料庫，在搜尋上將
產生相當大的問題。在過去，傳統的關鍵字搜尋方式不僅不直覺，且隨著每個人主觀的分類
不同，往往不能滿足我們在 3D 模型萃取上的需求。因此，如何有效率地搜尋出使用者所期
望的 3D 模型，儼然成為目前重要的研究課題。因此在本計劃中，我們藉由擷取 3D 模型的表
面曲率來函強表示出模型中的外部資訊，所以我們在本計劃是先結合 Grid-based Principal 
Components Analysis (GPCA) ,Continuous Principal Component Analysis (CPCA)和 PCA on the 
normals of the model’s faces (NPCA)，將 3D 模型擺正，避免 3D 模型旋轉時所造成的誤差，在
結合密度 3D-ART (Density 3D-ART Descriptor)、三維小曲率轉換(3D-Discrete Curvelet Transfo 
-rm, 3D-DCT)和三維傅立葉轉換(3D-Discrete Fourier Transform, 3D-DFT)來擷取特徵，並對特
徵進行比對。 
2. 研究目的 
基於這些外部及內部特徵，我們已可以粗略地描述 3D 模型，但是對於日趨複雜的 3D 模
型而言，我們希望能提出更精確的方法去描述它。因此本計畫結合密度 3D-ART、三維小曲
率轉換和三維傅立葉轉換擷取 3D 模型的特徵，使得 3D 模型檢索系統能夠更函的完善。 
 4 
對不同半徑的同心球(concentric spheres)中的資料，使用球型諧波來求得 3D 模型的特徵向量，
這樣就能避免因旋轉而產生的問題。 
Zhang 及 Chen [4] 提出一種有效率計算特徵的方法，首先將 3D 模型利用網格(mesh)切割
成一小塊一小塊的，而每一小塊就稱為 voxel。每個 voxel 可標為 1 或 0，視 voxel 為落在 3D
模型的內部或外部而定，由此可計算 3D 模型的體積，再利用模型中的三角片(mesh)對 3D 模
型取矩量(moments)和富立葉係數來當特徵。如此的觀念也可應用在 PCA 的正規化找尋主軸
上(如圖二)，主要是利用對 3D 模型取矩量所得到的一個 3×3 的矩陣，計算出該矩陣的 3 個
eigenvectors，則這些 eigenvectors 即為該 3D 模型的 3 個主軸。 
 
圖二  做 PCA 之前與之後的 3D 模型[4]。 
Papadakis[5]等人提出基於球型諧波的理論下，使用兩種不同的 3D 模型擺正方法，並將
兩種結合為一。而擺正的方法分為，在點座標系統下進行 3D 模型的擺正(CPCA)以及使用該
模型上三角片的單位法向量做擺正的動作(NPCA)。做完擺正的動作以後，對於每個 3D 模型
的中心點，根據不同的角度可放射出與模型表面形成交集的射線，將交集與中心點之間的線
段，等距離補點。再對 CPCA 與 NPCA 兩種擺正方式，利用球型諧波針對已補點完的 3D 模
型，進行擷取特徵值的動作。最後，將兩種擺正方法所得到的特徵值組合起來，即為該 3D
模型的特徵值(如圖三)。 
 
圖三  NPCA 和 CPCA 於特徵擷取和外形比對組合[5]。 
2) 二維投影特徵(2D view feature) : 
此類方法的主要觀念是藉由許多二維黑白影像(binary images)或是灰階影像(gray-level 
 6 
算出兩個 3D 模型的相似程度。 
 
圖六 3D 模型的六個投影立面圖 [10]。  
Chen-Tsung Kuo[11]提出了主要平面分析的方法，其目的是要改善傳統主軸分析的方法在
兩個相似的 3D 模型上因為外觀的些微差異而導致主軸的偏移。因此，將主軸分析的觀念沿
伸至主要平面分析，主平面的判斷是在 3D 模型中所有的點到某個平面距離之合最小，則該
平面為 3D 主要平面。 
主平面分析的做法是將一個原始 3D 模型(如圖七(a))，將模型上所有的點投影到主要平面
使得 3D 模型轉至成 2D 影像(如圖七(b))，最後在此 2D 影像上取特徵。 
            
                (a)   (b)  (c) 
圖七 主平面分析 (a)一個原始螞蟻模型，(b)投影至主平面的 2D 黑白影像，(c)和所切割出來的
最佳的三角形區域[11]。 
我們在 96 年所提出之國科會專題研究計畫曾針對 3D 模型的檢索提出了將 3D 模型投影
到三個主平面的方法[12]。主要的作法為，對於每個 3D 模型，在空間中找到一個平面使得模
型上的所有點到平面的距離總合會最小，此平面稱為第一主平面 E1。根據 E1 平面，我們可以
找出跟 E1 平面垂直的第二主平面 E2 及第三主平面 E３(如圖八(b))。對於每個 3D 模型，投影到
三個主平面，可以得到三張黑白影像，再利用同心圓的方式針對三張黑白影像擷取特徵(如圖
八(d))。 
 
 8 
         
(a)                                       (b) 
圖十 (a) 8 個小網格合成一個巨型網格,(b)在正二十面體上的十二個頂點中，兩個不同的頂點
所形成的切線平面。 
Mohamed Chaouch[15]等人提出一個 3D 模型檢索系統，這套系統主要的方法是藉由 3D
模型投影到一個正十二面體的二十個頂點方向如圖十一(a)所示，所得到的二十張深度影像，
再對這些深度影像作特徵擷取的動作。對於每張深度影像，根據影像大小(N*N)，分別在水平
以及垂直方向上劃出 N 條深度線，即每張影像可劃出 2*N 條深度線如圖十一(b)之上半部所
示。利用深度線來描述 3D 形狀的邊界輪廓比起其他使用 2D 形狀表示法來的更為精確。最後
再將深度線編碼完的序列，使用動態規劃演算法計算出兩個序列的相似度。 
Assfalg[16-18]等人提出利用曲率投影進行 3D 模型檢索的方法，主要的做法為先對每個
3D 模型上的三角片做平滑處理(如圖十二)。再對於 3D 模型做變形處理以及曲率投影的動作
(如圖十三)。最後利用直方圖即可統計出整張影像的曲率分布資訊。 
                
     (a)                                      (b) 
圖十一 (a) 從不同的角度所投影出來的深度影像。(b) 賽車影像的深度線[15]。 
 
圖十二 3D 模型做平滑處理的過程，(a)原來的 3D 模型，(b)做 Laplacian 運算，(c)做 Gaussian
運算，(d)結合 Laplacian 與 Gaussian 運算[16]。 
 
 10 
                 
                (a)           (b)           (c)           (d)            (e) 
圖十五  函式圖形(a) A3 (b) D1 (c) D2 (d) D3 (e) D4[20,21]。 
 MPEG-7 中擷取 3D 模型特徵的方法，其主要做法先把 3D 模型解析度統一為計算模型上
的每個面的曲率，然後統計每種曲率出現的頻率做成直方圖(histogram)當作檢索時之特徵向
量。其主要步驟介紹如下：先利用表面平滑細分演算法(Smooth Subdivision Surfaces)[22]。接
下來計算每一個平面的曲率(curvature)，及其平均法向量(mean normal vector)。如此可求出該
模型的形狀索引(shape index)。計算出來的形狀索引值會因為曲面的曲率不同而有所改變。例
如曲面呈現下凹的半球型的話,則計算出來的形狀所以會趨近於 0；曲面呈現上击的半球型的
話，則計算出來的形狀會趨近於 1(如圖十六)。根據這些形狀索引，我們將可以詳細的描述
3D 模型的外型。 
 
圖十六 MPEG-7 中擷取 3D 模型的形狀索引示意圖[23]。 
4. 研究方法 
    在過去的3D 模型檢索系統中，常運用Principal Component Analysis(PCA)的方法，求得3D 
模型的主軸，並以此擺正模型。傳統的PCA 做法，是利用模型中三角片的頂點座標們來計算
主軸 (Principal axes)，但以圖十七為例，吉普車中的輪胎的部分非常複雜，須要用許多的三
角片來表示，如此三角片分佈不均的情況，會造成主軸計算時的偏差。Papadakis[5]提出兩種
不同的3D 模型擺正方法，並將兩種結合為一。而擺正的方法分為，在點座標系統下利用三角
片面積為權重值來計算主軸 (Continuous Principal Component Analysis, CPCA)以及使用該模
型上三角片的單位法向量來計算主軸 (the PCA on the normals of the model’s faces, NPCA)。再
對經CPCA與NPCA兩種擺正後的3D 模型，進行擷取特徵值的動作。最後，將兩種擺正方法
所得到的特徵值組合起來。 
    因此在去年已結案的國科會計畫提出了 Grid-based Principal Components Analysis 
(GPCA)可把 3D 模型切成網格，去過濾模型的細微變化，也可充分的表現出 3D 模型的外型。
 12 
                                
(a)                      (b)                       (c) 
圖十九 對擺正後的 3D 模型做大小的正規化 (a)最小立方體凿圍住 3D 模型 (b)正規化 3D 模
型前 (c)正規化 3D 模型後。 
針對頻率特徵，我們希望整合三種方法: 
(1)密度 3D-ART(Density 3D-ART Descriptor)。 
(2)3D 小曲率轉換(3D Discrete Curvelet Transform )。 
(3)3D 傅立葉轉換(3D Fourier Transform)。 
(1) 密度3D-ART(Density 3D-ART Descriptor)： 
在這次計畫中的密度 3D-ART 特徵(Density 3D-ART Descriptor)是針對原本的 3D-ART[13]
做改善。主要作法為將一個 3D 模型切成 128×128×128 的網格，如圖二十一所示，每 8 個 2×2×2
的微型網格(tiny voxel)就組合成一個巨型網格(coarser voxel)，如圖二十所示，對於每個 3D 模
型，均可切出 64×64×64 個巨型網格，如圖二十(b)所示。在每格微型網格中若有 3D 模型多邊
型的面存在就將此網格視為 1，TinyVoxel(x,y,z) = 1，(代表此微型網格為有效網格)；反之微型
網格中沒有 3D 模型存在則將它視為 0，TinyVoxel(x,y,z) = 0，(代表此微型網格為無效網格)。
每個巨型網格中有效微型網格的個數，即為這巨型網格的代表值，範圍為[ 0 ~ 8 ]。 
                                  
                  (a)                                      (b) 
圖二十 3D 模型 (a)切成 128×128×128 的微型網格 (b)每 2×2×2 的微型網格，合併成一個巨型
網格，形成 64×64×64 的巨型網格。 
 
圖二十一 2×2×2 的微型網格，合併成一個巨型網格。 
對應的密度 3D-ART 係數   mmnF ,, 定義如下： 
 14 
其中 j , Zl , ),,( 321 kkkk  , j 為長度、 l 為角度方向、 k 為空間座標、 ),,( zyxf 為3D模型，
範圍在, 0 x , y , z n 。而基底函式 D klj ,, 依 j 的位置被分成三種等級: 
第一種用在內圈，切割網格較粗時 )( 0jj  ，經由傅立葉轉換所獲得的基底函式計算如下: 
        )]///(2exp[
)(
~
)(ˆ
000
000
0
0 ,333,222,111
,3,2,1
0,
,0, jjj
jjj
jD
kj LkLkLki
LLL
U


 

                              
其中
00 ,22,11
0,0 jj LkLk  , 0,330 jLk  。頻率視窗(frequency window) 0,0
~
jU ，其定義如下: 
        )(
~
)(
~
00,0
 jj WU  . 
笛卡兒環狀(Cartesian coronae) )(
~
0 jW ，其定義如下: 
         
0
~
jW =  0j . 
其中 ),,( 321 j = )2()2()2( 321 
jjj   . 
    第二種用在外圈，切割網格較細時 )( 0 ejjj  經由傅立葉轉換所獲得的基底函式計算如
下: 
        )]///(2exp[
)(
~
)(ˆ ,,333,,222,,111
,,3,,2,,1
,
,, ljljlj
ljljlj
ljD
klj LkLkLki
LLL
U


 

 . 
其中 ljljlj LkLkLk ,,33,,22,,11 0,0,0  。頻率視窗(frequency window) ljU ,
~
，定義如下: 
        )(
~
)(
~
)(
~
,,  ljjlj VWU  . 
在 l 角度方向， ),,1( ll  為在立方體中心線的方向的楔形立方體(wedge)，如圖二十三(b)，
角視窗(angular window) )(
~
, ljV 計算如下: 
        




 





 

1
132/
1
122/
, 2
~
2
~
)(
~




 ljljlj VVV  
笛卡兒環狀(Cartesian coronae) )(
~
jW ，則定義如下: 
         jW
~
= )(22 )(1  jj   . 
其中 ),,( 321 j = )2()2()2( 321 
jjj   . 
最後一種為用在最外圈時 ))2/(log( 2 njj e  )經由傅立葉轉換所獲得的底函式計算如
下: 
        )]///(2exp[
)(
~
)(ˆ ,333,222,111
,3,2,1
0,
,0, eee
eee
e
jjj
jjj
jD
kj LkLkLki
LLL
U


 

 . 
且 nLLL
eee jjj
 ,3,2,1 和0 1k , 2k , 3k n。頻率視窗(frequency window) 0,
~
ej
U 定義如下: 
 16 
        }2/,,2/,),,(),,({ NlkiNRlkiqlkiqQ   
經過轉換，發現係數 ),,( wvug 的絕對值中指數範圍 KwvuK  ,, (指的是最小頻率)。
除了係數 )0,0,0(g ，其他選定的複數都共軛成對。因此，特徵向量由    2/112 3 K 的實數所
組成。藉由3D-DFT，要獲得較精準的模型空間數值，必須參數 N 值要夠大(也就是選定的立
體像素)。 
    根據 3D-DFT特徵轉換得到  組係數，其中 ),,( wvug 是介於 2,,2  wvu (除了
)0,0,0(g )，最後3D-DFT特徵定義如下: 
         TD F TDD F TDD F TDD F TD vtvtvtvt )](),...,2(),1([ 3333    
3D傅立葉轉換特徵相似度比對: 
這裡介紹3D傅立葉轉換的相似度比對。v3D-DFT和u3D-DFT分別表示為3D傅立葉轉換特徵
中的查詢模型q和比對模型t的特徵向量。查詢模型和比對模型之間的距離就定義如下： 
        

 

1
333
, )()(
k
D F TDD F TDD F TD
tq kukvD i s  
 
 
5. 結果與討論 
 實驗中我們採用資的料庫是「普林斯頓資料庫（Princeton Shape Benchmark）」[24]，如圖
二十四、二十五，此資料庫是提供給對 3D 模型檢索研究有需求的使用者免費使用，大部分
的 3D 模型特徵擷取都有用此資料庫來做檢索研究。普林斯頓資料庫含有 1814 個 3D 模型，
凿含 161 個不同的類別。分成 907 訓練模型(90 個類別)以及 907 測詴模型(92 個類別) ，如表
一所示。 
實驗是將我們所提出三種 3D 模型特徵，密度 3D-ART (Density 3D-ART Descriptor)、三
維小曲率轉換(3D-Discrete Curvelet Transfom, 3D-DCT)和三維傅立葉轉換(3D-Discrete 
Fourier Transform, 3D-DFT)和把三種特徵合併後於資料庫中做檢索。表二為三種不同特徵和
合併後的特徵於普林斯頓大學 3D 模型資料庫檢索正確率。表三為其他特徵 shell grid 
descriptor(SGD)[25]、Grid D2(GD2)[26]、Beta/distance histogram(BD)[28]、Extended Gaussian 
images(EGI) [30]、depth buffer image(DBI) [33]、density-based framework(DBF) [29]、concrete 
radicalized spherical projection(CRSP)[31]、spherical harmonic representation of the Gaussian 
Euclidean distance transform(SH-GEDT)[32]、light-field descriptor(LFD)[9]、hybrid descriptor of 
DBI, SIL, and Ray-Based spherical harmonic(DSR)[33]、spherical wavelet descriptor(SWD)[34]、
rotation invariant spherical harmonic(RISH)[32]、shape histograms(SHIST)[35]、silhouette based 
feature vector(SIL)[33]、3D Hough transform(3DHT)[36]、cord and angle histogram(CAH)[37]、
 18 
 
 
 
 
圖二十四 普林斯頓資料庫中的模型類別。 
 
 
 
 
 
 
 
 20 
 
 
表一 普林斯頓資料庫內 92個不同類別模型, |Nc|表示類別裡模型的個數。 
Category name |Nc| Category name |Nc| Category name |Nc| Category name |Nc| 
Biplane  14 Book  4 Vase 11 Flying_bird 14 
Commercial 11 Barn 5 Mailbox 7 School_desk 4 
Fighter_jet 50 Church 4 Electrical_guitar 13 Staircase 7 
Glider 19 Gazebo 5 Newtonian_toy 4 Standing_bird 7 
Stealth_bomber 5 One_story_home 14 Bush 9 Bench 11 
Hot_air_balloon 9 Skyscraper 5 Flowers 4 Hammer 4 
Helicopter 18 One_peak_tent 4 Potted_plant 26 Dog 7 
Enterprise_like 11 Two_story_home 10 Barren 11 Dining_chair 11 
Flying_saucer 13 Chess_set 9 Conical 10 Shovel 6 
Satellite 7 City 10 Satellite_dish 4 Horse 6 
Tie_fighter 5 Desktop 11 Large_sail_boat 6 Desk_chair 15 
Ant 5 Computer_monitor 13 Ship 11 Umbrella 6 
Butterfly 7 Door 18 Submarine 9 Rabbit 4 
Human 50 Eyeglasses 7 Billboard 4 Shelves 13 
Human_arms_out 20 Fireplace 6 Sink 4 Race_car 14 
Walking 8 Cabinet 9 Slot_machine 4 Snake 4 
Rectangular 25 Sedan 10 Fish 17 Single_leg 6 
Covered_wagon 5 Sea_turtle 6 Geographic_map 12 Motorcycle 6 
Axe 4 Handgun 10 Monster_tuck 5 Knife 7 
Hat 6 Semi 7 Sword 16 Hourglass 6 
Jeep 5 Face 16 Ladder 4 Train_car 5 
Hand 17 Streetlight 8 Wheel 4 Head 16 
Glass_with_stem 9 Gear 9 Skull 6 Pail 4 
 
 
 
表二 在本計畫所提出之特徵在普林斯頓資料庫正確率比較結果 
  特徵  DCG(%) 
  密度 3D-ART 64.18 
  3D-Fourier 64.05 
  3D-Curvelet 65.32 
  合併三種特徵 70.16 
 
 
 
 
 
 22 
 
 
二. 參考文獻 
[1] D. V. Vranic, D. Saupe, J. RICHTER, "Tools for 3D-object retrieval : Karhunen-Loeve            
transform and spherical harmonics",Proceedings of the IEEE Workshop on Multimedia Signal 
Processing, pp. 293-298, 2001. 
[2] T. Funkhouser, P. Min, M. Kazhdan, J. Chan, A. Halderman, D. Dobkin, D. Jacobs, "A search 
engine for 3D models", ACM Trans. Graphics 22 (1), pp. 83-105, 2003. 
[3] M. Kazhdan, T. Funkhouser, S. Rusinkiewicz, "Rotation invariant spherical harmonic 
represent -ation of 3D shape descriptors",Symposium on Geometry Processing, 2003. 
[4] C. Zhang and T. Chen, ”Efficient feature extraction for 2D/3D objects in mesh representation”, 
Proceedings of IEEE International Conference on Image Processing(ICIP), Thessaloniki, 
Greece, pp. 935-938, 2001. 
[5] P. Papadakis, I. Pratikakis, S. Perantonis and T. Theoharis, “Efficient 3D shape matching and 
retrieval using a concrete radialized spherical projection representation”. Pattern Recognition, 
Vol. 40, pp. 2437-2452, 2007. 
[6] T. Funkhouser, P. Min, M. Kazhdan, J. Chan, A. Halderman, D. Dobkin, D. Jacobs, "A search 
engine for 3D models", ACM Trans. Graphics 22 (1), pp. 83-105, 2003. 
[7] B. J. Super, H. Lu, "Evaluation of a hypothesizer for silhouette-based 3-D object recognition", 
Pattern Recognition, Vol. 36,pp. 69-78, 2003. 
[8] D. Y. Chen and M. Ouhyoung, "A 3D Model Alignment and Retrieval System", Proc. of 
International Computer Symposium,Workshop on Multimedia Technologies, Vol. 2, pp. 
1436-1443, Hualien, Taiwan, Dec. 2002. 
[9] D. Y. Chen, X. P. Tian, Y. T. Shen, and M. Ouhyoung, "On visual similarity based 3D model 
retrieval", Computer Graphics Forum 22 (3), pp. 223-232, 2003. 
[10] J. L. Shih, C. H. Lee, and J. T. Wang, “A New 3D Model Retrieval Approach Based on the 
Elevation Descriptor”, Pattern Recognition , Vol. 40,No.1, pp. 283-295, Jan 2007. 
[11] C. T. Kuo and S. C. Cheng, "3D model retrieval using principal plane analysis and dynamic 
programming", Pattern Recognition, Vol 40, Issue: 2, pp. 742-755, Feb, 2007. 
[12] J.-L. Shih and W.-C.Wang “A 3D Model Retrieval Approach based on The Principal Plane 
Descriptor” , Proceedings of The 10 Second International Conference on Innovative 
Computing, Information and Control (ICICIC 2007). 
[13] J. Ricard, D. Coeurjolly and A. Baskurt “ART Extension for Description, Indexing and 
Retrieval of 3D Objects”. Pattern Recognition, Vol. 3, pp.79-82, 2004. 
[14] D. Zarpalas, P. Daras, A. Axenopoulos, D. Tzovaras and M. G. Strintzis, “3D model search 
and retrieval using the spherical trace transform”, EURASIP Journal on Applied Signal 
 24 
[30] B. K. P. Horn, “Extended Gaussian images,” Proc. IEEE, vol. 72, no. 12, pp. 1671-1686, Dec. 
1984. 
[31] P. Papadakis, I. Pratikakis, S. Perantonis, T. Theoharis, “Efficient 3D shape matching and 
retrieval using a concrete radicalized spherical projection representation,” Pattern Recognition, 
vol. 40, no. 9, pp. 2437-2452, Sep. 2007. 
[32] M. Kazhdan, T. Funkhouser, and S. Rusinkiewicz, “Rotation invariant spherical harmonic 
representation of 3D shape descriptors,” Proc. Eurographics/ACM SIGGRAPH symp. 
Geometry process., pp. 156-164, 2003. 
[33] D. V. Vranic, “3D model retrieval,” Ph.D. Dissertation, University of Leipzig, Department of 
Computer Science, 2004. 
[34] H. Laga, H. Takahashi, and M. Nakajima, “Spherical wavelet descriptors for content-based 3D 
model retrieval,” Proc. IEEE Int. Conf. Shape Modeling and Applicat., 2006. 
[35] M. Ankerst, G. Kastenmüller, H. P. Kriegel, and T. Seidl, “3D shape histograms for similarity 
search and classification in spatial databases,” Proc. 6th Int. Symp. Advances in Spatial 
Databases, pp. 207-226, 1999. 
[36] T. Zaharia and F. J. Preteux, “Shape-based retrieval of 3D mesh models,” Proc. IEEE Int’l 
Conf. Multimedia and Expo, vol. 1, pp. 437-440, 2002. 
[37] E. Paquet and M. Rioux, “Nefertiti: A Query by Content Software for Three-Dimensional 
Models Databases Management,” Proc. Int. Conf. Recent Advances in 3D Digital Imaging and 
Modeling, pp. 345-352, 1997. 
[38] D. V. Vranic, “An Improvement of Rotation Invariant 3D Shape Descriptor Based on 
Functions on Concentric Spheres,” Proc. IEEE Int. Conf. Image Process., pp. 757-760, Sept. 
2003. 
[39] T. F. Ansary, M. Daoudi, and J. P. Vandeborre, “3D model retrieval based on adaptive views 
clustering,” in Proc. Third Int. Conf. on Advances in Pattern Recognition, pp. 473-483, 2005. 
 
 
 
 
 
 
 
 
報告內容應包括下列各項： 
一、 參加會議經過 
此次會議地點位於日本九州北部的福岡，離台灣不到兩小時的飛行時間，是國人常去的旅遊景
點，之前也曾經因為參加會議造訪此地。 
我是在會議前一天晚上來到福岡，下榻於福岡 JR 站旁的飯店，飯店有通道直達捷運車站，相
當方便。會議地點位於福岡西北方的福岡工業大學，必須搭 JR線火車前往，還好學校在車站附近，
沒有找尋上的困擾。 
此次會議有相當多的 workshops 同時進行，session rooms 分布於不同的建築物間，因此感覺
上人數比較稀疏，比較缺乏一群人共同研討的感覺。我所屬的 session 是在會議的第二天中午，這
個 workshop 是由台灣學者所主持，可能是多個 sessions 同時進行，來聆聽的人數並不多，發問情
況倒是不少。 
 
 
 
 
 
 
 
 
 
 
 
        圖一 會場-福岡工業大學                 圖二 會場報到處 
 
 
 
 
 
 論文被接受之證明文件: 
 
We are pleased to inform you that your paper:  
A 3D Model Retrieval System Based On The Cylindrical Projection Descriptor  
has been accepted for presentation at ISSE-2010.  
 
We would like to kindly remind you the following important issues:  
 
Please follow EXACTLY the online Submission Guidelines  
(http://isse2010.yuntech.edu.tw/), provided by the Conference Publishing  
Services of the IEEE Computer Society and us, in the preparation of your  
camera-ready copies. Please upload your camera-ready copies via the online  
submission system (http://www.easychair.org/conferences/?conf=isse2010) by  
July 23, 2010. In the submission system, you can use the item [Submit a new  
version] to upload your camera-ready copies.  
 
As a prerequisite of having your papers included in the proceedings,  
conference registration is due by July 30, 2010.  
 
Congratulations on this fine achievement! We are looking forward to seeing you  
in Fukuoka in November 2010.  
 
Sincerely,  
Chien-Cheng Lee, PC chair  
ISSE-2010 
 
[13]. Ricard et al. [14] presented a 3D shape descriptor, 
the 3D Angular Radial Transform (3D-ART) for 3D 
model retrieval. First, the 3D models are represented in 
spherical coordinates. Next, a Principal Components 
Analysis (PCA) is applied to align the 3D models along 
the z-axis. Then, the 3D extension of MPEG-7‟s ART 
[15] is applied to extract feature vectors. 
Mademlis et al. [16] decomposed 3D models into 
meaningful parts and an attributed graph was 
constructed based on the connectivity of the parts. Then, 
the 3D Distance Field Descriptor (3D-DFD) was 
computed and associated to the corresponding graph 
nodes for partial and global 3D model retrieval. 
Papadakis et al. [17] proposed two shape descriptors 
for 3D model retrieval. The 3D model was first aligned 
by continuous PCA (CPCA) or normal PCA (NPCA). 
In CPCA, the traditional one, the principal component 
is analyzed based on the covariance matrix computed 
from the coordinate vectors of the vertices, whereas in 
NPCA the covariance matrix is computed from the unit 
normal vectors of the mesh surfaces. The spherical 
harmonics was then applied on the filled 3D model to 
extract two feature vectors from the CPCA and NPCA 
aligned models separately. Vranic and Saupe proposed 
a modified PCA which used the corresponding triangle 
areas as weighting factors for covariance matrix 
computation [18]. The directions of 20 vertices on 
dodecahedron and the distances computed from the 
center point to the farthest intersections were used as 
features to index similar 3D models. 
Zarpalas et al. [19] proposed a 3D model retrieval 
method using 240 (12×20) 2D gray-level projection 
images, which are obtained by projecting a 3D model 
onto the 240 planes rendered from the 12 vertices of 20 
icosahedrons with different radii. Features were 
extracted from these gray-level images and combined 
to improve the performance. Another 3D model 
retrieval system used 20 depth images rendered from 
the 20 vertices of a dodecahedron [20]. The depth 
information of a pixel in each depth image was 
encoded as a 5-level character. Each row (depth line) in 
the depth image is then represented as a sequence of 
depth information. Dynamic programming was then 
used to compute the distance between two depth line 
descriptors. 
In this paper, the cylindrical projection descriptor 
(CPD) will be proposed for 3D model retrieval. To 
derive better retrieval results, the CPD will be 
combined with the radial distance descriptor (RDD) 
[21]. The rest of the paper is organized as follows. In 
Section 2, the proposed 3D model retrieval method will 
be described. In Section 3, gives the experimental 
results to show the effectiveness of the proposed 
features. Finally, conclusions are given in Section 4. 
 
 
 
2. THE PROPOSED 3D MODEL RETRIEVAL 
METHOD 
 
In this study, two descriptors, including the radial 
distance descriptor (RDD) [21] and the cylindrical 
projection descriptor (CPD) are used for 3D model 
retrieval. Before extracting the feature vectors, the 3D 
model is aligned according to the principal plane [12].  
 
2.1 Radial Distance Descriptor(RDD) 
 
The main steps for computing the radial distance 
descriptor [21] are described as follows: 
(1) 3D model is aligned by it‟s the principal plane [12]. 
The principal plane is defined as the symmetric 
plane on which the sum of distance of all points 
projected is minimal. 
(2) The bounding cube is then decomposed into a voxel 
grid of size 100×100×100 (see Fig. 1). A voxel 
located at coordinates (x, y, z) will be defined as an 
opaque voxel, notated as Voxel(x, y, z) = 1, if there 
is a mesh located within this voxel; otherwise, the 
voxel is defined as a transparent voxel, notated as 
Voxel(x, y, z) = 0. To normalize for translation and 
scale, the object‟s mass center, is moved to the 
point (0, 0, 0) and the average distance from 
non-zero voxels to the mass center is scaled to 25. 
(3) Six projection planes (see Fig. 1), which describe 
the radial distance from the 3D model surface to the 
mass center (see Fig. 2), are derived to represent a 
3D model. Each projection plane is represented by a 
gray level image in which the gray value denotes 
the distance from an opaque voxel to the mass 
center (see Fig. 3). Let the six projection planes be 
notated as Ik, k = 1, 2,…,6. Then ,the gray value of 
each pixel on these images is defined as follows:                 
 
,50,05for                    
)),,,(Voxel),,(R(max),(
501
1



zx
zyxzyxzxI
y  
 
,50,05for                    
)),,,(Voxel),,(R(max),(
501
2



yx
zyxzyxyxI
z  
 
,50,05for                    
)),,,(Voxel),,(R(max),(
501
3



zy
zyxzyxzyI
x  
 
,50,05for                    
)),,,(Voxel),,(R(max),(
150
4



zx
zyxzyxzxI
y  
 
,50,05for                    
)),,,(Voxel),,(R(max),(
150
5



yx
zyxzyxyxI
z  
 
,50,05for                    
)),,,(Voxel),,(R(max),(
150
6



zy
zyxzyxzyI
x  
where .),,(R 222 zyxzyx   
 
  
 
 
 
Fig. 5 The cylindrical projection descriptor. PO  
represent the distance from the 3D model surface to the 
mass. 
 
   
   
   
   
Fig. 6 The three gray-level image F1, F2, and F3, are 
obtained by the cylindrial projection. 
 
2.3 Distance Computation 
 
Let TT6
T
2
T
1 ])( , ... ,)( ,)[( rddrddrddrdd  and
TT
6
T
2
T
1 ])( , ... ,)( ,)[(
bbbb
rddrddrddrdd  denote the 
RDD of a query model and the b-th matching model in 
the database, respectively. The distance between the 
query model and the b-th matching model is defined as 
follows: 


 



6
1
36
1RDD
1
6
1RDD
RDD
)(rdd)(rdd
1
           
1
Dis
k i
b
kk
k
b
kk
b
ii
N
N
rddrdd
 
where 366RDD N . CPD is defined as: 
Let
TT
3
T
2
T
1 ])( ,)( ,)[( cpdcpdcpdcpd  and
TT
3
T
2
T
1 ])( ,)( ,)[(
bbb
cpdcpdcpdcpd   denote the CPD 
of a query model and the b-th matching model in the 
database, respectively. The distance between the query 
model and the b-th matching model is defined as 
follows: 


 



3
1
1024
1CPD
1
3
1CPD
CPD
)(cpd)(cpd
1
           
1
Dis
k i
b
kk
k
b
kk
b
ii
N
N
cpdcpd
 
where 10243CPD N . Finall we use three kinds of 
similarity measure methods to combine RDD and 
CPD: 
1) 
bb
b
CPDRDD
1
DisDis
1
Sim

  
2) Use the Borda Count Algorithm [34] to combine 
the RDD and CPD:  
bb
b
CPDRDD
2
RankRank
1
Sim

  
where. 
bRankRDD  and 
bRankCPD  are the retrieval 
rank values of the b-th matching model for the 
RDD and CPD, respectively. 
 
3. EXPERIMENTAL RESULTS 
 
To demonstrate the effectiveness of the proposed 
method for different 3D models, some experiments 
have been conducted on the Princeton Shape 
Benchmark (PSB) database [23]. The PSB database 
contains 1814 models (161 classes) which are divided 
into 907 training models (90 classes) and 907 test 
models (92 classes). Note that in this database the 
number of models is different for each class. Since the 
number of models in each class is different in the PSB 
database, the recall value ( j
iRe ) for the j-th query 
model in the i-th class is defined as follows: 
,/ i
j
i
j
i NNRe   
where j
iN  
denotes in the retrieval list the number of 
models labeled as class i and Ni is the total number of 
models in class i. The average recall values is defined 
as follows: 
92
1 1
1 i
T
j
i
i jS
Re Re
T  
 
 
where Ts = T1 + T2 + … + T92. The Discounted 
Cumulative Gain (DCG) [28], will also be employed to 
compare the performance of different approaches. DCG 
at the k-th rank is recursively defined as follows: 
,
1 ,                           
2 ,
)(log
DCG
=DCG
1
2
1







kL
k
k
Lk
k
k  
where Lk=1 if the k-th retrieval model and the query 
one belong to the same class; otherwise, Lk=0. The 
overall DCG score for a query model q is defined as 
,DCG
maxk
where kmax is the total number of models in 
the database. DCG is clear that if the top-ranked 
models and the query one are of the same class,
 
max
DCG k will be larger than the retrieval result with 
similar models appearing in the bottom of the retrieval 
list. 
In our experimental, each model in database is 
presented as a query one. Table 1 compares the 
y x 
z 
P 
P’ 
O 
e
1 
e
2 
e
3 
z 
x y 
z 
x y 
z 
y x 
F1 
 
F3 
 
F2 
 
Descriptor”, Pattern Recognition, pp. 283-295, 
2007. 
[11] C.T. Kuo and S.C. Cheng, “3D model retrieval 
using principal plane analysis and dynamic 
programming”, Pattern Recognition, pp. 742-755, 
2007. 
[12] J.L. Shih and W.C. Wang, “A 3D Model Retrieval 
Approach based on The Principal Plane 
Descriptor”, Proceedings of The Second 
International Conference on Innovative Computing, 
Information and Control (ICICIC), pp. 59-62, 
2007. 
[13] M. Ankerst, G. Kastenmuller, H.P. Kriegel, and T. 
Seidl, “3D shape histograms for similarity search 
and classification in spatial databases”, 
Proceedings of 6th International Symposium on 
Spatial Databases (SSD‟99), pp. 207-226, 1999. 
[14] J. Ricard, D. Coeurjolly and A. Baskurt, 
“Generalizations of angular radial transform for 2D 
and 3D shape retrieval”, Pattern Recognition 
Letters,  pp. 2174-2186, 2005. 
[15] MPEG Video Group, “MPEG-7 Visual part of 
experimentation Model Version 9.0“, 2001. 
[16] A. Mademlis, P. Daras, A. Axenopoulos, D. 
Tzovaras, and M. G. Strintzis, “Combining      
Topological and Geometrical Features for Global 
and Partial 3D Shape Retrieval”, IEEE Tran. on 
Multimedia, pp. 819-831, 2008.  
[17] Panagiotis Papadakisa, Ioannis Pratikakisa, Stavros 
Perantonisa, Theoharis Theoharis,  “Efficient 3D 
shape matching and retrieval using a concrete 
radialized spherical projection representation”, 
Pattern Recognition, pp. 2437-2452, 2007.  
[18] D. V. Vranic and D. Saupe, “3D Model Retrieval”, 
Proceedings of the Spring Conference on 
Computer Graphics and its Applications 
(SCCG2000), pp. 89-93, 2000. 
[19] Dimitrios Zarpalas, Petros Daras, Apostolos 
Axenopoulos, Dimitrios Tzovaras, and Michael G. 
Strintzis, “3D Model Search and Retrieval Using 
the Spherical Trace Transform,” EURASIP Journal 
on Advances in Signal Processing, 2007. 
[20] Mohamed Chaouch, Anne Verroust-Blondet, “ A 
New Descriptor for 2D Depth Image Indexing and 
3D Model Retrieval”, IEEE International 
Conference on Image Processing, pp. 373-376, 
2007. 
[21] J.L. Shih, C.H. Lee and C.H Chuang, “A 3D Model 
Retrieval System Based On The Derivative Radial 
Distance”, Proceedings of The 22th IPPR 
Conference On Computer Vision, Graphics and 
Image Processing (CVGIP) 2009. 
[22] J.L. Shih, T.Y Huang, and Y.C. Wang, “A 3D 
Model Retrieval System Using the Derivative 
Elevation and 3D-ART”, Proceedings of the IEEE 
Asia-Pacific Services Computing Conference, 
(APSCC), pp. 739-744, 2008.  
[23] P. Shilane, P. Min, M. Kazhdan, T. Funkhouser, 
“The Princeton shape benchmark”, Proceedings of 
Shape Modeling Applications, pp. 167-178, 2004. 
[24] J. L. Shih and H. Y. Chen, “A 3D model retrieval 
approach using the interior and exterior 3D shape 
information”, Multimedia Tools Applicaion., vol. 
43, no. 1, pp. 45-62, May 2009. 
[25] B. K. P. Horn, “Extended Gaussian images”, in 
Proceedings of IEEE, vol. 72, no. 12, pp. 
1671-1686, Dec. 1984. 
[26] M. Kazhdan, T. Funkhouser, and S. Rusinkiewicz, 
“Rotation invariant spherical harmonic 
representation of 3D shape descriptors”, in 
Proceedings of Eurographics/ACM SIGGRAPH 
Symposium on Geometry processing, pp. 156-164, 
2003. 
[27] D. V. Vranic, “3D model retrieval”, Ph.D. 
Dissertation, University of Leipzig, Department of 
Computer Science, 2004. 
[28] C. B. Akgul, B. Sankur, Y. Yemez, and F. Schmitt, 
“3D model retrieval using probability 
density-based shape descriptors”, IEEE 
Transaction on Pattern Analysis and Machine 
Intelligence, vol. 31, no. 6, pp. 1117-1133, June, 
2009. 
[29] H. Laga, H. Takahashi, and M. Nakajima, 
“Spherical wavelet descriptors for content-based 
3D model retrieval,” in Proceedings of IEEE 
International Conference on Shape Modeling and 
Application (SMI„06), 2006. 
[30] T. Zaharia and F. J. Preteux, “Shape-based retrieval 
of 3D mesh models”, in Proceedings of the IEEE 
International Conference on Multimedia and Expo, 
vol. 1, pp. 437-440, 2002. 
[31] E. Paquet and M. Rioux, “Nefertiti: A Query by 
Content Software for Three-Dimensional Models 
Databases Management”, in Proceedings of 
International Conference on Recent Advances in 
3D Digital Imaging and Modeling, pp. 345-352, 
1997. 
[32] D. V. Vranic, “An Improvement of Rotation 
Invariant 3D Shape Descriptor Based on Functions 
on Concentric Spheres”, in Proceedings of IEEE 
International Conference on Image Processing, pp. 
757-760, Sept. 2003. 
[33] T. F. Ansary, M. Daoudi, and J.-P. 
Vandeborre, ”3D Model Retrieval Based on 
Adaptive Views Clustering”, LNCS 3687, pp. 
473–483, 2005. 
[34] M. Jovic, Y. Hatakeyana, F. Dong, and K. Hirota, 
“Image Retrieval Based on Similarity Score Fusion 
from Feature Similarity Ranking Lists”, LNAI 
4223, pp. 461-470, 2006. 
99 年度專題研究計畫研究成果彙整表 
計畫主持人：石昭玲 計畫編號：99-2221-E-216-045- 
計畫名稱：整合三維頻率特徵及相關與非相關模型之自動選擇機制於 3D 模型檢索系統 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 3 3 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
