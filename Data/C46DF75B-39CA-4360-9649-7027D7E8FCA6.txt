一、摘要 
在本年度的計畫中提出了兩套適用於家
用看護應用的演算法：辨識遮蔽物體與估測
語者聲源方向的演算法。本計劃使用二維影
像來辨識遮蔽物體的遮蔽部位，並結合全域
影像特徵與局部影像特徵來處理遮蔽問
題。首先，會先利用以高斯混合模型為基礎
的背景濾除系統來抽取前景區域，接著再利
用形態學運算子來抽取前景物體的輪廓。最
後再利用所提出來的切割演算法配合抽取
出來的輪廓資訊來偵測物件的顯著點。在估
測聲源方位演算法部分，本計畫研發出一即
時語者方位估測系統，此系統利用八顆麥克
風估測出聲源二維角度位置。此系統可自動
估測聲源角度，而全系統包含了麥克風陣列
平台、主要頻率選擇機制、語音活動偵測和
聲源角度偵測演算法。本報告將語者角度估
測系統置於一真實環境作量測用以評估其
效能。 
關鍵詞：家用看護、部分形狀、遮蔽物體辨
識、語者方位、麥克風陣列 
This work proposes an occluded objective 
recognition and speaker direction estimation 
system for home-care applications. In 
occluded objective recognition, this work 
overcomes the occluded problem using 2D 
images and tries to detect the occluded part of 
an object. The global information is extracted 
for combining local information to overcome 
the occluded problem. A GMM background 
removal system is employed to extract the 
foreground object and then the contour of the 
foreground object is extracted using 
morphological operation. A split process is 
proposed to detect the dominant points of an 
object using the extracted contour information. 
In speaker direction estimation, a real-time 
speaker direction estimation system using 
eight microphones has been developed to 
estimate two-dimensional direction of speaker. 
This system which contains a microphone 
array platform, principal frequencies selection 
mechanism, voice activity detection and 
direction of arrival estimation system can 
estimate speaker direction automatically. The 
effectiveness of the proposed system is 
demonstrated by the experiments in indoor 
environment. 
Key Word: Home-care, partial shape, 
occluded object recognition, DOA, 
microphone array. 
 
二、緣由與目的 
In the digital homecare system, human 
posture is an important factor. Vision 
information is useful for deciding human 
posture. However, the occlusion affects the 
shape of object and the extracted features. It is 
difficult to establish a database by using all 
kinds of occluded objects. In this work, using 
perfect objects to establish a database is 
proposed to overcome the effect about 
occlusion.  
In the occluded object recognition, the 
global information is separated for combing 
local information. The occlusion only affects 
local features and the other features can be 
matched when the system adopts local 
features. 
In the speaker direction estimation, the idea 
of using multiple microphones to localize 
sound sources has been developed for a long 
time. In the noisy environment, the 
conventional delay estimation methods in time 
domain [1] or in frequency domain [2-3] can’t 
obtain satisfied results. In this paper, a 
real-time speaker direction estimation system 
using eight microphones has been proposed 
and implemented in this paper. The objective 
points describing the boundary of the shape. 
Calculating the region of support of ip point 
follow the below algorithm. 
(a) Right region of support: 
(1) Initialize 2+= ik and 0=oldF  
(2) Calculate ikL : the length of the line 
segment that joins points ip and kp  
(3) Calculate ikE : the sum of perpendicular 
distances from all the points 
between ip and kp  
(4) Calculate ikiknew ELF −=  
(5) If the condition of two 
successive oldnew FF <  , then return 2−kp as the 
end support point, else, 
set newold FF = , 1+= kk and go to step (2) 
(b) Left region of support: Follow the same 
steps but move in the opposite direction. 
3. Node strength and sorting 
The end points are used for calculating the 
strength. Fig. 1 shows an example of 
calculating the strength of the node at point i . 
The lengths of the right and left support arms 
are shown for each point. As indicated, 
point i serves as the right node for 
points ),,,,( hgfed and as left node for 
points ),,,,( nmlkj . Hence, the strength of this 
node is 10. 
We only consider the nodes that the strength 
greater than zero and sort these nodes in 
descending order. 
4. Shape Covering 
The shape covering algorithm starts with the 
ranked set of nodes, it finds the best subset of 
these nodes that covers the entire shape 
according to the following steps: 
 
Fig. 1. Calculating the strength of node i  
Mark all points of the boundary shape as 
non-dominant )0( =d and uncover )0( =c . For 
each node in the ranked set of nodes, if the 
node corresponds to an uncovered boundary 
point (its immediate left or right neighbor 
has 0=c ), then 
(1) Set this point as dominant 1=d , and 
mark it as covered 1=c . 
(2)  Starting from this node, mark each 
point that belongs to its right support region 
as covered. If any already covered point is 
detected, set this crossing point as dominant 
and goes to the next step. If the point xp next 
to the “last point in the right support arm” is 
a covered point, marks xp as dominant. 
(3)  Repeat the above step for covering the 
left support region. 
Fig. 2 shows the three cases of the shape 
covering algorithm that determines the 
dominant points. Fig. 2(a) depicts the covering 
of node aP . The length of both the left and 
right support arms for this node is 5. Fig. 2(b) 
illustrates the first scenario of the second step 
of the algorithm. The node aP is covered first 
and then the node bP is covered later and the 
intersection point will be set as dominant. Fig. 
2(c) illustrates the second scenario of the 
second step of the algorithm. In this case, the 
point xP  is the left end point of node aP  and 
yP is the right end point of node bP . Since the 
point next to the point yP is covered, we 
mark xP as dominant. 
2. Group matching 
  The group matching stage finds the 
correct matching parts by detecting the 
successive matching parts, and detects the 
occluded part of the unknown object by 
detecting the unmatched parts of the segment 
matching table.     
3. Detect the occluded parts 
After group matching, the best matching 
result of the database is determined. The 
system detects the unmatched parts of the two 
objects. If the number of unmatched parts is 
more than a threshold, then the system marks 
the occluded parts of the contour of unknown 
object. Fig. 5 shows an example of detected 
occluded part of an object.  
 
 
(a) unknown object (b)best matching result 
Fig. 5. Mark the occluded parts (blue points) 
Speaker Direction Estimation 
The overall speaker direction estimation 
system architecture is illustrated in Fig. 6.  
)(1 nx
)(2 nx
)(nxM
M
 
Fig. 6. Speaker direction estimation system architecture 
The speaker direction estimation system 
can be separated into two stages by the voice 
activity detection (VAD) system, silent stage 
and speech stage. The result of VAD algorithm 
[5] is adopted to decide which stage the 
system should be executed in. If the result of 
VAD is equal to zero, which indicates that no 
speech exists, the system would be executed 
in the silent stage. In the silent stage, 
the P significant frequencies nPn ww ˆ,,ˆ 1 K  will be 
chosen by comparing the received signals’ 
amplitude spectrum in each frequency to 
represent the principal frequencies of the 
non-speech environment. The received signal 
which contains d sources at the thm −   
microphone can be modeled as: 
∑
=
+−=
d
k
mmkkmkm tntsatx
1
)()()( τ               (7) 
where mka  is the transfer function from the 
thk −  source to the thm −  microphone and 
)(tnm  is the interference signal. Transform the 
received signal into frequency domain and the 
original model at frequency band 
jω  and 
frame l can be described as: 
∑
=
− +=
d
k
jm
j
jkmkjm lNelSalX mkj
1
),(),(),( ωωω τω     (8) 
Assume that )(nxm  is utilized to detect the 
speech. The P significant frequencies can be 
selected as follows: 
∑
=
=
N
l
jmj lXN
wX
0
),(1)(ˆ ω                   (9) 
PLwXwXww
pLnPn
>= )}(ˆ,),(ˆ{}ˆ,,ˆ{ 11 KK        (10) 
where N  is the order of frame-average. L  
means the number of frequency bands. 
p
. denotes the biggest P values operation. 
When the result of VAD is one, the system 
would be switched to the speech stage and 
then the P significant frequencies of the silent 
stage are transferred to the DOA algorithm for 
estimating the speakers’ directions. A 
well-known blind DOA estimation algorithm 
called MUSIC is adopted in this paper. 
Re-write (8) in matrix form: 
 Fig. 7. The flowchart of the proposed method. 
Hence, the new significant frequencies can 
be written as (20) to be more representative 
for speech stage.    
}ˆ,,ˆ{}ˆ,,ˆ{}ˆ,,ˆ{ 111 nPnsQsvRv wwwwww KKK −=            (20) 
Hence, the computational complexity of (18) 
can be reduced by considering only R  
significant frequencies from (20) and the 
speakers’ directions are determined by finding 
the peaks of MUSIC spectrum: 
∑
=
= R
r
vrivrNvr
H
i
i
wAwwA
R
J
1
)ˆ()ˆ()ˆ(1
1)(
P
θ       (21) 
四、實驗結果 
A. Occluded Objective Recognition 
Fig. 7 shows the flowchart of occluded 
object recognition system. It divides into 
database construction and object recognition 
stages. In the experiment, object database 
contains 8 objects which are shown in Fig. 8 
and the dominant points of the objects are 
shown in Fig. 9. The database has been 
constructed by using the complete object 
images. In the occluded test, the shape of 
object has been occluded by user’s hand. The 
experiment tries to test the tolerance of the 
occluded object. The 20% and 40% occluded 
objects have been used to test the tolerance of 
the system. Fig. 10 shows an example of 
detected dominant points of occluded objects. 
Fig. 11 displays the results of occluded part 
detection, where the blue points represent the 
detected occluded parts of the objects. In 
Table 2, the recognition rate of the 40% 
occluded images is around 75%.  
B. Speaker Direction Estimation 
In the speaker direction estimation system, 
the experiment was performed in a room 
approximately of the size 10.5 m x 7.2 m and 
height of 3.6 m. A uniform circular array of 8 
microphones with 17.5 cm radius is 
constructed for the experiment. The uniform 
circular array geometry can provide 360° 
azimuthal coverage and information on source 
elevation angles. Ten major frequencies, 
ranging from 0.1 KHz to 2.8 KHz, were 
adopted for the proposed DOA estimation 
system and the sampling rate is 16 KHz, 16 bit. 
The experimental conditions of DOA 
estimation are shown in Fig. 12, where the 
signals from speech 1 to speech 9 are speech 
signals; noise 1 is an air conditioning noise. 
Two cases, single source and double sources, 
were tested in this experiment to evaluate the 
performance of the proposed system. 
The experimental results of single and 
double sources cases are shown in Table 3 and 
4. The trial number in each condition is 100. 
Two-dimensional angels, 360° azimuth and 
90° elevation are considered to be estimated in 
this experiment. As shown in Table 3 and 4, 
the statistical estimation results of the 
proposed DOA estimation system are 
sufficiently accurate for the vision 
applications. 
 
1. bear 2. funnel 3.container 4. cup 
 
5. phone 6. adhesive 7. base 8. dinosaur 
Fig. 8. The database contains 8 object. 
