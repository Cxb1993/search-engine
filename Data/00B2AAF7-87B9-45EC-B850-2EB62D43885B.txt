1行政院國家科學委員會專題研究計畫成果報告
對數常態和Weibull分配於型 II高設限資料下
之百分位數的估計與誤判分析
計畫編號：NSC 98-2221-E-151-026
執行期限：98 年 8 月 1 日至 99 年 7 月 31 日
主持人：于鴻福 國立高雄應用科技大學商務經營研究所
中文摘要
基於成本與時間的考量，欲於一段合理的
試驗時間內，觀測到所有受測樣本的壽命
資料是一件相當困難的事情，所以設限資
料(censored data)的搜集即常發生於壽命
試驗中，甚至是採用加速壽命試驗
(accelerated life test)亦然；尤其是面對現
今的高可靠度產品，設限的比例更可能高
達五成以上，此種資料一般即稱為高設限
資料(highly censored data)。在此一情境
下 ， 甚 至 是 最 大 概 似 法 (maximum
likelihood method)亦可能無法獲得令人滿
意之產品可靠度資訊的精確估計。實務
上，若高設限資料之產生主要是基於時間
的限制（亦即，成本不是主要的考量），那
麼即可於試驗中投入較大量的測試樣本以
做為補救，此種方式有時稱為數量加速
(quantity acceleration)，本計畫之目的即是
要探討高設限資料之產品可靠度資訊的估
計。不同於傳統的壽命分析技術利用所有
的試驗資料（包括失效資料和尚未失效的
資料）以進行壽命推估，本計畫擬提出一
種僅利用失效資料的分析方法；更明確地
說，對於一組型 II的高設限資料，本計畫
將試驗所得的失效資料視為產品壽命分配
中的最小極端值(smallest extremes)，並以
Peak-over-Threshold (POT) 模型來建構這
些極端值的近似分配，以推估所關注之產
品壽命的百分位數。其次並將所得之結果
與由最大概似法估得之結果做一比較，以
評估本計畫所提方法之績效。
關鍵詞：高可靠度產品，高設限資料，數
量加速，Peak-over-Threshold 模型
Abstract
Due to cost and/or time considerations, it is
difficult to observe all of the lifetime data of
products within a reasonable time period of
experimentation. Hence, censored lifetime
data are usually collected in real applications.
Even when accelerated life tests (ALTs) are
used, censoring is usually inevitable, too.
Especially for highly reliable products
nowadays, the censoring proportions are
more likely greater than 0.5. Such data are
called highly censored data. In such a case, it
is not easy to obtain a precise estimation of
reliability information that is of interest,
even though maximum likelihood (ML)
methods are utilized. With respect to the
scenario that highly censored data occur due
to time restriction (i.e., cost is not of main
concern), a remedy is to put a great number
of devices into testing. This is sometimes
termed as quantity acceleration. The main
purpose of the project is to address this issue.
Differing from traditional methods
(including ML method) in reliability
engineering which use the whole censored
data (including failure times and the running
times of unfailed items) to estimate the
reliability information of interest, this
project will provide a methodology to
estimate the reliability information of
interest based only on the observed lifetime
data in the life test. Specifically, with respect
to a type II highly censored data, we treat the
failure data as the smallest extremes of the
lifetime distribution and then model the
extremes using the Peaks-over-Threshold
(POT) model to estimate the lifetime
quantile of interest. A comparison with ML
method is made to evaluate the effectiveness
of the proposed method.
Keywords: highly reliable products, highly
censored data, quantity acceleration,
Peaks-over-Threshold model
3normal distribution  2,N  or
extreme value distribution buExtreme , .
3. Assume that rttt  ...21  are the r
smallest lifetimes observed in the life
test. Obviously, rt  is random.
Due to the equivalence of lognormal
(Weibull) and normal (extreme value)
distributions, in the following paragraphs,
we will address the issue based on the log
lifetimes.
According to Assumption 2, the thp
quantile p of Tln can be easily
expressed as follows:
(1) If  2,~ln NT :
)(Np =   pz , (1)
where pz  is the
thp quantile of a
standard normal distribution.
(2) If  buExtremeT ,~ln :
)(Ep = bcu  , (2)
where ))1ln(ln( pc  .
3. Brief Description of the POT
Model
3.1 Description of the generalized Pareto
distribution
    Let X denote a random variable having
the distribution function F and let   denote
a threshold. Consider the following
conditional excess distribution function
(CEDF):
)|Pr()(   XyXyF
)(1
)()(


F
FyF

 . (3)
Then, according to Pickands-Balkema-de
Haan Theorem, as   approaches infinity,
)( yF will converge to a generalized
Pareto distribution. In other words,
0)()(suplim
,
0


yGyF
uxy
 ,
where








 

0if,exp1
;0if,11
)(
1
,


 

y
--
y
yG (4)
is called a generalized Pareto distribution,
defined on }0and0|{  yy , with   a
scale parameter and   a shape parameter.
Thus, for sufficiently large  , )( yF  can
be approximated by the generalized Pareto
distribution in Equation (4). Thus, according
to Equation (4), the probability function (pdf)
of X  can be given by








 

.0if,exp1
;0if,11
)(
11
,






y
-
y
yg (5)
3.2 Parameter estimation of the
generalized Pareto distribution
   Suppose that ryyy ,...,, 21  are the r
excesses of the threshold  . Then the
log-likelihood is derived from Equation (5)
as


  )(ln),(ln ,1 i
r
i
ygL 




 


  r
i
iyr
1
1ln11ln 

 .
Taking the first-order partial derivatives of
),(ln L  with respect to   and  ,
respectively, and setting them equal to zero
yield





 



 

 





r
i i
i
r
i i
i
r
i
i
y
ynL
y
yyL
1
11
2
.0)(
11ln
0111ln1ln






Thus, the maximum likelihood estimates
(MLEs) of   and   can be obtained by
solving the simultaneous equations above.
3.3 Estimation of a quantile of the CEDF
5unfailed items. Let ˆ  and ˆ  denote the
MLEs of   and   based on the whole
censored data niit 1}{  . The procedure to
compute ˆ  and ˆ  can be found in
Lawless (1982).
Because of the invariance properties of
MLEs, according to Equation (1), the MLE
of )( Np  can be given as follows by
substituting ˆ  and ˆ  into Equation (1):
 ˆˆ),(ˆ )(  pNp zrn .
4.2 The log lifetime data follow an
extreme value distribution
Let uˆ  and bˆ  denote the MLEs of u
and b based on the whole log censored data
n
iit 1}{  . The procedure to compute uˆ  and
bˆ  can be found in Lawless (1982).
Similarly, due to the invariance properties of
MLEs, according to Equation (2), the MLE
of )(Ep  can be given as follows by
substituting these two estimators into
Equation (2):
bcurnEp ˆˆ),(ˆ )(  .
5. Results and Discussion
 First, for convenience, let NM
represent the case that the data are identified
and analyzed as a normal distribution; EM
represent the case that the data are identified
and analyzed as an extreme value
distribution; GM  represent the case that the
data are analyzed by the proposed method.
To evaluate the efficiency of the proposed
method, a simulation analysis is conducted
to compare the MSE of the estimated thp
quantile obtained by GM  with those
obtained by NM  and EM .
Two criteria are proposed to compare
the MSEs. In practice, the true distribution
of the data is unknown in advance. It may be
that one distribution has a larger likelihood
of occurrence than the other. Hence, the first
criterion proposed here takes the prior
probabilities of occurrence into account.
Next, with respect to the uncertainty of the
occurrence of normal and extreme value
distributions, one possible way to compare
the MSEs obtained by GM , NM , and
EM  is based on their worst possible
outcomes of these three methods.
Specifically, the second criterion selects an
“optimal” method with the minimum of the
maximum possible MSEs obtained by GM ,
NM , and EM . That is, the minimax
criterion is used to compare the MSEs.
      Simulation analyses are conducted at
each of 44 different combinations of the
sample size n and the censoring rate 


n
rq ,
shown in Table 1. At each of the
combinations, 10000 simulations are
conducted for both of normal and extreme
value distributions under the following
conditions and the MSEs of the estimated
thp  quantiles (p=0.01~q) are computed:
(1) )1,0(),(   and )1,0(),( bu ;
(2) )2,0(),(   and )2,0(),( bu ;
(3) )1,2(),(   and )1,2(),( bu .
Table 1. Forty-four different combinations of the sample size
and the censoring rate
q
n 0.05 0.1 0.2 0.3 0.4 0.5
20   x x x ○ ○ ○
30 x x ○ ○ ○ ○
40 x x ○ ○ ○ ○
7(b) for 40,30,20n  and 5.0q ,
80,60n  and 4.0q ,
120,100n  and 3.0q , and
160n  and 3.0q ,
)),(ˆ(MSE)),(ˆ(MSE )|()|( rnrn EEpEGp  
for p near q.
6. With 5.021  pp , for 40,30,20n
and 5.0q , 80,60n  and 4.0q ,
120,100n  and 3.0q , and 160n
and 3.0q ,
)),(ˆ(MSE )( rnGp
))},(ˆ(MSE)),,(ˆ(MSEmin{ )()( rnrn NpEp 
for p near q.
5.2 Criterion 2
Next, let
),;(MSE rni
))},(ˆ(MSE),,(ˆ(MSEmax{ )|()|( rnrn EipNip  ,
GENi ,, .
Obviously, ),;(MSE rnG  represents the
worst result if the thp  quantile is estimated
by using the proposed method;
),;(MSE rnN  and ),;(MSE rnE  represent
the worst results if the data get identified as
a normal distribution and an extreme value
distribution, respectively.
   Based on the ),;(MSE rni , GENi ,, ,
we propose a rule to choose a method among
},,{ GEN MMM  to be used for data
analysis:
(CR) For given n and p, the method iM
is chosen to estimate p  if
),;(MSE rni
 ),;(MSE),,;(MSE),,;(MSEmin rnGrnGrnN .
Table 2 lists the methods which are
selected by the CR criterion and the
corresponding values of p under the
combinations of (n, q) in Table 1. Similar to
Criterion 1, from Table 2, it is seen that for
3.0q , the proposed method is selected by
the CR criterion for data analysis for p near
q.
Table 2. The methods which are selected by the CR criterion and the corresponding values of
p under the combinations of (n, q) in Table 1
(n, q) iM :the values of p (n, q) iM :the values of p
(20, 0.3) EM :0.01~0.05
GM :0.06~0.28
NM :0.29~0.30
(100, 0.2) EM :0.01~0.03
GM :0.04~0.19
NM :0.20
(20, 0.4) EM :0.01~0.07, 0.39
GM :0.08~0.37
NM :0.29~0.30
(100, 0.3) EM :0.01~0.05, 0.11~0.23,
  0.30
GM :0.06~0.10
(20, 0.5) EM :0.01~0.09, 0.47~0.50
GM :0.10~0.46
(100, 0.4) EM :0.01~0.07, 0.10~0.40
GM :0.08~0.09
(30, 0.2) EM :0.01~0.03
GM :0.04~0.19
NM :0.20
(100, 0.5) EM :0.01~0.09, 0.13~0.50
GM :0.10~0.12
(30, 0.3) EM :0.01~0.05
GM :0.06~0.28
NM :0.29~0.30
(120, 0.05) GM :0.01~0.04
NM :0.05
9(80, 0.4) EM :0.01~0.07, 0.11~0.35,
    0.40
GM :0.08~0.10, 0.36~0.39
(200, 0.3) EM :0.01~0.05, 0.08~0.27,
    0.30
GM :0.06~0.07, 0.28~0.29
(80, 0.5) EM :0.01~0.09, 0.13~0.50
GM :0.10~0.12
(200, 0.4) EM :0.01~0.07, 0.10~0.40
GM :0.08~0.09
(100, 0.1) EM :0.01
GM :0.02~0.09
NM :0.10
(200, 0.5) EM :0.01~0.09, 0.11~0.50
GM :0.10
References
1. Bacha, M. and Celeux, G. (1996).
Bayesian estimation of a Weibull
distribution in a highly censored and small
sample setting, Institut National De
Recherche En Informatque Et
Automatique.
2. Cohen, A. C. (1991). Truncated and
censored samples - theory and
applications, Marcel Dekker, Inc. New
York.
3. Elsay, E. A. (1996). Reliability
Engineering, Addison Wesley Longman,
Inc., New York.
4. Lawless, J. F. (1982). Statistical Models
and Methods for Lifetime Data. John
Wiley & Sons, New York.
5. Lawless, J. F. (2003). Statistical Models
and Methods for Lifetime Data. 2nd ed.
John Wiley & Sons, New York.
6. Meeker, W. Q. and Escobar, L. A. (1998).
Statistical Methods for Reliability Data,
John Wiley & Sons, New York.
7. Nelson, W. B. (1970). Statistical methods
for accelerated lifetest data-the inverse
power law model. General Electric Co.
Technical Report}, 71-C-011,
Schenectady, New York.
8. Nelson, W. (1982). Applied Life Data
Analysis, Wiley, New York.
9. Nelson, W. (1990). Accelerated
Testing---statistical models, test plans,
and data analyses. John Wiley & Sons,
New York.
10. Reineke, D. M. Pohl, E. A. and Murdock
Jr, W. P. (1999). Maintenance-policy
cost-analysis for a series system with
highly-censored data. IEEE Transactions
on Reliability 48(4), pp. 413-419.
11. Steiner, S. H. and Mackay, R. J. (2000).
Monitoring processes with highly
censored data. Journal of Quality
Technology 32, pp. 1999-208.
無研發成果推廣資料 
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
