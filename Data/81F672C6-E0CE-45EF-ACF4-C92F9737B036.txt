the lighting condition. The algorithm of
surface reconstruction is based on [Y.-L.
Chen and S.-H. Lai, 2007] and this work has
been accepted by Shape Modeling
International, Lyon, France, June 2007.
2. Contour-Based Shape from Circular
Motion
Reconstructing 3D model from image
sequences has been studied for decades. In
real applications, for instance 3D object
digitization in digital museum, modeling
from circular motion sequences is a
practical and widely used approach in
computer vision and computer graphic
communities. Numerous methods, which
focus on circular motion, have been
proposed and they can be classified into two
camps; namely, the feature-based and
silhouette-based approaches.
However, it is difficult to establish accurate
feature correspondences from the image
sequences for objects of texture-less,
semi-transparent, or reflective materials,
such as jade. Instead of feature
correspondences, the silhouette-based
approach integrates the object contours to
recover the 3D geometry.
Most of the silhouette-based methods are
based on the surface of revolution (SoR) to
obtain an initial guess of image invariants,
thus making them infeasible when the
image sequence is sparse (for example,
interval angle larger than 20 degree) or
incomplete.
In our approach, we first use the same cost
function, as proposed in [P. R. S. Mendonca
and R. Cipolla, 1999], to determine the
epipoles of successive image pairs from
silhouettes. Thus, constant interval angle is
the main assumption of our algorithm. In
addition, we propose a method for
initializing the positions of epipoles, which
is important in practice. A pair of epipoles
formed by a certain interval angle can
provide a constraint on the angle and focal
length. With more pairs of epipoles
recovered, the focal length can therefore be
determined as the one that best satisfies
these constraints and the angle is
determined concurrently. After obtaining the
camera intrinsic parameters, the rotation
matrix about camera center can be
recovered from the image invariants up to
two sign ambiguities which can be further
resolved by making the sign of
back-projection epipoles consistent with the
camera coordinate. Finally, the epipolar
tangency constraints for all pairs of views
are minimized to refine the camera
parameters by using all determined
parameters as an initial guess in the
nonlinear optimization process.
Figure 2.1. (a) The geometry of circular motion. (b) The
image invariants under circular motion.
The geometry of circular motion can be
illustrated in Figure 2.1(a). A camera C
rotates about an axis Ls, and its track forms
a circle on a plane Πh that is perpendicular
to Ls and intersects at the circle center Xs.
Without loss of generality, we assume the
world coordinate system be centered at Xs
with Y-axis along Ls and C be placed on the
negative Z-axis. If the camera parameters
are kept constant under circular motion, the
imageΠi of C will contain invariant entities
of the geometry as shown in Figure 2.1(b).
Line lh (ls) is the projection of Πh(Ls). The
three points, vx, vy, and xs, are the vanishing
points of X-axis, Y-axis and Z-axis,
respectively.
Assume the camera intrinsic parameters and
the rotation matrix about camera center,
which will be referred as camera pose in the
circle with a constant interval angle θ. With
a certain interval angle, a pair of determined
epipoles can provide a constraint on the
angle and focal length. For instance, for the
image of C3 as shown in Figure 2.3(b),
epipoles formed by the angleθare e2 and e4.
Therefore, we can derive a relationship of
the angle and focal length with epipoles as
follows:
 4121 , eKeKang  (2.4)
where the function ang(.,.) gives the angle
between two vectors. In equation (2.4), we
have one constraint but two unknowns,
which are the angle θand the focal length,
the constraint is not enough to determine the
unknowns. Recall that, the image sequence
is taken under a constant interval angle.
Take Figure 2.3(a) for example, C1-C-
2-C3-C4-C5 is an image sequence with a
constant interval angle θ. Also, C1-C3-C5 is
an image sequence with a constant interval
angle 2θ, which can provide another
constraint as following:
 5111 ,2 eKeKang  (2.5)
With more pairs of epipoles formed by
different interval angles to be recovered,
more constraints similar to equation (2.4)
and (2.5) can be applied to determine the
focal length. Because it not easy to derive a
closed-form solution from these equations,
we perform a linear search on the angleθto
find the one that best satisfies these
constraints in our implementation.
From the extracted epipoles, lh can be
computed by line fitting these epipoles, and
also ls can be determined concurrently in the
epipole extraction stage. Then, xs is the
intersection of lh and ls. After camera
intrinsic parameter K is obtained, vx can be
computed from the pole-polar relationship,
i.e. vx~KKTls.
From equation (2.2), with the camera
intrinsic parameters and image invariants
known, the camera pose R can be computed
up to two sign ambiguities as follows:
 
 
132
1
3
1
1
1,
1,
rrr
xKnormr
vKnormr
s
x







(2.6)
where the function norm(.) normalizes a
vector to unit norm.
Notice that, the sign of rotation axis has no
difference for projection to the image
coordinates, but back-projection of image
points will lead to a sign ambiguity. This
ambiguity can be resolved by
back-projecting the epipole, which is
obtained from image, and checking the sign
with the corresponding camera position
which is transformed to the camera
coordinate system from the world
coordinate system by using the determined
camera pose R. Because the camera position
in the world coordinate system is irrelevant
to camera pose R, we still can recover the
camera position in the presence of rotation
ambiguity. Furthermore, the Gram-Schmidt
process is applied to obtain the orthogonal
basis.
In the next, we show some experimental
results on both synthetic and real data sets
of applying the proposed silhouette-based
algorithm to reconstruct 3D object models
from sparse and incomplete image
sequences under circular motion.
First, we used the Stanford bunny model to
generate the synthetic data, with some
example images shown in Figure 2.4. The
image sequence contains 36 images, each
image is of size 800x600 pixels and the
interval rotation angle is 10 degrees. The
focal length is set to 2000. In the epipole
estimation stage, we compute the epipoles
for images with 40-degree interval angle
and the two fixed epipoles are (-5483.9,
1919.3) and (7221.0, 927.1) after the
minimization process, which are very close
to the ground truth (-5460.9, 1911.2) and
(7234.8, 929.3). Then, we use the estimated
parameters as the initial guess to perform
the overall minimization and then use image
eigenhead basis vectors:



m
i
iisSS
1
 


m
i
iit
1
 (3.1)
where αdenotes the shape coefficients and
si is the i-th eigenhead basis of the
morphable model . βand it denote the
texture coefficients and the i-th texture
principal component vector, respectively.
For spherical harmonics, it is easier to
describe if we write it as a function of x, y, z
instead of the angle of spherical coordinates.
Let nx, ny, nz denotes the normal direction of
n vertices with unit length, λdenote the
vector containing the albedo of n vertices
and the operator.* denote the element-wise
product. The first nine spherical harmonic
bases are given bellow:
)(.
12
5
2
3
)2(.
4
3
2
1
);;(.
12
5
3);;(
);;(.
4
3
);;(
4
22
20
212221
101111
00
yyxx
e
yyxxzz
zxyxzy
eoo
zyx
eoe
nnnnb
nnnnnnb
nnnnnnbbb
nnnbbb
b















(3.2)
For all possible face model, the shape and
texture (λ) can be approximated by equation
(3.1), and the first nine SH bases can be
computed by approximating λand nx, ny, nz
with the corresponding linear subspace
representations. Therefore, all intensity
values of the vertices in the 3D face model
can be approximated by the weighted sum
of the corresponding SH bases bwT . An
example of the first nine spherical harmonic
bases for a 3D head model is shown in
Figure 3.1.
The main algorithm to reconstruct a 3D face
model from a single image under unknown
light condition is separated into two steps.
The first step is to initialize all the
parameters, includes pose, shape, texture,
and illumination coefficients, and the
second step iteratively refines all the
parameters.
Figure 3.1. An example of the first nine spherical
harmonics. Lighter part represented the positive value, and
darker part shows the negative values in spherical
harmonics.
In the first step, we apply the 3D
reconstruction algorithm described in [S.-F.
Wang and S.-H. Lai, 2006] to initialize the
shape model by minimizing the geometric
distance of landmark features and silhouette
simultaneously. According to different
reflection properties between face feature
area and skin area, we defined these two
areas for more accurate texture and lighting
estimation (Figure 3.2). Since face skin is
sensitive to lighting variations, the
coefficients of the SH bases are estimated
by minimizing the image intensity errors in
the skin area. On the other hand, the
estimation of the albedo () parameters is
based on minimizing the intensity errors in
the face feature area, which contains most
texture variations in the face.
Figure 3.2. The blue points denote the vertices of the
model. The left picture shows the face feature area, and the
right one shows.
Figure 3.3 shows some examples of the
original source images (top 3 rows) under
12 different illumination conditions and the
corresponding 3D face models (bottom 3
rows).
4. A POU-based Algorithm for Implicit
Surface Reconstruction Using Belief
Propagation
In this section, we briefly describe a new
algorithm for the fundamental problem of
reconstructing surfaces from a large set of
unorganized 3D data points. The local
shapes of the surface are recovered by
variational implicit surface represented as a
weighted combination of radial basis
functions. The variational implicit patches
are then combined together to form the
overall surface via a set of blending
functions, which is also referred to as the
partition-of-unity (POU) method. The
reconstruction algorithm first partitions the
input point set by octree subdivision and
surface normal estimation is performed so
as to orientate the local variational implicit
patches. A new graph optimization scheme
based on the belief propagation framework
is proposed to determine the global
consistent orientation for the entire set of
data points. To achieve multi-scale
reconstruction, we propose a novel
progressive reconstruction algorithm which
utilizes the Schur complement formula to
reduce the computational cost of iteratively
updating the radial basis function
coefficients.
As we have mentioned earlier in this section,
the proposed algorithm is a POU-based
implicit surface algorithm. The notion of
Multi-Level Partition of Unity implicits
(MPU) is firstly introduced by Ohtake et al
[Y. Ohtake et al., 2003]. Briefly speaking,
the implicit surface to be modeled is
described by a scalar valued function f,
which is blended by a set of local shape
functions fi by the following equation.
,
)(
)()(
)( 

i i
i ii
f
f
x
xx
x 

(4.1)
where iare a set of weighting functions. To
correctly blend the local shape functions,
they should have been properly and
consistently oriented in advance. Unlike the
previous methods, we do not assume any
orientation information, e.g. surface normals
are available. Instead, we perform PCA on
local neighborhood of a point to estimate its
normal vectors. However, we are uncertain
of which part of the model these estimated
normal vectors are directed to, say, inside or
outside. We treat this problem as a graph
labeling problem and apply the Belief
Propagation algorithm to infer a maximum a
posteriori (MAP) solution for the global
consistent orientation.
Consider the following energy function E(X)
defined on a local graph G = {V, E} with
each node in V corresponding to one of the
3D points:



Eji
jis
Vi
id xxExEXE
),(
),,()()( (4.2)
where
,)( iid xxE  (4.3)
ij
xx
jis
jixxE   )(1),( (4.4)
Note that Ed(xi) is the data energy measuring
how well the estimated labels fits to our
prior knowledge about the model.
Intuitively, the consistency of two normal
vectors can be defined as their inner product,
which is positive if they have consistent
orientations and negative otherwise. By
letting jiij nn  , ),( jis xxE behaves like
a smooth energy which penalizes the
inconsistent changes of normal orientations
associated with two neighboring nodes.
With a label }1,0{ix corresponding to
outside and inside of the model, the label
assignment X which minimizes E(X)
determines the global consistent orientation.
The Belief Propagation, which is an
The BP orientation inference timings are
also included. Figure 4.1 demonstrates an
example of multi-scale reconstruction
from real-world data sets. Figure 4.2
illustrates an example of coarse-to-fine
reconstruction using the proposed
progressive reconstruction algorithm.
Figure 4.3. Examples of reconstructed implicit surfaces
by the proposed algorithm.
All of the examples presented in the report
are generated on a standard PC with
Pentium 4 3.4 GHz CPU and 1 GB RAM.
In addition,we use Bloomenthal’s implicit 
surface polygonizer [J. Bloomenthal, 1994]
to extract a triangular mesh of the
reconstructed implicit surface for
visualization. Many of the subproblems
discussed above require extensive
searching for the nearest neighbors of a
specific data point, such as local tangent
plane fitting and Riemannian graph
construction. We apply a spatial
partitioning technique, say, k-D tree for
solving the range searching problem more
efficiently. The input data set is scaled and
inserted into a unit bounding cube. Then,
an octree-based hierarchy is constructed
and local variational implicits are
computed and refined until a desired
accuracy is achieved. We use a B-spline
based weighting function as suggested in
[Y. Ohtake et al., 2003] for
partition-of-unity blending. The blended
function can be evaluated at different
levels for multi-scale reconstruction.
Figure 4.3 illustrates the capability of the
proposed algorithm to reconstruct implicit
surfaces from real-world data sets
accurately and efficiently.
5. References
[K. Levenberg, 1944] K. Levenberg, “A method for the
solution of certain non-linear problems in least squares”,
Quarterly of Applied Mathematics, 2(2):164–168, Jul.
1944.
[J. Bloomenthal, 1994] J. Bloomenthal,“An implicit 
surface polygonizer”, Graphics Gems IV, pages 324–349,
1994.
[P. R. S. Mendonca and R. Cipolla, 1999] P. R. S.
Mendonca and R. Cipolla, “Estimation of Epipolar
Geometry from Apparent Contours: Affine and Circular
Motion Cases”, In Proc. Computer Vision and Pattern
Recognition, 9-14, 1999.
[P. R. S. Mendonca et al., 2001] P. R. S. Mendonca,
K.-Y. K. Wong, and R. Cipolla, “Epipolar Geometry
from Profiles under Circular Motion”, IEEE Trans. on
Pattern Analysis Machine Intelligence, 23(6):604-616,
2001.
[Y. Ohtake et al., 2003] Y. Ohtake, A. Belyaev, M.
Alexa, G. Turk, and H.-P. Seidel, “Multi-level partition
of unity implicits,”In Proceedings of ACM SIGGRAPH,
pages 463–470, July 2003.
[S.-F. Wang and S.-H. Lai, 2006] S.-F. Wang and S.-H.
Lai, “Efficient 3D face reconstruction from a single 2D
Image by combining statistical and geometrical
information”, In Proc. Asian Conference on Computer
Vision, (2): 427-436, 2006
[Y.-L. Chen and S.-H. Lai, 2007] Y.-L. Chen and S.-H.
Lai, “A Partition-of-Unity Based Algorithm for Implicit
Surface Reconstruction Using Belief Propagation”, To be
appeared in Shape Modeling International, Lyon, France,
2007.
