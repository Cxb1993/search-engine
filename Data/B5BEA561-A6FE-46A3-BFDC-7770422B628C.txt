 應用具有嵌入式主動視覺無線網路系統於自走車之研究(2/2) 
計畫編號：NSC-96-2221-E-032-012-MY2 
執行期間：97 年 8 月 1 日至 98 年 7 月 31 日 
主   持   人：黃志良   淡江大學電機工程學系 
計畫參與人員：許庭嘉、傅建鈞、李昇遠  淡江大學電機工程學系 
 
 
中文摘要 
本計畫乃是應用主動嵌入式視覺系統(Active 
Embedded Vision System (AEVS))及差速機器人
(Differential Mobile Robot(DMR))來實現分佈的主
動嵌入視覺網路系統中差速機器人包括折線軌跡追蹤
及躲避障礙之導引。所應用的AEVS包括數位訊號處理
器(TMS320DM642EVM)及具高速迴轉台之攝影機(Speed 
Dome)。而DMR包括兩組直流馬達、一個微處理器
TMS320F2812、一個驅動電路和一個無線模組，其具
有零迴轉半徑，更適合於折線軌跡追蹤。由於
TMS320DM642內定的彩色影像輸出格式為YCrCb，故將
紅色和矩形特徵貼於DMR上，而藍色和圓形特徵貼於
障礙物上，以利於其辨識及定位。接著由迴轉台所捕
捉到的影像訊號輸入到TMS320DM642，以進行如下的
影像處理：分割紅色或藍色、二值化、以中值濾波器
去除雜訊、計算面積、求中心位置的座標，然後以多
層感知器類神經網路建立影像平面座標與世界座標的
轉 換 。 所 謂 的 分 佈 的 AEVS (Distributed 
AEVS(DAVES))，即是應用至少兩組AVES於適當的位置
監控相關空間內的DMR，並追蹤因建築物限制所規劃
的折線軌跡及躲避相關障礙，以解決典型的輪型機器
人所遭遇的定位、軌跡追蹤及躲避障礙之問題。一般
的分佈式視覺系統都是固定的，它們監控區域是有限
的，如果要增加監控的區域則須要增加攝影機的數
量，如此一來，會導致系統更加地複雜。雖然全方位
的視覺系統可觀看360度的區域，由於其具有很大影
像失真，它的影像處理須要消耗大量的計算時間和它
的估測(或校正)誤差亦很大。因此我們將應用模糊可
變 結 構 控 制 (Fuzzy Decentralized Variable 
Structure Control (FDVSC))，驅動AEVS以鎖住運動
中的DMR，並以FDVSC操控DMR進行折線軌跡追蹤及躲
避障礙。最後以相關實驗，驗證所建議系統的優越性
及有效性。 
關鍵詞：分佈式的主動嵌入視覺網路空間、差速機器
人、導航、折線軌跡追蹤及躲避障礙、模糊可變結構
控制、多處理器控制系統。 
 
Abstract --- The trajectory tracking and obstacle 
avoidance of a differential mobile robot (DMR) in a 
distributed active embedded vision system (DAEVS) is 
developed. The proposed active embedded vision system 
(AEVS) includes the digital signal processor (DSP) and 
the speed dome with the vision of high-speed feature. 
For the purpose of easy recognition and localization of 
DMR and obstacle, the red and rectangular shape and the 
blue and circle shape are respectively placed on the top 
of the DMR and the obstacle. In the beginning, the visual 
information coming from the speed dome is transferred 
to the DSP to execute the corresponding image 
processing: the segmentation of red or blue component, 
the binary processing, the removal of noise by median 
filter and shape feature, and the calculation of the area 
and central position of image feature. Because the task is 
planned in the world coordinate and because the relation 
between the image plane coordinate and the world 
coordinate is highly nonlinear, a multilayer neural 
network (MNN) is employed to establish the relation 
between them. From the viewpoint of the constraint of 
house architecture, the energy consumption of DMR, and 
the ease of path planning, a desired trajectory made up 
by a set of piecewise lines is addressed. Simultaneously, 
three trajectory tracking modes: approach mode, fine-
tune mode, and inertia-navigation mode, are designed to 
obtain a fast trajectory tracking with the energy saving 
manner. Finally, the corresponding experiments of the 
trajectory tracking and obstacle avoidance for a DMR in 
the DAEVS confirm the validity and efficiency of the 
proposed methodology. 
Keywords: Distributed active embedded vision system, 
Differential mobile robot, Navigation, Trajectory 
tracking, Obstacle avoidance, Fuzzy decentralized 
variable structure control.  
 
I. Introduction 
 Recently, distributed control within sensor networks 
has received wide attention in many engineering 
applications. Some representative works may be found in 
[1]-[9]. The distributed network-space system can 
monitor the occurrence within itself, build its own 
models, communicate with its inhabitants, and act on the 
decisions made by itself. For instance, a mobile robot is 
designed to track a trajectory, which is often made up by 
a set of piecewise lines from the viewpoint of the 
constraint of house architecture, the energy consumption 
of mobile robot, and the ease of path planning [9]. 
Simultaneously, the obstacle avoidance is accomplished. 
In addition, many problems encountered in classic 
mobile robots (e.g., localization [10], [11], high 
computational power [12], [13], different software for 
different kinds of mobile robot [14], interference 
between sensors [15]) may be resolved when they are 
cast into a distributed vision system.  
   On the other hand, almost all distributed visions are 
fixed. Therefore the visible region is limited or the 
number of visions must be increased when the monitored 
area is increased ([2]-[5]). Although the omni-directional 
vision system (ODVS) possesses a 360D view angle, its 
image processing is time-consuming and the estimation 
error (or modeling error) is large owing to the image 
 format NTSC, power consumption 13W, minimum 
illumination 0.3Lux, horizontal resolution 480 TV lines, 
and signal/noise over 50dB. It is also known that the 
bandwidths of the proposed AEVS1 and 2 are much 
larger than that of the DMR. In brief, the first difference 
as compared with the previous studies (e.g., [8], [9]) is 
an active embedded vision system, possessing portable, 
computational, and wireless features are more suitable 
for the distributed sensor network system.  
Two rectangular landmarks with red color and 
different size are used on the DMR (see Fig. 2). The 
microprocessor in DMR is the TMS320F2812 from TI 
Co. with the following important specifications: two 
event managers (i.e., EVA and EVB), series 
communication interface (SCI), series periphery 
interface (SPI), enhanced control array network (eCAN), 
multi-channel buffer series peripheral (McBSP), analog 
to digital conversion (ADC), 128KB Flash memory, 
18KB SARAM, and 150MHz clock speed [21]. It is 
known that almost no minimum turning radius for a 
DMR occurs [11]. The trajectory tracking for a set of 
piecewise-lines with (or without) obstacle avoidance is 
much better than that of the CLMR. This feature will be 
confirmed by the experiments. This is the second 
difference as compared with our previous study [9]. 
 
 
Fig. 2. Photograph of the DMR with two rectangular 
landmarks of red color and different size. 
 
Table 1. The specifications of DMR. 
Specification Quantity 
Length 320 mm 
Width 280 mm 
Height 200mm 
Weight 4.9kg 
Radius of Wheel 125 mm  
Distance Between Wheels 240 mm 
2.2 Research Task 
In the beginning, two DC servo motors for the left 
and right wheels are controlled by individual fuzzy 
variable structure (FVSC). Hence, the proposed control 
is called fuzzy decentralized variable structure control 
(FDVSC). The details can be found from the previous 
papers, e.g., [9]. As one knows, the manipulation of a 
DMR is different from that of a CLMR. Hence, an 
effective operation of a DMR will be introduced to 
obtain the desired task. In addition, the strategy for the 
navigation of a DMR to the trajectory of piecewise-lines 
includes the following three modes: (1) approach mode, 
(2) fine-tune mode, (3) inertia-navigation mode. This is 
the third difference as compared with the previous 
papers. Similarly, two sets of FDVSCs for the AEVS1 
and 2 can be effectively implemented to lock the DMR 
into the center of visual window once it is inside of 
visual window.  
 The main goal of this project is to investigate the 
trajectory tracking with (or without) obstacle avoidance 
using three sets FDVSCs for a DMR in a DAEVS with 
two AEVSs. The experiment is performed for four cases: 
(i) with initial lock of the DMR in the DAEVS, the 
trajectory tracking of a set of piecewise-lines with the 
reference command of translation velocity 35cm/s; (ii) 
the requirement of a search to lock the DMR for the same 
trajectory of part (i); (iii) the tracking of the same 
trajectory of part (i) with one or two static obstacles; and 
(iv) the same experiment of part (iii) with different 
lighting condition.  
 
III. Image Processing and Neural Network 
Modeling 
3.1 Image Processing 
    The background of the DAEVS (i.e., the ground in 
Fig. 3(a) contains similar size pattern as compared with 
DMR, some lines in the ground, and non-uniform 
illumination) is difficult to deal with [22]-[24]. The 
following six-step procedure shows how to obtain the 
position error of the DMR with respect to the image 
center. The position error is then used to lock the image 
of the DMR into the center of the lens such that the 
distortion of lens is reduced [25]. 
 A. Image acquisition 
    The speed dome is the vision sensor to obtain the 
information of color image which is then transmitted to 
the DSP-TMS320DM642 having 720 480× pixels. To 
increase the processing speed, the grabbed color image is 
compressed into 360 240× pixels. Because the default 
format of the TMS320DM642 is  4 : 2 : 2,r bYC C where Y 
represents the luminance component, and rC , bC are 
respectively chrominance components of red and blue, 
no conversion of color space is required. 
B. Image segmentation 
    Since the value of Y is strongly dependent on the 
luminance, it will not be considered in this project. The 
ranges of the rC and bC for the DMR and the obstacle 
are different. Together with the shape feature (i.e., 
rectangle and circle), the process of the image 
segmentation is more robust in distinguishing the DMR 
and the obstacle from the ground.  
 
 
(a) Source image. 
 After the aforementioned preprocessing (i.e., parts 
A~D), there may be some white salts or black peppers 
and disconnections of edge. In this case, the image 
reconstruction using median filter is employed to 
eliminate the disturbances caused by preprocessing (see 
Figs. 3(c) and (e)).  
 F. Image representation and description  
The area, center, and coordinate of image features 
are considered to represent the posture of the DMR on 
the image plane coordinate. For digital image, their 2D 
moments of order p+q and centered moments are defined 
as follows [22]-[23], [25]:  
∑ ∑= x yI I yxqypxpq IIfIIm ),(        (3) ( ) ( )∑ ∑ −−=
x yI I yx
q
yy
p
xxpq IIfIIII ),(μ      (4) 
where ),( yx IIf is the same as (1), ,0, ≥qp  and 
∑∑∑∑
∈∈
==
ΩΩ ),(),(
  ,
yxyx II
yy
II
xx NIINII denotes the center 
of the area N of the desired image feature .Ω  The areas 
and centers of the image features 1 and 2 in Fig. 5 can be 
calculated by (3) and (4) respectively. The central 
position ( )RyRx II ,  and orientation Iθ (i.e., posture) of 
the DMR on the image plane can then be computed as  
( ) ( ) ( ){ }1 1 2 2, , , 2,Rx Ry Rx Ry Rx RyI I I I I I= +  
( ) ( ){ }1 2 1 2 1tanI Ry Ry Rx RxI I I Iθ −= − − .     (5) 
In this project, the height of the obstacle is assumed to be 
the same as that of the DMR. Then, the centers and areas 
of obstacles can be estimated using the same learned 
weight and bias values for the DMR.  
1 1( , )Rx RyI I
2 2( , )Rx RyI I
,( )Rx RyI I
xI
yI
Iθ
 
 
Fig. 5. Illustration of the image features and 
calculation of the posture of the DMR on the image plane. 
 
3.2 Neural Network Modeling 
Generally, a homogeneous coordinate is employed to 
establish a camera model; however, this method needs 
accurate calibration and is therefore impractical. In 
addition, different mechanisms for driving the pan and 
tilt motion will result in different kinematic and dynamic 
relationships. Under these circumstances, an effective 
method using multilayer neural network (MNN) is 
applied to model the relation between the world 
coordinate and the image plane coordinate. From Fig. 6, 
different visible areas are obtained for different angles of 
the tilt and pan motion; e.g., the area denoted by the 
dash-dot line is for 0 , 45 ,x yθ θ= =D D and the area denoted 
by the solid line is for 22.5 ,xθ = − D 37.5 .yθ = D We note 
that these relations are highly nonlinear [18], [19], [22]-
[25]. This motivates the use of MNN for modeling. The 
advantage of this method is that a camera model and the 
kinematic and dynamic relations of mechanism are not 
required.  
 
2
xI
2
iO
1
iO
1
xI
1
yI
WY
WX
2
yI
 
Fig. 6. Modeling between the image plane coordinate 
and the world coordinate. 
B. Multilayer neural network   
    A three-layer MNN, including input-layer, hidden-
layer, and output-layer, is depicted in Fig. 8. The inputs 
of the MNN are the angles of the pan-tilt platform and 
the position of the DMR on the image plane coordinate 
respectively given as , , ,x y RxIθ θ and RyI .The outputs are 
the position of the DMR on the world coordinate given 
as and Rw RwX Y . To avoid the complexity of the MNN, the 
orientation of the DMR is not set as its output. It is 
indirectly calculated by (4) because the orientation is 
only used for the navigation of direction. The following 
“cost” is assigned for deriving the learning law: 
   2 2
1
( ) 2k kk d yε == −∑        (6) 
where kd is the desired output (or target), and ky is the 
output of MNN. Figure 7 shows the concept for the 
different postures of the DMR monitored by the same 
angles of AEVS1 or 2 (e.g., the area enclosed by the 
solid line). The data in this region should have the 
representative relationship between the world coordinate 
and the image plane coordinate. Similarly, the data for 
different postures of the AEVS1 or 2 are obtained. After 
using ( ){ }( ), ( ) ,i kx n y n  where ,2,1,4,3,2,1 == ki and 
,,..,2,1 Mn = with M being the total pair of data, these 
  
(b) 
 
(c) 
 
(d) 
Fig. 11. Model verification of MNN. 
 
VI. Manipulation of DMR 
The manipulation of a DMR is different from that of 
a CLMR (e.g., [8], [9], [15], [20]), which can control the 
orientation by its front wheel and the translation velocity 
by its rear wheel. Therefore, the manipulation of a DMR 
must be considered. In the beginning, the kinematics of a 
DMR is described as follows:  
( ) ( ) cos( ), ( ) ( )sin( ), ( ) ( )x t v t y t v t t tθ θ θ ω= = =     (7) 
[ ] [ ]( ) ( ) ( ) 2, ( ) ( ) ( )r l r lv t t t r t t t r dω ω ω ω ω= + = − (8) 
where ( ) and ( )t tθ ω respectively denote the angular 
position and angular velocity with respect to z-
axis, ( ) and ( )r lt tω ω are respectively the angular 
velocities of the right and left wheels, r is the radius of 
the wheel, d  is the distance between two wheels. It is 
assumed that ( ) and ( )r lt tω ω are approximately constant 
in the sampling interval 1k kt t tΔ −= − . Then the position 
and orientation of a DMR are described as follows: 
1( ) ( ) ( ) cos( ( ) ( ))
        sin( ( )) ( )
k k k k k
k k
x t x t v t t t t
t t
Δ θ Δθ
Δθ Δθ
−= + +
⋅       (9) 
1( ) ( ) ( ) sin( ( ) ( ))
         sin( ( )) ( )
k k k k k
k k
y t y t v t t t t
t t
Δ θ Δθ
Δθ Δθ
−= + +
⋅      (10) 
 1( ) ( ) ( )k k kt t t tθ θ ω Δ−= +                  (11) 
where 
 ( ) ( ) 2k kt t tΔθ ω Δ=
 
[ ]
[ ]
( ) ( ) ( ) 2,
( ) ( ) ( )
k r k l k
k r k l k
v t t q t q t r
t t q t q t r d
Δ Δ Δ
ω Δ Δ Δ
= +
= −          (12) 
where ( ) and ( )r k l kq t q tΔ Δ are respectively denoted as the 
angular positions of the right and left wheels for the time 
interval .tΔ Based on the requirement of task, the 
corresponding path can be planned by ( )d ktθ and ( ),d kv t  
which respectively represent the desired angular position 
and translation velocity at the sampling time .kt Then the 
corresponding angular velocity can be expressed as 
[ ]1( ) ( ) ( ) .d k d k kt t t tω θ θ Δ−= − Finally, the desired angular 
velocities of the right and left wheels are respectively 
derived as follows:  
( )
( )
,
,
( ) 2 ( ) ( ) 2
( ) 2 ( ) ( ) 2 .
r d k d k d k
l d k d k d k
t v t t d r
t v t t d r
ω ω
ω ω
= +⎡ ⎤⎣ ⎦
= −⎡ ⎤⎣ ⎦
         (13) 
In summary, according to the assigned task two 
corresponding desired angular velocities of the right and 
left wheels are obtained. Then the fuzzy decentralized 
variable structure control (e.g., [8], [9]) is applied to 
make the angular velocities of the right and left wheels 
track the desired values. 
    Due to the feature of house architecture, the 
consumption of energy and the ease of path planning, a 
set of trajectory of piecewise-lines is applied for the path 
planning. The strategy for tracking the trajectory of 
piecewise-lines includes the following three modes (see 
Fig. 12): (i) approach mode, (ii) fine-tune mode, and (iii) 
inertia-navigation mode. As the DMR is in the approach 
mode (e.g., 1( ) ,ke t e> where 1 20e cm= ), the strategy 
forces the DMR to approach the desired trajectory as fast 
as it can. It implies that in this mode the quantity of 
trajectory tracking is more important as compared with 
the quality of that. As the DMR is in the fine-tune mode 
(e.g., 1 2( ) ,ke e t e≥ > where 2 7.5e cm= ), the strategy 
adjusts the motion of the DMR to approach the desired 
trajectory as close as it can. The detail of the fine-tune 
mode is shown in Fig. 13. The DMR first turns an 
angle ( ),d ktθ travels with a desired translation velocity for 
the time interval [ ]( ) ( ) sin( ( )) ,k d k d ke t v t tΔτ θ= then 
turns a negative value of the original angle, i.e., 
( ).d ktθ− It indicates that the quality of trajectory tracking 
is most important in this mode. As the DMR is in the 
inertia-navigation mode (e.g., 2( )ke t e≤ ), the strategy 
 in the periphery of the DAEVS, exhibiting poor quality 
for posture estimation [22], [23], [25], the performance 
shown in Figs. 14~21 confirm the superiority of the 
control system. The limitation of the DMR’s translation 
velocity is determined by the bandwidth and window 
size of AEVS1 or 2, the image processing time, and the 
computation time of the FDVSC. Based on a similar 
analysis of [22], the upper bound of the DMR’s 
translation velocity in the vertical optical axis of the 
AEVS 1 or 2 is approximately estimated as 6.4 m/s, 
which is much greater than the translation velocity 
35cm/s. Hence, there is no worry for the escape of the 
DMR from the field of view of the AEVS 1 or 2 once it 
is locked (or tracked). If the height of the landmarks for 
the DMR and the obstacle is much different, the output 
of the MNN model becomes three dimensions, i.e., 
( , , ).Rw Rw RwX Y Z  If the monitoring region increases, the 
number of AEVS should increase. That is, the setting 
here can be easily extended to more than two AEVSs.  
 
 
Fig. 14. Response of the DMR with an initial lock. 
 
Fig. 15. Response of the DMR with an initial lock but 
different initial posture of the DMR. 
 
Fig. 16. Response of the DMR with an initial unlock. 
 
 
Fig. 17. Response of the DMR with an initial unlock  
and different initial posture as compared with Figure 16. 
 
 
Fig. 18. Response of Figure 15 case with one obstacle. 
 
Obstacle 
 [7]  V. Lippiello, B. Siciliano and L. Villani, “Position-
based visual servoing in industrial multirobot cells 
using a hybrid cameras configuration,” IEEE Trans. 
Robotics, vol. 25, no. 1, pp. 73-86, Feb. 2007.  
[8]  C. L. Hwang and N. W. Chang, “Fuzzy 
decentralized sliding-mode control of car-like 
mobile robots in a distributed sensor-network 
space,” IEEE Trans.   Fuzzy Syst., vol. 16, no. 1, 
pp. 97-109, Feb. 2008. 
[9]  C. L. Hwang and C. Y. Shih, “A distributed active 
vision network-space approach for trajectory 
tracking and obstacle avoidance of a wheeled 
robot,” IEEE Trans. Ind. Electronics, vol. 56, no. 3, 
pp. 846-855, Mar. 2009. 
[10] D. Lee and W. Chang, “Discrete-stature-based 
localization for indoor service robots,” IEEE Trans. 
Ind. Electron., vol. 53, no. 5, pp. 1737-1746, Oct. 
2006. 
[11] S. Han. H. S. Lim and J. M. Lee, “An efficient 
localizations scheme for a differential-driving 
mobile robot based on RFID system,” IEEE Trans. 
Ind. Electron., vol. 54, no. 6, pp. 3362-3369, Dec. 
2007. 
[12] S. Se, D. G. Lowe and J. J. Little, “Vision-based 
global localization and mapping for mobile robots,” 
IEEE Trans. Robot. & Automat., vol. 21, no. 3, pp. 
364-375, Jun. 2005. 
[13] D. Xu, L. Han, M. Tan and Y. F. Li, “Ceiling-based 
visual positioning for an indoor mobile robot with 
monocular vision” IEEE Trans. Ind. Electron., vol. 
56, no. 5, pp. 1617-1628, May 2009. 
[14] J. Minguez and L. Montano, “Nearness diagram 
(ND) navigation: collision avoidance in 
troublesome scenarios,” IEEE Trans. Robot. & 
Automat., vol. 20, no. 1, pp. 45-59, Jan. 2004. 
[15] T. H. S. Li, S. J. Chang, “Fuzzy target tracking 
control of autonomous mobile robots by using 
infrared sensors,” IEEE Trans. Fuzzy Syst., vol. 12, 
no. 4, pp. 491-501, Aug. 2004. 
[16] A. A. Argyros, D. P. Tsakiris and C. Groyer, 
“Biomimetric centering behavior --- Mobile robots 
with panoramic sensors,” IEEE Robotics & Automat. 
Mag., pp. 21-31, Dec. 2004. 
[17] E. Menegatti, A. Pretto, A. Scarpa, and E. Pagello, 
“Omni-directional vision scan matching for robot 
localization in dynamic environments,” IEEE Trans. 
Robotics, vol. 22, no. 3, pp. 523-535, Jun. 2006. 
[18] K. T. Song and J. C. Tai, “Dynamic calibration of 
pan-tilt-zoom cameras for traffic monitoring,” IEEE 
Trans. Syst. Man & Cybern., Pt. B, vol. 36, no. 5, pp. 
1091-1103, Oct. 2006. 
[19] Y. Motai and A. Kosaka, “Hand-eye calibration 
applied to viewpoint selection for robotic vision,” 
Trans. Ind. Electron., vol. 55, no. 10, pp. 3731-3741, 
Oct. 2008. 
[20] I. Baturone, F. J. Moreno-Velo, V. Blanco and J. 
Fervuz, “Design of embedded DSP-based fuzzy 
controllers for autonomous mobile robots,” IEEE 
Trans. Ind. Electron., vol. 55, no. 2, pp. 928-936, 
Feb. 2007. 
[21] Y. S. Kung, “Design and implementation of a high-
performance PMLSM drives using DSP chip,” 
IEEE Trans. Ind. Electronics, vol. 55, no. 3, pp. 
1341-1351, Mar. 2008. 
[22] P. Vadakkepat, P. Lim, L. C. De Silva, L. Jing and 
L. L. Ling, “Multimodal approach to human-face 
detection and tracking,” IEEE Trans. Ind. Electron., 
vol. 55, no. 3, pp. 1385-1393, Mar. 2008. 
[23] D. Xu, Y. F. Li, M. Tan and Y. Shen, “A new active 
visual for humanoid robots,” IEEE Trans. Syst. Man 
& Cyber., Part B, vol. 38, no. 2, pp. 320-330, Apr. 
2008.  
[24] Y. Hu, W. Zhao and L. Wang, “Vision-based target 
tracking and collision avoidance for two 
autonomous fish,” IEEE Trans. Ind. Electronics, 
vol. 56, no. 5, pp. 1401-1410, May 2009. 
[25] Y. Han, “Imitation of human-eye motion --- how to 
fix gaze of an active vision system,” IEEE Trans. 
Syst. Mans & Cybern., Part A., vol. 37, no. 6, pp. 
854-863, Nov. 2007. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
-22.5 7.5 -60 80 -61.931 91.318 
-22.5 7.5 -60 60 -59.624 52.155 
-22.5 7.5 -60 40 -59.389 36.041 
-22.5 7.5 -60 20 -61.077 15.372 
-22.5 7.5 -60 0 -62.926 -0.928 
-22.5 22.5 20 80 18.66 79.59 
-22.5 22.5 20 100 17.363 100.086 
-22.5 22.5 20 120 17.63 124.069 
-22.5 22.5 20 140 20.531 139.812 
-22.5 22.5 20 160 22.284 161.066 
-22.5 22.5 0 160 -2.133 160.424 
-22.5 22.5 0 140 -0.592 141.169 
-22.5 22.5 0 120 1.82 120.659 
-45 30 -140 140 -141.885 137.213 
-45 30 -140 120 -140.097 124.037 
-45 30 -140 100 -140.493 99.897 
-45 30 -140 80 -139.935 82.974 
-45 30 -140 60 -139.848 58.78 
-45 30 -160 80 -162.556 77.788 
-45 30 -160 100 -160.855 96.291 
-45 30 -160 120 -160.475 118.97 
-45 30 -140 140 -141.885 137.213 
-45 30 -140 120 -140.097 124.037 
-45 45 -140 220 -137.283 218.523 
-45 45 -140 200 -138.435 201.493 
-45 45 -140 180 -137.646 179.898 
-45 45 -140 160 -139.968 161.624 
-45 45 -140 140 -139.206 141.39 
  
 
 
 
 
 
 
 
45 22.5 -60 620 -59.652 619.313 
45 22.5 -60 600 -60.586 600.593 
0 30 20 480 19.361 480.556 
0 30 20 460 21.524 460.062 
0 30 20 440 19.149 439.147 
0 30 0 440 2.873 440.528 
0 30 0 460 0.835 459.506 
0 30 0 480 0.979 481.154 
45 30 -80 500 -80.929 498.24 
45 30 -80 520 -79.728 518.766 
45 30 -80 540 -80.109 538.809 
45 30 -80 560 -81.288 559.592 
45 30 -80 580 -81.333 579.211 
45 30 -80 600 -79.335 600.292 
0 37.5 0 480 -0.034 479.775 
0 37.5 0 500 -0.372 498.834 
0 37.5 0 520 -1.669 520.919 
0 37.5 -20 520 -19.798 520.669 
0 37.5 -20 500 -18.806 499.697 
0 37.5 -20 480 -20.383 479.524 
45 37.5 -100 440 -99.855 440.989 
45 37.5 -120 420 -119.151 422.843 
45 37.5 -120 440 -120.155 439.748 
45 37.5 -120 460 -118.517 459.175 
45 37.5 -120 480 -119.204 480.068 
45 37.5 -120 500 -119.107 497.513 
0 45 0 440 1.169 443.323 
0 45 0 460 0.304 460.289 
0 45 0 480 0.635 482.687 
 66
出席 2008 年世界國會計算智慧會議(IEEE-WCCI2008) 
心得報告 
 
報告人：淡江大學 電機工程學系 黃  志  良 
 
一. 參加會議經過 
 
2008 年世界國會計算智慧會議(IEEE-WCCI2008)於中國香港召開，會議日
期是從 6 月 1 日至 6 月 6 日止，共計六天。此次會議共有 548 篇論文投稿，每
一篇論文均經過三位評審審查，通過率約 69%，亦即約 376 篇論文在此次會議
發表，此次筆者所參與的會議場為模糊控制及系統。除了進行分組論文口頭及
壁報發表外，大會現場並有相關書籍展示、產品展覽、及提供電子郵件服務。
此次會議來自世界各國，約數百位專家學者參與，其中來自我國之與會人員約
二十位，分別來自學術界、研究機構等。筆者亦在會中發表兩篇論文“(1)應
用模糊混合 HH2 最佳化設計分散控制於非線性連結動態延遲系統，(2) 應用
模糊滑動輸入少於輸出的控制於具有自主動態平衡之電動腳踏車。並與多位同
領域的學者討論，使筆者獲益良多。 
 
 
二. 與會心得 
 
此次會議是一個大型的會議，主辦單位事先已將大會手冊預先寄給作者參
考，且大會亦於事前透過網際網路將每位作者之論文發表時間告知，因此，筆
者有相當充裕的時間安排所欲聆聽之論文發表。 
筆者有幸獲得國科會之補助，前往中國香港參加 2008 年世界國會計算智慧
會議(IEEE-WCCI2008)並發表論文，使筆者在各方面均有相當豐富之收穫。筆
者近年來一直致力於非線性系統控制、強健適應控制、模糊類神經控制和建模
及智慧型機器人之研究，因此與會期間，筆者曾就非線性系統控制、適應控制、
及模糊控制等方面與與會之學者專家分享研究心得與經驗。並利用彼此討論機
會和與會之學者專家建立友誼關係。 
大會總共安排有口頭發表以及壁報論文，分為四個分組並行進行論文發
表，每個人均可參加有興趣或較相近領域之論文發表。其中與筆者近年的研究
較為相關的有如下之主題：(1) 非線性系統控制，（2）模糊控制器設計，（3）
類神經控制及建模，(4）機器人控制，(5）適應控制系統。主講者對於未來的
研究方向皆有詳細且完整的介紹，也有諸多建設性的建議及意見。 
 
 
 
 
 
 
