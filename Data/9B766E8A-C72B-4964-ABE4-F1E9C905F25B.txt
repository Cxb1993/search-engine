行政院國家科學委員會補助專題研究計畫成果報告 
作用於三維未知曲面之機械手臂智慧型感測與控制(I) 
 
計劃編號： NSC  95－2221－E－027－049 
執行期限：95 年 8 月 1 日至 96 年 7 月 31 日 
計畫主持人：張文中 國立臺北科技大學電機系(所) 
計畫參與人員：卓之威 蔡柏賢 曹太嘉 洪亦陽 國立臺北科技大學電機系(所) 
 
摘要 
傳統以視覺為基礎的力與姿態追
蹤控制中，通常需要使用昂貴的六軸
力量感測器搭配視覺感測器才能完成
在未知曲面上的控制。其主要原因在
於其需要利用六軸力量感測器來量測
出三維未知曲面的法向量。因此，本
計畫的主要目的為利用新型的系統架
構以在能完成同樣任務的情況下，最
大化的減少系統的需求已減低成本。
本計畫中分別提出了兩種新的架構，
其中第一種架構為利用單眼視覺與雷
射十字結構光來完成三維未知曲面的
法向量重建。第二種架構則為搭配雙
眼視覺與雷射十字結構光來完成。其
主要估測三維未知曲面的法向量的方
法為利用視覺系統觀測投影到未知曲
面上的十字結構光的變化來達成。本
計畫以提出之兩種系統架構分別實驗
於一未知三維曲面來驗證理論並更進
一步的搭配一台機械手臂以其姿態控
制來驗證系統的正確性。由實驗結果
可知本計劃可成功的正確估計出三維
未知曲面的法向量並成功的控制機械
手臂達成於三維未知曲面定位的任
務。 
 
關鍵詞： 單眼視覺，雙眼視覺，三維
未知曲面，姿態控制，視覺伺服。 
Abstract 
  Classical force and vision-based 
tracking control approaches typically 
require expensive six-axis force sensors 
in addition to vision sensors.  Since the 
system needs to estimate the direction 
normal to an unknown 3-D surface by 
the six-axis force sensors.  In this 
article, two new approaches are 
presented to estimate the direction 
normal to an unknown 3-D surface, the 
first approach only requires a CCD 
cameras and a laser cross projector and 
the second approach requires two CCD 
cameras and a laser cross projector.   
The key idea is to estimate the direction 
normal to an unknown 3-D surface by 
projecting and reconstructing a laser 
cross on it.  The proposed autonomous 
task is to drive the end-effector of a 
6-DOF manipulator to a visually 
determined position in desired pose for 
verify the proposed approaches.  The 
proposed approaches are successfully 
validated in a real task environment by 
performing experiments with an 
industrial robotic manipulator on an 
 2
他感測器資訊，以對三維未知曲面進
行估計與姿態的定位控制。具體而
言，可能採用之感測器架構有兩種，
其一為單眼攝影機搭配雷射結構光，
另一種架構則為雙眼攝影機搭配雷射
結構光。此兩種架構之系統皆由一台
機械手臂、雷射結構光、攝影機、未
知曲面和個人電腦所組成。攝影機獲
取之視覺資料經由一台個人電腦快速
處理，即時推算三維未知曲面的法線
向量，分別如圖一、二所示。兩系統
因為架構上的不同，因此再設計理論
時也需要設計各別相對應之估計三維
位之曲面理論與其控制任務編碼。 
 
圖一 眼看手系統架構 
 
圖二 眼在手系統架構 
本研究目的是採用單眼視覺與雙
眼視覺搭配雷射結構光來估計未知曲
面的法線向量，在未知曲面進行法線
向量估計，利用單眼視覺由於在單張
影像中，無法進行深度估測，因此，
利用雷射結構光投射出的標記，投影
在未知曲面上時，會造成標記的扭曲
變化，利用此標記在影像上的變化，
推算三度空間未知曲面的法線向量。
雙眼視覺是當雷射結構光投射在未知
曲面上的雷射線段在三度空間中逐點
的被重建出來後，就可以利用最小平
方誤差法將通過這些點的兩條在三度
空間中的曲線方程式求出，接著利用
線段方程式將通過十字雷射中心的兩
條切線向量求出及就可以得到未知曲
面的法線向量。在求得未知曲面的法
線向量在配合力量感測器來進行機械
手臂的姿態與力量控制。當我們要對
一個未知曲面完成高自由度的接觸任
務時，只需要使用低自由度的力量感
測器即可完成。 
Laser projector 
Unknown 3D surface 
Robot 
Cameras 
 
3. 十字雷射偵測 
十字雷射的偵測在本研究中是十
分重要的。假使偵測的結果不如預
期，那麼所計算出來的法向量就會出
問題。如圖三中所示的十字雷射， 
Robot controller 
Robot 
Laser projector Camera 
 
Trajectory 
Robot controller 
圖三 影像原始圖 
 4
投影中心，如圖九所示。不過這個設
計的方法有個先決條件，那就是影像
上處理完的十字雷射投影必須夠完
整，這是因為若是處理完的十字雷射
投影不夠完整，那所計算出來的中心
會因資訊不夠而有誤差，除了這一點
外，十字雷射投影的樣式需為 X 形
狀，若是呈現+型，十字雷射投影中心
必須以其他方式計算出。 
 
圖八 雷射十字估測結果圖 
 
圖九 雷射十字光中心估測結果圖 
 
4. 曲面法線向量估計 
4.1 眼在手架構 
在單眼視覺部分，為了找出未知曲面
的法向量，我們將利用雷射結構光來
投影在未知曲面上，並利用雷射結構
光在曲面上的投影來推算未知曲面的
法向量。首先，計算出攝影機與雷射
結構光的相對關係，如圖九所示。其
中，c 為攝影機的光學中心。( )  分
別為雷射結構光之基底座標。在重建
三度空間十字雷射結構光時，我們利
用攝影機光學中心 c 與影像上雷射光
點的投影座標
zyx ,,
m
I 的延伸線，與在三度
空間中 yz 平面上所發出的雷射光，來
求取在三度空間中 x 分量為零時的交
點m  的 y 與 z 分量，其關係式如下式
所示。 
⎟⎠
⎞⎜⎝
⎛ −=− cmkcm I  
 
 
 
 
 
 
 
圖十 雷射結構光重建示意圖 
其中 為比例常數。同理，我們可以利
用由
k
xz 平面上所發出的雷射光在分量
y 為零時求出 的 x 與 z 分量。因此，
利用上述方法即可重建出三度空間中
相對應於雷射基底座標上的雷射水平
與垂直曲線方程式，分別為 與( )zyf ,,0
( )zxg ,0, ，接著，取微分並且代入相對
應於雷射座標十字型標記的中心點座
標 ( )LLL zyx ,, ，即可求出通過交點的兩
個切線向量。 
( ) ( )
( ) ( )
⎪⎪⎩
⎪⎪⎨
⎧
⎥⎦
⎤⎢⎣
⎡
∂
∂
∂
∂=
⎥⎦
⎤⎢⎣
⎡
∂
∂
∂
∂=
==
==
LL
LL
zzxx
t
zzyy
t
z
zxg
x
zxgg
z
zyf
y
zyff
,
,
,0,0,0,
,,0,,00
 
再將兩方程式取外積 ， 即為tt gfn ×=
m
m
I  
c
z
x 單眼攝影機 
y
 6
( ) ( ) ( )
ccc
iii
i
zzyyxx
z
zyxF
y
zyxF
x
zyxFv
~~,~~,~~
~
~,~,~
~
~,~,~
~
~,~,~
===
⎥⎦
⎤⎢⎣
⎡
∂
∂
∂
∂
∂
∂=
其中 為這兩個方程式的切
線向量，(
2,1, =ivi )ccc zyx ~,~,~ 為三度空間中十
字雷射的中心。最後求取這兩條切
線的外積，即為三度空間中雷射十
字中的曲面法向量 n。 
21 vvn ×=  
我們利用上述不同架構來進行未知曲
面的偵測時，可以把偵測未知曲面所
接觸到的點連續紀錄起來，並利用
RLS[9]演算法找出方程式 ( ) 0,, =zyxf
來擬合(fitting)在曲面上經過的點，如
圖十三所示，如此一來，當對未知曲
面進行偵測時，就可以不斷更新未知
曲面的方程式，當偵測結束後，也就
完成了曲面的估算。 
 
圖十三 曲面法向量重建示意圖 
 
5. 實驗結果 
本研究分別針對所提出之眼在手
與眼看手兩種架構來分析與驗證重建
三維位之曲面法向量之理論，並進一
不利用重建出的法向量達成機械手臂
的姿態控制任務，其分別之實驗結果
如下。 
5.1 眼看手架構 
本研究中眼看手的實際系統架構
如圖十四所示。 
 
圖十四 眼看手系統架構圖 
為了要驗証所用來估測維未知曲面法
向量的方法之可行性, 因此對一個曲
度變化大的曲面來進行測試,首先,在
曲面上投影一十字雷射,在計算完法向
量之後,移動十字雷射到其他位置, 如
同圖十五所示, 在移動的過程中, 把
法向量記錄下來後可以發現,所設計的
方法的確可以計算出曲面法向量的變
化, 如同圖十六所示。 
time(s) 
 
圖十五 十字雷射移動過程圖 
 8
0 10 20 30 40 50 60 70 80 90
−60
−40
−20
0
20
40
60
a
u
v
b
I II III
 
圖二十 點到點誤差收斂圖
0 10 20 30 40 50 60 70 80 90
−60
−40
−20
0
20
40
60
a
b
x
y
z
I II III
 
圖十八 姿態誤差收斂圖 
 
6. 結論 
本計劃提出一套利用視覺與雷射
結構光達成三維未知曲面重建的演算
法，並分別由兩種架構來驗證。第一
種架構中，利用了雙眼攝影機配合上
十字雷射可以對三維曲面進行估計與
姿態的控制，即時計算出十字雷射中
心的曲面法向量，來控制機械手臂完
成此姿態。並由實驗的結果中可知在
估計出之法向量正確且機械手臂可依
靠此法向量達成姿態控制，並使得系
統可以快速且正確地控制機械手臂。
本研究提出之另一種眼在手架構，其
利用了裝設在機械手臂上之單眼攝影
機與十字雷射即可對三維曲面進行估
計與完成姿態的控制任務。並由實驗
結果可知此架構也同時能正確與即時
的完成三維未知曲面之重建與機械手
臂姿態控制之任務。由於本計劃為一
連續三年計畫的第一年，基於在此計
劃完成之三維未知曲面估計之理論與
實驗，未來的兩年計劃中將會闊展現
有的系統，加入各種力感測器並利用
已估計出的三維曲面完成機械手臂混
合力與姿態的各式高自由度任務，如
插銷、鑽孔、鎖螺絲等任務控制。 
 
pixel 
time(s) 
7. 計劃成果自評 
本研究計畫之研發成果成功的視
覺與雷射結構光搭配，做到即時重建
三為未知曲面，在未知工作物體之曲
面狀況下即時估計出曲面法向量以完
成機器手臂的姿態控制。此方法未來
發展可使機器手臂應用在工廠或特定
環境中需要曲面估計的任務時不需使
用高自由度的力感測器，而僅需以視
覺搭配雷射結構光即可完成未知三維
曲面之估計，大量減少成本，並同時
使系統依然擁有快速與準確的工作效
果。基於此計畫所成功設計與驗證的
未知三維曲面估計理論，未來此三年
計畫的第二、三兩年，將分別針對眼
在手與眼看手兩種架構中加入各式力
感測器，並分別設計如插銷、鑽孔、
鎖螺絲等不同高自由度的混合力與姿
態任務，且根據系統任務的需求設計
不同的控制法則與任務編碼，以期望
可利用低維度力量感測器搭配本計劃
所提出之系統架構以正確與有效的完
成高自由度的混合力與姿態任務，並
同時節省大量的成本。 
pose error
time(s) 
8. 參考文獻 
[1] Wen-Chung Chang and Shu-An Lee, 
“Monitoring and Control of A Mobile 
Tele-Robotic System”, in Proc. 2004 
 10
表 Y04                                                                          第 1 頁 共 3 頁 
行政院國家科學委員會補助國內專家學者出席國際學術會議報告 
                                                              96 年 9 月 28 日 
報告人姓名  張文中 
 
服務機構 
及職稱 
 
國立臺北科技大學 電機工程系 
副教授 
 
     時間 
會議 
     地點 
 
96/01/25 至 96/01/27 
日本 別府 
本會核定 
補助文號 
 
NSC 95-2221-E-027-049 
會議 
名稱 
 (中文) 第 12 屆國際人工生命與機器人會議 
 (英文) The 12th International Symposium on Artificial Life and Robotics 
發表 
論文 
題目 
 (中文) 眼在手型機械手臂之混合追蹤控制 
 (英文) Hybrid Tracking Control of Eye-in-Hand Robotic Manipulators 
報告內容應包括下列各項： 
一、參加會議經過 
          
第 12 屆國際人工生命與機器人會議(The 12th International Symposium on 
Artificial Life and Robotics)在人工生命與機器人領域中具有前瞻性的會議之ㄧ，此
次由日本學術振興會(Japan Society for the Promotion of Science)、Santa Fe 學院(Santa 
Fe Institute)與日本器械工程師協會(The Society of Instrument and Control Engineers)
等贊助，國際人工生命與機器人會議委員會(Organizing Committee of International 
Symposium on Artificial Life and Robotics)與大分大學(Oita University) 共同主辦，此
次會議地點為日本別府的國際會議場(B-Con Plaza, Beppu, Oita, Japan)。此會議乃是
亞洲人工生命與機器人領域相當重要的會議之一，且包含內容極為廣泛。此次會議
計有來自於全球數十個國家共約 196 篇論文被此會議之國際議程委員會所接受，依
論文性質分為 31 個技術議程於三天會議中以口頭報告方式發表論文。 
會議進行方式主要是以技術會
議 (technical program) 的方式
來進行。這次會議同時包括 3
個獲得特別邀請議程，其主講
人分別為 Lund 教授、Pagliarini 
教授與 Pillai 教授 (3 special 
invited talks: Prof. H. H. Lund, 
Prof. L. Pagliarini, and Prof. B. 
Pillai) 和 31 個技術議程  (31 
technical sessions) ，其中其技術
議程是以口頭報告的型式共分
為三天來舉行，其分類方法主
要是以其技術的類型，功能，
及硬體設備來做區分。 
附件一
 
表 Y04                                                                          第 3 頁 共 3 頁 
 
 
五、攜回資料名稱及內容 
 
1. Symposium Digest, AROB2007: 此次會議所有發表論文的名稱、作者及摘要 
2. AROB2007 Symposium CD-ROM  
3. 多項未來將舉辦之國際會議 Call for Papers 
 
六、其他 
 
此項會議可謂機器人學與人工生命領域相當重要的會議之一，雖然有一些國內
論文被接受，但相較日本及韓國等其他國家為低。國內學者應持續積極參與這類國
際學術會議才能藉由學術交流而不斷進步，並進而激勵國內研究水準。 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
terest is to simultaneously control the normal contact
force and the pose of a six-degree-of-freedom robotic
manipulator on the unknown 3-D surface. The goal
of the autonomous task is to drive the end-eﬀector to
the trajectory and continue tracking the trajectory in
desired pose and contact force. The proposed hybrid
control structure is illustrated in Figure 2.
2 Normal vectors on 3-D surface
2.1 Detection of laser cross
As the color of the laser cross is diﬀerent from the
surrounding environment, the laser cross could be de-
tected by color ﬁltering and connected components la-
belling [5]. A typical observed image from a CCD cam-
era and the corresponding image processing results can
be seen in Figure 3. In order to locate the two curves
Figure 3: Laser cross on image plane.
that the laser cross is composed of, one could ﬁrst
identify the corresponding two sets of pixels and apply
least square algorithm to determine their equations in
image space. An eﬀective way of computing the cen-
ter of the cross for correctly allocating sets of pixels to
the two curves is as follows. Let [ u v ]T be the 2-D
coordinates in the image plane, α denote the distance
between the edges of laser cross at ﬁxed u, and β de-
note the distance between the edges of laser cross at
ﬁxed v as illustrated in Figure 4. By determining the
u
v β
α
α
uc u
β
vc v
Figure 4: Laser cross curves on image plane{left}, uα-
plane{middle}, and vβ-plane{right}.
equation of the curves
α = g1(u) and β = g2(v) (1)
on the uα-plane and the vβ-plane as illustrated in Fig-
ure 4, the image coordinate of the laser cross center
[ uc vc ]T are calculated by setting α = 0 and β = 0
in (1). To determine the two curves and the precise
center of laser cross, four regions are partitioned by
the previously detected laser cross center [ uc vc ]T .
The curve in quadrant I and quadrant III can be esti-
mated by least square algorithm. Similarly, the other
curve in quadrant II and quadrant IV can also be es-
timated.
2.2 Reconstruction of normal vectors
To determine the directional vector normal to the
3D unknown surface, the image projection of laser
cross onto the unknown surface is used to estimate
the normal vector. Firstly, calculate the transforma-
tion matrix between the camera and the laser projec-
tor, and then the transformation matrix between the
laser projector and the robot. Finally, reconstruct the
projected laser cross on the surface in laser projec-
tor frame by the known transformation between the
camera and the laser projector as shown in Figure 5.
Speciﬁcally, when projecting a laser line to form the
yz-plane in the laser projector frame, one can recon-
struct a 3-D laser point m¯ with Im¯ as the 3-D coordi-
nate of its projection on the image space by setting the
x-component of m¯ to be zero in the following equality.
m¯− c = k(Im¯− c) (2)
Similarly, one can reconstruct a 3-D laser point by
setting the y-component of m¯ to be zero in (2) if a
laser line is projected to form the xz-plane. Based on
m¯
Im¯
c
Laser cross projector
CCD camera
z
x
y
Figure 5: Reconstruction of laser cross curves.
the reconstructed laser cross in Cartesian space, one
can compute the normal vector n at the laser cross
center, which is the cross product of the two tangential
lines at the laser cross center.
