21. INTRODUCTION
Sensor techniques have been prospering in the recent decade. Many engineering systems,
e.g. bridges, buildings, airplanes, etc., are instrumented nowadays for damage detection and
health monitoring. An important question is how to update the reliability of these systems
based on the monitoring data. However, this is, in general, a very challenging research topic.
An attempt was made by Beck and Au [10] who proposed adaptive Metropolis-Hastings
algorithm to first update the probability density function (PDF) of the uncertain system
parameters and then to update reliability. A limitation of this approach is that the dimension
of uncertainties cannot be too high since updating high dimensional PDF is infeasible. Ching
and Beck [11] proposed another method based on ISEE [12] to update reliability of linear
dynamical systems. Their approach is not constrained in the uncertainty dimension, but it can
be only applied to deterministic linear dynamical systems with Gaussian uncertainties.
Updating reliability of nonlinear dynamical systems remains a pending research problem.
In this research, it is shown that it is not necessary to first update the PDF of uncertain
parameters before the reliability is updated when the data is a scalar, i.e. the system reliability
can be directly updated. Since the updating of the PDF of uncertain parameters is bypassed,
the approach is not limited to the number of uncertainties. To relax the constraint of scalar
data, an approximate technique is further proposed to condense all information provided in
4the probability distribution of the uncertainties in the target dynamical system and the
probabilistic model M of the system, i.e. to compute  |P F M , where F is the failure
event. When monitoring data D is available, it is essential to incorporate it to update the
reliability to reduce the uncertainties in the system. This is especially the case if D is the
direct measurement on the target dynamical system: this measurement directly reflects the
system status. Therefore, it is desirable to develop a methodology to update reliability based
on these measurements, i.e. to compute  | ,P F D M . A usual way of estimating this
probability is through the following equation:
      ( )
1
1
| , | , | , | ,
N
i
i
P F D M P F M f D M d P F M
N
   

   (1)
where  contains uncertain parameters of interest, and ( )i is drawn from  | ,f D M .
Here it has been assumed that conditioning on , D and the failure event are independent.
With this approach, the PDF of the uncertain parameters is first updated through stochastic
simulation, and then the updated reliability is simply the average of the reliabilities for which
the uncertain parameters are fixed at their sampled values.
This approach of updating reliability is feasible when the  dimension is low. Beck
and Au (2002) has demonstrated that this approach works reasonably well when the
dimension is less than five. When the  dimension is high, e.g.: thousands, this approach
may be problematic since drawing samples from the high dimensional PDF  | ,f D M is
technically challenging, and in many instances, practically infeasible. To circumvent this
6provide extra information with respect to D. According to Bayes’ rule
     
  
      
( ) | , |
| ( ),
( ) |
( ) | , |
( ) | , | ( ) | , 1 |C
f D F M P F M
P F D M
f D M
f D F M P F M
f D F M P F M f D F M P F M



 


   
(3)
where CF denotes the non-failure event. Note that in this approach, the updating of the PDF
of the uncertain parameters  is not involved, i.e. it is bypassed. Therefore, the dimension
of  does not impose any limitation on the approach.
This new approach thus requires two components: (a) the search of such an approximate
sufficient statistics ( )D , and (b) the determination of  | ( ),P F D M , the failure
probability given the scalar data ( )D , which, in turns, requires the knowledge of
 ( ) | ,f D F M ,  ( ) | ,Cf D F M , and  |P F M . In the next two sections, the detailed
descriptions for estimating  ( ) | ,f D F M ,  ( ) | ,Cf D F M , and  |P F M by using
Monte Carlo simulation (MCS) and Subset Simulation (SubSim) will be given. In a later
section, a way of finding the approximate sufficient statistics ( )D for dynamical systems
will be proposed.
For notational simplicity, the symbol M in the conditions will be dropped and  will
denote ( )D in all the following discussions. Readers should keep in mind that all results
are always conditioned on the assumed probabilistic model M .
3. ESTIMATION OF  |P F  VIA MCS
8using histograms. Let us denote the estimated histograms by  ˆ |f F and  ˆ | Cf F . As a
consequence,
       
ˆ ˆ|
| ˆ ˆˆ ˆ| | 1C
f F P F
P F
f F P F f F P F

 

   
(5)
The performance of MCS in estimating  |P F  is independent of the number of
degree of freedom of the system, system complexity, and the uncertainty dimension. In spite
of this, MCS is inefficient when  |P F  is small. The reason for this inefficiency is
two-fold: (a) MCS is inefficient in estimating small P F . This is because the R samples
from MCS, i.e. (1: )NR , mostly cluster in the main support region of the PDF of R , denoted
by f r . However, in order to estimate small P F accurately, R samples in the tail are
needed. Unfortunately, MCS is inefficient in propagating samples into the tail region; (b)
most failure samples drawn from  |f F via MCS reside in the main support region of
 |f F . However, in order to estimate  |f F accurately for the small  |f F
region, failure samples in the tail of  |f F are needed. Again, MCS is inefficient for this
purpose.
4. ESTIMATION OF  |P F  VIA SUBSIM
According to the previous discussion, the main drawback of MCS in estimating
 |P F  stems from the fact that it is inefficient in propagating R and | F samples into
the tail regions of f r and  |f F . In this section, SubSim is introduced and employed
10
being f g but enforce the acceptance criterion 1G b . Together with the original 1N N
samples, there are, again, N samples distributed as  1|f g G b .
Now the next threshold is chosen to be 2b . Suppose there are 2N samples less than 2b ;
therefore,  2 1|P G b G b  and  2 1|P G b G b  are roughly 2N N and 21 N N ,
respectively. These 2N samples, denoted by 21 2
(1: )
,
N
b bG , are distributed as  1 2|f g b G b  ,
while the other 2N N samples greater than 2b are distributed as  2|f g G b . Then
these 2N N samples are used to generate 2N more samples so that there are, again, N
samples distributed as  2|f g G b . The same procedure is repeated until enough samples
have propagated to the desirable tail region of f g . Later in the examples, the sample
number N in the above descriptions will be called the stage sample number since the
sample number remains constant and is equal to N for all stages.
For notational simplicity, the following notations will be used throughout the paper:

1 1
,b bf g P   denote    1 1| ,f g G b P G b    , 1 1, |,j j j jb b b bf g P    denote
   1 1| , |j j j jf g b G b P G b G b      , mbf g denotes  | mf g G b , 1,j jb bP  denotes
 1j jP b G b   , and mbP denotes  mP G b .
Suppose the procedure is repeated for m stages, the following samples will be
available: 1
1
(1: )N
bG distributed as 1bf g , 11(1: ), jj jNb bG  distributed as 1,j jb bf g ( 1,..., 1j m  ),
and (1: )
m
N
bG distributed as mbf g . Also, the following probability estimates are available:
1 1b
P N N ,
1| 1j jb b j
P N N
  (for 1,..., 1j m  ). One can see that the tail probability
12
number of stages, i.e. m , is usually chosen such that mb b and  | 0.1mP G b G b   .
Under this choice, (6) and (9) become
   ( )
1
10 m N i
m
i
P G b I G b
N



    (10)
and
   
1 1
1
,
1
9 9ˆ ˆ ˆ10 10
10 10 j j m
m
j m
b b b b
j
f g f g f g f g


 

     (11)
Since the SubSim samples propagate to the tail in a very efficient way, the  P G b
estimator is more stable, and the estimated f g is much more accurate in the tail region.
The performance of SubSim is also independent of the degree of freedom of the system,
system complexity, and the uncertainty dimension.
4.2 Estimating  |P F  via SubSim
4.2.1 Estimation of P F and  | Cf F with SubSim
In the perspective of SubSim, P F can be effectively estimated with (10) by taking
G to be R and b to be 1 since the failure event F is defined as 1R . To facilitate the
discussion of the estimation for  | Cf F , let us denote the  samples obtained in the j-th
SubSim stage by 1
1
(1: )
,
j
j j
N
b b  , i.e. the  samples satisfying 1j jb R b   . The following
samples will be available at the end of SubSim: 1
1
(1: )N
b distributed as 1bf  , 11(1: ), jj jNb b 
distributed as 
1,j jb b
f 

(for 1,..., 1j m  ), and (1: )
m
N
b distributed as mbf  . Among
(1: )
m
N
b , there are ,1mbN samples, denoted by
,1(1: )
,1
bm
m
N
b , satisfying 1mb R  ; they are
distributed as ,1mbf  . The other samples, denoted by ,1(1: )bmN NF  , satisfy 1R ; they are
14
tail of  |f F : Choose a threshold 1b so that there are 1N | F samples less than 1b ;
therefore,  1 |P b F and  1 |P b F are roughly 1N N and 11 N N , respectively.
These 1N samples, denoted by 11
(1: )
|
N
b F , are distributed as    11| , |bf b F f F   , while
the other 1N N samples greater than 1b are distributed as  1| ,f b F . These
1N N samples are used to generate 1N more samples that are also distributed as
 
1
|bf F by using the Metropolis-Hastings algorithm: simply conduct the
Metropolis-Hastings algorithm but enforce the acceptance criterion 1R and 1b .
Together with the original 1N N samples, there are, again, N samples distributed as
 1| ,f b F .
Then the next threshold 2b is chosen. There are 2N samples, denoted by 21 2
(1: )
, |
N
b b F , less
than 2b , so they are distributed as    1 21 2 ,| , |b bf b b F f F     . The same procedure is
repeated m times. Finally, the following samples will be obtained: 1
1
(1: )
|
N
b F distributed as
 
1
|bf F , 11
(1: )
, |
j
j j
N
b b F  distributed as  1, |j jb bf F (for 1,..., 1j m  ), and (1: )|m Nb F distributed
as    | | ,
mb m
f F f b F   . Also,  
1| 1 1
|b FP P b F N N   and
 
1| , 1 1
| ,
j jb b F j j j
P P b b F N N 
      (for 1,..., 1j m  ). If the 0.9 rule is adopted,
 |f F can be estimated as follows:
       
1 1
1
,
1
9 9ˆ ˆ ˆ| | | 10 | 10
10 10 j j m
m
j m
b b b b
j
f F f F f F f F   


 

     (13)
where fˆ denotes the estimated PDF with histograms, e.g.  
1,ˆ
|
j jb b
f F

is estimated based
on the 1
1
(1: )
, |
j
j j
N
b b F  samples by using histograms.
16
the roof, and the failure is defined as the exceedance of the maximum inter-story drift over a
prescribed threshold. The third example is a real case study, a deep excavation problem,
where the monitoring value is the maximum diaphragm wall deformation, and the failure is
defined as the exceedance of the maximum ground settlement over a prescribed threshold.
There are some common features for the three examples: (a) the uncertainties are so
significant that the failure probability is quite large when no monitoring data is available; (b)
the physical quantities that directly define failure cannot be monitored easily, but the
monitored value contains certain information about those quantities, so the knowledge of the
monitoring value is helpful in reducing the uncertainties associated with the defined failure.
6.1 Infinite slope
In this hypothetical example, let us consider the infinite slope in Figure 2, where H is
the thickness of the soil layer,  is the slope angle, h is the height of the water table, 
is the unit weight of the soil, and sat is unit weight of the saturated soil. The failure event is
defined as the sliding of the slope along the soil-rock interface, i.e. downward sliding force is
greater than the shear resistance along the interface. Therefore, the limit-state function is
         2
sin cos
cos tan
sat
sat
h H h
R Z
h H h
   
    
   
    
(14)
The height of the water table is uncertain and is uniformly distributed over the [0, H ] interval,
i.e. h H U  , where U is uniformly distributed over the [0,1] interval. For this example,
Z contains all uncertainties, including , , , ,sat H U  . It is assumed that the uncertain
18
Generate numerous independent samples of Z , each sample corresponds to a monitoring
value . Suppose the observed monitoring value is ˆ, the samples whose monitoring
values are close to ˆ (in the range of ˆ 0.1 ) are kept. Assume that there are m such
samples and among them, H samples satisfy the failure definition. Then  ˆ|P F  can be
roughly estimated as /H m . Figure 4 shows the examining results as circles when ˆ is
fixed at various values. Comparison between the analysis and examining results indicates that
the proposed method provides consistent  |P F  estimate. Nevertheless, the proposed
approach requires much less computation than the examining approach.
6.2 Ten-story building subjected to earthquake motions
In this hypothetical example, a ten-story building subjected to various uncertainties is
considered. The governing equation is given by:
( ) ( ) ( ) ( )Mu t C u t K u t F t      (15)
where
1 1 2 2
2 2 3
10
10 10 10
1 2 2
2 2 3
10
10 10
m c c c
c c c
M C
c
m c c
k k k
k k k
K
k
k k
    
           
         
  
    
   

 

(16)
  1 10,..., TF t p t m m , where p t is the 20-sec uncertain excitation (sampling interval
t = 0.01 second). It is assumed that 1 10,...,m m are independent Gaussian uncertain
20
significant. The failure probability will be updated with the monitoring data to reduce the
uncertainties. The estimated  |f F and  | Cf F made by SubSim samples are shown
in Figure 6, and the estimated  |P F  is plotted in Figure 7, where the left-hand-side
plot is the result of a single SubSim run with stage sample number N = 1000, while the
right-hand-side shows the average and 95% confidence interval of the results from
independent 200 SubSim runs. It is clear that the updated failure probability increases with
increasing roof acceleration. From Figure 7, it is found that the confidence intervals for  >
6m/s2 is quite large. This is because  samples beyond that value are rare, rendering the
estimated  |P F  relatively inaccurate beyond 6m/s2. Figure 8 shows the comparison of
the variabilities in the  |P F  estimates made by MCS and SubSim with the same total
sample number. It is clear that the SubSim approach outperforms MCS.
The same verifying procedure described in the last example is adopted to examine the
analysis results. Figure 7 shows the examining results as circles. Comparison between the
analysis and examining results indicates that the proposed method provides consistent
 |P F  estimate. Nevertheless, the proposed approach requires much less computation
than the examining approach.
6.3 Deep excavation
This real case of deep excavation is taken from Ou et al. [20]. The site was located in the
Taipei City in Taiwan. The diaphragm wall is 35m deep and 0.9m in thickness. The
22
the modulus exponent; ucs is the undrained shear strength; a and b are parameters in the
eE  relation. This strain-dependent modulus model is based on the observations made by
Wood [23] and Jardine [24]: the small-strain modulus of clayey soils is considerably higher
than that in common range. Hsieh and Ou [21, 25] found that the modified model
outperforms the original model in predicting ground settlement in many deep excavation
problems.
The uncertainties associated with the real case study include the properties of the sandy
and clayey soils, locations of water tables and the forces provided by the brace systems. In
selecting the PDF of the uncertainties, most of the mean values of the uncertain soil
properties are taken to be equal to the lab test results from Ou et al. [25] (see Tables 1 and 2),
while c.o.v.s are chosen based on the recommendations made by Phoon [26]. All uncertainties
are assumed to be independent. The failure ratio fR of the sandy and clayey soils are taken
to be uniformly distributed over [0.8,0.9], and the modulus exponent n to be uniformly
distributed over [0.4,1.0]. The Poisson ratios  of all sandy soils are uniformly distributed
over [0.2,0.4], while those of all clayey soils are equal to 0.49. Cohesion c of all sandy soils
are taken to be 0. According to Ou et al.’s lab test results, / uE S of the clayey soils is
roughly among 1800 and 2200, so we assume / uE S is uniformly distributed over
[1800,2200]. For the clayey soil layers, /uc vs is assumed to be normally distributed with
mean value described by the following equation:
24
runs with stage sample number N = 1000 are plotted in Figure 12 as the dashed lines, while
the average of the five curves is presented as the solid line. It is clear that the updated failure
probability increases with increasing wall deformation. The finite element analysis is quite
time-consuming, so the confidence intervals are not computed.
The same verifying procedure described is adopted to examine the analysis results.
Figure 12 shows the examining results as circles. Comparison between the analysis and
examining results indicates that the proposed method provides consistent  |P F  estimate.
Nevertheless, the proposed approach requires much less computation than the examining
approach.
7. DISCUSSIONS AND CONCLUSION
A new method of updating reliability of geotechnical systems is proposed in this paper.
Geotechnical systems are usually quite uncertain due to the fact that its materials, soils and
rocks, are buried in the ground. The consequence is that in some cases, the failure probability
can be unacceptably large. The proposed method is capable of reducing the uncertainties by
using new information, i.e. monitoring data  from the target system, to update the failure
probability. The methodology can apply to general nonlinear systems with high dimensional
uncertainties. Moreover, the functional relationship between the updated failure probability
and the monitoring value can be obtained prior to the monitoring process. This means in real
26
Principles 1984, John Wiley & Sons.
5. Duncan JM. Factors of Safety and Reliability Ingeotechnical Engineering. Journal of
Geotechnical and Geoenvironmental Engineering 2000; 126(4): 307-316.
6. Kulhawy FH, Phoon KK. Observations on geotechnical reliability-based
designdevelopment in North America. Foundation Design Codes and Soil Investigation in
view of International Harmonization and Performance 2002; 31–48.
7. Zhang L, Tang WH, Ng CWW. Reliability of Axially Loaded Driven Pile Groups. Journal
of Geotechnical and Geoenvironmental Engineering 2001; 127(12): 1051-1060.
8. Low BK, Gilbert RB, Wright SG.. Slope Reliability Analysis Using Generalized Method of
Slices. Journal of Geotechnical and Geoenvironmental Engineering 1998; 124(4): 350-362.
9. Phoon KK, Kulhawy FH, Grigoriu MD. Development of a Reliability-Based Design
Framework for Transmission Line Structure Foundations. Journal of Geotechnical and
Geoenvironmental Engineering 2003; 129(9): 798-806.
10. Beck JL, Au SK. Bayesian updating of structural models and reliability using markov
chain monte carlo simulation. Journal of Engineering Mechanics 2002; 128(4): 380-391.
11. Ching J, Beck JL. Real-Time Reliability Estimation for Serviceability Limit States in
Structures Using only Incomplete Output Data. Accepted by Probabilistic Engineering
Mechanics 2006.
12. Au SK, Beck JL. First excursion probability for linear systems by very efficient
28
method. Journal of Geotechnical and Geoenvironmental Engineering, ASCE 1998; 124(9):
987-808.
21. Hsieh PG, Ou CY. Use of the modified hyperbolic model in excavation analysis under
undrained condition. Geotechnical Engineering, SEGAS 1997; 28(2): 123-150.
22. Duncan JM, Chang CY. Nonlinear analysis of stress and strain in soil. ASCE Journal of
the Soil Mechanics and Foundations 1970; 96(5): 1629-1653.
23. Wood DM. Soil Behavior and Critical State Soil Mechanics 1990, Cambridge University
Press.
24. Jardine RJ. Some observations on the kinematic nature of soil stiffness. Soil and
Foundations 1992; 32(2): 111-124.
25. Hsieh PG, Ou CY. Shape of ground surface settlement profiles caused by excavation.
Canadian Geotechnical Journal 1998; 35(6): 1004-1017.
26. Phoon KK. Reliability-based design of foundations for transmission line structures. Ph.D.
Dissertation 1995, Department of Civil and Environmental Engineering, Cornell University.
27. Ladd CC, Foote R. A new design procedure for stability of soft clays. Journal of the
Geotechnical Engineering Division. ASCE 1974; 100(7): 763-786.
Soong, T. T. and Grigoriu, M. (1993). Random vibration of mechanical and structural
systems, Prentice Hall, Englewood Cliffs, N.J.
30
Table 1 Prior PDF parameters for the clayey soils in Example 3
(mean values from Ou et al. [20])
Normal distribution
Total unit weight
(kN/m3)
Depth
(m)
Soil
type
mean c.o.v.
0.0～5.6 CL 18.25 7%
8.0～33.0 CL 18.93 7%
35.0～37.5 CL 18.15 7%
Table 2 Prior PDF parameters for the sandy soils in Example 3
(mean values from Ou et al. [20])
Normal distribution
Lognormal
distribution
Total unit weight
(kN/m3)
 K
(MPa)
Depth
(m)
Soil
type
mean c.o.v mean c.o.v mean c.o.v
5.6～8.0 SM 18.93 7% 31o 10% 750 40%
33.0～35.0 SM 19.62 7% 31o 10% 2500 40%
37.5～46.0 SM 19.62 7% 32o 10% 2500 40%
32
Figure 2. An illustration of the infinite slope.
seepage force
H
h
β
γ
γsat Rock
34
0 5 10 15
10
-5
10
-4
10
-3
10
-2
10
-1
10
0
Monitoring value(m)
U
p
d
at
ed
fa
ilu
re
p
ro
b
ab
ili
ty
0 5 10 15
10
-5
10
-4
10
-3
10
-2
10
-1
10
0
Monitoring value(m)
Figure 4. Analysis results for Example 1. The left-hand-side plot is the result from a single
SubSim run, while the right-hand-side plot compiles the results from 200 independent
SubSim runs. The circles are the examining results.
36
3 4 5 6 7 8
0.0001
0.001
0.01
0.1
Monitoring value(m/s2)
P
ro
b
ab
ili
ty
d
en
si
ty
3 4 5 6 7 8
0.0001
0.001
0.01
0.1
Monitoring value(m/s2)
Figure 6. The histograms of the  |f F (left) and  | Cf F (right) estimated by using
the SubSim samples (Example 2).
38
10
-2
10
-1
10
0
0
0.5
1
1.5
2
2.5
Updated failure probability
C
o
ef
fi
ci
en
t
o
f
va
ri
at
io
n
Figure 8. Comparison of variabilities, i.e. coefficient of variation, in the updated failure
probabilities obtained by SubSim (circles) and MCS (crosses) for Example 2.
40
Figure 10. The finite element mesh used in Example 3 (after Ou et al. [20]).
42
0.13 0.14 0.15 0.16 0.17 0.18 0.19 0.2
10
-5
10
-4
10
-3
10
-2
10
-1
10
0
Monitoring value(m)
U
p
d
at
in
g
fa
ilu
re
p
ro
b
ab
ili
ty
Figure 12. Analysis results for Example 3. The circles are the examining results.
Sorensen 1994; Gasser and Schueller 1997; Royset et al. 2001; Papadrakakis and
Lagaros 2002). In practice, it is often of interest to calculate reliability of the target
system under various design settings. Taking reliability-based optimization as an
example, let us consider the following optimization problem:
*
0min ( ) . . ( ) ( ) 0 1,...,F F ic s t P P c i m      (1)
where is the design parameter; PF(is the failure probability of the target system
given the design variable is ; c0() is the objective function; {ci():i=1,…,m}are
deterministic constraints of ; PF* is the target probability of failure. If the entire PF(
function can be obtained beforehand, the reliability-based optimization in (1) can be
transformed into an ordinary optimization problem. Otherwise, the optimization problem
in (1) can be highly non-trivial because of the reliability constraint. Another example is
reliability sensitivity analysis (Bjerager and Krenk 1989; Karamchandani and Cornell
1992; Enevoldsen 1994), where reliability sensitivity under design variable variation, i.e.
sensitivity of PF(with respect to, is the main target.
However, finding the failure probability function PF(, denoted by FPF, is not
trivial. It seems that numerous reliability analyses need to be conducted for various 
locations. This approach has been taken by Jensen (2005), where he adopted a linear
function of to locally approximate log[PF(of a deterministic linear system subject
to stochastic excitation. The number of the to-be-determined coefficients in the linear
function is equal to the dimension of , denoted by n, so at least nreliability analyses
are required to determine those coefficients. In Gasser and Schueller (1997), a quadratic
function is assumed, so the minimum required number of reliability analyses rapidly
increases to n+n(n)/2. However, for complicated problems, large number of
reliability analyses can be computationally infeasible. This may explain why most
examples in relevant reliability-based optimization literature are academic type, i.e.
simple systems subject to few uncertainties. There is a strong need to enhance our ability
of estimating the PF( function for general nonlinear systems subject to
high-dimensional uncertainties.
In Ching and Hsieh (2006), a novel approach is proposed to locally estimate the
failure probability function PF(and its confidence interval by using Subset Simulation
(Au and Beck 2001). In this paper, it is shown that the same problem can be easily
solved by using Monte Carlo simulation (MCS) and the maximum entropy principle
(Jaynes 1957). Moreover, it is possible to estimate the gradient of the logarithm of the
FPF with respect to the design variables. Those features are essential for
reliability-based design and reliability sensitivity computations.
Monte Carlo simulation. In this section, MCS is introduced to estimate P(F) and obtain
samples from f(|F). According to the Law of Large Number,
  ( ) ( )
1
1
( ) ( , ) ( , ) ( )
N
i i
F F MCS
i
P F E I Z I Z P F
N
 

   (5)
where Z(i) and (i) are the i-th independent identically distributed (i.i.d.) sample pair
drawn from the joint PDF f(Z,)=f(Z|)f(); IF(Z(i),(i)) is the indicator function of the
failure event, i.e. IF(Z(i),(i))=1 if Z(i) and (i) represent a failure state and IF(Z(i),(i))= 0
otherwise. Note that the samples satisfying failure are distributed as f(Z,|F), so the 
parts of the samples are distributed as f(|F). With these samples, it is possible to
estimate f(|F), as described in the next section.
Estimating f(|F): maximum entropy method. The underlying PDF f(|F) can be
estimated from its samples. One option of estimating f(|F) is the kernel method, i.e. the
sum of Gaussian kernels centered at the sample points. However, kernel methods are not
implemented in this paper because it requires many samples to converge well, especially
when the dimension of is large. According to past experience (see Gasser and
Schueller (1997) and Jensen (2005)), f(|F) is usually quite smooth in the low failure
probability region. In fact, in Gasser and Schueller (1997) and Jensen (2005), linear and
quadratic functions ofare used to approximate log[PF(in the low probability region.
If this approximation is appropriate, it is a pity to abandon this valuable prior
information, which is the case when either kernels or histograms are chosen.
In this study, the maximum entropy method (Zellner and Highfield 1988; Ormoneit
and White 1999) is adopted to estimate the PDF. The idea is to first estimate the first
moment (mean) of f(|F) from thesamples and then to find the PDF which maximizes
the entropy subject to the first moment constraint. The rationale of this approach is that
the PDF maximizing entropy is the least subjective PDF subject to the moment
information. The resulting PDF estimate is usually quite smooth. The maximum entropy
method of estimating f(|F) is stated as following:
( )
max log[ ( )] ( )
. .
( ) 1 ( ) 1,...,
g
D
i i
D D
g g d
s t
g d g d i n


 
  
     


 
  
     

 
(6)
wherei is the i-th design variable;i is the sample mean of thei samples. Note that the
variable in this optimization problem is the entire g(.) function. The optimal solution of
   2 22 log 1 ( ) 2 log 1 ( )
( ) ( ) ( )
F FP P
F F FP e P P e
   
  
               
    (10)
where
   2* 1 ( )( ) ( )
( )
MCS
F
MCS
P F
P g
N P F
     

 (11)
and (g*()) is the coefficient of variation of the g*() estimator, whose formula can be
found in Ching and Hsieh (2006).
Examples
We present two numerical examples in this section: (a) an earth-fill dam subject to
various uncertainties; and (b) a retaining wall subject to various uncertainties. The goal
of the examples is to demonstrate the use of the proposed approach, i.e. locally estimate
the FPF PF(in the design region D, where failure, design parameters and design
regions D will be defined differently in each example. For all examples, is treated as
uncertain and its prior PDF is taken to be uniform over the design region D.
Example 1: earth fill dam. This example consists of a cross section of an earth fill dam
which is depicted in Figure 1, where the material properties are uncertain. It is proposed
to model the elastic and shear moduli as lognormal random fields E(x,z) and G(x,z),
respectively:
( , ) 0.5 ( , ) 0.5
2 2
( , ) 30 0.5 12.5 ( , ) 12 0.1 5
Y x z Y x ze e e e
E x z z G x z z
e e e e
            
    
(12)
where Y(x,z) is a zero-mean, unit-variance Gaussian random field with a given
autocorrelation RY(Δx,Δz)=exp(-Δx/10-Δz/3) (Note: the mean of Y = e0.5 and variance
of Y = e2-e).
The cross section is discretized into triangular, 3-node, finite elements and the
resulting system is solved under the plane-strain condition in the linear elastic regime.
The dam is subject to a fixed loading q = 30 kPa/m at the top, self weight (soil mass
density = 1800 kg/m3) and the hydrostatic loading where the top level of the water is 2m
below the crest. Failure is defined when the Mohr-Coulomb criterion is satisfied in at
Example 2: retaining wall. Consider the retaining wall in Figure 3 that is subject to self
weight and earthquake excitation. The uncertainties include the density and friction
angle of the backfill cohesiveless soil, friction angle between the wall and soil and
peak horizontal and vertical earthquake acceleration kh and kv. All uncertain variables
are modeled as Gaussian random variables with means equal to [kh kv] =
[20KN/m3 32o 19o 0.2g 0.067g] and standard deviations equal to [kh kv] =
[1.5KN/m3 3o 3o 0.02g 0.0067g]. The design parameters include the height H(1), the
backfill angle (2), the rare-wall inclination angle (3) and the weight WW(4) of the
wall. Failure is defined as the retaining wall fails in lateral sliding. The limit-state
function is:
 ( , ) cos( ) sin( ) tan( )ae W aeR Z P W P          (13)
Figure 3. The cross section of the retaining wall.
where
2 ' 1
2
'
20.5
2
1
(1 ) tan
2 1
cos ( )
sin( )sin( )
cos ( ) cos( )cos( ) 1
cos( )cos( )
h
ae v a
v
a
k
P H k K
k
K
 
  
             
      
 
              
(14)
In this example, we examine the ability of the approach of estimating the sensitivity
of log[PF(with respect toaround the following design location: H = 4 m,= 15o,
it only requires simple Monte Carlo simulations (MCS); (b) pointwise confidence
interval of the PF(estimator can be established with computational cost less than
brute-force MCS simulations; (c) it is applicable to nonlinear systems subject to high
dimensional uncertainties since it is based on MCS. The approach should be valuable for
reliability-based design and reliability sensitivity analysis.
Reference
Ang, A.H-S. and Tang, W.H. (1984). Probability Concepts in Engineering Planning and
Design. New York, NY: John Wiley & Sons.
Au, S.K. and Beck, J.L. (2001). “Estimation of smal failure probability in high 
dimensions by subset simulation.” Probabilistic Engineering Mechanics, 16(4),
263-277.
Benjamin, J.R. and Cornell, C.A. (1970). Reliability, Statistics and Decision for Civil
Engineers, McGraw Hill, New York.
Bjerager, P. and Krenk S. (1989). “Parametric sensitivity in first order reliability theory.” 
Journal of Engineering Mechanics, 115(7), 1577-1582.
Ching, J. and Hsieh, Y.H. (2006). “Local estimation of failure probability function and 
its confidence interval with maximum entropy principle.”Probabilistic
Engineering Mechanics, in press.
Der Kiureghian, A. (2000). “The geometry of random vibrations and solutions by FORM 
and SORM.” Probabilistic Engineering Mechanics, 15(1), 81-90.
Enevoldsen, I. (1994). “Sensitivity analysis or reliability-based optimal solution.” 
Journal of Engineering Mechanics, 120(1), 198-205.
Enevoldsen, I. and Sorensen, J.D. (1994). “Reliability-based optimization in structural
engineering.” Structural Safety, 15(3), 169-196.
Gasser, M. and Schueller, G.I. (1997). “Reliability-based optimization of structural
systems.” Mathematical Methods of Operations Research, 46(3), 287-307.
Jaynes, E.T. (1957). “Information theory and statistical mechanics.” Physical Review,
106(4), 620-630.
Jensen, H.A. (2005). “Structural optimization of linear dynamical systems
understochastic excitation: a moving reliability database approach.” Comput.
