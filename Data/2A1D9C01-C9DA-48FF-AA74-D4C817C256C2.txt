studied in the 1st phase to handling dice of multiple 
colors and views with large tilt angles. The outcome 
of this study has been presented in SMC 2012, a major 
conference in human-computer systems and cybernetics. 
The progresses in these three studies are summarized 
in this report. 
英文關鍵詞： RGBD camera, scene reconstruction, object 
recognition, stereo vision 
 
 I 
 
中文摘要 
 
本計畫延續上年度(99)執行之「快速辨識立體物件之機器人視覺技術第一期計畫」第二期
年度計畫，目的為發展一套可在不同視角與不同光照條件下快速辨識立體物件的視覺系統。
本(100)年度的研究是在第一期的研究基礎上，繼續發展更成熟的物件辨識技術。研發成果
可以三方向說明：第一個方向為利用 Kinect 感測器取得彩色與深度影像，先運用色彩訊息
對場景物件進行分割，再以深度訊息整合分割場域中的立體資訊，建立精確的三維場景和
物件模型。初步成果發表於 Automation 2012。第二個方向為以外觀特徵(Appearance- 
based features)結合 Naive Bayes 分類器之即時物件辨識系統之設計和製作，此研究乃先進
行外觀特徵與局部不變特徵在物件辨識的效能評估，再依評估結果選擇最佳外觀特徵和最
合適之分類器。研究成果已為模式識別領域主要研討會 ICPR 2012 所接受，並為一審稿者
認為是目前最完備的外觀特徵效能評估研究。另一更完整版本已投稿 MVA(J. Machine 
Vision and Applications)。第三個方向為繼續在前一期的研究中已有部分成果之骰點辨識，
並挑戰多顏色與大角度下的辨識效能。新的研究成果發表於人機互動領域知名研討會 SMC 
2012，完整版本亦已投稿了 MVA。本報告將以上述三項成果進行分項說明。 
 
英文摘要 
 
This is the 2ndphase of the research on Robotic Vision for Fast 3D Object Recognition. 
Based on the outcomes from the 1st phase, new progress has been made in advancing the 
technology for the recognition of generic objects. The progress can be addressed in three 
studies. The first is the 3D scene and object segmentation using RGBD images. The scene 
segmentation based on colors is used as a prior for achieving refined segmentation 
when the depth is taken into account. The result is presented in Automation 2012. The 
second is the study on using appearance-based features with Bayesian classifier, which 
is experimentally proven the most compelling approach in a comparative study that 
covers various appearance features and classifiers for generic object recognition. The 
result will be presented in ICPR 2012, a major conference in pattern recognition. The 
third is the extension of the dice recognition studied in the 1st phase to handling dice of 
multiple colors and views with large tilt angles. The outcome of this study has been 
presented in SMC 2012, a major conference in human-computer systems and cybernetics. 
The progresses in these three studies are summarized in this report.  
 
關鍵詞: RGBD camera, scene reconstruction, object recognition, stereo vision.   
 1 
 
前言 
本計畫為開發「快速辨識立體物件之機器人視覺技術」的第二年計畫。在第一年計畫
執行所得的成果上，繼續改進快速辨識立體物件的視覺技術。第二年所得之成果可以三方
向說明：第一為利用 Kinect 感測器取得之彩色與深度影像，先運用色彩訊息對場景和物件
進行二維空間的分割，再以深度訊息整合並分析場域中的立體資訊，進行三維空間的分割
以建立精確的三維場景和物件模型。初步成果發表於 Automation 2012。第二為以外觀特
徵(Appearnace-based features)結合 Naive Bayes 分類器之即時物件辨識系統之研發和設
計，此研發乃根據一項詳盡的外觀特徵與局部不變特徵在物件辨識效能評估的結果而製定
的方法。本研究成果已為模式識別領域主要研討會之一的 ICPR (IEEE Int’l Conference on 
Pattern Recognition)所接受，並為一審稿者認為是目前最完備的外觀特徵在物件辨識效能之
評估研究，將於十一月中旬發表。更完整版本已投稿 MVA(Journal of Machine Vision and 
Applications)。第三個方向為繼續在前一期的研究中已有部分成果之骰點辨識，並挑戰多
顏色與大角度下的辨識效能。新的研究成果發表於人機互動領域知名研討會 SMC (IEEE 
Int’l Conf on Systems, Man and Cybernetics)，完整版本亦已投稿了 MVA。本報告整合了上
述三項成果進行說明。 
 
研究目的 
本計畫之目的在開發一個可與機器人整合進行快速立體物件辨識的機器視覺系統。第
一年為整合計畫下之一分項研究計畫，第二年被審定為個別研究計畫。第二年的計畫目標
為發展即時立體物件辨識視覺系統，運用第一年研究所得之影像特徵建立物件模型，再結
合深度感應器(Kinect)有效提高辨識系統的精準度和可靠性。依上述之研究目的，本計畫擬
定並執行了三項在前言中所列之工作項目，該三項工作項目是根據下述目的所擬定： 
一、以 Kinect 提供之 RGBD 影像進行 3D 場景中的物件切割(segmentation)：不同於
以往單以 2D 影像為基礎之立體視覺技術，RGBD 感測器同時提供了 2D 彩色影像
和 2D 深度影像，所以可取得場景和物件精確的深度值，大幅降低了物件切割時、
或複雜背景下特徵擷取時可能的誤差。 
二、決定最適合一般物件辨識的外貌特徵與分類器：雖然外貌特徵已大量使用在特定
物件辨識，如人臉、車輛，但卻少有文獻探討外貌特徵在辨識一般物件的效能與
瓶頸。本研究首次針對此一基礎研究進行深入探討，由此決定出一有效的外貌特
徵與分類器之組合，並製作出一即時物件辨識系統。 
三、挑戰複雜變數下的骰點辨識：因骰點辨識為一娛樂型機器人所需之物件辨識的關
鍵技術，並可推展至解決其它特殊物件的辨識需求，故本期研究仍持續改進原有
方法，並挑戰實際應用時所需考慮的參數，如不同顏色的骰子與多變化的視角。 
  
 3 
 
others on recognition across viewpoints. SIFT outperforms most appearance features 
when the image is blurred by noise. However, a few classifiers with appearance features 
outperform SIFT in both noise-free conditions and cluttered backgrounds.  
 
第三、四篇論文摘要(Stereo Vision and Invariant Features for Dice Recognition in Uncon- 
trolled Conditions, 第四篇為第三篇之期刊延伸版本) 
 A system is proposed for automatic reading of the number of dots on dice in general 
table game settings. Different from previous dice recognition systems which recognize 
dice of a specific color using a single top-view camera in an enclosure with controlled 
settings, the proposed one uses multiple cameras to recognize dice of various colors 
posed in a wide range of viewing angle and under uncontrolled conditions. It is 
composed of three modules. Module-1 locates the dice using the gradient-conditioned 
color segmentation (GCCS), proposed in this paper, to segment dice of arbitrary colors 
from the background. Module-2 exploits the local invariant features good for building 
homographies across multiple views and lighting conditions. The homographies are 
used to enhance coplanar features and weaken non-coplanar features, giving a solution 
to segment the top faces of the dice and make up the features ruined by possible 
specular reflection. To identify the dots on the segmented top faces, an MSER detector is 
embedded in Module-3 for its consistency in locating the dot regions regardless of 
illumination and viewpoint variations. Experiments show that the proposed system 
performs satisfactorily in various test conditions. 
 
第五篇論文摘要(3D Scene Segmentation and Modeling Using RGBD Images) 
 Different from the stereo image based scene segmentation and modeling, which 
strongly depends on the image feature correspondences across different views, the 
proposed method exploits the color and depth readings from a RGBD camera and 
segment the scene using color and depth features. The color is used as a prior parameter 
for initial segmentation, and the depth follows as a clue to split or merge the color- 
segmented regions. Meanshift is applied to segment the colors in the scene. The 
color-segmented scene is then processed by a plane search scheme based on RANSAC 
(Random Sample Consensus) that can remove the measurement noises in the depth data 
and identify planes of various gradients. The depth along with the identified gradient is 
then processed by moving windows of various sizes so that the split of a windowed 
region or merge of different regions can be determined. Experiments reveal that the 
proposed method outperforms the scene segmentation and modeling by either color or 
depth image alone.  
  
 5 
 
such an evaluation. Our comparison also includes the SIFT feature [6], one of the most 
popular local invariant features for object recognition, so that we can better justify the 
performance of appearance-based features and classification methods.  
 The impacts of the following parameters are investigated: (1) Viewpoint, to recognize 
the object from the views different from those available for feature extraction and 
classifier training; (2) Complex background, to recognize the object when it is in a 
cluttered scene; (3) Blur, to recognize the object when its image is blurred by noise. 
When appearance features are considered, many works skip the detection, segmentation 
and size normalization of the target object in a given image, and assume that the object 
has been located, normalized in size, and made ready for feature extraction [2, 4, 5, 8]. 
However, it is often a case in real life that a training set is offered for determining 
features and training a classifier and the trained classifier is evaluated on a disjoint test 
set or query set. To better handle real-life scenarios, we assume that the detection, 
segmentation and normalization must be solved given an image from the test set before 
carrying out recognition, and we propose a method, Silhouette Alignment, for handling 
this issue.   
 
[1] K. Mikolajczyk, T. Tuytelaars, C. Schmid, A. Zisserman,J. Matas, T. Kadir, and L.J.V. Gool, “A comparison of affine region 
detectors,” IJCV, vol. 65, no. 1-2, pp. 43–72, 2005. 
[2] M.Pontil and A.Verri, “Support vector machines for 3d object recognition,” TPAMI, vol. 20, no. 6, pp. 637 –646, June 1998. 
[3] A.M.Martinez and A.C.Kak, “Pca versus lda,” TPAMI, vol. 23,no. 2, pp. 228 –233, Feb 2001. 
[4] X. Liu, A. Srivastava, and K. Gallivan, “Optimal linear representations of images for object recognition,” TPAMI, vol. 26(5),pp. 
662–666, 2004. 
[5] T.V. Pham and A.W.M. Smeulders, “Sparse representation for coarse and fine object recognition,” TPAMI, vol. 28, no. 4, 
pp.555 –567, April 2006. 
[6] D. G. Lowe, “Distinctive image features from scale-invariant keypoints,” IJCV, vol. 60, pp. 91–110, 2004. 
[7] R. O. Duda and P. E. Hart, Pattern Classification, Wiley Interscience;2nd ed., 2000. 
[8] I. Buciu, I. Nafornita, and I. Pitas, “Gabor features for rotation invariant object classification,” in ICCP, 2008, pp. 41–46. 
 
第三、四篇論文文獻探討(Stereo Vision and Invariant Features for Dice Recognition in 
Uncon- trolled Conditions, 第四篇為第三篇之期刊延伸版本) 
 Different from existing dice recognition systems [1, 2, 3], which use a single top-view 
camera and only work in an enclosure with controlled settings, the proposed system 
exploits stereo view and works in general uncontrolled settings, including dice of 
various colors, under different illumination conditions, and with various camera 
viewpoints. In controlled settings edges are the prominent features considered for dice 
recognition. But specular reflection, often observed in uncontrolled illumination, make 
 7 
 
the depth map quality and can be improved with better input data. Silberman et al. [3] 
proposed the major segmented surfaces in indoor scene and inferred the support 
relations of objects and surfaces which are required by robotics and scene analysis.  
 Recently the RGBD images are applied for plane detection, for example, [4] and [5]. 
Guan et al. [4] segment the 3D plane by iteratively refining the plane function that 
considers both appearance and geometry information from a RGBD camera. Holz et al. 
[5] extract the local surface normals from a RGBD camera, and segment the planes in 
normal space and distance space.  
 This research takes the advantages of both the color channel and depth channel. The 
former enables color-based segmentation, and the segmented regions are further split or 
merged depending on the depth and distance information offered by the latter. Our 
preliminary result shows that the result is better than that of using either channel along. 
We are now focusing on the further improvement of the accuracy and reduction on the 
computational cost.   
 
[1] Silberman, N., Fergus, R, “Indoor scene segmentation using a structured light sensor,” ICCV Workshops 2011, 601-608. 
[2] Chenxi Zhang, Liang Wang, Ruigang Yang, “Semantic Segmentation of Urban Scenes Using Dense Depth Maps,” ECCV (4) 2010, 
708-721. 
[3] Nathan Silberman, Derek Hoiem, Pushmeet Kohli3, Rob Fergus, "Indoor Segmentation and Support Inference from RGBD 
Images,” ECCV 2012. 
[4] Li Guan, Ting Yu, Peter Tu, Ser-Nam Lim, "Simultaneous Image Segmentation and 3D Plane Fitting for RGB-D Sensors - An 
Iterative Framework," CVPR Workshop 2012. 
[5] Dirk Holz, Stefan Holzer, RaduBogdanRusu, Sven Behnke, "Real-Time Plane Segmentation Using RGB-D Cameras," RoboCup 
2011, 306-317. 
 
  
 9 
 
 
出席國際學術會議心得報告 
 
Gee-Sern Hsu 
 
因本年度接受之國際研討會論文均為 2012 年 10 月之後舉辦，而本年度研究經費中的海外差旅補助已用於
2011 年 8 月底的 CAIP 研討會。故仍以 CAIP 參加的心得為以下報告內容。在 CAIP 發表之論文已寫入去(99)
年度的報告成果，本報告不再列入。 
 
I joined the CAIP 2011 held in Seville, Spain on Aug 29~31, and presented the paper Dice 
Recognition in Uncontrolled Illumination Conditions by Local Invariant Features. According to the 
conference ranking referred in http://www.cs.ucla.edu/~eklee/paper/CS_conf_rank.htm and a 
few other websites, CAIP is considered a fine conference in the area of computer vision. It is 
given 0.84 on a unity scale, compared with ICCV (0.96) and ICIP (0.71), in 
http://perso.crans.org/~genest/conf.html.  
 
Quite a few attendees were interested to know more details about how we determine matches 
across different views as features from different dice revealed the same characteristics. Some 
were impressed by the extraction of features across dice, on top of the features within each die, 
using invariant features. Many considered our work an interesting application of invariant 
features to the entertainment and game technology sector. I joined several talks with topics on 
face recognition, object recognition, kernel methods and stereo vision. Among those I kept in 
contact with, the work by Herrera, a Ph.D. student from the University of Oulu, is closely related 
to the continuing phase of this research. He proposes a simplified method to calibrate Kinect, the 
depth and color camera pair. We talked about possible collaboration in the near future, and he 
offers me the package he developed and introduced in the conference. Since the second phase of 
this research will exploit the depth and color cameras in establishing 3D perception, which has 
been in progress for now, Herrera’s toolbox will be studied and compared with other tools that 
are available on the web. We expect this interaction to be able to initiate some collaboration 
research opportunities good for both parties.  
 
 
附件 1 
obtained by previous methods. Because it is not limited to controlled illumina-
tion, the proposed allows a much wider scope of applications, e.g., integration
with table games or different designs of automatic dice games.
Fig. 1. Middle: specular reflection on the dices; Left: the edge map obtained by previous
methods; Right: the edge map obtained by the proposed method.
Existing dice recognition systems only consider the top view of dices. But
a top-view camera is difficult to install on a game table as a specially designed
camera support will be needed. To enable an easy integration with a game table,
the proposed system considers tilted views to the dices captured by the cameras
held on the peripheral supports around the table. Peripheral cameras are more
friendly to install on a game table than top-view ones. However top views only
capture the top faces of the dices, tilted views reveal the top and side surfaces.
The latter is harder to handle as a method is required to segment the top faces
and remove the side surfaces.
The proposed system consists of two major modules: dice segmentation and
dots identification. To segment dices, it exploits the local invariant features ro-
bust to illumination variation and good for building homographies across multi-
views. The homographies are used to enhance coplanar features, segment the top
faces of the dices and make up the features ruined by possible specular reflection.
To identify the dots on the segmented top faces, a MSER (Maximally Stable Ex-
treme Region) [8] detector is applied for its consistency rendering local interest
regions across large illumination variation. The rest of this paper is organized
as follows: the dice segmentation is presented in Section 2. The dot identifica-
tion is elaborated in Section 3. Section 4 presents an experimental study of the
proposed methods, followed by a conclusion in Section 5.
2 Dice Segmentation Using Local Invariant Features
Because dices can pose in arbitrary locations and orientations on a dice roller
base and their sizes vary slightly according to the distance to the camera, local
invariant features are explored in capturing these variations. Many local invariant
feature detectors were proposed and applied in a broad range of applications.
Reviews on these detectors can be found in [10], and [9], [3]. The invariant
feature detectors can be generally categorized into three types [11]. One detects
corner-like features, e.g., Harris-affine, Harris-Laplace, and multi-scale Harris
pair of different viewpoints, and such a transformation only works for the top
faces of the dices as these surfaces are coplanar. This property motivates the
stacking of coplanar surfaces to segment the top faces of the dices even when
specular reflection appears in certain viewpoints. One can choose a dice image
of any viewpoint as a reference image and transform the rest N − 1 images of
different viewpoints to the reference one using the corresponding homographies.
Stacking of the reference image and N − 1 transformed images does not just
enhance the coplanar features but also weaken the non-coplanar features, as
those on the lateral sides of the dice would be overlapped with features from
different planes. As the specular reflection can be considered a view-dependent
feature, different from the coplanar features observed in other majority of views,
it can be removed by imposing a threshold on a similarity measure. An example
with N = 3 is shown in Fig. 1, which in the middle shows a view of the dices
with strong specular reflection, and on the right is the edge map of the image
by stacking the homography-transformed images from the rest two views.
3 Dot Identification and Dice Recognition
Given a segmented top face of a dice, a MSER detector [8] is exploited to extract
the dots from the segmented area because of its stability in rendering persistent
or slowly varying edges around the dots as illumination varies. The extraction
of MSER considers the set of all possible thresholds able to binarize an intensity
image I(x) into a binary image EtM (x),
EtM (x) =
{
1 ifI(x) ≤ tM
0 otherwise.
(1)
where tM is the threshold. A MSER is a connected region in EtM (x), with
little change in its size for a range of thresholds, extracted with a watershed
like segmentation algorithm. The homogeneous intensity regions extracted are
stable over a wide range of thresholds. The number of thresholds that maintain
the connected region similar in size is known as the margin of the region.
The dots on dices are blob-like objects and MSER usually anchors on the
boundaries of such objects, and thus the dots can be better located by MSER
compared to other interest region detectors. Fig. 3 shows the MSER regions
detected on dices. With some preprocessing, as histogram equalization, MSER
can achieve highly accurate identification rate. Fig. 3 shows a case with the
segmented top faces, and the regions detected by MSER before and after pre-
processing. Note that the MSER can detect incomplete or partial interest regions
which can be due to imperfect segmentation.
The dots identified by the MSER are clustered by k-means (k happens to
be the number of dices) subject to the constraints that the number of dots in
a cluster must be less than 7 and the distance between the farthest dots must
be less than the diagonal of the dice. The spatial distribution of the dots in
each cluster must be verified against the 6 known patterns. For example, 6-dot
must contain two parallel rows of dots and 3 dots each row. 5-dot must have two
Fig. 4. First column from the left is the training set with 3 illumination conditions;
the rest is the test set with 9 illumination conditions.
where H
(a,b)
Fi
is the homography that transforms the invariant features xbFi de-
tected by the invariant feature detector Fi in the image Ib to the corresponding
ones in Ia; HG is the ground-truth homography obtained by manual selected
correspondences between Ia are Ib, NFi is the number of features detected by
Fi, and a, b denote two different viewpoints.
Additionally, it is also desired that the correspondences from the feature-
based homographies can be consistent across different scales, as some features
change with scales. To investigate what features are better than others in ren-
dering desired homographies across illumination and scale, the original images
in 320×240 pixels are scaled down to smaller sizes, and the error is computed in
each size and averaged over the three illumination conditions in the training set.
Fig. 5 shows this comparison, the smallest scale with 128× 96 reveals relatively
Fig. 5. Normalized error of feature-based homography across scales and three illumi-
nation conditions.
5 Conclusion
A solution with invariant features across multiple views is proposed for dice
recognition under uncontrolled illumination. An extensive comparison on the
performance of various invariant feature detectors in rendering correct homogra-
phies under various test conditions and parameters shows that the multi-scale
Harris Hessian is the best, and better than the commonly selected SIFT features.
The homographies built on the multi-scale Harris Hessian features are exploited
to enhance the coplanar features and weaken the non-coplanar features on the
dices. This leads to an extraction of the coplanar features and the segmenta-
tion of the top faces of the dices even when the features, observed from some
viewpoint, are ruined by specular reflection. A MSER detector is applied for the
identification of dots on the top faces, followed by a pattern-specific confirma-
tion of the spatial distribution of dots. Experiments reveal that, although false
positives of dots are observed in few cases, as under strong or insufficient illumi-
nation, the numbers of the dots on the dices can still be recognized accurately
by the proposed solution.
References
1. Dufournaud, Y., Schmid, C., Horaud, R.: Matching images with different resolu-
tions. In: CVPR. pp. 1612–1618 (2000)
2. Fischler, M.A., Bolles, R.C.: Random sample consensus: A paradigm for model
fitting with applications to image analysis and automated cartography. Commun.
ACM 24(6), 381–395 (1981)
3. Hsu, G.S.J.: Advances in Theory and Applications of Stereo Vision, chap. 7: Stereo
Correspondence with Local Descriptors for Object Recognition, pp. 129–150. In-
Tech (2011)
4. Huang, K.Y.: An auto-recognizing system for dice games using a modified unsu-
pervised grey clustering algorithm. Sensors 8(2), 1212–1221 (2008)
5. Lai, Y.N., Hsu, S.T., Wang, C.Y., Tsai, M.T.: Method for recognizing dice dots.
U.S. Patent No. 2009/0263008 A1 (October 2009)
6. Lindeberg, T., G˚arding, J.: Shape-adapted smoothing in estimation of 3-d shape
cues from affine deformations of local 2-d brightness structure. Image Vision Com-
put. 15(6), 415–434 (1997)
7. Lowe, D.G.: Distinctive image features from scale-invariant keypoints. Interna-
tional Journal of Computer Vision 60(2), 91–110 (Month 2004)
8. Matas, J., Chum, O., Urban, M., Pajdla, T.: Robust wide baseline stereo from
maximally stable extremal regions. In: BMVC (2002)
9. Mikolajczyk, K., Tuytelaars, T., Schmid, C., Zisserman, A., Matas, J., Schaffal-
itzky, F., Kadir, T., Gool, L.V.: A comparison of affine region detectors. Interna-
tional Journal of Computer Vision 65(1-2), 43–72 (2005)
10. Mikolajczyk, K., Schmid, C.: A performance evaluation of local descriptors. IEEE
Trans. Pattern Anal. Mach. Intell. 27(10), 1615–1630 (2005)
11. Tuytelaars, T., Mikolajczyk, K.: Local invariant feature detectors: A survey. Foun-
dations and Trends in Computer Graphics and Vision 3(3), 177–280 (2007)
國科會補助計畫衍生研發成果推廣資料表
日期:2012/11/05
國科會補助計畫
計畫名稱: 快速辨識立體物件之機器人視覺技術 (II)
計畫主持人: 徐繼聖
計畫編號: 100-2221-E-011-057- 學門領域: 自動化系統整合技術
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
無 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
