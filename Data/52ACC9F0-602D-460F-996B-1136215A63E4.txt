II 
 
英文摘要 
As the technology and the application of the cloud computing are more and more mature and popular, 
data center not only is the core of the cloud computing but directly effects its performance. According to the 
suggestions from the major network manufactures, data center networks are constructed based on the 
currently mainstream input-buffered switches interconnected to form fat-tree topology and enables the 
service provided by the backend servers. But in the fat-tree topology the required link bandwidth is increased 
exponentially as aggregation level raising. Furthermore, the speed of the network processor in the 
input-buffered switch must be increased. Therefore, the scale or the performance of the data center network 
will be limited. 
To handle the above challenges, a fat-tree topology can be treated as a Benes network in terms of 
topology equivalence. Benes networks, that are able to realize all input-output permutations, have been 
widely used to construct switch fabrics, and therefore we might view a fat-tree topology as a switch fabric. 
The unique property of the scalable load-balanced switch achieves 100% throughput by all internal 
decomposed switching nodes periodically running predefined connection patterns despite traffic distribution 
of external network. Applying the schedule of the load-balanced switch on the internal switching nodes in a 
fat-tree topology, we do not need any network processors, because all internal switching nodes switch cells 
are based on predefined connection patterns. Since the schedule of the load-balanced switch only requires one 
cycle permutations, we can reduce not only the required bandwidth but also the complexity of the switching 
network from the Benes network to the banyan network by the bit reversal permutation. 
To realize the fundamental switching device that can be used to construct an NP-free fat-tree topology, 
we propose several design solutions to meet the practical challenges, complete the Verilog modules of the 
linecards and the switch fabrics, and develop a 18-layered-PCB and programmable hardware platform. 
Integrating the programmable PCBs of the Verilog modules of the linecards and the switch fabric respectively 
into a standard AdvancedTCA chassis and connecting with two external Intel network processor development 
platforms, we finally complete a prototype of the load-balanced switch. 
Keywords: high-speed switching, line cards, load balancing, data center networks, bit-reversal permutations 
 
IV 
 
4.1 集中式虛擬輸出佇列的複雜度限制了擴充性 ...................................... 25 
4.2 傳輸距離變異量和長傳輸延遲限制了交換效能 .................................. 27 
4.3 同步假設限制了從不同線卡到交換核心間傳輸距離的變異量 .......... 28 
4.4 傳統虛擬輸出佇列管理需要加速 .......................................................... 30 
4.5 順序錯亂的傳輸令封包重組困難重重 .................................................. 31 
4.6 故障的線卡造成永久無法復原的封包重組 .......................................... 32 
第 5章 系統實作 .................................................................................................. 34 
5.1 網路處理器開發平台 .............................................................................. 34 
5.2 線卡和交換核心通用可程控硬體平台 .................................................. 37 
5.2.1 直流電源模組 .......................................................................................... 39 
5.2.2 FPGA及周邊支援模組 .......................................................................... 41 
5.3 交換系統原型 .......................................................................................... 43 
第 6章 功能驗證 .................................................................................................. 45 
6.1 直流電源模組 .......................................................................................... 45 
6.2 負載平衡交換 .......................................................................................... 48 
6.3 網路處理器封包切割 .............................................................................. 50 
6.4 封包追縱 .................................................................................................. 53 
6.5 容錯系統 .................................................................................................. 56 
6.6 串流應用驗證 .......................................................................................... 59 
第 7章 結論 .......................................................................................................... 61 
參考文獻 ...................................................................................................................... 62 
附錄一 電路板堆疊設計 ...................................................................................... 63 
  
VI 
 
圖 4-1：  摺疊式布可夫范紐曼交換機的演進 ................................................... 25 
圖 4-2：  摺疊式布可夫范紐曼交換機中線卡和二級交換核心的連結 ........... 26 
圖 4-3：  摺疊式布可夫范紐曼交換機的運作示意 ........................................... 26 
圖 4-4：  交換層級管線化設計 ........................................................................... 27 
圖 4-5：  典型插卡型交換機因不同的線卡槽位所造成不同傳輸距離 ........... 28 
圖 4-6：  根據封包緩衝暫存器容量試算容許最大傳輸距離變異量 ............... 29 
圖 4-7：  結合平行鏈結串列實現虛擬輸出佇列及鏈結串列資料結構 ........... 30 
圖 4-8：  三階層虛擬輸出佇列設計 ................................................................... 31 
圖 4-9：  三階層虛擬輸出佇列運作示意圖 ....................................................... 31 
圖 4-10： 序重組緩衝器運作示意圖 ................................................................... 32 
圖 4-11： 線卡和交換機連接埠同步協定以接受線卡註冊及偵測線卡故障 ... 33 
圖 4-12： 容錯交換核心（４埠對稱式分時多工交換） ................................... 33 
圖 4-13： 容錯交換核心（３埠對稱式分時多工交換） ................................... 33 
圖 5-1：  Intel網路處理器開發平台，僅可作單機回路測試 ........................... 35 
圖 5-2：  CSIX Redirection 6層印刷電路板 ...................................................... 35 
圖 5-3：  整合自行開發的 CSIX重新導向印刷電路板，將網路處理器開
發平台整合到交換系統之中 ............................................................... 36 
圖 5-4：  線卡和交換核心共用的可程控硬體平台：十八層印刷電路板設
計 ........................................................................................................... 37 
圖表 5-5：電路板組裝正面圖及線卡模組交換功能示意 ................................... 38 
圖 5-6：  電路板組裝背面圖 ............................................................................... 39 
圖 5-7：  直流電源模組設計邏輯關係圖 ........................................................... 40 
圖 5-8：  電路板之直流電源模組實體配置和路由示意 ................................... 41 
圖 5-9：  FPGA以及周邊模組實體配置及互連關係示意圖 ............................ 42 
圖 5-10：  FPGA模組為電路板設計的核心，為了啟動和外接週邊模組，
所配置的驅動電壓及參考電壓 ........................................................... 43 
圖 5-11： 在標準先進電信運算架構機箱整合線卡和交換核心的交換機原
型 ........................................................................................................... 44 
圖 6-1： 直流電源轉換模組關係圖 .................................................................... 46 
圖 6-2： 電源供應器輸入電源 ............................................................................ 46 
圖 6-3： 3.3V直流電源模組輸出量測 ............................................................... 46 
圖 6-4： 5V直流電源模組輸出量測 .................................................................. 47 
圖 6-5： 2.5V直流電源轉換模組輸出量測 ....................................................... 47 
圖 6-6： 12V直流電源模轉換組輸出量測 ........................................................ 47 
VIII 
 
表格 
表 3-1：16×16位元逆轉排列輸入輸出對照表 .................................................... 13 
表 3-2：16×16位元逆轉排列拉丁方陣................................................................ 14 
表 3-3：16×16對稱式分時多工拉丁矩陣，level 2所需頻寬檢視 .................... 15 
表 3-4：16×16對稱式分時多工拉丁矩陣，level 1所需頻寬檢視 .................... 16 
表 3-5：16×16對稱式分時多工拉丁矩陣，level 0所需頻寬檢視 .................... 17 
表 3-6：16×16位元逆轉排列拉丁矩陣，level 2所需頻寬檢視 ........................ 18 
表 3-7：16×16位元逆轉排列拉丁矩陣，level 1所需頻寬檢視 ........................ 19 
表 3-8：16×16位元逆轉排列拉丁矩陣，level 0所需頻寬檢視 ........................ 20 
表 3-9：符合單調遞增之 16×16位元逆轉排列拉丁矩陣................................... 22 
 
2 
 
 
圖 1-1：一個 k（k=4）進元的 fat-tree拓撲[7] 
1.1.2 DCell 
  一個稱作 DCell 的可擴充以及容錯的資料中心網路架構在[12]中被提出。DCell 是一個被
遞迴定義的結構。在這樣的結構中，一個高層級的 DCell由很多低層級的 DCell所建構。在同
一個層級的 DCell彼此之間是完全連接（fully connected）的。特別的是 DCell0包含 n個伺服
器連接到n埠交換機，而且是一個建構區塊以建造更大的DCells。一個DCell1是由n+1個DCell0
所建構的（在圖 1-2中，我們展示了一個 n=4的例子，由 5個 DCell0建構出一個 DCell1）。相
似的道理可以透過合適數量的 DCellk-1建構出一個 DCellk（更詳細的部份請參閱[12]）。DCell
有許多卓越的特性。首先當節點鏈結數增加時，DCell 擴充性呈雙倍指數增加。第二，DCell
是一個容錯的系統，而且它的分散式容錯路由協定，即使在嚴重的鏈結或是節點失效依然可
以達到近乎最短路徑的效能。第三，相較於傳統以樹為基礎的架構，對於多樣性的服務 DCell
提供伺服器之間較高的通訊頻寬。然而 DCell也有下述的兩個缺點。首先在 DCell的連線是很
複雜的而且會導致高昂的連線成本。另一個則是每個伺服器需要有路由的能力而導致每個伺
服器的成本增加。 
 
圖 1-2：一個 n=4的 DCell1的網路架構[12] 
  
4 
 
 
圖 1-4：VL2的網路架構[14] 
1.2 動機 
  使用 fat-tree拓撲連結現有的 input-buffered交換節點所建造的資料中心網路的規模受限於網路
處理器的速度，所需的頻寬隨著層級匯流呈指數增加，因此資料中心的規模會受到局限。如在[7]
所建構的資料中心規模約可容納 10萬台伺服器。因此我們的第一個想法就是設法去移除網路處理
器技術對於網路規模的局限。依據文獻探討得知 fat-tree拓撲和摺疊後的 Benes網路是等效的，而
Benes 網路又廣泛應用於交換核心的設計，因此我們可以將整個資料中心的 fat-tree拓撲視為大型
交換核心。但緊接的問題是如何決定這樣大型交換核心的輸入/輸出配對？根據文獻探討負載平衡
交換機的交換核心只需要執行周期性的交換配對即可達到 100%交換效能。因此我們可以將 fat-tree
拓撲視為交換核心並套用負載平衡排程，進而將整個資料中心網路視為一個大型的負載平衡交換
機。然而進一步若考慮到頻寬使用的最佳化，負載平衡排程所需要的只是一個 one-cycle permutation，
因此我們可以用位元逆轉排列，以降低所需的頻寬以及交換網路的複雜度。最後我們想要實作出
一個這樣的交換機雛型。這個雛型不但是克服現實和理論的差距所實現的第一個負載平衡交換機
雛型，更可以據以實現一個低頻寬和網路複雜度的資料中心負載平衡交換網路。 
1.2.1 將資料中心網路視為負載平衡交換機 
  如果可以將整個資料中心網路視為一個大型的交換機，將原本 input-buffered 交換節點視
為大型交換機拆解成小的交換節點，那麼就可以省去網路處理器。我們已知負載平衡交換機
具備良好的擴充性，而且可以保證 100%的交換效能。那麼，我們嘗試將這樣的 fat-tree 拓撲
視為交換核心，將整個資料中心網路視為一個大型的負載平衡交換機。這樣的話，所有內部
交換的節點都不需要任何的網路處理器，僅僅最外層的交換節點（相當於是 fat-tree的葉子節
點），需要網路處理器為每個進來的封包查路由表的動作，以決定封包的輸出埠。現有的網路
處理器技術便足以處理未經匯集流量的負荷。 
  檢閱現有的文獻，我們知道 fat-tree拓撲和 Benes網路是等效的。因為 Benes網路可以實
現所有輸入輸出配對，所以常被用來實作交換核心。因此我們可以將 fat-tree拓撲視為資料中
心網路的交換核心。 
6 
 
  在第五章中，我們描述細部的系統設計和實作。這個雛型包含了三大部份：網路處理器、線
卡和交換核心。我們在這一章，說明網路處理器程式的架構以及如何將原本獨立的網路處理平台，
作額外的電路板的設計以整合到交換系統中。接著我們會介紹如何去實作一個線卡和交換核心可
以共用的電路板硬體平台。最後我們會分別就線卡和交換核心去介紹 Verilog 功能模組：CSIX 界
面控制器、交換核心 SerDes界面、虛擬輸出佇列、順序重組佇列、線卡錯誤偵測模組以及容錯交
換核心。 
  在第六章中， 我們針對實作出來的雛形去作個別以及整合功能驗證。電源是電路板穩定度最
重要的一環，不穩定的電源無法保證穩定的工作效能。我們會先從各別電源轉換模組去作電壓驗
證。再來會分別去檢視交換核心和虛擬輸出佇列的功能驗證。然後我們就網路處理器去作封包切
割的功能驗證，接著作封包追縱，交換機容錯熱插拔驗證。最後作串流應用驗證。 
  最後，我們在第七章總結我們的工作。 
  
8 
 
(4) 在高負載和爆發流量是有低平均延遲的表現: 當輸入爆發的流量，負載平衡可以很有效
率的降低延遲，而且負載平衡布可夫范紐曼交換機被證明在高負載的情形下，平均延遲
會收斂到輸出暫存交換機的表現。而且從模擬的結果來看，在高負載情形下，負載平衡
相對於衝突解析演算法，如 SLIP，表現的更有效。 
(5) 有效的暫存器使用率：當將負載平衡布可夫范紐曼交換機和相對應的輸出暫存交換機的
每個埠都配置相同有限數量的暫存器，負載平衡布可夫范紐曼交換機的封包遺失率比起
輸出暫存交換機來的小。 
2.1.2 Benes網路 
  Benes 網路[21]可以實現所有的輸入輸出配對排列，所以廣為被應用到商業交換機的交換
核心設計[19][20]。Benes網路是一個當 N是 2的指數次可重新排列網路例子。因此我們可以
建造一個由基礎的 2×2交換機所建造的一個可重新排列網路。根據 Clos網路，可以在第一級
和第三級使用 2×2交換機，在二級則包含兩個 N/2×N/2 交換機，如圖 2-2所示。我們可以進
一步將第二級 N/2×N/2 交換機使用相同的方式去作遞迴建造，建造出一個多級 2×2 交換機串
接的 Benes網路。圖 2-3顯示一個經由遞迴建造的 8×8 Benes網路。對於一個 N×N交換機，所
需要的 2×2交換機的個數為O(𝑁𝑙𝑜𝑔2𝑁)。 
2
N
2
N
2  x  2 2  x  2
2  x  22  x  2
22
NN
22
NN
 
圖 2-2：Benes網路的遞迴建造[21] 
1st
stage 2nd stage 3rd stage
2x2
2x2
2x2
2x2
2x2
2x2
2x2
2x2
2x2
2x2
2x2
2x2
2x2
2x2
2x2
2x2
2x2
2x2
2x2
2x2
4th stage 5th stage
 
圖 2-3：一個 8×8 Benes網路 
10 
 
 
圖 2-6：Fat-tree網路和摺疊 Benes網路是拓撲等效[18] 
2.2 將 Fat-tree拓撲視為交換核心實現無需網路處理器之交換網路 
  根據前一節所作的文獻探討，我們在這一節中提出一個將 fat-tree拓撲視為交換核心實現無需
網路處理器之交換網路。設備製造商建議用 fat-tree拓撲連結目前主流的 input-buffered交換節點建
構資料中心網路，如圖 2-7(a)。然而使用這樣的架構卻會受限於網路處理器的速度，而限制了資
料中心網路的規模。[18]提出 fat-tree網路和 Benes網路在拓撲上是等效的，如圖 2-7(b)。因為 Benes
網路可實現所有輸入輸出配對排列，廣泛應用於交換核心的實現[19][20]，如圖 2-7(c)。所以換句
話說，因為拓撲等效的關係，fat-tree網路也可以實現交換核心，如圖 2-7(d)。 
 
圖 2-7：(a)設備製造商建議用 fat-tree拓撲連結 input-buffered交換節點建構資料中心網路、(b)fat-tree網路和 Benes網
路在拓撲上是等效的、(c)Benes可以實現所有輸入輸出配對排列，廣泛應用於交換核心的實現、(d)因為拓撲等效，所
以 fat-tree 拓撲亦可以實現交換核心、(e)負載平衡交換機是一個可擴充且週期性執行事先定義交換配對二級交換的架
構，經證明可以達到 100%的交換效能、(f)應用負載平衡排程到原本的 fat-tree 拓撲連結 input-buffered 交換節點建構
資料中心網路，則內部的 input-buffered 交換節點不需要任何網路處理器，只要執行事先定義好的交換配對，就可以
實現 100%的交換效能 
12 
 
第3章 使用位元逆轉排列矩陣降低頻寬需求 
  誠如之前所述，目前網路製造商所建議的網路建構架構，本質上就是一個 fat tree的架構，而一個
二進位 fat tree的架構，根據最近的文獻探討[18]，等同一個 Benes Network，亦即任何一個網路看成一
個大型的交換機，因此可以套用負載平衡交換機的理論，引進負載平衡的特性，可以省去目前所有核
心路由器的網路處理器。 
  在負載平衡交換機的理論中，廣被應用的交換配對樣式，為對稱式分時多工輸出輸入配對。但是
更進一步的研究發現，只要滿足 one-cycle permutation的輸入輸出交換配對樣式，都可以應用在負載平
衡交換機中。在 fat-tree 架構中，以頻寬使用最佳化來作考量，我們設計出一個位元逆轉排列（Bit 
Reversal Permutation）。 
  在 fat-tree的架構中，位元逆轉排列的最大優點，在於用更聰明的方式配對，透過輸入埠彼此之間
分層級交錯交換的方式，讓每次經過上個層級的 link所需的個數降低，達到節省傳輸頻寬的功效。假
設 fat-tree有 m個層級，相較原始的 fat-tree頻寬需求，使用位元逆轉排列後，可於第 0層的連線可以
節省2−1的頻寬，第 1層的連線可以節省2−2的頻寬，……，第 m-3層的連線可以節省2−(m−3)+1的頻寬。
但是，第 m-2 和 m-1層的連線則無法節省頻寬。 
 
圖 3-1：一個 m層級的完整二進位 fat-tree拓撲及各層級連線所需頻寬 
  在一個 m 層級完整二進位 fat-tree拓撲中，如圖 3-1所示。利用位元逆轉排列去作封包的交換，
共可以省下的頻寬有 
 2 × 2𝑚−1 × 2−1 + 4 × 2𝑚−2 × 2−2 +⋯+ 2𝑚−2 × 2𝑚−(𝑚−3)−1 × 2−(𝑚−2) 
= 2𝑚−1 + 2𝑚−2 +⋯+ 2𝑚−(𝑚−2) 
= � 2(𝑚−𝑖)𝑚−2
𝑖=1
 
  負載平衡交換網路透過位元逆轉排列作封包交換，不僅可以利用負載平衡的特性，省去核心路由
器的網路處理器，更可以利用層級間流量平衡的方式，讓網路的連結頻寬大幅降低。 
14 
 
表 3-2：16×16位元逆轉排列拉丁方陣 
  Time 
slot 
Input    
port  
0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 
0 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 
1 8 9 10 11 12 13 14 15 0 1 2 3 4 5 6 7 
2 4 5 6 7 8 9 10 11 12 13 14 15 0 1 2 3 
3 12 13 14 15 0 1 2 3 4 5 6 7 8 9 10 11 
4 2 3 4 5 6 7 8 9 10 11 12 13 14 15 0 1 
5 10 11 12 13 14 15 0 1 2 3 4 5 6 7 8 9 
6 6 7 8 9 10 11 12 13 14 15 0 1 2 3 4 5 
7 14 15 0 1 2 3 4 5 6 7 8 9 10 11 12 13 
8 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 0 
9 9 10 11 12 13 14 15 0 1 2 3 4 5 6 7 8 
10 5 6 7 8 9 10 11 12 13 14 15 0 1 2 3 4 
11 13 14 15 0 1 2 3 4 5 6 7 8 9 10 11 12 
12 3 4 5 6 7 8 9 10 11 12 13 14 15 0 1 2 
13 11 12 13 14 15 0 1 2 3 4 5 6 7 8 9 10 
14 7 8 9 10 11 12 13 14 15 0 1 2 3 4 5 6 
15 15 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 
3.3 優化頻寬需求 
  一個 16×16 fat-tree網路如圖 3-2所示，我們可以注意到每個層級所需要的頻寬，呈指數增加。
在這一節中，我們將探討位元逆轉排列拉丁矩陣，可以有效的優化頻寬需求。在開始討論位元逆
轉排列拉丁矩陣前，我們先來檢視一個常被討論的對稱式分時多工交換配對（Symmetric Time 
Domain Multiplex，STDM）拉丁矩陣，如表 3-3。我們先聚焦在 level 2所需要的頻寬。以表 3-3
中，輸入埠 0和 1為例，塗上灰色的方格代表不會用到 level 2的連線，而白色的方格代表會使用
到 level 2的連線。輸入埠 0和 1，往輸出埠 0和 1都不需要用到 level 2的連線，所以輸出埠 0和
1都塗上灰色的方格。在全部 16個時槽中，時槽 2~14均需要同時到輸出埠 0和 1以外的輸出埠， 
所以需要二倍的頻寬。依此類推，其餘組的輸入埠（2~3， 4~5， 6~7， 8~9， 10~11， 12~13， 
14~15），也都有相同的現象。 
  再來我們聚焦 level 1並檢視其所需要的頻寬。以表 3-4中，輸入埠 0、1、2和 3為例，塗上
灰色的方格代表不會用到 level 1的連線，而白色的方格代表會使用到 level 1的連線。輸入埠 0、1、
2和 3，往輸出埠 0、1、2和 3都不需要用到 level 1的連線，所以輸出埠 0、1、2和 3都塗上灰色
的方格。在全部 16個時槽中，時槽 4~12均需要同時到輸出埠 0、1、2和 3以外的輸出埠，所以
需要四倍的頻寬。依此類推，其餘組的輸入埠（4~7、8~11、12~15），也都有相同的現象。 
16 
 
表 3-4：16×16對稱式分時多工拉丁矩陣，level 1所需頻寬檢視 
  Time 
slot 
Input    
port  
0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 
0 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 
1 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 0 
2 2 3 4 5 6 7 8 9 10 11 12 13 14 15 0 1 
3 3 4 5 6 7 8 9 10 11 12 13 14 15 0 1 2 
4 4 5 6 7 8 9 10 11 12 13 14 15 0 1 2 3 
5 5 6 7 8 9 10 11 12 13 14 15 0 1 2 3 4 
6 6 7 8 9 10 11 12 13 14 15 0 1 2 3 4 5 
7 7 8 9 10 11 12 13 14 15 0 1 2 3 4 5 6 
8 8 9 10 11 12 13 14 15 0 1 2 3 4 5 6 7 
9 9 10 11 12 13 14 15 0 1 2 3 4 5 6 7 8 
10 10 11 12 13 14 15 0 1 2 3 4 5 6 7 8 9 
11 11 12 13 14 15 0 1 2 3 4 5 6 7 8 9 10 
12 12 13 14 15 0 1 2 3 4 5 6 7 8 9 10 11 
13 13 14 15 0 1 2 3 4 5 6 7 8 9 10 11 12 
14 14 15 0 1 2 3 4 5 6 7 8 9 10 11 12 13 
15 15 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 
  最後，我們聚焦 level 0並檢視其所需要的頻寬。以表 3-5中，輸入埠 0、1、2、3、4、5、6
和 7為例，塗上灰色的方格代表不會用到 level 0的連線，而白色的方格代表會使用到 level 0的連
線。輸入埠 0、1、2、3、4、5、6和 7，往輸出埠 0、1、2、3、4、5、6和 7都不需要用到 level 1
的連線，所以輸出埠 0、1、2、3、4、5、6和 7都塗上灰色的方格。整個在全部 16個時槽中，時
槽 8均需要同時到另一組輸出埠：8、9、10、11、12、13、14及 15。所以需要八倍的頻寬。依此
類推，另一組的輸入埠(8~15)也都有相同的現象。 
  使用對稱式分時多工交換配對拉丁矩陣，可以說明為什麼每個層級所需要的頻寬，會呈指數
增加。 
  
18 
 
表 3-6：16×16位元逆轉排列拉丁矩陣，level 2所需頻寬檢視 
  Time 
slot 
Input    
port  
0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 
0 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 
1 8 9 10 11 12 13 14 15 0 1 2 3 4 5 6 7 
2 4 5 6 7 8 9 10 11 12 13 14 15 0 1 2 3 
3 12 13 14 15 0 1 2 3 4 5 6 7 8 9 10 11 
4 2 3 4 5 6 7 8 9 10 11 12 13 14 15 0 1 
5 10 11 12 13 14 15 0 1 2 3 4 5 6 7 8 9 
6 6 7 8 9 10 11 12 13 14 15 0 1 2 3 4 5 
7 14 15 0 1 2 3 4 5 6 7 8 9 10 11 12 13 
8 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 0 
9 9 10 11 12 13 14 15 0 1 2 3 4 5 6 7 8 
10 5 6 7 8 9 10 11 12 13 14 15 0 1 2 3 4 
11 13 14 15 0 1 2 3 4 5 6 7 8 9 10 11 12 
12 3 4 5 6 7 8 9 10 11 12 13 14 15 0 1 2 
13 11 12 13 14 15 0 1 2 3 4 5 6 7 8 9 10 
14 7 8 9 10 11 12 13 14 15 0 1 2 3 4 5 6 
15 15 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 
  再來我們聚焦 level 1並檢視其所需要的頻寬。以表 3-7中，輸入埠 0、1、2和 3為例，塗上
灰色的方格代表不會用到 level 1的連線，而白色的方格代表會使用到 level 1的連線。輸入埠 0、1、
2和 3，往輸出埠 0、1、2和 3都不需要用到 level 1的連線，所以輸出埠 0、1、2和 3都塗上灰色
的方格。我們會發現到會使用到 level 1的連線平均份配在全部 16個時槽中，每個時槽恰好分配到
3個。所以 level 1的頻寬，只需要三倍的頻寬。依此類推，其餘組的輸入埠（4~7、8~11、12~15），
也都有相同的現象。  
20 
 
表 3-8：16×16位元逆轉排列拉丁矩陣，level 0所需頻寬檢視 
  Time 
slot 
Input    
port  
0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 
0 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 
1 8 9 10 11 12 13 14 15 0 1 2 3 4 5 6 7 
2 4 5 6 7 8 9 10 11 12 13 14 15 0 1 2 3 
3 12 13 14 15 0 1 2 3 4 5 6 7 8 9 10 11 
4 2 3 4 5 6 7 8 9 10 11 12 13 14 15 0 1 
5 10 11 12 13 14 15 0 1 2 3 4 5 6 7 8 9 
6 6 7 8 9 10 11 12 13 14 15 0 1 2 3 4 5 
7 14 15 0 1 2 3 4 5 6 7 8 9 10 11 12 13 
8 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 0 
9 9 10 11 12 13 14 15 0 1 2 3 4 5 6 7 8 
10 5 6 7 8 9 10 11 12 13 14 15 0 1 2 3 4 
11 13 14 15 0 1 2 3 4 5 6 7 8 9 10 11 12 
12 3 4 5 6 7 8 9 10 11 12 13 14 15 0 1 2 
13 11 12 13 14 15 0 1 2 3 4 5 6 7 8 9 10 
14 7 8 9 10 11 12 13 14 15 0 1 2 3 4 5 6 
15 15 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 
 
 
 
圖 3-3：Fat-tree網路使用位元逆轉排列拉丁方陣後各個階級所需要的頻寬 
  
22 
 
表 3-9：符合單調遞增之 16×16位元逆轉排列拉丁矩陣 
  Time 
slot 
Input    
port  
0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 
0 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 
8 1 0 3 2 5 4 7 6 9 8 11 10 13 12 15 14 
4 2 3 1 0 6 7 5 4 10 11 9 8 14 15 13 12 
12 3 2 0 1 7 6 4 5 11 10 8 9 15 14 12 13 
2 4 5 6 7 2 3 1 0 12 13 14 15 10 11 9 8 
10 5 4 7 6 3 2 0 1 13 12 15 14 11 10 8 9 
6 6 7 5 4 1 0 3 2 14 15 13 12 9 8 11 10 
14 7 6 4 5 0 1 2 3 15 14 12 13 8 9 10 11 
1 8 9 10 11 12 13 14 15 4 5 6 7 2 3 1 0 
9 9 8 11 10 13 12 15 14 5 4 7 6 3 2 0 1 
5 10 11 9 8 14 15 13 12 6 7 5 4 1 0 3 2 
13 11 10 8 9 15 14 12 13 7 6 4 5 0 1 2 3 
3 12 13 14 15 10 11 9 8 2 3 1 0 6 7 5 4 
11 13 12 15 14 11 10 8 9 3 2 0 1 7 6 4 5 
7 14 15 13 12 9 8 11 10 1 0 3 2 5 4 7 6 
15 15 14 12 13 8 9 10 11 0 1 2 3 4 5 6 7 
 
 
 
圖 3-4：8×8 fat-tree網路符合單調遞增位元逆轉排列拉丁方陣 
 
24 
 
 
圖 3-6：(a) 8×8單調遞增位元逆轉排列拉丁方陣、(b) 8×8 fat-tree 網路使用單調遞增位元逆轉排列拉丁方陣所需的頻
寬、(c)使用 8×8 banyan網路實現 8×8單調遞增位元逆轉排列拉丁方陣、(d)使用 Benes網路不容易拆解各個 2×2交換
機的交換配對，但是可以利用等效的 banyan自我繞徑方法，決定各個 2×2交換機的交換配對 
  總結上述，一個符合單調遞增位元逆排列拉丁方陣（如圖 3-6(a)所示），不但可以降低所需的
fat-tree 頻寬（如圖 3-6(b)所示），更可以使用 banyan 網路利用自我繞徑實現符合單調遞增位元逆
排列拉丁方陣（如圖 3-6(c)所示）。此外可以將原本 Benes 網路的複雜度降低為 banyan 網路，並
可將原不容易拆解的 Benes 網路，透過 banyan 網路的自我路由（self-routing）決定每個對應拆解
的小交換機交換配對（如圖 3-6(d)所示）。 
  
26 
 
  然後我們又發現，對稱式分時多工（symmetric time-division multiplexing, STDM）交換配對有
一個很好的對稱特性。那就是當輸入埠 i連接到中間埠 j時，中間埠 j在同個時間也正好連接到輸
出埠 i。根據這個對稱特性，我們可以將疊在一起的交換核心再摺疊一次將原本集中式虛擬輸出佇
列分散到每張線卡上。摺疊式負載平衡布可夫范紐曼交換機的進化如圖 4-1 所示。經過二次摺疊
後，線卡和交換核心的實體連線如圖 4-2 所示。和原本的架構比較，負載平衡和布可夫范紐曼這
兩級交換核心依然存在。不同的地方在於，每張線卡必須要額外提供一組額外的連線以作為虛擬
輸出佇列的存取。如圖 4-3 所示，第一張線卡在第一個時槽作了負載平衡將封包送到最後一張線
卡的虛擬輸出佇列。在同一個時槽，最後一張線卡從虛擬輸出佇列取出一個封包，經由回授路徑
送回到第一張線卡輸出。封包透過回授路徑送到輸出埠的動作，實際上就是布可夫范紐曼級的交
換。 
 
圖 4-2：摺疊式布可夫范紐曼交換機中線卡和二級交換核心的連結 
 
 
圖 4-3：摺疊式布可夫范紐曼交換機的運作示意 
28 
 
4.3 同步假設限制了從不同線卡到交換核心間傳輸距離的變異量 
挑戰： 
  負載平衡布可夫范紐曼交換機架是基於同步交換的假設。在沒有輸入緩衝器的條件下，所有
的封包被期望可以同時抵達交換機的輸入埠。然而在實際環境下，來自不同線卡的封包都會經歷
不同的傳輸延遲。SERDES傳輸操作在時脈 3.125Gbps下，一個週期為 0.32ns。考慮到半週率以及
扣除0.12ns的上升時間，穩態時間僅有0.04ns。在FR4 PCB工具中的傳輸速率是166×10-12(s/inch)，
而允許的的傳輸距離變化被限制在 0.24 inch之內，相當於 0.612 cm。在大部份實際狀況中，這是
相當嚴格的。 
解決設計方案： 
  在 4.2 節中，我們提出了交換層級管線化的解決設計方案。因為交換層級管線化在交換核心
和 SERDES傳輸介面之間多加了封包緩衝暫存器，即可縮短交換配對的連結時間。但是，若封包
緩衝暫存器只允許暫存一個封包，封包還是要同時間到達，對於改善傳輸距離的變異量並沒有幫
助。因為早到的封包，並有多餘的空間可以等得晚到的封包。因此必須要增加封包緩衝暫存器的
容量讓早到的封包可以等待晚到的封包，再同時經過交換核心的交換。這樣方能增加傳輸距離的
變異量，以符合實際系統的需求。封包緩衝暫存器的容量該設計成容納幾個封包方能符合需求成
了我們下一個要解決的問題。 
  我們來看一個典型的機櫃插卡型交換機的例子，如圖 4-5 所示。線卡 B 位於距離交換核心最
遠的插槽。相反地，線卡Ａ則位於距離交換核心最近的插槽，並假設其距離可以近到忽略不計。
我們根據不同的封包緩衝暫存器的容量去試算系統的最大傳輸距離變異量，亦即為線卡Ｂ和線卡
Ａ之間所能容忍的最大傳輸距離差。 
 
圖 4-5：典型插卡型交換機因不同的線卡槽位所造成不同傳輸距離 
 
30 
 
4.4 傳統虛擬輸出佇列管理需要加速 
挑戰： 
  最經濟的的儲存元件是同步動態隨機存取記憶體（synchronous dynamic random access memory, 
SDRAM）而整合鍊結串列設計廣泛被應用在實現虛擬輸出佇列的功能。意即所有的記憶體被區分
為固定大小的記憶區塊，再透過鍊結串列將儲存封包的記憶區塊依先進先出的順序串成一列。結
合並行的鍊結串列即等同一個虛擬輸出佇列。儲存一個封包到虛擬輸出佇列需要一個記憶體讀出
和二個記憶體寫入的動作。但是這三個記憶體存取的動作是彼此相依的，因此無法利用交錯式模
式以降低系統的存取時間。依據 DDR333 同步動態隨機存取記憶體的規格（存取長度為八的模式
下），寫入一個封包和取出一個封包需耗時 396ns。然而，這個存取時間卻遠大於滿足 100%效能的
管線時脈週期，122ns。 
解決設計方案： 
  虛擬輸出佇列實作的概念如圖 4-7 所示。以這個例子來說，它包含了四個平行的鏈結串列，
其中每個鏈結串列用以串起到相同目的地封包。佇列描述器（queue descriptor）用以指向佇列的頭
和尾以及先準備好的儲存記憶區塊。透過這個佇列描述器可以最有效的方式去存入一個封包或取
出一個封包。 
 
圖 4-7：結合平行鏈結串列實現虛擬輸出佇列及鏈結串列資料結構 
  既然鏈結串列加入或移出需要三個相依的記憶體存取的動作，在同步動態隨機存取記憶體會
因為存取時間大於管線時脈週期。那麼將傳統的虛擬輸出佇列設計的中間插入高速但低容量的靜
態隨機存取記憶體（static random access memory，SRAM），如圖 4-8所示。一樣地，靜態隨機存
取記憶體和同步動態隨機存取記憶體被區分為固定大小的記憶區塊。同步動態隨機存取記憶體用
以儲存封包而靜態隨機存取記憶體則用以儲存鏈結到下一個記憶區塊的位址資訊。其運作的示意
如圖 4-9所示。同步動態隨機存取記憶體的每個記憶區塊為 80位元組，透過存取長度 8的設定，
共可分為 4 mega的區塊。靜態隨機存取記憶體恰好可定址 4 mega，彼此之間恰好建立 1對 1映射。
一旦取得靜態隨機存取記憶體的鏈結區塊位址，便可得知封包儲存在同步動態隨機存取記憶體的
位址。透過這兩組記憶體的平行運作，便可將寫入一個封包和取出一個封包存取時間由原本 396 ns
大輻降低為 114 ns，符合管線時脈週期 122 ns的需求。 
32 
 
如圖 4-10所示。順重組緩衝器是配置一連續串流的記憶區塊，根據封包的輸入線卡去索引佇列描
述器，再由封包序號取得位址，將封包寫入靜態隨機存取記憶體對應的記憶區塊中。 
 
圖 4-10：順序重組緩衝器運作示意圖 
4.6 故障的線卡造成永久無法復原的封包重組 
挑戰： 
  雖然摺疊式負載平衡布可夫范紐曼交換機使用對稱式分時多工交換配對可以降低交換機硬體
複雜度，但若是單純地使用分時多工交換配對卻可能帶來額外的問題。任一線卡的故障會造成整
個系統的封包都無法重組的問題，因為被交換到位於故障線卡中的虛擬輸出佇列的封包永遠都無
法抵達最終目的地線卡。 
解決設計方案： 
  我們需要一個同步偵測協定以偵測出系統中的故障線卡。一旦發現故障線卡，容錯式分時多
工交換核心就必須避開交換封包到故障的線卡。圖 4-11展示著線卡和交換機間的同步偵測協定有
限狀態機。當新的線卡完成註冊的狀態，交換核心便會更新容錯交換核心，以利來自新註冊線卡
的封包交換。同樣地，若是交換核心的任一個埠的同步偵測狀態進入到 Idle，意謂著偵測到故障
的線卡，此時便需要更新容錯交換核心以避開交換封包到此故障的線卡。 
34 
 
第5章 系統實作 
  為了實現一個完整的交換系統原型，除了完整而堅實的理論基礎、克服實務的挑戰、提出可行的
解決設計，並落實設計方案。根據現行系統的需求，我們設計出一個交換系統原型，分別包含三大子
系統：封包處理子系統、線卡子系統以及交換核心子系統。 
  封包處理子系統主要的工作針對進到交換網路的封包去作查表的工作以決定封包的目的地，將封
包分割成固定長度區段送到交換網路以利同步交換，將從交換網路收到的固定長度區段重組回原本的
封包，然後再送到網路的下一級或是最終目的地。在這個子系統，我們使用現有的 Intel網路處理器開
發平台，並在硬體上作必要的修改，加入新設計的電路板，將原本單機迴路測試的 CSIX 信號旁路並
導到交換機（見 5.1節）。除此之外，我們亦在這個開發平台上開發所需的軟體以滿足系統查表，封包
分割，封包重組，封包轉送的功能。 
  線卡子系統和交換核心子系統，必須落實第四章所討論的設計方案。其中包含系統硬體設計，線
卡功能 Verilog模組，以及交換核心功能 Verilog模組。經過系統分析後，我們可以實作一個通用可程
控硬體平台（見 5.2 節），透過載入線卡功能或是交換核心功能 Verilog 模組，便可分別實現線卡或是
交換核心子系統的功能。電路板的設計是根據標準 AdvancedTCA 的規格來設計，包含直流電源模組
（見 5.2.1節），FPGA以及程控模組（見 5.2.2節），封包輸入輸出界面及管線時脈模組，靜態記憶體
模組，以及動態記憶體模組。 
  載入子計畫四所開發的功能 Verilog 模組，將線卡子系統和交換核心子系統整合到標準
AdvancedTCA機櫃。完成我們的交換系統原型（見 5.3節）。 
5.1 網路處理器開發平台 
  我們首先處理的工作就是封包處理子系統，打算使用 Intel網路處理器開發平台作為基礎，但
是，這個開發平台的設計僅能支援單機回路測試，如圖 5-1 所示。Ingress processor 根據 loopback
電路板所提供的參考時脈（圖 5-1中的信號０）送出 CSIX信號（圖 5-1中的信號１），而 egress 
processor根據 loopback電路板提供的參考時脈（圖 5-1中的信號０），收下由 ingress processor送
出再經過 loopback電路板作回路（圖 5-1中的信號２）的 CSIX信號（圖 5-1中的信號３）。換句
話說，依據現有的開發平台，我們無法將信號導入到線卡子系統進行封包的交換。我們必須針對
閞發平台去作一些修改，方能將現有網路處理器開發平台整合到我們設計的交換系統。 
 
36 
 
  完成這樣的電路板是一件知易行難的挑戦，因為網路處理器的開發平台主機板以及 loopback
子板，都已是成品，新設計的實體尺寸和元件稍有不合，便無法完全契合，信號便無法將 CSIX
信號及參考時脈導入/出線卡子系統。最終，我們克服了這個挑戰，完成了 CSIX 重新導向印刷電
路板，並順利地整合到網路處理器開發平台中，如圖 5-3所示。Ingress processor還是依據 loopback
電路板提供的參考時脈（圖 5-3 中的信號０）送出 CSIX 信號（圖 5-3中的信號１）併另一路參考
時脈（圖 5-3中的信號０）經過我們設計的電路板導到線卡子系統。而由線卡子系統導出的 CSIX
信號（圖 5-3中的信號３）和參考時脈則透過重新導向電路板導到 egress processor。至今，我們已
完成封包處理子系統硬體部份的整合。再下一節我們就要著眼於封包處理子系統軟體部份的設
計。 
 
圖 5-3：整合自行開發的 CSIX重新導向印刷電路板，將網路處理器開發平台整合到交換系統之中 
  
38 
 
 
圖表 5-5：電路板組裝正面圖及線卡模組交換功能示意 
40 
 
 
圖 5-7：直流電源模組設計邏輯關係圖 
除錯隔離設計 
  除錯是系統開發十分重要的一環，若是沒有良善的隔離設計，一來出現問題時，無法除
錯，二來當其中某一個轉換模組供給的電壓不穩定而且超出電子元件所能接受的額定電壓時，
可能造成該元件永久無法正常工作，而且難以界定受影響的範圍。 
  為此，我們大量使用大功率金屬氧化物半導體場效電晶體（Power MOSFET）用以隔離所
有的轉換模組，如圖 5-7所示。如此，便可隔離掉與前後級相關聯的變數，針對每個模組獨立
地作測試調整。再逐級將各個轉換模組整合起來。 
安全性及熱插拔 
  一個完善的設計，安全性的考量永遠是不可或缺的。因此在-48V 電源輸入後，設計了一
個熔絲保護電路。當電路板的某些模組出現非預期故障，電源過載後，熔絲斷以避免電源過
載所造成系統故障的風險。 
  隨著交換系統以及流量愈來愈龐大，無須全機關機作電路板檢修更換的熱插拔設計亦愈
顯重要。為了要實現熱插拔設計，首要工作即是隔開瞬間插入電路板所造成的突波干擾，待
電路板完全推入機箱而且電壓供給穩定後，啟動第一級電壓轉換模組（5V和 3.3V轉換模組）。
由第一級電壓轉換模組輸出帶動第二級電壓轉換模組（12V、2.5V、1.8V、1.5V、1.25V、0.75V），
進而驅動 FPGA由 CF載入程式完成啟動。 
  落實直流電源模組的邏輯設計於實體電路板的配置和路由示意如圖 5-8。-48V 直流電源
後端接頭送到熔絲保護模組（圖 5-8路由 1），再送到熱插拔控制模組（圖 5-8路由 2）。待熱
插拔偵測電壓穩定且無突波後，便啟動第一級電壓轉換模組（圖 5-8路由 3）。5V轉換模組輸
出，分別驅動二組 12V 及 2.5V 轉換模組（圖 5-8 路由 4）。相同地，3.3V 轉換模組輸出分別
驅動二組 1.8V，1.5V，1.25V和 0.75V轉換模組（圖 5-8路由 5）。 
 
42 
 
 
圖 5-9：FPGA以及周邊模組實體配置及互連關係示意圖 
  要驅動 FPGA 的核心，電路板必須提供 1.5V 直流電源（圖 5-10 電源 0），以驅動 FPGA
內部的核心電路。緊接著是提供 2.5V直流電源（圖 5-10電源 1），驅動 FPGA內部輔助電路，
此時 FPGA便以準備讀入儲存在 CompactFlash中的程式。預存在 CompactFlash程式的讀取，
經 3.3V 直流電源（圖 5-10 電源 2）驅動的石英振盪器透過 Xilinx System ACE（Advanced 
Configuration Environment）元件讀出再程控 FPGA（圖 5-10信號 3），以實現線卡或是交換核
心的功能。 
  為了實現線卡或是交換核心的功能，系統須支援不同工作位準的周邊模組，所以在 FPGA
設計上必需針對不同的互連周邊模組配置不同的驅動電壓或是參考電壓，如圖 5-10 所示。為
了和網路處理器透過 CSIX連接，電路板必須提供 FPGA 3.3V直流電源（圖 5-10電源 2）。為
了封包暫存，系統分別需要靜態記憶體及動態記憶體，分別輔以不同的參考電壓。因此電路
板也必須提供 FPGA上述的電源 1.8V、1.5V、2.5V、0.75V和 1.25V的直流電源（圖 5-10電
源 5、1、6和 4）。 
44 
 
 
圖 5-11：在標準先進電信運算架構機箱整合線卡和交換核心的交換機原型 
  
46 
 
 
圖 6-1：直流電源轉換模組關係圖 
  我們首先檢視圖 6-1中第一級直流電源轉換模組 3.3V和 5V的直流電源轉換模組輸出表現。
我們於圖 6-3中檢視 3.3V的直流電壓輸出，並於圖 6-4中檢視 5V的直流電壓輸出。其輸出電壓
值非常穩定，均在額定輸出的 10%以內。 
 
圖 6-2：電源供應器輸入電源 
 
圖 6-3：3.3V直流電源模組輸出量測 
  在確保第一級直流電源轉換輸出的穩定後，接下來我們將檢驗第二級的直流電源轉換輸出。
我們先檢視經由 5V轉換後的 2.5V以及 12V輸出。於圖 6-5我們檢視了 2.5V直流電源的輸出。
於圖 6-6中，我們檢視了 12V直流電源的輸出。 
48 
 
 
圖 6-8：1.5V直流電源轉換模組輸出量測 
 
 
圖 6-9：1.25V直流電源轉換模組輸出量測 
 
圖 6-10：0.75V直流電源轉換模組輸出量測 
 
6.2 負載平衡交換 
在  負載平衡布可夫范紐曼交換機中，最重要的部份，就是負載平衡交換核心和布可夫范紐曼
交換核心。負載平衡交換核心最主要的工作就是將進到線卡的流量均勻地分配到虛擬輸出佇列。
因為透過這一級的工作，可以得知進到每個虛擬輸出佇列的流量都是均勻的，所以我們就可以透
過布可夫范紐曼的拆解，得到一組輸入輸出的配對，透過這組交換配對將封包送抵目的地線卡。 
50 
 
 
圖 6-12：布可夫范紐曼交換核心，將均勻分散的流量封包交換到最終的輸出埠 
6.3 網路處理器封包切割 
  為了要作到 100%的交能效能，因此負載平衡交換機的基本假設是同步交換，然而在真實的網
路環境卻必須面臨封包大小不一的複雜環境，因此我們必須要透過網路處理器將大小不一的封包
切割成相同大小的封包，以利內部作同步傳輸。在這一節中，我們主要檢視網路處理器的封包切
割表現。為了測試我們的系統，我們事先用 sniffer軟體錄下了大小分別為 142 bytes和 542byte的
ping封包，分別如圖 6-13 和圖 6-15 所示。然後再使用 sniffer 軟體將些封包送到網路處理器，經
過網路處理器每 64 bytes切割，再送到線卡。我們在線卡 CSIX界面上用 chipscope攔下網路處理
器送入線卡的封包。當輸入的封包是 142 bytes時，我們從 CSIX界面上看到 3個區段，如圖 6-14
所示。而當輸入的封包是 142 bytes時，我們則從 CSIX界面上可看到 9個區段，如圖 6-16所示。 
完整的實驗記錄發佈於 
1. YouTube（http://www.youtube.com/watch?v=DUeDCp8THeU）或關鍵字搜尋「Segmentation 
Demonstration」。 
2. http://gibbs.ee.nthu.edu.tw/implement.htm#1，點選影片 2：Segmentation Demonstration 
52 
 
 
圖 6-15：Sniffer送入線卡 542-byte ping封包 
 
圖 6-16：網路處理器將 542-byte ping封包，以每 64 byte為單位切成 9個區段 
  
54 
 
 
圖 6-18：在 11.0.0.101電腦上去對 10.0.0.102電腦作 ping測試 
 
圖 6-19：網路處理器針對進來的封包作查路由表的工作，目標往 10.0.0.102的封包被送到線卡 1，網路處理器的埠 1 
56 
 
6.5 容錯系統 
  為了穩定性的考量，交換機必須可以偵測到錯誤的線卡，一旦線卡發生錯誤時，立即更換交
換核心的交換配對，以避免將封包送到錯誤的線卡上。在這一節中，我們將檢視系統可以動態偵
測到線卡狀態的異動（由原本的二張線卡，逐步加入線卡數目到 4張），並自動更新交換核心的交
換配對。在一開始系統只有兩張交換核心和兩張線卡。由圖 6-22可以看到每張卡片上都是亮著 2
個藍色LED，表示系統偵測到的線卡狀態都是一致的，而綠色LED則是表示系統當時的交換配對。
我們在設計這個系統時，有引入熱插拔設計，因此可以在系統運轉時，插入第三張線卡，如圖 6-23
所示。圖 6-24則是顯示系統已偵測到第三張線卡，並更換新的交換配對。我們於圖 6-25插入第四
張線卡，系統偵測到第四張線卡，並更換新的交換配對，如圖 6-26所示。 
完整的實驗記錄發佈於 
1. YouTube（http://www.youtube.com/watch?v=Igv-Xxlv1oY）或關鍵字搜尋「Arbitrary-linecards 
Demostration of the Load-balanced Switch Prototype」。 
2. http://gibbs.ee.nthu.edu.tw/implement.htm#1，點選影片 5：Switching Demonstration for Different 
Configuration 
 
圖 6-22：在初始狀態時，交換系統僅有兩張交換核心和兩張線卡 
 
58 
 
 
圖 6-25：在支援熱插拔功能的系統中推入第四張線卡 
 
圖 6-26：當系統偵測到第四張線卡，便會更新交換配對（藍色 LED代表現有線卡，綠色 LED代表目前執行交換配對） 
  
60 
 
 
圖 6-28：影音封包經過二級交換抵達線卡 
 
圖 6-29：經封包重組後，在另一端的電腦還原為影音資料 
  
62 
 
參考文獻 
[1] S. Brin and L. Page, “The anatomy of a large-scale hypertexual web search engine,” Computer Networks and ISDN 
Systems, vol. 30, pp. 107–117, April 1998. 
[2] F. Schmuck and R. Haskin, “GPFS: A shared-disk file system for large computing clusters,” in Proceedings 1st USENIX 
Conference on File and Storage Technologies (FAST’02), Monterey, CA, USA, January 28–30, 2002. 
[3] S. Ghemawat, H. Gobioff, and S.-T. Leung, “The Google file system,” ACM SIGOPS Operating Systems Review, vol. 5, 
pp. 29–43, December 2003. 
[4] G. DeCandia, D. Hastorun, M. Jampani, G. Kakulapati, A. Lakshman, A. Pilchin, S. Sivasubramanian, P. Vosshall, and W. 
Vogels, “Dynamo: Amazon’s highly available key-value store,” in Proceedings ACM Symposium on Operating Systems 
Principles (SOSP’07), Stevenson, WA, USA, October 14–17, 2007. 
[5] SGI Developer Central Open Source Linux XFS, “XFS: A high-performance journaling filesystem.” 
http://oss.sgi.com/projects/xfs/. 
[6] J. Dean and S. Ghemawat, “MapReduce: Simplified data processing on large clusters,” in Proceedings 6th USENIX 
Symposium on Operating Systems Design and Implementation (OSDI’04), San Francisco, CA, USA, December 6–8, 2004. 
[7] M. Al-Fares, A. Loukissas, and A. Vahdat, “A scalable, commodity data center network architecture,” in Proceedings ACM 
Special Interest Group on Data Communication (SIGCOMM’08), Seattle, WA, USA, August 17–22, 2008. 
[8] Emerson Network Power, “Energy Logic: Reducing Data Center Energy Consumption by Creating Savings that Cascade 
Across Systems,” available at http://www.liebert.com/common/ViewDocument.aspx?id=880. 
[9] Rad Stanojevic and Robert Shorten, “Distributed Dynamic Speed Scaling,” in Proceedings International Symposium on 
Information Theory (INFOCOM’10). 
[10] Ramya Raghavendra, Parthasarathy Ranganathan, Vanish Talwar, Zhikui Wang, and Xiaoyun Zhu, “No “Power” Struggles: 
Coordinated Multi-level Power Management for the Data Center,” in Proceedings International Conference on 
Architectural Support for Programming Languages and Operating Systems (ASPLOS’08). 
[11] C. E. Leiserson, “Fat-Trees: Universal Networks for hardware-efficient supercomputing,” IEEE Transactions on 
Computers, vol. 34, pp. 892–901, October 1985. 
[12] C. Guo, H. Wu, K. Tan, L. Shi, Y. Zhang, and S. Lu, “DCell: A scalable and fault-tolerant network structure for data 
centers,” in Proceedings ACM Special Interest Group on Data Communication (SIGCOMM’08), Seattle, WA, USA, 
August 17–22, 2008. 
[13] C. Guo, G. Lu, D. Li, H. Wu, X. Zhang, Y. Shi, C. Tian, Y. Zhang, and S. Lu, “BCube: A high performance, servicecentric 
network architecture for modular data centers,” in Proceedings ACM Special Interest Group on Data Communication 
(SIGCOMM’09), Barcelona, Spain, August 17–21, 2009. 
[14] A. Greenberg, J. R. Hamilton, and N. Jain, “VL2: A scalable and flexible data center network,” in Proceedings ACM 
Special Interest Group on Data Communication (SIGCOMM’09), Barcelona, Spain, August 17–21, 2009. 
[15] 
 
“Virtex-Ⅱ Pro and Virtex-Ⅱ Pro X FPGA UserGuide,” Retrieved from http://www.xilinx.com/support/documentation/user 
_guides/ug012.pdf. 
[16] 
 
C.-S Chang, D.-S. Lee and Y.-S. Jou, “Load balanced Birkhoff-von Neumann switches, part I: one-stage buffering,” 
Computer Communications, Vol. 25, pp. 611-622, 2002. 
[17] “Double Data Rate (DDR) SDRAM,” Retrieved from http://cache.micron.com/Protected/expiretime=1307382702;badurl=a 
HR0cDovL3d3dy5taWNyb24uY29tLy80MDQuaHRtbA==/13adaa55bdd6ee3ceaf5559d6ea50410/1/16/512Mb_DDR.pdf. 
[18] J. Duato, S. Yalamanchili and L. Ni, Interconnection Networks: An Engineering Approach”, Morgan Kaufmann (pubs.), 
2003. 
[19] 1.Sapountzis, G.,  Katevenis, M., “Benes switching fabrics with O(N)-complexity internal backpressure,” IEEE 
Communications Magazine, pp. 88 - 94, Vol. 43, Jan. 2005. 
[20] Cisco Sytems, Inc, “Switch Fabric,” Retrieved fromhttp://www.cisco.com/en/US/docs/routers/crs/crs1/8_slot/system/descri 
ption/hq6345_4.pdf. 
[21] C. S. Change and D. S. Lee, Principles, Architectures and Mathematical Theories of High Performance Packet Switches, 
NTHU Academic Press, 2008. 
[22] CSIX, CSIX-L1: Common switch interface specification-L1, Retrieved from http://www.oiforum.com/public/documents/cs 
ixL1.pdf. 
 
CAM350 V 9.1 : Mon May 03 09:05:16 2010 - (Untitled)
64
CAM350 V 9.1 : Mon Apr 12 09:10:06 2010 - (Untitled)
66
CAM350 V 9.1 : Wed Mar 31 02:44:43 2010 - (Untitled)
68
CAM350 V 9.1 : Wed Mar 31 02:39:58 2010 - (Untitled)
70
CAM350 V 9.1 : Wed Mar 31 02:40:57 2010 - (Untitled)
72
CAM350 V 9.1 : Wed Mar 31 02:42:10 2010 - (Untitled)
74
CAM350 V 9.1 : Wed Mar 31 02:44:11 2010 - (Untitled)
76
CAM350 V 9.1 : Wed Mar 31 02:36:27 2010 - (Untitled)
78
CAM350 V 9.1 : Wed Mar 31 02:37:14 2010 - (Untitled)
80
CAM350 V 9.1 : Wed Mar 31 02:38:18 2010 - (Untitled)
82
CAM350 V 9.1 : Wed Mar 31 02:39:07 2010 - (Untitled)
84
國科會補助計畫衍生研發成果推廣資料表
日期:2011/09/15
國科會補助計畫
計畫名稱: 總計畫:高速封包交換機之研究
計畫主持人: 張正尚
計畫編號: 97-2221-E-007-103-MY3 學門領域: 網路
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
研究成果獲得旺宏金矽獎銅獎 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
