  
行政院國家科學委員會補助專題研究計畫 ■ 成 果 報 告   
□期中進度報告 
 
 
以非監督式學習為基礎的家庭相片簿管理系統之研究 
 
計畫類別：■ 個別型計畫  □ 整合型計畫 
計畫編號：NSC97－2221－E－194－053－ 
執行期間：97年 08月 01日至 98年 07月 31日 
 
計畫主持人： 林維暘 
共同主持人： 
計畫參與人員：劉文廣，林政憲，鍾幸夫，黃嘉吉，龔士捷 
 
 
成果報告類型(依經費核定清單規定繳交)：■精簡報告  □完整報告 
 
本成果報告包括以下應繳交之附件： 
■赴國外出差或研習心得報告一份 
□赴大陸地區出差或研習心得報告一份 
□出席國際學術會議心得報告及發表之論文各一份 
□國際合作研究計畫國外研究報告書一份 
 
處理方式：除產學合作研究計畫、提升產業技術及人才培育研究計畫、列
管計畫及下列情形者外，得立即公開查詢 
          ■涉及專利或其他智慧財產權，■一年□二年後可公開查詢 
          
執行單位：國立中正大學資訊工程學系 
 
中   華   民   國 九 十 八 年 十 月 十一  日 
 
 
  ii 
研究計畫英文摘要： 
 
A traditional face recognition system requires training a set of data usually, and then the testing 
data can be classified through this trained system. In general, the training data are some simple or 
noncomplex photos so that recognition system may classify them effectively. A supervised learning 
system is too waste of time and may not suit to all situations such as various database or training 
data. For this reason, the destination of our research is to build an unsupervised system that 
classifying face without providing training data manually. 
This research exploits an algorithm of data analysis and attaches some hidden parameters to 
the information produced from data. The system does not know how to get the hidden parameters 
but classifies them utilizing the distribution of probability. This approach is not the similarity 
comparison between two faces but exploits the integrated information to determine. Afterward the 
experiments utilize the approach of combining two feature extractions so that obtain more 
appropriate features. In the first instance, we use the face database (Caltech 101) to estimate our 
system, and then we use the living photos to estimate for the more complex photos. Finally, the 
photos searched from Google are tested; these photos are more complex than the common living 
photos. In the final part of this report, we discuss the effect of various situations and various face 
variations. 
 
Keywords: Family photo album, unsupervised learning, face classification. 
 
 
 2 
貳、 相關研究探討 
 
一、 非監督式學習 
本論文將會使用非監督式學習 (unsupervised learning) 為架構，系統不需要給予
訓練樣本就可以對相片做分類或辨識，或是在有訓練樣本的情況下，並沒有給予訓
練樣本任何的限制與標籤，系統可以根據沒有限制的訓練資料去訓練出一個辨識
器，稱為非監督式學習。而本論文將會以非監督式學習為主題，使用者只需要提供
最後分類結果中有多少個類別 (subjects)，並不需要針對訓練樣本及分類過程中提供
任何的資料。 
在這方面的文獻中，接下來將會以影像分類的研究上做探討，在這方面目前大
都針對相片中包含物件做分類的研究，例如飛機或汽車等物件。Unsupervised learning
除了針對相片中物件做分類的研究外，還有針對不同領域中所拍攝的相片做辨識，
像是細胞或雷達所拍攝照片等等。Arman [4]等人針對細胞相片來做辨識，利用原始
相片去轉成的灰階 (gray) 相片及一次微分 (deviation) 的相片作為基礎，建立起
pyramid node linking來辨識細胞的位置。Fjortoft等人[15]利用高空拍攝的雷達照片
作為資料，利用 hidden Markov model和 generalized mixture estimation作為辨識的基
本架構，將原始雷達照片中強度分佈拆解成不同的機率分佈組合。Kersten 等人[24]
則針對高空俯看圖作辨識，要達到的是將所拍攝的森林場景，依年代切割成不同區
塊，可以觀察出森林在不同時間點下的變化，在辨識的過程裡，是透過Wishart辨識
器來達成 unsupervised learning。由上述得知在不同的領域下 unsupervised learning是
一個很重要的議題。 
而針對影像中的物件做分類的文獻中，Weber等人[26, 38]提出了一篇關於非監
督式學習的方法，利用 Burl等人[7]所提出的方法針對訓練樣本去建立物件模型，用
聯合機率分佈 (joint probability density) 來表示物件的位置及形狀，測試資料將會根
據不同的物件模型來做辨識，找尋最相近的物件模型。Fergus等人[14]提出的理論也
是使用 Burl等人[7]的方法建立物件模型，用機率模型來表示照片中的特徵所呈現的
特性，像是特徵的大小、位置與向量，將會利用貝氏模型 (Bayesian model) 來表示，
其模型中的參數會利用最大似然法 (maximum likelihood) 來求得，測試資料也是根
據不同的物件模型做辨識。 
Hofmann[19, 20]提出 probabilistic latent semantic analysis (PLSA) 的架構，起先
此模型的目的，在於抽取文件裡的關鍵詞。而在利用於影像辨識的領域中，以 bags of 
keypoints為基礎，由相片中所有特徵分佈來分類，bags of keypoints由Csurka等人[10]
提出，而 PLSA模型應用在影像辨識領域中則由 Sivic等人[39]提出，在從人臉與相
片之間加上一個隱藏的標籤，將相片中的特徵分佈拆解成相片與隱藏標籤，和隱藏
標籤和特徵的機率分佈所組合。 
針對 PLSA模型做修改的文獻裡，Liu等人[28, 29]中加入位置的資訊來更新整
個模型，除了將物件分類外，也可以偵測物件的位置。Blei[5]提出 LDA (Latent 
Dirichlet Allocation)，從 PLSA概念衍伸出去，建構在 Dirichlet分佈中，將相片機率
分佈拆解成 subjects與人臉的機率組合。Fei-Fei等人[12]提出方法以 LDA為主體，
從 LDA模型裡加入類別的參數，重新去取得新的模型，跟之前不同的情況是，一個
類別會訓練出一個模型，當測試資料進入時，則是根據哪個模型比較適合表示，藉
此來分類。 
本論文將會以 PLSA 做為分類的依據，而在使用 PLSA 模型在各個領域已經有
許多的研究，像是文件分類、網頁探勘及語音辨識技術上。在影像處理方面的研究
上，利用 PLSA模型作為基礎已經有許多文獻提出，Monay等人[37]利用 RGB直方
圖和特徵擷取來取得可以表示相片的特徵，並將這些特徵作為 PLSA 的分類依據。
 4 
使用者會先挑選出一個人，系統會找出粗略的分類結果中包含同一個人的相片給使
用者選擇，使用者會挑出正確的相片後，不正確的相片系統會放入下一次疊代，直
到全部的人臉都有挑選到才結束。 
雖然是依據相片中的人臉做分類，也有許多文獻利用相片中許多額外的資訊，
例如衣服特徵或是照相時間。Gallagher 等人[16]提出利用一張相片裡有二人以上的
情況，來增加辨識的效能，通常在生活相片裡有多個人，通常他們都有某些關係，
像是朋友，親屬，工作上的夥伴，則下次一起出現的機會很高。Anguelov 等人[3]
提出加入人臉下方區域所包含的資訊，並透過馬可夫隨機域 (Markov Random Field) 
來將這些資訊結合進分類結果中。Song等人[40]加入衣服的資訊，透過牛頓-拉福生
演算法 (Newton-Raphson) 來取得利用人臉和衣服辨識結果的權重。Yeh等人[17]則
加入拍照地點和時間的資訊。Zhao 等人[36]提出一個自動分類的系統，利用拍照地
點、時間、衣服和人臉的資訊，先設定過濾條件將同一地點或是同一區段時間的相
片歸類成同一族群，使用二維隱馬爾可夫模型 (2D hidden Markov model) 來做辨識。 
 
四、 特徵擷取 
本系統從相片中手動圈選人臉的位置後，接下來從人臉的位置上找尋有效的特
徵，以利於使用辨識用的模型，假使挑選到不佳的特徵擷取方式，導致在人臉中取
得的特徵之間變異性不高，則會大大影響其辨識結果。因此，需要慎重挑選特徵擷
取方法。 
這方面在影像處理領域中已經有十幾年的研究並有學者提出多項有效的方法。
主要方法可以依結果分成二種，取得的特徵以位置表示或區域表示。以取得位置為
特徵的文獻裡，Crowley等人[8, 9]提出了特徵會在不同的 scale中極值的位置，建立
了 difference of Gaussian (DoG)的概念。Lowe[30]則使用了 DoG並且提出了 SIFT特
徵表示方法。Harris等人[18]提出的文獻裡，其特徵點位在圖片中 intensity變化較大
的位置上，利用不同的矩陣對圖片做 convolution。Mikolajczyk等人[32, 34]提出的方
法中，利用 Harris所提出的方法，再加上尺度空間 (scale-space) 找尋特徵。 
以取得區域為特徵的文獻裡，Tuytelaars[42]等人提出 EBR (Extrema-based 
Region)，利用取得 corner的方法，再根據 corner取得二條邊，結合整張圖片所有 corner
所取得的邊，可以取得某些區域作為特徵。Matas[31]提出MSER (Maximally Stable 
Extremal Region)，利用 intensity變化所形成的區塊，達到穩定的特性就將它認為特
徵。Kadir等人[23]提出的方法中以圖形的 intensity為根據，形成的 probability density 
function (PDF)來決定橢圓區域，稱為 Salient region。 
根據Mikolajczyk等人[35]針對特徵擷取的方法去做比較，MSER計算時間與其
他區域特徵擷取方法較短，在本研究裡特徵擷取的步驟中，將會使用 DoG及MSER
來從人臉擷取特徵。 
 
 
參、 使用 PLSA架構之非監督式人臉分類系統 
 
一、 系統架構 
本論文中的人臉分類系統是針對人臉當作分類的依據，此系統架構如圖一，此
架構是參考 Sivic等人[39]提出的文獻中所使用的架構，可以分成以下三項： 
[A] ：feature extraction and representation 
[B] ：visual word dictionary formation  
[C] ：PLSA model 
當此系統有一組包含人臉的進入時，將會透過[A]，在人臉的區域中找尋特徵並
 6 
                 
(a)                                  (b) 
 
(c) 
圖二：Difference of Gaussian 範例圖。(a)為原圖。(b)為結果。(c)表示此圖建立的尺度空間 
(scale-space)。 
 
在一張圖片中擷取出特徵點位置後，接下來會計算其特徵點所代表的特徵向
量。在這裡會使用 SIFT[30] (Scale-Invariant Feature Transform) 來計算正規化後的區
域所對應的特徵向量。SIFT主要是利用圖片中某一位置鄰近的區域資訊，用來表示
這一位置的特徵值，它的特徵本身擁有大小不變性 (scale invariance) 和抵抗背景雜
訊的特性。其方法對於每一個點會先去計算它周遭位置的梯度 (gradient) 大小和方
向。然後將這些資訊統合起來當作此位置的特徵向量。 
在 SIFT 方法中計算圖片中每個像素梯度 (gradient) 大小和方向主要是透過式
3.2與式 3.3來計算。其中 ,i jA 表示圖片中位置 ( , )i j 。 
gradient magnitude
2 2
, 1, , , 1= ( ) ( )i j i j i j i jA A A A+ +− + −  (3.2) 
gradient orientation , 1, , 1 ,=a tan 2(( , )i j i j i j i jA A A A+ +− −  (3.3) 
 
2. Maximally Stable Extremal Region (MSER) 
MSER[31]是以圖片中某些區域作為特徵，方式是根據圖片中 intensity變化，從
這些變化中觀察到較穩定 (stable) 的區域來當作特徵，在這裡達到穩定的條件下是
指，圖片根據一連串的 intensity做處理時，假使有個區域對於 intensity的變化不受
影響，仍舊保持這個區域的大小，就可以稱這個區域為擁有穩定的特性。MSER 的
做法如下： 
 
(a) 設定一連串的由小到大的門檻值將圖片二值化處理。經過二值化的步驟後，透
過較小的門檻值 所得到的結果是幾乎全白的圖片，慢慢將門檻值調高後，圖片
 8 
程裡會使用 k-means clustering。 
(c) 經過 k-means clustering後，所產生的中心位置的值將他儲存起來，這些中心位置
的集合就稱為 visual word dictionary，如同圖五。在本論文實驗中的設定是 1000
個 visual words。也就是利用 DoG 所取得的特徵經過這步驟後所形成的 visual 
words個數為 1000 (M1＝1000)，利用 MSER所形成的 visual words個數也為 1000 
(M2＝1000)。 
 
 
圖四：visual word dictionary formation流程圖 
 
 
圖五：visual word dictionary示意圖。每一個小方塊為一個 visual word。 
 
四、 PLSA Model 
在這個系統裡將會使用 PLSA (Probabilistic Latent Semantic Analysis) 來做為分
類的架構。PLSA模型由 Hofmann[19]所提出，以統計學為基礎，當時是根據關鍵字
來分類大量的文章為目的，使用文章中出現的文字去歸類整合，進而得到整篇文章
的關鍵字。Sivic等人[39]利用了 PLSA模型於物件辨識中，將 Hofmann利用的文章
用相片來取代，文章中的單字用相片裡的特徵來取代，而文章中的關鍵字則是用相
片裡的主題來表示。而在本系統將會針對人臉來做分類。PLSA 的基本架構圖如圖
六所示，該架構會使用到表格 ( , )n w d ，去計算每張相片中不同 visual word的個數，
 10 
機率， ( | )k iP z d 表示 kz 在 id 中的機率分佈。根據上面的敘述，可以將整個 PLSA模型
先描述成以下三項[20]： 
(a) 根據 ( )iP d 選擇相片 id  
(b) 根據 ( | )k iP z d 選擇類別 kz  
(c) 根據 ( | )j kP w z 選擇 visual word jw  
接下來將以上三個步驟利用機率模型來表示，如式 3.5所示。 
 
( , , ) ( ) ( , | )i k j i k j iP d z w P d P z w d=  
( ) ( | , ) ( | )i j k i k iP d P w z d P z d=  
( ) ( | ) ( | )i j k k iP d P w z P z d=  
(3.5) 
 
接下來針對所有的 kz 將上列式子改寫成式 3.6。能夠描述成式子 (3.5) 與 (3.6) 
之前，必須要先假設 id 和 jw 是獨立的。針對所有的 kz ，其 id 和 jw 都和它有條件機率
的關係。並且 ( | )j iP w d 為所有 K個 ( | )j kP w z 凸性組合 (convex combination)。 
 
1
( , ) ( ) ( | ) ( | )
K
j i i j k k i
k
P w d P d P w z P z d
=
=∑
 
(3.6) 
 
為了去求得分類的結果，將 objective function作為依據。在這裡 ),( ji dwn 為一開
始所統計的 co-occurrence table， ( | )j kP w z 和 ( | )k iP z d 是想要求得的解答。為了能夠去
求得式子 (3.7) 的最佳解，將透過 expectation maximization (EM) 演算法來求得結
果。 
 
( , )
1 1
( , ) i j
M N
n d w
i j
j i
P d w
= =
∏∏
 
( , )
11 1
( ) ( | ) ( | )
i jn d wM N K
i j k k i
kj i
P d P w z P z d
== =
 
=   
 
∑∏∏
 
(3.7) 
 
在利用 EM求解的過程裡，主要透過最大化 log likelihood來得到解答。如式 3.8
所示。 
 
( , )
( , ) 1 1
arg max log ( , ) i j
j i
M N
n d w
j i
P w d j i
P w d
= =
 
 
 
 
∏∏
 
( | ), ( | ) 1 1 1
arg max ( , ) log ( ) ( | ) ( | )
j k k i
M N K
i j i j k k i
P w z P z d j i k
n d w P d P w z P z d
= = =
 
=   
 
∑∑ ∑
 
(3.8) 
 
式 3.9為推導過程： 
 12 
1 1 1
( , ) ( | , ) lo g( , , )
M N K
i j k j i j k i
j i k
n d w Q z w d P w z d
= = =
∑∑ ∑
 
1 1 1
( , ) ( | , ) log ( )
M N K
i j k j i i
j i k
n d w Q z w d P d
= = =
=∑∑ ∑
 
1 1 1
( , ) ( | , ) lo g( | )
M N K
i j k j i k i
j i k
n d w Q z w d P z d
= = =
+∑∑ ∑
 
1 1 1
( , ) ( | , ) log ( | )
M N K
i j k j i j k
j i k
n d w Q z w d P w z
= = =
+∑∑ ∑
 
(3.12) 
 
在(3.12)中 ( )iP d 和 id 的長度成正比，跟要求的參數 ( | )k iP z d 和 ( | )j kP w z 為獨立關
係，所以可以省略，接下來使用 Lagrange乘數法 (Lagrange Multiplier Method)，設
定二種 Lagrange 乘數法中的參數 kτ 和 iρ ，將二種已知的限制， 1
( | ) 1
K
k i
k
P z d
=
=∑
和
1
( | ) 1
M
j k
j
P w z
=
=∑
加入(3.12)，然後將其改寫成如式 3.13。 
 
1 1 1
( , ) ( | , ) lo g( | )
M N K
i j k j i k i
j i k
n d w Q z w d P z d
= = =
∑∑ ∑
 
1 1 1
( , ) ( | , ) log ( | )
M N K
i j k j i j k
j i k
n d w Q z w d P w z
= = =
+∑∑ ∑
 
1 1
1 ( | )
N K
i k i
i k
P z dρ
= =
 
− −  
 
∑ ∑
 
1 1
1 ( | )
K M
k j k
k j
P w zτ
= =
 
 − −
 
 
∑ ∑
 
(3.13) 
 
透過 Lagrange乘數法將(3.13)最大化，可以從過程中得知式 3.17與式 3.18二個
特性。 
 
( | ) ( , ) ( | , )
M
k i i j k i j
j
P z d n d w Q z d w
=1
∝∑
 
(3.14) 
( | ) ( , ) ( | , )
N
j k i j k i j
i
P w z n d w Q z d w
=1
∝∑
 
(3.15) 
 
因為 ( | , )k j iQ z w d 和 ( | ) ( | )j k k iP w z P z d 成正比，而根據式 3.14與式 3.15中 ( | )j kP w z 和
( | )k iP z d 又和 ( | , )k j iQ z w d 有著正比的關係，因此可以根據這項特性從 ( | , )k j iQ z w d 去計
算最後所要求的參數 ( | )j kP w z 和 ( | )k iP z d 。 
在本論文中，會先給予所要估計的參數 ( | )j kP w z 和 ( | )k iP z d 初始值，一開始將會
設定成均勻的分佈。而接下來在 E-step 中，利用之前設定的 ( | )j kP w z 和 ( | )k iP z d 再根
據貝式定理 (Bayas formula) 去計算 kz 的 posterior，如式 3.16。在這裡 l表示所有的
k，這裡因為要針對 ( | , )k i jP z d w 更新，會利用到所有的 ( | )j kP w z 和 ( | )k iP z d ，因此用 l暫
時取代 k來表示 z的標籤。 
 14 
現出每個實驗中的分類正確率。 
 
(a) Sivic[39]的實驗中，不同的 Label表示不同的物件，#images表示每個物件
資料庫中的張數。文獻裡所使用的 PLSA架構是類似的，所使用的方法為 Harris affine 
detector[33]與MSER[31]，而本論文使用的是 DoG[30]與MSER。其中最後的比較如
表一。 
 
表一：Sivic[39]文獻中的實驗結果與本論文中的結果。其中%表示分類正確率，#表示錯誤張
數。 
Ex Categories Sivic[39] Our results 
  % # % # 
A 2,3 ub 100 1 100 1 
B 1-3 ub 100 2 99 15 
C 1-3 97 56 93 137 
D 1-4 98 70 92 257 
E 1-4 + bg 78 931 55 2050 
F 1-5, 7-8 + bg 59 1515 57 2161 
 
(b) 在第二個實驗中，主要是針對人臉分類的實驗，利用的資料庫為 Caltech 101
中的人臉資料庫，並將會從不同的 subjects 個數及所對應的張數去探討，在這個實
驗中將分成 5個實驗 (ABCDE)，例如實驗 C，是用 3個 subjects，分別為 10、10和
5 張去做分類的實驗。以下將會描述每一個實驗中使用的資料，及综合結果，表示
於表二及表三。 
(A) 2 subjects，40 images (20, 20 images) 
這是本論文中最基本的實驗，利用 2個人相片去分成 2類， 2K = 。挑選相片的
方式是選擇 Caltech 101 人臉資料庫裡編號在最前面的二組資料。由實驗結果得知
分類結果中有 1張錯誤分類，沒有完全分類正確。 
(B) 3 subjects，60 images(20, 20, 20 images) 
實驗 B是將實驗 A擴展到 3個 subjects，但固定每一個人相片的張數，都是同
樣的 20張，挑選方式是由 Caltech 101人臉資料庫中，張數大於 20張，並且編號在
前的 3組資料，其錯誤分類的張數與實驗 A相同 2張分類錯誤。 
(C) 3 subjects，50 images(20, 20, 10 images) 
實驗 C是為了去觀察不同人，相片張數的不同會不會影響結果，其實驗過程中
參數設定跟實驗 B 相同，但將第三人的相片拿掉 10 張，其錯誤分類的結果也上升
許多，可以看出不同人之間相片張數對於分類正確率影響很大。 
(D) 26 subjects，430 images 
由於實驗 C所得到的結論，因此將實驗擴展到人臉資料庫中的第一部分，將同
一個人只有一張相片的先排除，再將剩餘的相片作為實驗用資料，所以共有 26 個
subject，每一個 subject 有 5 到 25 張不等的相片，共有 430 相片。其分類正確率為
73.26%，當 subject個數越多，其分類正確率會越低。 
(E) 31 subjects，435 images 
將實驗擴展到 Caltech 101中的人臉資料庫全部相片，將實驗 D的資料加上一個
subject只有一張相片的情況。因此共有 435張相片，其分類正確率與實驗 D相差不
多。 
由實驗 A-E最後呈現的分類結果來觀察，可以看出有些 subject很清楚地被分類
 16 
words dictionary外，可以從系統裡特徵擷取的步驟著手，取得不受到表情變化的特
徵，才能夠讓 PLSA模型得到更佳的機率分佈結果。 
 
伍、 結論 
在本研究中，主要模擬之前學者所提出的系統流程架構，並在此架構裡結合了不同
的特徵擷取方法：DoG和MSER。而本論文的主要用意，是在於希望能夠在沒有訓練樣
本的情況下，也可以有效地達到分類人臉的目的，藉此來跟傳統人臉辨識流程有所區別。
在本論文最主要的部份，使用了 PLSA 的技巧，根據機率分佈作為分類的依據，實驗資
料使用了 Caltech 101人臉資料庫、一般相片及 Google搜尋引擎裡的相片。在使用 Caltech 
101人臉資料庫的結論裡，可以觀察出 subjects的個數及 visual word dictionary的大小對
於分類結果有影響。而在一般相片及 Google搜尋引擎裡的相片的實驗中，針對人臉沒有
限制的情況下，可以察覺出特徵擷取對於整體系統的分類正確率，仍舊有很大的改善空
間。 
由全部的實驗結果可以得知，針對沒有事先給予標籤，沒有訓練資料的人臉相片，
並在人臉有限制的條件下，使用 PLSA 架構在人臉分類上可以達到不錯的效果，並且只
需要提供 subjects 的個數，不需要提供訓練資料。接下來的工作除了針對表情變化能夠
達到更佳的分類結果外，並希望可以連提供 subjects 的個數都可以省略，達到全自動化
的效果。 
 
陸、 參考文獻 
[1] L. Zhang, Y. Hu, M. Li, W. Ma, and H. Zhang, "Efficient Propagation for Face Annotation in Family 
Albums," Proceedings of the ACM Conference on Multimedia, pp. 716-723, 2004. 
[2] L. Zhang, L. Chen, M. Li, and H. Zhang, "Automated Annotation of Human Faces in Family Albums," 
Proceedings of the ACM Conference on Multimedia, pp. 355-358, 2003. 
[3] D. Anguelov, K.-c. Lee, S. B. Gokturk, and B. Sumengen, "Contextual Identity Recognition in Personal 
Photo Albums,"  Proceedings of IEEE International Conference on Computer Vision and Pattern 
Recognition, pp.1-7, 2007. 
[4] F. Arman and J. A. Pearce, "Unsupervised Classification of Cell Images Using Pyramid Node Linking," 
IEEE Transactions on Biomedical Engineering, vol. 37, pp. 647-650, 1990. 
[5] D. M. Blei, A. Y. Ng, and M. I. Jordan, "Latent Dirichlet allocation," Journal of Machine Learning 
Research, vol. 3, pp. 993-1022, 2003. 
[6] Bosch, A. Zisserman, and X. Munoz, "Scene Classification via PLSA," Proceedings of European 
Conference on Computer Vision vol. 4, pp. 517-530, 2006. 
[7] M. C. Burl, M. Weber, and P. Perona, "A Probabilistic Approach to Object Recognition Using Local 
Photometry and Global Geometry," Proceedings of European Conference on Computer Vision, pp. 628–641, 
1998. 
[8] J. L. Crowley, "A Representation for Visual Information," Carnegie Mellon University Institute of Robotics, 
1982. 
[9] J. L. Crowley and A. C. Parker, "A Representation for Shape Based on Peaks and Ridges in the Difference 
of Low-pass Transform," IEEE Transactions on Pattern Analysis and Machine Intelligence vol. 6, pp. 
156-170, 1984. 
[10] G. Csurka, C. Bray, C. Dance, and L. Fan, "Visual categorization with bags of keypoints," Proceedings of 
European Conference on Computer Vision, pp. 1–22, 2004. 
[11] M. Dengpan, R. Schweer, and A. Rothermel, "Automatic Databases for Unsupervised Face Recognition,"  
Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp.90-90, 2004. 
[12] L. Fei-Fei and P. Perona, "A Bayesian Hierarchical Model for Learning Natural Scene Categories,"  
Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition, vol.2, 
pp.524-531, 2005. 
[13] R. Fergus, L. Fei-Fei, P. Perona, and A. Zisserman, "Learning object categories from Google's image 
search,"  Proceedings of the IEEE International Conference on Computer Vision vol.2, pp.1816-1823 Vol. 
2, 2005. 
[14] R. Fergus, P. Perona, and A. Zisserman, "Object Class Recognition by Unsupervised Scale-Invariant 
Learning,"  Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern 
Recognition, vol.2, pp.264-271, 2003. 
