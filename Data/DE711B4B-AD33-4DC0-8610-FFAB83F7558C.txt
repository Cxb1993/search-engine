 II
一、中英文摘要 
1. 中文摘要 
隨著生產技術不斷地創新改進下，不僅大幅縮短產品產出時間，產出數量亦隨之
暴增。面對此趨勢下，為解決生產技術所帶來之效應，產品品質檢驗技術勢必要獲得有
效提升，加快檢驗速度及準確性，才足以因應此問題。本研究目的在運用機器視覺技術，
結合共變異矩陣之特徵值（Eigenvalue）及自相關係數之不變性（Invariance property），
建立一套有效的二維物件之視覺辨識系統。本研究經由兩階段特性擷取（Feature 
extraction），強化特徵值之能力，改善以往較難克服之物件變化辨識問題。研究內容主
要探討二維圖形之不變性，針對在不同旋轉角度（Rotation）、縮放比例（Scale），及隨
機位移（Random translation）之二維圖形下，將二維圖形先作二值化，藉由型態學
(Morphologic)擷取物件臨界點(Critical point)之座標值，利用共變異矩陣(Covariance 
matrix)之理論求得物件邊界之特徵值，透過抽樣取一固定數量之特徵值，計算其自相關
係數（Autocorrelation coefficient），所得之自相關係數向量與標準樣本之自相關係數向
量進行相似性量測（Minimum distance measure）及灰關聯度（Gray relation grade）之分
析，另外再應用倒傳遞網路（Back propagation network）學習標準樣板之自相關係數向
量並分類，進而判定其歸屬。依據實驗結果，觀察目前所測試 100 張標準樣本中，灰關
聯度分析辨識率可達 96.8％（最小距離法為 95.7%），倒傳遞網路更可高達 99.5％（最
小距離法為 97.2%）辨識率之成效，顯示分類效果良好。本研究主要成果已發表於國際
期刊論文(Expert System With Applications – SCI)一篇。 
 
關鍵字：物件辨識, eigenvalues of covariance matrix, 自相關係數, 特性擷取 
 1
二、報告內容 
1. Background and Research Objective 
Computer vision has extensively adopted in industry for the last two decades. It enhances 
productivity and quality management, and is flexible, efficient, inexpensive, and reliable. The 
applications of computer vision mainly relate to part inspection and measurement (e.g., food, 
wood, electronic components, glass, textile, machine parts, printing products and integrated 
circuits) and defect classification (Noble 1995, Malamas et al. 2003). In this area, the process of 
using computer vision usually performs in the following sequence: data acquisition, part 
recognition, feature extraction and measurement and decision-making. Ullman (1996) noted that 
object recognition is the most difficult of these tasks owing to the varying positions, orientations 
and scales of objects. Hence, the recognizing objects, even when they are translated, rotated, or 
scaled, is of priority concern issue. In particular, using computer vision for object recognition 
plays a critical role that first determines which process plan should be adopted for the 
manufactured work piece in a flexible manufacturing system (FMS), assembly line or robot 
system (Haralick and Shapiro, 1992).  
2. Literature Review 
Many methods have been developed for invariant object recognition. Sarkodie-Gyan et al. 
(1996) presented an object recognition scheme for inspecting in manufacturing engine 
components using a fuzzy membership function. Kreutz et al. (1996) proposed a framework of a 
translation and scale-invariant image recognition system with high-order autocorrelation features. 
 3
constraint for finding point correspondences such that the problem was formulated by 
minimizing the predefined energy function through a Hopfield network. Huang et al. (2005) 
proposed a scheme based on independent component analysis (ICA) for object recognition with 
affine transformation and for affine motion estimation between video frames. Recently, 
Sookhanaphibarn and Lursinsap (2006) proposed a method for extracting the invariant features 
of a color image based on the concept of principal component analysis and a competitive 
learning algorithm. Yu and Bennamoun (2007) developed two complete sets of similarity 
invariant descriptors using Fourier-Mellin transform and the analytical Fourier-Mellin transform 
frameworks, and then adopted 2D-PCA to simplify the invariant descriptor for face recognition. 
Artificial Neural Networks (ANNs) are computational modeling tools that have emerged in 1990 
and found extensive applications in many disciplines for modeling complex real-world problems. 
A variety of areas have adopted ANN as a tool to solve complex problems (Smith and Gupta, 
2000). ANNs may be defined as structures comprised of densely interconnected adaptive 
processing elements (neurons or nodes) that are capable of performing parallel computations for 
data processing and knowledge representation (Hecht Nielsen, 1990; Schalkoff, 1997). The 
attractiveness of ANNs can be accredited to their remarkable information processing 
characteristics of the biological system such as nonlinearity, high parallelism, robustness, fault 
and failure tolerance, learning, ability to handle imprecise and fuzzy information, and their 
capability to generalize. There are at least five reasons of using ANNs with such characteristics: 
(i) nonlinearity allows better fit to data, (ii) noise-insensitivity provides accurate prediction when 
the data with uncertainty and measurement errors, (iii) high parallelism implies fast processing 
and hardware failure-tolerance, (iv) learning and adaptivity allow ANNs to modify their internal 
structures in response to changing environment, and (v) generalization enables applications of 
 5
 
3.1 Image acquisition and segmentation 
Image acquisition refers to acquiring the digital information of objects through a digitizer. 
Once images have been acquired, image segmentation is performed to separate the digitized 
object from the background. Image segmentation attempts to derive effective information from a 
digital image. A conventional segmentation method is thresholding, in which each pixel is 
 7
 
            
(a) Original object    (b) Dilation   (c) Subtraction: B - A 
Figure 2. Boundary extraction using morphological operation 
3.3 Feature extraction 
The proposed feature extraction process derives the transition, rotation and scaling-invariant 
features based on the obtained sequential boundary. This project represents the boundary by the 
smaller eigenvalue of covariance matrices to obtain the transition invariant property; uses a 
re-sampling process to obtain scaling invariant property; and employs the transformation of 
autocorrelation to ensure the orientation-free property. 
3.3.1 Boundary representation using eigenvalue of covariance matrices 
As a curvature-based boundary descriptor developed by Tsai (1999), the eigenvalue of the 
covariance matrix method adopts the smaller eigenvalue of covariance matrices to estimate the 
curvature of a two-dimensional boundary point over a small region of support.  Let the 
sequential n digital pixels describe a boundary P, 
      P= { pi= (Xi, Yi), i=1, 2, 3, …, n}      (3) 
where pi+1 is adjacent to pi on P.  Additionally, let NS(pi) denote a small boundary segment, 
 9
lengths of the object, respectively. The λS approximates to zero when point pi is on a straight line 
or on a flat curve. The smaller the radius of a circle, the larger the λS obtained, and vice versa. In 
particular, the λS of a corner point on the boundary segment is generally a local maximum, which 
is a peak when representing the boundary as a 1D sequence, while the λS of the boundary points 
gradually decreases away from the corner.  Using the region of support s=30, the boundary 
representation of the digital object shown in Figure 2 is illustrated in Figure 3. 
 
Note: there are 912 boundary points (s=91) in total.  
Figure 3. Boundary representation using the smaller eigenvalue of covariance matrices 
3.3.2 Re-sampling 
The boundary representation derived previously is scale-dependent when using the same 
starting-point. A digital object with different scales is converted into different numbers of 
eigenvalue, λS. Figure 4 illustrates the boundary representation of the original object in Figure 2 
 11
profile of boundary representation as shown in Figure 5(c). After re-sampling the boundaries of 
the objects with different scales, the re-sampled boundary then has the same number of pixels. 
An example is also shown in Figure 5(d) to demonstrate the boundary representation of the 
object, originally presented in Figure 4, after re-sampling to n=300  
 
Note: There are 445 boundary points (s=44). 
Figure 4. Boundary representation with 1/4 scale 
3.3.3 Autocorrelation 
Autocorrelation coefficients have been extensively applied as features for 1D and 2D signal 
classification in various applications such as character recognition, texture classification, face 
detection and recognition, signal classification and so forth (Popovici and Thiran, 2004). 
Autocorrelation coefficient provides important information about matching pattern in time-series 
data (Makridakis and Wheelwright, 1978). The formula of autocorrelation coefficient of time lag 
K is as follows: 
 13
3.4.1 Minimum Euclidean Distance 
Calculating the minimum Euclidean distance between patterns is a simple but useful pattern 
recognition method. Assuming patterns A (standard pattern), and B (test patterns) with n feature 
elements denoted as 
A= [a1, a2, …, an], 
B= [b1, b2, …, bn]. 
Euclidean Distance between A and B is calculated as follows. 
Distance（A, B）= ∑
=
−
n
i
ii ba
1
2)(     (8) 
Hence, the index of the targeting pattern with the minimum distance to the testing pattern is 
determined as the class of the testing pattern belongs. 
3.4.2 Backpropagation Neural Network 
Backpropagation neural networks (BPN) are the most widely used ANN networks and are 
considered as the work horse of artificial neural networks (Rumelhart et al., 1986). As shown in 
Figure 7, a BPN is a multilayer feed-forward network consisting of (1) an input layer with nodes 
representing input variables to the problem, (2) an output layer with nodes representing the 
dependent variables, and (3) one or more hidden layers containing nodes to help capture the 
nonlinearity in the data. The neurons between layers can be fully or partially interconnected 
between layers with weight (wij). The data are fed forward from the input layer, through hidden 
 15
and backpropagates errors into the networks. These extracted features are continuously fed into a 
BPN and the network will self-adjust until a set of weights (wij) with pre-specified error (SSE or 
MSE) is reached. Then these weights are stored and used for recognition later on.  Figure 7 also 
represents the architecture of the network for object recognition, in which ρi is the element of 
feature vectors with predetermined dimension n, and ai = 0 or 1 is the output with the dimension 
of number of recognizing objects m. 
When using BPN for object recognition, the processes, learning, testing, and validation, are 
three required stages. First, the collected standard 2D object boundary features are divided into 
60%, 20%, and 20% for the use of learning, testing and validation (Basheer and Hajmeer, 2000). 
Then, the learning data set is fed into different structures of BPN, and is tested with the 20% 
testing data, in order to prevent from overtraining or under training. After learning and testing, 
the validation data (20%) are used to determine a proper BPN structure with the best recognition 
performance. 
For the training process, the parameters including learning rate, momentum, types of 
transfer function, and structure of networks (number of hidden layer, and number of nodes in 
hidden layers) must be determined in advance. In this project, the nonlinear Sigmoid function is 
the most commonly used transfer function and is chosen in both hidden and output layers as 
below. 
( ) xexf −+= 1
1                                   (9) 
 17
Patterns 51 to 100 were acquired using real objects. Ten additional test patterns with various 
positions, rotations (30°, 60°, 90°, 150°, 200°, 300°) and scales (1/4 and 1/8) were created for each 
object. Figure 9 displays the 10 test patterns generated using standard Pattern 10. Hence, 1000 
test patterns were created in total. All standard and test patterns were then segmented by a 
pre-determined threshold and stored as binary images. 
   
 
Figure 8. Standard patterns 
 19
 3 227 0.908 
 4 228 0.912 
 5 229 0.916* 
d=20 1 239 0.956 
 2 240 0.960* 
 3 240 0.960* 
 4 238 0.952 
 5 233 0.932 
d=10 1 250 1.000* 
 2 243 0.972 
 3 243 0.972 
 4 242 0.968 
 5 233 0.932 
Note: 1. this table only shows the results with d=10, 20, 30, and t=1, 2, 3, 4, 5. 
  2. this experiment was undertaken using the patterns 1 to 50 (with 5 extra testing images each) 
Table 1. Recognition rates with different s 
Eventually, we used Objects 1, 2, and 22, for instance, to demonstrate the robustness of the 
proposed method. Figure 10 illustrates the extracted invariant features after applying the 
proposed method. The boundary representation using the smaller eigenvalue of covariance 
matrices for Objects 1, 2, and 22, are shown in Figure 10(d), (e), and (f), which have 706, 612 
and 1191 boundary points respectively. After that, the boundary sequences were re-sampled into 
300 features as shown in Figures 10(g) (h) and (i). Then, Figures 10(j) (k) and (l) depict the 
patterns after autocorrelation transformation with K=250. Obviously, the square pattern (Object 
1) and rectangle pattern (Object 2) have distinct sequences which can be easily differentiated. In 
addition, the extracted features of Object 22 have conspicuous difference to Objects 1 and 2’s. 
 21
boundary representation with different numbers of point (n) and region of support (s), 
respectively. The boundary sequences were then re-sampled into 300 points. After that, the 
features were further transformed using autocorrelation function, and are shown in Figures 11(j), 
(k) and (l). Accordingly, the extracted features are obviously similar series, and can be utilized 
for object recognition.  
                            
(a) Original object  (b) 1/4 scale, translation and 30° rotation  (c) 1/8 scale, translation 
    
(d) n=912, s=91      (e) n=445, s=44,        (f) n=214, s=21 
   
(g) Re-sampling with n=300    (h) Re-sampling with n=300   (i) Re-sampling with n=300 
   
(j) Autocorrelation K=250   (k) Autocorrelation K=250    (l) Autocorrelation K=250 
 
Figure 11. Recognition using different positions, orientations, and scales 
 23
pre-determined lag. After applying backpropagation neural networks for object recognition with 
minimum Euclidean distance method as a benchmark, we conclude that BPN slightly 
outperformed MD method and obtained almost perfect recognition. This implies that the 
extracted invariant features can be easily applied to object recognition using simple classifiers. 
The proposed method has been practically applied to various applications in industrial 
manufacturing such as object sorting, robot positioning and automated inspection systems. 
However, the appropriate values of threshold (T) and region of support (s) must be determined 
by trial-and-errors at this stage, for which is left for future study.  In particular, this project has 
been published and accepted in the journal Expert System With Applications.. 
 
三、參考文獻 
Bruckstein, A., Shaked, D. (1997), Skew-symmetry via invariant signatures, Pattern Recognition 
31 (2), 181-192. 
Cao, W., Hao, F., Wang, S., (2004), The application of DBF neural networks for object 
recognition, Information Sciences 160, 153-160. 
Jones III, G., Bhanu, B. (2001), Recognizing articulated objects in SAR images, Pattern 
Recognition 34, 469-485. 
Haralick, R.M and Shapiro, L.C. (1992), Computer and Robot Vision, Addison-Wesley, Reading, 
MA. 
Huang, X, Wang, B., Zhang, L. (2005), A new scheme for extraction of affine invariant 
descriptor and affine motion estimation based on independent component analysis, Pattern 
Recognition Letters 26, 1244-1255. 
 25
1273-1282. 
Popovici, V., Thiran, J.-P. (2004), Pattern recognition using higher-order local autocorrelation 
coefficients, Pattern Recognition Letters 25, 1107-1113. 
Sarkodie-Gyan, T., Lam, C.W., Hong, D., Campbell, A.W. (1996), An efficient object recognition 
scheme for a prototype component inspection, Mechatronics 7 (2), 185-197. 
Sookhanaphibarn, K., Lursinsap, C. (2006), A new feature extractor invariant to intensity, 
rotation, and scaling of color mages, Information Sciences 176, 2097-1229. 
Tien. F.C, Yeh, C.H, Hsieh, K.H., (2004) Automated Visual Inspection of Microdrill for PCB 
production, International Journal of Production Research 15 (42), 2477-2495. 
Tsai, D.M., Hou, H.-T., Su, H.-J. (1999), Boundary-based corner detection using eigenvalues of 
covariance matrices, Pattern Recognition Letters 20, 31-40. 
Tsang, P.W., (1997), A genetic algorithm for affine invariant recognition of object shapes from 
broken boundaries, Pattern Recognition Letters 18, 631-639. 
Ullman, S., High-level vision, MIT Press, Cambridge, MA, 1996. 
Wöhler, C., Anlauf, J.K. (2001), Real-time object recognition on image sequences with the 
adaptable time delay neural network algorithm – applications for autonomous vehicles, Image 
and Vision Computing 19, 593-618. 
Yu, H., Bennamoun, M. (2007), Complete invariants for robust face recognition, Pattern 
Recognition 40, 1579-1591. 
 27
可供推廣之研發成果資料表 
□ 可申請專利  ■ 可技術移轉                                      日期：95 年 5 月 17 日 
國科會補助計畫  
技術/創作名稱   
發明人/創作人   
技術說明  
可利用之產業 
及 
可開發之產品 
  
技術特點 
 
 
 
 
推廣及運用的價值
 
 
 
 
 
 
 
表 Y04                  共 4 頁    第 2 頁 
報告內容： 
一、參加會議經過 
1. 由於飛機行程之安排不易，故於 2007 年 10 月 7 日之下午約
4:00 抵達 Montreal 後，直接至會場報到報到，並領取相關資
料，並至旅館 check in。 
 
報到處 
2. 於10月8日為大會之opening day，上午9:00 參加Keynote session，首先，由Program 
Committee Chair: Eugene Santos先做講者介紹，主要邀請 University of Waterloo之Keith W. 
Hipel教授做Keynote speaker，演講之主題為Smart Cooperative Systems and Cybernetics 
Advancing Knowledge and Security for Humanity；之後，則參與相關領域之論文報告。 
 
 
 
 
 
 
Program Committee Chair: Eugene Santos       Keynote speaker: Keith W. Hipel 
3. 第二日10月8日為主要之研討日，為大會於上午8:30 邀請Dr. William Gruver 做Keynote 
speech，演講之主題: Holonic Intelligence: A New Paradigm for Systems Integration，演講
內容主要說明Holonic式智慧型之網路系統整合，及研究及執行現狀。 
 
 
 
 
 
Keynote speaker: William Gruver      Keynote session 之 Q&A 
