 2
所有的文件中，則代表此索引詞對文件的
重要性不高。然而僅依此兩項統計因素來
計算的索引詞權重以使用者的角度來看
還不夠理想，因此造成符合使用者查詢的
文件其與使用者查詢的相似度不高，也因
而 使 得 資 訊 擷 取 系 統 的 效 能
(Effectiveness)不高。為了增加資訊擷取系
統的效能，一些為索引詞設定權重的方法
已經被提出。在參考文獻[8]中，Jung 等
人提出了一個索引詞設定權重的方法，在
這個方法中他們不僅在文件描述向量
(Document Descriptor Vectors)中為文件中
有使用到的索引詞給定正值的權重值，另
外也考慮到沒有使用到的索引詞，並為這
些沒有使用到的索引詞設定負值的權重
值，並依此來計算文件間的相似度。在參
考文獻[14]中，Singhal 等人在設定索引詞
的權重時把文件的長度也考慮進來，因而
使得各種長度的文件在被擷取時都能有
一樣公平的機會。然而，這些方法卻無法
針對不同的使用者來設計不同的文件索
引詞權重。 
另一個能夠增加擷取效能的方法則
為修改使用者查詢的資訊擷取方法[3], 
[7], [8]。在參考文獻[3]中，Chan 等人提
出 一 個 基 於 使 用 者 相 關 回 饋 (User 
Relevance Feedback)來擴充使用者查詢的
方法，他們在使用者相關回饋之前對於每
次的查詢結果先加以分群整理，並取出分
群結果摘要，以節省使用者一一查看每筆
查詢結果的時間。在參考文獻[7]中，我們
提出一個修改使用者查詢的方法，而這個
方法是先對文件庫中的文件做階層分
群，並依這些文件分群的群中心來建立一
些推論規則，以描述索引詞之間的關係，
最後再依據建立好的推論規則來修改使
用者的查詢。在參考文獻[9]中，Kim 等
人提出一個基於索引詞間在回饋文件中
共同出現(Co-Occurrence)的頻率來修改
使用者查詢的方法。在這些修改使用者查
詢的方法中，使用者相關回饋是常被用到
的一個方法，此一方法需要使用者對於資
訊擷取系統所初步擷取出的文件做出是
否符合使用者需求的判斷。然而大部份的
使用者相關回饋只是用來修改使用者當
次的查詢，所以應用使用者相關回饋的效
果將只能侷限在當次的查詢中，而不能對
後續的查詢產生影響。如果我們能把使用
者相關回饋依某種形式儲存下來，使其能
改善後續的查詢效果，則資訊擷取系統的
效能將有很大的改善空間。 
在參考文獻[1]中，Bang 等人將多媒
體文件與使用者查詢視為特徵空間
(Feature Space)中的點，依據使用者相關
回饋，他們提出一個方法來作文件特徵調
整，讓符合使用者需求的文件移向使用者
查詢，而不符合使用者需求的文件離開使
用者查詢，以增進查詢的效能，但此論文
所提的方法無法針對不同的使用者作不
同的文件特徵權重調整。在參考文獻[12]
中，Robertson 等人提出了幾個新的機率
模式(Probabilistic Models)以做為資訊擷
取的基礎。在這幾個新的機率模式中，將
原本機率模式中計算索引詞對文件的權
重的公式分別參考文件長度、索引詞在文
件中的頻率、及索引詞在查詢中的頻率加
以修改，他們並以實驗來證明新的機率模
式有較好的擷取效能，但這些機率模式因
為都需要大量的統計資料，所以其缺點為
在沒有大量資料的資訊擷取環境時會有
其侷限性。在參考文獻[6]中，我們提出了
一個基於使用者相關回饋來做文件索引
詞權重調整的方法。首先，我們找出一個
適合的文件調整向量，然後利用此一向量
來調整索引詞在文件描述向量中的權
重，使得符合使用者需求的文件其滿足使
用者查詢的程度將會提高，反之不符合使
用者需求的文件其滿足使用者查詢的程
度將會降低，而此一文件調整向量就可當
 4
當類神經網路經由訓練樣本訓練完成
後，雖然類神經網路的輸出已經與我們所
要求的數值接近，但對於不是由訓練樣本
所產生的輸入，我們並不知道會得到何種
輸出。因此，我們必須使用另外一些類神
經網路從未見過的測試資料進入到類神經
網路中，測試其一般性，看看是否與所要
求的目標值接近，而此測試資料稱為測試
樣本（Testing Pattern）。一般性亦是類神
經網路中的一項優點，當類神經網路訓練
完成後，對於與訓練樣本相近的輸入，類
神經網路亦能給予一個合理的輸出，但是
如果測試樣本與訓練樣本的差異性過大，
類神經網路仍是無法給予合理的輸出。 
類神經網路的訓練就是在調整鍵結
加權值，而最常見的方法為最小均平方演
算法(The Least Mean Square Algorithm) 
[5]。最小均平方演算法是由 Widrow 等人
在 1960 年於史丹福大學所提出，這種學
習法則又稱做 Widrow-Hoff Learning 
Rule 或 Delta Rule。以最小均平方演算法
訓練單層式網路是倒傳遞學習網路用以
訓練多層感知機的起源[11]，其透過縮小
類神經元的鍵結加權值與輸入的內積和
理想輸出之間的均差來調節鍵結加權值。 
下面我們介紹我們在研究計畫中所
提的類神經網路模型及其學習演算法。我
們首先提出一個處理單一文件查詢的類
神經網路模型。假設在索引詞集合中有 s
個索引詞，則在此類神經網路模型中將包
含 s 個輸入與 s 個鍵結加權值。我們令文
件描述向量 id = <wi1, wi2, …, wis>中的 s
個元素wi1, wi2, …, wis分別為類神經網路
的 s 個輸入(Inputs)，而經過 k 次學習調
整後的 s 個鍵結加權值 wq1(k), wq2(k), …, 
wqs(k)將構成虛擬使用者查詢向量的 s 個
元素，我們以 kvq 來代表此一虛擬使用者
查詢向量，其中 kvq = <wq1(k), wq2(k), …, 
wqs(k)>。我們所提的處理單一文件查詢的
類神經網路模型如圖 3 所示，其中 wij為
文件描述向量 id 的第 j 個元素，即為此
類神經網路的第 j 個輸入；wqj(k)代表經
過第 k 次調整後的第 j 個鍵結加權值，0 ≤ 
wij ≤ 1，0 ≤ wqj(k) ≤ 1 且 1 ≤ j ≤ s；DS( id )
代表相似度函數，用來計算文件描述向量
id 符合虛擬使用者查詢向量 kvq 的程
度；fsl 為控制輸出的映射函數，如下所
示： 
⎩⎨
⎧
≥
<≤=
1,   if          1
1,0 if          
)(
x
xx
xf sl         (1) 
其中 Y 代表實際輸出，Y = ))(( isl dDSf ；t
代表目標值(Taget Value)，如果文件 di是符
合使用者查詢的文件，則目標值設為 1； e
代表實際輸出值與目標值之間的差值，即
e = t - Y。 
根據最小均平方演算法，我們設計一
個均平方差 (Mean-Square Error) 函數
J( kvq )，如下所示(其中 kvq 為虛擬使用者
查詢向量)： 
J( kvq ) = 2
1 e 2  
= 
2
1 (t - Y) 2   
= 
2
1 [t - ))(( isl dDSf ]
2  
= 
2
1 [t - )
)),((   
( 1,2,...,= 
s
wkwT
f sj
ijqj
sl
∑
] 2 , (2) 
其中 s 為索引詞集合中的索引詞個數，T
為計算兩個介於0與1之間的實數值的相
似度函數。我們希望 J( kvq )的值愈小愈
好，才能使整個網路的鍵結加權值
(Weights)儘可能朝所希望的目標調整。利
用最陡坡降法 (The Gradient Steepest 
Descent Method)的觀念[11], [15]，我們將
均平方差函數 J( kvq )對虛擬使用者查詢
向量 kvq 微分，得到斜率函數 )( kvqJ∇ ，
如下所示： 
)( kvqJ∇  = 2
1
kvq
e
∂
∂ 2 =
2
1
k
isl
vq
dDSft
∂
−∂ 2))](([
 
=
2
1
k
islisl
vq
dDSfdDStft
∂
+−∂ }))](([))((2{ 22
 
= – t id  + slf (DS(di)) id  
= – (t – slf (DS(di))) id  
 6
< )(),...,(),( 0w0w0w qs2q1q >，其中 0 ≤ wqj(0) 
≤ 1，1 ≤ j ≤ s，且 s 為索引詞的個數。 
步驟三：將所有在使用者相關回饋中被認
為符合使用者需求的文件分為一群，假
設其群中心為C 。 
步驟四：將 m 個根據原始的使用者查詢
向 量 q 所 擷 取 出 的 文 件 描 述 向 量
mddd ..., ,, 21 當作類神經網路的輸入，與
虛擬使用者查詢向量 kvq  (鍵結加權值)
經過相似度函數 DS(di)與線性映射函數
fsl(DS(di))計算)後得到相似度 yq1, yq2,…, 
yqm，其中 yqi代表文件 di符合虛據使用者
查詢向量 kvq 的程度，且 1 ≤ i ≤ m。將文
件依相似度大小排序後利用 RDRS 函數
計算得到輸出值，若輸出值與目標值相減
的絕對值小於β，則跳至步驟七，否則跳
至步驟五。 
步驟五：假設符合使用者需求的文件符合
度最小者文件 jd ，取誤差 e 為 1- qjy ，其
中 qjy 代表文件描述向量 jd 符合虛擬使
用者查詢向量 kvq 的符合程度，且 1 ≤ j≤ 
m。 
步驟六：利用已知的虛擬使用者查詢向量
kvq 、群中心C 、誤差值 e 及學習率u ，
計算出調整向量 vqΔ 以修正查詢向量
kvq 。新的虛擬使用者查詢向量 1kvq + 計
算出後，令 k = k+1；跳至步驟四。 
步驟七：利用向量的減法運算，計算最後
的虛擬使用者查詢向量 kvq 與原始的使
用者查詢向量 q 在向量空間中的向量
差，把此向量差當成虛擬查詢調整向量
qΔ 。 
步驟八：將此虛擬查詢調整向量的反向量
當成文件的調整向量Δ。 
步驟九：將文件調整向量Δ用來調整索引
詞在被擷取出的文件集合 D 其各文件描
述向量 mddd ,...,, 21 中的權重，其中 D = 
{ 1d , 2d ,…, md }, 亦即從 i  = 1 到 m  , 
使得 id = id  + Δ  。 
 
四、結果與討論 
 
我們已利用 Delphi 5.0 版在一部
Pentium 4 PC 上實作一個系統，以處理使
用者之文件查詢。NSC 文件庫[18]取至中
華民國國科會的研究報告摘要，其節錄
520 篇資訊科學相關領域的文件共 28 類
(Categories)，其中每類文件的數目介於 16
至 25 篇文件之間，每篇文件原含有標題、
索引號、中文摘要及英文摘要，經由系統
自動篩選出每篇文件的索引號及英文摘要
後，且用 stem 的方法[2]過濾出每個英文
字的字根(Term Root)後，以字根作為索引
詞庫(Term Database)中的索引詞。從實驗
結果我們可以得知各查詢索引詞在權重調
整後的回想率及正確率均分別比權重調整
前的回想率及正確率高。 
 
五、計畫成果自評 
 
本計畫在理論與實際應用上均有很高
的價值。本計畫之研究內容與原計畫相符
程度為 100%，也 100%達成預期目標。 
本三年期的研究計畫成果非常豐碩，
在本三年期研究計畫的經費支持下，我們
目前已發表或已被接受下列之期刊論文及
研討會論文，謹此致謝： 
1. H. C. Lin, L. H. Wang, and S. M. Chen, 
“Query expansion for document retrieval 
based on fuzzy rules and user relevance 
feedback techniques,” Expert Systems 
with Applications, vol. 31, no. 2, pp. 
397-405, August 2006. 
2. Y. C. Chang and S. M. Chen, “A new 
query reweighting method for document 
retrieval based on genetic algorithms,” 
IEEE Transactions on Evolutionary 
Computation, vol. 10, no. 5, October 
2006. 
3.  S. M. Chen, H. C. Lin, and Y. C. Chang, 
“A new method for query reweighting 
for document retrieval based on neural 
networks,” International Journal of 
Information and Management Sciences, 
vol. 17, no. 4, December. 
4.  L. Y. Chen and S. M. Chen, “A new 
approach for automatic thesaurus 
 8
similarity and fuzzy inference,” 
Proceedings of the Joint 9th IFSA 
World Congress and 20th NAFIPS 
International Conference, Vancouver, 
Canada, 2001, vol. 2, pp. 715-720. 
[10] T. Mandl, “Tolerant information 
retrieval with backpropagation 
networks,” Neural Computing & 
Applications, vol. 9, no. 4, pp. 280-289, 
2000. 
[11] S. G. Nash and A. Sofer, Linear and 
Nonlinear Programming. New York: 
McGraw-Hill, 1996. 
[12] S. E. Robertson, S. Walker, and M. M. 
Hancock-Beaulieu, “Large test 
collection experiments on An 
Operational, Interactive System: okapi 
at TREC,” Information Processing and 
Management, vol. 31, no. 3, pp. 
345-360, 1995. 
[13] G. Salton, The Smart Retrieval System - 
Experiments in Automatic Document 
Processing. NJ: Prentice Hall, 
Englewood Cliffs, 1971. 
[14] A. Singhal, C. Buckley, and M. Mitra, 
“Pivoted document length 
normalization,” Proceedings of the 19th 
Annual International ACM SIGIR 
Conference on Research and 
Development in Information Retrieval, 
Zurich, Switzerland, pp. 21-29, 1996. 
[15] B. Widrow and M. E. Hoff, Jr., 
“Adaptive switching circuits,” IRE 
WESCORN Convention Record, Part 4. 
NewYork: IRE, pp. 96-104, 1960. 
[16] J. Xu and W. B. Croft, “Query 
expansion using local and global 
document analysis,” Proceedings of the 
19th Annual International ACM-SIGIR 
Conference on Research and 
Development in Information Retrieval, 
Zurich, Switzerland, pp. 4-11, 1996. 
[17] D. C Yang, Using Relevance Feedback 
in Bayesian Probabilistic Mixture 
Retrieval Model.  Master Thesis, 
Department of Computer Science and 
Information Engineering, National 
Cheng Kung University, Tainan, 
Taiwan, Republic of China, 2003. 
[18] A Subset of the Collection of the   
Research Reports of the National      
Science Council, Taiwan, Republic of 
China, http://fuzzylab.et.ntust.edu.tw/ 
NSC_Report_Database/520document
s.html(Data Source: http://sticnet.stic.gov.tw). 
 
 
 
 
 
 
 
 
                                          ○ 
 
 
                               S 
 
 
 
 
圖 1. 類神經元的模型 
 
 
 
1x ○ 
 
2x ○ 
‧ 
‧ 
‧ 
nx ○ 
1w
2w‧‧‧
nw 
f (‧)
θ  
(閥值) 
 加法單元            活化函數              輸 出 
輸入向量  
虛線的部分為類神經元 
Y 
