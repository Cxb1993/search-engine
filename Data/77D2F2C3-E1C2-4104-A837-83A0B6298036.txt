2 
 
行政院國家科學委員會補助專題研究計畫成果報告 
Bi-prediction Combining Template and Block Motion Compensations 
計畫編號：99-2221-E-009-017 
執行期限：2010年08月01日至 2011年07月31日 
主持人：彭文孝 教授 國立交通大學資訊工程系所 
計畫參與人員：詹家欣、李宗霖、陳俊吉、陳漪文、吳牧軒、吳崇豪、黃嘉彥、陳孟傑、曾于真、陳
彥宇 國立交通大學資訊工程系所 
一、中文摘要 
關鍵詞： 雙向預測、交疊區塊動作補償、樣板核對 
此篇報告提出一個如同單向預測僅需一個動作向量傳輸負擔的雙向預測機制。此方法透過參數化交疊
區塊動作補償的方法，不僅結合樣板核對的動作向量，且重新設計了區塊動作搜索的機制，而其中所
使用的最佳視窗函數是基於模型的框架所設計的。此外，我們結合了可適性動作合併機制達到了無樣
板核對的實作。根據 JCT-VC 所提出之一般測試條件，三種分別代表不同效能及複雜度取捨的演算法
實作於 TMuC-0.9_HM 參考軟體。相較於對照組的壓縮結果，我們的技術平均能夠節省 2.2%的資料
量，最小與最大的節省分別為 0.2%與 4.7%。 
 
二、英文摘要 
Keywords：Bi-prediction, OBMC, Template Matching 
This report introduces a bi-prediction scheme with only a motion overhead as for unidirectional prediction.  It 
combines motion vectors found by template and block matchings with the overlapped block motion compensation 
(OBMC). An optimal window function is designed based on a model-based framework.  Additionally, the concept of 
adaptive motion merging is incorporated to enable a template-matching-free implementation. Three algorithms 
featuring different performance and complexity trade-offs are implemented using the TMuC-0.9_HM software and 
tested with the common test conditions.   Relative to the anchor, the best of them achieves an average BD-rate saving 
of 2.2%, with a minimum of 0.2% and a maximum of 4.7%. 
  
4 
 
2. PARAMETRIC OBMC 
In [8], OBMC is introduced to provide a better prediction of a pixel’s intensity value ( )I s based on 
motion-compensated signals 1{ (s v(s ))}
L
i iI   derived from its own and nearby block MVs 1{v(s )}
L
i i . 
Essentially, these MVs are considered to be plausible hypotheses for its true motion; their weights
1 2w = ( , ,..., )Lw w w are chosen to minimize the mean squared prediction error subject to the unit-gain 
constraint: 
*
w
1
w  arg min (w) . . 1,
L
i
i
s t 

                             (1) 
where 
 
2
1
(w) = E ( ) (s+ v (s ))( ){ }
L
i i
i
I s I 

 .                         (2) 
In applying OBMC to variable block-size motion partition, our previous work [3] proposes a parametric 
window solution. Using the motion model in [12], the (w)  at pixel s is shown, under some mild 
conditions, to have the following form: 
 
2 2
1
(w) = (s;s ),
L
i i
i
r 

                                 (3) 
where   indicates the randomness of the motion and intensity fields; 1{ (s;s )}
L
i ir   are the 2L distances 
between s and its nearby block centers 1{s }
L
i i  where 1{v(s )}
L
i i  are sampled. Upon setting the gradient of 
with respect to w to 0, the optimal weights become 
                                          
2
*
2
1
(s;s )
 = ,1 .
(s;s )
i
i L
i
i
r
i L
r




 

                                   
(4) 
The significance of this result is that it requires only the geometry relations of pixel s and its nearby block 
centers 1{s }
L
i i  to obtain 
*
1{ }
L
i i  . This remarkable property allows MVs associated with any motion 
partitions to be incorporated for OBMC.
 
 
 
 
 
 
 
 
 
 
 
Fig. 1. Joint application of TMP and BMC. 
  
6 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Fig. 2. SMSE surface as a function of Sb’s location, and the 
optimal window functions associated with vt and vb, respectively. 
 
Each term in the summation of (6) is simply the mean squared prediction error, produced by OBMC based 
on v(s )t  
and v(s )b , at some pixel s and can be modeled with (3). For a given sb , (6) is minimized when 
each operand reaches its minimum, that is, according to (4), when 
* 2 2 2(s) (s) r (s;s ) / ( (s;s ) + (s;s ))b b t t br r   . Noting this, we have: 
  * * 2 2 * 2 2
s
s B
s arg min ( (s)) (s;s ) ( (s)) (s;s ) .
b
b t t b b
B
r r  


                      (7) 
Due to its non-linear nature, 
*sb  has to be found by numerical simulations, i.e., we have to compute SMSE 
for every admissible location of sb . Fortunately, the computation is tedious but not difficult, and can be 
made offline. Once it has been solved, the 
*(s)b  is immediate by (4). Applying this window function to (5), 
we get an optimized block matching criterion, with which a 
*vb  approximating the pixel true motion at 
*sb  
can be found. 
To get a sense of where 
*sb  should be located, Fig. 2 (b) plots the SMSE as a function of its location. 
As can be observed, the SMSE becomes smaller when sb  sits in the bottom right quarter; a further precise 
calculation shows that its optimal location occurs at point (9.5, 9.5) for a 16×16 target block. This is of no 
surprise because vt , located at the template centroid (1.9, 1.9), has a higher correlation with the motion field 
in the upper left quarter and thus contributes more to minimizing the errors there. Intuitively, sb  should be 
so placed that the errors in the remaining part of B can be minimized. 
  
(c) 1 - 
*(s)b  
(a) InvL 
(d) 
*(s)b  
(b) SMSE Surface 
8 
 
4. EXTENSIONWITH MOTION MERGING 
Recognizing that performing template matching not only increases the decoding complexity but also 
complicates the pipeline design of the decoder, we additionally propose a low-complexity and TMPfree 
implementation. This is accomplished by replacing the template MV vt by one of those decoded MVs from 
neighboring partitions (cf. Fig. 4). In this way, the need to perform TMP is waived at the cost of extra bits. 
To minimize the overhead, we adopt the same signaling mechanism as for motion merging [11]. When 
enabled, it sends one flag to indicate the choice of the first available neighboring partition, to the left or 
above the current one, of which its motion parameters are reused as vt. Depending on the inference direction, 
a separate window function is applied for OBMC. For example, in Fig. 4, if vt is deduced from v1 
(respectively, v2), the window created for the Rect-T (respectively, Rect-L) template is selected. In other 
cases where v1 and v2 are identical, the one for the InvL template is used instead. Essentially, we treat v1 
and v2 as if they were the pixel true motion associated with the corresponding template centroids. Because 
these assumptions may not always hold true, we let the encoder to switch adaptively between this proposed 
mode and the usual inter mode. 
 
5. EXPERIMENTS 
Based on the proposed scheme (referred hereafter to as TB-mode), we develop three algorithms featuring 
different performance and complexity trade-offs. Extensive experiments are carried out using the 
TMuC-0.9_HM software [4] and the common test conditions [2] to compare their BD-rate savings relative 
to anchor encodings with TB-mode disabled. Rough estimates of their complexity characteristics are made 
by showing the encoding and decoding time ratios relative to anchor settings. All three algorithms use 
parametric window functions. Weighting coefficients are rounded offline into 16-bit integers and stored in 
tables for reducing computational complexity. The following summarizes these algorithms:  
• Algo. #1 applies TB-mode to 2N×2N prediction units (PUs)2 only. The vt is found by performing 
shape-adaptive template matching in a search range of MVp±8 pixels. For each 2N×2N PU, one flag 
is sent to switch adaptively between TBmode and the usual inter mode. When the former is chosen, it 
codes two extra bits (at most) to specify the template shape (InvL, Rect-T or Rect-L). A separate set 
of window functions are designed for each distinct 2N×2N PU size. 
• Algo. #2 simplifies Algo. #1 by signaling vt with motion merging mechanism (See Section 4). 
• Algo. #3 extends Algo. #2 to all PU sizes (2N×2N, 2N×N, N×2N, N×N). However, the flag 
indicating TB-mode is sent at coding unit (CU) level—i.e., all PUs in a CUmust be coded either in 
TB-mode or in the usual inter mode. When TB-mode is in use, each of its PU needs one more flag to 
signal how v  is derived and thus which window function to apply. 
 
5.1. Compression Performance and Complexity 
Table 1 presents the average BD-rate savings of these algorithms in different test classes and configurations. 
As can be seen, Algo. #1 has an average BD-rate (Y) saving of 1.3% over all test cases, with a minimum of 
0.2% and a maximum of 3.4%. Due to the extra computations needed for template matching, it doubles the 
decoding time while increasing the encoding time by about 70%. 
Algo. #2 gives better coding performance at a much faster decoding speed than Algo. #1. Averagely, it 
performs 0.1% better in terms of BD-rate saving (Avg:1.4%; Min: 0.0%; Max: 3.3%) with an average 
decoding time only 4% slightly longer than anchors’. In tests with High Efficiency configurations, its 
10 
 
5.2. Mode Distribution 
Fig. 5 charts the mode distributions of different schemes, including the anchor. The percentage of a 
prediction mode is segmented into several bars according to the CU size; the length of each bar represents its 
average spatial coverage (in units of pixels) in CUs of some specific size. From the figure, two observations 
can be made. First, when Skip and Merge modes are excluded, TB-mode tends to dominate over other inter 
modes, especially in Algo. #2 and #3. This confirms its effectiveness in providing similar or better 
prediction efficiency with less overhead. Second, the percentage of Merge mode drops moderately when 
TB-mode is enabled, which implies that a considerable number of PUs can benefit from motion refinement. 
Besides, we also observe that TB-mode increases a bit the use of larger CUs. 
 
6. CONCLUSION 
Summarizing, in this report, we propose a bi-prediction scheme, which combines MVs found by template 
and block matchings with an optimized OBMC window function. Since the template MV is inferred on the 
decoder side, it has only to signal one block MV. This notion is further generalized by incorporating 
adaptive motion merging to allow a template-matching-free implementation. Three algorithms featuring 
different performance and complexity tradeoffs are presented; they all show moderate coding gains. The 
best of them produces an effect similar to performing partial motion merging for geometry/asymmetric 
motion partitions. 
 
四、結果與討論、計畫成果自評 
本計畫有以下幾類成果。第一類為提出一個如同單向預測僅需一個動作向量傳輸負擔的雙向預測機制。
透過參數化交疊區塊動作補償結合樣板核對的動作向量，且重新設計了區塊動作搜索的機制，而其中
所使用的最佳視窗函數是基於模型的框架所設計。本實驗室亦有發表提案參與 JCT-VC 的 CfP 競賽，
在 27 個參賽隊伍中，取得了第 12 名的成績，其中競賽單位包括 Samsung、Qualcomm 等知名大廠。
第二類為在計畫執行期間參與了 JCT-VC 標準會議，總計有 9 件標準會議的貢獻文件。第三類為計畫
執行過程中所獲得之研究成果論文，已發表於(含接受)國際學術會議及國際學術期刊，共有 2 篇期刊
論文與 3 篇研討會論文。第四類成果為一篇美國專利案正在申請中。此外，參與計畫之研究人員亦獲
得了許多視訊壓縮相關之最新技術之設計經驗，達到人才培育之目的。 
綜合評估：本計畫發表了許多具有學術價值的成果，其中在國際標準會議上也有貢獻，並藉此機會培
育出許多視訊壓縮領域之人才，不論是對學術相關研究或是與國內業界合作進行相關產業之新產品開
發，都有正面的價值。 
 
五、參考文獻 
[1] G. Bjontegaard, ―Improvements of the BD-PSNR Model,‖ VCEGAI11,Jul. 2008. 
[2] F. Bossen, ―Common Test Conditions and Software Reference Configurations,‖ JCTVC-C500, Oct. 
2010. 
[3] Y. W. Chen and et al., ―A Parametric Window Design for Overlapped Block Motion Compensation 
with Variable Block-size Motion Estimates,‖ IEEE MMSP, 2009. 
[4] JCT-VC, ―TMuC-0.9_HM,‖ https://hevc.hhi.fraunhofer.de/svn/svn_TMuCSoftware/branches/0.9-hm/. 
[5] S. Kamp and et al., ―Decoder Side Motion Vector Derivation for Inter Frame Video Coding,‖ IEEE 
表 Y04 
行政院國家科學委員會補助國內專家學者出席國際學術會議報告 
                                                          100 年 10 月 19 日 
報告人姓名 陳俊吉 
服務機構 
及職稱 
國立交通大學資訊工程學系 
博士生 
     時間 
會議 
     地點 
99年 12月 7日 至 
99年 12 月 10 日  
日本 名古屋 
本會核定 
補助文號 
  
會議 
名稱 
 (中文) 
 2011 影像編碼研討會 
 (英文) 
2011 Picture Coding Symposium 
發表 
論文 
題目 
 (中文) 
 位元平面之壓縮取樣搭配貝氏估計解碼法於失真壓縮之應用 
 (英文) 
Bit-Plane Compressive Sensing with Bayesian Decoding for Lossy 
Compression 
報告內容應包括下列各項： 
一、參加會議經過 
    2010年影像編碼研討會（Picture Coding Symposium）研討會於12月7日至12月10
日在日本名古屋舉行，本屆PCS’2010最後僅接受來至世界各地論文發表共157篇，依論
文特色與領域共分成22個技術主題，在25個平行場次進行。同時本次研討會在議程的設
計上，除了一般性的論文發表外，大會亦特別安排了兩場Tutorial Sessions與三場
Keynote Speech，分別介紹三個極具潛力及前瞻性的研究領域，參與這三位大師的演說，
不僅瞻仰大師的丰采，亦提升了筆者於學術領域的廣度，著實獲益良多。 
    此外，於四天的議程安排中，大會並聘請兩位專家學者，針對影像處理相關領域的
特定主題安排兩場訓練課程（Tutorials）。主題分別為：(1) Evolutive Video Coding 
- From Generic Algorithm towards Content-Specific Algorithm、 (2) Quality 
Assessment for Image Compression Purpose。PCS’2011 接受之論文內容涵蓋數位影
像處理、新一代視訊壓縮技術 (High Efficiency Video Coding)、電腦視覺與圖學、
與 3D 電視與自由視角電視等相關領域，不但針對相關技術的介紹，亦加深理論於實務
設計上的考量。其餘三天為論文口頭報告（Lecture Session）與壁報發表（Poster 
Session），大會總共包含 22 個技術主題，共 25場次分 5個口頭報告場次及 20 個壁報
發表場次同時進行，與會者可依興趣與專長自由參與感興趣的場次聽講及發問。其中 10
個主題分別為：(1) 3DTV、(2) Free-viewpoint Television、(3) Beyond H.264/MPEG-4 
AVC、(4) Coding of still and moving pictures、(5) Model-based and synthetic 
coding、(6) Distributed source coding、(7) Image and video processing、(8) 
Multimodal coding and processing、(9) Very high-resolution imaging, coding and 
processing、(10) Multi-view video processing and coding、(11) Representation, 
analysis and coding of 3D scenes、(12) Virtual/augmented/mixed reality、 
 
國科會補助計畫衍生研發成果推廣資料表
日期:2011/03/04
國科會補助計畫
計畫名稱: 新興高效能視訊編碼技術
計畫主持人: 彭文孝
計畫編號: 99-2221-E-009-017- 學門領域: 訊號處理 
研發成果名稱
(中文) 畫面估測系統及其估測方法
(英文) Frame Prediction System and Prediction Method Thereof
成果歸屬機構
國立交通大學 發明人
(創作人)
彭文孝,陳渏紋
技術說明
(中文) 本發明係揭露一種畫面估測系統及其估測方法，其包含初始模組初始化一具有複
數個像素之第一畫面區塊。提供模組係提供一第二畫面區塊之第一重心點及第一
運動向量。位置查找模組根據第一重心點查找一位置點，並根據各該像素對第一
重心點及位置點之關係，各別對應產生第一權重值和第二權重值。向量查找模組
根據第一重心點、第一運動向量、位置點、第一權重值及第二權重值，查找該複
數個像素於第一畫面區塊中具有最低像素強度誤差值之第二運動向量。處理模組
根據該些運動向量及該些權重值，依序運算各該像素之一預測強度值。
(英文) The present invention discloses a frame prediction system and a prediction method 
thereof. An initializing module initializes a first image block having a plurality of pixels. 
A providing module provides a first centroid and a first motion vector of a second image 
block. The location lookup module finds a location according to the first centroid, and 
generates a first weight and a second weight respectively according to a relationship 
between each of the pixels, the first centroid and the location. A vector lookup module 
finds a second motion vector, which gives a minimum pixel intensity error for the 
plurality of pixels in the first image block according to the first centroid, the first motion 
vector, the location, the first weight and the second weight. A processing module 
sequentially calculates a plurality of predictive intensity values according to the motion 
vectors and the weights.
產業別 研究發展服務業
技術/產品應用範圍 視訊影像編解碼器 
技術移轉可行性及
預期效益
此一發明所推廣之技術已由ISO/IEC MPEG與ITU-T VCEG之新一代高效能視訊編碼國際標
準所採用
註：本項研發成果若尚未申請專利，請勿揭露可申請專利之主要內容。
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
1. 提出一個如同單向預測僅需一個動作向量傳輸負擔的雙向預測機制。透過參
數化交疊區塊動作補償結合樣板核對的動作向量，且重新設計了區塊動作搜索
的機制，而其中所使用的最佳視窗函數是基於模型的框架所設計。 
2. 本實驗室亦有發表提案參與 JCT-VC 的 CfP 競賽，在 27 個參賽隊伍中，取得
了第 12 名的成績，其中競賽單位包括 Samsung、Qualcomm 等知名大廠。 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
