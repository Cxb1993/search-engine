I摘要
多核心處理器與嵌入式系統之運用已日漸普及，原來在單一核心處理器環境下執行的大部分程式
卻無法在多核心處理器下發揮應有的執行效率。本計畫建構一嵌入式多核心平行開發環境以支援未來
多核心系統更大量的電腦運算，並提供程式碼平行化機制，以利從事平行處理的設計者於多核心架構
上之開發。我們將此環境建置於 FPGA 實驗平台，並利用此平行化機制，從事軟體環境改善研究。
對於多核心處理器執行程式碼的平行化機制，我們將以開放原始碼 SWARM平行化程式框架為基
礎，此函示庫針對多執行緒程式提供如同步化、記憶體控制與管理等基本平行處理功能，並參考MPI、
CUDA C、OpenCL等平行程式語言，以加強 SWARM之功能。
本計畫參考 SUIF 編譯系統，對使用者輸入的原始碼配合 SWARM 之函數庫進行結構重組，再進
行程式碼最佳化，最後輸出改良後的 SWARM函示庫之平行化程式碼。由於本計畫建立之系統軟體環
境降低了平行處理的門檻，不僅增加平行處理環境的使用率及接受度，也能吸引更多的人進入該領域，
繼續為平行與分散式處理進行研究及資源分享。
關鍵詞：多核心處理器、平行計算環境、嵌入式系統
1一、前言
由於嵌入式系統的發展與具備多核心處理器的電腦日漸普及，本研究計畫將針對嵌入式多核心系
統建構一平行開發環境以支援未來多核心系統更大量的電腦運算，提供程式碼平行化機制，以利從事
平行處理的設計者於多核心架構上之開發。本計畫建置之嵌入式多核心系統基本架構如圖 1 所示。
圖 1 本計畫建置於 FPGA 之多核心架構
嵌入式系統主要是用來控制和輔助機器或家電等設備的運作，在現今科技進步如此快速的時代，
嵌入式系統已廣泛地運用到軍事領域、工程領域、科學領域，甚至商業資訊的處理與我們生活周遭的
各種事物，均存在各種嵌入式系統。隨著國內外的嵌入式商品的研發與推廣，嵌入式系統與我們的生
活更息息相關。
而即時系統為一種正確性不僅取決於計算的邏輯結果，也與產生那些結果所耗費的時間相關，因
此，即時系統必須在可預測的時間範圍內做出對外部事件的反應，如果無法達到前述之要求(即在時限
內完成指派的特定任務)，系統便有可能做出錯誤的操作。隨著科技的發展，嵌入式即時系統(如汽車剎
車系統)便成為上述兩種方案的另一個整合方向，透過此動作來發揮各自的優點；而實務上，如何設計
一個低成本、低耗能及高可靠度之嵌入式即時系統便成了未來研究方向的重點。此外，由於具備多核
心處理器的電腦日漸普及，設計上將不再只侷限於過去單核心處理器的方式與記憶體架構，若能導入
平行計算的機制，讓工作在平行處理環境下來運行，便可達到整體效能提升的目標。本計畫在此背景
理論下，將嵌入式即時系統上之平行處理環境作為本研究之重點，採用 Altera 之 FPGA 為實驗平台來
進行。
二、研究目的
本計畫建構一嵌入式多核心即時系統之平行開發環境，以支援未來多核心系統更大量的電腦運
算，並提供程式碼平行化機制，以利從事平行處理的設計者於多核心架構上之開發。我們將此環境建
置於 FPGA 實驗平台，並利用此平行化機制，從事軟體環境改善研究。此外，也將針對記憶體的使用
3[2] 可重新配置的彈性
以通訊產品為例，需連結多種不同設備，而不同地區可能有不同標準，傳輸資料也有不同格式，若
開發工具未具備重配置(Reconfigurable)功能，產品將難以符合各個地區之需求。
[3] 符合 Time-To-Market 的要求
傳統開發模式，基本上除了設計階段外，還有修正、原型製作與模擬測試等階段，若以 Gate Array
與 FPGA 開發時間作比較，通常可將開發時間降到 1/3。
3.2 平行程式語言
MPI(Message Passing Interface)為一標準化的 Message Passing 平行語言。可以使用在 Fortran、C、
C++ 等語言撰寫的程式上。MPI 平行程式可以在分散式記憶體平行系統上執行，也可以在分散式共享
記憶體之叢集(Cluster)平行系統上執行。目前系統廠商所提供的 MPI 軟體是屬於 MPI1.2 版。它提供
了一百多個函式，讓程式人員來選用。
SWARM(SoftWare and Algorithms for Running on Multicore)則是為一種平行化的程式框架，提供了
一些基本的功能給多執行緒程式設計使用，包含同步功能，控制功能以及記憶體管理功能。程式設計
者可以使用這個架構，有效設計出可供平行處理的程式。與 MPI 不同的是記憶體運作採用的方式，
SWARM 採用的是共享式記憶體，而MPI 則主要採用分散式記憶體的方式，若平行計算環境建構在現
今多核心的架構下，似乎以 SWARM 的方式更能發揮其效能。由於 SWARM 所提供的函式較少，尚
需使用者自行去定義或開發，可參考的建置實例亦不多。
NVIDIA CUDA 技術是為充分利用 GPU 平行計算能力而設計的，NVIDIA CUDA 能夠透過通用
性防範的高階程式語言，讓 GPU 進行最合適的平行計算，它是 NVIDIA 平行計算戰略的基礎。和使
用 CPU 相比，科學家們見證了 CUDA 為其應用程序所帶來的最高 20 到 200 倍的速度提升，因此
CUDA 已經被全球研究界人士所廣泛採用。CUDA C 是可讓人了解 GPU 運算的平行程式語言，而
CUDA 則為一種平行運算的架構，若將每一個支援 CUDA 的 NVIDIAGPU 當作是一個 CUDA 架構，
如：GT200 在進行運算時，可將其視為一個具有 240 個處理器的 CUDA 架構，而 CUDA C 語言則僅
是協調、控制這個 CUDA 架構的一種語言環境。
OpenCL(Open Compute Library)是一種全新支援計算的 API，讓程式開發人員能夠發揮 GPU 內部
巨大的平行計算能力，OpenCL 即為通用計算領域提供一個跨平台的統一標準語言。OpenCL 最早是
由 Apple 公司提出，而 KHRONOS Group 透過協調各個廠商，從而使 OpenCL的跨平台特性更加完善；
簡言之，OpenCL 是針對平行計算的 API，利用 GPU 以進行平行計算。
由於 CUDA 本身主要應用在顯示卡上，其架構及 API 雖頗完整，但並不完全適用於本計畫之嵌
入式多核心平台，於實作上本計畫將參考各類型的平行程式語言，來開發本計畫之平行計算環境。
四、研究方法
針對平行程式語言，對於非資訊背景的研究單位或是一般個人而言，是一道阻礙平行處理環境使
用率及接受度的門檻。而平行程式語言之設計，與系統之記憶體架構息息相關，針對不同的記憶體架
構，有不同的平行程式語言，如MPI 適用於分散式記憶體架構，或是將分散式共享記體架構；SWARM
適用於共享式記憶體架構；而 CUDA 則採用更複雜的記憶體架構來符合其異質性處理器之需求。多核
心系統基本上為共享記憶體架構，若能將原有程式碼平行化，而不只是分派給不同的核心去處理個別
的任務，勢必可以提高整體運算的效能。因此，部分平行語言(如MPI)在本計畫之嵌入式多核心平台下，
似乎不是最佳的選擇方案，而一開始就是以共享記憶體為架構開發的 SWAM 便成了我們所要建置之
多核心平行處理環境的基礎。但 SWARM 的函式不多(基礎內容描述如圖 2，且要將其建置在 FPGA 上
就必須考量到各種資料間溝通的問題。
5圖 3 FPGA 硬體架構圖
至於在連線方面，每個核心都需要被分配到 ID，所以每個核心都必須要跟 SystemID 元件做連結，
至於 Memory 的空間，基本上分成可以共用及分屬於各個核心私用兩部分，在我們的設計上，所有的
Memory(SSRAM、SDRAM)都是屬於共用的 Memory；此外，在 FPGA 多核心系統上，必須要注意的
是，Input 的部份(botton)可以分別針對某一個核心下指令，但是 Output的部份(LED、JTAG UART)就
必須由其中一個主核心統一控管，當其他的核心要做輸出的動作時，就要透過 Bus 傳遞由主核心來輸
出，當有一個核心在使用 Bus 傳遞訊息時，必須要讓其他的核心不能使用 Bus，所以這個時候，就要
再另外加上一個元件Mutex，由Mutex 來控制，每一次都只能有一個核心在 Bus 上傳遞訊息。
完成上述工作，即是完成 FPGA 基本的多核心架構，但只能讓每個核心做屬於自己的工作，如此
就像是多個單一核心架構的 FPGA 擺在一起而已，為了要達到平行多工處理的目的，還要再另外加上
讓核心之間能溝通的方法，使得核心之間的資料能夠互相傳遞(與傳遞輸出訊息不同，此處指的是可以
運算以及利用的參數、資料等等)，此部份，Altera 提供了Mailbox 的機制來解決如共享記憶體所產生
的定址問題，我們利用如同 Mailbox 的方式，將資料在多個核心之間做傳遞，藉此協調多個核心之間
的溝通，以達到平行多工的效果。即使多個核心的資料之傳遞問題可透過上述之方法解決，但是依然
無法發揮多核心之最大效能，因此本計畫以 MPI 為平行語言為基礎，改善及新增 SWARM 程式架構
各種溝通上必要的函式，強化本計畫之嵌入式平行環境，以提供嵌入式平行程式設計者能更有效率的
進行平行程式的開發。
4.2本計畫之平行程式架構介紹
本計畫參考 MPI、CUDA、OpenCL 做為改良 SWARM 平行程式架構與擴增函式之基礎，針對多
個核心彼此間以共享記憶體作為資料交換的機制，發展本計畫之平行程式架構。由於 CUDA 與 OpenCL
主要是針對異質性計算機系統來設計，因此，本計畫主要參考MPI、CUDA 與 OpenCL以加強 SWARM
功能。我們在多核心架構上提出的程式結構，不同於以編譯器為基礎的 OpenMP 方式，此架構是採用
函式為基礎的平行化程式架構，可以使用在 C或 C++語言撰寫的程式上。以下針對變數宣告、系統變
數和一些平行函式做詳細的描述。
4.2.1 變數宣告
7{
i=10;
}
i=Bcast(i, 2);
在 pdpl_Bcast執行之前，i在 cpu2的值為 10，而在其他 cpu是 5。當執行了 pdpl_Bcast以後，cpu2
會將值傳到共享記憶體中，而其他 cpu 會等到所有處理器都執行到此函式時到共享記憶體去存取值，
因此每個 cpu的 i值皆為 10。
另一種集體傳訊函式是 pdpl_reduce函式，此函數可將各處理器的資料透過指定的運算方式，每兩
個一組執行，可以減少運算的次數，如 SUM是把各處理器的值做加總，MAX則是找出最大值，MIN
是找出作小值。為了達到此函式的執行方式，本計畫使用Mailbox來實現，以加總為範例，用法如下：
total=Reduce(num, SUM);
該函式用到兩個參數，前者是要參與計算的資料，後者是要指定的運算方式。以上的範例執行後，
每個處理器的 num值會被加總放到 total變數裡。最後一個集體傳訊函式是 pdpl_Scan函式，此函式跟
上一段介紹的函式有點類似，不過不一樣的是該函式會將運算出來的值依序傳給下一個，直到把最後
的結果算出來。本計畫以共享記憶體來實現此函式，以加總為範例，用法如下：
total=Scan(num, SUM);
該函式用到兩個參數，前者是要參與計算的資料，後者是要指定的運算方式。當以上的例子執行
後，每個處理器的 num值會被加總放到 total變數裡。
五、結果與討論
5.1實驗結果與分析
在本章節我們從選擇了 Livermore Loop 1 和 Livermore Loop 21 兩支程式作為標竿程式
(benchmark)，並且將程式碼利用本計畫提出的平行程式函式，使其平行化，在設計的硬體架構上執行，
然後記錄在不同的核心數和不同的資料量下的執行時間，來檢驗程式的正確性並評估其效能。實驗中
的標竿程式，係在多核心的硬體架構上執行，此架構有四個處理器，頻率為 100 MHz；記憶體是 64MB
的 SDRAM，每個處理器擁有 16MB的空間儲存指令和資料；共享記憶體是 2MB的 SRAM。本實驗測
試的標竿程式，包括 Livermore Loop 21和 Livermore Loop 1，這兩個程式皆是由迴圈來進行運算，且
迴圈與迴圈的資料沒有相依性，所以適合在分配給多個處理器做平行運算，進而評估效能。
Livermore Loop 21(即為矩陣相乘)的測試條件為當矩陣大小為 50*50或 100 *100時，分別在 1, 2, 4
顆核心作運算。Livermore Loop 1本身是利用迴圈去做浮點運算。利用 pardo函式可使每個處理器各做
一部份迴圈，達到平行化的效果。其測試條件為當資料量 loop=30, size=720或 loop=90, size=1440，分
別利用核心數為 1, 2, 4去作測試。以上的實驗方法測試完後，將數據記錄下來可以得到表 1和表 2的
數據。圖 4和圖 5是標竿程式在各核心數上執行的比較。
表 1 矩陣相乘執行時間(單位：秒)
處理器數目矩陣
大小 1 2 4
50*50 8.262 4.894 3.823
100*100 65.542 37.588 27.002
9者在嵌入式多核心平台上面開發平行程式，程式平行化後執行速度可以有效的提升。另外我們也針對
集體傳訊函式去做修改並新增功能，使得平行程式設計更為方便並提升執行時的效能。由於本計畫建
立之系統軟體環境降低了平行處理的門檻，不僅增加平行處理環境的使用率及接受度，也能吸引更多
的人進入該領域，繼續為平行與分散式處理進行研究及資源分享。
參考文獻
[1] Jean-Luc Gaudiot, Liang-Teh Lee, “Occamflow：A Methodology for Programming Multiprocessor
Systems”, Journal of parallel and distributed computing, Vol 7, pp. 96-124, 1989.
[2] Georgios Goumas, Nikolaos Drosinos, Maria Athanasaki, Nectarios Koziris, "Automatic Parallel Code
Generation for Tiled Nested Loops," ACM Symposium on Applied Computing, 14-17 Mar., 2004.
[3] Daesuk Kwon and Sangyong Han, Heunghwan Kim, "MPI Backend for an Automatic Parallelizing
Compiler,”I-SPAN'99, pp.152-157, 23-25 Jun. 1999.
[4] Jan-Jan Wu, Chia-Lien Chiang, Nai-Wei Lin, "A Hybrid Multithreading/Message-Passing Approach for
Solving Irregular Problems on SMP Clusters,”PDPTA, pp.1826-1832, 1999.
[5] Ferner, C.S., "The Paraguin Compiler- Message-passing Code Generation Using SUIF,” IEEE
Southeastcon, pp.1-6, 5-7 Apr. 2002.
[6] Gengbin Zheng, Orion Sky Lawlor, Laxmikant V. Kale, "Multiple Flows of Control in Migratable
Parallel Programs,”ICPPW, 14-18 Aug. 2006.
[7] Georgios Goumas, Maria Athanasaki, Nectarios Koziris, "Code Generation Methods for Tiling
Transformations,”Journal of Information Science and Engineering 18, pp.667-691, 2002.
[8] Prakash, S., Bagrodia, R.L., "MPI-SIM： using parallel simulation to evaluate MPI programs,”WSC'98,
vol 1,pp.467-474, 13-16 Dec. 1998.
[9] Ya-Nan Shen, Rong-Cai Zhao, Jian-Min Pang,"Automatic Code Generation of Data Decomposition",
INFOSCALE '06,May 29-June 1, 2006.
[10] Georgios Goumas, Maria Athanasaki, Nectarios Koziris,"Automatic Code Generation for Executing
Tiled Nested Loops onto Parallel Architectures", SAC, 2002.
[11] K. Chanchio and X. H. Sun, “Data Collection and Restoration for Heterogeneous Process Migration,”
Parallel and Distributed Processing Symposium., Proceedings 15th International 23-27, Apr. 2001.
[12] Hai Jiang and Vipin Chaudhary, “On Improving Thread Migration： Safety and Performance,”9th
International Conference on High Performance Computing 2002, vol 2552 of LNCS, pp. 474-484, Berlin,
Germany, Dec. 2002.
[13] J. B. Dennis and G. R. Gao, “Multithreaded Architectures： Principles, Projects, and Issues”, in
Multithreaded Computer Architecture： A Summary of a State of the Art, pp.1-72, 1994.
[14] D. Robert Blumofe, F. Christopher Joerg, C. Bradley Kuszmaul, E. Charles Leiserson, H. Keith Randall,
and Yuli Zhou,“Cilk： An Efficient Multithreaded Runtime System,”Journal of Parallel and Distributed
Computing, 37(1), pp.55-69, Oct., 1996.
[15] P. Smith, and N. Hutchinson, “Heterogeneous process migration： the TUI system,”Tech rep 96-04,
University of British Columbia 1996.
[16] Stephen Jenks and Jean-Luc Gaudiot, “A Multithreaded Runtime System With Thread Migration for
Distributed Memory Parallel Computing,”in Proceedings of High Performance Computing Symposium,
2003 Advanced Simulation Technologies Conference, Orlando, FL, 2003.
出席國際學術會議心得報告 
                                                             
計畫編號 NSC 98-2221-E-036-034 
計畫名稱 以 FPGA 為基礎之嵌入式多核心系統之建構與軟體環境改善之研究 
出國人員姓名 
服務機關及職稱 
李良德 
大同大學資訊工程學系教授 
會議時間地點 99 年 5 月 21 日 至 99 年 5 月 23 日  韓國釜山 
會議名稱 第十屆平行處理演算法與架構國際研討會 
發表論文題目 Parallel Programming on a Soft-Core Based Multi-Core System  
一、 參加會議經過 
2010 年第十屆平行處理演算法與架構國際研討會(ICA3PP 2010)，從 5 月 21
日至 5 月 23 日計 3 天在韓國釜山 Lotte Hotel 舉行。此次大會同時也包含三個
Workshop：Frontiers of Parallel and Distributed Computing (FPDC2010)、High 
Performance Computing, Technologies, and Applications (HPCTA2010), 以及
Multicore and Multithreaded Architecture and Algorithm (M2A22010)。研討會分成
20 個場次進行研討，論文內容涵蓋 Parallel algorithms, architectures and 
applications、GPU computing and applications、Parallel programming and multi-core 
technologies、Grid/Cluster computing、Parallel architectures、Distributed computing、
Cloud computing/virtualization Techniques、GPU Technologies and applications、
Grid/Cluster computing、 Multi-core and Multithreaded Architectures、 Parallel 
programming 、 performance evaluation 、 Fault-tolerant/information security and 
management、Mobile computing/web services 以及 Wireless communication network
等。此外尚有四場專題演講，由日本 Hosei University 之 Prof. Lei Li 主講
“Structure and Model of Algorithms”、由澳洲 Deakin University 之 Prof. Wanlei Zhou
主講 “Efficient Web Browsing with Perfect Anonymity Using Page Prefetching”、 由
澳洲 University of Melbourne 之 Prof. Rajkumar Buyya 主講“Cloud Computing: The
無衍生研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
99.1.20 舉辦多核心嵌入式系統技術研習會,參加人員: 校內外人士 110 人 
99.6.26 舉辦 2010 資訊科技與應用產學研討會-- 嵌入式系統與計算機結構研
討會,參加人員:本校師生 39 人，校外人士 42 人 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
