遙測資料三維紋理分析
中文摘要
傳統遙測影像紋理分析主要透過影像灰階共生矩陣 (Gray Level Co-Occurrence Matrix, GLCM) 
以二維型式計算影像中的特徵統計指標。然而，新型態的遙測資料（如高光譜影像）在特徵空
間中以具備實體資料的特性，因此傳統二維紋理分析可能無法真正有效地萃取隱含於複雜三維
資料格式中之有用特徵。因此，本研究計畫針對遙測資料，開發有效的三維影像紋理分析演算
法及流程，以進行遙測資料的特徵萃取。整體研究期程共三年，第一年的主要工作為延伸二維 
GLCM 計算至三維模式，並應用至高光譜遙測影像資料之特徵萃取及分類等相關應用。第二年
（本年度）的主要工作項目是利用光譜分離度分析求取高光譜影像立方體於三維紋理計算時在
光譜方向的最佳視窗（核）大小，以更有效萃取光譜影像立方體的三維紋理特徵。第三年則是
發展真正的三維紋理特徵萃取演算法，並提出灰階共生張量場概念以真正落實實體資料之三維
紋理分析。
關鍵詞：紋理分析、共生矩陣、三維遙測資料、灰階共生張量場、光譜分離度分析
Abstract
Conventional texture analysis for remote sensing imagery commonly utilizes Gray Level Co-
Occurrence Matrix (GLCM) to obtain two-dimensional statistical patterns of spatial features in the 
dataset. However, new types of remote sensing data, such as hyperspectral images, can be considered 
volumetric in feature space. Therefore, 2D texture analysis may not be adequate to extract subtle 
features from complicated volumetric datasets. This project undertakes the research and development 
of three-dimensional texture analysis algorithms and procedures for better feature extraction of remote 
sensing data. The research schedule is separated into three phases in three years. The objective of first 
year's task was to extend traditional 2D GLCM texture analysis into 3D mode and apply the developed 
3D GLCM computation algorithms to the feature extraction and classification of hyperspectral remote 
sensing imagery. The objective of the second year's task is to identify the most appropriate kernel size 
in the spectral dimension of a hyperspectral image cube when computing 3D gray level co-occurrence 
matrix in order to extract more useful 3D texture features from hyperspectral data sets. The core task of 
the third year is to develop truly 3D texture feature extraction algorithms for hyperstral image cubes. A 
Gray-level Co-occurrence Tensor Field (GLCTF) is developed for volumetric texture analysis.
Keywords: texture analysis, volumetric data, GLCM, GLCTF, separability measures
年研發成果，發展可以真正進行三維紋理特徵萃取的演算法。本研究提出一灰階共生張量場
(Gray-level Co-occurrence Tensor Field, GLCTF)概念，可計算高光譜影像立方體中三個像元資料
的灰階共生頻率，探索高光譜影像立方體的三維紋理特徵，以萃取此種特徵空間中實體資料的
隱含特性，發揮其最大功效。
HOM=∑∑ { 11i− j 2 M ij}  (4)
ENT=∑∑ M ij⋅log M ij   (5)
ASM=∑∑ M ij2  (6)
然而，此種統計指標只利用兩個像元，因此就特徵空間觀點而言，仍屬於二維分析，無
法充分探索三維實體資料的紋理特性。因此，本研究將上述傳統二維紋理統計指標擴展為三維
型式，以公式(7)的三維灰階共生張量場(Gray-level Co-occurrence Tensor Field, GLCTF)計算三個
像元的灰階共生頻率，其三維紋理統計方式如公式(8)~(11)所示。
M d i , j , k =∑ x=1
W x−dx ∑ y=1
W y−dy ∑z=1
W z−dz ={1 W x , y , z =iW xdx1 , ydy1 , zdz1= jW xdx2 , ydy2 , zdz2 =k
0 otherwise
 (7)
CON=∑∑∑ [i− j 2 j−k 2i−k 2 ]  (8)
HOM=∑∑∑ { Pijk1[i− j 2 j−k 2i−k 2 ] }  (9)
ENT=∑∑∑ P ijk−ln P ijk  (10)
ASM=∑∑∑ P ijk2  (11)
而三維灰階共生張量場計算時的三個像元對組成方式可以有許多，本研究僅考慮 Fig. 2-2 
所示的兩種組成方式。
Fig 2-2: GLCTF 計算時像元組成方式
平面方向
垂直方向
平面方向
垂直方向
用光譜分離度(separability measures)分析不同地物群組間在光譜上具最佳分辨率的取樣間距，並
以此做為計算紋理特徵時在光譜維度方向上的最佳視窗大小，結合半變異分析所決定的空間方
向視窗大小，進行高光譜影像立方體的三維紋理計算，以有效萃取高光譜影像立方體的三維紋
理特徵。
最常使用的光譜分離度分析是 Divergence，其計算如公式(13)所示：
d ij=∫ { p x∣i − p x∣ j }ln
p x∣i 
p x∣ j 
d x  (13)
Divergence 隨著波長增加，呈現發散的趨勢，因此並不適合用以決定最佳視窗尺寸。比
較合理的方式應該是採用如公式(14)所示的 Jeffries-Matusita距離(JM Distance)計算兩兩地物類別
間的光譜分離度：
J ij=21−e
−B
B=1
8
mi−m j
t {i j2 }
−1
m i−m j1 /2 ln {∣i j/2∣∣i∣∣ j∣ }  (14)
Fig. 2-6 所示是 JM Distance 的典型型式，由圖中可以發現，JM Distance 在波長（光譜）
間距變大時會很快地趨於一定值，因此可以快速地求得可明確分離兩地物群組的光譜間隔。而
此光譜間距表示可有效地於影像中區分此兩地物群組，亦即可做為計算高光譜影像立方體三維
紋理特徵時於光譜維度方向上的最佳視窗大小。
Fig 2-5: 高光譜影像立方體。
 
Y
X
λ
三、研究成果及討論
基於上述研究方法及流程，本計畫本年度利用兩組高光譜影像資料進行光譜分離度分析，
並搭配上一年度已完成之延伸傳統二維灰階共生矩陣為三維計算模式進行三維紋理特徵萃取，
並進行影像分類。第一組資料是美國 NASA EO-1 衛星上的 Hyperion 高光譜影像（Fig. 3-
1a）；另一組則為國家實驗研究院儀器科技研究中心所提供的空載 ISIS (Intelligent Spectral 
Imaging System) 高光譜影像（Fig. 3-1b）。
第一組Hyperion 資料涵蓋恆春半島墾丁國家公園附近地區的植生區域，拍攝時間為 2004
年 6 月；原始Hyperion 資料共有 220波段，去除雜訊過多及重複波段後取第一段連續的 45個波
段形成一影像立方體。第二組 ISIS 資料則涵蓋溪頭部分山區的原始林地，拍攝時間為 2006 年 9
月；由原始 218個波段中萃取出大致符合Hyperion 資料組所使用的波長範圍的 190個波段形成
影像立方體進行分析。分析的方式為配合輔助地真資料分別利用兩組資料進行分類，並比較純
使用半變異分析所求得的最佳視窗大小與結合光譜分離度分析以決定光譜方向最佳視窗大小所
萃取之三維紋理特徵於分類表現上之優劣。
Fig. 3-2所示為使用 ISIS 資料進行四種植物（紅色–臺灣杉；暗紅色–柳杉；綠色–楓樹；
藍色–竹林）分類的訓練區、二維 GLCM 特徵分類成果、以及三維 GLCM 計算特徵分類成果。
由圖中可發現，使用傳統二維 GLCM 計算所得特徵進行之分類在兩種杉木的分類成果都非常不
理想；而三維 GLCM 計算所得特徵的分類成果明顯的較為合理。Fig. 3-3 則顯示二維和三維
GLCM 計算所得特徵的分類經度評估。可以發現同樣是以原始光譜資訊加上三維 GLCM 計算所
得特徵的分類成果最佳。此一分析更粗步證明對高光譜影像分類應用而言，三維 GLCM 計算在
特徵萃取上優於傳統二維紋理分析。
Fig. 3-1: 研究使用高光譜資料之假色影像（ a: 
Hyperion; b: ISIS ）
Fig. 3-6 所示則為 ISIS 資料中兩兩植物類別族群的 JM Distance 光譜分離度分析成果。由
圖中成果所示，最能分離不同植物族群之光譜取樣間距為 7；搭配空間方向二維半變異元分析
的最佳成果 9x9，因此取 9x9x7 為計算三維紋理特徵時之移動視窗尺寸，萃取三維紋理特徵進
行分類，並與上述純半變異分析所得之 5x5x5移動視窗特徵萃取分類成果進行比較。
Fig 3-6: ISIS 光譜分離度分析
Fig. 3-7 和 Fig. 3-8所示為利用純半變異分析所定移動視窗大小(5x5x5)及結合光譜分離度
分析所定移動視窗大小(9x9x7)所萃取之紋理特徵，使用相同訓練區以最大似然法進行監督式分
類，並以相同檢核資料所得之總體精度(Overall Accuracy, OA)與 Kappa評估成果。其中 GLCTF1
代表萃取水平及垂直方向的鄰近像元，GLCTF2 則是萃取周圍上下斜邊的像元。由圖中可明顯
發現，9x9x9移動視窗所求得之紋理特徵的分類成果在四種統計指標的精度皆優於以 5x5x5 為
移動視窗所得紋理特徵之分類成果。初步證明，以光譜分離度分析決定高光譜影像立方體三維
紋理計算時於光譜方向之最佳核尺寸並結合半變異分析以決定空間維度方向之最佳核尺寸可能
是較合理的方式。
0.7
0.9
1.1
1.3
1.5
1.7
1.9
1 3 5 7 9 11 13 15
Spectral interval
JM
 d
ist
an
ce
vs草地 農耕地
 vs草地 針葉林
 vs草地 竹林
 vs農耕地 針葉林
 vs農耕地 竹林
 vs針葉林 竹林
Fig 3-7: ISIS 二維及三維分類 OA
類似的分析也於 Hyperion 資料進行。首先進行三維 GLCM 計算最佳核尺寸之選取。Fig. 
3-11所式為 Hyperion 資料中四種主要地物類別的半變異分析成果；由圖中成果顯示，此四種地
物在不同方向與角度時半變異分析所的的最佳核尺寸皆為 5。
為比較三維及傳統二維 GLCM 計算的優劣，以同樣的訓練區進行二維 GLCM 影像的分類，
其成果則顯示於 Fig. 3-12。由 Fig 3-12 可發現，不論是根據整體經度或 Kappa值，最佳的分類
成果都是以原始光譜資訊加入三維 GLCM 計算所得之紋理特徵所得為最佳；證明三維 GCLM
計算的紋理分析可充分萃取隱含於複雜高光譜影像立方體內的特徵，並能有效區隔不同的目標
類別。
Fig 3-10: ISIS 三維紋理計算 Kappa評估
根據三維半變異分析，決定 5x5x5 為最佳移動視窗尺寸；而加入光譜分離度分析後，發
現光譜方向最具分離度的光譜取樣間隔為 7，因此以 5x5x7 為整合式的移動視窗尺寸，分別進
行三維紋理灰階共生矩陣計算。經四種統計指標換算為紋理特徵後同樣以相同的訓練資料進行
分類，並以相同檢核資料進行精度評估。兩組分類的 OA精度比較如 Fig. 3-13所示，Kappa評
估則顯示於 Fig. 3-14。同樣地，以半變異分析決定空間方向移動視窗尺寸，結合光譜分離度分
析決定光譜維度方向之最佳核尺寸所得之三維灰階共生矩陣計算移動視窗(5x5x7)所萃取的紋理
特徵在四種統計指標於分類上的表現皆優於純粹使用半變異分析決定移動視窗尺寸。
以 Fig. 3-15 與 Fig. 3-16 之三維分析精度進ㄧ步探討，發現 5×5×7 之灰階共生張量場成果，
除了ASM 之 GLCTF2 成果外，都較 5×5×5 之 3D GLCM 佳。而 GLCTF1 相較 5×5×7 之 3D 
Fig 3-13: Hyperion 二維及三維紋理分析 OA
Fig 3-14: Hyperion 二維及三維紋理分析 Kappa
決定灰階共生矩陣三維計算時於光譜維度方向之最視核尺寸；搭配半變異分析所決定之空間視
窗尺寸，兩者整合所得之移動視窗尺寸可更精確地萃取細微的三維紋理特徵，以達到更佳的分
類成果。
參考資料
1. 賴哲儇、蔡富安，2009. 高光譜影像立方體於特徵空間之三維紋理計算，第 28屆測量及
空間資訊研討會，中壢。
2. Akono, A., Tonyé, E., Nyoungui, A. N., and Rudant, J.-P., 2003. Nouvelle méthodologie 
d'évaluation des paramètres de texture d'ordre trois, International Journal of Remote Sensing, 
24(9): 1957-1967.
3. Arivazhagan, S., and Ganesan, L., 2003, “Texture Segmentation Using Wavelet Transform”. 
Pattern Recognition Letters, Vol. 24, No. 16, pp. 3197-3203.
4. Clausi, D. A., 2002, “An analysis of co-occurrence statistics as a function of grey level 
quantization”, Canadian J. Remote Sensing. Vol. 28, pp. 45-62.
5. Haralick, R. M., Shanmugam, K., and Dinstein, I., 1973, “Texture Features for Image 
Classification”. IEEE Transactions on Systems, Man, and Cybernetics, Vol. 3, pp. 610-621.
6. Jobanputra, R., D. A. Clausi, 2006, “Preserving boundaries for image texture segmentation 
using grey level co-occurring probabilities”. Pattern Recognition, Vol. 39, pp. 234-245.
7. Kourgli, A. and A. Belhadj-Aissa, 2004, “Texture primitives description and segmentation using 
variography and mathematical morphology”. IEEE International Conference on Systems, Man 
and Cybernetics, Oct. 2004, Vol. 7, pp. 6360-6365.
8. de Martino, F. Causa and S. B. Serpico, 2003, “Classification of optical high resolution images 
in urban environment using spectral and textural information”. In IGARSS'03, Vol. 1, pp. 467-
469.
9. Tsai, F. and M.-J. Chou, 2006, “Texture Augmented Analysis of High Resolution Satellite 
Imagery in Detecting Invasive Plant Species”. Journal of the Chinese Institute of Engineers, 
Vol. 29, No. 4, pp. 581-592.
10. Tsai, F., C-K Chang, J-Y Rau, T-H Lin, G-R Liu, 2007, "3D Computation of Gray Level Co-
Occurrence in Hyperspectral Image Cubes", Lecture Notes in Computer Science, vol. 4676, pp. 
429-440.
11. Lai, J-S and F. Tsai, T-H Lin, G-R Liu, 2008, "Three Dimensional Texture Computation of 
Gray-Level Co-occurrence Tensor in Hyperspectral Image Cubes", Proc. 29th Asian Conference 
on Remote Sensing (ACRS2008), Nov. 10-14, Colombo, Sri Lanka.
2010 國際空間資訊理論、資料處理、及模式聯合學術研討會
蔡富安
國立中央大學太空及遙測研究中心
一、前言
2010 國際空間資訊理論、資料處理、及模式聯合學術研討會 (2010 Joint 
International Conference on Theory, Data Handling and Modelling in GeoSpatial 
Information Science) 是國際航測遙測學會(International Society of Photogrammetry 
and Remote Sensing, ISPRS)第二委員會(Commission II)和國際地理聯盟
(International Geographical Union, IGU)之地理資訊系統和地理系統模式兩個委員
會針對空間資訊理論、資料處理、和系統模式等主題所共同主辦的國際學術研討
會。ISPRS 各委員會在每四年一次的大會間會舉辦所謂的 Inter-Congress 研討會，
並且經常結合其他相關研討會共同舉辦以擴大規模並進行交流。本次聯合研討會
雖然只是中等規模，但參與的人士都是國際上空間資訊領域頂尖的教授和學術研
究人員。會議的規模雖然不大，但會議中所發表的論文品質都很高，會議由數百
篇投稿論文中經不具名評審，只接受約百分之二十至百分之三十。本次聯合研討
會在香港理工大學(Hong Kong Polytechnic University)舉行。今年初，本研究團隊
的論文在經過嚴格審核後，獲得接受於研討會中進行口頭發表。本人代表本研究
團隊參與此一研討會，進行論文發表，並與其他與會之專家學者進行交流。
二、參加會議經過
此次會議從五月二十六日至五月月二十八日，涵蓋三個工作日。除第一天
早上的報到與開幕式和邀請專題演講以及最後一天下午的事務討論外，其餘每個
工作日上、下午皆各安排有四個時段四個平行場次(parallel sessions)的口頭論文發
表。會議大致分成數個主題以收錄論文與安排發表場次。與會人士來自除當地及
大陸各地的教授、學者、及研究生外，並有來自美國、加拿大、法國、德國、義
大利、奧地利、荷蘭、澳洲、日本等地的教授、研究人員、和研究生。而參與的
各國教授包括許多 ISPRS 和 IGU 的重要人士，包括 ISPRS 的主席。此外，還有一
與要求所屬研究生積極參與如亞洲遙測研討會等國際會議的信念與決心，但更希
望學校當局及國科會等機關能提供經費之補助。
而香港地區的幾所大學利用此一機會在會場設立攤位，推廣空間資訊的大
學和高等教育，顯示對這一方面的教育市場有極旺盛的企圖心，而且具體實踐國
際化。這是台灣空間資訊教育極待努力加強的部分。
四、建議
此一研討會雖然只有中等規模，但不論其內涵及品質都具國際一流水準，
且與會的國際學者專家有許多重量級人士。反觀台灣地區只有本人及台大一位教
授與會，且只有本人進行論文發表。顯示台灣地區對此一領域的國際參與仍有待
加強。日後除更積極參與類似會議和活動外，當可盡力爭取類似國際學術研討會
的主辦。這一類的研討會不論在論文的創新性和品質都有不錯的水準，因此舉辦
這類研討會不僅可提高校方和中心在學術界的能見度，對於學術地位的提昇也有
幫助。目前國立中央大學大學太空及遙測研究中心已成功爭取到 2010 年亞洲遙測
研討會在台舉辦，算是一個很好的開始，也希望藉由舉辦這類國際研討會增加參
與重要國際學術組織的機會和份量。
五、攜回資料
此次會議本人除攜回研討會之論文集外，另帶回與會專家學者所提供之其
他相關論文及資料。這些文獻和資料提供了許多目前空間資訊研究與應用上的嶄
新觀念與方法，對於將來更進一步發展創新之三維空間資訊系統建置和應用提供
極大的助益。另外也攜回一些香港學校的招生資料，可做為將來推廣本校空間資
訊教育的參考和學習。
The reason of applying tile-based approach is that it is easy to im-
plement view-dependent visualization for reducing the amount
of data to process and render. However, a disadvantage in tile-
based terrain visualization is the cracks caused by discontinuities
(T-junctions) among tile boundaries. A commonly adopted tech-
nique to compensate this artifact is applying a pseudo generic
texture layer beneath the terrain surface (Pouderoux and Marvie,
2005). Nevertheless, other than not providing true textures, this
workaround will not work if the view angle is too low. A mesh
refinement procedure was developed to address this issue. Tak-
ing Fig. 2 as an example, the procedure to remove T-junctions is
listed in Algorithm 1.
Figure 2: T-junction removal
Algorithm 1 T-junction removal procedure
1. Starting from T1 and A1, because T1 = A1, they remain
unchanged.
2. Moving to the next pair, because T2 6= A2, there exists a
T-junction.
3. Remove Ta and add two new triangles, ∆(T1,T5,A2) and
∆(A2,T5,T2).
4. Continue the process from T2 and A3 and a new T-junction
is found at T3.
5. Replace Ac with ∆(A3,T3,A7) and ∆(A7,T3,A4).
Combining these algorithms, the proposed tile-based quad-tree
processing of terrain meshes can generate multiple LODs of large
digital terrain datasets based on different viewing parameters.
The algorithms can reduce data to process and render while pre-
serving important terrain features. In addition, the adaptive data
structure enables progressive transmission of data streams. All
together, they provide high-performance terrain visualization ca-
pability for real-time applications.
3 MULTI-RESOLUTION 3D BUILDING MODELS
Unlike terrain data, most 3D building models used in cyber city
implementations are not in mesh format. Therefore, mesh-based
LOD schemes may not be applied to the process of building mod-
els. A few approaches have been proposed to deal with the LOD
generation of 3D building models. For example, an algorithm
based on mathematical morphology and curvature space of scale-
spaces theory was presented to generalize 3D building models
(Mayer, 1998). The algorithm was further refined by moving par-
allel facets toward each other to eliminate protrusion and close the
gaps (Forberg, 2007). Another type of approach is segmenting
building models into several structural elements and performing
generalization on individual building segments, such as applying
half-space modeling by cell decomposition and primitive instanc-
ing (Kada, 2007) or simplifying 2D projections of 3D geometries
but only with linear and neighboring building groups (Anders,
2005).
Most of existing LOD techniques for 3D building models are
either computationally expensive or are limited to certain types
of buildings. A semi-automatic generalization approach is pro-
posed to provide better multi-resolution representation of com-
plicated building models. The idea is to apply generalization in
2D orthographic views of individual buildings and then recon-
struct simplified 3D models accordingly as illustrated in Fig. 3.
The process can be repeated with different generalization param-
eters so multiple levels of details can be created. The principle is
similar to Anders (2005), but the procedure and algorithms em-
ployed in this study is very different. Anders (2005) utilized a
program (CHANGE), which was originally designed to aggregate
two-dimensional building ground plans for the generation of to-
pographic maps, to simplify three projections of building groups
and then grue them to form 3D block models. This approach
is efficient for linear building groups but might not be adequate
for complex buildings. On the other hand, the algorithms devel-
oped in this study is a divide-and-conquer strategy that is capable
of dealing with building models with complicated structures and
shapes. In addition, the developed algorithms can also general-
ize buildings with non-orthogonal façades, which are difficult to
handle using existing methods.
Figure 3: LOD for 3D building models
Before applying the generalization process, a geometric structure
analysis is conducted to determine the complexity of each build-
ing and its number of levels to generalize. The shape complexity
is defined as Eq. (3), where Nr is the number of vertices of the
roof polygon and NC is the number of vertices of the 3D convex
hull of all roof structures. A few examples of shape complex-
ity are demonstrated in Fig. 4. Based on calculated shape com-
plexity, necessary levels of detail for individual building models
can be determined. For instance, the most complicated model
(SC=0.72) in Fig. 4 may require four levels of generalization
while the second case (SC=0.3) may need only two levels.
SC =
Nr−NC
Nr
(3)
sc= 0 sc= 0.3 sc= 0.51 sc= 0.72
Figure 4: Shape complexity examples
After determining the levels to generalize, at least three ortho-
graphic projections of each building are generated and converted
into raster formats. Then, a series of morphological operations
(including dilation, point in polygon elimination, and erosion) is
applied to create raster versions of the orthographic projections
for constructing the outlines of building models as demonstrated
in Fig. 5. A topology connector, which is modified from the
Target Defined Ground Operator (TDGO) (Chen and Lee, 1992),
validate their performances. Figure 10 shows the LOD1, 3 and 5
of a large terrain mesh and the comparison with Delaunay trian-
gulation. Both the proposed quad-tree based LOD processing and
Delaunay triangulation can effective reduce the data in different
LOD levels.
(a) LOD1 (3087 vertices) (b) Delaunay LOD1
(c) LOD3 (5808 vertices) (d) Delaunay LOD3
(e) LOD5 (14900 vertices) (f) Delaunay LOD5
(g) Textured LOD1 (h) Textured Delaunay LOD1
Figure 10: Terrain LOD with proposed method (left) and Delau-
nay triangulation
Although it may appear that Delaunay has better triangulated
meshes, the proposed method can also preserve important terrain
features in different LODs. (If the meshes are textured, the dif-
ference between the two is almost indistinguishable, even in the
low resolution LOD1 as displayed in Fig. 10g and h.) More im-
portantly, the data structure of the proposed Quad-tree processing
is more organized than Delaunay and makes the rendering more
efficient. Taking T-junctions removal as an example, Delaunay
will require significantly more efforts to remove T-junctions be-
cause the triangles on tile edges are irregular. In addition, for De-
launay triangulations, it will be inefficient to use the “difference
vectors” scheme because vertices in different levels of Delaunay-
based LOD do not have an “add-on” property. Therefore, it will
be difficult, if not impossible, to achieve progressive transmission
and adaptive rendering of Delaunay-based LOD tiles and thus in-
adequate for real-time visualization applications.
Figure 11 shows the effect of T-junction removal. From the fig-
ure, the crack at the tile boundary has been repaired with the
proposed mesh refinement algorithm and resulting in a seam-
less terrain scene. The proposed mesh refinement algorithm is
very efficient. In previous tests (Tsai and Chiu, 2008), the CPU
time used to remove T-junctions at run-time was almost negligi-
ble and caused insignificant impact to the rendering performance.
Figure 12 shows the comparison of accumulated CPU time for a
fly-through of a large terrain (originally 5022 by 9555 grids and
partitioned into 10 by 19 tiles) with and without performing T-
junction removal while rendering the terrain meshes. It is clear
that applying T-junction removal has increased very little render-
ing time, but the improvement in visual quality is significant as
demonstrated in Fig. 11.
Figure 11: T-junction removal
Figure 12: Cumulative rendering time comparison of T-junction
removal
The proposed terrain LOD generating algorithms were tested with
two large DEM datasets in different scenarios (Tsai and Chiu,
2008). From the tests, the frame rate of rendering can achieve
at least 24.5 FPS (frames per second) within two-pixels error on
screen display even in a very complicated mountainous terrain.
This should be adequate for real-time visualization and applica-
tions.
Figure 13 displays an example of generated multiple building
level of detail (BLOD) from a fairly complicated 3D building
model. In this example four different levels of detail were gen-
erated with the generalization algorithms described above. From
the figure, it is clear the generalization has effectively reduced
the number of polygons from 290 to 61, 19 and 7 subsequently.
Although the data (polygon) amount has been reduced signifi-
cantly in lower-resolution building models, the characteristics of
the building has been preserved.
Table 1: Data reduction rate of BLOD
BLOD3 BLOD2 BLOD1 BLOD0
Points 61795 22825 17535 16110
Reduction rate 37% 28% 26%
Polygons 14045 5350 4175 3841
Reduction rate 38% 30% 27%
One thing to note is that it seems data reduction is more ag-
gressive when generalizing the models from BLOD3 to BLOD2
than the rest generalization. This might caused by inappropriate
thresholding for generalization. However, BLOD3 is the origi-
nal (most detailed) building model and consists of many minor
structures. (This can be observed from the examples presented
in previous figures.) Therefore, it is expected to have a signif-
icant reduction in terms of point and polygon numbers, but the
geometric shapes or characteristics of the models do not deform
too dramatically. In addition, the buildings are treated indepen-
dently, thus building aggregation may seem necessary. Whether
to aggregate building groups should depend on the objective of
applications. If it is necessary, aggregation should be performed
with additional merging process.
5 CONCLUSIONS
This paper presents systematic approaches to create multiple lev-
els of detail for digital terrain and building models. For terrain
meshes, a tile-based quad-tree processing with thresholds deter-
mined from ground sampling distance under different viewing pa-
rameters is suggested to generate terrain LODs. A mesh refine-
ment procedure to correct discontinuities (T-junctions) among tile
edges is also presented, which can eliminate discontinuities be-
tween adjacent tile meshes effectively and have little impact to
the overall rendering performance. For 3D building models, an
iterative procedure based on algorithms for generalization on 2D
orthographic projections and reconstructing simplified 3D mod-
els is proposed. For special structures of building models, addi-
tional processes are developed to simplify them but maintain their
characteristics. The developed algorithms are effective for indi-
vidual building models and large building groups with various
degree of complexity.
Examples demonstrated in this paper indicate that the developed
algorithms can be used for multi-resolution representation of com-
plicated terrain and building models effectively and efficiently.
All together, the proposed methods can increase the performance
of large cyber city implementation for real-time visualization and
applications. More importantly, while reducing the data amount
to transmit and process, the proposed multi-resolution represen-
tation methods can preserve important geometric and visual char-
acteristics of complicated terrain and building models
ACKNOWLEDGEMENTS
This study was partially supported by the National Science Coun-
cil of Taiwan under project No. NSC-98-2221-097-MY2.
References
Anders, K., 2005. Level of detail generation of 3d building
groups by aggregation and typification. In: Proc. of 22nd
International Cartographic Conference, La Coruña, Span.
Blow, J., 2000. Terrain rendering at high levels of detail. In:
Proceedings of Game Developers Conference, pp. 903–912.
Chen, L.-C. and Lee, L.-H., 1992. Progressive generation of con-
trol frameworks for image registration. Photogrammetric
Engineering and Remote Sensing 58(9), pp. 1321–1328.
Cignoni, P., Ganovelli, F., Gobbetti, E., Marton, F., Ponchio, F.
and Scopigno, R., 2003. BDAM-batched dynamic adaptive
meshes for high performance terrain visualization. In: Pro-
ceedings of EUROGRAPHICS, Vol. 22number 3, pp. 505–
514.
Coope, I. D., 1993. Circle fitting by linear and nonlinear least
squares. Journal of Optimization Theory and Applications
76(2), pp. 381–388.
Forberg, A., 2007. Generalization of 3d building data based on a
scale-space approach. ISPRS Journal of Photogrammetry &
Remote Sensing 62, pp. 104–111.
Gallier, J., 2000. Curves and Surfaces in Geometric Modeling.
Morgan Kaufmann, San Fancisco, CA USA.
Gröger, G., Kolbe, T. H., Czerwinski, A. and Nagel, C., 2008.
OpenGIS city geography markup language (CityGML) en-
coding standard. Technical Report OGC-08-007r1, Open
Geospatial Consortium Inc. v. 1.0.0.
Kada, M., 2007. Generalization of 3d building models by cell de-
composition and primitive instancing. In: Proc. Joint ISPRS
Workshop on Visualization and Exploration of Geospatial
Data, Stuttgart, Germany.
Losasso, F. and Hoppe, H., 2004. Geometry clipmaps: Terrain
rendering using nested regular grids. ACM Transactions on
Graphics 23(3), pp. 769–776.
Luebke, D., Reddy, M., Cohen, J. D., Varshney, A., Watson, B.
and Huebner, R., 2003. Level of Detail for 3D Graphics.
Morgan Kaufmann Publishers.
Mayer, H., 1998. Three dimensional generalization of build-
ings based on scale-spaces. Technical report, Dept. of Pho-
togrammetry and Remote Sensing, Technische Universität
München, Germany.
Pouderoux, J. and Marvie, J.-E., 2005. Adaptive streaming and
rendering of large terrains using strip masks. In: Proceed-
ings of ACM GRAPHITE 2005, pp. 299–306.
Tsai, F. and Chiu, H.-C., 2008. Adaptive level of detail for terrain
rendering in cyber city applications. International Archives
of Photogrammetry, Remote Sensing and Spatial Informa-
tion Sciences XXXVII-B4, pp. 579–584.
Tsai, F., Liu, H.-S., Liu, J.-K. and Hsiao, K.-H., 2006. Progres-
sive streaming and rendering of 3d terrain for cyber city vi-
sualization. In: Proc. ACRS2006, Ulaanbatar Mongolia.
96年度專題研究計畫研究成果彙整表 
計畫主持人：蔡富安 計畫編號：96-2221-E-008-062-MY3 
計畫名稱：遙測資料三維紋理分析 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 1 1 100%  
研究報告/技術報告 3 3 100%  
研討會論文 3 3 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 3 2 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 1 1 100%  
研究報告/技術報告 0 0 100%  
研討會論文 3 3 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
 
