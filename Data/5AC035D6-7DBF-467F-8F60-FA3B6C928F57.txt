 2 
 
 
 
 
which is through the analysis of the visitor’s navigational behavior, can quickly tell 
malicious injection tools from welcome crawlers (such as a search engine) while not 
affecting the functionality and ease of use of a protected website.  
There are two main contributions in this paper. First, it uses a specific Web page named 
Filer page to deeply reduce the load of preprocessing session. Thus the automated injection 
tools can be quickly distinguished while crawling is still in progress. Second, it shows a 
crawling screen named Injection Guard to identify automated injection tools based on 
navigational behavior. Therefore, the speediness of distinguishability is independent on the 
amount or components of Web pages since we plant hidden link hooks in every Web page 
and use the ingenious Filter page as common Web page for distinguishing. Our scheme can 
be used on various Web sites.  
The paper is organized as follows: Section 2 describes the processes of the automated 
injection tools in detail. In section 3, we describe the technical details of detecting 
automated injection tools. The experiments are evaluated in section 4. The last section 
summarizes conclusions. 
 
2. How Automated Injection Tools Work. Most automated tools work based on the same 
basic functionality built on a concept of crawling and fault injections [9]. The processes of 
their work are shown in Figure 1. These tools usually rely on some kind of crawling to get a 
list of links, forms and other information used by following work. The common crawler can 
only discover all static pages in a Web site. Another Web crawler, named enhanced crawler, 
can uncover the hidden Web pages that the common crawler can’t. Here the Web pages that 
are hidden behind HTML forms are called hidden Web. The differences between the two 
crawlers are demonstrated in Figure 1. The left part of the flowchart indicates the execution 
loop of the common crawler, the middle part distinguishing between pages with and 
without forms and the right part shows the additional actions for pages on which forms are 
detected. Form analyzing and form filling are main differences between common crawler 
and enhanced crawler.  
According to Figure 1, the enhanced crawler can create an injection list including a part 
of the injection points and their respective parameters after the processes of crawling Web 
and analyzing form. Afterward various values selected from the domain of each form 
element are automatically assigned to input element to perform automated form filling. 
Here the aim of response handling is to automatically distinguish between a response page 
[10]. Based on the feedback from the response handling, the form filling module can tune 
the strategy of assigning value at run time to fill proper value. To detect vulnerabilities in 
applications, the automated injection tools often use injector to perform fault injections. 
Some attack patterns (a range of knowingly bad characters or content) and their expected 
responses stored in another table can be used to be injected automatically via automated 
injector to elicit vulnerabilities which can be exploited to launch attacks. 
 4 
 
 
 
 
 
3.2 Discovery of Automated Injection Tools. All visitors embedded Web crawlers will be 
caught by hidden link hooks but the greater part of them may not belong to automated 
injection tools. Thus they should be further classified based on navigational behavior. 
According to Figure 1, the automated injection tools comprise enhanced crawler and 
injector. To lunch an injection while crawling is a special navigational behavior for 
automated injection tools. Thus we can use the signature to tell them from other crawlers. 
There might not be necessary embedded objects for differentiating crawlers based on 
navigational behavior in common Web page, so a special Web page, named Filter page, is 
designed meticulously to supply embedded objects such as form components. All HTTP 
request from various Web crawler will be trapped into hidden link hooks and led into the 
Filter page. The automated injection tools must perform form analyzing and form filling in 
the form component of the Filter page for retrieving hidden Web pages. To keep the visit 
information of the requests for the embedded objects, we must redirect all traffic to the 
Filer page to the special Web page named Classifier. The traffic will be separated based on 
the different situations described as follows. (1) If the query string misses parameters, it 
means the request is sent by common crawler. (2) If the query string has parameters, it 
means the request is sent by enhanced crawler or injector. Therefore the Classifier can 
differentiate between common crawler and enhanced crawler via the type of a query string. 
The Classifier is also capable of analyzing the HTTP request headers to get necessary visit 
information and then saved to the respective logfiles in the Logger. The processes of 
discovery of automated injection tools are presented in Figure 2. 
 
4 Implementation and Experimental Evaluation. We propose a novel scheme named 
Injection Guard to detect the automated injection tools and stop them according to security 
policy. All processes of the system can be portioned out three phases and shown in Figure 2. 
The Phase 1 is responsible for accurately tell apart human users and Web crawler as 
quickly as possible. The works relative to it have been described in subsection 3.1 in detail. 
Figure 2 The diagram of the Injection Guard
 6 
 
 
 
 
results are encouraging and provide early evidence that showed the effectiveness of the 
Injection Guard.  
 
5 Conclusions. The automated injection tools and WVS can be used to uncover 
vulnerabilities for being exploited by attackers. Therefore it is a necessary task to ensure 
the WVS or the automated injection tools being legitimately used. In this paper, we come 
up with an Injection Guard to detect and remove automated injection threats according to 
security policy. Our scheme can redirect all suspected crawlers’ traffic to the Classifier 
through Filter page and distinguish them by means of matching feature. The work of 
grouping together the Web log entries into a session log according to their IP address and 
agent fields while date is within a threshold period is unnecessary, so we can quickly 
distinguish the automated injection tools while they are still in progress. Our scheme can 
guarantee the speediness of distinguishability and it is suitable for various Web sites. 
 
REFERENCES 
 
[1]  K. Park, V. S. Pai, K. W. Lee and S. B. Calo, Securing Web Service by Automatic 
Robot Detection, in: Proceedings of the 2006 USENIX Annual Technical Conference. 
[2]  G. Ollmann, Stopping Automated Attack Tools, http://www.ngssoftware.com/papers/. 
[3]  Yang Sun, Isaac G. Councill and C. Lee Giles, BotSeer:An automated information 
system for analyzing Web robots, in Proceedings of the Eighth International 
Conference on Web Engineering, pp.108-114, 2008. 
[4]  P-N. Tan, V. Kumar, Discovery of Web robot sessions based on their navigational 
patterns, Data Mining and Knowledge Discovery, Volume 6, Number 1, January 2002 , 
pp. 9-35(27). 
[5]  Weigang Guo; Shiguang Ju; Yi Gu , Web robot Detection Techniques Based on 
Statistics of their Requested URL Resources, Proceedings of the Ninth International 
Conference on Computer Supported Cooperative Work in Design, 2005, Vol. 1 
Page(s): 302 – 306 
[6]  J. C. Lin, J. M. Chen, Tien-Wei Lin and Shu-Wei Yang, A Multi-level Sanitizing 
Strategy Based on Injection Point, Int. J. of Innovative Computing, Information and 
Control, Vol. 3, No. 3(A), pp. 471-476, 2009. 
[7]  T. Nakashima, S. Oshima and T. Sueyoshi, Observation-based Detective Method for 
SYN Flooding Attacks, Trans. International Journal of Innovative Computing, 
Information and Control, Vol.4, No.3, pp. 749-759, 2008. 
[8]  Captcha, http://www.captcha.net/. 
[9]  Y. Kadakia, Automated Attack Prevention, 
http://www.acunetix.com/vulnerability-scanner/ yashkadakia.pdf. 
[10]  S. Raghavan and H. Garcia-Molina, Crawling the hidden Web, in: Proceedings of the 
27th VLDB Conference, pp. 129–138, 2001. 
TABLE 2: The speediness and accuracy of distinguishability of the Injection 
Guard 
Crawler type Phase no. Min. request number 
Avg. request 
number Accuracy 
Common crawler 1 2 5.7 100% 
Enhanced crawler 2 4 8.7 100% 
表 Y04 
行政院國家科學委員會補助國內專家學者出席國際學術會議報告 
                                                           99 年  9 月  10 日 
報告人姓名  陳建民 
 
服務機構
及職稱 
育達商業科技大學 
 
助理教授 
     時間 
會議 
     地點 
2010年 9 月 6 日至 8日 
中國大陸大連市 
本會核定
補助文號
NSC 99-2221-E-412 -003 
會議 
名稱 
 (中文)第三屆國際智慧資訊討論會 
 (英文) The Third International Symposium on Intelligent Informatics 
發表 
論文 
題目 
 (中文) 基於瀏覽行為防禦自動注入攻擊工具的方案 
 (英文) Stopping Automated Injection Attack Tools Based on Navigational 
Behavior 
附件三
 
 
Dear Dr. JAN-MIN CHEN, 
  
It is our pleasure to inform you that your paper, 
  
Reference No.: ISII2010-078 
Title: Stopping Automated Injection Attack Tools Based on Navigational Behavior 
Author(s): JAN-MIN CHEN AND JIN-CHERNG LIN 
  
submitted to The Third International Symposium on Intelligent Informatics (ISII2010),
which will be held on September 5-7, 2010, in Dalian, China, has been accepted for an oral
presentation at the symposium, and for the publication in ICIC Express Letters (ICIC-EL)
with the conditions described below. Please prepare your paper (No more than 6 pages)
based  on  the  Acceptance  Conditions  and  ICIC  Express  Letters  style  (download  from
http://www.ijicic.org/icicel.htm) for publication. 
  
----------------------------------------------------------- 
Acceptance Conditions: 
  
1) The motivation on the study should be further emphasized.  The key features of  the
results  obtained compared with  some existing  ones should  be  clearly  explained in  the
Introduction section.  
  
 2) English should be substantially improved. The authors should carefully and thoroughly
check the paper, and correct all the grammar and composition mistakes in the final version. 
  
3)  Please  cite  some  recently  published  papers  in  IJICIC  (www.ijicic.org  )  or  ICIC-EL
(http://www.ijicic.org/icicel.htm) in your paper, which is related to the topic in the paper, and
this will promote your work in wider community and have a positive impact on the journal.  
  
Please note that if the paper is not revised satisfactorily complying with the Acceptance
Conditions  above,  ISII2010  Committee  reserves  the  right  to  reject  the  paper  from the
symposium.    
----------------------------------------------------------- 
  
Please send the final version of your paper (either LaTex source files, or both Word and
PDF  files)  together  with  completed  Registration  Form  (download  from
http://www.ijicic.org/isii2010.htm) to ISII2010 (isii2010@ijicic.org) before June 10, 2010. 
  
Please note that if we do not receive BOTH your Final Version and the Registration Fee
before June 10, 2010, we will assume that you have decided to withdraw your paper(s)
from  ISII2010,  consequently,  not  be  published  in  ICIC-EL. Thank  you  for  your
understanding and cooperation. 
  
The further 
 information concerning ISII2010 can be fund out at the website: http://www.ijicic.org/isii2010.htm 
  
來源: icic_international@yahoo.co.jp 
收信: ydjames@webmail.ydu.edu.tw 
副本: isii2010@ijicic.org 
日期: Wed, 21 Apr 2010 12:11:26 +0900 (JST) 
標題: Acceptance Letter: ISII2010-078 
Page 1 of 3
  
Dr. Xiangwei Kong 
Program Committee Chair, ISII2010 
Professor, School of Electronic and Information Engineering 
Dalian University of Technology 
No.2, Linggong Rd., Dalian, China 
Tel.: +81-411-84706368 
  
  
Dear Editor: 
        Append file is a manuscript to ISII2010. Please acknowledge me if you had 
received the email, thanks. My contact information is as follows: 
  
Paper Title :Stopping Automated Injection Attack tools Based on Navigational 
Behavior 
Author: Jan-Min Chen (ydjames@ydu.edu.tw) 
  
Thank you for your help. 
Sincerely yours 
  
Jan-Min Chen 
  
March 9, 2010 
  
 
 
===================== 
コニヒサ糂フ鯱ラEmailオ・ー゜ 
床゜ナェケ．ハ・・・トトキ　膜家lt;BR>===================== 
 
Get the new Internet Explorer 8 optimized for Yahoo! JAPAN 
Get the new Internet Explorer 8 optimized for Yahoo! JAPAN
Page 3 of 3




99 年度專題研究計畫研究成果彙整表 
計畫主持人：陳建民 計畫編號：99-2221-E-412-003- 
計畫名稱：基於瀏覽行為防禦非授權網頁爬蟲的自動機制 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 1 1 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 2 2 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 1 1 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
國科會補助專題研究計畫成果報告自評表 
請就研究內容與原計畫相符程度、達成預期目標情況、研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）、是否適
合在學術期刊發表或申請專利、主要發現或其他有關價值等，作一綜合評估。
1. 請就研究內容與原計畫相符程度、達成預期目標情況作一綜合評估 
■達成目標 
□未達成目標（請說明，以 100 字為限） 
□實驗失敗 
□因故實驗中斷 
□其他原因 
說明： 
2. 研究成果在學術期刊發表或申請專利等情形： 
論文：■已發表 □未發表之文稿 □撰寫中 □無 
專利：□已獲得 □申請中 ■無 
技轉：□已技轉 □洽談中 ■無 
其他：（以 100 字為限） 
3. 請依學術成就、技術創新、社會影響等方面，評估研究成果之學術或應用價
值（簡要敘述成果所代表之意義、價值、影響或進一步發展之可能性）（以
500 字為限） 
學術成就： 
我們一直致力於防禦網頁應用程式弱點攻擊方法的研究 [1-3]，在研究过程中，使我們關
注到網頁爬蟲識別問題的重要性，我們提出了更簡單、有效且即時的網頁爬蟲識別方法，
此方法透過組合各種爬蟲陷井的特性，整合成一個可不破壞網站易用性卻能成功即時區別
人、善意及惡意的網頁爬蟲的系統 [4]，在更進一步觀查及研究網頁爬蟲的行為後，我們
已提出了可分辨出人、網頁爬蟲及進階網頁爬蟲的可行方法，並有了初步成果[5]，所發
表之相關論文如下。 
[1] J. C. Lin, J. M. Chen and H. K. Wong, ’An Automatic Meta-revised Mechanism 
for Anti-malicious Injection,’ LNCS 4658, pp. 98-107, 2007. 
[2] J. C. Lin, J. M. Chen, T. W. Lin and S.W. Yang, ’A Multi-level Sanitizing 
strategy Based on Injection Point,’ ICIC Express Letters, Vol.3, No.3(A), 
pp.471-476 , 2009. 
[3] J. C. Lin and J. M. Chen, ’An Automated Mechanism for Secure Input Handling,’ 
JOURNAL OF COMPUTERS, VOL. 4, NO. 9, pp. 837-844, 2009. 
[4] J. C. Lin and J. M. Chen, ’A Harmless Mechanism for Stopping Malicious 
Crawler,’ International Journal of Innovative Computing, Information and 
Control, VOL. 6, NO. 5, pp. 2310-2317, 2010. 
[5] J. M. Chen, ’Stopping Automated Injection Attack Tools Based on Navigational 
