Abstract 
A new shape recognition-based neural network built with universal feature planes, called 
Shape Cognitron (S-Cognitron) is introduced to interpret the features of clustered 
microcalcifications (MCC’s) proposed by breast image report and data system (BIRADS). The 
architecture of S-Cognitron consists of two modules (each has two layers) and an extra layer, 
called 3-D figure layer lies in the between. The first module contains a shape orientation layer, 
which built with 20 cell planes of low level universal shape features, is to convert first-order 
shape orientations into numeric values, and a complex layer, which combines the orientation 
information in the shape orientation layer and extracts second-order shape features. The 3-D 
figure layer is a feature extract-display layer that extracts the shape orientations of an input 
pattern and displays the input 2-D pattern as a 3-D figure using the numeric representations of the 
shape orientations generated by the first module as the elevation of the input pattern to show 
orientations in the third dimension. It is then followed by a second module made up of a feature 
formation layer and a probabilistic neural network (PNN)-based classification layer where the 
feature formation layer constructs "potential" high-order shape features and feeds them to the 
PNN for classification. The performance of the entire system using S-Cognitron in classification 
of clustered MCCs is evaluated by using Nijmegen mammogram database and experimental 
results show that sensitivity and specificity can reach 86.1% and 74.1% respectively. 
Keywords: Classification; Microcalcifications (MCCs); Neural Networks; Probabilistic neural 
network (PNN); Shape Cognitron (S-Cognitron) 
 
 Figure 1: Architecture of S-Cognitron 
 
2.1. Input layer U0 of S-Cognitron 
The input pattern shows MCCs as a binary image corresponding to an ROI which contains a 
cluster of MCCs. The prior information of an ROI includes the area of region over MCCs -- Ac 
and the number of blobs, NB.  The size of the input patterns in U0 is fixed at NN × , where N is 
256 used in our system, which can vary subject to applications. 
2.2. First Module (S1,C1) of S-Cognitron 
This module can be thought of as a shape orientation conversion module, which converts 
shape orientations from input patterns into numeric values. Two layers are composed in this 
module. One is called S1 layer, where contains 20 NN ×  cell planes caused by 20 masks (see 
Figure 2), which is designed to extract first-order shape of orientation features by three window 
masking processes built with universal feature planes. The other is called C1 layer, where contains 
8 NN ×  cell planes obtained from S1 layer (see Figure 4), which is to combine/fuse first-order 
shape orientations into second-order shape features. s a result of using these 20 window masking 
processes, a total of twenty NN ×  cell planes will be generated, one for each window masking 
process. For demonstration, weights generated by spatial patterns in Figure 2 to represent 8 
typical geometric patterns, each of which corresponds to various orientation, 22.5o  (i.e., < 45o ), 
45o , 90o , 135o , 180o , 225o , 270o , and 360o , shown in Figure 3. 
 Figure 3: Weights generated by spatial patterns in Fig. 2 to represent 8 different geometric 
patterns, each of which corresponds to various orientation, 22.5o  (i.e., < 45o ), 45o , 90o , 
135o , 180o , 225o , 270o , 360o  
figures produced in this layer for a number of clustered MCC’s where the numeric value of each 
pixel in the pattern was obtained in accordance with the numeric representations of shape 
orientations given in Table 1. 
 
Figure 5: Numeric values of 3-D figure layer generated by spatial patterns in Fig. 4 to represent 8 
different geometric patterns, each of which corresponds to various orientation, 22.5o  (i.e., 
< 45o ), 45o , 90o , 135o , 180o , 225o , 270o , 360o  
  
 
 (a) (b) 
2.4. Second Module ),( 22 CS  of S-Cognitron 
2.4.1. Feature formation layer 2S : 
We follow the criteria proposed from the Breast Imaging Reporting and Data System 
(BI-RADS) which was developed by the American College of Radiology. These criteria are based 
on the numbers of MCC’s, morphologic appearances, arrangements, concentrations, distributed 
sizes and densities, etc. Based on the guidelines, 8 important shape features were generated in 
layer 2S  from shape orientation. Different parameters were designed to generate the 8 features 
by using convolution planes in this layer. For example, iN  can be computed from the 3-D figure 
pattern by the convolution formula [ ]∑∑
= =
−
N
i
N
j
ij ihu
1 1
)(  where ijh  is the elevation of the pixel 
located at the (i,j) position and )(xu  is the unit step function, i.e.,  0for x  1)( ≥=xu and 0, 
otherwise.  
 
2.4.2. Classification layer 2C : 
This layer is regarded as a classification or recognition layer in which a probabilistic neural 
network (PNN) is implemented. Features generated in layer 2S  are served as the inputs to the 
network. Through a statistical evaluation, the outputs provide the likelihood of malignance of 
MCC’s associated with the input pattern. A more detailed description of this layer will be shown 
in the next section. 
In summary, how S-Cognitron works is described in the flow chart given in Figure 7. It (1) 
first takes the detected MCC’s produced by the MCC’s detection system as input patterns in layer 
0U , (2) uses the first module ),( 11 CS  to convert universal shape orientation information to 
numeric representations, (3) extracts and displays the numeric values in the shape feature 
dimension in the 3-D figure layer, (4) employs the second module ),( 22 CS  to format shape 
features in layer 2S  and fnally (5) classifies MCC’s in layer 2C . 
3. Experiments 
In this section, the 40-mammogram data base provided by the Department of Radiology at 
the University of Hospital Nijmegen in Netherlands was used for experiments to evaluate the 
proposed system. There are 21 cases with 7 cases being benign and 14 cases being malignant. 102 
ROIs were selected from these 40 mammograms, among which 29 ROIs are benign and 73 ROIs 
are malignant. The size of each ROI, NN ×  is set to 256256× . From these selected 102 ROIs, 
52 were randomly chosen for training cases (15 are benign and 37 are malignant) and the 
remaining 50 (14 are benign and 36 are malignant) for test cases. These sets of training patterns 
and test patterns were applied to the PNN in layer 2C . The parameter 
2σ  used in the PNN is 
set to 200.  
Table 3 shows the classification results for the test cases in number of patterns. The rejection 
(R) in Table 3 represents that the case is undetermined when applied to the system and thus, no 
 Table 2: 8 S-Cognitron generated features used for classification 
Note: ROI = region of interest; MCCs = microcalcifications; cA = the number of pixels of MCCs; RA =the area 
cover of MCCs; BN = the number of blobs. iN  = the total number of pixels of shape feature dimensional number no. 
i of 3-D figure layer within an ROI; 
Average Benign MCC’s ( 14 cases ) Malignant MCC’s ( 36 cases ) 
 B M R B M R 
cases 10 1 3 0 31 5 
Total number: 50 
B: Benign, M: Malignant, R: Rejected 
Table 3: Classification results using S-Cognitron are tabulated in benign cases and malignant 
cases respectively 
 
classification rate 
correct incorrect rejected 
82.0% 2.0% 16.0% 
 
Table 4: Classification rates for Table 3 
 
classification rate 
correct incorrect 
97.6% 2.4% 
 
Table 5: Classification rates with rejection ignored for Table 3 
 
 
TP FP TN FN 
