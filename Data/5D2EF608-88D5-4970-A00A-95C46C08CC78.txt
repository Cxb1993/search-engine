diagnosis support system is challenging since we need 
to consider a large number of risk factors, symptoms, 
and signs (RSS) of individual diseases, and moreover 
the RSS items are correlating and evolving. Therefore 
in this project, we propose to develop a text-based 
approach to developing a disease ranking system to 
provide disease diagnosis support online. Technical 
motivations of the text-based approach include (1) 
new medical findings are often written in text form, 
and (2) the input to a disease diagnosis system is 
often a description of RSS (from patients or medical 
students) that is in text form as well. In this 
project, we develop techniques to (1) extract from 
medical texts those passages that are about main 
aspects of diseases (the 1st year of the project), 
and based on the extracted passages (2) rank diseases 
with respect to the given RSS descriptions (the 2nd 
year of the project). Typical disease aspects include 
etiology, diagnosis, treatment, prevention, and 
symptoms. In the 1st year, we have developed a 
technique to extract (from medical texts) those 
passages that are related to various disease aspects. 
In the 2nd year, we have developed and tested two 
techniques that rank diseases with respect to the 
given RSS descriptions: disease ranking based on text 
classifiers and disease ranking based on document 
rankers. The research is of both theoretical and 
practical significance, and the interdisciplinary 
study may provide impacts to the communities of both 
information technology and healthcare. 
英文關鍵詞： disease diagnosis support, disease aspect 
information, text classification, disease ranking 
 
 2
symptoms. In the 1st year, we have developed a 
technique to extract (from medical texts) those 
passages that are related to various disease 
aspects. In the 2nd year, we have developed and 
tested two techniques that rank diseases with 
respect to the given RSS descriptions: disease 
ranking based on text classifiers and disease 
ranking based on document rankers. The 
research is of both theoretical and practical 
significance, and the interdisciplinary study 
may provide impacts to the communities of 
both information technology and healthcare. 
 
Keyword: disease diagnosis support, disease 
aspect information, text classification, disease 
ranking 
 
2. Introduction 
The Internet has been a main channel from 
which healthcare professionals and consumers 
get medical information services, and the 
critical success factor of the information 
services lies on the discovery of in-depth and 
relevant medical knowledge. To deal with the 
critical success factor, identification of the 
target disease is a fundamental step, since the 
management and treatment of specific diseases 
are the topmost information needs of users.  
Conceptually, a disease is caused by its 
risk factors, and then leads to several symptoms 
and signs that may be detected in the bodies of 
the patients. Therefore, diagnosis of a disease 
should consider the risk factors, symptoms, and 
signs (RSS) of individual diseases. The RSS 
sets for multiple diseases may form a diagnosis 
knowledge map in which there are many 
correlating and evolving relationships between 
diseases and their RSS items, since the RSS 
sets of two diseases may overlap with each 
other and the items in an RSS set for a disease 
may be updated by medical research. 
 
2.1 Problem definition and motivation 
In this project, we develop a text-based 
approach to building a DDS for disease 
diagnosis support. The text-based approach is 
motivated by three observations: (1) medical 
research findings are often recorded in texts, 
and hence a text-based approach is necessary in 
extracting the evolving relationships between 
diseases and their RSS items, (2) descriptions 
of RSS from patients are often in natural 
language text form, and hence a text-based 
approach is necessary in recognizing the natural 
language RSS descriptions, and (3) there have 
been many techniques developed for text 
analysis, and hence a text-based approach that 
integrates and improves the existing techniques 
to build a DDS is of significance. 
More specifically, in the two-year project, 
we develop the techniques to (1) extract from 
medical texts those passages that are about 
main disease aspects, including  etiology, 
diagnosis, treatment, prevention, and symptoms 
(the 1st year of the project), and based on the 
extracted passages (2) rank diseases with 
respect to the given RSS descriptions (the 2nd 
year of the project). 
 
2.2 Main challenges and contributions 
Main challenges of the project include (1) 
medical texts are often written for a specific 
disease and hence often contain information 
about multiple aspects of the disease, and (2) 
the description of RSS input by a patient is 
often quite brief and does not necessarily 
correspond to a single disease. To tackle the 
first challenge, we model the disease aspect 
identification problem as a text classification 
(TC) problem, and hence focus on the 
extraction of passages that are related to 
individual disease aspects. For the second 
challenge, we approach the disease ranking 
problem by both text classification and 
document ranking techniques.  
Accordingly, in the 1st year, we develop a 
technique to extract (from medical texts) those 
passages that are related to various disease 
aspects. The passages can also be input to text 
classifiers so that the classifiers can have better 
performance in classifying the medical texts, 
which often simultaneously contain multiple 
aspects of disease information. In the 2nd year, 
we develop and test two techniques that rank 
diseases with respect to the given RSS 
descriptions: disease classification based on 
text classifiers and disease ranking based on 
document rankers. The research result is of 
significance to the development of a disease 
diagnosis support system whose disease 
 4
and hence is said to be positively correlated to 
c; otherwise it is negatively correlated to c. The 
correlation strength CS between t and c is thus 
defined in equation 2, where logarithm is 
employed to reduce the effect of dramatic 
change of the χ2(t,c) scores. 
 
 
 
3.1.1.2 Task in the testing phase: term 
frequency assessment 
Given a text d and a category c, PETC 
employs the term-category correlations to 
extract candidate passages from d with respect 
to c. PETC sequentially scans the terms in d to 
extract the candidate passages for c. The 
sequential scanning process is defined by a 
state transition diagram shown in Figure 1. 
There are three states: S0, SP, and SE. State S0 is 
the initial state, and PETC leaves S0 only when 
the next term x is positively correlated to c (i.e. 
the correlation strength of the next term 
CS(x,c)>0, see the transition from S0 to SP in 
Figure 1) or the end of d has been encountered 
(see the transition from S0 to SE in Figure 1). 
Therefore, S0 is actually a state for skipping 
those parts that are negatively correlated to c. 
When PETC transits from S0 to SP, it 
initializes two values: the current net strength 
NetS and the starting position of the possible 
core part pStart (see the actions associated with 
the transition from S0 to SP in Figure 1). The net 
strength NetS is the sum of the correlation 
strengths of the terms at and after pStart. PETC 
stays at SP if NetS>0, and in SP PETC records 
the position pEnd at which NetS is maximized. 
Therefore, the text part from position pStart to 
position pEnd is the possible core part in which 
the strength sum of the positively correlated 
terms is larger than the strength sum of the 
negatively correlated terms (i.e., NetS>0) and 
the difference between the strength sums is 
maximized at position pEnd. 
PETC leaves SP in two cases: (1) NetS≤0 
or too many terms have been scanned since 
position pStart (see the transition from SP to S0 
in Figure 1), or (2) the end of the text is 
encountered (see the transition from SP to SE in 
Figure 1). When NetS≤0, the text part spanning 
from position pStart to the current position 
(CurPos) is actually an area that is said to be 
positively correlated to c (since NetS remains to 
be positive in the area). Therefore, extraction of 
a candidate passage is invoked, and PETC 
transits to S0. Similarly, if end of the text is 
encountered, the text part spanning from 
position pStart to the end of the text is 
positively correlated to c, and hence extraction 
of the candidate passage is triggered as well 
and then PETC transits to SE. Note that if too 
many terms have been scanned since position 
pStart, the positively correlated area is actually 
too large and hence extraction of a candidate 
passage is invoked as well, and then PETC 
transits to S0. Whether a text area is too large is 
governed by the system parameter PLEN, 
which is the length of each extracted passage. 
To extract a candidate passage based on 
the core part currently identified (i.e., the text 
segment spanning from pStart to pEnd), PETC 
invokes a function ExtractP. The behavior of 
ExtractP is governed by two parameters PLEN 
and POSNUM, which are the length of each 
extracted passage and the minimum number of 
positively correlated terms in the core part, 
respectively. A candidate passage can be 
extracted only if the number of terms (in the 
core part) that are positively correlated to c is 
larger than or equal to POSNUM (a system 
parameter); otherwise the core part is ignored 
and no passage is extracted. If the length of the 
core part is smaller than PLEN (a system 
parameter), the extracted passage consists of 
 6
idea of CTFA was that, a term t in a document 
d could not provide reliable evidence for a 
category c, if t happens to appear in d with its 
neighboring terms not of the same correlation 
type to c. Therefore, CTFA amplified (reduced) 
the term frequency of t if the evidence provided 
by t is reliable (not reliable). By revising the 
term frequencies of the terms in each document, 
various kinds of text classifiers could be 
improved without requiring any modification to 
the classifiers. The SVM classifier that 
employed CTFA as the front-end processor was 
named SVM+CTFA. 
To further measure the contribution of 
PETC with respect to previous passage 
extractors for TC, we implemented two 
baseline passage extractors. The first baseline 
was OWP (Overlapping Window Passages), 
which was tested by Kim & Kim, 2004. It 
extracted fixed-length passages using an 
overlapping window. The second baseline was 
KDP (Keyword-based Dynamic Passage), 
which was developed by Mengle & Goharian, 
2009. It extracted fixed-length passages as well, 
with an additional constraint: the passages 
extracted should have a term that is strongly 
correlated to the category of interest.  The 
SVM classifiers that employed OWP, KDP, 
and PETC as front-end passage extractors were 
named SVM+OWP, SVM+KDP, and 
SVM+PETC respectively. 
Experimental results showed that SVM 
performed quite poor in classifying 
multi-aspect medical texts. Its MicroF1 and 
MacroF1 dropped dramatically when the texts 
to be classified have the information about 
multiple disease aspects. Therefore, the texts 
with multi-aspect information had more noises 
for the classifier, making the classifier more 
difficult to classify the texts into proper aspects. 
The results also showed that the 
proximity-based enhancer CTFA and all the 
passage extractors (PETC, OWP, and KDP) 
successfully enhanced MicroF1 and MacroF1 of 
SVM especially when classifying multi-aspect 
medical texts. However, CTFA performed 
poorer than all the passage extractors. For a 
category c, CTFA did not remove any textual 
parts about the categories other than c, although 
it had employed term proximity information to 
amplify or reduce the effect of some terms. 
Therefore, passage extraction is a better way to 
enhance SVM to classify multi-aspect medical 
texts. It is also a natural way to identify disease 
aspect information from the medical texts, 
since it can specifically output the candidate 
passages about the categories of interest. 
Among the passage extractors, PETC 
performed best in helping SVM to classify 
multi-aspect medical texts. The best baseline 
passage extractor should be KDP. As PETC, it 
considered how the terms in the passages 
correlate with the categories as well, indicating 
that term-category correlation is helpful in 
passage extraction for TC. 
In addition to the quality (MicroF1 and 
MacroF1) of TC, we are also concerned with 
the efficiency of TC. SVM was invoked for 
each passage extracted, and hence a large 
amount of passages extracted heavily 
deteriorated the efficiency of TC. The result 
shows that although KDP was superior to OWP 
in promoting the quality of TC, it extracted 
much more passages than both OWP and PETC. 
It extracted more than 20 times as many 
passages as PETC. SVM and SVM+OWP spent 
smaller amounts of time for a test document. 
Efficiency of KDP was quite poor as it 
generated much more passages.  
Therefore, SVM+PETC achieved the best 
quality of TC at the cost of more time required 
for passage extraction. The results also showed 
that the passages extracted by PETC are more 
precisely related to disease aspects (categories). 
A preliminary result has been published in Liu, 
2012, and the refined and extended result has 
been published in Liu, 2013a. 
 
3.2 Result of the 2nd year: Ranking diseases 
with respect to the given RSS descriptions 
We have developed and tested two 
techniques that rank diseases with respect to the 
given RSS descriptions: disease ranking based 
on text classifiers and disease ranking based on 
document rankers. 
 
3.2.1 Technical development 
We first model disease ranking as a text 
classification problem. We develop a technique 
TNR (Training Noise Reduction) that removes 
 8
4. Evaluation 
In the two-year project, we have two 
missions: (1) develop a technique to extract 
from medical texts those passages that are 
about main aspects of diseases (the 1st year of 
the project), and based on the extracted 
passages (2) develop a technique to rank 
diseases with respect to the given RSS 
descriptions (the 2nd year of the project). For 
the research results in the 1st year, a preliminary 
paper has been published (Liu, 2012), and the 
refined and extended paper has been published 
as well (Liu, 2013a). For the research results in 
the 2nd year, a paper has been published (Liu, 
2013b). A system is also developed to provide 
online service of providing disease-related 
information for health promotion and disease 
management. 
The missions of the project have thus been 
achieved. The research results are of both 
theoretical and practical significance to the 
communities of both information technology 
and healthcare. 
 
Reference 
[1] Kim, J. and Kim, M. H. (2004). An 
Evaluation of Passage-Based Text 
Categorization. Journal of Intelligent 
Information Systems, 23:1, 47–65. 
[2] Liu R.-L., 2013(a), "A Passage Extractor for 
Classification of Disease Aspect Information," 
to appear in Journal of the American Society 
for Information Science and Technology. 
[3] Liu R.-L., 2013(b), "Reduction of Training 
Noises for Text Classifiers," Proc. of the 5th 
Asian Conferences on Intelligent Information 
and Database Systems  (ACIIDS 2013),  
LNAI 7803, Springer-Verlag Berlin 
Heidelberg, pp. 30–39, Kuala Lumpur, 
Malaysia (18-20 March 2013). 
[4] Liu R.-L, 2012, "Enhancing Text Classifiers 
to Identify Disease Aspect Information," in 
Proc. of the 25th International Conference on 
Industrial, Engineering & Other Applications 
of Applied Intelligent Systems (IEA/AIE 
2012), Studies in Computational Intelligence, 
Springer, Dalian, Mainland China. 
[5] Liu R.-L., Tung S.-Y., and Lu Y.-L. (2011). 
"Identifying Disease Diagnosis Factors by 
Proximity-based Mining of Medical Texts," 
Proc. of the 3rd Asian Conference on 
Intelligent Information and Database Systems 
(ACIIDS 2011), LNAI 6592, Springer, pp. 
171–180, Daegu, South Korea. 
[6] Liu R.-L (2010). “Context-based Term 
Frequency Assessment for Text 
Classification,” Journal of the American 
Society for Information Science and 
Technology, Vol. 61, Issue 2, pp. 300-309 
[7] Mengle, S. and Goharian N. (2009). 
Passage Detection Using Text Classification. 
Journal of the American Society for 
Information Science and Technology, Vol. 60, 
Issue 4, 814–825. 
 
(keynote speech)，談論的議題亦相當廣泛，多以大型及雲端資訊系統
之建置與創新應用為主題。讓筆者印象較為深刻的是氣味(odor)之辨
識技術及其應用。此類技術包括底層之電子感測器設計及高層之氣味
分類技術。以演講者之經驗來說，氣味之辨識似已能用現今常見之分
類技術(如：類神經網路，Artitifical Neural Network)來達到不錯的效
果。此方面的應用相當廣，包括特殊場合(如：機場)之自動辯味
(如：毒品之辨味)，相當有實務意義。筆者之論文是以疾病醫療相關
文件(含疾病之病因、診斷、治療、預防、症狀)之分類為主題，提出
一個科技來改進一般分類技術，讓疾病文件自動分類之準確度可以更
進一步提升，以作為智慧型資訊檢索及教育系統之基礎。口頭發表過
程順利，並有機會與數位專家學者針對該論文進行交流。 
本次會議攜回會議論文集一冊，內收錄發表的論文可供查閱參
考。 
 
二、與會心得 
此次 ACIIDS 2013 會議已是第五屆，規模與品質都有提升。會
議之主辦單位在許多方面相當用心，但似仍有些可再改進之處，包括
會議時間之掌控(如：開幕致詞時間超過規劃太多)等。此外，本次會
議期間有機會親身體驗馬來西亞之風土民情，對其多民族及多宗教的
融合社會印象深刻，但其社會治安及對旅客之誠信則有相當大的改善
空間。此問題亦為台灣所應注意的，特別是司機與商家對國外旅客之
友善與誠信會直接影響外國人對台灣的觀感。政府應確實做好相關教
育及管制工作，以提升我國之國際形象並促進觀光。 
the classifiers using a set of training texts that have been tagged with proper category 
labels. However, as the training texts are often inevitably unsound or incomplete in 
practice, they often contain many terms that are not really related to the categories of 
the texts. Such terms are actually training noises in classifier training, and hence can 
deteriorate the performance of the classifiers.  
1.1 Problem Definition and Motivation 
In this paper, we develop a technique TNR (Training Noise Reduction) to remove the 
possible training noises for the text classifiers. Reduction of the training noises is 
essential. By proper reduction of the noises, the classifiers can be trained more proper-
ly and hence the classifiers can have better performance in classifying in-space docu-
ments and filtering out out-space documents.  
Technically, reduction of training noises is challenging since training texts are in-
evitably unsound or incomplete. In response to the challenge, TNR employs term 
proximity information as the key evidence to identify the noises in the training texts. 
Given a training text d of a category c, TNR identifies a sequence of consecutive 
terms (in d) as the noises if the terms are not strongly related to c. The idea is motivat-
ed by the observation: those terms (in d) that have many neighboring terms not related 
to c may simply happen to appear in d and hence are likely to be irrelevant to c (and 
hence are likely to be the training noises in d). By removing the possible training nois-
es, the classifiers can be trained more properly. 
1.2 Major Challenge and Related Work 
Major challenge of developing TNR is the fusion of relatedness scores of consecutive 
terms to determine whether the terms are training noises. To our knowledge, no previ-
ous studies tackled the challenge. 
Given training texts that are tagged with category labels, previous TC studies have 
developed and tested many feature (term) selection techniques that estimated the relat-
edness of a term with respect to each category, and accordingly selected those features 
that were capable of discriminating the categories (e.g., [8][11]). The selected features 
served as the basis on which text classifiers were built. Many excellent text classifiers 
have been developed, including the Support Vector Machine (SVM) classifiers that 
have been routinely employed and shown to be one of the best classifiers. TNR aims 
at serving as a front-end processor of the feature selection and classification tech-
niques. It reduces the noises in the training texts for the techniques. 
TNR employs term proximity information as the evidence to identify training nois-
es. Previous studies have noted term proximity as important information as well. 
However the term proximity information was employed to improve the ranking of text 
retrieval [4][10][12] or feature selection for text classification (e.g., considering mul-
tiple consecutive terms [9], nearby terms in a fixed order, and co-occurring terms in 
whatever order and location [3]). TNR employs term proximity to reduce training 
the actual and the estimated correlation types of t to c, we have four possible kinds of 
terms: TP (True Positive) terms, FN (False Negative) terms, FP (False Positive) terms, 
and TN (True Negative) terms. Obviously TNR should treat FP and TN terms as the 
training nosies as their occurrences in d may mislead the training process of the txt 
classifier for c. It is also interesting to note that, as the correlation types of a term is 
estimated across all categories, the removal of FP and TN terms for a category may 
reduce the number of FN terms for another category.  
Table 2 Algorithm of TNR 
Procedure: TNR(d,c), where d is a training document of category c 
Output: d’: The content of d with training noises for c removed 
Method: 
// Initialization of variables 
(1) d’ ← d;   
(2) NetS ← 0;   
(3) NoiseStart ← NULL;  
(4) CurrentPos ← 1; 
// Sequentially scan all terms in d to remove all training noises in d 
(5) While CurrentPos ≤ Length of d, do   
(5.1) t ← The term at position CurrentPos of d; 
(5.1) χ2(t,c) ← Chi-square correlation strength of t with respect to c; 
// Revise the correlation strength of t to c 
(5.2) If t is positively correlated to c and χ2(t,c) ≥ CorThreshold, 
RevisedS ← Log2(1+χ2(t,c)−CorThreshold); 
(5.3) Else if t is positively correlated to c,   // t is weakly positively correlated to c 
RevisedS ← −1×Log2(1+ CorThreshold−χ2(t,c)); 
(5.4) Else RevisedS ← −1×Log2(1+ CorThreshold+χ2(t,c)). // t is negatively correlated to c 
// Identify the start and end of the possible training noise 
(5.5) If NetS = 0 and RevisedS < 0     // The start of a possible training noise is found 
NoiseStart ← Position of t in d; 
(5.6) NetS ← NetS + RevisedS; 
(5.7) If NetS ≥ 0,     // Identify the end of the possible training noise 
(5.7.1) NetS ← 0;   
(5.7.2) If NoiseStart <> NULL and more than three terms after NoiseStart have Re-
visedS < 0,  // A training noise is found and hence should be removed 
(5.7.2.1) NoiseEnd ← Position of the term at which NetS is minimized; 
(5.7.2.2) d’ ← d’ with the textual part from NoiseStart to NoiseEnd removed; 
(5.7.2.3) CurrentPos ← NoiseEnd; 
(5.7.3) Else NoiseStart ← NULL;  // Not a training noise, and thus no removal is done 
(5.8) CurrentPos ← CurrentPos + 1;    
// Remove the final noise, if there is one before the end of d 
(6) If NoiseStart <> NULL and more than three terms after NoiseStart have RevisedS < 0,   
(6.1) NoiseEnd ← Position of the term at which NetS is minimized; 
(6.2) d’ ← d’ with the textual part from NoiseStart to NoiseEnd removed; 
(7) Return d’; 
 
However, as training texts are inevitably unsound or incomplete, precise identifica-
tion of FP and TN terms is challenging. TNR thus employs term proximity infor-
3   A Case Study on Classification of Disease Information 
A case study on thousands of Chinese texts of disease information was conducted to 
empirically evaluate the contribution of TNR. Automatic classification of disease 
information is a fundamental task for the dissemination of medical information for 
medical decision support and disease management. 
3.1 Experimental Data 
In the case study, we tested medical texts about top-10 fatal diseases and top-20 can-
cers in Taiwan, resulting in 28 diseases of interest. Chinese texts about the 28 diseases 
were collected from several reliable sources, including National Taiwan University 
Hospital1, Department of Health in Taiwan2, and many medical associations and hos-
pitals. We were also interested in 5 aspects of the diseases: etiology, diagnosis, treat-
ment, prevention, and symptom, which are critical aspects in clinical practice and 
disease management. There were 2 diseases for which we could not find medical texts 
about the aspect of prevention, and hence we totally had 138 categories (=28×5-2) in 
which there were 4669 medical texts. We randomly selected 2300 of the documents as 
the training data. The remaining 2369 documents were used as the in-space testing 
data (i.e., the testing data belonging to the space of the 138 categories). The data was 
used to measure how text classifiers performed in classifying in-space documents.  
On the other hand, to measure how text classifiers performed in filtering out out-
space documents (those that belonged to none of the 138 categories), we collected 446 
medical texts about other 15 diseases. As noted in Section 1, filtering of out-space 
documents is particularly essential as most real-world documents are actually out-
space documents for the domain in which text classifiers are trained. 
3.2 Underlying text classifier 
We employed SVM as the underlying classification technique. SVM is a popular 
technique in TC, and previous studies have shown that SVM is one of the best classi-
fication techniques. To implement the SVM classifier, we employed SVMLight that is 
publicly available3 [5] and has been tested in many previous studies. SVM required a 
feature set, which was built using the training data. The features were selected based 
on their maximum χ2 scores with respect to all categories [11]. We reported the con-
tributions of TNR to SVM under different feature set sizes. 
                                                          
1
 Available at http://www.ntuh.gov.tw/en/default.aspx. 
2
 Available at http://www.doh.gov.tw/EN2006/index_EN.aspx. 
3
 Available at http://www.cs.cornell.edu/People/tj/svm%5Flight/old/svm_light_v5.00.html. 
the out-space documents that are successfully rejected by all categories / number of 
the out-space documents] and AM is [number of misclassifications for the out-space 
documents / number of the out-space documents]. A system should filter out as many 
out-space documents as possible (i.e., higher FR) and avoid misclassifying the out-
space documents into many categories (i.e. lower AM). 
 
 
Figure 2 Filtering of out-space medical documents: TNR successfully helps SVM 
to filter out a higher percentage of out-space documents (i.e., achieving higher 
FR) and reduce the average number of misclassifications for the out-space doc-
uments (i.e., achieving a lower AM). 
3.4 Result and Discussion 
Figure 1 shows the performance of SVM and SVM+TNR (SVM with TNR as the 
front-end processor to remove training noises) in classifying in-space medical docu-
ments. The results show that TNR can help SVM to achieve better performance, espe-
Acknowledgment. This research was supported by the National Science Council of 
the Republic of China under the grant NSC 100-2221-E-320-004-MY2. 
References 
1. Abdul-Jaleel N., Allan J., Croft W. B., Diaz F., Larkey L., Li X., Metzler D., Smucker M. D., 
Strohman T., Turtle H., and Wade C.: UMass at TREC 2004: Notebook. In Proceedings of 
the 13th Text REtrieval Conference (2004), Gaithersburg, MD: National Institute of Stand-
ards and Technology. 
2. Chen C. C. and Chen M. C.: TSCAN: A Novel Method for Topic Summarization and Con-
tent Anatomy. In Proceedings of SIGIR'08 (2008), Singapore, 579–586. 
3. Cohen W. W. and Singer Y.: Context-Sensitive Mining Methods for Text Cate-gorization, In 
Proceedings of the 19th annual international ACM SIGIR conference on research and de-
velopment in information retrieval (1996), pp. 307-315, Zurich, Swit-zerland. 
4. Gerani S., Carman M. J., and Crestani F.: Proximity-Based Opinion Retrieval. In Proceed-
ings of the 33rd annual international ACM SIGIR conference on research and development 
in information retrieval (2010), Geneva, Switzerland, 403–410 
5. Joachims T.: Making Large-Scale SVM Learning Practical. In Advances in Kernel Methods - 
Support Vector Learning (1999), B. Schölkopf and C. Burges and A. Smola (ed.), MIT-
Press. 
6. Kim, J. and Kim, M. H.: An Evaluation of Passage-Based Text Categorization. Journal of 
Intelligent Information Systems  (2004), 23:1, 47–65. 
7. Mengle, S. and Goharian N.: Passage Detection Using Text Classification. Journal of the 
American Society for Information Science and Technology (2009), Vol. 60, Issue 4, 814–
825. 
8. Mladeniá D., Brank J., Grobelnik M., and Milic-Frayling N.: Feature Selection Using Linear 
Classifier Weights: Interaction with Classification Models. In Proceedings of the 27th Annu-
al International ACM SIGIR Conference on Research and Development in Information Re-
trieval (2004), pp. 234–241 
9. Peng F. and Schuurmans D.: Combining Naive Bayes and n-Gram Language Models for 
Text Classification. In Proceedings of 25th European Conference on In-formation Retrieval 
Research (ECIR), (2003), pp. 335-350. Pisa, Italy. 
10. Svore K. M., Kanani P. H., and Khan N.: How Good is a Span of Terms? Exploiting Prox-
imity to Improve Web Retrieval. In Proceedings of the 33rd annual international ACM 
SIGIR conference on research and development in information retrieval, Geneva, Switzer-
land (2010), 154–161 
11. Yang, Y. and Pedersen, J. O.: A Comparative Study on Feature Selection in Text Categori-
zation. In Proceedings of the 14th International Conference on Machine Learning (1997), pp. 
412-420. Nashville, Tennessee 
12. Zhao J. and Yun, Y.: A Proximity Language Model for Information Retrieval. In Proceed-
ings of the 32nd annual international ACM SIGIR conference on research and development 
in information retrieval (2009), Boston, USA, 291–298 
100年度專題研究計畫研究成果彙整表 
計畫主持人：劉瑞瓏 計畫編號：100-2221-E-320-004-MY2 
計畫名稱：植基於文件分類與排名之疾病診斷支援 
量化 
成果項目 實際已達成
數（被接受
或已發表）
預期總達成
數(含實際已
達成數) 
本計畫實
際貢獻百
分比 
單位 
備 註 （ 質 化 說
明：如數個計畫
共同成果、成果
列 為 該 期 刊 之
封 面 故 事 ...
等） 
期刊論文 0 0 100%  
研究報告/技術報告 0 0 100%  
研討會論文 0 0 100% 
篇 
 
論文著作 
專書 0 0 100%   
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 0 0 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國內 
參與計畫人力 
（本國籍） 
專任助理 0 0 100% 
人次 
 
期刊論文 1 1 100%  
研究報告/技術報告 0 0 100%  
研討會論文 2 2 100% 
篇 
 
論文著作 
專書 0 0 100% 章/本  
申請中件數 0 0 100%  專利 已獲得件數 0 0 100% 件  
件數 0 0 100% 件  
技術移轉 
權利金 0 0 100% 千元  
碩士生 3 3 100%  
博士生 0 0 100%  
博士後研究員 0 0 100%  
國外 
參與計畫人力 
（外國籍） 
專任助理 0 0 100% 
人次 
 
