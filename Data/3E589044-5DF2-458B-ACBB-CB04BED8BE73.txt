 ii
可供推廣之研發成果資料表 
可申請專利  ;可技術移轉                                      日期：95 年 10 月 28 日 
國科會補助計畫 
計畫名稱：植基於整數相似性策略之密碼學多重運算 
計畫主持人：楊吳泉 
計畫編號：NSC 94-2213-E-156-004-   學門領域：資訊安全 
技術/創作名稱 植基於非同步策略之密碼學多重運算 
發明人/創作人 楊吳泉、官大智、賴溪松 
中文： 
一般密碼學多重運算，包括多指數運算與多重純量積運算多以相同
加權之數字為之。這樣的的方式，在數字位元小時一般多用於二進
制帶號位元重編法，聯合漢明加權受限於 0.5n(n 為運算整數長度)；
在數字位元大時多用於預先計算建表法，記憶體又成指數成長。本
計畫提出一個使用不同加權達成多重運算之方式，在使用數字為單
一位元時，聯合漢明加權可達到 0.407n，使用數字位元加大時，記
憶體呈現性成長。因此計畫所提出之策略可用於不同環境之密碼元
件，相關內容將會發表在 IEEE Transactions on Computers。 
技術說明 英文： 
In general, the synchronous weight digits are used in cryptographic 
multi-computation, including multi-exponentiation and multi-scalar 
multiplication.  By this way, the joint Hamming weight is limited to 
0.5n (n is the length of integer) in binary signed-digit representations; 
the memory requirement is increased exponentially in large-length 
digits.  In this project the asynchronous digits are used to evaluate 
multi-computation.  The joint Hamming weight is improved to 0.407n
in binary signed-digit representations; the memory requirement is 
increased linearly in large-length digits.  Thus the proposed strategy 
can be used in many environments, the related description will be 
published in IEEE Transactions on Computers. 
可利用之產業 
及 
可開發之產品 
1. 憑證卡、智慧卡及智慧型電子裝置等記憶體有限之密碼元件。
2. 電腦、伺服器、防火牆及電腦網路相關裝置之密碼元件。 
技術特點 
1. 演算法具有多重樣貌且容易實現。 
2. 記憶體有所限制之裝置可以達到良好之效率。 
3. 即使在記憶體較充裕之環境，記憶體呈線性成長，更可應用於
各式各樣不同之環境。 
推廣及運用 
的價值 
1. 簡單容易實現。 
2. 效率佳且記憶體運用更具彈性。 
※ 1.每項研發成果請填寫一式二份，一份隨成果報告送繳本會，一份送 貴單位研
發成果推廣單位（如技術移轉中心）。 
※ 2.本項研發成果若尚未申請專利，請勿揭露可申請專利之主要內容。 
※ 3.本表若不敷使用，請自行影印使用。 
 iv
行政院國家科學委員會專題研究計畫成果報告 
 
植基於整數相似性策略之密碼學多重運算 
Cryptographic Multi-computation with Integer Similarity Strategy 
 
z Abstract 
Keyword: Multi-computation, binary signed-digit (BSD) representation, joint sparse form (JSF), 
integer similarity strategy 
Multi-computations in finite groups, such as multi-exponentiations, e.g. c = axby, and multi-scalar 
multiplications, e.g. C = xA + yB (A, B, and C denote points in one elliptic curve), are very 
important in many ElGamal-like public key cryptosystems. In addition to the algorithms for 
single computations, the performance of multi-computations can be improved by the concept of 
multi-exponentiation. 
Based on the concept of multi-exponentiations, many algorithms have been proposed to 
improve the performance of multi-computations. In general, these algorithms can be classified 
into two categories: pre-computing methods and recoding methods. Pre-computing methods use a 
large table to store the pre-computed values, such as the BGMW method and the Lim-Lee 
method. Pre-computing methods are very suitable for memory sufficient environment and have 
the better performance indeed. Since the binary signed-digit(BSD) representation of an integer is 
not unique, recoding methods, such as the DJM method and joint sparse form(JSF), try to recode 
the BSD representations of x and y such that their joint Hamming weight is as minimal as 
possible. Recoding methods are very useful in memory limited environments, such as IC cards or 
smart consumer electronic devices. Due to the wide use of certification, it is very important for 
the algorithms in memory limited environment. Recently, this topic has been discussed in many 
articles, and is researched in this project.  
Solinas proves that the joint Hamming weight ω(x,y) of JSF is minimal in all recoding methods, 
the ratio  of ω(x,y) to the integer length(call performance factor ρ) is 1/2(=0.5) when the length 
of x and y is near-infinite. In this project, we introduce a totally new integer similarity strategy (it 
is renamed to asynchronous strategy in paper submission) to improve the performance of 
multi-computations. The new strategy improve the performance by deleting or inserting some 
digits in x and y, such that the two integers have as much similarity as possible. It is very useful in 
some non-recoded case and binary representations. Base on the proposed strategy, we proposed 
two draft algorithms. The performance factor is improved to 4/9(≈0.444) and 11/27(≈0.407), 
respectively. 
The related result will be published in IEEE Transactions on Computers (accepted). The web 
site, http://www.twcrypt.org, for research background, experience, and software download, will 
be built in this project. We would like the implemented technology is advantage to the relative 
researches and applications.  
 2
植基於所提出之策略，我們所提出之演算法突破 JSF 之 AJHD=0.5n 的最小限制，所提出來
SS1 法之 AJHD=0.444n 而 DS1 法之 AJHD=0.407n。且在拓展時，記憶體是呈線性成長
[11,12,13,14,15]。 
 
二、基本重新編碼策略及其限制 
為了方便描述起見，我們以二維多指數運算代表來描述，我們將二維多指數運算之基本
演算法以圖 1 來描述。其中小寫字母，如 a、b、x、y，表示一個大整數；小寫字母加上下標，
如 xj、yj，表示一個數字，如為二進位則數字為 0 或 1，如為 BSD 則為–1、0、或 1。演算法
之第 4 行 2 ( )j jx yc c a b= ⋅ 是以下兩敘述之簡寫。在多指數運算之演算法中 AJHD 可視為
(xj,yj)≠(0,0)之個數，以 Algorithm 1 而言，其 AJHD= 34 n。 
       4-1. c = c2; 
       4-2. if ( (xj,yj)≠(0,0) ) ( )j jx yc c a b= ⋅ ; 
Algorithm 1: 二維多指數運算之基本演算法 
I/P: a, b, x=(xn–1, xn–2, ..., x1,x0)2, y=(yn–1, yn–2, ..., y1,y0)2. 
O/P: c = ax⋅by 
Step:  
1. Pre-compute and store ab; 
2. c = 1; 
3. for ( j = n–1; j ≥ 0; j= j-1) { 
4.   2 ( )j jx yc c a b= ⋅ ; 
5. } 
6. output c ; 
圖1  二維多指數運算之基本演算法 
就重新編碼策略之精神而言，即為尋求一個(xj,yj)≠(0,0)個數較少之演算法，例如 BSD
表示法之 JSF，可將 AJHD 降至趨近於 0.5n[8]；就預先計算策略之精神而言，即為利用事先
計算存表來減少第 4 行與 ( )j jx ya b 相乘之個數，例如兩個位元一起處理之滑動視窗法可將
AJHD 降至 15 1512 16 32n n× = 。本節介紹改進策略之演算法。 
有許多不錯之演算法可將整數之二進位表示法改為最低加權 BSD 表示法[17,18,19]，一
般最常見之最低加權表示法稱為非相鄰表示法(Non-adjacent form, NAF，也有人稱為 sparse 
form 或是 canonical form)，意即兩個相鄰之數字不能同時為非零。如此非零數字之比例可從
從 12 降為 13 [20]。若將 Algorithm 1 中 x 與 y 表示法改為 BSD 表示法，以 x=(xn–1, xn–2, ..., x1,x0)2′
與 y=(yn–1, yn–2, ..., y1,y0)2′來表示，且在第 1 行之之步驟中編碼成 NAF 並預先計算 ab、ab–1、
a–1b、及 a–1b–1，則可將 Algorithm 1 之 AJHD 可從 34 n降為 Algorithm 2 之 59 n (≈0.556n)。 
由於 BSD 最低加權表示法並不唯一，且兩個單一整數之最低加權表示法未必可以形成
最低之聯合加權。如果加以重新編碼的話，或可找出比 0.556n 更小之編碼方式。Dimitrov、
 4
 
三、重新編碼策略之突破 --- 非同步策略 
重新編碼策略之相關演算法在編碼成 JSF 時，被證明效率為 AJHD=0.5n，已為最佳。
但仍有論文不斷突破，包括使用 w-NAF(數字 2 為底但不侷限於 0,1,及-1，有結合視窗法與
NAF 之感覺) [22,23,24,25,26,27]，以及非同步策略(以不同加權數字運算) [11,13,14,15]。本報
告介紹非同步策略相關演算法之基本概念。 
基本之重新編碼策略主要是針對相同加權之數字做計算，為了進一步降低 AJHD，我們
可嘗試去尋找不同加權之數字，使得零與非零之整數對齊得更好，一個最簡單的想法如下：
當兩個數字同為零或同為非零時(考慮到未來之拓展，記作 xi~yi)，我們就直接處理相關運算，
一為零一為非零時(記作 xi ~/ yi)，可固定一數字(如 xi)，在往後掃描另一整數之下一數字(如
yi-1)，以獲得效能改善。這個概念可由如下圖 3 之狀態圖來描述。當執行與一般相同加權數
字之運算時，狀態記為 S0，當往後掃描執行不同加權運算時，，狀態記為 Sx。由 S0 轉換為
Sx時，只需考慮 xi之計算效應，反之由 Sx轉換為 S0 時，便需考慮 xi、yi、及 yi+1 之計算效應。
如果狀態轉換條件設計好的話，便可進一步改進之效能。 
圖 3 基本非同步策略之狀態圖 
針對上述觀念，我們可列出各相關狀態轉換時，附屬之計算如下表二所示： 
表 2 非同步策略狀態轉換時附屬之計算 
狀態 附屬之計算 
S0 → S0 2 ( )i ix yc c a b= ⋅  
S0 → Sx 2 ( )ixc c a= ⋅  
Sx → Sx 122 ( )i ix yc c a b += ⋅  
Sx → S0 1 2( ) ( )i i iy x yc c b a b+= ⋅ ⋅  
為了降低 AJHD，當 xi ~/ yi 可採用觀望之方式來促使零(或非零)數字能一起計算，此時
可先處理 xi之相對效應，將 yi保留與下一個 xi–1 來一起處理(在下一回合即變成 yi+1 與 xi)。並
將狀態從 S0 轉換為 Sx。在 Sx狀態下，如果 yi+1~xi 則狀態維持不變。但返回時之計算需考慮
yi+1、yi、xi之效應亦即計算表 2 最後一個計算式， 1 2( ) ( )i i iy x yc c b a b+= ⋅ ⋅ 。為了讓 AJHD 能夠
減少，我們將狀態轉之條件定為 1i ix y +∼/ 且 ~i ix y ，簡寫為 1i i ix y y +∼ ∼/ ，如此可維持
S0 
(xi,yi)
Sx 
(xi,yi+1)
(xi) 
Shift xi
(xi,yi,yi+1)
Reverse shift xi
 6
 
Algorithm 3: SU1 演算法 
I/P: a, b, x, y. 
O/P: c = axby 
Step:  
1. Compute and store ab and ab2; 
2. c = 1, state = S0; 
3. for (i = n–1 ; i ≥ 0; i= i–1) { 
4.   if (state = S0) { 
5.     if ( i ix y∼ ) 2 ( )i ix yc c a b= ⋅ ; 
6.     else state = Sx, 2 ( )ixc c a= ⋅ ;  
7.   } else { 
8.     if ( 1~i ix y +/ ) { 
9.       if ( i ix y∼ ) state = S0, 1 2( ) ( )i i iy x yc c b a b+= ⋅ ⋅ ; 
10.       else 2( ) ( )ixc c b a= ⋅ ⋅ ;  
11.     } 
12.     else 122 ( )i ix yc c a b += ⋅ ;  
13.   } 
14. } 
15. if (state = Sx) C = C + (y0B); 
16. output C ; 
圖 5 SU1 演算法 
 
 
 
表3 SU1演算法之效能分析 
State yi+1 xiyi Computation ωi 1i i iy x yP + Line 
S0→S0 x00 C = 2C 0 1/12 5 
S0→Sx x01 C = 2C 0 1/12 6 
S0→Sx x10 C = 2C + (A) 1 1/12 6 
S0→ S0 x11 C = 2C + (A+B) 1 1/12 5 
Sx→Sx 00x C = 2C 0 1/6 12 
Sx→Sx 010 C = 2C + (A) 1 1/12 10 
Sx→S0 011 C = 2C + (A+B) 1 1/12 9 
Sx→S0 100 C = 2(C+B) 1 1/12 9 
Sx→Sx 101 C = 2(C+B) 1 1/12 10 
Sx→Sx 11x C = 2C + (A+2B) 1 1/6 12 
 
 8
預備定理 3: 若 x、y 為兩個獨立之 NAF，則
1 1|i i i ix y x y
P + + 的概率如下： 
1.  ˆ ˆ00|11 1P = , 
2.  1ˆ ˆ ˆ ˆ ˆ ˆ 200|01 10|01 00|10 01|10P P P P= = = = , 
3.  1ˆ ˆ ˆ ˆ00|00 401|00 10|00 11|00P P P P= = = = , 
4.  ˆ ˆ ˆ ˆ ˆ ˆ ˆ ˆ ˆ ˆ ˆ ˆ ˆ ˆ ˆ ˆ ˆ ˆ ˆ ˆ01|11 10|11 11|11 01|01 11|01 10|10 11|10 0P P P P P P P= = = = = = = . 
 
預備定理 4: 若 x、y 為兩個獨立之 NAF，則
1 1i i i ix x y y
P + + 之值有 9 個為非零，分別為 0000P 、
ˆ0001
P 、 ˆ0100P 、 ˆ ˆ0101P 、 ˆ ˆ1010P 、 ˆ0010P 、 ˆ ˆ0110P 、 1ˆ000P 及 ˆ ˆ1001P ，其值均為 19 。 
 
定理 2: SS1 演算法中，AJHD 49= 0.444n n≈ ( 1 1 1 19 n+ + + ，效能分析如表 4)。 
 
表4 SS1演算法之效能分析 
State xi+1yi+1 xiyi Computation ωi Paαbβ Line 
S0 → S0 00 00 C = 2C 0 1/9 5 
S0 → Sx 00 01ˆ C = 2C 0 1/9 6 
S0 → Sx 00 1ˆ0 C = 2C ± A 1 1/9 6 
S0 → S0 00 1ˆ 1ˆ C = 2C ± (A±B) 1 1/9 5 
S0 → S0 1ˆ 1ˆ  00 C = 2C 0 1/9 5 
Sx → S0 01ˆ  00 C = 2(C±B) 1 1/9 9 
Sx → Sx 01ˆ  1ˆ0 C = 2C ± (A±2B) 1 1/9 8 
Sx → S0 1ˆ0 00 C = 2C 0 1/9 9 
Sx → Sx 1ˆ0 01ˆ C = 2C 0 1/9 8 
從演算法之分析中，會發現當 ~i ix y/ 時，先處理值為零之數字較能減少乘法次數，由此
可將 SS1 改進為 DS1，意即先處理的數字不一定只侷限於 xi，而是 xi與 yi中值為零的那個數
字我們將演算法稱為 DS1 演算法(意即 Double-Signed one-stage)。因此 DS1 狀態轉變之判別條
件可由 SS1 增編如圖 8。 
以多純量積運算而言，DS1 演算法狀態轉換對應之運算如表 5。DS1 演算法可如圖 9 所
描述。DS1 之效能分析與 SS1 略有區分，需再將 Sx再細分才可得正確結果燒為繁瑣些，不在
此贅述，進一步資料可參考[14,15]。此處只列出 AJHD 結果之定理，如下定理 3。 
 10
 
Algorithm 5: DS1 演算法 
I/P: 兩個橢圓曲線上之點 A, B, 及兩個 NAF 之整數 x, y. 
O/P: C = xA+yB 
Step:  
1. Compute and store A±B and A±2B; 
2. C = O, state = S0; 
3. for ( i = n; i ≥ 0; i= i-1) { 
4.   if (state = S0) { 
5.     if ( i ix y∼ ) C = 2C + (xiA+yiB); 
6.     else if ( ˆ( , ) (0,1)i ix y = ) state = Sx, C = 2C;  
7.     else state = Sy, C = 2C;  
8.   } else if (state = Sx){ 
9.     if ( i ix y∼/ ) C = 2C + (xiA+yi+12B); 
10.     else state = S0, C = 2(C+ yi+1B) + (xiA+yiB);  
11.   } else { 
12.     if ( i ix y∼/ ) C = 2C + (xi+12A+yiB); 
13.     else state = S0, C = 2(C+ xi+1A) + (xiA+yiB)  
14.   } 
15. } 
16. if (state = Sx) C = C + (y0B); 
17. else if (state = Sy) C = C + (x0A); 
18. output C; 
圖 9 DS1 演算法 
 
表6 DS1演算法之效能分析 
State xi+1yi+1 xiyi Computation ωi Paαbβ Line 
S0 → S0 00 00 C = 2C 0 1/9 5 
S0 → Sx 00 01ˆ C = 2C 0 1/9 6 
S0 → Sy 00 1ˆ0 C = 2C 1 1/9 7 
S0 → S0 00 1ˆ 1ˆ C = 2C ± (A±B) 1 1/9 5 
S0 → S0 1ˆ 1ˆ  00 C = 2C 0 1/9 5 
Sx′ → S0 01ˆ  00 C = 2(C±B) 1 2/27 10 
Sx′ → Sx″ 01ˆ  1ˆ0 C = 2C ± (A±2B) 1 2/27 9 
Sx″ → S0 1ˆ0 00 C = 2C 0 1/27 10 
Sx″ → Sx′ 1ˆ0 01ˆ C = 2C 0 1/27 9 
Sx″ → S0 01ˆ  00 C = 2C 0 1/27 13 
Sx″ → Sx′ 01ˆ  1ˆ0 C = 2C 0 1/27 12 
Sx′ → S0 1ˆ0 00 C = 2(C±A) 1 2/27 13 
Sx′ → Sx″ 1ˆ0 01ˆ C = 2C ± (2A±B) 1 2/27 12 
 12
 
圖 10 SUt演算法之狀態轉換考量 
應用一些預先計算策略列表法之概念[9,10,16]，多指數運算之快速演算法也可應用回單
一指數運算，假設計算 c=dz為例，一個最簡單之方法是 z 摺疊來計算。設 z=(zh,zl)，其中 zh
為高的 12 n位數字而 zl為低的 12 n位數字，如此，可令 a d= 、 lzb d= 、 lx z= 、 hy z= ，則 c=dz= 
axby。換言之，若使用 SS1 演算法於 n 個數字之單一指數運算時，其 AJHD= 1 42 9 0.222n n× ≈ ，
若使用 DS1 演算法於 n 個數字之單一指數運算時，其 AJHD= 1 112 27 0.204n n× ≈ ，效果相當不錯
(計算 b 所需之 12 n個平方計算及後來作多指數運算之 12 n個平方計算，與原來計算所需之 n
個平方計算需求相同)。 
五、結果與討論 
本報告介紹多指數運算重新編碼策略之相關演算法，除了基本之重新編碼演算法外，
我們主要介紹非同步策略之概念，透過基本形式之 SU1、SS1、及 DS1 等演算法，希望大家
能夠理解這類演算法之特色與優點：具有良好之效能、不侷限於 BSD 表示法、記憶體需求
呈線性成長等。這次計畫之主要研究成果”Fast Multi-computation with Asynchronous 
Strategy”已被 IEEE Transactions on Computers 接受為 regular paper，論文初步排版之內容詳
見附錄。對非同步策略搭配基本重新編碼法之效能做比較，以了解到相關之 SS1 及 DS1 演
算法最適用於 NAF 情形。此外扼要提醒大家注意多指數運算也可再應用於單一指數運算。
這些在軟硬體設計時，都是值得參考之觀點。若以單一 NAF 之非零數字為 13 n 的角度來觀，
這類演算法之 AJHD 仍有可資成長之處，密碼學多重運算在研究與實務設計上是個有趣的
研究課題。 
S0 
(xi,yi) Stage 
Sx1 
(xi,yi+1) Stage 
Sx2 
(xi,yi+2) Stage
Sxt 
(xi,yi+t) Stage 
01 
00,10,11 
01 
10
00,11 
01
10
00,11
10
00,01,11 
p0
p1 p2 pt
 14
 
[16] W. C. Yang, K. M. Lin, and C. S. Laih, “A precomputation method for elliptic curve point 
multiplication,” Journal of the Chinese Institute of Electrical Engineering, vol. 9, no. 4, pp. 
339–344, Nov. 2002.  
[17] G. W. Reitwiesner, “Binary arithmetic,” Advance in computers, pp. 231–308, 1960.  
[18] J. Jedwab and C. J. Mitchell, “Minimum weight modified signed-digit representations and fast 
exponentiation,” Electronics Letters, vol. 25, no. 17, pp. 1171–1172, 1989.  
[19] M. Joye and S. M. Yen, “Optimal left-to-right binary signed-digit recoding,” IEEE 
Transactions on Computers, vol. 49, no. 7, pp. 740–748, 2000.  
[20] S. Arno and F. S. Wheeler, “Signed digit representations of minimal hamming weight,” IEEE 
Transactions on Computers, vol. 42, no. 8, pp. 1007–1010, 1993.  
[21] V. S. Dimitrov, G. A. Jullien, and W. C. Miller, “Algorithms for multi- exponentiation based 
on complex arithmetic,” in Proceedings of the 13th IEEE Symposium on Computer Arithmetic, 
pp. 208–215, 1997.  
[22] H. Cohen, A. Miyagi, and T. Ono, “Efficient elliptic curve exponentiation using mixed 
coordinates,” in Advances in Cryptology–AsiaCrypt’98, LNCS 1514. Springer-Verlag, pp. 
51–65, 1998.  
[23] J. Muir and D. Stinson, “Minimality and other properties of the width-w nonadjacent form,” 
University of Waterloo, Tech. Rep. CORR 2004-08, 2004, http://www.cacr.math.uwaterloo.ca. 
Aug., 2005.  
[24] J. Muir and D. Stinson, “Minimality and other properties of the width-w nonadjacent form,” 
University of Waterloo, Tech. Rep. CORR 2004-08, 2004, http://www.cacr.math.uwaterloo.ca. 
Aug., 2005.  
[25] E. Dahmen, K. Okeya, and T. Takagi, “An Advanced Method for Joint Scalar Multiplications 
on Memory Constraint Devices,” 2nd European Workshop on Security and Privacy in Ad hoc 
and Sensor Networks -- ESAS 2005, LNCS 3813, Springer-Verlag, pp. 189-204, 2005. 
[26] B. Kuang, Y. Zhu, and Y. Zhang, "An Improved Algorithm for uP+vQ using JSF3,” 
Proceedings of Applied Cryptography and Network Security ACNS 2004, LNCS 3089, 
Springer-Verlag, pp. 467-478, 2004. 
[27] R. M. Avanzi, “The Complexity of Certain Multi-Exponentiation Techniques in 
Cryptography,” Journal of Cryptology, vol 18, no.4, pp. 357-373, 2005. 
 
 
 
 
 
 
 
 
附錄：Fast Multi-computation with Asynchronous Strategy 
IEEE TRANSACTIONS ON COMPUTERS, VOL. XX, NO. XX, MONTH YEAR 2
call ω¯(x, y) the average joint Hamming weight of x and y.
The computational cost of the classical methods are shown as
follows.
1) Directly using two sparse forms [10]:
ω¯1(x, y) = 0.556n.
2) Using the Dimitrov-Jullien-Miller method [5], [11]:
ω¯′1(x, y) = 0.518n.
3) Using the joint sparse forms [6]:
ω¯′′1 (x, y)→ 0.5n as n→∞.
The proposed asynchronous strategy can be used to fur-
ther improve the performance for all the above recoding
algorithms. We propose two efficient algorithms based on
the asynchronous strategy. We call them the SS1 method
and DS1 method, respectively. By using the SS1 method
to the above codes, the values of ω¯(x, y)’s can be reduced
to (1) ω¯2(x, y) = 0.444n, (2) ω¯′2(x, y) = 0.453n, and
(3) ω¯′′2 (x, y) = 0.469n respectively. By using the DS1 method,
the values of ω¯(x, y)’s can further be reduced to (1) ω¯3(x, y) =
0.407n, (2) ω¯′3(x, y) = 0.414n, and (3) ω¯
′′
3 (x, y) = 0.438n
respectively. Table I summarizes the performances of the
algorithms.
TABLE I
THE PERFORMANCE OF MULTI-COMPUTATION ALGORITHMS.
classical method SS1 method DS1 method
sparse form 0.556n 0.444n 0.407n
DJM code 0.518n 0.453n 0.414n
join sparse form 0.500n 0.469n 0.438n
Signed-digit code may not be practical when the inverse of
an element in the group is difficult to compute. Our strategy
can also be used in pure binary code. The value of ω¯(x, y)
can be reduced from 0.75n to 0.667n in binary method.
The rest of this paper is organized as follows. In Section
2, we first review some well-known multi-computation algo-
rithms. Our algorithms by using the asynchronous strategy are
presented in Section 3. The application of the asynchronous
strategy to binary code is discussed in Section 4. Finally, we
make conclusions in Section 5.
II. REVIEW OF MULTI-COMPUTATION ALGORITHMS
For simplicity, we use multi-scalar-multiplication C = xA+
yB with binary signed-digit code of x and y to describe the
algorithms. The notations used in this paper are defined as
follows. The uppercase letters, such as A or B, denotes an
element in the addition group defined by an elliptic curve.
The lowercase letters, such as x or y, denotes an n-bit integer.
Recall that, x and y are encoded by n+ 1 digits as
x =
n∑
i=0
xi2i = (xnxn−1 · · ·x1x0)2, and
y =
n∑
i=0
yi2i = (ynyn−1 · · · y1y0)2,
where xi, yi ∈ {1¯, 0, 1}. Note that we use 1¯ to denote −1.
The symbol |x| denotes the bit-length of x, ω(x) denotes the
Hamming weight of x.
In multi-computation, the computational cost depends on
the joint Hamming weight. For integer pairs x and y, the joint
Hamming weight ω(x, y) is defined as the total number of
(xi, yi) 6= (0, 0), for 0 ≤ i ≤ n. For simplicity, we use 1ˆ
to denote the nonzero digits. The digits can be classified into
two sets: (1) the zero set S0 = {0}, and (2) the nonzero set
S1ˆ = {1, 1¯}. The symbol xi ∼ yi denotes the two digits are
in the same set, i. e., xi, yi ∈ S0 or xi, yi ∈ S1ˆ. The symbol
xi 6∼ yi denotes the two digits are in different sets.
In a minimum weight binary signed-digit code the expected
value ω¯(x) for an integer x is 13n [12]. Many efficient
algorithms can be used to encode a binary code or any binary
signed-digit code into minimum weight binary signed-digit
code [13], [14], [15].
The minimum weight binary signed-digit code of an integer
is not unique. The most commonly used one is called sparse
form. In sparse form no two consecutive digits are both
non-zeros. It is also called canonical form or non-adjacent
forms [16].
A. Classical methods
The Classical binary signed-digit method for multi-scalar-
multiplications is shown in Algorithm 1.
Algorithm 1
input: A, B, x, y
output: C = xA+ yB
1: encode x and y into binary signed-digit code;
2: compute the values of A+B, A−B;
3: C = O;
4: for (i = n; i ≥ 0; i−−) {
5: C = 2C;
6: if ((xi, yi) 6= (0, 0)) C = C + (xiA+ yiB);
7: }
8: output C.
Fig. 1. Basic binary signed-digit method for multi-computations
The value of all possible xiA+ yiB must be precomputed
in Line 2 of Algorithm 1. Therefore, it needs 5 registers to
store the value of A, B, A + B, A − B, as well as the final
result C. The inverses −A, −B, −A − B and −A + B can
easily be computed from the precomputed values. Therefore,
they need not be stored. Let ω¯1(x, y) be the average joint
Hamming weight for using sparse forms in Algorithm 1. It is
easy to show that ω¯1(x, y) = 0.556n.
B. Recoding methods
Since the binary signed-digit code is not unique, the result
of Algorithm 1 can be improved by selecting proper code of x
and y. Dimitrov, Jullien, and Miller proposed 8 reduction rules
to recode x and y [5]. We called this method the DJM code. In
their method, if any sub-sequence of three consecutive digits
matches one of the upper part of Table II, the algorithm recode
the sub-sequence into the sequence stored in the corresponding
lower part of the table. The average joint Hamming weight,
IEEE TRANSACTIONS ON COMPUTERS, VOL. XX, NO. XX, MONTH YEAR 4
TABLE III
THE CORRESPONDING COMPUTATIONS OF THE PROPOSED ALGORITHM
States Corresponding computations
S0 → S0 C = 2C + (xiA+ yiB)
S0 → Sx C = 2C + xiA
Sx → Sx C = 2C + (xiA+ yi+12B)
Sx → S0 C = 2(C + yi+1B) + (xiA+ yiB)
Therefore, the computation of C = 2(C + yv+1B) + (xvA+
yvB) consists of at most two additions.
Note that our algorithm simulate a Mealy machine, in which
the computations taken depends on the state and the input.
Since the inputs can be obtained by the next state, they are
not shown in the table. Algorithm 1 can be modified to obtain
Algorithm 2 as shown in Figure 3.
Algorithm 2:
input: A, B, x, y
output: C = xA+ yB
1: compute the values of A±B, A± 2B;
2: C = O, state = S0;
3: for (i = n; i ≥ 0; i−−) {
4: if (state = S0) {
5: if (xi ∼ yi) C = 2C + (xiA+ yiB);
6: else { state = Sx; C = 2C + xiA};
7: } else {
8: if (xi 6∼ yi) C = 2C + (xiA+ yi+12B);
9: else { state = S0;
C = 2(C + yi+1B) + (xiA+ yiB)};
10: }
11: }
12: if (state = Sx) C = C + y0B;
13: output C.
Fig. 3. The SS1 method for sparse forms
The rules in Figure 2 are simple and can be implemented
efficiently. Theorem 1 shows that Algorithm 2 can do at
least as good as Algorithm 1. Our experience shows that it
can improve the performance of Algorithm 1 with randomly
generated test data in binary signed-digit sparse forms. We
shall prove this fact in Theorem 2.
Theorem 1: Let ω1(x, y) and ω2(x, y) be the average joint
Hamming weight of Algorithm 1 and Algorithm 2, respec-
tively. If x and y are both in sparse forms, then ω2(x, y) ≤
ω1(x, y).
Proof: The average Hamming weight ω2(x, y) is analyzed
by considering the computations at each state. First, we
consider ω2(x, y) in state S0. In Line 5, ω2(x, y) is same
as ω1(x, y). In Line 6, if yi = 0, ω2(x, y) is decreased by 1,
otherwise, ω2(x, y) is the same as ω1(x, y).
We then consider the computation in state Sx. If xi 6∼ yi
for u ≥ i > v, then Sx occurred when u ≥ i > v, (Note that
(xv, yv) = (0, 0)), thus the corresponding computations are
shown as follows.
S0 S0 → Sx Sx · · · Sx Sx → S0 S0
xu+1 xu xu−1 · · · xv+1 xv xv−1
yu+1 yu · · · yv+2 yv+1yv yv−1
Let the length of the block to be shifted be k, then k = v−u.
It is easy to show that the original joint Hamming weight is
k. After shifting, xi ∼ yi+1 for u > i > v, because x and y
are represented in sparse forms and xi 6∼ yi for u ≥ i > v.
Thus, the change of the value of ω2(x, y) can be obtained by
considering the following 3 cases.
1) xu = xv+1: ω2(x, y) is decreased by k−12 , k =
1, 3, 5, · · ·
2) xu = 0 and xv+1 = 1ˆ: ω2(x, y) is decreased by k2 ,
k = 2, 4, 6, · · ·
3) xu = 1ˆ and xv+1 = 0: ω2(x, y) is decreased by k2 − 1,
k = 2, 4, 6, · · ·
For all of the above cases, ω2(x, y) can never be increased in
Sx. Therefore, ω2(x, y) ≤ ω1(x, y).
According to Theorem 1, the computation cost will not be
increased in the worst case. We show that it performs better
than Algorithm 1 in average case.
Let Pa|b be the conditional probability of the i-th digit is
a given that the (i + 1)-st digit is b in sparse form. Let P0
be the probability that the current digit is 0, and P1ˆ be the
probability that the current digit is not 0. We know P0 = 23
and P1ˆ =
1
3 in sparse forms [13]. Lemma 1 shows the values
of the conditional probability.
Lemma 1: Let x and y be represented in sparse form.
Assume that each digit of x, as well as each digit of y, is
independent. Then
1) P0|0 = P1ˆ|0 =
1
2 ,
2) P0|1ˆ = 1, and
3) P1ˆ|1ˆ = 0.
Proof: Since no two consecutive digits are nonzero,
P0|1ˆ = 1 and P1ˆ|1ˆ = 0. Let P0|0 = p and P1ˆ|0 = 1 − p. We
have P0 = P0 · P0|0 + P1ˆP0|1ˆ, therefore 23 = 23 · p + 13 · 1
implies p = 12 . We conclude that P0|0 = p =
1
2 and
P1ˆ|0 = 1− p = 12 .
Let Paα|bβ be the conditional probability of xi = a and
yi = α given that the xi+1 = b and yi+1 = β. The values of
these conditional probabilities are shown in Lemma 2.
Lemma 2: Let x and y be represented in sparse form.
Assume that each digit of x, as well as each digit of y, is
independent. Then
1) P00|1ˆ1ˆ = 1,
2) P00|01ˆ = P1ˆ0|01ˆ = P00|1ˆ0 = P01ˆ|1ˆ0 =
1
2 ,
3) P00|00 = P01ˆ|00 = P1ˆ0|00 = P1ˆ1ˆ|00 =
1
4 ,
4) P01ˆ|1ˆ1ˆ = P1ˆ0|1ˆ1ˆ = P1ˆ1ˆ|1ˆ1ˆ = P01ˆ|01ˆ = P1ˆ1ˆ|01ˆ = P1ˆ0|1ˆ0 =
P1ˆ1ˆ|1ˆ0 = 0.
Proof: Since the digits in x and y are independent, the
probability Paα|bβ = Pa|b × Pα|β .
Furthermore, Let Paαbβ be the probability of xi = a, yi =
α, xi+1 = b, and yi+1 = β. Lemma 3 shows that the values
of this probability.
IEEE TRANSACTIONS ON COMPUTERS, VOL. XX, NO. XX, MONTH YEAR 6
TABLE IV
PERFORMANCE ANALYSIS OF ALGORITHM 2
States xi+1yi+1 xiyi Computations ωi Paαbβ Line
S0 → S0 00 00 C = 2C 0 1/9 5
S0 → Sx 00 01ˆ C = 2C 0 1/9 6
S0 → Sx 00 1ˆ0 C = 2C ±A 1 1/9 6
S0 → S0 00 1ˆ1ˆ C = 2C ± (A±B) 1 1/9 5
S0 → S0 1ˆ1ˆ 00 C = 2C 0 1/9 5
Sx → S0 01ˆ 00 C = 2(C ±B) 1 1/9 9
Sx → Sx 01ˆ 1ˆ0 C = 2C ± (A± 2B) 1 1/9 8
Sx → S0 1ˆ0 00 C = 2C 0 1/9 9
Sx → Sx 1ˆ0 01ˆ C = 2C 0 1/9 8
the probabilities of the state to be S0, S′x, S
′′
x , S
′
y , and S
′′
y ,
respectively. Then
1) PS0 =
5
9 ,
2) PS′x =
4
27 ,
3) PS′′x =
2
27 ,
4) PS′y =
4
27 , and
5) PS′′y =
2
27 .
Proof: According to Lemma 1 and Lemma 2, the proba-
bility of the states is summarized as Figure 6.
&%
'$
&%
'$
&%
'$
&%
'$
&%
'$
S′y S0 S
′
x
S′′y S
′′
x
ﬀ -
- ﬀ
M
6 6
? ?
Q
Q
Q
Q
Q
Qs
´
´
´
´
´
+´1
5
1
5
3
5
1
2
1
2
1
2
1
2
1
2
1
2
1
2
1
2
Fig. 6. The detail state probability in Algorithm 3
Consider the probability in Figure 6, we get PS′′y =
1
2PS′y
implies PS′y = 2PS′′y , PS′y =
1
5PS0 +
1
2PS′′y implies PS0 =
15
2 PS′′y , PS′′x =
1
2PS′x implies PS′x = 2PS′′x , PS′x =
1
5PS0 +
1
2PS′′x implies PS0 =
15
2 PS′′x . Thus, we may assume that
PS′′y = PS′′x = p, and PS′y = PS′x = 2p, PS0 =
15
2 p. We
get (1 + 1 + 2 + 2 + 152 )p = 1 implies p =
2
27 , Therefore,
PS0 =
5
9 , PS′x =
4
27 , PS′′x =
2
27 , PS′y =
4
27 , and PS′′y =
2
27 .
Theorem 4: ω¯3(x, y) = 1127n ' 0.407n.
Proof: According to Table VI, the average joint Hamming
weight is computed as ω¯3(x, y) = ( 19+2
1+1+1+1
27 )n =
11
27n '
0.407n.
C. Apply asynchronous strategy to other codes
We have shown that asynchronous strategy can reduce
computational cost if x and y are encoded in sparse forms.
Asynchronous strategy can also be applied to other codes,
such as DJM code and joint sparse forms. Unfortunately,
the improvements of applying asynchronous strategy to these
codes are not as effective as sparse forms.
We first give an example to show that asynchronous strategy
can further improve the computational cost when it is applied
to DJM code and joint sparse from. Let the pair of integers
be
x = 100010101010100010100,
y = 01000101¯01¯01010001010.
We can first recode x and y by DJM code and joint sparse
form methods. Then apply the SS1 and DS1 methods to these
forms. All the values and the joint Hamming weight is shown
in Table VII.
Our simulation of 10000 pairs of 1024-bit integers generated
by the class of java.security.SecureRandom in Java
2 platform is shown in Table VIII.
Note that the results shown in the table also show that the
average performance for sparse form agrees perfectly to our
theoretical estimation.
IV. ASYNCHRONOUS STRATEGY FOR PURE BINARY CODE
Asynchronous strategy can also be applied to pure binary
code. In order to reduce the computational cost, the condition
for state transition from Sx to S0 should be modified to xi =
yi and yi 6= yi+1, denoted by xi = yi 6= yi+1. We need this
condition to ensure that 2(C+yi+1B)+(xiA+yiB) consists
of at most one additions and one doubles. The conditions of
shifting for pure binary code are shown in Figure 7. The
modified algorithm is called the SU1 algorithm. Here SU1
means single unsigned-integer and single stage. Similar to the
analysis of the SS1 algorithm, the average joint Hamming
weight can be reduced from 0.75n to 0.667n as shown in
Theorem 5. It needs only one extra register to store A+ 2B.
Lemma 5: In the SU1 algorithm, PS0 =
1
3 and PSx =
2
3 .
Theorem 5: The average joint Hamming weight of the SU1
algorithm is ω4(x, y) = 23n ' 0.667n.
The proof of Lemma 5 and Theorem 5 is similar to the SS1
method, and they are omitted.
Furthermore the proposed strategy can be generalized to
the t-stage version. For example, the SU1 method can be
IEEE TRANSACTIONS ON COMPUTERS, VOL. XX, NO. XX, MONTH YEAR 8
&%
'$
&%
'$
S0 Sx
-
-
xi 6= yixi = yi
ﬀ
ﬀ
xi = yi 6= yi+1 xi = yi+1 or
yi = yi+1 6= xi
Fig. 7. The state diagram for binary code
generalized to the SUt method. We now consider the values
of (xi, yi+s), s = 0, 1, · · · , t − 1. When State Sxi+s (S0 can
be regarded as Sx0) is transferred to Sxi+s+1 , the value of xi
is important. The condition for the state Sxi+s to transfer to
Sxi+s+1 is (xi, yi+s) = (0, 1). When State Sxi+j+1 is returned
to Sxi+j , we should consider the values of xi and yi+s−1. We
found that (xi, yi+s) = (1, 0) is time for the state to return to
Sxi+j . But in the first and the last stages, the state must keep
the same state even when the above condition occurs.
The state diagram of the SUt method is shown in Figure 8.
We summarize the SUt method in the Algorithm 4.
Algorithm 4
input: A, B, x, y
output: C = xA+ yB
1: compute A+B, A+ 2B, · · · , A+ 2tB, and 2tB.
2: C = O, s = 0, i = n;
3: for (i = n; i ≥ 0; i = i− 1) {
4: if (s = 0) {
5: if ((xi, yi) = (0, 1)) { s = 1; C = 2C; }
6: else C = 2C + (xiA+ yiB);
7: } else if (s = t) {
8: if ((xi, yi+t) = (1, 0)) {
9: s = t− 1; i = i+ 1;
10: } else C = 2C + (xiA+ yi+t2tB);
11: } else {
12: if ((xi, yi+s) = (0, 1)) { s = s+ 1; C = 2C;}
13: else if ((xi, yi+s) = (1, 0)) {
14: s = s− 1; i = i+ 1;
15: } else C = 2C + (xiA+ yi+s2sB);
16: }
17: }
18: while (s 6= 0) do s = s− 1, C = C + 2sysB;
19: output C.
Fig. 9. The SUt multi-exponentiation method.
By using Algorithm 4, the average joint Hamming weight
is reduced from 0.750n to 3
t−2t−1
5·3t−1−2tn as shown in Theorem 6.
Theorem 6: The average joint Hamming weight
ω
(t)
4 (x, y) =
3t−2t−1
5·3t−1−2tn in the SUt method.
In order to prove Theorem 6, we must subdivided the
probability of pi to p′i (yi+s = 0) and p
′′
i (yi+s = 1).
The technique to proof this theorem is similar to the DS1
algorithm, and it omitted here.
The number of additional registers required is increased
linearly as shown in Table IX.
V. CONCLUSIONS
In this paper, we propose a new strategy, the asynchronous
strategy, for multi-computations. In order to match more
zeros and non-zeros in multi-computation, the asynchronous
strategy modifies the computing sequences by shifting a block
of digits. By using the strategy, we propose two efficient
algorithms, named the SS1 and DS1 method for multi-scalar-
multiplications with binary signed-digit sparse forms. The
average joint Hamming weight is improved from 0.556n to
0.444n and to 0.407n, respectively. The number of additional
registers required is 2 and 4, respectively. Thus, the proposed
algorithms is suitable for memory limited environments.
Our proposed algorithms can also be combined with recod-
ing methods, including the DJM code and Solinas’ joint sparse
forms. However, our experiments show that the improvements
are not better than applying the method directly to the binary
sparse from.
Note that the recoding methods are useless in pure binary
code. However, our proposed strategy can also be applied to
pure binary code. In binary code for multi-computation, the
average joint Hamming weight can be improved form 0.75n
to 0.667n with only one extra register in single stage version.
The proposed strategy, especially the SU1 algorithm can be
extended to small window method. The simplest case is that
the basis 2 in the SU1 algorithm is replaced by 2h. Thus we
need to store all possible value of (xiA + yiB) and (xiA +
yi2hB). This will need (22h+1 − 2h) extra registers (h ≥ 2)
in the small window SU1 algorithm. When h is increased, the
storage is exponentially increased. This is a common problem
for sliding window method.
In general case, the shifting operations can be applied
more than once. Consider the multi-stage version of the
binary code, the average joint Hamming weight can be further
improved to 3
t−2t−1
5·3t−1−2tn in the t-stage version. The number of
additional registers increases linearly in comparison with the
exponentially increase in sliding window method [17], [18].
ACKNOWLEDGEMENT
This work was supported by the National Science Council,
Taiwan, under contract NSC 94-2213-E-156-004, NSC 94-
2219-E-006-007, and in part by TWISC@NCKU under the
Grants NSC 94-3114-P-006-001-Y.
REFERENCES
[1] W. C. Yang, D. J. Guan, and C. S. Laih, “Fast multi-computations with
integer similarity strategy,” in International Workshop on Practice and
Theory in Public key Cryptography-PKC 2005, LNCS 3386. Springer-
Verlag, 2005, pp. 139–153.
[2] T. ElGamal, “A public key cryptosystem and a signature scheme based
on discrete logarithms,” IEEE Transactions on Information Theory,
vol. 31, no. 4, pp. 469–472, Jul. 1985.
[3] C. P. Schnorr, “Efficient identification and signatures for smart cards,”
in Advances in Cryptology-CRYPTO’89, LNCS 435. Springer-Verlag,
1989, pp. 239–252.
