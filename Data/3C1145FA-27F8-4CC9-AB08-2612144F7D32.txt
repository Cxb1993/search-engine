                                                                             
運用物理屬性於三維虛擬角色骨架之動作調適法 
Applying a Physically Based Motion Adaptation Technique to 
Animate Multi-limbs 3D Virtual 
Characters 
 
盧天麒 
國立嘉義大學資訊工程學系 
60004 嘉義市鹿寮里學府路 300 號 
TEL: +886-5-2717730 
tclu@mail.ncyu.edu.tw 
中文摘要 
擷取虛擬角色所有的反應動作是一件相當困難
的事情，於是本計畫提出一套新的反應動作生成
方法，利用少量的反應動作資料產生眾多的受力
情形，此方法適用於雙足或多足之各類虛擬角
色。我們預先擷取部份反應動作，並使用動作編
輯方法 (motion editing)擴增來源動作數量。本計
畫利用一段原始的動作資料，由使用者定義外力
施力於虛擬角色特定部位，再以物理屬性運算方
法，計算虛擬角色所增加的動量，並使用反向運
動學 (inverse kinematics)技術中的 damped least 
squares (DLS)方法模擬其受力過程，為了使反應
動作更完整，系統從資料庫中尋找相似的反應動
作資料並給予適當的動作調整，最後利用動作串
接技術完成整個動作生成方法。 
關鍵詞：電腦動畫、力的限制、物理屬性運算、
反向運動學、動作編輯、動作串接。 
第一章、簡介 
電腦動畫技術中模擬出真實的虛擬角色動作的
各種姿勢[16][24][33]，仰賴動畫設計師運用個人
的能力，然而不同的場景與情境可能都會改變虛
擬角色的動作，因此動畫設計師必須花費相當多
的時間調整角色的動作。 
而動作擷取器的興起[3][20][23]及動作重置技術
(motion retargeting) 的 使 用  [9] [11] 
[14][26][30]，使動作資料能夠用於更多不同種類
但骨架結構相似的虛擬角色上。儘管如此，許多
虛擬角色無法透過真實的生物進行錄製動作，因
此本計畫將以海豹作為實驗角色，提出一套反應
動作產生的方法，其主要原因為海豹動作並不易
取得，我們希望用少量的反應動作，產生更多受
力反應情形。本計畫著重於脊椎生物，首先輸入
原始的動作與骨架資料，根據使用者給予力的限
制，再透過線性動量與角動量的分析與反向運動
學 (inverse kinematics, IK) 技術模擬其受力結
果，最後從資料庫動作檔案當中尋找相似的動作
資料與以串接，並依據施力的大小進行動量的調
整，使串接結果更為自然。 
第二章、相關工作  
現今動畫技術領域中，創造出擁有物理屬性和合
理的反應動作已成為近年來備受關注的議題，而
模擬角色又多以人 [1][4][5][8][12][13][27] 為
主，但這些技術未必能夠套用在非人類的相關生
物上 ;在 2009 年 Wampler [32]提出時空方法
(spacetime constraints)和樣本基礎的混合式最佳
化方法，對於兩足或多足生物都能有效計算。 
對於動作資料，如何修改少量的動作資料而產生
更多的真實動作，即為動作編輯(Motion Editing)
的範疇；Ikemoto [15]針對一個虛擬角色，將其中
一段的角色動作移植到另一段動作上，而所有修
改過後的動作內容，將由訓練過的 support vector 
machine (SVM) [7]分析結果是否符合自然動作。 
                                                                             
[34]利用線性化處理解決了此問題，其對應關節
速度與角速度之線性關係如 2-2所示: 
p ( ) ,
.
J
f
J
 




             
(2-2)
 
其中 p 為末端節點速度， J 為雅可比矩陣
(Jacobian matrix)，為關節角速度，Jacobian矩
陣之目的為找出角度與末端節點世界座標之相
對關係，我們可以得到反向運動學的解法: 
1( )p,J             (2-3) 
當虛擬角色的動作達到特定姿勢時，會使得雅可
比矩陣的秩減少；原因為某些關節對於末端位置
之影響可由其他關節取代，為了解決此問題，
damped least squares (DLS)是常見使用來完成反
向運動學之方法， DLS 方法如下: 
1. 根據關節矩陣轉換方法，找出從 root到末端 
關節之矩陣關係式，其中 p 為末端節點於世
界座標中之位置， 0p 為髖骨關節之位置。 
0
0
,
.
i
i
p p M
p p M
 
 
          
(2-4) 
2. 將關節矩陣轉換方法，對於各相關關節角度
取偏微分，找出各關節對於末端位置之影
響，而該微分後的矩陣即為雅可比矩陣，其 
中 ixM 為關節轉換矩陣對於末端節點 X 軸座
標值之影響， iyM 與 izM 為對 Y 以及 Z 軸值
之 
影響。 
1 2 3
1 2 3
1 2 3
   ....
 =    .... .
   ....
ix ix i x i x
n
i y i y iy i y
n
iz iz i z i z
n
M M M M
M M M M
J
M M M M
   
   
   
 
    
 
 
 
    
 
 
           
(2-5) 
3. 為了找出最適合的關節角度變化，我們將對
式 2-6取得最佳化結果，其中  為角度變 
化量， e為末端節點位置與目標位置之向
量，為阻尼值，該值影響收斂的時間複雜 
度與反向運動學方法之準確程度。 
2 22 -  ,J e    
      
(2-6) 
4. 藉由最佳化後的結果，我們可以得出式 2-7，
以此式找出最適當之關節角度修改值。 
2 -1  (   )  .T TJ JJ I e   
      (2-7) 
 根據上述四個步驟，我們可以利用 DLS 方
法調整末端節點位置，亦可修正違反角色穿透地
面之不正常情況。 
第三章、虛擬角色參數化與力的限制  
 
圖 3.1 為整個研究架構方塊圖，包含虛擬角色的
整個反應動作流程，將經過七個階段的程序，依
序處理而產生結果反應動作。 
 
1. 角色初始設定(character  initializeation) :
對虛擬角色的骨架內容，給與相對應的物理
性質。 
2. 預先擷取反應動作 (pre-captured motion 
data) :預先擷取的反應動作並將依受力的大
小、方向排序，這些反應動作將會在海豹模
擬完受力反應後，尋找最相似者並串接。 
                                                                             
4. 關節運動限制(range):本計畫以來源動作為
參考依據，使用動量為基底的反向運動學技
術模擬受力動作，由於反向運動學方法會以
最小關節修改量調整，因此無須對每個關 
節作限制。 
3.2預先擷取反應動作與動作編輯  
我們預先模擬了部份反應動作，接著使用動作編
輯技術，產生豐富的動作反應片段，以確保每種
施力至少有一種反應；我們利用動作限制方法定
義了虛擬角色所應變動的內容，符合使用者的動
作需求並且需遵守運動定律。我們使用牛頓運動
定律之延伸拉格朗日方程式，本計畫參考[31]，
而為了更為符合系統的要求，我們將其公式推導
為式 3-4，其中 q為廣義座標系統中之向量，而 f
為廣義力 i為骨架編號， j表示每個關節之廣義
座標內容，
G
jf 代表根關節(root)之重量而
M
jf 表
其他關節肌肉力量，我們將式 3-4視為動態限制
D，於合理之運動狀態下其值必須為 0 : 
( , ) ( ) 0,
 root,  
.
 
i i
j
j i j j
G
j j
M
j j
T Td
D q f f
dt q q
if i f f
else f f
 
   
 
  



  (3-4) 
 當此限制用於虛擬角色動作模擬時，我們將
給予基本的動能、關節作用力等基本數值，我們
利用梯度方法找出每個階段所需修改之最小方
向向量，以該階段最佳的修改長度進行調整，如
式 3-5所示，其中 D為動態限制，使用者所定義 
的限制 K。 
2
arg min
( ) 0
   .
( ) 0
i
v
i
i
v v
D q v
subject to
K q v




      
(3-5)
 
i  表當前修改階段， iv 為階段最小修改向量， iq
則是當前修改階段之角色動作狀態，其中包含關
節角度、位置、速度、受力等內容， iv 必須受由
動態限制、運動限制之線性化函式控制，並決定
該向量是否被接受，其後再取最小者做為階段的
修改向量，並經過數個修改步驟完成整個動作內
容修改。 
3.3力的限制 
根據來源動作，使用者可以給與特定的施力，在
本系統中，我們定義了力的方向、力的大小與施
力點的位置，其中力的方向可分為水平上的四個
方位，分別為前後、左右，此外還有垂直面上的
上下方位，力的單位為牛頓。 
第四章、反應動作模擬 
本計畫中提出新的方法產生虛擬角色的反應動
作，首先錄製或手動繪製部份的虛擬角色反應動
作，並將一段虛擬角色的原始動作檔案，經過使
用者定義的施力後，利用動量為基底的反向運動
學技術產生受力反應，模擬受力階段完成後，再
與預先錄製或手動繪製的反應動作比對，找出相
近的反應動作進行調整串接，以完成整個反應動
作之產生過程。本章節我們將詳細的介紹如何利
用反向運動學技術產生反應動作，以及提出動作
調整串接的詳細步驟。 
4.1以動量為基底的反向運動學技術  
進行反應動作模擬之前，我們先考慮虛擬角色整
體骨架系統的運動方程式，我們必須找出虛擬角
色身上的原始動量。當虛擬角色在移動時必帶有
速度，根據虛擬角色存在的質量推算其線性動量
的存在，首先我們簡化問題，考量單一質點的動
量 p時，我們可以由 p mv 找出該質點動量，而
延伸到剛體時，我們可以經由 mivi式子去加總
剛體上每一質點的線性動量，其中 mi為第 i 個質
點之質量，vi為該質點之速度，但考量剛體的每
個質點是相當複雜的事情，因此我們若以該剛體
的質心點為其質量總和，再以該質心點推算其線
性動量，這是較為簡易且正確的方法；虛擬角色
的質心位置通常為虛擬角色的髖骨關節(或根關
                                                                             
方向向量， ,0rv 則為原始影格中海豹右前肢到海
豹髖骨的向量， ,0hv 是海豹頭部關節至海豹髖骨
的向量，海豹脊椎末端到海豹髖骨的向量 ,0bv ，
,1lv 為資料庫裡初始影格中海豹的左前肢到海豹
髖骨的向量， 0I 表示原始影格中虛擬角色的慣性
值， 1I 表示動作資料庫裡初始影格中虛擬角色的
慣性值， 1k 與 2k 為加權參數，由式 4-7我們可以 
找到最接近的動作資料。 
4.3相似動作優化與動作串接 
預先擷取的反應動作當中，其虛擬角色所受的外
力未必和使用者給予的預設力相同，因此模擬完
受力後的動作片段與資料庫相似的動作片段仍
然有一段差異，為了彌補受力的差距，我們將線
性動量( p )的彌補方法與角動量( l )的彌補方法
分開討論。 
4.3.1線性動量之彌補  
為了彌補所受力道大小之不同，我們必須先找出
其受力的大小關係，由於力的大小將會直接影響
線性動量( p )的數值，影響海豹的移動速度，我
們假定 sF 為預先擷取反應動作中虛擬角色所受
的外力， dF 則是使用者定義的新外力，我們將計
算其受力的倍率大小，如下所示 : 
d
s
 .
F
F
 
            
(4-8)
 
 我們試著將不同力道所應影響的海豹速度
納入考量，根據線性動量的方法，增加的比例
會顯著的增加海豹的位移量，因此我們列出以下
的式子，藉此找出所應調整的海豹速度 : 
' .
N
v v
m

 
          
(4-9)
 
 其中 N 為角色所受之正向力，對於摩擦力中
動摩擦力係數( )的考量，會使動作更為逼真，
利用式 4-8、式 4-9 我們可以將調整資料庫的動
作資料，使得兩個片段動作更為符合。 
4.3.2角動量之彌補  
對於動作資料庫過多的調整，將使得系統整體運
算複雜度提升；較不利於即時運算結果，因此角
動量的調整，我們採用較為直接的想法，預先擷
取的動作，由於經過較長時間的調整或是從真實
生物身上的取得，預錄的動作皆為真實度相當高
的動作，而根據力道的不同則會影響關節的力
矩，由
dl
dt
  與 l I 發現力矩與角速度之間的 
關連性，我們將根據力矩的比例找出其對應的角
度變化量， 3k 為根據離髖骨(root)關節階層遠近
的加權矩陣， 'i 是新的角速度向量， i 則為尚
未修改的角速度向量，i 則為相關關節 : 
3'i ik            (4-10) 
 只調整關節角度不能夠達到有效且令人信
服的結果，為了使海豹更能夠符合真實情況，我
們結合了線性與角動量的方法，根據施力前後的
差距，調整其線性動量與角動量的大小，再找出
動量與海豹的關聯，以物理屬性的方式進行調
整，而系統將會對海豹的關節角速度、移動速度
做出對應的變化，以利後續動作串接的自然性。 
4.3.3動作串接  
完整的動作片段需要的不單是模擬受力的結
果，受力後的反應也是相當重要的，在反應動作
的最後階段，我們將兩段動作進行動作串接，在
本計畫中，為了能夠快速的生成反應動作，我們
不使用過於複雜的計算方法，本計畫利用線性內
插法結合此兩段動作資料，其中 p為內插後的線
性動量， I  則為內插後的角動量，如下所示 : 
0 0 1 1( ( ), ( )) (1 )( ( ), ( )) ( ( ), ( ))p t I t p t I t p t I t       
 
(4-11) 
 由 4-11 可以找出線性內插後的結果，我們
將新的線性動量與角動量，分別對海豹的速度與
相關關節角速度進行調整，完成反應動作結果。 
                                                                             
5.3受力反應  
模擬受力反應時，我們將線性動量與角動量分開
討論，使用者可以給予不同的施力方向與施力大
小，影響角色的速度與角速度，線性動量(Linear 
Momentum)能夠顯著的改變角色速度，適當修改
海豹的線性動量，當得到新的動作後，我們試著
將動作資料轉移到 3dsmax 上套用海豹角色，如
圖 5.7 所示，海豹受到向前與向側邊的推力時，
產生應有的新速度。 
 
圖 5.7：線性動量修改。上圖為海豹受力而改變
向前的速度，下圖為海豹受側邊力增加線性動
量而產生應有的位移。 
 
而角動量(Angular Momentum)對於海豹的擺動
幅度有顯著的影響，因此在施力方面，我們針對
了同位置不同角度、同角度不同施力兩種情況，
施力於海豹身上最顯著的頭部位置，如圖 5.8 所
示。 
 
圖 5.8：不同受力反應實例一。 
 
除了不同方向的施力外，使用者亦能修改施力的
大小，而此大小將會明顯的影響海豹所增加的角
動量，如圖 5.9所示。 
 
圖 5.9：不同受力反應實例二。 
利用最佳化方程與 Damped Least Squares，我們
能夠確實的模擬海豹的受力反應，如圖 5.10 所
示。 
 
圖 5.10：受力反應實例三。 
當海豹受到特定方向力時，其運動結果應該會有
特定軸之數值變化不顯著，如圖 5.11 與 5.12 所
示，從當中我們可看出其末端節點位置變化量符
合我們所預期的結果，也確保了海豹頭部軌跡變
化的速度相似。 
 
 
圖 5.11：末端節點動作資料一。當海豹受到向左
的力時，其末端節點座標位置變化之情形，我們
可由表看出由於海豹頭部擺幅偏向 X 軸中正值
部分，因此 X座標值快速上升，因為是水平的推 
力，因此海豹頭部高度的變化不明顯。 
 
 
圖 5.12：末端節點動作資料二。當海豹受到向上
的力時其頭部位置的變化情形，Y軸座標的變化
顯示出海豹頭部向上擺動的幅度，而其斜率相近
象徵其速度相似。 
  
  
                                                                             
[4] Norman I. Badler, Ramamani Bindiganavale, 
John P. Granieri, Susanua Wei, and Xinmin 
Zhao, “Posture Interpolation with Collision 
Avoidance,” Proceedings of Computer 
Animation, pp. 13-20, 1994. 
[5] Srikanth Bandi and Daniel Thalmann, “A 
Configuration Space Approach for Efficient 
Animation of Human Figures,” Proceedings of 
IEEE Non Rigid and Articulated Motion 
Workshop, IEEE Computer Society Press, pp. 
38-45, 1997. 
[6] Samuel R. BUSS, “Introduction to Inverse 
Kinematics with Jacobian Transpose, 
Pseudoinverse, and Damped Least Squares 
Methods,” available through 
http://math.ucsd.edu/~sbuss/ResearchWeb, 
October 2009. 
[7] Chih Chung Chang and Chih Jen Lin, 
“Libsvm: Introduction and Benchmarks. Tech. 
Rep.,” Department of Computer Science and 
Information Engineering, National Taiwan 
University, 2000. 
[8] Stephen Chenney, “Flow Tiles,” Proceedings 
of the 2004 ACM SIGGRAPH/Eurographics 
Symposium on Computer Animation, pp. 
233-242, 2004. 
[9] Kwang Jin Choi and Hyeong Seok Ko, 
“On-line Motion Retargetting,” The Journal of 
Visualization and Computer Animation, Vol. 
11, No. 5, pp. 223-235, 2000. 
[10] FLTK, http://www.fltk.org/, February 2010. 
[11] Michael Gleicher, “Retargetting Motion to 
New Characters,” Proceedings of the 25th 
Annual Conference on Computer Graphics 
and Interactive Techniques, pp. 33-42, 1998. 
[12] Hugh Herr and Marko Popovic, “Angular 
Momentum in Human Walking,” Journal of 
Experimental Biology, No. 211, pp. 467-481, 
2008. 
[13] Jessica K. Hodgins, Wayne L. Wooten, David 
C. Brogan And James F. O’Brien, “Animating 
Human Athletics,” ACM Transactions on 
Graphics, Vol. 29, pp. 71-78. 1995. 
[14] Ming Kai Hsieh, Bing Yu Chen, and Ming 
Ouhyoung, “Motion Retargetting and 
Transition in Different Articulated Figures,” 
Proceedings of Ninth International Conference 
on Computer Aided Design and Computer 
Graphics, pp. 457-462, 2005. 
[15] Leslie Ikemoto and David A. Forsyth, 
“Enriching a Motion Collection by 
Transplanting Limb,” Proceedings of the 2004 
ACM SIGGRAPH/Eurographics Symposium 
on Computer Animation, pp. 99-108, 2004. 
[16] Isaac V. Kerlow, The Art of 3D Computer 
Animation and Effects, 3
rd
 Edition, John Wiley 
& Sons, Inc., 2004. 
[17] Taku Komura, Edmond S. L. Ho and Rynson 
W. H. Lau, “Animating Reactive Motion 
Using Momentum-Based Inverse Kinematics,” 
Computer Animation and Virtual Worlds, Vol. 
16, Issue 3-4, pp. 213-223, 2005. 
[18] Lucas Kovar, Michael Gleicher, and Frédéric 
Pighin, “Motion Graphs,” ACM Transactions 
on Graphics, Vol. 21, Issue 3, pp. 473-482, 
2002. 
[19] Jehee Lee, Jinxiang Chai, Paul S. A. Reitsma, 
Jessica K. Hodgins, and Nancy S. Pollard, 
“Interactive Control of Avatars Animated with 
Human Motion Data,” ACM Transactions on 
Graphics, Vol. 21, Issue 3, pp. 491-500, 2002. 
[20] Alberto Menache, Understanding Motion 
Capture for Computer Animation and Video 
Games, Academic Press, 2000. 
[21] Michael Meredith and Steve Maddock, 
“Adapting Motion Capture Data Using 
Weighted Real-Time Inverse Kinematics,” 
ACM Computers in Entertainment, Vol. 3, 
Issue 1, p. 5, 2005. 
[22] Masaki Oshita and Akifumi Makinouchi, “A 
Dynamic Motion Control Technique for 
Human-Like Articulated Figures,” Computer 
Graphics Forum, Vol. 20, No. 3, pp. 192-202, 
2001. 
[23] Pitotech, available through 
http://www.pitotech.com.tw/c/2-product07.ht
m, February 2011. 
[24] Jr. Richard S. Wright and Benjamin Lipchak, 
OpenGL SuperBible 3/e, SAMS, 2004. 
[25] Alla Safonova and Jessica K. Hodgins, 
“Construction and Optimal Search of 
Interpolated Motion Graphs,” ACM 
Transactions on Graphics, Vol. 26, Issue 3, pp. 
106-116, 2007. 
[26] Alexander Savenko and Gordon Clapworthy, 
“Using Motion Analysis Techniques for 
國科會補助專題研究計畫項下出席國際學術會議心得報告 
                                   日期：2011年 11月 30日 
                                 
一、參加會議經過 
本屆國防、科學與研究國際研討會(DSR2011)由新加坡國立大學主辦，地點在新加坡舉行，該
會議定期舉辦且歷屆的規模龐大，每年均吸引眾多學者投稿發表論文，因為本屆 DSR2011有數個國際
相關研討會平行舉辦，所以論文發表數量相對較多，因此論文接受率平均值較高；今年會議地點位於
新加坡 Suntec 會議展覽中心，本次的 full paper 論文被大會安排於 8/3 16:00PM 至 18:00PM 的 General 
Session 1 進行論文發表，此場次的論文發表主題為 Simulation Technology and Series Gaming，共計有
6 篇論文發表，此場次論文報告者均來至於亞洲各國，國家包含台灣、新加坡、大陸及日本等國家，
內容涵蓋虛擬環境規劃與設計、體感互動感知技術、決策資源系統模擬及大型兵棋推演模擬訓練等議
題，會場 Q&A 討論情況踴躍，同時也跟在場與會人士進行短暫的主題討論。 
 
二、與會心得 
本屆 DSR2011 在新加坡舉辦，因開會地點位於大型會議展覽中心並且交通方便，因此吸引眾多
的學者參與本次的研討會；在發表論文方面，雖然台灣的研究學者發表為數眾多的論文在此研討會，
但相較於新加坡學者積極參與及流利的論文發表，平均英文論文報告的能力明顯提升，我們還有更努
力的空間；此外，在日後也希望國內能多爭取類似的大型國際會議，除了讓國內學者能和國際學者進
行更緊密交流之外，也能讓國際學者及學生進一步瞭解台灣，增加跨國合作機會並提升國內相關領域
研究水準。而本次 DSR2011 並邀請了其它國家的知名學者擔任 session chairs 並進行論文發表，因此
session 數量及 workshop 數量非常多，會場中儼然成為一個小型聯合國。 
 
三、建議 
無 
 
四、攜回資料名稱及內容 
 大會手冊一本 
 大會議程一紙 
 論文集一本(含光碟)
計畫編號 NSC99-2221-E-415-014 
計畫名稱 運用物理屬性於三維虛擬角色骨架之動作調適法 
出國人員
姓名 
盧天麒 
服務機構
及職稱 
嘉義大學資工系副教授 
會議時間 August 3-5, 2011 會議地點 新加坡 
會議名稱 
(中文) 2011 年國防、科學與研究國際研討會 
(英文)2011 Defence, Science & Research Conference (DSR 2011) 
system or not. As a result, we design a virtual pet system with 
remote sensing device to demonstrate the adaptability of the 
proposed technology, and the system is appropriate to most 
little children to educate them to learn how to take care a 
virtual baby seal. 
II. RELATED WORK 
In this section, we survey related methods about performing 
motion editing, motion transition, and simulating physically 
motions of virtual characters. Existing motions could not be 
applicable to new task requests, wherefore these existing 
motions are demanded for modifications with some approaches, 
such as transition, interpolation, or user-defined simulation 
methods. The considerations to motion editing have been 
concentrated on yielding more derived motions through an 
easy-to-use user interface [10]. Ikemoto and Forsyth took 
advantage of transplant of limb motion to enrich motion data 
[11]. They hived off upper limbs of human bodies, and then 
attached upper limbs to other human bodies through analogous 
step matching, random matching, and least difference matching. 
However, their method only adapts to humanoid characters. 
Reference [12] presented a physical simulation technique to 
manipulate a rigid body throughout the interaction. Animators 
are able to directly manipulate the entire motion by grapping 
and changing the state of the rigid body in a free fashion. The 
technique computed physical parameters and simulated the 
resulting motions. 
To generate complete motions for different tasks, motion 
transition is one of the convenient means to be carried out. 
Reference [7] proposed a so-called “motion graph”, which is 
based on directed graph for concatenating several short motion 
clips by aggregating a long motion clip. The source motion can 
be partitioned and rearranged to accomplish particular tasks. 
Heck and Gleicher [13] presented an example-based technique 
to produce accurate, controllable, high-fidelity motion 
sequences. They devised a data structure, namely parametric 
motion graph, to describe adequate ways of transiting motion 
clips in real-time with less user-intervention. Safonova and 
Hodgins [14] furthermore integrated interpolations for 
optimizing the resulting motions, which can be adapted to more 
motion and environment constraints. Reference [15] presented 
a two-layer structure to first preprocess for flexibility in 
behavior and then search through the resulting graph structure 
for creating a plausible motion transition. In addition, three 
interface techniques have been demonstrated for controlling 
avatar motion by means of the two-layer structure. Reference 
[16] designed a time warping method to not only concentrate 
on one single frame but the neighbors of the frame. 
Accordingly, two point clouds that belong to destination and 
source motions respectively are created before they measured 
the joint distance for each corresponding point. With respect to 
a large motion data set, it almost contains a wide variety of 
character actions that are likely same kind of motion; 
consequently it is hard to properly exploit the point. Kovar and 
Gleicher [17] developed an algorithm in terms of the use of 
registration curves to aim to identify logically similar motions 
from a large motion data set. The above methods can be 
applied to serve as useful tools for on-line motion composing; 
however, these methods are to be provided with a large-scale 
motion database to achieve different requirements. 
III. MOTION SENSING TECHNOLOGY 
With regard to prior research on computer animation and 
entertainment games, biped characters are most adopted instead 
of paying attention to quadruped animals. In this section, we 
present the proposed approach in detail and choose a baby seal 
as a sample object to demonstrate how to make use of a remote 
sensing device to interact with an animal character. 
A. Motion Graph Construction 
As shown in Figure 1. , we classify the possible locomotion 
of a baby seal no matter what the motions are real or fake into 
five states. In other words, fourteen motions are hand-crafted 
by a skilled animator by which they are categorized into the 
five states, as listed in TABLE I. . Subsequently dynamic time 
warping (DTW) is employed to measure similarity between 
two motions that are individually in different states. A distance 
map regarding each pair of two motions will be constructed 
after accomplishing the DTW and an optimal shortest path will 
be also obtained through the distance map. Theoretically, a 
motion graph is regarded as a directed graph which each edge 
represents clips of motions. Due to the fact that all reference 
motions are cyclic, we can simply find a starting point to start 
the blending. Suppose that there is a directed edge between two 
states in the motion graph, we are capable of using linear 
blending to blend specified destination and source frames with 
each other and transfer from the current state to another target 
state smoothly. 
 
Figure 1.  The motion graph. 
TABLE I.  MOTION STATES IN THE MOTION GRAPH 
States Motion Data 
Idle Idle (above the land), Head-Nodding, Sleep, Wake up, 
Idle (under the sea) 
Walk Crawl, Swim (under the sea) 
Turn Turn (above the land), Turn (under the sea), Follow 
Roll Roll, Circle 
Special Clap, Head-Poking 
 
B. Motion Sensing Manipulation 
The proposed system provides users with two phases, 
including static and dynamic phases, to try to interest users no 
matter while the system is being idle or busy. In the static 
phase, the baby seal will be animated by which the system 
arbitrarily chooses a state in the motion graph. After finishing 
the current motion display, the state of the character will be 
back to the idle state immediately such that the idle state can be 
automatically transferred to another state as long as users still 
have no response to the character. Regarding dynamic phase, if 
Figure 4.  (a) An illustration of a distance map with the computed optomal 
path. The destination motion is walking with the head rotating around and the 
source motion is walking forward. (b) The result of applying motion blending. 
In Figure 5. 5, we demonstrate motion displays in the static 
phase where the top row is to make the seal walk forward, the 
middle row is to turn it around, and the bottom row is to roll it 
back at the same place. When the system really interests users 
to interact the character again, we will immediately change the 
system from the static phase to the dynamic phase. 
 
Figure 5.  Motion displays in the static phase. (Top row) walking forward. 
(Middle row) turning around. (Bottom row) rolling back. 
In Figure 6. 6, the system is working in the dynamic mode 
with the touching scenario. Users can swing the remote 
controller for moving the virtual palm and make the seal 
become clap. After successfully touching the seal via the palm, 
the seal will first walk forward to be near users and try to clap 
its hand for attracting users to contact with it again. 
 
Figure 6.  Motion displays in the dynamic phase with the touchingscenario. 
V. CONCLUSION 
In this paper, we have proposed an interesting motion 
sensing system that users can hold a remote sensing device to 
control a virtual character as well as interacting with a virtual 
environment. A baby seal has been picked up to serve as a 
sample quadruped character to either move on an ice land or 
swim under the sea. Two manipulation modes with pre-scripted 
scenarios, including static and dynamic operations, are devised 
to raise physical interactions between the proposed system and 
users. With regard to the technologies that are applied to the 
system, we first take advantage of dynamic time warping to 
measure the similarity of each pair of motion sequences and 
then make use of motion transition and linear blending to 
transit from a source motion to a destination motion seamlessly. 
A motion graph has been established to facilitate the motion 
transition in a smooth manner. All possible responsive motions 
of a baby seal have been associated with the remote sensing 
device in order to make users interact with the character. The 
implementation results show that we have demonstrated the 
feasibility of the proposed motion sensing technology in 
interacting with a baby seal in an ice field. In particular, the 
proposed method is applicable to design a game-based learning 
tool due to its operational flexibility and technical feasibility. 
ACKNOWLEDGMENT 
This work is supported in part by the National Science 
Council at Taiwan, R.O.C., under the project grant numbers 
NSC99-2221-E-415-014 and NSC 99-2218-E-006-001. 
REFERENCES 
[1] Yeuhi Abe and Jovan Popović, “Interactive Animation of Dynamic 
Manipulation,” In Proceedings of the 2006 ACM 
SIGGRAPH/Eurographics Symposium on Computer Animation, pp. 
195-203, Sept. 2006. 
[2] Minchih Tsai, Tainchi Lu, and Tailin Chen, "Physically Based Motion 
Adaptation for Diverse Articulated Figures," International Journal of 
Digital Content Technology and its Applications, Vol. 5, No. 2, pp. 
72-84, 2011. 
[3] Sumit Jain, Yuting Ye, and C. Karen Liu, “Optimization-Based 
Interactive Motion Synthesis, “ACM Transactions on Graphics, Vol. 28, 
No. 1, pp. 491-500, Jan. 2009. 
[4] Yuting Ye and C. Karen Liu, “Optimal Feedback Control for Character 
Animation Using an Abstract Model,” ACM Transactions on Graphics, 
Vol. 29, No. 4, pp. 1-9, July 2010. 
[5] Kwang Won Sok, Manmyung Kim, and Jehee Lee, “Simulating Biped 
Behaviors from Human Motion Data,” ACM Transactions on Graphics, 
Vol. 26, No. 3, Article 107, pp. 1-9, July 2007. 
[6] Jonathan Starck and Adrian Hilton, “Surface Capture for 
Performance-Based Animation,” IEEE Computer Graphics and 
Applications, Vol. 27, No. 3, pp. 21-31, 2007. 
[7] Lucas Kovar, Michael Gleicher, and Fr´ed´eric Pighin, “Motion 
Graphs,” ACM Transactions on Graphics, Vol. 21, No. 3, pp. 473-482, 
July 2002. 
[8] Pavel Senin, Dynamic Time Warping Algorithm Review. Information 
and Computer Science Department University of Hawaii at Manoa 
Honolulu, USA, 2008. 
[9] Kristine Slot, Motion Blending, Department of Computer Science at the 
University of Copenhagen, Feb. 2007. 
[10] Sumit Jain and C. Karen Liu, “Interactive Synthesis of Human-Object 
Interaction,” In Proceedings of the 2009 ACM 
SIGGRAPH/Eurographics Symposium on Computer Animation, pp. 
47-53, 2009. 
[11] Leslie Ikemoto and David A. Forsyth, “Enriching a Motion Collection 
by Transplanting Limb”, In Proceedings of the 2004 ACM 
SIGGRAPH/Eurographics Symposium on Computer Animation, pp. 
99-108, 2004. 
[12] Jovan Popović, Steven M. Seitz, Michael Erdmann, Zoran Popović, and 
Andrew Witkin, “Interactive Manipulation of Rigid Body Simulations,” 
In Proceedings of SIGGRAPH 2000, pp. 209-217, 2000. 
[13] Rachel Heck and Michael Gleicher, “Parametric Motion Graphs,” In 
Proceedings of the 2007 Symposium on Interactive 3D Graphics and 
Games, pp. 129-136, 2007. 
[14] Alla Safonova and Jessica K. Hodgins, “Construction and Optimal 
Search of Interpolated Motion Graphs,” ACM Transactions on Graphics, 
Vol. 26, No. 3, p. 106, 2007. 
[15] Jehee Lee, Jinxiang Chai, Paul Reitsma, Jessica Hodgins, and Nancy 
Pollard, “Interactive Control of Avatars Animated with Human Motion 
Data,” ACM Transactions on Graphics, Vol. 21, No. 3, pp. 491-500, 
July 2002. 
[16] Michael Gleicher, Hyun Joon Shin, Lucas Kovar, and Andrew Jepsen, 
“Snap-Together Motion: Assembling Run-Time Animations,” In 
Proceedings of the 2003 Symposium on Interactive 3D Graphics, April 
2003. 
[17] Lucas Kovar and Michael Gleicher, “Automated Extraction and 
Parameterization of Motions in Large Data Sets,” ACM Transactions on 
Graphics, Vol. 23, No. 3, pp. 559–568, 2004.
國科會補助計畫衍生研發成果推廣資料表
日期:2011/11/30
國科會補助計畫
計畫名稱: 運用物理屬性於三維虛擬角色骨架之動作調適法
計畫主持人: 盧天麒
計畫編號: 99-2221-E-415-014- 學門領域: 計算機圖學
無研發成果推廣資料
其他成果 
(無法以量化表達之成
果如辦理學術活動、獲
得獎項、重要國際合
作、研究成果國際影響
力及其他協助產業技
術發展之具體效益事
項等，請以文字敘述填
列。) 
將本計畫所研發的技術整合至三維電腦遊戲作品中並榮獲台北市政府「第六屆
台北數位藝術節 K.T.科藝獎」數位遊戲組銅獎，2011。 
 成果項目 量化 名稱或內容性質簡述 
測驗工具(含質性與量性) 0  
課程/模組 0  
電腦及網路系統或工具 0  
教材 0  
舉辦之活動/競賽 0  
研討會/工作坊 0  
電子報、網站 0  
科 
教 
處 
計 
畫 
加 
填 
項 
目 計畫成果推廣之參與（閱聽）人數 0  
 
